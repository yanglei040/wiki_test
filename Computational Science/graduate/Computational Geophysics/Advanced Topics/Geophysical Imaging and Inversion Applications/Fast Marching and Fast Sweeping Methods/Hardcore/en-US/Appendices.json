{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of developing reliable numerical solvers is formal verification. Before a code can be trusted for complex scientific inquiry, we must confirm that it behaves as theoretically predicted. This practice guides you through a grid-refinement study, a standard procedure to empirically measure a scheme's order of convergence. By solving the Eikonal equation on progressively finer grids and comparing the numerical solutions to the known analytical result, you will verify that the first-order Godunov upwind scheme indeed reduces error linearly with grid spacing, a key indicator of a correct implementation .",
            "id": "3591153",
            "problem": "Consider the two-dimensional Eikonal equation for first-arrival travel time in isotropic media, given by the partial differential equation\n$$\\lvert \\nabla T(\\mathbf{x}) \\rvert = s,$$\nwhere $T(\\mathbf{x})$ is the travel-time field in seconds, $\\mathbf{x} = (x,y)$ is position in meters, and $s$ is the constant slowness with units of seconds per meter. On the rectangular domain $[0,1]\\times[0,1]$ measured in meters, consider a point source at the center located at $(x_s,y_s) = (0.5,0.5)$ meters with boundary condition $T(x_s,y_s) = 0$ seconds. For constant $s$, the analytical solution in the continuum is\n$$T(x,y) = s \\sqrt{(x-x_s)^2 + (y-y_s)^2}.$$\n\nYour task is to set up a grid-refinement study using a first-order monotone upwind discretization of the Eikonal equation and to compute the empirical convergence slope in a log–log plot of the error norm $\\lVert T_h - T \\rVert$ versus the grid spacing $h$ for several slowness values. Here $T_h$ denotes the numerical solution computed on a uniform Cartesian grid with spacing $h$ and $T$ denotes the analytical solution. Use a solver appropriate for first-order schemes (e.g., a Fast Marching Method or a Fast Sweeping Method) that is consistent with the monotone upwind discretization and yields a causal solution.\n\nFundamental base and requirements:\n- Use the definition of travel time in isotropic media governed by the Eikonal equation $\\lvert \\nabla T \\rvert = s$ with constant $s$ and Dirichlet data $T(x_s,y_s)=0$.\n- Use the well-tested first-order Godunov upwind discretization on a uniform grid of spacing $h$ meters. At a grid node $(i,j)$ with discrete neighbor values, the local update for the discrete travel time $T_{i,j}$ must be obtained by solving the quadratic equation that enforces the discrete Eikonal condition using the smallest upwind neighbors in the coordinate directions. Explicitly, if $a$ is the minimum of the two neighbors in the $x$-direction and $b$ is the minimum of the two neighbors in the $y$-direction, then the update $U$ solves\n$$\\left(\\max\\left(\\frac{U-a}{h},0\\right)\\right)^2 + \\left(\\max\\left(\\frac{U-b}{h},0\\right)\\right)^2 = s^2,$$\nwith the admissibility condition $U \\ge \\max(a,b)$. This yields the closed-form update\n$$\nU =\n\\begin{cases}\n\\min(a,b) + h s,  \\text{if } \\lvert a-b \\rvert \\ge h s, \\\\\n\\dfrac{a+b + \\sqrt{2(h s)^2 - (a-b)^2}}{2},  \\text{otherwise}.\n\\end{cases}\n$$\n- The numerical solution must be computed in seconds. The grid spacing must be in meters. The slowness must be in seconds per meter.\n- To isolate the asymptotic order away from the point-source singularity, compute error norms excluding a small disk of radius $2h$ around the source. That is, only include nodes whose Euclidean distance from $(x_s,y_s)$ is strictly greater than $2h$.\n\nError norms and convergence slope:\n- For a given grid spacing $h$, compute the discrete $L^2$ error\n$$\\lVert T_h - T \\rVert_{2,h} = \\sqrt{ h^2 \\sum_{i,j} \\left(T_{i,j} - T(x_i,y_j)\\right)^2 },$$\nand the discrete $L^\\infty$ error\n$$\\lVert T_h - T \\rVert_{\\infty,h} = \\max_{i,j} \\lvert T_{i,j} - T(x_i,y_j)\\rvert,$$\nwhere the sums and maxima are taken over the grid nodes outside the exclusion disk of radius $2h$ centered at $(x_s,y_s)$.\n- For a set of grid spacings $\\{h_k\\}$, fit a straight line to the data $\\left(\\log_{10} h_k, \\log_{10} \\lVert T_h - T \\rVert\\right)$ using least squares to obtain the empirical slope for each norm. A first-order scheme is expected to produce a slope close to $1$.\n\nTest suite and final output:\n- Use the following slowness values in seconds per meter: $s \\in \\{0.75, 1.5, 3.0\\}$.\n- For each $s$, use uniform grids with $N \\in \\{33, 65, 129, 257\\}$ nodes per dimension. The grid spacing is $h = 1/(N-1)$ meters.\n- For each $s$, compute the empirical slope for the $L^2$ error and the $L^\\infty$ error based on the four grid levels.\n- Your program should produce a single line of output containing the six results as a comma-separated list enclosed in square brackets, in the order\n$$[\\text{slope}_{L^2}(s{=}0.75), \\text{slope}_{L^\\infty}(s{=}0.75), \\text{slope}_{L^2}(s{=}1.5), \\text{slope}_{L^\\infty}(s{=}1.5), \\text{slope}_{L^2}(s{=}3.0), \\text{slope}_{L^\\infty}(s{=}3.0)].$$\nAll numbers must be printed as decimal numbers (no units in the output line), rounded by the program as it deems appropriate. Internally, ensure all travel times are in seconds, all distances in meters, and all slowness values in seconds per meter.",
            "solution": "The problem requires a grid-refinement study to determine the empirical order of convergence for a first-order numerical solution to the two-dimensional Eikonal equation. The problem is scientifically and mathematically well-posed, providing all necessary components: the governing partial differential equation, a specific case with an analytical solution, the numerical discretization scheme, the error metrics, and the parameters for the study.\n\nThe physical problem is to find the first-arrival travel time $T(\\mathbf{x})$ of a wave expanding from a point source in a medium with constant slowness $s$. This is governed by the Eikonal equation, $\\lvert \\nabla T(\\mathbf{x}) \\rvert = s$, on the domain $\\mathbf{x} = (x,y) \\in [0,1] \\times [0,1]$ meters. Given a point source at $(x_s, y_s) = (0.5, 0.5)$ m, where the travel time is defined to be zero, $T(x_s, y_s) = 0$ s, the analytical solution in the continuum is $T(x,y) = s \\sqrt{(x-x_s)^2 + (y-y_s)^2}$ seconds.\n\nTo solve this equation numerically, we employ the specified first-order Godunov upwind finite-difference scheme. This scheme discretizes the domain into a uniform Cartesian grid with spacing $h$ and approximates the Eikonal equation at each grid node $(i,j)$. The travel time $T_{i,j}$ is updated based on the travel times of its upwind neighbors, i.e., the neighbors from which the wavefront arrives. The problem provides the correct closed-form solution for the updated travel time $U$ at a node, derived from the quadratic equation that results from the discretized gradient operator:\n$$\nU =\n\\begin{cases}\n\\min(a,b) + h s,  \\text{if } \\lvert a-b \\rvert \\ge h s, \\\\\n\\dfrac{a+b + \\sqrt{2(h s)^2 - (a-b)^2}}{2},  \\text{otherwise},\n\\end{cases}\n$$\nwhere $a$ and $b$ are the minimum travel times among neighbors in the $x$ and $y$ directions, respectively. This non-linear system of equations requires a specialized solver.\n\nThe Fast Marching Method (FMM) is the chosen algorithm to solve the discretized system. FMM is an efficient, single-pass algorithm that correctly captures the viscosity solution by propagating the wavefront in order of increasing travel time, analogous to Dijkstra's algorithm on a graph. The method operates by maintaining three sets of grid points: `KNOWN` (points whose final travel time has been computed), `TRIAL` (a narrow band of points adjacent to the known region, representing the current wavefront), and `FAR` (all other points). A min-priority queue manages the `TRIAL` points. The algorithm proceeds iteratively:\n1. Initialize the travel time grid with $\\infty$, except for the source point $T(x_s, y_s) = 0$. Add the source point to the priority queue.\n2. While the priority queue is not empty, extract the `TRIAL` point with the minimum travel time.\n3. Move this point from the `TRIAL` set to the `KNOWN` set.\n4. For each neighbor of this newly `KNOWN` point, calculate a potential new travel time using the Godunov update formula. If this new time is less than the neighbor's current time, update the neighbor's time and add it to (or update its priority in) the queue.\n\nFor the convergence study, this FMM solver is executed for each specified slowness $s \\in \\{0.75, 1.5, 3.0\\}$ s/m over a sequence of four grids with $N \\in \\{33, 65, 129, 257\\}$ nodes per side. The grid spacing is $h = 1/(N-1)$ m. After computing the numerical solution $T_h$ on each grid, we calculate the error by comparing it to the analytical solution $T$. The discrete $L^2$ and $L^\\infty$ error norms are computed as specified:\n$$ \\lVert T_h - T \\rVert_{2,h} = \\sqrt{ h^2 \\sum_{i,j} \\left(T_{i,j} - T(x_i,y_j)\\right)^2 }, \\quad \\lVert T_h - T \\rVert_{\\infty,h} = \\max_{i,j} \\lvert T_{i,j} - T(x_i,y_j)\\rvert. $$\nCrucially, the summation and maximum are taken only over grid points outside a disk of radius $2h$ centered at the source. This excludes the region around the point-source singularity, where the analytical solution is not differentiable and the numerical error does not follow the asymptotic behavior of the scheme, thus allowing for a clean measurement of the convergence rate.\n\nFinally, for each slowness $s$ and each error norm, the empirical order of convergence is determined by the slope of a best-fit line to the four data points $(\\log_{10} h_k, \\log_{10} \\text{error}_k)$ using a linear least-squares regression. For a first-order scheme, this slope is expected to be close to $1$. The implementation will compute these six slopes and format them as the final output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Main function to perform the grid-refinement study and compute convergence slopes.\n    \"\"\"\n    \n    def godunov_update(a, b, h, s):\n        \"\"\"\n        Computes the travel time update using the first-order Godunov scheme.\n        a: min travel time in x-direction\n        b: min travel time in y-direction\n        h: grid spacing\n        s: slowness\n        \"\"\"\n        hs = h * s\n        # This handles the case where one or both of a, b are np.inf\n        # abs(np.inf - finite) is np.inf, correctly triggering the 1D update\n        if np.abs(a - b) = hs:\n            return min(a, b) + hs\n        else:\n            # This case requires both a and b to be finite\n            term_under_sqrt = 2 * (hs**2) - (a - b)**2\n            # A numerically robust check to prevent sqrt of small negative number\n            if term_under_sqrt  0:\n                return min(a, b) + hs\n            return (a + b + np.sqrt(term_under_sqrt)) / 2\n\n    def run_fmm(N, h, s):\n        \"\"\"\n        Solves the Eikonal equation using the Fast Marching Method.\n        \"\"\"\n        # Constants for node states\n        KNOWN = 2\n        TRIAL = 1\n        FAR = 0\n        \n        T = np.full((N, N), np.inf, dtype=np.float64)\n        states = np.full((N, N), FAR, dtype=np.int8)\n        \n        # Source setup\n        source_idx = (N - 1) // 2\n        isrc, jsrc = source_idx, source_idx\n        T[isrc, jsrc] = 0.0\n        \n        trial_heap = [(0.0, isrc, jsrc)]\n        \n        while trial_heap:\n            t, i, j = heapq.heappop(trial_heap)\n            \n            if states[i, j] == KNOWN:\n                continue\n                \n            states[i, j] = KNOWN\n            \n            # Update neighbors\n            for ni, nj in [(i-1, j), (i+1, j), (i, j-1), (i, j+1)]:\n                if not (0 = ni  N and 0 = nj  N):\n                    continue\n                \n                if states[ni, nj] == KNOWN:\n                    continue\n\n                t_x1 = T[ni - 1, nj] if ni  0 else np.inf\n                t_x2 = T[ni + 1, nj] if ni  N - 1 else np.inf\n                a = min(t_x1, t_x2)\n\n                t_y1 = T[ni, nj - 1] if nj  0 else np.inf\n                t_y2 = T[ni, nj + 1] if nj  N - 1 else np.inf\n                b = min(t_y1, t_y2)\n                \n                if a == np.inf and b == np.inf:\n                    continue\n\n                U = godunov_update(a, b, h, s)\n\n                if U  T[ni, nj]:\n                    T[ni, nj] = U\n                    states[ni, nj] = TRIAL\n                    heapq.heappush(trial_heap, (U, ni, nj))\n                    \n        return T\n\n    def calculate_analytical(N, h, s, source_pos):\n        \"\"\"\n        Computes the analytical solution on the grid.\n        \"\"\"\n        grid_coords = np.linspace(0.0, 1.0, N)\n        xx, yy = np.meshgrid(grid_coords, grid_coords, indexing='ij')\n        xs, ys = source_pos\n        T_exact = s * np.sqrt((xx - xs)**2 + (yy - ys)**2)\n        return T_exact\n\n    def calculate_errors(T_h, T_exact, N, h, source_pos):\n        \"\"\"\n        Computes L2 and Linf errors, excluding a disk of radius 2h around the source.\n        \"\"\"\n        exclusion_radius = 2.0 * h\n        xs, ys = source_pos\n        \n        sum_sq_err = 0.0\n        max_abs_err = 0.0\n        \n        grid_coords = np.linspace(0.0, 1.0, N)\n        \n        for i in range(N):\n            for j in range(N):\n                xi, yj = grid_coords[i], grid_coords[j]\n                dist_from_source = np.sqrt((xi - xs)**2 + (yj - ys)**2)\n                \n                if dist_from_source  exclusion_radius:\n                    abs_err = np.abs(T_h[i, j] - T_exact[i, j])\n                    sum_sq_err += abs_err**2\n                    if abs_err  max_abs_err:\n                        max_abs_err = abs_err\n        \n        l2_err = np.sqrt(h**2 * sum_sq_err)\n        linf_err = max_abs_err\n        \n        return l2_err, linf_err\n\n    # --- Main Execution Logic ---\n    s_values = [0.75, 1.5, 3.0]\n    N_values = [33, 65, 129, 257]\n    source_pos = (0.5, 0.5)\n    \n    all_slopes = []\n\n    for s in s_values:\n        log_h_vals = []\n        log_l2_errors = []\n        log_linf_errors = []\n\n        for N in N_values:\n            h = 1.0 / (N - 1)\n            \n            T_h = run_fmm(N, h, s)\n            T_exact = calculate_analytical(N, h, s, source_pos)\n            \n            l2_err, linf_err = calculate_errors(T_h, T_exact, N, h, source_pos)\n            \n            if l2_err  0 and linf_err  0:\n                log_h_vals.append(np.log10(h))\n                log_l2_errors.append(np.log10(l2_err))\n                log_linf_errors.append(np.log10(linf_err))\n\n        # Perform linear regression to find the slope (order of convergence)\n        # using numpy.polyfit for least-squares\n        if len(log_h_vals)  1:\n            slope_l2 = np.polyfit(log_h_vals, log_l2_errors, 1)[0]\n            slope_linf = np.polyfit(log_h_vals, log_linf_errors, 1)[0]\n            all_slopes.extend([slope_l2, slope_linf])\n        else:\n            # Handle case where not enough data points were collected\n            all_slopes.extend([np.nan, np.nan])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_slopes))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While robust, first-order schemes for the Eikonal equation exhibit significant error, particularly near the gradient singularity of a point source. A powerful technique to overcome this is the additive factored method, where the travel-time field $T(\\mathbf{x})$ is decomposed into an analytical component $T_0(\\mathbf{x})$ that captures the singularity, and a smoother correction term $\\tau(\\mathbf{x})$ that is solved for numerically. This exercise involves implementing both standard and factored versions of Fast Marching and Fast Sweeping methods to directly quantify the dramatic improvement in accuracy that this approach provides .",
            "id": "3591136",
            "problem": "You are to implement and compare two first-order numerical methods for the isotropic Eikonal equation in two spatial dimensions, and their additive factored variants that reduce the point-source singularity. The methods are the Fast Marching Method (FMM) and the Fast Sweeping Method (FSM). Your program must be a complete, runnable Python script that computes quantitative error-reduction metrics for a homogeneous medium where a closed-form solution exists.\n\nFundamental base:\n- The isotropic Eikonal equation for travel time $T(\\mathbf{x})$ in a medium with wave speed $c(\\mathbf{x})$ is\n$$ \\|\\nabla T(\\mathbf{x})\\| = \\frac{1}{c(\\mathbf{x})}, \\quad \\mathbf{x} \\in \\Omega \\subset \\mathbb{R}^2, $$\nsubject to a point-source boundary condition $T(\\mathbf{x}_s) = 0$ at the source location $\\mathbf{x}_s$.\n- For a homogeneous medium with constant wave speed $c_0$, the exact point-source solution is\n$$ T_0(\\mathbf{x}) = \\frac{\\|\\mathbf{x} - \\mathbf{x}_s\\|}{c_0}. $$\n\nDiscretization base:\n- Use a uniform Cartesian grid with spacing $h$ (in meters) in both spatial directions. Let the grid be $N \\times N$ with indices $i,j \\in \\{0,\\dots,N-1\\}$. The source is located at the central grid point $(i_s, j_s)$ corresponding to physical coordinates $\\mathbf{x}_s$.\n- Apply the standard upwind Godunov discretization for the isotropic Eikonal equation. For a grid node $(i,j)$, using the minimum in the $x$-direction $a = \\min(T_{i-1,j}, T_{i+1,j})$ and in the $y$-direction $b = \\min(T_{i,j-1}, T_{i,j+1})$, the local update $t^\\star$ for $T_{i,j}$ satisfies the quadratic condition\n$$ \\left( \\max\\left( \\frac{t^\\star - a}{h}, 0 \\right) \\right)^2 + \\left( \\max\\left( \\frac{t^\\star - b}{h}, 0 \\right) \\right)^2 = \\left(\\frac{1}{c_{i,j}}\\right)^2, $$\nwith $c_{i,j} = c_0$. The smallest admissible nonnegative solution consistent with upwind causality is used.\n- In the additive factored formulation, write $T(\\mathbf{x}) = T_0(\\mathbf{x}) + \\tau(\\mathbf{x})$, where $T_0(\\mathbf{x})$ is the exact homogeneous solution as above and $\\tau(\\mathbf{x})$ satisfies\n$$ \\|\\nabla \\tau(\\mathbf{x}) + \\nabla T_0(\\mathbf{x})\\| = \\frac{1}{c(\\mathbf{x})}. $$\nUsing the same Godunov discretization principle but now applied to $\\tau$, at a grid node $(i,j)$ the local update for $\\tau_{i,j}$ uses shifted neighbor quantities\n$$ a_\\tau = \\min\\left( \\tau_{i-1,j} + T_{0,i-1,j} - T_{0,i,j}, \\ \\tau_{i+1,j} + T_{0,i+1,j} - T_{0,i,j} \\right), $$\n$$ b_\\tau = \\min\\left( \\tau_{i,j-1} + T_{0,i,j-1} - T_{0,i,j}, \\ \\tau_{i,j+1} + T_{0,i,j+1} - T_{0,i,j} \\right), $$\nand the same quadratic condition as for the unfactored case with $a_\\tau$ and $b_\\tau$ replacing $a$ and $b$. This implements the additive factoring by exactly accounting for discrete increments of $T_0$.\n\nAlgorithmic base:\n- The Fast Marching Method (FMM) is a label-setting method analogous to Dijkstra's algorithm that uses a minimum-heap (priority queue) over \"trial\" nodes keyed by their current $T$-values. Nodes transition from \"unknown\" to \"trial\" to \"accepted\" according to the smallest $T$. Each time a node is accepted, its immediate neighbors are updated using the local quadratic formula described above. For the additive factored FMM, you must maintain $\\tau$ values and compute updates for the total travel time $T = \\tau + T_0$ using the shifted neighbor quantities, but the heap ordering and acceptance test are always based on the total $T$.\n- The Fast Sweeping Method (FSM) is a Gauss–Seidel fixed-point iteration over four alternating sweep orders of the grid (e.g., lexicographic in the four diagonal directions). At each grid node (except the source, which is fixed), FSM applies the local quadratic update using the current neighbor values. For the additive factored FSM, $\\tau$ is updated using the shifted neighbor quantities as above, and the total $T = \\tau + T_0$ is derived for evaluating errors.\n\nScientific realism and units:\n- Use $c_0 = 2000$ m/s for the constant wave speed.\n- Use grid spacing $h = 10$ m in both $x$ and $y$ directions.\n- The domain is a square with side length $L = h (N-1)$ m and the source is located at the geometric center.\n- All travel-time outputs and errors must be expressed in seconds.\n\nTasks:\n1. Implement standard FMM (unfactored) and additive factored FMM for the Eikonal equation on a $2$D grid in a homogeneous medium.\n2. Implement standard FSM (unfactored) and additive factored FSM for the same problem.\n3. For each computed travel-time field $T_{ij}$, compute the root-mean-square error (RMSE) relative to the exact homogeneous solution $T_0(\\mathbf{x}_{ij})$:\n$$ \\mathrm{RMSE} = \\sqrt{ \\frac{1}{N^2} \\sum_{i=0}^{N-1} \\sum_{j=0}^{N-1} \\left( T_{ij} - T_0(\\mathbf{x}_{ij}) \\right)^2 }. $$\nThe RMSE must be reported in seconds.\n\nTest suite and output specification:\n- The test suite consists of four cases, probing method type and grid resolution:\n  - Case 1: Fast Marching Method, coarse grid $N=21$.\n  - Case 2: Fast Marching Method, fine grid $N=101$.\n  - Case 3: Fast Sweeping Method, coarse grid $N=21$.\n  - Case 4: Fast Sweeping Method, fine grid $N=101$.\n- For each case, compute the RMSE for the standard solver ($\\mathrm{RMSE}_\\mathrm{std}$) and the additive factored solver ($\\mathrm{RMSE}_\\mathrm{fact}$), and then compute the error-reduction factor\n$$ R = \\frac{\\mathrm{RMSE}_\\mathrm{std}}{\\max(\\mathrm{RMSE}_\\mathrm{fact}, 10^{-12})}. $$\nLarger $R$ indicates more reduction of singularity-induced error by the additive factoring.\n- Final output format: Your program should produce a single line of output containing the four reduction factors for the four cases as a comma-separated list enclosed in square brackets, in the exact order [Case1, Case2, Case3, Case4]. For example: \"[r1,r2,r3,r4]\".",
            "solution": "The problem requires the implementation and comparison of two first-order numerical methods, the Fast Marching Method (FMM) and the Fast Sweeping Method (FSM), for solving the isotropic Eikonal equation in two dimensions. For each method, we must implement both a standard version and an additive factored version designed to improve accuracy near the point source. The comparison is based on the reduction of root-mean-square error (RMSE) in a homogeneous medium, where an exact analytical solution is known.\n\nFirst, we establish the mathematical and numerical framework. The isotropic Eikonal equation is a non-linear partial differential equation that describes the travel time $T(\\mathbf{x})$ of a wavefront:\n$$ \\|\\nabla T(\\mathbf{x})\\| = \\frac{1}{c(\\mathbf{x})} $$\nHere, $\\mathbf{x}$ is a point in the domain $\\Omega \\subset \\mathbb{R}^2$, and $c(\\mathbf{x})$ is the wave speed. We are given a point source condition $T(\\mathbf{x}_s) = 0$ at a source location $\\mathbf{x}_s$. For the specific case of a homogeneous medium with constant wave speed $c(\\mathbf{x}) = c_0$, the exact solution is the distance from the source scaled by the slowness ($1/c_0$):\n$$ T_0(\\mathbf{x}) = \\frac{\\|\\mathbf{x} - \\mathbf{x}_s\\|}{c_0} $$\nThis solution has a conical singularity at $\\mathbf{x}_s$, where its gradient is undefined. This singularity poses a challenge for standard numerical schemes.\n\nThe domain is discretized into a uniform Cartesian grid of size $N \\times N$ with grid spacing $h$. A grid node is indexed by $(i,j)$. The standard first-order Godunov upwind finite-difference scheme approximates the gradient magnitude. To update the travel time $T_{i,j}$ at grid node $(i,j)$, we define neighbor values $a = \\min(T_{i-1,j}, T_{i+1,j})$ and $b = \\min(T_{i,j-1}, T_{i,j+1})$. The updated time $t^\\star$ is the smallest non-negative solution to the quadratic equation:\n$$ \\left( \\max\\left( \\frac{t^\\star - a}{h}, 0 \\right) \\right)^2 + \\left( \\max\\left( \\frac{t^\\star - b}{h}, 0 \\right) \\right)^2 = s_{i,j}^2 $$\nwhere $s_{i,j} = 1/c_{i,j}$ is the slowness. For a constant slowness $s_0 = 1/c_0$, the solution $t^\\star$ is given by:\n$$ t^\\star = \\begin{cases} \\min(a, b) + h s_0  \\text{if } |a-b| \\ge h s_0 \\\\ \\frac{a+b + \\sqrt{2(h s_0)^2 - (a-b)^2}}{2}  \\text{if } |a-b|  h s_0 \\end{cases} $$\nThis update rule is causal, only using information from directions where the travel time is smaller (upwind).\n\nThe additive factored method aims to mitigate the error from the source singularity. It reformulates the problem by writing the total travel time $T(\\mathbf{x})$ as a sum of the known singular solution $T_0(\\mathbf{x})$ and a correction term $\\tau(\\mathbf{x})$: $T(\\mathbf{x}) = T_0(\\mathbf{x}) + \\tau(\\mathbf{x})$. Substituting this into the Eikonal equation gives an equation for $\\tau(\\mathbf{x})$:\n$$ \\|\\nabla \\tau(\\mathbf{x}) + \\nabla T_0(\\mathbf{x})\\| = s(\\mathbf{x}) $$\nAt the discrete level, this is handled by applying the same Godunov update logic, but to $\\tau_{i,j}$ instead of $T_{i,j}$. The neighbor values are modified to incorporate the known analytic solution $T_0$. The shifted neighbor values are:\n$$ a_\\tau = \\min\\left( \\tau_{i-1,j} + T_{0,i-1,j} - T_{0,i,j}, \\ \\tau_{i+1,j} + T_{0,i+1,j} - T_{0,i,j} \\right) $$\n$$ b_\\tau = \\min\\left( \\tau_{i,j-1} + T_{0,i,j-1} - T_{0,i,j}, \\ \\tau_{i,j+1} + T_{0,i,j+1} - T_{0,i,j} \\right) $$\nThe new $\\tau_{i,j}$ is then calculated using the same quadratic update formula with $a_\\tau$ and $b_\\tau$ as inputs. Since $\\tau(\\mathbf{x})$ is generally much smoother than $T(\\mathbf{x})$ near the source, this method yields a more accurate numerical solution.\n\nThe two algorithms for solving the resulting system of equations are:\n\n$1$. **Fast Marching Method (FMM)**: This is a label-setting algorithm, analogous to Dijkstra's algorithm. Grid nodes are classified into three sets: `ACCEPTED` (finalized time), `TRIAL` (has a temporary time value), and `UNKNOWN`. The algorithm maintains a min-priority queue of `TRIAL` nodes, ordered by their travel time. In each step, the `TRIAL` node with the minimum travel time is moved to the `ACCEPTED` set. Its non-`ACCEPTED` neighbors are then updated using the Godunov scheme, and their status is set to `TRIAL` and they are added to or updated in the priority queue. The process begins with the source node and marches outwards. For the factored FMM, the priority queue is ordered by the total time $T = \\tau + T_0$, but the updates are computed for $\\tau$.\n\n$2$. **Fast Sweeping Method (FSM)**: This is an iterative method based on Gauss-Seidel iterations. It repeatedly sweeps across the entire grid in different directions. The problem specifies four alternating sweep directions (e.g., in increasing/decreasing order of $i$ and $j$ indices). In each sweep, every grid point (except the fixed source) is updated using the Godunov scheme, using the most recent values of its neighbors. This iterative process continues for a fixed number of iterations or until convergence. The multiple sweep directions ensure that characteristics (information flow) are correctly propagated throughout the domain. For the factored FSM, the sweeps update the $\\tau$ field instead of the $T$ field.\n\nThe implementation will proceed as follows:\n- Set up the grid parameters: $N \\in \\{21, 101\\}$, $h = 10$ m, $c_0 = 2000$ m/s. The source is at the central grid point.\n- Pre-compute the exact solution $T_0$ on the grid.\n- Implement a function for the Godunov update rule.\n- Implement FMM (standard and factored versions). FMM will use Python's `heapq` module for the priority queue.\n- Implement FSM (standard and factored versions). FSM will perform $20$ iterations, each consisting of four sweeps.\n- For each of the four test cases specified (FMM on coarse/fine grids, FSM on coarse/fine grids), compute the travel time fields $T_{\\text{std}}$ and $T_{\\text{fact}} = \\tau_{\\text{fact}} + T_0$.\n- Calculate the root-mean-square errors, $\\mathrm{RMSE}_\\mathrm{std}$ and $\\mathrm{RMSE}_\\mathrm{fact}$, with respect to the exact solution $T_0$.\n- Compute the error-reduction factor $R = \\mathrm{RMSE}_\\mathrm{std} / \\max(\\mathrm{RMSE}_\\mathrm{fact}, 10^{-12})$.\n- The final output will be a list of the four computed $R$ values.",
            "answer": "```python\nimport numpy as np\nimport heapq\n\n# Per the problem context, scipy is available but not strictly necessary for this implementation.\n# The core algorithms are implemented from scratch using numpy and the standard library.\n\ndef solve_eikonal_update(a, b, h, c_val):\n    \"\"\"\n    Solves the Godunov update for the Eikonal equation.\n    \n    Args:\n        a (float): Minimum travel time from x-neighbors.\n        b (float): Minimum travel time from y-neighbors.\n        h (float): Grid spacing.\n        c_val (float): Wave speed.\n\n    Returns:\n        float: Updated travel time.\n    \"\"\"\n    a, b = float(a), float(b)\n    \n    if np.isinf(a) and np.isinf(b):\n        return np.inf\n\n    h_over_c = h / c_val\n\n    if np.isinf(a) or np.isinf(b):\n        return min(a, b) + h_over_c\n\n    if abs(a - b) = h_over_c:\n        return min(a, b) + h_over_c\n    else:\n        discriminant = 2 * h_over_c**2 - (a - b)**2\n        # Discriminant should be non-negative due to the check above,\n        # but floating point issues might make it slightly negative.\n        if discriminant  0:\n            return min(a,b) + h_over_c\n        return (a + b + np.sqrt(discriminant)) / 2.0\n\n\ndef fast_marching_method(N, h, c0, isrc, jsrc, factored, T0):\n    \"\"\"\n    Implements the Fast Marching Method for the Eikonal equation.\n    \"\"\"\n    if factored:\n        values = np.full((N, N), np.inf)  # This will store tau\n        values[isrc, jsrc] = 0.0\n    else:\n        values = np.full((N, N), np.inf)  # This will store T\n        values[isrc, jsrc] = 0.0\n\n    states = np.zeros((N, N), dtype=int)  # 0: UNKNOWN, 1: TRIAL, 2: ACCEPTED\n    heap = []\n\n    # Initializing the source\n    T_val = T0[isrc, jsrc] if factored else 0.0\n    heapq.heappush(heap, (T_val, (isrc, jsrc)))\n    states[isrc, jsrc] = 1\n\n    while heap:\n        t_total, (i, j) = heapq.heappop(heap)\n\n        if states[i, j] == 2:\n            continue\n        \n        current_T_val = (values[i, j] + T0[i, j]) if factored else values[i, j]\n        if t_total  current_T_val:\n            continue\n\n        states[i, j] = 2  # Accept the node\n\n        for di, dj in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n            ni, nj = i + di, j + dj\n\n            if 0 = ni  N and 0 = nj  N and states[ni, nj] != 2:\n                \n                # Get upwind values from accepted neighbors\n                if not factored:\n                    a = np.inf\n                    if ni  0 and states[ni - 1, nj] == 2: a = min(a, values[ni - 1, nj])\n                    if ni  N-1 and states[ni + 1, nj] == 2: a = min(a, values[ni + 1, nj])\n                    \n                    b = np.inf\n                    if nj  0 and states[ni, nj - 1] == 2: b = min(b, values[ni, nj - 1])\n                    if nj  N-1 and states[ni, nj + 1] == 2: b = min(b, values[ni, nj + 1])\n                    \n                    if np.isinf(a) and np.isinf(b): continue\n                    \n                    t_new = solve_eikonal_update(a, b, h, c0)\n\n                    if t_new  values[ni, nj]:\n                        values[ni, nj] = t_new\n                        states[ni, nj] = 1\n                        heapq.heappush(heap, (t_new, (ni, nj)))\n                else: # Factored\n                    a_tau = np.inf\n                    if ni  0 and states[ni - 1, nj] == 2:\n                        val = values[ni-1, nj] + T0[ni-1, nj] - T0[ni, nj]\n                        a_tau = min(a_tau, val)\n                    if ni  N-1 and states[ni + 1, nj] == 2:\n                        val = values[ni+1, nj] + T0[ni+1, nj] - T0[ni, nj]\n                        a_tau = min(a_tau, val)\n                    \n                    b_tau = np.inf\n                    if nj  0 and states[ni, nj-1] == 2:\n                        val = values[ni, nj-1] + T0[ni, nj-1] - T0[ni, nj]\n                        b_tau = min(b_tau, val)\n                    if nj  N-1 and states[ni, nj+1] == 2:\n                        val = values[ni, nj+1] + T0[ni, nj+1] - T0[ni, nj]\n                        b_tau = min(b_tau, val)\n\n                    if np.isinf(a_tau) and np.isinf(b_tau): continue\n                    \n                    tau_new = solve_eikonal_update(a_tau, b_tau, h, c0)\n\n                    if tau_new  values[ni, nj]:\n                        values[ni, nj] = tau_new\n                        T_new = tau_new + T0[ni, nj]\n                        states[ni, nj] = 1\n                        heapq.heappush(heap, (T_new, (ni, nj)))\n\n    return values\n\n\ndef fast_sweeping_method(N, h, c0, isrc, jsrc, factored, T0, num_iter=20):\n    \"\"\"\n    Implements the Fast Sweeping Method for the Eikonal equation.\n    \"\"\"\n    if factored:\n        values = np.full((N, N), np.inf)  # tau\n        values[isrc, jsrc] = 0.0\n    else:\n        values = np.full((N, N), np.inf)  # T\n        values[isrc, jsrc] = 0.0\n\n    sweep_ranges = [\n        (range(N), range(N)),\n        (range(N - 1, -1, -1), range(N)),\n        (range(N - 1, -1, -1), range(N - 1, -1, -1)),\n        (range(N), range(N - 1, -1, -1))\n    ]\n\n    for _ in range(num_iter):\n        for i_range, j_range in sweep_ranges:\n            for i in i_range:\n                for j in j_range:\n                    if (i, j) == (isrc, jsrc):\n                        continue\n                    \n                    if not factored:\n                        a = min(values[i-1,j] if i0 else np.inf, values[i+1,j] if iN-1 else np.inf)\n                        b = min(values[i,j-1] if j0 else np.inf, values[i,j+1] if jN-1 else np.inf)\n                        \n                        t_new = solve_eikonal_update(a, b, h, c0)\n                        values[i,j] = min(values[i,j], t_new)\n                    else:\n                        a_tau = np.inf\n                        if i  0: a_tau = min(a_tau, values[i-1,j] + T0[i-1,j] - T0[i,j])\n                        if i  N-1: a_tau = min(a_tau, values[i+1,j] + T0[i+1,j] - T0[i,j])\n                        \n                        b_tau = np.inf\n                        if j  0: b_tau = min(b_tau, values[i,j-1] + T0[i,j-1] - T0[i,j])\n                        if j  N-1: b_tau = min(b_tau, values[i,j+1] + T0[i,j+1] - T0[i,j])\n                        \n                        tau_new = solve_eikonal_update(a_tau, b_tau, h, c0)\n                        values[i,j] = min(values[i,j], tau_new)\n    return values\n\n\ndef calculate_rmse(T_computed, T_exact):\n    \"\"\"Computes the Root-Mean-Square Error.\"\"\"\n    return np.sqrt(np.mean((T_computed - T_exact)**2))\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    test_cases = [\n        {'method': 'FMM', 'N': 21},\n        {'method': 'FMM', 'N': 101},\n        {'method': 'FSM', 'N': 21},\n        {'method': 'FSM', 'N': 101},\n    ]\n\n    c0 = 2000.0  # m/s\n    h = 10.0     # m\n    results = []\n\n    for case in test_cases:\n        N = case['N']\n        method = case['method']\n\n        isrc = jsrc = (N - 1) // 2\n\n        # Create grid and compute exact solution T0\n        x = np.arange(N) * h\n        y = np.arange(N) * h\n        X, Y = np.meshgrid(x, y, indexing='ij')\n        xs, ys = isrc * h, jsrc * h\n        T0_exact = np.sqrt((X - xs)**2 + (Y - ys)**2) / c0\n\n        solver = fast_marching_method if method == 'FMM' else fast_sweeping_method\n\n        # Standard solver\n        T_std = solver(N, h, c0, isrc, jsrc, factored=False, T0=T0_exact)\n        rmse_std = calculate_rmse(T_std, T0_exact)\n        \n        # Factored solver\n        tau_fact = solver(N, h, c0, isrc, jsrc, factored=True, T0=T0_exact)\n        T_fact = tau_fact + T0_exact\n        rmse_fact = calculate_rmse(T_fact, T0_exact)\n\n        # Compute reduction factor\n        reduction_factor = rmse_std / max(rmse_fact, 1e-12)\n        results.append(reduction_factor)\n        \n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Bridging the gap between abstract algorithms and physical reality requires accurately modeling boundary conditions. In geophysics, seismic waves reflecting off surfaces like the Moho or the free surface are fundamental phenomena. This practice explores how to correctly incorporate a specularly reflecting boundary into a Fast Sweeping solver using the classic method-of-images. You will implement a 'boundary-aware' source extension and compare its accuracy against a naive implementation, demonstrating how to properly enforce physical reflection principles within the numerical framework .",
            "id": "3591123",
            "problem": "You are tasked with designing and implementing a boundary-aware numerical solver for high-frequency travel times governed by the Eikonal equation in a homogeneous isotropic medium, and to quantify the impact of a reflecting boundary on numerical accuracy near that boundary via a source extension using an image method. The fundamental base consists of the Eikonal equation and Hamilton-Jacobi theory for travel time, the method-of-images for specular reflection in homogeneous media, and the Godunov upwind discretization for first-order nonlinear partial differential equations. The domain is a two-dimensional rectangular grid with a reflecting boundary at the bottom side. The solver must be based on the Fast Sweeping Method, and the comparison must be made against a standard point-source initialization without boundary-aware source extension.\n\nStart from the Eikonal equation\n$$\n\\lvert \\nabla T(x,y) \\rvert \\,=\\, s(x,y),\n$$\nwhere $T(x,y)$ is the first-arrival travel time and $s(x,y)$ is the slowness field, $s(x,y) = 1/v(x,y)$, with $v(x,y)$ the wave speed. Assume a homogeneous isotropic medium where $v(x,y) \\equiv v_0$ is a constant, so $s(x,y) \\equiv s_0 = 1/v_0$. The domain is discretized on a uniform grid with spacing $h$ in both directions, and the computational indices are $i \\in \\{0,\\dots,N_x-1\\}$ and $j \\in \\{0,\\dots,N_y-1\\}$ with physical coordinates $x_i = i h$ and $y_j = j h$. The bottom boundary at $y = 0$ reflects specularly (Neumann-type behavior for rays), and a point source located at $(x_s,y_s)$ in the interior initiates the travel time field with $T(x_s,y_s) = 0$.\n\nImplement two numerical variants:\n- Variant A (standard point source): initialize with $T_{i_s,j_s} = 0$ at the source grid node $(i_s,j_s)$, and perform Fast Sweeping updates using one-sided stencils at the domain boundaries (no special boundary-aware source extension).\n- Variant B (boundary-aware source extension): use the method-of-images to construct a boundary-aware ghost layer immediately outside the bottom boundary ($j=-1$) with values $T_0(i)$ obtained from the image source located at $(x_s,-y_s)$. Specifically, define the ghost values at $(x_i,y_{-1}) = (i h,-h)$ by\n$$\nT_0(i) \\,=\\, \\frac{1}{v_0}\\sqrt{(x_i - x_s)^2 + (y_{-1} - (-y_s))^2} \\,=\\, \\frac{1}{v_0}\\sqrt{(x_i - x_s)^2 + (y_s - h)^2}.\n$$\nThese $T_0(i)$ are not Dirichlet boundary conditions on $y=0$, but are to be used as boundary-aware ghost values in the upwind stencil for nodes at $j=0$ when computing Fast Sweeping updates.\n\nFor reference, given the homogeneous medium and a source at $(x_s,y_s)$ inside the domain, the analytic first-arrival travel time at the bottom boundary is given by\n$$\nT^{\\text{true}}(x,0) \\,=\\, \\frac{1}{v_0}\\sqrt{(x - x_s)^2 + y_s^2}.\n$$\n\nDesign and implement a two-dimensional Fast Sweeping Method using the Godunov upwind discretization appropriate for the Eikonal equation on a Cartesian grid, with the bottom ghost layer incorporated only in Variant B. Use a constant slowness $s_0 = 1/v_0$ and uniform spacing $h$ in both directions. Your implementation must compute the numerical travel time field $T_{i,j}$ for both Variant A and Variant B, and then evaluate the maximum absolute error along the bottom boundary $j=0$ by comparing $T_{i,0}$ with the analytic boundary value $T^{\\text{true}}(x_i,0)$.\n\nPhysical units must be used consistently: wave speed $v_0$ in meters per second (m/s), grid spacing $h$ in meters (m), and travel times $T$ in seconds (s). Errors must be reported in seconds (s), and improvement factors must be dimensionless ratios.\n\nTest Suite:\n- Case $1$ (happy path near boundary): $N_x = N_y = 101$, $h = 10$ m, $v_0 = 2000$ m/s, source $(x_s,y_s) = (500\\,\\text{m}, 10\\,\\text{m})$ corresponding to $(i_s,j_s) = (50,1)$.\n- Case $2$ (boundary-aligned source): $N_x = N_y = 101$, $h = 10$ m, $v_0 = 2000$ m/s, source $(x_s,y_s) = (500\\,\\text{m}, 0\\,\\text{m})$ corresponding to $(i_s,j_s) = (50,0)$.\n- Case $3$ (far from boundary): $N_x = N_y = 101$, $h = 10$ m, $v_0 = 2000$ m/s, source $(x_s,y_s) = (500\\,\\text{m}, 300\\,\\text{m})$ corresponding to $(i_s,j_s) = (50,30)$.\n- Case $4$ (corner proximity): $N_x = N_y = 101$, $h = 10$ m, $v_0 = 2000$ m/s, source $(x_s,y_s) = (10\\,\\text{m}, 10\\,\\text{m})$ corresponding to $(i_s,j_s) = (1,1)$.\n\nFor each case, compute the maximum absolute error along the bottom boundary for Variant A and Variant B, denoted $E_{\\text{A}}$ and $E_{\\text{B}}$ in seconds. Then compute the improvement factor\n$$\n\\rho \\,=\\, \\frac{E_{\\text{A}}}{E_{\\text{B}}}.\n$$\n\nFinal Output Format:\nYour program should produce a single line of output containing the improvement factors for the four test cases as a comma-separated list enclosed in square brackets, with each value rounded to six decimal places (e.g., $\\left[\\rho_1,\\rho_2,\\rho_3,\\rho_4\\right]$). The output must be dimensionless.",
            "solution": "The problem requires the design and implementation of a numerical solver for the Eikonal equation in a two-dimensional homogeneous medium with a reflecting boundary. The core task is to compare two variants of a Fast Sweeping Method (FSM) solver: a standard implementation (Variant A) and one enhanced with a boundary-aware source extension using the method-of-images (Variant B). The goal is to quantify the improvement in accuracy near the reflecting boundary.\n\n### 1. The Eikonal Equation and Godunov Discretization\n\nThe first-arrival travel time $T(x,y)$ in a medium with slowness $s(x,y)$ is governed by the Eikonal equation:\n$$\n|\\nabla T(x,y)|^2 = s(x,y)^2\n$$\nIn a homogeneous medium with constant wave speed $v_0$, the slowness is also constant, $s(x,y) = s_0 = 1/v_0$. On a uniform Cartesian grid with spacing $h$, where $T_{i,j}$ denotes the travel time at $(x_i, y_j) = (ih, jh)$, the equation can be written as:\n$$\n\\left( \\frac{\\partial T}{\\partial x} \\right)^2 + \\left( \\frac{\\partial T}{\\partial y} \\right)^2 = s_0^2\n$$\nA stable numerical scheme is a Godunov-type upwind finite-difference method. For an update at node $(i,j)$, the spatial derivatives are approximated using only \"upwind\" information, i.e., from neighboring nodes that have smaller travel times and from which the wave is arriving. This leads to a local non-linear equation for a candidate update time $\\hat{T}_{i,j}$. Let $T_x = \\min(T_{i-1,j}, T_{i+1,j})$ and $T_y = \\min(T_{i,j-1}, T_{i,j+1})$ be the minimum travel times of neighbors in the $x$ and $y$ directions, respectively. The updated time $\\hat{T}_{i,j}$ must satisfy:\n$$\n\\left( \\frac{\\max(\\hat{T}_{i,j}-T_x, 0)}{h} \\right)^2 + \\left( \\frac{\\max(\\hat{T}_{i,j}-T_y, 0)}{h} \\right)^2 = s_0^2\n$$\nThis equation can be solved for $\\hat{T}_{i,j}$. A common and robust procedure is as follows:\nLet $t_{min} = \\min(T_x, T_y)$ and $t_{max} = \\max(T_x, T_y)$.\n1.  First, attempt a one-dimensional update using the neighbor with the minimum time: $\\hat{T}_{1D} = t_{min} + h s_0$.\n2.  If this update yields a time less than or equal to the other neighbor's time ($\\hat{T}_{1D} \\le t_{max}$), it is accepted. This corresponds to the case where the characteristic (ray path) arriving at $(i,j)$ is aligned primarily with one grid axis.\n3.  If $\\hat{T}_{1D}  t_{max}$, both neighbors contribute, and the update is determined by solving the full quadratic equation, which yields the two-dimensional update:\n    $$\n    \\hat{T}_{2D} = \\frac{t_{min} + t_{max} + \\sqrt{2(hs_0)^2 - (t_{max} - t_{min})^2}}{2}\n    $$\nThe new candidate time for node $(i,j)$ is $\\hat{T}$. The final value is updated via a Gauss-Seidel approach: $T_{i,j} \\leftarrow \\min(T_{i,j}, \\hat{T})$.\n\n### 2. The Fast Sweeping Method (FSM)\n\nFSM is an iterative algorithm that efficiently solves the discretized Eikonal equation. It leverages the Gauss-Seidel-like updates described above and systematically sweeps through the grid in different directions to correctly propagate information from the source.\nThe algorithm proceeds as follows:\n1.  **Initialization**: The travel time grid $T$ is initialized with $T_{i_s, j_s} = 0$ at the source location $(i_s, j_s)$ and $T=\\infty$ at all other grid points.\n2.  **Sweeping**: The method iterates through a set of four sweeps that cover all characteristic propagation directions:\n    - Sweep 1: $i = 0, \\dots, N_x-1$; $j = 0, \\dots, N_y-1$ (bottom-left to top-right)\n    - Sweep 2: $i = N_x-1, \\dots, 0$; $j = 0, \\dots, N_y-1$ (bottom-right to top-left)\n    - Sweep 3: $i = N_x-1, \\dots, 0$; $j = N_y-1, \\dots, 0$ (top-right to bottom-left)\n    - Sweep 4: $i = 0, \\dots, N_x-1$; $j = N_y-1, \\dots, 0$ (top-left to bottom-right)\n    In each sweep, every non-source grid point is updated using the Godunov scheme.\n3.  **Convergence**: The cycle of four sweeps is repeated until the travel time field $T$ converges, i.e., the maximum change in any $T_{i,j}$ between full cycles is below a small tolerance. For homogeneous media, convergence is typically achieved in only a few cycles.\n\n### 3. Boundary Condition Variants\n\nThe key difference between the two variants lies in the treatment of the bottom boundary at $y=0$ ($j=0$).\n\n**Variant A (Standard Point Source)**:\nAt the domain boundaries, standard one-sided finite differences are used. When updating a node on the bottom boundary, $(i,0)$, the upwind neighbor search for the $y$-direction considers only the interior neighbor $T_{i,1}$. The out-of-bounds neighbor $T_{i,-1}$ is effectively treated as having infinite travel time, so $T_y = T_{i,1}$. This is a simple but often inaccurate approximation of the boundary condition.\n\n**Variant B (Boundary-Aware Source Extension)**:\nThis variant uses the method-of-images to model the specularly reflecting boundary at $y=0$. For a source at $(x_s, y_s)$, an image source is placed at $(x_s, -y_s)$. This image source is used to define travel times on a layer of \"ghost\" nodes located at $y_{-1} = -h$. The travel time $T_0(i)$ at a ghost node $(x_i, y_{-1})$ is the time taken to travel from the image source to that ghost node:\n$$\nT_0(i) \\,=\\, \\frac{1}{v_0}\\sqrt{(x_i - x_s)^2 + (y_{-1} - (-y_s))^2} \\,=\\, \\frac{1}{v_0}\\sqrt{(x_i - x_s)^2 + (y_s - h)^2}\n$$\nWhen updating a node $(i,0)$ on the physical boundary, these ghost values are used in the upwind stencil. The minimum neighbor time in the $y$-direction becomes $T_y = \\min(T_0(i), T_{i,1})$. This provides the solver with accurate information from \"across\" the boundary, effectively enforcing the correct physics of reflection and yielding a more accurate numerical solution for the first-arrival time field near the boundary.\n\n### 4. Error Quantification\n\nTo assess the accuracy of each variant, the numerically computed travel times along the bottom boundary, $T_{i,0}$, are compared to the analytical solution. For a homogeneous medium, the first-arrival travel time at a point $(x,0)$ on the boundary from a source at $(x_s, y_s)$ is simply the direct path distance divided by the velocity:\n$$\nT^{\\text{true}}(x,0) \\,=\\, \\frac{1}{v_0}\\sqrt{(x - x_s)^2 + y_s^2}\n$$\nThe maximum absolute errors for Variant A ($E_{\\text{A}}$) and Variant B ($E_{\\text{B}}$) are calculated along this boundary. The improvement factor, $\\rho = E_{\\text{A}} / E_{\\text{B}}$, quantifies the performance gain of the boundary-aware method.",
            "answer": "```python\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main solver to run test cases and compute improvement factors.\n    \"\"\"\n    test_cases = [\n        {'Nx': 101, 'Ny': 101, 'h': 10.0, 'v0': 2000.0, 'xs': 500.0, 'ys': 10.0},\n        {'Nx': 101, 'Ny': 101, 'h': 10.0, 'v0': 2000.0, 'xs': 500.0, 'ys': 0.0},\n        {'Nx': 101, 'Ny': 101, 'h': 10.0, 'v0': 2000.0, 'xs': 500.0, 'ys': 300.0},\n        {'Nx': 101, 'Ny': 101, 'h': 10.0, 'v0': 2000.0, 'xs': 10.0, 'ys': 10.0},\n    ]\n\n    improvement_factors = []\n\n    for case in test_cases:\n        Nx, Ny, h, v0 = case['Nx'], case['Ny'], case['h'], case['v0']\n        xs, ys = case['xs'], case['ys']\n        s0 = 1.0 / v0\n        ix_s = int(round(xs / h))\n        iy_s = int(round(ys / h))\n\n        def solve_for_T_at_node(i, j, T, T_ghost, h_s0):\n            \"\"\"Calculates the updated travel time at a single node.\"\"\"\n            # Get minimum travel times from neighbors\n            Tx_min = np.inf\n            if i  0: Tx_min = min(Tx_min, T[i - 1, j])\n            if i  Nx - 1: Tx_min = min(Tx_min, T[i + 1, j])\n\n            Ty_min = np.inf\n            if j  0:\n                Ty_min = min(Ty_min, T[i, j - 1])\n            elif T_ghost is not None:  # Variant B at j=0\n                Ty_min = min(Ty_min, T_ghost[i])\n\n            if j  Ny - 1: Ty_min = min(Ty_min, T[i, j + 1])\n\n            t_min = min(Tx_min, Ty_min)\n            if t_min == np.inf:\n                return np.inf\n\n            # Attempt 1D update\n            t_new = t_min + h_s0\n\n            # If 2D update is necessary and possible\n            t_max = max(Tx_min, Ty_min)\n            if t_max != np.inf and t_new  t_max:\n                discriminant = 2.0 * h_s0**2 - (t_max - t_min)**2\n                if discriminant = 0:\n                    t_new = (t_min + t_max + np.sqrt(discriminant)) / 2.0\n            \n            return t_new\n\n        def run_fsm(variant):\n            \"\"\"Performs the Fast Sweeping Method for a given variant.\"\"\"\n            T = np.full((Nx, Ny), np.inf)\n            if 0 = ix_s  Nx and 0 = iy_s  Ny:\n                T[ix_s, iy_s] = 0.0\n\n            T_ghost = None\n            if variant == 'B':\n                y_ghost = -h\n                T_ghost = s0 * np.sqrt((np.arange(Nx) * h - xs)**2 + (ys - h)**2)\n\n            h_s0 = h * s0\n            \n            for _ in range(20):  # FSM converges quickly in homogeneous media\n                T_old = T.copy()\n                \n                # Sweep 1: i -, j -\n                for i in range(Nx):\n                    for j in range(Ny):\n                        if i == ix_s and j == iy_s: continue\n                        t_updated = solve_for_T_at_node(i, j, T, T_ghost, h_s0)\n                        T[i, j] = min(T[i, j], t_updated)\n                \n                # Sweep 2: i -, j -\n                for i in range(Nx - 1, -1, -1):\n                    for j in range(Ny):\n                        if i == ix_s and j == iy_s: continue\n                        t_updated = solve_for_T_at_node(i, j, T, T_ghost, h_s0)\n                        T[i, j] = min(T[i, j], t_updated)\n                \n                # Sweep 3: i -, j -\n                for i in range(Nx - 1, -1, -1):\n                    for j in range(Ny - 1, -1, -1):\n                        if i == ix_s and j == iy_s: continue\n                        t_updated = solve_for_T_at_node(i, j, T, T_ghost, h_s0)\n                        T[i, j] = min(T[i, j], t_updated)\n                \n                # Sweep 4: i -, j -\n                for i in range(Nx):\n                    for j in range(Ny - 1, -1, -1):\n                        if i == ix_s and j == iy_s: continue\n                        t_updated = solve_for_T_at_node(i, j, T, T_ghost, h_s0)\n                        T[i, j] = min(T[i, j], t_updated)\n                        \n                if np.max(np.abs(T - T_old))  1e-12:\n                    break\n            \n            return T\n\n        # Run both variants\n        T_A = run_fsm(variant='A')\n        T_B = run_fsm(variant='B')\n\n        # Calculate analytical solution and errors\n        x_coords = np.arange(Nx) * h\n        T_true_boundary = s0 * np.sqrt((x_coords - xs)**2 + ys**2)\n\n        error_A = np.max(np.abs(T_A[:, 0] - T_true_boundary))\n        error_B = np.max(np.abs(T_B[:, 0] - T_true_boundary))\n        \n        if error_B  1e-15:\n            rho = 1.0 if error_A  1e-15 else np.inf\n        else:\n            rho = error_A / error_B\n            \n        improvement_factors.append(rho)\n\n    print(f\"[{','.join([f'{r:.6f}' for r in improvement_factors])}]\")\n\nsolve()\n```"
        }
    ]
}