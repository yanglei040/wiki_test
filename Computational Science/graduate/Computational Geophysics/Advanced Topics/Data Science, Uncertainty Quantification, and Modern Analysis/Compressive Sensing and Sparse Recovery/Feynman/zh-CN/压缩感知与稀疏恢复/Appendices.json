{
    "hands_on_practices": [
        {
            "introduction": "本练习将引导您探索两种地球物理反演中广泛使用的正则化方法：经典的吉洪诺夫 (Tikhonov) 正则化（基于梯度的 $\\ell_2$ 范数）和促进稀疏性的总变差 (Total Variation) 正则化（基于梯度的 $\\ell_1$ 范数）。通过对一个包含尖锐界面的一维层状地球模型进行解析推导，您将亲手揭示这两种方法在恢复地质不连续性方面的根本差异。这个实践旨在加深您对正则化器选择如何影响模型分辨率的理解，并阐明为何 $\\ell_1$ 范数在保持地质构造边缘方面具有独特优势 ()。",
            "id": "3580648",
            "problem": "考虑区间 $[-L,L]$ 上的一个一维分层地球属性 $m(x)$，它在 $x=0$ 处有一个单一的尖锐界面，模型化为一个幅度为 $A0$ 的阶跃：\n$$\nf(x)=A\\,H(x),\\quad x\\in[-L,L],\n$$\n其中 $H(x)$ 是亥维赛德函数。要求您在计算地球物理学中使用的标准变分框架内，比较模型 $u(x)$ 的两种正则化反演方法，这两种方法旨在平衡数据保真度和平滑度/稀疏性。\n\n- $\\ell_{2}$ (吉洪诺夫) 平滑，使用梯度平方惩罚项：\n$$\n\\min_{u}\\;\\frac{1}{2}\\int_{-\\infty}^{\\infty}\\big(u(x)-f(x)\\big)^{2}\\,dx+\\frac{\\lambda}{2}\\int_{-\\infty}^{\\infty}\\big(u'(x)\\big)^{2}\\,dx,\n$$\n其中正则化参数 $\\lambda0$。\n\n- $\\ell_{1}$ 全变分 (TV) 去噪，使用梯度绝对值惩罚项：\n$$\n\\min_{u}\\;\\frac{1}{2}\\int_{-L}^{L}\\big(u(x)-f(x)\\big)^{2}\\,dx+\\lambda\\int_{-L}^{L}|u'(x)|\\,dx,\n$$\n其中相同的符号 $\\lambda0$ 表示正则化权重（注意，两个泛函中的 $\\lambda$ 具有不同的物理单位）。\n\n请从上述基本定义出发，不要引入任何现成的公式，并按以下步骤进行。\n\n1) 对于 $\\ell_{2}$ (吉洪诺夫) 问题，推导欧拉-拉格朗日方程，并求解在 $\\mathbb{R}$ 上对应于阶跃输入的格林函数问题。证明吉洪诺夫解 $u_{\\ell_{2}}(x)$ 是一个具有指数过渡的平滑阶跃。将 $10$–$90$ 过渡宽度 $w_{2}$ 定义为 $x_{90}-x_{10}$，其中 $u_{\\ell_{2}}(x_{10})=0.1\\,A$ 且 $u_{\\ell_{2}}(x_{90})=0.9\\,A$。明确推导出 $w_{2}$ 作为 $\\lambda$ 的函数。\n\n2) 对于 $[-L,L]$ 上的 $\\ell_{1}$ 全变分 (TV) 问题，将搜索范围限制为在 $x=0$ 处有单一跳跃的分段常数候选解，即对于 $x\\in[-L,0)$ 有 $u(x)=u_{\\ell}$，对于 $x\\in[0,L]$ 有 $u(x)=u_{r}$，并最小化由此产生的双参数凸泛函。推导优化器保留非零跳跃 $u_{r}-u_{\\ell}0$ 的充要条件，并给出该情况下的最优解 $(u_{\\ell},u_{r})$。\n\n3) 现场实践要求两次运行使用同一个正则化权重 $\\lambda$（以保持不同实验间的正则化预算固定）。分辨率要求规定，如果一个反演的 $10$–$90$ 过渡宽度超过了预设的分辨率长度 $w_{c}0$，则该反演被视为“过度平滑”。确定最小界面幅度 $A_{\\min}$（以 $L$ 和 $w_{c}$ 的精确闭式表达式表示），使得存在一个单一的 $\\lambda$ 满足以下条件：\n- $\\ell_{2}$ 解根据判据 $w_{2}\\geq w_{c}$ 过度平滑了界面，且同时\n- $\\ell_{1}$ TV 解保留了一个非零跳跃。\n\n请将您的最终答案表示为仅含 $L$ 和 $w_{c}$ 的 $A_{\\min}$ 的闭式解析表达式，必要时可使用自然对数。最终幅度应与 $A$ 的单位相同（不要转换单位）。无需进行数值代入；不要四舍五入。",
            "solution": "首先将验证问题的科学性和数学合理性。\n\n### 步骤 1：提取已知条件\n- **模型函数**：表示单一尖锐界面的一维属性 $f(x)$。\n  $$f(x)=A\\,H(x),\\quad x\\in[-L,L], \\quad A0$$\n  其中 $H(x)$ 是亥维赛德阶跃函数。\n- **$\\ell_2$ (吉洪诺夫) 正则化泛函**：\n  $$J_2[u] = \\min_{u}\\;\\frac{1}{2}\\int_{-\\infty}^{\\infty}\\big(u(x)-f(x)\\big)^{2}\\,dx+\\frac{\\lambda}{2}\\int_{-\\infty}^{\\infty}\\big(u'(x)\\big)^{2}\\,dx, \\quad \\lambda0$$\n- **$\\ell_1$ (全变分) 正则化泛函**：\n  $$J_1[u] = \\min_{u}\\;\\frac{1}{2}\\int_{-L}^{L}\\big(u(x)-f(x)\\big)^{2}\\,dx+\\lambda\\int_{-L}^{L}|u'(x)|\\,dx, \\quad \\lambda0$$\n- **任务 1 (关于 $\\ell_2$)**：推导欧拉-拉格朗日方程，求解在 $\\mathbb{R}$ 上的解 $u_{\\ell_2}(x)$，并求出 $10$–$90$ 过渡宽度 $w_2$。\n- **任务 2 (关于 $\\ell_1$)**：对于在 $x=0$ 处有单一跳跃的分段常数候选解 $u(x)$，求出保留非零跳跃的条件以及最优跳跃值 $(u_{\\ell}, u_r)$。\n- **任务 3 (综合)**：两个问题使用单一的正则化权重 $\\lambda$。如果一个反演的过渡宽度 $w_2 \\ge w_c$（其中分辨率长度 $w_c  0$），则该反演被视为“过度平滑”。求出最小幅度 $A_{\\min}$，使得存在一个 $\\lambda$，满足 $\\ell_2$ 解是过度平滑的，并且 $\\ell_1$ 解保留一个非零跳跃。\n\n### 步骤 2：使用已知条件进行验证\n1.  **科学依据**：该问题比较了吉洪诺夫 ($\\ell_2$) 正则化和全变分 ($\\ell_1$) 正则化，这两种方法是反演问题中的基础且广泛使用的技术，尤其是在地球物理学和信号处理领域。使用阶跃函数分析分辨率是一种经典且有效的方法。\n2.  **适定性**：这两个最小化问题是标准的凸优化问题，存在唯一解。各项任务在数学上是精确的，并能导出一个唯一的答案。\n3.  **量纲一致性**：一个关键的检查点涉及“现场实践要求两次运行使用同一个正则化权重 $\\lambda$”这一陈述。两个泛函都使用了一个记为 $\\lambda$ 的参数，但它们的物理单位不同。\n    - 在 $\\ell_2$ 泛函中，设 $u$ 的单位为 $[U]$，$x$ 的单位为 $[L]$。数据保真项的单位是 $[U]^2 [L]$。惩罚项是 $\\lambda_2 \\int (u')^2 dx$，其单位为 $[\\lambda_2] ([U]/[L])^2 [L] = [\\lambda_2] [U]^2 [L]^{-1}$。为使泛函一致，$[\\lambda_2] = [L]^2$。\n    - 在 $\\ell_1$ 泛函中，数据保真项的单位是 $[U]^2 [L]$。惩罚项是 $\\lambda_1 \\int |u'| dx$，它表示 $u$ 的全变分，单位为 $[\\lambda_1] [U]$。为保证一致性，$[\\lambda_1] = [U][L]$。\n    - 为了使两种情况下 $\\lambda$ 的数值相同 ($\\lambda_1 = \\lambda_2$)，我们必须有 $[L]^2 = [U][L]$，这意味着 $[U]=[L]$。这意味着物理属性 $u(x)$ 必须具有长度单位。这在地球物理学中是一种可能的情景（例如，界面的深度、地层厚度）。假设存在这样的物理背景，该问题在量纲上是一致的。\n\n### 步骤 3：结论与行动\n在合理的假设下，即被建模的物理属性具有长度单位以确保量纲一致性，该问题被认为是有效的。我将继续进行求解。\n\n### 第 1 部分：$\\ell_2$ 吉洪诺夫正则化\n吉洪诺夫泛函为 $J_2[u] = \\int_{-\\infty}^{\\infty} \\mathcal{L}(x, u, u') dx$，其中拉格朗日量为 $\\mathcal{L} = \\frac{1}{2}(u-f)^2 + \\frac{\\lambda}{2}(u')^2$。欧拉-拉格朗日方程 $\\frac{\\partial \\mathcal{L}}{\\partial u} - \\frac{d}{dx}\\frac{\\partial \\mathcal{L}}{\\partial u'} = 0$ 为：\n$$ (u(x)-f(x)) - \\frac{d}{dx}(\\lambda u'(x)) = 0 \\implies u(x) - \\lambda u''(x) = f(x) $$\n这是一个二阶线性常微分方程。解可以通过与算子 $1 - \\lambda \\frac{d^2}{dx^2}$ 的格林函数进行卷积求得。格林函数 $G(x)$ 满足 $G(x) - \\lambda G''(x) = \\delta(x)$。齐次方程 $\\lambda y'' - y = 0$ 的解为 $y(x) = c_1 \\exp(x/\\sqrt{\\lambda}) + c_2 \\exp(-x/\\sqrt{\\lambda})$。为了使 $G(x)$ 在 $\\pm\\infty$ 处衰减，它必须具有 $C \\exp(-|x|/\\sqrt{\\lambda})$ 的形式。对 $G(x)$ 的常微分方程在 $x=0$ 两侧积分，得到导数的跳跃条件：$-\\lambda(G'(0^+) - G'(0^-)) = 1$。由此得出 $C = \\frac{1}{2\\sqrt{\\lambda}}$。\n格林函数为 $G(x) = \\frac{1}{2\\sqrt{\\lambda}}\\exp(-|x|/\\sqrt{\\lambda})$。\n解 $u_{\\ell_2}(x)$ 是 $f(x)=A H(x)$ 与 $G(x)$ 的卷积：\n$$u_{\\ell_2}(x) = (f*G)(x) = \\int_{-\\infty}^{\\infty} A H(\\xi) \\frac{1}{2\\sqrt{\\lambda}}\\exp\\left(-\\frac{|x-\\xi|}{\\sqrt{\\lambda}}\\right)d\\xi = \\frac{A}{2\\sqrt{\\lambda}}\\int_{0}^{\\infty}\\exp\\left(-\\frac{|x-\\xi|}{\\sqrt{\\lambda}}\\right)d\\xi$$\n对于 $x  0$，有 $|x-\\xi| = \\xi-x$。积分变为 $\\int_0^\\infty \\exp(-(\\xi-x)/\\sqrt{\\lambda})d\\xi = \\sqrt{\\lambda}\\exp(x/\\sqrt{\\lambda})$。\n对于 $x \\ge 0$，我们在 $\\xi=x$ 处拆分积分：$\\int_0^x \\exp(-(x-\\xi)/\\sqrt{\\lambda})d\\xi + \\int_x^\\infty \\exp(-(\\xi-x)/\\sqrt{\\lambda})d\\xi = \\sqrt{\\lambda}(1-\\exp(-x/\\sqrt{\\lambda})) + \\sqrt{\\lambda} = \\sqrt{\\lambda}(2-\\exp(-x/\\sqrt{\\lambda}))$。\n综合这些结果，我们得到解：\n$$ u_{\\ell_2}(x) = \\begin{cases} \\frac{A}{2} \\exp(x/\\sqrt{\\lambda})  \\text{若 } x  0 \\\\ A\\left(1-\\frac{1}{2}\\exp(-x/\\sqrt{\\lambda})\\right)  \\text{若 } x \\ge 0 \\end{cases} $$\n该函数代表一个平滑的阶跃。我们现在求 $10$–$90$ 过渡宽度 $w_2 = x_{90}-x_{10}$。\n$u_{\\ell_2}(x_{10}) = 0.1\\,A \\implies \\frac{A}{2} \\exp(x_{10}/\\sqrt{\\lambda}) = 0.1\\,A \\implies \\exp(x_{10}/\\sqrt{\\lambda}) = 0.2$。\n$$ x_{10} = \\sqrt{\\lambda}\\ln(0.2) = -\\sqrt{\\lambda}\\ln(5) $$\n$u_{\\ell_2}(x_{90}) = 0.9\\,A \\implies A(1-\\frac{1}{2}\\exp(-x_{90}/\\sqrt{\\lambda})) = 0.9\\,A \\implies \\exp(-x_{90}/\\sqrt{\\lambda}) = 0.2$。\n$$ x_{90} = -\\sqrt{\\lambda}\\ln(0.2) = \\sqrt{\\lambda}\\ln(5) $$\n过渡宽度为：\n$$ w_2 = x_{90}-x_{10} = \\sqrt{\\lambda}\\ln(5) - (-\\sqrt{\\lambda}\\ln(5)) = 2\\sqrt{\\lambda}\\ln(5) $$\n\n### 第 2 部分：$\\ell_1$ 全变分正则化\n我们对分段常数函数 $u(x) = u_{\\ell}$ (对于 $x0$) 和 $u(x)=u_{r}$ (对于 $x \\ge 0$) 最小化 $J_1[u] = \\frac{1}{2}\\int_{-L}^{L}(u-f)^2 dx + \\lambda\\int_{-L}^{L}|u'|dx$。\n数据项为 $\\frac{1}{2}\\int_{-L}^0 (u_{\\ell}-0)^2 dx + \\frac{1}{2}\\int_0^L (u_r-A)^2 dx = \\frac{L}{2}u_{\\ell}^2 + \\frac{L}{2}(u_r-A)^2$。\n正则化项是全变分 $\\lambda |u_r - u_{\\ell}|$。我们最小化这个双参数函数：\n$$ J_1(u_{\\ell}, u_r) = \\frac{L}{2}u_{\\ell}^2 + \\frac{L}{2}(u_r-A)^2 + \\lambda|u_r-u_{\\ell}| $$\n这是一个凸函数。最小化子必须满足次梯度最优性条件 $0 \\in \\partial J_1$。次梯度为：\n$$ \\partial_{u_{\\ell}} J_1 = L u_{\\ell} - \\lambda \\gamma $$\n$$ \\partial_{u_r} J_1 = L(u_r-A) + \\lambda \\gamma $$\n其中 $\\gamma \\in \\mathrm{sgn}(u_r-u_{\\ell})$。此处，对于 $z \\neq 0$，$\\mathrm{sgn}(z) = z/|z|$，而 $\\mathrm{sgn}(0) = [-1,1]$。\n将次梯度设为零：$u_{\\ell} = \\lambda\\gamma/L$ 且 $u_r=A-\\lambda\\gamma/L$。\n跳跃为 $u_r-u_{\\ell} = A-2\\lambda\\gamma/L$。\n- 对于非零跳跃 $u_r-u_{\\ell}  0$，我们必须有 $\\gamma=1$。跳跃为 $A-2\\lambda/L$。为使其为正，需要 $A  2\\lambda/L$。在这种情况下，最优解为 $(u_{\\ell}, u_r) = (\\lambda/L, A-\\lambda/L)$。\n- 对于零跳跃 $u_r-u_{\\ell}=0$，我们需要找到一个 $\\gamma \\in [-1,1]$ 使得 $A - 2\\lambda\\gamma/L = 0$，这意味着 $\\gamma = AL/(2\\lambda)$。由于 $\\gamma$ 必须在 $[-1,1]$ 内，此情况在 $|AL/(2\\lambda)| \\le 1$ 时成立。因为 $A,L,\\lambda  0$，这变为 $A \\le 2\\lambda/L$。在这种情况下，跳跃被消除，最优解为 $u_{\\ell}=u_r=A/2$。\n\n因此，当且仅当 $A  2\\lambda/L$ 时，非零跳跃被保留。\n\n### 第 3 部分：综合求最小幅度 $A_{\\min}$\n我们需要找到最小的 $A$，使得存在一个单一的 $\\lambda$ 值同时满足两个条件：\n1. $\\ell_2$ 解是过度平滑的：$w_2 \\ge w_c$。根据第 1 部分，这意味着 $2\\sqrt{\\lambda}\\ln(5) \\ge w_c$。解出 $\\lambda$：\n   $$ \\lambda \\ge \\frac{w_c^2}{4(\\ln(5))^2} $$\n2. $\\ell_1$ 解保留一个非零跳跃。根据第 2 部分，这意味着 $A  2\\lambda/L$。解出 $\\lambda$：\n   $$ \\lambda  \\frac{AL}{2} $$\n为了使这样一个 $\\lambda$ 值存在，由这两个不等式定义的区间必须非空。下界必须严格小于上界：\n$$ \\frac{w_c^2}{4(\\ln(5))^2}  \\frac{AL}{2} $$\n我们对这个不等式求解幅度 $A$：\n$$ A > \\frac{2}{L} \\cdot \\frac{w_c^2}{4(\\ln(5))^2} = \\frac{w_c^2}{2L(\\ln(5))^2} $$\n所有满足条件的幅度 $A$ 构成的集合是开区间 $(\\frac{w_c^2}{2L(\\ln(5))^2}, \\infty)$。最小幅度 $A_{\\min}$ 是这个集合的下确界。\n$$ A_{\\min} = \\frac{w_c^2}{2L(\\ln(5))^2} $$",
            "answer": "$$\\boxed{\\frac{w_{c}^{2}}{2L(\\ln(5))^{2}}}$$"
        },
        {
            "introduction": "在了解了 $\\ell_1$ 正则化的优势之后，下一个关键问题是：它是如何实现稀疏恢复的？本练习将带您深入研究“最小绝对收縮和选择算子” (LASSO) 的核心数学原理。您将从凸分析的基本概念出发，为LASSO问题推导其必要且充分的最优性条件，即著名的卡罗需-库恩-塔克 (Karush-Kuhn-Tucker, KKT) 条件。通过这个过程，您将清晰地理解解的支撑集（非零元素的位置）是如何由残差与字典矩阵列之间的相互作用决定的，从而揭示稀疏性产生的内在机制 ()。",
            "id": "3580666",
            "problem": "在叠后地震道反演中，一个稀疏促进模型假设存在一个反射系数向量 $x \\in \\mathbb{R}^{n}$，其元素表示在 $n$ 个候选深度采样点处的波阻抗差异。经过子波反褶积和噪声预白化后，预白化数据 $y \\in \\mathbb{R}^{m}$ 和正演算子 $A \\in \\mathbb{R}^{m \\times n}$ 满足线性模型 $y = A x + \\varepsilon$，其中 $\\varepsilon$ 是一个零均值、单位协方差的噪声向量。为了恢复 $x$，考虑最小绝对值收缩和选择算子 (LASSO) 估计量 $\\hat{x}$，它被定义为以下凸目标函数的最小化子：\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\;\\; \\frac{1}{2} \\|A x - y\\|_{2}^{2} + \\lambda \\|x\\|_{1},\n$$\n其中 $\\lambda  0$ 是一个控制解的稀疏性的正则化参数。\n\n从凸分析的基本原理（凸函数的次微分计算）和一阶最优性条件（Karush–Kuhn–Tucker 条件）出发，完成以下任务：\n\n1. 根据二次数据项的梯度和 $\\ell_1$范数惩罚项的次微分，推导 $\\hat{x}$ 的充要最优性条件。你的推导必须是明确的，并且不得假定任何专门的捷径或预先给定的最优性公式。清晰地以向量形式和分量形式陈述所得条件。\n\n2. 使用这些最优性条件，刻画支撑集的恢复是如何由残差 $r = y - A \\hat{x}$ 与 $A$ 的列向量之间的相互作用决定的。特别地，解释一个索引属于 $\\hat{x}$ 的支撑集以及一个索引被排除在支撑集之外所必须满足的条件，并将这些条件与支撑集上的符号一致性和支撑集外的相关性界限联系起来。你的刻画必须从第一性原理推导得出。\n\n3. 考虑一个特定的预白化地震设置，$m=6$，$n=4$，其中 $A$ 的列是标准正交的，即 $A^{\\top} A = I_{4}$。设\n$$\nA = \\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1 \\\\\n0  0  0  0 \\\\\n0  0  0  0\n\\end{pmatrix}, \\quad\ny = \\begin{pmatrix}\n2.3 \\\\\n-0.9 \\\\\n0.4 \\\\\n-3.2 \\\\\n0.1 \\\\\n-0.2\n\\end{pmatrix}, \\quad\n\\lambda = 1.\n$$\n计算此数据集的 LASSO 估计值 $\\hat{x}$。使用 `pmatrix` 环境将你的最终答案表示为单个行向量。不需要四舍五入，反射系数的振幅也不需要物理单位。",
            "solution": "该问题要求对 LASSO 估计量进行三部分分析，分析必须从最优性条件的基本推导开始，然后用这些条件来刻画支撑集的恢复，最后以一个具体的计算结束。\n\nLASSO 目标函数由下式给出：\n$$\nJ(x) = \\frac{1}{2} \\|A x - y\\|_{2}^{2} + \\lambda \\|x\\|_{1}\n$$\n我们寻求最小化子 $\\hat{x} = \\arg\\min_{x \\in \\mathbb{R}^{n}} J(x)$。目标函数 $J(x)$ 是两个凸函数的和：$f(x) = \\frac{1}{2} \\|A x - y\\|_{2}^{2}$（一个可微的二次函数，因此是凸的）和 $g(x) = \\lambda \\|x\\|_{1}$（一个缩放的范数，因此也是凸的）。因此，它们的和 $J(x)$ 也是一个凸函数。\n\n**1. 最优性条件的推导**\n\n根据凸优化的费马法则，一个点 $\\hat{x}$ 是 $J(x)$ 的最小化子，当且仅当零向量是 $J(x)$ 在 $\\hat{x}$ 处的次微分的一个元素。即：\n$$\n0 \\in \\partial J(\\hat{x})\n$$\n对于两个凸函数的和，其中一个可微（如 $f(x)$），和的次微分等于可微部分的梯度与不可微部分的次微分之和：\n$$\n\\partial J(x) = \\nabla f(x) + \\partial g(x)\n$$\n首先，我们求 $f(x)$ 的梯度。\n$$\nf(x) = \\frac{1}{2} (Ax - y)^{\\top}(Ax - y) = \\frac{1}{2} (x^{\\top}A^{\\top}Ax - 2y^{\\top}Ax + y^{\\top}y)\n$$\n对 $x$ 求梯度得到：\n$$\n\\nabla f(x) = \\frac{1}{2} (2A^{\\top}Ax - 2A^{\\top}y) = A^{\\top}(Ax - y)\n$$\n接下来，我们求 $g(x) = \\lambda \\|x\\|_{1} = \\lambda \\sum_{i=1}^{n} |x_i|$ 的次微分。一个函数和的次微分是各个函数次微分的笛卡尔积。令 $v \\in \\partial g(x)$。则 $v_i \\in \\partial (\\lambda |x_i|)$。绝对值函数在点 $z \\in \\mathbb{R}$ 处的次微分是：\n$$\n\\partial|z| = \\begin{cases} \\{\\mathrm{sign}(z)\\}   \\text{若 } z \\neq 0 \\\\ [-1, 1]  \\text{若 } z = 0 \\end{cases}\n$$\n因此，对于向量 $v \\in \\partial g(x)$ 的每个分量 $v_i$：\n$$\nv_i \\in \\begin{cases} \\{\\lambda \\cdot \\mathrm{sign}(x_i)\\}  \\text{若 } x_i \\neq 0 \\\\ [-\\lambda, \\lambda]  \\text{若 } x_i = 0 \\end{cases}\n$$\n这个向量 $v$ 是次微分 $\\partial g(x)$ 中的一个元素。\n\n最优性条件 $0 \\in \\nabla f(\\hat{x}) + \\partial g(\\hat{x})$ 可以写成 $-\\nabla f(\\hat{x}) \\in \\partial g(\\hat{x})$。代入梯度和次微分的表达式，我们得到：\n$$\n-A^{\\top}(A\\hat{x} - y) \\in \\lambda \\partial\\|\\hat{x}\\|_{1}\n$$\n这就是向量形式下的充要最优性条件。令 $r = y - A\\hat{x}$ 为残差。该条件变为：\n$$\nA^{\\top}r \\in \\lambda \\partial\\|\\hat{x}\\|_{1}\n$$\n对于分量形式，令 $a_i$ 为 $A$ 的第 $i$ 列。向量 $A^{\\top}r$ 的第 $i$ 个分量是 $a_i^{\\top}r$。解的每个分量 $\\hat{x}_i$ 的最优性条件是：\n\\begin{itemize}\n    \\item 如果 $\\hat{x}_i \\neq 0$：次微分是单值的，所以我们得到一个等式 $a_i^{\\top}(y - A\\hatx) = \\lambda \\cdot \\mathrm{sign}(\\hat{x}_i)$。\n    \\item 如果 $\\hat{x}_i = 0$：次微分是一个区间，所以我们得到一个不等式 $|a_i^{\\top}(y - A\\hatx)| \\le \\lambda$。\n\\end{itemize}\n\n**2. 支撑集恢复的刻画**\n\n解 $\\hat{x}$ 的支撑集是索引集合 $S = \\{i \\mid \\hat{x}_i \\neq 0\\}$。支撑集的补集是 $S^c = \\{i \\mid \\hat{x}_i = 0\\}$。上面推导的最优性条件为哪些索引属于支撑集提供了精确的刻画。令 $r = y - A\\hat{x}$ 为解处的残差向量。\n\n对于一个索引 $i$ 属于支撑集（$i \\in S$）：\n条件是 $a_i^{\\top}r = \\lambda \\cdot \\mathrm{sign}(\\hat{x}_i)$。这蕴含了两件事。首先，基向量 $a_i$ 与最终残差 $r$ 之间相关性的绝对值必须恰好等于正则化参数 $\\lambda$，即 $|a_i^{\\top}r| = \\lambda$。其次，该相关性的符号必须与恢复出的系数 $\\hat{x}_i$ 的符号相匹配。这是一个**符号一致性**条件。它意味着被激活的系数 $\\hat{x}_i$ 的选择方式，使得它们所解释的数据部分留下的残差在相应字典原子 $a_i$ 上的投影在阈值 $\\lambda$ 处达到饱和。\n\n对于一个索引 $j$ 被排除在支撑集之外（$j \\in S^c$）：\n条件是 $|a_j^{\\top}r| \\le \\lambda$。这意味着任何未被激活的基向量 $a_j$ 与最终残差 $r$ 之间相关性的绝对值必须小于或等于 $\\lambda$。这是对支撑集外元素的**相关性界限**。如果对于某个 $j \\in S^c$ 该条件被违反（即 $|a_j^{\\top}r|  \\lambda$），那么通过引入一个与 $a_j^{\\top}r$ 同号的微小非零系数 $\\hat{x}_j$ 可以使总目标函数 $J(x)$ 减小，这与 $\\hat{x}$ 的最优性假设相矛盾。\n\n本质上，LASSO 中的支撑集恢复是一个阈值处理过程。一个索引 $i$ 只有在对应的基向量 $a_i$ 与数据（在考虑了其他选定基向量的贡献之后）充分相关时，才会被包含在模型中。参数 $\\lambda$ 为这个选择设定了阈值，$\\lambda$ 值越高，解就越稀疏。\n\n**3. 特定情况的计算**\n\n我们给定 $m=6$, $n=4$, $\\lambda=1$，以及矩阵\n$$\nA = \\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1 \\\\\n0  0  0  0 \\\\\n0  0  0  0\n\\end{pmatrix}, \\quad\ny = \\begin{pmatrix}\n2.3 \\\\\n-0.9 \\\\\n0.4 \\\\\n-3.2 \\\\\n0.1 \\\\\n-0.2\n\\end{pmatrix}\n$$\n一个关键信息是 $A$ 的列是标准正交的，我们可以验证：$A^{\\top}A = I_{4}$，其中 $I_4$ 是 $4 \\times 4$ 的单位矩阵。这极大地简化了最优性条件。\n\n从最优性条件的向量形式出发，$-A^{\\top}(A\\hat{x} - y) = s$，对于某个 $s \\in \\lambda \\partial\\|\\hat{x}\\|_{1}$：\n$$\nA^{\\top}y - A^{\\top}A\\hat{x} = s\n$$\n因为 $A^{\\top}A = I_4$，这变为：\n$$\nA^{\\top}y - \\hat{x} = s \\quad \\implies \\quad \\hat{x} + s = A^{\\top}y\n$$\n我们定义 $z = A^{\\top}y$。解的每个分量 $\\hat{x}_i$ 都通过 $\\hat{x}_i + s_i = z_i$ 与相应的分量 $z_i$ 相关联，其中 $s_i \\in \\lambda \\partial|\\hat{x}_i|$。这正是软阈值算子 $S_{\\lambda}(z_i)$ 的定义：\n$$\n\\hat{x}_i = S_{\\lambda}(z_i) = \\mathrm{sign}(z_i) \\max(|z_i| - \\lambda, 0)\n$$\n首先，我们计算向量 $z = A^{\\top}y$：\n$$\nA^{\\top} = \\begin{pmatrix}\n1  0  0  0  0  0 \\\\\n0  1  0  0  0  0 \\\\\n0  0  1  0  0  0 \\\\\n0  0  0  1  0  0\n\\end{pmatrix}\n$$\n$$\nz = A^{\\top}y = \\begin{pmatrix}\n1  0  0  0  0  0 \\\\\n0  1  0  0  0  0 \\\\\n0  0  1  0  0  0 \\\\\n0  0  0  1  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n2.3 \\\\\n-0.9 \\\\\n0.4 \\\\\n-3.2 \\\\\n0.1 \\\\\n-0.2\n\\end{pmatrix} =\n\\begin{pmatrix}\n2.3 \\\\\n-0.9 \\\\\n0.4 \\\\\n-3.2\n\\end{pmatrix}\n$$\n现在我们对 $z$ 的每个分量应用软阈值算子，其中 $\\lambda=1$。\n\n对于 $i=1$：$z_1 = 2.3$。由于 $|z_1|  1$，$\\hat{x}_1 = \\mathrm{sign}(2.3)(|2.3| - 1) = 1 \\cdot (2.3 - 1) = 1.3$。\n对于 $i=2$：$z_2 = -0.9$。由于 $|z_2| \\le 1$，$\\hat{x}_2 = \\mathrm{sign}(-0.9)(|-0.9| - 1)_+ = -1 \\cdot (0) = 0$。\n对于 $i=3$：$z_3 = 0.4$。由于 $|z_3| \\le 1$，$\\hat{x}_3 = \\mathrm{sign}(0.4)(|0.4| - 1)_+ = 1 \\cdot (0) = 0$。\n对于 $i=4$：$z_4 = -3.2$。由于 $|z_4|  1$，$\\hat{x}_4 = \\mathrm{sign}(-3.2)(|-3.2| - 1) = -1 \\cdot (3.2 - 1) = -2.2$。\n\nLASSO 估计值为 $\\hat{x} = (1.3, 0, 0, -2.2)^{\\top}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1.3  0  0  -2.2 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "稀疏恢复的成功不仅取决于信号的内在稀疏性，还关键地依赖于观测矩阵 $A$ 的性质。本练习将探讨一种与基于凸优化的方法（如LASSO）不同的策略：贪婪算法，特别是正交匹配追踪 (Orthogonal Matching Pursuit, OMP) 算法。您将从第一性原理出发，推导保证OMP算法在无噪声情况下能够精确恢复稀疏信号的充分条件，该条件与观测矩阵的互相关性 $\\mu(A)$ 直接相关。这项实践突出了传感矩阵设计在压缩感知中的核心地位，并帮助您理解为什么一个“良好”的观测矩阵对于任何稀疏恢复算法的成功都至关重要 ()。",
            "id": "3580652",
            "problem": "一个一维地震道被建模为带限子波与稀疏反射系数序列卷积的离散线性叠加。设 $A \\in \\mathbb{R}^{m \\times n}$ 是一个已知字典，其列 $\\{a_{j}\\}_{j=1}^{n}$ 是单位范数原子，每个原子代表一个经过平移和缩放的地震子波。设 $x \\in \\mathbb{R}^{n}$ 是一个 $k$-稀疏反射系数向量，其支撑集为 $S \\subset \\{1,\\dots,n\\}$，且 $|S|=k$。无噪声测量值为 $y = A x \\in \\mathbb{R}^{m}$。考虑正交匹配追踪 (Orthogonal Matching Pursuit, OMP) 算法，其定义如下：初始化残差 $r^{(0)} = y$ 和支撑集估计 $S^{(0)} = \\emptyset$。在每次迭代 $t \\geq 0$ 时，选择使 $|a_{j}^{\\top} r^{(t)}|$ 最大化的索引 $j_{t} \\in \\{1,\\dots,n\\}$，更新支撑集 $S^{(t+1)} = S^{(t)} \\cup \\{j_{t}\\}$，在 $S^{(t+1)}$ 上计算最小二乘估计，并更新残差 $r^{(t+1)} = y - A_{S^{(t+1)}} \\hat{x}_{S^{(t+1)}}$。\n\n$A$ 的互相关性定义为 $\\mu(A) = \\max_{i \\neq j} |a_{i}^{\\top} a_{j}|$，其中所有列都已归一化，使得 $\\|a_{j}\\|_{2} = 1$。仅使用这些定义以及内积和正交投影的性质，严格推导一个关于 $\\mu(A)$ 的充分条件，该条件表示为 $k$ 的显式函数，并保证在无噪声测量下，OMP 在每次迭代中都能选择一个正确的原子，并在 $k$ 步内精确恢复真实支撑集 $S$。您的推导必须从第一性原理出发：为真实支撑集内部和外部的索引所对应的相关性 $|a_{j}^{\\top} r^{(t)}|$ 定界，在每次迭代中比较这些界限，并得出一个关于 $\\mu(A)$ 的、依赖于 $k$ 的显式上界，该上界能确保在整个 OMP 运行过程中，真实相关和虚假相关之间存在严格的分离。\n\n最后，假设一个由现场校准的震源信号构成的子波字典具有互相关性 $\\mu(A) = 0.19$。根据您推导出的条件，确定最大的整数稀疏度 $k_{\\max}$，使得对于这个字典 $A$，OMP 能够保证从无噪声测量中精确恢复任何 $k$-稀疏的反射系数向量。将 $k_{\\max}$ 以整数形式报告。由于最终答案是精确整数，因此不需要舍入说明。",
            "solution": "该问题要求两个结果：首先，严格推导一个关于互相关性 $\\mu(A)$ 的充分条件，该条件保证正交匹配追踪 (OMP) 能够从无噪声测量 $y=Ax$ 中精确恢复一个 $k$-稀疏向量 $x$；其次，应用此条件找出一个给定 $\\mu(A)$ 所对应的最大稀疏度 $k_{\\max}$。\n\n推导将从第一性原理出发，分析 OMP 算法每一步计算的相关性。\n\n设 $A \\in \\mathbb{R}^{m \\times n}$ 是一个字典矩阵，其列 $\\{a_j\\}_{j=1}^n$ 是单位范数向量。设 $x \\in \\mathbb{R}^n$ 是一个 $k$-稀疏向量，其真实支撑集为 $S = \\{j : x_j \\neq 0\\}$，其中 $|S|=k$。无噪声测量向量为 $y = Ax = A_S x_S = \\sum_{j \\in S} x_j a_j$。\n\nOMP 算法从 $S^{(0)} = \\emptyset$ 开始，迭代地构建支撑集的估计 $S^{(t)}$。在每次迭代 $t \\ge 0$ 时，它选择使与当前残差 $r^{(t)}$（其中 $r^{(0)} = y$）的相关性大小最大化的索引 $j_t$。我们将使用归纳论证来证明，如果关于 $\\mu(A)$ 的条件得到满足，该算法在每一步都能正确识别出 $S$ 中的一个元素。\n\n在给定所有先前选择都正确（即 $S^{(t)} \\subset S$）的情况下，OMP 在迭代 $t$ 成功的条件是，新选择的索引 $j_t$ 也必须在真实支撑集中。这意味着最大相关性必须对应于 $S \\setminus S^{(t)}$ 中的一个原子。形式上，我们需要：\n$$ \\max_{j \\in S \\setminus S^{(t)}} |a_j^{\\top} r^{(t)}|  \\max_{l \\notin S} |a_l^{\\top} r^{(t)}| $$\n这个不等式必须对所有迭代 $t = 0, 1, \\dots, k-1$ 都成立。\n\n我们从分析第一次迭代 $t=0$ 开始。残差为 $r^{(0)} = y = \\sum_{i \\in S} x_i a_i$。\n\n首先，考虑与一个“正确”原子（即 $j \\in S$ 的原子 $a_j$）的相关性。其内积为：\n$$ a_j^{\\top} r^{(0)} = a_j^{\\top} \\left( \\sum_{i \\in S} x_i a_i \\right) = x_j (a_j^{\\top} a_j) + \\sum_{i \\in S, i \\neq j} x_i (a_j^{\\top} a_i) $$\n由于原子是单位范数的， $a_j^{\\top} a_j = \\|a_j\\|_2^2 = 1$。使用三角不等式和互相关性的定义 $\\mu(A) = \\max_{i \\neq j} |a_i^{\\top} a_j|$，我们可以为一个“正确”的相关性建立一个下界：\n$$ |a_j^{\\top} r^{(0)}| \\geq |x_j| - \\left| \\sum_{i \\in S, i \\neq j} x_i (a_j^{\\top} a_i) \\right| \\geq |x_j| - \\sum_{i \\in S, i \\neq j} |x_i| |a_j^{\\top} a_i| \\geq |x_j| - \\mu(A) \\sum_{i \\in S, i \\neq j} |x_i| $$\n为确保至少选择一个正确的原子，我们可以为可能的最大正确相关性找到一个下界。令 $j_0 = \\arg\\max_{j \\in S} |x_j|$，因此 $|x_{j_0}| = \\|x_S\\|_{\\infty}$。这个和可以用 $x_S$ 的 $\\ell_1$-范数 $\\|x_S\\|_1 = \\sum_{i \\in S} |x_i|$ 来表示。\n$$ \\max_{j \\in S} |a_j^{\\top} r^{(0)}| \\geq |a_{j_0}^{\\top} r^{(0)}| \\geq \\|x_S\\|_{\\infty} - \\mu(A) (\\|x_S\\|_1 - \\|x_S\\|_{\\infty}) $$\n\n其次，考虑与一个“不正确”原子（即 $l \\notin S$ 的原子 $a_l$）的相关性：\n$$ a_l^{\\top} r^{(0)} = a_l^{\\top} \\left( \\sum_{i \\in S} x_i a_i \\right) = \\sum_{i \\in S} x_i (a_l^{\\top} a_i) $$\n由于 $l \\notin S$，对于所有 $i \\in S$ 都有 $l \\neq i$。任何“不正确”相关性的大小的上界是：\n$$ |a_l^{\\top} r^{(0)}| \\leq \\sum_{i \\in S} |x_i| |a_l^{\\top} a_i| \\leq \\mu(A) \\sum_{i \\in S} |x_i| = \\mu(A) \\|x_S\\|_1 $$\n\n为了让 OMP 在第一步成功，我们需要最大正确相关性严格大于最大不正确相关性：\n$$ \\max_{j \\in S} |a_j^{\\top} r^{(0)}|  \\max_{l \\notin S} |a_l^{\\top} r^{(0)}| $$\n一个充分条件是：\n$$ \\|x_S\\|_{\\infty} - \\mu(A) (\\|x_S\\|_1 - \\|x_S\\|_{\\infty})  \\mu(A) \\|x_S\\|_1 $$\n重新整理这个不等式：\n$$ \\|x_S\\|_{\\infty}  \\mu(A) \\|x_S\\|_1 + \\mu(A) (\\|x_S\\|_1 - \\|x_S\\|_{\\infty}) $$\n$$ \\|x_S\\|_{\\infty} (1 + \\mu(A))  2 \\mu(A) \\|x_S\\|_1 $$\n$$ \\frac{\\|x_S\\|_{\\infty}}{\\|x_S\\|_1}  \\frac{2 \\mu(A)}{1 + \\mu(A)} $$\n这个条件依赖于向量 $x$ 中的具体值。然而，问题要求一个关于 $\\mu(A)$ 的条件，该条件能保证对*任何* $k$-稀疏向量 $x$ 都能成功恢复。因此，我们必须考虑 $x$ 的最坏情况，即最难满足不等式的情况。左边的项 $\\|x_S\\|_{\\infty}/\\|x_S\\|_1$ 在 $x$ 的能量尽可能均匀地分布在其 $k$ 个非零项中时达到最小值。该比率的最小值为 $1/k$，这发生在所有 $k$ 个非零项的幅值都相同时。\n\n将这个最坏情况的比率代入条件中：\n$$ \\frac{1}{k}  \\frac{2 \\mu(A)}{1 + \\mu(A)} $$\n$$ 1 + \\mu(A)  2k \\mu(A) $$\n$$ 1  (2k - 1) \\mu(A) $$\n$$ \\mu(A)  \\frac{1}{2k - 1} $$\n\n这就建立了第一步的条件。要进行完整证明，必须表明此条件对所有后续步骤都充分。一个完整的归纳证明要复杂得多，因为它需要在每一步都对正交投影对相关性的影响进行定界。然而，一个启发式的论证可以阐明为什么第一步的条件是最严格的。在任何迭代 $t$ 中，OMP 试图为残差 $r^{(t)}$ 找到一个稀疏的成因。产生 $r^{(t)}$ 的“真实”潜在稀疏信号与 $x_{S \\setminus S^{(t)}}$ 有关，其稀疏度为 $k-t$。因此，这个子问题类似于初始问题，但稀疏度降低了。相应的条件将是 $\\mu(A)  1/(2(k-t)-1)$。为确保该条件对所有 $t \\in \\{0, 1, \\dots, k-1\\}$ 都成立，我们必须满足分母值最大时的条件，这发生在 $t=0$ 时。因此，$\\mu(A)  1/(2k-1)$ 是对所有 $k$ 步都充分的条件。\n\n现在，我们将这个推导出的条件应用于给定的具体情况。我们有 $\\mu(A) = 0.19$，需要找到使该条件成立的最大整数 $k_{\\max}$。\n$$ 0.19  \\frac{1}{2k_{\\max} - 1} $$\n我们可以解出 $k_{\\max}$：\n$$ 2k_{\\max} - 1  \\frac{1}{0.19} $$\n$$ 2k_{\\max}  1 + \\frac{1}{0.19} $$\n$$ k_{\\max}  \\frac{1}{2} \\left( 1 + \\frac{1}{0.19} \\right) $$\n计算数值：\n$$ \\frac{1}{0.19} = \\frac{100}{19} \\approx 5.26315\\dots $$\n$$ k_{\\max}  \\frac{1}{2} (1 + 5.26315\\dots) = \\frac{6.26315\\dots}{2} = 3.13157\\dots $$\n由于 $k_{\\max}$ 必须是整数，满足此不等式的最大整数值 $k_{\\max}$ 是 $3$。\n\n为了验证：\n如果 $k=3$，条件是 $\\mu(A)  1/(2 \\cdot 3 - 1) = 1/5 = 0.2$。由于 $0.19  0.2$，条件成立。\n如果 $k=4$，条件是 $\\mu(A)  1/(2 \\cdot 4 - 1) = 1/7 \\approx 0.1428$。由于 $0.19 \\not 0.1428$，条件不成立。\n因此，最大的整数稀疏度确实是 $3$。",
            "answer": "$$\\boxed{3}$$"
        }
    ]
}