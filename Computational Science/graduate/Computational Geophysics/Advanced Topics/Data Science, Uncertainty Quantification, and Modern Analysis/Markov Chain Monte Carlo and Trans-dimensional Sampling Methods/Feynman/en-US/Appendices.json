{
    "hands_on_practices": [
        {
            "introduction": "Before implementing a full trans-dimensional sampler, it is crucial to grasp the theoretical underpinnings of Markov chain convergence. This exercise simplifies the complex dynamics of switching between model dimensions into a tractable two-state Markov chain. By deriving the stationary distribution and analyzing the eigenvalues, you will build a foundational understanding of how transition probabilities dictate a sampler's long-term behavior and mixing efficiency, which are key to reliable posterior exploration .",
            "id": "3609582",
            "problem": "In trans-dimensional Markov chain Monte Carlo (MCMC) for computational geophysics, it is common to switch between model spaces of different dimensions using Reversible-Jump Markov chain Monte Carlo (RJMCMC). Consider a Bayesian inversion for a stratified subsurface where the model dimension indicator $K$ toggles between $K=1$ and $K=2$ layers. Suppose the marginal dynamics of $K$ under the RJMCMC proposal-accept scheme can be approximated by a two-state homogeneous Markov chain on $\\{1,2\\}$ with transition matrix\n$$\nP \\;=\\; \\begin{pmatrix}\n1-a & a \\\\\nb & 1-b\n\\end{pmatrix},\n$$\nwhere $a \\in (0,1)$ is the one-step probability to propose and accept a move from $K=1$ to $K=2$, and $b \\in (0,1)$ is the analogous probability to move from $K=2$ to $K=1$. Assume $0<a<1$ and $0<b<1$ so that the chain is irreducible and aperiodic.\n\nUsing the foundational definitions of a stationary distribution for a Markov chain and the spectral characterization of convergence for finite-state chains, do the following:\n\n1. Derive the stationary distribution $\\pi$ satisfying $\\pi P = \\pi$ with $\\pi_1+\\pi_2=1$, expressing $\\pi$ in terms of $a$ and $b$.\n\n2. Compute the eigenvalues of $P$ and determine the second largest eigenvalue modulus (SLEM) as a function of $a$ and $b$.\n\n3. Explain, from first principles, how the SLEM governs the asymptotic decay rate of deviations from stationarity and discuss the implications for relaxation and mixing of the trans-dimensional indicator $K$ in terms of $a$ and $b$.\n\nReport as your final answer the spectral gap, defined as $1$ minus the second largest eigenvalue modulus, expressed in closed form as a function of $a$ and $b$. No numerical evaluation is required and no units are involved. The final answer must be a single closed-form analytic expression.",
            "solution": "This problem is deemed valid as it is scientifically grounded, well-posed, and objective. It presents a standard theoretical exercise in the study of finite-state Markov chains, which is a core component of MCMC methods. The problem is self-contained and mathematically consistent.\n\nThe problem asks for three items related to a two-state homogeneous Markov chain described by the transition matrix $P$. We will address each in turn.\n\n1.  Derivation of the stationary distribution $\\pi$.\nThe stationary distribution $\\pi = (\\pi_1, \\pi_2)$ is a probability distribution that remains unchanged by the action of the transition matrix $P$. It is defined by two conditions:\n1.  The balance equation: $\\pi P = \\pi$.\n2.  The normalization condition: $\\sum_{i} \\pi_i = 1$.\n\nFor the given $2 \\times 2$ matrix $P$, the balance equation $\\pi P = \\pi$ is written as:\n$$\n\\begin{pmatrix} \\pi_1 & \\pi_2 \\end{pmatrix} \\begin{pmatrix} 1-a & a \\\\ b & 1-b \\end{pmatrix} = \\begin{pmatrix} \\pi_1 & \\pi_2 \\end{pmatrix}\n$$\nThis matrix equation yields a system of two linear equations:\n$$\n\\begin{cases} \\pi_1 (1-a) + \\pi_2 b = \\pi_1 & (1) \\\\ \\pi_1 a + \\pi_2 (1-b) = \\pi_2 & (2) \\end{cases}\n$$\nLet us simplify equation $(1)$:\n$$\n\\pi_1 - \\pi_1 a + \\pi_2 b = \\pi_1\n$$\n$$\n-\\pi_1 a + \\pi_2 b = 0\n$$\n$$\n\\pi_1 a = \\pi_2 b\n$$\nSimplifying equation $(2)$ leads to the exact same relationship, as expected for a stochastic matrix where the vector of all ones is a right eigenvector with eigenvalue $1$.\nNow we use the second condition, the normalization $\\pi_1 + \\pi_2 = 1$. From $\\pi_1 a = \\pi_2 b$, we can express $\\pi_1$ in terms of $\\pi_2$ (since $a \\in (0,1)$, $a \\neq 0$):\n$$\n\\pi_1 = \\pi_2 \\frac{b}{a}\n$$\nSubstituting this into the normalization equation:\n$$\n\\pi_2 \\frac{b}{a} + \\pi_2 = 1\n$$\n$$\n\\pi_2 \\left( \\frac{b}{a} + 1 \\right) = 1\n$$\n$$\n\\pi_2 \\left( \\frac{b+a}{a} \\right) = 1\n$$\nSolving for $\\pi_2$ gives:\n$$\n\\pi_2 = \\frac{a}{a+b}\n$$\nNow we can find $\\pi_1$:\n$$\n\\pi_1 = 1 - \\pi_2 = 1 - \\frac{a}{a+b} = \\frac{(a+b)-a}{a+b} = \\frac{b}{a+b}\n$$\nThus, the stationary distribution is:\n$$\n\\pi = \\left( \\frac{b}{a+b}, \\frac{a}{a+b} \\right)\n$$\n\n2.  Eigenvalues of $P$ and the Second Largest Eigenvalue Modulus (SLEM).\nThe eigenvalues $\\lambda$ of a matrix $P$ are the solutions to the characteristic equation $\\det(P - \\lambda I) = 0$, where $I$ is the identity matrix.\n$$\n\\det \\begin{pmatrix} 1-a-\\lambda & a \\\\ b & 1-b-\\lambda \\end{pmatrix} = 0\n$$\nThe determinant is calculated as:\n$$\n(1-a-\\lambda)(1-b-\\lambda) - ab = 0\n$$\nLet's rearrange the terms within the parentheses:\n$$\n((1-\\lambda)-a)((1-\\lambda)-b) - ab = 0\n$$\nExpanding this product gives:\n$$\n(1-\\lambda)^2 - b(1-\\lambda) - a(1-\\lambda) + ab - ab = 0\n$$\n$$\n(1-\\lambda)^2 - (a+b)(1-\\lambda) = 0\n$$\nWe can factor out the term $(1-\\lambda)$:\n$$\n(1-\\lambda) \\left[ (1-\\lambda) - (a+b) \\right] = 0\n$$\nThis equation gives two solutions for $\\lambda$:\nThe first solution is from $1-\\lambda = 0$, which gives $\\lambda_1 = 1$. This is the largest eigenvalue, which is always $1$ for an irreducible stochastic matrix, corresponding to the stationary distribution.\nThe second solution is from $(1-\\lambda) - (a+b) = 0$, which gives $1 - (a+b) = \\lambda$, so $\\lambda_2 = 1-a-b$.\n\nThe eigenvalues of $P$ are $\\lambda_1 = 1$ and $\\lambda_2 = 1-a-b$.\nThe problem asks for the Second Largest Eigenvalue Modulus (SLEM). This is the largest modulus of all eigenvalues except for the leading eigenvalue $\\lambda_1 = 1$. In this case, it is simply $|\\lambda_2|$.\nGiven the constraints $a \\in (0,1)$ and $b \\in (0,1)$, we have $0 < a+b < 2$.\nThis implies $-1 < 1-(a+b) < 1$, so $|\\lambda_2| = |1-a-b| < 1$.\nThe SLEM is therefore $|\\lambda_2| = |1-a-b|$.\n\n3.  Convergence, Relaxation, and Mixing.\nThe convergence of a Markov chain to its stationary distribution is governed by its eigenvalues. According to the Perron-Frobenius theorem for stochastic matrices, an irreducible and aperiodic chain has a unique largest eigenvalue $\\lambda_1 = 1$, and all other eigenvalues $\\lambda_i$ satisfy $|\\lambda_i| < 1$.\n\nLet an arbitrary initial distribution be $v_0$. The distribution after $n$ steps is $v_n = v_0 P^n$. The deviation of this distribution from the stationary distribution $\\pi$ is $v_n - \\pi$. The rate at which this deviation decays to zero as $n \\to \\infty$ is determined by the SLEM.\n\nThe matrix $P$ can be written in its spectral decomposition. For a distribution vector $v_n$, its distance to the stationary distribution $\\pi$ (in a suitable norm, like the total variation distance) is bounded by a term proportional to $(\\text{SLEM})^n$. That is,\n$$\nd(v_n, \\pi) \\le C \\cdot |\\lambda_2|^n = C \\cdot |1-a-b|^n\n$$\nfor some constant $C$ that depends on the initial state. The term $|1-a-b|^n$ dictates the asymptotic rate of decay. A smaller SLEM leads to a faster decay, meaning the chain \"forgets\" its initial state and converges to stationarity more quickly. This process is known as relaxation.\n\nThe spectral gap, defined as $1 - \\text{SLEM} = 1 - |1-a-b|$, is a direct measure of the convergence speed. A larger spectral gap implies faster convergence.\n\nImplications for the trans-dimensional indicator $K$:\nThe quantity SLEM $= |1-a-b|$ controls how quickly the MCMC sampler's estimate of the posterior probability of being in state $K=1$ or $K=2$ converges to the true stationary probabilities, $\\pi_1$ and $\\pi_2$.\n-   If $a+b \\approx 1$, then $1-a-b \\approx 0$, and the SLEM is very small. This leads to a large spectral gap and very fast convergence. The chain mixes well, meaning it switches efficiently between the $1$-layer and $2$-layer models, allowing for rapid exploration of the different model spaces. This is the ideal scenario for an RJMCMC sampler.\n-   If $a+b \\approx 0$ (i.e., $a$ and $b$ are very small), then $1-a-b \\approx 1$ and the SLEM is close to $1$. The spectral gap is small, and convergence is very slow. The chain gets \"stuck\" in one dimension for long periods, leading to poor mixing and inefficient sampling.\n-   If $a+b \\approx 2$ (i.e., $a$ and $b$ are both close to $1$), then $1-a-b \\approx -1$ and the SLEM is again close to $1$. Convergence is also very slow. The chain's behavior is highly anti-correlated, tending to jump between dimensions on almost every step, which also hinders efficient exploration of the parameter space within each dimension.\n\nIn summary, for good mixing and fast relaxation of the trans-dimensional sampler, the proposal and acceptance probabilities $a$ and $b$ between model dimensions should be tuned such that their sum $a+b$ is close to $1$, which minimizes the SLEM and maximizes the spectral gap.\n\nThe final answer requested is the spectral gap, which is $1 - \\text{SLEM}$.\nSpectral Gap $= 1 - |1-a-b|$.",
            "answer": "$$\n\\boxed{1 - |1-a-b|}\n$$"
        },
        {
            "introduction": "A core requirement of the Reversible-Jump Markov Chain Monte Carlo (RJMCMC) algorithm is the careful construction of a deterministic and invertible mapping between parameter spaces of differing dimensions. This practice focuses on a key mathematical component of such a mapping: the Jacobian determinant for a \"split\" move, where one model parameter is expanded into two. Calculating this term is an essential skill, as the Jacobian correctly adjusts the acceptance probability to account for the change in volume induced by the transformation, ensuring the sampler satisfies detailed balance .",
            "id": "3609556",
            "problem": "In reversible-jump Markov chain Monte Carlo (RJMCMC) for trans-dimensional geophysical inversion, one common proposal is a split move that increases model dimension by splitting a single stratigraphic layer of thickness $h$ into two daughter layers with thicknesses $h_1$ and $h_2$, while also perturbing a layer property such as seismic velocity $v$ into two daughter properties $v_1$ and $v_2$. Suppose the split move is constructed by drawing an auxiliary variable $r \\in (0,1)$ and a perturbation $\\delta \\in \\mathbb{R}$, and defining the forward, dimension-matching transformation\n$$\n(h, r, v, \\delta) \\mapsto (h_1, h_2, v_1, v_2)\n$$\nvia the relations\n$$\nh_1 = r\\, h, \\quad h_2 = (1 - r)\\, h, \\quad v_1 = v - \\frac{\\delta}{2}, \\quad v_2 = v + \\frac{\\delta}{2}.\n$$\nAssume the physical constraint $h > 0$ holds. In RJMCMC, detailed balance under change of variables requires the absolute value of the Jacobian determinant of the above transformation.\n\nStarting from the change-of-variables principle for differentiable bijections and the definition of the Jacobian matrix as the matrix of first partial derivatives of the target variables with respect to the source variables, compute the absolute value of the Jacobian determinant of the combined mapping from $(h, r, v, \\delta)$ to $(h_1, h_2, v_1, v_2)$. Express your final answer as a closed-form analytic expression in terms of $h$ only.",
            "solution": "The problem requires the computation of the absolute value of the Jacobian determinant for a given trans-dimensional transformation used in Reversible-Jump Markov Chain Monte Carlo (RJMCMC). The transformation maps the source variables $(h, r, v, \\delta)$ to the target variables $(h_1, h_2, v_1, v_2)$.\n\nLet the vector of source variables be $\\mathbf{x} = (x_1, x_2, x_3, x_4) = (h, r, v, \\delta)$ and the vector of target variables be $\\mathbf{y} = (y_1, y_2, y_3, y_4) = (h_1, h_2, v_1, v_2)$. The transformation is defined by the following set of equations:\n$$\nh_1 = r h\n$$\n$$\nh_2 = (1 - r) h\n$$\n$$\nv_1 = v - \\frac{\\delta}{2}\n$$\n$$\nv_2 = v + \\frac{\\delta}{2}\n$$\n\nThe Jacobian matrix, denoted by $J$, is the matrix of all first-order partial derivatives of the target variables with respect to the source variables. The entry in the $i$-th row and $j$-th column of $J$ is given by $J_{ij} = \\frac{\\partial y_i}{\\partial x_j}$. Therefore, the Jacobian matrix is a $4 \\times 4$ matrix:\n$$\nJ = \\frac{\\partial(h_1, h_2, v_1, v_2)}{\\partial(h, r, v, \\delta)} = \\begin{pmatrix}\n\\frac{\\partial h_1}{\\partial h} & \\frac{\\partial h_1}{\\partial r} & \\frac{\\partial h_1}{\\partial v} & \\frac{\\partial h_1}{\\partial \\delta} \\\\\n\\frac{\\partial h_2}{\\partial h} & \\frac{\\partial h_2}{\\partial r} & \\frac{\\partial h_2}{\\partial v} & \\frac{\\partial h_2}{\\partial \\delta} \\\\\n\\frac{\\partial v_1}{\\partial h} & \\frac{\\partial v_1}{\\partial r} & \\frac{\\partial v_1}{\\partial v} & \\frac{\\partial v_1}{\\partial \\delta} \\\\\n\\frac{\\partial v_2}{\\partial h} & \\frac{\\partial v_2}{\\partial r} & \\frac{\\partial v_2}{\\partial v} & \\frac{\\partial v_2}{\\partial \\delta}\n\\end{pmatrix}\n$$\nWe compute each partial derivative from the given transformation equations.\n\nFor the first row (derivatives of $h_1 = r h$):\n$\\frac{\\partial h_1}{\\partial h} = r$\n$\\frac{\\partial h_1}{\\partial r} = h$\n$\\frac{\\partial h_1}{\\partial v} = 0$\n$\\frac{\\partial h_1}{\\partial \\delta} = 0$\n\nFor the second row (derivatives of $h_2 = (1 - r) h$):\n$\\frac{\\partial h_2}{\\partial h} = 1 - r$\n$\\frac{\\partial h_2}{\\partial r} = -h$\n$\\frac{\\partial h_2}{\\partial v} = 0$\n$\\frac{\\partial h_2}{\\partial \\delta} = 0$\n\nFor the third row (derivatives of $v_1 = v - \\frac{\\delta}{2}$):\n$\\frac{\\partial v_1}{\\partial h} = 0$\n$\\frac{\\partial v_1}{\\partial r} = 0$\n$\\frac{\\partial v_1}{\\partial v} = 1$\n$\\frac{\\partial v_1}{\\partial \\delta} = -\\frac{1}{2}$\n\nFor the fourth row (derivatives of $v_2 = v + \\frac{\\delta}{2}$):\n$\\frac{\\partial v_2}{\\partial h} = 0$\n$\\frac{\\partial v_2}{\\partial r} = 0$\n$\\frac{\\partial v_2}{\\partial v} = 1$\n$\\frac{\\partial v_2}{\\partial \\delta} = \\frac{1}{2}$\n\nSubstituting these derivatives into the Jacobian matrix gives:\n$$\nJ = \\begin{pmatrix}\nr & h & 0 & 0 \\\\\n1 - r & -h & 0 & 0 \\\\\n0 & 0 & 1 & -\\frac{1}{2} \\\\\n0 & 0 & 1 & \\frac{1}{2}\n\\end{pmatrix}\n$$\nThis matrix has a block-diagonal structure:\n$$\nJ = \\begin{pmatrix} A & 0 \\\\ 0 & B \\end{pmatrix}\n$$\nwhere $A = \\begin{pmatrix} r & h \\\\ 1 - r & -h \\end{pmatrix}$ and $B = \\begin{pmatrix} 1 & -\\frac{1}{2} \\\\ 1 & \\frac{1}{2} \\end{pmatrix}$.\nThe determinant of a block-diagonal matrix is the product of the determinants of its diagonal blocks. Thus, $\\det(J) = \\det(A) \\det(B)$.\n\nFirst, we compute the determinant of the block $A$:\n$$\n\\det(A) = \\det \\begin{pmatrix} r & h \\\\ 1 - r & -h \\end{pmatrix} = (r)(-h) - (h)(1 - r) = -rh - h + rh = -h\n$$\nNext, we compute the determinant of the block $B$:\n$$\n\\det(B) = \\det \\begin{pmatrix} 1 & -\\frac{1}{2} \\\\ 1 & \\frac{1}{2} \\end{pmatrix} = (1)\\left(\\frac{1}{2}\\right) - \\left(-\\frac{1}{2}\\right)(1) = \\frac{1}{2} + \\frac{1}{2} = 1\n$$\nThe determinant of the full Jacobian matrix $J$ is the product of these two determinants:\n$$\n\\det(J) = \\det(A) \\det(B) = (-h)(1) = -h\n$$\nThe problem asks for the absolute value of the Jacobian determinant, $|\\det(J)|$.\n$$\n|\\det(J)| = |-h|\n$$\nGiven the physical constraint that layer thickness must be positive, $h > 0$, the absolute value simplifies to:\n$$\n|\\det(J)| = h\n$$\nThe result is a closed-form expression in terms of $h$ only, as required.",
            "answer": "$$\\boxed{h}$$"
        },
        {
            "introduction": "This final practice moves from individual calculations to a complete synthesis, challenging you to implement the full machinery of a trans-dimensional MCMC sampler. You will construct the Metropolis-Hastings-Green acceptance probability for \"birth\" and \"death\" moves within a geophysical model where the number of layers, $K$, is unknown. This capstone exercise integrates the likelihood, prior distributions, proposal densities, and the Jacobian determinant into a single algorithm, providing a holistic, practical understanding of how these powerful methods are applied to solve complex model selection problems in geophysics .",
            "id": "3609577",
            "problem": "You are tasked with implementing a Metropolis–Hastings–Green trans-dimensional sampler component for a one-dimensional layered Earth model in which the number of layers is unknown. The model consists of a sequence of horizontal layers with positive thicknesses and positive P-wave velocities. The forward model maps a layered model to a zero-offset vertical travel time, which is the sum of per-layer travel times.\n\nYou must design and implement birth and death moves that change the number of layers by one while maintaining reversibility through a deterministic, differentiable, and invertible mapping augmented with auxiliary random variables. Your implementation must compute the acceptance probability for a single proposed move using the principles of Bayesian inference and detailed balance for Markov chains. All computations must be based on the specified priors and proposal distributions, and the acceptance probability must account for the change in model dimension, the prior on the number of layers, the parameter priors, the likelihood, the proposal densities, and the absolute value of the Jacobian determinant of the mapping.\n\nUse the following fundamental bases:\n\n- Bayes’ rule for posterior probability.\n- Detailed balance for Markov chains ensuring reversibility.\n- The principle of dimension matching and inclusion of the Jacobian determinant for trans-dimensional mappings in Reversible Jump Markov Chain Monte Carlo.\n\nModel specification:\n\n- A model has a number of layers $K \\in \\{K_{\\min},\\ldots,K_{\\max}\\}$ with $K_{\\min} = 1$ and $K_{\\max} = 5$. Each layer $i \\in \\{1,\\ldots,K\\}$ has thickness $h_i \\in \\mathbb{R}_{+}$ in meters and P-wave velocity $v_i \\in \\mathbb{R}_{+}$ in meters per second.\n- The zero-offset vertical travel time is\n$$\nT(m) = \\sum_{i=1}^{K} \\frac{h_i}{v_i} \\quad \\text{seconds}.\n$$\n- The data consist of a single observation $T_{\\text{obs}}$ with independent Gaussian noise of known standard deviation $\\sigma_T$ (in seconds).\n\nPriors:\n\n- The prior on the number of layers is a truncated Poisson distribution with rate $\\lambda$ over $\\{K_{\\min},\\ldots,K_{\\max}\\}$:\n$$\np(K) = \\frac{\\exp(-\\lambda)\\lambda^{K}/K!}{\\sum_{k=K_{\\min}}^{K_{\\max}} \\exp(-\\lambda)\\lambda^{k}/k!}.\n$$\n- Given $K$, layer thicknesses are independent and identically distributed as Exponential with rate $\\beta_h$:\n$$\np(h_i) = \\beta_h \\exp(-\\beta_h h_i), \\quad h_i > 0.\n$$\n- Given $K$, layer velocities are independent and identically distributed as Log-Normal with parameters $\\mu_v$ and $\\sigma_v$:\n$$\n\\ln v_i \\sim \\mathcal{N}(\\mu_v,\\sigma_v^2), \\quad v_i > 0.\n$$\n\nLikelihood:\n\n- The likelihood for the single observation is Gaussian:\n$$\np(T_{\\text{obs}}\\mid m) \\propto \\exp\\!\\left(-\\frac{(T(m) - T_{\\text{obs}})^2}{2\\sigma_T^2}\\right).\n$$\n\nMove types and proposals:\n\n- At a given $K$, select move type with probabilities $p_b(K)$ for birth and $p_d(K)$ for death:\n  - For $K = K_{\\min}$: $p_b(K_{\\min}) = 1$ and $p_d(K_{\\min}) = 0$.\n  - For $K = K_{\\max}$: $p_b(K_{\\max}) = 0$ and $p_d(K_{\\max}) = 1$.\n  - Otherwise: $p_b(K) = p_d(K) = 1/2$.\n- Birth move ($K \\to K+1$): select a layer index $j$ uniformly from $\\{1,\\ldots,K\\}$. Draw $r \\sim \\text{Beta}(1,1)$ (i.e., Uniform on $(0,1)$), and $\\delta \\sim \\mathcal{N}(0,\\sigma_{\\delta}^2)$. For the selected layer with parameters $(h, v)$, propose a split into two layers with\n$$\nh_1 = r h, \\quad h_2 = (1-r) h, \\quad v_1 = v\\,\\exp(\\delta), \\quad v_2 = v\\,\\exp(-\\delta).\n$$\nInsert the two new layers in place of the original. The absolute value of the Jacobian determinant of the transformation from $(h,v,r,\\delta)$ to $(h_1,h_2,v_1,v_2)$ must be included.\n- Death move ($K \\to K-1$): select an adjacent pair $(j,j+1)$ uniformly from $\\{(1,2),(2,3),\\ldots,(K-1,K)\\}$. Merge into a single layer with\n$$\nh = h_1 + h_2, \\quad v = \\sqrt{v_1 v_2}.\n$$\nThe inverse mapping yields the auxiliary variables\n$$\nr = \\frac{h_1}{h_1 + h_2}, \\quad \\delta = \\tfrac{1}{2}\\ln\\!\\left(\\frac{v_1}{v_2}\\right),\n$$\nwhich must be used to evaluate the reverse proposal density for the birth move and to include the correct absolute value of the inverse Jacobian determinant.\n\nProposal densities:\n\n- For the birth move forward proposal, the density factors include the move-type probability $p_b(K)$, the uniform selection of $j$ with probability $1/K$, and the densities of the auxiliary variables $r$ and $\\delta$:\n$$\nf_r(r) = 1 \\ \\text{for} \\ r \\in (0,1), \\quad f_{\\delta}(\\delta) = \\frac{1}{\\sigma_{\\delta}\\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{\\delta^2}{2\\sigma_{\\delta}^2}\\right).\n$$\n- For the death move forward proposal, the density factors include the move-type probability $p_d(K)$ and the uniform selection of the pair $(j,j+1)$ with probability $1/(K-1)$.\n\nYour program must compute the Metropolis–Hastings–Green acceptance probability for each proposed move in the test suite below by combining the posterior factors, the forward and reverse proposal densities, and the absolute value of the Jacobian determinant. If a proposed move is invalid due to violating the bounds on $K$ (for example, a death move at $K = K_{\\min}$ or a birth move at $K = K_{\\max}$), the acceptance probability must be returned as $0.0$.\n\nGlobal constants for all test cases:\n\n- Use $\\lambda = 2.5$, $K_{\\min}=1$, $K_{\\max}=5$.\n- Use $\\beta_h = 1/1000$ in $\\text{m}^{-1}$.\n- Use $\\mu_v = \\ln(2200)$ and $\\sigma_v = 0.25$.\n- Use $\\sigma_{\\delta} = 0.2$.\n- Use $T_{\\text{obs}} = 0.6$ seconds and $\\sigma_T = 0.02$ seconds.\n\nAngle units are not applicable. All physical quantities must be in the International System of Units: thickness in meters, velocity in meters per second, and time in seconds.\n\nTest suite:\n\nEach test case specifies the move type, the current number of layers $K$, the current thickness and velocity lists, the selected index for the move, and any required auxiliary variables. The interpretation of the selected index is:\n- For birth, the selected index $j$ is the layer to split (1-based).\n- For death, the selected index $j$ is the first layer in the adjacent pair $(j, j+1)$ to merge (1-based).\n\nProvide the acceptance probability as a single floating-point number for each case.\n\n- Case 1 (happy-path birth):\n  - Move: birth\n  - $K = 2$\n  - Thicknesses $[500.0, 700.0]$ meters\n  - Velocities $[2000.0, 2500.0]$ meters per second\n  - Selected index $j = 2$\n  - $r = 0.4$\n  - $\\delta = 0.1$\n- Case 2 (happy-path death):\n  - Move: death\n  - $K = 3$\n  - Thicknesses $[500.0, 280.0, 420.0]$ meters\n  - Velocities $[2000.0, 2762.925465, 2262.093545]$ meters per second\n  - Selected index $j = 2$ (merge layers 2 and 3)\n- Case 3 (boundary invalid death):\n  - Move: death\n  - $K = 1$\n  - Thicknesses $[1200.0]$ meters\n  - Velocities $[2300.0]$ meters per second\n  - Selected index $j = 1$\n- Case 4 (boundary invalid birth):\n  - Move: birth\n  - $K = 5$\n  - Thicknesses $[300.0, 400.0, 500.0, 600.0, 700.0]$ meters\n  - Velocities $[1800.0, 2000.0, 2200.0, 2400.0, 2600.0]$ meters per second\n  - Selected index $j = 3$\n  - $r = 0.5$\n  - $\\delta = 0.0$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"), in the same order as the test cases. Each result must be a floating-point number in $[0,1]$ representing the acceptance probability for the corresponding test case. There is no user input, and the program must run deterministically with the values specified above.",
            "solution": "The problem requires the computation of the Metropolis–Hastings–Green acceptance probability for trans-dimensional birth and death moves in a geophysical inverse problem. The model represents the Earth's subsurface as a series of one-dimensional layers, where the number of layers, $K$, is an unknown parameter to be inferred. The solution involves applying the principles of Reversible Jump Markov Chain Monte Carlo (RJMCMC).\n\nThe acceptance probability $\\alpha$ for a move from a current model state $m$ to a proposed model state $m'$ is given by:\n$$\n\\alpha(m'|m) = \\min \\left(1, A \\right)\n$$\nwhere $A$ is the acceptance ratio. For trans-dimensional moves where the dimension of the parameter space changes, this ratio is composed of the posterior probability ratio, the proposal probability ratio, and the absolute value of the Jacobian determinant of the transformation that maps between spaces.\n\nThe posterior probability $p(m|d)$ is given by Bayes' rule as $p(m|d) \\propto p(d|m) p(m)$, where $p(d|m)$ is the likelihood and $p(m)$ is the prior. The full prior is $p(m) = p(\\mathbf{h}, \\mathbf{v}, K) = p(\\mathbf{h}, \\mathbf{v}|K) p(K)$. Given $K$, all layer parameters $(h_i, v_i)$ are independent, so $p(\\mathbf{h}, \\mathbf{v}|K) = \\prod_{i=1}^K p(h_i) p(v_i)$.\n\nThe general form of the acceptance ratio for a move from $m$ to $m'$ is:\n$$\nA = \\frac{p(m'|d)}{p(m|d)} \\frac{q(m|m')}{q(m'|m)} |J| = \\underbrace{\\frac{p(d|m')}{p(d|m)}}_{\\text{Likelihood ratio}} \\underbrace{\\frac{p(m')}{p(m)}}_{\\text{Prior ratio}} \\underbrace{\\frac{q(m|m')}{q(m'|m)}}_{\\text{Proposal ratio}} \\underbrace{|J|}_{\\text{Jacobian}}\n$$\nHere, $q(m'|m)$ is the forward proposal density, $q(m|m')$ is the reverse proposal density, and $|J|$ is the Jacobian term for the dimension-matching transformation. We will analyze the birth and death moves separately. To avoid numerical underflow, all calculations are performed using log-probabilities. The log-acceptance ratio is $\\log A$, and $\\alpha = \\min(1, \\exp(\\log A))$.\n\n### Function Definitions\nFirst, we define the log-probabilities for the various components based on the problem specification.\n- Travel time: $T(m) = \\sum_{i=1}^{K} h_i/v_i$\n- Log-likelihood (ignoring constants that cancel in the ratio): $\\log p(d|m) = -\\frac{(T(m) - T_{\\text{obs}})^2}{2\\sigma_T^2}$\n- Log-prior on $K$: $\\log p(K) = -\\lambda + K\\log\\lambda - \\ln(K!) - \\log C$, where $C$ is the normalization constant for the truncated Poisson distribution on $\\{K_{\\min}, ..., K_{\\max}\\}$.\n- Log-prior on thickness $h_i$: $\\log p(h_i) = \\log\\beta_h - \\beta_h h_i$ for $h_i > 0$.\n- Log-prior on velocity $v_i$: $\\log p(v_i) = -\\ln v_i - \\ln(\\sigma_v\\sqrt{2\\pi}) - \\frac{(\\ln v_i - \\mu_v)^2}{2\\sigma_v^2}$ for $v_i > 0$.\n- Log-proposal for auxiliary variable $\\delta$: $\\log f_\\delta(\\delta) = -\\ln(\\sigma_\\delta\\sqrt{2\\pi}) - \\frac{\\delta^2}{2\\sigma_\\delta^2}$. The proposal for $r$ is $U(0,1)$, so its density is $f_r(r)=1$ and $\\log f_r(r)=0$.\n\n### Birth Move ($K \\to K+1$)\nA birth move proposes to increase the number of layers from $K$ to $K+1$.\n1.  **State and Proposal**: The current model is $m_c$ with $K$ layers. A layer $j$ with parameters $(h_j, v_j)$ is chosen uniformly ($1/K$). Two auxiliary variables $r \\sim U(0,1)$ and $\\delta \\sim \\mathcal{N}(0, \\sigma_\\delta^2)$ are drawn. The proposed model $m_p$ has $K+1$ layers, where layer $j$ is replaced by two new layers with parameters $(h_{p1}, v_{p1})$ and $(h_{p2}, v_{p2})$.\n2.  **Transformation**: The deterministic mapping is $(h_j, v_j, r, \\delta) \\mapsto (h_{p1}, h_{p2}, v_{p1}, v_{p2})$ where:\n    $h_{p1} = r h_j$, $h_{p2} = (1-r) h_j$, $v_{p1} = v_j e^\\delta$, $v_{p2} = v_j e^{-\\delta}$.\n3.  **Jacobian**: The Jacobian matrix of this transformation is $J = \\frac{\\partial(h_{p1}, h_{p2}, v_{p1}, v_{p2})}{\\partial(h_j, v_j, r, \\delta)}$. Its determinant is $\\det(J) = -2h_j v_j$. The absolute value is $|J| = 2h_j v_j$.\n4.  **Proposal Densities**:\n    -   Forward proposal density: $q(m_p|m_c) = p_b(K) \\cdot \\frac{1}{K} \\cdot f_r(r) \\cdot f_\\delta(\\delta)$.\n    -   Reverse proposal (death from $K+1$ layers): A pair is selected uniformly from the $K$ available adjacent pairs to merge. The reverse proposal density is $q(m_c|m_p) = p_d(K+1) \\cdot \\frac{1}{K}$.\n5.  **Acceptance Ratio**: The full log-acceptance ratio is:\n$\\log A_{\\text{birth}} = \\log\\left(\\frac{p(d|m_p)}{p(d|m_c)}\\right) + \\log\\left(\\frac{p(m_p)}{p(m_c)}\\right) + \\log\\left(\\frac{q(m_c|m_p)}{q(m_p|m_c)}\\right) + \\log|J|$\nSubstituting the components:\n$\\log A_{\\text{birth}} = \\left(\\log p(d|m_p) - \\log p(d|m_c)\\right) + \\left(\\log p(K+1) - \\log p(K)\\right) + \\left(\\log p(h_{p1}) + \\log p(h_{p2}) - \\log p(h_j)\\right) + \\left(\\log p(v_{p1}) + \\log p(v_{p2}) - \\log p(v_j)\\right) + \\left(\\log p_d(K+1) - \\log p_b(K)\\right) - \\log f_\\delta(\\delta) + \\log(2 h_j v_j)$.\nThe problem states that if $K=K_{\\max}$, the move is invalid, giving an acceptance probability of $0$.\n\n### Death Move ($K \\to K-1$)\nA death move proposes to decrease the number of layers from $K$ to $K-1$. It is the inverse of a birth move.\n1.  **State and Proposal**: The current model is $m_c$ with $K$ layers. An adjacent pair of layers $(j, j+1)$ with parameters $(h_j, v_j, h_{j+1}, v_{j+1})$ is chosen uniformly ($1/(K-1)$). These are merged into a single layer, forming the proposed model $m_p$ with $K-1$ layers.\n2.  **Transformation**: The deterministic merge operation is:\n    $h_p = h_j + h_{j+1}$, $v_p = \\sqrt{v_j v_{j+1}}$.\n3.  **Jacobian**: This move is the inverse of the birth move. The Jacobian term in the acceptance ratio is the inverse of the birth Jacobian, i.e., $1/|J| = 1/(2h_p v_p)$.\n4.  **Proposal Densities**:\n    -   Forward proposal density: $q(m_p|m_c) = p_d(K) \\cdot \\frac{1}{K-1}$.\n    -   Reverse proposal (birth from $K-1$ layers): The merged layer is chosen to be split. The auxiliary variables for this reverse move are calculated deterministically: $r = h_j / (h_j + h_{j+1})$ and $\\delta = \\frac{1}{2}\\ln(v_j/v_{j+1})$. The reverse proposal density is $q(m_c|m_p) = p_b(K-1) \\cdot \\frac{1}{K-1} \\cdot f_r(r) \\cdot f_\\delta(\\delta)$.\n5.  **Acceptance Ratio**: The log-acceptance ratio is:\n$\\log A_{\\text{death}} = \\log\\left(\\frac{p(d|m_p)}{p(d|m_c)}\\right) + \\log\\left(\\frac{p(m_p)}{p(m_c)}\\right) + \\log\\left(\\frac{q(m_c|m_p)}{q(m_p|m_c)}\\right) - \\log|J|$\nSubstituting the components:\n$\\log A_{\\text{death}} = \\left(\\log p(d|m_p) - \\log p(d|m_c)\\right) + \\left(\\log p(K-1) - \\log p(K)\\right) + \\left(\\log p(h_{p}) - \\log p(h_j) - \\log p(h_{j+1})\\right) + \\left(\\log p(v_{p}) - \\log p(v_j) - \\log p(v_{j+1})\\right) + \\left(\\log p_b(K-1) - \\log p_d(K)\\right) + \\log f_r(r) + \\log f_\\delta(\\delta) - \\log(2 h_p v_p)$.\nThe problem states that if $K=K_{\\min}$, the move is invalid, resulting in an acceptance probability of $0$.\n\nThe following implementation computes these acceptance probabilities for the provided test cases.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import gammaln, logsumexp\n\ndef solve():\n    \"\"\"\n    Main solver function that processes test cases and prints results.\n    \"\"\"\n    # Define global constants for the model\n    LAMBDA = 2.5\n    K_MIN = 1\n    K_MAX = 5\n    BETA_H = 1.0 / 1000.0\n    MU_V = np.log(2200.0)\n    SIGMA_V = 0.25\n    SIGMA_DELTA = 0.2\n    T_OBS = 0.6\n    SIGMA_T = 0.02\n    \n    # Pre-compute the normalization constant for the truncated Poisson prior on K\n    log_poisson_k_terms = [\n        k * np.log(LAMBDA) - gammaln(k + 1) for k in range(K_MIN, K_MAX + 1)\n    ]\n    log_poisson_k_norm_const = -LAMBDA + logsumexp(log_poisson_k_terms)\n\n    def log_p_k(k):\n        \"\"\"Computes the log-prior probability for the number of layers, log p(K).\"\"\"\n        if not (K_MIN = k = K_MAX):\n            return -np.inf\n        log_unnorm_prob = -LAMBDA + k * np.log(LAMBDA) - gammaln(k + 1)\n        return log_unnorm_prob - log_poisson_k_norm_const\n\n    def log_p_h(h):\n        \"\"\"Computes the log-prior probability for a layer thickness, log p(h).\"\"\"\n        if h = 0:\n            return -np.inf\n        return np.log(BETA_H) - BETA_H * h\n\n    def log_p_v(v):\n        \"\"\"Computes the log-prior probability for a layer velocity, log p(v).\"\"\"\n        if v = 0:\n            return -np.inf\n        log_v = np.log(v)\n        return -log_v - np.log(SIGMA_V * np.sqrt(2 * np.pi)) - \\\n               (log_v - MU_V)**2 / (2 * SIGMA_V**2)\n\n    def log_f_delta(delta):\n        \"\"\"Computes the log-density of the auxiliary variable delta.\"\"\"\n        return -np.log(SIGMA_DELTA * np.sqrt(2 * np.pi)) - \\\n               delta**2 / (2 * SIGMA_DELTA**2)\n\n    def travel_time(h_list, v_list):\n        \"\"\"Computes the total vertical travel time.\"\"\"\n        return np.sum(np.array(h_list) / np.array(v_list))\n\n    def get_move_prob(k, move_type):\n        \"\"\"Gets the probability of proposing a birth or death move at K layers.\"\"\"\n        if move_type == 'birth':\n            if k == K_MAX: return 0.0\n            if k == K_MIN: return 1.0\n            return 0.5\n        elif move_type == 'death':\n            if k == K_MIN: return 0.0\n            if k == K_MAX: return 1.0\n            return 0.5\n        return 0.0\n\n    def calculate_acceptance_prob(case):\n        \"\"\"Calculates the Metropolis-Hastings-Green acceptance probability for a given case.\"\"\"\n        move = case['move']\n        k_c = case['k']\n        h_c = case['h']\n        v_c = case['v']\n        j_idx = case['j'] - 1  # 1-based to 0-based index\n\n        # --- Handle BIRTH move ---\n        if move == 'birth':\n            if k_c == K_MAX:\n                return 0.0\n\n            r = case['r']\n            delta = case['delta']\n            \n            h_j_split = h_c[j_idx]\n            v_j_split = v_c[j_idx]\n            T_c = travel_time(h_c, v_c)\n\n            k_p = k_c + 1\n            h_p1, h_p2 = r * h_j_split, (1 - r) * h_j_split\n            v_p1, v_p2 = v_j_split * np.exp(delta), v_j_split * np.exp(-delta)\n            \n            h_p = h_c[:j_idx] + [h_p1, h_p2] + h_c[j_idx+1:]\n            v_p = v_c[:j_idx] + [v_p1, v_p2] + v_c[j_idx+1:]\n            T_p = travel_time(h_p, v_p)\n            \n            # Proposal choice probabilities (1/k) cancel out in the ratio for birth move\n            # So we only need the move type probabilities (p_b, p_d)\n            \n            log_likelihood_ratio = -0.5 / SIGMA_T**2 * ((T_p - T_OBS)**2 - (T_c - T_OBS)**2)\n            log_k_prior_ratio = log_p_k(k_p) - log_p_k(k_c)\n            log_h_prior_ratio = log_p_h(h_p1) + log_p_h(h_p2) - log_p_h(h_j_split)\n            log_v_prior_ratio = log_p_v(v_p1) + log_p_v(v_p2) - log_p_v(v_j_split)\n            log_proposal_ratio = np.log(get_move_prob(k_p, 'death')) - np.log(get_move_prob(k_c, 'birth'))\n            log_aux_proposal_ratio = -log_f_delta(delta) # log_f_r(r) is 0 as f_r(r)=1\n            log_jacobian = np.log(2 * h_j_split * v_j_split)\n            \n            log_A = (log_likelihood_ratio + log_k_prior_ratio + log_h_prior_ratio + \n                     log_v_prior_ratio + log_proposal_ratio + log_aux_proposal_ratio + \n                     log_jacobian)\n\n            return min(1.0, np.exp(log_A))\n\n        # --- Handle DEATH move ---\n        elif move == 'death':\n            if k_c = K_MIN:\n                return 0.0\n\n            h_j1, h_j2 = h_c[j_idx], h_c[j_idx+1]\n            v_j1, v_j2 = v_c[j_idx], v_c[j_idx+1]\n            T_c = travel_time(h_c, v_c)\n            \n            k_p = k_c - 1\n            h_p_merged = h_j1 + h_j2\n            v_p_merged = np.sqrt(v_j1 * v_j2)\n\n            h_p = h_c[:j_idx] + [h_p_merged] + h_c[j_idx+2:]\n            v_p = v_c[:j_idx] + [v_p_merged] + v_c[j_idx+2:]\n            T_p = travel_time(h_p, v_p)\n            \n            # For reverse move (birth)\n            r = h_j1 / h_p_merged\n            delta = 0.5 * np.log(v_j1 / v_j2)\n            \n            # Proposal choice probabilities (1/(k-1)) cancel out for death move\n            \n            log_likelihood_ratio = -0.5 / SIGMA_T**2 * ((T_p - T_OBS)**2 - (T_c - T_OBS)**2)\n            log_k_prior_ratio = log_p_k(k_p) - log_p_k(k_c)\n            log_h_prior_ratio = log_p_h(h_p_merged) - (log_p_h(h_j1) + log_p_h(h_j2))\n            log_v_prior_ratio = log_p_v(v_p_merged) - (log_p_v(v_j1) + log_p_v(v_j2))\n            log_proposal_ratio = np.log(get_move_prob(k_p, 'birth')) - np.log(get_move_prob(k_c, 'death'))\n            log_aux_proposal_ratio = log_f_delta(delta) # log_f_r(r) is 0\n            log_inv_jacobian = -np.log(2 * h_p_merged * v_p_merged)\n            \n            log_A = (log_likelihood_ratio + log_k_prior_ratio + log_h_prior_ratio + \n                     log_v_prior_ratio + log_proposal_ratio + log_aux_proposal_ratio +\n                     log_inv_jacobian)\n\n            return min(1.0, np.exp(log_A))\n            \n        return 0.0\n\n    test_cases = [\n        {'move': 'birth', 'k': 2, 'h': [500.0, 700.0], 'v': [2000.0, 2500.0], 'j': 2, 'r': 0.4, 'delta': 0.1},\n        {'move': 'death', 'k': 3, 'h': [500.0, 280.0, 420.0], 'v': [2000.0, 2762.925465, 2262.093545], 'j': 2},\n        {'move': 'death', 'k': 1, 'h': [1200.0], 'v': [2300.0], 'j': 1},\n        {'move': 'birth', 'k': 5, 'h': [300.0, 400.0, 500.0, 600.0, 700.0], 'v': [1800.0, 2000.0, 2200.0, 2400.0, 2600.0], 'j': 3, 'r': 0.5, 'delta': 0.0},\n    ]\n\n    results = [calculate_acceptance_prob(case) for case in test_cases]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}