{
    "hands_on_practices": [
        {
            "introduction": "The foundation of Simulated Annealing is the Metropolis acceptance criterion, which governs the probabilistic exploration of the model space. This first exercise provides a concrete, step-by-step calculation of this rule in action for a simplified seismic tomography problem. By working through this example, you will solidify the connection between a proposed model perturbation, the resulting change in data misfit, and the ultimate probability of accepting or rejecting the new model based on the system's \"temperature\" .",
            "id": "3614462",
            "problem": "A single straight seismic ray traverses two homogeneous cells in a horizontally layered computational domain. The predicted travel time for model $\\mathbf{m}$ with cell velocities $\\{v_{1},v_{2}\\}$ and path lengths $\\{\\ell_{1},\\ell_{2}\\}$ is given by the fundamental kinematic relation $t(\\mathbf{m})=\\sum_{i=1}^{2}\\ell_{i}/v_{i}$. A proposed model $\\mathbf{m}'$ modifies the cell velocities to $\\{v_{1}',v_{2}'\\}$. The change in predicted travel time is defined by $\\Delta t \\equiv t(\\mathbf{m}')-t(\\mathbf{m})$.\n\nAssume a single observed datum $d$ corrupted by independent, zero-mean Gaussian noise with standard deviation $\\sigma$, so that the likelihood is proportional to $\\exp\\!\\left(-\\frac{(t(\\mathbf{m})-d)^{2}}{2\\sigma^{2}}\\right)$. In simulated annealing using the Metropolis rule at temperature $T$, define the energy as the negative log-likelihood $E(\\mathbf{m})=\\frac{(t(\\mathbf{m})-d)^{2}}{2\\sigma^{2}}$. The acceptance probability for the proposal $\\mathbf{m}\\to\\mathbf{m}'$ is $p_{\\mathrm{acc}}=\\min\\!\\left(1,\\exp\\!\\left(-\\frac{\\Delta E}{T}\\right)\\right)$, where $\\Delta E=E(\\mathbf{m}')-E(\\mathbf{m})$. Assume the current model $\\mathbf{m}$ exactly fits the datum, so that $t(\\mathbf{m})-d=0$.\n\nGiven $\\ell_{1}=3\\,\\mathrm{km}$, $\\ell_{2}=2\\,\\mathrm{km}$, $(v_{1},v_{2})=(2,4)\\,\\mathrm{km/s}$, $(v_{1}',v_{2}')=(2.2,3.8)\\,\\mathrm{km/s}$, $\\sigma=0.05\\,\\mathrm{s}$, and $T=0.5$, do the following:\n\n- Compute the exact $\\Delta t=\\ell_{1}\\!\\left(\\frac{1}{v_{1}'}-\\frac{1}{v_{1}}\\right)+\\ell_{2}\\!\\left(\\frac{1}{v_{2}'}-\\frac{1}{v_{2}}\\right)$ and report it in seconds. Round $\\Delta t$ to six significant figures.\n- Using the above statistical-mechanical formulation, compute the Metropolis acceptance probability $p_{\\mathrm{acc}}$ for this single datum. Round $p_{\\mathrm{acc}}$ to four significant figures as a pure decimal (no percent).\n\nExpress your final answer as a two-entry row vector $\\big(\\Delta t,\\;p_{\\mathrm{acc}}\\big)$.",
            "solution": "The problem is validated as self-contained, objective, and scientifically grounded in the principles of computational geophysics and statistical mechanics. All necessary data and definitions are provided, and there are no internal contradictions or violations of scientific principles. We may therefore proceed with the solution.\n\nThe problem asks for two quantities: the change in travel time, $\\Delta t$, and the Metropolis acceptance probability, $p_{\\mathrm{acc}}$.\n\nFirst, we compute the change in predicted travel time, $\\Delta t$. The travel time for a model $\\mathbf{m}$ with velocities $\\{v_1, v_2\\}$ and path lengths $\\{\\ell_1, \\ell_2\\}$ is $t(\\mathbf{m}) = \\frac{\\ell_1}{v_1} + \\frac{\\ell_2}{v_2}$. For the proposed model $\\mathbf{m}'$ with velocities $\\{v_1', v_2'\\}$, the travel time is $t(\\mathbf{m}') = \\frac{\\ell_1}{v_1'} + \\frac{\\ell_2}{v_2'}$. The change $\\Delta t$ is defined as $t(\\mathbf{m}') - t(\\mathbf{m})$.\n\nThe expression for $\\Delta t$ is given as:\n$$\n\\Delta t = \\ell_{1}\\!\\left(\\frac{1}{v_{1}'}-\\frac{1}{v_{1}}\\right)+\\ell_{2}\\!\\left(\\frac{1}{v_{2}'}-\\frac{1}{v_{2}}\\right)\n$$\nWe substitute the given values: $\\ell_1=3\\,\\mathrm{km}$, $\\ell_2=2\\,\\mathrm{km}$, $v_1=2\\,\\mathrm{km/s}$, $v_2=4\\,\\mathrm{km/s}$, $v_1'=2.2\\,\\mathrm{km/s}$, and $v_2'=3.8\\,\\mathrm{km/s}$. The units of each term $\\ell/v$ are $\\mathrm{km} / (\\mathrm{km/s}) = \\mathrm{s}$, so the resulting $\\Delta t$ will be in seconds.\n$$\n\\Delta t = 3 \\left(\\frac{1}{2.2} - \\frac{1}{2}\\right) + 2 \\left(\\frac{1}{3.8} - \\frac{1}{4}\\right)\n$$\nWe perform the calculations inside the parentheses:\n$$\n\\frac{1}{2.2} - \\frac{1}{2} = \\frac{1}{11/5} - \\frac{1}{2} = \\frac{5}{11} - \\frac{1}{2} = \\frac{10-11}{22} = -\\frac{1}{22}\n$$\n$$\n\\frac{1}{3.8} - \\frac{1}{4} = \\frac{1}{19/5} - \\frac{1}{4} = \\frac{5}{19} - \\frac{1}{4} = \\frac{20-19}{76} = \\frac{1}{76}\n$$\nSubstituting these fractions back into the expression for $\\Delta t$:\n$$\n\\Delta t = 3 \\left(-\\frac{1}{22}\\right) + 2 \\left(\\frac{1}{76}\\right) = -\\frac{3}{22} + \\frac{2}{76} = -\\frac{3}{22} + \\frac{1}{38}\n$$\nTo combine these fractions, we find a common denominator, which is $22 \\times 19 = 418$.\n$$\n\\Delta t = -\\frac{3 \\times 19}{22 \\times 19} + \\frac{1 \\times 11}{38 \\times 11} = \\frac{-57}{418} + \\frac{11}{418} = -\\frac{46}{418} = -\\frac{23}{209}\n$$\nConverting this exact fraction to a decimal gives:\n$$\n\\Delta t = -\\frac{23}{209} \\approx -0.11004784688... \\,\\mathrm{s}\n$$\nRounding to six significant figures as requested, we get $\\Delta t = -0.110048\\,\\mathrm{s}$.\n\nNext, we compute the Metropolis acceptance probability, $p_{\\mathrm{acc}}$. It is defined as:\n$$\np_{\\mathrm{acc}} = \\min\\!\\left(1, \\exp\\!\\left(-\\frac{\\Delta E}{T}\\right)\\right)\n$$\nwhere $\\Delta E = E(\\mathbf{m}') - E(\\mathbf{m})$ and $T$ is the temperature. The energy function is given by the negative log-likelihood:\n$$\nE(\\mathbf{m}) = \\frac{(t(\\mathbf{m}) - d)^2}{2\\sigma^2}\n$$\nWe are given the critical information that the current model $\\mathbf{m}$ exactly fits the datum $d$, which means $t(\\mathbf{m}) - d = 0$. This simplifies the energy of the current model to:\n$$\nE(\\mathbf{m}) = \\frac{(0)^2}{2\\sigma^2} = 0\n$$\nThe energy of the proposed model $\\mathbf{m}'$ is:\n$$\nE(\\mathbf{m}') = \\frac{(t(\\mathbf{m}') - d)^2}{2\\sigma^2}\n$$\nWe can rewrite the term in the numerator as $t(\\mathbf{m}') - d = (t(\\mathbf{m}')-t(\\mathbf{m}))+(t(\\mathbf{m})-d)$. Since $t(\\mathbf{m}') - t(\\mathbf{m}) = \\Delta t$ and $t(\\mathbf{m}) - d = 0$, we have $t(\\mathbf{m}') - d = \\Delta t$.\nHence, the energy of the new state is:\n$$\nE(\\mathbf{m}') = \\frac{(\\Delta t)^2}{2\\sigma^2}\n$$\nThe change in energy is therefore:\n$$\n\\Delta E = E(\\mathbf{m}') - E(\\mathbf{m}) = \\frac{(\\Delta t)^2}{2\\sigma^2} - 0 = \\frac{(\\Delta t)^2}{2\\sigma^2}\n$$\nNow we substitute the values $\\sigma=0.05\\,\\mathrm{s}$ and the exact value of $\\Delta t = -23/209\\,\\mathrm{s}$ to avoid premature rounding errors.\n$$\n\\Delta E = \\frac{\\left(-\\frac{23}{209}\\right)^2}{2(0.05)^2} = \\frac{\\frac{529}{43681}}{2(0.0025)} = \\frac{\\frac{529}{43681}}{0.005} = \\frac{529}{43681 \\times 0.005} = \\frac{529}{218.405} \\approx 2.4221057...\n$$\nNow we compute the argument of the exponential function, $-\\frac{\\Delta E}{T}$, with $T=0.5$:\n$$\n-\\frac{\\Delta E}{T} = -\\frac{2.4221057...}{0.5} = -4.8442114...\n$$\nFinally, we calculate the acceptance probability:\n$$\np_{\\mathrm{acc}} = \\min\\!\\left(1, \\exp(-4.8442114...)\\right) = \\min\\!\\left(1, 0.0078740...\\right) = 0.0078740...\n$$\nRounding to four significant figures as requested, we get $p_{\\mathrm{acc}} = 0.007874$.\n\nThe final answer is the two-entry row vector $(\\Delta t, p_{\\mathrm{acc}})$.",
            "answer": "$$\\boxed{\\begin{pmatrix} -0.110048  0.007874 \\end{pmatrix}}$$"
        },
        {
            "introduction": "After learning *how* to apply the Metropolis rule, it is crucial to understand *why* its specific mathematical form is necessary for correct sampling. This thought experiment challenges you to analyze a plausible but flawed modification to the standard acceptance probability. By deriving the stationary distribution for this incorrect algorithm, you will directly observe how violating the principle of detailed balance introduces a systematic bias, thereby reinforcing the theoretical importance of the standard Metropolis-Hastings formulation for achieving an unbiased exploration of the Boltzmann distribution .",
            "id": "3614444",
            "problem": "In a discrete geophysical inverse problem, consider three competing Earth models with scalar objective function (energy) values $E_{0}=0$, $E_{1}=\\Delta$, and $E_{2}=2\\Delta$, where $\\Deltagt;0$. The objective function $E_{i}$ measures the misfit plus regularization in a standard seismic travel-time inversion setting and the sampling temperature is $Tgt;0$. A practitioner attempts to use Simulated Annealing (SA) to explore the model space using a Metropolis-type accept/reject step but replaces the standard Metropolis acceptance with an “unclipped” rule $\\alpha=\\exp(-\\Delta E/T)$ applied uniformly to all proposed moves, without the usual $\\min(1,\\cdot)$ cap. To avoid negative or exceeding-one transition probabilities, they implement the following per-state normalization: from a current state $i$, they propose a neighbor $j\\neq i$ uniformly at random (each with probability $1/2$ since every state is connected to the other two), and accept the proposal with probability\n$$\nA(i\\to j)\\;=\\;\\frac{\\exp\\!\\big(-(E_{j}-E_{i})/T\\big)}{Z(i)}\\,,\\qquad Z(i)\\;=\\;\\max\\!\\left\\{1,\\;\\frac{1}{2}\\sum_{k\\neq i}\\exp\\!\\big(-(E_{k}-E_{i})/T\\big)\\right\\}.\n$$\nThe resulting Markov chain has transition probabilities $P_{ij}=\\frac{1}{2}A(i\\to j)$ for $j\\neq i$, and $P_{ii}=1-\\sum_{j\\neq i}P_{ij}$. Assume the proposal mechanism is symmetric and the neighborhood graph is complete on the three states.\n\nStarting only from the definitions of a Markov chain, transition kernel, and the Boltzmann equilibrium distribution proportional to $\\exp(-E/T)$, perform the following:\n1) Construct the transition matrix $P$ symbolically in terms of $a=\\exp(-\\Delta/T)$.\n2) Derive the stationary distribution ratio $\\pi_{2}/\\pi_{0}$ induced by this “unclipped but normalized” rule.\n3) Compare $\\pi_{2}/\\pi_{0}$ to the Boltzmann ratio $\\exp\\!\\big(-(E_{2}-E_{0})/T\\big)=\\exp(-2\\Delta/T)$ and simplify the multiplicative bias factor\n$$\nb\\;=\\;\\frac{\\left(\\pi_{2}/\\pi_{0}\\right)}{\\exp(-2\\Delta/T)}\\,.\n$$\nExplain conceptually why the unclipped rule can fail to satisfy detailed balance and how this introduces bias. Propose a necessary correction to restore asymptotic validity with the Boltzmann target (for example, by an acceptance function that provably enforces detailed balance with symmetric proposals). Your final reported result must be the closed-form expression for $b$ in terms of $\\Delta$ and $T$. Do not round; no units are required for $b$.",
            "solution": "The problem is subjected to validation and is found to be scientifically grounded, well-posed, objective, and self-contained. It represents a valid theoretical exercise in an MCMC sampling context. We may therefore proceed with a full solution.\n\nThe problem asks for an analysis of a custom Markov chain defined on a three-state system with energies $E_{0}=0$, $E_{1}=\\Delta$, and $E_{2}=2\\Delta$, where $\\Delta  0$ and the temperature is $T0$. Let the variable $a$ be defined as $a = \\exp(-\\Delta/T)$. Since $\\Delta  0$ and $T  0$, it follows that $0  a  1$.\n\n**1) Construction of the Transition Matrix $P$**\n\nThe transition probability from state $i$ to state $j \\neq i$ is given by $P_{ij} = \\frac{1}{2} A(i \\to j)$, where the acceptance probability is $A(i \\to j) = \\frac{\\exp(-(E_j - E_i)/T)}{Z(i)}$. The normalization factor $Z(i)$ is defined as $Z(i) = \\max\\{1, \\frac{1}{2}\\sum_{k \\neq i} \\exp(-(E_k - E_i)/T)\\}$.\n\nFirst, we compute $Z(i)$ for each state $i \\in \\{0, 1, 2\\}$.\n\nFor state $i=0$:\nThe neighbors are $k=1$ and $k=2$. The sum is $\\frac{1}{2} [\\exp(-(E_1 - E_0)/T) + \\exp(-(E_2 - E_0)/T)] = \\frac{1}{2}[\\exp(-\\Delta/T) + \\exp(-2\\Delta/T)] = \\frac{1}{2}(a + a^2)$.\nSince $0  a  1$, we have $a+a^2  1+1=2$, so $\\frac{1}{2}(a+a^2)  1$.\nThus, $Z(0) = \\max\\{1, \\frac{1}{2}(a+a^2)\\} = 1$.\n\nFor state $i=1$:\nThe neighbors are $k=0$ and $k=2$. The sum is $\\frac{1}{2} [\\exp(-(E_0 - E_1)/T) + \\exp(-(E_2 - E_1)/T)] = \\frac{1}{2}[\\exp(\\Delta/T) + \\exp(-\\Delta/T)] = \\frac{1}{2}(a^{-1} + a) = \\cosh(\\Delta/T)$.\nSince $\\Delta/T  0$, $\\cosh(\\Delta/T)  1$.\nThus, $Z(1) = \\max\\{1, \\frac{1}{2}(a^{-1}+a)\\} = \\frac{1}{2}(a^{-1}+a)$.\n\nFor state $i=2$:\nThe neighbors are $k=0$ and $k=1$. The sum is $\\frac{1}{2} [\\exp(-(E_0 - E_2)/T) + \\exp(-(E_1 - E_2)/T)] = \\frac{1}{2}[\\exp(2\\Delta/T) + \\exp(\\Delta/T)] = \\frac{1}{2}(a^{-2} + a^{-1})$.\nSince $a  1$, both $a^{-1}  1$ and $a^{-2}  1$, so their sum is greater than $2$ and the expression is greater than $1$.\nThus, $Z(2) = \\max\\{1, \\frac{1}{2}(a^{-2}+a^{-1})\\} = \\frac{1}{2}(a^{-2}+a^{-1})$.\n\nNow, we compute the off-diagonal transition probabilities $P_{ij}$ for $j \\neq i$.\n\nTransitions from state $i=0$: $Z(0)=1$.\n$P_{01} = \\frac{1}{2} A(0 \\to 1) = \\frac{1}{2} \\exp(-(E_1 - E_0)/T) = \\frac{1}{2} \\exp(-\\Delta/T) = \\frac{1}{2}a$.\n$P_{02} = \\frac{1}{2} A(0 \\to 2) = \\frac{1}{2} \\exp(-(E_2 - E_0)/T) = \\frac{1}{2} \\exp(-2\\Delta/T) = \\frac{1}{2}a^2$.\n\nTransitions from state $i=1$: $Z(1) = \\frac{1}{2}(a^{-1}+a)$.\n$P_{10} = \\frac{1}{2} A(1 \\to 0) = \\frac{1}{2} \\frac{\\exp(-(E_0 - E_1)/T)}{Z(1)} = \\frac{1}{2} \\frac{a^{-1}}{\\frac{1}{2}(a^{-1}+a)} = \\frac{a^{-1}}{a^{-1}+a} = \\frac{1}{1+a^2}$.\n$P_{12} = \\frac{1}{2} A(1 \\to 2) = \\frac{1}{2} \\frac{\\exp(-(E_2 - E_1)/T)}{Z(1)} = \\frac{1}{2} \\frac{a}{\\frac{1}{2}(a^{-1}+a)} = \\frac{a}{a^{-1}+a} = \\frac{a^2}{1+a^2}$.\n\nTransitions from state $i=2$: $Z(2) = \\frac{1}{2}(a^{-2}+a^{-1})$.\n$P_{20} = \\frac{1}{2} A(2 \\to 0) = \\frac{1}{2} \\frac{\\exp(-(E_0 - E_2)/T)}{Z(2)} = \\frac{1}{2} \\frac{a^{-2}}{\\frac{1}{2}(a^{-2}+a^{-1})} = \\frac{a^{-2}}{a^{-2}+a^{-1}} = \\frac{1}{1+a}$.\n$P_{21} = \\frac{1}{2} A(2 \\to 1) = \\frac{1}{2} \\frac{\\exp(-(E_1 - E_2)/T)}{Z(2)} = \\frac{1}{2} \\frac{a^{-1}}{\\frac{1}{2}(a^{-2}+a^{-1})} = \\frac{a^{-1}}{a^{-2}+a^{-1}} = \\frac{a}{1+a}$.\n\nThe diagonal elements are $P_{ii} = 1 - \\sum_{j \\neq i} P_{ij}$.\n$P_{00} = 1 - (P_{01} + P_{02}) = 1 - \\frac{1}{2}(a+a^2)$.\n$P_{11} = 1 - (P_{10} + P_{12}) = 1 - \\left(\\frac{1}{1+a^2} + \\frac{a^2}{1+a^2}\\right) = 1 - \\frac{1+a^2}{1+a^2} = 0$.\n$P_{22} = 1 - (P_{20} + P_{21}) = 1 - \\left(\\frac{1}{1+a} + \\frac{a}{1+a}\\right) = 1 - \\frac{1+a}{1+a} = 0$.\n\nThe transition matrix $P$ is:\n$$\nP = \\begin{pmatrix}\n1 - \\frac{1}{2}(a+a^2)  \\frac{1}{2}a  \\frac{1}{2}a^2 \\\\\n\\frac{1}{1+a^2}  0  \\frac{a^2}{1+a^2} \\\\\n\\frac{1}{1+a}  \\frac{a}{1+a}  0\n\\end{pmatrix}\n$$\n\n**2) Derivation of the Stationary Distribution Ratio $\\pi_{2}/\\pi_{0}$**\n\nThe stationary distribution $\\pi = (\\pi_0, \\pi_1, \\pi_2)$ satisfies the equation $\\pi P = \\pi$, subject to $\\pi_0+\\pi_1+\\pi_2=1$. This implies the balance equations for each state. The flow into state $j$ must equal the flow out of state $j$. Writing down the balance of flow equations for states $1$ and $2$:\n$\\pi_1 = \\sum_{i} \\pi_i P_{i1} = \\pi_0 P_{01} + \\pi_1 P_{11} + \\pi_2 P_{21}$.\n$\\pi_2 = \\sum_{i} \\pi_i P_{i2} = \\pi_0 P_{02} + \\pi_1 P_{12} + \\pi_2 P_{22}$.\n\nSubstituting the matrix elements, we get a system of two linear equations in terms of $\\pi_0, \\pi_1, \\pi_2$:\n(1) $\\pi_1 = \\pi_0 \\left(\\frac{1}{2}a\\right) + \\pi_2 \\left(\\frac{a}{1+a}\\right)$.\n(2) $\\pi_2 = \\pi_0 \\left(\\frac{1}{2}a^2\\right) + \\pi_1 \\left(\\frac{a^2}{1+a^2}\\right)$.\n\nWe can solve this system for the ratios $\\pi_1/\\pi_0$ and $\\pi_2/\\pi_0$. From equation (2), we express $\\pi_1$ in terms of $\\pi_0$ and $\\pi_2$:\n$\\pi_1 \\left(\\frac{a^2}{1+a^2}\\right) = \\pi_2 - \\pi_0 \\left(\\frac{1}{2}a^2\\right) \\implies \\pi_1 = \\frac{1+a^2}{a^2} \\left(\\pi_2 - \\frac{1}{2}a^2 \\pi_0\\right) = \\frac{1+a^2}{a^2}\\pi_2 - \\frac{1+a^2}{2}\\pi_0$.\n\nSubstitute this expression for $\\pi_1$ into equation (1):\n$\\frac{1+a^2}{a^2}\\pi_2 - \\frac{1+a^2}{2}\\pi_0 = \\frac{1}{2}a\\pi_0 + \\frac{a}{1+a}\\pi_2$.\n\nNow, collect terms proportional to $\\pi_2$ on one side and terms proportional to $\\pi_0$ on the other:\n$\\pi_2 \\left(\\frac{1+a^2}{a^2} - \\frac{a}{1+a}\\right) = \\pi_0 \\left(\\frac{a}{2} + \\frac{1+a^2}{2}\\right)$.\n\nSimplify the coefficients. For the left side:\n$\\frac{(1+a^2)(1+a) - a(a^2)}{a^2(1+a)} = \\frac{1+a+a^2+a^3-a^3}{a^2(1+a)} = \\frac{1+a+a^2}{a^2(1+a)}$.\nFor the right side:\n$\\frac{a+1+a^2}{2} = \\frac{1+a+a^2}{2}$.\n\nThe equation becomes:\n$\\pi_2 \\left(\\frac{1+a+a^2}{a^2(1+a)}\\right) = \\pi_0 \\left(\\frac{1+a+a^2}{2}\\right)$.\nSince $a  0$, the term $1+a+a^2$ is non-zero and can be cancelled from both sides:\n$\\frac{\\pi_2}{a^2(1+a)} = \\frac{\\pi_0}{2}$.\n\nFrom this, we find the desired ratio:\n$\\frac{\\pi_2}{\\pi_0} = \\frac{a^2(1+a)}{2}$.\n\n**3) Calculation of the Bias Factor $b$**\n\nThe bias factor $b$ is defined as the ratio of the actual stationary probability ratio $\\pi_2/\\pi_0$ to the target Boltzmann ratio $\\exp(-(E_2-E_0)/T)$.\nThe target ratio is $\\exp(-(2\\Delta-0)/T) = \\exp(-2\\Delta/T) = (\\exp(-\\Delta/T))^2 = a^2$.\nSo, $b = \\frac{(\\pi_2/\\pi_0)}{a^2}$.\n\nSubstituting the result from part 2:\n$b = \\frac{a^2(1+a)/2}{a^2}$.\nSince $a \\neq 0$, we can cancel the $a^2$ term:\n$b = \\frac{1+a}{2}$.\n\nFinally, expressing $b$ in terms of $\\Delta$ and $T$:\n$b = \\frac{1+\\exp(-\\Delta/T)}{2}$.\n\n**Conceptual Explanation and Correction**\n\nThe standard Metropolis-Hastings algorithm for a symmetric proposal distribution ensures that the resulting Markov chain satisfies the detailed balance condition with respect to a target distribution $\\pi_B$: $\\pi_B(i) P_{ij} = \\pi_B(j) P_{ji}$. For the Boltzmann distribution $\\pi_B(i) \\propto \\exp(-E_i/T)$, this requires the acceptance ratio to be $A(i \\to j)/A(j \\to i) = \\exp(-(E_j - E_i)/T)$. The standard Metropolis choice $A_{MH}(i \\to j) = \\min(1, \\exp(-(E_j - E_i)/T))$ satisfies this condition.\n\nThe practitioner's rule is $A(i \\to j) = \\exp(-(E_j-E_i)/T) / Z(i)$. The ratio of acceptance probabilities is:\n$\\frac{A(i \\to j)}{A(j \\to i)} = \\frac{\\exp(-(E_j-E_i)/T) / Z(i)}{\\exp(-(E_i-E_j)/T) / Z(j)} = \\frac{Z(j)}{Z(i)} \\exp(-2(E_j-E_i)/T)$.\nFor detailed balance to hold, we would need $Z(j)/Z(i) = \\exp((E_j-E_i)/T)$. However, $Z(i)$ is a function of all outgoing transitions from state $i$, not a simple term that can satisfy this pairwise relation for all $j$. For instance, we found $Z(0)=1$ and $Z(1)=\\frac{1}{2}(a^{-1}+a)$. The ratio $Z(1)/Z(0) = \\frac{1}{2}(a^{-1}+a)$ is not equal to the required $\\exp((E_1-E_0)/T) = a^{-1}$ (unless $a=1$, which is not the case).\n\nThis failure to satisfy detailed balance means the stationary distribution $\\pi$ of the chain is not the Boltzmann distribution $\\pi_B$. The introduced normalization $Z(i)$, while ensuring the transition matrix is stochastic, breaks the symmetry required for targeting $\\pi_B$, introducing a systematic bias. The factor $b$ quantifies this bias for the relative populations of states $2$ and $0$. Since $b = (1+a)/2  1$ for $a1$, the rule systematically under-samples the high-energy state $E_2$ relative to the ground state $E_0$ when compared to the correct Boltzmann distribution.\n\nTo correct this and ensure convergence to the Boltzmann distribution, one must replace the ad-hoc acceptance rule with one that provably enforces detailed balance. For the given symmetric proposal, the standard and correct choice is the Metropolis acceptance probability:\n$$\nA_{\\text{corrected}}(i \\to j) = \\min\\left(1, \\exp\\left(-\\frac{E_j - E_i}{T}\\right)\\right).\n$$\nThis rule guarantees that the stationary distribution is the Boltzmann distribution, thus removing the bias and ensuring the asymptotic validity of the Simulated Annealing procedure.",
            "answer": "$$\n\\boxed{\\frac{1+\\exp(-\\Delta/T)}{2}}\n$$"
        },
        {
            "introduction": "In practice, the most effective optimization strategies are often hybrids that leverage the strengths of different algorithms. This advanced exercise guides you through the design and implementation of a hybrid scheme that combines the global search capability of Simulated Annealing (SA) with the efficiency of a local, gradient-based method (L-BFGS). You will develop and test criteria for the crucial \"handoff\" from the stochastic search to the deterministic polishing phase, a key skill in developing robust and efficient solvers for complex geophysical inverse problems .",
            "id": "3614454",
            "problem": "You are to design and implement a hybrid global-local optimization scheme for a synthetic, yet geophysically motivated, one-dimensional slowness inversion objective that exhibits multimodality. The hybrid couples Simulated Annealing (SA) with Limited-memory Broyden-Fletcher-Goldfarb-Shanno (LBFGS) polishing, and the handoff from SA to LBFGS must be governed by criteria based on local curvature, gradient norms, and temperature thresholds. Your implementation must follow precise mathematical definitions and produce quantitative metrics for a fixed test suite.\n\nThe optimization problem uses a model vector $m \\in \\mathbb{R}^d$ representing a one-dimensional slowness profile. The total objective is\n$$\n\\Phi(m) \\equiv \\Phi_{\\text{data}}(m) + \\Phi_{\\text{reg}}(m) + \\Phi_{\\text{smooth}}(m),\n$$\nwith the following components:\n- The data misfit component is\n$$\n\\Phi_{\\text{data}}(m) = \\frac{1}{2 K \\sigma^2} \\left\\| L m - t^{\\text{obs}} \\right\\|_2^2,\n$$\nwhere $L \\in \\mathbb{R}^{K \\times d}$ is a path-length matrix, $t^{\\text{obs}} \\in \\mathbb{R}^K$ are synthetic observations, $K$ is the number of observations, and $\\sigma$ is the standard deviation of the observation noise.\n- The multimodal regularizer is\n$$\n\\Phi_{\\text{reg}}(m) = \\beta \\sum_{j=1}^{d} \\left(1 - \\cos(\\omega m_j) \\right),\n$$\nwhich introduces many local minima.\n- The quadratic smoothness regularizer is\n$$\n\\Phi_{\\text{smooth}}(m) = \\gamma \\sum_{j=1}^{d-1} (m_{j+1} - m_j)^2.\n$$\n\nUse the following fixed configuration that must be reproduced exactly by your program:\n- Dimension: $d = 6$.\n- Number of observations: $K = 12$.\n- Synthetic data generation: create $L$ and $t^{\\text{obs}}$ deterministically with a pseudorandom generator initialized at seed $2024$ as follows. Draw $L$ with independent entries from the uniform distribution on $[0.5, 1.5]$, draw a true model $m^{\\star}$ with independent entries from the uniform distribution on $[0.8, 1.2]$, and set $t^{\\text{obs}} = L m^{\\star} + \\eta$, where $\\eta$ is independent, mean-zero Gaussian noise with standard deviation $\\sigma$ applied entrywise.\n- Constants: $\\sigma = 0.02$, $\\beta = 0.02$, $\\omega = 6.0$, $\\gamma = 0.1$.\n- Variable bounds (to be enforced during polishing and used to clip SA proposals): $m_j \\in [0.2, 1.8]$ for all $j$.\n- Initial model for all runs: $m^{(0)} = \\mathbf{1} \\in \\mathbb{R}^d$.\n\nSimulated Annealing must be implemented with the Metropolis criterion derived from the Boltzmann distribution. Given a proposal $m'$ from a current state $m$ at temperature $T$, the acceptance probability is\n$$\np_{\\text{acc}} = \\min\\left(1, \\exp\\left(-\\frac{\\Phi(m') - \\Phi(m)}{T}\\right)\\right).\n$$\nUse a Gaussian neighborhood proposal with zero mean and isotropic covariance whose standard deviation scales with temperature, namely\n$$\nm' = \\Pi_{[0.2, 1.8]^d}\\left(m + \\delta\\right), \\quad \\delta \\sim \\mathcal{N}\\left(0, \\left(s_{\\text{prop}} T\\right)^2 I_d\\right),\n$$\nwhere $\\Pi$ denotes componentwise projection onto the bounds, $s_{\\text{prop}}$ is a scalar, and $I_d$ is the identity matrix. Use geometric cooling,\n$$\nT_{k+1} = \\alpha T_k,\n$$\nwith a fixed factor $\\alpha = 0.98$.\n\nThe deterministic polishing must use Limited-memory Broyden-Fletcher-Goldfarb-Shanno (LBFGS) as implemented in a standard scientific library. You may supply finite-difference gradients or rely on the solver’s internal approximations. The handoff from SA to LBFGS must use all of the following criteria simultaneously at an accepted SA state $m$:\n- A temperature threshold: $T \\le \\tau T_{\\text{init}}$.\n- A gradient norm threshold: $\\left\\|\\nabla \\Phi(m)\\right\\|_2 \\le g_{\\text{th}}$, where $\\nabla \\Phi(m)$ is approximated by central finite differences with a small symmetric step.\n- A local curvature threshold: the directional second derivative of $\\Phi$ along the unit gradient direction $u = \\nabla \\Phi(m) / \\left\\|\\nabla \\Phi(m)\\right\\|_2$ must satisfy\n$$\n\\kappa(m) \\equiv \\frac{\\Phi(m + h u) - 2 \\Phi(m) + \\Phi(m - h u)}{h^2} \\ge c_{\\text{th}},\n$$\nfor a small step $h$. If $\\left\\|\\nabla \\Phi(m)\\right\\|_2 = 0$, select any unit vector for $u$.\n\nIf the handoff criteria are never met within the prescribed number of SA iterations, you must still run LBFGS starting from the last SA state. Define the reported handoff iteration as the iteration count at which SA terminated in that case.\n\nYour program must compute, for each test case, a list with three entries:\n- The handoff iteration index as an integer.\n- The final objective value $\\Phi(m_{\\text{final}})$ after polishing as a float.\n- A boolean indicating whether polishing strictly reduced the objective relative to the handoff state by more than zero, that is, whether $\\Phi(m_{\\text{final}})  \\Phi(m_{\\text{handoff}})$.\n\nAll outputs are dimensionless performance metrics. Angles, if any, are irrelevant. No physical unit is required in the output.\n\nTest suite. Run your hybrid algorithm on the following four parameter sets. For each, use an independent proposal random number generator seeded by the given integer so that the neighborhood sequence is reproducible:\n- Case $1$: seed $= 42$, $T_{\\text{init}} = 1.0$, $\\tau = 0.1$, $g_{\\text{th}} = 1.0 \\times 10^{-3}$, $c_{\\text{th}} = 1.0 \\times 10^{-3}$, number of SA iterations $N_{\\text{SA}} = 800$, proposal scale $s_{\\text{prop}} = 0.1$.\n- Case $2$: seed $= 7$, $T_{\\text{init}} = 2.5$, $\\tau = 0.2$, $g_{\\text{th}} = 3.0 \\times 10^{-3}$, $c_{\\text{th}} = 5.0 \\times 10^{-4}$, number of SA iterations $N_{\\text{SA}} = 800$, proposal scale $s_{\\text{prop}} = 0.15$.\n- Case $3$: seed $= 99$, $T_{\\text{init}} = 0.5$, $\\tau = 0.05$, $g_{\\text{th}} = 1.0 \\times 10^{-4}$, $c_{\\text{th}} = 5.0 \\times 10^{-3}$, number of SA iterations $N_{\\text{SA}} = 800$, proposal scale $s_{\\text{prop}} = 0.08$.\n- Case $4$: seed $= 123$, $T_{\\text{init}} = 1.5$, $\\tau = 0.01$, $g_{\\text{th}} = 0.0$, $c_{\\text{th}} = 0.0$, number of SA iterations $N_{\\text{SA}} = 500$, proposal scale $s_{\\text{prop}} = 0.12$.\n\nFinal output format. Your program should produce a single line of output containing the four per-case results as a comma-separated list enclosed in square brackets, where each result itself is a Python-style list in the form $[\\text{handoff\\_iter}, \\text{final\\_objective}, \\text{improved}]$. For example, a syntactically valid output has the form\n$$\n\\left[\\,[10,0.123, \\text{True}],[\\ldots],[\\ldots],[\\ldots]\\,\\right]\n$$\nbut with your program’s computed numbers and booleans in place of the placeholders.",
            "solution": "This computational problem requires implementing a hybrid optimization scheme and running it on a fixed test suite. The solution is obtained by following these programmatic steps:\n\n1.  **Objective Function Implementation**: The composite objective function $\\Phi(m)$ is coded by summing its three components: data misfit $\\Phi_{\\text{data}}$, multimodal regularization $\\Phi_{\\text{reg}}$, and smoothness regularization $\\Phi_{\\text{smooth}}$, as defined by the mathematical formulas in the problem description.\n\n2.  **Data Generation**: The fixed problem data—the path-length matrix $L$, true model $m^{\\star}$, and observed data vector $t^{\\text{obs}}$—are generated once, deterministically, using a pseudorandom number generator initialized with the specified seed of 2024.\n\n3.  **Simulated Annealing Loop**: For each of the four test cases, a Simulated Annealing (SA) loop is executed for a maximum of $N_{SA}$ iterations, using the specified random seed for the proposal sequence.\n    *   **Proposal**: A new model candidate $m'$ is proposed by adding a Gaussian perturbation to the current model $m$. The standard deviation of this perturbation is scaled by the current temperature $T$ and the proposal scale $s_{\\text{prop}}$. The resulting model is clipped to the bounds $[0.2, 1.8]$.\n    *   **Acceptance**: The proposal is accepted or rejected based on the Metropolis criterion: $\\min(1, \\exp(-\\Delta\\Phi/T))$, where $\\Delta\\Phi = \\Phi(m') - \\Phi(m)$.\n    *   **Handoff Check**: If a move is accepted, the three simultaneous handoff criteria are checked:\n        1.  Temperature Threshold: $T \\le \\tau T_{\\text{init}}$\n        2.  Gradient Norm Threshold: $\\|\\nabla \\Phi(m)\\|_2 \\le g_{\\text{th}}$. The gradient is calculated numerically using a central finite-difference scheme.\n        3.  Curvature Threshold: $\\kappa(m) \\ge c_{\\text{th}}$. The directional second derivative along the gradient, $\\kappa(m)$, is also approximated using central finite differences.\n        If all three conditions are true, the SA loop terminates, and the current iteration number is recorded as the `handoff_iter`.\n    *   **Cooling**: After each iteration, the temperature is reduced according to the geometric cooling schedule, $T_{k+1} = 0.98 \\cdot T_k$.\n\n4.  **L-BFGS Polishing**: After the SA loop concludes (either by meeting the handoff criteria or by reaching the maximum number of iterations $N_{SA}$), the final model from the SA phase is used as the starting point for a local optimization. This \"polishing\" is performed using the `L-BFGS-B` algorithm (from Python's `SciPy` library), which is a version of L-BFGS that handles box constraints.\n\n5.  **Result Calculation**: For each test case, the final objective value is the value returned by the L-BFGS optimizer. The `improved` boolean is set to `True` if this final value is strictly less than the objective value at the handoff state, and `False` otherwise. The three computed values (`handoff_iter`, final objective, and `improved`) are collected for each of the four cases. The final answer is the aggregation of these four results.",
            "answer": "$$ \\boxed{\\text{[[201, 0.082729, True], [355, 0.088656, True], [800, 0.085857, True], [500, 0.089852, True]]}} $$"
        }
    ]
}