{
    "hands_on_practices": [
        {
            "introduction": "The foundation of a robust domain decomposition preconditioner lies in its coarse space, which is responsible for global information exchange. Before delving into computational costs, it is crucial to understand what makes a coarse space effective, especially for geophysically realistic problems with complex, high-contrast material properties. This first practice uses a conceptual problem to explore why naive coarse spaces fail and what principles must be followed to properly handle challenging geometries, such as subdomains with disconnected interiors .",
            "id": "3586626",
            "problem": "Consider the heterogeneous scalar diffusion model for steady-state flow in the subsurface, written as the elliptic boundary value problem $\\nabla \\cdot (\\kappa \\nabla u) = f$ in a bounded domain $\\Omega \\subset \\mathbb{R}^d$ with appropriate boundary conditions, where $\\kappa(\\mathbf{x})$ denotes a positive, spatially varying conductivity that may exhibit high contrast and geometric complexity typical of computational geophysics. Discretization by a conforming finite element method leads to a symmetric positive definite linear system $A u = b$ with bilinear form $a(u,v) = \\int_{\\Omega} \\kappa \\nabla u \\cdot \\nabla v \\, d\\mathbf{x}$.\n\nTo precondition $A$, consider a two-level domain decomposition method in which $\\Omega$ is partitioned into $N$ nonoverlapping subdomains $\\{D_i\\}_{i=1}^N$, and the coarse space provides global coupling while local spaces are associated with subdomain solvers. Denote by $A_i$ the local operator corresponding to the subdomain $D_i$ equipped with homogeneous Neumann conditions on internal interfaces. In practice for high-contrast geology, a subdomain interior $D_i$ can be disconnected due to the presence of impermeable inclusions or cavities (e.g., salt bodies, voids), so that $D_i = \\bigcup_{m=1}^{M_i} D_i^{(m)}$ with each $D_i^{(m)}$ a connected open set and $M_i \\ge 2$.\n\nFrom first principles, recall that the local Neumann operator $A_i$ on $D_i$ acts through the restriction of $a(\\cdot,\\cdot)$ to $H^1(D_i)$ and enforces zero normal flux across the interface $\\partial D_i \\cap \\mathrm{int}(\\Omega)$. For each connected component $D_i^{(m)}$, the local energy $a(\\cdot,\\cdot)$ vanishes on constant functions supported on $D_i^{(m)}$; thus, the nullspace $\\ker(A_i)$ contains the span of componentwise constants, with dimension at least $M_i$.\n\nIn two-level Additive Schwarz and Balancing Domain Decomposition by Constraints (BDDC), a robust coarse space must capture global low-energy modes that otherwise degrade the condition number. A similar requirement exists for Finite Element Tearing and Interconnecting - Dual-Primal (FETI-DP). Suppose the current coarse space only includes one average per subdomain or only vertex-based constraints, without accounting for the multiplicity of interior connectivity.\n\nWhich option correctly explains why the coarse space must include modes that couple the disconnected parts and proposes a simple enrichment that ensures a proper coarse correction for the heterogeneous diffusion operator described above?\n\nA. Because the local Neumann problems on $D_i$ possess a nullspace spanned by functions that are constant on each connected component $D_i^{(m)}$, any coarse space that fails to represent all such componentwise constants leaves uncoupled, low-energy modes in $\\ker(A_i)$ that appear as small eigenvalues of the preconditioned operator. A simple enrichment is to add, for every subdomain $D_i$ and each component $D_i^{(m)}$, one coarse basis function that is constant on $D_i^{(m)}$ (and zero elsewhere), equivalently enforcing one primal constraint per connected component (componentwise average) so that $\\ker(A_i) \\subset \\mathrm{Range}$ of the coarse space.\n\nB. Because Krylov methods stall on oscillatory wave solutions, the remedy is to add a damped Jacobi smoother; coarse space enrichment is unnecessary as long as the iterative method is restarted frequently.\n\nC. Because insufficient overlap prevents information transfer, increasing the overlap between subdomains by a factor of $2$ guarantees coupling of disconnected interiors and obviates the need to modify the coarse space.\n\nD. Because disconnected interiors cause rank deficiency only at geometric vertices, it suffices to add one vertex-based coarse degree of freedom per subdomain; there is no need for componentwise constraints or basis functions.\n\nE. Because high permeability contrast induces high-frequency bubble modes, enriching the coarse space with subdomain bubble functions that vanish on all interfaces and average to zero on each $D_i$ is sufficient to couple disconnected components.",
            "solution": "The core principle for designing a robust two-level domain decomposition preconditioner is that the coarse space must effectively handle all error modes that the local solvers are blind to. These \"blind spots\" correspond to the nullspace (or kernel) of the local subdomain operators.\n\nIn this problem, the local operator $A_i$ on each subdomain $D_i$ is defined with homogeneous Neumann conditions on the internal interfaces. The energy associated with this operator is $a_i(u_i, u_i) = \\int_{D_i} \\kappa |\\nabla u_i|^2 d\\mathbf{x}$. A function $u_i$ is in the nullspace of $A_i$ if this energy is zero. Since the conductivity $\\kappa$ is positive, this implies that the gradient $\\nabla u_i$ must be zero everywhere in $D_i$.\n\nThe problem specifies that a subdomain $D_i$ can be composed of $M_i$ disconnected components, $D_i = \\bigcup_{m=1}^{M_i} D_i^{(m)}$. A function's gradient is zero on this domain if and only if the function is constant on each of these connected components. The constant values can be different for each component. Therefore, the nullspace $\\ker(A_i)$ is an $M_i$-dimensional space, spanned by functions that are constant on one component and zero on all others.\n\nIf a coarse space is constructed with only one average per subdomain or only with vertex constraints, it cannot control the relative values of the solution on these $M_i$ different floating components (when $M_i > 1$). These unconstrained modes are \"low-energy\" (in fact, zero-energy) from the local solver's perspective but represent global errors that must be resolved. Failure to include them in the coarse space results in very small eigenvalues in the preconditioned operator, which severely degrades convergence, making the condition number very large.\n\nTo ensure robustness, the coarse space must be able to represent every function in the nullspace of every local operator. The simplest way to achieve this is to introduce one coarse basis function (or one primal constraint) for each connected component of each subdomain. This ensures that all componentwise constant modes are handled by the global coarse solve.\n\nLet's evaluate the options based on this principle:\n\n- **A:** This option correctly identifies the nullspace of the local Neumann problem as the space of componentwise constant functions. It correctly diagnoses the problem—that failing to include these in the coarse space leads to small eigenvalues—and proposes the correct solution: enriching the coarse space with one basis function or constraint per connected component. This ensures that $\\ker(A_i)$ is a subset of the range of the coarse space interpolation operator, which is the necessary condition for robustness. This option is correct.\n\n- **B:** This is incorrect. The problem is with low-energy modes, not high-frequency oscillatory modes. Smoothers like Jacobi are ineffective for low-frequency errors; that is the job of the coarse grid.\n\n- **C:** This is incorrect. While larger overlap can improve convergence for Schwarz methods, it cannot solve the fundamental problem of a singular local operator. The nullspace modes are internal to the subdomain components and are not resolved by increasing overlap at the boundaries.\n\n- **D:** This is incorrect. A floating, disconnected component may not contain any geometric vertices, so vertex-based constraints would fail to constrain its constant mode. The rank deficiency is related to the domain's topology, not just its vertices.\n\n- **E:** This is incorrect. Bubble functions vanish on the boundary and are typically used to handle high-frequency behavior *within* a subdomain. They are orthogonal to the constant functions that span the nullspace of the Neumann operator and thus cannot fix the problem.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "After establishing the theoretical requirements for a robust coarse space, the next logical step is to analyze its practical cost and its impact on solver performance. This practice provides a hands-on analysis of the computational trade-offs involved in the coarse-grid correction of a two-level additive Schwarz method. You will derive the cost of assembling the coarse operator in parallel and quantify how using an inexact (and therefore cheaper) coarse solver affects the overall convergence rate of the preconditioned iterative method .",
            "id": "3586575",
            "problem": "Consider a symmetric positive definite (SPD) linear system $A u = f$ arising from a second-order elliptic partial differential equation model used in computational geophysics. A two-level additive Schwarz preconditioner is used, with $S$ nonoverlapping subdomains, each with $n_{s}$ interior unknowns. On each subdomain $i \\in \\{1,\\dots,S\\}$, the local stiffness matrix is $A_{i} \\in \\mathbb{R}^{n_{s} \\times n_{s}}$, and the coarse space is constructed with $r$ basis functions per subdomain. The global coarse restriction is $R_{0} \\in \\mathbb{R}^{n_{0} \\times n}$, where $n_{0} = r S$, and $R_{0i} \\in \\mathbb{R}^{r \\times n_{s}}$ denotes the block of $R_{0}$ corresponding to subdomain $i$.\n\nThe coarse operator is defined by $A_{0} = R_{0} A R_{0}^{T}$ and can be expressed as a sum of local contributions $B_{i} = R_{0i} A_{i} R_{0i}^{T}$, making it amenable to parallel assembly. Assume a floating-point operation (flop) cost model with the following well-tested facts:\n- The cost to apply a sparse matrix $A_{i}$ to a dense vector of length $n_{s}$ is $2 \\,\\mathrm{nnz}(A_{i})$ flops, where $\\mathrm{nnz}(A_{i})$ is the number of nonzero entries of $A_{i}$.\n- The cost to form an inner product of two dense vectors of length $n_{s}$ is $2 n_{s}$ flops.\n- The average number of nonzeros per row of $A_{i}$ is a constant $\\gamma > 0$, so $\\mathrm{nnz}(A_{i}) \\approx \\gamma n_{s}$.\n- A local subdomain solve (one application of the inverse of $A_{i}$ using a precomputed sparse Cholesky factorization) requires a forward and backward triangular solve whose combined cost is approximately $4\\,\\mathrm{nnz}(L_{i})$ flops, where $\\mathrm{nnz}(L_{i})$ is the number of nonzeros in the Cholesky factor. Assume a fill factor $\\theta > 1$ so that $\\mathrm{nnz}(L_{i}) \\approx \\theta\\,\\mathrm{nnz}(A_{i})$.\n\nAssume each $R_{0i}^{T}$ has $r$ dense columns supported on subdomain $i$, and that for each subdomain, $B_{i}$ is assembled by:\n1. Computing $y_{j} = A_{i} v_{j}$ for $j = 1,\\dots,r$, where $v_{j}$ is the $j$-th column of $R_{0i}^{T}$.\n2. Forming the $r \\times r$ block $B_{i}$ with entries $(B_{i})_{jk} = v_{j}^{T} y_{k}$.\n\nUnder these assumptions:\n1. Derive the parallel assembly expression for $A_{0}$ and compute the total coarse assembly cost per subdomain, $c_{\\mathrm{asm},i}$, in terms of $n_{s}$, $r$, and $\\gamma$.\n2. Compute the ratio $R$ of the total coarse assembly cost to the cost of one local subdomain solve (forward plus backward substitution) using the given model, and simplify $R$ in terms of $r$, $\\gamma$, and $\\theta$.\n\nNow consider the effect of using an inexact coarse solver. Let $\\tilde{A}_{0}^{-1}$ be an approximate inverse of $A_{0}^{-1}$ satisfying the spectral equivalence\n$$(1 - \\epsilon)\\, z^{T} A_{0}^{-1} z \\le z^{T} \\tilde{A}_{0}^{-1} z \\le (1 + \\epsilon)\\, z^{T} A_{0}^{-1} z \\quad \\text{for all } z \\in \\mathbb{R}^{n_{0}},$$\nwith $0 < \\epsilon < 1$. Let $M^{-1}$ denote the exact two-level additive Schwarz preconditioner and $M_{\\epsilon}^{-1}$ the same preconditioner with $A_{0}^{-1}$ replaced by $\\tilde{A}_{0}^{-1}$. Suppose the condition number of the preconditioned operator with exact coarse solve is $\\kappa = \\kappa(M^{-1} A)$. Using well-tested facts about Preconditioned Conjugate Gradient (PCG) for SPD problems, the asymptotic contraction factor per iteration in the $A$-norm is $q = \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}$.\n\n3. Show how the inexact coarse solve modifies the condition number bound to $\\kappa' \\le \\kappa \\,\\frac{1 + \\epsilon}{1 - \\epsilon}$, and write the corresponding contraction factor $q'$ in terms of $\\kappa$ and $\\epsilon$.\n\nDefine the figure-of-merit $\\phi$ to be the product of the cost ratio and the degraded contraction factor, i.e.,\n$$\\phi = R \\, q'.$$\nProvide $\\phi$ as a single closed-form analytic expression in terms of the parameters $r$, $\\gamma$, $\\theta$, $\\epsilon$, and $\\kappa$. Express the answer in dimensionless form. No rounding is required.",
            "solution": "We consider a symmetric positive definite (SPD) linear system $A u = f$ and a two-level additive Schwarz preconditioner. The global coarse operator is defined as $A_{0} = R_{0} A R_{0}^{T}$. In a domain decomposition framework with $S$ nonoverlapping subdomains, we partition the vector of unknowns according to subdomains and represent the restriction $R_{0}$ blockwise as $R_{0} = \\begin{pmatrix} R_{0 1} & \\cdots & R_{0 S} \\end{pmatrix}$, with each $R_{0 i} \\in \\mathbb{R}^{r \\times n_{s}}$ mapping subdomain $i$ degrees of freedom to $r$ coarse basis coefficients. The local subdomain stiffness matrix is $A_{i} \\in \\mathbb{R}^{n_{s} \\times n_{s}}$. Under nonoverlapping decomposition, the fine-level matrix $A$ can be viewed as block-assembled from local contributions, and the coarse operator can be assembled as a sum of local contributions\n$$\nA_{0} = \\sum_{i=1}^{S} R_{0 i} A_{i} R_{0 i}^{T}.\n$$\nThis equality follows from linearity and the definition of $R_{0}$ as a block row concatenation, which implies that $R_{0} A R_{0}^{T}$ collects contributions of $A$ restricted to each subdomain and projected to the coarse space.\n\nTo assemble $A_{0}$ in parallel, each subdomain $i$ independently computes its local coarse block\n$$\nB_{i} = R_{0 i} A_{i} R_{0 i}^{T} \\in \\mathbb{R}^{r \\times r},\n$$\nand then these $r \\times r$ blocks are summed over $i$ to produce $A_{0}$. An algorithmic realization on each subdomain $i$ is:\n1. Let $V_{i} = R_{0 i}^{T} \\in \\mathbb{R}^{n_{s} \\times r}$ with columns $v_{1},\\dots,v_{r}$. Compute $y_{j} = A_{i} v_{j}$ for $j = 1,\\dots,r$.\n2. Form the entries of $B_{i}$ via $(B_{i})_{jk} = v_{j}^{T} y_{k}$, for $j,k = 1,\\dots,r$.\n\nWe now compute the flop count of this assembly per subdomain under the given model.\n\nFor step 1, each application of $A_{i}$ to a dense vector costs $2\\,\\mathrm{nnz}(A_{i})$ flops. Since this is done $r$ times, the total cost for step 1 on subdomain $i$ is\n$$\nc_{1,i} = 2 r\\, \\mathrm{nnz}(A_{i}).\n$$\nFor step 2, there are $r^{2}$ inner products of length $n_{s}$ (between $v_{j}$ and $y_{k}$). Each inner product costs $2 n_{s}$ flops, so the total cost is\n$$\nc_{2,i} = 2 n_{s} r^{2}.\n$$\nTherefore, the total coarse assembly cost per subdomain is\n$$\nc_{\\mathrm{asm},i} = c_{1,i} + c_{2,i} = 2 r\\, \\mathrm{nnz}(A_{i}) + 2 n_{s} r^{2}.\n$$\nUsing $\\mathrm{nnz}(A_{i}) \\approx \\gamma n_{s}$, we obtain\n$$\nc_{\\mathrm{asm},i} \\approx 2 r \\gamma n_{s} + 2 n_{s} r^{2} = 2 n_{s} \\left( r \\gamma + r^{2} \\right).\n$$\n\nWe compare this to the cost of one local subdomain solve using a precomputed factorization. Let the Cholesky factor $L_{i}$ have $\\mathrm{nnz}(L_{i}) \\approx \\theta\\, \\mathrm{nnz}(A_{i})$ nonzeros, where $\\theta > 1$ is a fill factor. One application of $A_{i}^{-1}$ via forward and backward substitution costs approximately\n$$\nc_{\\mathrm{solve},i} \\approx 4\\,\\mathrm{nnz}(L_{i}) \\approx 4 \\theta\\, \\mathrm{nnz}(A_{i}) \\approx 4 \\theta \\gamma n_{s}.\n$$\nThe ratio of coarse assembly cost to one local subdomain solve cost, per subdomain, is thus\n$$\nR_{i} = \\frac{c_{\\mathrm{asm},i}}{c_{\\mathrm{solve},i}} \\approx \\frac{2 n_{s} \\left( r \\gamma + r^{2} \\right)}{4 \\theta \\gamma n_{s}} = \\frac{r \\gamma + r^{2}}{2 \\theta \\gamma} = \\frac{r}{2 \\theta} + \\frac{r^{2}}{2 \\theta \\gamma}.\n$$\nAssuming identical subdomains, the global ratio $R$ equals $R_{i}$:\n$$\nR = \\frac{r}{2 \\theta} + \\frac{r^{2}}{2 \\theta \\gamma}.\n$$\n\nWe now quantify the effect of an inexact coarse solver. Define the exact two-level preconditioner by\n$$\nM^{-1} = \\sum_{i=1}^{S} R_{i}^{T} A_{i}^{-1} R_{i} + R_{0}^{T} A_{0}^{-1} R_{0},\n$$\nwhere $R_{i}$ are local restriction operators onto subdomain degrees of freedom. The inexact coarse solver replaces $A_{0}^{-1}$ by $\\tilde{A}_{0}^{-1}$ satisfying\n$$\n(1 - \\epsilon)\\, z^{T} A_{0}^{-1} z \\le z^{T} \\tilde{A}_{0}^{-1} z \\le (1 + \\epsilon)\\, z^{T} A_{0}^{-1} z,\\quad \\forall z \\in \\mathbb{R}^{n_{0}},\n$$\nwith $0 < \\epsilon < 1$. This implies spectral equivalence of the exact and inexact coarse inverses with constants $(1 - \\epsilon)$ and $(1 + \\epsilon)$. Consequently, the preconditioner with inexact coarse solve,\n$$\nM_{\\epsilon}^{-1} = \\sum_{i=1}^{S} R_{i}^{T} A_{i}^{-1} R_{i} + R_{0}^{T} \\tilde{A}_{0}^{-1} R_{0},\n$$\nis spectrally equivalent to $M^{-1}$:\n$$\n(1 - \\epsilon)\\, y^{T} M^{-1} y \\le y^{T} M_{\\epsilon}^{-1} y \\le (1 + \\epsilon)\\, y^{T} M^{-1} y,\\quad \\forall y \\in \\mathbb{R}^{n}.\n$$\nTo see this, decompose any $y$ into local and coarse components via the stable decomposition underpinning two-level methods; the only modified term is the coarse component, which is scaled by $(1 \\pm \\epsilon)$ as per the assumed equivalence for $\\tilde{A}_{0}^{-1}$. Therefore, for the preconditioned operator, the Rayleigh quotient bounds imply\n$$\n\\kappa(M_{\\epsilon}^{-1} A) \\le \\frac{1 + \\epsilon}{1 - \\epsilon}\\, \\kappa(M^{-1} A) = \\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}.\n$$\nLet $\\kappa' = \\kappa(M_{\\epsilon}^{-1} A)$ denote the inexact-coarse condition number bound. Then\n$$\n\\kappa' \\le \\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}.\n$$\nFor Preconditioned Conjugate Gradient (PCG) applied to an SPD system, the asymptotic contraction factor per iteration in the $A$-norm is given by\n$$\nq = \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}.\n$$\nReplacing $\\kappa$ by $\\kappa'$ yields\n$$\nq' = \\frac{\\sqrt{\\kappa'} - 1}{\\sqrt{\\kappa'} + 1} \\le \\frac{\\sqrt{\\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}} - 1}{\\sqrt{\\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}} + 1}.\n$$\n\nFinally, define the figure-of-merit $\\phi$ as the product of the cost ratio and the degraded contraction factor:\n$$\n\\phi = R \\, q' = \\left( \\frac{r}{2 \\theta} + \\frac{r^{2}}{2 \\theta \\gamma} \\right) \\, \\frac{\\sqrt{\\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}} - 1}{\\sqrt{\\kappa \\, \\frac{1 + \\epsilon}{1 - \\epsilon}} + 1}.\n$$\nThis expression is dimensionless and reflects how the parallel coarse assembly cost compares to a local subdomain solve and how an inexact coarse solver impacts the asymptotic convergence per iteration.",
            "answer": "$$\\boxed{\\left( \\frac{r}{2 \\theta} + \\frac{r^{2}}{2 \\theta \\gamma} \\right) \\,\\frac{\\sqrt{\\kappa \\,\\frac{1 + \\epsilon}{1 - \\epsilon}} - 1}{\\sqrt{\\kappa \\,\\frac{1 + \\epsilon}{1 - \\epsilon}} + 1}}$$"
        },
        {
            "introduction": "Manually designing a coarse space that is both robust and economical can be challenging for the highly heterogeneous media encountered in computational geophysics. Modern domain decomposition methods automate this process using adaptive techniques. This final practice introduces the powerful Generalized Eigenproblems in the Overlap (GenEO) method, which systematically builds a coarse space tailored to the specific problem by identifying problematic low-energy modes. Through a computational exercise, you will implement the core logic of the GenEO selection strategy to estimate the coarse space size needed to achieve a target condition number .",
            "id": "3586617",
            "problem": "Consider the scalar elliptic operator encountered in subsurface flow modeling, where the governing equation is the heterogeneous diffusion problem $-\\nabla \\cdot (k(\\mathbf{x}) \\nabla u(\\mathbf{x})) = f(\\mathbf{x})$ with heterogeneous permeability $k(\\mathbf{x})$ taken from Society of Petroleum Engineers (SPE) benchmark data. Suppose the data for SPE10 layer $85$ are mapped to a piecewise linear ($P_1$) finite element (FEM) grid on a rectangular domain, and an overlapping domain decomposition is used to precondition the resulting linear system. Focus on two-level additive Schwarz preconditioning augmented by an adaptive spectral coarse space built from Generalized Eigenproblems in the Overlap (GenEO).\n\nStarting from the standard weak form and overlap-based partition of unity, the GenEO approach constructs, for each subdomain $\\Omega_i$, a local generalized eigenproblem whose Rayleigh quotients measure the propensity of functions to be poorly represented by local solvers plus overlap. A practical coarse space is assembled by selecting local eigenvectors whose eigenvalues lie below a chosen threshold, and extending them by the partition of unity. The adaptive threshold balances the cost of the coarse space dimension with the preconditioner quality.\n\nYour task is to estimate the coarse space dimension required to achieve a target preconditioned condition number $ \\kappa \\le 50 $ using an eigenvalue-threshold selection rule. Use the following principle: if, for each subdomain $\\Omega_i$, all local generalized eigenmodes with eigenvalue $ \\lambda \\le \\theta $ are included in the coarse space, then the remaining subspace on which the local Rayleigh quotients satisfy $ \\lambda \\ge \\theta $ yields a global condition number bounded by\n$$\n\\kappa \\le \\frac{C_{\\text{stab}}}{\\theta},\n$$\nwhere $ C_{\\text{stab}} $ is a stability constant that depends on the decomposition geometry, overlap size, and the partition-of-unity weights (but is independent of coefficient contrasts once the coarse space is enriched). To meet the target $ \\kappa_{\\text{target}} = 50 $, choose the threshold\n$$\n\\theta = \\frac{C_{\\text{stab}}}{\\kappa_{\\text{target}}}.\n$$\nThe estimated coarse space dimension is then computed as the sum over subdomains of the counts of local eigenvalues less than or equal to $ \\theta $:\n$$\n\\dim(\\mathcal{V}_{\\text{coarse}}) \\approx \\sum_{i} \\#\\{\\lambda^{(i)}_j \\,|\\, \\lambda^{(i)}_j \\le \\theta\\}.\n$$\nAssume the eigenvalues are dimensionless (the generalized eigenproblems are normalized using overlap weights and finite element mass forms), and the dimension estimate is the integer count indicated above.\n\nImplement a program that, for each test case, takes:\n- A list of local eigenvalue arrays $[\\{\\lambda^{(1)}_j\\}, \\{\\lambda^{(2)}_j\\}, \\ldots]$, one array per subdomain, each sorted in ascending order and containing representative eigenvalues for the SPE10 layer $85$ permeability mapped to a $P_1$ FEM grid.\n- A stability constant $ C_{\\text{stab}} $ for the given overlap configuration.\n\nThe program must:\n- Set $ \\kappa_{\\text{target}} = 50 $ for all cases.\n- Compute $ \\theta = C_{\\text{stab}} / \\kappa_{\\text{target}} $.\n- Count and sum, over all subdomains, the number of eigenvalues $ \\lambda \\le \\theta $.\n- Return this sum as the estimated coarse space dimension for the case.\n\nProvide results for the following test suite, designed to probe different scenarios:\n\n- Case $1$ (moderate heterogeneity, happy path): $ C_{\\text{stab}} = 25 $. Subdomain eigenvalues:\n  - Subdomain $1$: $[0.012, 0.08, 0.12, 0.42, 1.1, 3.0]$\n  - Subdomain $2$: $[0.038, 0.09, 0.15, 0.5, 0.8, 2.2]$\n  - Subdomain $3$: $[0.02, 0.07, 0.25, 0.6, 1.5, 2.5]$\n  - Subdomain $4$: $[0.01, 0.05, 0.2, 1.0, 2.0, 6.0]$\n- Case $2$ (boundary case: threshold below all local eigenvalues, yielding zero added coarse modes): $ C_{\\text{stab}} = 25 $. Subdomain eigenvalues:\n  - Subdomain $1$: $[0.6, 0.9, 1.2]$\n  - Subdomain $2$: $[0.7, 1.0, 1.5]$\n  - Subdomain $3$: $[0.55, 0.8, 3.0]$\n- Case $3$ (extreme high contrast, many very small local eigenvalues): $ C_{\\text{stab}} = 5 $. Subdomain eigenvalues:\n  - Subdomain $1$: $[0.0005, 0.001, 0.005, 0.02, 0.3, 0.9]$\n  - Subdomain $2$: $[0.0003, 0.002, 0.007, 0.015, 0.08, 0.4]$\n  - Subdomain $3$: $[0.0008, 0.004, 0.012, 0.09, 0.2, 1.0]$\n  - Subdomain $4$: $[0.0001, 0.003, 0.01, 0.04, 0.06, 0.08]$\n- Case $4$ (larger overlap constant, allowing a larger threshold): $ C_{\\text{stab}} = 100 $. Subdomain eigenvalues:\n  - Subdomain $1$: $[0.02, 0.2, 0.9, 1.8, 2.5, 5.0]$\n  - Subdomain $2$: $[0.03, 0.6, 1.4, 2.1, 4.0]$\n  - Subdomain $3$: $[0.05, 0.4, 0.7, 1.3, 2.7]$\n  - Subdomain $4$: $[0.01, 0.08, 0.3, 0.8, 1.6, 3.6]$\n- Case $5$ (mixed behavior across subdomains): $ C_{\\text{stab}} = 50 $. Subdomain eigenvalues:\n  - Subdomain $1$: $[1.2, 1.5, 2.0]$\n  - Subdomain $2$: $[0.09, 0.2, 0.5, 0.9, 1.1]$\n  - Subdomain $3$: $[0.4, 0.7, 1.1, 1.8]$\n\nFinal output format requirement: Your program should produce a single line of output containing the results for Cases $1$ through $5$ in order as a comma-separated list enclosed in square brackets, for example, $[n_1,n_2,n_3,n_4,n_5]$, where each $n_i$ is the estimated coarse space dimension (an integer). No other text should be printed. All quantities in this problem are dimensionless, so no physical units are required. Angles do not appear. Percentages are not used.",
            "solution": "The goal is to estimate the dimension of the coarse space required to achieve a target preconditioned condition number of $\\kappa_{\\text{target}} = 50$. The GenEO method provides a systematic way to do this by relating the condition number to a threshold $\\theta$ used for selecting local eigenmodes.\n\nThe fundamental relationship provided is the condition number bound:\n$$\n\\kappa \\le \\frac{C_{\\text{stab}}}{\\theta}\n$$\nTo meet the target, we must ensure $\\kappa_{\\text{target}} \\ge \\frac{C_{\\text{stab}}}{\\theta}$. To build the most economical coarse space that satisfies this, we choose the largest possible threshold, which gives:\n$$\n\\theta = \\frac{C_{\\text{stab}}}{\\kappa_{\\text{target}}}\n$$\nOnce the threshold $\\theta$ is calculated for a given stability constant $C_{\\text{stab}}$, the dimension of the coarse space is estimated by counting how many eigenvalues from each subdomain fall at or below this threshold and summing these counts.\n\n$$\n\\dim(\\mathcal{V}_{\\text{coarse}}) = \\sum_{i} \\#\\{\\lambda^{(i)}_j \\,|\\, \\lambda^{(i)}_j \\le \\theta\\}\n$$\n\nWe apply this procedure to each test case:\n\n**Case 1**:\n- Given: $C_{\\text{stab}} = 25$.\n- Threshold: $\\theta = \\frac{25}{50} = 0.5$.\n- Eigenvalue Counts ($\\le 0.5$):\n    - Subdomain 1: 4 eigenvalues ($0.012, 0.08, 0.12, 0.42$).\n    - Subdomain 2: 4 eigenvalues ($0.038, 0.09, 0.15, 0.5$).\n    - Subdomain 3: 3 eigenvalues ($0.02, 0.07, 0.25$).\n    - Subdomain 4: 3 eigenvalues ($0.01, 0.05, 0.2$).\n- Total Dimension: $4 + 4 + 3 + 3 = 14$.\n\n**Case 2**:\n- Given: $C_{\\text{stab}} = 25$.\n- Threshold: $\\theta = \\frac{25}{50} = 0.5$.\n- Eigenvalue Counts ($\\le 0.5$):\n    - Subdomain 1: 0 eigenvalues.\n    - Subdomain 2: 0 eigenvalues.\n    - Subdomain 3: 0 eigenvalues.\n- Total Dimension: $0 + 0 + 0 = 0$.\n\n**Case 3**:\n- Given: $C_{\\text{stab}} = 5$.\n- Threshold: $\\theta = \\frac{5}{50} = 0.1$.\n- Eigenvalue Counts ($\\le 0.1$):\n    - Subdomain 1: 4 eigenvalues.\n    - Subdomain 2: 5 eigenvalues.\n    - Subdomain 3: 4 eigenvalues.\n    - Subdomain 4: 6 eigenvalues.\n- Total Dimension: $4 + 5 + 4 + 6 = 19$.\n\n**Case 4**:\n- Given: $C_{\\text{stab}} = 100$.\n- Threshold: $\\theta = \\frac{100}{50} = 2.0$.\n- Eigenvalue Counts ($\\le 2.0$):\n    - Subdomain 1: 4 eigenvalues.\n    - Subdomain 2: 3 eigenvalues.\n    - Subdomain 3: 4 eigenvalues.\n    - Subdomain 4: 5 eigenvalues.\n- Total Dimension: $4 + 3 + 4 + 5 = 16$.\n\n**Case 5**:\n- Given: $C_{\\text{stab}} = 50$.\n- Threshold: $\\theta = \\frac{50}{50} = 1.0$.\n- Eigenvalue Counts ($\\le 1.0$):\n    - Subdomain 1: 0 eigenvalues.\n    - Subdomain 2: 4 eigenvalues.\n    - Subdomain 3: 2 eigenvalues.\n- Total Dimension: $0 + 4 + 2 = 6$.\n\nThe provided Python code in the answer block implements this logic to compute the results for all cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Estimates the GenEO coarse space dimension based on local eigenvalue spectra\n    and a target condition number.\n    \"\"\"\n    # Define the target condition number as per the problem statement.\n    kappa_target = 50.0\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (C_stab, list_of_eigenvalue_arrays)\n    test_cases = [\n        # Case 1\n        (25.0, [\n            np.array([0.012, 0.08, 0.12, 0.42, 1.1, 3.0]),\n            np.array([0.038, 0.09, 0.15, 0.5, 0.8, 2.2]),\n            np.array([0.02, 0.07, 0.25, 0.6, 1.5, 2.5]),\n            np.array([0.01, 0.05, 0.2, 1.0, 2.0, 6.0])\n        ]),\n        # Case 2\n        (25.0, [\n            np.array([0.6, 0.9, 1.2]),\n            np.array([0.7, 1.0, 1.5]),\n            np.array([0.55, 0.8, 3.0])\n        ]),\n        # Case 3\n        (5.0, [\n            np.array([0.0005, 0.001, 0.005, 0.02, 0.3, 0.9]),\n            np.array([0.0003, 0.002, 0.007, 0.015, 0.08, 0.4]),\n            np.array([0.0008, 0.004, 0.012, 0.09, 0.2, 1.0]),\n            np.array([0.0001, 0.003, 0.01, 0.04, 0.06, 0.08])\n        ]),\n        # Case 4\n        (100.0, [\n            np.array([0.02, 0.2, 0.9, 1.8, 2.5, 5.0]),\n            np.array([0.03, 0.6, 1.4, 2.1, 4.0]),\n            np.array([0.05, 0.4, 0.7, 1.3, 2.7]),\n            np.array([0.01, 0.08, 0.3, 0.8, 1.6, 3.6])\n        ]),\n        # Case 5\n        (50.0, [\n            np.array([1.2, 1.5, 2.0]),\n            np.array([0.09, 0.2, 0.5, 0.9, 1.1]),\n            np.array([0.4, 0.7, 1.1, 1.8])\n        ])\n    ]\n\n    results = []\n    for c_stab, subdomain_eigs_list in test_cases:\n        # Calculate the eigenvalue threshold theta.\n        theta = c_stab / kappa_target\n        \n        # Initialize the coarse space dimension for the current case.\n        coarse_space_dim = 0\n        \n        # Iterate over each subdomain's eigenvalue array.\n        for eig_array in subdomain_eigs_list:\n            # Count the number of eigenvalues less than or equal to the threshold.\n            # Since the arrays are sorted, a more efficient search could be used,\n            # but for small arrays, direct comparison is clear and sufficient.\n            count = np.sum(eig_array = theta)\n            coarse_space_dim += count\n            \n        results.append(int(coarse_space_dim))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}