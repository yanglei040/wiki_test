{
    "hands_on_practices": [
        {
            "introduction": "The first step in implementing the Boundary Element Method is choosing a discretization scheme to transform the continuous boundary integral equation into a finite-dimensional matrix system. This exercise explores the two most common approaches, the Collocation and Galerkin methods, for the fundamental single-layer potential operator. By constructing and comparing the resulting matrices, you will gain hands-on insight into their distinct properties, such as symmetry and convergence, which are crucial for developing robust BEM solvers. ",
            "id": "3616082",
            "problem": "Consider the two-dimensional Laplace equation and its boundary integral representation on a smooth closed curve. Let $\\Gamma$ be the boundary of a simply connected domain in $\\mathbb{R}^2$, and let $G(x,y) = -\\frac{1}{2\\pi}\\ln\\|x-y\\|$ be the fundamental solution of the Laplace operator. The single-layer boundary integral operator $V$ acts on a scalar density $\\phi$ as $(V\\phi)(x) = \\int_{\\Gamma} G(x,y)\\phi(y)\\,ds_y$. In the Boundary Element Method (BEM), one discretizes this operator. Two common approaches are the collocation method and the Galerkin method. In the collocation method, one constructs a system by evaluating the integral at discrete boundary points, while in the Galerkin method, one uses a variational formulation with test functions and basis functions.\n\nYour task is to construct both discrete systems on the same mesh for the single-layer operator $V$ on a polygonal approximation of the unit circle, and analyze their symmetry and convergence properties under mesh refinement. Use piecewise constant basis functions defined on straight boundary segments that approximate the unit circle by $N$ equally spaced points. Treat angles in radians.\n\nThe geometric and algebraic setup is as follows:\n\n- Mesh: Let $N$ be a positive integer ($N \\in \\{8,16,32\\}$). Define boundary nodes $x_k = (\\cos(2\\pi k/N), \\sin(2\\pi k/N))$ for $k=0,\\dots,N-1$ and straight segments $\\Gamma_i$ connecting $x_i$ to $x_{i+1}$ with indices modulo $N$. Let $L_i$ denote the length of segment $\\Gamma_i$, and $t \\in [0,L_i]$ parametrize $\\Gamma_i$ by $x_i(t) = x_i + \\hat{u}_i t$, where $\\hat{u}_i$ is the unit direction vector along $\\Gamma_i$.\n\n- Basis functions: Use piecewise constant basis functions $b_j$ with $b_j = 1$ on $\\Gamma_j$ and $b_j = 0$ elsewhere.\n\n- Galerkin system: Define the matrix $A \\in \\mathbb{R}^{N\\times N}$ with entries\n$$\nA_{ij} = \\int_{\\Gamma_i}\\int_{\\Gamma_j} G(x,y)\\,ds_x\\,ds_y.\n$$\nFor $i=j$, use the exact diagonal formula for the straight segment self-interaction,\n$$\nA_{ii} = -\\frac{1}{2\\pi}\\left(L_i^2\\ln L_i - \\frac{3}{2}L_i^2\\right).\n$$\nFor $i\\neq j$, evaluate $A_{ij}$ by tensor-product Gauss–Legendre quadrature with $4$ points per segment parameter, i.e., $4\\times 4$ points on $[0,L_i]\\times[0,L_j]$.\n\n- Collocation system: Choose the collocation points as the midpoints $x_i^{\\text{mid}} = x_i + \\hat{u}_i L_i/2$ of each segment $\\Gamma_i$. Define the matrix $B \\in \\mathbb{R}^{N\\times N}$ with entries\n$$\nB_{ij} = \\int_{\\Gamma_j} G(x_i^{\\text{mid}},y)\\,ds_y,\n$$\nevaluated by Gauss–Legendre quadrature with $16$ points on $[0,L_j]$. For $j=i$, the integral kernel has a logarithmic singularity at the collocation point, but it is integrable; use the specified quadrature without special singular treatment.\n\n- Symmetry analysis: Compute the relative asymmetry measures\n$$\n\\sigma_{\\text{gal}} = \\frac{\\|A - A^\\top\\|_F}{\\|A\\|_F}, \\quad \\sigma_{\\text{col}} = \\frac{\\|B - B^\\top\\|_F}{\\|B\\|_F},\n$$\nwhere $\\|\\cdot\\|_F$ is the Frobenius norm.\n\n- Convergence analysis using a known density: Consider the constant density $\\phi(y) \\equiv 1$. For the unit circle, the exact boundary trace of the single-layer potential satisfies $(V\\phi)(x) = 0$ for all $x\\in\\Gamma$ because\n$$\n\\int_0^{2\\pi} \\ln\\left(2\\sin\\frac{\\vartheta}{2}\\right)\\,d\\vartheta = 0\n$$\nand $G(x,y)$ depends only on the angular difference on the circle. For the collocation discretization, define $v^{\\text{col}} = B\\mathbf{1}$, where $\\mathbf{1}\\in\\mathbb{R}^N$ is the vector of ones. For the Galerkin discretization, define $v^{\\text{gal}} = A\\mathbf{1}$. Estimate the errors\n$$\ne_{\\text{col}}(N) = \\max_{i} |v^{\\text{col}}_i|, \\quad e_{\\text{gal}}(N) = \\max_{i} |v^{\\text{gal}}_i|.\n$$\nCompute empirical convergence rates between successive refinements using the mesh size $h(N) = \\frac{2\\pi}{N}$:\n$$\nr_{\\text{col}}(N_1\\to N_2) = \\frac{\\ln\\left(e_{\\text{col}}(N_1)/e_{\\text{col}}(N_2)\\right)}{\\ln\\left(h(N_1)/h(N_2)\\right)},\\quad\nr_{\\text{gal}}(N_1\\to N_2) = \\frac{\\ln\\left(e_{\\text{gal}}(N_1)/e_{\\text{gal}}(N_2)\\right)}{\\ln\\left(h(N_1)/h(N_2)\\right)}.\n$$\n\nImplementation requirements:\n\n- Numerics: Use double precision arithmetic. Use Gauss–Legendre quadrature as specified. Angles must be handled in radians.\n\n- Test suite: Evaluate the metrics for $N\\in\\{8,16,32\\}$. For each $N$, compute $(\\sigma_{\\text{col}}, \\sigma_{\\text{gal}}, e_{\\text{col}}(N), e_{\\text{gal}}(N))$. Additionally, compute the convergence rates $r_{\\text{col}}(8\\to 16)$, $r_{\\text{col}}(16\\to 32)$, $r_{\\text{gal}}(8\\to 16)$, and $r_{\\text{gal}}(16\\to 32)$.\n\n- Output specification: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must consist of the $12$ floats in the following order:\n$$\n[\\sigma_{\\text{col}}(8),\\sigma_{\\text{gal}}(8),e_{\\text{col}}(8),e_{\\text{gal}}(8),\\sigma_{\\text{col}}(16),\\sigma_{\\text{gal}}(16),e_{\\text{col}}(16),e_{\\text{gal}}(16),\\sigma_{\\text{col}}(32),\\sigma_{\\text{gal}}(32),e_{\\text{col}}(32),e_{\\text{gal}}(32)]\n$$\nfollowed by the $4$ convergence rates\n$$\n[r_{\\text{col}}(8\\to 16),r_{\\text{col}}(16\\to 32),r_{\\text{gal}}(8\\to 16),r_{\\text{gal}}(16\\to 32)],\n$$\nconcatenated to form a single flat list of $16$ numbers. The final output format must be exactly\n$$\n[\\text{val}_1,\\text{val}_2,\\dots,\\text{val}_{16}],\n$$\nwith each $\\text{val}_k$ printed as a standard floating-point number.",
            "solution": "The user has provided a well-defined computational problem in the domain of the Boundary Element Method (BEM). The task is to implement and analyze two discretization schemes, Galerkin and Collocation, for the single-layer potential operator associated with the 2D Laplace equation. The analysis involves assessing matrix symmetry and empirical convergence rates on a specific test case.\n\n### Problem Validation\n\n1.  **Extract Givens**: The problem statement specifies the following:\n    *   **Governing Equation**: 2D Laplace equation, $\\Delta u = 0$.\n    *   **Fundamental Solution**: $G(x,y) = -\\frac{1}{2\\pi}\\ln\\|x-y\\|$.\n    *   **Single-Layer Operator**: $(V\\phi)(x) = \\int_{\\Gamma} G(x,y)\\phi(y)\\,ds_y$.\n    *   **Geometry**: A regular $N$-sided polygon inscribed in a unit circle, with $N \\in \\{8, 16, 32\\}$.\n    *   **Basis Functions**: Piecewise constant functions on each segment of the polygon.\n    *   **Galerkin System**: An $N \\times N$ matrix $A$ with entries $A_{ij} = \\int_{\\Gamma_i}\\int_{\\Gamma_j} G(x,y)\\,ds_x\\,ds_y$.\n        *   Diagonal entries $A_{ii}$ are given by the analytical formula $-\\frac{1}{2\\pi}\\left(L_i^2\\ln L_i - \\frac{3}{2}L_i^2\\right)$.\n        *   Off-diagonal entries $A_{ij}$ are to be computed by a $4 \\times 4$ tensor-product Gauss-Legendre quadrature.\n    *   **Collocation System**: An $N \\times N$ matrix $B$ with entries $B_{ij} = \\int_{\\Gamma_j} G(x_i^{\\text{mid}},y)\\,ds_y$, where $x_i^{\\text{mid}}$ is the midpoint of segment $\\Gamma_i$.\n        *   Entries are to be computed by $16$-point Gauss-Legendre quadrature, including for the singular case $i=j$.\n    *   **Analysis Metrics**:\n        *   Relative Asymmetry: $\\sigma = \\frac{\\|M - M^\\top\\|_F}{\\|M\\|_F}$ for $M=A, B$.\n        *   Error Estimate: $e(N) = \\max_i |(M\\mathbf{1})_i|$ for a test case with constant density $\\phi=1$, where $\\mathbf{1}$ is the vector of ones.\n        *   Convergence Rate: $r(N_1\\to N_2) = \\frac{\\ln\\left(e(N_1)/e(N_2)\\right)}{\\ln\\left(h(N_1)/h(N_2)\\right)}$, with mesh size $h(N) = 2\\pi/N$.\n    *   **Output**: A specific list of $16$ floating-point numbers comprising the computed metrics and rates.\n\n2.  **Validate Using Extracted Givens**:\n    *   **Scientific Grounding**: The problem is rooted in standard principles of potential theory and numerical analysis, specifically the BEM for elliptic partial differential equations. All definitions and formulas are standard in this field.\n    *   **Well-Posedness**: The problem is clearly specified. The geometry, basis functions, quadrature rules, and analytical formulas provide a complete and unambiguous set of instructions for constructing the matrices $A$ and $B$. The analysis metrics are also precisely defined.\n    *   **Objectivity**: The problem is stated in objective, mathematical terms, free from any subjective or biased language.\n\n3.  **Verdict**: The problem is valid. It is a well-posed, scientifically sound, and objective task that can be solved computationally as described.\n\n### Solution Design\n\nThe solution will be implemented in Python using the `numpy` and `scipy` libraries. The core of the solution is a function that, for a given number of boundary elements $N$, performs the following steps:\n\n1.  **Geometric Discretization**: The vertices of the regular $N$-gon inscribed in the unit circle are computed. From these vertices, the properties of each linear segment $\\Gamma_i$ are determined: its start and end points, its length $L$, its midpoint $x_i^{\\text{mid}}$, and its unit direction vector $\\hat{u}_i$.\n\n2.  **Quadrature Setup**: Gauss-Legendre quadrature nodes and weights are pre-computed using `scipy.special.roots_legendre` for $4$ and $16$ points. These are scaled from the standard interval $[-1, 1]$ to the segment length interval $[0, L]$.\n\n3.  **Matrix Construction**: The Galerkin matrix $A$ and Collocation matrix $B$ are assembled.\n    *   For the **Galerkin matrix $A$**:\n        *   The diagonal entries $A_{ii}$ are calculated using the provided analytical formula for self-interaction.\n        *   The off-diagonal entries $A_{ij}$ are calculated by a double numerical integration over segments $\\Gamma_i$ and $\\Gamma_j$ using a $4 \\times 4$ a tensor-product of Gauss-Legendre quadrature rules. This involves evaluating the kernel $G(x,y)$ for all $16$ pairs of quadrature points.\n    *   For the **Collocation matrix $B$**:\n        *   Each entry $B_{ij}$ is calculated by a single numerical integration over the segment $\\Gamma_j$. The kernel $G(x_i^{\\text{mid}}, y)$ is evaluated at $16$ Gauss-Legendre quadrature points on $\\Gamma_j$. The instruction to use this numerical quadrature even for the case $i=j$, where the kernel is singular at the midpoint of the integration interval, is strictly followed.\n\n4.  **Symmetry and Convergence Analysis**:\n    *   **Symmetry**: The relative asymmetry measures $\\sigma_{\\text{gal}}$ and $\\sigma_{\\text{col}}$ are computed using the Frobenius norm as specified. Theoretically, for the highly symmetric geometry of a regular polygon, both matrices are expected to be symmetric (and circulant), so any asymmetry will be due to floating-point representation and quadrature errors.\n    *   **Convergence**: For the test case of a constant density $\\phi=1$, the discrete potentials $v^{\\text{gal}} = A\\mathbf{1}$ and $v^{\\text{col}} = B\\mathbf{1}$ are calculated. The maximum absolute value of the entries in these vectors serves as the error estimate, $e_{\\text{gal}}(N)$ and $e_{\\text{col}}(N)$, respectively.\n\nThe main script will execute this process for each required value of $N \\in \\{8, 16, 32\\}$, storing the four metrics $(\\sigma_{\\text{col}}, \\sigma_{\\text{gal}}, e_{\\text{col}}, e_{\\text{gal}})$ for each $N$. Subsequently, the empirical convergence rates are calculated from the error values at successive refinements. Finally, all $16$ computed values are collected into a single list and printed in the specified format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import roots_legendre\n\ndef solve():\n    \"\"\"\n    Main function to solve the BEM problem, including matrix construction,\n    symmetry analysis, and convergence analysis.\n    \"\"\"\n\n    def compute_metrics_for_N(N: int):\n        \"\"\"\n        Constructs BEM matrices and computes analysis metrics for a polygon with N segments.\n        \n        Args:\n            N (int): The number of segments in the polygonal approximation of the unit circle.\n\n        Returns:\n            A tuple containing:\n            - sigma_col (float): Relative asymmetry of the collocation matrix.\n            - sigma_gal (float): Relative asymmetry of the Galerkin matrix.\n            - e_col (float): Error for the collocation method.\n            - e_gal (float): Error for the Galerkin method.\n        \"\"\"\n        # 1. Geometric Setup\n        # Generate nodes for a regular N-gon inscribed in a unit circle.\n        angles = 2.0 * np.pi * np.arange(N, dtype=np.float64) / N\n        nodes = np.array([np.cos(angles), np.sin(angles)]).T\n\n        # For a regular polygon, all segments have the same length.\n        segment_len = np.linalg.norm(nodes[1] - nodes[0])\n        \n        # Define segment properties\n        start_points = nodes\n        end_points = np.roll(nodes, -1, axis=0)\n        midpoints = (start_points + end_points) / 2.0\n        u_vectors = (end_points - start_points) / (segment_len + 1e-30)\n\n        # 2. Quadrature Setup\n        # Galerkin (off-diagonal): 4 points\n        q_nodes_4, q_weights_4 = roots_legendre(4)\n        q_points_gal = segment_len / 2.0 * (q_nodes_4 + 1.0)\n        q_weights_gal = segment_len / 2.0 * q_weights_4\n\n        # Collocation: 16 points\n        q_nodes_16, q_weights_16 = roots_legendre(16)\n        q_points_col = segment_len / 2.0 * (q_nodes_16 + 1.0)\n        q_weights_col = segment_len / 2.0 * q_weights_16\n\n        # 3. Matrix Assembly\n        A = np.zeros((N, N), dtype=np.float64) # Galerkin matrix\n        B = np.zeros((N, N), dtype=np.float64) # Collocation matrix\n\n        for i in range(N):\n            for j in range(N):\n                # Collocation Matrix B entry B_ij\n                quad_pts_on_j_col = start_points[j] + np.outer(q_points_col, u_vectors[j])\n                dists_col = np.linalg.norm(midpoints[i] - quad_pts_on_j_col, axis=1)\n                kernel_vals_col = -1.0 / (2.0 * np.pi) * np.log(dists_col)\n                B[i, j] = np.sum(kernel_vals_col * q_weights_col)\n\n                # Galerkin Matrix A entry A_ij\n                if i == j:\n                    A[i, i] = -1.0 / (2.0 * np.pi) * (segment_len**2 * np.log(segment_len) - 1.5 * segment_len**2)\n                else:\n                    quad_pts_on_i_gal = start_points[i] + np.outer(q_points_gal, u_vectors[i])\n                    quad_pts_on_j_gal = start_points[j] + np.outer(q_points_gal, u_vectors[j])\n                    dists_gal = np.linalg.norm(quad_pts_on_i_gal[:, None, :] - quad_pts_on_j_gal[None, :, :], axis=2)\n                    kernel_vals_gal = -1.0 / (2.0 * np.pi) * np.log(dists_gal)\n                    weights_prod_gal = np.outer(q_weights_gal, q_weights_gal)\n                    A[i, j] = np.sum(kernel_vals_gal * weights_prod_gal)\n        \n        # 4. Analysis\n        norm_A = np.linalg.norm(A, 'fro')\n        norm_B = np.linalg.norm(B, 'fro')\n        sigma_gal = np.linalg.norm(A - A.T, 'fro') / norm_A if norm_A > 0 else 0.0\n        sigma_col = np.linalg.norm(B - B.T, 'fro') / norm_B if norm_B > 0 else 0.0\n        \n        v_gal = A.sum(axis=1) # Corresponds to A @ ones(N)\n        v_col = B.sum(axis=1) # Corresponds to B @ ones(N)\n        \n        e_gal = np.max(np.abs(v_gal))\n        e_col = np.max(np.abs(v_col))\n\n        return sigma_col, sigma_gal, e_col, e_gal\n\n    # Define the test cases from the problem statement.\n    test_cases_N = [8, 16, 32]\n\n    metrics_results = []\n    error_results_for_rates = {}\n\n    for N in test_cases_N:\n        # Main logic to calculate the result for one case goes here.\n        sig_c, sig_g, e_c, e_g = compute_metrics_for_N(N)\n        metrics_results.extend([sig_c, sig_g, e_c, e_g])\n        error_results_for_rates[N] = {'col': e_c, 'gal': e_g}\n\n    # Post-processing to calculate rates\n    log_h_ratio = np.log(2.0)\n    \n    r_col_8_16 = np.log(error_results_for_rates[8]['col'] / error_results_for_rates[16]['col']) / log_h_ratio\n    r_col_16_32 = np.log(error_results_for_rates[16]['col'] / error_results_for_rates[32]['col']) / log_h_ratio\n    \n    r_gal_8_16 = np.log(error_results_for_rates[8]['gal'] / error_results_for_rates[16]['gal']) / log_h_ratio\n    r_gal_16_32 = np.log(error_results_for_rates[16]['gal'] / error_results_for_rates[32]['gal']) / log_h_ratio\n    \n    rate_results = [r_col_8_16, r_col_16_32, r_gal_8_16, r_gal_16_32]\n    \n    final_output = metrics_results + rate_results\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_output))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A high-fidelity Boundary Element Method requires accurate approximation of not just the physical quantities on the boundary, but the boundary geometry itself. This practice delves into the critical and often subtle topic of geometric error, which becomes particularly important when modeling strongly curved geological features. By deriving and applying asymptotic error models, you will uncover how using simple planar facets can limit the overall accuracy of a high-order scheme, demonstrating the importance of isoparametric curvilinear elements for achieving high-order convergence. ",
            "id": "3616106",
            "problem": "Consider a two-dimensional, smooth, closed geological boundary represented by a curve with curvature field denoted by $\\kappa(s)$ as a function of arc length $s$. Let the governing equation in the surrounding homogeneous medium be Laplace’s equation, $\\Delta u = 0$, modeling, for example, a scalar potential field commonly encountered in computational geophysics. The Boundary Element Method (BEM) approximates $u$ via boundary integral equations built from the fundamental solution (Green’s function) of Laplace’s equation. For two dimensions, a classical single-layer representation writes the field at a point $x$ as an integral over the true boundary $\\Gamma$: \n$$\nu(x) = \\int_{\\Gamma} G(x,y)\\,\\phi(y)\\,ds_y, \\quad \\text{where} \\quad G(x,y) = -\\frac{1}{2\\pi}\\log\\|x-y\\|,\n$$\nand $\\phi$ is an unknown boundary density to be approximated numerically. Discretization requires two independent design choices: \n- the approximation order $p$ used for $\\phi$ on each boundary element of characteristic size $h$, \n- the representation of the geometry: either planar facets (straight-line or flat elements) or curvilinear (isoparametric) elements that use polynomial geometry mappings of degree matching or exceeding the unknown approximation order.\n\nYour task is to evaluate, from first principles, how the geometry parameterization (planar versus curvilinear elements) affects the asymptotic BEM accuracy when the true boundary is strongly curved. You must start your reasoning from fundamental definitions (Laplace equation, boundary integral representation, curvature as the inverse radius of curvature, and Taylor expansion of a smooth curve) and derive asymptotic error estimates that explicitly quantify the dependence on curvature $\\kappa$, element order $p$, and boundary mesh size $h$.\n\nYou must show that the total discretization error can be decomposed into a contribution from density approximation and a contribution from geometry approximation. Your derivation must yield asymptotic upper bounds that depend on $\\kappa$, $p$, and $h$, with distinct scalings for planar versus curvilinear geometry parameterizations, and must explain the mechanism by which curvature couples into the geometry error. You must not assume or quote any final BEM error formula; instead, you must derive the scaling from the fundamental base.\n\nFor the programming component, adopt the following normalization, which is indispensable for obtaining explicit numerical outputs without physical units:\n- Work with normalized, dimensionless asymptotic upper bounds in which all hidden constants that do not depend on $\\kappa$, $p$, or $h$ are set to $1$. That is, after completing your derivation, implement the normalized error models you obtained for the two cases (planar geometry parameterization and curvilinear geometry parameterization) using unit constants. \n- Your program must compute, for each test case, the ratio $R = E_{\\text{planar}}/E_{\\text{curv}}$, where $E_{\\text{planar}}$ is your normalized asymptotic error estimate for planar facets and $E_{\\text{curv}}$ is your normalized asymptotic error estimate for curvilinear elements.\n\nInput data and units: There is no run-time input. All quantities are dimensionless. Angles are not directly used; no angle units are needed.\n\nTest suite: Use the following set of five test cases, each specified by curvature magnitude $\\kappa$, polynomial order $p$, and element size $h$:\n- Case A: $\\kappa = 5.0$, $p = 3$, $h = 0.05$.\n- Case B: $\\kappa = 0.1$, $p = 2$, $h = 0.1$.\n- Case C: $\\kappa = 10.0$, $p = 6$, $h = 0.04$.\n- Case D: $\\kappa = 2.0$, $p = 1$, $h = 0.02$.\n- Case E: $\\kappa = 3.0$, $p = 4$, $h = 0.5$.\n\nFinal output specification:\n- For each test case, compute the ratio $R = E_{\\text{planar}}/E_{\\text{curv}}$ using your derived and normalized asymptotic formulas. \n- Your program should produce a single line of output containing the five ratios, in the order of the test cases A through E, as a comma-separated list enclosed in square brackets. \n- Each ratio must be rounded to exactly $6$ decimal places. \n- The required output format is: \n\"[R_A,R_B,R_C,R_D,R_E]\".",
            "solution": "The problem statement as presented is scientifically grounded, well-posed, objective, and internally consistent. It outlines a standard, albeit non-trivial, task in the numerical analysis of boundary integral equations, a core topic in computational geophysics and other areas of computational science. The problem provides all necessary definitions, equations, and parameters to derive the requested asymptotic error estimates from first principles. The governing equation, $\\Delta u = 0$, and the single-layer potential representation with its logarithmic kernel are fundamental to potential theory. The core task, which involves contrasting the asymptotic error of planar versus curvilinear boundary element approximations, is a classic and important subject in the field. The provided parameters are dimensionless and suitable for the requested theoretical analysis. Therefore, the problem is valid, and we may proceed with the derivation.\n\nOur objective is to derive the asymptotic error bounds for the Boundary Element Method (BEM) as a function of the boundary mesh size $h$, the polynomial order of the density approximation $p$, and the local boundary curvature $\\kappa$. The total numerical error in the BEM solution originates primarily from two distinct sources: the approximation of the unknown boundary density $\\phi$ and the approximation of the true boundary geometry $\\Gamma$. The total error can be expressed as an upper bound by the sum of the error contributions from these two sources.\n\nFirst, we consider the error arising from the approximation of the density function, $E_{\\text{density}}$. In BEM, the true, smooth density function $\\phi(y)$ on the boundary $\\Gamma$ is approximated by a function $\\phi_h(y)$ which is typically a piecewise polynomial of degree $p$ over a set of boundary elements of characteristic size $h$. According to standard results from approximation theory, for a sufficiently smooth function $\\phi$, the error of its approximation by a piecewise polynomial of degree $p$ is bounded as:\n$$\n\\|\\phi - \\phi_h\\|_{L^\\infty(\\Gamma)} \\le C_1 h^{p+1} \\max_y |\\phi^{(p+1)}(y)|\n$$\nwhere $C_1$ is a constant independent of $h$ and $\\phi$. This error in the density propagates to the potential calculation, leading to an error contribution that scales as $\\mathcal{O}(h^{p+1})$. This component of the error is determined by the choice of the function space for the unknown and is common to both planar and curvilinear element formulations. We can write its contribution to the total error as $E_{\\text{density}} \\sim \\mathcal{O}(h^{p+1})$.\n\nSecond, we analyze the error contribution from geometry approximation, $E_{\\text{geom}}$, which is the central point of distinction. The true, smooth boundary $\\Gamma$ is replaced by a computational boundary $\\Gamma_h$, which is a union of simpler geometric shapes (elements).\n\nTo quantify this error, we establish a local coordinate system at an arbitrary point on $\\Gamma$, with the origin at the point, the first axis aligned with the tangent vector $T$, and the second axis aligned with the normal vector $N$. By Taylor expansion, a point $y(s)$ on the curve, parameterized by arc length $s$, can be expressed locally as:\n$$\ny(s) = (s, \\frac{1}{2}\\kappa s^2 + \\mathcal{O}(s^3))\n$$\nwhere $\\kappa$ is the local curvature. This shows that any curved boundary locally resembles a parabola. The magnitude of the quadratic term, and thus the deviation from a straight line, is directly proportional to the curvature $\\kappa$.\n\nCase 1: Planar Facet Approximation.\nIn this scheme, each curved segment of the true boundary is approximated by a straight-line segment (a chord) connecting its endpoints. This corresponds to a piecewise linear approximation of the geometry, i.e., a geometric polynomial order $p_{\\text{geom}}=1$. The maximum distance between a parabolic arc of length $h$ and its chord is well-known to occur at the midpoint and scales as $\\frac{1}{8}\\kappa h^2$. Thus, the geometric error, i.e., the distance between $\\Gamma$ and $\\Gamma_h$, is of order $\\mathcal{O}(\\kappa h^2)$. This geometric perturbation introduces an error into the evaluation of the boundary integrals. The magnitude of this error, when propagated through the BEM solution process, is also of order $\\mathcal{O}(\\kappa h^2)$. Therefore, for planar facets, $E_{\\text{geom}}^{\\text{planar}} \\sim \\mathcal{O}(\\kappa h^2)$.\n\nThe total error for the planar facet BEM is the sum of the two contributions. The asymptotic upper bound is determined by the less accurate of the two components:\n$$\nE_{\\text{planar}} \\lesssim C_{\\text{density}} h^{p+1} + C_{\\text{geom}}^{\\text{planar}} \\kappa h^2\n$$\nWhen $p > 1$, the geometry error term $\\mathcal{O}(\\kappa h^2)$ converges more slowly than the density approximation error $\\mathcal{O}(h^{p+1})$. As $h \\to 0$, the $\\mathcal{O}(\\kappa h^2)$ term will dominate, \"polluting\" the high-order accuracy of the density approximation and limiting the overall convergence rate to second order, regardless of how high $p$ is chosen.\n\nCase 2: Curvilinear (Isoparametric) Element Approximation.\nIn an isoparametric formulation, the geometry is represented using the same polynomial basis functions of degree $p$ that are used to approximate the density. Thus, the geometric approximation order is matched to the density approximation order, $p_{\\text{geom}} = p$. The error in approximating the smooth curve $y(s)$ on an interval of size $h$ with a polynomial of degree $p$ is given by approximation theory as $\\mathcal{O}(h^{p+1})$. The magnitude of this error is proportional to the $(p+1)$-th derivative of the function being approximated. Since the deviation of the curve from a flat line is driven by curvature $\\kappa$, the geometric error still scales with $\\kappa$. The resulting distance between $\\Gamma$ and $\\Gamma_h$ is of order $\\mathcal{O}(\\kappa h^{p+1})$. This, in turn, contributes an error to the BEM solution of the same order. Therefore, for curvilinear elements, $E_{\\text{geom}}^{\\text{curv}} \\sim \\mathcal{O}(\\kappa h^{p+1})$.\n\nThe total error for the curvilinear BEM is:\n$$\nE_{\\text{curv}} \\lesssim C_{\\text{density}} h^{p+1} + C_{\\text{geom}}^{\\text{curv}} \\kappa h^{p+1} = (C_{\\text{density}} + C_{\\text{geom}}^{\\text{curv}} \\kappa) h^{p+1}\n$$\nIn this case, both the density and geometry approximation errors converge at the same rate, $\\mathcal{O}(h^{p+1})$. The high-order convergence rate is preserved, and curvature only influences the constant factor in the error bound, not the asymptotic rate. For $p=1$, the method degenerates to the planar facet case, and both formulations yield an $\\mathcal{O}(h^2)$ error.\n\nFor the purpose of the computational task, we adopt the specified normalization where all constants ($C_{\\text{density}}$, $C_{\\text{geom}}^{\\text{planar}}$, $C_{\\text{geom}}^{\\text{curv}}$) are set to $1$. Our normalized asymptotic error models become:\n$$\nE_{\\text{planar}} = h^{p+1} + \\kappa h^2\n$$\n$$\nE_{\\text{curv}} = h^{p+1} + \\kappa h^{p+1} = (1 + \\kappa) h^{p+1}\n$$\nThese models encapsulate the derived principles: the pollution of planar element accuracy by a fixed second-order geometric error proportional to curvature, and the preservation of the optimal convergence rate by curvilinear elements. We will compute the ratio $R = E_{\\text{planar}}/E_{\\text{curv}}$ using these models.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the ratio of BEM asymptotic errors (planar vs. curvilinear)\n    for a given set of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (curvature, polynomial order, element size)\n    # (kappa, p, h)\n    test_cases = [\n        (5.0, 3, 0.05),  # Case A\n        (0.1, 2, 0.1),   # Case B\n        (10.0, 6, 0.04), # Case C\n        (2.0, 1, 0.02),  # Case D\n        (3.0, 4, 0.5),   # Case E\n    ]\n\n    results = []\n    for case in test_cases:\n        kappa, p, h = case\n\n        # Asymptotic error estimate for planar facets, using the derived\n        # normalized formula: E_planar = h^(p+1) + kappa * h^2\n        # This comprises the density approximation error O(h^(p+1)) and the\n        # geometry approximation error O(kappa * h^2).\n        h_p_plus_1 = np.power(h, p + 1)\n        h_2 = np.power(h, 2)\n        e_planar = h_p_plus_1 + kappa * h_2\n\n        # Asymptotic error estimate for curvilinear (isoparametric) elements,\n        # using the derived normalized formula: E_curv = (1 + kappa) * h^(p+1)\n        # Here, both density and geometry errors are O(h^(p+1)).\n        e_curv = (1 + kappa) * h_p_plus_1\n\n        # The problem asks for the ratio R = E_planar / E_curv.\n        # This ratio quantifies the performance degradation from using\n        # low-order geometry (planar) instead of high-order (curvilinear).\n        # A special case occurs if e_curv is zero, but given the inputs\n        # (h>0, kappa>=0), e_curv will be positive.\n        ratio = e_planar / e_curv\n        results.append(ratio)\n\n    # Format the output as a comma-separated list of strings, with each\n    # number rounded to 6 decimal places, enclosed in square brackets.\n    # e.g., \"[1.234567,8.901234,...]\"\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n# Execute the solver function.\nsolve()\n\n```"
        },
        {
            "introduction": "When applying BEM to problems in elastostatics, such as modeling fault mechanics or crustal deformation, a unique challenge arises from the physics of unconstrained bodies. The resulting linear system is singular because it cannot distinguish physical deformation from non-unique rigid body motions. This exercise guides you through the process of diagnosing and resolving this issue by constructing a synthetic system that mimics these properties, allowing you to practice implementing constraints to ensure a unique and physically stable solution. ",
            "id": "3616146",
            "problem": "Consider a two-dimensional boundary element discretization for linear elastostatics on a smooth, closed boundary with $N$ boundary nodes, parameterized on the unit circle. In $2$D, the space of rigid body motions has dimension $3$ (two translations and one in-plane rotation). At the discrete level, this manifests as a nontrivial nullspace of the boundary integral operator, so that the assembled linear system exhibits a rank deficiency corresponding to these rigid body modes. The Fredholm alternative for the associated finite-dimensional operator states that for a linear system $A x = b$ arising from a compact-operator perturbed by a finite-rank operator (in this discrete setting, a symmetric positive semidefinite matrix with a nontrivial nullspace), solvability requires $b$ to be orthogonal to the nullspace of $A^{\\top}$. When the system is underdetermined or has nonunique solutions due to rigid body modes, one can enforce auxiliary constraints via Lagrange multipliers to eliminate these modes and recover uniqueness.\n\nYou will implement a fully deterministic, synthetic, yet physically consistent algebraic model of this situation. The goal is to construct a symmetric positive semidefinite matrix $A \\in \\mathbb{R}^{(2N)\\times(2N)}$ whose nullspace is spanned by the discrete rigid body modes, impose boundary constraints via Lagrange multipliers that remove these modes, and test solvability under full and limited boundary measurements. The construction must proceed as follows:\n\n- Geometry and rigid body modes:\n  - Let $N$ be the number of boundary nodes, with $N = 12$. Place nodes at angles $\\theta_i = \\frac{2\\pi i}{N}$ for $i = 0,1,\\dots,N-1$ on the unit circle, giving coordinates $x_i = \\cos(\\theta_i)$ and $y_i = \\sin(\\theta_i)$.\n  - Stack displacement components nodewise to form vectors in $\\mathbb{R}^{2N}$, ordered as $(u_{x,0},u_{y,0},u_{x,1},u_{y,1},\\dots,u_{x,N-1},u_{y,N-1})^{\\top}$.\n  - Define the three discrete rigid body mode vectors $v_1, v_2, v_3 \\in \\mathbb{R}^{2N}$:\n    - $v_1$ corresponds to translation in $x$: $u_{x,i} = 1$, $u_{y,i} = 0$ for all $i$.\n    - $v_2$ corresponds to translation in $y$: $u_{x,i} = 0$, $u_{y,i} = 1$ for all $i$.\n    - $v_3$ corresponds to in-plane rotation about the origin: $u_{x,i} = -y_i$, $u_{y,i} = x_i$ for all $i$.\n  - Let $V = [v_1\\ v_2\\ v_3] \\in \\mathbb{R}^{(2N)\\times 3}$.\n\n- Constraints via Lagrange multipliers:\n  - Use constant boundary element weights $w_i = \\frac{2\\pi}{N}$ for each node. Construct a diagonal weight matrix $W \\in \\mathbb{R}^{(2N)\\times(2N)}$ that repeats each $w_i$ for $u_{x,i}$ and $u_{y,i}$.\n  - Define the constraint matrix $C \\in \\mathbb{R}^{3\\times(2N)}$ as $C = V^{\\top} W$. Enforcing $C x = 0$ eliminates weighted-average components of $x$ along the rigid body modes.\n\n- Synthetic boundary integral operator:\n  - Let $n = 2N$. Using a fixed pseudo-random number generator seed, construct a random matrix $R \\in \\mathbb{R}^{(n-3)\\times n}$, and project it onto the orthogonal complement of $\\operatorname{span}(V)$ to obtain $\\widetilde{R} = R (I - P)$, where $P = V (V^{\\top} V)^{-1} V^{\\top}$ is the Euclidean projector onto $\\operatorname{span}(V)$ and $I$ is the identity in $\\mathbb{R}^{n\\times n}$. Then form\n  $$\n  A = \\widetilde{R}^{\\top} \\widetilde{R} + \\gamma (I - P),\n  $$\n  with $\\gamma = 10^{-1}$. By construction, $A$ is symmetric positive semidefinite with $\\operatorname{Null}(A) = \\operatorname{span}(V)$.\n\n- Right-hand sides and measurements:\n  - Generate a ground-truth displacement $x_{\\mathrm{true}} \\in \\mathbb{R}^{n}$ by drawing a random vector and projecting it onto the nullspace of $C$ to satisfy $C x_{\\mathrm{true}} = 0$. Define the full right-hand side $b_{\\mathrm{full}} = A x_{\\mathrm{true}}$.\n  - Consider measurement masks that select a subset of the equations (rows) of $A x = b$. If $S \\subset \\{0,1,\\dots,n-1\\}$ is the index set of measured equations, define $A_S$ as the submatrix of $A$ with rows in $S$ and $b_S$ as the corresponding entries of $b$.\n  - To enforce the constraints $C x = 0$, parameterize feasible solutions as $x = N y$, where columns of $N \\in \\mathbb{R}^{n\\times(n-3)}$ form an orthonormal basis for $\\operatorname{Null}(C)$. Solve the constrained least-squares system\n    $$\n    \\min_{y \\in \\mathbb{R}^{n-3}} \\|A_S N y - b_S\\|_2^2,\n    $$\n    which is consistent if and only if $b_S$ lies in the range of $A_S N$. Report solvability by comparing the relative residual $\\|A_S N \\hat{y} - b_S\\|_2 / \\max(\\|b_S\\|_2, \\varepsilon)$ against a tolerance $\\tau$, where $\\varepsilon = 10^{-16}$ is a safety floor and $\\tau = 10^{-8}$.\n\nYour program must implement the above construction with the following fixed parameters to ensure reproducibility:\n- Number of boundary nodes $N = 12$.\n- Random seed for the operator construction $= 2025$.\n- Random seed for the ground-truth displacement $= 7$.\n- Weight parameter $\\gamma = 10^{-1}$.\n- Tolerance $\\tau = 10^{-8}$.\n\nDefine four test cases as follows:\n- Test $1$ (full, consistent): $S = \\{0,1,\\dots,n-1\\}$ and $b = b_{\\mathrm{full}}$.\n- Test $2$ (full, incompatible): $S = \\{0,1,\\dots,n-1\\}$ and $b = b_{\\mathrm{full}} + \\alpha \\,\\hat{v}_3$, where $\\hat{v}_3 = v_3 / \\|v_3\\|_2$ and $\\alpha = \\|b_{\\mathrm{full}}\\|_2$.\n- Test $3$ (limited, consistent): $S = \\{0,2,4,\\dots,n-2\\}$ (every even index) and $b = b_{\\mathrm{full}}$ restricted to $S$.\n- Test $4$ (no measurements): $S = \\varnothing$ and $b$ empty, which is vacuously solvable under the constraints.\n\nFor each test, compute the boolean result indicating whether the constrained least-squares residual is below $\\tau$. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[{\\rm True},{\\rm False},{\\rm True},{\\rm True}]$). No physical units are involved; all quantities are dimensionless. Angles are in radians.",
            "solution": "The problem requires the implementation and analysis of a synthetic algebraic system that models a two-dimensional boundary element method (BEM) formulation for linear elastostatics. A key feature of such systems is the presence of a non-trivial nullspace in the system matrix, corresponding to rigid body motions (RBMs). The solution addresses this by constructing a system with a predefined nullspace, imposing constraints to ensure a unique solution, and evaluating solvability under various measurement scenarios.\n\nThe number of boundary nodes is given as $N=12$. The nodes are located at coordinates $(x_i, y_i)$ on the unit circle, defined by $x_i = \\cos(\\theta_i)$ and $y_i = \\sin(\\theta_i)$, where the angles are $\\theta_i = \\frac{2\\pi i}{N}$ for $i \\in \\{0, 1, \\dots, N-1\\}$. The displacement vector $x \\in \\mathbb{R}^{n}$ where $n=2N=24$, is formed by stacking the $x$ and $y$ components of displacement at each node: $x = (u_{x,0}, u_{y,0}, u_{x,1}, u_{y,1}, \\dots, u_{x,N-1}, u_{y,N-1})^{\\top}$.\n\nIn $2$D elastostatics, there are three rigid body modes: two translations and one in-plane rotation. These are represented by three vectors $v_1, v_2, v_3 \\in \\mathbb{R}^{n}$:\n-   Translation in the $x$-direction, $v_1$: The displacement at each node is $(1, 0)$, so $v_1$ has entries $u_{x,i}=1$ and $u_{y,i}=0$ for all $i$.\n-   Translation in the $y$-direction, $v_2$: The displacement at each node is $(0, 1)$, so $v_2$ has entries $u_{x,i}=0$ and $u_{y,i}=1$ for all $i$.\n-   Rotation about the origin, $v_3$: A small rotation by angle $\\phi$ maps a point $(x_i, y_i)$ to approximately $(x_i - \\phi y_i, y_i + \\phi x_i)$. The displacement vector is thus $(-y_i, x_i)$. The vector $v_3$ has entries $u_{x,i}=-y_i$ and $u_{y,i}=x_i$ for all $i$.\n\nThese three vectors are assembled into a matrix $V = [v_1, v_2, v_3] \\in \\mathbb{R}^{n \\times 3}$. The column space of $V$, $\\operatorname{span}(V)$, represents the space of all possible rigid body motions of the discretized boundary.\n\nTo obtain a unique solution to the elastostatics problem $Ax=b$, the ambiguity introduced by the RBMs must be removed. This is achieved by imposing constraints on the solution vector $x$. The specified constraints are $Cx = 0$, where the constraint matrix $C \\in \\mathbb{R}^{3 \\times n}$ is given by $C = V^{\\top}W$. Here, $W \\in \\mathbb{R}^{n \\times n}$ is a diagonal matrix of quadrature weights. With constant boundary element weights $w_i = \\frac{2\\pi}{N}$, $W$ is simply $\\frac{2\\pi}{N}$ times the identity matrix. The condition $Cx=0$ forces the solution $x$ to have zero weighted-average component along each of the three rigid body modes, effectively \"pinning\" the body and preventing rigid motion. The space of admissible solutions is thus the nullspace of $C$, $\\operatorname{Null}(C)$.\n\nThe core of the problem is the construction of a synthetic system matrix $A \\in \\mathbb{R}^{n \\times n}$ that is symmetric positive semidefinite (SPSD) and whose nullspace is precisely the space of rigid body modes, i.e., $\\operatorname{Null}(A) = \\operatorname{span}(V)$. The construction proceeds as follows:\nFirst, we define the Euclidean projector $P$ onto $\\operatorname{span}(V)$:\n$$P = V (V^{\\top} V)^{-1} V^{\\top}$$\nThe matrix $I-P$ is then the projector onto the orthogonal complement of $\\operatorname{span}(V)$. A random matrix $R \\in \\mathbb{R}^{(n-3) \\times n}$ is generated using a fixed seed for reproducibility. This matrix is projected to be orthogonal to the RBM space:\n$$\\widetilde{R} = R (I - P)$$\nFinally, the system matrix $A$ is assembled as:\n$$A = \\widetilde{R}^{\\top} \\widetilde{R} + \\gamma (I - P)$$\nwith a given constant $\\gamma = 10^{-1}$. Let us verify the properties of $A$.\n-   Symmetry: $A^{\\top} = (\\widetilde{R}^{\\top} \\widetilde{R})^{\\top} + \\gamma (I - P)^{\\top} = \\widetilde{R}^{\\top} \\widetilde{R}^{\\top\\top} + \\gamma(I-P) = A$, since $P$ is a symmetric projector.\n-   Positive Semidefiniteness: For any vector $z \\in \\mathbb{R}^n$, $z^{\\top}Az = z^{\\top}\\widetilde{R}^{\\top}\\widetilde{R}z + \\gamma z^{\\top}(I-P)z = \\|\\widetilde{R}z\\|_2^2 + \\gamma \\|(I-P)z\\|_2^2 \\ge 0$, since $\\gamma > 0$ and $I-P$ is also a projector.\n-   Nullspace: $Az=0$ if and only if both terms in the above sum are zero. $\\gamma \\|(I-P)z\\|_2^2 = 0$ implies $(I-P)z=0$, which means $z=Pz$, so $z \\in \\operatorname{span}(V)$. If $z \\in \\operatorname{span}(V)$, then $(I-P)z = 0$, which in turn implies $\\widetilde{R}z = R(I-P)z = 0$. Thus, $Az=0$ if and only if $z \\in \\operatorname{span}(V)$. The construction is sound.\n\nThe problem then requires solving a system $A_S x = b_S$ under the constraint $Cx=0$, where $S$ is a set of measured row indices. The constraint is handled by parameterizing the solution as $x=Ny$, where the columns of $N \\in \\mathbb{R}^{n \\times (n-3)}$ form an orthonormal basis for $\\operatorname{Null}(C)$. Substituting this into the system yields an unconstrained problem for the coefficient vector $y \\in \\mathbb{R}^{n-3}$:\n$$ A_S N y = b_S $$\nThis system is solved in the least-squares sense, minimizing $\\|A_S N y - b_S\\|_2^2$. A solution for $y$, denoted $\\hat{y}$, is found. Solvability is determined by checking if the relative residual is below a tolerance $\\tau = 10^{-8}$:\n$$ \\frac{\\|A_S N \\hat{y} - b_S\\|_2}{\\max(\\|b_S\\|_2, \\varepsilon)}  \\tau $$\nwhere $\\varepsilon = 10^{-16}$ is a numerical floor.\n\nThe four test cases are designed to probe the behavior of this system:\n1.  **Full, Consistent**: The right-hand side is $b_{\\mathrm{full}} = A x_{\\mathrm{true}}$, where $x_{\\mathrm{true}}$ is constructed to be in $\\operatorname{Null}(C)$. The system $Ax = b_{\\mathrm{full}}$ is solved for $x \\in \\operatorname{Null}(C)$. Since $b_{\\mathrm{full}}$ is in the range of A and we seek a solution in the complement of the nullspace, a solution should exist and the residual should be near zero.\n2.  **Full, Incompatible**: A vector from the nullspace of $A$, $\\hat{v}_3$, is added to the right-hand side. The resulting vector $b = b_{\\mathrm{full}} + \\alpha \\hat{v}_3$ is no longer in the range of $A$ (as $\\operatorname{Range}(A) = (\\operatorname{Null}(A^{\\top}))^{\\perp} = (\\operatorname{Null}(A))^{\\perp}$). The residual of the least-squares problem will be non-zero, corresponding to the projection of $b$ onto the nullspace of $A^{\\top}$.\n3.  **Limited, Consistent**: The system is underdetermined, with fewer equations (rows of $A$) than unknowns (columns of $N$). However, the right-hand side $b_S$ is generated from $x_{\\mathrm{true}}$, ensuring $b_S = (A x_{\\mathrm{true}})_S = (A N y_{\\mathrm{true}})_S = (A_S N) y_{\\mathrm{true}}$. Thus, $b_S$ is in the range of $A_S N$, the system is consistent, and the residual should be near zero.\n4.  **No Measurements**: An empty set of equations is vacuously consistent. The residual is trivially zero.\n\nThe algorithm proceeds by constructing all matrices, generating the data for each test case, solving the corresponding constrained least-squares problem, and evaluating the solvability criterion.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import null_space\n\ndef solve():\n    \"\"\"\n    Implements the synthetic boundary element method model, constructs the system,\n    and tests solvability for four different cases.\n    \"\"\"\n    # Define fixed parameters from the problem statement.\n    N = 12\n    n = 2 * N\n    gamma = 10**-1\n    tau = 10**-8\n    epsilon = 10**-16\n    seed_op = 2025\n    seed_disp = 7\n\n    # 1. Geometry and rigid body modes\n    thetas = np.array([2 * np.pi * i / N for i in range(N)])\n    node_coords = np.array([np.cos(thetas), np.sin(thetas)]).T\n\n    # Construct rigid body mode vectors v1, v2, v3\n    v1 = np.zeros(n)\n    v1[0::2] = 1.0  # x-translation\n\n    v2 = np.zeros(n)\n    v2[1::2] = 1.0  # y-translation\n\n    v3 = np.zeros(n)\n    v3[0::2] = -node_coords[:, 1]  # -y_i for rotation\n    v3[1::2] = node_coords[:, 0]   #  x_i for rotation\n\n    V = np.vstack([v1, v2, v3]).T  # V is (n, 3)\n\n    # 2. Constraints via Lagrange multipliers\n    w_i = (2 * np.pi) / N\n    W = np.diag(np.full(n, w_i))\n    C = V.T @ W  # C is (3, n)\n\n    # 3. Synthetic boundary integral operator\n    # Orthonormal basis for Null(C)\n    N_basis = null_space(C)  # N_basis is (n, n-3)\n\n    # Projector onto span(V)\n    I_n = np.identity(n)\n    P = V @ np.linalg.inv(V.T @ V) @ V.T\n\n    # Generate random matrix R\n    rng_op = np.random.default_rng(seed_op)\n    R = rng_op.standard_normal(size=(n - 3, n))\n\n    # Project R\n    R_tilde = R @ (I_n - P)\n\n    # Construct operator A\n    A = R_tilde.T @ R_tilde + gamma * (I_n - P)\n\n    # 4. Right-hand sides and measurements\n    # Generate ground-truth displacement x_true in Null(C)\n    rng_disp = np.random.default_rng(seed_disp)\n    x_rand = rng_disp.standard_normal(size=n)\n    x_true = N_basis @ (N_basis.T @ x_rand)\n\n    # Generate full right-hand side\n    b_full = A @ x_true\n\n    # Define test cases\n    v3_hat = v3 / np.linalg.norm(v3)\n    alpha = np.linalg.norm(b_full)\n    \n    test_cases_defs = [\n        # Test 1: Full, consistent\n        {'S': np.arange(n), 'b_source': b_full},\n        # Test 2: Full, incompatible\n        {'S': np.arange(n), 'b_source': b_full + alpha * v3_hat},\n        # Test 3: Limited, consistent\n        {'S': np.arange(0, n, 2), 'b_source': b_full},\n        # Test 4: No measurements\n        {'S': np.array([], dtype=int), 'b_source': b_full}\n    ]\n\n    results = []\n    for case in test_cases_defs:\n        S = case['S']\n        b_full_source = case['b_source']\n        \n        # Sub-sample A and b\n        A_S = A[S, :]\n        b_S = b_full_source[S]\n\n        # Form the least-squares system matrix\n        M = A_S @ N_basis\n\n        # Solve the least-squares problem min||My - b_S||^2\n        y_hat, residuals, rank, s = np.linalg.lstsq(M, b_S, rcond=None)\n\n        # Calculate the residual norm from the solution y_hat\n        if M.shape[0] == 0: # Empty system\n            residual_norm = 0.0\n        else:\n            residual_norm = np.linalg.norm(M @ y_hat - b_S)\n\n        b_S_norm = np.linalg.norm(b_S)\n        \n        # Calculate relative residual\n        relative_residual = residual_norm / max(b_S_norm, epsilon)\n        \n        # Check for solvability\n        is_solvable = relative_residual  tau\n        results.append(is_solvable)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}