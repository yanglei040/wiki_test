{
    "hands_on_practices": [
        {
            "introduction": "The asymptotic convergence rate is a key metric for evaluating any iterative solver. For multigrid methods, this rate is determined by the spectral properties of the two-grid or V-cycle error-propagation operator. This exercise bridges the gap between abstract theory and practical measurement by guiding you through the calculation of the convergence factor as an operator norm in the energy space, a natural setting for symmetric positive definite problems common in geophysics . Mastering this calculation allows you to quantitatively verify theoretical predictions against observed numerical behavior.",
            "id": "3611389",
            "problem": "Consider a two-grid cycle used in Algebraic Multigrid (AMG) for a symmetric positive definite (SPD) linear system arising from a discretized heterogeneous diffusion problem in computational geophysics. The fine-grid operator is assumed SPD, and the coarse-grid operator and intergrid transfer have been constructed so that the resulting two-grid error-propagation operator is linear. Let the coarse-level energy operator be\n$$\nA \\;=\\; \\begin{pmatrix}\n2 & 0.6 \\\\\n0.6 & 1\n\\end{pmatrix},\n$$\nand let the measured two-grid error-propagation operator (including one symmetric Gauss–Seidel pre-relaxation and one post-relaxation and an exact coarse-grid correction) be\n$$\nE \\;=\\; \\begin{pmatrix}\n0.3 & -0.1 \\\\\n0 & 0.25\n\\end{pmatrix}.\n$$\nThroughout, use the energy norm induced by $A$, defined by $\\|x\\|_{A} = \\sqrt{x^{\\mathsf{T}} A x}$, and the corresponding induced operator norm $\\|E\\|_{A} = \\sup_{x \\neq 0} \\frac{\\|E x\\|_{A}}{\\|x\\|_{A}}$. The residual is $r = f - A u$, and for an exact right-hand side $f$ and current iterate $u$, the error is $e = u^\\star - u$ with $u^\\star$ the exact solution, so that $r = A e$.\n\nUsing only fundamental definitions and properties of SPD operators and induced norms:\n- Derive an expression that enables computing the asymptotic convergence rate $\\rho = \\|E\\|_{A}$ from $A$ and $E$.\n- Evaluate $\\rho$ numerically for the given $A$ and $E$.\n- Given that the observed residual reduction factor per two-grid cycle, measured in the $A^{-1}$-norm $\\|r\\|_{A^{-1}} = \\sqrt{r^{\\mathsf{T}} A^{-1} r}$, is $0.312$, use the relationship between error reduction in the $A$-norm and residual reduction in the $A^{-1}$-norm to compute the absolute discrepancy\n$$\nd \\;=\\; \\big|\\, \\rho \\;-\\; 0.312 \\,\\big|.\n$$\n\nRound your final numerical answer for $d$ to four significant figures. No physical units are required for the answer.",
            "solution": "The problem is first validated to ensure it is scientifically sound, well-posed, and self-contained.\n\n**Step 1: Extract Givens**\n- The coarse-level energy operator is $A = \\begin{pmatrix} 2 & 0.6 \\\\ 0.6 & 1 \\end{pmatrix}$.\n- The two-grid error-propagation operator is $E = \\begin{pmatrix} 0.3 & -0.1 \\\\ 0 & 0.25 \\end{pmatrix}$.\n- The operator $A$ is stated to be symmetric positive definite (SPD).\n- The energy norm is defined as $\\|x\\|_{A} = \\sqrt{x^{\\mathsf{T}} A x}$.\n- The induced operator norm is $\\|E\\|_{A} = \\sup_{x \\neq 0} \\frac{\\|E x\\|_{A}}{\\|x\\|_{A}}$.\n- The asymptotic convergence rate is $\\rho = \\|E\\|_{A}$.\n- The relationship between residual $r$ and error $e$ is $r = A e$.\n- The $A^{-1}$-norm is defined as $\\|r\\|_{A^{-1}} = \\sqrt{r^{\\mathsf{T}} A^{-1} r}$.\n- The observed residual reduction factor in the $A^{-1}$-norm is given as the numerical value $0.312$.\n- The task is to compute the absolute discrepancy $d = |\\rho - 0.312|$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is well-defined and operates within the standard framework of numerical linear algebra and multigrid methods. The matrix $A$ is symmetric. Its leading principal minors are $2 > 0$ and $\\det(A) = (2)(1) - (0.6)(0.6) = 2 - 0.36 = 1.64 > 0$. Therefore, $A$ is indeed symmetric positive definite, which ensures that $\\| \\cdot \\|_{A}$ is a valid vector norm and the problem is mathematically sound. The given operators and definitions are standard. The problem is self-contained and consistent.\n\n**Verdict**\nThe problem is valid. We proceed with the solution.\n\n**Part 1: Derivation of the expression for the convergence rate $\\rho = \\|E\\|_{A}$**\n\nThe asymptotic convergence rate is given by $\\rho = \\|E\\|_{A}$. To derive a computable expression, we start from the definition of the induced operator norm:\n$$\n\\rho^2 = \\|E\\|_{A}^2 = \\sup_{x \\neq 0} \\frac{\\|E x\\|_{A}^2}{\\|x\\|_{A}^2}\n$$\nUsing the definition of the energy norm, $\\|v\\|_{A}^2 = v^{\\mathsf{T}} A v$, we can write:\n$$\n\\rho^2 = \\sup_{x \\neq 0} \\frac{(E x)^{\\mathsf{T}} A (E x)}{x^{\\mathsf{T}} A x} = \\sup_{x \\neq 0} \\frac{x^{\\mathsf{T}} E^{\\mathsf{T}} A E x}{x^{\\mathsf{T}} A x}\n$$\nThis expression is the maximum value of the Rayleigh quotient for the matrix pencil $(E^{\\mathsf{T}} A E, A)$. This maximum value is the largest eigenvalue, $\\lambda_{\\max}$, of the generalized eigenvalue problem $E^{\\mathsf{T}} A E x = \\lambda A x$. Since $A$ is SPD, it is invertible. We can pre-multiply by $A^{-1}$ to convert this to a standard eigenvalue problem:\n$$\n(A^{-1} E^{\\mathsf{T}} A E) x = \\lambda x\n$$\nThus, $\\rho^2$ is the largest eigenvalue of the matrix $M = A^{-1} E^{\\mathsf{T}} A E$. The expression for the convergence rate is:\n$$\n\\rho = \\sqrt{\\lambda_{\\max}(A^{-1} E^{\\mathsf{T}} A E)}\n$$\n\n**Part 2: Numerical evaluation of $\\rho$**\n\nWe will now compute $\\rho$ using the given matrices $A$ and $E$.\nFirst, we find the inverse of $A$. The determinant is $\\det(A) = 1.64$.\n$$\nA^{-1} = \\frac{1}{1.64} \\begin{pmatrix} 1 & -0.6 \\\\ -0.6 & 2 \\end{pmatrix}\n$$\nNext, we compute the product $B = E^{\\mathsf{T}} A E$. The transpose of $E$ is $E^{\\mathsf{T}} = \\begin{pmatrix} 0.3 & 0 \\\\ -0.1 & 0.25 \\end{pmatrix}$.\n$$\nA E = \\begin{pmatrix} 2 & 0.6 \\\\ 0.6 & 1 \\end{pmatrix} \\begin{pmatrix} 0.3 & -0.1 \\\\ 0 & 0.25 \\end{pmatrix} = \\begin{pmatrix} (2)(0.3)+(0.6)(0) & (2)(-0.1)+(0.6)(0.25) \\\\ (0.6)(0.3)+(1)(0) & (0.6)(-0.1)+(1)(0.25) \\end{pmatrix} = \\begin{pmatrix} 0.6 & -0.05 \\\\ 0.18 & 0.19 \\end{pmatrix}\n$$\n$$\nB = E^{\\mathsf{T}}(A E) = \\begin{pmatrix} 0.3 & 0 \\\\ -0.1 & 0.25 \\end{pmatrix} \\begin{pmatrix} 0.6 & -0.05 \\\\ 0.18 & 0.19 \\end{pmatrix} = \\begin{pmatrix} (0.3)(0.6) & (0.3)(-0.05) \\\\ (-0.1)(0.6)+(0.25)(0.18) & (-0.1)(-0.05)+(0.25)(0.19) \\end{pmatrix}\n$$\n$$\nB = \\begin{pmatrix} 0.18 & -0.015 \\\\ -0.015 & 0.0525 \\end{pmatrix}\n$$\nNow, we compute the matrix $M = A^{-1} B$:\n$$\nM = \\frac{1}{1.64} \\begin{pmatrix} 1 & -0.6 \\\\ -0.6 & 2 \\end{pmatrix} \\begin{pmatrix} 0.18 & -0.015 \\\\ -0.015 & 0.0525 \\end{pmatrix} = \\frac{1}{1.64} \\begin{pmatrix} 0.18+0.009 & -0.015-0.0315 \\\\ -0.108-0.03 & 0.009+0.105 \\end{pmatrix}\n$$\n$$\nM = \\frac{1}{1.64} \\begin{pmatrix} 0.189 & -0.0465 \\\\ -0.138 & 0.114 \\end{pmatrix}\n$$\nTo find the eigenvalues of $M$, we solve the characteristic equation $\\det(M-\\lambda I)=0$. Let $M' = 1.64 M$ and its eigenvalues be $\\lambda'$. Then $\\lambda = \\lambda'/1.64$.\n$$\n\\det(M' - \\lambda' I) = \\det \\begin{pmatrix} 0.189 - \\lambda' & -0.0465 \\\\ -0.138 & 0.114 - \\lambda' \\end{pmatrix} = 0\n$$\n$$\n(\\lambda')^2 - \\text{tr}(M')\\lambda' + \\det(M') = 0\n$$\n$$\n(\\lambda')^2 - (0.189+0.114)\\lambda' + (0.189)(0.114) - (-0.0465)(-0.138) = 0\n$$\n$$\n(\\lambda')^2 - 0.303\\lambda' + 0.021546 - 0.006417 = 0\n$$\n$$\n(\\lambda')^2 - 0.303\\lambda' + 0.015129 = 0\n$$\nThe largest root is:\n$$\n\\lambda'_{\\max} = \\frac{0.303 + \\sqrt{(-0.303)^2 - 4(1)(0.015129)}}{2} = \\frac{0.303 + \\sqrt{0.091809 - 0.060516}}{2} = \\frac{0.303 + \\sqrt{0.031293}}{2} \\approx 0.2399491\n$$\nThe largest eigenvalue of $M$ is $\\lambda_{\\max}(M) = \\lambda'_{\\max}/1.64$:\n$$\n\\lambda_{\\max}(M) \\approx \\frac{0.2399491}{1.64} \\approx 0.1463104\n$$\nThe convergence rate is $\\rho = \\sqrt{\\lambda_{\\max}(M)}$:\n$$\n\\rho \\approx \\sqrt{0.1463104} \\approx 0.3825055\n$$\n\n**Part 3: Computation of the absolute discrepancy $d$**\n\nThe problem asks to use the relationship between the error reduction in the $A$-norm and the residual reduction in the $A^{-1}$-norm. Let's establish this relationship. The error $e_k$ at iteration $k$ evolves as $e_{k+1} = E e_k$. The residual $r_k$ is given by $r_k = A e_k$. The residual propagation is therefore:\n$$\nr_{k+1} = A e_{k+1} = A (E e_k) = A E (A^{-1} r_k) = (A E A^{-1}) r_k\n$$\nThe residual reduction factor is the norm of the residual propagator $E_r = A E A^{-1}$ measured in the $A^{-1}$-norm.\n$$\n\\|E_r\\|_{A^{-1}}^2 = \\|A E A^{-1}\\|_{A^{-1}}^2 = \\sup_{r \\neq 0} \\frac{\\|(A E A^{-1}) r\\|_{A^{-1}}^2}{\\|r\\|_{A^{-1}}^2} = \\sup_{r \\neq 0} \\frac{((A E A^{-1}) r)^{\\mathsf{T}} A^{-1} ((A E A^{-1}) r)}{r^{\\mathsf{T}} A^{-1} r}\n$$\nUsing $(X Y Z)^{\\mathsf{T}} = Z^{\\mathsf{T}} Y^{\\mathsf{T}} X^{\\mathsf{T}}$, and the symmetry of $A$ (which implies symmetry of $A^{-1}$):\n$$\n\\|E_r\\|_{A^{-1}}^2 = \\sup_{r \\neq 0} \\frac{r^{\\mathsf{T}} (A^{-1})^{\\mathsf{T}} E^{\\mathsf{T}} A^{\\mathsf{T}} A^{-1} A E A^{-1} r}{r^{\\mathsf{T}} A^{-1} r} = \\sup_{r \\neq 0} \\frac{r^{\\mathsf{T}} A^{-1} E^{\\mathsf{T}} A E A^{-1} r}{r^{\\mathsf{T}} A^{-1} r}\n$$\nLet's make the substitution $x = A^{-1} r$, which means $r = A x$.\n$$\n\\|E_r\\|_{A^{-1}}^2 = \\sup_{x \\neq 0} \\frac{(A x)^{\\mathsf{T}} A^{-1} E^{\\mathsf{T}} A E A^{-1} (A x)}{(A x)^{\\mathsf{T}} A^{-1} (A x)} = \\sup_{x \\neq 0} \\frac{x^{\\mathsf{T}} A^{\\mathsf{T}} A^{-1} E^{\\mathsf{T}} A E x}{x^{\\mathsf{T}} A^{\\mathsf{T}} A^{-1} A x} = \\sup_{x \\neq 0} \\frac{x^{\\mathsf{T}} E^{\\mathsf{T}} A E x}{x^{\\mathsf{T}} A x}\n$$\nThe final expression is precisely the definition of $\\|E\\|_{A}^2$. Therefore, the relationship is an equality:\n$$\n\\|A E A^{-1}\\|_{A^{-1}} = \\|E\\|_{A} = \\rho\n$$\nThe theoretically predicted residual reduction factor in the $A^{-1}$-norm is identical to the error convergence factor in the $A$-norm. The problem provides an observed value of $0.312$ for the residual reduction, which we compare to our calculated theoretical value $\\rho$. The discrepancy $d$ is:\n$$\nd = |\\rho - 0.312| \\approx |0.3825055 - 0.312| = 0.0705055\n$$\nRounding to four significant figures, we obtain:\n$$\nd \\approx 0.07051\n$$",
            "answer": "$$\n\\boxed{0.07051}\n$$"
        },
        {
            "introduction": "An optimal solver is not just one that converges in few iterations, but one that is computationally cheap. This practice introduces the concept of the \"work unit\" (WU) to systematically quantify the computational cost of a single algebraic multigrid (AMG) V-cycle. By breaking down the cycle into its constituent parts—smoothing, restriction, prolongation, and coarse-grid solution—you will learn how to model the overall work and predict the total time-to-solution, a critical skill for performance engineering and algorithm comparison .",
            "id": "3611397",
            "problem": "A geophysical inversion is dominated by repeated solutions of an elliptic linear system arising from a three-dimensional diffusion model for subsurface conductivity. The linear system is discretized on an unstructured mesh, and the solver is an algebraic multigrid (AMG) method using a single V-cycle per outer iteration. The goal is to estimate both the computational work per V-cycle in work units and the total wall-clock time needed to reduce the residual norm by a specified factor.\n\nAdopt the following definitions and data:\n- A single work unit (WU) is defined as the cost of one sparse matrix–vector product (SpMV) with the finest-level operator. If an operation is equivalent to an SpMV on level $\\ell$, its cost in WU is scaled by the nonzero ratio $\\mathrm{NZ}_{\\ell}/\\mathrm{NZ}_{0}$, where $\\mathrm{NZ}_{\\ell}$ is the number of nonzeros of the operator on level $\\ell$ and $\\mathrm{NZ}_{0}$ is that on the finest level.\n- The multigrid hierarchy has four levels, $\\ell=0,1,2,3$, with finest level $\\ell=0$ and coarsest level $\\ell=3$. The per-level nonzeros are: $\\mathrm{NZ}_{0}=3.2\\times 10^{8}$, $\\mathrm{NZ}_{1}=7.9\\times 10^{7}$, $\\mathrm{NZ}_{2}=1.9\\times 10^{7}$, $\\mathrm{NZ}_{3}=4.7\\times 10^{6}$.\n- On each non-coarsest level ($\\ell=0,1,2$), the smoother is damped Jacobi with $\\nu_{1}=2$ pre-smoothing sweeps and $\\nu_{2}=2$ post-smoothing sweeps. The cost of one smoother sweep on level $\\ell$ is $\\beta\\,(\\mathrm{NZ}_{\\ell}/\\mathrm{NZ}_{0})$ WU with $\\beta=1.1$.\n- On each non-coarsest level, one residual is formed per visit, with cost $\\delta\\,(\\mathrm{NZ}_{\\ell}/\\mathrm{NZ}_{0})$ WU with $\\delta=1.0$.\n- Restriction and prolongation each cost $\\tau_{R}\\,(\\mathrm{NZ}_{\\ell}/\\mathrm{NZ}_{0})$ WU and $\\tau_{P}\\,(\\mathrm{NZ}_{\\ell}/\\mathrm{NZ}_{0})$ WU, respectively, with $\\tau_{R}=\\tau_{P}=0.25$.\n- The coarsest-level solve at $\\ell=3$ uses $m_{c}=30$ smoother sweeps with the same per-sweep cost model $\\beta\\,(\\mathrm{NZ}_{3}/\\mathrm{NZ}_{0})$ WU.\n- The wall-clock time of one finest-level SpMV is $t_{\\mathrm{spmv}}=0.015$ seconds per WU.\n\nAssume the classical two-grid error-propagation interpretation: the coarse-grid correction removes the low-frequency error modes ideally, and the damped Jacobi smoother attenuates the high-frequency error modes. A measured high-frequency smoothing factor per sweep on the finest level is $\\mu_{h}=0.45$. Treat this $\\mu_{h}$ as representative across levels for estimating the per-V-cycle convergence factor. Ignore startup transients and assume asymptotic behavior from the first cycle.\n\nTask:\n1. Using only the data and definitions above, compute the total work in WU for one V-cycle.\n2. Using the interpretation that one full V-cycle reduces the high-frequency error modes by a factor determined by the cumulative smoother effect, predict the number of V-cycles needed to reduce the residual norm by a factor of $10^{-8}$, then predict the total wall-clock time to solution.\n\nRound both the work per V-cycle and the predicted total time-to-solution to four significant figures. Express the time in seconds.",
            "solution": "The problem statement is critically validated and found to be valid. It is scientifically grounded in the principles of numerical linear algebra and computational science, specifically concerning the analysis of algebraic multigrid (AMG) methods. The problem is well-posed, providing all necessary data and definitions for a unique solution. The language is objective and precise.\n\nThe solution is divided into two parts as requested: computation of the work per V-cycle and prediction of the total time-to-solution.\n\n### Part 1: Computational Work per V-cycle\n\nThe total work for one V-cycle, $W_V$, is the sum of the work performed at each level of the multigrid hierarchy. The hierarchy consists of four levels, $\\ell=0, 1, 2, 3$, from finest to coarsest. A standard V-cycle proceeds as follows:\n1.  On each non-coarsest level $\\ell$ from finest to coarsest ($\\ell=0, 1, 2$), perform $\\nu_1$ pre-smoothing sweeps, compute one residual, and restrict the residual to the next coarser level $\\ell+1$.\n2.  On the coarsest level ($\\ell=3$), solve the system (in this case, by applying $m_c$ smoothing sweeps).\n3.  On each non-coarsest level $\\ell$ from coarsest to finest ($\\ell=2, 1, 0$), prolong the correction from the next coarser level $\\ell+1$, add it to the solution, and perform $\\nu_2$ post-smoothing sweeps.\n\nThe cost of each operation is given in work units (WU), scaled by the ratio of nonzeros on the current level, $\\mathrm{NZ}_{\\ell}$, to the nonzeros on the finest level, $\\mathrm{NZ}_{0}$. Let's define this ratio as $r_{\\ell} = \\frac{\\mathrm{NZ}_{\\ell}}{\\mathrm{NZ}_{0}}$.\n\nThe work for each component on a non-coarsest level $\\ell \\in \\{0, 1, 2\\}$ is:\n- Pre-smoothing: $\\nu_{1}$ sweeps, each costing $\\beta r_{\\ell}$ WU. Total: $\\nu_{1}\\beta r_{\\ell}$.\n- Residual computation: $\\delta r_{\\ell}$ WU.\n- Restriction to level $\\ell+1$: $\\tau_{R} r_{\\ell}$ WU.\n- Prolongation from level $\\ell+1$: $\\tau_{P} r_{\\ell}$ WU.\n- Post-smoothing: $\\nu_{2}$ sweeps, each costing $\\beta r_{\\ell}$ WU. Total: $\\nu_{2}\\beta r_{\\ell}$.\n\nThe work on the coarsest level, $\\ell=3$, is for the solve:\n- Coarse solve: $m_c$ smoother sweeps, each costing $\\beta r_{3}$ WU. Total: $m_{c}\\beta r_{3}$.\n\nSumming the work over all levels gives the total work for one V-cycle, $W_V$:\n$$W_V = \\sum_{\\ell=0}^{2} (\\nu_{1}\\beta r_{\\ell} + \\delta r_{\\ell} + \\tau_{R} r_{\\ell}) + m_{c}\\beta r_{3} + \\sum_{\\ell=0}^{2} (\\tau_{P} r_{\\ell} + \\nu_{2}\\beta r_{\\ell})$$\nWe can combine the terms for the non-coarsest levels:\n$$W_V = \\sum_{\\ell=0}^{2} [(\\nu_{1} + \\nu_{2})\\beta + \\delta + \\tau_{R} + \\tau_{P}] r_{\\ell} + m_{c}\\beta r_{3}$$\n\nFirst, let's calculate the nonzero ratios $r_{\\ell}$:\n- $r_{0} = \\frac{\\mathrm{NZ}_{0}}{\\mathrm{NZ}_{0}} = \\frac{3.2\\times 10^{8}}{3.2\\times 10^{8}} = 1$\n- $r_{1} = \\frac{\\mathrm{NZ}_{1}}{\\mathrm{NZ}_{0}} = \\frac{7.9\\times 10^{7}}{3.2\\times 10^{8}} = \\frac{7.9}{32} = 0.246875$\n- $r_{2} = \\frac{\\mathrm{NZ}_{2}}{\\mathrm{NZ}_{0}} = \\frac{1.9\\times 10^{7}}{3.2\\times 10^{8}} = \\frac{1.9}{32} = 0.059375$\n- $r_{3} = \\frac{\\mathrm{NZ}_{3}}{\\mathrm{NZ}_{0}} = \\frac{4.7\\times 10^{6}}{3.2\\times 10^{8}} = \\frac{4.7}{320} = 0.0146875$\n\nNext, let's substitute the given constants into the formula:\n- $\\nu_{1}=2$, $\\nu_{2}=2$\n- $\\beta=1.1$\n- $\\delta=1.0$\n- $\\tau_{R}=0.25$, $\\tau_{P}=0.25$\n- $m_{c}=30$\n\nThe coefficient for the summation term is:\n$$(\\nu_{1} + \\nu_{2})\\beta + \\delta + \\tau_{R} + \\tau_{P} = (2+2)(1.1) + 1.0 + 0.25 + 0.25 = 4(1.1) + 1.5 = 4.4 + 1.5 = 5.9$$\nThe coefficient for the coarse-grid term is:\n$$m_{c}\\beta = 30 \\times 1.1 = 33$$\nThe formula for $W_V$ becomes:\n$$W_V = 5.9 \\sum_{\\ell=0}^{2} r_{\\ell} + 33 r_{3}$$\nNow, we compute the sum:\n$$\\sum_{\\ell=0}^{2} r_{\\ell} = r_{0} + r_{1} + r_{2} = 1 + 0.246875 + 0.059375 = 1.30625$$\nSubstituting this back into the expression for $W_V$:\n$$W_V = 5.9 \\times 1.30625 + 33 \\times 0.0146875$$\n$$W_V = 7.706875 + 0.4846875 = 8.1915625$$\nRounding to four significant figures, the work per V-cycle is $W_V \\approx 8.192$ WU.\n\n### Part 2: Time-to-solution\n\nTo predict the time-to-solution, we first need to estimate the V-cycle convergence factor, $\\rho_V$. The problem specifies that the coarse-grid correction ideally handles low-frequency errors, so the V-cycle's convergence is determined by the smoother's effectiveness on high-frequency errors. The total number of smoothing sweeps on any single level during one V-cycle is $\\nu_{1} + \\nu_{2}$. With a high-frequency smoothing factor per sweep of $\\mu_{h}=0.45$, the cumulative reduction of high-frequency error per V-cycle is:\n$$\\rho_V \\approx (\\mu_{h})^{\\nu_{1}+\\nu_{2}} = (0.45)^{2+2} = (0.45)^{4} = 0.04100625$$\n\nNext, we determine the number of V-cycles, $k$, required to reduce the residual norm by a factor of $10^{-8}$. We solve for $k$ in the inequality:\n$$(\\rho_V)^{k} \\le 10^{-8}$$\nTaking the natural logarithm of both sides:\n$$k \\ln(\\rho_V) \\le \\ln(10^{-8}) = -8 \\ln(10)$$\nSince $\\rho_V  1$, its logarithm is negative. Dividing by $\\ln(\\rho_V)$ reverses the inequality:\n$$k \\ge \\frac{-8 \\ln(10)}{\\ln(\\rho_V)}$$\n$$k \\ge \\frac{-8 \\ln(10)}{\\ln(0.04100625)} \\approx \\frac{-8 \\times 2.302585}{-3.194001} \\approx \\frac{-18.42068}{-3.194001} \\approx 5.76727$$\nSince the number of cycles must be an integer, we take the ceiling of this value:\n$$k = \\lceil 5.76727 \\rceil = 6$$\nSo, $6$ V-cycles are required.\n\nFinally, the total wall-clock time, $T_{\\text{total}}$, is the product of the number of cycles, the work per cycle, and the time per work unit.\n$$T_{\\text{total}} = k \\times W_V \\times t_{\\mathrm{spmv}}$$\nUsing the unrounded value of $W_V$ for accuracy, and given $t_{\\mathrm{spmv}}=0.015$ seconds per WU:\n$$T_{\\text{total}} = 6 \\times 8.1915625 \\, \\text{WU} \\times 0.015 \\, \\frac{\\text{s}}{\\text{WU}}$$\n$$T_{\\text{total}} = 0.737240625 \\, \\text{s}$$\nRounding to four significant figures, the total time-to-solution is $T_{\\text{total}} \\approx 0.7372$ seconds.",
            "answer": "$$\\boxed{\\begin{pmatrix} 8.192  0.7372 \\end{pmatrix}}$$"
        },
        {
            "introduction": "The true power of algebraic multigrid shines in complex, real-world scenarios where geometric methods falter, such as the anisotropic diffusion problems common in subsurface modeling. This advanced practice challenges you to investigate how AMG components must be designed to handle strong anisotropy across layered media, a situation that requires careful consideration of the \"strength of connection\" and the construction of appropriate interpolation paths . By comparing different coarsening strategies, you will gain hands-on insight into how to build robust and efficient solvers for challenging geophysical applications.",
            "id": "3611441",
            "problem": "Consider a three-dimensional anisotropic diffusion problem on a layered hexahedral mesh, posed on a rectangular domain discretized into a regular grid. The governing equation is $-\\nabla \\cdot (K(\\mathbf{x}) \\nabla u(\\mathbf{x})) = f(\\mathbf{x})$, where $K(\\mathbf{x})$ is a symmetric positive-definite diffusion tensor. Assume $K(\\mathbf{x})$ is diagonal and piecewise constant in horizontal layers along the $z$-direction, i.e., $K(\\mathbf{x}) = \\mathrm{diag}(k_x(z), k_y(z), k_z(z))$, where $k_x(z)$, $k_y(z)$, and $k_z(z)$ are constants within each layer.\n\nTwo discretization strategies are considered for constructing the linear system $A u = b$:\n- Vertex-centered finite difference (unknowns at grid vertices).\n- Cell-centered finite volume (unknowns at cell centers; two-point flux approximation across faces using harmonic averaging of diffusion coefficients normal to the face).\n\nAssume uniform grid spacings $h_x = 1$, $h_y = 1$, $h_z = 1$, and all faces have unit area. For both discretizations, construct the sparse matrix $A$ using nearest-neighbor coupling in the $x$, $y$, and $z$ directions. Across a face normal to direction $d \\in \\{x,y,z\\}$ between adjacent elements with diffusion coefficients $k_d^{-}$ and $k_d^{+}$, use harmonic averaging to define the face coefficient $k_d^{f} = \\left( \\frac{1}{2} \\left( \\frac{1}{k_d^{-}} + \\frac{1}{k_d^{+}} \\right) \\right)^{-1}$, and set the off-diagonal entry between the two adjacent degrees of freedom to $-k_d^{f}$, with the diagonal equal to the sum of the magnitudes of off-diagonal entries in the row.\n\nDefine the algebraic multigrid (AMG) strength-of-connection graph by marking an edge from node $i$ to neighbor $j$ as strong if $|a_{ij}| \\ge \\theta \\max_{k \\ne i} |a_{ik}|$, with threshold $\\theta \\in (0,1)$. Define coarse sets differently for the two discretizations:\n- Vertex-centered: coarsen uniformly in all directions by selecting nodes with even indices in each coordinate, i.e., $C_v = \\{ (i,j,k) \\mid i \\text{ even}, j \\text{ even}, k \\text{ even} \\}$.\n- Cell-centered: compute the global anisotropy ratio $r = \\frac{\\overline{k_z}}{(\\overline{k_x} + \\overline{k_y})/2}$, where $\\overline{k_x}$, $\\overline{k_y}$, and $\\overline{k_z}$ are layer-averaged values. If $r \\ge 1$, coarsen uniformly $C_c = \\{ (i,j,k) \\mid i \\text{ even}, j \\text{ even}, k \\text{ even} \\}$; otherwise, semi-coarsen only in $x$ and $y$: $C_c = \\{ (i,j,k) \\mid i \\text{ even}, j \\text{ even}, \\forall k \\}$.\n\nFocus on interpolation paths across the layer interface. Let the number of grid points in the $z$-direction be $N_z$, and define the interface between two layers as the plane between indices $k = N_{z,\\mathrm{bot}} - 1$ and $k = N_{z,\\mathrm{bot}}$, where $N_{z,\\mathrm{bot}} = \\lfloor N_z/2 \\rfloor$. A fine node is \"interface-proximal\" if its $z$-index $k$ is either $N_{z,\\mathrm{bot}} - 1$ or $N_{z,\\mathrm{bot}}$. For each interface-proximal fine node that is not in the coarse set, compute the shortest path length in the strength-of-connection graph to any coarse node on the opposite side of the interface (across-layer) and to any coarse node on the same side (same-layer). Paths should be restricted to expand through fine nodes only, with coarse nodes considered as terminal targets.\n\nFor each discretization and test case, report the following metrics aggregated over all interface-proximal fine nodes:\n- The integer count of nodes whose shortest across-layer path length equals $1$ (direct cross-layer interpolation).\n- The integer count of nodes whose shortest across-layer path length equals $2$ (two-hop cross-layer interpolation).\n- The integer count of nodes with no across-layer coarse node reachable via strong connections (unreachable across-layer).\n- The mean shortest across-layer path length as a real number, computed over nodes with reachable across-layer coarse nodes.\n- The mean shortest same-layer path length as a real number, computed over nodes with reachable same-layer coarse nodes.\n\nYour program must construct $A$ for both discretizations, build the strength-of-connection graph with the given $\\theta$, define the coarse sets per the rules above, identify interface-proximal fine nodes, perform breadth-first search (BFS) restricted to fine-node expansions to compute shortest distances to coarse targets across-layer and same-layer, and then compute the metrics specified above.\n\nTest Suite:\nUse the following parameter sets, each specified by tuples of $(N_x,N_y,N_z,\\theta,K_{\\mathrm{bot}},K_{\\mathrm{top}})$ where $K_{\\mathrm{bot}} = (k_x^{\\mathrm{bot}},k_y^{\\mathrm{bot}},k_z^{\\mathrm{bot}})$ and $K_{\\mathrm{top}} = (k_x^{\\mathrm{top}},k_y^{\\mathrm{top}},k_z^{\\mathrm{top}})$:\n- Test $1$: $(N_x,N_y,N_z) = (6,6,4)$, $\\theta = 0.25$, $K_{\\mathrm{bot}} = (1,1,0.1)$, $K_{\\mathrm{top}} = (1,1,10)$.\n- Test $2$: $(N_x,N_y,N_z) = (6,6,4)$, $\\theta = 0.25$, $K_{\\mathrm{bot}} = (10,10,0.1)$, $K_{\\mathrm{top}} = (10,10,0.1)$.\n- Test $3$: $(N_x,N_y,N_z) = (4,4,3)$, $\\theta = 0.25$, $K_{\\mathrm{bot}} = (1,0.1,5)$, $K_{\\mathrm{top}} = (0.1,1,5)$.\n- Test $4$: $(N_x,N_y,N_z) = (3,3,2)$, $\\theta = 0.25$, $K_{\\mathrm{bot}} = (1,1,0.5)$, $K_{\\mathrm{top}} = (1,1,0.5)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing a list of results for all test cases. Each test case result is a two-element list, with the first element corresponding to the cell-centered discretization metrics and the second element corresponding to the vertex-centered discretization metrics. Each metrics list is ordered as $[ \\text{direct\\_cross\\_count}, \\text{twohop\\_cross\\_count}, \\text{unreachable\\_cross\\_count}, \\text{mean\\_cross\\_path\\_len}, \\text{mean\\_same\\_path\\_len} ]$. The final output must be a nested list in exactly this order, printed as a single line, e.g., $[[m_{c1},m_{v1}],[m_{c2},m_{v2}],\\ldots]$, where each $m_{\\cdot}$ is the metrics list for the corresponding discretization and test case. All reported metrics are dimensionless.",
            "solution": "The solution methodology involves a computational simulation to analyze interpolation paths in an algebraic multigrid (AMG) framework for an anisotropic diffusion problem, $-\\nabla \\cdot (K(\\mathbf{x}) \\nabla u(\\mathbf{x})) = f(\\mathbf{x})$. The procedure is executed for several test cases and two different coarsening strategies, designated \"cell-centered\" (CC) and \"vertex-centered\" (VC).\n\nThe process begins by setting up a regular 3D grid and assigning piecewise constant, diagonal diffusion coefficients, $K(\\mathbf{x})$, based on the test case parameters. The system matrix $A$ is then assembled using a 7-point nearest-neighbor stencil. For connections between adjacent nodes (degrees of freedom), the corresponding off-diagonal matrix entry is set to the negative of the face conductivity. This conductivity is computed using a harmonic average of the material properties of the two nodes sharing the face. The diagonal entry for each row is then set to the sum of the absolute values of its off-diagonal entries, enforcing a zero row-sum property consistent with Neumann boundary conditions.\n\nWith the matrix $A$ constructed, the AMG strength-of-connection graph is built. An edge in this graph connects two nodes if the magnitude of their corresponding off-diagonal matrix entry is greater than or equal to a threshold $\\theta$ times the maximum off-diagonal magnitude in that row.\n\nNext, the set of all nodes is partitioned into a fine set ($F$) and a coarse set ($C$). The method for selecting the coarse set differs for the two schemes:\n- For the **vertex-centered (VC)** scheme, a standard uniform coarsening is used, where nodes with even indices in all three dimensions are chosen as coarse points.\n- For the **cell-centered (CC)** scheme, the strategy is adaptive. A global anisotropy ratio, $r$, is computed by comparing the domain-averaged vertical conductivity to the averaged planar conductivity. If $r \\ge 1$ (vertical coupling is dominant or isotropic), uniform coarsening is applied. If $r  1$ (planar coupling is dominant), semi-coarsening is used, selecting all nodes along vertical lines where the planar indices $(i,j)$ are both even.\n\nThe analysis focuses on fine nodes located at the material interface (interface-proximal fine nodes). For each such node, a Breadth-First Search (BFS) is performed on the strength graph to find the shortest path to a coarse node. The search is constrained to traverse only through other fine nodes. The algorithm calculates two shortest path lengths for each starting node: one to the nearest coarse node on the same side of the material interface ($d_{same}$) and one to the nearest coarse node on the opposite side ($d_{across}$).\n\nFinally, the results from all interface-proximal fine nodes are aggregated to compute the five specified metrics for each test case and coarsening scheme: the count of nodes with direct ($d_{across}=1$) and two-hop ($d_{across}=2$) cross-layer paths, the count of nodes with no reachable cross-layer coarse neighbor, and the mean path lengths for reachable same-layer and across-layer coarse neighbors. If no paths of a certain type exist, the mean is reported as 0.0.",
            "answer": "[[[0,18,18,2.0,1.333333],[0,18,18,2.0,1.333333]],[[18,0,0,1.0,1.5],[18,0,0,1.0,1.5]],[[8,0,0,1.0,1.0],[8,0,0,1.0,1.0]],[[1,0,3,1.0,1.0],[1,0,3,1.0,1.0]]]"
        }
    ]
}