{
    "hands_on_practices": [
        {
            "introduction": "The power of Fourier spectral methods is most evident in their elegant approach to differentiation. This exercise provides a foundational hands-on experience with spectral differentiation, a cornerstone technique for solving differential equations. You will verify the principle that a derivative in physical space, $\\frac{d}{dx}$, transforms into a simple multiplication by the imaginary wavenumber, $ik$, in Fourier space, and implement this using the Fast Fourier Transform (FFT). By comparing your numerical result to the exact derivative, you will witness the hallmark of spectral methods: the error decreases exponentially as the grid resolution increases, a property known as spectral accuracy .",
            "id": "3614982",
            "problem": "You are asked to formulate, implement, and validate a spectral differentiation procedure for a periodic function within the context of computational geophysics. Consider the function $f(x) = \\sin(3x) + 0.1\\cos(9x)$ defined on the interval $[0, 2\\pi]$, interpreted with $x$ measured in radians. The objective is to compute the numerical derivative of $f(x)$ using a spectral method based on Fourier series and to quantify the numerical error as the number of grid points $N$ varies, using double-precision arithmetic.\n\nBegin from the fundamental definition of the Fourier series of a $2\\pi$-periodic function and the relationship between spatial differentiation and its counterpart in the frequency domain derived from that definition. Your implementation must use the discrete formulation consistent with equally spaced samples on $[0, 2\\pi]$ and must rely on the Discrete Fourier Transform (DFT) evaluated via the Fast Fourier Transform (FFT). You must ensure that the procedure respects the periodic boundary conditions and is coherent with the Fourier series interpretation of a periodic grid.\n\nFor each chosen $N$, sample the function $f(x)$ at $N$ equally spaced points on $[0, 2\\pi)$, apply spectral differentiation as implied by the Fourier series framework, and compare the computed derivative to the exact derivative of $f(x)$ evaluated on the same grid. The exact derivative is to be evaluated analytically from first principles. Quantify the error using both the normalized $L^2$ error and the $L^\\infty$ error at the grid points. The normalized $L^2$ error must be defined as $\\sqrt{\\frac{1}{N}\\sum_{j=0}^{N-1} \\left(e_j\\right)^2}$, where $e_j$ is the pointwise error at the $j$-th grid point; the $L^\\infty$ error must be defined as $\\max_{0 \\leq j \\leq N-1} |e_j|$. Both errors are dimensionless.\n\nWork strictly in double precision, treating real and complex quantities accordingly. The angle unit must be radians throughout. Your program must implement the algorithm and produce a single line of output summarizing the results for a fixed test suite of $N$ values chosen to probe different numerical regimes, including under-resolved cases, boundary cases at the highest resolved frequency, and well-resolved cases.\n\nUse the following test suite for $N$: $N \\in \\{8, 16, 18, 32, 64, 128\\}$. For each $N$ in this set, compute and report a triple $[N, E_2, E_\\infty]$, where $E_2$ is the normalized $L^2$ error and $E_\\infty$ is the $L^\\infty$ error. Your program should produce a single line of output containing the list of these triples as a comma-separated list enclosed in square brackets, for example, $[[8, E_2, E_\\infty], [16, E_2, E_\\infty], \\dots]$, with numeric values in standard decimal notation. No physical units are involved because the quantities are dimensionless, and angles are in radians by construction.",
            "solution": "The target in spectral differentiation is to exploit the structure of periodic functions under Fourier series. A $2\\pi$-periodic function $f(x)$ admits a Fourier series representation\n$$\nf(x) = \\sum_{k=-\\infty}^{\\infty} \\hat{f}_k e^{i k x},\n$$\nwhere $\\hat{f}_k$ are the Fourier coefficients. Differentiation in physical space translates to a simple algebraic operation in the frequency domain. Differentiating term-by-term yields\n$$\n\\frac{d f}{d x}(x) = \\sum_{k=-\\infty}^{\\infty} i k \\hat{f}_k e^{i k x}.\n$$\nTherefore, if one can compute $\\hat{f}_k$, the derivative is recovered by multiplying each coefficient by $i k$ and performing the inverse transform.\n\nOn a discrete grid, we sample at $N$ equally spaced points on $[0, 2\\pi)$,\n$$\nx_j = \\frac{2\\pi j}{N}, \\quad j = 0, 1, \\dots, N-1,\n$$\nand form samples $f_j = f(x_j)$. The Discrete Fourier Transform (DFT) relates the samples to discrete spectral coefficients. Using the convention implemented by the Fast Fourier Transform (FFT), the forward transform computes\n$$\nF_n = \\sum_{j=0}^{N-1} f_j e^{-2\\pi i j n / N}, \\quad n = 0, 1, \\dots, N-1,\n$$\nand the inverse transform reconstructs\n$$\nf_j = \\frac{1}{N} \\sum_{n=0}^{N-1} F_n e^{2\\pi i j n / N}.\n$$\nFor functions of the form $f(x) = \\sum_k \\hat{f}_k e^{i k x}$ sampled at $x_j = 2\\pi j/N$, the discrete coefficients $F_n$ align with the continuous-series coefficients up to normalization that is consistent with the above DFT definition. The discrete wave numbers $k$ are represented by integers mapped to indices via the array returned by the frequency function that encodes the ordering\n$$\nk \\in \\{0, 1, 2, \\dots, \\lfloor\\frac{N}{2}\\rfloor, -\\lceil\\frac{N}{2}\\rceil, \\dots, -2, -1\\}.\n$$\nWith this mapping, spectral differentiation proceeds as follows:\n1. Compute the DFT $F_n$ of the sampled function $f_j$.\n2. Form the integer wave-number array $k_n$ matching the DFT ordering.\n3. Compute the spectral derivative coefficients $G_n = i k_n F_n$.\n4. Apply the inverse DFT to $G_n$ to obtain the derivative samples at the grid points,\n$$\n\\left(\\frac{d f}{d x}\\right)_j = \\frac{1}{N} \\sum_{n=0}^{N-1} G_n e^{2\\pi i j n / N}.\n$$\nBecause the exact function is band-limited to modes $k=\\pm 3$ and $k=\\pm 9$, the spectral differentiation reproduces the derivative exactly when those modes are representable on the grid without aliasing. For even $N$ such that $N/2 \\geq 9$, the $k=\\pm 9$ modes are included; however, at $N=18$ the $k=9$ mode corresponds to the Nyquist frequency. On the grid $x_j = 2\\pi j / 18$, the term $-0.9\\sin(9x_j)$ vanishes identically since $\\sin(9 \\cdot 2\\pi j / 18) = \\sin(\\pi j) = 0$, which is consistent with the discrete representation: the derivative contribution from the Nyquist cosine mode produces zero samples in physical space on that grid.\n\nThe exact derivative is computed analytically by the elementary differentiation rules,\n$$\n\\frac{d f}{d x}(x) = 3\\cos(3x) - 0.9\\sin(9x).\n$$\nWe quantify the error by comparing the spectral derivative samples to the exact ones at the grid points. For each $N$, define the pointwise error $e_j = \\left(\\frac{d f}{d x}\\right)_{\\text{spectral}}(x_j) - \\left(\\frac{d f}{d x}\\right)_{\\text{exact}}(x_j)$. We report two measures:\n1. The normalized $L^2$ error,\n$$\nE_2 = \\sqrt{\\frac{1}{N}\\sum_{j=0}^{N-1} e_j^2},\n$$\nwhich is a discrete approximation to the $L^2$ norm per unit interval length.\n2. The $L^\\infty$ error,\n$$\nE_{\\infty} = \\max_{0 \\leq j \\leq N-1} |e_j|.\n$$\nThese errors are dimensionless because $f(x)$ and its derivative are dimensionless real-valued functions of a dimensionless angle variable $x$ in radians.\n\nAlgorithmically, the steps are:\n- For each $N$ in the test suite $\\{8, 16, 18, 32, 64, 128\\}$, construct the grid $x_j$ and samples $f_j$ in double precision.\n- Compute the DFT of $f_j$ using the Fast Fourier Transform (FFT).\n- Create integer wave numbers matching the FFT ordering using the frequency generator, scale to integer wavenumbers, and multiply the spectral coefficients by $i k$ to obtain the spectral derivative coefficients.\n- Invert the transform to obtain the derivative samples and take the real part to remove any residual imaginary numerical noise.\n- Construct the exact derivative samples and compute $E_2$ and $E_{\\infty}$.\n- Aggregate the results in the specified output format as $[N, E_2, E_{\\infty}]$ for each $N$.\n\nThis approach adheres to the fundamental Fourier series framework and directly connects the mathematical property of differentiation in Fourier space to an efficient computational realization via the Fast Fourier Transform. It avoids extraneous approximations and, for sufficiently large $N$, yields errors that approach the round-off level in double precision, illustrating spectral accuracy for smooth periodic functions.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef spectral_derivative_on_grid(N):\n    \"\"\"\n    Compute the spectral derivative of f(x) = sin(3x) + 0.1*cos(9x) on [0, 2*pi)\n    using N equispaced points, and return the normalized L2 and Linfty errors\n    versus the exact derivative at the grid points. All computations are\n    performed in double precision.\n    \"\"\"\n    # Double-precision grids and values\n    x = (2.0 * np.pi) * np.arange(N, dtype=np.float64) / np.float64(N)\n    f = np.sin(3.0 * x, dtype=np.float64) + 0.1 * np.cos(9.0 * x, dtype=np.float64)\n\n    # Exact derivative at grid points\n    exact_df = 3.0 * np.cos(3.0 * x, dtype=np.float64) - 0.9 * np.sin(9.0 * x, dtype=np.float64)\n\n    # Compute FFT of f\n    F = np.fft.fft(f.astype(np.float64))\n\n    # Integer wavenumbers consistent with numpy FFT ordering\n    # fftfreq returns frequencies in cycles per sample; multiplying by N gives integer k.\n    k = np.fft.fftfreq(N, d=1.0) * N  # array of ints in float dtype: [0,1,...,N/2-1,-N/2,...,-1]\n    k = k.astype(np.float64)\n\n    # Spectral derivative coefficients: G = i * k * F\n    G = (1j * k) * F\n\n    # Inverse FFT to get derivative samples in physical space\n    df_spec = np.fft.ifft(G)\n\n    # Due to numerical round-off, df_spec may have tiny imaginary parts; take real part\n    df_spec_real = np.real(df_spec).astype(np.float64)\n\n    # Compute errors\n    err = df_spec_real - exact_df\n    # Normalized L2 error: sqrt(mean(err^2))\n    E2 = float(np.sqrt(np.mean(err * err)))\n    # Linfty error: max absolute error\n    Einf = float(np.max(np.abs(err)))\n\n    return E2, Einf\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [8, 16, 18, 32, 64, 128]\n\n    results = []\n    for N in test_cases:\n        E2, Einf = spectral_derivative_on_grid(N)\n        results.append([int(N), E2, Einf])\n\n    # Final print statement in the exact required format.\n    # Single line output: list of triples [N, E2, Einf] as comma-separated list in brackets.\n    print(f\"[{','.join(str(item) for item in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While spectral methods excel at linear problems, real-world applications often involve nonlinearities, which appear as products of functions. Naively multiplying functions on a discrete grid can lead to a critical numerical artifact known as aliasing. This practice is designed to give you a concrete understanding of this phenomenon, which occurs when the product generates frequencies higher than the grid can resolve. By computing the integral of a product in two ways—an exact spectral-space method and a direct grid-based quadrature—you will directly measure the error introduced by aliasing and learn how to diagnose it .",
            "id": "3615024",
            "problem": "You are given a periodic domain and two real-valued functions represented by finite Fourier series. Your task is to compute the integral of the product of these functions using two distinct methods and quantify the aliasing-induced bias. The base is the definition of the Fourier series on a periodic domain, the definition of convolution in spectral space, and the quadrature of periodic functions on a uniform grid.\n\nConsider a one-dimensional periodic domain of length $2\\pi$ with spatial coordinate $x \\in [0,2\\pi)$ expressed in radians. Let $f(x)$ and $g(x)$ be real-valued functions with finite Fourier series written in the trigonometric basis,\n$$\nf(x) = a_0^{(f)} + \\sum_{k=1}^{K_f} \\left(a_k^{(f)}\\cos(kx) + b_k^{(f)}\\sin(kx)\\right), \\quad\ng(x) = a_0^{(g)} + \\sum_{k=1}^{K_g} \\left(a_k^{(g)}\\cos(kx) + b_k^{(g)}\\sin(kx)\\right).\n$$\nThe goal is to compute the integral of the product $h(x) = f(x)g(x)$ over $[0,2\\pi)$, denoted by\n$$\nI = \\int_{0}^{2\\pi} h(x)\\,dx,\n$$\nusing two methods:\n\n1. A spectral-space method based on the convolution of Fourier series that is dealiased. This computation must be derived from Fourier series principles and must return the correct integral without aliasing when the Fourier coefficients are known and finite.\n\n2. A direct quadrature method on a uniform grid of $N$ points using the trapezoidal rule (which equals the uniform average times the domain length for periodic functions sampled on an equispaced grid). This method will be susceptible to aliasing when the grid does not resolve the highest frequency content.\n\nYou should implement both methods and compute the bias as the difference between the direct quadrature integral and the dealiased spectral convolution integral,\n$$\n\\Delta I = I_{\\text{direct}} - I_{\\text{dealiased}}.\n$$\nYour program must carry out these computations for each test case in the suite below. Angles must be interpreted in radians. Output must be a list of floating-point numbers, one per test case, representing $\\Delta I$ for that case.\n\nTest Suite (each case specifies the grid size $N$, and the coefficients of $f$ and $g$):\n\n- Case 1 (well-resolved, general case): $N=64$,\n  $f(x) = 0 + 1.0\\cdot\\cos(5x) + 0.4\\cdot\\sin(7x)$,\n  $g(x) = 0 + 1.2\\cdot\\cos(5x) - 0.1\\cdot\\sin(7x)$.\n\n- Case 2 (Nyquist boundary condition): $N=32$,\n  $f(x) = 0 + 1.0\\cdot\\cos(16x)$,\n  $g(x) = 0 + 1.0\\cdot\\cos(16x)$.\n\n- Case 3 (significant aliasing-induced bias due to frequency collision under sampling): $N=32$,\n  $f(x) = 0 + 1.0\\cdot\\cos(18x)$,\n  $g(x) = 0 + 1.0\\cdot\\cos(14x)$.\n\n- Case 4 (multi-mode aliasing scenario): $N=24$,\n  $f(x) = 0 + 1.0\\cdot\\cos(17x) + 0.5\\cdot\\sin(5x)$,\n  $g(x) = 0 + 1.3\\cdot\\cos(7x) + 0.5\\cdot\\sin(17x)$.\n\n- Case 5 (well-resolved multi-mode case): $N=48$,\n  $f(x) = 0 + 0.8\\cdot\\cos(20x) - 0.5\\cdot\\sin(22x)$,\n  $g(x) = 0 + 0.8\\cdot\\cos(20x) - 0.5\\cdot\\sin(22x)$.\n\nRequired algorithmic details to implement:\n\n- For the dealiased spectral-space calculation, derive the expression for the zero-wavenumber (mean) mode of the convolution of the Fourier series of $f(x)$ and $g(x)$ and use it to compute $I_{\\text{dealiased}}$. You must proceed from the basic Fourier series definitions and convolution in spectral space, ensuring no aliasing influences the result when the series are finite.\n\n- For the direct quadrature calculation, sample the functions at $N$ equispaced points $x_n = \\frac{2\\pi n}{N}$ for $n = 0,1,\\dots,N-1$ and compute $I_{\\text{direct}}$ as the product average times $2\\pi$:\n$$\nI_{\\text{direct}} = \\left(\\frac{1}{N}\\sum_{n=0}^{N-1} f(x_n)g(x_n)\\right) \\cdot 2\\pi.\n$$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4,result5]\"). Each entry must be the floating-point value of $\\Delta I$ for the corresponding case. No physical units are required because the domain length is $2\\pi$ in radians, and the integrals are dimensionless in this setup.",
            "solution": "The problem requires the computation of the integral of a product of two functions, $h(x) = f(x)g(x)$, over a periodic domain $[0, 2\\pi)$. This integral, denoted by $I = \\int_{0}^{2\\pi} h(x)\\,dx$, is to be calculated using two different methods: a dealiased spectral-space method and a direct quadrature method on a uniform grid. The bias between these two methods, $\\Delta I = I_{\\text{direct}} - I_{\\text{dealiased}}$, is the quantity to be reported.\n\nThe validation of the problem statement confirms that it is scientifically grounded, well-posed, and objective. It is a standard problem in numerical analysis and spectral methods, with all necessary data and definitions provided.\n\nThe solution proceeds by first deriving the expressions for the integral based on the two specified methods.\n\n**Method 1: Dealiased Spectral-Space Integral ($I_{\\text{dealiased}}$)**\n\nThis method computes the exact integral of the product of two functions with finite Fourier series. The integral of a periodic function over its domain is directly proportional to its mean value, which corresponds to the zero-wavenumber ($k=0$) coefficient of its Fourier series.\n\nLet the Fourier series of $h(x)$ be expressed in complex form as $h(x) = \\sum_{k=-\\infty}^{\\infty} c_k^{(h)} e^{ikx}$. The coefficient for $k=0$ is given by $c_0^{(h)} = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} h(x) e^{-i(0)x} dx = \\frac{1}{2\\pi}I$. Therefore, the exact integral is $I = 2\\pi c_0^{(h)}$.\n\nThe functions $f(x)$ and $g(x)$ are given in a real trigonometric basis:\n$$\nf(x) = a_0^{(f)} + \\sum_{k=1}^{K_f} \\left(a_k^{(f)}\\cos(kx) + b_k^{(f)}\\sin(kx)\\right)\n$$\nand similarly for $g(x)$. The integral $I = \\int_{0}^{2\\pi} f(x)g(x) dx$ can be computed by substituting these series and using the orthogonality relations of trigonometric functions over the interval $[0, 2\\pi)$:\n$$\n\\int_{0}^{2\\pi}\\cos(kx)\\cos(jx)dx = \\pi\\delta_{kj} \\quad (k,j > 0)\n$$\n$$\n\\int_{0}^{2\\pi}\\sin(kx)\\sin(jx)dx = \\pi\\delta_{kj} \\quad (k,j > 0)\n$$\n$$\n\\int_{0}^{2\\pi}\\cos(kx)\\sin(jx)dx = 0\n$$\n$$\n\\int_{0}^{2\\pi}\\cos(kx)dx = 0, \\quad \\int_{0}^{2\\pi}\\sin(kx)dx = 0 \\quad (k > 0)\n$$\n$$\n\\int_{0}^{2\\pi} 1 \\cdot 1 \\, dx = 2\\pi\n$$\nWhen computing the integral of the product $f(x)g(x)$, the only terms that yield non-zero results are the product of the constant terms and products of trigonometric functions of the same type and same wavenumber. This leads to:\n$$\nI_{\\text{dealiased}} = \\int_{0}^{2\\pi} (a_0^{(f)})(a_0^{(g)}) dx + \\sum_{k=1}^{\\infty} \\int_{0}^{2\\pi} (a_k^{(f)}\\cos(kx))(a_k^{(g)}\\cos(kx)) dx + \\sum_{k=1}^{\\infty} \\int_{0}^{2\\pi} (b_k^{(f)}\\sin(kx))(b_k^{(g)}\\sin(kx)) dx\n$$\nUsing the orthogonality relations, this simplifies to:\n$$\nI_{\\text{dealiased}} = 2\\pi a_0^{(f)} a_0^{(g)} + \\sum_{k=1}^{\\infty} \\pi(a_k^{(f)} a_k^{(g)} + b_k^{(f)} b_k^{(g)})\n$$\nSince the input series are finite, this sum is also finite. This formula is exact and free of aliasing, hence it is the \"dealiased\" result.\n\n**Method 2: Direct Quadrature Integral ($I_{\\text{direct}}$)**\n\nThis method approximates the integral using the trapezoidal rule on a uniform grid of $N$ points, $x_n = \\frac{2\\pi n}{N}$ for $n = 0, 1, \\dots, N-1$. For periodic functions, this is equivalent to averaging the function values on the grid and multiplying by the domain length:\n$$\nI_{\\text{direct}} = \\frac{2\\pi}{N} \\sum_{n=0}^{N-1} h(x_n) = \\frac{2\\pi}{N} \\sum_{n=0}^{N-1} f(x_n)g(x_n)\n$$\nThis numerical quadrature is susceptible to aliasing. The product function $h(x)$ contains wavenumbers up to $K_f + K_g$. If this maximum wavenumber exceeds the Nyquist wavenumber of the grid, $k_{Nyquist} = N/2$, then higher-frequency components are misrepresented as lower-frequency components.\n\nThe discrete sum computed by the quadrature rule is exactly equal to the integral of the aliased function as seen by the grid. The aliasing relationship states that the discrete Fourier transform coefficients, $\\hat{h}_k$, of the sampled signal $h(x_n)$ are related to the continuous Fourier series coefficients, $c_k^{(h)}$, by the formula $\\hat{h}_k = N \\sum_{m=-\\infty}^{\\infty} c_{k+mN}^{(h)}$.\n\nThe direct integral is related to the $k=0$ component of the DFT: $I_{\\text{direct}} = \\frac{2\\pi}{N} \\hat{h}_0$. Substituting the aliasing formula for $\\hat{h}_0$:\n$$\nI_{\\text{direct}} = \\frac{2\\pi}{N} \\left( N \\sum_{m=-\\infty}^{\\infty} c_{mN}^{(h)} \\right) = 2\\pi \\sum_{m=-\\infty}^{\\infty} c_{mN}^{(h)}\n$$\n$$\nI_{\\text{direct}} = 2\\pi (c_0^{(h)} + c_N^{(h)} + c_{-N}^{(h)} + c_{2N}^{(h)} + c_{-2N}^{(h)} + \\dots)\n$$\n\n**Aliasing-Induced Bias ($\\Delta I$)**\n\nThe bias is the difference between the two computed integrals:\n$$\n\\Delta I = I_{\\text{direct}} - I_{\\text{dealiased}}\n$$\nSubstituting the expressions derived above:\n$$\n\\Delta I = \\left( 2\\pi \\sum_{m=-\\infty}^{\\infty} c_{mN}^{(h)} \\right) - (2\\pi c_0^{(h)}) = 2\\pi \\sum_{m \\neq 0} c_{mN}^{(h)}\n$$\nSince $h(x)$ is real, its Fourier coefficients satisfy $c_{-k}^{(h)} = (c_k^{(h)})^*$, so the bias can be written as:\n$$\n\\Delta I = 2\\pi \\sum_{m=1}^{\\infty} (c_{mN}^{(h)} + c_{-mN}^{(h)}) = 4\\pi \\sum_{m=1}^{\\infty} \\text{Re}(c_{mN}^{(h)})\n$$\nThis shows that a non-zero bias occurs if and only if the product function $h(x)$ has spectral power at wavenumbers that are non-zero multiples of the grid size $N$. These components alias directly to the zero-wavenumber (mean) component, thus corrupting the estimate of the integral. If the maximum wavenumber in $h(x)$ is less than $N$, then $c_{mN}^{(h)}=0$ for all $m \\geq 1$, resulting in zero bias.\n\nThe algorithm to solve the problem is as follows:\n1. For each test case, define the Fourier coefficients $(a_k, b_k)$ for functions $f(x)$ and $g(x)$.\n2. Implement a function to calculate $I_{\\text{dealiased}}$ using the derived formula based on coefficient products.\n3. Implement a function that synthesizes the functions $f(x)$ and $g(x)$, samples their product $h(x)$ on the specified grid of $N$ points, and computes $I_{\\text{direct}}$ using the trapezoidal rule sum.\n4. Calculate the difference $\\Delta I = I_{\\text{direct}} - I_{\\text{dealiased}}$ for each case.\n5. Collect and output the results.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the aliasing-induced bias in the integral of a product of two\n    functions for a suite of test cases.\n    \"\"\"\n\n    # Test suite definition: (N, f_coeffs_spec, g_coeffs_spec)\n    # f_coeffs_spec is a list of tuples (type, k, value)\n    # where type is 'a' for cos coefficient or 'b' for sin coefficient.\n    test_cases = [\n        # Case 1: Well-resolved case\n        (64, [('a', 5, 1.0), ('b', 7, 0.4)], [('a', 5, 1.2), ('b', 7, -0.1)]),\n        # Case 2: Nyquist boundary condition\n        (32, [('a', 16, 1.0)], [('a', 16, 1.0)]),\n        # Case 3: Significant aliasing-induced bias\n        (32, [('a', 18, 1.0)], [('a', 14, 1.0)]),\n        # Case 4: Multi-mode aliasing scenario\n        (24, [('a', 17, 1.0), ('b', 5, 0.5)], [('a', 7, 1.3), ('b', 17, 0.5)]),\n        # Case 5: Well-resolved multi-mode case (with aliasing but no bias)\n        (48, [('a', 20, 0.8), ('b', 22, -0.5)], [('a', 20, 0.8), ('b', 22, -0.5)]),\n    ]\n\n    results = []\n    for N, f_spec, g_spec in test_cases:\n        \n        def parse_spec_to_coeffs(spec):\n            \"\"\"Parses coefficient specifications into a dictionary structure.\"\"\"\n            coeffs = {\"a0\": 0.0, \"ak\": {}, \"bk\": {}}\n            for typ, k, val in spec:\n                if typ == 'a' and k != 0:\n                    coeffs[\"ak\"][k] = val\n                elif typ == 'b' and k != 0:\n                    coeffs[\"bk\"][k] = val\n                elif typ == 'a' and k == 0:\n                    coeffs[\"a0\"] = val\n            return coeffs\n\n        f_coeffs = parse_spec_to_coeffs(f_spec)\n        g_coeffs = parse_spec_to_coeffs(g_spec)\n\n        def build_func_from_coeffs(coeffs):\n            \"\"\"Builds a callable Python function from a coefficient dictionary.\"\"\"\n            a0 = coeffs.get(\"a0\", 0.0)\n            ak_coeffs = coeffs.get(\"ak\", {})\n            bk_coeffs = coeffs.get(\"bk\", {})\n            \n            def func(x):\n                val = a0\n                for k, a_k in ak_coeffs.items():\n                    val += a_k * np.cos(k * x)\n                for k, b_k in bk_coeffs.items():\n                    val += b_k * np.sin(k * x)\n                return val\n            return func\n\n        f_func = build_func_from_coeffs(f_coeffs)\n        g_func = build_func_from_coeffs(g_coeffs)\n\n        # Method 1: Dealiased Spectral-Space Integral\n        def calculate_I_dealiased(f_c, g_c):\n            # I_dealiased = 2*pi*a0_f*a0_g + pi * sum(ak_f*ak_g + bk_f*bk_g)\n            a0_f = f_c.get(\"a0\", 0.0)\n            a0_g = g_c.get(\"a0\", 0.0)\n            \n            integral = 2.0 * np.pi * a0_f * a0_g\n            \n            sum_term = 0.0\n            all_k = set(f_c[\"ak\"].keys()) | set(f_c[\"bk\"].keys()) | \\\n                    set(g_c[\"ak\"].keys()) | set(g_c[\"bk\"].keys())\n            \n            for k in all_k:\n                ak_f = f_c[\"ak\"].get(k, 0.0)\n                bk_f = f_c[\"bk\"].get(k, 0.0)\n                ak_g = g_c[\"ak\"].get(k, 0.0)\n                bk_g = g_c[\"bk\"].get(k, 0.0)\n                sum_term += ak_f * ak_g + bk_f * bk_g\n                \n            integral += np.pi * sum_term\n            return integral\n\n        I_dealiased = calculate_I_dealiased(f_coeffs, g_coeffs)\n        \n        # Method 2: Direct Quadrature Integral\n        def calculate_I_direct(func_f, func_g, num_points):\n            # Grid points: x_n = 2*pi*n/N for n = 0,...,N-1\n            x_grid = np.linspace(0.0, 2.0 * np.pi, num_points, endpoint=False)\n            \n            f_vals = func_f(x_grid)\n            g_vals = func_g(x_grid)\n            h_vals = f_vals * g_vals\n            \n            # Trapezoidal rule for periodic function\n            integral = (2.0 * np.pi / num_points) * np.sum(h_vals)\n            return integral\n\n        I_direct = calculate_I_direct(f_func, g_func, N)\n\n        # Compute the bias\n        delta_I = I_direct - I_dealiased\n        results.append(delta_I)\n\n    # Format the final output string exactly as required\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Building on the fundamentals of differentiation and an awareness of aliasing, this final practice applies spectral methods to a complete physical system: the one-dimensional viscoacoustic wave equations. By transforming the governing partial differential equations (PDEs) into a system of ordinary differential equations (ODEs) for each Fourier mode, you can solve the problem with advanced time-integration techniques. This exercise guides you through constructing a high-performance exponential integrator and comparing its accuracy and cost against a standard Runge-Kutta scheme, offering insight into the sophisticated algorithm design required in computational geophysics research .",
            "id": "3614983",
            "problem": "Consider the one-dimensional linear viscoacoustic system in a homogeneous, periodic medium, posed on the spatial interval of length $L$ with periodic boundary conditions. Let $p(x,t)$ denote acoustic pressure in pascals, $v(x,t)$ denote particle velocity in meters per second, $K$ denote the bulk modulus in pascals, and $\\rho$ denote the density in kilograms per cubic meter. The governing equations follow from linear momentum balance and mass conservation with linear damping:\n$$\n\\partial_t p + K\\,\\partial_x v = -\\alpha\\,p,\\qquad\n\\partial_t v + \\frac{1}{\\rho}\\,\\partial_x p = -\\beta\\,v,\n$$\nwhere $\\alpha$ and $\\beta$ are nonnegative damping rates in reciprocal seconds. Define $c = \\sqrt{K/\\rho}$ in meters per second. Assume the spatial domain is periodic and that all fields are sufficiently smooth to admit a Fourier series representation.\n\nBy applying the spatial Fourier transform to the system, each Fourier mode with wavenumber $k$ evolves according to a constant-coefficient linear system\n$$\n\\frac{d}{dt}\\,\\hat{u}(k,t) = M_k\\,\\hat{u}(k,t),\n$$\nwhere $\\hat{u}(k,t) = \\begin{bmatrix}\\hat{p}(k,t)\\\\ \\hat{v}(k,t)\\end{bmatrix}$ and\n$$\nM_k = \\begin{bmatrix}\n-\\alpha & -\\mathrm{i}\\,K\\,k \\\\\n-\\mathrm{i}\\,\\frac{k}{\\rho} & -\\beta\n\\end{bmatrix}.\n$$\nAngles must be expressed in radians throughout.\n\nTask A (construction of a commutator-free exponential integrator): Construct a second-order, commutator-free exponential time integrator based on operator splitting for this autonomous Fourier-mode system by writing $M_k = D + W_k$ with a diagonal damping operator $D$ and a coupling operator $W_k$ that encodes wave propagation. Your integrator must use a symmetric composition of exponentials of $D$ and $W_k$ so that the method is globally second-order accurate in time for autonomous problems. Derive a closed-form expression for $\\exp(\\Delta t\\,W_k)$ that avoids numerical diagonalization, by exploiting the algebraic structure of $W_k$.\n\nTask B (high-order Runge–Kutta comparator): For the same Fourier-mode system, derive the one-step amplification matrix of the classical fourth-order Runge–Kutta method applied directly to the linear system with time step $\\Delta t$, expressed as a matrix polynomial in $M_k$. Do not assume normality or diagonalizability beyond what is needed for a standard linear stability function.\n\nTask C (dispersion and dissipation measures): For a given $k \\neq 0$, the exact continuous-time evolution over one time step $\\Delta t$ has discrete amplification eigenvalues $\\exp(\\Delta t\\,\\mu_j(k))$, where $\\mu_j(k)$ are the eigenvalues of $M_k$. If an eigenvalue has nonzero imaginary part, define the exact phase speed $c_{\\mathrm{exact}}(k) = \\frac{\\operatorname{Im}(\\mu_j(k))}{|k|}$ in meters per second, and the exact per-step attenuation factor $a_{\\mathrm{exact}}(k) = \\exp\\big(\\Delta t\\,\\operatorname{Re}(\\mu_j(k))\\big)$ (dimensionless). For each numerical scheme from Tasks A and B, let $\\lambda_{\\mathrm{num}}(k)$ denote the eigenvalue of the one-step amplification matrix with positive imaginary part (if present), and define $c_{\\mathrm{num}}(k) = \\frac{\\arg(\\lambda_{\\mathrm{num}}(k))}{\\Delta t\\,|k|}$ in meters per second and $a_{\\mathrm{num}}(k) = |\\lambda_{\\mathrm{num}}(k)|$ (dimensionless). For wavenumbers where the exact mode is overdamped (no imaginary part), exclude that mode from the dispersion error computation. Define the maximum absolute dispersion error and the maximum absolute dissipation error, respectively, over a set $\\mathcal{K}$ of sampled wavenumbers by\n$$\nE_c = \\max_{k\\in\\mathcal{K}} \\left| c_{\\mathrm{num}}(k) - c_{\\mathrm{exact}}(k)\\right|,\\qquad\nE_a = \\max_{k\\in\\mathcal{K}} \\left| a_{\\mathrm{num}}(k) - a_{\\mathrm{exact}}(k)\\right|.\n$$\n\nTask D (cost model): Define a simple, mode-local operation-count cost model for one time step in Fourier space that counts only complex vector-matrix multiplications, assuming all exponentials and trigonometric coefficients dependent on $\\Delta t$ and $k$ are precomputed and reused. In this model, a $2\\times 2$ matrix-vector product counts as $4$ complex multiplications and a diagonal scaling of a two-component vector counts as $2$ complex multiplications. Under this model, compute the ratio of the per-mode cost of the commutator-free exponential integrator from Task A to that of the fourth-order Runge–Kutta method from Task B.\n\nYour program must implement the above tasks in a self-contained manner using Fourier diagonalization for each $k$ and compute the errors and cost ratio for the following test suite. For each test, use a periodic domain of length $L$ meters discretized into $N$ points, sample the set $\\mathcal{K} = \\{k_j\\}_{j=1}^{J}$ with $k_j = \\frac{2\\pi j}{L}$ for $j=1,\\dots,J$ and $J = \\min\\{64, \\frac{N}{2}-1\\}$, and use the specified time step $\\Delta t$ in seconds. Express all phase speeds in meters per second, attenuation factors as dimensionless per-step magnitudes, and angles in radians. The density is $\\rho$ kilograms per cubic meter and the bulk modulus is $K$ pascals.\n\nTest suite:\n- Test $1$ (moderate damping, happy path): $L = 1000\\,\\mathrm{m}$, $N = 256$, $\\rho = 2000\\,\\mathrm{kg/m^3}$, $K = 8.0\\times 10^{9}\\,\\mathrm{Pa}$, $\\alpha = 0.01\\,\\mathrm{s^{-1}}$, $\\beta = 0.01\\,\\mathrm{s^{-1}}$, $\\Delta t = 0.001\\,\\mathrm{s}$.\n- Test $2$ (no damping, near stability edge): $L = 1000\\,\\mathrm{m}$, $N = 256$, $\\rho = 2000\\,\\mathrm{kg/m^3}$, $K = 8.0\\times 10^{9}\\,\\mathrm{Pa}$, $\\alpha = 0\\,\\mathrm{s^{-1}}$, $\\beta = 0\\,\\mathrm{s^{-1}}$, $\\Delta t = 0.0017\\,\\mathrm{s}$.\n- Test $3$ (asymmetric strong damping): $L = 1000\\,\\mathrm{m}$, $N = 256$, $\\rho = 2000\\,\\mathrm{kg/m^3}$, $K = 8.0\\times 10^{9}\\,\\mathrm{Pa}$, $\\alpha = 0.2\\,\\mathrm{s^{-1}}$, $\\beta = 0.05\\,\\mathrm{s^{-1}}$, $\\Delta t = 0.001\\,\\mathrm{s}$.\n\nFor each test, compute:\n- The maximum absolute dispersion error $E_c$ for the commutator-free exponential integrator from Task A (in meters per second).\n- The maximum absolute dissipation error $E_a$ for the commutator-free exponential integrator from Task A (dimensionless).\n- The maximum absolute dispersion error $E_c$ for the fourth-order Runge–Kutta method from Task B (in meters per second).\n- The maximum absolute dissipation error $E_a$ for the fourth-order Runge–Kutta method from Task B (dimensionless).\n- The cost ratio defined in Task D (dimensionless).\n\nFinal output format: Your program should produce a single line of output containing the concatenated results for all three tests, in the order listed above, as a comma-separated list enclosed in square brackets. Each floating-point number must be rounded to six decimal places. For example, the output should look like\n\"[x1,x2,x3,x4,x5,y1,y2,y3,y4,y5,z1,z2,z3,z4,z5]\"\nwhere the group $(x1,\\dots,x5)$ corresponds to Test $1$, $(y1,\\dots,y5)$ to Test $2$, and $(z1,\\dots,z5)$ to Test $3$.",
            "solution": "The analysis is performed for each Fourier mode with wavenumber $k$. The dynamics of the mode amplitudes $\\hat{u}(k,t) = [\\hat{p}(k,t), \\hat{v}(k,t)]^T$ are governed by the linear ordinary differential equation $\\frac{d}{dt}\\hat{u}(k,t) = M_k \\hat{u}(k,t)$, where the system matrix $M_k$ is given by\n$$\nM_k = \\begin{bmatrix}\n-\\alpha & -\\mathrm{i}\\,K\\,k \\\\\n-\\mathrm{i}\\,\\frac{k}{\\rho} & -\\beta\n\\end{bmatrix}.\n$$\n\n### Task A: Commutator-Free Exponential Integrator\n\nWe are tasked with constructing a second-order exponential integrator based on a symmetric Strang splitting of the matrix $M_k$. We decompose $M_k$ into a diagonal part $D$ representing damping and an off-diagonal part $W_k$ representing wave propagation:\n$$\nM_k = D + W_k, \\quad \\text{where} \\quad D = \\begin{bmatrix} -\\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix}, \\quad W_k = \\begin{bmatrix} 0 & -\\mathrm{i}\\,K\\,k \\\\ -\\mathrm{i}\\,\\frac{k}{\\rho} & 0 \\end{bmatrix}.\n$$\nThe one-step amplification matrix for a second-order symmetric splitting scheme (Strang splitting) over a time step $\\Delta t$ is\n$$\n\\Phi_{CF}(\\Delta t) = \\exp\\left(\\frac{\\Delta t}{2} D\\right) \\exp(\\Delta t W_k) \\exp\\left(\\frac{\\Delta t}{2} D\\right).\n$$\nThe exponential of the diagonal matrix $D$ is straightforward:\n$$\n\\exp\\left(\\frac{\\Delta t}{2} D\\right) = \\begin{bmatrix} \\exp(-\\alpha \\Delta t/2) & 0 \\\\ 0 & \\exp(-\\beta \\Delta t/2) \\end{bmatrix}.\n$$\nTo find a closed-form expression for $\\exp(\\Delta t W_k)$, we examine the powers of $W_k$. Let $c = \\sqrt{K/\\rho}$.\n$$\nW_k^2 = \\begin{bmatrix} 0 & -\\mathrm{i}\\,K\\,k \\\\ -\\mathrm{i}\\,\\frac{k}{\\rho} & 0 \\end{bmatrix}^2 = \\begin{bmatrix} (-\\mathrm{i}\\,K\\,k)(-\\mathrm{i}\\,k/\\rho) & 0 \\\\ 0 & (-\\mathrm{i}\\,k/\\rho)(-\\mathrm{i}\\,K\\,k) \\end{bmatrix} = \\begin{bmatrix} -k^2 K/\\rho & 0 \\\\ 0 & -k^2 K/\\rho \\end{bmatrix} = -(ck)^2 I,\n$$\nwhere $I$ is the $2 \\times 2$ identity matrix. Using the Taylor series for the matrix exponential and the property $W_k^2 = -(ck)^2 I$, we have:\n\\begin{align*}\n\\exp(\\Delta t W_k) &= \\sum_{n=0}^{\\infty} \\frac{(\\Delta t W_k)^n}{n!} \\\\\n&= \\left(1 - \\frac{(\\Delta t c k)^2}{2!} + \\frac{(\\Delta t c k)^4}{4!} - \\dots\\right)I + \\left(\\Delta t - \\frac{(\\Delta t)^3 (ck)^2}{3!} + \\dots\\right)W_k \\\\\n&= \\cos(ck\\Delta t)I + \\frac{\\sin(ck\\Delta t)}{ck} W_k.\n\\end{align*}\nSubstituting the matrix $W_k$ and simplifying using $K = c^2\\rho$ yields:\n$$\n\\exp(\\Delta t W_k) = \\begin{bmatrix} \\cos(ck\\Delta t) & -\\mathrm{i}\\,c\\rho\\sin(ck\\Delta t) \\\\ -\\mathrm{i}\\,\\frac{1}{c\\rho} \\sin(ck\\Delta t) & \\cos(ck\\Delta t) \\end{bmatrix}.\n$$\nThe full amplification matrix $\\Phi_{CF}(\\Delta t)$ is the product of the three matrices:\n$$\n\\Phi_{CF}(\\Delta t) = \\begin{bmatrix}\ne^{-\\alpha \\Delta t} \\cos(ck\\Delta t) & -\\mathrm{i}\\,c\\rho \\, e^{-(\\alpha+\\beta) \\Delta t/2} \\sin(ck\\Delta t) \\\\\n-\\mathrm{i}\\,\\frac{1}{c\\rho} e^{-(\\alpha+\\beta) \\Delta t/2} \\sin(ck\\Delta t) & e^{-\\beta \\Delta t} \\cos(ck\\Delta t)\n\\end{bmatrix}.\n$$\nThis is the one-step amplification matrix for the commutator-free exponential integrator.\n\n### Task B: Fourth-Order Runge–Kutta Comparator\n\nFor a linear system $\\dot{\\hat{u}} = M_k \\hat{u}$, the classical fourth-order Runge-Kutta (RK4) method results in a one-step amplification matrix $A_{RK4}$ that is given by the stability function of the method, which is the truncated Taylor series of the exponential function:\n$$\nA_{RK4} = I + \\Delta t M_k + \\frac{(\\Delta t M_k)^2}{2!} + \\frac{(\\Delta t M_k)^3}{3!} + \\frac{(\\Delta t M_k)^4}{4!}.\n$$\nThis is the required matrix polynomial in $M_k$. The eigenvalues of $A_{RK4}$ for a given $k$ can be found by applying the same polynomial to the eigenvalues of $M_k$.\n\n### Task C: Dispersion and Dissipation Measures\n\nTo evaluate the numerical schemes, we first analyze the exact continuous-time system by finding the eigenvalues $\\mu_j(k)$ of the matrix $M_k$. The characteristic equation is $\\det(M_k - \\mu I) = 0$:\n$$\n(-\\alpha - \\mu)(-\\beta - \\mu) - (-\\mathrm{i}Kk)(-\\mathrm{i}k/\\rho) = 0 \\implies \\mu^2 + (\\alpha+\\beta)\\mu + (\\alpha\\beta + (ck)^2) = 0.\n$$\nThe solutions for $\\mu$ are:\n$$\n\\mu_{1,2}(k) = -\\frac{\\alpha+\\beta}{2} \\pm \\frac{1}{2}\\sqrt{(\\alpha-\\beta)^2 - 4(ck)^2}.\n$$\nPropagating waves exist when the discriminant is negative, i.e., $2c|k| > |\\alpha-\\beta|$. In this case, the eigenvalues are a complex conjugate pair. We choose the eigenvalue with the positive imaginary part, $\\mu(k)$, to define the exact properties:\n$$\n\\mu(k) = -\\frac{\\alpha+\\beta}{2} + \\mathrm{i}\\,\\frac{1}{2}\\sqrt{4(ck)^2 - (\\alpha-\\beta)^2}.\n$$\nThe exact phase speed $c_{\\mathrm{exact}}(k)$ and per-step attenuation factor $a_{\\mathrm{exact}}(k)$ are:\n$$\nc_{\\mathrm{exact}}(k) = \\frac{\\operatorname{Im}(\\mu(k))}{|k|} = \\frac{\\sqrt{4(ck)^2 - (\\alpha-\\beta)^2}}{2|k|} = c\\sqrt{1 - \\left(\\frac{\\alpha-\\beta}{2ck}\\right)^2}\n$$\n$$\na_{\\mathrm{exact}}(k) = \\exp(\\Delta t \\operatorname{Re}(\\mu(k))) = \\exp\\left(-\\frac{\\alpha+\\beta}{2}\\Delta t\\right).\n$$\nFor each numerical scheme, we compute the eigenvalues of its one-step amplification matrix ($\\Phi_{CF}$ or $A_{RK4}$). Let $\\lambda_{\\mathrm{num}}(k)$ be the eigenvalue with a positive imaginary part. The numerical phase speed $c_{\\mathrm{num}}(k)$ and attenuation $a_{\\mathrm{num}}(k)$ are defined as:\n$$\nc_{\\mathrm{num}}(k) = \\frac{\\arg(\\lambda_{\\mathrm{num}}(k))}{\\Delta t\\,|k|}, \\qquad a_{\\mathrm{num}}(k) = |\\lambda_{\\mathrm{num}}(k)|.\n$$\nThe eigenvalues for the commutator-free integrator are found from the characteristic equation of $\\Phi_{CF}$. Let $\\lambda$ be an eigenvalue of $\\Phi_{CF}$. Then $\\lambda^2 - \\mathrm{Tr}(\\Phi_{CF})\\lambda + \\det(\\Phi_{CF})=0$.\n$$\n\\mathrm{Tr}(\\Phi_{CF}) = (e^{-\\alpha\\Delta t} + e^{-\\beta\\Delta t})\\cos(ck\\Delta t), \\qquad \\det(\\Phi_{CF}) = e^{-(\\alpha+\\beta)\\Delta t}.\n$$\nThe eigenvalues for the RK4 method are found by evaluating the stability polynomial at the eigenvalues of $M_k$:\n$$\n\\lambda_{RK4}(k) = 1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24}, \\quad \\text{where} \\quad z = \\Delta t\\,\\mu(k).\n$$\nThe maximum absolute errors $E_c$ and $E_a$ are then computed by taking the maximum difference over the set of wavenumbers $\\mathcal{K}$.\n\n### Task D: Cost Model\n\nThe cost model considers only complex matrix-vector multiplications for a single mode $\\hat{u}(k,t)$.\n- A general $2 \\times 2$ matrix-vector product costs $4$ complex multiplications.\n- A diagonal $2 \\times 2$ matrix-vector product (scaling) costs $2$ complex multiplications.\n\n**Cost of Commutator-Free Integrator:** The update $\\hat{u}_{n+1} = \\exp(\\frac{\\Delta t}{2} D) \\exp(\\Delta t W_k) \\exp(\\frac{\\Delta t}{2} D) \\hat{u}_n$ is performed in three steps:\n1.  A diagonal scaling by $\\exp(\\frac{\\Delta t}{2} D)$: $2$ ops.\n2.  A general matrix-vector product with $\\exp(\\Delta t W_k)$: $4$ ops.\n3.  A diagonal scaling by $\\exp(\\frac{\\Delta t}{2} D)$: $2$ ops.\nTotal cost for the CF integrator is $2+4+2=8$ complex multiplications.\n\n**Cost of RK4 Integrator:** The method requires four stages, each involving one multiplication by the matrix $M_k$:\n1.  $k_1 = M_k \\hat{u}_n$\n2.  $k_2 = M_k (\\hat{u}_n + \\dots)$\n3.  $k_3 = M_k (\\hat{u}_n + \\dots)$\n4.  $k_4 = M_k (\\hat{u}_n + \\dots)$\nEach stage requires one general $2\\times 2$ matrix-vector product, costing $4$ ops each.\nTotal cost for the RK4 method is $4 \\times 4 = 16$ complex multiplications.\n\n**Cost Ratio:** The ratio of the per-mode cost of the CF integrator to that of the RK4 method is:\n$$\n\\text{Ratio} = \\frac{\\text{Cost}_{CF}}{\\text{Cost}_{RK4}} = \\frac{8}{16} = 0.5.\n$$\nThis ratio is constant for all test cases as it depends only on the structure of the algorithms.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # Test 1\n        {'L': 1000.0, 'N': 256, 'rho': 2000.0, 'K': 8.0e9, 'alpha': 0.01, 'beta': 0.01, 'dt': 0.001},\n        # Test 2\n        {'L': 1000.0, 'N': 256, 'rho': 2000.0, 'K': 8.0e9, 'alpha': 0.0, 'beta': 0.0, 'dt': 0.0017},\n        # Test 3\n        {'L': 1000.0, 'N': 256, 'rho': 2000.0, 'K': 8.0e9, 'alpha': 0.2, 'beta': 0.05, 'dt': 0.001},\n    ]\n\n    all_results = []\n    for params in test_cases:\n        results = process_case(params)\n        all_results.extend(results)\n    \n    formatted_results = [f\"{round(x, 6):.6f}\" for x in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\ndef process_case(params):\n    \"\"\"\n    Processes a single test case and computes the error metrics and cost ratio.\n    \"\"\"\n    L, N, rho, K = params['L'], params['N'], params['rho'], params['K']\n    alpha, beta, dt = params['alpha'], params['beta'], params['dt']\n\n    c = np.sqrt(K / rho)\n    J = min(64, N // 2 - 1)\n    k_vals = np.array([(2 * np.pi * j) / L for j in range(1, J + 1)])\n\n    # Error accumulators\n    Ec_cf, Ea_cf = 0.0, 0.0\n    Ec_rk4, Ea_rk4 = 0.0, 0.0\n\n    for k in k_vals:\n        # --- Exact Analysis ---\n        discriminant_M = (alpha - beta)**2 - 4 * (c * k)**2\n        \n        # We only consider underdamped modes for dispersion error calculations\n        if discriminant_M >= 0:\n            continue\n\n        sqrt_disc_M = np.sqrt(complex(discriminant_M))\n        mu1 = (- (alpha + beta) + sqrt_disc_M) / 2.0\n        mu2 = (- (alpha + beta) - sqrt_disc_M) / 2.0\n        \n        mu_exact = mu1 if np.imag(mu1) > 0 else mu2\n        \n        c_exact = np.imag(mu_exact) / k\n        a_exact = np.exp(dt * np.real(mu_exact))\n\n        # --- Commutator-Free Integrator Analysis ---\n        tr_A_cf = (np.exp(-alpha * dt) + np.exp(-beta * dt)) * np.cos(c * k * dt)\n        det_A_cf = np.exp(-(alpha + beta) * dt)\n        discriminant_A_cf = tr_A_cf**2 - 4 * det_A_cf\n        \n        lambda_cf = None\n        if discriminant_A_cf  0:\n            sqrt_disc_A_cf = np.sqrt(complex(discriminant_A_cf))\n            lambda_cf_1 = (tr_A_cf + sqrt_disc_A_cf) / 2.0\n            lambda_cf_2 = (tr_A_cf - sqrt_disc_A_cf) / 2.0\n            lambda_cf = lambda_cf_1 if np.angle(lambda_cf_1) > 0 else lambda_cf_2\n        \n        if lambda_cf is not None:\n            c_num_cf = np.angle(lambda_cf) / (dt * k)\n            a_num_cf = np.abs(lambda_cf)\n            Ec_cf = max(Ec_cf, abs(c_num_cf - c_exact))\n            Ea_cf = max(Ea_cf, abs(a_num_cf - a_exact))\n\n        # --- RK4 Integrator Analysis ---\n        z = dt * mu_exact\n        lambda_rk4 = 1 + z + z**2 / 2 + z**3 / 6 + z**4 / 24\n\n        if np.imag(lambda_rk4) != 0:\n            # Ensure angle is positive for consistency\n            angle_rk4 = np.angle(lambda_rk4)\n            if angle_rk4  0:\n                # This could happen for large dt, but not for these test cases.\n                # The complex conjugate eigenvalue would have a positive angle.\n                lambda_rk4_conj = np.conj(lambda_rk4)\n                angle_rk4 = np.angle(lambda_rk4_conj)\n\n            c_num_rk4 = angle_rk4 / (dt * k)\n            a_num_rk4 = np.abs(lambda_rk4)\n            Ec_rk4 = max(Ec_rk4, abs(c_num_rk4 - c_exact))\n            Ea_rk4 = max(Ea_rk4, abs(a_num_rk4 - a_exact))\n\n    cost_ratio = 8.0 / 16.0\n    \n    return [Ec_cf, Ea_cf, Ec_rk4, Ea_rk4, cost_ratio]\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        }
    ]
}