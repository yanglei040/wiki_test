{
    "hands_on_practices": [
        {
            "introduction": "The accuracy of any finite difference scheme is fundamentally determined by its local truncation error, a quantity formally derived from Taylor series expansions. This first practice provides a direct, computational method to verify this core theoretical principle by comparing the actual, observed error of a discrete operator against its predicted leading-term error for a known smooth function . By completing this exercise, you will build a robust intuition for the concept of convergence order and gain a concrete understanding of how grid spacing $h$ governs the local accuracy of discretization.",
            "id": "3592019",
            "problem": "You are tasked with developing a program that, for a one-dimensional uniform structured grid, computes an a posteriori estimate of the discretization error by evaluating the leading truncation error term derived from Taylor series for finite difference operators, and validates the estimate against the observed error on a sequence of refined grids. The context is a periodic domain and a known smooth function with a closed-form expression for its derivatives, ensuring scientific realism suitable for computational geophysics.\n\nStart from the following fundamental base: Taylor series expansion of a sufficiently smooth function about a point. For a function $u(x)$ possessing continuous derivatives up to at least order $6$, the Taylor series around a grid point $x_i$ with grid spacing $h$ can be written as\n$$\nu(x_i \\pm h) = u(x_i) \\pm h u'(x_i) + \\frac{h^2}{2} u''(x_i) \\pm \\frac{h^3}{6} u^{(3)}(x_i) + \\frac{h^4}{24} u^{(4)}(x_i) \\pm \\frac{h^5}{120} u^{(5)}(x_i) + \\frac{h^6}{720} u^{(6)}(x_i) + \\mathcal{O}(h^7).\n$$\nUse these expansions to derive the leading truncation error terms for the central finite difference approximations of the first derivative and the second derivative.\n\nYour program must perform the following steps:\n\n- Consider the periodic domain $[0,1)$ with grid points $x_i = i h$ for $i = 0, 1, \\dots, N-1$, where $h = 1/N$.\n- Use the manufactured smooth solution $u(x) = \\sin(2 \\pi x)$, where angles must be in radians.\n- For each test case, select the operator and grid resolution as specified below, and:\n  1. Construct the periodic structured grid and evaluate $u(x_i)$.\n  2. For the operator indicated by the test case:\n     - If the operator is the central finite difference for the first derivative,\n       compute the discrete approximation\n       $$\n       D^{(1)}_h u(x_i) = \\frac{u(x_{i+1}) - u(x_{i-1})}{2 h},\n       $$\n       and the exact derivative $u'(x_i)$.\n       Derive and evaluate the leading truncation error term at each grid point based on Taylor series and $u^{(3)}(x_i)$.\n     - If the operator is the central finite difference for the second derivative,\n       compute the discrete approximation\n       $$\n       D^{(2)}_h u(x_i) = \\frac{u(x_{i+1}) - 2 u(x_i) + u(x_{i-1})}{h^2},\n       $$\n       and the exact derivative $u''(x_i)$.\n       Derive and evaluate the leading truncation error term at each grid point based on Taylor series and $u^{(4)}(x_i)$.\n  3. Compute the observed pointwise discretization error field as the difference between the discrete approximation and the exact derivative for the chosen operator.\n  4. Compute the a posteriori pointwise error estimate by evaluating only the leading truncation error term at grid points.\n  5. For validation, compute the ratio of the infinity norms (supremum norms) of the observed error and the leading-term estimate:\n     $$\n     R = \\frac{\\| \\text{observed error} \\|_{\\infty}}{\\| \\text{leading-term estimate} \\|_{\\infty}},\n     $$\n     and then report the decimal relative mismatch defined by\n     $$\n     \\delta = \\left| R - 1 \\right|.\n     $$\n     The quantity $\\delta$ must be reported as a decimal number (not a percentage). As $N$ increases (refinement), $\\delta$ should decrease if the truncation error derivation is correct, because higher-order terms become negligible.\n\nTest suite and coverage:\n\n- Use operator code values $1$ for the central finite difference first derivative and $2$ for the central finite difference second derivative.\n- Use the following test cases covering a standard case, refined grids, coarse grids as edge cases, and non-power-of-two grids:\n  - $(\\text{operator} = 1, N = 8)$\n  - $(\\text{operator} = 1, N = 64)$\n  - $(\\text{operator} = 2, N = 8)$\n  - $(\\text{operator} = 2, N = 32)$\n  - $(\\text{operator} = 2, N = 128)$\n  - $(\\text{operator} = 1, N = 4)$\n  - $(\\text{operator} = 2, N = 4)$\n  - $(\\text{operator} = 1, N = 33)$\n  - $(\\text{operator} = 2, N = 33)$\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered exactly as listed in the test suite above. Each entry must be the decimal relative mismatch $\\delta$ for that test case. For example, an output of the form\n$[d_1,d_2,\\dots,d_9]$\nwith each $d_k$ a floating-point number.\n\nAll angles must be in radians. No physical units are involved. Ensure scientific realism by implementing periodic boundary conditions and using a manufactured smooth solution with known derivatives.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of numerical analysis, specifically Taylor series analysis of finite difference operators. It is well-posed, objective, and complete, representing a standard procedure for the verification of numerical methods. We may therefore proceed with a full solution.\n\nThe core objective is to derive and numerically validate the a posteriori error estimate for central finite difference approximations of the first and second derivatives. This task is accomplished by comparing the observed discretization error with the theoretical estimate derived from the leading term of the truncation error. The fundamental basis for this derivation is the Taylor series expansion of a sufficiently smooth function $u(x)$ around a grid point $x_i$, given a uniform grid spacing $h$.\n\nThe Taylor series for $u(x_{i} \\pm h) \\equiv u(x_i \\pm h)$ are provided up to $\\mathcal{O}(h^7)$:\n$$\nu(x_i + h) = u(x_i) + h u'(x_i) + \\frac{h^2}{2} u''(x_i) + \\frac{h^3}{6} u^{(3)}(x_i) + \\frac{h^4}{24} u^{(4)}(x_i) + \\frac{h^5}{120} u^{(5)}(x_i) + \\frac{h^6}{720} u^{(6)}(x_i) + \\mathcal{O}(h^7)\n$$\n$$\nu(x_i - h) = u(x_i) - h u'(x_i) + \\frac{h^2}{2} u''(x_i) - \\frac{h^3}{6} u^{(3)}(x_i) + \\frac{h^4}{24} u^{(4)}(x_i) - \\frac{h^5}{120} u^{(5)}(x_i) + \\frac{h^6}{720} u^{(6)}(x_i) + \\mathcal{O}(h^7)\n$$\n\nThe analysis will be performed on a periodic domain $[0,1)$ using the manufactured solution $u(x) = \\sin(2\\pi x)$. The required derivatives of this function are:\n- $u'(x) = 2\\pi \\cos(2\\pi x)$\n- $u''(x) = -(2\\pi)^2 \\sin(2\\pi x)$\n- $u^{(3)}(x) = -(2\\pi)^3 \\cos(2\\pi x)$\n- $u^{(4)}(x) = (2\\pi)^4 \\sin(2\\pi x)$\n\n**1. Analysis of the First Derivative Central Difference Operator ($D^{(1)}_h$)**\n\nThe central difference approximation for the first derivative is defined as:\n$$\nD^{(1)}_h u(x_i) = \\frac{u(x_{i+1}) - u(x_{i-1})}{2 h}\n$$\nTo determine the truncation error, we substitute the Taylor series for $u(x_{i+1})$ and $u(x_{i-1})$ into the formula. Subtracting the expansion for $u(x_i-h)$ from that of $u(x_i+h)$ cancels the even-order derivative terms:\n$$\nu(x_{i+1}) - u(x_{i-1}) = 2 h u'(x_i) + 2 \\frac{h^3}{6} u^{(3)}(x_i) + 2 \\frac{h^5}{120} u^{(5)}(x_i) + \\mathcal{O}(h^7)\n$$\nDividing by the $2h$ term in the denominator of the operator gives:\n$$\nD^{(1)}_h u(x_i) = u'(x_i) + \\frac{h^2}{6} u^{(3)}(x_i) + \\frac{h^4}{120} u^{(5)}(x_i) + \\mathcal{O}(h^6)\n$$\nThe discretization error, $E^{(1)}(x_i)$, is the difference between the discrete approximation and the exact continuous operator. This is also known as the truncation error, $\\tau^{(1)}(x_i)$:\n$$\nE^{(1)}(x_i) = D^{(1)}_h u(x_i) - u'(x_i) = \\frac{h^2}{6} u^{(3)}(x_i) + \\frac{h^4}{120} u^{(5)}(x_i) + \\mathcal{O}(h^6)\n$$\nThe leading term of this error, which provides the a posteriori estimate, is:\n$$\n\\text{Leading-term estimate for } E^{(1)}(x_i) = \\frac{h^2}{6} u^{(3)}(x_i)\n$$\nThis is an $\\mathcal{O}(h^2)$ accurate scheme. The observed error is computed directly as $E^{(1)}(x_i) = D^{(1)}_h u(x_i) - u'(x_i)$.\n\n**2. Analysis of the Second Derivative Central Difference Operator ($D^{(2)}_h$)**\n\nThe central difference approximation for the second derivative is:\n$$\nD^{(2)}_h u(x_i) = \\frac{u(x_{i+1}) - 2 u(x_i) + u(x_{i-1})}{h^2}\n$$\nTo analyze this operator, we first sum the Taylor expansions for $u(x_{i+1})$ and $u(x_{i-1})$, which cancels the odd-order derivative terms:\n$$\nu(x_{i+1}) + u(x_{i-1}) = 2 u(x_i) + h^2 u''(x_i) + \\frac{h^4}{12} u^{(4)}(x_i) + \\frac{h^6}{360} u^{(6)}(x_i) + \\mathcal{O}(h^8)\n$$\nSubstituting this into the numerator of the operator definition:\n$$\nu(x_{i+1}) - 2 u(x_i) + u(x_{i-1}) = h^2 u''(x_i) + \\frac{h^4}{12} u^{(4)}(x_i) + \\frac{h^6}{360} u^{(6)}(x_i) + \\mathcal{O}(h^8)\n$$\nDividing by $h^2$:\n$$\nD^{(2)}_h u(x_i) = u''(x_i) + \\frac{h^2}{12} u^{(4)}(x_i) + \\frac{h^4}{360} u^{(6)}(x_i) + \\mathcal{O}(h^6)\n$$\nThe discretization error for the second derivative is therefore:\n$$\nE^{(2)}(x_i) = D^{(2)}_h u(x_i) - u''(x_i) = \\frac{h^2}{12} u^{(4)}(x_i) + \\frac{h^4}{360} u^{(6)}(x_i) + \\mathcal{O}(h^6)\n$$\nThe leading term of this error, which constitutes our a posteriori estimate, is:\n$$\n\\text{Leading-term estimate for } E^{(2)}(x_i) = \\frac{h^2}{12} u^{(4)}(x_i)\n$$\nThis scheme is also $\\mathcal{O}(h^2)$ accurate. The observed error is computed as $E^{(2)}(x_i) = D^{(2)}_h u(x_i) - u''(x_i)$.\n\n**3. Algorithmic Validation Procedure**\n\nFor each specified test case $(\\text{operator code}, N)$, the algorithm proceeds as follows:\n$1$. A uniform grid with $N$ points on the domain $[0,1)$ is constructed, where $x_i = i h$ for $i=0, 1, \\dots, N-1$ and $h = 1/N$.\n$2$. The function $u(x) = \\sin(2\\pi x)$ is evaluated at each grid point $x_i$.\n$3$. Based on the operator code ($1$ or $2$), the corresponding discrete approximation ($D^{(1)}_h u$ or $D^{(2)}_h u$) and the exact derivative ($u'$ or $u''$) are computed at each grid point. Periodicity is handled by wrapping indices, such that $u_{i-1}$ for $i=0$ refers to $u_{N-1}$ and $u_{i+1}$ for $i=N-1$ refers to $u_0$.\n$4$. The observed pointwise error field is computed as the difference between the discrete approximation and the exact derivative.\n$5$. The a posteriori pointwise error estimate is computed by evaluating the derived leading truncation error term, using the known analytical form of the appropriate higher-order derivative ($u^{(3)}$ or $u^{(4)}$).\n$6$. The infinity norm (supremum norm), $\\|v\\|_{\\infty} = \\max_i |v_i|$, is computed for both the observed error field and the estimated error field.\n$7$. The ratio $R = \\frac{\\| \\text{observed error} \\|_{\\infty}}{\\| \\text{leading-term estimate} \\|_{\\infty}}$ is calculated.\n$8$. Finally, the decimal relative mismatch $\\delta = | R - 1 |$ is computed. As $N$ increases, $h$ decreases, causing the higher-order terms in the truncation error to become negligible. Consequently, $R$ should converge to $1$, and $\\delta$ should converge to $0$, thus validating the analytical derivation.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes an a posteriori estimate of the discretization error for finite\n    difference operators and validates it against the observed error.\n\n    The validation is performed for central difference approximations of the first\n    and second derivatives on a periodic domain with a manufactured solution.\n    The decimal relative mismatch between the norms of the observed and\n    estimated errors is calculated for a suite of test cases.\n    \"\"\"\n\n    # Test cases defined as (operator_code, N_points).\n    # operator_code=1: First derivative central difference.\n    # operator_code=2: Second derivative central difference.\n    test_cases = [\n        (1, 8),\n        (1, 64),\n        (2, 8),\n        (2, 32),\n        (2, 128),\n        (1, 4),\n        (2, 4),\n        (1, 33),\n        (2, 33),\n    ]\n\n    results = []\n    for case in test_cases:\n        operator, N = case\n        \n        # Step 1: Construct the periodic grid and evaluate the function u(x).\n        h = 1.0 / N\n        x = np.arange(N, dtype=float) * h\n        k = 2.0 * np.pi  # Angular frequency for u(x) = sin(k*x)\n        \n        u_vals = np.sin(k * x)\n\n        # To handle periodic boundaries, neighboring values u(x_{i+1}) and u(x_{i-1})\n        # are found by \"rolling\" the grid point array.\n        u_plus_1 = np.roll(u_vals, -1)\n        u_minus_1 = np.roll(u_vals, 1)\n\n        obs_error = None\n        est_error = None\n\n        # Step 2: Select operator and compute approximations.\n        if operator == 1:\n            # First derivative central difference\n            \n            # Compute discrete approximation and exact derivative\n            D1_u = (u_plus_1 - u_minus_1) / (2.0 * h)\n            u_prime_exact = k * np.cos(k * x)\n            \n            # Step 3: Compute observed pointwise discretization error\n            obs_error = D1_u - u_prime_exact\n            \n            # Step 4: Compute a posteriori pointwise error estimate\n            # Leading term is (h^2/6) * u'''(x)\n            u_3_exact = -(k**3) * np.cos(k * x)\n            est_error = (h**2 / 6.0) * u_3_exact\n            \n        elif operator == 2:\n            # Second derivative central difference\n            \n            # Compute discrete approximation and exact derivative\n            D2_u = (u_plus_1 - 2.0 * u_vals + u_minus_1) / (h**2)\n            u_2_exact = -(k**2) * np.sin(k * x)\n            \n            # Step 3: Compute observed pointwise discretization error\n            obs_error = D2_u - u_2_exact\n            \n            # Step 4: Compute a posteriori pointwise error estimate\n            # Leading term is (h^2/12) * u''''(x)\n            u_4_exact = (k**4) * np.sin(k * x)\n            est_error = (h**2 / 12.0) * u_4_exact\n\n        # Step 5: For validation, compute the ratio of the infinity norms\n        # and the decimal relative mismatch.\n        norm_obs_error = np.max(np.abs(obs_error))\n        norm_est_error = np.max(np.abs(est_error))\n        \n        # The problem is structured to ensure norm_est_error is non-zero.\n        ratio_R = norm_obs_error / norm_est_error\n        \n        delta = np.abs(ratio_R - 1.0)\n        results.append(delta)\n\n    # Print the final results in the specified single-line format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Moving from local error analysis to a global perspective, this practice addresses the crucial task of verifying a complete numerical solver for a partial differential equation. You will implement the \"Method of Manufactured Solutions,\" a powerful technique for assessing code correctness, to solve a 2D diffusion problem with spatially varying conductivityâ€”a common scenario in geophysical modeling . This comprehensive exercise guides you through the entire verification workflow, from discretizing a heterogeneous medium using a conservative scheme to performing a rigorous grid convergence study to confirm the global order of accuracy.",
            "id": "3592062",
            "problem": "Design and implement a program that performs a grid-convergence study for a heterogeneous diffusion problem on a two-dimensional structured grid, using a method consistent with second-order centered finite differences. The mathematical model is the steady diffusion equation with a spatially varying scalar conductivity. Let the bounded planar domain be the unit square $\\Omega = [0,1]^2$. Consider the boundary value problem\n$$\n- \\nabla \\cdot \\left( k(x,y) \\nabla u(x,y) \\right) = f(x,y) \\quad \\text{in } \\Omega,\\qquad u(x,y) = g(x,y) \\quad \\text{on } \\partial\\Omega ,\n$$\nwith a smooth, positive conductivity $k(x,y) > 0$, and Dirichlet boundary data $g(x,y) = u_{\\text{exact}}(x,y)$. Use the method of manufactured solutions: choose a smooth $u_{\\text{exact}}(x,y)$ and a smooth $k(x,y)$, then define $f(x,y)$ by the identity\n$$\nf(x,y) = -\\nabla \\cdot \\left( k(x,y)\\nabla u_{\\text{exact}}(x,y) \\right) = -\\left(k(x,y) \\, u_{xx}(x,y) + \\frac{\\partial k}{\\partial x}(x,y)\\, u_x(x,y) + k(x,y)\\, u_{yy}(x,y) + \\frac{\\partial k}{\\partial y}(x,y)\\, u_y(x,y)\\right),\n$$\nwhere subscripts denote partial derivatives. Take the manufactured exact solution\n$$\nu_{\\text{exact}}(x,y) = \\sin(\\pi x)\\sin(\\pi y).\n$$\nYou must discretize the operator $-\\nabla\\cdot(k\\nabla u)$ on a uniform Cartesian grid with mesh spacings $h_x$ and $h_y$ in the $x$ and $y$ directions, respectively, using a conservative, symmetric two-point flux approximation with face conductivities given by the harmonic average of nodal conductivities. Let the unknowns be placed at the interior grid nodes $\\{(x_i,y_j)\\}_{i=1,\\dots,N_x}^{j=1,\\dots,N_y}$ with $x_i=i\\,h_x$, $y_j=j\\,h_y$, and $h_x=1/(N_x+1)$, $h_y=1/(N_y+1)$. Enforce Dirichlet boundary conditions by setting boundary nodal values equal to $u_{\\text{exact}}$ and incorporating them into the right-hand side for interior equations. Assemble and solve the resulting linear system using a robust sparse direct method. After computing the numerical solution $u_h$ on the nodal grid (including the boundary where it equals $u_{\\text{exact}}$), evaluate the discrete error field $e_{i,j} = u_h(x_i,y_j) - u_{\\text{exact}}(x_i,y_j)$ on all grid nodes, and compute the following discrete error norms:\n$$\n\\|e\\|_{2,h} = \\left( h_x h_y \\sum_{i=0}^{N_x+1}\\sum_{j=0}^{N_y+1} e_{i,j}^2 \\right)^{1/2}, \\qquad \\|e\\|_{\\infty} = \\max_{0\\le i\\le N_x+1,\\,0\\le j\\le N_y+1} |e_{i,j}|.\n$$\nFor a sequence of grids with characteristic mesh size $h=\\max(h_x,h_y)$, compute the error norms and estimate the observed order of accuracy $p$ by fitting a straight line to the data $\\log(\\|e\\|)$ versus $\\log(h)$ using least squares; the slope gives an estimator of $p$. Use the natural logarithm.\n\nYour program must implement and report the observed convergence rates for the three test cases below. In all cases, use the exact solution specified above, set $g=u_{\\text{exact}}$ on $\\partial\\Omega$, and define $f$ from the identity provided. Each test case defines a conductivity field and a family of grids.\n\n- Test Case A (smooth, mildly varying conductivity): $k(x,y)=1+x+y$. Use square grids with $(N_x,N_y)\\in\\{(16,16),(32,32),(64,64),(128,128)\\}$.\n- Test Case B (smooth, rapidly varying but analytic conductivity): $k(x,y)=\\exp(x+y)$. Use square grids with $(N_x,N_y)\\in\\{(16,16),(32,32),(64,64),(128,128)\\}$.\n- Test Case C (smooth, oscillatory conductivity and anisotropic grids): $k(x,y)=1+\\tfrac{1}{2}\\sin(5\\pi x)\\sin(5\\pi y)$. Use rectangular grids with $(N_x,N_y)\\in\\{(12,24),(24,48),(48,96),(96,192)\\}$.\n\nFor each test case, compute the observed order $p_2$ from the slope of $\\log(\\|e\\|_{2,h})$ against $\\log(h)$ and $p_{\\infty}$ from the slope of $\\log(\\|e\\|_{\\infty})$ against $\\log(h)$. Your program should produce a single line of output containing the six slopes for the three test cases in the following order: $[p_2^{\\text{A}},p_{\\infty}^{\\text{A}},p_2^{\\text{B}},p_{\\infty}^{\\text{B}},p_2^{\\text{C}},p_{\\infty}^{\\text{C}}]$. Express each slope as a floating-point number rounded to $3$ decimals. No physical units are required.\n\nYour discretization and solver choices must be scientifically sound and consistent with the stated model and numerical method. The implementation should not accept any external input and must run as-is to completion. The test suite covers a general smooth case, a rapidly varying smooth case, and an anisotropic grid with oscillatory smooth coefficients to probe both the asymptotic regime and potential sensitivity to grid anisotropy. The expected observed order for the smooth cases is near $2$ provided the discretization is second order; deviations in the most oscillatory case on the coarsest levels may occur but should trend toward $2$ as $h\\to 0$.",
            "solution": "The user-provided problem is assessed to be valid. It is a well-posed problem in computational science, grounded in the established principles of numerical analysis for partial differential equations. The problem is self-contained, with all necessary parameters, equations, and methods clearly specified. No scientific, factual, or logical inconsistencies are present. The task is to perform a grid-convergence study, a standard verification technique, for a second-order finite difference discretization of a steady-state diffusion equation with variable coefficients. The specified methodology, including the use of a manufactured solution, a conservative flux approximation with harmonic averaging, and log-log regression for convergence rate estimation, is scientifically sound and appropriate for the problem.\n\n### 1. Mathematical Model\n\nThe physical process is described by the two-dimensional steady-state diffusion equation with a spatially varying scalar conductivity $k(x,y)$. The governing partial differential equation (PDE) on the unit square domain $\\Omega = [0,1]^2$ is:\n$$\n- \\nabla \\cdot \\left( k(x,y) \\nabla u(x,y) \\right) = f(x,y) \\quad \\text{in } \\Omega\n$$\nThis equation is subject to Dirichlet boundary conditions:\n$$\nu(x,y) = g(x,y) \\quad \\text{on } \\partial\\Omega\n$$\nThe problem employs the method of manufactured solutions for verification. A smooth, exact solution $u_{\\text{exact}}(x,y) = \\sin(\\pi x)\\sin(\\pi y)$ is chosen. The source term $f(x,y)$ and boundary conditions $g(x,y)$ are then derived from this exact solution to ensure consistency. The boundary condition is set to $g(x,y) = u_{\\text{exact}}(x,y)$ on $\\partial\\Omega$. The source term $f(x,y)$ is obtained by applying the differential operator to the manufactured solution:\n$$\nf(x,y) = -\\nabla \\cdot \\left( k(x,y)\\nabla u_{\\text{exact}}(x,y) \\right)\n$$\nExpanding the divergence operator yields the explicit form of the source term:\n$$\nf(x,y) = -\\left(\\frac{\\partial k}{\\partial x}\\frac{\\partial u_{\\text{exact}}}{\\partial x} + k \\frac{\\partial^2 u_{\\text{exact}}}{\\partial x^2} + \\frac{\\partial k}{\\partial y}\\frac{\\partial u_{\\text{exact}}}{\\partial y} + k \\frac{\\partial^2 u_{\\text{exact}}}{\\partial y^2}\\right)\n$$\nSubstituting the partial derivatives of $u_{\\text{exact}}(x,y)$ gives:\n$$\nf(x,y) = 2\\pi^2 k(x,y) \\sin(\\pi x)\\sin(\\pi y) - \\pi \\frac{\\partial k}{\\partial x} \\cos(\\pi x)\\sin(\\pi y) - \\pi \\frac{\\partial k}{\\partial y} \\sin(\\pi x)\\cos(\\pi y)\n$$\n\n### 2. Finite Difference Discretization\nThe domain $\\Omega$ is discretized using a uniform Cartesian grid with nodes $(x_i, y_j)$, where $x_i = i h_x$ for $i=0, \\dots, N_x+1$ and $y_j = j h_y$ for $j=0, \\dots, N_y+1$. The grid spacings are $h_x = 1/(N_x+1)$ and $h_y = 1/(N_y+1)$. The unknowns are the values of $u$ at the $N_x \\times N_y$ interior nodes.\n\nThe PDE is discretized using a conservative finite difference scheme based on a control volume approach. Integrating the PDE over a control volume $\\Omega_{i,j}$ centered at an interior node $(x_i, y_j)$ and applying the divergence theorem, we obtain:\n$$\n- \\oint_{\\partial\\Omega_{i,j}} (k \\nabla u) \\cdot \\vec{n} \\,ds = \\iint_{\\Omega_{i,j}} f \\,dA \\approx f(x_i,y_j) h_x h_y\n$$\nThe flux integral on the left is approximated by summing the fluxes across the four faces of the control volume. The flux across the face at $x = x_{i+1/2}$ is approximated using a centered difference for the gradient and a specific average for the conductivity. The problem specifies a symmetric two-point flux approximation with the harmonic average for the face conductivity:\n$$\n-k(x_{i+1/2}, y_j) \\frac{u(x_{i+1},y_j) - u(x_i,y_j)}{h_x} h_y\n$$\nThe face conductivity $k_{i+1/2,j} = k(x_{i+1/2},y_j)$ is approximated by the harmonic mean of the conductivities at the adjacent nodes:\n$$\nk_{i+1/2, j} \\approx \\frac{2 k(x_i,y_j) k(x_{i+1},y_j)}{k(x_i,y_j) + k(x_{i+1},y_j)}\n$$\nThis choice is crucial for accurately modeling fluxes in heterogeneous media. Applying this approximation to all four faces and dividing by the control volume area $h_x h_y$ yields the discrete equation at node $(i,j)$:\n$$\n-\\frac{1}{h_x^2} \\left[ k_{i+1/2, j} (u_{i+1,j} - u_{i,j}) - k_{i-1/2, j} (u_{i,j} - u_{i-1,j}) \\right] - \\frac{1}{h_y^2} \\left[ k_{i, j+1/2} (u_{i,j+1} - u_{i,j}) - k_{i, j-1/2} (u_{i,j} - u_{i,j-1}) \\right] = f_{i,j}\n$$\nThis scheme results in a 5-point stencil, which is second-order accurate for smooth solutions and coefficients.\n\n### 3. Linear System Formulation\nRearranging the discrete equation collects terms associated with each nodal unknown $u_{i,j}$. This yields a large, sparse system of linear equations of the form $A\\vec{U} = \\vec{b}$, where $\\vec{U}$ is a vector of the $N=N_x N_y$ unknown interior nodal values.\nThe matrix $A$ is an $N \\times N$ sparse matrix. For a row-major ordering of unknowns, $k=(j-1)N_x + (i-1)$, the matrix has a block-tridiagonal structure with five non-zero diagonals. The diagonal entry for the equation at node $(i,j)$ is:\n$$\nA_{k,k} = \\frac{k_{i+1/2, j} + k_{i-1/2, j}}{h_x^2} + \\frac{k_{i, j+1/2} + k_{i, j-1/2}}{h_y^2}\n$$\nand the off-diagonal entries corresponding to neighboring nodes are:\n$$\nA_{k,k-1} = -\\frac{k_{i-1/2, j}}{h_x^2}, \\quad A_{k,k+1} = -\\frac{k_{i+1/2, j}}{h_x^2}, \\quad A_{k,k-N_x} = -\\frac{k_{i,j-1/2}}{h_y^2}, \\quad A_{k,k+N_x} = -\\frac{k_{i,j+1/2}}{h_y^2}\n$$\nThe matrix $A$ is symmetric and positive definite, which guarantees a unique solution.\nThe right-hand side vector $\\vec{b}$ contains the source terms $f_{i,j}$ and contributions from the Dirichlet boundary conditions. For an interior node $(i,j)$ adjacent to a boundary (e.g., at $i=1$), the term involving the known boundary value $u_{0,j} = g(x_0, y_j)$ is moved to the right-hand side. For example, the term $-A_{k,k-1}u_{0,j}$ becomes $+\\frac{k_{1/2,j}}{h_x^2}u_{0,j}$ added to $b_k$. The resulting linear system is solved using a sparse direct solver, as specified.\n\n### 4. Error Analysis and Convergence Rate\nAfter solving for the numerical solution $u_h$ on the interior nodes, the solution is extended to the whole grid by including the known boundary values. The error is computed as the difference between the numerical and exact solutions, $e_{i,j} = u_h(x_i,y_j) - u_{\\text{exact}}(x_i,y_j)$, at all nodes. The magnitude of the error is quantified using two discrete norms:\n- The discrete $L_2$-norm: $\\|e\\|_{2,h} = \\left( h_x h_y \\sum_{i=0}^{N_x+1}\\sum_{j=0}^{N_y+1} e_{i,j}^2 \\right)^{1/2}$\n- The discrete $L_{\\infty}$-norm (maximum error): $\\|e\\|_{\\infty} = \\max_{0\\le i\\le N_x+1,\\,0\\le j\\le N_y+1} |e_{i,j}|$\n\nFor a method with an order of accuracy $p$, the error is expected to behave as $\\|e\\| \\approx C h^p$ for some constant $C$, where $h = \\max(h_x, h_y)$ is the characteristic mesh size. To estimate $p$, we take the natural logarithm of this relation:\n$$\n\\ln(\\|e\\|) \\approx \\ln(C) + p \\ln(h)\n$$\nThis shows a linear relationship between $\\ln(\\|e\\|)$ and $\\ln(h)$. By computing the errors on a sequence of successively refined grids, we obtain a set of data points $(\\ln(h_k), \\ln(\\|e\\|_k))$. The observed order of accuracy $p$ is estimated as the slope of a straight line fitted to these points using the method of least squares. For each test case, we compute $p_2$ from the $L_2$-norm data and $p_{\\infty}$ from the $L_{\\infty}$-norm data.",
            "answer": "```python\nimport numpy as np\nimport scipy\nfrom scipy.sparse import lil_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    test_cases = {\n        'A': {\n            'grids': [(16, 16), (32, 32), (64, 64), (128, 128)],\n        },\n        'B': {\n            'grids': [(16, 16), (32, 32), (64, 64), (128, 128)],\n        },\n        'C': {\n            'grids': [(12, 24), (24, 48), (48, 96), (96, 192)],\n        },\n    }\n\n    results = []\n    \n    for case_id in ['A', 'B', 'C']:\n        grids = test_cases[case_id]['grids']\n        p2, pinf = compute_convergence_rates(case_id, grids)\n        results.extend([round(p2, 3), round(pinf, 3)])\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\ndef get_problem_functions(case_id):\n    \"\"\"\n    Returns the conductivity, exact solution, and source term functions for a given case.\n    \"\"\"\n    pi = np.pi\n    if case_id == 'A':\n        k = lambda x, y: 1 + x + y\n        kx = lambda x, y: 1.0 + 0 * x  # Use 0*x to handle array inputs\n        ky = lambda x, y: 1.0 + 0 * y\n    elif case_id == 'B':\n        k = lambda x, y: np.exp(x + y)\n        kx = lambda x, y: np.exp(x + y)\n        ky = lambda x, y: np.exp(x + y)\n    elif case_id == 'C':\n        k = lambda x, y: 1 + 0.5 * np.sin(5*pi*x) * np.sin(5*pi*y)\n        kx = lambda x, y: 0.5 * 5*pi * np.cos(5*pi*x) * np.sin(5*pi*y)\n        ky = lambda x, y: 0.5 * 5*pi * np.sin(5*pi*x) * np.cos(5*pi*y)\n    \n    u_exact = lambda x, y: np.sin(pi*x) * np.sin(pi*y)\n    \n    f_source = lambda x, y: (2 * pi**2 * k(x, y) * np.sin(pi*x) * np.sin(pi*y) -\n                           pi * kx(x, y) * np.cos(pi*x) * np.sin(pi*y) -\n                           pi * ky(x, y) * np.sin(pi*x) * np.cos(pi*y))\n\n    return k, u_exact, f_source\n\ndef harmonic_mean(k1, k2):\n    \"\"\"Computes the harmonic mean of two values.\"\"\"\n    return 2 * k1 * k2 / (k1 + k2)\n\ndef compute_convergence_rates(case_id, grid_resolutions):\n    \"\"\"\n    Performs the grid convergence study for a single test case.\n    \"\"\"\n    k_func, u_exact_func, f_func = get_problem_functions(case_id)\n    \n    h_vals, e2_norms, einf_norms = [], [], []\n\n    for Nx, Ny in grid_resolutions:\n        hx = 1.0 / (Nx + 1)\n        hy = 1.0 / (Ny + 1)\n        h_vals.append(max(hx, hy))\n\n        # Set up grid and evaluate functions\n        x_nodes = np.linspace(0, 1, Nx + 2)\n        y_nodes = np.linspace(0, 1, Ny + 2)\n        xv, yv = np.meshgrid(x_nodes, y_nodes, indexing='xy')\n\n        u_exact_grid = u_exact_func(xv, yv)\n        k_grid = k_func(xv, yv)\n        \n        # Assemble linear system\n        num_unknowns = Nx * Ny\n        A = lil_matrix((num_unknowns, num_unknowns))\n        b = np.zeros(num_unknowns)\n\n        for j in range(1, Ny + 1):\n            for i in range(1, Nx + 1):\n                idx = (j - 1) * Nx + (i - 1)\n                b[idx] = f_func(x_nodes[i], y_nodes[j])\n                \n                # West face\n                k_W = harmonic_mean(k_grid[j, i], k_grid[j, i-1])\n                c_W = k_W / hx**2\n                if i == 1:\n                    b[idx] += c_W * u_exact_grid[j, 0]\n                else:\n                    A[idx, idx - 1] = -c_W\n                \n                # East face\n                k_E = harmonic_mean(k_grid[j, i], k_grid[j, i+1])\n                c_E = k_E / hx**2\n                if i == Nx:\n                    b[idx] += c_E * u_exact_grid[j, Nx+1]\n                else:\n                    A[idx, idx + 1] = -c_E\n                    \n                # South face\n                k_S = harmonic_mean(k_grid[j, i], k_grid[j-1, i])\n                c_S = k_S / hy**2\n                if j == 1:\n                    b[idx] += c_S * u_exact_grid[0, i]\n                else:\n                    A[idx, idx - Nx] = -c_S\n\n                # North face\n                k_N = harmonic_mean(k_grid[j, i], k_grid[j+1, i])\n                c_N = k_N / hy**2\n                if j == Ny:\n                    b[idx] += c_N * u_exact_grid[Ny+1, i]\n                else:\n                    A[idx, idx + Nx] = -c_N\n\n                A[idx, idx] = c_W + c_E + c_S + c_N\n        \n        # Solve system and reconstruct solution\n        u_interior = spsolve(A.tocsc(), b)\n        u_h = np.copy(u_exact_grid)\n        u_h[1:-1, 1:-1] = u_interior.reshape((Ny, Nx))\n        \n        # Compute and store errors\n        error_grid = u_h - u_exact_grid\n        einf_norms.append(np.max(np.abs(error_grid)))\n        e2_norms.append(np.sqrt(hx * hy * np.sum(error_grid**2)))\n    \n    # Calculate convergence rates via linear regression on log-log data\n    log_h = np.log(np.array(h_vals))\n    p2, _ = np.polyfit(log_h, np.log(np.array(e2_norms)), 1)\n    pinf, _ = np.polyfit(log_h, np.log(np.array(einf_norms)), 1)\n    \n    return p2, pinf\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "For wave propagation problems, which are central to computational geophysics, simply confirming the order of convergence is insufficient; we must also analyze how accurately the scheme propagates waves of different wavelengths. This property, known as numerical dispersion, can introduce significant, unphysical errors into simulations if not properly controlled. This final practice delves into this critical topic, using Fourier analysis to relate the phase error of a scheme to its discretization parameters and ultimately determine the grid resolution required to maintain simulation fidelity .",
            "id": "3592024",
            "problem": "Consider the one-dimensional constant-coefficient acoustic wave equation $\\,\\partial_{t}^{2} u(x,t) = c^{2}\\,\\partial_{x}^{2} u(x,t)\\,$ on an infinite uniform grid with spacing $\\,h\\,$. The spatial second derivative is approximated by a centered, order-$\\,2p\\,$ finite-difference stencil on a structured grid. Let $\\,\\theta = k h\\,$ denote the nondimensional wavenumber, where $\\,k\\,$ is the continuous wavenumber, and let $\\,\\widehat{L}(\\theta)\\,$ be the Fourier symbol of the semi-discrete second-derivative operator. Define the modified wavenumber $\\,\\widetilde{k}(\\theta)\\,$ by $\\, -\\widehat{L}(\\theta) = \\widetilde{k}(\\theta)^{2}\\,$. For a $\\,2p\\,$-order accurate centered second-derivative stencil, Taylor expansion about $\\,\\theta=0\\,$ implies that\n$$\n\\widetilde{k}(\\theta)^{2} = k^{2}\\,\\Big(1 - C_{2p}\\,\\theta^{2p} + \\mathcal{O}(\\theta^{2p+2})\\Big),\n$$\nwhere $\\,C_{2p} > 0\\,$ is a constant that depends only on the stencil order $\\,2p\\,$.\n\nA plane-wave ansatz $\\,u(x,t) = \\exp\\!\\big(i(k x - \\omega t)\\big)\\,$ satisfies the semi-discrete dispersion relation $\\,\\omega^{2} = c^{2}\\,\\widetilde{k}(\\theta)^{2}\\,$, which induces a phase velocity $\\,v_{p} = \\omega/k\\,$. Define the phase error as the relative deviation of phase velocity from the continuous wave speed $\\,c\\,$, namely $\\,E_{p}(\\theta) = \\big|v_{p}/c - 1\\big|\\,$.\n\nUsing only the stated foundations and asymptotic consistency at small $\\,\\theta\\,$, derive, to leading order in small $\\,\\varepsilon\\,$, a closed-form asymptotic expression for the minimal number of grid points per wavelength $\\,n_{\\lambda}\\,$ required to ensure $\\,E_{p}(\\theta) \\le \\varepsilon\\,$. Here, the points per wavelength are defined by $\\,n_{\\lambda} = 2\\pi/\\theta\\,$. Express your final answer as a single analytic expression in terms of $\\,p\\,$, $\\,\\varepsilon\\,$, and $\\,C_{2p}\\,$. No numerical substitution is required. The final answer must be a single expression and must not contain any inequalities or units.",
            "solution": "The problem is first assessed for validity.\n\n### Step 1: Extract Givens\n- **Governing Equation**: One-dimensional constant-coefficient acoustic wave equation, $\\partial_{t}^{2} u(x,t) = c^{2}\\,\\partial_{x}^{2} u(x,t)$.\n- **Discretization**: Infinite uniform grid with spacing $h$. Spatial second derivative is approximated by a centered, order-$2p$ finite-difference stencil.\n- **Nondimensional Wavenumber**: $\\theta = k h$, where $k$ is the continuous wavenumber.\n- **Fourier Symbol and Modified Wavenumber**: The Fourier symbol of the semi-discrete second-derivative operator is $\\widehat{L}(\\theta)$. The modified wavenumber $\\widetilde{k}(\\theta)$ is defined by $-\\widehat{L}(\\theta) = \\widetilde{k}(\\theta)^{2}$.\n- **Asymptotic Form**: For small $\\theta$, the modified wavenumber squared has the expansion $\\widetilde{k}(\\theta)^{2} = k^{2}\\,\\Big(1 - C_{2p}\\,\\theta^{2p} + \\mathcal{O}(\\theta^{2p+2})\\Big)$, with $C_{2p} > 0$.\n- **Dispersion Relation**: A plane-wave ansatz leads to the semi-discrete dispersion relation $\\omega^{2} = c^{2}\\,\\widetilde{k}(\\theta)^{2}$.\n- **Phase Velocity and Error**: The phase velocity is $v_{p} = \\omega/k$. The phase error is defined as $E_{p}(\\theta) = \\big|v_{p}/c - 1\\big|$.\n- **Constraint**: The phase error must satisfy $E_{p}(\\theta) \\le \\varepsilon$.\n- **Points Per Wavelength**: Defined as $n_{\\lambda} = 2\\pi/\\theta$.\n- **Objective**: Derive a closed-form asymptotic expression for the minimal number of grid points per wavelength, $n_{\\lambda}$, required to satisfy the error constraint. The expression must be to leading order in small $\\varepsilon$ and be in terms of $p$, $\\varepsilon$, and $C_{2p}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically grounded, well-posed, and objective. It outlines a standard numerical dispersion analysis for finite-difference methods, a fundamental topic in computational science and engineering. All terms are clearly defined, and the premises are consistent with established theory. The problem is formalizable and contains sufficient information to derive a unique solution. It does not violate any scientific principles, is not based on false premises, and contains no ambiguities.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be derived.\n\n### Derivation of the Solution\nThe objective is to find the minimal number of grid points per wavelength, $n_{\\lambda}$, such that the phase error $E_{p}(\\theta)$ does not exceed a specified tolerance $\\varepsilon$. The number of points per wavelength $n_{\\lambda}$ is inversely proportional to the nondimensional wavenumber $\\theta$ through the relation $n_{\\lambda} = 2\\pi/\\theta$. Therefore, finding the minimum $n_{\\lambda}$ is equivalent to finding the maximum permissible $\\theta$.\n\nWe begin with the semi-discrete dispersion relation:\n$$\n\\omega^{2} = c^{2}\\,\\widetilde{k}(\\theta)^{2}\n$$\nSubstituting the given asymptotic expression for $\\widetilde{k}(\\theta)^{2}$:\n$$\n\\omega^{2} = c^{2}\\,k^{2}\\,\\Big(1 - C_{2p}\\,\\theta^{2p} + \\mathcal{O}(\\theta^{2p+2})\\Big)\n$$\nTo find the phase velocity $v_p = \\omega/k$, we first solve for the angular frequency $\\omega$. Taking the positive square root (as frequency is non-negative):\n$$\n\\omega = c k \\sqrt{1 - C_{2p}\\,\\theta^{2p} + \\mathcal{O}(\\theta^{2p+2})}\n$$\nThe numerical phase velocity is then:\n$$\nv_{p}(\\theta) = \\frac{\\omega}{k} = c \\sqrt{1 - C_{2p}\\,\\theta^{2p} + \\mathcal{O}(\\theta^{2p+2})}\n$$\nNext, we compute the ratio of the numerical phase velocity to the true wave speed $c$:\n$$\n\\frac{v_{p}(\\theta)}{c} = \\sqrt{1 - C_{2p}\\,\\theta^{2p} + \\mathcal{O}(\\theta^{2p+2})}\n$$\nThe problem requires an analysis for small $\\varepsilon$, which implies that the deviation from the true speed is small. This corresponds to the regime where $\\theta$ is small. We can therefore use a Taylor series expansion for the square root function, $\\sqrt{1+x} \\approx 1 + \\frac{1}{2}x$ for small $x$. Let $x = - C_{2p}\\,\\theta^{2p}$. For small $\\theta$, this term is small.\n$$\n\\frac{v_{p}(\\theta)}{c} \\approx 1 - \\frac{1}{2} C_{2p}\\,\\theta^{2p}\n$$\nThe phase error $E_{p}(\\theta)$ is defined as $E_{p}(\\theta) = |v_{p}/c - 1|$. Using the leading-order approximation derived above:\n$$\nE_{p}(\\theta) = \\left| \\left(1 - \\frac{1}{2} C_{2p}\\,\\theta^{2p}\\right) - 1 \\right| = \\left| -\\frac{1}{2} C_{2p}\\,\\theta^{2p} \\right|\n$$\nSince it is given that $C_{2p} > 0$, the expression inside the absolute value is negative for $\\theta > 0$. Thus, to leading order:\n$$\nE_{p}(\\theta) \\approx \\frac{1}{2} C_{2p}\\,\\theta^{2p}\n$$\nNow, we enforce the error constraint $E_{p}(\\theta) \\le \\varepsilon$. To find the minimal $n_{\\lambda}$, we must find the maximum allowable $\\theta$, which will occur at the boundary of this inequality:\n$$\n\\frac{1}{2} C_{2p}\\,\\theta^{2p} = \\varepsilon\n$$\nWe solve this equation for $\\theta$:\n$$\n\\theta^{2p} = \\frac{2\\varepsilon}{C_{2p}}\n$$\n$$\n\\theta = \\left(\\frac{2\\varepsilon}{C_{2p}}\\right)^{\\frac{1}{2p}}\n$$\nThis value of $\\theta$ represents the largest nondimensional wavenumber for which the phase error is approximately $\\varepsilon$.\nFinally, we substitute this expression for $\\theta$ into the definition of the number of grid points per wavelength, $n_{\\lambda} = 2\\pi/\\theta$, to find the minimum required value of $n_{\\lambda}$:\n$$\nn_{\\lambda} = \\frac{2\\pi}{\\left(\\frac{2\\varepsilon}{C_{2p}}\\right)^{\\frac{1}{2p}}}\n$$\nSimplifying the expression by inverting the term in the denominator:\n$$\nn_{\\lambda} = 2\\pi \\left(\\frac{C_{2p}}{2\\varepsilon}\\right)^{\\frac{1}{2p}}\n$$\nThis is the desired closed-form asymptotic expression for the minimal number of grid points per wavelength required to ensure the phase error is no more than $\\varepsilon$, valid to leading order for small $\\varepsilon$. The expression depends on the stencil order parameter $p$, the error tolerance $\\varepsilon$, and the stencil-dependent constant $C_{2p}$, as required.",
            "answer": "$$\n\\boxed{2\\pi \\left(\\frac{C_{2p}}{2\\varepsilon}\\right)^{\\frac{1}{2p}}}\n$$"
        }
    ]
}