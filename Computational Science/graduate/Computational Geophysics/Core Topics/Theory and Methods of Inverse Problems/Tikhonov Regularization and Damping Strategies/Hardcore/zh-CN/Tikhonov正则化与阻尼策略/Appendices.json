{
    "hands_on_practices": [
        {
            "introduction": "这个练习旨在通过一个简单的低维系统来建立直观理解。通过直接计算和比较正则化解与非正则化解，你将能清晰地观察到阻尼参数 $\\lambda$、正则化算子 $L$ 以及参考模型 $m_{\\text{ref}}$ 是如何协同作用以稳定反演过程并影响最终解的。这个基础练习将为你掌握吉洪诺夫正则化的核心机制奠定坚实基础 ()。",
            "id": "3617477",
            "problem": "考虑计算地球物理学中的线性反演问题，其中观测数据 $\\mathbf{d} \\in \\mathbb{R}^n$ 通过作用于模型参数 $\\mathbf{m} \\in \\mathbb{R}^p$ 的线性正演算子 $\\mathbf{G} \\in \\mathbb{R}^{n \\times p}$ 进行建模，并带有加性噪声 $\\boldsymbol{\\epsilon}$，使得 $\\mathbf{d} = \\mathbf{G}\\mathbf{m} + \\boldsymbol{\\epsilon}$。为稳定反演过程，引入一个 Tikhonov 正则化目标函数，该函数平衡了数据失配和阻尼策略：\n$$\nJ(\\mathbf{m}) = \\|\\mathbf{G}\\mathbf{m} - \\mathbf{d}\\|_2^2 + \\lambda^2 \\|\\mathbf{L}(\\mathbf{m} - \\mathbf{m}_{\\mathrm{ref}})\\|_2^2,\n$$\n其中 $\\lambda \\ge 0$ 是阻尼（正则化）参数，$\\mathbf{L} \\in \\mathbb{R}^{q \\times p}$ 是一个阻尼（或粗糙度）算子，$\\mathbf{m}_{\\mathrm{ref}} \\in \\mathbb{R}^p$ 是一个参考模型。非正则化最小二乘解通过仅最小化 $\\|\\mathbf{G}\\mathbf{m} - \\mathbf{d}\\|_2^2$ 获得。\n\n您的任务是计算 Tikhonov 正则化解 $\\mathbf{m}_{\\mathrm{Tik}}$，并将其与非正则化最小二乘解 $\\mathbf{m}_{\\mathrm{LS}}$ 进行比较，以应对以下测试集。对于每个测试案例，使用欧几里得 $2$-范数计算差异量级 $\\|\\mathbf{m}_{\\mathrm{Tik}} - \\mathbf{m}_{\\mathrm{LS}}\\|_2$。不涉及物理单位。所有计算均以纯数值形式进行。\n\n测试集：\n- 案例 1（理想情况，零阶阻尼）：$\\mathbf{G} = \\begin{bmatrix}1  0\\\\ 0  0.1\\end{bmatrix}$，$\\mathbf{d} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$，$\\lambda = 0.2$，$\\mathbf{L} = \\mathbf{I}_{2 \\times 2}$，$\\mathbf{m}_{\\mathrm{ref}} = \\begin{bmatrix}0\\\\ 0\\end{bmatrix}$。\n- 案例 2（边界条件，无阻尼）：$\\mathbf{G} = \\begin{bmatrix}1  0\\\\ 0  0.1\\end{bmatrix}$，$\\mathbf{d} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$，$\\lambda = 0$，$\\mathbf{L} = \\mathbf{I}_{2 \\times 2}$，$\\mathbf{m}_{\\mathrm{ref}} = \\begin{bmatrix}0\\\\ 0\\end{bmatrix}$。\n- 案例 3（强阻尼，零阶）：$\\mathbf{G} = \\begin{bmatrix}1  0\\\\ 0  0.1\\end{bmatrix}$，$\\mathbf{d} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$，$\\lambda = 2.0$，$\\mathbf{L} = \\mathbf{I}_{2 \\times 2}$，$\\mathbf{m}_{\\mathrm{ref}} = \\begin{bmatrix}0\\\\ 0\\end{bmatrix}$。\n- 案例 4（一阶平滑度阻尼）：$\\mathbf{G} = \\begin{bmatrix}1  0\\\\ 0  0.1\\end{bmatrix}$，$\\mathbf{d} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$，$\\lambda = 0.5$，$\\mathbf{L} = \\begin{bmatrix}-1  1\\end{bmatrix}$，$\\mathbf{m}_{\\mathrm{ref}} = \\begin{bmatrix}0\\\\ 0\\end{bmatrix}$。\n- 案例 5（向非零参考模型阻尼）：$\\mathbf{G} = \\begin{bmatrix}1  0\\\\ 0  0.1\\end{bmatrix}$，$\\mathbf{d} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$，$\\lambda = 0.5$，$\\mathbf{L} = \\mathbf{I}_{2 \\times 2}$，$\\mathbf{m}_{\\mathrm{ref}} = \\begin{bmatrix}0.5\\\\ 0\\end{bmatrix}$。\n\n算法要求：\n- 对于每个案例，通过最小化 $J(\\mathbf{m})$ 来计算 $\\mathbf{m}_{\\mathrm{Tik}}$，使用上述定义。\n- 使用适用于任意 $\\mathbf{G}$ 的稳健数值方法（例如，Moore–Penrose 伪逆或数值稳定的最小二乘求解器）计算作为非正则化最小二乘解的 $\\mathbf{m}_{\\mathrm{LS}}$。\n- 对于每个案例，报告 $5$ 个数字：$\\mathbf{m}_{\\mathrm{Tik}}$ 的两个分量、$\\mathbf{m}_{\\mathrm{LS}}$ 的两个分量，以及标量 $\\|\\mathbf{m}_{\\mathrm{Tik}} - \\mathbf{m}_{\\mathrm{LS}}\\|_2$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个测试案例由一个包含五个浮点数的子列表表示，顺序如上所述。例如，输出应如下所示：\n$$\n[\\,[m^{(1)}_{\\mathrm{Tik},1},m^{(1)}_{\\mathrm{Tik},2},m^{(1)}_{\\mathrm{LS},1},m^{(1)}_{\\mathrm{LS},2},\\Delta^{(1)}],\\,[m^{(2)}_{\\mathrm{Tik},1},m^{(2)}_{\\mathrm{Tik},2},m^{(2)}_{\\mathrm{LS},1},m^{(2)}_{\\mathrm{LS},2},\\Delta^{(2)}],\\,\\dots\\,]\n$$\n其中 $\\Delta^{(i)} = \\|\\mathbf{m}^{(i)}_{\\mathrm{Tik}} - \\mathbf{m}^{(i)}_{\\mathrm{LS}}\\|_2$。将报告的每个浮点数四舍五入到六位小数。程序不得打印任何附加文本。",
            "solution": "在进行求解之前，需对问题进行验证。\n\n### 步骤 1：提取已知条件\n该问题描述了一个线性反演问题 $\\mathbf{d} = \\mathbf{G}\\mathbf{m} + \\boldsymbol{\\epsilon}$，其中 $\\mathbf{d} \\in \\mathbb{R}^n$，$\\mathbf{G} \\in \\mathbb{R}^{n \\times p}$，$\\mathbf{m} \\in \\mathbb{R}^p$。\nTikhonov 正则化目标函数由下式给出：\n$$\nJ(\\mathbf{m}) = \\|\\mathbf{G}\\mathbf{m} - \\mathbf{d}\\|_2^2 + \\lambda^2 \\|\\mathbf{L}(\\mathbf{m} - \\mathbf{m}_{\\mathrm{ref}})\\|_2^2\n$$\n其中 $\\lambda \\ge 0$ 是阻尼参数，$\\mathbf{L} \\in \\mathbb{R}^{q \\times p}$ 是阻尼算子，$\\mathbf{m}_{\\mathrm{ref}} \\in \\mathbb{R}^p$ 是参考模型。\n\n任务是计算 Tikhonov 正则化解 $\\mathbf{m}_{\\mathrm{Tik}}$ 和非正则化最小二乘解 $\\mathbf{m}_{\\mathrm{LS}}$，以及它们之间差的欧几里得范数 $\\|\\mathbf{m}_{\\mathrm{Tik}} - \\mathbf{m}_{\\mathrm{LS}}\\|_2$。\n\n测试集提供了以下数据：\n- **案例 1**：$\\mathbf{G} = \\begin{bmatrix}1  0\\\\ 0  0.1\\end{bmatrix}$，$\\mathbf{d} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$，$\\lambda = 0.2$，$\\mathbf{L} = \\mathbf{I}_{2 \\times 2}$，$\\mathbf{m}_{\\mathrm{ref}} = \\begin{bmatrix}0\\\\ 0\\end{bmatrix}$。\n- **案例 2**：$\\mathbf{G} = \\begin{bmatrix}1  0\\\\ 0  0.1\\end{bmatrix}$，$\\mathbf{d} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$，$\\lambda = 0$，$\\mathbf{L} = \\mathbf{I}_{2 \\times 2}$，$\\mathbf{m}_{\\mathrm{ref}} = \\begin{bmatrix}0\\\\ 0\\end{bmatrix}$。\n- **案例 3**：$\\mathbf{G} = \\begin{bmatrix}1  0\\\\ 0  0.1\\end{bmatrix}$，$\\mathbf{d} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$，$\\lambda = 2.0$，$\\mathbf{L} = \\mathbf{I}_{2 \\times 2}$，$\\mathbf{m}_{\\mathrm{ref}} = \\begin{bmatrix}0\\\\ 0\\end{bmatrix}$。\n- **案例 4**：$\\mathbf{G} = \\begin{bmatrix}1  0\\\\ 0  0.1\\end{bmatrix}$，$\\mathbf{d} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$，$\\lambda = 0.5$，$\\mathbf{L} = \\begin{bmatrix}-1  1\\end{bmatrix}$，$\\mathbf{m}_{\\mathrm{ref}} = \\begin{bmatrix}0\\\\ 0\\end{bmatrix}$。\n- **案例 5**：$\\mathbf{G} = \\begin{bmatrix}1  0\\\\ 0  0.1\\end{bmatrix}$，$\\mathbf{d} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$，$\\lambda = 0.5$，$\\mathbf{L} = \\mathbf{I}_{2 \\times 2}$，$\\mathbf{m}_{\\mathrm{ref}} = \\begin{bmatrix}0.5\\\\ 0\\end{bmatrix}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n1.  **科学依据**：该问题是线性反演理论和正则化的标准练习，是计算地球物理学和许多其他科学领域的基石。Tikhonov 正则化框架是一种成熟的基础方法。该问题具有科学合理性。\n2.  **适定性**：该问题为正则化和非正则化情况提供了计算唯一解所需的所有矩阵、向量和参数。目标函数是凸的和二次的，确保了唯一最小化子的存在，并且可以通过求解线性方程组找到。\n3.  **客观性**：问题以精确的数学语言陈述，没有歧义或主观性。\n4.  **完整性与一致性**：每个测试案例的所有参数都已明确定义。矩阵和向量的维度对于所有指定的操作都是一致的（例如，对于 $\\mathbf{G} \\in \\mathbb{R}^{2 \\times 2}$ 和 $\\mathbf{m} \\in \\mathbb{R}^2$，$\\mathbf{G}\\mathbf{m}$ 是良定义的）。对于案例 4，$\\mathbf{L} \\in \\mathbb{R}^{1 \\times 2}$ 和 $\\mathbf{m} \\in \\mathbb{R}^2$，因此 $\\mathbf{L}\\mathbf{m}$ 是一个标量，也是良定义的。\n5.  **无其他缺陷**：问题并非微不足道、不切实际或病态的。它提出了一个标准的计算任务。\n\n### 步骤 3：结论与行动\n问题是有效的。将提供完整解答。\n\n### 求解推导\n\n求解需要找到使两个不同目标函数最小化的模型参数 $\\mathbf{m}$。\n\n**1. 非正则化最小二乘解 ($\\mathbf{m}_{\\mathrm{LS}}$)**\n\n非正则化最小二乘解 $\\mathbf{m}_{\\mathrm{LS}}$ 最小化数据失配：\n$$J_{\\mathrm{LS}}(\\mathbf{m}) = \\|\\mathbf{G}\\mathbf{m} - \\mathbf{d}\\|_2^2$$\n为了找到最小值，我们计算 $J_{\\mathrm{LS}}$ 相对于 $\\mathbf{m}$ 的梯度并将其设为零。\n$$J_{\\mathrm{LS}}(\\mathbf{m}) = (\\mathbf{G}\\mathbf{m} - \\mathbf{d})^T(\\mathbf{G}\\mathbf{m} - \\mathbf{d}) = \\mathbf{m}^T\\mathbf{G}^T\\mathbf{G}\\mathbf{m} - 2\\mathbf{d}^T\\mathbf{G}\\mathbf{m} + \\mathbf{d}^T\\mathbf{d}$$\n梯度为：\n$$\\nabla_{\\mathbf{m}} J_{\\mathrm{LS}}(\\mathbf{m}) = 2\\mathbf{G}^T\\mathbf{G}\\mathbf{m} - 2\\mathbf{G}^T\\mathbf{d}$$\n将梯度设为零，我们得到正规方程组：\n$$(\\mathbf{G}^T\\mathbf{G})\\mathbf{m} = \\mathbf{G}^T\\mathbf{d}$$\n解 $\\mathbf{m}_{\\mathrm{LS}}$ 由下式给出：\n$$\\mathbf{m}_{\\mathrm{LS}} = (\\mathbf{G}^T\\mathbf{G})^{-1}\\mathbf{G}^T\\mathbf{d}$$\n这是经典的最小二乘解，可以使用 Moore-Penrose 伪逆 $\\mathbf{G}^\\dagger$ 进行稳健计算，使得 $\\mathbf{m}_{\\mathrm{LS}} = \\mathbf{G}^\\dagger\\mathbf{d}$。\n\n在我们的具体问题中，$\\mathbf{G} = \\begin{bmatrix}1  0\\\\ 0  0.1\\end{bmatrix}$ 和 $\\mathbf{d} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$。\n$\\mathbf{G}$ 是可逆的，所以 $\\mathbf{m}_{\\mathrm{LS}} = \\mathbf{G}^{-1}\\mathbf{d}$。\n$\\mathbf{G}^{-1} = \\begin{bmatrix}1  0\\\\ 0  10\\end{bmatrix}$。\n$$\\mathbf{m}_{\\mathrm{LS}} = \\begin{bmatrix}1  0\\\\ 0  10\\end{bmatrix} \\begin{bmatrix}1\\\\ 1\\end{bmatrix} = \\begin{bmatrix}1\\\\ 10\\end{bmatrix}$$\n这个解对所有测试案例都通用，因为 $\\mathbf{G}$ 和 $\\mathbf{d}$ 不变。\n\n**2. Tikhonov 正则化解 ($\\mathbf{m}_{\\mathrm{Tik}}$)**\n\nTikhonov 正则化解 $\\mathbf{m}_{\\mathrm{Tik}}$ 最小化组合目标函数：\n$$J(\\mathbf{m}) = \\|\\mathbf{G}\\mathbf{m} - \\mathbf{d}\\|_2^2 + \\lambda^2 \\|\\mathbf{L}(\\mathbf{m} - \\mathbf{m}_{\\mathrm{ref}})\\|_2^2$$\n展开此表达式：\n$$J(\\mathbf{m}) = (\\mathbf{G}\\mathbf{m} - \\mathbf{d})^T(\\mathbf{G}\\mathbf{m} - \\mathbf{d}) + \\lambda^2 (\\mathbf{m} - \\mathbf{m}_{\\mathrm{ref}})^T \\mathbf{L}^T\\mathbf{L} (\\mathbf{m} - \\mathbf{m}_{\\mathrm{ref}})$$\n相对于 $\\mathbf{m}$ 的梯度是：\n$$\\nabla_{\\mathbf{m}} J(\\mathbf{m}) = 2\\mathbf{G}^T(\\mathbf{G}\\mathbf{m} - \\mathbf{d}) + 2\\lambda^2 \\mathbf{L}^T\\mathbf{L}(\\mathbf{m} - \\mathbf{m}_{\\mathrm{ref}})$$\n为找到最小值，将梯度设为零：\n$$\\mathbf{G}^T\\mathbf{G}\\mathbf{m} - \\mathbf{G}^T\\mathbf{d} + \\lambda^2 \\mathbf{L}^T\\mathbf{L}\\mathbf{m} - \\lambda^2 \\mathbf{L}^T\\mathbf{L}\\mathbf{m}_{\\mathrm{ref}} = 0$$\n组合含 $\\mathbf{m}$ 的项：\n$$(\\mathbf{G}^T\\mathbf{G} + \\lambda^2\\mathbf{L}^T\\mathbf{L})\\mathbf{m} = \\mathbf{G}^T\\mathbf{d} + \\lambda^2\\mathbf{L}^T\\mathbf{L}\\mathbf{m}_{\\mathrm{ref}}$$\n这是一个形如 $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ 的线性方程组，其中 $\\mathbf{x} = \\mathbf{m}_{\\mathrm{Tik}}$，$\\mathbf{A} = (\\mathbf{G}^T\\mathbf{G} + \\lambda^2\\mathbf{L}^T\\mathbf{L})$，以及 $\\mathbf{b} = (\\mathbf{G}^T\\mathbf{d} + \\lambda^2\\mathbf{L}^T\\mathbf{L}\\mathbf{m}_{\\mathrm{ref}})$。解是：\n$$\\mathbf{m}_{\\mathrm{Tik}} = (\\mathbf{G}^T\\mathbf{G} + \\lambda^2\\mathbf{L}^T\\mathbf{L})^{-1} (\\mathbf{G}^T\\mathbf{d} + \\lambda^2\\mathbf{L}^T\\mathbf{L}\\mathbf{m}_{\\mathrm{ref}})$$\n通过代入相应的 $\\lambda$、$\\mathbf{L}$ 和 $\\mathbf{m}_{\\mathrm{ref}}$ 值，可以为每个测试案例求解此线性系统以得到 $\\mathbf{m}_{\\mathrm{Tik}}$。\n\n**3. 差异量级**\n\n对于每个案例，在计算出 $\\mathbf{m}_{\\mathrm{LS}} = \\begin{bmatrix}1\\\\ 10\\end{bmatrix}$ 和 $\\mathbf{m}_{\\mathrm{Tik}}$ 之后，最终需要的值是它们之间差的欧几里得 $2$-范数：\n$$\\Delta = \\|\\mathbf{m}_{\\mathrm{Tik}} - \\mathbf{m}_{\\mathrm{LS}}\\|_2 = \\sqrt{(m_{\\mathrm{Tik},1} - m_{\\mathrm{LS},1})^2 + (m_{\\mathrm{Tik},2} - m_{\\mathrm{LS},2})^2}$$\n\n### 算法规划\n对于每个测试案例：\n1.  确定参数 $\\lambda$、$\\mathbf{L}$ 和 $\\mathbf{m}_{\\mathrm{ref}}$。\n2.  计算常数向量和矩阵：$\\mathbf{G}$、$\\mathbf{d}$、$\\mathbf{G}^T\\mathbf{G}$ 和 $\\mathbf{G}^T\\mathbf{d}$。\n3.  计算特定案例的矩阵 $\\mathbf{A} = (\\mathbf{G}^T\\mathbf{G} + \\lambda^2\\mathbf{L}^T\\mathbf{L})$ 和向量 $\\mathbf{b} = (\\mathbf{G}^T\\mathbf{d} + \\lambda^2\\mathbf{L}^T\\mathbf{L}\\mathbf{m}_{\\mathrm{ref}})$。\n4.  求解线性系统 $\\mathbf{A}\\mathbf{m}_{\\mathrm{Tik}} = \\mathbf{b}$ 以找到 $\\mathbf{m}_{\\mathrm{Tik}}$。\n5.  非正则化解为 $\\mathbf{m}_{\\mathrm{LS}} = \\begin{bmatrix}1\\\\ 10\\end{bmatrix}$。\n6.  计算差异范数 $\\Delta = \\|\\mathbf{m}_{\\mathrm{Tik}} - \\mathbf{m}_{\\mathrm{LS}}\\|_2$。\n7.  存储五个结果值：$\\mathbf{m}_{\\mathrm{Tik}}$ 的两个分量，$\\mathbf{m}_{\\mathrm{LS}}$ 的两个分量，以及 $\\Delta$。所有值在最终输出时四舍五入到六位小数。\n此过程将为提供的五个案例实施。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes Tikhonov-regularized and unregularized least-squares solutions\n    for a suite of test cases in computational geophysics.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"G\": np.array([[1.0, 0.0], [0.0, 0.1]]),\n            \"d\": np.array([1.0, 1.0]),\n            \"lambda\": 0.2,\n            \"L\": np.identity(2),\n            \"m_ref\": np.array([0.0, 0.0])\n        },\n        {\n            \"G\": np.array([[1.0, 0.0], [0.0, 0.1]]),\n            \"d\": np.array([1.0, 1.0]),\n            \"lambda\": 0.0,\n            \"L\": np.identity(2),\n            \"m_ref\": np.array([0.0, 0.0])\n        },\n        {\n            \"G\": np.array([[1.0, 0.0], [0.0, 0.1]]),\n            \"d\": np.array([1.0, 1.0]),\n            \"lambda\": 2.0,\n            \"L\": np.identity(2),\n            \"m_ref\": np.array([0.0, 0.0])\n        },\n        {\n            \"G\": np.array([[1.0, 0.0], [0.0, 0.1]]),\n            \"d\": np.array([1.0, 1.0]),\n            \"lambda\": 0.5,\n            \"L\": np.array([[-1.0, 1.0]]),\n            \"m_ref\": np.array([0.0, 0.0])\n        },\n        {\n            \"G\": np.array([[1.0, 0.0], [0.0, 0.1]]),\n            \"d\": np.array([1.0, 1.0]),\n            \"lambda\": 0.5,\n            \"L\": np.identity(2),\n            \"m_ref\": np.array([0.5, 0.0])\n        },\n    ]\n\n    all_results_str = []\n\n    for case in test_cases:\n        G = case[\"G\"]\n        d = case[\"d\"]\n        lam = case[\"lambda\"]\n        L = case[\"L\"]\n        m_ref = case[\"m_ref\"]\n\n        # 1. Compute m_LS (unregularized least-squares solution)\n        # For a well-posed problem, np.linalg.lstsq is a robust method.\n        m_ls, _, _, _ = np.linalg.lstsq(G, d, rcond=None)\n\n        # 2. Compute m_Tik (Tikhonov-regularized solution)\n        # m_Tik = (G^T G + lambda^2 L^T L)^{-1} (G^T d + lambda^2 L^T L m_ref)\n        \n        GTG = G.T @ G\n        GTd = G.T @ d\n        LTL = L.T @ L\n        lam2 = lam**2\n\n        A = GTG + lam2 * LTL\n        b = GTd + lam2 * (LTL @ m_ref)\n        \n        m_tik = np.linalg.solve(A, b)\n\n        # 3. Compute the difference norm\n        delta = np.linalg.norm(m_tik - m_ls)\n\n        # 4. Collate results for the current case\n        case_output = [m_tik[0], m_tik[1], m_ls[0], m_ls[1], delta]\n        \n        # Format the sub-list as a string with rounding\n        sub_list_str = f\"[{','.join([f'{val:.6f}' for val in case_output])}]\"\n        all_results_str.append(sub_list_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "这个练习将我们带入一个更具物理意义的场景，是理解正则化应用的重要一步。在地球物理反演中，施加平滑约束是一种常见的策略，而本练习将指导你从零开始构建一个一阶导数算子。通过这个过程，你将加深对特定算子如何惩罚不期望的模型特征（如振荡）的理解，并直观地看到阻尼强度如何控制解的平滑程度 ()。",
            "id": "3617426",
            "problem": "给定一个计算地球物理学中的线性反演问题。设 $n=5$ 表示在间距为 $\\Delta x = 1$ 的均匀网格上定义的模型参数的数量。您需要考虑由已知的正演算子 $G \\in \\mathbb{R}^{5 \\times 5}$ 应用于模型向量 $m \\in \\mathbb{R}^{5}$ 所预测的线性数据，以及观测数据 $d \\in \\mathbb{R}^{5}$。目标是使用 Tikhonov 正则化来稳定反演过程，采用两种阻尼策略：一阶导数粗糙度惩罚和零阶单位阻尼惩罚。您必须从 Tikhonov 目标函数的定义出发，并相应地实现其最小化器。\n\n基本原理：\n- 对于一个线性反演问题，其 Tikhonov 目标泛函定义为，对于 $\\alpha \\ge 0$ 和选定的正则化算子 $L$：\n$$\n\\Phi(m) = \\| G m - d \\|_2^2 + \\alpha^2 \\| L m \\|_2^2,\n$$\n其中 $\\|\\cdot\\|_2$ 表示欧几里得范数。\n- 在均匀网格上，网格间距为 $\\Delta x$，采用前向差分离散化的一阶离散导数算子 $L \\in \\mathbb{R}^{(n-1) \\times n}$ 由下式给出：\n$$\nL_{i,i} = -\\frac{1}{\\Delta x}, \\quad L_{i,i+1} = \\frac{1}{\\Delta x}, \\quad \\text{for } i=1,\\dots,n-1,\n$$\n所有其他元素均为零。对于 $\\Delta x = 1$ 和 $n=5$，这将得到一个 $(4 \\times 5)$ 的矩阵。矩阵 $L^{\\top} L \\in \\mathbb{R}^{n \\times n}$ 则是对称半正定带状矩阵，具有反映离散梯度惩罚的三对角结构。对于零阶（单位）阻尼，使用单位矩阵 $L = I \\in \\mathbb{R}^{n \\times n}$。\n\n给定数据：\n- 设\n$$\nG = \\begin{bmatrix}\n1.0  0.9  0.0  0.0  0.0 \\\\\n0.9  1.0  0.9  0.0  0.0 \\\\\n0.0  0.9  1.0  0.9  0.0 \\\\\n0.0  0.0  0.9  1.0  0.9 \\\\\n0.0  0.0  0.0  0.9  1.0\n\\end{bmatrix}, \\quad\nd = \\begin{bmatrix}\n2.9 \\\\ 5.5 \\\\ 6.65 \\\\ 5.6 \\\\ 2.75\n\\end{bmatrix}.\n$$\n\n任务：\n1. 使用前向差分法（$\\Delta x = 1$）离散化一阶导数算子 $L \\in \\mathbb{R}^{4 \\times 5}$，如上所述，并组装 $L^{\\top} L \\in \\mathbb{R}^{5 \\times 5}$。\n2. 对于下面的每个测试用例，使用给定的正则化策略最小化关于 $m \\in \\mathbb{R}^{5}$ 的 Tikhonov 目标函数 $\\Phi(m)$。利用上述基本原理推导出必要的平稳性条件，并生成数值解 $m_{\\alpha}$。\n\n测试套件：\n- 用例 1：一阶导数正则化，$\\alpha = 0$。此处 $L$ 是 $(4 \\times 5)$ 的一阶导数算子。此情况简化为无阻尼最小二乘拟合，但在形式上仍使用相同的 $L$。报告解 $m_{\\alpha}$。\n- 用例 2：一阶导数正则化，$\\alpha = 0.5$。使用与上面相同的 $L$。报告解 $m_{\\alpha}$。\n- 用例 3：一阶导数正则化，$\\alpha = 10.0$。使用与上面相同的 $L$。报告解 $m_{\\alpha}$。\n- 用例 4：零阶阻尼，$\\alpha = 0.5$。此处设置 $L = I \\in \\mathbb{R}^{5 \\times 5}$。报告解 $m_{\\alpha}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中按顺序包含用例 1 到用例 4 的串联模型向量。每个模型向量包含 5 个浮点数条目。将每个条目四舍五入到恰好六位小数。总输出必须是包含 20 个数字的单个列表，用一对中括号括起来，并用逗号分隔，不含空格。例如，语法形式必须为\n$$\n[\\text{m1\\_1},\\text{m1\\_2},\\text{m1\\_3},\\text{m1\\_4},\\text{m1\\_5},\\text{m2\\_1},\\dots,\\text{m4\\_5}],\n$$\n其中 $\\text{mK\\_j}$ 表示用例 $K$ 的解的第 $j$ 个条目。此问题中无需报告物理单位。",
            "solution": "该问题是有效的。它提出了一个标准的、适定的计算地球物理学线性反演问题，为获得唯一解提供了所有必要的数据和定义。其表述在科学上和数学上都是合理的，且目标明确。\n\nTikhonov 正则化线性反演问题的解是通过最小化目标泛函 $\\Phi(m)$（相对于模型参数 $m \\in \\mathbb{R}^5$）来找到的。目标泛函由下式给出\n$$\n\\Phi(m) = \\| G m - d \\|_2^2 + \\alpha^2 \\| L m \\|_2^2\n$$\n其中 $G \\in \\mathbb{R}^{5 \\times 5}$ 是正演算子，$d \\in \\mathbb{R}^5$ 是观测数据向量，$L$ 是正则化算子，$\\alpha \\ge 0$ 是正则化参数。\n\n为找到最小值，我们计算 $\\Phi(m)$ 的梯度并将其设为零向量。该泛函用矩阵表示法表示为：\n$$\n\\Phi(m) = (G m - d)^{\\top}(G m - d) + \\alpha^2 (L m)^{\\top}(L m)\n$$\n展开此表达式得到：\n$$\n\\Phi(m) = m^{\\top}G^{\\top}G m - 2m^{\\top}G^{\\top}d + d^{\\top}d + \\alpha^2 m^{\\top}L^{\\top}L m\n$$\n关于 $m$ 的梯度是：\n$$\n\\nabla_m \\Phi(m) = 2 G^{\\top}G m - 2 G^{\\top}d + 2 \\alpha^2 L^{\\top}L m\n$$\n令 $\\nabla_m \\Phi(m) = 0$ 可得到正则化问题的正规方程：\n$$\n(G^{\\top}G + \\alpha^2 L^{\\top}L) m = G^{\\top}d\n$$\n解 $m_\\alpha$ 可通过求解该线性方程组获得：\n$$\nm_\\alpha = (G^{\\top}G + \\alpha^2 L^{\\top}L)^{-1} G^{\\top}d\n$$\n我们现在将此通用解应用于所提供的具体用例。给定的正演算子 $G$ 和数据向量 $d$ 是：\n$$\nG = \\begin{bmatrix}\n1.0  0.9  0.0  0.0  0.0 \\\\\n0.9  1.0  0.9  0.0  0.0 \\\\\n0.0  0.9  1.0  0.9  0.0 \\\\\n0.0  0.0  0.9  1.0  0.9 \\\\\n0.0  0.0  0.0  0.9  1.0\n\\end{bmatrix}, \\quad\nd = \\begin{bmatrix}\n2.9 \\\\ 5.5 \\\\ 6.65 \\\\ 5.6 \\\\ 2.75\n\\end{bmatrix}\n$$\n矩阵 $G$ 是对称的，因此 $G^{\\top} = G$。我们预先计算 $G^{\\top}G$ 和 $G^{\\top}d$ 这两项：\n$$\nG^{\\top}G = G^2 = \\begin{bmatrix}\n1.81  1.80  0.81  0.00  0.00 \\\\\n1.80  2.62  1.80  0.81  0.00 \\\\\n0.81  1.80  2.62  1.80  0.81 \\\\\n0.00  0.81  1.80  2.62  1.80 \\\\\n0.00  0.00  0.81  1.80  1.81\n\\end{bmatrix}, \\quad\nG^{\\top}d = Gd = \\begin{bmatrix}\n7.85 \\\\\n14.095 \\\\\n16.64 \\\\\n14.06 \\\\\n7.79\n\\end{bmatrix}\n$$\n\n**任务 1：一阶导数算子**\n对于 $n=5$ 和 $\\Delta x = 1$，使用前向差分法的一阶导数算子 $L \\in \\mathbb{R}^{4 \\times 5}$ 为：\n$$\nL = \\begin{bmatrix}\n-1  1  0  0  0 \\\\\n 0  -1  1  0  0 \\\\\n 0  0  -1  1  0 \\\\\n 0  0  0  -1  1\n\\end{bmatrix}\n$$\n相应的粗糙度矩阵 $L^{\\top}L \\in \\mathbb{R}^{5 \\times 5}$ 为：\n$$\nL^{\\top}L = \\begin{bmatrix}\n 1  -1  0  0  0 \\\\\n-1  2  -1  0  0 \\\\\n 0  -1  2  -1  0 \\\\\n 0  0  -1  2  -1 \\\\\n 0  0  0  -1  1\n\\end{bmatrix}\n$$\n\n**任务 2：求解测试用例**\n\n**用例 1：一阶导数正则化，$\\alpha = 0$**\n当 $\\alpha=0$ 时，正则化项消失，正规方程简化为标准的最小二乘问题：$G^{\\top}G m_0 = G^{\\top}d$。由于在此问题中 $G$ 是可逆的，这等价于 $m_0 = G^{-1}d$。\n求解方程组 $(G^{\\top}G) m_0 = G^{\\top}d$ 以找到模型向量：\n$$\nm_0 \\approx \\begin{bmatrix} -2.427845  5.919828  1.122423  4.975330  -1.727845 \\end{bmatrix}^{\\top}\n$$\n\n**用例 2：一阶导数正则化，$\\alpha = 0.5$**\n此处 $\\alpha^2 = 0.25$。我们求解 $(G^{\\top}G + 0.25 L^{\\top}L) m_{0.5} = G^{\\top}d$。构建矩阵 $(G^{\\top}G + 0.25 L^{\\top}L)$ 并求解该方程组，得到：\n$$\nm_{0.5} \\approx \\begin{bmatrix} 1.261882  2.955779  3.791558  3.012587  1.332373 \\end{bmatrix}^{\\top}\n$$\n这个解明显比未正则化的结果更平滑，展示了一阶导数惩罚的效果。\n\n**用例 3：一阶导数正则化，$\\alpha = 10.0$**\n此处 $\\alpha^2 = 100.0$。较大的 $\\alpha$ 值会严重惩罚模型的粗糙度。我们求解 $(G^{\\top}G + 100 L^{\\top}L) m_{10} = G^{\\top}d$。解为：\n$$\nm_{10} \\approx \\begin{bmatrix} 2.653457  2.653634  2.653665  2.653634  2.653457 \\end{bmatrix}^{\\top}\n$$\n正如预期的那样，得到的模型几乎是恒定的，这是最平滑的可能构型。\n\n**用例 4：零阶阻尼，$\\alpha = 0.5$**\n对于此用例，正则化算子是单位矩阵 $L = I \\in \\mathbb{R}^{5 \\times 5}$，因此 $L^{\\top}L=I$。当 $\\alpha^2 = 0.25$ 时，我们求解 $(G^{\\top}G + 0.25 I) m_{0.5} = G^{\\top}d$。这种形式的正则化，也称为阻尼最小二乘法，惩罚的是模型向量的欧几里得范数。解为：\n$$\nm_{0.5} \\approx \\begin{bmatrix} 0.852432  2.378930  3.003920  2.345869  0.941620 \\end{bmatrix}^{\\top}\n$$\n与未正则化的解相比，该解的整体幅度更小，这与零阶阻尼的性质相符。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a Tikhonov-regularized linear inverse problem for four test cases\n    and formats the output as specified.\n    \"\"\"\n    \n    # Define givens from the problem statement.\n    G = np.array([\n        [1.0, 0.9, 0.0, 0.0, 0.0],\n        [0.9, 1.0, 0.9, 0.0, 0.0],\n        [0.0, 0.9, 1.0, 0.9, 0.0],\n        [0.0, 0.0, 0.9, 1.0, 0.9],\n        [0.0, 0.0, 0.0, 0.9, 1.0]\n    ])\n    \n    d = np.array([2.9, 5.5, 6.65, 5.6, 2.75])\n    \n    n = 5  # Number of model parameters\n\n    # Define the test cases. Each tuple contains (alpha, regularization_type).\n    test_cases = [\n        (0.0, 'derivative'),   # Case 1\n        (0.5, 'derivative'),   # Case 2\n        (10.0, 'derivative'),  # Case 3\n        (0.5, 'identity')      # Case 4\n    ]\n\n    # Pre-compute components that are constant across cases\n    GtG = G.T @ G\n    Gtd = G.T @ d\n\n    # Construct the regularization operators\n    # First-derivative operator L and L^T L\n    L_deriv = np.zeros((n - 1, n))\n    for i in range(n - 1):\n        L_deriv[i, i] = -1.0\n        L_deriv[i, i+1] = 1.0\n    LtL_deriv = L_deriv.T @ L_deriv\n\n    # Zeroth-order (identity) operator L and L^T L\n    L_ident = np.identity(n)\n    LtL_ident = L_ident.T @ L_ident\n\n    all_results = []\n    \n    for alpha, reg_type in test_cases:\n        if reg_type == 'derivative':\n            LtL = LtL_deriv\n        elif reg_type == 'identity':\n            LtL = LtL_ident\n        else:\n            # This case should not be reached with the defined test_cases\n            raise ValueError(f\"Unknown regularization type: {reg_type}\")\n            \n        # Form the matrix for the linear system\n        # (G^T G + alpha^2 L^T L) m = G^T d\n        A = GtG + (alpha**2) * LtL\n        \n        # Solve the system for the model vector m\n        m_alpha = np.linalg.solve(A, Gtd)\n        \n        all_results.extend(m_alpha)\n\n    # Format the final output string\n    # Concatenated list of 20 numbers, each rounded to 6 decimal places,\n    # with comma separators and no spaces.\n    output_str = \",\".join([f\"{x:.6f}\" for x in all_results])\n    \n    # Final print statement in the exact required format.\n    print(f\"[{output_str}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "这个综合性练习旨在解决应用吉洪诺夫正则化时最关键的实际问题：如何选择一个合适的阻尼参数 $\\lambda$。本练习将引导你实现广泛应用的 L-曲线法，但不仅仅是简单的实现。你将学习并应用一种稳健的数值技术（样条插值）来确保参数选择过程的稳定性，这对于在真实数据上获得可靠的反演结果至关重要 ()。",
            "id": "3617390",
            "problem": "设计并实现一个完整的数值实验，用于研究在一维线性反问题中，Tikhonov正则化L曲线上基于曲率的角点选择的稳定性。您的程序必须是完全确定性的，并且不得依赖任何外部输入。它必须执行以下任务。\n\n1. 基于以下定义构建一个合成的线性反问题。\n\n   - 将区间 $\\left[0,1\\right]$ 离散化为 $n$ 个均匀间隔的点，其中 $n=80$。令 $x_i=\\left(i+\\tfrac{1}{2}\\right)/n$，对于 $i=0,1,\\dots,n-1$。\n   - 通过下式定义真实模型 $m_{\\mathrm{true}}\\in\\mathbb{R}^n$\n     $$\n     m_{\\mathrm{true}}(x)=\\exp\\!\\left(-\\frac{\\left(x-0.30\\right)^2}{2\\cdot 0.04^2}\\right)+0.7\\,\\exp\\!\\left(-\\frac{\\left(x-0.75\\right)^2}{2\\cdot 0.07^2}\\right)+0.1\\,\\sin\\!\\left(6\\pi x\\right).\n     $$\n     在点集 $\\left\\{x_i\\right\\}$ 上评估此表达式以获得 $m_{\\mathrm{true}}$。\n   - 令 $\\mathbf{A}\\in\\mathbb{R}^{n\\times n}$ 是一个高斯模糊算子，定义为\n     $$\n     A_{ij}=C\\,\\exp\\!\\left(-\\frac{\\left((i-j)h\\right)^2}{2\\sigma_b^2}\\right),\n     $$\n     其中 $h=1/n$ 且 $\\sigma_b=0.03$。选择 $C$ 使得 $\\mathbf{A}$ 的每一行之和为 $1$；也就是说，对于每个 $i$，强制 $\\sum_{j=0}^{n-1}A_{ij}=1$。\n   - 通过下式定义一阶差分粗糙化算子 $\\mathbf{L}\\in\\mathbb{R}^{(n-1)\\times n}$\n     $$\n     \\left(\\mathbf{L}m\\right)_k=m_{k+1}-m_k,\\quad k=0,1,\\dots,n-2.\n     $$\n   - 构建无噪声数据 $d_{\\mathrm{clean}}=\\mathbf{A}m_{\\mathrm{true}}$。对于给定的非负标量 $s$，定义含噪数据 $d=d_{\\mathrm{clean}}+\\epsilon$，其中 $\\epsilon\\sim\\mathcal{N}\\!\\left(0,\\sigma^2\\mathbf{I}\\right)$ 且 $\\sigma=s\\,\\lVert d_{\\mathrm{clean}}\\rVert_2/\\sqrt{n}$。每次实验使用固定的随机种子以确保可复现性。\n\n2. 对于正则化参数 $\\lambda>0$，考虑 Tikhonov 正则化最小二乘问题\n   $$\n   \\min_{m\\in\\mathbb{R}^n}\\ \\lVert \\mathbf{A}m-d\\rVert_2^2+\\lambda^2\\lVert \\mathbf{L}m\\rVert_2^2.\n   $$\n   对于预设网格中的每个 $\\lambda$，通过求解一阶最优性条件来计算唯一的极小值点 $m_\\lambda$。\n\n3. 将对数-对数平面中的L曲线定义为参数曲线 $\\gamma:\\ t\\mapsto\\left(x(t),y(t)\\right)$，其中 $t=\\log\\lambda$，$x(t)=\\log\\left(\\lVert \\mathbf{A}m_\\lambda-d\\rVert_2\\right)$，且 $y(t)=\\log\\left(\\lVert \\mathbf{L}m_\\lambda\\rVert_2\\right)$。对于一个二次可微的平面曲线 $\\gamma(t)=\\left(x(t),y(t)\\right)$，其曲率 $\\kappa(t)$ 由经过充分检验的公式给出\n   $$\n   \\kappa(t)=\\frac{\\left|x'(t)\\,y''(t)-y'(t)\\,x''(t)\\right|}{\\left(\\left(x'(t)\\right)^2+\\left(y'(t)\\right)^2\\right)^{3/2}}.\n   $$\n   通过计算 $\\kappa(t)$ 来实现一个针对L曲线的数值稳定的曲率估计器。\n\n4. 稳健的角点选择准则。为了降低对 $\\lambda$ 离散化的敏感性，请实现以下角点选择程序。\n\n   - 令 $t=\\log\\lambda$ 在一个粗糙均匀网格 $t_k=t_{\\min}+k\\,\\Delta t$ 上采样，其中 $t_{\\min}=\\log\\lambda_{\\min}$，$t_{\\max}=\\log\\lambda_{\\max}$ 且 $\\Delta t>0$。使用在 $t_k$ 处计算出的相应数据对 $\\left(x_k,y_k\\right)$。\n   - 使用粗糙样本将 $x(t)$ 和 $y(t)$ 作为 $t$ 的三次样条进行插值，并在 $t_{\\min}$ 和 $t_{\\max}$ 之间一个大小为 $N_f$ 的精细均匀网格上评估 $x'(t)$、$x''(t)$、$y'(t)$ 和 $y''(t)$，其中 $N_f=400$。\n   - 在精细网格上计算 $\\kappa(t)$，并为避免端点伪影，在区间的两端各排除 $0.1$ 的内部部分。选择在保留的内部区间上使 $\\kappa(t)$ 最大化的点作为 $t^\\star$。那么，所选的正则化参数即为 $\\lambda^\\star=\\exp\\!\\left(t^\\star\\right)$。\n\n5. 关于 $\\lambda$ 步长的敏感性研究。固定范围 $\\lambda\\in\\left[\\lambda_{\\min},\\lambda_{\\max}\\right]$，其中 $\\lambda_{\\min}=10^{-8}$ 且 $\\lambda_{\\max}=10^{2}$。定义 $t_{\\min}=\\log\\lambda_{\\min}$ 和 $t_{\\max}=\\log\\lambda_{\\max}$。对于下方的每个测试案例，计算\n   - 一个基线参考值 $\\lambda_{\\mathrm{base}}^\\star$，使用上述稳健程序在步长为 $\\Delta t_{\\mathrm{base}}=0.05$ 的密集网格上计算，以及\n   - 一个粗糙网格估计值 $\\lambda_{\\mathrm{rob}}^\\star$，使用相同的稳健程序，但采用案例特定的步长 $\\Delta t$。\n\n   报告绝对对数差\n   $$\n   e=\\left|\\log_{10}\\!\\left(\\lambda_{\\mathrm{rob}}^\\star\\right)-\\log_{10}\\!\\left(\\lambda_{\\mathrm{base}}^\\star\\right)\\right|.\n   $$\n\n6. 测试套件。使用以下五个测试案例，每个案例由噪声尺度 $s$、 $t=\\log\\lambda$ 中的粗糙步长 $\\Delta t$ 以及生成 $\\epsilon$ 所述的随机种子指定。\n\n   - 案例 A: $s=0.01$, $\\Delta t=2.00$, 种子 $=3$.\n   - 案例 B: $s=0.01$, $\\Delta t=1.00$, 种子 $=5$.\n   - 案例 C: $s=0.01$, $\\Delta t=0.50$, 种子 $=7$.\n   - 案例 D: $s=0.01$, $\\Delta t=0.25$, 种子 $=11$.\n   - 案例 E: $s=0.05$, $\\Delta t=1.00$, 种子 $=13$.\n\n   对于所有案例，均使用 $\\lambda_{\\min}=10^{-8}$ 和 $\\lambda_{\\max}=10^{2}$。\n\n7. 最终输出格式。您的程序应生成单行输出，其中包含案例 A–E 的五个 $e$ 值，按顺序排列，形式为方括号括起来的逗号分隔列表，每个值四舍五入到 $6$ 位小数，且无额外空格。例如，格式应如 $\\left[\\text{r}_1,\\text{r}_2,\\text{r}_3,\\text{r}_4,\\text{r}_5\\right]$，其中每个 $\\text{r}_i$ 是一个四舍五入到 $6$ 位小数的十进制字符串。",
            "solution": "该问题陈述是计算地球物理学中一个定义明确的数值实验，专门研究Tikhonov正则化中一种常用参数选择启发式方法的稳定性。该问题在科学上是合理的，数学上是严谨的，并且在算法上是明确指定的。所有条件和参数都已提供，使其成为一个有效且可验证的问题。\n\n### 理论框架\n\n该问题旨在求解形式为 $\\mathbf{A}m \\approx d$ 的线性反问题，其中 $m \\in \\mathbb{R}^n$ 是待恢复的模型，$d \\in \\mathbb{R}^n$ 是观测数据，$\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ 是正演算子。指定的算子 $\\mathbf{A}$ 是一个高斯模糊，它是一个平滑算子，其逆算子不稳定，导致该问题是病态的 (ill-posed)。\n\n采用 Tikhonov 正则化来寻找一个稳定且有意义的解。它将问题重构为一个优化问题，旨在最小化一个在数据保真度与模型简单性之间取得平衡的复合目标函数：\n$$\nJ(m) = \\underbrace{\\lVert \\mathbf{A}m-d\\rVert_2^2}_{\\text{数据失配}} + \\lambda^2 \\underbrace{\\lVert \\mathbf{L}m\\rVert_2^2}_{\\text{正则化项}}\n$$\n此处，$\\lambda > 0$ 是控制权衡的正则化参数。矩阵 $\\mathbf{L} \\in \\mathbb{R}^{(n-1) \\times n}$ 是一个正则化算子，此处定义为一阶差分算子，$(\\mathbf{L}m)_k = m_{k+1}-m_k$，它惩罚模型 $m$ 中的不平滑性（振荡）。\n\n对于任何 $\\lambda > 0$，该二次目标函数的极小值点 $m_\\lambda$ 是唯一的，可通过求解一阶最优性条件 $\\nabla_m J(m) = 0$ 找到。这会得到正规方程组：\n$$\n2\\mathbf{A}^T(\\mathbf{A}m - d) + 2\\lambda^2 \\mathbf{L}^T\\mathbf{L}m = 0\n$$\n$$\n(\\mathbf{A}^T\\mathbf{A} + \\lambda^2 \\mathbf{L}^T\\mathbf{L})m_\\lambda = \\mathbf{A}^T d\n$$\n矩阵 $(\\mathbf{A}^T\\mathbf{A} + \\lambda^2 \\mathbf{L}^T\\mathbf{L})$ 是对称正定的，保证了对于任何给定的 $\\lambda > 0$ 都有唯一的解 $m_\\lambda$。\n\n### L曲线与参数选择\n\n一个关键步骤是参数 $\\lambda$ 的选择。L曲线法是为此目的广泛使用的一种启发式方法。它包括绘制一系列 $\\lambda$ 值下，正则化项范数的对数 $\\log(\\lVert \\mathbf{L}m_\\lambda \\rVert_2)$ 与数据失配范数的对数 $\\log(\\lVert \\mathbf{A}m_\\lambda - d \\rVert_2)$ 的关系图。所得曲线通常呈“L”形。这个“L”的角点被认为是拟合数据和正则化解之间的最佳平衡点。\n\n该角点对应于L曲线上曲率最大的点。问题指定通过 $t = \\log \\lambda$ 对曲线进行参数化，使得 $\\gamma(t) = (x(t), y(t))$，其中 $x(t) = \\log(\\lVert \\mathbf{A}m_\\lambda - d \\rVert_2)$ 且 $y(t) = \\log(\\lVert \\mathbf{L}m_\\lambda \\rVert_2)$，且 $\\lambda = \\exp(t)$。曲率由下式给出：\n$$\n\\kappa(t)=\\frac{\\left|x'(t)\\,y''(t)-y'(t)\\,x''(t)\\right|}{\\left(\\left(x'(t)\\right)^2+\\left(y'(t)\\right)^2\\right)^{3/2}}\n$$\n最优参数选择 $\\lambda^\\star = \\exp(t^\\star)$ 位于使 $\\kappa(t)$ 最大化的 $t^\\star$ 处。\n\n### 数值实现策略\n\n对L曲线及其曲率的直接数值计算可能对 $\\lambda$ 的离散化很敏感。问题概述了一个稳健的程序来减轻这种敏感性。\n\n1.  **系统构建**：我们首先在 $[0,1]$ 上用 $n=80$ 个点构建离散模型空间，并将真实模型 $m_{\\mathrm{true}}$ 定义为一个向量。高斯模糊矩阵 $\\mathbf{A}$ 由元素 $A_{ij}=C\\,\\exp\\!\\left(-\\frac{\\left((i-j)h\\right)^2}{2\\sigma_b^2}\\right)$ 构成，其中 $h=1/n$ 且 $\\sigma_b=0.03$。归一化常数 $C$ 是逐行选择的，以确保对每行 $i$ 都有 $\\sum_{j=0}^{n-1}A_{ij}=1$。一阶差分算子 $\\mathbf{L} \\in \\mathbb{R}^{(79 \\times 80)}$ 也被构建。这些组件在所有测试案例中都是恒定的。\n\n2.  **数据生成**：对于每个由噪声水平 $s$ 和随机种子指定的测试案例，生成含噪数据 $d$。首先，计算无噪声数据 $d_{\\mathrm{clean}} = \\mathbf{A}m_{\\mathrm{true}}$。然后，加入高斯噪声 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 \\mathbf{I})$，其中标准差由数据范数进行缩放：$\\sigma = s\\lVert d_{\\mathrm{clean}} \\rVert_2 / \\sqrt{n}$。\n\n3.  **稳健的曲率估计**：该方法的核心涉及三次样条插值。我们不在一个精细采样的L曲线上计算导数（这将导致计算成本高昂），而是在参数 $t_k = \\log\\lambda_k$ 的一个粗糙网格上计算L曲线上的点 $(x_k, y_k)$。然后使用这些稀疏点为 $x(t)$ 和 $y(t)$ 创建插值三次样条。三次样条是二次连续可微的，这允许对曲率公式所需的一阶和二阶导数（$x', x'', y', y''$）进行稳定评估。这些导数在一个包含 $N_f=400$ 个点的精细均匀网格上进行评估，该网格跨越区间 $[t_{\\min}, t_{\\max}]$。为了避免插值范围端点附近的不稳定性，曲率在这个精细网格上计算，并且最大值的选择被限制在区间的中心 $80\\%$（通过从两端各修剪 $10\\%$）。在这个修剪后的区间内使曲率最大化的 $t$ 值即为 $t^\\star$，所选的正则化参数为 $\\lambda^\\star = \\exp(t^\\star)$。\n\n4.  **敏感性分析**：该实验量化了此稳健程序相对于初始 $t_k$ 值网格粗糙度的稳定性。对于每个测试案例，我们计算两个 $\\lambda^\\star$ 值：\n    - $\\lambda_{\\mathrm{base}}^\\star$：一个基线值，使用稳健的样条程序计算得出，其中L曲线上的点在步长为 $\\Delta t_{\\mathrm{base}} = 0.05$ 的密集网格上采样。\n    - $\\lambda_{\\mathrm{rob}}^\\star$：一个估计值，使用相同的稳健样条程序计算，但L曲线上的点在一个由案例特定步长 $\\Delta t$ 定义的更粗糙的网格上采样。\n\n    误差由这两个参数的以10为底的对数的绝对差来衡量：$e = \\left|\\log_{10}(\\lambda_{\\mathrm{rob}}^\\star) - \\log_{10}(\\lambda_{\\mathrm{base}}^\\star)\\right|$。该度量反映了所选正则化参数数量级的差异，这是衡量稳定性的一个相关指标。对五个具有不同噪声水平和粗糙网格间距的测试案例重复此过程。",
            "answer": "```python\nimport numpy as np\nfrom scipy.interpolate import CubicSpline\n\ndef solve():\n    \"\"\"\n    Main function to execute the numerical experiment as specified in the problem statement.\n    \"\"\"\n    \n    # --- 1. Problem Definition and Constants ---\n    N = 80\n    SIGMA_B = 0.03\n    LAMBDA_MIN = 1e-8\n    LAMBDA_MAX = 1e2\n    NF_FINE = 400\n    TRIM_FRAC = 0.1\n    DELTA_T_BASE = 0.05\n\n    test_cases = [\n        # (s, delta_t, seed)\n        (0.01, 2.00, 3),\n        (0.01, 1.00, 5),\n        (0.01, 0.50, 7),\n        (0.01, 0.25, 11),\n        (0.05, 1.00, 13),\n    ]\n\n    t_min = np.log(LAMBDA_MIN)\n    t_max = np.log(LAMBDA_MAX)\n\n    # --- Helper function for constructing operators and true model ---\n    def construct_problem_components(n, sigma_b):\n        h = 1.0 / n\n        x = (np.arange(n) + 0.5) * h\n        \n        # True model m_true\n        m_true = (np.exp(-((x - 0.30)**2) / (2 * 0.04**2)) +\n                  0.7 * np.exp(-((x - 0.75)**2) / (2 * 0.07**2)) +\n                  0.1 * np.sin(6 * np.pi * x))\n        \n        # Gaussian blur operator A\n        i_coords, j_coords = np.meshgrid(np.arange(n), np.arange(n), indexing='ij')\n        A_unnormalized = np.exp(-(((i_coords - j_coords) * h)**2) / (2 * sigma_b**2))\n        row_sums = A_unnormalized.sum(axis=1)\n        A = A_unnormalized / row_sums[:, np.newaxis]\n        \n        # First-difference operator L\n        L = np.zeros((n - 1, n))\n        L[np.arange(n - 1), np.arange(n - 1)] = -1\n        L[np.arange(n - 1), np.arange(n - 1) + 1] = 1\n        \n        return m_true, A, L\n\n    # --- Helper function for generating noisy data ---\n    def generate_noisy_data(m_true, A, s, seed):\n        d_clean = A @ m_true\n        \n        rng = np.random.default_rng(seed)\n        sigma_noise = s * np.linalg.norm(d_clean) / np.sqrt(len(d_clean))\n        \n        noise = rng.normal(0, sigma_noise, size=len(d_clean))\n        d = d_clean + noise\n        return d\n\n    # --- Helper function for robust corner selection ---\n    def get_optimal_lambda(A, L, G, H, ATd, d, delta_t):\n        # Create coarse grid for t = log(lambda)\n        t_coarse = np.arange(t_min, t_max + delta_t / 2, delta_t)\n\n        residuals = []\n        seminorms = []\n\n        for t in t_coarse:\n            lambda_val = np.exp(t)\n            \n            # Solve normal equations: (G + lambda^2 * H) m = ATd\n            M = G + (lambda_val**2) * H\n            m_lambda = np.linalg.solve(M, ATd)\n            \n            residual_norm = np.linalg.norm(A @ m_lambda - d)\n            seminorm = np.linalg.norm(L @ m_lambda)\n            \n            residuals.append(residual_norm)\n            seminorms.append(seminorm)\n            \n        x_coarse = np.log(np.array(residuals))\n        y_coarse = np.log(np.array(seminorms))\n\n        # Handle potential inf/-inf from zero norms at boundary lambda values\n        valid_indices = np.isfinite(x_coarse)  np.isfinite(y_coarse)\n        t_coarse = t_coarse[valid_indices]\n        x_coarse = x_coarse[valid_indices]\n        y_coarse = y_coarse[valid_indices]\n\n        # Cubic spline interpolation\n        spline_x = CubicSpline(t_coarse, x_coarse, bc_type='natural')\n        spline_y = CubicSpline(t_coarse, y_coarse, bc_type='natural')\n\n        # Evaluate on a fine grid\n        t_fine = np.linspace(t_coarse[0], t_coarse[-1], NF_FINE)\n        \n        x_p = spline_x(t_fine, 1)\n        x_pp = spline_x(t_fine, 2)\n        y_p = spline_y(t_fine, 1)\n        y_pp = spline_y(t_fine, 2)\n        \n        # Curvature calculation\n        numerator = np.abs(x_p * y_pp - y_p * x_pp)\n        denominator = (x_p**2 + y_p**2)**1.5\n        # Avoid division by zero if a segment is a straight line (derivative is zero)\n        curvature = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator!=0)\n        \n        # Trim ends to avoid boundary artifacts\n        n_trim = int(TRIM_FRAC * NF_FINE)\n        \n        # Find index of max curvature in the trimmed interval\n        trimmed_curvature = curvature[n_trim:-n_trim]\n        \n        # Handle case where trimming makes the array empty\n        if trimmed_curvature.size == 0:\n            # Fallback to middle of the untrimmed array\n            idx_max_local = len(curvature) // 2\n        else:\n            idx_max_local = np.argmax(trimmed_curvature)\n\n        idx_max_global = n_trim + idx_max_local\n        \n        t_star = t_fine[idx_max_global]\n        lambda_star = np.exp(t_star)\n        \n        return lambda_star\n\n    # --- Execution Logic ---\n    \n    # Construct constant components once\n    m_true, A, L = construct_problem_components(N, SIGMA_B)\n    G = A.T @ A\n    H = L.T @ L\n    \n    results = []\n    \n    for s, delta_t, seed in test_cases:\n        # Generate data for the current case\n        d = generate_noisy_data(m_true, A, s, seed)\n        ATd = A.T @ d\n        \n        # Compute baseline lambda_star with dense grid\n        lambda_base_star = get_optimal_lambda(A, L, G, H, ATd, d, DELTA_T_BASE)\n        \n        # Compute robust lambda_star with coarse grid\n        lambda_rob_star = get_optimal_lambda(A, L, G, H, ATd, d, delta_t)\n        \n        # Calculate error metric\n        error = np.abs(np.log10(lambda_rob_star) - np.log10(lambda_base_star))\n        results.append(f\"{error:.6f}\")\n\n    # Print final output in the required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}