{
    "hands_on_practices": [
        {
            "introduction": "共轭梯度法的效率源于一种被称为 $A$-共轭的特殊性质，它不同于标准的几何正交性。这个练习通过一个具体的例子，帮助你直观地理解这一关键概念，并阐明为何该方法不仅仅是简单的最速下降法。通过亲手验证，你将能更深刻地体会到 $A$-共轭向量在线性系统求解中的独特作用。",
            "id": "3586928",
            "problem": "在用于求解具有对称正定 (SPD) 矩阵的线性系统的共轭梯度 (CG) 法中，要求搜索方向关于矩阵诱导的内积是共轭的。从实矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 是对称正定的基本定义（如果 $A^{\\top}=A$ 且对于所有非零 $x \\in \\mathbb{R}^{n}$ 都有 $x^{\\top} A x > 0$）以及两个向量 $p_{1}, p_{2} \\in \\mathbb{R}^{n}$ 是 $A$-共轭的定义（如果 $p_{1}^{\\top} A p_{2}=0$）出发，构造一个 $\\mathbb{R}^{3}$ 中的显式例子，以证明 $A$-共轭性与欧几里得正交性是不同的。\n\n令\n$$\nA \\in \\mathbb{R}^{3 \\times 3}, \\quad A \\;=\\; \\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix}, \\quad\np_{1} \\;=\\; \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad\np_{2} \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n$$\n仅使用对称正定矩阵和内积的基本定义与性质（不调用任何特定于算法的更新公式），执行以下操作：\n\n1. 根据第一性原理验证 $A$ 是对称正定的。\n2. 通过显式计算 $p_{1}^{\\top} A p_{2}$ 来验证 $p_{1}$ 和 $p_{2}$ 是 $A$-共轭的。\n3. 通过计算 $p_{1}^{\\top} p_{2}$ 来验证 $p_{1}$ 和 $p_{2}$ 在标准欧几里得内积下不是正交的。\n\n报告欧几里得内积 $p_{1}^{\\top} p_{2}$ 的确切值作为你的最终答案。请将最终答案表示为一个精确的整数。",
            "solution": "该问题要求在 $\\mathbb{R}^{3}$ 中给出一个明确的演示，证明对于对称正定 (SPD) 矩阵 $A$，$A$-共轭性的概念与标准的欧几里得正交性是不同的。为此，我们给定一个矩阵 $A$ 和两个向量 $p_1$ 和 $p_2$。任务是验证 $A$ 确实是 SPD 矩阵，证明 $p_1$ 和 $p_2$ 是 $A$-共轭的，并证明它们在欧几里得意义下不是正交的。最终答案是计算出的欧几里得内积的值。\n\n给定的矩阵 $A \\in \\mathbb{R}^{3 \\times 3}$ 和向量 $p_1, p_2 \\in \\mathbb{R}^{3}$ 是：\n$$\nA = \\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix}, \\quad\np_1 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad\np_2 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n$$\n\n分析按规定分三步进行。\n\n首先，我们验证矩阵 $A$ 是对称正定的 (SPD)。\n如果 $A = A^{\\top}$，则矩阵是对称的。通过观察 $A$，对于所有 $i, j \\in \\{1, 2, 3\\}$，第 $i$ 行第 $j$ 列的元素等于第 $j$ 行第 $i$ 列的元素。具体来说，$A_{12} = A_{21} = -1$，$A_{13} = A_{31} = 0$，以及 $A_{23} = A_{32} = -1$。因此，$A$ 是对称的。\n\n如果对于所有非零向量 $x \\in \\mathbb{R}^{3}$ 都有 $x^{\\top} A x > 0$，则对称矩阵 $A$ 是正定的。令 $x = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}$ 为任意非零向量。我们计算二次型 $x^{\\top} A x$：\n$$\nx^{\\top} A x = \\begin{pmatrix} x_1  x_2  x_3 \\end{pmatrix} \\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} x_1  x_2  x_3 \\end{pmatrix} \\begin{pmatrix} 2x_1 - x_2 \\\\ -x_1 + 2x_2 - x_3 \\\\ -x_2 + 2x_3 \\end{pmatrix}\n$$\n$$\n= x_1(2x_1 - x_2) + x_2(-x_1 + 2x_2 - x_3) + x_3(-x_2 + 2x_3)\n$$\n$$\n= 2x_1^2 - x_1x_2 - x_1x_2 + 2x_2^2 - x_2x_3 - x_2x_3 + 2x_3^2\n$$\n$$\n= 2x_1^2 - 2x_1x_2 + 2x_2^2 - 2x_2x_3 + 2x_3^2\n$$\n为了证明这个表达式是正的，我们可以通过配方法重新整理这些项：\n$$\nx^{\\top} A x = x_1^2 + (x_1^2 - 2x_1x_2 + x_2^2) + (x_2^2 - 2x_2x_3 + x_3^2) + x_3^2\n$$\n$$\n= x_1^2 + (x_1 - x_2)^2 + (x_2 - x_3)^2 + x_3^2\n$$\n该表达式是实数的平方和，因此它总是非负的。它等于零当且仅当和中的每一项都为零：$x_1^2=0$，$(x_1 - x_2)^2=0$，$(x_2 - x_3)^2=0$ 和 $x_3^2=0$。这要求 $x_1=0$，$x_3=0$，$x_1=x_2$ 和 $x_2=x_3$。综合来看，这些条件意味着 $x_1=x_2=x_3=0$，即 $x$ 是零向量。因此，对于任何非零向量 $x$，我们有 $x^{\\top} A x > 0$。由于 $A$既是对称的又是正定的，所以它是一个 SPD 矩阵。\n\n其次，我们验证向量 $p_1$ 和 $p_2$ 是 $A$-共轭的。如果两个向量 $p_1, p_2$ 的 $A$-内积为零，即 $p_1^{\\top} A p_2 = 0$，则它们是 $A$-共轭的。我们显式地计算这个值：\n$$\np_1^{\\top} A p_2 = \\begin{pmatrix} 1  1  0 \\end{pmatrix} \\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}\n$$\n我们可以先计算矩阵-向量积 $A p_2$：\n$$\nA p_2 = \\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2(1) - 1(0) + 0(1) \\\\ -1(1) + 2(0) - 1(1) \\\\ 0(1) - 1(0) + 2(1) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -2 \\\\ 2 \\end{pmatrix}\n$$\n现在，我们计算 $p_1^{\\top}$ 与此结果的点积：\n$$\np_1^{\\top} (A p_2) = \\begin{pmatrix} 1  1  0 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -2 \\\\ 2 \\end{pmatrix} = 1(2) + 1(-2) + 0(2) = 2 - 2 + 0 = 0\n$$\n由于 $p_1^{\\top} A p_2 = 0$，向量 $p_1$ 和 $p_2$ 确实是 $A$-共轭的。\n\n第三，我们验证 $p_1$ 和 $p_2$ 在标准欧几里得内积下不是正交的。如果两个向量的标准内积（点积）为零，则它们是正交的。$p_1$ 和 $p_2$ 的内积由 $p_1^{\\top} p_2$ 给出：\n$$\np_1^{\\top} p_2 = \\begin{pmatrix} 1  1  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix} = 1(1) + 1(0) + 0(1) = 1 + 0 + 0 = 1\n$$\n由于 $p_1^{\\top} p_2 = 1 \\neq 0$，向量 $p_1$ 和 $p_2$ 在欧几里得意义下不是正交的。\n\n这样就完成了证明：我们找到了一对向量，它们相对于给定的 SPD 矩阵 $A$ 是 $A$-共轭的，但相对于标准欧几里得内积不是正交的。这个欧几里得内积的值是 $1$。",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "在理解了 $A$-共轭的概念之后，下一步是掌握算法本身的运算机制。本练习将共轭梯度法的第一次迭代分解为一个简单的 $2 \\times 2$ 系统，让你能够从第一性原理出发，一步步计算出所有关键量。这个练习将巩固你对残差、搜索方向和解如何更新的理解。",
            "id": "3371621",
            "problem": "考虑一个线性系统，该系统来自计算流体力学中椭圆算子的对称正定离散化，例如最小控制体格式上的压力泊松方程。设矩阵为 $A = \\begin{pmatrix} 4 & 1 \\\\ 1 & 3 \\end{pmatrix}$，右端项为 $b = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$，初始迭代向量为 $x_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。共轭梯度法 (CG) 是通过在 Krylov 子空间上最小化二次泛函 $\\phi(x)=\\frac{1}{2}x^{\\top}Ax-b^{\\top}x$ 推导出来的，其中残差为 $r_{k}=b-Ax_{k}$，搜索方向相互 $A$ 共轭，并且步长的选择使得新的残差在欧几里得内积下与当前搜索方向正交。从这些原理出发，不使用任何快捷公式，为给定的 $A$、$b$ 和 $x_{0}$ 显式计算第一步的量 $\\alpha_{0}$、$x_{1}$、$r_{1}$ 和 $\\beta_{0}$。提供精确值，不要四舍五入。为了报告，将最终答案表示为行向量 $\\left(\\alpha_{0}, x_{1,1}, x_{1,2}, r_{1,1}, r_{1,2}, \\beta_{0}\\right)$，其中 $x_{1,i}$ 和 $r_{1,i}$ 分别表示 $x_{1}$ 和 $r_{1}$ 的分量。",
            "solution": "该问题是适定的且科学上合理的。它要求从算法的基本原理出发，而不是依赖于现成的算法总结，来计算给定线性系统的共轭梯度 (CG) 法的第一次迭代。\n\n待解系统为 $Ax=b$，其中矩阵 $A$ 是对称正定的 (SPD)。CG 方法通过最小化二次泛函 $\\phi(x) = \\frac{1}{2}x^{\\top}Ax - b^{\\top}x$ 来迭代地构造解。该泛函的梯度为 $\\nabla\\phi(x) = Ax - b$，即残差 $r(x) = b - Ax$ 的负值。因此，最小化 $\\phi(x)$ 等价于找到满足 $\\nabla\\phi(x) = 0$ 的 $x$，这正是 $Ax=b$ 的解。\n\n给定的条件是：\n矩阵 $A = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix}$。\n右端向量 $b = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$。\n解的初始猜测 $x_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。\n\nCG 算法对迭代 $k=0, 1, 2, ...$ 按如下步骤进行：\n1. 更新解：$x_{k+1} = x_{k} + \\alpha_{k} p_{k}$\n2. 更新残差：$r_{k+1} = r_{k} - \\alpha_{k} A p_{k}$\n3. 更新搜索方向：$p_{k+1} = r_{k+1} + \\beta_{k} p_{k}$\n\n参数 $\\alpha_k$ 和 $\\beta_k$ 是从核心原理推导得出的。\n\n**第0步：初始化**\n\n首先，我们根据初始猜测 $x_0$ 计算初始残差 $r_0$。\n$$r_{0} = b - Ax_{0}$$\n由于 $x_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，初始残差就是 $b$：\n$$r_{0} = b = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$$\n第一个搜索方向 $p_0$ 选择为最速下降方向，也就是初始残差：\n$$p_{0} = r_{0} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$$\n\n**第1步：第一次迭代 ($k=0$)**\n\n我们需要计算 $\\alpha_{0}$、$x_{1}$、$r_{1}$ 和 $\\beta_{0}$。\n\n**计算步长 $\\alpha_{0}$**\n步长 $\\alpha_{0}$ 的选择是为了沿搜索方向 $p_{0}$ 最小化 $\\phi(x_{1}) = \\phi(x_{0} + \\alpha_{0} p_{0})$。当新的残差 $r_{1}$ 与当前搜索方向 $p_{0}$ 正交时，即 $p_{0}^{\\top}r_{1} = 0$，达到此最小值。\n新的残差由 $r_{1} = b - Ax_{1} = b - A(x_{0} + \\alpha_{0} p_{0}) = (b - Ax_{0}) - \\alpha_{0}Ap_{0} = r_0 - \\alpha_0 A p_0$ 给出。\n将其代入正交条件：\n$$p_{0}^{\\top}(r_{0} - \\alpha_{0} A p_{0}) = 0$$\n$$p_{0}^{\\top}r_{0} - \\alpha_{0} p_{0}^{\\top}A p_{0} = 0$$\n解出 $\\alpha_0$ 得到：\n$$\\alpha_{0} = \\frac{p_{0}^{\\top}r_{0}}{p_{0}^{\\top}A p_{0}}$$\n由于 $p_0 = r_0$，上式变为：\n$$\\alpha_{0} = \\frac{r_{0}^{\\top}r_{0}}{r_{0}^{\\top}A r_{0}}$$\n我们计算必要的量：\n$r_{0}^{\\top}r_{0} = \\begin{pmatrix} 1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = (1)(1) + (2)(2) = 1 + 4 = 5$。\n$A p_{0} = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 4(1) + 1(2) \\\\ 1(1) + 3(2) \\end{pmatrix} = \\begin{pmatrix} 6 \\\\ 7 \\end{pmatrix}$。\n$p_{0}^{\\top}A p_{0} = r_{0}^{\\top}A p_{0} = \\begin{pmatrix} 1  2 \\end{pmatrix} \\begin{pmatrix} 6 \\\\ 7 \\end{pmatrix} = (1)(6) + (2)(7) = 6 + 14 = 20$。\n代入这些值：\n$$\\alpha_{0} = \\frac{5}{20} = \\frac{1}{4}$$\n\n**计算新的迭代向量 $x_{1}$**\n新的解估计值 $x_1$ 是通过从 $x_0$ 沿方向 $p_0$ 移动步长 $\\alpha_0$ 得到的：\n$$x_{1} = x_{0} + \\alpha_{0} p_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\frac{1}{4} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{4} \\\\ \\frac{2}{4} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{4} \\\\ \\frac{1}{2} \\end{pmatrix}$$\n所以，$x_{1,1} = \\frac{1}{4}$ 且 $x_{1,2} = \\frac{1}{2}$。\n\n**计算新的残差 $r_{1}$**\n新的残差 $r_1$ 可以使用更新公式计算：\n$$r_{1} = r_{0} - \\alpha_{0} A p_{0} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} - \\frac{1}{4} \\begin{pmatrix} 6 \\\\ 7 \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{6}{4} \\\\ 2 - \\frac{7}{4} \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{4} - \\frac{6}{4} \\\\ \\frac{8}{4} - \\frac{7}{4} \\end{pmatrix} = \\begin{pmatrix} -\\frac{2}{4} \\\\ \\frac{1}{4} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix}$$\n所以，$r_{1,1} = -\\frac{1}{2}$ 且 $r_{1,2} = \\frac{1}{4}$。\n\n**计算系数 $\\beta_{0}$**\n系数 $\\beta_0$ 用于构造下一个搜索方向 $p_1 = r_1 + \\beta_0 p_0$。基本原理是新的搜索方向 $p_1$ 必须与前一个方向 $p_0$ 是 $A$ 共轭的，即 $p_{1}^{\\top}A p_{0} = 0$。\n$$(r_{1} + \\beta_{0} p_{0})^{\\top}A p_{0} = 0$$\n$$r_{1}^{\\top}A p_{0} + \\beta_{0} p_{0}^{\\top}A p_{0} = 0$$\n解出 $\\beta_0$：\n$$\\beta_{0} = -\\frac{r_{1}^{\\top}A p_{0}}{p_{0}^{\\top}A p_{0}}$$\n我们有前面计算得到的项：$A p_0 = \\begin{pmatrix} 6 \\\\ 7 \\end{pmatrix}$ 和 $p_{0}^{\\top}A p_{0} = 20$。\n我们需要计算分子：\n$r_{1}^{\\top}A p_{0} = \\begin{pmatrix} -\\frac{1}{2}  \\frac{1}{4} \\end{pmatrix} \\begin{pmatrix} 6 \\\\ 7 \\end{pmatrix} = (-\\frac{1}{2})(6) + (\\frac{1}{4})(7) = -3 + \\frac{7}{4} = -\\frac{12}{4} + \\frac{7}{4} = -\\frac{5}{4}$。\n现在我们可以计算 $\\beta_0$：\n$$\\beta_{0} = - \\frac{-\\frac{5}{4}}{20} = \\frac{5}{4 \\cdot 20} = \\frac{5}{80} = \\frac{1}{16}$$\n\n所求的量为 $\\alpha_{0} = \\frac{1}{4}$，$x_{1} = \\begin{pmatrix} \\frac{1}{4} \\\\ \\frac{1}{2} \\end{pmatrix}$，$r_{1} = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix}$ 和 $\\beta_{0} = \\frac{1}{16}$。\n最终答案被组合成指定的行向量格式 $(\\alpha_{0}, x_{1,1}, x_{1,2}, r_{1,1}, r_{1,2}, \\beta_{0})$。\n这就得到了行向量 $(\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{2}, -\\frac{1}{2}, \\frac{1}{4}, \\frac{1}{16})$。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{4}  \\frac{1}{4}  \\frac{1}{2}  -\\frac{1}{2}  \\frac{1}{4}  \\frac{1}{16} \\end{pmatrix}}$$"
        },
        {
            "introduction": "现在，我们将从小规模的计算转向地球物理学中常见的、更具现实意义的计算问题。这个综合性练习要求你实现共轭梯度法来求解二维泊松方程，并数值验证其著名的收敛速度——该速度与矩阵条件数的平方根成正比。这个实践将理论收敛性分析与无矩阵（matrix-free）实现的实用技巧联系在一起，是连接理论与应用的重要一步。",
            "id": "3371602",
            "problem": "考虑一个矩形域上的二维稳态扩散模型，其带有齐次狄利克雷（Dirichlet）边界条件。设物理域为边长为 $L_x$ 和 $L_y$ 的矩形，控制方程为典型的椭圆模型 $-\\Delta u = f$，且在边界上 $u = 0$。使用中心差分法，在 $x$ 方向上取 $N_x$ 个内部点，在 $y$ 方向上取 $N_y$ 个内部点的均匀网格上对此模型进行离散化。这将得到一个线性系统 $A \\, x = b$，其中 $A$ 是对称正定（Symmetric Positive Definite, SPD）矩阵，$x$ 是离散解的节点值向量，$b$ 来自离散化的强制项。以下任务定义了一个独立的数值研究，旨在将共轭梯度（Conjugate Gradient）方法的预测收敛性与细长域（slender domains）情况下矩阵 $A$ 的谱条件数联系起来。\n\n任务：\n1. 从矩形上的离散拉普拉斯算子及其可分离结构出发。利用关于对称三对角托普利茨（Toeplitz）矩阵的基本性质以及与齐次狄利克雷边界条件相关的离散正弦基，推导出在张量积网格上由中心差分构造的二维算子的精确特征对。根据这些特征对，用极值特征值 $\\lambda_{\\min}$ 和 $\\lambda_{\\max}$ 表示谱条件数 $\\kappa(A)$，这些特征值依赖于 $L_x$、$L_y$、$N_x$ 和 $N_y$。\n2. 回顾共轭梯度法求解对称正定系统的定义属性：从零初始猜测开始，经过 $k$ 次迭代后，以能量范数度量的相对误差满足一个仅取决于 $\\kappa(A)$ 的极值多项式界。从第一性原理出发，将极小化极大（minimax）多项式特性与显式收敛包络联系起来，并解释在小容差情况下，与 $\\sqrt{\\kappa(A)}$ 相关的主导标度关系是如何出现的。\n3. 通过选择一个满足边界条件的光滑函数并计算相应的右端项来构造一个精确解。具体来说，令构造解为 $u(x,y) = \\sin\\!\\big(\\pi x / L_x\\big)\\,\\sin\\!\\big(\\pi y / L_y\\big)$，并在内部网格点 $x_i = i\\,h_x$ 和 $y_j = j\\,h_y$（其中 $h_x = L_x/(N_x+1)$，$h_y = L_y/(N_y+1)$）处进行采样。精确地构造 $b = A\\,x_{\\text{true}}$，从而使得离散解恰好为 $x_{\\text{true}}$。\n4. 从零向量 $x_0 = 0$ 开始实现共轭梯度法，当能量范数中的相对误差满足 $\\|x_k - x_{\\text{true}}\\|_A / \\|x_0 - x_{\\text{true}}\\|_A \\le \\varepsilon$ 时终止迭代，其中 $\\varepsilon$ 是给定的容差。此处的能量范数定义为 $\\|e\\|_A = \\sqrt{e^\\top A e}$。\n5. 对于下方的每个测试用例，计算：\n   - 满足停止准则所需的迭代次数 $k_{\\text{CG}}$，\n   - 使用任务1中推导的精确极值特征值计算的谱条件数 $\\kappa(A)$，\n   - 归一化比率 $s = k_{\\text{CG}} \\big/ \\big(\\tfrac{1}{2}\\,\\sqrt{\\kappa(A)}\\,\\log(2/\\varepsilon)\\big)$，该比率消除了理论上预测的、在小 $\\varepsilon$ 情况下对 $\\sqrt{\\kappa(A)}$ 的主阶依赖性。\n6. 你的程序必须实现 $A$ 的矩阵向量乘法操作，而不能显式地构造稠密矩阵 $A$。使用与均匀网格和齐次狄利克雷边界条件一致的五点格式。\n7. 使用以下测试套件，容差 $\\varepsilon = 10^{-8}$：\n   - 用例 1：$L_x = 1$, $L_y = 1$, $N_x = 31$, $N_y = 31$。\n   - 用例 2：$L_x = 1$, $L_y = 1$, $N_x = 127$, $N_y = 127$。\n   - 用例 3：$L_x = 1$, $L_y = 0.1$, $N_x = 127$, $N_y = 127$。\n   - 用例 4：$L_x = 1$, $L_y = 0.02$, $N_x = 127$, $N_y = 127$。\n   - 用例 5：$L_x = 5$, $L_y = 1$, $N_x = 255$, $N_y = 51$。\n8. 最终输出格式要求：你的程序应生成单行输出，其中包含五个测试用例的归一化比率 $s$，按用例1到5的顺序，以逗号分隔列表的形式包含在方括号中，不含空格。例如，输出必须类似于 $[s_1,s_2,s_3,s_4,s_5]$。每个 $s_i$ 必须是浮点数。\n\n注意：\n- 如果出现角度，必须以弧度为单位。此问题中不需要物理单位。\n- 唯一可接受的停止准则是任务4中指定的相对能量范数误差。\n- 离散算子必须严格对应于在所有边界上具有齐次狄利克雷边界条件的均匀网格五点格式。",
            "solution": "用户提供了一个在计算数学领域中有效、适定且具有科学依据的问题。这些任务涉及推导一个离散化偏微分方程的理论性质，并通过使用共轭梯度法的数值实验来验证这些性质。\n\n### 理论基础\n\n#### 任务1：离散拉普拉斯算子的特征值和条件数\n\n控制方程是在矩形域 $[0, L_x] \\times [0, L_y]$ 上的二维泊松（Poisson）方程，带有齐次狄利克雷边界条件：\n$$\n-\\Delta u = -\\left(\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}\\right) = f(x,y)\n$$\n在具有 $N_x \\times N_y$ 个内部点、网格间距为 $h_x = L_x / (N_x+1)$ 和 $h_y = L_y / (N_y+1)$ 的均匀网格上离散化此方程，并对导数采用二阶中心差分近似，我们得到在内部节点 $(i,j)$ 处负拉普拉斯算子 $A$ 的五点格式：\n$$\n(A u)_{i,j} = \\frac{-u_{i-1,j} + 2u_{i,j} - u_{i+1,j}}{h_x^2} + \\frac{-u_{i,j-1} + 2u_{i,j} - u_{i,j+1}}{h_y^2}\n$$\n其中 $u_{i,j}$ 是 $u(i h_x, j h_y)$ 的离散近似值。该系统可以写成线性系统 $A x = b$，其中 $x$ 是所有 $u_{i,j}$ 值的向量。\n\n算子 $A$ 是对称正定（SPD）的。其特征对可以通过利用其可分离结构找到。该算子是两个可交换算子的和，每个空间维度对应一个，这可以使用克罗内克（Kronecker）积形式化地表示：$A = A_x \\otimes I_y + I_x \\otimes A_y$。$A$ 的特征向量是一维离散拉普拉斯算子特征向量的张量积。\n\n对于具有 $N$ 个点和间距 $h$ 的一维问题，离散拉普拉斯矩阵与对称三对角托普利茨矩阵 $\\text{tridiag}(-1, 2, -1)$ 成比例。其特征向量是离散正弦函数，相应的特征值是众所周知的。对于用 $N_x$ 个点离散化的算子 $-\\frac{d^2}{dx^2}$，其特征值为：\n$$\n\\mu_{k_x} = \\frac{4}{h_x^2} \\sin^2\\left(\\frac{k_x \\pi}{2(N_x+1)}\\right), \\quad k_x = 1, 2, \\ldots, N_x\n$$\n类似地，对于 $y$ 方向：\n$$\n\\mu_{k_y} = \\frac{4}{h_y^2} \\sin^2\\left(\\frac{k_y \\pi}{2(N_y+1)}\\right), \\quad k_y = 1, 2, \\ldots, N_y\n$$\n二维算子 $A$ 的特征值 $\\lambda_{k_x, k_y}$ 是一维特征值的和：\n$$\n\\lambda_{k_x, k_y} = \\mu_{k_x} + \\mu_{k_y} = \\frac{4}{h_x^2} \\sin^2\\left(\\frac{k_x \\pi}{2(N_x+1)}\\right) + \\frac{4}{h_y^2} \\sin^2\\left(\\frac{k_y \\pi}{2(N_y+1)}\\right)\n$$\n其中 $1 \\le k_x \\le N_x$ 且 $1 \\le k_y \\le N_y$。\n\n要计算谱条件数 $\\kappa(A) = \\lambda_{\\max} / \\lambda_{\\min}$，需要极值特征值。\n最小特征值 $\\lambda_{\\min}$ 对应于最低频率，即 $k_x=1$ 和 $k_y=1$：\n$$\n\\lambda_{\\min} = \\frac{4}{h_x^2} \\sin^2\\left(\\frac{\\pi}{2(N_x+1)}\\right) + \\frac{4}{h_y^2} \\sin^2\\left(\\frac{\\pi}{2(N_y+1)}\\right)\n$$\n最大特征值 $\\lambda_{\\max}$ 对应于最高频率，即 $k_x=N_x$ 和 $k_y=N_y$。使用恒等式 $\\sin(\\frac{N \\pi}{2(N+1)}) = \\sin(\\frac{\\pi}{2} - \\frac{\\pi}{2(N+1)}) = \\cos(\\frac{\\pi}{2(N+1)})$，我们得到：\n$$\n\\lambda_{\\max} = \\frac{4}{h_x^2} \\sin^2\\left(\\frac{N_x \\pi}{2(N_x+1)}\\right) + \\frac{4}{h_y^2} \\sin^2\\left(\\frac{N_y \\pi}{2(N_y+1)}\\right) = \\frac{4}{h_x^2} \\cos^2\\left(\\frac{\\pi}{2(N_x+1)}\\right) + \\frac{4}{h_y^2} \\cos^2\\left(\\frac{\\pi}{2(N_y+1)}\\right)\n$$\n代入 $h_x = L_x/(N_x+1)$ 和 $h_y = L_y/(N_y+1)$ 即可得到用给定参数表示的最终表达式。谱条件数则为 $\\kappa(A) = \\lambda_{\\max} / \\lambda_{\\min}$。\n\n#### 任务2：共轭梯度收敛包络\n\n用于求解对称正定系统 $A x = b$ 的共轭梯度（CG）法是一种迭代方法，当从初始猜测 $x_0$ 开始时，会生成一个近似序列 $x_k$。误差 $e_k = x_k - x_{\\text{true}}$（其中 $x_{\\text{true}} = A^{-1}b$ 是精确解）在能量范数 $\\|v\\|_A = \\sqrt{v^\\top A v}$ 下满足一个关键的最优性：\n$$\n\\|e_k\\|_A = \\min_{P \\in \\mathcal{P}_k, P(0)=1} \\|P(A) e_0\\|_A\n$$\n其中 $\\mathcal{P}_k$ 是次数至多为 $k$ 的多项式空间。此性质导出了一个仅依赖于 $A$ 谱的相对误差减小的上界：\n$$\n\\frac{\\|e_k\\|_A}{\\|e_0\\|_A} \\le \\min_{P \\in \\mathcal{P}_k, P(0)=1} \\max_{\\lambda \\in [\\lambda_{\\min}, \\lambda_{\\max}]} |P(\\lambda)|\n$$\n这个极小化极大（minimax）多项式问题的解由一个经过缩放和平移的第一类切比雪夫（Chebyshev）多项式给出，从而得到紧凑界：\n$$\n\\frac{\\|e_k\\|_A}{\\|e_0\\|_A} \\le \\frac{1}{T_k\\left(\\frac{\\kappa+1}{\\kappa-1}\\right)}\n$$\n其中 $T_k$ 是 $k$ 次切比雪夫多项式，$\\kappa = \\kappa(A) = \\lambda_{\\max}/\\lambda_{\\min}$。一个更常用但稍弱的界是：\n$$\n\\frac{\\|e_k\\|_A}{\\|e_0\\|_A} \\le 2 \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^k\n$$\n要找到达到相对误差容差 $\\varepsilon$ 所需的迭代次数 $k$，我们将右侧设为小于等于 $\\varepsilon$：\n$$\n2 \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^k \\le \\varepsilon \\implies k \\log\\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right) \\le \\log(\\frac{\\varepsilon}{2})\n$$\n求解 $k$ 并使用 $\\log\\left( \\frac{a-1}{a+1} \\right) = -\\log\\left( \\frac{a+1}{a-1} \\right)$ 可得：\n$$\nk \\ge \\frac{\\log(2/\\varepsilon)}{\\log\\left( \\frac{\\sqrt{\\kappa} + 1}{\\sqrt{\\kappa} - 1} \\right)}\n$$\n对于大的条件数 $\\kappa \\gg 1$，我们可以使用近似 $\\log\\left( \\frac{z+1}{z-1} \\right) \\approx \\frac{2}{z}$（对于大的 $z$）。令 $z=\\sqrt{\\kappa}$，我们得到：\n$$\nk \\gtrsim \\frac{\\log(2/\\varepsilon)}{2/\\sqrt{\\kappa}} = \\frac{1}{2}\\sqrt{\\kappa} \\log(2/\\varepsilon)\n$$\n这个推导解释了迭代次数 $k_{\\text{CG}}$ 对 $\\sqrt{\\kappa(A)}$ 的主阶依赖性，并为归一化比率 $s = k_{\\text{CG}} \\big/ \\big(\\tfrac{1}{2}\\,\\sqrt{\\kappa(A)}\\,\\log(2/\\varepsilon)\\big)$ 的定义提供了依据，该比率预计接近于1。\n\n### 实现策略\n\n数值研究的实现遵循问题中的任务。\n- **构造解 (任务 3)**：通过在 $N_y \\times N_x$ 的内部网格点上采样函数 $u(x,y) = \\sin(\\pi x/L_x)\\sin(\\pi y/L_y)$ 来构造真实的离散解向量 $x_{\\text{true}}$。然后，使用一个免矩阵实现的 $A$ 的作用，将右端向量 $b$ 精确计算为 $b = A x_{\\text{true}}$。\n- **免矩阵算子 (任务 6)**：矩阵向量乘积 $v \\mapsto Av$ 被实现为一个函数。该函数接收一个扁平化的向量，将其重塑为 $N_y \\times N_x$ 的网格，通过在2D数组上操作并进行适当的填充来处理齐次狄利克雷边界，从而应用五点格式，然后将结果扁平化。这避免了存储完整矩阵 $A$（其维度为 $(N_xN_y) \\times (N_xN_y)$）所带来的过高内存成本。\n- **共轭梯度法 (任务 4)**：使用标准的CG算法实现，从零向量 $x_0=0$ 开始。迭代基于关于能量范数中相对误差的明确准则终止：$\\|x_k - x_{\\text{true}}\\|_A / \\|x_0 - x_{\\text{true}}\\|_A \\le \\varepsilon$。这需要在每次迭代中计算误差向量 $e_k = x_k - x_{\\text{true}}$ 及其能量范数 $\\|e_k\\|_A = \\sqrt{e_k^\\top A e_k}$，每次迭代需要额外一次矩阵向量乘积。分母 $\\|x_0 - x_{\\text{true}}\\|_A^2 = (-x_{\\text{true}})^\\top A (-x_{\\text{true}}) = x_{\\text{true}}^\\top A x_{\\text{true}} = x_{\\text{true}}^\\top b$ 是预先计算的。\n- **计算与分析 (任务 5  7)**：对于五个测试用例中的每一个，使用任务1中推导的公式计算精确的谱条件数 $\\kappa(A)$。运行CG求解器以确定迭代次数 $k_{\\text{CG}}$。最后，计算归一化比率 $s$ 并收集以供输出。\n整个过程通过使用NumPy库进行数值计算的Python脚本自动化实现。",
            "answer": "```python\nimport numpy as np\n\ndef get_matvec_operator(Nx, Ny, hx, hy):\n    \"\"\"\n    Returns a matrix-free function for the action of the 2D discrete Laplacian A.\n    \"\"\"\n    def matvec(x_flat):\n        \"\"\"\n        Computes the matrix-vector product A*x for the 2D discrete Laplacian.\n        -x_pp -x_mm + 2*x on each direction, scaled by 1/h^2.\n        \n        Args:\n            x_flat (np.ndarray): A 1D vector of shape (Nx*Ny,).\n\n        Returns:\n            np.ndarray: The result of A*x as a 1D vector.\n        \"\"\"\n        # Reshape the flat vector to a 2D grid representation\n        U = x_flat.reshape((Ny, Nx))\n        \n        # Pad the grid with zeros to enforce homogeneous Dirichlet boundary conditions\n        U_padded = np.zeros((Ny + 2, Nx + 2))\n        U_padded[1:-1, 1:-1] = U\n        \n        # Apply the five-point stencil for the negative Laplacian\n        laplacian_U = (\n            (2 * U - U_padded[1:-1, :-2] - U_padded[1:-1, 2:]) / (hx**2) +\n            (2 * U - U_padded[:-2, 1:-1] - U_padded[2:, 1:-1]) / (hy**2)\n        )\n        \n        return laplacian_U.flatten()\n\n    return matvec\n\ndef solve_cg(matvec, b, xtrue, epsilon, max_iter):\n    \"\"\"\n    Solves Ax = b using the Conjugate Gradient method.\n\n    Args:\n        matvec (function): A function that computes the matrix-vector product A*x.\n        b (np.ndarray): The right-hand side vector.\n        xtrue (np.ndarray): The true solution vector for error calculation.\n        epsilon (float): The tolerance for the stopping criterion.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        int: The number of iterations taken (k_CG).\n    \"\"\"\n    x = np.zeros_like(b)\n    r = b.copy()  # Since x0=0, r0 = b - A*x0 = b\n    p = r.copy()\n    rs_old = np.dot(r, r)\n\n    # Pre-calculate the denominator for the stopping criterion\n    # ||e0||_A^2 = ||-xtrue||_A^2 = xtrue.T * A * xtrue = xtrue.T * b\n    norm_A_e0_sq = np.dot(xtrue, b)\n    if norm_A_e0_sq == 0:\n        return 0\n\n    for k in range(1, max_iter + 1):\n        Ap = matvec(p)\n        alpha = rs_old / np.dot(p, Ap)\n        \n        x += alpha * p\n        r -= alpha * Ap\n        \n        # Check stopping criterion: ||x_k - xtrue||_A / ||x_0 - xtrue||_A = epsilon\n        e_k = x - xtrue\n        Ae_k = matvec(e_k)\n        norm_A_ek_sq = np.dot(e_k, Ae_k)\n        \n        rel_error_A = np.sqrt(norm_A_ek_sq / norm_A_e0_sq)\n\n        if rel_error_A = epsilon:\n            return k\n\n        rs_new = np.dot(r, r)\n        p = r + (rs_new / rs_old) * p\n        rs_old = rs_new\n        \n    return max_iter # Return max_iter if convergence is not reached\n\ndef run_case(Lx, Ly, Nx, Ny, epsilon):\n    \"\"\"\n    Runs a single test case for the numerical study.\n    \"\"\"\n    # 1. Grid and model parameters\n    hx = Lx / (Nx + 1)\n    hy = Ly / (Ny + 1)\n    \n    # 2. Compute exact extremal eigenvalues and condition number\n    sin_term_x_min = np.sin(np.pi / (2 * (Nx + 1)))**2\n    sin_term_y_min = np.sin(np.pi / (2 * (Ny + 1)))**2\n    cos_term_x_max = np.cos(np.pi / (2 * (Nx + 1)))**2\n    cos_term_y_max = np.cos(np.pi / (2 * (Ny + 1)))**2\n    \n    lambda_min = 4/hx**2 * sin_term_x_min + 4/hy**2 * sin_term_y_min\n    lambda_max = 4/hx**2 * cos_term_x_max + 4/hy**2 * cos_term_y_max\n    \n    kappa = lambda_max / lambda_min\n\n    # 3. Construct manufactured solution and RHS\n    x_coords = np.arange(1, Nx + 1) * hx\n    y_coords = np.arange(1, Ny + 1) * hy\n    XX, YY = np.meshgrid(x_coords, y_coords)\n    \n    U_true = np.sin(np.pi * XX / Lx) * np.sin(np.pi * YY / Ly)\n    xtrue = U_true.flatten()\n    \n    matvec = get_matvec_operator(Nx, Ny, hx, hy)\n    b = matvec(xtrue)\n    \n    # 4. Solve with CG and get iteration count\n    max_iter = 2 * (Nx + Ny) * 5 # A reasonable upper bound for iterations\n    k_cg = solve_cg(matvec, b, xtrue, epsilon, max_iter)\n    \n    # 5. Compute the normalized ratio s\n    theory_factor = 0.5 * np.sqrt(kappa) * np.log(2 / epsilon)\n    s = k_cg / theory_factor\n    \n    return s\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    epsilon = 1e-8\n    test_cases = [\n        # (Lx, Ly, Nx, Ny)\n        (1.0, 1.0, 31, 31),      # Case 1\n        (1.0, 1.0, 127, 127),    # Case 2\n        (1.0, 0.1, 127, 127),    # Case 3\n        (1.0, 0.02, 127, 127),   # Case 4\n        (5.0, 1.0, 255, 51),     # Case 5\n    ]\n\n    results = []\n    for case in test_cases:\n        Lx, Ly, Nx, Ny = case\n        s_val = run_case(Lx, Ly, Nx, Ny, epsilon)\n        results.append(s_val)\n\n    # Format the final output as specified\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}