{
    "hands_on_practices": [
        {
            "introduction": "The first step in any Polynomial Chaos Expansion is defining the set of basis functions, as the size of this set directly impacts the computational cost of building and evaluating the surrogate model. This exercise  delves into the combinatorial aspect of constructing a \"total-degree\" truncated basis, a common and efficient choice in practice. By deriving the formula for the basis size and enumerating the indices, you will gain a concrete understanding of the structure and dimensionality of a PCE approximation.",
            "id": "3523172",
            "problem": "Consider a non-intrusive Polynomial Chaos Expansion (PCE) for a coupled thermoelastic–fluid system in a multiphysics simulation. The uncertain input is modeled by a random vector $\\boldsymbol{\\xi} \\in \\mathbb{R}^{d}$ with $d$ independent components corresponding to five material and coupling parameters ($d=5$). To construct a finite-dimensional approximation, you use a total-degree truncated multiindex set defined by\n$$\n\\Lambda_{\\mathrm{TD}}(p) \\equiv \\left\\{ \\alpha \\in \\mathbb{N}_{0}^{d} : \\|\\alpha\\|_{1} \\le p \\right\\},\n$$\nwhere $\\|\\alpha\\|_{1} = \\sum_{i=1}^{d} \\alpha_{i}$ and $p$ is the maximum polynomial degree ($p=3$). The PCE basis functions are indexed by $\\alpha \\in \\Lambda_{\\mathrm{TD}}(p)$ and orthogonal with respect to the input measure. \n\nStarting from fundamental definitions of multiindices and first principles of combinatorial counting (combinations with repetition), derive the cardinality of the index set $\\Lambda_{\\mathrm{TD}}(p)$ for $d=5$ and $p=3$ without invoking any pre-memorized shortcut formulas. Then, explicitly enumerate all multiindices $\\alpha \\in \\mathbb{N}_{0}^{5}$ satisfying $\\|\\alpha\\|_{1} \\le 3$ in lexicographic order, where lexicographic order is defined by $\\alpha \\prec \\beta$ if there exists $j \\in \\{1,\\dots,5\\}$ such that $\\alpha_{i}=\\beta_{i}$ for all $i<j$ and $\\alpha_{j}<\\beta_{j}$. \n\nProvide both the derived cardinality and the complete lexicographic list as part of your reasoning. For submission, express your final answer as the single real-valued cardinality of $\\Lambda_{\\mathrm{TD}}(3)$ for $d=5$. No rounding is required.",
            "solution": "The problem requires the derivation of the cardinality of a total-degree truncated multi-index set and the explicit enumeration of its elements for a specific case. The set is defined as $\\Lambda_{\\mathrm{TD}}(p) \\equiv \\left\\{ \\alpha \\in \\mathbb{N}_{0}^{d} : \\|\\alpha\\|_{1} \\le p \\right\\}$, with dimension $d=5$ and maximum polynomial degree $p=3$.\n\nFirst, we derive the cardinality of $\\Lambda_{\\mathrm{TD}}(p)$, denoted $|\\Lambda_{\\mathrm{TD}}(p)|$, from first principles of combinatorial counting, as requested. The condition is that for a multi-index $\\alpha = (\\alpha_1, \\alpha_2, \\dots, \\alpha_d)$, where each $\\alpha_i$ is a non-negative integer, the sum must satisfy $\\sum_{i=1}^{d} \\alpha_i \\le p$.\n\nThis inequality can be converted into an equality by introducing an auxiliary non-negative integer variable, $\\alpha_{d+1} \\in \\mathbb{N}_0$, often called a slack variable. We define $\\alpha_{d+1}$ such that the sum is exactly equal to $p$:\n$$\n\\alpha_1 + \\alpha_2 + \\dots + \\alpha_d + \\alpha_{d+1} = p\n$$\nFor any set of non-negative integers $(\\alpha_1, \\dots, \\alpha_d)$ satisfying the original inequality $\\sum_{i=1}^{d} \\alpha_i = k \\le p$, there exists a unique non-negative integer $\\alpha_{d+1} = p - k$ that satisfies the equality. Conversely, for any solution $(\\alpha_1, \\dots, \\alpha_d, \\alpha_{d+1})$ to the equality in non-negative integers, the first $d$ components satisfy the original inequality. Thus, the number of solutions to the inequality in $d$ variables is identical to the number of non-negative integer solutions to the equality in $d+1$ variables.\n\nThis latter problem is a classic combinatorial problem known as \"combinations with repetition,\" which can be solved using the \"stars and bars\" method. We need to find the number of ways to partition a sum of $p$ into $d+1$ non-negative integer terms. This is equivalent to arranging $p$ identical items (stars) and $(d+1)-1 = d$ identical dividers (bars) in a sequence. The total number of positions in the sequence is $p+d$. The number of ways to choose the positions for the $d$ bars (or, equivalently, the $p$ stars) determines the number of unique solutions. This count is given by the binomial coefficient:\n$$\n|\\Lambda_{\\mathrm{TD}}(p)| = \\binom{p+d}{d} = \\binom{p+d}{p}\n$$\nThis derivation from the fundamental stars and bars analogy fulfills the requirement of not using a pre-memorized shortcut formula.\n\nNow, we apply this derived formula to the specific parameters given: $d=5$ and $p=3$.\n$$\n|\\Lambda_{\\mathrm{TD}}(3)| = \\binom{3+5}{5} = \\binom{8}{5}\n$$\nThe value of the binomial coefficient is calculated as:\n$$\n\\binom{8}{5} = \\frac{8!}{5!(8-5)!} = \\frac{8!}{5!3!} = \\frac{8 \\times 7 \\times 6}{3 \\times 2 \\times 1} = 8 \\times 7 = 56\n$$\nThe cardinality of the index set $\\Lambda_{\\mathrm{TD}}(3)$ for $d=5$ is $56$.\n\nSecond, we explicitly enumerate all $56$ multi-indices $\\alpha = (\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4, \\alpha_5)$ satisfying $\\alpha_i \\in \\mathbb{N}_0$ and $\\sum_{i=1}^{5} \\alpha_i \\le 3$. The enumeration is presented in lexicographic order.\n\nThe complete list of multi-indices is as follows:\n(0,0,0,0,0), (0,0,0,0,1), (0,0,0,0,2), (0,0,0,0,3), (0,0,0,1,0), (0,0,0,1,1), (0,0,0,1,2), (0,0,0,2,0), (0,0,0,2,1), (0,0,0,3,0), (0,0,1,0,0), (0,0,1,0,1), (0,0,1,0,2), (0,0,1,1,0), (0,0,1,1,1), (0,0,1,2,0), (0,0,2,0,0), (0,0,2,0,1), (0,0,2,1,0), (0,0,3,0,0), (0,1,0,0,0), (0,1,0,0,1), (0,1,0,0,2), (0,1,0,1,0), (0,1,0,1,1), (0,1,0,2,0), (0,1,1,0,0), (0,1,1,0,1), (0,1,1,1,0), (0,1,2,0,0), (0,2,0,0,0), (0,2,0,0,1), (0,2,0,1,0), (0,2,1,0,0), (0,3,0,0,0), (1,0,0,0,0), (1,0,0,0,1), (1,0,0,0,2), (1,0,0,1,0), (1,0,0,1,1), (1,0,0,2,0), (1,0,1,0,0), (1,0,1,0,1), (1,0,1,1,0), (1,0,2,0,0), (1,1,0,0,0), (1,1,0,0,1), (1,1,0,1,0), (1,1,1,0,0), (1,2,0,0,0), (2,0,0,0,0), (2,0,0,0,1), (2,0,0,1,0), (2,0,1,0,0), (2,1,0,0,0), (3,0,0,0,0)",
            "answer": "$$\n\\boxed{56}\n$$"
        },
        {
            "introduction": "With the basis defined, the next step is to compute the expansion coefficients for a given model output. This hands-on coding exercise  guides you through implementing the powerful \"non-intrusive\" pseudo-spectral projection method, which treats the underlying computational model as a black box. You will learn how to leverage numerical quadrature to accurately determine the coefficients, a fundamental skill for applying PCE to complex simulation codes.",
            "id": "3523191",
            "problem": "Consider a random input vector $\\boldsymbol{\\xi} \\in \\mathbb{R}^{d}$ whose components are independent and identically distributed standard normal random variables. Let $\\{\\Psi_{\\alpha}(\\boldsymbol{\\xi})\\}_{\\alpha \\in \\mathbb{N}_{0}^{d}}$ denote the tensorized orthonormal polynomial chaos basis built from the probabilists' Hermite polynomials, that is, for a multi-index $\\alpha = (\\alpha_{1},\\dots,\\alpha_{d})$, define\n$$\n\\Psi_{\\alpha}(\\boldsymbol{\\xi}) \\;=\\; \\prod_{k=1}^{d} \\psi_{\\alpha_{k}}(\\xi_{k}),\n$$\nwhere $\\psi_{n}(\\xi)$ is the $n$-th degree one-dimensional orthonormal polynomial under the standard normal measure. The probabilists' Hermite polynomials $\\mathrm{He}_{n}(\\xi)$ satisfy the recurrence $\\mathrm{He}_{0}(\\xi)=1$, $\\mathrm{He}_{1}(\\xi)=\\xi$, and $\\mathrm{He}_{n+1}(\\xi)=\\xi\\,\\mathrm{He}_{n}(\\xi) - n\\,\\mathrm{He}_{n-1}(\\xi)$ for $n \\geq 1$. The orthonormal polynomials are $\\psi_{n}(\\xi) = \\mathrm{He}_{n}(\\xi)/\\sqrt{n!}$, yielding $\\mathbb{E}[\\psi_{m}(\\xi)\\psi_{n}(\\xi)] = \\delta_{mn}$ and thus $\\mathbb{E}[\\Psi_{\\alpha}(\\boldsymbol{\\xi})\\Psi_{\\beta}(\\boldsymbol{\\xi})] = \\delta_{\\alpha\\beta}$.\n\nThe pseudo-spectral projection computes the polynomial chaos coefficients of a square-integrable model response $u(\\boldsymbol{\\xi})$ by\n$$\nc_{\\alpha} \\;=\\; \\mathbb{E}\\big[u(\\boldsymbol{\\xi})\\,\\Psi_{\\alpha}(\\boldsymbol{\\xi})\\big],\n$$\nfor all multi-indices $\\alpha$ in a chosen truncation. Consider the total-degree truncation set\n$$\n\\mathcal{A}_{p}^{(d)} \\;=\\; \\Big\\{ \\alpha \\in \\mathbb{N}_{0}^{d} \\,:\\, \\sum_{k=1}^{d} \\alpha_{k} \\leq p \\Big\\},\n$$\nfor a prescribed total degree $p \\in \\mathbb{N}_{0}$ and dimension $d \\in \\mathbb{N}$.\n\nTo approximate the expectations, use tensor-product Gauss–Hermite quadrature constructed from one-dimensional Gauss–Hermite rules, with the change of variables that maps the Gauss–Hermite abscissae and weights for the integral $\\int_{\\mathbb{R}} f(x)\\,e^{-x^{2}}\\,dx$ into the standard normal expectation $\\mathbb{E}[f(\\xi)]$. The resulting tensor-product quadrature should be exact for any multivariate polynomial whose degree in each coordinate is at most $2m-1$, where $m$ is the one-dimensional number of Gauss–Hermite points. Your program must:\n- Implement the pseudo-spectral projection to compute all coefficients $c_{\\alpha}$ for $\\alpha \\in \\mathcal{A}_{p}^{(d)}$ using tensor-product quadrature.\n- From first principles, determine and report the minimal one-dimensional quadrature level $m$ (i.e., the number of Gauss–Hermite points per dimension) required to integrate exactly any product of polynomials arising in the projections for total degree $p$, and the total number of tensor-product nodes $M = m^{d}$.\n- For a given test suite (specified below), construct $u(\\boldsymbol{\\xi})$ as a finite chaos expansion with known coefficients, and verify numerically that the computed coefficients match the true ones by reporting the maximum absolute coefficient error.\n\nTest suite. For each of the following parameter sets $(d,p)$, define the true nonzero coefficients $\\{c_{\\alpha}^{\\mathrm{true}}\\}$ of $u(\\boldsymbol{\\xi}) = \\sum_{\\alpha \\in \\mathcal{A}_{p}^{(d)}} c_{\\alpha}^{\\mathrm{true}}\\,\\Psi_{\\alpha}(\\boldsymbol{\\xi})$ as listed. Any coefficient not explicitly listed is zero. For each case, compute:\n- The minimal one-dimensional quadrature level $m$.\n- The total number of tensor-product nodes $M = m^{d}$.\n- The maximum absolute difference $\\max_{\\alpha \\in \\mathcal{A}_{p}^{(d)}} |c_{\\alpha}^{\\mathrm{quad}} - c_{\\alpha}^{\\mathrm{true}}|$.\n\nUse the following cases:\n- Case A: $d = 1$, $p = 3$, with\n  $c_{(0)}^{\\mathrm{true}} = 1.3$, $c_{(1)}^{\\mathrm{true}} = -0.7$, $c_{(2)}^{\\mathrm{true}} = 0.5$, $c_{(3)}^{\\mathrm{true}} = -0.2$.\n- Case B: $d = 2$, $p = 2$, with\n  $c_{(0,0)}^{\\mathrm{true}} = 0.9$, $c_{(1,0)}^{\\mathrm{true}} = -0.4$, $c_{(0,1)}^{\\mathrm{true}} = 0.75$, $c_{(2,0)}^{\\mathrm{true}} = 0.3$, $c_{(0,2)}^{\\mathrm{true}} = -0.35$, $c_{(1,1)}^{\\mathrm{true}} = 0.25$.\n- Case C: $d = 3$, $p = 3$, with\n  $c_{(0,0,0)}^{\\mathrm{true}} = 1.0$, $c_{(1,0,0)}^{\\mathrm{true}} = -0.2$, $c_{(0,1,0)}^{\\mathrm{true}} = 0.15$, $c_{(0,0,1)}^{\\mathrm{true}} = 0.1$, $c_{(2,0,0)}^{\\mathrm{true}} = 0.05$, $c_{(0,2,0)}^{\\mathrm{true}} = -0.04$, $c_{(0,0,2)}^{\\mathrm{true}} = 0.03$, $c_{(1,1,0)}^{\\mathrm{true}} = -0.06$, $c_{(1,0,1)}^{\\mathrm{true}} = 0.07$, $c_{(0,1,1)}^{\\mathrm{true}} = -0.02$, $c_{(3,0,0)}^{\\mathrm{true}} = 0.01$, $c_{(0,3,0)}^{\\mathrm{true}} = -0.008$, $c_{(0,0,3)}^{\\mathrm{true}} = 0.006$, $c_{(2,1,0)}^{\\mathrm{true}} = 0.004$.\n- Case D: $d = 2$, $p = 0$, with\n  $c_{(0,0)}^{\\mathrm{true}} = 2.5$.\n\nOutput specification. Your program must produce a single line of output containing a flat, comma-separated list of results for the cases in the order A, B, C, D. For each case, append in order:\n- the minimal one-dimensional quadrature level $m$ (an integer),\n- the total number of tensor-product nodes $M$ (an integer),\n- the maximum absolute coefficient error (a floating point number).\n\nThus the final output must be a single list in the form [m_A,M_A,err_A,m_B,M_B,err_B,m_C,M_C,err_C,m_D,M_D,err_D], with no additional text or whitespace beyond what is necessary to represent the list.",
            "solution": "We begin with a random input $\\boldsymbol{\\xi} \\in \\mathbb{R}^{d}$, whose components are independent standard normal random variables. Under this measure, the probabilists' Hermite polynomials $\\mathrm{He}_{n}(\\xi)$ provide an orthogonal family with respect to the standard normal density. By defining the orthonormal one-dimensional basis $\\psi_{n}(\\xi) = \\mathrm{He}_{n}(\\xi)/\\sqrt{n!}$, we obtain an orthonormal tensorized basis in $d$ dimensions:\n$$\n\\Psi_{\\alpha}(\\boldsymbol{\\xi}) \\;=\\; \\prod_{k=1}^{d} \\psi_{\\alpha_{k}}(\\xi_{k}), \\qquad \\alpha \\in \\mathbb{N}_{0}^{d},\n$$\nsatisfying $\\mathbb{E}\\big[\\Psi_{\\alpha}(\\boldsymbol{\\xi})\\Psi_{\\beta}(\\boldsymbol{\\xi})\\big] = \\delta_{\\alpha\\beta}$ by independence and one-dimensional orthonormality.\n\nFor a square-integrable model response $u(\\boldsymbol{\\xi})$, the pseudo-spectral projection defines the coefficient of mode $\\alpha$ by\n$$\nc_{\\alpha} \\;=\\; \\mathbb{E}\\big[u(\\boldsymbol{\\xi})\\,\\Psi_{\\alpha}(\\boldsymbol{\\xi})\\big] \\;=\\; \\int_{\\mathbb{R}^{d}} u(\\boldsymbol{\\xi})\\,\\Psi_{\\alpha}(\\boldsymbol{\\xi})\\, \\prod_{k=1}^{d} \\phi(\\xi_{k})\\,d\\boldsymbol{\\xi},\n$$\nwhere $\\phi(\\xi)$ is the standard normal density. For computational purposes, this expectation is approximated using tensor-product Gauss–Hermite quadrature rules. A one-dimensional Gauss–Hermite rule with $m$ points integrates exactly $\\int_{\\mathbb{R}} q(x)e^{-x^{2}}dx$ for any polynomial $q$ of degree at most $2m-1$. To apply this to the standard normal expectation, we use the change of variables $\\xi = \\sqrt{2}\\,x$, which yields\n$$\n\\mathbb{E}[f(\\xi)] \\;=\\; \\frac{1}{\\sqrt{\\pi}} \\int_{\\mathbb{R}} f(\\sqrt{2}\\,x)\\,e^{-x^{2}}\\,dx.\n$$\nThus, if $\\{(x_{i},w_{i})\\}_{i=1}^{m}$ are the Gauss–Hermite nodes and weights for $e^{-x^{2}}$, we obtain the quadrature approximation for the expectation:\n$$\n\\mathbb{E}[f(\\xi)] \\;\\approx\\; \\frac{1}{\\sqrt{\\pi}} \\sum_{i=1}^{m} w_{i}\\, f\\big(\\sqrt{2}\\,x_{i}\\big).\n$$\nIn $d$ dimensions with independent coordinates, the tensor-product quadrature yields\n$$\n\\mathbb{E}[f(\\boldsymbol{\\xi})] \\;\\approx\\; \\frac{1}{\\pi^{d/2}} \\sum_{i_{1}=1}^{m}\\cdots\\sum_{i_{d}=1}^{m} \\Big(\\prod_{k=1}^{d} w_{i_{k}}\\Big) \\, f\\big(\\sqrt{2}\\,x_{i_{1}},\\dots,\\sqrt{2}\\,x_{i_{d}}\\big).\n$$\n\nMinimal quadrature level. We consider the truncated basis set $\\mathcal{A}_{p}^{(d)} = \\{\\alpha \\in \\mathbb{N}_{0}^{d}: \\sum_{k=1}^{d}\\alpha_{k}\\le p\\}$. For each coefficient,\n$$\nc_{\\alpha} \\;=\\; \\mathbb{E}\\big[u(\\boldsymbol{\\xi})\\,\\Psi_{\\alpha}(\\boldsymbol{\\xi})\\big].\n$$\nWhen $u(\\boldsymbol{\\xi})$ is itself a polynomial chaos of total degree at most $p$:\n$$\nu(\\boldsymbol{\\xi}) \\;=\\; \\sum_{\\beta \\in \\mathcal{A}_{p}^{(d)}} c_{\\beta}^{\\mathrm{true}}\\, \\Psi_{\\beta}(\\boldsymbol{\\xi}),\n$$\nthe integrand $u(\\boldsymbol{\\xi})\\Psi_{\\alpha}(\\boldsymbol{\\xi})$ is a product of two orthonormal polynomials. As a function of each coordinate $\\xi_{k}$, this product is a polynomial whose degree in $\\xi_{k}$ is at most $\\alpha_{k} + \\beta_{k} \\le 2p$, and the total degree across all coordinates is at most $2p$ as well. A $d$-dimensional tensor-product Gauss–Hermite rule of $m$ points per dimension is exact for any integrand that is a polynomial of degree at most $2m-1$ in each coordinate (with respect to $e^{-x^{2}}$). Under the change of variables to the standard normal measure, the degree in each coordinate remains unchanged. Therefore, to integrate exactly all such products for any $\\alpha,\\beta \\in \\mathcal{A}_{p}^{(d)}$, it suffices to require\n$$\n2m - 1 \\;\\ge\\; 2p \\quad \\Longleftrightarrow \\quad m \\;\\ge\\; p + 1,\n$$\nand the minimal one-dimensional quadrature level is $m_{\\min} = p + 1$. The total number of tensor-product nodes is $M = m^{d} = (p+1)^{d}$.\n\nAlgorithmic design. For each test case $(d,p)$:\n- Construct the multi-index set $\\mathcal{A}_{p}^{(d)}$.\n- Compute $m = p+1$ and $M = m^{d}$.\n- Generate one-dimensional Gauss–Hermite nodes and weights $\\{(x_{i},w_{i})\\}_{i=1}^{m}$ for the weight $e^{-x^{2}}$, and transform them to standard normal quadrature nodes and weights via $\\xi_{i} = \\sqrt{2}\\,x_{i}$ and $\\tilde{w}_{i} = w_{i}/\\sqrt{\\pi}$.\n- Form the $d$-dimensional tensor product of nodes and weights.\n- Compute values of one-dimensional orthonormal polynomials $\\psi_{n}(\\xi)$ for $n=0,\\dots,p$ at the quadrature abscissae along each dimension using the probabilists' Hermite recurrence for $\\mathrm{He}_{n}(\\xi)$ and normalization by $\\sqrt{n!}$.\n- Synthesize $u(\\boldsymbol{\\xi})$ on the quadrature grid using the given true coefficients by summing the corresponding $\\Psi_{\\beta}(\\boldsymbol{\\xi})$ contributions.\n- For each $\\alpha \\in \\mathcal{A}_{p}^{(d)}$, evaluate $\\Psi_{\\alpha}(\\boldsymbol{\\xi})$ on the grid and compute $c_{\\alpha}^{\\mathrm{quad}}$ as the weighted sum $c_{\\alpha}^{\\mathrm{quad}} \\approx \\sum w^{(d)}\\, u(\\boldsymbol{\\xi})\\,\\Psi_{\\alpha}(\\boldsymbol{\\xi})$.\n- Compare to the true coefficients and report the maximum absolute error.\n\nVerification. Because $u$ is a polynomial chaos of total degree at most $p$ and we select $m = p+1$, the tensor-product Gauss–Hermite rule is exact for the coordinatewise polynomial degrees arising in the projections. Therefore, up to floating-point rounding errors, we expect $c_{\\alpha}^{\\mathrm{quad}} = c_{\\alpha}^{\\mathrm{true}}$ for all $\\alpha \\in \\mathcal{A}_{p}^{(d)}$, yielding a maximum absolute error on the order of machine precision. The program will output, for each case, the tuple $(m, M, \\max_{\\alpha}|c_{\\alpha}^{\\mathrm{quad}} - c_{\\alpha}^{\\mathrm{true}}|)$, concatenated into a single bracketed list as specified.",
            "answer": "```python\nimport numpy as np\nimport math\nfrom itertools import product\n\ndef hermite_probabilists_orthonormal_values(x, nmax):\n    \"\"\"\n    Compute values of orthonormal probabilists' Hermite polynomials psi_n at points x,\n    for n = 0..nmax. Returns an array of shape (nmax+1, len(x)).\n    psi_n = He_n / sqrt(n!), with He_0=1, He_1=x, He_{n+1} = x He_n - n He_{n-1}.\n    \"\"\"\n    x = np.asarray(x)\n    N = nmax + 1\n    vals = np.zeros((N, x.size), dtype=float)\n    # He_0\n    He_nm1 = np.ones_like(x)\n    vals[0, :] = He_nm1 / math.sqrt(math.factorial(0))\n    if nmax == 0:\n        return vals\n    # He_1\n    He_n = x.copy()\n    vals[1, :] = He_n / math.sqrt(math.factorial(1))\n    for n in range(1, nmax):\n        He_np1 = x * He_n - n * He_nm1\n        vals[n+1, :] = He_np1 / math.sqrt(math.factorial(n+1))\n        He_nm1, He_n = He_n, He_np1\n    return vals\n\ndef multiindex_total_degree(d, p):\n    \"\"\"\n    Generate all multi-indices alpha in N_0^d with total degree sum(alpha) <= p.\n    Order: lexicographic increasing by alpha.\n    \"\"\"\n    # We can generate by filtering all tuples in [0..p]^d\n    indices = []\n    for alpha in product(range(p+1), repeat=d):\n        if sum(alpha) <= p:\n            indices.append(tuple(alpha))\n    # Already lex order due to product with increasing ranges.\n    return indices\n\ndef tensor_product_gh_quadrature(d, m):\n    \"\"\"\n    Construct d-dimensional tensor product Gauss-Hermite quadrature for standard normal expectation.\n    One-dimensional rule: nodes x_i, weights w_i integrate \\int f(x) e^{-x^2} dx exactly up to deg 2m-1.\n    Transform to standard normal: xi_i = sqrt(2) * x_i, wtilde_i = w_i / sqrt(pi).\n    Returns grid nodes of shape (num_nodes, d) and weights of shape (num_nodes,).\n    \"\"\"\n    # 1D Gauss-Hermite for e^{-x^2}\n    x1d, w1d = np.polynomial.hermite.hermgauss(m)  # nodes/weights for e^{-x^2}\n    # Transform to standard normal expectation weights\n    xi1d = np.sqrt(2.0) * x1d\n    w1d_tilde = w1d / math.sqrt(math.pi)\n    # Tensor product\n    grids = np.meshgrid(*([xi1d] * d), indexing='ij')\n    nodes = np.stack([g.reshape(-1) for g in grids], axis=1)\n    # Weights as product\n    wg = w1d_tilde\n    wgrids = np.meshgrid(*([wg] * d), indexing='ij')\n    weights = np.ones_like(wgrids[0])\n    for wg_comp in wgrids:\n        weights = weights * wg_comp\n    weights = weights.reshape(-1)\n    return nodes, weights, xi1d, w1d_tilde\n\ndef build_u_on_grid(d, p, coeffs_true, xi1d, basis1d_cache):\n    \"\"\"\n    Build u on the full tensor grid using the chaos expansion with given true coefficients.\n    coeffs_true: dict mapping multiindex tuple to coefficient.\n    xi1d: 1D nodes per dimension (same across dims).\n    basis1d_cache: list of size d, each entry is (vals), where vals has shape (p+1, m).\n    Returns u_grid array of shape (m,)*d.\n    \"\"\"\n    m = xi1d.size\n    shape = (m,) * d\n    u_grid = np.zeros(shape, dtype=float)\n    # For broadcasting per dim, precompute basis grids per dim and degree\n    # B[k][n] has shape (m,)*d, storing psi_n evaluated along dimension k and broadcast on others.\n    B = []\n    for k in range(d):\n        vals_k = basis1d_cache[k]  # shape (p+1, m)\n        Bk = []\n        for n in range(p+1):\n            vec = vals_k[n, :]  # length m\n            resh = [1]*d\n            resh[k] = m\n            arr = vec.reshape(resh)\n            # Broadcast to full grid lazily during multiplication\n            Bk.append(arr)\n        B.append(Bk)\n    # Sum contributions\n    for alpha, c in coeffs_true.items():\n        if sum(alpha) > p:\n            continue  # outside truncation\n        phi = np.ones(shape, dtype=float)\n        for k in range(d):\n            phi = phi * B[k][alpha[k]]\n        u_grid += c * phi\n    return u_grid\n\ndef project_coefficients(d, p, u_grid, w_grid, xi1d, basis1d_cache, indices):\n    \"\"\"\n    Compute coefficients c_alpha via quadrature for alpha in indices.\n    u_grid: values of u on tensor grid of shape (m,)*d.\n    w_grid: tensor product weights on the same grid shape.\n    basis1d_cache: list per dim with shape (p+1, m).\n    indices: list of multi-indices to project.\n    Returns a dict mapping alpha to c_alpha.\n    \"\"\"\n    m = xi1d.size\n    shape = (m,) * d\n    # Precompute B grids as in build_u_on_grid\n    B = []\n    for k in range(d):\n        vals_k = basis1d_cache[k]  # shape (p+1, m)\n        Bk = []\n        for n in range(p+1):\n            vec = vals_k[n, :]  # length m\n            resh = [1]*d\n            resh[k] = m\n            arr = vec.reshape(resh)\n            Bk.append(arr)\n        B.append(Bk)\n    c = {}\n    for alpha in indices:\n        phi = np.ones(shape, dtype=float)\n        for k in range(d):\n            phi = phi * B[k][alpha[k]]\n        # Weighted inner product E[u * Psi_alpha]\n        val = np.sum(w_grid * u_grid * phi)\n        c[alpha] = float(val)\n    return c\n\ndef run_case(d, p, coeffs_true):\n    # Minimal quadrature level and total nodes\n    m = p + 1\n    nodes, weights, xi1d, w1d_tilde = tensor_product_gh_quadrature(d, m)\n    # Build tensor weight grid\n    m1 = xi1d.size\n    wgrids = np.meshgrid(*([w1d_tilde]*d), indexing='ij')\n    w_grid = np.ones_like(wgrids[0])\n    for wg in wgrids:\n        w_grid = w_grid * wg\n    # Basis values per dimension\n    basis1d_cache = [hermite_probabilists_orthonormal_values(xi1d, p) for _ in range(d)]\n    # Build u on grid\n    u_grid = build_u_on_grid(d, p, coeffs_true, xi1d, basis1d_cache)\n    # Multi-indices\n    indices = multiindex_total_degree(d, p)\n    # Project\n    c_quad = project_coefficients(d, p, u_grid, w_grid, xi1d, basis1d_cache, indices)\n    # Prepare true coefficients vector aligned with indices\n    true_vec = np.array([coeffs_true.get(alpha, 0.0) for alpha in indices], dtype=float)\n    quad_vec = np.array([c_quad[alpha] for alpha in indices], dtype=float)\n    max_err = float(np.max(np.abs(true_vec - quad_vec))) if indices else 0.0\n    M = m ** d\n    return m, M, max_err\n\ndef solve():\n    # Define test cases\n    # Case A: d=1, p=3\n    coeffs_A = {\n        (0,): 1.3,\n        (1,): -0.7,\n        (2,): 0.5,\n        (3,): -0.2,\n    }\n    # Case B: d=2, p=2\n    coeffs_B = {\n        (0,0): 0.9,\n        (1,0): -0.4,\n        (0,1): 0.75,\n        (2,0): 0.3,\n        (0,2): -0.35,\n        (1,1): 0.25,\n    }\n    # Case C: d=3, p=3\n    coeffs_C = {\n        (0,0,0): 1.0,\n        (1,0,0): -0.2,\n        (0,1,0): 0.15,\n        (0,0,1): 0.1,\n        (2,0,0): 0.05,\n        (0,2,0): -0.04,\n        (0,0,2): 0.03,\n        (1,1,0): -0.06,\n        (1,0,1): 0.07,\n        (0,1,1): -0.02,\n        (3,0,0): 0.01,\n        (0,3,0): -0.008,\n        (0,0,3): 0.006,\n        (2,1,0): 0.004,\n    }\n    # Case D: d=2, p=0\n    coeffs_D = {\n        (0,0): 2.5,\n    }\n\n    test_cases = [\n        (1, 3, coeffs_A),\n        (2, 2, coeffs_B),\n        (3, 3, coeffs_C),\n        (2, 0, coeffs_D),\n    ]\n\n    results = []\n    for d, p, coeffs in test_cases:\n        m, M, err = run_case(d, p, coeffs)\n        results.append(str(m))\n        results.append(str(M))\n        # Format error with sufficient precision but concise\n        results.append(f\"{err:.16g}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "A key benefit of PCE is that the resulting coefficients are not just for building a surrogate model; they contain a wealth of statistical information. This practice  demonstrates how, once the coefficients are known, one can efficiently compute the mean, variance, and Sobol' sensitivity indices. This post-processing step reveals how different uncertain inputs contribute to the output's variability, providing deep quantitative insights at a negligible computational cost.",
            "id": "3523157",
            "problem": "In a conjugate heat transfer–thermoelastic coupling, a reduced-order model predicts the steady interface temperature response $u(\\boldsymbol{\\xi})$ of a micro heat-exchanger subjected to uncertain thermal and mechanical boundary conditions. The uncertain inputs are mapped to three independent standardized variables $\\boldsymbol{\\xi}=(\\xi_{1},\\xi_{2},\\xi_{3})$, with $\\xi_{i}\\sim \\mathcal{U}[-1,1]$ and mutually independent. A Polynomial Chaos Expansion (PCE) represents the model output as\n$$\nu(\\boldsymbol{\\xi})=\\sum_{\\boldsymbol{\\alpha}\\in \\mathbb{N}_{0}^{3}} c_{\\boldsymbol{\\alpha}}\\,\\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}),\n$$\nwhere $\\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})=\\prod_{i=1}^{3}\\varphi_{\\alpha_{i}}(\\xi_{i})$ and $\\{\\varphi_{n}\\}_{n\\ge 0}$ are the orthonormal Legendre polynomials on $[-1,1]$ with respect to the uniform measure, i.e., $\\mathbb{E}[\\varphi_{n}(\\xi)\\varphi_{m}(\\xi)]=\\delta_{nm}$ and $\\varphi_{0}(\\xi)=1$. Consequently, the multivariate basis is orthonormal: $\\mathbb{E}[\\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})]=\\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$. The nonzero coefficients obtained from a nonintrusive PCE calibration are\n- $c_{(0,0,0)}=2$,\n- $c_{(1,0,0)}=\\frac{1}{2}$, $c_{(0,1,0)}=-\\frac{1}{4}$, $c_{(0,0,1)}=\\frac{1}{8}$,\n- $c_{(2,0,0)}=\\frac{1}{4}$, $c_{(0,2,0)}=-\\frac{1}{8}$, $c_{(0,0,2)}=\\frac{1}{16}$,\n- $c_{(1,1,0)}=\\frac{1}{8}$, $c_{(1,0,1)}=-\\frac{1}{16}$, $c_{(0,1,1)}=\\frac{1}{32}$, $c_{(1,1,1)}=-\\frac{1}{32}$,\nand all other $c_{\\boldsymbol{\\alpha}}$ are zero.\n\nStarting from the orthonormality of the basis, the definition of variance $\\mathbb{V}[u]=\\mathbb{E}\\big[(u-\\mathbb{E}[u])^{2}\\big]$, and the variance-based global sensitivity analysis definitions (first-order Sobol index $S_{i}=\\mathbb{V}\\big(\\mathbb{E}[u\\mid \\xi_{i}]\\big)/\\mathbb{V}[u]$ and total Sobol index $S_{T_{i}}=1-\\mathbb{V}\\big(\\mathbb{E}[u\\mid \\boldsymbol{\\xi}_{\\sim i}]\\big)/\\mathbb{V}[u]$, where $\\boldsymbol{\\xi}_{\\sim i}$ denotes all inputs except $\\xi_{i}$), do the following:\n\n1. Derive an expression for $\\mathbb{V}[u]$ in terms of the coefficients $c_{\\boldsymbol{\\alpha}}$.\n2. Derive expressions for the first-order Sobol indices $S_{i}$ in terms of sums of $c_{\\boldsymbol{\\alpha}}^{2}$ associated with multiindices $\\boldsymbol{\\alpha}$ supported only on variable $\\xi_{i}$.\n3. Derive expressions for the total Sobol indices $S_{T_{i}}$ in terms of sums of $c_{\\boldsymbol{\\alpha}}^{2}$ associated with multiindices $\\boldsymbol{\\alpha}$ for which $\\alpha_{i}>0$.\n4. Evaluate the derived expressions for $i\\in\\{1,2,3\\}$ using the provided coefficients.\n\nExpress your final answer as a single row matrix\n$$\n\\big[\\ \\mathbb{V}[u],\\ S_{1},\\ S_{2},\\ S_{3},\\ S_{T_{1}},\\ S_{T_{2}},\\ S_{T_{3}}\\ \\big]\n$$\nwith exact values as simplified fractions. No rounding is required and no units are to be reported.",
            "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- Model output: $u(\\boldsymbol{\\xi})$, where $\\boldsymbol{\\xi}=(\\xi_{1},\\xi_{2},\\xi_{3})$.\n- Input variables: $\\xi_{i}$ are independent and identically distributed as $\\xi_{i}\\sim \\mathcal{U}[-1,1]$ for $i=1, 2, 3$.\n- Polynomial Chaos Expansion (PCE): $u(\\boldsymbol{\\xi})=\\sum_{\\boldsymbol{\\alpha}\\in \\mathbb{N}_{0}^{3}} c_{\\boldsymbol{\\alpha}}\\,\\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})$.\n- Basis functions: $\\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})=\\prod_{i=1}^{3}\\varphi_{\\alpha_{i}}(\\xi_{i})$.\n- Univariate polynomials: $\\{\\varphi_{n}\\}_{n\\ge 0}$ are orthonormal Legendre polynomials on $[-1,1]$, with $\\mathbb{E}[\\varphi_{n}(\\xi)\\varphi_{m}(\\xi)]=\\delta_{nm}$ and $\\varphi_{0}(\\xi)=1$.\n- Multivariate basis property: The basis $\\{\\psi_{\\boldsymbol{\\alpha}}\\}$ is orthonormal, $\\mathbb{E}[\\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})]=\\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$.\n- Nonzero PCE coefficients ($c_{\\boldsymbol{\\alpha}}$):\n  - $c_{(0,0,0)}=2$\n  - $c_{(1,0,0)}=\\frac{1}{2}$, $c_{(0,1,0)}=-\\frac{1}{4}$, $c_{(0,0,1)}=\\frac{1}{8}$\n  - $c_{(2,0,0)}=\\frac{1}{4}$, $c_{(0,2,0)}=-\\frac{1}{8}$, $c_{(0,0,2)}=\\frac{1}{16}$\n  - $c_{(1,1,0)}=\\frac{1}{8}$, $c_{(1,0,1)}=-\\frac{1}{16}$, $c_{(0,1,1)}=\\frac{1}{32}$\n  - $c_{(1,1,1)}=-\\frac{1}{32}$\n- All other coefficients $c_{\\boldsymbol{\\alpha}}$ are zero.\n- Definitions:\n  - Variance: $\\mathbb{V}[u]=\\mathbb{E}\\big[(u-\\mathbb{E}[u])^{2}\\big]$.\n  - First-order Sobol index: $S_{i}=\\mathbb{V}\\big(\\mathbb{E}[u\\mid \\xi_{i}]\\big)/\\mathbb{V}[u]$.\n  - Total Sobol index: $S_{T_{i}}=1-\\mathbb{V}\\big(\\mathbb{E}[u\\mid \\boldsymbol{\\xi}_{\\sim i}]\\big)/\\mathbb{V}[u]$, where $\\boldsymbol{\\xi}_{\\sim i}$ denotes all inputs except $\\xi_{i}$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is firmly rooted in the theory of uncertainty quantification, specifically using Polynomial Chaos Expansions for sensitivity analysis. This is a standard and well-established methodology in computational science and engineering.\n- **Well-Posed:** All necessary information, including the form of the expansion, the properties of the basis functions, and the numerical values of all non-zero coefficients, is provided. The tasks are clearly defined and lead to a unique, derivable solution.\n- **Objective:** The problem is stated in precise mathematical terms, free of any subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n### Solution\n\nThe solution requires performing four sequential tasks: deriving expressions for the total variance, first-order Sobol indices, and total Sobol indices in terms of the PCE coefficients, and then evaluating these quantities.\n\n**1. Derivation of the Variance $\\mathbb{V}[u]$**\n\nThe mean of the model output $u(\\boldsymbol{\\xi})$ is computed first. Using the linearity of the expectation operator and the orthonormality of the basis functions:\n$$\n\\mathbb{E}[u] = \\mathbb{E}\\left[\\sum_{\\boldsymbol{\\alpha}\\in \\mathbb{N}_{0}^{3}} c_{\\boldsymbol{\\alpha}}\\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\right] = \\sum_{\\boldsymbol{\\alpha}\\in \\mathbb{N}_{0}^{3}} c_{\\boldsymbol{\\alpha}}\\mathbb{E}[\\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})]\n$$\nSince $\\psi_{\\boldsymbol{0}}(\\boldsymbol{\\xi})=\\varphi_{0}(\\xi_1)\\varphi_{0}(\\xi_2)\\varphi_{0}(\\xi_3)=1 \\cdot 1 \\cdot 1 = 1$, the expectation of a basis function is:\n$$\n\\mathbb{E}[\\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})] = \\mathbb{E}[\\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\psi_{\\boldsymbol{0}}(\\boldsymbol{\\xi})] = \\delta_{\\boldsymbol{\\alpha}\\boldsymbol{0}}\n$$\nwhere $\\boldsymbol{0} = (0,0,0)$ is the zero multi-index. Thus, the mean is simply the first coefficient:\n$$\n\\mathbb{E}[u] = \\sum_{\\boldsymbol{\\alpha}\\in \\mathbb{N}_{0}^{3}} c_{\\boldsymbol{\\alpha}}\\delta_{\\boldsymbol{\\alpha}\\boldsymbol{0}} = c_{\\boldsymbol{0}} = c_{(0,0,0)}\n$$\nThe variance is defined as $\\mathbb{V}[u] = \\mathbb{E}[u^2] - (\\mathbb{E}[u])^2$. We compute the mean square value $\\mathbb{E}[u^2]$:\n$$\n\\mathbb{E}[u^2] = \\mathbb{E}\\left[\\left(\\sum_{\\boldsymbol{\\alpha}} c_{\\boldsymbol{\\alpha}}\\psi_{\\boldsymbol{\\alpha}}\\right)\\left(\\sum_{\\boldsymbol{\\beta}} c_{\\boldsymbol{\\beta}}\\psi_{\\boldsymbol{\\beta}}\\right)\\right] = \\sum_{\\boldsymbol{\\alpha},\\boldsymbol{\\beta}} c_{\\boldsymbol{\\alpha}}c_{\\boldsymbol{\\beta}}\\mathbb{E}[\\psi_{\\boldsymbol{\\alpha}}\\psi_{\\boldsymbol{\\beta}}]\n$$\nUsing the orthonormality $\\mathbb{E}[\\psi_{\\boldsymbol{\\alpha}}\\psi_{\\boldsymbol{\\beta}}] = \\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$:\n$$\n\\mathbb{E}[u^2] = \\sum_{\\boldsymbol{\\alpha},\\boldsymbol{\\beta}} c_{\\boldsymbol{\\alpha}}c_{\\boldsymbol{\\beta}}\\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}} = \\sum_{\\boldsymbol{\\alpha}} c_{\\boldsymbol{\\alpha}}^2\n$$\nSubstituting these results into the variance formula yields:\n$$\n\\mathbb{V}[u] = \\sum_{\\boldsymbol{\\alpha}} c_{\\boldsymbol{\\alpha}}^2 - c_{\\boldsymbol{0}}^2 = \\sum_{\\boldsymbol{\\alpha}\\neq\\boldsymbol{0}} c_{\\boldsymbol{\\alpha}}^2\n$$\nThis is the desired expression for the total variance.\n\n**2. Derivation of the First-Order Sobol Indices $S_i$**\n\nThe first-order Sobol index is $S_i = \\mathbb{V}_i / \\mathbb{V}[u]$, where $\\mathbb{V}_i = \\mathbb{V}[\\mathbb{E}[u \\mid \\xi_i]]$. We first compute the conditional expectation $\\mathbb{E}[u \\mid \\xi_i]$:\n$$\n\\mathbb{E}[u \\mid \\xi_i] = \\mathbb{E}\\left[\\sum_{\\boldsymbol{\\alpha}} c_{\\boldsymbol{\\alpha}} \\prod_{j=1}^3 \\varphi_{\\alpha_j}(\\xi_j) \\mid \\xi_i \\right] = \\sum_{\\boldsymbol{\\alpha}} c_{\\boldsymbol{\\alpha}} \\mathbb{E}\\left[\\prod_{j=1}^3 \\varphi_{\\alpha_j}(\\xi_j) \\mid \\xi_i \\right]\n$$\nDue to the independence of the $\\xi_j$ variables, the conditional expectation becomes:\n$$\n\\mathbb{E}\\left[\\prod_{j=1}^3 \\varphi_{\\alpha_j}(\\xi_j) \\mid \\xi_i \\right] = \\varphi_{\\alpha_i}(\\xi_i) \\prod_{j \\neq i} \\mathbb{E}[\\varphi_{\\alpha_j}(\\xi_j)]\n$$\nSince $\\mathbb{E}[\\varphi_{\\alpha_j}(\\xi_j)] = \\delta_{\\alpha_j, 0}$, the product $\\prod_{j \\neq i} \\delta_{\\alpha_j, 0}$ is non-zero (and equal to $1$) only if $\\alpha_j = 0$ for all $j \\neq i$. This restricts the sum to multi-indices that have at most one non-zero component, which must be at position $i$.\nLet $\\mathcal{A}_i = \\{\\boldsymbol{\\alpha} \\in \\mathbb{N}_0^3 \\mid \\alpha_j = 0, \\forall j \\neq i\\}$. Then:\n$$\nu_i \\equiv \\mathbb{E}[u \\mid \\xi_i] = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}_i} c_{\\boldsymbol{\\alpha}} \\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}) = \\sum_{k=0}^{\\infty} c_{(0,..,k,..,0)} \\varphi_k(\\xi_i)\n$$\nThe variance $\\mathbb{V}_i = \\mathbb{V}[u_i]$ is the variance of this partial sum. The mean is $\\mathbb{E}[u_i]=\\mathbb{E}[\\mathbb{E}[u|\\xi_i]]=\\mathbb{E}[u]=c_{\\boldsymbol{0}}$. Using the same logic as for the total variance:\n$$\n\\mathbb{V}_i = \\mathbb{E}[u_i^2] - (\\mathbb{E}[u_i])^2 = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}_i} c_{\\boldsymbol{\\alpha}}^2 - c_{\\boldsymbol{0}}^2 = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}_i, \\boldsymbol{\\alpha} \\neq \\boldsymbol{0}} c_{\\boldsymbol{\\alpha}}^2\n$$\nThis sum includes squares of coefficients whose multi-indices are supported only on variable $\\xi_i$. So, the first-order index is:\n$$\nS_i = \\frac{\\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}_i, \\boldsymbol{\\alpha} \\neq \\boldsymbol{0}} c_{\\boldsymbol{\\alpha}}^2}{\\sum_{\\boldsymbol{\\beta} \\neq \\boldsymbol{0}} c_{\\boldsymbol{\\beta}}^2}\n$$\n\n**3. Derivation of the Total Sobol Indices $S_{T_i}$**\n\nThe total Sobol index is $S_{T_i} = 1 - \\mathbb{V}[\\mathbb{E}[u \\mid \\boldsymbol{\\xi}_{\\sim i}]] / \\mathbb{V}[u]$. We compute the conditional expectation on all variables except $\\xi_i$, denoted by $\\boldsymbol{\\xi}_{\\sim i}$:\n$$\n\\mathbb{E}[u \\mid \\boldsymbol{\\xi}_{\\sim i}] = \\sum_{\\boldsymbol{\\alpha}} c_{\\boldsymbol{\\alpha}} \\mathbb{E}\\left[\\prod_{j=1}^3 \\varphi_{\\alpha_j}(\\xi_j) \\mid \\boldsymbol{\\xi}_{\\sim i} \\right] = \\sum_{\\boldsymbol{\\alpha}} c_{\\boldsymbol{\\alpha}} \\left(\\prod_{j \\neq i} \\varphi_{\\alpha_j}(\\xi_j) \\right) \\mathbb{E}[\\varphi_{\\alpha_i}(\\xi_i)]\n$$\nAgain, $\\mathbb{E}[\\varphi_{\\alpha_i}(\\xi_i)] = \\delta_{\\alpha_i, 0}$. The sum is restricted to indices $\\boldsymbol{\\alpha}$ for which $\\alpha_i = 0$. Let $\\mathcal{B}_i = \\{\\boldsymbol{\\alpha} \\in \\mathbb{N}_0^3 \\mid \\alpha_i=0 \\}$. Then:\n$$\nu_{\\sim i} \\equiv \\mathbb{E}[u \\mid \\boldsymbol{\\xi}_{\\sim i}] = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{B}_i} c_{\\boldsymbol{\\alpha}} \\psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\n$$\nThe variance of this term is $\\mathbb{V}[u_{\\sim i}] = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{B}_i, \\boldsymbol{\\alpha} \\neq \\boldsymbol{0}} c_{\\boldsymbol{\\alpha}}^2$. Then,\n$$\nS_{T_i} = 1 - \\frac{\\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{B}_i, \\boldsymbol{\\alpha} \\neq \\boldsymbol{0}} c_{\\boldsymbol{\\alpha}}^2}{\\sum_{\\boldsymbol{\\beta} \\neq \\boldsymbol{0}} c_{\\boldsymbol{\\beta}}^2} = \\frac{\\left(\\sum_{\\boldsymbol{\\beta} \\neq \\boldsymbol{0}} c_{\\boldsymbol{\\beta}}^2\\right) - \\left(\\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{B}_i, \\boldsymbol{\\alpha} \\neq \\boldsymbol{0}} c_{\\boldsymbol{\\alpha}}^2\\right)}{\\sum_{\\boldsymbol{\\beta} \\neq \\boldsymbol{0}} c_{\\boldsymbol{\\beta}}^2}\n$$\nThe set of all non-zero multi-indices $\\{\\boldsymbol{\\beta} \\neq \\boldsymbol{0}\\}$ can be partitioned into those with $\\beta_i=0$ (i.e., $\\mathcal{B}_i \\setminus \\{\\boldsymbol{0}\\}$) and those with $\\beta_i > 0$. The numerator is the sum of $c_{\\boldsymbol{\\alpha}}^2$ over all multi-indices $\\boldsymbol{\\alpha}$ for which $\\alpha_i > 0$.\n$$\nS_{T_i} = \\frac{\\sum_{\\boldsymbol{\\alpha} \\text{ with } \\alpha_i > 0} c_{\\boldsymbol{\\alpha}}^2}{\\sum_{\\boldsymbol{\\beta} \\neq \\boldsymbol{0}} c_{\\boldsymbol{\\beta}}^2}\n$$\n\n**4. Evaluation of Expressions**\n\nFirst, we calculate the total variance $\\mathbb{V}[u] = \\sum_{\\boldsymbol{\\alpha}\\neq\\boldsymbol{0}} c_{\\boldsymbol{\\alpha}}^2$. The squares of the given non-zero coefficients ($c_{\\boldsymbol{\\alpha}}$ for $\\boldsymbol{\\alpha} \\neq \\boldsymbol{0}$) are:\n- $c_{(1,0,0)}^2 = (\\frac{1}{2})^2 = \\frac{1}{4}$\n- $c_{(0,1,0)}^2 = (-\\frac{1}{4})^2 = \\frac{1}{16}$\n- $c_{(0,0,1)}^2 = (\\frac{1}{8})^2 = \\frac{1}{64}$\n- $c_{(2,0,0)}^2 = (\\frac{1}{4})^2 = \\frac{1}{16}$\n- $c_{(0,2,0)}^2 = (-\\frac{1}{8})^2 = \\frac{1}{64}$\n- $c_{(0,0,2)}^2 = (\\frac{1}{16})^2 = \\frac{1}{256}$\n- $c_{(1,1,0)}^2 = (\\frac{1}{8})^2 = \\frac{1}{64}$\n- $c_{(1,0,1)}^2 = (-\\frac{1}{16})^2 = \\frac{1}{256}$\n- $c_{(0,1,1)}^2 = (\\frac{1}{32})^2 = \\frac{1}{1024}$\n- $c_{(1,1,1)}^2 = (-\\frac{1}{32})^2 = \\frac{1}{1024}$\n$\\mathbb{V}[u] = \\frac{1}{4} + \\frac{1}{16} + \\frac{1}{64} + \\frac{1}{16} + \\frac{1}{64} + \\frac{1}{256} + \\frac{1}{64} + \\frac{1}{256} + \\frac{1}{1024} + \\frac{1}{1024}$\n$\\mathbb{V}[u] = \\frac{256+64+16+64+16+4+16+4+1+1}{1024} = \\frac{442}{1024} = \\frac{221}{512}$.\n\nNext, we calculate the partial variances for $S_i$:\n- $\\mathbb{V}_1 = c_{(1,0,0)}^2 + c_{(2,0,0)}^2 = \\frac{1}{4} + \\frac{1}{16} = \\frac{5}{16}$.\n- $\\mathbb{V}_2 = c_{(0,1,0)}^2 + c_{(0,2,0)}^2 = \\frac{1}{16} + \\frac{1}{64} = \\frac{5}{64}$.\n- $\\mathbb{V}_3 = c_{(0,0,1)}^2 + c_{(0,0,2)}^2 = \\frac{1}{64} + \\frac{1}{256} = \\frac{5}{256}$.\n$S_1 = \\frac{5/16}{221/512} = \\frac{5}{16} \\cdot \\frac{512}{221} = \\frac{5 \\cdot 32}{221} = \\frac{160}{221}$.\n$S_2 = \\frac{5/64}{221/512} = \\frac{5}{64} \\cdot \\frac{512}{221} = \\frac{5 \\cdot 8}{221} = \\frac{40}{221}$.\n$S_3 = \\frac{5/256}{221/512} = \\frac{5}{256} \\cdot \\frac{512}{221} = \\frac{5 \\cdot 2}{221} = \\frac{10}{221}$.\n\nFinally, we calculate the partial variances for $S_{T_i}$:\n- $\\mathbb{V}_{T_1} = c_{(1,0,0)}^2+c_{(2,0,0)}^2+c_{(1,1,0)}^2+c_{(1,0,1)}^2+c_{(1,1,1)}^2 = \\frac{1}{4}+\\frac{1}{16}+\\frac{1}{64}+\\frac{1}{256}+\\frac{1}{1024} = \\frac{256+64+16+4+1}{1024} = \\frac{341}{1024}$.\n- $\\mathbb{V}_{T_2} = c_{(0,1,0)}^2+c_{(0,2,0)}^2+c_{(1,1,0)}^2+c_{(0,1,1)}^2+c_{(1,1,1)}^2 = \\frac{1}{16}+\\frac{1}{64}+\\frac{1}{64}+\\frac{1}{1024}+\\frac{1}{1024} = \\frac{64+16+16+1+1}{1024} = \\frac{98}{1024} = \\frac{49}{512}$.\n- $\\mathbb{V}_{T_3} = c_{(0,0,1)}^2+c_{(0,0,2)}^2+c_{(1,0,1)}^2+c_{(0,1,1)}^2+c_{(1,1,1)}^2 = \\frac{1}{64}+\\frac{1}{256}+\\frac{1}{256}+\\frac{1}{1024}+\\frac{1}{1024} = \\frac{16+4+4+1+1}{1024} = \\frac{26}{1024} = \\frac{13}{512}$.\n$S_{T_1} = \\frac{341/1024}{442/1024} = \\frac{341}{442}$.\n$S_{T_2} = \\frac{49/512}{221/512} = \\frac{49}{221}$.\n$S_{T_3} = \\frac{13/512}{221/512} = \\frac{13}{221} = \\frac{1}{17}$.\n\nThe final results are collected into the required matrix format.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{221}{512} & \\frac{160}{221} & \\frac{40}{221} & \\frac{10}{221} & \\frac{341}{442} & \\frac{49}{221} & \\frac{1}{17} \\end{pmatrix}}\n$$"
        }
    ]
}