{
    "hands_on_practices": [
        {
            "introduction": "Partitioned solvers are a common strategy for multiphysics problems, where the full system is broken down into smaller, single-physics subproblems that are solved iteratively. The convergence of such a scheme is governed by the spectral radius of its iteration matrix, which must be less than one. This exercise provides fundamental practice in analyzing convergence by asking you to derive and compare the spectral radii for the Block-Jacobi and Block-Gauss–Seidel schemes applied to a model thermo-mechanical problem .",
            "id": "3504785",
            "problem": "A one-dimensional linear thermoelastic rod of length $L$ and cross-sectional area $A$ is modeled under small strain and small temperature rise about a reference absolute temperature $\\theta_{0}$. The rod is clamped at the left end and axially displaced by $u$ at the right end; the temperature field is assumed uniform and represented by a single degree of freedom $T$. The mechanical balance is quasi-static (no inertia), and the thermal balance uses Fourier conduction with heat capacity. Consider one backward (implicit) Euler time step of size $\\Delta t$ from time $t^{n}$ to $t^{n+1}$, and a single linear two-node bar in a single degree-of-freedom reduction for both mechanics and heat. The resulting monolithic linear system for the unknowns $(u^{n+1}, T^{n+1})$ takes the block form\n$$\n\\begin{pmatrix}\nK  -C \\\\\nD_{\\mathrm{eff}}  H\n\\end{pmatrix}\n\\begin{pmatrix}\nu^{n+1} \\\\\nT^{n+1}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nr_{u} \\\\\nr_{T}\n\\end{pmatrix},\n$$\nwith\n- $K = E A / L$ the axial stiffness,\n- $H = c \\rho A L / \\Delta t + \\kappa A / L$ the thermal backward Euler effective capacity-plus-conductance,\n- $C = E A \\alpha_{\\mathrm{th}}$ the thermoelastic thermal load coefficient entering the mechanical equation,\n- $D_{\\mathrm{eff}} = \\theta_{0} \\alpha_{\\mathrm{th}} E A / \\Delta t$ the effective thermoelastic coupling entering the thermal equation after time discretization,\nwhere $E$ is Young’s modulus, $\\alpha_{\\mathrm{th}}$ is the coefficient of thermal expansion, $\\kappa$ is the thermal conductivity, $c$ is the specific heat, and $\\rho$ is the mass density. Assume the right-hand side $(r_{u}, r_{T})$ is bounded.\n\nTwo partitioned fixed-point strategies are considered to solve this coupled system:\n- Block-Jacobi (simultaneous) partitioned iteration: at iteration $k+1$, solve the mechanical and thermal subproblems using, respectively, $T^{k}$ and $u^{k}$ on the right-hand sides.\n- Block-Gauss–Seidel (sequential) partitioned iteration: at iteration $k+1$, update $u^{k+1}$ from the mechanical subproblem using $T^{k}$, then update $T^{k+1}$ from the thermal subproblem using $u^{k+1}$.\n\nTasks:\n1) Starting from the definitions of the two partitioned iterations and the monolithic block system above, derive the linear error propagation mappings for the iteration errors $e_{u}^{k} = u^{k} - u^{\\star}$ and $e_{T}^{k} = T^{k} - T^{\\star}$, where $(u^{\\star}, T^{\\star})$ solves the monolithic system. Then, using only linear algebra and the definition of spectral radius, express the spectral radii $\\rho_{\\mathrm{J}}$ and $\\rho_{\\mathrm{GS}}$ of the Block-Jacobi and Block-Gauss–Seidel error propagation matrices in terms of $K$, $H$, $C$, and $D_{\\mathrm{eff}}$.\n2) Using the physically consistent parameters\n- $E = 210 \\times 10^{9}$, $A = 10^{-4}$, $L = 1$, $\\alpha_{\\mathrm{th}} = 1.2 \\times 10^{-5}$,\n- $\\kappa = 45$, $c = 450$, $\\rho = 7800$, $\\theta_{0} = 293$, $\\Delta t = 1$,\ncompute $K$, $H$, $C$, and $D_{\\mathrm{eff}}$ and then evaluate the numerical values of $\\rho_{\\mathrm{J}}$ and $\\rho_{\\mathrm{GS}}$.\n\nAnswer specification:\n- Provide your final answer as the ordered pair $(\\rho_{\\mathrm{J}}, \\rho_{\\mathrm{GS}})$.\n- Round both $\\rho_{\\mathrm{J}}$ and $\\rho_{\\mathrm{GS}}$ to four significant figures.\n- The final answer is dimensionless and must be reported without units.",
            "solution": "The problem is first validated by extracting all given information and checking for scientific consistency, completeness, and clarity.\n\n## Problem Validation\n\n### Step 1: Extract Givens\n- **System**: One-dimensional linear thermoelastic rod of length $L$ and area $A$.\n- **Assumptions**: Small strain, small temperature rise about $\\theta_{0}$, quasi-static mechanics, Fourier conduction with heat capacity.\n- **Discretization**: Single two-node linear element, one degree of freedom for displacement ($u$) and one for temperature ($T$). Single backward Euler time step of size $\\Delta t$.\n- **Monolithic System**:\n$$\n\\begin{pmatrix}\nK  -C \\\\\nD_{\\mathrm{eff}}  H\n\\end{pmatrix}\n\\begin{pmatrix}\nu^{n+1} \\\\\nT^{n+1}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nr_{u} \\\\\nr_{T}\n\\end{pmatrix}\n$$\n- **Coefficient Definitions**:\n  - Stiffness: $K = E A / L$\n  - Thermal effective matrix: $H = c \\rho A L / \\Delta t + \\kappa A / L$\n  - Mechanical coupling: $C = E A \\alpha_{\\mathrm{th}}$\n  - Thermal coupling: $D_{\\mathrm{eff}} = \\theta_{0} \\alpha_{\\mathrm{th}} E A / \\Delta t$\n- **Physical Parameters**:\n  - Young's modulus: $E = 210 \\times 10^{9}$\n  - Area: $A = 10^{-4}$\n  - Length: $L = 1$\n  - Thermal expansion coefficient: $\\alpha_{\\mathrm{th}} = 1.2 \\times 10^{-5}$\n  - Thermal conductivity: $\\kappa = 45$\n  - Specific heat: $c = 450$\n  - Mass density: $\\rho = 7800$\n  - Reference temperature: $\\theta_{0} = 293$\n  - Time step: $\\Delta t = 1$\n- **Partitioned Schemes**:\n  - Block-Jacobi: $u^{k+1}$ and $T^{k+1}$ solved using $u^k$ and $T^k$ from previous iteration.\n  - Block-Gauss-Seidel: $u^{k+1}$ solved using $T^k$, then $T^{k+1}$ solved using the new $u^{k+1}$.\n- **Tasks**:\n  1. Derive expressions for the spectral radii $\\rho_{\\mathrm{J}}$ and $\\rho_{\\mathrm{GS}}$ of the error propagation matrices.\n  2. Compute the numerical values of $\\rho_{\\mathrm{J}}$ and $\\rho_{\\mathrm{GS}}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem describes a standard, simplified model of linear thermoelasticity, a staple in computational multiphysics. The governing equations, coefficient definitions, and physical parameters are consistent with established principles of continuum mechanics and heat transfer. The discretization methods (FEM in space, backward Euler in time) are standard. The parameters provided are realistic for steel. The problem is self-contained, well-posed, and objective. It does not violate any of the invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n## Solution\n\nLet the exact solution to the monolithic system be $(u^{\\star}, T^{\\star})$. This solution satisfies:\n$$ K u^{\\star} - C T^{\\star} = r_{u} $$\n$$ D_{\\mathrm{eff}} u^{\\star} + H T^{\\star} = r_{T} $$\nThe iteration errors at step $k$ are defined as $e_{u}^{k} = u^{k} - u^{\\star}$ and $e_{T}^{k} = T^{k} - T^{\\star}$.\n\n### Task 1: Derivation of Spectral Radii\n\n**Block-Jacobi Partitioned Iteration**\n\nThe Block-Jacobi scheme is defined by solving the diagonal blocks independently, using values from the previous iteration $k$ for the off-diagonal coupling terms:\n$$ K u^{k+1} = r_{u} + C T^{k} $$\n$$ H T^{k+1} = r_{T} - D_{\\mathrm{eff}} u^{k} $$\nSubtracting the exact solution equations from the iteration equations yields the error propagation equations:\n$$ K (u^{k+1} - u^{\\star}) = C (T^{k} - T^{\\star}) \\implies K e_{u}^{k+1} = C e_{T}^{k} $$\n$$ H (T^{k+1} - T^{\\star}) = -D_{\\mathrm{eff}} (u^{k} - u^{\\star}) \\implies H e_{T}^{k+1} = -D_{\\mathrm{eff}} e_{u}^{k} $$\nArranging these into a system for the error vector $\\mathbf{e}^{k+1} = \\begin{pmatrix} e_{u}^{k+1} \\\\ e_{T}^{k+1} \\end{pmatrix}$:\n$$ e_{u}^{k+1} = K^{-1} C e_{T}^{k} $$\n$$ e_{T}^{k+1} = -H^{-1} D_{\\mathrm{eff}} e_{u}^{k} $$\nThe error propagation is governed by the matrix relationship $\\mathbf{e}^{k+1} = G_{\\mathrm{J}} \\mathbf{e}^{k}$, where $G_{\\mathrm{J}}$ is the Block-Jacobi iteration matrix:\n$$ G_{\\mathrm{J}} = \\begin{pmatrix} 0  K^{-1} C \\\\ -H^{-1} D_{\\mathrm{eff}}  0 \\end{pmatrix} $$\nThe spectral radius $\\rho_{\\mathrm{J}}$ is the maximum absolute value of the eigenvalues $\\lambda$ of $G_{\\mathrm{J}}$. The eigenvalues are found from the characteristic equation $\\det(G_{\\mathrm{J}} - \\lambda I) = 0$:\n$$ \\det \\begin{pmatrix} -\\lambda  K^{-1} C \\\\ -H^{-1} D_{\\mathrm{eff}}  -\\lambda \\end{pmatrix} = (-\\lambda)(-\\lambda) - (K^{-1} C)(-H^{-1} D_{\\mathrm{eff}}) = \\lambda^2 + K^{-1} H^{-1} C D_{\\mathrm{eff}} = 0 $$\n$$ \\lambda^2 = - \\frac{C D_{\\mathrm{eff}}}{K H} $$\nSince all coefficients $K, H, C, D_{\\mathrm{eff}}$ are positive scalars, the eigenvalues are purely imaginary:\n$$ \\lambda = \\pm i \\sqrt{\\frac{C D_{\\mathrm{eff}}}{K H}} $$\nThe spectral radius is the magnitude of these eigenvalues:\n$$ \\rho_{\\mathrm{J}} = \\left| \\pm i \\sqrt{\\frac{C D_{\\mathrm{eff}}}{K H}} \\right| = \\sqrt{\\frac{C D_{\\mathrm{eff}}}{K H}} $$\n\n**Block-Gauss-Seidel Partitioned Iteration**\n\nThe Block-Gauss-Seidel scheme updates the variables sequentially. First, $u^{k+1}$ is computed using $T^k$, and then this new value $u^{k+1}$ is immediately used to compute $T^{k+1}$:\n$$ K u^{k+1} = r_{u} + C T^{k} $$\n$$ H T^{k+1} = r_{T} - D_{\\mathrm{eff}} u^{k+1} $$\nAgain, we subtract the exact solution equations to find the error propagation:\n$$ K e_{u}^{k+1} = C e_{T}^{k} \\implies e_{u}^{k+1} = K^{-1} C e_{T}^{k} $$\n$$ H e_{T}^{k+1} = -D_{\\mathrm{eff}} e_{u}^{k+1} $$\nSubstitute the expression for $e_{u}^{k+1}$ from the first equation into the second:\n$$ H e_{T}^{k+1} = -D_{\\mathrm{eff}} (K^{-1} C e_{T}^{k}) \\implies e_{T}^{k+1} = -H^{-1} D_{\\mathrm{eff}} K^{-1} C e_{T}^{k} $$\nThe error propagation equations can be written in matrix form as $\\mathbf{e}^{k+1} = G_{\\mathrm{GS}} \\mathbf{e}^{k}$:\n$$ \\begin{pmatrix} e_{u}^{k+1} \\\\ e_{T}^{k+1} \\end{pmatrix} = \\begin{pmatrix} 0  K^{-1} C \\\\ 0  -H^{-1} D_{\\mathrm{eff}} K^{-1} C \\end{pmatrix} \\begin{pmatrix} e_{u}^{k} \\\\ e_{T}^{k} \\end{pmatrix} $$\nThe iteration matrix is:\n$$ G_{\\mathrm{GS}} = \\begin{pmatrix} 0  K^{-1} C \\\\ 0  - \\frac{C D_{\\mathrm{eff}}}{K H} \\end{pmatrix} $$\nSince $G_{\\mathrm{GS}}$ is an upper triangular matrix, its eigenvalues are its diagonal entries: $\\lambda_1 = 0$ and $\\lambda_2 = - \\frac{C D_{\\mathrm{eff}}}{K H}$.\nThe spectral radius $\\rho_{\\mathrm{GS}}$ is the maximum of their absolute values:\n$$ \\rho_{\\mathrm{GS}} = \\max \\left( |0|, \\left|- \\frac{C D_{\\mathrm{eff}}}{K H}\\right| \\right) = \\frac{C D_{\\mathrm{eff}}}{K H} $$\nNote that $\\rho_{\\mathrm{GS}} = (\\rho_{\\mathrm{J}})^2$, a known result for this class of problems.\n\n### Task 2: Numerical Evaluation\n\nFirst, we compute the numerical values of the coefficients using the provided physical parameters in SI units.\n- $K = \\frac{E A}{L} = \\frac{(210 \\times 10^{9}) (10^{-4})}{1} = 2.1 \\times 10^{7}$\n- $C = E A \\alpha_{\\mathrm{th}} = (210 \\times 10^{9}) (10^{-4}) (1.2 \\times 10^{-5}) = 252$\n- $D_{\\mathrm{eff}} = \\frac{\\theta_{0} \\alpha_{\\mathrm{th}} E A}{\\Delta t} = \\frac{293 \\times (1.2 \\times 10^{-5}) (210 \\times 10^{9}) (10^{-4})}{1} = 73836$\n- $H = \\frac{c \\rho A L}{\\Delta t} + \\frac{\\kappa A}{L} = \\frac{450 \\times 7800 \\times 10^{-4} \\times 1}{1} + \\frac{45 \\times 10^{-4}}{1} = 351 + 0.0045 = 351.0045$\n\nNext, we compute the dimensionless coupling parameter $\\gamma = \\frac{C D_{\\mathrm{eff}}}{K H}$:\n$$ \\gamma = \\frac{252 \\times 73836}{(2.1 \\times 10^{7}) \\times 351.0045} = \\frac{18606672}{7371094500} \\approx 0.002524263 $$\nNow we can compute the spectral radii:\n- $\\rho_{\\mathrm{GS}} = \\gamma \\approx 0.002524263$\n- $\\rho_{\\mathrm{J}} = \\sqrt{\\gamma} \\approx \\sqrt{0.002524263} \\approx 0.050242048$\n\nRounding to four significant figures as requested:\n- $\\rho_{\\mathrm{GS}} = 0.002524$\n- $\\rho_{\\mathrm{J}} = 0.05024$\n\nThe final answer is the ordered pair $(\\rho_{\\mathrm{J}}, \\rho_{\\mathrm{GS}})$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.05024  0.002524\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "In explicit multiphysics simulations involving different physical phenomena, the choice of a shared time step often involves balancing competing requirements. This hands-on calculation explores the critical trade-off between the numerical stability of a diffusion process and the numerical accuracy (specifically, dispersion error) of a wave propagation process . By performing a von Neumann analysis for each subsystem, you will determine the optimal Courant number that minimizes wave dispersion while satisfying the stability constraints imposed by the thermal coupling.",
            "id": "3504843",
            "problem": "A one-dimensional linear thermoacoustic model couples a hyperbolic acoustic wave with a parabolic thermal diffusion, posed on a uniform grid with spatial step size $\\Delta x$ and a shared time step $\\Delta t$. The acoustic pressure $p(x,t)$ satisfies the wave equation $p_{tt} = c^{2} p_{xx}$ to leading order, where $c$ is the acoustic wave speed, and the temperature $T(x,t)$ satisfies the heat equation $T_{t} = \\kappa T_{xx}$, where $\\kappa$ is the thermal diffusivity. The coupling terms are linear and weak in the sense that they do not alter the principal part (highest derivative terms) of either subsystem in the limit of small time step and grid spacing. A partitioned explicit scheme is adopted in which:\n- The wave component is advanced by the standard second-order explicit $3$-level central-difference scheme,\n$$\np_{j}^{n+1} = 2 p_{j}^{n} - p_{j}^{n-1} + S^{2}\\left(p_{j+1}^{n} - 2 p_{j}^{n} + p_{j-1}^{n}\\right),\n$$\nwith Courant number $S \\equiv c\\,\\Delta t/\\Delta x$.\n- The diffusion component is advanced by an explicit second-order method with standard centered second-order spatial differences.\n\nAssume von Neumann analysis applies and that the shared time step $\\Delta t$ must satisfy the stability conditions of both subsystems. Define dispersion error for the wave component as the relative phase speed error between the numerical and continuous waves for small nondimensional wavenumber $\\theta \\equiv k\\,\\Delta x$, where $k$ is the physical wavenumber.\n\nStarting only from the governing equations, the definition of the Courant number, and the above numerical updates, carry out a consistency and von Neumann analysis to:\n- Derive the small-$\\theta$ leading-order term of the relative phase speed error of the wave scheme as a function of $S$.\n- Use the stability constraints implied by the explicit diffusion update to delimit the feasible set of $S$.\n- Conclude which value of $S$ within the feasible set minimizes the leading-order dispersion error of the wave component.\n\nCompute and report the optimal Courant number $S_{\\mathrm{opt}}$ as a single closed-form analytic expression in terms of $c$, $\\kappa$, and $\\Delta x$. The final answer is dimensionless and must be given as an exact expression (no rounding). Express your final answer without units.",
            "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and contains sufficient information to derive a unique solution. It is therefore deemed valid. The solution proceeds by analyzing the numerical schemes for the wave and heat equations separately to determine their respective properties, and then combining the constraints to find the optimal parameter.\n\nThe process is broken down into three main parts:\n1.  Derivation of the leading-order dispersion error for the wave equation scheme.\n2.  Derivation of the stability constraint for the heat equation scheme.\n3.  Determination of the optimal Courant number $S_{\\mathrm{opt}}$ that minimizes the wave dispersion error subject to the stability constraints.\n\n**1. Dispersion Analysis of the Wave Scheme**\n\nThe numerical scheme for the acoustic pressure $p(x,t)$ is the explicit $3$-level central-difference scheme:\n$$p_{j}^{n+1} = 2 p_{j}^{n} - p_{j}^{n-1} + S^{2}\\left(p_{j+1}^{n} - 2 p_{j}^{n} + p_{j-1}^{n}\\right)$$\nwhere $S = c\\,\\Delta t/\\Delta x$ is the Courant number, $j$ is the spatial index, and $n$ is the temporal index.\n\nWe perform a von Neumann stability analysis by substituting a single Fourier mode solution of the form $p_j^n = \\hat{p}(k) g^n e^{i k x_j}$, where $x_j = j \\Delta x$, $k$ is the wavenumber, and $g$ is the complex amplification factor per time step. Using the non-dimensional wavenumber $\\theta \\equiv k \\Delta x$, the trial solution is $p_j^n \\propto g^n e^{i j \\theta}$. Substituting this into the numerical scheme yields:\n$$g^{n+1} e^{ij\\theta} = 2 g^n e^{ij\\theta} - g^{n-1} e^{ij\\theta} + S^2 \\left(g^n e^{i(j+1)\\theta} - 2 g^n e^{ij\\theta} + g^n e^{i(j-1)\\theta}\\right)$$\nDividing by $g^n e^{ij\\theta}$ and using $g^{n+1}/g^n=g$ and $g^{n-1}/g^n=g^{-1}$:\n$$g = 2 - g^{-1} + S^2 \\left(e^{i\\theta} - 2 + e^{-i\\theta}\\right)$$\nUsing the identity $e^{i\\theta} + e^{-i\\theta} = 2 \\cos(\\theta)$, we get:\n$$g + g^{-1} = 2 + S^2 (2 \\cos(\\theta) - 2) = 2 - 2S^2 (1 - \\cos(\\theta))$$\nUsing the half-angle identity $1 - \\cos(\\theta) = 2 \\sin^2(\\theta/2)$:\n$$g + g^{-1} = 2 - 4S^2 \\sin^2(\\theta/2)$$\nMultiplying by $g$ and rearranging gives a quadratic equation for the amplification factor $g$:\n$$g^2 - \\left(2 - 4S^2 \\sin^2(\\theta/2)\\right)g + 1 = 0$$\nFor a non-dissipative scheme, the roots must be complex conjugates on the unit circle, $|g|=1$. We can write $g=e^{-i\\omega_{\\mathrm{num}}\\Delta t}$, where $\\omega_{\\mathrm{num}}$ is the numerical angular frequency. For such a solution, $g+g^{-1} = 2\\cos(\\omega_{\\mathrm{num}}\\Delta t)$. Comparing this with the expression above:\n$$2\\cos(\\omega_{\\mathrm{num}}\\Delta t) = 2 - 4S^2 \\sin^2(\\theta/2)$$\n$$\\cos(\\omega_{\\mathrm{num}}\\Delta t) = 1 - 2S^2 \\sin^2(\\theta/2)$$\nThis implies that for a stable solution ($|g|=1$), the argument of the cosine must be real, which requires $|1-2S^2\\sin^2(\\theta/2)| \\leq 1$. This leads to the CFL stability condition $S \\leq 1$.\n\nThe numerical phase velocity is $c_{\\mathrm{num}} = \\omega_{\\mathrm{num}}/k$. The relative phase speed error is $\\frac{c_{\\mathrm{num}}}{c}-1$.\n$$\\omega_{\\mathrm{num}} = \\frac{1}{\\Delta t} \\arccos\\left(1 - 2S^2 \\sin^2(\\frac{\\theta}{2})\\right)$$\n$$c_{\\mathrm{num}} = \\frac{\\omega_{\\mathrm{num}}}{k} = \\frac{1}{k \\Delta t} \\arccos\\left(1 - 2S^2 \\sin^2(\\frac{\\theta}{2})\\right)$$\nThe relative phase speed is:\n$$\\frac{c_{\\mathrm{num}}}{c} = \\frac{1}{c k \\Delta t} \\arccos\\left(1 - 2S^2 \\sin^2(\\frac{\\theta}{2})\\right) = \\frac{\\Delta x}{S \\theta} \\arccos\\left(1 - 2S^2 \\sin^2(\\frac{\\theta}{2})\\right)$$\nTo find the leading-order error for small $\\theta$, we expand the terms. Let $\\alpha = \\omega_{\\mathrm{num}}\\Delta t$. Then we have $\\cos(\\alpha) = 1 - 2S^2 \\sin^2(\\theta/2)$.\nIt is more convenient to set $\\sin(\\alpha/2) = S \\sin(\\theta/2)$. Then $\\cos(\\alpha) = 1-2\\sin^2(\\alpha/2) = 1-2S^2\\sin^2(\\theta/2)$, which is consistent.\nFrom $\\alpha = 2 \\arcsin(S\\sin(\\theta/2))$, we expand for small $\\theta$:\nThe argument of $\\arcsin$ is $S \\sin(\\theta/2) = S \\left( \\frac{\\theta}{2} - \\frac{1}{6}\\left(\\frac{\\theta}{2}\\right)^3 + O(\\theta^5) \\right) = S\\frac{\\theta}{2} - \\frac{S\\theta^3}{48} + O(\\theta^5)$.\nUsing the expansion $\\arcsin(z) = z + z^3/6 + O(z^5)$:\n$$\\alpha = 2 \\left[ \\left(S\\frac{\\theta}{2} - \\frac{S\\theta^3}{48}\\right) + \\frac{1}{6}\\left(S\\frac{\\theta}{2}\\right)^3 + O(\\theta^5) \\right]$$\n$$\\alpha = S\\theta - \\frac{S\\theta^3}{24} + \\frac{S^3\\theta^3}{24} + O(\\theta^5) = S\\theta + \\frac{S(S^2-1)}{24}\\theta^3 + O(\\theta^5)$$\nNow we find the relative phase speed:\n$$\\frac{c_{\\mathrm{num}}}{c} = \\frac{\\omega_{\\mathrm{num}}/k}{c} = \\frac{\\alpha/\\Delta t}{c k} = \\frac{\\alpha \\Delta x}{c \\Delta t \\theta} = \\frac{\\alpha}{S\\theta}$$\n$$\\frac{c_{\\mathrm{num}}}{c} = \\frac{1}{S\\theta} \\left( S\\theta + \\frac{S(S^2-1)}{24}\\theta^3 + O(\\theta^5) \\right) = 1 + \\frac{S^2-1}{24}\\theta^2 + O(\\theta^4)$$\nThe relative phase speed error is $\\frac{c_{\\mathrm{num}}}{c} - 1$. The leading-order term is $\\frac{S^2-1}{24}\\theta^2$. To minimize the magnitude of this error, $|S^2-1|$ must be minimized. Since $S \\le 1$ for stability, this is equivalent to minimizing $1-S^2$, which is achieved by making $S$ as large as possible, i.e., as close to $1$ as possible.\n\n**2. Stability Analysis of the Diffusion Scheme**\n\nThe problem states the diffusion component $T_t = \\kappa T_{xx}$ is advanced by an explicit method with \"standard centered second-order spatial differences\". This specifies the spatial operator discretization as $\\kappa T_{xx} \\approx \\kappa \\frac{T_{j+1}-2T_j+T_{j-1}}{(\\Delta x)^2}$. The simplest and most common explicit time-integration scheme for this is the Forward-Time Centered-Space (FTCS) method, which is first-order in time and second-order in space. The scheme is:\n$$\\frac{T_j^{n+1} - T_j^n}{\\Delta t} = \\kappa \\frac{T_{j+1}^n - 2T_j^n + T_{j-1}^n}{(\\Delta x)^2}$$\nRearranging gives the update rule:\n$$T_j^{n+1} = T_j^n + D \\left( T_{j+1}^n - 2T_j^n + T_{j-1}^n \\right)$$\nwhere $D = \\frac{\\kappa \\Delta t}{(\\Delta x)^2}$ is the numerical diffusion number.\nApplying von Neumann analysis with the trial solution $T_j^n \\propto g^n e^{ij\\theta}$:\n$$g = 1 + D(e^{i\\theta} - 2 + e^{-i\\theta}) = 1 + D(2\\cos\\theta - 2) = 1 - 2D(1-\\cos\\theta) = 1 - 4D \\sin^2(\\frac{\\theta}{2})$$\nFor stability, the amplification factor must satisfy $|g| \\le 1$ for all $\\theta \\in [-\\pi, \\pi]$.\n$$|1 - 4D \\sin^2(\\frac{\\theta}{2})| \\le 1$$\nThis is equivalent to the two inequalities:\n1. $1 - 4D \\sin^2(\\frac{\\theta}{2}) \\le 1 \\implies -4D \\sin^2(\\frac{\\theta}{2}) \\le 0$. This is always true since $D  0$.\n2. $-1 \\le 1 - 4D \\sin^2(\\frac{\\theta}{2}) \\implies 4D \\sin^2(\\frac{\\theta}{2}) \\le 2 \\implies D \\sin^2(\\frac{\\theta}{2}) \\le \\frac{1}{2}$.\nThis must hold for all $\\theta$. The maximum value of $\\sin^2(\\theta/2)$ is $1$. Thus, the stability condition is:\n$$D \\le \\frac{1}{2} \\implies \\frac{\\kappa \\Delta t}{(\\Delta x)^2} \\le \\frac{1}{2}$$\nThis imposes an upper bound on the allowable time step:\n$$\\Delta t \\le \\frac{(\\Delta x)^2}{2\\kappa}$$\n\n**3. Determination of the Optimal Courant Number**\n\nThe coupled simulation uses a shared time step $\\Delta t$, which must satisfy the stability conditions of both subsystems. The wave scheme requires $S \\le 1$, which translates to $\\Delta t \\le \\frac{\\Delta x}{c}$. The diffusion scheme requires $\\Delta t \\le \\frac{(\\Delta x)^2}{2\\kappa}$.\nTherefore, the shared time step must satisfy $\\Delta t \\le \\min\\left(\\frac{\\Delta x}{c}, \\frac{(\\Delta x)^2}{2\\kappa}\\right)$.\n\nThe problem asks for the feasible set of the Courant number $S$. We can express the diffusion stability constraint in terms of $S$ by substituting $\\Delta t = S \\frac{\\Delta x}{c}$:\n$$\\frac{\\kappa}{(\\Delta x)^2} \\left(S \\frac{\\Delta x}{c}\\right) \\le \\frac{1}{2}$$\n$$S \\frac{\\kappa}{c \\Delta x} \\le \\frac{1}{2} \\implies S \\le \\frac{c \\Delta x}{2\\kappa}$$\nThe feasible set for $S$ is the intersection of the constraints from both schemes: $S  0$ and\n$$S \\le 1 \\quad \\text{and} \\quad S \\le \\frac{c \\Delta x}{2\\kappa}$$\nThis can be written compactly as $0  S \\le \\min\\left(1, \\frac{c \\Delta x}{2\\kappa}\\right)$.\n\nWe seek the value of $S$ in this feasible set that minimizes the magnitude of the leading-order wave dispersion error, which is proportional to $|S^2-1|$. Within the feasible set, $S \\le 1$, so $S^2-1 \\le 0$. The magnitude is $|S^2-1| = 1-S^2$. To minimize $1-S^2$, we must maximize $S$. The maximum value of $S$ permitted by the stability constraints is the optimal value, $S_{\\mathrm{opt}}$, which minimizes the dispersion error.\n$$S_{\\mathrm{opt}} = \\max_S \\left\\{ S \\mid 0  S \\le \\min\\left(1, \\frac{c \\Delta x}{2\\kappa}\\right) \\right\\}$$\nTherefore, the optimal Courant number is the upper bound of the feasible set:\n$$S_{\\mathrm{opt}} = \\min\\left(1, \\frac{c \\Delta x}{2\\kappa}\\right)$$\nThis expression provides the optimal Courant number in terms of the given parameters $c$, $\\kappa$, and $\\Delta x$.",
            "answer": "$$\\boxed{\\min\\left(1, \\frac{c \\Delta x}{2 \\kappa}\\right)}$$"
        },
        {
            "introduction": "Verifying that a simulation code correctly solves the intended mathematical model is a cornerstone of computational science. This exercise guides you through a practical code verification study using the Method of Manufactured Solutions . You will design and implement a numerical experiment to demonstrate how insufficient convergence of an iterative solver can introduce an algebraic error that masks the true discretization error, a crucial concept for debugging and building confidence in complex simulation software.",
            "id": "3504784",
            "problem": "Consider a one-dimensional, steady, two-field, linearly coupled reaction–diffusion system on the spatial interval $[0,1]$ with homogeneous Dirichlet boundary conditions. The unknown fields are $u(x)$ and $v(x)$, and the governing equations are\n$$\n-\\,u''(x) + a\\,u(x) + b\\,v(x) = s_u(x), \\quad -\\,v''(x) + c\\,v(x) + d\\,u(x) = s_v(x),\n$$\nwith $u(0)=u(1)=0$ and $v(0)=v(1)=0$. Assume a manufactured exact solution $u_e(x) = \\sin(\\pi x)$ and $v_e(x) = \\sin(2\\pi x)$. Let the positive reaction coefficients be $a=1$ and $c=2$, and the coupling coefficients be $b=0.1$ and $d=0.2$. The source terms are constructed so that the manufactured solution satisfies the continuous equations:\n$$\ns_u(x) = \\pi^2 \\sin(\\pi x) + a \\sin(\\pi x) + b \\sin(2\\pi x), \\quad s_v(x) = (2\\pi)^2 \\sin(2\\pi x) + c \\sin(2\\pi x) + d \\sin(\\pi x).\n$$\n\nYou will discretize the spatial domain using a uniform grid with $N$ points (including boundaries), grid spacing $h=1/(N-1)$, and second-order central differences for the diffusion operator. For interior grid points, the discrete operator approximating $-u''$ (and analogously $-v''$) is\n$$\n\\frac{2 u_i - u_{i-1} - u_{i+1}}{h^2},\n$$\nand the reaction terms are treated pointwise. The resulting uncoupled discrete operators for $u$ and $v$ are tridiagonal and strictly diagonally dominant. To treat coupling, use a partitioned Gauss–Seidel (Gauss–Seidel) iteration at the algebraic level: given an iterate $(u^{(k)}, v^{(k)})$ on the interior grid, compute the next iterate by solving the following two linear systems in sequence,\n$$\nA\\,u^{(k+1)} = s_u - b\\,v^{(k)}, \\quad C\\,v^{(k+1)} = s_v - d\\,u^{(k+1)},\n$$\nwhere $A$ and $C$ are the discrete uncoupled operators for $u$ and $v$, and $s_u, s_v$ are the discrete source vectors obtained by sampling the analytical $s_u(x), s_v(x)$ at interior grid points. Initialize $u^{(0)}=0$ and $v^{(0)}=0$ on the interior. Terminate iterations based on a tolerance on the combined change between successive iterates,\n$$\n\\| (u^{(k+1)} - u^{(k)}, v^{(k+1)} - v^{(k)}) \\|_{2,h} \\le \\mathrm{tol},\n$$\nwhere the discrete $L^2$ norm on the interior grid is defined as\n$$\n\\| (x,y) \\|_{2,h} = \\left( h \\sum_{i} x_i^2 + h \\sum_{i} y_i^2 \\right)^{1/2}.\n$$\n\nThe central questions are about discretization error, consistency, and convergence, and about how coupling iteration error can mask asymptotic discretization error. The total numerical error (relative to the continuous manufactured solution sampled on the grid) can be thought of as the sum of two contributions for sufficiently small errors:\n$$\nE_{\\mathrm{tot}}(h,\\mathrm{tol}) \\approx E_{\\mathrm{disc}}(h) + E_{\\mathrm{iter}}(h,\\mathrm{tol}),\n$$\nwhere $E_{\\mathrm{disc}}(h)$ is due to spatial discretization (with expected order $p=2$ for second-order central differences under sufficient smoothness), and $E_{\\mathrm{iter}}(h,\\mathrm{tol})$ is due to premature termination of the coupling iteration. If $\\mathrm{tol}$ is fixed (not scaled with $h$), then as $h \\to 0$, $E_{\\mathrm{disc}}(h) \\to 0$ while $E_{\\mathrm{iter}}(h,\\mathrm{tol})$ stays approximately constant, masking the discretization error and destroying the observed asymptotic rate.\n\nTask: Implement a program that carries out numerical experiments to quantify and separate these error contributions. For each run, compute the discrete $L^2$ errors of $u$ and $v$ combined:\n$$\nE_{\\mathrm{tot}}(h,\\mathrm{tol}) = \\left( h \\sum_{i} \\left(u^{(k_{\\mathrm{final})}}_i - u_e(x_i)\\right)^2 + h \\sum_{i} \\left(v^{(k_{\\mathrm{final})}}_i - v_e(x_i)\\right)^2 \\right)^{1/2}.\n$$\nAlso, when comparing two runs at the same $h$, estimate the coupling iteration error by\n$$\nE_{\\mathrm{iter,est}}(h) = \\left( h \\sum_{i} \\left(u_{\\mathrm{loose},i} - u_{\\mathrm{tight},i}\\right)^2 + h \\sum_{i} \\left(v_{\\mathrm{loose},i} - v_{\\mathrm{tight},i}\\right)^2 \\right)^{1/2},\n$$\nwhere “tight” denotes a run with an extremely small tolerance and “loose” denotes a run with a fixed tolerance.\n\nDesign a test suite comprising three runs, each evaluated on three grid resolutions $N\\in\\{33,65,129\\}$:\n\n- Case A (tight tolerance, near-monolithic convergence): $\\mathrm{tol} = 10^{-12}$ and maximum iterations $500$.\n- Case B (loose tolerance, masking expected): $\\mathrm{tol} = 10^{-4}$ and maximum iterations $500$.\n- Case C (severely under-iterated, edge case): $\\mathrm{tol}$ arbitrary and maximum iterations $1$.\n\nFor each case, compute the total error on each grid and then estimate the observed order of accuracy $p_{\\mathrm{obs}}$ using the two finest grids:\n$$\np_{\\mathrm{obs}} = \\frac{\\ln\\left( E_{\\mathrm{tot}}(h_2,\\mathrm{tol}) / E_{\\mathrm{tot}}(h_3,\\mathrm{tol}) \\right)}{\\ln\\left( h_2 / h_3 \\right)},\n$$\nwhere $h_2=1/(65-1)$ and $h_3=1/(129-1)$. Additionally, for Case B on the finest grid ($N=129$), compute the ratio\n$$\nr_{\\mathrm{fine}} = \\frac{E_{\\mathrm{iter,est}}(h_3)}{E_{\\mathrm{tot}}(h_3,\\mathrm{tol}_{\\mathrm{loose}})}.\n$$\n\nYour program must produce a single line of output containing a comma-separated list in square brackets with the following six entries:\n- The observed order $p_{\\mathrm{obs}}$ for Case A using the two finest grids, as a floating-point number.\n- The observed order $p_{\\mathrm{obs}}$ for Case B using the two finest grids, as a floating-point number.\n- The observed order $p_{\\mathrm{obs}}$ for Case C using the two finest grids, as a floating-point number.\n- The ratio $r_{\\mathrm{fine}}$ for Case B at $N=129$, as a floating-point number in $[0,1]$.\n- A boolean indicating whether the tight-tolerance observed order lies in $[1.8,2.2]$.\n- A boolean indicating whether masking is observed in Case B, defined as simultaneously $p_{\\mathrm{obs}}1.0$ and $r_{\\mathrm{fine}}0.5$.\n\nAll quantities are dimensionless, so no physical units are required. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[p_A,p_B,p_C,r_{\\mathrm{fine}},\\mathrm{bool}_A,\\mathrm{bool}_B]$). The program must be self-contained and run without any inputs or external files. The numerical experiments must adhere to the described discretization and coupling iteration procedure exactly, and use the specified test suite parameters verbatim.",
            "solution": "The user provided a valid, well-posed problem. This response provides the solution.\n\n### 1. Theoretical Framework\n\nThe problem requires a numerical investigation of a coupled, one-dimensional, steady-state reaction-diffusion system. The governing partial differential equations (PDEs) for the two fields, $u(x)$ and $v(x)$, on the domain $x \\in [0,1]$ are:\n$$\n-\\,u''(x) + a\\,u(x) + b\\,v(x) = s_u(x)\n$$\n$$\n-\\,v''(x) + c\\,v(x) + d\\,u(x) = s_v(x)\n$$\nThese are subject to homogeneous Dirichlet boundary conditions, $u(0)=u(1)=0$ and $v(0)=v(1)=0$. The coefficients are given as $a=1$, $c=2$, $b=0.1$, and $d=0.2$.\n\nTo facilitate a quantitative error analysis, the Method of Manufactured Solutions is employed. We prescribe exact analytical solutions, $u_e(x) = \\sin(\\pi x)$ and $v_e(x) = \\sin(2\\pi x)$, which conveniently satisfy the boundary conditions. The source terms, $s_u(x)$ and $s_v(x)$, are then derived by substituting these exact solutions back into the governing equations:\n$$\ns_u(x) = -(-\\pi^2 \\sin(\\pi x)) + a \\sin(\\pi x) + b \\sin(2\\pi x) = \\pi^2 \\sin(\\pi x) + a \\sin(\\pi x) + b \\sin(2\\pi x)\n$$\n$$\ns_v(x) = -(-(2\\pi)^2 \\sin(2\\pi x)) + c \\sin(2\\pi x) + d \\sin(\\pi x) = (2\\pi)^2 \\sin(2\\pi x) + c \\sin(2\\pi x) + d \\sin(\\pi x)\n$$\nWith these source terms, the continuous problem has a known, unique solution, providing a benchmark against which our numerical solution can be compared.\n\n### 2. Numerical Discretization and Solution Strategy\n\nThe continuous domain is discretized using a uniform grid of $N$ points, $x_i = i \\cdot h$ for $i=0, 1, \\dots, N-1$, where the grid spacing is $h=1/(N-1)$. The interior grid points are indexed from $i=1$ to $N-2$.\n\nThe second derivative terms, $-u''$ and $-v''$, are approximated using a second-order accurate central finite difference scheme. For an interior grid point $x_i$, this approximation is:\n$$\n-u''(x_i) \\approx \\frac{-u_{i-1} + 2u_i - u_{i+1}}{h^2}\n$$\nwhere $u_i$ is the numerical approximation of $u(x_i)$. Applying this to the first PDE at each interior point $i$ yields a system of linear equations:\n$$\n\\frac{-u_{i-1} + 2u_i - u_{i+1}}{h^2} + a u_i + b v_i = (s_u)_i\n$$\nRearranging terms for the $u$ field allows us to express the discrete system in matrix form. Let $\\mathbf{u}$ be the vector of unknown values $[u_1, u_2, \\dots, u_{N-2}]^T$. The uncoupled operator for $u$ can be written as a matrix $A$ such that the equations become $A\\mathbf{u} + b\\mathbf{v} = \\mathbf{s}_u$. The matrix $A$ is an $(N-2) \\times (N-2)$ tridiagonal matrix with diagonal entries $(2/h^2 + a)$ and off-diagonal entries $-1/h^2$. Since the reaction coefficient $a=1$ is positive, the matrix $A$ is strictly diagonally dominant, which guarantees its invertibility and the stability of numerical solvers. The same construction yields a matrix $C$ for the $v$ field, which is also tridiagonal and strictly diagonally dominant as $c=2  0$.\n\nThe fully coupled discrete system is a block matrix system:\n$$\n\\begin{pmatrix} A  \\mathrm{diag}(b) \\\\ \\mathrm{diag}(d)  C \\end{pmatrix} \\begin{pmatrix} \\mathbf{u} \\\\ \\mathbf{v} \\end{pmatrix} = \\begin{pmatrix} \\mathbf{s}_u \\\\ \\mathbf{s}_v \\end{pmatrix}\n$$\nTo solve this system, a partitioned (or block) Gauss-Seidel iterative scheme is adopted. Starting with an initial guess, typically $\\mathbf{u}^{(0)}=\\mathbf{0}$ and $\\mathbf{v}^{(0)}=\\mathbf{0}$, the scheme iterates for $k=0, 1, 2, \\dots$ by solving two smaller, uncoupled systems in sequence:\n1.  **Solve for** $\\mathbf{u}^{(k+1)}$: $A\\,\\mathbf{u}^{(k+1)} = \\mathbf{s}_u - b\\,\\mathbf{v}^{(k)}$\n2.  **Solve for** $\\mathbf{v}^{(k+1)}$: $C\\,\\mathbf{v}^{(k+1)} = \\mathbf{s}_v - d\\,\\mathbf{u}^{(k+1)}$\n\nIn each step, a tridiagonal linear system is solved. This is performed efficiently using a specialized algorithm such as the Thomas algorithm (or by using a library function like `scipy.linalg.solve_banded`). The iteration continues until the change between successive iterates is smaller than a specified tolerance, $\\mathrm{tol}$, measured in a discrete $L^2$-norm:\n$$\n\\| (\\mathbf{u}^{(k+1)} - \\mathbf{u}^{(k)}, \\mathbf{v}^{(k+1)} - \\mathbf{v}^{(k)}) \\|_{2,h} = \\left( h \\sum_{i=1}^{N-2} (u_i^{(k+1)} - u_i^{(k)})^2 + h \\sum_{i=1}^{N-2} (v_i^{(k+1)} - v_i^{(k)})^2 \\right)^{1/2} \\le \\mathrm{tol}\n$$\n\n### 3. Error Analysis and Experimental Design\n\nThe objective is to distinguish between two sources of error in the final numerical solution:\n1.  **Discretization Error ($E_{\\mathrm{disc}}$)**: This error arises from approximating the continuous differential operators with finite difference formulas. For the second-order scheme used, we expect this error to decrease quadratically with the grid spacing, i.e., $E_{\\mathrm{disc}} \\propto h^2$.\n2.  **Iteration Error ($E_{\\mathrm{iter}}$)**: This error is due to terminating the iterative Gauss-Seidel solver before it has fully converged to the exact solution of the discrete algebraic system. This error is controlled by the tolerance $\\mathrm{tol}$.\n\nThe total error, $E_{\\mathrm{tot}}$, is the sum of these contributions: $E_{\\mathrm{tot}}(h,\\mathrm{tol}) \\approx E_{\\mathrm{disc}}(h) + E_{\\mathrm{iter}}(h,\\mathrm{tol})$. If the tolerance $\\mathrm{tol}$ is held constant while the grid is refined (i.e., $h \\to 0$), the discretization error $E_{\\mathrm{disc}}(h)$ will decrease. However, the iteration error $E_{\\mathrm{iter}}(h,\\mathrm{tol})$ will remain roughly constant, eventually becoming the dominant component of the total error. This phenomenon, known as **error masking**, prevents the observed convergence rate from reaching its theoretical asymptotic value, $p=2$.\n\nTo demonstrate this, three numerical experiments are conducted on a sequence of grids with $N \\in \\{33, 65, 129\\}$:\n-   **Case A (Tight Tolerance)**: With $\\mathrm{tol} = 10^{-12}$, the iteration error is driven to a negligible level. The total error $E_{\\mathrm{tot}}$ should be dominated by the discretization error $E_{\\mathrm{disc}}$, and the observed order of accuracy, $p_{\\mathrm{obs}}$, should approach the theoretical value of $2$.\n-   **Case B (Loose Tolerance)**: With $\\mathrm{tol} = 10^{-4}$, the iteration error is significant. On coarse grids, it may be smaller than the discretization error, but on fine grids, it will dominate, causing $p_{\\mathrm{obs}}$ to drop significantly below $2$.\n-   **Case C (Under-iterated)**: With only one iteration, the solution is far from converged. The resulting error is large, and the \"order of accuracy\" calculation is not expected to yield a meaningful value, highlighting the importance of sufficient iteration.\n\nThe observed order of accuracy is computed from the total errors on the two finest grids ($N_2=65$, $N_3=129$) using the formula:\n$$\np_{\\mathrm{obs}} = \\frac{\\ln\\left( E_{\\mathrm{tot}}(h_2,\\mathrm{tol}) / E_{\\mathrm{tot}}(h_3,\\mathrm{tol}) \\right)}{\\ln\\left( h_2 / h_3 \\right)}\n$$\nFinally, for the finest grid, the iteration error is directly estimated by comparing the loose-tolerance solution (Case B) to the tight-tolerance solution (Case A, taken as a proxy for the exact discrete solution). The ratio of this estimated iteration error to the total error in the loose case, $r_{\\mathrm{fine}}$, quantifies the extent of error masking.\n\nThe implementation will proceed by systematically running these cases, computing the errors, and deriving the specified quantities for the final output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef run_simulation(N, tol, max_iter):\n    \"\"\"\n    Solves the coupled reaction-diffusion system for a given grid size,\n    tolerance, and max iterations.\n    \n    Args:\n        N (int): Number of grid points (including boundaries).\n        tol (float): Convergence tolerance for the Gauss-Seidel iteration.\n        max_iter (int): Maximum number of Gauss-Seidel iterations.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray, float]: Tuple containing the final solution\n        vector u, the final solution vector v, and the total L2 error.\n    \"\"\"\n    # 1. Setup grid and parameters\n    h = 1.0 / (N - 1)\n    x = np.linspace(0, 1, N)\n    x_int = x[1:-1]  # Interior points\n    num_int_pts = N - 2\n    \n    # Coefficients from problem statement\n    a, c = 1.0, 2.0\n    b, d = 0.1, 0.2\n    \n    # 2. Manufactured solution and source terms on the interior grid\n    pi = np.pi\n    u_exact_int = np.sin(pi * x_int)\n    v_exact_int = np.sin(2 * pi * x_int)\n    \n    s_u_int = pi**2 * u_exact_int + a * u_exact_int + b * v_exact_int\n    s_v_int = (2*pi)**2 * v_exact_int + c * v_exact_int + d * u_exact_int\n    \n    # 3. Construct uncoupled operators A and C in banded format for SciPy\n    # The banded format for a tridiagonal matrix (l=1, u=1) requires 3 rows:\n    # row 0: upper diagonal (shifted left)\n    # row 1: main diagonal\n    # row 2: lower diagonal (shifted right)\n    \n    # Matrix A for -u'' + a*u\n    A_banded = np.zeros((3, num_int_pts))\n    A_banded[0, 1:] = -1.0 / h**2\n    A_banded[1, :]  = 2.0 / h**2 + a\n    A_banded[2, :-1] = -1.0 / h**2\n    \n    # Matrix C for -v'' + c*v\n    C_banded = np.zeros((3, num_int_pts))\n    C_banded[0, 1:] = -1.0 / h**2\n    C_banded[1, :]  = 2.0 / h**2 + c\n    C_banded[2, :-1] = -1.0 / h**2\n    \n    # 4. Partitioned Gauss-Seidel Iteration\n    u_k = np.zeros(num_int_pts)\n    v_k = np.zeros(num_int_pts)\n    \n    for k in range(max_iter):\n        u_prev = u_k.copy()\n        v_prev = v_k.copy()\n        \n        # Solve for u^(k+1)\n        rhs_u = s_u_int - b * v_k\n        u_k = solve_banded((1, 1), A_banded, rhs_u)\n        \n        # Solve for v^(k+1)\n        rhs_v = s_v_int - d * u_k\n        v_k = solve_banded((1, 1), C_banded, rhs_v)\n        \n        # Check for convergence\n        diff_u = u_k - u_prev\n        diff_v = v_k - v_prev\n        norm_diff = np.sqrt(h * (np.sum(diff_u**2) + np.sum(diff_v**2)))\n        \n        if norm_diff = tol:\n            break\n            \n    # 5. Calculate total error against the exact manufactured solution\n    err_u = u_k - u_exact_int\n    err_v = v_k - v_exact_int\n    total_error = np.sqrt(h * (np.sum(err_u**2) + np.sum(err_v**2)))\n    \n    return u_k, v_k, total_error\n\n\ndef solve():\n    \"\"\"\n    Main function to run the numerical experiments and compute the final results.\n    \"\"\"\n    # Define test parameters\n    resolutions = [33, 65, 129]\n    cases = {\n        'A': {'tol': 1e-12, 'max_iter': 500},\n        'B': {'tol': 1e-4,  'max_iter': 500},\n        'C': {'tol': 1e-4,  'max_iter': 1}  # tol is arbitrary for 1 iteration\n    }\n    \n    # Store results from all runs\n    results_data = {}\n    \n    # Run simulations for all cases and resolutions\n    for case_name, params in cases.items():\n        results_data[case_name] = {}\n        for N in resolutions:\n            u, v, error = run_simulation(N, params['tol'], params['max_iter'])\n            results_data[case_name][N] = {'u': u, 'v': v, 'error': error}\n    \n    # ---------- Calculate Final Outputs ----------\n    \n    # 1. Observed order of accuracy (p_obs) for each case\n    h_values = {N: 1.0 / (N - 1) for N in resolutions}\n    p_obs = {}\n    for case_name in cases:\n        err_h2 = results_data[case_name][65]['error']\n        err_h3 = results_data[case_name][129]['error']\n        # p_obs = log(E2/E3) / log(h2/h3) where h2/h3 = 2\n        p_obs[case_name] = np.log(err_h2 / err_h3) / np.log(2.0)\n        \n    pA = p_obs['A']\n    pB = p_obs['B']\n    pC = p_obs['C']\n    \n    # 2. Ratio r_fine for Case B at N=129\n    N_fine = 129\n    h_fine = h_values[N_fine]\n    \n    # 'tight' solution is from Case A, 'loose' is from Case B\n    u_tight = results_data['A'][N_fine]['u']\n    v_tight = results_data['A'][N_fine]['v']\n    u_loose = results_data['B'][N_fine]['u']\n    v_loose = results_data['B'][N_fine]['v']\n    \n    # Estimate iteration error as difference between loose and tight solutions\n    diff_u_iter = u_loose - u_tight\n    diff_v_iter = v_loose - v_tight\n    iter_err_est = np.sqrt(h_fine * (np.sum(diff_u_iter**2) + np.sum(diff_v_iter**2)))\n    \n    # Total error for the loose case at the finest grid\n    total_err_loose_fine = results_data['B'][N_fine]['error']\n    \n    r_fine = iter_err_est / total_err_loose_fine\n\n    # 3. Boolean checks\n    # Check if tight-tolerance order is close to theoretical value of 2\n    bool_A = 1.8 = pA = 2.2\n    # Check if error masking is observed in Case B\n    bool_B = (pB  1.0) and (r_fine > 0.5)\n\n    # Compile final results into a list\n    final_list = [pA, pB, pC, r_fine, bool_A, bool_B]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_list))}]\")\n\nsolve()\n```"
        }
    ]
}