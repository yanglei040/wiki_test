{
    "hands_on_practices": [
        {
            "introduction": "本练习旨在奠定理论基础。我们将通过探究最直接的重采样方案——多项式重采样，来理解其固有的权衡。通过从第一性原理推导唯一父粒子的期望数量，您将直接量化权重退化如何导致粒子多样性的损失，这是序贯蒙特卡洛方法中的一个核心挑战。",
            "id": "3417338",
            "problem": "考虑一个反演问题中贝叶斯数据同化背景下的序贯蒙特卡洛 (SMC) 重采样步骤。你有一个由 $N$ 个粒子 $\\{x^{i}\\}_{i=1}^{N}$ 组成的加权粒子集，其归一化重要性权重为 $\\{\\tilde w^{i}\\}_{i=1}^{N}$，其中 $\\tilde w^{i} \\in (0,1)$ 且 $\\sum_{i=1}^{N} \\tilde w^{i} = 1$。一个标准的多项式重采样方案抽取 $N$ 个独立的后代索引 $(A_{1},\\dots,A_{N})$，其中给定权重，每个 $A_{n} \\in \\{1,\\dots,N\\}$ 都是条件独立的，并且对于每个 $i \\in \\{1,\\dots,N\\}$ 和每个 $n \\in \\{1,\\dots,N\\}$，都满足 $\\mathbb{P}(A_{n} = i \\mid \\tilde w^{1:N}) = \\tilde w^{i}$。\n\n仅使用 $N$ 次分类抽样的独立性以及多项式重采样的定义，从第一性原理出发推导以下量：\n\n首先，固定一个索引 $k \\in \\{1,\\dots,N\\}$，并令 $C_{k} := \\sum_{n=1}^{N} \\mathbf{1}\\{A_{n} = k\\}$ 表示粒子 $k$ 被选中的次数。计算粒子 $k$ 完全不被选中的概率，即计算 $\\mathbb{P}(C_{k} = 0 \\mid \\tilde w^{1:N})$，并将其表示为 $N$ 和 $\\tilde w^{k}$ 的闭合形式函数。\n\n其次，将重采样后选中的唯一父代粒子数量定义为 $U := \\sum_{i=1}^{N} \\mathbf{1}\\{C_{i} \\ge 1\\}$。计算期望值 $\\mathbb{E}[U \\mid \\tilde w^{1:N}]$，并将其表示为 $N$ 和 $\\{\\tilde w^{i}\\}_{i=1}^{N}$ 的闭合形式函数。\n\n你的推导必须从多项式重采样下独立分类抽样的基本性质开始，不得引用任何预先推导的重采样恒等式。最后，在定性渐近分析的层面上，简要解释表达式 $\\mathbb{E}[U \\mid \\tilde w^{1:N}]$ 如何反映高维反演问题中维度灾难所特有的权重退化现象。\n\n将你的最终答案表示为一个包含两个条目的单行矩阵：第一个条目是 $\\mathbb{P}(C_{k} = 0 \\mid \\tilde w^{1:N})$，第二个条目是 $\\mathbb{E}[U \\mid \\tilde w^{1:N}]$。不需要进行数值四舍五入，也不适用任何物理单位。",
            "solution": "问题陈述是一个适定且有科学依据的练习，它将基础概率论应用于序贯蒙特卡洛方法中多项式重采样的标准模型。所有术语都有正式定义，前提条件一致，并且任务可以直接从所提供的信息中推导出来。因此，该问题被认为是有效的。\n\n我们按要求进行推导，使每一步都基于概率论的第一性原理和前述的问题定义。在接下来的所有概率和期望计算中，对权重 $\\{\\tilde w^{i}\\}_{i=1}^{N}$ 的条件依赖是隐含的。为求符号清晰，我们将省略显式的条件符号 $\\mid \\tilde w^{1:N}$，直到最后的陈述。\n\n首先，我们计算在重采样步骤中特定粒子 $k \\in \\{1,\\dots,N\\}$ 完全未被选中的概率。令 $C_{k}$ 为粒子 $k$ 被选中的次数。事件 $\\{C_{k} = 0\\}$ 表示在所有 $N$ 次独立抽样中，索引 $k$ 从未被选中。\n\n令 $A_{n}$ 表示第 $n$ 次抽样中选中的索引，其中 $n \\in \\{1,\\dots,N\\}$。事件 $\\{C_{k} = 0\\}$ 等价于所有 $n$ 的事件 $\\{A_{n} \\neq k\\}$ 的交集。\n$$\n\\mathbb{P}(C_{k} = 0) = \\mathbb{P}(A_{1} \\neq k \\text{ and } A_{2} \\neq k \\text{ and } \\dots \\text{ and } A_{N} \\neq k) = \\mathbb{P}\\left(\\bigcap_{n=1}^{N} \\{A_{n} \\neq k\\}\\right)\n$$\n问题陈述指出抽样 $(A_{1},\\dots,A_{N})$ 是独立的。因此，这些事件交集的概率是它们各自概率的乘积。\n$$\n\\mathbb{P}(C_{k} = 0) = \\prod_{n=1}^{N} \\mathbb{P}(A_{n} \\neq k)\n$$\n对于任何单次抽样 $n$，选中索引 $i$ 的概率为 $\\mathbb{P}(A_{n} = i) = \\tilde w^{i}$。事件 $\\{A_n \\neq k\\}$ 是事件 $\\{A_n = k\\}$ 的互补事件。这个互补事件的概率是：\n$$\n\\mathbb{P}(A_{n} \\neq k) = 1 - \\mathbb{P}(A_{n} = k) = 1 - \\tilde w^{k}\n$$\n由于对于 $N$ 次独立抽样中的每一次，这个概率都是相同的，所以乘积变为：\n$$\n\\mathbb{P}(C_{k} = 0) = \\prod_{n=1}^{N} (1 - \\tilde w^{k}) = (1 - \\tilde w^{k})^{N}\n$$\n恢复显式条件，第一个所求的量是 $\\mathbb{P}(C_{k} = 0 \\mid \\tilde w^{1:N}) = (1 - \\tilde w^{k})^{N}$。\n\n其次，我们计算重采样后选中的唯一父代粒子的期望数量，记为 $U$。所给定义为 $U := \\sum_{i=1}^{N} \\mathbf{1}\\{C_{i} \\ge 1\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。事件 $\\{C_{i} \\ge 1\\}$ 表示粒子 $i$ 被选中了至少一次。\n\n我们被要求计算 $U$ 的期望。根据期望的线性性，我们可以将期望算子移到求和符号内部：\n$$\n\\mathbb{E}[U] = \\mathbb{E}\\left[\\sum_{i=1}^{N} \\mathbf{1}\\{C_{i} \\ge 1\\}\\right] = \\sum_{i=1}^{N} \\mathbb{E}[\\mathbf{1}\\{C_{i} \\ge 1\\}]\n$$\n指示函数的期望是它所指示事件的概率。因此，对于每个粒子 $i$：\n$$\n\\mathbb{E}[\\mathbf{1}\\{C_{i} \\ge 1\\}] = \\mathbb{P}(C_{i} \\ge 1)\n$$\n粒子 $i$ 被选中至少一次的事件 $\\{C_i \\ge 1\\}$，是它从未被选中的事件 $\\{C_i = 0\\}$ 的互补事件。因此，其概率为：\n$$\n\\mathbb{P}(C_{i} \\ge 1) = 1 - \\mathbb{P}(C_{i} = 0)\n$$\n使用我们第一个推导的结果，通过将索引 $k$ 替换为 $i$，我们可以代入 $\\mathbb{P}(C_{i} = 0)$ 的表达式：\n$$\n\\mathbb{P}(C_{i} = 0) = (1 - \\tilde w^{i})^{N}\n$$\n这得到 $\\mathbb{P}(C_{i} \\ge 1) = 1 - (1 - \\tilde w^{i})^{N}$。将其代回 $\\mathbb{E}[U]$ 的求和式中：\n$$\n\\mathbb{E}[U] = \\sum_{i=1}^{N} \\left(1 - (1 - \\tilde w^{i})^{N}\\right)\n$$\n恢复显式条件，第二个所求的量是 $\\mathbb{E}[U \\mid \\tilde w^{1:N}] = \\sum_{i=1}^{N} (1 - (1 - \\tilde w^{i})^{N})$。\n\n最后，我们解释表达式 $\\mathbb{E}[U \\mid \\tilde w^{1:N}]$ 如何反映维度灾难所特有的权重退化。在高维状态空间中，贝叶斯更新常常导致一种称为权重退化或样本贫化的现象。似然函数变得非常尖锐，导致后验分布集中在状态空间的一个非常小的体积内。在SMC的背景下，这意味着在重要性采样步骤之后，一个（或极少数）恰好落在这个高似然区域的粒子将获得一个接近于1的权重 $\\tilde w^{j}$，而所有其他粒子（$i\\neq j$）的权重 $\\tilde w^{i}$ 将变得无穷小，即 $\\tilde w^{i} \\approx 0$。\n\n让我们在这种退化情景下分析 $\\mathbb{E}[U]$ 的行为。考虑一个极端情况，其中一个权重 $\\tilde w^{j} \\to 1$，而所有其他权重 $\\tilde w^{i} \\to 0$（对于 $i \\neq j$），并满足约束条件 $\\sum_{i=1}^{N} \\tilde w^{i} = 1$。\n来自具有主导权重的粒子 $j$ 对 $\\mathbb{E}[U]$ 的贡献是：\n$$\n1 - (1 - \\tilde w^{j})^{N} \\to 1 - (1 - 1)^{N} = 1\n$$\n这表明高权重的粒子几乎肯定会被选为祖先。\n来自任何其他权重可忽略（$\\tilde w^{i} \\approx 0$）的粒子 $i \\neq j$ 的贡献可以被近似。根据二项式近似，对于一个小的 $x$ 值，$(1-x)^N \\approx 1-Nx$。因此：\n$$\n1 - (1 - \\tilde w^{i})^{N} \\approx 1 - (1 - N\\tilde w^{i}) = N\\tilde w^{i}\n$$\n对所有 $i \\neq j$ 的这些贡献求和：\n$$\n\\sum_{i \\neq j} (1 - (1 - \\tilde w^{i})^{N}) \\approx \\sum_{i \\neq j} N\\tilde w^{i} = N \\sum_{i \\neq j} \\tilde w^{i}\n$$\n因为 $\\sum_{i=1}^{N} \\tilde w^{i} = 1$，我们有 $\\sum_{i \\neq j} \\tilde w^{i} = 1 - \\tilde w^{j}$。所以，这个和是 $N(1-\\tilde w^{j})$。\n那么，唯一粒子的总期望数量为：\n$$\n\\mathbb{E}[U] \\approx \\left(1 - (1 - \\tilde w^{j})^{N}\\right) + N(1-\\tilde w^{j})\n$$\n随着退化变得极端，$\\tilde w^{j} \\to 1$，这意味着 $(1-\\tilde w^{j}) \\to 0$。在这个极限下：\n$$\n\\lim_{\\tilde w^{j} \\to 1} \\mathbb{E}[U] = 1 + N \\cdot 0 = 1\n$$\n唯一粒子的期望数量接近1意味着，在重采样之后，新的 $N$ 个粒子群体极有可能由单个祖先的 $N$ 个相同副本组成。这种灾难性的多样性损失是粒子滤波器坍塌的功能性定义，是权重退化的直接后果，而权重退化本身就是维度灾难的一种体现。因此，推导出的 $\\mathbb{E}[U]$ 表达式为这种退化提供了一个定量的度量。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} (1 - \\tilde w^{k})^{N}  \\sum_{i=1}^{N} \\left(1 - (1 - \\tilde w^{i})^{N}\\right) \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "在我们理解了为何需要重采样的基础上，现在我们将检验一种更先进方案的具体工作方式。本练习将引导您逐步了解系统性重采样的机制，这是一种流行的、替代多项式重采样的低方差方案。您不仅将逐步执行该算法，还将分析其结构特性，如选择的连贯性，从而体会其在实践中的优势与局限。",
            "id": "3417312",
            "problem": "考虑一个应用于数据同化中贝叶斯逆问题的序贯蒙特卡洛（SMC）粒子方法，该方法有 $N$ 个粒子和归一化的重要性权重 $\\{w_i\\}_{i=1}^N$，其和为 $1$。粒子按标量状态坐标的升序索引，因此相邻的索引对应于相邻的状态。SMC 算法采用系统重采样方案，定义如下：从 $[0, 1/N)$ 上的均匀分布中抽取一个 $U$，并形成阈值序列 $t_k = U + (k-1)/N$，其中 $k = 1, \\dots, N$。令 $c_j = \\sum_{i=1}^j w_i$ 表示权重的累积和。位置 $k$ 处的重采样祖先索引定义为 $a_k = \\min\\{j \\in \\{1,\\dots,N\\} : c_j \\ge t_k\\}$。\n\n给定 $N = 10$，归一化的权重为\n$$\n(w_1, \\dots, w_{10}) = (0.24, 0.01, 0.01, 0.18, 0.18, 0.20, 0.05, 0.03, 0.05, 0.05),\n$$\n以及一个固定的 $U = 0.07$。根据上述系统重采样的定义，计算完整的选择索引向量 $(a_1, \\dots, a_{10})$。\n\n为了量化索引空间中相邻选择的一致性程度（这反映了系统重采样众所周知的相关性结构），定义相邻一致性指数\n$$\n\\kappa = \\frac{1}{N-1} \\sum_{k=1}^{N-1} \\mathbf{1}\\left(|a_{k+1} - a_k| \\le 1\\right),\n$$\n其中 $\\mathbf{1}(\\cdot)$ 是指示函数。以 $\\kappa$ 的值作为最终答案。最终答案需表示为最简分数。在你的推导过程中，请将此相邻一致性的概念与权重退化情况下的粒子多样性联系起来，并讨论其在高维逆问题中对维度灾难的影响。最终答案必须是一个没有单位的数字，并且必须表示为最简分数。",
            "solution": "首先根据所需标准对问题进行验证。问题陈述是自洽的，科学上基于序贯蒙特卡洛方法的理论，并且在算法上是适定的。所有必要的数据均已提供，包括粒子数 $N=10$、归一化的权重 $\\{w_i\\}$ 以及随机抽取的特定值 $U=0.07$。所提供权重的总和确实是 $0.24 + 0.01 + 0.01 + 0.18 + 0.18 + 0.20 + 0.05 + 0.03 + 0.05 + 0.05 = 1.00$，证实了它们的归一化。$U=0.07$ 的值与所需的分布 $\\mathcal{U}[0, 1/N) = \\mathcal{U}[0, 0.1)$ 一致。系统重采样和相邻一致性指数 $\\kappa$ 的定义是精确的，并允许有唯一的解。因此，该问题被认为是有效的，有必要给出完整解法。\n\n求解过程分为三步：首先，我们计算祖先索引向量 $(a_1, \\dots, a_{10})$；其次，我们用这个向量计算相邻一致性指数 $\\kappa$；最后，我们讨论这一结果的更广泛意义。\n\n第1步：计算祖先索引向量 $(a_1, \\dots, a_{10})$。\n\n根据系统重采样的定义，我们必须首先计算权重的累积和 $c_j = \\sum_{i=1}^j w_i$，以及阈值序列 $t_k = U + (k-1)/N$。\n\n给定的权重是：\n$$ (w_1, \\dots, w_{10}) = (0.24, 0.01, 0.01, 0.18, 0.18, 0.20, 0.05, 0.03, 0.05, 0.05) $$\n累积和 $c_j$ 是：\n\\begin{align*}\nc_1 = 0.24 \\\\\nc_2 = 0.24 + 0.01 = 0.25 \\\\\nc_3 = 0.25 + 0.01 = 0.26 \\\\\nc_4 = 0.26 + 0.18 = 0.44 \\\\\nc_5 = 0.44 + 0.18 = 0.62 \\\\\nc_6 = 0.62 + 0.20 = 0.82 \\\\\nc_7 = 0.82 + 0.05 = 0.87 \\\\\nc_8 = 0.87 + 0.03 = 0.90 \\\\\nc_9 = 0.90 + 0.05 = 0.95 \\\\\nc_{10} = 0.95 + 0.05 = 1.00\n\\end{align*}\n\n粒子数为 $N=10$，随机抽取值为 $U=0.07$。阈值序列 $t_k = 0.07 + (k-1)/10$ 对于 $k=1, \\dots, 10$ 如下：\n\\begin{align*}\nt_1 = 0.07 + 0.0 = 0.07 \\\\\nt_2 = 0.07 + 0.1 = 0.17 \\\\\nt_3 = 0.07 + 0.2 = 0.27 \\\\\nt_4 = 0.07 + 0.3 = 0.37 \\\\\nt_5 = 0.07 + 0.4 = 0.47 \\\\\nt_6 = 0.07 + 0.5 = 0.57 \\\\\nt_7 = 0.07 + 0.6 = 0.67 \\\\\nt_8 = 0.07 + 0.7 = 0.77 \\\\\nt_9 = 0.07 + 0.8 = 0.87 \\\\\nt_{10} = 0.07 + 0.9 = 0.97\n\\end{align*}\n\n祖先索引 $a_k$ 是满足 $c_j \\ge t_k$ 的最小索引 $j$。我们通过将 $t_k$ 与累积权重序列 $c_j$ 进行比较来找到每个 $a_k$：\n\\begin{itemize}\n    \\item 对于 $t_1 = 0.07$：第一个累积权重 $c_1=0.24$ 大于 $0.07$。因此，$a_1=1$。\n    \\item 对于 $t_2 = 0.17$：第一个累积权重 $c_1=0.24$ 大于 $0.17$。因此，$a_2=1$。\n    \\item 对于 $t_3 = 0.27$：$c_3=0.26  0.27$，但 $c_4=0.44 \\ge 0.27$。因此，$a_3=4$。\n    \\item 对于 $t_4 = 0.37$：$c_3=0.26  0.37$，但 $c_4=0.44 \\ge 0.37$。因此，$a_4=4$。\n    \\item 对于 $t_5 = 0.47$：$c_4=0.44  0.47$，但 $c_5=0.62 \\ge 0.47$。因此，$a_5=5$。\n    \\item 对于 $t_6 = 0.57$：$c_4=0.44  0.57$，但 $c_5=0.62 \\ge 0.57$。因此，$a_6=5$。\n    \\item 对于 $t_7 = 0.67$：$c_5=0.62  0.67$，但 $c_6=0.82 \\ge 0.67$。因此，$a_7=6$。\n    \\item 对于 $t_8 = 0.77$：$c_5=0.62  0.77$，但 $c_6=0.82 \\ge 0.77$。因此，$a_8=6$。\n    \\item 对于 $t_9 = 0.87$：$c_6=0.82  0.87$，但 $c_7=0.87 \\ge 0.87$。因此，$a_9=7$。\n    \\item 对于 $t_{10} = 0.97$：$c_9=0.95  0.97$，但 $c_{10}=1.00 \\ge 0.97$。因此，$a_{10}=10$。\n\\end{itemize}\n完整的选择索引向量为 $(a_1, \\dots, a_{10}) = (1, 1, 4, 4, 5, 5, 6, 6, 7, 10)$。\n\n第2步：计算相邻一致性指数 $\\kappa$。\n\n该指数定义为 $\\kappa = \\frac{1}{N-1} \\sum_{k=1}^{N-1} \\mathbf{1}\\left(|a_{k+1} - a_k| \\le 1\\right)$。当 $N=10$ 时，我们有 $N-1=9$。我们对向量 $a$ 中的每个相邻对评估指示函数 $\\mathbf{1}(\\cdot)$：\n\\begin{itemize}\n    \\item $k=1$: $|a_2 - a_1| = |1 - 1| = 0 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=2$: $|a_3 - a_2| = |4 - 1| = 3 > 1 \\implies \\mathbf{1}(\\cdot) = 0$。\n    \\item $k=3$: $|a_4 - a_3| = |4 - 4| = 0 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=4$: $|a_5 - a_4| = |5 - 4| = 1 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=5$: $|a_6 - a_5| = |5 - 5| = 0 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=6$: $|a_7 - a_6| = |6 - 5| = 1 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=7$: $|a_8 - a_7| = |6 - 6| = 0 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=8$: $|a_9 - a_8| = |7 - 6| = 1 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=9$: $|a_{10} - a_9| = |10 - 7| = 3 > 1 \\implies \\mathbf{1}(\\cdot) = 0$。\n\\end{itemize}\n指示函数值的总和为 $1 + 0 + 1 + 1 + 1 + 1 + 1 + 1 + 0 = 7$。\n因此，相邻一致性指数为：\n$$ \\kappa = \\frac{7}{9} $$\n\n第3步：讨论。\n\n计算出的 $\\kappa = 7/9$ 值很高，表明重采样序列中的大多数相邻索引对应的祖先在原始有序粒子集中是相同或紧邻的。这种高一致性是系统重采样的标志。与多项式重采样（其中每个新粒子都是独立抽取的）不同，系统重采样通过单次随机抽取 $U$ 来固定整个选择模式。阈值 $t_k$ 是等距的，因此它们倾向于选择连续的祖先块，从而保留了局部结构。\n\n这直接关系到 **权重退化** (weight degeneracy) 的问题。在SMC中，一个常见的问题是重要性权重集中在少数几个粒子上，而其余粒子的权重可以忽略不计。这就是 **权重退化**。重采样是标准的补救措施，其目的是丢弃低权重粒子并复制高权重粒子，从而将计算资源集中在状态空间中有希望的区域。所提供的权重中，$w_1=0.24$、$w_4=0.18$、$w_5=0.18$ 和 $w_6=0.20$，显示出中等程度的退化。\n\n重采样虽然必要，但会引入其自身的问题：**粒子多样性** (particle diversity) 的损失，因为重采样后集合中唯一祖先的数量小于 $N$。这种样本的贫化是粒子方法的一个关键限制。由 $\\kappa$ 测量出的高一致性体现了系统重采样如何管理这种权衡。通过保留邻域结构，它避免了独立重采样可能导致的粒子位置完全随机化，如果高权重粒子在状态空间中形成一个“簇”，这可能是有益的。\n\n整个动态被 **维度灾难** (curse of dimensionality) 严重加剧，这是高维逆问题中的一个关键问题。随着状态空间维度的增加，空间的体积呈指数级增长。SMC采样器所针对的后验分布通常集中在该体积中一个极小的部分。因此，固定数量的随机粒子 $N$ 落入这个高概率区域的可能性越来越小。这会导致极端的权重退化，通常在更新步骤之后只有一个粒子具有非零权重。在这种灾难性的崩溃中，任何重采样方案（包括系统重采样）都只会选择那一个粒子 $N$ 次。最终的重采样集合将是 $(a_1, \\dots, a_N) = (j, j, \\dots, j)$，对于某个索引 $j$。在这种情况下，$\\kappa$ 将为 $1$，但这将意味着多样性的完全丧失，而不是健康的结构保留。因此，系统重采样的一致性属性并非解决维度灾难的万能药；它仅仅反映了其所获得的权重结构。根本问题在于重要性采样无法有效探索高维空间，这是一个需要超越简单重采样的更高级技术来应对的挑战。",
            "answer": "$$ \\boxed{\\frac{7}{9}} $$"
        },
        {
            "introduction": "重采样是一个强大的工具，但它并非没有代价——它会引入噪声和计算开销。这最后一个练习将我们的视角从具体机制提升到策略层面，并提出一个关键问题：何时进行重采样才是最优的？您将通过建立一个简洁而有力的决策理论模型，来推导出一个用于自适应重采样的最优阈值，该模型旨在平衡估计误差的减少与重采样操作的成本。",
            "id": "3339239",
            "problem": "考虑一个在时间 $t-1$ 具有 $N$ 个粒子的序贯重要性采样粒子系统，其归一化权重为 $\\{W_{t-1}^{i}\\}_{i=1}^{N}$，相关的变异系数平方为 $u \\equiv \\mathrm{CV}^{2}(W_{t-1})$。在时间 $t$，一个增量加权步骤将未归一化的权重乘以独立的、正的增量权重 $\\{\\tilde{w}_{t}^{i}\\}_{i=1}^{N}$，其变异系数平方为 $v \\equiv \\mathrm{CV}^{2}(\\tilde{w}_{t})$。在时间 $t$，对于一个有界检验函数 $\\varphi$，自归一化重要性采样估计量为 $\\hat{I}_{t} \\equiv \\sum_{i=1}^{N} W_{t}^{i}\\,\\varphi(X_{t}^{i})$，其中 $\\{W_{t}^{i}\\}_{i=1}^{N}$ 是在应用增量权重并可能进行重采样步骤后的归一化权重，而 $\\{X_{t}^{i}\\}_{i=1}^{N}$ 是传播后的粒子。\n\n假设以下标准事实和建模假设：\n$1.$ 对于独立的、正的随机变量 $X$ 和 $Y$，其变异系数平方满足 $1+\\mathrm{CV}^{2}(XY)=\\bigl(1+\\mathrm{CV}^{2}(X)\\bigr)\\bigl(1+\\mathrm{CV}^{2}(Y)\\bigr)$。\n$2.$ 对于归一化权重 $W$，有效样本量分数满足 $\\mathrm{ESS}/N = 1/\\bigl(1+\\mathrm{CV}^{2}(W)\\bigr)$。\n$3.$ 在小到中等权重退化的情况下，自归一化估计量的均方误差可以通过一阶灵敏度模型 $\\mathrm{MSE}(\\hat{I}_{t}) \\approx \\mathrm{MSE}_{0} + S\\,\\mathrm{CV}^{2}(W_{t})$ 很好地近似，其中 $S0$ 是估计量灵敏度系数，取决于 $\\varphi$、提议机制和时间 $t$ 的目标，而 $\\mathrm{MSE}_{0}$ 是零退化时的基线均方误差。\n$4.$ 单次重采样操作会产生一个附加的计算成本惩罚 $\\lambda0$，该惩罚以与均方误差相同的单位来衡量。如果选择执行重采样，它会在时间 $t$ 应用增量权重之前立即执行，从而将更新前的权重退化从 $u$ 重置为 $0$。\n\n考虑以下由阈值 $\\tau \\in (0,1)$ 参数化的自适应重采样规则：当且仅当更新前的有效样本量分数满足 $\\mathrm{ESS}/N \\le \\tau$ 时，在时间 $t$ 进行重采样。\n\n从第一性原理推导闭式最优阈值 $\\tau^{\\star}$，该阈值最小化单步目标：“在时间 $t$ 进行增量加权后的均方误差，加上（如果执行了重采样）重采样惩罚”。将 $\\tau^{\\star}$ 表示为增量权重变异系数平方 $v$、估计量灵敏度 $S$ 和重采样惩罚 $\\lambda$ 的函数。您的最终答案必须是 $\\tau^{\\star}$ 的单个解析表达式。不需要进行数值四舍五入。",
            "solution": "我们从序贯重要性采样中的权重更新开始。设时间 $t-1$ 的归一化权重的变异系数平方为 $u \\equiv \\mathrm{CV}^{2}(W_{t-1})$，时间 $t$ 的增量权重的变异系数平方为 $v \\equiv \\mathrm{CV}^{2}(\\tilde{w}_{t})$。在时间 $t$ 的未归一化权重与 $w_{t-1}^{i}\\,\\tilde{w}_{t}^{i}$ 成正比。根据假设，增量权重与更新前的权重无关，且两者均为正。利用独立随机变量乘积的方差，对于独立的、正的随机变量 $X$ 和 $Y$，我们有：\n\n$$\n\\mathrm{Var}(XY) \\,=\\, \\mathbb{E}[X]^{2}\\,\\mathrm{Var}(Y) \\,+\\, \\mathbb{E}[Y]^{2}\\,\\mathrm{Var(X)} \\,+\\, \\mathrm{Var}(X)\\,\\mathrm{Var}(Y).\n$$\n\n令 $\\mu_{X} \\equiv \\mathbb{E}[X]$，$\\mu_{Y} \\equiv \\mathbb{E}[Y]$，$\\sigma_{X}^{2} \\equiv \\mathrm{Var}(X)$，$\\sigma_{Y}^{2} \\equiv \\mathrm{Var}(Y)$，以及 $\\mathrm{CV}^{2}(X) \\equiv \\sigma_{X}^{2}/\\mu_{X}^{2}$，则 $Z \\equiv XY$ 的变异系数平方为\n\n$$\n\\mathrm{CV}^{2}(Z) \\,=\\, \\frac{\\mathrm{Var}(Z)}{\\mathbb{E}[Z]^{2}} \\,=\\, \\frac{\\mu_{X}^{2}\\sigma_{Y}^{2} + \\mu_{Y}^{2}\\sigma_{X}^{2} + \\sigma_{X}^{2}\\sigma_{Y}^{2}}{\\mu_{X}^{2}\\mu_{Y}^{2}} \\,=\\, \\mathrm{CV}^{2}(X) + \\mathrm{CV}^{2}(Y) + \\mathrm{CV}^{2}(X)\\,\\mathrm{CV}^{2}(Y).\n$$\n\n等价地，\n\n$$\n1 + \\mathrm{CV}^{2}(XY) \\,=\\, \\bigl(1 + \\mathrm{CV}^{2}(X)\\bigr)\\,\\bigl(1 + \\mathrm{CV}^{2}(Y)\\bigr).\n$$\n\n将此应用于 $X$ 代表更新前权重、$Y$ 代表增量权重的情况，我们得到未经重采样的更新后权重为\n\n$$\n1 + \\mathrm{CV}^{2}(W_{t}^{\\mathrm{no\\text{-}res}}) \\,=\\, \\bigl(1+u\\bigr)\\,\\bigl(1+v\\bigr),\n$$\n\n因此\n\n$$\n\\mathrm{CV}^{2}(W_{t}^{\\mathrm{no\\text{-}res}}) \\,=\\, (1+u)(1+v) - 1 \\,=\\, u + v + uv.\n$$\n\n\n如果我们在时间 $t$ 应用增量权重之前立即执行重采样，那么更新前的退化将被重置为零，即 $u$ 被替换为 $0$，更新后的退化变为\n\n$$\n\\mathrm{CV}^{2}(W_{t}^{\\mathrm{res}}) \\,=\\, (1+0)(1+v) - 1 \\,=\\, v.\n$$\n\n\n接下来，我们将均方误差与归一化权重的变异系数平方联系起来。在小到中等退化情况下，根据前述的灵敏度模型，自归一化估计量的均方误差满足\n\n$$\n\\mathrm{MSE}\\bigl(\\hat{I}_{t}\\bigr) \\,\\approx\\, \\mathrm{MSE}_{0} + S\\,\\mathrm{CV}^{2}(W_{t}),\n$$\n\n其中 $S0$ 取决于检验函数和粒子系统，但在时间 $t$ 被视为一个给定的常数。因此，更新后的均方误差为\n\n$$\n\\mathrm{MSE}^{\\mathrm{no\\text{-}res}} \\,\\approx\\, \\mathrm{MSE}_{0} + S\\bigl(u + v + uv\\bigr)\n$$\n\n如果不执行重采样，以及\n\n$$\n\\mathrm{MSE}^{\\mathrm{res}} \\,\\approx\\, \\mathrm{MSE}_{0} + S v\n$$\n\n如果在更新前执行重采样。\n\n如果执行重采样，自适应决策会产生一个重采样惩罚 $\\lambda0$。要最小化的单步目标是更新后的均方误差加上（如果发生重采样）惩罚。因此，在这两种操作下的目标是\n\n$$\nJ^{\\mathrm{no\\text{-}res}} \\,=\\, \\mathrm{MSE}_{0} + S\\bigl(u + v + uv\\bigr),\n$$\n\n\n$$\nJ^{\\mathrm{res}} \\,=\\, \\mathrm{MSE}_{0} + S v + \\lambda.\n$$\n\n在给定的更新前退化水平 $u$ 下，最优决策是当且仅当 $J^{\\mathrm{res}} \\le J^{\\mathrm{no\\text{-}res}}$ 时进行重采样，即：\n\n$$\n\\mathrm{MSE}_{0} + S v + \\lambda \\,\\le\\, \\mathrm{MSE}_{0} + S\\bigl(u + v + uv\\bigr).\n$$\n\n消去项后，该不等式简化为\n\n$$\n\\lambda \\,\\le\\, S\\bigl(u + uv\\bigr) \\,=\\, S u (1+v).\n$$\n\n因此，无差异边界出现在\n\n$$\nu_{\\mathrm{th}} \\,=\\, \\frac{\\lambda}{S(1+v)}.\n$$\n\n等价地，当且仅当 $u \\ge u_{\\mathrm{th}}$ 时，重采样是最优的。\n\n自适应规则对有效样本量分数使用一个阈值 $\\tau$。使用有效样本量分数和变异系数平方之间的标准关系，\n\n$$\n\\frac{\\mathrm{ESS}}{N} \\,=\\, \\frac{1}{1 + \\mathrm{CV}^{2}(W)} \\,=\\, \\frac{1}{1+u},\n$$\n\n条件 $\\mathrm{ESS}/N \\le \\tau$ 等价于 $1/(1+u) \\le \\tau$，即 $u \\ge (1-\\tau)/\\tau$。因此，将最优决策边界与阈值策略对齐可得\n\n$$\n\\frac{1-\\tau^{\\star}}{\\tau^{\\star}} \\,=\\, u_{\\mathrm{th}} \\,=\\, \\frac{\\lambda}{S(1+v)}.\n$$\n\n解出 $\\tau^{\\star}$ 可得\n\n$$\n\\tau^{\\star} \\,=\\, \\frac{1}{1 + \\dfrac{\\lambda}{S(1+v)}} \\,=\\, \\frac{S(1+v)}{S(1+v) + \\lambda}.\n$$\n\n\n该表达式是关于增量权重变异系数平方 $v$、估计量灵敏度 $S$ 和重采样惩罚 $\\lambda$ 的闭式形式，符合要求。对于 $S0$，$v \\ge 0$ 和 $\\lambda0$，它也满足 $\\tau^{\\star} \\in (0,1)$。",
            "answer": "$$\\boxed{\\frac{S(1+v)}{S(1+v)+\\lambda}}$$"
        }
    ]
}