{
    "hands_on_practices": [
        {
            "introduction": "在深入研究复杂的重采样方案之前，理解其基本影响至关重要。本练习将引导您通过第一性原理推导，来量化多项式重采样的一个关键后果：粒子多样性的预期损失。通过计算重采样后唯一父代粒子的期望数量，您将能更深刻地体会其中涉及的权衡，并理解为何管理权重退化问题如此重要 。",
            "id": "3417338",
            "problem": "考虑一个反问题中贝叶斯数据同化背景下的序列蒙特卡洛 (SMC) 重采样步骤。你有一个由 $N$ 个粒子 $\\{x^{i}\\}_{i=1}^{N}$ 组成的加权系综，其归一化重要性权重为 $\\{\\tilde w^{i}\\}_{i=1}^{N}$，其中 $\\tilde w^{i} \\in (0,1)$ 且 $\\sum_{i=1}^{N} \\tilde w^{i} = 1$。一个标准的多项式重采样方案抽取 $N$ 个独立的后代索引 $(A_{1},\\dots,A_{N})$，其中每个 $A_{n} \\in \\{1,\\dots,N\\}$ 在给定权重下条件独立，并对每个 $i \\in \\{1,\\dots,N\\}$ 和每个 $n \\in \\{1,\\dots,N\\}$ 满足 $\\mathbb{P}(A_{n} = i \\mid \\tilde w^{1:N}) = \\tilde w^{i}$。\n\n仅使用 $N$ 次分类抽样的独立性和多项式重采样的定义，从第一性原理推导以下量：\n\n首先，固定一个索引 $k \\in \\{1,\\dots,N\\}$，并令 $C_{k} := \\sum_{n=1}^{N} \\mathbf{1}\\{A_{n} = k\\}$ 表示粒子 $k$ 被选中的次数。计算粒子 $k$ 完全不被选中的概率，即计算 $\\mathbb{P}(C_{k} = 0 \\mid \\tilde w^{1:N})$，并以 $N$ 和 $\\tilde w^{k}$ 的函数闭合形式表示。\n\n其次，将重采样后选中的唯一父代粒子数量定义为 $U := \\sum_{i=1}^{N} \\mathbf{1}\\{C_{i} \\ge 1\\}$。计算期望值 $\\mathbb{E}[U \\mid \\tilde w^{1:N}]$，并以 $N$ 和 $\\{\\tilde w^{i}\\}_{i=1}^{N}$ 的函数闭合形式表示。\n\n你的推导必须从多项式重采样下的独立分类抽样的基本性质出发，不引用任何预先推導出的重采样恒等式。最后，在定性渐近的层面上简要解释 $\\mathbb{E}[U \\mid \\tilde w^{1:N}]$ 的表达式如何反映高维反问题中维度灾难所特有的权重退化现象。\n\n将你的最终答案表示为一个包含两个条目的单行矩阵：第一个条目是 $\\mathbb{P}(C_{k} = 0 \\mid \\tilde w^{1:N})$，第二个条目是 $\\mathbb{E}[U \\mid \\tilde w^{1:N}]$。不需要进行数值四舍五入，也没有物理单位。",
            "solution": "该问题陈述是一个适定的、有科学依据的练习，它将初等概率论应用于序列蒙特卡洛方法中多项式重采样的标准模型。所有术语都得到了正式定义，前提条件是一致的，各项任务都可以从所提供的信息中直接推导出来。因此，该问题被认为是有效的。\n\n我们按要求进行推导，每一步都基于概率的第一性原理和上述问题定义。在下文所有的概率和期望计算中，都隐含了对权重 $\\{\\tilde w^{i}\\}_{i=1}^{N}$ 的条件依赖。为了符号清晰起见，我们将省略显式的条件符号 $\\mid \\tilde w^{1:N}$，直到最后的陈述。\n\n首先，我们计算在重采样步骤中特定粒子 $k \\in \\{1,\\dots,N\\}$ 完全不被选中的概率。令 $C_{k}$ 为粒子 $k$ 被选中的次数。事件 $\\{C_{k} = 0\\}$ 意味着在所有 $N$ 次独立抽样中，索引 $k$从未被选中。\n\n令 $A_{n}$ 表示第 $n$ 次抽样中选中的索引，其中 $n \\in \\{1,\\dots,N\\}$。事件 $\\{C_{k} = 0\\}$ 等价于对所有 $n$ 的事件 $\\{A_{n} \\neq k\\}$ 的交集。\n$$\n\\mathbb{P}(C_{k} = 0) = \\mathbb{P}(A_{1} \\neq k \\text{ and } A_{2} \\neq k \\text{ and } \\dots \\text{ and } A_{N} \\neq k) = \\mathbb{P}\\left(\\bigcap_{n=1}^{N} \\{A_{n} \\neq k\\}\\right)\n$$\n问题陈述指出抽样 $(A_{1},\\dots,A_{N})$ 是独立的。因此，这些事件交集的概率是它们各自概率的乘积。\n$$\n\\mathbb{P}(C_{k} = 0) = \\prod_{n=1}^{N} \\mathbb{P}(A_{n} \\neq k)\n$$\n对于任意单次抽样 $n$，选中索引 $i$ 的概率为 $\\mathbb{P}(A_{n} = i) = \\tilde w^{i}$。事件 $\\{A_n \\neq k\\}$ 是事件 $\\{A_n = k\\}$ 的补集。这个互补事件的概率是：\n$$\n\\mathbb{P}(A_{n} \\neq k) = 1 - \\mathbb{P}(A_{n} = k) = 1 - \\tilde w^{k}\n$$\n由于对于 $N$ 次独立抽样中的每一次，这个概率都是相同的，因此乘积变为：\n$$\n\\mathbb{P}(C_{k} = 0) = \\prod_{n=1}^{N} (1 - \\tilde w^{k}) = (1 - \\tilde w^{k})^{N}\n$$\n恢复显式条件，第一个要求的量是 $\\mathbb{P}(C_{k} = 0 \\mid \\tilde w^{1:N}) = (1 - \\tilde w^{k})^{N}$。\n\n其次，我们计算重采样后选中的唯一父代粒子的期望数量，记为 $U$。所提供的定义为 $U := \\sum_{i=1}^{N} \\mathbf{1}\\{C_{i} \\ge 1\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。事件 $\\{C_{i} \\ge 1\\}$ 表示粒子 $i$ 至少被选中一次。\n\n我们被要求计算 $U$ 的期望值。根据期望的线性性质，我们可以将期望算子移到求和符号内部：\n$$\n\\mathbb{E}[U] = \\mathbb{E}\\left[\\sum_{i=1}^{N} \\mathbf{1}\\{C_{i} \\ge 1\\}\\right] = \\sum_{i=1}^{N} \\mathbb{E}[\\mathbf{1}\\{C_{i} \\ge 1\\}]\n$$\n指示函数的期望是它所指示事件的概率。因此，对于每个粒子 $i$：\n$$\n\\mathbb{E}[\\mathbf{1}\\{C_{i} \\ge 1\\}] = \\mathbb{P}(C_{i} \\ge 1)\n$$\n粒子 $i$ 至少被选中一次的事件 $\\{C_i \\ge 1\\}$ 是它从未被选中的事件 $\\{C_i = 0\\}$ 的补集。因此，其概率为：\n$$\n\\mathbb{P}(C_{i} \\ge 1) = 1 - \\mathbb{P}(C_{i} = 0)\n$$\n使用我们第一个推导的结果，我们可以通过将索引 $k$ 替换为 $i$ 来代入 $\\mathbb{P}(C_{i} = 0)$ 的表达式：\n$$\n\\mathbb{P}(C_{i} = 0) = (1 - \\tilde w^{i})^{N}\n$$\n这得到 $\\mathbb{P}(C_{i} \\ge 1) = 1 - (1 - \\tilde w^{i})^{N}$。将其代回到 $\\mathbb{E}[U]$ 的求和式中：\n$$\n\\mathbb{E}[U] = \\sum_{i=1}^{N} \\left(1 - (1 - \\tilde w^{i})^{N}\\right)\n$$\n恢复显式条件，第二个要求的量是 $\\mathbb{E}[U \\mid \\tilde w^{1:N}] = \\sum_{i=1}^{N} (1 - (1 - \\tilde w^{i})^{N})$。\n\n最后，我们解释 $\\mathbb{E}[U \\mid \\tilde w^{1:N}]$ 的表达式如何反映维度灾难所特有的权重退化。在高维状态空间中，贝叶斯更新常常导致一种称为权重退化或样本贫化的现象。似然函数变得非常尖锐，导致后验分布集中在状态空间的一个非常小的体积内。在 SMC 的背景下，这意味着在重要性采样步骤之后，一个（或极少数）恰好落入这个高似然区域的粒子将获得一个接近 1 的权重 $\\tilde w^{j}$，而所有其他粒子的权重 $\\tilde w^{i}$（对于 $i\\neq j$）将变得无穷小，即 $\\tilde w^{i} \\approx 0$。\n\n让我们在这种退化情景下分析 $\\mathbb{E}[U]$ 的行为。考虑一个极端情况，其中一个权重 $\\tilde w^{j} \\to 1$ 而所有其他权重 $\\tilde w^{i} \\to 0$（对于 $i \\neq j$），并满足约束条件 $\\sum_{i=1}^{N} \\tilde w^{i} = 1$。\n来自具有主导权重的粒子 $j$ 对 $\\mathbb{E}[U]$ 的贡献是：\n$$\n1 - (1 - \\tilde w^{j})^{N} \\to 1 - (1 - 1)^{N} = 1\n$$\n这表明高权重的粒子几乎肯定会被选为父代粒子。\n来自任何其他权重可忽略的粒子 $i \\neq j$（$\\tilde w^{i} \\approx 0$）的贡献可以被近似。根据二项式近似，对于一个很小的 $x$ 值，有 $(1-x)^N \\approx 1-Nx$。因此：\n$$\n1 - (1 - \\tilde w^{i})^{N} \\approx 1 - (1 - N\\tilde w^{i}) = N\\tilde w^{i}\n$$\n对所有 $i \\neq j$ 的这些贡献求和：\n$$\n\\sum_{i \\neq j} (1 - (1 - \\tilde w^{i})^{N}) \\approx \\sum_{i \\neq j} N\\tilde w^{i} = N \\sum_{i \\neq j} \\tilde w^{i}\n$$\n因为 $\\sum_{i=1}^{N} \\tilde w^{i} = 1$，我们有 $\\sum_{i \\neq j} \\tilde w^{i} = 1 - \\tilde w^{j}$。所以，这个和是 $N(1-\\tilde w^{j})$。\n那么，唯一粒子的总期望数量为：\n$$\n\\mathbb{E}[U] \\approx \\left(1 - (1 - \\tilde w^{j})^{N}\\right) + N(1-\\tilde w^{j})\n$$\n当退化变得极端时，$\\tilde w^{j} \\to 1$，这意味着 $(1-\\tilde w^{j}) \\to 0$。在此极限下：\n$$\n\\lim_{\\tilde w^{j} \\to 1} \\mathbb{E}[U] = 1 + N \\cdot 0 = 1\n$$\n唯一粒子期望数量趋近于 1 意味着，在重采样之后，新的 $N$ 个粒子群体极有可能由单个父代粒子的 $N$ 个相同副本组成。这种灾难性的多样性损失是粒子滤波器坍塌的功能性定义，它是权重退化的直接后果，而权重退化本身就是维度灾难的一种表现。因此，推导出的 $\\mathbb{E}[U]$ 表达式为这种退化提供了一个定量度量。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} (1 - \\tilde w^{k})^{N} & \\sum_{i=1}^{N} \\left(1 - (1 - \\tilde w^{i})^{N}\\right) \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "虽然多项式重采样易于分析，但在实践中，系统重采样因其能够减少选择过程的随机性而通常更受青睐。本练习提供了一个具体的、分步的计算，以揭开系统重采样算法的神秘面纱。通过为一组给定的权重追踪粒子的选择过程，您将建立起对该方法如何保留粒子簇的直观理解，并明白其性能与重要性权重的结构有何关联。",
            "id": "3417312",
            "problem": "考虑一个应用于数据同化中贝叶斯逆问题的序贯蒙特卡洛（SMC）粒子法，该方法有 $N$ 个粒子和归一化的重要性权重 $\\{w_i\\}_{i=1}^N$，且权重之和为 $1$。粒子按其标量状态坐标升序索引，因此相邻的索引对应于相邻的状态。SMC 算法采用系统重采样方案，定义如下：从区间 $[0, 1/N)$ 上的均匀分布中抽取一个 $U$，并为 $k=1, \\dots, N$ 构建阈值序列 $t_k = U + (k-1)/N$。令 $c_j = \\sum_{i=1}^j w_i$ 表示权重的累积和。位置 $k$ 处的重采样祖先索引定义为 $a_k = \\min\\{j \\in \\{1,\\dots,N\\} : c_j \\ge t_k\\}$。\n\n给定 $N = 10$，归一化权重为\n$$\n(w_1, \\dots, w_{10}) = (0.24, 0.01, 0.01, 0.18, 0.18, 0.20, 0.05, 0.03, 0.05, 0.05),\n$$\n以及一个固定的 $U = 0.07$。请根据上述系统重采样定义，计算完整的选择索引向量 $(a_1, \\dots, a_{10})$。\n\n为了量化索引空间中相邻选择的相干性（这反映了系统重采样的众所周知的相关性结构），定义邻域相干性指数\n$$\n\\kappa = \\frac{1}{N-1} \\sum_{k=1}^{N-1} \\mathbf{1}\\left(|a_{k+1} - a_k| \\le 1\\right),\n$$\n其中 $\\mathbf{1}(\\cdot)$ 是指示函数。将 $\\kappa$ 的值作为最终答案。最终答案需表示为既约分数。在你的推导过程中，请将这种邻域相干性的概念与存在权重退化时的粒子多样性联系起来，并讨论其对于高维逆问题中维度灾难的意义。最终答案必须是一个无单位的数值，并表示为既约分数。",
            "solution": "首先根据要求对问题进行验证。问题陈述是自洽的，科学上基于序贯蒙特卡洛方法的理论，并且在算法上是适定的。所有必要的数据都已提供，包括粒子数 $N=10$、归一化权重 $\\{w_i\\}$ 以及随机抽取的特定值 $U=0.07$。所提供权重的总和确实是 $0.24 + 0.01 + 0.01 + 0.18 + 0.18 + 0.20 + 0.05 + 0.03 + 0.05 + 0.05 = 1.00$，这证实了它们的归一化。$U=0.07$ 的值与要求的分布 $\\mathcal{U}[0, 1/N) = \\mathcal{U}[0, 0.1)$ 一致。系统重采样和邻域相干性指数 $\\kappa$ 的定义是精确的，可以得出唯一解。因此，该问题被视为有效，值得给出完整解答。\n\n解题过程分为三步：首先，我们计算祖先索引向量 $(a_1, \\dots, a_{10})$；其次，我们用这个向量计算邻域相干性指数 $\\kappa$；最后，我们讨论这个结果的更广泛意义。\n\n步骤1：计算祖先索引向量 $(a_1, \\dots, a_{10})$。\n\n根据系统重采样的定义，我们必须首先计算权重的累积和 $c_j = \\sum_{i=1}^j w_i$ 和阈值序列 $t_k = U + (k-1)/N$。\n\n给定的权重为：\n$$ (w_1, \\dots, w_{10}) = (0.24, 0.01, 0.01, 0.18, 0.18, 0.20, 0.05, 0.03, 0.05, 0.05) $$\n累积和 $c_j$ 为：\n\\begin{align*}\nc_1 = 0.24 \\\\\nc_2 = 0.24 + 0.01 = 0.25 \\\\\nc_3 = 0.25 + 0.01 = 0.26 \\\\\nc_4 = 0.26 + 0.18 = 0.44 \\\\\nc_5 = 0.44 + 0.18 = 0.62 \\\\\nc_6 = 0.62 + 0.20 = 0.82 \\\\\nc_7 = 0.82 + 0.05 = 0.87 \\\\\nc_8 = 0.87 + 0.03 = 0.90 \\\\\nc_9 = 0.90 + 0.05 = 0.95 \\\\\nc_{10} = 0.95 + 0.05 = 1.00\n\\end{align*}\n\n粒子数为 $N=10$，随机抽样为 $U=0.07$。对于 $k=1, \\dots, 10$ 的阈值序列 $t_k = 0.07 + (k-1)/10$ 为：\n\\begin{align*}\nt_1 = 0.07 + 0.0 = 0.07 \\\\\nt_2 = 0.07 + 0.1 = 0.17 \\\\\nt_3 = 0.07 + 0.2 = 0.27 \\\\\nt_4 = 0.07 + 0.3 = 0.37 \\\\\nt_5 = 0.07 + 0.4 = 0.47 \\\\\nt_6 = 0.07 + 0.5 = 0.57 \\\\\nt_7 = 0.07 + 0.6 = 0.67 \\\\\nt_8 = 0.07 + 0.7 = 0.77 \\\\\nt_9 = 0.07 + 0.8 = 0.87 \\\\\nt_{10} = 0.07 + 0.9 = 0.97\n\\end{align*}\n\n祖先索引 $a_k$ 是使 $c_j \\ge t_k$ 成立的最小索引 $j$。我们通过将 $t_k$ 与累积权重序列 $c_j$ 进行比较来找到每个 $a_k$：\n\\begin{itemize}\n    \\item 对于 $t_1 = 0.07$：第一个累积权重 $c_1=0.24$ 大于 $0.07$。因此，$a_1=1$。\n    \\item 对于 $t_2 = 0.17$：第一个累积权重 $c_1=0.24$ 大于 $0.17$。因此，$a_2=1$。\n    \\item 对于 $t_3 = 0.27$：$c_3=0.26  0.27$，但 $c_4=0.44 \\ge 0.27$。因此，$a_3=4$。\n    \\item 对于 $t_4 = 0.37$：$c_3=0.26  0.37$，但 $c_4=0.44 \\ge 0.37$。因此，$a_4=4$。\n    \\item 对于 $t_5 = 0.47$：$c_4=0.44  0.47$，但 $c_5=0.62 \\ge 0.47$。因此，$a_5=5$。\n    \\item 对于 $t_6 = 0.57$：$c_4=0.44  0.57$，但 $c_5=0.62 \\ge 0.57$。因此，$a_6=5$。\n    \\item 对于 $t_7 = 0.67$：$c_5=0.62  0.67$，但 $c_6=0.82 \\ge 0.67$。因此，$a_7=6$。\n    \\item 对于 $t_8 = 0.77$：$c_5=0.62  0.77$，但 $c_6=0.82 \\ge 0.77$。因此，$a_8=6$。\n    \\item 对于 $t_9 = 0.87$：$c_6=0.82  0.87$，但 $c_7=0.87 \\ge 0.87$。因此，$a_9=7$。\n    \\item 对于 $t_{10} = 0.97$：$c_9=0.95  0.97$，但 $c_{10}=1.00 \\ge 0.97$。因此，$a_{10}=10$。\n\\end{itemize}\n完整的选择索引向量为 $(a_1, \\dots, a_{10}) = (1, 1, 4, 4, 5, 5, 6, 6, 7, 10)$。\n\n步骤2：计算邻域相干性指数 $\\kappa$。\n\n该指数定义为 $\\kappa = \\frac{1}{N-1} \\sum_{k=1}^{N-1} \\mathbf{1}\\left(|a_{k+1} - a_k| \\le 1\\right)$。当 $N=10$ 时，我们有 $N-1=9$。我们对向量 $a$ 中的每一对相邻项评估指示函数 $\\mathbf{1}(\\cdot)$：\n\\begin{itemize}\n    \\item $k=1$：$|a_2 - a_1| = |1 - 1| = 0 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=2$：$|a_3 - a_2| = |4 - 1| = 3 > 1 \\implies \\mathbf{1}(\\cdot) = 0$。\n    \\item $k=3$：$|a_4 - a_3| = |4 - 4| = 0 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=4$：$|a_5 - a_4| = |5 - 4| = 1 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=5$：$|a_6 - a_5| = |5 - 5| = 0 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=6$：$|a_7 - a_6| = |6 - 5| = 1 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=7$：$|a_8 - a_7| = |6 - 6| = 0 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=8$：$|a_9 - a_8| = |7 - 6| = 1 \\le 1 \\implies \\mathbf{1}(\\cdot) = 1$。\n    \\item $k=9$：$|a_{10} - a_9| = |10 - 7| = 3 > 1 \\implies \\mathbf{1}(\\cdot) = 0$。\n\\end{itemize}\n指示函数值的总和为 $1 + 0 + 1 + 1 + 1 + 1 + 1 + 1 + 0 = 7$。\n因此，邻域相干性指数为：\n$$ \\kappa = \\frac{7}{9} $$\n\n步骤3：讨论。\n\n计算出的 $\\kappa = 7/9$ 值很高，表明重采样序列中的大多数相邻索引对应的祖先在原始有序粒子集中是相同或紧邻的。这种高相干性是系统重采样的标志。与每个新粒子都独立抽取的多项式重采样不同，系统重采样通过一次随机抽取 $U$ 就固定了整个选择模式。阈值 $t_k$ 是等距的，因此它们倾向于选择连续的祖先块，从而保留了局部结构。\n\n这直接关系到**权重退化**问题。在SMC中，一个常见的问题是重要性权重集中在少数几个粒子上，而其余粒子的权重可以忽略不计。这就是**权重退化**。重采样是标准的补救措施，其目的是丢弃低权重的粒子并复制高权重的粒子，以便将计算精力集中在状态空间中有希望的区域。所提供的权重中，$w_1=0.24$，$w_4=0.18$，$w_5=0.18$ 和 $w_6=0.20$，显示出中等程度的退化。\n\n重采样虽然是必要的，但它也引入了自身的问题：**粒子多样性**的丧失，因为重采样后集合中唯一祖先的数量少于 $N$。这种样本贫化是粒子法的一个关键限制。由 $\\kappa$ 测量的高相干性体现了系统重采样如何处理这种权衡。通过保留邻域结构，它避免了独立重采样可能导致的粒子位置完全随机化，如果高权重粒子在状态空间中形成一个“簇”，这样做可能是有益的。\n\n在高维逆问题中，**维度灾难**是一个关键问题，它严重加剧了整个动态过程。随着状态空间维度的增加，空间的体积呈指数级增长。SMC采样器所针对的后验分布通常集中在该体积中一个极小的部分。因此，固定数量的随机粒子 $N$ 越来越不可能落在这个高概率区域内。这导致了极端的权重退化，通常在更新步骤之后只有一个粒子具有非零权重。在这种灾难性崩溃中，任何重采样方案（包括系统重采样）都将只选择那一个粒子 $N$ 次。得到的重采样集合将是 $(a_1, \\dots, a_N) = (j, j, \\dots, j)$，其中 $j$ 是某个索引。在这种情况下，$\\kappa$ 将为 $1$，但这将意味着多样性的完全丧失，而不是健康的结构保留。因此，系统重采样的相干性特性并非解决维度灾难的万能药；它仅仅反映了所给权重的结构。根本问题在于重要性采样无法有效地探索高维空间，这是一个需要超越简单重采样的更高级技术来应对的挑战。",
            "answer": "$$ \\boxed{\\frac{7}{9}} $$"
        },
        {
            "introduction": "重采样是一个强大的工具，但它并非没有代价——它会引入方差并增加计算成本，正如我们在之前的问题中看到的，它还会导致多样性的损失。因此，最高效的粒子滤波器并非在每一步都进行重采样，而是采用自适应策略。这项高级练习将让您扮演算法设计者的角色 ，通过形式化地权衡降低估计误差与承担重采样惩罚之间的利弊，推导出一个最优的重采样阈值。",
            "id": "3339239",
            "problem": "考虑一个在时间 $t-1$ 有 $N$ 个粒子的序贯重要性采样粒子系统，其归一化权重为 $\\{W_{t-1}^{i}\\}_{i=1}^{N}$，相关的变异系数平方为 $u \\equiv \\mathrm{CV}^{2}(W_{t-1})$。在时间 $t$，一个增量加权步骤将未归一化的权重乘以独立的、正的增量权重 $\\{\\tilde{w}_{t}^{i}\\}_{i=1}^{N}$，其变异系数平方为 $v \\equiv \\mathrm{CV}^{2}(\\tilde{w}_{t})$。在时间 $t$，对于一个有界测试函数 $\\varphi$，其自归一化重要性采样估计量为 $\\hat{I}_{t} \\equiv \\sum_{i=1}^{N} W_{t}^{i}\\,\\varphi(X_{t}^{i})$，其中 $\\{W_{t}^{i}\\}_{i=1}^{N}$ 是在应用增量权重并可能进行重采样步骤后的归一化权重，而 $\\{X_{t}^{i}\\}_{i=1}^{N}$ 是传播后的粒子。\n\n假设以下标准事实和建模假设：\n$1.$ 对于独立的正常数随机变量 $X$ 和 $Y$，其变异系数的平方满足 $1+\\mathrm{CV}^{2}(XY)=\\bigl(1+\\mathrm{CV}^{2}(X)\\bigr)\\bigl(1+\\mathrm{CV}^{2}(Y)\\bigr)$。\n$2.$ 对于归一化权重 $W$，有效样本量分数满足 $\\mathrm{ESS}/N = 1/\\bigl(1+\\mathrm{CV}^{2}(W)\\bigr)$。\n$3.$ 在权重退化程度为小到中等的区间内，自归一化估计量的均方误差可以由一阶灵敏度模型 $\\mathrm{MSE}(\\hat{I}_{t}) \\approx \\mathrm{MSE}_{0} + S\\,\\mathrm{CV}^{2}(W_{t})$ 很好地近似，其中 $S0$ 是估计量灵敏度系数，它依赖于 $\\varphi$、提议机制和时间 $t$ 的目标，而 $\\mathrm{MSE}_{0}$ 是零退化时的基线均方误差。\n$4.$ 单次重采样操作会产生一个附加的计算成本惩罚 $\\lambda0$，其单位与均方误差相同。如果选择重采样，则在时间 $t$ 应用增量权重之前立即执行，从而将更新前的权重退化从 $u$ 重置为 $0$。\n\n考虑以下由阈值 $\\tau \\in (0,1)$ 参数化的自适应重采样规则：当且仅当更新前的有效样本量分数满足 $\\mathrm{ESS}/N \\le \\tau$ 时，在时间 $t$ 进行重采样。\n\n从第一性原理推导闭式最优阈值 $\\tau^{\\star}$，该阈值最小化单步目标：“时间 $t$ 增量加权后的均方误差，加上（如果执行了重采样）重采样惩罚”。将 $\\tau^{\\star}$ 表示为增量权重变异系数平方 $v$、估计量灵敏度 $S$ 和重采样惩罚 $\\lambda$ 的函数。你的最终答案必须是 $\\tau^{\\star}$ 的单个解析表达式。不需要进行数值舍入。",
            "solution": "我们从序贯重要性采样中的权重更新开始。设时间 $t-1$ 的归一化权重的变异系数平方为 $u \\equiv \\mathrm{CV}^{2}(W_{t-1})$，时间 $t$ 的增量权重的变异系数平方为 $v \\equiv \\mathrm{CV}^{2}(\\tilde{w}_{t})$。时间 $t$ 的未归一化权重与 $w_{t-1}^{i}\\,\\tilde{w}_{t}^{i}$ 成正比。根据假设，增量权重独立于更新前的权重，且二者均为正。利用独立随机变量乘积的方差公式，对于独立的正常数随机变量 $X$ 和 $Y$，我们有，\n\n$$\n\\mathrm{Var}(XY) \\,=\\, \\mathbb{E}[X]^{2}\\,\\mathrm{Var}(Y) \\,+\\, \\mathbb{E}[Y]^{2}\\,\\mathrm{Var}(X) \\,+\\, \\mathrm{Var}(X)\\,\\mathrm{Var}(Y).\n$$\n\n设 $\\mu_{X} \\equiv \\mathbb{E}[X]$, $\\mu_{Y} \\equiv \\mathbb{E}[Y]$, $\\sigma_{X}^{2} \\equiv \\mathrm{Var}(X)$, $\\sigma_{Y}^{2} \\equiv \\mathrm{Var}(Y)$，以及 $\\mathrm{CV}^{2}(X) \\equiv \\sigma_{X}^{2}/\\mu_{X}^{2}$，则 $Z \\equiv XY$ 的变异系数平方为\n\n$$\n\\mathrm{CV}^{2}(Z) \\,=\\, \\frac{\\mathrm{Var}(Z)}{\\mathbb{E}[Z]^{2}} \\,=\\, \\frac{\\mu_{X}^{2}\\sigma_{Y}^{2} + \\mu_{Y}^{2}\\sigma_{X}^{2} + \\sigma_{X}^{2}\\sigma_{Y}^{2}}{\\mu_{X}^{2}\\mu_{Y}^{2}} \\,=\\, \\mathrm{CV}^{2}(X) + \\mathrm{CV}^{2}(Y) + \\mathrm{CV}^{2}(X)\\,\\mathrm{CV}^{2}(Y).\n$$\n\n等价地，\n\n$$\n1 + \\mathrm{CV}^{2}(XY) \\,=\\, \\bigl(1 + \\mathrm{CV}^{2}(X)\\bigr)\\,\\bigl(1 + \\mathrm{CV}^{2}(Y)\\bigr).\n$$\n\n将此公式应用于 $X$ 代表更新前权重、$Y$ 代表增量权重的情况，我们得到不进行重采样的更新后权重的关系式\n\n$$\n1 + \\mathrm{CV}^{2}(W_{t}^{\\mathrm{no\\text{-}res}}) \\,=\\, \\bigl(1+u\\bigr)\\,\\bigl(1+v\\bigr),\n$$\n\n因此\n\n$$\n\\mathrm{CV}^{2}(W_{t}^{\\mathrm{no\\text{-}res}}) \\,=\\, (1+u)(1+v) - 1 \\,=\\, u + v + uv.\n$$\n\n\n如果我们在时间 $t$ 应用增量权重之前立即执行重采样，那么更新前的退化将被重置为零，即 $u$ 被替换为 $0$，更新后的退化变为\n\n$$\n\\mathrm{CV}^{2}(W_{t}^{\\mathrm{res}}) \\,=\\, (1+0)(1+v) - 1 \\,=\\, v.\n$$\n\n\n接下来，我们将均方误差与归一化权重的变异系数平方联系起来。在所述的权重退化程度为小到中等的区间内，根据灵敏度模型，自归一化估计量的均方误差满足\n\n$$\n\\mathrm{MSE}\\bigl(\\hat{I}_{t}\\bigr) \\,\\approx\\, \\mathrm{MSE}_{0} + S\\,\\mathrm{CV}^{2}(W_{t}),\n$$\n\n其中 $S0$ 依赖于测试函数和粒子系统，但在时间 $t$ 被视为一个给定的常数。因此，更新后的均方误差为\n\n$$\n\\mathrm{MSE}^{\\mathrm{no\\text{-}res}} \\,\\approx\\, \\mathrm{MSE}_{0} + S\\bigl(u + v + uv\\bigr)\n$$\n\n如果不进行重采样，以及\n\n$$\n\\mathrm{MSE}^{\\mathrm{res}} \\,\\approx\\, \\mathrm{MSE}_{0} + S v\n$$\n\n如果在更新前进行重采样。\n\n如果执行重采样，自适应决策会产生一个重采样惩罚 $\\lambda0$。要最小化的单步目标是更新后的均方误差加上（如果发生重采样）惩罚。因此，两种操作下的目标函数是\n\n$$\nJ^{\\mathrm{no\\text{-}res}} \\,=\\, \\mathrm{MSE}_{0} + S\\bigl(u + v + uv\\bigr),\n$$\n\n\n$$\nJ^{\\mathrm{res}} \\,=\\, \\mathrm{MSE}_{0} + S v + \\lambda.\n$$\n\n在给定的更新前退化水平 $u$ 下，最优决策是当且仅当 $J^{\\mathrm{res}} \\le J^{\\mathrm{no\\text{-}res}}$ 时进行重采样，即，\n\n$$\n\\mathrm{MSE}_{0} + S v + \\lambda \\,\\le\\, \\mathrm{MSE}_{0} + S\\bigl(u + v + uv\\bigr).\n$$\n\n消元后，该不等式简化为\n\n$$\n\\lambda \\,\\le\\, S\\bigl(u + uv\\bigr) \\,=\\, S u (1+v).\n$$\n\n因此，无差异边界出现在\n\n$$\nu_{\\mathrm{th}} \\,=\\, \\frac{\\lambda}{S(1+v)}.\n$$\n\n等价地，当且仅当 $u \\ge u_{\\mathrm{th}}$ 时，重采样是最优的。\n\n自适应规则对有效样本量分数使用一个阈值 $\\tau$。利用有效样本量分数和变异系数平方之间的标准关系，\n\n$$\n\\frac{\\mathrm{ESS}}{N} \\,=\\, \\frac{1}{1 + \\mathrm{CV}^{2}(W)} \\,=\\, \\frac{1}{1+u},\n$$\n\n条件 $\\mathrm{ESS}/N \\le \\tau$ 等价于 $1/(1+u) \\le \\tau$，即 $u \\ge (1-\\tau)/\\tau$。因此，将最优决策边界与阈值策略对齐可得\n\n$$\n\\frac{1-\\tau^{\\star}}{\\tau^{\\star}} \\,=\\, u_{\\mathrm{th}} \\,=\\, \\frac{\\lambda}{S(1+v)}.\n$$\n\n解出 $\\tau^{\\star}$ 可得\n\n$$\n\\tau^{\\star} \\,=\\, \\frac{1}{1 + \\dfrac{\\lambda}{S(1+v)}} \\,=\\, \\frac{S(1+v)}{S(1+v) + \\lambda}.\n$$\n\n\n该表达式是关于增量权重变异系数平方 $v$、估计量灵敏度 $S$ 和重采样惩罚 $\\lambda$ 的闭式形式，符合要求。对于 $S0$, $v \\ge 0$ 和 $\\lambda0$，它也满足 $\\tau^{\\star} \\in (0,1)$。",
            "answer": "$$\\boxed{\\frac{S(1+v)}{S(1+v)+\\lambda}}$$"
        }
    ]
}