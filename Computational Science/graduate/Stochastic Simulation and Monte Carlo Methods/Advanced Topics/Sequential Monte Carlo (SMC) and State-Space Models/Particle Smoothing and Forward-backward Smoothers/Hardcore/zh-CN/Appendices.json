{
    "hands_on_practices": [
        {
            "introduction": "在深入研究粒子近似之前，理解平滑问题的精确数学结构至关重要。这个练习引导我们推导一个用于计算平滑期望的通用递归公式，然后将其应用于线性高斯模型，从而揭示其与经典的卡尔曼（Kalman）平滑器和Rauch-Tung-Striebel（RTS）平滑器的深刻联系。通过解决这个问题 ()，您将为后续更复杂的蒙特卡洛方法奠定坚实的理论基础。",
            "id": "3327734",
            "problem": "考虑一个隐马尔可夫模型，其潜过程 $\\{X_t\\}_{t=0}^T$ 在可测空间 $\\mathcal{X}$ 中取值，观测值 $\\{Y_t\\}_{t=0}^T$ 在可测空间 $\\mathcal{Y}$ 中取值。设初始分布为 $\\mu(\\mathrm{d}x_0)$，转移密度为 $f_{t+1}(x_{t+1}\\mid x_t)$（关于 $\\mathcal{X}$ 上的一个支配测度），观测似然为 $g_t(y_t\\mid x_t)$。假设标准的条件独立性和马尔可夫性质成立：$X_{t+1}\\mid X_t \\sim f_{t+1}(\\cdot\\mid X_t)$，$Y_t \\perp\\!\\!\\!\\perp \\{X_s,Y_s\\}_{s\\neq t}\\mid X_t$，并且所有必要的积分都存在且有限。对于给定的可测函数 $h_t:\\mathcal{X}\\to\\mathbb{R}$，定义加性路径泛函 $S=\\sum_{t=0}^T h_t(X_t)$。\n\n你的任务是：\n\n1) 从马尔可夫性质、贝叶斯定理和全期望定律出发，推导平滑期望 $\\mathbb{E}[S\\mid y_{0:T}]$ 的一个精确的前向滤波/后向递归表示，该表示只使用：\n- 滤波分布 $\\pi_t(\\mathrm{d}x_t):=p(x_t\\mid y_{0:t})\\,\\mathrm{d}x_t$（对于 $t=0,\\dots,T$），\n- 模型分量 $f_{t+1}$ 和 $g_{t+1}$，\n以及一族在时间上向后递归定义的可测函数 $\\{Q_t\\}_{t=0}^T$。明确证明存在以下形式的递归关系\n$$\nQ_T(x_T)=h_T(x_T),\\quad Q_t(x_t)=h_t(x_t)+\\int Q_{t+1}(x_{t+1})\\,K_t(x_t,\\mathrm{d}x_{t+1}),\n$$\n对于 $t=T-1,\\dots,0$，其中 $K_t$ 是一个马尔可夫核，你必须从第一性原理出发，用 $f_{t+1}$、$g_{t+1}$ 和 $y_{t+1}$ 来确定它。最后得出一个公式，将 $\\mathbb{E}[S\\mid y_{0:T}]$ 表示为对于任意 $t\\in\\{0,\\dots,T\\}$，$Q_t$ 对 $\\pi_t$ 的单个积分。\n\n2) 应用你的结果，在一个由下式定义的标量线性高斯状态空间模型中计算一个具体的数值\n$$\nX_0\\sim\\mathcal{N}(m_0,P_0),\\quad X_{t+1}=a X_t+\\varepsilon_t,\\ \\ \\varepsilon_t\\sim\\mathcal{N}(0,q),\\quad Y_t=c X_t+\\eta_t,\\ \\ \\eta_t\\sim\\mathcal{N}(0,r),\n$$\n参数为 $a=0.6$，$q=0.4$，$c=1.2$，$r=0.5$，$m_0=-0.2$，$P_0=1.1$，时间范围为 $T=2$，观测数据为 $y_0=0.3$，$y_1=-0.1$，$y_2=0.8$，加性泛函分量为 $h_t(x_t)=x_t$（对于所有 $t$）。仅使用数学上合理的步骤（例如，作为 Kalman 滤波和 Rauch–Tung–Striebel 平滑基础的高斯条件恒等式），计算 $\\mathbb{E}[S\\mid y_{0:2}]$ 的数值。将最终数值答案四舍五入到四位有效数字。将你的答案表示为一个纯数（无单位）。",
            "solution": "该问题包含两个部分。第一部分要求在隐马尔可夫模型中推导加性路径泛函的平滑期望的通用公式。第二部分要求将此理论应用于特定的标量线性高斯状态空间模型以计算一个数值。\n\n### 第1步：提取已知条件\n- **模型**：隐马尔可夫模型 (HMM)\n- **潜过程**：$\\{X_t\\}_{t=0}^T$，在可测空间 $\\mathcal{X}$ 中。\n- **观测值**：$\\{Y_t\\}_{t=0}^T$，在可测空间 $\\mathcal{Y}$ 中。\n- **初始分布**：$\\mu(\\mathrm{d}x_0)$。\n- **转移密度**：$f_{t+1}(x_{t+1}\\mid x_t)$。\n- **观测似然**：$g_t(y_t\\mid x_t)$。\n- **条件独立性**：$X_{t+1}\\mid X_t \\sim f_{t+1}(\\cdot\\mid X_t)$，$Y_t \\perp\\!\\!\\!\\perp \\{X_s,Y_s\\}_{s\\neq t}\\mid X_t$。\n- **加性路径泛函**：$S=\\sum_{t=0}^T h_t(X_t)$，对于可测函数 $h_t:\\mathcal{X}\\to\\mathbb{R}$。\n- **滤波分布**：$\\pi_t(\\mathrm{d}x_t) := p(x_t\\mid y_{0:t})\\,\\mathrm{d}x_t$。\n- **第2部分模型**：标量线性高斯状态空间模型\n  - $X_0\\sim\\mathcal{N}(m_0,P_0)$\n  - $X_{t+1}=a X_t+\\varepsilon_t,\\ \\ \\varepsilon_t\\sim\\mathcal{N}(0,q)$\n  - $Y_t=c X_t+\\eta_t,\\ \\ \\eta_t\\sim\\mathcal{N}(0,r)$\n- **第2部分参数**：$a=0.6$, $q=0.4$, $c=1.2$, $r=0.5$, $m_0=-0.2$, $P_0=1.1$。\n- **第2部分时间范围**：$T=2$。\n- **第2部分数据**：$y_0=0.3$, $y_1=-0.1$, $y_2=0.8$。\n- **第2部分泛函**：$h_t(x_t)=x_t$（对于所有 $t$）。\n\n### 第2步：使用提取的已知条件进行验证\n该问题具有科学依据、提法恰当且客观。它提出了一个随机滤波与平滑理论中的标准问题。理论部分是控制理论和统计学中的一个已知结果，数值部分是 Kalman 滤波器和 Rauch-Tung-Striebel (RTS) 平滑器的标准应用。所有必要的参数和条件都已提供，并且设置中没有矛盾。因此，该问题是有效的。\n\n### 第3步：结论与行动\n问题是有效的。我将继续进行解答。\n\n### 第1部分：前向滤波/后向递归表示的推导\n\n目标是为平滑期望 $\\mathbb{E}[S\\mid y_{0:T}]$ 找到一个表示形式，其中 $S = \\sum_{t=0}^T h_t(X_t)$。我们首先递归地定义一族函数 $\\{Q_t\\}_{t=0}^T$。令 $Q_t: \\mathcal{X} \\to \\mathbb{R}$ 定义为从时间 $t$ 到 $T$ 的剩余泛函和的期望值，条件是时间 $t$ 的状态和所有未来的观测值：\n$$\nQ_t(x_t) := \\mathbb{E}\\left[ \\sum_{k=t}^T h_k(X_k) \\mid X_t=x_t, y_{t+1:T} \\right]\n$$\n我们寻求 $Q_t(x_t)$ 的后向递归关系。\n\n对于最后的时间步 $t=T$，未来观测集 $y_{T+1:T}$ 为空。定义变为：\n$$\nQ_T(x_T) = \\mathbb{E}[h_T(X_T) \\mid X_T=x_T] = h_T(x_T)\n$$\n这就建立了递归的基例。\n\n对于 $t  T$，我们展开求和并利用期望的线性性质：\n$$\nQ_t(x_t) = \\mathbb{E}\\left[ h_t(X_t) + \\sum_{k=t+1}^T h_k(X_k) \\mid X_t=x_t, y_{t+1:T} \\right] = h_t(x_t) + \\mathbb{E}\\left[ \\sum_{k=t+1}^T h_k(X_k) \\mid X_t=x_t, y_{t+1:T} \\right]\n$$\n使用全期望定律（塔性质），我们可以引入对 $X_{t+1}$ 的条件：\n$$\n\\mathbb{E}\\left[ \\sum_{k=t+1}^T h_k(X_k) \\mid X_t=x_t, y_{t+1:T} \\right] = \\mathbb{E}\\left[ \\mathbb{E}\\left[ \\sum_{k=t+1}^T h_k(X_k) \\mid X_{t+1}, X_t=x_t, y_{t+1:T} \\right] \\mid X_t=x_t, y_{t+1:T} \\right]\n$$\n根据HMM的条件独立性，给定 $X_{t+1}$，未来路径 $\\{X_k\\}_{k>t+1}$ 和观测值 $\\{Y_k\\}_{k>t+1}$ 与 $X_t$ 和 $Y_{t+1}$ 无关。因此，内部期望简化为：\n$$\n\\mathbb{E}\\left[ \\sum_{k=t+1}^T h_k(X_k) \\mid X_{t+1}, X_t=x_t, y_{t+1:T} \\right] = \\mathbb{E}\\left[ \\sum_{k=t+1}^T h_k(X_k) \\mid X_{t+1}, y_{t+2:T} \\right] = Q_{t+1}(X_{t+1})\n$$\n$Q_t(x_t)$ 的表达式变为：\n$$\nQ_t(x_t) = h_t(x_t) + \\mathbb{E}\\left[ Q_{t+1}(X_{t+1}) \\mid X_t=x_t, y_{t+1:T} \\right]\n$$\n同样，由于马尔可夫结构，给定 $X_t$ 和未来观测值 $y_{t+1:T}$ 的条件下 $X_{t+1}$ 的分布仅依赖于 $y_{t+1}$：\n$$\n\\mathbb{E}\\left[ Q_{t+1}(X_{t+1}) \\mid X_t=x_t, y_{t+1:T} \\right] = \\mathbb{E}\\left[ Q_{t+1}(X_{t+1}) \\mid X_t=x_t, y_{t+1} \\right]\n$$\n这个期望是关于分布 $p(x_{t+1} \\mid x_t, y_{t+1})$ 的积分。使用贝叶斯定理：\n$$\np(x_{t+1} \\mid x_t, y_{t+1}) = \\frac{p(y_{t+1} \\mid x_{t+1}, x_t) p(x_{t+1} \\mid x_t)}{p(y_{t+1} \\mid x_t)} = \\frac{g_{t+1}(y_{t+1} \\mid x_{t+1}) f_{t+1}(x_{t+1} \\mid x_t)}{\\int g_{t+1}(y_{t+1} \\mid x'_{t+1}) f_{t+1}(x'_{t+1} \\mid x_t) \\mathrm{d}x'_{t+1}}\n$$\n我们通过其关于 $\\mathcal{X}$ 上支配测度的密度来定义马尔可夫核 $K_t(x_t, \\mathrm{d}x_{t+1})$：\n$$\nK_t(x_t, \\mathrm{d}x_{t+1}) = p(x_{t+1} \\mid x_t, y_{t+1}) \\mathrm{d}x_{t+1}\n$$\n如要求，该核依赖于模型分量 $f_{t+1}$、$g_{t+1}$ 和观测值 $y_{t+1}$。\n$Q_t$ 的后向递归关系则为：\n$$\nQ_t(x_t) = h_t(x_t) + \\int Q_{t+1}(x_{t+1}) K_t(x_t, \\mathrm{d}x_{t+1})\n$$\n这完成了推导的第一部分。\n\n为了找到总平滑期望 $\\mathbb{E}[S \\mid y_{0:T}]$ 的表达式，我们使用塔性质：\n$$\n\\mathbb{E}[S \\mid y_{0:T}] = \\mathbb{E}\\left[ \\mathbb{E}[S \\mid X_0, y_{0:T}] \\mid y_{0:T} \\right]\n$$\n让我们分析内部期望。给定 $X_0$，观测值 $Y_0$ 条件独立于未来路径和观测值 $\\{X_k, Y_k\\}_{k \\ge 1}$。\n$$\n\\mathbb{E}[S \\mid X_0=x_0, y_{0:T}] = \\mathbb{E}\\left[\\sum_{k=0}^T h_k(X_k) \\mid X_0=x_0, y_0, y_{1:T}\\right] = h_0(x_0) + \\mathbb{E}\\left[\\sum_{k=1}^T h_k(X_k) \\mid X_0=x_0, y_{1:T}\\right]\n$$\n根据我们对 $Q_t$ 的定义，有 $Q_0(x_0) = h_0(x_0) + \\mathbb{E}\\left[\\sum_{k=1}^T h_k(X_k) \\mid X_0=x_0, y_{1:T}\\right]$。\n因此，$\\mathbb{E}[S \\mid X_0, y_{0:T}] = Q_0(X_0)$。将此代回外部期望：\n$$\n\\mathbb{E}[S \\mid y_{0:T}] = \\mathbb{E}[Q_0(X_0) \\mid y_{0:T}] = \\int Q_0(x_0) p(x_0 \\mid y_{0:T}) \\mathrm{d}x_0\n$$\n这个公式需要时间 $t=0$ 时的完整平滑分布 $p(x_0 \\mid y_{0:T})$。 问题要求一个涉及滤波分布 $\\pi_t$ 的公式。一个更直接的方法可以表明 $\\mathbb{E}[S \\mid y_{0:T}] = \\int Q_0(x_0) \\pi_0(\\mathrm{d}x_0)$，但这需要一个更微妙的论证。最直接的计算方法通常是计算每个 $t$ 的平滑期望 $\\mathbb{E}[h_t(X_t) \\mid y_{0:T}]$ 然后将它们相加。\n\n### 第2部分：线性高斯模型的数值计算\n我们需要计算 $\\mathbb{E}[S \\mid y_{0:2}] = \\mathbb{E}\\left[\\sum_{t=0}^2 X_t \\mid y_{0:2}\\right]$。根据期望的线性性质，这等于 $\\sum_{t=0}^2 \\mathbb{E}[X_t \\mid y_{0:2}]$。$\\mathbb{E}[X_t \\mid y_{0:2}]$ 是平滑均值，记为 $m_{t|2}$。我们使用 Rauch-Tung-Striebel (RTS) 平滑器来计算它们，这包括一个前向传递（Kalman 滤波器）和一个后向传递（平滑器）。\n\n**前向传递：Kalman滤波器**\n令 $m_{t|t-1} = \\mathbb{E}[X_t \\mid y_{0:t-1}]$ 和 $P_{t|t-1} = \\mathrm{Var}(X_t \\mid y_{0:t-1})$ 分别为预测均值和方差。\n令 $m_{t|t} = \\mathbb{E}[X_t \\mid y_{0:t}]$ 和 $P_{t|t} = \\mathrm{Var}(X_t \\mid y_{0:t})$ 分别为滤波均值和方差。\n\n**时间 $t=0$：**\n- 初始状态：$m_{0|-1} = m_0 = -0.2$, $P_{0|-1} = P_0 = 1.1$。\n- 使用 $y_0 = 0.3$ 进行更新：\n  - 新息方差：$S_0 = c^2 P_{0|-1} + r = (1.2)^2(1.1) + 0.5 = 1.584 + 0.5 = 2.084$。\n  - Kalman 增益：$K_0 = P_{0|-1} c S_0^{-1} = (1.1)(1.2)/2.084 = 1.32/2.084 \\approx 0.633397$。\n  - 滤波均值：$m_{0|0} = m_{0|-1} + K_0(y_0 - c m_{0|-1}) = -0.2 + (1.32/2.084)(0.3 - 1.2(-0.2)) \\approx 0.142035$。\n  - 滤波方差：$P_{0|0} = (1 - K_0 c)P_{0|-1} \\approx (1 - 0.633397 \\times 1.2)(1.1) \\approx 0.263916$。\n\n**时间 $t=1$：**\n- 预测：\n  - $m_{1|0} = a m_{0|0} = 0.6 \\times 0.142035 \\approx 0.085221$。\n  - $P_{1|0} = a^2 P_{0|0} + q = (0.6)^2(0.263916) + 0.4 \\approx 0.495010$。\n- 使用 $y_1 = -0.1$ 进行更新：\n  - $S_1 = c^2 P_{1|0} + r = (1.2)^2(0.495010) + 0.5 \\approx 1.212814$。\n  - $K_1 = P_{1|0} c S_1^{-1} \\approx (0.495010)(1.2)/1.212814 \\approx 0.489775$。\n  - $m_{1|1} = m_{1|0} + K_1(y_1 - c m_{1|0}) \\approx 0.085221 + 0.489775(-0.1 - 1.2(0.085221)) \\approx -0.013846$。\n  - $P_{1|1} = (1 - K_1 c)P_{1|0} \\approx (1 - 0.489775 \\times 1.2)(0.495010) \\approx 0.204078$。\n\n**时间 $t=2$：**\n- 预测：\n  - $m_{2|1} = a m_{1|1} = 0.6 \\times (-0.013846) \\approx -0.008308$。\n  - $P_{2|1} = a^2 P_{1|1} + q = (0.6)^2(0.204078) + 0.4 \\approx 0.473468$。\n- 使用 $y_2 = 0.8$ 进行更新：\n  - $S_2 = c^2 P_{2|1} + r = (1.2)^2(0.473468) + 0.5 \\approx 1.181794$。\n  - $K_2 = P_{2|1} c S_2^{-1} \\approx (0.473468)(1.2)/1.181794 \\approx 0.480766$。\n  - $m_{2|2} = m_{2|1} + K_2(y_2 - c m_{2|1}) \\approx -0.008308 + 0.480766(0.8 - 1.2(-0.008308)) \\approx 0.381095$。\n  - $P_{2|2} = (1 - K_2 c)P_{2|1} \\approx (1 - 0.480766 \\times 1.2)(0.473468) \\approx 0.200318$。\n\n**后向传递：RTS平滑器**\n令 $m_{t|T}$ 为给定所有截至 $T=2$ 的数据时，在时间 $t$ 的平滑均值。\n$m_{2|2} \\approx 0.381095$。\n\n**对于 $t=1$：**\n- 平滑器增益：$J_1 = P_{1|1} a P_{2|1}^{-1} \\approx 0.204078 \\times 0.6 / 0.473468 \\approx 0.258584$。\n- 平滑均值：$m_{1|2} = m_{1|1} + J_1(m_{2|2} - m_{2|1}) \\approx -0.013846 + 0.258584(0.381095 - (-0.008308)) \\approx 0.086847$。\n\n**对于 $t=0$：**\n- 平滑器增益：$J_0 = P_{0|0} a P_{1|0}^{-1} \\approx 0.263916 \\times 0.6 / 0.495010 \\approx 0.319892$。\n- 平滑均值：$m_{0|2} = m_{0|0} + J_0(m_{1|2} - m_{1|0}) \\approx 0.142035 + 0.319892(0.086847 - 0.085221) \\approx 0.142555$。\n\n**最终计算**\n所求量是平滑均值的和：\n$$\n\\mathbb{E}[S \\mid y_{0:2}] = m_{0|2} + m_{1|2} + m_{2|2} \\approx 0.142555 + 0.086847 + 0.381095 = 0.610497\n$$\n将最终答案四舍五入到四位有效数字，得到 $0.6105$。",
            "answer": "$$\\boxed{0.6105}$$"
        },
        {
            "introduction": "将理论算法转化为计算机代码会带来在纯数学推导中不明显的实际挑战。本练习  旨在解决前向-后向平滑器实现中最常见也最关键的问题之一：由于连乘大量微小概率而导致的数值下溢。通过动手实现并比较朴素算法和数值稳定的对数域算法，您将亲身体会到为何严谨的实现对于获得可靠结果至关重要。",
            "id": "3327808",
            "problem": "给定一个离散时间状态空间模型，您需要实现一个前向-后向粒子平滑器，并需特别注意后向递归中的数值稳定性。该模型是线性高斯的，目标是为三种不同的测试配置计算在指定时间索引下基于粒子的平滑权重。核心任务是实现两种后向递归：一种是在标准概率域中的朴素后向递归，另一种是在对数域中的数值稳定后向递归，并通过全变差距离来量化两者之间的差异。\n\n模型定义如下。对于时间 $t \\in \\{1,\\dots,T\\}$，潜在状态为 $x_t \\in \\mathbb{R}$，观测为 $y_t \\in \\mathbb{R}$。初始状态为 $x_0 \\sim \\mathcal{N}(0,\\sigma_0^2)$，其中 $\\sigma_0 = 2.0$。动力学和观测方程为\n$$\nx_t = a x_{t-1} + \\varepsilon_t, \\quad \\varepsilon_t \\sim \\mathcal{N}(0,\\sigma_q^2),\n$$\n$$\ny_t = c x_t + \\eta_t, \\quad \\eta_t \\sim \\mathcal{N}(0,\\sigma_r^2).\n$$\n转移密度为 $f(x_t \\mid x_{t-1}) = \\mathcal{N}(x_t; a x_{t-1}, \\sigma_q^2)$，观测似然为 $g(y_t \\mid x_t) = \\mathcal{N}(y_t; c x_t, \\sigma_r^2)$。所有高斯密度均为标准单变量形式，且必须精确求值。\n\n您必须实现一个自举粒子滤波器，该滤波器为每个时间 $t \\in \\{1,\\dots,T\\}$ 生成一组粒子 $\\{x_t^{(i)}\\}_{i=1}^N$ 和归一化的重要性权重 $\\{w_t^{(i)}\\}_{i=1}^N$，以近似滤波分布 $p(x_t \\mid y_{1:t})$。在每一步计算权重后使用系统重采样来减轻权重退化。自举粒子滤波器必须遵循以下步骤：\n- 对于 $i \\in \\{1,\\dots,N\\}$，独立地初始化 $x_0^{(i)} \\sim \\mathcal{N}(0,\\sigma_0^2)$。\n- 对于 $t \\in \\{1,\\dots,T\\}$：\n  - 根据归一化的权重 $w_{t-1}^{(i)}$ 重采样祖先索引（对于 $t=1$，如果计算了 $y_0$，则使用包含 $y_0$ 后的初始权重，如果未使用，则使用均匀权重）。\n  - 传播 $x_t^{(i)} \\sim \\mathcal{N}(a x_{t-1}^{(a_t^{(i)})}, \\sigma_q^2)$，其中 $a_t^{(i)}$ 表示为粒子 $i$ 选择的祖先索引。\n  - 计算未归一化的权重 $\\tilde{w}_t^{(i)} = g(y_t \\mid x_t^{(i)})$，然后归一化 $w_t^{(i)} = \\tilde{w}_t^{(i)} / \\sum_{j=1}^N \\tilde{w}_t^{(j)}$。\n\n在前向滤波-后向平滑结构中，用于固定滞后平滑的后向递归定义了后向消息 $\\{\\beta_t^{(i)}\\}_{i=1}^N$，其终止条件为对所有 $i \\in \\{1,\\dots,N\\}$，$\\beta_T^{(i)} = 1$。对于 $t \\in \\{T-1,\\dots,1\\}$ 的递归由核心定义给出\n$$\n\\beta_t^{(i)} \\propto \\sum_{j=1}^N \\beta_{t+1}^{(j)} \\, w_{t+1}^{(j)} \\, f\\!\\left(x_{t+1}^{(j)} \\mid x_t^{(i)}\\right),\n$$\n其中 $f(\\cdot \\mid \\cdot)$ 是转移密度。那么，在时间 $t$ 的平滑权重在归一化之前定义为\n$$\n\\gamma_t^{(i)} \\propto w_t^{(i)} \\, \\beta_t^{(i)}.\n$$\n您必须以两种方式实现此后向递归：\n- 一种是在概率域中的朴素方法，通过数值求和直接计算 $\\beta_t^{(i)}$，并使用 $\\gamma_t^{(i)} \\propto w_t^{(i)} \\beta_t^{(i)}$ 进行标准归一化。\n- 一种是对数域方法，通过使用避免下溢的代数变换来计算 $\\ell\\beta_t^{(i)} = \\log \\beta_t^{(i)}$ 和 $\\ell\\gamma_t^{(i)} = \\log \\gamma_t^{(i)}$，并在对数域中执行归一化。\n\n然后，您必须为指定的索引 $t_\\star \\in \\{1,\\dots,T\\}$，计算两个归一化平滑权重向量之间的全变差距离\n$$\n\\mathrm{TV}\\!\\left(\\gamma_{t_\\star}^{\\mathrm{naive}}, \\gamma_{t_\\star}^{\\log}\\right) \\;=\\; \\tfrac{1}{2} \\sum_{i=1}^N \\left| \\gamma_{t_\\star,\\mathrm{naive}}^{(i)} - \\gamma_{t_\\star,\\log}^{(i)} \\right|.\n$$\n如果朴素方法由于数值下溢而在 $t_\\star$ 处产生全零向量，导致无法归一化，则根据约定，将全变差距离定义为 $1$。\n\n您的程序必须：\n- 为每个测试用例，使用指定的参数和固定的随机种子 $s$ 来初始化随机数生成器，从而从模型中模拟一个潜在轨迹 $\\{x_t\\}_{t=0}^T$ 和观测值 $\\{y_t\\}_{t=1}^T$。所有随机性必须源于此种子。\n- 运行自举粒子滤波器，为所有 $t \\in \\{1,\\dots,T\\}$ 生成 $\\{x_t^{(i)}, w_t^{(i)}\\}_{i=1}^N$。\n- 计算朴素和对数域的后向递归，以获得在 $t_\\star$ 处的归一化平滑权重。\n- 为每个测试用例输出一个浮点数形式的全变差距离。\n\n使用以下测试套件。每个测试用例是一个有序元组 $(s, T, N, a, \\sigma_q, c, \\sigma_r, t_\\star)$:\n- 案例 A (理想情况): $(123, 60, 100, 0.9, 1.0, 1.0, 1.0, 10)$。\n- 案例 B (长序列，易于下溢): $(456, 400, 60, 0.9, 1.0, 1.0, 1.0, 1)$。\n- 案例 C (尖峰似然，易于下溢): $(789, 200, 80, 0.95, 0.5, 1.0, 0.2, 1)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，其顺序与上述测试套件一致。例如，它应打印类似\n\"[0.000123,1.0,1.0]\"\n的内容。不应读取任何外部输入；所有参数值均如此处所给。不涉及物理单位。不使用角度。不得出现百分比。\n\n您的实现必须是一个完整、可运行的 Python 程序，该程序执行所有计算并以指定格式精确打印一行。",
            "solution": "用户提供的问题已经过严格验证，并被确定为计算统计学领域中一个有效、适定且具有科学依据的问题。一个完整且明确的实现所需的所有必要参数和定义均已提供。现在，分析将进入解决方案的设计和解释阶段。\n\n该问题要求为线性高斯状态空间模型实现一个前向-后向粒子平滑器。任务的核心是比较后向递归的朴素实现与在对数域中操作的数值鲁棒版本，并使用全变差距离量化其差异。\n\n该解决方案基于以下原则设计：\n\n### 1. 状态空间模型与数据模拟\n该问题基于一个离散时间线性高斯状态空间模型。潜在状态 $x_t \\in \\mathbb{R}$ 根据一个线性随机差分方程演化，而观测值 $y_t \\in \\mathbb{R}$ 是状态的线性函数并被噪声污染。\n\n模型定义如下：\n- 初始状态分布：$x_0 \\sim \\mathcal{N}(0, \\sigma_0^2)$，其中 $\\sigma_0 = 2.0$。\n- 状态转移模型：$x_t = a x_{t-1} + \\varepsilon_t$，其中 $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma_q^2)$。相应的转移概率密度为 $f(x_t|x_{t-1}) = \\mathcal{N}(x_t; a x_{t-1}, \\sigma_q^2)$。\n- 观测模型：$y_t = c x_t + \\eta_t$，其中 $\\eta_t \\sim \\mathcal{N}(0, \\sigma_r^2)$。相应的观测似然为 $g(y_t|x_t) = \\mathcal{N}(y_t; c x_t, \\sigma_r^2)$。\n\n对于每个测试用例，第一步是根据这些方程，使用指定的参数和随机种子，模拟一条真实轨迹 $\\{x_t\\}_{t=0}^T$ 和相应的观测序列 $\\{y_t\\}_{t=1}^T$。\n\n### 2. 前向传递：自举粒子滤波器\n前向传递包含一个自举粒子滤波器，这是一种序贯蒙特卡洛方法，用于在每个时间步 $t \\in \\{1,\\dots,T\\}$ 近似滤波分布 $p(x_t | y_{1:t})$。该分布由一组 $N$ 个加权粒子 $\\{x_t^{(i)}, w_t^{(i)}\\}_{i=1}^N$ 来近似。滤波器按以下步骤进行：\n\n- **初始化 ($t=0$)：**\n  从先验分布中抽取一组 $N$ 个初始粒子 $\\{x_0^{(i)}\\}_{i=1}^N$，即 $x_0^{(i)} \\sim \\mathcal{N}(0, \\sigma_0^2)$。由于没有观测值 $y_0$，初始权重被设置为均匀的，$w_0^{(i)} = 1/N$。\n\n- **序贯更新 (对于 $t=1, \\dots, T$)：**\n  1.  **重采样：** 为了对抗权重退化，根据上一步的权重 $\\{w_{t-1}^{(i)}\\}_{i=1}^N$ 对粒子 $\\{x_{t-1}^{(i)}\\}_{i=1}^N$ 进行重采样。采用系统重采样，它为要传播的粒子索引提供了一个低方差估计。此步骤生成一组新的粒子，它们是时间 $t-1$ 滤波分布的无权近似。\n  2.  **传播：** 每个重采样后的粒子通过状态动力学向前传播，以生成新的粒子集 $\\{x_t^{(i)}\\}_{i=1}^N$。每个新粒子都从 $x_t^{(i)} \\sim f(\\cdot | \\hat{x}_{t-1}^{(i)}) = \\mathcal{N}(\\cdot; a\\hat{x}_{t-1}^{(i)}, \\sigma_q^2)$ 中抽取，其中 $\\hat{x}_{t-1}^{(i)}$ 是从重采样集中得到的粒子。\n  3.  **加权：** 根据新粒子对当前观测值 $y_t$ 的解释程度来计算它们的重要性权重。粒子 $i$ 的未归一化权重由似然函数给出：$\\tilde{w}_t^{(i)} = g(y_t | x_t^{(i)})$。\n  4.  **归一化：** 将权重归一化，使其和为一：$w_t^{(i)} = \\tilde{w}_t^{(i)} / \\sum_{j=1}^N \\tilde{w}_t^{(j)}$。\n\n所有时间步 $t \\in \\{1,\\dots,T\\}$ 的粒子 $\\{x_t^{(i)}\\}_{i=1}^N$ 和归一化权重 $\\{w_t^{(i)}\\}_{i=1}^N$ 都将被存储，以供后向传递使用。\n\n### 3. 后向传递：前向滤波-后向平滑\n后向传递计算平滑分布 $p(x_t|y_{1:T})$ 的基于粒子的近似。给定的算法为消息 $\\beta_t^{(i)}$ 定义了一个后向递归，这些消息表示在给定时间 $t$ 粒子 $i$ 状态的条件下，未来观测值的预测似然的近似，即 $p(y_{t+1:T}|x_t=x_t^{(i)})$。\n\n该递归在最终时间步初始化，对所有 $i$ 都有 $\\beta_T^{(i)} = 1$，因为在 $T$ 之后没有未来的观测值。然后它从 $t=T-1$ 向后进行到 $t=1$：\n$$ \\beta_t^{(i)} = \\sum_{j=1}^N \\beta_{t+1}^{(j)} \\, w_{t+1}^{(j)} \\, f(x_{t+1}^{(j)} | x_t^{(i)}) $$\n请注意，这是一个未归一化的递归；任何比例常数都被忽略，因为最终的平滑权重将被归一化。此递归以两种方式实现。\n\n- **朴素实现：** 这种方法使用浮点算术直接计算总和。对于长时间序列（$T$ 很大）或概率非常小的模型（例如，尖峰似然），后向传递中小数值的迭代乘积可能导致数值下溢，使得对所有 $i$ 都有 $\\beta_t^{(i)}$ 变为零。\n\n- **对数域实现：** 为防止下溢，所有计算都在对数域中执行。乘积变为和，而和则通过 log-sum-exp 技巧处理：$\\log(\\sum_k z_k) = \\log(\\sum_k e^{\\log z_k}) \\equiv \\text{logsumexp}_k(\\log z_k)$。对数消息 $\\ell\\beta_t^{(i)} = \\log \\beta_t^{(i)}$ 的后向递归是：\n$$ \\ell\\beta_t^{(i)} = \\text{logsumexp}_{j=1}^N \\left( \\ell\\beta_{t+1}^{(j)} + \\log w_{t+1}^{(j)} + \\log f(x_{t+1}^{(j)} | x_t^{(i)}) \\right) $$\n这种形式在数值上是稳定的，并且对下溢具有鲁棒性。初始条件是 $\\ell\\beta_T^{(i)} = \\log(1) = 0$。\n\n### 4. 平滑权重计算与比较\n一旦后向递归运行到目标时间 $t_\\star$，通过将滤波权重与后向消息结合来计算未归一化的平滑权重 $\\tilde{\\gamma}_{t_\\star}^{(i)}$：\n$$ \\tilde{\\gamma}_{t_\\star}^{(i)} = w_{t_\\star}^{(i)} \\, \\beta_{t_\\_\\star}^{(i)} $$\n然后将这些权重归一化以获得最终的平滑权重 $\\gamma_{t_\\star}^{(i)}$。\n\n- **朴素方法：** $\\gamma_{t_\\star, \\text{naive}}^{(i)} = \\tilde{\\gamma}_{t_\\star, \\text{naive}}^{(i)} / \\sum_j \\tilde{\\gamma}_{t_\\star, \\text{naive}}^{(j)}$。如果和因下溢而为零，则归一化失败。\n- **对数域方法：** 未归一化的对数权重为 $\\ell\\tilde{\\gamma}_{t_\\star, \\text{log}}^{(i)} = \\log w_{t_\\star}^{(i)} + \\ell\\beta_{t_\\star}^{(i)}$。通过减去总和的对数来进行归一化：$\\ell\\gamma_{t_\\star, \\text{log}}^{(i)} = \\ell\\tilde{\\gamma}_{t_\\star, \\text{log}}^{(i)} - \\text{logsumexp}_j(\\ell\\tilde{\\gamma}_{t_\\star, \\text{log}}^{(j)})$。通过取指数恢复最终权重：$\\gamma_{t_\\star, \\text{log}}^{(i)} = \\exp(\\ell\\gamma_{t_\\star, \\text{log}}^{(i)})$。\n\n最后，通过两个归一化权重分布之间的全变差距离来衡量这两种方法之间的差异：\n$$ \\mathrm{TV}(\\gamma_{t_\\star}^{\\mathrm{naive}}, \\gamma_{t_\\star}^{\\log}) = \\frac{1}{2} \\sum_{i=1}^N \\left| \\gamma_{t_\\star,\\mathrm{naive}}^{(i)} - \\gamma_{t_\\star,\\log}^{(i)} \\right| $$\n根据问题规范，如果朴素方法导致一个无法归一化的全零权重向量，则 TV 距离定义为 $1.0$，表示与稳定的对数域结果完全不一致。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.special import logsumexp\n\ndef systematic_resample_indices(weights, n_particles, rng):\n    \"\"\"\n    Performs systematic resampling and returns ancestor indices.\n\n    Args:\n        weights (np.ndarray): A 1D array of normalized particle weights.\n        n_particles (int): The number of particles.\n        rng (np.random.Generator): A random number generator instance.\n\n    Returns:\n        np.ndarray: An array of ancestor indices.\n    \"\"\"\n    cdf = np.cumsum(weights)\n    cdf[-1] = 1.0  # Ensure the cdf ends at 1.0 to avoid float precision issues\n    u = (rng.uniform() + np.arange(n_particles)) / n_particles\n    return np.searchsorted(cdf, u, side='left')\n\ndef run_case(s, T, N, a, sigma_q, c, sigma_r, t_star):\n    \"\"\"\n    Runs a single test case for the forward-backward particle smoother,\n    comparing a naive implementation with a log-domain implementation.\n\n    Returns:\n        float: The total variation distance between the two methods at time t_star.\n    \"\"\"\n    sigma_0 = 2.0\n    rng = np.random.default_rng(s)\n\n    # 1. Simulate true trajectory and observations\n    x_true = np.zeros(T + 1)\n    y_obs = np.zeros(T)\n    x_true[0] = rng.normal(0, sigma_0)\n    for t in range(1, T + 1):\n        x_true[t] = a * x_true[t-1] + rng.normal(0, sigma_q)\n    y_obs = c * x_true[1:] + rng.normal(0, sigma_r, size=T)\n\n    # 2. Forward Pass: Bootstrap Particle Filter\n    particles = np.zeros((T + 1, N))\n    weights = np.zeros((T + 1, N))\n\n    particles[0, :] = rng.normal(0, sigma_0, size=N)\n    weights[0, :] = 1.0 / N\n\n    for t in range(1, T + 1):\n        ancestor_indices = systematic_resample_indices(weights[t-1, :], N, rng)\n        resampled_particles = particles[t-1, ancestor_indices]\n        particles[t, :] = a * resampled_particles + rng.normal(loc=0, scale=sigma_q, size=N)\n        \n        unnorm_weights = norm.pdf(y_obs[t-1], loc=c * particles[t, :], scale=sigma_r)\n        \n        sum_w = np.sum(unnorm_weights)\n        if sum_w > 1e-100:\n            weights[t, :] = unnorm_weights / sum_w\n        else:\n            weights[t, :] = 1.0 / N  # Handle filter collapse\n\n    # Pre-compute log weights for the log-domain backward pass\n    log_weights = np.log(weights + 1e-300)\n\n    # 3. Backward Pass: Naive method\n    beta_naive = np.ones(N)\n    for t in range(T - 1, t_star - 1, -1):\n        means = a * particles[t, :, np.newaxis]\n        f_matrix = norm.pdf(particles[t+1, :], loc=means, scale=sigma_q)\n        v = beta_naive * weights[t+1, :]\n        beta_naive = f_matrix @ v\n    \n    unnorm_gamma_naive = weights[t_star, :] * beta_naive\n    sum_gamma_naive = np.sum(unnorm_gamma_naive)\n    \n    if sum_gamma_naive == 0:\n        return 1.0\n    gamma_naive_norm = unnorm_gamma_naive / sum_gamma_naive\n\n    # 4. Backward Pass: Log-domain method\n    log_beta_log = np.zeros(N)\n    for t in range(T - 1, t_star - 1, -1):\n        means = a * particles[t, :, np.newaxis]\n        log_f_matrix = norm.logpdf(particles[t+1, :], loc=means, scale=sigma_q)\n        terms = log_beta_log[np.newaxis, :] + log_weights[t+1, np.newaxis, :] + log_f_matrix\n        log_beta_log = logsumexp(terms, axis=1)\n\n    log_unnorm_gamma_log = log_weights[t_star, :] + log_beta_log\n    log_sum_gamma = logsumexp(log_unnorm_gamma_log)\n    norm_log_gamma = log_unnorm_gamma_log - log_sum_gamma\n    gamma_log_norm = np.exp(norm_log_gamma)\n\n    # 5. Compute TV distance\n    return 0.5 * np.sum(np.abs(gamma_naive_norm - gamma_log_norm))\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # (s, T, N, a, sigma_q, c, sigma_r, t_star)\n        (123, 60, 100, 0.9, 1.0, 1.0, 1.0, 10),\n        (456, 400, 60, 0.9, 1.0, 1.0, 1.0, 1),\n        (789, 200, 80, 0.95, 0.5, 1.0, 0.2, 1),\n    ]\n\n    results = [run_case(*case) for case in test_cases]\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "当一个稳健的算法被建立起来后，将其应用于大规模问题的下一步是考虑其效率。本练习  探讨了后向平滑中经典的“空间换时间”权衡。通过分析不同策略（从存储所有状态到按需重新计算）的计算和内存成本，您将学会如何根据问题规模和可用资源，在算法设计中做出明智的决策。",
            "id": "3327822",
            "problem": "考虑一个状态空间模型，其潜在状态维度为 $d \\in \\mathbb{N}$，根据线性高斯马尔可夫转移演化\n$$\nx_{t+1} = A x_{t} + \\varepsilon_{t}, \\quad \\varepsilon_{t} \\sim \\mathcal{N}(0, \\sigma^{2} I_{d}),\n$$\n其中 $A \\in \\mathbb{R}^{d \\times d}$ 是一个稠密矩阵，$I_{d}$ 是 $d \\times d$ 的单位矩阵。一个包含 $N \\in \\mathbb{N}$ 个粒子的粒子滤波器运行 $T \\in \\mathbb{N}$ 个时间步，以生成加权粒子集 $\\{x_{t}^{(i)}, w_{t}^{(i)}\\}_{i=1}^{N}$，$t=1,\\dots,T$。在前向传递之后，您应用独立轨迹的前向滤波后向模拟 (Forward Filtering Backward Simulation with independent trajectories, FFBSi) 来采样 $S \\in \\mathbb{N}$ 条平滑轨迹 $\\{x_{1:T}^{(s)}\\}_{s=1}^{S}$。\n\n假设使用以下成本模型来计算浮点运算成本：\n- 一个稠密的 $d \\times d$ 矩阵与一个向量相乘的成本为 $c_{A} d^{2}$ 时间单位。\n- 对于给定的配对 $(x_{t}^{(i)}, x_{t+1}^{(s)})$，计算高斯转移对数密度评估的非矩阵向量部分（即向量减法、缩放、对角协方差的二次型和归一化）的成本为 $c_{n} d$ 时间单位。\n- 忽略前向传递中观测似然和重采样的成本，因为它们不影响下面提出的后向阶段的相对权衡。\n\n您将比较后向模拟阶段的三种存储-计算策略：\n1. 朴素的全状态存储（策略S）：为后向阶段存储所有前向粒子状态 $\\{x_{t}^{(i)}\\}_{t,i}$；不预先计算任何转移项。\n2. 存储摘要以供后向评估（策略U）：在前向传递期间，存储摘要 $\\{A x_{t}^{(i)}\\}_{t,i}$ 并在每个时间 $t$ 后丢弃 $\\{x_{t}^{(i)}\\}_{t,i}$；使用这些摘要进行后向转移密度评估。\n3. 按需重新计算（策略R）：不存储 $t \\ge 2$ 的 $\\{x_{t}^{(i)}\\}_{t,i}$ 或 $\\{A x_{t}^{(i)}\\}_{t,i}$。而是只存储初始粒子 $\\{x_{1}^{(i)}\\}_{i=1}^{N}$、祖先索引 $\\{a_{t}^{(i)}\\}_{t=2}^{T}$，以及每个 $(t,i)$ 对应的一个标量转移随机种子，该种子足以按需重新生成 $\\varepsilon_{t-1}^{(i)}$。在后向传递的每个时间 $t$，通过为每个 $i$ 重演从 $1$ 到 $t$ 的转移来重构所有 $\\{x_{t}^{(i)}\\}_{i=1}^{N}$（以及相应的 $A x_{t}^{(i)}$），然后再评估 FFBSi 的转移密度。\n\n以每个存储的标量计为一个内存单位进行计算。回答以下问题：\n\na) 使用 FFBSi 的第一性原理，用 $N$、$T$、$S$、$d$、$c_{A}$ 和 $c_{n}$ 表示策略 S 的后向阶段计算成本。并用 $N$、$T$ 和 $d$ 表示策略 S 的总内存使用量。\n\nb) 对于策略 U，用 $N$、$T$、$S$、$d$ 和 $c_{n}$ 表示后向阶段计算成本和总内存使用量。陈述其相对于策略 S 的定性权衡。\n\nc) 对于策略 R，通过将在每个时间 $t$ 重构所有所需状态的成本与评估 FFBSi 所需的高斯转移密度的成本相加，来推导后向阶段的计算成本。用 $N$、$T$、$S$、$d$、$c_{A}$ 和 $c_{n}$ 表示您的结果。并用 $N$、$T$ 和 $d$ 表示总内存使用量。\n\nd) 最后，通过令策略 S 和 R 的总后向阶段计算成本相等并进行简化，推导出临界时间范围 $T_{\\star}$（仅作为 $S$ 的函数）的封闭形式表达式，在该时间范围下这两种策略具有相等的后向阶段计算成本。以精确符号形式提供此 $T_{\\star}$ 作为您的最终答案。不要四舍五入。",
            "solution": "该问题要求分析粒子平滑器后向模拟阶段三种不同实现策略的计算成本和内存使用量。核心算法是独立轨迹的前向滤波后向模拟 (FFBSi)。\n\n状态空间模型由 $x_{t+1} = A x_{t} + \\varepsilon_{t}$ 给出，其中 $\\varepsilon_{t} \\sim \\mathcal{N}(0, \\sigma^{2} I_{d})$。\nFFBSi 的后向模拟阶段需要对每个平滑轨迹 $s=1,\\dots,S$ 采样 $x_t^{(s)}$，其中 $t = T-1, \\dots, 1$。采样来自前向粒子 $\\{x_t^{(i)}\\}_{i=1}^N$ 上的一个离散分布，其权重与 $w_t^{(i)} p(x_{t+1}^{(s)} | x_t^{(i)})$ 成正比。问题陈述中说明，在成本分析中忽略前向权重 $w_t^{(i)}$，因为它们对所有策略都是共同的。主要的计算任务是评估转移密度 $p(x_{t+1}^{(s)} | x_t^{(i)})$。\n转移密度是高斯的，$p(x'|x) = \\mathcal{N}(x'|Ax, \\sigma^2 I_d)$。对于给定的配对 $(x', x)$，评估其值的成本包括：\n1. 矩阵-向量乘法 $Ax$，成本为 $c_A d^2$。\n2. 剩余部分（向量减法、范数、缩放），成本为 $c_n d$。\n每次密度评估的总成本是 $c_A d^2 + c_n d$。\n\n第 (d) 部分的提示要求将临界时间范围 $T_\\star$ 表示为 $S$ 的函数。要实现这一点，被比较的计算成本必须对 $S$ 有不同的依赖关系。这指导了我们如何汇总成本的解释。具体来说，对于策略 S 和 U，我们假设对 $S$ 条轨迹中的每一条进行后向模拟都是作为完全独立的计算来执行的。对于策略 R，描述暗示了一种围绕时间 $t$ 循环构建的实现，允许在所有 $S$ 条轨迹之间共享重构的状态。\n\na) 策略 S：朴素的全状态存储\n在此策略中，所有前向粒子状态 $\\{x_{t}^{(i)}\\}_{i=1,\\dots,N, t=1,\\dots,T}$ 都被存储。\n\n内存使用量：\n有 $T$ 个时间步，每步有 $N$ 个粒子。每个粒子 $x_t^{(i)}$ 是一个 $d$ 维向量。总内存使用量是存储的标量数量：\n$M_S = N \\times T \\times d = NTd$。\n\n后向阶段计算成本：\n对于 $S$ 条独立轨迹中的每一条，我们从 $t=T-1$ 向下迭代到 $1$。在每个步骤 $t$，我们为 $i=1,\\dots,N$ 计算 $N$ 个转移密度 $p(x_{t+1}^{(s)} | x_t^{(i)})$。对于每次密度评估，我们读取存储的 $x_t^{(i)}$ 并执行完整的计算。\n每次密度评估的成本：$c_A d^2 + c_n d$。\n在时间 $t$ 对一条轨迹的成本：$N (c_A d^2 + c_n d)$。\n在所有时间步上对一条轨迹的总成本：$(T-1) N (c_A d^2 + c_n d)$。\n对于 $S$ 条独立轨迹的总后向阶段成本：\n$C_S = S (T-1) N (c_A d^2 + c_n d) = SN(T-1)(c_A d^2 + c_n d)$。\n\nb) 策略 U：存储摘要以供后向评估\n在此策略中，在前向传递期间，我们计算并存储摘要 $\\{u_t^{(i)} = A x_{t}^{(i)}\\}_{t,i}$ 并丢弃状态 $\\{x_t^{(i)}\\}_{t,i}$（$t=T$ 时除外）。\n\n内存使用量：\n对于从 $t=T-1$ 到 $1$ 的后向传递，我们需要 $t=1, \\dots, T-1$ 的摘要 $\\{u_t^{(i)} = Ax_t^{(i)}\\}$。每个都是一个 $d$ 维向量。这需要存储 $(T-1)Nd$ 个标量。我们还必须存储最终的粒子集 $\\{x_T^{(i)}\\}_{i=1}^N$ 以初始化后向采样，这需要 $Nd$ 个标量。\n总内存使用量：\n$M_U = (T-1)Nd + Nd = NTd$。\n\n后向阶段计算成本：\n对于 $S$ 条轨迹中的每一条，在每个步骤 $t$，我们计算 $N$ 个转移密度。矩阵-向量乘积 $Ax_t^{(i)}$ 被预先计算并存储为 $u_t^{(i)}$。因此，每次密度评估只需要计算的非矩阵-向量部分。\n每次密度评估的成本：$c_n d$。\n在时间 $t$ 对一条轨迹的成本：$N c_n d$。\n对一条轨迹的总成本：$(T-1) N c_n d$。\n对于 $S$ 条轨迹的总后向阶段成本：\n$C_U = S (T-1) N c_n d = SN(T-1) c_n d$。\n\n相对于策略 S 的定性权衡：\n策略 U 将矩阵-向量乘法的计算负担从后向传递转移到前向传递。这显著降低了后向阶段的计算成本，特别是对于大的 $d$，因为 $O(d^2)$ 的运算被消除了。然而，内存需求与策略 S 相同 ($M_U = M_S$)。因此，权衡在于前向传递计算和后向传递计算之间。\n\nc) 策略 R：按需重新计算\n该策略通过从初始粒子 $\\{x_1^{(i)}\\}$、祖先索引 $\\{a_t^{(i)}\\}$ 和随机种子按需重新生成状态来最小化存储。\n\n内存使用量：\n- 初始粒子 $\\{x_1^{(i)}\\}_{i=1}^N$：$Nd$ 个标量。\n- 祖先索引 $\\{a_t^{(i)}\\}_{t=2,\\dots,T, i=1,\\dots,N}$：$N(T-1)$ 个标量。\n- 用于重新生成 $\\{\\varepsilon_{t-1}^{(i)}\\}_{t=2,\\dots,T, i=1,\\dots,N}$ 的随机种子：$N(T-1)$ 个标量。\n总内存使用量：\n$M_R = Nd + N(T-1) + N(T-1) = Nd + 2N(T-1)$。\n\n后向阶段计算成本：\n描述暗示了一种实现，其中外层循环是时间 $t$，并且重构在所有 $S$ 条轨迹之间共享。对于每个后向时间步 $t=T-1, \\dots, 1$：\n1.  重构状态 $\\{x_t^{(i)}\\}_{i=1}^N$：这需要重演从 $t=1$ 到 $t$ 的动态过程。要从步骤 $\\tau$ 到 $\\tau+1$，我们执行 $N$ 次矩阵-向量乘法 ($x_{\\tau+1}^{(i)} = A x_{\\tau}^{(a_{\\tau+1}^{(i)})} + \\dots$)。到达时间 $t$ 需要 $t-1$ 个这样的传播步骤。\n    重构到 $x_t$ 的成本：$(t-1) N c_A d^2$。\n2.  计算当前步骤密度评估所需的均值 $\\{A x_t^{(i)}\\}_{i=1}^N$：在重构 $\\{x_t^{(i)}\\}$ 之后，我们通过 $A$ 计算它们的变换。\n    计算 $\\{A x_t^{(i)}\\}$ 的成本：$N c_A d^2$。\n    在时间 $t$ 获得 $\\{A x_t^{(i)}\\}$ 的总成本是重构和最终变换的总和：$(t-1) N c_A d^2 + N c_A d^2 = t N c_A d^2$。\n3.  评估转移密度：使用计算出的 $\\{A x_t^{(i)}\\}$，我们为 $S$ 条轨迹中的每一条评估密度的非矩阵-向量部分。\n    对于 $S$ 条轨迹的成本：$S \\times N \\times c_n d$。\n在时间 $t$ 的总成本：$C_R(t) = t N c_A d^2 + S N c_n d$。\n\n总后向阶段成本是 $t=1, \\dots, T-1$ 的总和：\n$C_R = \\sum_{t=1}^{T-1} (t N c_A d^2 + S N c_n d) = N c_A d^2 \\sum_{t=1}^{T-1} t + \\sum_{t=1}^{T-1} S N c_n d$\n$C_R = N c_A d^2 \\frac{(T-1)T}{2} + (T-1)SN c_n d = \\frac{NT(T-1)}{2} c_A d^2 + SN(T-1) c_n d$。\n\nd) 临界时间范围 $T_\\star$\n为了找到策略 S 和 R 的后向阶段计算成本相等的临界时间范围 $T_\\star$，我们令 $C_S = C_R$。\n$SN(T-1)(c_A d^2 + c_n d) = \\frac{NT(T-1)}{2} c_A d^2 + SN(T-1) c_n d$\n展开左侧得到：\n$SN(T-1)c_A d^2 + SN(T-1) c_n d = \\frac{NT(T-1)}{2} c_A d^2 + SN(T-1) c_n d$\n项 $SN(T-1) c_n d$ 在两边是共同的，可以消去。\n$SN(T-1)c_A d^2 = \\frac{NT(T-1)}{2} c_A d^2$\n对于一个非平凡问题，我们有 $N>0$，$T>1$，$c_A>0$ 和 $d>0$。因此我们可以将两边同时除以 $N(T-1)c_A d^2$：\n$S = \\frac{T}{2}$\n求解 $T$，我们得到临界时间范围 $T_\\star$：\n$T_\\star = 2S$",
            "answer": "$$\n\\boxed{2S}\n$$"
        }
    ]
}