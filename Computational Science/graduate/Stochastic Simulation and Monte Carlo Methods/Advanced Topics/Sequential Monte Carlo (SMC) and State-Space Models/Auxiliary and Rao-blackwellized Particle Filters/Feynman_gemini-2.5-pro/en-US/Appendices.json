{
    "hands_on_practices": [
        {
            "introduction": "The primary motivation for the Auxiliary Particle Filter (APF) is the reduction of variance compared to simpler methods like the bootstrap filter. This first exercise goes to the heart of this issue by tasking you with a theoretical analysis of the APF's performance . By deriving the variance of the incremental normalizing constant estimator from first principles, you will gain a deep, quantitative understanding of how the choice of auxiliary weights and the resampling scheme interact to determine the filter's statistical efficiency. This foundational insight is crucial for designing and troubleshooting advanced sequential Monte Carlo algorithms.",
            "id": "3290186",
            "problem": "Consider a Feynman–Kac model specified by a Markov transition kernel $M_t(x_{t-1}, \\mathrm{d}x_t)$ that admits a density $\\ell_k(x) := \\ell(x \\mid x_{t-1}^k)$ with respect to a common reference measure, and a nonnegative potential function $G_t(x)$. At time $t-1$, assume a fixed weighted particle approximation $\\{x_{t-1}^k, \\bar{w}_{t-1}^k\\}_{k=1}^N$ with $\\sum_{k=1}^N \\bar{w}_{t-1}^k = 1$. Define the incremental normalizing constant\n$$\nc_t \\;=\\; \\sum_{k=1}^N \\bar{w}_{t-1}^k \\int G_t(x)\\,\\ell_k(x)\\,\\mathrm{d}x.\n$$\nAn Auxiliary Particle Filter (APF) uses adjustment multipliers $\\nu_k > 0$ to define ancestor selection probabilities\n$$\n\\pi_k \\;=\\; \\frac{\\bar{w}_{t-1}^k \\,\\nu_k}{\\sum_{j=1}^N \\bar{w}_{t-1}^j \\,\\nu_j}, \n\\qquad \nC \\;:=\\; \\sum_{j=1}^N \\bar{w}_{t-1}^j \\,\\nu_j,\n$$\nand, conditional on selecting ancestor index $K=k$, a proposal $q_k(\\mathrm{d}x)$ for $x_t$. The single-sample APF importance contribution is\n$$\nH_k(x) \\;:=\\; C \\,\\frac{G_t(x)\\,\\ell_k(x)}{\\nu_k\\,q_k(x)}.\n$$\nLet $\\{(K_i, X_i)\\}_{i=1}^N$ be generated by an unbiased resampling scheme $\\mathcal{R}$ for the ancestor indices with expected counts $\\mathbb{E}[N_k]=N\\pi_k$, where $N_k := \\sum_{i=1}^N \\mathbf{1}\\{K_i=k\\}$, followed by conditionally independent proposals $X_i \\sim q_{K_i}$. The APF estimator of $c_t$ is\n$$\n\\hat{c}_t \\;=\\; \\frac{1}{N}\\sum_{i=1}^N H_{K_i}(X_i).\n$$\n\nStarting from the definitions of importance sampling and the law of total variance, derive the conditional variance of $\\hat{c}_t$ given $\\{x_{t-1}^k, \\bar{w}_{t-1}^k\\}_{k=1}^N$ in the following form:\n- Express it in terms of the vector of per-ancestor conditional means $\\boldsymbol{\\mathfrak{m}} \\in \\mathbb{R}^N$ with entries $\\mathfrak{m}_k := \\mathbb{E}_{q_k}[H_k(X)]$, the per-ancestor conditional variances $v_k := \\mathrm{Var}_{q_k}[H_k(X)]$, and the covariance matrix of the ancestor count vector $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})$ induced by the resampling scheme $\\mathcal{R}$.\n- Then specialize your expression by substituting the explicit $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})$ for the following two schemes:\n  1. Multinomial resampling, for which $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) = N\\big(\\mathrm{Diag}(\\boldsymbol{\\pi}) - \\boldsymbol{\\pi}\\boldsymbol{\\pi}^{\\top}\\big)$.\n  2. Residual resampling, where $a_k := \\lfloor N\\pi_k \\rfloor$, $R := N - \\sum_{k=1}^N a_k$, $r_k := \\frac{N\\pi_k - a_k}{R}$ (for $R>0$), and $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) = R\\big(\\mathrm{Diag}(\\mathbf{r}) - \\mathbf{r}\\mathbf{r}^{\\top}\\big)$ with the convention $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})=\\mathbf{0}$ if $R=0$.\n\nFinally, using only the definitions above, identify conditions on the proposals $q_k$ and adjustment multipliers $\\nu_k$ under which this conditional variance is minimized, and state the minimal value. Your final answer must be a single closed-form analytic expression for the conditional variance in terms of $\\boldsymbol{\\pi}$, $\\{v_k\\}$, $\\boldsymbol{\\mathfrak{m}}$, and $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})$. Do not include units. If you introduce any additional symbols, define them explicitly in your derivation. Your final answer must be an analytic expression, not an inequality or an equation with unspecified terms.",
            "solution": "The problem requires the derivation of the conditional variance of the Auxiliary Particle Filter (APF) estimator $\\hat{c}_t$ for the incremental normalizing constant $c_t$, given the state of the system at time $t-1$, which is encapsulated by the particle set $\\{x_{t-1}^k, \\bar{w}_{t-1}^k\\}_{k=1}^N$. All expectations, variances, and covariances derived henceforth are conditional on this information.\n\nFirst, we establish the necessary definitions from the problem statement. The estimator for $c_t$ is given by\n$$\n\\hat{c}_t = \\frac{1}{N}\\sum_{i=1}^N H_{K_i}(X_i)\n$$\nwhere $\\{K_i\\}_{i=1}^N$ are the ancestor indices drawn via a resampling scheme $\\mathcal{R}$, and $X_i \\sim q_{K_i}$ are the proposed states. The randomness in $\\hat{c}_t$ arises from two sources: the random selection of ancestor indices $\\{K_i\\}$, and the random generation of the states $\\{X_i\\}$.\n\nTo analyze the variance, it is convenient to rewrite the estimator in terms of the ancestor count vector $\\mathbf{N} = (N_1, \\dots, N_N)^\\top$, where $N_k = \\sum_{i=1}^N \\mathbf{1}\\{K_i=k\\}$ is the number of times ancestor $k$ is chosen. The estimator becomes\n$$\n\\hat{c}_t = \\frac{1}{N} \\sum_{k=1}^N \\sum_{j=1}^{N_k} Y_j^{(k)}\n$$\nwhere each $Y_j^{(k)}$ is an independent draw of the random variable defined by $H_k(X)$ with $X \\sim q_k(\\cdot)$. The distribution of $Y_j^{(k)}$ depends only on the ancestor index $k$.\n\nWe apply the law of total variance, conditioning on the random count vector $\\mathbf{N}$:\n$$\n\\mathrm{Var}(\\hat{c}_t) = \\mathbb{E}_{\\mathbf{N}}[\\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N})] + \\mathrm{Var}_{\\mathbf{N}}(\\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}])\n$$\n\nLet's compute the two terms on the right-hand side.\n\n1.  **Inner Conditional Expectation and its Variance:**\n    We first compute the expectation of $\\hat{c}_t$ conditional on a realization of the count vector $\\mathbf{N}$.\n    $$\n    \\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}] = \\mathbb{E}\\left[ \\frac{1}{N} \\sum_{k=1}^N \\sum_{j=1}^{N_k} Y_j^{(k)} \\;\\Bigg|\\; \\mathbf{N} \\right]\n    $$\n    By linearity of expectation and since the draws $Y_j^{(k)}$ are independent given $\\mathbf{N}$,\n    $$\n    \\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}] = \\frac{1}{N} \\sum_{k=1}^N N_k \\, \\mathbb{E}[Y_j^{(k)}]\n    $$\n    The problem defines $\\mathfrak{m}_k := \\mathbb{E}_{q_k}[H_k(X)]$ as the per-ancestor conditional mean. Thus, $\\mathbb{E}[Y_j^{(k)}] = \\mathfrak{m}_k$.\n    $$\n    \\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}] = \\frac{1}{N} \\sum_{k=1}^N N_k \\mathfrak{m}_k = \\frac{1}{N} \\mathbf{N}^\\top \\boldsymbol{\\mathfrak{m}}\n    $$\n    where $\\boldsymbol{\\mathfrak{m}}$ is the column vector with entries $\\mathfrak{m}_k$. The second term of the law of total variance is the variance of this quantity with respect to the distribution of $\\mathbf{N}$ induced by the resampling scheme $\\mathcal{R}$:\n    $$\n    \\mathrm{Var}_{\\mathbf{N}}(\\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}]) = \\mathrm{Var}_{\\mathbf{N}}\\left( \\frac{1}{N} \\boldsymbol{\\mathfrak{m}}^\\top \\mathbf{N} \\right) = \\frac{1}{N^2} \\mathrm{Var}_{\\mathbf{N}}(\\boldsymbol{\\mathfrak{m}}^\\top \\mathbf{N})\n    $$\n    Using the general formula for the variance of a linear combination of a random vector, $\\mathrm{Var}(\\mathbf{A}^\\top \\mathbf{X}) = \\mathbf{A}^\\top \\mathrm{Cov}(\\mathbf{X}) \\mathbf{A}$, we get:\n    $$\n    \\mathrm{Var}_{\\mathbf{N}}(\\mathbb{E}[\\hat{c}_t \\mid \\mathbf{N}]) = \\frac{1}{N^2} \\boldsymbol{\\mathfrak{m}}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}}\n    $$\n\n2.  **Inner Conditional Variance and its Expectation:**\n    Next, we compute the variance of $\\hat{c}_t$ conditional on $\\mathbf{N}$.\n    $$\n    \\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N}) = \\mathrm{Var}\\left( \\frac{1}{N} \\sum_{k=1}^N \\sum_{j=1}^{N_k} Y_j^{(k)} \\;\\Bigg|\\; \\mathbf{N} \\right)\n    $$\n    Given $\\mathbf{N}$, the terms for different $k$ are independent, and for a fixed $k$, the terms $Y_j^{(k)}$ are i.i.d.\n    $$\n    \\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N}) = \\frac{1}{N^2} \\sum_{k=1}^N \\mathrm{Var}\\left( \\sum_{j=1}^{N_k} Y_j^{(k)} \\right) = \\frac{1}{N^2} \\sum_{k=1}^N N_k \\mathrm{Var}(Y_j^{(k)})\n    $$\n    The problem defines $v_k := \\mathrm{Var}_{q_k}[H_k(X)]$ as the per-ancestor conditional variance. Thus, $\\mathrm{Var}(Y_j^{(k)}) = v_k$.\n    $$\n    \\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N}) = \\frac{1}{N^2} \\sum_{k=1}^N N_k v_k\n    $$\n    The first term of the law of total variance is the expectation of this quantity:\n    $$\n    \\mathbb{E}_{\\mathbf{N}}[\\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N})] = \\mathbb{E}_{\\mathbf{N}}\\left[ \\frac{1}{N^2} \\sum_{k=1}^N N_k v_k \\right] = \\frac{1}{N^2} \\sum_{k=1}^N \\mathbb{E}[N_k] v_k\n    $$\n    We are given that the resampling scheme is unbiased, meaning $\\mathbb{E}[N_k] = N \\pi_k$.\n    $$\n    \\mathbb{E}_{\\mathbf{N}}[\\mathrm{Var}(\\hat{c}_t \\mid \\mathbf{N})] = \\frac{1}{N^2} \\sum_{k=1}^N (N \\pi_k) v_k = \\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k\n    $$\n\n**General Variance Expression:**\nCombining the two terms, we obtain the general expression for the conditional variance of $\\hat{c}_t$:\n$$\n\\mathrm{Var}(\\hat{c}_t) = \\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k + \\frac{1}{N^2} \\boldsymbol{\\mathfrak{m}}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}}\n$$\n\n**Specialization for Resampling Schemes:**\n\n1.  **Multinomial Resampling:**\n    The covariance matrix is given as $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) = N\\big(\\mathrm{Diag}(\\boldsymbol{\\pi}) - \\boldsymbol{\\pi}\\boldsymbol{\\pi}^{\\top}\\big)$. Substituting this into the general formula:\n    $$\n    \\boldsymbol{\\mathfrak{m}}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}} = N \\boldsymbol{\\mathfrak{m}}^\\top (\\mathrm{Diag}(\\boldsymbol{\\pi}) - \\boldsymbol{\\pi}\\boldsymbol{\\pi}^{\\top}) \\boldsymbol{\\mathfrak{m}} = N \\left( \\sum_{k=1}^N \\pi_k \\mathfrak{m}_k^2 - \\left(\\sum_{k=1}^N \\pi_k \\mathfrak{m}_k\\right)^2 \\right)\n    $$\n    The total variance is:\n    $$\n    \\mathrm{Var}(\\hat{c}_t) = \\frac{1}{N}\\sum_k \\pi_k v_k + \\frac{N}{N^2}\\left(\\sum_k \\pi_k \\mathfrak{m}_k^2 - \\left(\\sum_k \\pi_k \\mathfrak{m}_k\\right)^2\\right) = \\frac{1}{N} \\left( \\sum_k \\pi_k (v_k + \\mathfrak{m}_k^2) - \\left(\\sum_k \\pi_k \\mathfrak{m}_k\\right)^2 \\right)\n    $$\n    Since $v_k + \\mathfrak{m}_k^2 = \\mathbb{E}_{q_k}[H_k(X)^2]$, this simplifies to the variance of a sample mean from an i.i.d. population, as expected for multinomial sampling.\n\n2.  **Residual Resampling:**\n    The covariance matrix is $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) = R\\big(\\mathrm{Diag}(\\mathbf{r}) - \\mathbf{r}\\mathbf{r}^{\\top}\\big)$ for $R > 0$ and $\\mathbf{0}$ for $R=0$.\n    If $R=0$, the counts $N_k$ are deterministic, so $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})=\\mathbf{0}$ and the variance is $\\mathrm{Var}(\\hat{c}_t) = \\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k$.\n    If $R>0$, the variance is:\n    $$\n    \\mathrm{Var}(\\hat{c}_t) = \\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k + \\frac{R}{N^2} \\boldsymbol{\\mathfrak{m}}^\\top (\\mathrm{Diag}(\\mathbf{r}) - \\mathbf{r}\\mathbf{r}^{\\top}) \\boldsymbol{\\mathfrak{m}}\n    $$\n    $$\n    \\mathrm{Var}(\\hat{c}_t) = \\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k + \\frac{R}{N^2} \\left( \\sum_{k=1}^N r_k \\mathfrak{m}_k^2 - \\left(\\sum_{k=1}^N r_k \\mathfrak{m}_k\\right)^2 \\right)\n    $$\n\n**Variance Minimization:**\nThe variance is a sum of non-negative terms. It is minimized when both terms are zero.\nThe first term, $\\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k$, is zero if and only if $v_k = 0$ for all $k$ such that $\\pi_k > 0$. The variance $v_k = \\mathrm{Var}_{q_k}[H_k(X)]$ is zero if and only if the random variable $H_k(X)$ is a constant for all $X$ in the support of $q_k(x)$.\n$$\nH_k(x) = C \\frac{G_t(x)\\,\\ell_k(x)}{\\nu_k\\,q_k(x)} = \\text{constant (w.r.t. } x)\n$$\nThis condition is satisfied by choosing the proposal density $q_k(x)$ to be proportional to $G_t(x)\\ell_k(x)$. The normalized optimal proposal is:\n$$\nq_k^{\\text{opt}}(x) = \\frac{G_t(x)\\ell_k(x)}{\\int G_t(y)\\ell_k(y)\\,\\mathrm{d}y}\n$$\nUnder this choice, $v_k=0$ for all $k$.\n\nThe variance then reduces to the second term: $\\frac{1}{N^2} \\boldsymbol{\\mathfrak{m}}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}}$. This term is zero if $\\boldsymbol{\\mathfrak{m}}$ is in the null space of $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N})$. For resampling schemes, the total count $\\sum_k N_k = N$ is fixed, which implies $\\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\mathbf{1} = \\mathbf{0}$, where $\\mathbf{1}$ is the vector of ones. Thus, if we can make $\\boldsymbol{\\mathfrak{m}}$ a constant vector, i.e., $\\mathfrak{m}_k$ is independent of $k$, the second term will vanish.\nLet's examine $\\mathfrak{m}_k$ under the optimal proposal $q_k=q_k^{\\text{opt}}$:\n$$\n\\mathfrak{m}_k = \\mathbb{E}_{q_k^{\\text{opt}}}[H_k(X)] = C \\frac{\\int G_t(y)\\ell_k(y)\\,\\mathrm{d}y}{\\nu_k}\n$$\nTo make $\\mathfrak{m}_k$ independent of $k$, we must choose $\\nu_k$ to be proportional to $\\int G_t(y)\\ell_k(y)\\,\\mathrm{d}y$. Let's set $\\nu_k = \\int G_t(y)\\ell_k(y)\\,\\mathrm{d}y$. With this choice:\n$$\n\\mathfrak{m}_k = C = \\sum_{j=1}^N \\bar{w}_{t-1}^j \\nu_j = \\sum_{j=1}^N \\bar{w}_{t-1}^j \\int G_t(y)\\ell_j(y)\\,\\mathrm{d}y = c_t\n$$\nSo $\\mathfrak{m}_k = c_t$ for all $k$. The vector $\\boldsymbol{\\mathfrak{m}}$ is $c_t \\mathbf{1}$, and $\\boldsymbol{\\mathfrak{m}}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}} = c_t^2 \\mathbf{1}^\\top \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\mathbf{1} = 0$.\n\nTherefore, the conditional variance is minimized and equals $0$ under the following conditions:\n1.  Proposals: $q_k(x) \\propto G_t(x)\\ell_k(x)$ for each $k$.\n2.  Adjustment multipliers: $\\nu_k \\propto \\int G_t(x)\\ell_k(x)\\,\\mathrm{d}x$ for each $k$.\n\nUnder these \"fully adapted\" or \"optimal\" choices, the estimator $\\hat{c}_t$ becomes exactly $c_t$, hence its variance is zero. This, however, requires computing the integrals $\\int G_t(x)\\ell_k(x)\\,\\mathrm{d}x$, which is often as hard as the original problem.\n\nThe principal result requested is the general expression for the conditional variance.",
            "answer": "$$\n\\boxed{\\frac{1}{N} \\sum_{k=1}^N \\pi_k v_k + \\frac{1}{N^2} \\boldsymbol{\\mathfrak{m}}^{\\top} \\mathrm{Cov}_{\\mathcal{R}}(\\mathbf{N}) \\boldsymbol{\\mathfrak{m}}}\n$$"
        },
        {
            "introduction": "Rao-Blackwellization is a powerful variance reduction technique, often used in conjunction with auxiliary proposals, that exploits model structure by marginalizing out some variables analytically. This problem applies this principle to a classic and important model class: the Switching Linear Gaussian State-Space Model (SLG-SSM), where a discrete latent state governs the dynamics of a continuous one . By working through the detailed calculations for a small-scale example, you will master the mechanics of a hybrid smoother, which combines exact Kalman smoothing for the continuous states with inference for the discrete switching paths, providing a concrete illustration of this elegant and efficient technique.",
            "id": "3290212",
            "problem": "Consider a Switching Linear Gaussian State-Space Model (SLG-SSM) in which a discrete regime process $z_{t} \\in \\{1,2\\}$ controls the linear dynamics of a continuous latent state $s_{t} \\in \\mathbb{R}$. The joint model is defined by the following fundamental components:\n\n- The discrete regime process $\\{z_{t}\\}_{t=0}^{T}$ is a homogeneous first-order Markov chain with initial distribution $p(z_{0})$ and transition matrix $A = [a_{ij}]$, where $a_{ij} = p(z_{t} = j \\mid z_{t-1} = i)$.\n- The continuous latent dynamics are linear-Gaussian conditioned on $z_{t}$:\n$$\ns_{t} = A_{z_{t}} s_{t-1} + \\eta_{t}, \\quad \\eta_{t} \\sim \\mathcal{N}(0, Q_{z_{t}}).\n$$\n- Observations are conditionally linear-Gaussian:\n$$\ny_{t} = H s_{t} + \\epsilon_{t}, \\quad \\epsilon_{t} \\sim \\mathcal{N}(0, R),\n$$\nwith $H = 1$.\n\nYou are to work within the Rao-Blackwellized Particle Filter (RBPF; Rao-Blackwellization replaces sampling of linear-Gaussian components by exact conditional inference) paradigm, augmented with an Auxiliary Particle Filter (APF; auxiliary proposals use one-step lookahead likelihoods) perspective to construct a hybrid forward-backward smoother: the discrete path $z_{0:T}$ is sampled using forward-backward methodology with backward sampling weights informed by linear-Gaussian predictive likelihoods, and the continuous trajectory $s_{0:T}$ is smoothed by Kalman smoothing conditioned on the sampled $z_{0:T}$.\n\nStart from the core definitions of Bayesian smoothing, the Hidden Markov Model (HMM) forward-backward decomposition, and linear-Gaussian filtering and smoothing. Derive a principled hybrid forward-backward smoother for the RBPF that:\n\n1. Samples $z_{0:T}$ from the exact smoothed distribution $p(z_{0:T} \\mid y_{0:T})$ using backward sampling weights that are constructed from forward regime-filtering messages and the regime-conditioned linear-Gaussian predictive likelihoods $p(y_{t+1} \\mid y_{0:t}, z_{t})$ (this is the APF lookahead principle).\n2. Applies Rauch–Tung–Striebel (RTS) Kalman smoothing to $s_{0:T}$ conditional on the sampled $z_{0:T}$.\n3. Uses the law of iterated expectations to express the smoothed expectation of a general functional $\\phi(z_{t}, s_{t})$ as a decomposition over $z_{t}$ with regime-conditioned linear-Gaussian moments for $s_{t}$.\n\nThen, instantiate and compute a specific smoothed expectation for a short horizon. Let $T=1$, with parameters\n- $p(z_{0} = 1) = 0.5$, $p(z_{0} = 2) = 0.5$,\n- $A = \\begin{pmatrix} 0.8 & 0.2 \\\\ 0.3 & 0.7 \\end{pmatrix}$,\n- $A_{1} = 1.0$, $Q_{1} = 0.5$; $A_{2} = 0.5$, $Q_{2} = 0.5$,\n- $H = 1$, $R = 0.25$,\n- $s_{0} \\sim \\mathcal{N}(m_{0}, P_{0})$ with $m_{0} = 0$ and $P_{0} = 1$,\nand observed values $y_{0} = 0.2$, $y_{1} = 0.3$.\n\nFor the functional $\\phi(z_{1}, s_{1}) = z_{1} s_{1}$, compute the smoothed expectation $\\mathbb{E}[\\phi(z_{1}, s_{1}) \\mid y_{0}, y_{1}]$ exactly under the specified model using the hybrid smoother you derived. Round your final numerical answer to four significant figures. No physical units are involved.",
            "solution": "The smoothed expectation of a functional $\\phi(z_t, s_t)$ is found by the law of total expectation:\n$$\n\\mathbb{E}[\\phi(z_t, s_t) \\mid y_{0:T}] = \\mathbb{E}_{z_{0:T} \\mid y_{0:T}} \\left[ \\mathbb{E}_{s_{0:T} \\mid z_{0:T}, y_{0:T}} [\\phi(z_t, s_t)] \\right]\n$$\nFor our specific problem, $t=1$, $T=1$, and $\\phi(z_1, s_1) = z_1 s_1$. The expectation becomes:\n$$\n\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\sum_{z_0=1}^2 \\sum_{z_1=1}^2 \\mathbb{E}[z_1 s_1 \\mid y_{0:1}, z_0, z_1] p(z_0, z_1 \\mid y_{0:1})\n$$\nSince $z_0$ and $z_1$ are given in the inner conditional expectation, this simplifies to:\n$$\n\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\sum_{i=1}^2 \\sum_{j=1}^2 j \\cdot \\mathbb{E}[s_1 \\mid y_{0:1}, z_0=i, z_1=j] \\cdot p(z_0=i, z_1=j \\mid y_{0:1})\n$$\nTo compute this, we need two components for each of the four paths $(i,j)$:\n1. The posterior probability of the path, $p(z_0=i, z_1=j \\mid y_{0:1})$.\n2. The smoothed mean of $s_1$, $\\mathbb{E}[s_1 \\mid y_{0:1}, z_0=i, z_1=j]$. Since $t=T=1$, this is equivalent to the filtered mean, which we denote $m_{1|1}^{(i,j)}$.\n\nThe posterior path probability is given by Bayes' rule:\n$$\np(z_0=i, z_1=j \\mid y_{0:1}) = \\frac{p(y_{0:1} \\mid z_0=i, z_1=j) p(z_0=i, z_1=j)}{p(y_{0:1})}\n$$\nThe unnormalized weight for each path $(i,j)$ is $\\tilde{w}_{i,j} = p(z_0=i, z_1=j, y_{0:1})$. Using the chain rule of probability:\n$\\tilde{w}_{i,j} = p(y_1 \\mid y_0, z_0=i, z_1=j) p(y_0 \\mid z_0=i) p(z_1=j \\mid z_0=i) p(z_0=i)$.\nThe term $p(y_1 \\mid y_0, z_0=i, z_1=j)$ is the predictive likelihood from a Kalman filter run along the path $(i,j)$. The term $p(y_0 \\mid z_0=i)$ is the likelihood of the first observation.\n\nNow we instantiate the computation with the given parameters:\n- $p(z_0=1) = 0.5$, $p(z_0=2) = 0.5$.\n- $A=\\begin{pmatrix} 0.8 & 0.2 \\\\ 0.3 & 0.7 \\end{pmatrix}$, so $a_{11}=0.8, a_{12}=0.2, a_{21}=0.3, a_{22}=0.7$.\n- For $z_t=1$: $A_1=1.0$, $Q_1=0.5$.\n- For $z_t=2$: $A_2=0.5$, $Q_2=0.5$.\n- $H=1$, $R=0.25$.\n- Prior for $s_0$: $s_0 \\sim \\mathcal{N}(m_0, P_0)$ with $m_0=0$ and $P_0=1$.\n- Observations: $y_0=0.2$, $y_1=0.3$.\n\n**Step 1: Process observation $y_0$**\nThe prior on $s_0$, $p(s_0)=\\mathcal{N}(s_0; 0, 1)$, is independent of $z_0$. We perform a Kalman update for $s_0$ using $y_0=0.2$.\n- Prior mean $m_{0|-1} = 0$, prior covariance $P_{0|-1} = 1$.\n- Innovation covariance: $S_0 = H P_{0|-1} H^T + R = 1 \\cdot 1 \\cdot 1 + 0.25 = 1.25$.\n- Kalman gain: $K_0 = P_{0|-1} H^T S_0^{-1} = 1 \\cdot 1 \\cdot (1.25)^{-1} = 0.8$.\n- Posterior mean: $m_{0|0} = m_{0|-1} + K_0 (y_0 - H m_{0|-1}) = 0 + 0.8(0.2 - 0) = 0.16$.\n- Posterior covariance: $P_{0|0} = (I - K_0 H) P_{0|-1} = (1 - 0.8 \\cdot 1) \\cdot 1 = 0.2$.\nThe posterior distribution $p(s_0 \\mid y_0) = \\mathcal{N}(s_0; 0.16, 0.2)$ is common to all paths, as the prior was independent of $z_0$. Let's denote $m_{0|0}^{(i)} = 0.16$ and $P_{0|0}^{(i)} = 0.2$ for $i \\in \\{1,2\\}$.\n\n**Step 2: Process observation $y_1$ for each path $(i,j)$**\nWe compute the path-specific filtered means $m_{1|1}^{(i,j)}$ and predictive likelihoods $p(y_1 \\mid y_0, z_0=i, z_1=j)$. Since $m_{0|0}$ and $P_{0|0}$ are common, these quantities will only depend on the value of $z_1=j$.\n\nCase 1: $z_1=1$ (Paths $(1,1)$ and $(2,1)$)\n- Predict step:\n  $m_{1|0}^{(1)} = A_1 m_{0|0} = 1.0 \\cdot 0.16 = 0.16$.\n  $P_{1|0}^{(1)} = A_1 P_{0|0} A_1^T + Q_1 = 1.0^2 \\cdot 0.2 + 0.5 = 0.7$.\n- Update step with $y_1=0.3$:\n  Innovation covariance: $S_1^{(1)} = H P_{1|0}^{(1)} H^T + R = 0.7 + 0.25 = 0.95$.\n  Kalman gain: $K_1^{(1)} = P_{1|0}^{(1)} H^T (S_1^{(1)})^{-1} = 0.7 \\cdot (0.95)^{-1} = \\frac{14}{19}$.\n  Posterior mean: $m_{1|1}^{(1)} = m_{1|0}^{(1)} + K_1^{(1)}(y_1 - H m_{1|0}^{(1)}) = 0.16 + \\frac{14}{19}(0.3 - 0.16) = \\frac{16}{100} + \\frac{14}{19} \\cdot \\frac{14}{100} = \\frac{4}{25} + \\frac{196}{1900} = \\frac{304+196}{1900} = \\frac{500}{1900} = \\frac{5}{19}$.\n- Predictive likelihood value is proportional to $L_1^{(1)} = \\mathcal{N}(y_1; m_{1|0}^{(1)}, S_1^{(1)}) = \\mathcal{N}(0.3; 0.16, 0.95)$.\n\nCase 2: $z_1=2$ (Paths $(1,2)$ and $(2,2)$)\n- Predict step:\n  $m_{1|0}^{(2)} = A_2 m_{0|0} = 0.5 \\cdot 0.16 = 0.08$.\n  $P_{1|0}^{(2)} = A_2 P_{0|0} A_2^T + Q_2 = 0.5^2 \\cdot 0.2 + 0.5 = 0.05 + 0.5 = 0.55$.\n- Update step with $y_1=0.3$:\n  Innovation covariance: $S_1^{(2)} = H P_{1|0}^{(2)} H^T + R = 0.55 + 0.25 = 0.80$.\n  Kalman gain: $K_1^{(2)} = P_{1|0}^{(2)} H^T (S_1^{(2)})^{-1} = 0.55 \\cdot (0.80)^{-1} = \\frac{11}{16}$.\n  Posterior mean: $m_{1|1}^{(2)} = m_{1|0}^{(2)} + K_1^{(2)}(y_1 - H m_{1|0}^{(2)}) = 0.08 + \\frac{11}{16}(0.3 - 0.08) = \\frac{8}{100} + \\frac{11}{16} \\cdot \\frac{22}{100} = \\frac{2}{25} + \\frac{242}{1600} = \\frac{128+242}{1600} = \\frac{370}{1600} = \\frac{37}{160}$.\n- Predictive likelihood value is proportional to $L_1^{(2)} = \\mathcal{N}(y_1; m_{1|0}^{(2)}, S_1^{(2)}) = \\mathcal{N}(0.3; 0.08, 0.80)$.\n\n**Step 3: Compute path probabilities**\nThe unnormalized weight of a path $(i,j)$ is $\\tilde{w}_{i,j} = p(z_0=i) \\cdot a_{ij} \\cdot L_1^{(j)}$. The likelihood of $y_0$ is common and can be dropped.\nLet $l_1 = L_1^{(1)}$ and $l_2 = L_1^{(2)}$.\n$\\tilde{w}_{1,1} = p(z_0=1) a_{11} l_1 = 0.5 \\cdot 0.8 \\cdot l_1 = 0.4 l_1$.\n$\\tilde{w}_{1,2} = p(z_0=1) a_{12} l_2 = 0.5 \\cdot 0.2 \\cdot l_2 = 0.1 l_2$.\n$\\tilde{w}_{2,1} = p(z_0=2) a_{21} l_1 = 0.5 \\cdot 0.3 \\cdot l_1 = 0.15 l_1$.\n$\\tilde{w}_{2,2} = p(z_0=2) a_{22} l_2 = 0.5 \\cdot 0.7 \\cdot l_2 = 0.35 l_2$.\n\nThe total weight is $W = \\tilde{w}_{1,1}+\\tilde{w}_{1,2}+\\tilde{w}_{2,1}+\\tilde{w}_{2,2} = (0.4+0.15)l_1 + (0.1+0.35)l_2 = 0.55 l_1 + 0.45 l_2$.\nThe posterior probability of a path is $p(z_0=i, z_1=j \\mid y_{0:1}) = \\tilde{w}_{i,j}/W$.\n\n**Step 4: Compute the final expectation**\nThe expectation is $\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\sum_{i,j} j \\cdot \\frac{\\tilde{w}_{i,j}}{W} \\cdot m_{1|1}^{(j)}$.\n$= \\frac{1}{W} \\left( 1 \\cdot \\tilde{w}_{1,1} m_{1|1}^{(1)} + 2 \\cdot \\tilde{w}_{1,2} m_{1|1}^{(2)} + 1 \\cdot \\tilde{w}_{2,1} m_{1|1}^{(1)} + 2 \\cdot \\tilde{w}_{2,2} m_{1|1}^{(2)} \\right)$\n$= \\frac{1}{W} \\left( (\\tilde{w}_{1,1}+\\tilde{w}_{2,1}) m_{1|1}^{(1)} + 2(\\tilde{w}_{1,2}+\\tilde{w}_{2,2}) m_{1|1}^{(2)} \\right)$\n$= \\frac{1}{W} \\left( 0.55 l_1 m_{1|1}^{(1)} + 2 \\cdot 0.45 l_2 m_{1|1}^{(2)} \\right)$\nLet's compute the ratio $\\rho = l_2/l_1$:\n$\\rho = \\frac{\\mathcal{N}(0.3; 0.08, 0.80)}{\\mathcal{N}(0.3; 0.16, 0.95)} = \\frac{(2\\pi \\cdot 0.80)^{-1/2} \\exp(-\\frac{0.22^2}{2 \\cdot 0.80})}{(2\\pi \\cdot 0.95)^{-1/2} \\exp(-\\frac{0.14^2}{2 \\cdot 0.95})} = \\sqrt{\\frac{0.95}{0.80}} \\exp\\left(-\\frac{0.0484}{1.6} + \\frac{0.0196}{1.9}\\right)$\n$\\rho = \\sqrt{1.1875} \\exp(-0.03025 + 0.0103157...) = 1.08972... \\times \\exp(-0.0199342...) \\approx 1.08972 \\times 0.98026 \\approx 1.06822$.\nNow, substitute $\\rho$ into the expectation expression, dividing numerator and denominator by $l_1$:\n$\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] = \\frac{0.55 m_{1|1}^{(1)} + 0.90 \\rho m_{1|1}^{(2)}}{0.55 + 0.45 \\rho}$\nUsing $m_{1|1}^{(1)} = 5/19$ and $m_{1|1}^{(2)} = 37/160 = 0.23125$:\n$\\mathbb{E}[z_1 s_1 \\mid y_{0:1}] \\approx \\frac{0.55 \\cdot (5/19) + 0.90 \\cdot 1.06822 \\cdot 0.23125}{0.55 + 0.45 \\cdot 1.06822}$\n$\\approx \\frac{0.144737 + 0.961398 \\cdot 0.23125}{0.55 + 0.480699} \\approx \\frac{0.144737 + 0.222274}{1.030699} \\approx \\frac{0.367011}{1.030699} \\approx 0.356089$.\nRounding to four significant figures, the result is $0.3561$.",
            "answer": "$$\n\\boxed{0.3561}\n$$"
        },
        {
            "introduction": "The final step in mastering these methods is translating theory into effective, working code. This exercise challenges you to design and implement an Auxiliary Particle Filter for a model with state-dependent observation noise (heteroscedasticity), a common feature in financial and engineering applications . You will first derive an appropriate lookahead proposal that anticipates measurement quality and then implement it. By empirically comparing the Effective Sample Size (ESS) of your APF to that of a naive bootstrap filter, you will directly observe and quantify the performance gains, bridging the gap between abstract theory and practical, high-performance implementation.",
            "id": "3290181",
            "problem": "You are given a one-dimensional state-space model with heteroscedastic observations. The latent state evolves according to a first-order autoregression and the observation is a nonlinear function corrupted by state-dependent noise. The purpose of this task is to derive auxiliary particle filter (APF) weights that anticipate observation noise amplitude and then to implement and empirically compare the effective sample size (ESS) of those weights against a naive bootstrap particle filter that ignores any lookahead. Your final program must compute the ratio of ESS for APF over the naive filter across a small test suite and print the results in a specified single-line format.\n\nConsider the model\n- State transition: $x_t \\mid x_{t-1} \\sim \\mathcal{N}(\\varphi x_{t-1}, \\tau^2)$.\n- Observation: $y_t = g(x_t) + \\sigma(x_t)\\,\\eta_t$, with $\\eta_t \\sim \\mathcal{N}(0,1)$, $g(x) = x$, and $\\sigma(x) = \\sigma_0 \\left(1 + \\alpha \\lvert x \\rvert \\right)$.\n\nAssume the previous particle approximation to the filtering distribution at time $t-1$ consists of particles $\\{x_{t-1}^i\\}_{i=1}^N$ with equal weights $w_{t-1}^i = 1/N$. You must:\n\n1. Starting only from fundamental definitions and well-tested formulas, derive a principled auxiliary particle filter lookahead scheme that anticipates the state-dependent observation noise amplitude $ \\sigma(x) $ at time $ t $.\n   - Use the importance sampling identity for sequential Monte Carlo with an auxiliary index and the product rule for densities.\n   - Use properties of the normal density $\\mathcal{N}(\\cdot;\\mu,\\sigma^2)$.\n   - Do not use pre-packaged formulas for the auxiliary particle filter; show the derivation to a stage-one lookahead weight and the associated stage-two importance correction.\n\n2. Specialize your derivation to the given heteroscedastic observation model with $g(x) = x$ and $\\sigma(x) = \\sigma_0 (1 + \\alpha \\lvert x \\rvert)$. The lookahead must explicitly prioritize particles predicting smaller observation variance for $y_t$.\n\n3. Implement two single-step filters from time $t-1$ to $t$ given a single observation $y_t$:\n   - A naive bootstrap particle filter that resamples using $w_{t-1}^i$ only, propagates with the transition kernel, and weights by the exact heteroscedastic likelihood $p(y_t \\mid x_t^i)$.\n   - An auxiliary particle filter that uses your derived stage-one lookahead weights $\\alpha^i$ to resample ancestors, propagates with the transition kernel, and applies the correct stage-two importance weights.\n\n4. Compute and return, for each test case, a single number: the ratio $\\mathrm{ESS}_\\mathrm{APF} / \\mathrm{ESS}_\\mathrm{naive}$ where the effective sample size is defined as\n$$\n\\mathrm{ESS}(\\{w^i\\}_{i=1}^N) \\equiv \\frac{1}{\\sum_{i=1}^N (\\bar{w}^i)^2},\n\\quad \\bar{w}^i \\equiv \\frac{w^i}{\\sum_{j=1}^N w^j}.\n$$\n\nTo make the problem fully specified and testable, use the following test suite. For each case, let $\\{x_{t-1}^i\\}$ be drawn independently from the stationary distribution of the autoregression, that is $x_{t-1}^i \\sim \\mathcal{N}(0, \\tau^2 / (1 - \\varphi^2))$, and use equal prior weights $w_{t-1}^i = 1/N$. For reproducibility, use the provided random seeds for all sampling steps.\n\n- Test case A (general heteroscedastic, happy path):\n  - $N = 3000$, $\\varphi = 0.9$, $\\tau = 0.5$, $\\sigma_0 = 0.2$, $\\alpha = 0.8$, $y_t = 1.0$, seed $= 123$.\n\n- Test case B (homoscedastic boundary, $\\alpha = 0$):\n  - $N = 3000$, $\\varphi = 0.9$, $\\tau = 0.5$, $\\sigma_0 = 0.2$, $\\alpha = 0.0$, $y_t = 1.0$, seed $= 456$.\n\n- Test case C (strong heteroscedasticity and informative observation):\n  - $N = 3000$, $\\varphi = 0.95$, $\\tau = 0.3$, $\\sigma_0 = 0.1$, $\\alpha = 1.5$, $y_t = 3.0$, seed $= 789$.\n\n- Test case D (fewer particles and negative observation):\n  - $N = 1000$, $\\varphi = 0.7$, $\\tau = 1.0$, $\\sigma_0 = 0.3$, $\\alpha = 1.0$, $y_t = -2.0$, seed $= 2024$.\n\nYour program must implement both filters, compute the two ESS values for each case, and produce the final output as a single line containing a comma-separated list of the four ratios in the order A, B, C, D, enclosed in square brackets, for example $[r_A,r_B,r_C,r_D]$. Each ratio must be a real number. No physical units are involved. No angles are involved. Percentages are not used; report ratios as raw decimal numbers.\n\nThe program must be complete and runnable as-is, require no input, and must not access external files or networks. It must strictly use the specified execution environment. The computation should be numerically stable for the provided parameter ranges.",
            "solution": "We begin from the fundamental structure of sequential Monte Carlo for state-space models. Let $\\{x_{t-1}^i, w_{t-1}^i\\}_{i=1}^N$ approximate the filtering distribution $p(x_{t-1} \\mid y_{1:t-1})$. The goal at time $t$ is to approximate $p(x_t \\mid y_{1:t}) \\propto p(y_t \\mid x_t) \\int p(x_t \\mid x_{t-1}) p(x_{t-1} \\mid y_{1:t-1}) \\mathrm{d}x_{t-1}$.\n\nA bootstrap particle filter draws ancestors $I$ according to $w_{t-1}^i$ and propagates $x_t \\sim p(x_t \\mid x_{t-1}^I)$, with importance weights proportional to $p(y_t \\mid x_t)$. An auxiliary particle filter introduces an auxiliary index and constructs a more informative proposal by augmenting the sampling space and then using importance sampling.\n\nThe importance sampling principle states that if a target density on $(I, x_t)$ is $\\pi(I, x_t)$ and we propose from $q(I, x_t)$, then the importance weight is $w(I, x_t) \\propto \\pi(I, x_t) / q(I, x_t)$. For the filtering update, a convenient target is\n$$\n\\pi(I, x_t) \\propto w_{t-1}^I \\, p(x_t \\mid x_{t-1}^I) \\, p(y_t \\mid x_t),\n$$\nwhose marginal over $x_t$ yields the usual mixture approximation to the predictive distribution. The auxiliary particle filter constructs a proposal as a mixture:\n$$\nq(I, x_t) = \\alpha^I \\, q(x_t \\mid x_{t-1}^I, y_t),\n$$\nwhere $\\alpha^i$ are stage-one weights that anticipate the relevance of ancestor $i$ for the observation $y_t$ and $q(x_t \\mid x_{t-1}^i, y_t)$ is a proposal for the propagated state. The corresponding importance weight is\n$$\nw(I, x_t) \\propto \\frac{w_{t-1}^I \\, p(x_t \\mid x_{t-1}^I) \\, p(y_t \\mid x_t)}{\\alpha^I \\, q(x_t \\mid x_{t-1}^I, y_t)}.\n$$\n\nA principled and computationally convenient choice of the stage-one weights uses a deterministic lookahead for the observation likelihood. Let $\\mu_t^i \\equiv \\mathbb{E}[x_t \\mid x_{t-1}^i]$, which for a linear-Gaussian transition is simply $\\mu_t^i = \\varphi x_{t-1}^i$. Define a lookahead score\n$$\nm^i \\equiv \\tilde{p}(y_t \\mid x_t \\approx \\mu_t^i),\n$$\nwhere $\\tilde{p}$ is an approximation to the observation likelihood evaluated at the predicted mean. Then choose\n$$\n\\alpha^i \\propto w_{t-1}^i \\, m^i, \\quad \\sum_{i=1}^N \\alpha^i = 1.\n$$\nWith this choice and the proposal $q(x_t \\mid x_{t-1}^i, y_t) = p(x_t \\mid x_{t-1}^i)$ equal to the transition kernel, the importance weight simplifies to\n$$\nw(I, x_t) \\propto \\frac{w_{t-1}^I \\, p(x_t \\mid x_{t-1}^I) \\, p(y_t \\mid x_t)}{\\alpha^I \\, p(x_t \\mid x_{t-1}^I)} = \\frac{w_{t-1}^I \\, p(y_t \\mid x_t)}{\\alpha^I} \\propto \\frac{p(y_t \\mid x_t)}{m^I}.\n$$\nThus the auxiliary particle filter proceeds by:\n- Stage one: compute $\\alpha^i \\propto w_{t-1}^i m^i$ and sample ancestors $I^1,\\dots,I^N$ i.i.d. from the categorical distribution on $\\{1,\\dots,N\\}$ with probabilities $\\{\\alpha^i\\}$.\n- Stage two: propagate $x_t^j \\sim p(x_t \\mid x_{t-1}^{I^j})$ and assign importance weights $w_t^j \\propto p(y_t \\mid x_t^j)/m^{I^j}$, then normalize.\n\nWe now specialize this to the given heteroscedastic observation model. The observation model is\n$$\ny_t = g(x_t) + \\sigma(x_t)\\,\\eta_t,\\quad \\eta_t \\sim \\mathcal{N}(0,1),\n$$\nwith $g(x) = x$ and $\\sigma(x) = \\sigma_0 (1 + \\alpha \\lvert x \\rvert)$. The exact observation likelihood is\n$$\np(y_t \\mid x_t) = \\mathcal{N}\\!\\left(y_t; g(x_t), \\sigma^2(x_t)\\right) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma(x_t)} \\exp\\!\\left(-\\frac{(y_t - g(x_t))^2}{2\\,\\sigma^2(x_t)}\\right).\n$$\nTo anticipate the measurement quality, we evaluate a lookahead score at the predicted mean $\\mu_t^i = \\varphi x_{t-1}^i$ as\n$$\nm^i = \\mathcal{N}\\!\\left(y_t; g(\\mu_t^i), \\sigma^2(\\mu_t^i)\\right) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma(\\mu_t^i)} \\exp\\!\\left(-\\frac{(y_t - g(\\mu_t^i))^2}{2\\,\\sigma^2(\\mu_t^i)}\\right).\n$$\nBecause $\\sigma(\\mu_t^i)$ varies with $\\lvert \\mu_t^i \\rvert$, this choice explicitly prioritizes ancestors that both predict $g(\\mu_t^i)$ close to $y_t$ and have smaller predicted observation noise $\\sigma(\\mu_t^i)$, thereby favoring well-measured particles.\n\nThe naive bootstrap particle filter uses resampling probabilities $\\alpha_\\mathrm{naive}^i \\propto w_{t-1}^i$ (here uniform), propagation with $p(x_t \\mid x_{t-1}^i)$, and weights $w_t^j \\propto p(y_t \\mid x_t^j)$.\n\nFor numerical stability, we work with logarithms. For any normal density $\\mathcal{N}(y;\\mu,\\sigma^2)$, the log-density is\n$$\n\\log \\mathcal{N}(y;\\mu,\\sigma^2) = -\\frac{1}{2}\\left(\\frac{y - \\mu}{\\sigma}\\right)^2 - \\log \\sigma - \\frac{1}{2} \\log (2\\pi).\n$$\nWe can compute unnormalized log-weights $\\ell^j$ and then normalize them by subtracting the maximum and exponentiating to avoid underflow:\n$$\n\\bar{w}^j = \\frac{\\exp(\\ell^j - \\max_k \\ell^k)}{\\sum_{k=1}^N \\exp(\\ell^k - \\max_k \\ell^k)}.\n$$\nThen compute $\\mathrm{ESS} = 1/\\sum_j (\\bar{w}^j)^2$.\n\nAlgorithmic steps for each test case:\n- Sample $\\{x_{t-1}^i\\}_{i=1}^N$ i.i.d. from the stationary distribution of the autoregression: $x_{t-1}^i \\sim \\mathcal{N}(0, \\tau^2/(1-\\varphi^2))$.\n- Naive bootstrap filter:\n  - Resample ancestors uniformly.\n  - Propagate $x_t^j \\sim \\mathcal{N}(\\varphi x_{t-1}^{I^j}, \\tau^2)$.\n  - Compute $\\log p(y_t \\mid x_t^j)$ using the heteroscedastic $\\sigma(x_t^j)$.\n  - Normalize to get weights and compute $\\mathrm{ESS}_\\mathrm{naive}$.\n- Auxiliary particle filter:\n  - Compute $\\mu_t^i = \\varphi x_{t-1}^i$ and $m^i = \\mathcal{N}(y_t; \\mu_t^i, \\sigma^2(\\mu_t^i))$; set $\\alpha^i \\propto m^i$.\n  - Resample ancestors $I^j$ from $\\{\\alpha^i\\}$.\n  - Propagate $x_t^j \\sim \\mathcal{N}(\\varphi x_{t-1}^{I^j}, \\tau^2)$.\n  - Compute $\\log p(y_t \\mid x_t^j)$ and subtract $\\log m^{I^j}$ to get the log of the stage-two weights; normalize to get weights and compute $\\mathrm{ESS}_\\mathrm{APF}$.\n\nWe report the ratio $\\mathrm{ESS}_\\mathrm{APF}/\\mathrm{ESS}_\\mathrm{naive}$ for each test case.\n\nExpectations:\n- In the homoscedastic boundary $\\alpha = 0$, the APF still uses mean lookahead via $g(\\mu_t^i)$ and may show modest improvement over naive resampling; however, it does not prioritize by $\\sigma(x)$ because $\\sigma(x)$ is constant.\n- With large $\\alpha$ or informative $y_t$ far in the tails, heteroscedasticity is more pronounced; we expect APF to allocate more particles to states with smaller $\\sigma(\\mu_t^i)$ near $y_t$, increasing $\\mathrm{ESS}$ relative to naive.\n\nThe final program implements these steps for the four specified test cases and prints a single line containing the four ratios in a list format $[r_A,r_B,r_C,r_D]$.",
            "answer": "```python\nimport numpy as np\n\ndef normal_logpdf(y, mu, sigma):\n    # Compute log N(y; mu, sigma^2) with vectorized sigma > 0\n    return -0.5 * ((y - mu) / sigma) ** 2 - np.log(sigma) - 0.5 * np.log(2.0 * np.pi)\n\ndef hetero_sigma(x, sigma0, alpha):\n    # sigma(x) = sigma0 * (1 + alpha * |x|)\n    return sigma0 * (1.0 + alpha * np.abs(x))\n\ndef ess_from_logweights(logw):\n    # Normalize log-weights and compute ESS\n    m = np.max(logw)\n    w = np.exp(logw - m)\n    w_sum = np.sum(w)\n    if w_sum == 0.0 or not np.isfinite(w_sum):\n        # Fallback to uniform if numerical issues arise\n        n = len(logw)\n        return float(n)\n    w /= w_sum\n    return 1.0 / np.sum(w * w)\n\ndef sample_stationary_x_prev(N, phi, tau, rng):\n    var = tau**2 / (1.0 - phi**2)\n    return rng.normal(loc=0.0, scale=np.sqrt(var), size=N)\n\ndef naive_bootstrap_step(x_prev, phi, tau, sigma0, alpha, y, rng):\n    N = len(x_prev)\n    # Resample ancestors with equal weights\n    ancestors = rng.integers(low=0, high=N, size=N)  # uniform categorical\n    mu = phi * x_prev[ancestors]\n    x_t = rng.normal(loc=mu, scale=tau, size=N)\n    sig = hetero_sigma(x_t, sigma0, alpha)\n    logw = normal_logpdf(y, mu=x_t, sigma=sig)  # g(x)=x\n    return ess_from_logweights(logw)\n\ndef apf_step(x_prev, phi, tau, sigma0, alpha, y, rng):\n    N = len(x_prev)\n    # Stage-one lookahead using mu_i = phi * x_prev[i], m_i = N(y; mu_i, sigma(mu_i)^2)\n    mu_pred = phi * x_prev\n    sig_pred = hetero_sigma(mu_pred, sigma0, alpha)\n    log_m = normal_logpdf(y, mu=mu_pred, sigma=sig_pred)\n    # Convert to probabilities alpha^i\n    m_max = np.max(log_m)\n    m_weights = np.exp(log_m - m_max)\n    m_sum = np.sum(m_weights)\n    if m_sum == 0.0 or not np.isfinite(m_sum):\n        # Fallback: uniform if numerical issues arise\n        alpha_probs = np.full(N, 1.0 / N)\n    else:\n        alpha_probs = m_weights / m_sum\n    # Resample ancestors according to alpha_probs\n    ancestors = rng.choice(N, size=N, replace=True, p=alpha_probs)\n    # Stage-two: propagate and compute importance weights w ∝ p(y|x_t)/m_{ancestor}\n    mu = phi * x_prev[ancestors]\n    x_t = rng.normal(loc=mu, scale=tau, size=N)\n    sig_xt = hetero_sigma(x_t, sigma0, alpha)\n    loglik = normal_logpdf(y, mu=x_t, sigma=sig_xt)\n    log_m_anc = log_m[ancestors]\n    logw = loglik - log_m_anc\n    return ess_from_logweights(logw)\n\ndef ess_ratio_case(N, phi, tau, sigma0, alpha, y, seed):\n    rng = np.random.default_rng(seed)\n    x_prev = sample_stationary_x_prev(N, phi, tau, rng)\n    ess_naive = naive_bootstrap_step(x_prev, phi, tau, sigma0, alpha, y, rng)\n    ess_apf = apf_step(x_prev, phi, tau, sigma0, alpha, y, rng)\n    # Avoid division by zero\n    if ess_naive == 0.0:\n        return float('inf') if ess_apf > 0.0 else 1.0\n    return ess_apf / ess_naive\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (N, phi, tau, sigma0, alpha, y, seed)\n    test_cases = [\n        (3000, 0.9, 0.5, 0.2, 0.8,  1.0, 123),   # A\n        (3000, 0.9, 0.5, 0.2, 0.0,  1.0, 456),   # B\n        (3000, 0.95, 0.3, 0.1, 1.5, 3.0, 789),   # C\n        (1000, 0.7, 1.0, 0.3, 1.0, -2.0, 2024),  # D\n    ]\n\n    results = []\n    for case in test_cases:\n        N, phi, tau, sigma0, alpha, y, seed = case\n        ratio = ess_ratio_case(N, phi, tau, sigma0, alpha, y, seed)\n        # Round to a reasonable number of decimals for display\n        results.append(f\"{ratio:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}