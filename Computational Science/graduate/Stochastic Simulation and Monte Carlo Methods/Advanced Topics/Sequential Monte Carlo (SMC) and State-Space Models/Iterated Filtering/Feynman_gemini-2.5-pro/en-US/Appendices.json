{
    "hands_on_practices": [
        {
            "introduction": "Parameter estimation in Partially Observed Markov Processes (POMPs) presents a significant challenge that cannot be solved by direct differentiation. This exercise  reveals why by tasking you with decomposing the complete-data score function. By identifying which components of the gradient are rendered inaccessible under common \"plug-and-play\" modeling assumptions, you will establish the foundational motivation for simulation-based techniques like iterated filtering.",
            "id": "3315185",
            "problem": "Consider a partially observed Markov process (POMP), where the latent state process $\\{x_t\\}_{t=0}^{T}$ is a time-homogeneous Markov chain with parameter vector $\\theta \\in \\mathbb{R}^{d}$ and the observations $\\{y_t\\}_{t=1}^{T}$ are conditionally independent given the states. Let the initial state have density $p_{\\theta}(x_0)$, the transition density of the latent process be $f_{\\theta}(x_t \\mid x_{t-1})$, and the observation density be $g_{\\theta}(y_t \\mid x_t)$. Assume throughout that the Markov property and conditional independence structure hold in their standard forms, and that all densities exist and are differentiable with respect to $\\theta$.\n\nStarting from the fundamental laws and core definitions of a Markov chain and conditional independence (namely, that the joint density of the latent states and observations factorizes according to the product of the initial density, transition densities, and observation densities, consistent with the Markov property and the observation model), derive an expression for the gradient with respect to $\\theta$ of the log joint density $\\log p_{\\theta}(x_{0:T}, y_{1:T})$ as a sum of gradients of the log initial density, log transition densities, and log observation densities.\n\nThen, under a plug-and-play setup commonly used with iterated filtering, where one can simulate from $p_{\\theta}(x_0)$ and $f_{\\theta}(x_t \\mid x_{t-1})$ but cannot evaluate them pointwise, while one can evaluate $g_{\\theta}(y_t \\mid x_t)$ pointwise, explain in words which components of the gradient decomposition are directly accessible and which are not. Your explanation should be qualitative and should not introduce any shortcut formulas beyond the fundamental factorization implied by the model structure.\n\nProvide the final gradient decomposition formula only as your final answer. The final answer must be a single closed-form analytic expression. No rounding is required.",
            "solution": "The problem statement will be validated before a solution is attempted.\n\n### Step 1: Extract Givens\n- A partially observed Markov process (POMP).\n- Latent state process: $\\{x_t\\}_{t=0}^{T}$.\n- Latent process is a time-homogeneous Markov chain.\n- Parameter vector: $\\theta \\in \\mathbb{R}^{d}$.\n- Observations: $\\{y_t\\}_{t=1}^{T}$.\n- Observations are conditionally independent given the states.\n- Initial state density: $p_{\\theta}(x_0)$.\n- Transition density of the latent process: $f_{\\theta}(x_t \\mid x_{t-1})$.\n- Observation density: $g_{\\theta}(y_t \\mid x_t)$.\n- The Markov property and conditional independence structure hold in their standard forms.\n- All densities exist and are differentiable with respect to $\\theta$.\n- Task 1: Derive $\\nabla_{\\theta} \\log p_{\\theta}(x_{0:T}, y_{1:T})$ as a sum of gradients of log-densities, starting from fundamental laws.\n- Task 2: Under a \"plug-and-play\" setup where one can simulate from $p_{\\theta}(x_0)$ and $f_{\\theta}(x_t \\mid x_{t-1})$ but not evaluate them pointwise, while $g_{\\theta}(y_t \\mid x_t)$ can be evaluated pointwise, explain which components of the gradient decomposition are accessible.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria.\n- **Scientifically Grounded (Critical)**: The problem is situated within the standard mathematical framework of state-space models, also known as partially observed Markov processes (POMPs) or hidden Markov models. This is a well-established and fundamental topic in statistics, econometrics, and signal processing. All concepts—Markov chains, conditional independence, and likelihood factorization—are standard. The problem is scientifically sound.\n- **Well-Posed**: The problem is well-posed. It asks for the derivation of a standard identity (the score function for the complete data) and a qualitative analysis based on a clearly defined set of constraints. The assumptions of differentiability and the existence of all densities ensure that the required mathematical operations are valid, leading to a unique and meaningful result.\n- **Objective (Critical)**: The problem is stated using precise, unambiguous mathematical language. There are no subjective or opinion-based statements.\n- **Completeness and Consistency**: The problem provides all necessary definitions ($p_{\\theta}$, $f_{\\theta}$, $g_{\\theta}$) and properties (Markov, conditional independence, differentiability) to perform the derivation. The constraints for the second part of the question are also stated clearly. There are no contradictions.\n\nThe problem does not exhibit any of the flaws listed in the validation checklist (e.g., scientific unsoundness, non-formalizability, incompleteness, etc.).\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A complete, reasoned solution will be provided.\n\n***\n\nWe are tasked with deriving the gradient of the log joint density of the states and observations for a partially observed Markov process. Let the complete history of states be denoted by $x_{0:T} = (x_0, x_1, \\dots, x_T)$ and the sequence of observations be $y_{1:T} = (y_1, y_2, \\dots, y_T)$. The joint probability density is $p_{\\theta}(x_{0:T}, y_{1:T})$.\n\nThe fundamental definition of a POMP allows us to factorize this joint density. Using the chain rule of probability, we first separate the observations from the states:\n$$\np_{\\theta}(x_{0:T}, y_{1:T}) = p_{\\theta}(y_{1:T} \\mid x_{0:T}) \\, p_{\\theta}(x_{0:T})\n$$\nThe problem states that the observations $\\{y_t\\}$ are conditionally independent given the states $\\{x_t\\}$. More specifically, each observation $y_t$ depends only on the corresponding state $x_t$. This allows us to factor the conditional density of the observations:\n$$\np_{\\theta}(y_{1:T} \\mid x_{0:T}) = \\prod_{t=1}^{T} g_{\\theta}(y_t \\mid x_t)\n$$\nThe problem also states that the latent process $\\{x_t\\}$ is a time-homogeneous Markov chain. This property means that the density of the entire state trajectory can be factored into the product of the initial state density and the sequence of one-step transition densities:\n$$\np_{\\theta}(x_{0:T}) = p_{\\theta}(x_0, x_1, \\dots, x_T) = p_{\\theta}(x_0) \\prod_{t=1}^{T} f_{\\theta}(x_t \\mid x_{t-1})\n$$\nSubstituting these two factorizations into the expression for the joint density, we obtain the complete factorization:\n$$\np_{\\theta}(x_{0:T}, y_{1:T}) = p_{\\theta}(x_0) \\left( \\prod_{t=1}^{T} f_{\\theta}(x_t \\mid x_{t-1}) \\right) \\left( \\prod_{t=1}^{T} g_{\\theta}(y_t \\mid x_t) \\right)\n$$\nThe problem requires the gradient of the logarithm of this density. Taking the natural logarithm of both sides, the products are converted into sums:\n$$\n\\log p_{\\theta}(x_{0:T}, y_{1:T}) = \\log p_{\\theta}(x_0) + \\sum_{t=1}^{T} \\log f_{\\theta}(x_t \\mid x_{t-1}) + \\sum_{t=1}^{T} \\log g_{\\theta}(y_t \\mid x_t)\n$$\nFinally, we compute the gradient with respect to the parameter vector $\\theta$. As the gradient operator $\\nabla_{\\theta}$ is a linear operator, the gradient of the sum is the sum of the gradients:\n$$\n\\nabla_{\\theta} \\log p_{\\theta}(x_{0:T}, y_{1:T}) = \\nabla_{\\theta} \\log p_{\\theta}(x_0) + \\nabla_{\\theta} \\left( \\sum_{t=1}^{T} \\log f_{\\theta}(x_t \\mid x_{t-1}) \\right) + \\nabla_{\\theta} \\left( \\sum_{t=1}^{T} \\log g_{\\theta}(y_t \\mid x_t) \\right)\n$$\nSince the parameters $\\theta$ are assumed not to depend on time $t$, we can bring the gradient operator inside the summations:\n$$\n\\nabla_{\\theta} \\log p_{\\theta}(x_{0:T}, y_{1:T}) = \\nabla_{\\theta} \\log p_{\\theta}(x_0) + \\sum_{t=1}^{T} \\nabla_{\\theta} \\log f_{\\theta}(x_t \\mid x_{t-1}) + \\sum_{t=1}^{T} \\nabla_{\\theta} \\log g_{\\theta}(y_t \\mid x_t)\n$$\nThis is the desired decomposition of the score function for the complete data $(x_{0:T}, y_{1:T})$.\n\nNext, we analyze the accessibility of each component under the specified \"plug-and-play\" setup. The decomposition consists of three parts:\n1. The initial state component: $\\nabla_{\\theta} \\log p_{\\theta}(x_0)$\n2. The state transition component: $\\sum_{t=1}^{T} \\nabla_{\\theta} \\log f_{\\theta}(x_t \\mid x_{t-1})$\n3. The observation component: $\\sum_{t=1}^{T} \\nabla_{\\theta} \\log g_{\\theta}(y_t \\mid x_t)$\n\nUsing the identity for the gradient of a logarithm, $\\nabla_{\\theta} \\log h_{\\theta}(z) = \\frac{\\nabla_{\\theta} h_{\\theta}(z)}{h_{\\theta}(z)}$, evaluating each component requires pointwise evaluation of both the respective density and its gradient.\n\n- **Initial State and Transition Components**: The first two components involve the terms $\\nabla_{\\theta} \\log p_{\\theta}(x_0)$ and $\\nabla_{\\theta} \\log f_{\\theta}(x_t \\mid x_{t-1})$. To calculate these, one would need to evaluate the densities $p_{\\theta}(x_0)$ and $f_{\\theta}(x_t \\mid x_{t-1})$ themselves (as the denominators), as well as their gradients. The problem explicitly states that in the plug-and-play setting, one *cannot* evaluate these densities pointwise. Therefore, the initial state component and the state transition component of the gradient are **not directly accessible**. Their evaluation is precluded by the problem's constraints.\n\n- **Observation Component**: The third component, $\\sum_{t=1}^{T} \\nabla_{\\theta} \\log g_{\\theta}(y_t \\mid x_t)$, requires the evaluation of the observation density $g_{\\theta}(y_t \\mid x_t)$ and its gradient $\\nabla_{\\theta} g_{\\theta}(y_t \\mid x_t)$. The problem states that one *can* evaluate $g_{\\theta}(y_t \\mid x_t)$ pointwise. Since the functional form of this density is known, its gradient with respect to $\\theta$ can typically be derived analytically and also evaluated. Thus, for any given state $x_t$ and observation $y_t$, the term $\\nabla_{\\theta} \\log g_{\\theta}(y_t \\mid x_t)$ can be computed. Consequently, the observation component of the gradient decomposition **is directly accessible**.\n\nIn summary, under the specified plug-and-play conditions, only the portion of the score function related to the observation model can be directly computed. The parts related to the latent process dynamics (initialization and transition) cannot be evaluated, which is a principal difficulty addressed by algorithms like iterated filtering that use simulation-based (Monte Carlo) methods to handle these inaccessible terms.",
            "answer": "$$\n\\boxed{\\nabla_{\\theta} \\log p_{\\theta}(x_{0:T}, y_{1:T}) = \\nabla_{\\theta} \\log p_{\\theta}(x_0) + \\sum_{t=1}^{T} \\nabla_{\\theta} \\log f_{\\theta}(x_t \\mid x_{t-1}) + \\sum_{t=1}^{T} \\nabla_{\\theta} \\log g_{\\theta}(y_t \\mid x_t)}\n$$"
        },
        {
            "introduction": "A robust understanding of an algorithm requires analyzing its performance and sources of error, a core skill in computational statistics. This practice  combines theoretical analysis with numerical validation to study the behavior of the iterated filtering estimator. You will derive a heuristic scaling law for the variance of the score estimator, predicting that its variance $\\mathrm{Var}(\\hat{S})$ scales with the number of particles $N$ and data length $T$ as $\\mathrm{Var}(\\hat{S}) \\propto T/N$, and then write code to confirm this relationship, solidifying your intuition for tuning the algorithm.",
            "id": "3315217",
            "problem": "Consider a scalar autoregressive hidden Markov model with latent state and observation given by the following state space formulation: $$x_t = \\phi x_{t-1} + \\varepsilon_t,\\quad \\varepsilon_t \\sim \\mathcal{N}(0,\\sigma_x^2),$$ $$y_t \\mid x_t \\sim \\mathcal{N}(x_t,\\tau^2),$$ where $x_0 \\sim \\mathcal{N}(0,1)$, the autoregressive coefficient $\\phi$ is the parameter of interest, and $\\sigma_x^2$ and $\\tau^2$ are known positive constants. Iterated Filtering (IF) uses parameter perturbations within a Sequential Monte Carlo algorithm (particle filtering) to construct an estimator of the score function (the gradient of the log-likelihood with respect to the parameter). Define the particle filter with $N$ particles in which, at each time step $t$, the parameter is perturbed independently across particles by drawing $\\delta_i^{(t)} \\sim \\mathcal{N}(0,\\sigma_\\theta^2)$ and using $\\phi_i^{(t)} = \\phi + \\delta_i^{(t)}$ to propagate particle $i$ via $$x_{t,i} = \\phi_i^{(t)} x_{t-1,i} + \\eta_{t,i},\\quad \\eta_{t,i} \\sim \\mathcal{N}(0,\\sigma_x^2),$$ and to compute its incremental weight $$w_{t,i} \\propto \\exp\\left(-\\frac{(y_t - x_{t,i})^2}{2\\tau^2}\\right).$$ Let the normalized weights at time $t$ be $\\tilde{w}_{t,i} = w_{t,i} / \\sum_{j=1}^N w_{t,j}$ and denote the log-weights by $\\ell_{t,i} = \\log w_{t,i}$. A simple IF-based estimator of the score contribution at time $t$ is defined by $$g_t = \\frac{1}{\\sigma_\\theta^2}\\sum_{i=1}^N \\tilde{w}_{t,i}\\,\\delta_i^{(t)}\\left(\\ell_{t,i} - \\sum_{j=1}^N \\tilde{w}_{t,j}\\,\\ell_{t,j}\\right),$$ and the overall score estimator is $$\\hat{S} = \\sum_{t=1}^T g_t.$$ Throughout, take $\\phi$ equal to the true data-generating value so the expected score is near zero, and focus on the variance of the estimator $\\mathrm{Var}(\\hat{S})$.\n\nStarting from the central limit theorem for weighted sums and the independence of parameter perturbations from observation noise conditional on the latent state, derive a heuristic scaling law for the variance $\\mathrm{Var}(\\hat{S})$ as a function of the number of particles $N$ and sequence length $T$ under reasonable mixing conditions. Your derivation must start from well-tested principles: independence approximations for large $N$, the central limit theorem for averages of independent random variables, and the additive structure of the score contributions across time. Explicitly state any approximations you introduce along the way, and obtain a scaling of the form $$\\mathrm{Var}(\\hat{S}) \\approx \\frac{C\\,T}{N},$$ identifying the dependence of the constant $C$ on model quantities such as $\\sigma_\\theta^2$ and the variability of $\\ell_{t,i}$.\n\nThen, numerically validate the scaling law on a single fixed dataset generated from the model with the following parameter values: $$\\phi = 0.7,\\quad \\sigma_x^2 = 1.0,\\quad \\tau^2 = 1.0,\\quad \\sigma_\\theta^2 = 0.05^2.$$ Generate a single dataset $\\{y_t\\}_{t=1}^{T_{\\max}}$ with $T_{\\max} = 400$ from the model at these parameter values and $x_0 \\sim \\mathcal{N}(0,1)$. For each $(N,T)$ pair in the test suite below, compute the empirical variance of $\\hat{S}$ across $R$ independent replicates of the particle filter with parameter perturbations, where each replicate reuses the same fixed data prefix $\\{y_t\\}_{t=1}^{T}$ but draws new particle initializations, parameter perturbations, transition noises, and resampling randomness. Use $$R = 150.$$\n\nTest suite of $(N,T)$ pairs:\n- $(N,T) = (50,50)$,\n- $(N,T) = (50,200)$,\n- $(N,T) = (200,50)$,\n- $(N,T) = (200,200)$,\n- $(N,T) = (400,100)$,\n- $(N,T) = (100,400)$.\n\nFor each test case, compute the normalized variance $$V_{\\mathrm{norm}}(N,T) = \\mathrm{Var}(\\hat{S}) \\cdot \\frac{N}{T}.$$ Using the case $(N,T) = (200,200)$ as the baseline, compute the ratio $$\\rho(N,T) = \\frac{V_{\\mathrm{norm}}(N,T)}{V_{\\mathrm{norm}}(200,200)}.$$ Your program should produce a single line of output containing the values of $\\rho(N,T)$ for the test suite, in the order listed above, as a comma-separated list enclosed in square brackets (for example, $$[r_1,r_2,r_3,r_4,r_5,r_6]$$). All numerical answers are unitless real numbers and must be printed as machine-readable decimal floats in a single line as specified. The numerical experiment must be self-contained and reproducible without external input or files. The final program must implement the particle filter with parameter perturbations, the IF score estimator defined above, systematic resampling, and the empirical variance computation across $R$ replicates for each test case.",
            "solution": "The problem is well-posed, scientifically grounded, and provides a complete specification for both a theoretical derivation and a numerical experiment. All parameters and algorithmic components are clearly defined.\n\nThe first task is to derive a heuristic scaling law for the variance of the iterated filtering score estimator, $\\mathrm{Var}(\\hat{S})$, as a function of the number of particles $N$ and the length of the time series $T$. The estimator is given by $\\hat{S} = \\sum_{t=1}^T g_t$, where\n$$g_t = \\frac{1}{\\sigma_\\theta^2}\\sum_{i=1}^N \\tilde{w}_{t,i}\\,\\delta_i^{(t)}\\left(\\ell_{t,i} - \\sum_{j=1}^N \\tilde{w}_{t,j}\\,\\ell_{t,j}\\right).$$\nOur derivation proceeds in three main steps: decomposing the variance over time, analyzing the variance of a single time-step contribution, and combining the results.\n\n**Step 1: Decomposition of Variance over Time**\nThe total score estimator $\\hat{S}$ is a sum of contributions $g_t$ from each time step. The variance of this sum is given by\n$$\\mathrm{Var}(\\hat{S}) = \\mathrm{Var}\\left(\\sum_{t=1}^T g_t\\right) = \\sum_{t=1}^T \\mathrm{Var}(g_t) + 2\\sum_{1 \\le t < s \\le T} \\mathrm{Cov}(g_t, g_s).$$\nWe introduce our first key approximation:\n**Approximation 1:** For a well-mixing system, the particle filter's state at time $s$ becomes progressively independent of its state at time $t$ as the gap $s-t$ increases. Consequently, the score contributions $g_t$ and $g_s$ become approximately uncorrelated. We assume these covariances are negligible, which is a common assumption for ergodic systems.\nThis reduces the variance to a sum of variances:\n$$\\mathrm{Var}(\\hat{S}) \\approx \\sum_{t=1}^T \\mathrm{Var}(g_t).$$\nNext, we introduce a second approximation related to stationarity:\n**Approximation 2:** For a sufficiently long time series (large $t$), the filtering process is assumed to reach a stochastic steady state. This implies that the statistical properties of the filter, and thus the variance of the score contribution $\\mathrm{Var}(g_t)$, become approximately constant over time. Let us denote this stationary variance as $\\mathrm{Var}(g)$.\nUnder this assumption, the sum simplifies to:\n$$\\mathrm{Var}(\\hat{S}) \\approx T \\cdot \\mathrm{Var}(g).$$\nThis establishes the linear dependence on the time series length $T$.\n\n**Step 2: Analysis of Single-Step Variance $\\mathrm{Var}(g)$**\nNow we analyze the variance of the single-step score contribution, $g_t$. Let us drop the time index $t$ for notational simplicity. The estimator $g$ is a complex function of the particle states, weights, and parameter perturbations. However, its structure is that of a function of empirical means of quantities associated with the particles.\nConditional on the filter's history up to time $t-1$, which we denote by the sigma-algebra $\\mathcal{F}_{t-1}$, the set of random variables driving the filter at step $t$ for each particle $i$, namely the resampled ancestor $x_{t-1,i}^\\star$, the parameter perturbation $\\delta_i^{(t)}$, and the process noise $\\eta_{t,i}$, are independent and identically distributed across the particles $i=1, \\dots, N$. The term $g_t$ is a function of the empirical averages of quantities derived from these i.i.d. variables.\nAccording to the Central Limit Theorem for particle filters (and more generally for functions of means of i.i.d. random variables, via the Delta method), any such estimator converges to its true value, and its variance scales inversely with the number of particles $N$.\n**Conclusion from CLT:** Based on established theory for Monte Carlo methods, the variance of $g_t$ must scale with $N$ as:\n$$\\mathrm{Var}(g) \\approx \\frac{C}{N},$$\nfor some constant $C$ that does not depend on $N$, but depends on the model parameters and the data-generating process.\n\nTo gain more insight into the constant $C$, we can make a further approximation:\n**Approximation 3:** We assume the perturbation variance $\\sigma_\\theta^2$ is small. This allows us to treat the weights $\\tilde{w}_{i}$ and log-weights $\\ell_{i}$ as being primarily determined by the state propagation noise $\\eta_i$ and the ancestor particle $x_{t-1,i}$, and only weakly dependent on the perturbation $\\delta_i$.\nLet us analyze the variance of $g_t$ conditional on the state of the filter just before the parameter perturbations are applied. In this context, the quantities $\\tilde{w}_{t,i}$ and $\\ell_{t,i}$ are considered fixed coefficients for the random variables $\\delta_i^{(t)}$.\nLet $c_i = \\frac{1}{\\sigma_\\theta^2}\\tilde{w}_{t,i}(\\ell_{t,i} - \\bar{\\ell}_t)$. Then $g_t = \\sum_{i=1}^N c_i \\delta_i^{(t)}$. Since the $\\delta_i^{(t)} \\sim \\mathcal{N}(0, \\sigma_\\theta^2)$ are i.i.d., the conditional variance is:\n$$\\mathrm{Var}(g_t \\mid \\mathcal{F}_{t-1}, \\{\\eta_{t,i}\\}) = \\mathrm{Var}\\left(\\sum_{i=1}^N c_i \\delta_i^{(t)}\\right) = \\sum_{i=1}^N c_i^2 \\mathrm{Var}(\\delta_i^{(t)}) = \\sigma_\\theta^2 \\sum_{i=1}^N c_i^2.$$\nSubstituting the expression for $c_i$:\n$$\\mathrm{Var}(g_t \\mid \\dots) = \\sigma_\\theta^2 \\sum_{i=1}^N \\frac{1}{(\\sigma_\\theta^2)^2} \\tilde{w}_{t,i}^2 (\\ell_{t,i} - \\bar{\\ell}_t)^2 = \\frac{1}{\\sigma_\\theta^2} \\sum_{i=1}^N \\tilde{w}_{t,i}^2 (\\ell_{t,i} - \\bar{\\ell}_t)^2.$$\nThe term $\\sum_{i=1}^N \\tilde{w}_{t,i}^2$ is the inverse of the effective sample size, $N_{\\text{eff}}$. For a healthy particle filter, $N_{\\text{eff}}$ is proportional to $N$, so $\\sum_{i=1}^N \\tilde{w}_{t,i}^2 \\propto 1/N$. The sum can be approximated as $\\frac{1}{N} \\mathrm{Var}_{\\tilde{w}}(\\ell)$, where $\\mathrm{Var}_{\\tilde{w}}(\\ell) = \\sum_i \\tilde{w}_i (\\ell_i - \\bar{\\ell})^2$ is the weighted variance of the log-weights. This approximation is more accurate if the weights are not heavily concentrated.\nThus, the conditional variance scales as:\n$$\\mathrm{Var}(g_t \\mid \\dots) \\approx \\frac{1}{N} \\cdot \\frac{\\mathrm{Var}_{\\tilde{w}}(\\ell)}{\\sigma_\\theta^2}.$$\nTaking the expectation over thefilter randomness (the noise $\\eta$ and resampling) gives the unconditional variance $\\mathrm{Var}(g_t)$, assuming the mean term in the law of total variance is negligible (which it is, since $g_t$ is an approximately unbiased estimator of a quantity whose expectation is zero at the true parameter value).\n$$\\mathrm{Var}(g) \\approx \\frac{1}{N} \\cdot \\frac{1}{\\sigma_\\theta^2} \\mathbb{E}[\\mathrm{Var}_{\\tilde{w}}(\\ell)].$$\nThis gives us the explicit form of the constant $C = \\frac{1}{\\sigma_\\theta^2} \\mathbb{E}[\\mathrm{Var}_{\\tilde{w}}(\\ell)]$, which depends on the perturbation variance and the expected variability of the particle log-weights.\n\n**Step 3: Final Scaling Law**\nCombining the results from Step 1 and Step 2, we arrive at the final heuristic scaling law for the variance of the score estimator:\n$$\\mathrm{Var}(\\hat{S}) \\approx T \\cdot \\mathrm{Var}(g) \\approx T \\left( \\frac{C}{N} \\right) = \\frac{C\\,T}{N}.$$\nThis relationship implies that the quantity $\\mathrm{Var}(\\hat{S}) \\cdot \\frac{N}{T}$ should be approximately constant across different choices of $N$ and $T$, provided these are large enough for the approximations to hold. The numerical experiment is designed to verify this prediction.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to perform the numerical validation of the IF estimator variance scaling.\n    \"\"\"\n    # Set random seed for complete reproducibility of the experiment.\n    np.random.seed(12345)\n\n    # --- Problem Parameters ---\n    phi = 0.7\n    sigma_x_sq = 1.0\n    tau_sq = 1.0\n    sigma_theta_sq = 0.05**2\n    x0_var = 1.0\n    T_max = 400\n    R = 150\n\n    # --- Test Suite ---\n    test_cases = [\n        (50, 50),\n        (50, 200),\n        (200, 50),\n        (200, 200),\n        (400, 100),\n        (100, 400),\n    ]\n\n    # --- Helper Functions ---\n\n    def generate_data(T, phi_val, sigma_x_val, tau_val, x0_stdev):\n        \"\"\"Generates a single time series from the state-space model.\"\"\"\n        x = np.zeros(T + 1)\n        y = np.zeros(T)\n        x[0] = np.random.normal(0, x0_stdev)\n        for t in range(T):\n            x[t+1] = phi_val * x[t] + np.random.normal(0, sigma_x_val)\n            y[t] = x[t+1] + np.random.normal(0, tau_val)\n        return y\n\n    def systematic_resample(weights):\n        \"\"\"Performs systematic resampling.\"\"\"\n        N = len(weights)\n        # Generate N ordered random numbers from U[0, 1/N), U[1/N, 2/N), ...\n        positions = (np.arange(N) + np.random.uniform()) / N\n        cum_weights = np.cumsum(weights)\n        # Find indices of particles to keep\n        indices = np.searchsorted(cum_weights, positions)\n        return indices\n\n    def run_if_replicate(y_data_prefix, N, T, phi_val, sigma_x_val, tau_sq_val, sigma_theta_sq_val, x0_stdev):\n        \"\"\"Runs one replicate of the iterated filtering algorithm.\"\"\"\n        # Initial particles drawn from the prior p(x_0)\n        x_particles = np.random.normal(0, x0_stdev, N)\n        s_hat = 0.0\n        \n        y_obs = y_data_prefix[:T]\n        sigma_theta_val = np.sqrt(sigma_theta_sq_val)\n\n        for t in range(T):\n            # Propagate particles with perturbed parameters\n            deltas = np.random.normal(0, sigma_theta_val, N)\n            phis_perturbed = phi_val + deltas\n            etas = np.random.normal(0, sigma_x_val, N)\n            \n            x_particles = phis_perturbed * x_particles + etas\n\n            # Compute log-weights based on observation y_t\n            log_weights = -0.5 * ((y_obs[t] - x_particles)**2) / tau_sq_val\n\n            # Normalize weights for stability\n            max_log_w = np.max(log_weights)\n            weights = np.exp(log_weights - max_log_w)\n            sum_weights = np.sum(weights)\n            if sum_weights == 0: # Handle potential underflow, though unlikely with stabilization\n                # This case indicates filter collapse, assign uniform weights\n                norm_weights = np.full(N, 1.0/N)\n            else:\n                norm_weights = weights / sum_weights\n\n            # Calculate score contribution g_t\n            log_weight_mean = np.sum(norm_weights * log_weights)\n            g_t = (1.0 / sigma_theta_sq_val) * np.sum(norm_weights * deltas * (log_weights - log_weight_mean))\n            s_hat += g_t\n\n            # Resample particles for the next iteration\n            indices = systematic_resample(norm_weights)\n            x_particles = x_particles[indices]\n            \n        return s_hat\n\n    # --- Main Execution Logic ---\n\n    # 1. Generate a single, fixed dataset for all experiments\n    y_fixed_data = generate_data(T_max, phi, np.sqrt(sigma_x_sq), np.sqrt(tau_sq), np.sqrt(x0_var))\n\n    v_norm_results = []\n    # 2. Iterate through test cases\n    for N, T in test_cases:\n        s_hat_replicates = np.zeros(R)\n        for r in range(R):\n            s_hat = run_if_replicate(\n                y_fixed_data, N, T, phi, \n                np.sqrt(sigma_x_sq), tau_sq, sigma_theta_sq, np.sqrt(x0_var)\n            )\n            s_hat_replicates[r] = s_hat\n        \n        # 3. Compute empirical variance and normalized variance\n        var_s = np.var(s_hat_replicates, ddof=1)\n        v_norm = var_s * N / T\n        v_norm_results.append(v_norm)\n\n    # 4. Calculate ratios relative to the baseline case (200, 200)\n    baseline_v_norm = v_norm_results[3]  # (200, 200) is the 4th case (index 3)\n    rho_results = [v / baseline_v_norm for v in v_norm_results]\n\n    # 5. Print the final result in the specified format\n    print(f\"[{','.join(f'{r:.6f}' for r in rho_results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Beyond understanding how an algorithm works, an expert practitioner must know when to use it. This exercise  guides you through a crucial comparative analysis of Iterated Filtering (IF) and Particle MCMC (PMCMC), two cornerstone methods for inference in POMPs. By deriving how their computational costs scale differently with data length $T$, you will develop a clear, quantitative basis for choosing the most efficient algorithm for a given problem.",
            "id": "3315130",
            "problem": "Consider a general hidden Markov model with latent process $\\{x_{t}\\}_{t=1}^{T}$ and observations $\\{y_{t}\\}_{t=1}^{T}$ governed by a parameter vector $\\theta$. The latent transition density is $f_{\\theta}(x_{t} \\mid x_{t-1})$ and the observation density is $g_{\\theta}(y_{t} \\mid x_{t})$. You wish to perform parameter inference using either Iterated Filtering (IF) or Particle Markov chain Monte Carlo (PMCMC), specifically Particle Marginal Metropolis–Hastings (PMMH), both of which are “plug-and-play” algorithms relying on forward simulation from $f_{\\theta}$ and evaluation of $g_{\\theta}$.\n\nAssume the following well-tested facts that set the fundamental base for computational scaling in sequential Monte Carlo methods:\n- Let $N$ denote the number of state particles used by the bootstrap particle filter. The computational cost of one particle filter pass through the $T$ observations is proportional to $N T$. Introduce a constant of proportionality $\\gamma > 0$ so that the cost is $\\gamma N T$.\n- The particle filter’s log-likelihood estimator $\\widehat{\\ell}(\\theta)$ has variance that grows approximately linearly in $T$ and decreases inversely in $N$, i.e., $\\operatorname{Var}(\\widehat{\\ell}(\\theta)) \\approx c \\, T / N$ for some model- and algorithm-dependent constant $c > 0$.\n- In Particle Marginal Metropolis–Hastings (PMMH), to maintain a constant acceptance behavior and mixing independent of $T$, one tunes $N$ so that $\\operatorname{Var}(\\widehat{\\ell}(\\theta))$ is held near a fixed target level $\\sigma_{0}^{2} > 0$.\n\nDefine the per–effective parameter update cost for each method as the expected computational cost required to produce one effectively independent update of $\\theta$:\n- For IF, one effective parameter update requires one or a small fixed number of particle filter passes. Let the number of passes per effective update be absorbed into $\\gamma$, so the per–effective update cost is $C_{\\mathrm{IF}}(T,N) = \\gamma N T$. The $N$ used in IF is selected to keep the relative error of the estimated score (gradient of the log-likelihood) bounded as $T$ increases.\n- For PMMH, one effective parameter update requires a certain expected number of particle filter calls due to the acceptance–rejection mechanism and autocorrelation of the Markov chain. Let this expected multiplicative overhead be $\\eta > 0$, tuned to be independent of $T$ when $\\operatorname{Var}(\\widehat{\\ell}(\\theta))$ is held at $\\sigma_{0}^{2}$. Thus the per–effective update cost is $C_{\\mathrm{PMCMC}}(T) = \\eta \\gamma N^{\\star}(T) T$, where $N^{\\star}(T)$ is the $N$ required to achieve $\\operatorname{Var}(\\widehat{\\ell}(\\theta)) = \\sigma_{0}^{2}$.\n\nStarting from the facts above and using first-principles reasoning about variance scaling and computational work, do the following:\n1. Derive $N^{\\star}(T)$ as a function of $T$, $c$, and $\\sigma_{0}^{2}$.\n2. Express $C_{\\mathrm{IF}}(T,N)$ and $C_{\\mathrm{PMCMC}}(T)$ explicitly as functions of $T$, $N$, $\\gamma$, $c$, $\\sigma_{0}^{2}$, and $\\eta$.\n3. Derive the ratio $R(T,N) = C_{\\mathrm{PMCMC}}(T) / C_{\\mathrm{IF}}(T,N)$.\n4. Solve for the threshold data length $T^{\\star}$ (as a closed-form analytic expression) such that $C_{\\mathrm{PMCMC}}(T^{\\star}) = C_{\\mathrm{IF}}(T^{\\star},N)$.\n\nBased on your derivations, discuss qualitatively which regimes of $T$ and $N$ make Iterated Filtering preferable versus Particle Markov chain Monte Carlo. Your final answer must be the single closed-form expression for $T^{\\star}$ only. No numerical evaluation is required, and no rounding is needed. Do not include units in your final answer.",
            "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded in the principles of computational statistics, specifically sequential Monte Carlo methods, and is well-posed, objective, and internally consistent. We may proceed with the solution.\n\nThe problem requires a comparison of the computational cost scaling for two methods of parameter inference in hidden Markov models: Iterated Filtering (IF) and Particle Markov chain Monte Carlo (PMCMC), specifically in its Particle Marginal Metropolis–Hastings (PMMH) variant. The analysis is based on established scaling properties for the particle filter, which is the core computational component of both algorithms.\n\nWe are given the following:\n- The number of particles is $N$.\n- The number of time steps (observations) is $T$.\n- The computational cost of a single particle filter pass is $C_{PF} = \\gamma N T$, where $\\gamma > 0$ is a constant of proportionality.\n- The variance of the particle filter's log-likelihood estimator $\\widehat{\\ell}(\\theta)$ is $\\operatorname{Var}(\\widehat{\\ell}(\\theta)) \\approx \\frac{c T}{N}$, where $c > 0$ is a constant.\n- For PMMH, the number of particles $N$ is chosen to maintain the variance of the log-likelihood estimator at a constant target level, $\\operatorname{Var}(\\widehat{\\ell}(\\theta)) = \\sigma_{0}^{2}$. Let this required number of particles be $N^{\\star}(T)$.\n- The per–effective parameter update cost for IF is $C_{\\mathrm{IF}}(T,N) = \\gamma N T$.\n- The per–effective parameter update cost for PMMH is $C_{\\mathrm{PMCMC}}(T) = \\eta \\gamma N^{\\star}(T) T$, where $\\eta > 0$ accounts for MCMC overhead.\n\nWe will now address the four parts of the problem in sequence.\n\n**1. Derive $N^{\\star}(T)$ as a function of $T$, $c$, and $\\sigma_{0}^{2}$.**\n\nThe PMMH algorithm requires tuning the number of particles, $N$, such that the variance of the log-likelihood estimator is held at a constant level $\\sigma_{0}^{2}$ to ensure stable MCMC performance as $T$ increases. We are given the relationship for the variance:\n$$\n\\operatorname{Var}(\\widehat{\\ell}(\\theta)) \\approx \\frac{c T}{N}\n$$\nLetting $N = N^{\\star}(T)$, we set this variance equal to the target $\\sigma_{0}^{2}$:\n$$\n\\sigma_{0}^{2} = \\frac{c T}{N^{\\star}(T)}\n$$\nSolving for $N^{\\star}(T)$ gives the required number of particles as a function of the data length $T$:\n$$\nN^{\\star}(T) = \\frac{c T}{\\sigma_{0}^{2}}\n$$\nThis result shows that for PMMH to maintain its desired statistical properties, the number of particles must scale linearly with the length of the time series.\n\n**2. Express $C_{\\mathrm{IF}}(T,N)$ and $C_{\\mathrm{PMCMC}}(T)$ explicitly.**\n\nThe cost for Iterated Filtering, $C_{\\mathrm{IF}}(T,N)$, is already given in the desired form, representing the cost for a fixed number of particles $N$ and a time series of length $T$:\n$$\nC_{\\mathrm{IF}}(T,N) = \\gamma N T\n$$\nFor PMMH, the cost is given as $C_{\\mathrm{PMCMC}}(T) = \\eta \\gamma N^{\\star}(T) T$. We substitute the expression for $N^{\\star}(T)$ derived in the previous step:\n$$\nC_{\\mathrm{PMCMC}}(T) = \\eta \\gamma \\left( \\frac{c T}{\\sigma_{0}^{2}} \\right) T\n$$\nSimplifying this expression, we get the cost for PMMH as a function of $T$ and the various constants:\n$$\nC_{\\mathrm{PMCMC}}(T) = \\frac{\\eta \\gamma c}{\\sigma_{0}^{2}} T^{2}\n$$\nThis derivation highlights a fundamental difference in computational scaling: for a fixed $N$, the cost of an effective IF update scales linearly with $T$, whereas the cost of an effective PMMH update scales quadratically with $T$.\n\n**3. Derive the ratio $R(T,N) = C_{\\mathrm{PMCMC}}(T) / C_{\\mathrm{IF}}(T,N)$.**\n\nWe now compute the ratio of the two costs using the expressions derived above.\n$$\nR(T,N) = \\frac{C_{\\mathrm{PMCMC}}(T)}{C_{\\mathrm{IF}}(T,N)} = \\frac{\\frac{\\eta \\gamma c T^{2}}{\\sigma_{0}^{2}}}{\\gamma N T}\n$$\nWe can simplify this expression by canceling common terms. The term $\\gamma T$ appears in both the numerator and the denominator.\n$$\nR(T,N) = \\frac{\\eta c T}{N \\sigma_{0}^{2}}\n$$\nThis ratio encapsulates the relative computational expense of the two methods.\n\n**4. Solve for the threshold data length $T^{\\star}$.**\n\nThe threshold data length $T^{\\star}$ is defined as the value of $T$ at which the computational costs of the two methods are equal, i.e., $C_{\\mathrm{PMCMC}}(T^{\\star}) = C_{\\mathrm{IF}}(T^{\\star},N)$. This is equivalent to setting the ratio $R(T^{\\star},N)$ to $1$.\n$$\nR(T^{\\star},N) = 1\n$$\nSubstituting the expression for the ratio:\n$$\n\\frac{\\eta c T^{\\star}}{N \\sigma_{0}^{2}} = 1\n$$\nWe now solve for $T^{\\star}$:\n$$\nT^{\\star} = \\frac{N \\sigma_{0}^{2}}{\\eta c}\n$$\nThis is the closed-form analytic expression for the threshold data length.\n\n**Qualitative Discussion**\n\nThe derived costs, $C_{\\mathrm{IF}}(T,N) = \\gamma N T$ (linear in $T$) and $C_{\\mathrm{PMCMC}}(T) = \\frac{\\eta \\gamma c}{\\sigma_{0}^{2}} T^{2}$ (quadratic in $T$), reveal the core trade-off. For a data series of length $T$ and a fixed number of particles $N$ used in the IF algorithm:\n- If $T < T^{\\star}$, then $R(T,N) < 1$, which implies $C_{\\mathrm{PMCMC}}(T) < C_{\\mathrm{IF}}(T,N)$. In this regime of shorter time series, PMMH is computationally more efficient per effective parameter update.\n- If $T > T^{\\star}$, then $R(T,N) > 1$, which implies $C_{\\mathrm{PMCMC}}(T) > C_{\\mathrm{IF}}(T,N)$. In this regime of longer time series, Iterated Filtering becomes the more efficient method.\n- If $T = T^{\\star}$, the costs are equal.\n\nTherefore, PMMH is preferable for problems with a short time series, while Iterated Filtering's linear scaling in $T$ makes it superior for problems involving a long time series. The threshold $T^{\\star} = \\frac{N \\sigma_{0}^{2}}{\\eta c}$ indicates that the specific crossover point depends on the number of particles $N$ used for IF. If one chooses a larger $N$ for the IF procedure (e.g., to obtain higher accuracy), the threshold $T^{\\star}$ increases, thereby extending the range of $T$ for which PMMH is the more economical choice.",
            "answer": "$$\\boxed{\\frac{N \\sigma_{0}^{2}}{\\eta c}}$$"
        }
    ]
}