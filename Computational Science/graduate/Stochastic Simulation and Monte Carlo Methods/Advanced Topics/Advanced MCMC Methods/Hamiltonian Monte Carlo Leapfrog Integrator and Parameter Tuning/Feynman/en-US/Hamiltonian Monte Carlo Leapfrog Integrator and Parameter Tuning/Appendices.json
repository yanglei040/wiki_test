{
    "hands_on_practices": [
        {
            "introduction": "At the heart of Hamiltonian Monte Carlo is the leapfrog integrator, which simulates the system's dynamics. For the algorithm to be effective, this numerical simulation must be stable, and understanding this stability is the first step in successful parameter tuning. This practice guides you through a foundational linear stability analysis for the harmonic oscillator, a cornerstone model in physics, to determine the absolute limit on the step size $\\epsilon$ that ensures a valid simulation.",
            "id": "3311274",
            "problem": "Consider a one-dimensional Hamiltonian Monte Carlo (HMC) system with Hamiltonian defined by $H(q,p)=U(q)+K(p)$, where the potential is $U(q)=\\frac{1}{2}\\omega^{2}q^{2}$ and the kinetic energy is $K(p)=\\frac{1}{2}p^{2}$. The equations of motion are given by Hamilton's equations, $\\dot{q}=\\frac{\\partial H}{\\partial p}=p$ and $\\dot{p}=-\\frac{\\partial H}{\\partial q}=-\\omega^{2}q$. The leapfrog (also known as Störmer–Verlet) integrator with step size $\\epsilon$ is defined by the sequence of updates\n$$\np_{n+\\frac{1}{2}}=p_{n}-\\frac{\\epsilon}{2}\\,\\nabla U(q_{n}),\\quad\nq_{n+1}=q_{n}+\\epsilon\\,p_{n+\\frac{1}{2}},\\quad\np_{n+1}=p_{n+\\frac{1}{2}}-\\frac{\\epsilon}{2}\\,\\nabla U(q_{n+1}).\n$$\nFor this quadratic potential, $\\nabla U(q)=\\omega^{2}q$, so the leapfrog integrator is a linear, symplectic map on $(q,p)$. In the context of HMC parameter tuning, stability of the integrator is critical for controlling energy error growth and maintaining high acceptance probability.\n\nStarting from the fundamental definitions above, derive the one-step update map of the leapfrog integrator as a $2\\times 2$ matrix acting on the state vector $(q_{n},p_{n})$, and use linear stability analysis to find the condition on $\\epsilon$ under which the eigenvalues of the one-step map lie on the unit circle in the complex plane. Define the maximal $\\epsilon$ ensuring stability as the supremum value of $\\epsilon$ for which the map remains stable. Then compare this threshold with the exact discrete-time flow map obtained by integrating the harmonic oscillator analytically over one time interval of length $\\epsilon$.\n\nYour final answer must be the maximal stable step size $\\epsilon_{\\max}$ expressed in terms of $\\omega$, as a closed-form analytic expression. No rounding is required, and no units need be specified.",
            "solution": "The problem statement is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n- **System**: A one-dimensional Hamiltonian Monte Carlo (HMC) system.\n- **Hamiltonian**: $H(q,p)=U(q)+K(p)$.\n- **Potential Energy**: $U(q)=\\frac{1}{2}\\omega^{2}q^{2}$.\n- **Kinetic Energy**: $K(p)=\\frac{1}{2}p^{2}$.\n- **Equations of Motion**: $\\dot{q}=\\frac{\\partial H}{\\partial p}=p$ and $\\dot{p}=-\\frac{\\partial H}{\\partial q}=-\\omega^{2}q$.\n- **Integrator**: Leapfrog (Störmer–Verlet) with step size $\\epsilon$.\n- **Leapfrog Update Rules**:\n  $$p_{n+\\frac{1}{2}}=p_{n}-\\frac{\\epsilon}{2}\\,\\nabla U(q_{n})$$\n  $$q_{n+1}=q_{n}+\\epsilon\\,p_{n+\\frac{1}{2}}$$\n  $$p_{n+1}=p_{n+\\frac{1}{2}}-\\frac{\\epsilon}{2}\\,\\nabla U(q_{n+1})$$\n- **Potential Gradient**: $\\nabla U(q)=\\omega^{2}q$.\n- **Task**: Derive the one-step update map as a $2 \\times 2$ matrix. Use linear stability analysis to find the condition on $\\epsilon$ where the eigenvalues of the map lie on the unit circle. Define and find the maximal stable step size $\\epsilon_{\\max}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded and well-posed. It describes the application of a standard numerical integration scheme (leapfrog) to a fundamental model in physics (the harmonic oscillator). The task is to perform a linear stability analysis, which is a standard and rigorous mathematical procedure for assessing numerical methods. The problem statement is objective, using precisely defined terminology from computational physics and mathematics. It is self-contained, providing all necessary definitions and equations. The problem is not trivial, requiring a multi-step derivation, but it has a unique and meaningful solution. It is directly relevant to the specified topic of HMC parameter tuning, as integrator stability is a central concern. There are no scientific or factual unsoundness, no contradictions, and no ambiguities.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n### Solution\nThe objective is to find the maximum stable step size $\\epsilon_{\\max}$ for the leapfrog integrator applied to the harmonic oscillator. This is achieved by deriving the one-step update matrix and analyzing its eigenvalues.\n\nThe Hamiltonian is $H(q,p) = \\frac{1}{2}\\omega^{2}q^{2} + \\frac{1}{2}p^{2}$. The gradient of the potential energy is $\\nabla U(q) = \\frac{dU}{dq} = \\omega^{2}q$.\n\nThe leapfrog update steps are given as:\n$1$. $p_{n+\\frac{1}{2}}=p_{n}-\\frac{\\epsilon}{2}\\nabla U(q_{n}) = p_{n}-\\frac{\\epsilon}{2}\\omega^{2}q_{n}$\n$2$. $q_{n+1}=q_{n}+\\epsilon p_{n+\\frac{1}{2}}$\n$3$. $p_{n+1}=p_{n+\\frac{1}{2}}-\\frac{\\epsilon}{2}\\nabla U(q_{n+1}) = p_{n+\\frac{1}{2}}-\\frac{\\epsilon}{2}\\omega^{2}q_{n+1}$\n\nWe express the state $(q_{n+1}, p_{n+1})$ as a linear transformation of the state $(q_n, p_n)$.\nFirst, substitute the expression for $p_{n+\\frac{1}{2}}$ from step $1$ into step $2$:\n$$q_{n+1} = q_{n} + \\epsilon \\left(p_{n} - \\frac{\\epsilon}{2}\\omega^{2}q_{n}\\right)$$\n$$q_{n+1} = \\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{2}\\right)q_{n} + \\epsilon p_{n} \\quad (*)$$\n\nNext, we derive the expression for $p_{n+1}$. Substitute $p_{n+\\frac{1}{2}}$ from step $1$ into step $3$:\n$$p_{n+1} = \\left(p_{n} - \\frac{\\epsilon}{2}\\omega^{2}q_{n}\\right) - \\frac{\\epsilon}{2}\\omega^{2}q_{n+1}$$\nNow, substitute the expression for $q_{n+1}$ from equation $(*)$:\n$$p_{n+1} = p_{n} - \\frac{\\epsilon}{2}\\omega^{2}q_{n} - \\frac{\\epsilon}{2}\\omega^{2}\\left[ \\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{2}\\right)q_{n} + \\epsilon p_{n} \\right]$$\nGroup the terms by $q_n$ and $p_n$:\n$$p_{n+1} = \\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{2}\\right)p_{n} + \\left(-\\frac{\\epsilon}{2}\\omega^{2} - \\frac{\\epsilon}{2}\\omega^{2}\\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{2}\\right)\\right)q_{n}$$\n$$p_{n+1} = \\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{2}\\right)p_{n} + \\left(-\\epsilon\\omega^{2} + \\frac{\\epsilon^{3}\\omega^{4}}{4}\\right)q_{n}$$\n$$p_{n+1} = -\\epsilon\\omega^{2}\\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{4}\\right)q_{n} + \\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{2}\\right)p_{n} \\quad (**)$$\n\nEquations $(*)$ and $(**)$ define the one-step update map $\\begin{pmatrix} q_{n+1} \\\\ p_{n+1} \\end{pmatrix} = M \\begin{pmatrix} q_{n} \\\\ p_{n} \\end{pmatrix}$, where $M$ is the $2 \\times 2$ transfer matrix:\n$$M = \\begin{pmatrix} 1 - \\frac{\\epsilon^{2}\\omega^{2}}{2} & \\epsilon \\\\ -\\epsilon\\omega^{2}\\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{4}\\right) & 1 - \\frac{\\epsilon^{2}\\omega^{2}}{2} \\end{pmatrix}$$\nFor linear stability, the eigenvalues of $M$ must lie on the unit circle in the complex plane, i.e., their magnitude must be $1$. Let $\\lambda$ denote an eigenvalue. The eigenvalues are the roots of the characteristic equation $\\det(M - \\lambda I) = 0$.\nThe leapfrog integrator is symplectic, meaning it preserves the phase space volume. For a linear map, this implies $\\det(M) = 1$. We can verify this property:\n$$\\det(M) = \\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{2}\\right)^{2} - \\epsilon\\left[-\\epsilon\\omega^{2}\\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{4}\\right)\\right]$$\n$$\\det(M) = \\left(1 - \\epsilon^{2}\\omega^{2} + \\frac{\\epsilon^{4}\\omega^{4}}{4}\\right) + \\epsilon^{2}\\omega^{2}\\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{4}\\right)$$\n$$\\det(M) = 1 - \\epsilon^{2}\\omega^{2} + \\frac{\\epsilon^{4}\\omega^{4}}{4} + \\epsilon^{2}\\omega^{2} - \\frac{\\epsilon^{4}\\omega^{4}}{4} = 1$$\nThe characteristic equation is $\\lambda^{2} - \\text{Tr}(M)\\lambda + \\det(M) = 0$, which simplifies to $\\lambda^{2} - \\text{Tr}(M)\\lambda + 1 = 0$.\nThe trace of $M$ is:\n$$\\text{Tr}(M) = \\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{2}\\right) + \\left(1 - \\frac{\\epsilon^{2}\\omega^{2}}{2}\\right) = 2 - \\epsilon^{2}\\omega^{2}$$\nThe eigenvalues are $\\lambda = \\frac{\\text{Tr}(M) \\pm \\sqrt{\\text{Tr}(M)^{2}-4}}{2}$. For the eigenvalues to lie on the unit circle ($|\\lambda|=1$), they must be complex conjugates of the form $e^{\\pm i\\theta}$. This requires the discriminant of the characteristic equation to be non-positive:\n$$\\text{Tr}(M)^{2} - 4 \\le 0 \\implies \\text{Tr}(M)^{2} \\le 4$$\nThis is equivalent to the condition $|\\text{Tr}(M)| \\le 2$.\nSubstituting the expression for the trace:\n$$|2 - \\epsilon^{2}\\omega^{2}| \\le 2$$\nThis inequality can be written as:\n$$-2 \\le 2 - \\epsilon^{2}\\omega^{2} \\le 2$$\nWe analyze the two parts of the inequality separately.\n$1$. The right-hand side: $2 - \\epsilon^{2}\\omega^{2} \\le 2 \\implies -\\epsilon^{2}\\omega^{2} \\le 0 \\implies \\epsilon^{2}\\omega^{2} \\ge 0$. This is always true for real $\\epsilon$ and $\\omega$.\n$2$. The left-hand side: $-2 \\le 2 - \\epsilon^{2}\\omega^{2} \\implies \\epsilon^{2}\\omega^{2} \\le 4$.\nAssuming $\\epsilon > 0$ and $\\omega > 0$ (as is physically meaningful for a time step and oscillation frequency), we can take the square root of both sides:\n$$\\epsilon\\omega \\le 2$$\nThis gives the condition on the step size for the integrator to be stable:\n$$\\epsilon \\le \\frac{2}{\\omega}$$\nThe maximal stable step size, $\\epsilon_{\\max}$, is the supremum of the set of values of $\\epsilon$ for which the integrator remains stable. This corresponds to the equality in the condition.\nTherefore, the maximal stable step size is:\n$$\\epsilon_{\\max} = \\frac{2}{\\omega}$$\nAt this threshold, $\\epsilon\\omega = 2$, and $\\text{Tr}(M) = 2 - (2)^{2} = -2$. The characteristic equation becomes $\\lambda^2 + 2\\lambda + 1 = (\\lambda+1)^2=0$, giving a degenerate eigenvalue $\\lambda=-1$. For $\\epsilon > \\epsilon_{\\max}$, $\\text{Tr}(M) < -2$, leading to real eigenvalues, one of which has a magnitude greater than $1$, causing the numerical solution to grow exponentially and become unstable.",
            "answer": "$$\\boxed{\\frac{2}{\\omega}}$$"
        },
        {
            "introduction": "A non-exact integrator introduces errors in the numerically-computed Hamiltonian, which directly impacts the Metropolis-Hastings acceptance probability. To build a deeper intuition for parameter tuning, we can model this energy error, $\\Delta H$, and calculate its effect on the sampler's performance. This exercise asks you to derive the expected acceptance rate under a Gaussian error model, revealing how the bias and variance of the energy error shape the behavior of the HMC algorithm.",
            "id": "3311225",
            "problem": "Consider Hamiltonian Monte Carlo (HMC), in which proposals are generated by numerically integrating Hamiltonian dynamics using the leapfrog integrator with a finite step size. Because the integrator is not exact, the change in Hamiltonian over a single proposal, denoted by $\\Delta H$, is a random variable whose distribution depends on integrator parameters such as the step size and the number of leapfrog steps. Assume that $\\Delta H$ is well-approximated by a normal distribution with mean $\\mu$ and variance $\\sigma^{2}$, i.e., $\\Delta H \\sim \\mathcal{N}(\\mu,\\sigma^{2})$, where $\\sigma>0$. In the Metropolis-Hastings (MH) test used by HMC, the acceptance probability for a single proposal is $\\min\\!\\big(1, \\exp(-\\Delta H)\\big)$. \n\nUsing only foundational facts about the MH acceptance function and Gaussian integrals, derive a closed-form analytic expression for the expectation $\\mathbb{E}\\!\\left[\\min\\!\\big(1, \\exp(-\\Delta H)\\big)\\right]$ in terms of $\\mu$ and $\\sigma$. Express your final answer using the cumulative distribution function of a standard normal random variable, denoted by $\\Phi$. Then, from first principles, interpret how the parameters $\\mu$ and $\\sigma$ influence the expected acceptance, discussing the roles of bias and variability in $\\Delta H$ induced by leapfrog parameter tuning. \n\nProvide the exact analytic expression; do not approximate or round. No units are required for the final answer.",
            "solution": "The problem requires the derivation of the expected acceptance probability in a Hamiltonian Monte Carlo (HMC) framework, under the assumption that the change in the Hamiltonian, $\\Delta H$, follows a normal distribution. Subsequently, an interpretation of the result in the context of HMC parameter tuning is requested.\n\nLet the random variable for the change in Hamiltonian be $h \\equiv \\Delta H$. The problem states that $h$ is distributed according to a normal distribution with mean $\\mu$ and variance $\\sigma^2$, where $\\sigma > 0$. The probability density function (PDF) of $h$ is given by:\n$$\np(h) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(h-\\mu)^2}{2\\sigma^2}\\right)\n$$\nThe Metropolis-Hastings acceptance probability for a proposal is $\\alpha(h) = \\min\\!\\big(1, \\exp(-h)\\big)$. We are asked to compute the expectation of this quantity, $\\mathbb{E}[\\alpha(h)]$.\n\nBy definition, the expectation of a function of a continuous random variable is the integral of the function multiplied by the variable's PDF over its support.\n$$\n\\mathbb{E}[\\alpha(h)] = \\int_{-\\infty}^{\\infty} \\min\\!\\big(1, \\exp(-h)\\big) \\, p(h) \\, dh\n$$\nThe $\\min$ function can be split based on its arguments. The condition $\\exp(-h) < 1$ is equivalent to $-h < \\ln(1)$, which simplifies to $-h < 0$, or $h > 0$. Therefore:\n$$\n\\min\\!\\big(1, \\exp(-h)\\big) =\n\\begin{cases}\n1 & \\text{if } h \\le 0 \\\\\n\\exp(-h) & \\text{if } h > 0\n\\end{cases}\n$$\nWe can now split the integral into two parts corresponding to these two cases:\n$$\n\\mathbb{E}[\\alpha(h)] = \\int_{-\\infty}^{0} 1 \\cdot p(h) \\, dh + \\int_{0}^{\\infty} \\exp(-h) \\cdot p(h) \\, dh\n$$\nLet's evaluate each integral separately.\n\nThe first integral, let's call it $I_1$, is:\n$$\nI_1 = \\int_{-\\infty}^{0} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(h-\\mu)^2}{2\\sigma^2}\\right) dh\n$$\nThis integral represents the probability $P(h \\le 0)$. We can evaluate this by standardizing the random variable. Let $z = \\frac{h-\\mu}{\\sigma}$, which implies $dh = \\sigma \\, dz$. The integration limits change as follows: as $h \\to -\\infty$, $z \\to -\\infty$; and when $h = 0$, $z = \\frac{-\\mu}{\\sigma}$.\n$$\nI_1 = \\int_{-\\infty}^{-\\mu/\\sigma} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) dz\n$$\nThis is the definition of the cumulative distribution function (CDF) of a standard normal random variable, denoted by $\\Phi(z)$, evaluated at $z = -\\mu/\\sigma$. Thus,\n$$\nI_1 = \\Phi\\left(-\\frac{\\mu}{\\sigma}\\right)\n$$\n\nThe second integral, $I_2$, is:\n$$\nI_2 = \\int_{0}^{\\infty} \\exp(-h) \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(h-\\mu)^2}{2\\sigma^2}\\right) dh\n$$\nWe can combine the exponential terms:\n$$\n\\exp(-h) \\exp\\left(-\\frac{(h-\\mu)^2}{2\\sigma^2}\\right) = \\exp\\left(-h - \\frac{h^2 - 2h\\mu + \\mu^2}{2\\sigma^2}\\right)\n$$\nThe argument of the exponent is:\n$$\n-\\frac{2\\sigma^2 h + h^2 - 2h\\mu + \\mu^2}{2\\sigma^2} = -\\frac{h^2 - 2(\\mu-\\sigma^2)h + \\mu^2}{2\\sigma^2}\n$$\nWe complete the square for the terms involving $h$ in the numerator: $h^2 - 2(\\mu-\\sigma^2)h = \\left(h - (\\mu-\\sigma^2)\\right)^2 - (\\mu-\\sigma^2)^2$. Substituting this back into the exponent's argument gives:\n$$\n-\\frac{\\left(h - (\\mu-\\sigma^2)\\right)^2 - (\\mu-\\sigma^2)^2 + \\mu^2}{2\\sigma^2} = -\\frac{\\left(h - (\\mu-\\sigma^2)\\right)^2}{2\\sigma^2} + \\frac{(\\mu-\\sigma^2)^2 - \\mu^2}{2\\sigma^2}\n$$\nThe second term simplifies to:\n$$\n\\frac{\\mu^2 - 2\\mu\\sigma^2 + \\sigma^4 - \\mu^2}{2\\sigma^2} = \\frac{\\sigma^4 - 2\\mu\\sigma^2}{2\\sigma^2} = \\frac{\\sigma^2}{2} - \\mu\n$$\nSo, the combined exponential term is:\n$$\n\\exp\\left(-\\mu + \\frac{\\sigma^2}{2}\\right) \\exp\\left(-\\frac{\\left(h - (\\mu-\\sigma^2)\\right)^2}{2\\sigma^2}\\right)\n$$\nNow, substitute this back into the integral for $I_2$:\n$$\nI_2 = \\int_{0}^{\\infty} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\mu + \\frac{\\sigma^2}{2}\\right) \\exp\\left(-\\frac{\\left(h - (\\mu-\\sigma^2)\\right)^2}{2\\sigma^2}\\right) dh\n$$\nThe term $\\exp(-\\mu + \\frac{\\sigma^2}{2})$ is a constant with respect to $h$ and can be factored out. The remaining integrand is the PDF of a normal distribution with mean $\\mu' = \\mu - \\sigma^2$ and variance $\\sigma^2$.\n$$\nI_2 = \\exp\\left(-\\mu + \\frac{\\sigma^2}{2}\\right) \\int_{0}^{\\infty} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(h-\\mu')^2}{2\\sigma^2}\\right) dh\n$$\nThe integral represents the probability $P(X \\ge 0)$ where $X \\sim \\mathcal{N}(\\mu', \\sigma^2)$. We can write this as $1 - P(X < 0)$.\n$P(X < 0)$ is the CDF of this normal distribution evaluated at $0$, which is $\\Phi\\left(\\frac{0 - \\mu'}{\\sigma}\\right) = \\Phi\\left(-\\frac{\\mu - \\sigma^2}{\\sigma}\\right) = \\Phi\\left(\\frac{\\sigma^2 - \\mu}{\\sigma}\\right)$.\nSo the integral part is $1 - \\Phi\\left(\\frac{\\sigma^2 - \\mu}{\\sigma}\\right)$. Using the identity $\\Phi(-z) = 1 - \\Phi(z)$, this is equal to $\\Phi\\left(-\\frac{\\sigma^2 - \\mu}{\\sigma}\\right) = \\Phi\\left(\\frac{\\mu - \\sigma^2}{\\sigma}\\right)$.\nTherefore,\n$$\nI_2 = \\exp\\left(-\\mu + \\frac{\\sigma^2}{2}\\right) \\Phi\\left(\\frac{\\mu - \\sigma^2}{\\sigma}\\right)\n$$\nFinally, we sum the two parts to get the total expected acceptance probability:\n$$\n\\mathbb{E}[\\alpha(h)] = I_1 + I_2 = \\Phi\\left(-\\frac{\\mu}{\\sigma}\\right) + \\exp\\left(-\\mu + \\frac{\\sigma^2}{2}\\right) \\Phi\\left(\\frac{\\mu - \\sigma^2}{\\sigma}\\right)\n$$\n\nFrom first principles, we interpret the influence of the parameters $\\mu$ and $\\sigma$.\nThe parameter $\\mu = \\mathbb{E}[\\Delta H]$ represents the average, or systematic bias, in the energy error introduced by the numerical integrator. For a perfect, time-reversible, and symplectic integrator, the Hamiltonian would be exactly conserved, meaning $\\Delta H=0$. In practice, the leapfrog integrator is not exact for a finite step size, often leading to a small positive bias in energy, $\\mu > 0$. The derivative of the expected acceptance with respect to $\\mu$ is $\\frac{\\partial \\mathbb{E}[\\alpha]}{\\partial \\mu} = -\\exp(-\\mu + \\sigma^2/2) \\Phi(\\frac{\\mu - \\sigma^2}{\\sigma})$, which is non-positive for all valid $\\mu$ and $\\sigma$. This demonstrates that increasing the average energy error $\\mu$ monotonically decreases the expected acceptance probability. This is intuitive: a larger systematic increase in energy makes rejection of a proposed state more likely.\n\nThe parameter $\\sigma = \\sqrt{\\text{Var}(\\Delta H)}$ represents the variability or random fluctuation of the energy error. It is a measure of the numerical instability of the integration. Both $\\mu$ and $\\sigma$ are influenced by integrator parameters, primarily the step size $\\epsilon$. In general, both increase with $\\epsilon$. The influence of $\\sigma$ on the acceptance rate is more complex than that of $\\mu$. In the limit as $\\sigma \\to 0$, the expected acceptance rate converges to $\\min(1, \\exp(-\\mu))$. For a non-zero $\\sigma$, the effect depends on the value of $\\mu$. When $\\mu$ is large and positive, $\\Delta H$ is almost always positive, and the acceptance rate is approximately $\\mathbb{E}[\\exp(-\\Delta H)]$. Since $\\exp(-h)$ is a convex function, Jensen's inequality implies that $\\mathbb{E}[\\exp(-\\Delta H)] \\ge \\exp(-\\mathbb{E}[\\Delta H]) = \\exp(-\\mu)$. In fact, the term $\\exp(\\sigma^2/2)$ in our derived expression shows that for a given $\\mu > 0$, increasing $\\sigma$ can increase the expected acceptance rate. This is because variability introduces a chance for $\\Delta H$ to be smaller than its mean (or even negative), which leads to a disproportionately large increase in the acceptance probability due to the non-linearity of $\\exp(-h)$ and the cap at $1$. However, in the regime where HMC is typically tuned (high acceptance rate, so $\\mu$ is small), an increase in $\\sigma$ introduces more frequent large positive energy errors, which reduces the average acceptance. In HMC tuning, the objective is to make the numerical integration as accurate as possible to ensure high acceptance rates, which means minimizing both the bias $\\mu$ and the variability $\\sigma$ of the energy error.",
            "answer": "$$\n\\boxed{\\Phi\\left(-\\frac{\\mu}{\\sigma}\\right) + \\exp\\left(-\\mu + \\frac{\\sigma^2}{2}\\right) \\Phi\\left(\\frac{\\mu - \\sigma^2}{\\sigma}\\right)}\n$$"
        },
        {
            "introduction": "Tuning the step size $\\epsilon$ by hand is tedious and inefficient, so modern HMC implementations automate this process using sophisticated adaptation schemes. Building on the insight that the acceptance rate is a function of integrator error, we can devise algorithms to find a good step size automatically. This practice provides a hands-on walkthrough of the dual averaging algorithm, allowing you to manually perform the updates and see how the sampler uses past acceptance probabilities to intelligently steer the step size toward an optimal value.",
            "id": "3311213",
            "problem": "Consider Hamiltonian Monte Carlo (HMC) step-size adaptation via the dual averaging scheme used to steer the expected Metropolis acceptance probability toward a target. You are given three synthetic acceptance probability observations $a_1$, $a_2$, and $a_3$, a target acceptance level $\\delta$, and the dual averaging hyperparameters. Assume the standard dual averaging recursion applied to the log step size, with noise terms driven by the discrepancy between the target acceptance level and the observed acceptances, and with the conventional initialization of the dual-averaged statistic at zero.\n\nData and settings:\n- Target acceptance level: $\\delta = 0.8$.\n- Acceptance observations: $a_1 = 0.2$, $a_2 = 0.9$, $a_3 = 0.7$.\n- Dual averaging hyperparameters: $t_0 = 10$, $\\gamma = 0.05$, $\\kappa = 0.75$.\n- Initial step size guess: $\\epsilon_0 = 0.1$.\n- Centering parameter for the log step size: $\\mu = \\ln(10\\,\\epsilon_0)$.\n- Initialize the dual-averaged statistic at zero.\n\nApply three iterations of dual averaging and compute the raw step size $\\epsilon_3$ produced at iteration $t=3$. Round your final answer to four significant figures.",
            "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- Target acceptance level: $\\delta = 0.8$.\n- Acceptance probability observations: $a_1 = 0.2$, $a_2 = 0.9$, $a_3 = 0.7$.\n- Dual averaging hyperparameters: $t_0 = 10$, $\\gamma = 0.05$, $\\kappa = 0.75$.\n- Initial step size guess: $\\epsilon_0 = 0.1$.\n- Centering parameter for the log step size: $\\mu = \\ln(10\\,\\epsilon_0)$.\n- Initialization of the dual-averaged statistic: $\\bar{H}_0 = 0$.\n- Task: Compute the raw step size $\\epsilon_3$ after three iterations of dual averaging and round to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem describes a standard numerical procedure, the dual averaging scheme, used for hyperparameter tuning in statistical algorithms, specifically for adapting the step size in Hamiltonian Monte Carlo (HMC).\n- **Scientifically Grounded**: The algorithm and its context are well-established in the computational statistics and machine learning literature (e.g., Hoffman & Gelman, 2014, \"The No-U-Turn Sampler\"). The formulation is based on standard stochastic approximation theory. The problem is scientifically sound.\n- **Well-Posed**: The problem provides all necessary parameters and initial conditions to uniquely determine the result of the first three iterations of the specified recursive algorithm. The request for a specific output, $\\epsilon_3$, is unambiguous.\n- **Objective**: The problem is stated using precise mathematical and algorithmic terms. There is no subjective or ambiguous language.\n\nThe parameter $\\kappa$ is part of the full dual averaging scheme, where it controls the convergence rate of a separate averaged step size, but it is not required for the calculation of the raw step size $\\epsilon_t$ series. Its inclusion does not create a contradiction but is simply extraneous information for the specific question asked.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe dual averaging scheme adapts the HMC step size $\\epsilon$ to steer the expected Metropolis-Hastings acceptance probability towards a target value $\\delta$. The adaptation is performed on the logarithm of the step size, $\\log \\epsilon$. The core of the algorithm is a set of recursive equations.\n\nLet $t$ be the iteration index. The update equations are:\n1.  The statistic representing the error at iteration $t$ is $H_t = \\delta - a_t$, where $a_t$ is the acceptance probability observed at iteration $t$.\n2.  The dual-averaged statistic $\\bar{H}_t$ is updated via a weighted average:\n    $$ \\bar{H}_t = \\left(1 - \\frac{1}{t + t_0}\\right) \\bar{H}_{t-1} + \\frac{1}{t + t_0} H_t $$\n3.  The logarithm of the raw step size for the next iteration, $\\log \\epsilon_t$, is then determined by:\n    $$ \\log \\epsilon_t = \\mu - \\frac{\\sqrt{t}}{\\gamma} \\bar{H}_t $$\n    where $\\mu$ is a centering point, and $\\gamma$ is a parameter controlling the shrinkage towards $\\mu$.\n\nWe are given the following values:\n- Target acceptance level: $\\delta = 0.8$\n- Observed acceptance probabilities: $a_1 = 0.2$, $a_2 = 0.9$, $a_3 = 0.7$\n- Dual averaging hyperparameters: $t_0 = 10$, $\\gamma = 0.05$\n- Initial step size guess: $\\epsilon_0 = 0.1$\n- Initial dual-averaged statistic: $\\bar{H}_0 = 0$\n\nFirst, we calculate the centering parameter $\\mu$:\n$$ \\mu = \\ln(10\\,\\epsilon_0) = \\ln(10 \\times 0.1) = \\ln(1) = 0 $$\nThis simplifies the subsequent calculations for $\\log \\epsilon_t$.\n\nWe proceed through the iterations to find $\\epsilon_3$.\n\n**Iteration $t=1$:**\n- The acceptance probability is $a_1 = 0.2$.\n- The error statistic is $H_1 = \\delta - a_1 = 0.8 - 0.2 = 0.6$.\n- The dual-averaged statistic $\\bar{H}_1$ is updated from $\\bar{H}_0 = 0$:\n$$ \\bar{H}_1 = \\left(1 - \\frac{1}{1 + 10}\\right) \\bar{H}_0 + \\frac{1}{1 + 10} H_1 = \\left(1 - \\frac{1}{11}\\right)(0) + \\frac{1}{11}(0.6) = \\frac{0.6}{11} $$\n- The log step size $\\log \\epsilon_1$ is computed:\n$$ \\log \\epsilon_1 = \\mu - \\frac{\\sqrt{1}}{\\gamma} \\bar{H}_1 = 0 - \\frac{1}{0.05} \\left(\\frac{0.6}{11}\\right) = -20 \\left(\\frac{0.6}{11}\\right) = -\\frac{12}{11} $$\nThe step size for the next HMC run would be $\\epsilon_1 = \\exp(-\\frac{12}{11})$.\n\n**Iteration $t=2$:**\n- The acceptance probability is $a_2 = 0.9$.\n- The error statistic is $H_2 = \\delta - a_2 = 0.8 - 0.9 = -0.1$.\n- The dual-averaged statistic $\\bar{H}_2$ is updated from $\\bar{H}_1 = \\frac{0.6}{11}$:\n$$ \\bar{H}_2 = \\left(1 - \\frac{1}{2 + 10}\\right) \\bar{H}_1 + \\frac{1}{2 + 10} H_2 = \\frac{11}{12} \\left(\\frac{0.6}{11}\\right) + \\frac{1}{12} (-0.1) $$\n$$ \\bar{H}_2 = \\frac{0.6}{12} - \\frac{0.1}{12} = \\frac{0.5}{12} $$\n- The log step size $\\log \\epsilon_2$ is computed:\n$$ \\log \\epsilon_2 = \\mu - \\frac{\\sqrt{2}}{\\gamma} \\bar{H}_2 = 0 - \\frac{\\sqrt{2}}{0.05} \\left(\\frac{0.5}{12}\\right) = -20\\sqrt{2} \\left(\\frac{0.5}{12}\\right) = -\\frac{10\\sqrt{2}}{12} = -\\frac{5\\sqrt{2}}{6} $$\nThe step size for the next HMC run would be $\\epsilon_2 = \\exp(-\\frac{5\\sqrt{2}}{6})$.\n\n**Iteration $t=3$:**\n- The acceptance probability is $a_3 = 0.7$.\n- The error statistic is $H_3 = \\delta - a_3 = 0.8 - 0.7 = 0.1$.\n- The dual-averaged statistic $\\bar{H}_3$ is updated from $\\bar{H}_2 = \\frac{0.5}{12}$:\n$$ \\bar{H}_3 = \\left(1 - \\frac{1}{3 + 10}\\right) \\bar{H}_2 + \\frac{1}{3 + 10} H_3 = \\frac{12}{13} \\left(\\frac{0.5}{12}\\right) + \\frac{1}{13} (0.1) $$\n$$ \\bar{H}_3 = \\frac{0.5}{13} + \\frac{0.1}{13} = \\frac{0.6}{13} $$\n- The log step size $\\log \\epsilon_3$, which is the quantity needed to find the final answer, is computed:\n$$ \\log \\epsilon_3 = \\mu - \\frac{\\sqrt{3}}{\\gamma} \\bar{H}_3 = 0 - \\frac{\\sqrt{3}}{0.05} \\left(\\frac{0.6}{13}\\right) = -20\\sqrt{3} \\left(\\frac{0.6}{13}\\right) = -\\frac{12\\sqrt{3}}{13} $$\n\nFinally, we compute the raw step size $\\epsilon_3$:\n$$ \\epsilon_3 = \\exp\\left(-\\frac{12\\sqrt{3}}{13}\\right) $$\nTo provide the numerical answer, we evaluate this expression:\n$$ \\epsilon_3 \\approx \\exp\\left(-\\frac{12 \\times 1.7320508}{13}\\right) \\approx \\exp\\left(-\\frac{20.7846096}{13}\\right) \\approx \\exp(-1.5988161) $$\n$$ \\epsilon_3 \\approx 0.20213904 $$\nRounding the result to four significant figures gives $0.2021$.\n\nThe parameter $\\kappa = 0.75$ was not used, as it pertains to the computation of a separate, \"averaged\" step size $\\bar{\\epsilon}_t$, which is not what the problem asks for. The \"raw\" step size $\\epsilon_t$ is determined solely by the recursion shown above.",
            "answer": "$$\\boxed{0.2021}$$"
        }
    ]
}