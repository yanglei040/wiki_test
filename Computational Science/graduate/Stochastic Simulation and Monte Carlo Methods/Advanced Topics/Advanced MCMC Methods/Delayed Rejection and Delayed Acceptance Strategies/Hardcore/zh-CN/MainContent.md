## 引言
[马尔可夫链蒙特卡洛](@entry_id:138779)（MCMC）方法是现代统计推断和计算科学的基石，但标准的[MCMC算法](@entry_id:751788)，如Metropolis-Hastings，在实践中常面临两大瓶颈：一是提议分布选择不当导致的低接受率，使得链的探索效率低下；二是目标概率密度函数本身计算成本高昂，导致采样过程极为耗时。这些问题严重限制了MCMC在处理复杂模型或大规模数据集时的应用。本文旨在深入探讨两种为克服这些挑战而设计的精妙策略：[延迟拒绝](@entry_id:748290)（Delayed Rejection, DR）与[延迟接受](@entry_id:748288)（Delayed Acceptance, DA）。

尽管名称相似，DR与DA针对的问题和采用的机制截然不同。本文将揭示DR如何通过“从失败中学习”来提升[统计效率](@entry_id:164796)，以及DA如何利用“廉价代理”来提升计算效率。通过学习本文，读者将能够理解这两种方法的内在逻辑、适用场景以及它们之间的根本权衡。

文章结构如下：第一章“原理与机制”将深入剖析两种策略的数学构造和理论保证。第二章“应用与跨学科联系”将展示它们在[贝叶斯推断](@entry_id:146958)、无[似然](@entry_id:167119)计算、[机器人学](@entry_id:150623)等前沿领域的实际应用。最后，“动手实践”部分将通过具体问题，帮助读者巩固理论知识并掌握实践技巧。

## 原理与机制

标准的Metropolis-Hastings等马尔可夫链蒙特卡洛（MCMC）算法在实践中可能面临两大挑战：一是由于[提议分布](@entry_id:144814)与[目标分布](@entry_id:634522)失配导致的低接受率，二是目标[概率密度函数](@entry_id:140610) $\pi(x)$ 本身计算成本高昂。这两种情况都会严重影响从[目标分布](@entry_id:634522)中采样的效率。为了应对这些挑战，研究人员发展出了两种精巧的策略，即[延迟拒绝](@entry_id:748290)（Delayed Rejection）和[延迟接受](@entry_id:748288)（Delayed Acceptance）。尽管名称相似，但这两种方法旨在解决不同的问题，并遵循截然不同的机制。本章将深入探讨这两种策略的根本原理、数学构造及其对算法效率的影响。

### [延迟拒绝](@entry_id:748290)：给被拒绝的提议第二次机会

在标准的[Metropolis-Hastings算法](@entry_id:146870)中，当一个提议被拒绝时，马尔可夫链会在当前状态停留一步。如果拒绝频繁发生，链的移动会变得非常缓慢，导致生成的样本具有高度的[自相关](@entry_id:138991)性，从而降低了**[统计效率](@entry_id:164796)**。[延迟拒绝](@entry_id:748290)（Delayed Rejection, DR）策略的核心思想是：与其在拒绝后立即原地踏步，不如利用这次失败提供的信息，尝试进行第二次、可能更优的提议。这相当于给了算法一个“弥补”的机会，旨在通过增加链的移动性来降低样本的自相关性。

#### 广义[细致平衡条件](@entry_id:265158)

为了在引入第二阶段提议后仍能确保链的平稳分布为目标分布 $\pi$，我们必须满足一个比标准[细致平衡条件](@entry_id:265158)更强的约束——**广义[细致平衡条件](@entry_id:265158)（Generalized Detailed Balance Condition）**。标准的细致平衡关注的是任意两状态 $x$ 和 $y$ 之间的[概率流](@entry_id:150949)（flux）平衡。而在[延迟拒绝](@entry_id:748290)中，我们需要平衡的是沿着整个“提议-拒绝-接受”路径的概率流。

让我们考虑一个两阶段的[延迟拒绝](@entry_id:748290)过程。在当前状态 $x$，我们首先从提议分布 $q_1(x, \cdot)$ 中抽取一个候选点 $y_1$。该提议以概率 $\alpha_1(x, y_1)$ 被接受。如果被拒绝（发生概率为 $1 - \alpha_1(x, y_1)$），我们则从第二个提议分布 $q_2(x, y_1, \cdot)$ 中抽取第二个候选点 $y_2$。注意，第二个提议可以依赖于第一个被拒绝的候选点 $y_1$。这个新的候选点 $y_2$ 将以概率 $\alpha_2(x, y_1, y_2)$ 被接受。

为了推导 $\alpha_2$，我们必须平衡从 $x$ 经过拒绝 $y_1$ 最终到达 $y_2$ 的“前向”路径，与从 $y_2$ 经过拒绝 $y_1$ 最终回到 $x$ 的“反向”路径。

前向路径的[概率流密度](@entry_id:152013)为：
$$
\text{Flux}(x \to y_1^{\text{rej}} \to y_2) = \pi(x) \underbrace{q_1(x, y_1) [1 - \alpha_1(x, y_1)]}_{\text{提议并拒绝 } y_1} \underbrace{q_2(x, y_1, y_2) \alpha_2(x, y_1, y_2)}_{\text{提议并接受 } y_2}
$$
反向路径的[概率流密度](@entry_id:152013)为：
$$
\text{Flux}(y_2 \to y_1^{\text{rej}} \to x) = \pi(y_2) \underbrace{q_1(y_2, y_1) [1 - \alpha_1(y_2, y_1)]}_{\text{提议并拒绝 } y_1} \underbrace{q_2(y_2, y_1, x) \alpha_2(y_2, y_1, x)}_{\text{提议并接受 } x}
$$
令这两个[概率流](@entry_id:150949)相等，我们得到广义[细致平衡方程](@entry_id:265021)。为了满足此方程，一个标准的选择是采用Metropolis-Hastings形式的接受率，这使得：
$$
\frac{\alpha_2(x, y_1, y_2)}{\alpha_2(y_2, y_1, x)} = \frac{\pi(y_2) q_1(y_2, y_1) [1 - \alpha_1(y_2, y_1)] q_2(y_2, y_1, x)}{\pi(x) q_1(x, y_1) [1 - \alpha_1(x, y_1)] q_2(x, y_1, y_2)}
$$
由此，我们得到第二阶段的接受率公式  ：
$$
\alpha_2(x, y_1, y_2) = \min\left\{1, \frac{\pi(y_2) q_1(y_2, y_1) [1 - \alpha_1(y_2, y_1)] q_2(y_2, y_1, x)}{\pi(x) q_1(x, y_1) [1 - \alpha_1(x, y_1)] q_2(x, y_1, y_2)}\right\}
$$
第一阶段的接受率 $\alpha_1$ 通常就是标准的Metropolis-Hastings接受率：
$$
\alpha_1(x, y_1) = \min\left\{1, \frac{\pi(y_1) q_1(y_1, x)}{\pi(x) q_1(x, y_1)}\right\}
$$
值得注意的是，尽管计算过程涉及中间变量 $y_1$ 和 $y_2$，但马尔可夫链的状态仍然仅由 $x$ 定义。这些中间变量是单个转移步内的辅助变量，并不会成为链状态的一部分，从而保持了算法的马尔可夫性。

#### 为何朴素的方法会失败：一个反例

一个自然而然的问题是：为什么第二阶段的接受率 $\alpha_2$ 如此复杂？我们能否直接使用一个标准的Metropolis-Hastings接受率，例如 $\alpha_2^{\text{naive}}(x, y_2) = \min\{1, \pi(y_2)/\pi(x)\}$（假设 $q_2$ 对称）？答案是否定的，这样做会破坏[细致平衡条件](@entry_id:265158)，导致链收敛到错误的[分布](@entry_id:182848)。

失败的根源在于，进入第二阶段的**条件**（即第一阶段的拒绝）在正向和反向路径上其概率通常是**不对称的**。让我们通过一个具体的例子来说明这一点  。

考虑一个三[状态空间](@entry_id:177074) $\mathcal{X}=\{0, 1, 2\}$，目标分布为 $\pi(0)=1/2, \pi(1)=3/10, \pi(2)=1/5$。第一阶段提议 $q_1$ 从当前状态均匀选择另外两个状态之一。如果 $y_1$ 被拒绝，则第二阶段确定性地提议第三个状态 $y_2$。假设我们天真地使用 $\alpha_2^{\text{naive}}(x, y_2) = \min\{1, \pi(y_2)/\pi(x)\}$。

我们来检验从状态 $0$ 到状态 $2$ 的第二阶段概率流。这个过程必须是：从 $0$ 提议 $1$ 并拒绝，然后提议 $2$ 并接受。
- 从 $0$ 提议 $1$ 的概率：$q_1(0 \to 1) = 1/2$。
- 接受该提议的概率：$\alpha_1(0 \to 1) = \min\{1, \pi(1)/\pi(0)\} = \min\{1, (3/10)/(1/2)\} = 3/5$。
- 拒绝该提议的概率：$1 - \alpha_1(0 \to 1) = 2/5$。
- 第二阶段接受 $2$ 的朴素概率：$\alpha_2^{\text{naive}}(0, 2) = \min\{1, \pi(2)/\pi(0)\} = \min\{1, (1/5)/(1/2)\} = 2/5$。

因此，从 $0$ 到 $2$ 的第二阶段概率流为：
$$
\text{Flux}(0 \to 2)_{\text{stage 2}} = \pi(0) \cdot q_1(0 \to 1) \cdot [1 - \alpha_1(0 \to 1)] \cdot \alpha_2^{\text{naive}}(0, 2) = \frac{1}{2} \cdot \frac{1}{2} \cdot \frac{2}{5} \cdot \frac{2}{5} = \frac{1}{25} = 0.04
$$
现在我们看反向过程：从状态 $2$ 到状态 $0$ 的第二阶段概率流。这个过程必须是：从 $2$ 提议 $1$ 并拒绝，然后提议 $0$ 并接受。
- 从 $2$ 提议 $1$ 的概率：$q_1(2 \to 1) = 1/2$。
- 接受该提议的概率：$\alpha_1(2 \to 1) = \min\{1, \pi(1)/\pi(2)\} = \min\{1, (3/10)/(1/5)\} = 1$。
- 拒绝该提议的概率：$1 - \alpha_1(2 \to 1) = 0$。

由于从 $2$ 提议 $1$ 的拒绝概率为零，因此链根本不可能从状态 $2$ 通过第二阶段转移到状态 $0$。
$$
\text{Flux}(2 \to 0)_{\text{stage 2}} = \pi(2) \cdot q_1(2 \to 1) \cdot [1 - \alpha_1(2 \to 1)] \cdot \alpha_2^{\text{naive}}(2, 0) = \frac{1}{5} \cdot \frac{1}{2} \cdot 0 \cdot \dots = 0
$$
显然，$0.04 \neq 0$，细致平衡被打破。这个例子清晰地表明，朴素的接受率是错误的。正确的 $\alpha_2$ 公式中的 $[1 - \alpha_1(x, y_1)]$ 和 $[1 - \alpha_1(y_2, y_1)]$ 等项，正是为了补偿这种进入第二阶段的概率不对称性而引入的修正项。忽略它们将导致算法收敛到一个有偏的、错误的平稳分布。

### [延迟接受](@entry_id:748288)：用廉价的代理进行预筛选

与[延迟拒绝](@entry_id:748290)旨在提高[统计效率](@entry_id:164796)不同，[延迟接受](@entry_id:748288)（Delayed Acceptance, DA）的目标是提高**[计算效率](@entry_id:270255)**。它特别适用于目标密度 $\pi(x)$ 的评估（evaluation）本身非常耗时的场景，例如在物理学或复杂贝叶斯模型中。

#### 基本思想与机制

[延迟接受](@entry_id:748288)的核心思想是引入一个计算上“廉价”的代理（surrogate）密度 $\tilde{\pi}(x)$，它能够粗略地近似真实的、计算上“昂贵”的目标密度 $\pi(x)$。算法首先使用这个廉价代理进行快速的预筛选（pre-screening）。只有一个提议通过了这个粗略的筛选，我们才花费昂贵的计算资源来评估真实的 $\pi(x)$ 进行最终的、精确的检验。

具体来说，对于一个从 $x$ 提议的候选点 $y$，它需要通过两道“关卡”才能被接受：
1.  **第一阶段（筛选）**：基于廉价的 $\tilde{\pi}(x)$ 计算接受率 $\alpha_1(x, y)$。
2.  **第二阶段（修正）**：仅当第一阶段接受时，才进行第二阶段检验，计算接受率 $\alpha_2(x, y)$。

一个提议最终被接受，当且仅当它连续通过了两阶段的检验。整个算法的正确性（即最终仍能精确地采样于 $\pi(x)$）依赖于一个精妙的代数构造：对标准Metropolis-Hastings接受率的**[乘法分解](@entry_id:199514)**  。

标准MH的接受率由Hastings比率决定：$r(x, y) = \frac{\pi(y)q(y, x)}{\pi(x)q(x, y)}$。在[延迟接受](@entry_id:748288)中，我们将这个比率分解为两部分：
$$
r(x, y) = r_1(x, y) \cdot r_2(x, y)
$$
一个有效的分解方式是：
$$
r_1(x, y) = \frac{\tilde{\pi}(y)q(y, x)}{\tilde{\pi}(x)q(x, y)} \quad \text{和} \quad r_2(x, y) = \frac{\pi(y)\tilde{\pi}(x)}{\pi(x)\tilde{\pi}(y)}
$$
第一阶段的接受率被设置为 $\alpha_1(x, y) = \min\{1, r_1(x, y)\}$，它只涉及廉价的 $\tilde{\pi}$ 和提议分布 $q$。第二阶段的接受率则为 $\alpha_2(x, y) = \min\{1, r_2(x, y)\}$。它包含了昂贵的 $\pi$，但只有在第一阶段通过时才需要计算。这种构造通过在第二阶段引入修正因子 $\tilde{\pi}(x)/\tilde{\pi}(y)$，精确地“抵消”了第一阶段使用近似[分布](@entry_id:182848) $\tilde{\pi}$ 所带来的偏差。

#### 代理[分布](@entry_id:182848)的条件：正确性的关键

为了保证[延迟接受算法](@entry_id:638056)的正确性（无偏性），代理[分布](@entry_id:182848) $\tilde{\pi}$ 必须满足某些条件，但这些条件可能与直觉不完全相符  。

1.  **支撑集条件 (Support Condition)**：一个至关重要的要求是，代理[分布](@entry_id:182848)的支撑集必须包含目标分布的支撑集。即，如果 $\pi(x) > 0$，那么必须有 $\tilde{\pi}(x) > 0$。如果这个条件不满足，算法将是有偏的。例如，假设存在一个状态 $c$，使得 $\pi(c) > 0$ 但 $\tilde{\pi}(c) = 0$。那么，任何从其他状态 $x$ 到 $c$ 的提议，在第一阶段的接受率 $\alpha_1(x, c)$ 的计算中，其比率 $r_1$ 的分子将为零。因此 $\alpha_1(x, c) = 0$。这意味着链永远无法转移到状态 $c$。如果链的初始状态不在 $c$，它将永远无法访问状态空间中一个具有正概率的区域，这破坏了算法的遍历性（irreducibility），导致其无法收敛到正确的[分布](@entry_id:182848) $\pi$ 。

2.  **无需无偏性和归一化**：与某些其他方法（如[伪边缘方法](@entry_id:753838)）不同，[延迟接受](@entry_id:748288)**不要求**代理 $\tilde{\pi}$ 是 $\pi$ 的无偏估计。算法的正确性来自于第二阶段的确定性代数修正，而非期望意义上的抵消。同样，$\tilde{\pi}$ 也**无需**被归一化（即积分不一定为1），因为在所有接受率的计算中都只使用了 $\tilde{\pi}$ 的比率，任何归一化常数都会被约掉。

3.  **近似质量仅影响效率**：$\tilde{\pi}$ 与 $\pi$ 的接近程度不影响算法的**正确性**，只影响其**效率**。一个非常糟糕的代理（只要满足支撑集条件）仍然会产生一个理论上正确的算法，但其第一阶段的筛选可能会过于严苛或过于宽松，导致总接受率极低，或节省的计算量微乎其微。一个好的代理则能在保持高接受率的同时，有效过滤掉大量不良提议，从而显著提升计算效率。

#### 一个量化节约的例子

为了更具体地理解计算效率的提升，我们考虑一个例子 。假设目标分布是一维高斯分布 $\pi(x) \propto \exp(-x^2 / (2\sigma^2))$，代理[分布](@entry_id:182848)是另一个[方差](@entry_id:200758)较小的高斯分布 $\tilde{\pi}(x) \propto \exp(-x^2 / (2\tau^2))$，其中 $0  \tau^2  \sigma^2$。提议分布是对称的[随机游走](@entry_id:142620) $q(y|x) = \mathcal{N}(x, s^2)$。

在这种情况下，从 $x=0$ 出发，总接受率可以被计算为 $\alpha_{\mathrm{DA}}(0, y) = \exp(-y^2 / (2\tau^2))$。昂贵的 $\pi$ 的评估成本为 $c_e$，廉价的 $\tilde{\pi}$ 的评估成本为 $c_s$。标准MH算法每次提议的成本是 $c_s + c_e$（假设提议成本为 $c_s$）。而在DA算法中，只有第一阶段接受时才产生 $c_e$ 的成本。第一阶段的[接受概率](@entry_id:138494)为 $\alpha_1(0, y) = \exp(-y^2/(2\tau^2))$。对提议分布 $y \sim \mathcal{N}(0, s^2)$ 求期望，可以得到第一阶段的平均[接受概率](@entry_id:138494)为 $\tau / \sqrt{s^2 + \tau^2}$。

因此，相对于标准MH算法，DA算法的预期成本节省分数 $F$ 为：
$$
F = 1 - \frac{c_s}{c_e} - \frac{\tau}{\sqrt{s^2+\tau^2}}
$$
这个公式清晰地显示了节省量如何依赖于成本比率 $c_s/c_e$ 以及代理质量和提议步长的相互作用（由 $\tau$ 和 $s$ 体现）。

### 效率对比：Peskun 排序的视角

我们已经看到，DR旨在提高[统计效率](@entry_id:164796)，而DA旨在提高计算效率。这种效率上的此消彼长可以通过**[Peskun排序](@entry_id:753366)**（Peskun ordering）这一理论工具进行更严格的刻画 。

对于两个都以 $\pi$ 为[平稳分布](@entry_id:194199)的[可逆马尔可夫链](@entry_id:198392)核 $P_1$ 和 $P_2$，如果对于所有状态 $x$ 和所有不包含 $x$ 的[可测集](@entry_id:159173) $A$，都有 $P_1(x, A) \ge P_2(x, A)$，我们就说 $P_1$ 在Peskun意义上优于（Peskun-dominates）$P_2$。这个条件的直观含义是，$P_1$ 对应的链有更高的概率离开当前状态。Peskun定理指出，如果 $P_1$ Peskun-优于 $P_2$，那么对于任何合适的函数 $f$，由 $P_1$ 产生的估计量的[渐近方差](@entry_id:269933)将小于或等于由 $P_2$ 产生的估计量，即 $\sigma_{P_1}^2(f) \le \sigma_{P_2}^2(f)$。这意味着 $P_1$ 具有更高的[统计效率](@entry_id:164796)。

- **[延迟拒绝](@entry_id:748290) (DR) vs. 标准MH**：DR核的转移概率 $P_{\mathrm{DR}}(x, A)$ 是标准MH核的转移概率 $P_{\mathrm{MH}}(x, A)$ 加上一个由第二阶段贡献的非负项。因此，显然有 $P_{\mathrm{DR}}(x, A) \ge P_{\mathrm{MH}}(x, A)$。这意味着DR总是在Peskun意义上优于或等于标准的MH算法。**[延迟拒绝](@entry_id:748290)从不降低[统计效率](@entry_id:164796)，通常会提升它。**

- **[延迟接受](@entry_id:748288) (DA) vs. 标准MH**：DA的总接受率 $\alpha_{\mathrm{DA}}(x,y) = \alpha_1(x,y)\alpha_2(x,y)$。由于 $\alpha_1 \le 1$ 且 $\alpha_2 \le 1$，所以 $\alpha_{\mathrm{DA}}(x,y)$ 必然小于或等于标准MH算法的接受率 $\alpha_{\mathrm{MH}}(x,y)$（后者可被视为DA的一个特例，其中 $\tilde{\pi}=\pi$）。因此，$P_{\mathrm{DA}}(x, A) \le P_{\mathrm{MH}}(x, A)$。这意味着标准MH算法在Peskun意义上优于DA算法。**[延迟接受](@entry_id:748288)通常以牺牲[统计效率](@entry_id:164796)为代价。**

#### 总结：没有免费的午餐

[延迟拒绝](@entry_id:748290)和[延迟接受](@entry_id:748288)是[MCMC方法](@entry_id:137183)工具箱中两种功能强大但目标迥异的策略。
- **[延迟拒绝](@entry_id:748290)**通过在每次迭代中投入可能更多的计算（当第一阶段被拒绝时），来换取更高的[统计效率](@entry_id:164796)（更低的样本自相关性）。当生成样本的计算成本相对较低，但链的混合速度是主要瓶颈时，DR是一个极具吸[引力](@entry_id:175476)的选择。
- **[延迟接受](@entry_id:748288)**则通过牺牲[统计效率](@entry_id:164796)（接受率降低，样本相关性增加），来换取更高的[计算效率](@entry_id:270255)（降低了每次迭代的平均成本）。当目标函数的评估是整个过程的主要计算瓶颈时，DA是加速采样的关键技术。

理解这两种策略的内在机制和它们之间的根本权衡，对于在具体的科学和工程问题中设计和实施高效的[MCMC算法](@entry_id:751788)至关重要。