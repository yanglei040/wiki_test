{
    "hands_on_practices": [
        {
            "introduction": "To build a solid foundation, our first practice involves a direct, first-principles analysis of the Propp-Wilson algorithm. We will examine a simple birth-death Markov chain on a three-state space, where the update function is explicitly defined and guaranteed to be monotone . The objective is to analyze the \"sandwiching\" process, where we track the coupled evolution of the lowest and highest possible states, and to derive an exact analytical expression for the probability that these two extremal chains coalesce by a given time $t$. This exercise demystifies the core mechanism of CFTP by making the dynamics of the coupled system fully transparent.",
            "id": "3356322",
            "problem": "Consider a time-homogeneous birth–death Markov chain on the finite partially ordered state space $\\{0,1,2\\}$, with the following transition probabilities at each discrete time step:\n- From state $0$: move to $1$ with probability $1/2$, stay at $0$ with probability $1/2$.\n- From state $1$: move to $0$ with probability $1/4$, stay at $1$ with probability $1/4$, move to $2$ with probability $1/2$.\n- From state $2$: move to $1$ with probability $1/2$, stay at $2$ with probability $1/2$.\n\nAssume the update rule is implemented by a single collection of independent and identically distributed random inputs: at each time $n$, an input $U_{n}$ is drawn from the Uniform$(0,1)$ distribution, and the next state is given by a threshold mapping $F(i,U_{n})$ defined for each current state $i \\in \\{0,1,2\\}$ as follows:\n$$\nF(0,u) = \\begin{cases}\n0,  0 \\le u  \\tfrac{1}{2},\\\\\n1,  \\tfrac{1}{2} \\le u \\le 1,\n\\end{cases}\n\\quad\nF(1,u) = \\begin{cases}\n0,  0 \\le u  \\tfrac{1}{4},\\\\\n1,  \\tfrac{1}{4} \\le u  \\tfrac{1}{2},\\\\\n2,  \\tfrac{1}{2} \\le u \\le 1,\n\\end{cases}\n\\quad\nF(2,u) = \\begin{cases}\n1,  0 \\le u  \\tfrac{1}{2},\\\\\n2,  \\tfrac{1}{2} \\le u \\le 1.\n\\end{cases}\n$$\n\nThis update function is monotone with respect to the natural order on $\\{0,1,2\\}$, so the Propp–Wilson Coupling From The Past (CFTP) method can be implemented using the sandwiching approach: given a time horizon $t \\in \\mathbb{N}$, start at time $-t$ with the lower and upper bounding states $L_{0}=0$ and $U_{0}=2$, and apply the same update inputs $U_{-t}, U_{-(t-1)}, \\dots, U_{-1}$ forward to time $0$ to obtain the bounding images $L_{t}$ and $U_{t}$. Coalescence by time $t$ occurs if and only if $L_{t} = U_{t}$.\n\nUsing only the foundational definitions of monotone Markov chains, the Propp–Wilson CFTP, and the above update rule, derive from first principles the exact closed-form expression (as a function of $t$) for the probability that coalescence occurs by time $t$ under this sandwiching scheme. Your final answer must be a single analytic expression. No rounding is required and no units should be included.",
            "solution": "The problem asks for the probability of coalescence by time $t$ for a Propp-Wilson Coupling From The Past (CFTP) process. The process is defined on the state space $S = \\{0, 1, 2\\}$ with the natural ordering $0 \\le 1 \\le 2$. The CFTP algorithm is implemented using a sandwiching approach, starting with a lower chain $L$ and an upper chain $U$ at the extremal states. The simulation runs for a time horizon of $t$ steps, from time $-t$ to time $0$.\n\nLet the state of the lower chain at a given time be denoted by $l$ and the upper chain by $u$. The simulation starts at time $-t$ with $l_{-t} = 0$ and $u_{-t} = 2$. At each step $k$ from $-t$ to $-1$, both chains are updated using the same random number $U_k \\sim \\text{Uniform}(0,1)$ and the monotone update function $F(i,u)$. Let the states of the chains after $n$ steps of the simulation (i.e., at time $-t+n$) be $(l_n, u_n)$. The initial state of this pair-process is $(l_0, u_0) = (0,2)$. The state after $n$ steps is $(l_n, u_n) = (F(l_{n-1}, U_{n-1}), F(u_{n-1}, U_{n-1}))$. We are interested in the probability that the chains coalesce after $t$ steps, i.e., $P(l_t = u_t)$.\n\nDue to the monotonicity of $F$, we are guaranteed that $l_n \\le u_n$ for all $n \\ge 0$. The state of the pair-process $(l_n, u_n)$ is an element of $\\{(i,j) \\in S \\times S \\mid i \\le j\\}$.\nCoalescence occurs when $l_n = u_n$. The states $(0,0)$, $(1,1)$, and $(2,2)$ are therefore absorbing states for the pair-process. Once a pair $(i,i)$ is reached, all subsequent states will be $(F(i,U), F(i,U))$, which means the chains remain coalesced.\n\nThe non-coalesced, or transient, states for the pair-process are $(0,1)$, $(0,2)$, and $(1,2)$. Let us analyze the transitions between these transient states. Let the random variable $U$ be drawn from $\\text{Uniform}(0,1)$. The next state $(l', u')$ is given by $(F(l,U), F(u,U))$.\n\nLet's define three states for our analysis of the non-coalesced dynamics:\n- State $A$: The pair is $(0,2)$.\n- State $B$: The pair is $(0,1)$.\n- State $C$: The pair is $(1,2)$.\n- State $D$: The chains have coalesced (the pair is in $\\{(0,0), (1,1), (2,2)\\}$). State $D$ is absorbing.\n\nThe initial state of the simulation is $(l_0, u_0) = (0,2)$, which is State $A$.\n\nWe now compute the single-step transition probabilities for states $A, B, C$.\n1.  From State $A = (0,2)$:\n    - If $U \\in [0, \\frac{1}{2})$: $l' = F(0,U)=0$, $u' = F(2,U)=1$. The new state is $(0,1)$, which is $B$. The probability is $P(U  \\frac{1}{2}) = \\frac{1}{2}$.\n    - If $U \\in [\\frac{1}{2}, 1]$: $l' = F(0,U)=1$, $u' = F(2,U)=2$. The new state is $(1,2)$, which is $C$. The probability is $P(U \\ge \\frac{1}{2}) = \\frac{1}{2}$.\n    - Transition Summary: $P(A \\to A) = 0$, $P(A \\to B) = \\frac{1}{2}$, $P(A \\to C) = \\frac{1}{2}$, $P(A \\to D) = 0$.\n\n2.  From State $B = (0,1)$:\n    - If $U \\in [0, \\frac{1}{4})$: $l' = F(0,U)=0$, $u' = F(1,U)=0$. The new state is $(0,0)$, which is $D$ (coalescence). The probability is $P(U  \\frac{1}{4}) = \\frac{1}{4}$.\n    - If $U \\in [\\frac{1}{4}, \\frac{1}{2})$: $l' = F(0,U)=0$, $u' = F(1,U)=1$. The new state is $(0,1)$, which is $B$. The probability is $P(\\frac{1}{4} \\le U  \\frac{1}{2}) = \\frac{1}{4}$.\n    - If $U \\in [\\frac{1}{2}, 1]$: $l' = F(0,U)=1$, $u' = F(1,U)=2$. The new state is $(1,2)$, which is $C$. The probability is $P(U \\ge \\frac{1}{2}) = \\frac{1}{2}$.\n    - Transition Summary: $P(B \\to B) = \\frac{1}{4}$, $P(B \\to C) = \\frac{1}{2}$, $P(B \\to D) = \\frac{1}{4}$.\n\n3.  From State $C = (1,2)$:\n    - If $U \\in [0, \\frac{1}{4})$: $l' = F(1,U)=0$, $u' = F(2,U)=1$. The new state is $(0,1)$, which is $B$. The probability is $P(U  \\frac{1}{4}) = \\frac{1}{4}$.\n    - If $U \\in [\\frac{1}{4}, \\frac{1}{2})$: $l' = F(1,U)=1$, $u' = F(2,U)=1$. The new state is $(1,1)$, which is $D$ (coalescence). The probability is $P(\\frac{1}{4} \\le U  \\frac{1}{2}) = \\frac{1}{4}$.\n    - If $U \\in [\\frac{1}{2}, 1]$: $l' = F(1,U)=2$, $u' = F(2,U)=2$. The new state is $(2,2)$, which is $D$ (coalescence). The probability is $P(U \\ge \\frac{1}{2}) = \\frac{1}{2}$.\n    - Transition Summary: $P(C \\to B) = \\frac{1}{4}$, $P(C \\to D) = \\frac{1}{4} + \\frac{1}{2} = \\frac{3}{4}$.\n\nLet $p_n(S)$ be the probability of being in a transient state $S \\in \\{A, B, C\\}$ after $n$ steps. Let $v_n = [p_n(A), p_n(B), p_n(C)]^T$ be the column vector of these probabilities. The evolution of this vector is given by $v_{n+1} = T v_n$, where $T$ is the transition matrix for the transient states.\n$$\nT = \\begin{pmatrix}\nP(A \\to A)  P(B \\to A)  P(C \\to A) \\\\\nP(A \\to B)  P(B \\to B)  P(C to B) \\\\\nP(A \\to C)  P(B \\to C)  P(C \\to C)\n\\end{pmatrix} = \\begin{pmatrix}\n0  0  0 \\\\\n\\frac{1}{2}  \\frac{1}{4}  \\frac{1}{4} \\\\\n\\frac{1}{2}  \\frac{1}{2}  0\n\\end{pmatrix}\n$$\nThe simulation starts in state $A$, so the initial probability vector is $v_0 = [1, 0, 0]^T$. After $t$ steps, the vector of probabilities is $v_t = T^t v_0$. The probability of not having coalesced by time $t$, $S_t$, is the sum of the components of $v_t$. The desired probability of coalescence is $P_c(t) = 1 - S_t$.\n\nTo compute $T^t$, we find the eigenvalues and eigenvectors of $T$. The characteristic equation is $\\det(T - \\lambda I) = 0$:\n$$ \\det \\begin{pmatrix} -\\lambda  0  0 \\\\ \\frac{1}{2}  \\frac{1}{4}-\\lambda  \\frac{1}{4} \\\\ \\frac{1}{2}  \\frac{1}{2}  -\\lambda \\end{pmatrix} = -\\lambda \\left( \\left(\\frac{1}{4}-\\lambda\\right)(-\\lambda) - \\left(\\frac{1}{4}\\right)\\left(\\frac{1}{2}\\right) \\right) = -\\lambda \\left( \\lambda^2 - \\frac{1}{4}\\lambda - \\frac{1}{8} \\right) = 0 $$\nThe eigenvalues are $\\lambda_3 = 0$ and the roots of $8\\lambda^2 - 2\\lambda - 1 = 0$, which are $\\lambda = \\frac{2 \\pm \\sqrt{4 - 4(8)(-1)}}{16} = \\frac{2 \\pm 6}{16}$.\nSo, the eigenvalues are $\\lambda_1 = \\frac{8}{16} = \\frac{1}{2}$, $\\lambda_2 = \\frac{-4}{16} = -\\frac{1}{4}$, and $\\lambda_3 = 0$.\n\nNext, we find the corresponding eigenvectors:\n- For $\\lambda_1 = \\frac{1}{2}$: $(T - \\frac{1}{2}I)x = 0$ leads to the eigenvector $e_1 = [0, 1, 1]^T$.\n- For $\\lambda_2 = -\\frac{1}{4}$: $(T + \\frac{1}{4}I)x = 0$ leads to the eigenvector $e_2 = [0, 1, -2]^T$.\n- For $\\lambda_3 = 0$: $Tx = 0$ leads to the eigenvector $e_3 = [1, -1, -1]^T$.\n\nWe express the initial vector $v_0$ as a linear combination of eigenvectors: $v_0 = c_1 e_1 + c_2 e_2 + c_3 e_3$.\n$$ \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = c_1 \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix} + c_2 \\begin{pmatrix} 0 \\\\ 1 \\\\ -2 \\end{pmatrix} + c_3 \\begin{pmatrix} 1 \\\\ -1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} c_3 \\\\ c_1 + c_2 - c_3 \\\\ c_1 - 2c_2 - c_3 \\end{pmatrix} $$\nThis gives a system of linear equations for $(c_1, c_2, c_3)$, which solves to $c_1=1$, $c_2=0$, $c_3=1$.\nSo, $v_0 = e_1 + e_3$.\n\nNow we can compute $v_t = T^t v_0$:\n$$ v_t = T^t(e_1 + e_3) = T^t e_1 + T^t e_3 = \\lambda_1^t e_1 + \\lambda_3^t e_3 $$\nThe problem specifies $t \\in \\mathbb{N}$, which is typically interpreted as $t \\ge 1$. For $t \\ge 1$, $\\lambda_3^t = 0^t = 0$.\n$$ v_t = \\left(\\frac{1}{2}\\right)^t e_1 = \\left(\\frac{1}{2}\\right)^t \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ (\\frac{1}{2})^t \\\\ (\\frac{1}{2})^t \\end{pmatrix} $$\nThis vector gives the probabilities of being in states $A, B, C$ after $t$ steps.\n$p_t(A) = 0$, $p_t(B) = (\\frac{1}{2})^t$, $p_t(C) = (\\frac{1}{2})^t$.\n\nThe probability of not having coalesced by time $t$, $S_t$, is the sum of these probabilities:\n$$ S_t = p_t(A) + p_t(B) + p_t(C) = 0 + \\left(\\frac{1}{2}\\right)^t + \\left(\\frac{1}{2}\\right)^t = 2 \\left(\\frac{1}{2}\\right)^t = \\left(\\frac{1}{2}\\right)^{t-1} $$\nThis result is valid for $t \\ge 1$.\n\nFinally, the probability that coalescence occurs by time $t$, $P_c(t)$, is $1$ minus the probability of not having coalesced:\n$$ P_c(t) = 1 - S_t = 1 - \\left(\\frac{1}{2}\\right)^{t-1} $$\nThis can be rewritten as $1 - 2^{1-t}$. This is the closed-form expression for the coalescence probability as a function of the time horizon $t$.\nFor $t=1$, $P_c(1) = 1 - 2^0 = 0$. This is correct, as the first step can only lead to non-coalesced states $(0,1)$ or $(1,2)$.\nFor $t \\to \\infty$, $P_c(t) \\to 1$, as expected for an irreducible and aperiodic finite-state Markov chain.",
            "answer": "$$\n\\boxed{1 - 2^{1-t}}\n$$"
        },
        {
            "introduction": "While monotone coupling is powerful, it is not universally applicable. This practice explores the boundaries of the standard Propp-Wilson algorithm by examining a system where monotonicity does not hold: the antiferromagnetic Ising model on a non-bipartite graph . This scenario introduces the concept of \"frustration,\" where it is impossible to transform the system into a monotone (ferromagnetic) one. This exercise is crucial for understanding the limitations of basic CFTP and appreciating the need for more advanced methods, such as Dominated Coupling From The Past (DCFTP), which can provide exact samples even in the absence of a global monotone structure.",
            "id": "3356306",
            "problem": "Consider an undirected finite graph $G=(V,E)$ and the Ising model with spins $\\sigma_i \\in \\{-1,+1\\}$ for $i \\in V$, Gibbs distribution proportional to $\\exp\\big(\\sum_{\\{i,j\\}\\in E} J_{ij}\\sigma_i\\sigma_j + \\sum_{i\\in V} h_i \\sigma_i\\big)$, and single-site heat-bath Glauber dynamics. Recall the following foundational notions.\n\n- A Markov chain update is monotone with respect to the product partial order on $\\{-1,+1\\}^V$ if, when two configurations satisfy $\\sigma \\le \\tau$ coordinatewise, then the update map at any site $i$ can be coupled so that the post-update spins also satisfy $\\sigma' \\le \\tau'$ almost surely. For the Ising heat-bath update at site $i$, the conditional probability $p_i(\\sigma_{-i}) := \\mathbb{P}(\\sigma_i=+1 \\mid \\sigma_{-i})$ is nondecreasing in each neighbor spin $\\sigma_j$ if and only if the couplings $\\{J_{ij}\\}_{j\\sim i}$ are all nonnegative.\n\n- A node-wise sign transformation is a map $\\tau_i = s_i \\sigma_i$ with $s_i \\in \\{-1,+1\\}$ for each $i \\in V$, which sends couplings to $J'_{ij} = J_{ij} s_i s_j$ and fields to $h'_i = h_i s_i$.\n\n- A graph $G$ is bipartite if and only if its vertex set admits a $2$-coloring $V = U \\cup W$ such that every edge has one endpoint in $U$ and one in $W$. Equivalently, $G$ contains no odd cycle.\n\n- The Propp–Wilson algorithm for Coupling From The Past (CFTP) in its monotone form requires a partial order with top and bottom elements and a monotone update map to ensure coalescence from extremal initial states. Dominated Coupling From The Past (DCFTP) constructs a backward-in-time dependency graph controlled by a stochastically dominating process; if this backward exploration almost surely terminates, an exact sample can be produced without monotonicity.\n\nFocus on the antiferromagnetic case on the triangle $C_3$ with uniform pairwise couplings $J_{ij} = -\\beta$ for all $\\{i,j\\}\\in E$ and external fields $h_i=0$ for all $i\\in V$, where $\\beta0$ is fixed. Analyze the effect of non-bipartiteness on the existence of monotone transformations and on the feasibility of perfect sampling.\n\nWhich of the following statements are correct?\n\nA. There exists a choice of signs $\\{s_i\\}_{i\\in V}$ such that the node-wise sign transformation $\\tau_i = s_i \\sigma_i$ sends the antiferromagnetic Ising model on $C_3$ into a ferromagnetic model with $J'_{ij} \\ge 0$ for all $\\{i,j\\}\\in E$, thereby enabling monotone Propp–Wilson CFTP from the top and bottom elements.\n\nB. On any non-bipartite graph, and in particular on $C_3$, no node-wise sign transformation can make all transformed couplings $J'_{ij}$ nonnegative when all original couplings $J_{ij}0$. Consequently, the heat-bath update is not attractive under any product order, and the standard monotone Propp–Wilson CFTP with top and bottom bounding chains cannot be applied.\n\nC. Even without attractiveness, for sufficiently small $\\beta$ (high temperature), there exist perfect simulation schemes based on Dominated Coupling From The Past (DCFTP) that construct a backward dependency graph dominated by a subcritical branching process guaranteed to die out almost surely, yielding exact samples for the antiferromagnetic Ising model on $C_3$.\n\nD. The failure of bipartiteness implies the nonexistence of any perfect sampling algorithm for the model on $C_3$, since monotonicity is a necessary condition for perfect sampling.\n\nE. By modifying the dynamics to block-update two adjacent spins at a time with a heat-bath rule, one always recovers a monotone update map on $C_3$, so monotone Propp–Wilson CFTP becomes applicable regardless of $\\beta$.",
            "solution": "The problem asks for an analysis of the antiferromagnetic Ising model on a triangle graph $C_3$ concerning the applicability of perfect sampling algorithms like Coupling From The Past (CFTP).\n\nThe model is defined on the graph $G=(V,E)$ where $V=\\{1,2,3\\}$ and $E=\\{\\{1,2\\}, \\{2,3\\}, \\{3,1\\}\\}$. The Gibbs distribution is proportional to $\\exp\\big(\\sum_{\\{i,j\\}\\in E} J_{ij}\\sigma_i\\sigma_j\\big)$ with couplings $J_{ij} = -\\beta$ for a constant $\\beta0$ and external fields $h_i=0$. The Hamiltonian is $H(\\sigma) = -\\sum_{\\{i,j\\}\\in E} J_{ij}\\sigma_i\\sigma_j = \\beta(\\sigma_1\\sigma_2 + \\sigma_2\\sigma_3 + \\sigma_3\\sigma_1)$. The system seeks to minimize this energy, which favors anti-alignment of neighboring spins, typical of an antiferromagnet.\n\nThe standard monotone Propp-Wilson CFTP algorithm for single-site heat-bath dynamics requires the update rule to be monotone. This holds if and only if all couplings $J_{ij}$ are non-negative (ferromagnetic model). The problem explores whether the given antiferromagnetic model can be rendered ferromagnetic via a node-wise sign transformation $\\tau_i = s_i \\sigma_i$, where $s_i \\in \\{-1, +1\\}$. Such a transformation changes the couplings to $J'_{ij} = J_{ij} s_i s_j$. For our model, $J'_{ij} = (-\\beta) s_i s_j$. To make these non-negative, we need $s_i s_j = -1$ for all adjacent pairs $\\{i,j\\}$. This implies that adjacent vertices must have different signs. This is equivalent to finding a $2$-coloring for the graph $G$. A graph is $2$-colorable if and only if it is bipartite (contains no odd-length cycles). The graph $C_3$ is a cycle of length $3$, which is odd, and thus it is not bipartite. Therefore, it is impossible to find signs $\\{s_i\\}$ that make all transformed couplings $J'_{ij}$ non-negative. This phenomenon, where antiferromagnetic interactions on a non-bipartite graph cannot all be simultaneously satisfied, is called frustration.\n\nNow we evaluate each statement.\n\n**A. There exists a choice of signs $\\{s_i\\}_{i\\in V}$ such that the node-wise sign transformation $\\tau_i = s_i \\sigma_i$ sends the antiferromagnetic Ising model on $C_3$ into a ferromagnetic model with $J'_{ij} \\ge 0$ for all $\\{i,j\\}\\in E$, thereby enabling monotone Propp–Wilson CFTP from the top and bottom elements.**\n\nAs demonstrated, such a sign transformation is equivalent to finding a $2$-coloring of the graph $C_3$. Since $C_3$ is an odd cycle, it is not bipartite and thus not $2$-colorable. No such choice of signs $\\{s_i\\}$ exists. The product of the required sign relations along the cycle gives $(s_1 s_2)(s_2 s_3)(s_3 s_1) = (-1)^3 = -1$, while algebraically the expression is $s_1^2 s_2^2 s_3^2=1$, a contradiction. Therefore, the model cannot be transformed into a ferromagnetic one, and this route to applying monotone CFTP is closed.\n**Verdict: Incorrect.**\n\n**B. On any non-bipartite graph, and in particular on $C_3$, no node-wise sign transformation can make all transformed couplings $J'_{ij}$ nonnegative when all original couplings $J_{ij}0$. Consequently, the heat-bath update is not attractive under any product order, and the standard monotone Propp–Wilson CFTP with top and bottom bounding chains cannot be applied.**\n\nThis statement is correct. The first part is the general principle of frustration discussed above: an antiferromagnetic model on a non-bipartite graph cannot be gauge-transformed into a ferromagnetic one. The second part is a direct consequence. The attractiveness (monotonicity) of single-site heat-bath dynamics with respect to the standard product order on $\\{-1,+1\\}^V$ requires all couplings $J_{ij}$ to be non-negative. Attractiveness with respect to a different product order (related by signs $\\{s_i\\}$) is equivalent to attractiveness of the transformed variables $\\{\\tau_i\\}$ with respect to the standard order, which requires all $J'_{ij}$ to be non-negative. Since this cannot be achieved, the dynamics are not attractive under any product order. The standard monotone Propp-Wilson CFTP algorithm's mechanism of coupling chains starting from the extremal states (all $+1$s and all $-1$s) relies fundamentally on this attractiveness property. Without it, the algorithm is not applicable in its standard form.\n**Verdict: Correct.**\n\n**C. Even without attractiveness, for sufficiently small $\\beta$ (high temperature), there exist perfect simulation schemes based on Dominated Coupling From The Past (DCFTP) that construct a backward dependency graph dominated by a subcritical branching process guaranteed to die out almost surely, yielding exact samples for the antiferromagnetic Ising model on $C_3$.**\n\nThis statement correctly describes an alternative perfect sampling method, DCFTP, which does not require monotonicity. Its convergence depends on the dependencies in the system being sufficiently weak. For the Ising model, this corresponds to the high-temperature regime (small $\\beta$). In this regime, the system satisfies conditions like the Dobrushin uniqueness condition, which implies that the influence of any single spin on another decays rapidly. The backward dependency exploration of DCFTP can then be stochastically dominated by a simple process, like a Galton-Watson branching process. If the expected number of \"offspring\" in this dominating process is less than $1$ (i.e., it is subcritical), the process dies out almost surely, meaning the DCFTP algorithm terminates and produces an exact sample. For any finite-range Ising model on a finite graph, including our case on $C_3$, such a high-temperature regime always exists for sufficiently small $\\beta$.\n**Verdict: Correct.**\n\n**D. The failure of bipartiteness implies the nonexistence of any perfect sampling algorithm for the model on $C_3$, since monotonicity is a necessary condition for perfect sampling.**\n\nThis statement is factually incorrect. Monotonicity is a sufficient, but not necessary, condition for perfect sampling. As established in the analysis of option C, the DCFTP algorithm is a valid perfect sampling method that does not require monotonicity and can be applied to the antiferromagnetic Ising model on $C_3$ in the high-temperature regime. The existence of DCFTP provides a direct counterexample to the claim that no perfect sampling algorithm exists.\n**Verdict: Incorrect.**\n\n**E. By modifying the dynamics to block-update two adjacent spins at a time with a heat-bath rule, one always recovers a monotone update map on $C_3$, so monotone Propp–Wilson CFTP becomes applicable regardless of $\\beta$.**\n\nThis statement proposes to recover monotonicity by using a block update. Let's analyze the update of the block of spins $\\{\\sigma_1, \\sigma_2\\}$ conditional on the state of spin $\\sigma_3$. The heat-bath rule for the block means sampling from the conditional Gibbs distribution $\\mathbb{P}(\\sigma_1, \\sigma_2 \\mid \\sigma_3) \\propto \\exp(-H(\\sigma_1,\\sigma_2|\\sigma_3))$, where $H$ is the Hamiltonian. The relevant part of the Hamiltonian is $H = \\beta(\\sigma_1\\sigma_2 + \\sigma_2\\sigma_3 + \\sigma_3\\sigma_1)$. The conditional probability is proportional to $\\exp(-\\beta\\sigma_1\\sigma_2 - \\beta\\sigma_3(\\sigma_1+\\sigma_2))$. To check for monotonicity, we analyze how this distribution changes as $\\sigma_3$ flips from $-1$ to $+1$. The ratio of probabilities is:\n$$ \\frac{\\mathbb{P}(\\sigma_1, \\sigma_2 \\mid \\sigma_3=+1)}{\\mathbb{P}(\\sigma_1, \\sigma_2 \\mid \\sigma_3=-1)} = \\frac{\\exp(-\\beta\\sigma_1\\sigma_2 - \\beta(\\sigma_1+\\sigma_2))}{\\exp(-\\beta\\sigma_1\\sigma_2 + \\beta(\\sigma_1+\\sigma_2))} = \\exp(-2\\beta(\\sigma_1+\\sigma_2)) $$\nThis ratio decreases as the sum $\\sigma_1+\\sigma_2$ increases. For example, when $\\sigma_3$ flips from $-1$ to $+1$, the state $(\\sigma_1, \\sigma_2) = (+1,+1)$ (with sum $2$) becomes less likely relative to the state $(-1,-1)$ (with sum $-2$). This is the definition of anti-monotonicity with respect to the standard product order on the block. The update does not recover monotonicity; it reverses it. The claim that this works \"always\" and \"regardless of $\\beta$\" is false.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{BC}$$"
        },
        {
            "introduction": "The true power of an algorithm is revealed by the breadth of its applications. In this final practice, we step outside of statistical physics to apply the CFTP framework to the stable matching problem, a classic topic in economics and computer science . We will define a monotone Markov chain on the lattice of stable matchings, based on the proposal dynamics of the Gale-Shapley algorithm. This hands-on coding exercise demonstrates the remarkable generality of the Propp-Wilson method, requiring you to implement a perfect sampler and empirically measure its coalescence time as a function of market size, thereby connecting abstract theory to practical performance analysis.",
            "id": "3356328",
            "problem": "Consider a two-sided matching market with $n$ men $\\mathcal{M} = \\{m_1,\\dots,m_n\\}$ and $n$ women $\\mathcal{W} = \\{w_1,\\dots,w_n\\}$. Each man $m \\in \\mathcal{M}$ has a strict total order over $\\mathcal{W}$, and each woman $w \\in \\mathcal{W}$ has a strict total order over $\\mathcal{M}$. A matching $\\mu$ is a bijection between $\\mathcal{M}$ and $\\mathcal{W}$. A matching $\\mu$ is stable if there is no pair $(m,w)$ such that $w$ is strictly preferred by $m$ to $\\mu(m)$ and $m$ is strictly preferred by $w$ to $\\mu^{-1}(w)$.\n\nDefine the partial order (the Gale–Shapley order) on the set of stable matchings by\n$$\n\\mu \\succeq \\nu \\quad \\Longleftrightarrow \\quad \\forall m \\in \\mathcal{M}: \\mu(m) \\text{ is weakly preferred by } m \\text{ to } \\nu(m).\n$$\nIt is known that the set of stable matchings forms a lattice under $\\succeq$, with a greatest element $\\mu^{\\mathcal{M}}$ (the men-optimal stable matching) and a least element $\\mu^{\\mathcal{W}}$ (the women-optimal stable matching).\n\nWe consider a monotone Markov chain on the state space of proposal configurations, coupled with the acceptance rule of Deferred Acceptance (DA). A proposal configuration is represented by a matrix $P \\in \\{0,1\\}^{n \\times n}$, where $P_{m,w} = 1$ indicates that man $m$ has proposed to woman $w$. Given a proposal configuration $P$, the acceptance mapping $A(P)$ assigns each woman $w$ her favorite proposer among $\\{m : P_{m,w} = 1\\}$ using her strict preference order; if no proposers exist, $w$ remains unmatched. The induced matching for men is the inverse image of accepted pairs. Proposals accumulate over time, and acceptances are recomputed from $P$ at each time but not used to retract proposals.\n\nWe define the monotone update function $F$ as follows: at each time step, a random man $m$ is selected uniformly from $\\mathcal{M}$. He proposes to his highest-ranked woman $w$ among those to whom he has not yet proposed, toggling $P_{m,w}$ from $0$ to $1$. If $m$ has proposed to every woman, the step leaves $P$ unchanged. The acceptance is then derived by applying $A(P)$ to obtain the current tentative matching. This update $F$ is monotone with respect to the partial order on proposal configurations given by componentwise inclusion: if $P \\leq Q$ (i.e., $P_{m,w} \\leq Q_{m,w}$ for all $m,w$), then the men’s induced matching under $A(P)$ is weakly preferred (in the Gale–Shapley order) to the men’s induced matching under $A(Q)$.\n\nCoupling From The Past (CFTP) constructs a perfect sample from the stationary distribution of a monotone Markov chain by running the chain backward in time from $-\\tau$ to $0$ for both extremal states and checking for coalescence. In our setting:\n- The bottom element is the proposal configuration $P^{\\bot}$ where $P^{\\bot}_{m,w} = 0$ for all $m,w$, representing no proposals made yet.\n- The top element is the proposal configuration $P^{\\top}$ where $P^{\\top}_{m,w} = 1$ for all $m,w$, representing that all proposals have been made.\nUnder $A(P^{\\top})$, the induced matching equals $\\mu^{\\mathcal{W}}$, the women-optimal stable matching. The monotone chain $F$ absorbs toward $P^{\\top}$ in the sense that proposals only accumulate. The CFTP procedure will detect coalescence exactly when the image of $P^{\\bot}$ under the composed updates from time $-\\tau$ to $0$ yields the same induced matching as $A(P^{\\top})$, i.e., when the bottom trajectory has reached the women-optimal matching, which is the stationary state of this absorbing monotone process.\n\nYour tasks:\n- Derive the extremal elements $\\mu^{\\mathcal{M}}$ and $\\mu^{\\mathcal{W}}$ under the Gale–Shapley order from first principles of stability and preference orders. Formalize why proposals accumulation induces monotonicity with respect to the Gale–Shapley order for men.\n- Implement the CFTP procedure with backward doubling in time, using uniformly random preference profiles for men and women (random strict total orders). The random preference profiles are the \"random preference perturbations\" in this setting. For each market size $n$, generate independent preference instances and, for each, perform CFTP with update inputs being independent uniform choices of a man at each time step. Use backward doubling until coalescence occurs, then perform a binary search to find the minimal $\\tau$ such that applying updates from $-\\tau$ to $0$ yields coalescence between the top and bottom trajectories.\n- Quantify $\\tau$ as a function of market size by computing the sample mean of $\\tau$ over several independent preference instances and update sequences for each $n$.\n\nTest suite (each test case specifies $(n, \\text{repetitions}, \\text{seed})$):\n- $(3, 50, 42)$: general case with small market size.\n- $(4, 50, 43)$: general case, slightly larger.\n- $(5, 50, 44)$: medium size within computational limits.\n- $(6, 30, 45)$: larger case to observe scaling.\n- $(1, 200, 46)$: boundary case with a single man and woman.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\dots]$).\n- Each result must be a floating-point number equal to the sample mean of $\\tau$ for the corresponding test case. No physical units are involved. The output must be deterministic given the fixed seeds.",
            "solution": "The problem is well-posed, scientifically grounded in the theory of stable marriage and stochastic processes, and contains all necessary information for a unique, verifiable solution. It is therefore deemed valid.\n\n### 1. Theoretical Framework\n\n#### 1.1. The Lattice of Stable Matchings\nWe are given a two-sided matching market with a set of $n$ men, $\\mathcal{M}$, and $n$ women, $\\mathcal{W}$. Each participant has a strict preference ordering over the members of the opposite set. A matching $\\mu$ is a bijection between $\\mathcal{M}$ and $\\mathcal{W}$. A matching is said to be stable if there exists no blocking pair $(m,w)$, where man $m$ strictly prefers woman $w$ to his assigned partner $\\mu(m)$, and woman $w$ strictly prefers man $m$ to her assigned partner $\\mu^{-1}(w)$.\n\nThe set of all stable matchings for a given instance of preferences is non-empty. This set can be endowed with a partial order, known as the Gale–Shapley order. For any two stable matchings $\\mu$ and $\\nu$, we say $\\mu \\succeq \\nu$ if and only if every man weakly prefers his partner in $\\mu$ to his partner in $\\nu$. Formally:\n$$\n\\mu \\succeq \\nu \\quad \\Longleftrightarrow \\quad \\forall m \\in \\mathcal{M}: \\mu(m) \\text{ is weakly preferred by } m \\text{ to } \\nu(m).\n$$\nA seminal result by Gale and Shapley (1962) establishes that the set of stable matchings under this partial order forms a distributive lattice. This structure guarantees the existence of a unique greatest element and a unique least element.\n\nThe greatest element, denoted $\\mu^{\\mathcal{M}}$, is the men-optimal stable matching. It is the stable matching that is simultaneously the most preferred for all men. This matching can be found using the men-proposing Deferred Acceptance (DA) algorithm. In this algorithm, unmarried men propose to the highest-ranked woman on their list to whom they have not yet proposed. Each woman provisionally accepts the best proposal she has received so far and rejects all others. The algorithm terminates when no man is rejected, resulting in the stable matching $\\mu^{\\mathcal{M}}$.\n\nThe least element, denoted $\\mu^{\\mathcal{W}}$, is the women-optimal stable matching. Symmetrically, this is the stable matching that is most preferred for all women and least preferred for all men. It can be found using the women-proposing DA algorithm. A key property of this lattice is the opposition of interests: for any two stable matchings $\\mu$ and $\\nu$, $\\mu \\succeq \\nu$ (in the men's ordering) if and only if $\\nu$ is weakly preferred to $\\mu$ by all women.\n\n#### 1.2. A Monotone Markov Chain for Stable Matching\nThe problem defines a Markov chain on the state space of proposal configurations. A state is an $n \\times n$ matrix $P$, where $P_{m,w} = 1$ if man $m$ has proposed to woman $w$, and $P_{m,w} = 0$ otherwise. The state space is ordered by component-wise inclusion: $P \\le Q$ if $P_{m,w} \\le Q_{m,w}$ for all pairs $(m,w)$. The extremal elements are:\n- The bottom element $P^{\\bot}$, the zero matrix, where no proposals have been made.\n- The top element $P^{\\top}$, the all-ones matrix, where every man has proposed to every woman.\n\nThe update function $F$ proceeds as follows: at each time step, a man $m$ is chosen uniformly at random. He proposes to his most-preferred woman $w$ to whom he has not yet proposed. This corresponds to setting $P_{m,w} = 1$. Since proposals are never retracted, this update rule is monotone with respect to the inclusion order on $P$: if $P_t$ is the state at time $t$, then $P_t \\le P_{t+1}$. The process is absorbing, as it terminates in the state $P^{\\top}$ once all possible proposals have been made.\n\nFrom any proposal configuration $P$, we can derive a tentative matching via the acceptance mapping $A(P)$: each woman $w$ accepts the proposal from the man she most prefers among the set $\\{m \\in \\mathcal{M} \\mid P_{m,w} = 1\\}$. Let $\\mu_P$ denote this induced matching.\n\n#### 1.3. Formalization of Monotonicity\nThe problem asserts that this process is monotone with respect to the Gale-Shapley order. That is, if $P \\le Q$, then the induced matching $\\mu_P$ is weakly preferred by all men to $\\mu_Q$, i.e., $\\mu_P \\succeq \\mu_Q$. We now formalize this proof.\n\nLet $P, Q$ be two proposal configurations with $P \\le Q$. Let $\\mu_P$ and $\\mu_Q$ be their respective induced matchings. Assume for contradiction that the claim is false, meaning there exists at least one man $m_0$ who strictly prefers his partner in $\\mu_Q$ to his partner in $\\mu_P$. Let $w_P = \\mu_P(m_0)$ and $w_Q = \\mu_Q(m_0)$. By our assumption, $m_0$ strictly prefers $w_Q$ to $w_P$.\n\n1.  Since $m_0$ is matched to $w_Q$ in $\\mu_Q$, he must have proposed to her in configuration $Q$. So, $Q_{m_0, w_Q} = 1$.\n2.  Since $m_0$ strictly prefers $w_Q$ to $w_P$, his proposal to $w_P$ must come after his proposal to $w_Q$ in his preference list. For $m_0$ to be matched with $w_P$ under configuration $P$, he must have proposed to $w_P$, i.e., $P_{m_0, w_P}=1$. Therefore, he must have also proposed to $w_Q$ under $P$, i.e., $P_{m_0, w_Q}=1$.\n3.  In configuration $P$, $m_0$ proposed to $w_Q$ but was matched with the less-preferred woman $w_P$. This implies that $w_Q$ must have rejected $m_0$'s proposal in favor of another man, say $m'$, whom she strictly prefers. Thus, $m' = (\\mu_P)^{-1}(w_Q)$ and $w_Q$ prefers $m'$ to $m_0$. Also, $P_{m', w_Q} = 1$.\n4.  Now consider configuration $Q$. Since $P \\le Q$, we have $P_{m', w_Q} \\le Q_{m', w_Q}$, which means $Q_{m', w_Q} = 1$. So, in configuration $Q$, woman $w_Q$ receives proposals from both $m_0$ and $m'$.\n5.  By the acceptance rule $A(Q)$, $w_Q$ must choose her most-preferred suitor from her set of proposers under $Q$. Since $m'$ is in this set and she prefers $m'$ to $m_0$, she will choose a partner at least as good as $m'$. Let this partner be $m'' = (\\mu_Q)^{-1}(w_Q)$. It must be that $w_Q$ weakly prefers $m''$ to $m'$, and thus strictly prefers $m''$ to $m_0$.\n6.  However, we are given that $m_0$ is matched to $w_Q$ in $\\mu_Q$, so $m'' = m_0$. This leads to the contradiction that $w_Q$ strictly prefers $m_0$ to $m_0$.\n\nTherefore, our initial assumption is false. No man can strictly prefer his partner in $\\mu_Q$ to his partner in $\\mu_P$. This proves that $\\mu_P \\succeq \\mu_Q$.\n\n### 2. Algorithmic Design for Coupling From The Past (CFTP)\n\nThe described Markov chain is monotone, and thus amenable to the Coupling From The Past (CFTP) algorithm for perfect sampling from its stationary distribution.\n\n#### 2.1. Stationary Distribution\nThe chain is defined on a finite state space and has a single absorbing state, $P^{\\top}$, where all proposals have been made. The unique stationary distribution of such a chain is a point mass on the absorbing state. The matching induced by $P^{\\top}$ is $\\mu_{P^{\\top}} = A(P^{\\top})$. Under $A(P^{\\top})$, every woman $w$ receives proposals from all men in $\\mathcal{M}$ and chooses her most-preferred one. This resulting matching is, by definition, the women-optimal stable matching, $\\mu^{\\mathcal{W}}$. It is straightforward to show this matching is stable: no woman has an incentive to leave her partner as she is matched with her top choice from all men. Thus, the stationary distribution of the chain of induced matchings is a point mass on $\\mu^{\\mathcal{W}}$.\n\n#### 2.2. CFTP Implementation\nThe CFTP algorithm for a monotone system works by evolving the bottom state $P^{\\bot}$ and top state $P^{\\top}$ backward in time. However, in our setup, the top state chain is trivial: since any update on $P^{\\top}$ leaves it unchanged, the induced matching for the top chain is always $\\mu^{\\mathcal{W}}$. Coalescence occurs when the bottom chain, starting from $P^{\\bot}$, also yields the matching $\\mu^{\\mathcal{W}}$.\n\nOur goal is to find the minimal coalescence time $\\tau$, which is the smallest number of update steps required for the chain starting at $P^{\\bot}$ to produce the matching $\\mu^{\\mathcal{W}}$. We employ a two-phase strategy:\n1.  **Backward Doubling**: We find a time horizon $T$ that is guaranteed to be long enough for coalescence. We start with a window of size $\\tau=1$, generate random choices for this window, and check for coalescence. If it fails, we double the window size to $\\tau=2$, generate $\\tau$ *new* random choices for the earlier time period, and check again over the now larger total horizon. We repeat this, doubling $\\tau$ at each step, until coalescence is observed at time $0$. Let the total time horizon be $T$.\n2.  **Binary Search**: Once we have a sufficiently large time $T$ and the corresponding sequence of random choices $(u_{-T+1}, \\dots, u_0)$, we know that applying all $T$ updates leads to coalescence. To find the *minimal* time, we perform a binary search for the smallest $k \\in [1, T]$ such that applying the last $k$ updates, $(u_{-k+1}, \\dots, u_0)$, to $P^{\\bot}$ results in the matching $\\mu^{\\mathcal{W}}$. This minimal $k$ is our sample for $\\tau$.\n\nThis procedure is repeated for several independent preference profiles and random update sequences to compute the sample mean of $\\tau$ as a function of the market size $n$. The implementation will create a distinct random number generator for each test case to ensure deterministic and reproducible results.\n\nKey components of the implementation are:\n- A function `get_induced_matching(P, women_ranks)` that computes $\\mu_P$ from a proposal matrix $P$.\n- A function `update_chain(initial_P, choices, men_prefs)` that applies a sequence of updates to a proposal matrix. To efficiently find the next proposal for a chosen man, we pre-calculate the number of proposals he has already made.\n\nThe case $n=1$ provides a trivial-by-design baseline: with one man and one woman, the first and only proposal results in coalescence, so $\\tau=1$ always.",
            "answer": "```python\nimport numpy as np\n\ndef get_induced_matching(n, P, women_ranks):\n    \"\"\"\n    Computes the induced matching from a proposal matrix P.\n    This implements the acceptance mapping A(P).\n    \"\"\"\n    women_match = -np.ones(n, dtype=int)\n    for w in range(n):\n        proposers = np.where(P[:, w] == 1)[0]\n        if proposers.size  0:\n            proposer_ranks = women_ranks[w, proposers]\n            best_proposer_idx = np.argmin(proposer_ranks)\n            women_match[w] = proposers[best_proposer_idx]\n\n    men_match = -np.ones(n, dtype=int)\n    for w, m in enumerate(women_match):\n        if m != -1:\n            men_match[m] = w\n            \n    return men_match\n\ndef update_chain(n, initial_P, choices, men_prefs):\n    \"\"\"\n    Applies a sequence of updates to a proposal matrix.\n    \"\"\"\n    current_P = initial_P.copy()\n    num_proposals_by_man = np.sum(current_P, axis=1)\n\n    for man_choice in choices:\n        num_proposals = num_proposals_by_man[man_choice]\n        if num_proposals  n:\n            woman_to_propose_to = men_prefs[man_choice, num_proposals]\n            current_P[man_choice, woman_to_propose_to] = 1\n            num_proposals_by_man[man_choice] += 1\n            \n    return current_P\n\ndef run_single_cftp_trail(n, rng):\n    \"\"\"\n    Runs one full CFTP trial to find the minimal coalescence time tau.\n    This includes generating preferences and running the backward doubling + binary search.\n    \"\"\"\n    # 1. Generate random preferences for this trial\n    men_prefs = np.array([rng.permutation(n) for _ in range(n)], dtype=int)\n    women_prefs = np.array([rng.permutation(n) for _ in range(n)], dtype=int)\n\n    women_ranks = np.empty((n, n), dtype=int)\n    for w in range(n):\n        for rank, m in enumerate(women_prefs[w]):\n            women_ranks[w, m] = rank\n\n    # 2. Define extremal states and target matching\n    P_bot = np.zeros((n, n), dtype=int)\n    P_top = np.ones((n, n), dtype=int)\n    match_top = get_induced_matching(n, P_top, women_ranks)  # This is mu_W\n\n    # 3. CFTP with backward doubling\n    tau_window = 1\n    random_choices = []\n    \n    while True:\n        # Generate tau new choices and prepend them\n        new_choices = rng.integers(0, n, size=tau_window)\n        random_choices = np.concatenate((new_choices, random_choices)).astype(int)\n        \n        # Evolve bottom chain\n        P_bot_evolved = update_chain(n, P_bot, random_choices, men_prefs)\n        match_bot = get_induced_matching(n, P_bot_evolved, women_ranks)\n\n        # Check for coalescence\n        if np.array_equal(match_bot, match_top):\n            break\n        \n        # Double the time window for the next iteration\n        tau_window *= 2\n\n    # 4. Binary search for minimal tau\n    T = len(random_choices)\n    low, high = 1, T\n    min_tau = T\n\n    while low = high:\n        mid = (low + high) // 2\n        if mid == 0: # a time of 0 is not meaningful\n            low = 1\n            continue\n\n        # Test with the last 'mid' choices\n        sub_choices = random_choices[T - mid:]\n        P_bot_evolved = update_chain(n, P_bot, sub_choices, men_prefs)\n        match_bot = get_induced_matching(n, P_bot_evolved, women_ranks)\n        \n        if np.array_equal(match_bot, match_top):\n            min_tau = mid\n            high = mid - 1\n        else:\n            low = mid + 1\n            \n    return min_tau\n\n\ndef compute_mean_tau(n, repetitions, seed):\n    \"\"\"\n    Computes the sample mean of tau over a number of repetitions.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    taus = [run_single_cftp_trail(n, rng) for _ in range(repetitions)]\n    return np.mean(taus)\n\n\ndef solve():\n    # Test suite: (n, repetitions, seed)\n    test_cases = [\n        (3, 50, 42),\n        (4, 50, 43),\n        (5, 50, 44),\n        (6, 30, 45),\n        (1, 200, 46),\n    ]\n\n    results = []\n    for n, repetitions, seed in test_cases:\n        mean_tau = compute_mean_tau(n, repetitions, seed)\n        results.append(mean_tau)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}