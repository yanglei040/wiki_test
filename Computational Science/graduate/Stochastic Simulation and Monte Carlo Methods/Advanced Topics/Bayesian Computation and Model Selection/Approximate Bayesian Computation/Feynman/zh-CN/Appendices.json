{
    "hands_on_practices": [
        {
            "introduction": "在近似贝叶斯计算（ABC）中，选择合适的概括统计量（summary statistics）是至关重要的一步，因为它直接决定了我们从数据中提取哪些信息来进行推断。这项练习  提供了一个形式化的框架，通过评估不同统计量对最终后验近似质量的影响（以贝叶斯风险衡量），来比较它们的优劣。这个练习将帮助你理解如何基于统计效率来做出明智的选择。",
            "id": "3288801",
            "problem": "考虑一个数据生成过程，其中 $Y_{1},\\dots,Y_{n}$ 是来自对数正态分布的独立同分布随机变量，其参数为 $\\mu$ 和 $\\sigma^{2}$，即 $\\ln(Y_{i}) \\equiv Z_{i} \\sim \\mathcal{N}(\\mu,\\sigma^{2})$，其中 $\\sigma^{2}$ 已知而 $\\mu$ 未知。假设 $\\mu$ 的先验分布为高斯分布，$\\mu \\sim \\mathcal{N}(m_{0},v_{0})$，其中 $m_{0}$ 和 $v_{0}0$ 已知。使用对称核和容忍度参数执行近似贝叶斯计算（ABC），该容忍度参数趋于零，因此从模拟器中接受的样本在选定的低维摘要统计量上满足精确匹配。考虑两种采用在对数变换数据上计算的不同摘要的 ABC 方案：\n- 基于矩的摘要 $s_{\\mathrm{mom}} = \\bar{Z} = \\frac{1}{n}\\sum_{i=1}^{n} Z_{i}$。\n- 基于分位数的摘要 $s_{\\mathrm{quant}} = \\tilde{Z}$，即 $\\{Z_{1},\\dots,Z_{n}\\}$ 的样本中位数。\n\n在估计 $\\mu$ 的二次损失 $L(\\hat{\\mu},\\mu) = (\\hat{\\mu} - \\mu)^{2}$ 下，贝叶斯估计量是后验均值，贝叶斯风险等于后验方差在先验预测分布上的平均值。假设在 ABC 条件化步骤中使用摘要统计量的大样本抽样分布：基于矩的摘要满足 $\\bar{Z} \\stackrel{\\mathrm{approx}}{\\sim} \\mathcal{N}(\\mu,\\sigma^{2}/n)$，而基于分位数的摘要满足 $\\tilde{Z} \\stackrel{\\mathrm{approx}}{\\sim} \\mathcal{N}\\!\\left(\\mu,\\frac{\\pi \\sigma^{2}}{2n}\\right)$。\n\n在此设置下，推导在二次损失下，通过在这两种摘要之间进行选择，ABC 后验均值所能达到的最小贝叶斯风险的解析表达式。你的最终答案必须是关于 $n$、$v_{0}$ 和 $\\sigma^{2}$ 的单个闭式表达式，并且不应包含任何不等式或方程。不需要进行数值舍入。",
            "solution": "问题要求在近似贝叶斯计算（ABC）框架内，通过在两种不同的摘要统计量之间进行选择，来估计参数 $\\mu$ 在二次损失函数 $L(\\hat{\\mu}, \\mu) = (\\hat{\\mu} - \\mu)^2$ 下的最小贝叶斯风险。ABC 的容忍度趋于零，这意味着 $\\mu$ 的 ABC 后验分布收敛于以所选摘要统计量 $s$ 为条件的精确后验分布 $p(\\mu|s)$。\n\n在二次损失下，贝叶斯估计量是后验均值 $\\hat{\\mu}_{\\text{Bayes}} = \\mathbb{E}[\\mu|s]$。与摘要统计量 $s$ 的特定观测值相关的风险是后验方差 $\\text{Var}(\\mu|s)$。总贝叶斯风险 $R$ 是该后验方差的期望值，该期望是针对摘要统计量的边际（先验预测）分布 $p(s)$ 计算的：\n$$ R = \\mathbb{E}_{s}[\\text{Var}(\\mu|s)] = \\int \\text{Var}(\\mu|s) p(s) \\,ds $$\n\n我们首先为一个抽样分布为高斯分布的通用摘要统计量 $s$ 推导贝叶斯风险的一般表达式。该问题建立了一个共轭高斯-高斯模型。\n$\\mu$ 的先验分布给定为：\n$$ \\mu \\sim \\mathcal{N}(m_{0}, v_{0}) $$\n这对应于一个概率密度函数 $p(\\mu) \\propto \\exp\\left(-\\frac{(\\mu-m_0)^2}{2v_0}\\right)$。\n\n给定摘要统计量 $s$ 时 $\\mu$ 的似然是基于 $s$ 的抽样分布的大样本近似。我们假设一个通用形式：\n$$ s | \\mu \\sim \\mathcal{N}(\\mu, \\tau^{2}) $$\n这对应于一个似然函数 $p(s|\\mu) \\propto \\exp\\left(-\\frac{(s-\\mu)^2}{2\\tau^2}\\right)$。\n\n后验分布 $p(\\mu|s)$ 与似然和先验的乘积成正比，即 $p(\\mu|s) \\propto p(s|\\mu)p(\\mu)$。\n$$ p(\\mu|s) \\propto \\exp\\left(-\\frac{(s-\\mu)^2}{2\\tau^2}\\right) \\exp\\left(-\\frac{(\\mu-m_0)^2}{2v_0}\\right) $$\n指数是关于 $\\mu$ 的二次式，这表明后验分布也是高斯分布。我们可以通过在指数中对 $\\mu$ 进行配方来找到后验分布的参数。后验精度（方差的倒数）是先验精度和数据精度的总和：\n$$ \\frac{1}{\\text{Var}(\\mu|s)} = \\frac{1}{v_0} + \\frac{1}{\\tau^2} $$\n因此，后验方差为：\n$$ \\text{Var}(\\mu|s) = \\left(\\frac{1}{v_0} + \\frac{1}{\\tau^2}\\right)^{-1} = \\frac{v_0 \\tau^2}{v_0 + \\tau^2} $$\n关键在于，后验方差不依赖于摘要统计量 $s$ 的具体观测值。因此，对 $p(s)$ 的期望是平凡的。贝叶斯风险 $R$ 就等于后验方差：\n$$ R(\\tau^2) = \\mathbb{E}_{s}\\left[\\frac{v_0 \\tau^2}{v_0 + \\tau^2}\\right] = \\frac{v_0 \\tau^2}{v_0 + \\tau^2} $$\n为了找到最小贝叶斯风险，我们必须选择使该表达式最小化的摘要统计量。让我们分析 $R(\\tau^2)$ 作为抽样方差 $\\tau^2$ 的函数的行为。我们对 $\\tau^2$ 求导：\n$$ \\frac{dR}{d(\\tau^2)} = \\frac{v_0(v_0 + \\tau^2) - v_0 \\tau^2(1)}{(v_0 + \\tau^2)^2} = \\frac{v_0^2}{(v_0 + \\tau^2)^2} $$\n由于给定 $v_0  0$，所以 $v_0^2  0$，且分母总是正的。因此，$\\frac{dR}{d(\\tau^2)}  0$，这意味着贝叶斯风险 $R$ 是摘要统计量抽样方差 $\\tau^2$ 的严格单调递增函数。为了最小化贝叶斯风险，我们必须选择具有较小抽样方差的摘要统计量。\n\n现在我们评估所提出的两种摘要的抽样方差。\n1.  基于矩的摘要：$s_{\\mathrm{mom}} = \\bar{Z}$。\n    其抽样分布给定为 $\\bar{Z} \\stackrel{\\mathrm{approx}}{\\sim} \\mathcal{N}(\\mu, \\sigma^2/n)$。抽样方差为：\n    $$ \\tau_{\\mathrm{mom}}^2 = \\frac{\\sigma^2}{n} $$\n2.  基于分位数的摘要：$s_{\\mathrm{quant}} = \\tilde{Z}$。\n    其抽样分布给定为 $\\tilde{Z} \\stackrel{\\mathrm{approx}}{\\sim} \\mathcal{N}(\\mu, \\frac{\\pi \\sigma^2}{2n})$。抽样方差为：\n    $$ \\tau_{\\mathrm{quant}}^2 = \\frac{\\pi \\sigma^2}{2n} $$\n\n我们现在比较这两个方差：\n$$ \\tau_{\\mathrm{mom}}^2 = \\frac{\\sigma^2}{n} \\quad \\text{和} \\quad \\tau_{\\mathrm{quant}}^2 = \\frac{\\pi}{2} \\cdot \\frac{\\sigma^2}{n} $$\n比较取决于常数 $\\frac{\\pi}{2}$ 的值。使用 $\\pi \\approx 3.14159$，我们有 $\\frac{\\pi}{2} \\approx 1.5708$。\n由于 $\\frac{\\pi}{2}  1$，直接得出：\n$$ \\tau_{\\mathrm{quant}}^2  \\tau_{\\mathrm{mom}}^2 $$\n基于矩的摘要统计量 $\\bar{Z}$ 的抽样方差小于基于分位数的摘要统计量 $\\tilde{Z}$ 的抽样方差。这与以下事实一致：对于高斯样本，样本均值是总体均值的最小方差无偏估计量，并且比样本中位数更有效。\n\n由于贝叶斯风险 $R(\\tau^2)$ 是 $\\tau^2$ 的增函数，因此使用具有最小方差的摘要可以达到最小风险。因此，两者之间的最优选择是基于矩的摘要 $s_{\\mathrm{mom}}$。\n\n将 $\\tau^2 = \\tau_{\\mathrm{mom}}^2 = \\frac{\\sigma^2}{n}$ 代入我们的一般风险表达式中，即可得到最小贝叶斯风险：\n$$ R_{\\min} = R(\\tau_{\\mathrm{mom}}^2) = \\frac{v_0 (\\frac{\\sigma^2}{n})}{v_0 + \\frac{\\sigma^2}{n}} $$\n简化此表达式得到最终结果：\n$$ R_{\\min} = \\frac{\\frac{v_0\\sigma^2}{n}}{\\frac{n v_0 + \\sigma^2}{n}} = \\frac{v_0 \\sigma^2}{n v_0 + \\sigma^2} $$\n该表达式代表在二次损失下，通过在两种指定的摘要统计量之间进行选择所能达到的最小贝叶斯风险。",
            "answer": "$$\\boxed{\\frac{v_{0}\\sigma^{2}}{nv_{0} + \\sigma^{2}}}$$"
        },
        {
            "introduction": "理论需要通过实践来检验。这项练习  是一个编码挑战，将引导你为一个简单的、已知精确解的模型构建一个完整的 ABC 分析流程。这使得直接校准成为可能，让你能使用形式化的统计检验来评估 ABC 近似结果与真实的后验预测分布的吻合程度，从而获得关于算法性能的直观反馈。",
            "id": "3288776",
            "problem": "您需要为近似贝叶斯计算（ABC）的后验预测检验构建一个校准测试。目标是比较从ABC后验预测过程中抽取的重复数据的经验分布与从精确后验预测过程中抽取的重复数据的经验分布，并使用Cramer–von Mises统计量来量化偏差。\n\n此任务的基本基础包括以下经过充分检验的公式和定义：\n\n- 泊松模型的贝叶斯法则和共轭先验-后验关系：设数据为 $y_1, y_2, \\dots, y_n$，其中 $y_i \\sim \\mathrm{Poisson}(\\theta)$，先验为形状-率参数化的 $\\theta \\sim \\mathrm{Gamma}(\\alpha, \\beta)$。后验分布为 $\\theta \\mid y \\sim \\mathrm{Gamma}(\\alpha', \\beta')$，其中 $\\alpha' = \\alpha + \\sum_{i=1}^n y_i$ 且 $\\beta' = \\beta + n$。\n- 单个未来观测值 $y^{\\mathrm{rep}}$ 的后验预测分布是泊松-伽马混合分布：等价地，通过采样 $\\lambda \\sim \\mathrm{Gamma}(\\alpha', \\beta')$，然后令 $y^{\\mathrm{rep}} \\sim \\mathrm{Poisson}(\\lambda)$ 来获得精确的后验预测样本。\n- 带拒绝采样的近似贝叶斯计算（ABC）：从先验分布中提出 $\\theta^{(j)} \\sim \\mathrm{Gamma}(\\alpha, \\beta)$，从模型中模拟一个数据集 $y^{(j)} = (y_1^{(j)}, \\dots, y_n^{(j)})$，计算一个摘要统计量 $s(y^{(j)})$，如果差异 $d(s(y^{(j)}), s(y))$ 小于阈值 $\\varepsilon$，则接受 $\\theta^{(j)}$。使用接受的 $\\theta$ 样本，模拟 $y^{\\mathrm{rep}} \\sim \\mathrm{Poisson}(\\theta)$ 来近似后验预测分布。\n- Cramer–von Mises (CvM) 双样本统计量：给定两个样本 $x_1, \\dots, x_m$ 和 $z_1, \\dots, z_n$，令 $N = m + n$，并令 $\\{w_{(i)}\\}_{i=1}^N$ 为 $\\{x_j\\}$ 和 $\\{z_k\\}$ 的混合排序值。定义经验累积分布函数 $F_m$ 和 $G_n$。双样本Cramer–von Mises统计量为\n$$\nT_{\\mathrm{CvM}} = \\frac{mn}{N^2} \\sum_{i=1}^N \\left( F_m(w_{(i)}) - G_n(w_{(i)}) \\right)^2,\n$$\n其中 $F_m(w)$ 是 $\\{x_j\\}$ 中小于或等于 $w$ 的比例，而 $G_n(w)$ 是 $\\{z_k\\}$ 中小于或等于 $w$ 的比例。\n\n待实现的模型和算法规范：\n\n1. 数据生成过程：对每个测试用例，使用固定的随机种子 $123$ 生成观测数据 $y_1, \\dots, y_n$ 作为独立的 $\\mathrm{Poisson}(\\theta_{\\mathrm{true}})$ 计数，以确保可复现性。\n2. 先验：使用 $\\theta \\sim \\mathrm{Gamma}(\\alpha, \\beta)$，其中形状-率参数为 $(\\alpha, \\beta)$。\n3. 通过拒绝采样的ABC后验：\n   - 摘要统计量：$s(y) = \\frac{1}{n} \\sum_{i=1}^n y_i$。\n   - 差异：$d(s_{\\mathrm{sim}}, s_{\\mathrm{obs}}) = \\left| s_{\\mathrm{sim}} - s_{\\mathrm{obs}} \\right|$。\n   - 阈值：如果 $d(s_{\\mathrm{sim}}, s_{\\mathrm{obs}}) \\le \\varepsilon$，则接受。\n   - 提议与模拟：抽取 $N_{\\mathrm{prior}}$ 个独立的提议 $\\theta^{(j)} \\sim \\mathrm{Gamma}(\\alpha, \\beta)$；对每个提议，模拟 $n$ 个独立的 $\\mathrm{Poisson}(\\theta^{(j)})$ 观测值并计算 $s_{\\mathrm{sim}}$。\n   - 接受的参数集：$\\{\\theta^{(j)} : d \\le \\varepsilon\\}$。\n4. ABC后验预测样本：对每个接受的 $\\theta^{(j)}$，抽取一个 $y^{\\mathrm{rep}}_j \\sim \\mathrm{Poisson}(\\theta^{(j)})$；这将产生 $m$ 个ABC后验预测重复样本，其中 $m$ 是接受的提议数量。\n5. 精确后验预测样本：从观测数据中计算 $(\\alpha', \\beta')$，抽取 $m$ 个独立的 $\\lambda_j \\sim \\mathrm{Gamma}(\\alpha', \\beta')$，然后抽取 $z_j \\sim \\mathrm{Poisson}(\\lambda_j)$ 以获得 $m$ 个重复的精确后验预测样本。使用与接受的ABC重复样本数量相同的 $m$ 个精确重复样本，以便于双样本比较。\n6. 对每个测试用例，计算ABC预测样本与精确预测样本之间的双样本Cramer–von Mises统计量 $T_{\\mathrm{CvM}}$。\n\n测试套件：\n\n使用以下三个测试用例评估不同方案下的校准情况。对所有测试用例，使用固定的随机种子 $123$。\n\n- 案例1（理想路径）：$(n, \\alpha, \\beta, \\theta_{\\mathrm{true}}, \\varepsilon, N_{\\mathrm{prior}}) = (50, 2.0, 1.0, 3.0, 0.12, 20000)$。\n- 案例2（更分散的数据）：$(n, \\alpha, \\beta, \\theta_{\\mathrm{true}}, \\varepsilon, N_{\\mathrm{prior}}) = (30, 2.0, 1.0, 1.5, 0.20, 20000)$。\n- 案例3（更大的样本量，更紧的容差）：$(n, \\alpha, \\beta, \\theta_{\\mathrm{true}}, \\varepsilon, N_{\\mathrm{prior}}) = (100, 2.0, 1.0, 4.0, 0.10, 25000)$。\n\n答案规范和要求的输出格式：\n\n- 对每个测试用例，计算一个实数，该实数等于比较ABC后验预测样本和精确后验预测样本的Cramer–von Mises双样本统计量 $T_{\\mathrm{CvM}}$。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果（例如，$[t_1,t_2,t_3]$）。不应打印任何其他文本。\n\n所有量均为计数或无量纲；不涉及物理单位。不使用角度。所有数值输出均表示为十进制浮点数。\n\n实现约束：\n\n- 对所有随机数生成使用等于 $123$ 的固定随机种子，以确保可复现性。\n- 程序必须是自包含的，不需要任何输入，并在指定环境下运行至完成。",
            "solution": "该问题要求构建并执行一个近似贝叶斯计算（ABC）程序的校准测试。任务的核心是量化通过ABC近似的后验预测分布与相应的精确后验预测分布之间的差异。这是通过计算Cramer-von Mises（CvM）双样本统计量来实现的。模型是一个泊松似然与共轭伽马先验，这允许解析推导精确的后验分布，并因此得到精确的后验预测分布，为比较提供了一个黄金标准。\n\n首先，让我们正式定义所涉及的统计模型和分布。\n观测数据是一组 $n$ 个独立同分布的计数 $y = \\{y_1, y_2, \\dots, y_n\\}$，其中每个观测值都从一个未知速率参数 $\\theta$ 的泊松分布中抽取：\n$$y_i \\mid \\theta \\sim \\mathrm{Poisson}(\\theta)$$\n参数 $\\theta$ 本身假定服从伽马分布，作为先验分布。伽马先验，在其形状-率参数化下，由以下公式给出：\n$$\\theta \\sim \\mathrm{Gamma}(\\alpha, \\beta)$$\n其中 $\\alpha$ 是形状参数，$\\beta$ 是率参数。其概率密度函数为 $f(\\theta; \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\theta^{\\alpha-1} e^{-\\beta\\theta}$。\n\n由于伽马先验对于泊松似然是共轭的，给定数据 $y$ 的 $\\theta$ 的后验分布也是一个伽马分布。后验参数，记为 $\\alpha'$ 和 $\\beta'$，更新如下：\n$$\\alpha' = \\alpha + \\sum_{i=1}^n y_i$$\n$$\\beta' = \\beta + n$$\n因此，精确的后验分布为 $\\theta \\mid y \\sim \\mathrm{Gamma}(\\alpha', \\beta')$。\n\n后验预测分布是在参数 $\\theta$ 的不确定性（由其后验分布描述）上进行积分后，一个新的、未观测到的数据点 $y^{\\mathrm{rep}}$ 的分布。精确的后验预测分布正式定义为：\n$$p(y^{\\mathrm{rep}} \\mid y) = \\int p(y^{\\mathrm{rep}} \\mid \\theta) p(\\theta \\mid y) \\, d\\theta$$\n在本例中，这对应于一个泊松-伽马混合模型，也称为负二项分布。可以从此分布中生成样本，通过一个两步分层过程：\n1. 从后验分布中抽取一个参数值 $\\lambda$：$\\lambda \\sim \\mathrm{Gamma}(\\alpha', \\beta')$。\n2. 从具有该参数的泊松分布中抽取一个重复数据点 $y^{\\mathrm{rep}}$：$y^{\\mathrm{rep}} \\sim \\mathrm{Poisson}(\\lambda)$。\n重复此过程即可得到一个来自精确后验预测分布的样本。\n\n该问题接着指定了一个ABC程序来近似后验分布。这是一种基于模拟的方法，它绕过了似然函数的显式计算。ABC拒绝算法的步骤如下：\n1. 从先验分布中提出一个参数 $\\theta^{(j)}$：$\\theta^{(j)} \\sim \\mathrm{Gamma}(\\alpha, \\beta)$。\n2. 使用提出的参数从似然中模拟一个数据集 $y^{(j)} = \\{y_1^{(j)}, \\dots, y_n^{(j)}\\}$：$y_i^{(j)} \\sim \\mathrm{Poisson}(\\theta^{(j)})$。\n3. 为观测数据 $s_{\\mathrm{obs}} = s(y)$ 和模拟数据 $s_{\\mathrm{sim}} = s(y^{(j)})$ 计算一个摘要统计量。指定的摘要统计量是样本均值，$s(y) = \\frac{1}{n} \\sum_{i=1}^n y_i$。\n4. 计算摘要统计量之间的差异度量，$d(s_{\\mathrm{sim}}, s_{\\mathrm{obs}}) = |s_{\\mathrm{sim}} - s_{\\mathrm{obs}}|$。\n5. 如果差异 $d$ 小于或等于容差阈值 $\\varepsilon$，即 $d \\le \\varepsilon$，则接受提出的参数 $\\theta^{(j)}$ 作为后验分布的一个近似抽样。否则，拒绝它。\n对大量提议 $N_{\\mathrm{prior}}$ 重复此过程，以形成一个接受的参数集 $\\{\\theta_k^{\\mathrm{acc}}\\}_{k=1}^m$，其中 $m$ 是接受的样本总数。该集合构成了后验分布 $\\theta \\mid y$ 的一个经验近似。\n\n然后，通过取每个接受的参数 $\\theta_k^{\\mathrm{acc}}$ 并抽取一个新的数据点 $y_k^{\\mathrm{rep}} \\sim \\mathrm{Poisson}(\\theta_k^{\\mathrm{acc}})$ 来生成ABC后验预测样本。这将产生样本 $\\{y_k^{\\mathrm{rep}}\\}_{k=1}^m$。\n\n最后一步是将ABC后验预测样本与精确后验预测样本进行比较。设大小为 $m$ 的ABC预测样本为 $X = \\{x_1, \\dots, x_m\\}$，同样大小为 $m$ 的精确预测样本为 $Z = \\{z_1, \\dots, z_m\\}$。该问题要求使用双样本Cramer-von Mises（CvM）统计量来量化它们经验分布之间的差异。\n设 $F_m$ 和 $G_m$ 分别是样本 $X$ 和 $Z$ 的经验累积分布函数（ECDF）。设 $\\{w_{(i)}\\}_{i=1}^N$ 是合并样本的混合排序值，其中 $N = 2m$。CvM统计量由以下公式给出：\n$$\nT_{\\mathrm{CvM}} = \\frac{m \\cdot m}{(m+m)^2} \\sum_{i=1}^{N} \\left( F_m(w_{(i)}) - G_m(w_{(i)}) \\right)^2 = \\frac{1}{4} \\sum_{i=1}^{2m} \\left( F_m(w_{(i)}) - G_m(w_{(i)}) \\right)^2\n$$\n在此，$F_m(w)$ 是 $X$ 中小于或等于 $w$ 的元素比例，而 $G_m(w)$ 是 $Z$ 中小于或等于 $w$ 的元素比例。较小的 $T_{\\mathrm{CvM}}$ 值表示ABC近似与精确分布之间的匹配度更高。\n\n对于每个测试用例，计算过程如下，使用固定的随机种子 $123$ 以实现完全可复现性：\n1. 为特定案例设置参数 $(n, \\alpha, \\beta, \\theta_{\\mathrm{true}}, \\varepsilon, N_{\\mathrm{prior}})$。\n2. 通过从 $\\mathrm{Poisson}(\\theta_{\\mathrm{true}})$ 中抽样，生成大小为 $n$ 的观测数据集 $y_{\\mathrm{obs}}$。\n3. 对 $N_{\\mathrm{prior}}$ 个提议执行ABC拒绝算法，以获得一组 $m$ 个接受的参数 $\\{\\theta_k^{\\mathrm{acc}}\\}$。\n4. 对每个接受的参数，抽取一个 $\\mathrm{Poisson}(\\theta_k^{\\mathrm{acc}})$ 样本，以生成大小为 $m$ 的ABC后验预测样本。\n5. 计算精确后验的参数，$\\alpha' = \\alpha + \\sum y_i$ 和 $\\beta' = \\beta + n$。\n6. 通过抽取 $\\lambda_k \\sim \\mathrm{Gamma}(\\alpha', \\beta')$，然后抽取 $z_k \\sim \\mathrm{Poisson}(\\lambda_k)$（对于 $k=1, \\dots, m$）来生成大小为 $m$ 的精确后验预测样本。\n7. 使用指定的公式计算两个预测样本之间的 $T_{\\mathrm{CvM}}$ 统计量。\n对提供的三个测试用例重复整个过程。```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Runs the ABC calibration test for the three specified cases and prints the results.\n    \"\"\"\n    # Use a fixed random seed for reproducibility, as required.\n    seed = 123\n    rng = np.random.default_rng(seed)\n\n    # Test suite parameters:\n    # (n, alpha, beta, theta_true, epsilon, N_prior)\n    test_cases = [\n        (50, 2.0, 1.0, 3.0, 0.12, 20000),\n        (30, 2.0, 1.0, 1.5, 0.20, 20000),\n        (100, 2.0, 1.0, 4.0, 0.10, 25000),\n    ]\n\n    results = []\n    for case_params in test_cases:\n        # The rng object is passed to ensure the random number stream is\n        # consumed sequentially across test cases, maintaining reproducibility.\n        cvm_statistic = run_simulation_case(case_params, rng)\n        results.append(cvm_statistic)\n\n    # Print the final results in the specified format: [t_1,t_2,t_3]\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation_case(case_params, rng):\n    \"\"\"\n    Executes the full simulation and comparison for a single test case.\n\n    Args:\n        case_params (tuple): A tuple containing the parameters\n                             (n, alpha, beta, theta_true, epsilon, N_prior).\n        rng (numpy.random.Generator): The random number generator instance.\n\n    Returns:\n        float: The calculated Cramer-von Mises statistic.\n    \"\"\"\n    n, alpha, beta, theta_true, epsilon, N_prior = case_params\n\n    # Step 1: Generate observed data\n    # Generate n i.i.d. Poisson samples for the \"observed\" data.\n    y_obs = rng.poisson(theta_true, size=n)\n    s_obs = np.mean(y_obs)\n\n    # Step 2: ABC posterior via rejection\n    # Propose N_prior parameters from the prior distribution.\n    theta_proposals = rng.gamma(shape=alpha, scale=1.0/beta, size=N_prior)\n\n    # Vectorized simulation for efficiency:\n    # For each proposed theta, simulate a dataset of size n.\n    # The shape of y_sim will be (N_prior, n).\n    y_sim = rng.poisson(theta_proposals[:, np.newaxis], size=(N_prior, n))\n    \n    # Compute the summary statistic (mean) for each simulated dataset.\n    s_sim = np.mean(y_sim, axis=1)\n\n    # Apply the ABC acceptance criterion.\n    discrepancy = np.abs(s_sim - s_obs)\n    accepted_mask = discrepancy = epsilon\n    accepted_thetas = theta_proposals[accepted_mask]\n\n    m_acc = len(accepted_thetas)\n    # If no samples are accepted, the discrepancy cannot be measured.\n    # According to the problem's well-posed nature, this is not expected.\n    # We return 0.0, indicating no deviation between empty sets.\n    if m_acc == 0:\n        return 0.0\n\n    # Step 3: ABC posterior predictive sample\n    # For each accepted theta, draw one posterior predictive replicate.\n    abc_pred_sample = rng.poisson(accepted_thetas)\n\n    # Step 4: Exact posterior predictive sample\n    # Compute the parameters of the exact Gamma posterior.\n    alpha_prime = alpha + np.sum(y_obs)\n    beta_prime = beta + n\n\n    # Draw m_acc parameters from the exact posterior.\n    exact_posterior_thetas = rng.gamma(shape=alpha_prime, scale=1.0/beta_prime, size=m_acc)\n    # For each, draw one exact posterior predictive replicate.\n    exact_pred_sample = rng.poisson(exact_posterior_thetas)\n\n    # Step 5: Compute the Cramer-von Mises statistic\n    sample_1 = abc_pred_sample\n    sample_2 = exact_pred_sample\n    n_1 = len(sample_1)\n    n_2 = len(sample_2)\n    N = n_1 + n_2\n\n    # Pool and sort the observations from both samples.\n    w_pooled_sorted = np.sort(np.concatenate((sample_1, sample_2)))\n\n    # Sort each sample individually to compute ECDFs efficiently.\n    sample_1_sorted = np.sort(sample_1)\n    sample_2_sorted = np.sort(sample_2)\n\n    # Compute the ECDF values for each sample at each point in the pooled data.\n    # np.searchsorted gives the number of elements = value, which is what we need for the ECDF.\n    ecdf_1 = np.searchsorted(sample_1_sorted, w_pooled_sorted, side='right') / n_1\n    ecdf_2 = np.searchsorted(sample_2_sorted, w_pooled_sorted, side='right') / n_2\n\n    # Calculate the sum of squared differences of the ECDFs.\n    sum_sq_diff = np.sum((ecdf_1 - ecdf_2)**2)\n\n    # Apply the full formula for the CvM statistic.\n    T_cvm = (n_1 * n_2 / N**2) * sum_sq_diff\n    \n    return T_cvm\n\nif __name__ == '__main__':\n    solve()\n```",
            "answer": "[0.03852003814896081,0.04013915183376781,0.013401588661750534]"
        },
        {
            "introduction": "现在我们将视野拓宽，将 ABC 与一个密切相关且功能强大的方法——合成似然（synthetic likelihood）联系起来。这项练习  揭示了两者之间的理论联系，展示了合成似然如何被看作是 ABC 在概括统计量服从高斯分布的假设下的一种参数化形式。通过这个推导，你将加深对这两种方法的理解。",
            "id": "3288741",
            "problem": "令 $X$ 表示在由参数 $\\theta \\in \\Theta \\subset \\mathbb{R}^{p}$ 索引的参数模型下生成的数据，并令 $s(X) \\in \\mathbb{R}^{d}$ 为一个固定的低维摘要统计量。假设对于每个 $\\theta$，$s(X)\\mid \\theta$ 的分布可以很好地由一个多元正态分布近似，其均值为 $\\mu_{\\theta} \\in \\mathbb{R}^{d}$，协方差矩阵为正定的 $\\Sigma_{\\theta} \\in \\mathbb{R}^{d \\times d}$。您观察到一个单一数据集 $X_{\\mathrm{obs}}$，其观测到的摘要为 $s_{\\mathrm{obs}} = s(X_{\\mathrm{obs}})$。考虑基于摘要的近似贝叶斯计算（ABC），使用平滑核 $K_{\\epsilon}(\\cdot)$、容差 $\\epsilon  0$ 和先验密度 $\\pi(\\theta)$。基于ABC摘要的似然是核卷积\n$$\nL_{\\mathrm{ABC},\\epsilon}(\\theta) \\propto \\int_{\\mathbb{R}^{d}} K_{\\epsilon}\\!\\left(s - s_{\\mathrm{obs}}\\right)\\, p\\!\\left(s \\mid \\theta\\right)\\, ds,\n$$\n其中 $p\\!\\left(s \\mid \\theta\\right)$ 是 $s(X)\\mid \\theta$ 的抽样密度。令 $\\phi(\\cdot;\\mu,\\Sigma)$ 表示均值为 $\\mu$、协方差为 $\\Sigma$ 的 $d$ 维高斯密度。\n\n任务：\n1) 从 $L_{\\mathrm{ABC},\\epsilon}(\\theta)$ 的定义以及高斯核在 $\\epsilon \\to 0$ 时形成近似单位元的性质出发，证明如果 $s(X)\\mid \\theta$ 近似为均值为 $\\mu_{\\theta}$、协方差为 $\\Sigma_{\\theta}$ 的高斯分布，那么合成似然\n$$\nL_{\\mathrm{SL}}(\\theta) \\equiv \\phi\\!\\left(s_{\\mathrm{obs}};\\mu_{\\theta},\\Sigma_{\\theta}\\right)\n$$\n在极限 $\\epsilon \\to 0$ 时可作为参数化的近似贝叶斯计算（ABC）似然。\n2) 现在假设对于一个固定的 $\\theta$，您可以执行独立模拟，从 $s(X)\\mid \\theta$ 的分布中获得 $m \\in \\mathbb{N}$ 个独立重复样本 $s^{(1)},\\dots,s^{(m)}$。仅使用期望和协方差的定义，推导基于 $\\{s^{(i)}\\}_{i=1}^{m}$ 的蒙特卡洛估计量 $\\widehat{\\mu}_{\\theta}$ 和 $\\widehat{\\Sigma}_{\\theta}$，在 $s(X)\\mid \\theta$ 精确为高斯分布的条件下，这些估计量对于 $\\mu_{\\theta}$ 和 $\\Sigma_{\\theta}$ 是无偏的；用 $\\{s^{(i)}\\}_{i=1}^{m}$ 和 $m$ 以闭合形式表示您的答案。您可以视 $d$ 为固定且有限的，并且可以假设通常的正则性条件，以确保近似单位元的积分和极限可以互换。\n\n您的最终答案必须包含一个单行矩阵，按顺序包含：$L_{\\mathrm{SL}}(\\theta)$ 作为 $s_{\\mathrm{obs}},\\mu_{\\theta},\\Sigma_{\\theta}$ 函数的显式闭合形式表达式，接着是 $\\widehat{\\mu}_{\\theta}$，然后是 $\\widehat{\\Sigma}_{\\theta}$。不需要进行数值计算，也不需要四舍五入。所有符号必须在您的推导中定义。最终答案中不要包含任何单位。",
            "solution": "该问题包含两部分。第一部分要求证明合成似然 $L_{\\mathrm{SL}}(\\theta)$ 可以被看作是近似贝叶斯计算（ABC）似然 $L_{\\mathrm{ABC},\\epsilon}(\\theta)$ 的一个极限情况。第二部分要求基于一组模拟重复样本，推导高斯分布摘要统计量的均值和协方差的无偏估计量。\n\n**第一部分：作为极限ABC似然的合成似然**\n\n问题给出了基于ABC摘要的似然的定义，即核卷积：\n$$\nL_{\\mathrm{ABC},\\epsilon}(\\theta) \\propto \\int_{\\mathbb{R}^{d}} K_{\\epsilon}\\!\\left(s - s_{\\mathrm{obs}}\\right)\\, p\\!\\left(s \\mid \\theta\\right)\\, ds\n$$\n此处，$p(s \\mid \\theta)$ 是在给定参数 $\\theta$ 的情况下摘要统计量 $s(X)$ 的抽样密度，$s_{\\mathrm{obs}}$ 是观测到的摘要统计量，而 $K_{\\epsilon}$ 是一个容差为 $\\epsilon  0$ 的平滑核。\n\n问题指出我们应该使用一个在 $\\epsilon \\to 0$ 时形成近似单位元的高斯核。一个近似单位元是一个函数序列 $\\{K_{\\epsilon}\\}_{\\epsilon  0}$，在极限 $\\epsilon \\to 0$ 时收敛于狄拉克δ函数 $\\delta$。对于任何行为良好的函数 $f$，与近似单位元的卷积具有以下性质：\n$$\n\\lim_{\\epsilon \\to 0} \\int_{\\mathbb{R}^{d}} K_{\\epsilon}(x-y) f(y) dy = f(x)\n$$\n在我们的情况下，函数是摘要统计量的似然，$f(s) = p(s \\mid \\theta)$，我们在 $s_{\\mathrm{obs}}$ 处计算卷积。假设核是对称的，$K_{\\epsilon}(u) = K_{\\epsilon}(-u)$，积分可以写成：\n$$\n\\int_{\\mathbb{R}^{d}} K_{\\epsilon}\\!\\left(s - s_{\\mathrm{obs}}\\right)\\, p\\!\\left(s \\mid \\theta\\right)\\, ds = \\int_{\\mathbb{R}^{d}} K_{\\epsilon}\\!\\left(s_{\\mathrm{obs}} - s\\right)\\, p\\!\\left(s \\mid \\theta\\right)\\, ds\n$$\n这是卷积 $(K_{\\epsilon} * p(\\cdot \\mid \\theta))(s_{\\mathrm{obs}})$。当 $\\epsilon \\to 0$ 时，近似单位元的性质意味着这个卷积收敛于在 $s_{\\mathrm{obs}}$ 处求值的函数 $p(\\cdot \\mid \\theta)$。\n$$\n\\lim_{\\epsilon \\to 0} L_{\\mathrm{ABC},\\epsilon}(\\theta) \\propto \\lim_{\\epsilon \\to 0} \\int_{\\mathbb{R}^{d}} K_{\\epsilon}\\!\\left(s - s_{\\mathrm{obs}}\\right)\\, p\\!\\left(s \\mid \\theta\\right)\\, ds = p(s_{\\mathrm{obs}} \\mid \\theta)\n$$\n这表明在零容差的极限下，ABC似然与摘要统计量的真实似然成正比。\n\n问题接着引入了假设，即 $s(X) \\mid \\theta$ 的分布可以很好地由一个均值为 $\\mu_{\\theta}$、协方差为 $\\Sigma_{\\theta}$ 的 $d$ 维正态分布近似。这意味着我们可以用高斯概率密度函数 $\\phi(s; \\mu_{\\theta}, \\Sigma_{\\theta})$ 来近似抽样密度 $p(s \\mid \\theta)$：\n$$\np(s \\mid \\theta) \\approx \\phi(s; \\mu_{\\theta}, \\Sigma_{\\theta})\n$$\n将这个近似代入我们的极限结果中，得到：\n$$\n\\lim_{\\epsilon \\to 0} L_{\\mathrm{ABC},\\epsilon}(\\theta) \\propto \\phi(s_{\\mathrm{obs}}; \\mu_{\\theta}, \\Sigma_{\\theta})\n$$\n右边的表达式正是合成似然 $L_{\\mathrm{SL}}(\\theta)$ 的定义。\n$$\nL_{\\mathrm{SL}}(\\theta) \\equiv \\phi(s_{\\mathrm{obs}}; \\mu_{\\theta}, \\Sigma_{\\theta})\n$$\n因此，当 $\\epsilon \\to 0$ 时，合成似然可作为ABC似然的参数化近似。\n\n$d$ 维高斯密度 $\\phi(x; \\mu, \\Sigma)$ 的显式闭合形式表达式为：\n$$\n\\phi(x; \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{d/2} \\det(\\Sigma)^{1/2}} \\exp\\left(-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-1} (x-\\mu)\\right)\n$$\n因此，合成似然为：\n$$\nL_{\\mathrm{SL}}(\\theta) = \\frac{1}{(2\\pi)^{d/2} \\det(\\Sigma_{\\theta})^{1/2}} \\exp\\left(-\\frac{1}{2}(s_{\\mathrm{obs}}-\\mu_{\\theta})^T \\Sigma_{\\theta}^{-1} (s_{\\mathrm{obs}}-\\mu_{\\theta})\\right)\n$$\n\n**第二部分：无偏估计量的推导**\n\n我们有从 $s(X)\\mid \\theta$ 分布中抽取的 $m$ 个独立同分布（i.i.d.）的重复样本 $s^{(1)}, \\dots, s^{(m)}$。在这一部分，我们假设这个分布是精确的高斯分布，$s^{(i)} \\sim \\mathcal{N}(\\mu_{\\theta}, \\Sigma_{\\theta})$。我们需要为 $\\mu_{\\theta}$ 和 $\\Sigma_{\\theta}$ 推导无偏估计量。\n\n**均值 $\\mu_{\\theta}$ 的无偏估计量**\n总体均值的标准估计量是样本均值。我们定义估计量 $\\widehat{\\mu}_{\\theta}$ 为：\n$$\n\\widehat{\\mu}_{\\theta} = \\frac{1}{m} \\sum_{i=1}^{m} s^{(i)}\n$$\n为了证明它是无偏的，我们必须证明其期望值为 $\\mu_{\\theta}$。利用期望的线性性质：\n$$\nE[\\widehat{\\mu}_{\\theta}] = E\\left[\\frac{1}{m} \\sum_{i=1}^{m} s^{(i)}\\right] = \\frac{1}{m} \\sum_{i=1}^{m} E[s^{(i)}]\n$$\n由于每个 $s^{(i)}$ 都是从均值为 $\\mu_{\\theta}$ 的分布中抽取的，所以对于所有的 $i \\in \\{1, \\dots, m\\}$，我们有 $E[s^{(i)}] = \\mu_{\\theta}$。\n$$\nE[\\widehat{\\mu}_{\\theta}] = \\frac{1}{m} \\sum_{i=1}^{m} \\mu_{\\theta} = \\frac{1}{m} (m \\mu_{\\theta}) = \\mu_{\\theta}\n$$\n这证实了 $\\widehat{\\mu}_{\\theta}$ 是 $\\mu_{\\theta}$ 的一个无偏估计量。\n\n**协方差 $\\Sigma_{\\theta}$ 的无偏估计量**\n总体协方差的标准无偏估计量是样本协方差矩阵，它包含了贝塞尔校正。我们定义估计量 $\\widehat{\\Sigma}_{\\theta}$ 为：\n$$\n\\widehat{\\Sigma}_{\\theta} = \\frac{1}{m-1} \\sum_{i=1}^{m} (s^{(i)} - \\widehat{\\mu}_{\\theta})(s^{(i)} - \\widehat{\\mu}_{\\theta})^T\n$$\n为了证明其无偏性，我们计算它的期望。让我们首先分析求和项 $\\sum_{i=1}^{m} (s^{(i)} - \\widehat{\\mu}_{\\theta})(s^{(i)} - \\widehat{\\mu}_{\\theta})^T$。我们可以通过加上和减去真实均值 $\\mu_{\\theta}$ 来重写求和内的项：\n$$\ns^{(i)} - \\widehat{\\mu}_{\\theta} = (s^{(i)} - \\mu_{\\theta}) - (\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})\n$$\n求和变为：\n\\begin{align*}\n\\sum_{i=1}^{m} (s^{(i)} - \\widehat{\\mu}_{\\theta})(s^{(i)} - \\widehat{\\mu}_{\\theta})^T = \\sum_{i=1}^{m} \\left[(s^{(i)} - \\mu_{\\theta}) - (\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})\\right]\\left[(s^{(i)} - \\mu_{\\theta}) - (\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})\\right]^T \\\\\n= \\sum_{i=1}^{m} (s^{(i)} - \\mu_{\\theta})(s^{(i)} - \\mu_{\\theta})^T - \\sum_{i=1}^m (s^{(i)} - \\mu_{\\theta})(\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})^T \\\\\n \\quad - \\sum_{i=1}^m (\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})(s^{(i)} - \\mu_{\\theta})^T + \\sum_{i=1}^m (\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})(\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})^T\n\\end{align*}\n我们注意到 $\\sum_{i=1}^{m} (s^{(i)} - \\mu_{\\theta}) = m(\\frac{1}{m}\\sum s^{(i)}) - m\\mu_{\\theta} = m(\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})$。利用这一点，表达式简化为：\n$$\n\\sum_{i=1}^{m} (s^{(i)} - \\mu_{\\theta})(s^{(i)} - \\mu_{\\theta})^T - m(\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})(\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})^T\n$$\n现在，我们对这个表达式取期望：\n$$\nE\\left[ \\sum_{i=1}^{m} (s^{(i)} - \\widehat{\\mu}_{\\theta})(s^{(i)} - \\widehat{\\mu}_{\\theta})^T \\right] = E\\left[\\sum_{i=1}^{m} (s^{(i)} - \\mu_{\\theta})(s^{(i)} - \\mu_{\\theta})^T\\right] - m E\\left[(\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})(\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})^T\\right]\n$$\n右手边的第一项是：\n$$\nE\\left[\\sum_{i=1}^{m} (s^{(i)} - \\mu_{\\theta})(s^{(i)} - \\mu_{\\theta})^T\\right] = \\sum_{i=1}^{m} E\\left[(s^{(i)} - \\mu_{\\theta})(s^{(i)} - \\mu_{\\theta})^T\\right] = \\sum_{i=1}^{m} \\text{Cov}(s^{(i)}) = \\sum_{i=1}^{m} \\Sigma_{\\theta} = m\\Sigma_{\\theta}\n$$\n第二项涉及样本均值的协方差矩阵，$\\text{Cov}(\\widehat{\\mu}_{\\theta}) = E\\left[(\\widehat{\\mu}_{\\theta} - E[\\widehat{\\mu}_{\\theta}])(\\widehat{\\mu}_{\\theta} - E[\\widehat{\\mu}_{\\theta}])^T\\right] = E\\left[(\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})(\\widehat{\\mu}_{\\theta} - \\mu_{\\theta})^T\\right]$。\n$$\n\\text{Cov}(\\widehat{\\mu}_{\\theta}) = \\text{Cov}\\left(\\frac{1}{m}\\sum_{i=1}^{m} s^{(i)}\\right) = \\frac{1}{m^2}\\text{Cov}\\left(\\sum_{i=1}^{m} s^{(i)}\\right)\n$$\n由于样本 $s^{(i)}$ 是独立的，和的协方差是协方差的和：\n$$\n\\text{Cov}(\\widehat{\\mu}_{\\theta}) = \\frac{1}{m^2} \\sum_{i=1}^{m} \\text{Cov}(s^{(i)}) = \\frac{1}{m^2} \\sum_{i=1}^{m} \\Sigma_{\\theta} = \\frac{1}{m^2}(m\\Sigma_{\\theta}) = \\frac{1}{m}\\Sigma_{\\theta}\n$$\n将这些结果代回，我们得到：\n$$\nE\\left[ \\sum_{i=1}^{m} (s^{(i)} - \\widehat{\\mu}_{\\theta})(s^{(i)} - \\widehat{\\mu}_{\\theta})^T \\right] = m\\Sigma_{\\theta} - m\\left(\\frac{1}{m}\\Sigma_{\\theta}\\right) = (m-1)\\Sigma_{\\theta}\n$$\n因此，我们提出的估计量 $\\widehat{\\Sigma}_{\\theta}$ 的期望是：\n$$\nE[\\widehat{\\Sigma}_{\\theta}] = E\\left[ \\frac{1}{m-1} \\sum_{i=1}^{m} (s^{(i)} - \\widehat{\\mu}_{\\theta})(s^{(i)} - \\widehat{\\mu}_{\\theta})^T \\right] = \\frac{1}{m-1} E\\left[ \\sum_{i=1}^{m} (s^{(i)} - \\widehat{\\mu}_{\\theta})(s^{(i)} - \\widehat{\\mu}_{\\theta})^T \\right] = \\frac{1}{m-1} (m-1)\\Sigma_{\\theta} = \\Sigma_{\\theta}\n$$\n这证实了 $\\widehat{\\Sigma}_{\\theta}$ 是 $\\Sigma_{\\theta}$ 的一个无偏估计量。\n\n最终答案由 $L_{\\mathrm{SL}}(\\theta)$ 的闭合形式表达式、估计量 $\\widehat{\\mu}_{\\theta}$ 和估计量 $\\widehat{\\Sigma}_{\\theta}$ 组成。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{(2\\pi)^{d/2} \\det(\\Sigma_{\\theta})^{1/2}} \\exp\\left(-\\frac{1}{2}(s_{\\mathrm{obs}}-\\mu_{\\theta})^T \\Sigma_{\\theta}^{-1} (s_{\\mathrm{obs}}-\\mu_{\\theta})\\right)  \\frac{1}{m}\\sum_{i=1}^{m} s^{(i)}  \\frac{1}{m-1}\\sum_{i=1}^{m} (s^{(i)} - \\widehat{\\mu}_{\\theta})(s^{(i)} - \\widehat{\\mu}_{\\theta})^T \\end{pmatrix}}\n$$"
        }
    ]
}