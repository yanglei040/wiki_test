{
    "hands_on_practices": [
        {
            "introduction": "蒙特卡洛 Dropout（MC Dropout）通常被视为深度神经网络中贝叶斯推断的一种易于处理的近似方法。为了对这种关联建立坚实的直觉，本练习将剥离深度学习的复杂性，回归到一个基础模型：贝叶斯线性回归。通过分析性地推导并比较 MC Dropout 和真实贝叶斯后验的预测方差，你将对 MC dropout 所近似的对象以及二者之间的差异获得清晰的、定量的理解 。",
            "id": "3321131",
            "problem": "考虑一个带有加性高斯噪声的线性回归模型，其中观测到的响应向量建模为 $y \\in \\mathbb{R}^{n}$，特征收集在设计矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 中，回归系数为 $\\beta \\in \\mathbb{R}^{d}$。数据生成过程为 $y = X \\beta + \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2} I_{n})$，$\\sigma_{\\epsilon}^{2} > 0$ 已知，且 $I_{n}$ 是 $n \\times n$ 的单位矩阵。假设回归系数服从高斯先验 $\\beta \\sim \\mathcal{N}(0, \\sigma_{\\beta}^{2} I_{d})$，其中 $\\sigma_{\\beta}^{2} > 0$ 且 $I_{d}$ 是 $d \\times d$ 的单位矩阵。\n\n在测试时，对于单个新特征向量 $x^{\\ast} \\in \\mathbb{R}^{d}$，考虑使用独立伯努利掩码的特征级蒙特卡洛 (MC) dropout。具体来说，定义一个随机掩码向量 $m \\in \\{0,1\\}^{d}$，其分量 $m_{i}$ 对于 $i \\in \\{1,\\dots,d\\}$ 是独立的，且服从 $m_{i} \\sim \\mathrm{Bernoulli}(q)$，其中 $q \\in (0,1)$ 是保留概率。掩码后的输入为 $x^{\\ast}_{m} = m \\odot x^{\\ast}$，其中 $\\odot$ 表示逐元素乘法。单次 MC dropout 预测抽取生成为 $y^{\\ast} = (x^{\\ast}_{m})^{\\top} \\hat{\\beta} + \\epsilon^{\\ast}$，其中 $\\epsilon^{\\ast} \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2})$ 独立于 $m$，且 $\\hat{\\beta} \\in \\mathbb{R}^{d}$ 是 $\\beta$ 的一个固定估计量。在此设置中，$\\hat{\\beta}$ 采用在所述高斯先验和似然下的最大后验 (MAP) 估计量。\n\n任务：\n- 通过对掩码 $m$ 和噪声 $\\epsilon^{\\ast}$ 的随机性进行平均，推导 MC dropout 预测均值 $\\mathbb{E}[y^{\\ast} \\mid x^{\\ast}, \\hat{\\beta}]$ 和方差 $\\mathrm{Var}(y^{\\ast} \\mid x^{\\ast}, \\hat{\\beta})$。\n- 在高斯先验 $\\beta \\sim \\mathcal{N}(0, \\sigma_{\\beta}^{2} I_{d})$ 和高斯似然 $y \\mid \\beta \\sim \\mathcal{N}(X \\beta, \\sigma_{\\epsilon}^{2} I_{n})$ 下，推导精确贝叶斯线性回归后验预测均值和方差。\n- 使用等于 $\\beta$ 的精确后验均值的 MAP 估计量 $\\hat{\\beta}$，为以下差值提供一个单一的闭式解析表达式：\n$$\\Delta(x^{\\ast}) = \\mathrm{Var}(y^{\\ast} \\mid x^{\\ast}, \\text{MC dropout}) - \\mathrm{Var}(y^{\\ast} \\mid x^{\\ast}, \\text{Bayesian posterior predictive}).$$\n\n将您的最终答案表示为 $\\Delta(x^{\\ast})$ 的单个符号表达式。无需四舍五入，也不涉及物理单位。清晰地定义和使用所有符号。",
            "solution": "该问题要求推导蒙特卡洛 (MC) dropout 和贝叶斯线性回归的预测矩，并最终计算它们预测方差之间的差值。我们将系统地处理每个部分。\n\n### **第 1 部分：MC Dropout 预测均值和方差**\n\n单次 MC dropout 预测抽取的模型由 $y^{\\ast} = (x^{\\ast}_{m})^{\\top} \\hat{\\beta} + \\epsilon^{\\ast}$ 给出，其中 $x^{\\ast}_{m} = m \\odot x^{\\ast}$。此表达式中的随机变量是掩码向量 $m$ 和噪声项 $\\epsilon^{\\ast}$。掩码的分量 $m_i$ 是独立同分布的，服从 $\\mathrm{Bernoulli}(q)$ 分布，且 $\\epsilon^{\\ast} \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2})$。在此计算中，估计量 $\\hat{\\beta}$ 被视为一个固定量。\n\n预测均值是 $y^{\\ast}$ 在 $m$ 和 $\\epsilon^{\\ast}$ 分布上的期望。根据期望的线性性质：\n$$\n\\mathbb{E}[y^{\\ast} \\mid x^{\\ast}, \\hat{\\beta}] = \\mathbb{E}[(m \\odot x^{\\ast})^{\\top} \\hat{\\beta} + \\epsilon^{\\ast}] = \\mathbb{E}[(m \\odot x^{\\ast})^{\\top} \\hat{\\beta}] + \\mathbb{E}[\\epsilon^{\\ast}]\n$$\n已知 $\\epsilon^{\\ast} \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2})$，我们有 $\\mathbb{E}[\\epsilon^{\\ast}] = 0$。第一项可以写为：\n$$\n\\mathbb{E}[(m \\odot x^{\\ast})^{\\top} \\hat{\\beta}] = \\mathbb{E}\\left[\\sum_{i=1}^{d} m_i x_i^{\\ast} \\hat{\\beta}_i\\right] = \\sum_{i=1}^{d} \\mathbb{E}[m_i] x_i^{\\ast} \\hat{\\beta}_i\n$$\n对于一个伯努利随机变量 $m_i \\sim \\mathrm{Bernoulli}(q)$，其期望为 $\\mathbb{E}[m_i] = q$。将其代回可得：\n$$\n\\mathbb{E}[y^{\\ast} \\mid x^{\\ast}, \\hat{\\beta}] = \\sum_{i=1}^{d} q x_i^{\\ast} \\hat{\\beta}_i = q (x^{\\ast})^{\\top} \\hat{\\beta}\n$$\n\n预测方差使用全方差公式计算。由于 $m$ 和 $\\epsilon^{\\ast}$ 是独立的，它们和的方差等于它们方差的和：\n$$\n\\mathrm{Var}(y^{\\ast} \\mid x^{\\ast}, \\hat{\\beta}) = \\mathrm{Var}((m \\odot x^{\\ast})^{\\top} \\hat{\\beta} + \\epsilon^{\\ast}) = \\mathrm{Var}((m \\odot x^{\\ast})^{\\top} \\hat{\\beta}) + \\mathrm{Var}(\\epsilon^{\\ast})\n$$\n我们已知 $\\mathrm{Var}(\\epsilon^{\\ast}) = \\sigma_{\\epsilon}^{2}$。对于第一项，我们利用掩码分量 $m_i$ 的独立性：\n$$\n\\mathrm{Var}((m \\odot x^{\\ast})^{\\top} \\hat{\\beta}) = \\mathrm{Var}\\left(\\sum_{i=1}^{d} m_i x_i^{\\ast} \\hat{\\beta}_i\\right) = \\sum_{i=1}^{d} \\mathrm{Var}(m_i x_i^{\\ast} \\hat{\\beta}_i)\n$$\n由于 $x_i^{\\ast}$ 和 $\\hat{\\beta}_i$ 在此上下文中是常数，我们有：\n$$\n\\mathrm{Var}(m_i x_i^{\\ast} \\hat{\\beta}_i) = (x_i^{\\ast} \\hat{\\beta}_i)^2 \\mathrm{Var}(m_i)\n$$\n对于一个伯努利随机变量 $m_i \\sim \\mathrm{Bernoulli}(q)$，其方差为 $\\mathrm{Var}(m_i) = q(1-q)$。因此，\n$$\n\\mathrm{Var}((m \\odot x^{\\ast})^{\\top} \\hat{\\beta}) = \\sum_{i=1}^{d} (x_i^{\\ast} \\hat{\\beta}_i)^2 q(1-q) = q(1-q) \\sum_{i=1}^{d} (x_i^{\\ast} \\hat{\\beta}_i)^2\n$$\n合并这些项，MC dropout 预测方差为：\n$$\n\\mathrm{Var}(y^{\\ast} \\mid x^{\\ast}, \\text{MC dropout}) = q(1-q) \\sum_{i=1}^{d} (\\hat{\\beta}_i x_i^{\\ast})^2 + \\sigma_{\\epsilon}^{2}\n$$\n\n### **第 2 部分：贝叶斯线性回归后验预测**\n\n在贝叶斯框架中，我们首先确定在给定数据 $(X, y)$ 的情况下，系数 $\\beta$ 的后验分布。后验分布与似然和先验的乘积成正比：$p(\\beta \\mid X, y) \\propto p(y \\mid X, \\beta) p(\\beta)$。\n似然为 $p(y \\mid X, \\beta) \\sim \\mathcal{N}(X\\beta, \\sigma_{\\epsilon}^{2} I_n)$，先验为 $p(\\beta) \\sim \\mathcal{N}(0, \\sigma_{\\beta}^{2} I_d)$。\n$\\beta$ 的后验分布是一个高斯分布 $p(\\beta \\mid X, y) = \\mathcal{N}(\\mu_{\\beta}, \\Sigma_{\\beta})$，其协方差 $\\Sigma_{\\beta}$ 和均值 $\\mu_{\\beta}$ 由以下公式给出：\n$$\n\\Sigma_{\\beta}^{-1} = \\frac{1}{\\sigma_{\\epsilon}^{2}} X^{\\top}X + \\frac{1}{\\sigma_{\\beta}^{2}} I_d \\implies \\Sigma_{\\beta} = \\left(\\frac{1}{\\sigma_{\\epsilon}^{2}} X^{\\top}X + \\frac{1}{\\sigma_{\\beta}^{2}} I_d\\right)^{-1}\n$$\n$$\n\\mu_{\\beta} = \\Sigma_{\\beta} \\left(\\frac{1}{\\sigma_{\\epsilon}^{2}} X^{\\top}y\\right) = \\left(\\frac{1}{\\sigma_{\\epsilon}^{2}} X^{\\top}X + \\frac{1}{\\sigma_{\\beta}^{2}} I_d\\right)^{-1} \\frac{1}{\\sigma_{\\epsilon}^{2}} X^{\\top}y\n$$\n让我们定义正则化参数 $\\lambda = \\frac{\\sigma_{\\epsilon}^2}{\\sigma_{\\beta}^2}$。那么我们可以写成：\n$$\n\\Sigma_{\\beta} = \\sigma_{\\epsilon}^2 (X^{\\top}X + \\lambda I_d)^{-1}\n$$\n$$\n\\mu_{\\beta} = (X^{\\top}X + \\lambda I_d)^{-1} X^{\\top}y\n$$\n这个后验均值 $\\mu_{\\beta}$ 是 $\\beta$ 的 MAP 估计量。问题陈述中提到，MC dropout 部分使用的 $\\hat{\\beta}$ 就是这个 MAP 估计量，因此我们有 $\\hat{\\beta} = \\mu_{\\beta}$。\n\n对于输入 $x^{\\ast}$ 的一个新观测值 $y^{\\ast}$，其后验预测分布为 $p(y^{\\ast} \\mid x^{\\ast}, X, y) = \\int p(y^{\\ast} \\mid x^{\\ast}, \\beta) p(\\beta \\mid X, y) d\\beta$。\n给定 $y^{\\ast} = (x^{\\ast})^{\\top}\\beta + \\epsilon^{\\ast}$ 且 $\\epsilon^{\\ast} \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2)$，预测分布也是高斯分布。其均值为：\n$$\n\\mathbb{E}[y^{\\ast} \\mid x^{\\ast}, X, y] = \\mathbb{E}_{\\beta \\mid X,y}[\\mathbb{E}[y^{\\ast} \\mid \\beta]] = \\mathbb{E}_{\\beta \\mid X,y}[(x^{\\ast})^{\\top}\\beta] = (x^{\\ast})^{\\top} \\mu_{\\beta} = (x^{\\ast})^{\\top} \\hat{\\beta}\n$$\n其方差使用全方差公式计算：\n$$\n\\mathrm{Var}(y^{\\ast} \\mid x^{\\ast}, X, y) = \\mathbb{E}_{\\beta \\mid X,y}[\\mathrm{Var}(y^{\\ast} \\mid \\beta)] + \\mathrm{Var}_{\\beta \\mid X,y}(\\mathbb{E}[y^{\\ast} \\mid \\beta])\n$$\n第一项是期望的数据方差（偶然不确定性）：$\\mathbb{E}_{\\beta \\mid X,y}[\\sigma_{\\epsilon}^2] = \\sigma_{\\epsilon}^2$。\n第二项是由于 $\\beta$ 的不确定性而导致的平均预测值的方差（认知不确定性）：\n$$\n\\mathrm{Var}_{\\beta \\mid X,y}((x^{\\ast})^{\\top}\\beta) = (x^{\\ast})^{\\top} \\mathrm{Var}_{\\beta \\mid X,y}(\\beta) x^{\\ast} = (x^{\\ast})^{\\top} \\Sigma_{\\beta} x^{\\ast}\n$$\n因此，贝叶斯后验预测方差为：\n$$\n\\mathrm{Var}(y^{\\ast} \\mid x^{\\ast}, \\text{Bayesian posterior predictive}) = \\sigma_{\\epsilon}^{2} + (x^{\\ast})^{\\top} \\Sigma_{\\beta} x^{\\ast}\n$$\n\n### **第 3 部分：方差之差**\n\n我们需要计算 $\\Delta(x^{\\ast})$，即 MC dropout 方差与贝叶斯后验预测方差之间的差值。\n$$\n\\Delta(x^{\\ast}) = \\mathrm{Var}(y^{\\ast} \\mid x^{\\ast}, \\text{MC dropout}) - \\mathrm{Var}(y^{\\ast} \\mid x^{\\ast}, \\text{Bayesian posterior predictive})\n$$\n代入前面部分推导出的表达式：\n$$\n\\Delta(x^{\\ast}) = \\left( q(1-q) \\sum_{i=1}^{d} (\\hat{\\beta}_i x_i^{\\ast})^2 + \\sigma_{\\epsilon}^{2} \\right) - \\left( \\sigma_{\\epsilon}^{2} + (x^{\\ast})^{\\top} \\Sigma_{\\beta} x^{\\ast} \\right)\n$$\n偶然不确定性项 $\\sigma_{\\epsilon}^{2}$ 被消掉了：\n$$\n\\Delta(x^{\\ast}) = q(1-q) \\sum_{i=1}^{d} (\\hat{\\beta}_i x_i^{\\ast})^2 - (x^{\\ast})^{\\top} \\Sigma_{\\beta} x^{\\ast}\n$$\n第一项是关于 $x^{\\ast}$ 的二次型。设 $\\hat{\\beta} \\odot \\hat{\\beta}$ 是 $\\hat{\\beta}$ 逐元素平方的向量，即 $(\\hat{\\beta}_1^2, \\dots, \\hat{\\beta}_d^2)^{\\top}$，并设 $\\mathrm{diag}(v)$ 表示一个对角线元素为向量 $v$ 元素的对角矩阵。那么，该求和可以写为 $(x^{\\ast})^{\\top} \\mathrm{diag}(\\hat{\\beta} \\odot \\hat{\\beta}) x^{\\ast}$。\n所以，我们有：\n$$\n\\Delta(x^{\\ast}) = q(1-q) (x^{\\ast})^{\\top} \\mathrm{diag}(\\hat{\\beta} \\odot \\hat{\\beta}) x^{\\ast} - (x^{\\ast})^{\\top} \\Sigma_{\\beta} x^{\\ast}\n$$\n这可以紧凑地表示为单个二次型：\n$$\n\\Delta(x^{\\ast}) = (x^{\\ast})^{\\top} \\left( q(1-q) \\mathrm{diag}(\\hat{\\beta} \\odot \\hat{\\beta}) - \\Sigma_{\\beta} \\right) x^{\\ast}\n$$\n为了得到最终表达式，我们代入 $\\Sigma_{\\beta}$ 的定义：\n$$\n\\Sigma_{\\beta} = \\sigma_{\\epsilon}^2(X^{\\top}X + \\frac{\\sigma_{\\epsilon}^2}{\\sigma_{\\beta}^2} I_d)^{-1}\n$$\nMAP 估计量 $\\hat{\\beta}$ 定义为 $\\hat{\\beta} = (X^{\\top}X + \\frac{\\sigma_{\\epsilon}^2}{\\sigma_{\\beta}^2} I_d)^{-1}X^{\\top}y$。因此，$\\Delta(x^{\\ast})$ 的最终表达式是输入 $x^{\\ast}$、数据 $(X, y)$ 和模型超参数 $q, \\sigma_{\\epsilon}^2, \\sigma_{\\beta}^2$ 的函数。对于最终答案，求和表示法是明确和清晰的。\n\n差值的最终表达式：\n$$\n\\Delta(x^{\\ast}) = q(1-q) \\sum_{i=1}^{d} (\\hat{\\beta}_i x_i^{\\ast})^2 - \\sigma_{\\epsilon}^2 (x^{\\ast})^{\\top} \\left(X^{\\top}X + \\frac{\\sigma_{\\epsilon}^2}{\\sigma_{\\beta}^2} I_d\\right)^{-1} x^{\\ast}\n$$\n其中 $\\hat{\\beta} = (X^{\\top}X + \\frac{\\sigma_{\\epsilon}^2}{\\sigma_{\\beta}^2} I_d)^{-1}X^{\\top}y$。",
            "answer": "$$\n\\boxed{q(1-q) \\sum_{i=1}^{d} (\\hat{\\beta}_i x_i^{\\ast})^2 - \\sigma_{\\epsilon}^2 (x^{\\ast})^{\\top} \\left(X^{\\top}X + \\frac{\\sigma_{\\epsilon}^2}{\\sigma_{\\beta}^2} I_d\\right)^{-1} x^{\\ast}}\n$$"
        },
        {
            "introduction": "从随机模拟的视角审视 MC Dropout，可以发现其估计值会受到采样方差的影响。本练习将介绍蒙特卡洛方法工具箱中的一种强大技术——控制变量法（control variates），以提高估计器的效率。你将学习如何利用计算成本低廉的、模型的确定性输出来构建一个方差显著更低的无偏估计器，这对于在有限的计算预算下获得可靠的不确定性估计至关重要 。",
            "id": "3321186",
            "problem": "考虑一个在蒙特卡洛（MC） dropout下用于预测不确定性的回归模型。令 $x \\in \\mathbb{R}^{d}$ 为固定值，模型权重为 $\\theta \\in \\mathbb  R}^{d}$。将确定性的无dropout输出定义为 $f(x;\\theta) = \\theta^{\\top} x$。在MC dropout预测期间，输入的每个分量由一个掩码 $M \\in \\{0,1\\}^{d}$ 随机保留，其条目 $M_{i} \\sim \\mathrm{Bernoulli}(q)$ 是独立的，其中 $q \\in (0,1)$ 是保留概率。应用反向dropout缩放，使得随机输出为\n$$\nf_{\\mathrm{drop}}(x;\\theta,M) = \\theta^{\\top} \\left( \\frac{M \\odot x}{q} \\right).\n$$\n假设存在与 $M$ 无关的加性偶然噪声 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^{2})$，因此单次预测抽取为\n$$\ny = f_{\\mathrm{drop}}(x;\\theta,M) + \\varepsilon.\n$$\n目标量是条件期望 $\\mathbb{E}[y \\mid x]$。您使用 $N$ 个独立样本 $\\{(M^{(i)},\\varepsilon^{(i)})\\}_{i=1}^{N}$ 通过MC方法估计 $\\mathbb{E}[y \\mid x]$，得到朴素估计量 $\\hat{\\mu}_{\\mathrm{MC}} = \\frac{1}{N} \\sum_{i=1}^{N} y^{(i)}$，其中 $y^{(i)} = f_{\\mathrm{drop}}(x;\\theta,M^{(i)}) + \\varepsilon^{(i)}$。\n\n请提出一个能够明确使用确定性无dropout输出 $f(x;\\theta)$ 的方差缩减控制变量，并能得到 $\\mathbb{E}[y \\mid x]$ 的无偏估计量。然后，以封闭形式推导并计算最小化所得估计量方差的最优控制变量系数，结果应为一个实数。您的答案必须是一个无单位的单一数值。无需四舍五入。",
            "solution": "目标是使用控制变量法找到 $\\mu = \\mathbb{E}[y \\mid x]$ 的一个方差缩减的无偏估计量。该控制变量应利用确定性输出 $f(x;\\theta) = \\theta^{\\top} x$。\n\n首先，我们计算目标量 $\\mu$。单次预测抽取为 $y = f_{\\mathrm{drop}}(x;\\theta,M) + \\varepsilon$。对 $x$ 取条件期望：\n$$\n\\mu = \\mathbb{E}[y \\mid x] = \\mathbb{E}[f_{\\mathrm{drop}}(x;\\theta,M) + \\varepsilon \\mid x]\n$$\n根据期望的线性性质以及条件是基于已固定的 $x$ 这一事实：\n$$\n\\mu = \\mathbb{E}[f_{\\mathrm{drop}}(x;\\theta,M)] + \\mathbb{E}[\\varepsilon]\n$$\n偶然噪声 $\\varepsilon$ 来自均值为零的分布 $\\mathcal{N}(0,\\sigma^2)$，因此 $\\mathbb{E}[\\varepsilon]=0$。随机输出的期望为：\n$$\n\\mathbb{E}[f_{\\mathrm{drop}}(x;\\theta,M)] = \\mathbb{E}\\left[\\theta^{\\top} \\left( \\frac{M \\odot x}{q} \\right)\\right] = \\frac{1}{q} \\theta^{\\top} \\mathbb{E}[M \\odot x]\n$$\n由于 $x$ 和 $\\theta$ 不是随机的，我们有：\n$$\n\\mathbb{E}[f_{\\mathrm{drop}}(x;\\theta,M)] = \\frac{1}{q} \\theta^{\\top} (\\mathbb{E}[M] \\odot x)\n$$\n掩码 $M$ 的分量是独立的伯努利随机变量，$M_i \\sim \\mathrm{Bernoulli}(q)$，因此对于所有 $i \\in \\{1, \\dots, d\\}$，$\\mathbb{E}[M_i] = q$。所以，期望掩码 $\\mathbb{E}[M]$ 是一个每个条目都为 $q$ 的向量。\n$$\n\\mathbb{E}[f_{\\mathrm{drop}}(x;\\theta,M)] = \\frac{1}{q} \\theta^{\\top} (q \\mathbf{1} \\odot x) = \\frac{1}{q} \\theta^{\\top}(qx) = \\theta^{\\top} x\n$$\n其中 $\\mathbf{1}$ 是一个全为1的向量。这恰好是确定性的无dropout输出 $f(x;\\theta)$。因此，目标量是：\n$$\n\\mu = \\mathbb{E}[y \\mid x] = f(x;\\theta)\n$$\n\n现在，我们引入控制变量法。为了估计 $\\mu = \\mathbb{E}[Y]$，我们可以使用一个与 $Y$ 相关且具有已知期望 $\\mathbb{E}[C]$ 的辅助随机变量 $C$。控制变量估计量基于随机变量 $Y_{\\lambda} = Y - \\lambda(C - \\mathbb{E}[C])$，其中 $\\lambda$ 是一个系数。对于任何 $\\lambda$，这个估计量都是无偏的，因为 $\\mathbb{E}[Y_{\\lambda}] = \\mathbb{E}[Y] - \\lambda(\\mathbb{E}[C] - \\mathbb{E}[C]) = \\mathbb{E}[Y] = \\mu$。\n\n$Y_{\\lambda}$ 的方差是：\n$$\n\\mathrm{Var}(Y_{\\lambda}) = \\mathrm{Var}(Y - \\lambda C) = \\mathrm{Var}(Y) + \\lambda^2 \\mathrm{Var}(C) - 2\\lambda \\mathrm{Cov}(Y, C)\n$$\n为了最小化关于 $\\lambda$ 的方差，我们对 $\\lambda$ 求导并令其为零：\n$$\n\\frac{d}{d\\lambda} \\mathrm{Var}(Y_{\\lambda}) = 2\\lambda \\mathrm{Var}(C) - 2 \\mathrm{Cov}(Y, C) = 0\n$$\n这得出了最优系数 $\\lambda^*$: \n$$\n\\lambda^* = \\frac{\\mathrm{Cov}(Y, C)}{\\mathrm{Var}(C)}\n$$\n\n我们必须提出一个合适的控制变量 $C$。问题建议使用 $f(x;\\theta)$。一个好的控制变量必须是一个随机变量，而 $f(x;\\theta)$ 相对于 $M$ 和 $\\varepsilon$ 的随机性是一个常数。然而，我们已经发现 $\\mathbb{E}[f_{\\mathrm{drop}}(x;\\theta,M)] = f(x;\\theta)$。这为控制变量提供了一个自然的选择。\n\n令 $Y = y = f_{\\mathrm{drop}}(x;\\theta,M) + \\varepsilon$。我们提出控制变量 $C = f_{\\mathrm{drop}}(x;\\theta,M)$。\n这个变量 $C$ 是 $Y$ 的一个分量，因此预期它与 $Y$ 强相关。它的期望 $\\mathbb{E}[C] = f(x;\\theta)$ 是已知的。这个选择满足了明确使用 $f(x;\\theta)$ 的要求。\n\n我们现在计算这个 $Y$ 和 $C$ 选择下的最优系数 $\\lambda^*$。\n分母是 $\\mathrm{Var}(C) = \\mathrm{Var}(f_{\\mathrm{drop}}(x;\\theta,M))$。\n分子是 $\\mathrm{Cov}(Y, C) = \\mathrm{Cov}(f_{\\mathrm{drop}}(x;\\theta,M) + \\varepsilon, f_{\\mathrm{drop}}(x;\\theta,M))$。\n利用协方差的双线性性质：\n$$\n\\mathrm{Cov}(Y, C) = \\mathrm{Cov}(f_{\\mathrm{drop}}(x;\\theta,M), f_{\\mathrm{drop}}(x;\\theta,M)) + \\mathrm{Cov}(\\varepsilon, f_{\\mathrm{drop}}(x;\\theta,M))\n$$\n这可以简化为：\n$$\n\\mathrm{Cov}(Y, C) = \\mathrm{Var}(f_{\\mathrm{drop}}(x;\\theta,M)) + \\mathrm{Cov}(\\varepsilon, f_{\\mathrm{drop}}(x;\\theta,M))\n$$\n根据问题陈述，偶然噪声 $\\varepsilon$ 与dropout掩码 $M$ 是独立的。随机变量 $f_{\\mathrm{drop}}(x;\\theta,M)$ 仅是 $M$ 的函数。因此，$\\varepsilon$ 和 $f_{\\mathrm{drop}}(x;\\theta,M)$ 是独立的随机变量。\n两个独立随机变量的协方差为零。因此，$\\mathrm{Cov}(\\varepsilon, f_{\\mathrm{drop}}(x;\\theta,M)) = 0$。\n分子变为：\n$$\n\\mathrm{Cov}(Y, C) = \\mathrm{Var}(f_{\\mathrm{drop}}(x;\\theta,M))\n$$\n现在我们可以计算最优系数 $\\lambda^*$: \n$$\n\\lambda^* = \\frac{\\mathrm{Cov}(Y, C)}{\\mathrm{Var}(C)} = \\frac{\\mathrm{Var}(f_{\\mathrm{drop}}(x;\\theta,M))}{\\mathrm{Var}(f_{\\mathrm{drop}}(x;\\theta,M))}\n$$\n假设在一个非退化的情况下，即 $\\mathrm{Var}(f_{\\mathrm{drop}}(x;\\theta,M)) > 0$（也就是说，并非所有的 $\\theta_i x_i$ 都为零且 $q \\in (0,1)$），表达式简化为：\n$$\n\\lambda^* = 1\n$$\n如果 $\\mathrm{Var}(f_{\\mathrm{drop}}(x;\\theta,M)) = 0$，那么 $C$ 是一个常数，控制变量项 $\\lambda(C-\\mathbb{E}[C])$ 总是为零。在这种情况下，任何 $\\lambda$ 都是‘最优’的，因为无法实现方差缩减。选择 $\\lambda^*=1$ 仍然有效。问题要求一个单一的实数，这意味着一个普遍适用的值。\n\n最优控制变量系数是 $1$。",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "不确定性量化的一个关键应用是识别分布外（OOD）样本，这对于构建安全可靠的机器学习系统至关重要。这个综合性练习将指导你设计一个完整的计算实验，以比较不同基于不确定性的 OOD 检测分数。你将实现一个合成数据生成过程，并使用严谨的统计工具（例如用于相关 ROC 曲线的 DeLong 检验）来得出关于这些方法相对性能的有意义的结论，这完整地模拟了一个计算研究项目的流程 。",
            "id": "3321128",
            "problem": "要求您设计、实现并分析一个随机模拟实验，以比较从多类别分类器中的蒙特卡洛 dropout 派生出的两种基于不确定性的分布外 (OOD) 检测分数，并使用 DeLong 方法推导受试者工作特征曲线下面积 (ROC AUC) 的标准误。该实验必须完全是合成的且可复现的，所有随机性由一个固定的种子控制。您的程序必须是独立完整的，并严格按照规定生成所要求的输出。\n\n您将在纯数学环境中工作，不参考任何外部数据集。考虑一个在蒙特卡洛 (MC) dropout 下的 $K$ 类分类器，该分类器被视为对网络权重的近似贝叶斯后验采样器。对于每个输入，重复的随机前向传播会生成类别概率向量，我们通过围绕一个潜在类别概率向量从狄利克雷分布中抽样来近似这些向量。使用以下组成部分：\n\n1. 用作基础的基本定义：\n   - 对于一个二元分类分数，受试者工作特征曲线下面积 (ROC AUC) 是指一个随机抽取的正例获得的分数严格大于一个随机抽取的负例分数的概率，平局情况贡献 1/2。这可以写成一个基于正例和负例分数之间两两比较的 U-统计量。\n   - 蒙特卡洛 dropout 通过随机子网络来近似后验预测推断，在这里它被抽象为对类别概率向量的重复抽样，这些抽样的平均值近似于预测均值。\n   - 一个具有概率 $p_{1},\\dots,p_{K}$ 的离散分布的香农熵（使用自然对数）是 $-\\sum_{c=1}^{K} p_{c} \\log p_{c}$。\n   - 对于一个预测类别概率向量 $p$，最大 softmax 概率 (MSP) 异常分数定义为 $1 - \\max_{c} p_{c}$。\n\n2. 数据生成过程：\n   - 对于每个分布内 (ID) 样本，从 $\\{1,\\dots,K\\}$ 中均匀随机选择一个主导类别索引 $c^{\\star}$。定义一个潜在类别概率向量 $q \\in \\mathbb{R}^{K}$，方法是赋值 $q_{c^{\\star}} = \\delta$ 以及对于所有 $c \\neq c^{\\star}$，赋值 $q_{c} = \\frac{1-\\delta}{K-1}$，其中 $\\delta \\in (0,1)$ 是一个固定的主导参数。\n   - 对于每个分布外 (OOD) 样本，将潜在类别概率向量定义为均匀分布：$q = \\left(\\frac{1}{K},\\dots,\\frac{1}{K}\\right)$。\n   - 对于每个具有潜在向量 $q$ 和浓度参数 $s > 0$ 的样本，通过抽取 $T$ 个独立样本 $p^{(t)} \\sim \\operatorname{Dirichlet}(s \\, q)$（其中 $t = 1,\\dots,T$）来近似 MC dropout 预测分布，并计算预测均值 $\\bar{p} = \\frac{1}{T} \\sum_{t=1}^{T} p^{(t)}$。\n\n3. 每个样本的 OOD 检测分数：\n   - 蒙特卡洛预测熵分数：$H(\\bar{p}) = -\\sum_{c=1}^{K} \\bar{p}_{c} \\log \\bar{p}_{c}$。\n   - 最大 softmax 概率异常分数：$M(\\bar{p}) = 1 - \\max_{c} \\bar{p}_{c}$。\n\n4. 标签和 ROC AUC：\n   - 将 OOD 样本视为正例（标签为 $1$），将 ID 样本视为负例（标签为 $0$）。对于任何实值分数 $s$，使用两两比较的定义来计算 ROC AUC。平局贡献值为 $\\frac{1}{2}$。\n\n5. 通过 DeLong 方法进行方差估计：\n   - 从 ROC AUC 的 U-统计量定义出发，从第一性原理推导并实现 DeLong 方差估计器（即，使用跨正例和负例的影响函数分解），以获得每个 AUC 的标准误。\n   - 此外，推导并实现两个在同一数据集上但使用不同分数计算的相关 AUC 估计器之间的协方差，并获得它们差值的标准误。\n\n6. 实现要求：\n   - 使用固定的随机种子以确保可复现性。\n   - 为了熵计算的数值稳定性，请安全地处理 $\\log 0$。\n   - 除了 DeLong 方法的 U-统计量理论所隐含的内容外，不要假设任何高斯近似。\n\n测试套件：\n实现您的程序以运行以下参数集。在每种情况下，使用上面描述的构造和相同的随机种子生成数据集并计算两种 OOD 检测分数，以确保结果是确定性的。\n\n- 案例 $1$（一般理想路径）：$(N_{\\mathrm{ID}}, N_{\\mathrm{OOD}}, K, T, s_{\\mathrm{ID}}, s_{\\mathrm{OOD}}, \\delta) = (200, 200, 5, 30, 50, 5, 0.85)$。\n- 案例 $2$（重叠边界）：$(200, 200, 5, 30, 20, 15, 0.85)$。\n- 案例 $3$（类别不平衡）：$(800, 200, 10, 20, 60, 8, 0.85)$。\n- 案例 $4$（小样本）：$(40, 40, 3, 10, 40, 12, 0.85)$。\n- 案例 $5$（近乎完美分离）：$(200, 200, 4, 15, 200, 1.5, 0.85)$。\n\n对于每种案例，您的程序必须计算：\n- $A_{\\mathrm{ent}}$：使用蒙特卡洛预测熵分数的 ROC AUC。\n- $\\mathrm{SE}_{\\mathrm{ent}}$：$A_{\\mathrm{ent}}$ 的 DeLong 标准误。\n- $A_{\\mathrm{msp}}$：使用最大 softmax 概率异常分数的 ROC AUC。\n- $\\mathrm{SE}_{\\mathrm{msp}}$：$A_{\\mathrm{msp}}$ 的 DeLong 标准误。\n- $\\Delta A = A_{\\mathrm{ent}} - A_{\\mathrm{msp}}$。\n- $\\mathrm{SE}_{\\Delta}$：差值 $\\Delta A$ 的 DeLong 标准误，使用同一数据上两个相关 AUC 之间的协方差计算。\n- $z = \\frac{\\Delta A}{\\mathrm{SE}_{\\Delta}}$，约定如果 $\\mathrm{SE}_{\\Delta} = 0$，则设 $z = 0$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。整体输出必须是一个列表的列表，每个测试案例对应一个内部列表，其中每个内部列表的格式为 $[A_{\\mathrm{ent}}, \\mathrm{SE}_{\\mathrm{ent}}, A_{\\mathrm{msp}}, \\mathrm{SE}_{\\mathrm{msp}}, \\Delta A, \\mathrm{SE}_{\\Delta}, z]$。所有值都必须打印为浮点数。例如，一个包含两个案例的示意性输出看起来像这样 $[[0.900000,0.020000,0.850000,0.025000,0.050000,0.010000,5.000000],[\\dots]]$。",
            "solution": "问题陈述已经过严格验证，并被认为是有效的。它在随机模拟和机器学习领域构成了一个适定的、有科学依据的、客观的模拟任务。该问题提供了一套完整的定义、参数和计算要求，以推导出一个唯一且可验证的解决方案。所有组成部分都基于已建立的原则，包括蒙特卡洛 dropout 建模、标准不确定性度量以及用于 U-统计量方差估计的非参数 DeLong 方法。\n\n解决方案的步骤是：首先详细阐述模拟的数学框架，然后从第一性原理推导必要的统计估计量，最后描述完整实验的实现。\n\n**1. 数据生成过程与 OOD 分数**\n\n该模拟构建了一个包含分布内 (ID) 和分布外 (OOD) 样本的合成数据集。对于每个样本，我们通过模拟蒙特卡洛 dropout 过程来生成一个预测均值概率向量 $\\bar{p}$。\n\n设 $N_{\\mathrm{ID}}$ 和 $N_{\\mathrm{OOD}}$ 分别是 ID 和 OOD 样本的数量。设 $K$ 是类别数。\n\n对于每个 ID 样本 $i \\in \\{1, \\dots, N_{\\mathrm{ID}}\\}$：\n1. 从 $\\{1, \\dots, K\\}$ 中均匀选择一个主导类别 $c^{\\star}$。\n2. 定义一个潜在类别概率向量 $q^{(i)} \\in \\mathbb{R}^K$，其中 $q^{(i)}_{c^{\\star}} = \\delta$，对于 $c \\neq c^{\\star}$ 则为 $q^{(i)}_{c} = \\frac{1-\\delta}{K-1}$，$\\delta \\in (0,1)$ 是一个主导参数。\n3. 狄利克雷浓度参数向量为 $\\alpha^{(i)} = s_{\\mathrm{ID}} q^{(i)}$，其中 $s_{\\mathrm{ID}} > 0$ 是浓度参数。\n4. 从狄利克雷分布中独立抽取 $T$ 个概率向量 $\\{p^{(i,t)}\\}_{t=1}^T$：$p^{(i,t)} \\sim \\operatorname{Dirichlet}(\\alpha^{(i)})$。\n5. 计算预测均值为 $\\bar{p}^{(i)} = \\frac{1}{T} \\sum_{t=1}^{T} p^{(i,t)}$。\n\n对于每个 OOD 样本 $j \\in \\{1, \\dots, N_{\\mathrm{OOD}}\\}$：\n1. 潜在类别概率向量是均匀的：$q^{(j)} = (\\frac{1}{K}, \\dots, \\frac{1}{K})$。\n2. 狄利克雷浓度参数向量为 $\\alpha^{(j)} = s_{\\mathrm{OOD}} q^{(j)}$，其中 $s_{\\mathrm{OOD}} > 0$ 是浓度参数。\n3. 独立抽取 $T$ 个概率向量 $\\{p^{(j,t)}\\}_{t=1}^T$：$p^{(j,t)} \\sim \\operatorname{Dirichlet}(\\alpha^{(j)})$。\n4. 计算预测均值为 $\\bar{p}^{(j)} = \\frac{1}{T} \\sum_{t=1}^{T} p^{(j,t)}$。\n\n从每个预测均值向量 $\\bar{p}$，计算两个 OOD 检测分数：\n1.  **蒙特卡洛预测熵：** $H(\\bar{p}) = -\\sum_{c=1}^{K} \\bar{p}_{c} \\log \\bar{p}_{c}$。为了数值稳定性，在对数的参数中加入一个小的常数 $\\epsilon > 0$，即 $\\log(\\bar{p}_c + \\epsilon)$，因为 $\\lim_{x\\to0^+} x \\log x = 0$。\n2.  **最大 Softmax 概率 (MSP) 异常分数：** $M(\\bar{p}) = 1 - \\max_{c} \\bar{p}_{c}$。\n\n为了进行 ROC AUC 分析，OOD 样本被视为正类（标签为 $1$），ID 样本被视为负类（标签为 $0$）。通常，更高的分数表示属于 OOD 的可能性更高。\n\n**2. ROC AUC 和 DeLong 方差估计方法**\n\n受试者工作特征曲线下面积 (ROC AUC) 是评估二元分类器分数性能的标准度量。设 $\\{X_i\\}_{i=1}^{m}$ 是 $m=N_{\\mathrm{OOD}}$ 个正样本的分数，$\\{Y_j\\}_{j=1}^{n}$ 是 $n=N_{\\mathrm{ID}}$ 个负样本的分数。ROC AUC 是一个随机选择的正样本分数高于一个随机选择的负样本分数的概率。AUC 的一个无偏估计量是 Mann-Whitney U-统计量：\n$$ \\hat{A} = \\frac{1}{mn} \\sum_{i=1}^{m} \\sum_{j=1}^{n} \\psi(X_i, Y_j) $$\n其中核函数 $\\psi$ 定义为：\n$$ \\psi(x, y) = \\begin{cases} 1 & \\text{if } x > y \\\\ 1/2 & \\text{if } x = y \\\\ 0 & \\text{if } x < y \\end{cases} $$\n\nDeLong 方法为 $\\hat{A}$ 的方差以及在同一数据上估计的两个相关 AUC 之间的协方差提供了一个非参数估计。其推导基于 U-统计量理论，特别是 Hoeffding 的投影法。U-统计量 $\\hat{A}$ 被投影到独立同分布随机变量的和上，这些和的方差更容易分析。\n\n设 $A = E[\\hat{A}]$。$\\hat{A}-A$ 的投影由下式给出：\n$$ (\\hat{A}-A)_{\\text{proj}} = \\frac{1}{m} \\sum_{i=1}^{m} (E[\\psi(X_i, Y)|X_i] - A) + \\frac{1}{n} \\sum_{j=1}^{n} (E[\\psi(X, Y_j)|Y_j] - A) $$\n$\\hat{A}$ 的方差渐近地等于这个投影的方差。条件期望是未知的，必须从数据中估计。我们将这些条件期望的经验估计定义为“影响”分量：\n- 对于每个正样本分数 $X_i$：$v_{10}(X_i) = \\frac{1}{n} \\sum_{j=1}^{n} \\psi(X_i, Y_j)$。\n- 对于每个负样本分数 $Y_j$：$v_{01}(Y_j) = \\frac{1}{m} \\sum_{i=1}^{m} \\psi(X_i, Y_j)$。\n\n$E[\\psi(X, Y)|X]$ 的方差通过 $v_{10}$ 分量的样本方差来估计，而 $E[\\psi(X, Y)|Y]$ 的方差通过 $v_{01}$ 分量的样本方差来估计。请注意，$v_{10}(X)$ 和 $v_{01}(Y)$ 的总体均值都是 $A$。因此，我们估计结构分量的方差如下：\n$$ S_{10} = \\frac{1}{m-1} \\sum_{i=1}^{m} (v_{10}(X_i) - \\hat{A})^2 $$\n$$ S_{01} = \\frac{1}{n-1} \\sum_{j=1}^{n} (v_{01}(Y_j) - \\hat{A})^2 $$\n那么 $\\hat{A}$ 的 DeLong 方差估计为：\n$$ \\widehat{\\mathrm{Var}}(\\hat{A}) = \\frac{S_{10}}{m} + \\frac{S_{01}}{n} $$\n标准误为 $\\mathrm{SE}(\\hat{A}) = \\sqrt{\\widehat{\\mathrm{Var}}(\\hat{A})}$。\n\n这个逻辑可以扩展到从同一批样本的两种不同评分方法计算出的两个 AUC 估计器 $\\hat{A}_1$ 和 $\\hat{A}_2$ 之间的协方差。设它们各自的影响分量为 $(v_{10}^{(1)}, v_{01}^{(1)})$ 和 $(v_{10}^{(2)}, v_{01}^{(2)})$。影响分量的样本协方差为：\n$$ S_{10}^{(1,2)} = \\frac{1}{m-1} \\sum_{i=1}^{m} (v_{10}^{(1)}(X_i^{(1)}) - \\hat{A}_1)(v_{10}^{(2)}(X_i^{(2)}) - \\hat{A}_2) $$\n$$ S_{01}^{(1,2)} = \\frac{1}{n-1} \\sum_{j=1}^{n} (v_{01}^{(1)}(Y_j^{(1)}) - \\hat{A}_1)(v_{01}^{(2)}(Y_j^{(2)}) - \\hat{A}_2) $$\n两个 AUC 之间的估计协方差为：\n$$ \\widehat{\\mathrm{Cov}}(\\hat{A}_1, \\hat{A}_2) = \\frac{S_{10}^{(1,2)}}{m} + \\frac{S_{01}^{(1,2)}}{n} $$\n\n**3. 统计比较**\n\n对于每个测试案例，我们为所有生成的样本计算两种 OOD 分数（熵和 MSP）。设 $\\hat{A}_{\\mathrm{ent}}$ 和 $\\hat{A}_{\\mathrm{msp}}$ 分别为熵分数和 MSP 分数的 AUC。我们使用上面推导的方差公式计算它们的标准误 $\\mathrm{SE}_{\\mathrm{ent}}$ 和 $\\mathrm{SE}_{\\mathrm{msp}}$。\n\n为了比较这两个分数，我们分析它们的差值 $\\Delta A = \\hat{A}_{\\mathrm{ent}} - \\hat{A}_{\\mathrm{msp}}$。这个差值的方差是：\n$$ \\mathrm{Var}(\\Delta A) = \\mathrm{Var}(\\hat{A}_{\\mathrm{ent}} - \\hat{A}_{\\mathrm{msp}}) = \\mathrm{Var}(\\hat{A}_{\\mathrm{ent}}) + \\mathrm{Var}(\\hat{A}_{\\mathrm{msp}}) - 2\\mathrm{Cov}(\\hat{A}_{\\mathrm{ent}}, \\hat{A}_{\\mathrm{msp}}) $$\n标准误 $\\mathrm{SE}_{\\Delta}$ 是该方差的平方根。然后我们计算一个 $z$-分数来检验两个 AUC 相等的原假设：\n$$ z = \\frac{\\Delta A}{\\mathrm{SE}_{\\Delta}} $$\n约定如果 $\\mathrm{SE}_{\\Delta}=0$，则 $z=0$。\n\n**4. 算法实现**\n\n该模拟使用 Python 的 `numpy` 库实现。固定的随机种子确保了可复现性。对于指定的每个测试案例：\n1. 执行数据生成过程，为 ID 和 OOD 样本生成预测均值向量 $\\bar{p}$ 的数组。这涉及到从 `numpy.random.dirichlet` 进行抽样。\n2. 为每个 $\\bar{p}$ 计算熵和 MSP 异常分数。\n3. 使用一个实现 DeLong 方法的函数。它接收正例 (OOD) 和负例 (ID) 的分数。为了提高效率，两两比较矩阵 $\\psi(X_i, Y_j)$ 是通过向量化计算的。从这个矩阵中，通过沿适当的轴求平均值来计算影响分量 $v_{10}$ 和 $v_{01}$。\n4. 使用这些分量，根据推导出的公式计算 AUC、方差和协方差。为此目的，使用了 `numpy.var`（设置 `ddof=1`）和 `numpy.cov`。\n5. 计算并存储最终的量（$A_{\\mathrm{ent}}$, $\\mathrm{SE}_{\\mathrm{ent}}$, $A_{\\mathrm{msp}}$, $\\mathrm{SE}_{\\mathrm{msp}}$, $\\Delta A$, $\\mathrm{SE}_{\\Delta}$ 和 $z$）。\n6. 汇总所有测试案例的结果，并按指定格式打印。",
            "answer": "```python\nimport numpy as np\n\ndef delong_analysis(scores1_pos, scores1_neg, scores2_pos, scores2_neg):\n    \"\"\"\n    Computes AUCs, standard errors, and their covariance using DeLong's method.\n\n    Args:\n        scores1_pos (np.array): Scores for the positive class, method 1.\n        scores1_neg (np.array): Scores for the negative class, method 1.\n        scores2_pos (np.array): Scores for the positive class, method 2.\n        scores2_neg (np.array): Scores for the negative class, method 2.\n    \n    Returns:\n        tuple: (auc1, se1, auc2, se2, cov)\n    \"\"\"\n    m = len(scores1_pos)  # Number of positive samples\n    n = len(scores1_neg)  # Number of negative samples\n\n    if m == 0 or n == 0:\n        return (np.nan,) * 5\n\n    # Vectorized computation of psi matrices\n    psi1_matrix = (scores1_pos[:, np.newaxis] > scores1_neg[np.newaxis, :]) + \\\n                  0.5 * (scores1_pos[:, np.newaxis] == scores1_neg[np.newaxis, :])\n    psi2_matrix = (scores2_pos[:, np.newaxis] > scores2_neg[np.newaxis, :]) + \\\n                  0.5 * (scores2_pos[:, np.newaxis] == scores2_neg[np.newaxis, :])\n\n    # Influence components (v) for both methods\n    v10_1 = np.mean(psi1_matrix, axis=1)\n    v01_1 = np.mean(psi1_matrix, axis=0)\n    v10_2 = np.mean(psi2_matrix, axis=1)\n    v01_2 = np.mean(psi2_matrix, axis=0)\n\n    # AUCs\n    auc1 = np.mean(v10_1)\n    auc2 = np.mean(v10_2)\n\n    # Sample variances of influence components\n    # ddof=1 for unbiased sample variance\n    s10_1 = np.var(v10_1, ddof=1) if m > 1 else 0\n    s01_1 = np.var(v01_1, ddof=1) if n > 1 else 0\n    s10_2 = np.var(v10_2, ddof=1) if m > 1 else 0\n    s01_2 = np.var(v01_2, ddof=1) if n > 1 else 0\n\n    # Variances of AUCs\n    var1 = (s10_1 / m) + (s01_1 / n)\n    var2 = (s10_2 / m) + (s01_2 / n)\n    se1 = np.sqrt(var1) if var1 >= 0 else 0\n    se2 = np.sqrt(var2) if var2 >= 0 else 0\n\n    # Sample covariances of influence components\n    if m > 1:\n        s10_cov = np.cov(v10_1, v10_2, ddof=1)[0, 1]\n    else:\n        s10_cov = 0\n    if n > 1:\n        s01_cov = np.cov(v01_1, v01_2, ddof=1)[0, 1]\n    else:\n        s01_cov = 0\n        \n    # Covariance of AUCs\n    cov = (s10_cov / m) + (s01_cov / n)\n\n    return auc1, se1, auc2, se2, cov\n\ndef run_simulation(N_ID, N_OOD, K, T, s_ID, s_OOD, delta, rng):\n    \"\"\"\n    Runs one full simulation for a given set of parameters.\n    \"\"\"\n    # Generate In-Distribution (ID) data\n    p_bar_ID = np.zeros((N_ID, K))\n    for i in range(N_ID):\n        c_star = rng.integers(0, K)\n        q = np.full(K, (1 - delta) / (K - 1))\n        q[c_star] = delta\n        alpha = s_ID * q\n        samples = rng.dirichlet(alpha, size=T)\n        p_bar_ID[i] = np.mean(samples, axis=0)\n\n    # Generate Out-of-Distribution (OOD) data\n    p_bar_OOD = np.zeros((N_OOD, K))\n    q_ood = np.ones(K) / K\n    alpha_ood = s_OOD * q_ood\n    for i in range(N_OOD):\n        samples = rng.dirichlet(alpha_ood, size=T)\n        p_bar_OOD[i] = np.mean(samples, axis=0)\n        \n    # Calculate OOD detection scores\n    # Add a small epsilon for log stability\n    epsilon = 1e-15\n    scores_ent_ID = -np.sum(p_bar_ID * np.log(p_bar_ID + epsilon), axis=1)\n    scores_ent_OOD = -np.sum(p_bar_OOD * np.log(p_bar_OOD + epsilon), axis=1)\n    \n    scores_msp_ID = 1 - np.max(p_bar_ID, axis=1)\n    scores_msp_OOD = 1 - np.max(p_bar_OOD, axis=1)\n    \n    # Perform DeLong analysis\n    A_ent, SE_ent, A_msp, SE_msp, cov_ent_msp = delong_analysis(\n        scores_ent_OOD, scores_ent_ID, scores_msp_OOD, scores_msp_ID\n    )\n\n    # Compute difference and z-score\n    delta_A = A_ent - A_msp\n    var_ent = SE_ent**2\n    var_msp = SE_msp**2\n    \n    var_delta = var_ent + var_msp - 2 * cov_ent_msp\n    SE_delta = np.sqrt(var_delta) if var_delta > 0 else 0.0\n    \n    z = delta_A / SE_delta if SE_delta > 0 else 0.0\n    \n    return [A_ent, SE_ent, A_msp, SE_msp, delta_A, SE_delta, z]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (200, 200, 5, 30, 50, 5, 0.85),\n        (200, 200, 5, 30, 20, 15, 0.85),\n        (800, 200, 10, 20, 60, 8, 0.85),\n        (40, 40, 3, 10, 40, 12, 0.85),\n        (200, 200, 4, 15, 200, 1.5, 0.85),\n    ]\n\n    results = []\n    # Use a fixed seed for reproducibility across all cases\n    rng = np.random.default_rng(0)\n\n    for case in test_cases:\n        N_ID, N_OOD, K, T, s_ID, s_OOD, delta = case\n        result = run_simulation(N_ID, N_OOD, K, T, s_ID, s_OOD, delta, rng)\n        results.append(result)\n\n    # Format the final output string\n    outer_list = []\n    for res_list in results:\n        inner_str = f\"[{','.join(f'{x:.6f}' for x in res_list)}]\"\n        outer_list.append(inner_str)\n    \n    print(f\"[{','.join(outer_list)}]\")\n\nsolve()\n```\n[[0.998400,0.001602,0.998425,0.001584,-0.000025,0.000109,-0.229239],[0.742362,0.026412,0.738875,0.026601,0.003487,0.001716,2.032128],[0.996738,0.001460,0.996719,0.001471,0.000019,0.000067,0.278937],[0.865625,0.057375,0.865000,0.057531,0.000625,0.001157,0.539992],[1.000000,0.000000,1.000000,0.000000,0.000000,0.000000,0.000000]]"
        }
    ]
}