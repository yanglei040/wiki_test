{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp Bayesian optimization, there is no substitute for hands-on implementation. This first practice challenges you to build a core component of a modern BO system: a Thompson sampling policy. You will implement the algorithm for a continuous domain, which involves computing the Gaussian process posterior, drawing a function sample from this posterior, and then selecting the next point to evaluate by optimizing this sample. This exercise () provides a concrete understanding of how the GP belief model is used to guide the search for an optimum in an elegant and probabilistically principled way.",
            "id": "3291534",
            "problem": "Implement a single-step Thompson sampling policy for continuous-domain Bayesian optimization using a Gaussian process prior with a squared exponential covariance. Your program must compute the chosen next evaluation location for each of several test cases and output the results as specified.\n\nStart from the following fundamental base:\n- A Gaussian process (GP) prior over an unknown function $f$ on a compact interval with zero mean and a positive definite covariance kernel is defined by the property that any finite collection of evaluations has a joint multivariate normal distribution.\n- For a squared exponential covariance kernel with variance parameter $\\alpha^2$ and length-scale $\\ell$, the kernel is given by\n$$\nk(x,x') \\;=\\; \\alpha^2 \\exp\\!\\Big(-\\,\\frac{(x-x')^2}{2\\,\\ell^2}\\Big).\n$$\n- Observations are corrupted by independent, identically distributed Gaussian noise of known variance $\\tau^2$, so that for observed inputs $\\{x_i\\}_{i=1}^n$ and outputs $\\{y_i\\}_{i=1}^n$ we have $y_i \\,=\\, f(x_i) + \\varepsilon_i$ with $\\varepsilon_i \\sim \\mathcal{N}(0,\\tau^2)$ and independent across $i$.\n\nDefinitions and requirements to implement:\n- Consider a closed interval $[a,b] \\subset \\mathbb{R}$ and a discretization grid of $M$ equispaced points $X_\\star = \\{x_\\star^{(j)}\\}_{j=1}^M$ including the endpoints $a$ and $b$.\n- Given observed data $(X,y)$, where $X = (x_1,\\dots,x_n)$ and $y=(y_1,\\dots,y_n)$, the Gaussian process posterior at the grid points $X_\\star$ is a multivariate normal distribution. You must use the Gaussian conditioning identity applied to the joint prior over $(f(X), f(X_\\star))$ with additive Gaussian noise on $y$ to derive the posterior mean vector $m_\\star$ and posterior covariance matrix $\\Sigma_\\star$ at $X_\\star$.\n- A single-step Thompson sampling policy on the grid $X_\\star$ draws a sample $g_\\star \\sim \\mathcal{N}(m_\\star,\\Sigma_\\star)$ and selects the next input to evaluate as the maximizer over the grid:\n$$\nx_{\\text{TS}} \\;=\\; \\arg\\max_{x \\in X_\\star} g_\\star(x).\n$$\n- In the event of ties within numerical tolerance, choose the smallest index (i.e., the leftmost grid point) among the maximizers.\n\nNumerical requirements:\n- Use a Cholesky factorization for linear solves and sampling from the multivariate normal distribution.\n- Add a small positive diagonal \"jitter\" $\\epsilon$ to any covariance matrix you factorize to ensure numerical positive definiteness. Use $\\epsilon = 10^{-9}$.\n- All arithmetic is real-valued and without physical units.\n- For each test case, use a pseudorandom number generator seeded with the specified seed before drawing the posterior sample. The seed must be applied per test case independently, and only to the sampling step.\n\nDiscretization:\n- For all test cases, use the same grid size $M = 501$ and $[a,b]=[0,1]$. Thus $x_\\star^{(j)} = a + (j-1)\\,\\frac{b-a}{M-1}$ for $j=1,\\dots,M$.\n\nTest suite:\n- Case $1$ (prior only):\n  - Inputs: no observations ($n=0$).\n  - Hyperparameters: $\\alpha = 1.2$, $\\ell = 0.18$, $\\tau = 0.05$ (unused when $n=0$).\n  - Seed: $1234$.\n- Case $2$ (single noisy observation):\n  - Inputs: $X=(0.3)$, $y=(0.4)$, so $n=1$.\n  - Hyperparameters: $\\alpha = 0.9$, $\\ell = 0.2$, $\\tau = 0.01$.\n  - Seed: $2025$.\n- Case $3$ (moderate data, moderate noise):\n  - Inputs: $X=(0.15,\\,0.5,\\,0.85)$, $y=(1.0,\\,-0.2,\\,0.7)$, so $n=3$.\n  - Hyperparameters: $\\alpha = 1.0$, $\\ell = 0.25$, $\\tau = 0.05$.\n  - Seed: $7$.\n- Case $4$ (nearly collinear design, very low noise):\n  - Inputs: $X=(0.499,\\,0.5,\\,0.501,\\,0.9)$, $y=(0.0,\\,0.0,\\,0.0,\\,0.2)$, so $n=4$.\n  - Hyperparameters: $\\alpha = 0.8$, $\\ell = 0.05$, $\\tau = 10^{-4}$.\n  - Seed: $42$.\n\nYour program must, for each case, compute $x_{\\text{TS}}$ on the grid $X_\\star$ and output the four values as a single line containing a Python-style list of four real numbers in the order of the cases, e.g., $[r_1,r_2,r_3,r_4]$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with no spaces, in the exact order of the cases: $[x_{\\text{TS,1}},x_{\\text{TS,2}},x_{\\text{TS,3}},x_{\\text{TS,4}}]$.",
            "solution": "We begin with the Gaussian process prior and the Gaussian likelihood model. Let $f \\sim \\mathcal{GP}(0,k)$ with $k(x,x') = \\alpha^2 \\exp\\!\\big(-\\frac{(x-x')^2}{2\\ell^2}\\big)$. Observations satisfy $y_i = f(x_i) + \\varepsilon_i$ with $\\varepsilon_i \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\tau^2)$. For a finite set of inputs, the joint distribution is multivariate normal, which we will use to derive the posterior predictive distribution.\n\nDefine the observed inputs $X = (x_1,\\dots,x_n)$ and grid inputs $X_\\star = (x_\\star^{(1)},\\dots,x_\\star^{(M)})$. Construct the following covariance matrices and vectors:\n- The $n \\times n$ Gram matrix $K_{XX}$ with entries $[K_{XX}]_{ij} = k(x_i,x_j)$.\n- The $M \\times n$ cross-covariance matrix $K_{\\star X}$ with entries $[K_{\\star X}]_{j i} = k(x_\\star^{(j)}, x_i)$.\n- The $M \\times M$ grid Gram matrix $K_{\\star \\star}$ with entries $[K_{\\star \\star}]_{j j'} = k(x_\\star^{(j)}, x_\\star^{(j')})$.\n\nLet $\\sigma^2_n = \\tau^2$ denote the noise variance. The joint prior over $(f(X), f(X_\\star))$ is Gaussian with zero mean and covariance\n$$\n\\begin{bmatrix}\nK_{XX} & K_{X \\star} \\\\\nK_{\\star X} & K_{\\star \\star}\n\\end{bmatrix}.\n$$\nWith Gaussian observation noise, the likelihood implies that $y \\mid f(X) \\sim \\mathcal{N}(f(X), \\sigma_n^2 I_n)$. Integrating out $f(X)$ yields the marginal over $y$ as $y \\sim \\mathcal{N}(0, K_{XX} + \\sigma_n^2 I_n)$. The Gaussian conditioning identity for multivariate normal distributions then provides the posterior predictive distribution at the grid points:\n$$\nf_\\star \\mid X, y, X_\\star \\sim \\mathcal{N}\\big(m_\\star, \\Sigma_\\star \\big),\n$$\nwhere\n$$\nm_\\star \\;=\\; K_{\\star X}\\,(K_{XX} + \\sigma_n^2 I_n)^{-1} y,\n$$\nand\n$$\n\\Sigma_\\star \\;=\\; K_{\\star \\star} \\;-\\; K_{\\star X}\\,(K_{XX} + \\sigma_n^2 I_n)^{-1} K_{X \\star}.\n$$\n\nThese formulas follow directly from the standard result for conditioning a joint Gaussian vector. Specifically, if \n$$\n\\begin{bmatrix} u \\\\ v \\end{bmatrix} \\sim \\mathcal{N}\\!\\left( \\begin{bmatrix} \\mu_u \\\\ \\mu_v \\end{bmatrix}, \\begin{bmatrix} \\Sigma_{uu} & \\Sigma_{uv} \\\\ \\Sigma_{vu} & \\Sigma_{vv} \\end{bmatrix} \\right),\n$$\nthen\n$$\nu \\mid v \\sim \\mathcal{N}\\!\\big(\\mu_u + \\Sigma_{uv}\\Sigma_{vv}^{-1}(v - \\mu_v),\\; \\Sigma_{uu} - \\Sigma_{uv}\\Sigma_{vv}^{-1}\\Sigma_{vu}\\big).\n$$\nIdentifying $u = f_\\star$, $v = y$, $\\mu_u = 0$, $\\mu_v=0$, $\\Sigma_{uu} = K_{\\star \\star}$, $\\Sigma_{uv} = K_{\\star X}$, and $\\Sigma_{vv} = K_{XX} + \\sigma_n^2 I_n$ yields the stated posterior.\n\nThompson sampling requires drawing a function sample from the posterior, which, on the grid $X_\\star$, is a sample $g_\\star \\sim \\mathcal{N}(m_\\star, \\Sigma_\\star)$. To compute this efficiently and stably:\n- Use a Cholesky factorization of the positive definite matrix $K_{XX} + \\sigma_n^2 I_n + \\epsilon I_n$ to avoid explicit matrix inversion. Define $L = \\operatorname{chol}(K_{XX} + \\sigma_n^2 I_n + \\epsilon I_n)$ with $\\epsilon = 10^{-9}$. Solve $(K_{XX} + \\sigma_n^2 I_n)^{-1} y$ by solving two triangular systems: first $L z = y$ for $z$, then $L^\\top \\alpha = z$ for $\\alpha$, giving $\\alpha = (K_{XX} + \\sigma_n^2 I_n)^{-1} y$. Similarly, compute $V = L^{-1} K_{X \\star}$ by solving $L W = K_{X \\star}$ for $W$, so that $K_{\\star X} (K_{XX} + \\sigma_n^2 I_n)^{-1} K_{X \\star} = (K_{\\star X} L^{-T})(L^{-1} K_{X \\star}) = V^\\top V$.\n- Therefore, compute the posterior mean as $m_\\star = K_{\\star X}\\,\\alpha$ and the posterior covariance as $\\Sigma_\\star = K_{\\star \\star} - V^\\top V$. For numerical stability in sampling, add $\\epsilon I_M$ to $\\Sigma_\\star$ before factorization if needed.\n- To sample, compute a Cholesky factor $L_\\star = \\operatorname{chol}(\\Sigma_\\star + \\epsilon I_M)$ and set $g_\\star = m_\\star + L_\\star z$, where $z \\sim \\mathcal{N}(0, I_M)$. Seed the pseudorandom number generator as specified for each test case immediately before drawing $z$.\n\nWhen $n=0$, there are no observations. In that case, $m_\\star = 0$ and $\\Sigma_\\star = K_{\\star \\star}$, and sampling reduces to drawing from the prior on the grid.\n\nFinally, compute the Thompson sampling decision as $x_{\\text{TS}} = \\arg\\max_{x \\in X_\\star} g_\\star(x)$, breaking ties by selecting the smallest index. Since $X_\\star$ is equispaced on $[0,1]$ with $M=501$, we have $x_\\star^{(j)} = \\frac{j-1}{500}$ for $j=1,\\dots,501$.\n\nWe now outline the algorithm for each test case:\n- Construct $X_\\star$ with $M=501$ on $[0,1]$.\n- If $n>0$, build $K_{XX}$, $K_{\\star X}$, and $K_{\\star \\star}$. Add $\\sigma_n^2 I_n$ and jitter $\\epsilon I_n$ to $K_{XX}$ and factor with Cholesky. Compute $m_\\star$ and $\\Sigma_\\star$ via triangular solves and the Schur complement formula. If needed, add jitter to $\\Sigma_\\star$.\n- If $n=0$, set $m_\\star = 0$ and $\\Sigma_\\star = K_{\\star \\star}$ (with jitter).\n- Seed the pseudorandom generator and draw $g_\\star \\sim \\mathcal{N}(m_\\star,\\Sigma_\\star)$ via a Cholesky factor of $\\Sigma_\\star + \\epsilon I_M$.\n- Return the grid point maximizing $g_\\star$.\n\nThis procedure is grounded in the fundamental properties of Gaussian processes and multivariate normal conditioning, ensuring a correct and numerically stable implementation of one-step Thompson sampling over a continuous domain discretized to a fine grid.\n\nThe program will execute these steps for the four specified cases and print a single line with the four selected grid locations in the required format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef se_kernel(x, xprime, alpha, ell):\n    # Squared Exponential (RBF) kernel for 1D arrays x, xprime\n    # Returns Gram matrix of shape (len(x), len(xprime))\n    x = np.atleast_2d(x).T  # (n,1)\n    xprime = np.atleast_2d(xprime).T  # (m,1)\n    d2 = (x - xprime.T) ** 2  # (n,m)\n    return (alpha ** 2) * np.exp(-0.5 * d2 / (ell ** 2))\n\ndef cholesky_psd(A, jitter=1e-9, max_tries=5):\n    # Attempt a Cholesky factorization, increasing jitter if needed\n    jitter_scale = 1.0\n    for _ in range(max_tries):\n        try:\n            L = np.linalg.cholesky(A + (jitter * jitter_scale) * np.eye(A.shape[0]))\n            return L\n        except np.linalg.LinAlgError:\n            jitter_scale *= 10.0\n    # Final attempt may still fail; raise the error\n    L = np.linalg.cholesky(A + (jitter * jitter_scale) * np.eye(A.shape[0]))\n    return L\n\ndef gp_posterior_params(X_obs, y_obs, X_star, alpha, ell, tau, jitter=1e-9):\n    # Compute posterior mean m_star and covariance Sigma_star at X_star\n    n = len(X_obs)\n    M = len(X_star)\n    K_ss = se_kernel(X_star, X_star, alpha, ell)\n    if n == 0:\n        m_star = np.zeros(M)\n        # Add jitter for numerical stability\n        Sigma_star = K_ss.copy()\n        # Ensure symmetry\n        Sigma_star = (Sigma_star + Sigma_star.T) * 0.5\n        return m_star, Sigma_star\n    # Build K_xx and cross-covariances\n    K_xx = se_kernel(X_obs, X_obs, alpha, ell)\n    # Add noise variance and jitter to K_xx\n    K_xx_noisy = K_xx + (tau**2) * np.eye(n) + jitter * np.eye(n)\n    L = cholesky_psd(K_xx_noisy, jitter=jitter)\n    # Solve for alpha_vec = (K_xx + tau^2 I)^{-1} y\n    # First solve L z = y, then L^T alpha_vec = z\n    z = np.linalg.solve(L, y_obs)\n    alpha_vec = np.linalg.solve(L.T, z)\n    K_sx = se_kernel(X_star, X_obs, alpha, ell)  # (M,n)\n    # Posterior mean\n    m_star = K_sx @ alpha_vec  # (M,)\n    # Compute V = L^{-1} K_xs where K_xs = K(X_obs, X_star)\n    K_xs = K_sx.T  # (n,M)\n    V = np.linalg.solve(L, K_xs)  # (n,M)\n    # Posterior covariance: K_ss - V^T V\n    Sigma_star = K_ss - V.T @ V\n    # Symmetrize to remove numerical asymmetry\n    Sigma_star = (Sigma_star + Sigma_star.T) * 0.5\n    return m_star, Sigma_star\n\ndef thompson_sample_argmax(X_star, m_star, Sigma_star, seed, jitter=1e-9):\n    # Draw one sample from N(m_star, Sigma_star) using Cholesky and return argmax location\n    # Add jitter to ensure PSD\n    Ls = cholesky_psd(Sigma_star, jitter=jitter)\n    rng = np.random.RandomState(seed)\n    z = rng.randn(len(X_star))\n    g_star = m_star + Ls @ z\n    # Argmax with tie-break to smallest index\n    idx = int(np.argmax(g_star))\n    return X_star[idx]\n\ndef solve():\n    # Define grid [0,1] with M=501\n    M = 501\n    a, b = 0.0, 1.0\n    X_star = np.linspace(a, b, M)\n\n    # Define the test cases from the problem statement.\n    # Each case: dict with X_obs, y_obs, alpha, ell, tau, seed\n    test_cases = [\n        # Case 1: prior only\n        {\n            \"X_obs\": np.array([]),\n            \"y_obs\": np.array([]),\n            \"alpha\": 1.2,\n            \"ell\": 0.18,\n            \"tau\": 0.05,  # unused\n            \"seed\": 1234,\n        },\n        # Case 2: single observation\n        {\n            \"X_obs\": np.array([0.3]),\n            \"y_obs\": np.array([0.4]),\n            \"alpha\": 0.9,\n            \"ell\": 0.2,\n            \"tau\": 0.01,\n            \"seed\": 2025,\n        },\n        # Case 3: three observations\n        {\n            \"X_obs\": np.array([0.15, 0.5, 0.85]),\n            \"y_obs\": np.array([1.0, -0.2, 0.7]),\n            \"alpha\": 1.0,\n            \"ell\": 0.25,\n            \"tau\": 0.05,\n            \"seed\": 7,\n        },\n        # Case 4: nearly collinear design, very low noise\n        {\n            \"X_obs\": np.array([0.499, 0.5, 0.501, 0.9]),\n            \"y_obs\": np.array([0.0, 0.0, 0.0, 0.2]),\n            \"alpha\": 0.8,\n            \"ell\": 0.05,\n            \"tau\": 1e-4,\n            \"seed\": 42,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        X_obs = case[\"X_obs\"]\n        y_obs = case[\"y_obs\"]\n        alpha = case[\"alpha\"]\n        ell = case[\"ell\"]\n        tau = case[\"tau\"]\n        seed = case[\"seed\"]\n\n        m_star, Sigma_star = gp_posterior_params(X_obs, y_obs, X_star, alpha, ell, tau, jitter=1e-9)\n        x_ts = thompson_sample_argmax(X_star, m_star, Sigma_star, seed=seed, jitter=1e-9)\n        # Ensure Python float printing consistency\n        results.append(x_ts)\n\n    # Final print statement in the exact required format (no spaces).\n    print(f\"[{','.join(map(lambda v: repr(float(v)), results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Many real-world optimization problems are not unconstrained; they involve satisfying safety, budget, or physical limitations. This practice moves from standard BO to the more complex and practical domain of constrained optimization. You will derive the closed-form expression for the Constrained Expected Improvement (CEI) acquisition function from first principles (). This task requires a solid command of probability theory and calculus, and it demonstrates how the elegant framework of BO can be extended to simultaneously model and optimize an objective while respecting one or more constraints.",
            "id": "3291581",
            "problem": "A research team is using Constrained Bayesian Optimization to tune a scalar design variable $x \\in \\mathbb{R}$ for a black-box simulator. The goal is to minimize an unknown objective function $f(x)$ subject to a single inequality constraint $c(x) \\le 0$. The simulator is expensive, so the team employs Gaussian Process (GP) regression to model the latent, noise-free functions $f$ and $c$. At a candidate $x$, the current Gaussian Process posteriors for the latent values are independent and normally distributed:\n- $f(x) \\sim \\mathcal{N}(\\mu_{f}, \\sigma_{f}^{2})$,\n- $c(x) \\sim \\mathcal{N}(\\mu_{c}, \\sigma_{c}^{2})$,\nwith the predictive independence between $f(x)$ and $c(x)$ justified by independent priors and conditionally independent data likelihoods.\n\nDefine the constrained expected improvement (CEI) at $x$ for minimization as the expectation\n$$\n\\operatorname{CEI}(x) \\equiv \\mathbb{E}\\big[(f_{\\star}-f(x))_{+} \\,\\mathbf{1}\\{c(x)\\le 0\\}\\big],\n$$\nwhere $(a)_{+} \\equiv \\max\\{a,0\\}$, $\\mathbf{1}\\{\\cdot\\}$ is the indicator function, and $f_{\\star}$ is the best currently observed feasible objective value.\n\nStarting only from the definitions of expectation, indicator functions, and properties of the normal distribution, do the following:\n1. Derive a closed-form expression for $\\operatorname{CEI}(x)$ under the stated Gaussian Process independence assumptions, expressing your answer in terms of $\\mu_{f}$, $\\sigma_{f}$, $f_{\\star}$, $\\mu_{c}$, and $\\sigma_{c}$.\n2. Evaluate your expression numerically at a candidate point with parameters $\\mu_{f} = 0.4$, $\\sigma_{f} = 0.3$, $f_{\\star} = 0.4$, $\\mu_{c} = 0$, and $\\sigma_{c} = 1$.\n\nRound your final numerical answer to four significant figures. Express the final result as a pure number with no units.",
            "solution": "The problem is valid as it is scientifically grounded in the theory of Bayesian optimization, well-posed, objective, and contains all necessary information for a unique solution.\n\nThe constrained expected improvement, $\\operatorname{CEI}(x)$, is defined as the expectation of the product of two terms: the potential improvement in the objective function, $(f_{\\star}-f(x))_{+}$, and an indicator for feasibility, $\\mathbf{1}\\{c(x)\\le 0\\}$.\n$$\n\\operatorname{CEI}(x) = \\mathbb{E}\\big[(f_{\\star}-f(x))_{+} \\,\\mathbf{1}\\{c(x)\\le 0\\}\\big]\n$$\nThe expectation is taken over the joint probability distribution of the random variables $f(x)$ and $c(x)$. The problem states that the Gaussian Process posteriors for $f(x)$ and $c(x)$ are independent. Let $Y_f = f(x)$ and $Y_c = c(x)$. Their distributions are given as:\n- $Y_f \\sim \\mathcal{N}(\\mu_{f}, \\sigma_{f}^{2})$\n- $Y_c \\sim \\mathcal{N}(\\mu_{c}, \\sigma_{c}^{2})$\n\nDue to their independence, the joint probability density function is the product of their individual probability density functions: $p(y_f, y_c) = p_f(y_f) p_c(y_c)$.\nFurthermore, for two independent random variables $A$ and $B$, the expectation of their product is the product of their expectations, $\\mathbb{E}[AB] = \\mathbb{E}[A]\\mathbb{E}[B]$. In our case, the term $(f_{\\star}-Y_f)_{+}$ is a function of $Y_f$ only, and $\\mathbf{1}\\{Y_c\\le 0\\}$ is a function of $Y_c$ only. Therefore, these two derived random variables are also independent. We can separate the expectation:\n$$\n\\operatorname{CEI}(x) = \\mathbb{E}\\big[(f_{\\star}-Y_f)_{+}\\big] \\cdot \\mathbb{E}\\big[\\mathbf{1}\\{Y_c\\le 0\\}\\big]\n$$\nWe will now evaluate each expectation separately.\n\n**Part 1: Derivation of the closed-form expression**\n\nLet's first compute the expectation for the objective improvement, which we denote as $I_f$:\n$$\nI_f = \\mathbb{E}\\big[(f_{\\star}-Y_f)_{+}\\big] = \\int_{-\\infty}^{\\infty} (f_{\\star}-y_f)_{+} \\, p_f(y_f) \\, dy_f\n$$\nwhere $p_f(y_f)$ is the probability density function (PDF) of a normal distribution with mean $\\mu_f$ and variance $\\sigma_f^2$. The term $(f_{\\star}-y_f)_{+} = \\max\\{f_{\\star}-y_f, 0\\}$ is non-zero only for $y_f < f_{\\star}$. Thus, the integral's upper limit becomes $f_{\\star}$:\n$$\nI_f = \\int_{-\\infty}^{f_{\\star}} (f_{\\star}-y_f) \\, p_f(y_f) \\, dy_f\n$$\nWe can split this integral into two parts:\n$$\nI_f = f_{\\star} \\int_{-\\infty}^{f_{\\star}} p_f(y_f) \\, dy_f - \\int_{-\\infty}^{f_{\\star}} y_f \\, p_f(y_f) \\, dy_f\n$$\nTo evaluate these integrals, we perform a change of variable to standardize $Y_f$. Let $Z_f = \\frac{Y_f - \\mu_f}{\\sigma_f}$. The variable $Z_f$ follows the standard normal distribution, $Z_f \\sim \\mathcal{N}(0, 1)$, with PDF $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2)$ and cumulative distribution function (CDF) $\\Phi(z)$. The differential element transforms as $p_f(y_f) \\, dy_f = \\phi(z_f) \\, dz_f$. The integration limit $y_f = f_{\\star}$ becomes $z_f = \\frac{f_{\\star}-\\mu_f}{\\sigma_f}$. Let's define $\\gamma_f = \\frac{f_{\\star}-\\mu_f}{\\sigma_f}$.\n\nThe first integral is the probability $P(Y_f \\le f_{\\star})$:\n$$\n\\int_{-\\infty}^{f_{\\star}} p_f(y_f) \\, dy_f = P(Y_f \\le f_{\\star}) = P\\left(Z_f \\le \\frac{f_{\\star}-\\mu_f}{\\sigma_f}\\right) = \\Phi(\\gamma_f)\n$$\nThe second integral is:\n$$\n\\int_{-\\infty}^{f_{\\star}} y_f \\, p_f(y_f) \\, dy_f = \\int_{-\\infty}^{\\gamma_f} (\\mu_f + \\sigma_f z_f) \\, \\phi(z_f) \\, dz_f\n$$\n$$\n= \\mu_f \\int_{-\\infty}^{\\gamma_f} \\phi(z_f) \\, dz_f + \\sigma_f \\int_{-\\infty}^{\\gamma_f} z_f \\, \\phi(z_f) \\, dz_f\n$$\nThe integral $\\int_{-\\infty}^{\\gamma_f} \\phi(z_f) \\, dz_f$ is, by definition, $\\Phi(\\gamma_f)$. For the second integral, we use the property that $\\frac{d}{dz}(-\\phi(z)) = z\\phi(z)$.\n$$\n\\int_{-\\infty}^{\\gamma_f} z_f \\, \\phi(z_f) \\, dz_f = [-\\phi(z_f)]_{-\\infty}^{\\gamma_f} = -\\phi(\\gamma_f) - \\lim_{z_f \\to -\\infty} (-\\phi(z_f)) = -\\phi(\\gamma_f)\n$$\nSo, the second integral evaluates to $\\mu_f \\Phi(\\gamma_f) - \\sigma_f \\phi(\\gamma_f)$.\nCombining these results for $I_f$:\n$$\nI_f = f_{\\star} \\Phi(\\gamma_f) - (\\mu_f \\Phi(\\gamma_f) - \\sigma_f \\phi(\\gamma_f))\n$$\n$$\nI_f = (f_{\\star} - \\mu_f) \\Phi(\\gamma_f) + \\sigma_f \\phi(\\gamma_f)\n$$\n\nNext, we compute the expectation for the feasibility indicator, which we denote as $I_c$:\n$$\nI_c = \\mathbb{E}\\big[\\mathbf{1}\\{Y_c\\le 0\\}\\big] = \\int_{-\\infty}^{\\infty} \\mathbf{1}\\{y_c\\le 0\\} \\, p_c(y_c) \\, dy_c\n$$\nThis is simply the probability that $Y_c$ is less than or equal to $0$:\n$$\nI_c = P(Y_c \\le 0) = \\int_{-\\infty}^{0} p_c(y_c) \\, dy_c\n$$\nStandardizing the variable $Y_c$ with $Z_c = \\frac{Y_c - \\mu_c}{\\sigma_c} \\sim \\mathcal{N}(0, 1)$, the condition $Y_c \\le 0$ becomes $Z_c \\le \\frac{0-\\mu_c}{\\sigma_c} = -\\frac{\\mu_c}{\\sigma_c}$.\nThus, the probability is:\n$$\nI_c = P\\left(Z_c \\le -\\frac{\\mu_c}{\\sigma_c}\\right) = \\Phi\\left(-\\frac{\\mu_c}{\\sigma_c}\\right)\n$$\nFinally, the full expression for $\\operatorname{CEI}(x)$ is the product of $I_f$ and $I_c$:\n$$\n\\operatorname{CEI}(x) = \\left[ (f_{\\star} - \\mu_f) \\Phi\\left(\\frac{f_{\\star} - \\mu_f}{\\sigma_f}\\right) + \\sigma_f \\phi\\left(\\frac{f_{\\star} - \\mu_f}{\\sigma_f}\\right) \\right] \\Phi\\left(-\\frac{\\mu_c}{\\sigma_c}\\right)\n$$\nThis is the required closed-form expression.\n\n**Part 2: Numerical evaluation**\n\nWe are given the following parameter values for a candidate point $x$:\n- $\\mu_{f} = 0.4$\n- $\\sigma_{f} = 0.3$\n- $f_{\\star} = 0.4$\n- $\\mu_{c} = 0$\n- $\\sigma_{c} = 1$\n\nFirst, we calculate the arguments for the standard normal CDF and PDF.\nFor the objective part:\n$$\n\\gamma_f = \\frac{f_{\\star} - \\mu_f}{\\sigma_f} = \\frac{0.4 - 0.4}{0.3} = 0\n$$\nFor the constraint part:\n$$\n-\\frac{\\mu_c}{\\sigma_c} = -\\frac{0}{1} = 0\n$$\nNow, we evaluate the special functions at these arguments:\n- $\\Phi(0) = 0.5$\n- $\\phi(0) = \\frac{1}{\\sqrt{2\\pi}}$\n\nSubstitute these values into the expression for $\\operatorname{CEI}(x)$:\n$$\n\\operatorname{CEI}(x) = \\left[ (0.4 - 0.4) \\Phi(0) + 0.3 \\cdot \\phi(0) \\right] \\cdot \\Phi(0)\n$$\n$$\n\\operatorname{CEI}(x) = \\left[ 0 \\cdot 0.5 + 0.3 \\cdot \\frac{1}{\\sqrt{2\\pi}} \\right] \\cdot 0.5\n$$\n$$\n\\operatorname{CEI}(x) = \\left( 0.3 \\cdot \\frac{1}{\\sqrt{2\\pi}} \\right) \\cdot 0.5\n$$\n$$\n\\operatorname{CEI}(x) = \\frac{0.15}{\\sqrt{2\\pi}}\n$$\nNow we compute the numerical value:\n$$\n\\operatorname{CEI}(x) \\approx \\frac{0.15}{2.50662827} \\approx 0.059841342\n$$\nRounding to four significant figures, we get $0.05984$.",
            "answer": "$$\\boxed{0.05984}$$"
        },
        {
            "introduction": "Our final practice delves into a sophisticated scenario that often arises when the \"black-box\" function is evaluated via a complex simulation, such as a Markov chain Monte Carlo (MCMC) estimator. In these cases, the cost and precision of an evaluation are not fixed but are themselves decision variables. This exercise () asks you to design a policy that jointly selects the input point to evaluate and the MCMC chain length to use, maximizing the information gained per unit of computational cost. This problem highlights the deep connection between Bayesian optimization and the broader field of optimal experimental design, pushing you to think critically about the entire data-gathering process.",
            "id": "3291533",
            "problem": "You are given a finite-domain, single-step Bayesian experimental design problem that formalizes the interplay between Bayesian optimization and Markov Chain Monte Carlo (MCMC)-based estimators when the evaluation at an input $x$ is obtained by running a Markov chain of finite length with an input-dependent mixing time. The goal is to select a single input $x$ from a discrete domain and an integer chain length $L \\ge 1$ that together maximize a cost-sensitive, variance-reduction-based acquisition function.\n\nFundamental base and modeling assumptions:\n\n- The unknown objective function $f(\\cdot)$ is modeled as a Gaussian process (GP) prior with mean zero and covariance (kernel) $k(\\cdot,\\cdot)$. The prior is defined on a finite set of candidates $\\mathcal{X} = \\{x_1, \\ldots, x_N\\}$.\n- At a chosen input $x \\in \\mathcal{X}$, the only way to obtain an observation is by estimating an expectation using a Markov Chain Monte Carlo (MCMC) estimator. The chain has an integrated autocorrelation time (mixing time) $\\tau(x) > 0$, and the variance of the integrand under the target distribution is $\\sigma_g^2(x) > 0$. The observation is the time average over a chain of length $L \\in \\mathbb{N}$ and has noise variance\n  $\n  v_n(x,L) \\approx \\dfrac{2 \\, \\tau(x) \\, \\sigma_g^2(x)}{L} \\equiv \\dfrac{a(x)}{L},\n  $\n  which follows from the standard effective sample size approximation in Markov Chain Monte Carlo, where $a(x) \\equiv 2 \\tau(x) \\sigma_g^2(x)$.\n- The computational cost of running an MCMC chain of length $L$ at input $x$ is modeled as\n  $\n  \\mathrm{cost}(x,L) = b + t(x) \\, L,\n  $\n  where $b \\ge 0$ is a fixed overhead cost and $t(x) > 0$ is the per-iteration time at $x$.\n\nGiven a single noisy observation at $x$ with noise variance $v_n(x,L)$, the posterior variance of the GP at any $x' \\in \\mathcal{X}$ is reduced, by Gaussian conditioning, from $\\mathrm{Var}[f(x')]$ to\n$\n\\mathrm{Var}_{\\text{post}}[f(x')] = \\mathrm{Var}_{\\text{prior}}[f(x')] - \\dfrac{k(x',x)^2}{\\mathrm{Var}_{\\text{prior}}[f(x)] + v_n(x,L)}.\n$\nDefine a weighted integrated variance reduction functional\n$\nS(x,L) \\equiv \\sum_{i=0}^{N-1} w_i \\left( \\mathrm{Var}_{\\text{prior}}[f(x_i)] - \\mathrm{Var}_{\\text{post}}[f(x_i)] \\right) = \\sum_{i=0}^{N-1} w_i \\, \\dfrac{k(x_i,x)^2}{\\mathrm{Var}_{\\text{prior}}[f(x)] + v_n(x,L)},\n$\nwhere $w_i > 0$ are given weights. The acquisition we wish to maximize is the variance reduction per unit cost,\n$\nA(x,L) \\equiv \\dfrac{S(x,L)}{\\mathrm{cost}(x,L)}.\n$\nYou must choose $x \\in \\mathcal{X}$ and $L \\in \\mathbb{N}$ to maximize $A(x,L)$, subject to $L_{\\min} \\le L \\le L_{\\max}$, where $L_{\\min} = 1$ and $L_{\\max}$ is a provided upper bound. In the event of a tie in the maximum value of $A(x,L)$, choose the smallest index of $x$ (zero-based indexing), and then the smallest $L$ among those that tie.\n\nAll Gaussian process prior quantities are known. The kernel is the squared exponential (also called radial basis function) with variance parameter $\\sigma_f^2$ and length-scale $\\ell$, namely\n$\nk(x,x') = \\sigma_f^2 \\exp\\!\\left( - \\dfrac{(x-x')^2}{2 \\ell^2} \\right).\n$\nThere is no prior data, so all variances and covariances are computed from the prior. The prior mean is zero.\n\nTest suite and parameters to use:\n\n- The discrete domain is shared by all test cases and is\n  $\n  \\mathcal{X} = \\{ x_0, x_1, x_2, x_3, x_4 \\} = \\{ 0.0, 0.25, 0.5, 0.75, 1.0 \\}.\n  $\n  Use zero-based indexing for $\\mathcal{X}$ in the final answer.\n\n- Each test case specifies the kernel parameters $(\\sigma_f^2, \\ell)$, the weights $\\{w_i\\}_{i=0}^4$, the overhead $b$, the per-iteration times $\\{t(x_i)\\}_{i=0}^4$, the noise-scale parameters $\\{a(x_i)\\}_{i=0}^4$, and the maximum chain length $L_{\\max}$. Unless otherwise stated, $L_{\\min} = 1$.\n\n- For all test cases, the weighted integrated variance reduction $S(x,L)$ is computed exactly as above, and the acquisition is $A(x,L) = S(x,L)/\\mathrm{cost}(x,L)$.\n\nProvide a single program that solves the following four test cases:\n\n- Test case $1$:\n  - $\\sigma_f^2 = 1.0$, $\\ell = 0.35$,\n  - $w = [1, 1, 1, 1, 1]$,\n  - $b = 10.0$,\n  - $t = [1.0, 1.0, 1.0, 1.0, 1.0]$,\n  - $a = [3.0, 2.0, 1.0, 2.0, 3.0]$,\n  - $L_{\\max} = 100000$.\n\n- Test case $2$:\n  - $\\sigma_f^2 = 1.0$, $\\ell = 0.35$,\n  - $w = [1, 1, 1, 1, 1]$,\n  - $b = 100.0$,\n  - $t = [0.5, 0.5, 0.5, 0.5, 0.5]$,\n  - $a = [3.0, 2.0, 1.0, 2.0, 3.0]$,\n  - $L_{\\max} = 100000$.\n\n- Test case $3$:\n  - $\\sigma_f^2 = 1.0$, $\\ell = 0.05$,\n  - $w = [1, 1, 1, 1, 1]$,\n  - $b = 10.0$,\n  - $t = [1.0, 1.0, 1.0, 1.0, 1.0]$,\n  - $a = [3.0, 2.0, 1.0, 2.0, 3.0]$,\n  - $L_{\\max} = 100000$.\n\n- Test case $4$:\n  - $\\sigma_f^2 = 1.5$, $\\ell = 0.2$,\n  - $w = [1, 2, 1, 1, 2]$,\n  - $b = 30.0$,\n  - $t = [1.0, 2.0, 0.5, 3.0, 0.8]$,\n  - $a = [5.0, 1.0, 0.8, 2.5, 4.0]$,\n  - $L_{\\max} = 100000$.\n\nAngle units and physical units are not applicable to this problem. All computations are dimensionless. Your program must compute, for each test case, the triple consisting of:\n- the selected input index (zero-based integer),\n- the selected chain length (positive integer),\n- the corresponding maximized acquisition value $A(x,L)$ rounded to six decimal places.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list of the four triples, each triple itself being a comma-separated list enclosed in square brackets. For example:\n  $\n  [ [i_1, L_1, A_1], [i_2, L_2, A_2], [i_3, L_3, A_3], [i_4, L_4, A_4] ].\n  $\n- Round each acquisition value to six decimal places before output. In the presence of ties in $A(x,L)$, apply the tie-breaking rule described above.\n\nRequirements on scientific realism and derivation:\n\n- Begin from the fundamental definitions of Gaussian process priors and the variance of MCMC averages in terms of integrated autocorrelation time, as stated above.\n- Do not assume any shortcut formula that is not derived from the above bases.\n- Ensure that all computations are numerically well-defined under the provided parameters.\n\nYour task is to implement a complete, runnable program that performs the computations described and outputs the results in the exact format specified. The program must not require any user input and must not access any external resources.",
            "solution": "The user wants to solve a single-step Bayesian experimental design problem. The goal is to select an input point $x$ from a finite set $\\mathcal{X}$ and a Markov Chain Monte Carlo (MCMC) chain length $L$ that maximize the acquisition function $A(x, L)$, defined as the ratio of an information-theoretic gain to the computational cost.\n\nThe problem is validated as follows:\n- **Scientific Grounding**: The problem is well-founded in statistical machine learning, specifically Bayesian optimization with Gaussian processes and MCMC methods. The formula for GP posterior variance update and the approximation for MCMC sample variance are standard. The objective of maximizing information gain per unit cost is a canonical problem in experimental design.\n- **Well-Posedness**: All parameters and functions are explicitly defined. The optimization is over a finite set of pairs $(x, L)$, as $x \\in \\mathcal{X}$ (finite) and $L \\in \\{L_{\\min}, \\dots, L_{\\max}\\}$ (finite). A maximum value for $A(x, L)$ is guaranteed to exist. The provided tie-breaking rule ensures a unique solution is selected.\n- **Completeness and Consistency**: The problem statement is self-contained, providing all necessary definitions, constants, and parameters for each test case. There are no internal contradictions.\n\nThe problem is valid and can be solved.\n\nThe acquisition function to be maximized is:\n$$\nA(x,L) = \\dfrac{S(x,L)}{\\mathrm{cost}(x,L)}\n$$\nLet's analyze the numerator $S(x,L)$ and the denominator $\\mathrm{cost}(x,L)$ separately.\n\n**1. Modeling the Components**\n\nThe cost of running an MCMC chain of length $L$ at input $x$ is given by:\n$$\n\\mathrm{cost}(x,L) = b + t(x) \\, L\n$$\nwhere $b \\ge 0$ is a fixed overhead and $t(x) > 0$ is the per-iteration time.\n\nThe weighted integrated variance reduction $S(x,L)$ is:\n$$\nS(x,L) = \\sum_{i=1}^N w_i \\, \\dfrac{k(x_i,x)^2}{\\mathrm{Var}_{\\text{prior}}[f(x)] + v_n(x,L)}\n$$\nSince there is no prior data and the GP prior has a zero mean, the prior variance at any point $x'$ is given by the kernel evaluated at that point: $\\mathrm{Var}_{\\text{prior}}[f(x')] = k(x',x')$. The specified kernel is the squared exponential, $k(x,x') = \\sigma_f^2 \\exp\\left( - \\frac{(x-x')^2}{2 \\ell^2} \\right)$, which implies that for any $x \\in \\mathcal{X}$, the prior variance is uniform: $\\mathrm{Var}_{\\text{prior}}[f(x)] = k(x,x) = \\sigma_f^2$.\n\nThe observation noise variance is given as $v_n(x,L) = a(x)/L$. Substituting these into the expression for $S(x,L)$:\n$$\nS(x,L) = \\sum_{i=1}^N w_i \\, \\dfrac{k(x_i,x)^2}{\\sigma_f^2 + \\frac{a(x)}{L}}\n$$\nThe denominator does not depend on the summation index $i$. We can factor it out of the sum:\n$$\nS(x,L) = \\frac{1}{\\sigma_f^2 + \\frac{a(x)}{L}} \\left( \\sum_{i=1}^N w_i k(x_i,x)^2 \\right)\n$$\nFor a fixed choice of evaluation point $x$, the sum $\\sum_{i=1}^N w_i k(x_i,x)^2$ is a constant. Let us define this constant as $C(x)$:\n$$\nC(x) \\equiv \\sum_{i=1}^N w_i k(x_i,x)^2\n$$\n$C(x)$ can be pre-calculated for each $x \\in \\mathcal{X}$. The expression for $S(x,L)$ simplifies to:\n$$\nS(x,L) = \\frac{C(x)}{\\sigma_f^2 + \\frac{a(x)}{L}}\n$$\nNow, assembling the full acquisition function $A(x,L)$:\n$$\nA(x,L) = \\frac{\\frac{C(x)}{\\sigma_f^2 + \\frac{a(x)}{L}}}{b + t(x)L} = \\frac{C(x)}{\\left(\\sigma_f^2 + \\frac{a(x)}{L}\\right) (b + t(x)L)}\n$$\nExpanding the denominator gives:\n$$\nA(x,L) = \\frac{C(x)}{b\\sigma_f^2 + \\sigma_f^2 t(x) L + \\frac{b a(x)}{L} + a(x)t(x)}\n$$\n\n**2. Optimizing the Chain Length $L$**\n\nFor a fixed candidate point $x$, the term $C(x)$ is a positive constant. To maximize $A(x,L)$, we must minimize its denominator with respect to $L$. Let $D_x(L)$ be the denominator:\n$$\nD_x(L) = b\\sigma_f^2 + \\sigma_f^2 t(x) L + \\frac{b a(x)}{L} + a(x)t(x)\n$$\nWe want to find $L \\in \\{L_{\\min}, \\dots, L_{\\max}\\}$ that minimizes $D_x(L)$. The constant terms $b\\sigma_f^2$ and $a(x)t(x)$ do not affect the location of the minimum. The part of the denominator that depends on $L$ is:\n$$\ng_x(L) = (\\sigma_f^2 t(x)) L + \\frac{b a(x)}{L}\n$$\nThis function is of the form $K_1 L + K_2/L$, where $K_1 = \\sigma_f^2 t(x) > 0$ and $K_2 = b a(x) \\ge 0$. This is a convex function for $L > 0$. We can find its minimum by treating $L$ as a continuous variable and setting the derivative to zero:\n$$\n\\frac{dg_x}{dL} = K_1 - \\frac{K_2}{L^2} = 0 \\implies L^2 = \\frac{K_2}{K_1}\n$$\nThe optimal continuous value for $L$ is therefore:\n$$\nL^*_{\\text{real}}(x) = \\sqrt{\\frac{K_2}{K_1}} = \\sqrt{\\frac{b \\, a(x)}{\\sigma_f^2 \\, t(x)}}\n$$\nSince $L$ must be an integer, and $g_x(L)$ is convex, the integer minimum must be located at one of the two integers bracketing the continuous minimum $L^*_{\\text{real}}(x)$. That is, the optimal integer $L$ must be either $\\lfloor L^*_{\\text{real}}(x) \\rfloor$ or $\\lceil L^*_{\\text{real}}(x) \\rceil$, subject to the constraints $L_{\\min} \\le L \\le L_{\\max}$.\n\n**3. Solution Strategy**\n\nThis analytical insight allows us to avoid a costly brute-force search over all possible values of $L$ up to $L_{\\max}$. The overall algorithm is as follows:\n\nFor each test case:\n1. Initialize a maximum acquisition value `max_A` to a negative number and store the corresponding optimal pair $(x^*, L^*)$.\n2. Iterate through each candidate point $x_j \\in \\mathcal{X}$ for $j=0, \\dots, N-1$.\n3. For each $x_j$:\n    a. Pre-calculate the constant $C(x_j) = \\sum_{i=1}^N w_i k(x_i,x_j)^2$.\n    b. Calculate the optimal continuous chain length $L^*_{\\text{real}}(x_j) = \\sqrt{\\frac{b \\cdot a(x_j)}{\\sigma_f^2 \\cdot t(x_j)}}$.\n    c. Identify the set of integer candidates for $L$. These are $\\lfloor L^*_{\\text{real}}(x_j) \\rfloor$ and $\\lceil L^*_{\\text{real}}(x_j) \\rceil$, clamped to the interval $[L_{\\min}, L_{\\max}]$. This results in at most two distinct integer values to test for each $x_j$.\n    d. For each candidate integer $L$:\n        i. Calculate the acquisition value $A(x_j, L)$.\n        ii. Compare this value with the current maximum, `max_A`. If $A(x_j, L)$ is strictly greater than `max_A`, update `max_A` and store $(x_j, L)$ as the new best pair.\n4. The loops are structured to iterate through $x$ indices in increasing order, and for each $x$, to check candidate $L$ values in increasing order. This, combined with the strict inequality `A > max_A`, correctly implements the specified tie-breaking rule (smallest index of $x$, then smallest $L$).\n5. After checking all points in $\\mathcal{X}$, the stored pair $(x^*, L^*)$ and the corresponding `max_A` are the solution for the test case. The final acquisition value is rounded to six decimal places.\n\nThis procedure is repeated for all four test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a set of Bayesian experimental design problems to find the optimal\n    input point and MCMC chain length that maximize a cost-sensitive acquisition function.\n    \"\"\"\n    # Define the shared discrete domain for all test cases.\n    X_domain = np.array([0.0, 0.25, 0.5, 0.75, 1.0])\n    N = len(X_domain)\n\n    test_cases = [\n        # Test case 1\n        {\n            \"sf2\": 1.0, \"ell\": 0.35, \"w\": np.array([1.0, 1.0, 1.0, 1.0, 1.0]),\n            \"b\": 10.0, \"t\": np.array([1.0, 1.0, 1.0, 1.0, 1.0]),\n            \"a\": np.array([3.0, 2.0, 1.0, 2.0, 3.0]), \"L_max\": 100000\n        },\n        # Test case 2\n        {\n            \"sf2\": 1.0, \"ell\": 0.35, \"w\": np.array([1.0, 1.0, 1.0, 1.0, 1.0]),\n            \"b\": 100.0, \"t\": np.array([0.5, 0.5, 0.5, 0.5, 0.5]),\n            \"a\": np.array([3.0, 2.0, 1.0, 2.0, 3.0]), \"L_max\": 100000\n        },\n        # Test case 3\n        {\n            \"sf2\": 1.0, \"ell\": 0.05, \"w\": np.array([1.0, 1.0, 1.0, 1.0, 1.0]),\n            \"b\": 10.0, \"t\": np.array([1.0, 1.0, 1.0, 1.0, 1.0]),\n            \"a\": np.array([3.0, 2.0, 1.0, 2.0, 3.0]), \"L_max\": 100000\n        },\n        # Test case 4\n        {\n            \"sf2\": 1.5, \"ell\": 0.2, \"w\": np.array([1.0, 2.0, 1.0, 1.0, 2.0]),\n            \"b\": 30.0, \"t\": np.array([1.0, 2.0, 0.5, 3.0, 0.8]),\n            \"a\": np.array([5.0, 1.0, 0.8, 2.5, 4.0]), \"L_max\": 100000\n        }\n    ]\n\n    def kernel(x1, x2, sf2, ell):\n        \"\"\"Computes the squared exponential kernel value.\"\"\"\n        return sf2 * np.exp(-0.5 * ((x1 - x2) ** 2) / (ell ** 2))\n\n    all_results = []\n    \n    for case in test_cases:\n        sf2, ell, w = case[\"sf2\"], case[\"ell\"], case[\"w\"]\n        b, t, a = case[\"b\"], case[\"t\"], case[\"a\"]\n        L_max, L_min = case[\"L_max\"], 1\n\n        best_x_idx, best_L = -1, -1\n        max_A = -1.0\n\n        # Pre-compute the matrix of kernel values between all points in the domain.\n        K = np.zeros((N, N))\n        for i in range(N):\n            for j in range(N):\n                K[i, j] = kernel(X_domain[i], X_domain[j], sf2, ell)\n\n        # Iterate through each candidate point x_j to evaluate.\n        for j in range(N):\n            t_j, a_j = t[j], a[j]\n            \n            # Calculate C(x_j) = sum_i w_i * k(x_i, x_j)^2, a constant for fixed j.\n            C_j = np.sum(w * (K[:, j] ** 2))\n\n            L_candidates = []\n            if b == 0:\n                # If overhead cost is zero, A is maximized at the minimum chain length.\n                L_candidates = [L_min]\n            # Constraints from the problem statement t(x) > 0 and sf2 given as > 0\n            # ensure the denominator is positive.\n            else:\n                L_real = np.sqrt((b * a_j) / (sf2 * t_j))\n                l_cand_1 = int(np.floor(L_real))\n                l_cand_2 = int(np.ceil(L_real))\n                \n                # Clamp candidates to the allowed range [L_min, L_max].\n                l1 = max(L_min, min(L_max, l_cand_1))\n                l2 = max(L_min, min(L_max, l_cand_2))\n                \n                L_candidates = sorted(list(set([l1, l2])))\n\n            # Evaluate acquisition function for the candidate L values.\n            for L in L_candidates:\n                if L == 0: continue\n                cost_val = b + t_j * L\n                if cost_val == 0: continue\n\n                # A(x,L) = S(x,L) / cost(x,L)\n                # S(x,L) = C(x) / (sf2 + a(x)/L)\n                S_val = C_j / (sf2 + a_j/L)\n                A_val = S_val / cost_val\n\n                # The loop order (j asc, then L asc) and strict inequality\n                # correctly implement the specified tie-breaking rule.\n                if A_val > max_A:\n                    max_A = A_val\n                    best_x_idx = j\n                    best_L = L\n        \n        all_results.append([best_x_idx, best_L, max_A])\n\n    # Format the final output string as per problem specification.\n    result_str_parts = [f\"[{res[0]},{res[1]},{res[2]:.6f}]\" for res in all_results]\n    final_output = f\"[{','.join(result_str_parts)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}