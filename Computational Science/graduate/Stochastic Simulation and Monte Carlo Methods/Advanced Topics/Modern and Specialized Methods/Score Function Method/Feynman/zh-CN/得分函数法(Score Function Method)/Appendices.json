{
    "hands_on_practices": [
        {
            "introduction": "理论学习的最佳方式莫过于实践。本节将从最基础的离散概率分布——伯努利分布开始，引导您从零开始推导得分函数（score function）以及似然比（Likelihood Ratio, LR）恒等式。通过这个练习，您将能够掌握该方法的核心机制，为处理更复杂的问题打下坚实的基础 。",
            "id": "3337816",
            "problem": "考虑单个随机变量 $X$，其服从参数为 $p \\in (0,1)$ 的伯努利分布，概率质量函数为 $f_{p}(x) = p^{x} (1-p)^{1-x}$，其中 $x \\in \\{0,1\\}$。设得分函数定义为 $S_{p}(X) = \\partial_{p} \\ln f_{p}(X)$。从对数似然的定义出发，且不使用任何与似然比方法相关的预设公式，首先推导出一个关于 $X$ 和 $p$ 的 $S_{p}(X)$ 的显式表达式。接下来，仅使用期望的定义 $\\mathbb{E}_{p}[h(X)] = \\sum_{x \\in \\{0,1\\}} h(x) f_{p}(x)$ 以及在适当的正则性条件下微分与求和可交换的有效性，推导一个将 $\\partial_{p} \\mathbb{E}_{p}[h(X)]$ 与一个涉及 $S_{p}(X)$ 的期望联系起来的恒等式，其中 $h$ 为一个通用的可测函数。最后，将该恒等式应用于特例 $h(X) = \\mathbf{1}\\{X=1\\}$，并使用你推导出的似然比 (LR) 恒等式计算 $\\partial_{p} \\mathbb{E}_{p}[\\mathbf{1}\\{X=1\\}]$。你的最终答案应为一个无单位的精确实数。",
            "solution": "用户提供的问题被评估为有效。该问题在概率论和统计学方面有科学依据，问题陈述清晰，包含了所有必要信息，并以客观、正式的语言表述。问题要求从第一性原理出发，为伯努利随机变量推导得分函数和似然比恒等式，然后应用此恒等式。这是随机模拟领域一个标准的、可验证的练习。我们现在开始解答。\n\n问题分为三个部分。首先，我们必须推导得分函数 $S_{p}(X)$ 的显式表达式。其次，我们推导似然比 (LR) 恒等式，该恒等式将期望的导数与一个包含得分函数的期望联系起来。第三，我们将此恒等式应用于特定函数 $h(X) = \\mathbf{1}\\{X=1\\}$ 来计算导数。\n\n**第1部分：得分函数 $S_{p}(X)$ 的推导**\n\n随机变量 $X$ 服从参数为 $p \\in (0,1)$ 的伯努利分布。其概率质量函数 (PMF) 由下式给出：\n$$f_{p}(x) = p^{x} (1-p)^{1-x} \\quad \\text{for } x \\in \\{0, 1\\}$$\n得分函数 $S_{p}(X)$ 定义为对数似然函数关于参数 $p$ 的偏导数。首先，我们求对数似然函数 $\\ln f_{p}(x)$：\n$$ \\ln f_{p}(x) = \\ln(p^{x} (1-p)^{1-x}) $$\n利用对数的性质，上式可简化为：\n$$ \\ln f_{p}(x) = x \\ln(p) + (1-x) \\ln(1-p) $$\n现在，我们对该表达式关于 $p$ 求导：\n$$ \\partial_{p} \\ln f_{p}(x) = \\partial_{p} [x \\ln(p) + (1-x) \\ln(1-p)] $$\n$$ \\partial_{p} \\ln f_{p}(x) = x \\cdot \\frac{1}{p} + (1-x) \\cdot \\frac{1}{1-p} \\cdot (-1) $$\n$$ \\partial_{p} \\ln f_{p}(x) = \\frac{x}{p} - \\frac{1-x}{1-p} $$\n根据定义，得分函数为 $S_{p}(X) = \\partial_{p} \\ln f_{p}(X)$。因此，用随机变量 $X$ 替换具体结果 $x$，我们得到得分函数的表达式：\n$$ S_{p}(X) = \\frac{X}{p} - \\frac{1-X}{1-p} $$\n\n**第2部分：似然比 (LR) 恒等式的推导**\n\n我们被要求对于一个通用的可测函数 $h$ 推导一个将 $\\partial_{p} \\mathbb{E}_{p}[h(X)]$ 与一个涉及 $S_{p}(X)$ 的期望联系起来的恒等式。我们从 $h(X)$ 的期望的定义开始：\n$$ \\mathbb{E}_{p}[h(X)] = \\sum_{x \\in \\{0,1\\}} h(x) f_{p}(x) $$\n然后我们对该表达式关于 $p$ 求导：\n$$ \\partial_{p} \\mathbb{E}_{p}[h(X)] = \\partial_{p} \\left[ \\sum_{x \\in \\{0,1\\}} h(x) f_{p}(x) \\right] $$\n问题陈述中说明我们可以交换微分和求和的运算。这是一个关键步骤，被称为“对数求导技巧”或“似然比方法”：\n$$ \\partial_{p} \\mathbb{E}_{p}[h(X)] = \\sum_{x \\in \\{0,1\\}} h(x) \\left( \\partial_{p} f_{p}(x) \\right) $$\n我们可以利用应用于对数的链式法则来重写PMF的导数 $\\partial_{p} f_{p}(x)$：$\\partial_z \\ln(y) = \\frac{1}{y} \\partial_z y$，这意味着 $\\partial_z y = y \\cdot (\\partial_z \\ln y)$。应用此法则，我们得到：\n$$ \\partial_{p} f_{p}(x) = f_{p}(x) \\cdot (\\partial_{p} \\ln f_{p}(x)) $$\n项 $\\partial_{p} \\ln f_{p}(x)$ 正是在 $x$ 处求值的得分函数，我们记为 $S_p(x)$。将此代回求和式中，得到：\n$$ \\partial_{p} \\mathbb{E}_{p}[h(X)] = \\sum_{x \\in \\{0,1\\}} h(x) f_{p}(x) S_{p}(x) $$\n右侧的表达式根据定义是随机变量 $h(X)S_p(X)$ 的期望。因此，我们推导出了通用的似然比恒等式：\n$$ \\partial_{p} \\mathbb{E}_{p}[h(X)] = \\mathbb{E}_{p}[h(X) S_{p}(X)] $$\n\n**第3部分：特例化与最终计算**\n\n最后，我们必须使用第2部分推导的 LR 恒等式来计算 $\\partial_{p} \\mathbb{E}_{p}[\\mathbf{1}\\{X=1\\}]$。设 $h(X) = \\mathbf{1}\\{X=1\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n应用 LR 恒等式，我们有：\n$$ \\partial_{p} \\mathbb{E}_{p}[\\mathbf{1}\\{X=1\\}] = \\mathbb{E}_{p}[\\mathbf{1}\\{X=1\\} S_{p}(X)] $$\n我们使用其定义计算右侧的期望：\n$$ \\mathbb{E}_{p}[\\mathbf{1}\\{X=1\\} S_{p}(X)] = \\sum_{x \\in \\{0,1\\}} \\mathbf{1}\\{x=1\\} S_{p}(x) f_{p}(x) $$\n当 $x=0$ 时，项 $\\mathbf{1}\\{x=1\\}$ 为零；当 $x=1$ 时，为一。因此，求和式简化为仅对应于 $x=1$ 的一项：\n$$ \\mathbb{E}_{p}[\\mathbf{1}\\{X=1\\} S_{p}(X)] = \\mathbf{1}\\{0=1\\} S_{p}(0) f_{p}(0) + \\mathbf{1}\\{1=1\\} S_{p}(1) f_{p}(1) $$\n$$ = (0) \\cdot S_{p}(0) f_{p}(0) + (1) \\cdot S_{p}(1) f_{p}(1) = S_{p}(1) f_{p}(1) $$\n现在我们需要 $S_{p}(1)$ 和 $f_{p}(1)$ 的具体值。\n从第1部分可知，得分函数为 $S_{p}(x) = \\frac{x}{p} - \\frac{1-x}{1-p}$。对于 $x=1$，这给出：\n$$ S_{p}(1) = \\frac{1}{p} - \\frac{1-1}{1-p} = \\frac{1}{p} - 0 = \\frac{1}{p} $$\n对于 $x=1$ 的 PMF 是：\n$$ f_{p}(1) = p^{1} (1-p)^{1-1} = p \\cdot (1-p)^{0} = p $$\n将这些结果代回我们的表达式中：\n$$ \\partial_{p} \\mathbb{E}_{p}[\\mathbf{1}\\{X=1\\}] = S_{p}(1) f_{p}(1) = \\left(\\frac{1}{p}\\right) \\cdot (p) = 1 $$\n结果是一个与 $p$ 无关的常数。这可以通过直接计算来验证：$\\mathbb{E}_{p}[\\mathbf{1}\\{X=1\\}] = P(X=1) = p$，并且 $\\partial_{p}(p) = 1$。我们使用得分函数方法的推导得出了正确的结果。最终的数值答案是 $1$。",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "在掌握了离散情形下的基本应用后，我们将把目光投向连续域。本练习以无处不在的正态分布为例，展示了得分函数方法的普适性。通过解决这个问题，您将巩固对“对数导数技巧”的理解，并熟练地将其应用于连续型随机变量的参数敏感性分析中 。",
            "id": "3337798",
            "problem": "考虑一个实值随机变量 $X$ 的单参数概率密度族，其由均值参数为 $\\mu \\in \\mathbb{R}$、已知方差为 $\\sigma^{2} \\in (0,\\infty)$ 的正态分布给出，密度函数为\n$$\nf_{\\mu}(x) \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp\\!\\left(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right), \\quad x \\in \\mathbb{R}.\n$$\n参数 $\\mu$ 的得分函数（score function，或称似然比）定义为 $S_{\\mu}(x) \\equiv \\partial_{\\mu}\\ln f_{\\mu}(x)$。仅使用得分函数的定义、表达式 $\\mathbb{E}_{\\mu}[h(X)] = \\int_{\\mathbb{R}} h(x) f_{\\mu}(x)\\,dx$，以及在适当的正则性条件下微分和积分可交换的合理假设，完成以下任务：\n\n- 显式计算 $S_{\\mu}(X)$。\n- 应用得分函数法，推导 $\\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}]$ 的精确表达式，该表达式仅用 $\\mu$ 和 $\\sigma$ 表示。\n\n假设对于正态分布族和所考虑的被积函数，交换微分和积分所需的任何正则性条件均已满足。最终答案仅报告 $\\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}]$ 的值。请用精确的封闭形式表示答案。无需四舍五入。",
            "solution": "首先根据指定标准对问题进行验证。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n-   一个实值随机变量 $X$ 的单参数概率密度族是正态分布 $N(\\mu, \\sigma^2)$，其密度函数为：\n    $$f_{\\mu}(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp\\!\\left(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right), \\quad x \\in \\mathbb{R}$$\n-   均值参数为 $\\mu \\in \\mathbb{R}$。\n-   方差为已知常数 $\\sigma^{2} \\in (0,\\infty)$。\n-   得分函数定义为 $S_{\\mu}(x) \\equiv \\partial_{\\mu}\\ln f_{\\mu}(x)$。\n-   期望定义为 $\\mathbb{E}_{\\mu}[h(X)] = \\int_{\\mathbb{R}} h(x) f_{\\mu}(x)\\,dx$。\n-   假设交换微分和积分所需的任何正则性条件都已满足。\n-   任务是计算 $S_{\\mu}(X)$，然后使用得分函数法推导 $\\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}]$ 的表达式。\n-   最终报告的答案应仅为 $\\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}]$ 的值。\n\n**步骤2：使用提取的已知条件进行验证**\n\n-   **科学依据充分**：该问题基于概率论和统计学中基础且成熟的概念，即正态分布、期望和得分函数（似然比）法。这些是数理统计和随机模拟中的标准课题。\n-   **适定性**：问题陈述清晰。所有必要的定义均已提供，待计算的量是明确的。正则性条件的假设简化了分析，并确保可以应用标准方法，而无需证明其底层的测度论条件，从而使问题自洽且可解。存在唯一解。\n-   **客观性**：问题以精确、形式化的数学语言陈述，没有任何主观或模糊的术语。\n\n该问题未表现出验证清单中列出的任何缺陷。它科学合理、适定、客观，并与得分函数法的主题直接相关。\n\n**步骤3：结论与行动**\n\n该问题被判定为**有效**。将提供完整解答。\n\n### 解答\n\n解答过程根据题目要求分为两部分。首先，我们计算得分函数 $S_{\\mu}(X)$。其次，我们应用得分函数法来找出 $\\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}]$ 的表达式。\n\n**第一部分：计算得分函数**\n\n得分函数定义为 $S_{\\mu}(x) = \\partial_{\\mu}\\ln f_{\\mu}(x)$。我们首先对概率密度函数 $f_{\\mu}(x)$ 取自然对数：\n$$ \\ln f_{\\mu}(x) = \\ln\\left( \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp\\!\\left(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right) \\right) $$\n利用对数的性质，我们可以简化这个表达式：\n$$ \\ln f_{\\mu}(x) = \\ln\\left((2\\pi\\sigma^2)^{-1/2}\\right) - \\frac{(x-\\mu)^2}{2\\sigma^2} = -\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{(x-\\mu)^2}{2\\sigma^2} $$\n现在，我们对 $\\ln f_{\\mu}(x)$ 关于参数 $\\mu$ 求导。由于 $\\sigma^2$ 是已知的，项 $-\\frac{1}{2}\\ln(2\\pi\\sigma^2)$ 相对于 $\\mu$ 是一个常数。\n$$ S_{\\mu}(x) = \\partial_{\\mu} \\left( -\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{(x-\\mu)^2}{2\\sigma^2} \\right) = 0 - \\frac{1}{2\\sigma^2} \\partial_{\\mu}\\left((x-\\mu)^2\\right) $$\n使用链式法则求导，我们有 $\\partial_{\\mu}(x-\\mu)^2 = 2(x-\\mu) \\cdot (-1) = -2(x-\\mu)$。\n将其代回，我们得到得分函数：\n$$ S_{\\mu}(x) = -\\frac{1}{2\\sigma^2}(-2(x-\\mu)) = \\frac{x-\\mu}{\\sigma^2} $$\n当在随机变量 $X$ 处取值时，得分函数为 $S_{\\mu}(X) = \\frac{X-\\mu}{\\sigma^2}$。\n\n**第二部分：应用得分函数法**\n\n题目要求使用得分函数法推导 $\\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}]$。该方法，也称为似然比法，将期望的导数表示为一个期望。我们从 $\\mathbb{E}_{\\mu}[h(X)]$ 的定义出发，并对 $\\mu$ 求导：\n$$ \\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[h(X)] = \\partial_{\\mu} \\int_{\\mathbb{R}} h(x) f_{\\mu}(x)\\,dx $$\n题目声明我们可以假设满足正则性条件，以交换导数和积分（莱布尼茨积分法则）：\n$$ \\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[h(X)] = \\int_{\\mathbb{R}} h(x) \\left(\\partial_{\\mu}f_{\\mu}(x)\\right)\\,dx $$\n使用恒等式 $\\partial_{\\mu}f_{\\mu}(x) = f_{\\mu}(x) \\cdot \\partial_{\\mu}\\ln f_{\\mu}(x) = f_{\\mu}(x)S_{\\mu}(x)$，我们可以重写该积分：\n$$ \\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[h(X)] = \\int_{\\mathbb{R}} h(x) S_{\\mu}(x) f_{\\mu}(x)\\,dx $$\n根据定义，该积分是乘积 $h(X)S_{\\mu}(X)$ 关于密度 $f_{\\mu}(x)$ 的期望。因此，我们得到得分函数恒等式：\n$$ \\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[h(X)] = \\mathbb{E}_{\\mu}[h(X)S_{\\mu}(X)] $$\n对于本题，我们关心的是 $h(X) = X^2$。应用该恒等式：\n$$ \\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}] = \\mathbb{E}_{\\mu}[X^2 S_{\\mu}(X)] $$\n代入 $S_{\\mu}(X) = \\frac{X-\\mu}{\\sigma^2}$ 的表达式：\n$$ \\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}] = \\mathbb{E}_{\\mu}\\left[X^2 \\left(\\frac{X-\\mu}{\\sigma^2}\\right)\\right] = \\frac{1}{\\sigma^2}\\mathbb{E}_{\\mu}[X^2(X-\\mu)] $$\n利用期望的线性性质：\n$$ \\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}] = \\frac{1}{\\sigma^2}\\left(\\mathbb{E}_{\\mu}[X^3] - \\mu\\mathbb{E}_{\\mu}[X^2]\\right) $$\n为了继续计算，我们需要正态分布 $X \\sim N(\\mu, \\sigma^2)$ 的二阶矩和三阶矩。\n二阶矩 $\\mathbb{E}_{\\mu}[X^2]$ 可以通过方差的定义 $\\text{Var}_{\\mu}(X) = \\mathbb{E}_{\\mu}[X^2] - (\\mathbb{E}_{\\mu}[X])^2$ 求得。已知 $\\mathbb{E}_{\\mu}[X] = \\mu$ 和 $\\text{Var}_{\\mu}(X) = \\sigma^2$，我们有：\n$$ \\mathbb{E}_{\\mu}[X^2] = \\text{Var}_{\\mu}(X) + (\\mathbb{E}_{\\mu}[X])^2 = \\sigma^2 + \\mu^2 $$\n三阶矩 $\\mathbb{E}_{\\mu}[X^3]$ 可以通过考虑中心矩来计算。我们展开 $X^3 = ((X-\\mu)+\\mu)^3$：\n$$ \\mathbb{E}_{\\mu}[X^3] = \\mathbb{E}_{\\mu}[((X-\\mu)+\\mu)^3] = \\mathbb{E}_{\\mu}[(X-\\mu)^3 + 3\\mu(X-\\mu)^2 + 3\\mu^2(X-\\mu) + \\mu^3] $$\n根据期望的线性性质：\n$$ \\mathbb{E}_{\\mu}[X^3] = \\mathbb{E}_{\\mu}[(X-\\mu)^3] + 3\\mu\\mathbb{E}_{\\mu}[(X-\\mu)^2] + 3\\mu^2\\mathbb{E}_{\\mu}[X-\\mu] + \\mathbb{E}_{\\mu}[\\mu^3] $$\n我们使用正态分布的以下标准性质：\n-   一阶中心矩为 $\\mathbb{E}_{\\mu}[X-\\mu] = \\mathbb{E}_{\\mu}[X] - \\mu = \\mu - \\mu = 0$。\n-   二阶中心矩是方差，$\\mathbb{E}_{\\mu}[(X-\\mu)^2] = \\sigma^2$。\n-   三阶中心矩 $\\mathbb{E}_{\\mu}[(X-\\mu)^3]$ 为零，因为正态分布是关于其均值对称的。对称分布的所有奇数阶中心矩均为零。\n代入这些值：\n$$ \\mathbb{E}_{\\mu}[X^3] = 0 + 3\\mu(\\sigma^2) + 3\\mu^2(0) + \\mu^3 = 3\\mu\\sigma^2 + \\mu^3 $$\n现在我们将二阶矩和三阶矩的表达式代回我们关于 $\\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}]$ 的方程中：\n$$ \\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}] = \\frac{1}{\\sigma^2}\\left( (3\\mu\\sigma^2 + \\mu^3) - \\mu(\\sigma^2 + \\mu^2) \\right) $$\n展开括号内的项：\n$$ \\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}] = \\frac{1}{\\sigma^2}\\left( 3\\mu\\sigma^2 + \\mu^3 - \\mu\\sigma^2 - \\mu^3 \\right) $$\n$\\mu^3$ 项相互抵消，我们合并 $\\mu\\sigma^2$ 项：\n$$ \\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}] = \\frac{1}{\\sigma^2}\\left( 2\\mu\\sigma^2 \\right) $$\n最后，简化表达式得到结果：\n$$ \\partial_{\\mu}\\,\\mathbb{E}_{\\mu}[X^{2}] = 2\\mu $$\n这个结果可以通过直接对二阶矩的表达式 $\\mathbb{E}_{\\mu}[X^2] = \\sigma^2 + \\mu^2$ 关于 $\\mu$ 求导来验证，得到 $\\partial_{\\mu}(\\sigma^2 + \\mu^2) = 2\\mu$。这证实了我们使用得分函数法的推导是正确的。",
            "answer": "$$\\boxed{2\\mu}$$"
        },
        {
            "introduction": "我们为何需要得分函数方法？本练习通过一个泊松分布的例子，将得分函数法与路径导数法（pathwise derivative method）进行对比，从而解答了这一关键问题。您将发现，在处理涉及离散随机变量和不连续性能函数的期望导数时，得分函数法不仅是一种备选方案，更是一种不可或缺的工具。这个实践将加深您对该方法威力与适用范围的理解 。",
            "id": "3337820",
            "problem": "考虑一族随机变量 $X(\\lambda)$，其中对于 $\\lambda > 0$，有 $X \\sim \\mathrm{Poisson}(\\lambda)$。固定一个整数阈值 $k \\ge 1$。定义超出指示函数 $g(X) = \\mathbf{1}\\{X \\ge k\\}$ 和超出概率 $\\psi(\\lambda) = \\mathbb{P}_{\\lambda}(X \\ge k)$。你将使用似然比（LR）方法（也称为得分函数法）分析 $\\frac{\\partial}{\\partial \\lambda}\\,\\psi(\\lambda)$，并将其与使用路径导数法的尝试进行对比。\n\n任务：\n- 使用关于如何通过共同的随机源将不同 $\\lambda$ 的 $X(\\lambda)$ 耦合起来的基本原理，解释为什么在这种离散情况下，路径导数 $\\frac{\\partial}{\\partial \\lambda}\\,g(X(\\lambda))$ 几乎必然是未定义的，并且无法为 $\\frac{\\partial}{\\partial \\lambda}\\,\\psi(\\lambda)$ 提供一个正确的导数估计量。\n- 从泊松概率质量函数的定义以及通过引入得分函数来对期望进行微分的基本恒等式出发，推导 $\\frac{\\partial}{\\partial \\lambda}\\,\\psi(\\lambda)$ 的一个有效似然比表示，并将其简化为关于 $\\lambda$ 和 $k$ 的封闭形式解析表达式。\n- 假设对于一个固定的名义参数 $\\lambda_{0} > 0$，你有 $N$ 个独立样本 $X_{1},\\dots,X_{N} \\sim \\mathrm{Poisson}(\\lambda_{0})$。仅使用这些样本和似然比方法，为 $\\left.\\frac{\\partial}{\\partial \\lambda}\\,\\psi(\\lambda)\\right|_{\\lambda=\\lambda_{0}}$ 构建一个无偏蒙特卡洛估计量，并从基本原理证明其无偏性。\n\n你最终报告的答案必须是 $\\frac{\\partial}{\\partial \\lambda}\\,\\psi(\\lambda)$ 作为 $\\lambda$ 和 $k$ 的函数的简化封闭形式解析表达式。无需进行数值计算，也无需四舍五入。最终答案应不带单位。",
            "solution": "该问题要求分析泊松分布随机变量的超出概率的导数。我们将首先讨论路径导数方法的失效原因，然后使用似然比（得分函数）方法推导正确的导数，并提供一个蒙特卡洛估计量。这个问题提法恰当且科学上合理，其基础是概率论和随机模拟的基本原理。\n\n首先，我们讨论路径导数方法的失效原因。路径导数法依赖于将随机变量 $X(\\lambda)$ 表示为一个共同的底层随机变量（例如 $U \\sim \\mathrm{Uniform}(0,1)$）的变换，使得样本路径 $X(\\lambda, U)$ 关于 $\\lambda$ 可微。标准的构造方法是通过逆变换采样：$X(\\lambda) = F_{\\lambda}^{-1}(U)$，其中 $F_{\\lambda}$ 是 $\\mathrm{Poisson}(\\lambda)$ 分布的累积分布函数（CDF）。对于像泊松分布这样的离散分布，其 CDF $F_{\\lambda}(x) = \\sum_{i=0}^{\\lfloor x \\rfloor} \\frac{\\lambda^i \\exp(-\\lambda)}{i!}$ 是一个阶梯函数。因此，其逆函数 $F_{\\lambda}^{-1}(u)$ 是一个关于 $u$ 的分段常数函数。对于固定的 $U$，路径 $X(\\lambda, U)$ 也是一个关于 $\\lambda$ 的分段常数函数。其导数 $\\frac{\\partial}{\\partial \\lambda} X(\\lambda)$ 几乎处处为零，仅在 $X(\\lambda)$ 跳到下一个整数值的点上出现无限大的尖峰（狄拉克-德尔塔函数）。\n\n性能函数为 $g(X) = \\mathbf{1}\\{X \\ge k\\}$，其中 $k \\ge 1$ 是一个固定的整数。路径导数将是 $\\frac{\\partial}{\\partial \\lambda} g(X(\\lambda))$。由于 $g(\\cdot)$ 和 $X(\\cdot, \\lambda)$ 都是分段常数函数，它们的复合函数 $g(X(\\lambda))$ 也是一个关于 $\\lambda$ 的分段常数函数。它关于 $\\lambda$ 的导数对于几乎所有的 $\\lambda$ 值都为 0。因此，如果交换期望和微分算子：\n$$\n\\frac{\\partial}{\\partial \\lambda} \\psi(\\lambda) = \\frac{\\partial}{\\partial \\lambda} \\mathbb{E}_{\\lambda}[g(X(\\lambda))] \\stackrel{?}{=} \\mathbb{E}_{\\lambda}\\left[\\frac{\\partial}{\\partial \\lambda} g(X(\\lambda))\\right]\n$$\n得到的估计量将是 $\\mathbb{E}_{\\lambda}[0] = 0$。这是不正确的，因为超出概率 $\\psi(\\lambda) = \\sum_{x=k}^{\\infty} \\frac{\\lambda^x \\exp(-\\lambda)}{x!}$ 显然不是一个关于 $\\lambda$ 的常数函数。在这种情况下，微分和期望的交换是无效的，因为样本路径 $g(X(\\lambda))$ 关于 $\\lambda$ 不是绝对连续的。对于离散随机变量且性能函数 $g$ 不连续的问题，路径导数法会失效。\n\n接下来，我们使用似然比（LR）或得分函数法推导导数的一个有效表示。我们从超出概率 $\\psi(\\lambda)$ 的定义开始：\n$$\n\\psi(\\lambda) = \\mathbb{E}_{\\lambda}[g(X)] = \\sum_{x=0}^{\\infty} g(x) p(x; \\lambda) = \\sum_{x=k}^{\\infty} p(x; \\lambda)\n$$\n其中 $p(x; \\lambda) = \\frac{\\lambda^x \\exp(-\\lambda)}{x!}$ 是 $\\mathrm{Poisson}(\\lambda)$ 分布的概率质量函数（PMF）。似然比方法依赖于恒等式 $\\frac{\\partial}{\\partial \\lambda} p(x; \\lambda) = p(x; \\lambda) \\frac{\\partial}{\\partial \\lambda} \\ln p(x; \\lambda)$。术语 $S(x; \\lambda) = \\frac{\\partial}{\\partial \\lambda} \\ln p(x; \\lambda)$ 被称为得分函数。对于泊松分布：\n$$\n\\ln p(x; \\lambda) = x \\ln(\\lambda) - \\lambda - \\ln(x!)\n$$\n得分函数是：\n$$\nS(x; \\lambda) = \\frac{\\partial}{\\partial \\lambda} [x \\ln(\\lambda) - \\lambda - \\ln(x!)] = \\frac{x}{\\lambda} - 1\n$$\n由于泊松分布的支撑集（非负整数集）不依赖于 $\\lambda$，并且概率质量函数关于 $\\lambda$ 可微，我们可以交换微分和求和：\n$$\n\\frac{\\partial}{\\partial \\lambda} \\psi(\\lambda) = \\frac{\\partial}{\\partial \\lambda} \\sum_{x=k}^{\\infty} p(x; \\lambda) = \\sum_{x=k}^{\\infty} \\frac{\\partial}{\\partial \\lambda} p(x; \\lambda)\n$$\n使用得分函数恒等式：\n$$\n\\frac{\\partial}{\\partial \\lambda} \\psi(\\lambda) = \\sum_{x=k}^{\\infty} p(x; \\lambda) S(x; \\lambda) = \\mathbb{E}_{\\lambda}[\\mathbf{1}\\{X \\ge k\\} S(X; \\lambda)]\n$$\n这给出了导数的似然比表示。我们现在代入得分函数并进行简化：\n$$\n\\frac{\\partial}{\\partial \\lambda} \\psi(\\lambda) = \\mathbb{E}_{\\lambda}\\left[ \\mathbf{1}\\{X \\ge k\\} \\left(\\frac{X}{\\lambda} - 1\\right) \\right] = \\sum_{x=k}^{\\infty} \\left(\\frac{x}{\\lambda} - 1\\right) \\frac{\\lambda^x \\exp(-\\lambda)}{x!}\n$$\n我们可以将这个和分成两部分：\n$$\n\\frac{\\partial}{\\partial \\lambda} \\psi(\\lambda) = \\frac{1}{\\lambda} \\sum_{x=k}^{\\infty} x \\frac{\\lambda^x \\exp(-\\lambda)}{x!} - \\sum_{x=k}^{\\infty} \\frac{\\lambda^x \\exp(-\\lambda)}{x!}\n$$\n第二项就是 $\\mathbb{P}_{\\lambda}(X \\ge k)$。对于第一项，我们简化被加数：\n$$\nx \\frac{\\lambda^x}{x!} = x \\frac{\\lambda \\cdot \\lambda^{x-1}}{x \\cdot (x-1)!} = \\frac{\\lambda \\cdot \\lambda^{x-1}}{(x-1)!}\n$$\n因此，第一项变为：\n$$\n\\frac{1}{\\lambda} \\sum_{x=k}^{\\infty} \\frac{\\lambda \\cdot \\lambda^{x-1} \\exp(-\\lambda)}{(x-1)!} = \\sum_{x=k}^{\\infty} \\frac{\\lambda^{x-1} \\exp(-\\lambda)}{(x-1)!}\n$$\n令 $j = x-1$。当 $x=k$ 时，$j=k-1$。这个和变为：\n$$\n\\sum_{j=k-1}^{\\infty} \\frac{\\lambda^j \\exp(-\\lambda)}{j!} = \\mathbb{P}_{\\lambda}(Y \\ge k-1)\n$$\n其中 $Y \\sim \\mathrm{Poisson}(\\lambda)$。合并各项，我们得到：\n$$\n\\frac{\\partial}{\\partial \\lambda} \\psi(\\lambda) = \\mathbb{P}_{\\lambda}(X \\ge k-1) - \\mathbb{P}_{\\lambda}(X \\ge k)\n$$\n大于或等于 $k-1$ 的概率与大于或等于 $k$ 的概率之差，恰好是等于 $k-1$ 的概率：\n$$\n\\frac{\\partial}{\\partial \\lambda} \\psi(\\lambda) = \\mathbb{P}_{\\lambda}(X = k-1)\n$$\n这就得出了最终的简化封闭形式表达式：\n$$\n\\frac{\\partial}{\\partial \\lambda} \\psi(\\lambda) = p(k-1; \\lambda) = \\frac{\\lambda^{k-1} \\exp(-\\lambda)}{(k-1)!}\n$$\n\n最后，我们为 $\\left.\\frac{\\partial}{\\partial \\lambda}\\,\\psi(\\lambda)\\right|_{\\lambda=\\lambda_{0}}$ 构建一个无偏蒙特卡洛估计量，给定 $N$ 个独立样本 $X_{1},\\dots,X_{N} \\sim \\mathrm{Poisson}(\\lambda_{0})$。基于似然比表示 $\\frac{\\partial}{\\partial \\lambda} \\psi(\\lambda) = \\mathbb{E}_{\\lambda}[\\mathbf{1}\\{X \\ge k\\} S(X; \\lambda)]$，一个自然的估计量是期望内随机变量在 $\\lambda = \\lambda_0$ 处的样本均值：\n$$\n\\widehat{D}_{N} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{1}\\{X_i \\ge k\\} S(X_i; \\lambda_0) = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{1}\\{X_i \\ge k\\} \\left(\\frac{X_i}{\\lambda_0} - 1\\right)\n$$\n为了证明其无偏性，我们计算它的期望：\n$$\n\\mathbb{E}_{\\lambda_0}[\\widehat{D}_{N}] = \\mathbb{E}_{\\lambda_0}\\left[ \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{1}\\{X_i \\ge k\\} \\left(\\frac{X_i}{\\lambda_0} - 1\\right) \\right]\n$$\n根据期望的线性性质，并且由于样本 $X_i$ 是独立同分布的：\n$$\n\\mathbb{E}_{\\lambda_0}[\\widehat{D}_{N}] = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{E}_{\\lambda_0}\\left[ \\mathbf{1}\\{X_i \\ge k\\} \\left(\\frac{X_i}{\\lambda_0} - 1\\right) \\right] = \\mathbb{E}_{\\lambda_0}\\left[ \\mathbf{1}\\{X \\ge k\\} \\left(\\frac{X}{\\lambda_0} - 1\\right) \\right]\n$$\n正如我们的推导所证实的，这个期望恰好等于 $\\left.\\frac{\\partial}{\\partial \\lambda} \\psi(\\lambda)\\right|_{\\lambda=\\lambda_0}$。因此，估计量 $\\widehat{D}_{N}$ 是无偏的。",
            "answer": "$$\\boxed{\\frac{\\lambda^{k-1} \\exp(-\\lambda)}{(k-1)!}}$$"
        }
    ]
}