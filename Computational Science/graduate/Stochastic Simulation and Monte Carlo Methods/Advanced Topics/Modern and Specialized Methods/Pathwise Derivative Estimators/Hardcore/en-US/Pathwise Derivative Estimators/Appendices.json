{
    "hands_on_practices": [
        {
            "introduction": "To build a solid foundation, our first practice provides a direct, step-by-step walkthrough of constructing and validating a pathwise derivative estimator. You will work with the Ornstein-Uhlenbeck process over a finite time horizon, a common model in many scientific fields. This exercise () will guide you through deriving the \"tangent process\" and using it to form an estimator, then confirming its unbiasedness by comparing your result to a direct analytical calculation, reinforcing the core mechanics of the pathwise method.",
            "id": "3328507",
            "problem": "Consider the Ornstein–Uhlenbeck (OU) process parameterized by a scalar parameter $\\theta \\in (0,\\infty)$, defined as the unique strong solution to the linear stochastic differential equation (SDE)\n$$\ndX_{t}^{\\theta} = -\\lambda(\\theta)\\,X_{t}^{\\theta}\\,dt + \\sigma\\,dW_{t}, \\quad X_{0}^{\\theta} = x_{0},\n$$\nwhere $W_{t}$ is a standard Wiener process (also known as Brownian motion), $\\sigma \\in (0,\\infty)$ is a fixed diffusion coefficient, and $x_{0} \\in \\mathbb{R}$ is deterministic and independent of $\\theta$. Let the mean-reversion rate be $\\lambda(\\theta) = \\theta$. Define the performance functional at a fixed terminal time $T \\in (0,\\infty)$ by $f(x) = x^{2}$ and the quantity of interest $F(\\theta) = \\mathbb{E}[f(X_{T}^{\\theta})]$.\n\nUsing only foundational tools from the theory of stochastic processes and stochastic differential equations—namely, existence and uniqueness for linear SDEs, the variation-of-constants method for linear equations, the Itô isometry, and dominated convergence as needed—do the following:\n\n- Derive the pathwise sensitivity process $Y_{t} = \\nabla_{\\theta} X_{t}^{\\theta}$ and obtain a closed-form expression for the pathwise gradient estimator $G(\\theta) = f'(X_{T}^{\\theta})\\,Y_{T}$.\n\n- Compute $\\mathbb{E}[G(\\theta)]$ in closed form and compare it to the analytic derivative $\\nabla_{\\theta}\\,\\mathbb{E}[f(X_{T}^{\\theta})]$ obtained by differentiating the exact expression for $\\mathbb{E}[X_{T}^{\\theta\\,2}]$ with respect to $\\theta$. Conclude whether $G(\\theta)$ is an unbiased estimator of $\\nabla_{\\theta}\\,\\mathbb{E}[f(X_{T}^{\\theta})]$ under the stated regularity assumptions.\n\nExpress your final answer as a single, closed-form analytic expression for $\\nabla_{\\theta}\\,\\mathbb{E}[f(X_{T}^{\\theta})]$ in terms of $\\theta$, $T$, $\\sigma$, and $x_{0}$. No numerical approximation or rounding is required.",
            "solution": "The problem statement is evaluated as scientifically grounded, well-posed, objective, complete, and feasible. It represents a standard, non-trivial problem in the field of stochastic sensitivity analysis. Therefore, the problem is deemed **valid**, and a full solution is presented below.\n\nThe objective is to derive and analyze the pathwise gradient estimator for a parameter in an Ornstein-Uhlenbeck (OU) process. The procedure involves several steps: solving the primary SDE, deriving and solving the sensitivity SDE, constructing the estimator, calculating its expectation, and comparing this to the true analytical derivative.\n\nLet the OU process be given by the SDE:\n$$\ndX_{t}^{\\theta} = -\\theta X_{t}^{\\theta}\\,dt + \\sigma\\,dW_{t}, \\quad X_{0}^{\\theta} = x_{0}\n$$\nwhere $\\lambda(\\theta) = \\theta$.\n\n**1. Closed-Form Solution for $X_{t}^{\\theta}$**\n\nThis is a linear SDE. We can solve it using an integrating factor, $I_{t} = \\exp(\\theta t)$.\nApplying Itô's product rule to $I_{t}X_{t}^{\\theta}$:\n$$\nd(\\exp(\\theta t) X_{t}^{\\theta}) = \\theta \\exp(\\theta t) X_{t}^{\\theta}\\,dt + \\exp(\\theta t) dX_{t}^{\\theta}\n$$\nSubstituting $dX_{t}^{\\theta}$:\n$$\nd(\\exp(\\theta t) X_{t}^{\\theta}) = \\theta \\exp(\\theta t) X_{t}^{\\theta}\\,dt + \\exp(\\theta t) (-\\theta X_{t}^{\\theta}\\,dt + \\sigma\\,dW_{t}) = \\sigma \\exp(\\theta t)\\,dW_{t}\n$$\nIntegrating from $s=0$ to $s=t$:\n$$\n\\exp(\\theta t) X_{t}^{\\theta} - \\exp(0) X_{0}^{\\theta} = \\int_{0}^{t} \\sigma \\exp(\\theta s)\\,dW_{s}\n$$\nSolving for $X_{t}^{\\theta}$ with $X_{0}^{\\theta} = x_0$:\n$$\nX_{t}^{\\theta} = x_{0}\\exp(-\\theta t) + \\sigma \\int_{0}^{t} \\exp(-\\theta(t-s))\\,dW_{s}\n$$\nAt the terminal time $T$, we have:\n$$\nX_{T}^{\\theta} = x_{0}\\exp(-\\theta T) + \\sigma \\int_{0}^{T} \\exp(-\\theta(T-s))\\,dW_{s}\n$$\n\n**2. Derivation and Solution of the Sensitivity Process $Y_{t} = \\nabla_{\\theta} X_{t}^{\\theta}$**\n\nThe pathwise derivative process $Y_{t} = \\nabla_{\\theta} X_{t}^{\\theta}$ is found by formally differentiating the SDE for $X_{t}^{\\theta}$ with respect to $\\theta$. The interchange of differentiation and stochastic integration is permissible here because the SDE coefficients are smooth in $\\theta$ and the diffusion coefficient $\\sigma$ is independent of $\\theta$.\n$$\ndY_{t} = d(\\nabla_{\\theta} X_{t}^{\\theta}) = \\nabla_{\\theta}(dX_{t}^{\\theta}) = \\nabla_{\\theta}(-\\theta X_{t}^{\\theta}\\,dt + \\sigma\\,dW_{t})\n$$\n$$\ndY_{t} = -(\\nabla_{\\theta}(\\theta X_{t}^{\\theta}))\\,dt = -((\\nabla_{\\theta}\\theta) X_{t}^{\\theta} + \\theta (\\nabla_{\\theta} X_{t}^{\\theta}))\\,dt = -(X_{t}^{\\theta} + \\theta Y_{t})\\,dt\n$$\nThis gives the linear ordinary differential equation (for each sample path) for $Y_{t}$:\n$$\ndY_{t} = -\\theta Y_{t}\\,dt - X_{t}^{\\theta}\\,dt\n$$\nThe initial condition is $Y_{0} = \\nabla_{\\theta} X_{0}^{\\theta} = \\nabla_{\\theta} x_{0} = 0$, since $x_{0}$ is independent of $\\theta$.\nWe solve this ODE using the integrating factor $\\exp(\\theta t)$:\n$$\nd(\\exp(\\theta t) Y_{t}) = \\exp(\\theta t)(dY_{t} + \\theta Y_{t}\\,dt) = -\\exp(\\theta t)X_{t}^{\\theta}\\,dt\n$$\nIntegrating from $s=0$ to $s=t$:\n$$\n\\exp(\\theta t) Y_{t} - Y_0 = -\\int_{0}^{t} \\exp(\\theta s) X_{s}^{\\theta}\\,ds\n$$\nWith $Y_0=0$, we have $Y_{t} = -\\exp(-\\theta t) \\int_{0}^{t} \\exp(\\theta s) X_{s}^{\\theta}\\,ds$.\nSubstituting the expression for $X_{s}^{\\theta}$:\n$$\nY_{t} = -\\exp(-\\theta t) \\int_{0}^{t} \\exp(\\theta s) \\left( x_{0}\\exp(-\\theta s) + \\sigma\\int_{0}^{s} \\exp(-\\theta(s-u))\\,dW_{u} \\right)\\,ds\n$$\n$$\nY_{t} = -\\exp(-\\theta t) \\int_{0}^{t} \\left( x_{0} + \\sigma\\int_{0}^{s} \\exp(\\theta u)\\,dW_{u} \\right)\\,ds\n$$\n$$\nY_{t} = -\\exp(-\\theta t) \\left( x_{0}t + \\sigma \\int_{0}^{t} \\int_{0}^{s} \\exp(\\theta u)\\,dW_{u}\\,ds \\right)\n$$\nUsing the stochastic Fubini theorem to change the order of integration:\n$$\n\\int_{0}^{t} \\int_{0}^{s} \\exp(\\theta u)\\,dW_{u}\\,ds = \\int_{0}^{t} (t-u)\\exp(\\theta u)\\,dW_{u}\n$$\nThus, the sensitivity process is:\n$$\nY_{t} = -x_{0}t\\exp(-\\theta t) - \\sigma\\exp(-\\theta t)\\int_{0}^{t} (t-u)\\exp(\\theta u)\\,dW_{u} = -x_{0}t\\exp(-\\theta t) - \\sigma\\int_{0}^{t} (t-u)\\exp(-\\theta(t-u))\\,dW_{u}\n$$\nAt the terminal time $T$:\n$$\nY_{T} = -x_{0}T\\exp(-\\theta T) - \\sigma\\int_{0}^{T} (T-u)\\exp(-\\theta(T-u))\\,dW_{u}\n$$\n\n**3. The Pathwise Gradient Estimator $G(\\theta)$ and its Expectation**\n\nThe estimator is $G(\\theta) = f'(X_{T}^{\\theta})Y_{T}$. With $f(x)=x^2$, we have $f'(x)=2x$.\n$$\nG(\\theta) = 2X_{T}^{\\theta}Y_{T}\n$$\nWe now compute its expectation, $\\mathbb{E}[G(\\theta)]$:\n$$\n\\mathbb{E}[G(\\theta)] = 2\\,\\mathbb{E}[X_{T}^{\\theta}Y_{T}]\n$$\nLet's expand the product $X_{T}^{\\theta}Y_{T}$:\n$$\nX_{T}^{\\theta}Y_{T} = \\left( x_{0}\\exp(-\\theta T) + \\sigma\\int_{0}^{T} \\exp(-\\theta(T-s))\\,dW_{s} \\right) \\left( -x_{0}T\\exp(-\\theta T) - \\sigma\\int_{0}^{T} (T-u)\\exp(-\\theta(T-u))\\,dW_{u} \\right)\n$$\nTaking the expectation, the cross-terms involving a single Itô integral are zero, because the expectation of an Itô integral with a deterministic integrand is zero.\n$$\n\\mathbb{E}[X_{T}^{\\theta}Y_{T}] = -x_{0}^{2}T\\exp(-2\\theta T) - \\sigma^{2}\\,\\mathbb{E}\\left[ \\left(\\int_{0}^{T} \\exp(-\\theta(T-s))\\,dW_{s}\\right) \\left(\\int_{0}^{T} (T-u)\\exp(-\\theta(T-u))\\,dW_{u}\\right) \\right]\n$$\nUsing the Itô isometry property $\\mathbb{E}[(\\int g_1 dW)(\\int g_2 dW)] = \\int g_1 g_2 ds$:\n$$\n\\mathbb{E}[\\dots] = \\int_{0}^{T} \\exp(-\\theta(T-s)) \\cdot (T-s)\\exp(-\\theta(T-s))\\,ds = \\int_{0}^{T} (T-s)\\exp(-2\\theta(T-s))\\,ds\n$$\nLet $v=T-s$, so $dv=-ds$. The integral becomes $\\int_{T}^{0} v\\exp(-2\\theta v)(-dv) = \\int_{0}^{T} v\\exp(-2\\theta v)\\,dv$.\nWe compute this integral using integration by parts, $\\int u'v_{int} = uv_{int} - \\int uv'_{int}$:\n\\begin{align*}\n\\int_{0}^{T} v\\exp(-2\\theta v)\\,dv = \\left[v \\left(\\frac{\\exp(-2\\theta v)}{-2\\theta}\\right)\\right]_{0}^{T} - \\int_{0}^{T} \\frac{\\exp(-2\\theta v)}{-2\\theta} \\cdot 1 \\,dv \\\\\n= -\\frac{T}{2\\theta}\\exp(-2\\theta T) + \\frac{1}{2\\theta} \\int_{0}^{T} \\exp(-2\\theta v)\\,dv \\\\\n= -\\frac{T}{2\\theta}\\exp(-2\\theta T) + \\frac{1}{2\\theta} \\left[\\frac{\\exp(-2\\theta v)}{-2\\theta}\\right]_{0}^{T} \\\\\n= -\\frac{T}{2\\theta}\\exp(-2\\theta T) - \\frac{1}{4\\theta^2}(\\exp(-2\\theta T) - 1)\n\\end{align*}\nSubstituting this back into the expectation for $G(\\theta)$:\n$$\n\\mathbb{E}[G(\\theta)] = 2 \\left( -x_{0}^{2}T\\exp(-2\\theta T) - \\sigma^{2}\\left(-\\frac{T}{2\\theta}\\exp(-2\\theta T) - \\frac{1}{4\\theta^2}\\exp(-2\\theta T) + \\frac{1}{4\\theta^2}\\right) \\right)\n$$\n$$\n\\mathbb{E}[G(\\theta)] = -2x_{0}^{2}T\\exp(-2\\theta T) + \\frac{\\sigma^{2}T}{\\theta}\\exp(-2\\theta T) + \\frac{\\sigma^{2}}{2\\theta^2}\\exp(-2\\theta T) - \\frac{\\sigma^{2}}{2\\theta^2}\n$$\n\n**4. Analytic Derivative of $\\mathbb{E}[f(X_{T}^{\\theta})]$**\n\nFirst, we find $F(\\theta) = \\mathbb{E}[f(X_{T}^{\\theta})] = \\mathbb{E}[(X_{T}^{\\theta})^2]$. For any random variable $Z$, $\\mathbb{E}[Z^2] = \\text{Var}(Z) + (\\mathbb{E}[Z])^2$.\nFrom the solution for $X_{T}^{\\theta}$, it is a Gaussian random variable with:\nMean: $\\mathbb{E}[X_{T}^{\\theta}] = x_{0}\\exp(-\\theta T)$.\nVariance: $\\text{Var}(X_{T}^{\\theta}) = \\mathbb{E}[(\\sigma \\int_{0}^{T} \\exp(-\\theta(T-s))\\,dW_{s})^2] = \\sigma^2 \\int_{0}^{T} \\exp(-2\\theta(T-s))\\,ds$.\nLetting $v=T-s$, the integral is $\\int_{0}^{T} \\exp(-2\\theta v)\\,dv = \\frac{1-\\exp(-2\\theta T)}{2\\theta}$.\nSo, $\\text{Var}(X_{T}^{\\theta}) = \\frac{\\sigma^2}{2\\theta}(1-\\exp(-2\\theta T))$.\nTherefore, the quantity of interest is:\n$$\nF(\\theta) = \\mathbb{E}[(X_{T}^{\\theta})^2] = \\frac{\\sigma^2}{2\\theta}(1-\\exp(-2\\theta T)) + (x_{0}\\exp(-\\theta T))^2\n$$\n$$\nF(\\theta) = \\frac{\\sigma^2}{2\\theta} - \\frac{\\sigma^2}{2\\theta}\\exp(-2\\theta T) + x_{0}^{2}\\exp(-2\\theta T)\n$$\nNow, we differentiate $F(\\theta)$ with respect to $\\theta$:\n$$\n\\nabla_{\\theta}F(\\theta) = \\frac{d}{d\\theta}\\left(\\frac{\\sigma^2}{2}\\theta^{-1} - \\frac{\\sigma^2}{2}\\theta^{-1}\\exp(-2\\theta T) + x_0^2\\exp(-2\\theta T)\\right)\n$$\nDifferentiating term by term:\n\\begin{align*}\n\\nabla_{\\theta}F(\\theta) = \\frac{\\sigma^2}{2}(-\\theta^{-2}) - \\frac{\\sigma^2}{2}(-\\theta^{-2}\\exp(-2\\theta T) + \\theta^{-1}(-2T)\\exp(-2\\theta T)) + x_0^2(-2T)\\exp(-2\\theta T) \\\\\n= -\\frac{\\sigma^2}{2\\theta^2} + \\frac{\\sigma^2}{2\\theta^2}\\exp(-2\\theta T) + \\frac{\\sigma^2 T}{\\theta}\\exp(-2\\theta T) - 2x_0^2 T \\exp(-2\\theta T)\n\\end{align*}\nRearranging terms to match the previous result:\n$$\n\\nabla_{\\theta}F(\\theta) = -2x_0^2 T \\exp(-2\\theta T) + \\frac{\\sigma^2 T}{\\theta}\\exp(-2\\theta T) + \\frac{\\sigma^2}{2\\theta^2}\\exp(-2\\theta T) - \\frac{\\sigma^2}{2\\theta^2}\n$$\n\n**5. Comparison and Conclusion**\n\nComparing the expression for $\\mathbb{E}[G(\\theta)]$ from Section 3 and $\\nabla_{\\theta}F(\\theta)$ from Section 4, we find they are identical:\n$$\n\\mathbb{E}[G(\\theta)] = \\nabla_{\\theta}\\mathbb{E}[f(X_{T}^{\\theta})]\n$$\nThis demonstrates that the pathwise gradient estimator $G(\\theta) = f'(X_{T}^{\\theta})\\,Y_{T}$ is an unbiased estimator of the true gradient $\\nabla_{\\theta}F(\\theta)$. The validity of interchanging the expectation and differentiation operators, $\\nabla_{\\theta}\\mathbb{E}[\\cdot] = \\mathbb{E}[\\nabla_{\\theta}\\cdot]$, is guaranteed under the problem's conditions by the dominated convergence theorem, due to the smoothness of the SDE's coefficients with respect to the parameter $\\theta$.\n\nThe final answer is the closed-form expression for $\\nabla_{\\theta}F(\\theta)$. It can be written more compactly as:\n$$\n\\nabla_{\\theta}\\mathbb{E}[f(X_{T}^{\\theta})] = -2x_0^2 T \\exp(-2\\theta T) + \\frac{\\sigma^2}{2\\theta^2}\\left[(1+2\\theta T)\\exp(-2\\theta T) - 1\\right]\n$$\nThis is the required analytical expression.",
            "answer": "$$\\boxed{-2x_0^2 T \\exp(-2\\theta T) + \\frac{\\sigma^2}{2\\theta^2} \\left[ (1+2\\theta T)\\exp(-2\\theta T) - 1 \\right]}$$"
        },
        {
            "introduction": "Pathwise estimators are powerful, but it is crucial to understand their limitations. This practice explores a canonical case where the standard pathwise approach fails: calculating the sensitivity (Delta) of a digital option, whose payoff function is discontinuous. You will first analyze why naively differentiating the payoff leads to a biased and computationally useless estimator (). You will then employ the integration-by-parts technique from Malliavin calculus to correctly derive the sensitivity, learning a more robust method for handling such non-smooth problems.",
            "id": "3328492",
            "problem": "Consider the Black–Scholes–Merton (BSM) model under the risk-neutral measure. The underlying asset price $\\{S_{t}\\}_{t \\in [0,T]}$ satisfies the stochastic differential equation $dS_{t} = r S_{t}\\,dt + \\sigma S_{t}\\,dW_{t}$ with $S_{0}  0$, risk-free rate $r \\in \\mathbb{R}$, and volatility $\\sigma  0$, where $\\{W_{t}\\}$ is a standard Brownian motion. Let the maturity be $T  0$ and consider the cash-or-nothing digital call payoff $f(S_{T}) = \\mathbf{1}_{\\{S_{T}  K\\}}$ with strike $K  0$. The risk-neutral price is $V(S_{0}) = \\mathbb{E}\\!\\left[\\exp(-rT)\\,f(S_{T})\\right]$ and the Delta is $\\Delta(S_{0}) = \\frac{\\partial}{\\partial S_{0}} V(S_{0})$.\n\nUsing only fundamental principles of risk-neutral pricing, the explicit strong solution of the BSM stochastic differential equation, and the core definitions of the Malliavin derivative and Skorohod integral in Malliavin calculus (no further shortcut formulas may be assumed), do the following:\n\n- Explain, from first principles, why the pathwise (a.k.a. infinitesimal perturbation analysis) estimator $\\mathbb{E}\\!\\left[\\exp(-rT)\\,\\frac{\\partial}{\\partial S_{0}} f(S_{T})\\right]$ is biased for this discontinuous payoff, whereas the Malliavin calculus estimator obtained via an integration-by-parts argument is unbiased.\n\n- Then compute the Delta $\\Delta(S_{0})$ in closed form by deriving a Malliavin integration-by-parts representation that does not differentiate the discontinuous payoff and reducing the resulting expression to a standard normal expectation.\n\nProvide your final answer as a single closed-form analytic expression in terms of $S_{0}$, $K$, $r$, $\\sigma$, and $T$ using the standard normal density function $\\varphi(\\cdot)$ and, if needed, the standard normal cumulative distribution function $\\Phi(\\cdot)$. No numerical rounding is required, and no units are to be included in the final answer.",
            "solution": "The problem is valid as it is scientifically grounded in the established theories of financial mathematics and stochastic calculus, is well-posed, objective, and self-contained.\n\nThis problem requires a two-part analysis of the Delta of a cash-or-nothing digital call option in the Black-Scholes-Merton (BSM) model. First, we explain the failure of the pathwise derivative estimator for this option's discontinuous payoff. Second, we derive the correct closed-form expression for the Delta using an integration-by-parts technique, which is the foundation of the Malliavin calculus approach for this type of problem.\n\nThe underlying asset price $S_t$ follows a Geometric Brownian Motion under the risk-neutral measure $\\mathbb{Q}$:\n$$dS_{t} = r S_{t}\\,dt + \\sigma S_{t}\\,dW_{t}$$\nThe explicit solution for the asset price at maturity $T$ given an initial price $S_0$ is:\n$$S_{T} = S_{0} \\exp\\left(\\left(r - \\frac{1}{2}\\sigma^{2}\\right)T + \\sigma W_{T}\\right)$$\nwhere $W_T$ is a normally distributed random variable with mean $0$ and variance $T$, i.e., $W_T \\sim \\mathcal{N}(0, T)$.\n\nThe payoff function is that of a cash-or-nothing digital call: $f(S_{T}) = \\mathbf{1}_{\\{S_{T}  K\\}}$, where $\\mathbf{1}_{\\{\\cdot\\}}$ is the indicator function. The price of the option is $V(S_{0}) = \\mathbb{E}_{\\mathbb{Q}}\\!\\left[\\exp(-rT)\\,f(S_{T})\\right]$, and the Delta is defined as $\\Delta(S_{0}) = \\frac{\\partial}{\\partial S_{0}} V(S_{0})$.\n\n**Part 1: Bias of the Pathwise Derivative Estimator**\n\nThe Delta is given by $\\Delta(S_{0}) = \\frac{\\partial}{\\partial S_{0}} \\left( \\exp(-rT) \\mathbb{E}[f(S_T)] \\right)$. Since $\\exp(-rT)$ is a constant with respect to $S_0$, we have:\n$$\\Delta(S_{0}) = \\exp(-rT) \\frac{\\partial}{\\partial S_{0}} \\mathbb{E}[f(S_T)]$$\nThe pathwise derivative estimator, also known as Infinitesimal Perturbation Analysis (IPA), proceeds by interchanging the differentiation and expectation operators. If this interchange were valid, we would have:\n$$\\Delta(S_{0}) \\stackrel{?}{=} \\exp(-rT) \\mathbb{E}\\left[\\frac{\\partial}{\\partial S_{0}} f(S_T)\\right]$$\nUsing the chain rule, the derivative inside the expectation is:\n$$\\frac{\\partial}{\\partial S_{0}} f(S_T) = f'(S_T) \\cdot \\frac{\\partial S_T}{\\partial S_0}$$\nFrom the explicit solution for $S_T$, we compute the second term:\n$$\\frac{\\partial S_T}{\\partial S_0} = \\frac{\\partial}{\\partial S_0} \\left( S_{0} \\exp\\left(\\left(r - \\frac{1}{2}\\sigma^{2}\\right)T + \\sigma W_{T}\\right) \\right) = \\exp\\left(\\left(r - \\frac{1}{2}\\sigma^{2}\\right)T + \\sigma W_{T}\\right) = \\frac{S_T}{S_0}$$\nThe payoff function $f(x) = \\mathbf{1}_{\\{x  K\\}}$ is a Heaviside step function centered at $K$. Its derivative, in the sense of distributions, is the Dirac delta function, $f'(x) = \\delta(x-K)$. Substituting these into the pathwise expression gives:\n$$\\Delta_{\\text{pathwise}} = \\exp(-rT) \\mathbb{E}\\left[\\delta(S_T - K) \\frac{S_T}{S_0}\\right]$$\nThis estimator is fundamentally flawed for two reasons:\n$1$. **Invalid Interchange:** The interchange of a derivative and an expectation requires certain regularity conditions on the integrand, such as those provided by the Dominated Convergence Theorem. The payoff function $f(S_T)$ is discontinuous for any path where $S_T = K$. The function $\\frac{\\partial}{\\partial S_0} f(S_T)$ is a scaled Dirac delta distribution, not a function, and the conditions for interchanging the operators are not met. The interchange is mathematically invalid.\n$2$. **Computational Failure:** In a Monte Carlo simulation, we generate a large number of paths for $S_T$. Since $S_T$ is a continuous random variable, the probability of any single path yielding $S_T = K$ is exactly zero. Therefore, the term $\\delta(S_T - K)$ would evaluate to $0$ for almost every simulated path. The resulting Monte Carlo estimate for Delta would be $0$, which is incorrect. The true Delta is non-zero. This demonstrates the severe bias of the naive pathwise estimator.\n\nThe Malliavin calculus approach circumvents this by using an integration-by-parts formula to transfer the differentiation from the discontinuous payoff function onto a smooth component of the expectation, resulting in an unbiased estimator.\n\n**Part 2: Derivation of Delta using Malliavin Integration-by-Parts**\n\nWe will derive the closed-form expression for Delta by avoiding differentiation of the indicator function. The core idea is to express the expectation as an explicit integral and use standard integration by parts.\n\nLet $Z = W_T / \\sqrt{T}$, so $Z \\sim \\mathcal{N}(0, 1)$ under $\\mathbb{Q}$. We can write $S_T$ as a function of $S_0$ and the random variable $z$:\n$$S_{T}(z) = S_{0} \\exp\\left(\\left(r - \\frac{1}{2}\\sigma^{2}\\right)T + \\sigma\\sqrt{T} z\\right)$$\nThe expectation becomes an integral with respect to the standard normal probability density function, $\\varphi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2)$:\n$$\\mathbb{E}[f(S_T)] = \\int_{-\\infty}^{\\infty} f(S_T(z)) \\varphi(z) dz$$\nNow, we can compute the derivative of the expectation with respect to $S_0$. Since the integrand is sufficiently regular with respect to $S_0$, we can differentiate under the integral sign:\n$$\\frac{\\partial}{\\partial S_{0}} \\mathbb{E}[f(S_T)] = \\int_{-\\infty}^{\\infty} \\frac{\\partial}{\\partial S_{0}} \\left[ f(S_T(z)) \\right] \\varphi(z) dz$$\nApplying the chain rule:\n$$\\frac{\\partial}{\\partial S_0} f(S_T(z)) = f'(S_T(z)) \\frac{\\partial S_T(z)}{\\partial S_0} = f'(S_T(z)) \\frac{S_T(z)}{S_0}$$\nThis brings us back to the problematic $f'$ term:\n$$\\frac{\\partial}{\\partial S_{0}} \\mathbb{E}[f(S_T)] = \\frac{1}{S_0} \\int_{-\\infty}^{\\infty} f'(S_T(z)) S_T(z) \\varphi(z) dz$$\nThis is where the integration-by-parts argument, which is a specific instance of the Malliavin calculus principle, is applied. We relate the derivative with respect to the argument of $f$ to the derivative with respect to $z$:\n$$\\frac{df(S_T(z))}{dz} = f'(S_T(z)) \\frac{d S_T(z)}{dz} = f'(S_T(z)) \\left( S_0 \\exp\\left(\\dots\\right) \\cdot \\sigma\\sqrt{T} \\right) = f'(S_T(z)) S_T(z) \\sigma\\sqrt{T}$$\nWe can thus express $f'(S_T(z))$ without the prime:\n$$f'(S_T(z)) S_T(z) = \\frac{1}{\\sigma\\sqrt{T}} \\frac{df(S_T(z))}{dz}$$\nSubstituting this into the integral for the sensitivity:\n$$\\frac{\\partial}{\\partial S_0} \\mathbb{E}[f(S_T)] = \\frac{1}{S_0 \\sigma \\sqrt{T}} \\int_{-\\infty}^{\\infty} \\frac{df(S_T(z))}{dz} \\varphi(z) dz$$\nNow we perform standard integration by parts on the integral with respect to $z$. Let $u(z) = \\varphi(z)$ and $dv = \\frac{df(S_T(z))}{dz} dz$. Then $du = \\varphi'(z) dz$ and $v = f(S_T(z))$.\n$$ \\int_{-\\infty}^{\\infty} u dv = \\left[ uv \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} v du = \\left[ \\varphi(z) f(S_T(z)) \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} f(S_T(z)) \\varphi'(z) dz $$\nThe boundary term vanishes because $\\varphi(z) \\to 0$ as $z \\to \\pm\\infty$, and $f(S_T(z))$ is bounded (by $0$ and $1$). For the remaining integral, we use the identity $\\varphi'(z) = -z\\varphi(z)$:\n$$ - \\int_{-\\infty}^{\\infty} f(S_T(z)) (-z\\varphi(z)) dz = \\int_{-\\infty}^{\\infty} f(S_T(z)) z \\varphi(z) dz = \\mathbb{E}[f(S_T) Z] $$\nCombining our results, we have the integration-by-parts formula for the derivative:\n$$\\frac{\\partial}{\\partial S_0} \\mathbb{E}[f(S_T)] = \\frac{1}{S_0 \\sigma \\sqrt{T}} \\mathbb{E}[f(S_T) Z] = \\frac{1}{S_0 \\sigma T} \\mathbb{E}[f(S_T) W_T]$$\nThis gives us a representation for Delta that does not involve differentiating the payoff function:\n$$\\Delta(S_0) = \\exp(-rT) \\frac{\\mathbb{E}[f(S_T) W_T]}{S_0 \\sigma T}$$\nThis representation is unbiased and suitable for Monte Carlo estimation.\n\nFinally, we compute the closed-form solution by evaluating the expectation:\n$$\\mathbb{E}[f(S_T) Z] = \\mathbb{E}[\\mathbf{1}_{\\{S_T  K\\}} Z] = \\int_{-\\infty}^{\\infty} \\mathbf{1}_{\\{S_T(z)  K\\}} z \\varphi(z) dz$$\nThe condition $S_T(z)  K$ defines the integration region for $z$:\n$$S_0 \\exp\\left(\\left(r - \\frac{\\sigma^2}{2}\\right)T + \\sigma\\sqrt{T} z\\right)  K$$\n$$\\ln(S_0) + \\left(r - \\frac{\\sigma^2}{2}\\right)T + \\sigma\\sqrt{T} z  \\ln(K)$$\n$$\\sigma\\sqrt{T} z  \\ln(K/S_0) - \\left(r - \\frac{\\sigma^2}{2}\\right)T$$\n$$z  \\frac{\\ln(K/S_0) - (r - \\frac{\\sigma^2}{2})T}{\\sigma\\sqrt{T}} = - \\frac{\\ln(S_0/K) + (r - \\frac{\\sigma^2}{2})T}{\\sigma\\sqrt{T}}$$\nLet's define the standard BSM term $d_2$:\n$$d_2 = \\frac{\\ln(S_0/K) + (r - \\frac{\\sigma^2}{2})T}{\\sigma\\sqrt{T}}$$\nThe condition becomes $z  -d_2$. The expectation integral is thus:\n$$\\mathbb{E}[f(S_T) Z] = \\int_{-d_2}^{\\infty} z \\varphi(z) dz = \\int_{-d_2}^{\\infty} z \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2) dz$$\nThis integral can be solved directly:\n$$\\int_{-d_2}^{\\infty} z \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2) dz = -\\frac{1}{\\sqrt{2\\pi}} \\left[ \\exp(-z^2/2) \\right]_{-d_2}^{\\infty} = -\\frac{1}{\\sqrt{2\\pi}} (0 - \\exp(-(-d_2)^2/2)) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-d_2^2/2) = \\varphi(d_2)$$\nSubstituting this result back into our expression for Delta:\n$$\\Delta(S_0) = \\exp(-rT) \\frac{1}{S_0 \\sigma \\sqrt{T}} \\mathbb{E}[f(S_T) Z] = \\frac{\\exp(-rT) \\varphi(d_2)}{S_0 \\sigma \\sqrt{T}}$$\n\nThis is the final closed-form expression for the Delta of a cash-or-nothing digital call option. It correctly depends on the probability density at the decision boundary, which is what the $\\varphi(d_2)$ term represents.",
            "answer": "$$\\boxed{\\frac{\\exp(-rT)\\,\\varphi\\left(\\frac{\\ln(S_{0}/K) + (r - \\frac{1}{2}\\sigma^{2})T}{\\sigma\\sqrt{T}}\\right)}{S_{0}\\sigma\\sqrt{T}}}$$"
        },
        {
            "introduction": "This final exercise bridges theory with practical application by tasking you to build a complete Monte Carlo simulation for a steady-state system. You will analyze a regenerative process, where the goal is to estimate the sensitivity of a long-run average performance metric, a common task in operations research and engineering. The problem () requires you to apply Infinitesimal Perturbation Analysis (IPA) to both the cycle reward and the random cycle time, and then correctly combine these estimators using the renewal-reward theorem to finally implement a working simulation program.",
            "id": "3328523",
            "problem": "Consider a regenerative process defined as follows. Each regeneration cycle starts at time $t=0$ with a state $X(t;\\theta)$ that evolves continuously within the cycle according to the linear ordinary differential equation $dX/dt=-a\\,X(t;\\theta)+b(\\theta)$ with initial condition $X(0;\\theta)=0$. The cycle ends at a random time $C(\\theta)$, after which the process regenerates and restarts from the same initial condition. The cycle length $C(\\theta)$ is sampled by inversion from a Uniform random variable $U\\sim\\text{Uniform}(0,1)$ via $C(\\theta)=-\\ln(U)/\\lambda(\\theta)$, where $\\lambda(\\theta)0$. The cycle reward is defined by $R(\\theta)=\\int_{0}^{C(\\theta)}X(t;\\theta)\\,dt$. The long-run average performance per unit time is $J(\\theta)=\\mathbb{E}[R(\\theta)]/\\mathbb{E}[C(\\theta)]$. The parameter-dependent functions and constants are given by $\\lambda(\\theta)=\\lambda_0+\\theta$ and $b(\\theta)=b_0+\\beta\\,\\theta$, with fixed positive constants $a$, $\\lambda_0$, $b_0$, and $\\beta$. Assume all parameters and $\\theta$ are chosen so that $\\lambda(\\theta)0$.\n\nTasks:\n- Starting from the definitions above and using Infinitesimal Perturbation Analysis (IPA), derive the pathwise first derivative $dC(\\theta)/d\\theta$ by differentiating the inverse-transform sampling map of $C(\\theta)$ with respect to $\\theta$ along a fixed sample $U$. Next, derive the pathwise first derivative $dR(\\theta)/d\\theta$ by differentiating the integral of the state trajectory $X(t;\\theta)$ with respect to $\\theta$ on the same sample path, explicitly accounting for both the parameterized dynamics of $X(t;\\theta)$ and the parameterized terminal time $C(\\theta)$.\n- Using the Renewal-Reward framework, express the derivative $dJ(\\theta)/d\\theta$ in terms of expectations of cyclewise pathwise derivatives. Then, design a consistent Monte Carlo estimator for $dJ(\\theta)/d\\theta$ based on $n$ independent and identically distributed cycles generated by independent uniforms $U_1,\\dots,U_n$.\n- Implement a program that, for each specified value of $\\theta$, generates $n$ independent regeneration cycles, computes the cyclewise quantities $C(\\theta)$, $R(\\theta)$, $dC(\\theta)/d\\theta$, and $dR(\\theta)/d\\theta$ on each sample path, and outputs a single Monte Carlo estimate of $dJ(\\theta)/d\\theta$ as prescribed by your derived estimator.\n\nParameterization, simulation protocol, and test suite:\n- Use the constants $a=1.7$, $\\lambda_0=1.5$, $b_0=0.8$, and $\\beta=0.5$.\n- For each test case, simulate $n=400000$ independent cycles using the inverse-transform method for $C(\\theta)$ as defined above. Use the same $n$ for all test cases.\n- To ensure reproducibility, for the $k$-th test case (with zero-based index $k\\in\\{0,1,2\\}$), initialize an independent pseudorandom number generator with seed $s_k=s_0+1000\\,k$, where $s_0=24681357$, and then generate the $n$ uniforms $U_1,\\dots,U_n$ for that test case from that generator.\n- Test suite for $\\theta$: evaluate your estimator at the three values $\\theta\\in\\{-1.0,\\,0.0,\\,0.8\\}$.\n- The required final output of your program is a single line containing a list of three floating-point results corresponding to the three test cases in the specified order, each rounded to six decimal places, formatted exactly as a comma-separated list enclosed in square brackets. For example, the format should be like $[x_1,x_2,x_3]$ where each $x_i$ is a floating-point number rounded to six decimals.\n\nNotes:\n- There are no physical units in this problem.\n- All angles, if any, are to be interpreted in radians; however, no angles appear in this setup.\n- The required outputs are real numbers (floating-point). The final output format must be exactly one line as specified above, containing three comma-separated values enclosed in square brackets.\n- The provided test suite probes a typical case, a case with relatively larger expected cycle lengths (smaller $\\lambda(\\theta)$), and a case with relatively smaller expected cycle lengths (larger $\\lambda(\\theta)$), to stress different variance regimes of the estimator.",
            "solution": "The problem statement has been validated and is deemed sound, well-posed, and complete. It is a standard problem in stochastic simulation and sensitivity analysis, grounded in the established theories of regenerative processes and infinitesimal perturbation analysis (IPA). All provided parameters, functions, and conditions are consistent and sufficient for deriving a unique and meaningful solution.\n\nThe objective is to derive a pathwise derivative estimator for the long-run average performance $J(\\theta)$ of a regenerative process and implement it as a Monte Carlo simulation. The derivation proceeds in several steps: solving the state dynamics, deriving the pathwise derivatives of the cycle length $C(\\theta)$ and cycle reward $R(\\theta)$, formulating the derivative of the performance metric $dJ(\\theta)/d\\theta$, and finally constructing a consistent Monte Carlo estimator.\n\nFirst, we solve for the state trajectory $X(t;\\theta)$ within a cycle. The state evolves according to the linear first-order ordinary differential equation (ODE):\n$$\n\\frac{dX}{dt} = -a X(t;\\theta) + b(\\theta)\n$$\nwith the initial condition $X(0;\\theta)=0$. This can be rewritten as $\\frac{dX}{dt} + a X(t;\\theta) = b(\\theta)$. The integrating factor is $e^{at}$. Multiplying by the integrating factor yields $\\frac{d}{dt}(e^{at}X(t;\\theta)) = b(\\theta)e^{at}$. Integrating from $0$ to $t$ gives:\n$$\ne^{at}X(t;\\theta) - X(0;\\theta) = \\int_0^t b(\\theta)e^{a\\tau} d\\tau = \\frac{b(\\theta)}{a}(e^{at}-1)\n$$\nUsing the initial condition $X(0;\\theta)=0$, the solution for the state is:\n$$\nX(t;\\theta) = \\frac{b(\\theta)}{a} (1 - e^{-at})\n$$\nwhere $b(\\theta) = b_0 + \\beta\\theta$ and $a$ is a positive constant.\n\nNext, we derive the pathwise first derivative of the cycle length $C(\\theta)$ with respect to $\\theta$. The cycle length is generated via the inverse-transform method from a uniform random variable $U \\sim \\text{Uniform}(0,1)$ as $C(\\theta)=-\\ln(U)/\\lambda(\\theta)$, where $\\lambda(\\theta)>0$. For a fixed sample path (i.e., fixed $U$), we can differentiate $C(\\theta)$ with respect to $\\theta$:\n$$\n\\frac{dC(\\theta)}{d\\theta} = \\frac{d}{d\\theta} \\left( -\\frac{\\ln(U)}{\\lambda(\\theta)} \\right) = -\\ln(U) \\left( -\\frac{1}{\\lambda(\\theta)^2} \\frac{d\\lambda(\\theta)}{d\\theta} \\right)\n$$\nGiven $\\lambda(\\theta) = \\lambda_0 + \\theta$, we have $\\frac{d\\lambda(\\theta)}{d\\theta} = 1$. Substituting this and the relation $-\\ln(U) = C(\\theta)\\lambda(\\theta)$ into the derivative expression gives:\n$$\n\\frac{dC(\\theta)}{d\\theta} = \\frac{\\ln(U)}{\\lambda(\\theta)^2} = \\frac{-C(\\theta)\\lambda(\\theta)}{\\lambda(\\theta)^2} = -\\frac{C(\\theta)}{\\lambda(\\theta)}\n$$\nThis is the pathwise derivative of the cycle length.\n\nWe then derive the pathwise first derivative of the cycle reward $R(\\theta)=\\int_{0}^{C(\\theta)}X(t;\\theta)\\,dt$. We apply the Leibniz integral rule for differentiating an integral with a variable limit:\n$$\n\\frac{dR(\\theta)}{d\\theta} = X(C(\\theta);\\theta) \\frac{dC(\\theta)}{d\\theta} + \\int_{0}^{C(\\theta)} \\frac{\\partial X(t;\\theta)}{\\partial \\theta} dt\n$$\nWe have already found $\\frac{dC(\\theta)}{d\\theta}$. The two new terms are $X(C(\\theta);\\theta)$ and the integral of the partial derivative $\\frac{\\partial X(t;\\theta)}{\\partial \\theta}$. The state at the end of the cycle is:\n$$\nX(C(\\theta);\\theta) = \\frac{b(\\theta)}{a} (1 - e^{-aC(\\theta)})\n$$\nThe partial derivative of the state with respect to $\\theta$ is:\n$$\n\\frac{\\partial X(t;\\theta)}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta} \\left[ \\frac{b_0+\\beta\\theta}{a} (1 - e^{-at}) \\right] = \\frac{\\beta}{a}(1 - e^{-at})\n$$\nThe integral of this partial derivative is:\n$$\n\\int_{0}^{C(\\theta)} \\frac{\\partial X(t;\\theta)}{\\partial \\theta} dt = \\int_{0}^{C(\\theta)} \\frac{\\beta}{a}(1 - e^{-at}) dt = \\frac{\\beta}{a} \\left[ t + \\frac{e^{-at}}{a} \\right]_{0}^{C(\\theta)} = \\frac{\\beta}{a} \\left( C(\\theta) + \\frac{e^{-aC(\\theta)} - 1}{a} \\right)\n$$\nFor computational purposes, we can express the analytical form of $R(\\theta)$:\n$$\nR(\\theta) = \\int_{0}^{C(\\theta)} \\frac{b(\\theta)}{a} (1 - e^{-at}) dt = \\frac{b(\\theta)}{a} \\left( C(\\theta) + \\frac{e^{-aC(\\theta)} - 1}{a} \\right)\n$$\nObserving the expressions, the integral term can be simplified:\n$$\n\\int_{0}^{C(\\theta)} \\frac{\\partial X(t;\\theta)}{\\partial \\theta} dt = \\frac{\\beta}{b(\\theta)} R(\\theta)\n$$\nCombining all parts, the pathwise derivative of the cycle reward is:\n$$\n\\frac{dR(\\theta)}{d\\theta} = X(C(\\theta);\\theta) \\left( -\\frac{C(\\theta)}{\\lambda(\\theta)} \\right) + \\frac{\\beta}{b(\\theta)} R(\\theta)\n$$\n\nThe long-run average performance is $J(\\theta) = \\frac{\\mathbb{E}[R(\\theta)]}{\\mathbb{E}[C(\\theta)]}$. Using the quotient rule for differentiation, we get:\n$$\n\\frac{dJ(\\theta)}{d\\theta} = \\frac{\\mathbb{E}[C(\\theta)] \\frac{d}{d\\theta}\\mathbb{E}[R(\\theta)] - \\mathbb{E}[R(\\theta)] \\frac{d}{d\\theta}\\mathbb{E}[C(\\theta)]}{(\\mathbb{E}[C(\\theta)])^2}\n$$\nUnder the regularity conditions that permit IPA, we can interchange differentiation and expectation: $\\frac{d}{d\\theta}\\mathbb{E}[Y(\\theta)] = \\mathbb{E}[\\frac{dY(\\theta)}{d\\theta}]$. Applying this, we have:\n$$\n\\frac{dJ(\\theta)}{d\\theta} = \\frac{\\mathbb{E}[C(\\theta)] \\mathbb{E}\\left[\\frac{dR(\\theta)}{d\\theta}\\right] - \\mathbb{E}[R(\\theta)] \\mathbb{E}\\left[\\frac{dC(\\theta)}{d\\theta}\\right]}{(\\mathbb{E}[C(\\theta)])^2}\n$$\n\nFinally, we construct a consistent Monte Carlo estimator for $\\frac{dJ(\\theta)}{d\\theta}$ based on $n$ independent and identically distributed (i.i.d.) cycles. Let the $i$-th cycle be generated from an independent sample $U_i \\sim \\text{Uniform}(0,1)$, for $i=1,\\dots,n$. For each cycle, we compute the sample values: $C_i(\\theta)$, $R_i(\\theta)$, $(\\frac{dC(\\theta)}{d\\theta})_i$, and $(\\frac{dR(\\theta)}{d\\theta})_i$. By the Law of Large Numbers, a consistent estimator for an expectation $\\mathbb{E}[Y]$ is the sample mean $\\hat{E}[Y] = \\frac{1}{n} \\sum_{i=1}^n Y_i$. Substituting these sample means into the expression for $\\frac{dJ(\\theta)}{d\\theta}$:\n$$\n\\widehat{\\frac{dJ(\\theta)}{d\\theta}} = \\frac{\\left(\\frac{1}{n}\\sum_{i=1}^n C_i\\right) \\left(\\frac{1}{n}\\sum_{i=1}^n \\left(\\frac{dR}{d\\theta}\\right)_i\\right) - \\left(\\frac{1}{n}\\sum_{i=1}^n R_i\\right) \\left(\\frac{1}{n}\\sum_{i=1}^n \\left(\\frac{dC}{d\\theta}\\right)_i\\right)}{\\left(\\frac{1}{n}\\sum_{i=1}^n C_i\\right)^2}\n$$\nThe factors of $\\frac{1}{n}$ cancel out, yielding the final form of the estimator, which is computationally more stable as a ratio of sums:\n$$\n\\widehat{\\frac{dJ(\\theta)}{d\\theta}} = \\frac{\\left(\\sum_{i=1}^n C_i\\right) \\left(\\sum_{i=1}^n \\left(\\frac{dR}{d\\theta}\\right)_i\\right) - \\left(\\sum_{i=1}^n R_i\\right) \\left(\\sum_{i=1}^n \\left(\\frac{dC}{d\\theta}\\right)_i\\right)}{\\left(\\sum_{i=1}^n C_i\\right)^2}\n$$\nThis estimator will be implemented by generating $n$ cycles, calculating the required quantities for each cycle, aggregating their sums, and applying this final formula.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating the derivative of a regenerative process performance metric.\n    The function implements the derived Infinitesimal Perturbation Analysis (IPA) estimator.\n    \"\"\"\n    \n    # --- Define constants and simulation parameters ---\n    a = 1.7\n    lambda_0 = 1.5\n    b_0 = 0.8\n    beta = 0.5\n    \n    n = 400000\n    s_0 = 24681357\n\n    # --- Test suite for theta ---\n    test_cases = [\n        {'theta': -1.0, 'seed': s_0 + 1000 * 0},\n        {'theta': 0.0,  'seed': s_0 + 1000 * 1},\n        {'theta': 0.8,  'seed': s_0 + 1000 * 2},\n    ]\n\n    results = []\n    for case in test_cases:\n        theta = case['theta']\n        seed = case['seed']\n        \n        # Initialize a random number generator with the specified seed for reproducibility\n        rng = np.random.default_rng(seed)\n        \n        # --- Generate n uniform random numbers ---\n        # Generate U from (0, 1). Using 1 - U' where U' is from [0, 1) to avoid log(0).\n        uniform_samples = rng.uniform(low=0.0, high=1.0, size=n)\n        \n        # --- Parameter-dependent function values ---\n        lambda_theta = lambda_0 + theta\n        b_theta = b_0 + beta * theta\n        \n        # --- Vectorized computation for n cycles ---\n        \n        # C(theta): Cycle lengths\n        # C(theta) = -ln(U) / lambda(theta)\n        C = -np.log(uniform_samples) / lambda_theta\n        \n        # R(theta): Cycle rewards\n        # R(theta) = (b(theta)/a) * (C(theta) + (exp(-a*C(theta)) - 1)/a)\n        R = (b_theta / a) * (C + (np.exp(-a * C) - 1) / a)\n        \n        # dC(theta)/d(theta): Pathwise derivative of cycle length\n        # dC/d(theta) = -C(theta) / lambda(theta)\n        dC_dtheta = -C / lambda_theta\n        \n        # dR(theta)/d(theta): Pathwise derivative of cycle reward\n        # This uses the simplified form derived in the solution:\n        # dR/d(theta) = X(C(theta); theta) * dC/d(theta) + (beta / b(theta)) * R(theta)\n        # where X(t; theta) = (b(theta)/a) * (1 - exp(-a*t))\n        \n        # State at the end of the cycle, X(C(theta); theta)\n        X_at_C = (b_theta / a) * (1 - np.exp(-a * C))\n        \n        dR_dtheta = X_at_C * dC_dtheta + (beta / b_theta) * R\n        \n        # --- Aggregate sums for the estimator formula ---\n        S_C = np.sum(C)\n        S_R = np.sum(R)\n        S_dC = np.sum(dC_dtheta)\n        S_dR = np.sum(dR_dtheta)\n        \n        # --- Compute the final derivative estimate ---\n        # Estimator: (S_C * S_dR - S_R * S_dC) / (S_C^2)\n        if S_C == 0:\n            # This is highly unlikely with n  0, but good practice\n            dJ_dtheta_hat = 0.0\n        else:\n            dJ_dtheta_hat = (S_C * S_dR - S_R * S_dC) / (S_C**2)\n            \n        results.append(dJ_dtheta_hat)\n\n    # --- Format and print the final output ---\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}