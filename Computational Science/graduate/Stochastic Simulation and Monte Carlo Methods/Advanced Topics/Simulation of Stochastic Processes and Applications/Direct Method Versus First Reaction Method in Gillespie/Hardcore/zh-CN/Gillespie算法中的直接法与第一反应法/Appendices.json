{
    "hands_on_practices": [
        {
            "introduction": "在我们深入探讨 Gillespie 算法的具体实现之前，必须先牢固掌握其核心的数学构件：反应倾向（propensity）。本练习将引导你从第一性原理出发，为一个给定的化学反应网络计算其在特定状态下的各个反应倾向值 。通过这个基础计算，你将能够清晰地看到反应倾向是如何根据系统中反应物分子的不同组合方式来定义的，这是将宏观动力学与微观随机事件精确联系起来的关键一步。",
            "id": "3302951",
            "problem": "考虑一个由化学主方程建模的充分混合的等温系统，该系统将通过随机模拟算法 (SSA) 进行模拟。系统中有两种物种，$A$ 和 $B$，在时间 $t_{0}$ 时的状态向量为 $x(t_{0}) = (X_{A}, X_{B}) = (7, 4)$。反应网络如下：\n- $R_{1}: A + A \\rightarrow B$，化学计量变化向量为 $\\nu_{1} = (-2, +1)$，随机速率常数为 $c_{1} = 0.5\\,\\text{s}^{-1}$。\n- $R_{2}: A + B \\rightarrow 2A$，化学计量变化向量为 $\\nu_{2} = (+1, -1)$，随机速率常数为 $c_{2} = 0.2\\,\\text{s}^{-1}$。\n- $R_{3}: B \\rightarrow A$，化学计量变化向量为 $\\nu_{3} = (+1, -1)$，随机速率常数为 $c_{3} = 3\\,\\text{s}^{-1}$。\n- $R_{4}: A \\rightarrow \\varnothing$，化学计量变化向量为 $\\nu_{4} = (-1, 0)$，随机速率常数为 $c_{4} = 1\\,\\text{s}^{-1}$。\n\n在化学主方程框架下，基于与离散质量作用动力学一致的第一性原理，通过枚举在状态 $x(t_{0})$ 中存在的不同反应物组合的数量，来确定所有反应的倾向函数 $a_{\\mu}(x(t_{0}))$，然后计算总倾向 $a_{0}(x(t_{0})) = \\sum_{\\mu} a_{\\mu}(x(t_{0}))$。请以 $\\text{s}^{-1}$ 为单位，将单个数值 $a_{0}(x(t_{0}))$ 作为最终答案。给出确切值，不要四舍五入。",
            "solution": "该问题要求计算在特定状态 $x(t_{0})$ 下，给定化学反应网络的总倾向 $a_{0}(x(t_{0}))$。此计算需基于第一性原理，与化学主方程 (CME) 所描述的系统的离散和随机性质保持一致。\n\n对于反应 $R_{\\mu}$，其倾向函数 $a_{\\mu}(x)$ 的定义为：在时间 $t$ 系统处于状态 $x$ 的条件下，$a_{\\mu}(x) dt$ 表示在无穷小时间间隔 $[t, t+dt)$ 内发生一次反应 $R_{\\mu}$ 的概率。对于充分混合的等温系统中的质量作用动力学，倾向函数是随机速率常数 $c_{\\mu}$ 与当前状态 $x$ 下可用的反应物分子的不同组合数 $h_{\\mu}(x)$ 的乘积。其通用形式为：\n$$a_{\\mu}(x) = c_{\\mu} h_{\\mu}(x)$$\n系统在初始时间 $t_{0}$ 的状态由分子数向量 $x(t_{0}) = (X_{A}, X_{B}) = (7, 4)$ 给出，其中 $X_{A}$ 是物种 $A$ 的分子数，$X_{B}$ 是物种 $B$ 的分子数。我们将计算在此状态下四个指定反应中每一个的倾向。\n\n**反应 $R_{1}: A + A \\rightarrow B$**\n这是一个双分子反应，涉及两个相同的物种 $A$ 分子。反应物的不同组合数 $h_{1}(x)$ 是通过计算从总共 $X_{A}$ 个分子中选择 $2$ 个 $A$ 分子的方式数得到的。这由二项式系数给出：\n$$h_{1}(x) = \\binom{X_{A}}{2} = \\frac{X_{A}(X_{A}-1)}{2!}$$\n因此，反应 $R_{1}$ 的倾向为：\n$$a_{1}(x) = c_{1} h_{1}(x) = c_{1} \\frac{X_{A}(X_{A}-1)}{2}$$\n在给定状态 $X_{A} = 7$ 和速率常数 $c_{1} = 0.5\\,\\text{s}^{-1}$ 的条件下，倾向为：\n$$a_{1}(x(t_{0})) = (0.5) \\cdot \\frac{7(7-1)}{2} = (0.5) \\cdot \\frac{7 \\cdot 6}{2} = (0.5) \\cdot 21 = 10.5\\,\\text{s}^{-1}$$\n\n**反应 $R_{2}: A + B \\rightarrow 2A$**\n这是一个双分子反应，涉及两种不同的反应物种 $A$ 和 $B$。反应物的不同组合数 $h_{2}(x)$ 是从可用的 $X_{A}$ 个分子中选择一个 $A$ 分子，并从可用的 $X_{B}$ 个分子中选择一个 $B$ 分子的方式数。这即是它们数量的乘积：\n$$h_{2}(x) = X_{A} \\cdot X_{B}$$\n反应 $R_{2}$ 的倾向为：\n$$a_{2}(x) = c_{2} h_{2}(x) = c_{2} X_{A} X_{B}$$\n在 $X_{A} = 7$, $X_{B} = 4$ 和 $c_{2} = 0.2\\,\\text{s}^{-1}$ 的条件下，倾向为：\n$$a_{2}(x(t_{0})) = (0.2) \\cdot (7 \\cdot 4) = (0.2) \\cdot 28 = 5.6\\,\\text{s}^{-1}$$\n\n**反应 $R_{3}: B \\rightarrow A$**\n这是一个单分子反应，其中单个物种 $B$ 的分子是反应物。反应物“组合”数 $h_{3}(x)$ 就是物种 $B$ 的分子总数。\n$$h_{3}(x) = X_{B}$$\n反应 $R_{3}$ 的倾向为：\n$$a_{3}(x) = c_{3} h_{3}(x) = c_{3} X_{B}$$\n在 $X_{B} = 4$ 和 $c_{3} = 3\\,\\text{s}^{-1}$ 的条件下，倾向为：\n$$a_{3}(x(t_{0})) = (3) \\cdot 4 = 12\\,\\text{s}^{-1}$$\n\n**反应 $R_{4}: A \\rightarrow \\varnothing$**\n这是一个物种 $A$ 的单分子衰变反应。反应物分子数即为组合数 $h_{4}(x)$。\n$$h_{4}(x) = X_{A}$$\n反应 $R_{4}$ 的倾向为：\n$$a_{4}(x) = c_{4} h_{4}(x) = c_{4} X_{A}$$\n在 $X_{A} = 7$ 和 $c_{4} = 1\\,\\text{s}^{-1}$ 的条件下，倾向为：\n$$a_{4}(x(t_{0})) = (1) \\cdot 7 = 7\\,\\text{s}^{-1}$$\n\n**总倾向**\n总倾向 $a_{0}(x(t_{0}))$ 是所有单个反应倾向的总和。在 Gillespie 算法中，它代表了指数分布的速率参数，从该分布中抽取到下一个反应事件发生的时间。\n$$a_{0}(x(t_{0})) = \\sum_{\\mu=1}^{4} a_{\\mu}(x(t_{0})) = a_{1}(x(t_{0})) + a_{2}(x(t_{0})) + a_{3}(x(t_{0})) + a_{4}(x(t_{0}))$$\n代入计算出的值：\n$$a_{0}(x(t_{0})) = 10.5 + 5.6 + 12 + 7$$\n$$a_{0}(x(t_{0})) = 16.1 + 12 + 7$$\n$$a_{0}(x(t_{0})) = 28.1 + 7$$\n$$a_{0}(x(t_{0})) = 35.1\\,\\text{s}^{-1}$$\n在给定状态下，总倾向的确切值为 $35.1\\,\\text{s}^{-1}$。",
            "answer": "$$\\boxed{35.1}$$"
        },
        {
            "introduction": "在计算出所有反应的倾向后，下一步便是模拟随机过程中的“何时”发生下一个反应。本练习将让你亲手实现并验证直接法（DM）和第一反应法（FRM）在采样等待时间 $\\tau$ 方面的表现 。你将通过编写代码来生成大量的等待时间样本，并运用经典的 Kolmogorov-Smirnov (KS) 拟合优度检验，来从统计上判断这些样本是否真正服从由总倾向 $a_0$ 决定的理论指数分布。这个过程不仅能让你深刻理解两种方法的内在联系与区别，更是对随机模拟算法进行验证的基本功。",
            "id": "3302917",
            "problem": "考虑一个代表随机化学动力学的连续时间马尔可夫跳跃过程的固定状态，其反应通道由 $k \\in \\{1,\\dots,K\\}$ 索引。每个反应通道 $k$ 都有一个在固定状态下为常数的倾向函数 $a_k \\ge 0$，总倾向为 $a_0 = \\sum_{k=1}^{K} a_k$。在固定状态下，到下一个反应事件的等待时间是一个随机变量 $\\tau \\ge 0$。您将实现并比较用于采样 $\\tau$ 的直接法 (DM) 和第一反应法 (FRM)，然后使用柯尔莫哥洛夫-斯米尔诺夫 (KS) 统计量设计一个拟合优度检验，以验证来自 DM 或 FRM 的经验等待时间遵循累积分布函数 $F(t) = 1 - e^{-a_0 t}$（对于 $t \\ge 0$）。\n\n从适用于连续时间马尔可夫过程和随机模拟的基本原理出发，使用关于倾向和事件时间分布的公认事实，但除了定义 KS 检验的原假设所需的公式外，不要假设任何捷径公式。柯尔莫哥洛夫-斯米尔诺夫统计量应应用于通过在具有指定倾向的固定状态下使用 DM 或 FRM 模拟等待时间所获得的 $\\tau$ 的经验样本。\n\n您的程序必须：\n- 实现使用总倾向为 $a_0$ 的直接法 (DM) 和倾向为 $(a_1,\\dots,a_K)$ 的第一反应法 (FRM) 对 $\\tau$ 进行采样。\n- 对于每个测试用例，使用 DM 或 FRM 生成一个独立的等待时间样本 $\\{\\tau_i\\}_{i=1}^{n}$，根据理论累积分布函数 $F(t) = 1 - e^{-a_0^{\\mathrm{test}} t}$ 计算柯尔莫哥洛夫-斯米尔诺夫统计量，其中 $a_0^{\\mathrm{test}}$ 是真实的 $a_0$ 或指定的备择值。计算 KS 检验对应的 p 值，并在给定的显著性水平 $\\alpha$ 下做出决策。\n- 为每个测试用例返回一个布尔值：如果 KS 检验在指定的 $\\alpha$ 水平下未能拒绝原假设（即 p 值大于或等于 $\\alpha$），则返回 $\\mathrm{True}$，否则返回 $\\mathrm{False}$。\n- 所有等待时间使用秒作为时间单位，但最终输出应为布尔值，因此无单位。\n- 通过为每个测试用例使用固定的随机种子来确保可复现性。\n\n测试套件：\n- 案例 1（正常路径，DM）：倾向 $(a_1,a_2,a_3) = (0.5, 0.7, 2.3)$，因此 $a_0 = 3.5$；样本大小 $n = 300$；显著性水平 $\\alpha = 0.001$；使用 $a_0^{\\mathrm{test}} = a_0$；随机种子 $12345$。\n- 案例 2（正常路径，FRM）：倾向 $(a_1,a_2,a_3) = (0.5, 0.7, 2.3)$，因此 $a_0 = 3.5$；样本大小 $n = 300$；显著性水平 $\\alpha = 0.001$；使用 $a_0^{\\mathrm{test}} = a_0$；随机种子 $54321$。\n- 案例 3（错误设定边缘案例，FRM）：倾向 $(a_1,a_2,a_3) = (0.5, 0.7, 2.3)$，因此 $a_0 = 3.5$；样本大小 $n = 300$；显著性水平 $\\alpha = 0.05$；使用 $a_0^{\\mathrm{test}} = 0.5 a_0$；随机种子 $999$。\n- 案例 4（小倾向边界条件，DM）：倾向 $(a_1,a_2) = (0.001, 0.002)$，因此 $a_0 = 0.003$；样本大小 $n = 2000$；显著性水平 $\\alpha = 0.001$；使用 $a_0^{\\mathrm{test}} = a_0$；随机种子 $2023$。\n- 案例 5（零倾向边缘案例，FRM）：倾向 $(a_1,a_2) = (0.0, 1.5)$，因此 $a_0 = 1.5$；样本大小 $n = 300$；显著性水平 $\\alpha = 0.001$；使用 $a_0^{\\mathrm{test}} = a_0$；随机种子 $777$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的结果列表，例如 $[\\mathrm{result}_1,\\mathrm{result}_2,\\mathrm{result}_3,\\mathrm{result}_4,\\mathrm{result}_5]$，其中每个 $\\mathrm{result}_i$ 是对应于测试用例 $i$ 的决策的 $\\mathrm{True}$ 或 $\\mathrm{False}$。",
            "solution": "该问题要求实现并统计验证两种用于在随机化学动力学的连续时间马尔可夫跳跃过程模型中采样等待时间 $\\tau$ 的方法：直接法 (DM) 和第一反应法 (FRM)。验证将使用柯尔莫哥洛夫-斯米尔诺夫 (KS) 拟合优度检验来执行。\n\n该问题的理论基础在于化学动力学的随机公式，其中系统的状态由每种化学物质的分子数量来描述。反应作为离散的随机事件发生。对于处于固定状态的系统，$K$ 个可能的反应通道（由 $k \\in \\{1, \\dots, K\\}$ 索引）中的每一个都被视为一个独立的泊松过程。第 $k$ 个泊松过程的速率由其倾向函数 $a_k$ 给出。由于为了采样下一个事件时间，系统状态被认为是固定的，因此每个 $a_k$ 都是一个非负常数，$a_k \\ge 0$。\n\n总倾向 $a_0$ 是各个倾向之和：\n$$\na_0 = \\sum_{k=1}^{K} a_k\n$$\n该量表示*任何*反应事件发生的总速率。该模型的一个基本结果是，直到下一个反应事件（无论哪个事件）的等待时间 $\\tau$ 是一个连续随机变量，它遵循速率参数等于总倾向 $a_0$ 的指数分布。$\\tau$ 的概率密度函数 (PDF) 由下式给出：\n$$\np(t; a_0) = a_0 e^{-a_0 t} \\quad \\text{for } t \\ge 0\n$$\n相应的累积分布函数 (CDF) 给出了等待时间小于或等于某个时间 $t$ 的概率，其表达式为：\n$$\nF(t; a_0) = P(\\tau \\le t) = \\int_0^t a_0 e^{-a_0 s} ds = 1 - e^{-a_0 t} \\quad \\text{for } t \\ge 0\n$$\n这个理论 CDF 构成了我们统计检验中原假设的基础。\n\n我们现在描述两种用于采样 $\\tau$ 的模拟方法。\n\n**直接法 (DM)**\n\n直接法是 Gillespie 随机模拟算法 (SSA) 的核心组成部分，它直接从其指数分布中采样等待时间 $\\tau$。这可以通过逆变换采样法高效实现。我们从 CDF $F(\\tau) = 1 - e^{-a_0 \\tau}$ 开始。设 $r$ 是从 $(0, 1)$ 区间上的均匀分布中抽取的随机数，并设 $r = F(\\tau)$。然后我们求解 $\\tau$：\n$$\nr = 1 - e^{-a_0 \\tau}\n$$\n$$\n1 - r = e^{-a_0 \\tau}\n$$\n$$\n\\ln(1 - r) = -a_0 \\tau\n$$\n$$\n\\tau = -\\frac{1}{a_0} \\ln(1 - r)\n$$\n因为如果 $r$ 在 $(0, 1)$ 上均匀分布，那么 $1-r$ 也在 $(0, 1)$ 上均匀分布。因此，我们可以通过用另一个均匀分布的随机数（为简单起见，我们仍记为 $r$）替换 $1-r$ 来简化表达式。这导出了用于采样 $\\tau$ 的著名公式：\n$$\n\\tau = \\frac{1}{a_0} \\ln\\left(\\frac{1}{r}\\right)\n$$\n此方法需要生成一个随机数来确定等待时间。这假设 $a_0  0$。如果 $a_0 = 0$，则没有反应可以发生，$\\tau$ 实际上是无限的。\n\n**第一反应法 (FRM)**\n\n第一反应法提供了另一种在数学上等效的采样 $\\tau$ 的方法。我们不考虑总倾向，而是独立地考虑每个反应通道。对于每个倾向为 $a_k  0$ 的通道 $k$，我们提出了一个假定的等待时间 $\\tau_k$，即假设该特定反应是唯一可能发生的反应时，它发生的时间。每个 $\\tau_k$ 都从其自身的速率 $a_k$ 的指数分布中采样：\n$$\n\\tau_k = \\frac{1}{a_k} \\ln\\left(\\frac{1}{r_k}\\right)\n$$\n其中每个 $r_k$ 是来自 $(0, 1)$ 上均匀分布的独立随机数。对于任何 $a_k=0$ 的通道，等待时间 $\\tau_k$ 是无限的。整个系统中*下一个*反应发生的等待时间是所有这些假定时间的最小值，因为第一个“触发”的反应决定了整个系统的事件时间：\n$$\n\\tau = \\min_{k \\in \\{1,\\dots,K\\}} \\{\\tau_k\\}\n$$\n指数分布的一个关键性质是，一组独立的指数分布随机变量的最小值也服从指数分布。如果 $\\tau_k \\sim \\text{Exponential}(a_k)$，那么 $\\min\\{\\tau_k\\}$ 服从一个指数分布，其速率参数等于各个速率之和，即 $\\sum_k a_k = a_0$。因此，FRM 保证能生成与 DM 相同分布的样本。此方法需要生成 $K$ 个随机数（或对于每个 $a_k0$ 的通道生成一个）来确定等待时间。\n\n**柯尔莫哥洛夫-斯米尔诺夫 (KS) 拟合优度检验**\n\n为了验证由 DM 或 FRM 生成的样本 $\\{\\tau_i\\}_{i=1}^{n}$ 符合理论分布，我们采用 KS 检验。该检验将样本的经验分布函数 (EDF) 与参考分布的 CDF 进行比较。EDF，记为 $F_n(t)$，定义为小于或等于 $t$ 的样本点所占的比例：\n$$\nF_n(t) = \\frac{1}{n} \\sum_{i=1}^n I(\\tau_i \\le t)\n$$\n其中 $I(\\cdot)$ 是指示函数。原假设 $H_0$ 是样本从具有 CDF $F(t) = 1 - e^{-a_0^{\\mathrm{test}} t}$ 的理论分布中抽取。KS 统计量 $D_n$ 是在所有可能的 $t$ 值上，EDF 和理论 CDF 之间的最大绝对差：\n$$\nD_n = \\sup_{t} |F_n(t) - F(t)|\n$$\n该检验计算一个 p 值，即假设 $H_0$ 为真时，观察到等于或大于从样本中计算出的 $D_n$ 统计量的概率。决策规则基于预先定义的显著性水平 $\\alpha$：\n- 如果 p 值 $\\ge \\alpha$，我们未能拒绝原假设 $H_0$。这表明数据与理论分布一致。程序应返回 $\\mathrm{True}$。\n- 如果 p 值 $ \\alpha$，我们拒绝原假设 $H_0$。这表明数据与理论分布之间存在统计上显著的差异。程序应返回 $\\mathrm{False}$。\n\n对于每个测试用例，流程如下：\n1.  为保证可复现性，设置指定的随机种子。\n2.  根据指定的方法（DM 或 FRM），使用给定的倾向 $(a_1, \\dots, a_K)$ 生成一个包含 $n$ 个等待时间的样本。\n3.  按规定计算总倾向 $a_0 = \\sum_k a_k$ 和测试倾向 $a_0^{\\mathrm{test}}$。\n4.  对生成的样本 $\\{\\tau_i\\}$，与速率为 $a_0^{\\mathrm{test}}$（在 `scipy` 中对应于尺度参数 $1/a_0^{\\mathrm{test}}$）的理论指数分布进行双边 KS 检验。\n5.  将得到的 p 值与显著性水平 $\\alpha$ 进行比较，以决定是否拒绝 $H_0$，并确定布尔输出。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef solve():\n    \"\"\"\n    Implements and validates waiting time sampling for stochastic simulation\n    using the Direct Method (DM) and First Reaction Method (FRM).\n    Uses the Kolmogorov-Smirnov test to check if simulated waiting times\n    follow the theoretical exponential distribution.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"method\": \"DM\",\n            \"propensities\": (0.5, 0.7, 2.3),\n            \"n\": 300,\n            \"alpha\": 0.001,\n            \"a0_test_factor\": 1.0,\n            \"seed\": 12345\n        },\n        {\n            \"method\": \"FRM\",\n            \"propensities\": (0.5, 0.7, 2.3),\n            \"n\": 300,\n            \"alpha\": 0.001,\n            \"a0_test_factor\": 1.0,\n            \"seed\": 54321\n        },\n        {\n            \"method\": \"FRM\",\n            \"propensities\": (0.5, 0.7, 2.3),\n            \"n\": 300,\n            \"alpha\": 0.05,\n            \"a0_test_factor\": 0.5,\n            \"seed\": 999\n        },\n        {\n            \"method\": \"DM\",\n            \"propensities\": (0.001, 0.002),\n            \"n\": 2000,\n            \"alpha\": 0.001,\n            \"a0_test_factor\": 1.0,\n            \"seed\": 2023\n        },\n        {\n            \"method\": \"FRM\",\n            \"propensities\": (0.0, 1.5),\n            \"n\": 300,\n            \"alpha\": 0.001,\n            \"a0_test_factor\": 1.0,\n            \"seed\": 777\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Set seed for reproducibility\n        np.random.seed(case[\"seed\"])\n\n        propensities = np.array(case[\"propensities\"])\n        n = case[\"n\"]\n        alpha = case[\"alpha\"]\n        method = case[\"method\"]\n        a0_test_factor = case[\"a0_test_factor\"]\n\n        # Calculate true total propensity\n        a0_true = np.sum(propensities)\n\n        samples = []\n        if method == \"DM\":\n            if a0_true == 0:\n                # Waiting time is infinite, simulation should stop.\n                # KS test is not meaningful on a sample of infinities.\n                # This case isn't in the test suite, but is a necessary check.\n                # For this problem, we can assume a0_true > 0 based on test cases.\n                pass\n            \n            # Generate n random numbers for inverse transform sampling\n            rand_nums = np.random.uniform(low=0.0, high=1.0, size=n)\n            # Vectorized calculation of waiting times\n            samples = (1.0 / a0_true) * np.log(1.0 / rand_nums)\n\n        elif method == \"FRM\":\n            # Generate n samples one by one\n            for _ in range(n):\n                putative_times = []\n                for a_k in propensities:\n                    if a_k > 0:\n                        rand_num = np.random.uniform(low=0.0, high=1.0)\n                        tau_k = (1.0 / a_k) * np.log(1.0 / rand_num)\n                        putative_times.append(tau_k)\n                \n                if not putative_times:\n                    # All propensities are zero, waiting time is infinite.\n                    # As with DM, this case is not in the test suite.\n                    tau = np.inf\n                else:\n                    tau = min(putative_times)\n                samples.append(tau)\n        \n        # Define the null hypothesis for the KS test\n        a0_test = a0_true * a0_test_factor\n        \n        # The theoretical CDF is F(t) = 1 - exp(-a0_test * t).\n        # scipy.stats.expon uses a scale parameter, where scale = 1/rate.\n        # The rate parameter lambda is a0_test.\n        scale_param = 1.0 / a0_test\n        \n        # Perform the two-sided Kolmogorov-Smirnov test\n        # H0: samples are drawn from an exponential distribution with the specified scale.\n        ks_statistic, p_value = kstest(samples, 'expon', args=(0, scale_param))\n        \n        # Decision: Fail to reject H0 if p-value is greater than or equal to alpha\n        decision = p_value >= alpha\n        results.append(decision)\n\n    # Final print statement in the exact required format.\n    # The boolean values True/False must be capitalized as such in the output string.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个完整的 Gillespie 算法步骤不仅包括确定下一个反应“何时”发生，还包括决定“何种”反应将发生。这个选择过程是根据各反应倾向的相对大小按比例进行的。本练习将焦点放在算法的这一选择机制上，要求你运用统计学方法来验证其正确性 。你将使用经典的皮尔逊 $\\chi^2$ 检验来判断模拟中各反应的发生频率是否与理论概率 $p_\\mu = a_\\mu/a_0$ 一致，并进一步探索统计功效分析，计算需要多大的样本量才能可靠地检测出算法中的潜在偏差。这让你从算法实现者，转变为能够设计和评估计算实验的严谨研究者。",
            "id": "3302887",
            "problem": "考虑一个充分混合的随机化学反应网络，该网络包含 $M$ 个反应通道，以 $\\mu \\in \\{1,\\dots,M\\}$ 为索引，每个通道都具有在固定状态 $\\mathbf{x}$ 下评估的倾向（强度）$a_\\mu(\\mathbf{x})$。令 $a_0(\\mathbf{x}) = \\sum_{\\mu=1}^M a_\\mu(\\mathbf{x})$。根据随机模拟算法（通常称为 Gillespie 算法 (GA)）的直接法和第一反应法，下一个反应的索引是根据一个分类分布选择的，其概率与各倾向成正比。定义归一化目标概率 $p_\\mu$ 为 $p_\\mu = a_\\mu(\\mathbf{x}) / a_0(\\mathbf{x})$，其中 $\\mu = 1,\\dots,M$，并假设 $\\sum_{\\mu=1}^M p_\\mu = 1$ 且 $p_\\mu  0$。\n\n假设任一方法的实现，在固定状态 $\\mathbf{x}$ 下，产生了一个包含 $N$ 次反应选择的序列，其中每个通道 $\\mu$ 的观测计数为 $C_\\mu$，使得 $\\sum_{\\mu=1}^M C_\\mu = N$。科学任务是评估观测到的选择频率是否与理论概率 $\\{p_\\mu\\}$ 一致，并进一步确定在给定的统计功效下，检测指定偏差所需的样本量。\n\n从随机模拟和蒙特卡洛方法中经过充分检验的事实和核心定义出发，即：\n- 以当前状态为条件的反应事件的指数等待时间，\n- 在决策瞬间，各反应时钟样本之间的独立性，\n- 支配分类计数的\n  多项分布，\n为该选择机制构建一个有原则的假设检验和功效分析。\n\n您的程序必须为每个测试用例实现以下内容：\n1. 在零假设 $H_0$ 下，将计数向量 $(C_1,\\dots,C_M)$ 建模为具有概率 $(p_1,\\dots,p_M)$ 和总计数 $N$ 的多项分布。构建 Pearson $\\chi^2$ 统计量，指明自由度，并计算零假设 $H_0: \\text{选择概率} = \\{p_\\mu\\}$ 的 $p$ 值。使用测试用例中提供的显著性水平 $\\alpha$。拒绝规则必须由 $H_0$ 下的 $\\chi^2$ 分布定义。\n2. 对于一个指定的备择概率向量 $q = (q_1,\\dots,q_M)$，其中 $q_\\mu  0$ 且 $\\sum_{\\mu=1}^M q_\\mu = 1$，计算在显著性水平 $\\alpha$ 下，Pearson $\\chi^2$ 检验达到目标功效 $1-\\beta$ 所需的最小整数样本量 $N^\\star$。使用大样本近似，其中备择假设下的 Pearson $\\chi^2$ 统计量服从一个非中心 $\\chi^2$ 分布，其自由度相同，非中心参数依赖于 $N$、$p$ 和 $q$。此外，强制执行 Pearson $\\chi^2$ 检验的标准适用条件，即所有期望计数 $N p_\\mu$ 至少为 $5$；如果此条件比功效要求更严格，则报告较大的 $N$。\n3. 为与科学背景保持一致的可解释性，将所有概率视为无量纲量。潜在涉及的唯一物理单位是底层过程中的时间，但在此处的输出中不需要。计数是整数。不涉及角度。以无单位的数值形式报告最终输出。\n\n测试套件：\n- 案例 A（常见的三通道场景，“理想路径”）：\n  - $M = 3$\n  - 倾向 $a = (1.0, 2.0, 3.0)$，因此 $p = \\left(\\frac{1.0}{6.0}, \\frac{2.0}{6.0}, \\frac{3.0}{6.0}\\right)$\n  - 观测计数 $C = (16, 33, 51)$，其中 $N = 100$\n  - 显著性水平 $\\alpha = 0.05$\n  - 备择假设 $q = (0.15, 0.30, 0.55)$\n  - 目标功效 $1-\\beta = 0.80$\n- 案例 B（双通道边界到二项分布）：\n  - $M = 2$\n  - 倾向 $a = (0.4, 0.6)$，因此 $p = (0.4, 0.6)$\n  - 观测计数 $C = (36, 64)$，其中 $N = 100$\n  - 显著性水平 $\\alpha = 0.05$\n  - 备择假设 $q = (0.45, 0.55)$\n  - 目标功效 $1-\\beta = 0.80$\n- 案例 C（四通道，低期望计数边界）：\n  - $M = 4$\n  - 倾向 $a = (0.5, 0.5, 2.0, 7.0)$，因此 $p = (0.05, 0.05, 0.20, 0.70)$\n  - 观测计数 $C = (6, 3, 24, 67)$，其中 $N = 100$\n  - 显著性水平 $\\alpha = 0.05$\n  - 备择假设 $q = (0.10, 0.05, 0.20, 0.65)$\n  - 目标功效 $1-\\beta = 0.80$\n\n最终输出规范：\n- 对于每个案例，您的程序必须计算：\n  - 在水平 $\\alpha$ 下，Pearson $\\chi^2$ 检验在 $H_0$ 下的 $p$ 值，\n  - 一个布尔值，指示在水平 $\\alpha$ 下是否拒绝 $H_0$，\n  - 最小整数 $N^\\star$，同时满足针对 $q$ 的目标功效要求和期望计数条件 $N p_\\mu \\ge 5$（对所有 $\\mu$）。\n- 您的程序应生成单行输出，其中包含一个逗号分隔的 Python 风格列表，该列表包含按案例 A、案例 B、案例 C 顺序排列的各案例结果列表。例如，它应打印一个顶级列表，形式为 $[\\,[p\\_A,\\text{reject}\\_A,N^\\star\\_A],\\,[p\\_B,\\text{reject}\\_B,N^\\star\\_B],\\,[p\\_C,\\text{reject}\\_C,N^\\star\\_C]\\,]$，其中 $p\\_A$、$p\\_B$、$p\\_C$ 是浮点数，$\\text{reject}\\_A$、$\\text{reject}\\_B$、$\\text{reject}\\_C$ 是布尔值，$N^\\star\\_A$、$N^\\star\\_B$、$N^\\star\\_C$ 是整数。",
            "solution": "该问题的核心在于两个标准的统计任务：拟合优度检验和前瞻性功效分析。两者都基于应用于多项计数数据的 Pearson $\\chi^2$ 统计量。其背景是 Gillespie 随机模拟算法 (SSA) 中的反应通道选择，在任何给定状态 $\\mathbf{x}$ 下，这都是一个离散随机事件。\n\n设系统的状态由布居数向量 $\\mathbf{x}$ 描述。系统有 $M$ 个反应通道，以 $\\mu \\in \\{1,\\dots,M\\}$ 为索引。反应 $\\mu$ 发生的倾向为 $a_\\mu(\\mathbf{x})$。总倾向为 $a_0(\\mathbf{x}) = \\sum_{\\mu=1}^M a_\\mu(\\mathbf{x})$。根据 SSA 的原理，下一个反应是类型 $\\mu$ 的概率由 $p_\\mu = a_\\mu(\\mathbf{x}) / a_0(\\mathbf{x})$ 给出。在固定状态 $\\mathbf{x}$ 下进行的一系列 $N$ 次此类选择，会产生一个观测计数向量 $\\mathbf{C} = (C_1, C_2, \\dots, C_M)$，其中 $\\sum_{\\mu=1}^M C_\\mu = N$。\n\n**第一部分：Pearson $\\chi^2$ 拟合优度检验**\n\n第一个任务是检验观测计数 $\\mathbf{C}$ 是否在统计上与理论概率 $\\mathbf{p} = (p_1, \\dots, p_M)$ 一致。\n\n**零假设 ($H_0$)**：观测计数 $\\mathbf{C}$ 是从具有 $N$ 次试验和成功概率为 $\\mathbf{p}$ 的多项分布中抽取的。形式上，$\\mathbf{C} \\sim \\text{Multinomial}(N, \\mathbf{p})$。\n\n在 $H_0$ 下，反应通道 $\\mu$ 的期望计数为 $E_\\mu = N p_\\mu$。Pearson $\\chi^2$ 检验统计量衡量观测计数 ($O_\\mu = C_\\mu$) 与期望计数之间的平方偏差，并用期望计数进行归一化：\n$$\n\\chi^2 = \\sum_{\\mu=1}^M \\frac{(O_\\mu - E_\\mu)^2}{E_\\mu} = \\sum_{\\mu=1}^M \\frac{(C_\\mu - N p_\\mu)^2}{N p_\\mu}\n$$\n假设 $H_0$ 为真，并且对于足够大的样本量 $N$，该统计量 $\\chi^2$ 近似服从自由度为 $k = M-1$ 的中心卡方随机变量，记为 $\\chi^2_k$。唯一的约束是计数总和必须为 $N$，因此自由度为 $M-1$。\n\n该检验的 $p$ 值是在假设 $H_0$ 为真的情况下，观测到至少与从数据中计算出的值 $\\chi^2_{obs}$ 一样大的 $\\chi^2$ 统计量的概率。\n$$\np\\text{-值} = P(\\chi^2_k \\ge \\chi^2_{obs})\n$$\n这使用 $\\chi^2_k$ 分布的生存函数（互补累积分布函数）来计算。如果在显著性水平 $\\alpha$ 下 $p$ 值小于或等于 $\\alpha$，则拒绝零假设。\n\n**第二部分：用于确定样本量的功效分析**\n\n第二个任务是确定检测与 $H_0$ 的特定偏差所需的最小样本量 $N^\\star$，并达到期望的统计功效。\n\n**备择假设 ($H_1$)**：观测计数 $\\mathbf{C}$ 是从具有 $N$ 次试验和一组不同概率 $\\mathbf{q} = (q_1, \\dots, q_M)$ 的多项分布中抽取的，其中 $\\mathbf{q} \\ne \\mathbf{p}$。\n\n在 $H_1$ 下，相同的 Pearson 统计量（仍然使用来自 $H_0$ 的 $E_\\mu = Np_\\mu$ 计算）在 $N$ 较大时，服从一个非中心卡方分布 $\\chi^2_k(\\lambda)$，其自由度同样为 $k=M-1$，但带有一个非中心参数 $\\lambda$。该非中心参数由下式给出：\n$$\n\\lambda = N \\sum_{\\mu=1}^M \\frac{(q_\\mu - p_\\mu)^2}{p_\\mu}\n$$\n检验的功效 $1-\\beta$ 是在 $H_1$ 实际上为真时，正确拒绝 $H_0$ 的概率。当观测到的统计量 $\\chi^2_{obs}$ 超过一个临界值 $\\chi^2_{crit}$ 时，发生拒绝。该临界值由显著性水平 $\\alpha$ 决定，是中心 $\\chi^2_k$ 分布（$H_0$ 下的分布）的上 $1-\\alpha$ 分位数：\n$$\n\\chi^2_{crit} = F^{-1}_{\\chi^2_k}(1-\\alpha)\n$$\n其中 $F^{-1}$ 是分位数函数（逆累积分布函数）。\n\n因此，功效是一个来自非中心卡方分布 $\\chi^2_k(\\lambda)$ 的随机变量超过 $\\chi^2_{crit}$ 的概率：\n$$\n\\text{功效} = P(\\chi^2_k(\\lambda)  \\chi^2_{crit}) = 1 - F_{\\chi^2_k(\\lambda)}(\\chi^2_{crit})\n$$\n我们寻求满足“功效” $\\ge 1-\\beta$ 的最小整数 $N$。由于功效是非中心参数 $\\lambda$ 的单调递增函数，而 $\\lambda$ 是 $N$ 的线性函数，我们可以数值求解能精确产生目标功效 $1-\\beta$ 的 $N$ 值，我们称之为 $N_{power}$。\n\n此外，$\\chi^2$ 近似的有效性要求零假设下的期望计数不能太小。一个标准的经验法则是对所有 $\\mu=1, \\dots, M$ 都有 $E_\\mu = N p_\\mu \\ge 5$。这对 $N$ 施加了一个独立的约束：\n$$\nN \\ge \\max_{\\mu} \\left( \\frac{5}{p_\\mu} \\right)\n$$\n令 $N_{counts} = \\lceil \\max_{\\mu}(5/p_\\mu) \\rceil$ 为满足此条件的最小整数样本量。\n\n最终所需的样本量 $N^\\star$ 必须同时满足功效要求和期望计数条件。因此，它是两个最小值中的最大值：\n$$\nN^\\star = \\max \\left( \\lceil N_{power} \\rceil, N_{counts} \\right)\n$$\n这确保了检验既有足够的功效来检测指定的备择假设，又在其分布假设上是稳健的。我们现在将此框架应用于所提供的测试案例。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2, ncx2\nfrom scipy.optimize import brentq\nimport math\n\ndef solve():\n    \"\"\"\n    Processes all test cases for the Gillespie reaction selection analysis.\n    \"\"\"\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"M\": 3,\n            \"a\": np.array([1.0, 2.0, 3.0]),\n            \"C\": np.array([16, 33, 51]),\n            \"N\": 100,\n            \"alpha\": 0.05,\n            \"q\": np.array([0.15, 0.30, 0.55]),\n            \"power\": 0.80,\n        },\n        {\n            \"name\": \"Case B\",\n            \"M\": 2,\n            \"a\": np.array([0.4, 0.6]),\n            \"C\": np.array([36, 64]),\n            \"N\": 100,\n            \"alpha\": 0.05,\n            \"q\": np.array([0.45, 0.55]),\n            \"power\": 0.80,\n        },\n        {\n            \"name\": \"Case C\",\n            \"M\": 4,\n            \"a\": np.array([0.5, 0.5, 2.0, 7.0]),\n            \"C\": np.array([6, 3, 24, 67]),\n            \"N\": 100,\n            \"alpha\": 0.05,\n            \"q\": np.array([0.10, 0.05, 0.20, 0.65]),\n            \"power\": 0.80,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        # --- Unpack Test Case ---\n        a = case[\"a\"]\n        C = case[\"C\"]\n        N = case[\"N\"]\n        M = case[\"M\"]\n        alpha = case[\"alpha\"]\n        q = case[\"q\"]\n        target_power = case[\"power\"]\n        \n        # --- Part 1: Pearson Chi-squared Goodness-of-Fit Test ---\n        \n        # Calculate null hypothesis probabilities p\n        a0 = np.sum(a)\n        p = a / a0\n        \n        # Calculate expected counts under H0\n        E = N * p\n        \n        # Calculate the Pearson chi-squared statistic\n        chi2_obs = np.sum((C - E)**2 / E)\n        \n        # Degrees of freedom\n        df = M - 1\n        \n        # Calculate the p-value\n        p_value = chi2.sf(chi2_obs, df)\n        \n        # Determine rejection of H0\n        reject_h0 = p_value = alpha\n        \n        # --- Part 2: Power Analysis for Sample Size N* ---\n        \n        # Critical value for the test at significance level alpha\n        chi2_crit = chi2.ppf(1 - alpha, df)\n        \n        # Effect size for noncentrality parameter calculation\n        # This is the sum part of the lambda formula, without N\n        delta = np.sum((q - p)**2 / p)\n        \n        # Define a function to find the noncentrality parameter (lambda)\n        # that yields the target power. We want to find the root of this function.\n        # Power = ncx2.sf(chi2_crit, df, lambda). We want Power = target_power.\n        def power_eq(lmbda):\n            return ncx2.sf(chi2_crit, df, lmbda) - target_power\n\n        # Solve for the noncentrality parameter lambda_star\n        # The search interval [1e-9, 10000] is sufficiently large and robust.\n        try:\n            lambda_star = brentq(power_eq, 1e-9, 10000)\n        except ValueError:\n            # This would happen if the target power is not achievable within the bracket,\n            # which is not expected for these problem parameters.\n            lambda_star = np.nan\n            \n        # Calculate required sample size N_power from lambda_star = N * delta\n        # If delta is zero (p=q), N_power would be infinite.\n        if delta > 0:\n            n_power = lambda_star / delta\n        else:\n            n_power = float('inf')\n\n        # Calculate minimum N to satisfy the E_mu >= 5 rule of thumb\n        n_counts_min_float = np.max(5.0 / p)\n        n_counts_min = math.ceil(n_counts_min_float)\n        \n        # The final required sample size N_star is the maximum of the two requirements\n        n_star = max(math.ceil(n_power), n_counts_min)\n        \n        results.append([p_value, reject_h0, n_star])\n\n    # Final print statement in the exact required format.\n    # The default string representation of the list of lists is correct.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}