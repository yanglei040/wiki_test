{
    "hands_on_practices": [
        {
            "introduction": "在设计复杂的蒙特卡洛算法之前，至关重要的是要正确处理我们所模拟的随机变量的基本属性。混合随机变量，由于其同时包含离散和连续部分，因此构成了一个常见的陷阱。本练习探讨了一种忽略混合分布中离散部分的朴素模拟方法所带来的后果。通过推导这种有缺陷方法产生的估计量的解析偏差，您将更深刻地理解混合变量期望的定义，并认识到为什么正确处理每个组成部分对于精确估计是不可或缺的 。",
            "id": "3333837",
            "problem": "考虑一个定义在 $[0,\\infty)$ 上的混合随机变量 $X$，其概率测度可分解为一个离散原子和一个绝对连续部分。其原子位于 $x=0$ 处，质量为 $\\alpha \\in (0,1)$，即 $\\mathbb{P}(X=0)=\\alpha$。在 $X0$ 的条件下，其连续部分服从率参数为 $\\lambda0$ 的指数分布，因此在 $(0,\\infty)$ 上的密度为 $f(x)=(1-\\alpha)\\lambda \\exp(-\\lambda x)$。所以，累积分布函数 $F$ 满足 $F(0)=\\alpha$，并且对于 $x0$，$F(x)=\\alpha+(1-\\alpha)(1-\\exp(-\\lambda x))$。\n\n您的任务是使用蒙特卡洛模拟来估计量 $\\theta=\\mathbb{E}[\\exp(-\\beta X)]$，其中 $\\beta0$ 是一个固定常数。一位实践者未意识到在跳跃点处需要进行显式随机化，因而实施了一种忽略原子的朴素逆变换采样方案：他们通过将绝对连续部分归一化至总质量为 $1$ 来构造一个连续的代理累积分布函数，即对于 $x\\geq 0$，$F_{\\mathrm{cont}}(x)=(1-\\alpha)^{-1}(F(x)-\\alpha)=1-\\exp(-\\lambda x)$，然后通过 $X_{\\mathrm{naive}}=F_{\\mathrm{cont}}^{-1}(U)$ 生成样本，其中 $U\\sim \\mathrm{Uniform}(0,1)$。换句话说，这位朴素的模拟者从率参数为 $\\lambda$ 的纯指数分布中抽取 $X_{\\mathrm{naive}}$，并省略了本应以概率 $\\alpha$ 选择位于 $x=0$ 的原子的随机化步骤。\n\n请仅从混合随机变量、其累积分布函数以及期望作为关于概率测度的积分的定义出发，推导当样本数量趋于无穷大时，所得蒙特卡洛估计量的精确偏差。也就是说，推导出下列表达式的闭式解：\n$$\n\\mathrm{Bias}=\\lim_{n\\to\\infty}\\left(\\mathbb{E}\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\exp(-\\beta X_{\\mathrm{naive},i})\\right]-\\theta\\right),\n$$\n其中 $X_{\\mathrm{naive},i}$ 是从上述朴素逆变换方案中抽取的独立同分布样本。请用一个包含 $\\alpha$、$\\lambda$ 和 $\\beta$ 的单一闭式解析表达式来表示您的最终答案。无需四舍五入。",
            "solution": "首先验证该问题，以确保其具有科学依据、问题明确且客观。\n\n**步骤 1：提取已知条件**\n- 一个混合随机变量 $X$ 定义在支撑集 $[0, \\infty)$ 上。\n- 其概率测度在 $x=0$ 处有一个离散原子，质量为 $\\mathbb{P}(X=0)=\\alpha$，其中 $\\alpha \\in (0,1)$。\n- 其绝对连续部分定义在 $(0, \\infty)$ 上，概率密度为 $f(x)=(1-\\alpha)\\lambda \\exp(-\\lambda x)$，其中 $\\lambda0$。这对应于变量 $X$ 在 $X0$ 条件下的密度为 $\\lambda \\exp(-\\lambda x)$。\n- 累积分布函数 (CDF) 为 $F(x) = \\alpha$（当 $x=0$ 时）和 $F(x)=\\alpha+(1-\\alpha)(1-\\exp(-\\lambda x))$（当 $x0$ 时）。\n- 待估计的量为 $\\theta=\\mathbb{E}[\\exp(-\\beta X)]$，其中 $\\beta0$ 是一个固定常数。\n- 一种朴素的蒙特卡洛采样方案从率参数为 $\\lambda$ 的纯指数分布中生成样本 $X_{\\mathrm{naive}}$。问题陈述这通过 $X_{\\mathrm{naive}}=F_{\\mathrm{cont}}^{-1}(U)$ 实现，其中 $U\\sim \\mathrm{Uniform}(0,1)$ 且 $F_{\\mathrm{cont}}(x)=1-\\exp(-\\lambda x)$。\n- 任务是推导该蒙特卡洛估计量的渐近偏差：\n$$\n\\mathrm{Bias}=\\lim_{n\\to\\infty}\\left(\\mathbb{E}\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\exp(-\\beta X_{\\mathrm{naive},i})\\right]-\\theta\\right)\n$$\n其中 $X_{\\mathrm{naive},i}$ 为独立同分布 (i.i.d.) 的抽样。\n\n**步骤 2：使用已知条件进行验证**\n- **科学依据**：该问题基于概率论的既定原理，特别是关于混合随机变量、期望和蒙特卡洛模拟。CDF、概率密度、原子和逆变换采样等概念都是标准内容。\n- **问题明确性**：该问题是明确的。它要求基于明确定义的分布和参数计算一个确定的、可计算的量（渐近偏差）。参数 $\\alpha$、$\\lambda$ 和 $\\beta$ 均受约束，确保所要求的期望是有限且定义明确的。\n- **客观性**：语言精确、数学化，不含主观内容。\n- **一致性与完整性**：所提供的信息是自洽的。CDF $F(x)$ 正确地结合了 $x=0$ 处的点质量与 $(0, \\infty)$ 上给定密度的积分：$\\mathbb{P}(X \\le x) = \\mathbb{P}(X=0) + \\int_0^x (1-\\alpha)\\lambda \\exp(-\\lambda t) dt = \\alpha + (1-\\alpha)[-\\exp(-\\lambda t)]_0^x = \\alpha + (1-\\alpha)(1-\\exp(-\\lambda x))$，这与提供的 $F(x)$ 相符。所有必要信息均已给出。\n\n**步骤 3：结论与行动**\n该问题有效。现在开始求解过程。\n\n对于参数 $\\theta = \\mathbb{E}[g(X)]$，估计量 $\\hat{\\theta}_n = \\frac{1}{n}\\sum_{i=1}^{n} g(X_i)$ 的偏差定义为 $\\mathbb{E}[\\hat{\\theta}_n] - \\theta$。在此问题中，估计量是使用样本 $X_{\\mathrm{naive},i}$ 而不是正确的样本 $X_i$ 构建的。需要计算的量是渐近偏差。\n\n首先，让我们简化偏差的表达式。估计量为 $\\hat{\\theta}_{\\mathrm{naive}, n} = \\frac{1}{n}\\sum_{i=1}^{n}\\exp(-\\beta X_{\\mathrm{naive},i})$。根据期望的线性性质以及样本 $X_{\\mathrm{naive},i}$ 是独立同分布的，其期望为：\n$$\n\\mathbb{E}\\left[\\hat{\\theta}_{\\mathrm{naive}, n}\\right] = \\mathbb{E}\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\exp(-\\beta X_{\\mathrm{naive},i})\\right] = \\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}[\\exp(-\\beta X_{\\mathrm{naive},i})] = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}[\\exp(-\\beta X_{\\mathrm{naive}})] = \\mathbb{E}[\\exp(-\\beta X_{\\mathrm{naive}})]\n$$\n该期望不依赖于样本量 $n$。因此，偏差对于 $n$ 是一个常数。所以，问题定义中的偏差极限就是偏差本身：\n$$\n\\mathrm{Bias} = \\mathbb{E}[\\exp(-\\beta X_{\\mathrm{naive}})] - \\theta = \\mathbb{E}[\\exp(-\\beta X_{\\mathrm{naive}})] - \\mathbb{E}[\\exp(-\\beta X)]\n$$\n问题简化为计算两个期望并求其差值。\n\n**1. 计算真实期望，$\\theta = \\mathbb{E}[\\exp(-\\beta X)]$**\n\n对于混合随机变量 $X$，其函数 $g(X)$ 的期望是通过对概率测度 $dP_X(x)$ 积分 $g(x)$ 来计算的。该测度由一个离散部分（一个点质量）和一个连续部分组成。\n$$\n\\theta = \\mathbb{E}[\\exp(-\\beta X)] = \\int_{[0,\\infty)} \\exp(-\\beta x) \\, dP_X(x)\n$$\n该积分可以分解为来自 $x=0$ 处原子的贡献与在 $(0,\\infty)$ 上连续部分的积分之和：\n$$\n\\theta = \\exp(-\\beta \\cdot 0) \\cdot \\mathbb{P}(X=0) + \\int_0^{\\infty} \\exp(-\\beta x) f(x) \\, dx\n$$\n使用给定的值 $\\mathbb{P}(X=0)=\\alpha$ 和 $f(x)=(1-\\alpha)\\lambda \\exp(-\\lambda x)$（当 $x0$ 时）：\n$$\n\\theta = \\exp(0) \\cdot \\alpha + \\int_0^{\\infty} \\exp(-\\beta x) (1-\\alpha)\\lambda \\exp(-\\lambda x) \\, dx\n$$\n$$\n\\theta = 1 \\cdot \\alpha + (1-\\alpha)\\lambda \\int_0^{\\infty} \\exp(-(\\lambda+\\beta)x) \\, dx\n$$\n计算该积分为：\n$$\n\\int_0^{\\infty} \\exp(-(\\lambda+\\beta)x) \\, dx = \\left[ \\frac{\\exp(-(\\lambda+\\beta)x)}{-(\\lambda+\\beta)} \\right]_0^{\\infty} = 0 - \\frac{1}{-(\\lambda+\\beta)} = \\frac{1}{\\lambda+\\beta}\n$$\n由于 $\\lambda0$ 和 $\\beta0$，这意味着 $\\lambda+\\beta0$，因此该积分收敛。\n将此结果代回 $\\theta$ 的表达式中：\n$$\n\\theta = \\alpha + (1-\\alpha) \\lambda \\frac{1}{\\lambda+\\beta} = \\alpha + (1-\\alpha) \\frac{\\lambda}{\\lambda+\\beta}\n$$\n\n**2. 计算朴素期望，$\\mathbb{E}[\\exp(-\\beta X_{\\mathrm{naive}})]$**\n\n问题陈述 $X_{\\mathrm{naive}}$ 是从率参数为 $\\lambda$ 的纯指数分布中抽样的。这与应用于 $F_{\\mathrm{cont}}(x) = 1-\\exp(-\\lambda x)$ 的逆变换法是一致的。$X_{\\mathrm{naive}}$ 的概率密度函数是 $f_{\\mathrm{naive}}(x) = \\lambda \\exp(-\\lambda x)$（当 $x \\ge 0$ 时）。\n其期望计算如下：\n$$\n\\mathbb{E}[\\exp(-\\beta X_{\\mathrm{naive}})] = \\int_0^{\\infty} \\exp(-\\beta x) f_{\\mathrm{naive}}(x) \\, dx = \\int_0^{\\infty} \\exp(-\\beta x) \\lambda \\exp(-\\lambda x) \\, dx\n$$\n$$\n\\mathbb{E}[\\exp(-\\beta X_{\\mathrm{naive}})] = \\lambda \\int_0^{\\infty} \\exp(-(\\lambda+\\beta)x) \\, dx\n$$\n这与之前遇到的积分形式相同，只是乘以了 $\\lambda$：\n$$\n\\mathbb{E}[\\exp(-\\beta X_{\\mathrm{naive}})] = \\lambda \\left( \\frac{1}{\\lambda+\\beta} \\right) = \\frac{\\lambda}{\\lambda+\\beta}\n$$\n该结果也可被识别为率参数为 $\\lambda$ 的指数分布的矩生成函数 $M(t)=\\frac{\\lambda}{\\lambda-t}$ 在 $t=-\\beta$ 处的值。\n\n**3. 计算偏差**\n\n最后，我们通过从朴素计算的期望中减去真实期望 $\\theta$ 来计算偏差。\n$$\n\\mathrm{Bias} = \\mathbb{E}[\\exp(-\\beta X_{\\mathrm{naive}})] - \\theta = \\frac{\\lambda}{\\lambda+\\beta} - \\left( \\alpha + (1-\\alpha) \\frac{\\lambda}{\\lambda+\\beta} \\right)\n$$\n展开负号：\n$$\n\\mathrm{Bias} = \\frac{\\lambda}{\\lambda+\\beta} - \\alpha - (1-\\alpha) \\frac{\\lambda}{\\lambda+\\beta}\n$$\n将包含分数的项组合起来：\n$$\n\\mathrm{Bias} = \\left(1 - (1-\\alpha)\\right) \\frac{\\lambda}{\\lambda+\\beta} - \\alpha\n$$\n$$\n\\mathrm{Bias} = (1 - 1 + \\alpha) \\frac{\\lambda}{\\lambda+\\beta} - \\alpha\n$$\n$$\n\\mathrm{Bias} = \\alpha \\frac{\\lambda}{\\lambda+\\beta} - \\alpha\n$$\n提取公因式 $\\alpha$：\n$$\n\\mathrm{Bias} = \\alpha \\left( \\frac{\\lambda}{\\lambda+\\beta} - 1 \\right)\n$$\n将括号内的项通分：\n$$\n\\mathrm{Bias} = \\alpha \\left( \\frac{\\lambda - (\\lambda+\\beta)}{\\lambda+\\beta} \\right) = \\alpha \\left( \\frac{\\lambda - \\lambda - \\beta}{\\lambda+\\beta} \\right) = \\alpha \\left( \\frac{-\\beta}{\\lambda+\\beta} \\right)\n$$\n因此，偏差的最终表达式为：\n$$\n\\mathrm{Bias} = -\\frac{\\alpha\\beta}{\\lambda+\\beta}\n$$\n偏差为负，这符合预期。朴素采样器忽略了 $x=0$ 处的原子，而函数 $g(x)=\\exp(-\\beta x)$ 在此点达到其最大值 $g(0)=1$。通过仅从 $x0$ 且 $g(x)  1$ 的连续部分采样，朴素估计量会系统性地低估真实均值。",
            "answer": "$$\n\\boxed{-\\frac{\\alpha\\beta}{\\lambda+\\beta}}\n$$"
        },
        {
            "introduction": "一旦我们能够正确地模拟混合变量，下一步就是如何高效地进行模拟。分层抽样是一种强大的方差缩减技术，它利用了问题内在的结构。本练习将挑战您将分层抽样应用于一个混合随机变量，方法是将其原子部分和连续部分分离开来。其中的一个关键洞见在于，如何在固定的计算预算下，推导出最优的样本分配策略。通过这个练习，您会发现一个强有力的原则：当某个层级的方差为零时（例如点质量），我们就不需要对其进行抽样。这个练习结合了理论优化与实际算法设计，展示了如何从第一性原理出发，构建一个高效的估计器 。",
            "id": "3333855",
            "problem": "仅使用基本定义和原理，构建并分析一个用于混合随机变量的分层蒙特卡洛估计器。设 $X$ 是一个混合随机变量，在 $0$ 处有一个离散原子，在 $(0,\\infty)$ 上有一个连续分量。具体来说，假设 $\\mathbb{P}(X=0)=p$，且在 $X0$ 的条件下，$X$ 的条件分布在 $(0,\\infty)$ 上具有概率密度函数 $g$；等价地，$X$ 具有一个混合分布，在 $0$ 处有质量 $p$，在 $(0,\\infty)$ 上有密度 $(1-p)g(x)$。给定一个可测函数 $h:(0,\\infty)\\to\\mathbb{R}$ 且 $h(0)$ 有定义，你的任务是通过在集合 $\\{X=0\\}$ 和 $\\{X0\\}$ 上进行分层，推导出一个用于 $\\mathbb{E}[h(X)]$ 的分层估计器，并在成本约束下优化层间的样本分配以最小化方差。\n\n你的推导应基于以下基本定义和经过检验的事实：\n- 全期望定律：$\\mathbb{E}[h(X)] = \\mathbb{E}[h(X)\\mid X=0]\\mathbb{P}(X=0) + \\mathbb{E}[h(X)\\mid X0]\\mathbb{P}(X0)$。\n- 对于一个在层内使用独立样本的分层估计器，其分配给 $\\{X=0\\}$ 的样本数为 $n_0$，分配给 $\\{X0\\}$ 的样本数为 $n_1$，层权重为 $w_0=\\mathbb{P}(X=0)$ 和 $w_1=\\mathbb{P}(X0)$，则无偏估计器为 $\\widehat{\\mu} = w_0 \\widehat{\\mu}_0 + w_1 \\widehat{\\mu}_1$，其中 $\\widehat{\\mu}_i$ 是在层 $i\\in\\{0,1\\}$ 内 $h(X)$ 的样本均值。\n- 在独立性假设下，分层估计器的方差为 $\\mathrm{Var}(\\widehat{\\mu}) = \\sum_{i\\in\\{0,1\\}} \\frac{w_i^2 \\sigma_i^2}{n_i}$，其中 $\\sigma_i^2$ 是 $h(X)$ 的层内方差。\n- 由线性成本约束 $\\sum_{i\\in\\{0,1\\}} c_i n_i \\le B$ 建模的固定计算预算，其中 $c_0$ 和 $c_1$ 是已知的正单位样本成本，B 是固定的总预算（解释为总允许成本）。\n\n你的任务：\n- 从第一性原理出发，推导出一个最优分配规则 $(n_0^\\star,n_1^\\star)$，该规则在预算约束 $\\sum_{i\\in\\{0,1\\}} c_i n_i \\le B$ 下最小化 $\\mathrm{Var}(\\widehat{\\mu})$，其中 $p$、$g$ 和可测函数 $h$ 是给定的。\n- 将你的推导应用于给定的混合结构（其中 $\\{X=0\\}$ 是一个原子），并清楚地说明在这种情况下最优分配会发生什么变化。\n- 构建一个使用推导出的最优分配的可实现的分层估计器。如果某个层在最优分配下不需要抽样，解释原因以及在这种情况下你的估计器如何简化。\n- 实现该估计器，并使用一个为每个测试用例固定的种子 $s$ 的伪随机数生成器计算其在以下每个测试用例中的值，以使输出是确定性的。通过为从 $0$ 开始的测试用例索引 $k$ 使用 $s+k$ 作为种子，确保测试用例之间使用独立的流。\n\n测试套件（每个用例指定 $p$、连续部分的 $g$、函数 $h$、预算 $B$（无单位成本）以及单位样本成本 $c_0, c_1$）：\n- 用例 1：$p=\\frac{1}{3}$，$g$ 是率为 $\\lambda=2$ 的指数分布（密度 $g(x)=2 e^{-2x}$ on $(0,\\infty)$），$h(x)=x + \\mathbf{1}\\{x1\\}$，预算 $B=1000$，成本 $c_0=1, c_1=1$，种子 $s=12345$。\n- 用例 2：$p=0.99$，$g$ 是形状参数为 $k=3$、尺度参数为 $\\theta=1$ 的伽马分布（密度 $g(x)=\\frac{x^{k-1}e^{-x/\\theta}}{\\Gamma(k)\\theta^k}$ on $(0,\\infty)$），$h(x)=x^2$，预算 $B=200$，成本 $c_0=1, c_1=1$，种子 $s=12345$。\n- 用例 3：$p=0.05$，$g$ 是参数为 $\\mu=0$ 和 $\\sigma=1$ 的对数正态分布（即对于 $Y\\sim g$，有 $\\log Y\\sim \\mathcal{N}(0,1)$），$h(x)=\\mathbf{1}\\{x2\\}$，预算 $B=500$，成本 $c_0=1, c_1=1$，种子 $s=12345$。\n- 用例 4：$p=1$，$g$ 是率为 $\\lambda=1$ 的指数分布（密度 $g(x)=e^{-x}$ on $(0,\\infty)$），$h(x)=\\sqrt{x+1}-1$，预算 $B=50$，成本 $c_0=1, c_1=1$，种子 $s=12345$。\n\n对于每个用例，除了计算具有最优分配的分层估计器外，还要使用从定义推导出的解析公式（如果可用）计算 $\\mathbb{E}[h(X)]$ 的精确值：\n- 对于率为 $\\lambda$ 的指数分布，$\\mathbb{E}[Y]=\\frac{1}{\\lambda}$ 且对于 $t0$ 有 $\\mathbb{P}(Yt)=e^{-\\lambda t}$。\n- 对于形状参数为 $k$、尺度参数为 $\\theta$ 的伽马分布，$\\mathbb{E}[Y^2]=\\theta^2 k(1+k)$。\n- 对于参数为 $\\mu$ 和 $\\sigma$ 的对数正态分布，对于 $t0$ 有 $\\mathbb{P}(Yt)=1-\\Phi\\left(\\frac{\\ln t - \\mu}{\\sigma}\\right)$，其中 $\\Phi$ 是标准正态分布的累积分布函数。\n\n你的程序必须：\n- 根据你的推导实现最优分配计算和分层估计器。\n- 对于每个测试用例，输出最优层样本数 $(n_0^\\star,n_1^\\star)$（整数）、分层估计器值（浮点数）和从给定解析公式计算的精确值（浮点数）。\n- 使用指定的种子使模拟结果具有确定性。\n- 确保满足预算约束 $\\sum_{i\\in\\{0,1\\}} c_i n_i \\le B$。\n\n最终输出格式：\n- 你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表。对于按顺序 $1,2,3,4$ 的每个用例，依次追加四个条目：$n_0^\\star$、$n_1^\\star$、分层估计器值和精确值。例如，一个包含两个用例的输出应如下所示：$[n_{0,1}^\\star,n_{1,1}^\\star,\\widehat{\\mu}_1,\\mu_1,n_{0,2}^\\star,n_{1,2}^\\star,\\widehat{\\mu}_2,\\mu_2]$；对所有四个用例扩展此模式。",
            "solution": "该问题要求推导并实现一个用于混合随机变量的分层蒙特卡洛估计器。解决方案分两个阶段进行：首先，是样本最优分配和最终估计器的形式化推导；其次，是将此框架应用于所提供的具体测试用例。\n\n### 基于原理的推导与设计\n\n设 $X$ 是一个混合随机变量，其分布为 $\\mathbb{P}(X=0)=p$，并且在 $(0, \\infty)$ 上，$X0$ 条件下的条件概率密度函数为 $g(x)$。我们的任务是为给定函数 $h$ 估计 $\\mathbb{E}[h(X)]$。\n\n问题指定将样本空间分层为两个层：$S_0 = \\{x | x=0\\}$ 和 $S_1 = \\{x | x0\\}$。相应的层权重是这些事件的概率：\n$w_0 = \\mathbb{P}(X \\in S_0) = \\mathbb{P}(X=0) = p$\n$w_1 = \\mathbb{P}(X \\in S_1) = \\mathbb{P}(X0) = 1-p$\n\n全期望定律提供了我们希望估计的精确值：\n$$\n\\mathbb{E}[h(X)] = \\mathbb{E}[h(X) | X \\in S_0] w_0 + \\mathbb{E}[h(X) | X \\in S_1] w_1\n$$\n设 $\\mu_i = \\mathbb{E}[h(X) | X \\in S_i]$ 为层 $i$ 中 $h(X)$ 的条件均值。则 $\\mathbb{E}[h(X)] = \\mu_0 w_0 + \\mu_1 w_1$。\n\n$\\mathbb{E}[h(X)]$ 的一个分层蒙特卡洛估计器由 $\\widehat{\\mu} = w_0 \\widehat{\\mu}_0 + w_1 \\widehat{\\mu}_1$ 给出，其中 $\\widehat{\\mu}_i$ 是基于从层 $i$ 抽取的 $n_i$ 个样本的 $h(X)$ 的样本均值。假设样本独立，此估计器的方差为：\n$$\n\\mathrm{Var}(\\widehat{\\mu}) = \\frac{w_0^2 \\sigma_0^2}{n_0} + \\frac{w_1^2 \\sigma_1^2}{n_1}\n$$\n其中 $\\sigma_i^2 = \\mathrm{Var}(h(X) | X \\in S_i)$ 是 $h(X)$ 在层 $i$ 内的方差。\n\n**1. 最优样本分配**\n\n我们的目标是在线性预算约束 $\\sum_{i=0,1} c_i n_i \\le B$下最小化此方差，其中 $c_i  0$ 是层 $i$ 中每个樣本的成本，$B$ 是总预算。为了最小化方差，我们应该用尽全部预算，因此约束变为等式：$c_0 n_0 + c_1 n_1 = B$。\n\n这是一个约束优化问题，可以使用拉格朗日乘子法解决。拉格朗日函数是：\n$$\nL(n_0, n_1, \\lambda) = \\left( \\frac{w_0^2 \\sigma_0^2}{n_0} + \\frac{w_1^2 \\sigma_1^2}{n_1} \\right) + \\lambda(c_0 n_0 + c_1 n_1 - B)\n$$\n将关于 $n_0$ 和 $n_1$ 的偏导数设为零，得到：\n$$\n\\frac{\\partial L}{\\partial n_i} = -\\frac{w_i^2 \\sigma_i^2}{n_i^2} + \\lambda c_i = 0 \\implies n_i^2 = \\frac{w_i^2 \\sigma_i^2}{\\lambda c_i} \\implies n_i = \\frac{w_i \\sigma_i}{\\sqrt{\\lambda c_i}}\n$$\n这意味着最优分配 $n_i^\\star$ 与 $w_i \\sigma_i / \\sqrt{c_i}$ 成正比。为了找到比例常数，我们将其代入预算约束中：\n$$\n\\sum_{i=0,1} c_i \\left( \\frac{w_i \\sigma_i}{\\sqrt{\\lambda c_i}} \\right) = B \\implies \\frac{1}{\\sqrt{\\lambda}} \\sum_{i=0,1} w_i \\sigma_i \\sqrt{c_i} = B \\implies \\frac{1}{\\sqrt{\\lambda}} = \\frac{B}{\\sum_{j=0,1} w_j \\sigma_j \\sqrt{c_j}}\n$$\n将此结果代回 $n_i$ 的表达式，得到最优分配（对于实值 $n_i$）：\n$$\nn_i^\\star = B \\frac{w_i \\sigma_i / \\sqrt{c_i}}{\\sum_{j=0,1} w_j \\sigma_j \\sqrt{c_j}}\n$$\n\n**2. 应用于混合分布的特例**\n\n我们现在将这个一般结果应用于我们的特定分层。\n-   **层 $S_0 = \\{X=0\\}$:** 来自此层的样本总是 $X=0$。因此，$h(X)$ 的值总是常数 $h(0)$。一个常数的方差为零。因此，层内方差 $\\sigma_0^2$ 是：\n    $$\n    \\sigma_0^2 = \\mathrm{Var}(h(X) | X=0) = 0\n    $$\n-   **层 $S_1 = \\{X0\\}$:** 来自此层的样本遵循密度为 $g(x)$ 的分布。方差 $\\sigma_1^2$ 是 $h(Y)$ 的方差，其中 $Y \\sim g$，即 $\\sigma_1^2 = \\mathrm{Var}(h(Y))$。\n\n$\\sigma_0 = 0$ 这一事实极大地简化了最优分配。将 $\\sigma_0=0$ 代入分配公式：\n$$\nn_0^\\star = B \\frac{w_0 (0) / \\sqrt{c_0}}{w_0 (0) \\sqrt{c_0} + w_1 \\sigma_1 \\sqrt{c_1}} = 0\n$$\n$$\nn_1^\\star = B \\frac{w_1 \\sigma_1 / \\sqrt{c_1}}{w_0 (0) \\sqrt{c_0} + w_1 \\sigma_1 \\sqrt{c_1}} = B \\frac{w_1 \\sigma_1 / \\sqrt{c_1}}{w_1 \\sigma_1 \\sqrt{c_1}} = \\frac{B}{c_1}\n$$\n此推导在 $w_1 \\sigma_1  0$ 时成立，即 $p1$ 且 $h(X)$ 在 $(0, \\infty)$ 上不是常数。由于样本数量必须是整数，我们取底以确保满足预算约束：\n$$\nn_0^\\star = 0 \\quad \\text{and} \\quad n_1^\\star = \\left\\lfloor \\frac{B}{c_1} \\right\\rfloor\n$$\n这个结果是直观的：由于层 $S_0$ 中的结果是确定性的，因此没有不确定性需要减少。所有的模拟预算都应分配给层 $S_1$，因为它是方差的唯一来源。\n\n**3. 最终的估计器**\n\n在最优分配 $n_0^\\star=0$ 的情况下，我们不对层 $S_0$ 进行任何抽样。我们不使用样本均值 $\\widehat{\\mu}_0$，而是使用精确的条件期望 $\\mu_0 = \\mathbb{E}[h(X)|X=0] = h(0)$。对于层 $S_1$，我们从密度 $g(x)$ 中生成 $n_1^\\star$ 个样本 $Y_1, \\dots, Y_{n_1^\\star}$，并计算样本均值 $\\widehat{\\mu}_1 = \\frac{1}{n_1^\\star} \\sum_{j=1}^{n_1^\\star} h(Y_j)$。\n\n最终的分层估计器是：\n$$\n\\widehat{\\mu} = w_0 \\mu_0 + w_1 \\widehat{\\mu}_1 = p \\cdot h(0) + (1-p) \\frac{1}{n_1^\\star} \\sum_{j=1}^{n_1^\\star} h(Y_j)\n$$\n\n**4. 边缘情况：$p=1$**\n\n如果 $p=1$，则随机变量 $X$ 确定性地为 $0$。因此，$\\mathbb{E}[h(X)] = h(0)$ 是精确值。不需要进行估计。在这种情况下，$w_0=1$ 和 $w_1=0$。对于任何非零的 $n_0, n_1$，分层估计器的方差为 $\\mathrm{Var}(\\widehat{\\mu}) = \\frac{1^2 \\cdot 0^2}{n_0} + \\frac{0^2 \\cdot \\sigma_1^2}{n_1} = 0$。由于方差在没有任何抽样的情况下已经是零，最小化方差（和成本）的最优分配是 $n_0^\\star = 0$ 和 $n_1^\\star = 0$。估计器的值就是精确值 $h(0)$。\n\n**5. 精确值的解析计算**\n\n对于每个测试用例，精确值是 $\\mu = \\mathbb{E}[h(X)] = p \\cdot h(0) + (1-p) \\mathbb{E}[h(Y)]$，其中 $Y \\sim g$。$h(0)$ 和 $\\mathbb{E}[h(Y)]$ 的值计算如下：\n-   **用例 1:** $p=\\frac{1}{3}$，$Y \\sim \\text{Exp}(\\lambda=2)$，$h(x)=x + \\mathbf{1}\\{x1\\}$。$h(0)=0$。$\\mathbb{E}[h(Y)] = \\mathbb{E}[Y] + \\mathbb{P}(Y1) = \\frac{1}{\\lambda} + e^{-\\lambda} = \\frac{1}{2} + e^{-2}$。\n    $\\mu = (1/3) \\cdot 0 + (1-1/3)(\\frac{1}{2} + e^{-2}) = \\frac{1}{3} + \\frac{2}{3}e^{-2}$。\n-   **用例 2:** $p=0.99$，$Y \\sim \\text{Gamma}(k=3, \\theta=1)$，$h(x)=x^2$。$h(0)=0$。$\\mathbb{E}[h(Y)] = \\mathbb{E}[Y^2] = \\theta^2 k(k+1) = 1^2 \\cdot 3(4) = 12$。\n    $\\mu = (1-0.99)(12) = 0.12$。\n-   **用例 3:** $p=0.05$，$Y \\sim \\text{Lognormal}(\\mu_{ln}=0, \\sigma_{ln}=1)$，$h(x)=\\mathbf{1}\\{x2\\}$。$h(0)=0$。$\\mathbb{E}[h(Y)] = \\mathbb{P}(Y2) = 1-\\Phi(\\frac{\\ln(2)-\\mu_{ln}}{\\sigma_{ln}}) = 1-\\Phi(\\ln 2)$，其中 $\\Phi$ 是标准正态分布累积分布函数。\n    $\\mu = (1-0.05)(1-\\Phi(\\ln 2))$。\n-   **用例 4:** $p=1$，$h(x)=\\sqrt{x+1}-1$。$h(0)=0$。分布是在 $0$ 处的点质量。\n    $\\mu = \\mathbb{E}[h(X)] = h(0) = 0$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Computes stratified Monte Carlo estimates for a mixed random variable\n    based on optimal allocation derived from first principles.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            'p': 1/3,\n            'g': {'type': 'exponential', 'lambda': 2},\n            'h': lambda x: x + (x > 1).astype(float),\n            'B': 1000, 'c0': 1, 'c1': 1, 's': 12345\n        },\n        {\n            'p': 0.99,\n            'g': {'type': 'gamma', 'k': 3, 'theta': 1},\n            'h': lambda x: x**2,\n            'B': 200, 'c0': 1, 'c1': 1, 's': 12345\n        },\n        {\n            'p': 0.05,\n            'g': {'type': 'lognormal', 'mu': 0, 'sigma': 1},\n            'h': lambda x: (x > 2).astype(float),\n            'B': 500, 'c0': 1, 'c1': 1, 's': 12345\n        },\n        {\n            'p': 1,\n            'g': {'type': 'exponential', 'lambda': 1},\n            'h': lambda x: np.sqrt(x + 1) - 1,\n            'B': 50, 'c0': 1, 'c1': 1, 's': 12345\n        }\n    ]\n\n    results = []\n    \n    for k, case in enumerate(test_cases):\n        p = case['p']\n        g_params = case['g']\n        h = case['h']\n        B, c0, c1 = case['B'], case['c0'], case['c1']\n        seed = case['s']\n\n        # h(0) is needed for both estimator and exact value.\n        h_at_0 = h(np.array([0.0]))[0]\n        \n        # --- Optimal Allocation and Estimation ---\n        n0_star, n1_star = 0, 0\n        estimator_val = h_at_0  # Default for p=1\n\n        # The optimal allocation is n0=0, n1=floor(B/c1) unless p=1.\n        if p == 1:\n            # If p=1, X=0 deterministically. No sampling needed.\n            n0_star = 0\n            n1_star = 0\n            estimator_val = h_at_0\n        else:\n            # Allocate entire budget to stratum 1 (the continuous part).\n            n0_star = 0\n            n1_star = int(np.floor(B / c1))\n\n            if n1_star > 0:\n                rng = np.random.default_rng(seed + k)\n                samples_g = np.array([])\n                \n                if g_params['type'] == 'exponential':\n                    # scale = 1/lambda\n                    samples_g = rng.exponential(scale=1.0/g_params['lambda'], size=n1_star)\n                elif g_params['type'] == 'gamma':\n                    # shape=k, scale=theta\n                    samples_g = rng.gamma(shape=g_params['k'], scale=g_params['theta'], size=n1_star)\n                elif g_params['type'] == 'lognormal':\n                    # mean=mu, sigma=sigma\n                    samples_g = rng.lognormal(mean=g_params['mu'], sigma=g_params['sigma'], size=n1_star)\n                \n                h_samples = h(samples_g)\n                mu1_hat = np.mean(h_samples)\n                estimator_val = p * h_at_0 + (1 - p) * mu1_hat\n            else: # If budget is too small (n1_star = 0)\n                # No samples can be drawn, the estimator cannot be computed with sampling.\n                # In this problem setting, B/c1 >= 50, so n1_star > 0.\n                # If it were 0, the best one could do is use the known part.\n                estimator_val = p * h_at_0\n\n        # --- Analytic Calculation of Exact Value ---\n        exact_val = 0.0\n        E_hY = 0.0\n        \n        if g_params['type'] == 'exponential':\n            # E[h(Y)] for Y ~ Exp(lambda) and h(x) = x + 1_{x>1}\n            # E[Y] + P(Y>1) = 1/lambda + exp(-lambda)\n            lam = g_params['lambda']\n            E_hY = 1.0/lam + np.exp(-lam)\n        elif g_params['type'] == 'gamma':\n            # E[Y^2] for Y ~ Gamma(k, theta) = theta^2 * k * (k+1)\n            k_shape = g_params['k']\n            theta_scale = g_params['theta']\n            E_hY = (theta_scale**2) * k_shape * (k_shape + 1)\n        elif g_params['type'] == 'lognormal':\n            # E[1_{Y>2}] for Y ~ Lognormal(mu, sigma) = P(Y>2)\n            # P(Y>2) = 1 - Phi((ln(2)-mu)/sigma)\n            mu_ln = g_params['mu']\n            sigma_ln = g_params['sigma']\n            E_hY = 1.0 - norm.cdf((np.log(2) - mu_ln) / sigma_ln)\n\n        if p == 1:\n            exact_val = h_at_0\n        else:\n            exact_val = p * h_at_0 + (1 - p) * E_hY\n        \n        results.extend([n0_star, n1_star, estimator_val, exact_val])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{x:.7f}' if isinstance(x, float) else str(x) for x in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在分层抽样概念的基础上，本问题将处理一个更普遍的情景，并强调量化分析的重要性。我们将把我们设计的复杂方法的性能与一个更简单的基准方法进行比较。您将为一个混合分布实现一个使用奈曼分配（Neyman allocation）的分层估计器，其中原子层和连续层都对总方差有贡献。核心任务是解析地比较该估计器的方差与普通蒙特卡洛估计器的方差。这个练习不仅教您如何在一般情况下应用奈曼分配，还教您如何严格地证明和量化效率增益——这是计算科学中的一项关键技能。您将亲眼看到分层抽样在稀有事件场景下为何变得尤为强大 。",
            "id": "3333778",
            "problem": "设 $X$ 是一个混合随机变量，具有两个互斥的层：一个原子层和一个连续层。原子层以概率 $\\theta \\in (0,1)$ 被选中，此时 $X$ 等于三个原子 $\\{a_1,a_2,a_3\\} = \\{0.1,0.5,0.9\\}$ 中的一个，其条件概率为 $\\pi = (\\pi_1,\\pi_2,\\pi_3) = (0.5,0.3,0.2)$。连续层以概率 $1-\\theta$ 被选中，此时 $X$ 服从支撑集在区间 $[0,1]$ 上的 Beta 分布 $\\mathrm{Beta}(2,5)$。考虑目标事件集 $A = \\{0.5,1.1\\} \\cup [0.6,0.8]$，它包含孤立点和一个区间。\n\n您的任务是通过对原子集和连续补集进行分层来构建概率 $\\mathbb{P}(X \\in A)$ 的估计量，并应用 Neyman 分配法，在等成本抽样预算下最小化分层估计量的方差。然后，在原子层概率稀少的情况下，将分层估计量与普通蒙特卡洛（Monte Carlo (MC)）抽样进行比较。\n\n请使用以下纯粹的数学和算法术语进行操作。\n\n1. 定义指示随机变量 $Z = \\mathbf{1}\\{X \\in A\\}$。普通蒙特卡洛估计量使用来自其完整混合分布的 $X$ 的独立同分布样本。分层估计量将抽样划分到原子层和连续层，样本数量在每个样本成本相等的条件下使用 Neyman 分配法进行分配。\n2. 对于下面的每个测试用例，计算：\n   - 使用混合结构和 Beta 累积分布函数计算 $\\mathbb{P}(X \\in A)$ 的精确值。\n   - 使用大小为 $n$ 的独立样本的普通蒙特卡洛估计量的理论方差。\n   - 在总样本量同样为 $n$ 的 Neyman 分配下，分层估计量的理论方差，其中样本在原子层和连续层之间分配。\n   - 方差比，定义为分层方差除以普通蒙特卡洛方差。\n   - 在 Neyman 分配下，分配给原子层和连续层的整数样本数量，并遵守总预算。\n\n基本依据：使用混合随机变量、条件概率、指示随机变量以及独立抽样下样本均值方差的定义。原子层仅由位于 $\\{0.1,0.5,0.9\\}$ 的点质量组成，连续层关于勒贝格测度是绝对连续的。在每个样本成本相等的条件下，对于固定的总样本量 $n$，Neyman 分配法可以最小化分层估计量的方差。\n\n抽样预算和成本：假设各层的每个样本成本相等，固定的总样本量为 $n = 10000$ 个样本。所有计算结果均为无单位实数；请将任何数值答案表示为实值小数。\n\n测试套件：评估原子层概率 $\\theta$ 的以下四种参数体系：\n- 情况1：$\\theta = 0.0005$。\n- 情况2：$\\theta = 0.01$。\n- 情况3：$\\theta = 0.2$。\n- 情况4：$\\theta = 0.5$。\n\n答案规格：对于每个测试用例，按以下顺序生成一个包含六个条目的列表：\n- 精确概率 $\\mathbb{P}(X \\in A)$，以浮点数表示。\n- 普通蒙特卡洛方差，以浮点数表示。\n- Neyman 分配下的分层方差，以浮点数表示。\n- 方差比（分层方差除以普通蒙特卡洛方差），以浮点数表示。\n- 分配给原子层的整数样本数量。\n- 分配给连续层的整数样本数量。\n\n最终输出格式：您的程序应生成单行输出，其中包含四个测试用例的结果，形式为一个用方括号括起来的逗号分隔列表，其中每个元素是按上述顺序排列的单个测试用例的列表（例如，$[\\text{case1},\\text{case2},\\text{case3},\\text{case4}]$）。不应打印任何额外文本。",
            "solution": "该问题要求对普通蒙特卡洛（MC）抽样和分层抽样在估计混合随机变量事件概率方面的性能进行比较分析。我们将首先建立该问题的数学框架，包括精确概率，然后推导普通MC估计量和分层估计量的方差。\n\n设 $X$ 为混合随机变量。样本空间被划分为两层：原子层，由指示变量 $S=1$ 表示；连续层，由 $S=2$ 表示。选择这些层的概率由 $\\mathbb{P}(S=1) = \\theta$ 和 $\\mathbb{P}(S=2) = 1-\\theta$ 给出。\n\n如果 $S=1$（原子层），$X$ 从集合 $\\{a_1, a_2, a_3\\} = \\{0.1, 0.5, 0.9\\}$ 中取一个值，其条件概率为 $\\pi = (\\pi_1, \\pi_2, \\pi_3) = (0.5, 0.3, 0.2)$。\n\n如果 $S=2$（连续层），$X$ 服从参数为 $\\alpha=2$ 和 $\\beta=5$ 的 Beta 分布，$X \\sim \\mathrm{Beta}(\\alpha, \\beta)$，其支撑区间为 $[0,1]$。\n\n目标事件集为 $A = \\{0.5, 1.1\\} \\cup [0.6, 0.8]$。我们感兴趣的是估计 $p = \\mathbb{P}(X \\in A)$。待估计的量是指示随机变量 $Z = \\mathbf{1}\\{X \\in A\\}$ 的期望，即 $p = \\mathbb{E}[Z]$。\n\n**1. 精确概率 $\\mathbb{P}(X \\in A)$**\n\n根据全概率公式，精确概率 $p$ 由以下混合形式给出：\n$$p = \\mathbb{P}(X \\in A | S=1)\\mathbb{P}(S=1) + \\mathbb{P}(X \\in A | S=2)\\mathbb{P}(S=2)$$\n令 $p_1 = \\mathbb{P}(X \\in A | S=1)$ 且 $p_2 = \\mathbb{P}(X \\in A | S=2)$。层权重为 $W_1 = \\mathbb{P}(S=1) = \\theta$ 和 $W_2 = \\mathbb{P}(S=2) = 1-\\theta$。那么概率为 $p = W_1 p_1 + W_2 p_2$。\n\n首先，我们计算层内概率 $p_1$。在原子层中，$X$ 的取值可以是 $0.1$、$0.5$ 或 $0.9$。我们检查这些值中有哪些位于集合 $A = \\{0.5, 1.1\\} \\cup [0.6, 0.8]$ 中。\n- $X=0.1$：$0.1 \\notin A$。\n- $X=0.5$：$0.5 \\in A$。\n- $X=0.9$：$0.9 \\notin A$。\n因此，事件 $X \\in A$ 仅在 $X=0.5$ 时发生。其条件概率为 $\\pi_2$。\n$$p_1 = \\mathbb{P}(X=0.5 | S=1) = \\pi_2 = 0.3$$\n\n接下来，我们计算层内概率 $p_2$。在连续层中，$X \\sim \\mathrm{Beta}(2,5)$。对于一个连续随机变量，取任何单个值的概率为 $0$。因此，$\\mathbb{P}(X \\in \\{0.5, 1.1\\} | S=2) = 0$。概率 $p_2$ 完全由 $A$ 的区间部分决定。\n$$p_2 = \\mathbb{P}(X \\in [0.6, 0.8] | S=2)$$\n设 $F_{\\beta}(x; \\alpha, \\beta)$ 是 Beta 分布的累积分布函数（CDF）。则：\n$$p_2 = F_{\\beta}(0.8; 2, 5) - F_{\\beta}(0.6; 2, 5)$$\n通过计算评估，$p_2 \\approx 0.02677028$。\n\n总概率为 $p = \\theta(0.3) + (1-\\theta)p_2$。该值取决于测试用例的参数 $\\theta$。\n\n**2. 普通蒙特卡洛估计量方差**\n\n$p$ 的普通MC估计量是 $\\hat{p}_{MC} = \\frac{1}{n} \\sum_{i=1}^n Z_i$，其中 $Z_i$ 是 $Z = \\mathbf{1}\\{X \\in A\\}$ 的独立同分布样本。由于 $Z$ 是参数为 $p$ 的伯努利随机变量，其方差为 $\\mathrm{Var}(Z) = p(1-p)$。该估计量的方差是：\n$$\\mathrm{Var}(\\hat{p}_{MC}) = \\frac{\\mathrm{Var}(Z)}{n} = \\frac{p(1-p)}{n}$$\n这个方差将使用相应的 $p$ 值为每个 $\\theta$ 值计算。给定的总样本量为 $n=10000$。\n\n**3. 使用 Neyman 分配的分层估计量方差**\n\n$p$ 的分层估计量是 $\\hat{p}_{strat} = W_1 \\hat{p}_1 + W_2 \\hat{p}_2$，其中 $\\hat{p}_j$ 是在第 $j$ 层内，基于从该层抽取的 $n_j$ 个样本的指示变量的样本均值。该估计量的方差为：\n$$\\mathrm{Var}(\\hat{p}_{strat}) = \\frac{W_1^2 \\sigma_1^2}{n_1} + \\frac{W_2^2 \\sigma_2^2}{n_2}$$\n其中 $n_1+n_2=n$ 且 $\\sigma_j^2$ 是第 $j$ 层内指示变量的方差。\n$$\\sigma_1^2 = \\mathrm{Var}(Z|S=1) = p_1(1-p_1) = 0.3(1-0.3) = 0.21$$\n$$\\sigma_2^2 = \\mathrm{Var}(Z|S=2) = p_2(1-p_2) \\approx 0.02677028 \\times (1 - 0.02677028) \\approx 0.02605301$$\n\n对于固定的总样本量 $n$ 和相等的每样本成本，Neyman 分配法可以最小化 $\\mathrm{Var}(\\hat{p}_{strat})$。第 $j$ 层的样本量 $n_j$ 按与 $W_j \\sigma_j$ 成比例分配：\n$$n_j = n \\frac{W_j \\sigma_j}{\\sum_{k=1}^2 W_k \\sigma_k}$$\n其中 $\\sigma_j = \\sqrt{p_j(1-p_j)}$。对于我们的两层：\n$$n_1 = n \\frac{W_1 \\sigma_1}{W_1 \\sigma_1 + W_2 \\sigma_2} \\quad \\text{和} \\quad n_2 = n \\frac{W_2 \\sigma_2}{W_1 \\sigma_1 + W_2 \\sigma_2}$$\n由于样本数量必须是整数，我们计算理想的实值分配 $n_1^*$ 并将其四舍五入到最近的整数。剩余的样本分配给另一层，以保持总预算 $n$ 不变。\n$$n_1 = \\text{round}(n_1^*) \\quad \\text{和} \\quad n_2 = n - n_1$$\n使用这些整数分配，分层估计量的方差通过通用方差公式计算：\n$$\\mathrm{Var}(\\hat{p}_{strat}) = \\frac{W_1^2 \\sigma_1^2}{n_1} + \\frac{W_2^2 \\sigma_2^2}{n_2}$$\n\n**4. 计算摘要和方差比**\n\n对于每个测试用例的 $\\theta$ 值，我们执行以下计算：\n1.  计算层权重 $W_1 = \\theta$ 和 $W_2 = 1-\\theta$。\n2.  计算精确概率 $p = W_1 p_1 + W_2 p_2$。\n3.  计算普通MC方差 $\\mathrm{Var}(\\hat{p}_{MC}) = p(1-p)/n$。\n4.  基于 $W_1, \\sigma_1, W_2, \\sigma_2$ 计算 Neyman 分配比例。\n5.  确定在总预算 $n=10000$ 下的整数样本数量 $n_1$ 和 $n_2$。\n6.  计算最终的分层方差 $\\mathrm{Var}(\\hat{p}_{strat})$。\n7.  计算方差比 $\\mathrm{Var}(\\hat{p}_{strat}) / \\mathrm{Var}(\\hat{p}_{MC})$。\n\n所需的常数是：\n- $n = 10000$\n- $p_1 = 0.3$\n- $\\sigma_1 = \\sqrt{0.3 \\times 0.7} = \\sqrt{0.21} \\approx 0.45825757$\n- $p_2 = F_{\\beta}(0.8; 2, 5) - F_{\\beta}(0.6; 2, 5) \\approx 0.02677028$\n- $\\sigma_2 = \\sqrt{p_2(1-p_2)} \\approx 0.16140944$\n\n这些步骤在提供的测试套件中为每个 $\\theta$ 值实现。结果展示了 Neyman 分配如何调整抽样力度。当 $\\theta$ 很小时，原子层虽然稀有但方差较高（$\\sigma_1  \\sigma_2$），因此其抽样密度会比其权重 $W_1$ 所建议的要高。随着 $\\theta$ 的增加，分配越来越能反映层权重。在所有有效情况下，采用 Neyman 分配的分层抽样预计将产生小于或等于普通蒙特卡洛方差的方差，从而得到小于或等于 $1$ 的方差比。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import beta\n\ndef solve():\n    \"\"\"\n    Calculates exact probability, MC variance, stratified variance, variance ratio,\n    and sample allocations for a mixed random variable problem under four parameter regimes.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        0.0005, # Case 1\n        0.01,   # Case 2\n        0.2,    # Case 3\n        0.5,    # Case 4\n    ]\n\n    # --- Problem Constants ---\n    # Total sample size\n    n = 10000\n\n    # Atomic stratum properties\n    # Atoms: {0.1, 0.5, 0.9} with probs (0.5, 0.3, 0.2)\n    # Target set A = {0.5, 1.1} U [0.6, 0.8]\n    # Only atom 0.5 is in A.\n    p1 = 0.3  # P(X in A | atomic) = P(X=0.5)\n    sigma1_sq = p1 * (1 - p1)\n    sigma1 = np.sqrt(sigma1_sq)\n\n    # Continuous stratum properties\n    # X ~ Beta(2, 5) on [0, 1]\n    # Target set A = {0.5, 1.1} U [0.6, 0.8]\n    # For a continuous RV, P(X=x) = 0.\n    alpha, beta_param = 2, 5\n    p2 = beta.cdf(0.8, alpha, beta_param) - beta.cdf(0.6, alpha, beta_param) # P(X in [0.6, 0.8])\n    sigma2_sq = p2 * (1 - p2)\n    sigma2 = np.sqrt(sigma2_sq)\n    \n    results = []\n    for theta in test_cases:\n        # --- Calculations for the current test case (theta) ---\n\n        # Stratum weights\n        w1 = theta\n        w2 = 1 - theta\n\n        # 1. Exact probability P(X in A)\n        p_exact = w1 * p1 + w2 * p2\n\n        # 2. Plain Monte Carlo variance\n        var_mc = (p_exact * (1 - p_exact)) / n\n\n        # 3. Neyman allocation\n        # Denominator for allocation formula\n        alloc_denom = w1 * sigma1 + w2 * sigma2\n        \n        # Ideal (real-valued) allocation for stratum 1\n        n1_ideal = n * (w1 * sigma1) / alloc_denom\n        \n        # 5. Integer sample counts\n        # Round n1 and derive n2 to respect the total budget\n        n1_alloc = int(np.round(n1_ideal))\n        n2_alloc = n - n1_alloc\n\n        # Handle edge cases where rounding might lead to a zero allocation, although\n        # not expected for the given parameters.\n        if n1_alloc == 0: n1_alloc = 1; n2_alloc = n - 1\n        if n2_alloc == 0: n2_alloc = 1; n1_alloc = n - 1\n\n        # 4. Stratified variance under Neyman allocation\n        # Calculated using the actual integer allocations\n        var_strat = (w1**2 * sigma1_sq / n1_alloc) + (w2**2 * sigma2_sq / n2_alloc)\n        \n        # 5. Variance ratio\n        variance_ratio = var_strat / var_mc\n        \n        # Compile results for the case\n        case_results = [\n            p_exact,\n            var_mc,\n            var_strat,\n            variance_ratio,\n            n1_alloc,\n            n2_alloc,\n        ]\n        results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # The format [list1, list2, ...] is produced by str() on a list of lists.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}