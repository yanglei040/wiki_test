{
    "hands_on_practices": [
        {
            "introduction": "贝叶斯定理的一个特别优雅的应用体现在共轭先验的框架中，此时后验分布与先验分布属于同一族分布，从而极大地简化了分析计算。这项实践练习  将引导你通过一个经典案例——使用$\\mathrm{Gamma}$分布作为先验来更新对$\\mathrm{Poisson}$过程速率参数的认知。掌握这个经典的$\\mathrm{Gamma}$-$\\mathrm{Poisson}$共轭模型，是理解如何以数学上易于处理的方式利用证据更新信念的基石。",
            "id": "3290545",
            "problem": "考虑一个计数观测值 $x \\in \\{0,1,2,\\dots\\}$，它是在给定率参数 $\\lambda>0$ 的条件下，根据暴露度为 $n>0$ 的泊松似然生成的，即 $x \\mid \\lambda \\sim \\mathrm{Poisson}(n \\lambda)$。假设 $\\lambda$ 的先验分布为形状参数为 $a>0$、率参数为 $b>0$ 的伽马分布，写成形状-率参数化形式，即 $\\lambda$ 的先验密度为 $p(\\lambda) = \\frac{b^{a}}{\\Gamma(a)} \\lambda^{a-1} \\exp(-b \\lambda)$（对于 $\\lambda>0$），其中 $\\Gamma(\\cdot)$ 表示伽马函数。\n\n使用连续参数的贝叶斯定理和泊松似然的标准形式 $p(x \\mid \\lambda) = \\exp(-n \\lambda) \\frac{(n \\lambda)^{x}}{x!}$，推导后验密度 $p(\\lambda \\mid x)$，确定其分布族，并用 $a$、$b$、$n$ 和 $x$ 明确地表示更新后的超参数。\n\n然后，计算后验均值 $\\mathbb{E}[\\lambda \\mid x]$ 和后验方差 $\\mathrm{Var}[\\lambda \\mid x]$ 的闭式解。将最终答案表示为关于 $a$、$b$、$n$ 和 $x$ 的解析表达式。无需四舍五入。",
            "solution": "该问题是有效的，因为它是贝叶斯统计学中一个适定的、有科学依据的标准练习。它内容完备，提供了所有必要的定义和条件，并且没有矛盾或歧义。\n\n目标是推导率参数 $\\lambda$ 的后验分布，并计算其均值和方差。我们已知观测计数 $x$ 的泊松似然和 $\\lambda$ 的伽马先验。\n\n给定的组成部分是：\n1.  似然函数，从 $x \\mid \\lambda \\sim \\mathrm{Poisson}(n\\lambda)$ 导出：\n    $$p(x \\mid \\lambda) = \\frac{(n\\lambda)^x \\exp(-n\\lambda)}{x!}$$\n    其中 $x \\in \\{0, 1, 2, \\dots\\}$，$n>0$，且 $\\lambda>0$。\n2.  $\\lambda$ 的先验分布，即形状参数为 $a>0$、率参数为 $b>0$ 的伽马分布：$\\lambda \\sim \\mathrm{Gamma}(a, b)$。\n    先验概率密度函数为：\n    $$p(\\lambda) = \\frac{b^a}{\\Gamma(a)} \\lambda^{a-1} \\exp(-b\\lambda)$$\n\n根据连续参数的贝叶斯定理，后验密度 $p(\\lambda \\mid x)$ 与似然 $p(x \\mid \\lambda)$ 和先验 $p(\\lambda)$ 的乘积成正比：\n$$p(\\lambda \\mid x) \\propto p(x \\mid \\lambda) p(\\lambda)$$\n\n代入似然和先验的给定表达式：\n$$p(\\lambda \\mid x) \\propto \\left( \\frac{(n\\lambda)^x \\exp(-n\\lambda)}{x!} \\right) \\left( \\frac{b^a}{\\Gamma(a)} \\lambda^{a-1} \\exp(-b\\lambda) \\right)$$\n\n为了找到关于 $\\lambda$ 的后验密度的函数形式，我们可以将所有与 $\\lambda$ 无关的常数项合并到比例常数中。这些项是 $\\frac{n^x}{x!}$ 和 $\\frac{b^a}{\\Gamma(a)}$。\n$$p(\\lambda \\mid x) \\propto (\\lambda^x \\exp(-n\\lambda)) (\\lambda^{a-1} \\exp(-b\\lambda))$$\n\n现在，我们合并 $\\lambda$ 的幂和指数函数的参数：\n$$p(\\lambda \\mid x) \\propto \\lambda^{x} \\lambda^{a-1} \\exp(-n\\lambda) \\exp(-b\\lambda)$$\n$$p(\\lambda \\mid x) \\propto \\lambda^{x+a-1} \\exp(-(n+b)\\lambda)$$\n\n该表达式是 $\\lambda$ 的概率密度函数的核。我们识别出这是伽马分布的核。一个形状参数为 $\\alpha'$、率参数为 $\\beta'$ 的伽马分布，其概率密度函数正比于 $\\lambda^{\\alpha'-1} \\exp(-\\beta'\\lambda)$。\n\n通过将我们的结果 $p(\\lambda \\mid x) \\propto \\lambda^{(a+x)-1} \\exp(-(b+n)\\lambda)$ 与通用形式进行比较，我们可以确定后验分布的参数。\n给定 $x$ 时 $\\lambda$ 的后验分布是一个伽马分布，我们可以写作：\n$$\\lambda \\mid x \\sim \\mathrm{Gamma}(\\alpha', \\beta')$$\n更新后的超参数（即后验参数）是：\n-   后验形状：$\\alpha' = a + x$\n-   后验率：$\\beta' = b + n$\n\n这表明伽马分布是泊松似然的率参数的共轭先验。因此，后验密度函数是：\n$$p(\\lambda \\mid x) = \\frac{(b+n)^{a+x}}{\\Gamma(a+x)} \\lambda^{(a+x)-1} \\exp(-(b+n)\\lambda)$$\n\n接下来，题目要求我们求出后验均值 $\\mathbb{E}[\\lambda \\mid x]$ 和后验方差 $\\mathrm{Var}[\\lambda \\mid x]$。对于一个服从形状参数为 $\\alpha$、率参数为 $\\beta$ 的伽马分布的随机变量 $Y$，即 $Y \\sim \\mathrm{Gamma}(\\alpha, \\beta)$，其均值和方差由以下标准公式给出：\n$$\\mathbb{E}[Y] = \\frac{\\alpha}{\\beta}$$\n$$\\mathrm{Var}[Y] = \\frac{\\alpha}{\\beta^2}$$\n\n将这些公式应用于我们的后验分布 $\\lambda \\mid x \\sim \\mathrm{Gamma}(a+x, b+n)$，我们将形状参数替换为 $\\alpha' = a+x$，率参数替换为 $\\beta' = b+n$。\n\n$\\lambda$ 的后验均值是：\n$$\\mathbb{E}[\\lambda \\mid x] = \\frac{\\alpha'}{\\beta'} = \\frac{a+x}{b+n}$$\n\n$\\lambda$ 的后验方差是：\n$$\\mathrm{Var}[\\lambda \\mid x] = \\frac{\\alpha'}{(\\beta')^2} = \\frac{a+x}{(b+n)^2}$$\n\n这些就是以后验均值和方差关于给定参数 $a、b、n$ 和观测值 $x$ 的闭式表达式。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{a+x}{b+n} & \\frac{a+x}{(b+n)^2}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "真实世界的数据常常具有分组或嵌套结构，分层模型正是在这种情境下大放异彩。这项实践  深入探讨了一个分层正态模型，旨在推导组别特定参数的后验均值。通过这个推导，你将揭示“收缩”(shrinkage)这一核心概念，即各组的独立估计会被拉向一个共同的均值，这体现了分层模型如何智能地在组间“借力”(borrow strength)以获得更稳健的推断结果。",
            "id": "3290513",
            "problem": "考虑随机模拟和层级蒙特卡洛分析中常用的层级正态模型。存在 $m$ 个组，索引为 $i \\in \\{1,\\dots,m\\}$，在每个组 $i$ 中，有 $n_i$ 个观测值 $x_{ij}$，$j \\in \\{1,\\dots,n_i\\}$。数据模型和先验分布为\n$$\nx_{ij} \\mid \\theta_i \\sim \\mathcal{N}(\\theta_i,\\sigma^2), \\quad \\theta_i \\mid \\mu \\sim \\mathcal{N}(\\mu,\\tau^2), \\quad \\mu \\sim \\mathcal{N}(m_0,s_0^2),\n$$\n其中 $\\sigma^2>0$, $\\tau^2>0$, $s_0^2>0$ 和 $m_0 \\in \\mathbb{R}$ 为已知。令 $\\bar{x}_i = \\frac{1}{n_i}\\sum_{j=1}^{n_i} x_{ij}$ 表示组 $i$ 内的样本均值，令 $x$ 表示完整的观测集合 $\\{x_{ij}\\}_{i,j}$。仅从贝叶斯定理和正态分布的标准性质出发，推导该模型下后验均值 $E[\\theta_i \\mid x]$ 的闭式表达式，并将其表示为一个收缩估计量，该估计量线性地组合了组内均值 $\\bar{x}_i$ 和一个由数据决定的整体位置。你的最终答案必须是关于 $\\bar{x}_i$, $n_i$, $\\sigma^2$, $\\tau^2$, $m_0$, $s_0^2$ 以及集合 $\\{\\bar{x}_k,n_k\\}_{k=1}^m$ 的 $E[\\theta_i \\mid x]$ 的单一闭式解析表达式。不需要数值近似，也没有单位适用。",
            "solution": "问题陈述是有效的。它描述了一个标准的层级正态模型，这是贝叶斯统计和随机模拟中的一个基本课题，并要求对后验均值进行严格推导。所有参数和分布都已明确定义，任务阐述清晰。我们开始求解。\n\n问题是推导由以下方式指定的层级模型的后验均值 $E[\\theta_i \\mid x]$：\n$1$. 数据模型：$x_{ij} \\mid \\theta_i \\sim \\mathcal{N}(\\theta_i, \\sigma^2)$，对于 $i \\in \\{1,\\dots,m\\}$ 和 $j \\in \\{1,\\dots,n_i\\}$。\n$2$. 第一层先验：$\\theta_i \\mid \\mu \\sim \\mathcal{N}(\\mu, \\tau^2)$。\n$3$. 超先验：$\\mu \\sim \\mathcal{N}(m_0, s_0^2)$。\n参数 $\\sigma^2$、$\\tau^2$、 $s_0^2$ 和 $m_0$ 是已知的常数。完整数据由 $x = \\{x_{ij}\\}_{i,j}$ 表示。\n\n推导过程分三个主要阶段。首先，我们确定在给定数据 $x$ 和超参数 $\\mu$ 的条件下 $\\theta_i$ 的条件后验期望。其次，我们确定在给定数据 $x$ 的条件下 $\\mu$ 的后验分布。最后，我们使用全期望定律结合这些结果，求出边际后验期望 $E[\\theta_i \\mid x]$。\n\n**步骤1：条件后验期望 $E[\\theta_i \\mid x, \\mu]$**\n\n我们首先求在给定 $\\mu$ 和数据 $x$ 的条件下 $\\theta_i$ 的后验分布。由于模型的结构，对于一个给定的组 $i$，一旦 $\\theta_i$ 已知，其观测值 $x_{ij}$ 就条件独立于 $\\mu$ 和所有其他数据 $x_{kj}$ ($k \\neq i$) 。因此，$p(\\theta_i \\mid x, \\mu) = p(\\theta_i \\mid \\{x_{ij}\\}_{j=1}^{n_i}, \\mu)$。\n来自数据 $\\{x_{ij}\\}_{j=1}^{n_i}$ 的关于 $\\theta_i$ 的充分统计量是样本均值 $\\bar{x}_i = \\frac{1}{n_i}\\sum_{j=1}^{n_i} x_{ij}$。该统计量的抽样分布为 $\\bar{x}_i \\mid \\theta_i \\sim \\mathcal{N}(\\theta_i, \\sigma^2/n_i)$。\n\n我们应用贝叶斯定理来求 $\\theta_i$ 的后验分布：\n$$ p(\\theta_i \\mid \\bar{x}_i, \\mu) \\propto p(\\bar{x}_i \\mid \\theta_i) p(\\theta_i \\mid \\mu) $$\n似然函数是 $p(\\bar{x}_i \\mid \\theta_i)$，对应于 $\\mathcal{N}(\\theta_i, \\sigma^2/n_i)$，先验分布是 $p(\\theta_i \\mid \\mu)$，对应于 $\\mathcal{N}(\\mu, \\tau^2)$。两个正态概率密度函数的乘积与 $\\theta_i$ 的二次函数的指数成正比，这意味着后验分布也是正态的。对于一个正态-正态共轭对，后验均值是先验均值和似然均值的精度加权平均。\n\n令似然的精度为 $\\pi_{\\text{data}, i} = \\frac{1}{\\sigma^2/n_i} = \\frac{n_i}{\\sigma^2}$，先验的精度为 $\\pi_{\\text{prior}} = \\frac{1}{\\tau^2}$。\n后验均值为：\n$$ E[\\theta_i \\mid x, \\mu] = E[\\theta_i \\mid \\bar{x}_i, \\mu] = \\frac{\\pi_{\\text{data}, i} \\cdot \\bar{x}_i + \\pi_{\\text{prior}} \\cdot \\mu}{\\pi_{\\text{data}, i} + \\pi_{\\text{prior}}} = \\frac{\\frac{n_i}{\\sigma^2}\\bar{x}_i + \\frac{1}{\\tau^2}\\mu}{\\frac{n_i}{\\sigma^2} + \\frac{1}{\\tau^2}} $$\n分子和分母同乘以 $\\sigma^2\\tau^2$ 得：\n$$ E[\\theta_i \\mid x, \\mu] = \\frac{n_i\\tau^2 \\bar{x}_i + \\sigma^2 \\mu}{n_i\\tau^2 + \\sigma^2} $$\n这个表达式可以写成一个加权平均，或一个“收缩”估计量：\n$$ E[\\theta_i \\mid x, \\mu] = \\left(\\frac{n_i\\tau^2}{n_i\\tau^2 + \\sigma^2}\\right)\\bar{x}_i + \\left(\\frac{\\sigma^2}{n_i\\tau^2 + \\sigma^2}\\right)\\mu $$\n令 $B_i = \\frac{n_i\\tau^2}{n_i\\tau^2 + \\sigma^2}$。则 $1-B_i = \\frac{\\sigma^2}{n_i\\tau^2 + \\sigma^2}$，我们有 $E[\\theta_i \\mid x, \\mu] = B_i \\bar{x}_i + (1-B_i)\\mu$。\n\n**步骤2：给定 $x$ 的 $\\mu$ 的后验分布**\n\n接下来，我们推导后验分布 $p(\\mu \\mid x)$。根据贝叶斯定理：\n$$ p(\\mu \\mid x) \\propto p(x \\mid \\mu) p(\\mu) $$\n先验分布给定为 $p(\\mu) \\sim \\mathcal{N}(m_0, s_0^2)$。\n似然函数 $p(x \\mid \\mu)$ 可以用充分统计量 $\\{\\bar{x}_k\\}_{k=1}^m$ 来表示：\n$$ p(x \\mid \\mu) = p(\\{\\bar{x}_k\\}_{k=1}^m \\mid \\mu) = \\prod_{k=1}^m p(\\bar{x}_k \\mid \\mu) $$\n这里使用了给定 $\\mu$ 时 $\\bar{x}_k$ 的条件独立性。\n为了求 $p(\\bar{x}_k \\mid \\mu)$，我们对中间参数 $\\theta_k$ 进行积分消元：\n$$ p(\\bar{x}_k \\mid \\mu) = \\int p(\\bar{x}_k \\mid \\theta_k) p(\\theta_k \\mid \\mu) d\\theta_k $$\n这是两个正态分布的卷积：$\\bar{x}_k \\mid \\theta_k \\sim \\mathcal{N}(\\theta_k, \\sigma^2/n_k)$ 和 $\\theta_k \\mid \\mu \\sim \\mathcal{N}(\\mu, \\tau^2)$。得到的 $\\bar{x}_k$ 的分布也是正态的，其均值等于均值之和，方差等于方差之和：\n$$ \\bar{x}_k \\mid \\mu \\sim \\mathcal{N}(\\mu, \\tau^2 + \\sigma^2/n_k) $$\n现在我们面临一个标准问题：对于一个带有正态先验的正态分布的均值 $\\mu$，在给定 $m$ 个具有不同已知方差的独立观测值 $\\{\\bar{x}_k\\}$ 的情况下，求其后验分布。\n后验分布 $p(\\mu \\mid x)$ 是正态的。后验均值 $E[\\mu \\mid x]$ 是先验均值 $m_0$ 和观测值 $\\bar{x}_k$ 的精度加权平均。\n$\\mu$ 的先验精度是 $\\pi_{\\mu,0} = \\frac{1}{s_0^2}$。\n第 $k$ 个观测值 $\\bar{x}_k$ 的精度是 $\\pi_{\\mu,k} = \\frac{1}{\\tau^2 + \\sigma^2/n_k}$。\n后验均值 $E[\\mu \\mid x]$ 是：\n$$ E[\\mu \\mid x] = \\frac{\\pi_{\\mu,0} m_0 + \\sum_{k=1}^m \\pi_{\\mu,k} \\bar{x}_k}{\\pi_{\\mu,0} + \\sum_{k=1}^m \\pi_{\\mu,k}} = \\frac{\\frac{1}{s_0^2} m_0 + \\sum_{k=1}^m \\frac{1}{\\tau^2 + \\sigma^2/n_k} \\bar{x}_k}{\\frac{1}{s_0^2} + \\sum_{k=1}^m \\frac{1}{\\tau^2 + \\sigma^2/n_k}} $$\n为了代数上的清晰，我们可以写作 $\\frac{1}{\\tau^2 + \\sigma^2/n_k} = \\frac{n_k}{n_k\\tau^2 + \\sigma^2}$。让我们记 $\\hat{\\mu} = E[\\mu \\mid x]$。那么\n$$ \\hat{\\mu} = \\frac{\\frac{m_0}{s_0^2} + \\sum_{k=1}^m \\frac{n_k \\bar{x}_k}{n_k\\tau^2 + \\sigma^2}}{\\frac{1}{s_0^2} + \\sum_{k=1}^m \\frac{n_k}{n_k\\tau^2 + \\sigma^2}} $$\n\n**步骤3：最终的无条件后验期望 $E[\\theta_i \\mid x]$**\n\n最后，我们使用全期望定律（也称为塔性质或平滑性质）：\n$$ E[\\theta_i \\mid x] = E_{\\mu \\mid x}\\left[ E[\\theta_i \\mid x, \\mu] \\right] $$\n代入步骤1中 $E[\\theta_i \\mid x, \\mu]$ 的表达式：\n$$ E[\\theta_i \\mid x] = E_{\\mu \\mid x}\\left[ B_i \\bar{x}_i + (1-B_i)\\mu \\right] $$\n由于在此期望中 $B_i$ 和 $\\bar{x}_i$ 被视为常数（它们不依赖于后验分布 $p(\\mu \\mid x)$ 中的随机变量 $\\mu$），我们可以写成：\n$$ E[\\theta_i \\mid x] = B_i \\bar{x}_i + (1-B_i) E_{\\mu \\mid x}[\\mu] = B_i \\bar{x}_i + (1-B_i)\\hat{\\mu} $$\n代入 $B_i$ 和 $\\hat{\\mu}$ 的表达式：\n$$ E[\\theta_i \\mid x] = \\left(\\frac{n_i\\tau^2}{n_i\\tau^2 + \\sigma^2}\\right)\\bar{x}_i + \\left(\\frac{\\sigma^2}{n_i\\tau^2 + \\sigma^2}\\right) \\hat{\\mu} $$\n其中 $\\hat{\\mu}$ 是在步骤2中推导出的由数据决定的整体位置。\n因此，完整的表达式为：\n$$ E[\\theta_i \\mid x] = \\left(\\frac{n_i\\tau^2}{n_i\\tau^2 + \\sigma^2}\\right)\\bar{x}_i + \\left(\\frac{\\sigma^2}{n_i\\tau^2 + \\sigma^2}\\right) \\left( \\frac{\\frac{m_0}{s_0^2} + \\sum_{k=1}^m \\frac{n_k \\bar{x}_k}{n_k\\tau^2 + \\sigma^2}}{\\frac{1}{s_0^2} + \\sum_{k=1}^m \\frac{n_k}{n_k\\tau^2 + \\sigma^2}} \\right) $$\n这个表达式将 $\\theta_i$ 的后验均值表示为一个收缩估计量。它是特定于组的均值 $\\bar{x}_i$ 和一个汇集了所有组信息及超先验信息的整体均值估计 $\\hat{\\mu}$ 的线性组合。权重因子 $B_i$ 控制了向整体均值收缩的程度，这取决于组层面数据的相对精度与组间变异的对比。",
            "answer": "$$\n\\boxed{\\left(\\frac{n_i \\tau^2}{n_i \\tau^2 + \\sigma^2}\\right) \\bar{x}_i + \\left(\\frac{\\sigma^2}{n_i \\tau^2 + \\sigma^2}\\right) \\left( \\frac{\\frac{m_0}{s_0^2} + \\sum_{k=1}^m \\frac{n_k \\bar{x}_k}{n_k \\tau^2 + \\sigma^2}}{\\frac{1}{s_0^2} + \\sum_{k=1}^m \\frac{n_k}{n_k \\tau^2 + \\sigma^2}} \\right)}\n$$"
        },
        {
            "introduction": "对于许多现代复杂模型而言，其似然函数是难以处理的(intractable)，这使得贝叶斯定理的直接应用变得不可能。这项高级计算实践  旨在应对这一挑战，它引入了噪声对比估计(Noise-Contrastive Estimation, NCE)——一种处于机器学习与统计学交叉前沿的强大技术。你将亲手实现一个系统，该系统通过训练一个分类器来近似对数似然比，并利用这个代理(proxy)来构建近似后验分布，从而获得关于前沿的模拟为基推断(simulation-based inference)方法的实践经验。",
            "id": "3290514",
            "problem": "给定一个生成模型和一个基于模拟的推断任务，该任务必须通过结合噪声对比估计 (Noise-Contrastive Estimation, NCE) 和贝叶斯定理来解决。目的是研究分类器分数如何能够代理对数似然，以及校准如何修正最终的后验分布。底层的生成模型如下：对于一个标量参数 $\\theta \\in \\mathbb{R}$ 和已知的噪声方差 $\\sigma^{2} > 0$，观测模型为 $x \\mid \\theta \\sim \\mathcal{N}(\\theta, \\sigma^{2})$。先验为 $\\theta \\sim \\mathcal{N}(0, \\tau^{2})$，其中方差 $\\tau^{2} > 0$ 已知。NCE 使用一个固定的、由用户选择的辅助噪声分布 $q(x)$，其中 $x \\sim \\mathcal{N}(0, s_{q}^{2})$ 且方差 $s_{q}^{2} > 0$ 已知。所有量都是一维的。你将通过带有受限线性 logit 的二元逻辑斯蒂回归来实现 NCE，这是一种故意的模型错配，然后将得到的分类器分数嵌入贝叶斯定理，研究后验扭曲，最后使用温度缩放进行校准来修正。\n\n使用的基本理论基础包括以下内容：用于推导在类条件密度下最优分类器的二分类贝叶斯定理、逻辑斯蒂回归模型的定义、逻辑斯蒂函数的定义、无意识统计学家法则以及 Kullback–Leibler 散度的定义。\n\n你的程序必须为每个测试用例实现以下流程，仅使用模拟和确定性优化，并使用固定的随机种子以保证可复现性：\n\n1. 构建一个参数值的离散网格 $\\{\\theta_{j}\\}_{j=1}^{J}$，其中 $J$ 在所有测试用例中是固定的。使用一个对称网格 $\\theta_{j} \\in [-T, T]$，其具有均匀间距 $h$，其中 $T = 4.0$，$h = 0.2$，因此有 $J = 41$ 个点。该网格作为后验计算的离散支撑集。\n\n2. 对于每个网格点 $\\theta_{j}$，生成两个带标签的数据集：\n   - 一个大小为 $n_{\\text{train}}$ 的正类数据集，其样本独立同分布于 $p_{\\theta_{j}}(x) = \\mathcal{N}(\\theta_{j}, \\sigma^{2})$，标签为 $y = 1$。\n   - 一个大小为 $n_{\\text{train}}$ 的负类数据集，其样本独立同分布于 $q(x) = \\mathcal{N}(0, s_{q}^{2})$，标签为 $y = 0$。\n   在整个程序中对所有随机性使用固定的种子，且优化过程中无随机性。\n\n3. 通过最小化针对该 $\\theta_{j}$ 的训练数据的交叉熵，来拟合一个带有线性 logit $r_{\\theta_{j}}(x) = w_{0}^{(j)} + w_{1}^{(j)} x$ 的二元逻辑斯蒂回归分类器。优化使用精确的牛顿更新，并仅在斜率上施加一个极小的 $\\ell_{2}$ 正则化（截距上无惩罚）以确保数值稳定性。在训练中使用类别均等采样。这将为每个 $\\theta_{j}$ 生成一个原始分数函数 $r_{\\theta_{j}}(x)$。\n\n4. 对于每个 $\\theta_{j}$，独立地生成一个验证数据集，包含 $n_{\\text{val}}$ 个从 $p_{\\theta_{j}}(x)$ 中抽取的独立同分布样本（标签 $y=1$）和 $n_{\\text{val}}$ 个从 $q(x)$ 中抽取的独立同分布样本（标签 $y=0$）。通过寻找一个标量 $\\alpha^{(j)} > 0$ 来执行温度缩放校准，该标量使得当校准后的类别概率为 $\\sigma(\\alpha^{(j)} r_{\\theta_{j}}(x))$ 时，验证交叉熵最小化，其中 $\\sigma(\\cdot)$ 是逻辑斯蒂 sigmoid 函数。为 $\\alpha^{(j)}$ 的凸目标实现一个一维牛顿法，初始化 $\\alpha^{(j)} = 1$，并通过投影强制施加正性约束。\n\n5. 对于单个观测值 $x_{\\text{obs}}$，计算在 $\\{\\theta_{j}\\}$ 上的三个离散后验分布：\n   - 精确的离散后验权重与 $p(\\theta_{j}) p(x_{\\text{obs}} \\mid \\theta_{j})$ 成正比，其中 $p(\\theta)$ 是 $\\mathcal{N}(0, \\tau^{2})$ 的密度，而 $p(x \\mid \\theta)$ 是 $\\mathcal{N}(\\theta, \\sigma^{2})$。通过除以对所有 $j$ 的总和进行归一化，得到一个正常的离散分布。\n   - 未校准的基于 NCE 的近似离散后验权重与 $p(\\theta_{j}) \\exp(r_{\\theta_{j}}(x_{\\text{obs}}))$ 成正比。对所有 $j$ 进行归一化，得到一个正常的离散分布。\n   - 校准后的基于 NCE 的近似离散后验权重与 $p(\\theta_{j}) \\exp(\\alpha^{(j)} r_{\\theta_{j}}(x_{\\text{obs}}))$ 成正比。对所有 $j$ 进行归一化。\n\n6. 对于每个测试用例，计算两个量化后验扭曲的标量诊断指标：\n   - 从精确离散后验到未校准近似的 Kullback–Leibler 散度，定义为 $D_{\\mathrm{KL}}(P \\Vert Q) = \\sum_{j=1}^{J} P_{j} \\log\\left(\\frac{P_{j}}{Q_{j}}\\right)$，使用自然对数，其中 $P$ 是精确后验，$Q$ 是近似后验。\n   - 从精确离散后验到校准后近似的 Kullback–Leibler 散度，计算方法相同，但使用校准后的后验。\n\n你的实现细节必须满足：\n- 对所有随机数生成使用固定的随机种子 $s_{0} = 12345$。\n- 对逻辑斯蒂函数和后验归一化使用数值稳定的计算（采用 log-sum-exp 稳定化方法）。\n- 在分类器中仅使用线性特征 $x$，以便在 $s_{q}^{2} \\neq \\sigma^{2}$ 时有意引入模型错配，从而产生不可忽略的校准效应。\n- 不允许使用外部数据源或用户输入。\n\n测试套件：\n在以下四个测试用例上评估程序，每个用例由 $(\\sigma^{2}, \\tau^{2}, s_{q}^{2}, x_{\\text{obs}}, n_{\\text{train}}, n_{\\text{val}})$ 指定：\n- 用例 A（中等样本量，故意的噪声错配）：$(1.0, 4.0, 4.0, 1.0, 200, 100)$。\n- 用例 B（小样本量，故意的噪声错配）：$(1.0, 4.0, 4.0, 1.0, 30, 30)$。\n- 用例 C（良好指定的噪声和更紧的先验）：$(1.0, 1.0, 1.0, 0.0, 200, 100)$。\n- 用例 D（中等样本量，轻度错配，极端观测值）：$(1.0, 4.0, 2.0, 3.0, 200, 100)$。\n\n要求的最终输出格式：\n你的程序应生成单行输出，包含对应于四个测试用例的八个结果，按 A、B、C、D 的顺序排列，每个用例贡献两个浮点数：首先是未校准的 Kullback–Leibler 散度，然后是校准后的 Kullback–Leibler 散度。格式必须是一个逗号分隔的列表，包含在这八个数字序列中，并用方括号括起来，例如 `[r_{1}, r_{2}, r_{3}, r_{4}, r_{5}, r_{6}, r_{7}, r_{8}]`。不应打印任何其他文本。",
            "solution": "该问题要求实现一个基于模拟的推断流程，以近似贝叶斯后验分布。这是通过利用噪声对比估计 (Noise-Contrastive Estimation, NCE) 的原理来实现的，其中，我们训练一个二元分类器来区分来自生成模型 $p(x|\\theta)$ 的数据和来自辅助噪声分布 $q(x)$ 的数据。学习到的分类器输出可以作为对数似然比的代理，然后将其整合到贝叶斯定理中。分析的重点是由于故意的模型错配导致的后验分布扭曲，以及随后使用温度缩放进行的修正。\n\n首先，我们建立理论联系。对于一个具有特征向量 $x$ 和类别标签 $y \\in \\{0, 1\\}$ 的二分类问题，用于分类器的贝叶斯定理指出，类别 $1$ 的后验概率为 $P(y=1|x) = \\frac{p(x|y=1)P(y=1)}{p(x|y=1)P(y=1) + p(x|y=0)P(y=0)}$。logit 或对数几率是 $\\text{logit}(P(y=1|x)) = \\log\\left(\\frac{p(x|y=1)}{p(x|y=0)}\\right) + \\log\\left(\\frac{P(y=1)}{P(y=0)}\\right)$。在我们的 NCE 设置中，对于一个固定的参数 $\\theta_j$，我们将 $p(x|y=1)$ 等同于数据生成分布 $p_{\\theta_j}(x) = \\mathcal{N}(x; \\theta_j, \\sigma^2)$，并将 $p(x|y=0)$ 等同于噪声分布 $q(x) = \\mathcal{N}(x; 0, s_q^2)$。通过对每个类别使用相等的训练样本量（$n_{\\text{train}}$），我们有效地将经验类别先验设置为相等，即 $P(y=1) = P(y=0) = 0.5$。在这种情况下，最优分类器的 logit 正是对数似然比：$\\log\\left(\\frac{p_{\\theta_j}(x)}{q(x)}\\right)$。该对数比由下式给出：\n$$ \\log\\left(\\frac{p_{\\theta_j}(x)}{q(x)}\\right) = \\log\\left(\\frac{\\mathcal{N}(x; \\theta_j, \\sigma^2)}{\\mathcal{N}(x; 0, s_q^2)}\\right) = \\left(\\frac{1}{2s_q^2} - \\frac{1}{2\\sigma^2}\\right)x^2 + \\left(\\frac{\\theta_j}{\\sigma^2}\\right)x - \\frac{\\theta_j^2}{2\\sigma^2} + \\frac{1}{2}\\log\\left(\\frac{s_q^2}{\\sigma^2}\\right) $$\n除非 $\\sigma^2 = s_q^2$，否则该表达式是 $x$ 的二次函数。问题故意使用一个带有线性 logit $r_{\\theta_j}(x) = w_0^{(j)} + w_1^{(j)}x$ 的逻辑斯蒂回归模型，从而在 $\\sigma^2 \\neq s_q^2$ 时引入了模型错配。这个训练得到的 logit $r_{\\theta_j}(x)$ 成为我们对真实对数比的近似。\n\n在离散参数集 $\\{\\theta_j\\}_{j=1}^J$ 上，对于一个观测值 $x_{\\text{obs}}$ 的贝叶斯后验由 $P(\\theta_j|x_{\\text{obs}}) \\propto p(x_{\\text{obs}}|\\theta_j)p(\\theta_j)$ 给出。未校准的近似后验是通过将对数似然 $\\log p(x|\\theta)$ 替换为学习到的 logit $r_{\\theta_j}(x)$ 来构建的，得到 $Q_{\\text{uncal}}(\\theta_j|x_{\\text{obs}}) \\propto \\exp(r_{\\theta_j}(x_{\\text{obs}})) p(\\theta_j)$。这种替换是合理的，因为来自真实对数比的项 $q(x_{\\text{obs}})$ 相对于 $\\theta_j$ 是一个常数，并被吸收到归一化常数中。校准后的后验为每个 $\\theta_j$ 引入一个温度参数 $\\alpha^{(j)}$，得到 $Q_{\\text{cal}}(\\theta_j|x_{\\text{obs}}) \\propto \\exp(\\alpha^{(j)} r_{\\theta_j}(x_{\\text{obs}})) p(\\theta_j)$。\n\n实现过程如下：\n1.  在 $[-4.0, 4.0]$ 上定义一个具有 $J=41$ 个参数值 $\\{\\theta_j\\}$ 的离散网格，间距为 $h=0.2$。\n2.  对于该网格上的每个 $\\theta_j$：\n    a. 生成一个训练数据集，其中包含 $n_{\\text{train}}$ 个来自 $p_{\\theta_j}(x)$ 的样本（标签 $y=1$）和 $n_{\\text{train}}$ 个来自 $q(x)$ 的样本（标签 $y=0$）。\n    b. 通过最小化带有微小 $\\ell_2$ 惩罚项 $10^{-8}(w_1^{(j)})^2$ 的交叉熵损失，拟合一个权重为 $w^{(j)} = (w_0^{(j)}, w_1^{(j)})$ 的逻辑斯蒂回归模型。优化使用固定次数的牛顿-拉弗森（也称为迭代重加权最小二乘法，IRLS）更新。对于一个损失 $L(w)$，更新公式为 $w_{k+1} = w_k - H_L^{-1} \\nabla L$，其中 $\\nabla L$ 是梯度，$H_L$ 是损失的海森矩阵。\n    c. 生成一个大小为 $2n_{\\text{val}}$ 的独立验证集。在该集合上计算来自拟合分类器的原始分数 $r_{\\theta_j}(x)$。\n    d. 通过最小化验证数据上关于校准概率 $\\sigma(\\alpha^{(j)} r_{\\theta_j}(x))$ 的交叉熵损失，来优化温度参数 $\\alpha^{(j)}$。这是一个一维凸优化问题，使用牛顿法求解 $\\alpha > 0$。初始值为 $\\alpha=1$，并通过将任何负的更新结果投影到一个小的正值 $10^{-6}$ 来强制保持正性。\n3.  在获得所有 $j=1, \\dots, J$ 的 $(w_0^{(j)}, w_1^{(j)})$ 和 $\\alpha^{(j)}$ 后，我们为给定的观测值 $x_{\\text{obs}}$ 计算在 $\\{\\theta_j\\}$ 上的三个离散后验分布。\n    a. **精确后验**：权重为 $P_j \\propto \\mathcal{N}(x_{\\text{obs}}|\\theta_j, \\sigma^2)\\mathcal{N}(\\theta_j|0, \\tau^2)$。\n    b. **未校准后验**：权重为 $Q_{\\text{uncal},j} \\propto \\exp(w_0^{(j)} + w_1^{(j)} x_{\\text{obs}}) \\mathcal{N}(\\theta_j|0, \\tau^2)$。\n    c. **校准后验**：权重为 $Q_{\\text{cal},j} \\propto \\exp(\\alpha^{(j)}(w_0^{(j)} + w_1^{(j)} x_{\\text{obs}})) \\mathcal{N}(\\theta_j|0, \\tau^2)$。\n    所有分布都被归一化以使其总和为 $1$。为确保数值稳定性，计算在对数空间中进行，使用 log-sum-exp 技巧进行归一化。\n4.  最后，通过计算从精确后验 $P$ 到近似后验 $Q_{\\text{uncal}}$ 和 $Q_{\\text{cal}}$ 的 Kullback–Leibler (KL) 散度来量化扭曲，其定义为 $D_{\\mathrm{KL}}(P \\Vert Q) = \\sum_j P_j \\log(P_j/Q_j)$。\n\n对四个测试用例中的每一个都执行这整个过程，并报告所得的 KL 散度。固定的随机种子确保了可复现性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.special import expit, logsumexp\n\ndef solve():\n    \"\"\"\n    Implements the full pipeline for NCE-based posterior approximation and calibration.\n    \"\"\"\n    # Use a fixed random seed for reproducibility\n    s0 = 12345\n    rng = np.random.default_rng(s0)\n    \n    # Grid definition for theta\n    T = 4.0\n    h = 0.2\n    thetas = np.arange(-T, T + h / 2, h)\n    J = len(thetas)\n\n    # Optimization parameters\n    newton_iters_w = 15\n    newton_iters_alpha = 15\n    reg_lambda = 1e-8\n    alpha_min_proj = 1e-6\n    \n    # Test Suite\n    test_cases = [\n        # (sigma^2, tau^2, s_q^2, x_obs, n_train, n_val)\n        (1.0, 4.0, 4.0, 1.0, 200, 100),  # Case A\n        (1.0, 4.0, 4.0, 1.0, 30, 30),    # Case B\n        (1.0, 1.0, 1.0, 0.0, 200, 100),  # Case C\n        (1.0, 4.0, 2.0, 3.0, 200, 100),  # Case D\n    ]\n\n    results = []\n\n    for case in test_cases:\n        sigma_sq, tau_sq, s_q_sq, x_obs, n_train, n_val = case\n        sigma = np.sqrt(sigma_sq)\n        tau = np.sqrt(tau_sq)\n        s_q = np.sqrt(s_q_sq)\n\n        w_params = np.zeros((J, 2))  # Stores (w0, w1) for each theta_j\n        alphas = np.zeros(J)         # Stores alpha for each theta_j\n\n        for j, theta_j in enumerate(thetas):\n            # 1. Generate Training Data\n            x_pos_train = rng.normal(loc=theta_j, scale=sigma, size=n_train)\n            x_neg_train = rng.normal(loc=0.0, scale=s_q, size=n_train)\n            \n            X_data_train = np.concatenate([x_pos_train, x_neg_train])\n            X_design_train = np.vstack([np.ones_like(X_data_train), X_data_train]).T\n            y_train = np.concatenate([np.ones(n_train), np.zeros(n_train)])\n\n            # 2. Fit Logistic Regression via Newton's Method (IRLS)\n            w = np.zeros(2) # Initial weights (w0, w1)\n            reg_hess_penalty = np.diag([0, 2 * reg_lambda])\n            for _ in range(newton_iters_w):\n                z = X_design_train @ w\n                p = expit(z)\n                grad = X_design_train.T @ (p - y_train) + np.array([0, 2 * reg_lambda * w[1]])\n                W = np.diag(p * (1 - p))\n                H = X_design_train.T @ W @ X_design_train + reg_hess_penalty\n                w = w - np.linalg.inv(H) @ grad\n            w_params[j, :] = w\n\n            # 3. Generate Validation Data\n            x_pos_val = rng.normal(loc=theta_j, scale=sigma, size=n_val)\n            x_neg_val = rng.normal(loc=0.0, scale=s_q, size=n_val)\n            \n            X_data_val = np.concatenate([x_pos_val, x_neg_val])\n            y_val = np.concatenate([np.ones(n_val), np.zeros(n_val)])\n            \n            # 4. Fit Temperature Scale via Newton's Method\n            raw_scores = w[0] + w[1] * X_data_val\n            alpha = 1.0 # Initial temperature\n            for _ in range(newton_iters_alpha):\n                p_alpha = expit(alpha * raw_scores)\n                grad_alpha = np.sum(raw_scores * (p_alpha - y_val))\n                hess_alpha = np.sum((raw_scores**2) * p_alpha * (1 - p_alpha))\n                if hess_alpha > 1e-12: # Avoid division by zero\n                    alpha = alpha - grad_alpha / hess_alpha\n                alpha = max(alpha, alpha_min_proj) # Enforce positivity\n            alphas[j] = alpha\n            \n        # 5. Compute Posteriors for x_obs\n        log_prior = norm.logpdf(thetas, loc=0.0, scale=tau)\n        \n        # Exact Posterior\n        log_likelihood_exact = norm.logpdf(x_obs, loc=thetas, scale=sigma)\n        log_posterior_exact_un = log_prior + log_likelihood_exact\n        log_norm_const_exact = logsumexp(log_posterior_exact_un)\n        log_posterior_exact = log_posterior_exact_un - log_norm_const_exact\n        posterior_exact = np.exp(log_posterior_exact)\n\n        # Uncalibrated NCE Posterior\n        logits_uncal = w_params[:, 0] + w_params[:, 1] * x_obs\n        log_posterior_uncal_un = log_prior + logits_uncal\n        log_norm_const_uncal = logsumexp(log_posterior_uncal_un)\n        log_posterior_uncal = log_posterior_uncal_un - log_norm_const_uncal\n        posterior_uncal = np.exp(log_posterior_uncal)\n\n        # Calibrated NCE Posterior\n        logits_cal = alphas * (w_params[:, 0] + w_params[:, 1] * x_obs)\n        log_posterior_cal_un = log_prior + logits_cal\n        log_norm_const_cal = logsumexp(log_posterior_cal_un)\n        log_posterior_cal = log_posterior_cal_un - log_norm_const_cal\n        posterior_cal = np.exp(log_posterior_cal)\n\n        # 6. Compute KL Divergences\n        # Add a small constant to prevent log(0) if any posterior probability is exactly zero\n        eps = 1e-99\n        kl_uncal = np.sum(posterior_exact * (log_posterior_exact - np.log(posterior_uncal + eps)))\n        kl_cal = np.sum(posterior_exact * (log_posterior_exact - np.log(posterior_cal + eps)))\n        results.extend([kl_uncal, kl_cal])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n\n```"
        }
    ]
}