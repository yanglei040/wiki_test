{
    "hands_on_practices": [
        {
            "introduction": "在蒙特卡洛模拟中，一个核心目标是提高估计量的效率，即减少其方差。对偶变量是一种简洁而强大的方差缩减技术，它巧妙地利用了基础概率分布的对称性。本练习  将引导您通过理论推导，来量化该方法的具体优势，特别是当面对特定类型的函数（如奇函数）时，其效果尤为显著。",
            "id": "3322640",
            "problem": "考虑一个维度 $d \\in \\mathbb{N}$ 和一个随机向量 $Z \\in \\mathbb{R}^{d}$，其服从 $d$ 维多元正态分布 $\\mathcal{N}_{d}(0, I_{d})$，其中 $I_{d}$ 是 $d \\times d$ 的单位矩阵。设 $\\mu \\in \\mathbb{R}^{d}$ 为一个固定向量， $A \\in \\mathbb{R}^{d \\times d}$ 为一个固定的满秩矩阵，因此协方差矩阵 $\\Sigma := A A^{\\top}$ 是正定的。定义线性变换 $X := \\mu + A Z$，这是随机模拟中从多元正态分布 $\\mathcal{N}_{d}(\\mu, \\Sigma)$ 抽样的标准方法。\n\n在蒙特卡洛（MC）的对偶变量（AV）技术中，通过使用 $Z$ 及其对偶 $-Z$ 来构成对，相应地得到 $X := \\mu + A Z$ 和 $X^{-} := \\mu + A(-Z) = \\mu - A Z$。假设我们希望估计 $\\theta := \\mathbb{E}[f(X)]$，其中 $f : \\mathbb{R}^{d} \\to \\mathbb{R}$ 是一个可测函数，且满足 $\\operatorname{Var}(f(X)) < \\infty$。考虑两种每次重复使用两次函数求值的估计量：\n(i) 独立样本均值 $\\hat{\\theta}_{\\mathrm{ind}} := \\frac{1}{2}\\big(f(X^{(1)}) + f(X^{(2)})\\big)$，其中 $X^{(1)}$ 和 $X^{(2)}$ 独立同分布于 $\\mathcal{N}_{d}(\\mu, \\Sigma)$，\n以及 (ii) 对偶对均值 $\\hat{\\theta}_{\\mathrm{ant}} := \\frac{1}{2}\\big(f(X) + f(X^{-})\\big)$，其由单个 $Z \\sim \\mathcal{N}_{d}(0, I_{d})$ 及其对偶 $-Z$ 构建。\n\n仅从多元正态分布的定义性质、高斯向量的线性变换，以及方差、协方差和相关系数的定义出发，完成以下任务：\n1. 证明对偶对中的每个元素 $X$ 和 $X^{-}$ 的边际抽样分布不变，仍为 $\\mathcal{N}_{d}(\\mu, \\Sigma)$。\n2. 推导 $\\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ant}})$ 的精确表达式，用 $\\operatorname{Var}(f(X))$ 和 $\\operatorname{Cov}(f(X), f(X^{-}))$ 表示。\n3. 推导方差比 $R := \\frac{\\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ant}})}{\\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ind}})}$ 并用相关系数 $\\rho := \\operatorname{Corr}(f(X), f(X^{-}))$ 表示。\n4. 假设 $f$ 是关于 $\\mu$ 的奇函数，即对所有 $y \\in \\mathbb{R}^{d}$ 都有 $f(\\mu + y) = - f(\\mu - y)$。利用多元正态分布的对称性和 $A$ 的线性性，计算此情况下的 $\\rho$ 并推导出 $R$ 的值。\n\n将你的最终答案表示为 $R$ 关于 $\\rho$ 的单个闭式解析表达式，并附上如上所述的当 $f$ 为奇函数时的 $R$ 值。无需四舍五入，不涉及物理单位。",
            "solution": "该问题经验证是自洽的、有科学依据且定义明确的。我们进行逐步推导。\n\n1. $X$ 和 $X^{-}$ 的边际分布证明。\n\n给定随机向量 $Z \\in \\mathbb{R}^{d}$ 服从标准多元正态分布 $Z \\sim \\mathcal{N}_{d}(0, I_{d})$，其中 $I_d$ 是 $d \\times d$ 的单位矩阵。$Z$ 的概率密度函数（PDF）关于原点对称，即对所有 $z \\in \\mathbb{R}^{d}$ 都有 $p_{Z}(z) = p_{Z}(-z)$。这意味着随机向量 $-Z$ 与 $Z$ 具有相同的分布。\n为了正式地证明这一点，我们来求 $-Z$ 的均值和协方差。\n均值为 $\\mathbb{E}[-Z] = -\\mathbb{E}[Z] = -0 = 0$。\n协方差矩阵为 $\\operatorname{Cov}(-Z) = \\mathbb{E}[(-Z)(-Z)^{\\top}] - \\mathbb{E}[-Z]\\mathbb{E}[-Z]^{\\top} = \\mathbb{E}[ZZ^{\\top}] - 0 = \\operatorname{Cov}(Z) = I_{d}$。\n由于 $-Z$ 是多元正态向量 $Z$ 的线性变换，它也服从多元正态分布。因为它与 $Z$ 有相同的均值（$0$）和协方差矩阵（$I_d$），我们得出结论 $-Z \\sim \\mathcal{N}_{d}(0, I_{d})$。\n\n随机向量 $X$ 由仿射变换 $X := \\mu + A Z$ 定义。由于 $Z$ 是多元正态的，所以 $X$ 也是多元正态的。其均值为：\n$$ \\mathbb{E}[X] = \\mathbb{E}[\\mu + A Z] = \\mu + A \\mathbb{E}[Z] = \\mu + A \\cdot 0 = \\mu $$\n其协方差矩阵为：\n$$ \\operatorname{Cov}(X) = \\operatorname{Cov}(\\mu + A Z) = \\operatorname{Cov}(A Z) = A \\operatorname{Cov}(Z) A^{\\top} = A I_{d} A^{\\top} = A A^{\\top} = \\Sigma $$\n因此，如问题所述，$X \\sim \\mathcal{N}_{d}(\\mu, \\Sigma)$。\n\n对偶向量 $X^{-}$ 定义为 $X^{-} := \\mu - A Z = \\mu + A(-Z)$。由于我们已经确定 $-Z$ 与 $Z$ 具有相同的分布，即 $\\mathcal{N}_{d}(0, I_{d})$，所以随机向量 $X^{-}$ 必须与 $X$ 具有相同的分布。遵循同样的推导：\n$$ \\mathbb{E}[X^{-}] = \\mathbb{E}[\\mu + A(-Z)] = \\mu + A \\mathbb{E}[-Z] = \\mu + A \\cdot 0 = \\mu $$\n$$ \\operatorname{Cov}(X^{-}) = \\operatorname{Cov}(\\mu + A(-Z)) = \\operatorname{Cov}(A(-Z)) = A \\operatorname{Cov}(-Z) A^{\\top} = A I_{d} A^{\\top} = A A^{\\top} = \\Sigma $$\n因此，$X^{-}$ 的边际分布也是 $\\mathcal{N}_{d}(\\mu, \\Sigma)$，与 $X$ 的分布相同。这完成了第一部分的证明。\n\n2. $\\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ant}})$ 的推导。\n\n对偶对估计量为 $\\hat{\\theta}_{\\mathrm{ant}} = \\frac{1}{2}\\big(f(X) + f(X^{-})\\big)$。我们使用两个随机变量之和的方差的一般公式：$\\operatorname{Var}(aY_1 + bY_2) = a^2\\operatorname{Var}(Y_1) + b^2\\operatorname{Var}(Y_2) + 2ab\\operatorname{Cov}(Y_1, Y_2)$。\n这里，$Y_1 = f(X)$，$Y_2 = f(X^{-})$，且 $a = b = \\frac{1}{2}$。\n$$ \\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ant}}) = \\operatorname{Var}\\left(\\frac{1}{2}f(X) + \\frac{1}{2}f(X^{-})\\right) = \\left(\\frac{1}{2}\\right)^2 \\operatorname{Var}(f(X)) + \\left(\\frac{1}{2}\\right)^2 \\operatorname{Var}(f(X^{-})) + 2\\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right)\\operatorname{Cov}(f(X), f(X^{-})) $$\n$$ \\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ant}}) = \\frac{1}{4}\\operatorname{Var}(f(X)) + \\frac{1}{4}\\operatorname{Var}(f(X^{-})) + \\frac{1}{2}\\operatorname{Cov}(f(X), f(X^{-})) $$\n从第1部分我们知道，$X$ 和 $X^{-}$ 是同分布的。这意味着随机变量 $f(X)$ 和 $f(X^{-})$ 也是同分布的，因此具有相同的方差：$\\operatorname{Var}(f(X)) = \\operatorname{Var}(f(X^{-}))$.\n将此代入方程，我们得到：\n$$ \\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ant}}) = \\frac{1}{4}\\operatorname{Var}(f(X)) + \\frac{1}{4}\\operatorname{Var}(f(X)) + \\frac{1}{2}\\operatorname{Cov}(f(X), f(X^{-})) $$\n$$ \\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ant}}) = \\frac{1}{2}\\operatorname{Var}(f(X)) + \\frac{1}{2}\\operatorname{Cov}(f(X), f(X^{-})) $$\n这就是所求的表达式。\n\n3. 方差比 $R$ 的推导。\n\n首先，我们计算独立样本估计量 $\\hat{\\theta}_{\\mathrm{ind}} = \\frac{1}{2}\\big(f(X^{(1)}) + f(X^{(2)})\\big)$ 的方差。向量 $X^{(1)}$ 和 $X^{(2)}$ 是独立同分布（i.i.d.）于 $\\mathcal{N}_{d}(\\mu, \\Sigma)$ 的。因此，随机变量 $f(X^{(1)})$ 和 $f(X^{(2)})$ 也是独立同分布的。它们的独立性意味着它们的协方差为零：$\\operatorname{Cov}(f(X^{(1)}), f(X^{(2)})) = 0$。\n其方差为：\n$$ \\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ind}}) = \\operatorname{Var}\\left(\\frac{1}{2}f(X^{(1)}) + \\frac{1}{2}f(X^{(2)})\\right) = \\left(\\frac{1}{2}\\right)^2\\operatorname{Var}(f(X^{(1)})) + \\left(\\frac{1}{2}\\right)^2\\operatorname{Var}(f(X^{(2)})) + 0 $$\n由于它们是同分布的，$\\operatorname{Var}(f(X^{(1)})) = \\operatorname{Var}(f(X^{(2)})) = \\operatorname{Var}(f(X))$。\n$$ \\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ind}}) = \\frac{1}{4}\\operatorname{Var}(f(X)) + \\frac{1}{4}\\operatorname{Var}(f(X)) = \\frac{1}{2}\\operatorname{Var}(f(X)) $$\n方差比 $R$ 定义为 $R := \\frac{\\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ant}})}{\\operatorname{Var}(\\hat{\\theta}_{\\mathrm{ind}})}$。代入我们推导出的表达式：\n$$ R = \\frac{\\frac{1}{2}\\operatorname{Var}(f(X)) + \\frac{1}{2}\\operatorname{Cov}(f(X), f(X^{-}))}{\\frac{1}{2}\\operatorname{Var}(f(X))} = 1 + \\frac{\\operatorname{Cov}(f(X), f(X^{-}))}{\\operatorname{Var}(f(X))} $$\n相关系数 $\\rho$ 定义为 $\\rho := \\operatorname{Corr}(f(X), f(X^{-})) = \\frac{\\operatorname{Cov}(f(X), f(X^{-}))}{\\sqrt{\\operatorname{Var}(f(X)) \\operatorname{Var}(f(X^{-}))}}$。\n由于 $\\operatorname{Var}(f(X)) = \\operatorname{Var}(f(X^{-}))$，上式简化为 $\\rho = \\frac{\\operatorname{Cov}(f(X), f(X^{-}))}{\\operatorname{Var}(f(X))}$。\n将此代入我们关于 $R$ 的表达式，我们得到：\n$$ R = 1 + \\rho $$\n\n4. 对于奇函数 $f$，计算 $\\rho$ 和 $R$。\n\n给定 $f$ 是关于 $\\mu$ 的奇函数，即对所有 $y \\in \\mathbb{R}^{d}$ 都有 $f(\\mu + y) = -f(\\mu - y)$。\n我们利用这个性质来表示 $f(X)$ 和 $f(X^{-})$。我们有 $X = \\mu + AZ$ 和 $X^{-} = \\mu - AZ$。令 $y = AZ$。那么，我们可以写成：\n$f(X) = f(\\mu + AZ)$\n$f(X^{-}) = f(\\mu - AZ)$\n使用奇函数性质，令 $y = AZ$，我们有 $f(\\mu + AZ) = -f(\\mu - AZ)$。\n这意味着随机变量 $f(X)$ 和 $f(X^{-})$ 之间存在一个确定性关系：\n$$ f(X) = -f(X^{-}) $$\n这个关系对 $Z$ 的每次实现都成立。现在我们计算相关系数 $\\rho = \\operatorname{Corr}(f(X), f(X^{-}))$。\n使用关系 $f(X^{-}) = -f(X)$，我们有：\n$$ \\rho = \\operatorname{Corr}(f(X), -f(X)) $$\n利用协方差和方差的性质，$\\operatorname{Cov}(U, -V) = -\\operatorname{Cov}(U, V)$ 和 $\\operatorname{Var}(-U) = \\operatorname{Var}(U)$：\n$$ \\rho = \\frac{\\operatorname{Cov}(f(X), -f(X))}{\\sqrt{\\operatorname{Var}(f(X))\\operatorname{Var}(-f(X))}} = \\frac{-\\operatorname{Cov}(f(X), f(X))}{\\sqrt{\\operatorname{Var}(f(X))\\operatorname{Var}(f(X))}} = \\frac{-\\operatorname{Var}(f(X))}{\\operatorname{Var}(f(X))} $$\n假设 $\\operatorname{Var}(f(X)) > 0$（否则 $f(X)$ 是一个常数，问题就变得微不足道），我们得到：\n$$ \\rho = -1 $$\n达到了完全负相关。\n最后，我们可以推导出方差比 $R$ 的值：\n$$ R = 1 + \\rho = 1 + (-1) = 0 $$\n这个结果表明，对于一个关于 $\\mu$ 的奇函数，对偶变量技术产生了一个零方差估计量，这是可能实现的最大方差缩减。估计量 $\\hat{\\theta}_{\\mathrm{ant}} = \\frac{1}{2}(f(X)+f(X^-)) = \\frac{1}{2}(f(X)-f(X)) = 0$，所以其方差确实是 $0$。\n\n最终答案结合了 $R$ 关于 $\\rho$ 的表达式以及在 $f$ 为奇函数情况下 $R$ 的值。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 1 + \\rho & 0 \\end{pmatrix} } $$"
        },
        {
            "introduction": "理论知识最终要服务于实践。像对偶变量这样的技术不仅仅是理论上的精妙构造，更是加速复杂计算（例如贝叶斯统计推断）的实用工具。这个编码实践  要求您在一个完整的贝叶斯线性回归模型中，亲手实现并比较标准蒙特卡洛、对偶采样以及更高级的拟蒙特卡洛方法的收敛性，从而将理论与应用紧密结合。",
            "id": "3322642",
            "problem": "构建一个完整的程序，该程序针对多个具有高斯先验的高维贝叶斯线性回归实例，比较三种蒙特卡洛策略，用于在多元正态后验分布下近似预测矩：独立同分布采样、对偶采样，以及通过变换到多元正态分布的 Sobol 序列进行的拟蒙特卡洛采样。目标是展示在拟多元正态采样下预测矩的收敛性有所改善，并量化对偶采样对于线性泛函的方差缩减特性。\n\n您必须基于以下基本原理进行工作：\n- 线性高斯模型由 $y = X w + \\varepsilon$ 给出，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_n)$，先验为 $w \\sim \\mathcal{N}(0, \\tau^2 I_d)$。\n- 对于高斯似然和高斯先验，后验分布 $p(w \\mid y, X)$ 是高斯的。其精度矩阵是先验精度与数据精度之和。避免任何显式的矩阵求逆；仅依赖于线性代数恒等式和分解（例如，正定精度矩阵的 Cholesky 分解）以及三角求解。\n- 如果 $A$ 是一个对称正定矩阵，且 $A = R^\\top R$ 是其 Cholesky 分解，其中 $R$ 是上三角矩阵，那么采样 $z \\sim \\mathcal{N}(0, I_d)$ 并设置 $u = R^{-1} z$ 会得到 $\\operatorname{Cov}(u) = A^{-1}$。对于协方差为 $A^{-1}$、均值为 $\\mu$ 的多元正态采样，可以使用 $w = \\mu + u$。\n- 对偶采样对对称分布使用成对的参考抽样 $z$ 和 $-z$，以减少奇函数被积函数的估计量方差。\n- 拟蒙特卡洛采样通过逆累积分布函数将一个低差异序列 $u \\in (0,1)^d$ 映射到一个标准正态向量 $z$，然后通过线性变换映射到目标多元正态分布。\n\n程序要求：\n1) 对于下述每个测试用例，按如下方式生成数据，使用指定的随机数生成器种子（所有种子均为非负整数，可用于任何语言的伪随机数生成器）。所有向量和矩阵都应为实值。\n   - 抽取设计矩阵 $X \\in \\mathbb{R}^{n \\times d}$，其行独立同分布于 $\\mathcal{N}(0, \\Sigma_X)$，其中对于所有 $i, j \\in \\{1,\\dots,d\\}$，$(\\Sigma_X)_{ij} = \\rho^{|i-j|}$ 且 $|\\rho| < 1$。使用 $\\Sigma_X$ 的 Cholesky 分解来生成这些行，而不依赖于通用的多元正态例程。为生成 $X$，使用种子 $s_X$。\n   - 使用种子 $s_w$ 抽取真实系数向量 $w_{\\text{true}} \\sim \\mathcal{N}(0, \\tau^2 I_d)$，并使用种子 $s_\\varepsilon$ 抽取噪声 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_n)$。然后设置 $y = X w_{\\text{true}} + \\varepsilon$。\n   - 使用相同的 $\\Sigma_X$ 和种子 $s_*$ 抽取一个预测协变量 $x_* \\sim \\mathcal{N}(0, \\Sigma_X)$。\n2) 使用高斯模型的线性代数恒等式计算后验精度矩阵 $A$ 和后验均值 $\\mu$。通过 Cholesky 分解将 $A$ 分解为 $A = R^\\top R$，其中 $R$ 是上三角矩阵。不要显式地对任何矩阵求逆。\n3) 通过用 $A$、$\\mu$ 和 $x_*$ 表示它们，计算精确的预测均值 $\\mu_* = \\mathbb{E}[x_*^\\top w \\mid y, X]$ 和精确的预测方差 $v_* = \\operatorname{Var}(x_*^\\top w \\mid y, X) + \\sigma^2$，同样使用线性求解而无需显式矩阵求逆。\n4) 实现三种采样估计器来近似 $y_*$ 的预测均值和方差：\n   - 独立同分布（IID）采样器：抽取 $N$ 个独立的 $z \\sim \\mathcal{N}(0, I_d)$ 并映射到 $w = \\mu + R^{-1} z$。对于 IID 采样器，使用种子 $s_{\\text{iid}}$。\n   - 对偶采样器：抽取 $N/2$ 个独立的 $z \\sim \\mathcal{N}(0, I_d)$ 并同时包含 $z$ 和 $-z$，将每个都映射到 $w = \\mu + R^{-1} z$。使用种子 $s_{\\text{anti}}$。假设所有考虑的样本量 $N$ 均为偶数。\n   - 拟蒙特卡洛（QMC）采样器：使用种子 $s_{\\text{qmc}}$ 创建一个在 $[0,1)^d$ 范围内带 Owen 加扰的 Sobol 序列，通过逆标准正态累积分布函数进行逐分量变换以获得 $z \\in \\mathbb{R}^d$，然后映射到 $w = \\mu + R^{-1} z$。使用 2 的幂次方的样本量，并为每个 $N$ 使用前 $N$ 个 Sobol 点。\n5) 对于每个采样器和样本量集合中的每个 $N$，近似计算：\n   - 预测均值，通过 $x_*^\\top w$ 的样本均值计算。\n   - 预测方差，通过 $x_*^\\top w$ 的样本方差（使用总体归一化）加上 $\\sigma^2$ 计算。\n6) 对于每个采样器，累积在样本量 $N \\in \\{128, 512, 2048, 8192\\}$ 上的积分绝对误差：\n   - 对于预测均值：$E_{\\text{mean}} = \\sum_{N} \\left| \\hat{\\mu}_*(N) - \\mu_* \\right|$。\n   - 对于预测方差：$E_{\\text{var}} = \\sum_{N} \\left| \\hat{v}_*(N) - v_* \\right|$。\n7) 对于每个测试用例，报告三个布尔值结果：\n   - 对偶采样是否比 IID 改善了预测均值的收敛性：$E_{\\text{mean}}^{\\text{anti}} < E_{\\text{mean}}^{\\text{iid}}$。\n   - 拟蒙特卡洛是否比 IID 改善了预测均值的收敛性：$E_{\\text{mean}}^{\\text{qmc}} < E_{\\text{mean}}^{\\text{iid}}$。\n   - 拟蒙特卡洛是否比 IID 改善了预测方差的收敛性：$E_{\\text{var}}^{\\text{qmc}} < E_{\\text{var}}^{\\text{iid}}$。\n\n测试套件：\n- 案例 A（高维，中度病态）：\n  - $n = 60$, $d = 50$, $\\tau = 1.0$, $\\sigma = 0.5$, $\\rho = 0.7$,\n  - $s_X = 1729$, $s_w = 2718$, $s_\\varepsilon = 31415$, $s_* = 4242$,\n  - $s_{\\text{iid}} = 7771$, $s_{\\text{anti}} = 7772$, $s_{\\text{qmc}} = 12345$。\n- 案例 B（欠定，$d \\gg n$）：\n  - $n = 30$, $d = 100$, $\\tau = 1.5$, $\\sigma = 1.0$, $\\rho = 0.5$,\n  - $s_X = 2021$, $s_w = 1618$, $s_\\varepsilon = 1414$, $s_* = 1732$,\n  - $s_{\\text{iid}} = 8881$, $s_{\\text{anti}} = 8882$, $s_{\\text{qmc}} = 23456$。\n- 案例 C（接近共线性）：\n  - $n = 80$, $d = 80$, $\\tau = 0.8$, $\\sigma = 0.3$, $\\rho = 0.95$,\n  - $s_X = 271828$, $s_w = 161803$, $s_\\varepsilon = 141421$, $s_* = 173205$,\n  - $s_{\\text{iid}} = 9991$, $s_{\\text{anti}} = 9992$, $s_{\\text{qmc}} = 34567$。\n\n实现说明：\n- 所有线性代数运算必须避免显式矩阵求逆。仅使用分解和三角求解。\n- 基于 Sobol 的拟蒙特卡洛必须使用带有所提供种子的加扰 Sobol 生成器，并采用 2 的幂次方的样本量 $N \\in \\{128, 512, 2048, 8192\\}$；为每个 $N$ 使用前 $N$ 个点。通过逆累积分布函数逐分量映射到标准正态分布。\n- 将用于逆累积分布函数映射的任何均匀分布值裁剪到闭区间 $[10^{-12}, 1-10^{-12}]$ 内，以避免无穷大。\n- 不涉及角度；不适用物理单位。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三个案例的结果，格式为逗号分隔的方括号三元组列表，无空格，例如： “[[True,True,True],[True,True,True],[True,True,True]]”。每个内部三元组对应一个案例，并按顺序排列为 $[\\text{对偶采样改善均值}, \\text{拟蒙特卡洛改善均值}, \\text{拟蒙特卡洛改善方差}]$。",
            "solution": "该问题要求对三种蒙特卡洛方法进行比较分析，这些方法用于在高维贝叶斯线性回归模型中近似预测矩。这些方法是独立同分布（IID）采样、对偶采样和拟蒙特卡洛（QMC）采样。解决方案涉及推导后验分布、计算精确的预测矩、实现三种采样器，并基于积分绝对误差评估其性能。\n\n### 1. 贝叶斯线性回归模型与后验分布\n\n指定的模型是设计矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 与响应向量 $y \\in \\mathbb{R}^n$ 之间的线性关系，并带有高斯噪声。\n数据的似然由 $p(y \\mid w, \\sigma^2) = \\mathcal{N}(y \\mid Xw, \\sigma^2 I_n)$ 给出，其中 $w \\in \\mathbb{R}^d$ 是回归系数向量，$\\sigma^2$ 是噪声方差。似然函数正比于：\n$$\np(y \\mid w) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} (y - Xw)^\\top (y - Xw)\\right)\n$$\n权重上设置了高斯先验，$p(w \\mid \\tau^2) = \\mathcal{N}(w \\mid 0, \\tau^2 I_d)$，其中 $\\tau^2$ 是先验方差。先验正比于：\n$$\np(w) \\propto \\exp\\left(-\\frac{1}{2\\tau^2} w^\\top w\\right)\n$$\n根据贝叶斯定理，后验分布 $p(w \\mid y, X)$ 正比于似然与先验的乘积，$p(w \\mid y, X) \\propto p(y \\mid w) p(w)$。后验分布的指数部分是似然与先验指数部分之和：\n$$\n-\\frac{1}{2\\sigma^2} (y^\\top y - 2y^\\top Xw + w^\\top X^\\top X w) - \\frac{1}{2\\tau^2} w^\\top w\n$$\n对关于 $w$ 的项进行分组，我们得到：\n$$\n-\\frac{1}{2} \\left( w^\\top \\left(\\frac{1}{\\sigma^2} X^\\top X + \\frac{1}{\\tau^2} I_d\\right) w - 2 \\left(\\frac{1}{\\sigma^2} y^\\top X\\right) w \\right) + \\text{const}\n$$\n这是一个多元高斯分布的指数部分，证实了后验分布是高斯的，$p(w \\mid y, X) = \\mathcal{N}(w \\mid \\mu, A^{-1})$。通过“配方法”或与一般高斯形式 $\\exp(-\\frac{1}{2}(w-\\mu)^\\top A(w-\\mu))$ 进行比较，我们可以确定后验精度矩阵 $A$ 和后验均值 $\\mu$：\n后验精度矩阵为：\n$$\nA = \\frac{1}{\\sigma^2} X^\\top X + \\frac{1}{\\tau^2} I_d\n$$\n后验均值 $\\mu$ 是以下线性系统的解：\n$$\nA\\mu = \\frac{1}{\\sigma^2} X^\\top y\n$$\n为了在不进行显式矩阵求逆的情况下计算 $\\mu$，我们首先计算对称正定矩阵 $A$ 的 Cholesky 分解，使得 $A = R^\\top R$，其中 $R$ 是上三角矩阵。然后，我们使用两次三角求解来解 $R^\\top R \\mu = \\frac{1}{\\sigma^2} X^\\top y$：首先解 $R^\\top v = \\frac{1}{\\sigma^2} X^\\top y$ 得到 $v$（前向替换），然后解 $R\\mu = v$ 得到 $\\mu$（后向替换）。\n\n### 2. 精确的预测矩\n\n对于一个新的协变量向量 $x_* \\in \\mathbb{R}^d$，预测响应为 $y_* = x_*^\\top w + \\varepsilon_*$，其中 $w$ 从后验分布中抽取。我们感兴趣的预测量是 $x_*^\\top w$。由于 $w$ 是高斯的，所以 $x_*^\\top w$ 是一个一元高斯分布。\n\n$x_*^\\top w$ 的精确预测均值为：\n$$\n\\mu_* = \\mathbb{E}[x_*^\\top w \\mid y, X] = x_*^\\top \\mathbb{E}[w \\mid y, X] = x_*^\\top \\mu\n$$\n$y_*$ 的精确预测方差包括 $w$ 的不确定性和观测噪声 $\\sigma^2$。项 $x_*^\\top w$ 的方差由下式给出：\n$$\n\\operatorname{Var}(x_*^\\top w \\mid y, X) = x_*^\\top \\operatorname{Cov}(w) x_* = x_*^\\top A^{-1} x_*\n$$\n总预测方差 $v_*$ 为：\n$$\nv_* = \\operatorname{Var}(x_*^\\top w \\mid y, X) + \\sigma^2 = x_*^\\top A^{-1} x_* + \\sigma^2\n$$\n为了在不求逆 $A$ 的情况下计算 $x_*^\\top A^{-1} x_*$，我们求解线性系统 $Av = x_*$ 得到 $v$。然后，方差项为 $x_*^\\top v$。这个线性系统像之前一样使用 Cholesky 因子 $R$ 来求解：解 $R^\\top u = x_*$ 得到 $u$，然后解 $Rv = u$ 得到 $v$。\n\n### 3. 蒙特卡洛估计策略\n\n问题的核心是使用来自后验分布 $p(w \\mid y, X) = \\mathcal{N}(\\mu, A^{-1})$ 的样本来近似 $\\mu_*$ 和 $v_*$。要从该分布中抽取一个样本 $w$，我们首先抽取一个标准正态向量 $z \\sim \\mathcal{N}(0, I_d)$，然后应用一个仿射变换：\n$$\nw = \\mu + R^{-1} z\n$$\n这是有效的，因为如果 $z \\sim \\mathcal{N}(0, I_d)$，那么 $u = R^{-1} z$ 的协方差为 $\\operatorname{Cov}(u) = R^{-1} \\operatorname{Cov}(z) (R^{-1})^\\top = R^{-1} (R^\\top)^{-1} = (R^\\top R)^{-1} = A^{-1}$。项 $R^{-1}z$ 是通过后向替换解 $R u = z$ 得到 $u$ 来计算的。这三种采样方法在生成 $z$ 向量序列的方式上有所不同。\n\n**独立同分布（IID）采样：**这是基准方法。从 $\\mathcal{N}(0, I_d)$ 中独立抽取一组 $N$ 个向量 $\\{z_i\\}_{i=1}^N$，从而得到 $N$ 个后验样本 $\\{w_i\\}_{i=1}^N$。蒙特卡洛积分的近似误差通常以 $O(N^{-1/2})$ 的速率下降。\n\n**对偶采样：**这种方差缩减技术利用了被积函数的对称性。对于像 $\\mathcal{N}(0, I_d)$ 这样的对称分布，如果我们抽取一个样本 $z$，我们同时也包括其对偶对 $-z$。对于一个奇函数被积函数 $f(z)$，这对样本的平均值 $[f(z) + f(-z)]/2 = 0$，完全抵消了变异。预测均值的目标是 $x_*^\\top w = x_*^\\top \\mu + x_*^\\top R^{-1} z$。项 $x_*^\\top R^{-1} z$ 是 $z$ 的奇函数。该项的每个对偶对的平均值为 $0$，因此 $\\mathbb{E}[x_*^\\top R^{-1} z]$ 的估计量恰好为 $0$，而 $\\mathbb{E}[x_*^\\top w]$ 的估计量恰好为 $x_*^\\top \\mu$。这对均值估计提供了巨大的方差缩减。对于偶函数被积函数，例如用于方差计算的被积函数，对偶采样则没有任何好处。\n\n**拟蒙特卡洛（QMC）采样：**QMC 方法用确定性的低差异序列（如 Sobol 序列）取代随机样本。这些点比伪随机点更均匀地填充样本空间。Sobol 序列在单位超立方体 $[0,1)^d$ 中生成点 $u_i$。为了获得标准正态样本 $z_i$，$u_i$ 的每个分量都使用标准正态累积分布函数（CDF）的反函数（也称为概率单位函数）进行转换。对于表现良好的被积函数，QMC 方法可以实现更快的收敛速度，接近 $O(N^{-1})$，显著优于 IID 采样。对 Sobol 序列进行加扰可以打破其确定性模式，同时保留低差异性，从而进一步改善其性质。\n\n### 4. 算法与实现\n\n对于每个测试用例，程序将执行以下步骤：\n1.  **数据生成：**\n    - 构建 $d \\times d$ 协方差矩阵 $\\Sigma_X$，其元素为 $(\\Sigma_X)_{ij} = \\rho^{|i-j|}$。\n    - 计算 $\\Sigma_X$ 的下 Cholesky 因子 $L_X$，使得 $\\Sigma_X = L_X L_X^\\top$。\n    - 使用指定的种子 $s_X$，生成 $n$ 个向量 $z_{X,i} \\sim \\mathcal{N}(0, I_d)$ 并将 $X$ 的行构造成 $x_i^\\top = (L_X z_{X,i})^\\top$。\n    - 使用它们各自的种子和参数，类似地生成 $w_{\\text{true}}$、$\\varepsilon$ 和 $x_*$。\n    - 计算观测数据 $y = X w_{\\text{true}} + \\varepsilon$。\n\n2.  **后验和精确矩的计算：**\n    - 计算后验精度 $A = (1/\\sigma^2) X^\\top X + (1/\\tau^2) I_d$。\n    - 计算 $A$ 的上 Cholesky 因子 $R$，使得 $A = R^\\top R$。\n    - 计算右侧项 $b = (1/\\sigma^2) X^\\top y$。\n    - 通过两次三角求解，从 $R^\\top R \\mu = b$ 中解出后验均值 $\\mu$。\n    - 计算精确预测均值 $\\mu_* = x_*^\\top \\mu$。\n    - 通过两次三角求解，从 $R^\\top R v = x_*$ 中解出 $v$。\n    - 计算精确预测方差 $v_* = x_*^\\top v + \\sigma^2$。\n\n3.  **蒙特卡洛估计与误差累积：**\n    - 对于每个采样器（IID、对偶、QMC）和每个样本量 $N \\in \\{128, 512, 2048, 8192\\}$：\n        - 根据采样器的逻辑，使用其指定的种子生成 $N$ 个标准正态向量 $\\{z_i\\}$。对于 QMC，这涉及生成一个加扰的 Sobol 序列并应用逆正态 CDF。\n        - 对于每个 $z_i$，解 $R u_i = z_i$ 得到 $u_i$，并构成后验样本 $w_i = \\mu + u_i$。\n        - 计算样本预测值 $p_i = x_*^\\top w_i$。\n        - 将 $\\{p_i\\}$ 的样本均值作为均值估计 $\\hat{\\mu}_*(N)$。\n        - 将 $\\{p_i\\}$ 的样本方差（使用 $1/N$ 归一化）加上 $\\sigma^2$ 作为方差估计 $\\hat{v}_*(N)$。\n        - 计算绝对误差 $|\\hat{\\mu}_*(N) - \\mu_*|$ 和 $|\\hat{v}_*(N) - v_*|$。\n    - 将这些绝对误差在所有 $N$ 上求和，得到每个采样器的积分误差 $E_{\\text{mean}}$ 和 $E_{\\text{var}}$。\n\n4.  **最终比较：**\n    - 对于每个测试用例，执行问题陈述中指定的三个布尔比较，并存储结果三元组。\n\n5.  **输出：**\n    - 收集所有测试用例的三元组，并以要求的格式打印：`[[bool,bool,bool],[bool,bool,bool],[...]]`。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import cholesky, solve_triangular\nfrom scipy.stats import norm\nfrom scipy.stats.qmc import Sobol\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    test_cases = [\n        # Case A: high-dimensional, moderately ill-conditioned\n        {'n': 60, 'd': 50, 'tau': 1.0, 'sigma': 0.5, 'rho': 0.7,\n         's_X': 1729, 's_w': 2718, 's_epsilon': 31415, 's_star': 4242,\n         's_iid': 7771, 's_anti': 7772, 's_qmc': 12345},\n        # Case B: underdetermined, d >> n\n        {'n': 30, 'd': 100, 'tau': 1.5, 'sigma': 1.0, 'rho': 0.5,\n         's_X': 2021, 's_w': 1618, 's_epsilon': 1414, 's_star': 1732,\n         's_iid': 8881, 's_anti': 8882, 's_qmc': 23456},\n        # Case C: near-collinearity\n        {'n': 80, 'd': 80, 'tau': 0.8, 'sigma': 0.3, 'rho': 0.95,\n         's_X': 271828, 's_w': 161803, 's_epsilon': 141421, 's_star': 173205,\n         's_iid': 9991, 's_anti': 9992, 's_qmc': 34567},\n    ]\n\n    sample_sizes = [128, 512, 2048, 8192]\n    all_results = []\n    for case_params in test_cases:\n        results = run_case(case_params, sample_sizes)\n        all_results.append(results)\n\n    print(f\"[{','.join(map(str, all_results))}]\")\n\ndef run_case(params, sample_sizes):\n    \"\"\"\n    Executes the entire simulation for a single test case.\n    \"\"\"\n    n, d, tau, sigma, rho = params['n'], params['d'], params['tau'], params['sigma'], params['rho']\n    s_X, s_w, s_epsilon, s_star = params['s_X'], params['s_w'], params['s_epsilon'], params['s_star']\n    s_iid, s_anti, s_qmc = params['s_iid'], params['s_anti'], params['s_qmc']\n\n    # 1. Data Generation\n    # Generate covariance matrix Sigma_X and its Cholesky factor\n    indices = np.arange(d)\n    Sigma_X = rho ** np.abs(indices[:, np.newaxis] - indices)\n    L_X = np.linalg.cholesky(Sigma_X)\n\n    # Generate X\n    rng_X = np.random.default_rng(s_X)\n    Z_X = rng_X.standard_normal((n, d))\n    X = Z_X @ L_X.T\n\n    # Generate w_true\n    rng_w = np.random.default_rng(s_w)\n    w_true = tau * rng_w.standard_normal(d)\n\n    # Generate epsilon\n    rng_eps = np.random.default_rng(s_epsilon)\n    epsilon = sigma * rng_eps.standard_normal(n)\n\n    # Generate y\n    y = X @ w_true + epsilon\n\n    # Generate x_star\n    rng_star = np.random.default_rng(s_star)\n    x_star = L_X @ rng_star.standard_normal(d)\n\n    # 2. Posterior and Exact Moments Calculation\n    # Posterior precision matrix A\n    A = (1 / sigma**2) * (X.T @ X) + (1 / tau**2) * np.identity(d)\n    \n    # Cholesky factorization of A (upper triangular)\n    R = cholesky(A, lower=False)\n\n    # Posterior mean mu\n    b = (1 / sigma**2) * (X.T @ y)\n    v = solve_triangular(R, b, trans='T', lower=False)\n    mu = solve_triangular(R, v, trans='N', lower=False)\n\n    # Exact predictive mean mu_star\n    mu_star = x_star @ mu\n\n    # Exact predictive variance v_star\n    v_solve = solve_triangular(R, x_star, trans='T', lower=False)\n    u_solve = solve_triangular(R, v_solve, trans='N', lower=False)\n    var_w_term = x_star @ u_solve\n    v_star = var_w_term + sigma**2\n\n    # 3. Monte Carlo Estimation\n    errors = {}\n    samplers = {\n        'iid': lambda N, seed: np.random.default_rng(seed).standard_normal((N, d)),\n        'anti': lambda N, seed: _generate_antithetic(N, d, seed),\n        'qmc': lambda N, seed: _generate_qmc(N, d, seed)\n    }\n    sampler_seeds = {'iid': s_iid, 'anti': s_anti, 'qmc': s_qmc}\n\n    for name, sampler_func in samplers.items():\n        E_mean, E_var = 0.0, 0.0\n        for N in sample_sizes:\n            z_samples = sampler_func(N, sampler_seeds[name])\n\n            # Transform standard normal samples to posterior samples\n            # u = R^-1 * z\n            u_samples = solve_triangular(R, z_samples.T, lower=False).T\n            w_samples = mu + u_samples\n            \n            # Predictions\n            p_samples = w_samples @ x_star\n\n            # Estimated moments\n            mu_hat = np.mean(p_samples)\n            v_hat = np.var(p_samples, ddof=0) + sigma**2\n\n            # Accumulate errors\n            E_mean += np.abs(mu_hat - mu_star)\n            E_var += np.abs(v_hat - v_star)\n        \n        errors[name] = {'mean': E_mean, 'var': E_var}\n\n    # 4. Final Comparison\n    anti_improves_mean = errors['anti']['mean']  errors['iid']['mean']\n    qmc_improves_mean = errors['qmc']['mean']  errors['iid']['mean']\n    qmc_improves_var = errors['qmc']['var']  errors['iid']['var']\n\n    return [anti_improves_mean, qmc_improves_mean, qmc_improves_var]\n\ndef _generate_antithetic(N, d, seed):\n    \"\"\"Generates N antithetic standard normal samples.\"\"\"\n    rng = np.random.default_rng(seed)\n    half_N = N // 2\n    z_half = rng.standard_normal((half_N, d))\n    return np.vstack((z_half, -z_half))\n\ndef _generate_qmc(N, d, seed):\n    \"\"\"Generates N QMC standard normal samples.\"\"\"\n    sobol_engine = Sobol(d=d, scramble=True, seed=seed)\n    u_samples = sobol_engine.random(n=N)\n    # Clip to avoid infinity from ppf\n    u_samples = np.clip(u_samples, 1e-12, 1 - 1e-12)\n    return norm.ppf(u_samples)\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "构建了采样器之后，我们如何确信它是正确的？这是模拟工作流程中至关重要的一步，在并行计算环境中尤其棘手，因为细微的错误可能导致难以察觉的系统性偏差。本练习  提供了一个构建统计诊断工具的框架，用于检测多元正态采样器输出中意外的坐标间相关性，从而确保模拟结果的可靠性与有效性。",
            "id": "3322614",
            "problem": "在随机模拟和蒙特卡洛方法领域，您有一项任务：当并行实现重用或共享随机数流时，诊断来自多元正态分布的样本中坐标间的意外依赖性。目标是提出、论证并实现一套统计检验，用以检测不属于预期目标协方差结构的坐标间依赖性。您的最终程序必须实现这些检验，将其应用于指定的测试场景套件，并输出一行结果。\n\n从基本定义和广为接受的事实出发：\n- 如果一个随机向量 $\\mathbf{X} \\in \\mathbb{R}^p$ 的每个分量的线性组合都是单变量正态的，则称其为均值为 $\\boldsymbol{\\mu} \\in \\mathbb{R}^p$、协方差矩阵为 $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{p \\times p}$ 的多元正态分布，记作 $\\mathbf{X} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$。\n- 如果 $\\boldsymbol{\\Sigma}$ 是正定矩阵，则存在一个下三角 Cholesky 因子 $\\mathbf{L}$，使得 $\\boldsymbol{\\Sigma} = \\mathbf{L}\\mathbf{L}^\\top$。\n- 如果 $\\mathbf{Z} \\sim \\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$，那么 $\\boldsymbol{\\mu} + \\mathbf{L}\\mathbf{Z} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$。\n- 如果样本 $\\{\\mathbf{X}_k\\}_{k=1}^n$ 是从已知目标 $\\boldsymbol{\\Sigma}_0$ 的 $\\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}_0)$ 中生成的，那么白化样本 $\\mathbf{Y}_k = \\mathbf{L}_0^{-1}(\\mathbf{X}_k - \\boldsymbol{\\mu})$（其中 $\\boldsymbol{\\Sigma}_0 = \\mathbf{L}_0\\mathbf{L}_0^\\top$），在不存在超出 $\\boldsymbol{\\Sigma}_0$ 的意外依赖性的情况下，应该是独立同分布的，且 $\\mathbf{Y}_k \\sim \\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$。\n- 在多元正态性下，样本协方差矩阵服从 Wishart 分布，其相关性结构可以通过既有检验来评估是否满足球形性（单位相关矩阵）。\n\n设计并论证一套应用于白化样本 $\\{\\mathbf{Y}_k\\}$ 的检验，以诊断坐标间的意外依赖性：\n1. 在真实相关性为 $\\mathbf{I}_p$ 的原假设下，对 $\\{\\mathbf{Y}_k\\}$ 的相关矩阵进行全局球形性检验。具体来说，使用 Bartlett 球形性检验，评估样本相关矩阵与 $\\mathbf{I}_p$ 的偏离是否超出了在 $\\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$ 下的预期。\n2. 对 $\\{\\mathbf{Y}_k\\}$ 的坐标对进行一系列零相关性的成对检验，并通过 Bonferroni 校正进行族错误率控制。每个成对检验都应评估样本相关系数是否为零。\n\n您的程序必须：\n- 使用指定的采样器为每个测试用例生成样本。\n- 使用已知目标协方差 $\\boldsymbol{\\Sigma}_0$ 对样本进行白化，将问题转化为在 $\\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$ 下检验独立性。\n- 计算 Bartlett 球形性检验统计量及其近似的卡方 $p$ 值，自由度为 $p(p-1)/2$。\n- 在零相关性的原假设下，使用学生t分布计算所有成对相关性检验，并对所有 $p(p-1)/2$ 个配对应用 Bonferroni 校正以控制族错误率。\n- 如果 Bartlett 球形性检验在显著性水平 $\\alpha$ 下拒绝原假设，或任何经 Bonferroni 校正的成对检验在显著性水平 $\\alpha$ 下拒绝原假设，则声明检测到意外依赖性。\n\n使用显著性水平 $\\alpha = 0.01$。\n\n测试套件：\n为保证可复现性，请使用指定的种子。每个测试用例是一个元组，指定采样器类型、样本大小 $n$、维度 $p$、目标协方差 $\\boldsymbol{\\Sigma}_0$、共享流参数 $\\rho$（如果适用）以及随机种子。采样器定义如下：\n- \"correct\": 对每个样本，独立抽取 $\\mathbf{Z}_k \\sim \\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$ 并设置 $\\mathbf{X}_k = \\boldsymbol{\\mu} + \\mathbf{L}_0 \\mathbf{Z}_k$。\n- \"shared\": 对每个样本，抽取 $U_k \\sim \\mathcal{N}(0,1)$ 并设置 $\\mathbf{Z}_k = U_k \\mathbf{1}_p$，因此所有坐标共享相同的基础标准正态分布，然后 $\\mathbf{X}_k = \\boldsymbol{\\mu} + \\mathbf{L}_0 \\mathbf{Z}_k$。\n- \"partial\": 对每个样本，独立抽取 $U_k \\sim \\mathcal{N}(0,1)$ 和 $\\mathbf{V}_k \\sim \\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$，并设置 $\\mathbf{Z}_k = \\sqrt{\\rho}\\,U_k \\mathbf{1}_p + \\sqrt{1-\\rho}\\,\\mathbf{V}_k$，然后 $\\mathbf{X}_k = \\boldsymbol{\\mu} + \\mathbf{L}_0 \\mathbf{Z}_k$。\n\n所有情况下均设 $\\boldsymbol{\\mu} = \\mathbf{0}$。目标协方差 $\\boldsymbol{\\Sigma}_0$ 定义如下：\n- 情况 1 (\"correct\"): $\\boldsymbol{\\Sigma}_0$ 为参数 $\\phi = 0.6$ 的一阶自回归，即 $(\\boldsymbol{\\Sigma}_0)_{ij} = \\phi^{|i-j|}$，维度 $p = 6$，样本大小 $n = 1000$，种子 $12345$。\n- 情况 2 (\"shared\"): $\\boldsymbol{\\Sigma}_0$ 为与情况1相同的自回归协方差，参数 $\\phi = 0.6$，维度 $p = 6$，样本大小 $n = 300$，种子 $54321$。\n- 情况 3 (\"partial\"): $\\boldsymbol{\\Sigma}_0$ 为对角矩阵，对角线元素为 $(1.0, 1.5, 0.5, 2.0, 1.2, 0.8, 1.7, 1.1)$，维度 $p = 8$，共享流参数 $\\rho = 0.3$，样本大小 $n = 100$，种子 $2024$。\n\n答案规格：\n- 对于每个测试用例，您的程序必须输出一个布尔值，指示是否检测到意外依赖性（如果检测到则为 $\\text{True}$，否则为 $\\text{False}$），使用上述在显著性水平 $\\alpha = 0.01$ 下的决策规则。\n- 您的程序应生成单行输出，其中包含按测试用例顺序（情况1、情况2、情况3）排列的结果，形式为方括号括起来的逗号分隔列表。例如，输出形式可能为 $[\\text{False},\\text{True},\\text{True}]$。\n\n此问题不涉及物理单位或角度单位。显著性水平应表示为十进制数（例如，$0.01$）。程序的实现应基于提供的种子完全确定，且无需用户输入。",
            "solution": "我们从多元正态分布及其性质的基本定义开始。如果一个随机向量 $\\mathbf{X} \\in \\mathbb{R}^p$ 的每个分量的线性组合都是单变量正态的，则称其为均值为 $\\boldsymbol{\\mu}$、协方差为 $\\boldsymbol{\\Sigma}$ 的多元正态分布，记作 $\\mathbf{X} \\sim \\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$。如果 $\\boldsymbol{\\Sigma}$ 是正定矩阵，我们可以将其写为 $\\boldsymbol{\\Sigma} = \\mathbf{L}\\mathbf{L}^\\top$，其中 $\\mathbf{L}$ 是一个下三角 Cholesky 因子。如果 $\\mathbf{Z} \\sim \\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$，那么 $\\boldsymbol{\\mu} + \\mathbf{L}\\mathbf{Z}$ 的分布为 $\\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$。\n\n当从 $\\mathcal{N}_p(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}_0)$ 采样时，如果我们应用白化变换 $\\mathbf{Y}_k = \\mathbf{L}_0^{-1}(\\mathbf{X}_k - \\boldsymbol{\\mu})$（其中 $\\boldsymbol{\\Sigma}_0 = \\mathbf{L}_0\\mathbf{L}_0^\\top$），那么在正确实现下，我们应该有 $\\mathbf{Y}_k \\sim \\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$ 独立同分布。在并行的蒙特卡洛实现中，跨坐标意外共享或重用随机数流可能产生 $\\mathbf{Z}_k$ 向量，其分量间的依赖性超出了 $\\boldsymbol{\\Sigma}_0$ 所隐含的预期结构。白化之后，这种意外的依赖性表现为 $\\mathbf{Y}_k$ 坐标间独立性的偏离。\n\n现在，我们基于正态理论和协方差性质，设计并论证用于检测此类偏离的检验。\n\n步骤 1：白化变换。\n给定样本 $\\{\\mathbf{X}_k\\}_{k=1}^n$、已知目标协方差 $\\boldsymbol{\\Sigma}_0$ 和均值 $\\boldsymbol{\\mu}$，计算 Cholesky 因子 $\\mathbf{L}_0$ 使得 $\\boldsymbol{\\Sigma}_0 = \\mathbf{L}_0\\mathbf{L}_0^\\top$，并设置 $\\mathbf{Y}_k = \\mathbf{L}_0^{-1}(\\mathbf{X}_k - \\boldsymbol{\\mu})$。在正确采样的原假设下，$\\mathbf{Y}_k \\sim \\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$ 独立同分布。\n\n步骤 2：全局球形性检验 (Bartlett)。\n在 $\\mathbf{Y}_k \\sim \\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$ 下，真实相关矩阵为 $\\mathbf{I}_p$。令 $\\hat{\\mathbf{R}}$ 表示 $\\{\\mathbf{Y}_k\\}$ 的样本相关矩阵。Bartlett 球形性检验评估的是：\n$$\nH_0: \\ \\mathbf{R} = \\mathbf{I}_p \\quad \\text{versus} \\quad H_1: \\ \\mathbf{R} \\neq \\mathbf{I}_p.\n$$\n检验统计量为\n$$\n\\chi^2_{\\text{Bart}} = -\\left(n - 1 - \\frac{2p + 5}{6}\\right)\\ln\\det(\\hat{\\mathbf{R}}),\n$$\n在 $H_0$ 和多元正态性下，该统计量近似服从自由度为 $p(p-1)/2$ 的卡方分布。$\\chi^2_{\\text{Bart}}$ 的值越大，表明与球形性的偏离越大。如果 $\\det(\\hat{\\mathbf{R}}) \\leq 0$（当 $\\hat{\\mathbf{R}}$ 接近奇异时可能发生），我们将 $\\chi^2_{\\text{Bart}}$ 解释为 $+\\infty$，并以 $p$ 值为 0 拒绝 $H_0$。\n\n论证：在 $\\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$ 下，样本相关矩阵的期望为 $\\mathbf{I}_p$。跨坐标共享随机数流会在 $\\mathbf{Y}_k$ 中引入线性依赖，这会减小 $\\det(\\hat{\\mathbf{R}})$ 并增大 $\\chi^2_{\\text{Bart}}$ 统计量，从而对全局独立性的偏离提供敏感性。\n\n步骤 3：带 Bonferroni 控制的成对相关性检验。\n对于每对 $(i,j)$（$1 \\leq i  j \\leq p$），计算样本相关系数 $\\hat{r}_{ij}$。在独立性的 $H_0$ 下，统计量\n$$\nt_{ij} = \\hat{r}_{ij}\\sqrt{\\frac{n - 2}{1 - \\hat{r}_{ij}^2}}\n$$\n服从自由度为 $n - 2$ 的学生t分布。计算双边 $p$ 值 $p_{ij} = 2 \\cdot \\Pr\\left(T_{n-2} \\geq |t_{ij}|\\right)$。共有 $m = p(p-1)/2$ 个配对；应用 Bonferroni 校正来控制族错误率，方法是在 $\\alpha/m$ 水平上检验每个配对，或等效地将校正后的 $p$ 值 $p_{ij}^{\\text{adj}} = \\min(1, m \\cdot p_{ij})$ 与 $\\alpha$ 进行比较。如果 $p_{ij}^{\\text{adj}}  \\alpha$，则声明配对 $(i,j)$ 存在依赖关系。如果任何配对被拒绝，则声明检测到意外依赖性。\n\n论证：共享随机数流通常会在坐标间引入线性相关。成对相关性检验能够捕捉这种线性依赖。Bonferroni 校正为控制至少一次错误拒绝的概率提供了一种保守但简单的方法。\n\n决策规则：\n在显著性水平 $\\alpha = 0.01$ 下，如果 Bartlett 球形性检验的 $p$ 值小于 $\\alpha$，或所有配对中最小的经 Bonferroni 校正的成对 $p$ 值小于 $\\alpha$，则声明检测到意外依赖性。\n\n测试套件和采样器：\n我们考虑三个具有指定种子的用例以确保可复现性。\n\n情况 1 (\"correct\"): $p = 6$, $n = 1000$, $\\boldsymbol{\\mu} = \\mathbf{0}$，$\\boldsymbol{\\Sigma}_0$ 为参数 $\\phi = 0.6$ 的一阶自回归，即 $(\\boldsymbol{\\Sigma}_0)_{ij} = \\phi^{|i - j|}$，种子 $12345$。采样器生成独立的 $\\mathbf{Z}_k \\sim \\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$，因此白化后 $\\mathbf{Y}_k \\sim \\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$，检验应不会检测到依赖性，得出 $\\text{False}$。\n\n情况 2 (\"shared\"): $p = 6$, $n = 300$, $\\boldsymbol{\\mu} = \\mathbf{0}$，$\\boldsymbol{\\Sigma}_0$ 为与情况1相同的自回归协方差，参数 $\\phi = 0.6$，种子 $54321$。采样器使用 $\\mathbf{Z}_k = U_k \\mathbf{1}_p$（其中 $U_k \\sim \\mathcal{N}(0,1)$），因此所有坐标共享相同的标准正态分布。白化后，$\\mathbf{Y}_k = \\mathbf{Z}_k$，其坐标间具有完全相关性。Bartlett 检验和成对检验都应检测到依赖性，得出 $\\text{True}$。\n\n情况 3 (\"partial\"): $p = 8$, $n = 100$, $\\boldsymbol{\\mu} = \\mathbf{0}$, $\\boldsymbol{\\Sigma}_0 = \\operatorname{diag}(1.0, 1.5, 0.5, 2.0, 1.2, 0.8, 1.7, 1.1)$, 种子 $2024$，共享流参数 $\\rho = 0.3$。采样器使用 $\\mathbf{Z}_k = \\sqrt{\\rho}\\, U_k \\mathbf{1}_p + \\sqrt{1 - \\rho}\\,\\mathbf{V}_k$，其中 $U_k \\sim \\mathcal{N}(0,1)$ 和 $\\mathbf{V}_k \\sim \\mathcal{N}_p(\\mathbf{0}, \\mathbf{I}_p)$ 独立；共享分量在 $\\mathbf{Y}_k$ 的坐标间引入了近似为 $\\rho$ 的等相关性。Bartlett 球形性检验对全局相关结构敏感，应在 $\\alpha = 0.01$ 水平上检测到依赖性，得出 $\\text{True}$。\n\n算法设计：\n- 实现函数以构建一阶自回归和对角情况下的 $\\boldsymbol{\\Sigma}_0$。\n- 为 \"correct\"、\"shared\" 和 \"partial\" 场景实现采样器。\n- 通过对每个样本求解 $\\mathbf{L}_0 \\mathbf{y} = \\mathbf{x} - \\boldsymbol{\\mu}$ 来实现白化，等效于 $\\mathbf{y} = \\mathbf{L}_0^{-1}(\\mathbf{x} - \\boldsymbol{\\mu})$。\n- 计算样本相关矩阵、Bartlett 球形性统计量和 $p$ 值，以及带有 Bonferroni 校正 $p$ 值的成对相关性族。\n- 应用决策规则，为每个测试用例生成布尔结果。\n\n最终输出格式：\n生成单行输出，其中包含三个布尔结果，按顺序排列，形式为方括号括起来的逗号分隔列表，例如 $[\\text{False},\\text{True},\\text{True}]$。\n\n该方法整合了多元正态理论、协方差结构、白化变换和经典假设检验，以诊断并行实现中因共享随机数流而产生的意外依赖性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef make_cov_ar1(p: int, phi: float) - np.ndarray:\n    \"\"\"Construct an AR(1) covariance matrix with parameter phi.\"\"\"\n    idx = np.arange(p)\n    return phi ** np.abs(idx[:, None] - idx[None, :])\n\ndef sample_correct(n: int, mu: np.ndarray, Sigma: np.ndarray, rng: np.random.Generator) - np.ndarray:\n    \"\"\"Generate n samples from N(mu, Sigma) using independent standard normals.\"\"\"\n    p = Sigma.shape[0]\n    L = np.linalg.cholesky(Sigma)\n    Z = rng.standard_normal(size=(n, p))\n    return mu + Z @ L.T\n\ndef sample_shared_stream(n: int, mu: np.ndarray, Sigma: np.ndarray, rng: np.random.Generator) - np.ndarray:\n    \"\"\"Generate n samples where all coordinates share the same standard normal per sample.\"\"\"\n    p = Sigma.shape[0]\n    L = np.linalg.cholesky(Sigma)\n    U = rng.standard_normal(size=(n, 1))\n    Z = np.repeat(U, p, axis=1)  # each row has identical entries\n    return mu + Z @ L.T\n\ndef sample_partial_shared(n: int, mu: np.ndarray, Sigma: np.ndarray, rho: float, rng: np.random.Generator) - np.ndarray:\n    \"\"\"Generate n samples with a shared component sqrt(rho)*U*1_p plus independent component.\"\"\"\n    p = Sigma.shape[0]\n    L = np.linalg.cholesky(Sigma)\n    U = rng.standard_normal(size=(n, 1))\n    V = rng.standard_normal(size=(n, p))\n    Z = np.sqrt(rho) * np.repeat(U, p, axis=1) + np.sqrt(1.0 - rho) * V\n    return mu + Z @ L.T\n\ndef whiten_samples(X: np.ndarray, mu: np.ndarray, Sigma0: np.ndarray) - np.ndarray:\n    \"\"\"Whiten samples with respect to the known target covariance Sigma0.\"\"\"\n    L0 = np.linalg.cholesky(Sigma0)\n    # Solve L0 Y^T = (X - mu)^T - Y = L0^{-1} (X - mu)\n    centered = X - mu\n    # Use solve for stability\n    YT = np.linalg.solve(L0, centered.T)\n    Y = YT.T\n    return Y\n\ndef bartlett_sphericity_test(Y: np.ndarray) - float:\n    \"\"\"Compute Bartlett's sphericity test p-value for the correlation matrix of Y.\"\"\"\n    n, p = Y.shape\n    if n = p: # Not enough samples to have a non-singular correlation matrix\n        return 0.0\n    R = np.corrcoef(Y, rowvar=False)\n    sign, logdet = np.linalg.slogdet(R)\n    if sign = 0:\n        # Singular or non-positive definite correlation matrix: infinite statistic, p-value 0\n        return 0.0\n    # Bartlett's test statistic\n    c = n - 1 - (2 * p + 5) / 6.0\n    stat = -c * logdet\n    df = p * (p - 1) // 2\n    pval = 1.0 - stats.chi2.cdf(stat, df)\n    return float(pval)\n\ndef pairwise_bonferroni_test(Y: np.ndarray, alpha: float) - (bool, float):\n    \"\"\"Perform all pairwise correlation tests with Bonferroni adjustment. Return (reject_any, min_adj_p).\"\"\"\n    n, p = Y.shape\n    if n = 2:\n        return False, 1.0\n    m = p * (p - 1) // 2\n    if m == 0:\n        return False, 1.0\n    # Compute correlation matrix\n    R = np.corrcoef(Y, rowvar=False)\n    df = n - 2\n    min_adj_p = 1.0\n    reject_any = False\n    for i in range(p):\n        for j in range(i + 1, p):\n            r = R[i, j]\n            # Guard against edge cases r ~ +/-1 leading to division by zero; clamp slightly\n            r = np.clip(r, -0.999999999, 0.999999999)\n            t_stat = r * np.sqrt(df / (1.0 - r ** 2))\n            pval = 2.0 * stats.t.sf(np.abs(t_stat), df)\n            adj_p = min(1.0, m * pval)\n            if adj_p  min_adj_p:\n                min_adj_p = adj_p\n            if adj_p  alpha:\n                reject_any = True\n    return reject_any, float(min_adj_p)\n\ndef detect_unintended_dependence(X: np.ndarray, mu: np.ndarray, Sigma0: np.ndarray, alpha: float) - bool:\n    \"\"\"Apply whitening, then Bartlett sphericity and pairwise Bonferroni tests; return boolean detection.\"\"\"\n    Y = whiten_samples(X, mu, Sigma0)\n    pval_bartlett = bartlett_sphericity_test(Y)\n    reject_bartlett = pval_bartlett  alpha\n    reject_pairs, _ = pairwise_bonferroni_test(Y, alpha)\n    return bool(reject_bartlett or reject_pairs)\n\ndef solve():\n    # Define significance level\n    alpha = 0.01\n\n    # Define the test cases from the problem statement.\n    # Each case: dict with keys: sampler, n, p, Sigma0, rho (optional), seed\n    # Case 1: Correct sampler, AR(1) covariance\n    p1 = 6\n    Sigma1 = make_cov_ar1(p1, phi=0.6)\n    case1 = {\n        \"sampler\": \"correct\",\n        \"n\": 1000,\n        \"p\": p1,\n        \"Sigma0\": Sigma1,\n        \"seed\": 12345\n    }\n\n    # Case 2: Shared stream sampler, same AR(1) covariance\n    p2 = 6\n    Sigma2 = make_cov_ar1(p2, phi=0.6)\n    case2 = {\n        \"sampler\": \"shared\",\n        \"n\": 300,\n        \"p\": p2,\n        \"Sigma0\": Sigma2,\n        \"seed\": 54321\n    }\n\n    # Case 3: Partial shared stream sampler, diagonal covariance\n    Sigma3 = np.diag([1.0, 1.5, 0.5, 2.0, 1.2, 0.8, 1.7, 1.1])\n    case3 = {\n        \"sampler\": \"partial\",\n        \"n\": 100,\n        \"p\": 8,\n        \"Sigma0\": Sigma3,\n        \"rho\": 0.3,\n        \"seed\": 2024\n    }\n\n    test_cases = [case1, case2, case3]\n\n    results = []\n    for case in test_cases:\n        sampler = case[\"sampler\"]\n        n = case[\"n\"]\n        Sigma0 = case[\"Sigma0\"]\n        p = case[\"p\"]\n        mu = np.zeros(p)\n        rng = np.random.default_rng(case[\"seed\"])\n\n        if sampler == \"correct\":\n            X = sample_correct(n, mu, Sigma0, rng)\n        elif sampler == \"shared\":\n            X = sample_shared_stream(n, mu, Sigma0, rng)\n        elif sampler == \"partial\":\n            rho = case[\"rho\"]\n            X = sample_partial_shared(n, mu, Sigma0, rho, rng)\n        else:\n            # Unknown sampler type; treat as failure to detect\n            X = sample_correct(n, mu, Sigma0, rng)\n\n        detected = detect_unintended_dependence(X, mu, Sigma0, alpha)\n        results.append(detected)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}