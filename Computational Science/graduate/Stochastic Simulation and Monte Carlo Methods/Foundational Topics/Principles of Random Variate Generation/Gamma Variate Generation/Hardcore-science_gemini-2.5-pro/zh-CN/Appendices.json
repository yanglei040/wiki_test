{
    "hands_on_practices": [
        {
            "introduction": "理论学习的最佳伙伴是动手实践。本章的第一个练习将引导你从零开始，构建一个功能完备的伽马分布随机变量生成器。这个练习不仅涵盖了处理不同形状参数 $k$（如 $k1$ 和 $0k1$）的多种算法，还要求你通过一系列严谨的统计测试来验证其正确性，确保你的实现不仅能运行，而且在统计意义上是可靠的。通过这个过程，你将对伽马采样的复杂性有更深入的理解，并为后续更高级的应用打下坚实的基础。",
            "id": "3056410",
            "problem": "请使用接受-拒绝抽样法和增广法，实现一个统计上精确的伽马分布随机变量生成器，并通过一组基于基本分布关系的测试来验证其正确性。具体来说，构建一个程序，模拟从形状参数为 $k$、尺度参数为 $\\theta$ 的伽马分布（记作 $\\Gamma(k,\\theta)$）中抽取的独立同分布样本。程序应仅依赖于以下基本原理：(i) 伽马分布的定义，即在 $(0,\\infty)$ 上具有概率密度函数的一族分布；(ii) 用于验证样本矩的大数定律；(iii) 使用有效提议分布的接受-拒绝法；(iv) 贝塔分布的定义，即具有相同尺度的独立伽马随机变量之比的分布；以及 (v) 卡方分布作为伽马分布特例的定义。请勿使用任何预先构建的伽马、贝塔或卡方分布的抽样器。\n\n您的实现必须满足以下规范。\n- 对于 $k1$，使用一个基于标准正态提议分布的变换和“挤压”接受区域的接受-拒绝抽样器。该方法必须完全从基本原理出发，使用独立的均匀分布和标准正态分布变量进行编码。\n- 对于 $0k1$，使用增广法，该方法利用已为形状参数大于1实现的抽样器。\n- 对于边界情况 $k=1$，使用逆变换法。\n- 必须包含一个使用Box-Muller变换实现的标准正态随机变量生成器。\n- 您必须执行以下五个测试，并以布尔列表的形式打印结果：\n1. 从 $\\Gamma(3.5, 2.0)$ 中抽取200,000个样本，并验证样本均值和方差分别在理论值的 $\\pm 0.03$ 和 $\\pm 0.30$ 范围内。\n2. 从 $\\Gamma(0.7, 1.5)$ 中抽取200,000个样本，并验证样本均值和方差分别在理论值的 $\\pm 0.03$ 和 $\\pm 0.10$ 范围内。\n3. 通过生成两个独立的标准伽马变量的比率来生成200,000个 $\\mathrm{Beta}(2.1, 3.3)$ 样本，并验证样本均值在理论值的 $\\pm 0.01$ 范围内。\n4. 从一个自由度为 $\\nu=10$ 的卡方分布中抽取200,000个样本（将其实现为伽马分布的特例），并验证样本均值和方差分别在理论值的 $\\pm 0.03$ 和 $\\pm 0.20$ 范围内。\n5. 从 $\\Gamma(1.0, 0.8)$（一个指数分布）中抽取200,000个样本，并验证样本均值和方差分别在理论值的 $\\pm 0.02$ 和 $\\pm 0.05$ 范围内。\n\n最终输出应为单个布尔值列表，例如`[True,True,True,True,True,True,True,True,True]`。",
            "solution": "经评估，用户提供的问题是有效的，因为它在科学上是合理的、问题是明确的、客观的且内部是一致的。它提出了一个计算统计学中的标准但并非微不足道的问题：从基本原理出发，实现一个伽马分布的随机变量生成器并验证其性质。问题陈述为获得一个唯一且可验证的解提供了所有必要的定义、算法和测试条件。\n\n该解决方案首先构建一个标准伽马分布 $\\Gamma(k,1)$ 的生成器，然后利用尺度性质将其扩展到一般的 $\\Gamma(k,\\theta)$ 分布：如果 $X \\sim \\Gamma(k,1)$，则 $\\theta X \\sim \\Gamma(k,\\theta)$。标准伽马变量的生成由三种不同的方法处理，根据形状参数 $k$ 的值进行选择。\n\n所需的标准正态变量 $Z \\sim N(0,1)$ 是使用 Box-Muller 变换由成对的独立均匀变量 $U_1, U_2 \\sim \\operatorname{Uniform}(0,1)$ 合成的：$Z_1 = \\sqrt{-2 \\ln(U_1)} \\cos(2\\pi U_2)$ 和 $Z_2 = \\sqrt{-2 \\ln(U_1)} \\sin(2\\pi U_2)$。此变换为每对均匀样本生成两个独立的 $N(0,1)$ 样本。\n\n形状参数 $k$ 的三种情况如下：\n\n1.  **对于 $k  1$**：使用 Marsaglia and Tsang (2000) 的接受-拒绝法。这是一种高效的算法。\n    设目标分布为标准伽马分布 $\\Gamma(k,1)$。该方法使用对标准正态变量 $Z \\sim N(0,1)$ 的一个巧妙变换来提出候选值 $X$。算法如下：\n    a. 预计算常数 $d = k - 1/3$ 和 $c = 1/\\sqrt{9d}$。\n    b. 生成一个标准正态变量 $Z$ 和一个均匀变量 $U \\sim \\operatorname{Uniform}(0,1)$。\n    c. 计算 $V = (1+cZ)^3$。如果 $V \\le 0$，则拒绝并返回步骤 (b)。\n    d. 提议的伽马分布值为 $X = dV$。\n    e. 如果满足以下条件，则接受 $X$：$\\ln(U)  \\frac{Z^2}{2} + d - X + d \\ln(V)$。否则，拒绝 $X$ 并返回步骤 (b)。\n    重复此过程，直到生成所需数量的样本。\n\n2.  **对于 $0  k  1$**：采用 Ahrens and Dieter (1974) 描述的增广法。此方法利用了形状参数大于1的生成器。它基于以下性质：如果 $Y \\sim \\Gamma(k+1,1)$ 和 $U \\sim \\operatorname{Uniform}(0,1)$ 是独立的，那么随机变量 $X = Y \\cdot U^{1/k}$ 服从 $\\Gamma(k,1)$ 分布。\n    由于 $0  k  1$，所需变量 $Y$ 的形状参数 $k+1$ 将在 $(1,2)$ 范围内。因此，我们可以使用上述为 $k  1$ 设计的接受-拒绝法来生成 $Y$。这是一种直接方法（无拒绝），因此一个 $Y$ 和一个 $U$ 产生一个 $X$。\n\n3.  **对于 $k = 1$**：这是一个边界情况。$\\Gamma(1,1)$ 分布是标准指数分布 $\\operatorname{Exp}(1)$。可以使用逆变换法进行高效且精确的抽样。如果 $U \\sim \\operatorname{Uniform}(0,1)$，那么 $X = -\\ln(U)$ 服从 $\\operatorname{Exp}(1)$ 分布。\n\n最终的实现将这些方法整合到一个生成器函数中。然后使用该生成器执行五个指定的测试。对于每个测试，生成大量样本（$n=200000$），并将其样本矩（均值和方差）与从伽马、贝塔和卡方分布的性质推导出的理论值进行比较。这些比较的结果（布尔值）被收集起来并按指定格式打印。为随机数生成器使用固定种子可确保结果是可复现的。",
            "answer": "```python\nimport numpy as np\n\ndef _my_normal_sampler(size: int, rng: np.random.Generator) - np.ndarray:\n    \"\"\"Generates standard normal variates using the Box-Muller transform.\"\"\"\n    if size == 0:\n        return np.array([])\n    \n    num_pairs = (size + 1) // 2\n    u1 = rng.uniform(size=num_pairs)\n    # Avoid u1=0 for log\n    u1[u1 == 0] = 1e-100 \n    u2 = rng.uniform(size=num_pairs)\n    \n    r = np.sqrt(-2.0 * np.log(u1))\n    theta = 2.0 * np.pi * u2\n    \n    z1 = r * np.cos(theta)\n    z2 = r * np.sin(theta)\n    \n    all_z = np.empty(2 * num_pairs)\n    all_z[0::2] = z1\n    all_z[1::2] = z2\n    \n    return all_z[:size]\n\ndef _gamma_sampler_gt1(k: float, n: int, rng: np.random.Generator) - np.ndarray:\n    \"\"\"\n    Generates n samples from a standard Gamma(k, 1) distribution for k  1.\n    Uses the Marsaglia and Tsang (2000) acceptance-rejection method.\n    \"\"\"\n    d = k - 1.0/3.0\n    c = 1.0 / np.sqrt(9.0 * d)\n    \n    samples = np.empty(n)\n    count = 0\n    \n    while count  n:\n        needed = n - count\n        \n        # Generate candidate Zs and Us\n        z = _my_normal_sampler(needed, rng)\n        u = rng.uniform(size=needed)\n        \n        v = (1.0 + c * z)**3\n        \n        # Filter for valid V  0\n        mask_valid_v = v  0\n        z_valid = z[mask_valid_v]\n        u_valid = u[mask_valid_v]\n        v_valid = v[mask_valid_v]\n        \n        if len(v_valid) == 0:\n            continue\n            \n        x_cand = d * v_valid\n        \n        # Squeeze test and main acceptance condition\n        log_u_valid = np.log(u_valid)\n        accept_mask = log_u_valid  (0.5 * z_valid**2 + d - x_cand + d * np.log(v_valid))\n        \n        accepted_samples = x_cand[accept_mask]\n        num_accepted = len(accepted_samples)\n        \n        if num_accepted  0:\n            fill_count = min(num_accepted, needed)\n            samples[count:count + fill_count] = accepted_samples[:fill_count]\n            count += fill_count\n            \n    return samples\n\ndef _gamma_sampler_eq1(n: int, rng: np.random.Generator) - np.ndarray:\n    \"\"\"\n    Generates n samples from a standard Gamma(1, 1) distribution (Exponential).\n    Uses the inverse transform method.\n    \"\"\"\n    u = rng.uniform(size=n)\n    # Avoid u=0 for log\n    u[u == 0] = 1e-100\n    return -np.log(u)\n\ndef _gamma_sampler_lt1(k: float, n: int, rng: np.random.Generator) - np.ndarray:\n    \"\"\"\n    Generates n samples from a standard Gamma(k, 1) distribution for 0  k  1.\n    Uses augmentation method: Y * U^(1/k) where Y ~ Gamma(k+1, 1).\n    \"\"\"\n    # Generate Y ~ Gamma(k+1, 1)\n    # Since k+1 is in (1, 2), we use the k1 sampler.\n    y_samples = _gamma_sampler_gt1(k + 1.0, n, rng)\n    \n    # Generate U ~ Uniform(0, 1)\n    u_samples = rng.uniform(size=n)\n    \n    return y_samples * (u_samples ** (1.0/k))\n\ndef gamma_sampler(k: float, theta: float, n: int, rng: np.random.Generator) - np.ndarray:\n    \"\"\"\n    Generates n samples from a Gamma(k, theta) distribution.\n    \"\"\"\n    if k = 0 or theta = 0 or not isinstance(n, int) or n  0:\n        raise ValueError(\"k and theta must be positive, n must be a non-negative integer.\")\n\n    if k  1.0:\n        std_samples = _gamma_sampler_gt1(k, n, rng)\n    elif k == 1.0:\n        std_samples = _gamma_sampler_eq1(n, rng)\n    else:  # 0  k  1\n        std_samples = _gamma_sampler_lt1(k, n, rng)\n        \n    return std_samples * theta\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    seed = 123456789\n    n = 200000\n    rng = np.random.default_rng(seed)\n    \n    results = []\n\n    # Test 1: Gamma, shape greater than one\n    k, theta = 3.5, 2.0\n    samples_1 = gamma_sampler(k, theta, n, rng)\n    m_star_1, v_star_1 = k * theta, k * theta**2\n    m_hat_1, v_hat_1 = np.mean(samples_1), np.var(samples_1, ddof=1)\n    results.append(np.abs(m_hat_1 - m_star_1)  0.03)\n    results.append(np.abs(v_hat_1 - v_star_1)  0.30)\n    \n    # Test 2: Gamma, shape less than one (augmentation)\n    k, theta = 0.7, 1.5\n    samples_2 = gamma_sampler(k, theta, n, rng)\n    m_star_2, v_star_2 = k * theta, k * theta**2\n    m_hat_2, v_hat_2 = np.mean(samples_2), np.var(samples_2, ddof=1)\n    results.append(np.abs(m_hat_2 - m_star_2)  0.03)\n    results.append(np.abs(v_hat_2 - v_star_2)  0.10)\n\n    # Test 3: Beta via ratio of independent gammas\n    a, b = 2.1, 3.3\n    x_samples_3 = gamma_sampler(a, 1.0, n, rng)\n    y_samples_3 = gamma_sampler(b, 1.0, n, rng)\n    u_samples_3 = x_samples_3 / (x_samples_3 + y_samples_3)\n    u_mean_star_3 = a / (a + b)\n    u_mean_hat_3 = np.mean(u_samples_3)\n    results.append(np.abs(u_mean_hat_3 - u_mean_star_3)  0.01)\n\n    # Test 4: Chi-squared as a gamma\n    nu = 10\n    k, theta = nu / 2.0, 2.0\n    samples_4 = gamma_sampler(k, theta, n, rng)\n    m_star_4, v_star_4 = nu, 2.0 * nu\n    m_hat_4, v_hat_4 = np.mean(samples_4), np.var(samples_4, ddof=1)\n    results.append(np.abs(m_hat_4 - m_star_4)  0.03)\n    results.append(np.abs(v_hat_4 - v_star_4)  0.20)\n\n    # Test 5: Boundary case k=1 (exponential)\n    k, theta = 1.0, 0.8\n    samples_5 = gamma_sampler(k, theta, n, rng)\n    m_star_5, v_star_5 = k * theta, k * theta**2\n    m_hat_5, v_hat_5 = np.mean(samples_5), np.var(samples_5, ddof=1)\n    results.append(np.abs(m_hat_5 - m_star_5)  0.02)\n    results.append(np.abs(v_hat_5 - v_star_5)  0.05)\n\n    print(f\"[{','.join(map(str, results))}]\".lower())\n\nsolve()\n```"
        },
        {
            "introduction": "构建一个采样器是一回事，而使其高效则是另一回事。在接受-拒绝采样法中，提议分布的选择直接决定了算法的效率。这个练习将引导你深入该方法的理论核心，通过分析一个指数倾斜的提议分布族，从理论上推导出能使接受概率最大化（即接受指示符方差最小化）的最优参数。这不仅是一次计算，更是对采样算法设计背后优化思想的深刻体验。",
            "id": "3309202",
            "problem": "考虑一个目标伽马分布，其形状参数为 $k \\in (0,1)$，速率参数为 $r0$，概率密度函数为\n$$\nf(x) \\;=\\; \\frac{r^{k}}{\\Gamma(k)} \\, x^{k-1} \\exp(-r x), \\quad x0.\n$$\n你的任务是设计一个接受-拒绝方案，使用一个指数倾斜的提议分布从 $f$ 生成随机变量，该提议分布保留了原点附近的幂律行为。具体来说，考虑提议分布族\n$$\nq_{t}(x) \\;=\\; \\frac{t^{k}}{\\Gamma(k)} \\, x^{k-1} \\exp(-t x), \\quad x0,\n$$\n其倾斜参数为 $t0$，因此 $q_{t}$ 是一个具有相同形状参数 $k$ 和速率参数 $t$ 的伽马分布。对于接受-拒绝法，你必须选择一个有限常数 $M(t)$，使得对所有 $x0$ 都有 $f(x) \\leq M(t)\\, q_{t}(x)$，并且你以概率 $f(X)/(M(t) q_{t}(X))$ 接受一个从 $q_{t}$ 中抽取的样本 $X \\sim q_{t}$。令 $I_{t}$ 表示接受指示符，它是一个伯努利随机变量，其成功概率为 $p(t) = 1/M(t)$。\n\n从接受-拒绝法和伽马分布族的基本定义出发，并且不使用任何快捷公式，执行以下操作：\n\n- 推导 $M(t)$ 作为 $t$ 的函数的显式表达式，并描述使 $M(t)$ 为有限值的 $t$ 的取值范围。\n\n- 用 $t$、$r$ 和 $k$ 表示 $p(t)$ 和 $\\operatorname{Var}(I_{t})$。\n\n- 通过分析对数似然比的上确界并利用矩匹配解释解，使用凸对偶性确定在所有允许的 $t$ 中最小化 $\\operatorname{Var}(I_{t})$ 的最优倾斜参数 $t^{\\ast}$。\n\n你的最终答案必须是用 $r$ 表示的最优倾斜参数 $t^{\\ast}$。不需要数值近似；请提供精确的符号表达式。如果找到多个候选值，请选择在您推导的允许性约束下实现 $\\operatorname{Var}(I_{t})$ 全局最小值的那个。最终答案应为单个封闭形式的表达式。",
            "solution": "用户希望我解决并验证一个关于伽马分布的接受-拒绝方案的问题。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n\n*   **目标分布：** 形状参数为 $k \\in (0,1)$、速率参数为 $r0$ 的伽马分布。\n*   **目标 PDF：** $f(x) = \\frac{r^{k}}{\\Gamma(k)} x^{k-1} \\exp(-r x)$，对于 $x0$。\n*   **提议分布族：** 形状参数为 $k$、速率参数为 $t0$ 的伽马分布。\n*   **提议 PDF：** $q_{t}(x) = \\frac{t^{k}}{\\Gamma(k)} x^{k-1} \\exp(-t x)$，对于 $x0$。\n*   **接受-拒绝条件：** $f(x) \\leq M(t) q_{t}(x)$，对于所有 $x0$。\n*   **接受指示符：** $I_t$，一个伯努利随机变量。\n*   **成功概率：** $p(t) = 1/M(t)$。\n\n**任务：**\n1.  推导 $M(t)$ 的表达式，并找到使其为有限值的 $t$ 的取值范围。\n2.  用 $t$、$r$ 和 $k$ 表示 $p(t)$ 和 $\\operatorname{Var}(I_t)$。\n3.  通过使用凸对偶性和矩匹配解释，确定最小化 $\\operatorname{Var}(I_t)$ 的最优倾斜参数 $t^{\\ast}$。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n该问题具有科学依据，表述清晰且客观。这是一个计算统计学和蒙特卡洛方法中的标准问题，具体涉及为接受-拒绝抽样优化提议分布。\n\n1.  **科学或事实上的不健全性：** 无。该问题基于已确立的概率论（伽马分布、伯努利试验）和模拟（接受-拒绝法）原理。\n2.  **非形式化或不相关：** 无。该问题以精确的数学术语陈述，并与指定主题直接相关。\n3.  **不完整或矛盾的设置：** 无。所有必要的参数和定义（$k, r, t, f(x), q_t(x)$）都已提供。\n4.  **不切实际或不可行：** 无。该问题是纯数学问题。\n5.  **不适定或结构不良：** 无。目标函数 $\\operatorname{Var}(I_t)$ 定义明确，优化是在指定的参数 $t$ 上进行的。结构逻辑清晰。\n6.  **伪深刻、琐碎或同义反复：** 无。尽管最终答案可能看起来很简单，但所要求的涉及凸对偶性和矩匹配的论证，需要对抽样算法的基本理论有深刻的理解。该问题并非琐碎。\n7.  **超出科学可验证性：** 无。该推导可以通过严格的数学证明进行验证。\n\n**步骤 3：结论与行动**\n\n该问题有效。将提供完整解答。\n\n### 解答\n\n接受-拒绝算法需要一个常数 $M(t)$，使得对所有 $x  0$ 都有 $f(x) \\leq M(t) q_t(x)$。$M(t)$ 的最有效选择是满足条件的最小常数，由密度函数的比值的上确界给出。\n$$\nM(t) = \\sup_{x0} \\frac{f(x)}{q_t(x)}\n$$\n我们来计算这个比值：\n$$\n\\frac{f(x)}{q_t(x)} = \\frac{\\frac{r^{k}}{\\Gamma(k)} x^{k-1} \\exp(-r x)}{\\frac{t^{k}}{\\Gamma(k)} x^{k-1} \\exp(-t x)} = \\left(\\frac{r}{t}\\right)^{k} \\exp(-r x + t x) = \\left(\\frac{r}{t}\\right)^{k} \\exp((t-r)x)\n$$\n为了找到该表达式在 $x0$ 上的上确界，我们分析指数项 $\\exp((t-r)x)$ 的行为，它取决于系数 $t-r$ 的符号。\n\n1.  如果 $t  r$，则 $t-r  0$。函数 $\\exp((t-r)x)$ 对 $x$ 是严格递增的。当 $x \\to \\infty$ 时，该函数无界增长。因此，$M(t) = \\infty$。\n2.  如果 $t = r$，则 $t-r = 0$。对所有 $x0$，该比值恒为 $(r/r)^k \\exp(0) = 1$。因此，$M(r) = 1$。\n3.  如果 $0  t  r$，则 $t-r  0$。函数 $\\exp((t-r)x)$ 对 $x$ 是严格递减的。上确界在 $x \\to 0^{+}$ 时达到。\n    $$\n    \\sup_{x0} \\left(\\frac{r}{t}\\right)^{k} \\exp((t-r)x) = \\lim_{x \\to 0^{+}} \\left(\\frac{r}{t}\\right)^{k} \\exp((t-r)x) = \\left(\\frac{r}{t}\\right)^{k}\n    $$\n\n综合这些情况，我们发现只有当 $t \\in (0, r]$ 时，才存在有限常数 $M(t)$。对于这个允许的 $t$ 的范围，最优常数由下式给出：\n$$\nM(t) = \\left(\\frac{r}{t}\\right)^{k}, \\quad t \\in (0, r]\n$$\n\n接受指示符 $I_t$ 是一个伯努利随机变量。接受一个提议值 $X \\sim q_t(x)$ 的概率是 $f(X)/(M(t)q_t(X))$。总接受概率 $p(t)$ 是该数量的期望值。\n$$\np(t) = \\mathbb{E}_{X \\sim q_t}\\left[ \\frac{f(X)}{M(t) q_t(X)} \\right] = \\frac{1}{M(t)} \\int_0^{\\infty} \\frac{f(x)}{q_t(x)} q_t(x) \\,dx = \\frac{1}{M(t)} \\int_0^{\\infty} f(x) \\,dx = \\frac{1}{M(t)}\n$$\n因为 $f(x)$ 是一个概率密度函数。对于 $t \\in (0, r]$，这得到：\n$$\np(t) = \\frac{1}{(r/t)^k} = \\left(\\frac{t}{r}\\right)^{k}\n$$\n伯努利指示符 $I_t$ 的方差是 $\\operatorname{Var}(I_t) = p(t)(1-p(t))$。\n$$\n\\operatorname{Var}(I_t) = \\left(\\frac{t}{r}\\right)^{k} \\left(1 - \\left(\\frac{t}{r}\\right)^{k}\\right)\n$$\n我们的目标是在允许的范围 $(0, r]$ 内找到使该方差最小化的 $t$ 值。令 $P = p(t) = (t/r)^k$。当 $t$ 在 $(0, r]$ 内变化时，$P$ 在 $(0, 1]$ 内变化。我们希望最小化函数 $g(P) = P(1-P)$ 在 $P \\in (0, 1]$ 上的值。这个函数是一个开口向下的抛物线，其最大值在 $P=1/2$ 处，最小值在其定义域的边界 $P=0$ 和 $P=1$ 处。在区间 $(0, 1]$ 上，$g(P)$ 的最小值是 $0$，在 $P=1$ 时达到。\n令 $p(t)=1$，我们得到：\n$$\n\\left(\\frac{t}{r}\\right)^{k} = 1 \\implies \\frac{t}{r} = 1 \\implies t = r\n$$\n由于 $t=r$ 在允许集 $(0, r]$ 中，因此它是最优值。在 $t=r$ 时，方差为 $\\operatorname{Var}(I_r) = 1(1-1) = 0$。\n\n我们现在使用问题陈述中要求的概念来为这个结果提供论证。最小化 $\\operatorname{Var}(I_t)$ 等价于使 $p(t)$ 尽可能接近 $0$ 或 $1$。为了抽样效率，我们寻求最大化接受概率 $p(t)$，这对应于 $p(t)=1$ 的情况。最大化 $p(t)$ 等价于最小化其倒数 $M(t)$。因此，问题等价于求解：\n$$\n\\min_{t \\in (0, r]} M(t) \\quad \\text{也就是} \\quad \\min_{t \\in (0, r]} \\sup_{x0} \\frac{f(x)}{q_t(x)}\n$$\n这是一个极小化极大问题 (minimax problem)。通过取对数（这是一个单调函数），我们可以等价地求解：\n$$\n\\min_{t \\in (0, r]} \\sup_{x0} \\log\\left(\\frac{f(x)}{q_t(x)}\\right)\n$$\n令 $L(x,t) = \\log(f(x)/q_t(x)) = k\\log(r/t) + (t-r)x$。函数 $L(x,t)$ 对 $t$ 是凸的，对 $x$ 是线性的（因此是凹的）。由于 $t$ 和 $x$ 的定义域都是凸集，我们可以应用极小化极大定理并交换最小化和最大化的顺序（这是凸对偶性的一个应用）。\n$$\n\\min_{t \\in (0, r]} \\sup_{x0} L(x,t) = \\sup_{x0} \\min_{t \\in (0, r]} L(x,t)\n$$\n我们来分析内部的最小化问题：对于固定的 $x0$，求解 $\\min_{t \\in (0, r]} L(x,t)$。我们对 $L(x,t)$ 关于 $t$ 求导：\n$$\n\\frac{\\partial L}{\\partial t} = -\\frac{k}{t} + x\n$$\n令导数为零得到 $t = k/x$。这个临界点对应一个最小值，因为二阶导数 $\\frac{\\partial^2 L}{\\partial t^2} = k/t^2  0$。\n条件 $t=k/x$ 提供了矩匹配的解释。提议分布 $q_t(x)$（即 Gamma($k,t$) 分布）的均值是 $\\mathbb{E}_{q_t}[X] = k/t$。条件 $t = k/x$ 等价于 $\\mathbb{E}_{q_t}[X] = x$。这意味着对于一个给定的点 $x$，局部最优的提议是其期望值为 $x$ 的那个。\n\n解 $t=k/x$ 仅当其位于允许范围 $(0,r]$ 内时才有效。\n- 如果 $k/x \\in (0,r]$，即 $x \\ge k/r$，最小值在 $t=k/x$ 处达到。\n- 如果 $k/x  r$，即 $x  k/r$，导数 $\\partial L / \\partial t = x - k/t$ 对 $t \\in (0,r]$ 始终为负，因为 $t \\le r  k/x$。因此，$L(x,t)$ 对 $t$ 是递减的，最小值在边界 $t=r$ 处。\n\n现在，将此结果代入外部问题，得到极大化极小值 (maximin value)。然而，原始问题 $\\min_{t \\in (0, r]} \\sup_{x0} L(x,t)$ 的直接解法更为直接。如前所示，对于 $t \\in (0,r]$，$\\sup_{x0} L(x,t) = k\\log(r/t)$。函数 $k\\log(r/t)$ 是一个关于 $t$ 的递减函数。它在 $(0,r]$ 上的最小值在 $t$ 的最大可能值处达到，即 $t=r$。\n因此，最优倾斜参数为 $t^*=r$。\n\n矩匹配的解释提供了最终的洞见。全局最优的提议是通过将提议分布的均值与目标分布的均值相匹配来找到的。\n目标分布 $f(x) \\sim \\text{Gamma}(k,r)$ 的均值是 $\\mathbb{E}_f[X] = k/r$。\n提议分布 $q_t(x) \\sim \\text{Gamma}(k,t)$ 的均值是 $\\mathbb{E}_{q_t}[X] = k/t$。\n令两个均值相等以找到最优的 $t$：\n$$\n\\mathbb{E}_{q_t}[X] = \\mathbb{E}_{f}[X] \\implies \\frac{k}{t} = \\frac{k}{r} \\implies t = r\n$$\n这证实了在所要求的框架下，$t^*=r$ 是最优选择。在 $t=r$ 时，提议分布和目标分布是相同的 ($q_r = f$)，导致 $M(r)=1$，$p(r)=1$，以及 $\\operatorname{Var}(I_r)=0$，这是可能的最有效的结果。",
            "answer": "$$\\boxed{r}$$"
        },
        {
            "introduction": "伽马变量生成器通常不是最终目的，而是解决更复杂问题的关键工具。本练习将展示这一思想，将指数倾斜的概念应用于重要性采样，以高效地估计伽马分布的罕见事件概率（即尾部概率）。通过解决这个问题，你将学会如何设计和分析一个方差缩减技术，并理解为何精确的随机变量生成是高级计算统计方法中的重要组成部分。",
            "id": "3309211",
            "problem": "考虑一个随机变量 $X$，它服从形状参数为 $k0$、尺度参数为 $\\theta0$ 的伽马分布，记为 $X\\sim\\Gamma(k,\\theta)$。令 $\\beta\\equiv 1/\\theta$ 表示其率参数。目标是对于一个固定的阈值 $t0$，通过重要性采样来估计右尾概率 $p(t)\\equiv \\mathbb{P}(Xt)$。你需要设计并分析一个基于目标密度指数倾斜的重要性采样器。具体来说，考虑由下式定义的提议分布族 $\\{g_{\\lambda}:\\lambda\\in[0,\\beta)\\}$：\n$$\ng_{\\lambda}(x)\\propto \\exp(\\lambda x) f(x),\n$$\n其中 $f(x)$ 是 $X$ 的概率密度函数，比例常数用于将 $g_{\\lambda}$ 归一化为一个密度函数。使用这个提议分布，$p(t)$ 的标准重要性采样估计量为\n$$\n\\widehat{p}_{n}(t;\\lambda)\\equiv \\frac{1}{n}\\sum_{i=1}^{n} w_{\\lambda}(X_{i})\\,\\mathbf{1}\\{X_{i}t\\},\\quad X_{i}\\stackrel{\\text{i.i.d.}}{\\sim} g_{\\lambda},\n$$\n其中重要性权重为 $w_{\\lambda}(x)\\equiv f(x)/g_{\\lambda}(x)$。\n\n任务：\n1. 从重要性采样的第一性原理出发，推导 $g_{\\lambda}(x)$ 的确切形式（包括其归一化常数）和确切的权重函数 $w_{\\lambda}(x)$。然后，仅用 $k$、$\\beta$、$t$ 和 $\\lambda$ 推导单位样本二阶矩 $\\mathbb{E}_{g_{\\lambda}}[w_{\\lambda}(X)^{2}\\,\\mathbf{1}\\{Xt\\}]$ 的解析表达式，并用它来获得一个目标函数，该函数在 $\\lambda\\in[0,\\beta)$ 上的最小值点即为指数倾斜的方差最小化选择。\n2. 计算方差最小化 $\\lambda$ 的一阶最优性条件，用标准特殊函数表示它，并在稀有事件区域 $t\\to\\infty$ 中使用渐近分析，以获得最优倾斜参数 $\\lambda^{\\star}$ 的主阶渐近展开式。\n3. 将加权估计量的有效样本量 (ESS) 定义为 $\\mathrm{ESS} \\equiv n\\cdot \\left(\\mathbb{E}_{g_{\\lambda}}[w_{\\lambda}(X)\\,\\mathbf{1}\\{Xt\\}]\\right)^{2}\\big/\\mathbb{E}_{g_{\\lambda}}[w_{\\lambda}(X)^{2}\\,\\mathbf{1}\\{Xt\\}]$，并推导 ESS 分数 $\\mathrm{ESS}/n$ 关于 $k$、$\\beta$、$t$ 和 $\\lambda$ 的闭式表达式。然后，在任务2中获得的渐近最优 $\\lambda^{\\star}$ 处评估此表达式，并针对大的 $t$ 将其简化为其主阶渐近阶。\n\n你的最终答案必须包含两项：\n- 当 $t\\to\\infty$ 时 $\\lambda^{\\star}$ 的主阶渐近表达式。\n- 当 $t\\to\\infty$ 时，在 $\\lambda^{\\star}$ 处的 $\\mathrm{ESS}/n$ 的主阶渐近表达式。\n\n将最终答案表示为具有两个条目的行矩阵形式的单个闭式解析表达式。不需要进行数值舍入。",
            "solution": "问题要求分析用于伽马分布随机变量右尾概率的重要性采样估计量。该策略涉及指数倾斜。我们将按要求分三个连续的任务来解决这个问题。\n\n目标随机变量 $X$ 服从形状参数为 $k0$、尺度参数为 $\\theta0$ 的伽马分布，记为 $X\\sim\\Gamma(k,\\theta)$。率参数为 $\\beta = 1/\\theta$。$X$ 的概率密度函数 (PDF) 由下式给出\n$$\nf(x) = \\frac{\\beta^k}{\\Gamma(k)} x^{k-1} \\exp(-\\beta x), \\quad \\text{for } x0.\n$$\n我们想要估计 $p(t) = \\mathbb{P}(Xt) = \\int_t^\\infty f(x) dx$。\n\n### 任务1：推导提议密度、权重和二阶矩目标函数\n\n提议密度 $g_{\\lambda}(x)$ 由指数倾斜关系 $g_{\\lambda}(x) \\propto \\exp(\\lambda x) f(x)$ 定义，其中 $\\lambda \\in [0, \\beta)$。让我们来求归一化的密度函数。\n$$\ng_{\\lambda}(x) = C_{\\lambda} \\exp(\\lambda x) f(x) = C_{\\lambda} \\exp(\\lambda x) \\frac{\\beta^k}{\\Gamma(k)} x^{k-1} \\exp(-\\beta x) = C_{\\lambda} \\frac{\\beta^k}{\\Gamma(k)} x^{k-1} \\exp(-(\\beta-\\lambda)x).\n$$\n归一化常数 $C_{\\lambda}$ 是未归一化密度在其支撑集 $(0, \\infty)$ 上积分的倒数：\n$$\n\\frac{1}{C_{\\lambda}} = \\int_0^\\infty \\exp(\\lambda x) f(x) dx = \\mathbb{E}[\\exp(\\lambda X)].\n$$\n这是 $X$ 的矩生成函数 (MGF)，记为 $M_X(\\lambda)$。对于 $\\Gamma(k, \\beta)$ 分布，其 MGF 为\n$$\nM_X(\\lambda) = \\int_0^\\infty \\frac{\\beta^k}{\\Gamma(k)} x^{k-1} \\exp(-(\\beta-\\lambda)x) dx = \\frac{\\beta^k}{\\Gamma(k)} \\frac{\\Gamma(k)}{(\\beta-\\lambda)^k} = \\left(\\frac{\\beta}{\\beta-\\lambda}\\right)^k.\n$$\n当 $\\lambda  \\beta$ 时，该值为有限，这证明了给定的 $\\lambda$ 的定义域是合理的。\n归一化常数为 $C_{\\lambda} = 1/M_X(\\lambda) = (\\frac{\\beta-\\lambda}{\\beta})^k$。\n将 $C_{\\lambda}$ 代回，提议密度为\n$$\ng_{\\lambda}(x) = \\left(\\frac{\\beta-\\lambda}{\\beta}\\right)^k \\exp(\\lambda x) \\left(\\frac{\\beta^k}{\\Gamma(k)} x^{k-1} \\exp(-\\beta x)\\right) = \\frac{(\\beta-\\lambda)^k}{\\Gamma(k)} x^{k-1} \\exp(-(\\beta-\\lambda)x).\n$$\n这是一个形状参数为 $k$、率参数为 $\\beta' = \\beta-\\lambda$ 的伽马分布的 PDF，即 $X_i \\sim \\Gamma(k, (\\beta-\\lambda)^{-1})$。\n\n重要性权重函数 $w_{\\lambda}(x)$ 定义为 $w_{\\lambda}(x) = f(x)/g_{\\lambda}(x)$。使用关系式 $g_{\\lambda}(x) = \\exp(\\lambda x) f(x)/M_X(\\lambda)$，我们得到\n$$\nw_{\\lambda}(x) = M_X(\\lambda) \\exp(-\\lambda x) = \\left(\\frac{\\beta}{\\beta-\\lambda}\\right)^k \\exp(-\\lambda x).\n$$\n目标是找到使估计量 $\\widehat{p}_{n}(t;\\lambda)$ 方差最小的 $\\lambda$。方差由 $\\frac{1}{n}\\mathrm{Var}_{g_{\\lambda}}(w_{\\lambda}(X)\\mathbf{1}\\{Xt\\})$ 给出。估计量的均值为\n$$\n\\mathbb{E}_{g_{\\lambda}}[w_{\\lambda}(X)\\mathbf{1}\\{Xt\\}] = \\int_t^\\infty w_{\\lambda}(x) g_{\\lambda}(x) dx = \\int_t^\\infty f(x) dx = p(t).\n$$\n由于均值与 $\\lambda$ 无关，最小化方差等价于最小化二阶矩，我们将其记为 $V(\\lambda)$：\n$$\nV(\\lambda) \\equiv \\mathbb{E}_{g_{\\lambda}}[w_{\\lambda}(X)^2 \\mathbf{1}\\{Xt\\}] = \\int_t^\\infty w_{\\lambda}(x)^2 g_{\\lambda}(x) dx.\n$$\n让我们来计算这个积分：\n$$\nw_{\\lambda}(x)^2 g_{\\lambda}(x) = \\left(M_X(\\lambda) \\exp(-\\lambda x)\\right)^2 g_{\\lambda}(x) = M_X(\\lambda)^2 \\exp(-2\\lambda x) \\frac{(\\beta-\\lambda)^k}{\\Gamma(k)} x^{k-1} \\exp(-(\\beta-\\lambda)x).\n$$\n将其从 $t$ 积分到 $\\infty$：\n$$\nV(\\lambda) = M_X(\\lambda)^2 \\frac{(\\beta-\\lambda)^k}{\\Gamma(k)} \\int_t^\\infty x^{k-1} \\exp(-(2\\lambda + \\beta - \\lambda)x) dx = M_X(\\lambda)^2 \\frac{(\\beta-\\lambda)^k}{\\Gamma(k)} \\int_t^\\infty x^{k-1} \\exp(-(\\beta+\\lambda)x) dx.\n$$\n该积分与上不完全伽马函数 $\\Gamma(s,z) = \\int_z^\\infty u^{s-1}\\exp(-u)du$ 相关。通过变量代换 $u=(\\beta+\\lambda)x$，积分变为 $\\frac{\\Gamma(k, (\\beta+\\lambda)t)}{(\\beta+\\lambda)^k}$。\n代入这个结果以及 $M_X(\\lambda)$ 的表达式：\n$$\nV(\\lambda) = \\left(\\frac{\\beta}{\\beta-\\lambda}\\right)^{2k} \\frac{(\\beta-\\lambda)^k}{\\Gamma(k)} \\frac{\\Gamma(k, (\\beta+\\lambda)t)}{(\\beta+\\lambda)^k} = \\frac{\\beta^{2k}}{(\\beta-\\lambda)^k (\\beta+\\lambda)^k \\Gamma(k)} \\Gamma(k, (\\beta+\\lambda)t).\n$$\n这可以写作\n$$\nV(\\lambda) = \\frac{\\beta^{2k}}{(\\beta^2-\\lambda^2)^k \\Gamma(k)} \\Gamma(k, (\\beta+\\lambda)t).\n$$\n这就是目标函数，其最小值点给出了方差最小化的 $\\lambda$ 选择。\n\n### 任务2：最优性条件和渐近分析\n\n为了找到最优的 $\\lambda$，我们将 $V(\\lambda)$ 对 $\\lambda$ 的导数设为零。对 $\\ln V(\\lambda)$ 求导更简单一些：\n$$\n\\ln V(\\lambda) = 2k\\ln\\beta - k\\ln(\\beta^2-\\lambda^2) + \\ln\\Gamma(k, (\\beta+\\lambda)t) - \\ln\\Gamma(k).\n$$\n$$\n\\frac{d}{d\\lambda}\\ln V(\\lambda) = -k \\frac{-2\\lambda}{\\beta^2-\\lambda^2} + \\frac{1}{\\Gamma(k, (\\beta+\\lambda)t)} \\frac{d}{d\\lambda}\\Gamma(k, (\\beta+\\lambda)t) = 0.\n$$\n使用莱布尼茨积分法则，$\\frac{d}{dz}\\Gamma(s,z) = -z^{s-1}\\exp(-z)$。设 $z(\\lambda) = (\\beta+\\lambda)t$，根据链式法则可得\n$$\n\\frac{d}{d\\lambda}\\Gamma(k, (\\beta+\\lambda)t) = - ((\\beta+\\lambda)t)^{k-1} \\exp(-(\\beta+\\lambda)t) \\cdot t = -t^k (\\beta+\\lambda)^{k-1} \\exp(-(\\beta+\\lambda)t).\n$$\n将此代入 $\\ln V(\\lambda)$ 的导数中：\n$$\n\\frac{2k\\lambda}{\\beta^2-\\lambda^2} - \\frac{t^k (\\beta+\\lambda)^{k-1} \\exp(-(\\beta+\\lambda)t)}{\\Gamma(k, (\\beta+\\lambda)t)} = 0.\n$$\n这就是方差最小化 $\\lambda$ 的一阶最优性条件。\n\n对于 $t\\to\\infty$ 的渐近分析，我们使用不完全伽马函数的主阶渐近展开式：对于大的 $z$，有 $\\Gamma(s,z) \\sim z^{s-1}\\exp(-z)$。令 $z = (\\beta+\\lambda)t$。当 $t\\to\\infty$ 时，$z\\to\\infty$。最优性条件中的第二项变为\n$$\n\\frac{t^k (\\beta+\\lambda)^{k-1} \\exp(-(\\beta+\\lambda)t)}{\\Gamma(k, (\\beta+\\lambda)t)} \\sim \\frac{t^k (\\beta+\\lambda)^{k-1} \\exp(-(\\beta+\\lambda)t)}{((\\beta+\\lambda)t)^{k-1} \\exp(-(\\beta+\\lambda)t)} = \\frac{t^k (\\beta+\\lambda)^{k-1}}{t^{k-1}(\\beta+\\lambda)^{k-1}} = t.\n$$\n因此，渐近最优性条件是\n$$\n\\frac{2k\\lambda}{\\beta^2-\\lambda^2} \\approx t.\n$$\n这可以简化为一个关于 $\\lambda$ 的二次方程：$t\\lambda^2 + 2k\\lambda - t\\beta^2 = 0$。解是\n$$\n\\lambda = \\frac{-2k \\pm \\sqrt{4k^2 - 4(t)(-t\\beta^2)}}{2t} = \\frac{-k \\pm \\sqrt{k^2+t^2\\beta^2}}{t}.\n$$\n由于 $\\lambda$ 必须在 $[0, \\beta)$ 区间内，我们必须取正根。对于大的 $t$，$\\lambda$ 必须是正的。\n$$\n\\lambda^{\\star} \\approx \\frac{-k + \\sqrt{t^2\\beta^2(1+k^2/(t^2\\beta^2))}}{t} = \\frac{-k + t\\beta\\sqrt{1+k^2/(t^2\\beta^2)}}{t}.\n$$\n对于小的 $x$，使用泰勒展开式 $\\sqrt{1+x} \\approx 1 + x/2$：\n$$\n\\lambda^{\\star} \\approx \\frac{-k + t\\beta(1 + \\frac{k^2}{2t^2\\beta^2})}{t} = \\frac{-k + t\\beta + \\frac{k^2}{2t\\beta}}{t} = \\beta - \\frac{k}{t} + O(t^{-2}).\n$$\n最优倾斜参数的主阶渐近表达式为 $\\lambda^{\\star} \\approx \\beta - \\frac{k}{t}$。\n\n### 任务3：有效样本量 (ESS) 分析\n\nESS 分数定义为\n$$\n\\frac{\\mathrm{ESS}}{n} = \\frac{\\left(\\mathbb{E}_{g_{\\lambda}}[w_{\\lambda}(X)\\,\\mathbf{1}\\{Xt\\}]\\right)^{2}}{\\mathbb{E}_{g_{\\lambda}}[w_{\\lambda}(X)^{2}\\,\\mathbf{1}\\{Xt\\}]} = \\frac{p(t)^2}{V(\\lambda)}.\n$$\n我们有 $p(t) = \\mathbb{P}(Xt) = \\frac{\\Gamma(k, \\beta t)}{\\Gamma(k)}$。代入 $p(t)$ 和 $V(\\lambda)$ 的表达式：\n$$\n\\frac{\\mathrm{ESS}}{n} = \\frac{(\\Gamma(k, \\beta t)/\\Gamma(k))^2}{ \\frac{\\beta^{2k}}{(\\beta^2-\\lambda^2)^k \\Gamma(k)} \\Gamma(k, (\\beta+\\lambda)t) } = \\frac{\\Gamma(k, \\beta t)^2 (\\beta^2-\\lambda^2)^k}{\\Gamma(k) \\beta^{2k} \\Gamma(k, (\\beta+\\lambda)t)}.\n$$\n我们在渐近最优的 $\\lambda^{\\star} \\approx \\beta - k/t$ 处评估此表达式。\n对于大的 $t$：\n- $\\beta^2 - (\\lambda^{\\star})^2 \\approx \\beta^2 - (\\beta-k/t)^2 = 2k\\beta/t - k^2/t^2 \\sim \\frac{2k\\beta}{t}$。\n- $\\beta + \\lambda^{\\star} \\approx \\beta + (\\beta - k/t) = 2\\beta - k/t$。\n第二个不完全伽马函数的自变量是 $(\\beta+\\lambda^\\star)t \\approx 2\\beta t - k$。\n\n我们将这些代入 ESS/n 表达式中，使用渐近形式 $\\Gamma(s,z) \\sim z^{s-1}\\exp(-z)$：\n- $\\Gamma(k, \\beta t)^2 \\sim ((\\beta t)^{k-1}\\exp(-\\beta t))^2 = (\\beta t)^{2k-2}\\exp(-2\\beta t)$。\n- $\\Gamma(k, 2\\beta t-k) \\sim (2\\beta t-k)^{k-1}\\exp(-(2\\beta t-k)) \\sim (2\\beta t)^{k-1}\\exp(-2\\beta t)\\exp(k)$。\nESS 分数的表达式变为：\n$$\n\\frac{\\mathrm{ESS}}{n}(\\lambda^\\star) \\approx \\frac{[(\\beta t)^{k-1}\\exp(-\\beta t)]^2 (\\frac{2k\\beta}{t})^k}{\\Gamma(k) \\beta^{2k} [(2\\beta t)^{k-1}\\exp(-2\\beta t)\\exp(k)]}.\n$$\n通过消去 $\\exp(-2\\beta t)$ 来简化表达式：\n$$\n\\frac{\\mathrm{ESS}}{n} \\approx \\frac{(\\beta t)^{2k-2} (2k\\beta)^k t^{-k}}{\\Gamma(k) \\beta^{2k} (2\\beta t)^{k-1} \\exp(k)} = \\frac{\\beta^{2k-2} t^{2k-2} \\cdot 2^k k^k \\beta^k t^{-k}}{\\Gamma(k) \\beta^{2k} \\cdot 2^{k-1} \\beta^{k-1} t^{k-1} \\exp(k)}.\n$$\n现在，我们收集每一项的幂：\n- 2 的幂：$k - (k-1) = 1$。\n- $k$ 的幂：$k$。\n- $\\beta$ 的幂：$(2k-2)+k - (2k) - (k-1) = 3k-2-3k+1 = -1$。\n- $t$ 的幂：$(2k-2)-k - (k-1) = k-2-k+1 = -1$。\n- 剩余项：$1/\\Gamma(k)$ 和 $1/\\exp(k)$。\n\n将这些组合起来，得到 ESS 分数的主阶渐近表达式：\n$$\n\\frac{\\mathrm{ESS}}{n} \\approx \\frac{2 k^k}{\\Gamma(k) \\exp(k) \\beta t}.\n$$\n\n最终答案是 $\\lambda^{\\star}$ 和 $\\mathrm{ESS}/n$ 的渐近表达式。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\beta - \\frac{k}{t}  \\frac{2 k^k \\exp(-k)}{\\Gamma(k) \\beta t} \\end{pmatrix}}\n$$"
        }
    ]
}