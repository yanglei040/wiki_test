{
    "hands_on_practices": [
        {
            "introduction": "生成自定义随机变量的基石是逆变换采样法。这个练习将引导你为指数分布实现该方法。然而，实现算法只是成功的一半，验证同样至关重要。你不仅需要生成样本，还需运用柯尔莫哥洛夫-斯米尔诺夫 (Kolmogorov-Smirnov) 拟合优度检验，从统计上证明你的代码确实生成了符合目标指数分布的数据。这项实践旨在巩固概率论、算法实现与统计验证之间的核心联系。 ",
            "id": "2403697",
            "problem": "要求您使用第一性原理来形式化、实现和验证指数分布的抽样。考虑率参数为 $\\lambda \\in (0,\\infty)$ 且累积分布函数为 $F(x) = \\mathbb{P}(X \\le x)$ 的指数分布。\n\n任务：\n1. 使用逆变换原理，从单位区间上均匀分布的变量 $U$ 的独立抽样中，生成 $n$ 个来自率参数为 $\\lambda$ 的指数分布的独立样本。您必须利用以下性质：如果 $U$ 在单位区间上均匀分布，则 $F^{-1}(U)$ 的累积分布函数为 $F$。\n2. 对于每个参数三元组 $(\\lambda,n,\\alpha)$，其中 $\\lambda \\in (0,\\infty)$，$n \\in \\mathbb{N}$，且 $\\alpha \\in (0,1)$ 为显著性水平，基于您生成的 $n$ 个样本，对率参数为 $\\lambda$ 的指数分布进行单样本分布拟合优度检验。报告 $p$ 值以及一个布尔决策：如果在显著性水平 $\\alpha$ 下不拒绝数据服从率参数为 $\\lambda$ 的指数分布的原假设，则为 $\\text{True}$，否则为 $\\text{False}$。$p$ 值必须报告为实数。\n3. 为保证可复现性，请在开始时使用固定的整数种子 $s=123456789$ 对您的伪随机数生成器进行一次初始化。\n\n测试套件：\n- 情况 1：$(\\lambda,n,\\alpha) = (0.7,1000,0.05)$\n- 情况 2：$(\\lambda,n,\\alpha) = (2.3,200,0.01)$\n- 情况 3：$(\\lambda,n,\\alpha) = (0.1,500,0.10)$\n- 情况 4：$(\\lambda,n,\\alpha) = (10.0,100,0.05)$\n- 情况 5：$(\\lambda,n,\\alpha) = (0.5,5,0.20)$\n\n您的程序必须：\n- 实现项目 $1$ 中描述的采样器，为每种情况生成 $n$ 个样本。\n- 实现项目 $2$ 中描述的检验，并计算每种情况的 $p$ 值。\n- 对于每种情况 $i \\in \\{1,2,3,4,5\\}$，按顺序输出两个值：四舍五入到六位小数的 $p$ 值和如上指定的布尔决策。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含所有结果，形式为一个用方括号括起来的逗号分隔列表。该列表的长度必须为 $10$，并按 $[p_1,d_1,p_2,d_2,p_3,d_3,p_4,d_4,p_5,d_5]$ 的顺序排列，其中 $p_i$ 是情况 $i$ 的 $p$ 值（四舍五入到六位小数），$d_i$ 是对应的布尔决策。",
            "solution": "该问题要求使用逆变换法从指数分布中生成随机样本，然后使用拟合优度检验对这些样本进行统计验证。解决方案分两部分展开：首先，推导抽样算法；其次，指定统计检验方法。\n\n**1. 指数分布的逆变换抽样**\n\n指数分布由一个率参数 $\\lambda  0$ 表征。其随机变量 $X$ 的概率密度函数 (PDF) 由下式给出：\n$$\nf(x; \\lambda) = \\begin{cases} \\lambda e^{-\\lambda x}  \\text{if } x \\ge 0 \\\\ 0  \\text{if } x  0 \\end{cases}\n$$\n累积分布函数 (CDF) $F(x)$ 表示随机变量 $X$ 取值小于或等于 $x$ 的概率。它通过对 PDF 从 $0$ 到 $x$ 积分得到：\n$$\nF(x) = \\mathbb{P}(X \\le x) = \\int_0^x \\lambda e^{-\\lambda t} dt = \\left[ -e^{-\\lambda t} \\right]_0^x = 1 - e^{-\\lambda x} \\quad \\text{for } x \\ge 0\n$$\n逆变换抽样方法基于以下原理：如果 $U$ 是从区间 $(0, 1)$ 上的标准均匀分布中抽取的随机变量，则随机变量 $X = F^{-1}(U)$ 将服从由 CDF $F$ 表征的分布。\n\n要应用此方法，我们必须首先求出 CDF 的逆函数，记为 $F^{-1}(u)$。我们设 $u = F(x)$ 并求解 $x$：\n$$\nu = 1 - e^{-\\lambda x}\n$$\n整理各项以分离出 $x$：\n$$\ne^{-\\lambda x} = 1 - u\n$$\n对两边取自然对数：\n$$\n-\\lambda x = \\ln(1 - u)\n$$\n最后，求解 $x$ 得到逆 CDF：\n$$\nx = F^{-1}(u) = -\\frac{1}{\\lambda} \\ln(1 - u)\n$$\n因此，要从率参数为 $\\lambda$ 的指数分布中生成一个样本 $x$，可以从 $\\text{Uniform}(0,1)$ 中生成一个随机数 $u$，并应用变换 $x = -\\frac{1}{\\lambda} \\ln(1 - u)$。\n\n一个有用的简化源于以下性质：如果 $U \\sim \\text{Uniform}(0,1)$，则随机变量 $V = 1 - U$ 也服从 $\\text{Uniform}(0,1)$ 分布。这允许我们在公式中用 $u$ 替换 $1 - u$，从而得到计算上等价且更直接的表达式：\n$$\nx = -\\frac{1}{\\lambda} \\ln(u)\n$$\n此公式将用于为每个测试用例生成 $n$ 个样本。该过程首先使用指定的种子 $s=123456789$ 初始化一个伪随机数生成器，以确保可复现性。然后，对于每个测试用例 $(\\lambda, n, \\alpha)$，我们从 $\\text{Uniform}(0,1)$ 中抽取 $n$ 个独立的值 $u_1, u_2, \\dots, u_n$，并计算相应的指数样本 $x_i = -\\frac{1}{\\lambda} \\ln(u_i)$。\n\n**2. 拟合优度检验**\n\n生成样本数据 $\\{x_1, \\dots, x_n\\}$ 后，必须执行单样本分布拟合优度检验。原假设 $H_0$ 为数据来自具有指定率参数 $\\lambda$ 的指数分布。备择假设 $H_1$ 为数据不来自该分布。\n\n适用于此场景的标准且恰当的检验是单样本 Kolmogorov-Smirnov (K-S) 检验。该检验将样本数据的经验累积分布函数 (ECDF) $F_n(x)$ 与假设分布的理论 CDF $F(x) = 1 - e^{-\\lambda x}$ 进行比较。ECDF 定义为：\n$$\nF_n(x) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{I}(x_i \\le x)\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。K-S 检验统计量 $D_n$ 是 ECDF 和理论 CDF 在所有可能的 $x$ 值上的最大绝对差：\n$$\nD_n = \\sup_x | F_n(x) - F(x) |\n$$\n在原假设下，$D_n$ 统计量的分布是已知的，并且独立于所检验的特定连续分布。此性质允许计算 $p$ 值，其定义为：假设 $H_0$ 为真时，观测到与数据计算出的检验统计量一样极端或更极端的统计量的概率。\n\n决策规则基于显著性水平 $\\alpha$：\n- 如果 $p$ 值小于 $\\alpha$，我们拒绝原假设 $H_0$。\n- 如果 $p$ 值大于或等于 $\\alpha$，我们不拒绝原假设 $H_0$。\n\n问题要求一个布尔决策，当不拒绝 $H_0$ 时为 $\\text{True}$。因此，给定测试用例的决策将是比较 $p\\text{值} \\ge \\alpha$ 的结果。在实现上，我们将使用 `scipy.stats.kstest` 函数。`scipy` 中的指数分布实现由位置参数 `loc` 和尺度参数 `scale` 参数化。为了匹配我们的目标 PDF $\\lambda e^{-\\lambda x}$，我们必须设置 `loc`$=0$ 和 `scale`$=1/\\lambda$。\n\n每个测试用例 $(\\lambda, n, \\alpha)$ 的完整算法如下：\n1. 使用以 $s=123456789$ 为种子的生成器生成 $n$ 个均匀分布的随机数 $u_1, \\dots, u_n$。\n2. 将这些数转换为指数样本 $x_i = -\\frac{1}{\\lambda} \\ln(u_i)$。\n3. 对样本 $\\{x_i\\}$ 进行 K-S 检验，对照参数为 `loc=0` 和 `scale=1/\\lambda` 的 'expon' 分布。\n4. 从检验结果中获取 $p$ 值。\n5. 计算布尔决策为 $p\\text{值} \\ge \\alpha$。\n6. 报告四舍五入到六位小数的 $p$ 值和布尔决策。\n\n此过程将对所有五个指定的测试用例执行。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Solves the problem by generating exponential samples via inverse transform\n    and validating them with a Kolmogorov-Smirnov goodness-of-fit test.\n\n    The process adheres to the problem's requirements for validation,\n    reproducibility with a fixed seed, and specific output formatting.\n    \"\"\"\n    \n    # Global seed for reproducibility, as per problem statement.\n    # The modern `default_rng` is used for generating pseudo-random numbers.\n    seed = 123456789\n    rng = np.random.default_rng(seed)\n\n    # Test suite: each tuple is (lambda, n, alpha)\n    test_cases = [\n        (0.7, 1000, 0.05),\n        (2.3, 200, 0.01),\n        (0.1, 500, 0.10),\n        (10.0, 100, 0.05),\n        (0.5, 5, 0.20),\n    ]\n\n    results = []\n    for lambda_val, n, alpha in test_cases:\n        # Task 1: Generate n samples from the exponential distribution with rate lambda.\n        # This is implemented using the inverse transform method.\n        # If U is a random variable from Uniform(0, 1), then X = -ln(U)/lambda\n        # is a random variable from Exponential(lambda).\n        \n        # Generate n uniform random numbers in the interval [0.0, 1.0).\n        uniform_samples = rng.uniform(size=n)\n        \n        # Apply the inverse CDF transformation.\n        exponential_samples = -np.log(uniform_samples) / lambda_val\n\n        # Task 2: Conduct a one-sample Kolmogorov-Smirnov test.\n        # The null hypothesis (H0) is that the generated data follows an\n        # exponential distribution with the given rate lambda_val.\n        # The `scipy.stats.expon` distribution is parameterized by `loc` and `scale`.\n        # For a rate lambda, the scale parameter is 1/lambda and loc is 0.\n        scale_param = 1.0 / lambda_val\n        ks_statistic, p_value = stats.kstest(exponential_samples, 'expon', args=(0, scale_param))\n        \n        # The decision is True if we do not reject H0 at significance level alpha.\n        # This occurs when the p-value is greater than or equal to alpha.\n        decision = p_value = alpha\n        \n        # Format results as specified in the problem statement.\n        p_value_rounded = round(p_value, 6)\n        \n        results.append(p_value_rounded)\n        results.append(decision)\n\n    # Final print statement in the exact required format.\n    # The map(str, ...) function correctly converts boolean values to \"True\"/\"False\".\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the main function to solve the problem and print the output.\nsolve()\n```"
        },
        {
            "introduction": "一个理论上正确的算法在计算机上实现时，未必是数值稳健的。本练习将深入探讨逆变换采样中一个微妙但至关重要的问题：浮点数运算的精度。你将分析为何直接使用公式 $X = -\\frac{\\ln(1-U)}{\\lambda}$ 会在特定输入下导致灾难性的精度损失，并探索数值上更稳定的替代方案。对于编写能在各种输入下都保持可靠的专业级模拟代码而言，掌握这一概念是必不可少的。 ",
            "id": "3314503",
            "problem": "要求您分析在有限精度算术下，连续变量的逆变换采样法的数值稳定性。\n\n考虑通过对均匀分布变量 $U\\sim\\mathrm{Uniform}(0,1)$ 应用逆变换来从速率参数为 $\\lambda0$ 的指数分布中生成样本，即 $X=F^{-1}(U)$，其中 $F(x)=1-\\exp(-\\lambda x)$。直接的代数重排得到 $X=-\\log(1-U)/\\lambda$。假设我们使用符合 Institute of Electrical and Electronics Engineers (IEEE) 754标准的基2浮点运算，采用四舍五入到最近值的方式，并设机器精度为 $\\varepsilon_{\\mathrm{mach}}$（对于 IEEE 754 binary64，$\\varepsilon_{\\mathrm{mach}}=2^{-53}$ 是单位舍入误差的一半，即如果 $x$ 是一个实数，$\\mathrm{fl}(x)$ 表示其舍入后的表示，则对于一次没有溢出/下溢的正确舍入基本运算，有 $\\mathrm{fl}(x)=x(1+\\delta)$，其中 $|\\delta|\\le \\varepsilon_{\\mathrm{mach}}$）。在下文中，令 $\\mathrm{fl}(\\cdot)$ 表示单次浮点运算的舍入结果，并令 $\\log1p(z)$ 表示一个库函数，它能以高相对精度计算 $z$ 接近 $0$ 时的 $\\log(1+z)$。\n\n严格从逆变换采样和浮点舍入模型的定义出发，推断通过 $-\\log(1-U)$ 计算 $X$ 的数值行为，以及通过避免显式计算 $1-U$ 的替代方法的数值行为。特别地，确定以下哪些陈述是正确的。可能有一个以上的正确选项。\n\nA. 在采用四舍五入到最近值的 IEEE 754 binary64 标准中，如果 $u  2^{-53}$，则 $\\mathrm{fl}(1-u)=1$ 精确成立。因此，使用 $x=-\\log(\\mathrm{fl}(1-u))$ 的朴素逆变换返回 $x=0$，而真实值为 $x=-\\log(1-u)\\approx u0$。使用 $x=-\\log1p(-u)$ 可以避免这种信息损失，因为它不将 $1-u$ 作为中间量进行计算。\n\nB. 对于接近 $1$ 的 $u$，减法 $1-u$ 是良态的（well-conditioned），永远不会损失相对精度，所以 $-\\log(1-u)$ 的精度总是和 $-\\log1p(-u)$ 一样高。\n\nC. 用 $-\\log(u)$ 替换 $-\\log(1-u)$ 会产生同分布的样本，并且严格避免了相减抵消；然而，为了防止计算 $\\log(0)$，必须确保 $u\\in(0,1]$，例如，在应用对数函数之前，可以将精确的零映射到大于 $0$ 的下一个可表示数。\n\nD. 在计算 $-\\log(1-u)$ 之前，给 $u$ 加上一个固定的正常数 $\\varepsilon$（例如，$u\\leftarrow u+2^{-53}$）是修复抵消问题而又不使目标分布产生偏差的可靠方法。\n\nE. 对于可微函数 $F$ 的一般逆变换形式 $F^{-1}(u)$，在 $u$ 中的舍入可能产生灾难性误差的唯一地方是当 $u\\approx 1$ 时；对于 $-\\log(1-u)$ 来说，$u\\approx 0$ 的值在数值上是无害的。\n\n选择所有正确的选项，并使用关于逆变换法、小 $x$ 时 $\\log(1-x)$ 的行为以及浮点误差模型的基本原理来证明你的选择。",
            "solution": "问题要求分析使用逆变换法生成指数分布随机变量的数值稳定性。\n\n问题的核心在于计算 $X = -\\frac{\\log(1-U)}{\\lambda}$，其中 $U$ 是来自 $\\mathrm{Uniform}(0,1)$ 分布的随机变量。乘法因子 $1/\\lambda$ 在数值上是稳定的（假设 $\\lambda$ 不接近溢出或下溢的极限），所以我们关注 $-\\log(1-U)$ 这一项。此计算中的数值问题取决于 $U$ 的值。\n\n$U$ 的两个关键区间是 $U \\to 0$ 和 $U \\to 1$。\n\n情况1：$U = u$，其中 $u$ 接近 $0$。\n数学表达式为 $x = -\\log(1-u)/\\lambda$。使用 $\\log(1-z)$ 在 $z=0$ 附近的泰勒级数展开 $\\log(1-z) = -z - z^2/2 - \\dots$，我们发现对于小的 $u0$，$x \\approx -(-u)/\\lambda = u/\\lambda$。期望的结果是一个小的正数。\n朴素的浮点计算是 $\\mathrm{fl}(-\\log(\\mathrm{fl}(1-u))/\\lambda)$。第一步是减法 $\\mathrm{fl}(1-u)$。根据问题中对 IEEE 754 binary64 算术的描述，单位舍入误差是 $\\varepsilon_{\\mathrm{mach}} = 2^{-53}$。机器ε（machine epsilon），即从 $1$ 到下一个更大的可表示浮点数之间的距离，是 $\\varepsilon = 2\\varepsilon_{\\mathrm{mach}} = 2^{-52}$。\n当一个实数被舍入到最近的浮点数时，区间 $(1 - \\varepsilon/2, 1]$ 中的任何数都将被舍入为 $1$。这个区间是 $(1 - 2^{-53}, 1]$。如果 $u$ 是一个正的浮点数且满足 $u  2^{-53}$，那么 $1-u$ 就落入这个区间内，因此 $\\mathrm{fl}(1-u) = 1$。\n因此，对于这样小的 $u$，计算结果为 $\\mathrm{fl}(-\\log(1)/\\lambda) = 0$。这是灾难性的精度损失，因为真实值约为 $u/\\lambda  0$，而计算结果恰好是 $0$。这种由于减法导致重要信息丢失的误差是一种灾难性抵消（catastrophic cancellation）。\n\n情况2：$U = u$，其中 $u$ 接近 $1$。\n设 $u = 1-\\delta$，其中 $\\delta  0$ 是一个小数。数学表达式为 $x = -\\log(1-(1-\\delta))/\\lambda = -\\log(\\delta)/\\lambda$。当 $\\delta \\to 0^+$ 时，$x \\to +\\infty$。\n计算涉及减法 $1-u$。计算 $f(u)=1-u$ 这个问题的条件数是 $\\kappa(u) = |u f'(u) / f(u)| = |u(-1)/(1-u)| = |u/(1-u)|$。当 $u \\to 1$ 时，$\\kappa(u) \\to \\infty$。这意味着该问题是病态的（ill-conditioned）：输入 $u$ 的微小相对误差会被放大成输出 $1-u$ 的巨大相对误差。例如，将 $U$ 表示为浮点数时的舍入误差，即使只有一个 $\\varepsilon_{\\mathrm{mach}}$，也可能导致 $1-U$ 这个量的相对误差非常大，然后这个误差会通过对数函数传播。\n\n现在我们来评估每个选项。\n\nA. 在采用四舍五入到最近值的 IEEE 754 binary64 标准中，如果 $u  2^{-53}$，则 $\\mathrm{fl}(1-u)=1$ 精确成立。因此，使用 $x=-\\log(\\mathrm{fl}(1-u))$ 的朴素逆变换返回 $x=0$，而真实值为 $x=-\\log(1-u)\\approx u0$。使用 $x=-\\log1p(-u)$ 可以避免这种信息损失，因为它不将 $1-u$ 作为中间量进行计算。\n\n这个陈述是正确的。如情况1的分析所示，如果 $u$ 是一个小于单位舍入误差 $\\varepsilon_{\\mathrm{mach}} = 2^{-53}$ 的正数，那么在浮点运算中执行的减法 $1-u$ 会精确地得到 $1$。这导致 $\\log(1)=0$，完全丢失了包含在 $u$ 中的信息。真实值 $-\\log(1-u)$ 约等于 $u$，所以这是朴素算法的一个失败。函数 $\\log1p(z)$ 专门用于精确计算小 $|z|$ 时的 $\\log(1+z)$。通过将 $-\\log(1-u)$ 重写为 $-\\log1p(-u)$，我们将小量 $-u$ 直接传递给这个专用函数，该函数可以使用数值稳定的方法（如泰勒级数近似）来计算结果，而无需执行导致抵消的中间减法 $1-u$。这准确地反映了 `log1p` 的目的和功能。 **正确**。\n\nB. 对于接近 $1$ 的 $u$，减法 $1-u$ 是良态的，永远不会损失相对精度，所以 $-\\log(1-u)$ 的精度总是和 $-\\log1p(-u)$ 一样高。\n\n这个陈述是不正确的。第一个论断，即对于接近 $1$ 的 $u$ 减法 $1-u$ 是良态的，是错误的。如情况2的分析所示，计算 $1-u$ 的条件数是 $|u/(1-u)|$，当 $u \\to 1$ 时它趋于无穷大。一个病态问题是指微小的相对输入误差可能导致巨大的相对输出误差。虽然浮点减法本身在某些条件下可能是精确的（例如，Sterbenz's Lemma），但根本问题是病态的，这意味着 $u$ 中的任何误差（例如，来自原始的随机数生成）都将被极大地放大。由于该陈述的前提是错误的，所以该陈述不成立。 **不正确**。\n\nC. 用 $-\\log(u)$ 替换 $-\\log(1-u)$ 会产生同分布的样本，并且严格避免了相减抵消；然而，为了防止计算 $\\log(0)$，必须确保 $u\\in(0,1]$，例如，在应用对数函数之前，可以将精确的零映射到大于 $0$ 的下一个可表示数。\n\n这个陈述是正确的。如果一个随机变量 $U$ 服从 $\\mathrm{Uniform}(0,1)$ 分布，那么随机变量 $V=1-U$ 也服从 $\\mathrm{Uniform}(0,1)$ 分布。这是均匀分布的一个基本性质。因此，使用 $X = -\\log(U)/\\lambda$ 生成样本在统计上等价于使用 $X = -\\log(1-U)/\\lambda$。表达式 $-\\log(U)/\\lambda$ 不涉及减法 $1-U$，从而完全避免了在原始公式中当 $U$ 接近 $0$ 时发生的灾难性抵消问题。这种替代方法在数值上更优越。附带的警告也是正确的：由于均匀随机数生成器可能会产生精确的 $0$，因此必须处理 $U=0$ 的情况，以防止 $\\log(0)$ 产生错误。这是稳健实现所必需的实际考虑。 **正确**。\n\nD. 在计算 $-\\log(1-u)$ 之前，给 $u$ 加上一个固定的正常数 $\\varepsilon$（例如，$u\\leftarrow u+2^{-53}$）是修复抵消问题而又不使目标分布产生偏差的可靠方法。\n\n这个陈述是不正确的。提议的修改是 $X' = -\\log(1-(U+\\varepsilon))/\\lambda$。如果 $U \\sim \\mathrm{Uniform}(0,1)$，那么 $U' = U+\\varepsilon$ 服从 $\\mathrm{Uniform}(\\varepsilon, 1+\\varepsilon)$ 分布。对一个不服从 $\\mathrm{Uniform}(0,1)$ 分布的随机变量应用逆变换法，不会从原始目标分布中产生样本。得到的样本 $X'$ 的分布将不同于期望的指数分布。声称这样做可以“不使目标分布产生偏差”是错误的。这种方法引入了系统误差，即偏差。 **不正确**。\n\nE. 对于可微函数 $F$ 的一般逆变换形式 $F^{-1}(u)$，在 $u$ 中的舍入可能产生灾难性误差的唯一地方是当 $u\\approx 1$ 时；对于 $-\\log(1-u)$ 来说，$u\\approx 0$ 的值在数值上是无害的。\n\n这个陈述是不正确的。它提出了两个错误的论断。首先，如选项A的分析所确立的，当 $u \\approx 0$ 时，正是朴素计算 $-\\log(1-u)$ 会遭受灾难性抵消的地方，所以这种情况并非“数值上无害”。其次，关于误差只在 $u \\approx 1$ 时产生的泛化是错误的。对于一个一般分布， $F^{-1}(u)$ 对 $u$ 变化的敏感度由导数 $(F^{-1})'(u) = 1/f(F^{-1}(u))$ 给出，其中 $f$ 是概率密度函数。只要这个导数值很大，就可能出现大误差，这发生在分布的尾部，即 $f(x)$ 很小的地方。对于许多分布，如正态分布，有两个尾部，分别对应于 $u \\to 0$ 和 $u \\to 1$。因此，数值问题可能在 $(0,1)$ 区间的两端出现，而不仅仅是 $u \\approx 1$ 附近。 **不正确**。",
            "answer": "$$\\boxed{AC}$$"
        },
        {
            "introduction": "在第一个练习中，我们使用了柯尔莫哥洛夫-斯米尔诺夫 (KS) 检验来验证我们的生成器。但是，这个检验背后的理论依据是什么？本练习旨在挑战你对KS检验本身进行批判性思考。你将分析为何它对于参数完全指定的分布是有效的，以及当分布参数必须从数据中估计时——一个在实践中更为常见的情形——它的性质会如何改变。这将加深你对统计验证的理解，并介绍参数自助法 (parametric bootstrap) 等高级技术，这些技术对于严谨的模型检验至关重要。 ",
            "id": "3307758",
            "problem": "一名从业者正在验证一个指数变量生成器，该生成器旨在从率参数为 $\\lambda$ 的指数分布中生成独立同分布的样本 $X_1,\\dots,X_n$，记为 $X_i \\sim \\mathrm{Exp}(\\lambda)$，其概率密度函数为 $f_\\lambda(x) = \\lambda e^{-\\lambda x}$（当 $x \\ge 0$ 时），累积分布函数 (CDF) 为 $F_\\lambda(x) = 1 - e^{-\\lambda x}$。目标是使用从经验累积分布函数 (ECDF) 定义的柯尔莫哥洛夫-斯米尔诺夫 (KS) 统计量，检验一个完全指定的率 $\\lambda_0$ 的原假设 $H_0: X_i \\sim \\mathrm{Exp}(\\lambda_0)$。当 $\\lambda$ 不是先验已知时，该从业者考虑在应用检验之前通过最大似然估计来估计它。仅使用基本定义和事实，包括 ECDF $F_n(x) = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{X_i \\le x\\}$、KS 统计量的定义 $D_n = \\sup_{x \\in \\mathbb{R}} |F_n(x) - F_{\\lambda_0}(x)|$、概率积分变换的性质，以及在完全指定的连续原假设下经验过程上确界的已知大样本行为，选择所有关于在已知 $\\lambda_0$ 的情况下构建 $H_0$ 下的 KS 检验，以及当 $\\lambda$ 从数据中估计时所需调整的正确陈述。\n\nA. 在 $\\lambda_0$ 完全指定的 $H_0$ 下，由于通过 $Y_i = F_{\\lambda_0}(X_i)$ 应用了概率积分变换，统计量 $D_n = \\sup_{x \\in \\mathbb{R}} |F_n(x) - F_{\\lambda_0}(x)|$ 是分布无关的，并且 $\\sqrt{n} D_n \\xrightarrow{d}$ 柯尔莫哥洛夫分布；因此临界值不依赖于 $\\lambda_0$。\n\nB. 如果 $\\lambda$ 通过最大似然估计量 (MLE) $\\hat{\\lambda} = 1/\\bar{X}$ 进行估计，并计算 $D_n = \\sup_{x \\in \\mathbb{R}} |F_n(x) - F_{\\hat{\\lambda}}(x)|$，那么该统计量在 $H_0$ 下仍然是分布无关的，并且与完全指定 $\\lambda$ 的情况下相同的临界值无需调整即可适用。\n\nC. 当 $\\lambda$ 被估计时，对于指数分布情况，$D_n$ 的一个精确的有限样本零分布存在闭式解，并且与完全指定 $\\lambda$ 的情况相一致。\n\nD. 当 $\\lambda$ 被估计时，需要进行 Lilliefors 类型的调整：$D_n$ 的零分布依赖于估计过程，并且可以通过参数自助法获得有效的 $p$ 值，该方法对自助法重复 $b = 1,\\dots,B$ 次，每次模拟 $X_1^{*(b)},\\dots,X_n^{*(b)} \\overset{\\mathrm{iid}}{\\sim} \\mathrm{Exp}(\\hat{\\lambda})$，并重新计算 $\\hat{\\lambda}^{*(b)}$ 和相应的 $D_n^{*(b)}$。\n\nE. 对于已知的 $\\lambda_0$，通过 $Y_i = \\lambda_0 X_i$ 变换样本会改变 $D_n$ 的数值，尽管它简化了极限分布。\n\nF. 在已知 $\\lambda_0$ 的 $H_0$ 下，$T_n = \\sqrt{n} D_n$ 的一个渐近有效的尾部近似为 $P(T_n \\ge t) \\approx 2 \\sum_{k=1}^\\infty (-1)^{k-1} e^{-2 k^2 t^2}$ (当 $t \\ge 0$ 时)，这提供了不依赖于 $\\lambda_0$ 的大样本 $p$ 值和临界值。\n\n选择所有适用的选项。",
            "solution": "问题陈述描述了对指数分布进行单样本柯尔莫哥洛夫-斯米尔诺夫 (KS) 拟合优度检验的设置。该问题区分了两种情况：一种是率参数 $\\lambda_0$ 完全指定的简单原假设，另一种是率参数 $\\lambda$ 必须从数据中估计的复合原假设。所提供的关于指数分布、经验累积分布函数 (ECDF) 和 KS 统计量的定义都是标准且正确的。该问题在科学上基于统计假设检验理论，问题陈述清晰且客观。它不包含任何不一致或模糊之处。因此，该问题是有效的，我们可以继续评估给出的陈述。\n\n支配此问题的核心原则是：\n1.  **概率积分变换 (PIT)：** 对于一个具有累积分布函数 (CDF) $F_X$ 的连续随机变量 $X$，随机变量 $Y = F_X(X)$ 在区间 $[0, 1]$ 上均匀分布。\n2.  **简单假设的 KS 检验：** 当检验 $H_0: F = F_0$（其中 $F_0$ 是一个连续且完全指定的 CDF）时，KS 统计量 $D_n = \\sup_x |F_n(x) - F_0(x)|$ 的分布不依赖于 $F_0$。这是 PIT 的直接推论。渐近地，$\\sqrt{n} D_n$ 依分布收敛于标准布朗桥绝对值的上确界，该分布被称为柯尔莫哥洛夫分布。\n3.  **复合假设的 KS 检验：** 当检验 $H_0: F \\in \\{F_\\theta\\}$ 且参数 $\\theta$ 从数据中估计为 $\\hat{\\theta}$ 时，统计量变为 $D_n = \\sup_x |F_n(x) - F_{\\hat{\\theta}}(x)|$。该统计量的零分布不再是标准的 KS 分布。对 $\\hat{\\theta}$ 的数据依赖性估计使得拟合的 CDF $F_{\\hat{\\theta}}$ 比固定的 $F_0$ 更“接近”ECDF $F_n$，从而导致 $D_n$ 的值在随机意义上更小。由此产生的检验通常称为 Lilliefors 检验。零分布取决于分布族 $\\{F_\\theta\\}$、被估计的参数以及估计方法。临界值必须进行调整，通常通过参数自助法等模拟方法。\n\n我们现在将基于这些原则分析每个选项。\n\n**选项 A 评估：**\n该陈述涉及简单原假设的情况，即 $H_0: X_i \\sim \\mathrm{Exp}(\\lambda_0)$，其中 $\\lambda_0$ 已知。\n在 $H_0$ 下，数据 $X_i$ 来自 CDF 为 $F_{\\lambda_0}(x) = 1 - e^{-\\lambda_0 x}$ 的分布。应用概率积分变换，我们定义新变量 $Y_i = F_{\\lambda_0}(X_i)$。根据 PIT，如果原假设为真，则样本 $Y_1, \\dots, Y_n$ 是来自均匀分布 $U[0, 1]$ 的一个独立同分布样本。\nKS 统计量可以用这些变换后的变量重写。设 $G_n(y)$ 是 $Y_i$ 的 ECDF。\n$D_n = \\sup_{x \\in \\mathbb{R}} |F_n(x) - F_{\\lambda_0}(x)|$。通过变量替换 $y = F_{\\lambda_0}(x)$，我们有 $x = F_{\\lambda_0}^{-1}(y)$。\n$F_n(x) = F_n(F_{\\lambda_0}^{-1}(y)) = \\frac{1}{n}\\sum \\mathbf{1}\\{X_i \\le F_{\\lambda_0}^{-1}(y)\\} = \\frac{1}{n}\\sum \\mathbf{1}\\{F_{\\lambda_0}(X_i) \\le y\\} = G_n(y)$。\n因此，$D_n = \\sup_{y \\in [0,1]} |G_n(y) - y|$。\n该统计量的分布仅依赖于来自 $U[0, 1]$ 的独立同分布样本，因此与原始 CDF $F_{\\lambda_0}$ 无关。该统计量是**分布无关的**。\n根据 Donsker 定理，经验过程 $\\sqrt{n}(G_n(y) - y)$ 依分布收敛于 $[0, 1]$ 上的一个布朗桥。然后，连续映射定理意味着 $\\sqrt{n} D_n = \\sup_{y \\in [0,1]} |\\sqrt{n}(G_n(y) - y)|$ 依分布收敛于布朗桥绝对值的上确界，即柯尔莫哥洛夫分布。\n由于对于任何连续的 $F_0$，极限分布都是普适的，因此大样本临界值不依赖于 $\\lambda_0$。该陈述完全正确。\n**结论：正确**\n\n**选项 B 评估：**\n该陈述涉及复合原假设的情况，其中 $\\lambda$ 由 MLE $\\hat{\\lambda} = 1/\\bar{X}$ 估计。现在的统计量是 $D_n = \\sup_{x \\in \\mathbb{R}} |F_n(x) - F_{\\hat{\\lambda}}(x)|$。该陈述声称此统计量仍然是分布无关的，并且适用相同的临界值。这在根本上是错误的。从数据中估计 $\\lambda$ 的过程在 ECDF $F_n(x)$ 和假设的 CDF $F_{\\hat{\\lambda}}(x)$ 之间产生了一种依赖关系。与简单假设情况相比，这种依赖关系系统性地减小了 $D_n$ 的值。因此，$D_n$ 的零分布在随机意义上更小。使用完全指定情况下的临界值将导致过于保守的检验（即，实际的第一类错误率将低于名义水平，且统计功效会降低）。这个修正后统计量的零分布不再是标准的柯尔莫哥洛夫分布。虽然对于像指数族这样的某些分布族，得到的零分布仍然与真实参数 $\\lambda$ 无关（因此在有限的意义上是“分布无关的”），但它与完全指定情况下的分布是*不同*的分布。因此，“同样的临界值...无需调整即可适用”的说法是错误的。\n**结论：不正确**\n\n**选项 C 评估：**\n该陈述声称，对于估计参数的情况，“对于指数分布情况，$D_n$ 的一个精确的有限样本零分布存在闭式解，并且与完全指定 $\\lambda$ 的情况相一致”。\n该陈述的后半部分，“与完全指定 $\\lambda$ 的情况相一致”，是明显错误的，如选项 B 的评估中所解释。这两个分布是不同的。仅此一点就足以否定该陈述。\n此外，前半部分，“一个精确的有限样本零分布...存在闭式解”，也是一个可疑的说法。虽然像 J. Durbin 这样的研究人员已经推导出了这种特定情况（指数分布，均值已估计）的精确分布，但它由一个复杂的公式给出，该公式涉及矩阵的行列式，而矩阵的元素是样本量 $n$ 的函数。这通常不是指简单初等函数意义上的“闭式解”。\n**结论：不正确**\n\n**选项 D 评估：**\n该陈述描述了复合假设检验的程序，准确地反映了参数估计的后果。\n- “需要进行 Lilliefors 类型的调整”：这是正确的术语。Lilliefors 检验最初指的是对正态分布进行均值和方差已估计的 KS 检验，但该术语现在更广泛地用于任何带有估计参数的 KS 型检验。对临界值进行调整是必要的。\n- “$D_n$ 的零分布依赖于估计过程”：这是该理论的基石之一。检验统计量的渐近分布是某个高斯过程上确界的分布，该高斯过程的协方差核取决于底层的分布族和估计量的性质。\n- “有效的 $p$ 值可以通过参数自助法获得...”：这描述了在这种情况下寻找 $p$ 值或临界值的标准的、正确的基于模拟的方法。该程序是：1. 从数据中估计 $\\hat{\\lambda}$。2. 为了模拟零分布，假设真实分布是 $\\mathrm{Exp}(\\hat{\\lambda})$。3. 从 $\\mathrm{Exp}(\\hat{\\lambda})$ 中生成大量的（$B$ 个）大小为 $n$ 的自助样本。4. 对于每个自助样本，重复整个估计和检验过程：计算 MLE $\\hat{\\lambda}^{*(b)}$ 和统计量 $D_n^{*(b)}$。5. 这 $B$ 个 $D_n^{*(b)}$ 值的经验分布可作为检验统计量真实零分布的近似。然后可以将原始统计量 $D_n$ 与此经验分布进行比较以获得 $p$ 值。该描述是精确且正确的。\n**结论：正确**\n\n**选项 E 评估：**\n该陈述分析了变换 $Y_i = \\lambda_0 X_i$。让我们考察此变换下的 KS 统计量。\n如果 $H_0: X_i \\sim \\mathrm{Exp}(\\lambda_0)$ 为真，则变换后的变量 $Y_i$ 的 CDF 为 $P(Y_i \\le y) = P(\\lambda_0 X_i \\le y) = P(X_i \\le y/\\lambda_0) = F_{\\lambda_0}(y/\\lambda_0) = 1 - e^{-\\lambda_0 (y/\\lambda_0)} = 1 - e^{-y}$。因此，$Y_i \\sim \\mathrm{Exp}(1)$。\n原始的 KS 统计量是 $D_n(X) = \\sup_{x \\in \\mathbb{R}} |F_n(x) - F_{\\lambda_0}(x)|$。\n设 $G_n(y)$ 是 $Y_i$ 的 ECDF。\n$G_n(y) = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{Y_i \\le y\\} = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{\\lambda_0 X_i \\le y\\} = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{X_i \\le y/\\lambda_0\\} = F_n(y/\\lambda_0)$。\n对于变换后的样本 $Y_i$ 对比目标分布 $\\mathrm{Exp}(1)$（其 CDF 为 $F_1(y)=1-e^{-y}$）的 KS 统计量将是：\n$D_n(Y) = \\sup_{y \\in \\mathbb{R}} |G_n(y) - F_1(y)| = \\sup_{y \\in \\mathbb{R}} |F_n(y/\\lambda_0) - F_{\\lambda_0}(y/\\lambda_0)|$。\n通过令 $x = y/\\lambda_0$，对所有 $y \\ge 0$ 的上确界等价于对所有 $x \\ge 0$ 的上确界。\n因此，$D_n(Y) = \\sup_{x \\in \\mathbb{R}} |F_n(x) - F_{\\lambda_0}(x)| = D_n(X)$。\nKS 统计量的数值在这种尺度变换下是不变的。关于该变换“改变了 $D_n$ 的数值”的说法是错误的。这种变换的目的是为了证明 *为什么* $D_n$ 的分布与 $\\lambda_0$ 无关（通过将其简化为一个标准情况），而不是为了简化极限分布本身，因为无论如何极限分布都是柯尔莫哥洛夫分布。\n**结论：不正确**\n\n**选项 F 评估：**\n该陈述提供了在已知 $\\lambda_0$ 的简单原假设 $H_0$ 下，检验统计量 $T_n = \\sqrt{n} D_n$ 的渐近尾部概率。\n正如在选项 A 的分析中确立的，$T_n$ 依分布收敛于柯尔莫哥洛夫分布。与柯尔莫哥洛夫分布相关的随机变量是 $K = \\sup_{t \\in [0,1]} |B(t)|$，其中 $B(t)$ 是一个标准布朗桥。尾部概率 $P(K  t)$ 由公式 $2 \\sum_{k=1}^\\infty (-1)^{k-1} e^{-2 k^2 t^2}$ 给出。由于极限分布是连续的，$P(T_n \\ge t) \\approx P(K  t)$。选项中提供的公式是正确且众所周知的结果。由于尾部概率的公式是一个不涉及 $\\lambda_0$ 的固定表达式，它证实了从中导出的大样本 $p$ 值和临界值与原假设下指数分布的具体参数 $\\lambda_0$ 无关。\n**结论：正确**",
            "answer": "$$\\boxed{ADF}$$"
        }
    ]
}