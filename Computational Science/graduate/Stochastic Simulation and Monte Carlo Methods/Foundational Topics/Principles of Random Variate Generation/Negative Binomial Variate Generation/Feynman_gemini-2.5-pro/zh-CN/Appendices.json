{
    "hands_on_practices": [
        {
            "introduction": "本练习旨在连接负二项分布的理论定义及其实际生成成本。通过将生成过程分析为一系列伯努利试验，您将推导出生成一个随机变量所需的期望随机数数量，这是评估任何模拟算法效率的关键指标。这项基础分析有助于理解基本随机变量生成器的性能特征 。",
            "id": "3323098",
            "problem": "一个仿真引擎提供一串独立同分布 (i.i.d.) 的 $\\mathrm{Uniform}(0,1)$ 变量。单次 $\\mathrm{Bernoulli}(p)$ 试验，其成功概率固定为 $p \\in (0,1]$，通过抽取一个 $\\mathrm{Uniform}(0,1)$ 变量 $U$ 并返回指示函数 $\\mathbf{1}\\{U \\leq p\\}$ 来实现。考虑基于这些 $\\mathrm{Bernoulli}(p)$ 试验构建的两个生成器：\n\n- 一个几何生成器，其输出为观测到首次成功所需的 $\\mathrm{Bernoulli}(p)$ 试验次数。每次 $\\mathrm{Bernoulli}(p)$ 试验恰好消耗一个 $\\mathrm{Uniform}(0,1)$ 变量。\n- 一个负二项生成器，其参数为 $(r,p)$，其中 $r \\in \\mathbb{N}$ 是一个固定的正整数。该生成器输出第 $r$ 次成功之前的失败次数，其实现方式可以是累加 $r$ 个独立同分布的几何等待时间，或者等价地，运行 $\\mathrm{Bernoulli}(p)$ 试验直到第 $r$ 次成功发生。每次 $\\mathrm{Bernoulli}(p)$ 试验恰好消耗一个 $\\mathrm{Uniform}(0,1)$ 变量。\n\n设 $C_{\\mathrm{Geo}}(p)$ 表示生成一个几何分布随机数所需的 $\\mathrm{Uniform}(0,1)$ 调用的期望次数，并设 $C_{\\mathrm{NB}}(r,p)$ 表示生成一个负二项分布随机数所需的 $\\mathrm{Uniform}(0,1)$ 调用的期望次数。仅使用基础概率定义（独立性、从单个 $\\mathrm{Uniform}(0,1)$ 变量构造 $\\mathrm{Bernoulli}(p)$ 的指示函数方法，以及几何和负二项等待时间的定义），推导 $C_{\\mathrm{Geo}}(p)$，然后推断出 $C_{\\mathrm{NB}}(r,p)$。\n\n请以一个关于 $r$ 和 $p$ 的单一闭式解析表达式的形式报告您的最终答案 $C_{\\mathrm{NB}}(r,p)$。无需四舍五入，不涉及单位。",
            "solution": "问题要求推导生成一个几何分布随机数（记为 $C_{\\mathrm{Geo}}(p)$）和一个负二项分布随机数（记为 $C_{\\mathrm{NB}}(r,p)$）所需的 $\\mathrm{Uniform}(0,1)$ 变量的期望数量。\n\n首先，我们必须验证问题陈述。\n\n### 步骤1：提取已知条件\n- 提供一串独立同分布 (i.i.d.) 的 $\\mathrm{Uniform}(0,1)$ 变量。\n- 一次 $\\mathrm{Bernoulli}(p)$ 试验通过抽取一个 $\\mathrm{Uniform}(0,1)$ 变量 $U$ 并返回指示函数 $\\mathbf{1}\\{U \\leq p\\}$ 来实现。成功概率为 $p \\in (0,1]$。\n- 每次 $\\mathrm{Bernoulli}(p)$ 试验恰好消耗一个 $\\mathrm{Uniform}(0,1)$ 变量。\n- 一个几何生成器输出观测到首次成功所需的 $\\mathrm{Bernoulli}(p)$ 试验次数。\n- 一个负二项生成器参数为 $(r,p)$，其中 $r \\in \\mathbb{N}$ 是一个固定的正整数。它输出第 $r$ 次成功之前的失败次数。\n- 负二项生成器通过累加 $r$ 个独立同分布的几何等待时间，或等价地，通过运行伯努利试验直到第 $r$ 次成功发生来实现。\n- $C_{\\mathrm{Geo}}(p)$ 是生成一个几何分布随机数所需的 $\\mathrm{Uniform}(0,1)$ 调用的期望次数。\n- $C_{\\mathrm{NB}}(r,p)$ 是生成一个负二项分布随机数所需的 $\\mathrm{Uniform}(0,1)$ 调用的期望次数。\n- 任务是推导 $C_{\\mathrm{Geo}}(p)$，然后推断出 $C_{\\mathrm{NB}}(r,p)$。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题具有科学依据，提法恰当且客观。它基于概率论和随机模拟中的标准、基本定义。通过反演法从均匀变量构造伯努利变量是蒙特卡洛方法的一个基石。几何分布和负二项分布的定义是标准的。所有参数和约束（$p \\in (0,1]$, $r \\in \\mathbb{N}$）都已明确指定。问题是自洽且逻辑一致的，没有缺失或矛盾的信息。它要求推导一个明确定义的量——期望计算成本，该量具有唯一且有意义的解。该问题不违反任何无效性标准。\n\n### 步骤3：结论与行动\n问题有效。我们将继续进行解答。\n\n### 推导过程\n问题的核心在于认识到 $\\mathrm{Uniform}(0,1)$ 调用的次数与执行的 $\\mathrm{Bernoulli}(p)$ 试验的次数相同。因此，$C_{\\mathrm{Geo}}(p)$ 和 $C_{\\mathrm{NB}}(r,p)$ 分别是它们各自生成方案所需的伯努利试验的期望次数。\n\n**第一部分：$C_{\\mathrm{Geo}}(p)$ 的推导**\n\n设 $X$ 为获得首次成功所需试验次数的随机变量。根据定义，$X$ 服从成功概率为 $p$ 的几何分布。$X$ 的概率质量函数 (PMF) 由下式给出：\n$$P(X=k) = (1-p)^{k-1}p, \\quad \\text{for } k \\in \\{1, 2, 3, \\ldots\\}$$\n几何生成器输出 $X$ 的值。生成这单个几何分布随机数所进行的 $\\mathrm{Uniform}(0,1)$ 调用次数恰好是随机的试验次数 $X$。因此，期望调用次数 $C_{\\mathrm{Geo}}(p)$ 就是 $X$ 的期望值。\n$$C_{\\mathrm{Geo}}(p) = E[X]$$\n期望值通过对 $X$ 的支撑集求和来计算：\n$$E[X] = \\sum_{k=1}^{\\infty} k \\cdot P(X=k) = \\sum_{k=1}^{\\infty} k (1-p)^{k-1}p$$\n设 $q = 1-p$。表达式变为：\n$$E[X] = p \\sum_{k=1}^{\\infty} k q^{k-1}$$\n我们识别出该和式是几何级数的导数。对于 $|q| < 1$，我们有标准恒等式：\n$$\\sum_{k=0}^{\\infty} q^k = \\frac{1}{1-q}$$\n对两边关于 $q$ 求导得出：\n$$\\frac{d}{dq} \\left( \\sum_{k=0}^{\\infty} q^k \\right) = \\sum_{k=1}^{\\infty} k q^{k-1} = \\frac{d}{dq} \\left( \\frac{1}{1-q} \\right) = \\frac{1}{(1-q)^2}$$\n由于 $p \\in (0,1]$，我们有 $q = 1-p \\in [0,1)$，因此对于 $p \\in (0,1)$，满足 $|q|<1$。$p=1$（$q=0$）的情况是平凡的。\n将此结果代回期望的表达式中：\n$$E[X] = p \\left( \\frac{1}{(1-q)^2} \\right)$$\n现在，将 $q=1-p$ 代回：\n$$E[X] = p \\left( \\frac{1}{(1-(1-p))^2} \\right) = p \\left( \\frac{1}{p^2} \\right) = \\frac{1}{p}$$\n因此，生成一个几何分布随机数所需的期望均匀调用次数为：\n$$C_{\\mathrm{Geo}}(p) = \\frac{1}{p}$$\n\n**第二部分：$C_{\\mathrm{NB}}(r,p)$ 的推断**\n\n问题陈述，一个负二项生成器可以通过累加 $r$ 个独立同分布的几何等待时间来实现。更准确地说，达到 $r$ 次成功所需的总试验次数是 $r$ 个独立同分布的几何随机变量之和。设 $N$ 为观测到第 $r$ 次成功所需的总试验次数。设 $X_i$ 为从第 $(i-1)$ 次成功到第 $i$ 次成功所需的试验次数，其中 $i=1, 2, \\ldots, r$。\n- $X_1$ 是首次成功所需的试验次数。$X_1 \\sim \\mathrm{Geometric}(p)$。\n- $X_2$ 是第二次成功所需的额外试验次数。由于伯努利过程的无记忆性，$X_2$ 也服从 $\\mathrm{Geometric}(p)$ 分布，并且与 $X_1$ 独立。\n- ...\n- $X_r$ 是第 $r$ 次成功所需的额外试验次数。$X_r \\sim \\mathrm{Geometric}(p)$ 并且与 $X_1, \\ldots, X_{r-1}$ 独立。\n\n总试验次数 $N$ 是这些单个等待时间之和：\n$$N = X_1 + X_2 + \\cdots + X_r$$\n负二项生成器运行此过程，消耗 $N$ 个均匀变量。尽管生成器的*输出值*定义为失败次数 $N-r$，但产生此输出的*成本*是总试验次数 $N$。问题要求的是 $C_{\\mathrm{NB}}(r,p)$，即期望成本。\n$$C_{\\mathrm{NB}}(r,p) = E[N]$$\n使用期望的线性性：\n$$E[N] = E[X_1 + X_2 + \\cdots + X_r] = E[X_1] + E[X_2] + \\cdots + E[X_r]$$\n由于每个 $X_i$ 都是独立同分布的 $\\mathrm{Geometric}(p)$ 随机变量，它们的期望是相同的：\n$$E[X_i] = E[X_1] = C_{\\mathrm{Geo}}(p) = \\frac{1}{p} \\quad \\text{对于所有 } i \\in \\{1, \\ldots, r\\}$$\n因此，期望总试验次数是 $r$ 个相同期望之和：\n$$C_{\\mathrm{NB}}(r,p) = \\sum_{i=1}^{r} E[X_i] = \\sum_{i=1}^{r} \\frac{1}{p} = r \\cdot \\frac{1}{p} = \\frac{r}{p}$$\n这是生成一个参数为 $(r,p)$ 的负二项分布随机数所需的 $\\mathrm{Uniform}(0,1)$ 调用的期望次数的最终表达式。",
            "answer": "$$\\boxed{\\frac{r}{p}}$$"
        },
        {
            "introduction": "我们如何确信我们的模拟代码准确地反映了目标概率分布？本实践将指导您构建一个自动化单元测试工具，以验证负二项生成器的输出是否符合其理论性质。您将使用统计推断和Delta方法为相邻概率的比率创建置信区间，从而为检测模拟中的系统性偏差提供一种严谨的方法 。",
            "id": "3323022",
            "problem": "您的任务是编写一个完整的、可运行的程序，实现一个自动化单元测试框架，通过蒙特卡洛模拟来验证负二项分布的一个核心结构恒等式。该测试框架必须仅以基本定义和经过充分检验的基础事实作为出发点，从中推导出所需的目标量，并应用一种有原则的推断程序来检测系统性偏差。您的实现不得假定或硬编码待检验的恒等式；它必须根据从负二项分布定义推导出的第一性原理来计算所有必要的理论量。\n\n本问题中的负二项分布由一个正实数形状参数 $r \\in (0,\\infty)$ 和一个成功概率 $p \\in (0,1)$ 参数化，它模拟了在一系列成功概率为 $p$ 的独立 Bernoulli 试验中，在第 $r$ 次成功之前发生的失败次数 $K \\in \\{0,1,2,\\dots\\}$。其概率质量函数 (PMF) 对所有 $k \\in \\{0,1,2,\\dots\\}$ 定义如下\n$$\n\\mathbb{P}(K=k) \\;=\\; f(k) \\;=\\; \\binom{k+r-1}{k}\\,p^{\\,r}\\,(1-p)^{\\,k}\n\\;=\\; \\frac{\\Gamma(k+r)}{\\Gamma(r)\\,\\Gamma(k+1)}\\,p^{\\,r}\\,(1-p)^{\\,k},\n$$\n其中 $\\Gamma(\\cdot)$ 是伽马函数，$\\binom{k+r-1}{k}$ 通过伽马函数定义，这使得 $r$ 可以为非整数。对于下文要求的所有关于 $f(k)$ 的理论量的推导，此恒等式是您唯一允许的出发点。\n\n您的程序必须实现以下组件。\n\n- 模拟引擎：\n  - 为通用的实数 $r>0$ 和 $p \\in (0,1)$ 生成来自负二项分布的独立同分布样本。仅使用对实数 $r$ 有效的基本构造方法，例如 Poisson–Gamma 混合表示：如果 $\\Lambda \\sim \\mathrm{Gamma}(\\text{shape}=r,\\text{scale}=(1-p)/p)$，并且在给定 $\\Lambda$ 的条件下，$X \\mid \\Lambda \\sim \\mathrm{Poisson}(\\Lambda)$，则 $X$ 服从参数为 $r$ 和 $p$ 的负二项分布。这是一个经过充分检验的恒等式，您可以将其作为模拟器的基础。\n  - 随机数生成器必须使用确定性种子，以便输出是完全可复现的。\n\n- 经验直方图和相邻比率估计器：\n  - 从大小为 $n$ 的模拟样本中，构建 $k \\in \\{0,1,2,\\dots\\}$ 的直方图计数 $N_k$。\n  - 对于每个满足 $M_k := N_k + N_{k+1} \\ge m_{\\min}$ 的 $k$，定义双单元格条件比例 $q_k := \\frac{f(k+1)}{f(k) + f(k+1)}$ 及其经验估计量 $\\hat{q}_k := \\frac{N_{k+1}}{M_k}$。\n  - 使用变换 $g(q) = \\frac{q}{1-q}$ 来定义 PMF 的相邻比率 $R_k := \\frac{f(k+1)}{f(k)} = g(q_k)$ 及其经验对应量 $\\hat{R}_k := g(\\hat{q}_k)$，前提是 $\\hat{q}_k \\in [0,1)$ 以确保 $g$ 是有限的。\n  - 计算 $q_k$ 所需的量 $f(k)$ 和 $f(k+1)$ 必须根据上面的 PMF 定义计算，不能使用任何捷径恒等式。\n\n- 置信区间 (CI) 构建和系统性偏差标记：\n  - 对于每个满足 $M_k \\ge m_{\\min}$ 和 $\\hat{q}_k \\in [0,1)$ 的合格 $k$，基于 $N_{k+1} \\mid M_k \\sim \\mathrm{Binomial}(M_k, q_k)$ 的二项分布模型和 $g(q)=\\frac{q}{1-q}$ 的 Delta 方法线性化，为 $R_k$ 构建一个近似的双侧水平为 $1-\\alpha$ 的置信区间 (CI)。通过将 Delta 方法应用于二项比例，来证明标准误的形式的合理性。\n  - 令 $z_{1-\\alpha/2}$ 表示尾部概率为 $\\alpha/2$ 的标准正态分位数。构建以 $\\hat{R}_k$ 为中心，半宽度等于 $z_{1-\\alpha/2}$ 乘以一个由 Delta 方法得出的、用 $q_k$ 和 $M_k$ 表示的适当标准误的置信区间。\n  - 在标准误中使用 $q_k$（而不是 $\\hat{q}_k$），以避免在方差项中以数据为条件。\n  - 如果理论推导出的 $R_k$ 不在为该 $k$ 构建的置信区间内，则声明索引 $k$ 处存在违规。将该测试用例的总违规次数计为整数。\n\n- 聚合与输出：\n  - 对于每个指定的测试用例，计算所有合格 $k$ 的违规总次数（整数）。如果没有合格的 $k$，则该用例返回整数 $0$。\n  - 您的程序必须生成单行输出，其中包含所有给定测试用例的这些整数，按测试用例顺序排列，格式为方括号内逗号分隔的列表，例如 $[v_1,v_2,\\dots,v_T]$，其中 $T$ 是测试用例的数量，$v_t$ 是测试用例 $t$ 的违规计数。\n\n参数选择和要实现的测试套件：\n\n- 使用固定的显著性水平 $\\alpha = 0.01$，对应置信水平为 $1-\\alpha = 0.99$。任何地方都不要使用百分号；所有覆盖水平都以小数或分数表示。\n- 使用最小合并阈值 $m_{\\min} = 50$ 来决定索引 $k$ 是否符合检验资格。\n- 实现以下5个测试用例，每个用例由 $(r,p,n)$ 指定：\n  - 用例 1：$(r,p,n) = (5,\\,0.3,\\,200000)$。\n  - 用例 2：$(r,p,n) = (2.5,\\,0.7,\\,150000)$。\n  - 用例 3：$(r,p,n) = (0.7,\\,0.2,\\,300000)$。\n  - 用例 4：$(r,p,n) = (20,\\,0.5,\\,80000)$。\n  - 用例 5：$(r,p,n) = (1.3,\\,0.95,\\,120000)$。\n\n附加要求：\n\n- 实现该测试框架所需的所有数学推导必须仅从 PMF 定义和 Poisson-Gamma 混合恒等式开始。不要在没有推导的情况下假定或引用任何额外的目标恒等式。在代码中提供最终表达式，而不是在输出中。\n- 不涉及角度和物理单位。\n- 最终输出必须是如上所述的单行文本，没有额外内容。\n\n您的程序应生成一行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，例如 $[v_1,v_2,v_3,v_4,v_5]$。",
            "solution": "问题陈述已经过分析并被确定为有效。这是一个在计算统计学领域中定义明确、有科学依据的问题，提供了构建唯一且可验证解所需的所有必要定义、参数和程序。\n\n任务是构建一个基于蒙特卡洛的测试框架，以验证负二项分布的一个结构性质。这涉及几个步骤：推导理论量、从分布中模拟数据、对模拟数据进行统计分析，以及将经验结果与理论预测进行比较。\n\n问题的核心在于检验相邻计数的概率之间的关系。这种关系由比率 $R_k = f(k+1)/f(k)$ 捕获。测试方法依赖于将该比率的理论推导与从大量模拟样本中获得的经验估计值进行比较。\n\n首先，我们从已给出的负二项分布 $K \\sim \\mathrm{NB}(r, p)$ 的概率质量函数 (PMF) 出发，推导相邻计数比率 $R_k$ 的理论值：\n$$\nf(k) = \\mathbb{P}(K=k) = \\frac{\\Gamma(k+r)}{\\Gamma(r)\\,\\Gamma(k+1)}\\,p^{\\,r}\\,(1-p)^{\\,k}\n$$\n比率 $R_k$ 定义为：\n$$\nR_k = \\frac{f(k+1)}{f(k)} = \\frac{\\frac{\\Gamma(k+1+r)}{\\Gamma(r)\\,\\Gamma(k+2)}\\,p^{\\,r}\\,(1-p)^{\\,k+1}}{\\frac{\\Gamma(k+r)}{\\Gamma(r)\\,\\Gamma(k+1)}\\,p^{\\,r}\\,(1-p)^{\\,k}}\n$$\n通过消去公因子（$p^r$、$(1-p)^k$ 的一部分和 $\\Gamma(r)$）来简化表达式：\n$$\nR_k = \\frac{\\Gamma(k+r+1)}{\\Gamma(k+r)} \\cdot \\frac{\\Gamma(k+1)}{\\Gamma(k+2)} \\cdot \\frac{(1-p)^{k+1}}{(1-p)^k}\n$$\n利用伽马函数的基本性质 $\\Gamma(z+1)=z\\Gamma(z)$，我们可以简化伽马函数的比率：\n$$\n\\frac{\\Gamma(k+r+1)}{\\Gamma(k+r)} = k+r\n$$\n$$\n\\frac{\\Gamma(k+1)}{\\Gamma(k+2)} = \\frac{\\Gamma(k+1)}{(k+1)\\Gamma(k+1)} = \\frac{1}{k+1}\n$$\n将这些代回 $R_k$ 的表达式中，得到待检验的简单结构恒等式：\n$$\nR_k = (k+r) \\cdot \\left(\\frac{1}{k+1}\\right) \\cdot (1-p) = \\frac{k+r}{k+1}(1-p)\n$$\n这就是相邻概率之比的理论目标值。\n\n统计检验是基于从大小为 $n$ 的大样本中观测到的单元格计数 $N_k$ 构建的。对于任意一对相邻的单元格 $k$ 和 $k+1$，我们考虑总计数 $M_k = N_k + N_{k+1}$。在给定总数 $M_k$ 的条件下，单元格 $k+1$ 中的观测数 $N_{k+1}$ 服从二项分布：\n$$\nN_{k+1} \\mid M_k \\sim \\mathrm{Binomial}(M_k, q_k)\n$$\n其中 $q_k$ 是在观测值落入单元格 $k$ 或 $k+1$ 的条件下，其落入单元格 $k+1$ 的条件概率：\n$$\nq_k = \\frac{f(k+1)}{f(k) + f(k+1)}\n$$\n通过用 $f(k)$ 除以分子和分母，我们可以用 $R_k$ 来表示 $q_k$：\n$$\nq_k = \\frac{f(k+1)/f(k)}{1 + f(k+1)/f(k)} = \\frac{R_k}{1+R_k}\n$$\n$q_k$ 的自然估计量是经验比例 $\\hat{q}_k = N_{k+1}/M_k$。问题通过变换 $g(q) = q/(1-q)$ 定义了 $R_k$ 的估计量。很容易看出 $g(q_k) = R_k$。因此，我们对 $R_k$ 的经验估计量是 $\\hat{R}_k = g(\\hat{q}_k) = \\hat{q}_k/(1-\\hat{q}_k)$。\n\n为了构建 $R_k$ 的置信区间，我们应用 Delta 方法来求 $\\hat{R}_k$ 的近似方差。对于大量的试验次数 $M_k$，二项比例估计量 $\\hat{q}_k$ 的方差是 $\\mathrm{Var}(\\hat{q}_k) = q_k(1-q_k)/M_k$。Delta 方法将变换后估计量的方差近似为 $\\mathrm{Var}(\\hat{R}_k) \\approx [g'(q_k)]^2 \\mathrm{Var}(\\hat{q}_k)$。我们计算 $g(q)$ 的导数：\n$$\ng'(q) = \\frac{d}{dq}\\left(\\frac{q}{1-q}\\right) = \\frac{1(1-q) - q(-1)}{(1-q)^2} = \\frac{1}{(1-q)^2}\n$$\n将此代入方差近似式中：\n$$\n\\mathrm{Var}(\\hat{R}_k) \\approx \\left(\\frac{1}{(1-q_k)^2}\\right)^2 \\frac{q_k(1-q_k)}{M_k} = \\frac{q_k}{M_k(1-q_k)^3}\n$$\n标准误 (SE) 是该方差的平方根。根据规定，我们在此公式中使用理论值 $q_k$。\n$$\n\\mathrm{SE}(\\hat{R}_k) = \\sqrt{\\frac{q_k}{M_k(1-q_k)^3}}\n$$\n$R_k$ 的一个近似 $1-\\alpha$ 置信区间以经验估计值 $\\hat{R}_k$ 为中心，其半宽度由标准正态分位数 $z_{1-\\alpha/2}$ 决定：\n$$\n\\mathrm{CI}_k = \\left[ \\hat{R}_k - z_{1-\\alpha/2} \\mathrm{SE}(\\hat{R}_k), \\; \\hat{R}_k + z_{1-\\alpha/2} \\mathrm{SE}(\\hat{R}_k) \\right]\n$$\n如果理论比率 $R_k$ 落在此经验构建的置信区间之外，则对索引 $k$ 计为一次违规。这种情况发生在 $|\\hat{R}_k - R_k| > z_{1-\\alpha/2} \\mathrm{SE}(\\hat{R}_k)$ 时。\n\n对于每个测试用例 $(r, p, n)$，总体算法流程如下：\n1. 为确定性随机数生成器设置种子。\n2. 使用指定的 Poisson-Gamma 混合方法生成 $n$ 个来自 $\\mathrm{NB}(r,p)$ 的样本：对每个样本，从 $\\mathrm{Gamma}(r, (1-p)/p)$ 中抽取 $\\Lambda$，然后从 $\\mathrm{Poisson}(\\Lambda)$ 中抽取样本值。\n3. 将样本聚合到频率直方图中，生成计数 $N_k$。\n4. 一个循环从 0 迭代到观测到的最大值，遍历每个整数 $k$。\n5. 对每个 $k$，计算合并计数 $M_k = N_k + N_{k+1}$。\n6. 如果 $M_k \\ge m_{\\min}$ 且 $\\hat{q}_k = N_{k+1}/M_k < 1$，则该索引 $k$ 被视为符合检验资格。\n7. 对于每个合格的 $k$，计算理论量 $R_k$ 和 $q_k$，以及经验估计值 $\\hat{R}_k$。\n8. 使用理论值 $q_k$ 和观测值 $M_k$ 计算标准误 $\\mathrm{SE}(\\hat{R}_k)$。\n9. 检查违规条件：$|R_k - \\hat{R}_k| > z_{1-\\alpha/2} \\mathrm{SE}(\\hat{R}_k)$。如果为真，则记录一次违规。\n10. 对所有合格的 $k$ 的违规总数进行求和，并为该测试用例报告。如果没有合格的 $k$，则计数为 $0$。\n对所有指定的测试用例重复此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the Monte Carlo validation harness for all test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (r, p, n)\n        (5.0, 0.3, 200000),\n        (2.5, 0.7, 150000),\n        (0.7, 0.2, 300000),\n        (20.0, 0.5, 80000),\n        (1.3, 0.95, 120000),\n    ]\n\n    # Fixed parameters for the test harness\n    alpha = 0.01\n    m_min = 50\n    # Seed for reproducibility, as requested.\n    seed = 42\n    \n    # Pre-calculate the standard normal quantile\n    z_quantile = norm.ppf(1 - alpha / 2.0)\n    \n    # Initialize the random number generator\n    rng = np.random.default_rng(seed=seed)\n\n    results = []\n    \n    # Process each test case\n    for r, p, n in test_cases:\n        violation_count = run_test_case(r, p, n, m_min, z_quantile, rng)\n        results.append(violation_count)\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_test_case(r, p, n, m_min, z_quantile, rng):\n    \"\"\"\n    Runs the simulation and analysis for a single test case.\n    \n    Args:\n        r (float): Shape parameter of the Negative Binomial distribution.\n        p (float): Success probability parameter.\n        n (int): Sample size for the simulation.\n        m_min (int): Minimum pooled count for a cell pair to be eligible.\n        z_quantile (float): The z-score for the confidence interval.\n        rng (numpy.random.Generator): The random number generator instance.\n        \n    Returns:\n        int: The total count of violations for the test case.\n    \"\"\"\n    \n    # --- Step 1: Simulation Engine ---\n    # Generate samples using the Poisson-Gamma mixture representation\n    # Lambda ~ Gamma(shape=r, scale=(1-p)/p)\n    # X | Lambda ~ Poisson(Lambda)\n    if n == 0:\n        return 0\n        \n    gamma_scale = (1.0 - p) / p\n    lambda_samples = rng.gamma(shape=r, scale=gamma_scale, size=n)\n    nb_samples = rng.poisson(lam=lambda_samples, size=n)\n\n    # --- Step 2: Empirical Histogram ---\n    # Form the histogram counts Nk for k = 0, 1, 2, ...\n    if nb_samples.size == 0:\n        max_k_obs = -1\n    else:\n        max_k_obs = np.max(nb_samples)\n    \n    # We need counts up to max_k_obs + 1 for the loop\n    hist_counts = np.bincount(nb_samples, minlength=max_k_obs + 2)\n    \n    violations = 0\n    \n    # Iterate through all possible k values where Nk and N_{k+1} can be non-zero\n    for k in range(max_k_obs + 1):\n        N_k = hist_counts[k]\n        N_k_plus_1 = hist_counts[k + 1]\n        \n        M_k = N_k + N_k_plus_1\n        \n        # --- Step 3: Check Eligibility ---\n        if M_k < m_min:\n            continue\n            \n        # --- Step 4: Empirical and Theoretical Calculations ---\n        # Empirical two-cell conditional proportion\n        hat_q_k = N_k_plus_1 / M_k\n        \n        # According to the problem, the estimator for Rk is only defined for hat_q_k < 1.\n        if hat_q_k >= 1.0:\n            continue\n            \n        # Empirical adjacent ratio\n        hat_R_k = hat_q_k / (1.0 - hat_q_k)\n        \n        # Theoretical adjacent ratio R_k = (k+r)/(k+1) * (1-p)\n        R_k = (k + r) / (k + 1.0) * (1.0 - p)\n        \n        # Theoretical two-cell conditional proportion q_k = R_k / (1 + R_k)\n        q_k = R_k / (1.0 + R_k)\n\n        # --- Step 5: Confidence Interval and Violation Check ---\n        # The standard error of hat_R_k uses the theoretical q_k as specified.\n        # SE(hat_R_k) = sqrt( q_k / (M_k * (1-q_k)^3) )\n        if q_k == 0.0 or q_k >= 1.0:\n            # This case is theoretically unlikely but guards against numerical issues.\n            continue\n        \n        var_hat_R_k_numerator = q_k\n        var_hat_R_k_denominator = M_k * ((1.0 - q_k)**3)\n        \n        if var_hat_R_k_denominator <= 0:\n            continue\n            \n        std_err_hat_R_k = np.sqrt(var_hat_R_k_numerator / var_hat_R_k_denominator)\n        \n        # CI half-width\n        half_width = z_quantile * std_err_hat_R_k\n        \n        # Check if the theoretical R_k is outside the CI\n        if np.abs(hat_R_k - R_k) > half_width:\n            violations += 1\n            \n    return violations\n\nif __name__ == '__main__':\n    solve()\n\n```"
        },
        {
            "introduction": "从具有长尾的分布中生成随机变量会带来重大的数值挑战，例如下溢和上溢。这项高级实践通过实现在对数域中完全运行的内存高效逆变换采样器，正面解决了这些问题。您不仅将构建一个数值稳健的生成器，还将分析并界定累积浮点误差，这是开发高保真科学软件的一项关键技能 。",
            "id": "3323013",
            "problem": "设计并实现一个受限内存的负二项分布随机变量生成器，该生成器使用在对数域中即时计算的概率质量函数比率，并对累积浮点误差提供一个有理论依据的界。设参数为 $r>0$ 和 $p \\in (0,1)$ 的负二项分布表示一个非负整数值随机变量 $K \\in \\{0,1,2,\\dots\\}$ 的分布，其概率质量函数为\n$$\n\\mathbb{P}(K=k) \\;=\\; \\binom{k+r-1}{k} (1-p)^k p^r \\;=\\; \\frac{\\Gamma(k+r)}{\\Gamma(r)\\,\\Gamma(k+1)} (1-p)^k p^r,\n$$\n其中 $\\Gamma(\\cdot)$ 是 Gamma 函数。其累积分布函数满足\n$$\nF(k) \\;=\\; \\mathbb{P}(K \\le k) \\;=\\; \\sum_{j=0}^k \\mathbb{P}(K=j) \\;=\\; I_{p}(r, k+1),\n$$\n其中 $I_x(a,b)$ 是正则化不完全 Beta 函数。\n\n您的生成器必须：\n- 通过逆变换采样法从 $NB(r,p)$ 中采样，使用基于递推关系即时计算的概率质量函数累积和，该递推仅基于先前计算的值和参数 $(r,p)$。\n- 在对数域中维护所有运行时量，以避免下溢/上溢，使用形式为 $s_{k+1}=\\log\\left(\\exp(s_k)+\\exp(\\ell_{k+1})\\right)$ 的双参数 $\\log\\text{sum}\\exp$ 更新，其中 $\\ell_{k}$ 表示在 $k$ 处的概率质量函数的对数。\n- 每个生成的变量仅使用 $\\mathcal{O}(1)$ 的额外内存；例如，不要预计算或存储概率或累积概率的数组。\n- 使用 Gamma 函数对数（即 $\\log \\Gamma(\\cdot)$）的向量化评估，以验证您的即时递推与 $\\log \\mathbb{P}(K=k)$ 的封闭形式在一系列 $k$ 值上是否一致。\n\n浮点误差模型和界的要求：\n- 假设标准浮点运算的单位舍入误差为 $\\varepsilon_{\\mathrm{mach}}$，其模型为 $\\mathrm{fl}(x \\circ y) = (x \\circ y)(1+\\delta)$，其中对于每个基本算术运算 $\\circ \\in \\{+,-,\\times,\\div\\}$，$|\\delta| \\le \\varepsilon_{\\mathrm{mach}}$。并将 $\\exp(\\cdot)$、$\\log(\\cdot)$ 和 $\\log \\Gamma(\\cdot)$ 的评估视为产生同阶的乘性相对误差。您必须推导出一个可计算的、显式的界 $B(m)$，用于约束经过 $m$ 次双参数 $\\log\\text{sum}\\exp$ 更新后计算得到的对数累积和 $s_m$ 的绝对误差，形式如下\n$$\n\\big| s_m^{\\mathrm{comp}} - \\log F(k_m) \\big| \\;\\le\\; B(m),\n$$\n其中 $k_m$ 是当前索引，$s_m^{\\mathrm{comp}}$ 是经过 $m$ 次更新后计算出的对数累积和。您的界必须用 $m$ 和 $\\varepsilon_{\\mathrm{mach}}$ 表示，且不得依赖未知的内部常数；您可以选择一个通过运算计数证明其合理性的保守通用常数乘数。\n\n程序要求：\n- 实现一个 $NB(r,p)$ 的逆变换生成器，该生成器遵守内存限制，并使用即时计算的对数概率质量函数比率；从给定的概率质量函数定义中自行推导该比率，不预存任何表格。\n- 实现一个数值稳定的双参数 $\\log\\text{sum}\\exp$ 更新，用于在对数域中进行累积和计算。\n- 提供一个函数，该函数对于给定的参数集 $(r,p)$ 和一组预定的均匀随机数 $(u_i)$，对每个 $u_i$ 运行生成器直到停止索引 $k$，并为每个 $u_i$ 返回计算出的对数累积和 $s$、通过正则化不完全 Beta 函数评估的精确 $\\log F(k)$、$\\log\\text{sum}\\exp$ 更新的次数 $m$，以及不等式 $\\big| s - \\log F(k) \\big| \\le B(m)$ 是否成立。\n- 在连续范围 $k=0,1,\\dots,K^\\star$ 上，提供一个向量化检查，用于比较即时递推生成的 $\\log \\mathbb{P}(K=k)$ 与通过 $\\log \\Gamma(\\cdot)$ 计算的封闭形式 $\\log \\mathbb{P}(K=k)$，并验证最大绝对偏差受一个形式为 $C^\\star \\cdot (K^\\star+1)\\cdot \\varepsilon_{\\mathrm{mach}}$ 的保守表达式的限制，其中 $C^\\star$ 是您必须指定的显式常数。\n\n统计验证：\n- 对于一个大小为 $n$ 的独立同分布生成样本，使用单遍、数值稳定的算法（例如 Welford 方法）计算样本均值和样本方差，该算法使用 $\\mathcal{O}(1)$ 的内存。将样本均值与理论均值 $\\mathbb{E}[K] = r\\frac{1-p}{p}$ 进行比较。将样本均值的标准误视为 $\\sqrt{\\mathrm{Var}(K)/n}$，其中 $\\mathrm{Var}(K) = r\\frac{1-p}{p^2}$。报告样本均值与理论均值的绝对偏差是否至多为 4 个标准误。\n\n测试套件和输出规范：\n- 使用以下参数集和种子。所有随机数必须从固定的种子生成，以确保可复现性。\n    - 测试 1：$r=2.5$, $p=0.3$, $n=10000$, 种子 $1729$。除了统计验证外，还需对均匀网格 $\\{u=0.1,\\,0.5,\\,0.9\\}$ 进行数值验证，并在 $k=0,1,\\dots,K^\\star$ 上进行向量化的 $\\log \\Gamma$ 验证，其中 $K^\\star$ 是这三个 $u$ 值中遇到的最大停止索引。\n    - 测试 2：$r=10.0$, $p=0.05$, $n=5000$, 种子 $314159$。\n    - 测试 3：$r=0.7$, $p=0.95$, $n=20000$, 种子 $271828$。\n    - 测试 4：仅对 $(r,p)=(50.0,0.2)$ 和均匀网格 $\\{u=0.01,\\,0.5,\\,0.99\\}$ 进行数值验证。\n- 对每个测试，生成以下输出：\n    - 测试 1：一个列表 $[\\hat{\\mu}, \\hat{\\sigma}^2, \\mathrm{mean\\_ok}, \\mathrm{cdf\\_bound\\_ok}, \\mathrm{logpmf\\_bound\\_ok}]$，其中 $\\hat{\\mu}$ 是样本均值（浮点数），$\\hat{\\sigma}^2$ 是样本方差（浮点数），$\\mathrm{mean\\_ok}$ 是一个布尔值，指示样本均值是否在理论均值的 4 个标准误范围内，$\\mathrm{cdf\\_bound\\_ok}$ 是一个布尔值，指示所有三个均匀输入是否都满足界 $\\big| s - \\log F(k) \\big| \\le B(m)$，$\\mathrm{logpmf\\_bound\\_ok}$ 是一个布尔值，指示向量化的 $\\log \\Gamma$ 检查是否在 $k=0,1,\\dots,K^\\star$ 上满足其界。\n    - 测试 2：一个列表 $[\\hat{\\mu}, \\hat{\\sigma}^2, \\mathrm{mean\\_ok}]$。\n    - 测试 3：一个列表 $[\\hat{\\mu}, \\hat{\\sigma}^2, \\mathrm{mean\\_ok}]$。\n    - 测试 4：一个列表 $[\\mathrm{cdf\\_bound\\_ok}, \\mathrm{logpmf\\_bound\\_ok}]$，其定义与测试 1 类似，但不含统计输出。\n- 最终输出格式：您的程序应生成单行输出，包含一个由逗号分隔的列表，该列表包含在方括号中的结果，其中每个元素是按测试 1 到测试 4 顺序排列的测试列表（例如，$[[\\cdots],[\\cdots],[\\cdots],[\\cdots]]$）。不应打印任何其他文本。\n\n约束和说明：\n- 所有角度（如果出现）必须以弧度为单位。此处不涉及物理单位。\n- 在生成器中，您必须使用标量状态和 $\\mathcal{O}(1)$ 的额外内存；仅允许在诊断验证步骤（如 $\\log \\Gamma$ 检查）中使用向量化。\n- 您的界 $B(m)$ 必须在您的解决方案中明确说明，并在您的代码中严格按照说明实现，所有常数都需明确指定。",
            "solution": "我们从参数为 $r>0$ 和 $p \\in (0,1)$ 的负二项分布的定义开始，其概率质量函数为\n$$\nf(k) \\;=\\; \\mathbb{P}(K=k) \\;=\\; \\frac{\\Gamma(k+r)}{\\Gamma(r)\\,\\Gamma(k+1)} (1-p)^k p^r,\\quad k\\in\\{0,1,2,\\dots\\}.\n$$\n其累积分布函数满足\n$$\nF(k) \\;=\\; \\sum_{j=0}^{k} f(j) \\;=\\; I_{p}(r,k+1),\n$$\n其中 $I_x(a,b)$ 是正则化不完全 Beta 函数。理论均值和方差是众所周知的，可从负二项分布的标准性质得出：\n$$\n\\mathbb{E}[K] \\;=\\; r\\frac{1-p}{p}, \\qquad \\mathrm{Var}(K) \\;=\\; r\\frac{1-p}{p^2}.\n$$\n\n受限内存的即时生成原理。我们将实现逆变换采样。抽取 $U\\sim \\mathrm{Uniform}(0,1)$ 并找到满足 $F(k)\\ge U$ 的最小 $k$。为了避免预先计算或存储数组，我们使用从概率质量函数导出的比率，从 $f(0)$ 开始逐个计算 $f(k)$。根据定义，该比率满足\n$$\n\\frac{f(k+1)}{f(k)} \\;=\\; \\frac{\\Gamma(k+1+r)}{\\Gamma(k+r)} \\cdot \\frac{\\Gamma(k+1)}{\\Gamma(k+2)} \\cdot (1-p) \\;=\\; \\frac{k+r}{k+1} \\,(1-p),\n$$\n其中我们使用了 $\\Gamma(x+1)=x\\,\\Gamma(x)$。这就得到了对数递推关系\n$$\n\\ell_{k} \\;=\\; \\log f(k),\\quad \\ell_{0} \\;=\\; r\\log p,\\qquad \\ell_{k+1} \\;=\\; \\ell_{k} + \\log(1-p) + \\log(k+r) - \\log(k+1).\n$$\n为了在累积和计算中保持在对数域，我们通过双参数的 $\\log\\text{sum}\\exp$ 更新来维护 $s_k = \\log\\left(\\sum_{j=0}^{k} \\exp(\\ell_j)\\right)$：\n$$\ns_{k+1} \\;=\\; \\log\\Big( \\exp(s_k) + \\exp(\\ell_{k+1}) \\Big) \\;=\\; m + \\log\\left(\\exp(s_k - m) + \\exp(\\ell_{k+1}-m)\\right),\n$$\n其中 $m=\\max\\{s_k,\\ell_{k+1}\\}$。我们在对数域中进行比较，注意到 $U \\le \\sum_{j=0}^{k} f(j)$ 等价于 $\\log U \\le s_k$。此算法对每个生成的变量仅使用一个标量 $\\ell_k$、一个标量 $s_k$ 和索引 $k$，因此满足 $\\mathcal{O}(1)$ 的内存限制。\n\n向量化的 $\\log \\Gamma$ 验证。对于任何有限范围 $k=0,1,\\dots,K^\\star$，我们可以计算封闭形式的对数概率\n$$\n\\ell_k^{\\mathrm{ref}} \\;=\\; \\log f(k) \\;=\\; \\log\\Gamma(k+r) - \\log\\Gamma(r) - \\log\\Gamma(k+1) + k\\log(1-p) + r\\log p.\n$$\n通过在 $k=0,1,\\dots,K^\\star$ 上向量化地评估 $\\log\\Gamma(\\cdot)$，我们可以验证基于递推的 $\\ell_k$ 序列与 $\\ell_k^{\\mathrm{ref}}$ 是否一致，并记录最大绝对偏差。\n\n浮点误差模型和累积界。采用标准浮点运算模型：\n$$\n\\mathrm{fl}(x \\circ y) \\;=\\; (x\\circ y)(1+\\delta), \\qquad |\\delta|\\le \\varepsilon_{\\mathrm{mach}},\n$$\n对于运算 $\\circ \\in \\{+,-,\\times,\\div\\}$。我们假设 $\\exp(\\cdot)$、$\\log(\\cdot)$ 和 $\\log\\Gamma(\\cdot)$ 的实现也会产生阶数为 $\\varepsilon_{\\mathrm{mach}}$ 的相对误差。考虑一次双参数的 $\\log\\text{sum}\\exp$ 更新：\n$$\ns' \\;=\\; \\log\\Big(\\exp(s) + \\exp(\\ell)\\Big) \\;=\\; m + \\log\\left(\\exp(s-m)+\\exp(\\ell-m)\\right),\\quad m=\\max\\{s,\\ell\\}.\n$$\n计算出的 $s'_{\\mathrm{comp}}$ 涉及一个有限的基本运算序列：一次 $\\max$，两次指数运算，一次加法，一次对数运算和一次加法。计算所有基本算术运算和基本函数（我们保守地将每个函数的相对误差建模为至多 $\\varepsilon_{\\mathrm{mach}}$），一阶误差传播（忽略 $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}^2)$ 项）得出，一次更新中的绝对误差受常数倍数 $\\gamma_0 \\varepsilon_{\\mathrm{mach}}$ 的限制，其中常数 $\\gamma_0$ 解释了运算链中的累积。类似地，对数概率 $\\ell$ 的一次更新使用三次评估（两次 $\\log$ 和一次加法），每步产生一个阶数为 $\\varepsilon_{\\mathrm{mach}}$ 乘以一个适中常数的有界绝对误差。经过 $m$ 步后，一个标准的前向误差累积论证意味着一个形如\n$$\n\\big| s_m^{\\mathrm{comp}} - \\log F(k_m) \\big| \\;\\le\\; \\gamma \\, m \\, \\varepsilon_{\\mathrm{mach}} + \\mathcal{O}(\\varepsilon_{\\mathrm{mach}}^2),\n$$\n的界，其中某个通用常数 $\\gamma$ 为每步贡献提供了上界。为明确和保守起见，且不依赖未知的实现细节，我们选择\n$$\nB(m) \\;=\\; \\big(128\\, m + 1\\big)\\,\\varepsilon_{\\mathrm{mach}},\n$$\n取 $\\gamma=128$ 并增加一个额外的单位舍入误差以覆盖初始化。这个 $B(m)$ 界定了经过 $m$ 次双参数 $\\log\\text{sum}\\exp$ 更新后计算出的对数累积和的绝对误差。将类似的论证应用于 $\\ell_k$ 的递推关系可得，在 $k=0,1,\\dots,K^\\star$ 范围内，递推生成的 $\\ell_k$ 与 $\\ell_k^{\\mathrm{ref}}$ 之间的最大绝对偏差受以下界限制\n$$\n\\max_{0\\le k\\le K^\\star} \\big|\\ell_k^{\\mathrm{comp}} - \\ell_k^{\\mathrm{ref}}\\big| \\;\\le\\; C^\\star \\,(K^\\star+1)\\,\\varepsilon_{\\mathrm{mach}},\n$$\n我们保守地设置 $C^\\star=64$。\n\n统计验证。对于大小为 $n$ 的样本，使用单遍算法（例如 Welford 方法）在 $\\mathcal{O}(1)$ 内存下计算样本均值 $\\hat{\\mu}$ 和样本方差 $\\hat{\\sigma}^2$，以保持数值稳定性。使用标准误 $\\sqrt{\\mathrm{Var}(K)/n}$（其中 $\\mathrm{Var}(K)=r(1-p)/p^2$）将 $\\hat{\\mu}$ 与理论均值 $\\mu = r(1-p)/p$ 进行比较。报告 $|\\hat{\\mu}-\\mu|\\le 4 \\sqrt{\\mathrm{Var}(K)/n}$ 是否成立。\n\n测试套件和确定性输出。使用指定的参数集和种子：\n- 测试 1：$(r,p,n,\\text{seed})=(2.5,\\,0.3,\\,10000,\\,1729)$ 和均匀网格 $\\{0.1,0.5,0.9\\}$。\n- 测试 2：$(r,p,n,\\text{seed})=(10.0,\\,0.05,\\,5000,\\,314159)$。\n- 测试 3：$(r,p,n,\\text{seed})=(0.7,\\,0.95,\\,20000,\\,271828)$。\n- 测试 4：$(r,p)=(50.0,\\,0.2)$ 和均匀网格 $\\{0.01,0.5,0.99\\}$。\n\n对于测试 1-3，使用上述受限内存的逆变换算法生成样本；对于测试 1 和 4，使用指定的 $B(m)$ 和 $C^\\star$ 进行数值验证。最终程序必须打印单行输出，格式为包含四个测试输出的列表：\n$$\n\\big[\\,[\\hat{\\mu}_1,\\hat{\\sigma}^2_1,\\mathrm{mean\\_ok}_1,\\mathrm{cdf\\_bound\\_ok}_1,\\mathrm{logpmf\\_bound\\_ok}_1],\\,[\\hat{\\mu}_2,\\hat{\\sigma}^2_2,\\mathrm{mean\\_ok}_2],\\,[\\hat{\\mu}_3,\\hat{\\sigma}^2_3,\\mathrm{mean\\_ok}_3],\\,[\\mathrm{cdf\\_bound\\_ok}_4,\\mathrm{logpmf\\_bound\\_ok}_4]\\,\\big].\n$$\n\n这个设计整合了负二项分布的核心定义，从第一性原理推导了即时对数比率递推关系，实现了数值稳定的 $\\log\\text{sum}\\exp$ 更新，并使用了基于标准浮点模型的、有理论依据的、显式的浮点误差累积界。",
            "answer": "```python\nimport math\nfrom typing import Tuple, List\nimport numpy as np\nfrom scipy.special import gammaln, betainc\n\n# Negative Binomial NB(r, p) where K counts failures before r successes with success prob p\n# pmf: P(K=k) = C(k+r-1, k) (1-p)^k p^r\n# mean = r*(1-p)/p, var = r*(1-p)/p^2\n\ndef logsumexp2(a: float, b: float) -> float:\n    \"\"\"Stable log(exp(a)+exp(b)) for two scalars.\"\"\"\n    if a == -math.inf:\n        return b\n    if b == -math.inf:\n        return a\n    m = a if a >= b else b\n    return m + math.log(math.exp(a - m) + math.exp(b - m))\n\ndef sample_nb_inverse_log(r: float, p: float, rng: np.random.Generator) -> Tuple[int, int]:\n    \"\"\"\n    Sample one NB(r,p) variate using inverse transform in the log domain.\n    Returns (k, m_updates) where m_updates is the number of logsumexp updates performed.\n    Memory footprint per sample is O(1).\n    \"\"\"\n    # Precompute logs\n    logp = math.log(p)\n    log1mp = math.log1p(-p)  # log(1-p)\n    # Initialize\n    l = r * logp  # log pmf at k=0\n    s = l         # log cumulative at k=0\n    m_updates = 1\n    u = rng.random()\n    logu = math.log(u)\n    if logu <= s:\n        return 0, m_updates\n    # Iterate k = 1,2,...\n    k = 0\n    while True:\n        # Update k -> k+1: l_{k+1} = l_k + log(1-p) + log(k+r) - log(k+1)\n        kp1 = k + 1.0\n        l += log1mp + math.log(k + r) - math.log(kp1)\n        # Update cumulative in log domain: s = logsumexp(s, l)\n        # Inline two-arg logsumexp to reduce overhead\n        m = s if s >= l else l\n        s = m + math.log(math.exp(s - m) + math.exp(l - m))\n        m_updates += 1\n        k += 1\n        if logu <= s:\n            return k, m_updates\n\ndef nb_logpmf_closed_form_vec(r: float, p: float, kmax: int) -> np.ndarray:\n    \"\"\"Vectorized closed-form log pmf using gammaln for k=0..kmax.\"\"\"\n    ks = np.arange(kmax + 1, dtype=np.float64)\n    return gammaln(ks + r) - gammaln(r) - gammaln(ks + 1.0) + ks * math.log1p(-p) + r * math.log(p)\n\ndef nb_logpmf_recurrence_seq(r: float, p: float, kmax: int) -> np.ndarray:\n    \"\"\"Generate log pmf sequence 0..kmax using recurrence in double precision.\"\"\"\n    logp = math.log(p)\n    log1mp = math.log1p(-p)\n    out = np.empty(kmax + 1, dtype=np.float64)\n    l = r * logp\n    out[0] = l\n    for k in range(kmax):\n        l = l + log1mp + math.log(k + r) - math.log(k + 1.0)\n        out[k + 1] = l\n    return out\n\ndef cdf_log_exact_via_betainc(r: float, p: float, k: int) -> float:\n    \"\"\"Compute log CDF = log P(K <= k) using regularized incomplete Beta.\"\"\"\n    # CDF F(k) = I_p(r, k+1)\n    F = betainc(r, k + 1.0, p)\n    # Ensure it's in (0,1]; due to numerical issues, clip safely\n    F = min(max(F, np.finfo(float).tiny), 1.0)\n    return math.log(F)\n\ndef bound_logcdf_error(m_updates: int, eps: float) -> float:\n    \"\"\"Conservative absolute error bound for log-cumulative after m two-arg logsumexp updates.\"\"\"\n    # B(m) = (128*m + 1) * eps\n    return (128.0 * m_updates + 1.0) * eps\n\ndef bound_logpmf_seq_error(klen: int, eps: float) -> float:\n    \"\"\"Conservative bound for max abs discrepancy in log pmf sequence of length klen.\"\"\"\n    # C* (K+1) * eps with C=64; here klen = K+1\n    return 64.0 * klen * eps\n\ndef welford_mean_variance_nb(r: float, p: float, n: int, seed: int) -> Tuple[float, float]:\n    \"\"\"Generate n samples and compute mean and variance via Welford, using O(1) memory.\"\"\"\n    rng = np.random.default_rng(seed)\n    mean = 0.0\n    M2 = 0.0\n    for i in range(1, n + 1):\n        k, _ = sample_nb_inverse_log(r, p, rng)\n        x = float(k)\n        delta = x - mean\n        mean += delta / i\n        M2 += delta * (x - mean)\n    var = M2 / (n - 1) if n > 1 else 0.0\n    return mean, var\n\ndef numerical_validation(r: float, p: float, u_values: List[float]) -> Tuple[bool, bool]:\n    \"\"\"\n    For given (r,p) and list of uniform values, run the generator until stopping index k(u)\n    and check:\n      - |s - log F(k)| <= B(m) for all u (cdf_bound_ok)\n      - max_k |l_recur - l_ref| <= 64*(K*+1)*eps over k=0..K*, where K* is max stopping index (logpmf_bound_ok)\n    \"\"\"\n    eps = np.finfo(float).eps\n    # To force specific U values, wrap a RNG that returns given u's in order\n    # But we can emulate by looping the inversion logic with supplied u (without RNG)\n    cdf_bound_ok = True\n    Kmax = 0\n    # For collecting L sequences up to K per u to set Kmax\n    ks_for_check = []\n    for u in u_values:\n        # Reproduce the inversion steps deterministically for given u\n        logp = math.log(p)\n        log1mp = math.log1p(-p)\n        l = r * logp\n        s = l\n        m_updates = 1\n        logu = math.log(u)\n        k = 0\n        if not (logu <= s):\n            while True:\n                l = l + log1mp + math.log(k + r) - math.log(k + 1.0)\n                # logsumexp\n                m = s if s >= l else l\n                s = m + math.log(math.exp(s - m) + math.exp(l - m))\n                m_updates += 1\n                k += 1\n                if logu <= s:\n                    break\n        # Compare against exact log CDF\n        logF = cdf_log_exact_via_betainc(r, p, k)\n        err = abs(s - logF)\n        if err > bound_logcdf_error(m_updates, eps):\n            cdf_bound_ok = False\n        Kmax = max(Kmax, k)\n        ks_for_check.append(k)\n    # Vectorized log-pmf validation over 0..Kmax\n    l_ref = nb_logpmf_closed_form_vec(r, p, Kmax)\n    l_rec = nb_logpmf_recurrence_seq(r, p, Kmax)\n    max_abs_diff = float(np.max(np.abs(l_ref - l_rec)))\n    logpmf_bound_ok = (max_abs_diff <= bound_logpmf_seq_error(Kmax + 1, eps))\n    return cdf_bound_ok, logpmf_bound_ok\n\ndef test_case_1():\n    r, p, n, seed = 2.5, 0.3, 10000, 1729\n    mu = r * (1.0 - p) / p\n    var = r * (1.0 - p) / (p * p)\n    mean_hat, var_hat = welford_mean_variance_nb(r, p, n, seed)\n    se = math.sqrt(var / n)\n    mean_ok = abs(mean_hat - mu) <= 4.0 * se\n    # numerical validation\n    cdf_ok, lpmf_ok = numerical_validation(r, p, [0.1, 0.5, 0.9])\n    return [mean_hat, var_hat, bool(mean_ok), bool(cdf_ok), bool(lpmf_ok)]\n\ndef test_case_2():\n    r, p, n, seed = 10.0, 0.05, 5000, 314159\n    mu = r * (1.0 - p) / p\n    var = r * (1.0 - p) / (p * p)\n    mean_hat, var_hat = welford_mean_variance_nb(r, p, n, seed)\n    se = math.sqrt(var / n)\n    mean_ok = abs(mean_hat - mu) <= 4.0 * se\n    return [mean_hat, var_hat, bool(mean_ok)]\n\ndef test_case_3():\n    r, p, n, seed = 0.7, 0.95, 20000, 271828\n    mu = r * (1.0 - p) / p\n    var = r * (1.0 - p) / (p * p)\n    mean_hat, var_hat = welford_mean_variance_nb(r, p, n, seed)\n    se = math.sqrt(var / n)\n    mean_ok = abs(mean_hat - mu) <= 4.0 * se\n    return [mean_hat, var_hat, bool(mean_ok)]\n\ndef test_case_4():\n    r, p = 50.0, 0.2\n    cdf_ok, lpmf_ok = numerical_validation(r, p, [0.01, 0.5, 0.99])\n    return [bool(cdf_ok), bool(lpmf_ok)]\n\ndef solve():\n    results = []\n    results.append(test_case_1())\n    results.append(test_case_2())\n    results.append(test_case_3())\n    results.append(test_case_4())\n    # Print as a single line with exact required format\n    # Ensure Python default string of list is acceptable\n    print(str(results))\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}