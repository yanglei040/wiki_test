{
    "hands_on_practices": [
        {
            "introduction": "贝塔分布的生成是许多统计模拟应用的基础。一种常见且优雅的方法是利用两个伽马分布随机变量的比值。然而，当贝塔分布的形状参数 $\\alpha$ 或 $\\beta$ 变得极大或极小时，直接实现该方法会遇到数值不稳定的挑战，例如浮点数上溢或下溢。本练习  将指导你通过对数-和-指数（log-sum-exp）技巧来实现一个数值稳健的贝塔变量生成器，这是编写高质量科学计算代码的一项关键技能。",
            "id": "3292073",
            "problem": "要求您设计、分析并实现一个鲁棒的贝塔分布（Beta distribution）随机变量生成器，该生成器基于独立的伽马（Gamma）变量之比。目标是为一个分布为 $X \\sim \\mathrm{Beta}(\\alpha,\\beta)$ 的随机变量 $X$ 构建一个生成器，该生成器通过变换 $X = \\dfrac{G_\\alpha}{G_\\alpha + G_\\beta}$ 由两个独立的伽马变量 $G_\\alpha \\sim \\Gamma(\\alpha,1)$ 和 $G_\\beta \\sim \\Gamma(\\beta,1)$ 构建而成。实现必须在极端形状参数（特别是当 $\\alpha$ 或 $\\beta$ 非常大或非常小时）下保持数值稳定。您的程序必须使用 log-sum-exp 恒等式实现 $X$ 的稳定计算，以避免灾难性抵消：\n$$\n\\log\\left(e^{u} + e^{v}\\right) = \\mathrm{LSE}(u,v) \\equiv \\max(u,v) + \\log\\!\\left( 1 + e^{-|u-v|} \\right),\n$$\n这样，当 $u = \\log G_\\alpha$ 和 $v = \\log G_\\beta$ 时，该比率可以计算为\n$$\nX = \\exp\\!\\left( \\log G_\\alpha - \\mathrm{LSE}(\\log G_\\alpha, \\log G_\\beta) \\right).\n$$\n\n从伽马分布（使用形状-尺度参数化）和贝塔分布的基本定义开始。假设 $G_\\alpha$ 和 $G_\\beta$ 是独立的，并记住必须将数值稳定性视为首要设计约束。您必须从第一性原理出发，论证伽马变量比值构造的正确性以及 log-sum-exp 技术的稳定性。\n\n您的程序必须：\n- 实现一个函数，对于给定的实数形状参数 $\\alpha0$、$\\beta0$ 和整数样本量 $n \\ge 1$，该函数使用比值 $X=\\dfrac{G_\\alpha}{G_\\alpha+G_\\beta}$（其中 $G_\\alpha \\sim \\Gamma(\\alpha,1)$，$G_\\beta \\sim \\Gamma(\\beta,1)$）返回 $n$ 个来自 $\\mathrm{Beta}(\\alpha,\\beta)$ 分布的独立样本，并通过上述的 log-sum-exp 恒等式计算该比值。\n- 使用固定的伪随机数生成器种子以确保可复现性。\n- 为进行验证，根据贝塔分布的已知解析性质计算蒙特卡洛诊断指标。具体来说，如果 $\\mu=\\dfrac{\\alpha}{\\alpha+\\beta}$ 和 $\\sigma^2=\\dfrac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}$ 分别表示精确的均值和方差，则样本均值 $\\bar{X}_n$ 的蒙特卡洛标准误为 $\\mathrm{SE}=\\sqrt{\\sigma^2/n}$。对于选定的测试用例，如果对于指定的常数 $c$，满足 $|\\bar{X}_n-\\mu| \\le c \\cdot \\mathrm{SE}$，则判定为通过。\n\n测试套件和要求的输出：\n- 使用以下五个测试用例，每个用例由 $(\\alpha,\\beta,n,c)$ 指定：\n  - 用例 A（正常路径）：$(\\alpha,\\beta,n,c)=(2.5,5.0,100000,5)$。\n  - 用例 B（两个形状参数均小于1）：$(\\alpha,\\beta,n,c)=(0.3,0.7,200000,5)$。\n  - 用例 C（非常大且均衡的形状参数）：$(\\alpha,\\beta,n,c)=(10^6,10^6,20000,10)$。\n  - 用例 D（高度不均衡的形状参数）：$(\\alpha,\\beta,n,c)=(10^{-6},10^{6},200000,6)$。\n  - 用例 E（内部的分位数精度）：$(\\alpha,\\beta,n)=(15.2,9.7,150000)$。对于此用例，评估在概率 $\\tau \\in \\{0.1,0.5,0.9\\}$ 处的经验分位数与 $\\mathrm{Beta}(\\alpha,\\beta)$ 的理论分位数 $q_\\tau$ 的符合程度。使用样本分位数 $\\hat{q}_\\tau$ 的渐近方差公式，\n    $$\n    \\mathrm{Var}(\\hat{q}_\\tau) \\approx \\frac{\\tau(1-\\tau)}{n\\,f(q_\\tau)^2},\n    $$\n    其中 $f$ 是 $\\mathrm{Beta}(\\alpha,\\beta)$ 的概率密度函数，如果满足\n    $$\n    \\max_{\\tau \\in \\{0.1,0.5,0.9\\}} \\left|\\hat{q}_\\tau - q_\\tau\\right| \\le 4 \\cdot \\sqrt{\\frac{\\tau(1-\\tau)}{n\\,f(q_\\tau)^2}}.\n    $$\n    则判定为通过。对于此用例，报告一个布尔值，指示所有三个分位数是否同时满足界限。\n- 您的程序必须生成单行输出，其中包含用例 A–E 的结果，格式为方括号括起来的逗号分隔列表，例如 $[\\text{True},\\text{False},\\text{True},\\text{True},\\text{True}]$。\n\n所有数值答案必须是无量纲实数。不涉及角度。不要将任何答案表示为百分比；如果出现任何比例，它必须是 $[0,1]$ 范围内的实数。\n\n科学真实性与覆盖范围：\n- 伽马分布和贝塔分布必须严格按照概率论中的定义使用，其中伽马变量的形状参数 $\\alpha,\\beta0$，尺度参数为1。\n- 在计算 $X$ 时必须明确使用通过 log-sum-exp 恒等式实现的数值稳定化方法，以防止当 $\\alpha$ 或 $\\beta$ 为极端值时发生下溢或上溢。\n- 测试套件覆盖了典型、小形状参数、大形状参数、不均衡形状参数以及分位数精度等场景。",
            "solution": "从贝塔分布生成随机变量是随机模拟中的一项基本任务。所提出的问题要求设计并实现一个基于独立伽马变量之比的 $X \\sim \\mathrm{Beta}(\\alpha,\\beta)$ 生成器，并对数值稳定性有严格要求，尤其是在形状参数 $\\alpha$ 和 $\\beta$ 取极端值时。\n\n**1. 理论基础：伽马变量比值法**\n\n该方法的基础是概率论中一个已确立的、连接贝塔分布和伽马分布的定理。\n\n首先，我们定义相关的分布。一个随机变量 $Y$ 如果服从形状参数为 $k0$ 且单位尺度参数为（$\\theta=1$）的伽马分布，记作 $Y \\sim \\Gamma(k,1)$，其概率密度函数（PDF）由下式给出：\n$$f_Y(y; k, 1) = \\frac{1}{\\Gamma(k)} y^{k-1} e^{-y} \\quad \\text{for } y  0$$\n其中 $\\Gamma(k) = \\int_0^\\infty t^{k-1} e^{-t} dt$ 是伽马函数。\n\n一个随机变量 $X$ 如果服从形状参数为 $\\alpha0$ 和 $\\beta0$ 的贝塔分布，记作 $X \\sim \\mathrm{Beta}(\\alpha, \\beta)$，其概率密度函数为：\n$$f_X(x; \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha-1} (1-x)^{\\beta-1} \\quad \\text{for } x \\in (0, 1)$$\n其中 $B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$ 是贝塔函数。\n\n该定理指出，如果 $G_\\alpha \\sim \\Gamma(\\alpha, 1)$ 和 $G_\\beta \\sim \\Gamma(\\beta, 1)$ 是两个独立的随机变量，那么由比值\n$$X = \\frac{G_\\alpha}{G_\\alpha + G_\\beta}$$\n定义的变量 $X$ 服从 $\\mathrm{Beta}(\\alpha, \\beta)$ 分布。\n\n我们可以通过变量替换来证明这个结果。设独立变量 $(G_\\alpha, G_\\beta)$ 的联合概率密度函数为：\n$$f(g_\\alpha, g_\\beta) = f_{G_\\alpha}(g_\\alpha) f_{G_\\beta}(g_\\beta) = \\left(\\frac{1}{\\Gamma(\\alpha)} g_\\alpha^{\\alpha-1} e^{-g_\\alpha}\\right) \\left(\\frac{1}{\\Gamma(\\beta)} g_\\beta^{\\beta-1} e^{-g_\\beta}\\right)$$\n对于 $g_\\alpha, g_\\beta  0$。我们引入变换：\n$$X = \\frac{G_\\alpha}{G_\\alpha + G_\\beta} \\quad \\text{and} \\quad Y = G_\\alpha + G_\\beta$$\n逆变换为 $G_\\alpha = XY$ 和 $G_\\beta = Y(1-X)$。定义域 $(g_\\alpha, g_\\beta) \\in (0, \\infty) \\times (0, \\infty)$ 映射到 $(x, y) \\in (0, 1) \\times (0, \\infty)$。这个逆变换的雅可比行列式是：\n$$J = \\det \\begin{pmatrix} \\frac{\\partial g_\\alpha}{\\partial x}  \\frac{\\partial g_\\alpha}{\\partial y} \\\\ \\frac{\\partial g_\\beta}{\\partial x}  \\frac{\\partial g_\\beta}{\\partial y} \\end{pmatrix} = \\det \\begin{pmatrix} y  x \\\\ -y  1-x \\end{pmatrix} = y(1-x) - (-y)x = y$$\n$(X, Y)$ 的联合概率密度函数为 $f_{X,Y}(x, y) = f(xy, y(1-x))|J|$：\n$$f_{X,Y}(x, y) = \\frac{1}{\\Gamma(\\alpha)\\Gamma(\\beta)} (xy)^{\\alpha-1} e^{-xy} (y(1-x))^{\\beta-1} e^{-y(1-x)} y$$\n$$f_{X,Y}(x, y) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{\\Gamma(\\alpha)\\Gamma(\\beta)} y^{\\alpha-1} y^{\\beta-1} y \\, e^{-xy - y(1-x)}$$\n$$f_{X,Y}(x, y) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{\\Gamma(\\alpha)\\Gamma(\\beta)} y^{\\alpha+\\beta-1} e^{-y}$$\n为了找到 $X$ 的边缘概率密度函数，我们对 $Y$ 的所有可能值进行积分：\n$$f_X(x) = \\int_0^\\infty f_{X,Y}(x, y) dy = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\int_0^\\infty y^{\\alpha+\\beta-1} e^{-y} dy$$\n该积分是 $\\Gamma(\\alpha+\\beta)$ 的定义。因此：\n$$f_X(x) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1}(1-x)^{\\beta-1} = \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha-1}(1-x)^{\\beta-1}$$\n这正是 $\\mathrm{Beta}(\\alpha, \\beta)$ 分布的概率密度函数，从而验证了该方法。\n\n**2. 数值稳定性与 Log-Sum-Exp 技术**\n\n当形状参数为极端值时，直接计算比值 $X = G_\\alpha / (G_\\alpha + G_\\beta)$ 在数值上是不稳定的。\n- 如果 $\\alpha$ 和 $\\beta$ 非常大（例如，$10^6$），伽马变量 $G_\\alpha$ 和 $G_\\beta$ 可能会非常大，因为 $\\mathbb{E}[\\Gamma(k,1)] = k$。它们的和 $G_\\alpha + G_\\beta$ 可能会超出标准浮点表示的范围而导致上溢。\n- 如果 $\\alpha$ 非常小而 $\\beta$ 非常大（例如，$\\alpha=10^{-6}, \\beta=10^6$），那么 $G_\\alpha$ 将极度接近零，并可能下溢为 $0.0$。这会导致错误地得到 $X=0$。类似地，如果 $\\alpha$ 大而 $\\beta$ 小，$G_\\beta$ 可能会下溢，导致 $X=1$。\n\n为规避这些问题，我们在对数域中进行计算。设 $u = \\log G_\\alpha$ 和 $v = \\log G_\\beta$。那么 $X$ 可以写为：\n$$X = \\frac{e^u}{e^u + e^v}$$\n对 $X$ 取对数：\n$$\\log X = \\log(e^u) - \\log(e^u + e^v) = u - \\log(e^u + e^v)$$\n项 $\\log(e^u + e^v)$，被称为 log-sum-exp (LSE) 函数，在 $u$ 或 $v$ 很大时仍可能导致上溢。我们使用以下稳定恒等式进行计算：\n$$\\mathrm{LSE}(u, v) = \\log(e^u + e^v) = \\max(u, v) + \\log(1 + e^{-|u - v|})$$\n这种形式是稳定的，因为指数的参数 $-|u-v|$ 总为非正数，从而防止了上溢。$e^{-|u-v|}$ 的值总在 $[0, 1]$ 范围内，因此它与 $1$ 的和以及后续的对数运算都是良态的。\n\n因此，计算 $X$ 的稳定算法是：\n$$X = \\exp\\left( \\log G_\\alpha - \\mathrm{LSE}(\\log G_\\alpha, \\log G_\\beta) \\right)$$\n\n**3. 算法实现步骤**\n\n要从 $\\mathrm{Beta}(\\alpha, \\beta)$ 生成一个包含 $n$ 个样本的向量：\n1. 从 $\\Gamma(\\alpha, 1)$ 生成一个包含 $n$ 个样本的向量 $\\mathbf{g}_\\alpha$。\n2. 从 $\\Gamma(\\beta, 1)$ 生成一个包含 $n$ 个样本的向量 $\\mathbf{g}_\\beta$。\n3. 逐元素计算自然对数：$\\mathbf{u} = \\log \\mathbf{g}_\\alpha$ 和 $\\mathbf{v} = \\log \\mathbf{g}_\\beta$。\n4. 逐元素计算最大值：$\\mathbf{m} = \\max(\\mathbf{u}, \\mathbf{v})$。\n5. 计算 LSE 项：$\\mathbf{lse} = \\mathbf{m} + \\log(1 + \\exp(-|\\mathbf{u} - \\mathbf{v}|))$。\n6. 计算最终样本：$\\mathbf{x} = \\exp(\\mathbf{u} - \\mathbf{lse})$。向量 $\\mathbf{x}$ 包含所需的贝塔变量。\n\n**4. 验证方法**\n\n生成的样本将根据贝塔分布的已知理论性质进行验证。\n\n**均值验证（用例 A-D）：** 中心极限定理指出，对于大样本量 $n$，样本均值 $\\bar{X}_n$ 近似服从正态分布，其均值为 $\\mu$，方差为 $\\sigma^2/n$，其中 $\\mu$ 和 $\\sigma^2$ 是分布的真实均值和方差。\n- 真实均值：$\\mu = \\frac{\\alpha}{\\alpha+\\beta}$\n- 真实方差：$\\sigma^2 = \\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}$\n样本均值的蒙特卡洛标准误是 $\\mathrm{SE} = \\sqrt{\\sigma^2/n}$。如果样本均值在真实均值的 $c$ 个标准误范围内：$|\\bar{X}_n - \\mu| \\le c \\cdot \\mathrm{SE}$，我们判定为通过。\n\n**分位数验证（用例 E）：** 为了更严格地测试分布的形状，我们比较经验分位数与理论分位数。顺序统计量的渐近理论为概率水平 $\\tau$ 处的样本分位数 $\\hat{q}_\\tau$ 提供了近似方差：\n$$\\mathrm{Var}(\\hat{q}_\\tau) \\approx \\frac{\\tau(1-\\tau)}{n f(q_\\tau)^2}$$\n其中 $q_\\tau$ 是真实分位数，而 $f$ 是分布的概率密度函数。如果在一组分位数上的最大绝对偏差被 $4$ 倍的渐近标准误所界定，我们判定为通过：\n$$\\max_{\\tau \\in \\{0.1, 0.5, 0.9\\}} |\\hat{q}_\\tau - q_\\tau| \\le 4 \\cdot \\sqrt{\\frac{\\tau(1-\\tau)}{n f(q_\\tau)^2}}$$\n这个全面的验证框架确保了所实现的生成器不仅数值稳定，而且在统计上也是准确的。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the Beta variate generator.\n    \"\"\"\n    \n    # Use a fixed seed for the pseudorandom number generator for reproducibility.\n    SEED = 42\n    RNG = np.random.default_rng(SEED)\n\n    def generate_beta_stable(alpha, beta, n, rng_instance):\n        \"\"\"\n        Generates n samples from Beta(alpha, beta) using the stable\n        ratio-of-gammas method with the log-sum-exp trick.\n\n        Args:\n            alpha (float): Shape parameter  0.\n            beta (float): Shape parameter  0.\n            n (int): Number of samples to generate = 1.\n            rng_instance (numpy.random.Generator): A numpy random generator instance.\n\n        Returns:\n            numpy.ndarray: An array of n samples from the Beta distribution.\n        \"\"\"\n        # Generate n samples from two independent Gamma distributions.\n        # Scale parameter is 1 by default in numpy.random.gamma.\n        g_alpha = rng_instance.gamma(alpha, size=n)\n        g_beta = rng_instance.gamma(beta, size=n)\n\n        # Compute in the log domain to prevent overflow/underflow.\n        log_g_alpha = np.log(g_alpha)\n        log_g_beta = np.log(g_beta)\n\n        # Compute log(g_alpha + g_beta) robustly using log-sum-exp.\n        u = log_g_alpha\n        v = log_g_beta\n        m = np.maximum(u, v)\n        # LSE(u,v) = log(e^u + e^v)\n        log_sum_exp = m + np.log(1 + np.exp(-np.abs(u - v)))\n\n        # Compute log(X) = log(g_alpha / (g_alpha + g_beta))\n        # log(X) = log(g_alpha) - log(g_alpha + g_beta)\n        log_x = log_g_alpha - log_sum_exp\n        \n        # Exponentiate to get the final samples.\n        x = np.exp(log_x)\n        \n        return x\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (happy path)\n        {'type': 'mean', 'params': (2.5, 5.0, 100000, 5)},\n        # Case B (both shapes less than one)\n        {'type': 'mean', 'params': (0.3, 0.7, 200000, 5)},\n        # Case C (very large, balanced shapes)\n        {'type': 'mean', 'params': (10**6, 10**6, 20000, 10)},\n        # Case D (highly imbalanced shapes)\n        {'type': 'mean', 'params': (10**-6, 10**6, 200000, 6)},\n        # Case E (quantile accuracy)\n        {'type': 'quantile', 'params': (15.2, 9.7, 150000, 4)},\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'mean':\n            alpha, beta, n, c = case['params']\n            \n            samples = generate_beta_stable(alpha, beta, n, RNG)\n            \n            sample_mean = np.mean(samples)\n            \n            # Theoretical properties\n            # Using np.longdouble for precision with extreme parameters\n            a_ld, b_ld = np.longdouble(alpha), np.longdouble(beta)\n            \n            mu = a_ld / (a_ld + b_ld)\n            \n            # Handle potential overflow in (alpha+beta+1) for large alpha/beta\n            if (a_ld + b_ld + 1) == np.inf:\n                 var = 0.0\n            else:\n                 var = (a_ld * b_ld) / ((a_ld + b_ld)**2 * (a_ld + b_ld + 1))\n            \n            se = np.sqrt(var / n)\n            \n            # Check pass condition\n            passed = np.abs(sample_mean - mu) = c * se\n            results.append(bool(passed))\n\n        elif case['type'] == 'quantile':\n            alpha, beta, n, c_q = case['params']\n            \n            samples = generate_beta_stable(alpha, beta, n, RNG)\n\n            taus = np.array([0.1, 0.5, 0.9])\n            \n            # Empirical quantiles\n            q_hats = np.quantile(samples, taus)\n            \n            # Theoretical properties\n            q_s = stats.beta.ppf(taus, a=alpha, b=beta)\n            f_q_s = stats.beta.pdf(q_s, a=alpha, b=beta)\n            \n            # Asymptotic standard error of the sample quantile\n            asymptotic_var = (taus * (1 - taus)) / (n * f_q_s**2)\n            bound = c_q * np.sqrt(asymptotic_var)\n\n            # Check if all quantiles pass the test simultaneously.\n            passed = np.all(np.abs(q_hats - q_s) = bound)\n            results.append(bool(passed))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "实现一个随机数生成器后，验证其输出是否精确符合目标分布是至关重要的一步。一种强大的验证方法是矩检验，即比较生成样本的统计矩（如均值和方差）与理论值是否一致。本练习  要求你构建一个全面的压力测试程序，不仅要验证样本均值和方差，还要深入到样本方差本身的方差，从而对生成器的统计算法进行严格的检验。",
            "id": "3292115",
            "problem": "构建一个完整的、可运行的程序，通过验证经验均值和方差是否符合从第一性原理推导出的理论值，在一系列参数对网格上对贝塔分布（Beta）变异生成器进行压力测试。该程序必须是自包含的，并且仅使用标准的数值库。您的实现必须遵循以下要求。\n\n1. 基本原理和生成器规范：\n   - 使用以下定义：如果 $X \\sim \\mathrm{Gamma}(\\alpha,1)$ 和 $Y \\sim \\mathrm{Gamma}(\\beta,1)$ 是独立的，那么 $T = \\dfrac{X}{X+Y}$ 服从 $\\mathrm{Beta}(\\alpha,\\beta)$ 分布。这里 $\\mathrm{Gamma}(\\alpha,1)$ 表示形状参数为 $\\alpha$、尺度参数为单位1的伽马（Gamma）分布。\n   - 通过将 $X$ 和 $Y$ 作为形状参数分别为 $\\alpha$ 和 $\\beta$ 的独立伽马分布变异量进行采样，并逐元素计算 $T = \\dfrac{X}{X+Y}$，来实现一个贝塔分布变异生成器。\n   - 不要调用任何内置的贝塔分布随机变异生成器。\n\n2. 基于核心定义的理论目标：\n   - 从贝塔概率密度和贝塔函数 $B(\\alpha,\\beta)$ 出发，推导并使用原始矩恒等式\n     $$\\mathbb{E}[X^k] = \\prod_{j=0}^{k-1} \\frac{\\alpha + j}{\\alpha+\\beta + j}, \\quad k \\in \\{1,2,3,4\\},$$\n     来计算理论均值 $\\mu = \\mathbb{E}[X]$、理论方差 $\\sigma^2 = \\mathbb{E}[X^2] - \\mu^2$ 以及四阶中心矩\n     $$\\mu_4 = \\mathbb{E}[(X-\\mu)^4] = \\mathbb{E}[X^4] - 4 \\mu \\mathbb{E}[X^3] + 6 \\mu^2 \\mathbb{E}[X^2] - 3 \\mu^4.$$\n   - 对于来自大小为 $n$ 的独立同分布样本的无偏样本方差 $s^2$，使用其方差的通用恒等式\n     $$\\mathrm{Var}(s^2) = \\frac{1}{n}\\left(\\mu_4 - \\frac{n-3}{n-1}\\sigma^4\\right),$$\n     其中 $s^2$ 使用分母 $n-1$。\n\n3. 统计验证标准：\n   - 对于每对参数 $(\\alpha,\\beta)$，生成 $n$ 个独立的 $\\mathrm{Beta}(\\alpha,\\beta)$ 样本，计算样本均值 $\\hat{\\mu}$ 和无偏样本方差 $s^2$（使用分母 $n-1$）。\n   - 定义标准化差异\n     $$Z_{\\mathrm{mean}} = \\frac{|\\hat{\\mu} - \\mu|}{\\sqrt{\\sigma^2/n}}, \\qquad Z_{\\mathrm{var}} = \\frac{|s^2 - \\sigma^2|}{\\sqrt{\\mathrm{Var}(s^2)}},$$\n     其中 $\\mu$、$\\sigma^2$ 和 $\\mathrm{Var}(s^2)$ 如上所定义。\n   - 使用中心极限定理（CLT）和大样本近似，如果 $Z_{\\mathrm{mean}} \\leq \\tau$ 和 $Z_{\\mathrm{var}} \\leq \\tau$ 同时成立，则宣布一个测试用例通过，其中阈值 $\\tau$ 在所有用例中固定不变。使用 $\\tau = 4.5$。\n\n4. 测试套件和覆盖范围：\n   - 对每个用例使用相同的样本量 $n = 50000$。\n   - 使用以下 $(\\alpha,\\beta)$ 对的网格来探测平衡、不平衡、小形状参数和大形状参数的各种情况：\n     - $(\\alpha,\\beta) \\in \\{(0.1,0.1),(0.1,5.0),(5.0,0.1),(0.5,0.5),(1.0,1.0),(2.0,5.0),(5.0,2.0),(50.0,50.0),(100.0,1.0),(1.0,100.0)\\}$。\n   - 为确保可复现性，为随机数生成器固定一个确定性种子。\n\n5. 程序输入和输出：\n   - 程序必须是完全自包含的，且不要求任何用户输入。\n   - 最终输出必须是单行，包含一个由方括号括起来的、用逗号分隔的布尔值列表。每个布尔值按上述顺序对应一个测试用例，并且当且仅当该用例的两个标准化标准都通过时才为真。例如，像下面这样的输出\n     $$[\\mathrm{True},\\mathrm{False},\\dots]$$\n     表明了哪些 $(\\alpha,\\beta)$ 对通过或失败。\n\n不涉及物理单位或角度单位。所有数值必须以定点小数形式表示。最终程序必须在标准环境中按原样运行，并且只能使用指定的库。答案必须仅为代码，并按指定格式精确地产生一行输出。",
            "solution": "该问题要求构建一个贝塔（Beta）随机变异生成器并对其进行统计验证。生成器的实现基于一个基本原理，即两个独立的伽马（Gamma）分布随机变量之比服从贝塔分布。验证过程包括将为各种参数集生成的大样本的经验均值和方差与其精确的理论值进行比较。\n\n对于每对参数 $(\\alpha, \\beta)$，该过程涉及几个步骤：推导理论矩，生成样本，计算经验统计量，以及基于标准化差异的统计检验。\n\n首先，我们为验证建立理论基础。如果一个随机变量 $T$ 的概率密度函数由下式给出，则称其服从形状参数为 $\\alpha  0$ 和 $\\beta  0$ 的贝塔分布，记为 $T \\sim \\mathrm{Beta}(\\alpha, \\beta)$\n$$f(t; \\alpha, \\beta) = \\frac{t^{\\alpha-1}(1-t)^{\\beta-1}}{B(\\alpha, \\beta)}, \\quad t \\in [0, 1]$$\n其中 $B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$ 是贝塔函数。\n\n生成器将基于以下性质构建：如果 $X \\sim \\mathrm{Gamma}(\\alpha, 1)$ 和 $Y \\sim \\mathrm{Gamma}(\\beta, 1)$ 是独立的随机变量，那么它们的比值 $T = \\frac{X}{X+Y}$ 服从 $\\mathrm{Beta}(\\alpha, \\beta)$ 分布。\n\n为了进行验证，我们需要 $\\mathrm{Beta}(\\alpha, \\beta)$ 分布的前四阶原始矩。第 $k$ 阶原始矩 $\\mathbb{E}[T^k]$ 由下式给出：\n$$\\mathbb{E}[T^k] = \\int_0^1 t^k f(t; \\alpha, \\beta) dt = \\frac{1}{B(\\alpha, \\beta)} \\int_0^1 t^{\\alpha+k-1} (1-t)^{\\beta-1} dt = \\frac{B(\\alpha+k, \\beta)}{B(\\alpha, \\beta)}$$\n使用恒等式 $B(a, b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}$ 和性质 $\\Gamma(z+1)=z\\Gamma(z)$，我们可以将其表示为一个乘积：\n$$\\mathbb{E}[T^k] = \\frac{\\Gamma(\\alpha+k)\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\alpha+\\beta+k)} = \\frac{\\alpha(\\alpha+1)\\dots(\\alpha+k-1)}{(\\alpha+\\beta)(\\alpha+\\beta+1)\\dots(\\alpha+\\beta+k-1)} = \\prod_{j=0}^{k-1} \\frac{\\alpha + j}{\\alpha+\\beta + j}$$\n这种乘积形式在计算上很方便，因为它避免了直接计算伽马函数。\n\n使用这个恒等式对 $k \\in \\{1, 2, 3, 4\\}$，我们计算必要的理论量：\n1. 理论均值 $\\mu$：\n$$\\mu = \\mathbb{E}[T^1] = \\frac{\\alpha}{\\alpha+\\beta}$$\n2. 理论方差 $\\sigma^2$：\n$$\\sigma^2 = \\mathbb{E}[T^2] - \\mu^2, \\quad \\text{其中} \\quad \\mathbb{E}[T^2] = \\frac{\\alpha(\\alpha+1)}{(\\alpha+\\beta)(\\alpha+\\beta+1)}$$\n3. 四阶中心矩 $\\mu_4$：\n$$\\mu_4 = \\mathbb{E}[(T-\\mu)^4] = \\mathbb{E}[T^4] - 4\\mu\\mathbb{E}[T^3] + 6\\mu^2\\mathbb{E}[T^2] - 3\\mu^4$$\n其中 $\\mathbb{E}[T^3]$ 和 $\\mathbb{E}[T^4]$ 从乘积公式计算得出。\n4. 无偏样本方差 $s^2$ 的方差。对于一个大小为 $n$ 的独立同分布（i.i.d.）样本， $s^2 = \\frac{1}{n-1}\\sum_{i=1}^n(T_i - \\hat{\\mu})^2$ 的方差由下式给出：\n$$\\mathrm{Var}(s^2) = \\frac{1}{n}\\left(\\mu_4 - \\frac{n-3}{n-1}\\sigma^4\\right)$$\n\n对于给定的 $(\\alpha, \\beta)$ 对，验证过程如下：\n1. 生成一个大小为 $n = 50000$ 的样本。这通过首先从 $\\mathrm{Gamma}(\\alpha, 1)$ 分布中抽取 $n$ 个样本形成向量 $X$，并从 $\\mathrm{Gamma}(\\beta, 1)$ 分布中抽取 $n$ 个样本形成向量 $Y$ 来完成。然后逐元素计算贝塔变异量 $T = X / (X+Y)$。\n2. 从这个样本中，计算样本均值 $\\hat{\\mu}$ 和无偏样本方差 $s^2$（分母为 $n-1$）。\n3. 中心极限定理表明，对于大的 $n$，样本均值 $\\hat{\\mu}$ 近似服从均值为 $\\mu$、方差为 $\\sigma^2/n$ 的正态分布。类似地，样本方差 $s^2$ 近似服从均值为 $\\sigma^2$、方差为 $\\mathrm{Var}(s^2)$ 的正态分布。我们使用这些结果来定义两个标准化差异：\n$$Z_{\\mathrm{mean}} = \\frac{|\\hat{\\mu} - \\mu|}{\\sqrt{\\sigma^2/n}}, \\qquad Z_{\\mathrm{var}} = \\frac{|s^2 - \\sigma^2|}{\\sqrt{\\mathrm{Var}(s^2)}}$$\n4. 如果两个差异都低于指定的阈值 $\\tau = 4.5$，则宣布一个测试用例通过。这个阈值对应一个非常严格的置信水平，因为一个标准正态变量的绝对值超过 $4.5$ 的概率极小 ($P(|Z|  4.5) \\approx 6.8 \\times 10^{-6}$)。\n\n实现将包含一个主循环，该循环遍历指定的 $(\\alpha, \\beta)$ 对网格。对于每一对参数，它将计算理论矩，生成随机样本，计算经验统计量，并评估通过/失败标准。为随机数生成器设置一个固定的种子可以确保测试结果的可复现性。最终输出将是一个布尔值列表，每个值对应一个测试用例，表明其是否通过了验证。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and stress-tests a Beta variate generator.\n\n    The generator is based on the ratio of two Gamma variates. Its output\n    is validated by comparing the empirical mean and variance of large samples\n    against their theoretical values derived from first principles.\n    The test is performed across a grid of shape parameter pairs (alpha, beta).\n    \"\"\"\n\n    # 4. Test suite and coverage:\n    # Use a common sample size n = 50000 for every case.\n    N_SAMPLES = 50000\n    # Use the following grid of (α,β) pairs.\n    TEST_CASES = [\n        (0.1, 0.1), (0.1, 5.0), (5.0, 0.1), (0.5, 0.5), (1.0, 1.0),\n        (2.0, 5.0), (5.0, 2.0), (50.0, 50.0), (100.0, 1.0), (1.0, 100.0)\n    ]\n    # To ensure reproducibility, fix a deterministic seed.\n    RNG_SEED = 12345\n    # Use threshold τ = 4.5.\n    TAU = 4.5\n\n    rng = np.random.default_rng(RNG_SEED)\n    results = []\n\n    def _compute_theoretical_moments(alpha, beta, n):\n        \"\"\"\n        Computes theoretical moments for the Beta(alpha, beta) distribution.\n        \n        Args:\n            alpha (float): The alpha shape parameter.\n            beta (float): The beta shape parameter.\n            n (int): The sample size.\n\n        Returns:\n            A tuple containing:\n            - mu (float): Theoretical mean.\n            - sigma_sq (float): Theoretical variance.\n            - var_s_sq (float): Theoretical variance of the sample variance.\n        \"\"\"\n        # 2. Theoretical targets from core definitions:\n        # Use the raw moment identity.\n        e1 = (alpha) / (alpha + beta)\n        e2 = e1 * (alpha + 1) / (alpha + beta + 1)\n        e3 = e2 * (alpha + 2) / (alpha + beta + 2)\n        e4 = e3 * (alpha + 3) / (alpha + beta + 3)\n\n        mu = e1\n        sigma_sq = e2 - mu**2\n\n        # 2 ... and the fourth central moment\n        mu4 = e4 - 4 * mu * e3 + 6 * mu**2 * e2 - 3 * mu**4\n        \n        # 2 ... use the general identity for the variance of the unbiased sample variance s^2\n        if n > 1:\n            var_s_sq = (1 / n) * (mu4 - ((n - 3) / (n - 1)) * sigma_sq**2)\n        else:\n            var_s_sq = np.nan # Undefined for n=1\n            \n        return mu, sigma_sq, var_s_sq\n\n    def _generate_beta_samples(alpha, beta, n, generator):\n        \"\"\"\n        Generates beta variates using the Gamma ratio method.\n\n        Args:\n            alpha (float): The alpha shape parameter.\n            beta (float): The beta shape parameter.\n            n (int): The number of samples to generate.\n            generator (np.random.Generator): The random number generator instance.\n\n        Returns:\n            np.ndarray: An array of n beta variates.\n        \"\"\"\n        # 1. Fundamental base and generator specification:\n        # Use the definition that if X ~ Gamma(α,1) and Y ~ Gamma(β,1) are\n        # independent, then T = X/(X+Y) has a Beta(α,β) distribution.\n        x_samples = generator.gamma(shape=alpha, scale=1.0, size=n)\n        y_samples = generator.gamma(shape=beta, scale=1.0, size=n)\n        \n        # Avoid division by zero if both samples are zero, though highly unlikely.\n        denominator = x_samples + y_samples\n        # Set to a very small positive number where denominator is zero\n        denominator[denominator == 0] = 1e-300\n        \n        return x_samples / denominator\n\n    for alpha, beta in TEST_CASES:\n        # Compute theoretical targets\n        mu, sigma_sq, var_s_sq = _compute_theoretical_moments(alpha, beta, N_SAMPLES)\n        \n        # Generate samples\n        samples = _generate_beta_samples(alpha, beta, N_SAMPLES, rng)\n        \n        # Compute empirical statistics\n        mu_hat = np.mean(samples)\n        s_sq = np.var(samples, ddof=1) # Unbiased sample variance with n-1\n\n        # 3. Statistical verification criteria:\n        # Define the standardized discrepancies\n        std_err_mean = np.sqrt(sigma_sq / N_SAMPLES)\n        std_err_var = np.sqrt(var_s_sq)\n        \n        z_mean = np.abs(mu_hat - mu) / std_err_mean if std_err_mean > 0 else 0.0\n        z_var = np.abs(s_sq - sigma_sq) / std_err_var if std_err_var > 0 else 0.0\n\n        # Declare a test case as passing if both criteria are met\n        passed = (z_mean = TAU) and (z_var = TAU)\n        results.append(passed)\n\n    # 5. Program input and output:\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在蒙特卡洛方法中，除了算法的正确性，其计算效率也同样重要，尤其是在大規模模拟中。与其完全依赖经验性的基准测试，我们可以构建解析性能模型来预测和比较不同算法的效率。本练习  将引导你基于概率论第一性原理，为几种不同的贝塔变量生成算法建立性能模型，通过分析各算法的接受概率和基本运算开销来预测其预期的CPU周期成本。",
            "id": "3292114",
            "problem": "你的任务是构建一个有原则的性能模型，通过结合算法操作计数、接受率和基本操作的特定硬件成本，来生成 Beta 随机变量。目标是预测在不同硬件和接受机制下，多个算法族为每个 Beta 变量所需的预期中央处理器 (CPU) 周期。该模型必须基于概率和期望的第一性原理，而非启发式方法。\n\n从以下基本原理开始：\n- 考虑一个通过一系列独立试验来生成样本的算法，其中每次试验成功的概率为 $p \\in (0,1]$。首次成功所需的试验次数是一个服从几何分布的随机变量。预期的试验次数等于成功概率的倒数。\n- 一个过程的预期总成本等于其构成成本之和的期望值，并且在独立性和每次试验成本固定的条件下，等于预期的试验次数乘以每次试验的成本。\n- 当一个算法由独立的子过程组成时，根据期望的线性性，其预期的总成本是各组成部分预期成本的总和。\n\n你将围绕三类 Beta 变量生成算法构建一个计算模型：\n1.  一种基于拒绝的幂变换方法，使用均匀分布和幂函数基本操作，涉及对数和指数求值（记为算法 J）。\n2.  一种基于正态分布的接受方法，每次试验使用一个正态提议、一个对数和一个均匀分布（记为算法 C）。\n3.  一种 Gamma 比例方法，使用两个通过基于正态分布的接受方法生成的独立 Gamma 随机变量（记为算法 G）。Beta 变量由这两个 Gamma 变量的比例得到，除了用于获得这两个 Gamma 变量的操作外，不需要额外的基本操作。\n\n对于每种算法，一次试验使用固定数量的基本操作。除了每次试验所列举的基本操作外，没有额外的接受后基本操作成本。基本操作及其特定硬件成本（以周期为单位）如下：\n- 均匀随机抽取：硬件成本 $C_{\\mathrm{u}}$ 周期。\n- 正态随机抽取：硬件成本 $C_{\\mathrm{n}}$ 周期。\n- 自然对数：硬件成本 $C_{\\log}$ 周期。\n- 指数：硬件成本 $C_{\\exp}$ 周期。\n\n算法的每次试验基本操作计数如下：\n- 算法 J：每次试验需要 2 次均匀分布、2 次对数、2 次指数、0 次正态分布。每次试验的接受概率为 $p_{\\mathrm{J}}$。\n- 算法 C：每次试验需要 1 次正态分布、1 次对数、1 次均匀分布、0 次指数。每次试验的接受概率为 $p_{\\mathrm{C}}$。\n- 算法 G：生成两个独立的 Gamma 变量。每个 Gamma 变量的每次试验需要 1 次正态分布、1 次对数、1 次均匀分布、0 次指数，其接受概率 $p_{\\mathrm{G}}(\\cdot)$ 取决于该 Gamma 变量中使用的形状参数。设 $p_{\\mathrm{G}}(a)$ 和 $p_{\\mathrm{G}}(b)$ 分别表示两个 Gamma 变量的接受概率。Beta 变量由这两个 Gamma 样本的比例形成，该比例计算不产生额外的基本操作。\n\n你的任务是编写一个程序，在给定每个算法及其子组件的硬件基本成本和接受概率的情况下，计算每种算法生成一个 Beta 变量所需的预期 CPU 周期，并为每个测试用例返回三种算法中的最小预期周期。所有输出必须以周期为单位表示。\n\n使用以下测试套件。每个测试用例提供硬件成本 $\\{C_{\\mathrm{u}}, C_{\\mathrm{n}}, C_{\\log}, C_{\\exp}\\}$、Beta 形状参数 $(a,b)$ 以及接受概率 $\\{p_{\\mathrm{J}}, p_{\\mathrm{C}}, p_{\\mathrm{G}}(a), p_{\\mathrm{G}}(b)\\}$：\n\n- 测试用例 1（通用顺利路径）：$C_{\\mathrm{u}}=40$, $C_{\\mathrm{n}}=200$, $C_{\\log}=80$, $C_{\\exp}=90$, $(a,b)=(2.0,5.0)$, $p_{\\mathrm{J}}=0.35$, $p_{\\mathrm{C}}=0.80$, $p_{\\mathrm{G}}(a)=0.95$, $p_{\\mathrm{G}}(b)=0.90$。\n- 测试用例 2（接近于 1 的接受率）：$C_{\\mathrm{u}}=40$, $C_{\\mathrm{n}}=200$, $C_{\\log}=80$, $C_{\\exp}=90$, $(a,b)=(1.5,3.0)$, $p_{\\mathrm{J}}=0.95$, $p_{\\mathrm{C}}=0.99$, $p_{\\mathrm{G}}(a)=0.99$, $p_{\\mathrm{G}}(b)=0.99$。\n- 测试用例 3（昂贵的超越函数硬件，某方法中极低的接受率）：$C_{\\mathrm{u}}=40$, $C_{\\mathrm{n}}=150$, $C_{\\log}=500$, $C_{\\exp}=700$, $(a,b)=(0.5,0.5)$, $p_{\\mathrm{J}}=0.02$, $p_{\\mathrm{C}}=0.50$, $p_{\\mathrm{G}}(a)=0.60$, $p_{\\mathrm{G}}(b)=0.60$。\n- 测试用例 4（昂贵的正态分布硬件）：$C_{\\mathrm{u}}=40$, $C_{\\mathrm{n}}=1000$, $C_{\\log}=80$, $C_{\\exp}=90$, $(a,b)=(3.0,3.0)$, $p_{\\mathrm{J}}=0.40$, $p_{\\mathrm{C}}=0.60$, $p_{\\mathrm{G}}(a)=0.85$, $p_{\\mathrm{G}}(b)=0.85$。\n\n你的程序必须：\n- 对于每个测试用例，仅使用提供的操作计数、接受概率和基本成本，计算算法 J、C 和 G 生成每个 Beta 变量的预期 CPU 周期。\n- 对于算法 J，基于成功概率为 $p_{\\mathrm{J}}$ 的重复独立试验计算预期周期。\n- 对于算法 C，基于成功概率为 $p_{\\mathrm{C}}$ 的重复独立试验计算预期周期。\n- 对于算法 G，将预期周期计算为生成两个接受概率分别为 $p_{\\mathrm{G}}(a)$ 和 $p_{\\mathrm{G}}(b)$ 的 Gamma 变量的预期周期之和。\n\n最终输出格式：\n你的程序应生成一行输出，其中包含每个测试用例三种算法中的最小预期 CPU 周期，按顺序排列，形式为逗号分隔的列表，并用方括号括起来，例如 $[x_{1},x_{2},x_{3},x_{4}]$。所有值都必须是以周期为单位的浮点数。不应打印单位，只打印数值。\n\n确保科学真实性和内部一致性。不要执行任何随机模拟；使用所述的有原则的模型进行计算。程序必须是自包含的，不需要用户输入或外部文件。",
            "solution": "该问题陈述经评估具有科学依据、定义明确、客观且自包含。它提出了一个基于概率论和算法分析基本原理的标准性能建模任务。所有必要数据均已提供，任务是基于一个明确定义的模型计算期望值。因此，我将继续进行解答。\n\n这个问题的核心依赖于两个概率论的基本原理：几何分布过程的期望试验次数和总成本期望的线性性。\n\n设一个随机过程由一系列独立的伯努利试验组成，每次试验成功的概率为 $p \\in (0,1]$。令 $N$ 为实现首次成功所需试验次数的随机变量。$N$ 服从在 $\\{1, 2, 3, \\ldots\\}$ 上的几何分布，其概率质量函数为 $P(N=k) = (1-p)^{k-1}p$。$N$ 的期望值由下式给出：\n$$\nE[N] = \\frac{1}{p}\n$$\n这代表了任何基于拒绝的算法所需的预期试验次数。\n\n如果每次试验产生固定的成本，例如 $C_{\\text{trial}}$，那么该过程的总成本是随机变量 $C_{\\text{total}} = N \\times C_{\\text{trial}}$。根据期望的性质，预期的总成本为：\n$$\nE[C_{\\text{total}}] = E[N \\times C_{\\text{trial}}] = C_{\\text{trial}} \\times E[N] = \\frac{C_{\\text{trial}}}{p}\n$$\n此外，如果一个算法的总成本是来自独立子过程的成本之和，期望的线性性表明，预期的总成本是这些子过程预期成本的总和。\n\n我们现在将应用这些原理来推导三种指定算法中每一种的预期 CPU 周期成本。设基本操作的硬件成本分别表示为 $C_{\\mathrm{u}}$ (均匀分布), $C_{\\mathrm{n}}$ (正态分布), $C_{\\log}$ (对数) 和 $C_{\\exp}$ (指数)。\n\n**1. 算法 J（基于拒绝的幂变换方法）**\n\n该算法执行独立试验，直到有一次被接受。\n每次试验使用的基本操作指定为 2 次均匀分布、2 次对数和 2 次指数。\n每次试验的成本 $C_{\\text{trial,J}}$ 是这些基本操作成本的总和：\n$$\nC_{\\text{trial,J}} = 2 C_{\\mathrm{u}} + 2 C_{\\log} + 2 C_{\\exp}\n$$\n单次试验成功（接受）的概率给定为 $p_{\\mathrm{J}}$。\n应用预期总成本公式，每个生成的 Beta 变量的预期 CPU 周期数 $E_{\\mathrm{J}}$ 为：\n$$\nE_{\\mathrm{J}} = \\frac{C_{\\text{trial,J}}}{p_{\\mathrm{J}}} = \\frac{2 C_{\\mathrm{u}} + 2 C_{\\log} + 2 C_{\\exp}}{p_{\\mathrm{J}}}\n$$\n\n**2. 算法 C（基于正态分布的接受方法）**\n\n该算法也执行独立试验直到接受。\n每次试验使用的基本操作是 1 次正态分布、1 次对数和 1 次均匀分布。\n每次试验的成本 $C_{\\text{trial,C}}$ 是：\n$$\nC_{\\text{trial,C}} = C_{\\mathrm{n}} + C_{\\log} + C_{\\mathrm{u}}\n$$\n每次试验的接受概率给定为 $p_{\\mathrm{C}}$。\n每个生成的 Beta 变量的预期 CPU 周期数 $E_{\\mathrm{C}}$ 为：\n$$\nE_{\\mathrm{C}} = \\frac{C_{\\text{trial,C}}}{p_{\\mathrm{C}}} = \\frac{C_{\\mathrm{n}} + C_{\\log} + C_{\\mathrm{u}}}{p_{\\mathrm{C}}}\n$$\n\n**3. 算法 G（Gamma 比例方法）**\n\n该算法通过首先生成两个独立的 Gamma 变量，然后取它们的比值来生成一个 Beta 变量。问题陈述指出，总预期成本是生成两个 Gamma 变量的预期成本之和，这是期望线性性的直接应用。\n\n设这两个 Gamma 变量对应于 Beta 形状参数 $a$ 和 $b$。让它们各自的生成过程为 $G_a$ 和 $G_b$。\n总预期成本为 $E_{\\mathrm{G}} = E[G_a] + E[G_b]$。\n\n对于每个 Gamma 变量，生成方法是一种基于正态分布的接受方法。生成一个 Gamma 变量每次试验的基本操作是 1 次正态分布、1 次对数和 1 次均匀分布。\n因此，生成单个 Gamma 变量的每次试验成本 $C_{\\text{trial,G}}$ 是：\n$$\nC_{\\text{trial,G}} = C_{\\mathrm{n}} + C_{\\log} + C_{\\mathrm{u}}\n$$\n注意，这与 $C_{\\text{trial,C}}$ 相同。\n\n对于第一个 Gamma 变量（与参数 $a$ 相关），接受概率给定为 $p_{\\mathrm{G}}(a)$。预期成本 $E[G_a]$ 是：\n$$\nE[G_a] = \\frac{C_{\\text{trial,G}}}{p_{\\mathrm{G}}(a)} = \\frac{C_{\\mathrm{n}} + C_{\\log} + C_{\\mathrm{u}}}{p_{\\mathrm{G}}(a)}\n$$\n对于第二个 Gamma 变量（与参数 $b$ 相关），接受概率给定为 $p_{\\mathrm{G}}(b)$。预期成本 $E[G_b]$ 是：\n$$\nE[G_b] = \\frac{C_{\\text{trial,G}}}{p_{\\mathrm{G}}(b)} = \\frac{C_{\\mathrm{n}} + C_{\\log} + C_{\\mathrm{u}}}{p_{\\mathrm{G}}(b)}\n$$\n算法 G 的总预期成本是这两个成本的总和：\n$$\nE_{\\mathrm{G}} = E[G_a] + E[G_b] = \\frac{C_{\\mathrm{n}} + C_{\\log} + C_{\\mathrm{u}}}{p_{\\mathrm{G}}(a)} + \\frac{C_{\\mathrm{n}} + C_{\\log} + C_{\\mathrm{u}}}{p_{\\mathrm{G}}(b)}\n$$\n这可以因式分解为：\n$$\nE_{\\mathrm{G}} = (C_{\\mathrm{n}} + C_{\\log} + C_{\\mathrm{u}}) \\left( \\frac{1}{p_{\\mathrm{G}}(a)} + \\frac{1}{p_{\\mathrm{G}}(b)} \\right)\n$$\n\n最后的任务是使用提供的参数为每个测试用例计算 $E_{\\mathrm{J}}$、$E_{\\mathrm{C}}$ 和 $E_{\\mathrm{G}}$，并确定最小值 $\\min(E_{\\mathrm{J}}, E_{\\mathrm{C}}, E_{\\mathrm{G}})$。这将通过编程实现。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the minimum expected CPU cycles for generating a Beta variate\n    across three different algorithmic families based on a provided performance model.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a dictionary containing hardware costs and acceptance probabilities.\n    test_cases = [\n        {\n            \"costs\": {\"Cu\": 40, \"Cn\": 200, \"Clog\": 80, \"Cexp\": 90},\n            \"params\": {\"a\": 2.0, \"b\": 5.0},\n            \"probs\": {\"pJ\": 0.35, \"pC\": 0.80, \"pG_a\": 0.95, \"pG_b\": 0.90}\n        },\n        {\n            \"costs\": {\"Cu\": 40, \"Cn\": 200, \"Clog\": 80, \"Cexp\": 90},\n            \"params\": {\"a\": 1.5, \"b\": 3.0},\n            \"probs\": {\"pJ\": 0.95, \"pC\": 0.99, \"pG_a\": 0.99, \"pG_b\": 0.99}\n        },\n        {\n            \"costs\": {\"Cu\": 40, \"Cn\": 150, \"Clog\": 500, \"Cexp\": 700},\n            \"params\": {\"a\": 0.5, \"b\": 0.5},\n            \"probs\": {\"pJ\": 0.02, \"pC\": 0.50, \"pG_a\": 0.60, \"pG_b\": 0.60}\n        },\n        {\n            \"costs\": {\"Cu\": 40, \"Cn\": 1000, \"Clog\": 80, \"Cexp\": 90},\n            \"params\": {\"a\": 3.0, \"b\": 3.0},\n            \"probs\": {\"pJ\": 0.40, \"pC\": 0.60, \"pG_a\": 0.85, \"pG_b\": 0.85}\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        costs = case[\"costs\"]\n        probs = case[\"probs\"]\n        \n        c_u, c_n, c_log, c_exp = costs[\"Cu\"], costs[\"Cn\"], costs[\"Clog\"], costs[\"Cexp\"]\n        p_j, p_c, p_g_a, p_g_b = probs[\"pJ\"], probs[\"pC\"], probs[\"pG_a\"], probs[\"pG_b\"]\n\n        # 1. Calculate Expected Cost for Algorithm J\n        # Cost per trial = 2*Cu + 2*Clog + 2*Cexp\n        # Expected cost = Cost per trial / pJ\n        cost_per_trial_j = 2 * c_u + 2 * c_log + 2 * c_exp\n        expected_cost_j = cost_per_trial_j / p_j\n\n        # 2. Calculate Expected Cost for Algorithm C\n        # Cost per trial = Cn + Clog + Cu\n        # Expected cost = Cost per trial / pC\n        cost_per_trial_c = c_n + c_log + c_u\n        expected_cost_c = cost_per_trial_c / p_c\n\n        # 3. Calculate Expected Cost for Algorithm G\n        # Cost is the sum of costs for two independent Gamma variates.\n        # Cost per trial for one Gamma = Cn + Clog + Cu\n        # Total Expected Cost = (Cost per trial / pG_a) + (Cost per trial / pG_b)\n        cost_per_trial_g = c_n + c_log + c_u\n        expected_cost_g = cost_per_trial_g * (1 / p_g_a + 1 / p_g_b)\n\n        # Find the minimum expected cost among the three algorithms\n        min_cost = np.min([expected_cost_j, expected_cost_c, expected_cost_g])\n        results.append(min_cost)\n\n    # Format the output as a comma-separated list of floating-point numbers\n    # enclosed in square brackets.\n    # The map to str is important to handle the floating point representation.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}