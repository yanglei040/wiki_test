{
    "hands_on_practices": [
        {
            "introduction": "在贝叶斯推断中，估计后验预测分布是常见的任务。本练习将通过一个泊松-伽马共轭模型，让您亲手实现两种蒙特卡洛估计量，并直观地比较它们的方差。您将通过计算发现，利用Rao-Blackwell化（即解析地积分掉部分随机性）可以显著降低估计量的方差，这是计算统计中一种核心的方差缩减技巧。",
            "id": "3315544",
            "problem": "考虑一个由似然和先验定义的分层模型。设 $x_1,\\dots,x_n \\mid \\theta \\stackrel{\\text{ind}}{\\sim} \\operatorname{Poisson}(\\theta)$ 且 $\\theta \\sim \\operatorname{Gamma}(\\alpha,\\beta)$，其中 $\\operatorname{Gamma}(\\alpha,\\beta)$ 表示形状参数为 $\\alpha$、率参数为 $\\beta$ 的伽马分布（因此其概率密度函数与 $\\theta^{\\alpha-1}\\exp(-\\beta \\theta)$ 成正比）。定义联合分布 $f(x,\\theta)=f(x\\mid \\theta)\\,\\pi(\\theta)$，以及边缘分布（也称为证据或边缘似然）$m(x)=\\int f(x\\mid \\theta)\\,\\pi(\\theta)\\,\\mathrm{d}\\theta$。在观测到数据 $x=(x_1,\\dots,x_n)$ 后，$\\theta$ 的后验分布为 $\\pi(\\theta\\mid x)\\propto f(x\\mid \\theta)\\,\\pi(\\theta)$，新计数 $Y$ 的后验预测分布为 $m(y\\mid x)=\\int f(y\\mid \\theta)\\,\\pi(\\theta\\mid x)\\,\\mathrm{d}\\theta$。\n\n任务：\n- 从联合分布、边缘分布和条件分布的核心定义出发，推导上述共轭对的后验分布 $\\pi(\\theta\\mid x)$ 以及后验预测质量函数 $m(y\\mid x)$ 的闭式表达式。您的推导必须从 $f(x\\mid \\theta)=\\prod_{i=1}^n \\frac{\\exp(-\\theta)\\,\\theta^{x_i}}{x_i!}$ 和 $\\pi(\\theta)\\propto \\theta^{\\alpha-1}\\exp(-\\beta \\theta)$ 开始，并遵循第一性原理推导至定义 $m(y\\mid x)$ 的积分；不要通过调用预先记下的最终表达式来跳过步骤。\n- 构建并比较 $m(y\\mid x)$ 的两个无偏蒙特卡洛（MC）估计量：\n  1. 一个数值积分估计量，它从 $\\pi(\\theta\\mid x)$ 中抽样 $\\theta_1,\\dots,\\theta_N \\stackrel{\\text{iid}}{\\sim} \\pi(\\theta\\mid x)$ 并计算 $\\widehat{m}_{\\text{num}}(y\\mid x)=\\frac{1}{N}\\sum_{j=1}^N f(y\\mid \\theta_j)$。\n  2. 一个首先解析地对 $\\theta$ 积分以获得 $Y\\mid x$ 的闭式后验预测分布，然后从 $m(\\cdot\\mid x)$ 中抽样 $Y_1,\\dots,Y_N \\stackrel{\\text{iid}}{\\sim} m(\\cdot\\mid x)$ 并计算 $\\widehat{m}_{\\text{an}}(y\\mid x)=\\frac{1}{N}\\sum_{j=1}^N \\mathbb{I}\\{Y_j=y\\}$ 的估计量。\n从概念上，根据条件期望和 Rao–Blackwell 定理，解释为什么这两个估计量的方差不同，并将这种差异与层次结构 $Y\\mid \\theta$ 和 $\\theta\\mid x$ 联系起来。\n\n使用以下参数值测试套件来评估和比较这些估计量。在所有情况下，将伪随机生成器种子固定为 $12345$，以使输出具有确定性。\n\n- 测试用例1：$\\alpha=3$，$\\beta=1.2$，$x=(3,1,0,2)$，目标 $y=2$，MC样本量 $N=100000$。\n- 测试用例2：$\\alpha=1$，$\\beta=0.5$，$x=()$（空，所以 $n=0$），目标 $y=0$，MC样本量 $N=100000$。\n- 测试用例3：$\\alpha=10$，$\\beta=3$，$x=(10,9,12,8,11)$，目标 $y=15$，MC样本量 $N=100000$。\n\n您的程序必须：\n- 为每个测试用例计算闭式值 $m(y\\mid x)$。\n- 为每个测试用例计算如上定义的 $\\widehat{m}_{\\text{num}}(y\\mid x)$ 和 $\\widehat{m}_{\\text{an}}(y\\mid x)$。\n- 按顺序为每个测试用例返回以下五个浮点数：闭式 $m(y\\mid x)$、数值积分MC估计值 $\\widehat{m}_{\\text{num}}(y\\mid x)$、解析积分MC估计值 $\\widehat{m}_{\\text{an}}(y\\mid x)$、绝对误差 $\\left|\\widehat{m}_{\\text{num}}(y\\mid x)-m(y\\mid x)\\right|$ 和绝对误差 $\\left|\\widehat{m}_{\\text{an}}(y\\mid x)-m(y\\mid x)\\right|$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，首先是测试用例1的5个浮点数，然后是测试用例2的5个浮点数，最后是测试用例3的5个浮点数；例如，$[m_1,\\widehat{m}_{\\text{num},1},\\widehat{m}_{\\text{an},1},e_{\\text{num},1},e_{\\text{an},1},m_2,\\dots]$。\n- 此问题不涉及物理单位或角度单位。所有输出必须是实数。",
            "solution": "对用户提供的问题进行有效性评估。\n\n### 第一步：提取已知信息\n- **模型似然**：$x_1,\\dots,x_n \\mid \\theta \\stackrel{\\text{ind}}{\\sim} \\operatorname{Poisson}(\\theta)$，其中 $f(x_i \\mid \\theta) = \\frac{\\exp(-\\theta)\\,\\theta^{x_i}}{x_i!}$。\n- **模型先验**：$\\theta \\sim \\operatorname{Gamma}(\\alpha,\\beta)$，其概率密度函数（PDF）为 $\\pi(\\theta)\\propto \\theta^{\\alpha-1}\\exp(-\\beta \\theta)$。\n- **分布**：\n  - 联合分布：$f(x,\\theta)=f(x\\mid \\theta)\\,\\pi(\\theta)$。\n  - 边缘分布：$m(x)=\\int f(x\\mid \\theta)\\,\\pi(\\theta)\\,\\mathrm{d}\\theta$。\n  - 后验分布：$\\pi(\\theta\\mid x)\\propto f(x\\mid \\theta)\\,\\pi(\\theta)$。\n  - 后验预测分布：$m(y\\mid x)=\\int f(y\\mid \\theta)\\,\\pi(\\theta\\mid x)\\,\\mathrm{d}\\theta$（对于新计数 $Y$）。\n- **任务**：\n  1. 从第一性原理出发，推导后验分布 $\\pi(\\theta\\mid x)$ 和后验预测质量函数（PMF）$m(y\\mid x)$。\n  2. 为 $m(y\\mid x)$ 构建两个蒙特卡洛（MC）估计量：\n     - $\\widehat{m}_{\\text{num}}(y\\mid x)=\\frac{1}{N}\\sum_{j=1}^N f(y\\mid \\theta_j)$，其中 $\\theta_j \\stackrel{\\text{iid}}{\\sim} \\pi(\\theta\\mid x)$。\n     - $\\widehat{m}_{\\text{an}}(y\\mid x)=\\frac{1}{N}\\sum_{j=1}^N \\mathbb{I}\\{Y_j=y\\}$，其中 $Y_j \\stackrel{\\text{iid}}{\\sim} m(\\cdot\\mid x)$。\n  3. 使用 Rao–Blackwell 定理从概念上解释估计量之间的方差差异。\n- **测试用例**：\n  - 伪随机生成器种子：$12345$。\n  - 用例1：$\\alpha=3$, $\\beta=1.2$, $x=(3,1,0,2)$, 目标 $y=2$, $N=100000$。\n  - 用例2：$\\alpha=1$, $\\beta=0.5$, $x=()$, 目标 $y=0$, $N=100000$。\n  - 用例3：$\\alpha=10$, $\\beta=3$, $x=(10,9,12,8,11)$, 目标 $y=15$, $N=100000$。\n- **输出要求**：对于每个测试用例，返回五个浮点数：闭式 $m(y\\mid x)$、$\\widehat{m}_{\\text{num}}(y\\mid x)$、$\\widehat{m}_{\\text{an}}(y\\mid x)$ 以及两个估计量的绝对误差。\n\n### 第二步：使用提取的已知信息进行验证\n1.  **科学依据**：该问题基于泊松-伽马共轭先验模型，这是贝叶斯统计和计算方法中的一个标准和基础课题。所有定义和概念在概率论和统计学中都是公认的。该模型在科学上是合理的。\n2.  **定义明确**：问题定义清晰。泊松似然和伽马先验的组合是一个共轭系统，确保了后验分布和后验预测分布具有闭式表达式。任务具体，并导向一个唯一、有意义的解。\n3.  **客观性**：语言精确，没有主观性。参数和数据以数值形式给出，所要求的推导和计算是客观的数学任务。\n4.  **完整性**：提供了所有必要的信息（分布、参数、数据、任务）。没有缺失的定义或矛盾的约束。\n5.  **相关性**：该问题与随机模拟和蒙特卡洛方法直接相关，特别关注对后验预测概率的不同估计量的比较，这是该领域的核心概念。\n\n### 第三步：结论与行动\n问题是有效的。这是一个在贝叶斯统计和蒙特卡洛方法领域中定义明确、科学合理且客观的问题。我现在将着手解决。\n\n### 解析推导\n\n**1. 后验分布 $\\pi(\\theta\\mid x)$ 的推导**\n\n给定观测数据 $x=(x_1, \\dots, x_n)$，$\\theta$ 的后验分布由贝叶斯定理给出：\n$$\n\\pi(\\theta\\mid x) \\propto f(x\\mid\\theta)\\,\\pi(\\theta)\n$$\n对于来自 $\\operatorname{Poisson}(\\theta)$ 分布的 $n$ 个独立同分布的观测值，其似然函数 $f(x\\mid\\theta)$ 是单个概率质量函数的乘积：\n$$\nf(x\\mid\\theta) = \\prod_{i=1}^n f(x_i\\mid\\theta) = \\prod_{i=1}^n \\frac{\\exp(-\\theta)\\,\\theta^{x_i}}{x_i!} = \\frac{\\exp(-n\\theta)\\,\\theta^{\\sum_{i=1}^n x_i}}{\\prod_{i=1}^n x_i!}\n$$\n$\\theta$ 的先验分布是伽马分布，$\\theta \\sim \\operatorname{Gamma}(\\alpha,\\beta)$，其概率密度函数（PDF）正比于：\n$$\n\\pi(\\theta) \\propto \\theta^{\\alpha-1}\\exp(-\\beta \\theta)\n$$\n结合似然和先验，未归一化的后验分布为：\n$$\n\\pi(\\theta\\mid x) \\propto \\left( \\frac{\\exp(-n\\theta)\\,\\theta^{\\sum_{i=1}^n x_i}}{\\prod_{i=1}^n x_i!} \\right) \\left( \\theta^{\\alpha-1}\\exp(-\\beta \\theta) \\right)\n$$\n由于我们关心的是 $\\theta$ 的分布，我们可以省略任何不依赖于 $\\theta$ 的项，例如 $1/\\prod_{i=1}^n x_i!$：\n$$\n\\pi(\\theta\\mid x) \\propto \\exp(-n\\theta)\\,\\theta^{\\sum_{i=1}^n x_i} \\cdot \\theta^{\\alpha-1}\\exp(-\\beta \\theta)\n$$\n合并 $\\theta$ 的指数项和幂次项：\n$$\n\\pi(\\theta\\mid x) \\propto \\theta^{(\\alpha + \\sum_{i=1}^n x_i) - 1} \\exp(-(\\beta+n)\\theta)\n$$\n这个表达式是伽马分布的核。如果我们定义后验参数 $\\alpha' = \\alpha + \\sum_{i=1}^n x_i$ 和 $\\beta' = \\beta + n$，后验分布为：\n$$\n\\pi(\\theta\\mid x) \\propto \\theta^{\\alpha' - 1} \\exp(-\\beta'\\theta)\n$$\n因此，给定 $x$ 的 $\\theta$ 的后验分布是一个伽马分布：$\\theta\\mid x \\sim \\operatorname{Gamma}(\\alpha', \\beta')$。归一化的后验PDF为 $\\pi(\\theta\\mid x) = \\frac{(\\beta')^{\\alpha'}}{\\Gamma(\\alpha')} \\theta^{\\alpha'-1} \\exp(-\\beta'\\theta)$（对于 $\\theta  0$）。\n\n**2. 后验预测质量函数 $m(y\\mid x)$ 的推导**\n\n新观测值 $Y$ 的后验预测分布是通过将 $Y$ 的似然在 $\\theta$ 的后验分布上取平均得到的：\n$$\nm(y\\mid x) = \\int_0^\\infty f(y\\mid\\theta)\\,\\pi(\\theta\\mid x)\\,\\mathrm{d}\\theta\n$$\n在这里，$f(y\\mid\\theta)$ 是 $\\operatorname{Poisson}(\\theta)$ 分布的PMF，$f(y\\mid\\theta) = \\frac{\\exp(-\\theta)\\,\\theta^y}{y!}$，而 $\\pi(\\theta\\mid x)$ 是 $\\operatorname{Gamma}(\\alpha', \\beta')$ 分布的PDF。将它们代入积分中：\n$$\nm(y\\mid x) = \\int_0^\\infty \\left( \\frac{\\exp(-\\theta)\\,\\theta^y}{y!} \\right) \\left( \\frac{(\\beta')^{\\alpha'}}{\\Gamma(\\alpha')} \\theta^{\\alpha'-1} \\exp(-\\beta'\\theta) \\right) \\mathrm{d}\\theta\n$$\n我们可以将不依赖于 $\\theta$ 的项移到积分外：\n$$\nm(y\\mid x) = \\frac{(\\beta')^{\\alpha'}}{y!\\,\\Gamma(\\alpha')} \\int_0^\\infty \\theta^y\\,\\theta^{\\alpha'-1} \\exp(-\\theta)\\,\\exp(-\\beta'\\theta)\\,\\mathrm{d}\\theta\n$$\n合并积分内的项：\n$$\nm(y\\mid x) = \\frac{(\\beta')^{\\alpha'}}{y!\\,\\Gamma(\\alpha')} \\int_0^\\infty \\theta^{(y+\\alpha')-1} \\exp(-(\\beta'+1)\\theta)\\,\\mathrm{d}\\theta\n$$\n该积分是伽马PDF的核。伽马积分的一般形式是 $\\int_0^\\infty t^{k-1} e^{-rt} \\mathrm{d}t = \\frac{\\Gamma(k)}{r^k}$。在我们的例子中，形状为 $k=y+\\alpha'$，率为 $r=\\beta'+1$。因此，积分的计算结果为：\n$$\n\\int_0^\\infty \\theta^{(y+\\alpha')-1} \\exp(-(\\beta'+1)\\theta)\\,\\mathrm{d}\\theta = \\frac{\\Gamma(y+\\alpha')}{(\\beta'+1)^{y+\\alpha'}}\n$$\n将此结果代回 $m(y\\mid x)$ 的表达式中：\n$$\nm(y\\mid x) = \\frac{(\\beta')^{\\alpha'}}{y!\\,\\Gamma(\\alpha')} \\frac{\\Gamma(y+\\alpha')}{(\\beta'+1)^{y+\\alpha'}}\n$$\n使用恒等式 $y! = \\Gamma(y+1)$ 并重新整理各项：\n$$\nm(y\\mid x) = \\frac{\\Gamma(y+\\alpha')}{\\Gamma(y+1)\\Gamma(\\alpha')} \\left( \\frac{\\beta'}{\\beta'+1} \\right)^{\\alpha'} \\left( \\frac{1}{\\beta'+1} \\right)^y\n$$\n这是负二项分布的PMF。使用组合符号 $\\binom{n}{k} = \\frac{\\Gamma(n+1)}{\\Gamma(k+1)\\Gamma(n-k+1)}$，我们可以写出 $\\frac{\\Gamma(y+\\alpha')}{\\Gamma(y+1)\\Gamma(\\alpha')} = \\binom{y+\\alpha'-1}{y}$。如果我们设置参数 $r = \\alpha'$ 和 $p = \\frac{\\beta'}{\\beta'+1}$，PMF变为：\n$$\nm(y\\mid x) = \\binom{y+r-1}{y} p^r (1-p)^y\n$$\n这证实了 $Y$ 的后验预测分布是负二项分布，$Y\\mid x \\sim \\operatorname{NB}(r=\\alpha', p=\\frac{\\beta'}{\\beta'+1})$。\n\n### 蒙特卡洛估计量与方差比较\n\n我们被要求比较 $m(y\\mid x) = P(Y=y \\mid x)$ 的两个无偏MC估计量。\n\n1.  **数值积分估计量 $\\widehat{m}_{\\text{num}}(y\\mid x)$**：此估计量使用从 $\\theta$ 的后验分布中抽取的样本来近似定义 $m(y\\mid x)$ 的积分。它计算为 $\\widehat{m}_{\\text{num}}(y\\mid x) = \\frac{1}{N}\\sum_{j=1}^N f(y\\mid\\theta_j)$，其中 $\\theta_j \\sim \\pi(\\theta\\mid x)$。这是 $\\mathbb{E}_{\\theta\\mid x}[f(y\\mid\\theta)]$ 的一个估计。\n\n2.  **解析积分估计量 $\\widehat{m}_{\\text{an}}(y\\mid x)$**：此估计量利用解析推导出的闭式后验预测分布 $m(\\cdot\\mid x)$。它计算为 $\\widehat{m}_{\\text{an}}(y\\mid x) = \\frac{1}{N}\\sum_{j=1}^N \\mathbb{I}\\{Y_j=y\\}$，其中 $Y_j \\sim m(\\cdot\\mid x)$ 且 $\\mathbb{I}{\\cdot}$ 是指示函数。这是 $\\mathbb{E}_{Y\\mid x}[\\mathbb{I}\\{Y=y\\}]$ 的一个估计。\n\n**方差差异的概念性解释**：\n\n$\\widehat{m}_{\\text{num}}$ 和 $\\widehat{m}_{\\text{an}}$ 之间方差的差异是蒙特卡洛估计中Rao-Blackwell化的好处的一个经典例证。Rao–Blackwell定理表明，对于一个估计量 $T$，以一个充分统计量为条件，可以得到一个新的估计量 $T' = \\mathbb{E}[T \\mid S]$，其方差满足 $\\operatorname{Var}(T') \\le \\operatorname{Var}(T)$。在我们的情境中，$\\widehat{m}_{\\text{num}}$ 可以被看作是 $\\widehat{m}_{\\text{an}}$ 的一个Rao-Blackwell化版本。\n\n让我们分析每个估计量单个样本的方差。\n对于 $\\widehat{m}_{\\text{an}}$，估计量是 $W_j = \\mathbb{I}\\{Y_j=y\\}$ 的样本均值，其中 $Y_j \\sim m(\\cdot\\mid x)$。该估计量的方差为 $\\frac{1}{N}\\operatorname{Var}_{Y\\mid x}(\\mathbb{I}\\{Y=y\\})$。\n对于 $\\widehat{m}_{\\text{num}}$，估计量是 $Z_j = f(y\\mid \\theta_j)$ 的样本均值，其中 $\\theta_j \\sim \\pi(\\theta\\mid x)$。该估计量的方差为 $\\frac{1}{N}\\operatorname{Var}_{\\theta\\mid x}(f(y\\mid\\theta))$。\n\n通过将全方差定律应用于随机变量 $W = \\mathbb{I}\\{Y=y\\}$ 在 $(Y, \\theta)\\mid x$ 的联合分布上，可以建立联系：\n$$\n\\operatorname{Var}(W) = \\mathbb{E}[\\operatorname{Var}(W\\mid\\theta)] + \\operatorname{Var}(\\mathbb{E}[W\\mid\\theta])\n$$\n让我们识别各项：\n-   $\\mathbb{E}[W\\mid\\theta] = \\mathbb{E}[\\mathbb{I}\\{Y=y\\}\\mid\\theta] = P(Y=y\\mid\\theta) = f(y\\mid\\theta)$。这是数值积分估计量使用的随机变量 $Z$。\n-   $\\operatorname{Var}(\\mathbb{E}[W\\mid\\theta]) = \\operatorname{Var}_{\\theta\\mid x}(f(y\\mid\\theta))$。这一项是 $\\widehat{m}_{\\text{num}}$ 方差的 $N$ 倍。\n-   $\\operatorname{Var}(W\\mid\\theta) = \\operatorname{Var}_{Y\\mid \\theta}(\\mathbb{I}\\{Y=y\\}) = P(Y=y\\mid\\theta)(1-P(Y=y\\mid\\theta)) = f(y\\mid\\theta)(1-f(y\\mid\\theta))$。这是固定 $\\theta$ 时伯努利试验的方差。\n-   $\\mathbb{E}[\\operatorname{Var}(W\\mid\\theta)] = \\mathbb{E}_{\\theta\\mid x}[f(y\\mid\\theta)(1-f(y\\mid\\theta))]$。\n\n将这些代回全方差定律：\n$$\n\\operatorname{Var}_{Y\\mid x}(\\mathbb{I}\\{Y=y\\}) = \\mathbb{E}_{\\theta\\mid x}[f(y\\mid\\theta)(1-f(y\\mid\\theta))] + \\operatorname{Var}_{\\theta\\mid x}(f(y\\mid\\theta))\n$$\n估计量 $\\widehat{m}_{\\text{an}}$ 的方差与左侧成正比，而估计量 $\\widehat{m}_{\\text{num}}$ 的方差与右侧第二项成正比。由于 $\\mathbb{E}_{\\theta\\mid x}[f(y\\mid\\theta)(1-f(y\\mid\\theta))] \\ge 0$，可以清楚地看到：\n$$\n\\operatorname{Var}_{\\theta\\mid x}(f(y\\mid\\theta)) \\le \\operatorname{Var}_{Y\\mid x}(\\mathbb{I}\\{Y=y\\})\n$$\n这意味着 $\\operatorname{Var}(\\widehat{m}_{\\text{num}}) \\le \\operatorname{Var}(\\widehat{m}_{\\text{an}})$。\n\n从概念上讲，估计量 $\\widehat{m}_{\\text{an}}$ 涉及两个层次的随机性：从其后验分布中对 $\\theta$ 的抽样（隐式地）以及随后从泊松分布中对 $Y$ 的抽样。估计量 $\\widehat{m}_{\\text{num}}$ 解析地对泊松随机性进行平均（积分），用其条件期望 $f(y\\mid\\theta)$ 替代了随机指示符 $\\mathbb{I}\\{Y=y\\}$。通过消除一个随机性来源，它降低了估计的总体方差。这个过程被称为 Rao-Blackwell化。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import gammaln\nfrom scipy.stats import poisson\n\ndef solve():\n    \"\"\"\n    Computes and compares two Monte Carlo estimators for the posterior predictive\n    probability mass function in a Poisson-Gamma conjugate model.\n    \"\"\"\n    \n    test_cases = [\n        # (alpha, beta, x, y, N)\n        (3.0, 1.2, (3, 1, 0, 2), 2, 100000),\n        (1.0, 0.5, (), 0, 100000),\n        (10.0, 3.0, (10, 9, 12, 8, 11), 15, 100000),\n    ]\n\n    # Fix the pseudorandom generator seed for deterministic output.\n    np.random.seed(12345)\n\n    results = []\n    for alpha, beta, x, y, N in test_cases:\n        # Step 1: Calculate posterior parameters\n        n = len(x)\n        sum_x = sum(x)\n        \n        alpha_prime = alpha + sum_x\n        beta_prime = beta + n\n\n        # Step 2: Compute the closed-form value of m(y|x)\n        # This is the PMF of a Negative Binomial distribution with parameters\n        # r = alpha_prime and p = beta_prime / (beta_prime + 1)\n        log_m_true = (gammaln(y + alpha_prime) \n                      - (gammaln(y + 1) + gammaln(alpha_prime))\n                      + alpha_prime * np.log(beta_prime) \n                      - (y + alpha_prime) * np.log(beta_prime + 1))\n        m_true = np.exp(log_m_true)\n\n        # Step 3: Compute the numerical integration estimator, hat_m_num\n        # This is the Rao-Blackwellized estimator.\n        # Sample thetas from the posterior Gamma(alpha', beta')\n        # Note: numpy.random.gamma uses a scale parameter, which is 1/rate.\n        scale_param = 1.0 / beta_prime\n        thetas = np.random.gamma(shape=alpha_prime, scale=scale_param, size=N)\n        \n        # Calculate the Poisson PMF f(y|theta) for each sample\n        # This is E[I(Y=y)|theta]\n        f_values = poisson.pmf(y, thetas)\n        m_hat_num = np.mean(f_values)\n        \n        # Step 4: Compute the analytically-integrated estimator, hat_m_an\n        # This is the \"naive\" estimator that simulates the full hierarchy.\n        # Sample Y from the posterior predictive NegativeBinomial(r, p)\n        # and compute the proportion of samples equal to y.\n        p_nb = beta_prime / (beta_prime + 1)\n        Y_samples = np.random.negative_binomial(n=alpha_prime, p=p_nb, size=N)\n        m_hat_an = np.mean(Y_samples == y)\n\n        # Step 5: Calculate absolute errors\n        error_num = abs(m_hat_num - m_true)\n        error_an = abs(m_hat_an - m_true)\n        \n        results.extend([m_true, m_hat_num, m_hat_an, error_num, error_an])\n\n    # Format the final output as a single comma-separated list in brackets.\n    # Use general formatting to avoid scientific notation where possible, but allow it if needed.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Rao-Blackwell定理不仅适用于简单的随机抽样，在更复杂的实验设计中同样威力强大。本练习将探讨一个序贯抽样场景，其中实验持续进行直至观察到固定数量的成功。您的任务是基于一个简单的无偏估计量，通过对充分统计量（总试验次数$N$）取条件期望，推导出改进后的估计量，并解析地计算出方差缩减的程度。",
            "id": "1922452",
            "problem": "一项序贯临床试验旨在测试一种新药。患者被逐一治疗，每个患者的结果要么是“成功”，要么是“失败”。成功的概率 $p$ 被假设对所有患者都是恒定的，其中 $0  p  1$。试验将持续进行，直到记录到恰好 $k$ 次成功为止。令 $N$ 为接受治疗的患者总数，它是一个随机变量。\n\n提出了一个针对成功概率 $p$ 的初始简单无偏估计量：$\\hat{p}_{crude} = X_1$，其中如果第一个患者的结果是成功，则 $X_1=1$，否则 $X_1=0$。\n\n根据统计理论，这个估计量可以使用 Rao-Blackwell 定理进行改进。这个过程涉及到将 $\\hat{p}_{crude}$ 条件化于参数 $p$ 的一个充分统计量。对于这个试验设计，试验总次数 $N$ 是一个充分统计量。得到的 Rao-Blackwell化 估计量是 $\\hat{p}_{RB} = E[\\hat{p}_{crude} | N]$。\n\n您的任务是分析在试验设置为 $k=2$ 次成功后停止的特定情况下，估计质量的改善情况。计算方差缩减因子，定义为比率 $\\mathcal{R} = \\frac{\\text{Var}(\\hat{p}_{crude})}{\\text{Var}(\\hat{p}_{RB})}$。将您的最终答案表示为 $p$ 的解析函数。",
            "solution": "令 $X_i \\sim \\text{Bernoulli}(p)$ 为独立随机变量，代表每次试验的结果。试验进行直到观察到 $k$ 次成功。令 $N$ 为试验总次数。$N$ 服从负二项分布， $N \\sim \\text{NB}(k, p)$，其概率质量函数为 $P(N=n) = \\binom{n-1}{k-1}p^k(1-p)^{n-k}$，其中 $n = k, k+1, \\dots$。\n\n初始估计量为 $\\hat{p}_{crude} = X_1$。它是无偏的，因为 $E[\\hat{p}_{crude}] = E[X_1] = p$。其方差为 $\\text{Var}(\\hat{p}_{crude}) = \\text{Var}(X_1) = p(1-p)$。\n\nRao-Blackwell化估计量为 $\\hat{p}_{RB} = E[\\hat{p}_{crude} | N] = E[X_1 | N]$。对于 $N=n$，该值为 $P(X_1=1 | N=n) = \\frac{P(X_1=1, N=n)}{P(N=n)}$。\n\n联合事件 $\\{X_1=1, N=n\\}$ 意味着第一次试验成功，且在接下来的 $n-1$ 次试验中需要观察到 $k-1$ 次成功，并在第 $n$ 次试验时结束。这等价于第一次试验成功，且一个从第二次试验开始的序贯过程需要 $n-1$ 次试验来获得 $k-1$ 次成功。因此，\n$P(X_1=1, N=n) = P(X_1=1) \\times P(\\text{需要 } n-1 \\text{ 次试验获得 } k-1 \\text{ 次成功})$\n$= p \\times \\left[ \\binom{(n-1)-1}{(k-1)-1} p^{k-1} (1-p)^{(n-1)-(k-1)} \\right] = \\binom{n-2}{k-2} p^k (1-p)^{n-k}$。\n此公式对 $n \\ge k \\ge 2$ 成立。\n\n因此，条件期望为：\n$\\hat{p}_{RB}(n) = \\frac{\\binom{n-2}{k-2} p^k (1-p)^{n-k}}{\\binom{n-1}{k-1} p^k (1-p)^{n-k}} = \\frac{\\binom{n-2}{k-2}}{\\binom{n-1}{k-1}} = \\frac{(n-2)!/(k-2)!(n-k)!}{(n-1)!/(k-1)!(n-k)!} = \\frac{k-1}{n-1}$。\n所以，Rao-Blackwell化估计量为随机变量 $\\hat{p}_{RB} = \\frac{k-1}{N-1}$。\n\n当 $k=2$ 时，$\\hat{p}_{RB} = \\frac{1}{N-1}$。根据全期望定律，$E[\\hat{p}_{RB}] = E[X_1] = p$。\n$\\text{Var}(\\hat{p}_{RB}) = E[\\hat{p}_{RB}^2] - (E[\\hat{p}_{RB}])^2 = E\\left[\\frac{1}{(N-1)^2}\\right] - p^2$。\n\n我们需要计算 $E\\left[\\frac{1}{(N-1)^2}\\right]$。对于 $k=2$，$N \\sim \\text{NB}(2,p)$，$P(N=n) = (n-1)p^2(1-p)^{n-2}$ for $n=2,3,\\dots$。\n$E\\left[\\frac{1}{(N-1)^2}\\right] = \\sum_{n=2}^{\\infty} \\frac{1}{(n-1)^2} (n-1)p^2(1-p)^{n-2} = p^2 \\sum_{n=2}^{\\infty} \\frac{(1-p)^{n-2}}{n-1}$。\n令 $j=n-1$，则该和为 $p^2 \\sum_{j=1}^{\\infty} \\frac{(1-p)^{j-1}}{j} = \\frac{p^2}{1-p} \\sum_{j=1}^{\\infty} \\frac{(1-p)^j}{j}$。\n利用泰勒级数 $\\sum_{j=1}^{\\infty} \\frac{x^j}{j} = -\\ln(1-x)$，我们得到：\n$E\\left[\\frac{1}{(N-1)^2}\\right] = \\frac{p^2}{1-p} [-\\ln(1-(1-p))] = \\frac{-p^2\\ln p}{1-p}$。\n\n因此，$\\text{Var}(\\hat{p}_{RB}) = \\frac{-p^2\\ln p}{1-p} - p^2 = p^2\\left(\\frac{-\\ln p}{1-p}-1\\right) = p^2\\frac{p-1-\\ln p}{1-p}$。\n\n方差缩减因子 $\\mathcal{R}$ 为：\n$\\mathcal{R} = \\frac{\\text{Var}(\\hat{p}_{crude})}{\\text{Var}(\\hat{p}_{RB})} = \\frac{p(1-p)}{p^2\\frac{p-1-\\ln p}{1-p}} = \\frac{1-p}{p} \\cdot \\frac{1-p}{p-1-\\ln p} = \\frac{(1-p)^2}{p(p-1-\\ln p)}$。",
            "answer": "$$\\boxed{\\frac{(1-p)^{2}}{p\\left(p-1-\\ln p\\right)}}$$"
        },
        {
            "introduction": "理解一个定理的适用边界和理解其应用本身同样重要。这个练习设计了一个看似可以使用Rao-Blackwell化改进的情形，但实际上并不会带来任何方差缩减。通过这个编程实践，您将验证当一个估计量本身已经是充分统计量的函数时，对其进行条件化操作是无效的，从而加深对Rao-Blackwell定理核心条件的理解。",
            "id": "3297948",
            "problem": "考虑独立同分布的随机变量 $X_1,\\dots,X_n$，其中 $X_i \\sim \\text{Exp}(\\lambda)$，$\\text{Exp}(\\lambda)$ 表示速率参数为 $\\lambda$ 的指数分布。定义样本均值 $\\bar{X}$ 为 $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^n X_i$，以及充分统计量 $T$ 为 $T=\\sum_{i=1}^n X_i$。固定一个可测函数 $g:\\mathbb{R}_+\\to\\mathbb{R}$，其形式为 $g(x)=\\exp(-\\alpha x)$，其中 $\\alpha0$ 是一个固定常数。目标是近似期望 $E[g(\\bar{X})]$，并比较一个朴素估计量与一个在充分统计量 $T$ 上进行条件化的 Rao-Blackwell化估计量的蒙特卡洛方差。\n\n你的任务是：\n\n- 从第一性原理出发，推导一个用于计算 $E[g(\\bar{X})]$ 的朴素蒙特卡洛估计量，该估计量使用 $M$ 次独立重复实验，每次重复实验包含 $n$ 次从 $\\text{Exp}(\\lambda)$ 分布中的独立抽样。朴素估计量是在 $M$ 次重复实验中对 $g(\\bar{X})$ 的经验平均值。这里的 $M$ 是为保证计算稳定性而选择的一个正整数，其选择应在你的算法设计中予以说明。\n- 推导一个以充分统计量 $T=\\sum_{i=1}^n X_i$ 为条件的 Rao-Blackwell化估计量，并量化当 $n$ 变化时，其蒙特卡洛方差相对于朴素估计量的变化。\n- 使用充分统计量、条件期望和全方差公式的基本定义来证明该构造和比较的合理性。\n\n为了可复现性，将 $\\alpha$ 设置为固定值 $\\alpha=1.3$。本问题不涉及物理单位或角度；所有量均为无量纲量。蒙特卡洛方差的比较应通过定义的比率 $R(n,\\lambda)$ 来表示：\n$$\nR(n,\\lambda)=\\frac{\\operatorname{Var}(\\text{naive single-replicate }g(\\bar{X}))}{\\operatorname{Var}(\\text{Rao-Blackwellized single-replicate }E[g(\\bar{X})\\mid T])},\n$$\n在每个测试案例中，通过 $M$ 次重复实验进行经验估计。\n\n使用以下参数值 $(n,\\lambda)$ 的测试套件：\n- 测试案例 1：$n=1$，$\\lambda=0.7$。\n- 测试案例 2：$n=2$，$\\lambda=1.0$。\n- 测试案例 3：$n=10$，$\\lambda=1.0$。\n- 测试案例 4：$n=100$，$\\lambda=2.0$。\n\n你的程序必须：\n- 为每个测试案例实现朴素估计量和 Rao-Blackwell化估计量。\n- 使用 $M$ 次重复实验，估计单次重复实验的量 $g(\\bar{X})$ 和 $E[g(\\bar{X})\\mid T]$ 的经验方差，其中 $M$ 应选择为一个足够大的正整数，以确保数值稳定性，同时保持计算可行。\n- 为每个测试案例计算比率 $R(n,\\lambda)$，结果为浮点数。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为按上述测试案例顺序排列的结果，例如 $[r_1,r_2,r_3,r_4]$，其中每个 $r_i$ 是相应测试案例的经验估计比率 $R(n,\\lambda)$。",
            "solution": "构造过程基于以下基本原理。\n\n首先，回顾速率参数为 $\\lambda$ 的指数分布的概率密度函数 (PDF) 是 $f(x;\\lambda)=\\lambda e^{-\\lambda x}$（对于 $x\\ge 0$）。对于独立同分布的 $X_1,\\dots,X_n$ 且 $X_i\\sim \\text{Exp}(\\lambda)$，其联合概率密度函数为\n$$\nf(x_1,\\dots,x_n;\\lambda)=\\prod_{i=1}^n \\lambda e^{-\\lambda x_i}=\\lambda^n \\exp\\Big(-\\lambda \\sum_{i=1}^n x_i\\Big)\\prod_{i=1}^n \\mathbf{1}_{\\{x_i\\ge 0\\}}.\n$$\n根据关于充分性的因子分解定理，统计量 $T=\\sum_{i=1}^n X_i$ 是 $\\lambda$ 的充分统计量，因为联合概率密度函数可以分解为一个关于 $T$ 和 $\\lambda$ 的函数与一个与 $\\lambda$ 无关的函数的乘积。具体来说，令 $h(x_1,\\dots,x_n)=\\prod_{i=1}^n \\mathbf{1}_{\\{x_i\\ge 0\\}}$ 且 $g_\\lambda(T)=\\lambda^n e^{-\\lambda T}$，则联合概率密度函数为 $f(x_1,\\dots,x_n;\\lambda)=g_\\lambda(T)\\,h(x_1,\\dots,x_n)$。\n\n其次，注意到样本均值为 $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^n X_i=\\frac{T}{n}$。因此，对于任何可测函数 $g:\\mathbb{R}_+\\to\\mathbb{R}$，随机变量 $g(\\bar{X})$ 都是 $T$ 的可测函数。特别地，对于所选的 $g(x)=\\exp(-\\alpha x)$（其中 $\\alpha0$），我们有 $g(\\bar{X})=\\exp\\big(-\\alpha \\tfrac{T}{n}\\big)$。\n\n第三，回顾条件期望的定义：如果 $Y$ 是可积的，并且相对于由统计量 $S$ 生成的 $\\sigma$-代数是可测的，那么 $E[Y\\mid S]=Y$ 几乎必然成立。将此应用于 $Y=g(\\bar{X})$ 和 $S=T$，我们得到\n$$\nE\\big[g(\\bar{X})\\mid T\\big]=g(\\bar{X})=\\exp\\Big(-\\alpha \\frac{T}{n}\\Big).\n$$\n因此，以 $T$ 为条件的 Rao-Blackwell化估计量对于每一次实现都精确地等于朴素的单次重复实验估计量 $g(\\bar{X})$。\n\n第四，对一个可积的随机变量 $Y$ 和一个由统计量 $S$ 生成的 $\\sigma$-代数，使用全方差公式（一个标准的、经过充分检验的恒等式）：\n$$\n\\operatorname{Var}(Y) = \\operatorname{Var}\\big(E[Y\\mid S]\\big) + E\\big[\\operatorname{Var}(Y\\mid S)\\big].\n$$\n如果 $Y$ 相对于 $S$ 是可测的，那么 $\\operatorname{Var}(Y\\mid S)=0$ 几乎必然成立，因此 $\\operatorname{Var}(Y)=\\operatorname{Var}(E[Y\\mid S])$。将此应用于 $Y=g(\\bar{X})$ 和 $S=T$ 可得\n$$\n\\operatorname{Var}\\big(g(\\bar{X})\\big)=\\operatorname{Var}\\big(E[g(\\bar{X})\\mid T]\\big).\n$$\n因此，在这种特定情况下，Rao-Blackwell化不提供方差缩减，因为朴素的单次重复实验估计量本身已经是充分统计量 $T$ 的函数。\n\n蒙特卡洛研究的算法设计：\n- 对于每个测试案例 $(n,\\lambda)$，生成 $M$ 次独立重复实验；在每次重复实验中，从 $\\text{Exp}(\\lambda)$ 分布中抽取 $n$ 个独立样本。\n- 计算朴素的单次重复实验值 $Y=g(\\bar{X})$，其中 $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^n X_i$。\n- 计算 Rao-Blackwell化的单次重复实验值 $\\tilde{Y}=E[g(\\bar{X})\\mid T]$。根据上面的可测性论证，对于每次重复实验，都有 $\\tilde{Y}=g(\\bar{X})$。\n- 使用无偏样本方差，通过 $M$ 次重复实验估计经验方差 $\\widehat{\\operatorname{Var}}(Y)$ 和 $\\widehat{\\operatorname{Var}}(\\tilde{Y})$。由于 $Y$ 和 $\\tilde{Y}$ 在每次重复实验中都相等，所以这些经验方差也相等，它们的比率恰好为 $1$。\n- 按测试套件的顺序输出比率列表 $R(n,\\lambda)$。\n\n期望的可选解析验证（输出规范未要求）：因为 $T\\sim \\text{Gamma}(n,\\lambda)$，其形状参数为 $n$，速率参数为 $\\lambda$，所以有\n$$\nE\\left[\\exp\\left(-\\alpha \\frac{T}{n}\\right)\\right] = \\left(\\frac{\\lambda}{\\lambda+\\alpha/n}\\right)^n,\n$$\n这是通过使用伽玛分布的拉普拉斯变换得到的。这证实了目标期望是良定义的，并且可以精确计算，尽管此处的重点是方差比较。\n\n总之，对于所有测试案例，方差比 $R(n,\\lambda)$ 等于 $1$，这反映了一个事实：当估计量本身已经是某个充分统计量的函数时，以该统计量为条件并不能减少方差。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef estimate_variance_ratio(n: int, lam: float, alpha: float, M: int, chunk_size: int = 10000) -> float:\n    \"\"\"\n    Estimate the ratio Var(naive g(barX)) / Var(Rao-Blackwellized E[g(barX)|T])\n    using M replicates in chunks to control memory.\n    For this problem, the Rao-Blackwellized estimator equals the naive estimator exactly,\n    so the ratio should be exactly 1.0. We compute both variances empirically to\n    demonstrate equality.\n    \"\"\"\n    # Welford's algorithm for online variance estimation (unbiased sample variance)\n    # for the naive estimator Y and the RB estimator Y_rb. They will track identical values.\n    count = 0\n    mean_naive = 0.0\n    M2_naive = 0.0\n\n    mean_rb = 0.0\n    M2_rb = 0.0\n\n    # Process in chunks to limit memory usage\n    remaining = M\n    rng = np.random.default_rng(seed=12345)\n    scale = 1.0 / lam\n\n    while remaining > 0:\n        m = min(chunk_size, remaining)\n        # Draw m replicates of length n from Exp(lam)\n        x = rng.exponential(scale=scale, size=(m, n))\n        # Compute sample mean per replicate\n        xbar = x.mean(axis=1)\n        # Naive single-replicate values\n        y = np.exp(-alpha * xbar)\n        # Rao-Blackwellized single-replicate values; here equals g(T/n) = g(xbar)\n        y_rb = np.exp(-alpha * xbar)\n\n        # Update Welford statistics for naive\n        for val in y:\n            count += 1\n            delta = val - mean_naive\n            mean_naive += delta / count\n            M2_naive += delta * (val - mean_naive)\n\n        # Update Welford statistics for RB\n        # Note: y_rb equals y elementwise; we still update separately for clarity.\n        count_rb = count - m  # RB count before this chunk\n        mean_rb_chunk = mean_rb\n        M2_rb_chunk = M2_rb\n        for val in y_rb:\n            count_rb += 1\n            delta_rb = val - mean_rb_chunk\n            mean_rb_chunk += delta_rb / count_rb\n            M2_rb_chunk += delta_rb * (val - mean_rb_chunk)\n        mean_rb = mean_rb_chunk\n        M2_rb = M2_rb_chunk\n\n        remaining -= m\n\n    # Unbiased sample variance with ddof=1\n    var_naive = M2_naive / (count - 1) if count > 1 else 0.0\n    var_rb = M2_rb / (count - 1) if count > 1 else 0.0\n\n    # Ratio; guard against division by zero (should not happen unless M2 is zero).\n    ratio = var_naive / var_rb if var_rb > 0 else 1.0\n    return ratio\n\ndef solve():\n    # Define alpha and Monte Carlo replicates count M\n    alpha = 1.3\n    M = 100000  # Large enough for stability, small enough for speed\n\n    # Define the test cases from the problem statement.\n    # Each test case is a tuple (n, lambda)\n    test_cases = [\n        (1, 0.7),\n        (2, 1.0),\n        (10, 1.0),\n        (100, 2.0),\n    ]\n\n    results = []\n    for n, lam in test_cases:\n        ratio = estimate_variance_ratio(n=n, lam=lam, alpha=alpha, M=M, chunk_size=10000)\n        # To ensure clean output, round to 6 decimal places\n        results.append(f\"{ratio:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}