{
    "hands_on_practices": [
        {
            "introduction": "要掌握蒙特卡罗积分，第一步是理解其误差的来源。本练习旨在通过一个基础的计算，让您亲手推导估计量方差的精确表达式，从而直观地理解被积函数自身的性质如何直接影响蒙特卡罗方法的精度。通过分析一个简单的指示函数，您将揭示估计量的不确定性与其内在随机性之间的深刻联系 ()。",
            "id": "3301580",
            "problem": "考虑在定义域 $D=[0,1]$ 上对被积函数 $h(x)=\\mathbf{1}\\{x\\le t\\}$ 进行粗略蒙特卡洛积分，其中 $t\\in[0,1]$ 是一个固定值，$\\mathbf{1}\\{\\cdot\\}$ 表示指示函数。设 $X_{1},X_{2},\\dots,X_{n}$ 是从 $[0,1]$ 上的连续均匀分布中抽取的独立同分布样本，记为 $X_{i}\\sim\\mathrm{Uniform}(0,1)$，并将积分 $I=\\int_{0}^{1}h(x)\\,dx$ 的粗略蒙特卡洛估计量定义为\n$$\n\\hat I_{n}=\\frac{1}{n}\\sum_{i=1}^{n}h(X_{i}).\n$$\n从独立同分布随机变量的期望和方差的核心定义出发，当 $h(x)=\\mathbf{1}\\{x\\le t\\}$ 时，推导 $\\mathrm{Var}(\\hat I_{n})$ 作为 $n$ 和 $t$ 的函数的精确闭式表达式。然后，仅根据 $t$ 来解释 $t$ 的选择如何影响 $\\hat I_{n}$ 的变异性，具体方法是找出使方差最小化和最大化的 $t$ 值，并解释其在 $t\\in[0,1]$ 上的定性行为。最终答案必须是 $\\mathrm{Var}(\\hat I_{n})$ 的闭式表达式。无需四舍五入。",
            "solution": "该问题陈述定义明确、内容完整，并以概率论和蒙特卡洛方法的原理为科学依据。它是随机模拟中的一个标准问题。因此，该问题是有效的，并将推导求解。\n\n目标是推导粗略蒙特卡洛估计量方差 $\\mathrm{Var}(\\hat I_{n})$ 的闭式表达式。该估计量由下式给出：\n$$\n\\hat I_{n}=\\frac{1}{n}\\sum_{i=1}^{n}h(X_{i}),\n$$\n其中 $X_{1}, X_{2}, \\dots, X_{n}$ 是来自 $\\mathrm{Uniform}(0,1)$ 分布的独立同分布 (i.i.d.) 随机变量，被积函数为 $h(x)=\\mathbf{1}\\{x\\le t\\}$，其中 $t\\in[0,1]$ 是一个固定值。\n\n我们首先应用方差的性质。鉴于样本 $X_i$ 是独立同分布的，变换后的随机变量 $Y_i = h(X_i)$ 也是独立同分布的。\n估计量 $\\hat I_n$ 的方差为：\n$$\n\\mathrm{Var}(\\hat I_{n}) = \\mathrm{Var}\\left(\\frac{1}{n}\\sum_{i=1}^{n}h(X_{i})\\right)\n$$\n使用性质 $\\mathrm{Var}(aZ) = a^2\\mathrm{Var}(Z)$，其中 $a = \\frac{1}{n}$ 且 $Z = \\sum_{i=1}^{n}h(X_{i})$，我们得到：\n$$\n\\mathrm{Var}(\\hat I_{n}) = \\frac{1}{n^2}\\mathrm{Var}\\left(\\sum_{i=1}^{n}h(X_{i})\\right)\n$$\n由于随机变量 $h(X_i)$ 是独立的，它们和的方差等于它们方差的和：\n$$\n\\mathrm{Var}\\left(\\sum_{i=1}^{n}h(X_{i})\\right) = \\sum_{i=1}^{n}\\mathrm{Var}(h(X_{i}))\n$$\n此外，由于 $h(X_i)$ 是同分布的，它们的方差都相等。令对所有 $i=1,\\dots,n$，都有 $\\mathrm{Var}(h(X_i)) = \\sigma_h^2$。\n$$\n\\sum_{i=1}^{n}\\mathrm{Var}(h(X_{i})) = n \\cdot \\mathrm{Var}(h(X_1))\n$$\n将此结果代回 $\\mathrm{Var}(\\hat I_{n})$ 的表达式中：\n$$\n\\mathrm{Var}(\\hat I_{n}) = \\frac{1}{n^2} \\left( n \\cdot \\mathrm{Var}(h(X_1)) \\right) = \\frac{1}{n}\\mathrm{Var}(h(X_1))\n$$\n现在，我们必须计算 $\\mathrm{Var}(h(X_1))$。我们使用公式 $\\mathrm{Var}(Z) = \\mathrm{E}[Z^2] - (\\mathrm{E}[Z])^2$。在本例中，$Z = h(X_1) = \\mathbf{1}\\{X_1 \\le t\\}$。\n\n首先，我们计算期望 $\\mathrm{E}[h(X_1)]$。\n随机变量 $h(X_1)$ 只能取两个值：如果 $X_1 \\le t$，则为 $1$；如果 $X_1  t$，则为 $0$。这是一个伯努利随机变量。其期望是它等于 $1$ 的概率。\n$$\np = P(h(X_1) = 1) = P(X_1 \\le t)\n$$\n由于 $X_1 \\sim \\mathrm{Uniform}(0,1)$，其概率密度函数 (PDF) 在 $x \\in [0,1]$ 上为 $f(x) = 1$，在其他情况下为 $0$。其在 $x \\in [0,1]$ 上的累积分布函数 (CDF) 为 $F(x) = x$。对于给定的 $t \\in [0,1]$：\n$$\nP(X_1 \\le t) = \\int_0^t f(x) \\, dx = \\int_0^t 1 \\, dx = t\n$$\n因此，$h(X_1)$ 是一个参数为 $p=t$ 的伯努利随机变量。\n其期望为：\n$$\n\\mathrm{E}[h(X_1)] = t\n$$\n接下来，我们计算 $\\mathrm{E}[(h(X_1))^2]$。由于 $h(X_1)$ 是一个指示函数，其值只能是 $0$ 或 $1$。因此，$(h(X_1))^2$ 与 $h(X_1)$ 相同，因为 $0^2=0$ 且 $1^2=1$。\n$$\n(h(X_1))^2 = h(X_1)\n$$\n这意味着：\n$$\n\\mathrm{E}[(h(X_1))^2] = \\mathrm{E}[h(X_1)] = t\n$$\n现在我们可以计算 $h(X_1)$ 的方差：\n$$\n\\mathrm{Var}(h(X_1)) = \\mathrm{E}[(h(X_1))^2] - (\\mathrm{E}[h(X_1)])^2 = t - t^2 = t(1-t)\n$$\n这是伯努利($t$)随机变量的众所周知方差。\n\n最后，我们将此结果代入 $\\mathrm{Var}(\\hat I_{n})$ 的表达式中：\n$$\n\\mathrm{Var}(\\hat I_{n}) = \\frac{1}{n} \\mathrm{Var}(h(X_1)) = \\frac{t(1-t)}{n}\n$$\n这就是估计量方差作为 $n$ 和 $t$ 的函数的精确闭式表达式。\n\n为了进行解释，我们分析在样本数量 $n$ 固定的情况下，方差 $\\mathrm{Var}(\\hat I_{n})$ 如何随 $t \\in [0,1]$ 变化。变异性由项 $v(t) = t(1-t)$ 决定。这是一个关于 $t$ 的二次函数，表示一个在 $t=0$ 和 $t=1$ 处有根的开口向下的抛物线。\n- **最小化**：在区间 $[0,1]$ 上，$v(t)$ 的最小值出现在端点处。\n  - 在 $t=0$ 时，$v(0) = 0(1-0) = 0$，因此 $\\mathrm{Var}(\\hat I_n) = 0$。在这种情况下，$h(x) = \\mathbf{1}\\{x \\le 0\\}$，对于所有 $x \\in (0,1]$，其值为 $0$。所有样本 $h(X_i)$ 将以概率 $1$ 等于 $0$，因此估计量的方差为零。\n  - 在 $t=1$ 时，$v(1) = 1(1-1) = 0$，因此 $\\mathrm{Var}(\\hat I_n) = 0$。在这种情况下，$h(x) = \\mathbf{1}\\{x \\le 1\\}$，对于所有 $x \\in [0,1]$，其值为 $1$。所有样本 $h(X_i)$ 将等于 $1$，因此估计量的方差同样为零。\n在这两种情况下，被积函数在抽样分布的有效支撑集上是常数，因此没有抽样误差。\n- **最大化**：抛物线 $v(t) = -t^2 + t$ 的最大值出现在其顶点，即 $t = -\\frac{1}{2(-1)} = \\frac{1}{2}$。在该点，值为 $v(\\frac{1}{2}) = \\frac{1}{2}(1-\\frac{1}{2}) = \\frac{1}{4}$。\n  - 方差在 $t=1/2$ 时达到最大值，为 $\\mathrm{Var}(\\hat I_n) = \\frac{1}{4n}$。这对应于伯努利试验 $h(X_i)$ 不确定性最大的情况。当 $t=1/2$ 时，一个样本 $X_i$ 小于或大于 $1/2$ 的可能性是相等的，这意味着 $h(X_i)$ 等可能地为 $1$ 或 $0$。单个样本中的这种最大随机性导致了其均值的最大可能方差。\n\n总之，当问题是确定性的时候（$t=0$ 或 $t=1$），蒙特卡洛估计量的变异性为零；当每个样本的不确定性最高时（$t=1/2$），变异性最大。",
            "answer": "$$\\boxed{\\frac{t(1-t)}{n}}$$"
        },
        {
            "introduction": "理论联系实际是科学研究的核心。在理解了方差的理论基础后，本练习将引导您将理论付诸实践，完成一个端到端的蒙特卡罗积分任务。您需要首先设计并实现一个拒绝抽样算法，以从一个非标准的几何区域（一个三角形）中生成均匀样本，然后利用这些样本来估算指定函数的积分值 ()。这个过程模拟了现实世界中，当积分区域复杂时，如何结合抽样技术和积分方法来解决问题。",
            "id": "3301576",
            "problem": "要求您设计、分析并实现一个拒绝采样算法，用于从集合 $$D=\\{x\\in[0,1]^2:\\,x_1+x_2\\le 1\\}$$ 上的均匀分布 (Unif) 中抽取样本，并使用这些样本进行粗略蒙特卡洛 (MC) 积分。\n\n请从基本原理出发：可测集上均匀分布的定义、拒绝采样的定义，以及将粗略蒙特卡洛积分定义为通过从某个分布中采样来估计积分的方法，该分布的期望与目标积分相关。\n\n构建一个拒绝采样方案，该方案使用来自正方形 $$S=[0,1]^2$$ 上均匀分布的提议样本，接受与否由提议点是否位于 $$D$$ 中决定。请从基本定义出发，推导该方案的接受概率，并证明被接受的样本服从 $$D$$ 上的均匀分布。\n\n实现该算法以生成指定数量的被接受样本（将此数量表示为 $$N_{\\text{acc}}$$），并记录所用的提议总数 $$N_{\\text{prop}}$$。计算经验接受率 $$\\hat{\\alpha}=N_{\\text{acc}}/N_{\\text{prop}}$$。使用被接受的样本 $$\\{X^{(i)}\\}_{i=1}^{N_{\\text{acc}}}$$（其中 $$X^{(i)}\\in D$$），通过将积分与 $$D$$ 上均匀分布下的期望以及 $$D$$ 的面积相关联，采用粗略蒙特卡洛积分法估计积分\n$$I_1=\\int_D x_1 x_2\\,\\mathrm{d}x \\quad\\text{和}\\quad I_2=\\int_D (x_1+x_2)\\,\\mathrm{d}x,$$\n\n您的程序必须实现以下确定性测试套件，并为每个测试用例生成结果：\n\n- 测试用例 $$1$$：随机数生成器 (RNG) 种子 $$12345$$，目标接受样本数 $$N_{\\text{acc}}=1$$。\n- 测试用例 $$2$$：RNG 种子 $$202310$$，目标接受样本数 $$N_{\\text{acc}}=5000$$。\n- 测试用例 $$3$$：RNG 种子 $$42$$，目标接受样本数 $$N_{\\text{acc}}=20000$$。\n\n对于每个测试用例，运行拒绝采样器，直到恰好有 $$N_{\\text{acc}}$$ 个点被接受为止，然后：\n- 计算并返回经验接受率 $$\\hat{\\alpha}$$（浮点数）。\n- 计算并返回 $$I_1$$ 和 $$I_2$$ 的粗略蒙特卡洛估计值（浮点数）。\n- 返回提议总数 $$N_{\\text{prop}}$$（整数）。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果本身也是一个列表 $$[\\hat{\\alpha},\\,\\widehat{I}_1,\\,\\widehat{I}_2,\\,N_{\\text{prop}}]$$。例如，最终输出应类似于 $$[[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot]]$$。本问题不涉及物理单位或角度。所有随机性必须由指定的 RNG 种子控制，以确保可复现性。在边界上使用包含性接受，即当 $$x_1+x_2\\le 1$$ 时接受。",
            "solution": "该问题是有效的，因为它在科学上基于概率论和数值方法，是良定的、客观的、自洽的且计算上可行的。我们接下来将给出一个完整的解法。\n\n本解法将从基本原理出发，首先介绍相关数学和算法概念的基本定义。\n\n**1. 理论框架**\n\n**a. 目标分布**\n目标是从集合 $$D = \\{x \\in [0,1]^2 : x_1+x_2 \\le 1\\}$$ 上的均匀分布中抽取样本。集合 $$D$$ 是平面上的一个直角三角形，其顶点为 $$(0,0)$$、$$(1,0)$$ 和 $$(0,1)$$。该集合的面积，记为 $$\\text{Area}(D)$$，是一个标准的几何结论：\n$$\n\\text{Area}(D) = \\frac{1}{2} \\times \\text{base} \\times \\text{height} = \\frac{1}{2} \\times 1 \\times 1 = \\frac{1}{2}\n$$\n一个在可测集 $$A \\subset \\mathbb{R}^d$$ 上均匀分布的随机变量 $$X$$ 的概率密度函数 (PDF) 定义为：\n$$\nf_X(x) = \\begin{cases} 1/\\text{Area}(A)  \\text{if } x \\in A \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n因此，$$D$$ 上均匀分布的目标 PDF（我们记为 $$p(x)$$）为：\n$$\np(x) = \\begin{cases} 1/(1/2) = 2  \\text{if } x \\in D \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n这可以用指示函数紧凑地写为 $$p(x) = 2 \\cdot \\mathbb{I}_{D}(x)$$。\n\n**b. 拒绝采样**\n拒绝采样是一种从目标分布（其 PDF 为 $$p(x)$$）生成样本的方法，适用于我们可以轻松地从另一个分布，即提议分布（其 PDF 为 $$g(x)$$），中采样的情况。一个必要条件是 $$g(x)$$ 的支撑集必须包含 $$p(x)$$ 的支撑集。此外，必须存在一个常数 $$M  \\infty$$，使得对所有 $$x$$ 都有 $$p(x) \\le M \\cdot g(x)$$。该算法流程如下：\n1. 从提议分布 $$g(x)$$ 中抽取一个样本 $$Y$$。\n2. 从区间 $$[0, 1]$$ 上的均匀分布中抽取一个样本 $$U$$。\n3. 如果 $$U \\le \\frac{p(Y)}{M g(Y)}$$，则接受样本 $$Y$$（即令 $$X=Y$$）。否则，拒绝 $$Y$$ 并返回步骤 1。\n\n**c. 为 $$D$$ 构建采样器**\n问题指定使用正方形 $$S = [0,1]^2$$ 上的均匀分布作为提议分布。$$S$$ 的面积为 $$\\text{Area}(S) = 1^2 = 1$$。因此，提议分布的 PDF $$g(x)$$ 为：\n$$\ng(x) = \\begin{cases} 1/\\text{Area}(S) = 1  \\text{if } x \\in S \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n$$g(x)$$ 的支撑集是 $$S$$，并且由于 $$D \\subset S$$，$$g(x)$$ 的支撑集包含了 $$p(x)$$ 的支撑集。现在我们来寻找常数 $$M$$。我们需要对所有 $$x$$ 满足 $$p(x) \\le M \\cdot g(x)$$。\n- 如果 $$x \\in D$$，那么 $$p(x)=2$$ 且 $$g(x)=1$$。条件是 $$2 \\le M \\cdot 1$$，所以 $$M \\ge 2$$。\n- 如果 $$x \\in S \\setminus D$$，那么 $$p(x)=0$$ 且 $$g(x)=1$$。条件是 $$0 \\le M \\cdot 1$$，这对任何非负的 $$M$$ 都成立。\n- 如果 $$x \\notin S$$，那么 $$p(x)=0$$ 且 $$g(x)=0$$。条件成立。\n满足该不等式在任何地方都成立的最小 $$M$$ 值为 $$M=2$$。\n\n现在，我们分析当 $$M=2$$ 时的接受条件 $$U \\le \\frac{p(Y)}{M g(Y)}$$：\n- 如果提议的样本 $$Y$$ 在 $$D$$ 中，那么 $$p(Y)=2$$ 且 $$g(Y)=1$$。比率为 $$\\frac{p(Y)}{M g(Y)} = \\frac{2}{2 \\cdot 1} = 1$$。条件是 $$U \\le 1$$，这对于一个从 $$\\text{Unif}(0,1)$$ 中抽取的样本 $$U$$ 总是成立的。\n- 如果提议的样本 $$Y$$ 在 $$S \\setminus D$$ 中，那么 $$p(Y)=0$$ 且 $$g(Y)=1$$。比率为 $$\\frac{p(Y)}{M g(Y)} = \\frac{0}{2 \\cdot 1} = 0$$。条件是 $$U \\le 0$$，这几乎必然为假。\n\n这极大地简化了拒绝采样算法：\n1. 从正方形 $$S=[0,1]^2$$ 上的均匀分布中提议一个样本 $$Y=(Y_1, Y_2)$$。这通过独立地抽取 $$Y_1 \\sim \\text{Unif}(0,1)$$ 和 $$Y_2 \\sim \\text{Unif}(0,1)$$ 来实现。\n2. 如果 $$Y \\in D$$（即，如果 $$Y_1 + Y_2 \\le 1$$），则接受 $$Y$$。\n3. 否则，拒绝 $$Y$$ 并重复。\n\n**d. 接受概率与被接受样本的分布**\n在单次试验中接受一个提议样本 $$Y$$ 的概率，记为 $$\\alpha$$，是 $$Y$$ 落入接受区域（即 $$D$$）的概率。\n$$\n\\alpha = P(Y \\in D) = \\int_S \\mathbb{I}_D(y) g(y) \\, \\mathrm{d}y = \\int_D g(y) \\, \\mathrm{d}y\n$$\n由于对于所有 $$y \\in D \\subset S$$ 都有 $$g(y)=1$$，我们得到：\n$$\n\\alpha = \\int_D 1 \\, \\mathrm{d}y = \\text{Area}(D) = \\frac{1}{2}\n$$\n理论接受概率为 $$\\alpha = 0.5$$。获得一个被接受样本所需的提议次数 $$N_{\\text{prop}}$$ 服从成功概率为 $$\\alpha$$ 的几何分布。获得 $$N_{\\text{acc}}$$ 个样本所需的期望提议次数是 $$N_{\\text{acc}} / \\alpha$$。\n\n为了确认被接受的样本 $$X$$ 确实在 $$D$$ 上均匀分布，我们考虑一个被接受的样本落入任意可测子集 $$A \\subseteq D$$ 的概率。\n$$\nP(X \\in A) = P(Y \\in A \\mid Y \\text{ is accepted}) = \\frac{P(Y \\in A \\text{ and } Y \\text{ is accepted})}{P(Y \\text{ is accepted})}\n$$\n由于 $$A \\subseteq D$$，一个样本 $$Y \\in A$$ 总是被接受的。因此，$$P(Y \\in A \\text{ and } Y \\text{ is accepted}) = P(Y \\in A)$$。\n$$\nP(Y \\in A) = \\int_A g(y) \\, \\mathrm{d}y = \\int_A 1 \\, \\mathrm{d}y = \\text{Area}(A)\n$$\n分母是总的接受概率，$$P(Y \\text{ is accepted}) = \\alpha = \\text{Area}(D)$$。因此，\n$$\nP(X \\in A) = \\frac{\\text{Area}(A)}{\\text{Area}(D)}\n$$\n这正是 $$D$$ 上均匀概率测度的定义。因此，得到的样本分布是正确的。\n\n**2. 蒙特卡洛积分**\n\n我们希望估计形式为 $$I = \\int_D h(x) \\, \\mathrm{d}x$$ 的积分。这个积分可以与 $$h(X)$$ 的期望联系起来，其中 $$X$$ 是一个 PDF 为 $$p(x) = \\text{Unif}(D)$$ 的随机变量。\n$$\nE[h(X)] = \\int_D h(x) p(x) \\, \\mathrm{d}x = \\int_D h(x) \\frac{1}{\\text{Area}(D)} \\, \\mathrm{d}x\n$$\n整理后得到恒等式：\n$$\nI = \\int_D h(x) \\, \\mathrm{d}x = \\text{Area}(D) \\cdot E[h(X)]\n$$\n根据大数定律，期望 $$E[h(X)]$$ 可以通过对从 $$p(x)$$ 中抽取的 $$N_{\\text{acc}}$$ 个独立样本 $$\\{X^{(i)}\\}_{i=1}^{N_{\\text{acc}}}$$ 计算 $$h$$ 的样本均值来估计：\n$$\nE[h(X)] \\approx \\frac{1}{N_{\\text{acc}}} \\sum_{i=1}^{N_{\\text{acc}}} h(X^{(i)})\n$$\n将此代入 $$I$$ 的恒等式，得到粗略蒙特卡洛估计量 $$\\widehat{I}$$：\n$$\n\\widehat{I} = \\text{Area}(D) \\cdot \\frac{1}{N_{\\text{acc}}} \\sum_{i=1}^{N_{\\text{acc}}} h(X^{(i)})\n$$\n给定 $$\\text{Area}(D)=1/2$$，对于 $$I_1 = \\int_D x_1 x_2 \\, \\mathrm{d}x$$ 和 $$I_2 = \\int_D (x_1+x_2) \\, \\mathrm{d}x$$ 的具体估计量是：\n- 对于 $$I_1$$，令 $$h_1(x) = x_1 x_2$$。估计量为：\n$$\n\\widehat{I}_1 = \\frac{1}{2} \\cdot \\frac{1}{N_{\\text{acc}}} \\sum_{i=1}^{N_{\\text{acc}}} X^{(i)}_1 X^{(i)}_2\n$$\n- 对于 $$I_2$$，令 $$h_2(x) = x_1 + x_2$$。估计量为：\n$$\n\\widehat{I}_2 = \\frac{1}{2} \\cdot \\frac{1}{N_{\\text{acc}}} \\sum_{i=1}^{N_{\\text{acc}}} (X^{(i)}_1 + X^{(i)}_2)\n$$\n\n**3. 实现计划**\n该实现将包含一个函数，该函数接受一个 RNG 种子和一个目标接受样本数 $$N_{\\text{acc}}$$ 作为输入。\n1. 使用指定的种子初始化一个随机数生成器，以确保可复现性。\n2. 为被接受的样本初始化一个空列表，并将提议计数 $$N_{\\text{prop}}$$ 设置为 $$0$$。\n3. 循环直到被接受的样本数达到 $$N_{\\text{acc}}$$：\n    a. 将 $$N_{\\text{prop}}$$ 加一。\n    b. 通过从 $$\\text{Unif}(0,1)$$ 中抽取两个数来生成一个二维提议点 $$x = (x_1, x_2)$$。\n    c. 如果 $$x_1 + x_2 \\le 1$$，则将点 $$x$$ 添加到被接受样本的列表中。\n4. 循环终止后，计算所需的量：\n    a. 经验接受率：$$\\hat{\\alpha} = N_{\\text{acc}} / N_{\\text{prop}}$$。\n    b. 使用上述推导的公式，对收集到的样本应用，计算蒙特卡洛估计值 $$\\widehat{I}_1$$ 和 $$\\widehat{I}_2$$。\n    c. 提议总数 $$N_{\\text{prop}}$$。\n5. 返回这四个值：$$[\\hat{\\alpha}, \\widehat{I}_1, \\widehat{I}_2, N_{\\text{prop}}]$$。\n主程序将对每个指定的测试用例执行此逻辑，并将结果格式化为单个字符串。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the rejection sampling and Monte Carlo integration as per the problem description.\n    Runs a deterministic test suite and prints the results in the specified format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (RNG seed, Number of accepted samples N_acc)\n        (12345, 1),\n        (202310, 5000),\n        (42, 20000),\n    ]\n\n    all_results = []\n    for seed, N_acc in test_cases:\n        # Initialize the random number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n\n        accepted_samples = []\n        N_prop = 0\n\n        # Run the rejection sampler until exactly N_acc samples are collected.\n        while len(accepted_samples)  N_acc:\n            N_prop += 1\n            # Propose a point from the Uniform distribution on the unit square S = [0,1]^2.\n            # This is done by drawing two independent samples from Unif(0,1).\n            proposal_point = rng.random(size=2)\n            \n            # Acceptance condition: check if the point lies in the target set D.\n            # D = {x in [0,1]^2: x_1 + x_2 = 1}.\n            # The boundary condition x_1 + x_2 = 1 is inclusive as specified.\n            if proposal_point[0] + proposal_point[1] = 1.0:\n                accepted_samples.append(proposal_point)\n\n        # 1. Compute the empirical acceptance rate.\n        # This is the ratio of accepted samples to total proposals.\n        # The theoretical rate is Area(D)/Area(S) = (1/2)/1 = 0.5.\n        alpha_hat = N_acc / N_prop\n\n        # 2. Compute the crude Monte Carlo estimates of the integrals.\n        # The general formula is: I_hat = Area(D) * (1/N_acc) * sum(h(X_i)).\n        # Here, Area(D) = 0.5.\n        area_d = 0.5\n        \n        # Convert the list of samples to a NumPy array for efficient, vectorized calculations.\n        if N_acc > 0:\n            samples_np = np.array(accepted_samples)\n            \n            # For I_1 = integral(x_1 * x_2), the function is h_1(x) = x_1 * x_2.\n            h1_values = samples_np[:, 0] * samples_np[:, 1]\n            mean_h1 = np.mean(h1_values)\n            I1_hat = area_d * mean_h1\n            \n            # For I_2 = integral(x_1 + x_2), the function is h_2(x) = x_1 + x_2.\n            h2_values = samples_np[:, 0] + samples_np[:, 1]\n            mean_h2 = np.mean(h2_values)\n            I2_hat = area_d * mean_h2\n        else: # This branch is not hit by the given test cases but is robust.\n            I1_hat = 0.0\n            I2_hat = 0.0\n\n        # 3. N_prop is the total number of proposals.\n        # It's an integer.\n\n        # Package the results for this test case.\n        case_result = [alpha_hat, I1_hat, I2_hat, N_prop]\n        all_results.append(case_result)\n\n    # Format the final output according to the problem specification.\n    # e.g., [[val,val,val,val],[val,val,val,val]]\n    inner_lists_str = []\n    for res in all_results:\n        # Format each inner list as '[v1,v2,v3,v4]' without extra spaces.\n        inner_str = '[' + ','.join(map(str, res)) + ']'\n        inner_lists_str.append(inner_str)\n    \n    final_output_str = '[' + ','.join(inner_lists_str) + ']'\n\n    # Final print statement in the exact required format.\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "真正掌握一个方法不仅在于了解它如何工作，更在于洞悉其失效的边界条件。本练习将挑战您对蒙特卡罗积分的深层理解，探讨一个关键的“重尾”情景。通过分析一个方差无穷大的被积函数，您将发现标准中心极限定理为何不再适用，以及为何估计误差的收敛速度会异于常规的 $N^{-1/2}$ ()。这个问题揭示了应用蒙特卡罗方法前，检验被积函数可积性（尤其是平方可积性）的重要性。",
            "id": "3301536",
            "problem": "考虑对定义域 $D=[0,1]$ 上的积分 $I=\\int_{0}^{1} h(x)\\,dx$ 进行粗略蒙特卡罗积分。令 $(X_i)_{i\\ge 1}$ 为一个独立同分布序列，其中 $X_i\\sim \\mathrm{Uniform}(0,1)$。粗略蒙特卡罗估计量为 $\\widehat I_n=\\frac{1}{n}\\sum_{i=1}^n h(X_i)$。请你选出关于一个特定的重尾被积函数 $h$ 及其对方法估计和极限定理的影响的正确陈述。\n\n取被积函数 $h:D\\to [1,\\infty)$，定义为 $h(x)=x^{-3/4}$ 对于 $x\\in(0,1]$，且 $h(0)=+\\infty$（在勒贝格意义下解释，因此 $h\\in L^1([0,1])$，但在 $x=0$ 处的点奇异性是可积的）。对于估计量 $\\widehat I_n$，考虑以下陈述：\n\nA. $h\\in L^1([0,1])$ 但 $h\\notin L^2([0,1])$。\n\nB. $\\widehat I_n$ 是无偏的，满足强大数定律（SLLN），并且通常的中心极限定理（CLT）在 $\\sqrt{n}$-归一化和有限渐近方差的情况下适用。\n\nC. $\\mathrm{Var}(h(X_1))=+\\infty$，并且不存在 $\\mathrm{Var}(h(X_1))$ 的一致估计量；特别地，样本方差 $S_n^2=\\frac{1}{n-1}\\sum_{i=1}^n\\big(h(X_i)-\\widehat I_n\\big)^2$ 几乎必然发散到 $+\\infty$，当 $n\\to\\infty$。\n\nD. $\\widehat I_n$ 的涨落服从一个重尾广义极限定理：$n^{1/4}\\big(\\widehat I_n - I\\big)$ 在分布上收敛到一个非退化的 $\\alpha$-稳定律，其尾部指数为 $\\alpha=\\frac{4}{3}$（在中心化之后），而 $\\sqrt{n}\\big(\\widehat I_n - I\\big)$ 在概率上发散。\n\n选择所有正确的陈述。",
            "solution": "用户希望对问题陈述进行细致的验证，然后提供一个完整的解题过程，推导出正确答案并评估所有选项。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n-   待估计的积分为 $I=\\int_{0}^{1} h(x)\\,dx$。\n-   积分域为 $D=[0,1]$。\n-   采样使用独立同分布（i.i.d.）的随机变量序列 $(X_i)_{i\\ge 1}$，其中 $X_i\\sim \\mathrm{Uniform}(0,1)$。\n-   粗略蒙特卡罗估计量由 $\\widehat I_n=\\frac{1}{n}\\sum_{i=1}^n h(X_i)$ 给出。\n-   被积函数为 $h:D\\to [1,\\infty)$，定义为 $h(x)=x^{-3/4}$ 对于 $x\\in(0,1]$ 且 $h(0)=+\\infty$。\n-   问题指明 $h$ 在勒贝格意义下解释，且 $h\\in L^1([0,1])$。\n\n**步骤2：使用提取的已知条件进行验证**\n-   **科学基础：** 该问题牢固地建立在数值积分、概率论和统计学的数学领域之上，特别是关于蒙特卡罗方法。它考察了对 $L^p$ 空间、大数定律（LLN）、中心极限定理（CLT）以及针对重尾分布的广义中心极限定理（稳定律）的理解。所有概念都是标准的并且有严格定义。\n-   **良定性：** 问题定义了一个特定的被积函数、一个抽样分布和一个估计量。然后要求验证关于此设置的几个数学性质的陈述。这些都是具有唯一、可验证答案的良定问题。\n-   **客观性：** 问题使用精确、客观的数学语言陈述。诸如“无偏”、“强大数定律”、“在分布上收敛”和“$\\alpha$-稳定律”等术语具有明确的定义。\n-   **缺陷清单：**\n    1.  **科学/事实不健全性：** 无。该设置是用于说明标准CLT失效和稳定律出现的典型例子。\n    2.  **非形式化或不相关：** 无。问题是完全可以形式化的。\n    3.  **不完整或矛盾的设置：** 无。问题提供了所有必要的信息。$h\\in L^1([0,1])$ 的陈述是一个可以独立验证的前提，证实了设置的一致性。\n    4.  **不切实际或不可行：** 不适用，因为这是一个纯数学问题。数学构造是有效的。\n    5.  **病态或结构不良：** 无。\n    6.  **伪深刻、琐碎或同义反复：** 问题既不琐碎也非同义反复。它需要对可积性条件与概率论中极限定理之间非平凡的相互作用有扎实的理解。\n    7.  **超出科学可验证性范围：** 所有论断在数学上都是可验证的。\n\n**步骤3：结论与行动**\n问题陈述有效。我将继续进行解答。\n\n### 解题推导\n\n令 $Y_i = h(X_i)$ 为采样值。由于 $X_i$ 是独立同分布的 $\\mathrm{Uniform}(0,1)$ 变量，因此 $Y_i$ 也是独立同分布的随机变量。粗略蒙特卡罗估计量是这些变量的样本均值，$\\widehat I_n = \\frac{1}{n}\\sum_{i=1}^n Y_i$。\n\n问题的核心在于分析随机变量 $Y_1 = h(X_1)$ 的矩。第 $k$ 阶矩由 $E[Y_1^k] = E[(h(X_1))^k]$ 给出。根据无意识统计师法则，这等于：\n$$E[(h(X_1))^k] = \\int_0^1 (h(x))^k f_{X_1}(x) dx$$\n由于 $X_1 \\sim \\mathrm{Uniform}(0,1)$，其概率密度函数为 $f_{X_1}(x) = 1$ 对于 $x \\in [0,1]$。因此：\n$$E[(h(X_1))^k] = \\int_0^1 (h(x))^k dx = \\int_0^1 (x^{-3/4})^k dx = \\int_0^1 x^{-3k/4} dx$$\n这是一个形式为 $\\int_0^1 x^{-p} dx$ 的标准 $p$-积分，它收敛当且仅当 $p  1$。在我们的例子中，收敛的条件是 $\\frac{3k}{4}  1$，即 $k  \\frac{4}{3}$。\n\n**1. 一阶矩（期望）：**\n对于 $k=1$，我们有 $p = \\frac{3(1)}{4} = \\frac{3}{4}  1$。积分收敛。\n$$I = E[Y_1] = \\int_0^1 x^{-3/4} dx = \\left[ \\frac{x^{-3/4+1}}{-3/4+1} \\right]_0^1 = \\left[ \\frac{x^{1/4}}{1/4} \\right]_0^1 = [4x^{1/4}]_0^1 = 4(1) - 4(0) = 4$$\n$h(X_1)$ 的期望是有限的，等于 $I=4$。这证实了 $h \\in L^1([0,1])$。\n\n**2. 二阶矩和方差：**\n对于 $k=2$，我们有 $p = \\frac{3(2)}{4} = \\frac{3}{2} > 1$。积分发散。\n$$E[Y_1^2] = \\int_0^1 x^{-3/2} dx = \\left[ \\frac{x^{-1/2}}{-1/2} \\right]_0^1 = [-2x^{-1/2}]_0^1$$\n当 $x \\to 0^+$ 时，此表达式发散到 $+\\infty$。\n因此，$E[Y_1^2] = +\\infty$。\n$Y_1$ 的方差是 $\\mathrm{Var}(Y_1) = E[Y_1^2] - (E[Y_1])^2 = +\\infty - 4^2 = +\\infty$。方差是无穷大的。\n\n有了这些基础结果，我们可以评估每个陈述。\n\n### 逐项分析\n\n**陈述 A: $h\\in L^1([0,1])$ 但 $h\\notin L^2([0,1])$。**\n-   $L^p([0,1])$ 空间由满足 $\\int_0^1 |f(x)|^p dx  \\infty$ 的函数 $f$ 组成。\n-   对于 $p=1$，我们检查 $\\int_0^1 |h(x)| dx$。由于 $h(x) = x^{-3/4} \\ge 1 > 0$，这等于 $\\int_0^1 x^{-3/4} dx$。如上计算，该积分值为 $4$，是有限的。因此，$h \\in L^1([0,1])$。\n-   对于 $p=2$，我们检查 $\\int_0^1 |h(x)|^2 dx = \\int_0^1 (x^{-3/4})^2 dx = \\int_0^1 x^{-3/2} dx$。如上计算，该积分发散。因此，$h \\notin L^2([0,1])$。\n-   该陈述是两个真实事实的合取。\n-   结论：**正确**。\n\n**陈述 B: $\\widehat I_n$ 是无偏的，满足强大数定律（SLLN），并且通常的中心极限定理（CLT）在 $\\sqrt{n}$-归一化和有限渐近方差的情况下适用。**\n-   **无偏性：** 估计量的期望值为 $E[\\widehat I_n] = E[\\frac{1}{n}\\sum_{i=1}^n h(X_i)] = \\frac{1}{n}\\sum_{i=1}^n E[h(X_i)]$。由于对所有 $i$ 都有 $E[h(X_i)] = I = 4$，我们得到 $E[\\widehat I_n] = \\frac{1}{n}(n \\cdot I) = I$。估计量是无偏的。这部分是正确的。\n-   **SLLN：** Kolmogorov 强大数定律指出，对于一个独立同分布的随机变量序列 $Y_i$，如果 $E[|Y_1|]  \\infty$，那么样本均值几乎必然收敛于期望。这里 $Y_i = h(X_i)$。由于 $h(x) \\ge 1$，所以 $|h(X_1)| = h(X_1)$，我们发现 $E[h(X_1)] = 4  \\infty$。因此，SLLN 适用，并且 $\\widehat I_n \\to I$ 几乎必然。这部分是正确的。\n-   **CLT：** 标准的 Lindeberg-Lévy 中心极限定理指出，对于一个具有有限均值 $\\mu$ 和有限方差 $\\sigma^2 > 0$ 的独立同分布随机变量序列 $Y_i$，归一化的和 $\\sqrt{n}(\\frac{1}{n}\\sum Y_i - \\mu)$ 在分布上收敛到一个正态分布 $N(0, \\sigma^2)$。该定理的一个必要条件是方差 $\\sigma^2 = \\mathrm{Var}(Y_1)$ 必须是有限的。我们已经确定 $\\mathrm{Var}(h(X_1)) = +\\infty$。因此，标准 CLT 不适用。\n-   该陈述错误地声称通常的 CLT 适用。\n-   结论：**错误**。\n\n**陈述 C: $\\mathrm{Var}(h(X_1))=+\\infty$，并且不存在 $\\mathrm{Var}(h(X_1))$ 的一致估计量；特别地，样本方差 $S_n^2=\\frac{1}{n-1}\\sum_{i=1}^n\\big(h(X_i)-\\widehat I_n\\big)^2$ 几乎必然发散到 $+\\infty$，当 $n\\to\\infty$。**\n-   **方差：** 如前所示，$\\mathrm{Var}(h(X_1)) = E[(h(X_1))^2] - (E[h(X_1)])^2 = +\\infty$。这部分是正确的。\n-   **样本方差行为：** 令 $Y_i = h(X_i)$。样本方差为 $S_n^2 = \\frac{1}{n-1}\\left(\\sum_{i=1}^n Y_i^2 - n(\\widehat I_n)^2\\right) = \\frac{n}{n-1}\\left(\\frac{1}{n}\\sum_{i=1}^n Y_i^2 - (\\widehat I_n)^2\\right)$。\n    -   当 $n\\to\\infty$ 时，前置因子 $\\frac{n}{n-1} \\to 1$。\n    -   根据 SLLN（陈述 B），$\\widehat I_n \\to I = 4$ 几乎必然。因此 $(\\widehat I_n)^2 \\to 16$ 几乎必然。这一项是收敛且有界的。\n    -   考虑项 $\\frac{1}{n}\\sum_{i=1}^n Y_i^2$。变量 $Z_i = Y_i^2 = (h(X_i))^2$ 是独立同分布且非负的。它们的期望是 $E[Z_i] = E[Y_i^2] = +\\infty$。SLLN 的一个已知扩展指出，如果 $Z_i$ 是期望为 $E[Z_1] = +\\infty$ 的独立同分布非负随机变量，那么 $\\frac{1}{n}\\sum_{i=1}^n Z_i \\to +\\infty$ 几乎必然。\n    -   结合这些结果，$S_n^2$ 的行为类似于 $1 \\cdot (+\\infty - 16)$，它几乎必然发散到 $+\\infty$。\n-   关于 $S_n^2$ 几乎必然发散到 $+\\infty$ 的说法是正确的。这是对一个无穷量的估计量所预期的行为。\n-   结论：**正确**。\n\n**陈述 D: $\\widehat I_n$ 的涨落服从一个重尾广义极限定理：$n^{1/4}\\big(\\widehat I_n - I\\big)$ 在分布上收敛到一个非退化的 $\\alpha$-稳定律，其尾部指数为 $\\alpha=\\frac{4}{3}$（在中心化之后），而 $\\sqrt{n}\\big(\\widehat I_n - I\\big)$ 在概率上发散。**\n-   **广义 CLT：** 由于 $Y_1=h(X_1)$ 的方差是无穷大的，我们必须研究它是否位于某个稳定律的吸引场中。我们分析其尾部概率 $P(Y_1 > y)$。对于 $y \\ge 1$：\n    $$P(Y_1 > y) = P(h(X_1) > y) = P(X_1^{-3/4} > y) = P(X_1  y^{-4/3})$$\n    由于 $X_1 \\sim \\mathrm{Uniform}(0,1)$，此概率为 $P(Y_1 > y) = y^{-4/3}$。\n    这表明 $Y_1$ 分布的尾部是正则变化的，指数为 $\\alpha = 4/3$。\n-   由于 $1  \\alpha  2$，随机变量 $Y_1$ 位于一个 $\\alpha$-稳定律的吸引场中。广义 CLT 适用。对于来自这种分布的独立同分布变量之和，收敛到稳定律的正确归一化因子是 $n^{1/\\alpha}$。\n-   收敛结果是针对中心化的和：$\\frac{1}{n^{1/\\alpha}} \\sum_{i=1}^n (Y_i - E[Y_i]) \\xrightarrow{d} S$，其中 $S$ 是一个 $\\alpha$-稳定随机变量。\n-   当 $\\alpha = 4/3$ 时，归一化因子是 $n^{1/(4/3)} = n^{3/4}$。极限定理为：$\\frac{1}{n^{3/4}} \\sum_{i=1}^n (h(X_i) - I) \\xrightarrow{d} S$。\n-   让我们检查陈述中的表达式：\n    $n^{1/4}(\\widehat I_n - I) = n^{1/4}\\left(\\frac{1}{n}\\sum_{i=1}^n h(X_i) - I\\right) = \\frac{n^{1/4}}{n} \\sum_{i=1}^n (h(X_i) - I) = \\frac{1}{n^{3/4}} \\sum_{i=1}^n (h(X_i) - I)$。\n    这正是正确归一化的量。它在分布上收敛到一个非退化的 $\\alpha$-稳定律，且 $\\alpha=4/3$ 的说法是正确的。\n-   **$\\sqrt{n}$-归一化项的发散性：** 我们可以将 $\\sqrt{n}(\\widehat I_n - I)$ 写成：\n    $$\\sqrt{n}(\\widehat I_n - I) = n^{1/2}(\\widehat I_n - I) = n^{1/2-1/4} \\cdot \\left(n^{1/4}(\\widehat I_n - I)\\right) = n^{1/4} \\cdot Z_n$$\n    其中 $Z_n = n^{1/4}(\\widehat I_n - I)$。我们刚刚证明了 $Z_n$ 在分布上收敛到一个非退化的稳定律 $S$。一个在分布上收敛的随机变量序列是随机有界（紧）的。由于 $n^{1/4} \\to \\infty$ 并且 $Z_n$ 收敛到一个不几乎必然为零的随机变量，乘积 $n^{1/4} Z_n$ 必定在概率上发散。\n-   结论：**正确**。",
            "answer": "$$\\boxed{ACD}$$"
        }
    ]
}