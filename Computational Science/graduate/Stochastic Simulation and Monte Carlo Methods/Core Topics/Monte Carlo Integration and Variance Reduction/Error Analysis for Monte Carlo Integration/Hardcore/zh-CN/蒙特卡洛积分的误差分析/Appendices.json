{
    "hands_on_practices": [
        {
            "introduction": "蒙特卡洛积分的误差收敛性是其核心理论之一，中心极限定理预言了其均方根误差（RMSE）的标准收敛率为 $n^{-1/2}$。本练习提供了一个动手实践的机会，通过模拟来凭经验验证这一基本理论结果。通过在不同的被积函数和概率分布上观察这一收敛率，我们将为蒙特卡洛估计量的“典范”行为建立起坚实的直觉。",
            "id": "3306236",
            "problem": "考虑一个实值随机变量 $X$ 在某个概率分布下，对函数 $f$ 进行蒙特卡洛积分。令 $\\mu = \\mathbb{E}[f(X)]$，并且对于每个整数 $n \\ge 1$，令 $\\hat{\\mu}_n = \\frac{1}{n}\\sum_{i=1}^n f(X_i)$，其中 $\\{X_i\\}_{i=1}^n$ 是 $X$ 的独立同分布副本。将估计量 $\\hat{\\mu}_n$ 的均方根误差 $\\operatorname{RMSE}(n)$ 定义为 $\\operatorname{RMSE}(n) = \\sqrt{\\mathbb{E}\\big[(\\hat{\\mu}_n - \\mu)^2\\big]}$。在整个问题中，假设 $\\mathbb{E}[f(X)^2]$ 是有限的。\n\n您的任务是设计一个程序，通过模拟来估计 $\\operatorname{RMSE}(n)$ 作为 $n$ 的函数的经验衰减率。使用以下基本原理：\n- 独立同分布随机变量的期望线性性。\n- 独立随机变量的方差可加性。\n- 样本均值和均方误差的定义。\n\n算法说明：\n- 对于下面描述的每个测试用例，固定一个样本大小列表 $\\mathcal{N}$ 和一个重复计数 $R$。对于每个 $n \\in \\mathcal{N}$，通过每次重复抽取 $n$ 个 $X$ 的独立同分布样本，在这些样本上评估 $f$ 并求平均值，来生成 $R$ 个独立的蒙特卡洛估计量 $\\hat{\\mu}_n$。为了高效地获得所有 $n \\in \\mathcal{N}$ 的 $\\hat{\\mu}_n$，请使用一个大小为 $R \\times n_{\\max}$ 的样本池，其中 $n_{\\max} = \\max \\mathcal{N}$，并通过对每次重复的每个 $n$ 取前 $n$ 个样本来实现。计算经验均方根误差为 $\\widehat{\\operatorname{RMSE}}(n) = \\sqrt{\\frac{1}{R}\\sum_{r=1}^R (\\hat{\\mu}_n^{(r)} - \\mu)^2}$，其中对于下面的每个测试用例，$\\mu$ 是解析已知的。\n- 通过对所有 $n \\in \\mathcal{N}$ 的 $\\log \\widehat{\\operatorname{RMSE}}(n)$ 与 $\\log n$ 进行普通最小二乘拟合，来估计关系式 $\\widehat{\\operatorname{RMSE}}(n) \\approx C n^{\\alpha}$ 中的缩放指数 $\\alpha$。报告斜率 $\\alpha$。\n\n角度约定：任何出现的 $\\sin(\\cdot)$ 都必须将其参数解释为弧度。\n\n测试套件（三个测试用例）：\n1. 用例 A（高斯分布下的有界被积函数）：\n   - 分布：$X \\sim \\mathcal{N}(0,1)$。\n   - 被积函数：$f(x) = \\exp(-x^2)$。\n   - 解析均值：$\\mu = \\mathbb{E}[\\exp(-X^2)] = \\frac{1}{\\sqrt{1 + 2 \\cdot 1}} = \\frac{1}{\\sqrt{3}}$。\n   - 重复次数：$R = 4096$。\n   - 样本大小：$\\mathcal{N} = \\{100, 400, 1600\\}$。\n   - 随机种子：$s = 13579$。\n\n2. 用例 B（具有有限被积函数方差的重尾抽样）：\n   - 分布：$X \\sim t_{\\nu}$，自由度 $\\nu = 6$。\n   - 被积函数：$f(x) = x^2$。\n   - 解析均值：$\\mu = \\mathbb{E}[X^2] = \\frac{\\nu}{\\nu - 2} = \\frac{6}{4} = 1.5$。\n   - 重复次数：$R = 4096$。\n   - 样本大小：$\\mathcal{N} = \\{100, 400, 1600\\}$。\n   - 随机种子：$s = 24680$。\n\n3. 用例 C（具有混合振荡-线性被积函数的偏态分布）：\n   - 分布：$X \\sim \\operatorname{Exponential}(\\lambda)$，率参数 $\\lambda = 1$（均值为 $1$）。\n   - 被积函数：$f(x) = \\sin(x) + x$，其中 $x$ 以弧度为单位。\n   - 解析均值：由于对于 $X \\sim \\operatorname{Exponential}(1)$，有 $\\mathbb{E}[e^{iX}] = \\frac{1}{1 - i}$，因此我们有 $\\mathbb{E}[\\sin(X)] = \\operatorname{Im}\\big(\\frac{1}{1 - i}\\big) = \\frac{1}{2}$ 且 $\\mathbb{E}[X] = 1$，故 $\\mu = \\frac{1}{2} + 1 = 1.5$。\n   - 重复次数：$R = 4096$。\n   - 样本大小：$\\mathcal{N} = \\{100, 400, 1600\\}$。\n   - 随机种子：$s = 98765$。\n\n输出规格：\n- 对于每个测试用例，计算在 $\\mathcal{N}$ 上 $\\log \\widehat{\\operatorname{RMSE}}(n)$ 与 $\\log n$ 的最小二乘拟合的斜率 $\\alpha$。\n- 您的程序应生成单行输出，其中包含用例 A、B 和 C 的三个斜率，分别为逗号分隔的列表并用方括号括起来，例如 $[\\alpha_A,\\alpha_B,\\alpha_C]$。\n- 输出必须是实数（浮点数）。不应打印其他文本或单位。\n\n所有随机数生成必须在给定指定种子的情况下是确定性的。不需要用户输入。程序必须是自包含的，并且不得访问外部资源。",
            "solution": "任务是为蒙特卡洛积分执行经验误差分析，并估计均方根误差的收敛率。该分析的理论基础依赖于概率论的基本原理，即大数定律和中心极限定理。\n\n设 $X$ 是一个具有给定概率分布的实值随机变量， $f$ 是一个实值函数。我们感兴趣的是计算期望 $\\mu = \\mathbb{E}[f(X)]$。蒙特卡洛方法通过从 $X$ 的分布中抽取 $n$ 个独立同分布（i.i.d.）的样本 $\\{X_1, X_2, \\dots, X_n\\}$，然后计算函数在这些点上的求值结果的样本均值来近似该值：\n$$\n\\hat{\\mu}_n = \\frac{1}{n}\\sum_{i=1}^n f(X_i)\n$$\n这个估计量 $\\hat{\\mu}_n$ 本身就是一个随机变量，因为它的值取决于所抽取的随机样本。为了评估其质量，我们分析其统计特性。\n\n首先，我们确定估计量的偏差。根据期望的线性性，并且由于每个 $X_i$ 都与 $X$ 具有相同的分布：\n$$\n\\mathbb{E}[\\hat{\\mu}_n] = \\mathbb{E}\\left[\\frac{1}{n}\\sum_{i=1}^n f(X_i)\\right] = \\frac{1}{n}\\sum_{i=1}^n \\mathbb{E}[f(X_i)] = \\frac{1}{n}\\sum_{i=1}^n \\mu = \\frac{n\\mu}{n} = \\mu\n$$\n由于 $\\mathbb{E}[\\hat{\\mu}_n] = \\mu$，该估计量是无偏的。\n\n接下来，我们分析估计量的方差。令 $\\sigma_f^2 = \\operatorname{Var}(f(X)) = \\mathbb{E}[f(X)^2] - (\\mathbb{E}[f(X)])^2 = \\mathbb{E}[f(X)^2] - \\mu^2$。问题陈述 $\\mathbb{E}[f(X)^2]$ 是有限的，这保证了 $\\sigma_f^2$ 也是有限的。由于样本 $\\{X_i\\}$ 是独立的，函数值 $\\{f(X_i)\\}$ 也是独立的随机变量。对于独立变量，和的方差是方差的和：\n$$\n\\operatorname{Var}(\\hat{\\mu}_n) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{i=1}^n f(X_i)\\right) = \\frac{1}{n^2}\\operatorname{Var}\\left(\\sum_{i=1}^n f(X_i)\\right) = \\frac{1}{n^2}\\sum_{i=1}^n \\operatorname{Var}(f(X_i)) = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma_f^2 = \\frac{n\\sigma_f^2}{n^2} = \\frac{\\sigma_f^2}{n}\n$$\n问题使用均方根误差（RMSE）来定义估计量的误差，即 $\\operatorname{RMSE}(n) = \\sqrt{\\mathbb{E}[(\\hat{\\mu}_n - \\mu)^2]}$。平方根内的量是均方误差（MSE），它可以分解为方差和偏差的平方：\n$$\n\\operatorname{MSE}(n) = \\mathbb{E}[(\\hat{\\mu}_n - \\mu)^2] = \\operatorname{Var}(\\hat{\\mu}_n) + (\\mathbb{E}[\\hat{\\mu}_n] - \\mu)^2\n$$\n由于估计量是无偏的，其偏差为 $0$。因此，MSE 等于方差：\n$$\n\\operatorname{MSE}(n) = \\frac{\\sigma_f^2}{n}\n$$\n取平方根得到理论上的 RMSE：\n$$\n\\operatorname{RMSE}(n) = \\sqrt{\\frac{\\sigma_f^2}{n}} = \\frac{\\sigma_f}{\\sqrt{n}} = \\sigma_f n^{-1/2}\n$$\n这个结果表明，蒙特卡洛估计量的 RMSE 随样本大小 $n$ 以 $n^{-1/2}$ 的速率衰减。这对应于一般形式 $\\operatorname{RMSE}(n) = C n^{\\alpha}$，其中常数 $C = \\sigma_f$ 且衰减指数 $\\alpha = -1/2$。\n\n任务要求凭经验估计这个指数 $\\alpha$。这是通过多次模拟估计过程来完成的。对于给定集合 $\\mathcal{N}$ 中的每个样本大小 $n$，我们生成 $R$ 个独立的蒙特卡洛估计，记为 $\\{\\hat{\\mu}_n^{(1)}, \\hat{\\mu}_n^{(2)}, \\dots, \\hat{\\mu}_n^{(R)}\\}$。然后我们计算 RMSE 的一个经验估计，记为 $\\widehat{\\operatorname{RMSE}}(n)$，它近似于真实的 $\\operatorname{RMSE}(n)$：\n$$\n\\widehat{\\operatorname{RMSE}}(n) = \\sqrt{\\frac{1}{R}\\sum_{r=1}^R (\\hat{\\mu}_n^{(r)} - \\mu)^2}\n$$\n在这里，$\\mu$ 是 $f(X)$ 的已知解析均值，每个测试用例都已提供。\n\n为了估计 $\\alpha$，我们假设关系式 $\\widehat{\\operatorname{RMSE}}(n) \\approx C n^{\\alpha}$ 对我们的经验数据成立。通过对两边取自然对数，我们得到一个线性关系：\n$$\n\\log(\\widehat{\\operatorname{RMSE}}(n)) \\approx \\log(C) + \\alpha \\log(n)\n$$\n这对应于一个线性方程 $y = m x + c$，其中 $y = \\log(\\widehat{\\operatorname{RMSE}}(n))$，斜率 $m = \\alpha$，自变量 $x = \\log(n)$，截距 $c = \\log(C)$。因此，我们可以通过对所有 $n \\in \\mathcal{N}$ 的数据点集 $\\{(\\log(n), \\log(\\widehat{\\operatorname{RMSE}}(n)))\\}$ 执行普通最小二乘（OLS）线性回归来估计 $\\alpha$。所得回归线的斜率就是我们对 $\\alpha$ 的经验估计。\n\n算法流程如下：\n1. 对于每个测试用例，使用指定的种子初始化一个随机数生成器以确保可复现性。\n2. 生成一个大小为 $R \\times n_{\\max}$ 的单一大型随机样本块，其中 $R$ 是重复次数，$n_{\\max}$ 是 $\\mathcal{N}$ 中的最大样本大小。设该样本矩阵为 $S$。\n3. 将被积函数 $f$ 按元素应用于 $S$，以获得函数值矩阵 $F$。\n4. 对于每个样本大小 $n \\in \\mathcal{N}$：\n   a. 提取 $F$ 的前 $n$ 列，对应于 $R$ 组，每组 $n$ 个函数求值结果。\n   b. 对 $R$ 行中的每一行计算均值，以获得包含 $R$ 个估计值的向量 $\\{\\hat{\\mu}_n^{(r)}\\}_{r=1}^R$。\n   c. 使用提供的公式和已知的真实均值 $\\mu$ 计算经验 RMSE，即 $\\widehat{\\operatorname{RMSE}}(n)$。\n5. 在为所有 $n \\in \\mathcal{N}$ 计算完 $\\widehat{\\operatorname{RMSE}}(n)$ 后，创建两个向量：一个包含样本大小的对数 $\\log(n)$，另一个包含经验 RMSE 的对数 $\\log(\\widehat{\\operatorname{RMSE}}(n))$。\n6. 对这两个向量执行线性回归以找到斜率，该斜率即为 $\\alpha$ 的期望估计值。\n7. 对所有测试用例重复此过程并报告所得的斜率。\n在所有用例中，只要方差 $\\sigma_f^2$ 是有限且非零的，$\\alpha$ 的理论期望值就是 $-0.5$。经验结果应接近此值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import linregress, t as t_dist\n\ndef run_simulation_and_regression(params):\n    \"\"\"\n    Runs a Monte Carlo simulation for a single test case and computes the RMSE decay rate.\n\n    Args:\n        params (dict): A dictionary containing all parameters for the test case.\n\n    Returns:\n        float: The estimated decay exponent alpha.\n    \"\"\"\n    R = params['R']\n    N_list = params['N_list']\n    mu = params['mu']\n    seed = params['seed']\n    integrand = params['integrand']\n    sampler = params['sampler']\n    \n    # Set the random seed for reproducibility using a Generator object\n    rng = np.random.default_rng(seed)\n    \n    n_max = max(N_list)\n    \n    # Generate the base pool of random samples\n    # For scipy.stats distributions, the `random_state` argument accepts a Generator.\n    samples = sampler(rng, (R, n_max))\n    \n    # Evaluate the integrand on all samples\n    f_samples = integrand(samples)\n    \n    rmses = []\n    for n in N_list:\n        # Take the first n samples for each replication\n        f_samples_n = f_samples[:, :n]\n        \n        # Compute the R Monte Carlo estimators\n        mu_hat_n_r = np.mean(f_samples_n, axis=1)\n        \n        # Compute the empirical RMSE\n        # RMSE_hat(n) = sqrt(1/R * sum_{r=1 to R} (mu_hat_n^(r) - mu)^2)\n        rmse_n = np.sqrt(np.mean((mu_hat_n_r - mu)**2))\n        rmses.append(rmse_n)\n        \n    # Perform ordinary least squares fit on the log-log data\n    # log(RMSE_hat(n)) vs log(n)\n    log_N = np.log(N_list)\n    log_rmse = np.log(rmses)\n    \n    # linregress returns (slope, intercept, r_value, p_value, stderr)\n    regression_result = linregress(log_N, log_rmse)\n    \n    # The slope of the log-log plot is the scaling exponent alpha\n    alpha = regression_result.slope\n    return alpha\n\ndef solve():\n    \"\"\"\n    Defines and runs all test cases, then prints the results in the specified format.\n    \"\"\"\n    test_cases = [\n        {\n            # Case A: Bounded integrand, Gaussian law\n            'sampler': lambda rng, size: rng.normal(loc=0.0, scale=1.0, size=size),\n            'integrand': lambda x: np.exp(-x**2),\n            'mu': 1.0 / np.sqrt(3.0),\n            'R': 4096,\n            'N_list': [100, 400, 1600],\n            'seed': 13579\n        },\n        {\n            # Case B: Heavy-tailed sampling, finite integrand variance\n            'sampler': lambda rng, size: t_dist.rvs(df=6, size=size, random_state=rng),\n            'integrand': lambda x: x**2,\n            'mu': 1.5,\n            'R': 4096,\n            'N_list': [100, 400, 1600],\n            'seed': 24680\n        },\n        {\n            # Case C: Skewed law, mixed integrand\n            'sampler': lambda rng, size: rng.exponential(scale=1.0, size=size),\n            'integrand': lambda x: np.sin(x) + x,\n            'mu': 1.5,\n            'R': 4096,\n            'N_list': [100, 400, 1600],\n            'seed': 98765\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        alpha = run_simulation_and_regression(case)\n        results.append(alpha)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "虽然标准蒙特卡洛估计量是无偏的，但许多高级方法（如自归一化重要性采样）会引入有限样本偏差。本练习旨在深入剖析总估计误差的构成，通过经验性地将均方误差（MSE）分解为其两个基本组成部分：方差和偏差的平方。理解这种分解对于正确诊断复杂估计量的性能以及领会其设计中所涉及的权衡至关重要。",
            "id": "3306258",
            "problem": "考虑使用自归一化重要性抽样来估计一个函数在未归一化目标密度下的期望。设实线上的目标密度由未归一化的密度函数 $\\tilde{\\pi}(x) = \\exp\\!\\left(-\\tfrac{x^{4}}{2}\\right)$ 定义，其中归一化常数未知，适用于所有实数 $x$。归一化的目标密度为 $\\pi(x) = \\tilde{\\pi}(x)/Z$，其中归一化常数 $Z$ 为 $Z = \\int_{-\\infty}^{\\infty} \\tilde{\\pi}(x)\\,dx$。我们感兴趣的量是期望 $\\mu = \\mathbb{E}_{\\pi}[f(X)]$，其中 $f(x) = x^{2}$，即：\n$$\n\\mu = \\frac{\\int_{-\\infty}^{\\infty} x^{2}\\,\\tilde{\\pi}(x)\\,dx}{\\int_{-\\infty}^{\\infty} \\tilde{\\pi}(x)\\,dx}.\n$$\n在使用提议密度 $q(x)$ 的重要性抽样中，包含 $N$ 个样本的自归一化重要性抽样估计量为\n$$\n\\hat{\\mu}_{\\mathrm{SNIS}} = \\frac{\\sum_{i=1}^{N} w_{i} f(x_{i})}{\\sum_{i=1}^{N} w_{i}},\n$$\n其中 $x_{i} \\sim q$ 独立同分布，未归一化的重要性权重为 $w_{i} = \\tilde{\\pi}(x_{i})/q(x_{i})$。对于有限的 $N$，该估计量是有偏的，因为它是随机和的比率。\n\n从期望、方差、均方误差和重要性抽样的基本定义出发，编写一个完整、可运行的程序，该程序能够：\n- 对分子和分母的积分使用实线上的数值积分方法，计算基准值 $\\mu$ 的高精度数值近似。\n- 对于下面测试套件中的每个测试用例，使用指定的提议分布 $q$ 和样本大小 $N$，生成 $R$ 个独立的 $\\hat{\\mu}_{\\mathrm{SNIS}}$ 重复实验，并使用固定的伪随机数生成器种子以保证可复现性。对于 $\\{1,\\dots,R\\}$ 中的给定重复实验 $r$，抽取 $N$ 个独立样本 $x_{i}^{(r)} \\sim q$，计算相应的权重 $w_{i}^{(r)} = \\tilde{\\pi}(x_{i}^{(r)})/q(x_{i}^{(r)})$，并构建自归一化估计量 $\\hat{\\mu}_{r} = \\left(\\sum_{i=1}^{N} w_{i}^{(r)} f(x_{i}^{(r)})\\right)\\Big/\\left(\\sum_{i=1}^{N} w_{i}^{(r)}\\right)$。\n- 计算 $R$ 次重复实验的经验均方误差、经验方差和经验偏差的平方：\n  - 经验均方误差为\n    $$\n    \\widehat{\\mathrm{MSE}} = \\frac{1}{R} \\sum_{r=1}^{R} \\left(\\hat{\\mu}_{r} - \\mu\\right)^{2}.\n    $$\n  - 经验方差使用总体归一化，\n    $$\n    \\widehat{\\mathrm{Var}} = \\frac{1}{R} \\sum_{r=1}^{R} \\left(\\hat{\\mu}_{r} - \\bar{\\mu}\\right)^{2}, \\quad \\text{其中} \\quad \\bar{\\mu} = \\frac{1}{R}\\sum_{r=1}^{R} \\hat{\\mu}_{r}.\n    $$\n  - 经验偏差的平方为\n    $$\n    \\widehat{\\mathrm{Bias}}^{2} = \\left(\\bar{\\mu} - \\mu\\right)^{2}.\n    $$\n- 通过报告 $\\widehat{\\mathrm{MSE}}$、$\\widehat{\\mathrm{Var}}$ 和 $\\widehat{\\mathrm{Bias}}^{2}$ 来验证分解（$\\widehat{\\mathrm{Var}} + \\widehat{\\mathrm{Bias}}^{2}$ 的和应该在蒙特卡罗误差范围内与 $\\widehat{\\mathrm{MSE}}$ 数值上匹配）。\n\n使用以下科学合理且多样化的测试用例套件，由 $(N, R, \\text{提议分布}, \\text{自由度}, \\text{种子})$ 指定：\n- 用例 1：$(N = 1, R = 50000, \\text{提议分布} = \\text{正态分布}, \\text{自由度} = \\text{无}, \\text{种子} = 12345)$。这是一个边界情况，说明了最大的有限样本偏差，因为当 $N = 1$ 时，$\\hat{\\mu}_{\\mathrm{SNIS}}$ 简化为 $f(x)$。\n- 用例 2：$(N = 20, R = 10000, \\text{提议分布} = \\text{正态分布}, \\text{自由度} = \\text{无}, \\text{种子} = 23456)$。这是一个使用轻尾提议分布的中等样本情况。\n- 用例 3：$(N = 50, R = 5000, \\text{提议分布} = \\text{学生t分布}, \\text{自由度} = 3, \\text{种子} = 34567)$。此用例使用重尾提议分布来检验尾部的方差减小情况。\n- 用例 4：$(N = 200, R = 2000, \\text{提议分布} = \\text{正态分布}, \\text{自由度} = \\text{无}, \\text{种子} = 45678)$。这是一个针对轻尾提议分布的较大样本情况。\n\n对于提议密度 $q(x)$，使用：\n- 标准正态提议分布，其密度为 $q(x) = (2\\pi)^{-1/2}\\exp\\!\\left(-x^{2}/2\\right)$。\n- 自由度为 $\\nu$ 的学生t分布提议，其密度为\n$$\nq(x) = \\frac{\\Gamma\\!\\left(\\frac{\\nu+1}{2}\\right)}{\\sqrt{\\nu\\pi}\\,\\Gamma\\!\\left(\\frac{\\nu}{2}\\right)}\\left(1 + \\frac{x^{2}}{\\nu}\\right)^{-\\frac{\\nu+1}{2}},\n$$\n适用于所有实数 $x$。\n\n您的程序应生成单行输出，其中包含所有用例的结果，格式为三元组列表：\n$$\n\\big[\\,[\\widehat{\\mathrm{MSE}}_{1},\\,\\widehat{\\mathrm{Var}}_{1},\\,\\widehat{\\mathrm{Bias}}^{2}_{1}],\\,[\\widehat{\\mathrm{MSE}}_{2},\\,\\widehat{\\mathrm{Var}}_{2},\\,\\widehat{\\mathrm{Bias}}^{2}_{2}],\\,[\\widehat{\\mathrm{MSE}}_{3},\\,\\widehat{\\mathrm{Var}}_{3},\\,\\widehat{\\mathrm{Bias}}^{2}_{3}],\\,[\\widehat{\\mathrm{MSE}}_{4},\\,\\widehat{\\mathrm{Var}}_{4},\\,\\widehat{\\mathrm{Bias}}^{2}_{4}]\\,\\big].\n$$\n所有数值结果必须按照上述测试套件的顺序以浮点数形式报告，不得打印任何附加文本。",
            "solution": "该问题被评估为有效。它在科学上基于蒙特卡罗积分和误差分析的原理，问题陈述清晰，指令完整，并以客观、正式的语言表达。没有矛盾、歧义或事实错误。\n\n解决方案通过遵循结构化的、基于原则的方法来实现。\n\n### 步骤 1：基准值计算\n我们感兴趣的量 $\\mu = \\mathbb{E}_{\\pi}[f(X)]$ 的真实值是计算估计量偏差和均方误差的基准。函数为 $f(x) = x^2$，未归一化的目标密度为 $\\tilde{\\pi}(x) = \\exp(-x^4/2)$。根据定义，期望是两个积分的比值：\n$$\n\\mu = \\frac{\\int_{-\\infty}^{\\infty} x^2 \\tilde{\\pi}(x)\\,dx}{\\int_{-\\infty}^{\\infty} \\tilde{\\pi}(x)\\,dx} = \\frac{\\int_{-\\infty}^{\\infty} x^2 \\exp(-x^4/2)\\,dx}{\\int_{-\\infty}^{\\infty} \\exp(-x^4/2)\\,dx}\n$$\n这些积分没有以初等函数表示的简单闭合形式的反导数，但它们与伽马函数 $\\Gamma(z) = \\int_0^\\infty t^{z-1} e^{-t} dt$ 相关。分母积分为 $Z = 2^{-3/4}\\Gamma(1/4)$，分子积分为 $2^{-1/4}\\Gamma(3/4)$。因此，$\\mu = \\sqrt{2}\\Gamma(3/4)/\\Gamma(1/4)$。\n在实现上，一种更直接且高精度的方法是使用数值积分。`scipy.integrate.quad` 函数被用来计算在 $(-\\infty, \\infty)$ 域上的两个定积分。所得数值的比值提供了 $\\mu$ 的高精度近似。\n\n### 步骤 2：蒙特卡罗模拟设计\n对于每个由样本大小 $N$、重复次数 $R$、提议分布 $q(x)$ 和一个随机种子指定的测试用例，我们执行一次蒙特卡罗模拟，以分析自归一化重要性抽样 (SNIS) 估计量的统计特性。整个过程包括对同一估计过程进行 $R$ 次独立的重复实验。为伪随机数生成器使用固定的种子可以确保结果是可复现的。\n\n### 步骤 3：生成单个 SNIS 估计\n在 $R$ 次重复实验中的每一次（索引为 $r \\in \\{1, \\dots, R\\}$），按如下方式生成单个估计值 $\\hat{\\mu}_r$：\n1.  **抽样**：从指定的提议密度 $q(x)$ 中抽取 $N$ 个独立同分布的样本 $\\{x_i^{(r)}\\}_{i=1}^N$。问题使用了两种类型的提议分布：标准正态分布 $\\mathcal{N}(0, 1)$ 和具有指定自由度 $\\nu$ 的学生t分布。\n2.  **权重计算**：对于每个样本 $x_i^{(r)}$，计算一个未归一化的重要性权重 $w_i^{(r)}$。该权重是在样本点处评估的未归一化目标密度与提议密度的比值：\n    $$\n    w_i^{(r)} = \\frac{\\tilde{\\pi}(x_i^{(r)})}{q(x_i^{(r)})} = \\frac{\\exp\\left(-\\frac{(x_i^{(r)})^4}{2}\\right)}{q(x_i^{(r)})}\n    $$\n3.  **估计量构建**：SNIS 估计量 $\\hat{\\mu}_r$ 是使用计算出的权重，对函数值 $f(x_i^{(r)}) = (x_i^{(r)})^2$ 进行加权平均得到的：\n    $$\n    \\hat{\\mu}_{r} = \\frac{\\sum_{i=1}^{N} w_{i}^{(r)} f(x_{i}^{(r)})}{\\sum_{i=1}^{N} w_{i}^{(r)}}\n    $$\n这个过程重复 $R$ 次，以生成一组估计值 $\\{\\hat{\\mu}_1, \\hat{\\mu}_2, \\dots, \\hat{\\mu}_R\\}$。\n\n### 步骤 4：经验误差分析\n利用这 $R$ 个估计值的集合，我们量化估计量的性能。关键的统计指标是从这组估计样本中经验性地计算出来的。\n1.  **经验均值**：计算 $R$ 个估计值的平均值：\n    $$\n    \\bar{\\mu} = \\frac{1}{R} \\sum_{r=1}^{R} \\hat{\\mu}_r\n    $$\n2.  **经验偏差的平方**：经验均值 $\\bar{\\mu}$ 与真实值 $\\mu$ 之间的平方差提供了估计量偏差平方的估计：\n    $$\n    \\widehat{\\mathrm{Bias}}^2 = (\\bar{\\mu} - \\mu)^2\n    $$\n3.  **经验方差**：计算估计值的样本方差（按规定使用 $1/R$ 归一化的总体形式）：\n    $$\n    \\widehat{\\mathrm{Var}} = \\frac{1}{R} \\sum_{r=1}^{R} (\\hat{\\mu}_r - \\bar{\\mu})^2\n    $$\n4.  **经验均方误差 (MSE)**：通过平均每个估计值与真实值 $\\mu$ 之间的平方差来估计 MSE：\n    $$\n    \\widehat{\\mathrm{MSE}} = \\frac{1}{R} \\sum_{r=1}^{R} (\\hat{\\mu}_r - \\mu)^2\n    $$\n这三个量通过基本代数恒等式 $\\widehat{\\mathrm{MSE}} = \\widehat{\\mathrm{Var}} + \\widehat{\\mathrm{Bias}}^2$ 联系在一起。它们的数值计算用于验证此分解，并提供了关于 SNIS 估计量的总误差如何在方差和有限样本偏差之间分配的见解，这取决于 $N$ 和 $q(x)$ 的不同选择。\n\n### 步骤 5：实现细节\n该算法使用 `numpy` 和 `scipy` 库在 Python 中实现。\n-   基准值 $\\mu$ 在开始时计算一次。\n-   一个主循环遍历指定的测试用例。\n-   在每个用例的模拟函数内部，使用 `numpy.random.default_rng` 进行可复现的随机数生成。为了计算效率，对每个重复实验中 $N$ 个样本的内循环使用 `numpy` 数组进行向量化。`scipy.stats` 模块为正态分布和学生t分布这两种提议分布提供了必要的概率密度函数 (`pdf`) 和随机变量采样器 (`rvs`，或在本例中为直接的 `rng` 方法)。\n-   每个用例的最终结果，由三元组 $[\\widehat{\\mathrm{MSE}}, \\widehat{\\mathrm{Var}}, \\widehat{\\mathrm{Bias}}^2]$ 组成，按要求收集并格式化为单个字符串。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import integrate\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Solves the self-normalized importance sampling problem.\n    1. Computes the ground-truth value mu.\n    2. Iterates through test cases to run Monte Carlo simulations.\n    3. For each case, computes and stores the empirical MSE, variance, and squared bias.\n    4. Prints the final results in the specified format.\n    \"\"\"\n\n    # Define the function of interest f(x) = x^2 and the unnormalized target density pi_tilde(x).\n    f_x = lambda x: x**2\n    pi_tilde = lambda x: np.exp(-x**4 / 2)\n\n    def calculate_ground_truth():\n        \"\"\"\n        Computes the ground truth value mu = E_pi[f(X)] using numerical quadrature.\n        \"\"\"\n        numerator_integrand = lambda x: f_x(x) * pi_tilde(x)\n        denominator_integrand = pi_tilde\n\n        numerator_val, _ = integrate.quad(numerator_integrand, -np.inf, np.inf)\n        denominator_val, _ = integrate.quad(denominator_integrand, -np.inf, np.inf)\n\n        if denominator_val == 0:\n            raise ValueError(\"Normalizing constant Z is zero.\")\n            \n        return numerator_val / denominator_val\n\n    def run_simulation(N, R, proposal_type, dof, seed, mu_true):\n        \"\"\"\n        Runs the SNIS simulation for a single test case.\n\n        Args:\n            N (int): Number of samples per replicate.\n            R (int): Number of replicates.\n            proposal_type (str): Type of proposal distribution ('Normal' or 'Student-t').\n            dof (int or None): Degrees of freedom for Student-t proposal.\n            seed (int): Seed for the random number generator.\n            mu_true (float): The ground-truth value of the expectation.\n\n        Returns:\n            list: A list containing [MSE, Var, Bias^2].\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        mu_hat_replicates = np.zeros(R)\n\n        for r in range(R):\n            if proposal_type == 'Normal':\n                x_samples = rng.normal(size=N)\n                q_pdf_vals = stats.norm.pdf(x_samples)\n            elif proposal_type == 'Student-t':\n                x_samples = rng.standard_t(df=dof, size=N)\n                q_pdf_vals = stats.t.pdf(x_samples, df=dof)\n            else:\n                raise ValueError(\"Unknown proposal type specified.\")\n\n            pi_tilde_vals = pi_tilde(x_samples)\n            f_vals = f_x(x_samples)\n            \n            # Unnormalized importance weights\n            weights = pi_tilde_vals / q_pdf_vals\n\n            numerator = np.sum(weights * f_vals)\n            denominator = np.sum(weights)\n            \n            if denominator  0:\n                mu_hat_replicates[r] = numerator / denominator\n            else:\n                # This case is highly unlikely for the given proposals as weights are non-negative.\n                # It would only occur if all weights underflow to zero. We assign NaN, which\n                # might indicate a problem, but will be ignored in stats calculations.\n                mu_hat_replicates[r] = np.nan\n\n        # Filter out any potential NaN values before computing statistics.\n        valid_replicates = mu_hat_replicates[~np.isnan(mu_hat_replicates)]\n        \n        # Empirical mean of the estimates\n        mu_bar = np.mean(valid_replicates)\n        \n        # Empirical Mean Squared Error (MSE)\n        # Note: MSE is computed over all R trials as defined, NaNs become large numbers\n        mse_hat = np.mean((mu_hat_replicates - mu_true)**2)\n\n        # Empirical Variance (with 1/R normalization as specified)\n        var_hat = np.var(valid_replicates)\n        \n        # Squared Empirical Bias\n        bias_sq_hat = (mu_bar - mu_true)**2\n        \n        return [mse_hat, var_hat, bias_sq_hat]\n\n    # Calculate the ground truth value for mu\n    mu_true = calculate_ground_truth()\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 50000, 'Normal', None, 12345),\n        (20, 10000, 'Normal', None, 23456),\n        (50, 5000, 'Student-t', 3, 34567),\n        (200, 2000, 'Normal', None, 45678)\n    ]\n\n    results = []\n    for case in test_cases:\n        N, R, prop_type, dof, seed = case\n        result_triple = run_simulation(N, R, prop_type, dof, seed, mu_true)\n        results.append(result_triple)\n\n    # Final print statement in the exact required format.\n    result_strs = [f\"[{res[0]},{res[1]},{res[2]}]\" for res in results]\n    print(f\"[{','.join(result_strs)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "蒙特卡洛方法标准的 $n^{-1/2}$ 误差收敛率依赖于一个关键假设：被积函数具有有限方差。本练习将探讨当这一假设因被积函数存在奇点而失效时的情景，这种情况会导致估计效率低下甚至不收敛。您将首先从理论上诊断方差发散的条件，然后探索如何通过一种针对性的重要性采样策略来恢复有限方差，从而实现高效估计，这展示了计算科学中一个强大的“诊断-解决”问题循环。",
            "id": "3306284",
            "problem": "考虑在一个超立方体上对一个在原点处具有奇点的球对称被积函数进行积分。设 $d \\in \\mathbb{N}$ 且 $d \\ge 1$，并设 $\\alpha \\in \\mathbb{R}$ 且 $\\alpha \\ge 0$。定义函数 $f:[0,1]^d \\to [0,\\infty)$ 为 $f(x) = \\|x\\|^{-\\alpha}$，其中 $\\|x\\|$ 是 $\\mathbb{R}^d$ 中的欧几里得范数。我们感兴趣的是对 $\\int_{[0,1]^d} f(x)\\,dx$ 进行蒙特卡洛积分，以及当抽样分布为均匀分布或通过重要性采样设计时，估计量的误差性质。\n\n从基本定义开始：\n- 对于可积函数 $f$，在 $[0,1]^d$ 上均匀分布下的蒙特卡洛估计量是 $f$ 的独立评估值的样本均值，其方差（如果有限）等于当 $X$ 在 $[0,1]^d$ 上均匀分布时 $f(X)$ 的方差。\n- 在均匀分布下，$f$ 的二阶矩是 $\\int_{[0,1]^d} f(x)^2\\,dx$。\n- 在有限方差下，蒙特卡洛估计量的误差以 $N^{-1/2}$ 的量级衰减，其中 $N$ 是独立样本的数量，并且均方误差与方差除以 $N$ 成比例。\n\n您必须仅使用以下基本原则来分析 $x=0$ 处的奇点：\n- $\\mathbb{R}^d$ 中的球坐标，其体积元为 $r^{d-1}\\,dr\\,d\\Omega$，其中 $r \\ge 0$，$d\\Omega$ 是单位球面 $S^{d-1}$ 上的表面积元。\n- $S^{d-1}$ 的表面积是一个已知的常数，记为 $S_{d-1}$。\n- 对于任何固定的 $\\varepsilon \\in (0,1)$，积分 $\\int_0^\\varepsilon r^\\beta\\,dr$ 收敛当且仅当 $\\beta > -1$。\n\n您的任务：\n1. 推导关于 $\\alpha$（用 $d$ 表示）的必要和充分阈值，用于：\n   - 在均匀测度下 $f$ 在 $[0,1]^d$ 上的可积性（即，当 $X$ 在 $[0,1]^d$ 上均匀分布时，$f(X)$ 的均值存在）。\n   - 均匀蒙特卡洛估计量方差的有限性（即，二阶矩 $\\int_{[0,1]^d} f(x)^2\\,dx$ 的有限性）。\n   您的推导必须从 $x=0$ 附近的行为出发，使用球坐标和上述基本原则进行论证，不得直接引用最终的阈值公式。\n\n2. 提出一种重要性采样变换，通过将区域分裂为原点周围的一个小球及其补集，来专门处理 $x=0$ 附近的奇点。对于半径为 $\\varepsilon \\in (0,1)$ 的内部区域，限制在正卦限 $[0,1]^d$ 内，定义一个径向重要性采样方案，该方案以与 $r^q$（其中 $q$ 为某个指数）成正比的概率密度对半径 $r \\in [0,\\varepsilon]$ 进行采样，并在单位球面的正卦限上均匀采样方向。基于此方案，为内部区域估计量提供误差分析：\n   - 用 $r$、$q$、$d$ 和 $\\alpha$ 表示重要性权重。\n   - 再次仅使用上面列出的基本原则，推导确保内部区域估计量方差有限性的关于 $q$ 和 $\\alpha$（用 $d$ 表示）的阈值条件。\n   - 确定在可行的情况下能使内部区域估计量方差为零的 $q$ 值，并说明其为可行的关于 $\\alpha$ 的条件。\n\n3. 对于固定的选择 $\\varepsilon = 1/2$，表示内部区域对均值的贡献和内部区域对 $f$ 在均匀采样下二阶矩的贡献的精确表达式，两者都限制在与半径为 $\\varepsilon$ 的球相交的正卦限内。这些精确表达式必须用 $S_{d-1}$、$d$、$\\alpha$ 和 $\\varepsilon$ 表示，并且应考虑到在 $[0,1]^d$ 内方向被限制在正卦限。如果某个量发散，请将其表示为 $+\\infty$。\n\n您的程序必须实现以下测试套件，并为每个案例计算：\n- 一个布尔值，指示在 $[0,1]^d$ 上均匀采样下 $f$ 是否可积。\n- 一个布尔值，指示均匀蒙特卡洛估计量的方差是否有限。\n- 一个布尔值，指示对于指数选择为 $q = d - 1 - \\alpha + \\delta$ 和 $\\delta = (d - \\alpha)/2$（当 $\\alpha  d$ 时；否则此重要性采样布尔值为 false）的内部区域径向重要性采样，理论上的内部区域方差是否有限。\n- 一个浮点数，等于在 $\\{x \\in [0,1]^d: \\|x\\| \\le \\varepsilon\\}$ 上，当 $\\varepsilon = 1/2$ 时的精确内部区域均值贡献；如果发散，则返回正无穷大。\n- 一个浮点数，等于在 $\\{x \\in [0,1]^d: \\|x\\| \\le \\varepsilon\\}$ 上，当 $\\varepsilon = 1/2$ 时，在均匀采样下的精确内部区域二阶矩贡献；如果发散，则返回正无穷大。\n\n使用测试套件：\n- 案例 1：$(d,\\alpha) = (2,0.6)$。\n- 案例 2：$(d,\\alpha) = (2,1.2)$。\n- 案例 3：$(d,\\alpha) = (3,1.4)$。\n- 案例 4：$(d,\\alpha) = (3,1.5)$。\n- 案例 5：$(d,\\alpha) = (2,2.0)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含五个测试用例的结果，格式为逗号分隔的列表的列表，并按上述用例的顺序排列。每个内部列表的形式必须为 $[b_1,b_2,b_3,m,s]$，其中 $b_1$、$b_2$ 和 $b_3$ 是布尔值，$m$ 是内部区域均值的浮点数，$s$ 是内部区域二阶矩的浮点数。使用纯粹的列表的列表表示法，并通过正无穷大表示发散。例如，打印的输出必须类似于“[[True,False,True,0.123,inf],[...],...]”，其中五个内部列表按顺序排列。",
            "solution": "该问题要求分析在超立方体 $[0,1]^d$ 上对积分 $f(x) = \\|x\\|^{-\\alpha}$ 的蒙特卡洛估计量的收敛性质。该分析必须从涉及球坐标和径向积分性质的第一性原理推导得出。\n\n### 第 1 部分：可积性和方差阈值\n\n要积分的函数是 $f(x) = \\|x\\|^{-\\alpha}$，积分域为 $D = [0,1]^d$。该函数的奇点位于 $x=0$。积分 $\\int_D f(x) dx$ 的收敛性完全取决于被积函数在该奇点任意小邻域内的行为。让我们考虑原点附近的一个小区域 $B_\\varepsilon^+ = \\{x \\in [0,1]^d : \\|x\\| \\le \\varepsilon\\}$，其中 $\\varepsilon \\in (0,1)$ 是一个小数。对于这样的 $\\varepsilon$（例如 $\\varepsilon \\le 1$），该区域是半径为 $\\varepsilon$ 的 $d$ 维球体位于正卦限内的部分。在域的其余部分 $D \\setminus B_\\varepsilon^+$ 上的积分是有限的，因为 $f(x)$ 在那里是连续且有界的。因此，$D$ 上的积分收敛性等价于 $B_\\varepsilon^+$ 上的积分收敛性。\n\n我们在 $\\mathbb{R}^d$ 中使用球坐标。一个点 $x$ 由其径向距离 $r = \\|x\\|$ 和单位 $(d-1)$ 维球面 $S^{d-1}$ 上的一组角度 $\\Omega$ 表示。体积元为 $dx = r^{d-1} dr d\\Omega$。函数 $f(x)$ 变为 $f(r) = r^{-\\alpha}$。区域 $B_\\varepsilon^+$ 对应于 $r \\in [0, \\varepsilon]$ 和跨越正卦限的角度 $\\Omega$。单位球面在正卦限内的表面积是 $\\int_{S^{d-1}^+} d\\Omega = S_{d-1} / 2^d$，其中 $S_{d-1}$ 是 $S^{d-1}$ 的总表面积。\n\n**1. $f(x)$ 可积的条件**\n$f(x)$ 的积分由 $I = \\int_{[0,1]^d} \\|x\\|^{-\\alpha} dx$ 给出。其收敛性取决于原点附近的积分：\n$$\n\\int_{B_\\varepsilon^+} f(x) dx = \\int_0^\\varepsilon \\int_{S^{d-1}^+} (r^{-\\alpha}) (r^{d-1} dr d\\Omega) = \\left(\\int_{S^{d-1}^+} d\\Omega\\right) \\left(\\int_0^\\varepsilon r^{-\\alpha} r^{d-1} dr\\right)\n$$\n$$\n= \\frac{S_{d-1}}{2^d} \\int_0^\\varepsilon r^{d-1-\\alpha} dr\n$$\n根据提供的基本原则，积分 $\\int_0^\\varepsilon r^\\beta dr$ 收敛当且仅当指数 $\\beta > -1$。在我们的例子中，$\\beta = d-1-\\alpha$。因此，为了使积分收敛，我们需要：\n$d-1-\\alpha > -1 \\implies d-\\alpha > 0 \\implies \\alpha  d$\n这是 $f(x)$ 在 $[0,1]^d$ 上可积的必要和充分条件。\n\n**2. 方差有限性的条件**\n均匀蒙特卡洛估计量的方差是有限的，当且仅当函数的二阶矩 $\\mathbb{E}[f(X)^2]$ 是有限的。对于在 $[0,1]^d$（体积为 1）上的均匀分布，这等价于积分 $\\int_{[0,1]^d} f(x)^2 dx$ 的收敛性。被积函数是 $f(x)^2 = (\\|x\\|^{-\\alpha})^2 = \\|x\\|^{-2\\alpha}$。\n再次，我们分析原点附近的行为：\n$$\n\\int_{B_\\varepsilon^+} f(x)^2 dx = \\int_0^\\varepsilon \\int_{S_{d-1}^+} (r^{-2\\alpha}) (r^{d-1} dr d\\Omega) = \\frac{S_{d-1}}{2^d} \\int_0^\\varepsilon r^{d-1-2\\alpha} dr\n$$\n使用相同的收敛原则，指数 $\\beta = d-1-2\\alpha$ 必须满足 $\\beta > -1$：\n$d-1-2\\alpha > -1 \\implies d-2\\alpha > 0 \\implies \\alpha  d/2$\n这是均匀蒙特卡洛估计量方差有限的必要和充分条件。\n\n### 第 2 部分：重要性采样分析\n\n我们正在考虑在内部区域 $B_\\varepsilon^+$ 上的一个重要性采样方案。半径 $r$ 从一个概率密度函数 $p_r(r) \\propto r^q$（对于 $r \\in [0,\\varepsilon]$）中采样，方向 $\\Omega$ 从单位球面的正卦限中均匀采样。\n\n归一化的径向 PDF 是 $p_r(r) = C r^q$。我们从 $\\int_0^\\varepsilon C r^q dr = 1$ 中找到 $C$，这给出 $C[\\frac{r^{q+1}}{q+1}]_0^\\varepsilon = 1$。这要求 $q > -1$ 以确保在 $r=0$ 处收敛。那么 $C = \\frac{q+1}{\\varepsilon^{q+1}}$，所以 $p_r(r) = \\frac{q+1}{\\varepsilon^{q+1}} r^q$。\n\n我们感兴趣的积分是 $I_{inner} = \\int_{B_\\varepsilon^+} f(x) dx = \\frac{S_{d-1}}{2^d} \\int_0^\\varepsilon r^{-\\alpha} r^{d-1} dr = \\frac{S_{d-1}}{2^d} \\int_0^\\varepsilon r^{d-1-\\alpha} dr$。基于从 $p_r(r)$ 中采样 $r$ 的该积分的蒙特卡洛估计量基于期望 $E_{p_r}[\\frac{g(r)}{p_r(r)}]$，其中 $g(r)$ 是相对于 $r$ 进行积分的函数。这里，$g(r) = \\frac{S_{d-1}}{2^d} r^{d-1-\\alpha}$。重要性权重是在一个样本上评估的比率。让我们分析方差。如果 $\\int_0^\\varepsilon \\frac{g(r)^2}{p_r(r)} dr$ 是有限的，那么估计量的方差就是有限的。\n\n**1. 重要性权重**\n这个问题可以解释为要求估计量中被平均的项，即权重乘以原始值。期望下的项是 $\\frac{g(r)}{p_r(r)} = \\frac{(\\frac{S_{d-1}}{2^d}) r^{d-1-\\alpha}}{(\\frac{q+1}{\\varepsilon^{q+1}}) r^q} = \\frac{S_{d-1}}{2^d} \\frac{\\varepsilon^{q+1}}{q+1} r^{d-1-\\alpha-q}$。这个表达式代表了每个样本 $(r_i, \\Omega_i)$ 对总和的贡献值。\n\n**2. 重要性采样的方差有限性**\n如果平方项的积分是有限的，则方差是有限的：\n$$\n\\int_0^\\varepsilon \\frac{g(r)^2}{p_r(r)} dr = \\int_0^\\varepsilon \\frac{\\left( \\frac{S_{d-1}}{2^d} r^{d-1-\\alpha} \\right)^2}{\\frac{q+1}{\\varepsilon^{q+1}} r^q} dr = \\left( \\frac{S_{d-1}}{2^d} \\right)^2 \\frac{\\varepsilon^{q+1}}{q+1} \\int_0^\\varepsilon \\frac{r^{2(d-1-\\alpha)}}{r^q} dr\n$$\n$$\n\\propto \\int_0^\\varepsilon r^{2(d-1-\\alpha)-q} dr = \\int_0^\\varepsilon r^{2d-2-2\\alpha-q} dr\n$$\n为了使这个积分收敛，指数 $\\beta = 2d-2-2\\alpha-q$ 必须大于 $-1$：\n$2d-2-2\\alpha-q > -1 \\implies 2(d-1-\\alpha) > q-1$\n\n**3. $q$ 的最优选择**\n如果被平均的量 $\\frac{g(r)}{p_r(r)}$ 是一个常数，则可以实现零方差估计量。这意味着 $p_r(r)$ 必须与 $g(r)$ 成正比。\n$$\np_r(r) \\propto g(r) \\propto r^{d-1-\\alpha}\n$$\n将其与采样形式 $p_r(r) \\propto r^q$ 进行比较，最优选择是 $q = d-1-\\alpha$。\n为了使这个 $q$ 的选择定义一个有效的概率分布，归一化积分 $\\int_0^\\varepsilon r^q dr$ 必须收敛，这要求 $q > -1$。因此，这个最优选择可行的条件是：\n$d-1-\\alpha > -1 \\implies \\alpha  d$\n这与原始积分有限的条件相同。如果积分是无限的，没有任何重要性采样方案可以产生具有有限方差的有限估计。\n\n### 第 3 部分：精确的内部区域表达式\n\n我们给定 $\\varepsilon = 1/2$。内部区域是 $B_{1/2}^+ = \\{x \\in [0,1]^d : \\|x\\| \\le 1/2\\}$。\n\n**1. 内部区域均值贡献**\n均值贡献是 $m = \\int_{B_{1/2}^+} f(x) dx$。根据第 1 部分，这等于：\n$$\nm = \\frac{S_{d-1}}{2^d} \\int_0^{1/2} r^{d-1-\\alpha} dr\n$$\n如果 $\\alpha  d$（即 $d-1-\\alpha > -1$），积分计算为：\n$$\n\\int_0^{1/2} r^{d-1-\\alpha} dr = \\left[ \\frac{r^{d-\\alpha}}{d-\\alpha} \\right]_0^{1/2} = \\frac{(1/2)^{d-\\alpha}}{d-\\alpha}\n$$\n所以，对于 $\\alpha  d$，$m = \\frac{S_{d-1}}{2^d} \\frac{(0.5)^{d-\\alpha}}{d-\\alpha}$。\n如果 $\\alpha \\ge d$，积分发散，且 $m = +\\infty$。\n\n**2. 内部区域二阶矩贡献**\n二阶矩贡献是 $s = \\int_{B_{1/2}^+} f(x)^2 dx$。根据第 1 部分，这等于：\n$$\ns = \\frac{S_{d-1}}{2^d} \\int_0^{1/2} r^{d-1-2\\alpha} dr\n$$\n如果 $\\alpha  d/2$（即 $d-1-2\\alpha > -1$），积分计算为：\n$$\n\\int_0^{1/2} r^{d-1-2\\alpha} dr = \\left[ \\frac{r^{d-2\\alpha}}{d-2\\alpha} \\right]_0^{1/2} = \\frac{(1/2)^{d-2\\alpha}}{d-2\\alpha}\n$$\n所以，对于 $\\alpha  d/2$，$s = \\frac{S_{d-1}}{2^d} \\frac{(0.5)^{d-2\\alpha}}{d-2\\alpha}$。\n如果 $\\alpha \\ge d/2$，积分发散，且 $s = +\\infty$。\n\n### 实现摘要\n\n对于每个测试用例 $(d, \\alpha)$：\n- **可积性 ($b_1$):** 如果 $\\alpha  d$ 则为 True，否则为 False。\n- **有限方差 ($b_2$):** 如果 $\\alpha  d/2$ 则为 True，否则为 False。\n- **重要性采样有限方差 ($b_3$):** 重要性采样方案仅在 $\\alpha  d$ 时定义。对于此方案，我们给定 $q = d-1-\\alpha+\\delta$ 且 $\\delta = (d-\\alpha)/2$。有限方差的条件被推导为 $2(d-1-\\alpha) > q-1$。代入 $q$ 得到 $2(d-1-\\alpha) > (d-1-\\alpha+\\frac{d-\\alpha}{2}) - 1$，简化为 $2(d-\\alpha)-2 > \\frac{3}{2}(d-\\alpha)-2$，即 $\\frac{1}{2}(d-\\alpha) > 0$。这等价于 $\\alpha  d$。因此，如果 $\\alpha  d$，$b_3$ 为 True，否则为 False。\n- **内部均值 ($m$):** 如果 $\\alpha \\ge d$，$m = +\\infty$。否则，$m = \\frac{S_{d-1}}{2^d} \\frac{(0.5)^{d-\\alpha}}{d-\\alpha}$，其中 $S_{d-1} = \\frac{2\\pi^{d/2}}{\\Gamma(d/2)}$。\n- **内部二阶矩 ($s$):** 如果 $\\alpha \\ge d/2$，$s = +\\infty$。否则，$s = \\frac{S_{d-1}}{2^d} \\frac{(0.5)^{d-2\\alpha}}{d-2\\alpha}$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gamma\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases based on the derived theoretical thresholds\n    and formulas for Monte Carlo integration of a singular function.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (2, 0.6),  # Case 1\n        (2, 1.2),  # Case 2\n        (3, 1.4),  # Case 3\n        (3, 1.5),  # Case 4\n        (2, 2.0),  # Case 5\n    ]\n\n    results = []\n    \n    for d, alpha in test_cases:\n        # Task 1: Check integrability and finite variance for uniform sampling.\n        # Condition for integrability: alpha  d\n        b1 = alpha  d\n        \n        # Condition for finite variance: alpha  d / 2\n        b2 = alpha  d / 2\n\n        # Task 2: Check finite variance for the specified importance sampling scheme.\n        # The scheme is defined for alpha  d.\n        # The condition for finite variance of this scheme was derived to be alpha  d.\n        # Therefore, b3 is true if and only if alpha  d.\n        b3 = alpha  d\n\n        # Task 3: Calculate inner-region mean and second moment contributions.\n        epsilon = 0.5\n        \n        # Calculate surface area of (d-1)-sphere, S_{d-1} = 2 * pi^(d/2) / Gamma(d/2)\n        try:\n            sd_minus_1 = 2 * (np.pi**(d/2)) / gamma(d/2)\n        except (ValueError, TypeError):\n            # This case shouldn't be hit with integer d >= 1\n            sd_minus_1 = np.nan\n\n        # Calculate inner-region mean contribution 'm'\n        # Formula: (S_{d-1} / 2^d) * (epsilon^(d-alpha) / (d-alpha))\n        # This is finite if and only if alpha  d.\n        if alpha  d:\n            m = (sd_minus_1 / (2**d)) * (epsilon**(d - alpha)) / (d - alpha)\n        else:\n            m = np.inf\n\n        # Calculate inner-region second moment contribution 's'\n        # Formula: (S_{d-1} / 2^d) * (epsilon^(d-2*alpha) / (d-2*alpha))\n        # This is finite if and only if alpha  d / 2.\n        if alpha  d / 2:\n            s = (sd_minus_1 / (2**d)) * (epsilon**(d - 2 * alpha)) / (d - 2 * alpha)\n        else:\n            s = np.inf\n            \n        # Append the list of results for the current test case.\n        results.append([b1, b2, b3, m, s])\n\n    # Custom string formatting to match the required output format \"[[True,False,True,0.123,inf],...]\"\n    def format_list(lst):\n        items = []\n        for item in lst:\n            if isinstance(item, bool):\n                items.append(str(item))\n            elif isinstance(item, float):\n                if np.isinf(item):\n                    items.append('inf')\n                else:\n                    items.append(str(item))\n            else: # Should not happen based on logic\n                items.append(str(item))\n        return f\"[{','.join(items)}]\"\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(format_list, results))}]\")\n\nsolve()\n```"
        }
    ]
}