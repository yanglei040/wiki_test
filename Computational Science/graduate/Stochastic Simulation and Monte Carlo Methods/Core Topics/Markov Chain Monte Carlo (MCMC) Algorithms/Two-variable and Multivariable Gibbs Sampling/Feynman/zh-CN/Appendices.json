{
    "hands_on_practices": [
        {
            "introduction": "理解吉布斯采样器的效率至关重要。第一个练习旨在建立目标分布属性与采样器性能之间的基础联系。通过推导一个简单的二元高斯分布的自相关函数，您将精确地看到变量间的相关性 $\\rho$ 如何决定采样器的混合速度，这是诊断马尔可夫链蒙特卡洛（MCMC）收敛性的一个关键概念。",
            "id": "3358507",
            "problem": "考虑一个以零中心二元正态分布为目标分布的双变量吉布斯采样器。令 $(X,Y) \\sim \\mathcal{N}(\\boldsymbol{0}, \\Sigma)$，其协方差矩阵为\n$$\n\\Sigma \\;=\\; \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix},\n$$\n其中 $|\\rho| < 1$。吉布斯采样器在每次迭代 $t$ 中执行确定性扫描：首先从给定当前 $Y$ 的 $X$ 的条件分布中抽取 $X$，然后从给定新更新的 $X$ 的 $Y$ 的条件分布中抽取 $Y$。令 $x_t$ 表示在迭代 $t$ 完成完整的双变量吉布斯扫描后 $X$ 的值，因此序列 $\\{x_t\\}_{t \\geq 0}$ 构成一个嵌入在完整吉布斯链中的单变量马尔可夫链。\n\n仅使用多元正态分布的基本性质（特别是条件分布的形式）和马尔可夫链蒙特卡洛（MCMC）的基本定义，推导在平稳状态下 $\\{x_t\\}$ 在滞后 $k$ 时的自相关函数（ACF）。将记为 $\\mathrm{acf}(k) = \\mathrm{Corr}(x_t, x_{t+k})$ 的ACF表示为关于 $\\rho$ 和 $k$ 的封闭形式解析表达式。你的最终答案必须是单一的解析表达式。不需要数值近似。",
            "solution": "用户要求推导由一个以零中心二元正态分布为目标分布的双变量吉布斯采样器所生成的一个分量的序列的自相关函数。\n\n该问题具有科学依据，提法明确，客观，并包含得出唯一解所需的所有信息。这是马尔可夫链蒙特卡洛方法理论中的一个标准问题。因此，该问题是有效的，我们可以进行求解。\n\n目标分布是随机向量 $(X, Y)$ 的二元正态分布，由 $(X,Y) \\sim \\mathcal{N}(\\boldsymbol{0}, \\Sigma)$ 给出，其中均值向量为 $\\boldsymbol{\\mu} = \\boldsymbol{0}$，协方差矩阵为\n$$\n\\Sigma = \\begin{pmatrix} \\sigma_X^2 & \\rho \\sigma_X \\sigma_Y \\\\ \\rho \\sigma_X \\sigma_Y & \\sigma_Y^2 \\end{pmatrix} = \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix}\n$$\n这意味着边际分布是标准正态分布，$X \\sim \\mathcal{N}(0,1)$ 和 $Y \\sim \\mathcal{N}(0,1)$，且 $\\sigma_X^2 = \\sigma_Y^2 = 1$。参数 $\\rho$ 是 $X$ 和 $Y$ 之间的相关系数，约束条件 $|\\rho| < 1$ 确保协方差矩阵是正定的。\n\n首要步骤是确定吉布斯采样器所需的条件分布。对于上面指定的通用二元正态分布，$X$ 给定 $Y=y$ 的条件分布也是正态的：\n$$\nX | Y=y \\sim \\mathcal{N}\\left(\\mu_X + \\frac{\\rho \\sigma_X}{\\sigma_Y}(y - \\mu_Y), \\sigma_X^2(1-\\rho^2)\\right)\n$$\n在我们的特定情况下，由于 $\\mu_X = \\mu_Y = 0$ 和 $\\sigma_X = \\sigma_Y = 1$，条件分布显著简化。\n$X$ 给定 $Y=y$ 的条件分布是：\n$$\np(x|y) \\sim \\mathcal{N}(\\rho y, 1-\\rho^2)\n$$\n根据对称性，$Y$ 给定 $X=x$ 的条件分布是：\n$$\np(y|x) \\sim \\mathcal{N}(\\rho x, 1-\\rho^2)\n$$\n\n吉布斯采样算法以迭代方式进行。令 $(X_t, Y_t)$ 为迭代 $t$ 后链的状态。问题陈述定义了一个确定性扫描，其中为了从状态 $t$ 到达状态 $t+1$，我们首先更新 $X$，然后更新 $Y$。令迭代 $t+1$ 开始时的状态为 $(X_t, Y_t)$。更新步骤如下：\n$1$. 从 $X$ 给定 $Y_t$ 的条件分布中抽取一个中间值 $X'_{t+1}$：$X'_{t+1} \\sim p(X | Y=Y_t)$。\n$2$. 从 $Y$ 给定这个新的 $X'_{t+1}$ 的条件分布中抽取新值 $Y_{t+1}$：$Y_{t+1} \\sim p(Y | X=X'_{t+1})$。\n完成完整扫描后的状态是 $(X'_{t+1}, Y_{t+1})$。问题指定我们感兴趣的序列是 $\\{x_t\\}_{t \\geq 0}$，其中 $x_t$ 是在迭代 $t$ 扫描后 $X$ 分量的值。采用这种记法，我们设 $X_t = X'_t$。因此，从迭代 $t$ 到 $t+1$ 的转换涉及状态序列 $(X_t, Y_t) \\rightarrow (X_{t+1}, Y_{t+1})$，其生成方式如下：\n$$\nX_{t+1} \\sim p(X | Y=Y_t)\n$$\n$$\nY_{t+1} \\sim p(Y | X=X_{t+1})\n$$\n我们寻求平稳序列 $\\{X_t\\}$ 的自相关函数 $\\mathrm{acf}(k) = \\mathrm{Corr}(X_t, X_{t+k})$。在平稳状态下，分布的矩是时不变的。特别地，从目标分布我们可知，对于所有 $t$，$E[X_t] = 0$ 且 $\\mathrm{Var}(X_t) = E[X_t^2] = 1$。\n\n滞后 $k$ 的自相关定义为：\n$$\n\\mathrm{acf}(k) = \\mathrm{Corr}(X_t, X_{t+k}) = \\frac{\\mathrm{Cov}(X_t, X_{t+k})}{\\sqrt{\\mathrm{Var}(X_t) \\mathrm{Var}(X_{t+k})}}\n$$\n由于在平稳状态下 $\\mathrm{Var}(X_t) = \\mathrm{Var}(X_{t+k}) = 1$，自相关等于自协方差：\n$$\n\\mathrm{acf}(k) = \\mathrm{Cov}(X_t, X_{t+k}) = E[X_t X_{t+k}] - E[X_t]E[X_{t+k}] = E[X_t X_{t+k}]\n$$\n为了求得 $E[X_t X_{t+k}]$，我们可以使用重期望法则。首先，让我们建立 $X_{t+1}$ 和 $X_t$ 之间的关系。更新过程可以由一个基于条件分布的生成模型来描述：\n$$\nX_{t+1} = \\rho Y_t + \\varepsilon_{t+1}, \\quad \\text{其中 } \\varepsilon_{t+1} \\sim \\mathcal{N}(0, 1-\\rho^2)\n$$\n并且从上一步（或从 $(X_t, Y_t)$ 的平稳分布），我们知道 $Y_t$ 和 $X_t$ 通过以下方式相关：\n$$\nY_t = \\rho X_t + \\delta_t, \\quad \\text{其中 } \\delta_t \\sim \\mathcal{N}(0, 1-\\rho^2)\n$$\n噪声项 $\\delta_t$ 独立于 $X_t$，而 $\\varepsilon_{t+1}$ 独立于 $Y_t$（因此也独立于 $X_t$ 和 $\\delta_t$）。\n将 $Y_t$ 的表达式代入 $X_{t+1}$ 的表达式中，我们得到：\n$$\nX_{t+1} = \\rho(\\rho X_t + \\delta_t) + \\varepsilon_{t+1} = \\rho^2 X_t + \\rho \\delta_t + \\varepsilon_{t+1}\n$$\n这揭示了序列 $\\{X_t\\}$ 遵循一个一阶自回归过程，即 AR($1$)。让我们利用这个结构来求条件期望 $E[X_{t+1} | X_t]$。\n$$\nE[X_{t+1} | X_t=x_t] = E[\\rho^2 x_t + \\rho \\delta_t + \\varepsilon_{t+1} | X_t=x_t] = \\rho^2 x_t + \\rho E[\\delta_t] + E[\\varepsilon_{t+1}] = \\rho^2 x_t\n$$\n所以，$E[X_{t+1} | X_t] = \\rho^2 X_t$。\n现在，我们可以求出滞后 $k=1$ 时的自协方差：\n$$\nE[X_t X_{t+1}] = E[E[X_t X_{t+1} | X_t]] = E[X_t E[X_{t+1} | X_t]] = E[X_t (\\rho^2 X_t)] = \\rho^2 E[X_t^2] = \\rho^2 \\mathrm{Var}(X_t) = \\rho^2\n$$\n因此，$\\mathrm{acf}(1) = \\rho^2$。\n\n为了求出任意滞后 $k$ 的 ACF，我们通过逐次迭代条件期望来求 $E[X_{t+k} | X_t]$：\n$$\nE[X_{t+k} | X_t] = E[E[X_{t+k} | X_{t+k-1}] | X_t] = E[\\rho^2 X_{t+k-1} | X_t] = \\rho^2 E[X_{t+k-1} | X_t]\n$$\n这给出了一个递归关系。展开这个递归，我们得到：\n$$\nE[X_{t+k} | X_t] = \\rho^2 E[X_{t+k-1} | X_t] = (\\rho^2)^2 E[X_{t+k-2} | X_t] = \\dots = (\\rho^2)^k E[X_t | X_t] = (\\rho^2)^k X_t\n$$\n现在我们可以计算滞后 $k$ 的自协方差：\n$$\n\\mathrm{Cov}(X_t, X_{t+k}) = E[X_t X_{t+k}] = E[E[X_t X_{t+k} | X_t]] = E[X_t E[X_{t+k} | X_t]]\n$$\n代入条件期望的结果：\n$$\n\\mathrm{Cov}(X_t, X_{t+k}) = E[X_t ((\\rho^2)^k X_t)] = (\\rho^2)^k E[X_t^2] = (\\rho^2)^k \\mathrm{Var}(X_t) = (\\rho^2)^k \\cdot 1 = \\rho^{2k}\n$$\n由于在这种情况下自相关等于自协方差，我们得到了最终结果。嵌入的马尔可夫链 $\\{x_t\\}$ 在滞后 $k$ 时的自相关函数是：\n$$\n\\mathrm{acf}(k) = \\rho^{2k}\n$$\n这个结果表明样本之间的相关性呈几何衰减。衰减速率由 $\\rho^2$ 决定。一个接近 $\\pm 1$ 的 $\\rho$ 值意味着目标分布中存在高相关性，这导致慢衰减（$\\rho^2$ 接近 $1$），从而使得吉布斯采样器对于 $X$ 分量的混合速度变慢。相反，当 $\\rho$ 接近 $0$ 时，变量几乎是独立的，吉布斯采样器生成的样本也几乎是独立的（$\\rho^2$ 接近 $0$）。",
            "answer": "$$\n\\boxed{\\rho^{2k}}\n$$"
        },
        {
            "introduction": "吉布斯采样功能强大，但在面对复杂的后验分布（例如多峰分布）时，其性能可能会下降。本练习探讨了“标签切换”问题，这是贝叶斯混合模型中的一个典型挑战，源于后验分布的对称性。通过这个案例研究，您将分析为何一个朴素的吉布斯采样器无法充分探索整个后验分布，并了解用于克服混合不良问题的先进策略。",
            "id": "3358492",
            "problem": "考虑一个用于观测数据 $x_1,\\dots,x_n$ 的贝叶斯有限混合模型，该模型包含 $2$ 个正态分量，其中每个 $x_i \\in \\mathbb{R}$。抽样模型为\n$$\nx_i \\mid z_i,\\mu_1,\\mu_2,\\sigma^2 \\sim \\mathcal{N}\\big(\\mu_{z_i},\\sigma^2\\big), \\quad z_i \\in \\{1,2\\},\n$$\n其中 $z_1,\\dots,z_n$ 是隐分配，$\\sigma^2>0$ 是已知方差，$\\mu_1,\\mu_2 \\in \\mathbb{R}$ 是分量均值。混合权重 $\\pi \\in (0,1)$ 满足\n$$\n\\mathbb{P}(z_i=1\\mid \\pi) = \\pi,\\quad \\mathbb{P}(z_i=2\\mid \\pi) = 1-\\pi,\n$$\n且先验是对称的：\n$$\n\\pi \\sim \\text{Beta}(\\alpha,\\alpha),\\quad \\mu_1 \\stackrel{\\text{ind}}{\\sim} \\mathcal{N}(0,\\tau^2),\\quad \\mu_2 \\stackrel{\\text{ind}}{\\sim} \\mathcal{N}(0,\\tau^2),\n$$\n其中 $\\alpha>0$ 和 $\\tau^2>0$ 是固定的超参数。一个数据增广吉布斯采样器周期性地更新：给定 $(\\pi,\\mu_1,\\mu_2)$ 和 $x_{1:n}$ 更新 $(z_1,\\dots,z_n)$，然后给定 $(z_{1:n},x_{1:n})$ 更新 $(\\mu_1,\\mu_2)$，再给定 $z_{1:n}$ 更新 $\\pi$，并重复此过程。假设观测数据呈现出两个经验上分离良好的簇，即对于某个 $a>0$，在接近 $-a$ 和 $+a$ 的两个不同位置参数下的似然远比单簇解释更受青睐，且先验如上所述。\n\n根据贝叶斯定理和吉布斯采样（从全条件分布中抽样以保持目标后验不变）的基本定义，分析在该给定对称性下，此吉布斯采样器的后验结构和混合行为。选择所有正确的陈述。\n\nA. 由于先验在 $(\\mu_1,\\mu_2)$ 上是可交换的，并且似然仅通过对 $(\\{\\mu_1,\\mu_2\\},\\{z_i\\})$ 依赖于标签，因此联合后验在重标签映射 $(\\mu_1,\\mu_2,\\pi,z_{1:n}) \\mapsto (\\mu_2,\\mu_1,1-\\pi,\\tilde z_{1:n})$ (其中 $\\tilde z_i = 3-z_i$) 下是不变的。对于分离良好的簇，$(\\mu_1,\\mu_2)$ 的边缘后验是双峰的，具有两个由标签切换联系起来的对称众数。\n\nB. 在大 $n$ 和分离良好的簇的情况下，单点数据增广吉布斯采样器在两个标签之间混合迅速，因为每次扫描都会更新所有的 $z_i$，因此可以有效地以一个远离 $0$ 的概率将分配向量翻转到相反的标签。\n\nC. 通过拒绝任何违反可识别性约束 $\\mu_1 \\le \\mu_2$ 的提议更新来强制执行该约束，既能消除标签切换引起的多峰性，又能保持 $(\\mu_1,\\mu_2,\\pi,z_{1:n})$ 上的无约束后验不变。\n\nD. 一种回火转移或并行回火方案，它引入一个逆温度参数 $\\beta \\in (0,1]$，在 $\\beta<1$ 时使似然函数扁平化，同时保持在温度内部和温度之间转移的细致平衡，可以显著增加在 $\\beta=1$ 的基础链中标签切换的频率，而不改变其不变分布。\n\nE. 通过交换分量标签来对保存的抽样进行后验重标签，以强制执行顺序 $\\mu_1 \\le \\mu_2$，可以为任何满足 $f(\\mu_1,\\mu_2)=f(\\mu_2,\\mu_1)$ 的可交换函数 $f(\\mu_1,\\mu_2)$ 的期望提供有效估计，但这种后处理不会改变底层马尔可夫链的混合性质。\n\nF. 通过解析地边缘化掉 $(\\pi,\\mu_1,\\mu_2)$ 以获得一个关于 $z_{1:n}$ 的吉布斯采样器，可以消除标签切换的对称性，并在给定的对称先验下产生一个关于 $z_{1:n}$ 的单峰后验。\n\n选择所有适用项。",
            "solution": "下面对问题陈述和提供的选项进行分析。\n\n### 问题陈述的验证\n\n**第1步：提取已知条件**\n-   **模型：** 包含 $k=2$ 个正态分量的贝叶斯有限混合模型。\n-   **数据：** $x_1, \\dots, x_n$，其中 $x_i \\in \\mathbb{R}$。\n-   **抽样模型（似然）：** $x_i \\mid z_i, \\mu_1, \\mu_2, \\sigma^2 \\sim \\mathcal{N}(\\mu_{z_i}, \\sigma^2)$，其中 $z_i \\in \\{1, 2\\}$ 是一个隐分配变量。\n-   **已知参数：** 方差 $\\sigma^2 > 0$ 是已知的。\n-   **混合权重：** $\\mathbb{P}(z_i = 1 \\mid \\pi) = \\pi$ 且 $\\mathbb{P}(z_i = 2 \\mid \\pi) = 1 - \\pi$，对于 $\\pi \\in (0, 1)$。\n-   **先验：**\n    -   $\\pi \\sim \\text{Beta}(\\alpha, \\alpha)$，对于固定的 $\\alpha > 0$。\n    -   $\\mu_1 \\stackrel{\\text{ind}}{\\sim} \\mathcal{N}(0, \\tau^2)$，对于固定的 $\\tau^2 > 0$。\n    -   $\\mu_2 \\stackrel{\\text{ind}}{\\sim} \\mathcal{N}(0, \\tau^2)$。\n    -   $\\pi, \\mu_1, \\mu_2$ 上的先验是相互独立的。\n-   **算法：** 一个数据增广吉布斯采样器，周期性地更新：\n    1.  给定 $(\\pi, \\mu_1, \\mu_2)$ 和数据，更新 $(z_1, \\dots, z_n)$。\n    2.  给定 $(z_1, \\dots, z_n)$ 和数据，更新 $(\\mu_1, \\mu_2)$。\n    3.  给定 $(z_1, \\dots, z_n)$，更新 $\\pi$。\n-   **假设：** 数据 $x_{1:n}$ 呈现出两个经验上分离良好的簇。\n-   **任务：** 分析该吉布斯采样器的后验结构和混合行为。\n\n**第2步：使用提取的已知条件进行验证**\n-   **科学依据：** 该问题描述了一个标准的贝叶斯高斯混合模型。指定的先验（正态、贝塔）和数据增广吉布斯采样策略是贝叶斯统计和机器学习中的基础且广泛使用的方法。没有违反科学或数学原理。\n-   **良态问题：** 这是一个良态问题。模型通过适定的先验被完全指定，确保了适定的后验分布。任务是分析这个标准模型和采样器的已知属性和行为，这在统计理论中是一个有意义且可解决的问题。\n-   **客观性：** 问题以精确、客观和标准的贝叶斯统计术语陈述。“分离良好的簇”的假设是研究混合模型行为时一个常见且清晰的理论条件。\n\n**第3步：结论和行动**\n问题陈述是有效的。它在科学上是合理的、良态的且客观的。没有歧义、矛盾或谬误。我现在将继续解答。\n\n### 推导与选项分析\n\n这个问题的核心是“标签切换”现象，它源于混合分量的不可识别性。如果其他参数也相应地进行排列，那么模型的似然函数对于分量标签的排列是不变的。\n\n令 $\\theta = (\\pi, \\mu_1, \\mu_2)$ 为边缘似然（在积分掉 $z_{1:n}$ 之后）的参数向量。单个观测的似然是 $p(x_i | \\theta) = \\pi \\mathcal{N}(x_i | \\mu_1, \\sigma^2) + (1-\\pi) \\mathcal{N}(x_i | \\mu_2, \\sigma^2)$。\n如果我们定义一个排列后的参数向量 $\\theta' = (1-\\pi, \\mu_2, \\mu_1)$，似然函数保持不变：\n$p(x_i | \\theta') = (1-\\pi) \\mathcal{N}(x_i | \\mu_2, \\sigma^2) + \\pi \\mathcal{N}(x_i | \\mu_1, \\sigma^2) = p(x_i | \\theta)$。\n由于完整似然函数是 $L(\\theta | x_{1:n}) = \\prod_i p(x_i | \\theta)$，它对于这个排列也是不变的。\n\n先验分布是 $p(\\theta) = p(\\pi) p(\\mu_1) p(\\mu_2)$。$\\mu_1, \\mu_2$ 上的先验是 $p(\\mu_1, \\mu_2) = \\mathcal{N}(\\mu_1 | 0, \\tau^2) \\mathcal{N}(\\mu_2 | 0, \\tau^2)$，它是对称的：$p(\\mu_1, \\mu_2) = p(\\mu_2, \\mu_1)$。$\\pi$ 上的先验是 $p(\\pi) = \\text{Beta}(\\pi | \\alpha, \\alpha)$，它关于 $0.5$ 对称，意味着 $p(\\pi) = p(1-\\pi)$。因此，先验密度在这个排列下也是不变的：$p(\\theta') = p(\\theta)$。\n\n由于后验与似然和先验的乘积成正比，$p(\\theta | x_{1:n}) \\propto L(\\theta | x_{1:n}) p(\\theta)$，所以后验也是不变的：$p(\\theta | x_{1:n}) = p(\\theta' | x_{1:n})$。这意味着如果 $(\\hat{\\pi}, \\hat{\\mu}_1, \\hat{\\mu}_2)$ 是后验的一个众数，那么 $(1-\\hat{\\pi}, \\hat{\\mu}_2, \\hat{\\mu}_1)$ 也必定是另一个众数。\n\n**A. 由于先验在 $(\\mu_1,\\mu_2)$ 上是可交换的，并且似然仅通过对 $(\\{\\mu_1,\\mu_2\\},\\{z_i\\})$ 依赖于标签，因此联合后验在重标签映射 $(\\mu_1,\\mu_2,\\pi,z_{1:n}) \\mapsto (\\mu_2,\\mu_1,1-\\pi,\\tilde z_{1:n})$ (其中 $\\tilde z_i = 3-z_i$) 下是不变的。对于分离良好的簇，$(\\mu_1,\\mu_2)$ 的边缘后验是双峰的，具有两个由标签切换联系起来的对称众数。**\n\n我们来检查数据和参数的完整联合分布 $p(x_{1:n}, z_{1:n}, \\mu_1, \\mu_2, \\pi)$ 的不变性。它可以被分解为 $p(x_{1:n}|z_{1:n},\\mu_1,\\mu_2)p(z_{1:n}|\\pi)p(\\pi)p(\\mu_1)p(\\mu_2)$。\n我们应用这个变换：$(\\mu_1,\\mu_2,\\pi,z_{1:n}) \\mapsto (\\mu_1',\\mu_2',\\pi',\\tilde{z}_{1:n}) = (\\mu_2,\\mu_1,1-\\pi,\\tilde{z}_{1:n})$。\n1.  **似然：** $p(x_{1:n}| \\tilde{z}_{1:n}, \\mu_1', \\mu_2') = \\prod_i \\mathcal{N}(x_i | \\mu'_{\\tilde{z}_i}, \\sigma^2)$。如果 $z_i=1$，那么 $\\tilde{z}_i=2$，所以均值是 $\\mu'_2 = \\mu_1$。如果 $z_i=2$，那么 $\\tilde{z}_i=1$，所以均值是 $\\mu'_1 = \\mu_2$。在两种情况下，均值都是 $\\mu_{z_i}$。所以 $p(x_{1:n}|\\tilde{z}_{1:n},\\mu_2,\\mu_1) = p(x_{1:n}|z_{1:n},\\mu_1,\\mu_2)$。\n2.  **分配先验：** $p(\\tilde{z}_{1:n}|\\pi') = \\prod_i (\\pi')^{\\mathbb{I}(\\tilde{z}_i=1)} (1-\\pi')^{\\mathbb{I}(\\tilde{z}_i=2)} = \\prod_i (1-\\pi)^{\\mathbb{I}(z_i=2)} (\\pi)^{\\mathbb{I}(z_i=1)} = p(z_{1:n}|\\pi)$。\n3.  **参数先验：** $p(\\pi')p(\\mu_1')p(\\mu_2') = p(1-\\pi)p(\\mu_2)p(\\mu_1)$。由于对称的Beta先验和独立同分布的正态先验，这等于 $p(\\pi)p(\\mu_1)p(\\mu_2)$。\n\n联合分布是不变的，这意味着完整后验 $p(\\mu_1, \\mu_2, \\pi, z_{1:n} | x_{1:n})$ 在这个映射下是不变的。将 $\\pi$ 和 $z_{1:n}$ 边缘化掉，得到边缘后验 $p(\\mu_1, \\mu_2 | x_{1:n})$，它必须是对称的，即 $p(\\mu_1, \\mu_2 | x_{1:n}) = p(\\mu_2, \\mu_1 | x_{1:n})$。对于分离良好的簇，数据将强烈支持均值的不同值，比如在位置 $a$ 和 $b$ 附近（$a \\neq b$）。这在 $(\\mu_1, \\mu_2) = (a, b)$ 附近产生一个后验众数。由于对称性，必定在 $(b, a)$ 附近存在一个对应的众数。因此，$(\\mu_1, \\mu_2)$ 的边缘后验是双峰的。\n**结论：正确。**\n\n**B. 在大 $n$ 和分离良好的簇的情况下，单点数据增广吉布斯采样器在两个标签之间混合迅速，因为每次扫描都会更新所有的 $z_i$，因此可以有效地以一个远离 $0$ 的概率将分配向量翻转到相反的标签。**\n\n吉布斯采样器从它们的全条件分布中更新变量。考虑状态接近一个后验众数：$(\\mu_1, \\mu_2) \\approx (a,b)$，其中 $a$ 和 $b$ 是两个分离良好的簇的中心。当为第一个簇中的一个数据点 $x_i$ (即 $x_i \\approx a$) 更新 $z_i$ 时，条件概率为 $\\mathbb{P}(z_i=1|\\dots) \\propto \\pi \\mathcal{N}(x_i|a, \\sigma^2)$ 和 $\\mathbb{P}(z_i=2|\\dots) \\propto (1-\\pi) \\mathcal{N}(x_i|b, \\sigma^2)$。由于簇是分离良好的，$\\mathcal{N}(x_i|a, \\sigma^2) \\gg \\mathcal{N}(x_i|b, \\sigma^2)$，所以 $\\mathbb{P}(z_i=1|\\dots) \\approx 1$。要切换到另一个标签的众数，第一个簇的所有 $z_i$ 都必须翻转到标签2，第二个簇的所有 $z_i$ 都必须翻转到标签1。单次吉布斯扫描独立地更新每个 $z_i$（给定参数），因此所有 $z_i$ 都翻转到“错误”分量的概率小到可以忽略不计。采样器会被困在一个众数中，跨越分隔它们的低概率壁垒转换到另一个众数的概率极低。因此，采样器混合得非常慢。\n**结论：错误。**\n\n**C. 通过拒绝任何违反可识别性约束 $\\mu_1 \\le \\mu_2$ 的提议更新来强制执行该约束，既能消除标签切换引起的多峰性，又能保持 $(\\mu_1,\\mu_2,\\pi,z_{1:n})$ 上的无约束后验不变。**\n\n通过对吉布斯更新进行拒绝抽样来施加约束 $\\mu_1 \\le \\mu_2$ 会修改采样器的转移核。原始吉布斯采样器旨在将无约束后验 $p(\\theta|x_{1:n})$ 作为其平稳分布。修改后的采样器的状态空间被限制在子空间 $\\mathcal{S} = \\{(\\mu_1,\\mu_2,\\pi,z_{1:n}) : \\mu_1 \\le \\mu_2 \\}$。这个新马尔可夫链的不变分布是该子空间上的条件后验，即 $p(\\theta|x_{1:n}, \\theta \\in \\mathcal{S})$，它与 $p(\\theta|x_{1:n})\\mathbb{I}(\\mu_1 \\le \\mu_2)$ 成正比。这与无约束后验是不同的分布。声称该过程“保持无约束后验...不变”是错误的。该过程改变了采样器的不变分布。\n**结论：错误。**\n\n**D. 一种回火转移或并行回火方案，它引入一个逆温度参数 $\\beta \\in (0,1]$，在 $\\beta<1$ 时使似然函数扁平化，同时保持在温度内部和温度之间转移的细致平衡，可以显著增加在 $\\beta=1$ 的基础链中标签切换的频率，而不改变其不变分布。**\n\n并行回火（或Metropolis耦合MCMC）并行运行多个马尔可夫链，目标是幂次后验 $p_\\beta(\\theta|x_{1:n}) \\propto [L(\\theta|x_{1:n})]^\\beta p(\\theta)$，对应一系列逆温度 $1 = \\beta_1 > \\beta_2 > \\dots > \\beta_M > 0$。对于 $\\beta < 1$，后验景观被扁平化，降低了众数之间的概率壁垒。处于高温（低 $\\beta$）的链可以轻易地在标签切换的众数之间跳跃。该算法包括在相邻温度的链之间进行交换移动，这些移动以一个Metropolis-Hastings概率被接受或拒绝，该概率为联合系统维持细致平衡。这使得冷链（$\\beta=1$）能够访问由热链发现的其他众数的状态。这个过程是一个有效的MCMC算法，并且根据其构造，在 $\\beta=1$ 处的链的边际平稳分布就是原始的目标后验 $p(\\theta|x_{1:n})$。该方法专门用于改善多峰分布中的混合情况，它通过增加众数之间跳跃（标签切换）的频率来实现这一点。\n**结论：正确。**\n\n**E. 通过交换分量标签来对保存的抽样进行后验重标签，以强制执行顺序 $\\mu_1 \\le \\mu_2$，可以为任何满足 $f(\\mu_1,\\mu_2)=f(\\mu_2,\\mu_1)$ 的可交换函数 $f(\\mu_1,\\mu_2)$ 的期望提供有效估计，但这种后处理不会改变底层马尔可夫链的混合性质。**\n\n这个陈述有两部分。\n1. ‘这种后处理不会改变底层马尔可夫链的混合性质’：这是正确的。后处理应用于链保存的输出。它对马尔可夫链本身生成样本的过程没有影响。如果链混合得很差并卡在一个众数中，后处理无法解决这个问题。\n2. ‘为任何可交换函数 $f(\\mu_1,\\mu_2)$ 的期望提供有效估计’：一个可交换函数是像 $f(\\mu_1, \\mu_2) = \\mu_1+\\mu_2$ 或 $f(\\mu_1, \\mu_2) = \\mu_1^2 + \\mu_2^2$ 这样的函数，其中 $f(\\mu_1, \\mu_2) = f(\\mu_2, \\mu_1)$。真实期望是 $\\mathbb{E}[f] = \\int f(\\mu_1, \\mu_2) p(\\mu_1, \\mu_2|x_{1:n}) d\\mu_1 d\\mu_2$。因为 $f$ 和 $p(\\mu_1, \\mu_2|x_{1:n})$ 在交换 $\\mu_1$ 和 $\\mu_2$ 时都是对称的，所以在整个空间上的期望等于在其中一个众数上的期望（例如，$\\mu_1 \\le \\mu_2$ 的区域），只差一个归一化常数。实际上，即使采样器停留在一个众数中，$f$ 的MCMC平均值也将是正确的，因为来自另一个众数的样本损失被 $f$ 的对称性精确补偿了。对于这类函数，后处理是不必要的，但对估计没有坏处。对于不可交换的函数（例如，$f(\\mu_1, \\mu_2) = \\mu_1$），这就不成立。该陈述被谨慎地限制在可交换函数上，对此它是正确的。\n**结论：正确。**\n\n**F. 通过解析地边缘化掉 $(\\pi,\\mu_1,\\mu_2)$ 以获得一个关于 $z_{1:n}$ 的吉布斯采样器，可以消除标签切换的对称性，并在给定的对称先验下产生一个关于 $z_{1:n}$ 的单峰后验。**\n\n坍缩吉布斯采样器作用于分配的边缘后验 $p(z_{1:n}|x_{1:n})$。这与 $p(x_{1:n}|z_{1:n}) p(z_{1:n})$ 成正比。我们需要检查对称性是否被消除。\n令 $\\tilde{z}_{1:n}$ 为标签交换后的分配向量，$\\tilde{z}_i = 3-z_i$。\n分配的积分先验是 $p(z_{1:n}) = \\int p(z_{1:n}|\\pi)p(\\pi)d\\pi = \\frac{B(n_1+\\alpha, n_2+\\alpha)}{B(\\alpha,\\alpha)}$，其中 $n_k$ 是分配到分量 $k$ 的计数。由于 $B(a,b)=B(b,a)$，并且交换标签意味着交换 $n_1$ 和 $n_2$，所以 $p(\\tilde{z}_{1:n}) = p(z_{1:n})$。分配的先验是对称的。\n边缘似然是 $p(x_{1:n}|z_{1:n}) = \\int p(x_{1:n}|z_{1:n}, \\mu_1, \\mu_2)p(\\mu_1,\\mu_2)d\\mu_1 d\\mu_2$。由于 $\\mu_1, \\mu_2$ 上的独立同分布先验，这可以分解为两个形式相同的积分的乘积，一个是对分量1中的数据积分，另一个是对分量2中的数据积分。交换标签 $z_{1:n} \\to \\tilde{z}_{1:n}$ 等同于交换输入到这两个积分中的数据集，这使其乘积保持不变。因此，$p(x_{1:n}|\\tilde{z}_{1:n}) = p(x_{1:n}|z_{1:n})$。\n由于两项都是对称的，后验 $p(z_{1:n}|x_{1:n})$ 也是对称的。标签切换的对称性没有被消除；它被 $z_{1:n}$ 上的边缘后验所继承。因此，如果存在一个众数分配 $z^*$，那么也存在一个对称的众数 $\\tilde{z}^*$。后验不是单峰的。\n**结论：错误。**",
            "answer": "$$\\boxed{ADE}$$"
        },
        {
            "introduction": "对吉布斯采样器进行更深入的分析，需要从简单的自相关性研究转向更形式化的算子理论框架。这个高级练习将引导您完成将吉布斯采样器表示为线性算子的过程，并利用其谱特性来精确量化其长期效率。通过比较一个多元高斯分布的系统扫描和随机扫描策略，您将掌握一套分析 MCMC 估计量渐近方差的强大工具。",
            "id": "3358547",
            "problem": "考虑一个中心在原点、位于 $\\mathbb{R}^{3}$ 上的高斯分布，其精度矩阵为\n$$\nQ \\;=\\; \\begin{pmatrix}\n1 & -\\rho & 0\\\\\n-\\rho & 1 & -\\rho\\\\\n0 & -\\rho & 1\n\\end{pmatrix},\n$$\n其中 $\\rho \\in \\mathbb{R}$ 满足 $|\\rho| < 1/\\sqrt{2}$，以确保 $Q$ 是正定矩阵。令 $X = (X_{1},X_{2},X_{3})^{\\top} \\sim \\mathcal{N}(0, Q^{-1})$ 表示服从该分布的随机向量，并令 $f(x) = x_{2}$。你运行两种以该高斯分布为目标分布的马尔可夫链蒙特卡洛（MCMC）方案：\n\n- 系统扫描 Gibbs 采样：按固定顺序依次更新 $X_{1} \\mid (X_{2},X_{3})$，然后 $X_{2} \\mid (X_{1},X_{3})$，然后 $X_{3} \\mid (X_{1},X_{2})$。\n- 随机扫描 Gibbs 采样：在每个“微步”（mini-step）中，从 $\\{1,2,3\\}$ 中均匀随机选择一个坐标，并仅在其他两个坐标为条件的的情况下更新该坐标。\n\n在平稳状态下进行分析，并考虑状态的时间序列 $\\{X^{(t)}\\}_{t\\ge 0}$。对于系统扫描链，将一次完整的系统扫描视为一个时间步；对于随机扫描链，一个“微步”即为一个时间步。仅从多元高斯分布的 Gibbs 采样的核心定义、线性高斯更新的马尔可夫转移算子概念以及加性泛函的马尔可夫链中心极限定理（CLT）出发，按以下步骤进行：\n\n1) 对于系统扫描 Gibbs 采样器，推导出行列式线性算子 $B_{\\mathrm{sys}} \\in \\mathbb{R}^{3\\times 3}$，使得一次完整扫描的条件均值满足\n$$\n\\mathbb{E}\\!\\left[\\,X^{(t+1)} \\mid X^{(t)} = x\\,\\right] \\;=\\; B_{\\mathrm{sys}}\\, x.\n$$\n仅使用基于第一性原理的线性代数推理，确定 $B_{\\mathrm{sys}}$ 的谱及其谱半径，作为 $\\rho$ 的函数。\n\n2) 对形式为 $X^{(t+1)} = B_{\\mathrm{sys}} X^{(t)} + \\xi^{(t+1)}$ 且具有独立高斯新息 $\\xi^{(t+1)}$ 的线性高斯马尔可夫链，使用特征分析方法证明，对于 $f(X^{(t)}) = X^{(t)}_{2}$，其在滞后 $k$ 处的平稳自协方差具有以下形式\n$$\n\\mathrm{Cov}\\!\\left(f(X^{(t+k)}), f(X^{(t)})\\right)\n\\;=\\; \\alpha(\\rho)\\,\\lambda(\\rho)^{k},\n$$\n其中的系数 $\\alpha(\\rho)$ 和底数 $\\lambda(\\rho)$ 必须用 $\\rho$ 明确表示出来。从线性算子的角度证明每一步，不要假设可逆性。\n\n3) 令 $\\overline{f}_{T} = T^{-1}\\sum_{t=1}^{T} f(X^{(t)})$。使用马尔可夫链中心极限定理及你在第 2 部分得到的结果，推导在系统扫描链下 $\\overline{f}_{T}$ 的渐近方差的精确闭式表达式（作为 $\\rho$ 的函数），其定义为\n$$\n\\sigma_{\\mathrm{sys}}^{2}(\\rho) \\;=\\; \\lim_{T\\to\\infty} T\\cdot \\mathrm{Var}\\!\\left(\\overline{f}_{T}\\right).\n$$\n\n4) 现在考虑平稳状态下的随机扫描链。计算单个微步中 $f(X^{(t)})$ 的滞后一阶自相关。基于此结果和你第 1 部分的分析，仅从第一性原理出发进行定性讨论——当 $|\\rho|$ 很小时，哪种方案预计在每次完整扫描中会产生更小的渐近方差，无需尝试计算随机扫描的渐近方差的精确闭式解。\n\n请提供第 3 部分中 $\\sigma_{\\mathrm{sys}}^{2}(\\rho)$ 的闭式解析表达式作为你的最终答案（无单位）。不要提供任何数值近似。",
            "solution": "该问题是科学合理的、定义明确的且客观的。我们开始解答。\n\n目标分布是一个多元正态分布 $X \\sim \\mathcal{N}(0, \\Sigma)$，其精度矩阵 $Q = \\Sigma^{-1}$ 由下式给出\n$$\nQ = \\begin{pmatrix} 1 & -\\rho & 0 \\\\ -\\rho & 1 & -\\rho \\\\ 0 & -\\rho & 1 \\end{pmatrix}\n$$\n条件 $|\\rho| < 1/\\sqrt{2}$ 确保了 $Q$ 是正定的。对于一个具有精度矩阵 $Q$ 和均值 $\\mu$ 的一般多元正态分布，给定所有其他分量 $X_{-i}$ 时 $X_i$ 的条件分布是\n$$\nX_i \\mid X_{-i} \\sim \\mathcal{N}\\left(\\mu_i - \\frac{1}{Q_{ii}} \\sum_{j \\neq i} Q_{ij} (X_j - \\mu_j), \\frac{1}{Q_{ii}}\\right)\n$$\n在我们的例子中，均值为 $\\mu=0$，且 $Q$ 的所有对角元素均为 $Q_{ii}=1$。条件期望是：\n$$ \\mathbb{E}[X_1 \\mid X_2, X_3] = - (Q_{12}X_2 + Q_{13}X_3) = \\rho X_2 $$\n$$ \\mathbb{E}[X_2 \\mid X_1, X_3] = - (Q_{21}X_1 + Q_{23}X_3) = \\rho X_1 + \\rho X_3 $$\n$$ \\mathbb{E}[X_3 \\mid X_1, X_2] = - (Q_{31}X_1 + Q_{32}X_2) = \\rho X_2 $$\n\n**1) 系统扫描 Gibbs 采样器：转移算子和谱**\n\n令 $X^{(t)} = (X_1^{(t)}, X_2^{(t)}, X_3^{(t)})^\\top$ 为链在时间 $t$ 的状态。系统扫描 Gibbs 采样器的一次完整扫描按 1, 2, 3 的顺序更新各分量。令新状态为 $X'=(X'_1, X'_2, X'_3)^\\top = X^{(t+1)}$。\n更新是按顺序执行的：\n1. 从 $p(X_1 \\mid X_2=X_2^{(t)}, X_3=X_3^{(t)})$ 中采样得到 $X'_1$。\n2. 从 $p(X_2 \\mid X_1=X'_1, X_3=X_3^{(t)})$ 中采样得到 $X'_2$。\n3. 从 $p(X_3 \\mid X_1=X'_1, X_2=X'_2)$ 中采样得到 $X'_3$。\n\n算子 $B_{\\mathrm{sys}}$ 由下一状态的条件期望定义：$\\mathbb{E}[X^{(t+1)} \\mid X^{(t)} = x] = B_{\\mathrm{sys}} x$。我们使用全期望定律计算它：\n$$ \\mathbb{E}[X'_1 \\mid X^{(t)}=x] = \\mathbb{E}[ \\mathbb{E}[X'_1 \\mid X_2^{(t)}=x_2, X_3^{(t)}=x_3] \\mid X^{(t)}=x] = \\rho x_2 $$\n$$ \\mathbb{E}[X'_2 \\mid X^{(t)}=x] = \\mathbb{E}[ \\mathbb{E}[X'_2 \\mid X'_1, X_3^{(t)}=x_3] \\mid X^{(t)}=x] = \\mathbb{E}[\\rho X'_1 + \\rho x_3 \\mid X^{(t)}=x] = \\rho \\mathbb{E}[X'_1 \\mid X^{(t)}=x] + \\rho x_3 = \\rho(\\rho x_2) + \\rho x_3 = \\rho^2 x_2 + \\rho x_3 $$\n$$ \\mathbb{E}[X'_3 \\mid X^{(t)}=x] = \\mathbb{E}[ \\mathbb{E}[X'_3 \\mid X'_1, X'_2] \\mid X^{(t)}=x] = \\mathbb{E}[\\rho X'_2 \\mid X^{(t)}=x] = \\rho \\mathbb{E}[X'_2 \\mid X^{(t)}=x] = \\rho(\\rho^2 x_2 + \\rho x_3) = \\rho^3 x_2 + \\rho^2 x_3 $$\n将其写成矩阵形式：\n$$\n\\mathbb{E}[X^{(t+1)} \\mid X^{(t)}=x] = \\begin{pmatrix} \\rho x_2 \\\\ \\rho^2 x_2 + \\rho x_3 \\\\ \\rho^3 x_2 + \\rho^2 x_3 \\end{pmatrix} = \\begin{pmatrix} 0 & \\rho & 0 \\\\ 0 & \\rho^2 & \\rho \\\\ 0 & \\rho^3 & \\rho^2 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}\n$$\n因此，算子为\n$$\nB_{\\mathrm{sys}} = \\begin{pmatrix} 0 & \\rho & 0 \\\\ 0 & \\rho^2 & \\rho \\\\ 0 & \\rho^3 & \\rho^2 \\end{pmatrix}\n$$\n为求其谱，我们解特征方程 $\\det(B_{\\mathrm{sys}} - \\lambda I) = 0$：\n$$\n\\det\\begin{pmatrix} -\\lambda & \\rho & 0 \\\\ 0 & \\rho^2-\\lambda & \\rho \\\\ 0 & \\rho^3 & \\rho^2-\\lambda \\end{pmatrix} = -\\lambda \\left[ (\\rho^2-\\lambda)^2 - \\rho^4 \\right] = -\\lambda[\\lambda^2 - 2\\rho^2\\lambda + \\rho^4 - \\rho^4] = -\\lambda^2(\\lambda - 2\\rho^2) = 0\n$$\n特征值为 $\\lambda_1 = 2\\rho^2$，$\\lambda_2 = 0$ 和 $\\lambda_3 = 0$。$B_{\\mathrm{sys}}$ 的谱为 $\\{2\\rho^2, 0, 0\\}$。\n谱半径为 $\\rho(B_{\\mathrm{sys}}) = \\max_i |\\lambda_i| = |2\\rho^2| = 2\\rho^2$。收敛条件 $\\rho(B_{\\mathrm{sys}}) < 1$ 给出 $2\\rho^2 < 1$，即 $|\\rho| < 1/\\sqrt{2}$，这与问题陈述相符。\n\n**2) $f(X^{(t)}) = X_2^{(t)}$ 的自协方差**\n\n线性高斯马尔可夫链可以写成 $X^{(t+1)} = B_{\\mathrm{sys}} X^{(t)} + \\xi^{(t+1)}$，其中 $\\xi^{(t+1)}$ 是一个独立于 $X^{(t)}$ 的零均值高斯新息。在平稳状态下，$\\mathbb{E}[X^{(t)}] = 0$。\n状态向量在滞后 $k$ 处的自协方差由下式给出：\n$$\n\\mathrm{Cov}(X^{(t+k)}, X^{(t)}) = \\mathbb{E}[X^{(t+k)} (X^{(t)})^\\top] = \\mathbb{E}[(B_{\\mathrm{sys}}X^{(t+k-1)} + \\xi^{(t+k)})(X^{(t)})^\\top] = B_{\\mathrm{sys}} \\mathbb{E}[X^{(t+k-1)} (X^{(t)})^\\top]\n$$\n通过递归，这导向 $\\mathrm{Cov}(X^{(t+k)}, X^{(t)}) = (B_{\\mathrm{sys}})^k \\mathbb{E}[X^{(t)} (X^{(t)})^\\top] = (B_{\\mathrm{sys}})^k \\Sigma$，其中 $\\Sigma$ 是平稳协方差矩阵 $\\Sigma=Q^{-1}$。\n我们感兴趣的函数是 $f(X^{(t)}) = X_2^{(t)} = e_2^\\top X^{(t)}$，其中 $e_2 = (0, 1, 0)^\\top$。其自协方差为：\n$$\n\\mathrm{Cov}(f(X^{(t+k)}), f(X^{(t)})) = \\mathrm{Cov}(X_2^{(t+k)}, X_2^{(t)}) = e_2^\\top \\mathrm{Cov}(X^{(t+k)}, X^{(t)}) e_2 = e_2^\\top (B_{\\mathrm{sys}})^k \\Sigma e_2\n$$\n矩阵 $B_{\\mathrm{sys}}$ 是不可对角化的，因为特征值 $0$ 的几何重数为 $1$，而其代数重数为 $2$。为了分析 $(B_{\\mathrm{sys}})^k$，我们使用 Jordan 分解。然而，分析 $(B_{\\mathrm{sys}})^k$ 在特定向量 $\\Sigma e_2$ 上的作用更简单。首先，我们计算 $\\Sigma = Q^{-1}$：\n$$\n\\Sigma = \\frac{1}{1-2\\rho^2} \\begin{pmatrix} 1-\\rho^2 & \\rho & \\rho^2 \\\\ \\rho & 1 & \\rho \\\\ \\rho^2 & \\rho & 1-\\rho^2 \\end{pmatrix}\n$$\n向量 $\\Sigma e_2$ 是 $\\Sigma$ 的第二列：\n$$\n\\Sigma e_2 = \\frac{1}{1-2\\rho^2} \\begin{pmatrix} \\rho \\\\ 1 \\\\ \\rho \\end{pmatrix}\n$$\n我们来找 $B_{\\mathrm{sys}}$ 的特征向量。对于特征值 $\\lambda_1 = 2\\rho^2$，特征向量方程 $(B_{\\mathrm{sys}} - 2\\rho^2 I)v = 0$ 给出 $v_1 \\propto (1, 2\\rho, 2\\rho^2)^\\top$。对于 $\\lambda=0$ 的特征空间由 $v_2 = (1, 0, 0)^\\top$ 张成。\n向量 $\\Sigma e_2$ 不是一个特征向量。然而，它在相关特征空间上的投影决定了长期行为。我们来分析 $B_{\\mathrm{sys}}$ 在 $\\Sigma e_2$ 上的作用：\n$$\nB_{\\mathrm{sys}} (\\Sigma e_2) = \\frac{1}{1-2\\rho^2} \\begin{pmatrix} 0 & \\rho & 0 \\\\ 0 & \\rho^2 & \\rho \\\\ 0 & \\rho^3 & \\rho^2 \\end{pmatrix} \\begin{pmatrix} \\rho \\\\ 1 \\\\ \\rho \\end{pmatrix} = \\frac{1}{1-2\\rho^2} \\begin{pmatrix} \\rho \\\\ \\rho^2+\\rho^2 \\\\ \\rho^3+\\rho^2 \\end{pmatrix} = \\frac{1}{1-2\\rho^2} \\begin{pmatrix} \\rho \\\\ 2\\rho^2 \\\\ \\rho^2(\\rho+1)\\end{pmatrix}\n$$\n这种直接计算很繁琐。其形式暗示了一个更简单的结构。我们检查一下 $B_{\\mathrm{sys}}^\\top$ 是否有更方便的结构。对于高斯目标的 Gibbs 采样器的一个关键性质是 $B=I-\\Sigma_\\xi \\Sigma^{-1}$，其中 $\\Sigma_\\xi$ 是新息的协方差。这里，对于系统扫描，$B_{sys} = B_3 B_2 B_1$。平稳性意味着 $\\Sigma = B_{sys} \\Sigma B_{sys}^\\top + \\Sigma_\\xi$。自协方差也是 $\\Sigma (B_{sys}^\\top)^k$。因此我们需要分析 $e_2^\\top \\Sigma (B_{\\mathrm{sys}}^\\top)^k e_2$。$B_{sys}$ 的左特征向量是 $B_{sys}^\\top$ 的右特征向量。对于 $\\lambda_1=2\\rho^2$ 的左特征向量是 $w_1 = (0, \\rho, 1)^\\top$。\n我们直接计算 $e_2^\\top(B_{\\mathrm{sys}})^k$。注意 $e_2^\\top B_{\\mathrm{sys}} = (0, \\rho^2, \\rho)$。\n$e_2^\\top (B_{\\mathrm{sys}})^2 = (0, \\rho^2, \\rho) B_{\\mathrm{sys}} = (0, \\rho^4+\\rho^4, \\rho^3+\\rho^3) = (0, 2\\rho^4, 2\\rho^3) = 2\\rho^2 (0, \\rho^2, \\rho) = (2\\rho^2) e_2^\\top B_{\\mathrm{sys}}$。\n通过归纳法，对于 $k \\ge 1$：$e_2^\\top (B_{\\mathrm{sys}})^k = (2\\rho^2)^{k-1} e_2^\\top B_{\\mathrm{sys}}$。\n因此，对于 $k \\ge 1$：\n$$ \\mathrm{Cov}(X_2^{(t+k)}, X_2^{(t)}) = (e_2^\\top (B_{\\mathrm{sys}})^k) (\\Sigma e_2) = (2\\rho^2)^{k-1} (e_2^\\top B_{\\mathrm{sys}}) (\\Sigma e_2) $$\n$$ e_2^\\top B_{\\mathrm{sys}} = (0, \\rho^2, \\rho) $$\n$$ (\\Sigma e_2) = \\frac{1}{1-2\\rho^2} (\\rho, 1, \\rho)^\\top $$\n$$ (e_2^\\top B_{\\mathrm{sys}}) (\\Sigma e_2) = \\frac{1}{1-2\\rho^2} [ \\rho^2(1) + \\rho(\\rho) ] = \\frac{2\\rho^2}{1-2\\rho^2} $$\n因此，对于 $k \\ge 1$：\n$$ \\mathrm{Cov}(X_2^{(t+k)}, X_2^{(t)}) = (2\\rho^2)^{k-1} \\frac{2\\rho^2}{1-2\\rho^2} = \\frac{1}{1-2\\rho^2} (2\\rho^2)^k $$\n对于 $k=0$，$\\mathrm{Cov}(X_2^{(t)}, X_2^{(t)}) = \\mathrm{Var}(X_2) = \\Sigma_{22} = \\frac{1}{1-2\\rho^2}$。公式 $\\frac{1}{1-2\\rho^2} (2\\rho^2)^0$ 也给出相同的结果。\n所以，对于所有 $k \\ge 0$，自协方差为 $\\alpha(\\rho) \\lambda(\\rho)^k$，其中\n$$ \\alpha(\\rho) = \\frac{1}{1-2\\rho^2}, \\quad \\lambda(\\rho) = 2\\rho^2 $$\n\n**3) 渐近方差 $\\sigma_{\\mathrm{sys}}^2(\\rho)$**\n\n马尔可夫链中心极限定理指出，样本均值 $\\overline{f}_{T} = T^{-1}\\sum_{t=1}^{T} f(X^{(t)})$ 的渐近方差由下式给出：\n$$\n\\sigma^2(\\rho) = \\lim_{T\\to\\infty} T \\cdot \\mathrm{Var}(\\overline{f}_{T}) = \\mathrm{Var}_\\pi(f(X)) + 2 \\sum_{k=1}^{\\infty} \\mathrm{Cov}_\\pi(f(X^{(k)}), f(X^{(0)}))\n$$\n在我们的例子中，$f(X) = X_2$。我们有：\n$$ \\mathrm{Var}_\\pi(X_2) = \\Sigma_{22} = \\frac{1}{1-2\\rho^2} $$\n自协方差之和是一个几何级数：\n$$ \\sum_{k=1}^{\\infty} \\mathrm{Cov}(X_2^{(t+k)}, X_2^{(t)}) = \\sum_{k=1}^{\\infty} \\frac{1}{1-2\\rho^2} (2\\rho^2)^k $$\n级数的公比是 $2\\rho^2$，并且由于 $|\\rho| < 1/\\sqrt{2}$，我们有 $|2\\rho^2| < 1$。和为：\n$$ \\frac{1}{1-2\\rho^2} \\sum_{k=1}^{\\infty} (2\\rho^2)^k = \\frac{1}{1-2\\rho^2} \\left(\\frac{2\\rho^2}{1-2\\rho^2}\\right) = \\frac{2\\rho^2}{(1-2\\rho^2)^2} $$\n合并各项，渐近方差为：\n$$\n\\sigma_{\\mathrm{sys}}^{2}(\\rho) = \\frac{1}{1-2\\rho^2} + 2 \\cdot \\frac{2\\rho^2}{(1-2\\rho^2)^2} = \\frac{1-2\\rho^2}{(1-2\\rho^2)^2} + \\frac{4\\rho^2}{(1-2\\rho^2)^2} = \\frac{1-2\\rho^2+4\\rho^2}{(1-2\\rho^2)^2} = \\frac{1+2\\rho^2}{(1-2\\rho^2)^2}\n$$\n\n**4) 与随机扫描 Gibbs 采样器的定性比较**\n\n对于随机扫描采样器，在每个微步中，我们以 $1/3$ 的概率选择一个索引 $i \\in \\{1,2,3\\}$ 并仅更新 $X_i$。我们首先计算单个微步中 $f(X^{(t)})=X_2^{(t)}$ 的滞后一阶自相关。\n$$ \\mathrm{Corr}(X_2^{(t+1)}, X_2^{(t)}) = \\frac{\\mathrm{Cov}(X_2^{(t+1)}, X_2^{(t)})}{\\mathrm{Var}(X_2)} = \\frac{\\mathbb{E}[X_2^{(t+1)}X_2^{(t)}]}{\\mathrm{Var}(X_2)} $$\n使用全期望定律，以所选索引 $I_{t+1}$ 为条件：\n$$ \\mathbb{E}[X_2^{(t+1)} \\mid X^{(t)}] = \\frac{1}{3}\\mathbb{E}[X_2^{(t+1)} \\mid X^{(t)}, I=1] + \\frac{1}{3}\\mathbb{E}[X_2^{(t+1)} \\mid X^{(t)}, I=2] + \\frac{1}{3}\\mathbb{E}[X_2^{(t+1)} \\mid X^{(t)}, I=3] $$\n如果 $I=1$ 或 $I=3$，$X_2$ 不被更新，因此 $X_2^{(t+1)} = X_2^{(t)}$。如果 $I=2$，$X_2$ 被更新，其条件均值为 $\\rho X_1^{(t)} + \\rho X_3^{(t)}$。因此：\n$$ \\mathbb{E}[X_2^{(t+1)} \\mid X^{(t)}] = \\frac{1}{3}X_2^{(t)} + \\frac{1}{3}(\\rho X_1^{(t)} + \\rho X_3^{(t)}) + \\frac{1}{3}X_2^{(t)} = \\frac{2}{3}X_2^{(t)} + \\frac{\\rho}{3}(X_1^{(t)} + X_3^{(t)}) $$\n现在我们计算协方差：\n$$ \\mathbb{E}[X_2^{(t+1)}X_2^{(t)}] = \\mathbb{E}\\left[X_2^{(t)} \\left(\\frac{2}{3}X_2^{(t)} + \\frac{\\rho}{3}(X_1^{(t)} + X_3^{(t)})\\right)\\right] = \\frac{2}{3}\\mathbb{E}[(X_2^{(t)})^2] + \\frac{\\rho}{3}\\mathbb{E}[X_1^{(t)}X_2^{(t)}] + \\frac{\\rho}{3}\\mathbb{E}[X_3^{(t)}X_2^{(t)}] $$\n使用来自 $\\Sigma = Q^{-1}$ 的平稳协方差：$\\mathbb{E}[(X_2)^2] = \\Sigma_{22} = \\frac{1}{1-2\\rho^2}$，$\\mathbb{E}[X_1X_2] = \\Sigma_{12} = \\frac{\\rho}{1-2\\rho^2}$，$\\mathbb{E}[X_2X_3] = \\Sigma_{23} = \\frac{\\rho}{1-2\\rho^2}$。\n$$ \\mathbb{E}[X_2^{(t+1)}X_2^{(t)}] = \\frac{2}{3}\\frac{1}{1-2\\rho^2} + \\frac{\\rho}{3}\\frac{\\rho}{1-2\\rho^2} + \\frac{\\rho}{3}\\frac{\\rho}{1-2\\rho^2} = \\frac{2+2\\rho^2}{3(1-2\\rho^2)} $$\n每个微步的滞后一阶自相关是：\n$$ \\rho_{\\mathrm{rand}}(1) = \\frac{\\mathbb{E}[X_2^{(t+1)}X_2^{(t)}]}{\\mathrm{Var}(X_2)} = \\frac{(2+2\\rho^2)/(3(1-2\\rho^2))}{1/(1-2\\rho^2)} = \\frac{2(1+\\rho^2)}{3} $$\n一次完整扫描对应于 3 个微步。为了比较这两种方案，我们比较它们在一次完整扫描中的有效自相关。对于系统扫描链，$f(X_2)$ 的滞后一阶自相关恰好是 $\\lambda(\\rho)=2\\rho^2$。对于随机扫描链，如果我们将它在 3 步内的行为近似为一个 AR(1) 过程，有效自相关将是 $(\\rho_{\\mathrm{rand}}(1))^3 = (\\frac{2(1+\\rho^2)}{3})^3$。\n对于小的 $|\\rho|$，令 $\\varepsilon = |\\rho|$：\n- 系统扫描自相关：$2\\varepsilon^2$。这是 $O(\\varepsilon^2)$ 阶的。\n- 随机扫描有效自相关：$(\\frac{2(1+\\varepsilon^2)}{3})^3 \\approx (\\frac{2}{3})^3 = \\frac{8}{27}$。这是一个常数。\n\n渐近方差是过程自相关的增函数。因为当 $|\\rho|$ 很小时，系统扫描的自相关（$2\\rho^2$）远小于随机扫描的自相关（$\\approx 8/27$），所以系统扫描 Gibbs 采样器预计会混合得更快，因此每次完整扫描产生的渐近方差会显著更小。随机扫描花费了 $2/3$ 的时间在不改变 $X_2$ 的更新上，导致了高持续性，而系统扫描在每次扫描中更新所有变量，并且特定的有序交互在这种情况下导致了更快的收敛。",
            "answer": "$$\\boxed{\\frac{1+2\\rho^2}{(1-2\\rho^2)^2}}$$"
        }
    ]
}