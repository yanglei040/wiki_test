{
    "hands_on_practices": [
        {
            "introduction": "马尔可夫链蒙特卡洛（MCMC）算法的正确性取决于其是否满足细致平衡条件，这是确保链的平稳分布是我们期望的目标分布的关键。在实现切片采样时，即使是看似微小的错误也可能破坏这一性质，导致采样结果出现偏差。此实践练习 () 展示了一个有缺陷的切片采样器实现，通过计算其产生的偏差，帮助您深入理解为何标准的收缩步骤对于保证在切片上均匀采样至关重要。",
            "id": "3344650",
            "problem": "考虑在单位区间上的一个目标分布进行一维切片采样，其未归一化密度定义为\n$$\nf(x) \\;=\\; \\begin{cases}\n1, & x \\in [0,\\,0.2] \\cup [0.7,\\,1],\\\\\n0.4, & x \\in (0.2,\\,0.7).\n\\end{cases}\n$$\n设当前状态为 $x_{0} \\in [0.7,\\,1]$，并假设切片水平固定在 $y^{\\star} = 0.8$。因此，水平切片为\n$$\nS(y^{\\star}) \\;=\\; \\{ x \\in [0,\\,1] : f(x) \\ge y^{\\star} \\} \\;=\\; [0,\\,0.2] \\cup [0.7,\\,1].\n$$\n一位经验不足的实现者将采样区间初始化为 $[L,R] = [0,\\,1]$，然后执行以下“有偏区间更新”的收缩过程：\n- 从 $\\mathrm{Uniform}(L,R)$ 分布中提议一个样本 $x'$。\n- 如果 $x' \\in S(y^{\\star})$，则接受该样本并设置 $x_{1} = x'$。\n- 如果 $x' \\notin S(y^{\\star})$，则通过确定性地保留左侧来更新区间，即设置 $[L,R] \\leftarrow [L,\\,x']$，然后重复。\n\n这个更新规则没有强制满足标准切片采样的要求，即采样区间必须始终包含当前状态 $x_{0}$。事实上，当 $x' \\in (0.2,\\,0.7)$ 时，此更新会丢弃右侧，从而在此后排除了从右侧切片分量 $[0.7,\\,1]$ 中采样的任何可能性。\n\n在固定的切片水平 $y^{\\star}$ 和固定的初始化 $[L,R]=[0,\\,1]$ 的条件下，计算通过上述天真过程产生的最终接受样本 $x_{1}$ 位于左侧切片分量 $[0,\\,0.2]$ 内的概率。将你的答案表示为单个精确分数。不需要四舍五入。\n\n然后，从切片采样器不变性条件的核心定义以及区间更新需保持细致平衡的要求出发，简要说明收缩步骤中需要进行的修正，以恢复在 $S(y^{\\star})$ 上的均匀采样。你的解释必须从第一性原理推导，并且不能依赖于捷径公式。",
            "solution": "这个问题包含两部分。第一部分要求为一个有缺陷的切片采样过程计算一个概率。第二部分要求基于第一性原理，解释该缺陷以及必要的修正。\n\n### 第一部分：概率计算\n\n令 $S(y^{\\star}) = [0, 0.2] \\cup [0.7, 1]$ 为水平 $y^{\\star} = 0.8$ 处的水平切片。我们可以将左分量表示为 $I_L = [0, 0.2]$，右分量表示为 $I_R = [0.7, 1]$。它们之间的区域是 $I_M = (0.2, 0.7)$。\n\n这个天真的采样过程始于一个初始区间 $[L, R] = [0, 1]$。从该区间上的均匀分布中抽取一个提议样本 $x'$，即 $x' \\sim \\mathrm{Uniform}(0, 1)$。\n\n对于第一次提议的样本 $x'_1$，有三种互斥的结果：\n1.  $x'_1 \\in I_L = [0, 0.2]$。此事件的概率为 $P(x'_1 \\in I_L) = 0.2 - 0 = 0.2$。在这种情况下，样本被接受，令 $x_1 = x'_1$，过程终止。最终样本位于左分量。\n2.  $x'_1 \\in I_R = [0.7, 1]$。此事件的概率为 $P(x'_1 \\in I_R) = 1 - 0.7 = 0.3$。样本被接受，令 $x_1 = x'_1$，过程终止。最终样本位于右分量。\n3.  $x'_1 \\in I_M = (0.2, 0.7)$。此事件的概率为 $P(x'_1 \\in I_M) = 0.7 - 0.2 = 0.5$。样本被拒绝，并且采样区间根据规则 $[L, R] \\leftarrow [L, x'_1]$ 进行更新。由于初始左边界为 $L=0$，新区间变为 $[0, x'_1]$。\n\n让我们分析一下收缩步骤的后果。如果第一次提议的样本 $x'_1$ 落在 $I_M$ 中，那么所有后续提议样本的新采样区间都将变为 $[0, x'_1]$。由于 $x'_1  0.7$，这个新区间与切片的右分量 $I_R = [0.7, 1]$ 没有任何重叠。因此，如果算法进入收缩阶段，它将永远不可能从 $I_R$ 中生成样本。任何最终被接受的样本都必须来自新区间中唯一可用的切片部分，即 $I_L = [0, 0.2]$。\n\n令 $E_L$ 表示最终接受的样本 $x_1$ 位于左分量 $I_L$ 的事件。令 $E_R$ 表示 $x_1$ 位于右分量 $I_R$ 的事件。生成样本的过程必须终止，才能成为 MCMC 算法的有效部分。假设过程会终止，那么最终样本必须位于 $I_L$ 或 $I_R$ 中，因此 $P(E_L) + P(E_R) = 1$。\n\n事件 $E_R$ 仅当接受的样本来自 $I_R$ 时才会发生。根据上述逻辑，只有在第一次提议时才可能从 $I_R$ 中抽样。如果第一次提议的样本不在 $I_R$ 中，则从 $I_R$ 采样的机会就永久失去了。因此，事件 $E_R$ 等价于第一次提议的样本 $x'_1$ 位于 $I_R$ 中的事件。\n\n其概率为：\n$$ P(E_R) = P(x'_1 \\in I_R) = P(x'_1 \\in [0.7, 1]) $$\n由于 $x'_1 \\sim \\mathrm{Uniform}(0, 1)$，这个概率就是区间的长度：\n$$ P(E_R) = 1 - 0.7 = 0.3 = \\frac{3}{10} $$\n\n问题要求的是互补事件 $E_L$ 的概率。由于过程必须在 $E_L$ 或 $E_R$ 中终止，我们有：\n$$ P(E_L) = 1 - P(E_R) = 1 - 0.3 = 0.7 $$\n作为一个精确分数，概率是 $\\frac{7}{10}$。\n\n### 第二部分：对收缩步骤的修正\n\n在给定切片水平 $y^{\\star}$ 的情况下，切片采样器这一阶段的目标是从集合 $S(y^{\\star})$ 中均匀地抽取一个样本。如第一部分所示，所描述的过程未能做到这一点：一个正确的均匀采样器会以概率 $\\frac{|I_L|}{|I_L|+|I_R|} = \\frac{0.2}{0.2+0.3} = \\frac{0.2}{0.5} = 0.4$ 从 $I_L$ 中选取一个点，而不是 $0.7$。\n\n这个天真过程的缺陷在于它违反了有效的马尔可夫链蒙特卡洛（MCMC）转移所需遵循的原则。切片采样器是一种 MCMC 方法，其平稳分布必须是目标分布 $\\pi(x) \\propto f(x)$。一个充分条件是转移核 $K(x_1 | x_0)$ 满足细致平衡方程：\n$$ \\pi(x_0) K(x_1 | x_0) = \\pi(x_1) K(x_0 | x_1) $$\n该方程确保了马尔可夫链的可逆性。\n\n转移 $x_0 \\to x_1$ 涉及两个步骤：抽取一个垂直水平 $y \\sim \\mathrm{Uniform}(0, f(x_0))$，然后从一个旨在从切片 $S_y = \\{x : f(x) \\ge y\\}$ 中采样的过程中抽取一个新的水平位置 $x_1$。整个转移过程必须是可逆的。\n\n有缺陷的“有偏区间更新”是在提议样本 $x'$ 被拒绝时，由 $[L,R] \\leftarrow [L, x']$ 给出。这个规则与当前状态 $x_0$ 无关。正如问题中所指出的，这可能导致新的区间不再包含 $x_0$。例如，当 $x_0 \\in [0.7, 1]$ 且一个被拒绝的提议样本 $x' \\in (0.2, 0.7)$ 时，新区间变为 $[0, x']$，它排除了 $x_0$。\n\n这对细致平衡有关键性的影响。如果采样过程可以从可能的结果集中排除起始点 $x_0$，那么从 $x_0$ 到其自身（或从另一个状态 $x_1$ 回到 $x_0$）的转移就可能变得不可能。具体来说，反向移动的核 $K(x_0|x_1)$ 可能为零，而正向移动的核 $K(x_1|x_0)$ 非零。这将违反细致平衡。为了使切片采样器的可逆性证明成立，在给定 $x_0$ 的情况下采样 $x_1$ 的过程不能排除采样 $x_0$ 自身。\n\n必要的修正是使收缩过程依赖于当前状态 $x_0$，确保 $x_0$ 始终保持在采样区间内。这保留了采样 $x_0$ 的可能性，并且是细致平衡论证得以应用的必要条件。\n\n修正后的收缩步骤如下：\n当一个提议样本 $x'$ 被拒绝时（即 $x' \\notin S(y^{\\star})$），区间 $[L,R]$ 会根据 $x'$ 相对于 $x_0$ 的位置进行更新：\n- 如果 $x'  x_0$，提议样本落在了当前状态的左侧。区域 $[L, x')$ 可以被丢弃。更新为 $L \\leftarrow x'$。\n- 如果 $x' > x_0$，提议样本落在了当前状态的右侧。区域 $(x', R]$ 可以被丢弃。更新为 $R \\leftarrow x'$。\n\n这个规则确保了区间 $[L, R]$ 始终包含 $x_0$。它通过对称地处理 $x_0$ 左右两侧的区域，消除了天真实现中的方向性偏差。这一修正恢复了切片采样算法为满足细致平衡并从而从目标分布中正确采样所要求的关键属性。",
            "answer": "$$\\boxed{\\frac{7}{10}}$$"
        },
        {
            "introduction": "在确保算法的正确性之后，我们自然会关心其计算效率。对于切片采样等迭代方法，效率通常通过每次迭代中目标函数评估的次数来衡量，因为这往往是计算成本最高的部分。此练习 () 将引导您从第一性原理出发，推导广泛使用的“跨步与收缩”（stepping-out and shrinking）方法的期望函数评估次数。这个过程不仅能加深您对算法工作方式的理解，还将揭示在调整步长参数 $w$ 时所面临的关键权衡。",
            "id": "3344638",
            "problem": "考虑马尔可夫链蒙特卡洛（MCMC）框架下的一维切片采样。设目标密度是单峰且连续的，因此对于从 $[0, f(x_0)]$ 中均匀抽取的水平 $u$，切片 $\\{x : f(x) \\geq u\\}$ 是一个宽度为 $W = b - a$ 的单一区间 $[a,b]$。假设 $x_0 \\in [a,b]$，并且在给定 $u$ 的条件下，$x_0$ 在 $[a,b]$ 上均匀分布。按如下方式实现一步“跨步-收缩”切片采样器的迭代。\n\n跨步（Stepping-out）：\n- 固定一个区间宽度参数 $w  0$。\n- 抽取一个偏移量 $U \\sim \\mathrm{Uniform}(0,w)$，并设置初始区间的端点为 $L_0 = x_0 - U$ 和 $R_0 = x_0 + (w - U)$。\n- 在左侧，当 $L  a$ 时，向左移动 $w$：$L \\leftarrow L - w$。在右侧，当 $R  b$ 时，向右移动 $w$：$R \\leftarrow R + w$。在每次端点检查时，评估一次 $f$ 来确定该端点是否在切片内。在初始端点 $L_0$ 和 $R_0$ 处计一次函数评估，之后在两侧的每一次 $w$ 步端点检查都计一次。\n\n收缩（Shrinking）：\n- 此时区间 $[L,R]$ 包含 $[a,b]$ 且其两个端点都在切片之外。重复从 $[L,R]$ 中均匀抽取 $z \\sim \\mathrm{Uniform}(L,R)$ 并评估 $f(z)$。如果 $z \\in [a,b]$，则接受并停止。如果 $z  a$，则设置 $L \\leftarrow z$；如果 $z  b$，则设置 $R \\leftarrow z$；然后重复。对每个提议的 $z$（包括被接受的那个）计一次函数评估。\n\n假设每次形式为“$x$ 是否在水平 $u$ 的切片内？”的成员资格测试都需要恰好一次对 $f$ 的评估。不要计算用于生成 $u$ 的任何 $f(x_0)$ 的评估。在这些假设下，根据第一性原理，推导单次迭代中（包括跨步和收缩阶段）函数评估总数的期望值的一个封闭形式表达式，该表达式是关于 $W$ 和 $w$ 的函数。以单个解析表达式的形式给出最终答案。不需要四舍五入，也不涉及物理单位。",
            "solution": "问题要求计算特定切片采样算法单次迭代中函数评估的总期望次数 $E[N]$。评估总次数 $N$ 是跨步阶段评估次数 $N_{step}$ 和收缩阶段评估次数 $N_{shrink}$ 的和。根据期望的线性性质，总期望评估次数是每个阶段期望值的和：\n$$E[N] = E[N_{step}] + E[N_{shrink}]$$\n我们将分别计算每一项。\n\n首先，我们分析跨步阶段。\n此阶段的函数评估次数由 $N_{step} = 2 + N_L + N_R$ 给出，其中 $N_L$ 和 $N_R$ 分别是向左和向右的后续扩展步数。最初的 2 次评估对应于初始区间端点 $L_0 = x_0 - U$ 和 $R_0 = x_0 + (w - U)$。\n\n我们来确定向左扩展的期望步数 $E[N_L]$。只要端点 $L$ 大于 $a$，就以大小为 $w$ 的步长向左扩展。该过程从 $L_0 = x_0 - U$ 开始，并生成端点 $L_k = x_0 - U - k w$。当第一个满足 $L_k \\leq a$ 的整数 $k \\geq 0$ 出现时，跨步停止。设 $N_L$ 为这个 $k$ 的值。\n如果 $L_0 \\leq a$，则不进行任何步骤，因此 $N_L=0$。如果 $L_0  a$，则执行步骤。$N_L$ 是满足 $x_0 - U - N_L w \\leq a$ 的最小非负整数。这可以重写为 $N_L w \\geq x_0 - U - a$。\n这意味着 $N_L = \\max(0, \\lceil \\frac{x_0 - a - U}{w} \\rceil)$，其中 $\\lceil \\cdot \\rceil$ 是向上取整函数（ceiling function）。\n\n为了求得期望 $E[N_L]$，我们对 $x_0$ 和 $U$ 的分布进行平均。问题陈述 $x_0$ 在切片 $[a,b]$ 上均匀分布，而 $U$ 在 $[0,w]$ 上均匀分布。令 $Y = x_0 - a$。由于 $x_0 \\sim \\mathrm{Uniform}(a,b)$，则 $Y \\sim \\mathrm{Uniform}(0, W)$，其中 $W=b-a$ 是切片的宽度。变量 $Y$ 和 $U$ 是独立的。\n$$E[N_L] = E_{Y,U}\\left[\\max\\left(0, \\left\\lceil \\frac{Y-U}{w} \\right\\rceil\\right)\\right]$$\n我们可以使用全期望定律来计算：$E[N_L] = E_Y[E_U[N_L | Y]]$。我们来计算对于固定值 $Y=y$ 的内部期望：\n$$E_U[N_L|Y=y] = \\int_0^w \\max\\left(0, \\left\\lceil \\frac{y-u}{w} \\right\\rceil\\right) \\frac{1}{w} du$$\n我们来分析积分 $I(y) = \\int_0^w \\max(0, \\lceil \\frac{y-u}{w} \\rceil) du$。令 $v = \\frac{y-u}{w}$，则 $u = y - wv$ 且 $du = -w dv$。当 $u=0$ 时，$v=y/w$。当 $u=w$ 时，$v=(y-w)/w = y/w-1$。\n$$I(y) = \\int_{y/w}^{y/w-1} \\max(0, \\lceil v \\rceil) (-w) dv = w \\int_{y/w-1}^{y/w} \\max(0, \\lceil v \\rceil) dv$$\n令 $A = y/w$。我们需要计算 $\\int_{A-1}^A \\max(0, \\lceil v \\rceil) dv$。\n如果 $A-1 \\ge 0$（即 $y \\ge w$），积分为 $\\int_{A-1}^A \\lceil v \\rceil dv$。对于任何长度为 1 的区间，比如从 $z$ 到 $z+1$，向上取整函数的积分是 $\\int_z^{z+1} \\lceil v \\rceil dv = z+1$。这里，积分是在一个以 $A$ 结尾的长度为 1 的区间上进行的，所以 $\\int_{A-1}^A \\lceil v \\rceil dv = A$。\n如果 $A-1  0$（即 $y  w$），积分变为 $\\int_{A-1}^0 0 \\cdot dv + \\int_0^A 1 \\cdot dv = A$。\n在这两种情况下，积分都是 $A = y/w$。\n所以，$I(y) = w \\cdot (y/w) = y$。\n这给出了一个非常简单的条件期望结果：\n$$E_U[N_L|Y=y] = \\frac{1}{w} I(y) = \\frac{y}{w}$$\n现在，我们对 $Y \\sim \\mathrm{Uniform}(0, W)$ 取期望：\n$$E[N_L] = E_Y\\left[\\frac{Y}{w}\\right] = \\frac{1}{w} E[Y]$$\n一个 $\\mathrm{Uniform}(0,W)$ 随机变量的期望值是 $W/2$。\n$$E[N_L] = \\frac{1}{w} \\frac{W}{2} = \\frac{W}{2w}$$\n根据对称性，我们可以计算向右的期望步数 $E[N_R]$。这里，$N_R = \\max(0, \\lceil \\frac{b-x_0-(w-U)}{w} \\rceil)$。令 $Y' = b-x_0$ 和 $U' = w-U$。由于 $x_0 \\sim \\mathrm{Uniform}(a,b)$，所以 $Y' \\sim \\mathrm{Uniform}(0,W)$。由于 $U \\sim \\mathrm{Uniform}(0,w)$，所以 $U' \\sim \\mathrm{Uniform}(0,w)$。$N_R$ 的表达式与 $N_L$ 的形式相同，因此期望也相同：\n$$E[N_R] = \\frac{W}{2w}$$\n跨步阶段的总期望评估次数是：\n$$E[N_{step}] = E[2 + N_L + N_R] = 2 + E[N_L] + E[N_R] = 2 + \\frac{W}{2w} + \\frac{W}{2w} = 2 + \\frac{W}{w}$$\n\n接下来，我们分析收缩阶段。\n此阶段开始于一个包含切片 $[a,b]$ 的区间 $[L,R]$。该区间的宽度是 $S = R-L$。最终的端点是 $L = x_0-U-N_L w$ 和 $R=x_0+w-U+N_R w$。\n$$S = (x_0+w-U+N_R w) - (x_0-U-N_L w) = w + (N_L + N_R)w = w(1 + N_L + N_R)$$\n在收缩阶段的每一步，从 $[L,R]$ 中均匀抽取一个点 $z$。如果 $z \\in [a,b]$，则该提议被接受。接受的概率是：\n$$p_{acc} = \\frac{\\text{length}([a,b])}{\\text{length}([L,R])} = \\frac{W}{S}$$\n直到接受发生所需的提议次数 $N_{shrink}$ 服从成功概率为 $p_{acc}$ 的几何分布。期望的试验次数是 $E[N_{shrink}] = 1/p_{acc}$。\n在给定 $x_0$ 和 $U$ 的条件下，收缩阶段的期望评估次数是：\n$$E[N_{shrink} | x_0, U] = \\frac{1}{p_{acc}} = \\frac{S}{W} = \\frac{w(1 + N_L + N_R)}{W}$$\n为了求得总的无条件期望 $E[N_{shrink}]$，我们对这个表达式关于 $x_0$ 和 $U$ 取期望：\n$$E[N_{shrink}] = E\\left[\\frac{w(1 + N_L + N_R)}{W}\\right] = \\frac{w}{W} E[1 + N_L + N_R]$$\n再次使用期望的线性性质：\n$$E[N_{shrink}] = \\frac{w}{W} (1 + E[N_L] + E[N_R])$$\n代入之前推导出的 $E[N_L]$ 和 $E[N_R]$ 的值：\n$$E[N_{shrink}] = \\frac{w}{W} \\left(1 + \\frac{W}{2w} + \\frac{W}{2w}\\right) = \\frac{w}{W} \\left(1 + \\frac{W}{w}\\right) = \\frac{w}{W} + 1$$\n\n最后，我们将两个阶段的期望评估次数相加，得到总的期望评估次数：\n$$E[N] = E[N_{step}] + E[N_{shrink}] = \\left(2 + \\frac{W}{w}\\right) + \\left(1 + \\frac{w}{W}\\right) = 3 + \\frac{W}{w} + \\frac{w}{W}$$\n这就是单次迭代中函数评估总数的期望值的封闭形式表达式。",
            "answer": "$$\\boxed{3 + \\frac{W}{w} + \\frac{w}{W}}$$"
        },
        {
            "introduction": "为了全面评估一个算法，我们不仅需要孤立地分析它，还应将其与其它方法进行比较。此最终练习将切片采样置于更广阔的MCMC方法背景中，将其与经典的随机游走Metropolis-Hastings算法进行理论性能的比较。通过运用 Peskun 序的理论 ()，您将能够形式化地证明在特定条件下切片采样的优越性，并通过计算滞后一阶自相关系数，揭示其在理想对称情况下的卓越性能。",
            "id": "3344725",
            "problem": "考虑一个对数密度为二次的一维目标分布，其概率密度函数定义为 $$\\pi(x) \\propto \\exp\\!\\left(-\\frac{x^{2}}{2\\sigma^{2}}\\right), \\quad x \\in \\mathbb{R},$$ 其中 $\\sigma^{2}  0$。使用两种马尔可夫链蒙特卡罗 (MCMC) 算法从 $\\pi$ 中采样：(i) 一种随机游走 Metropolis-Hastings (MH) 算法，其高斯提议为 $$q(y \\mid x) = \\frac{1}{\\sqrt{2\\pi \\tau^{2}}} \\exp\\!\\left(-\\frac{(y-x)^{2}}{2\\tau^{2}}\\right),$$ 提议方差为 $\\tau^{2}  0$，接受概率为 $$\\alpha(x,y) = \\min\\!\\left\\{1, \\frac{\\pi(y)}{\\pi(x)}\\right\\} = \\min\\!\\left\\{1, \\exp\\!\\left(-\\frac{y^{2}-x^{2}}{2\\sigma^{2}}\\right)\\right\\},$$ 以及 (ii) 一种简单切片采样器，通过引入一个辅助变量 $u$ 并按如下方式更新：给定当前状态 $x$，采样 $$u \\sim \\mathrm{Uniform}(0, \\pi(x)),$$ 然后采样下一个状态 $$x' \\sim \\mathrm{Uniform}(S(u)),$$ 其中切片为 $$S(u) = \\{x \\in \\mathbb{R} : \\pi(x) \\ge u\\}.$$\n\n仅使用可逆马尔可夫核、Peskun 序的基本定义和性质，以及增广空间上切片采样的吉布斯热浴构造，完成以下任务：\n\n1. 推导切片采样器在 $(x,u)$ 上的联合增广目标密度以及实现上述简单切片采样器更新所需的全条件分布。然后，使用这些条件分布，将 x-边缘链的单步转移核表示为关于辅助变量 $u$ 的积分形式。\n\n2. 陈述并应用具有共同不变分布 $\\pi$ 的可逆马尔可夫核的 Peskun 序定义，以比较简单切片采样器核与随机游走 Metropolis-Hastings 核。你的比较必须从两个核的结构特性（例如，是否存在自转移分量以及非对角概率质量如何分布）开始，并得出对于该二次对数密度目标，哪个核 Peskun 占优于另一个核的结论。\n\n3. 考虑可观测量 $f(x) = x$。在切片采样器平稳性的条件下，使用增广表示来计算由简单切片采样器产生的 x-边缘链中 $f$ 的滞后一阶自相关系数 $$\\rho_{1} = \\frac{\\mathrm{Cov}_{\\mathrm{stat}}(X_{n}, X_{n+1})}{\\mathrm{Var}_{\\pi}(X)}$$。请将最终答案表示为一个精确的实数，无需四舍五入。\n\n最后，基于第2部分建立的 Peskun 序，推断哪种算法（简单切片采样器或随机游走 Metropolis-Hastings）对平方可积函数 $f$ 的 $\\mathbb{E}_{\\pi}[f(X)]$ 估计量产生更低的渐近方差，并从第一性原理上解释为什么这个推断成立。你最终提交的答案必须仅为第3部分中指定的 $\\rho_{1}$ 的值。",
            "solution": "该问题要求对高斯目标下的简单切片采样器和随机游走 Metropolis-Hastings (RWMH) 算法进行三部分分析比较，然后进行概念性推断。最终输出必须是切片采样器的滞后一阶自相关系数。\n\n目标概率密度函数由 $\\pi(x) \\propto \\exp(-\\frac{x^{2}}{2\\sigma^{2}})$ 给出。对于所有的采样步骤和接受率，我们可以使用未归一化的密度，我们将其记为 $\\pi(x) = \\exp(-\\frac{x^{2}}{2\\sigma^{2}})$。在平稳分布下计算期望和方差时，我们考虑相应的归一化密度，即隐式地除以归一化常数 $Z = \\int_{-\\infty}^{\\infty} \\exp(-\\frac{t^{2}}{2\\sigma^{2}}) dt = \\sqrt{2\\pi\\sigma^2}$。\n\n### 第1部分：切片采样器核的推导\n\n简单切片采样器是一种辅助变量方法。它从一个增广空间 $(x,u)$ 上的联合分布中采样，该分布关于 $x$ 的边缘分布就是目标分布 $\\pi(x)$。\n\n联合密度 $\\pi(x,u)$ 被构造成在目标密度曲线下方的区域上是均匀的。它由下式给出：\n$$ \\pi(x,u) = \\begin{cases} K  \\text{if } 0  u  \\pi(x) \\\\ 0  \\text{otherwise} \\end{cases} $$\n其中 $K$ 是一个归一化常数。$x$ 的边缘分布是 $\\int_{0}^{\\infty} \\pi(x,u) du = \\int_{0}^{\\pi(x)} K du = K \\pi(x)$。为了使这个边缘分布与 $\\pi(x)$ 成正比，这个构造是有效的。我们可以设 $K=1$ 并在整个过程中使用未归一化的密度。所以，$\\pi(x,u) = \\mathbf{1}_{\\{0  u  \\pi(x)\\}}$。\n\n所描述的简单切片采样器算法是这个增广空间上的一个吉布斯采样器，它从 $u$ 和 $x$ 的全条件分布中迭代地更新它们。\n1.  **给定 $x$ 时 $u$ 的全条件分布**：$p(u \\mid x) \\propto \\pi(x,u) = \\mathbf{1}_{\\{0  u  \\pi(x)\\}}$。为了归一化，我们对 $u$ 进行积分：$\\int_{0}^{\\pi(x)} 1 \\, du = \\pi(x)$。因此，归一化的条件密度是\n    $$ p(u \\mid x) = \\frac{1}{\\pi(x)} \\mathbf{1}_{\\{0  u  \\pi(x)\\}} $$\n    这对应于从 $\\mathrm{Uniform}(0, \\pi(x))$ 中抽样 $u$，如问题所述。\n\n2.  **给定 $u$ 时 $x$ 的全条件分布**：$p(x \\mid u) \\propto \\pi(x,u) = \\mathbf{1}_{\\{0  u  \\pi(x)\\}}$。这个分布的支撑集是集合 $S(u) = \\{x \\in \\mathbb{R} : \\pi(x) \\ge u\\}$，即“切片”。条件密度在该集合上是均匀的。\n    $$ p(x \\mid u) = \\frac{1}{|S(u)|} \\mathbf{1}_{\\{x \\in S(u)\\}} $$\n    其中 $|S(u)| = \\int_{S(u)} 1 \\, dx$ 是切片的勒贝格测度。这对应于从 $\\mathrm{Uniform}(S(u))$ 中抽样 $x'$。\n\n$x$-边缘链的单步转移核 $P_{SS}(x' \\mid x)$，它给出了从状态 $x$ 移动到 $x'$ 的概率密度，是通过对辅助变量 $u$ 积分得到的。从 $x$ 到 $x'$ 的转移涉及首先从 $p(u \\mid x)$ 中抽样 $u$，然后从 $p(x' \\mid u)$ 中抽样 $x'$。\n$$ P_{SS}(x' \\mid x) = \\int_{0}^{\\infty} p(x' \\mid u) p(u \\mid x) \\, du $$\n代入条件密度：\n$$ P_{SS}(x' \\mid x) = \\int_{0}^{\\pi(x)} \\left( \\frac{1}{|S(u)|} \\mathbf{1}_{\\{x' \\in S(u)\\}} \\right) \\frac{1}{\\pi(x)} \\, du $$\n条件 $x' \\in S(u)$ 等价于 $\\pi(x') \\ge u$。指示函数 $\\mathbf{1}_{\\{\\pi(x') \\ge u\\}}$ 限制了 $u$ 的积分域。积分范围是 $u \\in [0, \\pi(x)]$，所以合并后的条件是 $0 \\le u \\le \\min(\\pi(x), \\pi(x'))$。\n$$ P_{SS}(x' \\mid x) = \\frac{1}{\\pi(x)} \\int_{0}^{\\min(\\pi(x), \\pi(x'))} \\frac{1}{|S(u)|} \\, du $$\n这就是以辅助变量 $u$ 的积分形式表示的 $x$-边缘链的单步转移核的表达式。\n\n### 第2部分：Peskun 序\n\nPeskun 序提供了一种比较共享相同不变分布 $\\pi$ 的两个可逆马尔可夫核 $P_1$ 和 $P_2$ 效率的方法。如果核 $P_2$ 的非对角转移概率一致地更大，即对于所有 $x$ 和所有不包含 $x$ 的可测集 $A$ 都有 $P_2(x,A) \\ge P_1(x,A)$，则称核 $P_2$ Peskun 优于 $P_1$（记为 $P_1 \\preceq_P P_2$）。一个直接的推论和一个更实用的比较条件，特别是对于具有密度的核，是比较它们的自转移概率。如果对于所有 $x$ 都有 $P_1(x, \\{x\\}) \\ge P_2(x, \\{x\\})$，那么在估计量的渐近方差方面，$P_2$ 至少和 $P_1$ 一样好。\n\n我们来分析所讨论的两个核的结构。\n\n1.  **随机游走 Metropolis-Hastings (RWMH) 核**：从 $x$ 到 $y$ 的转移是从一个密度 $q(y \\mid x)$ 中提议，并以概率 $\\alpha(x,y)$ 被接受。如果提议被拒绝，链将停留在 $x$。该核可以写为：\n    $$ P_{MH}(x, dy) = q(y \\mid x)\\alpha(x,y) \\, dy + \\left( 1 - \\int_{-\\infty}^{\\infty} q(z \\mid x)\\alpha(x,z) \\, dz \\right) \\delta_x(dy) $$\n    其中 $\\delta_x$ 是 $x$ 处的狄拉克德尔塔测度。第二项表示自转移（拒绝）的概率质量。由于接受概率 $\\alpha(x,z)$ 不总是 $1$，因此存在一个非零的拒绝概率，$r(x) = P_{MH}(x, \\{x\\})  0$。\n\n2.  **简单切片采样器核**：如第1部分所推导，转移密度为\n    $$ P_{SS}(x' \\mid x) = \\frac{1}{\\pi(x)} \\int_{0}^{\\min(\\pi(x), \\pi(x'))} \\frac{1}{|S(u)|} \\, du $$\n    对于我们的特定目标 $\\pi(x) \\propto \\exp(-\\frac{x^{2}}{2\\sigma^{2}})$，切片 $S(u)$ 是一个区间 $[-c(u), c(u)]$，一个连续集。下一个状态 $x'$ 是从一个连续分布 $\\mathrm{Uniform}(S(u))$ 中抽取的。因此，抽取到与起始点 $x$ 完全相同的点 $x'$ 的概率为零。核 $P_{SS}$ 关于勒贝格测度是纯粹绝对连续的，并且没有原子部分。也就是说，$P_{SS}(x, \\{x\\}) = 0$。\n\n**比较**：\n我们比较自转移概率：\n-   对于几乎所有 $x$，$P_{MH}(x, \\{x\\}) = r(x)  0$。\n-   对于所有 $x$，$P_{SS}(x, \\{x\\}) = 0$。\n\n显然，对于所有 $x$ 都有 $P_{SS}(x, \\{x\\}) \\le P_{MH}(x, \\{x\\})$。这个不等式意味着切片采样器永远不会“卡”在当前状态，而 RWMH 算法则可能会。一个总是移动到新状态的算法比一个可能停留在原地的算法更有效地探索状态空间。根据 Peskun 序及其扩展理论，具有较小自转移概率的核会导致估计量的渐近方差更小。因此，对于这个目标分布，简单切片采样器 Peskun 占优于（或在基于渐近方差的相关序中更优于）随机游走 Metropolis-Hastings 算法。$P_{MH} \\preceq_P P_{SS}$。\n\n### 第3部分：切片采样器的滞后一阶自相关\n\n我们需要计算可观测量 $f(x)=x$ 的滞后一阶自相关系数：\n$$ \\rho_{1} = \\frac{\\mathrm{Cov}_{\\mathrm{stat}}(X_{n}, X_{n+1})}{\\mathrm{Var}_{\\pi}(X)} $$\n链处于平稳状态，所以 $X_n \\sim \\pi$。目标密度是高斯分布 $N(0, \\sigma^2)$。因此：\n-   $\\mathbb{E}_{\\pi}[X] = 0$\n-   $\\mathrm{Var}_{\\pi}(X) = \\mathbb{E}_{\\pi}[X^2] - (\\mathbb{E}_{\\pi}[X])^2 = \\sigma^2 - 0 = \\sigma^2$。\n\n协方差是 $\\mathrm{Cov}_{\\mathrm{stat}}(X_{n}, X_{n+1}) = \\mathbb{E}[X_{n}X_{n+1}] - \\mathbb{E}[X_{n}]\\mathbb{E}[X_{n+1}]$。由于链是平稳的，$\\mathbb{E}[X_n] = \\mathbb{E}[X_{n+1}] = \\mathbb{E}_\\pi[X] = 0$。\n因此，$\\mathrm{Cov}_{\\mathrm{stat}}(X_{n}, X_{n+1}) = \\mathbb{E}[X_{n}X_{n+1}]$。\n\n我们使用全期望定律和切片采样器的增广表示来计算这个期望。令 $(X_n, U_{n+1}, X_{n+1})$ 表示一个完整的转移。\n$$ \\mathbb{E}[X_n X_{n+1}] = \\mathbb{E}_{X_n} \\left[ X_n \\mathbb{E}[X_{n+1} \\mid X_n] \\right] $$\n内部的期望是给定当前状态 $x_n=x$ 时下一个状态的条件期望。这是通过对中间变量 $u$ 平均来计算的：\n$$ \\mathbb{E}[X_{n+1} \\mid X_n=x] = \\mathbb{E}_{u \\sim p(u|x)} \\left[ \\mathbb{E}[X_{n+1} \\mid U_{n+1}=u, X_n=x] \\right] $$\n$X_{n+1}$ 的抽取只依赖于 $U_{n+1}$，而不依赖于 $X_n$。所以，$\\mathbb{E}[X_{n+1} \\mid U_{n+1}=u, X_n=x] = \\mathbb{E}[X_{n+1} \\mid U_{n+1}=u]$。\n给定 $U_{n+1}=u$ 时 $X_{n+1}$ 的分布是 $\\mathrm{Uniform}(S(u))$。我们来刻画切片 $S(u)$：\n$$ S(u) = \\{x \\in \\mathbb{R} : \\exp(-\\frac{x^{2}}{2\\sigma^{2}}) \\ge u\\} $$\n这等价于 $-\\frac{x^2}{2\\sigma^2} \\ge \\ln(u)$，或 $x^2 \\le -2\\sigma^2 \\ln(u)$。这定义了一个区间 $[-c(u), c(u)]$，其中 $c(u) = \\sqrt{-2\\sigma^2\\ln(u)}$。这个区间关于 $0$ 对称。\n从 $\\mathrm{Uniform}([-c(u), c(u)])$ 中抽取的随机变量的期望是：\n$$ \\mathbb{E}[X_{n+1} \\mid U_{n+1}=u] = \\int_{-c(u)}^{c(u)} y \\frac{1}{2c(u)} \\, dy = \\frac{1}{2c(u)} \\left[ \\frac{y^2}{2} \\right]_{-c(u)}^{c(u)} = 0 $$\n由于对于任何 $u$ 值，这个条件期望都是 $0$，所以对 $u$ 的期望也为 $0$：\n$$ \\mathbb{E}[X_{n+1} \\mid X_n=x] = \\mathbb{E}_{u \\sim p(u|x)} [0] = 0 $$\n这对任何起始状态 $x$ 都成立。现在我们可以计算协方差：\n$$ \\mathrm{Cov}_{\\mathrm{stat}}(X_{n}, X_{n+1}) = \\mathbb{E}[X_n X_{n+1}] = \\mathbb{E}_{X_n}[X_n \\cdot 0] = 0 $$\n最后，滞后一阶自相关系数是：\n$$ \\rho_{1} = \\frac{0}{\\sigma^2} = 0 $$\n这个结果是目标分布和可观测量 $f(x)=x$ 两者对称性的一个特殊结果。\n\n### 关于渐近方差的概念性推断\n\n基于第2部分建立的 Peskun 序 ($P_{MH} \\preceq_P P_{SS}$)，我们推断对于任何平方可积函数 $f$ 的 $\\mathbb{E}_{\\pi}[f(X)]$ 估计量，**简单切片采样器会产生更低（或相等）的渐近方差**。\n\n这个推断从第一性原理上是成立的，因为 MCMC 估计量的渐近方差与积分自相关时间 (IACT) 成正比，即 $\\tau_f = 1 + 2\\sum_{k=1}^\\infty \\rho_k(f)$，其中 $\\rho_k(f)$ 是过程 $f(X_n)$ 的滞后 $k$ 阶自相关。Peskun 序与马尔可夫链的收敛速度内在地联系在一起。一个 Peskun 占优的核（如此处的切片采样器）对应于转移算子的第二大特征值模更小，这意味着谱隙更大，收敛到平稳分布的速度更快。这种更快的混合降低了连续样本之间的相关性，导致对于 $k \\ge 1$ 的自相关值 $\\rho_k(f)$ 更低。更小的 IACT 直接转化为更小的渐近方差，这意味着对于固定数量的样本 $N$，切片采样器产生的估计量将更精确。这种优越性的结构性原因在于切片采样器避免了自转移，这使得它能够比 RWMH 算法更有效地探索状态空间，后者可能因拒绝而停留在同一状态。",
            "answer": "$$\\boxed{0}$$"
        }
    ]
}