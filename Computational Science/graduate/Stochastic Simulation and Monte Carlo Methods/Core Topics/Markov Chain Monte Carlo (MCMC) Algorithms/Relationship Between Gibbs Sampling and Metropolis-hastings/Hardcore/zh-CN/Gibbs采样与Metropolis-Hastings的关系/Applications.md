## 应用与[交叉](@entry_id:147634)学科联系

在前面的章节中，我们已经深入探讨了 Gibbs 抽样和 Metropolis-Hastings (MH) 算法的基本原理与机制，并确立了一个核心观点：Gibbs 抽样可以被视为 Metropolis-Hastings 算法的一种特殊情况。在这种特殊情况下，提议分布恰好是目标[条件分布](@entry_id:138367)本身，从而使得[接受概率](@entry_id:138494)恒为 1。这一理论上的统一不仅仅是学术上的精炼，更重要的是，它为设计、理解和改进解决复杂现实世界问题的[马尔可夫链蒙特卡洛](@entry_id:138779)（MCMC）方法提供了强大而灵活的框架。

本章的目标并非重复这些核心原理，而是展示它们的实际效用、扩展和跨学科整合。我们将通过一系列源于不同领域的应用问题，探索如何利用 Gibbs 抽样与 MH 算法之间的深刻联系，来构建应对各种挑战的先进[抽样策略](@entry_id:188482)。这些应用将揭示，从理论上的特例到实践中的[混合算法](@entry_id:171959)，这一统一视角是现代[计算统计学](@entry_id:144702)中许多最强大工具的基石。

### 混合抽样器：[Metropolis-within-Gibbs](@entry_id:751940) [范式](@entry_id:161181)

在实际的[贝叶斯建模](@entry_id:178666)中，我们很少遇到所有参数的满条件分布都具有标准形式（即共轭性）的理想情况。一个更常见的场景是，模型中的一部分参数（例如，在[线性模型](@entry_id:178302)中的[方差](@entry_id:200758)参数，如果使用逆伽马先验）具有易于抽样的满条件分布，而另一部分参数（例如，非[共轭先验](@entry_id:262304)下的[位置参数](@entry_id:176482)或复杂模型中的超参数）的满[条件分布](@entry_id:138367)则难以处理。在这种情况下，纯粹的 Gibbs 抽样器无法实现。

这正是 Metropolis-Hastings 算法的通用性大放异彩的地方。我们可以构建一个**混合抽样器（hybrid sampler）**，也常被称为 **[Metropolis-within-Gibbs](@entry_id:751940)** 抽样器。其核心思想是在 MCMC 的每一次迭代中，对不同参数块采用不同的更新策略：对于那些满条件分布已知的参数，我们执行标准的 Gibbs 步骤；对于那些满条件分布复杂或未知的参数，我们嵌入一个 MH 步骤。这种组合是有效的，因为 Gibbs 步骤和 MH 步骤都是保证目标[后验分布](@entry_id:145605)不变的有效马尔可夫转移。因此，它们的任意组合（例如，在一个系统扫描中依次执行）同样能保持[目标分布](@entry_id:634522)不变。

例如，在一个[分层贝叶斯模型](@entry_id:169496)中，我们可能为均值参数 $\mu$ 设置了共轭的正态先验，但为其精度参数 $\kappa$ 设置了一个非共轭的对数正态先验。在这种情况下，$\mu$ 的满[条件分布](@entry_id:138367)是正态分布，可以直接进行 Gibbs 抽样。然而，$\kappa$ 的满条件分布并非[标准形式](@entry_id:153058)。为了更新 $\kappa$，我们可以构造一个 MH 步骤。一个常见的策略是在对数尺度上使用[随机游走](@entry_id:142620)提议，例如，从当前值 $\kappa$ 提议一个新值 $\kappa'$，其中 $\log \kappa' = \log \kappa + \eta$，而 $\eta$ 来自一个均值为零的[正态分布](@entry_id:154414) $\mathcal{N}(0, s^2)$。由于该提议在对数尺度上对称，但在原始尺度上并不对称，因此在计算接受概率时必须包含一个雅可比行列式（Jacobian）衍生的 Hastings 修正项。通过这种方式，我们成功地为整个参数空间构建了一个有效的 MCMC 抽样器，即使模型不完全共轭。

设计 [Metropolis-within-Gibbs](@entry_id:751940) 步骤的一个关键工程挑战是构造一个高效的提议分布 $q(\cdot \mid \cdot)$。一个糟糕的[提议分布](@entry_id:144814)会导致极低的接受率或极慢的[状态空间](@entry_id:177074)探索。一个有效的策略是使用一个能够很好地逼近真实满条件分布的[分布](@entry_id:182848)作为提议。在许多模型中，例如贝叶斯逻辑斯蒂回归，虽然满条件分布 $\pi(\beta_j \mid \beta_{-j}, y)$ 不是[标准形式](@entry_id:153058)，但它通常是单峰且大致对称的。在这种情况下，我们可以通过[拉普拉斯近似](@entry_id:636859)（Laplace approximation）来构造一个[提议分布](@entry_id:144814)。具体来说，我们可以找到该满[条件分布](@entry_id:138367)的众数（mode）$m$，并在该点计算其对[数密度](@entry_id:268986)的[二阶导数](@entry_id:144508)，从而得到一个局部的[高斯近似](@entry_id:636047) $\mathcal{N}(m, s^2)$。使用这个[高斯分布](@entry_id:154414)作为独立的提议分布，可以设计出一个高效的 MH 步骤来替代棘手的 Gibbs 步骤。这种方法将[优化技术](@entry_id:635438)（寻找众数）与抽样技术巧妙地结合起来。

这种[混合方法](@entry_id:163463)也凸显了 Gibbs 抽样与 MH 算法在实践中的一个重要区别：调优。Gibbs 步骤，作为接受概率恒为 1 的 MH 算法特例，其本身是“自适应”的，它从真实的条件分布中抽样，无需任何调优参数。相比之下，嵌入的 MH 步骤（如[随机游走](@entry_id:142620)）通常含有一个或多个需要仔细调优的参数，例如提议分布的尺度（或步长）$s_i$。为了达到理想的接受率（理论上常建议为 0.234 或 0.44，具体取决于模型维度和结构），研究人员常常需要采用自适应 MCMC 方案，例如使用 Robbins-Monro [随机近似](@entry_id:270652)算法，在抽样过程中动态调整 $s_i$。这种鲜明的对比进一步阐明了将 Gibbs 视为一个无需调优的、完美的 MH 步骤的观点。

### [数据增强](@entry_id:266029)：简化棘手的后验分布

在许多统计模型中，后验分布的复杂性并非源于先验，而是源于[似然函数](@entry_id:141927)本身。例如，像 Probit 或 Logistic 回归这样的[广义线性模型](@entry_id:171019)，其似然函数包含[非线性](@entry_id:637147)的链接函数（分别是正态CDF和[Sigmoid函数](@entry_id:137244)），导致参数的后验分布通常没有解析形式，直接抽样非常困难。

**[数据增强](@entry_id:266029)（Data Augmentation）**是一种强大的策略，它通过引入一组巧妙选择的“辅助”或“潜”变量（latent variables），使得在增广的参数和潜变量空间上的联合后验分布变得易于处理。其核心思想是，在增广空间上的 Gibbs 抽样（如果可行）远比在原始空间上进行复杂的 MH 抽样要简单和高效。

以贝叶斯 Probit 回归为例，其[似然函数](@entry_id:141927)涉及正态[累积分布函数](@entry_id:143135) $\Phi(\cdot)$，这使得后验分布难以处理。[数据增强](@entry_id:266029)方法为此模型引入一组潜变量 $z = (z_1, \dots, z_n)$，其定义如下：对于每个观测 $y_i \in \{0, 1\}$，我们假设存在一个潜变量 $z_i \sim \mathcal{N}(x_i^\top \beta, 1)$，并且观测值是通过 $y_i = \mathbf{1}(z_i > 0)$ 产生的。这个设定恰好等价于原始的 Probit 模型。然而，它的巨大优势在于，在包含 $(\beta, z)$ 的增广空间上，满条件分布变得非常简单：
1.  给定 $z$ 和 $X$，参数 $\beta$ 的满条件分布 $p(\beta \mid z, y, X)$ 简化为标准[贝叶斯线性回归](@entry_id:634286)的后验，即一个多维[高斯分布](@entry_id:154414)。这是因为给定 $z$，模型就变成了一个 $z$ 对 $X$ 的线性回归。
2.  给定 $\beta$ 和 $y_i$，每个潜变量 $z_i$ 的满条件分布 $p(z_i \mid \beta, y_i, x_i)$ 是一个被截断的[正态分布](@entry_id:154414)。如果 $y_i=1$，则其为一个在 $(0, \infty)$ 区间上截断的[正态分布](@entry_id:154414)；如果 $y_i=0$，则其为一个在 $(-\infty, 0]$ 区间上截断的正态分布。

由于多维高斯分布和截断[正态分布](@entry_id:154414)都是可以直接抽样的，因此我们可以构造一个简单的两步 Gibbs 抽样器，在 $\beta$ 和 $z$ 的满[条件分布](@entry_id:138367)之间交替抽样。这个过程完全避免了在原始复杂后验上的 MH 抽样。从我们统一的视角来看，这个增广空间上的 Gibbs 抽样器只是一个特殊的 MH 算法，其每一步的接受率都恰好为 1。这种将棘手问题转化为标准问题的思想，在计量经济学、[生物统计学](@entry_id:266136)和机器学习等领域得到了广泛应用。

### 应对挑战性几何的先进策略

MCMC 抽样器的性能（特别是收敛速度和样本的[自相关](@entry_id:138991)性）极大地依赖于目标后验分布的几何形态。当后验分布呈现出强相关性或多峰性时，简单的抽样算法往往会举步维艰。将 Gibbs 抽样理解为 MH 算法的特例，为我们开发克服这些几何挑战的先进策略提供了深刻的见解。

#### 面向相关后验的块抽样

在许多分层模型或具有共[线性预测](@entry_id:180569)变量的模型中，参数的[后验分布](@entry_id:145605)通常表现出强烈的相关性。例如，在一个分层正态模型中，个[体效应](@entry_id:261475) $\theta_i$ 与其总体的均值 $\mu$ 和[方差](@entry_id:200758) $\tau^2$ 在后验上是高度相关的。这种相关性在[后验概率](@entry_id:153467)密度[等高线图](@entry_id:178003)上表现为狭长的“山脊”。

对于这样的[分布](@entry_id:182848)，逐分量（single-site）的 Gibbs 抽样器或 MH 抽样器会表现出极差的混合性能。由于每次更新只允许沿着坐标轴方向移动，抽样器为了保持在概率密度高的山脊区域，只能采取微小的“之”字形步伐，导致样本之间存在高度自相关，收敛非常缓慢。在一个典型的分层模型中，与使用微小步长的[随机游走](@entry_id:142620) MH 抽样器相比，纯 Gibbs 抽样器虽然避免了拒绝，但其轴对齐的移动方式仍然受限于这种几何约束，尽管它的性能通常优于朴素的 MH 算法。

解决这个问题的根本方法是**块抽样（block sampling）**。其核心思想是将高度相关的参数分组到一个“块”中，并对整个块进行联合更新。通过联合提议一个跨越多个维度的移动，抽样器可以沿着相关性的方向（即沿着山脊）进行探索，从而实现更大幅度的有效移动，显著改善混合性能。

在最理想的情况下，如果整个块的联合满条件分布是可抽样的，我们可以执行一个块 Gibbs 步骤。例如，在一个简单的[二元正态分布](@entry_id:165129)中，将两个相关的变量 $(X, Y)$ 作为一个块，直接从它们的联合分布中抽样，可以在一步之内产生一个来自[目标分布](@entry_id:634522)的[独立样本](@entry_id:177139)，彻底消除相关性导致的混合慢问题。

然而，在更复杂的应用中，例如具有相关预测变量的稀疏[贝叶斯线性回归](@entry_id:634286)中，[相关系数](@entry_id:147037)块的联合满[条件分布](@entry_id:138367)往往是棘手的。在这种情况下，块抽样思想与 [Metropolis-within-Gibbs](@entry_id:751940) [范式](@entry_id:161181)完美结合：我们可以识别出相关的系数块，并为它们设计一个联合的 MH 提议。一个高效的[提议分布](@entry_id:144814)应该能近似该块的真实联合[条件分布](@entry_id:138367)，例如，使用一个考虑了预测变量相关性和[先验信息](@entry_id:753750)的多维高斯分布。这种**块 [Metropolis-within-Gibbs](@entry_id:751940)** 策略是处理高维模型中后验相关性的标准且强大的技术。

#### [数据增强](@entry_id:266029)与抽样器坍缩的权衡

在设计抽样器时，一个常见的策略是“坍缩”（collapsing），即通过解析地积分掉（[边缘化](@entry_id:264637)）某些“讨厌”的参数来降低参数空间的维度。这通常被认为可以提高效率，因为它减少了需要抽样的变量数量。然而，这种直觉并非总是正确的。

正如我们在一个简单的[潜变量](@entry_id:143771)高斯模型中所看到的，坍缩操作可能会对 MCMC 的性能产生微妙甚至有害的影响。当一个潜变量 $Z$ 同时影响两个观测变量 $X$ 和 $Y$ 时，$X$ 和 $Y$ 在给定 $Z$ 的条件下是独立的。然而，如果我们将 $Z$ 积分掉，在 $X$ 和 $Y$ 的[边际分布](@entry_id:264862)中，它们会变得相关。当 $Z$ 的先验[方差](@entry_id:200758)很大时，这种诱导出的边际相关性会变得非常强。

这就导致了一个关键的权衡：
-   **坍缩的 Gibbs 抽样器**：在一个积分掉 $Z$ 的 $(X, Y)$ 空间上进行抽样。由于 $X$ 和 $Y$ 边际相关性强，两步 Gibbs 抽样器（在 $p(X|Y)$ 和 $p(Y|X)$ 之间交替）会表现出与前述单点抽样器在相关后验上类似的“之”字形行为，导致混合缓慢。
-   **未坍缩的（[数据增强](@entry_id:266029)）Gibbs 抽样器**：在完整的 $(X, Y, Z)$ 空间上进行抽样。通过在 $Z$ 上进行条件化，该抽样器打破了 $X$ 和 $Y$ 之间的强相关性。更新 $X$（给定 $Y, Z$）和更新 $Y$（给定 $X, Z$）的步骤变得更加高效，因为它们利用了[条件独立性](@entry_id:262650)。

在这种情况下，与普遍的直觉相反，通过[数据增强](@entry_id:266029)（即不坍缩 $Z$）构建的抽样器实际上可能比坍缩的抽样器混合得更快。这揭示了 MCMC 算法设计的一个深刻原则：有时，将问题提升到一个更高维度的、但结构更简单的空间中，比在原始的、几何形态更复杂的低维空间中工作要更有效率。

#### 并行[回火](@entry_id:182408)：征服多峰[分布](@entry_id:182848)

许多复杂的科学模型，如蛋白质折叠模型或[贝叶斯模型选择](@entry_id:147207)问题，其[后验分布](@entry_id:145605)可能具有多个被低概率区域隔开的显著模式（即多峰性）。标准的 MCMC 算法，一旦陷入其中一个模式的[引力](@entry_id:175476)盆，就很难跨越低概率的“沙漠”去探索其他模式。

**并行[回火](@entry_id:182408)（Parallel Tempering）**，或称副本交换 MCMC（Replica Exchange MCMC），是为解决这一挑战而设计的强大技术。其思想是同时运行 $K$ 个 MCMC 链（称为副本），每个链在不同的“温度”下探索目标分布。具体来说，对于一个目标密度 $\pi(x) \propto \exp(-U(x))$，我们定义一个温度阶梯 $\beta_1 < \beta_2 < \dots < \beta_K=1$，并让第 $k$ 个链的[目标分布](@entry_id:634522)为 $\pi_{\beta_k}(x) \propto [\pi(x)]^{\beta_k} = \exp(-\beta_k U(x))$。
-   高温链（$\beta_k$ 小）的[目标分布](@entry_id:634522)更“平坦”，能够轻易地跨越能量壁垒，对整个[状态空间](@entry_id:177074)进行全局探索。
-   低温链（$\beta_k$ 大，特别是 $\beta_K=1$ 的目标链）的[目标分布](@entry_id:634522)更“尖锐”，能够精确地对局部模式进行细致的探索。

并行[回火](@entry_id:182408)算法的核心在于引入了**副本交换步骤**。在 MCMC 运行过程中，算法会定期尝试交换两个相邻温度（例如 $\beta_i$ 和 $\beta_j$）的副本的状态。假设副本 $i$ 的当前状态是 $x_i$，副本 $j$ 的当前状态是 $x_j$。交换提议被接受的概率由一个 MH [接受概率](@entry_id:138494)给出：
$$
\alpha = \min\left\{1, \frac{\pi_{\beta_i}(x_j) \pi_{\beta_j}(x_i)}{\pi_{\beta_i}(x_i) \pi_{\beta_j}(x_j)}\right\} = \min\left\{1, \exp\left( (\beta_i - \beta_j)[U(x_i) - U(x_j)] \right)\right\}
$$
这个交换步骤允许高温链探索到的新模式有机会“传递”给低温链，而低温链中精细探索的良好样本也有机会“传递”给高温链以帮助其跳出局部。整个并行[回火](@entry_id:182408)方案可以被看作是在一个巨大的[积空间](@entry_id:151693) $(\mathcal{X}^K)$ 上运行的 MCMC，其更新步骤包括了各个副本内部的常规 MCMC 更新（可以视为 Gibbs 步骤）和副本之间的交换更新（MH 步骤）。

### 前沿领域与高级应用

MH 算法的通用性及其与 Gibbs 抽样的关系，使其成为解决统计学和相关科学领域中一些最前沿问题的核心工具。

#### 用于模型选择的跨维 MCMC

在[贝叶斯模型选择](@entry_id:147207)或[模型平均](@entry_id:635177)的场景中，我们面临的挑战是后验分布定义在一个跨越多个模型的空间上，而这些模型的参数维度可能是不同的。例如，在变量选择问题中，比较一个包含 3 个预测变量的模型和一个包含 5 个预测变量的模型。

**可逆跳转 MCMC（Reversible Jump MCMC, [RJMCMC](@entry_id:754374)）**是为处理此类问题而设计的 MH 算法的精巧扩展。它允许[马尔可夫链](@entry_id:150828)在不同维度的[参数空间](@entry_id:178581)之间“跳转”。一个典型的 [RJMCMC](@entry_id:754374) 步骤包括：
1.  提议一个要跳转到的新模型 $k'$。
2.  为了匹配维度（这是 MH 提议与接受步骤能够成立的关键），从一个辅助[分布](@entry_id:182848)中抽取一个随机向量 $u$。
3.  通过一个精心设计的、可逆的确定性函数 $T$，将当前模型参数 $\theta_k$ 和辅助向量 $u$ 映射到新模型的参数 $\theta_{k'}$ 和其对应的辅助向量 $u'$。
4.  计算一个包含目标密度比、提议概率比和该映射的[雅可比行列式](@entry_id:137120) $|J|$ 的接受概率。

这个复杂的 MH 步骤可以无缝地嵌入到一个更大的 Gibbs 框架中。例如，在一个模型中，某些参数可能在所有模型中都存在（共享参数 $\psi$），而另一些则是模型特有的（$\theta_k$）。一个有效的抽样器可以交替进行：(a) 一个标准的 Gibbs 或 MH 步骤来更新共享参数 $\psi$（给定当前模型 $k$）；(b) 一个 [RJMCMC](@entry_id:754374) 步骤来更新模型索引 $k$ 及其特定参数 $\theta_k$（给定 $\psi$）。

#### 应对双重难解[分布](@entry_id:182848)

在某些高级[统计模型](@entry_id:165873)中，例如统计物理中的某些[格点模型](@entry_id:184345)或大规模[网络模型](@entry_id:136956)，我们可能遇到“双重难解”（doubly intractable）的后验分布。这意味着，不仅后验分布的归一化常数未知，连似然函数 $p(y|\theta) = f(y|\theta)/Z(\theta)$ 本身的归一化常数 $Z(\theta)$ 也是一个依赖于参数 $\theta$ 且无法计算的棘手积分或和。

对于这类问题，标准的 MH 算法会失败，因为计算接受率需要评估似然比 $p(y|\theta')/p(y|\theta)$，这会涉及到无法计算的 $Z(\theta')/Z(\theta)$ 比值。

**交换算法（Exchange Algorithm）**是一种巧妙的解决方案。它是一种在增广空间上构建的 MH 算法。其核心思想是，在提议一个新参数 $\theta'$ 的同时，从该新参数下的[似然](@entry_id:167119)模型 $p(u|\theta') = f(u|\theta')/Z(\theta')$ 中抽取一个辅助数据点 $u$。然后，构造一个特殊的接受率，该接受率同时包含真实数据 $y$ 和辅助数据 $u$ 在不同参数下的评估值。通过精巧的构造，棘手的[归一化常数](@entry_id:752675)比值 $Z(\theta')/Z(\theta)$ 在接受率的分子和分母中被另一项 $Z(\theta)/Z(\theta')$ 精确地抵消了。这个过程要求我们能够从 $p(u|\theta')$ 中进行[精确抽样](@entry_id:749141)，即便我们不知道 $Z(\theta')$。

交换算法与另一类称为**伪边际（Pseudo-Marginal）MH** 的方法密切相关。在伪边际方法中，如果我们可以构造一个似然函数 $p(y|\theta)$ 的[无偏估计量](@entry_id:756290)，我们就可以在增广空间中构建一个精确的 MH 算法。这些高级技术再次展示了 MH 框架的非凡适应性，使其能够处理传统方法束手无策的复杂棘手模型。

#### [并行计算](@entry_id:139241)时代的 MCMC

随着数据集和模型规模的爆炸式增长，将 MCMC 方法扩展到并行计算环境已成为一个活跃的研究领域。对于定义在大型图结构上的模型（如图[马尔可夫随机场](@entry_id:751685)），一个自然的想法是并行地更新图中不同节点上的变量。

如果我们将图中互不相邻的节点（即一个**[独立集](@entry_id:270749)**）分组，那么在给定图中所有其他节点状态的情况下，这些节点上的变量是条件独立的。因此，我们可以对一个[独立集](@entry_id:270749)中的所有变量同时进行并行的 Gibbs 更新，这在数学上等价于一个单块的、有效的 Gibbs 步骤。通过对图进行**着色**（graph coloring），将节点划分为若干个[独立集](@entry_id:270749)（颜色类），然后依次对每个颜色类进行并行更新，就构成了一个有效的并行 Gibbs 抽样器。

然而，在更复杂的异步并行环境中，不同的处理器可能基于“陈旧”的（stale）邻居节点信息来进行更新，这会破坏标准 Gibbs 抽样器的理论保证。有趣的是，MH 框架再次提供了解决方案。我们可以将这种[异步更新](@entry_id:266256)过程建模为一个在[增广状态空间](@entry_id:169453)（包括真实[状态和](@entry_id:193625)处理器读取的陈旧状态）上的 MCMC。通过推导一个相应的 MH 接受-拒绝步骤，可以修正由陈旧信息引入的偏差，从而恢复算法的精确性。这表明，即使在复杂的现代计算架构中，MH 算法的基本原理依然是保证抽样正确性的理论基石。

### [算子理论](@entry_id:139990)视角下的[收敛性分析](@entry_id:151547)

最后，Gibbs 抽样与 MH 算法之间的联系也可以从一个更抽象的数学视角——[算子理论](@entry_id:139990)——来理解，这为分析 MCMC 算法的收敛速度提供了深刻的工具。

我们可以将 MCMC 的转移核视为作用在[函数空间](@entry_id:143478)（例如 $L^2(\pi)$）上的一个[线性算子](@entry_id:149003)。从这个角度看，逐分量 Gibbs 抽样器在处理高斯目标分布时的行为，与[数值线性代数](@entry_id:144418)中用于[求解线性方程组](@entry_id:169069)的**高斯-赛德尔（Gauss-Seidel）[迭代法](@entry_id:194857)**有着深刻的类比。描述 Gibbs 抽样器[均值收敛](@entry_id:269534)的[转移矩阵](@entry_id:145510)，与[高斯-赛德尔迭代](@entry_id:136271)矩阵是等价的。这为使用线性代数的工具（如[谱半径](@entry_id:138984)）来分析 Gibbs 抽样器的[收敛率](@entry_id:146534)提供了可能。

此外，逐分量更新的根本局限性——“之”字形行为——也可以用[算子理论](@entry_id:139990)的语言来精确描述。我们可以将每次坐标更新定义为一个算子 $P_i$。理想的联合更新算子可以被想象为这些算子之和的指数，而一个扫描周期的 Gibbs 抽样器则是这些算子的乘积。算子乘积与算子和的指数之间的误差，在领先阶上由这些算子的**对易子（commutator）** $[P_i, P_j] = P_i P_j - P_j P_i$ 决定。对于相关性强的[后验分布](@entry_id:145605)，这些坐标更新算子是高度非对易的，其对易子的谱半径（最大[特征值](@entry_id:154894)模）量化了这种序贯更新所引入的内在“[分裂误差](@entry_id:755244)”，从而为收敛缓慢提供了一个根本性的数学解释。