{
    "hands_on_practices": [
        {
            "introduction": "The Gibbs sampler is a cornerstone of MCMC, valued for its simplicity when full conditional distributions are accessible. This exercise provides a foundational, hands-on walkthrough of the algorithm's core mechanics. By deriving the conditional distributions for a bivariate normal target and manually performing one sampling step, you will gain a concrete understanding of how the chain progresses by iteratively drawing from these simpler, lower-dimensional distributions .",
            "id": "3313366",
            "problem": "Consider a target distribution that is a bivariate normal with mean vector $\\boldsymbol{\\mu} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$ and covariance matrix $\\boldsymbol{\\Sigma} = \\begin{pmatrix} 4  3 \\\\ 3  9 \\end{pmatrix}$. A Gibbs sampler is a Markov chain Monte Carlo (MCMC) algorithm that iteratively samples from the full conditional distributions. Starting from first principles for multivariate normal distributions, derive explicit expressions for the full conditional distributions $p(x_{1} \\mid x_{2})$ and $p(x_{2} \\mid x_{1})$ in terms of the entries of $\\boldsymbol{\\mu}$ and $\\boldsymbol{\\Sigma}$. Then, perform one complete Gibbs sweep in the order $x_{1}$-then-$x_{2}$ starting from the current state $(x_{1}^{(0)}, x_{2}^{(0)}) = (0, 0)$, using independent standard normal variates $z_{1} = 1$ and $z_{2} = 0$ to realize the updates. State the updated pair $(x_{1}^{(1)}, x_{2}^{(1)})$ as exact expressions. Provide your final answer as a single row vector. Do not round.",
            "solution": "The problem requires us to first derive the full conditional distributions for a bivariate normal distribution and then use them to perform one sweep of a Gibbs sampler.\n\nLet a random vector $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$ follow a bivariate normal distribution with mean vector $\\boldsymbol{\\mu}$ and covariance matrix $\\boldsymbol{\\Sigma}$:\n$$\n\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\n$$\nwhere\n$$\n\\boldsymbol{\\mu} = \\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\end{pmatrix} \\quad \\text{and} \\quad \\boldsymbol{\\Sigma} = \\begin{pmatrix} \\Sigma_{11}  \\Sigma_{12} \\\\ \\Sigma_{21}  \\Sigma_{22} \\end{pmatrix}\n$$\n\nThe full conditional distributions for a multivariate normal are themselves normal. For the bivariate case, the conditional distribution of $x_1$ given $x_2$ is $p(x_1 \\mid x_2) = \\mathcal{N}(\\mu_{1|2}, \\sigma_{1|2}^2)$, where:\n- Conditional mean: $\\mu_{1|2} = \\mu_1 + \\Sigma_{12} \\Sigma_{22}^{-1} (x_2 - \\mu_2)$\n- Conditional variance: $\\sigma_{1|2}^2 = \\Sigma_{11} - \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21}$\n\nSimilarly, the conditional distribution of $x_2$ given $x_1$ is $p(x_2 \\mid x_1) = \\mathcal{N}(\\mu_{2|1}, \\sigma_{2|1}^2)$, where:\n- Conditional mean: $\\mu_{2|1} = \\mu_2 + \\Sigma_{21} \\Sigma_{11}^{-1} (x_1 - \\mu_1)$\n- Conditional variance: $\\sigma_{2|1}^2 = \\Sigma_{22} - \\Sigma_{21} \\Sigma_{11}^{-1} \\Sigma_{12}$\n\nFrom the problem statement, we have:\n$$\n\\boldsymbol{\\mu} = \\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\n$$\n$$\n\\boldsymbol{\\Sigma} = \\begin{pmatrix} \\Sigma_{11}  \\Sigma_{12} \\\\ \\Sigma_{21}  \\Sigma_{22} \\end{pmatrix} = \\begin{pmatrix} 4  3 \\\\ 3  9 \\end{pmatrix}\n$$\nSo, $\\mu_1 = 1$, $\\mu_2 = -1$, $\\Sigma_{11} = 4$, $\\Sigma_{22} = 9$, and $\\Sigma_{12} = \\Sigma_{21} = 3$.\n\n**Derivation of $p(x_1 \\mid x_2)$:**\nThe mean of the conditional distribution $p(x_1 \\mid x_2)$ is:\n$$\n\\mu_{1|2} = \\mu_1 + \\Sigma_{12} \\Sigma_{22}^{-1} (x_2 - \\mu_2) = 1 + (3) \\left(\\frac{1}{9}\\right) (x_2 - (-1)) = 1 + \\frac{1}{3}(x_2 + 1) = \\frac{4}{3} + \\frac{1}{3}x_2\n$$\nThe variance is:\n$$\n\\sigma_{1|2}^2 = \\Sigma_{11} - \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21} = 4 - (3) \\left(\\frac{1}{9}\\right) (3) = 4 - \\frac{9}{9} = 4 - 1 = 3\n$$\nThus, the full conditional distribution for $x_1$ is $p(x_1 \\mid x_2) = \\mathcal{N}\\left(\\frac{4}{3} + \\frac{1}{3}x_2, 3\\right)$.\n\n**Derivation of $p(x_2 \\mid x_1)$:**\nThe mean of the conditional distribution $p(x_2 \\mid x_1)$ is:\n$$\n\\mu_{2|1} = \\mu_2 + \\Sigma_{21} \\Sigma_{11}^{-1} (x_1 - \\mu_1) = -1 + (3) \\left(\\frac{1}{4}\\right) (x_1 - 1) = -1 + \\frac{3}{4}x_1 - \\frac{3}{4} = -\\frac{7}{4} + \\frac{3}{4}x_1\n$$\nThe variance is:\n$$\n\\sigma_{2|1}^2 = \\Sigma_{22} - \\Sigma_{21} \\Sigma_{11}^{-1} \\Sigma_{12} = 9 - (3) \\left(\\frac{1}{4}\\right) (3) = 9 - \\frac{9}{4} = \\frac{36 - 9}{4} = \\frac{27}{4}\n$$\nThus, the full conditional distribution for $x_2$ is $p(x_2 \\mid x_1) = \\mathcal{N}\\left(-\\frac{7}{4} + \\frac{3}{4}x_1, \\frac{27}{4}\\right)$.\n\n**Performing one Gibbs sweep:**\nWe start at state $(x_1^{(0)}, x_2^{(0)}) = (0, 0)$.\n\n**Step 1: Update $x_1$**\nWe sample $x_1^{(1)}$ from $p(x_1 \\mid x_2 = x_2^{(0)})$. The distribution for this sample is $\\mathcal{N}(\\mu_{1|2}^{(0)}, \\sigma_{1|2}^2)$, where:\n- Mean: $\\mu_{1|2}^{(0)} = \\frac{4}{3} + \\frac{1}{3}x_2^{(0)} = \\frac{4}{3} + \\frac{1}{3}(0) = \\frac{4}{3}$\n- Variance: $\\sigma_{1|2}^2 = 3$. The standard deviation is $\\sigma_{1|2} = \\sqrt{3}$.\nTo generate a sample from $\\mathcal{N}(\\mu, \\sigma^2)$, we use the transformation $x = \\mu + \\sigma z$, where $z \\sim \\mathcal{N}(0, 1)$. We are given $z_1 = 1$.\n$$\nx_1^{(1)} = \\mu_{1|2}^{(0)} + \\sigma_{1|2} \\cdot z_1 = \\frac{4}{3} + \\sqrt{3} \\cdot (1) = \\frac{4}{3} + \\sqrt{3}\n$$\n\n**Step 2: Update $x_2$**\nWe sample $x_2^{(1)}$ from $p(x_2 \\mid x_1 = x_1^{(1)})$, using the newly updated value of $x_1$. The distribution for this sample is $\\mathcal{N}(\\mu_{2|1}^{(1)}, \\sigma_{2|1}^2)$, where:\n- Mean: $\\mu_{2|1}^{(1)} = -\\frac{7}{4} + \\frac{3}{4}x_1^{(1)} = -\\frac{7}{4} + \\frac{3}{4}\\left(\\frac{4}{3} + \\sqrt{3}\\right) = -\\frac{7}{4} + 1 + \\frac{3\\sqrt{3}}{4} = -\\frac{3}{4} + \\frac{3\\sqrt{3}}{4}$\n- Variance: $\\sigma_{2|1}^2 = \\frac{27}{4}$. The standard deviation is $\\sigma_{2|1} = \\sqrt{\\frac{27}{4}} = \\frac{3\\sqrt{3}}{2}$.\nWe are given the standard normal variate $z_2 = 0$.\n$$\nx_2^{(1)} = \\mu_{2|1}^{(1)} + \\sigma_{2|1} \\cdot z_2 = \\left(-\\frac{3}{4} + \\frac{3\\sqrt{3}}{4}\\right) + \\frac{3\\sqrt{3}}{2} \\cdot (0) = -\\frac{3}{4} + \\frac{3\\sqrt{3}}{4}\n$$\nAfter one complete Gibbs sweep, the updated state is $(x_1^{(1)}, x_2^{(1)}) = \\left(\\frac{4}{3} + \\sqrt{3}, -\\frac{3}{4} + \\frac{3\\sqrt{3}}{4}\\right)$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{4}{3} + \\sqrt{3}  -\\frac{3}{4} + \\frac{3\\sqrt{3}}{4} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Moving from manual calculation to computational implementation is a critical step in mastering MCMC. This practice challenges you to build a Metropolis-Hastings sampler to empirically verify the ergodic theorem, which guarantees that sample averages converge to their true expectations. By applying your sampler to a variety of target distributions and comparing the results to known theoretical values, you will develop a practical intuition for MCMC convergence and the power of these methods in numerical integration and estimation .",
            "id": "3313367",
            "problem": "You are asked to design and implement a Markov Chain Monte Carlo (MCMC) simulation to empirically illustrate the convergence of the sample average to the true expectation with respect to a known target distribution. The setting is entirely probabilistic and mathematical. The fundamental base for this task consists of: the definition of a Markov chain with an invariant distribution, the concept of reversibility with respect to a target density, and the ergodic theorem for Markov chains which guarantees convergence of empirical averages under standard irreducibility and aperiodicity conditions. You must not rely on any black-box sampler; instead, construct a reversible Markov chain using the Metropolis–Hastings mechanism with symmetric proposals.\n\nGiven a target distribution with density proportional to a known function $\\pi(x)$ and a measurable function $f(x)$ such that $\\mathbb{E}_{\\pi}[|f(X)|]  \\infty$, define the empirical average\n$$\n\\bar{f}_n \\equiv \\frac{1}{n} \\sum_{t=1}^{n} f(X_t),\n$$\nwhere $X_t$ is the state of the chain at iteration $t$ after discarding an initial burn-in segment. The goal is to compute $\\bar{f}_n$ for several test cases and compare it to the true expectation $\\mathbb{E}_{\\pi}[f]$ using the absolute error $|\\bar{f}_n - \\mathbb{E}_{\\pi}[f]|$, thereby illustrating convergence as $n$ grows.\n\nConstruct a time-homogeneous Markov chain on the state space appropriate to each test case, with the following requirements.\n- Use a random-walk Metropolis–Hastings kernel with symmetric Gaussian proposals. Concretely, at each step propose $Y = X + \\epsilon$ where $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_d)$ in dimension $d$, and apply the acceptance rule that ensures reversibility with respect to the target density $\\pi$.\n- The chain must be initialized at a specified deterministic state $x_0$ and must discard an initial burn-in of $b$ iterations before collecting $n$ samples for the average $\\bar{f}_n$. Use $b = \\lfloor n / 10 \\rfloor$ for each requested $n$.\n- For reproducibility, use a fixed pseudorandom seed for each test case and each $n$ as specified below.\n\nTest suite. Implement the following five target-function pairs and compute the absolute error $|\\bar{f}_n - \\mathbb{E}_{\\pi}[f]|$ for the three sample sizes $n \\in \\{\\,500, 5000, 50000\\,\\}$. In every case use the step size $\\sigma$ and initial state $x_0$ exactly as specified. For multivariate targets, use the identity covariance for the proposal scaled by $\\sigma$, and denote $x = (x_1, \\ldots, x_d)$.\n\n- Case $C_1$ (univariate standard normal moment):\n  - Target: $\\pi(x) \\propto \\exp(-\\tfrac{1}{2} x^2)$ on $\\mathbb{R}$, dimension $d = 1$.\n  - Function: $f(x) = x^2$.\n  - True expectation: $\\mathbb{E}_{\\pi}[f] = 1$.\n  - Parameters: $\\sigma = 1.0$, $x_0 = 0$.\n  - Seeds for $n \\in \\{\\,500, 5000, 50000\\,\\}$: $101$, $102$, $103$.\n\n- Case $C_2$ (univariate standard normal indicator):\n  - Target: $\\pi(x) \\propto \\exp(-\\tfrac{1}{2} x^2)$ on $\\mathbb{R}$, dimension $d = 1$.\n  - Function: $f(x) = \\mathbf{1}\\{|x| \\le 1\\}$.\n  - True expectation: $\\mathbb{E}_{\\pi}[f] = 2 \\Phi(1) - 1$, where $\\Phi$ is the standard normal cumulative distribution function.\n  - Parameters: $\\sigma = 1.0$, $x_0 = 0$.\n  - Seeds for $n \\in \\{\\,500, 5000, 50000\\,\\}$: $202$, $203$, $204$.\n\n- Case $C_3$ (bivariate standard normal cross-moment):\n  - Target: $\\pi(x) \\propto \\exp(-\\tfrac{1}{2} \\|x\\|^2)$ on $\\mathbb{R}^2$, dimension $d = 2$.\n  - Function: $f(x) = x_1 x_2$.\n  - True expectation: $\\mathbb{E}_{\\pi}[f] = 0$.\n  - Parameters: $\\sigma = 0.9$, $x_0 = (0, 0)$.\n  - Seeds for $n \\in \\{\\,500, 5000, 50000\\,\\}$: $303$, $304$, $305$.\n\n- Case $C_4$ (Beta target via transformation):\n  - Target: $\\pi(x) \\propto x^{a-1} (1-x)^{b-1}$ on $(0,1)$ with $a = 2.5$, $b = 5.5$. Implement the chain on $\\mathbb{R}$ using the logistic transform $x = \\mathrm{logit}^{-1}(u) = 1/(1+e^{-u})$ and a Gaussian random walk in $u$, accounting for the Jacobian to target the correct stationary distribution in $u$.\n  - Function: $f(x) = x$.\n  - True expectation: $\\mathbb{E}_{\\pi}[f] = \\dfrac{a}{a+b} = \\dfrac{2.5}{8.0}$.\n  - Parameters: $\\sigma = 1.25$, $u_0 = 0$ (which corresponds to $x_0 = 0.5$).\n  - Seeds for $n \\in \\{\\,500, 5000, 50000\\,\\}$: $404$, $405$, $406$.\n\n- Case $C_5$ (heavy-tailed Student distribution):\n  - Target: $\\pi(x) \\propto \\left(1 + \\dfrac{x^2}{\\nu}\\right)^{-(\\nu+1)/2}$ on $\\mathbb{R}$ with $\\nu = 3$, dimension $d = 1$.\n  - Function: $f(x) = x^2$.\n  - True expectation: $\\mathbb{E}_{\\pi}[f] = \\dfrac{\\nu}{\\nu - 2} = 3$.\n  - Parameters: $\\sigma = 2.5$, $x_0 = 0$.\n  - Seeds for $n \\in \\{\\,500, 5000, 50000\\,\\}$: $505$, $506$, $507$.\n\nFor each case $C_j$ and each $n \\in \\{\\,500, 5000, 50000\\,\\}$:\n- Run the Metropolis–Hastings chain with burn-in $b = \\lfloor n/10 \\rfloor$ and collect $n$ post-burn-in samples to compute $\\bar{f}_n$.\n- Compute the absolute error $|\\bar{f}_n - \\mathbb{E}_{\\pi}[f]|$.\n- Round the absolute error to six decimal places.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the following fixed order:\n- Iterate $j$ in increasing order over the cases $C_1, C_2, C_3, C_4, C_5$,\n- For each case, iterate $n$ in increasing order over $\\{\\,500, 5000, 50000\\,\\}$,\n- Append the corresponding rounded absolute error to the list.\nFor example, the output must look like a single line of the form \"[e_{1,500},e_{1,5000},e_{1,50000},e_{2,500},\\ldots,e_{5,50000}]\", where $e_{j,n}$ denotes the required error for case $C_j$ at sample size $n$. There are no physical quantities or angles in this task, hence no units are required. All numerical answers must be pure real numbers as floats. The list should contain exactly $15$ floats. No other text should be printed.",
            "solution": "The problem requires the implementation of a Metropolis-Hastings Markov Chain Monte Carlo (MCMC) simulation to empirically verify the convergence of sample averages to known theoretical expectations for several target probability distributions. The solution involves constructing a suitable Markov chain for each case, running the simulation, and calculating the absolute error between the empirical estimate and the true value.\n\n### Principles of Metropolis-Hastings MCMC\n\nThe core of this problem is the Metropolis-Hastings (M-H) algorithm, a method for generating a sequence of random samples from a probability distribution for which direct sampling is difficult. The sequence of samples constitutes a Markov chain, $\\{X_t\\}_{t=0}^\\infty$. The M-H algorithm is designed such that the stationary (or invariant) distribution of this Markov chain is the desired target distribution, $\\pi(x)$.\n\nThe algorithm proceeds as follows, starting from an initial state $X_0=x_0$:\n1.  At iteration $t$, given the current state $X_t$, propose a new state $Y$ from a proposal distribution $q(Y|X_t)$.\n2.  Calculate the acceptance probability, $\\alpha(X_t, Y)$, given by:\n    $$\n    \\alpha(X_t, Y) = \\min\\left(1, \\frac{\\pi(Y)q(X_t|Y)}{\\pi(X_t)q(Y|X_t)}\\right)\n    $$\n    The term $\\frac{\\pi(Y)}{\\pi(X_t)}$ is the likelihood ratio, and $\\frac{q(X_t|Y)}{q(Y|X_t)}$ is the Hastings ratio. Since the target density $\\pi(x)$ often includes an unknown normalizing constant, we can use any function $\\tilde{\\pi}(x) \\propto \\pi(x)$ in the ratio, as the constants cancel.\n3.  Generate a random number $u$ from a uniform distribution on $[0,1]$.\n4.  The next state $X_{t+1}$ is set to the proposal $Y$ if $u  \\alpha(X_t, Y)$; otherwise, the chain remains at the current state, $X_{t+1} = X_t$.\n\nThis procedure guarantees that the resulting Markov chain satisfies the detailed balance condition with respect to $\\pi$, which is a sufficient condition for $\\pi$ to be the stationary distribution.\n\nThe problem specifies a random-walk Metropolis sampler with a symmetric Gaussian proposal distribution: $Y = X_t + \\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_d)$. For a symmetric proposal, $q(Y|X_t) = q(X_t|Y)$, so the Hastings ratio is $1$, and the acceptance probability simplifies to:\n$$\n\\alpha(X_t, Y) = \\min\\left(1, \\frac{\\pi(Y)}{\\pi(X_t)}\\right)\n$$\nTo improve numerical stability, computations are performed using log-probabilities. The acceptance step involves comparing $\\log(u)$ with the log-acceptance ratio $\\log(\\alpha) = \\min\\left(0, \\log\\tilde{\\pi}(Y) - \\log\\tilde{\\pi}(X_t)\\right)$.\n\n### Ergodic Theorem and Estimation\n\nUnder conditions of irreducibility and aperiodicity, which are met by our construction, the ergodic theorem for Markov chains ensures that the sample average of a function $f(x)$ converges to its true expectation under the stationary distribution:\n$$\n\\bar{f}_n = \\frac{1}{n} \\sum_{t=1}^{n} f(X_t) \\xrightarrow{a.s.} \\mathbb{E}_{\\pi}[f(X)] \\quad \\text{as } n \\to \\infty\n$$\nThe initial samples of the chain are typically discarded (a \"burn-in\" period) to reduce the influence of the arbitrary starting state $x_0$. The problem specifies a burn-in of $b = \\lfloor n/10 \\rfloor$ iterations. The empirical average is then computed using the subsequent $n$ samples.\n\n### Implementation for Test Cases\n\nA general MCMC function is implemented to handle the simulation for all specified cases. This function takes as input the log-target density, a function to evaluate on the samples, the initial state, proposal standard deviation, and simulation parameters.\n\n**Case $C_1$: Univariate Normal, $f(x) = x^2$**\n- Target: $\\pi(x) \\propto \\exp(-\\frac{1}{2}x^2)$ on $\\mathbb{R}$.\n- Log-target: $\\log\\tilde{\\pi}(x) = -\\frac{1}{2}x^2$.\n- Function: $f(x) = x^2$.\n- True Expectation: $\\mathbb{E}_{\\pi}[f(X)] = 1$.\n\n**Case $C_2$: Univariate Normal, $f(x) = \\mathbf{1}\\{|x| \\le 1\\}$**\n- Target: Same as $C_1$, $\\log\\tilde{\\pi}(x) = -\\frac{1}{2}x^2$.\n- Function: $f(x) = \\mathbf{1}\\{|x| \\le 1\\}$, which is $1$ if $|x| \\le 1$ and $0$ otherwise.\n- True Expectation: $\\mathbb{E}_{\\pi}[f(X)] = P(|X| \\le 1) = \\Phi(1) - \\Phi(-1) = 2\\Phi(1) - 1$, where $\\Phi$ is the standard normal CDF.\n\n**Case $C_3$: Bivariate Normal, $f(x) = x_1 x_2$**\n- Target: $\\pi(x) \\propto \\exp(-\\frac{1}{2}\\|x\\|^2)$ on $\\mathbb{R}^2$, where $x=(x_1, x_2)$.\n- Log-target: $\\log\\tilde{\\pi}(x) = -\\frac{1}{2}(x_1^2 + x_2^2)$.\n- Function: $f(x) = x_1 x_2$.\n- True Expectation: $\\mathbb{E}_{\\pi}[f(X)] = 0$.\n\n**Case $C_4$: Beta Distribution via Transformation**\n- The target for $x \\in (0,1)$ is the Beta distribution density, $\\pi_X(x) \\propto x^{a-1}(1-x)^{b-1}$ with $a=2.5, b=5.5$.\n- A direct random walk on $(0,1)$ is problematic. Instead, we reparameterize using the logistic function, $x = g(u) = 1/(1+e^{-u})$, which maps $u \\in \\mathbb{R}$ to $x \\in (0,1)$.\n- The MCMC is run on the transformed variable $u$. The target density for $u$, $\\pi_U(u)$, is found using the change of variables formula: $\\pi_U(u) = \\pi_X(g(u))|g'(u)|$.\n- The Jacobian determinant is $|g'(u)| = \\frac{e^{-u}}{(1+e^{-u})^2} = g(u)(1-g(u))$.\n- Thus, $\\pi_U(u) \\propto [g(u)]^{a-1}[1-g(u)]^{b-1} \\cdot g(u)(1-g(u)) = [g(u)]^a[1-g(u)]^b$.\n- Log-target for $u$: $\\log\\tilde{\\pi}_U(u) = a \\log(g(u)) + b \\log(1-g(u))$.\n- Function: The expectation is of $f(x)=x$. The simulation generates samples $u_t$, which are transformed back to $x_t=g(u_t)$ for averaging.\n- True Expectation: $\\mathbb{E}_{\\pi_X}[X] = \\frac{a}{a+b} = \\frac{2.5}{8.0}$.\n\n**Case $C_5$: Student's t-Distribution, $f(x) = x^2$**\n- Target: The density of a Student's t-distribution with $\\nu=3$ degrees of freedom, $\\pi(x) \\propto (1 + \\frac{x^2}{\\nu})^{-(\\nu+1)/2}$.\n- Log-target: $\\log\\tilde{\\pi}(x) = -\\frac{\\nu+1}{2}\\log(1 + \\frac{x^2}{\\nu})$.\n- Function: $f(x) = x^2$.\n- True Expectation: The variance of a standard t-distribution with $\\nu$ degrees of freedom is $\\frac{\\nu}{\\nu-2}$ for $\\nu2$. Since the mean is $0$, $\\mathbb{E}_{\\pi}[X^2] = \\text{Var}(X) = \\frac{3}{3-2} = 3$.\n\nFor each of the $5$ cases and $3$ sample sizes, the simulation is run with the specified parameters ($\\sigma$, $x_0$, seed), and the absolute error $|\\bar{f}_n - \\mathbb{E}_{\\pi}[f]|$ is computed and recorded. The final output is a list of these $15$ errors.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def run_mcmc(log_target_pdf, func_to_eval, x0, sigma, n_samples, seed):\n        \"\"\"\n        Runs a random-walk Metropolis-Hastings simulation.\n\n        Args:\n            log_target_pdf: A function that computes the log of the target density (unnormalized).\n            func_to_eval: A function of the chain's state to be averaged.\n            x0: Initial state of the chain (tuple or list).\n            sigma: Standard deviation of the Gaussian proposal distribution.\n            n_samples: Number of samples to collect after burn-in.\n            seed: Seed for the random number generator.\n\n        Returns:\n            The empirical average of func_to_eval over the samples.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        burn_in = n_samples // 10\n        total_iter = n_samples + burn_in\n\n        x = np.array(x0, dtype=float)\n        dim = x.size\n        \n        # Initial log probability\n        current_log_p = log_target_pdf(x)\n\n        f_values = []\n        for i in range(total_iter):\n            # Propose a new state\n            proposal = x + rng.normal(loc=0.0, scale=sigma, size=dim)\n\n            # Calculate acceptance probability in log-space\n            proposal_log_p = log_target_pdf(proposal)\n            log_alpha = proposal_log_p - current_log_p\n\n            if np.log(rng.uniform())  log_alpha:\n                x = proposal\n                current_log_p = proposal_log_p\n            \n            # Collect sample after burn-in\n            if i = burn_in:\n                f_values.append(func_to_eval(x))\n\n        return np.mean(f_values)\n\n    # --- Test Case Definitions ---\n\n    # Case C1: Univariate standard normal moment\n    c1_log_pdf = lambda x: -0.5 * x[0]**2\n    c1_f = lambda x: x[0]**2\n    \n    # Case C2: Univariate standard normal indicator\n    c2_log_pdf = c1_log_pdf\n    c2_f = lambda x: 1.0 if np.abs(x[0]) = 1.0 else 0.0\n    c2_true_E = 2 * norm.cdf(1) - 1\n\n    # Case C3: Bivariate standard normal cross-moment\n    c3_log_pdf = lambda x: -0.5 * (x[0]**2 + x[1]**2)\n    c3_f = lambda x: x[0] * x[1]\n\n    # Case C4: Beta target via transformation\n    c4_a, c4_b = 2.5, 5.5\n    g = lambda u_vec: 1.0 / (1.0 + np.exp(-u_vec[0]))\n    c4_log_pdf_u = lambda u: c4_a * np.log(g(u)) + c4_b * np.log(1.0 - g(u))\n    c4_f_on_u = lambda u: g(u)\n    c4_true_E = c4_a / (c4_a + c4_b)\n\n    # Case C5: Heavy-tailed Student distribution\n    c5_nu = 3.0\n    c5_log_pdf = lambda x: -((c5_nu + 1.0) / 2.0) * np.log(1.0 + x[0]**2 / c5_nu)\n    c5_f = lambda x: x[0]**2\n    c5_true_E = c5_nu / (c5_nu - 2.0)\n\n\n    test_cases = [\n        {\n            \"name\": \"C1\", \"log_pdf\": c1_log_pdf, \"func_f\": c1_f, \"true_E\": 1.0,\n            \"sigma\": 1.0, \"x0\": (0.0,), \"seeds\": {500: 101, 5000: 102, 50000: 103}\n        },\n        {\n            \"name\": \"C2\", \"log_pdf\": c2_log_pdf, \"func_f\": c2_f, \"true_E\": c2_true_E,\n            \"sigma\": 1.0, \"x0\": (0.0,), \"seeds\": {500: 202, 5000: 203, 50000: 204}\n        },\n        {\n            \"name\": \"C3\", \"log_pdf\": c3_log_pdf, \"func_f\": c3_f, \"true_E\": 0.0,\n            \"sigma\": 0.9, \"x0\": (0.0, 0.0), \"seeds\": {500: 303, 5000: 304, 50000: 305}\n        },\n        {\n            \"name\": \"C4\", \"log_pdf\": c4_log_pdf_u, \"func_f\": c4_f_on_u, \"true_E\": c4_true_E,\n            \"sigma\": 1.25, \"x0\": (0.0,), \"seeds\": {500: 404, 5000: 405, 50000: 406}\n        },\n        {\n            \"name\": \"C5\", \"log_pdf\": c5_log_pdf, \"func_f\": c5_f, \"true_E\": c5_true_E,\n            \"sigma\": 2.5, \"x0\": (0.0,), \"seeds\": {500: 505, 5000: 506, 50000: 507}\n        }\n    ]\n\n    sample_sizes = [500, 5000, 50000]\n    results = []\n\n    for case in test_cases:\n        for n in sample_sizes:\n            seed = case[\"seeds\"][n]\n            \n            # Run the MCMC simulation\n            empirical_mean = run_mcmc(\n                log_target_pdf=case[\"log_pdf\"],\n                func_to_eval=case[\"func_f\"],\n                x0=case[\"x0\"],\n                sigma=case[\"sigma\"],\n                n_samples=n,\n                seed=seed\n            )\n            \n            # Compute and store the absolute error\n            error = np.abs(empirical_mean - case[\"true_E\"])\n            rounded_error = round(error, 6)\n            results.append(rounded_error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A proficient MCMC practitioner not only knows how to build a sampler but also how to diagnose why it might fail. This exercise explores a classic pathological case in MCMC: using a light-tailed proposal distribution to sample from a heavy-tailed target. By analyzing the acceptance dynamics and long-term behavior of such a chain, you will develop critical insight into the crucial importance of proposal design and tail coverage for ensuring robust and reliable MCMC performance .",
            "id": "3313362",
            "problem": "Consider a one-dimensional independence Metropolis–Hastings (MH) algorithm targeting a heavy-tailed distribution with density proportional to a Student–t with degrees of freedom $\\nu \\in (1, \\infty)$,\n$$\n\\pi(x) \\propto \\left(1 + \\frac{x^2}{\\nu}\\right)^{-(\\nu+1)/2}, \\quad x \\in \\mathbb{R},\n$$\nand using a light-tailed independence proposal $q(x)$ given by the Gaussian density of $\\mathcal{N}(0,\\sigma^2)$ for some fixed $\\sigma^2 \\in (0,\\infty)$. The independence MH transition proposes $Y \\sim q(\\cdot)$ irrespective of the current state $X=x$, and accepts the move to $Y$ with the standard Metropolis–Hastings acceptance rule. Work from first principles of the Metropolis–Hastings algorithm, the asymptotic tail behavior of densities, and the definitions of reversibility and ergodicity in Markov chain theory.\n\nSelect all statements that are correct.\n\nA. As $\\lvert x \\rvert \\to \\infty$, the average one-step acceptance probability starting from $x$ under the independence Metropolis–Hastings algorithm tends to $0$; this is a manifestation of tail undercoverage because $q(x)/\\pi(x) \\to 0$.\n\nB. The chain fails to satisfy detailed balance with respect to $\\pi$ when $q$ has lighter tails than $\\pi$, so $\\pi$ cannot be invariant for the chain.\n\nC. Even if $q$ is strictly positive on $\\mathbb{R}$, the independence sampler with a light-tailed $q$ and heavy-tailed $\\pi$ is transient and cannot be Harris recurrent.\n\nD. Replacing the Gaussian $q$ with a Student–t proposal with sufficiently small degrees of freedom increases tail coverage and can substantially raise acceptance out of the tails; moreover, if $\\sup_{x \\in \\mathbb{R}} \\pi(x)/q(x)  \\infty$, then the independence sampler is uniformly ergodic.\n\nE. For any fixed $y$ in a typical high-probability region (for instance, $y$ near $0$), the independence Metropolis–Hastings acceptance probability from a large $\\lvert x \\rvert$ satisfies\n$$\n\\alpha(x,y) \\;=\\; \\min\\left\\{1,\\; \\frac{\\pi(y)\\, q(x)}{\\pi(x)\\, q(y)}\\right\\} \\;\\to\\; 0 \\quad \\text{as } \\lvert x \\rvert \\to \\infty,\n$$\nso proposed moves from extreme tails back to the center are almost always rejected under a light-tailed $q$.\n\nChoose all that apply: A, B, C, D, E.",
            "solution": "The problem explores the pathological behavior of an independence Metropolis-Hastings sampler when the proposal distribution $q(x)$ has lighter tails than the target distribution $\\pi(x)$. Here, the target $\\pi(x)$ is a heavy-tailed Student-t distribution, and the proposal $q(x)$ is a light-tailed Gaussian distribution. The key to analyzing this setup is the tail behavior of the ratio of the densities.\n\nThe target density behaves as $\\pi(x) = O(|x|^{-(\\nu+1)})$ for large $|x|$.\nThe proposal density behaves as $q(x) = O(e^{-x^2/(2\\sigma^2)})$.\nThe ratio $q(x)/\\pi(x)$ involves an exponential term divided by a polynomial term, so $\\lim_{|x| \\to \\infty} \\frac{q(x)}{\\pi(x)} = 0$. Conversely, $\\lim_{|x| \\to \\infty} \\frac{\\pi(x)}{q(x)} = \\infty$. This indicates that the proposal distribution severely under-samples the tails of the target distribution.\n\nThe acceptance probability for a move from state $x$ to $y$ in an independence sampler is $\\alpha(x,y) = \\min\\left\\{1, \\frac{\\pi(y)q(x)}{\\pi(x)q(y)}\\right\\}$.\n\nLet's analyze each statement:\n\n**A. Correct.** The average acceptance probability from a state $x$ is $\\bar{\\alpha}(x) = \\int \\alpha(x,y) q(y) dy = \\int \\min\\left\\{1, \\frac{\\pi(y)q(x)}{\\pi(x)q(y)}\\right\\} q(y) dy$. As $|x| \\to \\infty$, the ratio $\\frac{q(x)}{\\pi(x)} \\to 0$. Thus, the term inside the minimum, $\\frac{\\pi(y)q(x)}{\\pi(x)q(y)}$, goes to $0$ for any fixed $y$. By the Dominated Convergence Theorem, the integral $\\bar{\\alpha}(x)$ goes to $0$. This means if the chain wanders into the tails, it will have a very low probability of accepting any move, causing it to get \"stuck\". The reasoning given is correct.\n\n**B. Incorrect.** The Metropolis-Hastings algorithm is constructed specifically to ensure that the resulting Markov chain satisfies the detailed balance condition (reversibility) with respect to $\\pi$. This holds by construction regardless of the properties of $\\pi$ and $q$. Therefore, $\\pi$ is an invariant distribution for the chain. The problem is not a lack of invariance, but a lack of ergodicity (the chain will not converge to $\\pi$).\n\n**C. Incorrect.** A classic result states that an independence sampler is not ergodic if $\\sup_x \\pi(x)/q(x) = \\infty$, which is the case here. This means the chain is not Harris recurrent (specifically, not positive recurrent). However, the chain is not transient. A transient chain has a non-zero probability of never returning to a given set. Here, the proposal distribution $q(x)$ is a Gaussian centered at $0$, so it constantly proposes moves back to the center of the distribution. While the acceptance probability for these moves from the tail is very low (see E), it is not zero. The chain will eventually return to the center, so it is recurrent. The specific type of recurrence is null recurrence (the expected time to return is infinite). Since the statement claims the chain is transient, it is false.\n\n**D. Correct.** This statement consists of two correct parts. First, replacing the light-tailed Gaussian proposal with a heavy-tailed proposal (like a Student-t with degrees of freedom $\\nu' \\le \\nu$) ensures that the proposal tails are at least as heavy as the target tails. This prevents the ratio $\\pi(x)/q(x)$ from diverging and dramatically improves sampler performance by increasing acceptance rates from the tails. Second, the condition $\\sup_{x \\in \\mathbb{R}} \\pi(x)/q(x)  \\infty$ is the well-known necessary and sufficient condition for an independence sampler to be uniformly ergodic, which is a very strong and desirable mode of convergence.\n\n**E. Correct.** For a fixed $y$ in a high-probability region (e.g., $y$ near $0$), both $\\pi(y)$ and $q(y)$ are positive constants. The acceptance probability $\\alpha(x,y) = \\min\\left\\{1, \\frac{\\pi(y)q(x)}{\\pi(x)q(y)}\\right\\}$ is dominated by the ratio $q(x)/\\pi(x)$ as $|x| \\to \\infty$. Since this ratio tends to $0$, the acceptance probability $\\alpha(x,y)$ also tends to $0$. This accurately describes the mechanism: the chain, once in the tails, will almost always reject proposals to move back to the center, causing it to get stuck for very long periods.\n\nTherefore, statements A, D, and E are correct.",
            "answer": "$$\\boxed{ADE}$$"
        }
    ]
}