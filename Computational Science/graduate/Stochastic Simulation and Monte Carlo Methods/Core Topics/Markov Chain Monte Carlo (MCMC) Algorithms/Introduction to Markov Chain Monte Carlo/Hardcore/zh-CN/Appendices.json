{
    "hands_on_practices": [
        {
            "introduction": "本练习提供了一个具体、分步的吉布斯采样算法演练。通过为二元正态目标手动推导全条件分布并执行单次采样扫描，您将对这种强大的 MCMC 方法如何从复杂的联合分布中迭代构建样本获得基础性的理解。这个过程将揭示该算法在多维问题中的内在机制 。",
            "id": "3313366",
            "problem": "考虑一个目标分布，它是一个二元正态分布，其均值向量为 $\\boldsymbol{\\mu} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$，协方差矩阵为 $\\boldsymbol{\\Sigma} = \\begin{pmatrix} 4  3 \\\\ 3  9 \\end{pmatrix}$。Gibbs 采样器是一种马尔可夫链蒙特卡洛 (MCMC) 算法，它从完全条件分布中迭代采样。从多元正态分布的第一性原理出发，根据 $\\boldsymbol{\\mu}$ 和 $\\boldsymbol{\\Sigma}$ 的元素，推导出完全条件分布 $p(x_{1} \\mid x_{2})$ 和 $p(x_{2} \\mid x_{1})$ 的显式表达式。然后，从当前状态 $(x_{1}^{(0)}, x_{2}^{(0)}) = (0, 0)$ 开始，按照 $x_{1}$-然后-$x_{2}$ 的顺序执行一次完整的 Gibbs 扫描，使用独立的标准正态变量 $z_{1} = 1$ 和 $z_{2} = 0$ 来实现更新。将更新后的点对 $(x_{1}^{(1)}, x_{2}^{(1)})$ 表示为精确表达式。以单个行向量的形式提供你的最终答案。不要四舍五入。",
            "solution": "用户需要解决一个问题，该问题要求推导二元正态分布的完全条件分布，然后执行一步 Gibbs 采样。\n\n### 步骤 1：问题验证\n\n**1.1. 提取已知条件：**\n- 目标分布：二元正态分布。\n- 均值向量：$\\boldsymbol{\\mu} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$。\n- 协方差矩阵：$\\boldsymbol{\\Sigma} = \\begin{pmatrix} 4  3 \\\\ 3  9 \\end{pmatrix}$。\n- 算法：Gibbs 采样器。\n- 任务 1：推导完全条件分布 $p(x_{1} \\mid x_{2})$ 和 $p(x_{2} \\mid x_{1})$ 的显式表达式。\n- 任务 2：执行一次完整的 Gibbs 扫描。\n- 扫描顺序：$x_{1}$-然后-$x_{2}$。\n- 起始状态：$(x_{1}^{(0)}, x_{2}^{(0)}) = (0, 0)$。\n- 用于实现的标准正态变量：$z_{1} = 1$ 和 $z_{2} = 0$。\n- 最终答案格式：更新后的点对 $(x_{1}^{(1)}, x_{2}^{(1)})$，以单个行向量和精确表达式的形式给出。\n\n**1.2. 使用提取的已知条件进行验证：**\n- **科学依据：** 该问题基于多元统计和马尔可夫链蒙特卡洛 (MCMC) 方法的理论。Gibbs 采样器是从多元分布中采样的标准算法，其在多元正态分布上的应用是一个典型例子。所提供的协方差矩阵 $\\boldsymbol{\\Sigma}$ 是对称的。其行列式为 $\\det(\\boldsymbol{\\Sigma}) = (4)(9) - (3)(3) = 36 - 9 = 27 > 0$，且其对角线元素（方差）为正。因此，$\\boldsymbol{\\Sigma}$ 是一个有效的正定协方差矩阵。该问题在科学上和数学上都是合理的。\n- **适定性：** 该问题是适定的。它提供了计算唯一解所需的所有必要信息——目标分布参数、初始状态以及用于更新步骤的随机变量。\n- **客观性：** 该问题使用精确、客观的数学语言陈述。\n- **完整性与一致性：** 该问题是自洽的，没有矛盾之处。\n\n**1.3. 结论：**\n该问题是有效的。\n\n### 步骤 2：求解\n\n该问题要求我们首先推导二元正态分布的完全条件分布，然后用它们来执行一次 Gibbs 采样器的扫描。\n\n设随机向量 $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$ 服从均值向量为 $\\boldsymbol{\\mu}$、协方差矩阵为 $\\boldsymbol{\\Sigma}$ 的二元正态分布：\n$$\n\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\n$$\n其中\n$$\n\\boldsymbol{\\mu} = \\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\end{pmatrix} \\quad \\text{和} \\quad \\boldsymbol{\\Sigma} = \\begin{pmatrix} \\sigma_1^2  \\rho \\sigma_1 \\sigma_2 \\\\ \\rho \\sigma_1 \\sigma_2  \\sigma_2^2 \\end{pmatrix} = \\begin{pmatrix} \\Sigma_{11}  \\Sigma_{12} \\\\ \\Sigma_{21}  \\Sigma_{22} \\end{pmatrix}\n$$\n\n多元正态分布的完全条件分布本身也是正态分布。对于二元情况，$x_1$ 给定 $x_2$ 的条件分布为 $p(x_1 \\mid x_2) = \\mathcal{N}(\\mu_{1|2}, \\sigma_{1|2}^2)$，其中：\n- 条件均值：$\\mu_{1|2} = \\mu_1 + \\Sigma_{12} \\Sigma_{22}^{-1} (x_2 - \\mu_2)$\n- 条件方差：$\\sigma_{1|2}^2 = \\Sigma_{11} - \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21}$\n\n类似地，$x_2$ 给定 $x_1$ 的条件分布为 $p(x_2 \\mid x_1) = \\mathcal{N}(\\mu_{2|1}, \\sigma_{2|1}^2)$，其中：\n- 条件均值：$\\mu_{2|1} = \\mu_2 + \\Sigma_{21} \\Sigma_{11}^{-1} (x_1 - \\mu_1)$\n- 条件方差：$\\sigma_{2|1}^2 = \\Sigma_{22} - \\Sigma_{21} \\Sigma_{11}^{-1} \\Sigma_{12}$\n\n根据问题陈述，我们有：\n$$\n\\boldsymbol{\\mu} = \\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\n$$\n$$\n\\boldsymbol{\\Sigma} = \\begin{pmatrix} \\Sigma_{11}  \\Sigma_{12} \\\\ \\Sigma_{21}  \\Sigma_{22} \\end{pmatrix} = \\begin{pmatrix} 4  3 \\\\ 3  9 \\end{pmatrix}\n$$\n因此，$\\mu_1 = 1$, $\\mu_2 = -1$, $\\Sigma_{11} = 4$, $\\Sigma_{22} = 9$，并且 $\\Sigma_{12} = \\Sigma_{21} = 3$。由于 $\\Sigma_{11}$ 和 $\\Sigma_{22}$ 是标量，它们的逆就是它们的倒数：$\\Sigma_{11}^{-1} = \\frac{1}{4}$ 和 $\\Sigma_{22}^{-1} = \\frac{1}{9}$。\n\n**$p(x_1 \\mid x_2)$ 的推导：**\n条件分布 $p(x_1 \\mid x_2)$ 的均值为：\n$$\n\\mu_{1|2} = \\mu_1 + \\Sigma_{12} \\Sigma_{22}^{-1} (x_2 - \\mu_2) = 1 + (3) \\left(\\frac{1}{9}\\right) (x_2 - (-1)) = 1 + \\frac{1}{3}(x_2 + 1) = 1 + \\frac{1}{3}x_2 + \\frac{1}{3} = \\frac{4}{3} + \\frac{1}{3}x_2\n$$\n方差为：\n$$\n\\sigma_{1|2}^2 = \\Sigma_{11} - \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21} = 4 - (3) \\left(\\frac{1}{9}\\right) (3) = 4 - \\frac{9}{9} = 4 - 1 = 3\n$$\n因此，$x_1$ 的完全条件分布为：\n$$\np(x_1 \\mid x_2) = \\mathcal{N}\\left(\\frac{4}{3} + \\frac{1}{3}x_2, 3\\right)\n$$\n\n**$p(x_2 \\mid x_1)$ 的推导：**\n条件分布 $p(x_2 \\mid x_1)$ 的均值为：\n$$\n\\mu_{2|1} = \\mu_2 + \\Sigma_{21} \\Sigma_{11}^{-1} (x_1 - \\mu_1) = -1 + (3) \\left(\\frac{1}{4}\\right) (x_1 - 1) = -1 + \\frac{3}{4}x_1 - \\frac{3}{4} = -\\frac{7}{4} + \\frac{3}{4}x_1\n$$\n方差为：\n$$\n\\sigma_{2|1}^2 = \\Sigma_{22} - \\Sigma_{21} \\Sigma_{11}^{-1} \\Sigma_{12} = 9 - (3) \\left(\\frac{1}{4}\\right) (3) = 9 - \\frac{9}{4} = \\frac{36 - 9}{4} = \\frac{27}{4}\n$$\n因此，$x_2$ 的完全条件分布为：\n$$\np(x_2 \\mid x_1) = \\mathcal{N}\\left(-\\frac{7}{4} + \\frac{3}{4}x_1, \\frac{27}{4}\\right)\n$$\n\n**执行一次 Gibbs 扫描：**\nGibbs 采样器通过从完全条件分布中迭代抽取样本来进行。我们从状态 $(x_1^{(0)}, x_2^{(0)}) = (0, 0)$ 开始。\n\n**步骤 2.1：更新 $x_1$**\n我们从 $p(x_1 \\mid x_2 = x_2^{(0)})$ 中采样 $x_1^{(1)}$。\n该样本的分布是 $\\mathcal{N}(\\mu_{1|2}^{(0)}, \\sigma_{1|2}^2)$，其中：\n- 均值：$\\mu_{1|2}^{(0)} = \\frac{4}{3} + \\frac{1}{3}x_2^{(0)} = \\frac{4}{3} + \\frac{1}{3}(0) = \\frac{4}{3}$\n- 方差：$\\sigma_{1|2}^2 = 3$。标准差为 $\\sigma_{1|2} = \\sqrt{3}$。\n为了从 $\\mathcal{N}(\\mu, \\sigma^2)$ 生成一个样本，我们使用变换 $x = \\mu + \\sigma z$，其中 $z \\sim \\mathcal{N}(0, 1)$。我们被给予标准正态变量 $z_1 = 1$。\n$$\nx_1^{(1)} = \\mu_{1|2}^{(0)} + \\sigma_{1|2} \\cdot z_1 = \\frac{4}{3} + \\sqrt{3} \\cdot (1) = \\frac{4}{3} + \\sqrt{3}\n$$\n\n**步骤 2.2：更新 $x_2$**\n我们使用 $x_1$ 的新更新值，从 $p(x_2 \\mid x_1 = x_1^{(1)})$ 中采样 $x_2^{(1)}$。\n该样本的分布是 $\\mathcal{N}(\\mu_{2|1}^{(1)}, \\sigma_{2|1}^2)$，其中：\n- 均值：$\\mu_{2|1}^{(1)} = -\\frac{7}{4} + \\frac{3}{4}x_1^{(1)} = -\\frac{7}{4} + \\frac{3}{4}\\left(\\frac{4}{3} + \\sqrt{3}\\right) = -\\frac{7}{4} + 1 + \\frac{3\\sqrt{3}}{4} = -\\frac{3}{4} + \\frac{3\\sqrt{3}}{4}$\n- 方差：$\\sigma_{2|1}^2 = \\frac{27}{4}$。标准差为 $\\sigma_{2|1} = \\sqrt{\\frac{27}{4}} = \\frac{3\\sqrt{3}}{2}$。\n我们被给予标准正态变量 $z_2 = 0$。\n$$\nx_2^{(1)} = \\mu_{2|1}^{(1)} + \\sigma_{2|1} \\cdot z_2 = \\left(-\\frac{3}{4} + \\frac{3\\sqrt{3}}{4}\\right) + \\frac{3\\sqrt{3}}{2} \\cdot (0) = -\\frac{3}{4} + \\frac{3\\sqrt{3}}{4}\n$$\n\n经过一次完整的 Gibbs 扫描后，更新后的状态是 $(x_1^{(1)}, x_2^{(1)}) = \\left(\\frac{4}{3} + \\sqrt{3}, -\\frac{3}{4} + \\frac{3\\sqrt{3}}{4}\\right)$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{4}{3} + \\sqrt{3}  -\\frac{3}{4} + \\frac{3\\sqrt{3}}{4} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "为了真正掌握 MCMC 的威力，从手动计算转向代码实现至关重要。本实践将指导您编写一个 Metropolis-Hastings 采样器，以经验性地验证样本均值在多种不同目标分布下向真实期望值的收敛过程。这项练习将巩固 MCMC 理论与其在统计估计中的实际应用之间的联系 。",
            "id": "3313367",
            "problem": "要求您设计并实现一个马尔可夫链蒙特卡洛（MCMC）模拟，以经验性地说明样本均值如何收敛于某个已知目标分布的真实期望。此任务的背景完全是概率性和数学性的。此任务的基础包括：具有不变分布的马尔可夫链的定义、相对于目标密度的可逆性概念，以及保证在标准不可约性和非周期性条件下经验均值收敛的马尔可夫链遍历定理。您不得依赖任何黑盒采样器；相反，您必须使用带有对称提议的 Metropolis–Hastings 机制来构造一个可逆的马尔可夫链。\n\n给定一个目标分布，其密度与已知函数 $\\pi(x)$ 成正比，以及一个可测函数 $f(x)$ 满足 $\\mathbb{E}_{\\pi}[|f(X)|] < \\infty$，定义经验均值为\n$$\n\\bar{f}_n \\equiv \\frac{1}{n} \\sum_{t=1}^{n} f(X_t),\n$$\n其中 $X_t$ 是在舍弃初始“预烧”（burn-in）阶段后，在第 $t$ 次迭代时链的状态。目标是针对几个测试案例计算 $\\bar{f}_n$，并使用绝对误差 $|\\bar{f}_n - \\mathbb{E}_{\\pi}[f]|$ 将其与真实期望 $\\mathbb{E}_{\\pi}[f]$ 进行比较，从而说明随着 $n$ 的增长，收敛性得以体现。\n\n为每个测试案例在适当的状态空间上构造一个时间齐次马尔可夫链，并满足以下要求。\n- 使用带有对称高斯提议的随机游走 Metropolis–Hastings 核。具体来说，在每一步中，提议 $Y = X + \\epsilon$，其中在 $d$ 维空间中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_d)$，并应用确保相对于目标密度 $\\pi$ 可逆性的接受准则。\n- 链必须在指定的确定性状态 $x_0$ 处初始化，并且在为均值 $\\bar{f}_n$ 收集 $n$ 个样本之前，必须舍弃初始的 $b$ 次“预烧”迭代。对于每个要求的 $n$，使用 $b = \\lfloor n / 10 \\rfloor$。\n- 为保证可复现性，请为每个测试案例和每个 $n$ 使用下面指定的固定伪随机种子。\n\n测试套件。实现以下五个目标-函数对，并计算三个样本量 $n \\in \\{\\,500, 5000, 50000\\,\\}$ 的绝对误差 $|\\bar{f}_n - \\mathbb{E}_{\\pi}[f]|$。在所有情况下，均需严格按照规定使用步长 $\\sigma$ 和初始状态 $x_0$。对于多变量目标，提议分布使用由 $\\sigma$ 缩放的单位协方差矩阵，并记 $x = (x_1, \\ldots, x_d)$。\n\n- 案例 $C_1$（单变量标准正态矩）：\n  - 目标：$\\pi(x) \\propto \\exp(-\\tfrac{1}{2} x^2)$ on $\\mathbb{R}$，维度 $d = 1$。\n  - 函数：$f(x) = x^2$。\n  - 真实期望：$\\mathbb{E}_{\\pi}[f] = 1$。\n  - 参数：$\\sigma = 1.0$, $x_0 = 0$。\n  - $n \\in \\{\\,500, 5000, 50000\\,\\}$ 的种子：$101$, $102$, $103$。\n\n- 案例 $C_2$（单变量标准正态指示函数）：\n  - 目标：$\\pi(x) \\propto \\exp(-\\tfrac{1}{2} x^2)$ on $\\mathbb{R}$，维度 $d = 1$。\n  - 函数：$f(x) = \\mathbf{1}\\{|x| \\le 1\\}$。\n  - 真实期望：$\\mathbb{E}_{\\pi}[f] = 2 \\Phi(1) - 1$，其中 $\\Phi$ 是标准正态累积分布函数。\n  - 参数：$\\sigma = 1.0$, $x_0 = 0$。\n  - $n \\in \\{\\,500, 5000, 50000\\,\\}$ 的种子：$202$, $203$, $204$。\n\n- 案例 $C_3$（双变量标准正态交叉矩）：\n  - 目标：$\\pi(x) \\propto \\exp(-\\tfrac{1}{2} \\|x\\|^2)$ on $\\mathbb{R}^2$，维度 $d = 2$。\n  - 函数：$f(x) = x_1 x_2$。\n  - 真实期望：$\\mathbb{E}_{\\pi}[f] = 0$。\n  - 参数：$\\sigma = 0.9$, $x_0 = (0, 0)$。\n  - $n \\in \\{\\,500, 5000, 50000\\,\\}$ 的种子：$303$, $304$, $305$。\n\n- 案例 $C_4$（通过变换得到 Beta 目标）：\n  - 目标：$\\pi(x) \\propto x^{a-1} (1-x)^{b-1}$ on $(0,1)$，其中 $a = 2.5$, $b = 5.5$。使用 logistic 变换 $x = \\mathrm{logit}^{-1}(u) = 1/(1+e^{-u})$ 在 $\\mathbb{R}$ 上实现马尔可夫链，并在 $u$ 空间中进行高斯随机游走，同时考虑雅可比行列式以确保目标平稳分布在 $u$ 空间中是正确的。\n  - 函数：$f(x) = x$。\n  - 真实期望：$\\mathbb{E}_{\\pi}[f] = \\dfrac{a}{a+b} = \\dfrac{2.5}{8.0}$。\n  - 参数：$\\sigma = 1.25$, $u_0 = 0$（对应于 $x_0 = 0.5$）。\n  - $n \\in \\{\\,500, 5000, 50000\\,\\}$ 的种子：$404$, $405$, $406$。\n\n- 案例 $C_5$（重尾 Student 分布）：\n  - 目标：$\\pi(x) \\propto \\left(1 + \\dfrac{x^2}{\\nu}\\right)^{-(\\nu+1)/2}$ on $\\mathbb{R}$，其中 $\\nu = 3$，维度 $d = 1$。\n  - 函数：$f(x) = x^2$。\n  - 真实期望：$\\mathbb{E}_{\\pi}[f] = \\dfrac{\\nu}{\\nu - 2} = 3$。\n  - 参数：$\\sigma = 2.5$, $x_0 = 0$。\n  - $n \\in \\{\\,500, 5000, 50000\\,\\}$ 的种子：$505$, $506$, $507$。\n\n对于每个案例 $C_j$ 和每个 $n \\in \\{\\,500, 5000, 50000\\,\\}$：\n- 运行 Metropolis–Hastings 链，设置“预烧”期为 $b = \\lfloor n/10 \\rfloor$，并在预烧后收集 $n$ 个样本以计算 $\\bar{f}_n$。\n- 计算绝对误差 $|\\bar{f}_n - \\mathbb{E}_{\\pi}[f]|$。\n- 将绝对误差四舍五入到六位小数。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果按以下固定顺序排列：\n- 按递增顺序遍历案例 $C_1, C_2, C_3, C_4, C_5$ 中的 $j$，\n- 对于每个案例，按递增顺序遍历 $n \\in \\{\\,500, 5000, 50000\\,\\}$，\n- 将相应的四舍五入后的绝对误差追加到列表中。\n例如，输出必须是形如 \"[e_{1,500},e_{1,5000},e_{1,50000},e_{2,500},\\ldots,e_{5,50000}]\" 的单行文本，其中 $e_{j,n}$ 表示案例 $C_j$ 在样本量为 $n$ 时的所需误差。此任务中不涉及物理量或角度，因此不需要单位。所有数值答案必须是纯实数（浮点数）。列表应精确包含 $15$ 个浮点数。不应打印任何其他文本。",
            "solution": "该问题要求实现一个 Metropolis-Hastings 马尔可夫链蒙特卡洛（MCMC）模拟，以经验性地验证对于几个目标概率分布，样本均值是否收敛于已知的理论期望。解决方案包括为每个案例构建一个合适的马尔可夫链，运行模拟，并计算经验估计值与真实值之间的绝对误差。\n\n### Metropolis-Hastings MCMC 原理\n\n此问题的核心是 Metropolis-Hastings (M-H) 算法，该方法用于从一个难以直接采样的概率分布中生成一个随机样本序列。这个样本序列构成了一个马尔可夫链 $\\{X_t\\}_{t=0}^\\infty$。M-H 算法的设计使得该马尔可夫链的平稳（或不变）分布就是所需的目标分布 $\\pi(x)$。\n\n该算法从初始状态 $X_0=x_0$ 开始，按以下步骤进行：\n1.  在第 $t$ 次迭代时，给定当前状态 $X_t$，从一个提议分布 $q(Y|X_t)$ 中提议一个新状态 $Y$。\n2.  计算接受概率 $\\alpha(X_t, Y)$，其公式为：\n    $$\n    \\alpha(X_t, Y) = \\min\\left(1, \\frac{\\pi(Y)q(X_t|Y)}{\\pi(X_t)q(Y|X_t)}\\right)\n    $$\n    项 $\\frac{\\pi(Y)}{\\pi(X_t)}$ 是似然比，而 $\\frac{q(X_t|Y)}{q(Y|X_t)}$ 是 Hastings 比。由于目标密度 $\\pi(x)$ 通常包含一个未知的归一化常数，我们可以在比率中使用任何函数 $\\tilde{\\pi}(x) \\propto \\pi(x)$，因为常数项会相互抵消。\n3.  从 $[0,1]$ 上的均匀分布中生成一个随机数 $u$。\n4.  如果 $u < \\alpha(X_t, Y)$，则下一个状态 $X_{t+1}$ 被设置为提议值 $Y$；否则，链保持在当前状态，即 $X_{t+1} = X_t$。\n\n此过程保证了所得到的马尔可夫链满足关于 $\\pi$ 的细致平衡条件，这是 $\\pi$ 成为平稳分布的充分条件。\n\n问题指定了使用对称高斯提议分布的随机游走 Metropolis 采样器：$Y = X_t + \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_d)$。对于对称提议，$q(Y|X_t) = q(X_t|Y)$，因此 Hastings 比为 1，接受概率简化为：\n$$\n\\alpha(X_t, Y) = \\min\\left(1, \\frac{\\pi(Y)}{\\pi(X_t)}\\right)\n$$\n为了提高数值稳定性，计算时使用对数概率。接受步骤包括将 $\\log(u)$ 与对数接受率 $\\log(\\alpha) = \\min\\left(0, \\log\\tilde{\\pi}(Y) - \\log\\tilde{\\pi}(X_t)\\right)$ 进行比较。\n\n### 遍历定理与估计\n\n在不可约性和非周期性条件下（我们的构造满足这些条件），马尔可夫链的遍历定理确保了函数 $f(x)$ 的样本均值几乎必然收敛于其在平稳分布下的真实期望：\n$$\n\\bar{f}_n = \\frac{1}{n} \\sum_{t=1}^{n} f(X_t) \\xrightarrow{a.s.} \\mathbb{E}_{\\pi}[f(X)] \\quad \\text{as } n \\to \\infty\n$$\n链的初始样本通常会被丢弃（称为“预烧”期），以减少任意起始状态 $x_0$ 的影响。问题指定了 $b = \\lfloor n/10 \\rfloor$ 次迭代的“预烧”期。然后使用随后的 $n$ 个样本计算经验均值。\n\n### 测试案例的实现\n\n实现了一个通用的 MCMC 函数来处理所有指定案例的模拟。该函数接受对数目标密度、要在样本上求值的函数、初始状态、提议分布的标准差以及模拟参数作为输入。\n\n**案例 $C_1$：单变量正态分布, $f(x) = x^2$**\n- 目标：$\\pi(x) \\propto \\exp(-\\frac{1}{2}x^2)$ on $\\mathbb{R}$。\n- 对数目标：$\\log\\tilde{\\pi}(x) = -\\frac{1}{2}x^2$。\n- 函数：$f(x) = x^2$。\n- 真实期望：$\\mathbb{E}_{\\pi}[f(X)] = 1$。\n\n**案例 $C_2$：单变量正态分布, $f(x) = \\mathbf{1}\\{|x| \\le 1\\}$**\n- 目标：与 $C_1$ 相同，$\\log\\tilde{\\pi}(x) = -\\frac{1}{2}x^2$。\n- 函数：$f(x) = \\mathbf{1}\\{|x| \\le 1\\}$，即当 $|x| \\le 1$ 时为 $1$，否则为 $0$。\n- 真实期望：$\\mathbb{E}_{\\pi}[f(X)] = P(|X| \\le 1) = \\Phi(1) - \\Phi(-1) = 2\\Phi(1) - 1$，其中 $\\Phi$ 是标准正态累积分布函数。\n\n**案例 $C_3$：双变量正态分布, $f(x) = x_1 x_2$**\n- 目标：$\\pi(x) \\propto \\exp(-\\frac{1}{2}\\|x\\|^2)$ on $\\mathbb{R}^2$，其中 $x=(x_1, x_2)$。\n- 对数目标：$\\log\\tilde{\\pi}(x) = -\\frac{1}{2}(x_1^2 + x_2^2)$。\n- 函数：$f(x) = x_1 x_2$。\n- 真实期望：$\\mathbb{E}_{\\pi}[f(X)] = 0$。\n\n**案例 $C_4$：通过变换得到的 Beta 分布**\n- $x \\in (0,1)$ 的目标是 Beta 分布密度，$\\pi_X(x) \\propto x^{a-1}(1-x)^{b-1}$，其中 $a=2.5, b=5.5$。\n- 在 $(0,1)$ 上直接进行随机游走是有问题的。取而代之的是，我们使用 logistic 函数 $x = g(u) = 1/(1+e^{-u})$ 进行重新参数化，该函数将 $u \\in \\mathbb{R}$ 映射到 $x \\in (0,1)$。\n- MCMC 在变换后的变量 $u$ 上运行。$u$ 的目标密度 $\\pi_U(u)$ 通过变量变换公式得到：$\\pi_U(u) = \\pi_X(g(u))|g'(u)|$。\n- 雅可比行列式为 $|g'(u)| = \\frac{e^{-u}}{(1+e^{-u})^2} = g(u)(1-g(u))$。\n- 因此，$\\pi_U(u) \\propto [g(u)]^{a-1}[1-g(u)]^{b-1} \\cdot g(u)(1-g(u)) = [g(u)]^a[1-g(u)]^b$。\n- $u$ 的对数目标为：$\\log\\tilde{\\pi}_U(u) = a \\log(g(u)) + b \\log(1-g(u))$。\n- 函数：期望是针对 $f(x)=x$ 的。模拟生成样本 $u_t$，这些样本被变换回 $x_t=g(u_t)$ 用于求平均值。\n- 真实期望：$\\mathbb{E}_{\\pi_X}[X] = \\frac{a}{a+b} = \\frac{2.5}{8.0}$。\n\n**案例 $C_5$：Student t-分布, $f(x) = x^2$**\n- 目标：自由度为 $\\nu=3$ 的 Student t-分布的密度，$\\pi(x) \\propto (1 + \\frac{x^2}{\\nu})^{-(\\nu+1)/2}$。\n- 对数目标：$\\log\\tilde{\\pi}(x) = -\\frac{\\nu+1}{2}\\log(1 + \\frac{x^2}{\\nu})$。\n- 函数：$f(x) = x^2$。\n- 真实期望：自由度为 $\\nu$ 的标准 t-分布的方差为 $\\frac{\\nu}{\\nu-2}$（当 $\\nu>2$ 时）。由于均值为 $0$，则 $\\mathbb{E}_{\\pi}[X^2] = \\text{Var}(X) = \\frac{3}{3-2} = 3$。\n\n对于这 5 个案例和 3 个样本量中的每一个，都使用指定的参数（$\\sigma$、$x_0$、种子）运行模拟，并计算和记录绝对误差 $|\\bar{f}_n - \\mathbb{E}_{\\pi}[f]|$。最终输出是这 15 个误差的列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def run_mcmc(log_target_pdf, func_to_eval, x0, sigma, n_samples, seed):\n        \"\"\"\n        Runs a random-walk Metropolis-Hastings simulation.\n\n        Args:\n            log_target_pdf: A function that computes the log of the target density (unnormalized).\n            func_to_eval: A function of the chain's state to be averaged.\n            x0: Initial state of the chain (tuple or list).\n            sigma: Standard deviation of the Gaussian proposal distribution.\n            n_samples: Number of samples to collect after burn-in.\n            seed: Seed for the random number generator.\n\n        Returns:\n            The empirical average of func_to_eval over the samples.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        burn_in = n_samples // 10\n        total_iter = n_samples + burn_in\n\n        x = np.array(x0, dtype=float)\n        dim = x.size\n        \n        # Initial log probability\n        current_log_p = log_target_pdf(x)\n\n        f_values = []\n        for i in range(total_iter):\n            # Propose a new state\n            proposal = x + rng.normal(loc=0.0, scale=sigma, size=dim)\n\n            # Calculate acceptance probability in log-space\n            proposal_log_p = log_target_pdf(proposal)\n            log_alpha = proposal_log_p - current_log_p\n\n            if np.log(rng.uniform())  log_alpha:\n                x = proposal\n                current_log_p = proposal_log_p\n            \n            # Collect sample after burn-in\n            if i >= burn_in:\n                f_values.append(func_to_eval(x))\n\n        return np.mean(f_values)\n\n    # --- Test Case Definitions ---\n\n    # Case C1: Univariate standard normal moment\n    c1_log_pdf = lambda x: -0.5 * x[0]**2\n    c1_f = lambda x: x[0]**2\n    \n    # Case C2: Univariate standard normal indicator\n    c2_log_pdf = c1_log_pdf\n    c2_f = lambda x: 1.0 if np.abs(x[0]) = 1.0 else 0.0\n    c2_true_E = 2 * norm.cdf(1) - 1\n\n    # Case C3: Bivariate standard normal cross-moment\n    c3_log_pdf = lambda x: -0.5 * (x[0]**2 + x[1]**2)\n    c3_f = lambda x: x[0] * x[1]\n\n    # Case C4: Beta target via transformation\n    c4_a, c4_b = 2.5, 5.5\n    g = lambda u_vec: 1.0 / (1.0 + np.exp(-u_vec[0]))\n    c4_log_pdf_u = lambda u: c4_a * np.log(g(u)) + c4_b * np.log(1.0 - g(u))\n    c4_f_on_u = lambda u: g(u)\n    c4_true_E = c4_a / (c4_a + c4_b)\n\n    # Case C5: Heavy-tailed Student distribution\n    c5_nu = 3.0\n    c5_log_pdf = lambda x: -((c5_nu + 1.0) / 2.0) * np.log(1.0 + x[0]**2 / c5_nu)\n    c5_f = lambda x: x[0]**2\n    c5_true_E = c5_nu / (c5_nu - 2.0)\n\n\n    test_cases = [\n        {\n            \"name\": \"C1\", \"log_pdf\": c1_log_pdf, \"func_f\": c1_f, \"true_E\": 1.0,\n            \"sigma\": 1.0, \"x0\": (0.0,), \"seeds\": {500: 101, 5000: 102, 50000: 103}\n        },\n        {\n            \"name\": \"C2\", \"log_pdf\": c2_log_pdf, \"func_f\": c2_f, \"true_E\": c2_true_E,\n            \"sigma\": 1.0, \"x0\": (0.0,), \"seeds\": {500: 202, 5000: 203, 50000: 204}\n        },\n        {\n            \"name\": \"C3\", \"log_pdf\": c3_log_pdf, \"func_f\": c3_f, \"true_E\": 0.0,\n            \"sigma\": 0.9, \"x0\": (0.0, 0.0), \"seeds\": {500: 303, 5000: 304, 50000: 305}\n        },\n        {\n            \"name\": \"C4\", \"log_pdf\": c4_log_pdf_u, \"func_f\": c4_f_on_u, \"true_E\": c4_true_E,\n            \"sigma\": 1.25, \"x0\": (0.0,), \"seeds\": {500: 404, 5000: 405, 50000: 406}\n        },\n        {\n            \"name\": \"C5\", \"log_pdf\": c5_log_pdf, \"func_f\": c5_f, \"true_E\": c5_true_E,\n            \"sigma\": 2.5, \"x0\": (0.0,), \"seeds\": {500: 505, 5000: 506, 50000: 507}\n        }\n    ]\n\n    sample_sizes = [500, 5000, 50000]\n    results = []\n\n    for case in test_cases:\n        for n in sample_sizes:\n            seed = case[\"seeds\"][n]\n            \n            # Run the MCMC simulation\n            empirical_mean = run_mcmc(\n                log_target_pdf=case[\"log_pdf\"],\n                func_to_eval=case[\"func_f\"],\n                x0=case[\"x0\"],\n                sigma=case[\"sigma\"],\n                n_samples=n,\n                seed=seed\n            )\n            \n            # Compute and store the absolute error\n            error = np.abs(empirical_mean - case[\"true_E\"])\n            rounded_error = round(error, 6)\n            results.append(rounded_error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "当应用于非标准的复杂状态空间时，MCMC 方法展现出其真正的灵活性。这个高级问题挑战您将 Metropolis-Hastings 算法应用于有向无环图 (DAGs) 的空间，这是贝叶斯结构学习中的一项关键任务。通过推导一个图编辑提议的接受概率，您将学会处理完整的 MH 比率，包括处理组合结构上非对称提议分布时至关重要的 Hastings 项 。",
            "id": "3313416",
            "problem": "考虑节点集 $\\{1,2,3,4\\}$ 上的有向无环图 (DAG) 的状态空间。假设我们的目标是从一个 DAG 的后验分布中进行采样，该分布正比于 $\\exp(S(G))$，其中 $S(G)$ 是一个可分解的对数得分，它将基于每个节点的父节点集的局部得分相加，并且 DAG 的先验分布是均匀的。我们使用 Metropolis-Hastings (MH) 算法设计一个马尔可夫链蒙特卡洛 (MCMC) 采样器，其提议仅限于保持无环性的局部边编辑。一个局部编辑是以下操作之一：添加一条当前不存在的有向边 $i \\to j$，删除一条已有的有向边，或反转一条已有的边 $i \\to j$ 为 $j \\to i$（仅当生成的图保持无环时）。在每一步中，提议机制从当前 DAG 中所有有效的局部编辑集合中均匀随机地选择一个。所有会产生环的移动都是不允许的。\n\n从当前边集为 $\\{1 \\to 2,\\; 1 \\to 3,\\; 3 \\to 4\\}$ 的 DAG $G$ 开始，考虑提议添加边 $4 \\to 2$，得到提议的边集为 $\\{1 \\to 2,\\; 1 \\to 3,\\; 3 \\to 4,\\; 4 \\to 2\\}$ 的 DAG $G'$。可分解对数得分 $S(G)$ 的变化仅通过节点 2 的局部得分产生，其父节点集从 $G$ 中的 $\\{1\\}$ 变为 $G'$ 中的 $\\{1,4\\}$。相关的局部得分为：\n- $\\ell_{2}(\\{1\\}) = -120.5$，\n- $\\ell_{2}(\\{1,4\\}) = -121.3$。\n\n根据适用于马尔可夫链蒙特卡洛的基本原理，推导在给定后验分布下，此 DAG 提议机制的一般 MH 接受概率。然后，对于从 $G$ 到 $G'$ 的具体移动，通过显式地枚举从 $G$ 和 $G'$ 出发的所有有效局部编辑，并评估 $S(G)$ 的变化，来计算接受概率 $\\alpha(G \\to G')$。将您计算出的 $\\alpha(G \\to G')$ 的最终数值结果四舍五入到四位有效数字，并表示为一个无单位的小数。",
            "solution": "已根据指定的验证协议对用户提供的问题进行了分析。\n\n### 步骤 1：提取已知信息\n-   **状态空间**：节点集 $V=\\{1,2,3,4\\}$ 上所有有向无环图 (DAG) 的集合。\n-   **目标分布**：DAG $G$ 上的后验分布，记作 $\\pi(G)$，正比于 $\\exp(S(G))$。这意味着 DAG 空间上的先验是均匀分布。\n-   **得分函数**：$S(G)$ 是一个可分解的对数得分，$S(G) = \\sum_{i \\in V} \\ell_i(\\text{Pa}_G(i))$，其中 $\\text{Pa}_G(i)$ 是图 $G$ 中节点 $i$ 的父节点集。\n-   **MCMC 算法**：Metropolis-Hastings (MH)。\n-   **提议机制**：从当前 DAG $G$ 的所有有效局部编辑集合中均匀随机选择一个，生成提议 $G'$。\n-   **有效的局部编辑**：\n    1.  添加一条当前不在 $G$ 中的有向边 $i \\to j$，前提是生成的图是无环的。\n    2.  删除一条已有的有向边 $i \\to j$。\n    3.  反转一条已有的有向边 $i \\to j$ 为 $j \\to i$，前提是生成的图是无环的。\n-   **当前状态**：边集为 $E_G = \\{1 \\to 2,\\; 1 \\to 3,\\; 3 \\to 4\\}$ 的 DAG $G$。\n-   **提议状态**：边集为 $E_{G'} = \\{1 \\to 2,\\; 1 \\to 3,\\; 3 \\to 4,\\; 4 \\to 2\\}$ 的 DAG $G'$。\n-   **局部得分**：$\\ell_{2}(\\{1\\}) = -120.5$ 以及 $\\ell_{2}(\\{1,4\\}) = -121.3$。\n-   **约束**：对数得分 $S(G)$ 的变化仅通过节点 2 的局部得分产生。\n\n### 步骤 2：使用提取的已知信息进行验证\n该问题被评估为**有效**。\n-   **科学性**：该问题描述了一个使用 MCMC 进行图模型贝叶斯结构学习的标准任务，这是机器学习和统计学中的一个核心主题。Metropolis-Hastings 算法、可分解得分以及所描述的邻域结构（局部边编辑）都是成熟且基本合理的概念。\n-   **适定性**：该问题要求推导一个通用公式并进行具体的数值计算。完成这些任务所需的所有信息都已提供。说明清晰，可以确定一个唯一的、有意义的解。\n-   **客观性**：该问题使用精确、正式的语言陈述，不包含任何主观或模糊的元素。\n\n### 步骤 3：结论与行动\n该问题有效。下面提供了详细的解答。\n\n从状态 $G$ 转换到提议状态 $G'$ 的 Metropolis-Hastings (MH) 接受概率由以下通用公式给出：\n$$\n\\alpha(G \\to G') = \\min\\left(1, \\frac{\\pi(G')}{\\pi(G)} \\frac{q(G' \\to G)}{q(G \\to G')}\\right)\n$$\n其中 $\\pi(G)$ 是状态 $G$ 的目标概率，$q(G \\to G')$ 是从 $G$ 移动到 $G'$ 的提议概率。\n\n首先，我们确定目标分布比率 $\\frac{\\pi(G')}{\\pi(G)}$。问题陈述后验分布正比于 $\\exp(S(G))$，并且 DAG 上的先验是均匀的。均匀先验 $P(G)$ 意味着对于任何有效的 DAG $G$，$P(G) = C$，其中 $C$ 是某个常数。因此，目标分布为 $\\pi(G) \\propto P(\\text{Data}|G)P(G) \\propto \\exp(S(G)) \\cdot C$。该比率为：\n$$\n\\frac{\\pi(G')}{\\pi(G)} = \\frac{C \\cdot \\exp(S(G'))}{C \\cdot \\exp(S(G))} = \\exp(S(G') - S(G))\n$$\n接下来，我们确定提议概率比率 $\\frac{q(G' \\to G)}{q(G \\to G')}$。提议机制从所有有效局部编辑的集合中均匀选择。设 $N(G)$ 是从 $G$ 通过一次有效局部编辑可达的所有 DAG 的集合。这个集合的大小是 $|N(G)|$。因此，对于任何 $G' \\in N(G)$，提议概率为 $q(G \\to G') = \\frac{1}{|N(G)|}$，否则为 $0$。类似地，反向提议概率为 $q(G' \\to G) = \\frac{1}{|N(G')|}$。\n提议比率为：\n$$\n\\frac{q(G' \\to G)}{q(G \\to G')} = \\frac{1/|N(G')|}{1/|N(G)|} = \\frac{|N(G)|}{|N(G')|}\n$$\n将这些表达式代入 MH 公式，得到这个特定采样器的一般接受概率：\n$$\n\\alpha(G \\to G') = \\min\\left(1, \\exp(S(G') - S(G)) \\frac{|N(G)|}{|N(G')|}\\right)\n$$\n这是一般接受概率的表达式。\n\n现在，我们为从 $G$ 到 $G'$ 的具体移动计算这个值。\n对数得分的变化量 $\\Delta S = S(G') - S(G)$ 由局部得分的变化决定。从 $G$ 到 $G'$ 的移动包括添加边 $4 \\to 2$。这只改变了节点 2 的父节点集。在 $G$ 中，$\\text{Pa}_G(2)=\\{1\\}$。在 $G'$ 中，$\\text{Pa}_{G'}(2)=\\{1,4\\}$。所有其他父节点集保持不变。\n给定局部得分 $\\ell_{2}(\\{1\\}) = -120.5$ 和 $\\ell_{2}(\\{1,4\\}) = -121.3$，总得分的变化是：\n$$\n\\Delta S = S(G') - S(G) = \\ell_{2}(\\text{Pa}_{G'}(2)) - \\ell_{2}(\\text{Pa}_G(2)) = -121.3 - (-120.5) = -0.8\n$$\n目标比率为 $\\exp(-0.8)$。\n\n接下来，我们必须通过枚举每个图的所有有效局部编辑来计算 $|N(G)|$ 和 $|N(G')|$。\n\n**枚举从 $G$（边集：$\\{1 \\to 2, 1 \\to 3, 3 \\to 4\\}$）出发的编辑：**\n$G$ 中的路径有 $1 \\to 2$、$1 \\to 3$、$3 \\to 4$ 和 $1 \\to 3 \\to 4$。\n1.  **删除**：有 3 条边，所以有 3 个有效的删除移动。\n2.  **添加**：如果边 $i \\to j$ 不存在，并且在 $G$ 中没有从 $j$ 到 $i$ 的路径，我们就可以添加它。有 $4 \\times 3 - 3 = 9$ 条不存在的边。\n    -   无效的添加（会产生环）：\n        -   $2 \\to 1$（与 $1 \\to 2$ 构成环）\n        -   $3 \\to 1$（与 $1 \\to 3$ 构成环）\n        -   $4 \\to 1$（与 $1 \\to 3 \\to 4$ 构成环）\n        -   $4 \\to 3$（与 $3 \\to 4$ 构成环）\n    -   有效的添加：$9 - 4 = 5$ 个移动。它们是 $1 \\to 4$、$2 \\to 3$、$2 \\to 4$、$3 \\to 2$、$4 \\to 2$。\n3.  **反转**：如果 $G$ 中没有从 $i$ 到 $j$ 的其他路径，我们就可以反转边 $i \\to j$。\n    -   反转 $1 \\to 2$：没有从 1 到 2 的其他路径。有效。\n    -   反转 $1 \\to 3$：没有从 1 到 3 的其他路径。有效。\n    -   反转 $3 \\to 4$：没有从 3 到 4 的其他路径。有效。\n    -   有 3 个有效的反转移动。\n从 $G$ 出发的有效编辑总数是 $|N(G)| = 3 (\\text{删除}) + 5 (\\text{添加}) + 3 (\\text{反转}) = 11$。\n\n**枚举从 $G'$（边集：$\\{1 \\to 2, 1 \\to 3, 3 \\to 4, 4 \\to 2\\}$）出发的编辑：**\n图 $G'$ 是无环的。其路径包括 $1 \\to 2$、$1 \\to 3 \\to 4 \\to 2$、$1 \\to 3$、$3 \\to 4$ 和 $4 \\to 2$。\n1.  **删除**：有 4 条边，所以有 4 个有效的删除移动。\n2.  **添加**：我们检查 $4 \\times 3 - 4 = 8$ 条不存在的边。\n    -   无效的添加（在 $G'$ 中存在路径 $j \\to i$）：\n        -   $2 \\to 1$（存在路径 $1 \\to 2$）\n        -   $3 \\to 1$（存在路径 $1 \\to 3$）\n        -   $4 \\to 1$（存在路径 $1 \\to 3 \\to 4$）\n        -   $2 \\to 3$（存在路径 $3 \\to 4 \\to 2$）\n        -   $2 \\to 4$（存在路径 $4 \\to 2$）\n        -   $4 \\to 3$（存在路径 $3 \\to 4$）\n    -   有效的添加：剩下的 2 个移动是 $1 \\to 4$ 和 $3 \\to 2$。\n3.  **反转**：我们检查 4 条已有的边 $i \\to j$。\n    -   反转 $1 \\to 2$：无效，因为存在另一条路径 $1 \\to 3 \\to 4 \\to 2$。\n    -   反转 $1 \\to 3$：没有从 1 到 3 的其他路径。有效。\n    -   反转 $3 \\to 4$：没有从 3 到 4 的其他路径。有效。\n    -   反转 $4 \\to 2$：没有从 4 到 2 的其他路径。有效。\n    -   有 3 个有效的反转移动。\n从 $G'$ 出发的有效编辑总数是 $|N(G')| = 4 (\\text{删除}) + 2 (\\text{添加}) + 3 (\\text{反转}) = 9$。\n\n最后，我们整合接受概率：\n$$\n\\alpha(G \\to G') = \\min\\left(1, \\exp(-0.8) \\frac{11}{9}\\right)\n$$\n计算该值：\n$$\n\\exp(-0.8) \\approx 0.449329\n$$\n$$\n\\frac{11}{9} \\approx 1.222222\n$$\n$$\n\\exp(-0.8) \\frac{11}{9} \\approx 0.449329 \\times 1.222222 \\approx 0.5491807\n$$\n该值小于 $1$。四舍五入到四位有效数字，我们得到 $0.5492$。",
            "answer": "$$\\boxed{0.5492}$$"
        }
    ]
}