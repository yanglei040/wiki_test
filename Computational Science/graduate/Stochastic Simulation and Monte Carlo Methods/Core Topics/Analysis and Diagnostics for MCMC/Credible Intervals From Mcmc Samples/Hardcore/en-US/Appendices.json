{
    "hands_on_practices": [
        {
            "introduction": "This practice delves into the subtle but important distinction between the *nominal* coverage of a credible interval and its *expected* coverage when constructed from a finite sample. While we often speak of a $95\\%$ interval, the use of discrete order statistics from a finite number of MCMC draws means the actual posterior mass captured by the interval is a random variable. This exercise uses the theory of order statistics to calculate the exact expected coverage, providing a crucial insight into the finite-sample properties of MCMC-based inference .",
            "id": "3301098",
            "problem": "A scalar parameter $\\theta$ has a continuous posterior cumulative distribution function $F$ from which a Markov chain Monte Carlo (MCMC) sampler has produced $m$ effective independent draws at stationarity. Denote these draws by $Y_{1},\\dots,Y_{m}$ and their order statistics by $Y_{(1)} \\le \\dots \\le Y_{(m)}$. You wish to report a nominal $95\\%$ equal-tailed credible interval using finite-sample order statistics with the following index rule: for tail probability $\\alpha = 0.025$, take the lower endpoint to be $Y_{(\\ell)}$ with $\\ell = \\lceil (m+1)\\alpha \\rceil$ and the upper endpoint to be $Y_{(u)}$ with $u = \\lfloor (m+1)(1-\\alpha) \\rfloor$. \n\nAssume the draws are independent and identically distributed from the true posterior with continuous $F$. For $m=2000$, compute the expected posterior probability mass contained in the reported interval, that is, compute $\\mathbb{E}\\!\\left[F\\!\\left(Y_{(u)}\\right) - F\\!\\left(Y_{(\\ell)}\\right)\\right]$. Round your answer to four significant figures.",
            "solution": "The user wants to find the expected posterior probability mass of a credible interval constructed from Markov chain Monte Carlo (MCMC) samples.\n\n### Step 1: Extract Givens\n- Parameter of interest: A scalar parameter $\\theta$.\n- Posterior cumulative distribution function (CDF): $F$, which is continuous.\n- MCMC sample: $Y_1, \\dots, Y_m$ are $m$ effective independent draws from the posterior distribution of $\\theta$.\n- Order statistics of the sample: $Y_{(1)} \\le Y_{(2)} \\le \\dots \\le Y_{(m)}$.\n- Nominal credible interval level: $95\\%$, equal-tailed.\n- Tail probability: $\\alpha = 0.025$.\n- Interval endpoints: The interval is $[Y_{(\\ell)}, Y_{(u)}]$.\n- Index for lower endpoint: $\\ell = \\lceil (m+1)\\alpha \\rceil$.\n- Index for upper endpoint: $u = \\lfloor (m+1)(1-\\alpha) \\rfloor$.\n- Sample size: $m=2000$.\n- Assumption: The draws $Y_1, \\dots, Y_m$ are independent and identically distributed (i.i.d.) from the continuous CDF $F$.\n- Objective: Compute the expected posterior probability mass $\\mathbb{E}\\!\\left[F\\!\\left(Y_{(u)}\\right) - F\\!\\left(Y_{(\\ell)}\\right)\\right]$.\n- Required precision: Round the final answer to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-defined within the framework of Bayesian statistics and the theory of order statistics. The concepts used, such as posterior distributions, MCMC, credible intervals, and order statistics, are standard. The assumption that the MCMC draws are effective independent samples is a common idealization for theoretical analysis. The problem is scientifically grounded, objective, and self-contained. It requires a specific, non-trivial calculation based on established statistical theory. There are no contradictions, ambiguities, or factual errors. The problem is valid.\n\n### Step 3: Derivation of the Solution\nThe quantity of interest is the expected value of the posterior probability mass contained within the random interval $[Y_{(\\ell)}, Y_{(u)}]$. The posterior probability mass of this interval is given by $F(Y_{(u)}) - F(Y_{(\\ell)})$. We need to compute its expectation:\n$$\n\\mathbb{E}\\!\\left[F\\!\\left(Y_{(u)}\\right) - F\\!\\left(Y_{(\\ell)}\\right)\\right]\n$$\nBy the linearity of expectation, this is equal to:\n$$\n\\mathbb{E}\\!\\left[F\\!\\left(Y_{(u)}\\right)\\right] - \\mathbb{E}\\!\\left[F\\!\\left(Y_{(\\ell)}\\right)\\right]\n$$\nThe problem states that the draws $Y_1, \\dots, Y_m$ are i.i.d. from a distribution with a continuous CDF $F$. We can apply the probability integral transform. Let $U_i = F(Y_i)$ for $i=1, \\dots, m$. A fundamental result in probability theory states that if $Y$ has a continuous CDF $F$, then the random variable $U = F(Y)$ follows a standard uniform distribution, $U \\sim \\text{Uniform}(0,1)$.\n\nThus, $U_1, \\dots, U_m$ are $m$ i.i.d. random variables from a $\\text{Uniform}(0,1)$ distribution. Since the CDF $F$ is a non-decreasing function, it preserves the order of the random variables. This means that if $Y_{(j)}$ is the $j$-th order statistic of the sample $\\{Y_i\\}$, then $F(Y_{(j)})$ is the $j$-th order statistic of the transformed sample $\\{U_i\\}$. We denote this by $U_{(j)} = F(Y_{(j)})$.\n\nThe problem now reduces to computing $\\mathbb{E}[U_{(u)}] - \\mathbb{E}[U_{(\\ell)}]$, where $U_{(j)}$ is the $j$-th order statistic from a sample of size $m$ from a $\\text{Uniform}(0,1)$ distribution.\n\nFor a sample of size $m$ from a $\\text{Uniform}(0,1)$ distribution, the $j$-th order statistic $U_{(j)}$ is known to follow a Beta distribution. Specifically, $U_{(j)} \\sim \\text{Beta}(j, m-j+1)$.\nThe expected value of a random variable $X$ following a $\\text{Beta}(a,b)$ distribution is given by $\\mathbb{E}[X] = \\frac{a}{a+b}$.\n\nApplying this to our order statistic $U_{(j)}$, we have $a=j$ and $b=m-j+1$. The expectation is:\n$$\n\\mathbb{E}[U_{(j)}] = \\frac{j}{j + (m-j+1)} = \\frac{j}{m+1}\n$$\nUsing this result, we can compute the expectations for our specific indices $\\ell$ and $u$:\n$$\n\\mathbb{E}[F(Y_{(\\ell)})] = \\mathbb{E}[U_{(\\ell)}] = \\frac{\\ell}{m+1}\n$$\n$$\n\\mathbb{E}[F(Y_{(u)})] = \\mathbb{E}[U_{(u)}] = \\frac{u}{m+1}\n$$\nTherefore, the expected posterior probability mass is:\n$$\n\\mathbb{E}\\!\\left[F\\!\\left(Y_{(u)}\\right) - F\\!\\left(Y_{(\\ell)}\\right)\\right] = \\frac{u}{m+1} - \\frac{\\ell}{m+1} = \\frac{u - \\ell}{m+1}\n$$\nNow, we must calculate the values of $\\ell$ and $u$ using the given formulas and values $m=2000$ and $\\alpha=0.025$.\n\nFirst, calculate the lower index $\\ell$:\n$$\n\\ell = \\lceil (m+1)\\alpha \\rceil = \\lceil (2000+1) \\times 0.025 \\rceil = \\lceil 2001 \\times 0.025 \\rceil = \\lceil 50.025 \\rceil = 51\n$$\nNext, calculate the upper index $u$:\n$$\nu = \\lfloor (m+1)(1-\\alpha) \\rfloor = \\lfloor (2000+1)(1 - 0.025) \\rfloor = \\lfloor 2001 \\times 0.975 \\rfloor = \\lfloor 1950.975 \\rfloor = 1950\n$$\nNow, we substitute these indices into our expression for the expected probability mass:\n$$\n\\frac{u - \\ell}{m+1} = \\frac{1950 - 51}{2001} = \\frac{1899}{2001}\n$$\nTo obtain the final numerical answer, we perform the division and round to four significant figures:\n$$\n\\frac{1899}{2001} \\approx 0.949025487...\n$$\nRounding this value to four significant figures gives $0.9490$.\n\nThis result shows that the expected coverage of a nominal $95\\%$ credible interval constructed using this specific index rule on a finite sample is slightly less than $95\\%$. This discrepancy is due to the discrete nature of the order statistics and the use of the ceiling and floor functions.",
            "answer": "$$\n\\boxed{0.9490}\n$$"
        },
        {
            "introduction": "A common piece of advice for MCMC practitioners is to \"thin\" the output chain—keeping only every $k$-th sample—to reduce autocorrelation. This practice challenges you to investigate the true effect of thinning on the precision of your estimates. By comparing the Monte Carlo Standard Error (MCSE) of credible interval endpoints under a fixed computational budget, you will empirically discover that thinning, by discarding information, typically *increases* estimation error rather than reducing it, a critical lesson in maximizing statistical efficiency from your simulations .",
            "id": "3301155",
            "problem": "Consider a stationary Gaussian first-order autoregressive Markov chain defined by $X_t = \\varphi X_{t-1} + \\sqrt{1 - \\varphi^2}\\,Z_t$ with $Z_t \\sim \\mathcal{N}(0,1)$ independent and identically distributed, and $X_0 \\sim \\mathcal{N}(0,1)$ independent of $\\{Z_t\\}$. This chain has a stationary marginal distribution $\\mathcal{N}(0,1)$ for every $t \\ge 0$. Let $F$ denote the stationary cumulative distribution function and $f$ the corresponding stationary probability density function. For a credibility level $p \\in (0,1)$, define the $p$-quantile $x_p$ by $F(x_p) = p$. The $(1-\\alpha)$ credible interval endpoints for a univariate posterior are the quantiles at $p = \\alpha/2$ and $p = 1 - \\alpha/2$, here take $\\alpha = 0.05$, that is, $p \\in \\{0.025, 0.975\\}$.\n\nThe goal is to quantify the Monte Carlo standard error of the estimated credible interval endpoints from Markov Chain Monte Carlo (MCMC) samples under a fixed computational budget, and to assess the effect of thinning on precision. Use the fundamental base that for a geometrically ergodic Markov chain and a square-integrable function $h$, the Markov chain central limit theorem gives\n$$\n\\sqrt{n}\\left(\\frac{1}{n}\\sum_{t=1}^{n} h(X_t) - \\mathbb{E}[h(X)]\\right) \\xrightarrow{d} \\mathcal{N}\\left(0, \\sigma_h^2\\right),\n$$\nwhere the long-run variance is $\\sigma_h^2 = \\gamma_0 + 2\\sum_{\\ell=1}^{\\infty} \\gamma_\\ell$, with $\\gamma_\\ell = \\mathrm{Cov}(h(X_t), h(X_{t+\\ell}))$. For quantiles, use the delta method: with $h_p(x) = \\mathbf{1}\\{x \\le x_p\\}$, one has $\\mathbb{E}[h_p(X)] = p$ and\n$$\n\\mathrm{MCSE}\\left(\\hat{x}_p\\right) \\approx \\sqrt{\\frac{\\sigma_{h_p}^2}{n\\, f(x_p)^2}},\n$$\nwhere $n$ is the number of retained draws and $f(x_p)$ is the stationary density at $x_p$.\n\nIn practice, $\\sigma_{h_p}^2$ is unknown and must be estimated from the draws via a spectral (long-run variance) estimator. Implement the Bartlett spectral variance estimator with truncation $m = \\lfloor n^{1/3} \\rfloor$ applied to the centered indicator series $Y_t = h_p(X_t) - p$:\n$$\n\\widehat{\\sigma}_{h_p}^2 = \\widehat{\\gamma}_0 + 2 \\sum_{\\ell=1}^{m} w_\\ell\\, \\widehat{\\gamma}_\\ell,\n\\quad\nw_\\ell = 1 - \\frac{\\ell}{m+1},\n\\quad\n\\widehat{\\gamma}_\\ell = \\frac{1}{n}\\sum_{t=1}^{n-\\ell} Y_t Y_{t+\\ell}.\n$$\n\nDefine thinning by a factor $k \\in \\mathbb{N}$ as keeping only every $k$th draw from the Markov chain while still expending the same total number of transitions; under a fixed computational budget $B$, the retained sample size is $n = B/k$. For the thinned series, the same spectral variance estimator applies but now to the thinned indicator series and with its own truncation parameter $m = \\lfloor n^{1/3} \\rfloor$.\n\nTask:\n- For each specified parameter set $(\\varphi, B, k)$, simulate $B$ steps of the $\\mathcal{N}(0,1)$ stationary autoregressive chain. Use both the unthinned draws (retain all $B$ draws, i.e., $k=1$) and the thinned draws (retain every $k$th draw) to compute the approximate Monte Carlo standard error for each credible interval endpoint $p \\in \\{0.025, 0.975\\}$ using the Bartlett spectral variance estimator with $m = \\lfloor n^{1/3} \\rfloor$ for the retained sample size $n$ in each case. Use the stationary density $f(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}$ to evaluate $f(x_p)$ at the true $x_p$.\n- For each parameter set, compute the ratios\n$$\nR_p(\\varphi, B, k) = \\frac{\\mathrm{MCSE}_{\\text{thin}}(p)}{\\mathrm{MCSE}_{\\text{all}}(p)},\n$$\nwhere $\\mathrm{MCSE}_{\\text{thin}}(p)$ uses the thinned retained sample of size $n = B/k$ and $\\mathrm{MCSE}_{\\text{all}}(p)$ uses all $B$ draws.\n- Aggregate the evidence by returning a boolean for each parameter set that is true if both endpoints do not show improved precision under thinning, formalized here as $R_p(\\varphi, B, k) \\ge 1 - \\epsilon$ for $p \\in \\{0.025, 0.975\\}$ with tolerance $\\epsilon = 0.02$ to account for finite-sample estimation variability of the spectral variance, and false otherwise.\n\nDefinitions and constraints:\n- Markov Chain Monte Carlo (MCMC) refers to constructing a Markov chain whose stationary distribution equals the target posterior; here the target is $\\mathcal{N}(0,1)$ and the chain is autoregressive with parameter $\\varphi$.\n- The computational budget $B$ is the number of transitions taken; there is no unit beyond integer steps.\n- Thinning factor $k$ is a positive integer; $k=1$ means no thinning.\n- Credible interval endpoints are quantiles with levels $p \\in \\{0.025, 0.975\\}$ expressed as decimals.\n\nImplement the program to use the following test suite of parameter values:\n1. $(\\varphi, B, k) = (0.0, 200000, 10)$: independent draws, moderate thinning.\n2. $(\\varphi, B, k) = (0.5, 200000, 10)$: moderate autocorrelation, moderate thinning.\n3. $(\\varphi, B, k) = (0.95, 200000, 10)$: high autocorrelation, moderate thinning.\n4. $(\\varphi, B, k) = (0.95, 200000, 50)$: high autocorrelation, heavy thinning.\n5. $(\\varphi, B, k) = (0.0, 200000, 1)$: independent draws, no thinning (baseline).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,...]\"), where each entry is a boolean corresponding to the parameter sets in the order above.",
            "solution": "The problem is assessed as valid, being scientifically grounded in the theory of Markov Chain Monte Carlo (MCMC) methods, well-posed with all necessary definitions and parameters, and objectively stated. We may therefore proceed with a solution.\n\nThe objective is to empirically evaluate the effect of thinning on the statistical precision of credible interval endpoints estimated from a stationary Markov chain. A common misconception is that thinning improves precision by reducing autocorrelation. However, for a fixed computational budget (i.e., a fixed number of total Markov chain transitions), thinning discards information, which generally leads to a decrease in precision (i.e., an increase in Monte Carlo Standard Error, or MCSE).\n\nThe methodology for this evaluation is as follows:\n\n1.  **Stationary Process Simulation**: For each parameter set $(\\varphi, B, k)$, we simulate a total of $B$ steps of the stationary Gaussian first-order autoregressive process defined by $X_t = \\varphi X_{t-1} + \\sqrt{1 - \\varphi^2}\\,Z_t$. The process is initialized from its stationary distribution, $X_0 \\sim \\mathcal{N}(0,1)$, ensuring the entire generated sequence $\\{X_t\\}_{t=1}^B$ is from the stationary distribution $\\mathcal{N}(0,1)$.\n\n2.  **Sample Generation**: Two samples are derived from the simulated sequence:\n    *   An \"unthinned\" or \"all\" sample, containing all $B$ draws, with sample size $n_{\\text{all}} = B$.\n    *   A \"thinned\" sample, created by selecting every $k$-th draw from the original sequence. Its size is $n_{\\text{thin}} = B/k$.\n\n3.  **MCSE Estimation**: The core of the analysis is the calculation of the MCSE for the quantile estimates $\\hat{x}_p$. The problem provides the formula based on the delta method applied to the result of a Markov Chain Central Limit Theorem:\n    $$\n    \\mathrm{MCSE}\\left(\\hat{x}_p\\right) \\approx \\sqrt{\\frac{\\sigma_{h_p}^2}{n\\, f(x_p)^2}}\n    $$\n    The components of this formula are:\n    *   $p \\in \\{0.025, 0.975\\}$: The quantile levels corresponding to a $95\\%$ credible interval ($\\alpha=0.05$).\n    *   $x_p$: The true quantile, $x_p = \\Phi^{-1}(p)$, where $\\Phi$ is the CDF of the standard normal distribution.\n    *   $f(x_p)$: The value of the standard normal PDF at the true quantile $x_p$.\n    *   $n$: The number of draws in the sample ($n_{\\text{all}}$ or $n_{\\text{thin}}$).\n    *   $\\sigma_{h_p}^2$: The long-run variance of the indicator process for the quantile, where the indicator function is $h_p(x) = \\mathbf{1}\\{x \\le x_p\\}$.\n\n4.  **Long-Run Variance Calculation**: The long-run variance $\\sigma_{h_p}^2$ must be estimated from the Markov chain output. The problem specifies the use of the Bartlett spectral variance estimator. This involves creating a centered indicator series $Y_t = h_p(X_t) - p$ and then computing:\n    $$\n    \\widehat{\\sigma}_{h_p}^2 = \\widehat{\\gamma}_0 + 2 \\sum_{\\ell=1}^{m} w_\\ell\\, \\widehat{\\gamma}_\\ell\n    $$\n    where the sample autocovariance at lag $\\ell$ is $\\widehat{\\gamma}_\\ell = \\frac{1}{n}\\sum_{t=1}^{n-\\ell} Y_t Y_{t+\\ell}$, the Bartlett weights are $w_\\ell = 1 - \\frac{\\ell}{m+1}$, and the truncation lag is $m = \\lfloor n^{1/3} \\rfloor$. This calculation is performed independently for each sample (all and thinned).\n\n5.  **Performance Comparison**: The effect of thinning is quantified by the ratio of the estimated MCSEs:\n    $$\n    R_p(\\varphi, B, k) = \\frac{\\mathrm{MCSE}_{\\text{thin}}(p)}{\\mathrm{MCSE}_{\\text{all}}(p)}\n    $$\n    A ratio greater than $1$ signifies that thinning has increased the estimation error, thus reducing precision. The final evaluation for each parameter set is a boolean value, which is `True` if thinning does not offer an improvement in precision for both endpoints, defined with a tolerance $\\epsilon=0.02$ as $R_p \\geq 1 - \\epsilon$ for both $p=0.025$ and $p=0.975$.\n\nThe provided Python code implements this entire procedure. It iterates through the specified test cases, performs the AR(1) simulation, calculates the MCSE for both the full and thinned samples using the Bartlett estimator, computes the ratios, and applies the decision rule to generate the final list of boolean results. A fixed random seed is employed to ensure the simulation results are reproducible.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef calculate_mcse(samples, p, x_p, f_at_xp):\n    \"\"\"\n    Calculates the Monte Carlo Standard Error for a quantile estimate using the\n    Bartlett spectral variance estimator.\n    \n    Args:\n        samples (np.ndarray): The MCMC sample draws.\n        p (float): The quantile level.\n        x_p (float): The true value of the quantile.\n        f_at_xp (float): The value of the stationary PDF at the true quantile.\n        \n    Returns:\n        float: The estimated MCSE of the quantile.\n    \"\"\"\n    n = len(samples)\n    if n == 0:\n        return np.inf\n\n    # Form the centered indicator series Y_t = 1{X_t = x_p} - p\n    Y = (samples = x_p).astype(np.float64) - p\n    \n    # Define truncation lag for Bartlett estimator\n    m = int(n**(1/3))\n    \n    # Calculate sample autocovariance at lag 0 (proportional to sample variance)\n    # The problem defines gamma_hat_l with normalization by n.\n    gamma_0_hat = np.sum(Y**2) / n\n    \n    auto_cov_sum = 0.0\n    if m > 0:\n        for l in range(1, m + 1):\n            # Bartlett kernel weight\n            w_l = 1.0 - l / (m + 1.0)\n            \n            # Sample autocovariance at lag l, normalized by n\n            gamma_l_hat = np.sum(Y[:-l] * Y[l:]) / n\n            auto_cov_sum += w_l * gamma_l_hat\n            \n    # Estimate the long-run variance (spectral density at frequency 0)\n    sigma_h_sq_hat = gamma_0_hat + 2 * auto_cov_sum\n    \n    # Calculate MCSE using the formula from the delta method\n    denominator = n * f_at_xp**2\n    if denominator = 0:\n        return np.inf\n        \n    mcse = np.sqrt(sigma_h_sq_hat / denominator)\n    \n    return mcse\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and comparison for all test cases.\n    \"\"\"\n    # Set a seed for reproducibility of the simulation.\n    np.random.seed(42)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 200000, 10),\n        (0.5, 200000, 10),\n        (0.95, 200000, 10),\n        (0.95, 200000, 50),\n        (0.0, 200000, 1),\n    ]\n\n    # Define quantile levels and tolerance for the decision rule.\n    p_levels = [0.025, 0.975]\n    epsilon = 0.02\n\n    # Pre-compute true quantiles and density values for the N(0,1) distribution.\n    x_p_values = stats.norm.ppf(p_levels)\n    f_at_x_p_values = stats.norm.pdf(x_p_values)\n\n    results = []\n    \n    for phi, B, k in test_cases:\n        # 1. Simulate the stationary AR(1) chain of length B.\n        X_all = np.zeros(B)\n        x_current = np.random.randn() # Start from stationary distribution X_0 ~ N(0,1)\n        sqrt_term = np.sqrt(1 - phi**2)\n        \n        for i in range(B):\n            Z = np.random.randn()\n            x_current = phi * x_current + sqrt_term * Z\n            X_all[i] = x_current\n            \n        # 2. Prepare the thinned sample by taking every k-th draw.\n        X_thin = X_all[::k]\n\n        # 3. Calculate MCSE for both samples and for both quantile endpoints.\n        mcse_all_list = []\n        mcse_thin_list = []\n\n        for p, x_p, f_at_xp in zip(p_levels, x_p_values, f_at_x_p_values):\n            # MCSE for the full sample (all draws)\n            mcse_all = calculate_mcse(X_all, p, x_p, f_at_xp)\n            mcse_all_list.append(mcse_all)\n            \n            # MCSE for the thinned sample\n            mcse_thin = calculate_mcse(X_thin, p, x_p, f_at_xp)\n            mcse_thin_list.append(mcse_thin)\n\n        # 4. Compute ratios of MCSEs.\n        ratios = np.array(mcse_thin_list) / np.array(mcse_all_list)\n        \n        # 5. Apply the decision rule: True if thinning does not improve precision\n        # for both endpoints, within the given tolerance.\n        decision = np.all(ratios >= 1.0 - epsilon)\n        results.append(decision.item())\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Determining the \"burn-in\" period—the initial portion of an MCMC chain to be discarded—is a critical step in ensuring estimates are based on samples from the stationary distribution. Rather than relying on simple heuristics, this exercise formalizes the choice of burn-in as a principled bias-variance trade-off. You will quantify how discarding more samples reduces the bias caused by the chain's starting point but increases the variance of your estimators due to a smaller effective sample size, and then find the optimal balance for a given scenario .",
            "id": "3301169",
            "problem": "Consider a one-dimensional target distribution with density proportional to $p(x) \\propto \\exp\\left(-\\frac{x^2}{2}\\right)$ (a standard normal density up to normalization). The goal is to estimate a symmetric credible interval for a single parameter $x$ using samples from a Markov chain constructed by the Random-Walk Metropolis-Hastings (MH) algorithm, and to quantify how the choice of burn-in fraction affects the bias and variance of the interval endpoints. Then, design and implement a bias-variance optimal stopping rule for burn-in removal.\n\nBase the derivation and algorithm on the following fundamental facts:\n- Markov chain ergodic averages converge to expectations under the stationary distribution when the chain is ergodic. For a Markov chain with transition kernel $K$, if it is geometrically ergodic and started from an arbitrary initial distribution, then the distribution of states converges to the stationary distribution $\\pi$ as the number of steps increases.\n- The Random-Walk Metropolis-Hastings (MH) algorithm with a symmetric proposal density $q(y \\mid x) = \\mathcal{N}(x, \\sigma^2)$ has acceptance probability $a(x,y) = \\min\\left\\{1, \\frac{\\pi(y)}{\\pi(x)}\\right\\}$ when $\\pi$ is known up to a normalization constant.\n- For a fixed credibility level $1-\\alpha$ with $0  \\alpha  1$, a symmetric credible interval is defined by the lower and upper quantiles $q_{\\ell} = F^{-1}\\left(\\frac{\\alpha}{2}\\right)$ and $q_{u} = F^{-1}\\left(1 - \\frac{\\alpha}{2}\\right)$, where $F$ is the cumulative distribution function of the posterior (here, the target distribution). For the standard normal target, $q_{\\ell}$ and $q_{u}$ are known analytically.\n- The mean squared error of an estimator $\\hat{\\theta}$ decomposes as $\\mathrm{MSE}(\\hat{\\theta}) = \\left(\\mathrm{Bias}(\\hat{\\theta})\\right)^2 + \\mathrm{Var}(\\hat{\\theta})$, where $\\mathrm{Bias}(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta}] - \\theta$ and $\\mathrm{Var}(\\hat{\\theta}) = \\mathbb{E}\\left[(\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}])^2\\right]$.\n\nDefinitions and requirements:\n- Markov chain Monte Carlo (MCMC) refers to sampling methods that construct a Markov chain whose stationary distribution is the target distribution, allowing estimation of expectations and distributional quantities from the chain realizations.\n- The burn-in fraction $f \\in [0,1)$ specifies that the first $b = \\lfloor f N \\rfloor$ samples of a chain of length $N$ are discarded before computing estimators.\n- The credible interval endpoints are estimated by empirical quantiles computed from the post-burn-in samples: for credibility level $1-\\alpha$, with $\\alpha$ expressed as a decimal, the lower endpoint estimate $\\hat{q}_{\\ell}$ is the empirical quantile at $\\frac{\\alpha}{2}$ and the upper endpoint estimate $\\hat{q}_{u}$ is the empirical quantile at $1 - \\frac{\\alpha}{2}$.\n- To quantify bias and variance for the interval endpoints under a given burn-in fraction $f$, use $R$ independent, identically distributed MCMC replicates (each with independent random seed) to compute $\\{\\hat{q}_{\\ell}^{(r)}(f), \\hat{q}_{u}^{(r)}(f)\\}_{r=1}^R$. Let the true endpoints be $q_{\\ell}$ and $q_{u}$. Define the empirical bias and variance for each endpoint as:\n$$\n\\mathrm{Bias}_{\\ell}(f) = \\left(\\frac{1}{R}\\sum_{r=1}^R \\hat{q}_{\\ell}^{(r)}(f)\\right) - q_{\\ell}, \\quad\n\\mathrm{Var}_{\\ell}(f) = \\frac{1}{R}\\sum_{r=1}^R \\left(\\hat{q}_{\\ell}^{(r)}(f) - \\frac{1}{R}\\sum_{s=1}^R \\hat{q}_{\\ell}^{(s)}(f)\\right)^2,\n$$\nand similarly for the upper endpoint,\n$$\n\\mathrm{Bias}_{u}(f) = \\left(\\frac{1}{R}\\sum_{r=1}^R \\hat{q}_{u}^{(r)}(f)\\right) - q_{u}, \\quad\n\\mathrm{Var}_{u}(f) = \\frac{1}{R}\\sum_{r=1}^R \\left(\\hat{q}_{u}^{(r)}(f) - \\frac{1}{R}\\sum_{s=1}^R \\hat{q}_{u}^{(s)}(f)\\right)^2.\n$$\n- Propose a bias-variance optimal stopping rule for burn-in selection that minimizes the combined mean squared error across both endpoints:\n$$\n\\mathrm{Objective}(f;\\lambda) = \\left(\\mathrm{Bias}_{\\ell}(f)\\right)^2 + \\lambda \\, \\mathrm{Var}_{\\ell}(f) + \\left(\\mathrm{Bias}_{u}(f)\\right)^2 + \\lambda \\, \\mathrm{Var}_{u}(f),\n$$\nwhere $\\lambda  0$ is a trade-off weight parameter expressing the relative importance of variance versus squared bias. The optimal burn-in fraction is then $f^\\star = \\arg\\min_{f \\in \\mathcal{F}} \\mathrm{Objective}(f;\\lambda)$ over a candidate set $\\mathcal{F}$ of fractions.\n\nUse the following Random-Walk Metropolis-Hastings algorithm for each replicate:\n- Initialize at $x_0$.\n- For $t = 1, \\dots, N$, propose $y_t \\sim \\mathcal{N}(x_{t-1}, \\sigma^2)$ and accept with probability $a(x_{t-1}, y_t) = \\min\\left(1, \\exp\\left(-\\frac{y_t^2 - x_{t-1}^2}{2}\\right)\\right)$; set $x_t = y_t$ if accepted, else $x_t = x_{t-1}$. Record $x_t$ as the $t$-th sample.\n\nImplement the above and evaluate the optimal burn-in fraction across three test cases. For each test case, compute $f^\\star$ from the provided candidate set $\\mathcal{F}$ and output the three optimal fractions in a single line list. All quantities are dimensionless; there are no physical units.\n\nTest suite:\n- Case $1$ (slow convergence, far start):\n    - Target: standard normal (as above).\n    - Chain length: $N = 4000$.\n    - Proposal standard deviation: $\\sigma = 0.05$.\n    - Initial value: $x_0 = 5.0$.\n    - Credibility level: $1-\\alpha = 0.95$ (use $\\alpha = 0.05$ as a decimal).\n    - Candidate burn-in fractions: $\\mathcal{F} = \\{0.0, 0.1, 0.2, 0.4, 0.6\\}$.\n    - Replicates: $R = 100$.\n    - Trade-off weight: $\\lambda = 1.0$.\n    - Random seed base: $s = 12345$.\n- Case $2$ (boundary high burn-in options, same slow chain):\n    - Target: standard normal.\n    - Chain length: $N = 4000$.\n    - Proposal standard deviation: $\\sigma = 0.05$.\n    - Initial value: $x_0 = 5.0$.\n    - Credibility level: $1-\\alpha = 0.95$ (use $\\alpha = 0.05$).\n    - Candidate burn-in fractions: $\\mathcal{F} = \\{0.7, 0.8, 0.9\\}$.\n    - Replicates: $R = 100$.\n    - Trade-off weight: $\\lambda = 1.0$.\n    - Random seed base: $s = 54321$.\n- Case $3$ (well-mixed chain):\n    - Target: standard normal.\n    - Chain length: $N = 4000$.\n    - Proposal standard deviation: $\\sigma = 1.0$.\n    - Initial value: $x_0 = 0.0$.\n    - Credibility level: $1-\\alpha = 0.95$ (use $\\alpha = 0.05$).\n    - Candidate burn-in fractions: $\\mathcal{F} = \\{0.0, 0.25, 0.5\\}$.\n    - Replicates: $R = 100$.\n    - Trade-off weight: $\\lambda = 1.0$.\n    - Random seed base: $s = 67890$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each burn-in fraction reported as a decimal rounded to two digits (e.g., $[0.20,0.70,0.00]$).",
            "solution": "The posed problem requires the determination of an optimal burn-in fraction for samples generated by a Markov Chain Monte Carlo (MCMC) simulation. The optimality criterion is defined as the minimization of a weighted sum of squared bias and variance for the estimators of credible interval endpoints. This analysis explores the fundamental trade-off in MCMC diagnostics: discarding initial samples (burn-in) to reduce bias originating from a non-stationary starting point, at the cost of increasing the variance of estimators due to a reduced effective sample size.\n\nThe foundation of this problem lies in the ergodic theory of Markov chains. For an MCMC simulation targeting a stationary distribution $\\pi(x)$, the distribution of the chain's state, $x_t$, converges to $\\pi(x)$ as the number of steps $t$ approaches infinity. The Random-Walk Metropolis-Hastings (MH) algorithm is employed to construct such a chain. Given the current state $x_{t-1}$, a new state $y$ is proposed from a symmetric proposal distribution, $q(y \\mid x_{t-1})$, which in this case is a normal distribution centered at the current state, $\\mathcal{N}(x_{t-1}, \\sigma^2)$. The target distribution has a probability density function (PDF) proportional to $p(x) \\propto \\exp\\left(-\\frac{x^2}{2}\\right)$, which is the kernel of a standard normal distribution, $\\mathcal{N}(0, 1)$. The proposed state $y$ is accepted with probability\n$$\na(x_{t-1}, y) = \\min\\left\\{1, \\frac{p(y)}{p(x_{t-1})}\\right\\} = \\min\\left\\{1, \\frac{\\exp(-y^2/2)}{\\exp(-x_{t-1}^2/2)}\\right\\} = \\min\\left\\{1, \\exp\\left(-\\frac{y^2 - x_{t-1}^2}{2}\\right)\\right\\}.\n$$\nIf the proposal is accepted, the next state is $x_t = y$; otherwise, it is $x_t = x_{t-1}$.\n\nThe objective is to estimate a symmetric $1-\\alpha$ credible interval for the parameter $x$. For the target distribution $\\mathcal{N}(0, 1)$, the true endpoints of this interval are the quantiles $q_{\\ell} = \\Phi^{-1}(\\alpha/2)$ and $q_{u} = \\Phi^{-1}(1 - \\alpha/2)$, where $\\Phi^{-1}$ is the inverse cumulative distribution function (CDF) of the standard normal distribution. For the specified credibility level of $1-\\alpha = 0.95$, we have $\\alpha=0.05$. The true endpoints are thus $q_{\\ell} = \\Phi^{-1}(0.025) \\approx -1.96$ and $q_{u} = \\Phi^{-1}(0.975) \\approx 1.96$.\n\nThese endpoints are estimated from the MCMC samples. A chain of total length $N$ is generated. To mitigate the bias from the initial state $x_0$, which may be in a region of low probability, the first $b = \\lfloor fN \\rfloor$ samples are discarded, where $f$ is the burn-in fraction. The estimators for the endpoints, denoted $\\hat{q}_{\\ell}(f)$ and $\\hat{q}_{u}(f)$, are the empirical quantiles at levels $\\alpha/2$ and $1-\\alpha/2$ respectively, computed from the remaining $N-b$ samples.\n\nThe quality of these estimators is assessed through their bias and variance. Since these quantities depend on the specific realization of the MCMC chain, we must average over many independent replications. We generate $R$ independent chains. For a given burn-in fraction $f$, we obtain $R$ estimates for each endpoint, $\\{\\hat{q}_{\\ell}^{(r)}(f)\\}_{r=1}^R$ and $\\{\\hat{q}_{u}^{(r)}(f)\\}_{r=1}^R$. The empirical bias and variance are then calculated as specified:\n$$\n\\mathrm{Bias}_{\\ell}(f) = \\left(\\frac{1}{R}\\sum_{r=1}^R \\hat{q}_{\\ell}^{(r)}(f)\\right) - q_{\\ell}\n$$\n$$\n\\mathrm{Var}_{\\ell}(f) = \\frac{1}{R}\\sum_{r=1}^R \\left(\\hat{q}_{\\ell}^{(r)}(f) - \\frac{1}{R}\\sum_{s=1}^R \\hat{q}_{\\ell}^{(s)}(f)\\right)^2\n$$\nand analogously for the upper endpoint estimator $\\hat{q}_{u}$.\n\nThe optimal burn-in fraction $f^\\star$ is chosen to minimize a composite objective function that represents the total Mean Squared Error (MSE) of the endpoint estimators, with a weighting factor $\\lambda$ for the variance terms. The objective function is:\n$$\n\\mathrm{Objective}(f;\\lambda) = \\left(\\mathrm{Bias}_{\\ell}(f)\\right)^2 + \\lambda \\, \\mathrm{Var}_{\\ell}(f) + \\left(\\mathrm{Bias}_{u}(f)\\right)^2 + \\lambda \\, \\mathrm{Var}_{u}(f).\n$$\nThe optimal fraction $f^\\star$ is found by searching over a discrete set of candidate fractions $\\mathcal{F}$:\n$$\nf^\\star = \\arg\\min_{f \\in \\mathcal{F}} \\mathrm{Objective}(f;\\lambda).\n$$\nIncreasing $f$ typically reduces the bias terms, as more non-stationary initial samples are removed. However, this simultaneously reduces the number of samples used for estimation, which generally increases the variance terms. The optimal $f^\\star$ represents the best compromise in this trade-off for the given $\\lambda$.\n\nThe algorithmic procedure is as follows:\n1. For each test case, define the parameters: chain length $N$, proposal standard deviation $\\sigma$, initial value $x_0$, credibility level $\\alpha$, set of candidate fractions $\\mathcal{F}$, number of replicates $R$, trade-off weight $\\lambda$, and random seed base $s$.\n2. Calculate the true quantile endpoints $q_{\\ell}$ and $q_{u}$ using the inverse CDF of the standard normal distribution.\n3. Generate and store $R$ independent MCMC chains, each of length $N$. Each chain $r \\in \\{1, \\dots, R\\}$ is seeded using $s+r-1$ to ensure reproducibility and independence.\n4. For each candidate burn-in fraction $f \\in \\mathcal{F}$:\n    a. Determine the number of burn-in samples, $b = \\lfloor fN \\rfloor$.\n    b. For each of the $R$ chains, take the samples from index $b$ to $N-1$.\n    c. From these post-burn-in samples, compute the empirical quantile estimates $\\hat{q}_{\\ell}^{(r)}(f)$ and $\\hat{q}_{u}^{(r)}(f)$ for each replicate $r$.\n    d. Using the set of $R$ estimates for each endpoint, compute the empirical biases, $\\mathrm{Bias}_{\\ell}(f)$ and $\\mathrm{Bias}_{u}(f)$, and variances, $\\mathrm{Var}_{\\ell}(f)$ and $\\mathrm{Var}_{u}(f)$, according to the provided formulae.\n    e. Evaluate the objective function $\\mathrm{Objective}(f;\\lambda)$.\n5. Identify the fraction $f^\\star \\in \\mathcal{F}$ that yields the minimum value of the objective function. This is the optimal burn-in fraction for the test case.\n6. Repeat for all three test cases and report the resulting optimal fractions.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef run_mh_chain(N, x0, sigma, rng):\n    \"\"\"\n    Generates a single MCMC chain using the Random-Walk Metropolis-Hastings algorithm.\n\n    Args:\n        N (int): The length of the chain.\n        x0 (float): The initial value.\n        sigma (float): The proposal standard deviation.\n        rng (numpy.random.Generator): The random number generator.\n\n    Returns:\n        numpy.ndarray: The generated MCMC chain of length N.\n    \"\"\"\n    chain = np.zeros(N)\n    chain[0] = x0\n    current_x = x0\n    \n    # We use log-probabilities for numerical stability\n    log_alpha_num_term_current = -0.5 * current_x**2\n\n    for t in range(1, N):\n        proposed_y = rng.normal(loc=current_x, scale=sigma)\n        \n        log_alpha_num_term_proposed = -0.5 * proposed_y**2\n        log_acceptance_ratio = log_alpha_num_term_proposed - log_alpha_num_term_current\n\n        if np.log(rng.uniform())  log_acceptance_ratio:\n            current_x = proposed_y\n            log_alpha_num_term_current = log_alpha_num_term_proposed\n        \n        chain[t] = current_x\n        \n    return chain\n\ndef find_optimal_burn_in(N, sigma, x0, alpha, F_set, R, lambd, seed_base):\n    \"\"\"\n    Finds the optimal burn-in fraction for a given set of MCMC parameters.\n\n    Args:\n        N (int): Chain length.\n        sigma (float): Proposal standard deviation.\n        x0 (float): Initial value.\n        alpha (float): Significance level for credible interval.\n        F_set (list): Candidate burn-in fractions.\n        R (int): Number of replicates.\n        lambd (float): Bias-variance trade-off weight.\n        seed_base (int): Base for random seeds.\n\n    Returns:\n        float: The optimal burn-in fraction from F_set.\n    \"\"\"\n    # True quantiles for a standard normal distribution\n    q_lower_true = norm.ppf(alpha / 2.0)\n    q_upper_true = norm.ppf(1.0 - alpha / 2.0)\n\n    # Generate all R chains first\n    all_chains = np.zeros((R, N))\n    for r in range(R):\n        rng = np.random.default_rng(seed_base + r)\n        all_chains[r, :] = run_mh_chain(N, x0, sigma, rng)\n\n    objective_values = []\n    for f in F_set:\n        b = int(np.floor(f * N))\n        \n        # Ensure there are samples left after burn-in\n        if b >= N:\n          # Assign a very large value to objective if no samples remain\n          objective_values.append(np.inf)\n          continue\n          \n        post_burn_in_samples = all_chains[:, b:]\n\n        # Compute empirical quantiles for all R replicates at once\n        q_lower_estimates = np.quantile(post_burn_in_samples, q=alpha / 2.0, axis=1)\n        q_upper_estimates = np.quantile(post_burn_in_samples, q=1.0 - alpha / 2.0, axis=1)\n\n        # Calculate empirical bias\n        mean_q_lower = np.mean(q_lower_estimates)\n        mean_q_upper = np.mean(q_upper_estimates)\n        bias_l = mean_q_lower - q_lower_true\n        bias_u = mean_q_upper - q_upper_true\n\n        # Calculate empirical variance (using population variance formula, ddof=0)\n        var_l = np.var(q_lower_estimates, ddof=0)\n        var_u = np.var(q_upper_estimates, ddof=0)\n        \n        # Calculate the objective function\n        objective = bias_l**2 + lambd * var_l + bias_u**2 + lambd * var_u\n        objective_values.append(objective)\n\n    # Find the fraction that minimizes the objective function\n    min_idx = np.argmin(objective_values)\n    f_star = F_set[min_idx]\n    \n    return f_star\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case 1: Slow convergence, far start\n        {\n            \"N\": 4000, \"sigma\": 0.05, \"x0\": 5.0, \"alpha\": 0.05,\n            \"F_set\": [0.0, 0.1, 0.2, 0.4, 0.6], \"R\": 100, \n            \"lambd\": 1.0, \"seed_base\": 12345\n        },\n        # Case 2: Boundary high burn-in options, same slow chain\n        {\n            \"N\": 4000, \"sigma\": 0.05, \"x0\": 5.0, \"alpha\": 0.05,\n            \"F_set\": [0.7, 0.8, 0.9], \"R\": 100,\n            \"lambd\": 1.0, \"seed_base\": 54321\n        },\n        # Case 3: Well-mixed chain\n        {\n            \"N\": 4000, \"sigma\": 1.0, \"x0\": 0.0, \"alpha\": 0.05,\n            \"F_set\": [0.0, 0.25, 0.5], \"R\": 100,\n            \"lambd\": 1.0, \"seed_base\": 67890\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        f_star = find_optimal_burn_in(\n            N=case[\"N\"],\n            sigma=case[\"sigma\"],\n            x0=case[\"x0\"],\n            alpha=case[\"alpha\"],\n            F_set=case[\"F_set\"],\n            R=case[\"R\"],\n            lambd=case[\"lambd\"],\n            seed_base=case[\"seed_base\"]\n        )\n        results.append(f\"{f_star:.2f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}