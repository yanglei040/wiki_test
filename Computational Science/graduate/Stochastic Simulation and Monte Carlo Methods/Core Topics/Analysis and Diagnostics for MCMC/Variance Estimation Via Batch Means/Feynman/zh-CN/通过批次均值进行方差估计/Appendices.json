{
    "hands_on_practices": [
        {
            "introduction": "在尝试估计一个量之前，我们必须首先从理论上理解它的确切定义。这个练习  提供了一个基础性的实践：推导一阶自回归（AR(1)）过程的精确长程方差，这是模拟输出中一种常见的模型。这个推导出的精确值将作为我们后续仿真研究中的“真实基准”，用以评估我们估计的准确性。",
            "id": "3359811",
            "problem": "来自蒙特卡罗模拟的稳态输出过程被建模为一阶自回归过程 (AR(1))：$X_t=\\phi X_{t-1}+\\epsilon_t$，其中 $|\\phi|  1$ 且 $\\{\\epsilon_t\\}$ 独立同分布，满足 $\\mathbb{E}[\\epsilon_t]=0$ 和 $\\operatorname{Var}(\\epsilon_t)=\\sigma_{\\epsilon}^{2}$。假设过程 $\\{X_t\\}$ 是弱平稳的。在使用批均值法估计稳态均值的方差时，批均值估计量所针对的渐近方差是平稳时间序列样本均值的中心极限定理中出现的长期方差参数。\n\n从自协方差的定义 $\\gamma_k=\\operatorname{Cov}(X_t,X_{t+k})$ 和 AR(1) 递推关系出发，结合弱平稳性以及 $\\epsilon_t$ 与过去状态的独立性，推导所有整数 $k$ 的自协方差函数 $\\gamma_k$ 的闭式表达式。然后，仅使用时间序列理论中关于平稳过程中心极限定理的成熟结果，以闭式形式计算与 $\\{X_t\\}$ 的样本均值相关的长期方差参数 $\\sigma^{2}$，并用 $\\phi$ 和 $\\sigma_{\\epsilon}^{2}$ 表示。\n\n请以 $\\sigma^{2}$ 的单个闭式表达式形式提供您的最终答案。无需进行数值舍入，也不涉及任何单位。",
            "solution": "对问题陈述的有效性进行分析。\n\n## 步骤 1：提取已知条件\n-   **模型**：过程 $\\{X_t\\}$ 是由递推关系 $X_t=\\phi X_{t-1}+\\epsilon_t$ 定义的一阶自回归过程 (AR(1))。\n-   **参数约束**：$|\\phi|  1$。\n-   **噪声过程**：$\\{\\epsilon_t\\}$ 是一个独立同分布 (i.i.d.) 的随机变量序列。\n-   **噪声性质**：$\\mathbb{E}[\\epsilon_t]=0$ 且 $\\operatorname{Var}(\\epsilon_t)=\\sigma_{\\epsilon}^{2}$。\n-   **平稳性**：假设过程 $\\{X_t\\}$ 是弱平稳的。\n-   **独立性**：创新项 $\\epsilon_t$ 与过去的状态 $\\{X_{s} \\text{ for } s  t\\}$ 独立。\n-   **定义**：自协方差函数为 $\\gamma_k=\\operatorname{Cov}(X_t,X_{t+k})$。\n-   **目标 1**：推导所有整数 $k$ 的自协方差函数 $\\gamma_k$ 的闭式表达式。\n-   **目标 2**：计算与 $\\{X_t\\}$ 样本均值相关的长期方差参数 $\\sigma^{2}$，该参数是样本均值中心极限定理中的方差。$\\sigma^2$ 的表达式必须用 $\\phi$ 和 $\\sigma_{\\epsilon}^{2}$ 表示。\n\n## 步骤 2：使用提取的已知条件进行验证\n-   **科学依据**：该问题描述了一个标准的 AR(1) 过程，这是时间序列分析和随机模拟中的一个基石模型。弱平稳性、自协方差和长期方差（与零频率下的谱密度相关）等概念是基本且公认的原理。该分析是研究生水平统计学和计量经济学中的标准内容。\n-   **适定性**：问题陈述精确。条件 $|\\phi|  1$ 保证了 AR(1) 过程的弱平稳性，从而确保均值、方差和自协方差是明确定义且不随时间变化的。这使得 $\\gamma_k$ 和 $\\sigma^2$ 的推导成为一个具有唯一解的、定义明确的数学任务。\n-   **客观性**：问题使用了时间序列理论中形式化、无歧义的术语，并且不含主观或基于观点的陈述。\n\n## 步骤 3：结论与行动\n该问题是时间序列分析中一个标准、适定的练习，因此是有效的。可以开始求解过程。\n\n### 推导自协方差函数 $\\gamma_k$\n\n首先，我们确定过程的均值 $\\mu = \\mathbb{E}[X_t]$。由于弱平稳性，均值是恒定的。对 AR(1) 方程取期望：\n$$\n\\mathbb{E}[X_t] = \\mathbb{E}[\\phi X_{t-1} + \\epsilon_t]\n$$\n$$\n\\mathbb{E}[X_t] = \\phi \\mathbb{E}[X_{t-1}] + \\mathbb{E}[\\epsilon_t]\n$$\n使用 $\\mu = \\mathbb{E}[X_t] = \\mathbb{E}[X_{t-1}]$ 和给定的 $\\mathbb{E}[\\epsilon_t]=0$：\n$$\n\\mu = \\phi \\mu + 0 \\implies \\mu(1-\\phi) = 0\n$$\n由于 $|\\phi|  1$，因此 $1-\\phi \\ne 0$，这意味着过程的均值必须为 $\\mu=0$。\n\n接下来，我们求过程的方差 $\\gamma_0 = \\operatorname{Var}(X_t)$。\n$$\n\\gamma_0 = \\operatorname{Var}(X_t) = \\operatorname{Var}(\\phi X_{t-1} + \\epsilon_t)\n$$\n由于 $X_{t-1}$ 仅依赖于直到时间 $t-1$ 的创新项（即 $\\{\\epsilon_{t-1}, \\epsilon_{t-2}, \\dots\\}$），而 $\\epsilon_t$ 与所有先前的创新项独立，因此 $X_{t-1}$ 和 $\\epsilon_t$ 是独立的。所以，它们的协方差为零。它们和的方差等于它们方差的和：\n$$\n\\operatorname{Var}(X_t) = \\operatorname{Var}(\\phi X_{t-1}) + \\operatorname{Var}(\\epsilon_t) = \\phi^2 \\operatorname{Var}(X_{t-1}) + \\sigma_{\\epsilon}^{2}\n$$\n根据弱平稳性，$\\operatorname{Var}(X_t) = \\operatorname{Var}(X_{t-1}) = \\gamma_0$。将此代入方程：\n$$\n\\gamma_0 = \\phi^2 \\gamma_0 + \\sigma_{\\epsilon}^{2}\n$$\n$$\n\\gamma_0(1-\\phi^2) = \\sigma_{\\epsilon}^{2}\n$$\n给定 $|\\phi|  1$，则 $1-\\phi^2 > 0$，因此我们可以解出 $\\gamma_0$：\n$$\n\\gamma_0 = \\frac{\\sigma_{\\epsilon}^{2}}{1-\\phi^2}\n$$\n现在我们推导当 $k > 0$ 时的自协方差 $\\gamma_k$。根据定义，并利用 $\\mu=0$：\n$$\n\\gamma_k = \\operatorname{Cov}(X_t, X_{t+k}) = \\mathbb{E}[(X_t - \\mathbb{E}[X_t])(X_{t+k} - \\mathbb{E}[X_{t+k}])] = \\mathbb{E}[X_t X_{t+k}]\n$$\n代入 $X_{t+k}$ 的 AR(1) 表达式：\n$$\n\\gamma_k = \\mathbb{E}[X_t (\\phi X_{t+k-1} + \\epsilon_{t+k})] = \\phi \\mathbb{E}[X_t X_{t+k-1}] + \\mathbb{E}[X_t \\epsilon_{t+k}]\n$$\n根据自协方差的定义和平稳性，第一项是 $\\phi \\gamma_{k-1}$。对于第二项，$X_t$ 是创新项 $\\{\\epsilon_s \\text{ for } s \\le t\\}$ 的函数。因为 $k > 0$，所以 $t+k > t$。创新项 $\\epsilon_{t+k}$ 与过程历史 $\\{X_s \\text{ for } s  t+k\\}$（其中包括 $X_t$）是独立的。因此：\n$$\n\\mathbb{E}[X_t \\epsilon_{t+k}] = \\mathbb{E}[X_t] \\mathbb{E}[\\epsilon_{t+k}] = 0 \\cdot 0 = 0\n$$\n这就得出了 AR(1) 过程的 Yule-Walker 方程：\n$$\n\\gamma_k = \\phi \\gamma_{k-1} \\quad \\text{for } k \\ge 1\n$$\n这是一个一阶线性递推关系。其解为 $\\gamma_k = \\phi^k \\gamma_0$，对于 $k \\ge 0$。\n\n对于 $k  0$，令 $k = -m$ 且 $m > 0$。自协方差函数是对称的：\n$$\n\\gamma_k = \\gamma_{-m} = \\operatorname{Cov}(X_t, X_{t-m})\n$$\n根据弱平稳性，协方差仅取决于时滞，因此我们可以将时间索引平移 $m$：\n$$\n\\operatorname{Cov}(X_t, X_{t-m}) = \\operatorname{Cov}(X_{t+m}, X_{(t-m)+m}) = \\operatorname{Cov}(X_{t+m}, X_t) = \\gamma_m\n$$\n因此，$\\gamma_{-m} = \\gamma_m = \\phi^m \\gamma_0$。这意味着对于任意整数 $k$，我们有 $\\gamma_k = \\phi^{|k|} \\gamma_0$。\n代入 $\\gamma_0$ 的表达式，对于所有整数 $k$ 的自协方差函数的闭式表达式为：\n$$\n\\gamma_k = \\phi^{|k|} \\frac{\\sigma_{\\epsilon}^{2}}{1-\\phi^2}\n$$\n\n### 计算长期方差 $\\sigma^2$\n\n对于一个平稳过程（满足适当的混合条件，而平稳 AR(1) 过程满足这些条件）的样本均值 $\\bar{X}_n = \\frac{1}{n} \\sum_{t=1}^n X_t$，中心极限定理指出 $\\sqrt{n}(\\bar{X}_n - \\mu)$ 在分布上收敛于一个均值为 $0$、方差为 $\\sigma^2$ 的正态分布。这个长期方差参数 $\\sigma^2$ 由所有自协方差的总和给出：\n$$\n\\sigma^2 = \\sum_{k=-\\infty}^{\\infty} \\gamma_k\n$$\n代入我们推导出的 $\\gamma_k$ 表达式：\n$$\n\\sigma^2 = \\sum_{k=-\\infty}^{\\infty} \\phi^{|k|} \\frac{\\sigma_{\\epsilon}^{2}}{1-\\phi^2} = \\frac{\\sigma_{\\epsilon}^{2}}{1-\\phi^2} \\sum_{k=-\\infty}^{\\infty} \\phi^{|k|}\n$$\n这个求和可以通过将其分为三部分来计算：\n$$\n\\sum_{k=-\\infty}^{\\infty} \\phi^{|k|} = \\sum_{k=-\\infty}^{-1} \\phi^{|k|} + \\phi^{|0|} + \\sum_{k=1}^{\\infty} \\phi^{|k|}\n$$\n$$\n\\sum_{k=-\\infty}^{\\infty} \\phi^{|k|} = \\sum_{j=1}^{\\infty} \\phi^{j} + 1 + \\sum_{k=1}^{\\infty} \\phi^{k} = 1 + 2\\sum_{k=1}^{\\infty} \\phi^{k}\n$$\n该和是一个几何级数。由于 $|\\phi|  1$，它收敛：\n$$\n\\sum_{k=1}^{\\infty} \\phi^{k} = \\frac{\\phi}{1-\\phi}\n$$\n因此，\n$$\n1 + 2\\sum_{k=1}^{\\infty} \\phi^{k} = 1 + 2\\frac{\\phi}{1-\\phi} = \\frac{1-\\phi+2\\phi}{1-\\phi} = \\frac{1+\\phi}{1-\\phi}\n$$\n现在，将这个结果代回 $\\sigma^2$ 的表达式中：\n$$\n\\sigma^2 = \\frac{\\sigma_{\\epsilon}^{2}}{1-\\phi^2} \\left( \\frac{1+\\phi}{1-\\phi} \\right)\n$$\n使用因式分解 $1-\\phi^2=(1-\\phi)(1+\\phi)$：\n$$\n\\sigma^2 = \\frac{\\sigma_{\\epsilon}^{2}}{(1-\\phi)(1+\\phi)} \\left( \\frac{1+\\phi}{1-\\phi} \\right)\n$$\n消去 $(1+\\phi)$ 项，我们得到长期方差的最终表达式：\n$$\n\\sigma^2 = \\frac{\\sigma_{\\epsilon}^{2}}{(1-\\phi)^2}\n$$\n这就是用 $\\phi$ 和 $\\sigma_{\\epsilon}^{2}$ 表示的长期方差参数的闭式表达式。",
            "answer": "$$\\boxed{\\frac{\\sigma_{\\epsilon}^{2}}{(1-\\phi)^{2}}}$$"
        },
        {
            "introduction": "在确立了理论目标之后，我们现在转向如何从数据中估计它。这个实践  通过一个仿真实验来比较两种主要的分批均值方法：非重叠分批均值（NBM）和重叠分批均值（OBM）。通过研究它们的均方误差（MSE），你将获得关于它们性能的实践洞察，并理解批次大小 $b$ 的关键作用。",
            "id": "3359912",
            "problem": "考虑一个由递归式 $X_t = \\phi X_{t-1} + \\varepsilon_t$ 定义的严格平稳且遍历的一阶自回归过程，记为 $AR(1)$，其中 $\\{ \\varepsilon_t \\}$ 是一个均值为零、方差有限的独立同分布序列，且 $|\\phi|  1$。谱密度 $f(\\omega)$ 是自协方差函数的傅里叶变换，其在零频率处的值 $f(0)$ 通过中心极限定理 (CLT) 和泛函中心极限定理 (FCLT) 决定了样本均值的渐近方差，如下所示：$\\sqrt{n}(\\bar{X}_n - \\mu) \\Rightarrow \\mathcal{N}(0, 2\\pi f(0))$，其中 $\\mu = \\mathbb{E}[X_t]$ 且 $\\bar{X}_n = n^{-1}\\sum_{t=1}^n X_t$。长程方差为 $2\\pi f(0)$。\n\n您的任务是在以下受控研究中，通过经验性比较非重叠批次均值和重叠批次均值两种方法来估计 $f(0)$。您必须从上述基本定义和 CLT/FCLT 陈述出发，推导基于批次均值的有效 $f(0)$ 估计量。然后，您必须实现所推导的估计量，并研究它们的均方误差 (MSE) 作为批次大小 $b$ 的函数，最终在指定的网格内找出经验最优的批次大小。\n\n仿真模型和要求：\n- 将自回归参数固定为 $\\phi = 0.95$。\n- 选择新息方差，使 $X_t$ 的边际方差等于 $1$。\n- 将 $X_0$ 初始化为从 $X_t$ 的平稳边际分布中抽样，以避免启动偏差。\n- 对于每个仿真路径，生成一个长度为 $n$ 的时间序列 $\\{X_t\\}_{t=1}^n$。\n- 对于每个候选批次大小 $b$，计算两个 $f(0)$ 的估计量：\n  - 一个基于大小为 $b$ 的非重叠批次均值。\n  - 一个基于所有长度为 $b$ 的连续窗口的重叠批次均值。\n- 使用 $R$ 次独立的蒙特卡洛复制，将每个估计量和每个 $b$ 的 MSE 近似为相对于 $AR(1)$ 模型真实 $f(0)$ 值的平方误差的经验均值。如果经验最优的 $b$ 出现相同值，必须选择达到最小 MSE 的最小 $b$。\n\n测试套件：\n- 使用以下三组参数。对于每种情况，在指定的批次大小网格上评估两种估计量。\n  - 情况 A：$n = 8192$， $R = 256$，候选 $b \\in \\{8, 16, 32, 64, 128, 256, 512, 1024, 2048, 3072\\}$。\n  - 情况 B：$n = 512$， $R = 512$，候选 $b \\in \\{4, 8, 16, 32, 64, 96, 128, 192, 256\\}$。\n  - 情况 C：$n = 20000$，$R = 128$，候选 $b \\in \\{20, 40, 80, 160, 320, 640, 1280, 2560, 4000, 8000\\}$。\n- 对于非重叠批次均值，仅应用那些在长度 $n$ 内能产生至少两个完整批次的候选 $b$ 值。对于重叠批次均值，仅应用那些在长度 $n$ 内能产生至少两个重叠窗口的候选 $b$ 值。\n- 为保证可复现性，使用一个固定的伪随机数生成器种子，其值等于 $20240519$。\n\n交付成果和输出格式：\n- 您的程序必须：\n  - 从第一性原理出发，推导有效的非重叠和重叠批次均值 $f(0)$ 估计量，实现两者，并计算它们在指定批次大小网格上的经验 MSE。\n  - 对于每种情况，报告使非重叠方法和重叠方法的 MSE 最小化的经验批次大小 $b$，若出现相同值则选择最小的 $b$。\n- 最终输出格式：单行输出，包含一个由三个列表组成的列表，顺序为情况 A、情况 B、情况 C，其中每个内部列表的形式为 $[b_{\\text{nonoverlap}}, b_{\\text{overlap}}]$。例如，输出必须具有确切的形式 $[[b_{A,\\text{non}},b_{A,\\text{over}}],[b_{B,\\text{non}},b_{B,\\text{over}}],[b_{C,\\text{non}},b_{C,\\text{over}}]]$，数字内部的逗号后没有空格。\n\n此问题不涉及物理单位。所有角度（如果出现）都将以弧度为单位。要求的输出是整数。您的代码必须是自包含的，不需要用户输入，并严格按照指定格式产生一行输出。",
            "solution": "该问题要求对一个特定 AR(1) 过程的零频率谱密度 $f(0)$ 的非重叠与重叠批次均值估计量进行经验性比较。比较基于不同批次大小时估计量的均方误差 (MSE)。\n\n首先，我们建立理论基础并推导估计量。问题陈述指出，对于一个平稳时间序列，其样本均值为 $\\bar{X}_n$，中心极限定理 (CLT) 的形式为 $\\sqrt{n}(\\bar{X}_n - \\mu) \\Rightarrow \\mathcal{N}(0, \\sigma^2_{LR})$，其中 $\\sigma^2_{LR} = 2\\pi f(0)$ 是长程方差。这意味着对于大的 $n$，样本均值的方差约为 $\\text{Var}(\\bar{X}_n) \\approx \\frac{\\sigma^2_{LR}}{n}$。核心任务是从单个时间序列实现 $\\{X_t\\}_{t=1}^n$ 中估计 $\\sigma^2_{LR}$（并因此估计 $f(0) = \\sigma^2_{LR}/(2\\pi)$）。\n\n指定的仿真模型是 AR(1) 过程 $X_t = \\phi X_{t-1} + \\varepsilon_t$，其中 $\\phi=0.95$。新息 $\\{\\varepsilon_t\\}$ 是独立同分布的，且 $\\mathbb{E}[\\varepsilon_t] = 0$。对于此过程，均值为 $\\mu = \\mathbb{E}[X_t] = 0$。边际方差为 $\\sigma_X^2 = \\text{Var}(X_t) = \\frac{\\text{Var}(\\varepsilon_t)}{1-\\phi^2}$。问题要求 $\\sigma_X^2=1$，因此我们必须将新息方差设置为 $\\text{Var}(\\varepsilon_t) = \\sigma_\\varepsilon^2 = 1-\\phi^2$。初始状态 $X_0$ 从平稳分布中抽取，假设新息为高斯分布，则该分布为 $\\mathcal{N}(0, \\sigma_X^2) = \\mathcal{N}(0, 1)$。\n\nAR(1) 过程的长程方差 $\\sigma^2_{LR}$ 的真实值由其自协方差之和给出：\n$$\n\\sigma^2_{LR} = \\sum_{h=-\\infty}^{\\infty} \\gamma(h) = \\sum_{h=-\\infty}^{\\infty} \\sigma_X^2 \\phi^{|h|} = \\sigma_X^2 \\frac{1+\\phi}{1-\\phi}\n$$\n当 $\\sigma_X^2 = 1$ 和 $\\phi = 0.95$ 时，真实值为 $\\sigma^2_{LR, \\text{true}} = \\frac{1+0.95}{1-0.95} = \\frac{1.95}{0.05} = 39$。\n对应的 $f(0)$ 真实值为 $f(0)_{\\text{true}} = \\frac{\\sigma^2_{LR, \\text{true}}}{2\\pi} = \\frac{39}{2\\pi}$。我们的估计量将与此值进行评估。\n\n**估计量的推导**\n\n**1. 非重叠批次均值 (NBM) 估计量**\n时间序列 $X_1, \\dots, X_n$ 被划分为 $k = \\lfloor n/b \\rfloor$ 个大小为 $b$ 的连续、不重叠的批次。从 $X_{kb+1}, \\dots, X_n$ 的数据被丢弃。第 $i$ 个批次的均值为：\n$$\nY_i = \\frac{1}{b} \\sum_{j=1}^{b} X_{(i-1)b+j} \\quad \\text{for } i=1, \\dots, k\n$$\n如果批次大小 $b$ 足够大，批次均值 $\\{Y_i\\}_{i=1}^k$ 近似不相关且同分布。根据中心极限定理，每个 $Y_i$ 是一个长度为 $b$ 的序列的样本均值，因此 $\\text{Var}(Y_i) \\approx \\sigma^2_{LR}/b$。我们可以使用批次均值的样本方差来估计此方差。$Y_i$ 总体方差的标准无偏估计量为：\n$$\n\\hat{\\text{Var}}(Y_i) = \\frac{1}{k-1} \\sum_{i=1}^k (Y_i - \\bar{Y}_k)^2, \\quad \\text{where } \\bar{Y}_k = \\frac{1}{k} \\sum_{i=1}^k Y_i\n$$\n由于该量估计的是 $\\sigma^2_{LR}/b$，因此通过乘以 $b$ 可得到 $\\sigma^2_{LR}$ 的一个估计量：\n$$\n\\hat{\\sigma}^2_{NBM} = \\frac{b}{k-1} \\sum_{i=1}^k (Y_i - \\bar{Y}_k)^2\n$$\n因此，$f(0)$ 的 NBM 估计量为 $\\hat{f}(0)_{NBM} = \\frac{\\hat{\\sigma}^2_{NBM}}{2\\pi}$。计算方差至少需要 $k=2$ 个批次。\n\n**2. 重叠批次均值 (OBM) 估计量**\n与不相交的批次不同，OBM 方法使用所有 $m = n-b+1$ 个可能的长度为 $b$ 的连续子序列。第 $i$ 个重叠批次的均值为：\n$$\nZ_i = \\frac{1}{b} \\sum_{j=0}^{b-1} X_{i+j} \\quad \\text{for } i=1, \\dots, m\n$$\n序列 $\\{Z_i\\}_{i=1}^m$ 是高度相关的，因此若不仔细考虑缩放因子，简单应用样本方差公式是不合适的。一个严谨的推导（通常与 Bartlett 谱密度估计量相关联）表明，一个一致且常用的 $\\sigma^2_{LR}$ 估计量为：\n$$\n\\hat{\\sigma}^2_{OBM} = \\frac{nb}{(n-b+1)(n-b)} \\sum_{i=1}^{n-b+1} (Z_i - \\bar{X}_n)^2\n$$\n其中 $\\bar{X}_n = \\frac{1}{n} \\sum_{t=1}^n X_t$ 是整个序列的总均值。此形式包含一个因子 $\\frac{n}{n-b+1}$，它起着偏差校正的作用。$f(0)$ 的 OBM 估计量为 $\\hat{f}(0)_{OBM} = \\frac{\\hat{\\sigma}^2_{OBM}}{2\\pi}$。与 NBM 类似，该估计量需要至少两个批次均值（$m \\ge 2$ 或 $b \\le n-1$）才能明确定义。\n\n**仿真与评估**\n对于每个测试案例（A、B、C），我们执行 $R$ 次独立的蒙特卡洛复制。在每次复制中，生成一个长度为 $n$ 的时间序列。对于每个候选批次大小 $b$，我们计算 $\\hat{f}(0)_{NBM}$ 和 $\\hat{f}(0)_{OBM}$。性能通过均方误差 (MSE) 来衡量，其通过 $R$ 次复制的经验均值来近似：\n$$\n\\text{MSE}(\\hat{f}(0); b) = \\frac{1}{R} \\sum_{r=1}^R \\left(\\hat{f}(0)^{(r)}(b) - f(0)_{\\text{true}}\\right)^2\n$$\n其中 $\\hat{f}(0)^{(r)}(b)$ 是使用批次大小 $b$ 从第 $r$ 次复制中得到的估计值。对于每种估计量类型，我们从给定的网格中找出使此经验 MSE 最小化的批次大小 $b$，若出现相同值则选择最小的 $b$。实现将遵循这些推导出的公式和程序。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the batch means comparison problem by running a Monte Carlo simulation.\n    \"\"\"\n    \n    # --- Simulation Constants ---\n    PHI = 0.95\n    SEED = 20240519\n\n    # --- Test Cases ---\n    test_cases = [\n        # Case A\n        {'n': 8192, 'R': 256, 'b_grid': [8, 16, 32, 64, 128, 256, 512, 1024, 2048, 3072]},\n        # Case B\n        {'n': 512, 'R': 512, 'b_grid': [4, 8, 16, 32, 64, 96, 128, 192, 256]},\n        # Case C\n        {'n': 20000, 'R': 128, 'b_grid': [20, 40, 80, 160, 320, 640, 1280, 2560, 4000, 8000]},\n    ]\n\n    # --- Helper Functions ---\n    \n    def generate_ar1_series(n, phi, rng):\n        \"\"\"Generates a stationary AR(1) series of length n with Var(X)=1.\"\"\"\n        sigma_eps = np.sqrt(1 - phi**2)\n        innovations = rng.normal(loc=0, scale=sigma_eps, size=n)\n        x = np.zeros(n)\n        x0 = rng.normal(loc=0, scale=1.0)\n        \n        x[0] = phi * x0 + innovations[0]\n        for t in range(1, n):\n            x[t] = phi * x[t-1] + innovations[t]\n        return x\n\n    def estimate_f0_nbm(x, b):\n        \"\"\"Estimates f(0) using non-overlapping batch means.\"\"\"\n        n = len(x)\n        k = n // b\n        if k  2:\n            return np.nan\n        \n        x_trunc = x[:k * b]\n        batch_means = x_trunc.reshape((k, b)).mean(axis=1)\n        \n        var_batch_means = batch_means.var(ddof=1)\n        sigma_sq_lr_hat = b * var_batch_means\n        \n        f0_hat = sigma_sq_lr_hat / (2 * np.pi)\n        return f0_hat\n\n    def estimate_f0_obm(x, b):\n        \"\"\"Estimates f(0) using overlapping batch means.\"\"\"\n        n = len(x)\n        m = n - b + 1\n        if m  2:\n            return np.nan\n\n        batch_sums = np.convolve(x, np.ones(b), mode='valid')\n        batch_means = batch_sums / b\n        \n        x_bar = x.mean()\n        \n        sum_sq_dev = np.sum((batch_means - x_bar)**2)\n        \n        # This form of the estimator is from Flegal  Jones (2010)\n        sigma_sq_lr_hat = (n * b) / (m * (m - 1)) * sum_sq_dev\n        \n        f0_hat = sigma_sq_lr_hat / (2 * np.pi)\n        return f0_hat\n\n    # --- Main Logic ---\n    \n    final_results = []\n    rng = np.random.default_rng(SEED)\n    f0_true = (1 / (2 * np.pi)) * (1 + PHI) / (1 - PHI)\n\n    for case in test_cases:\n        n, R, b_grid = case['n'], case['R'], case['b_grid']\n        \n        sse_nbm = {b: 0.0 for b in b_grid}\n        sse_obm = {b: 0.0 for b in b_grid}\n        \n        for _ in range(R):\n            x_series = generate_ar1_series(n, PHI, rng)\n            \n            for b in b_grid:\n                # NBM estimator\n                if n // b >= 2:\n                    f0_hat_nbm = estimate_f0_nbm(x_series, b)\n                    if not np.isnan(f0_hat_nbm):\n                       sse_nbm[b] += (f0_hat_nbm - f0_true)**2\n                \n                # OBM estimator\n                if n - b + 1 >= 2:\n                    f0_hat_obm = estimate_f0_obm(x_series, b)\n                    if not np.isnan(f0_hat_obm):\n                        sse_obm[b] += (f0_hat_obm - f0_true)**2\n        \n        # Find optimal batch size for NBM\n        min_mse_nbm = float('inf')\n        opt_b_nbm = -1\n        for b in b_grid:\n            if n // b >= 2:\n                mse = sse_nbm[b] / R\n                if mse  min_mse_nbm:\n                    min_mse_nbm = mse\n                    opt_b_nbm = b\n        \n        # Find optimal batch size for OBM\n        min_mse_obm = float('inf')\n        opt_b_obm = -1\n        for b in b_grid:\n            if n - b + 1 >= 2:\n                mse = sse_obm[b] / R\n                if mse  min_mse_obm:\n                    min_mse_obm = mse\n                    opt_b_obm = b\n                    \n        final_results.append([opt_b_nbm, opt_b_obm])\n\n    # Format and print the final output as specified\n    inner_lists_str = [f\"[{r[0]},{r[1]}]\" for r in final_results]\n    print(f\"[{','.join(inner_lists_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "批次大小的选择至关重要，它涉及偏差和方差之间的权衡。这个练习  提供了一种系统性的方法来探索这种权衡，它通过一个指数 $\\alpha$ 将批次数与总样本量关联起来。你将通过经验确定最优指数，以最小化具有不同自相关水平过程的均方误差，从而更深入地理解如何调整分批均值方法。",
            "id": "3359849",
            "problem": "要求您设计并执行一项关于平稳一阶自回归过程中使用批均值法进行方差估计的实证研究。从以下基础理论开始：如果 $\\{X_t\\}_{t \\ge 1}$ 是一个具有有限二阶矩的平稳几何遍历马尔可夫链，那么对于样本均值 $\\bar{X}_n = \\frac{1}{n} \\sum_{t=1}^n X_t$，马尔可夫链中心极限定理 (CLT) 成立，即\n$$\n\\sqrt{n}\\left(\\bar{X}_n - \\mathbb{E}[X_1]\\right) \\Rightarrow \\mathcal{N}\\left(0, \\sigma_{\\mathrm{LRV}}^2\\right),\n$$\n其中长程方差为\n$$\n\\sigma_{\\mathrm{LRV}}^2 = \\gamma_0 + 2 \\sum_{k=1}^\\infty \\gamma_k, \\quad \\gamma_k = \\mathrm{Cov}(X_1, X_{1+k}).\n$$\n对于大的 $n$，样本均值的方差满足 $\\mathrm{Var}(\\bar{X}_n) \\approx \\sigma_{\\mathrm{LRV}}^2 / n$。批均值法通过将数据划分为等长的批次、计算批次均值，并利用它们的变异性来推断 $\\sigma_{\\mathrm{LRV}}^2$，从而估计 $\\mathrm{Var}(\\bar{X}_n)$。\n\n考虑由下式定义的一阶自回归过程\n$$\nX_{t+1} = \\lambda X_t + \\varepsilon_t, \\quad \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0, 1 - \\lambda^2),\n$$\n该过程从平稳状态开始，即 $X_1 \\sim \\mathcal{N}(0,1)$，因此对于所有 $t \\ge 1$，都有 $\\mathrm{Var}(X_t) = 1$。对于此过程，$\\gamma_k = \\lambda^{|k|}$，且长程方差等于\n$$\n\\sigma_{\\mathrm{LRV}}^2 = \\frac{1 + \\lambda}{1 - \\lambda}.\n$$\n\n您的任务是实现一个完整的程序，使用批均值法执行以下实证实验：\n\n- 对于固定的总长度 $n$ 和一个指数网格 $\\alpha \\in (0,1)$，令批数为 $b = \\lfloor n^\\alpha \\rfloor$。令批大小为 $m = \\lfloor n / b \\rfloor$；丢弃任何剩余的观测值，以使有效样本大小为 $n_{\\mathrm{eff}} = b \\cdot m$。从前 $n_{\\mathrm{eff}}$ 个观测值中形成 $b$ 个不重叠的连续批次，每个批次大小为 $m$。使用这些批次均值生成一个基于批均值的 $\\mathrm{Var}(\\bar{X}_{n_{\\mathrm{eff}}})$ 估计器。如果 $b  2$ 或 $m  2$，则认为该 $\\alpha$ 的估计器未定义，并将其排除在考虑范围之外。\n\n- 对于每个 $\\alpha$ 和每个混合率 $\\lambda \\in \\{0.5, 0.9, 0.99\\}$，通过蒙特卡洛方法（使用 $R$ 次独立重复实验）估计批均值估计器对 $\\mathrm{Var}(\\bar{X}_{n_{\\mathrm{eff}}})$ 的均方误差 (MSE)，并将其与理论真值 $\\sigma_{\\mathrm{LRV}}^2 / n_{\\mathrm{eff}}$ 进行比较，其中 $\\sigma_{\\mathrm{LRV}}^2 = (1+\\lambda)/(1-\\lambda)$。为了可复现性，使用单个固定的伪随机种子，并在不同的 $\\alpha$ 值之间重用相同的模拟路径以进行公平比较。\n\n- 对于每个 $(n,\\lambda)$，扫描 $\\alpha$ 的网格，并找出使经验 MSE 最小化的最优指数 $\\alpha^\\star$。如果多个 $\\alpha$ 在浮点数相等的情况下达到相同的最小值，请选择其中最小的 $\\alpha$。\n\n为确保科学真实性和可比性，需遵循以下实现细节：\n\n- 使用上述一阶自回归动态模型，初始状态从平稳分布中抽取，以确保从一开始就保持平稳性。使用方差为 $1-\\lambda^2$ 的独立正态噪声，以使 $\\mathrm{Var}(X_t)=1$。\n\n- 蒙特卡洛研究必须对所有组合使用一个公共的指数网格 $\\mathcal{A}$ 和相同数量的重复实验 $R$。使用网格\n$$\n\\mathcal{A} = \\{0.10, 0.15, 0.20, \\dots, 0.90\\}.\n$$\n\n- 使用 $R = 200$ 次重复实验，并为伪随机数生成器设置固定种子 $12345$。\n\n- 对于批均值估计器，从序列的开头构建不重叠的批次，并丢弃任何余数，以确保所有使用的批次具有相等的批次大小。\n\n- 对于每个保留的 $\\alpha$，估计批均值估计器相对于理论目标 $\\sigma_{\\mathrm{LRV}}^2 / n_{\\mathrm{eff}}$ 的 MSE。\n\n测试套件和要求的输出：\n\n为以下三个测试用例运行您的程序，每个测试用例包含一个总长度 $n$ 和三个混合率 $\\lambda \\in \\{0.5, 0.9, 0.99\\}$：\n\n- 测试用例 1: $n = 2000$。\n- 测试用例 2: $n = 4096$。\n- 测试用例 3: $n = 8192$。\n\n对于每个测试用例和每个 $\\lambda$，报告来自网格 $\\mathcal{A}$ 的最优 MSE 指数 $\\alpha^\\star$。最终输出必须是单行，包含一个列表，内含9个数字，对应于按以下顺序选择的 $\\alpha^\\star$：测试用例 1，$\\lambda = 0.5$；测试用例 1，$\\lambda = 0.9$；测试用例 1，$\\lambda = 0.99$；然后是测试用例 2，$\\lambda = 0.5$；测试用例 2，$\\lambda = 0.9$；测试用例 2，$\\lambda = 0.99$；最后是测试用例 3，$\\lambda = 0.5$；测试用例 3，$\\lambda = 0.9$；测试用例 3，$\\lambda = 0.99$。将每个 $\\alpha^\\star$ 表示为四舍五入到两位小数的十进制数。\n\n最终输出格式：\n\n- 您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表形式的结果（例如，\"[0.35,0.50,0.65,0.30,0.45,0.60,0.25,0.40,0.55]\"）。",
            "solution": "该问题要求进行一项实证研究，以确定当批均值方差估计器应用于平稳一阶自回归过程 AR(1) 时，最优的分批策略。最优性准则是最小化该方差估计器的均方误差 (MSE)。问题的核心在于批数 $b$ 和批大小 $m$ 选择中固有的权衡。\n\n### 1. 理论基础\n\n我们从指定的一阶自回归过程 AR(1) 开始：\n$$\nX_{t+1} = \\lambda X_t + \\varepsilon_t\n$$\n其中新息 $\\varepsilon_t$ 是独立同分布 (i.i.d.) 于 $\\mathcal{N}(0, 1 - \\lambda^2)$。该过程从其平稳分布 $X_1 \\sim \\mathcal{N}(0, 1)$ 开始，确保时间序列 $\\{X_t\\}$ 是平稳的，且对于所有 $t \\ge 1$，$\\mathbb{E}[X_t] = 0$ 和 $\\mathrm{Var}(X_t) = 1$。\n\n对于此过程，相依序列的中心极限定理 (CLT) 成立。对于样本均值 $\\bar{X}_n = \\frac{1}{n}\\sum_{t=1}^n X_t$，我们有：\n$$\n\\sqrt{n} \\bar{X}_n \\Rightarrow \\mathcal{N}(0, \\sigma_{\\mathrm{LRV}}^2)\n$$\n其中 $\\Rightarrow$ 表示依分布收敛。长程方差 $\\sigma_{\\mathrm{LRV}}^2$ 由所有自协方差之和给出：\n$$\n\\sigma_{\\mathrm{LRV}}^2 = \\sum_{k=-\\infty}^{\\infty} \\gamma_k = \\gamma_0 + 2 \\sum_{k=1}^\\infty \\gamma_k\n$$\n其中 $\\gamma_k = \\mathrm{Cov}(X_t, X_{t+k})$。对于给定的一阶自回归过程，$\\gamma_k = \\lambda^{|k|}$，这产生了以下解析表达式：\n$$\n\\sigma_{\\mathrm{LRV}}^2 = 1 + 2 \\sum_{k=1}^\\infty \\lambda^k = 1 + 2 \\frac{\\lambda}{1-\\lambda} = \\frac{1-\\lambda+2\\lambda}{1-\\lambda} = \\frac{1+\\lambda}{1-\\lambda}\n$$\n对于大样本量 $n$，样本均值的方差近似为 $\\mathrm{Var}(\\bar{X}_n) \\approx \\sigma_{\\mathrm{LRV}}^2/n$。我们的目标是估计这个量。\n\n### 2. 批均值估计器\n\n批均值法为 $\\mathrm{Var}(\\bar{X}_n)$ 提供了一个估计。其过程如下：\n1.  对总长度为 $n$ 的时间序列进行划分。批数 $b$ 由一个指数 $\\alpha \\in (0,1)$ 决定，即 $b = \\lfloor n^\\alpha \\rfloor$。\n2.  批大小为 $m = \\lfloor n/b \\rfloor$。任何剩余的数据点都将被丢弃，从而得到有效样本大小 $n_{\\mathrm{eff}} = b \\cdot m$。\n3.  将数据 $X_1, \\dots, X_{n_{\\mathrm{eff}}}$ 分为 $b$ 个大小为 $m$ 的不重叠批次。第 $j$ 个批次的均值计算如下：\n    $$\n    Y_j = \\frac{1}{m} \\sum_{i=1}^{m} X_{(j-1)m+i}, \\quad j = 1, \\dots, b\n    $$\n4.  如果批大小 $m$ 足够大，批均值 $\\{Y_j\\}_{j=1}^b$ 近似不相关，并且每个 $Y_j$ 的方差约为 $\\mathrm{Var}(Y_j) \\approx \\sigma_{\\mathrm{LRV}}^2/m$。\n5.  将批均值视为近似独立同分布的观测值，我们可以使用样本方差来估计它们的方差：\n    $$\n    S_Y^2 = \\frac{1}{b-1} \\sum_{j=1}^b (Y_j - \\bar{Y})^2, \\quad \\text{其中} \\quad \\bar{Y} = \\frac{1}{b}\\sum_{j=1}^b Y_j = \\bar{X}_{n_{\\mathrm{eff}}}\n    $$\n    $S_Y^2$ 是 $\\sigma_{\\mathrm{LRV}}^2 / m$ 的一个估计量。\n6.  因此，长程方差的一个估计量是 $\\hat{\\sigma}_{\\mathrm{LRV}}^2 = m \\cdot S_Y^2$。\n7.  最后，样本均值方差 $\\mathrm{Var}(\\bar{X}_{n_{\\mathrm{eff}}})$ 的批均值估计器为：\n    $$\n    \\widehat{\\mathrm{Var}}(\\bar{X}_{n_{\\mathrm{eff}}}) = \\frac{\\hat{\\sigma}_{\\mathrm{LRV}}^2}{n_{\\mathrm{eff}}} = \\frac{m \\cdot S_Y^2}{b \\cdot m} = \\frac{S_Y^2}{b}\n    $$\n\n### 3. 实验设计与 MSE 估计\n\n$\\alpha$ 的选择决定了一个关键的偏差-方差权衡：\n- **大的 $\\alpha$**：导致批数 $b$ 大而批大小 $m$ 小。批均值不相关的假设会失效，因为相邻批次之间的相关性变得显著。这会在估计器中引入负偏差，即 $\\mathbb{E}[S_Y^2]  \\sigma_{\\mathrm{LRV}}^2/m$。\n- **小的 $\\alpha$**：导致批数 $b$ 小而批大小 $m$ 大。批均值更接近于不相关，从而减少了偏差。然而，从小样本（大小为 $b$）中估计方差会导致估计器 $S_Y^2$ 的方差较高。\n\n最优的 $\\alpha^\\star$ 是最小化均方误差 (MSE) 的那一个：\n$$\n\\mathrm{MSE}(\\alpha) = \\mathbb{E}\\left[ \\left( \\widehat{\\mathrm{Var}}(\\bar{X}_{n_{\\mathrm{eff}}}) - \\frac{\\sigma_{\\mathrm{LRV}}^2}{n_{\\mathrm{eff}}} \\right)^2 \\right]\n$$\n这个期望值在解析上难以计算，因此我们通过蒙特卡洛模拟来估计它。对于一个给定的 $(n, \\lambda)$ 对：\n1.  我们生成 $R$ 次独立的 AR(1) 过程重复实验（路径），每个路径长度为 $n$。\n2.  对于每个路径和网格 $\\mathcal{A}$ 中的每个候选 $\\alpha$，我们计算批均值估计 $\\widehat{\\mathrm{Var}}_r(\\bar{X}_{n_{\\mathrm{eff}}})$，其中 $r \\in \\{1, \\dots, R\\}$。\n3.  然后，给定 $\\alpha$ 的 MSE 被估计为 $R$ 次重复实验中平方误差的样本均值：\n    $$\n    \\widehat{\\mathrm{MSE}}(\\alpha) = \\frac{1}{R} \\sum_{r=1}^R \\left( \\widehat{\\mathrm{Var}}_r(\\bar{X}_{n_{\\mathrm{eff}}}) - \\frac{\\sigma_{\\mathrm{LRV}}^2}{n_{\\mathrm{eff}}} \\right)^2\n    $$\n    其中 $\\sigma_{\\mathrm{LRV}}^2/n_{\\mathrm{eff}}$ 是已知的理论目标值。\n4.  最优指数 $\\alpha^\\star$ 是通过在 $\\mathcal{A}$ 上进行网格搜索找到的，以找到最小化 $\\widehat{\\mathrm{MSE}}(\\alpha)$ 的 $\\alpha$。\n\n### 4. 实现策略\n\n该模拟使用 Python 的 `numpy` 库实现，以进行高效的向量化计算。\n- 使用固定种子初始化一个伪随机数生成器，以确保整个实验的可复现性。\n- 对于每个 $(n, \\lambda)$ 测试用例，生成 $R=200$ 条路径。为确保公平比较，这同一组路径用于评估网格 $\\mathcal{A} = \\{0.10, 0.15, \\dots, 0.90\\}$ 中的所有 $\\alpha$ 值。\n- $R$ 条路径的模拟是向量化的：在每个时间步 $t$，所有 $R$ 条路径的 $X_{t+1}$ 值被同时计算。\n- 类似地，对于给定的 $\\alpha$，批均值估计器的计算在 $R$ 次重复实验中是向量化的。将 $R$ 条路径切片到长度 $n_{\\mathrm{eff}}$，重塑为形状为 $(R, b, m)$ 的三维数组，并沿适当的轴计算批均值及其样本方差。这样可以得到 $R$ 个 $\\mathrm{Var}(\\bar{X}_{n_{\\mathrm{eff}}})$ 的估计值。\n- 然后，估计的 MSE 是这 $R$ 个估计值与理论目标值之间差的平方的简单均值。\n- 程序遍历指定的测试用例，为每个用例找到 $\\alpha^\\star$，并按要求格式化结果。平局决胜规则（在 MSE 相等的情况下选择最小的 $\\alpha$）通过按升序迭代 $\\alpha$ 并仅在有严格改进时更新最优值来自然处理。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs an empirical study of the batch means variance estimator for an AR(1) process\n    to find the MSE-optimal batching exponent alpha.\n    \"\"\"\n    \n    # Define the experiment and test case parameters from the problem statement.\n    ns = [2000, 4096, 8192]\n    lambdas = [0.5, 0.9, 0.99]\n    alphas = np.round(np.arange(0.10, 0.91, 0.05), 2) # Grid A = {0.10, 0.15, ..., 0.90}\n    R = 200\n    seed = 12345\n    \n    # Initialize a single random number generator for reproducibility.\n    rng = np.random.default_rng(seed)\n    \n    # The problem specifies the order of test cases.\n    test_cases = [(n, lam) for n in ns for lam in lambdas]\n    \n    results = []\n    \n    # Iterate through each test case (n, lambda).\n    for case in test_cases:\n        n, lam = case\n        \n        # --- Core logic for one (n, lam) pair ---\n        \n        # 1. Generate R independent paths of the stationary AR(1) process.\n        # This is done once per (n, lam) and reused for all alpha values.\n        paths = np.zeros((R, n))\n        noise_std = np.sqrt(1 - lam**2)\n        \n        # Vectorized generation of initial states and subsequent steps.\n        paths[:, 0] = rng.normal(loc=0.0, scale=1.0, size=R)\n        for t in range(n - 1):\n            noise = rng.normal(loc=0.0, scale=noise_std, size=R)\n            paths[:, t + 1] = lam * paths[:, t] + noise\n\n        # 2. Calculate the theoretical long-run variance.\n        sigma2_lrv = (1 + lam) / (1 - lam)\n\n        min_mse = float('inf')\n        best_alpha = -1.0\n        \n        # 3. Grid search over alpha to find the one that minimizes MSE.\n        for alpha in alphas:\n            # Determine batching parameters.\n            b = int(np.floor(n**alpha))\n            \n            # Per problem spec, estimator must have at least 2 batches and batch size of at least 2.\n            if b  2:\n                continue\n            \n            m = int(np.floor(n / b))\n            if m  2:\n                continue\n            \n            n_eff = b * m\n\n            # Vectorized computation of the batch means estimator across all R replicates.\n            paths_eff = paths[:, :n_eff]\n            batches = paths_eff.reshape((R, b, m))\n            batch_means = np.mean(batches, axis=2)\n            \n            # Sample variance of batch means for each replicate (ddof=1).\n            var_of_batch_means = np.var(batch_means, axis=1, ddof=1)\n            \n            # The batch means estimator for Var(X_bar_n_eff) is S_Y^2 / b.\n            var_x_bar_hat = var_of_batch_means / b\n\n            # 4. Estimate the MSE of the estimator.\n            target_variance = sigma2_lrv / n_eff\n            errors_sq = (var_x_bar_hat - target_variance)**2\n            mse = np.mean(errors_sq)\n\n            # 5. Update the best alpha.\n            # Tie-breaking (choose smallest alpha) is handled by using ''\n            # and iterating through alphas in increasing order.\n            if mse  min_mse:\n                min_mse = mse\n                best_alpha = alpha\n        \n        # Append the formatted result for the current case.\n        results.append(f\"{best_alpha:.2f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}