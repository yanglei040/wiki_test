{
    "hands_on_practices": [
        {
            "introduction": "一个好的估计量不仅要能捕捉我们感兴趣的量，其自身的统计特性（如偏差和方差）也必须被充分理解。本练习将引导我们进行一次基础但至关重要的理论推导。通过在最简单的独立同分布（IID）数据假设下，我们将精确计算重叠批次均值（OBM）估计量的期望值，从而揭示其内在的有限样本偏差，并推导出消除该偏差所需的校正因子。这个过程不仅能加深我们对OBM方法基本原理的理解，也为处理更复杂的相依数据序列打下坚实的数学基础。",
            "id": "3326195",
            "problem": "考虑一个平稳的独立同分布 (IID) 序列 $\\{X_{t}\\}_{t=1}^{n}$，其满足 $\\mathbb{E}[X_{t}]=\\mu$ 和 $\\operatorname{Var}(X_{t})=\\sigma^{2}\\in(0,\\infty)$。令样本均值为 $\\bar{X}_{n}=(1/n)\\sum_{t=1}^{n}X_{t}$。对于满足 $1\\leq b\\leq n$ 的选定批次长度 $b$，定义 $m=n-b+1$ 个重叠批次及其批次均值为\n$$\nY_{j}=\\frac{1}{b}\\sum_{t=j}^{j+b-1}X_{t},\\quad j=1,2,\\dots,m.\n$$\n时间平均（长程）方差的重叠批次均值 (OBM) 估计量（在独立同分布抽样下，其值等于 $\\sigma^{2}$）定义为\n$$\n\\hat{\\sigma}^{2}_{\\text{OBM}}=\\frac{b}{m}\\sum_{j=1}^{m}\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}.\n$$\n从独立同分布随机变量的基本性质出发，推导精确的有限样本期望 $\\mathbb{E}[\\hat{\\sigma}^{2}_{\\text{OBM}}]$，将其表示为 $n$，$b$ 和 $\\sigma^{2}$ 的函数，过程中不使用渐近近似。然后，确定一个乘法修正因子 $c(n,b)$，使得 $c(n,b)\\,\\hat{\\sigma}^{2}_{\\text{OBM}}$ 是 $\\sigma^{2}$ 的无偏估计。你的最终答案应仅为 $c(n,b)$ 的闭式解析表达式。无需四舍五入。",
            "solution": "首先根据指定标准验证问题。\n\n### 步骤 1：提取已知条件\n-   一个平稳的独立同分布 (IID) 序列 $\\{X_{t}\\}_{t=1}^{n}$。\n-   $\\mathbb{E}[X_{t}]=\\mu$。\n-   $\\operatorname{Var}(X_{t})=\\sigma^{2}\\in(0,\\infty)$。\n-   样本均值：$\\bar{X}_{n}=(1/n)\\sum_{t=1}^{n}X_{t}$。\n-   批次长度：$b$，满足 $1\\leq b\\leq n$。\n-   重叠批次数：$m=n-b+1$。\n-   批次均值：$Y_{j}=\\frac{1}{b}\\sum_{t=j}^{j+b-1}X_{t}$，对于 $j=1,2,\\dots,m$。\n-   重叠批次均值 (OBM) 估计量：$\\hat{\\sigma}^{2}_{\\text{OBM}}=\\frac{b}{m}\\sum_{j=1}^{m}\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n-   **科学性**：该问题是数理统计中的一个标准练习，特别是在蒙特卡洛模拟中方差估计的背景下。所有术语和概念（IID 序列、批次均值、方差估计量）在该领域都是公认的。\n-   **适定性**：该问题要求推导一个期望值和一个由此产生的修正因子。问题设定清晰，并为得到唯一的解析解提供了路径。\n-   **客观性**：该问题以精确的数学语言陈述，没有任何主观或模糊的术语。\n-   **完整性与一致性**：该问题是自洽的。所有必要的定义和假设（IID 性质、有限非零方差）都已提供。不存在矛盾之处。\n\n### 步骤 3：结论与行动\n问题有效。将提供一个完整的、有理据的解答。\n\n### 解题推导\n我们的目标是求出 OBM 估计量的精确有限样本期望 $\\mathbb{E}[\\hat{\\sigma}^{2}_{\\text{OBM}}]$，然后确定使该估计量成为无偏估计的修正因子 $c(n,b)$。\n\nOBM 方差估计量由下式给出：\n$$\n\\hat{\\sigma}^{2}_{\\text{OBM}}=\\frac{b}{m}\\sum_{j=1}^{m}\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}\n$$\n根据期望的线性性质，我们有：\n$$\n\\mathbb{E}[\\hat{\\sigma}^{2}_{\\text{OBM}}] = \\frac{b}{m}\\sum_{j=1}^{m}\\mathbb{E}\\left[\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}\\right]\n$$\n我们来分析求和式内的期望项。首先，我们计算批次均值 $Y_j$ 和总样本均值 $\\bar{X}_n$ 的期望值。\n对于任意批次均值 $Y_j$：\n$$\n\\mathbb{E}[Y_{j}] = \\mathbb{E}\\left[\\frac{1}{b}\\sum_{t=j}^{j+b-1}X_{t}\\right] = \\frac{1}{b}\\sum_{t=j}^{j+b-1}\\mathbb{E}[X_{t}] = \\frac{1}{b}\\sum_{t=j}^{j+b-1}\\mu = \\frac{b\\mu}{b} = \\mu\n$$\n对于总样本均值 $\\bar{X}_n$：\n$$\n\\mathbb{E}[\\bar{X}_{n}] = \\mathbb{E}\\left[\\frac{1}{n}\\sum_{t=1}^{n}X_{t}\\right] = \\frac{1}{n}\\sum_{t=1}^{n}\\mathbb{E}[X_{t}] = \\frac{1}{n}\\sum_{t=1}^{n}\\mu = \\frac{n\\mu}{n} = \\mu\n$$\n因此，差值的期望为零：\n$$\n\\mathbb{E}[Y_{j}-\\bar{X}_{n}] = \\mathbb{E}[Y_{j}]-\\mathbb{E}[\\bar{X}_{n}] = \\mu - \\mu = 0\n$$\n这简化了求和式中的项，因为它的期望现在就是它的方差：\n$$\n\\mathbb{E}\\left[\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}\\right] = \\operatorname{Var}(Y_{j}-\\bar{X}_{n}) + (\\mathbb{E}[Y_j-\\bar{X}_n])^2 = \\operatorname{Var}(Y_{j}-\\bar{X}_{n})\n$$\n使用差值方差的性质，我们有：\n$$\n\\operatorname{Var}(Y_{j}-\\bar{X}_{n}) = \\operatorname{Var}(Y_{j}) + \\operatorname{Var}(\\bar{X}_{n}) - 2\\operatorname{Cov}(Y_{j}, \\bar{X}_{n})\n$$\n我们现在计算这三项。由于 $\\{X_t\\}$ 是一个 IID 序列，且 $\\operatorname{Var}(X_t) = \\sigma^2$：\n1.  批次均值 $Y_j$ 的方差：\n    $$\n    \\operatorname{Var}(Y_{j}) = \\operatorname{Var}\\left(\\frac{1}{b}\\sum_{t=j}^{j+b-1}X_{t}\\right) = \\frac{1}{b^2}\\sum_{t=j}^{j+b-1}\\operatorname{Var}(X_{t}) = \\frac{1}{b^2}(b\\sigma^2) = \\frac{\\sigma^2}{b}\n    $$\n2.  总样本均值 $\\bar{X}_n$ 的方差：\n    $$\n    \\operatorname{Var}(\\bar{X}_{n}) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{t=1}^{n}X_{t}\\right) = \\frac{1}{n^2}\\sum_{t=1}^{n}\\operatorname{Var}(X_{t}) = \\frac{1}{n^2}(n\\sigma^2) = \\frac{\\sigma^2}{n}\n    $$\n3.  批次均值 $Y_j$ 与总样本均值 $\\bar{X}_n$ 之间的协方差。我们使用 IID 变量的性质 $\\operatorname{Cov}(X_t, X_k) = \\sigma^2\\delta_{tk}$，其中 $\\delta_{tk}$ 是克罗内克 delta。\n    $$\n    \\operatorname{Cov}(Y_{j}, \\bar{X}_{n}) = \\operatorname{Cov}\\left(\\frac{1}{b}\\sum_{t=j}^{j+b-1}X_{t}, \\frac{1}{n}\\sum_{k=1}^{n}X_{k}\\right) = \\frac{1}{bn}\\sum_{t=j}^{j+b-1}\\sum_{k=1}^{n}\\operatorname{Cov}(X_{t}, X_{k})\n    $$\n    协方差项仅在 $k=t$ 时非零。$t$ 的索引为 $\\{j, j+1, \\dots, j+b-1\\}$，它是 $k$ 的索引 $\\{1, 2, \\dots, n\\}$ 的子集。因此，我们对 $k=t$ 的 $b$ 个实例求和：\n    $$\n    \\operatorname{Cov}(Y_{j}, \\bar{X}_{n}) = \\frac{1}{bn}\\sum_{t=j}^{j+b-1}\\operatorname{Var}(X_{t}) = \\frac{1}{bn}(b\\sigma^2) = \\frac{\\sigma^2}{n}\n    $$\n注意到 $\\operatorname{Var}(Y_j)$、$\\operatorname{Var}(\\bar{X}_n)$ 和 $\\operatorname{Cov}(Y_j, \\bar{X}_n)$ 都与批次索引 $j$ 无关。\n\n现在，我们将这些结果代入 $\\operatorname{Var}(Y_{j}-\\bar{X}_{n})$ 的表达式中：\n$$\n\\operatorname{Var}(Y_{j}-\\bar{X}_{n}) = \\frac{\\sigma^2}{b} + \\frac{\\sigma^2}{n} - 2\\frac{\\sigma^2}{n} = \\frac{\\sigma^2}{b} - \\frac{\\sigma^2}{n} = \\sigma^2\\left(\\frac{1}{b} - \\frac{1}{n}\\right)\n$$\n由于该项对于所有 $j=1, \\dots, m$ 都是常数，求和变得很简单：\n$$\n\\sum_{j=1}^{m}\\mathbb{E}\\left[\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}\\right] = \\sum_{j=1}^{m}\\sigma^2\\left(\\frac{1}{b} - \\frac{1}{n}\\right) = m\\sigma^2\\left(\\frac{1}{b} - \\frac{1}{n}\\right)\n$$\n最后，我们将此结果代入 $\\mathbb{E}[\\hat{\\sigma}^{2}_{\\text{OBM}}]$ 的表达式中：\n$$\n\\mathbb{E}[\\hat{\\sigma}^{2}_{\\text{OBM}}] = \\frac{b}{m}\\left[m\\sigma^2\\left(\\frac{1}{b} - \\frac{1}{n}\\right)\\right] = b\\sigma^2\\left(\\frac{n-b}{bn}\\right) = \\sigma^2\\left(\\frac{n-b}{n}\\right) = \\sigma^2\\left(1 - \\frac{b}{n}\\right)\n$$\n这就是 IID 序列的 OBM 估计量的精确有限样本期望。\n\n问题的第二部分要求一个乘法修正因子 $c(n,b)$，使得 $c(n,b)\\hat{\\sigma}^{2}_{\\text{OBM}}$ 是 $\\sigma^2$ 的无偏估计量。这意味着我们需要：\n$$\n\\mathbb{E}\\left[c(n,b)\\hat{\\sigma}^{2}_{\\text{OBM}}\\right] = \\sigma^2\n$$\n由于 $c(n,b)$ 是相对于随机变量的常数，我们有：\n$$\nc(n,b)\\mathbb{E}\\left[\\hat{\\sigma}^{2}_{\\text{OBM}}\\right] = \\sigma^2\n$$\n代入我们推导出的期望值：\n$$\nc(n,b)\\sigma^2\\left(1 - \\frac{b}{n}\\right) = \\sigma^2\n$$\n已知 $\\sigma^2 \\in (0, \\infty)$，我们可以除以 $\\sigma^2$。我们还假设 $b  n$，我们可以除以 $(1 - b/n)$。\n$$\nc(n,b) = \\frac{1}{1 - \\frac{b}{n}} = \\frac{1}{\\frac{n-b}{n}} = \\frac{n}{n-b}\n$$",
            "answer": "$$\\boxed{\\frac{n}{n-b}}$$"
        },
        {
            "introduction": "理论公式的优雅必须与计算上的可行性相结合，才能在实践中发挥价值。直接根据定义计算重叠批次均值（OBM）估计量，涉及到对大量重叠数据窗口的重复求和，其计算复杂度可能高达$O(nb)$，这在处理大规模时间序列时是无法接受的。本练习旨在将理论转化为高效算法，要求我们利用累积和（cumulative sums）这一经典技巧，设计并实现一个线性时间复杂度（$O(n)$）的算法来计算OBM估计量。掌握这种算法设计思想对于在实际应用中快速、准确地分析海量仿真输出至关重要。",
            "id": "3359876",
            "problem": "给定一个由弱相关、平稳且遍历的随机过程生成的有限时间序列 $\\{X_t\\}_{t=1}^n$。根据弱相关序列的中心极限定理，样本均值 $\\bar{X}_n = \\frac{1}{n}\\sum_{t=1}^n X_t$ 满足 $\\sqrt{n}(\\bar{X}_n - \\mu) \\Rightarrow \\mathcal{N}(0,\\sigma^2)$，其中 $\\sigma^2$ 是一个良定义的长程方差。$\\sigma^2$ 的一个广泛使用的一致估计量是重叠批均值（Overlapping Batch Means, OBM）估计量。对于选定的批大小 $b$（$1 \\le b \\le n$），定义重叠批均值为 $\\bar{X}_i^{(b)} = \\frac{1}{b}\\sum_{t=i}^{i+b-1} X_t$，其中 $i = 1,2,\\ldots,n-b+1$。OBM 估计量定义为\n$$\n\\hat{\\sigma}^2_{\\text{OBM}}(b) = \\frac{b}{n-b+1} \\sum_{i=1}^{n-b+1} \\left(\\bar{X}_i^{(b)} - \\bar{X}_n\\right)^2.\n$$\n您的任务是设计并实现一个算法，该算法使用累积和在 $\\mathcal{O}(n)$ 时间内计算所有重叠批均值 $\\bar{X}_i^{(b)}$ 和 OBM 估计量 $\\hat{\\sigma}^2_{\\text{OBM}}(b)$。该算法必须从第一性原理推导得出，并且必须避免冗余的重复计算。\n\n程序必须在没有外部输入的情况下执行，并且必须为以下测试套件计算 $\\hat{\\sigma}^2_{\\text{OBM}}(b)$。所有随机序列必须使用 NumPy 伪随机生成器 $\\texttt{np.random.default_rng}(\\text{seed})$ 生成，以确保可复现性。\n\n测试套件：\n- 测试用例 1（一般相关情况）：参数 $\\phi = 0.7$、新息标准差 $\\sigma_{\\varepsilon} = 1$、初始值 $X_0 = 0$、长度 $n = 1000$、种子 $2025$、批大小 $b = 50$ 的 $\\text{AR}(1)$ 序列。\n- 测试用例 2（边界 $b=1$）：确定性线性序列 $X_t = t$，$t = 1,\\ldots,n$，长度 $n = 10$，批大小 $b = 1$。\n- 测试用例 3（边界 $b=n$）：参数 $\\phi = 0.9$、新息标准差 $\\sigma_{\\varepsilon} = 0.5$、初始值 $X_0 = 0$、长度 $n = 128$、种子 $7$、批大小 $b = n$ 的 $\\text{AR}(1)$ 序列。\n- 测试用例 4（大型独立情况）：独立同分布（IID）的标准正态序列 $X_t \\sim \\mathcal{N}(0,1)$，长度 $n = 5000$，种子 $123456$，批大小 $b = 100$。\n- 测试用例 5（边界 $b=n-1$）：独立同分布（IID）的均匀序列 $X_t \\sim \\text{Uniform}(-1,1)$，长度 $n = 50$，种子 $99$，批大小 $b = n-1 = 49$。\n\n算法要求：\n- 使用单遍扫描计算的累积和数组 $S_k = \\sum_{t=1}^k X_t$（其中 $S_0 = 0$）来计算所有重叠窗口和 $\\sum_{t=i}^{i+b-1} X_t = S_{i+b-1} - S_{i-1}$，从而在 $\\mathcal{O}(n)$ 时间内计算出 $\\bar{X}_i^{(b)}$。\n- 计算 $\\bar{X}_n$，然后在对批均值进行单遍扫描时计算平方偏差和 $\\sum_{i=1}^{n-b+1}(\\bar{X}_i^{(b)} - \\bar{X}_n)^2$。\n- 确保总时间复杂度为 $\\mathcal{O}(n)$ 且内存使用在科学上是合理的。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含五个测试用例的结果，格式为方括号内以逗号分隔的浮点数列表，顺序与上述测试套件描述的顺序一致（例如，$[\\text{result}_1,\\text{result}_2,\\ldots,\\text{result}_5]$）。\n- 此问题不涉及物理单位或角度单位。所有输出均为实数。",
            "solution": "该问题是有效的，因为它在科学上基于随机过程理论和仿真输出分析，定义清晰，提供了所有必要的参数和定义，并且是客观且可通过计算验证的。\n\n任务是实现一个算法，用于在 $\\mathcal{O}(n)$ 时间内为长度为 $n$ 的时间序列 $\\{X_t\\}_{t=1}^n$ 和给定的批大小 $b$ 计算重叠批均值（OBM）方差估计量 $\\hat{\\sigma}^2_{\\text{OBM}}(b)$。OBM 估计量定义为：\n$$\n\\hat{\\sigma}^2_{\\text{OBM}}(b) = \\frac{b}{n-b+1} \\sum_{i=1}^{n-b+1} \\left(\\bar{X}_i^{(b)} - \\bar{X}_n\\right)^2\n$$\n其中 $\\bar{X}_n = \\frac{1}{n}\\sum_{t=1}^n X_t$ 是总均值，$\\bar{X}_i^{(b)} = \\frac{1}{b}\\sum_{t=i}^{i+b-1} X_t$ 是重叠批均值。\n\n一个朴素的实现会通过遍历 $b$ 个数据点来计算 $n-b+1$ 个批均值中的每一个，导致总时间复杂度为 $\\mathcal{O}((n-b+1)b)$，通常为 $\\mathcal{O}(nb)$。这是低效的。为了达到要求的 $\\mathcal{O}(n)$ 复杂度，我们必须避免这种冗余的和的重新计算。基本原理是使用累积和。\n\n算法按以下步骤进行，这些步骤从第一性原理推导得出。\n\n**第 1 步：预计算累积和**\n首先，我们为时间序列 $X = \\{X_1, X_2, \\ldots, X_n\\}$ 构建一个累积和数组 $S$。设 $S_0 = 0$，对于 $k \\in \\{1, \\ldots, n\\}$，$S_k$ 是序列前 $k$ 项的和：\n$$\nS_k = \\sum_{t=1}^k X_t\n$$\n这个数组可以在单遍扫描数据时计算出来，需要 $\\mathcal{O}(n)$ 时间。例如，$S_k = S_{k-1} + X_k$。\n\n**第 2 步：计算总均值 $\\bar{X}_n$**\n使用预先计算的累积和数组，可以高效地计算总均值 $\\bar{X}_n$。序列的总和就是 $S_n$。\n$$\n\\bar{X}_n = \\frac{1}{n} \\sum_{t=1}^n X_t = \\frac{S_n}{n}\n$$\n一旦 $S$ 可用，这个计算是一个 $\\mathcal{O}(1)$ 操作。\n\n**第 3 步：计算所有重叠批均值 $\\bar{X}_i^{(b)}$**\n任何批次内（从索引 $i$ 到 $i+b-1$）的值的总和可以表示为两个累积和之差：\n$$\n\\sum_{t=i}^{i+b-1} X_t = \\left(\\sum_{t=1}^{i+b-1} X_t\\right) - \\left(\\sum_{t=1}^{i-1} X_t\\right) = S_{i+b-1} - S_{i-1}\n$$\n因此，每个批均值 $\\bar{X}_i^{(b)}$ 可以在 $\\mathcal{O}(1)$ 时间内计算出来：\n$$\n\\bar{X}_i^{(b)} = \\frac{S_{i+b-1} - S_{i-1}}{b}\n$$\n我们需要为所有 $i = 1, 2, \\ldots, n-b+1$ 计算这些均值。这可以通过遍历这 $n-b+1$ 个索引并将结果存储在一个数组中来完成。由于每次计算都是 $\\mathcal{O}(1)$ 的，此步骤的总时间为 $\\mathcal{O}(n-b+1)$，其上界为 $\\mathcal{O}(n)$。在像 NumPy 这样的向量化环境中，这可以作为对累积和数组切片的单个操作来执行，从而进一步提高实际效率。\n\n**第 4 步：计算平方偏差和**\n下一个组成部分是每个批均值与总均值之间差的平方和：\n$$\n\\text{SSD} = \\sum_{i=1}^{n-b+1} \\left(\\bar{X}_i^{(b)} - \\bar{X}_n\\right)^2\n$$\n在第 2 步中计算了 $\\bar{X}_n$ 并在第 3 步中计算了所有 $\\bar{X}_i^{(b)}$ 之后，我们可以在对批均值数组进行单遍扫描时计算这个和。这涉及 $n-b+1$ 次减法、平方和加法，时间复杂度为 $\\mathcal{O}(n-b+1)$，即 $\\mathcal{O}(n)$。\n\n**第 5 步：最终估计量计算**\n最后，通过将平方偏差和乘以归一化因子来计算 OBM 估计量：\n$$\n\\hat{\\sigma}^2_{\\text{OBM}}(b) = \\frac{b}{n-b+1} \\times \\text{SSD}\n$$\n这是一个单一的乘法和除法，一个 $\\mathcal{O}(1)$ 操作。\n\n**总复杂度**\n总时间复杂度是一系列 $\\mathcal{O}(n)$ 和 $\\mathcal{O}(1)$ 操作的总和，即 $\\mathcal{O}(n)$。所需的内存为 $\\mathcal{O}(n)$，用于存储输入序列、累积和以及批均值。该设计满足了问题的所有算法要求。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef compute_obm_variance(X: np.ndarray, b: int) - float:\n    \"\"\"\n    Computes the Overlapping Batch Means (OBM) variance estimator in O(n) time.\n\n    Args:\n        X (np.ndarray): The time series data of length n.\n        b (int): The batch size.\n\n    Returns:\n        float: The OBM variance estimate.\n    \"\"\"\n    n = len(X)\n    if not (1 = b = n):\n        raise ValueError(\"Batch size b must be between 1 and n.\")\n\n    # Let k be the number of overlapping batches.\n    k = n - b + 1\n\n    # Step 1: Compute the cumulative sum array S.\n    # S[j] = sum(X[0]...X[j-1]), with S[0] = 0.\n    S = np.concatenate(([0.0], np.cumsum(X)))\n\n    # Step 2: Compute the grand mean X_bar_n.\n    # S[n] contains the sum of all elements in X.\n    X_bar_n = S[n] / n\n\n    # Step 3: Compute all overlapping batch means using vectorized operations.\n    # The sums of the b-sized batches are S[b:] - S[:-b].\n    # This creates an array of k batch sums.\n    batch_sums = S[b:] - S[:k]\n    batch_means = batch_sums / b\n    \n    # Step 4: Compute the sum of squared deviations.\n    sum_sq_dev = np.sum((batch_means - X_bar_n)**2)\n\n    # Step 5: Final OBM estimator calculation.\n    # The pre-factor is b / k.\n    obm_variance = (b / k) * sum_sq_dev\n    \n    return obm_variance\n\ndef generate_ar1_series(phi: float, sigma_eps: float, n: int, seed: int, X0: float = 0.0) - np.ndarray:\n    \"\"\"\n    Generates an AR(1) time series: X_t = phi * X_{t-1} + eps_t.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    eps = rng.normal(loc=0.0, scale=sigma_eps, size=n)\n    X = np.zeros(n)\n    if n  0:\n        X[0] = phi * X0 + eps[0]\n        for t in range(1, n):\n            X[t] = phi * X[t-1] + eps[t]\n    return X\n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1: General correlated case (AR(1))\n        {'type': 'ar1', 'phi': 0.7, 'sigma_eps': 1.0, 'n': 1000, 'seed': 2025, 'b': 50, 'X0': 0.0},\n        \n        # Test case 2: Boundary b=1 (deterministic linear)\n        {'type': 'linear', 'n': 10, 'b': 1},\n        \n        # Test case 3: Boundary b=n (AR(1))\n        {'type': 'ar1', 'phi': 0.9, 'sigma_eps': 0.5, 'n': 128, 'seed': 7, 'b': 128, 'X0': 0.0},\n        \n        # Test case 4: Large independent case (IID Normal)\n        {'type': 'normal', 'n': 5000, 'seed': 123456, 'b': 100},\n        \n        # Test case 5: Boundary b=n-1 (IID Uniform)\n        {'type': 'uniform', 'n': 50, 'seed': 99, 'b': 49}\n    ]\n\n    results = []\n    for case in test_cases:\n        X = None\n        if case['type'] == 'ar1':\n            X = generate_ar1_series(case['phi'], case['sigma_eps'], case['n'], case['seed'], case['X0'])\n        elif case['type'] == 'linear':\n            X = np.arange(1, case['n'] + 1, dtype=float)\n        elif case['type'] == 'normal':\n            rng = np.random.default_rng(case['seed'])\n            X = rng.normal(loc=0.0, scale=1.0, size=case['n'])\n        elif case['type'] == 'uniform':\n            rng = np.random.default_rng(case['seed'])\n            X = rng.uniform(low=-1.0, high=1.0, size=case['n'])\n        \n        b = case['b']\n        \n        result = compute_obm_variance(X, b)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "理论分析为我们提供了指导，但估计量的真实性能最终需要在模拟真实世界复杂性的受控实验中进行检验。这个综合性练习将我们置于一个完整的蒙特卡洛研究场景中。我们将通过模拟一个高度相关的AR(1)过程，实证对比重叠批次均值（OBM）与非重叠批次均值（NBM）这两种方法的性能。更重要的是，本练习将引导我们探索批次大小$b$的选择这一核心实践问题，通过计算均方误差（MSE）来经验性地寻找不同情境下的最优$b$值，从而深刻理解偏差-方差权衡在方差估计中的具体体现。",
            "id": "3359912",
            "problem": "考虑一个严格平稳且遍历的一阶自回归过程，记为 $AR(1)$，由递推关系 $X_t = \\phi X_{t-1} + \\varepsilon_t$ 定义，其中 $\\{ \\varepsilon_t \\}$ 是一个均值为零、方差有限的独立同分布序列，且 $|\\phi|  1$。谱密度 $f(\\omega)$ 是自协方差函数的傅里叶变换，其在零频率处的值 $f(0)$ 通过中心极限定理 (CLT) 和函数中心极限定理 (FCLT) 决定了样本均值的渐近方差，具体如下：$\\sqrt{n}(\\bar{X}_n - \\mu) \\Rightarrow \\mathcal{N}(0, 2\\pi f(0))$，其中 $\\mu = \\mathbb{E}[X_t]$ 且 $\\bar{X}_n = n^{-1}\\sum_{t=1}^n X_t$。长期方差为 $2\\pi f(0)$。\n\n您的任务是在以下对照研究中，经验性地比较非重叠批次均值法和重叠批次均值法在估计 $f(0)$ 时的表现。您必须从上述基本定义和 CLT/FCLT 陈述出发，推导出基于批次均值的有效 $f(0)$ 估计量。然后，您必须实现这些推导出的估计量，并研究它们的均方误差 (MSE) 作为批次大小 $b$ 的函数，最终在规定的网格内确定经验最优的批次大小。\n\n仿真模型与要求：\n- 将自回归参数固定为 $\\phi = 0.95$。\n- 选择新息方差，使 $X_t$ 的边缘方差等于 $1$。\n- 从 $X_t$ 的平稳边缘分布中抽取 $X_0$ 进行初始化，以避免启动偏差。\n- 对每个仿真路径，生成一个长度为 $n$ 的时间序列 $\\{X_t\\}_{t=1}^n$。\n- 对于每个候选批次大小 $b$，计算 $f(0)$ 的两种估计量：\n  - 一种基于大小为 $b$ 的非重叠批次均值法。\n  - 一种基于所有长度为 $b$ 的连续窗口的重叠批次均值法。\n- 使用 $R$ 次独立的蒙特卡洛重复实验，将相对于 $AR(1)$ 模型真实 $f(0)$ 值的平方误差的经验均值作为每个估计量和每个 $b$ 的 MSE 近似值。如果经验最优 $b$ 值出现平局，必须选择达到最小 MSE 的最小 $b$ 值。\n\n测试套件：\n- 使用以下三组参数。对于每种情况，在指定的批次大小网格上评估两种估计量。\n  - 情况 A：$n = 8192$，$R = 256$，候选 $b \\in \\{8, 16, 32, 64, 128, 256, 512, 1024, 2048, 3072\\}$。\n  - 情况 B：$n = 512$，$R = 512$，候选 $b \\in \\{4, 8, 16, 32, 64, 96, 128, 192, 256\\}$。\n  - 情况 C：$n = 20000$，$R = 128$，候选 $b \\in \\{20, 40, 80, 160, 320, 640, 1280, 2560, 4000, 8000\\}$。\n- 对于非重叠批次均值法，仅应用那些能在长度 $n$ 内产生至少两个完整批次的候选 $b$ 值。对于重叠批次均值法，仅应用那些能在长度 $n$ 内产生至少两个重叠窗口的候选 $b$ 值。\n- 为保证可复现性，请使用固定的伪随机数生成器种子，其值为 $20240519$。\n\n交付内容和输出格式：\n- 您的程序必须：\n  - 从第一性原理出发，推导 $f(0)$ 的有效非重叠和重叠批次均值估计量，实现这两种估计量，并计算它们在指定批次大小网格上的经验 MSE。\n  - 对于每种情况，报告非重叠法和重叠法的经验最小化批次大小 $b$，平局时选择较小的 $b$。\n- 最终输出格式：单行输出，包含一个由三个列表组成的列表，按情况 A、情况 B、情况 C 的顺序排列，其中每个内部列表的形式为 $[b_{\\text{nonoverlap}}, b_{\\text{overlap}}]$。例如，输出必须具有 $[[b_{A,\\text{non}},b_{A,\\text{over}}],[b_{B,\\text{non}},b_{B,\\text{over}}],[b_{C,\\text{non}},b_{C,\\text{over}}]]$ 的确切形式，数字内部的逗号后没有空格。\n\n此问题不涉及物理单位。如果出现任何角度，都将以弧度为单位。要求的输出是整数。您的代码必须是自包含的，不需要用户输入，并严格按照指定格式生成一行输出。",
            "solution": "问题要求对特定 AR(1) 过程在零频率处的谱密度 $f(0)$，经验性地比较非重叠批次均值估计量和重叠批次均值估计量。该比较基于不同批次大小时估计量的均方误差 (MSE)。\n\n首先，我们建立理论基础并推导估计量。问题指出，对于一个平稳时间序列，其样本均值为 $\\bar{X}_n$，中心极限定理 (CLT) 的形式为 $\\sqrt{n}(\\bar{X}_n - \\mu) \\Rightarrow \\mathcal{N}(0, \\sigma^2_{LR})$，其中 $\\sigma^2_{LR} = 2\\pi f(0)$ 是长期方差。这意味着对于较大的 $n$，样本均值的方差为 $\\text{Var}(\\bar{X}_n) \\approx \\frac{\\sigma^2_{LR}}{n}$。核心任务是从单个时间序列实现 $\\{X_t\\}_{t=1}^n$ 中估计 $\\sigma^2_{LR}$（并因此估计 $f(0) = \\sigma^2_{LR}/(2\\pi)$）。\n\n指定的仿真模型是 AR(1) 过程 $X_t = \\phi X_{t-1} + \\varepsilon_t$，其中 $\\phi=0.95$。新息 $\\{\\varepsilon_t\\}$ 是独立同分布的，且 $\\mathbb{E}[\\varepsilon_t] = 0$。对于此过程，均值为 $\\mu = \\mathbb{E}[X_t] = 0$。边缘方差为 $\\sigma_X^2 = \\text{Var}(X_t) = \\frac{\\text{Var}(\\varepsilon_t)}{1-\\phi^2}$。问题要求 $\\sigma_X^2=1$，因此我们必须将新息方差设置为 $\\text{Var}(\\varepsilon_t) = \\sigma_\\varepsilon^2 = 1-\\phi^2$。初始状态 $X_0$ 从平稳分布中抽取，假设新息为高斯分布，则该分布为 $\\mathcal{N}(0, \\sigma_X^2) = \\mathcal{N}(0, 1)$。\n\nAR(1) 过程的长期方差 $\\sigma^2_{LR}$ 的真实值由其自协方差之和给出：\n$$\n\\sigma^2_{LR} = \\sum_{h=-\\infty}^{\\infty} \\gamma(h) = \\sum_{h=-\\infty}^{\\infty} \\sigma_X^2 \\phi^{|h|} = \\sigma_X^2 \\frac{1+\\phi}{1-\\phi}\n$$\n在 $\\sigma_X^2 = 1$ 和 $\\phi = 0.95$ 的情况下，真实值为 $\\sigma^2_{LR, \\text{true}} = \\frac{1+0.95}{1-0.95} = \\frac{1.95}{0.05} = 39$。\n对应的 $f(0)$ 真实值为 $f(0)_{\\text{true}} = \\frac{\\sigma^2_{LR, \\text{true}}}{2\\pi} = \\frac{39}{2\\pi}$。我们的估计量将与此值进行评估。\n\n**估计量的推导**\n\n**1. 非重叠批次均值 (NBM) 估计量**\n时间序列 $X_1, \\dots, X_n$ 被划分为 $k = \\lfloor n/b \\rfloor$ 个大小为 $b$ 的连续、非重叠批次。从 $X_{kb+1}, \\dots, X_n$ 的数据被丢弃。第 $i$ 个批次的均值为：\n$$\nY_i = \\frac{1}{b} \\sum_{j=1}^{b} X_{(i-1)b+j} \\quad \\text{for } i=1, \\dots, k\n$$\n如果批次大小 $b$ 足够大，批次均值 $\\{Y_i\\}_{i=1}^k$ 近似不相关且同分布。根据中心极限定理，每个 $Y_i$ 是一个长度为 $b$ 的序列的样本均值，因此 $\\text{Var}(Y_i) \\approx \\sigma^2_{LR}/b$。我们可以使用批次均值的样本方差来估计此方差。$Y_i$ 总体方差的标准无偏估计量是：\n$$\n\\hat{\\text{Var}}(Y_i) = \\frac{1}{k-1} \\sum_{i=1}^k (Y_i - \\bar{Y}_k)^2, \\quad \\text{where } \\bar{Y}_k = \\frac{1}{k} \\sum_{i=1}^k Y_i\n$$\n由于此量估计的是 $\\sigma^2_{LR}/b$，因此通过乘以 $b$ 可得到 $\\sigma^2_{LR}$ 的一个估计量：\n$$\n\\hat{\\sigma}^2_{NBM} = \\frac{b}{k-1} \\sum_{i=1}^k (Y_i - \\bar{Y}_k)^2\n$$\n因此，$f(0)$ 的 NBM 估计量为 $\\hat{f}(0)_{NBM} = \\frac{\\hat{\\sigma}^2_{NBM}}{2\\pi}$。计算方差至少需要 $k=2$ 个批次。\n\n**2. 重叠批次均值 (OBM) 估计量**\nOBM 方法不使用不相交的批次，而是使用所有 $m = n-b+1$ 个可能的长度为 $b$ 的连续子序列。第 $i$ 个重叠批次的均值为：\n$$\nZ_i = \\frac{1}{b} \\sum_{j=0}^{b-1} X_{i+j} \\quad \\text{for } i=1, \\dots, m\n$$\n序列 $\\{Z_i\\}_{i=1}^m$ 是高度相关的，因此若不仔细考虑缩放因子，直接应用样本方差公式是不恰当的。一个通常与 Bartlett 谱密度估计量相关的严格推导表明，一个常用的一致性 $\\sigma^2_{LR}$ 估计量是：\n$$\n\\hat{\\sigma}^2_{OBM} = \\frac{nb}{(n-b+1)(n-b)} \\sum_{i=1}^{n-b+1} (Z_i - \\bar{X}_n)^2\n$$\n其中 $\\bar{X}_n = \\frac{1}{n} \\sum_{t=1}^n X_t$ 是整个序列的总均值。此形式包含一个因子 $\\frac{n}{n-b+1}$，用作偏差校正。$f(0)$ 的 OBM 估计量为 $\\hat{f}(0)_{OBM} = \\frac{\\hat{\\sigma}^2_{OBM}}{2\\pi}$。与 NBM 类似，这要求至少有两个批次均值（$m \\ge 2$，或 $b \\le n-1$）才能有良好定义。\n\n**仿真与评估**\n对于每个测试用例（A、B、C），我们执行 $R$ 次独立的蒙特卡洛重复实验。在每次重复实验中，生成一个长度为 $n$ 的时间序列。对于每个候选批次大小 $b$，我们计算 $\\hat{f}(0)_{NBM}$ 和 $\\hat{f}(0)_{OBM}$。性能通过均方误差 (MSE) 来衡量，其通过 $R$ 次重复实验的经验均值来近似：\n$$\n\\text{MSE}(\\hat{f}(0); b) = \\frac{1}{R} \\sum_{r=1}^R \\left(\\hat{f}(0)^{(r)}(b) - f(0)_{\\text{true}}\\right)^2\n$$\n其中 $\\hat{f}(0)^{(r)}(b)$ 是使用批次大小 $b$ 从第 $r$ 次重复实验中得到的估计值。对于每种类型的估计量，我们从给定的网格中找出使该经验 MSE 最小化的批次大小 $b$，并通过选择最小的 $b$ 来打破平局。实现将遵循这些推导出的公式和步骤。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the batch means comparison problem by running a Monte Carlo simulation.\n    \"\"\"\n    \n    # --- Simulation Constants ---\n    PHI = 0.95\n    SEED = 20240519\n\n    # --- Test Cases ---\n    test_cases = [\n        # Case A\n        {'n': 8192, 'R': 256, 'b_grid': [8, 16, 32, 64, 128, 256, 512, 1024, 2048, 3072]},\n        # Case B\n        {'n': 512, 'R': 512, 'b_grid': [4, 8, 16, 32, 64, 96, 128, 192, 256]},\n        # Case C\n        {'n': 20000, 'R': 128, 'b_grid': [20, 40, 80, 160, 320, 640, 1280, 2560, 4000, 8000]},\n    ]\n\n    # --- Helper Functions ---\n    \n    def generate_ar1_series(n, phi, rng):\n        \"\"\"Generates a stationary AR(1) series of length n with Var(X)=1.\"\"\"\n        sigma_eps = np.sqrt(1 - phi**2)\n        innovations = rng.normal(loc=0, scale=sigma_eps, size=n)\n        x = np.zeros(n)\n        x0 = rng.normal(loc=0, scale=1.0)\n        \n        x[0] = phi * x0 + innovations[0]\n        for t in range(1, n):\n            x[t] = phi * x[t-1] + innovations[t]\n        return x\n\n    def estimate_f0_nbm(x, b):\n        \"\"\"Estimates f(0) using non-overlapping batch means.\"\"\"\n        n = len(x)\n        k = n // b\n        if k  2:\n            return np.nan\n        \n        x_trunc = x[:k * b]\n        batch_means = x_trunc.reshape((k, b)).mean(axis=1)\n        \n        var_batch_means = batch_means.var(ddof=1)\n        sigma_sq_lr_hat = b * var_batch_means\n        \n        f0_hat = sigma_sq_lr_hat / (2 * np.pi)\n        return f0_hat\n\n    def estimate_f0_obm(x, b):\n        \"\"\"Estimates f(0) using overlapping batch means.\"\"\"\n        n = len(x)\n        m = n - b + 1\n        if m  2:\n            return np.nan\n\n        batch_sums = np.convolve(x, np.ones(b), mode='valid')\n        batch_means = batch_sums / b\n        \n        x_bar = x.mean()\n        \n        sum_sq_dev = np.sum((batch_means - x_bar)**2)\n        \n        sigma_sq_lr_hat = (n * b) / (m * (m - 1)) * sum_sq_dev\n        \n        f0_hat = sigma_sq_lr_hat / (2 * np.pi)\n        return f0_hat\n\n    # --- Main Logic ---\n    \n    final_results = []\n    rng = np.random.default_rng(SEED)\n    f0_true = (1 / (2 * np.pi)) * (1 + PHI) / (1 - PHI)\n\n    for case in test_cases:\n        n, R, b_grid = case['n'], case['R'], case['b_grid']\n        \n        sse_nbm = {b: 0.0 for b in b_grid}\n        sse_obm = {b: 0.0 for b in b_grid}\n        \n        for _ in range(R):\n            x_series = generate_ar1_series(n, PHI, rng)\n            \n            for b in b_grid:\n                # NBM estimator\n                if n // b = 2:\n                    f0_hat_nbm = estimate_f0_nbm(x_series, b)\n                    if not np.isnan(f0_hat_nbm):\n                       sse_nbm[b] += (f0_hat_nbm - f0_true)**2\n                \n                # OBM estimator\n                if n - b + 1 = 2:\n                    f0_hat_obm = estimate_f0_obm(x_series, b)\n                    if not np.isnan(f0_hat_obm):\n                        sse_obm[b] += (f0_hat_obm - f0_true)**2\n        \n        # Find optimal batch size for NBM\n        min_mse_nbm = float('inf')\n        opt_b_nbm = -1\n        for b in b_grid:\n            if n // b = 2:\n                mse = sse_nbm[b] / R\n                if mse  min_mse_nbm:\n                    min_mse_nbm = mse\n                    opt_b_nbm = b\n        \n        # Find optimal batch size for OBM\n        min_mse_obm = float('inf')\n        opt_b_obm = -1\n        for b in b_grid:\n            if n - b + 1 = 2:\n                mse = sse_obm[b] / R\n                if mse  min_mse_obm:\n                    min_mse_obm = mse\n                    opt_b_obm = b\n                    \n        final_results.append([opt_b_nbm, opt_b_obm])\n\n    # Format and print the final output as specified\n    inner_lists_str = [f\"[{r[0]},{r[1]}]\" for r in final_results]\n    print(f\"[{','.join(inner_lists_str)}]\")\n\nsolve()\n```"
        }
    ]
}