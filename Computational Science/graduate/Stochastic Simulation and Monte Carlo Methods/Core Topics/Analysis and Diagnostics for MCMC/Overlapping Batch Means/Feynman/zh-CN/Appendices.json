{
    "hands_on_practices": [
        {
            "introduction": "在将重叠分批均值法 (OBM) 应用于复杂的相​​关数据之前，在最简单的场景下理解其性质至关重要：即独立同分布 (IID) 数据。本练习将引导您完成一个基础推导，以揭示一个令人意外的有限样本偏差，并展示如何精确地校正它。通过这项从第一性原理出发的练习，您将巩固对该估计量统计特性的理解。",
            "id": "3326195",
            "problem": "考虑一个平稳的独立同分布 (IID) 序列 $\\{X_{t}\\}_{t=1}^{n}$，其期望为 $\\mathbb{E}[X_{t}]=\\mu$，方差为 $\\operatorname{Var}(X_{t})=\\sigma^{2}\\in(0,\\infty)$。令样本均值为 $\\bar{X}_{n}=(1/n)\\sum_{t=1}^{n}X_{t}$。对于满足 $1\\leq b\\leq n$ 的选定批次长度 $b$，定义 $m=n-b+1$ 个重叠批次及其批次均值为\n$$\nY_{j}=\\frac{1}{b}\\sum_{t=j}^{j+b-1}X_{t},\\quad j=1,2,\\dots,m.\n$$\n时间平均（长程）方差（在独立同分布抽样下等于 $\\sigma^{2}$）的重叠批次均值 (OBM) 估计量定义为\n$$\n\\hat{\\sigma}^{2}_{\\text{OBM}}=\\frac{b}{m}\\sum_{j=1}^{m}\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}.\n$$\n从独立同分布随机变量的基本性质出发，推导出精确的有限样本期望 $\\mathbb{E}[\\hat{\\sigma}^{2}_{\\text{OBM}}]$，将其表示为 $n$、$b$ 和 $\\sigma^{2}$ 的函数，过程中不使用渐近近似。然后，确定一个乘法校正因子 $c(n,b)$，使得 $c(n,b)\\,\\hat{\\sigma}^{2}_{\\text{OBM}}$ 是 $\\sigma^{2}$ 的无偏估计。你的最终答案应仅为 $c(n,b)$ 的闭式解析表达式。无需四舍五入。",
            "solution": "首先根据指定标准验证问题。\n\n### 步骤 1：提取已知条件\n-   一个平稳的独立同分布 (IID) 序列 $\\{X_{t}\\}_{t=1}^{n}$。\n-   $\\mathbb{E}[X_{t}]=\\mu$。\n-   $\\operatorname{Var}(X_{t})=\\sigma^{2}\\in(0,\\infty)$。\n-   样本均值：$\\bar{X}_{n}=(1/n)\\sum_{t=1}^{n}X_{t}$。\n-   批次长度：$b$，满足 $1\\leq b\\leq n$。\n-   重叠批次数：$m=n-b+1$。\n-   批次均值：$Y_{j}=\\frac{1}{b}\\sum_{t=j}^{j+b-1}X_{t}$，其中 $j=1,2,\\dots,m$。\n-   重叠批次均值 (OBM) 估计量：$\\hat{\\sigma}^{2}_{\\text{OBM}}=\\frac{b}{m}\\sum_{j=1}^{m}\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n-   **科学性**：该问题是数理统计中的一个标准练习，特别是在蒙特卡洛模拟中的方差估计背景下。所有术语和概念（IID 序列、批次均值、方差估计量）在该领域都是公认的。\n-   **适定性**：该问题要求推导一个期望和由此产生的校正因子。问题设置清晰，并为唯一的解析解提供了路径。\n-   **客观性**：该问题以精确的数学语言陈述，没有任何主观或模棱两可的术语。\n-   **完备性与一致性**：该问题是自洽的。所有必要的定义和假设（IID 性质、有限非零方差）均已提供。没有矛盾之处。\n\n### 步骤 3：结论与行动\n问题有效。将提供一个完整的、有理有据的解答。\n\n### 解答推导\n我们的目标是求出 OBM 估计量的精确有限样本期望 $\\mathbb{E}[\\hat{\\sigma}^{2}_{\\text{OBM}}]$，然后确定使该估计量无偏的校正因子 $c(n,b)$。\n\nOBM 方差估计量由下式给出：\n$$\n\\hat{\\sigma}^{2}_{\\text{OBM}}=\\frac{b}{m}\\sum_{j=1}^{m}\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}\n$$\n根据期望的线性性质，我们有：\n$$\n\\mathbb{E}[\\hat{\\sigma}^{2}_{\\text{OBM}}] = \\frac{b}{m}\\sum_{j=1}^{m}\\mathbb{E}\\left[\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}\\right]\n$$\n我们来分析求和号内的期望项。首先，我们计算批次均值 $Y_j$ 和总样本均值 $\\bar{X}_n$ 的期望值。\n对于任意批次均值 $Y_j$：\n$$\n\\mathbb{E}[Y_{j}] = \\mathbb{E}\\left[\\frac{1}{b}\\sum_{t=j}^{j+b-1}X_{t}\\right] = \\frac{1}{b}\\sum_{t=j}^{j+b-1}\\mathbb{E}[X_{t}] = \\frac{1}{b}\\sum_{t=j}^{j+b-1}\\mu = \\frac{b\\mu}{b} = \\mu\n$$\n对于总样本均值 $\\bar{X}_n$：\n$$\n\\mathbb{E}[\\bar{X}_{n}] = \\mathbb{E}\\left[\\frac{1}{n}\\sum_{t=1}^{n}X_{t}\\right] = \\frac{1}{n}\\sum_{t=1}^{n}\\mathbb{E}[X_{t}] = \\frac{1}{n}\\sum_{t=1}^{n}\\mu = \\frac{n\\mu}{n} = \\mu\n$$\n因此，差值的期望为零：\n$$\n\\mathbb{E}[Y_{j}-\\bar{X}_{n}] = \\mathbb{E}[Y_{j}]-\\mathbb{E}[\\bar{X}_{n}] = \\mu - \\mu = 0\n$$\n这简化了求和中的项，因为它的期望现在就是它的方差：\n$$\n\\mathbb{E}\\left[\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}\\right] = \\operatorname{Var}(Y_{j}-\\bar{X}_{n}) + (\\mathbb{E}[Y_j-\\bar{X}_n])^2 = \\operatorname{Var}(Y_{j}-\\bar{X}_{n})\n$$\n使用差值方差的性质，我们有：\n$$\n\\operatorname{Var}(Y_{j}-\\bar{X}_{n}) = \\operatorname{Var}(Y_{j}) + \\operatorname{Var}(\\bar{X}_{n}) - 2\\operatorname{Cov}(Y_{j}, \\bar{X}_{n})\n$$\n我们现在计算这三项中的每一项。由于 $\\{X_t\\}$ 是一个 IID 序列，且 $\\operatorname{Var}(X_t) = \\sigma^2$：\n1.  批次均值 $Y_j$ 的方差：\n    $$\n    \\operatorname{Var}(Y_{j}) = \\operatorname{Var}\\left(\\frac{1}{b}\\sum_{t=j}^{j+b-1}X_{t}\\right) = \\frac{1}{b^2}\\sum_{t=j}^{j+b-1}\\operatorname{Var}(X_{t}) = \\frac{1}{b^2}(b\\sigma^2) = \\frac{\\sigma^2}{b}\n    $$\n2.  总样本均值 $\\bar{X}_n$ 的方差：\n    $$\n    \\operatorname{Var}(\\bar{X}_{n}) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{t=1}^{n}X_{t}\\right) = \\frac{1}{n^2}\\sum_{t=1}^{n}\\operatorname{Var}(X_{t}) = \\frac{1}{n^2}(n\\sigma^2) = \\frac{\\sigma^2}{n}\n    $$\n3.  批次均值 $Y_j$ 和总样本均值 $\\bar{X}_n$ 之间的协方差。我们使用 IID 变量的性质 $\\operatorname{Cov}(X_t, X_k) = \\sigma^2\\delta_{tk}$，其中 $\\delta_{tk}$ 是克罗内克δ函数。\n    $$\n    \\operatorname{Cov}(Y_{j}, \\bar{X}_{n}) = \\operatorname{Cov}\\left(\\frac{1}{b}\\sum_{t=j}^{j+b-1}X_{t}, \\frac{1}{n}\\sum_{k=1}^{n}X_{k}\\right) = \\frac{1}{bn}\\sum_{t=j}^{j+b-1}\\sum_{k=1}^{n}\\operatorname{Cov}(X_{t}, X_{k})\n    $$\n    协方差项仅在 $k=t$ 时非零。$t$ 的索引为 $\\{j, j+1, \\dots, j+b-1\\}$，它是 $k$ 的索引 $\\{1, 2, \\dots, n\\}$ 的子集。因此，我们对 $k=t$ 的 $b$ 个实例求和：\n    $$\n    \\operatorname{Cov}(Y_{j}, \\bar{X}_{n}) = \\frac{1}{bn}\\sum_{t=j}^{j+b-1}\\operatorname{Var}(X_{t}) = \\frac{1}{bn}(b\\sigma^2) = \\frac{\\sigma^2}{n}\n    $$\n请注意，$\\operatorname{Var}(Y_j)$、$\\operatorname{Var}(\\bar{X}_n)$ 和 $\\operatorname{Cov}(Y_j, \\bar{X}_n)$ 都与批次索引 $j$ 无关。\n\n现在，我们将这些代回 $\\operatorname{Var}(Y_{j}-\\bar{X}_{n})$ 的表达式中：\n$$\n\\operatorname{Var}(Y_{j}-\\bar{X}_{n}) = \\frac{\\sigma^2}{b} + \\frac{\\sigma^2}{n} - 2\\frac{\\sigma^2}{n} = \\frac{\\sigma^2}{b} - \\frac{\\sigma^2}{n} = \\sigma^2\\left(\\frac{1}{b} - \\frac{1}{n}\\right)\n$$\n由于该项对于所有 $j=1, \\dots, m$ 都是常数，求和变得很简单：\n$$\n\\sum_{j=1}^{m}\\mathbb{E}\\left[\\left(Y_{j}-\\bar{X}_{n}\\right)^{2}\\right] = \\sum_{j=1}^{m}\\sigma^2\\left(\\frac{1}{b} - \\frac{1}{n}\\right) = m\\sigma^2\\left(\\frac{1}{b} - \\frac{1}{n}\\right)\n$$\n最后，我们将此代入 $\\mathbb{E}[\\hat{\\sigma}^{2}_{\\text{OBM}}]$ 的表达式中：\n$$\n\\mathbb{E}[\\hat{\\sigma}^{2}_{\\text{OBM}}] = \\frac{b}{m}\\left[m\\sigma^2\\left(\\frac{1}{b} - \\frac{1}{n}\\right)\\right] = b\\sigma^2\\left(\\frac{n-b}{bn}\\right) = \\sigma^2\\left(\\frac{n-b}{n}\\right) = \\sigma^2\\left(1 - \\frac{b}{n}\\right)\n$$\n这就是 IID 序列的 OBM 估计量的精确有限样本期望。\n\n问题的第二部分要求一个乘法校正因子 $c(n,b)$，使得 $c(n,b)\\hat{\\sigma}^{2}_{\\text{OBM}}$ 是 $\\sigma^2$ 的一个无偏估计量。这意味着我们需要：\n$$\n\\mathbb{E}\\left[c(n,b)\\hat{\\sigma}^{2}_{\\text{OBM}}\\right] = \\sigma^2\n$$\n由于 $c(n,b)$ 相对于随机变量是一个常数，我们有：\n$$\nc(n,b)\\mathbb{E}\\left[\\hat{\\sigma}^{2}_{\\text{OBM}}\\right] = \\sigma^2\n$$\n代入我们推导出的期望：\n$$\nc(n,b)\\sigma^2\\left(1 - \\frac{b}{n}\\right) = \\sigma^2\n$$\n给定 $\\sigma^2 \\in (0, \\infty)$，我们可以除以 $\\sigma^2$。我们还假设 $b  n$，这样分母 $n-b$ 就不会为零，这使得 $c(n,b)$ 有意义。因此，\n$$\nc(n,b) = \\frac{1}{1 - \\frac{b}{n}} = \\frac{n}{n-b}\n$$",
            "answer": "$$\\boxed{\\frac{n}{n-b}}$$"
        },
        {
            "introduction": "OBM 估计量的数学定义涉及对许多重叠窗口的求和，如果直接实现，计算成本可能很高。本练习挑战您从理论走向实践，设计一个具有线性时间复杂度 $\\mathcal{O}(n)$ 的高效算法。掌握这种累积求和技术对于将 OBM 应用于蒙特卡洛模拟中常见的大型数据集至关重要。",
            "id": "3359876",
            "problem": "给定一个由弱相依、平稳且遍历的随机过程产生的有限时间序列 $\\{X_t\\}_{t=1}^n$。根据弱相依序列的中心极限定理，样本均值 $\\bar{X}_n = \\frac{1}{n}\\sum_{t=1}^n X_t$ 满足 $\\sqrt{n}(\\bar{X}_n - \\mu) \\Rightarrow \\mathcal{N}(0,\\sigma^2)$，其中 $\\sigma^2$ 是一个良定义的长程方差。$\\sigma^2$ 的一个广泛使用的相合估计量是重叠批均值 (OBM) 估计量。对于选定的批大小 $b$（满足 $1 \\le b \\le n$），定义重叠批均值为 $\\bar{X}_i^{(b)} = \\frac{1}{b}\\sum_{t=i}^{i+b-1} X_t$，其中 $i = 1,2,\\ldots,n-b+1$。OBM 估计量定义为\n$$\n\\hat{\\sigma}^2_{\\text{OBM}}(b) = \\frac{b}{n-b+1} \\sum_{i=1}^{n-b+1} \\left(\\bar{X}_i^{(b)} - \\bar{X}_n\\right)^2.\n$$\n您的任务是设计并实现一个算法，使用累积和在 $\\mathcal{O}(n)$ 时间内计算所有的重叠批均值 $\\bar{X}_i^{(b)}$ 和 OBM 估计量 $\\hat{\\sigma}^2_{\\text{OBM}}(b)$。该算法必须从第一性原理推导得出，并且必须避免冗余的重复计算。\n\n程序必须在没有外部输入的情况下执行，并且必须为以下测试套件计算 $\\hat{\\sigma}^2_{\\text{OBM}}(b)$。所有随机序列必须使用 NumPy 伪随机数生成器 $\\texttt{np.random.default_rng}(\\text{seed})$ 生成，以确保可复现性。\n\n测试套件：\n- 测试用例 1（一般相关情况）：$\\text{AR}(1)$ 序列，参数 $\\phi = 0.7$，新息标准差 $\\sigma_{\\varepsilon} = 1$，初始值 $X_0 = 0$，长度 $n = 1000$，种子 $2025$，批大小 $b = 50$。\n- 测试用例 2（边界 $b=1$）：确定性线性序列 $X_t = t$，其中 $t = 1,\\ldots,n$，长度 $n = 10$，批大小 $b = 1$。\n- 测试用例 3（边界 $b=n$）：$\\text{AR}(1)$ 序列，参数 $\\phi = 0.9$，新息标准差 $\\sigma_{\\varepsilon} = 0.5$，初始值 $X_0 = 0$，长度 $n = 128$，种子 $7$，批大小 $b = n$。\n- 测试用例 4（大规模独立情况）：独立同分布 (IID) 标准正态序列 $X_t \\sim \\mathcal{N}(0,1)$，长度 $n = 5000$，种子 $123456$，批大小 $b = 100$。\n- 测试用例 5（边界 $b=n-1$）：IID 均匀分布序列 $X_t \\sim \\text{Uniform}(-1,1)$，长度 $n = 50$，种子 $99$，批大小 $b = n-1 = 49$。\n\n算法要求：\n- 使用单遍累积和数组 $S_k = \\sum_{t=1}^k X_t$（其中 $S_0 = 0$）来计算所有重叠窗口和 $\\sum_{t=i}^{i+b-1} X_t = S_{i+b-1} - S_{i-1}$，从而在 $\\mathcal{O}(n)$ 时间内计算出 $\\bar{X}_i^{(b)}$。\n- 计算 $\\bar{X}_n$，然后通过对批均值进行单遍处理来计算离差平方和 $\\sum_{i=1}^{n-b+1}(\\bar{X}_i^{(b)} - \\bar{X}_n)^2$。\n- 确保总体时间复杂度为 $\\mathcal{O}(n)$，且内存使用在科学上是合理的。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含五个测试用例的结果，结果为用方括号括起来的、以逗号分隔的浮点数列表，顺序与上述测试套件的描述一致（例如，$[\\text{result}_1,\\text{result}_2,\\ldots,\\text{result}_5]$）。\n- 本问题中没有物理单位或角度单位。所有输出均为实数。",
            "solution": "该问题是有效的，因为它在科学上基于随机过程理论和模拟输出分析，问题设定良好，提供了所有必要的参数和定义，并且是客观且可通过计算验证的。\n\n任务是为长度为 $n$ 的时间序列 $\\{X_t\\}_{t=1}^n$ 和给定的批大小 $b$ 实现一个在 $\\mathcal{O}(n)$ 时间内计算重叠批均值 (OBM) 方差估计量 $\\hat{\\sigma}^2_{\\text{OBM}}(b)$ 的算法。OBM 估计量定义为：\n$$\n\\hat{\\sigma}^2_{\\text{OBM}}(b) = \\frac{b}{n-b+1} \\sum_{i=1}^{n-b+1} \\left(\\bar{X}_i^{(b)} - \\bar{X}_n\\right)^2\n$$\n其中 $\\bar{X}_n = \\frac{1}{n}\\sum_{t=1}^n X_t$ 是总均值，$\\bar{X}_i^{(b)} = \\frac{1}{b}\\sum_{t=i}^{i+b-1} X_t$ 是重叠批均值。\n\n一个朴素的实现会通过遍历 $b$ 个数据点来计算 $n-b+1$ 个批均值中的每一个，导致总时间复杂度为 $\\mathcal{O}((n-b+1)b)$，通常情况下为 $\\mathcal{O}(nb)$。这是低效的。为达到所要求的 $\\mathcal{O}(n)$ 复杂度，我们必须避免这种对和的冗余重复计算。基本原理是使用累积和。\n\n该算法按以下步骤进行，这些步骤均从第一性原理推导得出。\n\n**第一步：累积和的预计算**\n首先，我们为时间序列 $X = \\{X_1, X_2, \\ldots, X_n\\}$ 构建一个累积和数组 $S$。令 $S_0 = 0$，对于 $k \\in \\{1, \\ldots, n\\}$，令 $S_k$ 为序列前 $k$ 项的和：\n$$\nS_k = \\sum_{t=1}^k X_t\n$$\n这个数组可以通过对数据进行单遍处理来计算，需要 $\\mathcal{O}(n)$ 时间。例如，$S_k = S_{k-1} + X_k$。\n\n**第二步：总均值 $\\bar{X}_n$ 的计算**\n使用预先计算的累积和数组，可以高效地计算总均值 $\\bar{X}_n$。序列的总和就是 $S_n$。\n$$\n\\bar{X}_n = \\frac{1}{n} \\sum_{t=1}^n X_t = \\frac{S_n}{n}\n$$\n一旦 $S$ 可用，这个计算就是一个 $\\mathcal{O}(1)$ 操作。\n\n**第三步：所有重叠批均值 $\\bar{X}_i^{(b)}$ 的计算**\n任何批次内（从索引 $i$ 到 $i+b-1$）的值的和可以表示为两个累积和之差：\n$$\n\\sum_{t=i}^{i+b-1} X_t = \\left(\\sum_{t=1}^{i+b-1} X_t\\right) - \\left(\\sum_{t=1}^{i-1} X_t\\right) = S_{i+b-1} - S_{i-1}\n$$\n因此，每个批均值 $\\bar{X}_i^{(b)}$ 可以在 $\\mathcal{O}(1)$ 时间内计算出来：\n$$\n\\bar{X}_i^{(b)} = \\frac{S_{i+b-1} - S_{i-1}}{b}\n$$\n我们需要为所有 $i = 1, 2, \\ldots, n-b+1$ 计算这些均值。这可以通过遍历这 $n-b+1$ 个索引并将结果存储在一个数组中来完成。由于每次计算都是 $\\mathcal{O}(1)$，这一步的总时间为 $\\mathcal{O}(n-b+1)$，其上界为 $\\mathcal{O}(n)$。在像 NumPy 这样的向量化环境中，这可以作为对累积和数组切片的单个操作来执行，从而进一步提高实际效率。\n\n**第四步：离差平方和的计算**\n下一个部分是每个批均值与总均值之差的平方和：\n$$\n\\text{SSD} = \\sum_{i=1}^{n-b+1} \\left(\\bar{X}_i^{(b)} - \\bar{X}_n\\right)^2\n$$\n在第二步中计算了 $\\bar{X}_n$ 并在第三步中计算了所有 $\\bar{X}_i^{(b)}$ 之后，我们可以通过对批均值数组进行单遍处理来计算这个和。这涉及 $n-b+1$ 次减法、平方和加法，时间复杂度为 $\\mathcal{O}(n-b+1)$，即 $\\mathcal{O}(n)$。\n\n**第五步：最终估计量的计算**\n最后，通过将离差平方和乘以归一化因子来计算 OBM 估计量：\n$$\n\\hat{\\sigma}^2_{\\text{OBM}}(b) = \\frac{b}{n-b+1} \\times \\text{SSD}\n$$\n这是一个乘法和除法操作，属于 $\\mathcal{O}(1)$ 操作。\n\n**总体复杂度**\n总时间复杂度是一系列 $\\mathcal{O}(n)$ 和 $\\mathcal{O}(1)$ 操作的总和，即 $\\mathcal{O}(n)$。所需的内存为 $\\mathcal{O}(n)$，用于存储输入序列、累积和以及批均值。该设计满足了问题的所有算法要求。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef compute_obm_variance(X: np.ndarray, b: int) - float:\n    \"\"\"\n    Computes the Overlapping Batch Means (OBM) variance estimator in O(n) time.\n\n    Args:\n        X (np.ndarray): The time series data of length n.\n        b (int): The batch size.\n\n    Returns:\n        float: The OBM variance estimate.\n    \"\"\"\n    n = len(X)\n    if not (1 = b = n):\n        raise ValueError(\"Batch size b must be between 1 and n.\")\n\n    # Let k be the number of overlapping batches.\n    k = n - b + 1\n\n    # Step 1: Compute the cumulative sum array S.\n    # S[j] = sum(X[0]...X[j-1]), with S[0] = 0.\n    S = np.concatenate(([0.0], np.cumsum(X)))\n\n    # Step 2: Compute the grand mean X_bar_n.\n    # S[n] contains the sum of all elements in X.\n    X_bar_n = S[n] / n\n\n    # Step 3: Compute all overlapping batch means using vectorized operations.\n    # The sums of the b-sized batches are S[b:] - S[:-b].\n    # This creates an array of k batch sums.\n    batch_sums = S[b:] - S[:k]\n    batch_means = batch_sums / b\n    \n    # Step 4: Compute the sum of squared deviations.\n    sum_sq_dev = np.sum((batch_means - X_bar_n)**2)\n\n    # Step 5: Final OBM estimator calculation.\n    # The pre-factor is b / k.\n    obm_variance = (b / k) * sum_sq_dev\n    \n    return obm_variance\n\ndef generate_ar1_series(phi: float, sigma_eps: float, n: int, seed: int, X0: float = 0.0) - np.ndarray:\n    \"\"\"\n    Generates an AR(1) time series: X_t = phi * X_{t-1} + eps_t.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    eps = rng.normal(loc=0.0, scale=sigma_eps, size=n)\n    X = np.zeros(n)\n    if n  0:\n        X[0] = phi * X0 + eps[0]\n        for t in range(1, n):\n            X[t] = phi * X[t-1] + eps[t]\n    return X\n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1: General correlated case (AR(1))\n        {'type': 'ar1', 'phi': 0.7, 'sigma_eps': 1.0, 'n': 1000, 'seed': 2025, 'b': 50, 'X0': 0.0},\n        \n        # Test case 2: Boundary b=1 (deterministic linear)\n        {'type': 'linear', 'n': 10, 'b': 1},\n        \n        # Test case 3: Boundary b=n (AR(1))\n        {'type': 'ar1', 'phi': 0.9, 'sigma_eps': 0.5, 'n': 128, 'seed': 7, 'b': 128, 'X0': 0.0},\n        \n        # Test case 4: Large independent case (IID Normal)\n        {'type': 'normal', 'n': 5000, 'seed': 123456, 'b': 100},\n        \n        # Test case 5: Boundary b=n-1 (IID Uniform)\n        {'type': 'uniform', 'n': 50, 'seed': 99, 'b': 49}\n    ]\n\n    results = []\n    for case in test_cases:\n        X = None\n        if case['type'] == 'ar1':\n            X = generate_ar1_series(case['phi'], case['sigma_eps'], case['n'], case['seed'], case['X0'])\n        elif case['type'] == 'linear':\n            X = np.arange(1, case['n'] + 1, dtype=float)\n        elif case['type'] == 'normal':\n            rng = np.random.default_rng(case['seed'])\n            X = rng.normal(loc=0.0, scale=1.0, size=case['n'])\n        elif case['type'] == 'uniform':\n            rng = np.random.default_rng(case['seed'])\n            X = rng.uniform(low=-1.0, high=1.0, size=case['n'])\n        \n        b = case['b']\n        \n        result = compute_obm_variance(X, b)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "最后一个练习在一个真实的模拟研究中将所有知识点融会贯通。您将应用重叠和非重叠分批均值法来估计相关 AR(1) 过程的长期方差，这是时间序列分析中的一个经典模型。通过实证评估均方误差，您将亲眼见证 OBM 的优势，并着手解决选择最优批次大小这一关键任务。",
            "id": "3359912",
            "problem": "考虑一个严格平稳且遍历的一阶自回归过程，记作$\\text{AR}(1)$，由递推式$X_t = \\phi X_{t-1} + \\varepsilon_t$定义，其中$\\{ \\varepsilon_t \\}$是一个均值为零、方差有限的独立同分布序列，且$|\\phi|  1$。谱密度$f(\\omega)$是自协方差函数的傅里叶变换，在零频率处的值$f(0)$通过中心极限定理（CLT）和函数中心极限定理（FCLT）决定了样本均值的渐近方差，如下所示：$\\sqrt{n}(\\bar{X}_n - \\mu) \\Rightarrow \\mathcal{N}(0, 2\\pi f(0))$，其中$\\mu = \\mathbb{E}[X_t]$且$\\bar{X}_n = n^{-1}\\sum_{t=1}^n X_t$。长期方差为$2\\pi f(0)$。\n\n你的任务是在以下受控研究中，实证比较用于估计$f(0)$的非重叠批次均值法和重叠批次均值法。你必须从上述基本定义和CLT/FCLT论述出发，推导出基于批次均值的$f(0)$的有效估计量。然后，你必须实现所推导的估计量，并研究它们的均方误差（MSE）作为批次大小$b$的函数，最终在指定的网格内确定经验最优的批次大小。\n\n模拟模型和要求：\n- 将自回归参数固定为$\\phi = 0.95$。\n- 选择创新项方差，使得$X_t$的边际方差等于$1$。\n- 初始化$X_0$，使其从$X_t$的平稳边际分布中抽取，以避免启动偏差。\n- 对于每个模拟路径，生成一个长度为$n$的时间序列$\\{X_t\\}_{t=1}^n$。\n- 对于每个候选批次大小$b$，计算$f(0)$的两个估计量：\n  - 一个基于非重叠批次均值，使用大小为$b$的批次。\n  - 一个基于重叠批次均值，使用所有长度为$b$的连续窗口。\n- 使用$R$次独立的蒙特卡洛复制，将每个估计量和每个$b$的MSE近似为相对于$\\text{AR}(1)$模型真实$f(0)$的平方误差的经验均值。经验最优$b$的平局情况必须通过选择达到最小MSE的最小$b$来解决。\n\n测试套件：\n- 使用以下三组参数集。对每种情况，在指定的批次大小网格上评估两种估计量。\n  - 情况A：$n = 8192$，$R = 256$，候选$b \\in \\{8, 16, 32, 64, 128, 256, 512, 1024, 2048, 3072\\}$。\n  - 情况B：$n = 512$，$R = 512$，候选$b \\in \\{4, 8, 16, 32, 64, 96, 128, 192, 256\\}$。\n  - 情况C：$n = 20000$，$R = 128$，候选$b \\in \\{20, 40, 80, 160, 320, 640, 1280, 2560, 4000, 8000\\}$。\n- 对于非重叠批次均值法，只应用那些在长度$n$内能产生至少两个完整批次的候选$b$值。对于重叠批次均值法，只应用那些在长度$n$内能产生至少两个重叠窗口的候选$b$值。\n- 为了可复现性，使用一个固定的伪随机数生成器种子，其值等于$20240519$。\n\n交付成果和输出格式：\n- 你的程序必须：\n  - 从第一性原理出发，推导出$f(0)$的有效的非重叠和重叠批次均值估计量，实现这两种估计量，并在指定的批次大小网格上计算它们的经验MSE。\n  - 对每种情况，报告非重叠方法和重叠方法的经验上最小化MSE的批次大小$b$，平局时选择最小的$b$。\n- 最终输出格式：一行包含一个由三个列表组成的列表，按情况A、情况B、情况C的顺序排列，其中每个内部列表的形式为$[b_{\\text{nonoverlap}}, b_{\\text{overlap}}]$。例如，输出必须是$[[b_{A,\\text{non}},b_{A,\\text{over}}],[b_{B,\\text{non}},b_{B,\\text{over}}],[b_{C,\\text{non}},b_{C,\\text{over}}]]$的确切形式，数字内部的逗号后没有空格。\n\n这个问题不涉及物理单位。所有角度（如果出现的话）都将以弧度为单位。要求的输出是整数。你的代码必须是自包含的，不需要用户输入，并以指定格式精确地产生一行输出。",
            "solution": "该问题要求对用于特定AR(1)过程的零频谱密度$f(0)$的非重叠和重叠批次均值估计量进行实证比较。比较是基于估计量在不同批次大小下的均方误差（MSE）。\n\n首先，我们建立理论基础并推导估计量。问题陈述，对于一个样本均值为$\\bar{X}_n$的平稳时间序列，中心极限定理（CLT）成立，其形式为$\\sqrt{n}(\\bar{X}_n - \\mu) \\Rightarrow \\mathcal{N}(0, \\sigma^2_{LR})$，其中$\\sigma^2_{LR} = 2\\pi f(0)$是长期方差。这意味着对于大的$n$，样本均值的方差为$\\text{Var}(\\bar{X}_n) \\approx \\frac{\\sigma^2_{LR}}{n}$。核心任务是从单个时间序列实现$\\{X_t\\}_{t=1}^n$中估计$\\sigma^2_{LR}$（并由此估计$f(0) = \\sigma^2_{LR}/(2\\pi)$）。\n\n指定的模拟模型是AR(1)过程$X_t = \\phi X_{t-1} + \\varepsilon_t$，其中$\\phi=0.95$。创新项$\\{\\varepsilon_t\\}$是独立同分布的，且$\\mathbb{E}[\\varepsilon_t] = 0$。对于此过程，均值为$\\mu = \\mathbb{E}[X_t] = 0$。边际方差是$\\sigma_X^2 = \\text{Var}(X_t) = \\frac{\\text{Var}(\\varepsilon_t)}{1-\\phi^2}$。问题要求$\\sigma_X^2=1$，所以我们必须将创新项方差设置为$\\text{Var}(\\varepsilon_t) = \\sigma_\\varepsilon^2 = 1-\\phi^2$。初始状态$X_0$从平稳分布中抽取，假设创新项为高斯分布，该分布为$\\mathcal{N}(0, \\sigma_X^2) = \\mathcal{N}(0, 1)$。\n\n对于一个AR(1)过程，长期方差$\\sigma^2_{LR}$的真实值由其自协方差之和给出：\n$$\n\\sigma^2_{LR} = \\sum_{h=-\\infty}^{\\infty} \\gamma(h) = \\sum_{h=-\\infty}^{\\infty} \\sigma_X^2 \\phi^{|h|} = \\sigma_X^2 \\frac{1+\\phi}{1-\\phi}\n$$\n在$\\sigma_X^2 = 1$和$\\phi = 0.95$的条件下，真实值为$\\sigma^2_{LR, \\text{true}} = \\frac{1+0.95}{1-0.95} = \\frac{1.95}{0.05} = 39$。\n$f(0)$对应的真实值是$f(0)_{\\text{true}} = \\frac{\\sigma^2_{LR, \\text{true}}}{2\\pi} = \\frac{39}{2\\pi}$。我们的估计量将与此值进行比较评估。\n\n**估计量的推导**\n\n**1. 非重叠批次均值（NBM）估计量**\n时间序列$X_1, \\dots, X_n$被划分为$k = \\lfloor n/b \\rfloor$个大小为$b$的连续、非重叠的批次。来自$X_{kb+1}, \\dots, X_n$的数据被丢弃。第$i$个批次的均值是：\n$$\nY_i = \\frac{1}{b} \\sum_{j=1}^{b} X_{(i-1)b+j} \\quad \\text{for } i=1, \\dots, k\n$$\n如果批次大小$b$足够大，批次均值$\\{Y_i\\}_{i=1}^k$近似不相关且同分布。根据CLT，每个$Y_i$是一个长度为$b$的序列的样本均值，所以$\\text{Var}(Y_i) \\approx \\sigma^2_{LR}/b$。我们可以使用批次均值的样本方差来估计这个方差。$Y_i$总体方差的标准无偏估计量是：\n$$\n\\hat{\\text{Var}}(Y_i) = \\frac{1}{k-1} \\sum_{i=1}^k (Y_i - \\bar{Y}_k)^2, \\quad \\text{where } \\bar{Y}_k = \\frac{1}{k} \\sum_{i=1}^k Y_i\n$$\n由于这个量估计的是$\\sigma^2_{LR}/b$，因此通过乘以$b$得到$\\sigma^2_{LR}$的一个估计量：\n$$\n\\hat{\\sigma}^2_{NBM} = \\frac{b}{k-1} \\sum_{i=1}^k (Y_i - \\bar{Y}_k)^2\n$$\n因此，$f(0)$的NBM估计量是$\\hat{f}(0)_{NBM} = \\frac{\\hat{\\sigma}^2_{NBM}}{2\\pi}$。计算方差至少需要$k=2$个批次。\n\n**2. 重叠批次均值（OBM）估计量**\n与不相交的批次不同，OBM方法使用所有$m = n-b+1$个可能的长度为$b$的连续子序列。第$i$个重叠批次均值是：\n$$\nZ_i = \\frac{1}{b} \\sum_{j=0}^{b-1} X_{i+j} \\quad \\text{for } i=1, \\dots, m\n$$\n序列$\\{Z_i\\}_{i=1}^m$是高度相关的，因此，若不仔细考虑缩放因子，简单应用样本方差公式是不合适的。一个严谨的推导（通常与Bartlett谱密度估计量相关）表明，$\\sigma^2_{LR}$的一个一致且常用的估计量是：\n$$\n\\hat{\\sigma}^2_{OBM} = \\frac{nb}{(n-b+1)(n-b)} \\sum_{i=1}^{n-b+1} (Z_i - \\bar{X}_n)^2\n$$\n其中$\\bar{X}_n = \\frac{1}{n} \\sum_{t=1}^n X_t$是整个序列的总均值。这种形式包含一个$\\frac{n}{n-b+1}$的因子，用作偏差校正。$f(0)$的OBM估计量是$\\hat{f}(0)_{OBM} = \\frac{\\hat{\\sigma}^2_{OBM}}{2\\pi}$。与NBM类似，为了使其有良好定义，这需要至少两个批次均值（$m \\ge 2$，或$b \\le n-1$）。\n\n**模拟与评估**\n对于每个测试用例（A, B, C），我们执行$R$次独立的蒙特卡洛复制。在每次复制中，生成一个长度为$n$的时间序列。对于每个候选批次大小$b$，我们计算$\\hat{f}(0)_{NBM}$和$\\hat{f}(0)_{OBM}$。性能由均方误差（MSE）衡量，通过$R$次复制的经验均值来近似：\n$$\n\\text{MSE}(\\hat{f}(0); b) = \\frac{1}{R} \\sum_{r=1}^R \\left(\\hat{f}(0)^{(r)}(b) - f(0)_{\\text{true}}\\right)^2\n$$\n其中$\\hat{f}(0)^{(r)}(b)$是使用批次大小$b$从第$r$次复制中得到的估计值。对于每种估计量类型，我们从给定的网格中找出使该经验MSE最小化的批次大小$b$，并通过选择最小的$b$来打破平局。实现将遵循这些推导出的公式和步骤。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the batch means comparison problem by running a Monte Carlo simulation.\n    \"\"\"\n    \n    # --- Simulation Constants ---\n    PHI = 0.95\n    SEED = 20240519\n\n    # --- Test Cases ---\n    test_cases = [\n        # Case A\n        {'n': 8192, 'R': 256, 'b_grid': [8, 16, 32, 64, 128, 256, 512, 1024, 2048, 3072]},\n        # Case B\n        {'n': 512, 'R': 512, 'b_grid': [4, 8, 16, 32, 64, 96, 128, 192, 256]},\n        # Case C\n        {'n': 20000, 'R': 128, 'b_grid': [20, 40, 80, 160, 320, 640, 1280, 2560, 4000, 8000]},\n    ]\n\n    # --- Helper Functions ---\n    \n    def generate_ar1_series(n, phi, rng):\n        \"\"\"Generates a stationary AR(1) series of length n with Var(X)=1.\"\"\"\n        sigma_eps = np.sqrt(1 - phi**2)\n        innovations = rng.normal(loc=0, scale=sigma_eps, size=n)\n        x = np.zeros(n)\n        x0 = rng.normal(loc=0, scale=1.0)\n        \n        x[0] = phi * x0 + innovations[0]\n        for t in range(1, n):\n            x[t] = phi * x[t-1] + innovations[t]\n        return x\n\n    def estimate_f0_nbm(x, b):\n        \"\"\"Estimates f(0) using non-overlapping batch means.\"\"\"\n        n = len(x)\n        k = n // b\n        if k  2:\n            return np.nan\n        \n        x_trunc = x[:k * b]\n        batch_means = x_trunc.reshape((k, b)).mean(axis=1)\n        \n        var_batch_means = batch_means.var(ddof=1)\n        sigma_sq_lr_hat = b * var_batch_means\n        \n        f0_hat = sigma_sq_lr_hat / (2 * np.pi)\n        return f0_hat\n\n    def estimate_f0_obm(x, b):\n        \"\"\"Estimates f(0) using overlapping batch means.\"\"\"\n        n = len(x)\n        m = n - b + 1\n        if m  2:\n            return np.nan\n\n        batch_sums = np.convolve(x, np.ones(b), mode='valid')\n        batch_means = batch_sums / b\n        \n        x_bar = x.mean()\n        \n        sum_sq_dev = np.sum((batch_means - x_bar)**2)\n        \n        sigma_sq_lr_hat = (n * b) / (m * (m - 1)) * sum_sq_dev\n        \n        f0_hat = sigma_sq_lr_hat / (2 * np.pi)\n        return f0_hat\n\n    # --- Main Logic ---\n    \n    final_results = []\n    rng = np.random.default_rng(SEED)\n    f0_true = (1 / (2 * np.pi)) * (1 + PHI) / (1 - PHI)\n\n    for case in test_cases:\n        n, R, b_grid = case['n'], case['R'], case['b_grid']\n        \n        sse_nbm = {b: 0.0 for b in b_grid}\n        sse_obm = {b: 0.0 for b in b_grid}\n        \n        for _ in range(R):\n            x_series = generate_ar1_series(n, PHI, rng)\n            \n            for b in b_grid:\n                # NBM estimator\n                if n // b  2:\n                    f0_hat_nbm = estimate_f0_nbm(x_series, b)\n                    if not np.isnan(f0_hat_nbm):\n                       sse_nbm[b] += (f0_hat_nbm - f0_true)**2\n                \n                # OBM estimator\n                if n - b + 1  2:\n                    f0_hat_obm = estimate_f0_obm(x_series, b)\n                    if not np.isnan(f0_hat_obm):\n                        sse_obm[b] += (f0_hat_obm - f0_true)**2\n        \n        # Find optimal batch size for NBM\n        min_mse_nbm = float('inf')\n        opt_b_nbm = -1\n        for b in b_grid:\n            if n // b  2:\n                mse = sse_nbm[b] / R\n                if mse  min_mse_nbm:\n                    min_mse_nbm = mse\n                    opt_b_nbm = b\n        \n        # Find optimal batch size for OBM\n        min_mse_obm = float('inf')\n        opt_b_obm = -1\n        for b in b_grid:\n            if n - b + 1  2:\n                mse = sse_obm[b] / R\n                if mse  min_mse_obm:\n                    min_mse_obm = mse\n                    opt_b_obm = b\n                    \n        final_results.append([opt_b_nbm, opt_b_obm])\n\n    # Format and print the final output as specified\n    inner_lists_str = [f\"[{r[0]},{r[1]}]\" for r in final_results]\n    print(f\"[{','.join(inner_lists_str)}]\")\n\nsolve()\n```"
        }
    ]
}