{
    "hands_on_practices": [
        {
            "introduction": "马尔可夫链蒙特卡洛（MCMC）方法的核心是生成来自后验分布的样本。但我们如何利用这些样本呢？这个练习将带你实践最基本也是最重要的一步：根据 MCMC 模拟的输出计算后验均值。通过处理一个具体的案例，你将学会如何将一系列离散的样本点转化为对模型参数有意义的估计，这正是贝叶斯推断中连接模拟与结论的关键环节。",
            "id": "1319931",
            "problem": "一位质量控制工程师正在评估一种新型半导体芯片的制造过程。该过程的质量由单个芯片为无缺陷的概率 $p$ 来表征。工程师对 $p$ 的先验信念是，它在离散集合 $S = \\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\\}$ 中的任何一个值都是等可能的。\n\n为了更新这一信念，工程师测试了随机一批 $n=20$ 个芯片，发现其中有 $k=15$ 个是无缺陷的。假设无缺陷芯片的数量服从二项分布。\n\n为了分析给定数据下 $p$ 的后验分布，使用Metropolis-Hastings算法进行了一次马尔可夫链蒙特卡罗（MCMC）模拟。从后验分布中总共生成了5000个样本。在丢弃前1000个样本作为“预烧”（burn-in）期后，对剩余的4000个样本进行了计数。集合 $S$ 中每个可能的 $p$ 值的计数如下：\n- $p=0.1$: 0 个样本\n- $p=0.2$: 0 个样本\n- $p=0.3$: 0 个样本\n- $p=0.4$: 0 个样本\n- $p=0.5$: 19 个样本\n- $p=0.6$: 301 个样本\n- $p=0.7$: 1690 个样本\n- $p=0.8$: 1845 个样本\n- $p=0.9$: 145 个样本\n\n使用这次模拟的结果，计算概率 $p$ 的估计后验均值。报告你的答案，四舍五入到三位有效数字。",
            "solution": "我们想要从预烧（burn-in）后的MCMC输出中估计 $p$ 的后验均值。设 $N$ 为保留的样本总数，$N_{j}$ 为在 $p_{j} \\in S$ 处的样本计数。后验均值的蒙特卡罗估计量为\n$$\n\\hat{\\mu}=\\frac{1}{N}\\sum_{j} p_{j} N_{j}=\\sum_{j} p_{j}\\left(\\frac{N_{j}}{N}\\right).\n$$\n根据计数，$N=4000$，并且只有以下 $N_{j}$ 是非零的：\n$$\nN_{0.5}=19,\\quad N_{0.6}=301,\\quad N_{0.7}=1690,\\quad N_{0.8}=1845,\\quad N_{0.9}=145.\n$$\n因此，\n$$\n\\hat{\\mu}=\\frac{0.5 \\cdot 19+0.6 \\cdot 301+0.7 \\cdot 1690+0.8 \\cdot 1845+0.9 \\cdot 145}{4000}.\n$$\n逐步计算分子：\n$$\n0.5 \\cdot 19=9.5,\\quad 0.6 \\cdot 301=180.6,\\quad 0.7 \\cdot 1690=1183,\\quad 0.8 \\cdot 1845=1476,\\quad 0.9 \\cdot 145=130.5,\n$$\n$$\n9.5+180.6+1183+1476+130.5 = 2979.6.\n$$\n因此，\n$$\n\\hat{\\mu}=\\frac{2979.6}{4000}=0.7449.\n$$\n四舍五入到三位有效数字，得到\n$$\n0.7449 \\approx 0.745.\n$$",
            "answer": "$$\\boxed{0.745}$$"
        },
        {
            "introduction": "标准的随机游走 Metropolis-Hastings 算法虽然通用，但有时效率不高。为了加速收敛，我们可以利用后验分布的几何信息。这个练习将向你介绍一种更高级的采样器——Metropolis-Adjusted Langevin Algorithm (MALA)。你将从朗之万随机微分方程出发，推导出 MALA 的提议机制和接受概率，并将其应用于一个具体的科学计算场景。通过这个实践，你将深刻理解如何利用梯度信息指导马尔可夫链的移动，从而设计出更高效的 MCMC 算法。",
            "id": "3289331",
            "problem": "计算系统生物学中的一项核心任务是根据含噪声的观测数据，对基因调控的随机模型进行参数推断。考虑一个双参数的转录-降解模型，其参数向量 $\\theta \\in \\mathbb{R}^{2}$ 上的贝叶斯后验是平滑且严格为正的。假设我们希望构造一个马尔可夫链蒙特卡洛（MCMC）方法，该方法受到过阻尼朗之万随机微分方程（SDE）的启发，以该后验为目标。针对目标密度 $\\pi(\\theta)$ 的过阻尼朗之万 SDE 由下式给出：\n$$\nd\\theta_{t} \\;=\\; \\frac{1}{2}\\,\\nabla \\log \\pi(\\theta_{t})\\,dt \\;+\\; dW_{t},\n$$\n其中 $W_{t}$ 是一个标准的二维 Wiener 过程，$\\nabla \\log \\pi(\\theta)$ 表示关于 $\\theta$ 的梯度。\n\n任务：\n- 仅从上述 SDE 和 Metropolis-Hastings (MH) 算法的基本定义出发，推导出一个形式为 $\\theta' = \\theta + \\frac{\\delta^{2}}{2}\\,\\nabla \\log \\pi(\\theta) + \\delta\\,\\eta$（其中 $\\eta \\sim \\mathcal{N}(0, I)$）的提议机制，并推导出相应的 MH 接受概率，用 $\\pi$、当前状态 $\\theta$、提议状态 $\\theta'$ 和高斯提议密度来表示。在你首次引入缩略词时，请给出其全称。\n\n然后，将问题具体化到以下源于随机基因表达模型的线性高斯近似的、科学上真实的后验分布。后验分布 $\\pi(\\theta)$ 与均值为 $\\mu$、协方差为 $\\Sigma$ 的高斯密度成正比：\n$$\n\\pi(\\theta) \\;\\propto\\; \\exp\\!\\left(-\\frac{1}{2}(\\theta - \\mu)^{\\top}\\Sigma^{-1}(\\theta - \\mu)\\right),\n$$\n其中\n$$\n\\mu \\;=\\; \\begin{pmatrix}0.5 \\\\ -0.3\\end{pmatrix}, \n\\qquad \n\\Sigma \\;=\\; \\begin{pmatrix}0.5  0.1 \\\\ 0.1  0.4\\end{pmatrix}.\n$$\n假设当前状态为\n$$\n\\theta \\;=\\; \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix},\n$$\n步长参数为 $\\delta = 0.2$，实现的高斯噪声抽取值为\n$$\n\\eta \\;=\\; \\begin{pmatrix}0.5 \\\\ -1.2\\end{pmatrix}.\n$$\n使用你推导的提议机制和通用的 MH 接受概率表达式，计算从 $\\theta$ 移动到提议状态 $\\theta'$ 的 Metropolis 调整的朗之万算法（MALA）的接受概率。将你的最终答案表示为小数，并四舍五入到四位有效数字。",
            "solution": "我们首先推导 Metropolis 调整的朗之万算法（Metropolis-Adjusted Langevin Algorithm, MALA）的提议机制和接受概率。\n\n**1. 提议机制推导**\n\n朗之万随机微分方程（SDE）为：\n$$d\\theta_{t} = \\frac{1}{2}\\nabla \\log \\pi(\\theta_{t})\\,dt + dW_{t}$$\n使用欧拉-丸山（Euler-Maruyama）方法对该 SDE 进行离散化，时间步长为 $\\Delta t$：\n$$\\theta_{t+\\Delta t} \\approx \\theta_t + \\frac{1}{2}\\nabla \\log \\pi(\\theta_t) \\Delta t + \\Delta W_t$$\n其中维纳过程的增量 $\\Delta W_t$ 是一个均值为 0、协方差为 $(\\Delta t)I$ 的高斯随机变量，即 $\\Delta W_t \\sim \\mathcal{N}(0, (\\Delta t)I)$。我们可以将其写为 $\\Delta W_t = \\sqrt{\\Delta t}\\,\\eta$，其中 $\\eta \\sim \\mathcal{N}(0, I)$。\n令步长参数 $\\delta = \\sqrt{\\Delta t}$，则 $\\Delta t = \\delta^2$。代入离散化方程，我们得到从当前状态 $\\theta$ 到提议状态 $\\theta'$ 的 MALA 提议机制：\n$$\\theta' = \\theta + \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta) + \\delta\\eta, \\quad \\eta \\sim \\mathcal{N}(0, I)$$\n这对应于从一个高斯提议分布 $q(\\theta'|\\theta)$ 中抽样，其均值为 $\\theta + \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta)$，协方差为 $\\delta^2 I$。\n\n**2. 接受概率推导**\n\nMetropolis-Hastings (MH) 接受概率为：\n$$\\alpha(\\theta', \\theta) = \\min\\left(1, \\frac{\\pi(\\theta')q(\\theta|\\theta')}{\\pi(\\theta)q(\\theta'|\\theta)}\\right)$$\n提议密度 $q(\\theta'|\\theta)$ 是一个均值为 $\\mu_{\\theta} = \\theta + \\frac{\\delta^2}{2}\\nabla \\log \\pi(\\theta)$、协方差为 $\\delta^2 I$ 的高斯密度。因此，对数提议密度的比值为：\n\\begin{align*} \\log q(\\theta|\\theta') - \\log q(\\theta'|\\theta) = -\\frac{1}{2\\delta^2} \\left( \\|\\theta - \\mu_{\\theta'}\\|^2 - \\|\\theta' - \\mu_{\\theta}\\|^2 \\right) \\\\ = -\\frac{1}{2}(\\theta'-\\theta)^T(\\nabla \\log \\pi(\\theta')+\\nabla \\log \\pi(\\theta)) - \\frac{\\delta^2}{8}(\\|\\nabla \\log \\pi(\\theta')\\|^2 - \\|\\nabla \\log \\pi(\\theta)\\|^2) \\end{align*}\n对于多元高斯目标分布，可以证明 $\\log\\pi(\\theta') - \\log\\pi(\\theta) = \\frac{1}{2}(\\theta'-\\theta)^T(\\nabla \\log \\pi(\\theta')+\\nabla \\log \\pi(\\theta))$。将这两部分代入对数接受率 $\\log R = \\log \\frac{\\pi(\\theta')}{\\pi(\\theta)} + \\log \\frac{q(\\theta|\\theta')}{q(\\theta'|\\theta)}$，前两项恰好抵消，得到一个简洁的表达式：\n$$\\log R = - \\frac{\\delta^2}{8} \\left( \\|\\nabla \\log \\pi(\\theta')\\|^2 - \\|\\nabla \\log \\pi(\\theta)\\|^2 \\right)$$\n\n**3. 数值计算**\n\n后验分布为高斯分布，$\\pi(\\theta) \\propto \\exp\\left(-\\frac{1}{2}(\\theta - \\mu)^{\\top}\\Sigma^{-1}(\\theta - \\mu)\\right)$。其对数梯度的表达式为 $g(\\theta) = \\nabla \\log \\pi(\\theta) = -\\Sigma^{-1}(\\theta - \\mu)$。\n\n给定的参数为：\n$$\\mu = \\begin{pmatrix}0.5 \\\\ -0.3\\end{pmatrix}, \\quad \\Sigma = \\begin{pmatrix}0.5  0.1 \\\\ 0.1  0.4\\end{pmatrix}, \\quad \\theta = \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix}, \\quad \\delta = 0.2, \\quad \\eta = \\begin{pmatrix}0.5 \\\\ -1.2\\end{pmatrix}$$\n首先，计算 $\\Sigma$ 的逆矩阵：\n$$\\det(\\Sigma) = (0.5)(0.4) - (0.1)(0.1) = 0.19$$\n$$\\Sigma^{-1} = \\frac{1}{0.19} \\begin{pmatrix}0.4  -0.1 \\\\ -0.1  0.5\\end{pmatrix}$$\n计算在 $\\theta$ 处的梯度 $g(\\theta)$:\n$$\\theta - \\mu = \\begin{pmatrix}0.1 \\\\ 0.1\\end{pmatrix}$$\n$$g(\\theta) = -\\Sigma^{-1}(\\theta - \\mu) = -\\frac{1}{0.19} \\begin{pmatrix}0.4  -0.1 \\\\ -0.1  0.5\\end{pmatrix} \\begin{pmatrix}0.1 \\\\ 0.1\\end{pmatrix} = -\\frac{1}{0.19} \\begin{pmatrix}0.03 \\\\ 0.04\\end{pmatrix} = -\\frac{1}{19} \\begin{pmatrix}3 \\\\ 4\\end{pmatrix}$$\n计算提议状态 $\\theta'$:\n$$\\theta' = \\theta + \\frac{\\delta^2}{2}g(\\theta) + \\delta\\eta = \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix} + \\frac{0.04}{2} \\left(-\\frac{1}{19}\\begin{pmatrix}3 \\\\ 4\\end{pmatrix}\\right) + 0.2\\begin{pmatrix}0.5 \\\\ -1.2\\end{pmatrix}$$\n$$\\theta' = \\begin{pmatrix}0.6 \\\\ -0.2\\end{pmatrix} - \\frac{1}{19}\\begin{pmatrix}0.06 \\\\ 0.08\\end{pmatrix} + \\begin{pmatrix}0.1 \\\\ -0.24\\end{pmatrix} = \\begin{pmatrix}0.7 \\\\ -0.44\\end{pmatrix} - \\begin{pmatrix}0.06/19 \\\\ 0.08/19\\end{pmatrix} = \\frac{1}{19}\\begin{pmatrix}13.24 \\\\ -8.44\\end{pmatrix}$$\n计算在 $\\theta'$ 处的梯度 $g(\\theta')$:\n$$\\theta'-\\mu = \\frac{1}{19}\\begin{pmatrix}13.24 \\\\ -8.44\\end{pmatrix} - \\begin{pmatrix}0.5 \\\\ -0.3\\end{pmatrix} = \\frac{1}{19}\\begin{pmatrix}13.24 - 9.5 \\\\ -8.44 + 5.7\\end{pmatrix} = \\frac{1}{19}\\begin{pmatrix}3.74 \\\\ -2.74\\end{pmatrix}$$\n$$g(\\theta') = -\\Sigma^{-1}(\\theta'-\\mu) = -\\frac{1}{0.19 \\times 19} \\begin{pmatrix}0.4  -0.1 \\\\ -0.1  0.5\\end{pmatrix}\\begin{pmatrix}3.74 \\\\ -2.74\\end{pmatrix} = -\\frac{1}{3.61} \\begin{pmatrix}1.77 \\\\ -1.744\\end{pmatrix}$$\n现在计算梯度的范数平方：\n$$\\|g(\\theta)\\|^2 = \\left(-\\frac{1}{19}\\right)^2 (3^2 + 4^2) = \\frac{25}{361} \\approx 0.069252$$\n$$\\|g(\\theta')\\|^2 = \\left(-\\frac{1}{3.61}\\right)^2 (1.77^2 + (-1.744)^2) = \\frac{6.174436}{13.0321} \\approx 0.473786$$\n最后，计算对数接受率 $\\log R$。其中 $\\delta^2/8 = 0.04/8 = 0.005$。\n$$\\log R = -0.005 \\times (\\|g(\\theta')\\|^2 - \\|g(\\theta)\\|^2) = -0.005 \\times (0.473786 - 0.069252) = -0.00202267$$\n接受概率为 $\\alpha = \\min(1, \\exp(\\log R))$。\n$$\\alpha = \\exp(-0.00202267) \\approx 0.99797936$$\n四舍五入到四位有效数字，结果是 $0.9980$。",
            "answer": "$$\\boxed{0.9980}$$"
        },
        {
            "introduction": "理论知识的最终考验在于能否将其转化为可靠的计算程序。这个综合性练习要求你从头开始，为一个计算核物理中的真实模型编写一个完整的、数值稳定的 Metropolis-Hastings 采样器。你将直面实际应用中的核心挑战：当概率值变得极小或极大时，如何通过在对数域（log-domain）中进行计算来避免浮点数下溢或上溢，确保算法的稳健性。这项实践将理论与编程紧密结合，让你掌握将贝叶斯模型付诸实践所必需的关键技能。",
            "id": "3604531",
            "problem": "您的任务是实现一个数值稳定的 Metropolis–Hastings 算法，为一个用于计算核物理的简单透射实验模型执行贝叶斯推断。您的实现必须是一个完整、可运行的程序，并且所有可能遭受下溢或上溢的计算都必须在适当的情况下于对数域中执行。\n\n考虑单能束流在选定束流能量下穿过薄靶的透射。设有效能量相关衰减由以下模型描述\n$$\n\\Sigma(E;\\sigma_0,A) = \\sigma_0 + \\frac{A}{(E - E_r)^2 + \\gamma^2},\n$$\n其中 $E$ 是束流能量，$\\sigma_0 \\ge 0$ 和 $A \\ge 0$ 是待推断的未知非负参数，$E_r$ 和 $\\gamma$ 是已知常数。在能量 $E_i$ 处的期望透射计数由以下模型描述\n$$\n\\lambda_i = I_0 \\exp\\left(-k \\, \\Sigma(E_i; \\sigma_0, A)\\right),\n$$\n其中 $I_0 > 0$ 和 $k > 0$ 是已知量。在每个选定 $E_i$ 处的观测透射计数 $y_i$ 是独立的，并服从均值为 $\\lambda_i$ 的泊松分布。\n\n您的任务是：\n- 通过对数变换 $\\theta = (\\theta_0,\\theta_1)$ 表示未知数，其中 $\\sigma_0 = \\exp(\\theta_0)$ 且 $A = \\exp(\\theta_1)$，以强制实现非负性。\n- 对 $\\theta_j$ 使用具有给定均值和标准差的独立高斯先验。\n- 在变换空间 $\\theta$ 中使用高斯提议分布实现一个随机游走 Metropolis–Hastings 采样器。由于提议分布是对称的，Hastings 校正项被抵消。\n- 使用对数域算术计算所有接受决策，以确保数值稳定性。特别地，不要在线性尺度上直接计算接受概率；而是将 $\\log u$ 与对数接受率进行比较，其中 $u$ 从 $(0,1)$ 上的均匀分布中抽取。\n- 通过对泊松对数概率求和来计算对数似然，仅使用对数安全的量。如果直接计算 $\\lambda_i$ 会有下溢风险，则不得通过先构造 $\\lambda_i$ 再计算 $\\log(\\lambda_i)$；而应将 $\\log(\\lambda_i)$ 计算为 $\\log(I_0) - k \\,\\Sigma(E_i; \\sigma_0, A)$，并将 $-\\lambda_i$ 计算为 $-\\exp(\\log(\\lambda_i))$。对 $\\log(y_i!)$ 使用数值稳定的函数。\n\n使用以下测试套件，它指定了三个具有不同机制的合成实验。在每种情况下，您必须使用指定的全局种子和种子偏移量，通过所述的泊松模型生成合成数据 $y_i$，然后执行推断。\n\n所有测试的通用设置：\n- 能量 $E = [6.0, 6.3, 6.6, 6.9, 7.2]$。\n- 共振参数 $E_r = 6.6$ 和 $\\gamma = 0.05$。\n- 全局基础种子 $s = 12345$。对于测试用例索引 $c \\in \\{0,1,2\\}$，使用数据生成和采样的随机数生成器种子 $s + c$。\n\n测试用例 1 (中等机制)：\n- $I_0 = 200000$, $k = 5.0$。\n- 用于数据生成的真实参数：$\\sigma_0^{\\mathrm{true}} = 0.3$, $A^{\\mathrm{true}} = 3.0$。\n- $\\theta$ 的先验：均值 $(\\mu_0,\\mu_1) = (\\log(0.3), \\log(3.0))$，标准差 $(\\tau_0,\\tau_1) = (1.0, 1.0)$。\n- $(\\theta_0,\\theta_1)$ 的提议标准差：$(0.05, 0.10)$。\n- Metropolis–Hastings 运行长度 $N = 12000$，老化期 $B = 2000$。\n\n测试用例 2 (极端衰减，预期有大量零值)：\n- $I_0 = 5000000$, $k = 50.0$。\n- 用于数据生成的真实参数：$\\sigma_0^{\\mathrm{true}} = 0.1$, $A^{\\mathrm{true}} = 10.0$。\n- $\\theta$ 的先验：均值 $(\\mu_0,\\mu_1) = (\\log(0.2), \\log(2.0))$，标准差 $(\\tau_0,\\tau_1) = (1.0, 1.0)$。\n- $(\\theta_0,\\theta_1)$ 的提议标准差：$(0.10, 0.20)$。\n- Metropolis–Hastings 运行长度 $N = 12000$，老化期 $B = 2000$。\n\n测试用例 3 (近乎平坦的背景，无共振贡献)：\n- $I_0 = 150000$, $k = 2.0$。\n- 用于数据生成的真实参数：$\\sigma_0^{\\mathrm{true}} = 0.25$, $A^{\\mathrm{true}} = 0.0$。\n- $\\theta$ 的先验：均值 $(\\mu_0,\\mu_1) = (\\log(0.2), \\log(1.0))$，标准差 $(\\tau_0,\\tau_1) = (1.0, 0.5)$。\n- $(\\theta_0,\\theta_1)$ 的提议标准差：$(0.05, 0.10)$。\n- Metropolis–Hastings 运行长度 $N = 12000$，老化期 $B = 2000$。\n\n要求：\n- 使用指定的种子生成合成计数并驱动采样器。\n- 为保证数值稳定性，所有接受决策必须完全在对数域中执行，即，如果 $\\log u  \\min\\{0, \\log \\pi(\\theta') - \\log \\pi(\\theta)\\}$ 则接受，其中 $\\pi$ 是变换空间中未归一化的后验密度，且 $u \\sim \\mathrm{Uniform}(0,1)$。\n- 对于每个测试用例，根据老化期后的样本计算 $\\sigma_0$ 和 $A$ 的后验均值估计，以及整个运行过程中的总接受率。在此简化模型中，这些参数是无量纲的，因此不需要物理单位。\n- 角度单位不适用。\n- 最终结果必须汇总所有三个测试用例并打印为单行：一个逗号分隔的 Python 风格列表，按顺序包含每个用例的 $\\sigma_0$ 的后验均值、 $A$ 的后验均值和接受率，即，\n$$\n[\\overline{\\sigma_0}^{(1)}, \\overline{A}^{(1)}, \\alpha^{(1)}, \\overline{\\sigma_0}^{(2)}, \\overline{A}^{(2)}, \\alpha^{(2)}, \\overline{\\sigma_0}^{(3)}, \\overline{A}^{(3)}, \\alpha^{(3)}].\n$$\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]$）。数值结果必须是浮点数。\n\n测试套件覆盖意图：\n- 测试用例 $1$ 是一个标准的、表现良好的机制。\n- 测试用例 $2$ 强调对数域稳定性，因为 $\\lambda_i$ 可能极小，从而产生许多零值。\n- 测试用例 $3$ 探究当共振贡献消失 ($A \\approx 0$) 时的可辨识性，并测试先验的影响。\n\n请准确实现程序以执行这些任务，并打印所需的单行输出。不允许用户输入，且程序在指定种子下必须是完全确定性的。",
            "solution": "该问题要求实现一个 Metropolis-Hastings 马尔可夫链蒙特卡洛 (MCMC) 算法，对一个核透射模型的参数进行贝叶斯推断。该解决方案必须数值稳定，特别是通过一致地使用对数域算术。整个过程可分解为贝叶斯模型的构建、MCMC 采样算法的描述以及对所生成样本的最终分析。\n\n### 1. 贝叶斯模型构建\n\n贝叶斯方法的核心是后验分布，它将关于参数的先验知识与来自观测数据的信息（似然）相结合。\n\n**参数变换：**\n待推断的物理参数是背景衰减 $\\sigma_0$ 和共振振幅 $A$，两者都必须是非负的。为了自然地强制执行此约束，我们在一个变换后的参数空间 $\\theta = (\\theta_0, \\theta_1)$ 中工作，其中：\n$$\n\\sigma_0 = \\exp(\\theta_0) \\quad \\text{and} \\quad A = \\exp(\\theta_1)\n$$\n此变换将每个 $\\theta_j$ 的整个实数轴 $(-\\infty, \\infty)$ 映射到 $\\sigma_0$ 和 $A$ 所需的正值域 $(0, \\infty)$。\n\n**似然函数：**\n观测数据由一组能量 $E = \\{E_i\\}$ 下的计数 $y = \\{y_i\\}$ 组成。每个 $y_i$ 被建模为来自泊松分布的独立抽样，其均值 $\\lambda_i$ 依赖于参数 $\\theta$：\n$$\ny_i \\sim \\text{Poisson}(\\lambda_i(\\theta))\n$$\n数据集 $y$ 的完整似然是各个泊松概率的乘积：\n$$\np(y | \\theta) = \\prod_{i} \\frac{\\lambda_i(\\theta)^{y_i} e^{-\\lambda_i(\\theta)}}{y_i!}\n$$\n平均计数率 $\\lambda_i$ 由比尔-朗伯衰减定律确定：\n$$\n\\lambda_i(\\theta) = I_0 \\exp\\left(-k \\, \\Sigma(E_i; \\sigma_0, A)\\right)\n$$\n其中 $I_0$ 是入射束流强度，$k$ 是一个与靶厚度和数密度相关的常数。与能量相关的衰减截面 $\\Sigma$ 被建模为一个恒定的背景加上一个洛伦兹共振：\n$$\n\\Sigma(E_i; \\sigma_0, A) = \\sigma_0 + \\frac{A}{(E_i - E_r)^2 + \\gamma^2}\n$$\n此处，$E_r$ 和 $\\gamma$ 分别是代表共振能量和宽度的已知常数。\n\n**先验分布：**\n先验分布代表了我们在观测数据之前对参数的了解。对于变换后的参数 $\\theta_j$，指定了独立的高斯先验：\n$$\np(\\theta) = p(\\theta_0)p(\\theta_1) = \\mathcal{N}(\\theta_0 | \\mu_0, \\tau_0^2) \\, \\mathcal{N}(\\theta_1 | \\mu_1, \\tau_1^2)\n$$\n其中 $(\\mu_0, \\mu_1)$ 是 $\\theta_0$ 和 $\\theta_1$ 的先验均值，$(\\tau_0, \\tau_1)$ 是先验标准差。\n\n### 2. 对数后验与数值稳定性\n\n后验分布 $\\pi(\\theta | y)$ 由贝叶斯定理给出：\n$$\n\\pi(\\theta | y) \\propto p(y | \\theta) \\, p(\\theta)\n$$\n出于计算目的，使用后验分布的对数要稳定和方便得多。由于 MCMC 算法仅依赖于后验密度的比率，因此可以忽略加法常数。\n$$\n\\log \\pi(\\theta | y) = \\log p(y | \\theta) + \\log p(\\theta) + \\text{constant}\n$$\n对数似然项为：\n$$\n\\log p(y | \\theta) = \\sum_i \\left( y_i \\log(\\lambda_i(\\theta)) - \\lambda_i(\\theta) - \\log(y_i!) \\right)\n$$\n为防止数值下溢/上溢，尤其是在具有极端衰减的测试用例中（其中 $\\lambda_i$ 可能非常接近于零），我们必须仔细计算这些项：\n1.  项 $\\log(\\lambda_i(\\theta))$ 直接根据其定义计算，以避免首先计算一个可能非常小的 $\\lambda_i$：\n    $$\n    \\log(\\lambda_i(\\theta)) = \\log(I_0) - k \\, \\Sigma(E_i; \\exp(\\theta_0), \\exp(\\theta_1))\n    $$\n2.  项 $-\\lambda_i(\\theta)$ 计算为 $-\\exp(\\log(\\lambda_i(\\theta)))$。\n3.  对数阶乘项 $\\log(y_i!)$ 通过数值稳定的对数伽马函数 $\\log \\Gamma(y_i+1)$ 计算。\n\n对数先验项是两个高斯对数概率密度之和（忽略归一化常数）：\n$$\n\\log p(\\theta) \\propto -\\frac{1}{2} \\left[ \\left(\\frac{\\theta_0 - \\mu_0}{\\tau_0}\\right)^2 + \\left(\\frac{\\theta_1 - \\mu_1}{\\tau_1}\\right)^2 \\right]\n$$\n\n### 3. Metropolis-Hastings 算法\n\n我们采用随机游走 Metropolis-Hastings (RWMH) 算法从后验分布 $\\pi(\\theta | y)$ 中抽取样本。\n\n1.  **初始化**：链在起始点 $\\theta^{(0)}$ 初始化，该点选为先验的均值 $(\\mu_0, \\mu_1)$。\n2.  **迭代**：对于从 $0$ 到 $N-1$ 的每一步 $t$：\n    a.  **提议**：通过向当前状态 $\\theta^{(t)}$ 添加一个来自对称高斯分布的随机扰动，来提议一个新的候选状态 $\\theta'$：\n        $$\n        \\theta' = \\theta^{(t)} + \\epsilon, \\quad \\text{where} \\quad \\epsilon \\sim \\mathcal{N}(0, \\Sigma_p)\n        $$\n        提议协方差 $\\Sigma_p$ 是对角阵，其方差由指定的提议标准差给出。由于提议是对称的，Hastings 校正项为 $1$。\n\n    b.  **接受**：候选状态 $\\theta'$ 以概率 $\\alpha(\\theta', \\theta^{(t)}) = \\min\\left(1, \\frac{\\pi(\\theta'|y)}{\\pi(\\theta^{(t)}|y)}\\right)$ 被接受。为了稳定地实现此决策，我们计算比率的对数：\n        $$\n        \\log r = \\log\\pi(\\theta'|y) - \\log\\pi(\\theta^{(t)}|y)\n        $$\n        然后我们抽取一个均匀随机数 $u \\sim \\mathcal{U}(0,1)$，如果 $\\log u  \\log r$ 则接受提议。问题指定了等效且稳健的条件：如果 $\\log u  \\min(0, \\log r)$ 则接受。如果接受，我们设置 $\\theta^{(t+1)} = \\theta'$；否则，我们设置 $\\theta^{(t+1)} = \\theta^{(t)}$，链不移动。\n\n### 4. 数据模拟与后验分析\n\n对于三个测试用例中的每一个，我们首先模拟合成数据，然后执行推断。\n\n-   **数据生成**：对于具有真实参数 $(\\sigma_0^{\\text{true}}, A^{\\text{true}})$ 的给定测试用例，我们为每个能量 $E_i$ 计算真实的平均计数 $\\lambda_i^{\\text{true}}$。然后，使用指定的随机数生成器种子，通过从泊松分布 $y_i \\sim \\text{Poisson}(\\lambda_i^{\\text{true}})$ 中抽样来生成合成数据集 $\\{y_i\\}$，以确保可复现性。\n\n-   **推断与分析**：\n    1.  RWMH 采样器总共运行 $N$ 次迭代，以生成样本链 $\\{\\theta^{(t)}\\}_{t=0}^{N-1}$。\n    2.  丢弃最初的 $B$ 个样本（老化期），以确保剩余的样本代表平稳后验分布。\n    3.  将老化期后的 $\\theta$ 样本变换回原始参数空间：$(\\sigma_0^{(t)}, A^{(t)}) = (\\exp(\\theta_0^{(t)}), \\exp(\\theta_1^{(t)}))$。\n    4.  通过对这些样本求平均来估计后验均值：\n        $$\n        \\overline{\\sigma_0} = \\frac{1}{N-B} \\sum_{t=B}^{N-1} \\sigma_0^{(t)}, \\quad \\overline{A} = \\frac{1}{N-B} \\sum_{t=B}^{N-1} A^{(t)}\n        $$\n    5.  总接受率 $\\alpha$ 计算为在 $N$ 次迭代的整个运行过程中被接受的提议所占的比例。\n\n整个过程在一个程序中实现，对每个测试用例执行，并将最终结果汇总为指定的输出格式。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef solve():\n    \"\"\"\n    Main function to run the full analysis for all test cases and print the final result.\n    \"\"\"\n\n    # Common settings for all test cases\n    common_settings = {\n        'E': np.array([6.0, 6.3, 6.6, 6.9, 7.2]),\n        'Er': 6.6,\n        'gamma': 0.05,\n        'N': 12000,\n        'B': 2000,\n        'base_seed': 12345\n    }\n\n    # Test suite definition\n    test_cases = [\n        {\n            # Test case 1: Moderate regime\n            'case_idx': 0,\n            'I0': 200000.0,\n            'k': 5.0,\n            'true_params': {'sigma0': 0.3, 'A': 3.0},\n            'prior_means': (np.log(0.3), np.log(3.0)),\n            'prior_stds': (1.0, 1.0),\n            'proposal_stds': (0.05, 0.10)\n        },\n        {\n            # Test case 2: Extreme attenuation\n            'case_idx': 1,\n            'I0': 5000000.0,\n            'k': 50.0,\n            'true_params': {'sigma0': 0.1, 'A': 10.0},\n            'prior_means': (np.log(0.2), np.log(2.0)),\n            'prior_stds': (1.0, 1.0),\n            'proposal_stds': (0.10, 0.20)\n        },\n        {\n            # Test case 3: Nearly flat background\n            'case_idx': 2,\n            'I0': 150000.0,\n            'k': 2.0,\n            'true_params': {'sigma0': 0.25, 'A': 0.0},\n            'prior_means': (np.log(0.2), np.log(1.0)),\n            'prior_stds': (1.0, 0.5),\n            'proposal_stds': (0.05, 0.10)\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        # Combine common settings with case-specific settings\n        params = {**common_settings, **case}\n        \n        # Run the MCMC simulation for the current case\n        mean_sigma0, mean_A, acceptance_rate = run_mcmc_for_case(params)\n        \n        # Append results for this case\n        all_results.extend([mean_sigma0, mean_A, acceptance_rate])\n\n    # Print results in the required format\n    print(f\"[{','.join(map(str, all_results))}]\")\n\ndef sigma_attenuation(E, sigma0, A, Er, gamma):\n    \"\"\"\n    Computes the effective energy-dependent attenuation Sigma.\n    \"\"\"\n    return sigma0 + A / ((E - Er)**2 + gamma**2)\n\ndef log_posterior(theta, y, E, I0, k, Er, gamma, prior_means, prior_stds):\n    \"\"\"\n    Computes the log of the unnormalized posterior density.\n    All calculations are performed in the log domain for numerical stability.\n    \"\"\"\n    theta0, theta1 = theta\n    sigma0 = np.exp(theta0)\n    A = np.exp(theta1)\n    \n    # Log-prior calculation\n    log_prior_val = -0.5 * np.sum(((theta - prior_means) / prior_stds)**2)\n\n    # Log-likelihood calculation (vectorized over energies E)\n    Sigma_vec = sigma_attenuation(E, sigma0, A, Er, gamma)\n    log_lambda_vec = np.log(I0) - k * Sigma_vec\n    \n    # Poisson log-likelihood: y*log(lambda) - lambda - log(y!)\n    log_likelihood_val = np.sum(y * log_lambda_vec - np.exp(log_lambda_vec) - gammaln(y + 1))\n    \n    return log_likelihood_val + log_prior_val\n\ndef run_mcmc_for_case(params):\n    \"\"\"\n    Generates synthetic data and runs the Metropolis-Hastings sampler for a single test case.\n    \"\"\"\n    # Unpack parameters\n    E = params['E']\n    Er = params['Er']\n    gamma = params['gamma']\n    I0 = params['I0']\n    k = params['k']\n    true_params = params['true_params']\n    prior_means = np.array(params['prior_means'])\n    prior_stds = np.array(params['prior_stds'])\n    proposal_stds = np.array(params['proposal_stds'])\n    N = params['N']\n    B = params['B']\n    seed = params['base_seed'] + params['case_idx']\n\n    # Initialize random number generator with the specified seed\n    rng = np.random.default_rng(seed)\n\n    # --- 1. Generate Synthetic Data ---\n    sigma0_true = true_params['sigma0']\n    A_true = true_params['A']\n    \n    Sigma_true = sigma_attenuation(E, sigma0_true, A_true, Er, gamma)\n    lambda_true = I0 * np.exp(-k * Sigma_true)\n    y = rng.poisson(lambda_true)\n\n    # --- 2. Run Metropolis-Hastings Sampler ---\n    # Initialization\n    theta_current = np.array(prior_means)\n    log_post_current = log_posterior(theta_current, y, E, I0, k, Er, gamma, prior_means, prior_stds)\n\n    samples = np.zeros((N, 2))\n    n_accepted = 0\n\n    for i in range(N):\n        # Propose a new state (random walk)\n        theta_proposal = theta_current + rng.normal(0, proposal_stds)\n\n        # Calculate log posterior for the proposal\n        log_post_proposal = log_posterior(theta_proposal, y, E, I0, k, Er, gamma, prior_means, prior_stds)\n\n        # Acceptance step in log-domain\n        log_r = log_post_proposal - log_post_current\n        log_u = np.log(rng.uniform())\n\n        if log_u  log_r: # Equivalent to log_u  min(0, log_r) as log_u is always negative\n            theta_current = theta_proposal\n            log_post_current = log_post_proposal\n            n_accepted += 1\n        \n        samples[i] = theta_current\n\n    # --- 3. Post-processing ---\n    # Discard burn-in samples\n    post_burn_in_samples = samples[B:]\n\n    # Transform samples from log-space (theta) to original space (sigma0, A)\n    sigma0_samples = np.exp(post_burn_in_samples[:, 0])\n    A_samples = np.exp(post_burn_in_samples[:, 1])\n\n    # Compute posterior means\n    mean_sigma0 = np.mean(sigma0_samples)\n    mean_A = np.mean(A_samples)\n\n    # Compute acceptance rate\n    acceptance_rate = n_accepted / N\n\n    return mean_sigma0, mean_A, acceptance_rate\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}