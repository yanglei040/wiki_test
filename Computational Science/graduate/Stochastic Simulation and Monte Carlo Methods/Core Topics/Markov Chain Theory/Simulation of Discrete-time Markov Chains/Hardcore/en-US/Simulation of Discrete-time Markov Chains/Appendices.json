{
    "hands_on_practices": [
        {
            "introduction": "The foundation of simulating any discrete-time Markov chain is the ability to correctly sample its next state. While the inverse transform method provides a theoretically sound way to sample from a categorical distribution, its real-world implementation is subject to the limitations of floating-point arithmetic. This practice  challenges you to dissect the practical details of this fundamental algorithm, exploring how numerical precision and endpoint handling can impact the correctness of your simulation.",
            "id": "3341578",
            "problem": "Consider a discrete-time Markov chain with finite state space $\\{1,\\dots,n\\}$ and transition probabilities from a given current state encoded by a categorical distribution $(p_1,\\dots,p_n)$ with $p_j \\ge 0$ and $\\sum_{j=1}^n p_j = 1$. Let $F(j) = \\sum_{k=1}^j p_k$ be the cumulative distribution function (CDF) of this categorical distribution on $\\{1,\\dots,n\\}$ in the sense of right-continuous cumulative sums, and let $U \\sim \\mathrm{Uniform}(0,1)$ be independent of the Markov chain. An implementation samples the next state via the inverse transform method by returning $J = \\min\\{j \\in \\{1,\\dots,n\\}: U \\le F(j)\\}$. Assume the implementation uses floating-point arithmetic conforming to Institute of Electrical and Electronics Engineers (IEEE) $754$ binary double precision with rounding to nearest, ties to even. A pseudorandom number generator (PRNG) supplies $U$ as a floating-point number on a finite grid inside $[0,1]$.\n\nWhich of the following statements are correct? Select all that apply.\n\nA. In exact arithmetic with $U \\sim \\mathrm{Uniform}(0,1)$ continuous, the rule $J = \\min\\{j: U \\le F(j)\\}$ produces $\\mathbb{P}(J=j) = p_j$ for all $j \\in \\{1,\\dots,n\\}$.\n\nB. In floating-point arithmetic with naive forward accumulation $S_j = \\mathrm{fl}(S_{j-1} + p_j)$, where $\\mathrm{fl}(\\cdot)$ denotes rounding to nearest, if at some step $j$ the increment $p_j$ is smaller than half the unit in the last place of $S_{j-1}$, then $S_j = S_{j-1}$ and the implemented interval for category $j$ has zero width; consequently, category $j$ is sampled with probability $0$ by the implementation, even though $p_j  0$.\n\nC. Replacing the comparison $U \\le F(j)$ by $U  F(j)$ in the selection rule eliminates all bias due to floating-point summation error in $F(j)$, regardless of the distribution of $(p_1,\\dots,p_n)$.\n\nD. If the PRNG can return $U = 1$ with positive probability, then using the strict inequality selection rule $U  F(j)$ can make the last category $n$ unreachable when $F(n) = 1$ in exact arithmetic; using $U \\le F(n)$ avoids this failure.\n\nE. Sorting $(p_1,\\dots,p_n)$ in decreasing order before forming cumulative sums, and then mapping the sampled index back to the original labels, strictly reduces the worst-case floating-point error in the cumulative thresholds compared to leaving the original order, for all $(p_1,\\dots,p_n)$.\n\nProvide your reasoning from first principles: justify the inverse transform method for categorical sampling from the definition of the cumulative distribution function and properties of the uniform distribution, and explain precisely how finite-precision accumulation and endpoint handling affect correctness of the implemented Markov chain transition sampling.",
            "solution": "The problem statement describes the inverse transform sampling method for a categorical distribution and asks about its properties under exact and finite-precision arithmetic. The problem is scientifically sound, well-posed, and based on established principles of probability theory and numerical analysis. We may proceed with the solution.\n\nFirst, let's establish the principle of the inverse transform method in the context of a discrete distribution on the finite state space $\\{1, \\dots, n\\}$ with probabilities $(p_1, \\dots, p_n)$. The cumulative distribution function (CDF) is given by $F(j) = \\sum_{k=1}^j p_k$ for $j \\in \\{1, \\dots, n\\}$. We define $F(0) = 0$ for convenience. The total probability is $\\sum_{j=1}^n p_j = 1$, so $F(n)=1$. The probability mass for category $j$ is $p_j = F(j) - F(j-1)$ for $j \\ge 1$.\n\nThe sampling rule is $J = \\min\\{j \\in \\{1, \\dots, n\\}: U \\le F(j)\\}$, where $U \\sim \\mathrm{Uniform}(0,1)$. The event $\\{J=j\\}$ occurs if and only if $U \\le F(j)$ and $U  F(k)$ for all $k  j$. Since the function $F$ is non-decreasing, this is equivalent to the event $\\{U  F(j-1) \\text{ and } U \\le F(j)\\}$.\n\nNow we evaluate each statement.\n\n**A. In exact arithmetic with $U \\sim \\mathrm{Uniform}(0,1)$ continuous, the rule $J = \\min\\{j: U \\le F(j)\\}$ produces $\\mathbb{P}(J=j) = p_j$ for all $j \\in \\{1,\\dots,n\\}$.**\n\nAs established above, the event $\\{J=j\\}$ is equivalent to the event $\\{F(j-1)  U \\le F(j)\\}$. The random variable $U$ is drawn from a continuous uniform distribution on $(0,1)$. The probability that $U$ falls within an interval $(a,b] \\subseteq [0,1]$ is given by the length of the interval, $b-a$.\nTherefore, the probability of sampling state $j$ is:\n$$ \\mathbb{P}(J=j) = \\mathbb{P}(F(j-1)  U \\le F(j)) $$\nSince $U$ is a continuous random variable, $\\mathbb{P}(U = x) = 0$ for any specific value $x$. Thus, $\\mathbb{P}(F(j-1)  U \\le F(j))$ is simply the length of the interval $(F(j-1), F(j)]$.\n$$ \\mathbb{P}(J=j) = F(j) - F(j-1) = \\left(\\sum_{k=1}^j p_k\\right) - \\left(\\sum_{k=1}^{j-1} p_k\\right) = p_j $$\nThis holds for all $j \\in \\{1, \\dots, n\\}$.\n**Verdict: Correct.**\n\n**B. In floating-point arithmetic with naive forward accumulation $S_j = \\mathrm{fl}(S_{j-1} + p_j)$, where $\\mathrm{fl}(\\cdot)$ denotes rounding to nearest, if at some step $j$ the increment $p_j$ is smaller than half the unit in the last place of $S_{j-1}$, then $S_j = S_{j-1}$ and the implemented interval for category $j$ has zero width; consequently, category $j$ is sampled with probability $0$ by the implementation, even though $p_j  0$.**\n\nThis statement describes a phenomenon known as absorption or swamping in floating-point addition. Let $S_{j-1}$ be a positive floating-point number. Its unit in the last place, $\\mathrm{ulp}(S_{j-1})$, is the gap between $S_{j-1}$ and the next larger representable floating-point number.\nAccording to the IEEE $754$ standard with rounding to nearest, the result of a floating-point operation is the representable number closest to the exact mathematical result. If the exact result is exactly halfway between two representable numbers, the one with an even least significant bit is chosen.\nIf we compute $S_{j-1} + p_j$, and $p_j  0$, the exact result is greater than $S_{j-1}$. The result will be rounded to $S_{j-1}$ if it is closer to $S_{j-1}$ than to the next representable number, $S_{j-1} + \\mathrm{ulp}(S_{j-1})$. The midpoint between these two is $S_{j-1} + 0.5 \\times \\mathrm{ulp}(S_{j-1})$.\nThe condition given is that $p_j$ is \"smaller than half the unit in the last place of $S_{j-1}$\", which translates to $p_j  0.5 \\times \\mathrm{ulp}(S_{j-1})$.\nUnder this condition, the exact sum $S_{j-1} + p_j$ falls in the interval $(S_{j-1}, S_{j-1} + 0.5 \\times \\mathrm{ulp}(S_{j-1}))$. The closest representable number is $S_{j-1}$.\nThus, $\\mathrm{fl}(S_{j-1} + p_j) = S_{j-1}$.\nLet $\\hat{F}(j)$ denote the computed cumulative sum $S_j$. We have $\\hat{F}(j) = \\hat{F}(j-1)$. The implemented sampling rule checks for $U$ in the interval $(\\hat{F}(j-1), \\hat{F}(j)]$. Since $\\hat{F}(j-1) = \\hat{F}(j)$, this interval is empty. No value of $U$ can satisfy $\\hat{F}(j-1)  U \\le \\hat{F}(j)$. Therefore, the implemented probability of sampling category $j$ is $0$, despite $p_j  0$.\n**Verdict: Correct.**\n\n**C. Replacing the comparison $U \\le F(j)$ by $U  F(j)$ in the selection rule eliminates all bias due to floating-point summation error in $F(j)$, regardless of the distribution of $(p_1,\\dots,p_n)$.**\n\nThe primary source of bias in the floating-point implementation is the inaccuracy of the computed cumulative probabilities, $\\hat{F}(j) = \\mathrm{fl}(\\sum_{k=1}^j p_k)$. Due to rounding errors, the effective length of the sampling interval for category $j$, which is $\\hat{F}(j) - \\hat{F}(j-1)$, is not equal to $p_j$. As shown in the analysis of option B, this difference can be extreme, even causing the interval length to become zero.\nChanging the comparison from $U \\le \\hat{F}(j)$ to $U  \\hat{F}(j)$ modifies the sampling event for category $j$ from $(\\hat{F}(j-1), \\hat{F}(j)]$ to $[\\hat{F}(j-1), \\hat{F}(j))$. Since the PRNG produces $U$ from a discrete set of floating-point numbers, this change only affects which category is chosen when $U$ happens to be exactly equal to one of the boundary points $\\hat{F}(k)$. This is a secondary, and much smaller, source of bias. It does not correct the fundamental problem that the positions of the boundaries $\\hat{F}(j)$ are themselves incorrect. The claim that this change \"eliminates all bias\" is a vast overstatement and is incorrect. The dominant bias from summation error remains.\n**Verdict: Incorrect.**\n\n**D. If the PRNG can return $U = 1$ with positive probability, then using the strict inequality selection rule $U  F(j)$ can make the last category $n$ unreachable when $F(n) = 1$ in exact arithmetic; using $U \\le F(n)$ avoids this failure.**\n\nLet us assume the PRNG can produce the value $U=1$. We analyze the behavior of both rules for this specific outcome, using exact arithmetic for the CDF values as specified ($F(n)=1$).\n\nCase 1: Strict inequality rule $J = \\min\\{j \\in \\{1,\\dots,n\\}: U  F(j)\\}$.\nWhen $U=1$, the condition becomes $1  F(j)$. By definition, $F(j) = \\sum_{k=1}^j p_k$. Since $\\sum_{k=1}^n p_k = 1$, we have $F(j) \\le 1$ for all $j \\in \\{1, \\dots, n\\}$. The condition $1  F(j)$ can never be satisfied for any $j$. The set $\\{j \\in \\{1,\\dots,n\\}: 1  F(j)\\}$ is empty. An implementation of this rule would fail, for example by an out-of-bounds array access after checking all $n$ categories. In any case, it does not select any category.\n\nCase 2: Non-strict inequality rule $J = \\min\\{j \\in \\{1,\\dots,n\\}: U \\le F(j)\\}$.\nWhen $U=1$, the condition is $1 \\le F(j)$.\nFor any $j  n$ where there is some $p_k  0$ for $k  j$, we have $F(j)  1$. The condition $1 \\le F(j)$ is false.\nFor $j=n$, we have $F(n) = 1$. The condition $1 \\le F(n)$ becomes $1 \\le 1$, which is true.\nThus, the smallest (and only) $j$ that satisfies the condition is $j=n$. The algorithm correctly returns $J=n$.\n\nThe statement accurately describes the failure of the strict inequality rule and the success of the non-strict rule when $U=1$ is possible.\n**Verdict: Correct.**\n\n**E. Sorting $(p_1,\\dots,p_n)$ in decreasing order before forming cumulative sums, and then mapping the sampled index back to the original labels, strictly reduces the worst-case floating-point error in the cumulative thresholds compared to leaving the original order, for all $(p_1,\\dots,p_n)$.**\n\nThis statement makes a strong claim about error reduction in floating-point summation. The established principle in numerical analysis for minimizing summation error is to sum the numbers in increasing order of their absolute magnitude. This technique, sometimes called compensated summation although here it's just about ordering, ensures that small numbers are added together first, preserving their significance before they are added to larger running sums where they might be partially or fully lost to rounding (absorption).\nSumming in decreasing order is generally the worst strategy, as it maximizes the potential for absorption of small numbers by the large, running sum.\nThe statement claims that sorting in *decreasing* order *strictly reduces* the worst-case error for *all* possible input vectors $(p_1, \\dots, p_n)$ compared to the original order. This is false. Consider an input vector that is already sorted in increasing order, for instance, $p_1 = 10^{-20}$, $p_2 = 10^{-19}, \\dots, p_n \\approx 1$. The original (increasing) order is close to optimal for summation accuracy. Re-sorting it into decreasing order would lead to the worst-case summation strategy, almost certainly increasing the error. Since the claim is not true for all distributions, it is false.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{ABD}$$"
        },
        {
            "introduction": "Building on the ability to sample single transitions, we can explore the collective behavior of a Markov chain. The concept of coupling, where trajectories starting from different states eventually coalesce, is a powerful tool for analyzing convergence rates. This hands-on exercise  guides you to implement a \"random mapping\" representation to run a synchronous \"grand coupling\" experiment, providing a concrete way to visualize and quantify how quickly a chain forgets its initial conditions.",
            "id": "3341652",
            "problem": "You are given a finite-state, discrete-time Markov chain with state space $\\{0,1,\\ldots,n-1\\}$ and a row-stochastic transition matrix $P \\in \\mathbb{R}^{n \\times n}$, where for each state $i \\in \\{0,1,\\ldots,n-1\\}$, the entries satisfy $P_{ij} \\ge 0$ and $\\sum_{j=0}^{n-1} P_{ij} = 1$. A random mapping representation seeks a measurable function $\\phi(i,u)$ such that, if $(U_t)_{t \\ge 0}$ is an independent and identically distributed sequence of Uniform$(0,1)$ random variables and $(X_t)_{t \\ge 0}$ is defined by $X_{t+1} = \\phi(X_t, U_t)$, then the one-step transitions of $(X_t)$ match $P$, that is, for all $i,j \\in \\{0,\\ldots,n-1\\}$,\n$$\n\\mathbb{P}(X_{t+1} = j \\mid X_t = i) = P_{ij}.\n$$\nYour task is to implement a program that constructs such a function $\\phi(i,u)$ for any given $P$, uses it to simulate chains, and quantifies how sharing the same driving sequence $(U_t)$ across multiple initial states aids coupling.\n\nStarting from the core definitions of a discrete-time Markov chain and a Uniform$(0,1)$ random variable, derive a construction for $\\phi(i,u)$ that guarantees the required transition probabilities. Use this $\\phi$ to implement a synchronous grand coupling: run the chain simultaneously from every initial state in $\\{0,1,\\ldots,n-1\\}$, driven by the same sequence $(U_t)$, and define the evolving set of possible states as $S_0 = \\{0,1,\\ldots,n-1\\}$ and $S_{t+1} = \\{\\phi(i,U_t) : i \\in S_t\\}$. Coupling occurs when $|S_t| = 1$, meaning all trajectories have coalesced.\n\nFor each test case described in the test suite, compute the following two quantities:\n1. The empirical coupling probability within a fixed horizon $T$: the fraction of independent trials in which the grand coupling coalesces by time $T$.\n2. A mapping fidelity metric: for each state $i$, generate $N$ independent samples $U \\sim \\text{Uniform}(0,1)$, map them via $j = \\phi(i,U)$, and form the empirical distribution $\\hat{P}_{i\\cdot}$. Report the maximum absolute deviation $\\max_{i,j} |\\hat{P}_{ij} - P_{ij}|$.\n\nExpress all probabilities as decimals in $[0,1]$.\n\nTest suite:\n- Case A (two-state mixing): $P = \\begin{pmatrix} 0.7  0.3 \\\\ 0.3  0.7 \\end{pmatrix}$ with $M = 5000$ trials, horizon $T = 20$, and $N = 50000$ samples per state for fidelity.\n- Case B (rows identical): $P = \\begin{pmatrix} 0.2  0.8 \\\\ 0.2  0.8 \\end{pmatrix}$ with $M = 3000$, $T = 5$, and $N = 50000$.\n- Case C (identity matrix): $P = I_3 = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix}$ with $M = 3000$, $T = 20$, and $N = 50000$.\n- Case D (near-deterministic cyclic drift): $P = \\begin{pmatrix} 0.95  0.05  0.0 \\\\ 0.0  0.95  0.05 \\\\ 0.05  0.0  0.95 \\end{pmatrix}$ with $M = 5000$, $T = 50$, and $N = 50000$.\n\nUse a fixed random seed of $42$ for reproducibility.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n$$\n[\\text{coupling\\_prob\\_A}, \\text{fidelity\\_error\\_A}, \\text{coupling\\_prob\\_B}, \\text{fidelity\\_error\\_B}, \\text{coupling\\_prob\\_C}, \\text{fidelity\\_error\\_C}, \\text{coupling\\_prob\\_D}, \\text{fidelity\\_error\\_D}].\n$$",
            "solution": "The problem is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. It is a valid problem in the field of stochastic simulation. We proceed with the solution.\n\nThe core of this problem is to construct a function $\\phi(i, u)$ that samples from a discrete probability distribution defined by the rows of a transition matrix $P$ and then to use this function in two distinct simulation experiments: one to measure a fidelity metric and another to analyze grand coupling.\n\nFirst, we address the construction of the random mapping function $\\phi(i, u)$. For a discrete-time Markov chain currently in state $i$, the next state is chosen from the set of all possible states $\\{0, 1, \\ldots, n-1\\}$ according to the probability distribution given by the $i$-th row of the transition matrix $P$. That is, the probability of transitioning to state $j$ is $P_{ij}$. The fundamental requirement for $\\phi(i, u)$, where $U$ is a Uniform$(0,1)$ random variable, is that $\\mathbb{P}(\\phi(i, U) = j) = P_{ij}$ for all $i, j$.\n\nThis is a classic sampling problem that can be solved using the inverse transform sampling method. For a fixed state $i$, we consider the discrete probability distribution $(P_{i0}, P_{i1}, \\ldots, P_{i,n-1})$. We can partition the unit interval $[0,1)$ into $n$ contiguous subintervals, where the length of the $j$-th subinterval is equal to $P_{ij}$. The intervals are $[\\sum_{k=0}^{j-1} P_{ik}, \\sum_{k=0}^{j} P_{ik})$ for $j=0, \\ldots, n-1$, with the convention that the sum is $0$ when the lower limit exceeds the upper limit.\n\nGiven a random number $u \\in [0,1)$, the next state is determined by which subinterval $u$ falls into. This leads to the definition of $\\phi(i,u)$:\n$$\n\\phi(i,u) = j \\quad \\text{if and only if} \\quad \\sum_{k=0}^{j-1} P_{ik} \\le u  \\sum_{k=0}^{j} P_{ik}.\n$$\nThis is equivalent to finding the smallest integer $j$ such that the cumulative probability up to $j$ exceeds or equals $u$. Let $CP$ be the matrix of cumulative probabilities, where $CP_{ij} = \\sum_{k=0}^{j} P_{ik}$. Then the function can be expressed as:\n$$\n\\phi(i,u) = \\min \\{ j \\in \\{0, 1, \\ldots, n-1\\} \\mid CP_{ij} \\ge u \\}.\n$$\nIn implementation, we first compute the cumulative sum matrix $CP$ from $P$. Then, for any given pair $(i,u)$, the value of $\\phi(i,u)$ can be found efficiently using a binary search for $u$ in the $i$-th row of $CP$.\n\nWith $\\phi(i,u)$ defined, we can proceed to the two computational tasks.\n\n1.  **Mapping Fidelity Metric:** This metric quantifies how accurately our implemented sampling function $\\phi(i,u)$ reproduces the target transition probabilities in $P$. The metric is defined as the maximum absolute deviation, $\\max_{i,j} |\\hat{P}_{ij} - P_{ij}|$. To compute this, we perform the following for each initial state $i$:\n    - Generate a large number, $N$, of independent random samples $U_1, U_2, \\ldots, U_N$ from a Uniform$(0,1)$ distribution.\n    - For each sample $U_k$, compute the corresponding next state $J_k = \\phi(i, U_k)$.\n    - The empirical probability $\\hat{P}_{ij}$ is the observed frequency of transitioning to state $j$, calculated as $\\hat{P}_{ij} = \\frac{1}{N} \\sum_{k=1}^N \\mathbb{I}(J_k = j)$, where $\\mathbb{I}(\\cdot)$ is the indicator function.\n    - We calculate the absolute error $| \\hat{P}_{ij} - P_{ij} |$ for all $j \\in \\{0, 1, \\ldots, n-1\\}$ and then take the maximum of these errors over all initial states $i$ and all final states $j$.\n\n2.  **Empirical Coupling Probability:** This experiment involves a synchronous grand coupling. We simulate multiple trajectories of the Markov chain, each starting from a different initial state, but all driven by the *same* sequence of random numbers $(U_t)_{t \\ge 0}$.\n    - Let the set of states occupied by the ensemble of trajectories at time $t$ be $S_t$. We start with $S_0 = \\{0, 1, \\ldots, n-1\\}$, representing that one trajectory starts from each state.\n    - At each time step $t$, we draw a single random number $U_t \\sim \\text{Uniform}(0,1)$.\n    - The set of states at the next time step, $S_{t+1}$, is found by applying the mapping function $\\phi$ with the same $U_t$ to every state currently in $S_t$:\n      $$\n      S_{t+1} = \\{ \\phi(i, U_t) \\mid i \\in S_t \\}.\n      $$\n    - The size of this set, $|S_t|$, is non-increasing. Coupling is said to have occurred when the set coalesces to a single state, i.e., $|S_t| = 1$.\n    - For each test case, we run this simulation $M$ independent times (trials). Each trial runs for a maximum of $T$ time steps.\n    - A trial is considered successful (i.e., coupling occurs) if $|S_t| = 1$ for any time $t \\in \\{1, \\ldots, T\\}$.\n    - The empirical coupling probability is the ratio of the number of successful trials to the total number of trials, $M$.\n\nThe overall algorithm proceeds by iterating through each test case, setting the specified parameters ($P, M, T, N$), initializing a pseudorandom number generator with a fixed seed of $42$ for reproducibility, and then executing the computations for the fidelity metric and the coupling probability as described above. The final results are collected and formatted as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Markov chain coupling and fidelity problem for all test cases.\n    \"\"\"\n    # A fixed random seed of 42 is used for reproducibility.\n    rng = np.random.default_rng(42)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (two-state mixing)\n        {\n            \"P\": np.array([[0.7, 0.3], [0.3, 0.7]]),\n            \"M\": 5000,\n            \"T\": 20,\n            \"N\": 50000,\n        },\n        # Case B (rows identical)\n        {\n            \"P\": np.array([[0.2, 0.8], [0.2, 0.8]]),\n            \"M\": 3000,\n            \"T\": 5,\n            \"N\": 50000,\n        },\n        # Case C (identity matrix)\n        {\n            \"P\": np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]),\n            \"M\": 3000,\n            \"T\": 20,\n            \"N\": 50000,\n        },\n        # Case D (near-deterministic cyclic drift)\n        {\n            \"P\": np.array([[0.95, 0.05, 0.0], [0.0, 0.95, 0.05], [0.05, 0.0, 0.95]]),\n            \"M\": 5000,\n            \"T\": 50,\n            \"N\": 50000,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        P = case[\"P\"]\n        M = case[\"M\"]\n        T = case[\"T\"]\n        N = case[\"N\"]\n\n        n_states = P.shape[0]\n\n        # Pre-compute the cumulative probability matrix for the random mapping function.\n        # CP[i, j] = sum_{k=0 to j} P[i, k]\n        CP = P.cumsum(axis=1)\n\n        # 1. Calculate the mapping fidelity metric\n        max_fidelity_error = 0.0\n        for i in range(n_states):\n            # Generate N uniform random samples\n            u_samples = rng.uniform(size=N)\n            # Map samples to next states using inverse transform sampling\n            # np.searchsorted finds the index of the first element in CP[i] = u\n            next_states = np.searchsorted(CP[i], u_samples)\n            # Count occurrences of each next state\n            counts = np.bincount(next_states, minlength=n_states)\n            # Calculate empirical probabilities\n            p_hat_i = counts / N\n            # Calculate absolute deviation for this row\n            deviation = np.max(np.abs(p_hat_i - P[i]))\n            # Update the maximum deviation found so far\n            if deviation  max_fidelity_error:\n                max_fidelity_error = deviation\n\n        # 2. Calculate the empirical coupling probability\n        coupled_trials = 0\n        for _ in range(M):\n            # Start with all states active_states in the grand coupling\n            active_states = set(range(n_states))\n            has_coupled = False\n            for _ in range(T):\n                # Draw a single uniform random number for the synchronous step\n                u_t = rng.uniform()\n                # Apply the same mapping to all currently active states\n                next_active_states = {np.searchsorted(CP[s], u_t) for s in active_states}\n                active_states = next_active_states\n\n                # Check for coupling (coalescence to a single state)\n                if len(active_states) == 1:\n                    has_coupled = True\n                    break\n            \n            if has_coupled:\n                coupled_trials += 1\n\n        coupling_prob = coupled_trials / M\n\n        results.extend([coupling_prob, max_fidelity_error])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.7f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond simulating dynamics, we can use simulation as an experimental tool to test theoretical properties of a Markov chain. The detailed balance condition, which ensures a chain is reversible with respect to its stationary distribution, is a cornerstone of many algorithms like MCMC. This practice  asks you to design and implement a statistical test based on transition counts from a long simulation, bridging the gap between the abstract theory of reversibility and its empirical verification.",
            "id": "3341611",
            "problem": "Consider a finite-state, time-homogeneous, discrete-time Markov chain $(X_t)_{t \\geq 0}$ with state space $\\mathcal{S} = \\{0,1,\\dots,n-1\\}$ and a transition matrix $P$ of size $n \\times n$, where the entry $P(x,y)$ is the probability of transitioning from state $x$ to state $y$ in one step. A distribution $\\pi$ on $\\mathcal{S}$ is stationary if it satisfies $\\pi = \\pi P$ and has strictly positive components. The chain is called ergodic if it is irreducible and aperiodic, which implies that a unique stationary distribution exists and that the chain converges to stationarity from any starting state. The detailed balance condition with respect to a stationary distribution $\\pi$ is the requirement that $\\pi(x) P(x,y) = \\pi(y) P(y,x)$ for all pairs of states $x,y \\in \\mathcal{S}$.\n\nYour task is to design and implement a simulation-based test of detailed balance grounded in first principles, using counts of directed transitions $x \\to y$ versus $y \\to x$ observed along a simulated trajectory. The test should be constructed as follows: simulate a long trajectory of the chain with a burn-in to approximate stationarity, count the number of transitions $N_{x,y}$ from $x$ to $y$ and $N_{y,x}$ from $y$ to $x$ for each unordered pair $\\{x,y\\}$ with $x  y$, derive a large-sample confidence interval for the deviation in directionality using an appropriate approximation justified from core probabilistic principles, and relate the resulting test to the asymptotic chi-squared paradigm in the case of two categories. You should aggregate the pairwise assessments into summary metrics.\n\nYour program must implement the following steps for each test case below:\n\n- Use a fixed random number generator seed to ensure reproducibility.\n- Compute or approximate a stationary distribution $\\pi$ for the given $P$ by a principled iterative method and sample the initial state $X_0$ from $\\pi$.\n- Simulate $B$ burn-in steps to approach stationarity, then simulate an additional $T$ steps, counting transitions $N_{x,y}$ for all ordered pairs $(x,y)$.\n- For each unordered pair $\\{x,y\\}$ with $xy$, compute the total $M_{x,y} = N_{x,y} + N_{y,x}$ and the deviation $D_{x,y} = N_{x,y} - N_{y,x}$. Based on a large-sample approximation derived from first principles, construct a $95\\%$ confidence interval for the underlying deviation and identify whether the null deviation $0$ lies inside the interval. In addition, for the same pair, compute the corresponding asymptotic chi-squared test statistic with $1$ degree of freedom and the associated $p$-value under the null that the expected counts of $x \\to y$ and $y \\to x$ are equal.\n- Combine results across all unordered pairs with $M_{x,y}  0$ to produce the following summary per test case:\n    1. The number of pairs tested, as an integer.\n    2. The number of pairs detected as significant at level $\\alpha = 0.05$ by the asymptotic chi-squared test, as an integer.\n    3. The maximum chi-squared statistic across tested pairs, as a floating-point number.\n    4. The average $p$-value across tested pairs, as a floating-point number.\n\nUse the following test suite of parameter values. Each test case specifies $(P, T, B, \\text{seed})$ where $P$ is given as a list of lists with entries in $[0,1]$, $T$ is the number of postâ€“burn-in steps, $B$ is the burn-in length, and $\\text{seed}$ is the fixed random number generator seed. All numerical values are exact targets for your implementation.\n\n- Test case $1$ (reversible, long run):\n    - $P = \\begin{bmatrix}\n    0  0.5882352941  0.29411764705  0.11764705882 \\\\\n    0.29411764705  0.26470588235  0.35294117647  0.08823529412 \\\\\n    0.09803921568  0.23529411764  0.50980392156  0.15686274511 \\\\\n    0.029411764705  0.044117647058  0.11764705882  0.80882352941\n    \\end{bmatrix}$\n    - $T = 200000$\n    - $B = 10000$\n    - $\\text{seed} = 12345$\n\n- Test case $2$ (non-reversible ring, long run):\n    - $P = \\begin{bmatrix}\n    0.2  0.6  0  0.2 \\\\\n    0.2  0.2  0.6  0 \\\\\n    0  0.2  0.2  0.6 \\\\\n    0.6  0  0.2  0.2\n    \\end{bmatrix}$\n    - $T = 200000$\n    - $B = 10000$\n    - $\\text{seed} = 314159$\n\n- Test case $3$ (reversible, short run edge case):\n    - $P = \\begin{bmatrix}\n    0  0.5882352941  0.29411764705  0.11764705882 \\\\\n    0.29411764705  0.26470588235  0.35294117647  0.08823529412 \\\\\n    0.09803921568  0.23529411764  0.50980392156  0.15686274511 \\\\\n    0.029411764705  0.044117647058  0.11764705882  0.80882352941\n    \\end{bmatrix}$\n    - $T = 2000$\n    - $B = 1000$\n    - $\\text{seed} = 271828$\n\n- Test case $4$ (reversible with sparse transitions):\n    - $P = \\begin{bmatrix}\n    0.8729166667  0.1041666667  0.0208333333  0.0020833333 \\\\\n    0.1388888889  0.8  0.0555555556  0.0055555556 \\\\\n    0.0416666667  0.0833333333  0.8541666667  0.0208333333 \\\\\n    0.0083333333  0.0166666667  0.0416666667  0.9333333333\n    \\end{bmatrix}$\n    - $T = 10000$\n    - $B = 1000$\n    - $\\text{seed} = 161803$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case and is itself a Python-style list $[n_{\\text{pairs}}, n_{\\text{sig}}, \\max\\_{\\chi^2}, \\overline{p}]$, in that order. For example, the overall output format must be exactly like $[[\\dots],[\\dots],[\\dots],[\\dots]]$ with no extra text. All values must be computed numerically by simulation as described, and the $p$-values must be those of the asymptotic chi-squared test with $1$ degree of freedom evaluated at the observed per-pair statistic. No physical units or angles are involved, and any significance level must be specified as a decimal; use $\\alpha = 0.05$ throughout. The test suite is designed to cover a general case, a violation case, a short-run edge case, and a sparse-transition boundary case. The correctness of your program will be evaluated based on the numerical output for the given test suite, not on symbolic steps.",
            "solution": "The user-provided problem is valid. It is scientifically grounded in the theory of Markov chains and statistical hypothesis testing, is well-posed with a clear objective and sufficient data, and uses objective, formal language. The problem is a standard exercise in computational statistics and presents no contradictions, ambiguities, or pseudo-profound aspects.\n\nHerein, a complete solution is developed based on first principles. The objective is to test the detailed balance condition for a discrete-time Markov chain (DTMC) using data from a simulated trajectory.\n\nA finite-state, time-homogeneous DTMC $(X_t)_{t \\geq 0}$ on state space $\\mathcal{S} = \\{0, 1, \\dots, n-1\\}$ with transition matrix $P$ is said to be reversible, or satisfy the detailed balance condition, with respect to a distribution $\\pi$ if, for all states $x, y \\in \\mathcal{S}$:\n$$ \\pi(x) P(x,y) = \\pi(y) P(y,x) $$\nThis condition implies that $\\pi$ is a stationary distribution, i.e., $\\pi = \\pi P$. For an ergodic chain (irreducible and aperiodic), this stationary distribution is unique and has strictly positive components. The detailed balance condition implies that the rate of flow from state $x$ to $y$ is equal to the rate of flow from $y$ to $x$ when the chain is in its stationary state.\n\nThe simulation-based test proceeds in several steps:\n\n**1. Approximation of the Stationary Distribution**\nThe stationary distribution $\\pi$ is a left eigenvector of the transition matrix $P$ corresponding to the eigenvalue $\\lambda=1$. It can be found by solving the linear system $\\pi P = \\pi$ subject to the constraint $\\sum_{i \\in \\mathcal{S}} \\pi(i) = 1$. A robust and common numerical method to find $\\pi$ is the power iteration method. Starting with an arbitrary initial probability vector $\\pi_0$ (e.g., the uniform distribution $\\pi_0(i) = 1/n$ for all $i$), we iteratively apply the transition matrix:\n$$ \\pi_{k+1} = \\pi_k P $$\nFor an ergodic chain, this process is guaranteed to converge to the unique stationary distribution $\\pi$ as $k \\to \\infty$. In practice, the iteration is stopped after a fixed number of steps or when the change $||\\pi_{k+1} - \\pi_k||$ falls below a small tolerance.\n\n**2. Simulation of the Markov Chain Trajectory**\nThe simulation generates a path $X_0, X_1, X_2, \\dots$ of the Markov chain.\n- **Initialization**: The initial state $X_0$ is sampled from the approximated stationary distribution $\\pi$. This helps to start the chain in a state that is representative of its long-term behavior.\n- **Burn-in**: The first $B$ steps of the chain are simulated and discarded. This burn-in period allows the chain to \"forget\" its initial state and converge to its stationary regime, mitigating any minor inaccuracies in the computed $\\pi$.\n- **Data Collection**: Following the burn-in, the subsequent $T$ transitions are recorded. An $n \\times n$ matrix of counts, $N$, is maintained, where $N_{x,y}$ stores the number of times a transition from state $x$ to $y$ is observed.\n\n**3. Statistical Test of Detailed Balance**\nThe core of the test lies in analyzing the transition counts $N_{x,y}$ for each unordered pair of states $\\{x, y\\}$.\nIn a long trajectory of length $T$ from a chain in stationarity, the number of visits to a state $i$ is approximately $T \\pi(i)$. Consequently, the expected number of transitions from $x$ to $y$ is $E[N_{x,y}] \\approx T \\pi(x) P(x,y)$. Similarly, $E[N_{y,x}] \\approx T \\pi(y) P(y,x)$.\n\nUnder the null hypothesis $H_0$ that detailed balance holds, $\\pi(x) P(x,y) = \\pi(y) P(y,x)$, which implies $E[N_{x,y}] = E[N_{y,x}]$.\n\nNow, consider the total number of transitions observed between states $x$ and $y$, denoted $M_{x,y} = N_{x,y} + N_{y,x}$. Conditional on this total $M_{x,y}$, each of these transitions was either $x \\to y$ or $y \\to x$. Under $H_0$, the probability of a specific one of these transitions being $x \\to y$ is $p = 1/2$. Thus, we can model the count $N_{x,y}$ as a random variable from a binomial distribution, conditional on the total $M_{x,y}$:\n$$ N_{x,y} | M_{x,y} \\sim \\text{Binomial}(M_{x,y}, p=1/2) $$\nThis model is valid under the assumption that the successive transitions between $x$ and $y$ are approximately independent, which is reasonable for a long, mixing trajectory.\n\nFor a large number of total transitions $M_{x,y}$, the binomial distribution can be approximated by a normal distribution:\n$$ N_{x,y} \\sim \\mathcal{N}\\left(\\mu = \\frac{M_{x,y}}{2}, \\sigma^2 = \\frac{M_{x,y}}{4}\\right) $$\nThe deviation statistic is $D_{x,y} = N_{x,y} - N_{y,x} = N_{x,y} - (M_{x,y} - N_{x,y}) = 2N_{x,y} - M_{x,y}$. Its properties under the normal approximation are:\n- Expected value: $E[D_{x,y}] = 2 E[N_{x,y}] - M_{x,y} = 2(M_{x,y}/2) - M_{x,y} = 0$.\n- Variance: $\\text{Var}(D_{x,y}) = \\text{Var}(2N_{x,y}) = 4 \\text{Var}(N_{x,y}) = 4(M_{x,y}/4) = M_{x,y}$.\n\nThis leads to a standardized test statistic $Z_{x,y}$ which follows a standard normal distribution under $H_0$:\n$$ Z_{x,y} = \\frac{D_{x,y} - E[D_{x,y}]}{\\sqrt{\\text{Var}(D_{x,y})}} = \\frac{D_{x,y}}{\\sqrt{M_{x,y}}} \\sim \\mathcal{N}(0,1) $$\nA $95\\%$ confidence interval for the mean of the deviation (which is $0$ under $H_0$) is derived from this. We can test $H_0$ by checking if the observed $D_{x,y}$ is plausible. The null hypothesis is rejected at significance level $\\alpha$ if $|Z_{x,y}|  Z_{1-\\alpha/2}$, where $Z_{1-\\alpha/2}$ is the critical value of the standard normal distribution (e.g., $1.96$ for $\\alpha=0.05$).\n\nThis test is directly related to the Pearson's chi-squared test for goodness-of-fit. For the two categories of transitions ($x \\to y$ and $y \\to x$), the observed counts are $O_1 = N_{x,y}$ and $O_2 = N_{y,x}$. The expected counts under $H_0$ are $E_1 = E_2 = M_{x,y}/2$. The chi-squared statistic is:\n$$ \\chi^2_{x,y} = \\sum_{i=1}^{2} \\frac{(O_i - E_i)^2}{E_i} = \\frac{(N_{x,y} - M_{x,y}/2)^2}{M_{x,y}/2} + \\frac{(N_{y,x} - M_{x,y}/2)^2}{M_{x,y}/2} $$\nSubstituting $N_{y,x} = M_{x,y} - N_{x,y}$, we find this simplifies to:\n$$ \\chi^2_{x,y} = \\frac{(2N_{x,y} - M_{x,y})^2}{M_{x,y}} = \\frac{D_{x,y}^2}{M_{x,y}} = (Z_{x,y})^2 $$\nThis statistic follows a chi-squared distribution with $k-1=2-1=1$ degree of freedom. This asymptotic result provides a way to calculate a $p$-value for each pair $\\{x,y\\}$, representing the probability of observing a deviation at least as large as the one measured, assuming the null hypothesis of detailed balance is true.\n\n**4. Aggregation of Results**\nThe pairwise tests are performed for every unordered pair of states $\\{x, y\\}$ for which at least one transition was observed (i.e., $M_{x,y}  0$). The results are then aggregated into four summary metrics for each test case:\n1.  **$n_{\\text{pairs}}$**: The total number of pairs $\\{x,y\\}$ tested (i.e., where $M_{x,y}  0$).\n2.  **$n_{\\text{sig}}$**: The number of tested pairs for which the null hypothesis of detailed balance is rejected at the $\\alpha = 0.05$ significance level (i.e., $p$-value $ 0.05$).\n3.  **$\\max_{\\chi^2}$**: The maximum chi-squared statistic observed among all tested pairs.\n4.  **$\\overline{p}$**: The arithmetic mean of the $p$-values calculated for all tested pairs.\n\nThis procedure provides a comprehensive, simulation-based assessment of the detailed balance property of the given Markov chain.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and analysis for all test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1 (reversible, long run)\n        (\n            [\n                [0.0, 0.5882352941, 0.29411764705, 0.11764705882],\n                [0.29411764705, 0.26470588235, 0.35294117647, 0.08823529412],\n                [0.09803921568, 0.23529411764, 0.50980392156, 0.15686274511],\n                [0.029411764705, 0.044117647058, 0.11764705882, 0.80882352941]\n            ],\n            200000, 10000, 12345\n        ),\n        # Test case 2 (non-reversible ring, long run)\n        (\n            [\n                [0.2, 0.6, 0.0, 0.2],\n                [0.2, 0.2, 0.6, 0.0],\n                [0.0, 0.2, 0.2, 0.6],\n                [0.6, 0.0, 0.2, 0.2]\n            ],\n            200000, 10000, 314159\n        ),\n        # Test case 3 (reversible, short run edge case)\n        (\n            [\n                [0.0, 0.5882352941, 0.29411764705, 0.11764705882],\n                [0.29411764705, 0.26470588235, 0.35294117647, 0.08823529412],\n                [0.09803921568, 0.23529411764, 0.50980392156, 0.15686274511],\n                [0.029411764705, 0.044117647058, 0.11764705882, 0.80882352941]\n            ],\n            2000, 1000, 271828\n        ),\n        # Test case 4 (reversible with sparse transitions)\n        (\n             [\n                [0.8729166667, 0.1041666667, 0.0208333333, 0.0020833333],\n                [0.1388888889, 0.8, 0.0555555556, 0.0055555556],\n                [0.0416666667, 0.0833333333, 0.8541666667, 0.0208333333],\n                [0.0083333333, 0.0166666667, 0.0416666667, 0.9333333333]\n             ],\n            10000, 1000, 161803\n        )\n    ]\n\n    results = [run_test_case(*case) for case in test_cases]\n    \n    # Custom formatting to match the python-style list of lists string representation\n    formatted_results = [f\"[{res[0]}, {res[1]}, {res[2]:.10f}, {res[3]:.10f}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef run_test_case(P_list, T, B, seed):\n    \"\"\"\n    Runs a single test case for the detailed balance simulation.\n    \n    Args:\n        P_list (list): The transition matrix as a list of lists.\n        T (int): Number of post-burn-in simulation steps.\n        B (int): Number of burn-in steps.\n        seed (int): The seed for the random number generator.\n\n    Returns:\n        list: A list containing [n_pairs, n_sig, max_chi2, avg_p].\n    \"\"\"\n    P = np.array(P_list, dtype=np.float64)\n    n = P.shape[0]\n    rng = np.random.default_rng(seed)\n    \n    # 1. Compute stationary distribution via power iteration\n    pi = np.ones(n) / n\n    for _ in range(1000): # Sufficient iterations for convergence for small matrices\n        pi = pi @ P\n        pi /= np.sum(pi)\n\n    # 2. Simulate the Markov chain\n    # Sample initial state\n    current_state = rng.choice(n, p=pi)\n    \n    # Burn-in period\n    for _ in range(B):\n        row_probs = P[current_state]\n        current_state = rng.choice(n, p=row_probs)\n        \n    # Simulation and transition counting\n    counts = np.zeros((n, n), dtype=np.int64)\n    for _ in range(T):\n        row_probs = P[current_state]\n        next_state = rng.choice(n, p=row_probs)\n        counts[current_state, next_state] += 1\n        current_state = next_state\n\n    # 3. Analyze transition counts for each pair {x, y}\n    chi2_stats = []\n    p_values = []\n    alpha = 0.05\n    \n    for x in range(n):\n        for y in range(x + 1, n):\n            N_xy = counts[x, y]\n            N_yx = counts[y, x]\n            M_xy = N_xy + N_yx\n            \n            if M_xy  0:\n                # D_xy = N_xy - N_yx\n                # chi2_stat = D_xy**2 / M_xy\n                # A more numerically stable calculation for the chi-squared statistic\n                # (O1-E1)^2/E1 + (O2-E2)^2/E2 where E1=E2=M/2\n                # = (N_xy - M_xy/2)^2 / (M_xy/2) * 2\n                chi2_stat = 2 * (N_xy - M_xy / 2)**2 / (M_xy / 2) if M_xy > 0 else 0\n                p_val = chi2.sf(chi2_stat, 1) # Survival function for 1 dof\n                \n                chi2_stats.append(chi2_stat)\n                p_values.append(p_val)\n                \n    # 4. Aggregate results\n    if not chi2_stats: # Handle case with no tested pairs\n        n_pairs = 0\n        n_sig = 0\n        max_chi2 = 0.0\n        avg_p = 0.0\n    else:\n        chi2_stats_arr = np.array(chi2_stats)\n        p_values_arr = np.array(p_values)\n        \n        n_pairs = len(chi2_stats)\n        n_sig = int(np.sum(p_values_arr  alpha))\n        max_chi2 = float(np.max(chi2_stats_arr))\n        avg_p = float(np.mean(p_values_arr))\n\n    return [n_pairs, n_sig, max_chi2, avg_p]\n\nsolve()\n```"
        }
    ]
}