{
    "hands_on_practices": [
        {
            "introduction": "This problem is a fundamental exercise in applying the definition of periodicity directly to a transition matrix. By analyzing a Markov chain with a clear bipartite structure, you will practice calculating the period of each state and verifying the chain's irreducibility (). This hands-on calculation solidifies the connection between the algebraic properties of the transition matrix $P^n$ and the graphical structure of the state space, which is the foundation for understanding more complex chain behaviors.",
            "id": "3329415",
            "problem": "Consider a time-homogeneous, discrete-time Markov chain with state space $\\{1,2,3,4\\}$ and transition matrix $P \\in \\mathbb{R}^{4 \\times 4}$ given by\n$$\nP \\;=\\;\n\\begin{pmatrix}\n0  \\frac{1}{3}  0  \\frac{2}{3} \\\\\n\\frac{1}{2}  0  \\frac{1}{2}  0 \\\\\n0  \\frac{3}{5}  0  \\frac{2}{5} \\\\\n\\frac{1}{4}  0  \\frac{3}{4}  0\n\\end{pmatrix}.\n$$\nThe structure of $P$ has zeros on the diagonal and positive off-diagonal entries that alternate between two partitions, creating a bipartite interaction pattern: states $\\{1,3\\}$ transition only to states $\\{2,4\\}$ and conversely. Using only foundational definitions from Markov chain theory and without invoking shortcut results, determine the period of each state and verify whether the chain is irreducible. Begin from the definition of period $d(i)$ of a state $i$ as the greatest common divisor of the set $\\{n \\geq 1 : (P^{n})_{ii}  0\\}$, and the definition of irreducibility as the property that for every pair of states $i,j$ there exists $n \\geq 1$ with $(P^{n})_{ij}  0$.\n\nExpress the final answer as a single row matrix using the LaTeX $\\texttt{pmatrix}$ environment with five entries: the four periods in the state order $(1,2,3,4)$ followed by an indicator $I$ that equals $1$ if the chain is irreducible and $0$ otherwise. No rounding is required.",
            "solution": "We start from the fundamental definitions for Markov chains. For a time-homogeneous Markov chain with transition matrix $P$, the period $d(i)$ of a state $i$ is defined by\n$$\nd(i) \\;=\\; \\gcd\\big\\{ n \\geq 1 : (P^{n})_{ii}  0 \\big\\}.\n$$\nThe chain is irreducible if and only if for all states $i,j$ there exists $n \\geq 1$ such that $(P^{n})_{ij}  0$.\n\nWe analyze the structure of $P$. The nonzero entries of $P$ satisfy\n- for states $1$ and $3$, transitions occur only to states $2$ and $4$,\n- for states $2$ and $4$, transitions occur only to states $1$ and $3$,\n- all diagonal entries satisfy $(P)_{ii} = 0$.\n\nThis induces a bipartition of the state space into $A = \\{1,3\\}$ and $B = \\{2,4\\}$, and every single step alternates between $A$ and $B$. Consequently, any path starting and ending in the same state must have even length. In particular, for any state $i$, $(P^{n})_{ii} = 0$ for all odd $n$. Therefore, possible return times belong to the set of even integers.\n\nTo demonstrate that $(P^{2})_{ii}  0$ for each $i$, we compute $P^{2} = P \\cdot P$ explicitly. Because of the bipartite structure, $(P^{2})$ has nonzero entries only between states within the same partition. We compute the diagonal entries:\n- For $i = 1$,\n$$\n(P^{2})_{11} = P_{12} P_{21} + P_{14} P_{41} = \\frac{1}{3} \\cdot \\frac{1}{2} + \\frac{2}{3} \\cdot \\frac{1}{4} = \\frac{1}{6} + \\frac{1}{6} = \\frac{1}{3}.\n$$\n- For $i = 2$,\n$$\n(P^{2})_{22} = P_{21} P_{12} + P_{23} P_{32} = \\frac{1}{2} \\cdot \\frac{1}{3} + \\frac{1}{2} \\cdot \\frac{3}{5} = \\frac{1}{6} + \\frac{3}{10} = \\frac{7}{15}.\n$$\n- For $i = 3$,\n$$\n(P^{2})_{33} = P_{32} P_{23} + P_{34} P_{43} = \\frac{3}{5} \\cdot \\frac{1}{2} + \\frac{2}{5} \\cdot \\frac{3}{4} = \\frac{3}{10} + \\frac{3}{10} = \\frac{3}{5}.\n$$\n- For $i = 4$,\n$$\n(P^{2})_{44} = P_{41} P_{14} + P_{43} P_{34} = \\frac{1}{4} \\cdot \\frac{2}{3} + \\frac{3}{4} \\cdot \\frac{2}{5} = \\frac{1}{6} + \\frac{3}{10} = \\frac{7}{15}.\n$$\nThus, $(P^{2})_{ii}  0$ for all $i \\in \\{1,2,3,4\\}$.\n\nNext, note that for all odd $n$, $(P^{n})_{ii} = 0$ because one step moves from $A$ to $B$ or $B$ to $A$, and hence returning to the same state requires an even number of steps. For $n = 2$, we have shown $(P^{2})_{ii}  0$; for $n = 4$, we have $(P^{4}) = (P^{2})^{2}$ and the same within-partition positivity implies $(P^{4})_{ii} \\geq (P^{2})_{ii}^{2}  0$, and similarly for any even $n$ by iterating two-step transitions. Therefore, the set of return times to state $i$ includes all even integers greater than or equal to $2$, and it excludes all odd integers. The greatest common divisor of the set $\\{2,4,6,\\dots\\}$ is $2$. Hence, for each $i \\in \\{1,2,3,4\\}$,\n$$\nd(i) \\;=\\; 2.\n$$\n\nWe now verify irreducibility. We must show that for any states $i,j$ there exists $n \\geq 1$ such that $(P^{n})_{ij}  0$.\n- If $i \\in A$ and $j \\in B$ (or vice versa), $(P)_{ij}  0$ directly by inspection of $P$: for example, $(P)_{12} = \\frac{1}{3}  0$, $(P)_{14} = \\frac{2}{3}  0$, $(P)_{32} = \\frac{3}{5}  0$, $(P)_{34} = \\frac{2}{5}  0$, and similarly for transitions from $B$ to $A$.\n- If $i,j$ lie in the same partition, then $(P^{2})_{ij}  0$. For instance, $(P^{2})_{13} = P_{12} P_{23} + P_{14} P_{43} = \\frac{1}{3} \\cdot \\frac{1}{2} + \\frac{2}{3} \\cdot \\frac{3}{4} = \\frac{1}{6} + \\frac{1}{2} = \\frac{2}{3}  0$, and $(P^{2})_{24} = P_{21} P_{14} + P_{23} P_{34} = \\frac{1}{2} \\cdot \\frac{2}{3} + \\frac{1}{2} \\cdot \\frac{2}{5} = \\frac{1}{3} + \\frac{1}{5} = \\frac{8}{15}  0$. Analogous computations show positivity for other same-partition pairs.\n\nTherefore, for every pair $i,j$, there exists $n \\in \\{1,2\\}$ with $(P^{n})_{ij}  0$. This proves the chain is irreducible.\n\nCollecting the results, the periods in the state order $(1,2,3,4)$ are all equal to $2$, and the irreducibility indicator $I$ equals $1$.\n\nThe requested final answer is the row matrix with entries $\\big(d(1), d(2), d(3), d(4), I\\big) = (2,2,2,2,1)$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 2  2  2  2  1 \\end{pmatrix}}$$"
        },
        {
            "introduction": "This exercise demonstrates the profound impact of a small modification to a Markov chain's dynamics on its periodic properties and convergence speed. You will start with a simple deterministic cycle, a canonical example of a periodic chain, and then analyze how introducing a stochastic \"reset\" mechanism renders the chain aperiodic (). By deriving the chain's eigenvalues and relaxation time, this practice illuminates the crucial link between aperiodicity and faster convergence to the stationary distribution, a key goal in MCMC methods.",
            "id": "3329433",
            "problem": "Consider a discrete-time Markov chain on the finite state space $\\{0,1,\\dots,m-1\\}$ identified with the cyclic group $\\mathbb{Z}_{m}$. Let the baseline dynamics be deterministic rotation: from state $x$ the chain transitions to $x+1 \\bmod m$ with probability $1$. This baseline chain is then modified by introducing a stochastic reset to the distinguished state $0$: at each step, from any current state $x$, with probability $\\epsilon \\in (0,1)$ the chain moves to $0$, and with probability $1-\\epsilon$ it moves to $x+1 \\bmod m$. Denote the transition matrix of the baseline chain by $S$ and that of the modified chain by $P$.\n\nUse the following fundamental definitions and facts:\n- A discrete-time Markov chain is specified by a transition matrix $P$ with nonnegative entries and rows summing to $1$, describing the probabilities of moving between states.\n- The period $d(i)$ of a state $i$ is defined by $d(i) = \\gcd\\{n \\geq 1 : (P^{n})_{ii}  0\\}$, where $(P^{n})_{ii}$ is the $i,i$ entry of the $n$-step transition matrix $P^{n}$. In an irreducible chain, all states share the same period.\n- The relaxation time $\\tau_{\\mathrm{rel}}$ is defined through the Second Largest Eigenvalue Modulus (SLEM): if $1=\\lambda_{1}$ is the Perron root of $P$, then $\\tau_{\\mathrm{rel}} = \\frac{1}{1 - \\max\\{|\\lambda| : \\lambda \\in \\mathrm{spec}(P), \\lambda \\neq 1\\}}$, assuming diagonalizability or, more generally, interpreting $\\max\\{|\\lambda| : \\lambda \\neq 1\\}$ as the modulus of the subdominant eigenvalue of $P$.\n\nTasks:\n1. For the baseline deterministic rotation chain $S$ (i.e., with $\\epsilon = 0$), determine the period $d(i)$ for any state $i \\in \\mathbb{Z}_{m}$.\n2. For the modified chain $P$ with $\\epsilon \\in (0,1)$, prove irreducibility and determine the period $d(i)$ for any state $i \\in \\mathbb{Z}_{m}$.\n3. For the modified chain $P$, derive the full set of eigenvalues of $P$ and from them compute the relaxation time $\\tau_{\\mathrm{rel}}$ as an explicit function of $\\epsilon$ and $m$.\n\nProvide the final answer as a single row matrix containing three entries in the order: the baseline period, the modified period, and the modified relaxation time. No approximation or rounding is required, and no physical units are involved.",
            "solution": "The problem asks for an analysis of two discrete-time Markov chains on the state space $\\mathbb{Z}_m = \\{0, 1, \\dots, m-1\\}$. We will address the three tasks in sequence after validating the problem setup.\n\nThe problem statement is well-defined, mathematically sound, and self-contained. The definitions of period and relaxation time are standard in the theory of Markov chains. The description of the modified chain's dynamics is unambiguous under the constraint that transition probabilities from any state must sum to unity. For any state $x \\in \\{0, 1, \\dots, m-2\\}$, the two potential next states, $0$ and $x+1$, are distinct. Thus, the transitions are $x \\to 0$ with probability $\\epsilon$ and $x \\to x+1$ with probability $1-\\epsilon$. For the state $x=m-1$, the next state under deterministic rotation is $(m-1)+1 \\pmod m = 0$. In this case, both mechanisms—reset and rotation—lead to the same state $0$. The total probability of transitioning from $m-1$ to $0$ is therefore $\\epsilon + (1-\\epsilon) = 1$. The problem is therefore valid.\n\n**Task 1: Period of the baseline chain S**\n\nThe baseline chain is a deterministic rotation on $\\mathbb{Z}_m$. From any state $i$, the chain moves to state $i+1 \\pmod m$ with probability $1$. This is a simple cycle $0 \\to 1 \\to \\dots \\to m-1 \\to 0$.\n\nThe period of a state $i$, denoted $d(i)$, is given by $d(i) = \\gcd\\{n \\geq 1 : (S^n)_{ii}  0\\}$, where $(S^n)_{ii}$ is the probability of returning to state $i$ in exactly $n$ steps.\n\nFor this deterministic cycle, starting from state $i$, the state of the chain after $n$ steps is $i+n \\pmod m$. For the chain to return to state $i$, we must have $i+n \\equiv i \\pmod m$, which simplifies to $n \\equiv 0 \\pmod m$. This means $n$ must be a multiple of $m$.\n\nThe set of possible return times to any state $i$ is $\\{m, 2m, 3m, \\dots\\}$. The period is the greatest common divisor (GCD) of this set.\n$$\nd(i) = \\gcd(\\{m, 2m, 3m, \\dots\\}) = m\n$$\nSince this holds for a single cycle, all states are in a single communicating class, and they all share the same period. Thus, the period of any state $i$ is $m$.\n\n**Task 2: Irreducibility and period of the modified chain P**\n\nThe modified chain has transitions defined as follows: from state $x$, the chain moves to $0$ with probability $\\epsilon \\in (0,1)$ and to $x+1 \\pmod m$ with probability $1-\\epsilon$. As established during validation, for $x=m-1$, the transition is to state $0$ with probability $1$.\n\nTo prove irreducibility, we must show that it is possible to go from any state $i$ to any state $j$ in a finite number of steps with positive probability.\n1.  From any state $i \\in \\{0, 1, \\dots, m-2\\}$, there is a transition to state $0$ with probability $P_{i0} = \\epsilon  0$. From state $m-1$, the transition to $0$ occurs with probability $P_{m-1,0}=1  0$. Therefore, state $0$ is reachable from any state $i \\in \\mathbb{Z}_m$.\n2.  From state $0$, we can reach state $1$ with probability $P_{01}=1-\\epsilon  0$. From state $1$, we can reach state $2$ with probability $P_{12}=1-\\epsilon  0$. By induction, we can reach any state $j \\in \\{1, \\dots, m-1\\}$ from state $0$ by taking $j$ consecutive \"rotate\" steps ($0 \\to 1 \\to \\dots \\to j$). The probability of this path is $(1-\\epsilon)^j  0$. State $0$ can reach itself with probability $P_{00}=\\epsilon  0$. Therefore, state $0$ can reach any state $j \\in \\mathbb{Z}_m$.\n\nCombining these two points, any state $i$ can reach any other state $j$ by first transitioning to state $0$ (which is always possible) and then from state $0$ to state $j$. Thus, the Markov chain is irreducible.\n\nFor an irreducible chain, all states share the same period $d$. We can compute the period for state $0$. We need to find $d(0) = \\gcd\\{n \\geq 1 : (P^n)_{00}  0\\}$.\nThe transition probability from state $0$ to itself in one step is $P_{00} = \\epsilon$. Since $\\epsilon \\in (0,1)$, we have $P_{00}  0$.\nThis means that $n=1$ is a possible return time for state $0$. The set of return times $\\{n \\geq 1: (P^n)_{00}0\\}$ contains the integer $1$. The greatest common divisor of any set of positive integers that includes $1$ is $1$.\nTherefore, $d(0) = \\gcd(\\{1, \\dots\\}) = 1$.\nSince the chain is irreducible, the period of every state is $d(i)=1$. A chain with period $1$ is called aperiodic.\n\n**Task 3: Eigenvalues and relaxation time of the modified chain P**\n\nThe transition matrix $P$ for the modified chain is:\n$$\nP_{ij} =\n\\begin{cases}\n\\epsilon  \\text{if } j=0, i \\in \\{0, \\dots, m-2\\} \\\\\n1-\\epsilon  \\text{if } j=i+1, i \\in \\{0, \\dots, m-2\\} \\\\\n1  \\text{if } j=0, i=m-1 \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nLet $v = (v_0, v_1, \\dots, v_{m-1})^T$ be an eigenvector of $P$ with eigenvalue $\\lambda$. The eigenvalue equation $Pv = \\lambda v$ gives the following system of linear equations:\nFor $i \\in \\{0, 1, \\dots, m-2\\}$: $\\epsilon v_0 + (1-\\epsilon)v_{i+1} = \\lambda v_i$.\nFor $i=m-1$: $v_0 = \\lambda v_{m-1}$.\n\nFrom the general equation for $i \\in \\{0, \\dots, m-2\\}$, we can write a recurrence relation for the components of the eigenvector:\n$v_{i+1} = \\frac{\\lambda v_i - \\epsilon v_0}{1-\\epsilon}$.\nThis is a first-order linear non-homogeneous recurrence relation for $v_i$.\nLet's analyze the case $\\lambda-1+\\epsilon = 0$, i.e., $\\lambda = 1-\\epsilon$. The recurrence becomes $v_{i+1} - v_i = -\\frac{\\epsilon v_0}{1-\\epsilon}$. This describes an arithmetic progression. The solution is $v_i = v_0 - i \\frac{\\epsilon v_0}{1-\\epsilon}$. Using the last equation of the system, $v_0 = \\lambda v_{m-1} = (1-\\epsilon)v_{m-1}$, we get $v_0 = (1-\\epsilon) \\left(v_0 - (m-1)\\frac{\\epsilon v_0}{1-\\epsilon}\\right)$. Assuming $v_0 \\neq 0$, we have $1 = (1-\\epsilon) - (m-1)\\epsilon = 1 - m\\epsilon$. This implies $m\\epsilon=0$, which is impossible as $m \\geq 1$ and $\\epsilon  0$. Thus, $\\lambda=1-\\epsilon$ is not an eigenvalue.\n\nFor $\\lambda \\neq 1-\\epsilon$, the solution to the recurrence is of the form $v_i = A r^i + C$, where $r = \\frac{\\lambda}{1-\\epsilon}$ is the root of the characteristic equation of the homogeneous part and $C$ is a particular solution. We find $C = \\frac{\\epsilon v_0}{\\lambda-1+\\epsilon}$. The constant $A$ is determined by the initial condition at $i=0$: $v_0 = A+C$, which gives $A = v_0 - C = v_0\\left(1-\\frac{\\epsilon}{\\lambda-1+\\epsilon}\\right) = v_0\\frac{\\lambda-1}{\\lambda-1+\\epsilon}$.\nSo, the general solution for the eigenvector components is:\n$$\nv_i = v_0 \\frac{\\lambda-1}{\\lambda-1+\\epsilon} \\left(\\frac{\\lambda}{1-\\epsilon}\\right)^i + v_0 \\frac{\\epsilon}{\\lambda-1+\\epsilon}\n$$\nThis must also satisfy the last equation from the system, $v_0 = \\lambda v_{m-1}$. Substituting $i=m-1$ and dividing by $v_0$ (assuming $v_0 \\neq 0$):\n$$\n1 = \\lambda \\left[ \\frac{\\lambda-1}{\\lambda-1+\\epsilon} \\left(\\frac{\\lambda}{1-\\epsilon}\\right)^{m-1} + \\frac{\\epsilon}{\\lambda-1+\\epsilon} \\right]\n$$\nMultiplying by $\\lambda-1+\\epsilon$:\n$$\n\\lambda-1+\\epsilon = \\lambda (\\lambda-1) \\left(\\frac{\\lambda}{1-\\epsilon}\\right)^{m-1} + \\lambda\\epsilon\n$$\n$$\n(\\lambda-1) - \\epsilon(\\lambda-1) = (\\lambda-1) \\frac{\\lambda^m}{(1-\\epsilon)^{m-1}}\n$$\n$$\n(\\lambda-1)(1-\\epsilon) = (\\lambda-1) \\frac{\\lambda^m}{(1-\\epsilon)^{m-1}}\n$$\nThis equation has two types of solutions.\nFirst, if $\\lambda-1 = 0$, then $\\lambda=1$. This is the Perron-Frobenius eigenvalue, which must exist for any stochastic matrix.\nSecond, if $\\lambda \\neq 1$, we can divide by $(\\lambda-1)$:\n$$\n1-\\epsilon = \\frac{\\lambda^m}{(1-\\epsilon)^{m-1}} \\implies \\lambda^m = (1-\\epsilon)^m\n$$\nThe solutions to this equation are $\\lambda_k = (1-\\epsilon)\\omega^k$ for $k \\in \\{0, 1, \\dots, m-1\\}$, where $\\omega = \\exp(2\\pi i/m)$ is a principal $m$-th root of unity.\nThe solution for $k=0$ is $\\lambda_0 = 1-\\epsilon$. However, we have already shown that $\\lambda=1-\\epsilon$ is not an eigenvalue because it leads to a contradiction. This extraneous root arose because our derivation for $v_i$ assumed $\\lambda-1+\\epsilon \\neq 0$.\nThus, the eigenvalues are $\\lambda=1$ and $\\lambda_k = (1-\\epsilon)\\omega^k$ for $k \\in \\{1, 2, \\dots, m-1\\}$. This gives a full set of $m$ distinct eigenvalues.\n\nThe relaxation time $\\tau_{\\mathrm{rel}}$ is defined by the Second Largest Eigenvalue Modulus (SLEM), which is the largest modulus of all eigenvalues except for the Perron root $\\lambda=1$.\nThe eigenvalues other than $1$ are $\\lambda_k = (1-\\epsilon)\\omega^k$ for $k=1, \\dots, m-1$.\nWe compute their moduli:\n$$\n|\\lambda_k| = |(1-\\epsilon)\\omega^k| = |1-\\epsilon| \\cdot |\\omega^k|\n$$\nSince $\\epsilon \\in (0,1)$, $|1-\\epsilon| = 1-\\epsilon$. Since $\\omega^k$ is a root of unity, $|\\omega^k|=1$.\nSo, $|\\lambda_k| = 1-\\epsilon$ for all $k \\in \\{1, \\dots, m-1\\}$.\nThe SLEM is $\\max_{k \\in \\{1, \\dots, m-1\\}} |\\lambda_k| = 1-\\epsilon$.\n\nThe relaxation time is then:\n$$\n\\tau_{\\mathrm{rel}} = \\frac{1}{1 - \\mathrm{SLEM}} = \\frac{1}{1 - (1-\\epsilon)} = \\frac{1}{\\epsilon}\n$$\n\nSummary of results:\n1.  Baseline period: $m$.\n2.  Modified period: $1$.\n3.  Modified relaxation time: $1/\\epsilon$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} m  1  \\frac{1}{\\epsilon} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "This advanced practice moves from theoretical analysis to practical implementation by asking you to build an adaptive simulation algorithm. You will design a \"streaming\" detector that diagnoses periodicity online by tracking return times and then automatically switches to a \"lazy\" kernel to enforce aperiodicity (). This exercise models a sophisticated strategy used in robust MCMC software to ensure reliable convergence even when the underlying chain structure is not known in advance.",
            "id": "3329404",
            "problem": "Consider a discrete-time, time-homogeneous Markov chain on a finite state space $\\mathcal{S} = \\{0,1,\\dots, n-1\\}$ with transition matrix $P \\in \\mathbb{R}^{n \\times n}$, where $P(i,j) \\geq 0$ and $\\sum_{j=0}^{n-1} P(i,j) = 1$ for all $i \\in \\mathcal{S}$. The period of a state $i$, denoted $d(i)$, is defined by the greatest common divisor of all positive integers $n$ such that the $n$-step transition probability from $i$ to itself is positive, that is\n$$\nd(i) = \\gcd\\{\\, n \\in \\mathbb{N} \\,:\\, (P^n)(i,i)  0 \\, \\}.\n$$\nA state $i$ is aperiodic if $d(i) = 1$. A Markov chain is aperiodic if all of its states are aperiodic (equivalently, all states in a communicating class have period $1$).\n\nIn streaming simulation, one does not generally compute $(P^n)(i,i)$ directly. Instead, one can detect periodicity online by tracking observed return times to each state. Suppose the chain generates a path $X_0, X_1, \\dots, X_T$ with $X_t \\in \\mathcal{S}$. For each state $i$, record the visit times $\\tau_0^{(i)}  \\tau_1^{(i)}  \\dots$ at which $X_{\\tau_k^{(i)}} = i$, and define the observed return intervals\n$$\nR_k^{(i)} = \\tau_k^{(i)} - \\tau_{k-1}^{(i)} \\quad \\text{for } k \\geq 1.\n$$\nDefine a streaming update for the period estimate $d(i)$ using the greatest common divisor operation by the recursion\n$$\nd(i) \\leftarrow \\gcd\\big(d(i), R_k^{(i)}\\big),\n$$\nwith initialization $d(i) \\leftarrow 0$ and the convention $\\gcd(0, r) = r$. To reduce false positives from finite-sample effects, require that at least two returns to a state $i$ have been observed (i.e., at least three visits, so that at least two intervals $R_k^{(i)}$ have contributed) before declaring a state periodic. When any state $i$ attains $d(i)  1$ under this streaming update and has at least two observed returns, trigger a switch to a lazy kernel.\n\nDefine the lazy kernel $P_{\\ell}$ by\n$$\nP_{\\ell} = \\tfrac{1}{2}\\,I + \\tfrac{1}{2}\\,P,\n$$\nwhere $I$ is the identity matrix. When simulating, the lazy kernel means: with probability $\\tfrac{1}{2}$ remain at the current state, and with probability $\\tfrac{1}{2}$ move according to $P$. This modification is known to produce an aperiodic chain and preserve the stationary distribution of $P$.\n\nTask: Design and implement a program that\n- Simulates a path $X_0, X_1, \\dots, X_T$ for each test case using $P$, starting from a specified initial state $X_0$, and toggles to the lazy kernel $P_{\\ell}$ immediately upon detecting any state $i$ satisfying $d(i)  1$ with at least two observed returns.\n- Maintains the streaming estimates $d(i)$ for all states $i \\in \\mathcal{S}$, using only the observed return intervals as described above.\n- Reports, for each test case, the boolean flag indicating whether toggling to $P_{\\ell}$ occurred, the integer value of $d(i)$ at the exact moment of toggling for the state that triggered the toggle (use $0$ if no toggle occurred), and the integer maximum of the final $d(i)$ values across all states after the simulation ends (use $0$ if a state was never revisited so its $d(i)$ remained $0$).\n\nYou must implement this detector and toggling mechanism in a Markov Chain Monte Carlo (MCMC) context, understood here as simulation from a Markov chain kernel; when the lazy kernel is engaged, simulate each next step by mixing an identity move with a move from $P$ as specified.\n\nTest Suite:\n- Case $1$ (periodic two-state chain): $P = \\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix}$, $n = 2$, $T = 50$, initial state $X_0 = 0$. This chain has states with period $2$.\n- Case $2$ (aperiodic two-state chain): $P = \\begin{pmatrix} 0.7  0.3 \\\\ 0.4  0.6 \\end{pmatrix}$, $n = 2$, $T = 400$, initial state $X_0 = 0$. This chain is irreducible and aperiodic with period $1$ for each state. Use a fixed random seed to ensure reproducibility.\n- Case $3$ (periodic three-state cycle): $P = \\begin{pmatrix} 0  1  0 \\\\ 0  0  1 \\\\ 1  0  0 \\end{pmatrix}$, $n = 3$, $T = 60$, initial state $X_0 = 0$. This chain has states with period $3$.\n- Case $4$ (short run with no return to the start): $P = \\begin{pmatrix} 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  1 \\\\ 1  0  0  0 \\end{pmatrix}$, $n = 4$, $T = 3$, initial state $X_0 = 0$. The run is too short to revisit the start, so the streaming $d(i)$ may remain $0$.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one test case and must be a list of the form $[\\text{toggle\\_flag}, d_{\\text{at\\_toggle}}, \\max\\_d_{\\text{final}}]$, where $\\text{toggle\\_flag}$ is a boolean, $d_{\\text{at\\_toggle}}$ and $\\max\\_d_{\\text{final}}$ are integers. For example: $[[\\text{True},2,1],[\\text{False},0,1],\\dots]$.\n\nNo physical units are involved, angles are not applicable, and no percentages are required; all numerical answers must be expressed as integers or booleans as specified.",
            "solution": "The problem of designing a streaming detector for periodicity in a Markov chain and toggling to a lazy kernel is valid. It is scientifically grounded in the theory of stochastic processes and Markov Chain Monte Carlo (MCMC) methods, is well-posed with a clear algorithmic description, and is stated objectively using standard mathematical formalism. The problem is self-contained and provides all necessary data for the specified test cases.\n\nThe solution involves simulating a discrete-time Markov chain and, for each state, maintaining an online estimate of its period. This estimate is updated upon each return to the state. If a state's estimated period becomes greater than $1$ and sufficient evidence has been collected (at least two returns), the simulation dynamics are altered by switching from the original transition kernel $P$ to a lazy kernel $P_{\\ell}$. This procedure is executed for a fixed number of steps $T$, and the final state of the detector is reported.\n\n### 1. Algorithmic Framework\n\nThe simulation of the path $X_0, X_1, \\dots, X_T$ is performed iteratively. For each time step $t$ from $1$ to $T$, the next state $X_t$ is sampled based on the current state $X_{t-1}$ and the active transition kernel. We must maintain several data structures to track the necessary information for each state $i \\in \\mathcal{S} = \\{0, 1, \\dots, n-1\\}$:\n\n- **Last Visit Time, $\\text{last\\_visit\\_time}[i]$**: Stores the time step of the most recent visit to state $i$. Initialized to $-1$ for $i \\neq X_0$ and to $0$ for $i=X_0$.\n- **Visit Counts, $\\text{visit\\_counts}[i]$**: Counts the total number of visits to state $i$. Initialized to $0$ for all $i$ and incremented at each visit. The initial state $X_0$ starts with a count of $1$.\n- **Estimated Period, $d[i]$**: The streaming estimate of the period of state $i$. Initialized to $0$ for all $i$.\n\nA global boolean flag, `toggle_flag`, is initialized to `False` and is set to `True` permanently if the toggle condition is met.\n\n### 2. Simulation Step and State Transition\n\nAt each time step $t \\in \\{1, \\dots, T\\}$, the simulation proceeds as follows:\n\n1.  **Select Kernel**: The choice of transition kernel depends on `toggle_flag`:\n    - If `toggle_flag` is `False`, the standard transition matrix $P$ is used. The next state $X_t$ is drawn from the probability distribution given by the row $P(X_{t-1}, \\cdot)$.\n    - If `toggle_flag` is `True`, the lazy kernel $P_{\\ell} = \\tfrac{1}{2}\\,I + \\tfrac{1}{2}\\,P$ is used. This is implemented by drawing a uniform random number $u \\in [0,1)$. If $u  0.5$, the chain remains in its current state ($X_t = X_{t-1}$). Otherwise (if $u \\ge 0.5$), the next state $X_t$ is drawn from the distribution $P(X_{t-1}, \\cdot)$.\n\n2.  **Update State**: The current state of the chain is updated to $X_t$.\n\nFor deterministic cases (where probabilities in $P$ are only $0$ or $1$), the \"draw\" is simply the selection of the unique state with transition probability $1$. For stochastic cases, a random number generator is used. To ensure reproducibility across all simulations, a single fixed random seed is set at the beginning of the program.\n\n### 3. Periodicity Detection and Toggling\n\nAfter transitioning to the new state $X_t = i$ at time $t$, the tracking variables for state $i$ are updated.\n\n1.  **Update Visit Data**: The `visit_counts[i]` is incremented. If this is a return visit (i.e., `visit_counts[i]  1`), the observed return interval $R^{(i)}$ is calculated as the difference between the current time $t$ and the `last_visit_time[i]`.\n\n2.  **Update Period Estimate**: The estimated period $d[i]$ is updated using the greatest common divisor (GCD) operation:\n    $$\n    d[i] \\leftarrow \\gcd(d[i], R^{(i)})\n    $$\n    The initial value is $d[i]=0$, and we use the convention $\\gcd(0, r) = r$ for any positive integer $r$. This ensures that the first observed return interval initializes the period estimate.\n\n3.  **Update Last Visit Time**: `last_visit_time[i]` is set to the current time $t$.\n\n4.  **Check Toggle Condition**: If `toggle_flag` is still `False`, we check if the conditions for toggling are met for the current state $i=X_t$:\n    - The estimated period $d[i]$ is greater than $1$.\n    - At least two returns to state $i$ have occurred, which is equivalent to the total number of visits `visit_counts[i]` being at least $3$.\n\n    If both conditions are met, `toggle_flag` is set to `True`, and the value of $d[i]$ at this exact moment is recorded as $d_{\\text{at\\_toggle}}$. The simulation will use the lazy kernel $P_{\\ell}$ from the next step ($t+1$) onwards.\n\n### 4. Final Output Generation\n\nAfter the simulation runs for $T$ steps, the results for the test case are compiled into a list $[\\text{toggle\\_flag}, d_{\\text{at\\_toggle}}, \\max\\_d_{\\text{final}}]$.\n- `toggle_flag`: The final state of the boolean flag indicating if a toggle occurred.\n- $d_{\\text{at\\_toggle}}$: The period estimate of the state that triggered the toggle at the moment it occurred. If no toggle occurred, this value is $0$.\n- $\\max\\_d_{\\text{final}}$: The maximum value among all final estimated periods $\\{d[0], d[1], \\dots, d[n-1]\\}$. If a state was never revisited, its period estimate remains at its initial value of $0$.\n\nThis entire process is repeated for each test case provided in the problem statement. The collected results are then formatted into the required single-line string output.",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    # A single fixed random seed for reproducibility of all stochastic parts.\n    np.random.seed(42)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"P\": np.array([[0, 1], [1, 0]], dtype=float),\n            \"n\": 2,\n            \"T\": 50,\n            \"X0\": 0,\n        },\n        {\n            \"P\": np.array([[0.7, 0.3], [0.4, 0.6]], dtype=float),\n            \"n\": 2,\n            \"T\": 400,\n            \"X0\": 0,\n        },\n        {\n            \"P\": np.array([[0, 1, 0], [0, 0, 1], [1, 0, 0]], dtype=float),\n            \"n\": 3,\n            \"T\": 60,\n            \"X0\": 0,\n        },\n        {\n            \"P\": np.array([[0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [1, 0, 0, 0]], dtype=float),\n            \"n\": 4,\n            \"T\": 3,\n            \"X0\": 0,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_simulation(case[\"P\"], case[\"n\"], case[\"T\"], case[\"X0\"])\n        results.append(result)\n\n    # Format the results into the exact required string format.\n    formatted_results = [f\"[{str(r[0])},{r[1]},{r[2]}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef run_simulation(P, n, T, X0):\n    \"\"\"\n    Simulates a Markov chain with an online periodicity detector.\n\n    Args:\n        P (np.ndarray): The transition matrix.\n        n (int): The number of states.\n        T (int): The total number of simulation steps (path length will be T+1).\n        X0 (int): The initial state.\n\n    Returns:\n        list: A list containing [toggle_flag, d_at_toggle, max_d_final].\n    \"\"\"\n    current_state = X0\n    \n    # Data structures for tracking state visits and period estimates\n    last_visit_time = {i: -1 for i in range(n)}\n    visit_counts = {i: 0 for i in range(n)}\n    estimated_periods = {i: 0 for i in range(n)}\n    \n    # Output variables\n    toggle_flag = False\n    d_at_toggle = 0\n    \n    # Process initial state at t=0\n    last_visit_time[X0] = 0\n    visit_counts[X0] = 1\n    \n    states_range = np.arange(n)\n\n    for t in range(1, T + 1):\n        # 1. Determine next state based on the active kernel\n        if toggle_flag:\n            # Lazy kernel P_l = 0.5*I + 0.5*P\n            if np.random.rand()  0.5:\n                next_state = current_state\n            else:\n                p_dist = P[current_state]\n                next_state = np.random.choice(states_range, p=p_dist)\n        else:\n            # Standard kernel P\n            p_dist = P[current_state]\n            next_state = np.random.choice(states_range, p=p_dist)\n\n        current_state = next_state\n        \n        # 2. Update statistics for the newly visited state\n        i = current_state\n        \n        # Check if it's a return visit to update period estimate\n        if visit_counts[i]  0:\n            return_interval = t - last_visit_time[i]\n            \n            # The streaming GCD update. math.gcd(0, r) = r, fulfilling the requirement.\n            old_d = estimated_periods[i]\n            if return_interval  0:\n                estimated_periods[i] = math.gcd(old_d, return_interval)\n\n        last_visit_time[i] = t\n        visit_counts[i] += 1\n\n        # 3. Check for toggle condition if not already toggled\n        if not toggle_flag:\n            # Condition: d(i)  1 AND at least 2 returns (i.e., 3 visits)\n            num_returns = visit_counts[i] - 1\n            if num_returns = 2 and estimated_periods[i]  1:\n                toggle_flag = True\n                d_at_toggle = estimated_periods[i]\n                \n    # 4. Finalize results after the simulation ends\n    max_d_final = 0\n    if estimated_periods:\n        max_d_final = max(estimated_periods.values())\n\n    return [toggle_flag, d_at_toggle, max_d_final]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}