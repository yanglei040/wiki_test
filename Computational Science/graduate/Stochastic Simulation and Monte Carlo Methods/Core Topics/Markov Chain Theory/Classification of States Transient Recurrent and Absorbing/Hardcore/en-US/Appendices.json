{
    "hands_on_practices": [
        {
            "introduction": "Understanding the classification of states is fundamental, but theory meets practice when we discretize continuous-time models for simulation. This practice challenges you to implement a state classifier from first principles, using graph-based algorithms to identify transient, recurrent, and absorbing states. By comparing a continuous-time Markov chain with its numerical approximations, you will gain firsthand experience with how discretization choices can fundamentally alter a model's qualitative behavior, a critical insight for any simulation practitioner .",
            "id": "3295807",
            "problem": "Consider a finite-state, continuous-time Markov jump process with generator matrix $Q \\in \\mathbb{R}^{n \\times n}$, where $q_{ij} \\ge 0$ for $i \\ne j$ and each row sums to zero, i.e., $\\sum_{j=1}^{n} q_{ij} = 0$. The discrete-time skeleton at time step $\\Delta t  0$ has transition matrix $P_{\\mathrm{exact}}(\\Delta t) = \\exp(Q \\Delta t)$, the matrix exponential of $Q \\Delta t$. In practice, one often uses a first-order Euler discretization $P_{\\mathrm{raw}}(\\Delta t) = I + \\Delta t \\, Q$. To enforce stochasticity and handle numerical sparsification, a heuristic thresholding-and-renormalization scheme with tolerance $\\tau  0$ is applied as follows:\n- Threshold: For each entry, set $(P_{\\mathrm{raw}}(\\Delta t))_{ij}$ to $0$ if $(P_{\\mathrm{raw}}(\\Delta t))_{ij}  \\tau$.\n- Renormalize: For each row $i$, compute the row sum $s_i = \\sum_{j=1}^{n} (P_{\\mathrm{raw}}(\\Delta t))_{ij}$ after thresholding. If $s_i  0$, set $(P_{\\mathrm{EC}})_{ij} = (P_{\\mathrm{raw}}(\\Delta t))_{ij} / s_i$. If $s_i = 0$, set the row to the $i$-th standard basis vector (i.e., $(P_{\\mathrm{EC}})_{ii} = 1$ and $(P_{\\mathrm{EC}})_{ij} = 0$ for $j \\ne i$). Denote the resulting matrix by $P_{\\mathrm{EC}}(\\Delta t,\\tau)$.\n\nState classification is defined as follows.\n- For the continuous-time Markov chain (CTMC) with generator $Q$, construct the directed graph on $\\{1,\\dots,n\\}$ with an edge $i \\to j$ if and only if $q_{ij}  0$ for $i \\ne j$. A communicating class is a strongly connected component of this graph. A class is closed if there is no edge from any state inside the class to any state outside the class. A state $i$ is absorbing if $q_{ij} = 0$ for all $j \\ne i$ (equivalently, $q_{ii} = 0$). A state is recurrent if it lies in a closed communicating class; otherwise it is transient.\n- For any discrete-time Markov chain (DTMC) with transition matrix $P$ (e.g., $P_{\\mathrm{exact}}$ or $P_{\\mathrm{EC}}$), construct the directed graph on $\\{1,\\dots,n\\}$ with an edge $i \\to j$ if and only if $p_{ij}  0$. Use the same communicating class definitions. A state $i$ is absorbing if $p_{ii} = 1$ and $p_{ij} = 0$ for all $j \\ne i$. A state is recurrent if it lies in a closed communicating class; otherwise it is transient.\n\nYour task is to implement a program that, for several given test cases, compares the classification of states for the CTMC and its two discretizations $P_{\\mathrm{exact}}(\\Delta t)$ and $P_{\\mathrm{EC}}(\\Delta t,\\tau)$, and empirically studies the effect of thresholding by estimating return probabilities via Monte Carlo simulation.\n\nStart from first principles: definitions of the generator $Q$, the skeleton $P_{\\mathrm{exact}}(\\Delta t)$, and the graph-theoretic classification into transient, recurrent, and absorbing states. Do not assume shortcut classification formulas beyond these definitions. You must implement:\n- An exact discretization subroutine using the matrix exponential.\n- The Euler-with-thresholding discretization $P_{\\mathrm{EC}}(\\Delta t,\\tau)$ as specified.\n- A graph-based classifier to label every state as one of the three categories: absorbing, recurrent non-absorbing, or transient, for both $Q$ and any $P$.\n- A Monte Carlo estimator for the probability that a trajectory starting in state $1$ (indexing states as $1,2,\\dots,n$) returns to state $1$ at some time $k \\ge 1$ within a fixed horizon of $N_{\\mathrm{steps}}$ steps under a given $P$. Use a fixed number of paths $N_{\\mathrm{paths}}$ and a fixed random seed for reproducibility.\n\nFor each test case, compute the following three quantities:\n1. $k_{\\mathrm{art}}$: the number of states that are absorbing under $P_{\\mathrm{EC}}(\\Delta t,\\tau)$ but not absorbing under the CTMC generator $Q$.\n2. $k_{\\mathrm{chg}}$: the number of states whose classification label among $\\{\\text{transient}, \\text{recurrent non-absorbing}, \\text{absorbing}\\}$ under $P_{\\mathrm{EC}}(\\Delta t,\\tau)$ differs from their classification label under the CTMC generator $Q$.\n3. $\\Delta r$: the difference between Monte Carlo estimated return probabilities to state $1$ under $P_{\\mathrm{EC}}(\\Delta t,\\tau)$ and $P_{\\mathrm{exact}}(\\Delta t)$, i.e., $\\Delta r = \\widehat{\\mathbb{P}}_{\\mathrm{EC}}(\\text{return to state }1) - \\widehat{\\mathbb{P}}_{\\mathrm{exact}}(\\text{return to state }1)$. Round $\\Delta r$ to three decimal places.\n\nUse the following test suite. In each case, states are indexed $1,2,\\dots,n$ with $n$ implicit in $Q$:\n- Test $1$ (irreducible two-state CTMC, small time step but large threshold):\n  - $Q = \\begin{bmatrix} -3  3 \\\\ 4  -4 \\end{bmatrix}$, $\\Delta t = 0.01$, $\\tau = 0.05$.\n- Test $2$ (same CTMC, moderate time step and tiny threshold):\n  - $Q = \\begin{bmatrix} -3  3 \\\\ 4  -4 \\end{bmatrix}$, $\\Delta t = 0.2$, $\\tau = 0.001$.\n- Test $3$ (three-state chain with a true absorbing state):\n  - $Q = \\begin{bmatrix} -1  1  0 \\\\ 0  -1  1 \\\\ 0  0  0 \\end{bmatrix}$, $\\Delta t = 0.1$, $\\tau = 10^{-4}$.\n- Test $4$ (same three-state chain, very small time step and large threshold creating artificial self-loops):\n  - $Q = \\begin{bmatrix} -1  1  0 \\\\ 0  -1  1 \\\\ 0  0  0 \\end{bmatrix}$, $\\Delta t = 0.001$, $\\tau = 0.05$.\n\nMonte Carlo parameters must be fixed as $N_{\\mathrm{paths}} = 5000$, $N_{\\mathrm{steps}} = 200$, and random seed $12345$. The event “return to state $1$” is defined as visiting state $1$ at any time step $k \\in \\{1,2,\\dots,N_{\\mathrm{steps}}\\}$ after starting in state $1$ at time $0$.\n\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list of triplets enclosed in square brackets, with each triplet in the order $[k_{\\mathrm{art}}, k_{\\mathrm{chg}}, \\Delta r]$, for Tests $1$ through $4$ in order, i.e., an output of the form $[[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot]]$. All quantities are dimensionless and must be printed as numbers (with $\\Delta r$ rounded to three decimal places).",
            "solution": "The problem requires a comparative analysis of state classifications for a continuous-time Markov chain (CTMC) and two of its discrete-time approximations. This involves implementing graph-based classification algorithms, numerical matrix operations, and a Monte Carlo simulation. The problem is scientifically grounded, well-posed, and all necessary parameters and definitions are provided. I will proceed with a full solution.\n\nThe core of the problem lies in correctly classifying the states of a Markov chain as transient, recurrent non-absorbing, or absorbing. The provided definitions are based on the graph structure of the chain.\n\n**1. State Classification Algorithm**\n\nThe classification of states relies on the concept of communicating classes and closed classes. A communicating class is a strongly connected component (SCC) of the state-space graph. A class is closed if no state within it can transition to any state outside of it. A state is recurrent if it belongs to a closed communicating class and transient otherwise. An absorbing state is a special case of a recurrent state that forms a closed class of size one.\n\nLet $n$ be the number of states.\nThe algorithm proceeds as follows for a given matrix ($Q$ for a CTMC or $P$ for a DTMC):\n1.  **Construct the Adjacency List:** A directed graph is constructed on the states $\\{1, \\dots, n\\}$.\n    -   For a CTMC generator $Q$, an edge exists from state $i$ to $j$ ($i \\neq j$) if and only if the transition rate $q_{ij}  0$.\n    -   For a DTMC transition matrix $P$, an edge exists from $i$ to $j$ if and only if the transition probability $p_{ij}  0$.\n2.  **Find Strongly Connected Components (SCCs):** We use Tarjan's algorithm, a depth-first search based approach, to find all SCCs of the graph. Each SCC is a communicating class.\n3.  **Identify Closed Classes:** For each SCC, we check if it is closed. An SCC is closed if there are no outgoing edges from any of its constituent states to any state not in that SCC.\n4.  **Classify States:** Each state $i \\in \\{1, \\dots, n\\}$ is classified based on the following hierarchy:\n    a.  **Absorbing:** A state $i$ is absorbing if it is a sink. For a CTMC, this is defined by $q_{ii} = 0$, which implies $q_{ij} = 0$ for all $j \\neq i$. For a DTMC, this is defined by $p_{ii} = 1$.\n    b.  **Recurrent Non-Absorbing:** If a state $i$ is not absorbing, but belongs to a closed communicating class, it is classified as recurrent non-absorbing.\n    c.  **Transient:** If a state $i$ is neither absorbing nor recurrent non-absorbing, it is transient. This means it belongs to a communicating class that is not closed, implying there is a path to escape the class.\n\n**2. Discretization Schemes**\n\nTwo discretization schemes are considered:\n\n-   **Exact Discretization ($P_{\\mathrm{exact}}$):** The transition matrix for the discrete-time skeleton over a time step $\\Delta t  0$ is given by the matrix exponential:\n    $$P_{\\mathrm{exact}}(\\Delta t) = \\exp(Q \\Delta t)$$\n    This is computed using `scipy.linalg.expm`.\n\n-   **Euler with Correction ($P_{\\mathrm{EC}}$):** This is a heuristic scheme involving three steps:\n    1.  **Euler Step:** A first-order approximation is made: $P_{\\mathrm{raw}}(\\Delta t) = I + \\Delta t \\, Q$, where $I$ is the identity matrix.\n    2.  **Thresholding:** Small entries, which may be numerical noise or small but true probabilities, are removed. Given a tolerance $\\tau  0$, any entry $(P_{\\mathrm{raw}})_{ij}  \\tau$ is set to $0$.\n    3.  **Renormalization:** To restore the stochastic property (rows summing to $1$), each row is renormalized. For each row $i$, let $s_i$ be its sum after thresholding.\n        -   If $s_i  0$, each element in the row is divided by $s_i$, yielding $(P_{\\mathrm{EC}})_{ij} = (P_{\\mathrm{raw}})_{ij} / s_i$.\n        -   If $s_i = 0$ (all entries in the row were thresholded to zero), the state is made absorbing: $(P_{\\mathrm{EC}})_{ii} = 1$ and $(P_{\\mathrm{EC}})_{ij} = 0$ for $j \\neq i$.\n\n**3. Monte Carlo Estimation of Return Probability**\n\nWe estimate the probability that a trajectory starting in state $1$ (index $0$) visits state $1$ again at any time step $k \\in \\{1, 2, \\dots, N_{\\mathrm{steps}}\\}$. This is the probability of the event $\\bigcup_{k=1}^{N_{\\mathrm{steps}}} \\{X_k=1\\} \\mid X_0=1$.\n\nThe estimation is performed using a Monte Carlo simulation with $N_{\\mathrm{paths}}$ trajectories, each simulated for up to $N_{\\mathrm{steps}}$.\n1.  Initialize a counter for returning paths, `return_count = 0`. A fixed random seed ensures reproducibility.\n2.  For each of the $N_{\\mathrm{paths}}$ simulations:\n    a.  Start the trajectory at `current_state = 0` (for state $1$).\n    b.  For each time step from $1$ to $N_{\\mathrm{steps}}$:\n        i. Sample the `next_state` from the categorical distribution defined by the `current_state` row of the transition matrix $P$.\n        ii. If `next_state` is $0$, the trajectory has returned. Mark this path as a success and break the inner loop to start the next path.\n        iii. Update `current_state = next_state`.\n    c.  If the path was a success, increment `return_count`.\n3.  The estimated probability is $\\widehat{\\mathbb{P}} = \\text{return\\_count} / N_{\\mathrm{paths}}$.\n\n**4. Analysis and Computation**\n\nFor each test case, we perform the following computations:\n-   Determine the classification arrays for the CTMC ($Q$) and the $P_{\\mathrm{EC}}$ approximation.\n-   $k_{\\mathrm{art}}$: The number of artificial absorbing states. This is the count of states that are absorbing under $P_{\\mathrm{EC}}$ but not under $Q$.\n-   $k_{\\mathrm{chg}}$: The number of states whose classification changes. This is found by comparing the classification arrays for $Q$ and $P_{\\mathrm{EC}}$ element-wise.\n-   $\\Delta r$: The difference in estimated return probabilities. We compute $\\widehat{\\mathbb{P}}_{\\mathrm{EC}}(\\text{return})$ and $\\widehat{\\mathbb{P}}_{\\mathrm{exact}}(\\text{return})$ via Monte Carlo and calculate $\\Delta r = \\widehat{\\mathbb{P}}_{\\mathrm{EC}} - \\widehat{\\mathbb{P}}_{\\mathrm{exact}}$, rounded to three decimal places.\n\nThese steps are systematically applied to each of the four test cases provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef get_classification(M, is_ctmc):\n    \"\"\"\n    Classifies states of a Markov chain as 'absorbing', 'recurrent non-absorbing', or 'transient'.\n\n    Args:\n        M (np.ndarray): The generator matrix Q (if is_ctmc) or transition matrix P.\n        is_ctmc (bool): True for CTMC (Q), False for DTMC (P).\n\n    Returns:\n        list[str]: A list of classification labels for each state.\n    \"\"\"\n    n = M.shape[0]\n\n    # 1. Build adjacency list based on the graph definition\n    adj = [[] for _ in range(n)]\n    if is_ctmc: # Graph from Q\n        for i in range(n):\n            for j in range(n):\n                if i != j and M[i, j] > 0:\n                    adj[i].append(j)\n    else: # Graph from P\n        for i in range(n):\n            for j in range(n):\n                if M[i, j] > 1e-9: # Use tolerance for float comparison\n                    # Self-loops are part of the graph for DTMCs\n                    adj[i].append(j)\n\n    # 2. Find Strongly Connected Components (SCCs) using Tarjan's algorithm\n    ids = [-1] * n\n    low = [-1] * n\n    onStack = [False] * n\n    stack = []\n    at_scc = 0\n    sccs = []\n    \n    def tarjan_dfs(at):\n        nonlocal at_scc\n        stack.append(at)\n        onStack[at] = True\n        ids[at] = low[at] = at_scc\n        at_scc += 1\n\n        for to in adj[at]:\n            if ids[to] == -1:\n                tarjan_dfs(to)\n            if onStack[to]:\n                low[at] = min(low[at], low[to])\n\n        if ids[at] == low[at]:\n            scc = []\n            while stack:\n                node = stack.pop()\n                onStack[node] = False\n                low[node] = ids[at]\n                scc.append(node)\n                if node == at: break\n            sccs.append(scc)\n\n    for i in range(n):\n        if ids[i] == -1:\n            tarjan_dfs(i)\n\n    # 3. Identify closed classes\n    state_to_scc_id = {state: i for i, scc in enumerate(sccs) for state in scc}\n    closed_scc_ids = set()\n    for i, scc in enumerate(sccs):\n        is_closed = True\n        for u in scc:\n            for v in adj[u]:\n                if state_to_scc_id.get(v) != i:\n                    is_closed = False\n                    break\n            if not is_closed:\n                break\n        if is_closed:\n            closed_scc_ids.add(i)\n\n    # 4. Classify states\n    labels = [''] * n\n    for i in range(n):\n        is_absorbing = False\n        if is_ctmc:\n            if np.allclose(M[i, i], 0) and np.allclose(M[i, :i], 0) and np.allclose(M[i, i+1:], 0):\n                is_absorbing = True\n        else: # DTMC\n            if np.allclose(M[i, i], 1.0):\n                is_absorbing = True\n\n        if is_absorbing:\n            labels[i] = 'absorbing'\n        else:\n            scc_id = state_to_scc_id.get(i)\n            if scc_id is not None and scc_id in closed_scc_ids:\n                labels[i] = 'recurrent non-absorbing'\n            else:\n                labels[i] = 'transient'\n    \n    return labels\n\ndef get_p_ec(Q, dt, tau):\n    \"\"\"\n    Computes the Euler-with-correction discretization P_EC.\n    \"\"\"\n    P_raw = np.eye(Q.shape[0]) + dt * Q\n    P_thresh = np.where(P_raw  tau, 0, P_raw)\n    \n    P_ec = np.zeros_like(P_thresh)\n    row_sums = P_thresh.sum(axis=1)\n    \n    for i in range(Q.shape[0]):\n        if row_sums[i] > 1e-9: # Tolerance\n            P_ec[i, :] = P_thresh[i, :] / row_sums[i]\n        else:\n            P_ec[i, i] = 1.0\n            \n    return P_ec\n\ndef monte_carlo_return_prob(P, n_paths, n_steps, seed):\n    \"\"\"\n    Estimates the probability of returning to state 1 (index 0).\n    \"\"\"\n    n = P.shape[0]\n    rng = np.random.default_rng(seed)\n    states = np.arange(n)\n    \n    return_count = 0\n    start_state = 0\n\n    for _ in range(n_paths):\n        current_state = start_state\n        has_returned = False\n        for _ in range(n_steps):\n            probs = P[current_state, :]\n            # Normalize to handle potential float inaccuracies\n            if not np.isclose(probs.sum(), 1.0):\n                probs /= probs.sum()\n            next_state = rng.choice(states, p=probs)\n            \n            if next_state == start_state:\n                has_returned = True\n                break\n            current_state = next_state\n        \n        if has_returned:\n            return_count += 1\n            \n    return return_count / n_paths\n\n\ndef solve():\n    \"\"\"\n    Main solver function to process test cases and produce the final output.\n    \"\"\"\n    test_cases = [\n        {\n            'Q': np.array([[-3., 3.], [4., -4.]]),\n            'dt': 0.01,\n            'tau': 0.05\n        },\n        {\n            'Q': np.array([[-3., 3.], [4., -4.]]),\n            'dt': 0.2,\n            'tau': 0.001\n        },\n        {\n            'Q': np.array([[-1., 1., 0.], [0., -1., 1.], [0., 0., 0.]]),\n            'dt': 0.1,\n            'tau': 1e-4\n        },\n        {\n            'Q': np.array([[-1., 1., 0.], [0., -1., 1.], [0., 0., 0.]]),\n            'dt': 0.001,\n            'tau': 0.05\n        }\n    ]\n\n    mc_params = {\n        'n_paths': 5000,\n        'n_steps': 200,\n        'seed': 12345\n    }\n\n    results = []\n    for case in test_cases:\n        Q, dt, tau = case['Q'], case['dt'], case['tau']\n        n = Q.shape[0]\n\n        # Classifications\n        class_q = get_classification(Q, is_ctmc=True)\n        \n        P_ec = get_p_ec(Q, dt, tau)\n        class_pec = get_classification(P_ec, is_ctmc=False)\n        \n        P_exact = expm(Q * dt)\n\n        # 1. k_art: artificial absorbing states\n        absorbing_q = {i for i, label in enumerate(class_q) if label == 'absorbing'}\n        absorbing_pec = {i for i, label in enumerate(class_pec) if label == 'absorbing'}\n        k_art = len(absorbing_pec - absorbing_q)\n\n        # 2. k_chg: states with changed classification\n        k_chg = sum(1 for i in range(n) if class_q[i] != class_pec[i])\n\n        # 3. Δr: difference in return probabilities\n        prob_ec = monte_carlo_return_prob(P_ec, **mc_params)\n        prob_exact = monte_carlo_return_prob(P_exact, **mc_params)\n        delta_r = round(prob_ec - prob_exact, 3)\n\n        results.append([k_art, k_chg, delta_r])\n\n    print(f\"[[{results[0][0]},{results[0][1]},{results[0][2]}],[{results[1][0]},{results[1][1]},{results[1][2]}],[{results[2][0]},{results[2][1]},{results[2][2]}],[{results[3][0]},{results[3][1]},{results[3][2]}]]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once we classify the states of a system, a crucial follow-up question is how robust that classification is to small changes in the model. This exercise moves from static classification to dynamic stability analysis, asking you to determine the margin of safety for a transient class . By applying tools from matrix perturbation theory, you will derive a precise bound that guarantees transience, developing a deeper appreciation for the connection between a system's spectral properties and its long-term behavior.",
            "id": "3295790",
            "problem": "Consider a discrete-time finite-state Markov chain with state space $\\{1,2,3\\}$. Its one-step transition probability matrix is\n$$\nP \\;=\\;\n\\begin{pmatrix}\n0.3  0.2  0.5 \\\\\n0.2  0.4  0.4 \\\\\n0    0    1\n\\end{pmatrix}.\n$$\nLet the transient class be $T=\\{1,2\\}$ and the absorbing state be $\\{3\\}$. Denote by $Q$ the $2\\times 2$ sub-stochastic block corresponding to transitions within $T$, and by $R$ the $2\\times 1$ block for transitions from $T$ to $\\{3\\}$. You may take as fundamental that a class $T$ is transient if and only if the spectral radius $\\rho(Q)$ satisfies $\\rho(Q)1$.\n\nSuppose $P$ is perturbed to $P' = P + \\Delta P$, where $P'$ remains a valid stochastic matrix on the same state space, with the same indexing for $T=\\{1,2\\}$, and where the perturbation is bounded in spectral norm by $\\|\\Delta P\\|_{2} \\le \\varepsilon$. Let $\\Delta Q$ be the corresponding perturbation of $Q$ extracted from $\\Delta P$. Using fundamental definitions of transience, matrix norms, and well-tested spectral perturbation bounds for eigenvalues of diagonalizable matrices, derive the supremal uniform radius $\\varepsilon^{\\star}$ such that for every perturbation with $\\|\\Delta P\\|_{2}  \\varepsilon^{\\star}$ the class $T$ remains transient for $P'$.\n\nCompute the numerical value of $\\varepsilon^{\\star}$ for the given $P$ and express your final answer rounded to four significant figures. No units are required.",
            "solution": "The problem is first validated to ensure it is scientifically sound, well-posed, and complete.\n\n### Step 1: Extract Givens\n- A discrete-time finite-state Markov chain with state space $S = \\{1, 2, 3\\}$.\n- The one-step transition probability matrix is $P = \\begin{pmatrix} 0.3  0.2  0.5 \\\\ 0.2  0.4  0.4 \\\\ 0  0  1 \\end{pmatrix}$.\n- The set of transient states is $T = \\{1, 2\\}$.\n- The absorbing state is $\\{3\\}$.\n- $Q$ is the submatrix of $P$ corresponding to transitions within $T$: $Q = \\begin{pmatrix} 0.3  0.2 \\\\ 0.2  0.4 \\end{pmatrix}$.\n- $R$ is the submatrix for transitions from $T$ to $\\{3\\}$: $R = \\begin{pmatrix} 0.5 \\\\ 0.4 \\end{pmatrix}$.\n- A class $T$ is transient if and only if the spectral radius of $Q$, $\\rho(Q)$, satisfies $\\rho(Q)  1$.\n- A perturbed matrix $P' = P + \\Delta P$ is a valid stochastic matrix.\n- The perturbation is bounded in the spectral norm: $\\|\\Delta P\\|_{2} \\le \\varepsilon$.\n- $\\Delta Q$ is the submatrix of $\\Delta P$ corresponding to the states in $T$.\n- The objective is to find the supremal uniform radius $\\varepsilon^{\\star}$ such that for any valid perturbation with $\\|\\Delta P\\|_{2}  \\varepsilon^{\\star}$, the class $T$ remains transient for the perturbed matrix $P'$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard application of matrix perturbation theory to the stability analysis of Markov chains. All concepts—transience, spectral radius, spectral norm, stochastic matrices—are rigorously defined in mathematics and engineering. The given matrix $P$ is a valid stochastic matrix as its entries are non-negative and its rows sum to $1$.\n- **Well-Posed:** The problem is well-defined. It asks for the computation of a specific quantity, $\\varepsilon^{\\star}$, defined as a supremum under clear constraints. A unique solution is expected.\n- **Objective:** The problem is stated in precise, objective mathematical language.\n\nThe problem is free of any scientific, logical, or structural flaws.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. A full solution will be provided.\n\n### Solution Derivation\nThe condition for the class of states $T = \\{1, 2\\}$ to be transient is that the spectral radius of the submatrix $Q$ is strictly less than $1$, i.e., $\\rho(Q)  1$. For the perturbed matrix $P'$, the corresponding submatrix for transitions within $T$ is $Q' = Q + \\Delta Q$. The class $T$ remains transient under this perturbation if and only if $\\rho(Q')  1$.\n\nA key result from the theory of Markov chains states that the class $T$ is transient if and only if the matrix $I-Q$ is invertible, where $I$ is the identity matrix of appropriate size. The matrix $N = (I-Q)^{-1}$ is known as the fundamental matrix, and its entries give the expected number of visits to states in $T$ before absorption. The convergence of the geometric series $N = \\sum_{k=0}^{\\infty} Q^k$ is equivalent to $\\rho(Q)  1$.\n\nFor the perturbed system, transience is maintained if and only if $I-Q'$ is invertible. We can write $I-Q'$ as a perturbation of $I-Q$:\n$$\nI - Q' = I - (Q + \\Delta Q) = (I - Q) - \\Delta Q\n$$\nAccording to a fundamental theorem in matrix perturbation theory, if a matrix $A$ is invertible, then the matrix $A+E$ is also invertible provided that the norm of the perturbation $E$ is sufficiently small. Specifically, if $\\|E\\|  \\frac{1}{\\|A^{-1}\\|}$ for some matrix norm, then $A+E$ is guaranteed to be invertible.\n\nLet's apply this theorem with $A = I - Q$ and the perturbation $E = -\\Delta Q$, using the spectral norm (induced $2$-norm). The matrix $I-Q$ is invertible since the original class $T$ is transient. The perturbed matrix $I-Q'$ remains invertible if:\n$$\n\\|-\\Delta Q\\|_{2}  \\frac{1}{\\|(I-Q)^{-1}\\|_{2}}\n$$\nSince $\\|-\\Delta Q\\|_{2} = \\|\\Delta Q\\|_{2}$, the condition is:\n$$\n\\|\\Delta Q\\|_{2}  \\frac{1}{\\|(I-Q)^{-1}\\|_{2}}\n$$\nThe perturbation $\\Delta Q$ is a principal submatrix of the full perturbation $\\Delta P$. A standard property of the spectral norm is that the norm of any submatrix is less than or equal to the norm of the full matrix. Thus, we have:\n$$\n\\|\\Delta Q\\|_{2} \\le \\|\\Delta P\\|_{2}\n$$\nThe problem states that $\\|\\Delta P\\|_{2}  \\varepsilon^{\\star}$. Therefore, we have $\\|\\Delta Q\\|_{2}  \\varepsilon^{\\star}$. To guarantee that the transience condition holds for any such perturbation, we must require that the upper bound $\\varepsilon^{\\star}$ on $\\|\\Delta P\\|_{2}$ satisfies:\n$$\n\\varepsilon^{\\star} \\le \\frac{1}{\\|(I-Q)^{-1}\\|_{2}}\n$$\nThe problem asks for the supremal uniform radius $\\varepsilon^{\\star}$. The bound is tight, meaning we can find a perturbation with norm equal to $1/\\|(I-Q)^{-1}\\|_{2}$ that makes $I-Q'$ singular. Thus, the supremum is:\n$$\n\\varepsilon^{\\star} = \\frac{1}{\\|(I-Q)^{-1}\\|_{2}}\n$$\nNow we must compute $\\|(I-Q)^{-1}\\|_{2}$. The matrix $Q$ is given by $Q = \\begin{pmatrix} 0.3  0.2 \\\\ 0.2  0.4 \\end{pmatrix}$. This is a real symmetric matrix. Consequently, the matrix $I-Q$ is also symmetric, and its inverse $(I-Q)^{-1}$ is symmetric. For a symmetric matrix, the spectral norm is equal to its spectral radius (the maximum absolute value of its eigenvalues).\n$$\n\\|(I-Q)^{-1}\\|_{2} = \\rho((I-Q)^{-1})\n$$\nThe eigenvalues of $(I-Q)^{-1}$ are related to the eigenvalues of $Q$. Let $\\lambda_i$ be the eigenvalues of $Q$. Then the eigenvalues of $I-Q$ are $1-\\lambda_i$, and the eigenvalues of $(I-Q)^{-1}$ are $(1-\\lambda_i)^{-1}$.\nTherefore:\n$$\n\\rho((I-Q)^{-1}) = \\max_i \\left| \\frac{1}{1-\\lambda_i} \\right|\n$$\nTo find the eigenvalues of $Q$, we solve the characteristic equation $\\det(Q - \\lambda I) = 0$:\n$$\n\\det \\begin{pmatrix} 0.3-\\lambda  0.2 \\\\ 0.2  0.4-\\lambda \\end{pmatrix} = (0.3-\\lambda)(0.4-\\lambda) - (0.2)(0.2) = 0\n$$\n$$\n\\lambda^2 - 0.7\\lambda + 0.12 - 0.04 = 0\n$$\n$$\n\\lambda^2 - 0.7\\lambda + 0.08 = 0\n$$\nUsing the quadratic formula, the eigenvalues are:\n$$\n\\lambda = \\frac{-(-0.7) \\pm \\sqrt{(-0.7)^2 - 4(1)(0.08)}}{2(1)} = \\frac{0.7 \\pm \\sqrt{0.49 - 0.32}}{2} = \\frac{0.7 \\pm \\sqrt{0.17}}{2}\n$$\nThe two eigenvalues are $\\lambda_1 = \\frac{0.7 + \\sqrt{0.17}}{2}$ and $\\lambda_2 = \\frac{0.7 - \\sqrt{0.17}}{2}$. Both eigenvalues are real and positive. The spectral radius of $Q$ is the larger eigenvalue:\n$$\n\\rho(Q) = \\lambda_1 = \\frac{0.7 + \\sqrt{0.17}}{2}\n$$\nNumerically, $\\sqrt{0.17} \\approx 0.412$, so $\\rho(Q) \\approx \\frac{1.112}{2} = 0.556  1$, confirming that $T$ is indeed a transient class.\nNow, we find the spectral radius of $(I-Q)^{-1}$. Since $0  \\lambda_2  \\lambda_1  1$, the expression $|(1-\\lambda_i)^{-1}|$ is maximized when $1-\\lambda_i$ is minimized, which occurs for the largest eigenvalue $\\lambda_1 = \\rho(Q)$.\n$$\n\\rho((I-Q)^{-1}) = \\frac{1}{1 - \\lambda_1} = \\frac{1}{1 - \\rho(Q)}\n$$\nSubstituting this back into the expression for $\\varepsilon^{\\star}$:\n$$\n\\varepsilon^{\\star} = \\frac{1}{\\rho((I-Q)^{-1})} = 1 - \\rho(Q)\n$$\nWe can now compute the numerical value:\n$$\n\\varepsilon^{\\star} = 1 - \\frac{0.7 + \\sqrt{0.17}}{2} = \\frac{2 - (0.7 + \\sqrt{0.17})}{2} = \\frac{1.3 - \\sqrt{0.17}}{2}\n$$\nUsing a calculator, $\\sqrt{0.17} \\approx 0.41231056256$.\n$$\n\\varepsilon^{\\star} = \\frac{1.3 - 0.41231056256}{2} = \\frac{0.88768943744}{2} = 0.44384471872\n$$\nRounding the result to four significant figures gives $0.4438$.",
            "answer": "$$\\boxed{0.4438}$$"
        },
        {
            "introduction": "The classification of states directly informs the design and analysis of Monte Carlo simulation strategies, especially for systems with absorbing states. This exercise presents a practical scenario where you must compare two common estimators for the expected absorption time: a direct, path-based approach and a model-based, \"plug-in\" method . Evaluating the trade-offs between their statistical properties—such as bias, variance, and numerical stability—will sharpen your ability to select the most appropriate simulation technique for a given problem.",
            "id": "3295792",
            "problem": "Consider a discrete-time, time-homogeneous, finite-state Markov chain with transition matrix $P$ on a state space that can be partitioned (after relabeling) into transient states $\\mathcal{T}$ and absorbing states $\\mathcal{A}$. Let $Q$ denote the submatrix of $P$ corresponding to transitions within $\\mathcal{T}$, and $R$ the submatrix corresponding to transitions from $\\mathcal{T}$ into $\\mathcal{A}$. For an initial transient state $i \\in \\mathcal{T}$, define the absorption time $T = \\inf\\{k \\ge 0 : X_k \\in \\mathcal{A}\\}$, with the convention that $T = \\infty$ if absorption never occurs. Assume for the questions below that classification into $\\mathcal{T}$ and $\\mathcal{A}$ is correct, unless explicitly stated otherwise.\n\nTwo estimators for the expected absorption time $t_i = \\mathbb{E}_i[T]$ are commonly used in stochastic simulation:\n\n$1.$ Naive path sampling: simulate $n$ independent trajectories from $i$, each until absorption, yielding independent and identically distributed samples $T^{(1)},\\dots,T^{(n)}$ of $T$ conditional on absorption occurring; then $\\hat{t}^{\\mathrm{PS}}_n = \\frac{1}{n}\\sum_{j=1}^n T^{(j)}$.\n\n$2.$ Fundamental-matrix plug-in: estimate $Q$ by the empirical transient-to-transient transition matrix $\\hat{Q}$ formed from a large pool of simulated transitions initiated in $\\mathcal{T}$, and compute $\\hat{t}^{\\mathrm{PLUG}} = (I - \\hat{Q})^{-1}\\mathbf{1}$, where $I$ is the identity on $\\mathbb{R}^{|\\mathcal{T}|}$ and $\\mathbf{1}$ is the vector of all ones.\n\nRecall the fundamental facts: if all states in $\\mathcal{T}$ are transient, then $N = (I - Q)^{-1}$ exists and equals $\\sum_{k=0}^{\\infty} Q^k$, and $t = N\\mathbf{1}$, where $t$ is the vector of expected absorption times starting from each transient state. Write $\\rho(Q)$ for the spectral radius of $Q$.\n\nAssume a fixed simulation budget measured by the total number of simulated state transitions, and suppose that when forming $\\hat{Q}$, only transitions originating in $\\mathcal{T}$ are used. Answer the following multiple-choice question by selecting all statements that are correct. Your justifications should rest on first principles: the definition of transient and absorbing states, the fundamental matrix, and standard properties of expectations, variances, and matrix inverses.\n\nA. If $\\mathbb{P}_i(T  \\infty) = 1$, then $\\hat{t}^{\\mathrm{PS}}_n$ is unbiased for $t_i$ and has variance $\\mathrm{Var}(T)/n$. In contrast, for finite samples the plug-in estimator $\\hat{t}^{\\mathrm{PLUG}}$ is in general biased because inversion is nonlinear, but for a fixed number of simulated transitions it can have substantially lower variance than $\\hat{t}^{\\mathrm{PS}}_n$ when $\\rho(Q)$ is close to $1$ and $\\mathrm{Var}(T)$ is large.\n\nB. If $\\mathbb{P}_i(T = \\infty)  0$ and one discards non-absorbing trajectories before averaging, the resulting naive path-sampling estimator remains unbiased for the unconditional expected absorption time $\\mathbb{E}_i[T]$.\n\nC. Correctly restricting $Q$ to the transient set $\\mathcal{T}$ guarantees that $N = (I - Q)^{-1}$ exists and equals $\\sum_{k=0}^{\\infty} Q^k$, which implies $t = N\\mathbf{1}$ and hence $t_i = \\mathbb{E}_i\\!\\left[\\sum_{k=0}^{\\infty} \\mathbf{1}\\{X_k \\in \\mathcal{T}\\}\\right]$.\n\nD. Because the inverse operation is nonlinear, the law of large numbers still implies $\\mathbb{E}[(I - \\hat{Q})^{-1}] = (I - \\mathbb{E}[\\hat{Q}])^{-1}$ for finite samples, so the plug-in estimator $\\hat{t}^{\\mathrm{PLUG}}$ is unbiased even at finite simulation budgets.\n\nE. When $\\rho(Q)$ is close to $1$, the mapping $Q \\mapsto (I - Q)^{-1}$ is ill-conditioned, so small errors in $\\hat{Q}$ can induce large errors (and bias) in $\\hat{t}^{\\mathrm{PLUG}}$; in that regime, naive path sampling can have lower mean squared error than the plug-in estimator for a fixed simulation budget.\n\nSelect all that apply and explain your reasoning in terms of transient, recurrent, and absorbing classifications, and variance and bias trade-offs in Monte Carlo (MC) estimation.",
            "solution": "This problem compares the statistical properties of two estimators for the expected absorption time in a finite-state Markov chain. All concepts are standard in stochastic simulation and statistical theory. The problem is well-posed and scientifically sound.\n\n**Analysis of Option A:**\n-   **Path Sampling Estimator ($\\hat{t}^{\\mathrm{PS}}_n$):** If absorption is certain ($\\mathbb{P}_i(T  \\infty) = 1$), which is true for any transient state in a finite-state chain that can reach an absorbing state, the estimator $\\hat{t}^{\\mathrm{PS}}_n$ is the average of $n$ i.i.d. samples of the random variable $T$. By the properties of expectation, $\\mathbb{E}[\\hat{t}^{\\mathrm{PS}}_n] = \\mathbb{E}[T] = t_i$, so the estimator is unbiased. The variance of the sample mean of $n$ i.i.d. random variables is the variance of one variable divided by $n$, so $\\mathrm{Var}(\\hat{t}^{\\mathrm{PS}}_n) = \\mathrm{Var}(T)/n$. This part is correct.\n-   **Plug-in Estimator ($\\hat{t}^{\\mathrm{PLUG}}$):** This estimator is of the form $g(\\hat{Q})$, where $\\hat{Q}$ is an empirical estimate of $Q$ and $g(X) = (I-X)^{-1}\\mathbf{1}$ is a nonlinear function. For a nonlinear function $g$ and a random variable $\\hat{Q}$, it is generally true that $\\mathbb{E}[g(\\hat{Q})] \\neq g(\\mathbb{E}[\\hat{Q}])$ for finite samples. Since the true value is $t = g(Q) = g(\\mathbb{E}[\\hat{Q}])$ (assuming $\\hat{Q}$ is unbiased), the estimator is generally biased. This part is correct.\n-   **Variance Comparison:** When $\\rho(Q) \\to 1$, the expected absorption time $t$ and its variance $\\mathrm{Var}(T)$ become very large. The path sampling estimator's variance, being proportional to $\\mathrm{Var}(T)$, will be large. The plug-in estimator uses the simulation budget to estimate the one-step transition probabilities in $Q$. This can be much more statistically efficient than simulating a few very long paths. By pooling information from all transitions, it can achieve a lower variance. This trade-off is a well-known phenomenon. Thus, the statement is correct.\n-   **Verdict for A:** Correct.\n\n**Analysis of Option B:**\n-   The premise is that $\\mathbb{P}_i(T = \\infty)  0$. In this case, the unconditional expectation is $\\mathbb{E}_i[T] = \\infty$.\n-   The proposed estimator discards non-absorbing trajectories and averages the absorption times of the ones that do absorb. This procedure estimates the *conditional* expectation $\\mathbb{E}_i[T \\mid T  \\infty]$, which is a finite quantity (assuming it exists).\n-   An estimator that yields a finite value cannot be an unbiased estimator for an infinite quantity. The bias is infinite. Therefore, the statement is incorrect. (Note: As discussed in the validation, the premise $\\mathbb{P}_i(T = \\infty)  0$ itself contradicts the problem's setup of a finite-state chain partitioned into transient and absorbing states, where absorption from a transient state is certain.)\n-   **Verdict for B:** Incorrect.\n\n**Analysis of Option C:**\n-   The statement asserts three things: (1) $N=(I-Q)^{-1}$ exists and equals the Neumann series, (2) this implies $t=N\\mathbf{1}$, and (3) this implies $t_i = \\mathbb{E}_i\\!\\left[\\sum_{k=0}^{\\infty} \\mathbf{1}\\{X_k \\in \\mathcal{T}\\}\\right]$.\n-   **(1)** For a finite-state chain, if $\\mathcal{T}$ is the set of all transient states, then from every state in $\\mathcal{T}$ there is a path to a recurrent state (here, an absorbing state in $\\mathcal{A}$). This guarantees that the probability of staying in $\\mathcal{T}$ forever is zero, which implies $\\lim_{k\\to\\infty} Q^k = \\mathbf{0}$. This, in turn, is equivalent to the spectral radius $\\rho(Q)  1$. If $\\rho(Q)  1$, the matrix $I-Q$ is invertible and its inverse is given by the convergent geometric series $N = \\sum_{k=0}^{\\infty} Q^k$. So, this part is correct.\n-   **(2)** The expected absorption time vector $t$ is derived from the first-step analysis: $t_i = 1 + \\sum_{j \\in \\mathcal{T}} Q_{ij} t_j$. In vector form, this is $t = \\mathbf{1} + Qt$, which gives $(I-Q)t = \\mathbf{1}$. Since $(I-Q)^{-1}$ exists, $t = (I-Q)^{-1}\\mathbf{1} = N\\mathbf{1}$. This is correct.\n-   **(3)** The absorption time $T$ is the time step at which the chain first leaves the transient set $\\mathcal{T}$. The total number of time steps (including $k=0$) that the chain spends in $\\mathcal{T}$ is exactly $T$. Thus, $T = \\sum_{k=0}^{\\infty} \\mathbf{1}\\{X_k \\in \\mathcal{T}\\}$. Taking the expectation gives $t_i = \\mathbb{E}_i[T] = \\mathbb{E}_i\\!\\left[\\sum_{k=0}^{\\infty} \\mathbf{1}\\{X_k \\in \\mathcal{T}\\}\\right]$. This is a fundamental interpretation of the expected absorption time. This is also correct.\n-   **Verdict for C:** Correct.\n\n**Analysis of Option D:**\n-   This statement claims that the Law of Large Numbers (LLN) implies $\\mathbb{E}[(I - \\hat{Q})^{-1}] = (I - \\mathbb{E}[\\hat{Q}])^{-1}$ for finite samples. This is fundamentally wrong. The LLN is an asymptotic theorem about convergence in probability or almost surely; it makes no claims about expectations at finite sample sizes. The fact that the inverse is nonlinear is precisely the reason why the equality does *not* hold for finite samples (by Jensen's inequality, for example). The statement uses a correct premise (nonlinearity) to draw a false conclusion, and misattributes it to the LLN.\n-   **Verdict for D:** Incorrect.\n\n**Analysis of Option E:**\n-   When $\\rho(Q)$ is close to $1$, the matrix $I-Q$ is nearly singular. The mapping from a matrix to its inverse is known to be ill-conditioned near a singular matrix. The condition number of the inversion problem blows up as $\\rho(Q) \\to 1$.\n-   Consequently, small errors in the estimation of $Q$ (i.e., a small norm of $\\hat{Q}-Q$) can be amplified into very large errors in the computed inverse $(I-\\hat{Q})^{-1}$. This large error will manifest as both high variance and significant bias in the plug-in estimator $\\hat{t}^{\\mathrm{PLUG}}$.\n-   In this same regime, the path-sampling estimator $\\hat{t}^{\\mathrm{PS}}_n$ is unbiased, but its variance is very large because the absorption times themselves have a large variance.\n-   The Mean Squared Error (MSE) is $\\text{Variance} + \\text{Bias}^2$. For the plug-in estimator, both terms can be large due to ill-conditioning. For the path-sampling estimator, the bias is zero. We are comparing a method with high variance ($\\hat{t}^{\\mathrm{PS}}_n$) to one with potentially high variance *and* high bias ($\\hat{t}^{\\mathrm{PLUG}}$). It is entirely possible that the bias and error amplification of the plug-in method are so severe that its MSE is larger than that of the simple, unbiased path-sampling method.\n-   **Verdict for E:** Correct.\n\nFinal selection is A, C, and E.",
            "answer": "$$\\boxed{ACE}$$"
        }
    ]
}