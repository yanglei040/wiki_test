{
    "hands_on_practices": [
        {
            "introduction": "The first step in evaluating any finite difference method is to quantify its local accuracy—how well it approximates the differential equation at a single point. This foundational exercise () guides you through the essential technique of using Taylor series expansions to derive the local truncation error (LTE). By applying this to the standard three-point centered difference approximation for the second derivative, you will rigorously establish its second-order accuracy, a cornerstone result in the numerical analysis of PDEs.",
            "id": "3416695",
            "problem": "Consider the one-dimensional partial differential equation (PDE) $-u''(x)=f(x)$ on $[0,1]$ with Dirichlet boundary conditions $u(0)=\\alpha$ and $u(1)=\\beta$, where $u\\in C^{4}([0,1])$ and $f$ is continuous. Let a uniform grid be given by $x_{i}=ih$ for $i=0,1,\\dots,N$ with $h=1/N$. Define the discrete operator at interior nodes by\n$$\nL_{h}u(x_{i}) \\equiv \\frac{-u(x_{i-1})+2u(x_{i})-u(x_{i+1})}{h^{2}}.\n$$\nThe local truncation error (LTE) at an interior grid point $x_{i}$ is defined as\n$$\n\\tau_{i}(h) \\equiv L_{h}u(x_{i})-f(x_{i}).\n$$\nUsing only the definition of LTE and Taylor’s theorem with an appropriate remainder valid under $u\\in C^{4}([0,1])$, derive the leading-order term of $\\tau_{i}(h)$ as $h\\to 0$ and thereby justify its order in $h$. Your final answer must be a single closed-form analytic expression for the leading term of $\\tau_{i}(h)$ at an interior node $x_{i}$. No numerical evaluation is required, and no rounding is needed. Express your final answer in terms of $h$ and derivatives of $u$ evaluated at $x_{i}$.",
            "solution": "The problem is first validated to ensure it is self-contained, scientifically grounded, and well-posed.\n\n### Step 1: Extract Givens\n- **PDE**: $-u''(x)=f(x)$ for $x \\in [0,1]$.\n- **Boundary Conditions**: $u(0)=\\alpha$ and $u(1)=\\beta$.\n- **Smoothness**: The solution $u$ is in the class $C^{4}([0,1])$, and $f$ is a continuous function.\n- **Discretization**: A uniform grid is defined by $x_{i}=ih$ for $i=0,1,\\dots,N$, with step size $h=1/N$.\n- **Discrete Operator**: At interior nodes $x_i$ ($i=1, \\dots, N-1$), the discrete operator is $L_{h}u(x_{i}) \\equiv \\frac{-u(x_{i-1})+2u(x_{i})-u(x_{i+1})}{h^{2}}$.\n- **Local Truncation Error (LTE)**: The LTE at an interior grid point $x_i$ is defined as $\\tau_{i}(h) \\equiv L_{h}u(x_{i})-f(x_{i})$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a standard exercise in the numerical analysis of differential equations, specifically concerning the derivation of the local truncation error for a finite difference approximation.\n- **Scientifically Grounded**: The problem is based on fundamental principles of calculus (Taylor's theorem) and numerical methods. The finite difference approximation of $-u''$ is a cornerstone of the field. All aspects are scientifically and mathematically sound.\n- **Well-Posed**: The problem is clearly stated, with all necessary definitions and conditions provided. The smoothness condition $u \\in C^{4}([0,1])$ is precisely what is required to perform the Taylor expansion to the necessary order. The goal is unambiguous.\n- **Objective**: The problem is stated in precise, formal mathematical language, devoid of any subjectivity or ambiguity.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. We may proceed with the derivation.\n\n### Derivation of the Local Truncation Error\n\nThe objective is to find the leading-order term of the local truncation error $\\tau_{i}(h)$ at an interior node $x_i$.\nThe definition of the LTE is:\n$$\n\\tau_{i}(h) \\equiv L_{h}u(x_{i})-f(x_{i}).\n$$\nThe problem states that the exact solution $u(x)$ satisfies the partial differential equation (in this one-dimensional case, an ordinary differential equation) $-u''(x)=f(x)$ for all $x \\in [0,1]$. Therefore, at the grid point $x_i$, we have $-u''(x_i)=f(x_i)$. Substituting this into the definition of $\\tau_i(h)$ gives:\n$$\n\\tau_{i}(h) = L_{h}u(x_{i}) - (-u''(x_i)) = L_{h}u(x_{i}) + u''(x_i).\n$$\nNow, we substitute the definition of the discrete operator $L_h u(x_i)$:\n$$\n\\tau_{i}(h) = \\frac{-u(x_{i-1})+2u(x_{i})-u(x_{i+1})}{h^{2}} + u''(x_{i}).\n$$\nTo analyze this expression, we use Taylor's theorem to expand the terms $u(x_{i-1})$ and $u(x_{i+1})$ around the point $x_i$. Note that $x_{i-1} = x_i - h$ and $x_{i+1} = x_i + h$. The given condition $u \\in C^{4}([0,1])$ ensures that the fourth derivative of $u$ is continuous, which validates the Taylor expansions up to the fourth-order term.\n\nThe Taylor expansion for $u(x_i+h)$ around $x_i$ is:\n$$\nu(x_{i+1}) = u(x_i+h) = u(x_i) + h u'(x_i) + \\frac{h^2}{2!} u''(x_i) + \\frac{h^3}{3!} u'''(x_i) + \\frac{h^4}{4!} u^{(4)}(x_i) + o(h^4).\n$$\nThe Taylor expansion for $u(x_i-h)$ around $x_i$ is:\n$$\nu(x_{i-1}) = u(x_i-h) = u(x_i) - h u'(x_i) + \\frac{h^2}{2!} u''(x_i) - \\frac{h^3}{3!} u'''(x_i) + \\frac{h^4}{4!} u^{(4)}(x_i) + o(h^4).\n$$\nNow, we substitute these expansions into the numerator of the expression for $L_h u(x_i)$:\n$$\n-u(x_{i-1})+2u(x_{i})-u(x_{i+1}) = -[u(x_i-h)] + 2u(x_i) - [u(x_i+h)].\n$$\nLet's group the terms by the order of the derivative of $u$ at $x_i$:\n$$\n\\begin{align*}\n-u(x_{i-1})+2u(x_{i})-u(x_{i+1}) = & -\\left(u(x_i) - h u'(x_i) + \\frac{h^2}{2} u''(x_i) - \\frac{h^3}{6} u'''(x_i) + \\frac{h^4}{24} u^{(4)}(x_i) + o(h^4)\\right) \\\\\n& + 2u(x_i) \\\\\n& - \\left(u(x_i) + h u'(x_i) + \\frac{h^2}{2} u''(x_i) + \\frac{h^3}{6} u'''(x_i) + \\frac{h^4}{24} u^{(4)}(x_i) + o(h^4)\\right) \\\\\n= & (-1+2-1)u(x_i) + (h-h)u'(x_i) + \\left(-\\frac{h^2}{2} - \\frac{h^2}{2}\\right)u''(x_i) \\\\\n& + \\left(\\frac{h^3}{6} - \\frac{h^3}{6}\\right)u'''(x_i) + \\left(-\\frac{h^4}{24} - \\frac{h^4}{24}\\right)u^{(4)}(x_i) + o(h^4) \\\\\n= & 0 \\cdot u(x_i) + 0 \\cdot u'(x_i) - h^2 u''(x_i) + 0 \\cdot u'''(x_i) - \\frac{2h^4}{24} u^{(4)}(x_i) + o(h^4) \\\\\n= & -h^2 u''(x_i) - \\frac{h^4}{12} u^{(4)}(x_i) + o(h^4).\n\\end{align*}\n$$\nNow, substitute this result back into the expression for $\\tau_i(h)$:\n$$\n\\tau_{i}(h) = \\frac{-h^2 u''(x_i) - \\frac{h^4}{12} u^{(4)}(x_i) + o(h^4)}{h^{2}} + u''(x_i).\n$$\nDividing the terms by $h^2$, we get:\n$$\n\\tau_{i}(h) = \\left(-u''(x_i) - \\frac{h^2}{12} u^{(4)}(x_i) + o(h^2)\\right) + u''(x_i).\n$$\nThe $u''(x_i)$ terms cancel out:\n$$\n\\tau_{i}(h) = - \\frac{h^2}{12} u^{(4)}(x_i) + o(h^2).\n$$\nAs $h \\to 0$, the dominant term in this expression is the one with the lowest power of $h$. This is the leading-order term. Therefore, the leading-order term of the local truncation error $\\tau_i(h)$ is $-\\frac{h^2}{12} u^{(4)}(x_i)$.\n\nThis result also justifies the order of accuracy of the finite difference scheme. Since the local truncation error $\\tau_i(h)$ is proportional to $h^2$, we say that the method is $O(h^2)$, or second-order accurate. This means that if the step size $h$ is reduced by a factor of $2$, the local error is expected to decrease by a factor of $2^2=4$, assuming $u^{(4)}(x_i)$ is not zero.\nThe final answer is the explicit analytical expression for this leading term.",
            "answer": "$$\n\\boxed{- \\frac{h^{2}}{12} u^{(4)}(x_{i})}\n$$"
        },
        {
            "introduction": "While uniform grids provide a clean theoretical starting point, practical applications often demand nonuniform meshes to resolve complex features efficiently. This practice () extends the analysis of local truncation error to this more general and challenging setting. You will discover that the order of accuracy is not an intrinsic property of the difference formula alone but is intricately linked to the local geometry of the grid, demonstrating how mesh irregularity can degrade a scheme's performance and revealing the conditions needed to restore higher-order accuracy.",
            "id": "3416659",
            "problem": "Consider a twice-interval nonuniform mesh in one spatial dimension with nodes $x_{i-1}$, $x_i$, $x_{i+1}$, local left spacing $h_i = x_i - x_{i-1}$, and local right spacing $h_{i+1} = x_{i+1} - x_i$. Let $u : [0,1] \\to \\mathbb{R}$ be a sufficiently smooth function. The standard three-point nonuniform finite-difference approximation to the second derivative at $x_i$ uses the linear combination of neighboring nodal values\n$$\nD^{2}u_i \\;=\\; \\frac{2}{h_i\\,h_{i+1}\\,(h_i + h_{i+1})}\\,\\Big( h_i\\,u_{i+1} \\;-\\; (h_i + h_{i+1})\\,u_i \\;+\\; h_{i+1}\\,u_{i-1} \\Big),\n$$\nwhere $u_j = u(x_j)$.\n\nTask A: Starting from Taylor’s theorem around $x_i$ and assuming the existence of at least four continuous derivatives of $u$, derive the local truncation error $\\tau_i = D^{2}u_i - u''(x_i)$ up to and including the terms proportional to $u^{(3)}(x_i)$ and $u^{(4)}(x_i)$, expressed in closed form in terms of $h_i$, $h_{i+1}$, $u^{(3)}(x_i)$, and $u^{(4)}(x_i)$.\n\nTask B: Consider the one-dimensional elliptic boundary value problem $-u''(x) = f(x)$ on $[0,1]$ with homogeneous Dirichlet boundary conditions $u(0) = 0$ and $u(1) = 0$. It is discretized at interior nodes by replacing $u''(x_i)$ with $D^{2}u_i$ and imposing the boundary conditions at the endpoints. State sufficient conditions on the mesh and the solution regularity that guarantee the global error $\\|u - u_h\\|_{\\infty}$ is $O(h_{\\max}^{2})$ as $h_{\\max} \\to 0$, where $h_{\\max} = \\max_j h_j$. In your conditions, explicitly identify the role of local symmetry, namely the behavior of $h_{i+1} - h_i$, and the stability of the discrete operator.\n\nYour final answer must be the closed-form analytic expression obtained in Task A. No rounding is required.",
            "solution": "The problem as stated is a standard exercise in the numerical analysis of finite difference methods. It is scientifically grounded, well-posed, objective, and complete. All components, including the finite difference formula, the concept of local truncation error, and the analysis of global error for a boundary value problem, are fundamental to the field. The problem is therefore deemed valid and a full solution is provided below.\n\nThe solution is divided into two parts, corresponding to Task A and Task B.\n\n**Task A: Derivation of the Local Truncation Error**\n\nThe objective is to find the local truncation error $\\tau_i = D^{2}u_i - u''(x_i)$, where $u''(x_i)$ is the exact second derivative of the function $u(x)$ at the node $x_i$. The given three-point finite-difference approximation for the second derivative on a nonuniform mesh is:\n$$\nD^{2}u_i = \\frac{2}{h_i h_{i+1} (h_i + h_{i+1})} \\left( h_i u_{i+1} - (h_i + h_{i+1})u_i + h_{i+1} u_{i-1} \\right)\n$$\nHere, $u_j = u(x_j)$, $h_i = x_i - x_{i-1} > 0$, and $h_{i+1} = x_{i+1} - x_i > 0$.\n\nWe are given that the function $u(x)$ has at least four continuous derivatives, i.e., $u \\in C^4([0,1])$. We can therefore use Taylor's theorem to expand the values $u_{i+1} = u(x_i + h_{i+1})$ and $u_{i-1} = u(x_i - h_i)$ around the point $x_i$. We expand up to the fourth-order term, with higher-order terms represented by $O(h^5)$.\nLet $u^{(k)}(x_i)$ denote the $k$-th derivative of $u$ at $x_i$. The expansions are:\n$$\nu_{i+1} = u(x_i) + h_{i+1} u^{(1)}(x_i) + \\frac{h_{i+1}^2}{2} u^{(2)}(x_i) + \\frac{h_{i+1}^3}{6} u^{(3)}(x_i) + \\frac{h_{i+1}^4}{24} u^{(4)}(x_i) + O(h_{i+1}^5)\n$$\n$$\nu_{i-1} = u(x_i) - h_i u^{(1)}(x_i) + \\frac{h_i^2}{2} u^{(2)}(x_i) - \\frac{h_i^3}{6} u^{(3)}(x_i) + \\frac{h_i^4}{24} u^{(4)}(x_i) + O(h_i^5)\n$$\nLet's substitute these expansions into the linear combination $h_i u_{i+1} - (h_i + h_{i+1})u_i + h_{i+1} u_{i-1}$. We group terms by the order of the derivative of $u$ at $x_i$.\n\nTerm with $u(x_i)$:\n$$\nh_i u(x_i) - (h_i + h_{i+1}) u(x_i) + h_{i+1} u(x_i) = (h_i - h_i - h_{i+1} + h_{i+1}) u(x_i) = 0\n$$\nTerm with $u^{(1)}(x_i)$:\n$$\nh_i (h_{i+1} u^{(1)}(x_i)) + h_{i+1} (-h_i u^{(1)}(x_i)) = (h_i h_{i+1} - h_{i+1} h_i) u^{(1)}(x_i) = 0\n$$\nTerm with $u^{(2)}(x_i)$:\n$$\nh_i \\left(\\frac{h_{i+1}^2}{2} u^{(2)}(x_i)\\right) + h_{i+1} \\left(\\frac{h_i^2}{2} u^{(2)}(x_i)\\right) = \\left(\\frac{h_i h_{i+1}^2 + h_{i+1} h_i^2}{2}\\right) u^{(2)}(x_i) = \\frac{h_i h_{i+1}(h_{i+1} + h_i)}{2} u^{(2)}(x_i)\n$$\nTerm with $u^{(3)}(x_i)$:\n$$\nh_i \\left(\\frac{h_{i+1}^3}{6} u^{(3)}(x_i)\\right) + h_{i+1} \\left(-\\frac{h_i^3}{6} u^{(3)}(x_i)\\right) = \\left(\\frac{h_i h_{i+1}^3 - h_{i+1} h_i^3}{6}\\right) u^{(3)}(x_i) = \\frac{h_i h_{i+1}(h_{i+1}^2 - h_i^2)}{6} u^{(3)}(x_i)\n$$\nUsing the difference of squares, $h_{i+1}^2 - h_i^2 = (h_{i+1} - h_i)(h_{i+1} + h_i)$. The term becomes:\n$$\n\\frac{h_i h_{i+1}(h_{i+1} - h_i)(h_{i+1} + h_i)}{6} u^{(3)}(x_i)\n$$\nTerm with $u^{(4)}(x_i)$:\n$$\nh_i \\left(\\frac{h_{i+1}^4}{24} u^{(4)}(x_i)\\right) + h_{i+1} \\left(\\frac{h_i^4}{24} u^{(4)}(x_i)\\right) = \\left(\\frac{h_i h_{i+1}^4 + h_{i+1} h_i^4}{24}\\right) u^{(4)}(x_i) = \\frac{h_i h_{i+1}(h_{i+1}^3 + h_i^3)}{24} u^{(4)}(x_i)\n$$\nUsing the sum of cubes, $h_{i+1}^3 + h_i^3 = (h_{i+1} + h_i)(h_{i+1}^2 - h_i h_{i+1} + h_i^2)$. The term becomes:\n$$\n\\frac{h_i h_{i+1}(h_{i+1} + h_i)(h_{i+1}^2 - h_i h_{i+1} + h_i^2)}{24} u^{(4)}(x_i)\n$$\nNow, we assemble these terms and multiply by the prefactor $\\frac{2}{h_i h_{i+1} (h_i + h_{i+1})}$ to obtain the expression for $D^{2}u_i$:\n\n$D^{2}u_i = \\frac{2}{h_i h_{i+1} (h_i + h_{i+1})} \\Big[$\n$\\frac{h_i h_{i+1}(h_{i+1} + h_i)}{2} u^{(2)}(x_i) +$\n$\\frac{h_i h_{i+1}(h_{i+1} - h_i)(h_{i+1} + h_i)}{6} u^{(3)}(x_i) +$\n$\\frac{h_i h_{i+1}(h_{i+1} + h_i)(h_{i+1}^2 - h_i h_{i+1} + h_i^2)}{24} u^{(4)}(x_i) + O(h^5) \\Big]$\n\nwhere $h = \\max(h_i, h_{i+1})$.\nMultiplying through, we get:\n$$\nD^{2}u_i = u^{(2)}(x_i) + \\frac{2}{6}(h_{i+1} - h_i) u^{(3)}(x_i) + \\frac{2}{24}(h_{i+1}^2 - h_i h_{i+1} + h_i^2) u^{(4)}(x_i) + O(h^3)\n$$\n$$\nD^{2}u_i = u^{(2)}(x_i) + \\frac{1}{3}(h_{i+1} - h_i) u^{(3)}(x_i) + \\frac{1}{12}(h_i^2 - h_i h_{i+1} + h_{i+1}^2) u^{(4)}(x_i) + O(h^3)\n$$\nThe local truncation error $\\tau_i$ is defined as $\\tau_i = D^{2}u_i - u^{(2)}(x_i)$. Therefore,\n$$\n\\tau_i = \\frac{h_{i+1} - h_i}{3} u^{(3)}(x_i) + \\frac{h_i^2 - h_i h_{i+1} + h_{i+1}^2}{12} u^{(4)}(x_i) + O(h^3)\n$$\nThe expression for the truncation error up to and including the terms proportional to $u^{(3)}(x_i)$ and $u^{(4)}(x_i)$ is the quantity requested.\n\n**Task B: Conditions for Second-Order Global Error**\n\nWe consider the boundary value problem $-u''(x) = f(x)$ for $x \\in [0,1]$ with $u(0)=0$ and $u(1)=0$. The discretization replaces $-u''(x_i)$ with $-D^2u_i$, leading to a system of linear equations $A_h u_h = f$ for the numerical solution vector $u_h$. The exact solution $u$ satisfies $-D^2 u(x_i) = f(x_i) - \\tau_i$, where $\\tau_i$ is the local truncation error derived in Task A. The global error vector $e = u - u_h$ therefore satisfies the error equation $A_h e = \\tau$, where $\\tau$ is the vector of local truncation errors.\n\nThe global error in the maximum norm is bounded by $\\|e\\|_{\\infty} \\le \\|A_h^{-1}\\|_{\\infty} \\|\\tau\\|_{\\infty}$. For the global error to be second-order, $\\|e\\|_{\\infty} = O(h_{\\max}^2)$, we need two main ingredients: stability of the discrete operator and second-order consistency of the scheme.\n\n1.  **Stability of the Discrete Operator:** This requires that the norm of the inverse matrix, $\\|A_h^{-1}\\|_{\\infty}$, is bounded by a constant independent of the mesh size $h_{\\max}$. The matrix $A_h$ corresponding to the operator $-D^2$ on a non-uniform grid is a tridiagonal matrix. It can be shown to be an M-matrix and thus its inverse has non-negative entries. For such matrices, stability is typically guaranteed if the mesh is quasi-uniform, meaning there exists a constant $\\sigma > 0$ such that for all adjacent intervals, $1/\\sigma \\le h_{i+1}/h_i \\le \\sigma$. This condition prevents the off-diagonal elements from becoming disproportionately large compared to the diagonal ones, ensuring the operator remains well-conditioned as $h_{\\max} \\to 0$.\n\n2.  **Second-Order Consistency:** This requires that the truncation error is of second order, i.e., $\\|\\tau\\|_{\\infty} = O(h_{\\max}^2)$. From Task A, the truncation error is\n    $$ \\tau_i = \\frac{h_{i+1} - h_i}{3} u^{(3)}(x_i) + \\frac{h_i^2 - h_i h_{i+1} + h_{i+1}^2}{12} u^{(4)}(x_i) + O(h_{\\max}^3) $$\n    The second term is of order $O(h_{\\max}^2)$. However, the first term, $\\frac{1}{3}(h_{i+1} - h_i)u^{(3)}(x_i)$, is generally of order $O(h_{\\max})$, which makes the scheme only first-order accurate. The role of \"local symmetry,\" described by the term $h_{i+1} - h_i$, is critical here. For the scheme to be second-order consistent, this leading error term must be reduced to $O(h_{\\max}^2)$. This is achieved if the mesh spacing varies smoothly, which can be stated formally as the condition $|h_{i+1} - h_i| \\le C h_{\\max}^2$ for some constant $C$ and for all $i$. If this condition holds, the scheme becomes second-order consistent. A uniform mesh ($h_{i+1} = h_i$) is a special case that trivially satisfies this condition.\n\n3.  **Solution Regularity:** The derivation of the truncation error and its bound assumes that the solution $u(x)$ is sufficiently smooth. The expression for $\\tau_i$ involves $u^{(3)}$ and $u^{(4)}$. For these terms to be well-defined and bounded across the domain $[0,1]$, we require $u \\in C^4([0,1])$. From the differential equation $-u''=f$, standard elliptic regularity theory implies that if the source term $f(x)$ is in $C^2([0,1])$, then the solution $u(x)$ will be in $C^4([0,1])$.\n\nIn summary, sufficient conditions for achieving a global error of $\\|u - u_h\\|_{\\infty} = O(h_{\\max}^2)$ are:\n(a) The solution has sufficient regularity, $u \\in C^4([0,1])$, which is ensured if $f \\in C^2([0,1])$.\n(b) The discrete operator is stable, which is ensured by a quasi-uniform mesh condition, $\\exists \\sigma: h_{i+1}/h_i \\le \\sigma$.\n(c) The mesh is smoothly varying, such that $|h_{i+1} - h_i| = O(h_{\\max}^2)$.",
            "answer": "$$\\boxed{\\frac{h_{i+1} - h_i}{3} u^{(3)}(x_i) + \\frac{h_i^2 - h_i h_{i+1} + h_{i+1}^2}{12} u^{(4)}(x_i)}$$"
        },
        {
            "introduction": "A powerful numerical scheme must do more than just minimize error; it must also preserve fundamental physical and mathematical properties of the underlying PDE, such as maximum principles. This advanced, code-based practice () explores this crucial connection between local discretization choices and the global qualitative behavior of the solution. You will investigate how a standard stencil for anisotropic diffusion can lead to non-physical \"overshoots\" by violating the conditions for a discrete maximum principle, and then implement a practical fix to restore this essential property and improve the global accuracy of the solution.",
            "id": "3416731",
            "problem": "Consider the two-dimensional anisotropic diffusion model posed on the unit square domain $[0,1]\\times[0,1]$ with homogeneous Dirichlet boundary data given by the exact solution $u(x,y)=\\sin(\\pi x)\\sin(\\pi y)$. The governing elliptic partial differential equation is $-\\nabla\\cdot(\\boldsymbol{D}\\nabla u)=f$, where the diffusion tensor is $$\\boldsymbol{D}=\\begin{pmatrix}1&\\beta\\\\ \\beta&1\\end{pmatrix}$$ with a constant anisotropy parameter $\\beta\\in\\mathbb{R}$. The source term $f$ is defined so that $u$ is the exact solution, i.e., $f(x,y)=-\\nabla\\cdot(\\boldsymbol{D}\\nabla u(x,y))$. The discrete approximation uses a uniform Cartesian grid with $N$ interior points per coordinate direction, with mesh spacing $h=1/(N+1)$ and interior nodes at coordinates $(x_i,y_j)=(ih,jh)$ for $i=1,\\dots,N$ and $j=1,\\dots,N$, respectively.\n\nYou must assemble the discrete operator $\\boldsymbol{A}$ acting on the vector of interior nodal unknowns using the following stencil:\n- The second derivatives $u_{xx}$ and $u_{yy}$ are each approximated by central differences with the standard five-point stencil, giving weights $4/h^2$ on the diagonal and $-1/h^2$ on each of the four axis-aligned neighbors.\n- The mixed derivative $u_{xy}$ is approximated by the standard central-difference nine-point contribution\n$$u_{xy}(x_i,y_j)\\approx \\frac{u_{i+1,j+1}-u_{i+1,j-1}-u_{i-1,j+1}+u_{i-1,j-1}}{4h^2},$$\nwhich contributes to the cross terms in $-\\nabla\\cdot(\\boldsymbol{D}\\nabla u)$ via $-2\\beta\\,u_{xy}$. This yields corner weights $\\pm \\beta/(2h^2)$ with signs as implied by the above formula. The resulting $\\boldsymbol{A}$ is symmetric.\n\nThe fundamental base for your derivation and algorithmic design must begin with the continuous maximum principle for uniformly elliptic operators, the notion of an $M$-matrix for discrete operators, and the standard definitions of local truncation error and global discretization error:\n- A symmetric tensor $\\boldsymbol{D}$ with eigenvalues bounded below by a positive constant implies uniform ellipticity and a continuous maximum principle: if $f\\ge 0$ and boundary data is bounded, then interior maxima do not exceed boundary maxima.\n- A sparse matrix $\\boldsymbol{A}$ is an $M$-matrix if its off-diagonal entries are nonpositive and it is weakly diagonally dominant by rows with a positive diagonal; this suffices for a discrete maximum principle.\n- The local truncation error at a grid point is the residual obtained by inserting the exact solution into the discrete operator, and the global discretization error is the difference between the discrete solution and the exact solution measured in a norm, here the $L^{\\infty}$ norm.\n\nThe problem you must solve comprises three parts:\n$1.$ Starting from these principles, explain clearly why the presence of locally sign-indefinite corner weights and overly large negative off-diagonals in the anisotropic nine-point stencil can violate the $M$-matrix property and hence the discrete maximum principle, thereby admitting global overshoots where the discrete solution exceeds the continuous maximum $1$ attained by $u(x,y)$ at $(x,y)=(\\tfrac{1}{2},\\tfrac{1}{2})$.\n$2.$ Propose and implement a strictly local algebraic fix that restores the $M$-matrix property without changing the discrete operator beyond the immediate row and column associated to the violating entries: for any positive off-diagonal entry $A_{ij}$, with $i\\ne j$, set $A_{ij}\\leftarrow 0$ and $A_{ji}\\leftarrow 0$, and increase both diagonals $A_{ii}$ and $A_{jj}$ by the removed amount to maintain the row-sum consistency at each row. Explain why this fix enforces nonpositive off-diagonals, increases diagonal dominance, and thereby improves conformity with the discrete maximum principle.\n$3.$ Quantify the change in the global $L^{\\infty}$ error due to this local fix. For each test case defined below, compute the $L^{\\infty}$ error $E_{\\infty}=\\max_{i,j}|u^{h}_{ij}-u(x_i,y_j)|$ for the original stencil and for the locally fixed stencil, and report the improvement $\\Delta E_{\\infty}=E_{\\infty,\\text{orig}}-E_{\\infty,\\text{fix}}$ as a float. Also compute the overshoot magnitude $O=\\max\\{0,\\max_{i,j}u^{h}_{ij}-1\\}$ before and after the fix, but only $\\Delta E_{\\infty}$ must be printed. No physical units are involved, and all angles, if any appear, must be in radians.\n\nUse the following test suite $(N,\\beta)$ values to exercise diverse regimes:\n- Case A (happy path, isotropic): $(N,\\beta)=(33,0)$.\n- Case B (moderate anisotropy): $(N,\\beta)=(33,0.6)$.\n- Case C (strong anisotropy, coarse grid): $(N,\\beta)=(17,0.95)$.\n- Case D (negative cross anisotropy): $(N,\\beta)=(33,-0.8)$.\n\nYour program must:\n- Assemble $\\boldsymbol{A}$ and the right-hand side vector $\\boldsymbol{b}$ with entries $b_{ij}=f(x_i,y_j)$ obtained analytically from $u$ and $\\boldsymbol{D}$, where $f(x,y)=-\\nabla\\cdot(\\boldsymbol{D}\\nabla u(x,y))$.\n- Solve $\\boldsymbol{A}\\boldsymbol{u}^{h}=\\boldsymbol{b}$ for the interior unknowns $\\boldsymbol{u}^{h}$ before and after applying the local fix.\n- Compute $E_{\\infty,\\text{orig}}$, $E_{\\infty,\\text{fix}}$, and the improvement $\\Delta E_{\\infty}$ for each case.\n\nFinal output format: Your program should produce a single line of output containing the four improvement values as a comma-separated list enclosed in square brackets (e.g., $[a,b,c,d]$). Each entry must be a float. No other text should be printed.",
            "solution": "The problem requires a three-part analysis of a finite difference discretization for an anisotropic diffusion equation. We must first validate the problem's formulation, then provide a theoretical explanation of a potential numerical artifact, propose and justify a fix, and finally implement a numerical experiment to quantify the fix's effect.\n\n### Problem Validation\n\nThe problem is deemed valid. It is scientifically grounded in the established theory of numerical analysis for partial differential equations, specifically concerning finite difference methods, matrix properties ($M$-matrices), and maximum principles. The setup is well-posed: it defines a linear elliptic PDE on a simple domain with a known smooth solution, specifies a consistent discretization scheme, and asks for a quantifiable analysis of a known numerical issue. The problem is objective, complete, and contains no contradictions. All parameters and test cases are physically and mathematically reasonable for the context of demonstrating the specified numerical behavior. We may therefore proceed with the solution.\n\n### Part 1: Violation of the Discrete Maximum Principle\n\nThe governing partial differential equation (PDE) is given by $-\\nabla\\cdot(\\boldsymbol{D}\\nabla u)=f$ on the domain $[0,1]\\times[0,1]$, where $$\\boldsymbol{D}=\\begin{pmatrix}1&\\beta\\\\ \\beta&1\\end{pmatrix}$$ Expanding the divergence operator, the PDE becomes:\n$$ -\\frac{\\partial}{\\partial x}\\left(1 \\cdot \\frac{\\partial u}{\\partial x} + \\beta \\frac{\\partial u}{\\partial y}\\right) - \\frac{\\partial}{\\partial y}\\left(\\beta \\frac{\\partial u}{\\partial x} + 1 \\cdot \\frac{\\partial u}{\\partial y}\\right) = f $$\n$$ - \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\beta \\frac{\\partial^2 u}{\\partial y \\partial x} \\right) - \\left( \\beta \\frac{\\partial^2 u}{\\partial x \\partial y} + \\frac{\\partial^2 u}{\\partial y^2} \\right) = f $$\nAssuming sufficient smoothness of $u$ such that mixed partial derivatives are equal ($u_{xy} = u_{yx}$), the PDE is:\n$$ -u_{xx} - u_{yy} - 2\\beta u_{xy} = f $$\nThe problem specifies a finite-difference discretization on a uniform grid with spacing $h$. The second derivatives are approximated using standard central differences, and the mixed derivative is approximated as specified. For a generic interior node $(i,j)$, let $u_{i,j}$ denote the approximate solution at $(x_i, y_j)$. The discrete form of the operator at this node is:\n$$ - \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} - \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} - 2\\beta \\frac{u_{i+1,j+1}-u_{i+1,j-1}-u_{i-1,j+1}+u_{i-1,j-1}}{4h^2} = f_{i,j} $$\nGrouping terms by their corresponding nodal values, we obtain the computational stencil:\n$$ \\frac{1}{h^2} \\left( 4u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1} \\right) - \\frac{\\beta}{2h^2} \\left( u_{i+1,j+1}-u_{i+1,j-1}-u_{i-1,j+1}+u_{i-1,j-1} \\right) = f_{i,j} $$\nThis equation defines a row in the linear system $\\boldsymbol{A}\\boldsymbol{u}^h = \\boldsymbol{b}$. The coefficients of the neighboring $u$ values become the off-diagonal entries of the matrix $\\boldsymbol{A}$.\nThe stencil weights for the row corresponding to node $(i,j)$ are:\n- Center $(i,j)$: $\\frac{4}{h^2}$ (diagonal entry of $\\boldsymbol{A}$)\n- Axis-aligned neighbors $(i\\pm1,j)$, $(i,j\\pm1)$: $-\\frac{1}{h^2}$\n- Diagonal neighbors $(i+1,j+1)$, $(i-1,j-1)$: $-\\frac{\\beta}{2h^2}$\n- Anti-diagonal neighbors $(i-1,j+1)$, $(i+1,j-1)$: $+\\frac{\\beta}{2h^2}$\n\nA matrix $\\boldsymbol{A}$ is an $M$-matrix if it is nonsingular, its diagonal entries are positive ($A_{kk} > 0$), and all its off-diagonal entries are nonpositive ($A_{kl} \\le 0$ for $k \\ne l$). A sufficient condition for this is that $\\boldsymbol{A}$ is weakly diagonally dominant with nonpositive off-diagonals and positive diagonals. An $M$-matrix property guarantees a discrete maximum principle (DMP), ensuring that the numerical solution does not exhibit non-physical oscillations or extrema not present in the source term or boundary data.\n\nFrom the stencil weights, we observe that the off-diagonal entries of $\\boldsymbol{A}$ depend on the sign of $\\beta$:\n- If $\\beta > 0$, the weights corresponding to the anti-diagonal neighbors $(i-1,j+1)$ and $(i+1,j-1)$ are $+\\frac{\\beta}{2h^2} > 0$.\n- If $\\beta < 0$, let $\\beta = -|\\beta|$. The weights for the diagonal neighbors $(i+1,j+1)$ and $(i-1,j-1)$ become $-\\frac{-|\\beta|}{2h^2} = +\\frac{|\\beta|}{2h^2} > 0$.\n\nIn either case, for any $\\beta \\neq 0$, the matrix $\\boldsymbol{A}$ will have positive off-diagonal entries. This violates the definition of an $M$-matrix. The failure to satisfy the $M$-matrix property implies that the discrete operator does not satisfy a discrete maximum principle. The continuous solution $u(x,y)=\\sin(\\pi x)\\sin(\\pi y)$ has a maximum value of $1$ at $(0.5, 0.5)$ and is zero on the boundary. The loss of the DMP can lead to spurious \"overshoots\" in the numerical solution, where $\\max_{i,j} u^h_{i,j}$ can exceed the continuous maximum of $1$, a non-physical artifact.\n\n### Part 2: Restoring the $M$-Matrix Property\n\nTo restore the $M$-matrix property, we apply a local algebraic fix to the matrix $\\boldsymbol{A}$. The goal is to eliminate all positive off-diagonal entries without significantly altering the matrix properties related to consistency. The proposed fix is as follows:\n\nFor every pair of indices $(k,l)$ with $k \\ne l$ and $A_{kl} > 0$:\n1. Set the positive off-diagonal entry to zero: $A_{kl} \\leftarrow 0$. Since the original matrix $\\boldsymbol{A}$ is symmetric, we also set $A_{lk} \\leftarrow 0$.\n2. To maintain the original row sums (which is important for first-order consistency of the scheme), add the removed positive value to the corresponding diagonal entry. Specifically, update $A_{kk} \\leftarrow A_{kk} + A_{kl, \\text{orig}}$ and $A_{ll} \\leftarrow A_{ll} + A_{lk, \\text{orig}}$.\n\nThis procedure transforms the original matrix $\\boldsymbol{A}_{\\text{orig}}$ into a new matrix $\\boldsymbol{A}_{\\text{fix}}$. Let's analyze why this fix is effective:\n- **Nonpositive Off-Diagonals:** The procedure systematically identifies and zeroes out every positive off-diagonal entry. Originally negative or zero off-diagonal entries are left unchanged. By construction, the resulting matrix $\\boldsymbol{A}_{\\text{fix}}$ has exclusively nonpositive off-diagonal entries.\n- **Diagonal Dominance:** The diagonal entries of $\\boldsymbol{A}_{\\text{orig}}$ are positive ($4/h^2 > 0$). The fix adds a non-negative value (the original positive off-diagonal element) to each diagonal entry involved in a modification. This strictly increases the magnitude of the diagonal entries relative to the off-diagonals, thereby strengthening the diagonal dominance of the matrix. The row sums are preserved by construction.\n- **$M$-Matrix and DMP:** The resulting matrix $\\boldsymbol{A}_{\\text{fix}}$ now has positive diagonals, nonpositive off-diagonals, and is at least as diagonally dominant as $\\boldsymbol{A}_{\\text{orig}}$. This ensures $\\boldsymbol{A}_{\\text{fix}}$ is an $M$-matrix. An invertible $M$-matrix has a non-negative inverse ($\\boldsymbol{A}_{\\text{fix}}^{-1} \\ge 0$), which is a sufficient condition for the discrete operator to satisfy a maximum principle. This restoration of the DMP suppresses the non-physical overshoots and is expected to yield a more stable and qualitatively correct numerical solution.\n\n### Part 3: Quantifying the Improvement\n\nThe theoretical benefit of restoring the DMP is the suppression of numerical overshoots and improved stability. We quantify the practical impact by measuring the change in the global discretization error. The error is measured in the infinity norm ($L^{\\infty}$), defined as the maximum absolute difference between the numerical solution $u^h$ and the exact solution $u$ at the grid nodes: $E_{\\infty} = \\max_{i,j}|u^{h}_{ij}-u(x_i,y_j)|$.\n\nBy solving the linear system for both the original matrix ($\\boldsymbol{A}_{\\text{orig}}\\boldsymbol{u}^h_{\\text{orig}} = \\boldsymbol{b}$) and the fixed matrix ($\\boldsymbol{A}_{\\text{fix}}\\boldsymbol{u}^h_{\\text{fix}} = \\boldsymbol{b}$), we obtain two numerical solutions. We can then compute their respective errors, $E_{\\infty,\\text{orig}}$ and $E_{\\infty,\\text{fix}}$. The improvement is defined as $\\Delta E_{\\infty} = E_{\\infty,\\text{orig}} - E_{\\infty,\\text{fix}}$. A positive value for $\\Delta E_{\\infty}$ indicates that the local algebraic fix has reduced a global error measure, yielding a more accurate solution in addition to being more qualitatively correct. The provided code implements this procedure for the specified test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import csr_matrix, dok_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef assemble_system(N, beta):\n    \"\"\"\n    Assembles the sparse matrix A and the right-hand side vector b.\n    \"\"\"\n    h = 1.0 / (N + 1)\n    N2 = N * N\n    \n    # Create grid\n    x = np.linspace(h, 1.0 - h, N)\n    y = np.linspace(h, 1.0 - h, N)\n    X, Y = np.meshgrid(x, y, indexing='ij')\n\n    # Exact solution\n    u_exact = np.sin(np.pi * X) * np.sin(np.pi * Y)\n    \n    # Source term f(x,y)\n    f = (2.0 * np.pi**2 * np.sin(np.pi * X) * np.sin(np.pi * Y) -\n         2.0 * beta * np.pi**2 * np.cos(np.pi * X) * np.cos(np.pi * Y))\n    b = f.flatten()\n\n    # Stencil weights\n    h2 = h * h\n    w_center = 4.0 / h2\n    w_axis = -1.0 / h2\n    w_diag = -beta / (2.0 * h2)\n    w_anti = beta / (2.0 * h2)\n\n    # Assemble A using COO format\n    rows, cols, data = [], [], []\n\n    for i in range(N):\n        for j in range(N):\n            k = i * N + j\n            \n            # Center\n            rows.append(k)\n            cols.append(k)\n            data.append(w_center)\n            \n            # Axis-aligned neighbors\n            if i > 0:   # (i-1, j)\n                rows.append(k); cols.append(k - N); data.append(w_axis)\n            if i < N-1: # (i+1, j)\n                rows.append(k); cols.append(k + N); data.append(w_axis)\n            if j > 0:   # (i, j-1)\n                rows.append(k); cols.append(k - 1); data.append(w_axis)\n            if j < N-1: # (i, j+1)\n                rows.append(k); cols.append(k + 1); data.append(w_axis)\n                \n            # Mixed-derivative neighbors\n            # (i-1, j-1)\n            if i > 0 and j > 0:\n                rows.append(k); cols.append(k - N - 1); data.append(w_diag)\n            # (i+1, j+1)\n            if i < N-1 and j < N-1:\n                rows.append(k); cols.append(k + N + 1); data.append(w_diag)\n            # (i-1, j+1)\n            if i > 0 and j < N-1:\n                rows.append(k); cols.append(k - N + 1); data.append(w_anti)\n            # (i+1, j-1)\n            if i < N-1 and j > 0:\n                rows.append(k); cols.append(k + N - 1); data.append(w_anti)\n\n    A = csr_matrix((data, (rows, cols)), shape=(N2, N2))\n    return A, b, u_exact.flatten()\n\ndef apply_local_fix(A_orig):\n    \"\"\"\n    Applies the local algebraic fix to restore the M-matrix property.\n    \"\"\"\n    A_fix = A_orig.todok()\n    \n    # Find positive off-diagonal entries. Iterate over a copy of keys.\n    positive_off_diagonals = []\n    for (r, c), v in A_fix.items():\n        if r != c and v > 0:\n            positive_off_diagonals.append((r, c))\n\n    for r, c in positive_off_diagonals:\n        # Check if it hasn't been zeroed out by its symmetric partner\n        if A_fix[r, c] > 0:\n            val = A_fix[r, c]\n            A_fix[r, r] += val\n            A_fix[c, c] += val  # Using symmetry, A[c,r] was also positive\n            A_fix[r, c] = 0\n            A_fix[c, r] = 0\n            \n    return A_fix.tocsr()\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and compute error improvements.\n    \"\"\"\n    test_cases = [\n        (33, 0.0),      # Case A\n        (33, 0.6),      # Case B\n        (17, 0.95),     # Case C\n        (33, -0.8),     # Case D\n    ]\n\n    results = []\n    for N, beta in test_cases:\n        # 1. Assemble original system\n        A_orig, b, u_exact_flat = assemble_system(N, beta)\n        \n        # 2. Solve original system and compute error\n        u_h_orig = spsolve(A_orig, b)\n        e_inf_orig = np.max(np.abs(u_h_orig - u_exact_flat))\n        \n        # 3. Apply fix\n        A_fix = apply_local_fix(A_orig)\n        \n        # 4. Solve fixed system and compute error\n        u_h_fix = spsolve(A_fix, b)\n        e_inf_fix = np.max(np.abs(u_h_fix - u_exact_flat))\n\n        # 5. Calculate error improvement\n        delta_e_inf = e_inf_orig - e_inf_fix\n        results.append(delta_e_inf)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}