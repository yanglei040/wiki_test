{
    "hands_on_practices": [
        {
            "introduction": "Our first practice delves into the elegant connection between Fourier analysis and the spectral properties of discrete operators. For problems with periodic boundary conditions, the discrete Fourier modes serve as the exact eigenvectors of any linear, shift-invariant operator, which allows for a complete and analytical characterization of the spectrum. This exercise  will guide you through deriving the eigenvalues, known as the Fourier symbol, of the 1D discrete Laplacian, providing a foundational understanding of how discretization parameters like grid spacing $h$ directly map to the spectrum and the spectral radius $\\rho(L_h)$.",
            "id": "3383470",
            "problem": "Consider the one-dimensional discrete Laplacian arising in the semi-discretization of the heat equation on a periodic domain. Let the spatial domain be the interval $[0,1]$ with periodic boundary conditions and a uniform grid of $N$ points, where $N$ is even. The grid spacing is $h = \\frac{1}{N}$ and the grid points are $x_j = j h$ for $j = 0,1,\\dots,N-1$. Define the discrete Laplacian operator $L_h : \\mathbb{C}^N \\to \\mathbb{C}^N$ by\n$$\n(L_h u)_j = \\frac{u_{j+1} - 2 u_j + u_{j-1}}{h^2},\n$$\nwith periodic indexing, i.e., $u_{-1} \\equiv u_{N-1}$ and $u_{N} \\equiv u_{0}$.\n\nStarting from the definition of the discrete Laplacian and the discrete Fourier mode $u^{(\\theta)}_j = \\exp(i \\theta j)$, where $\\theta \\in [-\\pi,\\pi)$ is a dimensionless discrete wavenumber, derive the Fourier symbol $\\hat{L}(\\theta)$ of $L_h$ and explain how the image of the allowed discrete wavenumbers $\\{\\theta_k = \\frac{2\\pi k}{N} : k = 0,1,\\dots,N-1\\}$ under $\\hat{L}$ characterizes the spectrum of $L_h$ under periodic boundary conditions. Use this characterization to determine the spectral radius $\\rho(L_h)$ of $L_h$ as a function of the grid spacing $h$.\n\nExpress your final answer as a single closed-form analytic expression. No rounding is required, and no units should be included in the final expression.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n- **Domain:** The interval $[0,1]$ with periodic boundary conditions.\n- **Discretization:** A uniform grid of $N$ points, where $N$ is an even integer.\n- **Grid Spacing:** $h = \\frac{1}{N}$.\n- **Grid Points:** $x_j = j h$ for $j = 0,1,\\dots,N-1$.\n- **Operator:** The discrete Laplacian $L_h : \\mathbb{C}^N \\to \\mathbb{C}^N$ is defined by $(L_h u)_j = \\frac{u_{j+1} - 2 u_j + u_{j-1}}{h^2}$.\n- **Boundary Conditions:** Periodic indexing is used, $u_{-1} \\equiv u_{N-1}$ and $u_N \\equiv u_0$.\n- **Test Function:** The discrete Fourier mode is given as $u^{(\\theta)}_j = \\exp(i \\theta j)$, where $\\theta \\in [-\\pi,\\pi)$ is a dimensionless discrete wavenumber.\n- **Allowed Wavenumbers:** The set of allowed discrete wavenumbers is $\\{\\theta_k = \\frac{2\\pi k}{N} : k = 0,1,\\dots,N-1\\}$.\n- **Objective:** Derive the Fourier symbol $\\hat{L}(\\theta)$, explain its relation to the spectrum of $L_h$, and use this to find the spectral radius $\\rho(L_h)$ as a function of $h$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard exercise in the Fourier analysis of finite difference methods, a core topic in numerical analysis for partial differential equations. All concepts are well-established.\n- **Well-Posed:** The operator, domain, boundary conditions, and goal are all precisely defined. A unique, meaningful solution is expected.\n- **Objective:** The problem is stated using formal mathematical language, with no ambiguity or subjective elements.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, missing information, or logical contradiction. It is a valid, well-posed problem.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full solution will be provided.\n\n---\n\nThe solution proceeds by first determining the action of the discrete Laplacian operator $L_h$ on the discrete Fourier modes $u^{(\\theta)}_j$. These modes are the eigenvectors of any linear, shift-invariant operator on a periodic grid, such as $L_h$. The corresponding eigenvalues are given by the Fourier symbol of the operator.\n\nLet's apply $L_h$ to the mode $u^{(\\theta)}_j = \\exp(i \\theta j)$:\n$$\n(L_h u^{(\\theta)})_j = \\frac{u^{(\\theta)}_{j+1} - 2 u^{(\\theta)}_j + u^{(\\theta)}_{j-1}}{h^2}\n$$\nSubstituting the definition of $u^{(\\theta)}_j$:\n$$\n(L_h u^{(\\theta)})_j = \\frac{\\exp(i \\theta (j+1)) - 2 \\exp(i \\theta j) + \\exp(i \\theta (j-1))}{h^2}\n$$\nWe can factor out the term $\\exp(i \\theta j)$:\n$$\n(L_h u^{(\\theta)})_j = \\frac{\\exp(i \\theta j) (\\exp(i \\theta) - 2 + \\exp(-i \\theta))}{h^2}\n$$\nUsing the definition $u^{(\\theta)}_j = \\exp(i \\theta j)$, we can write this as an eigenvalue equation:\n$$\n(L_h u^{(\\theta)})_j = \\left( \\frac{\\exp(i \\theta) + \\exp(-i \\theta) - 2}{h^2} \\right) u^{(\\theta)}_j\n$$\nThis equation shows that $u^{(\\theta)}$ is an eigenvector of $L_h$. The corresponding eigenvalue, which depends on the wavenumber $\\theta$, is called the Fourier symbol of the operator $L_h$, denoted by $\\hat{L}(\\theta)$.\n$$\n\\hat{L}(\\theta) = \\frac{\\exp(i \\theta) + \\exp(-i \\theta) - 2}{h^2}\n$$\nUsing Euler's formula, $\\cos(\\theta) = \\frac{\\exp(i \\theta) + \\exp(-i \\theta)}{2}$, we can simplify the expression for $\\hat{L}(\\theta)$:\n$$\n\\hat{L}(\\theta) = \\frac{2\\cos(\\theta) - 2}{h^2} = -\\frac{2(1 - \\cos(\\theta))}{h^2}\n$$\nEmploying the half-angle trigonometric identity $1 - \\cos(\\theta) = 2\\sin^2(\\frac{\\theta}{2})$, the Fourier symbol becomes:\n$$\n\\hat{L}(\\theta) = -\\frac{4}{h^2}\\sin^2\\left(\\frac{\\theta}{2}\\right)\n$$\nThe problem specifies a finite, periodic grid with $N$ points. For the Fourier mode $u^{(\\theta)}_j$ to be a valid function on this grid, it must satisfy the periodicity condition $u_j = u_{j+N}$. Applying this to our mode:\n$$\nu^{(\\theta)}_j = u^{(\\theta)}_{j+N} \\implies \\exp(i \\theta j) = \\exp(i \\theta (j+N)) = \\exp(i \\theta j)\\exp(i \\theta N)\n$$\nThis requires that $\\exp(i \\theta N) = 1$, which is true if and only if $\\theta N = 2\\pi k$ for some integer $k$. This quantizes the allowed wavenumbers:\n$$\n\\theta_k = \\frac{2\\pi k}{N}, \\quad \\text{for } k \\in \\mathbb{Z}\n$$\nThe set of distinct modes on the grid is obtained by considering $N$ consecutive values of $k$, for instance, $k = 0, 1, \\dots, N-1$. These $N$ modes, $\\{u^{(\\theta_k)}\\}_{k=0}^{N-1}$, form a complete orthogonal basis for the vector space $\\mathbb{C}^N$.\n\nThe spectrum of the operator $L_h$, denoted $\\text{spec}(L_h)$, is the set of all its eigenvalues. In this case, the eigenvalues are obtained by evaluating the Fourier symbol $\\hat{L}(\\theta)$ at each of the allowed discrete wavenumbers $\\theta_k$. Thus, the image of the set of allowed wavenumbers under the map $\\hat{L}$ characterizes the spectrum of $L_h$. The eigenvalues are:\n$$\n\\lambda_k = \\hat{L}(\\theta_k) = -\\frac{4}{h^2}\\sin^2\\left(\\frac{\\theta_k}{2}\\right) = -\\frac{4}{h^2}\\sin^2\\left(\\frac{1}{2} \\cdot \\frac{2\\pi k}{N}\\right) = -\\frac{4}{h^2}\\sin^2\\left(\\frac{\\pi k}{N}\\right)\n$$\nfor $k = 0, 1, \\dots, N-1$.\n\nThe spectral radius $\\rho(L_h)$ is the maximum absolute value of the eigenvalues:\n$$\n\\rho(L_h) = \\max_{k \\in \\{0, 1, \\dots, N-1\\}} |\\lambda_k|\n$$\nSubstituting the expression for $\\lambda_k$:\n$$\n\\rho(L_h) = \\max_{k \\in \\{0, 1, \\dots, N-1\\}} \\left|-\\frac{4}{h^2}\\sin^2\\left(\\frac{\\pi k}{N}\\right)\\right|\n$$\nSince $h^2  0$ and $\\sin^2(x) \\ge 0$ for any real $x$, the absolute value simplifies to:\n$$\n\\rho(L_h) = \\frac{4}{h^2} \\max_{k \\in \\{0, 1, \\dots, N-1\\}} \\sin^2\\left(\\frac{\\pi k}{N}\\right)\n$$\nTo find the maximum value, we need to maximize the function $f(k) = \\sin^2\\left(\\frac{\\pi k}{N}\\right)$ over the specified range of integers $k$. The function $\\sin^2(x)$ achieves its maximum value of $1$ when its argument $x$ is an odd integer multiple of $\\frac{\\pi}{2}$, i.e., $x = (2m+1)\\frac{\\pi}{2}$ for $m \\in \\mathbb{Z}$.\n\nWe are looking for an integer $k \\in \\{0, 1, \\dots, N-1\\}$ such that $\\frac{\\pi k}{N}$ is as close as possible to such a value. Let's try to set $\\frac{\\pi k}{N} = \\frac{\\pi}{2}$. Solving for $k$ gives $k = \\frac{N}{2}$.\nThe problem states that $N$ is an even integer. Therefore, $k = \\frac{N}{2}$ is an integer. For any grid with $N \\ge 2$, we have $1 \\le \\frac{N}{2} \\le N-1$, so $k = \\frac{N}{2}$ is a valid index in the set $\\{0, 1, \\dots, N-1\\}$.\nFor this value of $k$, we have:\n$$\n\\max_{k \\in \\{0, 1, \\dots, N-1\\}} \\sin^2\\left(\\frac{\\pi k}{N}\\right) = \\sin^2\\left(\\frac{\\pi (N/2)}{N}\\right) = \\sin^2\\left(\\frac{\\pi}{2}\\right) = 1^2 = 1\n$$\nThis is the highest possible value for the $\\sin^2$ function.\n\nSubstituting this maximum value back into the expression for the spectral radius:\n$$\n\\rho(L_h) = \\frac{4}{h^2} \\cdot 1 = \\frac{4}{h^2}\n$$\nThe spectral radius of the discrete Laplacian on a periodic grid with $N$ points is $\\frac{4}{h^2}$.",
            "answer": "$$\\boxed{\\frac{4}{h^2}}$$"
        },
        {
            "introduction": "Building on spectral analysis, we now turn to a critical application: ensuring the stability of time-dependent simulations. The spectral radius of the spatial discretization matrix, $\\rho(A)$, directly constrains the maximum allowable time step $\\Delta t$ for explicit methods like forward Euler. This computational exercise  explores how different physical boundary conditions—Dirichlet, Neumann, and Robin—alter the discrete operator matrix $A$, its spectrum, and consequently, the practical stability limits on simulations.",
            "id": "3383464",
            "problem": "Consider the one-dimensional diffusion equation on the unit interval subject to homogeneous boundary conditions and its method-of-lines discretization on a uniform grid. Let $M \\in \\mathbb{N}$ denote the number of interior grid points, and let $h = \\frac{1}{M+1}$. Define the discrete operator $A \\in \\mathbb{R}^{M \\times M}$ by the standard second-order central difference stencil applied to interior points, together with one of the following boundary closures at the two ends $x=0$ and $x=1$:\n- Homogeneous Dirichlet: $u(0)=0$ and $u(1)=0$,\n- Homogeneous Neumann: $u_x(0)=0$ and $u_x(1)=0$,\n- Homogeneous Robin: $u_x(0) + \\gamma u(0) = 0$ and $u_x(1) + \\gamma u(1) = 0$ with $\\gamma \\ge 0$.\n\nAssume the semi-discrete system is written as $u'(t) = - A u(t)$ with $A$ symmetric and positive semidefinite (positive definite except for the homogeneous Neumann case where a single zero eigenvalue appears). The matrix $A$ must be constructed as follows:\n- For homogeneous Dirichlet boundary conditions, $A = \\frac{1}{h^2} \\operatorname{tridiag}(-1, 2, -1)$ (constant main diagonal equal to $2$ and first sub- and super-diagonals equal to $-1$).\n- For homogeneous Neumann boundary conditions, $A = \\frac{1}{h^2}$ with the same tridiagonal interior entries, except that the first and last diagonal entries are modified to $1$ to account for the discrete zero-flux boundary using first-order accurate ghost-point elimination.\n- For homogeneous Robin boundary conditions with parameter $\\gamma \\ge 0$ on both ends, use first-order accurate ghost-point elimination to obtain $u_0 = \\frac{u_1}{1 + \\gamma h}$ and $u_{M+1} = \\frac{u_M}{1 + \\gamma h}$. This modifies only the first and last diagonal entries of the interior second-difference operator, yielding $A = \\frac{1}{h^2}$ with main diagonal equal to $2$ everywhere except at the first and last positions where it is $2 - \\frac{1}{1 + \\gamma h}$, and first sub- and super-diagonals equal to $-1$.\n\nLet $\\lambda(A)$ denote the multiset of eigenvalues of $A$ and let $\\rho(A)$ denote the spectral radius of $A$. Apply the explicit forward Euler time integrator to the linear ordinary differential equation (ODE) $u'(t) = - A u(t)$. Using the linear stability requirement for forward Euler on a symmetric positive semidefinite system, determine for each case the largest admissible time step $\\Delta t_{\\max}$ expressed as a real number, in units of seconds, that ensures stability for all initial data. Your reasoning must start from the definition of the eigenvalue problem $A v = \\lambda v$, the amplification matrix of forward Euler, and the definition of the spectral radius. You must not use any pre-stated closed-form eigenvalue formulas; instead, your program must construct $A$ and compute the eigenvalues numerically.\n\nTest suite:\n- Case $1$: $M = 5$, Dirichlet boundary conditions.\n- Case $2$: $M = 5$, Neumann boundary conditions.\n- Case $3$: $M = 5$, Robin boundary conditions with $\\gamma = 0.1$.\n- Case $4$: $M = 5$, Robin boundary conditions with $\\gamma = 10.0$.\n- Case $5$: $M = 1$, Dirichlet boundary conditions.\n- Case $6$: $M = 2$, Neumann boundary conditions.\n- Case $7$: $M = 10$, Dirichlet boundary conditions.\n- Case $8$: $M = 10$, Neumann boundary conditions.\n\nFor each test case, your program must:\n- Construct the matrix $A$ according to the specified boundary condition and parameters,\n- Compute all eigenvalues in $\\lambda(A)$,\n- Identify the largest eigenvalue $\\lambda_{\\max}(A)$,\n- Compute the largest admissible explicit forward Euler time step $\\Delta t_{\\max}$ in seconds using the linear stability condition for the amplification matrix applied to all eigenmodes.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list of the eight $\\Delta t_{\\max}$ values, in seconds, enclosed in square brackets (for example, $[\\Delta t_1,\\Delta t_2,\\ldots,\\Delta t_8]$). No additional text should be printed. All angles, if any, must be in radians; there are no angles in this problem. Express all real numbers as decimals (not fractions).",
            "solution": "The problem requires the determination of the maximum stable time step, $\\Delta t_{\\max}$, for the forward Euler method applied to the semi-discretized one-dimensional diffusion equation, $u_t = u_{xx}$. The semi-discretization via the method of lines on a uniform grid with $M$ interior points results in a system of ordinary differential equations (ODEs), $u'(t) = -A u(t)$, where $u(t) \\in \\mathbb{R}^M$ is the vector of temperature values at the interior grid points and $A \\in \\mathbb{R}^{M \\times M}$ is a matrix representing the discretized negative Laplacian, $- \\frac{d^2}{dx^2}$. The properties of $A$ depend on the boundary conditions imposed at the ends of the unit interval, $x=0$ and $x=1$.\n\nThe forward Euler method advances the solution in time from $t_n$ to $t_{n+1} = t_n + \\Delta t$ according to the explicit update rule:\n$$u^{n+1} = u^n + \\Delta t (-A u^n)$$\nThis can be rewritten as:\n$$u^{n+1} = (I - \\Delta t A) u^n$$\nwhere $I$ is the $M \\times M$ identity matrix. The matrix $G = I - \\Delta t A$ is known as the amplification matrix, as it determines how solution components evolve over a single time step.\n\nFor a numerical method to be stable, errors or perturbations must not grow unboundedly in time. For linear systems, this is ensured if the spectral radius of the amplification matrix, $\\rho(G)$, is no greater than $1$. The spectral radius is the maximum magnitude of the eigenvalues of $G$.\n$$\\rho(G) \\le 1$$\n\nThe eigenvalues of $G$ are directly related to the eigenvalues of $A$. Let $\\lambda$ be an eigenvalue of $A$ with corresponding eigenvector $v$, such that $Av = \\lambda v$. Then, applying $G$ to $v$ yields:\n$$Gv = (I - \\Delta t A) v = Iv - \\Delta t (Av) = v - \\Delta t (\\lambda v) = (1 - \\Delta t \\lambda) v$$\nThus, if $\\lambda$ is an eigenvalue of $A$, then $\\mu = 1 - \\Delta t \\lambda$ is an eigenvalue of $G$. The stability condition $\\rho(G) \\le 1$ translates to $|\\mu_j| \\le 1$ for all eigenvalues $\\mu_j$ of $G$, which implies:\n$$|1 - \\Delta t \\lambda_j| \\le 1$$\nfor all eigenvalues $\\lambda_j$ of $A$.\n\nThe problem states that the matrix $A$ is symmetric and positive semidefinite. This guarantees that its eigenvalues $\\lambda_j$ are real and non-negative, i.e., $\\lambda_j \\in \\mathbb{R}$ and $\\lambda_j \\ge 0$ for all $j=1, \\dots, M$. The stability inequality can be expanded as:\n$$-1 \\le 1 - \\Delta t \\lambda_j \\le 1$$\nThe right-hand side, $1 - \\Delta t \\lambda_j \\le 1$, simplifies to $-\\Delta t \\lambda_j \\le 0$. Since $\\Delta t  0$ and $\\lambda_j \\ge 0$, this condition is always satisfied.\nThe left-hand side, $-1 \\le 1 - \\Delta t \\lambda_j$, simplifies to $\\Delta t \\lambda_j \\le 2$.\n\nThis inequality must hold for all eigenvalues $\\lambda_j$. The most restrictive constraint arises from the largest eigenvalue of $A$, denoted $\\lambda_{\\max}(A)$. The spectral radius of a symmetric positive semidefinite matrix is its largest eigenvalue, so $\\rho(A) = \\lambda_{\\max}(A)$. The stability condition thus becomes:\n$$\\Delta t \\cdot \\lambda_{\\max}(A) \\le 2$$\n$$\\Delta t \\le \\frac{2}{\\lambda_{\\max}(A)}$$\nThe largest admissible time step that guarantees stability is therefore:\n$$\\Delta t_{\\max} = \\frac{2}{\\lambda_{\\max}(A)} = \\frac{2}{\\rho(A)}$$\nIf $\\lambda_{\\max}(A) = 0$, which occurs only if $A$ is the zero matrix, the method is unconditionally stable. However, for the given problem configurations, $A$ is never the zero matrix, so $\\lambda_{\\max}(A)  0$.\n\nThe computational procedure for each test case is as follows:\n$1$. Determine the grid spacing $h = \\frac{1}{M+1}$.\n$2$. Construct the $M \\times M$ matrix $A$ corresponding to the specified boundary conditions.\n$3$. Numerically compute the eigenvalues of the symmetric matrix $A$.\n$4$. Identify the maximum eigenvalue, $\\lambda_{\\max}(A)$.\n$5$. Calculate the maximum stable time step $\\Delta t_{\\max} = \\frac{2}{\\lambda_{\\max}(A)}$.\n\nThe construction of the matrix $A$ for each boundary condition type is explicitly given:\n\n- **Homogeneous Dirichlet**: $A = \\frac{1}{h^2} \\operatorname{tridiag}(-1, 2, -1)$. This is an $M \\times M$ matrix with $2$ on the main diagonal and $-1$ on the first sub-diagonal and super-diagonal, all scaled by $\\frac{1}{h^2}$.\n- **Homogeneous Neumann**: $A = \\frac{1}{h^2} \\operatorname{tridiag}(-1_s, d, -1_s)$, where $1_s$ denotes the sub/super-diagonals, and the main diagonal vector is $d = [1, 2, 2, \\dots, 2, 1]^T$. This is constructed by starting with the standard $\\operatorname{tridiag}(-1, 2, -1)$ matrix and modifying the first and last diagonal entries from $2$ to $1$.\n- **Homogeneous Robin**: $A = \\frac{1}{h^2} \\operatorname{tridiag}(-1_s, d, -1_s)$, where the main diagonal vector is $d = [d_1, 2, 2, \\dots, 2, d_1]^T$ with the specific value $d_1 = 2 - \\frac{1}{1 + \\gamma h}$. This is constructed by starting with the standard $\\operatorname{tridiag}(-1, 2, -1)$ matrix and modifying the first and last diagonal entries.\n\nFor each test case, the program will implement these steps to compute $\\Delta t_{\\max}$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the maximum stable time step for the forward Euler method\n    applied to the 1D diffusion equation under various boundary conditions.\n    \"\"\"\n    # Test cases: (M, boundary_condition_type, gamma)\n    # gamma is None for Dirichlet and Neumann cases.\n    test_cases = [\n        (5, 'dirichlet', None),\n        (5, 'neumann', None),\n        (5, 'robin', 0.1),\n        (5, 'robin', 10.0),\n        (1, 'dirichlet', None),\n        (2, 'neumann', None),\n        (10, 'dirichlet', None),\n        (10, 'neumann', None),\n    ]\n\n    results = []\n    \n    for M, bc_type, gamma in test_cases:\n        # 1. Calculate grid spacing h\n        h = 1.0 / (M + 1)\n        \n        # 2. Construct the matrix A\n        A = np.zeros((M, M))\n        \n        if bc_type == 'dirichlet':\n            # Main diagonal\n            np.fill_diagonal(A, 2.0)\n            # Sub-diagonal and Super-diagonal\n            if M > 1:\n                np.fill_diagonal(A[1:], -1.0)\n                np.fill_diagonal(A[:, 1:], -1.0)\n        \n        elif bc_type == 'neumann':\n            # Main diagonal\n            np.fill_diagonal(A, 2.0)\n            A[0, 0] = 1.0\n            if M > 1:\n                A[M - 1, M - 1] = 1.0\n            # Sub-diagonal and Super-diagonal\n            if M > 1:\n                np.fill_diagonal(A[1:], -1.0)\n                np.fill_diagonal(A[:, 1:], -1.0)\n\n        elif bc_type == 'robin':\n            # Main diagonal\n            np.fill_diagonal(A, 2.0)\n            diag_val_boundary = 2.0 - 1.0 / (1.0 + gamma * h)\n            A[0, 0] = diag_val_boundary\n            if M > 1:\n                A[M - 1, M - 1] = diag_val_boundary\n            # Sub-diagonal and Super-diagonal\n            if M > 1:\n                np.fill_diagonal(A[1:], -1.0)\n                np.fill_diagonal(A[:, 1:], -1.0)\n        \n        # Scale A by 1/h^2\n        A /= (h**2)\n        \n        # 3. Compute eigenvalues\n        # Since A is symmetric, eigvalsh is efficient and appropriate.\n        eigenvalues = np.linalg.eigvalsh(A)\n        \n        # 4. Find the spectral radius (maximum eigenvalue)\n        rho_A = np.max(eigenvalues)\n        \n        # 5. Calculate the maximum stable time step\n        # dt_max = 2 / rho(A)\n        # Avoid division by zero, although not expected for these test cases\n        if rho_A > 1e-12:\n            dt_max = 2.0 / rho_A\n        else:\n            # Unconditionally stable, dt_max is theoretically infinite.\n            # This case should not be reached with the given problems.\n            dt_max = np.inf\n            \n        results.append(dt_max)\n\n    # Final print statement in the exact required format.\n    # The format string ensures decimal representation for all numbers.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "In many practical scenarios, such as with nonuniform grids or complex operators, finding the exact spectrum is infeasible. This final practice introduces powerful techniques for estimating the location of eigenvalues using Gershgorin circle theorems. By implementing and comparing scalar and block Gershgorin bounds against the numerically computed spectrum for an advection-diffusion problem , you will gain experience with essential tools for analyzing the stability and convergence of numerical methods in more realistic settings.",
            "id": "3383510",
            "problem": "Consider the nondimensional one-dimensional linear advection–diffusion initial value problem for a scalar field $u(x,t)$ defined for $x \\in [0,1]$ and $t \\ge 0$,\n$$\nu_t(x,t) = -a\\,u_x(x,t) + \\nu\\,u_{xx}(x,t),\n$$\nwith homogeneous Dirichlet boundary conditions $u(0,t)=0$ and $u(1,t)=0$, where $a \\in \\mathbb{R}$ is the advection speed and $\\nu  0$ is the diffusion coefficient. Discretize the spatial domain on a nonuniform grid defined by interior points $\\{x_i\\}_{i=1}^N$ with $x_0=0$, $x_{N+1}=1$, and spacings $h_{i-1} = x_i - x_{i-1}$, $h_i = x_{i+1} - x_i$. Form a semi-discrete system $u_t = A u$ on the $N$ interior unknowns by using:\n- For the diffusion term, a second-order consistent three-point stencil on nonuniform grids derived from Taylor expansion,\n$$\nu_{xx}(x_i) \\approx \\alpha_{i-1} u_{i-1} + \\alpha_i u_i + \\alpha_{i+1} u_{i+1},\n$$\nwhere the coefficients are determined entirely by $\\{h_{i-1},h_i\\}$ and must be derived from first principles.\n- For the advection term, a first-order upwind difference that depends on the sign of $a$,\n$$\nu_x(x_i) \\approx\n\\begin{cases}\n\\dfrac{u_i - u_{i-1}}{h_{i-1}},  a \\ge 0,\\\\[1em]\n\\dfrac{u_{i+1} - u_i}{h_i},  a  0,\n\\end{cases}\n$$\nwith appropriate boundary handling given $u_0=0$ and $u_{N+1}=0$.\n\nLet $A \\in \\mathbb{R}^{N \\times N}$ be the matrix corresponding to the spatial operator $-a\\,u_x + \\nu\\,u_{xx}$ acting on interior unknowns. You will analyze the eigenvalue distribution of $A$ via Gershgorin discs and a block Gershgorin strategy, and quantify how conservative these bounds are compared to the true spectral radius. All quantities are nondimensional, and no physical units are to be used anywhere in the output.\n\nStarting from the definitions of eigenvalues, eigenvectors, and spectral radius, as well as basic Taylor expansions and consistent discretizations on nonuniform grids, derive the Gershgorin circle theorem appropriate for $A$ and show how it gives a computable upper bound on the spectral radius $\\rho(A)$. Then, derive a block Gershgorin enclosure for eigenvalues by partitioning $A$ into contiguous square blocks $A_{ij}$. Use an induced matrix norm (choose one and justify it) to define block radii, and explain why the union of block discs yields a computable upper bound on $\\rho(A)$ that can be tighter than the scalar Gershgorin bound.\n\nImplement a complete program that:\n1. Constructs the nonuniform grids as follows for given $N$ and parameter $\\beta \\ge 0$:\n   - For the uniform grid, set $x_i = i/(N+1)$ for $i=0,1,\\dots,N+1$.\n   - For the exponentially graded grid clustering near $x=0$, set $s_i = i/(N+1)$ and\n     $$\n     x_i = \\frac{e^{\\beta s_i} - 1}{e^{\\beta} - 1}, \\quad i=0,1,\\dots,N+1,\n     $$\n     with the convention that for $\\beta=0$ this reduces to the uniform grid.\n2. Builds the matrix $A$ using the nonuniform three-point second derivative stencil (derived from Taylor expansions) and first-order upwind discretization of $u_x$ depending on the sign of $a$, under homogeneous Dirichlet boundary conditions.\n3. Computes:\n   - The true spectral radius $\\rho(A)$.\n   - A scalar Gershgorin-based upper bound on $\\rho(A)$ using row discs.\n   - A block Gershgorin-based upper bound on $\\rho(A)$, where blocks are contiguous of a specified size $b$, using the $2$-norm to measure off-diagonal block magnitudes and the centers taken from the spectra of diagonal blocks $A_{ii}$.\n4. Reports, for each test case, the pair of gaps to the true spectral radius:\n   $$\n   \\Delta_{\\mathrm{G}} = B_{\\mathrm{G}} - \\rho(A), \\quad \\Delta_{\\mathrm{BG}} = B_{\\mathrm{BG}} - \\rho(A),\n   $$\n   where $B_{\\mathrm{G}}$ and $B_{\\mathrm{BG}}$ are the scalar and block Gershgorin upper bounds on $\\rho(A)$, respectively.\n\nUse the following test suite to exercise different regimes and edge cases:\n- Case 1 (advective-dominated, uniform grid): $N=20$, $a=1.0$, $\\nu=0.01$, uniform grid, block size $b=4$.\n- Case 2 (pure diffusion, uniform grid): $N=20$, $a=0.0$, $\\nu=0.5$, uniform grid, block size $b=5$.\n- Case 3 (mixed regime, moderate grading): $N=30$, $a=2.0$, $\\nu=0.02$, exponentially graded grid with $\\beta=3.0$, block size $b=3$.\n- Case 4 (advective-dominated with negative advection, strong grading): $N=40$, $a=-1.0$, $\\nu=0.005$, exponentially graded grid with $\\beta=8.0$, block size $b=4$.\n\nYour program must produce a single line of output containing the results aggregated in the following exact format: a single list whose $k$-th element corresponds to test case $k$, and each element is itself a list containing five floating-point numbers in this order:\n$$\n[\\rho(A),\\, B_{\\mathrm{G}},\\, B_{\\mathrm{BG}},\\, \\Delta_{\\mathrm{G}},\\, \\Delta_{\\mathrm{BG}}].\n$$\nFor example, the output should look like\n$$\n[[\\rho_1, B_{\\mathrm{G},1}, B_{\\mathrm{BG},1}, \\Delta_{\\mathrm{G},1}, \\Delta_{\\mathrm{BG},1}], [\\rho_2, B_{\\mathrm{G},2}, B_{\\mathrm{BG},2}, \\Delta_{\\mathrm{G},2}, \\Delta_{\\mathrm{BG},2}], \\dots]\n$$\nwith no spaces anywhere in the line. All computations are nondimensional; do not include any physical units or angle units in the output. Express all numeric values as decimal floating-point numbers.",
            "solution": "The problem posed is to analyze the eigenvalues of a matrix $A$ arising from the semi-discretization of the one-dimensional linear advection-diffusion equation. This involves deriving the discretization matrix, applying scalar and block Gershgorin circle theorems to bound its spectrum, and implementing a numerical comparison of these bounds. The problem is well-posed, scientifically grounded, and provides all necessary information for a unique solution.\n\n### Part 1: Derivation of the Semi-Discretization Matrix $A$\n\nThe governing partial differential equation (PDE) is the advection-diffusion equation for a scalar field $u(x,t)$:\n$$\n\\frac{\\partial u}{\\partial t} = -a \\frac{\\partial u}{\\partial x} + \\nu \\frac{\\partial^2 u}{\\partial x^2}, \\quad x \\in [0, 1], t \\ge 0.\n$$\nThe parameters are the advection speed $a \\in \\mathbb{R}$ and the diffusion coefficient $\\nu  0$. The boundary conditions are of the homogeneous Dirichlet type, $u(0,t) = 0$ and $u(1,t) = 0$.\n\nWe discretize the spatial domain $[0, 1]$ using $N$ interior grid points $x_1, x_2, \\ldots, x_N$, with $x_0 = 0$ and $x_{N+1} = 1$. The grid spacing is nonuniform, defined by $h_{i-1} = x_i - x_{i-1}$ for $i=1, \\ldots, N+1$. We seek an approximate solution $u_i(t) \\approx u(x_i, t)$ at these interior points. The semi-discrete system is an ordinary differential equation (ODE) system of the form $\\frac{d\\mathbf{u}}{dt} = A\\mathbf{u}$, where $\\mathbf{u}(t) = [u_1(t), \\dots, u_N(t)]^T$.\n\n**1. Discretization of the Diffusion Term ($u_{xx}$)**\n\nTo find a three-point stencil for the second derivative $u_{xx}$ at $x_i$ on a nonuniform grid, we use Taylor series expansions for $u(x_{i-1})$ and $u(x_{i+1})$ around $x_i$:\n$$\nu_{i-1} = u(x_i - h_{i-1}) = u_i - h_{i-1} u_x(x_i) + \\frac{h_{i-1}^2}{2} u_{xx}(x_i) - \\frac{h_{i-1}^3}{6} u_{xxx}(x_i) + \\mathcal{O}(h_{i-1}^4)\n$$\n$$\nu_{i+1} = u(x_i + h_i) = u_i + h_i u_x(x_i) + \\frac{h_i^2}{2} u_{xx}(x_i) + \\frac{h_i^3}{6} u_{xxx}(x_i) + \\mathcal{O}(h_i^4)\n$$\nWe form a linear combination $\\alpha_{i-1}u_{i-1} + \\alpha_i u_i + \\alpha_{i+1}u_{i+1}$ to approximate $u_{xx}(x_i)$. By solving a system of equations to make the combination exact for polynomials up to degree $2$, or by algebraic manipulation of the Taylor series, we can eliminate the $u_i$ and $u_x(x_i)$ terms. Multiplying the first equation by $h_i$ and the second by $h_{i-1}$ and adding them yields:\n$$\nh_i u_{i-1} + h_{i-1} u_{i+1} = (h_i + h_{i-1})u_i + \\frac{h_i h_{i-1}^2 + h_{i-1}h_i^2}{2} u_{xx}(x_i) + \\mathcal{O}(h^4)\n$$\nwhere $h = \\max(h_{i-1}, h_i)$. Rearranging for $u_{xx}(x_i)$ gives the stencil:\n$$\nu_{xx}(x_i) \\approx \\frac{2}{h_i h_{i-1}(h_i+h_{i-1})} [h_i u_{i-1} - (h_i+h_{i-1})u_i + h_{i-1}u_{i+1}]\n$$\nThis provides the coefficients for the approximation $u_{xx}(x_i) \\approx \\alpha_{i-1}u_{i-1} + \\alpha_i u_i + \\alpha_{i+1}u_{i+1}$:\n$$\n\\alpha_{i-1} = \\frac{2}{h_{i-1}(h_{i-1}+h_i)}, \\quad \\alpha_i = -\\frac{2}{h_{i-1}h_i}, \\quad \\alpha_{i+1} = \\frac{2}{h_i(h_{i-1}+h_i)}.\n$$\nThe local truncation error is $\\frac{1}{3}(h_i - h_{i-1})u_{xxx}(x_i) + \\mathcal{O}(h^2)$, making the scheme first-order accurate on a general nonuniform grid but second-order accurate on a uniform grid where $h_i = h_{i-1}$. The problem refers to this as \"second-order consistent,\" acknowledging its common use and properties.\n\n**2. Discretization of the Advection Term ($u_x$)**\n\nThe advection term is discretized using a first-order upwind scheme, which is chosen for stability, especially in advection-dominated problems. The direction of the differencing depends on the sign of the advection speed $a$.\n- If $a \\ge 0$ (flow to the right), a backward difference is used: $u_x(x_i) \\approx \\frac{u_i - u_{i-1}}{h_{i-1}}$.\n- If $a  0$ (flow to the left), a forward difference is used: $u_x(x_i) \\approx \\frac{u_{i+1} - u_i}{h_i}$.\n\n**3. Assembling the Matrix $A$**\n\nThe entry $A_{ij}$ of the matrix $A$ is the coefficient of $u_j$ in the discretized equation for $\\frac{du_i}{dt}$. Given the three-point stencils, $A$ is a tridiagonal matrix. For a generic interior row $i$ (corresponding to point $x_i$, $1  i  N$), the matrix elements are:\n\nCase $a \\ge 0$:\n$$\n\\frac{du_i}{dt} = -a\\left(\\frac{u_i - u_{i-1}}{h_{i-1}}\\right) + \\nu\\left(\\alpha_{i-1}u_{i-1} + \\alpha_i u_i + \\alpha_{i+1}u_{i+1}\\right)\n$$\nThe coefficients are:\n- Sub-diagonal ($A_{i,i-1}$): $\\frac{a}{h_{i-1}} + \\nu\\alpha_{i-1} = \\frac{a}{h_{i-1}} + \\frac{2\\nu}{h_{i-1}(h_{i-1}+h_i)}$\n- Diagonal ($A_{i,i}$): $-\\frac{a}{h_{i-1}} + \\nu\\alpha_i = -\\frac{a}{h_{i-1}} - \\frac{2\\nu}{h_{i-1}h_i}$\n- Super-diagonal ($A_{i,i+1}$): $\\nu\\alpha_{i+1} = \\frac{2\\nu}{h_i(h_{i-1}+h_i)}$\n\nCase $a  0$:\n$$\n\\frac{du_i}{dt} = -a\\left(\\frac{u_{i+1} - u_i}{h_i}\\right) + \\nu\\left(\\alpha_{i-1}u_{i-1} + \\alpha_i u_i + \\alpha_{i+1}u_{i+1}\\right)\n$$\nThe coefficients are:\n- Sub-diagonal ($A_{i,i-1}$): $\\nu\\alpha_{i-1} = \\frac{2\\nu}{h_{i-1}(h_{i-1}+h_i)}$\n- Diagonal ($A_{i,i}$): $\\frac{a}{h_i} + \\nu\\alpha_i = \\frac{a}{h_i} - \\frac{2\\nu}{h_{i-1}h_i}$\n- Super-diagonal ($A_{i,i+1}$): $-\\frac{a}{h_i} + \\nu\\alpha_{i+1} = -\\frac{a}{h_i} + \\frac{2\\nu}{h_i(h_{i-1}+h_i)}$\n\nAt the boundaries ($i=1$ and $i=N$), we incorporate the conditions $u_0=0$ and $u_{N+1}=0$. For example, for $i=1$ and $a \\ge 0$, the term $u_0$ in the stencils is set to $0$, so the sub-diagonal element $A_{1,0}$ does not exist, and its contribution is removed from the expression for $A_{1,1}$. The construction is symmetric for $i=N$.\n\n### Part 2: Eigenvalue Bounds\n\nAn eigenvalue $\\lambda$ and corresponding eigenvector $\\mathbf{v} \\neq \\mathbf{0}$ of a matrix $A \\in \\mathbb{C}^{N \\times N}$ satisfy the equation $A\\mathbf{v} = \\lambda\\mathbf{v}$. The set of all eigenvalues is the spectrum, $\\sigma(A)$. The spectral radius is $\\rho(A) = \\max\\{|\\lambda| : \\lambda \\in \\sigma(A)\\}$. It governs the long-term behavior of the system $\\frac{d\\mathbf{u}}{dt} = A\\mathbf{u}$.\n\n**1. Scalar Gershgorin Circle Theorem**\n\nThis theorem provides a region in the complex plane that contains all eigenvalues of a matrix.\n**Theorem:** Let $A = (A_{ij})$ be a complex $N \\times N$ matrix. For $i = 1, \\dots, N$, let $R_i = \\sum_{j \\neq i} |A_{ij}|$ be the sum of the absolute values of the non-diagonal entries in row $i$. Let $G_i = \\{z \\in \\mathbb{C} : |z - A_{ii}| \\le R_i\\}$ be the Gershgorin disc in the complex plane centered at $A_{ii}$ with radius $R_i$. Then all eigenvalues of $A$ are located in the union of these discs, $\\sigma(A) \\subseteq \\bigcup_{i=1}^N G_i$.\n\n**Proof:** Let $\\lambda$ be an eigenvalue of $A$ with eigenvector $\\mathbf{v} = [v_1, \\dots, v_N]^T$. Let $k$ be an index such that $|v_k| = \\max_j |v_j|$. Since $\\mathbf{v} \\neq \\mathbf{0}$, we have $|v_k|  0$. The $k$-th row of the equation $A\\mathbf{v} = \\lambda\\mathbf{v}$ is $\\sum_{j=1}^N A_{kj}v_j = \\lambda v_k$. Rearranging gives $(\\lambda - A_{kk})v_k = \\sum_{j \\neq k} A_{kj}v_j$. Taking the absolute value of both sides and using the triangle inequality:\n$$\n|\\lambda - A_{kk}| |v_k| = \\left|\\sum_{j \\neq k} A_{kj}v_j\\right| \\le \\sum_{j \\neq k} |A_{kj}||v_j|\n$$\nSince $|v_j| \\le |v_k|$ for all $j$, we have:\n$$\n|\\lambda - A_{kk}| |v_k| \\le \\sum_{j \\neq k} |A_{kj}| |v_k| = |v_k| \\sum_{j \\neq k} |A_{kj}| = |v_k| R_k\n$$\nDividing by $|v_k|  0$ gives $|\\lambda - A_{kk}| \\le R_k$. This shows that $\\lambda$ lies in the disc $G_k$. Since this holds for any eigenvalue $\\lambda$, all eigenvalues must lie in the union of all such discs.\n\n**Application:** For our tridiagonal matrix $A$, the row sums are simple. For row $i$, $R_i = |A_{i,i-1}| + |A_{i,i+1}|$ (with boundary cases $R_1=|A_{1,2}|$ and $R_N=|A_{N,N-1}|$). An upper bound on the spectral radius, $B_G$, is given by the point in the union of the discs furthest from the origin:\n$$\n\\rho(A) \\le \\max_{i} (|A_{ii}| + R_i) = B_G\n$$\nThis bound is readily computable once $A$ is constructed.\n\n**2. Block Gershgorin Theorem**\n\nThis theorem is a generalization where the matrix is partitioned into blocks. Let $A$ be partitioned into $m \\times m$ blocks $A_{ij}$, where each diagonal block $A_{ii}$ is square.\n**Theorem:** Let $A$ be partitioned as above. The spectrum of $A$ is contained in the union of the following sets:\n$$\n\\sigma(A) \\subseteq \\bigcup_{i=1}^m \\left\\{ z \\in \\mathbb{C} \\,:\\, \\text{dist}(z, \\sigma(A_{ii})) \\le \\sum_{j \\neq i} \\|A_{ij}\\| \\right\\}\n$$\nwhere $\\| \\cdot \\|$ is any induced matrix norm and $\\text{dist}(z, S) = \\min_{s \\in S} |z-s|$.\n\n**Derivation:** Let $(\\lambda, \\mathbf{v})$ be an eigenpair of $A$. Partition $\\mathbf{v} = [\\mathbf{v}_1^T, \\dots, \\mathbf{v}_m^T]^T$ conformally with $A$. The eigenvalue equation $\\sum_{j=1}^m A_{ij}\\mathbf{v}_j = \\lambda \\mathbf{v}_i$ for each block row $i$ becomes $(\\lambda I - A_{ii})\\mathbf{v}_i = \\sum_{j \\neq i} A_{ij}\\mathbf{v}_j$.\nIf $\\lambda \\notin \\sigma(A_{ii})$, then $\\lambda I - A_{ii}$ is invertible. Thus, $\\mathbf{v}_i = (\\lambda I - A_{ii})^{-1} \\sum_{j \\neq i} A_{ij}\\mathbf{v}_j$.\nTaking norms: $\\|\\mathbf{v}_i\\| \\le \\|(\\lambda I - A_{ii})^{-1}\\| \\sum_{j \\neq i} \\|A_{ij}\\| \\|\\mathbf{v}_j\\|$.\nLet $k$ be an index such that $\\|\\mathbf{v}_k\\|$ is maximal. For this $k$, dividing by $\\|\\mathbf{v}_k\\|  0$ gives $1 \\le \\|(\\lambda I - A_{kk})^{-1}\\| \\sum_{j \\neq k} \\|A_{kj}\\|$.\nA standard result in matrix analysis states that $\\|(B-zI)^{-1}\\|^{-1} \\ge \\text{dist}(z, \\sigma(B))$ for an induced norm. Applying this, we get $1 \\le \\frac{1}{\\text{dist}(\\lambda, \\sigma(A_{kk}))} \\sum_{j \\neq k} \\|A_{kj}\\|$, which rearranges to $\\text{dist}(\\lambda, \\sigma(A_{kk})) \\le \\sum_{j \\neq k} \\|A_{kj}\\|$. This must hold for some $k$, or $\\lambda$ must be in one of the $\\sigma(A_{ii})$. This establishes the theorem.\n\nThe problem specifies using the matrix $2$-norm, which is the norm induced by the Euclidean vector norm. This is a valid choice satisfying the theorem's requirements.\n\n**Application:** From the theorem, if $z \\in \\sigma(A)$, then there is a block index $k$ and a $\\mu \\in \\sigma(A_{kk})$ such that $|z - \\mu| \\le \\sum_{j \\neq k} \\|A_{kj}\\|_2$.\nBy the triangle inequality, $|z| = |z - \\mu + \\mu| \\le |z - \\mu| + |\\mu| \\le \\left(\\sum_{j \\neq k} \\|A_{kj}\\|_2\\right) + |\\mu|$.\nTo find an upper bound on $|z|$, we maximize over all possible $\\mu$ in $\\sigma(A_{kk})$:\n$$\n|z| \\le \\left(\\sum_{j \\neq k} \\|A_{kj}\\|_2\\right) + \\max_{\\mu \\in \\sigma(A_{kk})}|\\mu| = \\left(\\sum_{j \\neq k} \\|A_{kj}\\|_2\\right) + \\rho(A_{kk})\n$$\nAn upper bound on $\\rho(A)$ is found by taking the maximum over all block rows $k$:\n$$\n\\rho(A) \\le \\max_k \\left\\{ \\rho(A_{kk}) + \\sum_{j \\neq k} \\|A_{kj}\\|_2 \\right\\} = B_{BG}\n$$\nFor our tridiagonal matrix $A$ partitioned into blocks of size $b$, the only non-zero off-diagonal blocks are $A_{k, k-1}$ and $A_{k, k+1}$. Each of these contains only a single non-zero entry. The $2$-norm of a matrix with only one non-zero entry $c$ is simply $|c|$. This simplifies the calculation of the block radii $\\sum_{j \\neq k} \\|A_{kj}\\|_2$.\n\nBlock Gershgorin bounds can be tighter than scalar bounds because they account for the internal structure of the diagonal blocks $A_{ii}$. The eigenvalues of $A_{ii}$ provide more refined \"centers\" for the inclusion regions than single diagonal entries $A_{ii}$. This essentially means that large off-diagonal entries may have their effects \"cancelled out\" within a block's structure, whereas in the scalar case every off-diagonal element strictly increases the radius.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef build_matrix(N, a, nu, beta):\n    \"\"\"\n    Constructs the semi-discretization matrix A for the 1D advection-diffusion equation.\n    \n    Args:\n        N (int): Number of interior grid points.\n        a (float): Advection speed.\n        nu (float): Diffusion coefficient.\n        beta (float): Grid grading parameter. beta=0 gives a uniform grid.\n        \n    Returns:\n        numpy.ndarray: The N x N matrix A.\n    \"\"\"\n    # 1. Grid generation\n    x = np.zeros(N + 2)\n    s = np.linspace(0, 1, N + 2)\n    if beta == 0:\n        x = s\n    else:\n        # Using a small epsilon to avoid division by zero if beta is extremely small but not zero\n        if np.abs(np.exp(beta) - 1)  1e-12:\n            x = s\n        else:\n            x = (np.exp(beta * s) - 1) / (np.exp(beta) - 1)\n    \n    h = np.diff(x)\n    \n    A = np.zeros((N, N))\n    \n    # 2. Matrix population, row by row (0-indexed)\n    for i in range(N):  # Corresponds to row i, which is for unknown u_{i+1} at grid point x_{i+1}\n        # Spacings around x_{i+1}: h_i = x_{i+1}-x_i and h_{i+1} = x_{i+2}-x_{i+1}\n        h_left = h[i]\n        h_right = h[i+1]\n        \n        # Diffusion coefficients (multiplied by nu)\n        alpha_left_nu = (2 * nu) / (h_left * (h_left + h_right))  # for u_i\n        alpha_mid_nu = (-2 * nu) / (h_left * h_right)            # for u_{i+1}\n        alpha_right_nu = (2 * nu) / (h_right * (h_left + h_right)) # for u_{i+2}\n        \n        # Advection contributions, determined by upwinding\n        if a = 0:\n            # Diagonal and sub-diagonal entries\n            A[i, i] += -a / h_left + alpha_mid_nu\n            if i  N - 1:\n                A[i, i + 1] += alpha_right_nu\n            if i  0:\n                A[i, i - 1] += a / h_left + alpha_left_nu\n            # Boundary case i=0 (for u_1), upwind uses u_0=0\n            if i == 0:\n                A[i, i] = -a / h_left + alpha_mid_nu\n        else:  # a  0\n            # Diagonal and super-diagonal entries\n            A[i, i] += a / h_right + alpha_mid_nu\n            if i  N - 1:\n                A[i, i + 1] += -a / h_right + alpha_right_nu\n            if i  0:\n                A[i, i - 1] += alpha_left_nu\n            # Boundary case i=N-1 (for u_N), upwind uses u_{N+1}=0\n            if i == N - 1:\n                A[i, i] = a / h_right + alpha_mid_nu\n\n    return A\n\ndef compute_bounds(A, b):\n    \"\"\"\n    Computes spectral radius and its scalar/block Gershgorin bounds.\n    \n    Args:\n        A (numpy.ndarray): The matrix.\n        b (int): Block size for block Gershgorin.\n        \n    Returns:\n        tuple: (rho_A, B_G, B_BG) containing the true spectral radius,\n               the scalar Gershgorin bound, and the block Gershgorin bound.\n    \"\"\"\n    N = A.shape[0]\n    \n    # 1. True spectral radius\n    eigenvalues = np.linalg.eigvals(A)\n    rho_A = np.max(np.abs(eigenvalues))\n    \n    # 2. Scalar Gershgorin bound (row-based)\n    diag_abs = np.abs(np.diag(A))\n    off_diag_abs_row_sum = np.sum(np.abs(A), axis=1) - diag_abs\n    B_G = np.max(diag_abs + off_diag_abs_row_sum)\n    \n    # 3. Block Gershgorin bound\n    m = N // b\n    if N % b != 0:\n        raise ValueError(\"N must be a multiple of b for this implementation.\")\n    \n    block_bounds = []\n    \n    for k in range(m):  # 0-indexed block row\n        # Diagonal block A_kk\n        A_kk = A[k*b : (k+1)*b, k*b : (k+1)*b]\n        rho_A_kk = np.max(np.abs(np.linalg.eigvals(A_kk)))\n        \n        # Sum of norms of off-diagonal blocks |A_{k, k-1}| + |A_{k, k+1}|\n        # Since A is tridiagonal, these blocks have at most one non-zero entry.\n        # The 2-norm of such a matrix is the absolute value of that entry.\n        R_k_B = 0.0\n        \n        # Contribution from A_{k, k-1}\n        if k  0:\n            # The only non-zero entry is A[k*b, k*b - 1]\n            R_k_B += np.abs(A[k*b, k*b - 1])\n        \n        # Contribution from A_{k, k+1}\n        if k  m - 1:\n            # The only non-zero entry is A[(k+1)*b - 1, (k+1)*b]\n            R_k_B += np.abs(A[(k+1)*b - 1, (k+1)*b])\n            \n        block_bounds.append(rho_A_kk + R_k_B)\n        \n    B_BG = np.max(block_bounds)\n\n    return rho_A, B_G, B_BG\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    # (N, a, nu, beta, b)\n    test_cases = [\n        (20, 1.0, 0.01, 0.0, 4),  # Case 1\n        (20, 0.0, 0.5, 0.0, 5),   # Case 2\n        (30, 2.0, 0.02, 3.0, 3),  # Case 3\n        (40, -1.0, 0.005, 8.0, 4), # Case 4\n    ]\n\n    all_results = []\n    for N, a, nu, beta, b in test_cases:\n        A = build_matrix(N, a, nu, beta)\n        rho_A, B_G, B_BG = compute_bounds(A, b)\n        \n        delta_G = B_G - rho_A\n        delta_BG = B_BG - rho_A\n        \n        all_results.append([rho_A, B_G, B_BG, delta_G, delta_BG])\n\n    # Format the final output string exactly as required\n    output_str = f\"[{','.join([str(r).replace(' ', '') for r in all_results])}]\"\n    print(output_str)\n\nsolve()\n\n```"
        }
    ]
}