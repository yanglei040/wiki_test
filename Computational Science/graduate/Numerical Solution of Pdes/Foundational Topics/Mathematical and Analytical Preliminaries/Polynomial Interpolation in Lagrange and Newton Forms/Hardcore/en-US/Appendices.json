{
    "hands_on_practices": [
        {
            "introduction": "The Newton form of the interpolating polynomial provides a powerful and efficient framework for adding new data points, a common task in numerical PDE methods like ghost-cell boundary treatments. This exercise () grounds this abstract concept in a concrete calculation, building the essential skill of constructing a divided difference table. By working through this process, you will see how the nested structure of the Newton form arises directly from the data, providing a foundation for more advanced topics like error estimation.",
            "id": "3433298",
            "problem": "In a boundary treatment for a one-dimensional semi-discrete method-of-lines discretization of a linear scalar partial differential equation (PDE), one often needs a local polynomial reconstruction of the solution from interior nodal values to provide a ghost value outside the computational domain. Suppose we have sampled data $\\{(x_i,f_i)\\}$ from a smooth profile at the distinct nodes $x_0=0$, $x_1=1$, and $x_2=2$, with corresponding values $f_0=2$, $f_1=3$, and $f_2=10$. Let $p(x)$ denote the unique polynomial of degree at most $2$ that interpolates these data. Starting only from the recursive definition of divided differences and the defining property of polynomial interpolation (namely that $p(x_i)=f_i$ for each node), do the following:\n\n- Construct the divided difference table for the data using the recursion for divided differences.\n- From the table, write down the Newton form of $p(x)$ and then evaluate it at the off-grid location $x=3$.\n\nYour final answer must be the single number $p(3)$. No rounding is required, and you should give the exact value.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and complete. It describes a standard numerical analysis task: polynomial interpolation using the Newton form, constructed via divided differences. All necessary data, including the distinct nodes and their corresponding function values, are provided to determine a unique interpolating polynomial of degree at most $2$. The problem is therefore valid and a solution will be furnished.\n\nThe task is to find the value of an interpolating polynomial $p(x)$ at $x=3$, given the data points $(x_0, f_0)=(0, 2)$, $(x_1, f_1)=(1, 3)$, and $(x_2, f_2)=(2, 10)$. The polynomial $p(x)$ is the unique polynomial of degree at most $2$ such that $p(x_i)=f_i$ for $i \\in \\{0, 1, 2\\}$. We will construct this polynomial using the Newton form, which is built upon divided differences.\n\nThe Newton form of the interpolating polynomial is given by:\n$$p(x) = \\sum_{k=0}^{n} c_k \\prod_{j=0}^{k-1} (x-x_j)$$\nFor $n=2$, this expands to:\n$$p(x) = c_0 + c_1(x-x_0) + c_2(x-x_0)(x-x_1)$$\nThe coefficients $c_k$ are the divided differences, defined as $c_k = f[x_0, x_1, \\dots, x_k]$.\n\nWe begin by constructing the divided difference table based on their recursive definition.\nThe zeroth-order divided differences are simply the function values:\n$$f[x_0] = f_0 = 2$$\n$$f[x_1] = f_1 = 3$$\n$$f[x_2] = f_2 = 10$$\n\nThe first-order divided differences are calculated as:\n$$f[x_0, x_1] = \\frac{f[x_1] - f[x_0]}{x_1 - x_0} = \\frac{3 - 2}{1 - 0} = \\frac{1}{1} = 1$$\n$$f[x_1, x_2] = \\frac{f[x_2] - f[x_1]}{x_2 - x_1} = \\frac{10 - 3}{2 - 1} = \\frac{7}{1} = 7$$\n\nThe second-order divided difference is calculated from the first-order differences:\n$$f[x_0, x_1, x_2] = \\frac{f[x_1, x_2] - f[x_0, x_1]}{x_2 - x_0} = \\frac{7 - 1}{2 - 0} = \\frac{6}{2} = 3$$\n\nThe complete divided difference table is as follows:\n\\begin{array}{c|c|c|c}\nx_i & f[x_i] & f[x_i, x_{i+1}] & f[x_0, x_1, x_2] \\\\\n\\hline\nx_0=0 & f[x_0]=2 & & \\\\\n& & f[x_0, x_1]=1 & \\\\\nx_1=1 & f[x_1]=3 & & f[x_0, x_1, x_2]=3 \\\\\n& & f[x_1, x_2]=7 & \\\\\nx_2=2 & f[x_2]=10 & &\n\\end{array}\n\nThe coefficients for the Newton polynomial are the top entries in each column of the divided differences:\n$$c_0 = f[x_0] = 2$$\n$$c_1 = f[x_0, x_1] = 1$$\n$$c_2 = f[x_0, x_1, x_2] = 3$$\n\nNow, we can write the Newton form of the interpolating polynomial $p(x)$:\n$$p(x) = f[x_0] + f[x_0, x_1](x - x_0) + f[x_0, x_1, x_2](x - x_0)(x - x_1)$$\nSubstituting the coefficients and node values:\n$$p(x) = 2 + 1(x - 0) + 3(x - 0)(x - 1)$$\n$$p(x) = 2 + x + 3x(x-1)$$\n\nThe final step is to evaluate this polynomial at the specified point $x=3$:\n$$p(3) = 2 + (3) + 3(3)(3 - 1)$$\n$$p(3) = 2 + 3 + 3(3)(2)$$\n$$p(3) = 5 + 18$$\n$$p(3) = 23$$\nThis is the value of the polynomial at the off-grid location $x=3$.\nFor completeness, we can expand the polynomial to its standard form:\n$p(x) = 2 + x + 3x^2 - 3x = 3x^2 - 2x + 2$.\nEvaluating at $x=3$ again serves as a check:\n$p(3) = 3(3^2) - 2(3) + 2 = 3(9) - 6 + 2 = 27 - 6 + 2 = 23$.\nThe result is consistent.",
            "answer": "$$\\boxed{23}$$"
        },
        {
            "introduction": "Polynomial interpolation is not just for function approximation; it is a cornerstone of numerical integration, or quadrature, which is essential for solving PDEs. This practice () explores this link by analyzing the error that occurs when a low-order interpolatory quadrature rule is used to integrate a complex, nonlinear term—a common scenario in finite element methods. Understanding this \"aliasing error\" is critical for developing robust and accurate numerical solvers.",
            "id": "3433294",
            "problem": "Consider the one-dimensional reduction of the nonlinear diffusion partial differential equation (PDE), written as $\\,\\frac{d}{dx}\\big(\\kappa(u)\\,\\frac{du}{dx}\\big)=0\\,$. In assembling a stiffness-like contribution on a single reference element, the integral of interest for a given approximation $u(x)$ is the scalar quantity\n$$S_{\\mathrm{exact}} \\;=\\; \\int_{-1}^{1} \\kappa(u(x))\\,\\Big(\\frac{du}{dx}(x)\\Big)^{2}\\,dx.$$\nLet the approximate solution be the polynomial $\\,u(x)=x^{3}+x\\,$ and take the nonlinear diffusion coefficient to be $\\,\\kappa(u)=1+\\alpha\\,u^{2}\\,$, where $\\,\\alpha\\,$ is a real parameter. To emulate an under-integration scenario with interpolatory quadrature based on Lagrange nodes, use the degree-$2$ Lagrange interpolation nodes $\\,x_{0}=-1\\,,\\,x_{1}=0\\,,\\,x_{2}=1\\,$ and define the quadrature weights by integrating the corresponding Lagrange basis polynomials $\\,\\ell_{i}(x)\\,$:\n$$w_{i}\\;=\\;\\int_{-1}^{1} \\ell_{i}(x)\\,dx,\\quad i=0,1,2.$$\nThe quadrature approximation of the integral is then\n$$S_{\\mathrm{quad}}\\;=\\;\\sum_{i=0}^{2} w_{i}\\,f(x_{i}),\\qquad f(x)\\;=\\;\\kappa(u(x))\\,\\Big(\\frac{du}{dx}(x)\\Big)^{2}.$$\nStarting only from the core definitions of Lagrange interpolation and the Newton form of interpolation (via divided differences), and the elementary properties of polynomial integration on $[-1,1]$, derive the weights $w_{i}$ and compute the aliasing error\n$$E(\\alpha)\\;=\\;S_{\\mathrm{exact}}-S_{\\mathrm{quad}}.$$\nExpress your final answer as a single closed-form analytic expression in $\\,\\alpha\\,$. No rounding is required, and no physical units are associated with $E(\\alpha)$.",
            "solution": "The problem requires the calculation of the aliasing error $E(\\alpha) = S_{\\mathrm{exact}} - S_{\\mathrm{quad}}$ for a specific integral evaluated exactly and with a $3$-point interpolatory quadrature rule. The process involves three main steps: calculating the exact integral $S_{\\mathrm{exact}}$, calculating the quadrature approximation $S_{\\mathrm{quad}}$, and then finding their difference.\n\nFirst, we define the integrand function $f(x) = \\kappa(u(x))\\,\\Big(\\frac{du}{dx}(x)\\Big)^{2}$.\nGiven the approximate solution $u(x) = x^{3}+x$, its derivative is $\\frac{du}{dx}(x) = 3x^{2}+1$.\nThe square of the derivative is $\\Big(\\frac{du}{dx}(x)\\Big)^{2} = (3x^{2}+1)^{2} = 9x^{4}+6x^{2}+1$.\nThe nonlinear diffusion coefficient is $\\kappa(u)=1+\\alpha\\,u^{2}$. Substituting $u(x)$ into $\\kappa(u)$ gives:\n$\\kappa(u(x)) = 1+\\alpha\\,(x^{3}+x)^{2} = 1+\\alpha\\,(x(x^{2}+1))^{2} = 1+\\alpha\\,x^{2}(x^{4}+2x^{2}+1) = 1+\\alpha\\,(x^{6}+2x^{4}+x^{2})$.\nNow, we construct the full integrand $f(x)$:\n$f(x) = [1+\\alpha\\,(x^{6}+2x^{4}+x^{2})][9x^{4}+6x^{2}+1]$\n$f(x) = (9x^{4}+6x^{2}+1) + \\alpha\\,(x^{6}+2x^{4}+x^{2})(9x^{4}+6x^{2}+1)$\nExpanding the term multiplied by $\\alpha$:\n$(x^{6}+2x^{4}+x^{2})(9x^{4}+6x^{2}+1) = 9x^{10}+6x^{8}+x^{6} + 18x^{8}+12x^{6}+2x^{4} + 9x^{6}+6x^{4}+x^{2}$\n$= 9x^{10}+24x^{8}+22x^{6}+8x^{4}+x^{2}$.\nSo, the complete expression for the integrand is:\n$f(x) = (9x^{4}+6x^{2}+1) + \\alpha\\,(9x^{10}+24x^{8}+22x^{6}+8x^{4}+x^{2})$.\n\nNext, we calculate $S_{\\mathrm{exact}} = \\int_{-1}^{1} f(x)\\,dx$. Since $f(x)$ is an even function (all powers of $x$ are even), we can use the property $\\int_{-1}^{1} x^{2n}\\,dx = \\frac{2}{2n+1}$.\nThe integral is separated into two parts:\n$\\int_{-1}^{1} (9x^{4}+6x^{2}+1) \\,dx = 9\\Big(\\frac{2}{5}\\Big) + 6\\Big(\\frac{2}{3}\\Big) + 1(2) = \\frac{18}{5} + 4 + 2 = \\frac{18}{5} + 6 = \\frac{18+30}{5} = \\frac{48}{5}$.\n$\\int_{-1}^{1} (9x^{10}+24x^{8}+22x^{6}+8x^{4}+x^{2}) \\,dx = 9\\Big(\\frac{2}{11}\\Big) + 24\\Big(\\frac{2}{9}\\Big) + 22\\Big(\\frac{2}{7}\\Big) + 8\\Big(\\frac{2}{5}\\Big) + \\Big(\\frac{2}{3}\\Big)$\n$= \\frac{18}{11} + \\frac{48}{9} + \\frac{44}{7} + \\frac{16}{5} + \\frac{2}{3} = \\frac{18}{11} + \\frac{16}{3} + \\frac{44}{7} + \\frac{16}{5} + \\frac{2}{3} = \\frac{18}{11} + \\frac{18}{3} + \\frac{44}{7} + \\frac{16}{5} = \\frac{18}{11} + 6 + \\frac{44}{7} + \\frac{16}{5}$.\nTo sum these fractions, we find a common denominator, which is $5 \\times 7 \\times 11 = 385$:\n$ = \\frac{18 \\times 35}{385} + \\frac{6 \\times 385}{385} + \\frac{44 \\times 55}{385} + \\frac{16 \\times 77}{385} = \\frac{630 + 2310 + 2420 + 1232}{385} = \\frac{6592}{385}$.\nCombining these results, we find the exact integral:\n$S_{\\mathrm{exact}} = \\frac{48}{5} + \\alpha\\,\\frac{6592}{385}$.\n\nNow, we compute the quadrature approximation $S_{\\mathrm{quad}} = \\sum_{i=0}^{2} w_{i}\\,f(x_{i})$. This requires deriving the weights $w_i$ and evaluating $f(x_i)$ at the nodes $x_0=-1, x_1=0, x_2=1$.\nThe weights $w_i$ are found by integrating the corresponding Lagrange basis polynomials $\\ell_i(x)$ over $[-1, 1]$.\nThe basis polynomials for the nodes $x_0=-1$, $x_1=0$, $x_2=1$ are:\n$\\ell_{0}(x) = \\frac{(x-x_1)(x-x_2)}{(x_0-x_1)(x_0-x_2)} = \\frac{(x-0)(x-1)}{(-1-0)(-1-1)} = \\frac{1}{2}(x^{2}-x)$.\n$\\ell_{1}(x) = \\frac{(x-x_0)(x-x_2)}{(x_1-x_0)(x_1-x_2)} = \\frac{(x+1)(x-1)}{(0+1)(0-1)} = -(x^{2}-1) = 1-x^{2}$.\n$\\ell_{2}(x) = \\frac{(x-x_0)(x-x_1)}{(x_2-x_0)(x_2-x_1)} = \\frac{(x+1)(x-0)}{(1+1)(1-0)} = \\frac{1}{2}(x^{2}+x)$.\nThe weights are the integrals of these polynomials:\n$w_{0} = \\int_{-1}^{1} \\frac{1}{2}(x^{2}-x) \\,dx = \\frac{1}{2}\\Big[\\frac{x^{3}}{3}-\\frac{x^{2}}{2}\\Big]_{-1}^{1} = \\frac{1}{2}\\Big[\\Big(\\frac{1}{3}-\\frac{1}{2}\\Big)-\\Big(-\\frac{1}{3}-\\frac{1}{2}\\Big)\\Big] = \\frac{1}{2}\\Big(\\frac{2}{3}\\Big) = \\frac{1}{3}$.\n$w_{1} = \\int_{-1}^{1} (1-x^{2}) \\,dx = \\Big[x-\\frac{x^{3}}{3}\\Big]_{-1}^{1} = \\Big(1-\\frac{1}{3}\\Big)-\\Big(-1+\\frac{1}{3}\\Big) = \\frac{2}{3} - (-\\frac{2}{3}) = \\frac{4}{3}$.\n$w_{2} = \\int_{-1}^{1} \\frac{1}{2}(x^{2}+x) \\,dx = \\frac{1}{2}\\Big[\\frac{x^{3}}{3}+\\frac{x^{2}}{2}\\Big]_{-1}^{1} = \\frac{1}{2}\\Big[\\Big(\\frac{1}{3}+\\frac{1}{2}\\Big)-\\Big(-\\frac{1}{3}+\\frac{1}{2}\\Big)\\Big] = \\frac{1}{2}\\Big(\\frac{2}{3}\\Big) = \\frac{1}{3}$.\nThese are the weights for Simpson's rule.\n\nNext, we evaluate $f(x)$ at the nodes:\nAt $x_0=-1$:\n$u(-1) = (-1)^{3}+(-1) = -2$.\n$\\frac{du}{dx}(-1) = 3(-1)^{2}+1 = 4$.\n$f(-1) = \\kappa(u(-1))\\Big(\\frac{du}{dx}(-1)\\Big)^{2} = (1+\\alpha(-2)^{2})(4^{2}) = (1+4\\alpha)(16) = 16+64\\alpha$.\nAt $x_1=0$:\n$u(0) = 0$.\n$\\frac{du}{dx}(0) = 3(0)^{2}+1 = 1$.\n$f(0) = \\kappa(u(0))\\Big(\\frac{du}{dx}(0)\\Big)^{2} = (1+\\alpha(0)^{2})(1^{2}) = 1$.\nAt $x_2=1$:\n$u(1) = 1^{3}+1 = 2$.\n$\\frac{du}{dx}(1) = 3(1)^{2}+1 = 4$.\n$f(1) = \\kappa(u(1))\\Big(\\frac{du}{dx}(1)\\Big)^{2} = (1+\\alpha(2)^{2})(4^{2}) = (1+4\\alpha)(16) = 16+64\\alpha$.\n\nNow, we compute $S_{\\mathrm{quad}}$:\n$S_{\\mathrm{quad}} = w_0 f(-1) + w_1 f(0) + w_2 f(1) = \\frac{1}{3}(16+64\\alpha) + \\frac{4}{3}(1) + \\frac{1}{3}(16+64\\alpha)$.\n$S_{\\mathrm{quad}} = \\frac{1}{3}(16+64\\alpha + 4 + 16+64\\alpha) = \\frac{1}{3}(36+128\\alpha) = 12 + \\frac{128}{3}\\alpha$.\n\nFinally, we compute the aliasing error $E(\\alpha) = S_{\\mathrm{exact}} - S_{\\mathrm{quad}}$:\n$E(\\alpha) = \\Big(\\frac{48}{5} + \\alpha\\,\\frac{6592}{385}\\Big) - \\Big(12 + \\frac{128}{3}\\alpha\\Big)$.\nWe group the terms independent of $\\alpha$ and the terms proportional to $\\alpha$:\n$E(\\alpha) = \\Big(\\frac{48}{5} - 12\\Big) + \\Big(\\frac{6592}{385} - \\frac{128}{3}\\Big)\\alpha$.\nThe constant term is:\n$\\frac{48}{5} - \\frac{60}{5} = -\\frac{12}{5}$.\nThe coefficient of $\\alpha$ is:\n$\\frac{6592}{385} - \\frac{128}{3} = \\frac{3 \\times 6592 - 128 \\times 385}{3 \\times 385} = \\frac{19776 - 49280}{1155} = -\\frac{29504}{1155}$.\nThe fraction $-\\frac{29504}{1155}$ cannot be simplified, as $1155 = 3 \\times 5 \\times 7 \\times 11$ and $29504$ is not divisible by $3$, $5$, $7$, or $11$.\nThus, the final expression for the aliasing error is:\n$E(\\alpha) = -\\frac{12}{5} - \\frac{29504}{1155}\\alpha$.",
            "answer": "$$\n\\boxed{-\\frac{12}{5} - \\frac{29504}{1155}\\alpha}\n$$"
        },
        {
            "introduction": "Moving from manual calculation to automated computation is a key step in mastering numerical methods. This coding exercise () challenges you to implement a complete adaptive interpolation algorithm, a technique used in modern numerical libraries and spectral methods. You will work with the numerically stable barycentric form for evaluation and use an error-based criterion to intelligently refine your approximation, experiencing firsthand how theoretical concepts are translated into practical, efficient code.",
            "id": "3433292",
            "problem": "Consider the function $f(x)=\\exp(-x^2)$ defined on the interval $[-3,3]$. In spectral methods for solving Partial Differential Equations (PDE), polynomial interpolation on adaptively refined node sets is used both for function representation and as a building block for collocation and quadrature. Starting from an initial set of $n=4$ Chebyshev nodes of the first kind mapped to $[-3,3]$, perform one step of adaptive node insertion using the following principle: construct the barycentric Lagrange interpolant of $f$ on the current node set, estimate the point of largest absolute residual $|f(x)-p(x)|$ on a uniform grid of the interval, insert that point as a new node, and update the interpolant in both barycentric (Lagrange) and Newton (divided differences) forms. Angles used in cosine evaluations must be in radians.\n\nYour program must:\n- Generate the initial nodes $\\{x_k\\}_{k=1}^n$ using the Chebyshev nodes of the first kind mapped from $[-1,1]$ to $[-3,3]$, where $x_k=\\frac{a+b}{2}+\\frac{b-a}{2}\\cos\\left(\\frac{2k-1}{2n}\\pi\\right)$ with $a=-3$ and $b=3$, and $n=4$.\n- Construct the barycentric Lagrange interpolant $p(x)$ of degree $n-1$ from these nodes and the function values $\\{f(x_k)\\}$.\n- On a specified uniform grid of $M$ points in $[-3,3]$, compute the absolute residual $|f(x)-p(x)|$ and identify the point $x_{\\text{new}}$ where this residual attains its maximum. Insert $x_{\\text{new}}$ to the node set, recompute the barycentric interpolant from the updated node set, and also compute the Newton (divided differences) form of the updated interpolant.\n- Evaluate both updated interpolants on a specified set of test evaluation points and report their consistency via the maximum absolute difference.\n\nDesign the implementation from fundamental principles of polynomial interpolation:\n- Use the definition and uniqueness of the interpolating polynomial through $n$ distinct nodes, the Lagrange basis polynomials, and the Newton divided differences construction as the starting point for derivation and algorithmic design. Do not rely on shortcuts beyond these fundamental principles.\n\nTest Suite:\nProvide three test cases that vary the residual grid resolution and the evaluation points set to exercise different aspects of the algorithm (general case, coarse grid sensitivity, and fine grid near-boundary behavior). For each test case, use the same initial $n=4$ nodes, and specify:\n1. Case A (general resolution): residual grid size $M=401$ and evaluation points $E=\\{-3,-1.5,0,1.5,3\\}$.\n2. Case B (coarse resolution): residual grid size $M=51$ and evaluation points $E$ as $7$ equispaced points on $[-3,3]$.\n3. Case C (fine resolution): residual grid size $M=1001$ and evaluation points $E$ as $9$ Chebyshev–Gauss–Lobatto points mapped to $[-3,3]$, i.e., $x_j=\\frac{a+b}{2}+\\frac{b-a}{2}\\cos\\left(\\frac{j\\pi}{m}\\right)$ with $m=8$ and $j=0,1,\\dots,8$.\n\nFor each test case, your program must compute and return the following four quantities in the specified order:\n- The inserted node $x_{\\text{new}}$ (a float).\n- The maximum absolute residual before insertion, i.e., $\\max_{x\\in\\text{grid}}|f(x)-p(x)|$ (a float).\n- The maximum absolute residual after insertion, computed with the updated barycentric interpolant, i.e., $\\max_{x\\in\\text{grid}}|f(x)-p_{\\text{updated}}(x)|$ (a float).\n- The maximum absolute difference between the updated barycentric and updated Newton interpolants over the evaluation points set $E$, i.e., $\\max_{x\\in E}|p_{\\text{updated}}(x)-p_{\\text{Newton}}(x)|$ (a float).\n\nFinal Output Format:\nYour program should produce a single line of output containing the concatenated results of all three test cases as a comma-separated list enclosed in square brackets, in the order of the metrics listed above for Case A, then Case B, then Case C. For example, the output must have the form $[\\text{A}_1,\\text{A}_2,\\text{A}_3,\\text{A}_4,\\text{B}_1,\\text{B}_2,\\text{B}_3,\\text{B}_4,\\text{C}_1,\\text{C}_2,\\text{C}_3,\\text{C}_4]$, where each entry is a float.",
            "solution": "## Problem Validation\n\n### Step 1: Extract Givens\n- **Function**: $f(x)=\\exp(-x^2)$\n- **Interval**: $[-3,3]$\n- **Initial Node Count**: $n=4$\n- **Initial Node Generation**: Chebyshev nodes of the first kind mapped from $[-1,1]$ to $[-3,3]$ using the formula $x_k=\\frac{a+b}{2}+\\frac{b-a}{2}\\cos\\left(\\frac{2k-1}{2n}\\pi\\right)$ with $a=-3$, $b=3$, and $n=4$.\n- **Adaptive Refinement Procedure**:\n  1. Construct the barycentric Lagrange interpolant $p(x)$ for the current node set $\\{x_k\\}$.\n  2. Estimate the point of largest absolute residual $|f(x)-p(x)|$ on a uniform grid over the interval. Let this point be $x_{\\text{new}}$.\n  3. Insert $x_{\\text{new}}$ into the node set.\n  4. Construct the updated interpolant using both barycentric Lagrange and Newton divided differences forms.\n- **Test Cases**:\n  - **Case A**: Residual grid size $M=401$, evaluation points $E=\\{-3,-1.5,0,1.5,3\\}$.\n  - **Case B**: Residual grid size $M=51$, evaluation points $E$ as $7$ equispaced points on $[-3,3]$.\n  - **Case C**: Residual grid size $M=1001$, evaluation points $E$ as $9$ Chebyshev-Gauss-Lobatto (CGL) points on $[-3,3]$, given by $x_j=\\frac{a+b}{2}+\\frac{b-a}{2}\\cos\\left(\\frac{j\\pi}{m}\\right)$ with $m=8$ and $j=0,1,\\dots,8$.\n- **Required Output per Case**:\n  1. The inserted node $x_{\\text{new}}$.\n  2. The maximum absolute residual before insertion, $\\max_{x\\in\\text{grid}}|f(x)-p(x)|$.\n  3. The maximum absolute residual after insertion, $\\max_{x\\in\\text{grid}}|f(x)-p_{\\text{updated}}(x)|$.\n  4. The maximum absolute difference between the updated barycentric and Newton interpolants over the evaluation points $E$, $\\max_{x\\in E}|p_{\\text{updated}}(x)-p_{\\text{Newton}}(x)|$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the validation criteria.\n- **Scientifically Grounded**: The problem is fundamentally sound. It is based on established principles of numerical analysis, including polynomial interpolation, Lagrange and Newton forms, Chebyshev nodes, and adaptive refinement. These are standard topics in scientific computing and spectral methods.\n- **Well-Posed**: The problem is well-posed. All required parameters ($a, b, n, M, E$) and formulas are explicitly provided. The procedure is algorithmic and deterministic, leading to a unique set of numerical results. The existence and uniqueness of an interpolating polynomial through a set of distinct points is a cornerstone theorem of numerical analysis.\n- **Objective**: The problem is stated in precise, objective mathematical language, free from ambiguity or subjective claims.\n- **Flaw Checklist**: The problem does not exhibit any of the listed flaws. It is scientifically sound, formalizable, complete, feasible, well-posed, and non-trivial. The task requires a concrete implementation of fundamental numerical algorithms and a comparison of their results, which is a meaningful exercise.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n## Solution Derivation and Algorithmic Design\n\nThe solution involves a multi-step numerical procedure based on the theory of polynomial interpolation.\n\n### Theoretical Foundation\n\nFor a set of $n$ distinct nodes $\\{x_k\\}_{k=1}^n$ and corresponding values $\\{y_k\\}_{k=1}^n$, there exists a unique polynomial $p(x)$ of degree at most $n-1$ such that $p(x_k)=y_k$ for all $k$. This problem requires constructing and evaluating this polynomial in two different forms.\n\n**1. Barycentric Lagrange Interpolation**\nThe Lagrange form of the interpolating polynomial is $p(x) = \\sum_{k=1}^n y_k L_k(x)$, where $L_k(x)$ are the Lagrange basis polynomials. A more numerically stable and efficient evaluation is achieved using the second barycentric formula:\n$$\np(x) = \\frac{\\sum_{k=1}^n \\frac{w_k}{x-x_k} y_k}{\\sum_{k=1}^n \\frac{w_k}{x-x_k}}\n$$\nThis formula is valid for any $x$ not in the set of nodes. If $x=x_j$ for some index $j$, then $p(x_j)=y_j$. The barycentric weights $w_k$ are defined as:\n$$\nw_k = \\frac{1}{\\prod_{j=1, j\\neq k}^n (x_k - x_j)}\n$$\n\n**2. Newton Form and Divided Differences**\nThe Newton form of the interpolating polynomial is:\n$$\np(x) = c_1 + c_2(x-x_1) + c_3(x-x_1)(x-x_2) + \\dots + c_n \\prod_{j=1}^{n-1} (x-x_j)\n$$\nThe coefficients $c_k = f[x_1, \\dots, x_k]$ are called divided differences. They are computed recursively. For a set of nodes $\\{x_i\\}_{i=1}^n$ (assumed sorted for convention), the divided differences are:\n- Zeroth order: $f[x_i] = f(x_i) = y_i$\n- Higher orders: $f[x_i, \\dots, x_{i+j}] = \\frac{f[x_{i+1}, \\dots, x_{i+j}] - f[x_i, \\dots, x_{i+j-1}]}{x_{i+j} - x_i}$\nThe coefficients are the top diagonal of the divided differences table: $c_k = f[x_1, \\dots, x_k]$. The polynomial is evaluated efficiently using Horner's method.\n\n**3. Node Sets**\n- **Initial Nodes**: Chebyshev nodes of the first kind are the roots of the Chebyshev polynomial $T_n(x)$. They are chosen because they minimize the maximum value of $|\\prod(x-x_k)|$ over the interval, which tends to minimize interpolation error. The given formula maps the standard nodes from $[-1,1]$ to $[a,b]$.\n- **Evaluation Points**: The problem specifies different sets of evaluation points for each test case, including Chebyshev-Gauss-Lobatto points, which are the a-extrema of Chebyshev polynomials and include the interval endpoints.\n\n### Algorithmic Procedure\n\nFor each test case, the following sequence of steps is executed.\n\n**Step 1: Initial Setup**\n- Define the function $f(x)=\\exp(-x^2)$, interval parameters $a=-3, b=3$, and initial node count $n=4$.\n- Generate the initial $n=4$ Chebyshev nodes $\\{x_k\\}_{k=1}^4$ using the specified formula: $x_k = 3\\cos\\left(\\frac{2k-1}{8}\\pi\\right)$.\n- Compute the corresponding function values $y_k=f(x_k)$. For convenience in implementation, the nodes are sorted.\n\n**Step 2: Initial Interpolation and Residual Calculation**\n- Calculate the barycentric weights $w_k$ for the initial $n=4$ nodes.\n- Define the initial interpolant $p(x)$ using the barycentric formula.\n- Create a uniform grid of $M$ points over $[-3,3]$.\n- Evaluate the absolute residual $|f(x)-p(x)|$ at each point on the grid.\n- Identify the maximum residual, $\\max_{x\\in\\text{grid}}|f(x)-p(x)|$, and the grid point $x_{\\text{new}}$ at which this maximum occurs.\n\n**Step 3: Adaptive Node Insertion**\n- The set of nodes is updated by adding $x_{\\text{new}}$, resulting in a new set of $n+1=5$ nodes.\n- The corresponding function values are also updated to include $f(x_{\\text{new}})$.\n- The updated node set is sorted to maintain order for the Newton form construction.\n\n**Step 4: Construction of Updated Interpolants**\n- **Updated Barycentric Form**: New barycentric weights are computed for the set of $5$ nodes. This defines the updated barycentric interpolant, $p_{\\text{updated}}(x)$.\n- **Updated Newton Form**: A divided differences table is constructed for the $5$ nodes and their function values. The top diagonal of this table provides the coefficients for the Newton form of the interpolant, $p_{\\text{Newton}}(x)$.\n\n**Step 5: Final Evaluation and Comparison**\n- **Post-Insertion Residual**: The residual $|f(x) - p_{\\text{updated}}(x)|$ is evaluated on the same M-point grid, and its maximum value is computed.\n- **Consistency Check**: Both updated interpolants, $p_{\\text{updated}}(x)$ and $p_{\\text{Newton}}(x)$, are evaluated at the specified set of evaluation points $E$. The maximum absolute difference between their values, $\\max_{x\\in E}|p_{\\text{updated}}(x)-p_{\\text{Newton}}(x)|$, is calculated. Due to the uniqueness of the interpolating polynomial, this value should be close to machine epsilon, serving as a verification of the implementation's correctness.\n\nThe four required metrics ($x_{\\text{new}}$, pre-insertion max residual, post-insertion max residual, and interpolant difference) are collected for each of the three test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the polynomial interpolation problem with adaptive node insertion\n    for three test cases.\n    \"\"\"\n\n    def compute_barycentric_weights(nodes):\n        \"\"\"Computes barycentric weights for a given set of nodes.\"\"\"\n        n = len(nodes)\n        weights = np.ones(n, dtype=np.float64)\n        for k in range(n):\n            for j in range(n):\n                if j != k:\n                    weights[k] /= (nodes[k] - nodes[j])\n        return weights\n\n    def evaluate_barycentric(x_eval, nodes, values, weights):\n        \"\"\"Evaluates the barycentric interpolant at points x_eval.\"\"\"\n        x_eval = np.atleast_1d(x_eval)\n        y_eval = np.zeros_like(x_eval, dtype=np.float64)\n\n        for i, x in enumerate(x_eval):\n            # Check if x is one of the interpolation nodes\n            match_indices = np.where(np.isclose(nodes, x))[0]\n            if len(match_indices) > 0:\n                y_eval[i] = values[match_indices[0]]\n                continue\n\n            numerator = 0.0\n            denominator = 0.0\n            for k in range(len(nodes)):\n                term = weights[k] / (x - nodes[k])\n                numerator += term * values[k]\n                denominator += term\n            \n            y_eval[i] = numerator / denominator if denominator != 0 else np.inf\n        \n        return y_eval\n\n    def compute_divided_differences(nodes, values):\n        \"\"\"Computes divided difference coefficients for the Newton form.\"\"\"\n        n = len(nodes)\n        coeffs = np.copy(values)\n        for j in range(1, n):\n            for i in range(n - 1, j - 1, -1):\n                coeffs[i] = (coeffs[i] - coeffs[i-1]) / (nodes[i] - nodes[i-j])\n        return coeffs\n\n    def evaluate_newton(x_eval, nodes, coeffs):\n        \"\"\"Evaluates the Newton polynomial using Horner's method.\"\"\"\n        x_eval = np.atleast_1d(x_eval)\n        n = len(nodes)\n        y_eval = np.full_like(x_eval, coeffs[n-1], dtype=np.float64)\n        for k in range(n - 2, -1, -1):\n            y_eval = y_eval * (x_eval - nodes[k]) + coeffs[k]\n        return y_eval\n    \n    # Define the function to be interpolated\n    f = lambda x: np.exp(-np.square(x))\n    a, b = -3.0, 3.0\n    n_initial = 4\n\n    # Generate initial Chebyshev nodes\n    k_indices = np.arange(1, n_initial + 1)\n    cos_args = (2 * k_indices - 1) * np.pi / (2 * n_initial)\n    initial_nodes = (a + b) / 2 + (b - a) / 2 * np.cos(cos_args)\n    initial_nodes = np.sort(initial_nodes)\n    initial_values = f(initial_nodes)\n\n    # --- Test Cases ---\n    \n    # Case A\n    M_A = 401\n    E_A = np.array([-3.0, -1.5, 0.0, 1.5, 3.0])\n\n    # Case B\n    M_B = 51\n    E_B = np.linspace(a, b, 7)\n\n    # Case C\n    M_C = 1001\n    m_cgl = 8\n    j_cgl = np.arange(0, m_cgl + 1)\n    cos_args_cgl = j_cgl * np.pi / m_cgl\n    E_C = (a + b) / 2 + (b - a) / 2 * np.cos(cos_args_cgl)\n\n    test_cases = [\n        (M_A, E_A),\n        (M_B, E_B),\n        (M_C, E_C)\n    ]\n\n    all_results = []\n\n    for M, E in test_cases:\n        # --- Initial Interpolation and Residual ---\n        weights_initial = compute_barycentric_weights(initial_nodes)\n        \n        residual_grid = np.linspace(a, b, M)\n        true_values_on_grid = f(residual_grid)\n        \n        interp_values_initial = evaluate_barycentric(residual_grid, initial_nodes, initial_values, weights_initial)\n        residuals_initial = np.abs(true_values_on_grid - interp_values_initial)\n        \n        max_residual_before = np.max(residuals_initial)\n        new_node_index = np.argmax(residuals_initial)\n        x_new = residual_grid[new_node_index]\n        \n        # --- Adaptive Node Insertion ---\n        updated_nodes_list = list(initial_nodes) + [x_new]\n        updated_nodes = np.sort(np.array(updated_nodes_list))\n        updated_values = f(updated_nodes)\n        \n        # --- Updated Interpolants ---\n        \n        # Barycentric updated\n        weights_updated = compute_barycentric_weights(updated_nodes)\n        p_bary_updated = lambda x: evaluate_barycentric(x, updated_nodes, updated_values, weights_updated)\n        \n        # Newton updated\n        # The Newton coefficients from `compute_divided_differences` correspond\n        # to the form p(x) = c0 + c1(x-x0) + c2(x-x0)(x-x1) + ...\n        # where the nodes are sorted x0, x1, ...\n        # Our `evaluate_newton` is implemented for this form.\n        coeffs_newton_updated = compute_divided_differences(updated_nodes, updated_values)\n        p_newton_updated = lambda x: evaluate_newton(x, updated_nodes, coeffs_newton_updated)\n        \n        # --- Final Metrics Calculation ---\n        \n        # Max residual after insertion\n        interp_values_updated = p_bary_updated(residual_grid)\n        max_residual_after = np.max(np.abs(true_values_on_grid - interp_values_updated))\n        \n        # Consistency check\n        bary_evals_on_E = p_bary_updated(E)\n        newton_evals_on_E = p_newton_updated(E)\n        max_diff_interp = np.max(np.abs(bary_evals_on_E - newton_evals_on_E))\n\n        # Collect results for this case\n        all_results.extend([x_new, max_residual_before, max_residual_after, max_diff_interp])\n\n    # Final output formatting\n    print(f\"[{','.join(f'{r:.15e}' for r in all_results)}]\")\n\nsolve()\n```"
        }
    ]
}