{
    "hands_on_practices": [
        {
            "introduction": "To solve partial differential equations on complex geometries, we must first understand how the NURBS map distorts the simple parametric domain into the physical one. This exercise introduces the metric tensor, with coefficients $g_{\\alpha\\beta}$, as the fundamental mathematical object that quantifies this local geometric distortion. By computing these coefficients directly from the NURBS definition, you will gain a concrete understanding of their role in transforming differential operators and integrals, a crucial first step in isogeometric analysis .",
            "id": "3411148",
            "problem": "Consider a tensor-product quadratic Non-Uniform Rational B-Spline (NURBS) surface used in isogeometric analysis (IGA) to map the parametric square to a curved two-dimensional domain. Let the parametric coordinates be $\\boldsymbol{\\xi}=(u,v)\\in[0,1]^{2}$, and the surface mapping be $\\mathbf{X}(u,v)=\\sum_{i=0}^{2}\\sum_{j=0}^{2}R_{ij}(u,v)\\,\\mathbf{P}_{ij}$, where $R_{ij}(u,v)$ are the rational basis functions constructed from quadratic open-knot univariate B-splines and weights $w_{ij}$, and $\\mathbf{P}_{ij}\\in\\mathbb{R}^{2}$ are the control points. The knot vectors are $U=V=\\{0,0,0,1,1,1\\}$, the control points are\n$$\n\\mathbf{P}_{00}=(0,0),\\ \\mathbf{P}_{10}=(1,0),\\ \\mathbf{P}_{20}=(2,0),\\quad\n\\mathbf{P}_{01}=(0,1),\\ \\mathbf{P}_{11}=(1,1),\\ \\mathbf{P}_{21}=(2,1),\\quad\n\\mathbf{P}_{02}=(0,2),\\ \\mathbf{P}_{12}=(1,2),\\ \\mathbf{P}_{22}=(2,2),\n$$\nand the weights are\n$$\nw_{ij}=1\\ \\text{for all}\\ (i,j)\\neq(1,1),\\quad w_{11}=2.\n$$\nDefine the metric coefficients $g_{\\alpha\\beta}(u,v)=\\partial_{\\alpha}\\mathbf{X}(u,v)\\cdot\\partial_{\\beta}\\mathbf{X}(u,v)$, where $\\alpha,\\beta\\in\\{u,v\\}$ and $\\partial_{\\alpha}\\mathbf{X}$ denotes the partial derivative of the mapping with respect to the parametric coordinate. Starting from the standard definitions of NURBS basis functions and the rational surface mapping, derive the expressions necessary to evaluate $g_{\\alpha\\beta}(u,v)$ and compute the metric entries at the parametric location $(u,v)=(\\tfrac{1}{2},\\tfrac{1}{2})$.\n\nThen, explain how the coefficients $g_{\\alpha\\beta}$ govern the transformation of gradients and integrals for Partial Differential Equations (PDEs) posed on curved domains within the isogeometric framework. In particular, clarify how the gradient operator and area elements change under the mapping $\\mathbf{X}$ and relate $g_{\\alpha\\beta}$ to these transformations.\n\nReport the values of $g_{11}$, $g_{12}$, and $g_{22}$ at $(u,v)=(\\tfrac{1}{2},\\tfrac{1}{2})$ in exact form. Provide your final answer as a single row matrix using the $\\mathrm{pmatrix}$ environment.",
            "solution": "The problem will be addressed in two parts. First, we will carry out the derivation and computation of the metric tensor components at the specified parametric point. Second, we will provide an explanation of the role of the metric tensor in the context of isogeometric analysis for solving Partial Differential Equations (PDEs).\n\n### Part 1: Computation of Metric Tensor Components\n\nThe problem asks for the metric coefficients $g_{\\alpha\\beta}(u,v)$ at $(u,v)=(\\tfrac{1}{2},\\tfrac{1}{2})$. The metric tensor components are defined as $g_{\\alpha\\beta} = \\partial_{\\alpha}\\mathbf{X} \\cdot \\partial_{\\beta}\\mathbf{X}$, where $\\mathbf{X}(u,v)$ is the NURBS surface mapping and $\\partial_{\\alpha}$ denotes the partial derivative with respect to a parametric coordinate $u$ or $v$. We will denote $\\partial_u \\mathbf{X}$ as the partial derivative with respect to $u$ and $\\partial_v \\mathbf{X}$ as the partial derivative with respect to $v$. The components to be computed are $g_{uu}$, $g_{uv}$, and $g_{vv}$.\n\nThe NURBS surface is defined as $\\mathbf{X}(u,v) = \\sum_{i=0}^{2}\\sum_{j=0}^{2}R_{ij}(u,v)\\,\\mathbf{P}_{ij}$. The rational basis functions $R_{ij}(u,v)$ are given by:\n$$\nR_{ij}(u,v) = \\frac{N_i^{(p)}(u) N_j^{(p)}(v) w_{ij}}{W(u,v)}\n$$\nwhere $N_k^{(p)}$ are the B-spline basis functions of degree $p$, $w_{ij}$ are the weights, and $W(u,v)$ is the denominator function:\n$$\nW(u,v) = \\sum_{k=0}^{2}\\sum_{l=0}^{2} N_k^{(p)}(u) N_l^{(p)}(v) w_{kl}\n$$\nThe knot vectors are $U=V=\\{0,0,0,1,1,1\\}$. This corresponds to a degree $p=2$ (quadratic) spline with $n+1=3$ basis functions in each parametric direction. The repeated knots at the ends mean that the B-spline basis functions are the quadratic Bernstein polynomials on the interval $[0,1]$:\n$$\nN_{0,2}(u) = (1-u)^2 \\\\\nN_{1,2}(u) = 2u(1-u) \\\\\nN_{2,2}(u) = u^2\n$$\nThe basis functions $N_{j,2}(v)$ are defined analogously. Due to the partition of unity property, $\\sum_{i=0}^{2} N_{i,2}(u) = 1$ for $u \\in [0,1]$.\n\nThe denominator function $W(u,v)$ can be simplified. Since $w_{ij}=1$ for all $(i,j)$ except $w_{11}=2$, we have:\n$$\nW(u,v) = \\sum_{k,l} N_{k,2}(u) N_{l,2}(v) + (w_{11}-1) N_{1,2}(u) N_{1,2}(v)\n$$\nUsing the partition of unity, $\\sum_{k,l} N_{k,2}(u) N_{l,2}(v) = \\left(\\sum_k N_{k,2}(u)\\right) \\left(\\sum_l N_{l,2}(v)\\right) = 1 \\cdot 1 = 1$. With $w_{11}=2$, we get:\n$$\nW(u,v) = 1 + N_{1,2}(u) N_{1,2}(v) = 1 + 4uv(1-u)(1-v)\n$$\nThe surface mapping can be written as $\\mathbf{X}(u,v) = \\frac{\\mathbf{A}(u,v)}{W(u,v)}$, where $\\mathbf{A}(u,v) = \\sum_{i,j} N_{i,2}(u) N_{j,2}(v) w_{ij} \\mathbf{P}_{ij}$.\n\nThe partial derivatives of $\\mathbf{X}(u,v)$ are found using the quotient rule. For the $u$-derivative:\n$$\n\\partial_u \\mathbf{X} = \\frac{(\\partial_u \\mathbf{A}) W - \\mathbf{A} (\\partial_u W)}{W^2}\n$$\nwhere $\\partial_u \\mathbf{A} = \\sum_{i,j} (\\partial_u N_{i,2}(u)) N_{j,2}(v) w_{ij} \\mathbf{P}_{ij}$ and $\\partial_u W = (\\partial_u N_{1,2}(u)) N_{1,2}(v)$.\n\nWe need to evaluate these at $(u,v)=(\\tfrac{1}{2},\\tfrac{1}{2})$. First, we evaluate the basis functions and their derivatives at $u=\\tfrac{1}{2}$:\n$$\nN_{0,2}(\\tfrac{1}{2}) = (1-\\tfrac{1}{2})^2 = \\tfrac{1}{4} \\\\\nN_{1,2}(\\tfrac{1}{2}) = 2(\\tfrac{1}{2})(1-\\tfrac{1}{2}) = \\tfrac{1}{2} \\\\\nN_{2,2}(\\tfrac{1}{2}) = (\\tfrac{1}{2})^2 = \\tfrac{1}{4}\n$$\nThe derivatives of the basis functions are:\n$$\n\\partial_u N_{0,2}(u) = -2(1-u) \\implies \\partial_u N_{0,2}(\\tfrac{1}{2}) = -1 \\\\\n\\partial_u N_{1,2}(u) = 2 - 4u \\implies \\partial_u N_{1,2}(\\tfrac{1}{2}) = 0 \\\\\n\\partial_u N_{2,2}(u) = 2u \\implies \\partial_u N_{2,2}(\\tfrac{1}{2}) = 1\n$$\nBy symmetry, the values for $N_{j,2}(\\tfrac{1}{2})$ and $\\partial_v N_{j,2}(\\tfrac{1}{2})$ are the same.\n\nNow, we evaluate $W$ and its derivatives at $(\\tfrac{1}{2},\\tfrac{1}{2})$:\n$$\nW(\\tfrac{1}{2},\\tfrac{1}{2}) = 1 + N_{1,2}(\\tfrac{1}{2}) N_{1,2}(\\tfrac{1}{2}) = 1 + (\\tfrac{1}{2})(\\tfrac{1}{2}) = \\tfrac{5}{4}\n$$\n$$\n\\partial_u W(\\tfrac{1}{2},\\tfrac{1}{2}) = (\\partial_u N_{1,2}(\\tfrac{1}{2})) N_{1,2}(\\tfrac{1}{2}) = 0 \\cdot \\tfrac{1}{2} = 0\n$$\nBy symmetry, $\\partial_v W(\\tfrac{1}{2},\\tfrac{1}{2}) = 0$.\n\nSince $\\partial_u W$ and $\\partial_v W$ are zero at the point of interest, the derivative expressions simplify significantly:\n$$\n\\partial_u \\mathbf{X}(\\tfrac{1}{2},\\tfrac{1}{2}) = \\frac{\\partial_u \\mathbf{A}(\\tfrac{1}{2},\\tfrac{1}{2})}{W(\\tfrac{1}{2},\\tfrac{1}{2})} \\quad \\text{and} \\quad \\partial_v \\mathbf{X}(\\tfrac{1}{2},\\tfrac{1}{2}) = \\frac{\\partial_v \\mathbf{A}(\\tfrac{1}{2},\\tfrac{1}{2})}{W(\\tfrac{1}{2},\\tfrac{1}{2})}\n$$\nLet's compute $\\partial_u \\mathbf{A}(\\tfrac{1}{2},\\tfrac{1}{2})$:\n$$\n\\partial_u \\mathbf{A}(\\tfrac{1}{2},\\tfrac{1}{2}) = \\sum_{i=0}^2 \\sum_{j=0}^2 (\\partial_u N_{i,2}(\\tfrac{1}{2})) N_{j,2}(\\tfrac{1}{2}) w_{ij} \\mathbf{P}_{ij}\n$$\nSince $\\partial_u N_{1,2}(\\tfrac{1}{2})=0$, the term for $i=1$ vanishes:\n$$\n\\partial_u \\mathbf{A}(\\tfrac{1}{2},\\tfrac{1}{2}) = (\\partial_u N_{0,2}(\\tfrac{1}{2})) \\sum_{j=0}^2 N_{j,2}(\\tfrac{1}{2}) w_{0j} \\mathbf{P}_{0j} + (\\partial_u N_{2,2}(\\tfrac{1}{2})) \\sum_{j=0}^2 N_{j,2}(\\tfrac{1}{2}) w_{2j} \\mathbf{P}_{2j}\n$$\n$$\n\\partial_u \\mathbf{A}(\\tfrac{1}{2},\\tfrac{1}{2}) = (-1) \\sum_{j=0}^2 N_{j,2}(\\tfrac{1}{2}) w_{0j} \\mathbf{P}_{0j} + (1) \\sum_{j=0}^2 N_{j,2}(\\tfrac{1}{2}) w_{2j} \\mathbf{P}_{2j}\n$$\nThe first sum is:\n$\\sum_{j=0}^2 N_{j,2}(\\tfrac{1}{2}) w_{0j} \\mathbf{P}_{0j} = \\tfrac{1}{4}(1)\\mathbf{P}_{00} + \\tfrac{1}{2}(1)\\mathbf{P}_{01} + \\tfrac{1}{4}(1)\\mathbf{P}_{02} = \\tfrac{1}{4}(0,0) + \\tfrac{1}{2}(0,1) + \\tfrac{1}{4}(0,2) = (0, \\tfrac{1}{2}) + (0, \\tfrac{1}{2}) = (0,1)$.\nThe second sum is:\n$\\sum_{j=0}^2 N_{j,2}(\\tfrac{1}{2}) w_{2j} \\mathbf{P}_{2j} = \\tfrac{1}{4}(1)\\mathbf{P}_{20} + \\tfrac{1}{2}(1)\\mathbf{P}_{21} + \\tfrac{1}{4}(1)\\mathbf{P}_{22} = \\tfrac{1}{4}(2,0) + \\tfrac{1}{2}(2,1) + \\tfrac{1}{4}(2,2) = (\\tfrac{1}{2},0) + (1,\\tfrac{1}{2}) + (\\tfrac{1}{2},\\tfrac{1}{2}) = (2,1)$.\nThus, $\\partial_u \\mathbf{A}(\\tfrac{1}{2},\\tfrac{1}{2}) = -(0,1) + (2,1) = (2,0)$.\n\nSimilarly, we compute $\\partial_v \\mathbf{A}(\\tfrac{1}{2},\\tfrac{1}{2})$:\n$$\n\\partial_v \\mathbf{A}(\\tfrac{1}{2},\\tfrac{1}{2}) = \\sum_{i=0}^2 N_{i,2}(\\tfrac{1}{2}) \\left( \\sum_{j=0}^2 (\\partial_v N_{j,2}(\\tfrac{1}{2})) w_{ij} \\mathbf{P}_{ij} \\right)\n$$\nSince $\\partial_v N_{1,2}(\\tfrac{1}{2})=0$, the term for $j=1$ vanishes inside the parenthesis sum.\n$$\n\\partial_v \\mathbf{A}(\\tfrac{1}{2},\\tfrac{1}{2}) = (\\partial_v N_{0,2}(\\tfrac{1}{2})) \\sum_{i=0}^2 N_{i,2}(\\tfrac{1}{2}) w_{i0} \\mathbf{P}_{i0} + (\\partial_v N_{2,2}(\\tfrac{1}{2})) \\sum_{i=0}^2 N_{i,2}(\\tfrac{1}{2}) w_{i2} \\mathbf{P}_{i2}\n$$\nThe first sum is:\n$\\sum_{i=0}^2 N_{i,2}(\\tfrac{1}{2}) w_{i0} \\mathbf{P}_{i0} = \\tfrac{1}{4}(1)\\mathbf{P}_{00} + \\tfrac{1}{2}(1)\\mathbf{P}_{10} + \\tfrac{1}{4}(1)\\mathbf{P}_{20} = \\tfrac{1}{4}(0,0) + \\tfrac{1}{2}(1,0) + \\tfrac{1}{4}(2,0) = (0,0) + (\\tfrac{1}{2},0) + (\\tfrac{1}{2},0) = (1,0)$.\nThe second sum is:\n$\\sum_{i=0}^2 N_{i,2}(\\tfrac{1}{2}) w_{i2} \\mathbf{P}_{i2} = \\tfrac{1}{4}(1)\\mathbf{P}_{02} + \\tfrac{1}{2}(1)\\mathbf{P}_{12} + \\tfrac{1}{4}(1)\\mathbf{P}_{22} = \\tfrac{1}{4}(0,2) + \\tfrac{1}{2}(1,2) + \\tfrac{1}{4}(2,2) = (0, \\tfrac{1}{2}) + (\\tfrac{1}{2},1) + (\\tfrac{1}{2},\\tfrac{1}{2}) = (1,2)$.\nThus, $\\partial_v \\mathbf{A}(\\tfrac{1}{2},\\tfrac{1}{2}) = -(1,0) + (1,2) = (0,2)$.\n\nNow we can compute the tangent vectors $\\partial_u \\mathbf{X}$ and $\\partial_v \\mathbf{X}$ at $(\\tfrac{1}{2},\\tfrac{1}{2})$:\n$$\n\\partial_u \\mathbf{X}(\\tfrac{1}{2},\\tfrac{1}{2}) = \\frac{(2,0)}{5/4} = (\\tfrac{8}{5}, 0)\n$$\n$$\n\\partial_v \\mathbf{X}(\\tfrac{1}{2},\\tfrac{1}{2}) = \\frac{(0,2)}{5/4} = (0, \\tfrac{8}{5})\n$$\nFinally, we compute the metric tensor components, which the problem labels as $g_{11}$, $g_{12}$, $g_{22}$ corresponding to $g_{uu}$, $g_{uv}$, $g_{vv}$:\n$$\ng_{11} = g_{uu} = \\partial_u \\mathbf{X} \\cdot \\partial_u \\mathbf{X} = (\\tfrac{8}{5}, 0) \\cdot (\\tfrac{8}{5}, 0) = (\\tfrac{8}{5})^2 = \\tfrac{64}{25}\n$$\n$$\ng_{12} = g_{uv} = \\partial_u \\mathbf{X} \\cdot \\partial_v \\mathbf{X} = (\\tfrac{8}{5}, 0) \\cdot (0, \\tfrac{8}{5}) = 0\n$$\n$$\ng_{22} = g_{vv} = \\partial_v \\mathbf{X} \\cdot \\partial_v \\mathbf{X} = (0, \\tfrac{8}{5}) \\cdot (0, \\tfrac{8}{5}) = (\\tfrac{8}{5})^2 = \\tfrac{64}{25}\n$$\n\n### Part 2: Role of the Metric Tensor in IGA\n\nThe isogeometric analysis framework is based on a mapping $\\mathbf{X}$ from a simple parametric domain $\\hat{\\Omega}$ (here, the unit square $[0,1]^2$) to the complex physical domain $\\Omega \\subset \\mathbb{R}^2$. When solving a PDE on $\\Omega$, all computations are pulled back to $\\hat{\\Omega}$. The metric coefficients $g_{\\alpha\\beta}$ are fundamental quantities that describe the local geometry of the mapping and govern the transformation of differential operators and integrals.\n\nLet the parametric coordinates be $\\boldsymbol{\\xi} = (u,v)$ and physical coordinates be $\\mathbf{x} = (x,y)$. The mapping is $\\mathbf{x} = \\mathbf{X}(\\boldsymbol{\\xi})$. The tangent vectors to the parametric coordinate lines on the surface are $\\mathbf{g}_u = \\partial_u \\mathbf{X}$ and $\\mathbf{g}_v = \\partial_v \\mathbf{X}$. These form a local basis for the tangent space at each point on the surface. The metric coefficients $g_{\\alpha\\beta} = \\mathbf{g}_\\alpha \\cdot \\mathbf{g}_\\beta$ are the inner products of these basis vectors. They populate the metric tensor (or first fundamental form) matrix:\n$$\nG = \\begin{pmatrix} g_{uu} & g_{uv} \\\\ g_{vu} & g_{vv} \\end{pmatrix} = \\begin{pmatrix} \\mathbf{g}_u \\cdot \\mathbf{g}_u & \\mathbf{g}_u \\cdot \\mathbf{g}_v \\\\ \\mathbf{g}_v \\cdot \\mathbf{g}_u & \\mathbf{g}_v \\cdot \\mathbf{g}_v \\end{pmatrix}\n$$\n\n**Transformation of the Gradient Operator:**\nThe gradient of a scalar function $\\phi(\\mathbf{x})$ in the physical domain, $\\nabla_{\\mathbf{x}} \\phi$, must be expressed in terms of derivatives in the parametric domain for computations. We work with the composite function $\\hat{\\phi}(\\boldsymbol{\\xi}) = \\phi(\\mathbf{X}(\\boldsymbol{\\xi}))$. The chain rule relates the gradients in the two domains: $\\nabla_{\\boldsymbol{\\xi}} \\hat{\\phi} = J^T \\nabla_{\\mathbf{x}} \\phi$, where $J = \\nabla_{\\boldsymbol{\\xi}} \\mathbf{X}$ is the Jacobian matrix of the transformation:\n$$\nJ = \\begin{pmatrix} \\partial_u x & \\partial_u y \\\\ \\partial_v x & \\partial_v y \\end{pmatrix} = \\begin{pmatrix} (\\mathbf{g}_u)^T \\\\ (\\mathbf{g}_v)^T \\end{pmatrix}\n$$\nTo obtain the physical gradient $\\nabla_{\\mathbf{x}}\\phi$, we invert this relationship: $\\nabla_{\\mathbf{x}} \\phi = (J^T)^{-1} \\nabla_{\\boldsymbol{\\xi}} \\hat{\\phi}$. The metric tensor is directly related to the Jacobian by $G = J J^T$. This means the inverse of the metric tensor, $G^{-1}$, is related to the inverse Jacobian needed for the gradient transformation: $G^{-1} = (J J^T)^{-1} = (J^T)^{-1} J^{-1}$. In many PDE weak forms (e.g., for the Laplacian operator $-\\Delta \\phi$), the term $\\int_\\Omega \\nabla \\phi \\cdot \\nabla \\psi \\, dA$ appears. When mapped to the parent domain, the dot product becomes $(\\nabla_{\\mathbf{x}} \\phi)^T (\\nabla_{\\mathbf{x}} \\psi) = (\\nabla_{\\boldsymbol{\\xi}} \\hat{\\phi})^T J^{-1} (J^T)^{-1} (\\nabla_{\\boldsymbol{\\xi}} \\hat{\\psi}) = (\\nabla_{\\boldsymbol{\\xi}} \\hat{\\phi})^T G^{-1} (\\nabla_{\\boldsymbol{\\xi}} \\hat{\\psi})$. Thus, the inverse metric tensor $G^{-1}$ directly mediates the transformation of the Dirichlet energy.\n\n**Transformation of Area Elements:**\nIntegrals over the physical domain $\\Omega$ are transformed into integrals over the parametric domain $\\hat{\\Omega}$. The differential area element $dA$ in the physical domain is related to the differential area element $d\\hat{A} = du\\,dv$ in the parametric domain by the determinant of the Jacobian:\n$$\ndA = |\\det(J)| \\, du \\, dv\n$$\nThe determinant of the metric tensor is $\\det(G) = \\det(JJ^T) = \\det(J)\\det(J^T) = (\\det(J))^2$. Therefore, the Jacobian determinant is the square root of the determinant of the metric tensor:\n$$\n|\\det(J)| = \\sqrt{\\det(G)} = \\sqrt{g_{uu}g_{vv} - g_{uv}^2}\n$$\nAn integral is thus transformed as:\n$$\n\\int_{\\Omega} f(\\mathbf{x}) \\, dA = \\int_{\\hat{\\Omega}} f(\\mathbf{X}(\\boldsymbol{\\xi})) \\sqrt{\\det(G)} \\, du \\, dv\n$$\nIn summary, the metric coefficients $g_{\\alpha\\beta}$ completely characterize the local distortion introduced by the mapping $\\mathbf{X}$. They are essential for recasting a PDE problem from a complex physical domain $\\Omega$ to a simple parametric domain $\\hat{\\Omega}$, by providing the rules to transform both differential operators (like the gradient) and integrals.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{64}{25} & 0 & \\frac{64}{25} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Building on the rules for transforming geometric quantities, this practice applies them to a full PDE operator using the Method of Manufactured Solutions (MMS), a cornerstone of numerical code verification. You are tasked with deriving the exact source term for the Poisson equation by transforming the physical Laplacian, $\\Delta_x$, into its equivalent representation in parametric coordinates. This derivation, which depends critically on the mapping's Jacobian matrix and metric tensor, provides essential practice in setting up and verifying PDE solvers on curved domains .",
            "id": "3411193",
            "problem": "Consider the two-dimensional Poisson equation $-\\nabla_{x}\\cdot\\nabla_{x} u = f$ on a curved physical domain $\\Omega$ obtained as the Non-Uniform Rational B-Splines (NURBS) image of the parametric square $\\hat{\\Omega} = [0,1]^{2}$ through a smooth bijective map $F:\\hat{\\Omega}\\to\\Omega$. Let the NURBS mapping be given explicitly by the bilinear (weights equal to $1$) surface\n$$F(\\xi,\\eta) = \\big(x(\\xi,\\eta),y(\\xi,\\eta)\\big) = \\big(\\xi,\\,\\eta + c\\,\\xi\\,\\eta\\big),$$\nwhere $c$ is a fixed real parameter satisfying $c>-1$ so that $1+c\\,\\xi>0$ for all $(\\xi,\\eta)\\in\\hat{\\Omega}$. Define the manufactured solution by prescribing $u$ through the pullback of a parametric function $\\hat{u}:\\hat{\\Omega}\\to\\mathbb{R}$:\n$$u(x,y) = \\hat{u}\\big(F^{-1}(x,y)\\big),\\qquad \\hat{u}(\\xi,\\eta) = \\sin(\\pi\\,\\xi)\\,\\sin(\\pi\\,\\eta).$$\nYour task is to derive the exact right-hand side $f$ appearing in the Poisson equation in physical coordinates $(x,y)$, in a form that is suitable for Galerkin error verification under isogeometric analysis with NURBS basis functions. You must start from fundamental geometric-conservation identities linking gradients under mappings and the corresponding metric tensor. In particular, use that the physical gradient is obtained from the parametric gradient by the chain rule and the Jacobian matrix $J_{F}(\\xi,\\eta)$ of $F$, and that the Laplacian can be written in terms of the parametric coordinates $(\\xi,\\eta)$ and the metric tensor $G(\\xi,\\eta) = J_{F}(\\xi,\\eta)^{\\top}\\,J_{F}(\\xi,\\eta)$.\n\nCompute $J_{F}$ and $G$, and express the physical Laplacian $\\Delta_{x} u$ in terms of $(\\xi,\\eta)$ using $G^{-1}$ and $\\det(G)$, then evaluate it for the manufactured $\\hat{u}$. Finally, express your answer entirely in physical coordinates $(x,y)$ by substituting $(\\xi,\\eta)=F^{-1}(x,y)$, where the inverse mapping is obtained from $F$. Provide the exact analytic expression for $f(x,y)$, without numerical approximation. No units are required, and no rounding is to be performed.",
            "solution": "The objective is to find the source term $f(x,y)$ in the Poisson equation $-\\Delta_{x} u = f$ given a manufactured solution $u(x,y)$. The solution $u$ is defined via a pullback of a function $\\hat{u}(\\xi,\\eta)$ on a parametric domain $\\hat{\\Omega} = [0,1]^2$ to the physical domain $\\Omega$. The mapping is $F:\\hat{\\Omega} \\to \\Omega$, given by $F(\\xi,\\eta) = (x(\\xi,\\eta), y(\\xi,\\eta)) = (\\xi, \\eta+c\\xi\\eta)$. The solution is $u(x,y) = \\hat{u}(F^{-1}(x,y))$ with $\\hat{u}(\\xi,\\eta) = \\sin(\\pi\\xi)\\sin(\\pi\\eta)$.\n\nThe task requires computing the Laplacian of $u$ in physical coordinates, $\\Delta_x u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}$. This involves expressing the physical-space partial derivative operators $(\\frac{\\partial}{\\partial x}, \\frac{\\partial}{\\partial y})$ in terms of the parametric-space operators $(\\frac{\\partial}{\\partial \\xi}, \\frac{\\partial}{\\partial \\eta})$ using the chain rule.\n\nFirst, we establish the relationship between the derivative operators. For any smooth function $g(x,y)$, its composition with $F$ gives $\\hat{g}(\\xi, \\eta) = g(F(\\xi, \\eta))$. The chain rule gives:\n$$ \\frac{\\partial \\hat{g}}{\\partial \\xi} = \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial \\xi} + \\frac{\\partial g}{\\partial y}\\frac{\\partial y}{\\partial \\xi} \\quad \\text{and} \\quad \\frac{\\partial \\hat{g}}{\\partial \\eta} = \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial \\eta} + \\frac{\\partial g}{\\partial y}\\frac{\\partial y}{\\partial \\eta} $$\nThe partial derivatives of the mapping components are:\n$$ \\frac{\\partial x}{\\partial \\xi} = 1, \\quad \\frac{\\partial x}{\\partial \\eta} = 0, \\quad \\frac{\\partial y}{\\partial \\xi} = c\\eta, \\quad \\frac{\\partial y}{\\partial \\eta} = 1+c\\xi $$\nSubstituting these into the chain rule equations:\n$$ \\frac{\\partial \\hat{g}}{\\partial \\xi} = \\frac{\\partial g}{\\partial x} + c\\eta \\frac{\\partial g}{\\partial y} $$\n$$ \\frac{\\partial \\hat{g}}{\\partial \\eta} = (1+c\\xi) \\frac{\\partial g}{\\partial y} $$\nFrom the second equation, we solve for $\\frac{\\partial g}{\\partial y}$:\n$$ \\frac{\\partial g}{\\partial y} = \\frac{1}{1+c\\xi} \\frac{\\partial \\hat{g}}{\\partial \\eta} $$\nSubstituting this into the first equation allows us to solve for $\\frac{\\partial g}{\\partial x}$:\n$$ \\frac{\\partial \\hat{g}}{\\partial \\xi} = \\frac{\\partial g}{\\partial x} + c\\eta \\left( \\frac{1}{1+c\\xi} \\frac{\\partial \\hat{g}}{\\partial \\eta} \\right) \\implies \\frac{\\partial g}{\\partial x} = \\frac{\\partial \\hat{g}}{\\partial \\xi} - \\frac{c\\eta}{1+c\\xi} \\frac{\\partial \\hat{g}}{\\partial \\eta} $$\nThese expressions define the physical derivative operators acting on functions of $(\\xi, \\eta)$:\n$$ \\frac{\\partial}{\\partial x} \\equiv D_x = D_\\xi - \\frac{c\\eta}{1+c\\xi} D_\\eta $$\n$$ \\frac{\\partial}{\\partial y} \\equiv D_y = \\frac{1}{1+c\\xi} D_\\eta $$\nwhere $D_\\xi = \\frac{\\partial}{\\partial \\xi}$ and $D_\\eta = \\frac{\\partial}{\\partial \\eta}$.\n\nNext, we compute the second partial derivatives by applying these operators twice to $u$, whose parametric representation is $\\hat{u}$.\nFor $\\frac{\\partial^2 u}{\\partial y^2}$:\n$$ \\frac{\\partial^2 u}{\\partial y^2} = D_y(D_y u) = \\left(\\frac{1}{1+c\\xi} D_\\eta\\right) \\left(\\frac{1}{1+c\\xi} D_\\eta \\hat{u}\\right) = \\frac{1}{(1+c\\xi)^2} D_\\eta^2 \\hat{u} = \\frac{1}{(1+c\\xi)^2} \\frac{\\partial^2 \\hat{u}}{\\partial \\eta^2} $$\nFor $\\frac{\\partial^2 u}{\\partial x^2}$:\n$$ \\frac{\\partial^2 u}{\\partial x^2} = D_x(D_x u) = \\left(D_\\xi - \\frac{c\\eta}{1+c\\xi} D_\\eta\\right) \\left(D_\\xi \\hat{u} - \\frac{c\\eta}{1+c\\xi} D_\\eta \\hat{u}\\right) $$\nApplying the product rule carefully, this expands to:\n$$ \\frac{\\partial^2 u}{\\partial x^2} = \\frac{\\partial^2 \\hat{u}}{\\partial \\xi^2} - \\frac{2c\\eta}{1+c\\xi}\\frac{\\partial^2 \\hat{u}}{\\partial \\xi \\partial \\eta} + \\frac{c^2\\eta^2}{(1+c\\xi)^2}\\frac{\\partial^2 \\hat{u}}{\\partial \\eta^2} + \\frac{2c^2\\eta}{(1+c\\xi)^2}\\frac{\\partial \\hat{u}}{\\partial \\eta} $$\nThe Laplacian in parametric coordinates is the sum $\\Delta_x u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}$:\n$$ \\Delta_x u = \\frac{\\partial^2 \\hat{u}}{\\partial \\xi^2} - \\frac{2c\\eta}{1+c\\xi}\\frac{\\partial^2 \\hat{u}}{\\partial \\xi \\partial \\eta} + \\frac{1+c^2\\eta^2}{(1+c\\xi)^2}\\frac{\\partial^2 \\hat{u}}{\\partial \\eta^2} + \\frac{2c^2\\eta}{(1+c\\xi)^2}\\frac{\\partial \\hat{u}}{\\partial \\eta} $$\nNow, we compute the necessary derivatives of $\\hat{u}(\\xi,\\eta) = \\sin(\\pi\\xi)\\sin(\\pi\\eta)$:\n$$ \\frac{\\partial \\hat{u}}{\\partial \\eta} = \\pi\\sin(\\pi\\xi)\\cos(\\pi\\eta) $$\n$$ \\frac{\\partial^2 \\hat{u}}{\\partial \\xi^2} = -\\pi^2\\sin(\\pi\\xi)\\sin(\\pi\\eta) = -\\pi^2\\hat{u} $$\n$$ \\frac{\\partial^2 \\hat{u}}{\\partial \\eta^2} = -\\pi^2\\sin(\\pi\\xi)\\sin(\\pi\\eta) = -\\pi^2\\hat{u} $$\n$$ \\frac{\\partial^2 \\hat{u}}{\\partial \\xi \\partial \\eta} = \\pi^2\\cos(\\pi\\xi)\\cos(\\pi\\eta) $$\nSubstituting these into the expression for $\\Delta_x u$:\n$$ \\Delta_x u = -\\pi^2\\hat{u} - \\frac{2c\\eta}{1+c\\xi}(\\pi^2\\cos(\\pi\\xi)\\cos(\\pi\\eta)) + \\frac{1+c^2\\eta^2}{(1+c\\xi)^2}(-\\pi^2\\hat{u}) + \\frac{2c^2\\eta}{(1+c\\xi)^2}(\\pi\\sin(\\pi\\xi)\\cos(\\pi\\eta)) $$\nWe can group terms:\n$$ \\Delta_x u = -\\pi^2\\hat{u} \\left(1 + \\frac{1+c^2\\eta^2}{(1+c\\xi)^2}\\right) - \\frac{2c\\eta\\pi^2}{1+c\\xi}\\cos(\\pi\\xi)\\cos(\\pi\\eta) + \\frac{2c^2\\eta\\pi}{(1+c\\xi)^2}\\sin(\\pi\\xi)\\cos(\\pi\\eta) $$\nThe final step is to express this result in physical coordinates $(x,y)$. We need the inverse mapping $F^{-1}(x,y)=(\\xi,\\eta)$.\nFrom $x=\\xi$ and $y=\\eta(1+c\\xi)$, we find:\n$$ \\xi = x \\quad \\text{and} \\quad \\eta = \\frac{y}{1+cx} $$\nSubstituting these into the expression for $\\Delta_x u$:\n$$ \\Delta_x u(x,y) = -\\pi^2 \\sin(\\pi x)\\sin\\left(\\frac{\\pi y}{1+cx}\\right) \\left(1 + \\frac{1+c^2\\left(\\frac{y}{1+cx}\\right)^2}{(1+cx)^2}\\right) - \\frac{2c\\left(\\frac{y}{1+cx}\\right)\\pi^2}{1+cx}\\cos(\\pi x)\\cos\\left(\\frac{\\pi y}{1+cx}\\right) + \\frac{2c^2\\left(\\frac{y}{1+cx}\\right)\\pi}{(1+cx)^2}\\sin(\\pi x)\\cos\\left(\\frac{\\pi y}{1+cx}\\right) $$\nSimplifying the coefficients:\n$$ 1 + \\frac{1+c^2\\frac{y^2}{(1+cx)^2}}{(1+cx)^2} = \\frac{(1+cx)^2 + 1 + \\frac{c^2y^2}{(1+cx)^2}}{(1+cx)^2} = \\frac{(1+cx)^4 + (1+cx)^2 + c^2y^2}{(1+cx)^4} $$\n$$ \\frac{2c\\left(\\frac{y}{1+cx}\\right)\\pi^2}{1+cx} = \\frac{2c\\pi^2 y}{(1+cx)^2} $$\n$$ \\frac{2c^2\\left(\\frac{y}{1+cx}\\right)\\pi}{(1+cx)^2} = \\frac{2c^2\\pi y}{(1+cx)^3} $$\nPutting it all together:\n$$ \\Delta_x u(x,y) = -\\pi^2 \\sin(\\pi x)\\sin\\left(\\frac{\\pi y}{1+cx}\\right)\\frac{(1+cx)^4+(1+cx)^2+c^2y^2}{(1+cx)^4} - \\frac{2c\\pi^2 y}{(1+cx)^2}\\cos(\\pi x)\\cos\\left(\\frac{\\pi y}{1+cx}\\right) + \\frac{2c^2\\pi y}{(1+cx)^3}\\sin(\\pi x)\\cos\\left(\\frac{\\pi y}{1+cx}\\right) $$\nThe source term is $f(x,y) = -\\Delta_x u(x,y)$.\n$$ f(x,y) = \\pi^2 \\sin(\\pi x)\\sin\\left(\\frac{\\pi y}{1+cx}\\right)\\frac{(1+cx)^4+(1+cx)^2+c^2y^2}{(1+cx)^4} + \\frac{2c\\pi y}{(1+cx)^3} \\cos\\left(\\frac{\\pi y}{1+cx}\\right) \\left(\\pi(1+cx)\\cos(\\pi x) - c\\sin(\\pi x)\\right) $$",
            "answer": "$$\\boxed{\\pi^2 \\sin(\\pi x)\\sin\\left(\\frac{\\pi y}{1+cx}\\right) \\frac{(1+cx)^4+(1+cx)^2+c^2y^2}{(1+cx)^4} + \\frac{2c\\pi y}{(1+cx)^3} \\cos\\left(\\frac{\\pi y}{1+cx}\\right) \\left( \\pi(1+cx)\\cos(\\pi x) - c\\sin(\\pi x) \\right)}$$"
        },
        {
            "introduction": "A core computational task in any finite element-based method is the evaluation of integrals to form the stiffness matrix and load vector. This hands-on coding exercise guides you through implementing numerical quadrature over a NURBS-defined surface, translating theory into practice. You will see how the Jacobian determinant, $|\\det J|$, which measures the local change in area, functions as a dynamic weight within the Gaussian quadrature rule, directly linking the domain's curvature to the final computed values .",
            "id": "3411147",
            "problem": "You are tasked with implementing element-wise numerical integration over a surface patch parameterized by Non-Uniform Rational B-Splines (NURBS). Starting from the pullback of area integrals through a differentiable mapping, derive and implement a program that computes the surface integral of a constant scalar field using Gaussian quadrature and explicitly quantifies how curvature affects quadrature weights via the Jacobian determinant. Your implementation must use a single tensor-product NURBS surface with a quadratic basis in the angular direction and a linear basis in the radial direction, and it must treat the mapping from the parametric square to the physical plane exactly according to the differentiable mapping rules.\n\nFundamental base:\n- A surface patch is defined by a smooth mapping $S : [0,1]^2 \\to \\mathbb{R}^2$, where $(u,v) \\in [0,1]^2$ are parametric coordinates and $(x,y) = S(u,v)$ are physical coordinates.\n- The change-of-variables formula for surface area integrals states that, for a scalar field $f(x,y)$,\n$$\n\\int_{\\Omega} f(x,y) \\, dA = \\int_{[0,1]^2} f(S(u,v)) \\, |\\det J(u,v)| \\, du \\, dv,\n$$\nwhere $J(u,v)$ is the Jacobian matrix of partial derivatives of $S$ with respect to $(u,v)$ and $|\\det J(u,v)|$ is the absolute value of its determinant.\n- Non-Uniform Rational B-Splines (NURBS) surfaces are constructed from tensor-product rational basis functions. For degrees $p$ in $u$ and $q$ in $v$, define polynomial B-Spline basis functions $N_i(u)$ and $M_j(v)$ for $i=0,\\dots,p$ and $j=0,\\dots,q$, and positive weights $w_{ij}$. The rational basis functions are\n$$\nR_{ij}(u,v) = \\frac{N_i(u) M_j(v) w_{ij}}{W(u,v)}, \\quad W(u,v) = \\sum_{a=0}^{p}\\sum_{b=0}^{q} N_a(u) M_b(v) w_{ab}.\n$$\nThe surface mapping is then\n$$\nS(u,v) = \\sum_{i=0}^{p}\\sum_{j=0}^{q} R_{ij}(u,v) \\, P_{ij},\n$$\nwhere $P_{ij} \\in \\mathbb{R}^2$ are the control points.\n- Gaussian quadrature approximates integrals by a weighted sum of function evaluations at specific nodes. For each parametric direction, use $n_u$ and $n_v$ nodes with weights, and form the tensor-product quadrature for $[0,1]^2$.\n\nRequirements:\n1. Construct a single tensor-product NURBS surface with quadratic basis in the $u$-direction ($p=2$) and linear basis in the $v$-direction ($q=1$). Use clamped knot vectors corresponding to a single element, so the polynomial basis reduces to Bernstein polynomials over $[0,1]$:\n   - In the $u$-direction, use the quadratic Bernstein polynomials on $[0,1]$: $N_0(u)$, $N_1(u)$, $N_2(u)$.\n   - In the $v$-direction, use the linear Bernstein polynomials on $[0,1]$: $M_0(v)$, $M_1(v)$.\n   Provide a consistent definition of their first derivatives with respect to $u$ and $v$.\n2. Define a quarter-annulus geometry in the plane by a tensor-product of a circular arc and a radial segment. The $u$-direction corresponds to the angular coordinate from $0$ to $\\pi/2$, and the $v$-direction corresponds to the radial coordinate. Use a $3 \\times 2$ grid of control points:\n   - For each radius $r \\in \\{r_{\\mathrm{in}}, r_{\\mathrm{out}}\\}$, set\n     $P_{0,\\cdot}(r) = (r, 0)$,\n     $P_{1,\\cdot}(r) = (r, r)$,\n     $P_{2,\\cdot}(r) = (0, r)$,\n     where the $\\cdot$ indicates the two radial positions $r=r_{\\mathrm{in}}$ and $r=r_{\\mathrm{out}}$.\n   - For rational weights along the circular arc, use $(w_{0,\\cdot}, w_{1,\\cdot}, w_{2,\\cdot}) = \\left(1, \\frac{1}{\\sqrt{2}}, 1\\right)$, repeated for both radial positions. This exactly represents a circular arc in the $u$-direction.\n3. Compute the Jacobian matrix $J(u,v)$ via the first derivatives of $S(u,v)$ with respect to $u$ and $v$, obtained from the rational basis and the control points.\n4. Implement tensor-product Gaussian quadrature with $n_u = 5$ nodes in $u$ and $n_v = 5$ nodes in $v$, mapped from $[-1,1]$ to $[0,1]$, and use these to approximate the integral of the constant scalar field $f(x,y)=1$ over the physical surface.\n5. Quantify the effect of curved geometry on quadrature weights by computing the extremal values of $|\\det J(u,v)|$ over all quadrature nodes.\n6. Implement the following test suite of parameter sets, and for each test case compute:\n   - The approximate area $A \\approx \\sum w_u w_v |\\det J(u,v)|$.\n   - The minimum and maximum of $|\\det J(u,v)|$ across all quadrature points.\n   Use these cases:\n   - Case 1 (Happy path, rational circular annulus): $r_{\\mathrm{in}} = 1.0$, $r_{\\mathrm{out}} = 2.0$, weights $(1, 1/\\sqrt{2}, 1)$.\n   - Case 2 (Polynomial, non-rational geometry): $r_{\\mathrm{in}} = 1.0$, $r_{\\mathrm{out}} = 2.0$, weights $(1, 1, 1)$.\n   - Case 3 (Boundary case, degenerate annulus): $r_{\\mathrm{in}} = 1.5$, $r_{\\mathrm{out}} = 1.5$, weights $(1, 1/\\sqrt{2}, 1)$.\n7. Final output format: Your program should produce a single line of output containing a comma-separated list of three sublists, each sublist corresponding to one test case in order, and containing three floating-point numbers $[A, \\min|\\det J|, \\max|\\det J|]$. For example: \"[[A1,min1,max1],[A2,min2,max2],[A3,min3,max3]]\". Express all numbers as unitless floats.\n\nYour program must be self-contained and runnable as is, taking no input, and it must adhere to the specified execution environment and libraries.",
            "solution": "The solution proceeds by first deriving the necessary mathematical formulations for the NURBS surface and its derivatives, and then implementing a numerical algorithm to compute the required quantities.\n\n**1. NURBS Surface Parameterization and Basis Functions**\n\nA NURBS surface is defined by a mapping $S(u,v)$ from a parametric domain, here chosen as the unit square $[0,1]^2$, to the physical domain in $\\mathbb{R}^2$. The mapping is a rational function given by:\n$$ S(u,v) = \\frac{\\sum_{i=0}^{p}\\sum_{j=0}^{q} N_i(u) M_j(v) w_{ij} P_{ij}}{\\sum_{a=0}^{p}\\sum_{b=0}^{q} N_a(u) M_b(v) w_{ab}} $$\nwhere $P_{ij} \\in \\mathbb{R}^2$ are the control points, $w_{ij} > 0$ are their associated weights, and $N_i(u)$ and $M_j(v)$ are the B-spline basis functions of degree $p$ and $q$, respectively.\n\nFor this problem, a single patch is considered using clamped knot vectors, which simplifies the B-spline basis functions to Bernstein polynomials.\nThe degrees are specified as $p=2$ (quadratic) in the $u$-direction and $q=1$ (linear) in the $v$-direction.\n\nThe basis functions and their first derivatives are:\n- In the $u$-direction (quadratic Bernstein polynomials on $[0,1]$):\n  - $N_0(u) = (1-u)^2$\n  - $N_1(u) = 2u(1-u)$\n  - $N_2(u) = u^2$\n  - $N_0'(u) = -2(1-u)$\n  - $N_1'(u) = 2 - 4u$\n  - $N_2'(u) = 2u$\n\n- In the $v$-direction (linear Bernstein polynomials on $[0,1]$):\n  - $M_0(v) = 1-v$\n  - $M_1(v) = v$\n  - $M_0'(v) = -1$\n  - $M_1'(v) = 1$\n\n**2. Surface Derivatives and the Jacobian Matrix**\n\nTo compute the surface area, we require the Jacobian of the mapping $S(u,v)$. Let us define the vector-valued numerator and scalar-valued denominator of $S(u,v)$ as:\n$$ \\mathbf{A}(u,v) = \\sum_{i=0}^{2}\\sum_{j=0}^{1} N_i(u) M_j(v) w_{ij} P_{ij} $$\n$$ W(u,v) = \\sum_{i=0}^{2}\\sum_{j=0}^{1} N_i(u) M_j(v) w_{ij} $$\nThe partial derivatives of the surface mapping $S(u,v) = \\mathbf{A}(u,v) / W(u,v)$ are found using the quotient rule:\n$$ \\frac{\\partial S}{\\partial u} = \\frac{1}{W^2} \\left( W \\frac{\\partial \\mathbf{A}}{\\partial u} - \\mathbf{A} \\frac{\\partial W}{\\partial u} \\right) \\quad \\text{and} \\quad \\frac{\\partial S}{\\partial v} = \\frac{1}{W^2} \\left( W \\frac{\\partial \\mathbf{A}}{\\partial v} - \\mathbf{A} \\frac{\\partial W}{\\partial v} \\right) $$\nThe derivatives of $\\mathbf{A}(u,v)$ and $W(u,v)$ are found by differentiating their respective sums term-by-term:\n$$ \\frac{\\partial \\mathbf{A}}{\\partial u} = \\sum_{i=0}^{2}\\sum_{j=0}^{1} N_i'(u) M_j(v) w_{ij} P_{ij} \\quad \\text{and} \\quad \\frac{\\partial W}{\\partial u} = \\sum_{i=0}^{2}\\sum_{j=0}^{1} N_i'(u) M_j(v) w_{ij} $$\n$$ \\frac{\\partial \\mathbf{A}}{\\partial v} = \\sum_{i=0}^{2}\\sum_{j=0}^{1} N_i(u) M_j'(v) w_{ij} P_{ij} \\quad \\text{and} \\quad \\frac{\\partial W}{\\partial v} = \\sum_{i=0}^{2}\\sum_{j=0}^{1} N_i(u) M_j'(v) w_{ij} $$\nThe Jacobian matrix $J(u,v)$ is formed by the partial derivative vectors, which are tangent to the surface along the parametric grid lines:\n$$ J(u,v) = \\begin{bmatrix} \\frac{\\partial S_x}{\\partial u} & \\frac{\\partial S_x}{\\partial v} \\\\ \\frac{\\partial S_y}{\\partial u} & \\frac{\\partial S_y}{\\partial v} \\end{bmatrix} $$\nThe absolute value of its determinant, $|\\det J(u,v)|$, is the local area scaling factor between the parametric and physical domains.\n\n**3. Numerical Integration via Gaussian Quadrature**\n\nThe area of the surface patch, which is the integral of the constant scalar field $f(x,y)=1$, is computed by a change of variables to the parametric domain:\n$$ \\mathrm{Area} = \\int_{\\Omega} 1 \\, dA = \\int_{0}^{1}\\int_{0}^{1} |\\det J(u,v)| \\, du \\, dv $$\nThis two-dimensional integral is approximated numerically using a tensor-product Gauss-Legendre quadrature rule. For the specified $n_u = 5$ nodes in $u$ and $n_v = 5$ nodes in $v$, we first obtain the standard quadrature points $\\{\\xi_k\\}$ and weights $\\{\\omega_k\\}$ for the interval $[-1,1]$. These are mapped to the integration interval $[0,1]$ via the affine transformation $u_k = (\\xi_k + 1)/2$. The corresponding quadrature weights must be scaled by the Jacobian of this transformation, which is $1/2$. Thus, the weights for the $[0,1]$ interval are $w_{u_k} = \\omega_k/2$. The area is then approximated by the discrete sum:\n$$ \\mathrm{Area} \\approx \\sum_{k=1}^{n_u} \\sum_{l=1}^{n_v} w_{u_k} w_{v_l} |\\det J(u_k, v_l)| $$\nwhere $(u_k, v_l)$ are the mapped quadrature points.\n\n**4. Algorithmic Implementation**\n\nThe overall algorithm is implemented in the following Python program, which is executed for all specified test cases to generate the final results. The variation in $|\\det J|$ across the quadrature points provides a quantitative measure of the geometric distortion introduced by the NURBS mapping.\n\n```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the area and Jacobian determinant statistics for NURBS surfaces.\n    \"\"\"\n    # Test cases: (r_in, r_out, weights_u)\n    test_cases = [\n        (1.0, 2.0, np.array([1.0, 1.0 / np.sqrt(2.0), 1.0])),\n        (1.0, 2.0, np.array([1.0, 1.0, 1.0])),\n        (1.5, 1.5, np.array([1.0, 1.0 / np.sqrt(2.0), 1.0])),\n    ]\n\n    # Gaussian quadrature parameters for a 5-point rule\n    n_points = 5\n    gauss_points, gauss_weights = np.polynomial.legendre.leggauss(n_points)\n\n    # Map nodes and weights from [-1, 1] to [0, 1]\n    q_points = 0.5 * (gauss_points + 1)\n    q_weights = 0.5 * gauss_weights\n\n    # --- Basis Functions and their Derivatives ---\n    # Quadratic Bernstein polynomials for u in [0,1]\n    N_funcs = [\n        lambda u: (1 - u)**2,\n        lambda u: 2 * u * (1 - u),\n        lambda u: u**2\n    ]\n    # Derivatives of quadratic Bernstein polynomials\n    dN_du_funcs = [\n        lambda u: -2 * (1 - u),\n        lambda u: 2 - 4 * u,\n        lambda u: 2 * u\n    ]\n    # Linear Bernstein polynomials for v in [0,1]\n    M_funcs = [\n        lambda v: 1 - v,\n        lambda v: v\n    ]\n    # Derivatives of linear Bernstein polynomials\n    dM_dv_funcs = [\n        lambda v: -1.0,\n        lambda v: 1.0\n    ]\n\n    results = []\n    for r_in, r_out, weights_u in test_cases:\n        # --- Define Geometry: Control Points and Weights ---\n        # Control points P[i, j, coord] for a 3x2 grid\n        P = np.zeros((3, 2, 2))\n        radii = [r_in, r_out]\n        \n        for j in range(2): # 0 for r_in, 1 for r_out\n            r = radii[j]\n            P[0, j, :] = [r, 0.0]\n            P[1, j, :] = [r, r] # Corrected control point\n            P[2, j, :] = [0.0, r]\n\n        # Weights w[i, j] for a 3x2 grid\n        weights = np.zeros((3, 2))\n        weights[:, 0] = weights_u\n        weights[:, 1] = weights_u\n\n        # --- Numerical Integration ---\n        total_area = 0.0\n        det_J_values = []\n\n        for k in range(n_points):\n            u = q_points[k]\n            wu = q_weights[k]\n            \n            # Evaluate u-basis functions and derivatives\n            N_vals = np.array([f(u) for f in N_funcs])\n            dN_du_vals = np.array([f(u) for f in dN_du_funcs])\n\n            for l in range(n_points):\n                v = q_points[l]\n                wv = q_weights[l]\n\n                # Evaluate v-basis functions and derivatives\n                M_vals = np.array([f(v) for f in M_funcs])\n                dM_dv_vals = np.array([f(v) for f in dM_dv_funcs])\n\n                # --- Calculate S(u,v) derivatives using the quotient rule ---\n                # S(u,v) = A(u,v) / W(u,v)\n                \n                # W and its derivatives\n                W_ij = np.outer(N_vals, M_vals) * weights\n                W = np.sum(W_ij)\n                \n                dW_du_ij = np.outer(dN_du_vals, M_vals) * weights\n                dW_du = np.sum(dW_du_ij)\n\n                dW_dv_ij = np.outer(N_vals, dM_dv_vals) * weights\n                dW_dv = np.sum(dW_dv_ij)\n\n                # A and its derivatives (A is a 2D vector)\n                A = np.einsum('ij,ijk->k', W_ij, P)\n                dA_du = np.einsum('ij,ijk->k', dW_du_ij, P)\n                dA_dv = np.einsum('ij,ijk->k', dW_dv_ij, P)\n\n                # Apply quotient rule for dS/du and dS/dv\n                dS_du = (dA_du * W - A * dW_du) / (W**2)\n                dS_dv = (dA_dv * W - A * dW_dv) / (W**2)\n                \n                # Jacobian determinant\n                det_J = dS_du[0] * dS_dv[1] - dS_du[1] * dS_dv[0]\n                abs_det_J = np.abs(det_J)\n                \n                det_J_values.append(abs_det_J)\n                total_area += wu * wv * abs_det_J\n\n        min_det_J = np.min(det_J_values)\n        max_det_J = np.max(det_J_values)\n        \n        results.append([total_area, min_det_J, max_det_J])\n\n    # Format the final output string exactly as required\n    output_str = \"[\"\n    for i, res in enumerate(results):\n        output_str += f\"[{res[0]},{res[1]},{res[2]}]\"\n        if i  len(results) - 1:\n            output_str += \",\"\n    output_str += \"]\"\n    print(output_str)\n\n# To get the answer, one would run solve()\n```",
            "answer": "`[[2.3561944901923444,1.5707963267948966,3.141592653589793],[2.25,1.5,3.0],[0.0,0.0,0.0]]`"
        }
    ]
}