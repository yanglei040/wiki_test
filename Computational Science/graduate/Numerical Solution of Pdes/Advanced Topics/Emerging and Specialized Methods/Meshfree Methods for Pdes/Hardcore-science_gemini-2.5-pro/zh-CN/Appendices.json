{
    "hands_on_practices": [
        {
            "introduction": "在无网格方法中，节点集的质量直接影响近似的准确性和稳定性。与传统网格不同，我们使用填充距离（$h_{X,\\Omega}$）和分离距离（$q_X$）等度量来描述节点分布的特性。这个练习将带你亲手计算这些基本的几何参数，从而理解它们是如何量化一个节点集的“均匀性”的，这是无网格方法收敛性分析的基石。",
            "id": "3420013",
            "problem": "考虑二维域 $\\Omega = [0,1]\\times[0,1] \\subset \\mathbb{R}^{2}$ 以及由张量积网格给出的节点集 $X \\subset \\Omega$\n$$\nX = \\left\\{ \\left(\\frac{i}{4}, \\frac{j}{4}\\right) : i,j \\in \\{0,1,2,3,4\\} \\right\\}.\n$$\n在 $\\mathbb{R}^{2}$ 上采用欧几里得范数 $|\\cdot|$。使用无网格近似中的标准定义，\n$$\nh_{X,\\Omega} = \\sup_{x \\in \\Omega} \\min_{x_{i} \\in X} |x - x_{i}|, \\qquad q_{X} = \\frac{1}{2} \\min_{\\substack{x_{i}, x_{j} \\in X \\\\ i \\neq j}} |x_{i} - x_{j}|,\n$$\n从第一性原理计算 $h_{X,\\Omega}$ 和 $q_{X}$，然后通过估计比值 $\\rho = \\dfrac{h_{X,\\Omega}}{q_{X}}$ 来评估 $X$ 是否是准一致的。为在 $\\Omega$ 中达到 $h_{X,\\Omega}$ 定义中上确界的点的位置，以及为在 $X$ 中达到 $q_{X}$ 定义中最小值的点对提供清晰的几何论证。将最终答案表示为精确的符号表达式 $\\rho$，不要四舍五入。",
            "solution": "对问题陈述的有效性进行评估。\n\n**步骤1：提取已知条件**\n-   域：$\\Omega = [0,1]\\times[0,1] \\subset \\mathbb{R}^{2}$\n-   节点集：$X = \\left\\{ \\left(\\frac{i}{4}, \\frac{j}{4}\\right) : i,j \\in \\{0,1,2,3,4\\} \\right\\}$\n-   范数：$\\mathbb{R}^{2}$ 上的欧几里得范数 $|\\cdot|$\n-   填充距离（或网格尺寸）：$h_{X,\\Omega} = \\sup_{x \\in \\Omega} \\min_{x_{i} \\in X} |x - x_{i}|$\n-   分离距离：$q_{X} = \\frac{1}{2} \\min_{\\substack{x_{i}, x_{j} \\in X \\\\ i \\neq j}} |x_{i} - x_{j}|$\n-   目标：计算 $h_{X,\\Omega}$、$q_{X}$ 以及准一致性常数 $\\rho = \\dfrac{h_{X,\\Omega}}{q_{X}}$。\n\n**步骤2：使用提取的已知条件进行验证**\n-   **科学依据：** 该问题使用了数值分析和求解偏微分方程的无网格方法领域中的标准、成熟的定义。填充距离和分离距离的概念是此类方法收敛性分析的基础。\n-   **适定性：** 域 $\\Omega$ 是一个紧集，节点集 $X$ 是一组有限的点。函数 $f(x) = \\min_{x_i \\in X} |x - x_i|$ 是紧域 $\\Omega$ 上的一个连续函数，因此其上确界存在且可达到（根据极值定理）。$q_X$ 定义中的最小值是在一个有限的、非空的正值集合上取的，因此它也是适定的。问题是无歧义的，并允许有唯一的解。\n-   **客观性：** 问题以精确的数学语言陈述，没有主观或含糊的术语。\n\n**步骤3：结论与行动**\n问题是有效的。将提供完整解答。\n\n**解答**\n\n分析过程是通过根据定义和给定的节点集 $X$ 计算 $q_X$ 和 $h_{X,\\Omega}$ 这两个量。\n\n**1. 分离距离 $q_X$ 的计算**\n\n分离距离 $q_X$ 定义为节点集 $X$ 中任意两个不同节点之间最小距离的一半：\n$$\nq_{X} = \\frac{1}{2} \\min_{\\substack{x_{i}, x_{j} \\in X \\\\ i \\neq j}} |x_{i} - x_{j}|\n$$\n$X$ 中的节点由 $x_{i,j} = \\left(\\frac{i}{4}, \\frac{j}{4}\\right)$ 给出，其中 $i,j \\in \\{0,1,2,3,4\\}$。让我们考虑两个不同的节点 $x_{i,j}$ 和 $x_{k,l}$，其中 $(i,j) \\neq (k,l)$。它们之间欧几里得距离的平方是：\n$$\n|x_{i,j} - x_{k,l}|^2 = \\left(\\frac{i}{4} - \\frac{k}{4}\\right)^2 + \\left(\\frac{j}{4} - \\frac{l}{4}\\right)^2 = \\frac{1}{16} \\left( (i-k)^2 + (j-l)^2 \\right)\n$$\n要找到最小距离，我们必须找到项 $(i-k)^2 + (j-l)^2$ 的最小非零值，其中 $i, j, k, l$ 是来自集合 $\\{0,1,2,3,4\\}$ 的整数。因为 $(i,j) \\neq (k,l)$，所以项 $(i-k)^2 + (j-l)^2$ 必须是一个正整数。可以由两个平方和构成的最小正整数是 $1$，这发生在 $|i-k|$ 或 $|j-l|$ 中一个为 $1$ 而另一个为 $0$ 时。\n\n例如，考虑两个水平相邻的点，如 $x_{0,0}=(0,0)$ 和 $x_{1,0}=(1/4, 0)$。这里，$i=0, j=0, k=1, l=0$。距离为：\n$$\n|x_{0,0} - x_{1,0}| = \\sqrt{\\frac{1}{16} \\left( (0-1)^2 + (0-0)^2 \\right)} = \\sqrt{\\frac{1}{16}} = \\frac{1}{4}\n$$\n这个距离 $1/4$ 是网格间距。任何其他非相邻点对，例如对角相邻的点，如 $x_{0,0}=(0,0)$ 和 $x_{1,1}=(1/4, 1/4)$，它们之间的距离会更远：\n$$\n|x_{0,0} - x_{1,1}| = \\sqrt{\\frac{1}{16} \\left( (0-1)^2 + (0-1)^2 \\right)} = \\sqrt{\\frac{2}{16}} = \\frac{\\sqrt{2}}{4}\n$$\n因为 $\\frac{1}{4}  \\frac{\\sqrt{2}}{4}$，所以最小距离确实是 $1/4$。这个最小值在网格中任意两个水平或垂直相邻的节点之间达到。\n$$\n\\min_{\\substack{x_{i}, x_{j} \\in X \\\\ i \\neq j}} |x_{i} - x_{j}| = \\frac{1}{4}\n$$\n因此，分离距离为：\n$$\nq_X = \\frac{1}{2} \\left(\\frac{1}{4}\\right) = \\frac{1}{8}\n$$\n\n**2. 填充距离 $h_{X,\\Omega}$ 的计算**\n\n填充距离 $h_{X, \\Omega}$ 是域 $\\Omega$ 中任意一点到 $X$ 中最近节点的最大距离。\n$$\nh_{X,\\Omega} = \\sup_{x \\in \\Omega} \\min_{x_{i} \\in X} |x - x_{i}|\n$$\n节点集 $X$ 形成一个均匀的 $5 \\times 5$ 网格，包括域 $\\Omega=[0,1]\\times[0,1]$ 的边界。这个网格将域 $\\Omega$ 分割成一个由 $4 \\times 4$ 个更小的、不重叠的正方形组成的阵列。每个小正方形的边长为 $1/4$。让我们将这样一个通用的小正方形表示为：\n$$\nS_{i,j} = \\left[ \\frac{i}{4}, \\frac{i+1}{4} \\right] \\times \\left[ \\frac{j}{4}, \\frac{j+1}{4} \\right] \\quad \\text{对于 } i,j \\in \\{0,1,2,3\\}\n$$\n每个正方形 $S_{i,j}$ 的顶点都是节点集 $X$ 中的点。具体来说，$S_{i,j}$ 的顶点是 $x_{i,j}$、$x_{i+1,j}$、$x_{i,j+1}$ 和 $x_{i+1,j+1}$。\n\n对于 $S_{i,j}$ 中的任意点 $x$，整个集合 $X$ 中最近的节点必定是 $S_{i,j}$ 的四个顶点之一。这是因为 $X$ 中的任何其他节点都比这四个顶点中的至少一个更远。因此，在 $\\Omega$ 上寻找全局上确界的问题可以简化为在每个小正方形 $S_{i,j}$ 上寻找局部上确界的最大值：\n$$\nh_{X,\\Omega} = \\max_{i,j \\in \\{0,1,2,3\\}} \\left( \\sup_{x \\in S_{i,j}} \\min_{v \\in \\{x_{i,j}, x_{i+1,j}, x_{i,j+1}, x_{i+1,j+1}\\}} |x - v| \\right)\n$$\n在单个正方形 $S_{i,j}$ 内，距离其所有四个顶点最远的点，根据对称性，是其几何中心。设这个中心为 $x^*_{i,j}$。\n$$\nx^*_{i,j} = \\left( \\frac{i}{4} + \\frac{1}{8}, \\frac{j}{4} + \\frac{1}{8} \\right) = \\left( \\frac{2i+1}{8}, \\frac{2j+1}{8} \\right)\n$$\n这个中心点 $x^*_{i,j}$ 到四个顶点的任意一个的距离都是相同的。让我们计算到顶点 $x_{i,j} = (\\frac{i}{4}, \\frac{j}{4})$ 的距离：\n$$\n|x^*_{i,j} - x_{i,j}| = \\left| \\left( \\frac{2i+1}{8} - \\frac{2i}{8}, \\frac{2j+1}{8} - \\frac{2j}{8} \\right) \\right| = \\left| \\left( \\frac{1}{8}, \\frac{1}{8} \\right) \\right| = \\sqrt{\\left(\\frac{1}{8}\\right)^2 + \\left(\\frac{1}{8}\\right)^2} = \\sqrt{\\frac{1}{64} + \\frac{1}{64}} = \\sqrt{\\frac{2}{64}} = \\frac{\\sqrt{2}}{8}\n$$\n这个距离代表了正方形 $S_{i,j}$ 内部的最大“最小距离”。由于对于构成 $\\Omega$ 的所有16个小正方形，这个值 $\\frac{\\sqrt{2}}{8}$ 都是相同的，因此整个域上的上确界必定是这个值。在 $\\Omega$ 中达到这个上确界的点是这16个正方形的中心。\n因此，填充距离为：\n$$\nh_{X,\\Omega} = \\frac{\\sqrt{2}}{8}\n$$\n\n**3. 比值 $\\rho$ 的计算与评估**\n\n准一致性常数 $\\rho$ 是填充距离与分离距离的比值：\n$$\n\\rho = \\frac{h_{X,\\Omega}}{q_{X}}\n$$\n代入计算出的值：\n$$\n\\rho = \\frac{\\frac{\\sqrt{2}}{8}}{\\frac{1}{8}} = \\sqrt{2}\n$$\n如果比值 $\\rho$ 被一个与点的数量或它们之间的特征间距无关的常数所界定，那么点集 $X$ 被认为是准一致的。在这种情况下，$\\rho = \\sqrt{2}$，这是一个小的常数。这表明节点集 $X$ 确实是准一致的。值 $\\sqrt{2}$ 是均匀正方形网格的特征值。",
            "answer": "$$\\boxed{\\sqrt{2}}$$"
        },
        {
            "introduction": "移动最小二乘（MLS）近似是许多无网格方法的核心，它能从离散的节点数据构建出光滑的形函数。本练习将深入探讨 MLS 的计算细节，要求你构建矩量矩阵并计算形函数的导数，这是求解偏微分方程的关键步骤。通过这个实践，你将掌握将离散信息转化为连续近似的核心技术。",
            "id": "3420003",
            "problem": "考虑在一维空间中使用无网格方法数值求解偏微分方程的移动最小二乘 (MLS) 近似。使用线性多项式基函数 $p(x) = [1, x]^{\\top}$ 和高斯权重函数 $w(r) = \\exp\\!\\big(- (r / \\delta)^{2}\\big)$，形状参数 $\\delta = 0.6$。三个节点位于位置 $x_1 = 0$、$x_2 = 0.5$ 和 $x_3 = 1$，评估点为 $x_0 = 0.5$。设测试函数为光滑函数 $u(x) = \\exp(x)$。\n\n从 MLS 的最小二乘泛函和法方程出发，推导在点 $x_0$ 处的 MLS 形函数 $N_i(x_0)$（$i \\in \\{1,2,3\\}$），并用 $x_0$ 处的高斯权重显式表示。然后，利用 MLS 形函数导数的定义，计算在 $x_0$ 处的空间梯度（在一维情况下即为一阶导数）的 MLS 近似值：\n$$\nu_x^{h}(x_0) \\;=\\; \\sum_{i=1}^{3} N_i'(x_0)\\,u(x_i).\n$$\n所有中间步骤必须遵循 MLS 构建的第一性原理，包括矩量矩阵的形成、其逆矩阵的计算，以及 MLS 形函数在 $x_0$ 点对 $x$ 的微分。\n\n将 $u_x^{h}(x_0)$ 的最终答案表示为单个精确的解析表达式（不要小数化）。无需单位，也无需四舍五入。",
            "solution": "用户要求我解决一个关于移动最小二乘 (MLS) 近似的问题。我的计划如下：\n1.  **问题验证：**\n    *   **第1步：提取已知条件：** 我将列出所有给定的信息：多项式基、权重函数、形状参数、节点位置、评估点和测试函数。\n    *   **第2步：验证：** 我将检查问题是否具有科学依据、是否适定、客观和完整。这似乎是一个标准的数值方法问题。\n    *   **第3步：结论：** 问题似乎是有效的。我将继续进行解答。\n\n2.  **解答推导：**\n    *   **第1部分：MLS 形函数 $N_i(x_0)$**\n        *   MLS 近似 $u^h(x_0)$ 由 $u^h(x_0) = \\mathbf{p}^{\\top}(x_0) \\mathbf{a}(x_0)$ 给出。\n        *   系数 $\\mathbf{a}(x_0)$ 通过最小化加权最小二乘泛函来找到。\n        *   法方程给出 $\\mathbf{a}(x_0) = \\mathbf{M}^{-1}(x_0) \\mathbf{B}(x_0) \\mathbf{u}$。\n        *   因此，形函数由 $\\mathbf{N}(x_0) = \\mathbf{p}^{\\top}(x_0) \\mathbf{M}^{-1}(x_0) \\mathbf{B}(x_0)$ 给出。\n        *   我将明确计算矩量矩阵 $\\mathbf{M}(x_0)$、其逆矩阵 $\\mathbf{M}^{-1}(x_0)$，然后计算形函数 $N_i(x_0)$。\n\n    *   **第2部分：形函数的导数 $N_i'(x_0)$**\n        *   形函数的公式为 $N_i(x) = w(x-x_i) \\mathbf{p}^{\\top}(x) \\mathbf{M}^{-1}(x) \\mathbf{p}(x_i)$。\n        *   我将使用乘法法则计算 $\\frac{d N_i}{dx}$ 并在 $x_0=0.5$ 处求值。\n        *   这需要计算权重函数、基向量和逆矩量矩阵的导数。\n        *   我将系统地计算所有分量。\n\n    *   **第3部分：计算近似梯度 $u_x^h(x_0)$**\n        *   使用公式 $u_x^{h}(x_0) = \\sum_{i=1}^{3} N_i'(x_0)\\,u(x_i)$。\n        *   代入计算出的导数和测试函数 $u(x) = \\exp(x)$ 在节点处的值。\n        *   化简以获得最终的解析表达式。\n\n问题陈述的验证如下。\n**第1步：提取已知条件**\n- 方法：一维移动最小二乘 (MLS) 近似。\n- 多项式基：$\\mathbf{p}(x) = [1, x]^{\\top}$。这是一个大小为 $m=2$ 的线性基。\n- 权重函数：高斯函数，$w(r) = \\exp(-(r/\\delta)^2)$。\n- 形状参数：$\\delta = 0.6$。\n- 节点位置：$x_1 = 0$，$x_2 = 0.5$，$x_3 = 1$。节点总数 $n=3$。\n- 评估点：$x_0 = 0.5$。\n- 测试函数：$u(x) = \\exp(x)$。\n- 任务1：推导在 $x_0$ 处的 MLS 形函数 $N_i(x_0)$（$i \\in \\{1,2,3\\}$）。\n- 任务2：计算梯度的 MLS 近似值 $u_x^{h}(x_0) = \\sum_{i=1}^{3} N_i'(x_0) u(x_i)$。\n\n**第2步：使用提取的已知条件进行验证**\n- **科学性：** 该问题描述了移动最小二乘法的典型应用，该方法是求解偏微分方程的无网格方法的基石。所有组成部分（线性基、高斯权重函数）都是标准的。\n- **适定性：** 问题提供了所有必要信息。评估点 $x_0=0.5$ 与节点 $x_2$ 重合，这是一个有效的情景。矩量矩阵 $\\mathbf{M}(x_0)$ 必须是可逆的。只要权重函数支持域内的节点不以退化的方式与基函数共线（此处情况并非如此），$\\mathbf{M}$ 就是可逆的。\n- **客观性：** 问题使用精确的数学语言陈述，没有主观因素。\n\n**第3步：结论与行动**\n问题有效。将提供完整解答。\n\n### 解答推导\n\n在评估点 $x_0$ 处，函数 $u(x)$ 的移动最小二乘 (MLS) 近似由 $u^h(x_0) = \\mathbf{p}^{\\top}(x_0) \\mathbf{a}(x_0)$ 给出，其中 $\\mathbf{p}(x) = \\begin{pmatrix} 1 \\\\ x \\end{pmatrix}$ 是多项式基，$\\mathbf{a}(x_0)$ 是通过最小化加权离散 $L_2$ 范数确定的系数向量：\n$$ J(\\mathbf{a}) = \\sum_{i=1}^{3} w(x_0 - x_i) \\left[ \\mathbf{p}^{\\top}(x_i) \\mathbf{a} - u(x_i) \\right]^2 $$\n法方程 $\\frac{\\partial J}{\\partial \\mathbf{a}} = 0$ 产生线性系统 $\\mathbf{M}(x_0) \\mathbf{a}(x_0) = \\mathbf{C}(x_0) \\mathbf{u}$，其中矩量矩阵为 $\\mathbf{M}(x_0) = \\sum_{i=1}^{3} w(x_0-x_i) \\mathbf{p}(x_i) \\mathbf{p}^{\\top}(x_i)$，且 $\\mathbf{C}(x_0)\\mathbf{u} = \\sum_{i=1}^{3} w(x_0-x_i) \\mathbf{p}(x_i) u(x_i)$。\n\n求解 $\\mathbf{a}(x_0)$ 并代回，得到以形函数 $N_i(x_0)$ 表示的 MLS 近似：\n$$ u^h(x_0) = \\sum_{i=1}^{3} N_i(x_0) u(x_i) $$\n其中节点 $i$ 的形函数由下式给出：\n$$ N_i(x_0) = \\mathbf{p}^{\\top}(x_0) \\mathbf{M}^{-1}(x_0) \\mathbf{p}(x_i) w(x_0-x_i) $$\n\n**1. 形函数 $N_i(x_0)$ 的计算**\n\n首先，我们计算在 $x_0=0.5$ 处的必要分量。\n节点位置为 $x_1 = 0$，$x_2 = 0.5$，$x_3 = 1$。形状参数为 $\\delta=0.6$。\n评估点到各节点的距离为 $r_1 = |0.5-0|=0.5$，$r_2 = |0.5-0.5|=0$，$r_3 = |0.5-1|=0.5$。\n权重为：\n$w_1 = w(r_1) = \\exp(-(0.5/0.6)^2) = \\exp(-(5/6)^2) = \\exp(-25/36)$。\n$w_2 = w(r_2) = \\exp(0) = 1$。\n$w_3 = w(r_3) = \\exp(-(0.5/0.6)^2) = w_1$。\n我们记 $w_{13} = w_1 = w_3$。\n\n在节点处计算的基向量为：\n$\\mathbf{p}(x_1) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$，$\\mathbf{p}(x_2) = \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix}$，$\\mathbf{p}(x_3) = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n\n在 $x_0=0.5$ 处的矩量矩阵 $\\mathbf{M}(x_0)$ 为：\n$$ \\mathbf{M}(0.5) = w_1 \\mathbf{p}(x_1)\\mathbf{p}^{\\top}(x_1) + w_2 \\mathbf{p}(x_2)\\mathbf{p}^{\\top}(x_2) + w_3 \\mathbf{p}(x_3)\\mathbf{p}^{\\top}(x_3) $$\n$$ \\mathbf{M}(0.5) = w_{13} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\end{pmatrix} + 1 \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix} \\begin{pmatrix} 1  0.5 \\end{pmatrix} + w_{13} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 1  1 \\end{pmatrix} $$\n$$ \\mathbf{M}(0.5) = w_{13} \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} + \\begin{pmatrix} 1  0.5 \\\\ 0.5  0.25 \\end{pmatrix} + w_{13} \\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix} = \\begin{pmatrix} 1+2w_{13}  0.5+w_{13} \\\\ 0.5+w_{13}  0.25+w_{13} \\end{pmatrix} $$\n$\\mathbf{M}(0.5)$ 的行列式为：\n$$ \\det(\\mathbf{M}(0.5)) = (1+2w_{13})(0.25+w_{13}) - (0.5+w_{13})^2 $$\n$$ = (0.25 + 1.5w_{13} + 2w_{13}^2) - (0.25 + w_{13} + w_{13}^2) = 0.5w_{13} + w_{13}^2 = w_{13}(0.5+w_{13}) $$\n逆矩量矩阵为：\n$$ \\mathbf{M}^{-1}(0.5) = \\frac{1}{w_{13}(0.5+w_{13})} \\begin{pmatrix} 0.25+w_{13}  -(0.5+w_{13}) \\\\ -(0.5+w_{13})  1+2w_{13} \\end{pmatrix} $$\n为方便起见，我们计算向量 $\\mathbf{v}^{\\top} = \\mathbf{p}^{\\top}(x_0) \\mathbf{M}^{-1}(x_0)$：\n$$ \\mathbf{v}^{\\top} = \\begin{pmatrix} 1  0.5 \\end{pmatrix} \\frac{1}{w_{13}(0.5+w_{13})} \\begin{pmatrix} 0.25+w_{13}  -(0.5+w_{13}) \\\\ -(0.5+w_{13})  1+2w_{13} \\end{pmatrix} $$\n$$ \\mathbf{v}^{\\top} = \\frac{1}{w_{13}(0.5+w_{13})} \\begin{pmatrix} (0.25+w_{13}) - 0.5(0.5+w_{13})  -(0.5+w_{13}) + 0.5(1+2w_{13}) \\end{pmatrix} $$\n$$ \\mathbf{v}^{\\top} = \\frac{1}{w_{13}(0.5+w_{13})} \\begin{pmatrix} 0.5w_{13}  0 \\end{pmatrix} = \\frac{1}{0.5+w_{13}} \\begin{pmatrix} 0.5  0 \\end{pmatrix} $$\n现在我们可以求出形函数 $N_i(x_0) = \\mathbf{v}^{\\top} \\mathbf{p}(x_i) w_i$：\n$$ N_1(0.5) = \\left( \\frac{1}{0.5+w_{13}} \\begin{pmatrix} 0.5  0 \\end{pmatrix} \\right) \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} w_{13} = \\frac{0.5 w_{13}}{0.5+w_{13}} $$\n$$ N_2(0.5) = \\left( \\frac{1}{0.5+w_{13}} \\begin{pmatrix} 0.5  0 \\end{pmatrix} \\right) \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix} (1) = \\frac{0.5}{0.5+w_{13}} $$\n$$ N_3(0.5) = \\left( \\frac{1}{0.5+w_{13}} \\begin{pmatrix} 0.5  0 \\end{pmatrix} \\right) \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} w_{13} = \\frac{0.5 w_{13}}{0.5+w_{13}} $$\n其中 $w_{13} = \\exp(-25/36)$。\n\n**2. 形函数导数 $N_i'(x_0)$ 的计算**\n\n通过应用乘法法则可以求得形函数的导数：\n$$ N_i'(x) = \\frac{d}{dx} \\left( \\mathbf{p}^{\\top}(x) \\mathbf{M}^{-1}(x) \\mathbf{p}(x_i) w(x-x_i) \\right) $$\n设 $\\mathbf{C}(x)=\\mathbf{M}^{-1}(x)$。\n$$ N_i'(x) = \\left( \\mathbf{p}'^{\\top}\\mathbf{C}\\mathbf{p}_i + \\mathbf{p}^{\\top}\\mathbf{C}'\\mathbf{p}_i \\right)w_i + \\left( \\mathbf{p}^{\\top}\\mathbf{C}\\mathbf{p}_i \\right)w_i' $$\n其中 $w_i = w(x-x_i)$，$w_i' = \\frac{d}{dx}w(x-x_i)$，$\\mathbf{p} = \\mathbf{p}(x)$，$\\mathbf{p}_i = \\mathbf{p}(x_i)$，$\\mathbf{C}' = -\\mathbf{C}\\mathbf{M}'\\mathbf{C}$，以及 $\\mathbf{M}'(x) = \\sum_j \\frac{d}{dx}w(x-x_j) \\mathbf{p}_j\\mathbf{p}_j^{\\top}$。\n导数在 $x_0=0.5$ 处计算。\n\n权重函数的导数为 $\\frac{dw(r)}{dr} = \\exp(-(r/\\delta)^2) \\cdot (-2r/\\delta^2)$。\n关于 $x$ 的导数为 $w_i' = \\frac{dw(x-x_i)}{dx}|_{x_0} = \\frac{dw(r)}{dr}|_{r_i} \\cdot \\text{sgn}(x_0-x_i)$。\n$w_1' = \\left( \\exp(-(0.5/\\delta)^2) \\frac{-2(0.5)}{\\delta^2} \\right) \\cdot (1) = -w_{13}/\\delta^2$。\n因为 $r_2=0$，所以 $w_2' = 0$。\n$w_3' = \\left( \\exp(-(0.5/\\delta)^2) \\frac{-2(0.5)}{\\delta^2} \\right) \\cdot (-1) = w_{13}/\\delta^2$。\n基向量的导数为 $\\mathbf{p}'(x) = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。\n\n在 $x_0=0.5$ 处的矩量矩阵的导数为：\n$$ \\mathbf{M}'(0.5) = w_1' \\mathbf{p}_1 \\mathbf{p}_1^{\\top} + w_2' \\mathbf{p}_2 \\mathbf{p}_2^{\\top} + w_3' \\mathbf{p}_3 \\mathbf{p}_3^{\\top} $$\n$$ \\mathbf{M}'(0.5) = \\frac{-w_{13}}{\\delta^2} \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} + \\frac{w_{13}}{\\delta^2} \\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix} = \\frac{w_{13}}{\\delta^2} \\begin{pmatrix} 0  1 \\\\ 1  1 \\end{pmatrix} $$\n由于这个特定问题的显著对称性，计算 $N_i'(x_0)$ 的三个项会导致大量的抵消。\n- 来自 $\\mathbf{p}'$ 的项：$\\mathbf{p}'^{\\top}(x_0)\\mathbf{M}^{-1}(x_0)\\mathbf{p}(x_i) w_i$。\n- 来自 $w_i'$ 的项：$\\mathbf{p}^{\\top}(x_0)\\mathbf{M}^{-1}(x_0)\\mathbf{p}(x_i) w_i'$。\n- 来自 $\\mathbf{M}'$ 的项：$-\\mathbf{p}^{\\top}(x_0)\\mathbf{M}^{-1}(x_0)\\mathbf{M}'(x_0)\\mathbf{M}^{-1}(x_0)\\mathbf{p}(x_i) w_i$。\n\n如思路中所述，详细计算表明，对 $w_{13}$ 和 $\\delta$ 的依赖性完全抵消，从而得出一个非常简单的结果。MLS 导数的一致性条件 $\\sum_i N_i'(x) = 0$ 和 $\\sum_i N_i'(x) x_i = 1$ 可用于验证结果。\n\n导数的计算结果为：\n$$ N_1'(0.5) = -1 $$\n$$ N_2'(0.5) = 0 $$\n$$ N_3'(0.5) = 1 $$\n\n**3. 计算近似梯度 $u_x^h(x_0)$**\n\n在 $x_0=0.5$ 处，梯度的 MLS 近似为：\n$$ u_x^{h}(x_0) = \\sum_{i=1}^{3} N_i'(x_0) u(x_i) = N_1'(0.5) u(x_1) + N_2'(0.5) u(x_2) + N_3'(0.5) u(x_3) $$\n测试函数为 $u(x) = \\exp(x)$。在节点处的值为：\n$u(x_1) = u(0) = \\exp(0) = 1$。\n$u(x_2) = u(0.5) = \\exp(0.5)$。\n$u(x_3) = u(1) = \\exp(1) = e$。\n\n代入这些值和计算出的导数：\n$$ u_x^{h}(0.5) = (-1)(1) + (0)(\\exp(0.5)) + (1)(e) $$\n$$ u_x^{h}(0.5) = e - 1 $$\n此结果对应于在区间 $[0,1]$ 上对 $x=0.5$ 处导数的中心差分近似，即 $\\frac{u(1)-u(0)}{1-0}$。这种简化是由于节点围绕评估点对称分布，且评估点本身也是一个节点。",
            "answer": "$$\\boxed{e-1}$$"
        },
        {
            "introduction": "一旦我们掌握了 MLS 形函数，就可以在伽辽金框架内使用它们来求解偏微分方程，这就是无单元伽辽金（EFG）方法。这个练习展示了如何将 PDE 的变分形式转化为一个离散的线性方程组 $\\mathbf{K}\\mathbf{u}=\\mathbf{f}$。通过计算刚度矩阵中的一个元素，你将清晰地看到近似理论与最终数值系统之间的紧密联系。",
            "id": "3419988",
            "problem": "考虑一维空间中的标量泊松问题：寻找一个足够光滑的函数 $u(x)$，使得对于 $x \\in \\Omega$，有 $-u''(x) = f(x)$，并在 $\\partial \\Omega$ 上满足齐次狄利克雷边界条件。令 $\\Omega$ 为开区间 $(0,1)$，并假设 $f(x)$ 足够正则。从标准变分陈述出发，即：寻找 $u \\in H^{1}_{0}(\\Omega)$，使得对于所有 $v \\in H^{1}_{0}(\\Omega)$，均有 $\\int_{\\Omega} u'(x) v'(x) \\, dx = \\int_{\\Omega} f(x) v(x) \\, dx$，推导使用基于线性多项式基构建的移动最小二乘 (MLS) 形函数的无单元伽辽金 (EFG) 离散方程。明确定义 MLS 近似、相关的矩量矩阵以及 EFG 方法中产生的离散刚度矩阵项。讨论用于组装刚度的科学合理的数值积分策略，包括背景单元的作用以及与 MLS 形函数光滑性相一致的求积法则。\n\n然后，对于 $\\Omega = (0,1)$ 的特定情况，其中两个节点位于 $x_{1} = 0$ 和 $x_{2} = 1$，选择线性多项式基 $p(x) = [1 \\;\\; x]^{\\top}$ 和常数权重 $w_{1}(x) = 1$ 及 $w_{2}(x) = 1$（对于所有 $x \\in \\Omega$）。使用 EFG 框架和根据这些选择构建的 MLS 形函数，计算非对角刚度矩阵项 $K_{12} = \\int_{0}^{1} N_{1}'(x) N_{2}'(x) \\, dx$，其中 $N_{i}(x)$ 表示与节点 $i$ 相关的 MLS 形函数，撇号表示对 $x$ 的微分。将 $K_{12}$ 的值以单个实数的形式给出。无需四舍五入，最终答案不涉及单位。",
            "solution": "该问题是有效的，因为它是偏微分方程数值方法领域中一个适定问题，特别涉及无单元伽辽金 (EFG) 方法。它具有科学依据、客观，并为所需的推导和计算提供了所有必要的信息。\n\n该问题要求两部分：首先，对一维泊松问题进行 EFG 离散方程的一般性推导；其次，对一个刚度矩阵项进行具体计算。\n\n**第一部分：EFG 离散方程的一般性推导**\n\n我们从一维泊松问题 $-u''(x) = f(x)$ 开始，定义在域 $\\Omega = (0,1)$ 上，并带有齐次狄利克雷边界条件 $u(0)=u(1)=0$。相应的变分形式或弱形式是找到 $u \\in H^{1}_{0}(\\Omega)$ 使得：\n$$a(u,v) = \\ell(v) \\quad \\forall v \\in H^{1}_{0}(\\Omega)$$\n其中双线性形式 $a(u,v)$ 和线性形式 $\\ell(v)$ 由下式给出：\n$$a(u,v) = \\int_{\\Omega} u'(x) v'(x) \\, dx$$\n$$\\ell(v) = \\int_{\\Omega} f(x) v(x) \\, dx$$\n\n在无单元伽辽金方法中，未知函数 $u(x)$ 由一个使用移动最小二乘 (MLS) 构建的函数 $u^h(x)$ 来近似。在 $\\Omega$ 中任意点 $x$ 处的近似 $u^h(x)$ 表示为多项式基函数 $\\mathbf{p}(x)$ 的线性组合：\n$$u^h(x) = \\mathbf{p}(x)^\\top \\mathbf{a}(x) = \\sum_{j=1}^{m} p_j(x) a_j(x)$$\n对于一维的线性多项式基，我们有 $m=2$ 和 $\\mathbf{p}(x) = [1, x]^\\top$。系数 $\\mathbf{a}(x)$ 是在每个点 $x$ 通过最小化近似与一组 $n$ 个节点 $\\{x_I\\}_{I=1}^n$ 处的节点参数 $u_I$ 之间差值的加权离散 $L_2$ 范数来确定的。该泛函为：\n$$J(\\mathbf{a}(x)) = \\sum_{I=1}^{n} w_I(x) [u^h(x_I; x) - u_I]^2 = \\sum_{I=1}^{n} w_I(x) [\\mathbf{p}(x_I)^\\top \\mathbf{a}(x) - u_I]^2$$\n在这里，$u_I$ 是节点自由度（而不是 $u^h$ 在 $x_I$ 处的值），而 $w_I(x)$ 是具有紧支集（或在本问题的特殊情况下为常数）的非负权重函数。\n\n通过令 $\\frac{\\partial J}{\\partial \\mathbf{a}} = \\mathbf{0}$ 来最小化 $J$ 关于 $\\mathbf{a}(x)$，得到正规方程：\n$$\\left( \\sum_{I=1}^{n} w_I(x) \\mathbf{p}(x_I) \\mathbf{p}(x_I)^\\top \\right) \\mathbf{a}(x) = \\sum_{I=1}^{n} w_I(x) \\mathbf{p}(x_I) u_I$$\n这可以写作 $\\mathbf{M}(x) \\mathbf{a}(x) = \\mathbf{B}(x) \\mathbf{u}$，其中：\n- $\\mathbf{u} = [u_1, u_2, \\dots, u_n]^\\top$ 是节点参数的向量。\n- $\\mathbf{M}(x)$ 是矩量矩阵，定义为：\n  $$\\mathbf{M}(x) = \\sum_{I=1}^{n} w_I(x) \\mathbf{p}(x_I) \\mathbf{p}(x_I)^\\top$$\n- $\\mathbf{B}(x)$ 是一个矩阵，其第 $I$ 列为 $w_I(x)\\mathbf{p}(x_I)$。\n\n求解 $\\mathbf{a}(x)$ 得到 $\\mathbf{a}(x) = \\mathbf{M}(x)^{-1} \\mathbf{B}(x) \\mathbf{u}$。将此代入 $u^h(x)$ 的表达式中：\n$$u^h(x) = \\mathbf{p}(x)^\\top \\mathbf{M}(x)^{-1} \\mathbf{B}(x) \\mathbf{u} = \\sum_{I=1}^{n} N_I(x) u_I$$\n其中 $N_I(x)$ 是 MLS 形函数：\n$$N_I(x) = \\mathbf{p}(x)^\\top \\mathbf{M}(x)^{-1} \\mathbf{p}(x_I) w_I(x)$$\n\n现在，我们将近似 $u^h(x) = \\sum_{I=1}^{n} N_I(x) u_I$ 和测试函数 $v^h(x) = \\sum_{J=1}^{n} N_J(x) c_J$（其中 $c_J$ 是任意系数）代入弱形式中：\n$$\\int_{\\Omega} \\left( \\sum_{I=1}^{n} N_I'(x) u_I \\right) \\left( \\sum_{J=1}^{n} N_J'(x) c_J \\right) dx = \\int_{\\Omega} f(x) \\left( \\sum_{J=1}^{n} N_J(x) c_J \\right) dx$$\n$$\\sum_{J=1}^{n} c_J \\left( \\sum_{I=1}^{n} u_I \\int_{\\Omega} N_I'(x) N_J'(x) dx - \\int_{\\Omega} f(x) N_J(x) dx \\right) = 0$$\n因为这对 $c_J$ 的任何选择都必须成立，所以对于每个 $J=1, \\dots, n$，我们有：\n$$\\sum_{I=1}^{n} \\left( \\int_{\\Omega} N_J'(x) N_I'(x) dx \\right) u_I = \\int_{\\Omega} f(x) N_J(x) dx$$\n这就得到了离散线性方程组 $\\mathbf{K} \\mathbf{u} = \\mathbf{f}$，其中：\n- 刚度矩阵项为 $K_{JI} = \\int_{\\Omega} N_J'(x) N_I'(x) dx$。\n- 力向量项为 $f_J = \\int_{\\Omega} f(x) N_J(x) dx$。\n\n关于数值积分，$\\mathbf{K}$ 和 $\\mathbf{f}$ 的被积函数涉及 MLS 形函数及其导数的乘积。通常，$N_I(x)$ 是有理函数（由 $\\mathbf{p}(x)^\\top \\text{adj}(\\mathbf{M}(x))$ 产生的关于 $x$ 的多项式除以另一个多项式 $\\det(\\mathbf{M}(x))$），因此它们的导数也是复杂的有理函数。解析积分通常是难以处理的。因此，需要进行数值求积。一个标准的策略是创建一个覆盖域 $\\Omega$ 的背景积分单元网格。在每个单元内，使用诸如高斯求积之类的数值求积法则。求积法则的阶数必须足够高，才能精确地积分形函数或其导数的乘积。所需的阶数取决于权重函数 $w_I(x)$ 和多项式基 $\\mathbf{p}(x)$ 的复杂性。更高阶的基函数和更复杂的权重需要更高阶的求积法则来精确组装刚度矩阵和力向量。\n\n**第二部分：具体计算**\n\n我们给定一个具体情况，其中 $\\Omega = (0,1)$，两个节点位于 $x_1=0$ 和 $x_2=1$，线性基为 $\\mathbf{p}(x) = [1, x]^\\top$，并且对于所有 $x \\in \\Omega$，权重为常数 $w_1(x) = 1$ 和 $w_2(x) = 1$。\n\n首先，我们计算矩量矩阵 $\\mathbf{M}(x)$。由于权重是常数，$\\mathbf{M}$ 也是常数。\n$$\\mathbf{M} = \\sum_{I=1}^{2} w_I \\mathbf{p}(x_I) \\mathbf{p}(x_I)^\\top$$\n节点处的基向量是：\n$$\\mathbf{p}(x_1) = \\mathbf{p}(0) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad \\mathbf{p}(x_2) = \\mathbf{p}(1) = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n当 $w_1 = 1$ 和 $w_2 = 1$ 时：\n$$\\mathbf{M} = 1 \\cdot \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\end{pmatrix} + 1 \\cdot \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 1  1 \\end{pmatrix}$$\n$$\\mathbf{M} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} + \\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 1  1 \\end{pmatrix}$$\n\n接下来，我们求矩量矩阵的逆矩阵 $\\mathbf{M}^{-1}$。\n$$\\det(\\mathbf{M}) = (2)(1) - (1)(1) = 1$$\n$$\\mathbf{M}^{-1} = \\frac{1}{\\det(\\mathbf{M})} \\begin{pmatrix} 1  -1 \\\\ -1  2 \\end{pmatrix} = \\begin{pmatrix} 1  -1 \\\\ -1  2 \\end{pmatrix}$$\n\n现在我们可以确定 MLS 形函数 $N_1(x)$ 和 $N_2(x)$。\n对于 $N_1(x)$：\n$$N_1(x) = \\mathbf{p}(x)^\\top \\mathbf{M}^{-1} \\mathbf{p}(x_1) w_1(x) = \\begin{pmatrix} 1  x \\end{pmatrix} \\begin{pmatrix} 1  -1 \\\\ -1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\cdot 1$$\n$$N_1(x) = \\begin{pmatrix} 1  x \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = 1 - x$$\n\n对于 $N_2(x)$：\n$$N_2(x) = \\mathbf{p}(x)^\\top \\mathbf{M}^{-1} \\mathbf{p}(x_2) w_2(x) = \\begin{pmatrix} 1  x \\end{pmatrix} \\begin{pmatrix} 1  -1 \\\\ -1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\cdot 1$$\n$$N_2(x) = \\begin{pmatrix} 1  x \\end{pmatrix} \\begin{pmatrix} 1-1 \\\\ -1+2 \\end{pmatrix} = \\begin{pmatrix} 1  x \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = x$$\n\n得到的形函数 $N_1(x) = 1-x$ 和 $N_2(x) = x$ 是标准的线性有限元基函数。出现这种简化是因为节点数等于基函数数量（$n=m$），并且权重在整个域上是常数，导致 MLS 近似简化为全局多项式插值。\n\n问题要求计算非对角刚度矩阵项 $K_{12}$：\n$$K_{12} = \\int_{0}^{1} N_1'(x) N_2'(x) \\, dx$$\n首先，我们求形函数的导数：\n$$N_1'(x) = \\frac{d}{dx}(1-x) = -1$$\n$$N_2'(x) = \\frac{d}{dx}(x) = 1$$\n现在我们计算积分：\n$$K_{12} = \\int_{0}^{1} (-1)(1) \\, dx = \\int_{0}^{1} -1 \\, dx$$\n$$K_{12} = [-x]_{0}^{1} = -(1) - (-(0)) = -1$$",
            "answer": "$$\\boxed{-1}$$"
        }
    ]
}