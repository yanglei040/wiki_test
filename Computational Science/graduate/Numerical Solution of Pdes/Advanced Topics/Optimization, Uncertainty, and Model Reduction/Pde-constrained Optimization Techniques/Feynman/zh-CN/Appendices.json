{
    "hands_on_practices": [
        {
            "introduction": "要深刻理解伴随法，最好的方法莫过于从第一性原理出发，推导出它的核心方程。这个基本练习将指导您使用拉格朗日方法和格林恒等式（即分部积分），为一般的椭圆型偏微分方程推导其伴随方程以及至关重要的伴随边界条件。通过完成这项推导 ，您将能洞悉状态（或原始）问题与伴随（或对偶）问题之间深刻的对偶关系，这是整个偏微分方程约束优化领域的基石。",
            "id": "3429633",
            "problem": "考虑一个有界域 $\\Omega \\subset \\mathbb{R}^{d}$，其边界 $\\Gamma$ 足够光滑，单位外法向量为 $\\boldsymbol{n}$。边界被划分为三个不相交的可测部分 $\\Gamma_{D}$、$\\Gamma_{N}$ 和 $\\Gamma_{R}$，使得 $\\overline{\\Gamma_{D}} \\cup \\overline{\\Gamma_{N}} \\cup \\overline{\\Gamma_{R}} = \\Gamma$。设 $\\kappa \\in C^{1}(\\overline{\\Omega})$ 对所有 $\\boldsymbol{x} \\in \\overline{\\Omega}$ 满足 $\\kappa(\\boldsymbol{x}) \\ge \\kappa_{0} > 0$。给定一个期望状态 $y_{d} \\in L^{2}(\\Omega)$ 和一个控制 $u \\in L^{2}(\\Omega)$，状态 $y$ 由以下偏微分方程控制\n$$\n- \\nabla \\cdot \\big( \\kappa \\nabla y \\big) \\;=\\; u \\quad \\text{in } \\Omega,\n$$\n以及混合边界条件\n$$\ny \\;=\\; 0 \\quad \\text{on } \\Gamma_{D}, \\qquad \\kappa \\nabla y \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{N}, \\qquad \\alpha\\, y \\;+\\; \\beta\\, \\kappa \\nabla y \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{R},\n$$\n其中 $\\alpha, \\beta \\in C(\\Gamma_{R})$ 且在每个 $\\boldsymbol{s} \\in \\Gamma_{R}$ 处 $(\\alpha(\\boldsymbol{s}), \\beta(\\boldsymbol{s})) \\neq (0,0)$。考虑二次追踪代价泛函\n$$\nJ(y,u) \\;=\\; \\frac{1}{2} \\int_{\\Omega} \\big( y - y_{d} \\big)^{2} \\, \\mathrm{d}\\boldsymbol{x}.\n$$\n仅使用拉格朗日方法、伴随变量 $p$ 和基本的格林恒等式（分部积分），从第一性原理推导伴随边界条件，以确保拉格朗日量对于在给定边界约束下 $y$ 的变分是平稳的。具体来说：\n- 通过显式的边界项分析，证明在 $\\Gamma_{D}$ 和 $\\Gamma_{N}$ 上的伴随边界条件必须是什么，并解释为什么它们的类型不同。\n- 通过对变分强制施加线性化边界约束来处理 Robin 段 $\\Gamma_{R}$，并推导出形式为\n$$\n\\alpha^{\\ast} \\, p \\;+\\; \\beta^{\\ast} \\, \\kappa \\nabla p \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{R}\n$$\n的 Robin 型伴随边界条件。\n你的答案必须是伴随 Robin 系数的有序对 $(\\alpha^{\\ast}, \\beta^{\\ast})$，表示为单个行矩阵。不需要数值近似。请以闭式解析表达式的形式提供最终答案。最终答案中不要包含任何单位。",
            "solution": "我们从约束优化问题的拉格朗日量开始。引入伴随变量（拉格朗日乘子）$p \\in H^{1}(\\Omega)$ 并定义\n$$\n\\mathcal{L}(y,u,p) \\;=\\; \\frac{1}{2} \\int_{\\Omega} \\big( y - y_{d} \\big)^{2} \\, \\mathrm{d}\\boldsymbol{x} \\;+\\; \\int_{\\Omega} p \\Big( - \\nabla \\cdot \\big( \\kappa \\nabla y \\big) - u \\Big) \\, \\mathrm{d}\\boldsymbol{x}.\n$$\n为了推导伴随方程和边界条件，我们考虑 $\\mathcal{L}$ 关于 $y$ 在方向 $v$ 上的首次变分。容许变分 $v$ 必须满足由状态边界约束导出的线性化边界条件，即\n$$\nv \\;=\\; 0 \\quad \\text{on } \\Gamma_{D}, \n\\qquad \\kappa \\nabla v \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{N}, \n\\qquad \\alpha\\, v \\;+\\; \\beta\\, \\kappa \\nabla v \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{R}.\n$$\n$\\mathcal{L}$ 关于 $y$ 在方向 $v$ 上的 Gâteaux 导数为\n$$\n\\delta_{y}\\mathcal{L}(y,u,p)[v] \\;=\\; \\int_{\\Omega} (y - y_{d})\\, v \\, \\mathrm{d}\\boldsymbol{x} \\;+\\; \\int_{\\Omega} p \\big( - \\nabla \\cdot (\\kappa \\nabla v) \\big) \\, \\mathrm{d}\\boldsymbol{x}.\n$$\n对第二个积分应用格林恒等式。对于足够光滑的 $p$ 和 $v$，\n$$\n\\int_{\\Omega} p \\big( - \\nabla \\cdot (\\kappa \\nabla v) \\big) \\, \\mathrm{d}\\boldsymbol{x}\n\\;=\\;\n- \\int_{\\Omega} v \\, \\nabla \\cdot (\\kappa \\nabla p) \\, \\mathrm{d}\\boldsymbol{x}\n\\;+\\; \\int_{\\Gamma} \\kappa \\Big( v \\, \\nabla p \\cdot \\boldsymbol{n} \\;-\\; (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\Big) \\, \\mathrm{d}s.\n$$\n因此\n$$\n\\delta_{y}\\mathcal{L}(y,u,p)[v]\n\\;=\\;\n\\int_{\\Omega} \\Big( (y - y_{d}) - \\nabla \\cdot (\\kappa \\nabla p) \\Big) v \\, \\mathrm{d}\\boldsymbol{x}\n\\;+\\; \\int_{\\Gamma} \\kappa \\Big( v \\, \\nabla p \\cdot \\boldsymbol{n} \\;-\\; (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\Big) \\, \\mathrm{d}s.\n$$\n关于所有容许变分 $v$ 的平稳性要求内部项对所有 $v$ 均为零，从而得到伴随偏微分方程\n$$\n- \\nabla \\cdot (\\kappa \\nabla p) \\;=\\; y - y_{d} \\quad \\text{in } \\Omega.\n$$\n剩下的任务是强制使边界积分对于满足每个边界段上线性化边界条件的所有容许变分 $v$ 均为零。我们分别分析每个边界段。\n\n在 $\\Gamma_{D}$ 上：容许变分满足 $v = 0$ on $\\Gamma_{D}$，而 $\\nabla v \\cdot \\boldsymbol{n}$ 不受此条件约束。限制在 $\\Gamma_{D}$ 上的边界积分简化为\n$$\n\\int_{\\Gamma_{D}} \\kappa \\Big( 0 \\cdot \\nabla p \\cdot \\boldsymbol{n} \\;-\\; (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\Big) \\, \\mathrm{d}s\n\\;=\\; - \\int_{\\Gamma_{D}} \\kappa \\, (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\, \\mathrm{d}s.\n$$\n因为在 $v=0$ 的条件下，$(\\nabla v \\cdot \\boldsymbol{n})$ 可以（在迹的意义上）任意选择，所以使该积分对所有这样的 $v$ 均为零的唯一方法是施加\n$$\np \\;=\\; 0 \\quad \\text{on } \\Gamma_{D}.\n$$\n因此，Dirichlet 状态边界条件在同一边界段上导出 Dirichlet 伴随边界条件。\n\n在 $\\Gamma_{N}$ 上：容许变分满足 $\\kappa \\nabla v \\cdot \\boldsymbol{n} = 0$ on $\\Gamma_{N}$，而 $v$ 在 $\\Gamma_{N}$ 上不受其他约束。限制在 $\\Gamma_{N}$ 上的边界积分变为\n$$\n\\int_{\\Gamma_{N}} \\kappa \\Big( v \\, \\nabla p \\cdot \\boldsymbol{n} \\;-\\; 0 \\cdot p \\Big) \\, \\mathrm{d}s\n\\;=\\; \\int_{\\Gamma_{N}} \\kappa \\, v \\, \\nabla p \\cdot \\boldsymbol{n} \\, \\mathrm{d}s.\n$$\n因为 $v$ 可以在 $\\Gamma_{N}$ 上任意选择，所以使该积分对所有这样的 $v$ 均为零的唯一方法是施加\n$$\n\\kappa \\nabla p \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{N}.\n$$\n因此，Neumann 状态边界条件在同一边界段上导出 Neumann 伴随边界条件。这解释了 Dirichlet 和 Neumann 情况之间的区别：在 $\\Gamma_{D}$ 上，$v$ 的迹固定为零，迫使 $p$ 为零；在 $\\Gamma_{N}$ 上，$v$ 的法向导数固定为零，迫使 $p$ 的法向通量为零。\n\n在 $\\Gamma_{R}$ 上：容许变分满足线性化 Robin 约束\n$$\n\\alpha \\, v \\;+\\; \\beta \\, \\kappa \\nabla v \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{R}.\n$$\n限制在 $\\Gamma_{R}$ 上的边界积分可写为\n$$\n\\int_{\\Gamma_{R}} \\kappa \\Big( v \\, \\nabla p \\cdot \\boldsymbol{n} \\;-\\; (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\Big) \\, \\mathrm{d}s.\n$$\n为强制使其对所有这样的 $v$ 均为零，只需将 $v$ 用 $\\nabla v \\cdot \\boldsymbol{n}$ 表示（或反之）来消去 $v$。当边界点处 $\\alpha(\\boldsymbol{s}) \\neq 0$ 时，我们可以写出 $v \\,=\\, - (\\beta \\kappa / \\alpha) \\, \\nabla v \\cdot \\boldsymbol{n}$。逐点代入得到被积函数\n$$\n\\kappa \\left( - \\frac{\\beta \\kappa}{\\alpha} \\, (\\nabla v \\cdot \\boldsymbol{n}) \\, \\nabla p \\cdot \\boldsymbol{n} \\;-\\; (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\right)\n\\;=\\;\n- \\kappa \\, (\\nabla v \\cdot \\boldsymbol{n}) \\left( \\frac{\\beta \\kappa}{\\alpha} \\, \\nabla p \\cdot \\boldsymbol{n} \\;+\\; p \\right).\n$$\n因为在线性化约束下 $(\\nabla v \\cdot \\boldsymbol{n})$ 可以任意选择，所以括号中的因子必须为零，从而得到\n$$\n\\alpha \\, p \\;+\\; \\beta \\, \\kappa \\nabla p \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{R} \\cap \\{ \\alpha \\neq 0 \\}.\n$$\n在 $\\beta(\\boldsymbol{s}) \\neq 0$ 的点上，一个对称的论证也适用，即改为用 $v$ 解出 $\\nabla v \\cdot \\boldsymbol{n}$，也会得到相同的条件。由于 $(\\alpha,\\beta)$ 不会同时为零，我们得出结论，在 $\\Gamma_{R}$ 上处处成立的伴随 Robin 边界条件是\n$$\n\\alpha^{\\ast} \\, p \\;+\\; \\beta^{\\ast} \\, \\kappa \\nabla p \\cdot \\boldsymbol{n} \\;=\\; 0\n\\quad \\text{with} \\quad\n\\alpha^{\\ast} \\;=\\; \\alpha, \\;\\; \\beta^{\\ast} \\;=\\; \\beta.\n$$\n总之，分部积分和对变分 $v$ 强制施加线性化边界约束意味着\n- 在 $\\Gamma_{D}$ 上: $p = 0$ (Dirichlet)。\n- 在 $\\Gamma_{N}$ 上: $\\kappa \\nabla p \\cdot \\boldsymbol{n} = 0$ (Neumann)。\n- 在 $\\Gamma_{R}$ 上: $\\alpha p + \\beta \\kappa \\nabla p \\cdot \\boldsymbol{n} = 0$ (系数不变的 Robin)。\n因此，伴随 Robin 系数的有序对是 $(\\alpha^{\\ast}, \\beta^{\\ast}) = (\\alpha, \\beta)$。",
            "answer": "$$\\boxed{\\begin{pmatrix}\\alpha & \\beta\\end{pmatrix}}$$"
        },
        {
            "introduction": "在掌握了连续理论之后，下一步是将其转化为可计算的算法，这通常需要借助有限元等方法对问题进行离散化。本练习  将带您探索“先离散后优化”的策略，即首先写出离散的状态方程，然后为这个离散系统推导目标泛函的梯度。这项实践将强化您对抽象的变分形式与具体的矩阵向量运算（涉及刚度矩阵 $ \\boldsymbol{K} $ 和质量矩阵 $ \\boldsymbol{M} $）之间联系的理解，而后者正是构建真实世界求解器的基础。",
            "id": "3429645",
            "problem": "考虑一个在有界多边形区域 $\\Omega \\subset \\mathbb{R}^{2}$ 上，受线性椭圆偏微分方程和齐次狄利克雷边界条件约束的线性二次最优控制问题。令 $V := H_{0}^{1}(\\Omega)$，定义双线性形式 $a(\\cdot,\\cdot)$ 和 $L^{2}(\\Omega)$ 内积 $(\\cdot,\\cdot)$ 如下：\n$$\na(y,v) := \\int_{\\Omega} \\nabla y \\cdot \\nabla v \\, dx + \\int_{\\Omega} c(x) \\, y \\, v \\, dx, \\quad (u,v) := \\int_{\\Omega} u \\, v \\, dx,\n$$\n其中 $c \\in L^{\\infty}(\\Omega)$ 几乎处处满足 $c(x) \\ge 0$。对于给定的期望状态 $y_{d} \\in L^{2}(\\Omega)$ 和正则化参数 $\\alpha > 0$，目标泛函为\n$$\nJ(y,u) := \\frac{1}{2} \\, \\| y - y_{d} \\|_{L^{2}(\\Omega)}^{2} + \\frac{\\alpha}{2} \\, \\| u \\|_{L^{2}(\\Omega)}^{2},\n$$\n其约束条件为弱形式状态方程\n$$\na(y,v) = (u,v) \\quad \\text{对所有 } v \\in V.\n$$\n令 $V_{h} \\subset V$ 为一个具有基 $\\{ \\varphi_{i} \\}_{i=1}^{n}$ 的相容有限元空间，并在 $V_{h}$ 中将状态、伴随和控制近似为\n$$\ny_{h} = \\sum_{i=1}^{n} y_{i} \\, \\varphi_{i}, \\quad p_{h} = \\sum_{i=1}^{n} p_{i} \\, \\varphi_{i}, \\quad u_{h} = \\sum_{i=1}^{n} u_{i} \\, \\varphi_{i}.\n$$\n定义刚度矩阵 $\\boldsymbol{K} \\in \\mathbb{R}^{n \\times n}$ 和质量矩阵 $\\boldsymbol{M} \\in \\mathbb{R}^{n \\times n}$ 如下：\n$$\n\\boldsymbol{K}_{ij} := a(\\varphi_{j}, \\varphi_{i}), \\quad \\boldsymbol{M}_{ij} := (\\varphi_{j}, \\varphi_{i}),\n$$\n并令 $\\boldsymbol{y}_{d} \\in \\mathbb{R}^{n}$ 表示 $y_{d}$ 到 $V_{h}$ 上的 $L^{2}(\\Omega)$ 投影的系数向量，即对所有 $v_{h} \\in V_{h}$ 都有 $(y_{d,h}, v_{h}) = (y_{d}, v_{h})$。离散状态方程和离散伴随方程为\n$$\n\\boldsymbol{K} \\, \\boldsymbol{y} = \\boldsymbol{M} \\, \\boldsymbol{u}, \\quad \\boldsymbol{K} \\, \\boldsymbol{p} = \\boldsymbol{M} \\, (\\boldsymbol{y} - \\boldsymbol{y}_{d}),\n$$\n离散简约目标函数为\n$$\nj_{h}(\\boldsymbol{u}) := \\frac{1}{2} \\, (\\boldsymbol{y} - \\boldsymbol{y}_{d})^{\\top} \\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d}) + \\frac{\\alpha}{2} \\, \\boldsymbol{u}^{\\top} \\boldsymbol{M} \\boldsymbol{u},\n$$\n其中 $\\boldsymbol{y} = \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u}$。仅从这些定义和变分形式出发，通过离散伴随方程推导关于 $\\mathbb{R}^{n}$ 上欧几里得内积的离散简约梯度，然后消去伴随变量和状态变量，将此梯度完全用 $\\boldsymbol{K}$、$\\boldsymbol{M}$、$\\alpha$、$\\boldsymbol{u}$ 和 $\\boldsymbol{y}_{d}$ 表示。最后，评论此离散简约梯度与从 $L^{2}(\\Omega)$ 表达式 $\\alpha \\, u + p$ 得到的离散化连续梯度有何关系。\n\n你的最终答案必须是关于 $\\boldsymbol{K}$、$\\boldsymbol{M}$、$\\alpha$、$\\boldsymbol{u}$ 和 $\\boldsymbol{y}_{d}$ 的离散简约梯度向量的单一闭式解析表达式，并用方框括起来。不需要四舍五入，且不涉及物理单位。",
            "solution": "目标是推导离散简约目标泛函\n$$\nj_{h}(\\boldsymbol{u}) := \\frac{1}{2} \\, (\\boldsymbol{y} - \\boldsymbol{y}_{d})^{\\top} \\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d}) + \\frac{\\alpha}{2} \\, \\boldsymbol{u}^{\\top} \\boldsymbol{M} \\boldsymbol{u}\n$$\n关于 $\\mathbb{R}^{n}$ 上欧几里得内积的梯度。状态向量 $\\boldsymbol{y}$ 通过离散状态方程 $\\boldsymbol{K} \\boldsymbol{y} = \\boldsymbol{M} \\boldsymbol{u}$ 依赖于控制向量 $\\boldsymbol{u}$。问题规定使用离散伴随方法。\n\n让我们计算 $j_{h}(\\boldsymbol{u})$ 在任意方向 $\\delta \\boldsymbol{u} \\in \\mathbb{R}^{n}$ 上的 Gâteaux 导数。令 $\\boldsymbol{y}(\\boldsymbol{u}) = \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u}$。控制中的一个扰动 $\\delta \\boldsymbol{u}$ 会引起状态中的一个扰动 $\\delta \\boldsymbol{y}$，这可以通过对状态方程进行线性化得到：\n$$\n\\boldsymbol{K} \\, \\delta\\boldsymbol{y} = \\boldsymbol{M} \\, \\delta\\boldsymbol{u}.\n$$\n$j_{h}$ 的一阶变分为\n$$\n\\delta j_{h} = Dj_{h}(\\boldsymbol{u})[\\delta \\boldsymbol{u}] = (\\boldsymbol{y} - \\boldsymbol{y}_{d})^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{y} + \\alpha \\, \\boldsymbol{u}^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{u}.\n$$\n通常，通过避免直接计算 $\\delta \\boldsymbol{y} = \\boldsymbol{K}^{-1} \\boldsymbol{M} \\delta \\boldsymbol{u}$ 并将其代入 $\\delta j_{h}$ 的表达式，可以更有效地计算梯度。伴随方法引入一个伴随状态 $\\boldsymbol{p}$ 来消去 $\\delta \\boldsymbol{y}$。\n\n问题提供了离散伴随方程：\n$$\n\\boldsymbol{K} \\boldsymbol{p} = \\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d}).\n$$\n双线性形式 $a(\\cdot,\\cdot)$ 是对称的，这意味着刚度矩阵 $\\boldsymbol{K}$ 是对称的，即 $\\boldsymbol{K}^{\\top} = \\boldsymbol{K}$。根据定义，质量矩阵 $\\boldsymbol{M}$ 也是对称的，$\\boldsymbol{M}^{\\top} = \\boldsymbol{M}$。利用 $\\boldsymbol{K}$ 的对称性，伴随方程可以写成 $\\boldsymbol{K}^{\\top} \\boldsymbol{p} = \\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d})$。\n\n现在我们处理 $\\delta j_{h}$ 表达式中的第一项：\n$$\n(\\boldsymbol{y} - \\boldsymbol{y}_{d})^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{y} = (\\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d}))^{\\top} \\delta\\boldsymbol{y}.\n$$\n从伴随方程代入 $\\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d})$ 的表达式：\n$$\n(\\boldsymbol{y} - \\boldsymbol{y}_{d})^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{y} = (\\boldsymbol{K}^{\\top} \\boldsymbol{p})^{\\top} \\delta\\boldsymbol{y} = \\boldsymbol{p}^{\\top} \\boldsymbol{K} \\, \\delta\\boldsymbol{y}.\n$$\n接下来，我们从扰动状态方程代入 $\\boldsymbol{K} \\, \\delta\\boldsymbol{y}$ 的表达式：\n$$\n\\boldsymbol{p}^{\\top} \\boldsymbol{K} \\, \\delta\\boldsymbol{y} = \\boldsymbol{p}^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{u}.\n$$\n将此结果代回 $\\delta j_{h}$ 的表达式中：\n$$\n\\delta j_{h} = \\boldsymbol{p}^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{u} + \\alpha \\, \\boldsymbol{u}^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{u}.\n$$\n利用 $\\boldsymbol{M}$ 的对称性，我们可以将其重写为：\n$$\n\\delta j_{h} = (\\boldsymbol{M} \\boldsymbol{p})^{\\top} \\delta\\boldsymbol{u} + (\\alpha \\boldsymbol{M} \\boldsymbol{u})^{\\top} \\delta\\boldsymbol{u} = (\\alpha \\boldsymbol{M} \\boldsymbol{u} + \\boldsymbol{M} \\boldsymbol{p})^{\\top} \\delta\\boldsymbol{u}.\n$$\n$j_{h}$ 关于欧几里得内积的梯度，记为 $\\nabla j_{h}(\\boldsymbol{u})$，由关系式 $\\delta j_{h} = (\\nabla j_{h}(\\boldsymbol{u}))^{\\top} \\delta \\boldsymbol{u}$ 对所有 $\\delta \\boldsymbol{u}$ 定义。因此，我们将梯度确定为：\n$$\n\\nabla j_{h}(\\boldsymbol{u}) = \\alpha \\boldsymbol{M} \\boldsymbol{u} + \\boldsymbol{M} \\boldsymbol{p} = \\boldsymbol{M} (\\alpha \\boldsymbol{u} + \\boldsymbol{p}).\n$$\n问题要求评论此表达式与连续梯度 $\\alpha u + p$ 的关系。在连续情况下，最优性条件是 $\\nabla J(u) = \\alpha u + p = 0$。向量 $\\boldsymbol{u}$ 和 $\\boldsymbol{p}$ 分别包含有限元函数 $u_{h} = \\sum_{i=1}^{n} u_{i} \\varphi_{i}$ 和 $p_{h} = \\sum_{i=1}^{n} p_{i} \\varphi_{i}$ 的系数。因此，向量 $\\alpha \\boldsymbol{u} + \\boldsymbol{p}$ 包含函数 $\\alpha u_{h} + p_{h}$ 的系数。表达式 $\\boldsymbol{M}(\\alpha \\boldsymbol{u} + \\boldsymbol{p})$ 表示该函数到有限元基函数上的投影，因为其第 i 个分量是 $\\sum_{j} \\boldsymbol{M}_{ij} (\\alpha u_{j} + p_{j}) = \\sum_{j} (\\varphi_{j}, \\varphi_{i}) (\\alpha u_{j} + p_{j}) = (\\alpha u_{h} + p_{h}, \\varphi_{i})$。这正是 L2 梯度在欧几里得空间中的 Riesz 表示，通常被称为欧几里得梯度。\n\n最后，我们必须消去状态变量 $\\boldsymbol{y}$ 和伴随变量 $\\boldsymbol{p}$，以仅用 $\\boldsymbol{K}$、$\\boldsymbol{M}$、$\\alpha$、$\\boldsymbol{u}$ 和 $\\boldsymbol{y}_{d}$ 来表示梯度。我们有以下方程组：\n1. 状态方程： $\\boldsymbol{y} = \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u}$\n2. 伴随方程： $\\boldsymbol{p} = \\boldsymbol{K}^{-1} \\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d})$\n\n将 (1) 代入 (2)：\n$$\n\\boldsymbol{p} = \\boldsymbol{K}^{-1} \\boldsymbol{M} (\\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u} - \\boldsymbol{y}_{d}).\n$$\n现在将这个 $\\boldsymbol{p}$ 的表达式代入梯度公式 $\\nabla j_{h}(\\boldsymbol{u}) = \\boldsymbol{M} (\\alpha \\boldsymbol{u} + \\boldsymbol{p})$：\n$$\n\\nabla j_{h}(\\boldsymbol{u}) = \\boldsymbol{M} \\left( \\alpha \\boldsymbol{u} + \\boldsymbol{K}^{-1} \\boldsymbol{M} (\\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u} - \\boldsymbol{y}_{d}) \\right).\n$$\n展开此表达式得到梯度的最终形式：\n$$\n\\nabla j_{h}(\\boldsymbol{u}) = \\alpha \\boldsymbol{M} \\boldsymbol{u} + \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u} - \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{y}_{d}.\n$$\n这可以组合为：\n$$\n\\nabla j_{h}(\\boldsymbol{u}) = (\\alpha \\boldsymbol{M} + \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M}) \\boldsymbol{u} - \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{y}_{d}.\n$$\n这就是所要求的离散简约梯度的闭式表达式。",
            "answer": "$$\n\\boxed{(\\alpha \\boldsymbol{M} + \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M}) \\boldsymbol{u} - \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{y}_{d}}\n$$"
        },
        {
            "introduction": "伴随法的威力远不止于经典的优化控制问题，它在物理约束机器学习等前沿领域也有着强大的应用。在这个练习中，我们将利用一个离散偏微分方程残差算子的伴随，来高效地计算一个损失函数的梯度，该损失函数旨在惩罚那些由生成模型产生但违反了控制物理定律的解。这项高级实践  不仅展示了一个前沿应用，还训练了一项至关重要的技能：为瞬态问题推导离散伴随算子，并利用有限差分进行梯度检验以验证其实现的正确性。",
            "id": "3429635",
            "problem": "考虑与热方程相关的偏微分方程（PDE）残差算子，该算子定义在一个单位时空域上，由 $r(y) = \\partial_t y - \\Delta y$ 给出，其中 $y$ 是在 $[0,1] \\times [0,1] \\times [0,1]$ 上的一个标量场，包含空间变量和时间。设空间域在 $x$ 方向上由 $N_x$ 个点离散，在 $y$ 方向上由 $N_y$ 个点离散，时间由 $N_t$ 个点离散，所有点均为均匀间隔。记网格间距为 $\\Delta x = 1/(N_x - 1)$，$\\Delta y = 1/(N_y - 1)$，以及 $\\Delta t = 1/(N_t - 1)$。设内部空间索引为 $i \\in \\{1, \\dots, N_x - 2\\}$ 和 $j \\in \\{1, \\dots, N_y - 2\\}$，时间索引为 $n \\in \\{0, \\dots, N_t - 2\\}$。\n\n通过标准的显式时间前向差分和拉普拉斯算子的五点模板（齐次狄利克雷边界值为 $0$）来定义内部点的离散残差：\n$$\nr_{n,i,j}(y) = \\frac{y_{n+1,i,j} - y_{n,i,j}}{\\Delta t} - \\frac{y_{n,i+1,j} + y_{n,i-1,j} + y_{n,i,j+1} + y_{n,i,j-1} - 4 y_{n,i,j}}{\\Delta x^2},\n$$\n其中 $y_{n,i,j}$ 表示 $y$ 在时间索引 $n$ 和空间索引 $(i,j)$ 处的值，且拉普拉斯算子在时间索引 $n$ 处计算。假设 $\\Delta x = \\Delta y$。\n\n设生成器通过一组固定的基函数 $\\{\\phi_k\\}_{k=1}^K$ 生成样本 $y_\\theta$，该样本由参数向量 $\\theta \\in \\mathbb{R}^K$ 线性参数化：\n$$\ny_\\theta(n,i,j) = \\sum_{k=1}^K \\theta_k \\, \\phi_k(n,i,j).\n$$\n基函数被指定为在空间边界上为零的正弦函数的可分离乘积，\n$$\n\\phi_k(n,i,j) = \\sin\\!\\left(p_x^{(k)} \\pi x_i\\right) \\, \\sin\\!\\left(p_y^{(k)} \\pi y_j\\right) \\, \\sin\\!\\left(\\beta^{(k)} \\pi t_n\\right),\n$$\n其中 $x_i = i \\Delta x$，$y_j = j \\Delta y$，$t_n = n \\Delta t$。整数 $p_x^{(k)}$、$p_y^{(k)}$ 和 $\\beta^{(k)}$ 指定了空间和时间频率。齐次狄利克雷边界条件由空间正弦因子隐式地强制执行。\n\n定义残差惩罚泛函\n$$\nR(\\theta) = \\sum_{n=0}^{N_t-2} \\sum_{i=1}^{N_x-2} \\sum_{j=1}^{N_y-2} \\left( r_{n,i,j}\\!\\left(y_\\theta\\right) \\right)^2.\n$$\n\n任务：\n1. 在离散网格上的标准欧几里得内积下，推导残差算子 $A$（使得 $r=Ay$）的离散伴随算子 $A^\\ast$，并用它将梯度 $\\nabla_\\theta R(\\theta)$ 表示为 $\\theta$ 和基函数 $\\phi_k$ 的显式函数。\n2. 实现一个程序，使用残差算子的伴随方法为给定的测试用例计算 $R(\\theta)$ 和 $\\nabla_\\theta R(\\theta)$。\n3. 对每个测试用例，将基于伴随方法的梯度与梯度的数值中心有限差分近似进行验证，并报告由下式定义的相对误差：\n$$\n\\mathrm{err} = \\frac{\\left\\|\\nabla_\\theta R(\\theta)\\big|_{\\text{adjoint}} - \\nabla_\\theta R(\\theta)\\big|_{\\text{finite diff}}\\right\\|_2}{\\max\\!\\left(10^{-12}, \\left\\|\\nabla_\\theta R(\\theta)\\big|_{\\text{adjoint}}\\right\\|_2\\right)}.\n$$\n在中心有限差分中使用扰动大小 $\\varepsilon = 10^{-6}$。\n\n测试套件：\n为以下三个测试用例提供结果。在每个案例中，都指定了空间和时间频率 $(p_x^{(k)}, p_y^{(k)}, \\beta^{(k)})$ 以及参数向量 $\\theta$。\n\n- 测试用例 1（边界情况，零参数）：\n  - $N_x = 10$, $N_y = 10$, $N_t = 5$.\n  - 基函数频率：$\\left[(1,1,1), (2,1,1)\\right]$.\n  - 参数：$\\theta = [0, 0]$.\n\n- 测试用例 2（一般情况）：\n  - $N_x = 16$, $N_y = 16$, $N_t = 12$.\n  - 基函数频率：$\\left[(1,2,1), (2,2,1), (3,1,2)\\right]$.\n  - 参数：$\\theta = [0.4, -0.3, 0.2]$.\n\n- 测试用例 3（时间边界，最少时间层级）：\n  - $N_x = 12$, $N_y = 12$, $N_t = 2$.\n  - 基函数频率：$\\left[(1,1,1), (2,3,1), (3,3,1), (4,1,2)\\right]$.\n  - 参数：$\\theta = [0.1, -0.2, 0.05, 0.3]$.\n\n最终输出格式：\n您的程序应生成单行输出，其中包含三个测试用例的相对误差，格式为方括号括起来的逗号分隔列表（例如，$\\left[ \\mathrm{err}_1, \\mathrm{err}_2, \\mathrm{err}_3 \\right]$）。条目必须是十进制数。",
            "solution": "### 1. 理论推导\n\n主要任务是计算残差惩罚泛函 $R(\\theta)$ 的梯度。伴随方法提供了一种计算此梯度的高效途径。\n\n**1.1. 离散形式**\n\n令状态向量 $y$ 为离散网格上值的集合 $\\{y_{n,i,j}\\}$。为简化起见，我们将 $y$ 视为空间 $\\mathcal{Y} = \\mathbb{R}^{N_t \\times (N_x-2) \\times (N_y-2)}$ 中的一个向量，表示所有时间步上内部空间网格的解。基函数 $\\phi_k$ 也限制在该网格上。$\\mathcal{Y}$ 上的标准欧几里得内积定义为：\n$$\n\\langle y, p \\rangle_{\\mathcal{Y}} = \\sum_{n=0}^{N_t-1} \\sum_{i=1}^{N_x-2} \\sum_{j=1}^{N_y-2} y_{n,i,j} p_{n,i,j}\n$$\n离散残差 $r$ 是空间 $\\mathcal{R} = \\mathbb{R}^{(N_t-1) \\times (N_x-2) \\times (N_y-2)}$ 中的一个向量。$\\mathcal{R}$ 上的内积为：\n$$\n\\langle r, q \\rangle_{\\mathcal{R}} = \\sum_{n=0}^{N_t-2} \\sum_{i=1}^{N_x-2} \\sum_{j=1}^{N_y-2} r_{n,i,j} q_{n,i,j}\n$$\n离散残差算子 $A: \\mathcal{Y} \\to \\mathcal{R}$ 是一个线性算子，由给定公式定义：\n$$\n(Ay)_{n,i,j} = \\frac{y_{n+1,i,j} - y_{n,i,j}}{\\Delta t} - \\frac{y_{n,i+1,j} + y_{n,i-1,j} + y_{n,i,j+1} + y_{n,i,j-1} - 4 y_{n,i,j}}{\\Delta x^2}\n$$\n其中，对于邻近边界的点，在拉普拉斯模板中使用了齐次狄利克雷边界条件 $y_{n,0,j} = y_{n,N_x-1,j} = y_{n,i,0} = y_{n,i,N_y-1} = 0$。我们可以将 $A$ 写为 $A = \\partial_t^+ - \\Delta_d$，其中 $\\partial_t^+$ 是前向时间差分算子，$\\Delta_d$ 是离散拉普拉斯算子。\n\n**1.2. 通过伴随方法计算梯度**\n\n泛函为 $R(\\theta) = \\langle r(y_\\theta), r(y_\\theta) \\rangle_{\\mathcal{R}}$。状态 $y_\\theta$ 是 $\\theta$ 的线性函数：$y_\\theta = \\sum_{k=1}^K \\theta_k \\phi_k$。由于 $A$ 的线性性，残差对 $\\theta$ 也是线性的：$r(y_\\theta) = A y_\\theta = \\sum_{k=1}^K \\theta_k A \\phi_k$。\n\n关于 $\\theta_m$ 的梯度分量使用链式法则求得：\n$$\n\\frac{\\partial R}{\\partial \\theta_m} = 2 \\left\\langle r(y_\\theta), \\frac{\\partial r(y_\\theta)}{\\partial \\theta_m} \\right\\rangle_{\\mathcal{R}} = 2 \\langle r(y_\\theta), A \\phi_m \\rangle_{\\mathcal{R}}\n$$\n引入伴随算子 $A^*: \\mathcal{R} \\to \\mathcal{Y}$，它由关系式 $\\langle A y, q \\rangle_{\\mathcal{R}} = \\langle y, A^* q \\rangle_{\\mathcal{Y}}$ 对所有 $y \\in \\mathcal{Y}, q \\in \\mathcal{R}$ 定义，我们可以重写梯度表达式：\n$$\n\\frac{\\partial R}{\\partial \\theta_m} = 2 \\langle \\phi_m, A^* r(y_\\theta) \\rangle_{\\mathcal{Y}}\n$$\n这是伴随方法的核心。我们定义伴随状态（或协态）向量 $p \\in \\mathcal{Y}$ 为 $p = A^* r(y_\\theta)$。然后梯度计算如下：\n$$\n(\\nabla_\\theta R(\\theta))_m = 2 \\langle \\phi_m, p \\rangle_{\\mathcal{Y}}\n$$\n计算流程如下：\n1. 对于给定的 $\\theta$，计算状态 $y_\\theta = \\sum_k \\theta_k \\phi_k$。\n2. 计算残差 $r = r(y_\\theta)$。\n3. 计算伴随状态 $p = A^* r$。这需要推导算子 $A^*$。\n4. 使用基函数 $\\phi_m$ 和伴随状态 $p$ 之间的内积计算梯度。\n\n**1.3. 伴随算子 $A^*$ 的推导**\n\n我们有 $A = \\partial_t^+ - \\Delta_d$，所以 $A^* = (\\partial_t^+)^* - \\Delta_d^*$。\n\n- **离散拉普拉斯算子 ($-\\Delta_d$) 的伴随**：具有齐次狄利克雷边界条件的离散五点拉普拉斯模板是一个对称算子。因此，它是自伴的：$(-\\Delta_d)^* = -\\Delta_d$。\n\n- **前向时间差分 ($\\partial_t^+$) 的伴随**：我们通过分部求和法推导伴随算子。对于任意 $y \\in \\mathcal{Y}$ 和 $q \\in \\mathcal{R}$：\n$$\n\\langle \\partial_t^+ y, q \\rangle_{\\mathcal{R}} = \\sum_{n=0}^{N_t-2} \\left\\langle \\frac{y_{n+1} - y_n}{\\Delta t}, q_n \\right\\rangle_{space}\n$$\n其中 $\\langle \\cdot, \\cdot \\rangle_{space}$ 是单个空间切片上的内积。重新整理各项：\n$$\n= \\frac{1}{\\Delta t} \\left( \\sum_{n=0}^{N_t-2} \\langle y_{n+1}, q_n \\rangle - \\sum_{n=0}^{N_t-2} \\langle y_n, q_n \\rangle \\right)\n= \\frac{1}{\\Delta t} \\left( \\sum_{n'=1}^{N_t-1} \\langle y_{n'}, q_{n'-1} \\rangle - \\sum_{n=0}^{N_t-2} \\langle y_n, q_n \\rangle \\right)\n$$\n分离时间边界项（$y$ 的 $n=0$ 和 $n=N_t-1$）：\n$$\n= \\left\\langle y_0, -\\frac{q_0}{\\Delta t} \\right\\rangle + \\sum_{n=1}^{N_t-2} \\left\\langle y_n, \\frac{q_{n-1} - q_n}{\\Delta t} \\right\\rangle + \\left\\langle y_{N_t-1}, \\frac{q_{N_t-2}}{\\Delta t} \\right\\rangle\n$$\n这必须等于 $\\langle y, (\\partial_t^+)^* q \\rangle_{\\mathcal{Y}} = \\sum_{n=0}^{N_t-1} \\langle y_n, ((\\partial_t^+)^* q)_n \\rangle$。通过比较每一项 $y_n$ 的系数，我们确定 $((\\partial_t^+)^* q)$ 的分量：\n\\begin{align*}\n((\\partial_t^+)^* q)_n =  \\begin{cases} -q_0 / \\Delta t & n=0 \\\\ (q_{n-1} - q_n) / \\Delta t & 1 \\le n \\le N_t-2 \\\\ q_{N_t-2} / \\Delta t & n=N_t-1 \\end{cases}\n\\end{align*}\n\n结合空间和时间部分，伴随运算 $p = A^* q$ 由以下系统给出：\n\\begin{align*}\np_{N_t-1} = \\frac{q_{N_t-2}}{\\Delta t} \\\\\np_n = \\frac{q_{n-1} - q_n}{\\Delta t} - \\Delta_d q_n \\quad \\text{for } n = N_t-2, \\dots, 1 \\\\\np_0 = -\\frac{q_0}{\\Delta t} - \\Delta_d q_0\n\\end{align*}\n这是一个必须从最终时间 $n=N_t-1$ 开始，*逆向* 求解 $p$ 的系统。\n\n### 2. 实现策略\n\n实现直接遵循推导出的公式。\n\n1.  **网格和基函数**：对于每个测试用例，设置离散网格坐标 $x_i, y_j, t_n$。为所有 $k,n,i,j$ 计算基函数 $\\phi_k(n,i,j)$ 并存储它们。\n2.  **伴随梯度计算**：\n    a.  使用 $y_\\theta = \\sum_k \\theta_k \\phi_k$ 在完整网格上计算状态 $y_\\theta$。向量化的 `einsum` 对此非常高效。\n    b.  在内部网格上为 $n \\in \\{0, \\dots, N_t-2\\}$ 计算离散残差 $r = A y_\\theta$。这涉及应用离散时间导数和拉普拉斯算子。\n    c.  通过应用推导出的逆时伴随方程计算伴随状态 $p = A^* r$。计算从 $p_{N_t-1}$ 向下进行到 $p_0$。\n    d.  通过计算内积 $2\\langle\\phi_m, p\\rangle_{\\mathcal{Y}}$ 来计算梯度的每个分量 $(\\nabla_\\theta R(\\theta))_m$。\n3.  **有限差分梯度计算**：为进行验证，使用中心差分公式对梯度进行数值近似：\n    $$\n    (\\nabla_\\theta R(\\theta))_m \\approx \\frac{R(\\theta + \\varepsilon e_m) - R(\\theta - \\varepsilon e_m)}{2\\varepsilon}\n    $$\n    其中 $e_m$ 是第 $m$ 个标准基向量，$\\varepsilon=10^{-6}$ 是一个小的扰动。这需要对目标泛函 $R$ 进行 $2K$ 次评估。\n4.  **误差计算**：伴随梯度 $\\nabla_{\\text{adj}}$ 与有限差分近似 $\\nabla_{\\text{fd}}$ 之间的相对误差按规定计算：\n    $$\n    \\mathrm{err} = \\frac{\\|\\nabla_{\\text{adj}} - \\nabla_{\\text{fd}}\\|_2}{\\max(10^{-12}, \\|\\nabla_{\\text{adj}}\\|_2)}\n    $$\n\n所提供的 Python 代码使用 `numpy` 来实现此策略，以进行高效的数组运算。",
            "answer": "```python\nimport numpy as np\n\ndef apply_laplacian_to_y(y_slice, dx2):\n    \"\"\"Computes the Laplacian of a 2D slice y_n, returning it on the interior.\"\"\"\n    lap = (y_slice[2:, 1:-1] + y_slice[:-2, 1:-1] + \n           y_slice[1:-1, 2:] + y_slice[1:-1, :-2] - \n           4 * y_slice[1:-1, 1:-1]) / dx2\n    return lap\n\ndef apply_laplacian_to_q(q_slice, dx2):\n    \"\"\"Computes the Laplacian of a 2D slice q_n on the interior grid, assuming zero padding.\"\"\"\n    q_padded = np.pad(q_slice, pad_width=1, mode='constant', constant_values=0)\n    lap = (q_padded[2:, 1:-1] + q_padded[:-2, 1:-1] + \n           q_padded[1:-1, 2:] + q_padded[1:-1, :-2] - \n           4 * q_padded[1:-1, 1:-1]) / dx2\n    return lap\n\ndef compute_residual(y, dx, dt):\n    \"\"\"Computes the discrete residual r = A*y.\"\"\"\n    Nt, Nx, Ny = y.shape\n    dx2 = dx**2\n    r = np.zeros((Nt - 1, Nx - 2, Ny - 2))\n    \n    for n in range(Nt - 1):\n        y_forward = y[n + 1, 1:Nx-1, 1:Ny-1]\n        y_current = y[n, 1:Nx-1, 1:Ny-1]\n        dt_term = (y_forward - y_current) / dt\n        lap_y_n = apply_laplacian_to_y(y[n], dx2)\n        r[n, :, :] = dt_term - lap_y_n\n    return r\n\ndef compute_objective(r):\n    \"\"\"Computes the objective functional R = ||r||^2.\"\"\"\n    return np.sum(r**2)\n\ndef apply_adjoint(r, dx, dt):\n    \"\"\"Computes the adjoint state p = A*r by solving the backward system.\"\"\"\n    Nt_res, Nx_int, Ny_int = r.shape\n    Nt = Nt_res + 1\n    dx2 = dx**2\n    \n    p = np.zeros((Nt, Nx_int, Ny_int))\n\n    lap_r = np.zeros_like(r)\n    for n in range(Nt_res):\n        lap_r[n, :, :] = apply_laplacian_to_q(r[n], dx2)\n\n    if Nt > 1:\n        # Final time step for adjoint state p\n        p[Nt-1] = r[Nt-2] / dt\n        \n        # Backward time stepping for n = Nt-2 down to 1\n        for n in range(Nt - 2, 0, -1):\n            p[n] = (r[n-1] - r[n]) / dt - lap_r[n]\n        \n        # Initial time step for adjoint state p\n        p[0] = -r[0] / dt - lap_r[0]\n        \n    return p\n\ndef compute_y_theta(theta, phi):\n    \"\"\"Computes y_theta = sum(theta_k * phi_k).\"\"\"\n    return np.einsum('k,knij->nij', theta, phi)\n\ndef process_case(Nx, Ny, Nt, freqs, theta, eps):\n    \"\"\"Runs a single test case to compute the gradient validation error.\"\"\"\n    dx = 1.0 / (Nx - 1)\n    dt = 1.0 / (Nt - 1) if Nt > 1 else 1.0\n\n    x = np.linspace(0, 1, Nx)\n    y_coords = np.linspace(0, 1, Ny)\n    t = np.linspace(0, 1, Nt)\n    \n    K = len(freqs)\n    phi = np.zeros((K, Nt, Nx, Ny))\n    for k in range(K):\n        px, py, beta = freqs[k]\n        sin_x = np.sin(px * np.pi * x)\n        sin_y = np.sin(py * np.pi * y_coords)\n        sin_t = np.sin(beta * np.pi * t)\n        phi[k] = np.outer(sin_t, np.outer(sin_x, sin_y)).reshape(Nt, Nx, Ny)\n\n    # --- Adjoint Gradient Calculation ---\n    y_theta = compute_y_theta(theta, phi)\n    r = compute_residual(y_theta, dx, dt)\n    p = apply_adjoint(r, dx, dt)\n    \n    grad_adj = np.zeros(K)\n    phi_interior = phi[:, :, 1:Nx-1, 1:Ny-1]\n    for k in range(K):\n        grad_adj[k] = 2 * np.sum(phi_interior[k] * p)\n        \n    # --- Finite Difference Gradient Calculation ---\n    grad_fd = np.zeros(K)\n    theta_arr = np.array(theta, dtype=float)\n    for k in range(K):\n        theta_plus =  theta_arr.copy()\n        theta_plus[k] += eps\n        y_plus = compute_y_theta(theta_plus, phi)\n        r_plus = compute_residual(y_plus, dx, dt)\n        R_plus = compute_objective(r_plus)\n        \n        theta_minus = theta_arr.copy()\n        theta_minus[k] -= eps\n        y_minus = compute_y_theta(theta_minus, phi)\n        r_minus = compute_residual(y_minus, dx, dt)\n        R_minus = compute_objective(r_minus)\n        \n        grad_fd[k] = (R_plus - R_minus) / (2 * eps)\n        \n    # --- Error Calculation ---\n    norm_adj = np.linalg.norm(grad_adj)\n    norm_diff = np.linalg.norm(grad_adj - grad_fd)\n    \n    error = norm_diff / max(1e-12, norm_adj)\n    return error\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    test_cases = [\n        {'Nx': 10, 'Ny': 10, 'Nt': 5, 'freqs': [(1, 1, 1), (2, 1, 1)], 'theta': [0.0, 0.0]},\n        {'Nx': 16, 'Ny': 16, 'Nt': 12, 'freqs': [(1, 2, 1), (2, 2, 1), (3, 1, 2)], 'theta': [0.4, -0.3, 0.2]},\n        {'Nx': 12, 'Ny': 12, 'Nt': 2, 'freqs': [(1, 1, 1), (2, 3, 1), (3, 3, 1), (4, 1, 2)], 'theta': [0.1, -0.2, 0.05, 0.3]}\n    ]\n    eps = 1e-6\n    results = []\n    \n    for case in test_cases:\n        error = process_case(case['Nx'], case['Ny'], case['Nt'],\n                             case['freqs'], case['theta'], eps)\n        results.append(error)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}