{
    "hands_on_practices": [
        {
            "introduction": "在构建降维基底之前，理解其理论上的“黄金标准”至关重要。对于一组给定的解快照，本征正交分解（Proper Orthogonal Decomposition, POD）能够提供最紧凑的线性基底。本练习将引导您完成一个基础性的推导，它将POD基底的精度与快照数据矩阵的奇异值直接联系起来。掌握这一关系 ，您将明白为何POD是最优的，并为后续更实用的贪婪算法奠定理论基础。",
            "id": "3438787",
            "problem": "考虑一个定义在有界域 $\\Omega \\subset \\mathbb{R}^{d}$ 上的参数化非线性抛物型偏微分方程，其具有齐次狄利克雷边界条件，并通过协调有限元方法在空间上进行离散，基函数为 $\\{\\varphi_{i}\\}_{i=1}^{n}$。设半离散模型写作\n$$\nM \\frac{d x(t,\\mu)}{d t} + A(\\mu)\\, x(t,\\mu) + g\\!\\left(x(t,\\mu);\\mu\\right) = b(\\mu),\n$$\n其中 $M \\in \\mathbb{R}^{n \\times n}$ 是与 $L^{2}(\\Omega)$ 内积相关的对称正定质量矩阵，$A(\\mu) \\in \\mathbb{R}^{n \\times n}$ 是依赖于参数 $\\mu \\in \\mathcal{P}$ 的类刚度算子，$x(t,\\mu) \\in \\mathbb{R}^{n}$ 是时刻 $t$ 的有限元解的系数向量，$g(\\cdot;\\mu)$ 是一个非线性项，旨在通过离散经验插值方法 (DEIM) 以在线高效的方式进行近似，$b(\\mu) \\in \\mathbb{R}^{n}$ 是一个源项。假设将通过在 $\\mu \\in \\mathcal{P}$ 上的贪心算法来选择一个候选降阶基，但对于本问题，我们仅关注从解快照构造的正常正交分解 (POD)。\n\n令 $\\{x_{k}\\}_{k=1}^{m}$ 为在一个参数和时间的训练集上采样的 $m$ 个解快照的集合，并将其组装成快照矩阵 $X \\in \\mathbb{R}^{n \\times m}$，其列为 $x_{k}$。定义质量加权快照矩阵 $Y := M^{1/2} X \\in \\mathbb{R}^{n \\times m}$，其中 $M^{1/2}$ 表示 $M$ 的唯一对称正定平方根。设 $Y$ 的奇异值分解为 $Y = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{n \\times n}$ 和 $V \\in \\mathbb{R}^{m \\times m}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{n \\times m}$ 是对角矩阵，其非零元素是主对角线上的奇异值 $\\sigma_{1} \\geq \\sigma_{2} \\geq \\cdots \\geq \\sigma_{q} > 0$，其中 $q = \\min\\{n,m\\}$。秩为 $r$ 的 POD 空间由 $Y$ 的前 $r$ 个左奇异向量通过 $M^{-1/2}$ 映射回去来定义，即 $\\Psi_{r} := M^{-1/2} U_{r} \\in \\mathbb{R}^{n \\times r}$，其中 $U_{r} \\in \\mathbb{R}^{n \\times r}$ 包含了 $U$ 的前 $r$ 列。由于 $\\Psi_{r}^{\\top} M \\Psi_{r} = I_{r}$，到 $\\operatorname{span}(\\Psi_{r})$ 上的 $M$-正交投影算子为 $P_{r} := \\Psi_{r} \\Psi_{r}^{\\top} M$，快照的秩为 $r$ 的 POD 重构为 $X_{r} := P_{r} X$。\n\n定义在 $L^{2}(\\Omega)$ 意义下的总平方快照重构误差为\n$$\nE_{r}^{2} := \\sum_{k=1}^{m} \\|x_{k} - X_{r}(:,k)\\|_{L^{2}(\\Omega)}^{2} = \\sum_{k=1}^{m} \\left( x_{k} - X_{r}(:,k) \\right)^{\\top} M \\left( x_{k} - X_{r}(:,k) \\right),\n$$\n这可以紧凑地写为\n$$\nE_{r}^{2} = \\|X - X_{r}\\|_{M,F}^{2} := \\operatorname{trace}\\!\\left((X - X_{r})^{\\top} M (X - X_{r})\\right).\n$$\n\n仅从质量加权内积、奇异值分解和正交投影的定义出发，推导 $E_{r}^{2}$ 关于 $Y$ 的被忽略奇异值 $\\{\\sigma_{i}\\}_{i=r+1}^{q}$ 的闭式表达式，从而将 POD 截断误差与快照重构误差的 $L^{2}(\\Omega)$ 范数联系起来。你的最终答案必须是一个仅用 $\\{\\sigma_{i}\\}_{i=r+1}^{q}$ 表示的、精确等于 $E_{r}^{2}$ 的解析表达式。",
            "solution": "该问题是有效的，因为它在模型降阶的正常正交分解 (POD) 的既定框架内，提出了一个定义明确的数学推导。所有术语都得到了清晰的定义，并且其前提在科学上和数学上都是合理的。\n\n目标是推导总平方快照重构误差 $E_r^2$ 的闭式表达式。我们从该误差在质量矩阵加权的 Frobenius 范数下的给定定义开始：\n$$\nE_{r}^{2} = \\|X - X_{r}\\|_{M,F}^{2} = \\operatorname{trace}\\!\\left((X - X_{r})^{\\top} M (X - X_{r})\\right)\n$$\n其中 $X \\in \\mathbb{R}^{n \\times m}$ 是快照矩阵，$X_r \\in \\mathbb{R}^{n \\times m}$ 是其秩为 $r$ 的 POD 重构。\n\n质量矩阵 $M$ 是对称正定的，这保证了唯一的对称正定平方根 $M^{1/2}$ 的存在。我们可以通过插入 $M = M^{1/2} M^{1/2}$ 来重写迹的表达式。由于 $M$ 是对称的，所以 $(M^{1/2})^{\\top} = M^{1/2}$。\n$$\nE_{r}^{2} = \\operatorname{trace}\\!\\left((X - X_{r})^{\\top} M^{1/2} M^{1/2} (X - X_{r})\\right) = \\operatorname{trace}\\!\\left(\\left(M^{1/2}(X - X_{r})\\right)^{\\top} \\left(M^{1/2}(X - X_{r})\\right)\\right)\n$$\n该表达式是矩阵 $M^{1/2}(X - X_{r})$ 的标准 Frobenius 范数的平方。\n$$\nE_{r}^{2} = \\|M^{1/2}(X - X_{r})\\|_{F}^{2}\n$$\n现在，我们使用给定的定义来表示范数内的项。重构 $X_r$ 定义为 $X$ 在 POD 空间上的投影：\n$$\nX_{r} = P_{r} X\n$$\n其中投影算子 $P_r$ 由 $P_{r} = \\Psi_{r} \\Psi_{r}^{\\top} M$ 给出。POD 基 $\\Psi_r$ 定义为 $\\Psi_{r} = M^{-1/2} U_{r}$，其中 $U_r$ 包含质量加权快照矩阵 $Y = M^{1/2} X$ 的前 $r$ 个左奇异向量。\n\n让我们将 $\\Psi_r$ 的定义代入 $P_r$ 的表达式中：\n$$\nP_{r} = (M^{-1/2} U_{r}) (\\Psi_{r}^{\\top}) M = (M^{-1/2} U_{r}) (M^{-1/2} U_{r})^{\\top} M = (M^{-1/2} U_{r}) (U_{r}^{\\top} (M^{-1/2})^{\\top}) M\n$$\n由于 $M^{-1/2}$ 是对称的，$(M^{-1/2})^{\\top} = M^{-1/2}$。\n$$\nP_{r} = M^{-1/2} U_{r} U_{r}^{\\top} M^{-1/2} M = M^{-1/2} U_{r} U_{r}^{\\top} M^{1/2}\n$$\n现在我们可以分析项 $M^{1/2}(X - X_r)$：\n$$\nM^{1/2}(X - X_{r}) = M^{1/2}(X - P_{r}X) = M^{1/2}X - M^{1/2}P_{r}X\n$$\n代入 $P_r$ 的表达式：\n$$\nM^{1/2} P_{r} X = M^{1/2} (M^{-1/2} U_{r} U_{r}^{\\top} M^{1/2}) X = (M^{1/2} M^{-1/2}) U_{r} U_{r}^{\\top} (M^{1/2} X) = I U_{r} U_{r}^{\\top} (M^{1/2} X)\n$$\n使用定义 $Y = M^{1/2}X$，我们有：\n$$\nM^{1/2} P_{r} X = U_{r} U_{r}^{\\top} Y\n$$\n因此，误差项变为：\n$$\nM^{1/2}(X - X_{r}) = M^{1/2}X - U_{r} U_{r}^{\\top} Y = Y - U_{r} U_{r}^{\\top} Y\n$$\n问题因此从计算 $X$ 中误差的加权范数，转化为计算 $Y$ 在投影到由 $U_r$ 的列所张成的空间上时误差的标准 Frobenius 范数。\n$$\nE_{r}^{2} = \\|Y - U_{r} U_{r}^{\\top} Y\\|_{F}^{2}\n$$\n矩阵 $U_r U_r^T$ 是到由 $U$ 的前 $r$ 列所张成的子空间上的正交投影算子。我们现在使用 $Y$ 的奇异值分解，即 $Y = U \\Sigma V^{\\top}$。用求和形式表示为：\n$$\nY = \\sum_{i=1}^{q} \\sigma_{i} u_{i} v_{i}^{\\top}\n$$\n其中 $u_i$ 和 $v_i$ 分别是 $U$ 和 $V$ 的第 $i$ 列，$\\sigma_i$ 是奇异值，且 $q = \\min\\{n,m\\}$。列向量 $\\{u_i\\}$ 构成一个标准正交基。$Y$ 在 $\\{u_i\\}_{i=1}^r$ 的张成空间上的投影为：\n$$\nU_{r} U_{r}^{\\top} Y = \\left(\\sum_{j=1}^{r} u_j u_j^{\\top}\\right) \\left(\\sum_{i=1}^{q} \\sigma_{i} u_{i} v_{i}^{\\top}\\right) = \\sum_{j=1}^{r} \\sum_{i=1}^{q} \\sigma_{i} u_{j} (u_{j}^{\\top} u_{i}) v_{i}^{\\top}\n$$\n由于向量 $\\{u_i\\}$ 的标准正交性，我们有 $u_{j}^{\\top} u_{i} = \\delta_{ji}$，其中 $\\delta_{ji}$ 是克罗内克 δ。表达式简化为：\n$$\nU_{r} U_{r}^{\\top} Y = \\sum_{i=1}^{r} \\sigma_{i} u_{i} v_{i}^{\\top}\n$$\n这是 $Y$ 的截断 SVD，也就是 $Y$ 在 Frobenius 范数下的最佳秩 $r$ 近似（Eckart-Young-Mirsky 定理）。投影误差为：\n$$\nY - U_{r} U_{r}^{\\top} Y = \\sum_{i=1}^{q} \\sigma_{i} u_{i} v_{i}^{\\top} - \\sum_{i=1}^{r} \\sigma_{i} u_{i} v_{i}^{\\top} = \\sum_{i=r+1}^{q} \\sigma_{i} u_{i} v_{i}^{\\top}\n$$\n最后，我们计算这个误差矩阵的 Frobenius 范数的平方：\n$$\nE_{r}^{2} = \\left\\|\\sum_{i=r+1}^{q} \\sigma_{i} u_{i} v_{i}^{\\top}\\right\\|_{F}^{2} = \\operatorname{trace}\\!\\left(\\left(\\sum_{j=r+1}^{q} \\sigma_{j} u_{j} v_{j}^{\\top}\\right)^{\\top} \\left(\\sum_{i=r+1}^{q} \\sigma_{i} u_{i} v_{i}^{\\top}\\right)\\right)\n$$\n$$\nE_{r}^{2} = \\operatorname{trace}\\!\\left(\\left(\\sum_{j=r+1}^{q} \\sigma_{j} v_{j} u_{j}^{\\top}\\right) \\left(\\sum_{i=r+1}^{q} \\sigma_{i} u_{i} v_{i}^{\\top}\\right)\\right) = \\operatorname{trace}\\!\\left(\\sum_{j=r+1}^{q} \\sum_{i=r+1}^{q} \\sigma_{j} \\sigma_{i} v_{j} (u_{j}^{\\top} u_{i}) v_{i}^{\\top}\\right)\n$$\n再次使用 $u_{j}^{\\top} u_{i} = \\delta_{ji}$：\n$$\nE_{r}^{2} = \\operatorname{trace}\\!\\left(\\sum_{i=r+1}^{q} \\sigma_{i}^{2} v_{i} v_{i}^{\\top}\\right)\n$$\n根据迹算子的线性性质：\n$$\nE_{r}^{2} = \\sum_{i=r+1}^{q} \\sigma_{i}^{2} \\operatorname{trace}(v_{i} v_{i}^{\\top})\n$$\n使用迹的循环性质，$\\operatorname{trace}(v_{i} v_{i}^{\\top}) = \\operatorname{trace}(v_{i}^{\\top} v_{i})$。由于 $v_i$ 是正交矩阵 $V$ 的一列，它是一个单位向量，所以 $v_{i}^{\\top} v_{i} = 1$。\n$$\nE_{r}^{2} = \\sum_{i=r+1}^{q} \\sigma_{i}^{2} \\cdot 1 = \\sum_{i=r+1}^{q} \\sigma_{i}^{2}\n$$\n因此，在 $L^2(\\Omega)$ 意义下的总平方快照重构误差等于质量加权快照矩阵 $Y$ 的被忽略奇异值的平方和。",
            "answer": "$$\n\\boxed{\\sum_{i=r+1}^{q} \\sigma_{i}^{2}}\n$$"
        },
        {
            "introduction": "为了高效求解非线性参数化偏微分方程，我们常常在降维基框架内使用牛顿法，这需要在每一步计算一个降维雅可比矩阵。对雅可比矩阵本身应用超降维技术（hyper-reduction）是保持计算效率的关键。本练习  聚焦于将离散经验插值法应用于矩阵（MDEIM），以实现降维雅可比矩阵的离线-在线分解。通过完成这一推导，您将学会如何处理许多真实物理和工程问题中出现的复杂非线性项，确保您的降阶模型在处理非线性问题时依然能快速求解。",
            "id": "3438832",
            "problem": "考虑一个参数化的非线性偏微分方程，经过空间半离散化后，得到一个有限维残差 $R(u;\\mu)\\in\\mathbb{R}^{N}$，其中 $u\\in\\mathbb{R}^{N}$ 表示状态向量，$\\mu\\in\\mathcal{P}\\subset\\mathbb{R}^{p}$ 表示参数。求解 $R(u;\\mu)=0$ 的 Newton 法需要雅可比矩阵 $J(u;\\mu)\\in\\mathbb{R}^{N\\times N}$，其元素为 $J_{ij}(u;\\mu)=\\partial R_i(u;\\mu)/\\partial u_j$。假设采用降阶基近似，其试探子空间由 $V\\in\\mathbb{R}^{N\\times n}$ 的列向量张成，测试子空间由 $Z\\in\\mathbb{R}^{N\\times n}$ 的列向量张成（Petrov–Galerkin 设置），因此降阶坐标为 $c\\in\\mathbb{R}^{n}$，状态近似为 $u\\approx Vc$。降阶残差为 $r(c;\\mu)=Z^{T}R(Vc;\\mu)$，降阶雅可比矩阵为 $J_{r}(c;\\mu)=Z^{T}J(Vc;\\mu)V\\in\\mathbb{R}^{n\\times n}$。\n\n假设全雅可比矩阵具有形式为 $J(u;\\mu)=\\sum_{q=1}^{Q_{J}}\\theta_{q}(\\mu)\\,J^{(q)}(u)$ 的仿射参数结构，其中系数函数 $\\theta_{q}:\\mathcal{P}\\to\\mathbb{R}$ 是已知的，而 $J^{(q)}(u)\\in\\mathbb{R}^{N\\times N}$ 依赖于 $u$ 但不直接依赖于 $\\mu$。为实现对 $J_{r}(c;\\mu)$ 的高效在线评估，使用矩阵离散经验插值法 (Matrix Discrete Empirical Interpolation Method, MDEIM)，它是离散经验插值法 (Discrete Empirical Interpolation Method, DEIM) 的一个扩展，并应用于每个算子 $J^{(q)}(u)$。对于每个 $q\\in\\{1,\\dots,Q_{J}\\}$，令 $U_{q}\\in\\mathbb{R}^{N^{2}\\times M_{q}}$ 是从 $\\operatorname{vec}(J^{(q)}(u))$ 的快照中获得的一个列正交基，其中 $\\operatorname{vec}(\\cdot)$ 将矩阵的列堆叠成一个向量；令 $P_{q}\\in\\mathbb{R}^{N^{2}\\times M_{q}}$ 是根据标准 DEIM 贪婪选择规则选择 $\\operatorname{vec}(J^{(q)}(u))$ 的 $M_{q}$ 个条目的采样矩阵。假设 $M_{q}\\ll N^{2}$，并且对于每个 $q$，$P_{q}^{T}U_{q}\\in\\mathbb{R}^{M_{q}\\times M_{q}}$ 都是非奇异的。\n\n从 Petrov–Galerkin 投影和 MDEIM 近似的第一性原理出发，推导降阶雅可比矩阵 $J_{r}(c;\\mu)$ 的离线-在线分解、完全分离的表达式，该表达式用以下各项表示：\n- 参数函数 $\\theta_{q}(\\mu)$，\n- 从 $J^{(q)}(Vc)$ 的 MDEIM 采样中获得的在线系数向量，\n- 以及由 $Z$、$V$ 和 $U_{q}$ 离线构成的预计算降阶算子“切片”。\n\n您的推导必须明确定义您引入的所有中间量，包括 $\\operatorname{vec}(\\cdot)$、$\\operatorname{unvec}(\\cdot)$、采样矩阵和任何标准基向量。最后给出 $J_{r}(c;\\mu)$ 的单一闭式解析表达式，该表达式纯粹用 $\\theta_{q}(\\mu)$、DEIM 采样和基矩阵 $(P_{q},U_{q})$、向量 $c$ 以及一组离线预计算的降阶矩阵来表示。不需要进行数值评估。请提供您的最终表达式作为答案。答案应该是一个没有单位的单一闭式解析表达式。",
            "solution": "用户希望使用矩阵离散经验插值法 (MDEIM) 推导降阶雅可比矩阵 $J_{r}(c;\\mu)$ 的离线-在线分解表达式。\n\n### 步骤 1：提取已知条件\n-   **系统**：一个半离散化的参数化非线性偏微分方程，其残差方程为 $R(u;\\mu)=0$，其中 $R(u;\\mu)\\in\\mathbb{R}^{N}$，$u\\in\\mathbb{R}^{N}$ 是状态向量，$\\mu\\in\\mathcal{P}\\subset\\mathbb{R}^{p}$ 是参数向量。\n-   **全雅可比矩阵**：$J(u;\\mu)\\in\\mathbb{R}^{N\\times N}$，其元素为 $J_{ij}(u;\\mu)=\\partial R_i(u;\\mu)/\\partial u_j$。\n-   **降阶基 (Petrov-Galerkin)**：\n    -   状态近似：$u \\approx Vc$，其中试探基为 $V\\in\\mathbb{R}^{N\\times n}$，降阶坐标为 $c\\in\\mathbb{R}^{n}$。\n    -   测试基：$Z\\in\\mathbb{R}^{N\\times n}$。\n-   **降阶系统**：\n    -   降阶残差：$r(c;\\mu)=Z^{T}R(Vc;\\mu)$。\n    -   降阶雅可比矩阵：$J_{r}(c;\\mu)=Z^{T}J(Vc;\\mu)V\\in\\mathbb{R}^{n\\times n}$。\n-   **仿射雅可比结构**：全雅可比矩阵与参数呈仿射相关，由 $J(u;\\mu)=\\sum_{q=1}^{Q_{J}}\\theta_{q}(\\mu)\\,J^{(q)}(u)$ 给出，其中 $\\theta_{q}:\\mathcal{P}\\to\\mathbb{R}$ 是已知的系数函数，$J^{(q)}(u)\\in\\mathbb{R}^{N\\times N}$ 是与参数无关、仅与状态 $u$ 相关的矩阵值函数。\n-   **矩阵 DEIM (MDEIM) 设置**：对于每个分量 $J^{(q)}(u)$：\n    -   向量化算子 $\\operatorname{vec}(\\cdot)$ 将矩阵的列堆叠成一个单独的列向量。\n    -   一个列正交基 $U_{q}\\in\\mathbb{R}^{N^{2}\\times M_{q}}$ 是从 $\\operatorname{vec}(J^{(q)}(u))$ 的快照中获得的。\n    -   一个采样矩阵 $P_{q}\\in\\mathbb{R}^{N^{2}\\times M_{q}}$ 从一个向量化的矩阵中选择 $M_{q}$ 个条目，其中 $M_{q}\\ll N^{2}$。\n    -   对于每个 $q\\in\\{1,\\dots,Q_{J}\\}$，矩阵 $P_{q}^{T}U_{q}\\in\\mathbb{R}^{M_{q}\\times M_{q}}$ 是非奇异的。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，是适定的、客观且自洽的。它描述了计算科学中用于非线性系统模型降阶的一个标准且重要的过程，特别是将降阶基方法与用于超降阶的 MDEIM 相结合。所有术语和假设在该领域都是标准的。该问题有效，可以求解。\n\n### 步骤 3：推导\n目标是为降阶雅可比矩阵 $J_r(c;\\mu)$ 推导一个计算高效的、离线-在线分解的表达式。\n\n我们从 Petrov-Galerkin 设置下降阶雅可比矩阵的定义开始：\n$$J_{r}(c;\\mu) = Z^{T}J(Vc;\\mu)V$$\n将状态近似 $u \\approx Vc$ 代入全雅可比矩阵的表达式中。考虑到 $J(u;\\mu)$ 的仿射结构，我们有：\n$$J(Vc;\\mu) = \\sum_{q=1}^{Q_{J}}\\theta_{q}(\\mu)\\,J^{(q)}(Vc)$$\n将此代入 $J_r(c;\\mu)$ 的方程中，并利用矩阵乘法的线性性质，可得：\n$$J_{r}(c;\\mu) = Z^{T}\\left(\\sum_{q=1}^{Q_{J}}\\theta_{q}(\\mu)\\,J^{(q)}(Vc)\\right)V = \\sum_{q=1}^{Q_{J}}\\theta_{q}(\\mu)\\left(Z^{T}J^{(q)}(Vc)V\\right)$$\n这个表达式将依赖于参数的部分 $\\theta_q(\\mu)$ 与依赖于状态的部分 $Z^{T}J^{(q)}(Vc)V$ 分离开来。然而，$J^{(q)}(Vc)$ 的计算仍然是昂贵的，因为它需要在每个 Newton 步（在线阶段）构建一个 $N \\times N$ 矩阵。\n\n为减轻这种在线计算负担，我们将矩阵离散经验插值法 (MDEIM) 应用于每个矩阵函数 $J^{(q)}(u)$。MDEIM 将向量化的矩阵 $\\operatorname{vec}(J^{(q)}(u))$ 近似为基向量 $U_q$ 中的线性组合：\n$$\\operatorname{vec}(J^{(q)}(u)) \\approx U_q \\mathbf{d}_q(u)$$\n其中 $\\mathbf{d}_q(u) \\in \\mathbb{R}^{M_q}$ 是一个待定的系数向量。DEIM 的核心思想是通过强制近似在 $M_q$ 个索引处与精确向量匹配来确定这些系数。这些索引由采样矩阵 $P_q$ 指定。条件是：\n$$P_q^T \\operatorname{vec}(J^{(q)}(u)) = P_q^T (U_q \\mathbf{d}_q(u)) = (P_q^T U_q) \\mathbf{d}_q(u)$$\n由于假设 $P_q^T U_q$ 是非奇异的，我们可以解出系数向量 $\\mathbf{d}_q(u)$：\n$$\\mathbf{d}_q(u) = (P_q^T U_q)^{-1} P_q^T \\operatorname{vec}(J^{(q)}(u))$$\n将此代回 $\\operatorname{vec}(J^{(q)}(u))$ 的近似式中，我们得到：\n$$\\operatorname{vec}(J^{(q)}(u)) \\approx U_q (P_q^T U_q)^{-1} P_q^T \\operatorname{vec}(J^{(q)}(u))$$\n为了回到矩阵形式，我们引入算子 $\\operatorname{unvec}(\\cdot)$，它是 $\\operatorname{vec}(\\cdot)$ 的逆运算，将一个 $\\mathbb{R}^{N^2}$ 中的向量重塑为 $\\mathbb{R}^{N \\times N}$ 中的矩阵。设 $U_{q,i} \\in \\mathbb{R}^{N^2}$ 是基矩阵 $U_q$ 的第 $i$ 列。矩阵 $J^{(q)}(u)$ 的 MDEIM 近似可以写成一个和式：\n$$J^{(q)}(u) \\approx \\operatorname{unvec}\\left( \\sum_{i=1}^{M_q} \\left[ \\mathbf{d}_q(u) \\right]_i U_{q,i} \\right) = \\sum_{i=1}^{M_q} \\left[ \\mathbf{d}_q(u) \\right]_i \\operatorname{unvec}(U_{q,i})$$\n其中 $[\\mathbf{d}_q(u)]_i$ 是系数向量 $\\mathbf{d}_q(u)$ 的第 $i$ 个分量。\n设 $e_i \\in \\mathbb{R}^{M_q}$ 是第 $i$ 个标准基向量。那么 $[\\mathbf{d}_q(u)]_i = e_i^T \\mathbf{d}_q(u)$。在降阶状态 $u = Vc$ 下应用此式，$J^{(q)}(Vc)$ 的 MDEIM 近似为：\n$$J^{(q)}(Vc) \\approx \\sum_{i=1}^{M_q} \\left( e_i^T (P_q^T U_q)^{-1} P_q^T \\operatorname{vec}(J^{(q)}(Vc)) \\right) \\operatorname{unvec}(U_{q,i})$$\n现在，我们将此近似代入项 $Z^{T}J^{(q)}(Vc)V$ 中：\n$$Z^{T}J^{(q)}(Vc)V \\approx Z^{T} \\left( \\sum_{i=1}^{M_q} \\left( e_i^T (P_q^T U_q)^{-1} P_q^T \\operatorname{vec}(J^{(q)}(Vc)) \\right) \\operatorname{unvec}(U_{q,i}) \\right) V$$\n大括号中的项对于每个 $i$ 都是一个标量系数。我们可以将其从矩阵乘积中提出来：\n$$Z^{T}J^{(q)}(Vc)V \\approx \\sum_{i=1}^{M_q} \\left( e_i^T (P_q^T U_q)^{-1} P_q^T \\operatorname{vec}(J^{(q)}(Vc)) \\right) \\left( Z^T \\operatorname{unvec}(U_{q,i}) V \\right)$$\n最后，我们将此代回降阶雅可比矩阵 $J_r(c;\\mu)$ 的表达式中：\n$$J_r(c;\\mu) \\approx \\sum_{q=1}^{Q_J} \\theta_q(\\mu) \\left[ \\sum_{i=1}^{M_q} \\left( e_i^T (P_q^T U_q)^{-1} P_q^T \\operatorname{vec}(J^{(q)}(Vc)) \\right) \\left( Z^T \\operatorname{unvec}(U_{q,i}) V \\right) \\right]$$\n此表达式现在为高效的在线评估进行了完全分解。\n-   **离线阶段**：对于每个 $q \\in \\{1, \\dots, Q_J\\}$，我们预计算并存储：\n    1.  逆矩阵 $(P_q^T U_q)^{-1} \\in \\mathbb{R}^{M_q \\times M_q}$。\n    2.  $M_q$ 个降阶算子“切片”的集合：$\\mathbb{J}_{q,i} = Z^T \\operatorname{unvec}(U_{q,i}) V \\in \\mathbb{R}^{n \\times n}$，其中 $i=1, \\dots, M_q$。\n-   **在线阶段**：对于给定的参数 $\\mu$ 和降阶状态 $c$：\n    1.  评估参数函数 $\\theta_q(\\mu)$。\n    2.  对于每个 $q$，计算 $J^{(q)}(Vc)$ 所需的 $M_q$ 个条目，以构成向量 $\\mathbf{j}_q(c) = P_q^T \\operatorname{vec}(J^{(q)}(Vc))$。由于 $M_q \\ll N^2$，这个计算成本很低。\n    3.  对于每个 $q$，计算在线系数 $[(P_q^T U_q)^{-1} \\mathbf{j}_q(c)]_i$。\n    4.  通过将预计算的切片与在线系数加权求和来组装 $J_r(c;\\mu)$。\n\n最终推导出的表达式，使用 $e_i \\in \\mathbb{R}^{M_q}$ 表示第 $i$ 个标准基向量，$U_{q,i} \\in \\mathbb{R}^{N^2}$ 表示 $U_q$ 的第 $i$ 列，即为降阶雅可比矩阵的 MDEIM 近似。",
            "answer": "$$\\boxed{\\sum_{q=1}^{Q_{J}} \\theta_q(\\mu) \\sum_{i=1}^{M_q} \\left( e_i^T (P_q^T U_q)^{-1} P_q^T \\operatorname{vec}(J^{(q)}(Vc)) \\right) \\left( Z^T \\operatorname{unvec}(U_{q,i}) V \\right)}$$"
        }
    ]
}