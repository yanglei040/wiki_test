{
    "hands_on_practices": [
        {
            "introduction": "Dynamic Mode Decomposition (DMD) excels at extracting dynamically relevant patterns from data, but its effectiveness hinges on the assumption of underlying linear dynamics. This first exercise provides a foundational test of the DMD algorithm against analytically known solutions from linear partial differential equations. By implementing DMD on this \"perfect\" data, you will not only verify its accuracy in an ideal setting but also critically investigate how common data preprocessing steps, such as scaling and normalization, impact the results, revealing the core sensitivities of the method .",
            "id": "3383195",
            "problem": "You are asked to implement a program that constructs a suite of linear, one-dimensional, periodic, constant-coefficient partial differential equations (PDEs) whose Koopman eigenfunctions are analytically known, generates exact snapshots from their semigroup evolution, applies Dynamic Mode Decomposition (DMD), and quantitatively tests the impact of snapshot normalization and uniform scaling on the recovered spectra. All variables are non-dimensional and unitless.\n\nFundamental base and setting: Consider linear PDEs on a periodic spatial domain $x \\in [0,2\\pi)$ with spatial Fourier eigenfunctions $\\varphi_k(x) = e^{i k x}$ for $k \\in \\mathbb{Z}$. For linear, constant-coefficient PDEs, the evolution operator $e^{t \\mathcal{L}}$ is diagonal on the Fourier basis with exact semigroup evolution\n$$\nu(x,t) \\;=\\; \\sum_{j=1}^{r} a_j \\, e^{\\lambda_{k_j} t} \\, e^{i k_j x},\n$$\nwhere $a_j \\in \\mathbb{C}$ are initial amplitudes, $k_j$ are selected spatial wavenumbers, and $\\lambda_{k_j}$ are the Koopman generator eigenvalues (temporal exponents). For the three PDE families used here:\n- Diffusion: $u_t = \\nu u_{xx}$, the eigenvalues are $\\lambda_k = -\\nu k^2$.\n- Advection: $u_t + c u_x = 0$, the eigenvalues are $\\lambda_k = - i c k$.\n- Reaction–diffusion: $u_t = \\alpha u + \\nu u_{xx}$, the eigenvalues are $\\lambda_k = \\alpha - \\nu k^2$.\n\nDynamic Mode Decomposition (DMD): Given snapshots $\\{u(\\cdot,t_n)\\}_{n=0}^{m-1}$ at uniform sampling interval $\\Delta t$, define data matrices $X = [u(\\cdot,t_0), \\dots, u(\\cdot,t_{m-2})]$ and $X' = [u(\\cdot,t_1), \\dots, u(\\cdot,t_{m-1})]$. For a linear evolution $u_{n+1} = A \\, u_n$ with $A = e^{\\mathcal{L}\\Delta t}$, exact data satisfy $X' = A X$. DMD computes a low-rank approximation of $A$ and its eigenvalues $\\{\\mu_j\\}$; the continuous-time exponents are then recovered by $\\lambda_j^{(\\mathrm{DMD})} = \\frac{1}{\\Delta t} \\log \\mu_j$, using the principal branch of the complex logarithm (radians).\n\nPreprocessing variations: You must implement three snapshot preprocessing choices before assembling $X$ and $X'$:\n1. Raw snapshots: use $u(\\cdot,t_n)$ as generated.\n2. Uniform scaling: multiply all snapshots by the same constant $s \\in \\mathbb{R}$.\n3. Column normalization: rescale each snapshot $u(\\cdot,t_n)$ by its spatial $\\ell^2$ norm to have unit norm. Note that this rescaling generally destroys the existence of a single linear map $A$ relating consecutive snapshots unless the norms are constant across time.\n\nTask: Implement a program that, for each specified test case, constructs exact snapshots by spectral synthesis on a uniform spatial grid, applies the chosen preprocessing, runs DMD with a specified rank $r$, converts discrete-time DMD eigenvalues to continuous-time exponents, and compares the recovered set $\\{\\lambda_j^{(\\mathrm{DMD})}\\}_{j=1}^r$ to the analytic set $\\{\\lambda_{k_j}\\}_{j=1}^r$ by optimal matching (permutation) that minimizes the average absolute complex discrepancy. A test passes if the mean absolute error is less than or equal to a specified tolerance $\\varepsilon$.\n\nAngle unit: When any angles arise from complex phases, all angles are in radians.\n\nFinal output format: Your program should produce a single line of output containing the boolean results for all test cases as a comma-separated list enclosed in square brackets (e.g., \"[True,False,True]\"). No other text should be printed.\n\nTest suite: Use the following six test cases. In each case, the spatial grid has $N_x = 128$ points uniformly over $[0,2\\pi)$, all quantities are unitless, and the DMD rank is $r$ equal to the number of excited modes.\n\n- Test 1 (Diffusion, raw):\n  - PDE: $u_t = \\nu u_{xx}$ with $\\nu = 0.1$.\n  - Modes $k = [1, 3]$, amplitudes $a = [1.0, 0.3]$.\n  - Time step $\\Delta t = 0.01$, number of snapshots $m = 60$.\n  - Preprocessing: raw. Tolerance $\\varepsilon = 10^{-6}$.\n\n- Test 2 (Diffusion, uniform scaling invariance):\n  - Same as Test 1 but multiply all snapshots by $s = 5.0$ before forming $X$ and $X'$.\n  - Preprocessing: uniform scaling. Tolerance $\\varepsilon = 10^{-6}$.\n\n- Test 3 (Diffusion, column normalization failure on single decaying mode):\n  - PDE: $u_t = \\nu u_{xx}$ with $\\nu = 0.1$.\n  - Modes $k = [2]$, amplitudes $a = [1.0]$.\n  - Time step $\\Delta t = 0.01$, number of snapshots $m = 60$.\n  - Preprocessing: column normalization to unit $\\ell^2$ norm per snapshot. Tolerance $\\varepsilon = 10^{-3}$.\n\n- Test 4 (Advection, raw):\n  - PDE: $u_t + c u_x = 0$ with $c = 2.0$.\n  - Modes $k = [3]$, amplitudes $a = [0.8]$.\n  - Time step $\\Delta t = 0.02$, number of snapshots $m = 80$.\n  - Preprocessing: raw. Tolerance $\\varepsilon = 10^{-6}$.\n\n- Test 5 (Reaction–diffusion, raw):\n  - PDE: $u_t = \\alpha u + \\nu u_{xx}$ with $\\alpha = 0.05$, $\\nu = 0.02$.\n  - Modes $k = [1, 4]$, amplitudes $a = [1.0, 0.2]$.\n  - Time step $\\Delta t = 0.01$, number of snapshots $m = 60$.\n  - Preprocessing: raw. Tolerance $\\varepsilon = 10^{-6}$.\n\n- Test 6 (Reaction–diffusion, column normalization impact on mixed growth/decay):\n  - Same parameters as Test 5.\n  - Preprocessing: column normalization to unit $\\ell^2$ norm per snapshot. Tolerance $\\varepsilon = 10^{-3}$.\n\nRequired output: Your program should run all six tests in the order listed and print exactly one line with a Python-style list of six booleans indicating whether the DMD-recovered continuous-time exponents match the analytic eigenvalues within tolerance, after optimal matching of eigenvalues:\n- The line must have the form \"[b1,b2,b3,b4,b5,b6]\" where each bi is either True or False.",
            "solution": "The problem requires the implementation and verification of the Dynamic Mode Decomposition (DMD) algorithm on synthetically generated data from linear partial differential equations (PDEs). The core of the task is to assess the impact of different data preprocessing steps—specifically, no preprocessing (raw), uniform scaling, and per-snapshot normalization—on the accuracy of the DMD-recovered spectrum.\n\nFirst, we establish the analytical foundation for the data generation. The problem considers three families of one-dimensional, linear, constant-coefficient PDEs on a periodic domain $x \\in [0, 2\\pi)$:\n1.  Diffusion equation: $u_t = \\nu u_{xx}$\n2.  Advection equation: $u_t = -c u_x$\n3.  Reaction-diffusion equation: $u_t = \\alpha u + \\nu u_{xx}$\n\nFor such PDEs, the spatial Fourier modes $\\varphi_k(x) = e^{i k x}$ with wavenumber $k \\in \\mathbb{Z}$ are eigenfunctions of the spatial differential operator $\\mathcal{L}$. Applying $\\mathcal{L}$ to $\\varphi_k(x)$ yields $\\mathcal{L} e^{i k x} = \\lambda_k e^{i k x}$, where $\\lambda_k$ is the corresponding eigenvalue of the generator $\\mathcal{L}$. The evolution of an initial condition is governed by the semigroup $e^{t\\mathcal{L}}$. For the given PDE families, the eigenvalues $\\lambda_k$ are:\n-   Diffusion: Substituting $u = e^{i k x}$ into $u_t = \\nu u_{xx}$ leads to $\\lambda_k u = \\nu (i k)^2 u$, so $\\lambda_k = -\\nu k^2$.\n-   Advection: Substituting into $u_t = -c u_x$ gives $\\lambda_k u = -c(i k) u$, so $\\lambda_k = -i c k$.\n-   Reaction-diffusion: Substituting into $u_t = \\alpha u + \\nu u_{xx}$ yields $\\lambda_k u = \\alpha u + \\nu(i k)^2 u$, so $\\lambda_k = \\alpha - \\nu k^2$.\n\nThe solution to the PDE with an initial condition expressed as a superposition of a finite number of modes, $u(x,0) = \\sum_{j=1}^{r} a_j e^{i k_j x}$, is given by the exact formula:\n$$\nu(x,t) = \\sum_{j=1}^{r} a_j e^{\\lambda_{k_j} t} e^{i k_j x}\n$$\nThis formula is used to generate a sequence of \"snapshots\" of the system state, $\\{u(\\cdot, t_n)\\}_{n=0}^{m-1}$, at discrete times $t_n = n \\Delta t$. These snapshots form the input to the DMD algorithm.\n\nThe DMD algorithm aims to find a linear operator $A$ that best approximates the evolution between snapshots, i.e., $u_{n+1} \\approx A u_n$, where $u_n$ is the state vector at time $t_n$. The data is arranged into two matrices, $X = [u_0, u_1, \\dots, u_{m-2}]$ and $X' = [u_1, u_2, \\dots, u_{m-1}]$. The governing relationship is $X' \\approx A X$. DMD computes a low-rank approximation of $A$. The standard algorithm proceeds as follows:\n1.  Compute the Singular Value Decomposition (SVD) of the matrix $X$, truncated to a specified rank $r$: $X \\approx U_r \\Sigma_r V_r^*$, where $U_r \\in \\mathbb{C}^{N_x \\times r}$, $\\Sigma_r \\in \\mathbb{R}^{r \\times r}$ is a diagonal matrix of singular values, and $V_r \\in \\mathbb{C}^{(m-1) \\times r}$. The columns of $U_r$ are the Proper Orthogonal Decomposition (POD) modes.\n2.  The low-rank approximation of the operator $A$ is constructed in the basis of POD modes. The reduced operator $\\tilde{A} \\in \\mathbb{C}^{r \\times r}$ is computed as $\\tilde{A} = U_r^* X' V_r \\Sigma_r^{-1}$.\n3.  The eigenvalues $\\{\\mu_j\\}_{j=1}^r$ of $\\tilde{A}$ approximate the eigenvalues of the full operator $A$. These are the discrete-time DMD eigenvalues.\n4.  The continuous-time eigenvalues (DMD exponents), which correspond to the PDE's generator eigenvalues $\\{\\lambda_k\\}$, are recovered using the relationship $\\mu_j = e^{\\lambda_j^{(\\mathrm{DMD})} \\Delta t}$. This gives $\\lambda_j^{(\\mathrm{DMD})} = \\frac{1}{\\Delta t} \\log(\\mu_j)$, where the principal branch of the complex logarithm is used.\n\nThe problem investigates three preprocessing scenarios:\n1.  **Raw snapshots**: $X$ and $X'$ are constructed directly from the generated $u(\\cdot, t_n)$. Since the underlying dynamics are perfectly linear, DMD is expected to recover the analytic eigenvalues $\\{\\lambda_{k_j}\\}$ with high accuracy, limited only by floating-point precision.\n2.  **Uniform scaling**: All snapshots are multiplied by a constant $s \\in \\mathbb{R}$. The new data matrices are $sX$ and $sX'$. The operator equation becomes $sX' = A(sX)$, which simplifies to $X' = AX$. The underlying operator $A$ is unchanged. Therefore, DMD should be invariant to this transformation and produce the same eigenvalues as the raw case.\n3.  **Column normalization**: Each snapshot $u_n$ is normalized by its spatial $\\ell^2$ norm, $v_n = u_n / \\|u_n\\|_2$. The evolution from $v_n$ to $v_{n+1}$ is given by $v_{n+1} = \\frac{u_{n+1}}{\\|u_{n+1}\\|_2} = \\frac{A u_n}{\\|A u_n\\|_2} = \\frac{\\|u_n\\|_2}{\\|A u_n\\|_2} A v_n$. This map $v_n \\mapsto v_{n+1}$ is linear if and only if the scaling factor $\\frac{\\|u_n\\|_2}{\\|A u_n\\|_2}$ is constant for all $n$. This occurs if all active modes share the same growth/decay rate. If modes have different real parts of their eigenvalues (e.g., a mix of growing and decaying modes), this condition is violated. The underlying dynamics of the normalized data are no longer described by a single time-invariant linear operator, and DMD is expected to produce inaccurate eigenvalues. In the special case of a single mode, $u_n = c e^{\\lambda t_n} \\phi_k$, the norm is $\\|u_n\\|_2 \\propto e^{\\text{Re}(\\lambda) t_n}$. Normalization removes all amplitude information, replacing it with a constant. The resulting DMD eigenvalue will have a zero real part, failing to capture any growth or decay.\n\nFinally, to compare the set of $r$ recovered eigenvalues $\\{\\lambda_j^{(\\mathrm{DMD})}\\}$ with the $r$ analytical eigenvalues $\\{\\lambda_{k_j}\\}$, we must find the optimal pairing. This is an assignment problem. We compute a cost matrix $C$ where $C_{ij} = |\\lambda_{k_i} - \\lambda_j^{(\\mathrm{DMD})}|$. We then find the permutation $\\pi$ of the indices $\\{1, \\dots, r\\}$ that minimizes the total discrepancy, $\\sum_{j=1}^r |\\lambda_{k_j} - \\lambda_{\\pi(j)}^{(\\mathrm{DMD})}|$. The mean absolute error is this minimum sum divided by $r$. This error is then compared against the specified tolerance $\\varepsilon$ to determine if a test passes.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef solve():\n    \"\"\"\n    Main function to run the suite of DMD tests.\n    \"\"\"\n    test_cases = [\n        # Test 1: Diffusion, raw\n        {'pde': 'diffusion', 'params': {'nu': 0.1},\n         'modes': {'k': [1, 3], 'a': [1.0, 0.3]},\n         'time': {'dt': 0.01, 'm': 60},\n         'preprocess': {'type': 'raw'},\n         'tolerance': 1e-6},\n        # Test 2: Diffusion, uniform scaling\n        {'pde': 'diffusion', 'params': {'nu': 0.1},\n         'modes': {'k': [1, 3], 'a': [1.0, 0.3]},\n         'time': {'dt': 0.01, 'm': 60},\n         'preprocess': {'type': 'uniform_scaling', 's': 5.0},\n         'tolerance': 1e-6},\n        # Test 3: Diffusion, column normalization\n        {'pde': 'diffusion', 'params': {'nu': 0.1},\n         'modes': {'k': [2], 'a': [1.0]},\n         'time': {'dt': 0.01, 'm': 60},\n         'preprocess': {'type': 'column_norm'},\n         'tolerance': 1e-3},\n        # Test 4: Advection, raw\n        {'pde': 'advection', 'params': {'c': 2.0},\n         'modes': {'k': [3], 'a': [0.8]},\n         'time': {'dt': 0.02, 'm': 80},\n         'preprocess': {'type': 'raw'},\n         'tolerance': 1e-6},\n        # Test 5: Reaction-diffusion, raw\n        {'pde': 'reaction_diffusion', 'params': {'alpha': 0.05, 'nu': 0.02},\n         'modes': {'k': [1, 4], 'a': [1.0, 0.2]},\n         'time': {'dt': 0.01, 'm': 60},\n         'preprocess': {'type': 'raw'},\n         'tolerance': 1e-6},\n        # Test 6: Reaction-diffusion, column normalization\n        {'pde': 'reaction_diffusion', 'params': {'alpha': 0.05, 'nu': 0.02},\n         'modes': {'k': [1, 4], 'a': [1.0, 0.2]},\n         'time': {'dt': 0.01, 'm': 60},\n         'preprocess': {'type': 'column_norm'},\n         'tolerance': 1e-3},\n    ]\n\n    results = []\n    Nx = 128\n    x = np.linspace(0, 2 * np.pi, Nx, endpoint=False)\n\n    for case in test_cases:\n        # 1. Get parameters and compute analytic eigenvalues\n        pde_type = case['pde']\n        params = case['params']\n        k_values = np.array(case['modes']['k'])\n        a_values = np.array(case['modes']['a'])\n        dt = case['time']['dt']\n        m = case['time']['m']\n        r = len(k_values)\n        \n        analytic_lambdas = []\n        if pde_type == 'diffusion':\n            nu = params['nu']\n            analytic_lambdas = -nu * k_values**2\n        elif pde_type == 'advection':\n            c = params['c']\n            analytic_lambdas = -1j * c * k_values\n        elif pde_type == 'reaction_diffusion':\n            alpha = params['alpha']\n            nu = params['nu']\n            analytic_lambdas = alpha - nu * k_values**2\n        \n        # 2. Generate snapshots\n        times = np.arange(m) * dt\n        snapshots = np.zeros((Nx, m), dtype=complex)\n        for i in range(r):\n            k = k_values[i]\n            a = a_values[i]\n            lambda_k = analytic_lambdas[i]\n            # Evolve each mode and add to total solution\n            temporal_evolution = np.exp(lambda_k * times)\n            spatial_mode = np.exp(1j * k * x)\n            snapshots += a * np.outer(spatial_mode, temporal_evolution)\n\n        # 3. Preprocess snapshots\n        preprocess_info = case['preprocess']\n        if preprocess_info['type'] == 'uniform_scaling':\n            snapshots *= preprocess_info['s']\n        elif preprocess_info['type'] == 'column_norm':\n            norms = np.linalg.norm(snapshots, axis=0)\n            # Avoid division by zero for null snapshots, though not expected here\n            non_zero_norms = norms  1e-12\n            snapshots[:, non_zero_norms] /= norms[non_zero_norms]\n\n        # 4. Perform DMD\n        X = snapshots[:, :-1]\n        X_prime = snapshots[:, 1:]\n        \n        # SVD of X, truncated to rank r\n        U, S, Vh = np.linalg.svd(X, full_matrices=False)\n        Ur = U[:, :r]\n        Sr = S[:r]\n        Vr = Vh[:r, :].conj().T\n        \n        # Build reduced operator A_tilde\n        A_tilde = Ur.conj().T @ X_prime @ Vr @ np.diag(1 / Sr)\n        \n        # Eigenvalues of A_tilde (discrete-time)\n        mu_dmd = np.linalg.eigvals(A_tilde)\n        \n        # Convert to continuous-time eigenvalues\n        lambda_dmd = np.log(mu_dmd) / dt\n\n        # 5. Compare with analytic eigenvalues\n        # Create a cost matrix for the assignment problem\n        cost_matrix = np.abs(np.subtract.outer(analytic_lambdas, lambda_dmd))\n        \n        # Find optimal matching to minimize total error\n        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n        \n        # Calculate mean absolute error of the optimal matching\n        min_error_sum = cost_matrix[row_ind, col_ind].sum()\n        mean_abs_error = min_error_sum / r\n        \n        # 6. Check against tolerance\n        results.append(mean_abs_error = case['tolerance'])\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Moving from ideal theory to practical application, we must confront challenges inherent in data acquisition. One of the most critical is temporal aliasing, where high-frequency dynamics are misrepresented as lower frequencies due to insufficient sampling rates, a direct consequence of the Nyquist-Shannon sampling theorem. This practice problem leads you through a hands-on demonstration of how aliasing can corrupt DMD frequency estimates and then equips you with a powerful multi-rate sampling strategy to unambiguously recover the true frequencies from aliased data .",
            "id": "3383136",
            "problem": "You are given a one-dimensional spatially periodic field and asked to use Dynamic Mode Decomposition (DMD; Dynamic Mode Decomposition) to expose temporal aliasing and then mitigate it using a multi-rate approach. Consider the traveling-wave solution $u(x,t)=\\sin(kx-\\omega t)$, which is a classical harmonic solution of the linear constant-coefficient wave equation on a periodic domain. Snapshots of the field are collected at equispaced times with sampling interval $\\Delta t$, forming a sequence that can be modeled as a linear time-invariant discrete-time evolution on the snapshot space. In Dynamic Mode Decomposition, one seeks a linear operator whose action maps one snapshot to the next, and then infers its spectral properties. For harmonic time dependence, the discrete-time eigenvalues lie on the unit circle, and their arguments encode the sampled angular frequency. However, when the sampling interval is large, the principal argument is confined to $(-\\pi,\\pi]$, yielding a wrapped, aliased estimate of the continuous-time angular frequency. Sampling theory implies that aliasing arises when the true angular frequency exceeds the Nyquist angular frequency $\\omega_{\\mathrm{Nyq}}=\\pi/\\Delta t$.\n\nStarting from this base, derive and implement the following:\n\n- A simulator for $u(x,t)=\\sin(kx-\\omega t)$ on a periodic spatial grid $x\\in[0,2\\pi]$ with $N_x$ points, producing a snapshot matrix whose columns are $u(x,t_j)$ for times $t_j=j\\Delta t$.\n- A Dynamic Mode Decomposition estimator that, given snapshots at uniform sampling interval $\\Delta t$, returns a single angular frequency estimate. Use a rank-$2$ truncation appropriate for a single real sinusoid. For uniform sampling, let the estimated discrete-time eigenvalue be represented by a complex number with unit magnitude, whose principal argument (in radians) lies in $(-\\pi,\\pi]$; convert this to a continuous-time angular frequency by dividing the principal argument by $\\Delta t$ and taking the magnitude.\n- A multi-rate mitigation procedure that uses two uniform time series of snapshots with different sampling intervals $\\Delta t_1$ and $\\Delta t_2$ of the same field $u(x,t)$ (same $k$ and $\\omega$). Let the two principal arguments be $\\theta_1$ and $\\theta_2$ respectively. The true angular frequency satisfies $\\omega\\Delta t_1=\\theta_1+2\\pi n_1$ and $\\omega\\Delta t_2=\\theta_2+2\\pi n_2$ for some integers $n_1$ and $n_2$. Derive an algorithm to recover $\\omega$ by searching integer pairs $(n_1,n_2)$ that make the two expressions consistent, and return the smallest positive consistent $\\omega$.\n\nUnits and angles:\n- All angular quantities must be in radians, and all angular frequencies must be expressed in radians per second (rad/s).\n- Use radians for all angles.\n\nYour program must implement the above and run the following test suite, computing the DMD-estimated angular frequency for single-rate cases and the unwrapped angular frequency for multi-rate cases. For each test case, report the absolute error between the estimated and true angular frequency, in radians per second.\n\nTest suite:\n- Case A (happy path, no aliasing): $k=3$, $\\omega=12.8\\,\\mathrm{rad/s}$, $\\Delta t=0.01\\,\\mathrm{s}$, $N_x=128$, $M=80$ snapshots.\n- Case B (aliasing on coarse sampling): $k=3$, $\\omega=40.0\\,\\mathrm{rad/s}$, $\\Delta t=0.2\\,\\mathrm{s}$, $N_x=128$, $M=80$ snapshots. The DMD estimate will be aliased; report the error relative to the true $\\omega$.\n- Case C (multi-rate mitigation of aliasing): $k=3$, $\\omega=40.0\\,\\mathrm{rad/s}$, $\\Delta t_1=0.2\\,\\mathrm{s}$, $\\Delta t_2=0.22\\,\\mathrm{s}$, $N_x=128$, $M=80$ snapshots for each rate. Use the multi-rate algorithm to recover the unwrapped $\\omega$ and report the error.\n- Case D (near Nyquist boundary): $k=3$, $\\omega=15.5\\,\\mathrm{rad/s}$, $\\Delta t=0.2\\,\\mathrm{s}$, $N_x=128$, $M=80$ snapshots. Report the error of the single-rate DMD estimate.\n- Case E (strong aliasing, multi-rate mitigation): $k=5$, $\\omega=100.0\\,\\mathrm{rad/s}$, $\\Delta t_1=0.2\\,\\mathrm{s}$, $\\Delta t_2=0.19\\,\\mathrm{s}$, $N_x=128$, $M=100$ snapshots for each rate. Use the multi-rate algorithm and report the error.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of Cases A through E, where each entry is the absolute error in radians per second. For example, a valid output looks like $[e_A,e_B,e_C,e_D,e_E]$ with each $e_\\cdot$ a floating-point number in radians per second.",
            "solution": "The user has provided a valid problem statement grounded in the principles of numerical analysis, signal processing, and the study of partial differential equations. The task is to demonstrate and mitigate temporal aliasing in the context of Dynamic Mode Decomposition (DMD). I will construct the solution by first detailing the data generation process, then the DMD algorithm, and finally the multi-rate aliasing mitigation procedure.\n\n### 1. Field Simulation\nThe problem considers a one-dimensional traveling wave solution, $u(x,t) = \\sin(kx - \\omega t)$, on a spatially periodic domain $x \\in [0, 2\\pi]$. To simulate this field, we first discretize the spatial domain into $N_x$ equidistant points, $x_i = \\frac{2\\pi i}{N_x}$ for $i=0, 1, \\dots, N_x-1$. Snapshots of the field are taken at discrete time instances $t_j = j\\Delta t$ for $j=0, 1, \\dots, M-1$, where $\\Delta t$ is the sampling interval and $M$ is the number of snapshots.\n\nA single snapshot is a vector $s_j \\in \\mathbb{R}^{N_x}$ whose components are $s_j(i) = u(x_i, t_j) = \\sin(kx_i - \\omega t_j)$. The collection of all snapshots forms the snapshot matrix $S \\in \\mathbb{R}^{N_x \\times M}$, where the $j$-th column is the snapshot vector $s_j$.\n$$\nS = [s_0, s_1, \\dots, s_{M-1}]\n$$\n\n### 2. Standard Dynamic Mode Decomposition (DMD)\nDMD is a data-driven method to find a best-fit linear operator $A$ that approximates the evolution between snapshots: $s_{j+1} \\approx A s_j$. The spectral properties of $A$ (eigenvalues and eigenvectors, called DMD modes) reveal the underlying dynamics' frequencies and spatial structures.\n\nThe procedure is as follows:\n1.  Construct two matrices from the snapshot data: $X = [s_0, s_1, \\dots, s_{M-2}]$ and $Y = [s_1, s_2, \\dots, s_{M-1}]$. The governing relation is $Y \\approx AX$.\n2.  The operator $A$ is estimated as $A = YX^\\dagger$, where $X^\\dagger$ is the Moore-Penrose pseudoinverse of $X$. Since $A$ can be very large ($N_x \\times N_x$), we typically do not form it explicitly. Instead, we project the problem onto a low-dimensional subspace defined by the dominant Proper Orthogonal Decomposition (POD) modes of $X$.\n3.  Compute the Singular Value Decomposition (SVD) of $X = U\\Sigma V^*$. The problem specifies a rank-$r=2$ truncation, which is appropriate for a single real-valued sinusoid (which is a sum of two complex exponentials).\n    $$\n    X \\approx U_r \\Sigma_r V_r^*\n    $$\n    where $U_r \\in \\mathbb{R}^{N_x \\times r}$, $\\Sigma_r \\in \\mathbb{R}^{r \\times r}$, and $V_r \\in \\mathbb{C}^{(M-1) \\times r}$.\n4.  The high-dimensional operator $A$ is projected onto the subspace spanned by the columns of $U_r$ to obtain a small $r \\times r$ matrix $\\tilde{A}$:\n    $$\n    \\tilde{A} = U_r^* A U_r = U_r^* (Y V_r \\Sigma_r^{-1} U_r^*) U_r = U_r^* Y V_r \\Sigma_r^{-1}\n    $$\n5.  The eigenvalues of $\\tilde{A}$, denoted by $\\lambda_k$, approximate the dominant eigenvalues of the full operator $A$. These are the discrete-time DMD eigenvalues. For a traveling wave $u(x,t)=\\sin(kx-\\omega t)$, the underlying dynamics involve $e^{i\\omega t}$ and $e^{-i\\omega t}$. The discrete-time evolution operators are $e^{i\\omega\\Delta t}$ and $e^{-i\\omega\\Delta t}$. The DMD algorithm, with $r=2$, will find a pair of complex conjugate eigenvalues that approximate these values.\n6.  Each discrete-time eigenvalue $\\lambda$ is related to a continuous-time eigenvalue (frequency) $\\Omega$ by $\\lambda = e^{\\Omega \\Delta t}$. Thus, $\\Omega = \\frac{\\log(\\lambda)}{\\Delta t}$. The imaginary part of $\\Omega$ corresponds to the angular frequency.\n7.  The problem defines the estimated angular frequency $\\omega_{\\text{est}}$ based on the principal argument $\\theta = \\arg(\\lambda) \\in (-\\pi, \\pi]$ of a DMD eigenvalue:\n    $$\n    \\omega_{\\text{est}} = \\frac{|\\theta|}{\\Delta t}\n    $$\n    This estimate is subject to aliasing. If the true frequency $\\omega$ exceeds the Nyquist frequency $\\omega_{\\text{Nyq}} = \\pi/\\Delta t$, the estimated $\\omega_{\\text{est}}$ will be a \"wrapped\" or aliased value, different from the true $\\omega$.\n\n### 3. Multi-Rate Aliasing Mitigation\nThe core idea is to use two datasets sampled at different rates, $\\Delta t_1$ and $\\Delta t_2$, to resolve the ambiguity caused by aliasing. The problem states the relationships between the true angular frequency $\\omega  0$, the sampling intervals, and the principal arguments $\\theta_1, \\theta_2 \\in (-\\pi, \\pi]$ from the DMD analysis of each dataset:\n$$\n\\omega \\Delta t_1 = \\theta_1 + 2\\pi n_1 \\\\\n\\omega \\Delta t_2 = \\theta_2 + 2\\pi n_2\n$$\nHere, $n_1$ and $n_2$ are unknown integers representing the number of \"wraps\" by $2\\pi$. The task is to find a pair $(n_1, n_2)$ and the corresponding values of $\\theta_1, \\theta_2$ that yield a consistent, positive value for $\\omega$.\n\nThe DMD eigenvalues for a real signal appear as a complex conjugate pair, $(\\lambda, \\bar{\\lambda})$, corresponding to arguments $(\\phi, -\\phi)$. We do not know a priori whether $\\theta$ in the unwrapping equations corresponds to $\\phi$ or $-\\phi$. Therefore, we must consider all four sign combinations for $(\\theta_1, \\theta_2)$: $(|\\phi_1|, |\\phi_2|)$, $(|\\phi_1|, -|\\phi_2|)$, $(-|\\phi_1|, |\\phi_2|)$, and $(-|\\phi_1|, -|\\phi_2|)$.\n\nThe algorithm proceeds as follows:\n1.  For each sampling rate $i \\in \\{1, 2\\}$, perform DMD to find the eigenvalues. Extract the argument $\\phi_i$ of one of the complex conjugate eigenvalues. Let $\\theta_{i, \\text{raw}} = |\\phi_i|$.\n2.  Initialize an empty list of candidate frequencies.\n3.  Iterate through the four sign combinations for the arguments:\n    - For each pair of signs $(s_1, s_2) \\in \\{(1,1), (1,-1), (-1,1), (-1,-1)\\}$, set $\\theta_1 = s_1 \\theta_{1, \\text{raw}}$ and $\\theta_2 = s_2 \\theta_{2, \\text{raw}}$.\n4.  Within this loop, search for a consistent integer pair $(n_1, n_2)$. A practical way is to iterate through a plausible range of integers for $n_1$ (e.g., $n_1 \\in [-20, 20]$).\n5.  For each $n_1$:\n    a. Calculate a candidate frequency $\\omega_{\\text{cand}} = (\\theta_1 + 2\\pi n_1)/\\Delta t_1$.\n    b. If $\\omega_{\\text{cand}} \\le 0$, discard it and continue, as we seek a positive frequency.\n    c. From the second equation, the required integer $n_2$ would be $n_2 = (\\omega_{\\text{cand}} \\Delta t_2 - \\theta_2) / (2\\pi)$.\n    d. Check if this calculated $n_2$ is very close to an integer, i.e., $|\\text{round}(n_2) - n_2|  \\epsilon$ for a small tolerance $\\epsilon$.\n    e. If it is, we have found a consistent pair $(n_1, \\text{round}(n_2))$. The corresponding $\\omega_{\\text{cand}}$ is a valid solution. Add it to the list of candidates.\n6.  After checking all sign combinations and the range for $n_1$, the final estimated frequency $\\omega_{\\text{est}}$ is the smallest positive value in the list of candidates. This resolves the aliasing ambiguity. The absolute error is then computed as $|\\omega_{\\text{est}} - \\omega_{\\text{true}}|$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for DMD-based frequency estimation\n    and multi-rate aliasing mitigation.\n    \"\"\"\n\n    def simulator(k, w, dt, Nx, M):\n        \"\"\"\n        Generates a snapshot matrix for the traveling wave u(x,t) = sin(kx - wt).\n        \n        Args:\n            k (float): Wavenumber.\n            w (float): Angular frequency.\n            dt (float): Time step.\n            Nx (int): Number of spatial points.\n            M (int): Number of snapshots.\n            \n        Returns:\n            np.ndarray: Snapshot matrix of shape (Nx, M).\n        \"\"\"\n        x = np.linspace(0, 2 * np.pi, Nx, endpoint=False)\n        t = np.arange(M) * dt\n        xx, tt = np.meshgrid(x, t)\n        snapshot_matrix = np.sin(k * xx - w * tt)\n        return snapshot_matrix.T\n\n    def dmd_get_argument(S, r=2):\n        \"\"\"\n        Performs DMD on a snapshot matrix and returns a principal argument \n        of a dominant complex eigenvalue.\n        \n        Args:\n            S (np.ndarray): Snapshot matrix.\n            r (int): Rank for SVD truncation.\n            \n        Returns:\n            float: The principal argument of a DMD eigenvalue.\n        \"\"\"\n        X = S[:, :-1]\n        Y = S[:, 1:]\n    \n        U, s, Vh = np.linalg.svd(X, full_matrices=False)\n        \n        Ur = U[:, :r]\n        sr = s[:r]\n        Vr_T = Vh[:r, :]\n        \n        # A_tilde = U_r^T Y V_r Sigma_r^{-1}\n        A_tilde = Ur.T @ Y @ Vr_T.T @ np.diag(1/sr)\n        \n        eigvals = np.linalg.eigvals(A_tilde)\n        \n        # Select a non-real eigenvalue to get the oscillatory frequency.\n        # For a real signal, eigenvalues come in conjugate pairs for oscillatory modes.\n        non_real_eigvals = eigvals[np.abs(np.imag(eigvals))  1e-9]\n        if non_real_eigvals.size  0:\n            selected_eig = non_real_eigvals[0]\n        else: # Fallback for purely real eigenvalues (e.g., pure decay)\n            selected_eig = eigvals[0]\n\n        return np.angle(selected_eig)\n\n    def single_rate_dmd_error(k, w_true, dt, Nx, M):\n        \"\"\"\n        Computes the absolute error of a single-rate DMD frequency estimate.\n        \"\"\"\n        S = simulator(k, w_true, dt, Nx, M)\n        theta = dmd_get_argument(S)\n        w_est = np.abs(theta) / dt\n        return np.abs(w_est - w_true)\n\n    def multi_rate_dmd_error(k, w_true, dt1, dt2, Nx, M):\n        \"\"\"\n        Computes the absolute error of a multi-rate DMD frequency estimate,\n        mitigating aliasing.\n        \"\"\"\n        S1 = simulator(k, w_true, dt1, Nx, M)\n        S2 = simulator(k, w_true, dt2, Nx, M)\n        \n        theta1_raw = dmd_get_argument(S1)\n        theta2_raw = dmd_get_argument(S2)\n        \n        candidates = []\n        search_range = range(-20, 21)\n        \n        for s1 in [1, -1]:\n            for s2 in [1, -1]:\n                theta1 = s1 * np.abs(theta1_raw)\n                theta2 = s2 * np.abs(theta2_raw)\n                \n                for n1 in search_range:\n                    w1_candidate = (theta1 + 2 * np.pi * n1) / dt1\n                    \n                    if w1_candidate = 1e-9:\n                        continue\n                    \n                    n2_target = (w1_candidate * dt2 - theta2) / (2 * np.pi)\n                    \n                    if np.abs(n2_target - np.round(n2_target))  1e-6:\n                        n2 = int(np.round(n2_target))\n                        w2_candidate = (theta2 + 2 * np.pi * n2) / dt2\n                        \n                        if np.abs(w1_candidate - w2_candidate)  1e-6:\n                            candidates.append(w1_candidate)\n\n        if not candidates:\n            # This should not happen for the given valid test cases\n            return np.inf\n\n        w_est = min(candidates)\n        return np.abs(w_est - w_true)\n\n    test_cases = [\n        {'type': 'single', 'params': {'k': 3, 'w_true': 12.8, 'dt': 0.01, 'Nx': 128, 'M': 80}},\n        {'type': 'single', 'params': {'k': 3, 'w_true': 40.0, 'dt': 0.2, 'Nx': 128, 'M': 80}},\n        {'type': 'multi', 'params': {'k': 3, 'w_true': 40.0, 'dt1': 0.2, 'dt2': 0.22, 'Nx': 128, 'M': 80}},\n        {'type': 'single', 'params': {'k': 3, 'w_true': 15.5, 'dt': 0.2, 'Nx': 128, 'M': 80}},\n        {'type': 'multi', 'params': {'k': 5, 'w_true': 100.0, 'dt1': 0.2, 'dt2': 0.19, 'Nx': 128, 'M': 100}}\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'single':\n            error = single_rate_dmd_error(**case['params'])\n        else:\n            error = multi_rate_dmd_error(**case['params'])\n        results.append(error)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The standard DMD model assumes that system dynamics can be separated into a linear operator and uncorrelated noise. However, many real-world systems are subject to forcing that has its own temporal structure, or \"color\". This final exercise presents an advanced theoretical analysis to quantify the robustness of DMD in such scenarios. By deriving the analytical bias in the estimated eigenvalues caused by colored-in-time forcing, you will gain a deeper understanding of how DMD behaves in more complex, realistic settings and learn to critically assess its output when the noise is not simple white noise .",
            "id": "3383158",
            "problem": "Consider the one-dimensional heat partial differential equation (PDE) $u_{t} = \\nu u_{xx}$ posed on the periodic domain $x \\in [0,2\\pi)$ with viscosity parameter $\\nu  0$. Let $u(x,t)$ be expanded in the Fourier basis, and focus on the temporal dynamics of a single Fourier mode with wavenumber $k \\in \\mathbb{N}$. Under a stable time-stepping scheme with time step $\\Delta t  0$, the unforced discrete-time evolution of the mode amplitude $a_{k}(n)$ can be represented as $a_{k}(n) = \\alpha a_{k}(n-1)$, where $\\alpha \\in (-1,1)$ is the associated amplification factor of the linear numerical propagator for that mode.\n\nNow, suppose the PDE is driven by a zero-mean colored-in-time source that couples additively into the same mode, so that the observed mode amplitude dynamics obey\n$$\nx_{n} = \\alpha x_{n-1} + r_{n}, \\quad n \\in \\mathbb{Z},\n$$\nwhere $x_{n} := a_{k}(n)$ is the scalar mode amplitude and $r_{n}$ is an Autoregressive of order $1$ (AR(1)) process given by\n$$\nr_{n} = \\phi r_{n-1} + \\eta_{n},\n$$\nwith $\\phi \\in (-1,1)$, and $\\eta_{n}$ are independent and identically distributed zero-mean innovations with finite variance $\\sigma_{\\eta}^{2} \\in (0,\\infty)$. Assume stationarity of $x_{n}$ and $r_{n}$ and $|\\alpha|1$, $|\\phi|1$.\n\nYou collect $m$ consecutive snapshots of the scalar amplitude, forming the data arrays $X = [x_{0}, x_{1}, \\dots, x_{m-1}]$ and $Y = [x_{1}, x_{2}, \\dots, x_{m}]$. You apply Dynamic Mode Decomposition (DMD), defined by $A_{\\mathrm{DMD}} = Y X^{+}$ where $X^{+}$ denotes the Moore–Penrose pseudoinverse, to estimate the dominant eigenvalue of the one-dimensional linear evolution. In the scalar case, the DMD estimate reduces to the least-squares slope mapping $x_{n-1} \\mapsto x_{n}$.\n\nAnalyze the robustness of the DMD eigenvalue estimate under this colored-in-time forcing by deriving, in the limit $m \\to \\infty$, the expected bias of the DMD eigenvalue estimate due to the AR(1) forcing. Express your final answer as a closed-form analytic expression for\n$$\n\\mathbb{E}[\\hat{\\alpha}] - \\alpha\n$$\nin terms of $\\alpha$ and $\\phi$. No numerical rounding is required.",
            "solution": "The problem asks for the asymptotic bias of the Dynamic Mode Decomposition (DMD) eigenvalue estimate for a scalar autoregressive process driven by colored noise. The process is defined by the coupled equations:\n$$\nx_{n} = \\alpha x_{n-1} + r_{n}\n$$\n$$\nr_{n} = \\phi r_{n-1} + \\eta_{n}\n$$\nwhere $x_n$ is the observed scalar amplitude, $\\alpha$ is the true dynamics eigenvalue we wish to estimate, and $r_n$ is an Autoregressive process of order $1$ (AR(1)) representing colored-in-time forcing. The parameters are constrained by $|\\alpha|  1$ and $|\\phi|  1$, ensuring stationarity of the processes. The innovations $\\eta_n$ are i.i.d. with zero mean, $\\mathbb{E}[\\eta_n] = 0$, and finite variance $\\sigma_\\eta^2$.\n\nThe DMD estimate for the scalar case, denoted $\\hat{\\alpha}$, is the least-squares solution that minimizes the residual in mapping $x_{n-1}$ to $x_n$. Given the data vectors $X = [x_{0}, x_{1}, \\dots, x_{m-1}]$ and $Y = [x_{1}, x_{2}, \\dots, x_{m}]$, the DMD eigenvalue is given by $A_{\\mathrm{DMD}} = Y X^{+}$, where $X^{+}$ is the Moore-Penrose pseudoinverse of the row vector $X$. This simplifies to:\n$$\n\\hat{\\alpha} = \\frac{\\sum_{n=1}^{m} x_{n} x_{n-1}}{\\sum_{n=1}^{m} x_{n-1}^2}\n$$\nThe problem requires us to find the expected bias, $\\mathbb{E}[\\hat{\\alpha}] - \\alpha$, in the limit of a large number of snapshots, $m \\to \\infty$.\n\nIn this limit, by the law of large numbers for stationary and ergodic processes, the sample averages converge in probability to their respective expected values. The process $x_n$ is stationary under the given conditions. Thus, the estimator $\\hat{\\alpha}$ converges in probability to a value we denote by $\\alpha_{\\infty}$:\n$$\n\\hat{\\alpha} \\xrightarrow{p}_{m\\to\\infty} \\alpha_{\\infty} = \\frac{\\mathbb{E}[x_{n} x_{n-1}]}{\\mathbb{E}[x_{n-1}^2]}\n$$\nDue to stationarity, the denominator is $\\mathbb{E}[x_{n-1}^2] = \\mathbb{E}[x_n^2]$. Let $\\gamma_x(k) = \\mathbb{E}[x_n x_{n-k}]$ be the autocovariance function of the process $x_n$. The asymptotic estimate is then:\n$$\n\\alpha_{\\infty} = \\frac{\\gamma_x(1)}{\\gamma_x(0)}\n$$\nThe asymptotic bias is therefore $\\alpha_{\\infty} - \\alpha$. To calculate this, we must first determine the statistical properties of the process $x_n$, specifically its autocovariance function.\n\nThe process $x_n$ can be expressed as a single equation by substituting for the noise term $r_n$. From the primary dynamic equation, we have $r_n = x_n - \\alpha x_{n-1}$. Substituting this into the equation for $r_n$:\n$$\n(x_n - \\alpha x_{n-1}) = \\phi (x_{n-1} - \\alpha x_{n-2}) + \\eta_n\n$$\nRearranging the terms, we find the evolution equation for $x_n$:\n$$\nx_n = (\\alpha + \\phi) x_{n-1} - \\alpha\\phi x_{n-2} + \\eta_n\n$$\nThis reveals that $x_n$ is an Autoregressive process of order $2$ (AR(2)). The stability of this process is guaranteed by the conditions $|\\alpha|1$ and $|\\phi|1$, as the roots of the characteristic polynomial $1 - (\\alpha+\\phi)z + \\alpha\\phi z^2 = (1-\\alpha z)(1-\\phi z)$ are $1/\\alpha$ and $1/\\phi$, which lie outside the unit circle.\n\nFor a stationary AR(p) process, the autocovariances satisfy the Yule-Walker equations. For our AR(2) process, multiplying the equation for $x_n$ by $x_{n-k}$ for $k  0$ and taking the expectation yields:\n$$\n\\mathbb{E}[x_n x_{n-k}] = (\\alpha + \\phi) \\mathbb{E}[x_{n-1} x_{n-k}] - \\alpha\\phi \\mathbb{E}[x_{n-2} x_{n-k}] + \\mathbb{E}[\\eta_n x_{n-k}]\n$$\nSince $x_{n-k}$ for $k0$ depends only on innovations up to time $n-k$, it is uncorrelated with $\\eta_n$. Thus, $\\mathbb{E}[\\eta_n x_{n-k}] = 0$. The equation becomes:\n$$\n\\gamma_x(k) = (\\alpha + \\phi) \\gamma_x(k-1) - \\alpha\\phi \\gamma_x(k-2) \\quad \\text{for } k  0\n$$\nTo find the ratio $\\gamma_x(1)/\\gamma_x(0)$, we set $k=1$:\n$$\n\\gamma_x(1) = (\\alpha + \\phi) \\gamma_x(0) - \\alpha\\phi \\gamma_x(-1)\n$$\nUsing the property that $\\gamma_x(-1) = \\gamma_x(1)$, we have:\n$$\n\\gamma_x(1) = (\\alpha + \\phi) \\gamma_x(0) - \\alpha\\phi \\gamma_x(1)\n$$\nCollecting terms involving $\\gamma_x(1)$:\n$$\n\\gamma_x(1) (1 + \\alpha\\phi) = (\\alpha + \\phi) \\gamma_x(0)\n$$\nSolving for the ratio gives the asymptotic DMD estimate:\n$$\n\\alpha_{\\infty} = \\frac{\\gamma_x(1)}{\\gamma_x(0)} = \\frac{\\alpha + \\phi}{1 + \\alpha\\phi}\n$$\nThe asymptotic bias of the estimator is the difference between this value and the true parameter $\\alpha$:\n$$\n\\mathbb{E}[\\hat{\\alpha}] - \\alpha \\quad \\xrightarrow{m\\to\\infty} \\quad \\alpha_{\\infty} - \\alpha = \\frac{\\alpha + \\phi}{1 + \\alpha\\phi} - \\alpha\n$$\nWe place the terms over a common denominator to simplify:\n$$\n\\text{Bias} = \\frac{(\\alpha + \\phi) - \\alpha(1 + \\alpha\\phi)}{1 + \\alpha\\phi} = \\frac{\\alpha + \\phi - \\alpha - \\alpha^2\\phi}{1 + \\alpha\\phi} = \\frac{\\phi - \\alpha^2\\phi}{1 + \\alpha\\phi}\n$$\nFactoring out $\\phi$ from the numerator gives the final expression for the asymptotic bias:\n$$\n\\text{Bias} = \\frac{\\phi(1 - \\alpha^2)}{1 + \\alpha\\phi}\n$$\nThis result shows that the bias is zero only if $\\phi=0$, which corresponds to the case of white noise forcing. For any non-zero $\\phi$, the DMD estimate is biased, and the magnitude and sign of the bias depend on the interplay between the system's own dynamics ($\\alpha$) and the temporal correlation of the forcing ($\\phi$).",
            "answer": "$$\n\\boxed{\\frac{\\phi(1 - \\alpha^2)}{1 + \\alpha\\phi}}\n$$"
        }
    ]
}