{
    "hands_on_practices": [
        {
            "introduction": "A numerical scheme's accuracy depends not just on its formal order, but also on how well it propagates waves of different frequencies. This exercise guides you through a comparative analysis of the Beam-Warming and Lax-Wendroff schemes, focusing on the concept of numerical group velocity, $v_g(\\theta)$. By deriving and comparing their dispersive properties, you will gain a deeper understanding of how the upwind nature of the Beam-Warming scheme offers advantages for advection-dominated problems .",
            "id": "3366043",
            "problem": "Consider the constant-coefficient linear advection partial differential equation $u_{t} + a\\,u_{x} = 0$ with $a0$ on a uniform spatial grid with spacing $\\Delta x$ and time step $\\Delta t$. Define the Courant number $\\lambda = a\\,\\Delta t/\\Delta x$. Analyze two second-order explicit schemes: the Lax–Wendroff scheme and the Beam–Warming higher-order upwind scheme (for $a0$), each applied to the Fourier mode $u_{j}^{n} = \\hat{u}^{n}\\exp(i j \\theta)$, where $\\theta = k\\,\\Delta x \\in [0,\\pi]$ is the non-dimensional wavenumber (in radians). \n\n1. Starting from the update formula of each scheme, derive its complex amplification factor $G(\\theta)$ and the corresponding modified (non-dimensional) wavenumber $\\tilde{\\theta}(\\theta)$ defined by the imaginary part of the principal branch of the complex logarithm,\n$$\n\\tilde{\\theta}(\\theta) = -\\frac{1}{\\lambda}\\,\\operatorname{Im}\\big(\\ln G(\\theta)\\big),\n$$\nso that its numerical angular frequency obeys $\\,\\omega(\\theta)\\Delta t = a\\,\\tilde{k}(\\theta)\\Delta t = -\\operatorname{Im}\\big(\\ln G(\\theta)\\big)$ with $\\tilde{k}(\\theta) = \\tilde{\\theta}(\\theta)/\\Delta x$.\n\n2. Using the definition of group velocity $v_{g}(\\theta) = \\mathrm{d}\\omega/\\mathrm{d}k$, show that\n$$\nv_{g}(\\theta) \\;=\\; a\\,\\frac{\\mathrm{d}\\tilde{\\theta}}{\\mathrm{d}\\theta}\n\\;=\\; -\\frac{a}{\\lambda}\\,\\operatorname{Im}\\!\\left(\\frac{G'(\\theta)}{G(\\theta)}\\right),\n$$\nwhere the prime denotes differentiation with respect to $\\theta$.\n\n3. Specialize to the Courant number $\\lambda = 0.8$ and compute, for each scheme, the worst-case absolute group-velocity error over the full resolved band $\\theta \\in [0,\\pi]$:\n$$\nE_{\\mathrm{LW}} \\;=\\; \\sup_{\\theta \\in [0,\\pi]} \\big|v_{g,\\mathrm{LW}}(\\theta) - a\\big|,\\qquad\nE_{\\mathrm{BW}} \\;=\\; \\sup_{\\theta \\in [0,\\pi]} \\big|v_{g,\\mathrm{BW}}(\\theta) - a\\big|.\n$$\nFinally, quantify which scheme is better by reporting the ratio $E_{\\mathrm{BW}}/E_{\\mathrm{LW}}$ as a pure number. Use radians for $\\theta$ and round your final ratio to four significant figures.",
            "solution": "The problem is analyzed and validated according to the specified criteria.\n\n**Step 1: Extract Givens**\n-   **PDE**: $u_{t} + a\\,u_{x} = 0$, with constant $a0$.\n-   **Grid**: Uniform spatial grid with spacing $\\Delta x$ and time step $\\Delta t$.\n-   **Courant Number**: $\\lambda = a\\,\\Delta t/\\Delta x$.\n-   **Fourier Mode**: $u_{j}^{n} = \\hat{u}^{n}\\exp(i j \\theta)$, where $\\theta = k\\,\\Delta x \\in [0,\\pi]$.\n-   **Schemes**: Lax–Wendroff (LW) and Beam–Warming (BW) higher-order upwind scheme.\n-   **Modified Wavenumber**: $\\tilde{\\theta}(\\theta) = -\\frac{1}{\\lambda}\\,\\operatorname{Im}\\big(\\ln G(\\theta)\\big)$.\n-   **Numerical Frequency**: $\\omega(\\theta)\\Delta t = a\\,\\tilde{k}(\\theta)\\Delta t = -\\operatorname{Im}\\big(\\ln G(\\theta)\\big)$ with $\\tilde{k}(\\theta) = \\tilde{\\theta}(\\theta)/\\Delta x$.\n-   **Group Velocity**: $v_{g}(\\theta) = \\mathrm{d}\\omega/\\mathrm{d}k$.\n-   **Group Velocity Formula to Prove**: $v_{g}(\\theta) = a\\,\\frac{\\mathrm{d}\\tilde{\\theta}}{\\mathrm{d}\\theta} = -\\frac{a}{\\lambda}\\,\\operatorname{Im}\\!\\left(\\frac{G'(\\theta)}{G(\\theta)}\\right)$.\n-   **Specific Condition**: $\\lambda = 0.8$.\n-   **Error Metrics**: $E_{\\mathrm{LW}} = \\sup_{\\theta \\in [0,\\pi]} \\big|v_{g,\\mathrm{LW}}(\\theta) - a\\big|$ and $E_{\\mathrm{BW}} = \\sup_{\\theta \\in [0,\\pi]} \\big|v_{g,\\mathrm{BW}}(\\theta) - a\\big|$.\n-   **Final Output**: The ratio $E_{\\mathrm{BW}}/E_{\\mathrm{LW}}$ rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded**: The problem is a standard exercise in the numerical analysis of partial differential equations, focusing on fundamental concepts like von Neumann stability analysis, modified wavenumber, and group velocity for well-known finite difference schemes. The problem is firmly rooted in established scientific and mathematical principles.\n-   **Well-Posed**: The problem is clearly stated, with all necessary definitions provided. The tasks are sequential and logically connected, leading to a unique, well-defined numerical answer.\n-   **Objective**: The problem is formulated in precise, unbiased mathematical language.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A full solution will be provided.\n\n**Part 1: Amplification Factors and Modified Wavenumbers**\n\n**Lax-Wendroff (LW) Scheme**\nThe Lax-Wendroff scheme for $u_t+au_x=0$ is derived from a Taylor series expansion in time, using the PDE to replace time derivatives with spatial derivatives.\n$$\nu_j^{n+1} = u_j^n - a \\frac{\\Delta t}{2\\Delta x}(u_{j+1}^n - u_{j-1}^n) + \\frac{a^2 (\\Delta t)^2}{2(\\Delta x)^2}(u_{j+1}^n - 2u_j^n + u_{j-1}^n)\n$$\nSubstituting the Courant number $\\lambda = a\\Delta t/\\Delta x$, we get:\n$$\nu_j^{n+1} = u_j^n - \\frac{\\lambda}{2}(u_{j+1}^n - u_{j-1}^n) + \\frac{\\lambda^2}{2}(u_{j+1}^n - 2u_j^n + u_{j-1}^n)\n$$\nTo find the amplification factor $G(\\theta) = \\hat{u}^{n+1}/\\hat{u}^{n}$, we substitute $u_j^n = \\hat{u}^n \\exp(ij\\theta)$:\n$$\n\\hat{u}^{n+1}\\exp(ij\\theta) = \\hat{u}^n\\left[\\exp(ij\\theta) - \\frac{\\lambda}{2}(\\exp(i(j+1)\\theta) - \\exp(i(j-1)\\theta)) + \\frac{\\lambda^2}{2}(\\exp(i(j+1)\\theta) - 2\\exp(ij\\theta) + \\exp(i(j-1)\\theta))\\right]\n$$\nDividing by $\\hat{u}^n\\exp(ij\\theta)$:\n$$\nG_{\\mathrm{LW}}(\\theta) = 1 - \\frac{\\lambda}{2}(e^{i\\theta} - e^{-i\\theta}) + \\frac{\\lambda^2}{2}(e^{i\\theta} - 2 + e^{-i\\theta})\n$$\nUsing Euler's identities $e^{i\\theta} - e^{-i\\theta} = 2i\\sin\\theta$ and $e^{i\\theta} + e^{-i\\theta} = 2\\cos\\theta$:\n$$\nG_{\\mathrm{LW}}(\\theta) = 1 - i\\lambda\\sin\\theta + \\lambda^2(\\cos\\theta - 1)\n$$\nThe modified wavenumber is given by $\\tilde{\\theta}_{\\mathrm{LW}}(\\theta) = -\\frac{1}{\\lambda}\\operatorname{Im}(\\ln G_{\\mathrm{LW}}(\\theta))$. The imaginary part of the logarithm is the argument of the complex number:\n$$\n\\tilde{\\theta}_{\\mathrm{LW}}(\\theta) = -\\frac{1}{\\lambda} \\arg(G_{\\mathrm{LW}}) = -\\frac{1}{\\lambda} \\arctan\\left(\\frac{\\operatorname{Im}(G_{\\mathrm{LW}})}{\\operatorname{Re}(G_{\\mathrm{LW}})}\\right) = \\frac{1}{\\lambda} \\arctan\\left(\\frac{\\lambda\\sin\\theta}{1 - \\lambda^2(1 - \\cos\\theta)}\\right)\n$$\n\n**Beam-Warming (BW) Scheme**\nFor $a0$, the Beam-Warming scheme is a second-order upwind method. Its formula is:\n$$\nu_j^{n+1} = u_j^n - \\frac{\\lambda}{2}(3u_j^n - 4u_{j-1}^n + u_{j-2}^n) + \\frac{\\lambda^2}{2}(u_j^n - 2u_{j-1}^n + u_{j-2}^n)\n$$\nSubstituting $u_j^n = \\hat{u}^n \\exp(ij\\theta)$ yields the amplification factor:\n$$\nG_{\\mathrm{BW}}(\\theta) = 1 - \\frac{\\lambda}{2}(3 - 4e^{-i\\theta} + e^{-2i\\theta}) + \\frac{\\lambda^2}{2}(1 - 2e^{-i\\theta} + e^{-2i\\theta})\n$$\nThe real and imaginary parts are:\n$$\n\\operatorname{Re}(G_{\\mathrm{BW}}) = 1 - \\frac{3\\lambda}{2} + \\frac{\\lambda^2}{2} + (2\\lambda-\\lambda^2)\\cos\\theta + (\\frac{\\lambda^2-\\lambda}{2})\\cos(2\\theta)\n$$\n$$\n\\operatorname{Im}(G_{\\mathrm{BW}}) = (2\\lambda-\\lambda^2)\\sin\\theta + (\\frac{\\lambda^2-\\lambda}{2})\\sin(2\\theta)\n$$\nThe modified wavenumber is:\n$$\n\\tilde{\\theta}_{\\mathrm{BW}}(\\theta) = -\\frac{1}{\\lambda} \\arctan\\left(\\frac{(2\\lambda-\\lambda^2)\\sin\\theta + (\\frac{\\lambda^2-\\lambda}{2})\\sin(2\\theta)}{1 - \\frac{3\\lambda}{2} + \\frac{\\lambda^2}{2} + (2\\lambda-\\lambda^2)\\cos\\theta + (\\frac{\\lambda^2-\\lambda}{2})\\cos(2\\theta)}\\right)\n$$\n\n**Part 2: Group Velocity Formula**\nThe group velocity is defined as $v_g = \\mathrm{d}\\omega/\\mathrm{d}k$. The problem provides the relation for the numerical angular frequency $\\omega(\\theta) = a \\tilde{k}(\\theta) = a \\tilde{\\theta}(\\theta)/\\Delta x$. Since $\\theta = k\\Delta x$, we have $k = \\theta/\\Delta x$ and $\\mathrm{d}k = \\mathrm{d}\\theta/\\Delta x$.\nWe can now express $v_g$ in terms of $\\theta$:\n$$\nv_g(\\theta) = \\frac{\\mathrm{d}\\omega}{\\mathrm{d}k} = \\frac{\\mathrm{d}\\omega/\\mathrm{d}\\theta}{\\mathrm{d}k/\\mathrm{d}\\theta} = \\frac{\\mathrm{d}}{\\mathrm{d}\\theta}\\left(a \\frac{\\tilde{\\theta}(\\theta)}{\\Delta x}\\right) \\cdot \\frac{1}{1/\\Delta x} = a \\frac{\\mathrm{d}\\tilde{\\theta}}{\\mathrm{d}\\theta}\n$$\nThis establishes the first identity. For the second identity, we use the definition of $\\tilde{\\theta}(\\theta)$:\n$$\n\\tilde{\\theta}(\\theta) = -\\frac{1}{\\lambda}\\,\\operatorname{Im}\\big(\\ln G(\\theta)\\big)\n$$\nDifferentiating with respect to $\\theta$ and using the fact that differentiation and taking the imaginary part are interchangeable linear operations:\n$$\n\\frac{\\mathrm{d}\\tilde{\\theta}}{\\mathrm{d}\\theta} = -\\frac{1}{\\lambda} \\frac{\\mathrm{d}}{\\mathrm{d}\\theta}\\left( \\operatorname{Im}\\big(\\ln G(\\theta)\\big) \\right) = -\\frac{1}{\\lambda} \\operatorname{Im}\\left( \\frac{\\mathrm{d}}{\\mathrm{d}\\theta}\\ln G(\\theta) \\right)\n$$\nBy the chain rule for derivatives, $\\frac{\\mathrm{d}}{\\mathrm{d}\\theta}\\ln G(\\theta) = \\frac{G'(\\theta)}{G(\\theta)}$. Thus:\n$$\n\\frac{\\mathrm{d}\\tilde{\\theta}}{\\mathrm{d}\\theta} = -\\frac{1}{\\lambda} \\operatorname{Im}\\left(\\frac{G'(\\theta)}{G(\\theta)}\\right)\n$$\nMultiplying by $a$ gives the desired result:\n$$\nv_g(\\theta) = a \\frac{\\mathrm{d}\\tilde{\\theta}}{\\mathrm{d}\\theta} = -\\frac{a}{\\lambda} \\operatorname{Im}\\left(\\frac{G'(\\theta)}{G(\\theta)}\\right)\n$$\n\n**Part 3: Error Calculation for $\\lambda = 0.8$**\nThe exact group velocity for the PDE $u_t+au_x=0$ is $v_{g, \\text{exact}} = a$. The error is $|v_g(\\theta)-a|$. We analyze the normalized group velocity $v_g(\\theta)/a = \\mathrm{d}\\tilde{\\theta}/\\mathrm{d}\\theta$. We need to compute $E = \\sup_{\\theta \\in [0,\\pi]} a |v_g(\\theta)/a - 1|$.\n\n**Lax-Wendroff Scheme**\nFrom Part 1, $G_{\\mathrm{LW}}(\\theta) = 1 + \\lambda^2(\\cos\\theta - 1) - i\\lambda\\sin\\theta$.\nThe derivative is $G'_{\\mathrm{LW}}(\\theta) = -\\lambda^2\\sin\\theta - i\\lambda\\cos\\theta$.\nThe normalized group velocity is $v_{g,\\mathrm{LW}}(\\theta)/a = \\frac{\\mathrm{d}\\tilde{\\theta}_{\\mathrm{LW}}}{\\mathrm{d}\\theta}$. After algebraic manipulation, this is:\n$$\n\\frac{v_{g,\\mathrm{LW}}(\\theta)}{a} = \\frac{\\lambda^2 + (1-\\lambda^2)\\cos\\theta}{1 - \\lambda^2(1-\\lambda^2)(1-\\cos\\theta)^2}\n$$\nFor $\\lambda=0.8$, $\\lambda^2=0.64$. For second-order schemes, the error is typically largest for the highest wavenumber $\\theta=\\pi$. At $\\theta=\\pi$, $\\cos\\theta=-1$:\n$$\n\\frac{v_{g,\\mathrm{LW}}(\\pi)}{a} = \\frac{\\lambda^2 - (1-\\lambda^2)}{1 - \\lambda^2(1-\\lambda^2)(1-(-1))^2} = \\frac{2\\lambda^2 - 1}{1 - 4\\lambda^2(1-\\lambda^2)}\n$$\nSubstituting $\\lambda=0.8$:\n$$\n\\frac{v_{g,\\mathrm{LW}}(\\pi)}{a} = \\frac{2(0.64) - 1}{1 - 4(0.64)(1-0.64)} = \\frac{1.28 - 1}{1 - 2.56(0.36)} = \\frac{0.28}{1 - 0.9216} = \\frac{0.28}{0.0784} = \\frac{25}{7}\n$$\nThe error at $\\theta=\\pi$ is $a \\left| \\frac{25}{7} - 1 \\right| = a \\frac{18}{7}$. For LW, this is the maximum error over $\\theta \\in [0, \\pi]$.\n$$\nE_{\\mathrm{LW}} = \\frac{18}{7} a\n$$\n\n**Beam-Warming Scheme**\nFrom Part 1, $G_{\\mathrm{BW}}(\\theta) = 1 - \\frac{\\lambda}{2}(3 - 4e^{-i\\theta} + e^{-2i\\theta}) + \\frac{\\lambda^2}{2}(1 - 2e^{-i\\theta} + e^{-2i\\theta})$.\nThe derivative is $G'_{\\mathrm{BW}}(\\theta) = i(-\\lambda(2e^{-i\\theta}-e^{-2i\\theta}) + \\lambda^2(e^{-i\\theta}-e^{-2i\\theta}))$.\nThe normalized group velocity $v_{g,\\mathrm{BW}}(\\theta)/a$ is found via the formula from Part 2. At $\\theta=\\pi$, $e^{-i\\pi}=-1$ and $e^{-2i\\pi}=1$:\n$$\nG_{\\mathrm{BW}}(\\pi) = 1 - 4\\lambda + 2\\lambda^2, \\qquad G'_{\\mathrm{BW}}(\\pi) = i(3\\lambda - 2\\lambda^2)\n$$\nThe ratio $G'/G$ at $\\theta=\\pi$ is purely imaginary:\n$$\n\\frac{G'_{\\mathrm{BW}}(\\pi)}{G_{\\mathrm{BW}}(\\pi)} = \\frac{i(3\\lambda - 2\\lambda^2)}{1-4\\lambda+2\\lambda^2}\n$$\nSo, $v_g(\\pi)/a = -\\frac{1}{\\lambda} \\operatorname{Im}\\left( \\frac{G'_{\\mathrm{BW}}(\\pi)}{G_{\\mathrm{BW}}(\\pi)} \\right)$:\n$$\n\\frac{v_{g,\\mathrm{BW}}(\\pi)}{a} = -\\frac{1}{\\lambda} \\left(\\frac{3\\lambda - 2\\lambda^2}{1-4\\lambda+2\\lambda^2}\\right) = -\\frac{3 - 2\\lambda}{1 - 4\\lambda + 2\\lambda^2}\n$$\nSubstituting $\\lambda=0.8$:\n$$\n\\frac{v_{g,\\mathrm{BW}}(\\pi)}{a} = -\\frac{3 - 2(0.8)}{1 - 4(0.8) + 2(0.64)} = -\\frac{3 - 1.6}{1 - 3.2 + 1.28} = -\\frac{1.4}{-0.92} = \\frac{1.4}{0.92} = \\frac{140}{92} = \\frac{35}{23}\n$$\nThe error at $\\theta=\\pi$ is $a \\left| \\frac{35}{23} - 1 \\right| = a \\frac{12}{23}$. For BW at this Courant number, this is the maximum error.\n$$\nE_{\\mathrm{BW}} = \\frac{12}{23} a\n$$\n\n**Ratio of Errors**\nFinally, we compute the ratio $E_{\\mathrm{BW}}/E_{\\mathrm{LW}}$:\n$$\n\\frac{E_{\\mathrm{BW}}}{E_{\\mathrm{LW}}} = \\frac{\\frac{12}{23}a}{\\frac{18}{7}a} = \\frac{12}{23} \\cdot \\frac{7}{18} = \\frac{2 \\cdot 6}{23} \\cdot \\frac{7}{3 \\cdot 6} = \\frac{14}{69}\n$$\nAs a decimal, this is $14/69 \\approx 0.20289855...$.\nRounding to four significant figures gives $0.2029$.",
            "answer": "$$\n\\boxed{0.2029}\n$$"
        },
        {
            "introduction": "Beyond simply analyzing a given scheme, a powerful skill is the ability to systematically improve it. This practice introduces the modified equation, a Taylor-series-based tool that reveals the actual partial differential equation a scheme solves, including its error terms. You will construct a custom Beam-Warming-like scheme and tune a higher-order corrective term, with coefficient $\\kappa$, to precisely cancel the leading source of dispersive error, a common technique in the design of high-fidelity methods .",
            "id": "3366042",
            "problem": "Consider the linear advection equation $u_{t} + a\\,u_{x} = 0$ with constant advection speed $a0$ on a uniform spatial grid with spacing $\\Delta x$ and time step $\\Delta t$. Let the Courant number be $\\nu = a\\,\\Delta t/\\Delta x$. Define the backward difference operators\n$$D_{-} u_{j}^{n} = \\frac{u_{j}^{n} - u_{j-1}^{n}}{\\Delta x},\\quad D_{-}^{2} u_{j}^{n} = \\frac{u_{j}^{n} - 2 u_{j-1}^{n} + u_{j-2}^{n}}{\\Delta x^{2}},\\quad D_{-}^{3} u_{j}^{n} = \\frac{u_{j}^{n} - 3 u_{j-1}^{n} + 3 u_{j-2}^{n} - u_{j-3}^{n}}{\\Delta x^{3}}.$$\nConstruct a one-step Beam–Warming-like explicit update by truncating the time Taylor series of $u$ to second order and replacing the spatial derivatives $u_{x}$ and $u_{xx}$ by $D_{-}$ and $D_{-}^{2}$ evaluated at time level $n$, then augment the scheme with a tunable third-derivative upwind term to target third-order behavior in space:\n$$u_{j}^{n+1} \\;=\\; u_{j}^{n} \\;-\\; a\\,\\Delta t\\, D_{-} u_{j}^{n} \\;+\\; \\frac{a^{2}\\Delta t^{2}}{2}\\, D_{-}^{2} u_{j}^{n} \\;+\\; \\kappa\\,a\\,\\Delta t\\,\\Delta x^{2}\\, D_{-}^{3} u_{j}^{n}.$$\nHere $\\kappa$ is a dimensionless coefficient to be chosen. Using a modified equation analysis up to and including terms of order $\\mathcal{O}(\\Delta x^{2})$, determine the unique analytic expression $\\kappa(\\nu)$ such that, at the target Courant number $\\nu$, the coefficient multiplying the dispersive term $\\Delta x^{2} u_{xxx}$ in the modified equation vanishes. Provide your final expression for $\\kappa(\\nu)$ in closed form. No numerical approximation or rounding is required.",
            "solution": "The user wants me to solve the following problem:\nConsider the linear advection equation $u_{t} + a\\,u_{x} = 0$ with constant advection speed $a0$ on a uniform spatial grid with spacing $\\Delta x$ and time step $\\Delta t$. Let the Courant number be $\\nu = a\\,\\Delta t/\\Delta x$. Define the backward difference operators\n$$D_{-} u_{j}^{n} = \\frac{u_{j}^{n} - u_{j-1}^{n}}{\\Delta x},\\quad D_{-}^{2} u_{j}^{n} = \\frac{u_{j}^{n} - 2 u_{j-1}^{n} + u_{j-2}^{n}}{\\Delta x^{2}},\\quad D_{-}^{3} u_{j}^{n} = \\frac{u_{j}^{n} - 3 u_{j-1}^{n} + 3 u_{j-2}^{n} - u_{j-3}^{n}}{\\Delta x^{3}}.$$\nConstruct a one-step Beam–Warming-like explicit update by truncating the time Taylor series of $u$ to second order and replacing the spatial derivatives $u_{x}$ and $u_{xx}$ by $D_{-}$ and $D_{-}^{2}$ evaluated at time level $n$, then augment the scheme with a tunable third-derivative upwind term to target third-order behavior in space:\n$$u_{j}^{n+1} \\;=\\; u_{j}^{n} \\;-\\; a\\,\\Delta t\\, D_{-} u_{j}^{n} \\;+\\; \\frac{a^{2}\\Delta t^{2}}{2}\\, D_{-}^{2} u_{j}^{n} \\;+\\; \\kappa\\,a\\,\\Delta t\\,\\Delta x^{2}\\, D_{-}^{3} u_{j}^{n}.$$\nHere $\\kappa$ is a dimensionless coefficient to be chosen. Using a modified equation analysis up to and including terms of order $\\mathcal{O}(\\Delta x^{2})$, determine the unique analytic expression $\\kappa(\\nu)$ such that, at the target Courant number $\\nu$, the coefficient multiplying the dispersive term $\\Delta x^{2} u_{xxx}$ in the modified equation vanishes. Provide your final expression for $\\kappa(\\nu)$ in closed form. No numerical approximation or rounding is required.\n\n### Step 1: Extract Givens\n-   **Governing Equation**: $u_{t} + a\\,u_{x} = 0$, with constant $a0$.\n-   **Discretization**: Uniform grid with spatial spacing $\\Delta x$ and time step $\\Delta t$.\n-   **Courant Number**: $\\nu = a\\,\\Delta t/\\Delta x$.\n-   **Difference Operators**:\n    -   $D_{-} u_{j}^{n} = \\frac{u_{j}^{n} - u_{j-1}^{n}}{\\Delta x}$\n    -   $D_{-}^{2} u_{j}^{n} = \\frac{u_{j}^{n} - 2 u_{j-1}^{n} + u_{j-2}^{n}}{\\Delta x^{2}}$\n    -   $D_{-}^{3} u_{j}^{n} = \\frac{u_{j}^{n} - 3 u_{j-1}^{n} + 3 u_{j-2}^{n} - u_{j-3}^{n}}{\\Delta x^{3}}$\n-   **Numerical Scheme**: $u_{j}^{n+1} = u_{j}^{n} - a\\,\\Delta t\\, D_{-} u_{j}^{n} + \\frac{a^{2}\\Delta t^{2}}{2}\\, D_{-}^{2} u_{j}^{n} + \\kappa\\,a\\,\\Delta t\\,\\Delta x^{2}\\, D_{-}^{3} u_{j}^{n}$.\n-   **Objective**: Find the function $\\kappa(\\nu)$ that makes the coefficient of the $\\Delta x^{2} u_{xxx}$ term in the modified equation equal to zero.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is a standard exercise in the analysis of finite difference schemes for partial differential equations, a core topic in numerical analysis and computational fluid dynamics. The methods used (Taylor series expansion, modified equation analysis) are fundamental to the field.\n2.  **Well-Posed**: The problem provides a clearly defined numerical scheme and asks for the value of a parameter $\\kappa$ that cancels a specific term in the modified equation. This is a non-ambiguous, solvable algebraic problem.\n3.  **Objective**: The problem is stated in precise mathematical language with no subjective or opinion-based content.\n\nThe problem does contain a potentially misleading phrase, \"target third-order behavior in space.\" A rigorous analysis reveals that the base scheme (with $\\kappa=0$) is only first-order accurate, due to an uncorrected error term proportional to $u_{xx}$. Canceling the $u_{xxx}$ term as requested will not make the scheme third-order. However, the problem does not claim the resulting scheme *will be* third-order; it only states this as a \"target.\" The specific task is to find $\\kappa(\\nu)$ so that the coefficient of the $u_{xxx}$ term vanishes. This task is well-defined and does not depend on the behavior of other error terms. Therefore, the problem is not technically flawed or self-contradictory.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. I will proceed with the solution.\n\nTo determine the expression for $\\kappa(\\nu)$, we must perform a modified equation analysis. This involves expanding each term of the numerical scheme in a Taylor series around a generic point $(x_j, t_n)$ and then collecting terms to find the partial differential equation that the scheme actually solves.\n\nThe given numerical scheme is:\n$$u_{j}^{n+1} = u_{j}^{n} - a\\,\\Delta t\\, D_{-} u_{j}^{n} + \\frac{a^{2}\\Delta t^{2}}{2}\\, D_{-}^{2} u_{j}^{n} + \\kappa\\,a\\,\\Delta t\\,\\Delta x^{2}\\, D_{-}^{3} u_{j}^{n}$$\nWe start by expanding each term as a Taylor series in space and time around the point $(x_j, t_n)$, letting $u$ and its partial derivatives represent their values at this point.\n\nThe left-hand side expansion in time is:\n$$u_j^{n+1} = u + \\Delta t \\, u_t + \\frac{\\Delta t^2}{2} \\, u_{tt} + \\frac{\\Delta t^3}{6} \\, u_{ttt} + \\mathcal{O}(\\Delta t^4)$$\n\nThe expansions for the backward difference operators in space are:\n$$D_{-} u_{j}^{n} = \\frac{u - (u - \\Delta x u_x + \\frac{\\Delta x^2}{2} u_{xx} - \\frac{\\Delta x^3}{6} u_{xxx} + \\dots)}{\\Delta x} = u_x - \\frac{\\Delta x}{2} u_{xx} + \\frac{\\Delta x^2}{6} u_{xxx} + \\mathcal{O}(\\Delta x^3)$$\n$$D_{-}^{2} u_{j}^{n} = \\frac{u - 2(u - \\Delta x u_x + \\frac{\\Delta x^2}{2} u_{xx} - \\dots) + (u - 2\\Delta x u_x + \\frac{(2\\Delta x)^2}{2} u_{xx} - \\dots)}{\\Delta x^2} = u_{xx} - \\Delta x u_{xxx} + \\mathcal{O}(\\Delta x^2)$$\n$$D_{-}^{3} u_{j}^{n} = \\frac{u - 3(u - \\Delta x u_x + \\dots) + 3(u - 2\\Delta x u_x + \\dots) - (u - 3\\Delta x u_x + \\dots)}{\\Delta x^3} = u_{xxx} + \\mathcal{O}(\\Delta x)$$\nWe only need the leading term for $D_-^3$ as it is already multiplied by $\\Delta x^2$.\n\nLet's divide the entire scheme by $\\Delta t$ and substitute the expansions:\n$$\\frac{u_j^{n+1} - u_j^n}{\\Delta t} = - a\\, D_{-} u_{j}^{n} + \\frac{a^{2}\\Delta t}{2}\\, D_{-}^{2} u_{j}^{n} + \\kappa\\,a\\,\\Delta x^{2}\\, D_{-}^{3} u_{j}^{n}$$\nSubstituting the Taylor series:\n$$u_t + \\frac{\\Delta t}{2} u_{tt} + \\frac{\\Delta t^2}{6} u_{ttt} + \\dots = -a\\left(u_x - \\frac{\\Delta x}{2}u_{xx} + \\frac{\\Delta x^2}{6}u_{xxx} + \\dots\\right) + \\frac{a^2\\Delta t}{2}\\left(u_{xx} - \\Delta x u_{xxx} + \\dots\\right) + \\kappa a \\Delta x^2 (u_{xxx} + \\dots)$$\nWe rearrange this to form an equation for $u_t$:\n$$u_t = -a u_x + \\left(\\frac{a\\Delta x}{2} + \\frac{a^2\\Delta t}{2}\\right)u_{xx} - \\left(\\frac{a\\Delta x^2}{6} + \\frac{a^2\\Delta t\\Delta x}{2} - \\kappa a \\Delta x^2\\right)u_{xxx} - \\left(\\frac{\\Delta t}{2}u_{tt} + \\frac{\\Delta t^2}{6}u_{ttt}\\right) + \\dots$$\nThis is the preliminary modified equation, but it contains time derivatives on the right-hand side. We eliminate them by repeatedly using the equation itself. From the equation, we have $u_t = -a u_x + \\mathcal{O}(\\Delta x, \\Delta t)$. This allows us to approximate the time derivatives:\n$$u_{tt} = \\frac{\\partial}{\\partial t}(u_t) \\approx \\frac{\\partial}{\\partial t}(-a u_x) = -a u_{xt} = -a \\frac{\\partial}{\\partial x}(u_t) \\approx -a \\frac{\\partial}{\\partial x}(-a u_x) = a^2 u_{xx}$$\n$$u_{ttt} = \\frac{\\partial}{\\partial t}(u_{tt}) \\approx \\frac{\\partial}{\\partial t}(a^2 u_{xx}) = a^2 u_{xxt} = a^2 \\frac{\\partial^2}{\\partial x^2}(u_t) \\approx a^2 \\frac{\\partial^2}{\\partial x^2}(-a u_x) = -a^3 u_{xxx}$$\nThese are sufficiently accurate for the required order of analysis. Substituting these back into the equation for $u_t$:\n$$u_t = -a u_x + \\left(\\frac{a\\Delta x}{2} + \\frac{a^2\\Delta t}{2}\\right)u_{xx} - \\left(\\frac{a\\Delta x^2}{6} + \\frac{a^2\\Delta t\\Delta x}{2} - \\kappa a \\Delta x^2\\right)u_{xxx} - \\frac{\\Delta t}{2}(a^2 u_{xx}) - \\frac{\\Delta t^2}{6}(-a^3 u_{xxx}) + \\dots$$\nNow we group the terms by the spatial derivative to get the final form of the modified equation, $u_t + a u_x = C_2 u_{xx} + C_3 u_{xxx} + \\dots$.\n\nThe coefficient of the second derivative term, $u_{xx}$, is:\n$$C_2 = \\left(\\frac{a\\Delta x}{2} + \\frac{a^2\\Delta t}{2}\\right) - \\frac{a^2\\Delta t}{2} = \\frac{a\\Delta x}{2}$$\nThis term, being of order $\\mathcal{O}(\\Delta x)$, shows that the scheme is first-order accurate. The problem, however, asks us to analyze the coefficient of the third derivative.\n\nThe coefficient of the third derivative term, $u_{xxx}$, is:\n$$C_3 = -\\left(\\frac{a\\Delta x^2}{6} + \\frac{a^2\\Delta t\\Delta x}{2} - \\kappa a \\Delta x^2\\right) - \\frac{\\Delta t^2}{6}(-a^3) = -\\frac{a\\Delta x^2}{6} - \\frac{a^2\\Delta t\\Delta x}{2} + \\kappa a \\Delta x^2 + \\frac{a^3\\Delta t^2}{6}$$\nThe problem asks to find $\\kappa$ such that this coefficient, $C_3$, vanishes. To express $C_3$ in terms of the Courant number $\\nu = a\\Delta t/\\Delta x$, we substitute $\\Delta t = \\nu \\Delta x/a$:\n$$C_3 = -\\frac{a\\Delta x^2}{6} - \\frac{a^2(\\nu \\Delta x/a)\\Delta x}{2} + \\kappa a \\Delta x^2 + \\frac{a^3(\\nu \\Delta x/a)^2}{6}$$\n$$C_3 = -\\frac{a\\Delta x^2}{6} - \\frac{a\\nu\\Delta x^2}{2} + \\kappa a \\Delta x^2 + \\frac{a\\nu^2\\Delta x^2}{6}$$\nWe can factor out the term $a\\Delta x^2$:\n$$C_3 = a\\Delta x^2 \\left( -\\frac{1}{6} - \\frac{\\nu}{2} + \\kappa + \\frac{\\nu^2}{6} \\right)$$\nTo make the coefficient $C_3$ zero, the expression in the parenthesis must be zero:\n$$-\\frac{1}{6} - \\frac{\\nu}{2} + \\frac{\\nu^2}{6} + \\kappa = 0$$\nSolving for $\\kappa$ as a function of $\\nu$:\n$$\\kappa = \\frac{1}{6} + \\frac{\\nu}{2} - \\frac{\\nu^2}{6}$$\nCombining the terms into a single fraction gives the final expression for $\\kappa(\\nu)$:\n$$\\kappa(\\nu) = \\frac{1 + 3\\nu - \\nu^2}{6}$$\nThis is the unique analytic expression for $\\kappa(\\nu)$ that eliminates the specified dispersive error term.",
            "answer": "$$\\boxed{\\frac{1 + 3\\nu - \\nu^2}{6}}$$"
        },
        {
            "introduction": "This practice bridges classical numerical analysis with modern computational techniques. Instead of analytically canceling a single error term, we can frame scheme improvement as a data-driven optimization problem, learning a correction coefficient $c(\\nu,\\theta)$. You will formulate and solve a linear least-squares problem to find an optimal correction for the Beam-Warming scheme, minimizing error across a range of Courant numbers $\\nu$ and wavenumbers $\\theta$ . This exercise demonstrates how principles from machine learning can be used to engineer high-performance numerical methods.",
            "id": "3365998",
            "problem": "Consider the linear advection partial differential equation $u_t + a u_x = 0$ on a periodic uniform grid with spacing $\\Delta x$, advanced in time using an explicit single-step scheme with time step $\\Delta t$. Assume $a  0$ and define the Courant number $\\,\\nu = a\\,\\Delta t / \\Delta x$. Let the backward difference operator be $D_- u_i = u_i - u_{i-1}$, with higher-order backward differences $D_-^2 u_i = D_-(D_- u_i)$ and $D_-^3 u_i = D_- (D_-^2 u_i)$. The Beam-Warming higher-order upwind scheme seeks improved dispersion accuracy beyond first order by adding higher-order backward-difference terms derived from truncated Taylor expansion.\n\nYou are asked to augment the classical Beam-Warming update with a learned, small-stencil correction proportional to $D_-^3 u$. Specifically, consider the one-step update of the form\n$$\nu_i^{n+1} \\;=\\; u_i^n \\;-\\; \\nu\\, D_- u_i^n \\;+\\; \\frac{\\nu(1-\\nu)}{2}\\, D_-^2 u_i^n \\;+\\; c(\\nu,\\theta)\\, D_-^3 u_i^n,\n$$\nwhere $c(\\nu,\\theta)$ is a real-valued scalar coefficient to be learned as a function of the Courant number $\\nu$ and the non-dimensional wavenumber $\\theta = k\\,\\Delta x$; all angles must be expressed in radians. The learning objective is to minimize one-step dispersion error over a collection of Fourier modes. For a Fourier mode $u_i^n = \\exp(\\mathrm{i}\\,\\theta\\, i)$, the exact amplification factor over one step is $\\exp(-\\mathrm{i}\\,\\nu\\,\\theta)$. The numerical update with the correction generates an amplification factor $G(\\nu,\\theta;c)$ that must be derived from first principles, starting from the linear advection equation, the backward difference operator definitions, and properties of Fourier modes.\n\nYou must formulate $c(\\nu,\\theta)$ as a parametric model\n$$\nc(\\nu,\\theta) \\;=\\; \\sum_{m=1}^{M} w_m\\, \\phi_m(\\nu,\\theta),\n$$\nwith a chosen small set of real-valued basis functions $\\{\\phi_m(\\nu,\\theta)\\}_{m=1}^M$ that are polynomials in $\\nu$ and $\\theta$. Design the training objective by minimizing the mean squared complex residual between the corrected numerical amplification factor and the exact amplification factor over a training set of $(\\nu,\\theta)$ pairs:\n$$\n\\min_{w \\in \\mathbb{R}^M} \\;\\; \\frac{1}{N_{\\mathrm{train}}} \\sum_{(\\nu,\\theta) \\in \\mathcal{T}} \\left| G(\\nu,\\theta; c(\\nu,\\theta)) \\;-\\; e^{-\\mathrm{i}\\,\\nu\\,\\theta} \\right|^2,\n$$\nwith the constraint that $c(\\nu,\\theta)$ is real-valued. Derive a linear least-squares system for $w$ by expressing the residual in terms of the unknown coefficients and the derived Fourier symbols of the backward difference operators. Solve the least-squares problem using a numerically stable method, and report the learned $w$.\n\nAfter training, assess generalization to unseen spectra by evaluating the same mean squared complex residual over test sets of $(\\nu,\\theta)$ not present in training. Use angles in radians throughout. No physical units other than angles are needed.\n\nYour program must implement the following steps and produce the specified outputs:\n\n1. Derive the discrete Fourier symbol of $D_-^m$ acting on $\\exp(\\mathrm{i}\\,\\theta\\, i)$ for $m=1,2,3$, and from that derive the corrected numerical amplification factor $G(\\nu,\\theta;c)$ for the given update. Use this derivation to set up a real-valued linear least-squares problem for the coefficient vector $w$ of the chosen basis functions, ensuring $c(\\nu,\\theta)$ is real.\n\n2. Choose the basis functions\n   $$\n   \\phi_1(\\nu,\\theta)=1,\\quad \\phi_2(\\nu,\\theta)=\\nu,\\quad \\phi_3(\\nu,\\theta)=\\nu^2,\\quad \\phi_4(\\nu,\\theta)=\\theta,\\quad \\phi_5(\\nu,\\theta)=\\theta^2,\\quad \\phi_6(\\nu,\\theta)=\\nu\\,\\theta,\n   $$\n   i.e., $M=6$. Train $w$ on the training set\n   $$\n   \\mathcal{T} = \\{ \\nu \\in \\{0.2, 0.4, 0.6, 0.8\\} \\} \\times \\{ \\theta \\in \\{\\pi/12, \\pi/6, \\pi/4, \\pi/3, \\pi/2\\} \\}.\n   $$\n\n3. Compute and output the following four scalar diagnostics:\n   - The training mean squared residual,\n     $$\n     E_{\\mathrm{train}} = \\frac{1}{|\\mathcal{T}|} \\sum_{(\\nu,\\theta) \\in \\mathcal{T}} \\left| G(\\nu,\\theta;c(\\nu,\\theta)) - e^{-\\mathrm{i}\\,\\nu\\,\\theta} \\right|^2.\n     $$\n   - The validation mean squared residual on unseen wavenumbers (all angles in radians),\n     with test set\n     $$\n     \\mathcal{V}_\\theta = \\{ \\nu \\in \\{0.2, 0.4, 0.6, 0.8\\} \\} \\times \\{ \\theta \\in \\{\\pi/5, 2\\pi/5, 3\\pi/5\\} \\}.\n     $$\n   - The validation mean squared residual on unseen Courant numbers,\n     with test set\n     $$\n     \\mathcal{V}_\\nu = \\{ \\nu \\in \\{0.3, 0.5, 0.7\\} \\} \\times \\{ \\theta \\in \\{\\pi/12, \\pi/6, \\pi/4, \\pi/3, \\pi/2\\} \\}.\n     $$\n   - A high-frequency stress-test mean squared residual near the Nyquist limit on\n     $$\n     \\mathcal{S} = \\{ \\nu \\in \\{0.2, 0.4, 0.6, 0.8\\} \\} \\times \\{ \\theta \\in \\{5\\pi/6, 11\\pi/12, \\pi\\} \\}.\n     $$\n\nYour program should produce a single line of output containing the four results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"), where each result is a floating-point number. Angles must be in radians, and the solution should be fully self-contained and runnable without external input or files.",
            "solution": "The problem is valid as it is scientifically grounded in the numerical analysis of partial differential equations, is well-posed, objective, and provides a complete and consistent set of definitions and data. We proceed to the solution.\n\nThe core of the problem is to determine the coefficients $w_m$ of a parametric model for a correction term $c(\\nu,\\theta)$ in a modified Beam-Warming scheme by minimizing the dispersion error in the Fourier domain. This amounts to solving a linear least-squares problem.\n\nFirst, we perform a von Neumann stability analysis to find the numerical amplification factor $G(\\nu, \\theta; c)$. The scheme is given by\n$$u_i^{n+1} \\;=\\; u_i^n \\;-\\; \\nu\\, D_- u_i^n \\;+\\; \\frac{\\nu(1-\\nu)}{2}\\, D_-^2 u_i^n \\;+\\; c(\\nu,\\theta)\\, D_-^3 u_i^n.$$\nWe substitute a single Fourier mode $u_i^n = A^n e^{\\mathrm{i} i \\theta}$, where $\\theta = k \\Delta x$ is the dimensionless wavenumber and $A^n$ is the amplitude at time step $n$. The amplification factor is defined as $G(\\theta) = A^{n+1}/A^n$. Applying the finite difference operators to the Fourier mode yields:\n$$D_- e^{\\mathrm{i} i \\theta} = e^{\\mathrm{i} i \\theta} - e^{\\mathrm{i} (i-1) \\theta} = (1 - e^{-\\mathrm{i}\\theta}) e^{\\mathrm{i} i \\theta}.$$\nThe action of the operator $D_-$ on a Fourier mode is equivalent to multiplication by its symbol, $\\widehat{D_-}(\\theta) = 1 - e^{-\\mathrm{i}\\theta}$. Consequently, the symbol of the $m$-th power of the operator, $D_-^m$, is $\\widehat{D_-^m}(\\theta) = (1 - e^{-\\mathrm{i}\\theta})^m$.\n\nSubstituting this into the numerical scheme and dividing by $e^{\\mathrm{i} i \\theta}$ gives the numerical amplification factor:\n$$G(\\nu, \\theta; c) = 1 - \\nu \\widehat{D_-}(\\theta) + \\frac{\\nu(1-\\nu)}{2} \\widehat{D_-^2}(\\theta) + c(\\nu, \\theta) \\widehat{D_-^3}(\\theta).$$\nExplicitly, this is:\n$$G(\\nu, \\theta; c) = 1 - \\nu(1 - e^{-\\mathrm{i}\\theta}) + \\frac{\\nu(1-\\nu)}{2}(1 - e^{-\\mathrm{i}\\theta})^2 + c(\\nu, \\theta)(1 - e^{-\\mathrm{i}\\theta})^3.$$\nFor the exact solution of the advection equation $u_t + a u_x = 0$, a Fourier mode evolves as $u(x, t+\\Delta t) = u(x-a\\Delta t, t)$. In the discrete setting, this corresponds to an exact amplification factor $G_{exact}(\\nu, \\theta) = e^{-\\mathrm{i} a k \\Delta t} = e^{-\\mathrm{i} (a \\Delta t / \\Delta x) (k \\Delta x)} = e^{-\\mathrm{i} \\nu \\theta}$.\n\nThe objective is to minimize the mean squared complex residual between the numerical and exact amplification factors over the training set $\\mathcal{T}$:\n$$\\min_{w \\in \\mathbb{R}^M} \\;\\; \\frac{1}{N_{\\mathrm{train}}} \\sum_{(\\nu_j, \\theta_j) \\in \\mathcal{T}} \\left| G(\\nu_j, \\theta_j; c_j) - G_{exact}(\\nu_j, \\theta_j) \\right|^2.$$\nLet us define the residual for a single data point $(\\nu_j, \\theta_j)$ as $r_j = G_j - G_{exact, j}$. We can separate the known part of the scheme (the classical Beam-Warming part, $G_{BW}$) from the part containing the unknown parameters:\n$$G_j = G_{BW}(\\nu_j, \\theta_j) + c_j \\widehat{D_-^3}(\\theta_j),$$\nwhere $G_{BW}(\\nu, \\theta) = 1 - \\nu(1 - e^{-\\mathrm{i}\\theta}) + \\frac{\\nu(1-\\nu)}{2}(1 - e^{-\\mathrm{i}\\theta})^2$ and $c_j = c(\\nu_j, \\theta_j)$.\nThe residual is then:\n$$r_j = G_{BW}(\\nu_j, \\theta_j) + c_j \\widehat{D_-^3}(\\theta_j) - G_{exact}(\\nu_j, \\theta_j).$$\nSubstituting the parametric model for $c_j$, which is $c(\\nu_j, \\theta_j) = \\sum_{m=1}^{M} w_m \\phi_m(\\nu_j, \\theta_j)$, we obtain:\n$$r_j = G_{BW}(\\nu_j, \\theta_j) + \\left(\\sum_{m=1}^{M} w_m \\phi_m(\\nu_j, \\theta_j)\\right) \\widehat{D_-^3}(\\theta_j) - G_{exact}(\\nu_j, \\theta_j).$$\nTo formulate a linear least-squares problem, we rearrange this equation to isolate the unknown weights $w_m$:\n$$\\sum_{m=1}^{M} w_m \\left(\\phi_m(\\nu_j, \\theta_j) \\widehat{D_-^3}(\\theta_j)\\right) \\approx G_{exact}(\\nu_j, \\theta_j) - G_{BW}(\\nu_j, \\theta_j).$$\nThis equation for all $j \\in \\{1, \\dots, N_{\\mathrm{train}}\\}$ forms a linear system $A\\mathbf{w} \\approx \\mathbf{b}$, where $\\mathbf{w}$ is the real-valued vector of weights $[w_1, \\dots, w_M]^T$. The matrix $A$ and vector $\\mathbf{b}$ are complex-valued, with entries for the $j$-th sample given by:\n$$A_{j,m} = \\phi_m(\\nu_j, \\theta_j) \\widehat{D_-^3}(\\theta_j) = \\phi_m(\\nu_j, \\theta_j) (1 - e^{-\\mathrm{i}\\theta_j})^3$$\n$$b_j = G_{exact}(\\nu_j, \\theta_j) - G_{BW}(\\nu_j, \\theta_j) = e^{-\\mathrm{i}\\nu_j\\theta_j} - \\left( 1 - \\nu_j(1-e^{-\\mathrm{i}\\theta_j}) + \\frac{\\nu_j(1-\\nu_j)}{2}(1-e^{-\\mathrm{i}\\theta_j})^2 \\right).$$\nSince the weights $\\mathbf{w}$ must be real, but $A$ and $\\mathbf{b}$ are complex, we convert the system $A\\mathbf{w} \\approx \\mathbf{b}$ into an equivalent real-valued system. Let $A = A_R + \\mathrm{i}A_I$ and $\\mathbf{b} = \\mathbf{b}_R + \\mathrm{i}\\mathbf{b}_I$. The minimization problem $\\min_{\\mathbf{w} \\in \\mathbb{R}^M} \\| A\\mathbf{w} - \\mathbf{b} \\|_2^2$ is equivalent to minimizing $\\| (A_R \\mathbf{w} - \\mathbf{b}_R) + \\mathrm{i}(A_I \\mathbf{w} - \\mathbf{b}_I) \\|_2^2$, which simplifies to minimizing $\\| A_R \\mathbf{w} - \\mathbf{b}_R \\|_2^2 + \\| A_I \\mathbf{w} - \\mathbf{b}_I \\|_2^2$. This is the standard least-squares solution to the vertically concatenated real system:\n$$\\begin{pmatrix} A_R \\\\ A_I \\end{pmatrix} \\mathbf{w} \\approx \\begin{pmatrix} \\mathbf{b}_R \\\\ \\mathbf{b}_I \\end{pmatrix}.$$\nThis system $\\tilde{A}\\mathbf{w} \\approx \\tilde{\\mathbf{b}}$ has a $2N_{\\mathrm{train}} \\times M$ matrix $\\tilde{A}$ and a $2N_{\\mathrm{train}} \\times 1$ vector $\\tilde{\\mathbf{b}}$. For this problem, $N_{\\mathrm{train}} = 4 \\times 5 = 20$ samples and $M=6$ basis functions. The overdetermined system is solved numerically using a stable method such as one based on QR factorization or Singular Value Decomposition (SVD).\n\nThe implementation proceeds as follows:\n1.  The training set $\\mathcal{T}$ of $20$ pairs of $(\\nu, \\theta)$ is constructed.\n2.  For each pair $(\\nu_j, \\theta_j) \\in \\mathcal{T}$, the basis functions $\\phi_m(\\nu_j, \\theta_j)$ are evaluated for $m=1, \\dots, 6$.\n3.  The complex matrix entries $A_{j,m}$ and vector entries $b_j$ are calculated.\n4.  The real system matrix $\\tilde{A}$ of size $40 \\times 6$ and vector $\\tilde{\\mathbf{b}}$ of size $40 \\times 1$ are assembled.\n5.  The linear least-squares problem $\\tilde{A}\\mathbf{w} \\approx \\tilde{\\mathbf{b}}$ is solved to find the optimal real weight vector $\\mathbf{w}$.\n6.  With the learned weights $\\mathbf{w}$, the correction coefficient $c(\\nu, \\theta)$ is now fully defined.\n7.  Finally, the mean squared residual is computed for the training set $\\mathcal{T}$ and the three test sets $\\mathcal{V}_\\theta$, $\\mathcal{V}_\\nu$, and $\\mathcal{S}$ by evaluating $|G(\\nu, \\theta; c(\\nu, \\theta)) - G_{exact}(\\nu, \\theta)|^2$ for each point and averaging over the respective set.\n\nThis procedure yields the required four diagnostic values.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves for the optimal correction term in a modified Beam-Warming scheme and evaluates its performance.\n    \"\"\"\n    \n    # 1. Define sets of Courant numbers (nu) and wavenumbers (theta) for training and testing.\n    # Training set T\n    nu_train = np.array([0.2, 0.4, 0.6, 0.8])\n    theta_train = np.array([np.pi/12, np.pi/6, np.pi/4, np.pi/3, np.pi/2])\n    \n    # Validation set for unseen wavenumbers V_theta\n    nu_val_theta = np.array([0.2, 0.4, 0.6, 0.8])\n    theta_val_theta = np.array([np.pi/5, 2*np.pi/5, 3*np.pi/5])\n    \n    # Validation set for unseen Courant numbers V_nu\n    nu_val_nu = np.array([0.3, 0.5, 0.7])\n    theta_val_nu = np.array([np.pi/12, np.pi/6, np.pi/4, np.pi/3, np.pi/2])\n    \n    # High-frequency stress-test set S\n    nu_stress = np.array([0.2, 0.4, 0.6, 0.8])\n    theta_stress = np.array([5*np.pi/6, 11*np.pi/12, np.pi])\n\n    # 2. Define basis functions phi_m(nu, theta) for the parametric model of c(nu, theta).\n    # phi_1=1, phi_2=nu, phi_3=nu^2, phi_4=theta, phi_5=theta^2, phi_6=nu*theta\n    def get_phi_vector(nu, theta):\n        return np.array([1, nu, nu**2, theta, theta**2, nu*theta])\n\n    # 3. Construct and solve the linear least-squares problem to find the weights w.\n    train_set = np.array(np.meshgrid(nu_train, theta_train, indexing='ij')).T.reshape(-1, 2)\n    N_train = train_set.shape[0]\n    M = 6  # Number of basis functions\n\n    # Complex-valued matrix A and vector b for the system A*w = b\n    A_complex = np.zeros((N_train, M), dtype=np.complex128)\n    b_complex = np.zeros(N_train, dtype=np.complex128)\n\n    for i, (nu, theta) in enumerate(train_set):\n        # Fourier symbols of backward difference operators\n        d_minus_symbol = 1 - np.exp(-1j * theta)\n        d_minus_2_symbol = d_minus_symbol**2\n        d_minus_3_symbol = d_minus_symbol**3\n\n        # Uncorrected Beam-Warming amplification factor G_bw\n        G_bw = 1 - nu * d_minus_symbol + (nu * (1 - nu) / 2) * d_minus_2_symbol\n\n        # Exact amplification factor G_exact\n        G_exact = np.exp(-1j * nu * theta)\n\n        # Populate the i-th row of A and b\n        b_complex[i] = G_exact - G_bw\n        phi_vec = get_phi_vector(nu, theta)\n        A_complex[i, :] = phi_vec * d_minus_3_symbol\n\n    # Convert the complex system to a real system by stacking real and imaginary parts\n    A_real = np.vstack([A_complex.real, A_complex.imag])\n    b_real = np.hstack([b_complex.real, b_complex.imag])\n\n    # Solve the real-valued least-squares problem for the weights w\n    w, _, _, _ = np.linalg.lstsq(A_real, b_real, rcond=None)\n\n    # 4. Evaluate the mean squared residual on all specified datasets.\n    def calculate_mse(nu_values, theta_values, weights):\n        \"\"\"\n        Calculates the mean squared error between the corrected numerical and exact\n        amplification factors for a given set of nu and theta values.\n        \"\"\"\n        dataset = np.array(np.meshgrid(nu_values, theta_values, indexing='ij')).T.reshape(-1, 2)\n        total_sq_error = 0.0\n\n        for nu, theta in dataset:\n            # Fourier symbols\n            d_minus_symbol = 1 - np.exp(-1j * theta)\n            d_minus_2_symbol = d_minus_symbol**2\n            d_minus_3_symbol = d_minus_symbol**3\n\n            # Calculate the learned correction coefficient c(nu, theta)\n            phi_vec = get_phi_vector(nu, theta)\n            c = np.dot(weights, phi_vec)\n\n            # Calculate the corrected numerical amplification factor G_corrected\n            G_corrected = (1 - nu * d_minus_symbol +\n                           (nu * (1 - nu) / 2) * d_minus_2_symbol +\n                           c * d_minus_3_symbol)\n\n            # Exact amplification factor G_exact\n            G_exact = np.exp(-1j * nu * theta)\n\n            # Accumulate the squared absolute error\n            error = G_corrected - G_exact\n            total_sq_error += np.abs(error)**2\n        \n        return total_sq_error / len(dataset)\n\n    # Calculate the four required diagnostic values\n    E_train = calculate_mse(nu_train, theta_train, w)\n    E_val_theta = calculate_mse(nu_val_theta, theta_val_theta, w)\n    E_val_nu = calculate_mse(nu_val_nu, theta_val_nu, w)\n    E_stress = calculate_mse(nu_stress, theta_stress, w)\n    \n    results = [E_train, E_val_theta, E_val_nu, E_stress]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.12e}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}