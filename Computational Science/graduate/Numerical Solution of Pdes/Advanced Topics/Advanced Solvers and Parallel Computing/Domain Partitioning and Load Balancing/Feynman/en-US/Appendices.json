{
    "hands_on_practices": [
        {
            "introduction": "The ultimate goal of domain partitioning is to improve performance by minimizing idle time and communication overhead. This exercise provides a practical framework for evaluating the effectiveness of a partitioning strategy by analyzing concrete performance data. By working through this problem , you will connect the theoretical concepts of load imbalance and communication cost to measurable quantities and learn how to calculate the expected speedup from a repartitioning effort.",
            "id": "3382812",
            "problem": "Consider an implicit solver for a three-dimensional elliptic partial differential equation with a finite-volume discretization, executed on a distributed-memory High-Performance Computing (HPC) cluster using the Message Passing Interface (MPI). In each nonlinear iteration, the solver performs computation on subdomains and exchanges ghost data with neighbors. The parallel iteration time is modeled as the sum of the computation time and the communication time, with the computation time determined by the slowest process (to account for load imbalance). Formally, for one iteration on a given partition, the total time is defined by $T_{\\text{total}}=T_{\\text{comp}}+T_{\\text{comm}}$, where $T_{\\text{comp}}=\\gamma\\,\\bar{t}_{\\text{comp}}$ and $\\gamma=\\frac{t_{\\text{comp}}^{\\max}}{\\bar{t}_{\\text{comp}}}$ is the imbalance factor.\n\nA baseline partition over $P=64$ processes has the following profiling data aggregated over $60$ iterations:\n- Mean per-process computation time per iteration before repartition: $\\bar{t}_{\\text{comp}}^{\\text{b}}=0.011\\,\\text{s}$.\n- Imbalance factor before repartition: $\\gamma^{\\text{b}}=1.09$.\n- Dominant communication time per iteration before repartition: $t_{\\text{comm}}^{\\text{b}}=0.0040\\,\\text{s}$.\n- Sample mean and sample standard deviation of total iteration time before repartition: $\\bar{t}_{\\text{total}}^{\\text{b}}=0.01599\\,\\text{s}$ and $s^{\\text{b}}=0.0012\\,\\text{s}$.\n\nA graph-based repartition is applied to reduce both imbalance and the number of interprocess edges. The new profiling data over $60$ iterations is:\n- Mean per-process computation time per iteration after repartition: $\\bar{t}_{\\text{comp}}^{\\text{a}}=0.0103\\,\\text{s}$.\n- Imbalance factor after repartition: $\\gamma^{\\text{a}}=1.02$.\n- Dominant communication time per iteration after repartition: $t_{\\text{comm}}^{\\text{a}}=0.0028\\,\\text{s}$.\n- Sample mean and sample standard deviation of total iteration time after repartition: $\\bar{t}_{\\text{total}}^{\\text{a}}=0.013306\\,\\text{s}$ and $s^{\\text{a}}=0.0009\\,\\text{s}$.\n\nUsing only the foundational definitions above, do the following:\n1. From the component times, compute the expected speedup $S$ due to the repartition, defined by $S=\\frac{T_{\\text{total}}^{\\text{b}}}{T_{\\text{total}}^{\\text{a}}}$.\n2. Assess whether the observed change in total iteration time is statistically significant by performing a two-sample Welch’s $t$-test (unequal variances) to test the null hypothesis that the mean total iteration times before and after are equal, at significance level $\\alpha=0.01$. Report the test statistic, approximate degrees of freedom, and the two-sided $p$-value, and state whether the change is significant.\n\nRound the expected speedup $S$ to four significant figures. The final numeric answer to provide is the rounded expected speedup $S$ with no units. All intermediate quantities may use seconds as the unit.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\nThe given data and definitions are as follows:\n- Total iteration time model: $T_{\\text{total}}=T_{\\text{comp}}+T_{\\text{comm}}$\n- Computation time model: $T_{\\text{comp}}=\\gamma\\,\\bar{t}_{\\text{comp}}$, where $\\gamma$ is the imbalance factor.\n- Number of processes: $P=64$\n- Number of iterations per sample: $N=60$\n- Significance level for statistical test: $\\alpha=0.01$\n\n- Data before repartition (baseline):\n  - Mean per-process computation time: $\\bar{t}_{\\text{comp}}^{\\text{b}}=0.011\\,\\text{s}$\n  - Imbalance factor: $\\gamma^{\\text{b}}=1.09$\n  - Communication time: $t_{\\text{comm}}^{\\text{b}}=0.0040\\,\\text{s}$\n  - Sample mean of total time: $\\bar{t}_{\\text{total}}^{\\text{b}}=0.01599\\,\\text{s}$\n  - Sample standard deviation of total time: $s^{\\text{b}}=0.0012\\,\\text{s}$\n\n- Data after repartition:\n  - Mean per-process computation time: $\\bar{t}_{\\text{comp}}^{\\text{a}}=0.0103\\,\\text{s}$\n  - Imbalance factor: $\\gamma^{\\text{a}}=1.02$\n  - Communication time: $t_{\\text{comm}}^{\\text{a}}=0.0028\\,\\text{s}$\n  - Sample mean of total time: $\\bar{t}_{\\text{total}}^{\\text{a}}=0.013306\\,\\text{s}$\n  - Sample standard deviation of total time: $s^{\\text{a}}=0.0009\\,\\text{s}$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the principles of parallel computing and performance modeling for numerical simulations. The models for computation and communication time are standard in this field. The values are realistic for a HPC simulation. The problem is well-posed, providing all necessary data for the requested calculations. The consistency of the provided data is checked:\n- Modeled total time before: $T_{\\text{total}}^{\\text{b}} = \\gamma^{\\text{b}}\\,\\bar{t}_{\\text{comp}}^{\\text{b}} + t_{\\text{comm}}^{\\text{b}} = (1.09)(0.011\\,\\text{s}) + 0.0040\\,\\text{s} = 0.01199\\,\\text{s} + 0.0040\\,\\text{s} = 0.01599\\,\\text{s}$. This matches the provided sample mean $\\bar{t}_{\\text{total}}^{\\text{b}}$.\n- Modeled total time after: $T_{\\text{total}}^{\\text{a}} = \\gamma^{\\text{a}}\\,\\bar{t}_{\\text{comp}}^{\\text{a}} + t_{\\text{comm}}^{\\text{a}} = (1.02)(0.0103\\,\\text{s}) + 0.0028\\,\\text{s} = 0.010506\\,\\text{s} + 0.0028\\,\\text{s} = 0.013306\\,\\text{s}$. This matches the provided sample mean $\\bar{t}_{\\text{total}}^{\\text{a}}$.\nThe problem is internally consistent, objective, and contains no scientific flaws, ambiguities, or missing information.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n### Part 1: Expected Speedup Calculation\nThe expected speedup $S$ is the ratio of the total iteration time before repartition to the total iteration time after repartition. The total times are calculated using the provided performance model.\n\nThe total time before repartition, $T_{\\text{total}}^{\\text{b}}$, is:\n$$T_{\\text{total}}^{\\text{b}} = T_{\\text{comp}}^{\\text{b}} + T_{\\text{comm}}^{\\text{b}} = \\gamma^{\\text{b}}\\,\\bar{t}_{\\text{comp}}^{\\text{b}} + t_{\\text{comm}}^{\\text{b}}$$\nSubstituting the given values:\n$$T_{\\text{total}}^{\\text{b}} = (1.09)(0.011) + 0.0040 = 0.01199 + 0.0040 = 0.01599\\,\\text{s}$$\n\nThe total time after repartition, $T_{\\text{total}}^{\\text{a}}$, is:\n$$T_{\\text{total}}^{\\text{a}} = T_{\\text{comp}}^{\\text{a}} + T_{\\text{comm}}^{\\text{a}} = \\gamma^{\\text{a}}\\,\\bar{t}_{\\text{comp}}^{\\text{a}} + t_{\\text{comm}}^{\\text{a}}$$\nSubstituting the given values:\n$$T_{\\text{total}}^{\\text{a}} = (1.02)(0.0103) + 0.0028 = 0.010506 + 0.0028 = 0.013306\\,\\text{s}$$\n\nThe expected speedup $S$ is defined as:\n$$S = \\frac{T_{\\text{total}}^{\\text{b}}}{T_{\\text{total}}^{\\text{a}}}$$\nSubstituting the calculated total times:\n$$S = \\frac{0.01599}{0.013306} \\approx 1.2017135$$\nRounding to four significant figures as requested, we get:\n$$S \\approx 1.202$$\n\n### Part 2: Statistical Significance Test\nTo assess if the change in total iteration time is statistically significant, we perform a two-sample Welch's $t$-test for the null hypothesis $H_0: \\mu_{\\text{b}} = \\mu_{\\text{a}}$ against the alternative hypothesis $H_1: \\mu_{\\text{b}} \\neq \\mu_{\\text{a}}$, where $\\mu_{\\text{b}}$ and $\\mu_{\\text{a}}$ are the true mean total iteration times before and after repartition, respectively. The significance level is $\\alpha=0.01$.\n\nThe sample data are:\n- Sample 1 (before): sample size $n_1=60$, sample mean $\\bar{x}_1 = \\bar{t}_{\\text{total}}^{\\text{b}} = 0.01599$, sample standard deviation $s_1 = s^{\\text{b}} = 0.0012$.\n- Sample 2 (after): sample size $n_2=60$, sample mean $\\bar{x}_2 = \\bar{t}_{\\text{total}}^{\\text{a}} = 0.013306$, sample standard deviation $s_2 = s^{\\text{a}} = 0.0009$.\n\nThe Welch's $t$-statistic is calculated as:\n$$t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$$\nSubstituting the values:\n$$t = \\frac{0.01599 - 0.013306}{\\sqrt{\\frac{(0.0012)^2}{60} + \\frac{(0.0009)^2}{60}}} = \\frac{0.002684}{\\sqrt{\\frac{1.44 \\times 10^{-6}}{60} + \\frac{0.81 \\times 10^{-6}}{60}}}$$\n$$t = \\frac{0.002684}{\\sqrt{2.4 \\times 10^{-8} + 1.35 \\times 10^{-8}}} = \\frac{0.002684}{\\sqrt{3.75 \\times 10^{-8}}} \\approx \\frac{0.002684}{1.93649 \\times 10^{-4}} \\approx 13.86$$\nThe test statistic is $t \\approx 13.86$.\n\nThe degrees of freedom $\\nu$ are approximated using the Welch-Satterthwaite equation:\n$$\\nu \\approx \\frac{\\left( \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} \\right)^2}{\\frac{(s_1^2/n_1)^2}{n_1-1} + \\frac{(s_2^2/n_2)^2}{n_2-1}} = \\frac{\\left( 3.75 \\times 10^{-8} \\right)^2}{\\frac{(2.4 \\times 10^{-8})^2}{59} + \\frac{(1.35 \\times 10^{-8})^2}{59}}$$\n$$\\nu \\approx \\frac{1.40625 \\times 10^{-15}}{\\frac{5.76 \\times 10^{-16}}{59} + \\frac{1.8225 \\times 10^{-16}}{59}} = \\frac{1.40625 \\times 10^{-15}}{(9.7627 \\times 10^{-18}) + (3.0890 \\times 10^{-18})} \\approx \\frac{1.40625 \\times 10^{-15}}{1.28517 \\times 10^{-17}} \\approx 109.4$$\nThe approximate degrees of freedom are $\\nu \\approx 109.4$.\n\nFor a two-sided test with $\\nu \\approx 109.4$ and a test statistic of $t \\approx 13.86$, the $p$-value is given by $P(|T| > 13.86)$, where $T$ follows a $t$-distribution with $109.4$ degrees of freedom. This is an extremely large $t$-value, indicating a very small $p$-value. The $p$-value is far smaller than any conventional significance level, $p \\ll 0.0001$.\n\nConclusion of the test: Since the $p$-value is substantially smaller than the specified significance level $\\alpha=0.01$, we reject the null hypothesis $H_0$. This means there is extremely strong statistical evidence that the observed reduction in total iteration time is not due to random chance. The change is statistically significant.\n\nSummary of statistical results:\n- Test statistic: $t \\approx 13.86$\n- Approximate degrees of freedom: $\\nu \\approx 109.4$\n- Two-sided $p$-value: $p \\ll 0.0001$\n- Conclusion: The change in mean total iteration time is statistically significant at the $\\alpha=0.01$ level.\n\nThe problem requires providing only the computed speedup $S$ as the final answer.",
            "answer": "$$\\boxed{1.202}$$"
        },
        {
            "introduction": "While space-filling curves offer an elegant way to map multidimensional domains to one dimension for easy partitioning, their effectiveness depends critically on the geometry of the underlying grid. This exercise  challenges you to analyze the performance of SFC-based partitioning on a highly anisotropic mesh, a scenario common in fluid dynamics and other fields. You will derive the asymptotic communication costs and identify the critical conditions under which these geometry-oblivious methods are outperformed by anisotropy-aware graph partitioners.",
            "id": "3382849",
            "problem": "You are given a two-dimensional boundary-layer mesh arising from the numerical solution of partial differential equations in a rectangular domain of fixed physical size. The mesh has highly anisotropic cells of aspect ratio $a \\gg 1$, defined as the ratio of the tangential to normal cell sizes near the wall. Let the total number of mesh cells be $N$, arranged on a logically rectangular grid with $n_x$ cells in the streamwise direction and $n_y$ in the wall-normal direction, so that $n_x n_y = N$ and the anisotropy at fixed physical size implies $n_x \\asymp N^{1/2} a^{-1/2}$ and $n_y \\asymp N^{1/2} a^{1/2}$. The mesh is partitioned among $P$ identical processors.\n\nCommunication volume is modeled as the total number of unique inter-partition mesh adjacencies (graph edges) cut by the partition, denoted $V$. You will compare three families of partitions:\n\n- Space-filling curve (SFC) partitions based on contiguous segments of Morton (Z-order) or Hilbert curves defined on the $n_x \\times n_y$ grid. Denote their communication volumes by $V_M$ and $V_H$ respectively.\n- An “optimal” multilevel graph partitioner that can exploit anisotropy by aligning cuts as stripes along the long direction, yielding communication volume $V_G$.\n\nUse the following modeling assumptions derived from core geometric principles:\n\n- For a connected set of $A_b$ grid cells with $A_b \\ll n_x n_y$, the minimal interface length in grid edges satisfies an isoperimetric scaling $L_{\\min}(A_b) \\asymp \\min\\{\\kappa_1 \\sqrt{A_b}, \\kappa_2 A_b/n_x\\}$, where the first term corresponds to nearly square shapes and the second to “strip-like” shapes when the width saturates at $n_x$. Here $\\kappa_1$ and $\\kappa_2$ are constants independent of $a$, $N$, and $P$.\n- A contiguous range of the Hilbert space-filling curve (SFC) produces a single connected block whose interface is within a constant factor of $L_{\\min}(A_b)$, while a Morton SFC block has the same asymptotic exponents but a larger constant. Therefore, neglecting constants, you may take $L_H(A_b) \\asymp \\min\\{\\sqrt{A_b}, A_b/n_x\\}$ and $L_M(A_b) \\asymp \\min\\{\\sqrt{A_b}, A_b/n_x\\}$ for scaling purposes.\n- Partitioning by taking $P$ equal contiguous SFC segments yields $P$ blocks each of area $A_b = N/P$. The total unique cut edges for SFC partitions scale as $V_{\\mathrm{SFC}} \\asymp \\tfrac{P}{2} L_{\\mathrm{SFC}}(A_b)$, up to constants that do not depend on $a$, $N$, and $P$.\n- A stripe partition aligned with the long direction cuts across the short side $n_x$, creating $P-1$ boundaries of length $n_x$, so $V_G \\asymp n_x P$ to leading order.\n\nTasks:\n\n- Starting from the above foundational scalings and the definitions of communication volume as cut size in the dual graph, derive asymptotic formulas for $V_H(a,P,N)$ and $V_M(a,P,N)$ as functions of $a$, $P$, and $N$, including the regime change in $P$ relative to $a$ imposed by the constraint $A_b \\le n_x^2$.\n- Identify the regime in which space-filling curves underperform the stripe-aligned graph partitioning by comparing $V_H$ (or $V_M$) to $V_G$.\n- Finally, determine the asymptotic critical processor count $P^{\\star}(a)$ at which the Hilbert SFC communication volume matches that of the stripe graph partitioner to leading order in $a \\gg 1$ and ignoring constant factors and lower-order terms.\n\nProvide your final answer as a single closed-form expression for $P^{\\star}(a)$ in terms of $a$ only. No numerical rounding is required and no units are to be reported. Clearly state any intermediate regime conditions you use during the derivation, but ensure the final reported quantity is only $P^{\\star}(a)$.",
            "solution": "The user-provided problem is first subjected to a rigorous validation procedure.\n\n### Step 1: Extract Givens\n- **Mesh Properties**: A two-dimensional, logically rectangular boundary-layer mesh in a domain of fixed physical size.\n- **Anisotropy**: Cell aspect ratio $a \\gg 1$.\n- **Grid Size**: Total cells $N$, with $n_x$ cells in the streamwise direction and $n_y$ in the wall-normal direction.\n- **Grid Scalings**: $n_x n_y = N$, $n_x \\asymp N^{1/2} a^{-1/2}$, $n_y \\asymp N^{1/2} a^{1/2}$.\n- **Parallelization**: The mesh is partitioned among $P$ identical processors.\n- **Communication Volume ($V$)**: Total number of unique cut mesh edges.\n- **Partitioning Methods and Volume Models**:\n    - Space-filling curve (SFC) partitions (Morton $V_M$, Hilbert $V_H$): Total cut edges scale as $V_{\\mathrm{SFC}} \\asymp \\frac{P}{2} L_{\\mathrm{SFC}}(A_b)$, with $A_b = N/P$. For scaling purposes, this is taken as $V_{\\mathrm{SFC}} \\asymp P \\cdot L_{\\mathrm{SFC}}(A_b)$.\n    - The interface length for an SFC block of area $A_b$ is modeled as $L_H(A_b) \\asymp \\min\\{\\sqrt{A_b}, A_b/n_x\\}$ and $L_M(A_b) \\asymp \\min\\{\\sqrt{A_b}, A_b/n_x\\}$, neglecting constants.\n    - Stripe graph partitioner ($V_G$): Communication volume scales as $V_G \\asymp n_x P$.\n- **Constraint**: A regime change is noted, associated with the condition $A_b \\le n_x^2$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is well-grounded in the field of parallel scientific computing, specifically the performance analysis of domain decomposition methods for solving partial differential equations on structured anisotropic grids. The concepts of mesh anisotropy, space-filling curves, graph partitioning, and communication volume scaling are standard in this domain. The problem is directly relevant to the specified topic *domain partitioning and load balancing* for the *numerical solution of pdes*.\n- **Well-Posedness**: The problem provides a complete set of scaling relations and definitions required to derive the desired quantities. The tasks are clearly stated, leading to a unique asymptotic result.\n- **Objectivity**: The problem is stated in precise, objective, and technical language, free from subjective claims.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid** as it is scientifically sound, well-posed, and objective. A full solution will be provided.\n\n### Solution Derivation\n\nThe analysis proceeds by deriving the asymptotic scaling laws for the communication volume of each partitioning strategy and then comparing them to find the critical processor count $P^{\\star}(a)$. Asymptotic equivalence is denoted by $\\asymp$, and we will treat it as equality for the purpose of solving for $P^{\\star}$, since we are ignoring constant factors.\n\n**1. Asymptotic Formula for SFC Communication Volume ($V_H$, $V_M$)**\n\nThe communication volume for an SFC partition is given by $V_{\\mathrm{SFC}} \\asymp P \\cdot L_{\\mathrm{SFC}}(A_b)$, where the block area is $A_b = N/P$. The interface length of a single block is $L_{\\mathrm{SFC}}(A_b) \\asymp \\min\\{\\sqrt{A_b}, A_b/n_x\\}$.\n\nThe behavior of the $\\min$ function depends on the comparison between $\\sqrt{A_b}$ and $A_b/n_x$. The two terms are equal when $\\sqrt{A_b} = A_b/n_x$, which implies $\\sqrt{A_b} = n_x$, or $A_b = n_x^2$. Let's determine the condition on $P$ for this crossover.\n$$A_b = n_x^2 \\implies \\frac{N}{P} = \\left(N^{1/2} a^{-1/2}\\right)^2 = \\frac{N}{a} \\implies P = a$$\nThis defines two regimes for the processor count $P$ relative to the anisotropy $a$.\n\nBased on the physical interpretation that \"squarish\" blocks are possible for small areas and \"strip-like\" shapes are forced for large areas:\n- For $P > a$ (small blocks, 'squarish' possible): $\\sqrt{A_b} < n_x$, so the block fits within the width of the domain. The minimal perimeter scales as $L_{\\mathrm{SFC}}(A_b) \\asymp \\sqrt{A_b} = \\sqrt{N/P}$.\n- For $P < a$ (large blocks, 'strip-like' forced): $\\sqrt{A_b} > n_x$, so the block's width is constrained by the domain width $n_x$. The minimal perimeter scales as $L_{\\mathrm{SFC}}(A_b) \\asymp A_b/n_x = (N/P)/n_x$.\n\nNow we compute $V_{\\mathrm{SFC}} \\asymp P \\cdot L_{\\mathrm{SFC}}(A_b)$:\n- For $P > a$: $V_{\\mathrm{SFC}} \\asymp P \\sqrt{N/P} = \\sqrt{NP}$.\n- For $P \\le a$: $V_{\\mathrm{SFC}} \\asymp P \\cdot \\frac{N/P}{n_x} = \\frac{N}{n_x}$. Substituting $n_x \\asymp N^{1/2} a^{-1/2}$, we get $V_{\\mathrm{SFC}} \\asymp \\frac{N}{N^{1/2} a^{-1/2}} = N^{1/2} a^{1/2}$.\n\nSo, the asymptotic formula for $V_H$ and $V_M$ is:\n$$V_{\\mathrm{SFC}}(a,P,N) \\asymp \\begin{cases} N^{1/2} a^{1/2} & \\text{for } P \\le a \\\\ \\sqrt{NP} & \\text{for } P > a \\end{cases}$$\nThis shows that for a low number of processors, the communication cost is constant, determined by the grid anisotropy. For a high number of processors, the cost grows as $\\sqrt{P}$.\n\n**2. Asymptotic Formula for Stripe Partitioner ($V_G$)**\n\nThe model for the stripe graph partitioner is given as $V_G \\asymp n_x P$. Substituting the scaling for $n_x$:\n$$V_G(a,P,N) \\asymp (N^{1/2} a^{-1/2}) P = P N^{1/2} a^{-1/2}$$\n\n**3. Comparison and Identification of Underperformance Regime**\n\nWe compare $V_{\\mathrm{SFC}}$ and $V_G$ in the two regimes of $P$.\n-   **Regime 1: $P \\le a$**\n    $V_{\\mathrm{SFC}} \\asymp N^{1/2} a^{1/2}$.\n    $V_G \\asymp P N^{1/2} a^{-1/2}$.\n    The ratio is $\\frac{V_{\\mathrm{SFC}}}{V_G} \\asymp \\frac{N^{1/2} a^{1/2}}{P N^{1/2} a^{-1/2}} = \\frac{a}{P}$.\n    Since $P \\le a$ and $a \\gg 1$, this ratio is $\\ge 1$. Thus, $V_{\\mathrm{SFC}} \\ge V_G$. Space-filling curves underperform (or perform equally when $P=a$) compared to the anisotropy-aware stripe partitioner in this regime.\n\n-   **Regime 2: $P > a$**\n    $V_{\\mathrm{SFC}} \\asymp \\sqrt{NP} = N^{1/2} P^{1/2}$.\n    $V_G \\asymp P N^{1/2} a^{-1/2}$.\n    The ratio is $\\frac{V_{\\mathrm{SFC}}}{V_G} \\asymp \\frac{N^{1/2} P^{1/2}}{P N^{1/2} a^{-1/2}} = \\frac{P^{1/2}}{P a^{-1/2}} = \\frac{a^{1/2}}{P^{1/2}} = \\sqrt{\\frac{a}{P}}$.\n    Since $P > a$, this ratio is less than $1$. Thus, $V_{\\mathrm{SFC}} < V_G$. In this regime, space-filling curves outperform the stripe partitioner.\n\nThe regime where SFCs underperform is $P \\le a$.\n\n**4. Determination of the Critical Processor Count $P^{\\star}(a)$**\n\nThe critical processor count $P^{\\star}(a)$ is the value of $P$ where the communication volumes are equal, i.e., $V_H(P^{\\star}) \\asymp V_G(P^{\\star})$. From our analysis above, the two costs transition from $V_G < V_{\\mathrm{SFC}}$ to $V_G > V_{\\mathrm{SFC}}$ at the point $P=a$. We can verify this by setting the expressions equal at the boundary.\nAt $P=a$:\n$$V_{\\mathrm{SFC}}(a,a,N) \\asymp N^{1/2} a^{1/2}$$\n$$V_G(a,a,N) \\asymp a \\cdot N^{1/2} a^{-1/2} = N^{1/2} a^{1/2}$$\nThe two expressions are asymptotically equal at $P=a$. Therefore, the critical processor count is $P^{\\star}(a) = a$. This signifies that for Hilbert curve partitions to be competitive with an optimal stripe partition on a highly anisotropic grid, the number of processors must scale with the grid's aspect ratio.\nThe final result is requested in terms of $a$ only.\n\n$$P^{\\star}(a) \\asymp a$$",
            "answer": "$$\\boxed{a}$$"
        },
        {
            "introduction": "Effective domain decomposition is not solely about minimizing communication at a single step; it's about minimizing the total time to solution. This hands-on practice  explores the crucial trade-off in overlapping methods like the Additive Schwarz preconditioner: more overlap can reduce the total number of iterations but increases the cost of each iteration. By building and analyzing a performance model, you will determine the optimal overlap that balances these competing factors, a key skill in tuning advanced numerical solvers.",
            "id": "3382824",
            "problem": "You are asked to design and implement a program that selects the optimal integer overlap size $\\delta$ (in grid points) for an additive Schwarz preconditioner applied to a two-dimensional elliptic partial differential equation, under a model of per-iteration cost and convergence rate that depends on the overlap, the stencil radius, and the domain partition. The goal is to minimize the total time to solution $T(\\delta)$, defined as the product of the number of iterations and the time per iteration. The program must compute the optimal $\\delta$ for several specified test cases and output all results in a single line.\n\nAssume the following fundamental base and well-tested facts.\n\n- The preconditioned Conjugate Gradient method for a symmetric positive definite linear system with condition number $\\kappa$ requires at least\n$$\nn_{\\text{iter}} \\ge \\tfrac{1}{2} \\sqrt{\\kappa} \\, \\ln\\!\\bigl(\\tfrac{2}{\\varepsilon}\\bigr)\n$$\niterations to reduce the relative error below a prescribed tolerance $\\varepsilon$, where $\\ln$ is the natural logarithm.\n\n- For overlapping domain decomposition with the additive Schwarz preconditioner on a two-dimensional elliptic operator with subdomain characteristic diameter $H$ and overlap $\\delta$ (in grid points), rigorous theory gives a bound of the form\n$$\n\\kappa(\\delta) \\le C_{\\kappa} \\, \\bigl(1 + \\tfrac{H}{\\delta}\\bigr)^{2},\n$$\nwhere $C_{\\kappa} \\ge 1$ is a dimensionless constant reflecting properties of the operator, mesh regularity, and the coarse space. In practice, the smallest admissible effective overlap is constrained by the mesh resolution; interpret $\\delta$ in grid-point units and take $\\delta_{\\text{eff}} = \\max(1,\\delta)$ when using this bound. If $\\delta=0$ (non-overlapping block Jacobi), you may model additional degradation by a constant multiplicative factor $\\phi_{0} \\ge 1$ on the iteration count.\n\n- The per-iteration time for a synchronous nearest-neighbor iterative method on a uniform two-dimensional grid partitioned into a logical processor grid of $P_x \\times P_y$ subdomains is dominated by the slowest subdomain. Use a standard linear communication model with latency and bandwidth:\n    - Each subdomain exchanges halo data of thickness equal to the stencil radius $k$ (in grid points) with its up to $4$ face neighbors. Let $k$ be the stencil radius, so that $k=1$ corresponds to a $5$-point stencil and $k=2$ to a $9$-point stencil, in the sense of required halo thickness.\n    - The time to compute one stencil update at one grid point is $\\alpha \\, k$ seconds, reflecting that the floating-point work scales with the stencil radius $k$.\n    - Each neighbor exchange costs a latency of $\\lambda$ seconds and a bandwidth cost of $\\nu$ seconds per grid point communicated. Exchanging a halo of thickness $k$ in two dimensions requires transmitting $k$ columns of height equal to the local extended subdomain height and $k$ rows of width equal to the local extended subdomain width on each corresponding face.\n\n- Consider a uniform rectangular global grid of $N_x \\times N_y$ points, partitioned into $P_x \\times P_y$ rectangular subdomains. The core (non-overlapped) subdomain sizes are distributed as evenly as possible along each coordinate: along $x$, the first $r_x = N_x \\bmod P_x$ subdomains have size $\\lceil N_x / P_x \\rceil$ and the remaining $P_x - r_x$ have size $\\lfloor N_x / P_x \\rfloor$; similarly for $y$. An overlap of $\\delta$ grid points extends each subdomain by $\\delta$ to each interior face; at the global boundary there is no extension beyond the physical domain, so the extension on a boundary side is only on the interior face. Thus, for a subdomain whose core size is $n_x \\times n_y$ and which is interior in $x$ and $y$, the extended size is $(n_x + 2\\delta)\\times(n_y + 2\\delta)$; on a boundary in $x$ and interior in $y$ it is $(n_x + \\delta)\\times(n_y + 2\\delta)$; on a boundary in both $x$ and $y$ it is $(n_x + \\delta)\\times(n_y + \\delta)$.\n\n- The per-iteration compute time for a subdomain with extended size $n_x^{\\text{ext}} \\times n_y^{\\text{ext}}$ is\n$$\nt_{\\text{comp}} = \\alpha \\, k \\, n_x^{\\text{ext}} \\, n_y^{\\text{ext}}.\n$$\nThe per-iteration communication time for that subdomain is\n$$\nt_{\\text{comm}} = \\lambda \\, n_{\\text{nbr}} \\;+\\; \\nu \\, k \\, \\bigl( 2 n_x^{\\text{ext}} + 2 n_y^{\\text{ext}} \\bigr),\n$$\nwhere $n_{\\text{nbr}} \\in \\{2,3,4\\}$ is the number of face neighbors (corners do not communicate in this model). The per-iteration time for the whole parallel step is the maximum over all subdomains of $t_{\\text{comp}} + t_{\\text{comm}}$.\n\n- Let the characteristic subdomain diameter $H$ be taken as the maximum of the core subdomain side lengths along $x$ or $y$ in grid-point units under the even distribution described above.\n\nYour program must, for each test case, compute the optimal integer overlap $\\delta^{\\star} \\in \\{0,1,2,\\dots,\\delta_{\\max}\\}$ that minimizes\n$$\nT(\\delta) \\;=\\; n_{\\text{iter}}(\\delta) \\;\\cdot\\; t_{\\text{iter}}(\\delta),\n$$\nwith\n$$\nn_{\\text{iter}}(\\delta) \\;=\\; \\left\\lceil \\tfrac{1}{2} \\, \\sqrt{\\kappa(\\delta)} \\, \\ln\\!\\bigl(\\tfrac{2}{\\varepsilon}\\bigr) \\cdot \\bigl( \\phi_{0} \\text{ if } \\delta=0 \\text{ else } 1 \\bigr) \\right\\rceil,\n\\quad\n\\kappa(\\delta) \\;=\\; C_{\\kappa} \\, \\bigl( 1 + \\tfrac{H}{\\delta_{\\text{eff}}} \\bigr)^{2},\n\\quad\n\\delta_{\\text{eff}} \\;=\\; \\max(1,\\delta),\n$$\nand $t_{\\text{iter}}(\\delta)$ defined by the maximum over subdomains of $t_{\\text{comp}} + t_{\\text{comm}}$ as above. Break ties by choosing the smallest $\\delta$ that attains the minimum $T(\\delta)$.\n\nTest suite. For each tuple of parameters, use the exact definitions and units stated. Time is in seconds. Angles are not used. Percentages are not used.\n\n- Case $\\#1$: $N_x=4096$, $N_y=4096$, $P_x=8$, $P_y=8$, $k=1$, $\\alpha=4\\times 10^{-10}$, $\\lambda=5\\times 10^{-6}$, $\\nu=8\\times 10^{-10}$, $C_{\\kappa}=4$, $\\varepsilon=10^{-8}$, $\\phi_{0}=3$, $\\delta_{\\max}=8$.\n- Case $\\#2$: $N_x=4096$, $N_y=4096$, $P_x=4$, $P_y=4$, $k=1$, $\\alpha=4\\times 10^{-10}$, $\\lambda=5\\times 10^{-5}$, $\\nu=8\\times 10^{-10}$, $C_{\\kappa}=4$, $\\varepsilon=10^{-8}$, $\\phi_{0}=3$, $\\delta_{\\max}=8$.\n- Case $\\#3$: $N_x=8192$, $N_y=1024$, $P_x=16$, $P_y=2$, $k=3$, $\\alpha=4\\times 10^{-10}$, $\\lambda=5\\times 10^{-6}$, $\\nu=8\\times 10^{-10}$, $C_{\\kappa}=6$, $\\varepsilon=10^{-8}$, $\\phi_{0}=3$, $\\delta_{\\max}=12$.\n- Case $\\#4$: $N_x=3000$, $N_y=3000$, $P_x=7$, $P_y=7$, $k=1$, $\\alpha=3\\times 10^{-10}$, $\\lambda=1\\times 10^{-5}$, $\\nu=1\\times 10^{-9}$, $C_{\\kappa}=5$, $\\varepsilon=10^{-8}$, $\\phi_{0}=3$, $\\delta_{\\max}=10$.\n- Case $\\#5$: $N_x=2048$, $N_y=2048$, $P_x=32$, $P_y=32$, $k=1$, $\\alpha=2\\times 10^{-10}$, $\\lambda=1\\times 10^{-6}$, $\\nu=2\\times 10^{-9}$, $C_{\\kappa}=4$, $\\varepsilon=10^{-8}$, $\\phi_{0}=3$, $\\delta_{\\max}=6$.\n\nFinal output format. Your program should produce a single line of output containing the optimal overlaps for the test cases, in order, as a comma-separated list enclosed in square brackets, for example, $[d_1,d_2,\\dots,d_5]$, where each $d_i$ is the optimal integer $\\delta^{\\star}$ for case $i$.",
            "solution": "The problem statement has been meticulously reviewed and is determined to be valid. It presents a well-posed optimization problem grounded in standard performance models for parallel numerical methods, with all necessary parameters and definitions provided.\n\nThe overarching goal is to find the integer overlap size $\\delta^{\\star}$ within the range $\\{0, 1, \\dots, \\delta_{\\max}\\}$ that minimizes the total time to solution, $T(\\delta)$. This time is modeled as the product of the number of iterations required for convergence, $n_{\\text{iter}}(\\delta)$, and the time elapsed per iteration, $t_{\\text{iter}}(\\delta)$.\n$$\nT(\\delta) = n_{\\text{iter}}(\\delta) \\cdot t_{\\text{iter}}(\\delta)\n$$\nThe optimal overlap $\\delta^{\\star}$ is therefore the argument that minimizes this function:\n$$\n\\delta^{\\star} = \\underset{\\delta \\in \\{0, 1, \\dots, \\delta_{\\max}\\}}{\\arg\\min} T(\\delta)\n$$\nIn case of ties, the smallest value of $\\delta$ is chosen. The solution requires systematically evaluating $T(\\delta)$ for each permissible integer value of $\\delta$ and identifying the one that yields the minimum time. This involves deriving expressions for both $n_{\\text{iter}}(\\delta)$ and $t_{\\text{iter}}(\\delta)$ from the provided models.\n\n### Number of Iterations, $n_{\\text{iter}}(\\delta)$\n\nThe number of iterations is determined by the convergence properties of the preconditioned conjugate gradient method, which depend on the condition number $\\kappa(\\delta)$ of the preconditioned system. The model is given by:\n$$\nn_{\\text{iter}}(\\delta) = \\left\\lceil \\tfrac{1}{2} \\, \\sqrt{\\kappa(\\delta)} \\, \\ln\\!\\bigl(\\tfrac{2}{\\varepsilon}\\bigr) \\cdot M(\\delta) \\right\\rceil\n$$\nwhere $\\varepsilon$ is the error tolerance and $M(\\delta)$ is a multiplicative factor defined as:\n$$\nM(\\delta) = \\begin{cases} \\phi_0 & \\text{if } \\delta=0 \\\\ 1 & \\text{if } \\delta > 0 \\end{cases}\n$$\nThe condition number $\\kappa(\\delta)$ itself depends on the ratio of the characteristic subdomain diameter $H$ to the effective overlap $\\delta_{\\text{eff}}$:\n$$\n\\kappa(\\delta) = C_{\\kappa} \\left( 1 + \\frac{H}{\\delta_{\\text{eff}}} \\right)^{2}, \\quad \\text{with } \\delta_{\\text{eff}} = \\max(1, \\delta)\n$$\nThe characteristic diameter $H$ is the maximum of the largest core subdomain dimensions along each coordinate axis. For a global grid of $N_x \\times N_y$ points partitioned among $P_x \\times P_y$ processors, the largest core dimensions are $\\lceil N_x / P_x \\rceil$ and $\\lceil N_y / P_y \\rceil$. Thus,\n$$\nH = \\max\\left(\\lceil N_x / P_x \\rceil, \\lceil N_y / P_y \\rceil\\right)\n$$\nAs $\\delta$ increases, $\\delta_{\\text{eff}}$ increases, causing $\\kappa(\\delta)$ and consequently $n_{\\text{iter}}(\\delta)$ to decrease monotonically for $\\delta \\ge 1$. The case $\\delta=0$ introduces a penalty factor $\\phi_0$.\n\n### Time per Iteration, $t_{\\text{iter}}(\\delta)$\n\nThe time per iteration, $t_{\\text{iter}}(\\delta)$, is governed by the slowest subdomain in the parallel computation. For any given subdomain $p$, its single-iteration time $t_p$ is the sum of its computation time $t_{\\text{comp}, p}$ and communication time $t_{\\text{comm}, p}$.\n$$\nt_{\\text{iter}}(\\delta) = \\max_{p} \\left( t_{\\text{comp}, p}(\\delta) + t_{\\text{comm}, p}(\\delta) \\right)\n$$\nThe constituents of this time are modeled as:\n$$\nt_{\\text{comp}, p} = \\alpha \\, k \\, n_{x,p}^{\\text{ext}} \\, n_{y,p}^{\\text{ext}}\n$$\n$$\nt_{\\text{comm}, p} = \\lambda \\, n_{\\text{nbr},p} + \\nu \\, k \\, \\bigl( 2 n_{x,p}^{\\text{ext}} + 2 n_{y,p}^{\\text{ext}} \\bigr)\n$$\nHere, $\\alpha$, $k$, $\\lambda$, and $\\nu$ are constants related to computation and communication performance. The terms $n_{x,p}^{\\text{ext}}$, $n_{y,p}^{\\text{ext}}$, and $n_{\\text{nbr},p}$ are properties of the specific subdomain $p$: its extended dimensions and number of neighbors, which depend on its core dimensions and its location within the processor grid.\n\nA subdomain's properties are determined by its processor grid indices $(i, j)$, where $i \\in \\{0, \\dots, P_x-1\\}$ and $j \\in \\{0, \\dots, P_y-1\\}$.\nThe core dimensions are given by:\n$$\nn_{x,i}^{\\text{core}} = \\begin{cases} \\lceil N_x / P_x \\rceil & \\text{if } i < (N_x \\bmod P_x) \\\\ \\lfloor N_x / P_x \\rfloor & \\text{otherwise} \\end{cases}\n$$\n$$\nn_{y,j}^{\\text{core}} = \\begin{cases} \\lceil N_y / P_y \\rceil & \\text{if } j < (N_y \\bmod P_y) \\\\ \\lfloor N_y / P_y \\rfloor & \\text{otherwise} \\end{cases}\n$$\nThe extended dimensions are found by adding the overlap $\\delta$ for each internal face:\n$$\nn_{x,i}^{\\text{ext}} = n_{x,i}^{\\text{core}} + \\delta \\cdot ( (1 \\text{ if } i > 0) + (1 \\text{ if } i < P_x-1) )\n$$\n$$\nn_{y,j}^{\\text{ext}} = n_{y,j}^{\\text{core}} + \\delta \\cdot ( (1 \\text{ if } j > 0) + (1 \\text{ if } j < P_y-1) )\n$$\nThe number of neighbors is:\n$$\nn_{\\text{nbr},ij} = (1 \\text{ if } i > 0) + (1 \\text{ if } i < P_x-1) + (1 \\text{ if } j > 0) + (1 \\text{ if } j < P_y-1)\n$$\nThe time for a subdomain, $t_p(\\delta)$, is a monotonically increasing function of its core dimensions, extended dimensions, and number of neighbors. The extended dimensions and number of neighbors are largest for interior subdomains, and the core dimensions are largest for subdomains with small indices $i, j$. To find the maximum time $t_{\\text{iter}}(\\delta)$, we must identify the subdomain for which the combination of these factors is greatest. This requires comparing the total time for a small set of representative subdomains that capture all unique combinations of large/small core dimensions and corner/edge/interior positions. The indices to check are those on either side of the boundaries that separate large and small subdomains (i.e., at $i=r_x$ and $j=r_y$) and at the physical domain boundaries (i.e., at $i=0, P_x-1$ and $j=0, P_y-1$). A sufficient set of representative processor indices $(i,j)$ to check includes combinations from $\\{0, 1, r_x, r_x+1, P_x-1\\}$ for the x-index and similarly for the y-index, ensuring that all distinct configurations are evaluated.\n\n### Algorithmic Solution\n\nThe optimization procedure is as follows:\n1. For a given test case, pre-calculate all parameters that are independent of $\\delta$, such as the subdomain core sizes and the characteristic diameter $H$.\n2. Initialize a minimum time $T_{\\min}$ to infinity and the optimal overlap $\\delta^{\\star}$ to an invalid value.\n3. Loop through each integer $\\delta$ from $0$ to $\\delta_{\\max}$.\n    a. Calculate $n_{\\text{iter}}(\\delta)$ using the formulas above.\n    b. Calculate $t_{\\text{iter}}(\\delta)$ by finding the maximum time over all representative subdomain configurations. For each representative processor index pair $(i,j)$:\n        i. Determine its core size, extended size, and number of neighbors.\n        ii. Calculate its total iteration time $t_{i,j}(\\delta)$.\n        iii. The maximum of these calculated times is $t_{\\text{iter}}(\\delta)$.\n    c. Compute the total solution time $T(\\delta) = n_{\\text{iter}}(\\delta) \\cdot t_{\\text{iter}}(\\delta)$.\n    d. If $T(\\delta) < T_{\\min}$, update $T_{\\min} = T(\\delta)$ and $\\delta^{\\star} = \\delta$.\n4. After the loop completes, the final value of $\\delta^{\\star}$ is the optimal overlap for the test case. This procedure is repeated for all test cases.",
            "answer": "$$\\boxed{[8, 8, 12, 10, 6]}$$"
        }
    ]
}