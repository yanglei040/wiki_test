{
    "hands_on_practices": [
        {
            "introduction": "Many powerful numerical methods are built upon the idea of linearization. For nonlinear equations, this often involves approximating the problem with a linear one based on the local Jacobian. This practice explores the fundamental limitations of this approach, especially for strongly nonlinear systems. By deriving the local linearization of a nonlinear operator , you will critically evaluate why simple \"correction-only\" multigrid schemes can fail and build the foundational motivation for the more robust Full Approximation Scheme (FAS).",
            "id": "3396560",
            "problem": "Consider a nonlinear elliptic boundary value problem on a bounded domain $\\Omega \\subset \\mathbb{R}^d$ with sufficiently smooth boundary, given by the partial differential equation $-\\nabla \\cdot (\\kappa(u) \\nabla u) = f$ with Dirichlet boundary conditions, where $\\kappa(u)$ is a smooth, positive function, and $f$ is a given source. Let a consistent, stable finite-volume or finite-difference discretization on a grid with spacing $h$ produce a nonlinear algebraic system $F_h(u_h) = 0$, where $F_h:\\mathbb{R}^{n_h} \\to \\mathbb{R}^{n_h}$ is continuously Fréchet differentiable and $u_h \\in \\mathbb{R}^{n_h}$ denotes the vector of nodal unknowns. Denote by $u_h^* \\in \\mathbb{R}^{n_h}$ the exact discrete solution satisfying $F_h(u_h^*) = 0$, and let $J_h(u_h^*) \\in \\mathbb{R}^{n_h \\times n_h}$ denote the Jacobian (Fréchet derivative in matrix form) of $F_h$ evaluated at $u_h^*$. \n\nPart (a): Starting strictly from the definition of the Fréchet derivative of $F_h$ at $u_h^*$, derive the leading-order approximation of $F_h(u_h^* + e)$ for a perturbation $e \\in \\mathbb{R}^{n_h}$ with $\\|e\\|$ small, and express it in terms of $F_h(u_h^*)$ and $J_h(u_h^*)$.\n\nPart (b): Consider applying multigrid to this nonlinear system. A correction-only multigrid scheme attempts to compute an error $e_h$ on the fine grid by solving an error equation on a coarse grid of spacing $H$, typically of the form $J_H(\\bar{u}_H) e_H \\approx - I_h^H F_h(u_h)$, where $J_H(\\bar{u}_H)$ is a coarse-grid Jacobian evaluated at a reference state $\\bar{u}_H$, $I_h^H$ is a restriction operator, and $I_H^h$ is a prolongation operator. For strongly nonlinear problems, such as the nonlinear diffusion with $\\kappa(u) = \\exp(\\alpha u)$ for large $\\alpha$, determine which of the following statements are correct:\n\nA. The Fréchet derivative definition implies $F_h(u_h^*+e) = F_h(u_h^*) + J_h(u_h^*) e + o(\\|e\\|)$, and since $F_h(u_h^*) = 0$, the leading-order approximation is $F_h(u_h^*+e) \\approx J_h(u_h^*) e$, which is a local relation valid when $\\|e\\|$ is small.\n\nB. The linearization in option A justifies correction-only multigrid globally: solving a coarse-grid linear error equation with a Jacobian evaluated at any fixed reference state $\\bar{u}_H$ yields accurate coarse-grid corrections even when $\\|e\\|$ is not small and the nonlinearity is strong.\n\nC. In strongly nonlinear problems, $J_h(u)$ depends sensitively on the state $u$, so the linear error equation is only accurate near $u_h^*$. Away from the solution, correction-only multigrid can misrepresent the coarse-grid physics because the operator changes with the approximation. The Full Approximation Scheme (FAS) for nonlinear multigrid addresses this by solving a coarse-grid approximation equation $F_H(u_H) = \\tau_H$, where the coarse-grid defect $\\tau_H$ is chosen to enforce consistency with the fine-grid state (e.g., $\\tau_H = F_H(I_h^H u_h) - I_h^H F_h(u_h)$), and by transferring approximations rather than corrections.\n\nD. The relation in option A fails even in the limit $\\|e\\| \\to 0$ for differentiable $F_h$, so correction-only multigrid is always invalid, regardless of the problem’s nonlinearity.\n\nE. Strong nonlinearity implies that the Jacobian $J_h(u)$ does not exist anywhere, so linearization cannot be used at any stage of a multigrid method.\n\nSelect all correct options.",
            "solution": "### Part (a): Derivation\n\nThe function $F_h: \\mathbb{R}^{n_h} \\to \\mathbb{R}^{n_h}$ is stated to be continuously Fréchet differentiable. The definition of the Fréchet derivative of $F_h$ at the point $u_h^*$, denoted by the linear operator (Jacobian matrix) $J_h(u_h^*)$, states that for any perturbation $e \\in \\mathbb{R}^{n_h}$:\n$$ F_h(u_h^* + e) = F_h(u_h^*) + J_h(u_h^*) e + o(\\|e\\|) $$\nwhere $o(\\|e\\|)$ is a term such that $\\lim_{\\|e\\| \\to 0} \\frac{\\|o(\\|e\\|)\\|}{\\|e\\|} = 0$.\n\nThis is the first-order Taylor expansion of $F_h$ around $u_h^*$. The leading-order approximation is obtained by neglecting the higher-order term $o(\\|e\\|)$, which is valid for sufficiently small $\\|e\\|$. This gives:\n$$ F_h(u_h^* + e) \\approx F_h(u_h^*) + J_h(u_h^*) e $$\nThe problem specifies that $u_h^*$ is the exact discrete solution, which means it satisfies the discrete system of equations $F_h(u_h^*) = 0$. Substituting this into the leading-order approximation yields:\n$$ F_h(u_h^* + e) \\approx J_h(u_h^*) e $$\nThis result shows that for a point $u_h^*+e$ very close to the solution $u_h^*$, the value of the nonlinear function $F_h$ is well-approximated by the action of the Jacobian at the solution point on the perturbation $e$.\n\n### Part (b): Option-by-Option Analysis\n\nThe context is a strongly nonlinear problem, where the properties of the operator, particularly its Jacobian $J_h(u)$, change significantly with the state $u$.\n\n**A. The Fréchet derivative definition implies $F_h(u_h^*+e) = F_h(u_h^*) + J_h(u_h^*) e + o(\\|e\\|)$, and since $F_h(u_h^*) = 0$, the leading-order approximation is $F_h(u_h^*+e) \\approx J_h(u_h^*) e$, which is a local relation valid when $\\|e\\|$ is small.**\n\nThis statement is a direct summary of the derivation performed in Part (a). The expression is the definition of Fréchet differentiability. Setting $F_h(u_h^*) = 0$ and dropping the $o(\\|e\\|)$ term gives the leading-order approximation. Crucially, the statement correctly qualifies this as a *local* relation, valid only for small perturbations $\\|e\\|$.\n\n**Verdict: Correct.**\n\n**B. The linearization in option A justifies correction-only multigrid globally: solving a coarse-grid linear error equation with a Jacobian evaluated at any fixed reference state $\\bar{u}_H$ yields accurate coarse-grid corrections even when $\\|e\\|$ is not small and the nonlinearity is strong.**\n\nThis statement makes an incorrect leap from a local property to a global justification. The correction-only multigrid scheme approximates the nonlinear error equation by a linear one. For a strongly nonlinear problem, the Jacobian $J_h(u)$ is highly dependent on $u$. When the current approximation is far from the solution, the error is not small, and a linear model based on a fixed Jacobian is a poor approximation. This discrepancy means the coarse grid operator does not correctly represent the physics of the problem, leading to poor convergence or divergence.\n\n**Verdict: Incorrect.**\n\n**C. In strongly nonlinear problems, $J_h(u)$ depends sensitively on the state $u$, so the linear error equation is only accurate near $u_h^*$. Away from the solution, correction-only multigrid can misrepresent the coarse-grid physics because the operator changes with the approximation. The Full Approximation Scheme (FAS) for nonlinear multigrid addresses this by solving a coarse-grid approximation equation $F_H(u_H) = \\tau_H$, where the coarse-grid defect $\\tau_H$ is chosen to enforce consistency with the fine-grid state (e.g., $\\tau_H = F_H(I_h^H u_h) - I_h^H F_h(u_h)$), and by transferring approximations rather than corrections.**\n\nThis statement provides an accurate analysis. It correctly identifies the core weakness of the correction-only scheme for strongly nonlinear problems: the inadequacy of a single, fixed linearization to represent the problem over a wide range of states. It then correctly describes the Full Approximation Scheme (FAS), which solves the full nonlinear problem on the coarse grid using the appropriate nonlinear operator $F_H$, linked to the fine grid via a defect correction. This allows FAS to effectively handle strong nonlinearities where correction-only schemes fail.\n\n**Verdict: Correct.**\n\n**D. The relation in option A fails even in the limit $\\|e\\| \\to 0$ for differentiable $F_h$, so correction-only multigrid is always invalid, regardless of the problem’s nonlinearity.**\n\nThis is false. The relation in option A is the very definition of Fréchet differentiability at $u_h^*$. The problem states that $F_h$ is continuously Fréchet differentiable, so this relation holds by definition. Correction-only multigrid is not \"always invalid\"; it is the standard and efficient method for linear problems and works well for weakly nonlinear problems where the Jacobian is nearly constant.\n\n**Verdict: Incorrect.**\n\n**E. Strong nonlinearity implies that the Jacobian $J_h(u)$ does not exist anywhere, so linearization cannot be used at any stage of a multigrid method.**\n\nThis statement confuses strong nonlinearity with non-differentiability. A function can be perfectly smooth (infinitely differentiable) and still be strongly nonlinear. For the given example $\\kappa(u) = \\exp(\\alpha u)$, $\\kappa(u)$ and its derivatives exist and are continuous for all $u$. The problem statement explicitly assumes $F_h$ is continuously Fréchet differentiable. Linearization is still a key concept, for instance, in the analysis of smoothers or in Newton-based methods.\n\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{AC}$$"
        },
        {
            "introduction": "The power of the Full Approximation Scheme lies in how it handles nonlinearity across different grid levels, a feat accomplished through the \"tau-correction\" term, $\\tau_{H}$. This practice moves from the theoretical motivation for FAS to its concrete mechanics. You will calculate the $\\tau$-correction explicitly for a 2D nonlinear boundary value problem , providing a tangible understanding of how this term ensures the coarse-grid problem correctly informs the fine-grid solution.",
            "id": "3396512",
            "problem": "Consider the nonlinear partial differential equation $-\\Delta u + u^{3} = f$ on the square domain $(0,1)^{2}$ with homogeneous Dirichlet boundary conditions $u=0$ on $\\partial(0,1)^{2}$. Assume $f$ is chosen so that the exact solution is $u(x,y) = \\sin(\\pi x)\\sin(\\pi y)$. Starting from the continuous equation and standard definitions of the Laplacian and Dirichlet boundary conditions, derive a closed-form expression for $f(x,y)$ that makes $u(x,y) = \\sin(\\pi x)\\sin(\\pi y)$ an exact solution.\n\nNext, consider a finite difference discretization on a uniform fine grid of spacing $h=\\frac{1}{4}$ with the standard five-point stencil approximation for the Laplacian and zero boundary values imposed at grid points on the boundary. Define the discrete nonlinear operator on the fine grid by $F_{h}(u_{h}) = -\\Delta_{h} u_{h} + (u_{h})^{\\odot 3} - f_{h}$, where $\\Delta_{h}$ is the five-point discrete Laplacian and $f_{h}$ is the pointwise sampling of the continuous $f$ at grid nodes. Similarly, define the coarse grid of spacing $H=\\frac{1}{2}$ with the same discrete operator form $F_{H}(u_{H}) = -\\Delta_{H} u_{H} + (u_{H})^{\\odot 3} - f_{H}$.\n\nUsing the Full Approximation Scheme (FAS), where the coarse-grid right-hand side is corrected by the $\\tau$-term, set up the coarse-grid equation $F_{H}(u_{H}) = \\hat{f}_{H}$ with $\\hat{f}_{H} = I_{h}^{H} f_{h} + \\tau_{H}$ and the standard choice of restriction $I_{h}^{H}$ as point injection (i.e., the coarse node value equals the fine node value at the coincident location). Compute explicitly the $\\tau$-correction $\\tau_{H}$ at the single interior coarse-grid node $(x,y)=(\\frac{1}{2},\\frac{1}{2})$, assuming the fine-grid approximation equals the exact solution sampled at fine grid nodes.\n\nProvide your final answer as a two-entry row matrix using the pmatrix environment: the first entry must be the closed-form expression for $f(x,y)$ obtained from the continuous equation, and the second entry must be the exact value of $\\tau_{H}$ at $(\\frac{1}{2},\\frac{1}{2})$ under the described discretization and transfer choices. No rounding is required; report exact values and do not include units inside the final boxed answer.",
            "solution": "### Part 1: Derivation of the source term $f(x,y)$\n\nTo find the source term $f(x,y)$ that corresponds to the exact solution $u(x,y) = \\sin(\\pi x)\\sin(\\pi y)$, we substitute this solution into the PDE $-\\Delta u + u^3 = f$. First, we compute the Laplacian $\\Delta u$:\n$$ \\frac{\\partial u}{\\partial x} = \\pi \\cos(\\pi x)\\sin(\\pi y) \\implies \\frac{\\partial^2 u}{\\partial x^2} = -\\pi^2 \\sin(\\pi x)\\sin(\\pi y) $$\n$$ \\frac{\\partial u}{\\partial y} = \\pi \\sin(\\pi x)\\cos(\\pi y) \\implies \\frac{\\partial^2 u}{\\partial y^2} = -\\pi^2 \\sin(\\pi x)\\sin(\\pi y) $$\n$$ \\Delta u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = -2\\pi^2 \\sin(\\pi x)\\sin(\\pi y) = -2\\pi^2 u $$\nNow, we substitute this back into the PDE:\n$$ f(x,y) = -(-2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)) + (\\sin(\\pi x)\\sin(\\pi y))^3 $$\n$$ f(x,y) = 2\\pi^2 \\sin(\\pi x)\\sin(\\pi y) + \\sin^3(\\pi x)\\sin^3(\\pi y) $$\n\n### Part 2: Computation of the $\\tau$-correction $\\tau_H$\n\nThe $\\tau$-correction is defined by the relationship between the fine-grid and coarse-grid problems. The coarse-grid equation is $F_H(u_H) = \\hat{f}_H$. The standard FAS formulation defines the corrected right-hand side as $\\hat{f}_H = F_H(I_h^H u_h) - I_h^H(F_h(u_h)) + I_h^H f_h$. The problem states $\\hat{f}_H = I_h^H f_h + \\tau_H$, which implies the standard definition of the relative truncation error:\n$$ \\tau_H = F_H(I_h^H u_h) - I_h^H(F_h(u_h)) $$\nSubstituting the definitions of the operators $F_h$ and $F_H$:\n$$ \\tau_H = \\left(-\\Delta_H(I_h^H u_h) + (I_h^H u_h)^{\\odot 3} - f_H\\right) - I_h^H\\left(-\\Delta_h u_h + (u_h)^{\\odot 3} - f_h\\right) $$\nSince restriction $I_h^H$ is point injection, the source terms cancel out because $f_H = I_h^H f_h$. The cubing operation is pointwise, so $(I_h^H u_h)^{\\odot 3} = I_h^H((u_h)^{\\odot 3})$. Therefore, the nonlinear terms also cancel. The expression for $\\tau_H$ simplifies to:\n$$ \\tau_H = I_h^H(\\Delta_h u_h) - \\Delta_H(I_h^H u_h) $$\nWe need to evaluate this at the coarse-grid point $p = (1/2, 1/2)$.\n\n**1. Compute $\\Delta_H(I_h^H u_h)$ at $p$:**\nThe coarse grid spacing is $H=1/2$. The function is $v_H = I_h^H u_h$, where $u_h$ is the exact solution sampled on the grid.\nThe value at the center is $v_H(p) = u(1/2, 1/2) = \\sin(\\pi/2)\\sin(\\pi/2) = 1$.\nThe neighbors of $p$ on the coarse grid are $(0, 1/2)$, $(1, 1/2)$, $(1/2, 0)$, and $(1/2, 1)$. At these boundary points, $u=0$, so $v_H=0$.\nUsing the five-point stencil for the Laplacian:\n$$ \\Delta_H v_H(p) = \\frac{v_H(p_E) + v_H(p_W) + v_H(p_N) + v_H(p_S) - 4v_H(p)}{H^2} = \\frac{0+0+0+0 - 4(1)}{(1/2)^2} = \\frac{-4}{1/4} = -16 $$\n\n**2. Compute $I_h^H(\\Delta_h u_h)$ at $p$:**\nDue to injection, this is simply $\\Delta_h u_h$ evaluated at $p=(1/2, 1/2)$. The fine grid spacing is $h=1/4$.\nThe neighbors of $p$ on the fine grid are $(1/2 \\pm h, 1/2)$ and $(1/2, 1/2 \\pm h)$, which are $(1/4, 1/2)$, $(3/4, 1/2)$, $(1/2, 1/4)$, and $(1/2, 3/4)$.\nThe value of $u_h$ at the center is $u_h(p) = u(1/2, 1/2) = 1$.\nThe value at the neighbors is:\n$u_h(1/4, 1/2) = \\sin(\\pi/4)\\sin(\\pi/2) = \\frac{\\sqrt{2}}{2}$.\nBy symmetry, the value at all four neighbors is $\\frac{\\sqrt{2}}{2}$.\nUsing the five-point stencil:\n$$ \\Delta_h u_h(p) = \\frac{4 \\times \\frac{\\sqrt{2}}{2} - 4(1)}{h^2} = \\frac{2\\sqrt{2} - 4}{(1/4)^2} = 16(2\\sqrt{2} - 4) = 32\\sqrt{2} - 64 $$\n\n**3. Final Calculation:**\n$$ \\tau_H(p) = (\\Delta_h u_h(p)) - (\\Delta_H(I_h^H u_h)(p)) = (32\\sqrt{2} - 64) - (-16) = 32\\sqrt{2} - 48 $$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2\\pi^{2} \\sin(\\pi x)\\sin(\\pi y) + \\sin^{3}(\\pi x)\\sin^{3}(\\pi y)  32\\sqrt{2} - 48\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A complete algorithm requires not only a method for generating iterates but also a robust criterion for stopping them. For an iterative solver like FAS, it is crucial to know when the computed approximation is sufficiently accurate. This final practice addresses the practical challenge of designing effective stopping criteria , forcing you to connect the observable residual to the unobservable solution error and consider the trade-off between algebraic and discretization errors.",
            "id": "3396549",
            "problem": "Consider a nonlinear discrete boundary value problem arising from the numerical solution of a Partial Differential Equation (PDE), written in residual form as finding $u_h \\in V_h$ such that $F_h(u_h) = 0$, where $F_h: V_h \\to V_h'$ is the discrete nonlinear operator, and $V_h$ is a finite-dimensional space. Suppose the Full Approximation Scheme (FAS) for nonlinear multigrid is employed to compute an approximation $u_h^{(k)}$ after $k$ cycles. Let the nonlinear residual at cycle $k$ be $r_h^{(k)} := F_h(u_h^{(k)})$, measured in some consistent norm $\\|\\cdot\\|$ on $V_h'$. Let the (unknown) discrete solution be $u_h^\\ast$ and the algebraic error be $e_h^{(k)} := u_h^{(k)} - u_h^\\ast$.\n\nYou are asked to propose practical stopping criteria for FAS based on the nonlinear residual norm $\\|F_h(u_h^{(k)})\\|$ and its relative decrease per cycle, and to justify how these criteria relate to the actual algebraic error $\\|e_h^{(k)}\\|$ under commonly used regularity and stability assumptions for nonlinear elliptic problems.\n\nWhich of the following proposals and justifications are valid?\n\nA. Stop at the first $k$ such that $\\|F_h(u_h^{(k)})\\| \\le \\max\\{\\tau_{\\mathrm{abs}},\\, \\tau_{\\mathrm{rel}}\\|F_h(u_h^{(0)})\\|\\}$, with $\\tau_{\\mathrm{abs}}  0$ and $\\tau_{\\mathrm{rel}} \\in (0,1)$. Justification: if $F_h$ is Fréchet differentiable and its Jacobian at $u_h^\\ast$ is uniformly nonsingular and coercive in a neighborhood of $u_h^\\ast$, with constants independent of $h$, then there exists $C0$ independent of $h$ such that $\\|e_h^{(k)}\\| \\le C \\|F_h(u_h^{(k)})\\|$. Hence this residual-based criterion controls the algebraic error up to a constant multiple.\n\nB. Stop as soon as the per-cycle relative decrease $\\theta^{(k)} := \\|F_h(u_h^{(k)})\\|/\\|F_h(u_h^{(k-1)})\\|$ falls below a prescribed threshold, e.g., $\\theta^{(k)} \\le 0.95$, regardless of the absolute residual magnitude. Justification: a sustained decrease per cycle guarantees that the algebraic error is already small because multigrid smoothers damp high-frequency error components.\n\nC. Use a combined criterion: stop when either $\\|F_h(u_h^{(k)})\\| \\le \\max\\{\\tau_{\\mathrm{abs}},\\, \\tau_{\\mathrm{rel}}\\|F_h(u_h^{(0)})\\|\\}$ or when $\\theta^{(k)} \\ge \\rho_{\\mathrm{sat}}$ for $m \\ge 2$ consecutive cycles with $\\rho_{\\mathrm{sat}} \\in (0,1)$, and an independent discretization error indicator $\\eta_h$ (e.g., an a posteriori estimator of order $\\mathcal{O}(h^p)$) satisfies $\\|F_h(u_h^{(k)})\\| \\lesssim \\eta_h$. Justification: if the observed reduction has saturated and the residual is at the level consistent with the estimated discretization error, then the remaining algebraic error is negligible relative to the discretization error, making further FAS cycles unnecessary.\n\nD. Use only a step-difference test: stop when $\\|u_h^{(k)} - u_h^{(k-1)}\\| \\le \\tau_{\\mathrm{step}}$ for some $\\tau_{\\mathrm{step}}  0$, without monitoring the nonlinear residual. Justification: small successive updates imply that the nonlinear fixed point has been reached.\n\nE. Relate residual and error via local linearization: if $F_h$ is Fréchet differentiable and satisfies strong monotonicity and Lipschitz continuity in a neighborhood of $u_h^\\ast$, with constants independent of $h$, then there exist mesh-independent constants $c_1,c_20$ such that for all $u_h$ sufficiently close to $u_h^\\ast$, $c_1 \\|u_h - u_h^\\ast\\| \\le \\|F_h(u_h)\\| \\le c_2 \\|u_h - u_h^\\ast\\|$. Consequently, an absolute/relative residual criterion yields a reliable proxy for the algebraic error up to multiplicative constants.",
            "solution": "The problem requires an evaluation of stopping criteria for an iterative solver. The core task is to relate an observable quantity, the nonlinear residual norm $\\|F_h(u_h^{(k)})\\|$, to the unobservable algebraic error norm $\\|e_h^{(k)}\\| = \\|u_h^{(k)} - u_h^\\ast\\|$.\n\nFor well-posed nonlinear problems arising from elliptic PDEs, the discrete operator $F_h$ often exhibits properties that establish a norm equivalence between the error and the residual for approximations sufficiently close to the solution. Specifically, if $F_h$ is strongly monotone and Lipschitz continuous with mesh-independent constants $c_1, c_2  0$, then for any $u_h$ in a neighborhood of the exact discrete solution $u_h^*$, the following two-sided inequality holds:\n$$c_1 \\|u_h - u_h^\\ast\\| \\le \\|F_h(u_h)\\| \\le c_2 \\|u_h - u_h^\\ast\\|$$\nThis relationship shows that the residual norm is a reliable proxy for the algebraic error norm. A stopping criterion based on reducing $\\|F_h(u_h)\\|$ is therefore theoretically sound.\n\nAnother key principle is the balancing of errors. The total error is the sum of the algebraic error and the discretization error. It is computationally inefficient to reduce the algebraic error to a level significantly below that of the inherent discretization error. A good stopping criterion may therefore involve comparing the residual (proxy for algebraic error) to an estimate of the discretization error, $\\eta_h$.\n\nWith these principles, we evaluate each option.\n\n**A. Stop at the first $k$ such that $\\|F_h(u_h^{(k)})\\| \\le \\max\\{\\tau_{\\mathrm{abs}},\\, \\tau_{\\mathrm{rel}}\\|F_h(u_h^{(0)})\\|\\}$, with $\\tau_{\\mathrm{abs}}  0$ and $\\tau_{\\mathrm{rel}} \\in (0,1)$. Justification: if $F_h$ is Fréchet differentiable and its Jacobian at $u_h^\\ast$ is uniformly nonsingular and coercive in a neighborhood of $u_h^\\ast$, with constants independent of $h$, then there exists $C0$ independent of $h$ such that $\\|e_h^{(k)}\\| \\le C \\|F_h(u_h^{(k)})\\|$. Hence this residual-based criterion controls the algebraic error up to a constant multiple.**\n\nThis proposal describes a standard, practical, and robust stopping criterion. The justification is sound. The assumption of a uniformly nonsingular and coercive Jacobian ensures that for $u_h^{(k)}$ sufficiently close to $u_h^\\ast$, the error is bounded by a multiple of the residual. Therefore, a small residual guarantees a small algebraic error.\n**Verdict: Correct.**\n\n**B. Stop as soon as the per-cycle relative decrease $\\theta^{(k)} := \\|F_h(u_h^{(k)})\\|/\\|F_h(u_h^{(k-1)})\\|$ falls below a prescribed threshold, e.g., $\\theta^{(k)} \\le 0.95$, regardless of the absolute residual magnitude. Justification: a sustained decrease per cycle guarantees that the algebraic error is already small because multigrid smoothers damp high-frequency error components.**\n\nThis proposal is unreliable. The convergence factor $\\theta^{(k)}$ measures the *rate* of convergence, not the *proximity* to the solution. An iterative method can exhibit a good reduction factor while the residual magnitude is still unacceptably large.\n**Verdict: Incorrect.**\n\n**C. Use a combined criterion: stop when either $\\|F_h(u_h^{(k)})\\| \\le \\max\\{\\tau_{\\mathrm{abs}},\\, \\tau_{\\mathrm{rel}}\\|F_h(u_h^{(0)})\\|\\}$ or when $\\theta^{(k)} \\ge \\rho_{\\mathrm{sat}}$ for $m \\ge 2$ consecutive cycles with $\\rho_{\\mathrm{sat}} \\in (0,1)$, and an independent discretization error indicator $\\eta_h$ ... satisfies $\\|F_h(u_h^{(k)})\\| \\lesssim \\eta_h$. Justification: if the observed reduction has saturated and the residual is at the level consistent with the estimated discretization error, then the remaining algebraic error is negligible relative to the discretization error, making further FAS cycles unnecessary.**\n\nThis describes a sophisticated and highly efficient stopping strategy. It combines a standard residual check with a check based on balancing errors. It detects when convergence has stagnated because the algebraic error has become smaller than the discretization error, at which point further iterations are inefficient. The justification correctly articulates this sound principle.\n**Verdict: Correct.**\n\n**D. Use only a step-difference test: stop when $\\|u_h^{(k)} - u_h^{(k-1)}\\| \\le \\tau_{\\mathrm{step}}$ for some $\\tau_{\\mathrm{step}}  0$, without monitoring the nonlinear residual. Justification: small successive updates imply that the nonlinear fixed point has been reached.**\n\nThis criterion is not robust on its own. While a small step difference is a necessary condition for convergence, it is not sufficient. A method can converge very slowly, leading to small successive differences while the iterates are still far from the solution. This test can cause premature termination.\n**Verdict: Incorrect.**\n\n**E. Relate residual and error via local linearization: if $F_h$ is Fréchet differentiable and satisfies strong monotonicity and Lipschitz continuity in a neighborhood of $u_h^\\ast$, with constants independent of $h$, then there exist mesh-independent constants $c_1,c_20$ such that for all $u_h$ sufficiently close to $u_h^\\ast$, $c_1 \\|u_h - u_h^\\ast\\| \\le \\|F_h(u_h)\\| \\le c_2 \\|u_h - u_h^\\ast\\|$. Consequently, an absolute/relative residual criterion yields a reliable proxy for the algebraic error up to multiplicative constants.**\n\nThis option provides the rigorous theoretical foundation for using residual-based stopping criteria. It correctly states the conditions (strong monotonicity and Lipschitz continuity) under which the norm equivalence between the algebraic error and the nonlinear residual holds. This equivalence is precisely what makes monitoring the residual an effective strategy for controlling the error. The statement and its conclusion are entirely correct.\n**Verdict: Correct.**",
            "answer": "$$\\boxed{ACE}$$"
        }
    ]
}