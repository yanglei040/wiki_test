{
    "hands_on_practices": [
        {
            "introduction": "This first practice focuses on the fundamental task of quantifying the smoothing property. Through a combination of analytical derivation and numerical implementation, you will compute the smoothing factor for the weighted Jacobi method, a key metric that measures how effectively a smoother damps high-frequency error components. This exercise provides a concrete understanding of Local Fourier Analysis (LFA) as a tool for predicting the performance of iterative methods. ",
            "id": "3387327",
            "problem": "Consider the error smoothing properties of relaxation when solving elliptic partial differential equations by iterative methods. Use the following foundational setting: start from a discretization of the negative Laplace operator on a regular grid, which yields a linear system $A u = f$ with a standard three-point stencil in one dimension and a standard five-point stencil in two dimensions on uniform grids. The weighted Jacobi relaxation method updates $u$ by $u^{(k+1)} = u^{(k)} + \\omega D^{-1} (f - A u^{(k)})$, where $D$ is the diagonal of $A$ and $\\omega$ is a scalar relaxation weight. The error propagation for one relaxation step is $e^{(k+1)} = (I - \\omega D^{-1} A) e^{(k)}$. Local Fourier Analysis (LFA) considers error components as discrete Fourier modes on an infinite grid, which diagonalize translation-invariant operators; consequently, each mode is amplified by a scalar factor that depends on the mode’s frequency. High-frequency components are those that are poorly represented on a coarser grid. In one dimension, define the high-frequency set as $\\theta \\in [\\pi/2,\\pi]$. In two dimensions, define the high-frequency set as all $(\\theta_x,\\theta_y) \\in [0,\\pi] \\times [0,\\pi]$ such that at least one of $\\theta_x$ or $\\theta_y$ lies in $[\\pi/2,\\pi]$. Angles must be treated and reported in radians.\n\nStarting from these definitions and the discrete operator symbols implied by the standard stencils, derive the scalar amplification factor for a single weighted Jacobi relaxation step acting on a Fourier mode for both one and two space dimensions. Then, define the smoothing factor $\\mu(\\omega)$ as the supremum (maximum in a sampled sense) of the absolute value of this amplification factor over the specified high-frequency sets. Implement a program that computes $\\mu(\\omega)$ numerically by sampling the frequency domain uniformly. To make the computation well-defined and testable, approximate the supremum by a maximum over a uniform grid of angles with specified resolution $N_\\theta$. Specifically:\n- For one dimension ($d=1$), sample $\\theta$ uniformly over $[\\pi/2,\\pi]$ using $N_\\theta$ points including endpoints.\n- For two dimensions ($d=2$), sample $(\\theta_x,\\theta_y)$ uniformly over $[0,\\pi] \\times [0,\\pi]$ using $N_\\theta$ points in each dimension including endpoints, and restrict to the high-frequency set defined above by selecting only those sampled pairs $(\\theta_x,\\theta_y)$ with $\\theta_x \\in [\\pi/2,\\pi]$ or $\\theta_y \\in [\\pi/2,\\pi]$.\n\nYour program must compute $\\mu(\\omega)$ for each parameter set in the following test suite, and produce the results as floats rounded to $10$ decimal places:\n\n1. $d=1$, $\\omega = 2/3$, $N_\\theta = 1024$.\n2. $d=2$, $\\omega = 2/3$, $N_\\theta = 512$.\n3. $d=2$, $\\omega = 1$, $N_\\theta = 256$.\n4. $d=1$, $\\omega = 0$, $N_\\theta = 64$.\n5. $d=2$, $\\omega = 0.8$, $N_\\theta = 512$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4,result5]\"). Angles must be in radians, and all reported floats must be rounded to exactly $10$ decimal places.",
            "solution": "The task is to derive the amplification factor for the weighted Jacobi relaxation method for the one-dimensional and two-dimensional Poisson equation, and then to compute the corresponding smoothing factor, $\\mu(\\omega)$, numerically.\n\nThe weighted Jacobi iteration for a linear system $A u = f$ is given by $u^{(k+1)} = u^{(k)} + \\omega D^{-1} (f - A u^{(k)})$, where $D$ is the diagonal part of $A$ and $\\omega$ is the relaxation weight. The error $e^{(k)} = u - u^{(k)}$ (where $u$ is the exact solution) propagates according to the relation $e^{(k+1)} = (I - \\omega D^{-1} A) e^{(k)}$. The operator $S_\\omega = I - \\omega D^{-1} A$ is the iteration or error propagation operator.\n\nWe use Local Fourier Analysis (LFA) on an infinite grid. In LFA, we analyze the effect of a linear, translation-invariant operator on a single Fourier mode. An error component with frequency $\\boldsymbol{\\theta}$ is represented by a grid function $v(\\mathbf{x}) = e^{i \\boldsymbol{\\theta} \\cdot \\mathbf{x}/h}$, where on a discrete grid with integer indices $\\mathbf{j}$, this becomes $v_{\\mathbf{j}} = e^{i \\boldsymbol{\\theta} \\cdot \\mathbf{j}}$. The action of the operator $S_\\omega$ on such a mode results in its multiplication by a scalar, known as the symbol or amplification factor, denoted by $\\hat{S}_\\omega(\\boldsymbol{\\theta})$. This is because Fourier modes are the eigenvectors of any translation-invariant operator. The symbol is given by $\\hat{S}_\\omega(\\boldsymbol{\\theta}) = \\widehat{I - \\omega D^{-1} A}(\\boldsymbol{\\theta}) = 1 - \\omega \\widehat{D^{-1}A}(\\boldsymbol{\\theta})$. Since $D$ is a scalar multiple of the identity operator for the problems at hand ($D = cI$), $D^{-1} = c^{-1}I$, and its symbol is the constant $c^{-1}$. Thus, $\\hat{S}_\\omega(\\boldsymbol{\\theta}) = 1 - \\omega c^{-1} \\hat{A}(\\boldsymbol{\\theta})$, where $\\hat{A}(\\boldsymbol{\\theta})$ is the symbol of the operator $A$.\n\nThe smoothing factor $\\mu(\\omega)$ is defined as the maximum absolute value of the amplification factor over all high-frequency modes:\n$$\n\\mu(\\omega) = \\sup_{\\boldsymbol{\\theta} \\in \\text{HighFreqSet}} |\\hat{S}_\\omega(\\boldsymbol{\\theta})|\n$$\n\nWe will now derive the amplification factors for one and two dimensions. The grid spacing $h$ can be set to $1$, as any $1/h^2$ scaling of the discrete Laplacian operator $A$ would also scale its diagonal $D$ by $1/h^2$, leaving the product $D^{-1}A$ and thus the amplification factor invariant.\n\n**One-Dimensional Case ($d=1$)**\n\nThe standard three-point stencil for the negative Laplace operator in one dimension is $[-1, 2, -1]$. The operator $A$ acting on a grid function $u_j$ is $(Au)_j = 2u_j - u_{j-1} - u_{j+1}$. The diagonal of $A$ is $D=2I$, so $c=2$.\nTo find the symbol $\\hat{A}(\\theta)$, we apply $A$ to a Fourier mode $e^{i\\theta j}$:\n$$\nA e^{i\\theta j} = 2e^{i\\theta j} - e^{i\\theta(j-1)} - e^{i\\theta(j+1)} = (2 - e^{-i\\theta} - e^{i\\theta}) e^{i\\theta j} = (2 - 2\\cos(\\theta)) e^{i\\theta j}\n$$\nThus, the symbol of $A$ is $\\hat{A}(\\theta) = 2 - 2\\cos(\\theta)$.\nThe amplification factor for weighted Jacobi is:\n$$\n\\hat{S}_\\omega(\\theta) = 1 - \\omega D^{-1} \\hat{A}(\\theta) = 1 - \\omega \\frac{1}{2} (2 - 2\\cos(\\theta)) = 1 - \\omega(1 - \\cos(\\theta))\n$$\nThe high-frequency set is defined as $\\theta \\in [\\pi/2, \\pi]$. The problem requires us to compute $\\mu(\\omega)$ by taking the maximum of $|\\hat{S}_\\omega(\\theta)|$ over a uniform sampling of $N_\\theta$ points in this interval.\n\n**Two-Dimensional Case ($d=2$)**\n\nThe standard five-point stencil for the negative Laplace operator in two dimensions is represented by its action on a grid function $u_{j,k}$: $(Au)_{j,k} = 4u_{j,k} - u_{j-1,k} - u_{j+1,k} - u_{j,k-1} - u_{j,k+1}$. The diagonal of $A$ is $D=4I$, so $c=4$.\nWe apply $A$ to a Fourier mode $e^{i(\\theta_x j + \\theta_y k)}$:\n\\begin{align*}\nA e^{i(\\theta_x j + \\theta_y k)} &= \\left(4 - e^{-i\\theta_x} - e^{i\\theta_x} - e^{-i\\theta_y} - e^{i\\theta_y}\\right) e^{i(\\theta_x j + \\theta_y k)} \\\\\n&= (4 - 2\\cos(\\theta_x) - 2\\cos(\\theta_y)) e^{i(\\theta_x j + \\theta_y k)}\n\\end{align*}\nThe symbol of $A$ is $\\hat{A}(\\theta_x, \\theta_y) = 4 - 2\\cos(\\theta_x) - 2\\cos(\\theta_y)$.\nThe amplification factor for weighted Jacobi is:\n$$\n\\hat{S}_\\omega(\\theta_x, \\theta_y) = 1 - \\omega D^{-1} \\hat{A}(\\theta_x, \\theta_y) = 1 - \\omega \\frac{1}{4} (4 - 2\\cos(\\theta_x) - 2\\cos(\\theta_y)) = 1 - \\frac{\\omega}{2}(2 - \\cos(\\theta_x) - \\cos(\\theta_y))\n$$\nThe high-frequency set is defined as all $(\\theta_x, \\theta_y) \\in [0, \\pi] \\times [0, \\pi]$ where $\\theta_x \\in [\\pi/2, \\pi]$ or $\\theta_y \\in [\\pi/2, \\pi]$. The computation of $\\mu(\\omega)$ involves sampling the domain $[0, \\pi] \\times [0, \\pi]$ with an $N_\\theta \\times N_\\theta$ grid, filtering for the high-frequency points, calculating $|\\hat{S}_\\omega(\\theta_x, \\theta_y)|$ for these points, and finding the maximum value.\n\nThe provided Python code implements this numerical computation for each test case.\n- For $d=1$, it generates $N_\\theta$ points for $\\theta$ in $[\\pi/2, \\pi]$ and computes $\\max|\\hat{S}_\\omega(\\theta)|$.\n- For $d=2$, it generates an $N_\\theta \\times N_\\theta$ grid for $(\\theta_x, \\theta_y)$ in $[0, \\pi] \\times [0, \\pi]$, filters these points to retain only those in the high-frequency set, and then computes the maximum of $|\\hat{S}_\\omega(\\theta_x, \\theta_y)|$ over this subset.\nThe final results are rounded to $10$ decimal places as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_mu(d, omega, N_theta):\n    \"\"\"\n    Computes the smoothing factor mu(omega) numerically.\n\n    Args:\n        d (int): Dimension (1 or 2).\n        omega (float): Relaxation weight.\n        N_theta (int): Number of sample points for the angle(s).\n\n    Returns:\n        float: The computed smoothing factor mu.\n    \"\"\"\n    if d == 1:\n        # Sample theta uniformly over [pi/2, pi] using N_theta points.\n        theta_vals = np.linspace(np.pi / 2, np.pi, N_theta)\n        \n        # Calculate amplification factor for each theta.\n        # S(theta) = 1 - omega * (1 - cos(theta))\n        cos_vals = np.cos(theta_vals)\n        amp_factors = 1 - omega * (1 - cos_vals)\n        \n        # The smoothing factor is the max of the absolute values.\n        mu = np.max(np.abs(amp_factors))\n        return mu\n        \n    elif d == 2:\n        # Sample (theta_x, theta_y) uniformly over [0,pi] x [0,pi].\n        theta_1d = np.linspace(0, np.pi, N_theta)\n        theta_x, theta_y = np.meshgrid(theta_1d, theta_1d)\n\n        # Identify the high-frequency set.\n        # This is where theta_x >= pi/2 OR theta_y >= pi/2.\n        # Use a small tolerance for floating point comparison to be safe, though >= is fine.\n        pi_div_2 = np.pi / 2\n        high_freq_mask = (theta_x >= pi_div_2) | (theta_y >= pi_div_2)\n\n        # We only need to compute the amplification factor for the high-frequency modes.\n        theta_x_hf = theta_x[high_freq_mask]\n        theta_y_hf = theta_y[high_freq_mask]\n\n        # Calculate amplification factor for each high-frequency mode.\n        # S(theta_x, theta_y) = 1 - (omega/2) * (2 - cos(theta_x) - cos(theta_y))\n        cos_x = np.cos(theta_x_hf)\n        cos_y = np.cos(theta_y_hf)\n        amp_factors = 1 - (omega / 2) * (2 - cos_x - cos_y)\n        \n        # The smoothing factor is the max of the absolute values.\n        mu = np.max(np.abs(amp_factors))\n        return mu\n    else:\n        raise ValueError(\"Dimension d must be 1 or 2.\")\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (d, omega, N_theta)\n        (1, 2/3, 1024),\n        (2, 2/3, 512),\n        (2, 1.0, 256),\n        (1, 0.0, 64),\n        (2, 0.8, 512),\n    ]\n\n    results = []\n    for case in test_cases:\n        d, omega, N_theta = case\n        mu = compute_mu(d, omega, N_theta)\n        # Round the result to 10 decimal places.\n        results.append(round(mu, 10))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        },
        {
            "introduction": "Building on the foundational concept of the smoothing factor, this exercise delves into a more complex and practical scenario: anisotropic diffusion. You will use Local Fourier Analysis not just to measure smoothing, but to diagnose the failure of a standard point smoother and demonstrate the necessity of a more robust line smoother. This practice highlights the power of Fourier analysis in guiding the design of efficient multigrid methods for challenging problems. ",
            "id": "3387323",
            "problem": "Consider the anisotropic diffusion operator on a rectangular domain aligned with the coordinate axes, given by $-\\left(\\epsilon_{x} \\frac{\\partial^{2} u}{\\partial x^{2}} + \\epsilon_{y} \\frac{\\partial^{2} u}{\\partial y^{2}}\\right)$, where $\\epsilon_{x} > 0$ and $\\epsilon_{y} > 0$ are constant coefficients. Let $\\gamma := \\epsilon_{x}/\\epsilon_{y}$ denote the anisotropy ratio. Discretize this operator on a uniform Cartesian grid with mesh size $h$ in both directions using the standard $5$-point finite difference stencil. Consider a multigrid method that uses semi-coarsening in the $y$-direction only (i.e., coarsen $y$ and keep $x$ unchanged), and analyze the error smoothing properties of relaxation via Local Fourier Analysis (LFA), where the Fourier space is parameterized by $(\\theta_{x}, \\theta_{y}) \\in [-\\pi, \\pi] \\times [-\\pi, \\pi]$.\n\nThe high-frequency set for semi-coarsening in $y$ is defined as $\\mathcal{H}_{y} := \\{(\\theta_{x}, \\theta_{y}) : -\\pi \\le \\theta_{x} \\le \\pi, \\, \\pi/2 \\le |\\theta_{y}| \\le \\pi\\}$. The smoothing factor is the supremum, over $(\\theta_{x}, \\theta_{y}) \\in \\mathcal{H}_{y}$, of the magnitude of the error-propagation symbol for the relaxation scheme. Consider two relaxation strategies applied to the fine grid:\n\n$1.$ Weighted point Jacobi with relaxation weight $\\omega \\in (0, 1)$.\n\n$2.$ Line-block Jacobi with lines parallel to the $x$-axis (that is, exact block solves along $x$-lines and Jacobi coupling between neighboring lines in $y$) with relaxation weight $\\omega \\in (0, 1)$.\n\nStarting from the symbol of the discrete operator and the definitions above, perform Local Fourier Analysis to derive:\n\n- The optimized high-frequency smoothing factor for weighted point Jacobi, $\\mu_{J}^{\\star}(\\gamma)$, obtained by minimizing the worst-case amplification factor over $\\omega \\in (0, 1)$.\n- The optimized high-frequency smoothing factor for $x$-line block Jacobi, $\\mu_{L}^{\\star}$, obtained by minimizing the worst-case amplification factor over $\\omega \\in (0, 1)$.\n\nFor definiteness, call a point smoother “sufficient” if its optimized smoothing factor over $\\mathcal{H}_{y}$ does not exceed a prescribed target $\\eta$, where $\\eta \\in (1/3, 1)$. The line smoother is “necessary” when the point smoother is not sufficient according to this criterion, while the line smoother is able to meet the target in a single sweep.\n\nDetermine the critical anisotropy ratio $\\gamma_{c}(\\eta)$ such that for $\\gamma \\le \\gamma_{c}(\\eta)$ the weighted point Jacobi smoother is sufficient, and for $\\gamma > \\gamma_{c}(\\eta)$ an $x$-line smoother is necessary to meet the same target. Express your final result as a single closed-form analytic expression in terms of $\\eta$. No rounding is required.",
            "solution": "The problem asks for the determination of a critical anisotropy ratio $\\gamma_c(\\eta)$ that demarcates the regime of sufficiency for a weighted point Jacobi smoother versus the necessity of an $x$-line block Jacobi smoother for a specific anisotropic diffusion problem. The analysis will be conducted using Local Fourier Analysis (LFA).\n\nFirst, we discretize the anisotropic diffusion operator $L = -\\left(\\epsilon_{x} \\frac{\\partial^{2}}{\\partial x^{2}} + \\epsilon_{y} \\frac{\\partial^{2}}{\\partial y^{2}}\\right)$ on a uniform Cartesian grid with mesh spacing $h$. Using a standard $5$-point finite difference stencil, the discrete operator $L_h$ acting on a grid function $u_{i,j}$ at grid point $(i,j)$ is:\n$$\nL_h u_{i,j} = -\\epsilon_{x} \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} - \\epsilon_{y} \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2}\n$$\nIntroducing the anisotropy ratio $\\gamma = \\epsilon_x / \\epsilon_y$, we can write:\n$$\nL_h u_{i,j} = \\frac{\\epsilon_y}{h^2} \\left[ -\\gamma(u_{i+1,j} - 2u_{i,j} + u_{i-1,j}) - (u_{i,j+1} - 2u_{i,j} + u_{i,j-1}) \\right]\n$$\nTo perform LFA, we analyze the action of $L_h$ on a Fourier mode $v(\\theta)_{i,j} = \\exp(i(i\\theta_x + j\\theta_y))$, where $\\theta = (\\theta_x, \\theta_y)$ is the Fourier frequency pair. The symbol (or eigenvalue) $\\hat{L}_h(\\theta)$ of the operator $L_h$ is found by applying $L_h$ to $v(\\theta)$:\n$$\n\\hat{L}_h(\\theta) = \\frac{\\epsilon_y}{h^2} \\left[ -\\gamma(e^{i\\theta_x} - 2 + e^{-i\\theta_x}) - (e^{i\\theta_y} - 2 + e^{-i\\theta_y}) \\right]\n$$\n$$\n\\hat{L}_h(\\theta) = \\frac{2\\epsilon_y}{h^2} \\left[ \\gamma(1-\\cos\\theta_x) + (1-\\cos\\theta_y) \\right]\n$$\nUsing the half-angle identity $1 - \\cos\\alpha = 2\\sin^2(\\alpha/2)$, the symbol becomes:\n$$\n\\hat{L}_h(\\theta) = \\frac{4\\epsilon_y}{h^2} \\left[ \\gamma\\sin^2\\left(\\frac{\\theta_x}{2}\\right) + \\sin^2\\left(\\frac{\\theta_y}{2}\\right) \\right]\n$$\n\nNext, we analyze the smoothing properties of the two relaxation schemes. The smoothing factor is the supremum of the magnitude of the error amplification symbol over the high-frequency set $\\mathcal{H}_{y} = \\{(\\theta_{x}, \\theta_{y}) : -\\pi \\le \\theta_{x} \\le \\pi, \\, \\pi/2 \\le |\\theta_{y}| \\le \\pi\\}$.\n\n$1.$ Weighted Point Jacobi\nThe weighted Jacobi iteration for the system $L_h u = f$ is given by $u^{(k+1)} = u^{(k)} - \\omega D^{-1}(L_h u^{(k)} - f)$, where $D$ is the diagonal of $L_h$. The error $e^{(k)}$ propagates according to $e^{(k+1)} = (I - \\omega D^{-1}L_h)e^{(k)}$. The symbol of the error amplification operator $S_J = I - \\omega D^{-1}L_h$ is $\\hat{S}_J(\\theta) = 1 - \\omega \\hat{D}^{-1}\\hat{L}_h(\\theta)$.\nThe diagonal of the stencil of $L_h$ is the coefficient of $u_{i,j}$, which is $D = \\frac{\\epsilon_y}{h^2}(2\\gamma + 2)$.\nThus, the amplification symbol is:\n$$\n\\hat{S}_J(\\theta) = 1 - \\omega \\frac{\\frac{4\\epsilon_y}{h^2} \\left[ \\gamma\\sin^2\\left(\\frac{\\theta_x}{2}\\right) + \\sin^2\\left(\\frac{\\theta_y}{2}\\right) \\right]}{\\frac{2\\epsilon_y}{h^2}(2\\gamma+2)} = 1 - \\frac{2\\omega}{\\gamma+1} \\left[ \\gamma\\sin^2\\left(\\frac{\\theta_x}{2}\\right) + \\sin^2\\left(\\frac{\\theta_y}{2}\\right) \\right]\n$$\nLet $s_x = \\sin^2(\\theta_x/2)$ and $s_y = \\sin^2(\\theta_y/2)$. Over the Fourier domain $\\theta \\in [-\\pi, \\pi]^2$, $s_x \\in [0, 1]$ and $s_y \\in [0, 1]$. For the high-frequency set $\\mathcal{H}_y$, we have $\\theta_x \\in [-\\pi, \\pi]$ and $|\\theta_y| \\in [\\pi/2, \\pi]$. This means $s_x \\in [0, 1]$ and $s_y \\in [\\sin^2(\\pi/4), \\sin^2(\\pi/2)] = [1/2, 1]$.\nLet $X = \\frac{2}{\\gamma+1}(\\gamma s_x + s_y)$. The amplification factor is $1-\\omega X$. We need to find the range of $X$ for $\\theta \\in \\mathcal{H}_y$.\nThe minimum value of $\\gamma s_x + s_y$ occurs at $s_x=0, s_y=1/2$, giving $1/2$. The maximum occurs at $s_x=1, s_y=1$, giving $\\gamma+1$.\nSo, $X_{min} = \\frac{2}{\\gamma+1}\\left(\\frac{1}{2}\\right) = \\frac{1}{\\gamma+1}$ and $X_{max} = \\frac{2}{\\gamma+1}(\\gamma+1) = 2$.\nThe smoothing factor for a given $\\omega$ is $\\mu_J(\\omega, \\gamma) = \\sup_{\\theta \\in \\mathcal{H}_y} |\\hat{S}_J(\\theta)| = \\sup_{X \\in [1/(\\gamma+1), 2]} |1-\\omega X| = \\max\\left(\\left|1 - \\frac{\\omega}{\\gamma+1}\\right|, |1-2\\omega|\\right)$.\nTo find the optimized smoothing factor $\\mu_J^\\star(\\gamma)$, we minimize $\\mu_J(\\omega, \\gamma)$ with respect to $\\omega \\in (0, 1)$. The minimum occurs when the two arguments of the max function are equal in magnitude: $1 - \\frac{\\omega^*}{\\gamma+1} = -(1-2\\omega^*) = 2\\omega^* - 1$.\n$$\n2 = \\omega^*\\left(2 + \\frac{1}{\\gamma+1}\\right) = \\omega^*\\left(\\frac{2\\gamma+3}{\\gamma+1}\\right) \\implies \\omega^* = \\frac{2(\\gamma+1)}{2\\gamma+3}\n$$\nThis optimal weight is in $(0,1)$ for $\\gamma>0$. The optimized smoothing factor is the value at this weight:\n$$\n\\mu_J^\\star(\\gamma) = |1-2\\omega^*| = \\left|1 - 2\\frac{2(\\gamma+1)}{2\\gamma+3}\\right| = \\left|\\frac{2\\gamma+3 - 4\\gamma-4}{2\\gamma+3}\\right| = \\left|\\frac{-2\\gamma-1}{2\\gamma+3}\\right| = \\frac{2\\gamma+1}{2\\gamma+3}\n$$\n\n$2.$ $x$-Line Block Jacobi\nIn $x$-line Jacobi relaxation, we solve exactly for all variables on a horizontal line simultaneously. The iteration is $u^{(k+1)} = (1-\\omega)u^{(k)} + \\omega u^{(k+1/2)}$, where $u^{(k+1/2)}$ is obtained by solving the system along each $x$-line using values from iteration $k$ for the neighboring lines. The symbol of the error amplification operator $S_L$ for weighted line Jacobi is:\n$$\n\\hat{S}_L(\\theta) = 1-\\omega + \\omega \\frac{\\hat{N}(\\theta)}{\\hat{T}(\\theta)}\n$$\nwhere $\\hat{T}(\\theta)$ is the symbol of the block-diagonal part (the $x$-line operator) and $\\hat{N}(\\theta)$ is the symbol of the off-diagonal part (the coupling between lines).\nThe $x$-line operator is $-\\epsilon_x \\frac{\\partial^2}{\\partial x^2} + \\frac{2\\epsilon_y}{h^2}I$. Its symbol is $\\hat{T}(\\theta_x) = \\frac{4\\epsilon_y}{h^2}\\gamma\\sin^2(\\frac{\\theta_x}{2}) + \\frac{2\\epsilon_y}{h^2}$.\nThe inter-line coupling operator is $\\frac{\\epsilon_y}{h^2}(u_{i,j-1} + u_{i,j+1})$. Its symbol is $\\frac{\\epsilon_y}{h^2}(e^{-i\\theta_y} + e^{i\\theta_y}) = \\frac{2\\epsilon_y}{h^2}\\cos\\theta_y$.\nThe symbol of the full operator is $\\hat{L_h}(\\theta) = \\hat{T}(\\theta_x) - \\frac{2\\epsilon_y}{h^2}\\cos\\theta_y$. The line Jacobi iteration symbol comes from $e^{(k+1)} = (1-\\omega)e^{(k)} + \\omega \\hat{T}(\\theta_x)^{-1}(\\frac{2\\epsilon_y}{h^2} \\cos\\theta_y) e^{(k)}$.\n$$\n\\hat{S}_L(\\theta) = 1-\\omega + \\omega \\frac{\\frac{2\\epsilon_y}{h^2}\\cos\\theta_y}{\\frac{4\\epsilon_y}{h^2}\\gamma\\sin^2(\\frac{\\theta_x}{2}) + \\frac{2\\epsilon_y}{h^2}} = 1-\\omega + \\omega \\frac{\\cos\\theta_y}{2\\gamma\\sin^2(\\frac{\\theta_x}{2}) + 1}\n$$\n$$\n\\hat{S}_L(\\theta) = 1 - \\omega\\left(1 - \\frac{\\cos\\theta_y}{2\\gamma\\sin^2(\\theta_x/2) + 1}\\right)\n$$\nLet $Y = 1 - \\frac{\\cos\\theta_y}{2\\gamma s_x + 1}$. For $\\theta \\in \\mathcal{H}_y$, we have $s_x \\in [0, 1]$ and $\\cos\\theta_y \\in [-1, 0]$.\nThe denominator $2\\gamma s_x + 1$ is in $[1, 2\\gamma+1]$.\nThe fraction $\\frac{\\cos\\theta_y}{2\\gamma s_x + 1}$ ranges from a minimum of $\\frac{-1}{1} = -1$ (at $s_x=0, \\cos\\theta_y=-1$) to a maximum of $0$ (at $\\cos\\theta_y=0$).\nSo, $Y$ is in the range $[1-0, 1-(-1)] = [1, 2]$.\nThe smoothing factor is $\\mu_L(\\omega) = \\sup_{Y \\in [1, 2]} |1-\\omega Y| = \\max(|1-\\omega|, |1-2\\omega|)$, which is independent of $\\gamma$.\nTo optimize, we set $1-\\omega^* = -(1-2\\omega^*) \\implies 2=3\\omega^* \\implies \\omega^*=2/3$.\nThe optimized smoothing factor is $\\mu_L^\\star = |1-2/3|=1/3$.\n\nDetermining the critical anisotropy ratio $\\gamma_c(\\eta)$\nThe weighted point Jacobi smoother is sufficient if its optimized smoothing factor does not exceed the target $\\eta$, i.e., $\\mu_J^\\star(\\gamma) \\le \\eta$.\n$$\n\\frac{2\\gamma+1}{2\\gamma+3} \\le \\eta\n$$\nSince $\\gamma>0$ and $\\eta \\in (1/3, 1)$, we can multiply by $2\\gamma+3$ without changing the inequality direction.\n$$\n2\\gamma+1 \\le \\eta(2\\gamma+3)\n$$\n$$\n2\\gamma+1 \\le 2\\eta\\gamma + 3\\eta\n$$\n$$\n2\\gamma - 2\\eta\\gamma \\le 3\\eta - 1 \\implies 2\\gamma(1-\\eta) \\le 3\\eta - 1\n$$\nSince $1-\\eta > 0$, we have:\n$$\n\\gamma \\le \\frac{3\\eta-1}{2(1-\\eta)}\n$$\nThis is the condition for the point smoother to be sufficient. The critical anisotropy ratio $\\gamma_c(\\eta)$ is the maximum value of $\\gamma$ for which this condition holds. It is found by setting the inequality to an equality:\n$$\n\\gamma_c(\\eta) = \\frac{3\\eta-1}{2(1-\\eta)}\n$$\nFor $\\gamma \\le \\gamma_c(\\eta)$, the point Jacobi smoother is sufficient. For $\\gamma > \\gamma_c(\\eta)$, it is insufficient. In this case, an $x$-line smoother is necessary if it can meet the target. The optimized line smoother has a smoothing factor $\\mu_L^\\star = 1/3$. The problem states $\\eta \\in (1/3, 1)$, which means $1/3 < \\eta$. Therefore, the condition $\\mu_L^\\star \\le \\eta$ is always satisfied ($1/3 \\le \\eta$). This confirms that the $x$-line smoother is always able to meet the target and is thus necessary when point Jacobi fails.",
            "answer": "$$\\boxed{\\frac{3\\eta-1}{2(1-\\eta)}}$$"
        },
        {
            "introduction": "This final practice connects the theoretical concept of error smoothing to its practical role within an iterative algorithm. You will implement a frequency-aware stopping criterion that monitors the spectral properties of the residual, halting the relaxation process once the high-frequency content has been sufficiently damped. This exercise demonstrates the core principle of multigrid methods: using a simple smoother to handle high-frequency errors before transferring the remaining smooth error to a coarser grid for more efficient resolution. ",
            "id": "3387287",
            "problem": "Consider the standard one-dimensional Poisson problem on the unit interval with homogeneous Dirichlet boundary conditions, discretized by second-order centered finite differences. Let the number of interior grid points be $n \\in \\mathbb{N}$, the uniform grid spacing be $h = 1/(n+1)$, and let $A \\in \\mathbb{R}^{n \\times n}$ denote the tridiagonal stiffness matrix corresponding to the discrete Laplacian with entries $A_{jj} = \\frac{2}{h^{2}}$ and $A_{j,j\\pm 1} = -\\frac{1}{h^{2}}$. Consider the linear system $A u = b$ with an initial guess $u^{(0)} = 0$.\n\nWe study the error smoothing properties of relaxation via the Weighted Jacobi (WJ) method, defined by the iteration\n$$\nu^{(k+1)} = u^{(k)} + \\omega D^{-1} \\left(b - A u^{(k)}\\right),\n$$\nwhere $D$ is the diagonal of $A$ and $\\omega \\in (0,1)$ is the relaxation weight. Define the residual at iteration $k$ as $r^{(k)} = b - A u^{(k)}$.\n\nTo make the stopping criterion frequency-aware with respect to a factor-$2$ coarse grid, proceed as follows. Let $\\{\\varphi_{k}\\}_{k=1}^{n}$ denote the Dirichlet eigenmodes of the one-dimensional discrete Laplacian on $n$ interior points, which coincide with the Discrete Sine Transform (DST) of type I basis functions $\\varphi_{k}(j) = \\sin\\!\\big(\\theta_{k} j\\big)$, where $\\theta_{k} = \\frac{k \\pi}{n+1}$ and $j \\in \\{1,2,\\dots, n\\}$. The frequencies with $\\theta_{k} \\in \\left(\\frac{\\pi}{2}, \\pi\\right)$, equivalently indices $k > \\frac{n+1}{2}$, are invisible to a factor-$2$ coarse grid because they alias beyond the coarse-grid Nyquist limit. Denote the index set of these coarse-grid-invisible modes by\n$$\n\\mathcal{K}_{\\text{high}} = \\left\\{ k \\in \\{1,\\dots,n\\} \\,:\\, k > \\frac{n+1}{2} \\right\\}.\n$$\n\nFor any residual vector $r \\in \\mathbb{R}^{n}$, let $\\widehat{r} = \\mathrm{DST}_{\\mathrm{I}}(r)$ denote its Discrete Sine Transform of type I with orthonormal normalization. The high-frequency content of $r$ relative to the coarse grid is quantified by the fraction\n$$\n\\phi(r) = \\frac{\\left\\| \\widehat{r}_{\\mathcal{K}_{\\text{high}}} \\right\\|_{2}}{\\left\\| \\widehat{r} \\right\\|_{2}},\n$$\nwhere $\\widehat{r}_{\\mathcal{K}_{\\text{high}}}$ is the restriction of $\\widehat{r}$ to indices in $\\mathcal{K}_{\\text{high}}$. All angles inside sine functions are to be interpreted in radians.\n\nYour task is to implement a program that, for each specified test case, performs Weighted Jacobi relaxation starting from $u^{(0)} = 0$ and uses the frequency-aware stopping rule: stop at the first iteration $k$ such that $\\phi\\!\\left(r^{(k)}\\right) \\le \\tau$, where $\\tau > 0$ is a given threshold. If the condition is already satisfied at $k = 0$, then return $0$ iterations. If the condition is not met within a given maximum number of iterations, stop and return that maximum.\n\nIn order to ensure that the initial residual $r^{(0)}$ contains a controllable mixture of high and low frequencies, construct the right-hand side as $b = A v$ for a prescribed synthetic solution\n$$\nv_{j} = \\sin\\!\\big(k_{\\text{hi}} \\pi x_{j}\\big) + \\alpha \\sin\\!\\big(k_{\\text{lo}} \\pi x_{j}\\big), \\quad x_{j} = j h,\n$$\nwith integers $k_{\\text{hi}}, k_{\\text{lo}} \\in \\{1,\\dots,n\\}$ and a mixing coefficient $\\alpha > 0$. This guarantees that $r^{(0)} = b$ has the same modal content as $v$, scaled by the eigenvalues of $A$.\n\nBase your derivation and implementation on the following fundamental and well-tested facts: the second-order finite difference discretization of the one-dimensional Laplace operator, the definition of Weighted Jacobi relaxation, the orthogonality and completeness of the Discrete Sine Transform of type I for vectors with homogeneous Dirichlet boundary conditions, and the characterization of coarse-grid-invisible frequencies for factor-$2$ coarsening as those with indices $k > \\frac{n+1}{2}$.\n\nImplement the above frequency-aware stopping criterion and return, for each test case, the smallest nonnegative integer number of iterations required to achieve $\\phi\\!\\left(r^{(k)}\\right) \\le \\tau$. The angle unit is radians. No physical units are involved.\n\nTest suite to implement and evaluate:\n- Case $1$ (general smoothing with effective weight): $n = 63$, $\\omega = \\frac{2}{3}$, $k_{\\text{hi}} = 40$, $k_{\\text{lo}} = 1$, $\\alpha = 0.1$, $\\tau = 10^{-6}$, $\\text{max\\_iters} = 10000$.\n- Case $2$ (slower smoothing with smaller weight): $n = 63$, $\\omega = 0.5$, $k_{\\text{hi}} = 40$, $k_{\\text{lo}} = 1$, $\\alpha = 0.1$, $\\tau = 10^{-6}$, $\\text{max\\_iters} = 10000$.\n- Case $3$ (smaller grid edge case): $n = 15$, $\\omega = \\frac{2}{3}$, $k_{\\text{hi}} = 10$, $k_{\\text{lo}} = 2$, $\\alpha = 0.2$, $\\tau = 10^{-5}$, $\\text{max\\_iters} = 10000$.\n- Case $4$ (loose threshold): $n = 63$, $\\omega = \\frac{2}{3}$, $k_{\\text{hi}} = 48$, $k_{\\text{lo}} = 2$, $\\alpha = 0.1$, $\\tau = 2 \\times 10^{-1}$, $\\text{max\\_iters} = 10000$.\n\nRequired final output format:\nYour program should produce a single line of output containing the iteration counts for the four test cases as a comma-separated list enclosed in square brackets (for example, $[i_{1},i_{2},i_{3},i_{4}]$), where each $i_{m}$ is an integer equal to the iteration count determined by the frequency-aware stopping rule for test case $m$.",
            "solution": "The problem is valid as it presents a well-defined, scientifically sound task rooted in the numerical analysis of partial differential equations. It is complete, consistent, and objective. We proceed with a complete solution.\n\nThe objective is to determine the number of Weighted Jacobi iterations required to reduce the high-frequency content of the residual below a specified threshold $\\tau$. The process is simulated for a one-dimensional Poisson problem on a grid with $n$ interior points.\n\nFirst, we establish the mathematical framework. The problem is discretized as a linear system $A u = b$, where $A \\in \\mathbb{R}^{n \\times n}$ is the stiffness matrix representing the second-order finite difference approximation of the negative Laplacian with homogeneous Dirichlet boundary conditions. The grid spacing is $h = 1/(n+1)$. The matrix $A$ is tridiagonal with diagonal entries $A_{j,j} = 2/h^2$ and off-diagonal entries $A_{j,j\\pm 1} = -1/h^2$.\n\nThe iterative method is the Weighted Jacobi (WJ) scheme, defined by the update rule for the solution vector $u \\in \\mathbb{R}^n$:\n$$\nu^{(k+1)} = u^{(k)} + \\omega D^{-1} \\left(b - A u^{(k)}\\right)\n$$\nwhere $k$ is the iteration index, $\\omega \\in (0,1)$ is a given weight, and $D$ is the diagonal part of $A$. In this case, $D$ is a scalar matrix, $D = (2/h^2)I$, where $I$ is the $n \\times n$ identity matrix. Thus, $D^{-1} = (h^2/2)I$.\n\nThe residual is defined as $r^{(k)} = b - A u^{(k)}$. A more efficient way to track the residual is to derive its update rule directly:\n$$\nr^{(k+1)} = b - A u^{(k+1)} = b - A\\left(u^{(k)} + \\omega D^{-1} r^{(k)}\\right) = \\left(b - A u^{(k)}\\right) - \\omega A D^{-1} r^{(k)}\n$$\nThis simplifies to:\n$$\nr^{(k+1)} = \\left(I - \\omega A D^{-1}\\right) r^{(k)}\n$$\nThe matrix $M_{WJ} = I - \\omega A D^{-1}$ is the iteration matrix for the residual. Substituting the expressions for $A$ and $D^{-1}$, the update rule for the components of the residual vector $r^{(k)} \\in \\mathbb{R}^n$ can be expressed as a stencil operation:\n$$\nr^{(k+1)}_j = (1-\\omega)r^{(k)}_j + \\frac{\\omega}{2}\\left(r^{(k)}_{j-1} + r^{(k)}_{j+1}\\right)\n$$\nfor interior components $j \\in \\{2, \\ldots, n-1\\}$. At the boundaries $j=1$ and $j=n$, the stencil is adapted to a one-sided difference, reflecting the structure of $M_{WJ}$:\n$$\nr^{(k+1)}_1 = (1-\\omega)r^{(k)}_1 + \\frac{\\omega}{2} r^{(k)}_2\n$$\n$$\nr^{(k+1)}_n = (1-\\omega)r^{(k)}_n + \\frac{\\omega}{2} r^{(k)}_{n-1}\n$$\n\nThe core of the problem lies in analyzing the frequency content of the residual. The eigenvectors of the matrix $A$ are the discrete sine functions (DST-I basis):\n$$\n\\varphi_k, \\quad \\text{with components} \\quad [\\varphi_k]_j = \\sin\\left(\\frac{k \\pi j}{n+1}\\right) \\quad \\text{for } j, k \\in \\{1, \\ldots, n\\}\n$$\nThe corresponding eigenvalue for each eigenvector $\\varphi_k$ is:\n$$\n\\lambda_k = \\frac{4}{h^2} \\sin^2\\left(\\frac{k \\pi}{2(n+1)}\\right)\n$$\nSince $\\{\\varphi_k\\}$ form a basis, any residual vector $r$ can be expanded as $r = \\sum_k c_k \\varphi_k$. The WJ iteration acts on each frequency component by multiplying it by an amplification factor $\\mu_k$, which is the eigenvalue of the iteration matrix $M_{WJ}$ corresponding to the eigenvector $\\varphi_k$:\n$$\n\\mu_k = 1 - \\frac{\\omega h^2}{2}\\lambda_k = 1 - 2\\omega \\sin^2\\left(\\frac{k \\pi}{2(n+1)}\\right)\n$$\nFor high frequencies ($k$ close to $n$), the term $\\sin^2(\\dots)$ is close to $1$, so $\\mu_k \\approx 1-2\\omega$. For the choice $\\omega = 2/3$, this gives $|\\mu_k| \\le 1/3$ for all high frequencies, leading to their rapid damping. This is the \"smoothing\" property. Low frequencies ($k$ close to $1$) are damped slowly, as $\\mu_k \\approx 1$.\n\nThe initial residual is constructed to have a mix of high and low frequencies. Starting with $u^{(0)}=0$, the initial residual is $r^{(0)} = b$. The right-hand side $b$ is set as $b=Av$ for a synthetic solution $v = \\varphi_{k_{\\text{hi}}} + \\alpha \\varphi_{k_{\\text{lo}}}$. Using the eigenvector property $Av = A(\\varphi_{k_{\\text{hi}}} + \\alpha\\varphi_{k_{\\text{lo}}}) = \\lambda_{k_{\\text{hi}}}\\varphi_{k_{\\text{hi}}} + \\alpha\\lambda_{k_{\\text{lo}}}\\varphi_{k_{\\text{lo}}}$. Thus,\n$$\nr^{(0)} = \\lambda_{k_{\\text{hi}}} \\varphi_{k_{\\text{hi}}} + \\alpha\\lambda_{k_{\\text{lo}}} \\varphi_{k_{\\text{lo}}}\n$$\nThis provides a well-defined initial state for our simulation.\n\nThe stopping criterion is based on the relative energy of high-frequency components. The high-frequency modes are those not representable on a coarse grid with half the points, corresponding to indices $k > (n+1)/2$. The set of such indices is $\\mathcal{K}_{\\text{high}}$. To quantify the frequency content, we use the Discrete Sine Transform of type I (DST-I) with orthonormal normalization to compute the coefficients $\\widehat{r}$ of a residual $r$ in the orthonormal basis derived from $\\{\\varphi_k\\}$. The stopping metric is:\n$$\n\\phi(r) = \\frac{\\left\\| \\widehat{r}_{\\mathcal{K}_{\\text{high}}} \\right\\|_{2}}{\\left\\| \\widehat{r} \\right\\|_{2}}\n$$\nwhere $\\widehat{r}_{\\mathcal{K}_{\\text{high}}}$ consists of the coefficients with indices in $\\mathcal{K}_{\\text{high}}$. The iteration stops at the first step $k$ where $\\phi(r^{(k)}) \\le \\tau$.\n\nThe algorithm is as follows:\n1.  For each test case, define parameters $n$, $\\omega$, $k_{\\text{hi}}$, $k_{\\text{lo}}$, $\\alpha$, $\\tau$, and $\\text{max\\_iters}$.\n2.  Calculate grid spacing $h=1/(n+1)$ and eigenvalues $\\lambda_{k_{\\text{hi}}}$, $\\lambda_{k_{\\text{lo}}}$.\n3.  Construct the initial residual vector $r^{(0)} = \\lambda_{k_{\\text{hi}}}\\varphi_{k_{\\text{hi}}} + \\alpha\\lambda_{k_{\\text{lo}}}\\varphi_{k_{\\text{lo}}}$.\n4.  Compute $\\phi(r^{(0)})$. If $\\phi(r^{(0)}) \\le \\tau$, the process stops with $0$ iterations.\n5.  Otherwise, iterate from $k=1$ to $\\text{max\\_iters}$:\n    a. Update the residual vector $r^{(k)}$ from $r^{(k-1)}$ using the efficient stencil computation.\n    b. Compute the orthonormal DST-I of $r^{(k)}$ to get the coefficients $\\widehat{r}^{(k)}$.\n    c. Calculate $\\phi(r^{(k)})$ by taking the ratio of vector norms of the high-frequency components and the total components of $\\widehat{r}^{(k)}$.\n    d. If $\\phi(r^{(k)}) \\le \\tau$, record the iteration count $k$ and terminate the loop for this case.\n6.  If the loop completes without meeting the criterion, the result is $\\text{max\\_iters}$.\n7.  Collect the iteration counts for all test cases. All angle computations are performed in radians.",
            "answer": "```python\nimport numpy as np\nfrom scipy import fft\n\ndef calculate_phi(r, n):\n    \"\"\"\n    Calculates the high-frequency content ratio phi for a given residual vector.\n    \n    Args:\n        r (np.ndarray): The residual vector of size n.\n        n (int): The number of interior grid points.\n        \n    Returns:\n        float: The high-frequency content ratio phi(r).\n    \"\"\"\n    # The problem statement defines high-frequency modes with 1-based indices k > (n+1)/2.\n    # We create a boolean mask for these modes.\n    k_1based = np.arange(1, n + 1)\n    high_freq_mask = k_1based > (n + 1) / 2.0\n    \n    # Compute the Discrete Sine Transform of type I with orthonormal normalization.\n    # The output array `r_hat` corresponds to modes k=1, ..., n.\n    # `r_hat[i]` is the coefficient for mode i+1.\n    r_hat = fft.dst(r, type=1, norm='ortho')\n    \n    # Extract the coefficients corresponding to high-frequency modes using the mask.\n    r_hat_high = r_hat[high_freq_mask]\n    \n    # Calculate the L2 norm of the high-frequency components.\n    norm_r_hat_high = np.linalg.norm(r_hat_high)\n    \n    # Calculate the L2 norm of the total set of components.\n    # Due to Parseval's theorem for an orthonormal transform, this is equal to np.linalg.norm(r).\n    norm_r_hat_total = np.linalg.norm(r_hat)\n    \n    # Avoid division by zero if the residual is zero.\n    if norm_r_hat_total == 0:\n        return 0.0\n        \n    return norm_r_hat_high / norm_r_hat_total\n\ndef solve_case(n, omega, k_hi, k_lo, alpha, tau, max_iters):\n    \"\"\"\n    Solves one test case of the frequency-aware stopping problem.\n    \n    Returns:\n        int: The number of iterations required.\n    \"\"\"\n    \n    # 1. Setup constants and grid\n    h = 1.0 / (n + 1)\n    x = np.arange(1, n + 1, dtype=float) * h\n    \n    # Function to compute eigenvalues of the discrete Laplacian matrix A\n    def get_eigenvalue(k_mode, n_pts, h_spacing):\n        return (4.0 / h_spacing**2) * np.sin(k_mode * np.pi / (2.0 * (n_pts + 1)))**2\n        \n    lambda_hi = get_eigenvalue(k_hi, n, h)\n    lambda_lo = get_eigenvalue(k_lo, n, h)\n    \n    # Unnormalized eigenvectors (modes)\n    phi_hi = np.sin(k_hi * np.pi * x)\n    phi_lo = np.sin(k_lo * np.pi * x)\n    \n    # 2. Construct the initial residual r^(0) = b = A*v\n    r_k = lambda_hi * phi_hi + alpha * lambda_lo * phi_lo\n    \n    # 3. Check stopping criterion for k = 0\n    phi_k = calculate_phi(r_k, n)\n    if phi_k <= tau:\n        return 0\n        \n    # 4. Iteration Loop\n    for k in range(1, max_iters + 1):\n        r_prev = r_k.copy()\n        \n        # Update residual using the efficient stencil application of (I - omega*A*D^-1)\n        r_k[1:-1] = (1.0 - omega) * r_prev[1:-1] + (omega / 2.0) * (r_prev[:-2] + r_prev[2:])\n        r_k[0] = (1.0 - omega) * r_prev[0] + (omega / 2.0) * r_prev[1]\n        r_k[-1] = (1.0 - omega) * r_prev[-1] + (omega / 2.0) * r_prev[-2]\n        \n        # Calculate phi for the new residual\n        phi_k = calculate_phi(r_k, n)\n\n        # Check stopping criterion\n        if phi_k <= tau:\n            return k\n            \n    # 5. If criterion is not met within max_iters, return max_iters\n    return max_iters\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # (n, omega, k_hi, k_lo, alpha, tau, max_iters)\n        (63, 2.0/3.0, 40, 1, 0.1, 1e-6, 10000),\n        (63, 0.5, 40, 1, 0.1, 1e-6, 10000),\n        (15, 2.0/3.0, 10, 2, 0.2, 1e-5, 10000),\n        (63, 2.0/3.0, 48, 2, 0.1, 2e-1, 10000),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(*case)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}