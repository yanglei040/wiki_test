{
    "hands_on_practices": [
        {
            "introduction": "To effectively implement numerical continuation, one must first have a concrete understanding of the underlying linear algebraic structures. This exercise guides you through a foundational pencil-and-paper calculation for a simple, two-point discretization of the Bratu equation. By explicitly constructing the residual vector, the Jacobian matrix, and solving for the tangent direction at a specific point, you will solidify your grasp of the core components that form a single predictor step in a pseudo-arclength framework .",
            "id": "3373968",
            "problem": "Consider the steady-state one-dimensional Bratu-type Partial Differential Equation (PDE)\n$$\\frac{d^{2}u}{dx^{2}} + \\lambda \\exp(u) = 0,$$\nposed on the interval $x \\in [0,1]$ with homogeneous Dirichlet boundary conditions $u(0) = 0$ and $u(1) = 0$. Using the standard second-order central finite difference scheme on a uniform grid with spacing $h = \\frac{1}{3}$, the interior grid points are at $x_{1} = h$ and $x_{2} = 2h$, with unknowns $u_{1} \\approx u(x_{1})$ and $u_{2} \\approx u(x_{2})$. Denote $u_{0} = 0$ and $u_{3} = 0$ as the boundary values. The residual at interior node $x_{i}$ is defined by\n$$R_{i}(u,\\lambda) = \\frac{u_{i-1} - 2u_{i} + u_{i+1}}{h^{2}} + \\lambda \\exp(u_{i}), \\quad i = 1,2,$$\nso that the discrete nonlinear system is $R(u,\\lambda) = 0$ in $\\mathbb{R}^{2}$. Let $J(u,\\lambda) = \\frac{\\partial R}{\\partial u}$ be the Jacobian matrix with respect to the vector $u = (u_{1},u_{2})^{\\top}$, and let $R_{\\lambda}(u,\\lambda) = \\frac{\\partial R}{\\partial \\lambda}$ be the partial derivative of the residual with respect to the parameter $\\lambda$.\n\nIn a pseudo-arclength continuation framework, the tangent $(u_{s},\\lambda_{s})$ to the solution branch solves the linearized coupling\n$$J(u,\\lambda)\\,u_{s} + R_{\\lambda}(u,\\lambda)\\,\\lambda_{s} = 0,$$\nsupplemented by a normalization constraint\n$$c^{\\top} u_{s} + \\gamma\\,\\lambda_{s} = 1,$$\nfor a given vector $c \\in \\mathbb{R}^{2}$ and scalar $\\gamma \\in \\mathbb{R}$.\n\nStarting from the above fundamental definitions and using $h = \\frac{1}{3}$, derive explicit expressions for $R(u,\\lambda)$, $J(u,\\lambda)$, and $R_{\\lambda}(u,\\lambda)$ for this discretization. Then, at the state\n$$u_{1} = 0.2,\\quad u_{2} = 0.1,\\quad \\lambda = 2,$$\nwith normalization data\n$$c = \\begin{pmatrix}1 \\\\ -1\\end{pmatrix},\\quad \\gamma = 0,$$\nsolve the coupled linear system for the tangent and compute the scalar $\\lambda_{s}$. Round your answer to five significant figures. The final answer must be a single real number without units.",
            "solution": "The user wants to find the tangent component $\\lambda_s$ for a pseudo-arclength continuation problem applied to a discretized Bratu-type PDE.\n\n### Step 1: Derivation of System Components\n\nFirst, we derive the explicit forms of the residual vector $R(u, \\lambda)$, the Jacobian matrix $J(u, \\lambda)$, and the parameter derivative vector $R_{\\lambda}(u, \\lambda)$. The grid spacing is $h = \\frac{1}{3}$, so $h^2 = \\frac{1}{9}$.\n\nThe residual equations at the interior nodes $i=1$ and $i=2$ are:\n$$R_{1}(u,\\lambda) = \\frac{u_{0} - 2u_{1} + u_{2}}{h^{2}} + \\lambda \\exp(u_{1})$$\n$$R_{2}(u,\\lambda) = \\frac{u_{1} - 2u_{2} + u_{3}}{h^{2}} + \\lambda \\exp(u_{2})$$\nUsing the boundary conditions $u_0 = 0$ and $u_3 = 0$, the residual vector $R = (R_1, R_2)^\\top$ is:\n$$R(u,\\lambda) = \\begin{pmatrix} \\frac{-2u_{1} + u_{2}}{h^{2}} + \\lambda \\exp(u_{1}) \\\\ \\frac{u_{1} - 2u_{2}}{h^{2}} + \\lambda \\exp(u_{2}) \\end{pmatrix}$$\n\nThe Jacobian matrix $J(u,\\lambda) = \\frac{\\partial R}{\\partial u}$ is a $2 \\times 2$ matrix with elements $J_{ij} = \\frac{\\partial R_i}{\\partial u_j}$:\n$$J_{11} = \\frac{\\partial R_1}{\\partial u_1} = -\\frac{2}{h^2} + \\lambda \\exp(u_1)$$\n$$J_{12} = \\frac{\\partial R_1}{\\partial u_2} = \\frac{1}{h^2}$$\n$$J_{21} = \\frac{\\partial R_2}{\\partial u_1} = \\frac{1}{h^2}$$\n$$J_{22} = \\frac{\\partial R_2}{\\partial u_2} = -\\frac{2}{h^2} + \\lambda \\exp(u_2)$$\nSo, the Jacobian matrix is:\n$$J(u,\\lambda) = \\begin{pmatrix} -2/h^2 + \\lambda \\exp(u_1) & 1/h^2 \\\\ 1/h^2 & -2/h^2 + \\lambda \\exp(u_2) \\end{pmatrix}$$\n\nThe derivative of the residual with respect to $\\lambda$, $R_{\\lambda}(u,\\lambda) = \\frac{\\partial R}{\\partial \\lambda}$, is the vector:\n$$R_{\\lambda}(u,\\lambda) = \\begin{pmatrix} \\frac{\\partial R_1}{\\partial \\lambda} \\\\ \\frac{\\partial R_2}{\\partial \\lambda} \\end{pmatrix} = \\begin{pmatrix} \\exp(u_1) \\\\ \\exp(u_2) \\end{pmatrix}$$\n\n### Step 2: Setting up and Solving the Linear System for the Tangent\n\nThe tangent vector $(u_s, \\lambda_s)$, where $u_s = (u_{s1}, u_{s2})^\\top$, is found by solving the coupled system:\n1. $J(u,\\lambda)\\,u_{s} + R_{\\lambda}(u,\\lambda)\\,\\lambda_{s} = 0$\n2. $c^{\\top} u_{s} + \\gamma\\,\\lambda_{s} = 1$\n\nWe substitute the given normalization data $c = (1, -1)^\\top$ and $\\gamma=0$ into the second equation:\n$$c^{\\top} u_{s} = 1 \\implies \\begin{pmatrix} 1 & -1 \\end{pmatrix} \\begin{pmatrix} u_{s1} \\\\ u_{s2} \\end{pmatrix} = 1 \\implies u_{s1} - u_{s2} = 1$$\n\nFrom the first equation, we can express $u_s$ in terms of $\\lambda_s$:\n$$J u_s = -R_{\\lambda} \\lambda_s \\implies u_s = -\\lambda_s J^{-1} R_{\\lambda}$$\nSubstituting this into the normalization equation gives:\n$$c^{\\top} (-\\lambda_s J^{-1} R_{\\lambda}) = 1$$\n$$- \\lambda_s (c^{\\top} J^{-1} R_{\\lambda}) = 1$$\n$$\\lambda_s = \\frac{-1}{c^{\\top} J^{-1} R_{\\lambda}}$$\n\nLet's compute the term $c^{\\top} J^{-1} R_{\\lambda}$. The inverse of the Jacobian is:\n$$J^{-1} = \\frac{1}{\\det(J)} \\begin{pmatrix} J_{22} & -J_{12} \\\\ -J_{21} & J_{11} \\end{pmatrix}$$\nSo we have:\n$$c^{\\top} J^{-1} R_{\\lambda} = \\frac{1}{\\det(J)} \\begin{pmatrix} 1 & -1 \\end{pmatrix} \\begin{pmatrix} J_{22} & -J_{12} \\\\ -J_{21} & J_{11} \\end{pmatrix} \\begin{pmatrix} \\exp(u_1) \\\\ \\exp(u_2) \\end{pmatrix}$$\n$$= \\frac{1}{\\det(J)} \\begin{pmatrix} J_{22}+J_{21} & -J_{12}-J_{11} \\end{pmatrix} \\begin{pmatrix} \\exp(u_1) \\\\ \\exp(u_2) \\end{pmatrix}$$\n$$= \\frac{1}{\\det(J)} \\left[ (J_{22}+J_{21})\\exp(u_1) - (J_{12}+J_{11})\\exp(u_2) \\right]$$\nSubstituting the expressions for $J_{ij}$:\n$$= \\frac{1}{\\det(J)} \\left[ (-\\frac{2}{h^2} + \\lambda\\exp(u_2) + \\frac{1}{h^2})\\exp(u_1) - (\\frac{1}{h^2} - \\frac{2}{h^2} + \\lambda\\exp(u_1))\\exp(u_2) \\right]$$\n$$= \\frac{1}{\\det(J)} \\left[ (-\\frac{1}{h^2} + \\lambda\\exp(u_2))\\exp(u_1) - (-\\frac{1}{h^2} + \\lambda\\exp(u_1))\\exp(u_2) \\right]$$\n$$= \\frac{1}{\\det(J)} \\left[ -\\frac{1}{h^2}\\exp(u_1) + \\lambda\\exp(u_1)\\exp(u_2) + \\frac{1}{h^2}\\exp(u_2) - \\lambda\\exp(u_1)\\exp(u_2) \\right]$$\n$$= \\frac{1}{\\det(J)} \\left[ \\frac{1}{h^2}(\\exp(u_2) - \\exp(u_1)) \\right]$$\nThus,\n$$\\lambda_s = \\frac{-1}{\\frac{1}{\\det(J)} \\frac{\\exp(u_2) - \\exp(u_1)}{h^2}} = \\frac{-h^2 \\det(J)}{\\exp(u_2) - \\exp(u_1)} = \\frac{h^2 \\det(J)}{\\exp(u_1) - \\exp(u_2)}$$\n\n### Step 3: Numerical Evaluation\n\nNow we evaluate this expression at the state $u_1=0.2$, $u_2=0.1$, $\\lambda=2$, with $h=1/3$ ($1/h^2=9$).\nFirst, we compute the determinant of the Jacobian at this state:\n$$J = \\begin{pmatrix} -18 + 2 \\exp(0.2) & 9 \\\\ 9 & -18 + 2 \\exp(0.1) \\end{pmatrix}$$\n$$\\det(J) = (-18 + 2\\exp(0.2))(-18 + 2\\exp(0.1)) - (9)(9)$$\n$$\\det(J) = 324 - 36\\exp(0.1) - 36\\exp(0.2) + 4\\exp(0.3) - 81$$\n$$\\det(J) = 243 - 36(\\exp(0.1) + \\exp(0.2)) + 4\\exp(0.3)$$\n\nUsing high-precision values:\n$\\exp(0.1) \\approx 1.105170918$\n$\\exp(0.2) \\approx 1.221402758$\n$\\exp(0.3) \\approx 1.349858808$\n\n$\\det(J) = 243 - 36(1.105170918 + 1.221402758) + 4(1.349858808)$\n$\\det(J) = 243 - 36(2.326573676) + 5.399435232$\n$\\det(J) = 243 - 83.756652336 + 5.399435232$\n$\\det(J) \\approx 164.6427829$\n\n$\\exp(u_1) - \\exp(u_2) = \\exp(0.2) - \\exp(0.1) \\approx 1.221402758 - 1.105170918 = 0.11623184$\n\n$h^2 = (1/3)^2 = 1/9$.\n\n$\\lambda_s = \\frac{(1/9) \\times 164.6427829}{0.11623184} = \\frac{18.29364254}{0.11623184} \\approx 157.3891465$\n\nThe problem requires rounding to five significant figures.\n$\\lambda_s \\approx 157.39$",
            "answer": "$$\n\\boxed{157.39}\n$$"
        },
        {
            "introduction": "The central advantage of pseudo-arclength continuation is its ability to trace solution branches through turning points where simpler methods fail. This practice provides a direct and compelling demonstration of this capability by challenging you to implement and compare two algorithms on the canonical cusp bifurcation model . You will observe how single-parameter continuation stalls at a fold, while the pseudo-arclength method, by parameterizing the curve by its own arclength, successfully navigates the turning point, revealing the full 'S'-shaped structure of the solution set.",
            "id": "3217867",
            "problem": "Construct and analyze a one-parameter family of steady-state equations that exhibits a cusp bifurcation, and implement two numerical continuation methods to compare their behavior near turning points. Consider the scalar equilibrium condition defined by the implicit equation\n$$\nf(x,\\lambda,\\mu) \\equiv x^3 + \\lambda x + \\mu = 0,\n$$\nwhere $x \\in \\mathbb{R}$ is the state variable and $(\\lambda,\\mu) \\in \\mathbb{R}^2$ are parameters. This equation arises as the stationarity condition of a smooth potential and is a standard normal form model exhibiting a cusp singularity in the $(\\lambda,\\mu)$ plane.\n\nTasks to implement and verify:\n- Implement a single-parameter predictor-corrector continuation method using $\\mu$ as the continuation parameter, with predictor based on the implicit function theorem when applicable. That is, when $\\partial f/\\partial x \\neq 0$, the local slope satisfies\n$$\n\\frac{dx}{d\\mu} = -\\frac{\\partial f/\\partial \\mu}{\\partial f/\\partial x}.\n$$\nUse this slope to form a predictor $x_{\\text{pred}}$, and then correct to a root of $f(x,\\lambda,\\mu_{\\text{next}})=0$ using Newton's method in one dimension. Define a numerical \"stall\" for single-parameter continuation as follows: initialize at a solution $(x_0,\\mu_0)$ and track the sign of $\\partial f/\\partial x$ evaluated at the corrected solution on each step. If this sign changes relative to its initial value while stepping $\\mu$ in a fixed direction, declare that the single-parameter continuation has stalled (because the target branch terminates at a fold and the algorithm necessarily jumps to a different branch).\n- Implement a pseudo-arclength continuation method (also called arclength continuation) that treats $(x,\\mu)$ as unknowns and augments the scalar equilibrium equation by a linearized arclength constraint. At a known solution $(x_k,\\mu_k)$, compute a tangent direction $(t_x,t_\\mu)$ orthogonal to the gradient of $f$, for example by taking\n$$\n(t_x,t_\\mu) \\propto \\left(-\\frac{\\partial f}{\\partial \\mu}, \\frac{\\partial f}{\\partial x}\\right) = (-1, 3x_k^2+\\lambda),\n$$\nand normalizing. Use a predictor $(x_{\\text{pred}},\\mu_{\\text{pred}})=(x_k,\\mu_k)+h(t_x,t_\\mu)$, and then perform a Newton corrector for the $2\\times 2$ system\n$$\n\\begin{cases}\nf(x,\\lambda,\\mu) = 0,\\\\\nt_x (x - x_k) + t_\\mu (\\mu - \\mu_k) - h = 0,\n\\end{cases}\n$$\nwith Jacobian matrix\n$$\nJ(x,\\mu) =\n\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x} & \\frac{\\partial f}{\\partial \\mu}\\\\\nt_x & t_\\mu\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n3x^2+\\lambda & 1\\\\\nt_x & t_\\mu\n\\end{bmatrix}.\n$$\nThis augmented system remains nonsingular at a fold where $3x^2+\\lambda=0$ provided $t_\\mu \\neq 0$, so the method can generically pass through turning points.\n- Use the canonical cusp diagnostics to justify the setup. The fold set for fixed $\\lambda$ is given by simultaneous solutions of $f=0$ and $\\partial f/\\partial x=0$, namely $3x^2+\\lambda=0$ and $\\mu=-x^3-\\lambda x$. Eliminating $x$ gives the cusp curve in parameter space,\n$$\n4\\lambda^3 + 27\\mu^2 = 0,\n$$\nwith the cusp point at $(\\lambda,\\mu)=(0,0)$. For a fixed negative $\\lambda$, there are two distinct folds at\n$$\nx_{\\text{fold}}=\\pm\\sqrt{-\\lambda/3},\\quad \\mu_{\\text{fold}}=\\mp\\left(\\frac{-\\lambda}{3}\\right)^{3/2}-\\lambda\\left(\\pm\\sqrt{-\\lambda/3}\\right).\n$$\n- Algorithmic details to enforce:\n  - Use Newton's method with a maximum of $50$ iterations and an absolute stopping tolerance of $10^{-12}$ on the update norm for both the one-dimensional and two-dimensional correctors.\n  - For single-parameter continuation, at each step use the predictor $x_{\\text{pred}}=x_k + \\left(-1/(3x_k^2+\\lambda)\\right) h_\\mu$ when $3x_k^2+\\lambda \\neq 0$, then correct to $f(x,\\lambda,\\mu_{k+1})=0$ with $\\mu_{k+1}=\\mu_k+h_\\mu$. If Newton fails to converge within the iteration budget, declare a stall. Otherwise, compare the sign of $3x^2+\\lambda$ at the corrected point to its initial sign; if it differs, declare a stall.\n  - For pseudo-arclength continuation, at each step compute and normalize $(t_x,t_\\mu)=(-1, 3x_k^2+\\lambda)$, choose its sign so that $t_\\mu>0$ at the initial step and so that it varies continuously thereafter (align with the previous step by enforcing a positive dot product), then use the predictor-corrector described above. Record the sequence of $\\mu$ values and declare success if all correctors converge and the maximum attained $\\mu$ strictly exceeds the theoretical positive fold value by at least $10^{-3}$ when $\\lambda<0$.\n- Numerical values are unitless; no physical units are involved. Use radians if any trigonometric functions are employed, but none are required here.\n\nTest suite specification. Your program must run exactly these four tests and return booleans indicating the outcomes described above:\n- Test $1$ (single-parameter, happy path with stall): $\\lambda=-1$, start $(x_0,\\mu_0)=(0,0)$ on the middle branch, step size $h_\\mu=0.05$, number of steps $N=20$. Output should be $True$ if a stall is detected by the sign-change rule or by Newton failure, otherwise $False$.\n- Test $2$ (pseudo-arclength, successful fold crossing): $\\lambda=-1$, start $(x_0,\\mu_0)=(0,0)$, arclength step $h=0.1$, number of steps $N=20$. Output should be $True$ if all correctors converge and the maximum $\\mu$ visited exceeds the theoretical positive fold value by at least $10^{-3}$, otherwise $False$.\n- Test $3$ (single-parameter, no fold present): $\\lambda=0.5$, start $(x_0,\\mu_0)=(0,0)$, step size $h_\\mu=0.05$, number of steps $N=20$. Since there is no fold for $\\lambda>0$, the output should be $False$ (no stall).\n- Test $4$ (pseudo-arclength, small negative $\\lambda$ near cusp): $\\lambda=-0.1$, start $(x_0,\\mu_0)=(0,0)$, arclength step $h=0.05$, number of steps $N=40$. Output should be $True$ if all correctors converge and the maximum $\\mu$ visited exceeds the theoretical positive fold by at least $10^{-3}$, otherwise $False$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of Tests $1$ through $4$, for example, \"[result1,result2,result3,result4]\".\n- Each result must be a boolean literal $True$ or $False$.\n- There must be exactly $1$ line of output.",
            "solution": "The user has requested the implementation and comparison of two numerical continuation methods—a single-parameter predictor-corrector method and a pseudo-arclength method—for tracing solution curves of a system exhibiting a cusp bifurcation. The problem is mathematically sound and well-defined, representing a standard exercise in numerical bifurcation theory.\n\nThe governing equation is the normal form for a cusp bifurcation:\n$$\nf(x, \\lambda, \\mu) \\equiv x^3 + \\lambda x + \\mu = 0\n$$\nHere, $x$ is the state variable, while $\\lambda$ and $\\mu$ are control parameters. The continuation will be performed in the $(x, \\mu)$ plane for fixed values of $\\lambda$.\n\nThe set of steady-state solutions $(x, \\mu)$ for a fixed $\\lambda$ forms a curve in the $\\mathbb{R}^2$ plane. Turning points, or folds, on this curve occur where the curve's tangent becomes vertical with respect to the $\\mu$-axis. These points are critical because simple continuation methods that use $\\mu$ as a parameter will fail. The condition for a fold is that the derivative of $f$ with respect to $x$ vanishes:\n$$\n\\frac{\\partial f}{\\partial x} = 3x^2 + \\lambda = 0\n$$\nSolving this simultaneously with $f(x, \\lambda, \\mu) = 0$ gives the locations of the folds. For a fold to exist, we must have $x^2 = -\\lambda/3$, which requires $\\lambda \\le 0$. Substituting this into the equilibrium equation gives the corresponding $\\mu$ values at the folds:\n$$\n\\mu = -x^3 - \\lambda x = -x(x^2 + \\lambda) = -x(-\\lambda/3 + \\lambda) = -x(2\\lambda/3)\n$$\nSubstituting $x = \\pm\\sqrt{-\\lambda/3}$, we find the two fold locations:\n$$\n(x_{\\text{fold}}, \\mu_{\\text{fold}}) = \\left(\\pm\\sqrt{-\\frac{\\lambda}{3}}, \\mp\\frac{2\\lambda}{3}\\sqrt{-\\frac{\\lambda}{3}}\\right) = \\left(\\pm\\sqrt{-\\frac{\\lambda}{3}}, \\pm 2\\left(-\\frac{\\lambda}{3}\\right)^{3/2}\\right)\n$$\nFor $\\lambda > 0$, $\\partial f/\\partial x = 3x^2 + \\lambda > 0$ for all $x$, so no folds exist, and the solution $x$ is a single-valued monotonic function of $\\mu$.\n\nThe implementation proceeds as follows:\n\n1.  **Single-Parameter Continuation**: This method treats $\\mu$ as the independent continuation parameter. Given a solution $(x_k, \\mu_k)$, we take a step of size $h_\\mu$ to $\\mu_{k+1} = \\mu_k + h_\\mu$. The next solution point $x_{k+1}$ is predicted using a first-order Taylor expansion (Euler's method), where the derivative $dx/d\\mu$ is found from the implicit function theorem:\n    $$\n    \\frac{d}{d\\mu}f(x(\\mu), \\lambda, \\mu) = \\frac{\\partial f}{\\partial x}\\frac{dx}{d\\mu} + \\frac{\\partial f}{\\partial \\mu} = 0 \\implies \\frac{dx}{d\\mu} = -\\frac{\\partial f/\\partial \\mu}{\\partial f/\\partial x} = -\\frac{1}{3x^2+\\lambda}\n    $$\n    The predictor is $x_{\\text{pred}} = x_k + (dx/d\\mu)|_{x_k} \\cdot h_\\mu$. This predicted value serves as an initial guess for a one-dimensional Newton's method to find the exact root $x_{k+1}$ of $f(x, \\lambda, \\mu_{k+1}) = 0$. This method fails near a fold where $\\partial f/\\partial x \\to 0$, causing the step to diverge. A \"stall\" is declared if Newton's method fails or if the sign of $\\partial f/\\partial x$ changes, indicating a jump to a different solution branch with different stability properties.\n\n2.  **Pseudo-Arclength Continuation**: This more robust method treats both $x$ and $\\mu$ as dependent variables, parameterized by a pseudo-arclength parameter $s$. The original equation $f(x, \\lambda, \\mu) = 0$ is augmented with a constraint that defines the step size $h$ along the solution curve. At a known point $(x_k, \\mu_k)$, we compute a normalized tangent vector $(t_x, t_\\mu)$. A suitable choice, orthogonal to the gradient $(\\partial f/\\partial x, \\partial f/\\partial \\mu)$, is $(t_x, t_\\mu) \\propto (- \\partial f/\\partial \\mu, \\partial f/\\partial x) = (-1, 3x^2+\\lambda)$. The predictor step is taken along this tangent: $(x_{\\text{pred}}, \\mu_{\\text{pred}}) = (x_k, \\mu_k) + h \\cdot (t_x, t_\\mu)$. The corrector step then solves the following $2 \\times 2$ system for $(x_{k+1}, \\mu_{k+1})$ using a two-dimensional Newton's method:\n    $$\n    \\begin{cases}\n    f(x, \\lambda, \\mu) = 0 & \\text{(Equilibrium condition)} \\\\\n    t_x (x - x_k) + t_\\mu (\\mu - \\mu_k) - h = 0 & \\text{(Arclength constraint)}\n    \\end{cases}\n    $$\n    The Jacobian of this augmented system is non-singular even at fold points (provided $t_\\mu \\ne 0$), allowing the method to smoothly trace the solution curve around turning points. We implement a tangent-following strategy to ensure the curve is traversed in a consistent direction.\n\nThe provided Python code implements both algorithms, adhering strictly to the specified numerical parameters and test cases. The solution for each test case is determined based on the precise success/stall criteria given in the problem description.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and solves the test suite for comparing single-parameter\n    and pseudo-arclength continuation methods on a cusp bifurcation problem.\n    \"\"\"\n    # Define universal constants and algorithmic parameters from the problem\n    TOL = 1e-12\n    MAX_ITER = 50\n\n    # --- Newton Corrector Implementations ---\n\n    def newton1d(lam, mu_new, x_pred):\n        \"\"\"\n        Solves f(x, lam, mu_new) = x^3 + lam*x + mu_new = 0 using Newton's method.\n        Returns the root x or None if convergence fails.\n        \"\"\"\n        x = x_pred\n        for _ in range(MAX_ITER):\n            f_val = x**3 + lam * x + mu_new\n            df_val = 3 * x**2 + lam\n            # Avoid division by zero if Jacobian is singular\n            if abs(df_val) < 1e-14:\n                return None\n            update = -f_val / df_val\n            x += update\n            if abs(update) < TOL:\n                return x\n        return None # Failed to converge within max_iter\n\n    def newton2d(v_pred, lam, xk, muk, tx, tmu, h):\n        \"\"\"\n        Solves the 2x2 augmented system for pseudo-arclength continuation\n        using Newton's method.\n        Returns the solution vector [x, mu] or None if convergence fails.\n        \"\"\"\n        v = np.copy(v_pred)  # v = [x, mu]\n        for _ in range(MAX_ITER):\n            x, mu = v[0], v[1]\n            \n            # Form the residual vector G\n            g1 = x**3 + lam * x + mu\n            g2 = tx * (x - xk) + tmu * (mu - muk) - h\n            G = np.array([g1, g2])\n\n            # Form the Jacobian matrix J\n            j11 = 3 * x**2 + lam\n            J = np.array([[j11, 1.0], [tx, tmu]])\n            \n            # Check for singularity\n            if abs(np.linalg.det(J)) < 1e-14:\n                return None\n\n            update = np.linalg.solve(J, -G)\n            v += update\n            \n            if np.linalg.norm(update) < TOL:\n                return v\n        return None # Failed to converge within max_iter\n\n    # --- Continuation Method Implementations ---\n\n    def single_parameter_continuation(lam, x0, mu0, h_mu, N):\n        \"\"\"\n        Implements single-parameter continuation in mu.\n        Returns True if a stall is detected, False otherwise.\n        \"\"\"\n        xk, muk = x0, mu0\n        \n        dfdx_initial = 3 * xk**2 + lam\n        if abs(dfdx_initial) < 1e-14:\n            return True # Stall if starting exactly at a fold\n        initial_sign = np.sign(dfdx_initial)\n\n        for _ in range(N):\n            dfdx_k = 3 * xk**2 + lam\n            if abs(dfdx_k) < 1e-14:\n                return True # Stall at fold due to singular predictor\n\n            # Predictor step\n            x_pred = xk - (1.0 / dfdx_k) * h_mu\n            mu_new = muk + h_mu\n\n            # Corrector step\n            x_new = newton1d(lam, mu_new, x_pred)\n            \n            if x_new is None:\n                return True # Stall if Newton fails to converge\n\n            # Check for stall condition: sign change of derivative\n            dfdx_new = 3 * x_new**2 + lam\n            new_sign = np.sign(dfdx_new)\n\n            if new_sign != initial_sign:\n                return True # Stall if branch stability changes\n\n            # Update for next step\n            xk, muk = x_new, mu_new\n            \n        return False # No stall detected after N steps\n\n    def pseudo_arclength_continuation(lam, x0, mu0, h, N):\n        \"\"\"\n        Implements pseudo-arclength continuation.\n        Returns True if it successfully crosses the fold according to the\n        problem's success criteria, False otherwise.\n        \"\"\"\n        xk, muk = x0, mu0\n        mu_visited = [mu0]\n        prev_t = None\n\n        for i in range(N):\n            # Compute and orient tangent vector\n            dfdx_k = 3 * xk**2 + lam\n            t = np.array([-1.0, dfdx_k])\n            norm = np.linalg.norm(t)\n            # If norm is zero, we are at a point where the tangent is undefined.\n            if norm < 1e-14: return False \n            t = t / norm\n            \n            if i == 0:\n                # At initial step, enforce t_mu > 0 as per problem spec\n                if t[1] < 0.0:\n                    t = -t\n            else:\n                # Align with previous tangent to ensure consistent direction\n                if np.dot(t, prev_t) < 0.0:\n                    t = -t\n            prev_t = t\n            tx, tmu = t[0], t[1]\n\n            # Predictor step\n            v_pred = np.array([xk, muk]) + h * t\n\n            # Corrector step\n            v_new = newton2d(v_pred, lam, xk, muk, tx, tmu, h)\n            \n            # All correctors must converge for a successful run\n            if v_new is None:\n                return False\n\n            # Update for next step\n            xk, muk = v_new[0], v_new[1]\n            mu_visited.append(muk)\n        \n        # Check success condition for lambda < 0\n        if lam < 0:\n            mu_fold_pos = 2.0 * ((-lam / 3.0)**1.5)\n            # The maximum attained mu must strictly exceed the theoretical positive fold\n            if max(mu_visited) > (mu_fold_pos + 1e-3):\n                return True\n        \n        return False\n\n    # --- Test Suite Execution ---\n    \n    test_cases = [\n        {'id': 1, 'type': 'single', 'lambda': -1.0, 'x0': 0.0, 'mu0': 0.0, 'h': 0.05, 'N': 20},\n        {'id': 2, 'type': 'arclength', 'lambda': -1.0, 'x0': 0.0, 'mu0': 0.0, 'h': 0.1, 'N': 20},\n        {'id': 3, 'type': 'single', 'lambda': 0.5, 'x0': 0.0, 'mu0': 0.0, 'h': 0.05, 'N': 20},\n        {'id': 4, 'type': 'arclength', 'lambda': -0.1, 'x0': 0.0, 'mu0': 0.0, 'h': 0.05, 'N': 40},\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'single':\n            result = single_parameter_continuation(\n                lam=case['lambda'], x0=case['x0'], mu0=case['mu0'], h_mu=case['h'], N=case['N']\n            )\n        elif case['type'] == 'arclength':\n            result = pseudo_arclength_continuation(\n                lam=case['lambda'], x0=case['x0'], mu0=case['mu0'], h=case['h'], N=case['N']\n            )\n        results.append(result)\n\n    # Format and print the final output as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Applying continuation methods to discretized Partial Differential Equations (PDEs) is a powerful tool for exploring complex physical phenomena. This advanced practice elevates the technique by combining path-following with stability analysis for the Bratu reaction-diffusion model . Beyond implementing a complete and robust pseudo-arclength continuation loop, you will compute the eigenvalues of the system's Jacobian matrix at each converged step, allowing you to determine the linear stability of the steady-state solutions and understand how stability changes at turning points.",
            "id": "3373917",
            "problem": "Consider the steady-state boundary value problem arising from the one-dimensional Bratu model of a reaction-diffusion Partial Differential Equation (PDE) with Dirichlet boundary conditions on the unit interval. Starting from the time-dependent reaction-diffusion PDE $u_t = u_{xx} + \\lambda e^{u}$ on $x \\in (0,1)$ with $u(0,t) = 0$ and $u(1,t) = 0$, steady states satisfy the boundary value problem\n$$\nu_{xx} + \\lambda e^{u} = 0,\\quad x \\in (0,1),\\quad u(0) = 0,\\quad u(1) = 0,\n$$\nwhere $\\lambda$ is a real parameter. It is known from classical analysis that there is a fold (saddle-node) in the solution set, and solutions exist only for $\\lambda$ in an interval $\\lambda \\in (0,\\lambda_{\\mathrm{cr}})$ with $\\lambda_{\\mathrm{cr}} \\in \\mathbb{R}^{+}$. Your task is to design and implement a numerical continuation algorithm with pseudo-arclength to track solution branches of the discretized steady PDE and to assess linear stability along the branch via eigenvalues of the linearized operator.\n\nYou must proceed from the following foundational bases without using any shortcut formulas:\n\n- Finite difference discretization of the second derivative with a three-point stencil.\n- Newton’s method (Newton–Kantorovich iteration) for solving nonlinear algebraic systems.\n- Pseudo-arclength continuation that augments the steady-state residual with an arclength condition to cross folds.\n- Spectral stability determined by the sign of the rightmost (largest real part) eigenvalue of the Jacobian of the steady-state residual, which coincides with the linearization of the time-dependent PDE about the steady state in this setting.\n\nDiscretize the interval $[0,1]$ into $N$ interior grid points with uniform spacing $h = \\frac{1}{N+1}$ and enforce the Dirichlet boundary conditions $u(0)=0$ and $u(1)=0$. Let $u \\in \\mathbb{R}^{N}$ denote the vector of interior unknowns. The finite difference discretization of the steady-state residual is\n$$\nR(u,\\lambda) \\equiv \\frac{1}{h^2}Tu + \\lambda \\exp(u) = 0,\n$$\nwhere $T \\in \\mathbb{R}^{N\\times N}$ is the standard tridiagonal matrix with $-2$ on the main diagonal and $1$ on the sub- and super-diagonals, and $\\exp(u)$ applies the exponential function componentwise. The Jacobian with respect to $u$ equals\n$$\nJ(u,\\lambda) = \\frac{1}{h^2}T + \\lambda \\operatorname{diag}(\\exp(u)).\n$$\nThe derivative of $R$ with respect to $\\lambda$ equals $R_{\\lambda}(u,\\lambda) = \\exp(u) \\in \\mathbb{R}^{N}$.\n\nImplement a pseudo-arclength continuation scheme based on the following principles:\n\n- Start from a converged steady state computed by Newton’s method at an initial parameter value $\\lambda_{0} \\in \\mathbb{R}^{+}$ with initial guess $u^{(0)} = 0$.\n- At a generic continuation point $(u,\\lambda)$, compute a tangent direction $(\\tau_{u},\\tau_{\\lambda}) \\in \\mathbb{R}^{N}\\times\\mathbb{R}$ as the solution of the bordered linear system\n$$\n\\begin{bmatrix}\nJ(u,\\lambda) & R_{\\lambda}(u,\\lambda) \\\\\nR_{\\lambda}(u,\\lambda)^{\\top} & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\tau_{u}\\\\\n\\tau_{\\lambda}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0\\\\\n1\n\\end{bmatrix},\n$$\nthen normalize to unit arclength by dividing by $\\sqrt{\\|\\tau_{u}\\|_{2}^{2} + \\tau_{\\lambda}^{2}}$.\n- Form a predictor $(u^{\\mathrm{pred}},\\lambda^{\\mathrm{pred}}) = (u,\\lambda) + \\Delta s\\,(\\tau_{u},\\tau_{\\lambda})$ for a given arclength step size $\\Delta s > 0$.\n- Apply Newton’s method to the augmented residual\n$$\n\\mathcal{F}(u,\\lambda) \\equiv \\begin{bmatrix}\nR(u,\\lambda) \\\\\nc(u,\\lambda)\n\\end{bmatrix} = 0,\n\\quad\nc(u,\\lambda) \\equiv \\tau_{u}^{\\top}(u - u^{\\mathrm{ref}}) + \\tau_{\\lambda}(\\lambda - \\lambda^{\\mathrm{ref}}) - \\Delta s,\n$$\nwith $(u^{\\mathrm{ref}},\\lambda^{\\mathrm{ref}})$ taken as the last accepted continuation point (the base point for the arclength constraint). In each Newton iteration for the corrector, solve the bordered linear system\n$$\n\\begin{bmatrix}\nJ(u,\\lambda) & R_{\\lambda}(u,\\lambda) \\\\\n\\tau_{u}^{\\top} & \\tau_{\\lambda}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\delta u\\\\\n\\delta\\lambda\n\\end{bmatrix}\n= - \\begin{bmatrix}\nR(u,\\lambda)\\\\\nc(u,\\lambda)\n\\end{bmatrix},\n$$\nand update $(u,\\lambda) \\leftarrow (u,\\lambda) + (\\delta u,\\delta\\lambda)$ until convergence.\n\nAt each converged continuation point, assess linear stability of the steady state for the time-dependent PDE $u_t = u_{xx} + \\lambda e^{u}$ by computing the rightmost eigenvalue of the symmetric matrix $J(u,\\lambda)$; denote it by $\\alpha_{\\max}(u,\\lambda) \\in \\mathbb{R}$. A steady state is linearly asymptotically stable if and only if $\\alpha_{\\max}(u,\\lambda) < 0$.\n\nDefine the estimated critical parameter $\\widehat{\\lambda}_{\\mathrm{cr}}$ for a given run as the maximum value of $\\lambda$ attained along the computed continuation path, i.e.,\n$$\n\\widehat{\\lambda}_{\\mathrm{cr}} \\equiv \\max\\{\\lambda^{(k)}: k=0,1,2,\\dots,K\\},\n$$\nwhere $(u^{(k)},\\lambda^{(k)})$ are the converged continuation points produced by your algorithm. This quantity approximates the turning point of the solution branch.\n\nYour program must implement the above method and run it for each parameter triplet $(N,\\Delta s,K)$ in the following test suite:\n\n- Test $1$: $(N,\\Delta s,K) = (60,\\,0.12,\\,60)$.\n- Test $2$: $(N,\\Delta s,K) = (40,\\,0.10,\\,60)$.\n- Test $3$: $(N,\\Delta s,K) = (80,\\,0.15,\\,45)$.\n\nFor each test, use the initial parameter $\\lambda_{0} = 1.0$ (unitless) and the initial Newton guess $u^{(0)} = 0 \\in \\mathbb{R}^{N}$. Use absolute tolerances for Newton solves no larger than $10^{-8}$ on the residual norms and arclength constraint; when needed, you may employ simple backtracking or reduce $\\Delta s$ locally to achieve convergence, but the nominal $\\Delta s$ used to compute the arclength constraint must match the test input.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each entry must be the floating-point value of $\\widehat{\\lambda}_{\\mathrm{cr}}$ for the corresponding test in the same order as listed above. There are no physical units in this problem. Angles do not appear. Percentages do not appear. The final output format must be exactly of the form\n$[v_{1},v_{2},v_{3}]$,\nwhere each $v_{i}$ is a real number printed in standard decimal notation.",
            "solution": "The core of the solution is a direct implementation of the specified pseudo-arclength continuation method. The process can be broken down into the following steps, which will be encapsulated in a function to be run for each test case.\n\n**Step 1: Initial Point Calculation**\nThe continuation starts from a known solution. The problem specifies starting at $\\lambda_0 = 1.0$. However, the trivial solution $u=0$ is only a solution for $\\lambda=0$. Therefore, we must first find the non-trivial solution corresponding to $\\lambda_0 = 1.0$. This is achieved by solving the nonlinear system $R(u, \\lambda_0) = 0$ using a standard Newton's method, starting with the initial guess $u=0$.\nThe Newton iteration is:\n$u_{k+1} = u_k - J(u_k, \\lambda_0)^{-1} R(u_k, \\lambda_0)$, where the update is found by solving the linear system $J(u_k, \\lambda_0) \\delta u = -R(u_k, \\lambda_0)$. This iteration continues until $\\|R\\| < 10^{-8}$.\n\n**Step 2: Continuation Loop**\nStarting from the initial converged point $(u^{(0)}, \\lambda^{(0)})$, we generate a sequence of $K$ points $(u^{(k)}, \\lambda^{(k)})$ along the solution branch. Each step of the loop consists of a predictor and a corrector phase. Let the current accepted point be $(u, \\lambda)$.\n\n**Step 2a: Tangent Vector Calculation**\nTo determine the direction of the next step along the solution curve, we compute a tangent vector $(\\tau_u, \\tau_\\lambda)$. This is done by solving the bordered linear system as prescribed:\n$$\n\\begin{bmatrix}\nJ(u,\\lambda) & R_{\\lambda}(u,\\lambda) \\\\\nR_{\\lambda}(u,\\lambda)^{\\top} & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\tau_{u}\\\\\n\\tau_{\\lambda}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0\\\\\n1\n\\end{bmatrix}\n$$\nThis system is well-posed even at the turning point. After solving, the tangent vector is normalized to unit length: $(\\tau_u, \\tau_\\lambda) \\leftarrow (\\tau_u, \\tau_\\lambda) / \\sqrt{\\|\\tau_u\\|_2^2 + \\tau_\\lambda^2}$. To ensure a consistent traversal direction along the curve, the orientation of the tangent is managed. For the first step, we enforce $\\tau_\\lambda > 0$ to move towards increasing $\\lambda$. For subsequent steps, we ensure the dot product of the current tangent with the previous tangent is positive.\n\n**Step 2b: Predictor**\nA new point is predicted by taking a step of size $\\Delta s$ along the tangent direction from the current point $(u, \\lambda)$:\n$$\n(u^{\\mathrm{pred}}, \\lambda^{\\mathrm{pred}}) = (u, \\lambda) + \\Delta s (\\tau_u, \\tau_\\lambda)\n$$\nThis predicted point serves as the initial guess for the corrector step.\n\n**Step 2c: Corrector**\nThe predicted point is an approximation and does not lie exactly on the solution curve. Newton's method is used to correct it. The corrector solves the augmented system of $N+1$ equations for $N+1$ unknowns $(u, \\lambda)$:\n$$\n\\mathcal{F}(u,\\lambda) \\equiv \\begin{bmatrix}\nR(u,\\lambda) \\\\\nc(u,\\lambda)\n\\end{bmatrix} = 0\n$$\nwhere $c(u, \\lambda) = \\tau_{u}^{\\top}(u - u^{\\mathrm{ref}}) + \\tau_{\\lambda}(\\lambda - \\lambda^{\\mathrm{ref}}) - \\Delta s = 0$ is the arclength constraint. This constraint forces the corrected point to lie on a hyperplane orthogonal to the tangent vector, at a distance $\\Delta s$ from the reference point $(u^{\\mathrm{ref}}, \\lambda^{\\mathrm{ref}})$. The Newton update $(\\delta u, \\delta \\lambda)$ at each corrector iteration is found by solving the linear system:\n$$\n\\begin{bmatrix}\nJ(u,\\lambda) & R_{\\lambda}(u,\\lambda) \\\\\n\\tau_{u}^{\\top} & \\tau_{\\lambda}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\delta u\\\\\n\\delta\\lambda\n\\end{bmatrix}\n= - \\begin{bmatrix}\nR(u,\\lambda)\\\\\nc(u,\\lambda)\n\\end{bmatrix}\n$$\nThe iteration $(u, \\lambda) \\leftarrow (u, \\lambda) + (\\delta u, \\delta\\lambda)$ continues until $\\|R\\| < 10^{-8}$ and $|c| < 10^{-8}$.\n\n**Step 3: Calculating the Output**\nAfter completing $K$ continuation steps, we will have a sequence of converged parameter values $\\lambda^{(0)}, \\lambda^{(1)}, \\dots, \\lambda^{(K)}$. The estimated critical parameter, $\\widehat{\\lambda}_{\\mathrm{cr}}$, is the maximum value in this sequence. This procedure is repeated for each of the three test cases. The final output is a list of these maximum values.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Bratu problem using pseudo-arclength continuation for the given test cases.\n    \"\"\"\n\n    # --- Configuration and Helper Function Definition ---\n\n    NEWTON_TOL = 1e-8\n    MAX_NEWTON_ITER = 30\n    LAMBDA0 = 1.0\n\n    def solve_continuation_case(N, ds, K):\n        \"\"\"\n        Performs a full continuation run for a given parameter set (N, ds, K).\n\n        Args:\n            N (int): Number of interior grid points.\n            ds (float): Arclength step size.\n            K (int): Number of continuation steps.\n\n        Returns:\n            float: The estimated critical lambda value (max lambda found).\n        \"\"\"\n        # --- Discretization Setup ---\n        h = 1.0 / (N + 1)\n        T = np.diag(np.ones(N - 1), 1) + np.diag(np.ones(N - 1), -1) - 2 * np.diag(np.ones(N))\n        T_h2 = T / h**2\n\n        # --- Step 1: Find the initial solution at LAMBDA0 using Newton's method ---\n        u = np.zeros(N)\n        lam = LAMBDA0\n        \n        for _ in range(MAX_NEWTON_ITER):\n            R = T_h2 @ u + lam * np.exp(u)\n            if np.linalg.norm(R) < NEWTON_TOL:\n                break\n            # Jacobian of R w.r.t. u\n            J = T_h2 + lam * np.diag(np.exp(u))\n            delta_u = np.linalg.solve(J, -R)\n            u += delta_u\n        else:\n            raise RuntimeError(f\"Initial Newton solve failed to converge for (N={N}, ds={ds}, K={K}).\")\n\n        u_current = u\n        lam_current = lam\n        all_lams = [lam_current]\n        \n        # --- Variables for tangent direction control ---\n        tau_u_prev = np.zeros_like(u)\n        tau_lam_prev = 0.0\n\n        # --- Step 2: Main Continuation Loop ---\n        for k in range(K):\n            u_ref, lam_ref = u_current, lam_current\n            \n            # --- a) Tangent Computation ---\n            J = T_h2 + lam_ref * np.diag(np.exp(u_ref))\n            R_lam = np.exp(u_ref)\n\n            # Assemble and solve the bordered system for the tangent\n            A_tan = np.zeros((N + 1, N + 1))\n            A_tan[:N, :N] = J\n            A_tan[:N, N] = R_lam\n            A_tan[N, :N] = R_lam\n            \n            b_tan = np.zeros(N + 1)\n            b_tan[N] = 1.0\n            \n            sol = np.linalg.solve(A_tan, b_tan)\n            tau_u, tau_lam = sol[:-1], sol[-1]\n\n            # --- Tangent Direction Control ---\n            if k == 0:\n                # On the first step, ensure lambda increases\n                if tau_lam < 0:\n                    tau_u, tau_lam = -tau_u, -tau_lam\n            else:\n                # For subsequent steps, maintain direction relative to the previous step\n                if np.dot(tau_u, tau_u_prev) + tau_lam * tau_lam_prev < 0:\n                    tau_u, tau_lam = -tau_u, -tau_lam\n            \n            # Normalize tangent and store for the next step's orientation control\n            norm_tau = np.sqrt(np.dot(tau_u, tau_u) + tau_lam**2)\n            tau_u /= norm_tau\n            tau_lam /= norm_tau\n            tau_u_prev, tau_lam_prev = tau_u, tau_lam\n\n            # --- b) Predictor Step ---\n            u_new = u_ref + ds * tau_u\n            lam_new = lam_ref + ds * tau_lam\n            \n            # --- c) Corrector Step (Augmented Newton's Method) ---\n            for _ in range(MAX_NEWTON_ITER):\n                # Calculate augmented residual\n                R = T_h2 @ u_new + lam_new * np.exp(u_new)\n                c = np.dot(tau_u, u_new - u_ref) + tau_lam * (lam_new - lam_ref) - ds\n                \n                # Check for convergence\n                if np.linalg.norm(R) < NEWTON_TOL and abs(c) < NEWTON_TOL:\n                    break\n                \n                # Assemble augmented Jacobian and RHS for the correction\n                J_new = T_h2 + lam_new * np.diag(np.exp(u_new))\n                R_lam_new = np.exp(u_new)\n                \n                A_corr = np.zeros((N + 1, N + 1))\n                A_corr[:N, :N] = J_new\n                A_corr[:N, N] = R_lam_new\n                A_corr[N, :N] = tau_u\n                A_corr[N, N] = tau_lam\n                \n                b_corr = -np.concatenate((R, [c]))\n                \n                # Solve for the update and apply it\n                try:\n                    delta = np.linalg.solve(A_corr, b_corr)\n                except np.linalg.LinAlgError:\n                    raise RuntimeError(f\"Corrector system is singular at step {k+1} for (N={N}).\")\n                \n                u_new += delta[:-1]\n                lam_new += delta[-1]\n            else:\n                raise RuntimeError(f\"Corrector Newton failed to converge at step {k+1} for (N={N}).\")\n            \n            # Update current point and record lambda\n            u_current, lam_current = u_new, lam_new\n            all_lams.append(lam_current)\n            \n        return max(all_lams)\n\n    # --- Main Execution ---\n    test_cases = [\n        (60, 0.12, 60),  # Test 1\n        (40, 0.10, 60),  # Test 2\n        (80, 0.15, 45),  # Test 3\n    ]\n\n    results = []\n    for case in test_cases:\n        N, ds, K = case\n        lambda_cr_est = solve_continuation_case(N, ds, K)\n        results.append(lambda_cr_est)\n    \n    # Print the final result in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}