{
    "hands_on_practices": [
        {
            "introduction": "要掌握皮卡和牛顿-拉夫逊方法，第一步是理解它们在将非线性问题转化为线性问题时的根本区别。皮卡迭代通过“冻结”非线性系数来简化问题，通常会得到一个对称正定（SPD）的线性系统，而牛顿-拉夫逊方法则使用真实的雅可比矩阵，这能带来更快的收敛速度，但代价是矩阵可能更复杂且非对称。本练习  将指导你对一个非线性偏微分方程实现这两种方法的核心步骤，通过直接比较生成的矩阵的性质（如对称性、条件数），你将深入理解它们在代数结构和数值稳定性上的权衡。",
            "id": "3431358",
            "problem": "考虑单位区间上的一个非线性标量守恒型偏微分方程 (PDE)，其带有齐次狄利克雷边界条件，\n$$\n-\\frac{d}{dx}\\left(\\left(1+u(x)^2\\right)\\frac{du}{dx}(x)\\right) = f(x), \\quad x \\in (0,1), \\quad u(0) = 0, \\quad u(1) = 0.\n$$\n您将构建一个包含 $n$ 个内部节点的一维均匀网格，网格间距为 $h = \\frac{1}{n+1}$，节点位置为 $x_i = i h$，其中 $i = 1,2,\\dots,n$。使用基于通量的中心差分推导出的守恒有限差分格式。具体来说：\n- 定义系数函数 $a(u) = 1 + u^2$。\n- 通过节点中心值的算术平均来近似边中心的系数 $x_{i+\\frac{1}{2}}$，\n$$\na_{i+\\frac{1}{2}} \\approx 1 + \\frac{1}{2}\\left(u_i^2 + u_{i+1}^2\\right),\n$$\n其中 $u_i \\approx u(x_i)$，边界值 $u_0 = u(0)$ 和 $u_{n+1} = u(1)$ 固定为零。\n- 通过 $q_{i+\\frac{1}{2}} \\approx a_{i+\\frac{1}{2}} \\frac{u_{i+1} - u_i}{h}$ 来近似边上的通量，并通过边差分 $\\frac{q_{i+\\frac{1}{2}} - q_{i-\\frac{1}{2}}}{h}$ 来近似其散度。\n\n从给定的迭代步 $u^{(k)}$ 开始，实现：\n1. 一个皮卡 (Picard)（不动点）线性化步骤：将系数固定在当前迭代步，并形成与下式对应的线性系统\n$$\n-\\frac{1}{h}\\left(a_{i+\\frac{1}{2}}^{(k)} \\frac{u_{i+1}^{(k+1)} - u_i^{(k+1)}}{h} - a_{i-\\frac{1}{2}}^{(k)} \\frac{u_i^{(k+1)} - u_{i-1}^{(k+1)}}{h}\\right) = f_i, \\quad i = 1,\\dots,n,\n$$\n其中 $u_0^{(k+1)} = 0$ 且 $u_{n+1}^{(k+1)} = 0$。组装相应的矩阵 $A_{\\mathrm{Pic}}(u^{(k)})$ 和右端向量 $\\mathbf{f}$。\n2. 一个牛顿-拉夫逊 (Newton-Raphson) 步骤：从守恒离散化中推导出离散残差向量 $\\mathbf{R}(u)$，并通过对内部节点值求导残差来形成雅可比矩阵 $J(u^{(k)})$。求解\n$$\nJ(u^{(k)}) \\, \\delta^{(k)} = -\\mathbf{R}(u^{(k)}),\n$$\n并在内部节点上更新 $u^{(k+1)} = u^{(k)} + \\delta^{(k)}$（边界值保持不变，不属于未知向量的一部分）。\n\n您的程序必须：\n- 对于每个指定的测试用例，使用上述方案组装皮卡矩阵 $A_{\\mathrm{Pic}}(u^{(k)})$ 和牛顿雅可比矩阵 $J(u^{(k)})$。\n- 计算二范数条件数 $\\kappa_2\\left(A_{\\mathrm{Pic}}(u^{(k)})\\right)$ 和 $\\kappa_2\\left(J(u^{(k)})\\right)$。\n- 计算比率 $\\rho = \\kappa_2\\left(J(u^{(k)})\\right) / \\kappa_2\\left(A_{\\mathrm{Pic}}(u^{(k)})\\right)$。\n- 通过检查对称性和其特征值来验证 $A_{\\mathrm{Pic}}(u^{(k)})$ 是否为对称正定 (Symmetric Positive Definite, SPD)。\n- 在相对弗罗贝尼乌斯范数容差内检查 $J(u^{(k)})$ 是否对称。\n\n使用以下参数值测试套件，其中 $n$ 是内部节点的数量，初始迭代为 $u_i^{(k)} = \\alpha \\sin(\\pi x_i)$，强迫项采样为 $f_i = f(x_i)$：\n- 测试用例 1 (理想情况，线性基准): $n = 8$, $\\alpha = 0$, $f(x) = \\sin(\\pi x)$。\n- 测试用例 2 (中等非线性): $n = 32$, $\\alpha = 0.5$, $f(x) = \\sin(\\pi x)$。\n- 测试用例 3 (强非线性和混合强迫项): $n = 64$, $\\alpha = 2.0$, $f(x) = 1 + \\sin(2\\pi x)$。\n\n三角函数中的角度必须以弧度解释。不涉及物理单位。\n\n最终输出格式：\n- 对每个测试用例，按顺序生成五个值：$\\kappa_2\\left(A_{\\mathrm{Pic}}\\right)$ (浮点数)，$\\kappa_2\\left(J\\right)$ (浮点数)，$\\rho$ (浮点数)，$\\mathrm{SPD}(A_{\\mathrm{Pic}})$ (布尔值)，和 $\\mathrm{Sym}(J)$ (布尔值)。\n- 将所有浮点数输出四舍五入到六位小数。\n- 将所有测试用例的结果聚合到单行打印，格式为用方括号括起来的逗号分隔列表，跨测试用例展平，例如：\n$$\n[\\text{condP}_1,\\text{condN}_1,\\text{ratio}_1,\\text{SPD}_1,\\text{Sym}_1,\\text{condP}_2,\\dots,\\text{Sym}_3].\n$$\n您的程序必须是一个完整的、可运行的实现，它执行上述步骤并打印所需的单行。",
            "solution": "用户提供的问题已经过分析并被确定为 **有效**。这是一个适定、有科学依据的数值分析问题，内容自洽，没有矛盾或歧义。\n\n### 离散系统分析\n\n非线性偏微分方程 (PDE) 以守恒形式给出：\n$$\n-\\frac{d}{dx}\\left(\\left(1+u(x)^2\\right)\\frac{du}{dx}(x)\\right) = f(x), \\quad x \\in (0,1)\n$$\n带有齐次狄利克雷边界条件 $u(0) = 0$ 和 $u(1) = 0$。\n问题指定了在均匀网格上进行有限差分离散化，该网格有 $n$ 个内部节点 $x_i = ih$（$i=1, \\dots, n$），网格间距为 $h=1/(n+1)$。通量及其散度近似如下：\n$$\nq_{i+\\frac{1}{2}} \\approx a_{i+\\frac{1}{2}} \\frac{u_{i+1} - u_i}{h}, \\quad \\text{其中} \\quad a_{i+\\frac{1}{2}} = 1 + \\frac{1}{2}\\left(u_i^2 + u_{i+1}^2\\right)\n$$\n$$\n-\\left.\\frac{dq}{dx}\\right|_{x_i} \\approx -\\frac{q_{i+\\frac{1}{2}} - q_{i-\\frac{1}{2}}}{h}\n$$\n其中 $u_i \\approx u(x_i)$。边界值为 $u_0 = 0$ 和 $u_{n+1}=0$。\n将通量近似代入散度近似，得到每个内部节点 $i$ 的离散方程：\n$$\n-\\frac{1}{h^2}\\left[ a_{i+\\frac{1}{2}}(u_{i+1} - u_i) - a_{i-\\frac{1}{2}}(u_i - u_{i-1}) \\right] = f_i\n$$\n我们为未知量向量 $\\mathbf{u} = [u_1, u_2, \\dots, u_n]^T$ 定义离散残差向量 $\\mathbf{R}(\\mathbf{u})$。残差的第 $i$ 个分量是：\n$$\nR_i(\\mathbf{u}) = -\\frac{1}{h^2}\\left[ \\left(1 + \\frac{u_i^2+u_{i+1}^2}{2}\\right)(u_{i+1} - u_i) - \\left(1 + \\frac{u_{i-1}^2+u_i^2}{2}\\right)(u_i - u_{i-1}) \\right] - f_i\n$$\n问题是求解 $\\mathbf{u}$ 使得 $\\mathbf{R}(\\mathbf{u}) = \\mathbf{0}$。我们现在将推导皮卡 (Picard) 和牛顿-拉夫逊 (Newton-Raphson) 方法一步迭代所需的矩阵。\n\n### 1. 皮卡 (Picard) 线性化\n\n皮卡（或不动点）方法通过在上一迭代步 $\\mathbf{u}^{(k)}$ 处计算非线性系数函数 $a(u)$ 来线性化问题。新迭代步 $\\mathbf{u}^{(k+1)}$ 的系统为：\n$$\n-\\frac{1}{h^2}\\left[ a_{i+\\frac{1}{2}}^{(k)}(u_{i+1}^{(k+1)} - u_i^{(k+1)}) - a_{i-\\frac{1}{2}}^{(k)}(u_i^{(k+1)} - u_{i-1}^{(k+1)}) \\right] = f_i\n$$\n其中 $a_{i+\\frac{1}{2}}^{(k)} = 1 + \\frac{1}{2}\\left((u_i^{(k)})^2 + (u_{i+1}^{(k)})^2\\right)$。此方程可以写成线性系统 $A_{\\mathrm{Pic}}(\\mathbf{u}^{(k)}) \\mathbf{u}^{(k+1)} = \\mathbf{f}$。通过重新排列各项，我们可以确定矩阵 $A_{\\mathrm{Pic}}(\\mathbf{u}^{(k)})$ 的元素。对于第 $i$ 行，它对应于 $u_i^{(k+1)}$ 的方程，我们有：\n$$\n\\frac{1}{h^2}\\left[ -a_{i-\\frac{1}{2}}^{(k)}u_{i-1}^{(k+1)} + \\left(a_{i+\\frac{1}{2}}^{(k)} + a_{i-\\frac{1}{2}}^{(k)}\\right)u_i^{(k+1)} - a_{i+\\frac{1}{2}}^{(k)}u_{i+1}^{(k+1)} \\right] = f_i\n$$\n因此，矩阵 $A_{\\mathrm{Pic}}(\\mathbf{u}^{(k)})$ 是一个 $n \\times n$ 的三对角矩阵，其元素如下：\n- 对角线：$(A_{\\mathrm{Pic}})_{i,i} = \\frac{1}{h^2} \\left(a_{i+\\frac{1}{2}}^{(k)} + a_{i-\\frac{1}{2}}^{(k)}\\right)$\n- 次对角线：$(A_{\\mathrm{Pic}})_{i,i-1} = -\\frac{1}{h^2} a_{i-\\frac{1}{2}}^{(k)}$\n- 超对角线：$(A_{\\mathrm{Pic}})_{i,i+1} = -\\frac{1}{h^2} a_{i+\\frac{1}{2}}^{(k)}$\n\n矩阵 $A_{\\mathrm{Pic}}$ 是对称的，因为 $(A_{\\mathrm{Pic}})_{i,i+1} = -\\frac{1}{h^2} a_{i+\\frac{1}{2}}^{(k)} = (A_{\\mathrm{Pic}})_{i+1,i}$。由于 $a(u) = 1+u^2 \\geq 1$，所有系数 $a_{i\\pm 1/2}^{(k)}$ 都是正的。该矩阵也是对角占优且不可约的，这保证了其正定性。因此，$A_{\\mathrm{Pic}}$ 是对称正定 (Symmetric Positive Definite, SPD) 的。\n\n### 2. 牛顿-拉夫逊 (Newton-Raphson) 方法\n\n牛顿-拉夫逊方法通过迭代求解线性系统 $J(\\mathbf{u}^{(k)})\\delta^{(k)} = -\\mathbf{R}(\\mathbf{u}^{(k)})$ 得到校正量 $\\delta^{(k)}$，并更新 $\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + \\delta^{(k)}$，从而求解 $\\mathbf{R}(\\mathbf{u}) = \\mathbf{0}$。矩阵 $J$ 是残差向量 $\\mathbf{R}$ 的雅可比矩阵，其元素为 $J_{ij} = \\frac{\\partial R_i}{\\partial u_j}$。由于 $R_i$ 仅依赖于 $u_{i-1}$、$u_i$ 和 $u_{i+1}$，雅可比矩阵也是一个三对角矩阵。\n我们计算 $R_i(\\mathbf{u})$ 的偏导数（为清晰起见，省略上标 $(k)$）：\n\n- **主对角线, $J_{i,i} = \\frac{\\partial R_i}{\\partial u_i}$:**\n$$\nJ_{i,i} = \\frac{\\partial}{\\partial u_i} \\left( -\\frac{1}{h^2}\\left[ a_{i+\\frac{1}{2}}(u_{i+1} - u_i) - a_{i-\\frac{1}{2}}(u_i - u_{i-1}) \\right] \\right)\n$$\n使用乘法法则和 $\\frac{\\partial a_{i\\pm 1/2}}{\\partial u_i} = u_i$：\n$$\nJ_{i,i} = -\\frac{1}{h^2} \\left[ (u_i(u_{i+1}-u_i) - a_{i+\\frac{1}{2}}) - (u_i(u_i-u_{i-1}) + a_{i-\\frac{1}{2}}) \\right]\n$$\n$$\nJ_{i,i} = \\frac{1}{h^2} \\left[ a_{i+\\frac{1}{2}} + a_{i-\\frac{1}{2}} - u_i(u_{i+1} - 2u_i + u_{i-1}) \\right]\n$$\n\n- **超对角线, $J_{i,i+1} = \\frac{\\partial R_i}{\\partial u_{i+1}}$:**\n$$\nJ_{i,i+1} = \\frac{\\partial}{\\partial u_{i+1}} \\left( -\\frac{1}{h^2} a_{i+\\frac{1}{2}}(u_{i+1} - u_i) \\right)\n$$\n使用乘法法则和 $\\frac{\\partial a_{i+1/2}}{\\partial u_{i+1}} = u_{i+1}$：\n$$\nJ_{i,i+1} = -\\frac{1}{h^2} \\left[ u_{i+1}(u_{i+1}-u_i) + a_{i+\\frac{1}{2}}(1) \\right] = -\\frac{1}{h^2} \\left[ a_{i+\\frac{1}{2}} + u_{i+1}(u_{i+1}-u_i) \\right]\n$$\n\n- **次对角线, $J_{i,i-1} = \\frac{\\partial R_i}{\\partial u_{i-1}}$:**\n$$\nJ_{i,i-1} = \\frac{\\partial}{\\partial u_{i-1}} \\left( \\frac{1}{h^2} a_{i-\\frac{1}{2}}(u_i - u_{i-1}) \\right)\n$$\n使用乘法法则和 $\\frac{\\partial a_{i-1/2}}{\\partial u_{i-1}} = u_{i-1}$：\n$$\nJ_{i,i-1} = \\frac{1}{h^2} \\left[ u_{i-1}(u_i-u_{i-1}) + a_{i-\\frac{1}{2}}(-1) \\right] = \\frac{1}{h^2} \\left[ u_{i-1}(u_i-u_{i-1}) - a_{i-\\frac{1}{2}} \\right]\n$$\n\n雅可比矩阵 $J$ 通常是不对称的。为了检查对称性，我们比较 $J_{i,i+1}$ 和 $J_{i+1,i}$。根据次对角线公式，将索引替换为 $i+1$：\n$$\nJ_{i+1,i} = \\frac{1}{h^2} \\left[ u_i(u_{i+1}-u_i) - a_{i+\\frac{1}{2}} \\right]\n$$\n将此与 $J_{i,i+1}$ 比较，我们发现 $J_{i,i+1} \\neq J_{i+1,i}$，除非 $\\mathbf{u}=\\mathbf{0}$，在这种情况下问题是线性的，且 $J=A_{\\mathrm{Pic}}$。\n\n### 计算总结\n\n对于每个测试用例，我们将：\n1.  基于初始迭代步 $\\mathbf{u}^{(k)}$ 构建 $n \\times n$ 矩阵 $A_{\\mathrm{Pic}}$。\n2.  基于 $\\mathbf{u}^{(k)}$ 构建 $n \\times n$ 矩阵 $J$。\n3.  计算 2-范数条件数 $\\kappa_2(A_{\\mathrm{Pic}})$ 和 $\\kappa_2(J)$。\n4.  计算比率 $\\rho = \\kappa_2(J) / \\kappa_2(A_{\\mathrm{Pic}})$。\n5.  通过检查对称性和所有特征值是否为正来验证 $A_{\\mathrm{Pic}}$ 是否为对称正定 (SPD)。\n6.  通过检查 $J$ 是否接近其转置 $J^T$ 来验证 $J$ 是否对称。\n\n实现将遵循这些步骤来生成所需的输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases, assembling Picard and Newton\n    matrices, and computing their properties.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (8, 0.0, lambda x: np.sin(np.pi * x)),\n        (32, 0.5, lambda x: np.sin(np.pi * x)),\n        (64, 2.0, lambda x: 1 + np.sin(2 * np.pi * x)),\n    ]\n\n    results = []\n    \n    for n, alpha, f_func in test_cases:\n        # 1. Setup grid and initial iterate\n        h = 1.0 / (n + 1)\n        x_nodes = np.arange(1, n + 1) * h\n        u_k = alpha * np.sin(np.pi * x_nodes)\n        \n        # Create an extended u vector including boundary values u_0 = u_{n+1} = 0\n        u_ext = np.concatenate(([0.0], u_k, [0.0]))\n\n        # Pre-calculate edge-centered coefficients a_{i+1/2}\n        # a_coeffs[i] corresponds to a_{i+1/2} where i is from 0 to n\n        a_coeffs = 1.0 + 0.5 * (u_ext[:-1]**2 + u_ext[1:]**2)\n        \n        # 2. Assemble Picard Matrix A_Pic\n        # Main diagonal of A_Pic\n        diag_p = (a_coeffs[1:] + a_coeffs[:-1]) / h**2\n        # Off-diagonal of A_Pic (symmetric matrix)\n        off_diag_p = -a_coeffs[1:-1] / h**2\n        \n        A_pic = np.diag(diag_p) + np.diag(off_diag_p, k=1) + np.diag(off_diag_p, k=-1)\n\n        # 3. Assemble Newton Jacobian J\n        # Main diagonal of J\n        u_i = u_ext[1:-1]\n        u_im1 = u_ext[:-2]\n        u_ip1 = u_ext[2:]\n        term = -u_i * (u_ip1 - 2*u_i + u_im1)\n        diag_j = (a_coeffs[1:] + a_coeffs[:-1] + term) / h**2\n\n        # Super-diagonal of J\n        term_s = u_ip1 * (u_ip1-u_i)\n        super_diag_j = -(a_coeffs[1:-1] + term_s) / h**2\n\n        # Sub-diagonal of J\n        term_l = u_im1 * (u_i-u_im1)\n        sub_diag_j = -(a_coeffs[:-2] + term_l) / h**2\n        \n        # Correction in sub-diagonal from derivation J_{i,i-1} uses a_{i-1/2}.\n        # In a_coeffs, a_{i-1/2} corresponds to index i-1.\n        # So for sub_diag_j[i] (which is J_{i+1,i}), a_{i+1/2} is needed.\n        # Let's re-derive J_{i+1, i} which is what populates the sub-diagonal\n        # J_{i+1,i} = d(R_{i+1}) / d(u_i)\n        # R_{i+1} = -1/h^2 * [ a_{i+3/2}(u_{i+2}-u_{i+1}) - a_{i+1/2}(u_{i+1}-u_i) ] - f_{i+1}\n        # d(R_{i+1})/d(u_i) = -1/h^2 * [ -d(a_{i+1/2})/d(u_i)*(u_{i+1}-u_i) - a_{i+1/2}*(-1) ]\n        # d(a_{i+1/2})/d(u_i) = u_i\n        # d(R_{i+1})/d(u_i) = -1/h^2 * [ -u_i(u_{i+1}-u_i) + a_{i+1/2} ]\n        # = 1/h^2 * [ u_i(u_{i+1}-u_i) - a_{i+1/2} ]\n        u_i_sub = u_ext[1:-2]\n        u_ip1_sub = u_ext[2:-1]\n        a_coeffs_sub = a_coeffs[1:-1]\n        sub_diag_j_correct = ( u_i_sub * (u_ip1_sub - u_i_sub) - a_coeffs_sub ) / h**2\n        \n        # Re-derive super-diagonal J_{i, i+1}\n        # J_{i,i+1} = d(R_i)/d(u_{i+1})\n        # R_i = -1/h^2 * [ a_{i+1/2}(u_{i+1}-u_i) - a_{i-1/2}(u_i-u_{i-1}) ] - f_i\n        # d(R_i)/d(u_{i+1}) = -1/h^2 * [ d(a_{i+1/2})/d(u_{i+1})*(u_{i+1}-u_i) + a_{i+1/2}*1 ]\n        # d(a_{i+1/2})/d(u_{i+1}) = u_{i+1}\n        # d(R_i)/d(u_{i+1}) = -1/h^2 * [ u_{i+1}(u_{i+1}-u_i) + a_{i+1/2} ]\n        u_i_super = u_ext[1:-2]\n        u_ip1_super = u_ext[2:-1]\n        a_coeffs_super = a_coeffs[1:-1]\n        super_diag_j_correct = -(u_ip1_super * (u_ip1_super - u_i_super) + a_coeffs_super) / h**2\n        \n        J = np.diag(diag_j) + np.diag(super_diag_j_correct, k=1) + np.diag(sub_diag_j_correct, k=-1)\n        \n        # 4. Compute required values\n        cond_p = np.linalg.cond(A_pic, 2)\n        cond_j = np.linalg.cond(J, 2)\n        ratio = cond_j / cond_p\n        \n        # Check SPD for A_pic.\n        # It is symmetric by construction, so we only check positive definiteness.\n        # Use eigvalsh for symmetric matrices. Small tolerance for floating point.\n        eigvals_p = np.linalg.eigvalsh(A_pic)\n        is_spd = np.all(eigvals_p > 1e-12)\n\n        # Check symmetry for J using a standard tolerance\n        is_sym_j = np.allclose(J, J.T)\n        \n        # Append formatted results\n        results.extend([\n            f\"{cond_p:.6f}\",\n            f\"{cond_j:.6f}\",\n            f\"{ratio:.6f}\",\n            str(is_spd),\n            str(is_sym_j),\n        ])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "在实际应用中，我们常常希望结合皮卡迭代的全局收敛性和牛顿法的局部快速收敛性。一个有效的策略是构建一个混合求解器：在求解初期，当迭代点远离解时，使用稳健的皮卡方法；当迭代足够接近解时，切换到收敛速度更快的牛顿法。此练习  的核心挑战是设计一个可靠的切换准则，你将通过监控皮卡迭代的收敛因子和残差指标的稳定性，来决定切换到牛顿法的最佳时机。这项实践将使你掌握一种在科学计算中非常实用且高效的算法优化技巧。",
            "id": "3431395",
            "problem": "考虑在区间 $[0,1]$ 上设定的具有齐次狄利克雷边界条件的稳态一维非线性反应扩散边界值问题。令 $u:[0,1]\\to\\mathbb{R}$ 为未知函数。该偏微分方程 (PDE) 为\n$$\n-\\frac{d^2 u}{dx^2} + \\beta\\, u^3 = f(x), \\quad x\\in(0,1), \\quad u(0) = 0, \\quad u(1) = 0,\n$$\n其中 $\\beta0$ 是一个给定参数，$f$ 是一个给定的源项。\n\n使用标准二阶中心有限差分法，在 $N$ 个内部网格点上对 PDE 进行离散化，网格尺寸为 $h = \\frac{1}{N+1}$，网格节点为 $x_i = i h$（$i=1,\\dots,N$），并采用齐次狄利克雷边界条件 $u_0 = u_{N+1}=0$。令 $\\mathbf{u}\\in\\mathbb{R}^N$ 为节点值 $u_i \\approx u(x_i)$ 的向量，并定义离散拉普拉斯矩阵 $\\mathbf{K}\\in\\mathbb{R}^{N\\times N}$ 为\n$$\n\\mathbf{K} = \\frac{1}{h^2}\\begin{bmatrix}\n2  -1    \\\\\n-1  2  -1   \\\\\n \\ddots  \\ddots  \\ddots  \\\\\n  -1  2  -1 \\\\\n   -1  2\n\\end{bmatrix}.\n$$\n令离散残差映射 $\\mathbf{F}:\\mathbb{R}^N\\to\\mathbb{R}^N$ 为\n$$\n\\mathbf{F}(\\mathbf{u}) = \\mathbf{K}\\,\\mathbf{u} + \\beta\\, \\mathbf{u}^{\\odot 3} - \\mathbf{f},\n$$\n其中 $\\mathbf{u}^{\\odot 3}$ 表示逐元素立方，$\\mathbf{f}\\in\\mathbb{R}^N$ 是离散载荷向量 $f_i = f(x_i)$。\n\n考虑用于非线性系统 $\\mathbf{F}(\\mathbf{u})=\\mathbf{0}$ 的两种迭代求解器：\n- Picard 迭代：给定 $\\mathbf{u}^{(k)}$，构建对称正定 (SPD) 矩阵\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)}) = \\mathbf{K} + \\beta\\,\\mathrm{diag}\\!\\left(\\big(\\mathbf{u}^{(k)}\\big)^{\\odot 2}\\right),\n$$\n并将 $\\mathbf{u}^{(k+1)}$ 计算为线性系统\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{u}^{(k+1)} = \\mathbf{f}.\n$$\n的解。\n- Newton–Raphson 迭代：给定 $\\mathbf{u}^{(k)}$，构建雅可比矩阵\n$$\n\\mathbf{J}(\\mathbf{u}^{(k)}) = \\mathbf{K} + 3\\beta\\,\\mathrm{diag}\\!\\left(\\big(\\mathbf{u}^{(k)}\\big)^{\\odot 2}\\right),\n$$\n求解\n$$\n\\mathbf{J}(\\mathbf{u}^{(k)})\\, \\boldsymbol{\\delta}^{(k)} = -\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big),\n$$\n中的更新量 $\\boldsymbol{\\delta}^{(k)}$，并设置 $\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + \\boldsymbol{\\delta}^{(k)}$。\n\n定义 Picard 增量 $\\mathbf{d}^{(k)} = \\mathbf{u}^{(k+1)} - \\mathbf{u}^{(k)}$ 和 Picard 收缩因子\n$$\nc_k = \\frac{\\left\\|\\mathbf{d}^{(k)}\\right\\|_2}{\\left\\|\\mathbf{d}^{(k-1)}\\right\\|_2}, \\quad k\\ge 1.\n$$\n通过定义以下基于残差的指标\n$$\n\\gamma_k = \\frac{\\left\\|\\mathbf{d}^{(k)}\\right\\|_2}{\\left\\|\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2}.\n$$\n来设计一个指标。\n实现一个从 Picard 切换到 Newton-Raphson 的规则，该规则在 Picard 收缩因子稳定（通过准则\n$$\n\\left|c_k - c_{k-1}\\right| \\le \\varepsilon_c,\n$$\n操作化）且基于残差的指标稳定（通过准则\n$$\n\\left|\\gamma_k - \\gamma_{k-1}\\right| \\le \\varepsilon_\\gamma,\n$$\n操作化）时触发，其中 $\\varepsilon_c0$ 和 $\\varepsilon_\\gamma0$ 是预设的小阈值。\n\n从 $\\mathbf{u}^{(0)} = \\mathbf{0}$ 开始，应用 Picard 迭代直到满足切换规则，然后切换到 Newton-Raphson 并进行迭代，直到离散残差范数 $\\left\\|\\mathbf{F}(\\mathbf{u})\\right\\|_2$ 低于容差 $T0$ 或达到固定的最大迭代次数。使用以下源项：\n$$\nf(x) = \\sin(\\pi x),\n$$\n以及以下参数集 $(N,\\beta)$ 的测试套件：\n- 测试用例 1 (理想情况): $(N,\\beta) = (32,\\, 1.0)$。\n- 测试用例 2 (更强的非线性): $(N,\\beta) = (32,\\, 4.0)$。\n- 测试用例 3 (更粗的网格): $(N,\\beta) = (16,\\, 0.5)$。\n\n对于每个测试用例，在切换迭代索引 $k_\\star$ 处，计算：\n- 基于残差的指标 $\\gamma_{k_\\star}$。\n- 雅可比矩阵的逆利普希茨常数，对于 SPD 矩阵，其解释为在欧几里得范数下的逆算子范数，\n$$\n\\left\\|\\mathbf{J}\\big(\\mathbf{u}^{(k_\\star)}\\big)^{-1}\\right\\|_2 = \\frac{1}{\\lambda_{\\min}\\!\\big(\\mathbf{J}(\\mathbf{u}^{(k_\\star)})\\big)},\n$$\n其中 $\\lambda_{\\min}(\\cdot)$ 表示最小特征值。\n\n您的程序必须为每个测试用例输出比率\n$$\nq = \\frac{\\gamma_{k_\\star}}{\\left\\|\\mathbf{J}\\big(\\mathbf{u}^{(k_\\star)}\\big)^{-1}\\right\\|_2},\n$$\n结果为浮点数。最终输出必须是单行，包含测试套件的三个比率，格式为方括号内以逗号分隔的列表，例如 $[q_1,q_2,q_3]$。\n\n数学任务：\n- 从离散算子和迭代格式的定义出发，推导关系式\n$$\n\\mathbf{d}^{(k)} = -\\mathbf{M}\\big(\\mathbf{u}^{(k)}\\big)^{-1}\\,\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big),\n$$\n并证明基于残差的指标 $\\gamma_k$ 等于 $\\mathbf{M}\\big(\\mathbf{u}^{(k)}\\big)^{-1}$ 应用于离散残差的方向算子范数。证明对于 $\\beta0$，雅可比矩阵对所有 $\\mathbf{u}$ 满足勒夫纳序 $\\mathbf{J}(\\mathbf{u}) \\succeq \\mathbf{M}(\\mathbf{u})$，这意味着\n$$\n\\left\\|\\mathbf{J}(\\mathbf{u})^{-1}\\right\\|_2 \\le \\left\\|\\mathbf{M}(\\mathbf{u})^{-1}\\right\\|_2.\n$$\n得出结论：$\\gamma_k$ 的稳定等价于雅可比矩阵逆利普希茨常数上界估计的稳定，并解释为什么在所述稳定准则下触发切换，是由 Picard 迭代在解附近的局部线性行为证明是合理的。\n\n实现要求：\n- 使用 $\\varepsilon_c = 10^{-3}$，$\\varepsilon_\\gamma = 10^{-3}$，最大 Picard 迭代次数 100，以及牛顿法容差 $T=10^{-10}$ 和最大 100 次牛顿迭代。\n- 所有计算都应以一致的无量纲项进行；不需要物理单位。\n- 您的程序应生成单行输出，其中包含按上述测试用例顺序排列的结果，格式为方括号内的逗号分隔列表。",
            "solution": "问题陈述已得到分析，并被认为是有效的。它在非线性偏微分方程的数值分析方面具有科学依据，是适定的，并提供了一套完整且一致的定义、参数和目标。\n\n我们将首先处理所需的数学推导和论证，然后概述数值计算的算法。\n\n令离散非线性系统为 $\\mathbf{F}(\\mathbf{u}) = \\mathbf{0}$，其中残差映射 $\\mathbf{F}:\\mathbb{R}^N\\to\\mathbb{R}^N$ 由下式给出\n$$\n\\mathbf{F}(\\mathbf{u}) = \\mathbf{K}\\,\\mathbf{u} + \\beta\\, \\mathbf{u}^{\\odot 3} - \\mathbf{f}.\n$$\n此处，$\\mathbf{u} \\in \\mathbb{R}^N$ 是未知数向量，$\\mathbf{K} \\in \\mathbb{R}^{N \\times N}$ 是对称正定 (SPD) 的离散拉普拉斯算子，$\\beta  0$ 是一个常数，$\\mathbf{u}^{\\odot 3}$ 表示向量 $\\mathbf{u}$ 的逐元素立方，$\\mathbf{f} \\in \\mathbb{R}^N$ 是离散化的源项。\n\n### 1. 数学推导与分析\n\n**Picard 增量的关系式**\n\nPicard 迭代的定义是：给定当前迭代值 $\\mathbf{u}^{(k)}$，通过求解线性系统 $\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{u}^{(k+1)} = \\mathbf{f}$ 来得到下一个迭代值 $\\mathbf{u}^{(k+1)}$。矩阵 $\\mathbf{M}(\\mathbf{u}^{(k)})$ 由下式给出\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)}) = \\mathbf{K} + \\beta\\,\\mathrm{diag}\\!\\left(\\big(\\mathbf{u}^{(k)}\\big)^{\\odot 2}\\right).\n$$\nPicard 增量定义为 $\\mathbf{d}^{(k)} = \\mathbf{u}^{(k+1)} - \\mathbf{u}^{(k)}$。为推导所要求的关系式，我们对 Picard 步骤的定义进行变换：\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{u}^{(k+1)} = \\mathbf{f}.\n$$\n我们从等式两边减去 $\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{u}^{(k)}$：\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)}) \\left(\\mathbf{u}^{(k+1)} - \\mathbf{u}^{(k)}\\right) = \\mathbf{f} - \\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{u}^{(k)}.\n$$\n左侧是 $\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{d}^{(k)}$。对于右侧，我们代入 $\\mathbf{M}(\\mathbf{u}^{(k)})$ 的定义：\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{d}^{(k)} = \\mathbf{f} - \\left(\\mathbf{K} + \\beta\\,\\mathrm{diag}\\!\\left(\\big(\\mathbf{u}^{(k)}\\big)^{\\odot 2}\\right)\\right)\\mathbf{u}^{(k)}.\n$$\n注意到对于任意向量 $\\mathbf{v}$，有 $\\mathrm{diag}(\\mathbf{v}^{\\odot 2})\\mathbf{v} = \\mathbf{v}^{\\odot 3}$，因此我们得到：\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{d}^{(k)} = \\mathbf{f} - \\left(\\mathbf{K}\\mathbf{u}^{(k)} + \\beta\\left(\\mathbf{u}^{(k)}\\right)^{\\odot 3}\\right).\n$$\n括号中的项根据定义是 $\\mathbf{F}(\\mathbf{u}^{(k)}) + \\mathbf{f}$。因此，\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{d}^{(k)} = \\mathbf{f} - (\\mathbf{F}(\\mathbf{u}^{(k)}) + \\mathbf{f}) = -\\mathbf{F}(\\mathbf{u}^{(k)}).\n$$\n由于 $\\mathbf{K}$ 是 SPD 矩阵，而 $\\beta\\,\\mathrm{diag}\\!\\left(\\big(\\mathbf{u}^{(k)}\\big)^{\\odot 2}\\right)$ 是一个半正定对角矩阵，它们的和 $\\mathbf{M}(\\mathbf{u}^{(k)})$ 是 SPD 矩阵，因此是可逆的。我们可以求解 $\\mathbf{d}^{(k)}$：\n$$\n\\mathbf{d}^{(k)} = -\\mathbf{M}\\big(\\mathbf{u}^{(k)}\\big)^{-1}\\,\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big).\n$$\n推导至此完成。\n\n**对基于残差的指标 $\\gamma_k$ 的解释**\n\n指标 $\\gamma_k$ 定义为\n$$\n\\gamma_k = \\frac{\\left\\|\\mathbf{d}^{(k)}\\right\\|_2}{\\left\\|\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2}.\n$$\n利用上一节的结果，我们可以写出\n$$\n\\gamma_k = \\frac{\\left\\|-\\mathbf{M}\\big(\\mathbf{u}^{(k)}\\big)^{-1}\\,\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2}{\\left\\|\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2} = \\frac{\\left\\|\\mathbf{M}\\big(\\mathbf{u}^{(k)}\\big)^{-1}\\,\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2}{\\left\\|\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2}.\n$$\n此量度量了矩阵 $\\mathbf{M}(\\mathbf{u}^{(k)})^{-1}$ 应用于特定向量 $\\mathbf{F}(\\mathbf{u}^{(k)})$ 时的放大因子。它并非算子范数 $\\left\\|\\mathbf{M}(\\mathbf{u}^{(k)})^{-1}\\right\\|_2$，后者是在所有可能的非零向量上的最大此类放大。相反，它可以被描述为算子 $\\mathbf{M}(\\mathbf{u}^{(k)})^{-1}$ 限制在由残差向量 $\\mathbf{F}(\\mathbf{u}^{(k)})$ 张成的一维子空间上的范数。因此，它提供了 Picard 更新对当前残差响应的一个方向性度量。\n\n**雅可比矩阵和 Picard 矩阵的勒夫纳序**\n\n残差映射 $\\mathbf{F}(\\mathbf{u})$ 的雅可比矩阵是偏导数矩阵 $\\mathbf{J}_{ij}(\\mathbf{u}) = \\frac{\\partial F_i}{\\partial u_j}$。\n$$\nF_i(\\mathbf{u}) = \\sum_{j=1}^N K_{ij}u_j + \\beta u_i^3 - f_i.\n$$\n偏导数为：\n$$\n\\frac{\\partial F_i}{\\partial u_j} = K_{ij} + 3\\beta u_i^2 \\delta_{ij},\n$$\n其中 $\\delta_{ij}$ 是克罗内克符号。其矩阵形式为：\n$$\n\\mathbf{J}(\\mathbf{u}) = \\mathbf{K} + 3\\beta\\,\\mathrm{diag}\\!\\left(\\mathbf{u}^{\\odot 2}\\right).\n$$\n为了证明勒夫纳序 $\\mathbf{J}(\\mathbf{u}) \\succeq \\mathbf{M}(\\mathbf{u})$，我们必须证明差分矩阵 $\\mathbf{J}(\\mathbf{u}) - \\mathbf{M}(\\mathbf{u})$ 是半正定的 (PSD)。\n$$\n\\mathbf{J}(\\mathbf{u}) - \\mathbf{M}(\\mathbf{u}) = \\left(\\mathbf{K} + 3\\beta\\,\\mathrm{diag}\\!\\left(\\mathbf{u}^{\\odot 2}\\right)\\right) - \\left(\\mathbf{K} + \\beta\\,\\mathrm{diag}\\!\\left(\\mathbf{u}^{\\odot 2}\\right)\\right) = 2\\beta\\,\\mathrm{diag}\\!\\left(\\mathbf{u}^{\\odot 2}\\right).\n$$\n这个差是一个对角矩阵。其对角线元素为 $2\\beta (u_i)^2$。由于 $\\beta  0$ 且对所有 $i=1,\\dots,N$ 都有 $(u_i)^2 \\ge 0$，因此所有对角线元素都是非负的。根据定义，对角线上元素非负的对角矩阵是半正定的。因此，$\\mathbf{J}(\\mathbf{u}) \\succeq \\mathbf{M}(\\mathbf{u})$。\n\n矩阵分析中的一个标准结果指出，如果 $\\mathbf{A}$ 和 $\\mathbf{B}$ 是 SPD 矩阵且 $\\mathbf{A} \\succeq \\mathbf{B}$，则 $\\mathbf{B}^{-1} \\succeq \\mathbf{A}^{-1}$。由于对于任意 $\\mathbf{u}$，$\\mathbf{J}(\\mathbf{u})$ 和 $\\mathbf{M}(\\mathbf{u})$ 都是 SPD 矩阵（因为它们是 SPD 矩阵 $\\mathbf{K}$ 和一个 PSD 对角矩阵的和），我们可以应用此结果得出 $\\mathbf{M}(\\mathbf{u})^{-1} \\succeq \\mathbf{J}(\\mathbf{u})^{-1}$。这意味着对于任意向量 $\\mathbf{v}$，$\\mathbf{v}^T \\mathbf{M}(\\mathbf{u})^{-1} \\mathbf{v} \\ge \\mathbf{v}^T \\mathbf{J}(\\mathbf{u})^{-1} \\mathbf{v}$。\n对于任何 SPD 矩阵 $\\mathbf{S}$，其算子 2-范数为 $\\|\\mathbf{S}\\|_2 = \\lambda_{\\max}(\\mathbf{S})$。由于 $\\mathbf{M}(\\mathbf{u})^{-1} - \\mathbf{J}(\\mathbf{u})^{-1}$ 是 PSD 的，其特征值非负，因此 $\\lambda_{\\max}(\\mathbf{M}(\\mathbf{u})^{-1} - \\mathbf{J}(\\mathbf{u})^{-1}) \\ge 0$。这导致 $\\lambda_{\\max}(\\mathbf{M}(\\mathbf{u})^{-1}) \\ge \\lambda_{\\max}(\\mathbf{J}(\\mathbf{u})^{-1})$，直接意味着：\n$$\n\\left\\|\\mathbf{M}(\\mathbf{u})^{-1}\\right\\|_2 \\ge \\left\\|\\mathbf{J}(\\mathbf{u})^{-1}\\right\\|_2.\n$$\n正如问题中所述 `for SPD matrices`（对于 SPD 矩阵），逆范数也由原矩阵最小特征值的倒数给出。因此，$\\frac{1}{\\lambda_{\\min}(\\mathbf{M}(\\mathbf{u}))} \\ge \\frac{1}{\\lambda_{\\min}(\\mathbf{J}(\\mathbf{u}))}$。\n\n**切换规则的合理性**\n\n在求解非线性系统时，从 Picard 迭代切换到 Newton-Raphson 迭代是一种常用技术。\n- **Picard 迭代：** 这是一种不动点迭代。它通常表现出全局收敛性（或至少有较大的吸引盆），但仅线性收敛。其收敛速度由迭代的雅可比矩阵的谱半径决定。\n- **Newton-Raphson 迭代：** 当迭代值足够接近解时，此方法二次收敛，但若初始值相距较远则可能发散。\n\n混合策略利用了两者的优点：使用稳健的 Picard 方法生成一个趋近解的迭代序列，一旦迭代值进入牛顿法的二次收敛盆，就切换到后者以实现快速收敛。挑战在于确定何时切换。\n\n所提出的切换准则是基于监测 Picard 迭代的收敛行为。\n$1.$ **收缩因子 $c_k$ 的稳定：** 量 $c_k = \\|\\mathbf{d}^{(k)}\\|_2 / \\|\\mathbf{d}^{(k-1)}\\|_2$ 是线性收敛率的一个经验度量。当迭代进入其渐近线性收敛阶段时，该比率会趋于一个常数。准则 $|c_k - c_{k-1}| \\le \\varepsilon_c$ 检查这种稳定情况，表明迭代已进入一个可预测的线性区域。\n$2.$ **基于残差的指标 $\\gamma_k$ 的稳定：** 量 $\\gamma_k$ 作为范数 $\\mathbf{M}(\\mathbf{u}^{(k)})^{-1}$ 的一个方向性探针。当 $\\mathbf{u}^{(k)}$ 趋于一个极限时，我们预期 $\\mathbf{M}(\\mathbf{u}^{(k)})$ 以及残差向量 $\\mathbf{F}(\\mathbf{u}^{(k)})$ 的方向会稳定下来。因此，$\\gamma_k$ 也应趋于一个常数值。准则 $|\\gamma_k - \\gamma_{k-1}| \\le \\varepsilon_\\gamma$ 检测这种稳定情况。\n\n正如我们所证明的，$\\left\\|\\mathbf{M}(\\mathbf{u})^{-1}\\right\\|_2$ 为 $\\left\\|\\mathbf{J}(\\mathbf{u})^{-1}\\right\\|_2$ 提供了一个上界。牛顿法的局部收敛理论依赖于解附近雅可比矩阵及其逆的性质。$\\gamma_k$ 的稳定表明一个相关量，即逆雅可比范数估计的上界，也已稳定。\n\n综合来看，$c_k$ 和 $\\gamma_k$ 的稳定提供了一个强有力的启发式判据，表明 Picard 迭代已完全进入局部动力学稳定且可预测的线性收敛区域。这种稳定性意味着当前迭代值 $\\mathbf{u}^{(k)}$ 可能已足够接近真实解，使得 Newton-Raphson 方法能够二次收敛。因此，在此时切换是加速收敛的一个合理解释的策略。\n\n### 2. 算法实现\n\n对于每个测试用例 $(N, \\beta)$，算法流程如下：\n1.  **初始化：** 设置网格参数 $h = 1/(N+1)$，构建网格点 $x_i$、离散拉普拉斯矩阵 $\\mathbf{K}$ 和源向量 $\\mathbf{f}$。初始化解向量 $\\mathbf{u} = \\mathbf{0}$，并建立数据结构以存储增量、收缩因子和 gamma 指标的历史记录。\n2.  **迭代求解器：** 进入主循环，该循环运行直到收敛或达到最大迭代次数。\n3.  **Picard 阶段：** 对于初始迭代（最多 100 次或直到触发切换）：\n    a. 计算残差 $\\mathbf{F}(\\mathbf{u}^{(k)})$。\n    b. 构建 Picard 矩阵 $\\mathbf{M}(\\mathbf{u}^{(k)})$。\n    c. 求解线性系统 $\\mathbf{M}(\\mathbf{u}^{(k)}) \\mathbf{u}^{(k+1)} = \\mathbf{f}$ 以找到下一个迭代值 $\\mathbf{u}^{(k+1)}$。\n    d. 计算增量 $\\mathbf{d}^{(k)} = \\mathbf{u}^{(k+1)} - \\mathbf{u}^{(k)}$ 及其范数。\n    e. 计算 $\\gamma_k$，如果 $k \\ge 1$，则计算 $c_k$。存储这些值。\n    f. 如果 $k \\ge 2$，检查切换条件：$|c_k - c_{k-1}| \\le \\varepsilon_c$ 和 $|\\gamma_k - \\gamma_{k-1}| \\le \\varepsilon_\\gamma$。\n    g. 如果满足条件，则当前为切换迭代 $k_\\star = k$。\n        i.  存储 $\\gamma_{k_\\star} = \\gamma_k$。\n        ii. 使用当前迭代值 $\\mathbf{u}^{(k)}$ 构建雅可比矩阵 $\\mathbf{J}(\\mathbf{u}^{(k_\\star)})$。\n        iii. 计算其最小特征值 $\\lambda_{\\min}$ 和逆范数 $\\left\\|\\mathbf{J}^{-1}\\right\\|_2 = 1/\\lambda_{\\min}$。\n        iv. 计算比率 $q = \\gamma_{k_\\star} / \\left\\|\\mathbf{J}^{-1}\\right\\|_2$。\n        v.  设置一个标志为 `True` 以表示已发生切换。\n    h. 更新 $\\mathbf{u} \\leftarrow \\mathbf{u}^{(k+1)}$。\n4.  **Newton-Raphson 阶段：** 一旦设置了切换标志，对于所有后续迭代：\n    a. 计算残差 $\\mathbf{F}(\\mathbf{u}^{(k)})$。检查其范数是否低于容差 $T=10^{-10}$。如果是，则终止。\n    b. 构建雅可比矩阵 $\\mathbf{J}(\\mathbf{u}^{(k)})$。\n    c. 求解线性系统 $\\mathbf{J}(\\mathbf{u}^{(k)}) \\boldsymbol{\\delta}^{(k)} = -\\mathbf{F}(\\mathbf{u}^{(k)})$ 以获得更新量 $\\boldsymbol{\\delta}^{(k)}$。\n    d. 更新解 $\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + \\boldsymbol{\\delta}^{(k)}$。\n5.  **输出：** 对一个给定的测试用例，当循环终止后，存储计算出的 $q$ 值。最终输出是所有测试用例的这些 $q$ 值的列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the nonlinear reaction-diffusion problem using a hybrid Picard/Newton-Raphson method\n    and computes the specified ratio q at the switching point for three test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (32, 1.0),  # Test case 1\n        (32, 4.0),  # Test case 2\n        (16, 0.5),  # Test case 3\n    ]\n\n    # Implementation parameters\n    eps_c = 1e-3\n    eps_gamma = 1e-3\n    max_picard_iter = 100\n    max_newton_iter = 100\n    newton_tol = 1e-10\n\n    results = []\n\n    for N, beta in test_cases:\n        # --- Setup for the current test case ---\n        h = 1.0 / (N + 1)\n        x_nodes = np.linspace(h, 1.0 - h, N)\n        f_vec = np.sin(np.pi * x_nodes)\n        \n        # Construct the discrete Laplacian matrix K\n        diag_main = np.full(N, 2.0)\n        diag_sub = -np.ones(N - 1)\n        K = (np.diag(diag_main) + np.diag(diag_sub, k=1) + np.diag(diag_sub, k=-1)) / h**2\n\n        # --- Iteration Initialization ---\n        u = np.zeros(N)\n        switched = False\n        q_ratio = np.nan  # Use NaN as a sentinel for the result\n\n        d_norm_hist = []\n        c_hist = []\n        gamma_hist = []\n        \n        total_max_iter = max_picard_iter + max_newton_iter\n\n        # Combined Picard/Newton iteration loop\n        for k in range(total_max_iter):\n            \n            # Since u is updated at the end of the loop, u here is u^(k)\n            # The residual F(u^(k)) is needed by both methods\n            F_u = K @ u + beta * u**3 - f_vec\n            norm_F = np.linalg.norm(F_u)\n\n            if switched and norm_F  newton_tol:\n                break # Converged in Newton phase\n\n            # --- Picard Phase ---\n            if not switched and k  max_picard_iter:\n                u_sq = u**2\n                M_u = K + beta * np.diag(u_sq)\n                \n                try:\n                    u_next = np.linalg.solve(M_u, f_vec)\n                except np.linalg.LinAlgError:\n                    # In case of instability, break and result in NaN\n                    break\n                \n                d = u_next - u\n                norm_d = np.linalg.norm(d)\n                d_norm_hist.append(norm_d)\n                \n                gamma_k = norm_d / norm_F if norm_F > 1e-15 else 0.0\n                gamma_hist.append(gamma_k)\n\n                if k >= 1:\n                    norm_d_prev = d_norm_hist[k-1]\n                    c_k = norm_d / norm_d_prev if norm_d_prev > 1e-15 else 0.0\n                    c_hist.append(c_k)\n\n                # Check for switch condition, requires k>=2 for c_k and c_{k-1}\n                if k >= 2:\n                    c_k_val = c_hist[-1]\n                    c_k_minus_1_val = c_hist[-2]\n                    gamma_k_val = gamma_hist[-1]\n                    gamma_k_minus_1_val = gamma_hist[-2]\n\n                    if abs(c_k_val - c_k_minus_1_val) = eps_c and \\\n                       abs(gamma_k_val - gamma_k_minus_1_val) = eps_gamma:\n                        \n                        switched = True\n                        k_star = k\n                        \n                        # --- Compute q at the switching point k_star ---\n                        # Use gamma at k_star\n                        gamma_k_star = gamma_k_val\n\n                        # Use u at k_star (which is the current u)\n                        u_star = u\n                        u_star_sq = u_star**2\n                        J_u_star = K + 3 * beta * np.diag(u_star_sq)\n                        \n                        # J_u_star is symmetric, use eigvalsh for efficiency and stability\n                        eigenvalues = np.linalg.eigvalsh(J_u_star)\n                        lambda_min = np.min(eigenvalues)\n\n                        if lambda_min > 1e-12:\n                            norm_J_inv = 1.0 / lambda_min\n                            q_ratio = gamma_k_star / norm_J_inv\n                        else:\n                            q_ratio = np.nan\n                \n                # Update state for the next iteration\n                u = u_next \n\n            # --- Newton-Raphson Phase ---\n            else:\n                if not switched: # Picard failed to meet switch criteria\n                    switched = True # Switch anyway after max_picard_iter\n                \n                if norm_F  newton_tol:\n                    break\n\n                u_sq = u**2\n                J_u = K + 3.0 * beta * np.diag(u_sq)\n                \n                try:\n                    delta = np.linalg.solve(J_u, -F_u)\n                except np.linalg.LinAlgError:\n                    break\n                \n                u = u + delta\n        \n        results.append(q_ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, [f'{r:.6f}' if not np.isnan(r) else 'nan' for r in results]))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现在，我们将挑战一个更复杂的场景：参数依赖的非线性问题，其解可能随着参数的变化出现分岔或“转折点”。在这些临界点附近，简单的迭代方法（如皮卡迭代）往往会失效。本练习  以经典的Bratu方程为例，让你实现并对比两种参数跟踪策略：一种是基于皮卡迭代的简单参数步进法，另一种是基于牛顿法的、更为强大的伪弧长延拓法。通过亲手实现并观察皮卡方法的失效和伪弧长法的成功，你将深刻理解为何基于牛顿的方法对于探索复杂物理模型的完整解空间是不可或缺的。",
            "id": "3431387",
            "problem": "考虑由 Bratu 方程给出的单参数非线性边值问题族，这是一个用于参数化偏微分方程中折叠（转折点）分岔的原型模型：\n$$\n\\text{求 } u: [0,1] \\to \\mathbb{R} \\text{ 使得 } u''(x) + \\lambda \\exp(u(x)) = 0,\\quad u(0) = 0,\\quad u(1) = 0,\n$$\n其中 $\\lambda \\in \\mathbb{R}$ 是一个延拓参数。我们通过在具有 $N$ 个内部点的均匀网格上进行有限差分格式来寻求数值解。设 $h = \\frac{1}{N+1}$，并设 $u \\in \\mathbb{R}^N$ 是内部节点 $x_i = ih$, $i=1,\\dots,N$ 处的未知数向量。半离散非线性系统为\n$$\nF(u,\\lambda) = L u + \\lambda \\exp(u) = 0,\n$$\n其中 $L \\in \\mathbb{R}^{N \\times N}$ 是带狄利克雷边界条件的拉普拉斯算子的标准二阶中心差分近似，\n$$\nL = \\frac{1}{h^2}\n\\begin{bmatrix}\n-2  1                   \\\\\n1   -2  1               \\\\\n    \\ddots  \\ddots  \\ddots  \\\\\n            1       -2  1 \\\\\n                    1  -2\n\\end{bmatrix},\n$$\n并且 $\\exp(u)$ 表示元素为 $\\exp(u_i)$ 的向量。\n\n您将实现并比较两种迭代策略：\n\n1. 带自适应松弛的皮卡迭代（阻尼不动点法）：\n   从初始猜测 $u^{(0)}$ 开始，定义线性泊松求解\n   $$\n   L \\tilde{u}^{(k+1)} = -\\lambda \\exp\\left(u^{(k)}\\right),\n   $$\n   然后使用松弛进行更新\n   $$\n   u^{(k+1)} = (1-\\omega^{(k)}) u^{(k)} + \\omega^{(k)} \\tilde{u}^{(k+1)},\n   $$\n   其中松弛参数 $\\omega^{(k)} \\in (0,1]$ 在每次迭代时自适应选择，以确保残差范数 $\\lVert F(u^{(k+1)},\\lambda)\\rVert_2$ 减小（对 $\\omega^{(k)}$ 使用简单的回溯策略）。\n\n2. 带伪弧长延拓的牛顿-拉夫逊方法：\n   对于固定的 $\\lambda$，标准的牛顿-拉夫逊方法求解\n   $$\n   J(u,\\lambda) \\,\\delta u = -F(u,\\lambda), \\quad \\text{其中 } J(u,\\lambda) = L + \\lambda \\operatorname{diag}(\\exp(u)),\n   $$\n   并更新 $u \\leftarrow u + \\delta u$。为了在解分支上穿越转折点，使用伪弧长延拓：给定两个先前收敛的解 $(u_0,\\lambda_0)$ 和 $(u_1,\\lambda_1)$，定义基于割线的切线\n   $$\n   s = \\frac{1}{\\sqrt{\\lVert u_1 - u_0 \\rVert_2^2 + (\\lambda_1 - \\lambda_0)^2}} \\left( u_1 - u_0, \\ \\lambda_1 - \\lambda_0 \\right),\n   $$\n   形成一个预测子 $(u_{\\mathrm{pred}},\\lambda_{\\mathrm{pred}}) = (u_1,\\lambda_1) + d s$，其中 $d0$ 是弧长步长，并通过在增广系统上进行牛顿法来校正\n   $$\n   \\begin{cases}\n   F(u,\\lambda) = 0, \\\\\n   \\langle u - u_{\\mathrm{pred}}, s_u \\rangle + (\\lambda - \\lambda_{\\mathrm{pred}}) s_\\lambda = 0,\n   \\end{cases}\n   $$\n   其中 $s = (s_u,s_\\lambda)$ 且 $\\langle \\cdot,\\cdot \\rangle$ 是欧几里得内积。实现一个基于舒尔补的牛顿校正，该校正仅需使用 $J(u,\\lambda)$ 进行求解，并对全步长 $(\\delta u,\\delta\\lambda)$ 采用 Armijo 型回溯法，以确保增广系统的残差减小。\n\n您的任务是在所述离散化方案上实现这两种方法，并运行以下测试套件。使用 $N=80$，对 $F$ 的欧几里得范数使用容差 $\\varepsilon = 10^{-8}$，皮卡迭代最多 $1000$ 次，每个牛顿校正最多 $50$ 次。在所有测试中，当未指定先前解时，使用零向量作为初始猜测。\n\n测试套件：\n\n- 测试 1（理想路径）：对于 $\\lambda = 1.0$，从 $u^{(0)} = 0$ 开始运行带自适应松弛的皮卡迭代。返回一个布尔值，指示是否在迭代次数限制内（残差范数 $\\le \\varepsilon$）达到收敛。\n\n- 测试 2（近转折点固定参数尝试）：对于 $\\lambda = 3.2$，从 $u^{(0)} = 0$ 开始运行带自适应松弛的皮卡迭代。返回一个布尔值，指示是否在迭代次数限制内（残差范数 $\\le \\varepsilon$）达到收敛。\n\n- 测试 3（伪弧长穿越）：使用标准的牛顿-拉夫逊方法找到 $\\lambda_0 = 0.1$ 和 $\\lambda_1 = 0.2$ 处的解。以弧长步长 $d = 0.05$ 初始化伪弧长延拓，并运行 $40$ 个延拓步。返回一个布尔值，指示延拓是否穿越了转折点，定义为参数序列（即 $\\lambda$ 值序列）的离散导数发生严格的符号变化（即，$\\lambda$ 值序列先严格增加，之后至少有一次严格减少）。\n\n- 测试 4（覆盖范围比较）：使用带自适应松弛的皮卡迭代执行朴素参数延拓：从 $\\lambda = 0.1$ 和步长 $\\Delta \\lambda = 0.1$ 开始，使用先前收敛的解作为初始猜测来递增 $\\lambda$，当皮卡迭代在迭代次数限制内未能收敛时停止。同时，使用如测试 3 中初始化的伪弧长延拓，并记录其轨迹上达到的最大 $\\lambda$。返回浮点数\n$$\n\\lambda_{\\max}^{\\mathrm{PA}} - \\lambda_{\\mathrm{last}}^{\\mathrm{Picard}},\n$$\n其中 $\\lambda_{\\max}^{\\mathrm{PA}}$ 是伪弧长延拓在其所有步骤中达到的最大 $\\lambda$ 值，而 $\\lambda_{\\mathrm{last}}^{\\mathrm{Picard}}$ 是皮卡迭代收敛的最后一个 $\\lambda$ 值。将此答案表示为十进制数。\n\n您的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来的结果（例如，\"[result1,result2,result3,result4]\"）。这四个条目必须分别对应上述测试 1 到测试 4 的输出，顺序和类型需与规定一致。",
            "solution": "问题陈述是有效的。它提出了一个定义明确的数值分析任务，该任务基于求解非线性偏微分方程和分析其分岔的既定理论。所有参数和方法都已足够清晰地指定，以允许唯一且可验证的实现。\n\n该问题围绕一维 Bratu 方程的数值解展开，该方程是自燃的典型模型，也是折叠（或转折点）分岔的经典例子。方程为\n$$\nu''(x) + \\lambda \\exp(u(x)) = 0, \\quad x \\in [0,1],\n$$\n带有齐次狄利克雷边界条件 $u(0) = u(1) = 0$。解 $u(x)$ 的行为关键取决于参数 $\\lambda$。\n\n首先，对连续问题进行离散化。我们使用二阶中心差分格式，该格式作用于一个具有 $N$ 个内部点、间距为 $h = 1/(N+1)$ 的均匀网格上。节点 $x_i$ 处的二阶导数 $u''(x_i)$ 近似为 $(u_{i-1} - 2u_i + u_{i+1})/h^2$。在每个内部节点 $i=1, \\dots, N$ 应用此格式并结合边界条件 $u_0=u_{N+1}=0$，得到一个关于未知数向量 $u = (u_1, \\dots, u_N)^T$ 的 $N$ 个非线性代数方程组。该系统以向量形式写为：\n$$\nF(u, \\lambda) = L u + \\lambda \\exp(u) = 0,\n$$\n其中 $L \\in \\mathbb{R}^{N \\times N}$ 是表示离散化负拉普拉斯算子的稀疏三对角矩阵，$\\exp(u)$ 是逐元素的指数函数。\n\n为求解此非线性系统，需要实现两种迭代方法。\n\n1.  **带自适应松弛的皮卡迭代**：此方法是一种不动点迭代。系统 $Lu + \\lambda\\exp(u)=0$ 被重排为不动点形式 $u = -L^{-1}(\\lambda\\exp(u))$。因此，基本迭代是 $u^{(k+1)} = -L^{-1}(\\lambda \\exp(u^{(k)}))$。在实践中，我们求解线性系统 $L \\tilde{u}^{(k+1)} = -\\lambda \\exp(u^{(k)})$ 以得到 $\\tilde{u}^{(k+1)}$。对于 Bratu 问题，此迭代仅对小的 $\\lambda$ 值收敛。为了扩大收敛半径，引入了松弛（或阻尼）步骤：\n    $$\n    u^{(k+1)} = (1-\\omega^{(k)}) u^{(k)} + \\omega^{(k)} \\tilde{u}^{(k+1)}.\n    $$\n    松弛参数 $\\omega^{(k)} \\in (0, 1]$ 在每次迭代 $k$ 时通过回溯搜索自适应地选择，以确保残差的范数减小，即 $\\lVert F(u^{(k+1)}, \\lambda) \\rVert_2  \\lVert F(u^{(k)}, \\lambda) \\rVert_2$。\n\n2.  **带伪弧长延拓的牛顿-拉夫逊方法**：\n    对于固定的 $\\lambda$，牛顿法通过迭代求解一个线性系统来寻找 $F(u, \\lambda)=0$ 的根，以获得校正量 $\\delta u$。给定一个迭代点 $u^{(k)}$，通过求解以下方程找到更新量 $u^{(k+1)} = u^{(k)} + \\delta u$：\n    $$\n    J(u^{(k)}, \\lambda) \\delta u = -F(u^{(k)}, \\lambda),\n    $$\n    其中 $J(u, \\lambda) = \\frac{\\partial F}{\\partial u} = L + \\lambda \\operatorname{diag}(\\exp(u))$ 是雅可比矩阵。牛顿法在 Bratu 曲线的转折点附近会失效，因为雅可比矩阵 $J$ 在该点变得奇异。\n\n    伪弧长延拓是一种强大的技术，用于追踪由弧长 $s$ 参数化的整个解曲线 $(u(s), \\lambda(s))$，包括穿越转折点。它由一个预测-校正序列组成：\n    -   **预测**：通过从最后一个收敛点 $(u_1, \\lambda_1)$ 沿由最近两个点 $(u_0, \\lambda_0)$ 和 $(u_1, \\lambda_1)$ 定义的（归一化）割线向量 $s = (s_u, s_\\lambda)$ 进行外插，来对曲线上的下一个点做出初始猜测。预测子是 $(u_{\\mathrm{pred}}, \\lambda_{\\mathrm{pred}}) = (u_1, \\lambda_1) + d \\cdot s$，其中 $d$ 是弧长步长。\n    -   **校正**：通过求解一个包含 $N+1$ 个方程和 $N+1$ 个未知数 $(u, \\lambda)$ 的增广系统，将预测点 $(u_{\\mathrm{pred}}, \\lambda_{\\mathrm{pred}})$ 校正回解曲线上。该系统将原始方程与一个弧长约束耦合，该约束强制解位于与切向量 $s$ 正交的超平面上：\n        $$\n        \\begin{cases}\n        F(u, \\lambda) = 0, \\\\\n        g(u,\\lambda) := \\langle u - u_{\\mathrm{pred}}, s_u \\rangle + (\\lambda - \\lambda_{\\mathrm{pred}}) s_\\lambda = 0.\n        \\end{cases}\n        $$\n    该增广系统使用牛顿法求解。其雅可比矩阵是一个加边矩阵，在转折点处保持非奇异。每个牛顿步骤中的线性求解通过舒尔补方法高效处理。对于系统 $\\begin{psmallmatrix} J  \\exp(u) \\\\ s_u^T  s_\\lambda \\end{psmallmatrix} \\begin{psmallmatrix} \\delta u \\\\ \\delta \\lambda \\end{psmallmatrix} = -\\begin{psmallmatrix} F \\\\ g \\end{psmallmatrix}$，我们首先求解两个只涉及原始雅可比矩阵 $J$ 的线性系统，以找到向量 $w_F=J^{-1}F$ 和 $w_\\lambda=J^{-1}\\exp(u)$。这使得标量校正 $\\delta\\lambda$ 可以被显式求解：\n    $$\n    \\delta\\lambda = \\frac{\\langle s_u, w_F \\rangle - g}{s_\\lambda - \\langle s_u, w_\\lambda \\rangle}.\n    $$\n    然后向量校正 $\\delta u$ 可被恢复为 $\\delta u = -w_F - \\delta\\lambda \\cdot w_\\lambda$。这种方法避免了直接构建和求解完整的 $(N+1) \\times (N+1)$ 加边系统，利用了求解稀疏矩阵 $J$ 的高效性。对步长进行回溯可确保校正子的稳健收敛。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\n\ndef solve():\n    \"\"\"\n    Implements and compares Picard and Newton-Raphson-based solvers for the\n    discretized Bratu equation, executing a predefined test suite.\n    \"\"\"\n    # --- Problem Parameters ---\n    N = 80\n    TOL = 1e-8\n    PICARD_MAX_ITER = 1000\n    NEWTON_MAX_ITER = 50\n    H = 1.0 / (N + 1)\n\n    # --- Core Functions ---\n\n    def create_laplacian_sparse(n, h):\n        \"\"\"Creates the 1D finite difference Laplacian as a sparse matrix.\"\"\"\n        diagonals = [np.ones(n - 1), -2 * np.ones(n), np.ones(n - 1)]\n        offsets = [-1, 0, 1]\n        L = sparse.diags(diagonals, offsets, shape=(n, n), format='csc')\n        return L / h**2\n\n    def compute_residual(u, lam, L_sparse):\n        \"\"\"Computes the residual F(u, lam) = L*u + lam*exp(u).\"\"\"\n        return L_sparse @ u + lam * np.exp(u)\n\n    # --- Solver Implementations ---\n\n    def picard_solver(lam, u_init, L_sparse, tol, max_iter):\n        \"\"\"\n        Solves the Bratu equation using Picard iteration with adaptive relaxation.\n        \"\"\"\n        u = u_init.copy()\n        \n        for _ in range(max_iter):\n            res_norm = np.linalg.norm(compute_residual(u, lam, L_sparse))\n            \n            if res_norm  tol:\n                return u, True\n            \n            # Linear solve for Picard update\n            rhs = -lam * np.exp(u)\n            u_tilde = spsolve(L_sparse, rhs)\n\n            # Adaptive relaxation (backtracking on omega)\n            omega = 1.0\n            found_omega = False\n            for _ in range(10):  # Max 10 backtracking steps\n                u_next = (1 - omega) * u + omega * u_tilde\n                res_next_norm = np.linalg.norm(compute_residual(u_next, lam, L_sparse))\n                if res_next_norm  res_norm:\n                    u = u_next\n                    found_omega = True\n                    break\n                omega /= 2.0\n\n            if not found_omega:\n                return u, False\n\n        return u, np.linalg.norm(compute_residual(u, lam, L_sparse))  tol\n\n    def newton_solver(lam, u_init, L_sparse, tol, max_iter):\n        \"\"\"\n        Solves the Bratu equation for a fixed lambda using Newton-Raphson.\n        \"\"\"\n        u = u_init.copy()\n\n        for _ in range(max_iter):\n            res = compute_residual(u, lam, L_sparse)\n            if np.linalg.norm(res)  tol:\n                return u, True\n            \n            exp_u = np.exp(u)\n            J = L_sparse + sparse.diags(lam * exp_u, 0, format='csc')\n            \n            try:\n                delta_u = spsolve(J, -res)\n            except (np.linalg.LinAlgError, RuntimeError):\n                return u, False\n            u += delta_u\n        \n        return u, np.linalg.norm(compute_residual(u, lam, L_sparse))  tol\n\n    def pa_continuation(u0, lam0, u1, lam1, d, num_steps, L_sparse, tol, max_newton_iter):\n        \"\"\"\n        Performs pseudo-arclength continuation.\n        \"\"\"\n        branch = [(u0, lam0), (u1, lam1)]\n        u_curr, lam_curr = u1, lam1\n        u_prev, lam_prev = u0, lam0\n\n        for _ in range(num_steps):\n            # --- Predictor ---\n            u_diff = u_curr - u_prev\n            lam_diff = lam_curr - lam_prev\n            \n            tangent_norm = np.sqrt(np.dot(u_diff, u_diff) + lam_diff**2)\n            if tangent_norm  1e-12: break # Stalled\n            s_u = u_diff / tangent_norm\n            s_lam = lam_diff / tangent_norm\n\n            u_pred = u_curr + d * s_u\n            lam_pred = lam_curr + d * s_lam\n            \n            u_corr, lam_corr = u_pred, lam_pred\n\n            # --- Corrector (Newton on bordered system) ---\n            converged = False\n            for _ in range(max_newton_iter):\n                res_F = compute_residual(u_corr, lam_corr, L_sparse)\n                res_g = np.dot(s_u, u_corr - u_pred) + s_lam * (lam_corr - lam_pred)\n                aug_res_norm = np.sqrt(np.dot(res_F, res_F) + res_g**2)\n                if aug_res_norm  tol:\n                    converged = True\n                    break\n\n                # Schur complement solve\n                exp_u = np.exp(u_corr)\n                J_corr = L_sparse + sparse.diags(lam_corr * exp_u, 0, format='csc')\n                \n                try:\n                    w_F = spsolve(J_corr, res_F)\n                    w_lam = spsolve(J_corr, exp_u)\n                except (np.linalg.LinAlgError, RuntimeError): break\n\n                delta_lam_den = s_lam - np.dot(s_u, w_lam)\n                if abs(delta_lam_den)  1e-12: break\n\n                delta_lam_num = -res_g + np.dot(s_u, w_F)\n                delta_lam = delta_lam_num / delta_lam_den\n                delta_u = -w_F - delta_lam * w_lam\n\n                # Backtracking line search\n                alpha = 1.0\n                found_alpha = False\n                for _ in range(10):\n                    u_next = u_corr + alpha * delta_u\n                    lam_next = lam_corr + alpha * delta_lam\n                    \n                    res_F_next = compute_residual(u_next, lam_next, L_sparse)\n                    res_g_next = np.dot(s_u, u_next - u_pred) + s_lam * (lam_next - lam_pred)\n                    aug_res_norm_next = np.sqrt(np.dot(res_F_next, res_F_next) + res_g_next**2)\n\n                    if aug_res_norm_next  aug_res_norm:\n                        u_corr, lam_corr = u_next, lam_next\n                        found_alpha = True\n                        break\n                    alpha /= 2.0\n                \n                if not found_alpha: break\n            \n            if not converged: break\n            \n            branch.append((u_corr, lam_corr))\n            u_prev, lam_prev = u_curr, lam_curr\n            u_curr, lam_curr = u_corr, lam_corr\n\n        return branch\n\n    # --- Main Execution ---\n    L = create_laplacian_sparse(N, H)\n    u_zero = np.zeros(N)\n    results = []\n\n    # Test 1: Picard at lam=1.0\n    _, conv1 = picard_solver(1.0, u_zero, L, TOL, PICARD_MAX_ITER)\n    results.append(conv1)\n\n    # Test 2: Picard at lam=3.2\n    _, conv2 = picard_solver(3.2, u_zero, L, TOL, PICARD_MAX_ITER)\n    results.append(conv2)\n\n    # Test 3: PA turning point detection\n    u_sol_01, conv_01 = newton_solver(0.1, u_zero, L, TOL, NEWTON_MAX_ITER)\n    u_sol_02, conv_02 = newton_solver(0.2, u_sol_01, L, TOL, NEWTON_MAX_ITER)\n    \n    pa_branch_test3 = []\n    if conv_01 and conv_02:\n        pa_branch_test3 = pa_continuation(u_sol_01, 0.1, u_sol_02, 0.2, 0.05, 40, L, TOL, NEWTON_MAX_ITER)\n    \n    lams_pa = [p[1] for p in pa_branch_test3]\n    deltas_lam = np.diff(lams_pa)\n    crossed_turning_point = False\n    if len(deltas_lam) > 1 and np.all(np.diff(lams_pa[:5]) > 0): # Check if it starts increasing\n        if np.any(deltas_lam  0):\n            crossed_turning_point = True\n    results.append(crossed_turning_point)\n    \n    # Test 4: Coverage comparison\n    lam_picard = 0.1\n    delta_lam_picard = 0.1\n    u_guess_picard = np.zeros(N)\n    lam_last_picard = 0.0\n    while lam_picard  4.0: # Safety break\n        u_sol, conv = picard_solver(lam_picard, u_guess_picard, L, TOL, PICARD_MAX_ITER)\n        if conv:\n            lam_last_picard = lam_picard\n            u_guess_picard = u_sol\n            lam_picard += delta_lam_picard\n        else:\n            break\n\n    lam_max_pa = 0.0\n    if lams_pa:\n        lam_max_pa = max(lams_pa)\n\n    result4 = lam_max_pa - lam_last_picard\n    results.append(result4)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}