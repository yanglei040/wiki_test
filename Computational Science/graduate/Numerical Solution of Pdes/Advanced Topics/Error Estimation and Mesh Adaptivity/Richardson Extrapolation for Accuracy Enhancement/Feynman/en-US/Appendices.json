{
    "hands_on_practices": [
        {
            "introduction": "This first practice lays the groundwork for Richardson extrapolation by returning to first principles. You will start with the asymptotic error model for a first-order method and derive the famous linear combination that boosts its accuracy to second order. Furthermore, this exercise addresses the critical question of stability, demonstrating that this post-processing technique can enhance accuracy without sacrificing the robust stability of the underlying base method, such as backward Euler. ",
            "id": "3440894",
            "problem": "Consider a linear, dissipative semi-discrete evolution system arising from the method of lines applied to a linear parabolic partial differential equation (PDE), written as $U^{\\prime}(t)=A\\,U(t)+G(t)$, where $A$ is a time-independent matrix with spectrum contained in the closed left half-plane and $G(t)$ is a sufficiently smooth forcing. Let $u(t)$ denote the exact solution of this ordinary differential equation (ODE) initial-value problem at time $t$, and $U_{\\Delta t}(t^{n+1})$ denote the fully discrete approximation produced by a single backward Euler step of size $\\Delta t$ from time $t^{n}$ to $t^{n+1}=t^{n}+\\Delta t$. Likewise, let $U_{\\Delta t/2}(t^{n+1})$ denote the result of two consecutive backward Euler steps of size $\\Delta t/2$ advancing from $t^{n}$ to $t^{n+1}$. Assume the global error model at time $t^{n+1}$ for backward Euler has the asymptotic expansion $U_{\\Delta t}(t^{n+1})=u(t^{n+1})+C(t^{n+1})\\,\\Delta t+\\mathcal{O}((\\Delta t)^{2})$ with a bounded coefficient $C(t)$ that is independent of $\\Delta t$.\n\nUsing only the information above, construct an extrapolated estimate at time $t^{n+1}$ as a linear combination $\\widehat{U}(t^{n+1})=a\\,U_{\\Delta t/2}(t^{n+1})+b\\,U_{\\Delta t}(t^{n+1})$ whose truncation error in time is $\\mathcal{O}((\\Delta t)^{2})$. Your construction must start from the given error model and enforce consistency with $u(t^{n+1})$ while eliminating the $\\mathcal{O}(\\Delta t)$ term. Then, justify from first principles why this extrapolated estimate preserves the unconditional stability characteristics of backward Euler in the sense that, for a norm $|\\!|\\cdot|\\!|$ under which the backward Euler method is unconditionally stable for this dissipative linear system, the postprocessed estimate satisfies a bound of the form $|\\!|\\,\\widehat{U}(t^{n+1})\\,|\\!|\\leq K\\,|\\!|\\,U^{n}\\,|\\!|$ where $K$ is a constant independent of $\\Delta t$ and of the spectrum of $A$.\n\nProvide, as your final answer, the explicit algebraic expression for $\\widehat{U}(t^{n+1})$ in terms of $U_{\\Delta t/2}(t^{n+1})$ and $U_{\\Delta t}(t^{n+1})$. Do not include any inequalities or bounds in your final answer. Your final answer must be a single closed-form analytic expression. No rounding is required.",
            "solution": "We begin from the stated global error model for backward Euler at time $t^{n+1}$:\n$$\nU_{\\Delta t}(t^{n+1})=u(t^{n+1})+C(t^{n+1})\\,\\Delta t+\\mathcal{O}((\\Delta t)^{2}),\n$$\nwhere $C(t)$ is bounded and independent of $\\Delta t$. Applying the same model to the step size $\\Delta t/2$ and using that two steps of size $\\Delta t/2$ advance from $t^{n}$ to $t^{n+1}$, we obtain\n$$\nU_{\\Delta t/2}(t^{n+1})=u(t^{n+1})+C(t^{n+1})\\,\\frac{\\Delta t}{2}+\\mathcal{O}((\\Delta t)^{2}).\n$$\nMore precisely, assuming smoothness so that the global errors admit an asymptotic series, we may write\n$$\nU_{\\Delta t}(t^{n+1})=u(t^{n+1})+C(t^{n+1})\\,\\Delta t+D(t^{n+1})\\,(\\Delta t)^{2}+\\mathcal{O}((\\Delta t)^{3}),\n$$\n$$\nU_{\\Delta t/2}(t^{n+1})=u(t^{n+1})+C(t^{n+1})\\,\\frac{\\Delta t}{2}+D(t^{n+1})\\,\\frac{(\\Delta t)^{2}}{4}+\\mathcal{O}((\\Delta t)^{3}),\n$$\nwith bounded, $\\Delta t$-independent coefficients $C(t)$ and $D(t)$ that depend only on the solution and its derivatives at $t^{n+1}$.\n\nWe seek a linear combination\n$$\n\\widehat{U}(t^{n+1})=a\\,U_{\\Delta t/2}(t^{n+1})+b\\,U_{\\Delta t}(t^{n+1})\n$$\nthat is consistent and eliminates the $\\mathcal{O}(\\Delta t)$ term. Substituting the expansions gives\n\\begin{align*}\n\\widehat{U}(t^{n+1})&=a\\left(u(t^{n+1})+C\\,\\frac{\\Delta t}{2}+D\\,\\frac{(\\Delta t)^{2}}{4}+\\mathcal{O}((\\Delta t)^{3})\\right)+b\\left(u(t^{n+1})+C\\,\\Delta t+D\\,(\\Delta t)^{2}+\\mathcal{O}((\\Delta t)^{3})\\right)\\\\\n&=(a+b)\\,u(t^{n+1})+C\\,\\Delta t\\left(\\frac{a}{2}+b\\right)+D\\,(\\Delta t)^{2}\\left(\\frac{a}{4}+b\\right)+\\mathcal{O}((\\Delta t)^{3}).\n\\end{align*}\nFor consistency with $u(t^{n+1})$, we require\n$$\na+b=1.\n$$\nTo eliminate the first-order term, we require\n$$\n\\frac{a}{2}+b=0.\n$$\nSolving this linear system, the second equation gives $a=-2b$, which substituted into the first yields $-2b+b=1$, hence $b=-1$ and $a=2$. Therefore,\n$$\n\\widehat{U}(t^{n+1})=2\\,U_{\\Delta t/2}(t^{n+1})-U_{\\Delta t}(t^{n+1}).\n$$\nThe remaining truncation error is obtained by substituting $a=2$ and $b=-1$ into the coefficient of $(\\Delta t)^{2}$:\n$$\nD\\,(\\Delta t)^{2}\\left(\\frac{a}{4}+b\\right)=D\\,(\\Delta t)^{2}\\left(\\frac{2}{4}-1\\right)=-\\frac{1}{2}\\,D\\,(\\Delta t)^{2},\n$$\nso the extrapolated estimate has error $\\mathcal{O}((\\Delta t)^{2})$, as required.\n\nWe now justify that this postprocessing preserves unconditional stability properties of the backward Euler base method. For the linear test equation $y^{\\prime}=\\lambda\\,y$ with $\\operatorname{Re}(\\lambda)\\leq 0$, backward Euler has amplification factor\n$$\ng(z)=\\frac{1}{1-z},\\quad z=\\lambda\\,\\Delta t,\n$$\nwhich satisfies $|g(z)|\\leq 1$ for all $z$ with $\\operatorname{Re}(z)\\leq 0$, since $|1-z|=\\sqrt{(1-\\operatorname{Re}(z))^{2}+(\\operatorname{Im}(z))^{2}}\\geq |1-\\operatorname{Re}(z)|\\geq 1$. This is the defining property of algebraic stability for this scalar model and represents unconditional stability.\n\nFor the linear system $U^{\\prime}=A\\,U+G(t)$ with $A$ generating a contractive semigroup in an appropriate energy norm $|\\!|\\cdot|\\!|$, the backward Euler update $(I-\\Delta t\\,A)U^{n+1}=U^{n}+\\Delta t\\,G^{n+1}$ is unconditionally stable: there exists a constant $M$ independent of $\\Delta t$ and of the spectrum of $A$ such that\n$$\n|\\!|\\,U_{\\Delta t}(t^{n+1})\\,|\\!|\\leq M\\left(|\\!|\\,U^{n}\\,|\\!|+\\int_{t^{n}}^{t^{n+1}}|\\!|\\,G(s)\\,|\\!|\\,\\mathrm{d}s\\right),\n$$\nand the same bound holds for the two half-steps producing $U_{\\Delta t/2}(t^{n+1})$. The extrapolated estimate is a linear postprocessing of these two stable approximations. By the triangle inequality,\n\\begin{align*}\n|\\!|\\,\\widehat{U}(t^{n+1})\\,|\\!|&=|\\!|\\,2\\,U_{\\Delta t/2}(t^{n+1})-U_{\\Delta t}(t^{n+1})\\,|\\!|\\\\\n&\\leq 2\\,|\\!|\\,U_{\\Delta t/2}(t^{n+1})\\,|\\!|+|\\!|\\,U_{\\Delta t}(t^{n+1})\\,|\\!|\\\\\n&\\leq (2\\,M+M)\\left(|\\!|\\,U^{n}\\,|\\!|+\\int_{t^{n}}^{t^{n+1}}|\\!|\\,G(s)\\,|\\!|\\,\\mathrm{d}s\\right)\\\\\n&=3\\,M\\left(|\\!|\\,U^{n}\\,|\\!|+\\int_{t^{n}}^{t^{n+1}}|\\!|\\,G(s)\\,|\\!|\\,\\mathrm{d}s\\right).\n\\end{align*}\nThus the extrapolated estimate inherits an unconditional stability bound with a constant factor $K=3\\,M$ that is independent of $\\Delta t$ and of the spectrum of $A$. This shows that the accuracy enhancement via Richardson extrapolation is achieved without sacrificing the unconditional stability character of the backward Euler base integrator, since the postprocessing does not alter the evolution step itself and yields a uniformly bounded estimate.\n\nTherefore, the desired second-order, stability-preserving extrapolated estimate at time $t^{n+1}$ is\n$$\n\\widehat{U}(t^{n+1})=2\\,U_{\\Delta t/2}(t^{n+1})-U_{\\Delta t}(t^{n+1}).\n$$",
            "answer": "$$\\boxed{2\\,U_{\\Delta t/2}(t^{n+1})-U_{\\Delta t}(t^{n+1})}$$"
        },
        {
            "introduction": "While our first exercise showed that extrapolating an unconditionally stable method preserves stability, this practice explores the more nuanced case of a conditionally stable scheme. By applying Richardson extrapolation to the forward Euler method for the heat equation, you will perform a von Neumann stability analysis to determine the exact stability limit of the combined, higher-order method. This will reveal how the quest for higher accuracy interacts with the practical constraints on the time step. ",
            "id": "3440884",
            "problem": "Consider the one-dimensional linear diffusion partial differential equation (PDE) $u_{t} = \\nu u_{xx}$ with constant diffusivity $\\nu > 0$ on the periodic domain $x \\in [0, 2\\pi]$. Let the spatial derivative be approximated by second-order central differences on a uniform grid with $N$ points and grid spacing $h = \\frac{2\\pi}{N}$, resulting in the semi-discrete system $u_{t} = \\nu L u$, where $L$ is the discrete Laplacian matrix. The discrete Fourier modes are eigenvectors of $L$ with corresponding eigenvalues $\\lambda_{k} = -\\frac{4}{h^{2}} \\sin^{2}\\!\\left(\\frac{k h}{2}\\right)$ for $k \\in \\{0, 1, \\dots, N-1\\}$ (so that the spectrum of $\\nu L$ lies on the negative real axis).\n\nLet the time advance over one macrostep of size $\\Delta t$ be performed using the explicit forward Euler method (which is an explicit Runge–Kutta method), and let a Richardson extrapolation be constructed to enhance accuracy by combining one forward Euler step of size $\\Delta t$ with two successive forward Euler half-steps of size $\\Delta t/2$ to eliminate the leading global error term. The extrapolated solution at time $t^{n+1} = t^{n} + \\Delta t$ is defined as a weighted linear combination of these two approximations chosen to cancel the leading error term in $\\Delta t$.\n\nStarting from the semi-discrete linear model and the scalar test equation $y' = \\lambda y$ with $\\lambda \\in \\mathbb{R}$ and $\\lambda \\le 0$ representing an eigenvalue of $\\nu L$, derive the amplification factor of the Richardson-extrapolated method applied over one macrostep. Then, by imposing the linear stability condition on the negative real axis of the complex plane, determine the exact largest admissible time step $\\Delta t_{\\max}$ ensuring stability for all eigenvalues of $\\nu L$ produced by the second-order central difference spatial discretization of the diffusion operator on this periodic grid.\n\nProvide your final answer as a single closed-form expression for $\\Delta t_{\\max}$ in terms of $h$ and $\\nu$. No rounding is required.",
            "solution": "The problem requires finding the maximum stable time step, $\\Delta t_{\\max}$, for a one-dimensional diffusion equation solved numerically. The method involves a second-order central difference spatial discretization and a time-stepping scheme based on Richardson extrapolation of the forward Euler method.\n\nThe process begins with an analysis of the time-stepping method using the scalar test equation $y' = \\lambda y$, where $\\lambda \\le 0$ represents an eigenvalue of the semi-discretized spatial operator $\\nu L$.\n\nThe Richardson extrapolation scheme, designed to enhance the accuracy of the first-order forward Euler method, combines two numerical approximations of the solution at time $t^{n+1} = t^n + \\Delta t$.\nThe first approximation, $y_1$, is obtained using a single forward Euler step of size $\\Delta t$:\n$$y_1 = (1 + \\lambda \\Delta t) y_n$$\nThe second approximation, $y_2$, is obtained using two successive forward Euler steps, each of size $\\Delta t / 2$:\n$$y_2 = \\left(1 + \\lambda \\frac{\\Delta t}{2}\\right)^2 y_n$$\n\nSince the forward Euler method is first-order accurate (order $p=1$), the extrapolated solution, $y_{extrap}$, is a linear combination of $y_1$ and $y_2$ given by the formula:\n$$y_{extrap} = \\frac{2^p y_2 - y_1}{2^p - 1} = \\frac{2y_2 - y_1}{2-1} = 2y_2 - y_1$$\nSubstituting the expressions for $y_1$ and $y_2$ into this formula yields:\n$$y_{extrap} = \\left[ 2 \\left(1 + \\lambda \\frac{\\Delta t}{2}\\right)^2 - (1 + \\lambda \\Delta t) \\right] y_n$$\nThe amplification factor for the extrapolated method, $R_{RE}(z)$, is the term in the square brackets, where we define $z = \\lambda \\Delta t$.\n$$R_{RE}(z) = 2 \\left(1 + \\frac{z}{2}\\right)^2 - (1 + z)$$\nWe expand this expression to find the explicit form of the amplification factor:\n$$R_{RE}(z) = 2 \\left(1 + z + \\frac{z^2}{4}\\right) - 1 - z = 2 + 2z + \\frac{z^2}{2} - 1 - z$$\n$$R_{RE}(z) = 1 + z + \\frac{z^2}{2}$$\nThis polynomial is a second-order approximation to the exact amplification factor $e^z = 1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\dots$, confirming that the Richardson extrapolation has successfully produced a second-order accurate method.\n\nFor the method to be stable, the magnitude of the amplification factor must be less than or equal to $1$ for all relevant eigenvalues. The stability condition is $|R_{RE}(z)| \\le 1$.\nThe eigenvalues of the operator $\\nu L$ are $\\mu_k = \\nu \\lambda_k$, where $\\lambda_k = -\\frac{4}{h^2} \\sin^2(\\frac{kh}{2})$. Since $\\nu > 0$ and $\\lambda_k \\le 0$, the values of $\\mu_k$ are real and non-positive. Consequently, $z = \\mu_k \\Delta t$ is a non-positive real number. We can write $z = -x$ where $x = -\\mu_k \\Delta t \\ge 0$.\nThe stability condition becomes:\n$$|R_{RE}(-x)| \\le 1 \\implies \\left|1 - x + \\frac{x^2}{2}\\right| \\le 1$$\nThis inequality is equivalent to the system:\n$$-1 \\le 1 - x + \\frac{x^2}{2} \\le 1$$\nWe analyze each part of the inequality for $x \\ge 0$:\n1.  The right-hand inequality: $1 - x + \\frac{x^2}{2} \\le 1$. This simplifies to $\\frac{x^2}{2} - x \\le 0$, or $x(\\frac{x}{2} - 1) \\le 0$. Since $x \\ge 0$, this requires $\\frac{x}{2} - 1 \\le 0$, which gives $x \\le 2$. So, this part restricts $x$ to the interval $[0, 2]$.\n2.  The left-hand inequality: $-1 \\le 1 - x + \\frac{x^2}{2}$. This simplifies to $0 \\le 2 - x + \\frac{x^2}{2}$, or $x^2 - 2x + 4 \\ge 0$. The discriminant of the quadratic $x^2 - 2x + 4$ is $\\Delta = (-2)^2 - 4(1)(4) = -12$. Since the discriminant is negative and the leading coefficient is positive, the quadratic is always positive. Thus, this inequality holds for all real $x$.\n\nCombining both results, the stability region for the method along the negative real axis is $x \\in [0, 2]$.\n\nThe stability of the numerical solution for the PDE requires this condition to hold for all modes $k$. This means $x_k = -\\mu_k \\Delta t \\le 2$ must be satisfied for all $k$. The most restrictive constraint comes from the eigenvalue with the largest magnitude.\n$$x_{\\max} = \\max_k(-\\mu_k \\Delta t) = \\Delta t \\max_k(-\\nu \\lambda_k) = \\nu \\Delta t \\max_k(-\\lambda_k) \\le 2$$\nWe need to find the maximum value of $-\\lambda_k = \\frac{4}{h^2} \\sin^2(\\frac{kh}{2})$. The maximum value of $\\sin^2(\\cdot)$ is $1$. This value is attained when its argument is $\\pi/2$. The argument is $\\frac{kh}{2} = \\frac{k(2\\pi/N)}{2} = \\frac{k\\pi}{N}$. For $k = N/2$ (assuming $N$ is even), the argument is $\\pi/2$, so the maximum is indeed reached.\n$$\\max_k(-\\lambda_k) = \\frac{4}{h^2}$$\nSubstituting this into the stability inequality:\n$$\\nu \\Delta t \\left(\\frac{4}{h^2}\\right) \\le 2$$\nFinally, we solve for $\\Delta t$ to find the maximum permissible step size:\n$$\\Delta t \\le \\frac{2h^2}{4\\nu} = \\frac{h^2}{2\\nu}$$\nTherefore, the largest admissible time step for stability is:\n$$\\Delta t_{\\max} = \\frac{h^2}{2\\nu}$$",
            "answer": "$$\\boxed{\\frac{h^2}{2\\nu}}$$"
        },
        {
            "introduction": "The power of Richardson extrapolation hinges on a crucial assumption: that the numerical error has a regular, power-law dependence on the step size $h$. This final practice challenges you to think beyond this ideal scenario by considering a problem with a sharp boundary layer, where the error is dominated by its poor resolution rather than a simple power of $h$. Your task is to derive a modified scaling law for the extrapolation, demonstrating that the principles of error cancellation can be adapted even when the standard formula does not apply. ",
            "id": "3440892",
            "problem": "Consider the steady one-dimensional advection–diffusion boundary value problem whose exact solution exhibits a boundary layer at the inflow boundary. In the inner layer, the solution is well approximated by the boundary layer profile $u(x)=1-\\exp(-x/\\epsilon)$, where $\\epsilon>0$ is the diffusion-strength parameter controlling the layer thickness. A common practice in numerical solution of partial differential equations is to employ two-level Richardson extrapolation, which presumes a leading-order error model of the form $Q(h)=Q+C h^{p}$ for a quantity of interest $Q$, grid spacing $h$, constant $C$, and method order $p$. \n\nIn the presence of a boundary layer, the assumption that the leading error is a power series in $h$ can break down when $h$ is not much smaller than $\\epsilon$. Specifically, the under-resolution of the boundary layer over one grid interval $[0,h]$ introduces a leading error contribution that is proportional to the layer amplitude missed within the first cell. For the profile $u(x)=1-\\exp(-x/\\epsilon)$, this amplitude over a single grid step is the difference $u(h)-u(0)$.\n\nAssume that, for a consistent spatial discretization of the advection–diffusion operator with a Dirichlet boundary at $x=0$, the dominant discretization error in a boundary-layer-dominated quantity of interest $Q$ at mesh size $h$ is proportional to $u(h)-u(0)$, and the same proportionality applies at mesh size $h/2$. Under this model, two-level Richardson extrapolation should replace the scaling factor $2^{p}$ by a factor determined by the ratio of the leading errors at $h$ and $h/2$.\n\nDerive, in closed form, the modified scaling law $r(h,\\epsilon)$ that should replace $2^{p}$ in the two-level Richardson extrapolation formula when the leading error is governed by the unresolved boundary layer amplitude over a grid step. Your final answer must be the single analytic expression for $r(h,\\epsilon)$ with no units.",
            "solution": "The problem requires the derivation of a modified scaling law for two-level Richardson extrapolation, applicable to a numerical method whose dominant error is governed by the under-resolution of an exponential boundary layer.\n\nStandard two-level Richardson extrapolation is based on an assumed asymptotic error expansion for a quantity of interest, $Q$, approximated by a numerical method with grid spacing $h$. Let $Q(h)$ be the numerical approximation. The error model is typically a power series in $h$:\n$$Q(h) = Q + C h^{p} + \\mathcal{O}(h^q)$$\nwhere $Q$ is the exact value, $C$ is a constant independent of $h$, $p$ is the order of the method, and $q > p$.\n\nFor two grid levels, with spacings $h$ and $h/2$, we have the approximations:\n$$Q(h) \\approx Q + C h^{p}$$\n$$Q(h/2) \\approx Q + C \\left(\\frac{h}{2}\\right)^{p} = Q + C \\frac{h^{p}}{2^{p}}$$\n\nThe leading-order errors are $E(h) = Q(h) - Q \\approx C h^{p}$ and $E(h/2) = Q(h/2) - Q \\approx C h^{p}/2^{p}$. The ratio of these errors defines the scaling factor used in extrapolation:\n$$\\frac{E(h)}{E(h/2)} \\approx \\frac{C h^{p}}{C h^{p} / 2^{p}} = 2^{p}$$\nThe extrapolated solution, which eliminates the leading error term, is given by:\n$$Q_{extrap} = \\frac{2^{p} Q(h/2) - Q(h)}{2^{p} - 1}$$\n\nThe problem states that this standard error model is invalid due to the under-resolution of a boundary layer. Instead, the leading error is proportional to the unresolved amplitude of the boundary layer profile over the first grid cell. Let $K$ be the constant of proportionality. The errors at grid spacings $h$ and $h/2$ are given by:\n$$E(h) = K [u(h) - u(0)]$$\n$$E(h/2) = K [u(h/2) - u(0)]$$\nwhere the boundary layer profile is specified as $u(x) = 1 - \\exp(-x/\\epsilon)$.\n\nThe modified scaling law, which we denote by $r(h,\\epsilon)$, replaces the factor $2^{p}$. It is determined by the ratio of the actual leading errors:\n$$r(h, \\epsilon) = \\frac{E(h)}{E(h/2)} = \\frac{K [u(h) - u(0)]}{K [u(h/2) - u(0)]}$$\nThe proportionality constant $K$ cancels, yielding:\n$$r(h, \\epsilon) = \\frac{u(h) - u(0)}{u(h/2) - u(0)}$$\n\nWe now substitute the given functional form for $u(x)$ into this expression. First, we evaluate the function at the required points:\nAt $x=0$:\n$$u(0) = 1 - \\exp(-0/\\epsilon) = 1 - \\exp(0) = 1 - 1 = 0$$\nAt $x=h$:\n$$u(h) = 1 - \\exp(-h/\\epsilon)$$\nAt $x=h/2$:\n$$u(h/2) = 1 - \\exp\\left(-\\frac{h/2}{\\epsilon}\\right) = 1 - \\exp\\left(-\\frac{h}{2\\epsilon}\\right)$$\n\nSubstituting these values into the expression for $r(h, \\epsilon)$:\n$$r(h, \\epsilon) = \\frac{(1 - \\exp(-h/\\epsilon)) - 0}{(1 - \\exp(-h/(2\\epsilon))) - 0} = \\frac{1 - \\exp(-h/\\epsilon)}{1 - \\exp(-h/(2\\epsilon))}$$\n\nTo simplify this expression, we recognize that the numerator is a difference of squares. Let $y = \\exp(-h/(2\\epsilon))$. Then $y^2 = (\\exp(-h/(2\\epsilon)))^2 = \\exp(-h/\\epsilon)$. The expression becomes:\n$$r(h, \\epsilon) = \\frac{1 - y^2}{1 - y}$$\nFactoring the numerator, $1 - y^2 = (1 - y)(1 + y)$, we get:\n$$r(h, \\epsilon) = \\frac{(1 - y)(1 + y)}{1 - y}$$\nFor $h \\neq 0$, $y = \\exp(-h/(2\\epsilon)) \\neq 1$, so the term $(1 - y)$ is non-zero and can be cancelled from the numerator and denominator.\n$$r(h, \\epsilon) = 1 + y$$\n\nSubstituting the expression for $y$ back, we obtain the final closed-form expression for the modified scaling law:\n$$r(h, \\epsilon) = 1 + \\exp\\left(-\\frac{h}{2\\epsilon}\\right)$$\nThis is the factor that must replace $2^{p}$ in the Richardson extrapolation formula under the specified error model.",
            "answer": "$$ \\boxed{1 + \\exp\\left(-\\frac{h}{2\\epsilon}\\right)} $$"
        }
    ]
}