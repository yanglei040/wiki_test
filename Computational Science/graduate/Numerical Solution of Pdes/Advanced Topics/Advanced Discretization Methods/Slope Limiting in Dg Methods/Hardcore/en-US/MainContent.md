## Introduction
The Discontinuous Galerkin (DG) method is a highly successful numerical technique for [solving partial differential equations](@entry_id:136409), prized for its ability to achieve [high-order accuracy](@entry_id:163460) on complex geometries. However, this power comes with a significant challenge: when applied to problems with discontinuities, such as shock waves in [hyperbolic conservation laws](@entry_id:147752), high-order DG schemes produce non-physical, spurious oscillations. These oscillations, a manifestation of the Gibbs phenomenon, can corrupt the solution and lead to instability. The critical knowledge gap, therefore, is how to suppress these oscillations to ensure the numerical solution is both stable and physically realistic, without sacrificing the method's [high-order accuracy](@entry_id:163460) in smooth regions.

This article provides a detailed exploration of **[slope limiting](@entry_id:754953)**, the primary family of techniques developed to solve this problem. Across the following sections, you will gain a robust understanding of both the theory and practice of these essential numerical tools.
- The section on **Principles and Mechanisms** will lay the theoretical groundwork, explaining why oscillations arise and detailing the core design principles of conservation and stability that every limiter must follow.
- In **Applications and Interdisciplinary Connections**, we will see how these fundamental ideas are adapted to solve complex problems in fluid dynamics, [magnetohydrodynamics](@entry_id:264274), and geophysical flows, and discover surprising connections to fields like [image processing](@entry_id:276975) and [optimal control](@entry_id:138479).
- Finally, the **Hands-On Practices** section offers concrete problems that allow you to implement and test these concepts, solidifying your understanding of how limiters work in practice.

## Principles and Mechanisms

The Discontinuous Galerkin (DG) method provides a powerful framework for developing high-order accurate numerical schemes for [hyperbolic conservation laws](@entry_id:147752). A key feature of the method is its use of a discontinuous, [piecewise polynomial](@entry_id:144637) representation of the solution. While this local representation provides great flexibility and facilitates [high-order accuracy](@entry_id:163460) on complex geometries, it also presents a significant challenge: the generation of non-physical oscillations, known as the Gibbs phenomenon, in the vicinity of discontinuities such as [shock waves](@entry_id:142404) or [contact discontinuities](@entry_id:747781). This chapter elucidates the principles and mechanisms of **[slope limiting](@entry_id:754953)**, a class of techniques designed to control these [spurious oscillations](@entry_id:152404), ensuring the stability and physical realism of the numerical solution.

### The Origin of Spurious Oscillations: The Gibbs Phenomenon

To understand why limiting is necessary, we must first examine how a high-order DG scheme interacts with discontinuous data. Consider the simple [linear advection equation](@entry_id:146245), $u_t + a u_x = 0$ with $a>0$, whose exact solution is the translation of the initial profile. If we begin with a step-function initial condition, the DG solution is initialized by performing a cell-wise $L^2$-projection of this [step function](@entry_id:158924) onto the space of polynomials of degree $p$.

In any cell where the initial data is constant, this projection is exact. However, in the single cell containing the [jump discontinuity](@entry_id:139886), the $L^2$-projection of the step function onto a basis of smooth polynomials (such as Legendre polynomials) inevitably produces oscillations. This is a manifestation of the **Gibbs phenomenon**. The approximation exhibits overshoots and undershoots near the jump, with a peak amplitude that is a fixed fraction of the jump height—an amount that does not decrease as the polynomial degree $p$ increases . For large $p$, the primary overshoot of the $L^2$ projection using Legendre polynomials approaches approximately 5% of the jump size.

The DG [semi-discretization](@entry_id:163562), when using a stable [numerical flux](@entry_id:145174) like the [upwind flux](@entry_id:143931), is an exceptionally stable transport operator. For the [linear advection equation](@entry_id:146245) on a periodic domain, it is even $L^2$-norm conservative. This means the scheme does not introduce significant [numerical dissipation](@entry_id:141318); instead, it faithfully transports the entire numerical solution profile, including the oscillatory artifacts generated by the initial projection . Consequently, at any later time, the numerical solution will consist of the advected step profile corrupted by spurious oscillations of $O(1)$ amplitude, localized within a few cells around the discontinuity. While the physical support of these oscillations shrinks as the mesh size $h$ is refined (scaling like $O(h)$), their amplitude persists, preventing [pointwise convergence](@entry_id:145914) to the true, non-oscillatory solution.

This behavior distinguishes the local nature of DG from global [spectral methods](@entry_id:141737). In a global Fourier approximation, the Gibbs phenomenon also produces an $O(1)$ overshoot (approximately 9% of the jump size), but the oscillations, while decaying away from the jump, pollute the entire domain due to the global support of the basis functions. In DG, the effect is strictly confined to the element containing the discontinuity, a direct consequence of the method's [local basis](@entry_id:151573) functions . To eliminate these persistent, localized oscillations, a [nonlinear control](@entry_id:169530) mechanism is required. This is the role of [slope limiting](@entry_id:754953).

### The Fundamental Principles of Slope Limiting

Slope limiting refers to a family of nonlinear, a posteriori modifications applied to the polynomial solution within each cell. The goal is to enforce stability by suppressing oscillations while respecting the fundamental structure of the conservation law. To be valid, any [slope limiter](@entry_id:136902) must adhere to two inviolable principles: it must be conservative, and it must enforce a suitable stability or [monotonicity](@entry_id:143760) property.

#### Conservation: The Primacy of the Cell Average

The cornerstone of any numerical method for a conservation law is the discrete preservation of the conserved quantity. The integral form of a conservation law, $u_t + f(u)_x = 0$, applied to a [control volume](@entry_id:143882) (or cell) $I_j = [x_{j-1/2}, x_{j+1/2}]$ states that the rate of change of the total amount of $u$ in the cell is equal to the net flux across its boundaries:
$$
\frac{d}{dt} \int_{x_{j-1/2}}^{x_{j+1/2}} u(x,t) \, dx = f(u(x_{j-1/2}, t)) - f(u(x_{j+1/2}, t))
$$
Dividing by the cell width $\Delta x_j$, we see that the evolution of the **cell average**, $\bar{u}_j(t)$, is governed purely by the fluxes at the cell interfaces.

The DG semi-discrete [weak form](@entry_id:137295) is designed to mimic this exactly for the cell average. By choosing the [constant function](@entry_id:152060) $\phi_h(x) = 1$ as the test function in the DG [weak formulation](@entry_id:142897), the term involving the derivative of the test function vanishes. The equation elegantly simplifies to an exact evolution equation for the numerical cell average, $\bar{u}_{h,j}$:
$$
\frac{d\bar{u}_{h,j}}{dt} + \frac{1}{\Delta x_j} \left( \hat{f}_{j+1/2} - \hat{f}_{j-1/2} \right) = 0
$$
where $\hat{f}_{j\pm1/2}$ are the numerical fluxes evaluated at the cell interfaces. This is a crucial result: it shows that the high-order DG method contains, at its core, a conservative finite volume scheme for the cell averages .

A [slope limiter](@entry_id:136902), $\mathcal{L}$, acts on the polynomial $u_h$ within a cell. For the overall scheme to remain conservative, the [limiter](@entry_id:751283) must not alter the cell average. If $\mathcal{L}$ were to change the integral of $u_h$ over the cell, it would be equivalent to introducing a non-physical source or sink term into the evolution of $\bar{u}_{h,j}$, thereby violating the conservation law. Therefore, the fundamental constraint on any [slope limiter](@entry_id:136902) is that it must **preserve the cell average** of the solution on each element  . All practical limiters are designed to satisfy this property by construction.

#### Stability: Enforcing Monotonicity and Maximum Principles

The second principle is that the [limiter](@entry_id:751283) must enforce stability by preventing the growth of new, [spurious oscillations](@entry_id:152404). This is often formalized as a **Discrete Maximum Principle (DMP)**. A local DMP states that the numerical solution in an element $K$ at the new time level, $u_h^{n+1}(x)$, should remain bounded by the minimum and maximum values of the solution in a local neighborhood at the previous time level, $t^n$ . For instance, a common requirement is:
$$
\min_{J \in \mathcal{N}(K)} \bar{u}_J^n \le u_h^{n+1}(x) \le \max_{J \in \mathcal{N}(K)} \bar{u}_J^n \quad \forall x \in K
$$
where $\mathcal{N}(K)$ is the set of element $K$ and its face neighbors.

To achieve this, limiters typically work by scaling the high-order content of the solution. The polynomial solution $u_h$ in a cell $K$ can be written as the sum of its average $\bar{u}_K$ and its deviation from the average, $u_h'(x) = u_h(x) - \bar{u}_K$. A common limiting strategy is to scale this deviation:
$$
u_h^{\text{lim}}(x) = \bar{u}_K + \theta_K (u_h(x) - \bar{u}_K), \quad \text{with } \theta_K \in [0, 1]
$$
This form automatically preserves the cell average since the integral of the deviation $u_h'$ is zero. The scaling factor $\theta_K$ is chosen to be the largest value in $[0, 1]$ that ensures the limited polynomial $u_h^{\text{lim}}$ satisfies the desired DMP bounds. If the original polynomial already satisfies the bounds, $\theta_K=1$ is chosen, and the high-order representation is retained. If the bounds are violated, $\theta_K  1$ is chosen, effectively "flattening" the polynomial towards its mean value. In the most extreme case, $\theta_K = 0$, which reduces the solution in the cell to a constant, corresponding to a first-order reconstruction . This algebraic "clipping" of the polynomial at extrema is the key mechanism by which limiters control oscillations .

When such a procedure is applied to a piecewise linear DG scheme ($p=1$) using a specific [limiter](@entry_id:751283) like the `[minmod](@entry_id:752001)` function, combined with a monotone [numerical flux](@entry_id:145174) and an appropriate time step, the resulting scheme can be proven to be **Total Variation Diminishing (TVD)** for scalar problems. A TVD scheme, by definition, does not create new [local extrema](@entry_id:144991), providing a rigorous guarantee of non-oscillatory behavior .

### Mechanisms of Slope Limiting in Practice

The abstract principles of conservation and stability are realized through concrete algorithms. The specific implementation depends on the polynomial degree, the dimension, and the geometry of the mesh elements.

#### A Prototypical Example: The `[minmod](@entry_id:752001)` Limiter for Linear Elements

For a DG scheme with piecewise linear polynomials ($p=1$) in one dimension, the solution in cell $I_i$ is $u_h(x) = \bar{u}_i + s_i(x-x_i)$, where $\bar{u}_i$ is the cell average and $s_i$ is the slope. A DMP can be enforced by ensuring that the reconstructed values at the cell boundaries, $u_h(x_{i\pm1/2})$, do not create new extrema relative to the neighboring cell averages.

The **`[minmod](@entry_id:752001)` limiter** is a classic tool for this purpose . It modifies the slope $s_i$ to a new slope $\tilde{s}_i$ by comparing the original slope with the slopes implied by the neighboring data. A common form is:
$$
\tilde{s}_i = \operatorname{minmod}\left(s_i, \frac{\bar{u}_{i+1}-\bar{u}_i}{\Delta x}, \frac{\bar{u}_i-\bar{u}_{i-1}}{\Delta x}\right)
$$
The generalized `[minmod](@entry_id:752001)` function is defined as:
$$
\operatorname{minmod}(a,b,c) = \begin{cases} \operatorname{sign}(a)\,\min(|a|,|b|,|c|),   \text{if } \operatorname{sign}(a)=\operatorname{sign}(b)=\operatorname{sign}(c) \\ 0,   \text{otherwise} \end{cases}
$$
This limiter selects the smallest (in magnitude) of the three slopes if they all have the same sign. If the signs differ—which indicates that $\bar{u}_i$ is a local extremum in the cell-average data—it returns a slope of zero, flattening the reconstruction to a constant. This procedure guarantees that the reconstructed values at the interfaces remain bounded by the neighboring averages, thereby preventing the creation of new oscillations, all while preserving the cell average $\bar{u}_i$.

#### Extension to Multiple Dimensions: The Barth-Jespersen Limiter

In multiple dimensions, on simplicial meshes (triangles or tetrahedra), a linear polynomial's [extrema](@entry_id:271659) over an element are guaranteed to occur at its vertices. The **Barth-Jespersen limiter** leverages this geometric fact .

The procedure is analogous to the 1D case. For each element $K$, one first defines the allowable range for the solution based on the cell averages of its neighbors, $[u_{\min,K}, u_{\max,K}]$. Then, one computes the values of the unlimited polynomial $u_h$ at each of its vertices. If any vertex value falls outside the allowable range, the gradient of the polynomial, $\nabla u_K$, is scaled by a single factor $\alpha_K \in [0,1]$:
$$
\nabla u_K^{\text{lim}} = \alpha_K \nabla u_K
$$
The factor $\alpha_K$ is chosen to be the largest possible value that brings all vertex values of the modified polynomial just inside the bounds $[u_{\min,K}, u_{\max,K}]$. This uniform scaling of the gradient preserves the cell average and enforces the DMP over the entire element by controlling its values at the geometrically critical vertex points.

#### Interaction with Time Integration: SSP Methods

Limiters are nonlinear operators. Their interaction with the [time integration](@entry_id:170891) scheme is critical for stability. For [explicit time-stepping](@entry_id:168157), **Strong Stability Preserving (SSP)** Runge-Kutta methods are ubiquitously used. An SSP method can be decomposed into a convex combination of forward Euler steps. This structure guarantees that if the forward Euler step (combined with the [limiter](@entry_id:751283)) is stable in some sense (e.g., it satisfies a DMP or is TVD), then the full high-order SSP-RK method will also preserve that stability property .

This has a crucial practical implication: the [slope limiter](@entry_id:136902) must be applied after **each stage** of the SSP Runge-Kutta method. Applying the [limiter](@entry_id:751283) only once at the end of a full time step is not sufficient to guarantee stability .

### Advanced Topics and Applications

The basic principles of limiting can be extended to handle more complex physical systems and to satisfy more refined stability criteria.

#### Limiting for Systems of Equations: From Component-wise to Characteristic-wise

When applying DG to [systems of conservation laws](@entry_id:755768), such as the Euler equations of gas dynamics, a naive approach is **component-wise limiting**: applying a scalar [limiter](@entry_id:751283) independently to each conservative variable ($\rho, \rho u, E$) . This approach is simple to implement but has a severe physical flaw. Physical admissibility constraints, like the positivity of pressure $p = (\gamma-1)(E - \frac{(\rho u)^2}{2\rho})$, are nonlinear functions of the conservative variables. The set of admissible states is not convex. Applying independent, linear-style limiting operations to each component does not guarantee that the resulting [state vector](@entry_id:154607) will remain in this non-convex admissible set. It is common for component-wise limiting to produce states with non-physical [negative pressure](@entry_id:161198) or density.

A physically more sophisticated approach is **[characteristic-wise limiting](@entry_id:747272)**. This method first projects the polynomial's deviation from the mean onto the basis of [characteristic variables](@entry_id:747282), which are associated with the distinct wave families of the hyperbolic system (e.g., sound waves and entropy waves). This is achieved by using the left eigenvectors of the flux Jacobian evaluated at the cell average. A scalar limiter is then applied to each of these characteristic components independently. Finally, the limited [characteristic variables](@entry_id:747282) are transformed back to conservative variables using the right eigenvectors. By aligning the limiting process with the physics of wave propagation, this method reduces spurious coupling between different physical fields and is far more robust in maintaining physical admissibility than component-wise limiting .

#### Enforcing Physical Constraints: Positivity-Preserving Limiters for the Euler Equations

Even [characteristic-wise limiting](@entry_id:747272) does not offer an absolute guarantee of positivity for the Euler equations . To achieve rigorous positivity, specialized limiters are required. A powerful technique involves a final scaling correction, similar in spirit to the DMP limiter.

The goal is to enforce $\rho > 0$ and $p > 0$ at all quadrature points within a cell, while preserving the cell average of the conservative state vector $\mathbf{U} = (\rho, \rho\mathbf{u}, E)$. One constructs a scaling [limiter](@entry_id:751283) of the form $\mathbf{U}_h^{\text{new}} = \overline{\mathbf{U}} + \theta(\mathbf{U}_h - \overline{\mathbf{U}})$ with a single scaling factor $\theta \in [0, 1]$. One then determines the constraints on $\theta$ imposed by positivity at each quadrature point .
1.  **Density:** The condition $\rho_i^{\text{new}} \ge \varepsilon_\rho  0$ leads to a [linear inequality](@entry_id:174297) for $\theta$.
2.  **Pressure:** The condition $p(\mathbf{U}_i^{\text{new}}) \ge \varepsilon_p  0$ is more complex. Substituting the scaled state into the formula for pressure results in a **quadratic inequality** for $\theta$. The function of pressure is concave in $\theta$, and one can find the unique root $\theta_{p,i} \in (0,1)$ that makes the pressure exactly $\varepsilon_p$. The condition is satisfied for any $\theta \le \theta_{p,i}$.

The final, global scaling factor $\theta$ for the cell is then chosen as the minimum of all the [upper bounds](@entry_id:274738) derived from the density and pressure constraints at all quadrature points. This ensures all positivity constraints are met simultaneously.

#### A Refined Stability Criterion: Entropy and Slope Limiting

Beyond maximum principles, a deeper stability requirement for solutions to conservation laws is the **Lax [entropy inequality](@entry_id:184404)**, which states that for any [convex function](@entry_id:143191) $\eta(u)$ (an "entropy"), the total amount of entropy in the domain must not increase over time. This selects the physically relevant weak solution from among the infinitely many possible ones.

DG schemes can be designed to be **entropy stable** by using specific numerical fluxes. The question then arises: does the application of a [slope limiter](@entry_id:136902) preserve this property? For the common scaling [limiter](@entry_id:751283), $u_h^{L} = \bar{u}_K + \theta_K(u_h - \bar{u}_K)$ with $\theta_K \in [0,1]$, the answer is yes. By Jensen's inequality for [convex functions](@entry_id:143075), the integral of the entropy over the cell is guaranteed to not increase after limiting:
$$
\int_K \eta(u_h^L) \, dx \le \int_K \eta(u_h) \, dx
$$
This means that this form of limiting is compatible with the [entropy stability](@entry_id:749023) of the underlying scheme; it either preserves or enhances the rate of entropy dissipation .

#### Balance Laws and Well-Balanced Limiting

Many physical problems are modeled by **balance laws**, which include a [source term](@entry_id:269111): $u_t + f(u)_x = s(u,x)$. For such systems, it is often crucial that the numerical scheme can exactly preserve certain non-trivial [steady-state solutions](@entry_id:200351), where the flux gradient perfectly balances the [source term](@entry_id:269111) (e.g., the "lake-at-rest" state in the [shallow water equations](@entry_id:175291)). A scheme with this property is called **well-balanced**.

A standard [slope limiter](@entry_id:136902) is "unaware" of this delicate balance. It may mistake the non-constant profile of a [steady-state solution](@entry_id:276115) for a numerical oscillation and attempt to flatten it. This act of limiting breaks the balance, creating a non-zero residual and generating spurious, unphysical waves. For a limiter to preserve a discrete steady state, it must act as the identity on that state .

A powerful and widely used strategy to create a **well-balanced limiter** is to decompose the solution $u_h$ into a known discrete equilibrium part $u_h^\star$ and a perturbation $\tilde{u}_h$. The [limiter](@entry_id:751283) is then applied only to the perturbation part, $\tilde{u}_h$. If the solution is already at the steady state, the perturbation is zero, the limiter does nothing, and the equilibrium is perfectly preserved. This approach elegantly separates the part of the solution that must be preserved from the dynamic fluctuations that may require limiting .

### A Comparative Perspective: Slope Limiting versus Artificial Viscosity

Slope limiting is not the only method for capturing shocks. A major alternative is the use of **[artificial viscosity](@entry_id:140376) (AV)**, where the original hyperbolic PDE is augmented with a parabolic diffusion term, $\partial_x(\nu \partial_x u)$. The viscosity coefficient $\nu$ is designed to be active only in non-smooth regions detected by a sensor.

These two methods control oscillations through fundamentally different mechanisms :
-   **Artificial Viscosity** acts by adding a physical dissipation mechanism to the model. It preferentially damps high-frequency oscillations and tends to "smear" sharp discontinuities over several grid cells. The resulting profiles are smooth.
-   **Slope Limiting** is a non-physical, algebraic procedure. It directly manipulates the solution polynomial to enforce monotonicity. This "clipping" of polynomials results in sharper shock profiles compared to AV, but can introduce its own artifacts. A significant drawback is that limiters can inadvertently clip smooth, physical [extrema](@entry_id:271659), locally reducing the accuracy to first order.

In complex, under-resolved simulations (e.g., of turbulence), [slope limiters](@entry_id:638003) may not provide sufficient dissipation to prevent the pile-up of energy in the highest polynomial modes, which can lead to instability. In these cases, a more subtle form of AV, known as **modal viscosity**, can be advantageous. This technique adds a small amount of viscosity that specifically targets only the highest-degree basis functions within each element, providing a targeted energy sink at the grid scale without the bluntness of a full limiter . The choice between these methods involves a trade-off between the sharp but potentially clipped profiles of [slope limiters](@entry_id:638003) and the smooth but potentially smeared profiles of [artificial viscosity](@entry_id:140376).