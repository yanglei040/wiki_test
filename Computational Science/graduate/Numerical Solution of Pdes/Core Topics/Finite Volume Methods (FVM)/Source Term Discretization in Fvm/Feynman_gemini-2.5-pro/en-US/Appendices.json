{
    "hands_on_practices": [
        {
            "introduction": "The Finite Volume Method begins by integrating the governing equations over control volumes. This practice focuses on the crucial first step of approximating the source term integral, $\\int_V S dV$, using numerical quadrature. By implementing and testing various rules against functions of different smoothness, you will empirically verify how the accuracy of this fundamental approximation depends on both the method chosen and the nature of the source itself .",
            "id": "3444842",
            "problem": "Consider the Finite Volume Method (FVM) cell balance for a one-dimensional partition of the interval $\\left[0,1\\right]$ into $N$ uniform cells with cell edges $\\{x_i\\}_{i=0}^N$, $x_i = i/N$. For each cell $C_i = [x_i, x_{i+1}]$ with width $h = 1/N$, the source contribution entering the discrete balance is the cell integral $\\int_{x_i}^{x_{i+1}} S(x)\\,dx$. In FVM implementations this source integral is often approximated by a quadrature rule applied on each cell. Your task is to compute empirical convergence rates for different quadrature rules used to approximate these per-cell source integrals and compare results for smooth and nonsmooth source functions $S$.\n\nYou must proceed from the following fundamental base:\n- The Finite Volume Method (FVM) enforces local conservation by integrating the governing partial differential equation over each control volume, which produces cell integrals of the source function $S$ that must be approximated numerically when $S$ is not constant.\n- Classical quadrature rules for one-dimensional integrals include the midpoint rule, the trapezoidal rule, and Simpson’s rule. The accuracy of these rules depends on the smoothness of the integrand $S$ and the cell width $h$.\n\nImplement and test the following three source functions $S$, all defined on $\\left[0,1\\right]$:\n- A smooth source $S_{\\mathrm{smooth}}(x) = \\sin(2\\pi x)$.\n- A continuous but nonsmooth source with a kink at $x = c$: $S_{\\mathrm{kink}}(x) = |x - c|$, with $c = 0.314159265$.\n- A discontinuous source with a jump at $x = c$: $S_{\\mathrm{jump}}(x) = \\begin{cases} 1,  x  c \\\\ 2,  x \\ge c \\end{cases}$, with $c = 0.314159265$.\n\nFor each source function $S$ and for each cell $C_i = [x_i, x_{i+1}]$ with $h = x_{i+1} - x_i$, approximate the cell integral $\\int_{x_i}^{x_{i+1}} S(x)\\,dx$ using the following quadrature rules:\n- Midpoint rule: $Q_{\\mathrm{mid}}(C_i) = h \\, S\\!\\left(\\frac{x_i + x_{i+1}}{2}\\right)$.\n- Trapezoidal rule: $Q_{\\mathrm{trap}}(C_i) = \\frac{h}{2}\\,\\left(S(x_i) + S(x_{i+1})\\right)$.\n- Simpson’s rule: $Q_{\\mathrm{simp}}(C_i) = \\frac{h}{6}\\,\\left(S(x_i) + 4\\,S\\!\\left(\\frac{x_i + x_{i+1}}{2}\\right) + S(x_{i+1})\\right)$.\n\nFor each cell $C_i$, also compute the exact integral $\\int_{x_i}^{x_{i+1}} S(x)\\,dx$ using precise analytic formulas:\n- For $S_{\\mathrm{smooth}}(x) = \\sin(2\\pi x)$: use the antiderivative to evaluate $\\int_{x_i}^{x_{i+1}} \\sin(2\\pi x)\\,dx$ exactly.\n- For $S_{\\mathrm{kink}}(x) = |x - c|$: use the antiderivative $\\frac{1}{2}\\,(x - c)\\,|x - c|$ to evaluate the integral exactly on each cell.\n- For $S_{\\mathrm{jump}}(x)$: use piecewise evaluation on each cell depending on whether $[x_i, x_{i+1}]$ lies entirely on one side of $x=c$ or straddles it.\n\nDefine the global error for a given $N$ and quadrature rule as the $\\ell^1$ sum of per-cell absolute errors of the integrals:\n$$\nE(N; S, Q) = \\sum_{i=0}^{N-1} \\left| Q(C_i) - \\int_{x_i}^{x_{i+1}} S(x)\\,dx \\right|.\n$$\nFor each $S \\in \\{S_{\\mathrm{smooth}}, S_{\\mathrm{kink}}, S_{\\mathrm{jump}}\\}$ and $Q \\in \\{Q_{\\mathrm{mid}}, Q_{\\mathrm{trap}}, Q_{\\mathrm{simp}}\\}$, compute the empirical convergence rate using a refinement sequence $N \\in \\{16, 32, 64, 128, 256, 512\\}$ with $h = 1/N$. Define the empirical rate based on the last two refinements $N_{\\mathrm{prev}} = 256$ and $N_{\\mathrm{curr}} = 512$ by\n$$\np_{\\mathrm{emp}}(S,Q) = \\frac{\\log\\left(E(N_{\\mathrm{prev}}; S, Q)\\right) - \\log\\left(E(N_{\\mathrm{curr}}; S, Q)\\right)}{\\log\\left(h_{\\mathrm{prev}}\\right) - \\log\\left(h_{\\mathrm{curr}}\\right)} = \\frac{\\log\\left(\\frac{E(256; S, Q)}{E(512; S, Q)}\\right)}{\\log(2)}.\n$$\n\nYour program must:\n- Implement the three source functions and the three quadrature rules as specified.\n- For each $N$ in the refinement sequence, compute $E(N; S, Q)$ for all combinations of $S$ and $Q$.\n- Compute the nine empirical rates $p_{\\mathrm{emp}}(S,Q)$ using the last two $N$ values in the sequence.\n\nTest Suite and Coverage:\n- Use the refinement sequence $N \\in \\{16, 32, 64, 128, 256, 512\\}$ for every case.\n- Include all nine combinations: $(S_{\\mathrm{smooth}}, Q_{\\mathrm{mid}})$, $(S_{\\mathrm{smooth}}, Q_{\\mathrm{trap}})$, $(S_{\\mathrm{smooth}}, Q_{\\mathrm{simp}})$, $(S_{\\mathrm{kink}}, Q_{\\mathrm{mid}})$, $(S_{\\mathrm{kink}}, Q_{\\mathrm{trap}})$, $(S_{\\mathrm{kink}}, Q_{\\mathrm{simp}})$, $(S_{\\mathrm{jump}}, Q_{\\mathrm{mid}})$, $(S_{\\mathrm{jump}}, Q_{\\mathrm{trap}})$, $(S_{\\mathrm{jump}}, Q_{\\mathrm{simp}})$. This selection spans smooth, continuous nonsmooth, and discontinuous sources, probing the robustness and limits of different quadrature rules.\n- The expected outputs are real numbers measuring $p_{\\mathrm{emp}}$, one per case, returned as floating-point values.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the nine empirical rates in the fixed order listed above, as a comma-separated list enclosed in square brackets, for example $[r_1,r_2,\\dots,r_9]$.\n- Each reported rate must be rounded to four decimal places and expressed as a floating-point number with a decimal point.\n\nNo physical units are involved in this problem; all quantities are dimensionless and purely mathematical. Angles, if any appear, must be in radians, but none are required here.",
            "solution": "The user wants to compute the empirical convergence rates for three different quadrature rules (Midpoint, Trapezoidal, Simpson's) applied to the source term integral in a Finite Volume Method (FVM) setting. The analysis is performed for three source functions with varying degrees of smoothness: a smooth function, a continuous but non-differentiable (kink) function, and a discontinuous (jump) function.\n\nThe core of the problem is to quantify how the accuracy of the source term approximation, a crucial part of FVM, varies with the cell width $h$ and how this relationship is affected by the smoothness of the source function $S(x)$. The theoretical order of convergence $p$ of a numerical method implies that the global error $E$ behaves as $E \\approx C h^p$ for some constant $C$, where $h$ is the mesh size. By computing the error for a sequence of refined meshes, we can empirically estimate this order $p$.\n\nThe procedure is as follows:\n1.  Define the source functions and their corresponding exact integral formulas.\n2.  Implement the quadrature rules.\n3.  For each combination of source function and quadrature rule, compute the global error over a sequence of refined meshes.\n4.  Use the errors from the two finest meshes to calculate the empirical order of convergence.\n\n**1. Source Functions and Exact Integrals**\n\nThe problem is set on the one-dimensional domain $[0, 1]$, partitioned into $N$ uniform cells $C_i = [x_i, x_{i+1}]$ of width $h = 1/N$, where $x_i = i/N$.\n\nThe three source functions are:\n-   **Smooth Source:** $S_{\\mathrm{smooth}}(x) = \\sin(2\\pi x)$. This function is infinitely differentiable ($C^\\infty$). The exact integral over a cell $C_i$ is computed from its antiderivative:\n    $$\n    \\int_{x_i}^{x_{i+1}} \\sin(2\\pi x)\\,dx = \\left[-\\frac{\\cos(2\\pi x)}{2\\pi}\\right]_{x_i}^{x_{i+1}} = \\frac{\\cos(2\\pi x_i) - \\cos(2\\pi x_{i+1})}{2\\pi}\n    $$\n-   **Kink Source:** $S_{\\mathrm{kink}}(x) = |x - c|$ with $c = 0.314159265$. This function is continuous ($C^0$) but not differentiable at $x=c$. Its derivative has a jump discontinuity. The exact integral is computed using the provided antiderivative, $F(x) = \\frac{1}{2}(x - c)|x - c|$:\n    $$\n    \\int_{x_i}^{x_{i+1}} |x - c|\\,dx = F(x_{i+1}) - F(x_{i}) = \\frac{1}{2}\\left( (x_{i+1} - c)|x_{i+1} - c| - (x_i - c)|x_i - c| \\right)\n    $$\n-   **Jump Source:** $S_{\\mathrm{jump}}(x) = \\begin{cases} 1,  x  c \\\\ 2,  x \\geq c \\end{cases}$ with $c = 0.314159265$. This function is discontinuous at $x=c$. The integral must be evaluated piecewise. For a cell $C_i = [x_i, x_{i+1}]$:\n    -   If $x_{i+1} \\le c$, the cell is entirely to the left of the jump: $\\int_{x_i}^{x_{i+1}} S_{\\mathrm{jump}}(x)\\,dx = \\int_{x_i}^{x_{i+1}} 1\\,dx = h$.\n    -   If $x_i \\ge c$, the cell is entirely to the right of the jump: $\\int_{x_i}^{x_{i+1}} S_{\\mathrm{jump}}(x)\\,dx = \\int_{x_i}^{x_{i+1}} 2\\,dx = 2h$.\n    -   If $x_i  c  x_{i+1}$, the cell straddles the jump: $\\int_{x_i}^{x_{i+1}} S_{\\mathrm{jump}}(x)\\,dx = \\int_{x_i}^{c} 1\\,dx + \\int_{c}^{x_{i+1}} 2\\,dx = (c - x_i) + 2(x_{i+1} - c)$.\n\n**2. Quadrature Rules**\n\nFor each cell $C_i$, the integral $\\int_{x_i}^{x_{i+1}} S(x)\\,dx$ is approximated using three standard rules:\n-   **Midpoint Rule:** $Q_{\\mathrm{mid}}(C_i) = h \\, S\\!\\left(\\frac{x_i + x_{i+1}}{2}\\right)$. The local error is $O(h^3)$, and the global error is $O(h^2)$.\n-   **Trapezoidal Rule:** $Q_{\\mathrm{trap}}(C_i) = \\frac{h}{2}\\,\\left(S(x_i) + S(x_{i+1})\\right)$. The local error is $O(h^3)$, and the global error is $O(h^2)$.\n-   **Simpson’s Rule:** $Q_{\\mathrm{simp}}(C_i) = \\frac{h}{6}\\,\\left(S(x_i) + 4\\,S\\!\\left(\\frac{x_i + x_{i+1}}{2}\\right) + S(x_{i+1})\\right)$. The local error is $O(h^5)$, and the global error is $O(h^4)$.\n\nThese theoretical error orders assume the integrand is sufficiently smooth. For non-smooth functions, the convergence rate is expected to degrade.\n\n**3. Error and Convergence Rate Calculation**\n\nThe global error for a given mesh size $N$ (and corresponding cell width $h=1/N$) is the $\\ell^1$ norm of the per-cell approximation errors:\n$$\nE(N; S, Q) = \\sum_{i=0}^{N-1} \\left| Q(C_i) - \\int_{x_i}^{x_{i+1}} S(x)\\,dx \\right|\n$$\nWe compute this error for each pair $(S, Q)$ over a sequence of refinements $N \\in \\{16, 32, 64, 128, 256, 512\\}$.\n\nAssuming the error follows $E(N) \\approx C(1/N)^p$, we have $E(N_{\\mathrm{prev}}) \\approx C(1/N_{\\mathrm{prev}})^p$ and $E(N_{\\mathrm{curr}}) \\approx C(1/N_{\\mathrm{curr}})^p$. The empirical rate of convergence $p_{\\mathrm{emp}}$ can be calculated from the errors on two successive meshes, $N_{\\mathrm{prev}} = 256$ and $N_{\\mathrm{curr}} = 512$. Taking the ratio of errors eliminates the constant $C$:\n$$\n\\frac{E(N_{\\mathrm{prev}})}{E(N_{\\mathrm{curr}})} \\approx \\left(\\frac{N_{\\mathrm{curr}}}{N_{\\mathrm{prev}}}\\right)^p = \\left(\\frac{2 N_{\\mathrm{prev}}}{N_{\\mathrm{prev}}}\\right)^p = 2^p\n$$\nSolving for $p$ gives the formula for the empirical rate:\n$$\np_{\\mathrm{emp}}(S,Q) = \\log_2\\left(\\frac{E(N_{\\mathrm{prev}}; S, Q)}{E(N_{\\mathrm{curr}}; S, Q)}\\right) = \\frac{\\log\\left(\\frac{E(256; S, Q)}{E(512; S, Q)}\\right)}{\\log(2)}\n$$\nThis calculation is performed for all nine combinations of source functions and quadrature rules. The results demonstrate the impact of integrand smoothness:\n-   For $S_{\\mathrm{smooth}}$, we expect rates of $2$, $2$, and $4$ for the midpoint, trapezoidal, and Simpson's rules, respectively.\n-   For $S_{\\mathrm{kink}}$, the lack of a second derivative at $x=c$ is expected to reduce the convergence rate of all methods. The error will be dominated by the single cell containing the kink. We anticipate that all methods will exhibit a rate of approximately $2$.\n-   For $S_{\\mathrm{jump}}$, the discontinuity at $x=c$ is a more severe lack of smoothness. The error in the single cell containing the jump is expected to be $O(h)$, making the global error $O(h)$. Thus, all three methods should degrade to first-order convergence, a rate of $1$.\n\nThe implementation will systematically compute these nine rates and format them as requested.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes empirical convergence rates for different quadrature rules\n    applied to various source functions in an FVM context.\n    \"\"\"\n    # Define the constant for the kink and jump locations\n    C_VAL = 0.314159265\n\n    # --- 1. Define Source Functions and their Exact Integrals ---\n\n    # Source functions (vectorized)\n    def s_smooth(x):\n        return np.sin(2 * np.pi * x)\n\n    def s_kink(x):\n        return np.abs(x - C_VAL)\n\n    def s_jump(x):\n        return np.where(x  C_VAL, 1.0, 2.0)\n\n    # Exact integral functions for a cell [xi, xi1] (vectorized)\n    def i_exact_smooth(xi, xi1):\n        # Integral of sin(2*pi*x)\n        return (np.cos(2 * np.pi * xi) - np.cos(2 * np.pi * xi1)) / (2 * np.pi)\n\n    def i_exact_kink(xi, xi1):\n        # Antiderivative F(x) = 0.5 * (x - c) * |x - c|\n        def anti_deriv(x, c):\n            return 0.5 * (x - c) * np.abs(x - c)\n        return anti_deriv(xi1, C_VAL) - anti_deriv(xi, C_VAL)\n\n    def i_exact_jump(xi, xi1):\n        # Piecewise evaluation for discontinuous function (vectorized)\n        h = xi1[0] - xi[0] if isinstance(xi, np.ndarray) and xi.size  0 else xi1 - xi\n        \n        # Initialize result array\n        integral_vals = np.zeros_like(xi, dtype=float)\n\n        # Case 1: Cell is entirely to the left of the jump (xi1 = c)\n        mask1 = xi1 = C_VAL\n        integral_vals[mask1] = 1.0 * h\n\n        # Case 2: Cell is entirely to the right of the jump (xi = c)\n        mask2 = xi = C_VAL\n        integral_vals[mask2] = 2.0 * h\n\n        # Case 3: Cell straddles the jump (xi  c  xi1)\n        mask3 = (~mask1)  (~mask2)\n        integral_vals[mask3] = 1.0 * (C_VAL - xi[mask3]) + 2.0 * (xi1[mask3] - C_VAL)\n        \n        return integral_vals\n\n\n    def calculate_single_rate(source_fn, integral_fn, quad_name):\n        \"\"\"\n        Calculates the empirical convergence rate for a single combination\n        of source function and quadrature rule.\n        \"\"\"\n        refinement_Ns = [16, 32, 64, 128, 256, 512]\n        errors = {}\n\n        for N in refinement_Ns:\n            h = 1.0 / N\n            # Vector of left cell boundaries\n            xi = np.linspace(0.0, 1.0 - h, N)\n            # Vector of right cell boundaries\n            xi1 = np.linspace(h, 1.0, N)\n\n            # --- Compute exact integrals for all cells ---\n            exact_vals = integral_fn(xi, xi1)\n\n            # --- Compute approximate integrals for all cells using quadrature ---\n            quad_vals = np.zeros(N)\n            if quad_name == 'mid':\n                xm = (xi + xi1) / 2.0\n                quad_vals = h * source_fn(xm)\n            elif quad_name == 'trap':\n                quad_vals = (h / 2.0) * (source_fn(xi) + source_fn(xi1))\n            elif quad_name == 'simp':\n                xm = (xi + xi1) / 2.0\n                quad_vals = (h / 6.0) * (source_fn(xi) + 4 * source_fn(xm) + source_fn(xi1))\n            \n            # --- Calculate global L1 error ---\n            total_error = np.sum(np.abs(quad_vals - exact_vals))\n            errors[N] = total_error\n\n        # --- Calculate empirical convergence rate ---\n        e_prev = errors[256]\n        e_curr = errors[512]\n        \n        if e_curr = 0.0 or e_prev = 0.0:\n            # This case indicates the error is zero or became unstable,\n            # which is not expected for these test cases.\n            rate = np.nan\n        else:\n            rate = np.log(e_prev / e_curr) / np.log(2)\n        \n        return rate\n\n    # --- 2. Define Test Cases and Compute Rates ---\n    \n    # List of (source_function, integral_function) tuples\n    source_integral_pairs = [\n        (s_smooth, i_exact_smooth),\n        (s_kink, i_exact_kink),\n        (s_jump, i_exact_jump),\n    ]\n    # List of quadrature rule names\n    quad_rules = ['mid', 'trap', 'simp']\n    \n    results = []\n    \n    # Iterate through all 9 combinations\n    for s_fn, i_fn in source_integral_pairs:\n        for quad in quad_rules:\n            # Calculate the rate for the current combination\n            rate = calculate_single_rate(s_fn, i_fn, quad)\n            # Format the result to 4 decimal places\n            results.append(f\"{rate:.4f}\")\n\n    # --- 3. Final Output ---\n    # Print the list of formatted results in the required single-line format\n    print(f\"[{','.join(results)}]\")\n\n# Execute the main function\nsolve()\n```"
        },
        {
            "introduction": "When source terms are nonlinear and an implicit time-stepping scheme is used, the resulting algebraic equations are also nonlinear and must be solved iteratively. This exercise provides core training in the most common approach: linearizing the source term using a first-order Taylor expansion as part of a Newton-Raphson solver. You will derive the specific contributions of a nonlinear source to the system's Jacobian matrix and residual vector, a fundamental skill for developing advanced FVM codes .",
            "id": "3444840",
            "problem": "Consider the scalar parabolic partial differential equation $ \\frac{\\partial u}{\\partial t} = \\mathcal{L}(u) + S(u) $ where $ \\mathcal{L}(u) $ denotes spatial operators producing fluxes across control-volume faces and $ S(u) = \\exp(u) $ is a nonlinear volumetric source. Using the Finite Volume Method (FVM), assume a single control volume (cell) $ P $ of measure (volume in three dimensions, area in two dimensions, or length in one dimension) $ V_{P} $, with the cell-averaged unknown $ u_{P}(t) $ treated as constant over $ P $. Discretize in time with the backward Euler method over a time step from $ t^{n} $ to $ t^{n+1} $ of size $ \\Delta t $, and assemble a nonlinear algebraic equation for $ u_{P}^{n+1} $ by approximating the source term implicitly as $ V_{P} S(u_{P}^{n+1}) $.\n\nTo solve the nonlinear system, perform a Newton linearization at iteration $ k $ around the current iterate $ u_{P}^{(k)} $ for the source term. By writing the backward Euler residual in $ P $ as a linear system $ a_{PP} u_{P}^{n+1} + \\sum_{N} a_{PN} u_{N}^{n+1} = b_{P} $ after linearization, extract the source-term-only contributions to the local diagonal matrix entry and right-hand side, denoted $ a_{PP}^{(S)} $ and $ b_{P}^{(S)} $, respectively. You must express $ a_{PP}^{(S)} $ and $ b_{P}^{(S)} $ explicitly in terms of $ V_{P} $ and $ u_{P}^{(k)} $.\n\nProvide your final answer as a single row matrix containing the two expressions $ a_{PP}^{(S)} $ and $ b_{P}^{(S)} $, in that order. No numerical evaluation is required, and no rounding is needed. Ignore the contributions of $ \\mathcal{L}(u) $ and the time-derivative term other than to maintain correct sign conventions for assembling $ a_{PP}^{(S)} $ and $ b_{P}^{(S)} $.",
            "solution": "The problem at hand is valid as it is scientifically grounded in the principles of numerical analysis for partial differential equations, is well-posed, objective, and internally consistent. We can therefore proceed with a formal derivation.\n\nThe governing scalar parabolic partial differential equation is given by:\n$$ \\frac{\\partial u}{\\partial t} = \\mathcal{L}(u) + S(u) $$\nwhere $S(u) = \\exp(u)$ is the nonlinear volumetric source term.\n\nApplying the Finite Volume Method (FVM), we integrate this equation over a control volume (cell) $P$ of measure $V_P$:\n$$ \\int_{V_P} \\frac{\\partial u}{\\partial t} \\, dV = \\int_{V_P} \\mathcal{L}(u) \\, dV + \\int_{V_P} S(u) \\, dV $$\nAssuming the cell-averaged value $u_P$ is a good representation of $u$ over the entire cell $P$, the integrated equation becomes a semi-discretized ordinary differential equation for $u_P(t)$:\n$$ V_P \\frac{d u_P}{d t} = F_P(u) + V_P S(u_P) $$\nwhere $F_P(u)$ represents the discretized spatial operator $\\mathcal{L}(u)$ integrated over the volume, which yields the net flux across the cell faces.\n\nNext, we discretize in time using the fully implicit backward Euler method over a time step $\\Delta t = t^{n+1} - t^n$. This involves approximating the time derivative at time $t^{n+1}$ and evaluating all terms on the right-hand side at time $t^{n+1}$:\n$$ V_P \\frac{u_P^{n+1} - u_P^n}{\\Delta t} = F_P(u^{n+1}) + V_P S(u_P^{n+1}) $$\nTo solve for $u_P^{n+1}$, it is conventional to rearrange this equation into a residual form, $R_P(u^{n+1}) = 0$, by moving all terms to one side. The problem specifies a final linear system of the form $a_{PP} u_{P}^{n+1} + \\sum_{N} a_{PN} u_{N}^{n+1} = b_{P}$, which implies that terms involving the unknown $u^{n+1}$ are assembled on the left-hand side (LHS) and known quantities on the right-hand side (RHS).\nFollowing this convention, the equation is arranged as:\n$$ \\left( V_P \\frac{u_P^{n+1}}{\\Delta t} - F_P(u^{n+1}) - V_P S(u_P^{n+1}) \\right) - V_P \\frac{u_P^n}{\\Delta t} = 0 $$\nThe problem requires us to isolate the contributions from the source term only. The source term's appearance in the fully discretized equation is $-V_P S(u_P^{n+1})$ on the LHS. This term is nonlinear because $S(u) = \\exp(u)$.\n\nTo solve the nonlinear system, we employ a Newton linearization. At each iteration $k$ of the nonlinear solver, we linearize the nonlinear terms around the current known iterate, denoted as $u_P^{(k)}$. The unknown we are solving for is $u_P^{n+1}$. A general function $f(x)$ is linearized around $x_k$ as $f(x) \\approx f(x_k) + f'(x_k)(x - x_k)$.\nApplying this to the source function $S(u_P^{n+1})$ with $x = u_P^{n+1}$ and $x_k = u_P^{(k)}$:\n$$ S(u_P^{n+1}) \\approx S(u_P^{(k)}) + S'(u_P^{(k)}) (u_P^{n+1} - u_P^{(k)}) $$\nwhere $S'(u_P^{(k)})$ is the derivative of $S(u)$ with respect to $u$, evaluated at $u_P^{(k)}$.\n\nSubstituting this linearized expression into the source term part of our rearranged equation, $-V_P S(u_P^{n+1})$, we get:\n$$ -V_P S(u_P^{n+1}) \\approx -V_P \\left[ S(u_P^{(k)}) + S'(u_P^{(k)}) (u_P^{n+1} - u_P^{(k)}) \\right] $$\nExpanding this expression yields:\n$$ -V_P S'(u_P^{(k)}) u_P^{n+1} - V_P S(u_P^{(k)}) + V_P S'(u_P^{(k)}) u_P^{(k)} $$\nThis represents the total contribution of the linearized source term to the LHS of the algebraic equation at iteration $k$.\n\nWe must now segregate these contributions into the target form $a_{PP} u_{P}^{n+1} = b_{P}$, ignoring all other terms as instructed.\nThe term containing the unknown $u_P^{n+1}$ contributes to the matrix coefficient $a_{PP}$. The remaining terms are constant with respect to $u_P^{n+1}$ and are moved to the RHS to form $b_P$.\n\nThe contribution to the LHS term $a_{PP} u_{P}^{n+1}$ is:\n$$ \\underbrace{\\left( -V_P S'(u_P^{(k)}) \\right)}_{a_{PP}^{(S)}} u_P^{n+1} $$\nThus, the source-term-only contribution to the diagonal matrix entry is:\n$$ a_{PP}^{(S)} = -V_P S'(u_P^{(k)}) $$\n\nThe remaining terms from the linearized source term, $- V_P S(u_P^{(k)}) + V_P S'(u_P^{(k)}) u_P^{(k)}$, are on the LHS. To move them to the RHS to become part of $b_P$, we must change their sign:\n$$ b_P^{(S)} = - \\left( - V_P S(u_P^{(k)}) + V_P S'(u_P^{(k)}) u_P^{(k)} \\right) $$\n$$ b_P^{(S)} = V_P S(u_P^{(k)}) - V_P S'(u_P^{(k)}) u_P^{(k)} $$\nThis is the source-term-only contribution to the RHS vector.\n\nFinally, we substitute the specific forms for $S(u)$ and its derivative $S'(u)$:\nGiven $S(u) = \\exp(u)$, its derivative is $S'(u) = \\frac{d}{du}(\\exp(u)) = \\exp(u)$.\nEvaluating at $u_P^{(k)}$:\n$S(u_P^{(k)}) = \\exp(u_P^{(k)})$\n$S'(u_P^{(k)}) = \\exp(u_P^{(k)})$\n\nSubstituting these into the expressions for $a_{PP}^{(S)}$ and $b_P^{(S)}$:\n$$ a_{PP}^{(S)} = -V_P \\exp(u_P^{(k)}) $$\n$$ b_P^{(S)} = V_P \\exp(u_P^{(k)}) - V_P \\exp(u_P^{(k)}) u_P^{(k)} $$\nThe expression for $b_P^{(S)}$ can be factorized:\n$$ b_P^{(S)} = V_P \\exp(u_P^{(k)}) (1 - u_P^{(k)}) $$\nThese are the required explicit expressions for the source term contributions.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-V_{P} \\exp(u_{P}^{(k)})  V_{P} \\exp(u_{P}^{(k)}) (1 - u_{P}^{(k)})\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A robust numerical scheme must produce physically meaningful results, such as ensuring that quantities like concentration remain non-negative. This practice delves into the stability of the FVM discretization, exploring how the treatment of a linearized source term can make or break this positivity-preserving property. By applying the theory of M-matrices, you will derive strict conditions on the source term coefficients that guarantee a non-negative solution, connecting abstract matrix analysis to practical code development .",
            "id": "3444890",
            "problem": "Consider a scalar transport governed by a linear production-destruction source in a partial differential equation (PDE) discretized by the Finite Volume Method (FVM). Let the linearized source at a control volume $P$ be written as $S(u_{P}) = a_{P}\\,u_{P} + b_{P}$, where $a_{P}$ represents the destruction coefficient and $b_{P}$ represents the production coefficient. Assume a fully implicit temporal discretization over a time step $\\Delta t$, and that the spatial discretization (diffusion with central differencing, and convection with an upwind differencing that satisfies total variation diminishing monotonicity) yields face-based neighbor coupling coefficients that are nonnegative when written on the right-hand side. Let the transient mass coefficient be $m_{P} = \\rho c V_{P} / \\Delta t$, where $\\rho$ is the density, $c$ is a positive material constant, and $V_{P}$ is the volume of the control volume $P$. Assume that boundary conditions and initial data are nonnegative.\n\nStarting from the conservative integral form over $V_{P}$ and proceeding through the fully implicit FVM discretization, derive the coefficient form for the single control volume equation at the new time level $n+1$, and invoke the theory of nonsingular monotone matrices (M-matrices) to establish conditions on $a_{P}$ and $b_{P}$ that guarantee $u^{n+1} \\ge 0$ componentwise whenever the right-hand side is nonnegative. Prove that there exists a finite upper bound $a_{P}^{\\max}$ on the destruction coefficient above which positivity can be lost, and compute this bound exactly in closed form in terms of $m_{P}$ and $V_{P}$. Your final answer must be a single analytic expression for $a_{P}^{\\max}$, with no inequalities and no units.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard problem in the field of numerical solutions of partial differential equations, specifically concerning the stability and positivity of the Finite Volume Method (FVM).\n\nThe solution proceeds by first discretizing the general scalar transport equation and then applying the theory of M-matrices to derive conditions on the source term coefficients that ensure the non-negativity of the solution.\n\nLet $u$ be the scalar variable. The conservative integral form of the transport equation for a control volume $V_P$ over a time interval $[t^n, t^{n+1}]$ is:\n$$\n\\int_{V_P} \\rho c u^{n+1} dV - \\int_{V_P} \\rho c u^n dV + \\int_{t^n}^{t^{n+1}} \\left( \\int_{A_P} \\mathbf{J} \\cdot d\\mathbf{A} \\right) dt = \\int_{t^n}^{t^{n+1}} \\left( \\int_{V_P} S_v dV \\right) dt\n$$\nwhere $\\rho$ and $c$ are material properties, $\\mathbf{J}$ is the total flux vector, and $S_v$ is the volumetric source term.\n\nWe apply a fully implicit FVM discretization. The value of $u$ within the control volume is represented by its cell-average value, $u_P$. All terms, including fluxes and sources, are evaluated at the new time level $t^{n+1}$. For clarity, we will denote values at $t^{n+1}$ without a superscript (e.g., $u_P$) and values at $t^n$ with the superscript $n$ (e.g., $u_P^n$).\n\nThe time derivative term is approximated as:\n$$\n\\frac{1}{\\Delta t} \\left( \\int_{V_P} \\rho c u^{n+1} dV - \\int_{V_P} \\rho c u^n dV \\right) \\approx \\frac{\\rho c V_P}{\\Delta t} (u_P - u_P^n) = m_P(u_P - u_P^n)\n$$\nwhere $m_P = \\frac{\\rho c V_P}{\\Delta t}$ is the given transient mass coefficient.\n\nThe problem states that the linearized source is $S(u_P) = a_P u_P + b_P$. There is an ambiguity as to whether this is the volumetric source $S_v$ or the total source integrated over the volume, $\\int_{V_P} S_v dV$. The request for the final answer to be in terms of $m_P$ and $V_P$ strongly suggests that $S_v$ is the intended interpretation, such that $S_v(u) = a_P u + b_P$. In this case, the integrated source term is:\n$$\n\\int_{V_P} S_v dV \\approx (a_P u_P + b_P)V_P\n$$\nThe spatial discretization of the flux term $\\sum_f \\mathbf{J} \\cdot \\mathbf{A}_f$ is given to yield non-negative neighbor coupling coefficients on the right-hand side of the algebraic equation. This leads to the standard FVM form:\n$$\n\\sum_f (\\mathbf{J} \\cdot \\mathbf{A}_f) \\approx A_{P, \\text{flux}} u_P - \\sum_{N} A_N u_N\n$$\nwhere $N$ denotes the set of neighboring control volumes to $P$, and the coefficients $A_N \\ge 0$. For a conservative scheme on an internal control volume, the coefficient $A_{P, \\text{flux}}$ is equal to the sum of the neighbor coefficients, $A_{P, \\text{flux}} = \\sum_N A_N$.\n\nSubstituting these discretized terms into the integrated balance equation (after dividing by $\\Delta t$) gives:\n$$\nm_P(u_P - u_P^n) + \\left( \\sum_N A_N \\right) u_P - \\sum_N A_N u_N = (a_P u_P + b_P)V_P\n$$\nWe now rearrange this equation into the standard linear algebraic form $A_{P,P} u_P = \\sum_N A_{P,N} u_N + B_P$:\n$$\n\\left( m_P + \\sum_N A_N - a_P V_P \\right) u_P = \\sum_N A_N u_N + m_P u_P^n + b_P V_P\n$$\nFrom this, we identify the coefficients of the algebraic system:\n- Main diagonal coefficient on the LHS: $A_{P,P} = m_P + \\sum_N A_N - a_P V_P$\n- Off-diagonal coefficients on the RHS: $A_{P,N} = A_N$\n- Constant source term on the RHS: $B_P = m_P u_P^n + b_P V_P$\n\nFor the solution $u_P$ to be non-negative for any non-negative initial condition $u_P^n \\ge 0$ and boundary conditions, two conditions must be met. The system matrix must be a monotone matrix (an M-matrix), and the right-hand side vector must be non-negative.\n\nFirst, let's analyze the right-hand side, $B_P$. Given that $m_P  0$, $u_P^n \\ge 0$, and $V_P  0$, the condition $B_P \\ge 0$ requires that the production coefficient satisfies $b_P \\ge 0$.\n\nSecond, we analyze the system matrix, let's call it $\\mathbf{M}$. The equation for row $P$ is $\\mathbf{M}_{PP} u_P + \\sum_{N} \\mathbf{M}_{PN} u_N = B_P$.\nComparing with our derived form, we have:\n- Diagonal matrix entries: $\\mathbf{M}_{PP} = A_{P,P} = m_P + \\sum_N A_N - a_P V_P$\n- Off-diagonal matrix entries: $\\mathbf{M}_{PN} = -A_N$\n\nA sufficient condition for $\\mathbf{M}$ to be an M-matrix is that it is a strictly or irreducibly diagonally dominant L-matrix. An L-matrix has positive diagonal entries and non-positive off-diagonal entries.\n1.  Condition for non-positive off-diagonals: $\\mathbf{M}_{PN} = -A_N \\le 0$. Since we are given $A_N \\ge 0$, this condition is satisfied.\n2.  Condition for positive diagonals: $\\mathbf{M}_{PP}  0 \\implies m_P + \\sum_N A_N - a_P V_P  0$.\n3.  Condition for diagonal dominance: $|\\mathbf{M}_{PP}| \\ge \\sum_{N} |\\mathbf{M}_{PN}|$. Assuming $\\mathbf{M}_{PP}0$, this is:\n    $$\n    m_P + \\sum_N A_N - a_P V_P \\ge \\sum_N |-A_N| = \\sum_N A_N\n    $$\n    This inequality simplifies to:\n    $$\n    m_P - a_P V_P \\ge 0 \\implies a_P V_P \\le m_P \\implies a_P \\le \\frac{m_P}{V_P}\n    $$\nThis condition represents the constraint on $a_P$ for the system to guarantee a non-negative solution. It is more restrictive than the condition $\\mathbf{M}_{PP}  0$ because $\\sum_N A_N \\ge 0$. If $a_P$ violates this bound ($a_P  m_P/V_P$), diagonal dominance is lost, the matrix is not guaranteed to be an M-matrix, and its inverse may contain negative entries, allowing for $u_P  0$.\n\nThe problem refers to $a_P$ as the \"destruction coefficient\", which is confusing since a destruction term proportional to $u_P$ would typically have a negative coefficient (e.g., $-k u_P$ with $k  0$). A negative $a_P$ would always satisfy $a_P \\le m_P/V_P$ since $m_P  0$ and $V_P  0$. However, the problem asks for a finite upper bound $a_P^{\\max}$, which implies that $a_P$ can be a positive value (i.e., a production coefficient) that can become large enough to cause instability. Thus, we interpret \"$a_P$ represents the destruction coefficient\" as a misnomer, and we are tasked with finding the upper limit for the production coefficient $a_P$ beyond which positivity is lost.\n\nThis upper bound, $a_P^{\\max}$, is the value at which the diagonal dominance condition reaches its limit:\n$$\na_P^{\\max} = \\frac{m_P}{V_P}\n$$\nIf $a_P  a_P^{\\max}$, the system is no longer diagonally dominant, and positivity can be lost. This proves the existence of such a finite upper bound. The bound is provided exactly as a closed-form expression in terms of the specified variables $m_P$ and $V_P$.\nThe conditions on the source term coefficients to guarantee positivity are therefore $a_P \\le m_P/V_P$ and $b_P \\ge 0$. The requested upper bound is on $a_P$.",
            "answer": "$$\\boxed{\\frac{m_P}{V_P}}$$"
        }
    ]
}