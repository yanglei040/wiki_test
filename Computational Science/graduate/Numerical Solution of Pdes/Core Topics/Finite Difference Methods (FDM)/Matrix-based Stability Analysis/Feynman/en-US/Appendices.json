{
    "hands_on_practices": [
        {
            "introduction": "This first practice serves as a cornerstone for matrix-based stability analysis. By discretizing the classic one-dimensional heat equation, you will construct the discrete Laplacian matrix and perform an exact eigenvalue analysis . This exercise provides a complete, first-principles derivation of the famous stability condition for the Forward Euler scheme, solidifying the fundamental connection between the matrix spectrum and numerical stability.",
            "id": "3419083",
            "problem": "Consider the heat equation, a canonical linear Partial Differential Equation (PDE),\n$$\nu_{t}(x,t) = \\kappa\\,u_{xx}(x,t), \\quad x \\in (0,\\,1), \\quad t  0,\n$$\nwith homogeneous Dirichlet boundary conditions\n$$\nu(0,t) = 0, \\quad u(1,t) = 0,\n$$\nand a given strictly positive thermal diffusivity parameter $\\kappa  0$. Discretize the spatial interval $(0,\\,1)$ into $M$ equal subintervals of length $h = \\frac{1}{M}$, so the interior grid points are $x_{i} = i h$ for $i = 1,\\,2,\\,\\dots,\\,M-1$. Using the standard second-order central difference approximation for the second derivative, the semi-discrete system has the form of an Ordinary Differential Equation (ODE),\n$$\n\\frac{d\\boldsymbol{u}(t)}{dt} = \\kappa\\,L_{h}\\,\\boldsymbol{u}(t),\n$$\nwhere $\\boldsymbol{u}(t) \\in \\mathbb{R}^{M-1}$ collects the values at interior grid points and $L_{h} \\in \\mathbb{R}^{(M-1)\\times(M-1)}$ is the discrete Laplacian matrix with homogeneous Dirichlet boundary conditions,\n$$\nL_{h} = \\frac{1}{h^{2}}\n\\begin{bmatrix}\n-2  1  0  \\cdots  0 \\\\\n1  -2  1  \\ddots  \\vdots \\\\\n0  1  -2  \\ddots  0 \\\\\n\\vdots  \\ddots  \\ddots  \\ddots  1 \\\\\n0  \\cdots  0  1  -2\n\\end{bmatrix}.\n$$\nYou will analyze stability of the explicit Forward Euler (FE) time discretization, defined by\n$$\n\\boldsymbol{u}^{n+1} = \\boldsymbol{u}^{n} + \\Delta t\\,\\kappa\\,L_{h}\\,\\boldsymbol{u}^{n},\n$$\nwhere $\\Delta t  0$ is the time step. Using matrix-based stability analysis, proceed from first principles:\n\n- Determine the full set of eigenpairs of the symmetric tridiagonal Toeplitz matrix inside $L_{h}$ that correspond to homogeneous Dirichlet boundary conditions on $(0,\\,1)$.\n- Identify the algebraically largest eigenvalue of $L_{h}$ (that is, the eigenvalue with the greatest real value).\n- Using the scalar test ODE $y'(t) = \\lambda\\,y(t)$ as a foundational stability model and the FE stability region on the negative real axis, deduce the exact explicit time-step restriction $\\Delta t_{\\max}$ required to ensure the spectral radius of the FE amplification matrix $I + \\Delta t\\,\\kappa\\,L_{h}$ does not exceed $1$.\n\nExpress your final answers in closed form as functions of $M$, $h$, and $\\kappa$. No numerical evaluation is required, and no rounding is permitted. Provide the final answers as the algebraically largest eigenvalue of $L_{h}$ and the corresponding maximum stable time step $\\Delta t_{\\max}$.",
            "solution": "The problem statement is found to be valid as it represents a standard, well-posed problem in the field of numerical analysis for partial differential equations. It is scientifically grounded, objective, and self-contained.\n\nThe problem asks for a matrix-based stability analysis of the Forward Euler (FE) method applied to the semi-discretized heat equation. We will proceed by first determining the eigenpairs of the discrete Laplacian matrix, then identifying the relevant eigenvalue for stability, and finally deriving the maximum stable time step.\n\nLet the matrix $A \\in \\mathbb{R}^{(M-1)\\times(M-1)}$ be the tridiagonal matrix component of $L_h$, such that $L_h = \\frac{1}{h^2}A$.\n$$\nA =\n\\begin{bmatrix}\n-2  1  0  \\cdots  0 \\\\\n1  -2  1  \\ddots  \\vdots \\\\\n0  1  -2  \\ddots  0 \\\\\n\\vdots  \\ddots  \\ddots  \\ddots  1 \\\\\n0  \\cdots  0  1  -2\n\\end{bmatrix}\n$$\nThe eigenvalues $\\lambda$ and eigenvectors $\\boldsymbol{v}$ of $A$ are found by solving the eigenvalue problem $A\\boldsymbol{v} = \\lambda\\boldsymbol{v}$. Let $\\boldsymbol{v} = (v_1, v_2, \\dots, v_{M-1})^T$. The $i$-th row of the system of equations is:\n$$\nv_{i-1} - 2v_i + v_{i+1} = \\lambda v_i, \\quad \\text{for } i = 1, 2, \\dots, M-1.\n$$\nThe homogeneous Dirichlet boundary conditions $u(0,t)=0$ and $u(1,t)=0$ imply that for the eigenvectors, we must have $v_0 = 0$ and $v_M = 0$. We can rewrite the equation as a second-order linear homogeneous difference equation:\n$$\nv_{i+1} - (2+\\lambda)v_i + v_{i-1} = 0.\n$$\nA standard ansatz for the solution is $v_i = C\\sin(i\\theta)$ for some angle $\\theta$. Substituting this into the difference equation:\n$$\n\\sin((i+1)\\theta) - (2+\\lambda)\\sin(i\\theta) + \\sin((i-1)\\theta) = 0.\n$$\nUsing the trigonometric identity $\\sin(\\alpha+\\beta) + \\sin(\\alpha-\\beta) = 2\\sin(\\alpha)\\cos(\\beta)$, we get:\n$$\n2\\sin(i\\theta)\\cos(\\theta) - (2+\\lambda)\\sin(i\\theta) = 0.\n$$\nFor a non-trivial eigenvector, $\\sin(i\\theta)$ cannot be zero for all $i$, so we can divide by it:\n$$\n2\\cos(\\theta) - (2+\\lambda) = 0 \\implies \\lambda = 2\\cos(\\theta) - 2.\n$$\nUsing the half-angle identity $1-\\cos(\\theta) = 2\\sin^2(\\theta/2)$, this becomes:\n$$\n\\lambda = -2(1-\\cos(\\theta)) = -4\\sin^2\\left(\\frac{\\theta}{2}\\right).\n$$\nNow we apply the boundary conditions. The condition $v_0 = \\sin(0\\cdot\\theta)=0$ is automatically satisfied. The condition $v_M=0$ requires:\n$$\n\\sin(M\\theta) = 0.\n$$\nThis implies $M\\theta = p\\pi$ for some integer $p$. Thus, $\\theta_p = \\frac{p\\pi}{M}$.\nThe index $p$ must run from $p=1, 2, \\dots, M-1$ to generate $M-1$ linearly independent eigenvectors. If $p=0$ or $p=M$, a trivial zero vector is produced.\n\nSo, the $M-1$ eigenpairs $(\\lambda_p, \\boldsymbol{v}_p)$ of the matrix $A$ are:\n- Eigenvalues: $\\lambda_p = -4\\sin^2\\left(\\frac{p\\pi}{2M}\\right)$ for $p=1, 2, \\dots, M-1$.\n- Eigenvectors: The $i$-th component of the $p$-th eigenvector $\\boldsymbol{v}_p$ is $(\\boldsymbol{v}_p)_i = \\sin\\left(\\frac{ip\\pi}{M}\\right)$ for $i=1, 2, \\dots, M-1$.\n\nThe eigenvalues of the discrete Laplacian matrix $L_h = \\frac{1}{h^2}A$ are therefore:\n$$\n\\mu_p = \\frac{1}{h^2}\\lambda_p = -\\frac{4}{h^2}\\sin^2\\left(\\frac{p\\pi}{2M}\\right), \\quad \\text{for } p=1, 2, \\dots, M-1.\n$$\nAll these eigenvalues are real and negative. The \"algebraically largest\" eigenvalue is the one with the smallest magnitude (i.e., closest to zero). The function $\\sin^2(x)$ is increasing for $x \\in [0, \\pi/2]$. The argument $\\frac{p\\pi}{2M}$ is in the range $(0, \\pi/2)$ for $p=1, \\dots, M-1$. Therefore, the smallest magnitude occurs for the smallest value of $p$, which is $p=1$.\n\nThe algebraically largest eigenvalue of $L_h$ is:\n$$\n\\mu_{\\text{largest}} = \\mu_1 = -\\frac{4}{h^2}\\sin^2\\left(\\frac{\\pi}{2M}\\right).\n$$\nNext, we analyze the stability of the Forward Euler scheme:\n$$\n\\boldsymbol{u}^{n+1} = \\boldsymbol{u}^{n} + \\Delta t\\,\\kappa\\,L_{h}\\,\\boldsymbol{u}^{n} = (I + \\Delta t\\,\\kappa\\,L_{h})\\boldsymbol{u}^{n}.\n$$\nThe matrix $G = I + \\Delta t\\,\\kappa\\,L_{h}$ is the amplification matrix. For the method to be stable, the spectral radius of $G$ must not exceed $1$, i.e., $\\rho(G) \\le 1$.\nThe eigenvalues of $G$, denoted by $g_p$, are related to the eigenvalues $\\mu_p$ of $L_h$ by:\n$$\ng_p = 1 + \\Delta t\\,\\kappa\\,\\mu_p.\n$$\nThe stability condition is $|g_p| \\le 1$ for all $p=1, \\dots, M-1$.\n$$\n|1 + \\Delta t\\,\\kappa\\,\\mu_p| \\le 1.\n$$\nSince $\\Delta t  0$, $\\kappa  0$, and $\\mu_p  0$, the term $\\Delta t\\,\\kappa\\,\\mu_p$ is a negative real number. The stability condition simplifies to:\n$$\n-1 \\le 1 + \\Delta t\\,\\kappa\\,\\mu_p \\le 1.\n$$\nThe right-hand inequality, $1 + \\Delta t\\,\\kappa\\,\\mu_p \\le 1$, implies $\\Delta t\\,\\kappa\\,\\mu_p \\le 0$, which is always satisfied.\nThe left-hand inequality, $-1 \\le 1 + \\Delta t\\,\\kappa\\,\\mu_p$, is the one that imposes a restriction on $\\Delta t$:\n$$\n-2 \\le \\Delta t\\,\\kappa\\,\\mu_p \\implies \\Delta t \\le \\frac{-2}{\\kappa \\mu_p}.\n$$\nSubstituting The expression for $\\mu_p$:\n$$\n\\Delta t \\le \\frac{-2}{\\kappa \\left(-\\frac{4}{h^2}\\sin^2\\left(\\frac{p\\pi}{2M}\\right)\\right)} = \\frac{2h^2}{4\\kappa\\sin^2\\left(\\frac{p\\pi}{2M}\\right)} = \\frac{h^2}{2\\kappa\\sin^2\\left(\\frac{p\\pi}{2M}\\right)}.\n$$\nThis inequality must hold for all $p=1, 2, \\dots, M-1$. The most restrictive condition (the smallest upper bound on $\\Delta t$) comes from the eigenvalue that maximizes the term $\\sin^2\\left(\\frac{p\\pi}{2M}\\right)$ in the denominator. This occurs for the largest value of $p$, which is $p=M-1$.\nThe stability is thus governed by the eigenvalue $\\mu_{M-1}$:\n$$\n\\Delta t \\le \\frac{h^2}{2\\kappa\\sin^2\\left(\\frac{(M-1)\\pi}{2M}\\right)}.\n$$\nWe can simplify the sine term using $\\sin\\left(\\frac{(M-1)\\pi}{2M}\\right) = \\sin\\left(\\frac{M\\pi - \\pi}{2M}\\right) = \\sin\\left(\\frac{\\pi}{2} - \\frac{\\pi}{2M}\\right) = \\cos\\left(\\frac{\\pi}{2M}\\right)$.\nSo, the maximum stable time step, $\\Delta t_{\\max}$, is:\n$$\n\\Delta t_{\\max} = \\frac{h^2}{2\\kappa\\cos^2\\left(\\frac{\\pi}{2M}\\right)}.\n$$\nThe two requested quantities are the algebraically largest eigenvalue of $L_h$ and the maximum stable time step $\\Delta t_{\\max}$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{4}{h^{2}}\\sin^{2}\\left(\\frac{\\pi}{2M}\\right)  \\frac{h^{2}}{2\\kappa\\cos^{2}\\left(\\frac{\\pi}{2M}\\right)} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Exact eigenvalue analysis is powerful, but often impractical for matrices arising from complex geometries or in higher dimensions. This practice introduces a valuable tool for such scenarios: the Gershgorin Circle Theorem . You will apply this theorem to derive a guaranteed, though potentially conservative, enclosure for the spectrum of a multi-dimensional discrete Laplacian, and from it, a robust stability condition for the Forward Euler method.",
            "id": "3419070",
            "problem": "Consider the $d$-dimensional heat partial differential equation (PDE) $u_{t} = \\nu \\Delta u$ on the unit hypercube $(0,1)^{d}$ with homogeneous Dirichlet boundary conditions and kinematic viscosity $\\nu  0$. Discretize space on a uniform Cartesian grid with mesh size $h$, and eliminate boundary values to form the standard second-order central-difference semi-discrete system $u^{\\prime}(t) = A u(t)$, where $A \\in \\mathbb{R}^{N \\times N}$ is the discrete Laplacian with homogeneous Dirichlet boundary conditions scaled by $\\nu$. For each interior grid point, the diagonal entry of $A$ equals $-2d\\,\\nu/h^{2}$, each of its nearest-neighbor interior couplings equals $\\nu/h^{2}$, there are at most $2d$ such couplings, and all other entries are zero.\n\nState the Gershgorin Circle Theorem, and then, using only this theorem together with the structural properties of $A$ just described, derive a real interval guaranteed to contain the entire spectrum of $A$. Next, consider the Forward Euler (FE) time discretization applied to the semi-discrete system,\n$$\nu^{n+1} = \\bigl(I + \\Delta t\\, A\\bigr)\\,u^{n}.\n$$\nImpose absolute stability in the sense that the spectral radius of the amplification matrix is at most $1$ using only the spectral enclosure you derived. From this requirement, determine a conservative closed-form expression for the largest admissible time step $\\Delta t_{\\max}$ in terms of $d$, $\\nu$, and $h$ such that the FE method is guaranteed to be absolutely stable for all choices of $A$ consistent with the description above. Provide your final answer as a single analytic expression. Do not include units in your final answer.",
            "solution": "The problem asks for a derivation of the maximum stable time step for the Forward Euler method applied to the semi-discretized $d$-dimensional heat equation, based on a spectral enclosure provided by the Gershgorin Circle Theorem.\n\nFirst, we state the Gershgorin Circle Theorem. For any complex square matrix $M \\in \\mathbb{C}^{N \\times N}$, all of its eigenvalues lie within the union of the Gershgorin discs in the complex plane. The $i$-th disc, $D_i$, is defined by\n$$\nD_i = \\left\\{ z \\in \\mathbb{C} : |z - M_{ii}| \\leq R_i \\right\\}, \\quad \\text{where the radius is} \\quad R_i = \\sum_{j \\neq i} |M_{ij}|.\n$$\n\nNext, we apply this theorem to the given matrix $A \\in \\mathbb{R}^{N \\times N}$. The problem specifies the structure of $A$:\n1.  The diagonal entries are constant for all interior points: $A_{ii} = -\\frac{2d\\nu}{h^2}$.\n2.  The off-diagonal entries for nearest-neighbor couplings are $A_{ij} = \\frac{\\nu}{h^2}$. For all other non-diagonal connections, $A_{ij}=0$.\n3.  Each interior grid point $i$ has $k_i$ interior nearest neighbors, where $k_i \\le 2d$.\n\nWe can now determine the properties of the Gershgorin discs for matrix $A$. For any row $i$, the center of the disc $D_i$ is the diagonal entry:\n$$\nc_i = A_{ii} = -\\frac{2d\\nu}{h^2}.\n$$\nAll discs share the same center, which we denote by $c = -\\frac{2d\\nu}{h^2}$. The radius of the $i$-th disc, $R_i$, is the sum of the absolute values of the off-diagonal entries in the $i$-th row. Since $\\nu  0$ and $h  0$, the off-diagonal entries are non-negative.\n$$\nR_i = \\sum_{j \\neq i} |A_{ij}| = k_i \\cdot \\frac{\\nu}{h^2}.\n$$\nThe problem states that any interior point is coupled to at most $2d$ other interior points. Thus, $k_i \\le 2d$. The radius $R_i$ is therefore bounded by:\n$$\nR_i \\le 2d \\frac{\\nu}{h^2}.\n$$\nLet $R_{\\max} = 2d \\frac{\\nu}{h^2}$. The spectrum of $A$, denoted $\\sigma(A)$, is contained in the union of all discs $\\bigcup_{i=1}^{N} D_i$. Since all discs are centered at the same point $c$, their union is simply the largest disc, which is the one with the maximum possible radius, $R_{\\max}$. Thus, all eigenvalues $\\lambda$ of $A$ must lie within the disc $D_{\\max}$:\n$$\nD_{\\max} = \\left\\{ z \\in \\mathbb{C} : \\left|z - \\left(-\\frac{2d\\nu}{h^2}\\right)\\right| \\leq \\frac{2d\\nu}{h^2} \\right\\}.\n$$\nThe matrix $A$ is the discrete analogue of the operator $\\nu\\Delta$. The standard second-order central-difference discretization results in a symmetric matrix, as the coupling from grid point $i$ to $j$ is identical to the coupling from $j$ to $i$. This is consistent with the problem description. A real symmetric matrix has only real eigenvalues. Therefore, all eigenvalues $\\lambda$ of $A$ must be real numbers.\n\nThe real interval guaranteed to contain the spectrum of $A$ is the intersection of the disc $D_{\\max}$ with the real axis. This interval is $[c - R_{\\max}, c + R_{\\max}]$.\n$$\n\\lambda \\in \\left[ -\\frac{2d\\nu}{h^2} - \\frac{2d\\nu}{h^2}, -\\frac{2d\\nu}{h^2} + \\frac{2d\\nu}{h^2} \\right] = \\left[ -\\frac{4d\\nu}{h^2}, 0 \\right].\n$$\nNow, we analyze the stability of the Forward Euler (FE) method, $u^{n+1} = (I + \\Delta t\\, A)u^{n}$. The amplification matrix is $G = I + \\Delta t\\, A$. The method is absolutely stable if the spectral radius of $G$ is at most $1$, i.e., $\\rho(G) \\leq 1$.\nThe eigenvalues $\\mu_j$ of $G$ are related to the eigenvalues $\\lambda_j$ of $A$ by $\\mu_j = 1 + \\Delta t\\, \\lambda_j$. The stability condition is therefore $|\\mu_j| \\leq 1$ for all eigenvalues $j$, which translates to:\n$$\n|1 + \\Delta t\\, \\lambda_j| \\leq 1, \\quad \\forall \\lambda_j \\in \\sigma(A).\n$$\nTo guarantee stability for any matrix $A$ consistent with the problem description, we must enforce this condition for all values of $\\lambda$ in the enclosure we derived: $\\lambda \\in [-\\frac{4d\\nu}{h^2}, 0]$.\nSince $\\Delta t  0$ and $\\lambda_j \\leq 0$, the quantity $1 + \\Delta t\\, \\lambda_j$ is always less than or equal to $1$. The stability condition simplifies to:\n$$\n1 + \\Delta t\\, \\lambda_j \\geq -1.\n$$\nThis inequality must hold for all $\\lambda_j$ in the spectrum. The condition is most restrictive for the most negative eigenvalue. To ensure it holds for all possible eigenvalues based on our enclosure, we must satisfy it for the lower bound of the interval, $\\lambda = -\\frac{4d\\nu}{h^2}$.\n$$\n1 + \\Delta t \\left(-\\frac{4d\\nu}{h^2}\\right) \\geq -1.\n$$\nSolving for the time step $\\Delta t$:\n$$\n1 - \\frac{4d\\nu\\Delta t}{h^2} \\geq -1\n$$\n$$\n2 \\geq \\frac{4d\\nu\\Delta t}{h^2}\n$$\n$$\n\\Delta t \\leq \\frac{2h^2}{4d\\nu} = \\frac{h^2}{2d\\nu}.\n$$\nThis inequality gives the condition for absolute stability. The problem asks for the largest admissible time step, $\\Delta t_{\\max}$, which is the upper bound of this range.\n$$\n\\Delta t_{\\max} = \\frac{h^2}{2d\\nu}.\n$$\nThis expression is conservative because it is derived from the Gershgorin circle enclosure, which provides an upper bound on the magnitude of the eigenvalues.",
            "answer": "$$\\boxed{\\frac{h^2}{2d\\nu}}$$"
        },
        {
            "introduction": "Stability analysis based on eigenvalues, or the spectral radius, only guarantees the long-term, asymptotic behavior of a numerical method. For non-normal systems, it can miss significant short-term transient amplification that renders a scheme practically useless. This practice tackles this issue head-on by introducing the Kreiss Matrix Theorem , a powerful tool that uses the resolvent norm to quantify this worst-case transient growth, offering a much more complete picture of stability.",
            "id": "3419081",
            "problem": "Consider the linear constant-coefficient scalar partial differential equation (PDE) $u_{t} + a\\,u_{x} = 0$ on the spatial interval $[0,L]$ with advection speed $a0$ and an inflow boundary condition prescribed at $x=0$. Discretize the domain into $m$ uniform control volumes of size $\\Delta x = L/m$, and apply a first-order upwind finite-volume spatial discretization together with forward Euler time stepping of step $\\Delta t$. Let the Courant–Friedrichs–Lewy (CFL) number be $\\nu \\equiv a\\,\\Delta t/\\Delta x \\in (0,1]$. If $U^{n} \\in \\mathbb{R}^{m}$ collects the cell averages at time level $t^{n}$ over the $m$ interior cells (with the inflow boundary condition imposed as a known source at the left boundary), the corresponding homogeneous update is $U^{n+1} = G\\,U^{n}$, where $G \\in \\mathbb{R}^{m \\times m}$ is the strictly lower-bidiagonal Toeplitz matrix\n$$\nG \\;=\\; (1-\\nu)\\,I \\;+\\; \\nu\\,S,\\quad S \\;=\\; \\begin{pmatrix}\n0  0  0  \\cdots  0\\\\\n1  0  0  \\cdots  0\\\\\n0  1  0  \\cdots  0\\\\\n\\vdots  \\ddots  \\ddots  \\ddots  \\vdots\\\\\n0  \\cdots  0  1  0\n\\end{pmatrix},\n$$\nso that $S$ is the unit subdiagonal shift and $S^{m}=0$. Work with the matrix $1$-norm $\\|\\cdot\\|_{1}$ induced by the vector $1$-norm.\n\nUsing the discrete-time Kreiss matrix theorem as your conceptual starting point and only fundamental definitions and well-tested facts, carry out the following tasks:\n\n1. Derive an explicit expression for the resolvent $(zI - G)^{-1}$ in terms of the complex parameter $z \\in \\mathbb{C}$ with $|z|1$, using only the nilpotence of $S$ and geometric-series reasoning valid for matrices.\n2. From your expression, compute the induced matrix $1$-norm $\\|(zI - G)^{-1}\\|_{1}$ as a closed-form function of $z$, $\\nu$, and $m$.\n3. Define the Kreiss constant for the matrix $G$ in the matrix $1$-norm by\n$$\nK_{1}(G) \\;\\equiv\\; \\sup_{|z|1} \\big(|z|-1\\big)\\,\\big\\|(zI - G)^{-1}\\big\\|_{1}.\n$$\nEvaluate this supremum exactly, making sharp use of the structure of $G$ and basic complex inequalities, and thereby quantify the worst-case transient amplification predicted by the resolvent bound.\n\nYour final answer must be the exact value of the Kreiss constant $K_{1}(G)$ as a single real number (no units). No rounding is required.",
            "solution": "The problem asks for the evaluation of the Kreiss constant $K_{1}(G)$ for a specific matrix $G$ arising from the discretization of a linear advection equation. The solution will proceed in three steps as outlined in the problem statement.\n\nFirst, we derive an explicit expression for the resolvent matrix $(zI - G)^{-1}$ for any complex number $z \\in \\mathbb{C}$ with $|z|1$. The given amplification matrix is $G = (1-\\nu)I + \\nu S$, where $I$ is the $m \\times m$ identity matrix, $S$ is the unit subdiagonal shift matrix, and $\\nu \\in (0,1]$ is the CFL number. The matrix $S$ is strictly lower triangular and thus nilpotent, with $S^m=0$.\n\nStarting with the expression for the resolvent, we substitute the definition of $G$:\n$$\nzI - G = zI - \\big((1-\\nu)I + \\nu S\\big) = (z - (1-\\nu))I - \\nu S\n$$\nLet us define a complex scalar $\\alpha \\equiv z - (1-\\nu)$. The expression becomes $\\alpha I - \\nu S$. To find the inverse, we can factor out $\\alpha$:\n$$\n(\\alpha I - \\nu S)^{-1} = \\big(\\alpha(I - \\frac{\\nu}{\\alpha}S)\\big)^{-1} = \\frac{1}{\\alpha}\\left(I - \\frac{\\nu}{\\alpha}S\\right)^{-1}\n$$\nThis step is valid as long as $\\alpha \\neq 0$. The eigenvalues of $G$ are its diagonal entries, which are all $1-\\nu$. Since $|z|1$ and $\\nu \\in (0,1]$, we have $|1-\\nu| \\in [0,1)$, so $z$ cannot be an eigenvalue. Thus, $z-(1-\\nu) = \\alpha \\neq 0$.\n\nWe use the property that for any nilpotent matrix $A$ with $A^m=0$, the geometric series for $(I-A)^{-1}$ terminates, yielding the exact identity $(I-A)^{-1} = \\sum_{k=0}^{m-1} A^k$. In our case, $A = \\frac{\\nu}{\\alpha}S$. Since $S^m=0$, the matrix $A$ is also nilpotent with $A^m=0$. Therefore, we have:\n$$\n\\left(I - \\frac{\\nu}{\\alpha}S\\right)^{-1} = \\sum_{k=0}^{m-1} \\left(\\frac{\\nu}{\\alpha}S\\right)^k = \\sum_{k=0}^{m-1} \\frac{\\nu^k}{\\alpha^k}S^k\n$$\nSubstituting this back into the expression for the resolvent gives:\n$$\n(zI - G)^{-1} = \\frac{1}{\\alpha}\\sum_{k=0}^{m-1} \\frac{\\nu^k}{\\alpha^k}S^k = \\sum_{k=0}^{m-1} \\frac{\\nu^k}{\\alpha^{k+1}}S^k\n$$\nFinally, substituting back $\\alpha = z - (1-\\nu)$, we obtain the explicit expression for the resolvent:\n$$\n(zI - G)^{-1} = \\sum_{k=0}^{m-1} \\frac{\\nu^k}{\\big(z - (1-\\nu)\\big)^{k+1}} S^k\n$$\nThis completes the first task.\n\nSecond, we compute the induced matrix $1$-norm, $\\|(zI - G)^{-1}\\|_{1}$. The matrix $1$-norm is defined as the maximum absolute column sum. Let $R(z) = (zI - G)^{-1}$. From the expression above, $R(z)$ is a linear combination of the matrices $S^k$ for $k=0, 1, \\dots, m-1$. The matrix $S^k$ has entries of $1$ on its $k$-th subdiagonal and $0$s elsewhere. Consequently, $R(z)$ is a lower-triangular Toeplitz matrix. Let $c_k = \\frac{\\nu^k}{(z - (1-\\nu))^{k+1}}$. Then the entries of $R(z)$ are $(R(z))_{ij} = c_{i-j}$ for $i \\ge j$ and $0$ for $i  j$.\n\nThe sum of the absolute values of the elements in the $j$-th column is:\n$$\n\\sum_{i=1}^{m} |(R(z))_{ij}| = \\sum_{i=j}^{m} |c_{i-j}| = \\sum_{k=0}^{m-j} |c_k|\n$$\nThe matrix $1$-norm is the maximum of these sums over all columns $j=1, \\dots, m$:\n$$\n\\|(zI - G)^{-1}\\|_{1} = \\max_{1 \\le j \\le m} \\sum_{k=0}^{m-j} |c_k|\n$$\nSince $\\nu \\in (0,1]$, we have $\\nu^k \\ge 0$. The absolute value of $c_k$ is $|c_k| = \\frac{\\nu^k}{|z-(1-\\nu)|^{k+1}}$, which is non-negative. Therefore, the sum $\\sum_{k=0}^{m-j} |c_k|$ is maximized when the number of terms is maximized, which occurs for the first column ($j=1$).\n$$\n\\|(zI - G)^{-1}\\|_{1} = \\sum_{k=0}^{m-1} |c_k| = \\sum_{k=0}^{m-1} \\frac{\\nu^k}{|z - (1-\\nu)|^{k+1}}\n$$\nLet $r = |z - (1-\\nu)|$. The norm is a geometric series in terms of $\\nu/r$:\n$$\n\\|(zI - G)^{-1}\\|_{1} = \\frac{1}{r} \\sum_{k=0}^{m-1} \\left(\\frac{\\nu}{r}\\right)^k\n$$\nFor any $z$ with $|z|1$, we have $r = |z - (1-\\nu)| \\ge ||z| - |1-\\nu|| = |z| - (1-\\nu)  1 - (1-\\nu) = \\nu$. Thus, $r\\nu$, which implies $\\nu/r  1$. We can sum the finite geometric series:\n$$\n\\sum_{k=0}^{m-1} \\left(\\frac{\\nu}{r}\\right)^k = \\frac{1 - (\\nu/r)^m}{1 - \\nu/r}\n$$\nSubstituting this into the expression for the norm yields the closed-form function:\n$$\n\\|(zI - G)^{-1}\\|_{1} = \\frac{1}{r} \\frac{1 - (\\nu/r)^m}{1 - \\nu/r} = \\frac{1}{r} \\frac{(r^m - \\nu^m)/r^m}{(r-\\nu)/r} = \\frac{r^m - \\nu^m}{r^m(r-\\nu)}\n$$\nSubstituting $r = |z - (1-\\nu)|$ gives the expression as a function of $z$:\n$$\n\\|(zI - G)^{-1}\\|_{1} = \\frac{|z-(1-\\nu)|^m - \\nu^m}{|z-(1-\\nu)|^m (|z-(1-\\nu)| - \\nu)}\n$$\nThis completes the second task.\n\nThird, we evaluate the Kreiss constant $K_{1}(G)$, defined as:\n$$\nK_{1}(G) = \\sup_{|z|1} \\big(|z|-1\\big)\\,\\big\\|(zI - G)^{-1}\\big\\|_{1}\n$$\nLet $r=|z-(1-\\nu)|$. We have found that the norm depends only on $r$. The expression to maximize is $(|z|-1) \\frac{r^m - \\nu^m}{r^m(r-\\nu)}$.\nLet's analyze the term $(|z|-1)$. By the triangle inequality, $|z| = |(z-(1-\\nu)) + (1-\\nu)| \\le |z-(1-\\nu)| + |1-\\nu| = r + (1-\\nu)$. This implies $|z|-1 \\le r-\\nu$. This maximum value for $|z|-1$ is attained when $z$, $z-(1-\\nu)$, and $1-\\nu$ are collinear and positively oriented, i.e., for $z$ on the positive real axis. If we choose $z = r + (1-\\nu)$, then $|z|-1 = r-\\nu$. This choice of $z$ must be in the domain $|z|1$, which requires $r+1-\\nu  1$, or $r\\nu$. As we have shown that for any $|z|1$, $r=|z-(1-\\nu)|  \\nu$, the range of possible values for $r$ is $(\\nu, \\infty)$.\nThus, for any $r  \\nu$, the supremum of the factor $(|z|-1)$ over all $z$ with $|z-(1-\\nu)|=r$ and $|z|1$ is indeed $r-\\nu$. We can therefore reduce the supremum over the complex variable $z$ to a supremum over the real variable $r$:\n$$\nK_{1}(G) = \\sup_{r\\nu} (r-\\nu) \\left( \\frac{r^m - \\nu^m}{r^m(r-\\nu)} \\right)\n$$\nFor $r\\nu$, the term $(r-\\nu)$ is non-zero and can be canceled:\n$$\nK_{1}(G) = \\sup_{r\\nu} \\frac{r^m - \\nu^m}{r^m} = \\sup_{r\\nu} \\left(1 - \\left(\\frac{\\nu}{r}\\right)^m\\right)\n$$\nLet $h(r) = 1 - (\\nu/r)^m$. To find the supremum of $h(r)$ for $r \\in (\\nu, \\infty)$, we inspect its derivative: $h'(r) = - \\nu^m (-m r^{-m-1}) = m\\nu^m r^{-m-1}$. Since $m \\ge 1$, $\\nu0$, and $r0$, we have $h'(r)0$. So, $h(r)$ is a strictly increasing function on its domain. The supremum of an increasing function on an open interval $(\\nu, \\infty)$ is the limit as its argument approaches infinity.\n$$\nK_{1}(G) = \\lim_{r\\to\\infty} \\left(1 - \\left(\\frac{\\nu}{r}\\right)^m\\right)\n$$\nAs $r\\to\\infty$, the term $(\\nu/r)^m \\to 0$. Therefore,\n$$\nK_{1}(G) = 1 - 0 = 1\n$$\nThis result indicates that for the first-order upwind scheme in the $1$-norm, there is no transient amplification of perturbations as measured by the Kreiss constant. This aligns with the fact that the $1$-norm of the amplification matrix itself is $\\|G\\|_1 = 1$, which implies that $\\|G^n\\|_1 \\le (\\|G\\|_1)^n = 1$ for all $n \\ge 0$.",
            "answer": "$$\\boxed{1}$$"
        }
    ]
}