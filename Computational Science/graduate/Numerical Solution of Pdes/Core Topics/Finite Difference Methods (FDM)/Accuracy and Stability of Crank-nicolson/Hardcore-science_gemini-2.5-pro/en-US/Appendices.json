{
    "hands_on_practices": [
        {
            "introduction": "The Crank-Nicolson method is famously unconditionally stable for parabolic problems, a highly desirable property for numerical time integration. However, this $L_2$-stability does not guarantee that the numerical solution will respect all qualitative properties of the exact solution, such as positivity. This practice explores the crucial concept of positivity preservation, demonstrating that even for simple systems, Crank-Nicolson can produce non-physical oscillations unless the time step $\\Delta t$ is sufficiently small .",
            "id": "3360619",
            "problem": "Consider the linear parabolic initial value problem in semi-discrete form $u^{\\prime}(t)=-A\\,u(t)$, where $A\\in\\mathbb{R}^{2\\times 2}$ is the matrix\n$$\nA=\\begin{pmatrix}\n2  -1\\\\\n-1  2\n\\end{pmatrix}.\n$$\nAssume a single time step of the Crank–Nicolson method with step size $\\Delta t0$ is applied to advance the solution from $u^{n}$ to $u^{n+1}$. The notion of positivity is understood componentwise: a vector $v\\in\\mathbb{R}^{2}$ is positive if $v_{i}\\ge 0$ for each component.\n\nThe matrix $A$ has nonpositive off-diagonal entries and a positive inverse, hence $A$ is a nonsingular $M$-matrix in the standard sense. The continuous semigroup generated by $-A$ preserves positivity. However, the Crank–Nicolson method may fail to preserve positivity for certain choices of $\\Delta t$.\n\nStarting from the fundamental definition of the Crank–Nicolson method for linear systems and the definition of an $M$-matrix, do the following:\n- Derive the one-step linear update operator that maps $u^{n}$ to $u^{n+1}$ for the system $u^{\\prime}=-A u$ under Crank–Nicolson.\n- Using $u^{n}=e_{1}=(1,0)^{\\top}$ as a positive initial vector, determine the smallest positive time step $\\Delta t$ for which the first component of $u^{n+1}$ is strictly negative.\n\nYour final answer must be a single exact expression for this smallest $\\Delta t$. Do not round.",
            "solution": "The problem asks for the smallest positive time step $\\Delta t$ for which the Crank-Nicolson (CN) method, applied to the system $u^{\\prime}(t) = -A u(t)$, fails to preserve positivity. Specifically, we need to find the critical $\\Delta t$ where the first component of the solution becomes negative, starting from a positive initial vector $u^n = e_1$.\n\nFirst, we derive the one-step linear update operator for the Crank-Nicolson method. The method approximates the differential equation $u' = -A u$ over a time interval $[t_n, t_{n+1}]$ with $t_{n+1} = t_n + \\Delta t$ as follows:\n$$ \\frac{u^{n+1} - u^{n}}{\\Delta t} = \\frac{1}{2} \\left( (-A u^{n+1}) + (-A u^{n}) \\right) $$\nwhere $u^n$ and $u^{n+1}$ are the numerical approximations of the solution at times $t_n$ and $t_{n+1}$ respectively.\n\nTo find the update operator that maps $u^n$ to $u^{n+1}$, we must solve for $u^{n+1}$:\n$$ u^{n+1} - u^{n} = -\\frac{\\Delta t}{2} A u^{n+1} - \\frac{\\Delta t}{2} A u^{n} $$\nRearranging the terms to group $u^{n+1}$ on the left-hand side and $u^{n}$ on the right-hand side gives:\n$$ u^{n+1} + \\frac{\\Delta t}{2} A u^{n+1} = u^{n} - \\frac{\\Delta t}{2} A u^{n} $$\nFactoring out the vectors $u^{n+1}$ and $u^{n}$:\n$$ \\left(I + \\frac{\\Delta t}{2} A\\right) u^{n+1} = \\left(I - \\frac{\\Delta t}{2} A\\right) u^{n} $$\nwhere $I$ is the $2 \\times 2$ identity matrix.\n\nSolving for $u^{n+1}$, we get:\n$$ u^{n+1} = \\left(I + \\frac{\\Delta t}{2} A\\right)^{-1} \\left(I - \\frac{\\Delta t}{2} A\\right) u^{n} $$\nThis defines the one-step linear update operator, or amplification matrix, $G$:\n$$ G = \\left(I + \\frac{\\Delta t}{2} A\\right)^{-1} \\left(I - \\frac{\\Delta t}{2} A\\right) $$\n\nNow, we compute this operator explicitly for the given matrix $A = \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix}$. Let's simplify the notation by setting $k = \\frac{\\Delta t}{2}$. Since $\\Delta t  0$, we have $k  0$. The expression for $G$ becomes:\n$$ G = (I + kA)^{-1} (I - kA) $$\nFirst, we compute the two matrices in this expression:\n$$ I+kA = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + k \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} = \\begin{pmatrix} 1+2k  -k \\\\ -k  1+2k \\end{pmatrix} $$\n$$ I-kA = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} - k \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} = \\begin{pmatrix} 1-2k  k \\\\ k  1-2k \\end{pmatrix} $$\nNext, we find the inverse of $(I+kA)$. The determinant is:\n$$ \\det(I+kA) = (1+2k)(1+2k) - (-k)(-k) = (1+2k)^2 - k^2 = 1+4k+4k^2 - k^2 = 1+4k+3k^2 $$\nFactoring the determinant, we get $\\det(I+kA) = (1+k)(1+3k)$. Since $k0$, the determinant is non-zero, and the inverse exists.\nThe inverse is given by:\n$$ (I+kA)^{-1} = \\frac{1}{(1+k)(1+3k)} \\begin{pmatrix} 1+2k  k \\\\ k  1+2k \\end{pmatrix} $$\nNow we can compute the operator $G$:\n$$ G = \\frac{1}{(1+k)(1+3k)} \\begin{pmatrix} 1+2k  k \\\\ k  1+2k \\end{pmatrix} \\begin{pmatrix} 1-2k  k \\\\ k  1-2k \\end{pmatrix} $$\nPerforming the matrix multiplication:\n$$ G = \\frac{1}{(1+k)(1+3k)} \\begin{pmatrix} (1+2k)(1-2k)+k^2  (1+2k)k+k(1-2k) \\\\ k(1-2k)+(1+2k)k  k^2+(1+2k)(1-2k) \\end{pmatrix} $$\n$$ G = \\frac{1}{(1+k)(1+3k)} \\begin{pmatrix} 1-4k^2+k^2  k+2k^2+k-2k^2 \\\\ k-2k^2+k+2k^2  k^2+1-4k^2 \\end{pmatrix} $$\n$$ G = \\frac{1}{(1+k)(1+3k)} \\begin{pmatrix} 1-3k^2  2k \\\\ 2k  1-3k^2 \\end{pmatrix} $$\nThis is the explicit form of the update operator.\n\nThe problem asks to find the smallest $\\Delta t  0$ for which the first component of $u^{n+1}$ is strictly negative, given the initial vector $u^n = e_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$. We compute $u^{n+1}$:\n$$ u^{n+1} = G u^n = \\frac{1}{(1+k)(1+3k)} \\begin{pmatrix} 1-3k^2  2k \\\\ 2k  1-3k^2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} $$\n$$ u^{n+1} = \\frac{1}{(1+k)(1+3k)} \\begin{pmatrix} 1-3k^2 \\\\ 2k \\end{pmatrix} $$\nSo the components of $u^{n+1}$ are:\n$$ (u^{n+1})_1 = \\frac{1-3k^2}{(1+k)(1+3k)} \\quad \\text{and} \\quad (u^{n+1})_2 = \\frac{2k}{(1+k)(1+3k)} $$\nWe want to find the condition on $\\Delta t$ such that $(u^{n+1})_1  0$.\n$$ \\frac{1-3k^2}{(1+k)(1+3k)}  0 $$\nSince $k = \\Delta t/2  0$, the denominator $(1+k)(1+3k)$ is always positive. Therefore, the inequality is satisfied if and only if the numerator is negative:\n$$ 1-3k^2  0 $$\n$$ 1  3k^2 $$\n$$ k^2  \\frac{1}{3} $$\nSince $k0$, we take the positive square root of both sides:\n$$ k  \\frac{1}{\\sqrt{3}} $$\nNow, we substitute back $k = \\frac{\\Delta t}{2}$:\n$$ \\frac{\\Delta t}{2}  \\frac{1}{\\sqrt{3}} $$\n$$ \\Delta t  \\frac{2}{\\sqrt{3}} $$\nThe first component of $u^{n+1}$ is strictly negative for any time step $\\Delta t$ in the open interval $(\\frac{2}{\\sqrt{3}}, \\infty)$. The problem asks for the \"smallest positive time step\" for which this condition holds. This corresponds to the infimum of this set of values. At the boundary value $\\Delta t = \\frac{2}{\\sqrt{3}}$, the first component $(u^{n+1})_1$ is zero. For any $\\Delta t$ infinitesimally larger than this value, the component becomes negative. Thus, the critical value that marks the boundary between positivity preservation and its violation is this infimum.\n\nThe smallest positive time step $\\Delta t$ at which the positivity property is lost is $\\frac{2}{\\sqrt{3}}$. This can also be written with a rationalized denominator as $\\frac{2\\sqrt{3}}{3}$.",
            "answer": "$$\\boxed{\\frac{2}{\\sqrt{3}}}$$"
        },
        {
            "introduction": "A key advantage of the Crank-Nicolson method is its formal second-order accuracy in time, which suggests that the global error behaves like $O(\\Delta t^2)$. This property, however, is not automatic and depends critically on the accuracy of the entire numerical procedure, including the very first step. This exercise investigates how an initial error, such as one from a first-order startup scheme, propagates through the simulation and can degrade the overall accuracy of the solution . Understanding this principle is fundamental to achieving the expected rate of convergence in practice.",
            "id": "3360622",
            "problem": "Consider the one-dimensional heat equation $u_{t}=\\nu u_{xx}$ on a periodic domain. For a single spatial Fourier mode $k$, the method of lines reduces the partial differential equation to the scalar ordinary differential equation $a'(t)=-\\mu a(t)$ with $\\mu=\\nu k^{2}0$ and initial amplitude $a(0)=a_{0}$. The Crank–Nicolson method (the implicit trapezoidal rule) is used to advance this mode in time for steps $n\\geq 1$ with a fixed time step $\\Delta t0$, while the very first step is initialized by an auxiliary procedure that produces a first-step value $a^{1}$ that is only first-order accurate at $t=\\Delta t$. Concretely, assume\n$$\na^{1}=a(\\Delta t)+c\\,\\Delta t+O(\\Delta t^{2}),\n$$\nwhere $c$ is a constant independent of $\\Delta t$ and depends only on $\\mu$, $a_{0}$, and the chosen initialization procedure. Let $T=N\\Delta t$ be a fixed final time with integer $N\\geq 2$, and denote the discrete Crank–Nicolson solution at $t_{n}=n\\Delta t$ by $a^{n}$ and the exact solution at time $T$ by $a(T)$.\n\nStarting from the core definition that Crank–Nicolson is the trapezoidal rule applied to the method-of-lines ordinary differential equation $a'(t)=-\\mu a(t)$, and using only fundamental properties of the exponential solution of a linear constant-coefficient ordinary differential equation, derive the leading-order term of the global temporal error $e^{N}=a^{N}-a(T)$ as $\\Delta t\\to 0$, showing it is proportional to $\\Delta t$. Compute the coefficient of $\\Delta t$ explicitly in terms of $\\mu$, $T$, and $c$. Then, explain briefly why this coefficient disappears if a defect correction is applied at the first step that enforces the trapezoidal-rule residual at $t=\\Delta t$ to be $O(\\Delta t^{3})$.\n\nExpress your final answer as a single closed-form analytic expression for the coefficient of $\\Delta t$ in $e^{N}$; no units are required and no rounding is necessary.",
            "solution": "The problem asks for the leading-order term of the global temporal error for the Crank-Nicolson method applied to a model ODE, where the first step is computed with a first-order accurate method. It also asks for the coefficient of the leading error term and an explanation for why this term vanishes under a specific defect correction.\n\nFirst, we establish the exact solution and the numerical scheme. The method of lines reduces the PDE to the ordinary differential equation (ODE) for a single Fourier mode:\n$$\na'(t) = -\\mu a(t)\n$$\nwith initial condition $a(0) = a_0$ and $\\mu  0$. The exact solution is\n$$\na(t) = a_0 \\exp(-\\mu t)\n$$\nThe Crank-Nicolson method is the implicit trapezoidal rule applied to this ODE. For steps $n \\ge 1$, it is defined by:\n$$\n\\frac{a^{n+1} - a^n}{\\Delta t} = \\frac{1}{2}\\left(-\\mu a^{n+1} - \\mu a^n\\right)\n$$\nSolving for $a^{n+1}$ gives the recurrence relation:\n$$\na^{n+1}\\left(1 + \\frac{\\mu \\Delta t}{2}\\right) = a^n\\left(1 - \\frac{\\mu \\Delta t}{2}\\right)\n$$\n$$\na^{n+1} = \\frac{1 - \\mu \\Delta t/2}{1 + \\mu \\Delta t/2} a^n\n$$\nLet $R(\\mu\\Delta t) = \\frac{1 - \\mu \\Delta t/2}{1 + \\mu \\Delta t/2}$ be the amplification factor of the Crank-Nicolson method. The numerical solution for $n \\ge 1$ is given by $a^{n+1} = R(\\mu\\Delta t) a^n$.\n\nThe global error at time $t_n = n\\Delta t$ is defined as $e^n = a^n - a(t_n)$. We are given that the first step provides a value $a^1$ such that its error is:\n$$\ne^1 = a^1 - a(\\Delta t) = c\\,\\Delta t + O(\\Delta t^2)\n$$\nwhere $c$ is a constant. This is a first-order local error at the first step.\n\nFor $n \\ge 1$, we can derive a recurrence for the global error:\n$$\ne^{n+1} = a^{n+1} - a(t_{n+1}) = R(\\mu\\Delta t)a^n - a(t_{n+1})\n$$\nSubstitute $a^n = e^n + a(t_n)$:\n$$\ne^{n+1} = R(\\mu\\Delta t)(e^n + a(t_n)) - a(t_{n+1}) = R(\\mu\\Delta t)e^n + \\left( R(\\mu\\Delta t)a(t_n) - a(t_{n+1}) \\right)\n$$\nThe term in the parentheses is the one-step error, let's denote it by $d_{n+1}$. It represents the error introduced by a single Crank-Nicolson step applied to the exact solution at $t_n$. Since $a(t_{n+1}) = \\exp(-\\mu\\Delta t)a(t_n)$, we have:\n$$\nd_{n+1} = \\left( R(\\mu\\Delta t) - \\exp(-\\mu\\Delta t) \\right) a(t_n)\n$$\nTo find the order of $d_{n+1}$, we expand both $R(z)$ and $\\exp(-z)$ for $z=\\mu\\Delta t$ in a Taylor series around $z=0$:\n$$\n\\exp(-z) = 1 - z + \\frac{z^2}{2} - \\frac{z^3}{6} + O(z^4)\n$$\n$$\nR(z) = \\frac{1-z/2}{1+z/2} = (1-z/2)\\left(1 - \\frac{z}{2} + \\frac{z^2}{4} - \\frac{z^3}{8} + \\dots \\right) = 1 - z + \\frac{z^2}{2} - \\frac{z^3}{4} + O(z^4)\n$$\nThe difference is:\n$$\nR(z) - \\exp(-z) = \\left(-\\frac{1}{4} + \\frac{1}{6}\\right)z^3 + O(z^4) = -\\frac{1}{12}z^3 + O(z^4)\n$$\nThus, the one-step error is:\n$$\nd_{n+1} = \\left(-\\frac{1}{12}(\\mu\\Delta t)^3 + O(\\Delta t^4)\\right)a(t_n) = O(\\Delta t^3)\n$$\nThis confirms that the Crank-Nicolson method has a local error of $O(\\Delta t^3)$, making it a second-order accurate method.\n\nThe error recurrence is $e^{n+1} = R(\\mu\\Delta t)e^n + d_{n+1}$ for $n \\ge 1$. To find the global error at the final time $T=N\\Delta t$, $e^N$, we unroll this recurrence starting from $e^1$:\n$$\ne^N = R^{N-1}e^1 + R^{N-2}d_2 + R^{N-3}d_3 + \\dots + R^0 d_N = R^{N-1}e^1 + \\sum_{j=2}^{N} R^{N-j}d_j\n$$\nWe now analyze the magnitude of each term as $\\Delta t \\to 0$ with $T=N\\Delta t$ held fixed.\n\n1.  **Contribution from the initial error:** The first term is $R^{N-1}e^1$.\n    As $\\Delta t \\to 0$, $N = T/\\Delta t \\to \\infty$. The amplification factor can be approximated as $R(\\mu\\Delta t) = \\exp(-\\mu\\Delta t) + O(\\Delta t^3)$.\n    The power $R^{N-1}$ can be analyzed as follows:\n    $$\n    R^{N-1} = \\left(\\exp(-\\mu\\Delta t) + O(\\Delta t^3)\\right)^{N-1}\n    $$\n    Using the binomial expansion, this is $\\left(\\exp(-\\mu\\Delta t)\\right)^{N-1} + (N-1)\\left(\\exp(-\\mu\\Delta t)\\right)^{N-2}O(\\Delta t^3) + \\dots$.\n    The first term is $\\exp(-\\mu(N-1)\\Delta t) = \\exp(-\\mu(T-\\Delta t)) = \\exp(-\\mu T)\\exp(\\mu\\Delta t) = \\exp(-\\mu T)(1 + O(\\Delta t))$.\n    The correction term is of order $(T/\\Delta t) \\cdot \\Delta t^3 = O(\\Delta t^2)$.\n    So, $R^{N-1} = \\exp(-\\mu T) + O(\\Delta t)$.\n    Therefore, the contribution from the initial error is:\n    $$\n    R^{N-1}e^1 \\approx (\\exp(-\\mu T) + O(\\Delta t)) (c\\Delta t + O(\\Delta t^2)) = c\\exp(-\\mu T)\\Delta t + O(\\Delta t^2)\n    $$\n    The leading-order term from the initial error is $c\\exp(-\\mu T)\\Delta t$.\n\n2.  **Contribution from accumulated local errors:** The second term is the sum $\\sum_{j=2}^{N} R^{N-j}d_j$.\n    The one-step error $d_j$ is $O(\\Delta t^3)$. The amplification factor $R^{N-j} = O(1)$ for all $j$. The sum has $N-1$ terms.\n    The total contribution from this sum is approximately $(N-1) \\times O(\\Delta t^3) \\approx (T/\\Delta t) \\times O(\\Delta t^3) = O(\\Delta t^2)$.\n    More formally, the sum is a Riemann sum approximation of an integral:\n    $$\n    \\sum_{j=2}^{N} R^{N-j}d_j \\approx \\sum_{j=1}^{N-1} \\exp(-\\mu(N-1-j)\\Delta t) \\left( -\\frac{1}{12}(\\mu\\Delta t)^3 a(t_j) \\right)\n    $$\n    This can be shown to evaluate to an expression of order $O(\\Delta t^2)$. The leading term comes from the sum of local truncation errors, which is known to be of order $\\Delta t^2$ for a second-order method.\n\nCombining both contributions, the global error is:\n$$\ne^N = c\\exp(-\\mu T)\\Delta t + O(\\Delta t^2)\n$$\nThe first-order error introduced at the first step dominates the overall error, reducing the global accuracy to first order. The leading-order term of the global error is proportional to $\\Delta t$. The coefficient of $\\Delta t$ is $c\\exp(-\\mu T)$.\n\nFinally, we consider the effect of a defect correction at the first step. The problem states this correction \"enforces the trapezoidal-rule residual at $t=\\Delta t$ to be $O(\\Delta t^3)$\". The residual for a value $a^1$ is $\\rho(a^1) = \\frac{a^1-a_0}{\\Delta t} + \\frac{\\mu}{2}(a^1+a_0)$.\nA standard Crank-Nicolson step, which we'll call $a^1_{CN}$, sets this residual to zero. As shown previously, this step is second-order accurate, meaning the one-step error $a^1_{CN} - a(\\Delta t)$ is actually $O(\\Delta t^3)$.\nIf a corrected value $\\tilde{a}^1$ has a residual $\\rho(\\tilde{a}^1)=O(\\Delta t^3)$, this means\n$$\n\\tilde{a}^1 - a^1_{CN} = O(\\Delta t^4)\n$$\nTherefore, the error of this corrected first step is\n$$\n\\tilde{e}^1 = \\tilde{a}^1 - a(\\Delta t) = (a^1_{CN} + O(\\Delta t^4)) - a(\\Delta t) = (a(\\Delta t) + O(\\Delta t^3)) - a(\\Delta t) + O(\\Delta t^4) = O(\\Delta t^3)\n$$\nThis means the corrected first step is accurate to at least second order; there is no $O(\\Delta t)$ term in its error expansion. In the context of the problem statement's error form $e^1 = c\\Delta t + O(\\Delta t^2)$, this implies that the constant $c$ must be zero.\nWhen $c=0$, the coefficient of the leading-order global error term, $c\\exp(-\\mu T)$, becomes zero. The global error is then determined by the $O(\\Delta t^2)$ terms, restoring the expected second-order accuracy of the Crank-Nicolson scheme.",
            "answer": "$$\n\\boxed{c\\exp(-\\mu T)}\n$$"
        },
        {
            "introduction": "In numerical analysis, we often analyze the errors from spatial and temporal discretizations separately. This practice explores the more advanced and subtle idea that these errors can interact, and in carefully engineered circumstances, even cancel each other out to achieve a higher-than-expected order of accuracy. This phenomenon, known as superconvergence, is a powerful concept in the design of numerical methods. By deriving the specific relationship between the time step and grid spacing that achieves this error cancellation for the heat equation , you will gain insight into the intricate balance between different sources of discretization error.",
            "id": "3360618",
            "problem": "Consider the one-dimensional heat equation $u_{t} = \\nu u_{xx}$ on the periodic domain $x \\in [0,L]$, where $\\nu  0$ is the thermal diffusivity. Let $x_{j} = j h$ for $j = 0,1,\\dots,M-1$ with $h = L/M$ and $t_{n} = n \\Delta t$. Discretize $u_{t} = \\nu u_{xx}$ using the Crank–Nicolson (CN) method in time and the standard centered second-difference approximation to $u_{xx}$ in space:\n$$\n\\frac{u_{j}^{n+1} - u_{j}^{n}}{\\Delta t} = \\frac{\\nu}{2} \\left( \\frac{u_{j+1}^{n} - 2 u_{j}^{n} + u_{j-1}^{n}}{h^{2}} + \\frac{u_{j+1}^{n+1} - 2 u_{j}^{n+1} + u_{j-1}^{n+1}}{h^{2}} \\right).\n$$\nAssume a single Fourier mode initial condition $u(x,0) = \\exp(\\mathrm{i} k_{0} x)$ with wavenumber $k_{0} = \\frac{2\\pi m_{0}}{L}$ for some fixed integer $m_{0} \\neq 0$. For this mode, the exact continuous-time amplification over a single time step is $\\exp(-\\nu k_{0}^{2} \\Delta t)$. The fully discrete CN scheme applied to this mode has an amplification factor that can be expressed in terms of the discrete Laplacian’s eigenvalue, which depends on $h$.\n\nStarting from fundamental principles—Fourier mode analysis for linear constant-coefficient partial differential equations, the modified wavenumber of the centered second difference, and the Padé-approximant interpretation of the CN method—derive the leading-order combined error in the logarithm of the amplification factor over one time step, and design the mesh-to-time-step ratio so that the leading spatial discretization error cancels the leading CN time integration error for the specific mode $k_{0}$ (superconvergence for that mode). Explicitly, determine the unique closed-form expression for the dimensionless ratio $\\Delta t / h$ in terms of $\\nu$ and $k_{0}$ that achieves this cancellation to leading order.\n\nExpress your final answer as a single closed-form analytic expression for $\\Delta t / h$. No rounding is required, and no units should be included in your final expression.",
            "solution": "The problem requires us to find a specific ratio of the time step $\\Delta t$ to the spatial step $h$ such that the leading-order spatial discretization error cancels the leading-order temporal discretization error for a single Fourier mode solution to the heat equation, when using the Crank-Nicolson (CN) numerical method.\n\nThe one-dimensional heat equation is given by:\n$$\nu_{t} = \\nu u_{xx}\n$$\nThe Crank-Nicolson discretization provided is:\n$$\n\\frac{u_{j}^{n+1} - u_{j}^{n}}{\\Delta t} = \\frac{\\nu}{2} \\left( \\frac{u_{j+1}^{n} - 2 u_{j}^{n} + u_{j-1}^{n}}{h^{2}} + \\frac{u_{j+1}^{n+1} - 2 u_{j}^{n+1} + u_{j-1}^{n+1}}{h^{2}} \\right)\n$$\nWe analyze the behavior of this scheme on a single Fourier mode, $u(x,t) = \\exp(-\\nu k_{0}^{2} t) \\exp(\\mathrm{i} k_{0} x)$. The spatial part is $\\exp(\\mathrm{i} k_{0} x)$. Its discrete counterpart is $u_{j}^{n} = (G_{num})^{n} \\exp(\\mathrm{i} k_{0} x_{j}) = (G_{num})^{n} \\exp(\\mathrm{i} k_{0} j h)$, where $G_{num}$ is the numerical amplification factor per time step $\\Delta t$.\n\nLet's substitute this form of the solution into the CN scheme.\nThe finite difference operator in space, $\\delta_x^2$, acts on the spatial part as follows:\n$$\n\\delta_x^2 u_{j} = u_{j+1} - 2u_{j} + u_{j-1} = \\exp(\\mathrm{i} k_{0} (j+1) h) - 2\\exp(\\mathrm{i} k_{0} j h) + \\exp(\\mathrm{i} k_{0} (j-1) h)\n$$\n$$\n= \\exp(\\mathrm{i} k_{0} j h) \\left( \\exp(\\mathrm{i} k_{0} h) - 2 + \\exp(-\\mathrm{i} k_{0} h) \\right)\n$$\n$$\n= \\exp(\\mathrm{i} k_{0} j h) \\left( 2\\cos(k_{0}h) - 2 \\right) = -4\\sin^{2}\\left(\\frac{k_{0}h}{2}\\right) \\exp(\\mathrm{i} k_{0} j h)\n$$\nThe action of the discrete Laplacian operator $\\frac{\\delta_x^2}{h^2}$ on the mode is thus multiplication by the eigenvalue $\\lambda_{h}(k_{0})$:\n$$\n\\lambda_{h}(k_{0}) = -\\frac{4}{h^{2}}\\sin^{2}\\left(\\frac{k_{0}h}{2}\\right)\n$$\nSubstituting $u_{j}^{n} = (G_{num})^{n} \\exp(\\mathrm{i} k_{0} j h)$ into the CN scheme equation yields:\n$$\n\\frac{(G_{num})^{n+1} - (G_{num})^{n}}{\\Delta t} \\exp(\\mathrm{i} k_{0} j h) = \\frac{\\nu}{2} \\left( (G_{num})^{n} \\lambda_{h}(k_{0}) \\exp(\\mathrm{i} k_{0} j h) + (G_{num})^{n+1} \\lambda_{h}(k_{0}) \\exp(\\mathrm{i} k_{0} j h) \\right)\n$$\nDividing by $(G_{num})^{n} \\exp(\\mathrm{i} k_{0} j h)$ (assuming it is non-zero), we get an equation for $G_{num}$:\n$$\n\\frac{G_{num} - 1}{\\Delta t} = \\frac{\\nu}{2} \\lambda_{h}(k_{0}) (1 + G_{num})\n$$\nSolving for $G_{num}$:\n$$\nG_{num} - 1 = \\frac{\\nu \\Delta t \\lambda_{h}(k_{0})}{2} (1 + G_{num})\n$$\n$$\nG_{num}\\left(1 - \\frac{\\nu \\Delta t \\lambda_{h}(k_{0})}{2}\\right) = 1 + \\frac{\\nu \\Delta t \\lambda_{h}(k_{0})}{2}\n$$\n$$\nG_{num} = \\frac{1 + \\frac{1}{2} \\nu \\Delta t \\lambda_{h}(k_{0})}{1 - \\frac{1}{2} \\nu \\Delta t \\lambda_{h}(k_{0})}\n$$\nLet $z_{h} = \\nu \\Delta t \\lambda_{h}(k_{0})$. The numerical amplification factor is $G_{num} = \\frac{1+z_{h}/2}{1-z_{h}/2}$. This is the $(1,1)$-Padé approximant to $\\exp(z_h)$.\n\nThe problem concerns the error in the logarithm of the amplification factor. For the continuous PDE, the exact amplification factor over a time step $\\Delta t$ is $G_{exact} = \\exp(-\\nu k_{0}^{2} \\Delta t)$. The exact amplification exponent is $\\log(G_{exact}) = -\\nu k_{0}^{2} \\Delta t$. The numerical amplification exponent is $\\log(G_{num})$. The error is $E = \\log(G_{num}) - \\log(G_{exact})$.\n\nTo find the leading-order error, we expand $\\log(G_{num})$ in terms of the small parameters $h$ and $\\Delta t$.\nFirst, we expand the discrete eigenvalue $\\lambda_{h}(k_{0})$ for small $h$, using the Taylor series for $\\sin(x) = x - x^3/6 + \\mathcal{O}(x^5)$:\n$$\n\\lambda_{h}(k_{0}) = -\\frac{4}{h^{2}}\\left( \\frac{k_{0}h}{2} - \\frac{1}{6}\\left(\\frac{k_{0}h}{2}\\right)^{3} + \\mathcal{O}(h^5) \\right)^{2}\n$$\n$$\n= -\\frac{4}{h^{2}}\\left( \\frac{k_{0}^{2}h^{2}}{4} - 2\\frac{k_{0}h}{2}\\frac{k_{0}^{3}h^{3}}{48} + \\mathcal{O}(h^6) \\right)\n$$\n$$\n= -\\frac{4}{h^{2}}\\left( \\frac{k_{0}^{2}h^{2}}{4} - \\frac{k_{0}^{4}h^{4}}{48} + \\mathcal{O}(h^6) \\right) = -k_{0}^{2} + \\frac{k_{0}^{4}h^{2}}{12} + \\mathcal{O}(h^4)\n$$\nThe term $-k_{0}^{2}$ corresponds to the exact differential operator $\\frac{\\partial^2}{\\partial x^2}$, and $\\frac{k_{0}^{4}h^{2}}{12}$ is the leading-order spatial discretization error term for the eigenvalue.\n\nNext, we expand $\\log(G_{num})=\\log\\left(\\frac{1+z_{h}/2}{1-z_{h}/2}\\right)$ for small $z_{h}$. Using $\\log(1+x) = x - x^2/2 + x^3/3 - \\dots$:\n$$\n\\log(G_{num}) = \\log(1+z_{h}/2) - \\log(1-z_{h}/2)\n$$\n$$\n= \\left(\\frac{z_{h}}{2} - \\frac{1}{2}\\left(\\frac{z_{h}}{2}\\right)^{2} + \\frac{1}{3}\\left(\\frac{z_{h}}{2}\\right)^{3} - \\dots\\right) - \\left(-\\frac{z_{h}}{2} - \\frac{1}{2}\\left(-\\frac{z_{h}}{2}\\right)^{2} - \\frac{1}{3}\\left(-\\frac{z_{h}}{2}\\right)^{3} - \\dots\\right)\n$$\n$$\n= \\left(\\frac{z_{h}}{2} - \\frac{z_{h}^{2}}{8} + \\frac{z_{h}^{3}}{24} - \\dots\\right) - \\left(-\\frac{z_{h}}{2} - \\frac{z_{h}^{2}}{8} - \\frac{z_{h}^{3}}{24} - \\dots\\right)\n$$\n$$\n\\log(G_{num}) = z_{h} + \\frac{z_{h}^{3}}{12} + \\mathcal{O}(z_{h}^{5})\n$$\nThe term $z_{h}$ would be exact if the numerical method perfectly reproduced $\\exp(z_h)$, but $\\frac{z_h^3}{12}$ is the leading-order temporal error of the CN method in the logarithm of the amplification factor.\n\nNow, we combine these expansions. We substitute the expansion for $\\lambda_h(k_0)$ into $z_{h}$:\n$$\nz_{h} = \\nu \\Delta t \\lambda_{h}(k_{0}) = \\nu \\Delta t \\left(-k_{0}^{2} + \\frac{k_{0}^{4}h^{2}}{12} + \\mathcal{O}(h^4)\\right)\n$$\n$$\n= -\\nu k_{0}^{2} \\Delta t + \\frac{\\nu k_{0}^{4} h^{2} \\Delta t}{12} + \\mathcal{O}(h^4 \\Delta t)\n$$\nNow we substitute this into the expansion for $\\log(G_{num})$. We only need to keep the leading-order terms. The lowest order for $z_h$ is $\\mathcal{O}(\\Delta t)$. So $z_h^3$ is $\\mathcal{O}(\\Delta t^3)$.\n$$\n\\log(G_{num}) = \\left(-\\nu k_{0}^{2} \\Delta t + \\frac{\\nu k_{0}^{4} h^{2} \\Delta t}{12}\\right) + \\frac{1}{12}\\left(-\\nu k_{0}^{2} \\Delta t\\right)^{3} + \\text{H.O.T.}\n$$\n$$\n\\log(G_{num}) = -\\nu k_{0}^{2} \\Delta t + \\frac{\\nu k_{0}^{4} h^{2} \\Delta t}{12} - \\frac{\\nu^{3}k_{0}^{6}\\Delta t^{3}}{12} + \\text{H.O.T.}\n$$\nThe total error in the amplification exponent is $E = \\log(G_{num}) - \\log(G_{exact})$:\n$$\nE = \\left(-\\nu k_{0}^{2} \\Delta t + \\frac{\\nu k_{0}^{4} h^{2} \\Delta t}{12} - \\frac{\\nu^{3}k_{0}^{6}\\Delta t^{3}}{12}\\right) - (-\\nu k_{0}^{2} \\Delta t) + \\text{H.O.T.}\n$$\n$$\nE = \\underbrace{\\frac{\\nu k_{0}^{4} h^{2} \\Delta t}{12}}_{\\text{Spatial Error}} - \\underbrace{\\frac{\\nu^{3}k_{0}^{6}\\Delta t^{3}}{12}}_{\\text{Temporal Error}} + \\text{H.O.T.}\n$$\nThe first term arises from the spatial discretization error ($\\mathcal{O}(h^2)$) and the second from the temporal discretization error of the CN method ($\\mathcal{O}(\\Delta t^2)$ in the scheme, which manifests as $\\mathcal{O}(\\Delta t^3)$ in the amplification exponent).\n\nTo achieve cancellation of the leading-order errors for the mode $k_{0}$, we must set the sum of these two terms to zero:\n$$\n\\frac{\\nu k_{0}^{4} h^{2} \\Delta t}{12} - \\frac{\\nu^{3}k_{0}^{6}\\Delta t^{3}}{12} = 0\n$$\nAssuming $\\nu, k_{0}, \\Delta t \\neq 0$, we can divide by common factors:\n$$\n\\nu k_{0}^{4} h^{2} \\Delta t = \\nu^{3} k_{0}^{6} \\Delta t^{3}\n$$\n$$\nh^{2} = \\nu^{2} k_{0}^{2} \\Delta t^{2}\n$$\nTaking the square root of both sides (since $h, \\nu, k_0 > 0, \\Delta t > 0$):\n$$\nh = \\nu k_{0} \\Delta t\n$$\nThe problem asks for the ratio $\\Delta t / h$. Rearranging the equation gives:\n$$\n\\frac{\\Delta t}{h} = \\frac{1}{\\nu k_{0}}\n$$\nThis is the unique dimensionless ratio that causes the leading spatial and temporal errors to cancel for the specified Fourier mode, resulting in superconvergence for that mode.",
            "answer": "$$\n\\boxed{\\frac{1}{\\nu k_{0}}}\n$$"
        }
    ]
}