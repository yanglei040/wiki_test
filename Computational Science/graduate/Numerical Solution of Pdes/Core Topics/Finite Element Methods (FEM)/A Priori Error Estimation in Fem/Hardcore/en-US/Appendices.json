{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of finite element analysis is the ability to perform calculations on a single, fixed reference element and then translate the results to any arbitrary element in the mesh. This practice explores the fundamental scaling argument that forms the bedrock of a priori error estimation. By applying the chain rule and a change of variables, you will determine how the $H^1$ seminorm, a crucial measure of error for second-order PDEs, transforms under the affine mapping from a reference element to a physical one, revealing its dependence on the element's size $h_K$.",
            "id": "2575277",
            "problem": "Consider a bounded Lipschitz reference element $\\hat K \\subset \\mathbb{R}^{d}$ and a physical element $K \\subset \\mathbb{R}^{d}$ obtained via an affine mapping $F_{K} : \\hat K \\to K$ of the form $F_{K}(\\hat x) = A_{K}\\hat x + b_{K}$, where $A_{K} \\in \\mathbb{R}^{d \\times d}$ is invertible. Let $h_{K}$ denote the diameter of $K$. Assume a shape-regular family of elements, meaning there exist positive constants $c_{1},c_{2},c_{3},c_{4}$, independent of $K$, such that\n- $c_{1} h_{K} \\le \\|A_{K}\\| \\le c_{2} h_{K}$ and $c_{3} h_{K}^{-1} \\le \\|A_{K}^{-1}\\| \\le c_{4} h_{K}^{-1}$,\n- there exist $c_{5},c_{6} > 0$ with $c_{5} h_{K}^{d} \\le |\\det A_{K}| \\le c_{6} h_{K}^{d}$.\nFor $\\hat v \\in H^{1}(\\hat K)$ define $v \\in H^{1}(K)$ by $v(x) = \\hat v(F_{K}^{-1}(x))$. The $H^{1}$ seminorm on a domain $D$ is defined by $|w|_{H^{1}(D)} := \\left(\\int_{D} |\\nabla w(x)|^{2} \\, dx \\right)^{1/2}$.\n\nUsing only the chain rule and the change-of-variables formula, together with the above bounds, determine the exact power of $h_{K}$ that captures the scaling of the $H^{1}$ seminorm under $F_{K}$, in the sense that $|v|_{H^{1}(K)}$ is proportional, up to constants independent of $h_{K}$ and $\\hat v$, to a factor $S(h_{K},d)$ times $|\\hat v|_{H^{1}(\\hat K)}$. Your final answer must be the closed-form analytic expression for $S(h_{K},d)$ as a function of $h_{K}$ and $d$. Do not include any proportionality constants; report only the dependence on $h_{K}$ and $d$.",
            "solution": "The objective is to establish the relationship between the $H^{1}$ seminorm of a function $v$ on the physical element $K$ and the $H^{1}$ seminorm of its corresponding function $\\hat v$ on the reference element $\\hat K$. We begin with the definition of the squared seminorm of $v$:\n$$\n|v|_{H^{1}(K)}^{2} = \\int_{K} |\\nabla_{x} v(x)|^{2} \\, dx\n$$\nHere, $\\nabla_{x}$ denotes the gradient with respect to the variable $x \\in K$. The function $v$ is defined as $v(x) = \\hat v(\\hat x)$, where $\\hat x = F_{K}^{-1}(x)$. To relate $\\nabla_{x} v$ to $\\nabla_{\\hat x} \\hat v$, we employ the chain rule. The inverse mapping is given by $\\hat x = F_{K}^{-1}(x) = A_{K}^{-1}(x - b_{K})$. The Jacobian matrix of this inverse transformation is $J_{F_{K}^{-1}} = A_{K}^{-1}$.\n\nApplying the chain rule for vector-valued functions, the gradient of $v(x) = \\hat v(F_{K}^{-1}(x))$ with respect to $x$ is:\n$$\n\\nabla_{x} v(x) = (J_{F_{K}^{-1}})^{T} \\nabla_{\\hat x} \\hat v(\\hat x) = (A_{K}^{-1})^{T} \\nabla_{\\hat x} \\hat v(\\hat x)\n$$\nwhere $\\nabla_{\\hat x} \\hat v$ is the gradient of $\\hat v$ with respect to $\\hat x$.\n\nNow, we consider the squared Euclidean norm of this gradient vector:\n$$\n|\\nabla_{x} v(x)|^{2} = \\left| (A_{K}^{-1})^{T} \\nabla_{\\hat x} \\hat v(\\hat x) \\right|^{2}\n$$\nThe squared norm of a vector transformed by a matrix is bounded by the operator norm of that matrix. Specifically, we have the inequality:\n$$\n|\\nabla_{x} v(x)|^{2} \\le \\|(A_{K}^{-1})^{T}\\|^{2} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2}\n$$\nSince the operator norm of a matrix is equal to the norm of its transpose, $\\|(A_{K}^{-1})^{T}\\| = \\|A_{K}^{-1}\\|$, this becomes:\n$$\n|\\nabla_{x} v(x)|^{2} \\le \\|A_{K}^{-1}\\|^{2} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2}\n$$\nFor a lower bound, we use the property that for an invertible matrix $M$ and any vector $u$, $|Mu| \\ge \\|M^{-1}\\|^{-1}|u|$. Applying this to the matrix $(A_{K}^{-1})^{T}$ and the vector $\\nabla_{\\hat x} \\hat v(\\hat x)$:\n$$\n|\\nabla_{x} v(x)|^{2} = \\left| (A_{K}^{-1})^{T} \\nabla_{\\hat x} \\hat v(\\hat x) \\right|^{2} \\ge \\left( \\| ((A_{K}^{-1})^{T})^{-1} \\|^{-1} |\\nabla_{\\hat x} \\hat v(\\hat x)| \\right)^{2} = \\|(A_{K}^{T})^{-1}\\|^{-2} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2}\n$$\nUsing the properties $\\|M^{-1}\\|^{-1} = \\sigma_{\\min}(M)$ (the smallest singular value of $M$) and $\\|M\\| = \\|M^T\\|$, this simplifies to:\n$$\n|\\nabla_{x} v(x)|^{2} \\ge \\|A_{K}^{T}\\|^{-2} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2} = \\|A_{K}\\|^{-2} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2}\n$$\nCombining these inequalities, we have bounded the squared norm of the gradient:\n$$\n\\|A_{K}\\|^{-2} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2} \\le |\\nabla_{x} v(x)|^{2} \\le \\|A_{K}^{-1}\\|^{2} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2}\n$$\nNext, we perform a change of variables in the integral defining $|v|_{H^{1}(K)}^{2}$. We substitute $x = F_{K}(\\hat x)$, which implies the differential volume element transforms as $dx = |\\det(J_{F_{K}})| \\,d\\hat x = |\\det(A_{K})| \\,d\\hat x$. The domain of integration changes from $K$ to $\\hat K$.\n$$\n|v|_{H^{1}(K)}^{2} = \\int_{\\hat K} |\\nabla_{x} v(F_{K}(\\hat x))|^{2} |\\det(A_{K})| \\, d\\hat x\n$$\nSubstituting our bounds for $|\\nabla_{x} v(x)|^{2}$ into this integral expression, we obtain:\n$$\n\\int_{\\hat K} \\|A_{K}\\|^{-2} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2} |\\det(A_{K})| \\, d\\hat x \\le |v|_{H^{1}(K)}^{2} \\le \\int_{\\hat K} \\|A_{K}^{-1}\\|^{2} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2} |\\det(A_{K})| \\, d\\hat x\n$$\nThe terms involving $A_{K}$ are constant with respect to the integration variable $\\hat x$, so they can be factored out of the integral:\n$$\n\\|A_{K}\\|^{-2} |\\det(A_{K})| \\int_{\\hat K} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2} \\, d\\hat x \\le |v|_{H^{1}(K)}^{2} \\le \\|A_{K}^{-1}\\|^{2} |\\det(A_{K})| \\int_{\\hat K} |\\nabla_{\\hat x} \\hat v(\\hat x)|^{2} \\, d\\hat x\n$$\nThe integral is precisely the definition of the squared seminorm of $\\hat v$ on the reference element, $|\\hat v|_{H^{1}(\\hat K)}^{2}$. Thus, we have:\n$$\n\\|A_{K}\\|^{-2} |\\det(A_{K})| |\\hat v|_{H^{1}(\\hat K)}^{2} \\le |v|_{H^{1}(K)}^{2} \\le \\|A_{K}^{-1}\\|^{2} |\\det(A_{K})| |\\hat v|_{H^{1}(\\hat K)}^{2}\n$$\nNow we apply the given shape-regularity bounds to determine the dependence on $h_{K}$.\nFor the upper bound:\n-   $\\|A_{K}^{-1}\\| \\le c_{4} h_{K}^{-1} \\implies \\|A_{K}^{-1}\\|^{2} \\le c_{4}^{2} h_{K}^{-2}$\n-   $|\\det(A_{K})| \\le c_{6} h_{K}^{d}$\nThe product is $\\|A_{K}^{-1}\\|^{2} |\\det(A_{K})| \\le (c_{4}^{2} h_{K}^{-2})(c_{6} h_{K}^{d}) = c_{4}^{2}c_{6} h_{K}^{d-2}$.\n\nFor the lower bound:\n-   $\\|A_{K}\\| \\le c_{2} h_{K} \\implies \\|A_{K}\\|^{-2} \\ge (c_{2} h_{K})^{-2} = c_{2}^{-2} h_{K}^{-2}$\n-   $|\\det(A_{K})| \\ge c_{5} h_{K}^{d}$\nThe product is $\\|A_{K}\\|^{-2} |\\det(A_{K})| \\ge (c_{2}^{-2} h_{K}^{-2})(c_{5} h_{K}^{d}) = c_{2}^{-2}c_{5} h_{K}^{d-2}$.\n\nLet $C_{L} = c_{2}^{-2}c_{5}$ and $C_{U} = c_{4}^{2}c_{6}$. These are positive constants independent of $K$. The inequality becomes:\n$$\nC_{L} h_{K}^{d-2} |\\hat v|_{H^{1}(\\hat K)}^{2} \\le |v|_{H^{1}(K)}^{2} \\le C_{U} h_{K}^{d-2} |\\hat v|_{H^{1}(\\hat K)}^{2}\n$$\nTaking the square root of all parts yields:\n$$\n\\sqrt{C_{L}} (h_{K}^{d-2})^{1/2} |\\hat v|_{H^{1}(\\hat K)} \\le |v|_{H^{1}(K)} \\le \\sqrt{C_{U}} (h_{K}^{d-2})^{1/2} |\\hat v|_{H^{1}(\\hat K)}\n$$\nThis demonstrates that $|v|_{H^{1}(K)}$ is proportional to $h_{K}^{\\frac{d-2}{2}} |\\hat v|_{H^{1}(\\hat K)}$, with proportionality constants that are independent of $h_{K}$ and $\\hat v$.\nThe problem asks for the scaling factor $S(h_{K},d)$ that captures this dependence on $h_{K}$ and $d$. From our derivation, this factor is $h_{K}^{\\frac{d-2}{2}}$.",
            "answer": "$$\n\\boxed{h_{K}^{\\frac{d-2}{2}}}\n$$"
        },
        {
            "introduction": "Theoretical convergence rates promise that as the mesh size $h$ decreases, the error diminishes at a predictable rate, often $O(h^{k+1})$. This \"best-case\" scenario, however, relies on the assumption that the exact solution is sufficiently smooth. This exercise demonstrates how limited solution regularity, a common issue in physical problems with sharp corners or material interfaces, creates a bottleneck that can reduce the observed convergence rate, a crucial concept for accurately predicting computational costs and outcomes.",
            "id": "2557615",
            "problem": "Consider a bounded polygonal domain $\\Omega \\subset \\mathbb{R}^{2}$ and a family of conforming, shape-regular, quasi-uniform triangulations $\\{\\mathcal{T}_{h}\\}_{h>0}$ with meshsize $h$. Let $V_{h}^{k} \\subset H^{1}(\\Omega)$ denote the standard $C^{0}$ Lagrange finite element space of total polynomial degree $k \\in \\mathbb{N}$. For a target function $u:\\Omega \\to \\mathbb{R}$ with Sobolev regularity $u \\in H^{s}(\\Omega)$ for some $s>0$, let $\\Pi_{h}:L^{2}(\\Omega)\\to V_{h}^{k}$ be any local, $H^{m}$-stable quasi-interpolation operator (for example, Scott–Zhang) that reproduces polynomials of degree at most $k$.\n\n1) Starting from the Bramble–Hilbert lemma and scaling arguments on each $K \\in \\mathcal{T}_{h}$, derive an $L^{2}$-approximation estimate of the form\n$$\n\\|u - \\Pi_{h}u\\|_{L^{2}(\\Omega)} \\leq C\\, h^{t}\\, |u|_{H^{t}(\\Omega)},\n$$\nvalid for all $t$ satisfying $0<t\\leq \\min\\{k+1,s\\}$, where $C$ is independent of $h$ and $u$. Use this to conclude that the convergence rate in the $L^{2}$-norm cannot exceed $h^{\\min\\{k+1,s\\}}$ when $u \\in H^{s}(\\Omega)$.\n\n2) Provide a sharp example on a nonconvex, reentrant-corner domain where the reduced regularity of the exact solution limits the rate in item 1. Specifically, let $\\Omega_{\\omega}$ be a plane sector with opening angle $\\omega \\in (\\pi,2\\pi)$ truncated by a circle of radius $1$,\n$$\n\\Omega_{\\omega} := \\{(r,\\theta): 0<r<1,\\; 0<\\theta<\\omega\\},\n$$\nwritten in polar coordinates $(r,\\theta)$ about the reentrant corner at the origin. Consider the corner-singular function\n$$\nu_{\\lambda}(r,\\theta) := r^{\\lambda}\\sin(\\lambda \\theta), \\qquad \\lambda := \\frac{\\pi}{\\omega},\n$$\nand suppose one poses data so that $u_{\\lambda}$ is the exact solution to a second-order, linear, uniformly elliptic boundary value problem on $\\Omega_{\\omega}$ with homogeneous Dirichlet boundary conditions. Using regularity of $u_{\\lambda}$ in Sobolev spaces, show that $u_{\\lambda} \\in H^{s}(\\Omega_{\\omega})$ for all $s<1+\\lambda$ but $u_{\\lambda}\\notin H^{1+\\lambda}(\\Omega_{\\omega})$, and argue that the rate $h^{\\min\\{k+1,s\\}}$ is sharp on quasi-uniform meshes.\n\n3) Specialize to the canonical reentrant corner with opening angle $\\omega=3\\pi/2$ and to quadratic elements $k=2$ on a quasi-uniform mesh. Using the conclusion of item 1 with the limiting Sobolev index from item 2, determine the convergence-rate exponent in the $L^{2}$-norm predicted by the restricted regularity of $u_{\\lambda}$. Write your final answer as a single reduced fraction. No rounding is required and no units are involved.",
            "solution": "The problem is a standard exercise in the a priori error analysis of the finite element method, particularly concerning the effect of solution regularity on convergence rates. We address each of the three parts in sequence.\n\nFor the first part, we derive the $L^2$-norm error estimate. The objective is to find a bound for $\\|u - \\Pi_{h}u\\|_{L^{2}(\\Omega)}$. We begin by decomposing the global error into a sum of local errors over the elements $K$ of the triangulation $\\mathcal{T}_{h}$:\n$$\n\\|u - \\Pi_{h}u\\|_{L^{2}(\\Omega)}^{2} = \\sum_{K \\in \\mathcal{T}_{h}} \\|u - \\Pi_{h}u\\|_{L^{2}(K)}^{2}.\n$$\nWe analyze the local error on a single element $K$. The quasi-interpolation operator $\\Pi_{h}$ is defined to reproduce polynomials of degree up to $k$. That is, for any polynomial $p \\in \\mathcal{P}_{k}(\\Omega)$, where $\\mathcal{P}_{k}$ is the space of polynomials of total degree at most $k$, we have $\\Pi_{h}p = p$. Using this property, we can write for any $p \\in \\mathcal{P}_{k}$:\n$$\nu - \\Pi_{h}u = (u - p) - \\Pi_{h}(u - p).\n$$\nApplying the triangle inequality to the $L^{2}(K)$-norm yields:\n$$\n\\|u - \\Pi_{h}u\\|_{L^{2}(K)} \\leq \\|u - p\\|_{L^{2}(K)} + \\|\\Pi_{h}(u - p)\\|_{L^{2}(K)}.\n$$\nThe problem states that $\\Pi_h$ is a local, $H^{m}$-stable operator. For the $L^2$ estimate, we assume stability in the $L^2$-norm (i.e., $m=0$). The locality of the operator means that the value of $\\Pi_h v$ on an element $K$ depends only on the values of $v$ in a small patch of neighboring elements, which we denote $\\omega_K$. The stability property then implies there exists a constant $C_{stab}$, independent of $h$ and $v$, such that:\n$$\n\\|\\Pi_{h}v\\|_{L^{2}(K)} \\leq C_{stab} \\|v\\|_{L^{2}(\\omega_K)}.\n$$\nApplying this to the term $\\|\\Pi_{h}(u-p)\\|_{L^2(K)}$ gives:\n$$\n\\|u - \\Pi_{h}u\\|_{L^{2}(K)} \\leq \\|u - p\\|_{L^{2}(K)} + C_{stab} \\|u - p\\|_{L^{2}(\\omega_K)}.\n$$\nSince $K \\subset \\omega_K$, we can combine these terms:\n$$\n\\|u - \\Pi_{h}u\\|_{L^{2}(K)} \\leq (1+C_{stab}) \\|u - p\\|_{L^{2}(\\omega_K)}.\n$$\nThis inequality holds for any polynomial $p \\in \\mathcal{P}_{k}$. We can therefore choose the polynomial that minimizes the right-hand side:\n$$\n\\|u - \\Pi_{h}u\\|_{L^{2}(K)} \\leq (1+C_{stab}) \\inf_{p \\in \\mathcal{P}_{k}} \\|u - p\\|_{L^{2}(\\omega_K)}.\n$$\nThe Bramble–Hilbert lemma, combined with a scaling argument from a reference element, provides an estimate for this polynomial approximation error. For a domain such as $\\omega_K$ and for a function $v \\in H^{t}(\\omega_K)$, the following standard approximation result holds for $0 \\leq j \\leq t$ and $t \\leq k+1$:\n$$\n\\inf_{p \\in \\mathcal{P}_{k}} \\|v-p\\|_{H^{j}(\\omega_K)} \\leq C (\\text{diam}(\\omega_K))^{t-j} |v|_{H^{t}(\\omega_K)}.\n$$\nSince the mesh is quasi-uniform, the diameter of the patch $\\omega_K$ is proportional to the meshsize $h$, i.e., $\\text{diam}(\\omega_K) \\le C'h$. Setting $j=0$ and applying this to our function $u$, assuming $u \\in H^t(\\omega_K)$, we get:\n$$\n\\inf_{p \\in \\mathcal{P}_{k}} \\|u - p\\|_{L^{2}(\\omega_K)} \\leq C h^{t} |u|_{H^{t}(\\omega_K)}.\n$$\nThis holds for any $t$ such that $0 < t \\leq k+1$. For the term $|u|_{H^{t}(\\omega_K)}$ to be meaningful, we also require that the global function $u$ has at least this much regularity, i.e., $u \\in H^s(\\Omega)$ and $t \\le s$. Combining these constraints, the estimate is valid for $0 < t \\leq \\min\\{k+1, s\\}$. Substituting this into our local error bound:\n$$\n\\|u - \\Pi_{h}u\\|_{L^{2}(K)}^{2} \\leq C_{loc}^2 h^{2t} |u|_{H^{t}(\\omega_K)}^{2} = C_{loc}^2 h^{2t} \\sum_{K' \\subset \\omega_K} |u|_{H^{t}(K')}^{2}.\n$$\nWe sum over all elements $K \\in \\mathcal{T}_{h}$ to obtain the global error:\n$$\n\\|u - \\Pi_{h}u\\|_{L^{2}(\\Omega)}^{2} = \\sum_{K \\in \\mathcal{T}_{h}} \\|u - \\Pi_{h}u\\|_{L^{2}(K)}^{2} \\leq C h^{2t} \\sum_{K \\in \\mathcal{T}_{h}} \\sum_{K' \\subset \\omega_K} |u|_{H^{t}(K')}^{2}.\n$$\nThe assumption that the mesh family is shape-regular and quasi-uniform implies there is a finite overlap number. We can thus reorder the summation:\n$$\n\\sum_{K \\in \\mathcal{T}_{h}} \\sum_{K' \\subset \\omega_K} |u|_{H^{t}(K')}^{2} \\leq C_{overlap} \\sum_{K' \\in \\mathcal{T}_{h}} |u|_{H^{t}(K')}^{2} = C_{overlap} |u|_{H^{t}(\\Omega)}^{2}.\n$$\nThis leads to the global estimate $\\|u - \\Pi_{h}u\\|_{L^{2}(\\Omega)}^{2} \\leq C' h^{2t} |u|_{H^{t}(\\Omega)}^{2}$. Taking the square root gives the desired result:\n$$\n\\|u - \\Pi_{h}u\\|_{L^{2}(\\Omega)} \\leq C h^{t} |u|_{H^{t}(\\Omega)},\n$$\nvalid for $0 < t \\leq \\min\\{k+1,s\\}$. This implies the convergence rate is $O(h^{\\min\\{k+1,s\\}})$.\n\nFor the second part, we analyze the singular function $u_{\\lambda}(r,\\theta) = r^{\\lambda}\\sin(\\lambda \\theta)$ with $\\lambda = \\pi/\\omega$. A function belongs to $H^{s}(\\Omega)$ if its weak derivatives up to order $s$ are in $L^{2}(\\Omega)$. The singularity is at the origin ($r=0$). A generic partial derivative of $u_{\\lambda}$ of integer order $m$ behaves like $r^{\\lambda-m}$ near the origin. We check the square-integrability of a term $g(r,\\theta) \\sim r^{\\beta}$ near $r=0$. In polar coordinates, the $L^2$ norm squared involves the integral $\\int_0^{\\epsilon} r^{2\\beta} r \\, dr$. This converges if and only if $2\\beta+1 > 0$, which simplifies to $\\beta > -1/2$. A mistake was made in the original solution. Let me re-derive. The integral is $\\int_0^\\epsilon \\int_0^\\omega (r^\\beta)^2 r \\, d\\theta dr = \\omega \\int_0^\\epsilon r^{2\\beta+1} dr$. This converges if $2\\beta+1 > -1$, which means $2\\beta > -2$, or $\\beta > -1$. This part of the logic was correct.\nFor a partial derivative of order $m$, its radial behavior is $r^{\\lambda-m}$. For this to be in $L^2(\\Omega_{\\omega})$, we must have $\\lambda-m > -1$, which implies $m < \\lambda+1$. This means that $u_{\\lambda} \\in H^{m}(\\Omega_{\\omega})$ for all integers $m < \\lambda+1$, and by interpolation, $u_{\\lambda} \\in H^{s}(\\Omega_{\\omega})$ for all real numbers $s < \\lambda+1$. Conversely, a derivative of order $m \\ge \\lambda+1$ will have a radial component $r^\\beta$ with $\\beta \\le -1$, whose integral diverges. Thus, $u_{\\lambda} \\notin H^{s}(\\Omega_{\\omega})$ for any $s \\ge \\lambda+1$. The limiting Sobolev regularity is $s_{lim} = \\lambda+1$. The convergence rate from part 1, $O(h^{\\min\\{k+1,s\\}})$, is therefore limited by $O(h^{\\min\\{k+1, \\lambda+1-\\epsilon\\}})$ for any $\\epsilon > 0$. Taking the limit as $\\epsilon \\to 0$, the rate is limited by $s_{lim} = \\lambda+1$. The effective rate is $O(h^{\\min\\{k+1, \\lambda+1\\}})$. This rate is known to be sharp for quasi-uniform meshes due to pollution from the corner singularity.\n\nFor the third part, we are given the angle $\\omega = \\frac{3\\pi}{2}$ and quadratic elements, which corresponds to polynomial degree $k=2$. We compute the singularity exponent $\\lambda$:\n$$\n\\lambda = \\frac{\\pi}{\\omega} = \\frac{\\pi}{3\\pi/2} = \\frac{2}{3}.\n$$\nFrom part 2, the limiting Sobolev regularity index that determines the convergence rate is $s_{eff} = \\lambda+1$:\n$$\ns_{eff} = \\frac{2}{3} + 1 = \\frac{5}{3}.\n$$\nFrom part 1, the exponent of convergence in the $L^2$-norm is $\\min\\{k+1, s_{eff}\\}$. With $k=2$, the maximum possible exponent is $k+1 = 3$. We compare this with the regularity-limited exponent:\n$$\n\\text{exponent} = \\min\\left\\{3, \\frac{5}{3}\\right\\}.\n$$\nSince $3 = \\frac{9}{3}$, we have $\\min\\{\\frac{9}{3}, \\frac{5}{3}\\} = \\frac{5}{3}$. The convergence-rate exponent is $\\frac{5}{3}$.",
            "answer": "$$\n\\boxed{\\frac{5}{3}}\n$$"
        },
        {
            "introduction": "A priori error estimates provide powerful theoretical predictions about the accuracy of the finite element method. This hands-on practice moves from theory to implementation, challenging you to build a simple FEM solver from first principles. By conducting a numerical convergence study, you will computationally verify the predicted $O(h^{k+1})$ convergence rate and gain tangible experience in how abstract error bounds translate into concrete and measurable code performance.",
            "id": "2395840",
            "problem": "Design and implement a complete program that, from first principles, verifies the rate of convergence in the $L_2$ norm for the conforming finite element method applied to a one-dimensional Poisson problem. Consider the boundary value problem on the open interval $(0,1)$: find $u \\in H_0^1(0,1)$ such that\n$$\n-\\frac{d^2 u}{dx^2} = f \\quad \\text{in } (0,1), \\qquad u(0)=0, \\quad u(1)=0,\n$$\nwith the exact solution prescribed as $u(x) = \\sin(\\pi x)$ so that $f(x) = \\pi^2 \\sin(\\pi x)$. For a polynomial degree $k \\in \\{1,2\\}$ and a uniform partition of $(0,1)$ into $N$ elements of size $h = 1/N$, let $V_h^k \\subset H_0^1(0,1)$ denote the space of continuous, piecewise polynomials of degree at most $k$ on the mesh. Let $u_h \\in V_h^k$ be the unique function satisfying the Galerkin variational formulation\n$$\n\\int_0^1 \\frac{d u_h}{dx}(x)\\, \\frac{d v_h}{dx}(x)\\, dx = \\int_0^1 f(x)\\, v_h(x)\\, dx \\quad \\text{for all } v_h \\in V_h^k,\n$$\nwith homogeneous Dirichlet boundary conditions incorporated in $V_h^k$. For a set of decreasing mesh sizes, define the $L_2$ error\n$$\nE(h) = \\left(\\int_0^1 \\left(u(x) - u_h(x)\\right)^2\\, dx \\right)^{1/2},\n$$\nand define the observed convergence rate $r$ to be the real number that best fits the power law $E(h) \\approx C h^r$ in the least-squares sense over the given set of mesh sizes, that is, the value of $r$ that minimizes $\\sum_i \\left(\\log E(h_i) - (a + r \\log h_i)\\right)^2$ over real $a$ and $r$.\n\nThe computational experiment must produce the following test suite results, each derived entirely from the mathematical definitions above:\n\n- Test case A (happy path): $k = 1$ with element counts $N \\in \\{10,20,40,80,160\\}$.\n- Test case B (higher-order space): $k = 2$ with element counts $N \\in \\{8,16,32,64\\}$.\n- Test case C (boundary of asymptotic regime): $k = 1$ with element counts $N \\in \\{2,4,8,16\\}$.\n\nFor each test case, compute the observed rate $r$ as defined above. Additionally, for each test case, output a boolean flag indicating whether the inequality $r \\geq k+1 - \\delta$ holds, where $\\delta = 0.1$ for Test case A, $\\delta = 0.2$ for Test case B, and $\\delta = 0.4$ for Test case C. All angles are in radians, and no physical units are involved.\n\nYour program must produce a single line of output containing all results aggregated into a single list in the following order:\n$[r_A, r_B, r_C, b_A, b_B, b_C]$,\nwhere $r_A$, $r_B$, and $r_C$ are the observed convergence rates for Test cases A, B, and C, respectively, and $b_A$, $b_B$, and $b_C$ are the corresponding boolean flags. For example, an output should look like a single line with the format $[r_1,r_2,r_3,b_1,b_2,b_3]$ with no additional text.",
            "solution": "The problem requires a numerical verification of the convergence rate of the conforming finite element method for the one-dimensional Poisson problem with homogeneous Dirichlet boundary conditions. The problem is stated as: find $u \\in H_0^1(0,1)$ such that\n$$\n-\\frac{d^2 u}{dx^2} = f(x) \\quad \\text{for } x \\in (0,1), \\quad u(0) = u(1) = 0.\n$$\nThe exact solution is provided as $u(x) = \\sin(\\pi x)$, which implies the forcing function must be $f(x) = \\pi^2 \\sin(\\pi x)$.\n\nThe core of the finite element method is the conversion of this differential equation into its weak, or variational, formulation. We find $u \\in H_0^1(0,1)$ such that for all test functions $v \\in H_0^1(0,1)$:\n$$\n\\int_0^1 \\frac{du}{dx}(x) \\frac{dv}{dx}(x) \\, dx = \\int_0^1 f(x) v(x) \\, dx.\n$$\nThis is achieved by multiplying the original equation by a test function $v$, integrating over the domain $(0,1)$, and applying integration by parts, incorporating the boundary conditions. We define the bilinear form $a(u,v) = \\int_0^1 u'v' \\,dx$ and the linear form $L(v) = \\int_0^1 fv \\,dx$. The problem is then to find $u \\in H_0^1(0,1)$ such that $a(u,v) = L(v)$ for all $v \\in H_0^1(0,1)$.\n\nTo solve this numerically, we introduce a finite-dimensional subspace $V_h^k \\subset H_0^1(0,1)$. The domain $(0,1)$ is partitioned into $N$ uniform elements of size $h=1/N$. The space $V_h^k$ consists of continuous functions that are piecewise polynomials of degree at most $k$ on this partition. The subscript $h$ indicates the dependence on the mesh size. The condition $V_h^k \\subset H_0^1(0,1)$ implies that any function in this space must be zero at the boundaries $x=0$ and $x=1$.\n\nThe Galerkin method seeks an approximate solution $u_h \\in V_h^k$ such that\n$$\na(u_h, v_h) = L(v_h) \\quad \\text{for all } v_h \\in V_h^k.\n$$\nLet $\\{\\phi_j\\}_{j=1}^{M}$ be a set of basis functions for $V_h^k$, where $M$ is the dimension of the space (the number of interior degrees of freedom). The approximate solution can be written as a linear combination of these basis functions:\n$$\nu_h(x) = \\sum_{j=1}^{M} c_j \\phi_j(x),\n$$\nwhere $c_j$ are unknown coefficients. Substituting this into the Galerkin formulation and choosing the test functions to be the basis functions themselves ($v_h = \\phi_i$ for $i=1,\\dots,M$), we obtain a system of linear algebraic equations:\n$$\n\\sum_{j=1}^{M} c_j a(\\phi_j, \\phi_i) = L(\\phi_i) \\quad \\text{for } i=1,\\dots,M.\n$$\nThis is a linear system $A\\mathbf{c} = \\mathbf{b}$, where the entries of the stiffness matrix $A$ are $A_{ij} = a(\\phi_j, \\phi_i)$, the entries of the load vector $\\mathbf{b}$ are $b_i = L(\\phi_i)$, and $\\mathbf{c} = [c_1, \\dots, c_M]^T$ is the vector of unknown coefficients.\n\nThe practical implementation involves the following steps:\n\n1.  **Assembly:** The integrals defining the entries of $A$ and $\\mathbf{b}$ are computed element by element. This is done by mapping each physical element $[x_e, x_{e+1}]$ to a canonical reference element, say $\\hat{I}=[-1,1]$. The basis functions are defined on this reference element. For degree $k$, there are $k+1$ local basis functions (Lagrange polynomials).\n    The integrals are transformed:\n    $$\n    A_{ij}^e = \\int_{x_e}^{x_{e+1}} \\frac{d\\phi_j}{dx} \\frac{d\\phi_i}{dx} \\, dx, \\quad b_i^e = \\int_{x_e}^{x_{e+1}} f(x) \\phi_i(x) \\, dx.\n    $$\n    Using a coordinate transform $x(\\xi) = x_e + \\frac{h}{2}(\\xi+1)$, these become integrals over $\\xi \\in [-1,1]$. Since the integrands may not be simple polynomials, numerical quadrature, specifically Gaussian quadrature, is used for accurate evaluation. The element-wise contributions $A_{ij}^e$ and $b_i^e$ are then added to the global system $A\\mathbf{c} = \\mathbf{b}$ according to a mapping between local and global-node indices.\n\n2.  **Solving:** The resulting linear system is symmetric and positive-definite. It can be solved for the coefficient vector $\\mathbf{c}$ using standard numerical linear algebra routines. Once $\\mathbf{c}$ is known, the approximate solution $u_h(x)$ is fully determined.\n\n3.  **Error Calculation:** The $L_2$ error, $E(h)$, is computed to assess the accuracy of the solution:\n    $$\n    E(h) = \\| u - u_h \\|_{L_2(0,1)} = \\left( \\int_0^1 (u(x) - u_h(x))^2 \\, dx \\right)^{1/2}.\n    $$\n    This integral is also computed numerically using element-wise Gaussian quadrature of sufficient order to ensure accuracy.\n\n4.  **Convergence Rate Estimation:** A priori error estimates for the FEM predict that, for a sufficiently smooth solution $u$, the $L_2$ error converges as $E(h) \\approx C h^{k+1}$ for some constant $C$ as $h \\to 0$. To verify this numerically, we take the logarithm of this relation:\n    $$\n    \\log E(h) \\approx \\log C + (k+1) \\log h.\n    $$\n    This shows a linear relationship between $\\log E(h)$ and $\\log h$. For a set of computed errors $\\{E(h_i)\\}$ corresponding to a set of mesh sizes $\\{h_i\\}$, we perform a linear least-squares fit on the data points $(\\log h_i, \\log E(h_i))$. The slope of the resulting line is the observed order of convergence, $r$. The problem defines $r$ as the value that minimizes the sum of squared residuals $\\sum_i (\\log E(h_i) - (a + r \\log h_i))^2$. This is a standard linear regression problem.\n\nThe computational procedure described above is executed for each test case specified in the problem statement. The resulting rate $r$ is then compared against the theoretical expectation $k+1$ using the provided tolerance $\\delta$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import roots_legendre\nfrom typing import List, Dict, Any, Callable, Tuple\n\ndef get_basis_functions(k: int) -> Tuple[int, np.ndarray, Callable, Callable]:\n    \"\"\"\n    Returns Lagrange basis functions and their derivatives on the reference element [-1, 1].\n\n    Args:\n        k: The polynomial degree (1 or 2).\n\n    Returns:\n        A tuple containing:\n        - Number of local basis functions.\n        - Nodal points on the reference element.\n        - A function that evaluates all basis functions at a point xi.\n        - A function that evaluates all basis function derivatives at a point xi.\n    \"\"\"\n    if k == 1:\n        num_basis = 2\n        nodes = np.array([-1.0, 1.0])\n        def basis_vals(xi: float) -> np.ndarray:\n            return np.array([(1.0 - xi) / 2.0, (1.0 + xi) / 2.0])\n        def basis_ders(xi: float) -> np.ndarray:\n            # Derivatives are constant for linear basis functions\n            return np.array([-0.5, 0.5])\n        return num_basis, nodes, basis_vals, basis_ders\n    elif k == 2:\n        num_basis = 3\n        nodes = np.array([-1.0, 0.0, 1.0])\n        def basis_vals(xi: float) -> np.ndarray:\n            return np.array([\n                xi * (xi - 1.0) / 2.0,\n                1.0 - xi**2,\n                xi * (xi + 1.0) / 2.0\n            ])\n        def basis_ders(xi: float) -> np.ndarray:\n            return np.array([\n                xi - 0.5,\n                -2.0 * xi,\n                xi + 0.5\n            ])\n        return num_basis, nodes, basis_vals, basis_ders\n    else:\n        raise ValueError(\"This implementation only supports polynomial degrees k=1 and k=2.\")\n\ndef solve_fem_poisson_1d(k: int, N: int, num_quad_points: int = 5) -> float:\n    \"\"\"\n    Solves the 1D Poisson problem using the Finite Element Method.\n\n    Args:\n        k: The polynomial degree of the basis functions.\n        N: The number of elements in the uniform mesh.\n        num_quad_points: The number of points for Gaussian quadrature.\n\n    Returns:\n        The L2 error of the numerical solution.\n    \"\"\"\n    h = 1.0 / N\n    f = lambda x: np.pi**2 * np.sin(np.pi * x)\n    u_exact = lambda x: np.sin(np.pi * x)\n\n    num_local_basis, _, ref_basis_vals, ref_basis_ders = get_basis_functions(k)\n    num_dofs = k * N - 1\n\n    A = np.zeros((num_dofs, num_dofs))\n    b = np.zeros(num_dofs)\n\n    xi_q, w_q = roots_legendre(num_quad_points)\n\n    # Assembly loop over elements\n    for e in range(N):\n        x_e = e * h\n        A_elem = np.zeros((num_local_basis, num_local_basis))\n        b_elem = np.zeros(num_local_basis)\n\n        # Quadrature loop for element matrix and vector\n        for i in range(num_quad_points):\n            xi, w = xi_q[i], w_q[i]\n            x_phys = x_e + (h / 2.0) * (xi + 1.0)\n            jacobian = h / 2.0\n            \n            grads = ref_basis_ders(xi)\n            vals = ref_basis_vals(xi)\n            \n            # Element stiffness matrix\n            for p in range(num_local_basis):\n                for q in range(num_local_basis):\n                    A_elem[p, q] += (grads[q] / jacobian) * (grads[p] / jacobian) * w * jacobian\n            \n            # Element load vector\n            for p in range(num_local_basis):\n                b_elem[p] += f(x_phys) * vals[p] * w * jacobian\n\n        # Map local contributions to global system\n        for p_loc in range(num_local_basis):\n            p_glob_node = k * e + p_loc\n            if 0 < p_glob_node < k * N:\n                p_dof = p_glob_node - 1\n                b[p_dof] += b_elem[p_loc]\n                for q_loc in range(num_local_basis):\n                    q_glob_node = k * e + q_loc\n                    if 0 < q_glob_node < k * N:\n                        q_dof = q_glob_node - 1\n                        A[p_dof, q_dof] += A_elem[p_loc, q_loc]\n    \n    # Solve for coefficients\n    coeffs = np.linalg.solve(A, b)\n\n    # Compute L2 error\n    error_sq = 0.0\n    for e in range(N):\n        x_e = e * h\n        for i in range(num_quad_points):\n            xi, w = xi_q[i], w_q[i]\n            x_phys = x_e + (h / 2.0) * (xi + 1.0)\n            jacobian = h / 2.0\n            \n            u_val = u_exact(x_phys)\n            \n            uh_val = 0.0\n            vals = ref_basis_vals(xi)\n            for p_loc in range(num_local_basis):\n                p_glob_node = k * e + p_loc\n                node_coeff = 0.0\n                if 0 < p_glob_node < k * N:\n                    p_dof = p_glob_node - 1\n                    node_coeff = coeffs[p_dof]\n                uh_val += node_coeff * vals[p_loc]\n            \n            error_sq += (u_val - uh_val)**2 * w * jacobian\n\n    return np.sqrt(error_sq)\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        {'id': 'A', 'k': 1, 'N_list': [10, 20, 40, 80, 160], 'delta': 0.1},\n        {'id': 'B', 'k': 2, 'N_list': [8, 16, 32, 64], 'delta': 0.2},\n        {'id': 'C', 'k': 1, 'N_list': [2, 4, 8, 16], 'delta': 0.4}\n    ]\n\n    rates = {}\n    flags = {}\n\n    for case in test_cases:\n        k = case['k']\n        N_list = case['N_list']\n        delta = case['delta']\n        \n        h_values = 1.0 / np.array(N_list)\n        error_values = np.array([solve_fem_poisson_1d(k, N) for N in N_list])\n        \n        log_h = np.log(h_values)\n        log_e = np.log(error_values)\n        \n        # Calculate convergence rate r via linear regression slope\n        r, _ = np.polyfit(log_h, log_e, 1)\n        \n        # Check against theoretical rate k+1 with tolerance delta\n        passes_check = r >= (k + 1.0 - delta)\n        \n        rates[case['id']] = r\n        flags[case['id']] = passes_check\n\n    # Assemble final list in the specified order: [r_A, r_B, r_C, b_A, b_B, b_C]\n    final_results = [\n        rates['A'], rates['B'], rates['C'],\n        flags['A'], flags['B'], flags['C']\n    ]\n    \n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        }
    ]
}