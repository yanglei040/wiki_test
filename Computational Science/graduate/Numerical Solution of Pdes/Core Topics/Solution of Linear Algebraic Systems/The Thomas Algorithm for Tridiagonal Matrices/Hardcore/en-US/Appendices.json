{
    "hands_on_practices": [
        {
            "introduction": "Many fundamental problems in science and engineering are described by partial differential equations (PDEs). To solve them numerically, we often discretize the continuous equations, transforming them into a system of linear algebraic equations. This first exercise provides foundational practice by guiding you through the process of discretizing the one-dimensional heat equation using an implicit time-stepping scheme, a common and important technique. You will see firsthand how this standard approach naturally gives rise to a tridiagonal linear system, setting the stage for applying the Thomas algorithm.",
            "id": "3456851",
            "problem": "Consider the one-dimensional heat partial differential equation (PDE) $u_{t}=\\kappa\\,u_{xx}$ on a spatial interval with Dirichlet boundary conditions, where $\\kappa>0$ is a constant thermal diffusivity. Discretize the spatial domain using a uniform grid with spacing $h$ and interior nodes indexed by $i=1,2,\\dots,N-1$, and discretize time using a uniform step $\\Delta t$ with time levels $t^{n}$ and $t^{n+1}=t^{n}+\\Delta t$. Use the implicit backward Euler method in time and a second-order centered finite difference for the spatial second derivative. Starting from these fundamental discretizations, derive the linear algebraic system that must be solved at each time step for the interior nodal values $u_{i}^{n+1}$, show that the coefficient matrix is tridiagonal, and express the three distinct band entries (subdiagonal, diagonal, superdiagonal) purely in terms of $\\kappa$, $\\Delta t$, and $h$. Clearly state how the Dirichlet boundary values at the endpoints enter the right-hand side but do not alter the three band coefficients. Express your final answer as a single row matrix containing the three band entries in the order: subdiagonal, diagonal, superdiagonal. No numerical values are required; provide exact symbolic expressions.",
            "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and self-contained. It represents a standard and fundamental task in the field of numerical partial differential equations. The problem is therefore valid and a solution will be provided.\n\nThe governing partial differential equation (PDE) is the one-dimensional heat equation:\n$$\nu_{t} = \\kappa\\,u_{xx}\n$$\nwhere $u=u(x,t)$ is the temperature, $\\kappa > 0$ is the thermal diffusivity, $t$ is time, and $x$ is the spatial coordinate. The domain is a finite spatial interval, and Dirichlet boundary conditions are specified at the endpoints.\n\nWe are instructed to discretize this equation. Let the spatial domain be discretized by a uniform grid with spacing $h$, such that $x_i = i h$ for integer indices $i$. The interior nodes are indexed from $i=1$ to $N-1$. The time domain is discretized with a uniform step size $\\Delta t$, such that $t^n = n \\Delta t$. We denote the numerical approximation of $u(x_i, t^n)$ as $u_i^n$.\n\nThe problem specifies the use of the implicit backward Euler method for the time derivative. This scheme approximates the time derivative at time level $t^{n+1}$:\n$$\nu_t \\bigg|_{i}^{n+1} \\approx \\frac{u_i^{n+1} - u_i^n}{\\Delta t}\n$$\nFor the spatial second derivative, a second-order centered finite difference approximation is used. In an implicit scheme, this is also evaluated at the future time level $t^{n+1}$:\n$$\nu_{xx} \\bigg|_{i}^{n+1} \\approx \\frac{u_{i-1}^{n+1} - 2u_i^{n+1} + u_{i+1}^{n+1}}{h^2}\n$$\nSubstituting these discrete approximations into the original PDE, we obtain the finite difference equation for each interior node $i=1, 2, \\dots, N-1$:\n$$\n\\frac{u_i^{n+1} - u_i^n}{\\Delta t} = \\kappa \\left( \\frac{u_{i-1}^{n+1} - 2u_i^{n+1} + u_{i+1}^{n+1}}{h^2} \\right)\n$$\nOur goal is to derive the linear algebraic system for the unknown values $u_i^{n+1}$ at the new time step. To do this, we rearrange the equation to group all terms with superscript $n+1$ (the unknowns) on the left-hand side (LHS) and all terms with superscript $n$ (the knowns from the previous time step) on the right-hand side (RHS).\n\nFirst, multiply both sides by $\\Delta t$:\n$$\nu_i^{n+1} - u_i^n = \\frac{\\kappa \\Delta t}{h^2} \\left( u_{i-1}^{n+1} - 2u_i^{n+1} + u_{i+1}^{n+1} \\right)\n$$\nLet us define the non-dimensional diffusion number, $r$, as:\n$$\nr = \\frac{\\kappa \\Delta t}{h^2}\n$$\nSubstituting $r$ into the equation yields:\n$$\nu_i^{n+1} - u_i^n = r \\left( u_{i-1}^{n+1} - 2u_i^{n+1} + u_{i+1}^{n+1} \\right)\n$$\nNow, we collect all terms involving the unknown values $u^{n+1}$ on the LHS:\n$$\nu_i^{n+1} - r u_{i-1}^{n+1} + 2r u_i^{n+1} - r u_{i+1}^{n+1} = u_i^n\n$$\nGrouping the coefficients for each unknown nodal value gives the equation for a generic interior node $i$:\n$$\n-r u_{i-1}^{n+1} + (1 + 2r) u_i^{n+1} - r u_{i+1}^{n+1} = u_i^n\n$$\nThis equation holds for $i=1, 2, \\dots, N-1$. This set of $N-1$ linear equations forms a system $A \\mathbf{u}^{n+1} = \\mathbf{b}$, where $\\mathbf{u}^{n+1}$ is the vector of unknown nodal values $[u_1^{n+1}, u_2^{n+1}, \\dots, u_{N-1}^{n+1}]^T$.\n\nThe structure of the equation for $u_i^{n+1}$ involves only itself and its immediate neighbors, $u_{i-1}^{n+1}$ and $u_{i+1}^{n+1}$. This structure directly implies that the coefficient matrix $A$ is tridiagonal. The entries of the bands are given by the coefficients we derived:\n- The coefficient of $u_{i-1}^{n+1}$ is $-r$. This forms the subdiagonal of the matrix.\n- The coefficient of $u_i^{n+1}$ is $(1+2r)$. This forms the main diagonal of the matrix.\n- The coefficient of $u_{i+1}^{n+1}$ is $-r$. This forms the superdiagonal of the matrix.\n\nThe Dirichlet boundary conditions specify the values at the endpoints of the domain, let's say at $x_0=0$ and $x_N=L$. These are given functions of time, so at time $t^{n+1}$, the values $u_0^{n+1}$ and $u_N^{n+1}$ are known quantities. Let's examine how they affect the system.\n\nFor the first interior node, $i=1$:\n$$\n-r u_{0}^{n+1} + (1 + 2r) u_1^{n+1} - r u_2^{n+1} = u_1^n\n$$\nSince $u_0^{n+1}$ is a known value from the boundary condition, its term is moved to the RHS:\n$$\n(1 + 2r) u_1^{n+1} - r u_2^{n+1} = u_1^n + r u_0^{n+1}\n$$\nThis shows that the first row of the $(N-1) \\times (N-1)$ coefficient matrix for the interior nodes has $(1+2r)$ on the diagonal and $-r$ on the superdiagonal. The subdiagonal element is effectively zero. The boundary value $u_0^{n+1}$ contributes to the first entry of the RHS vector $\\mathbf{b}$.\n\nFor the last interior node, $i=N-1$:\n$$\n-r u_{N-2}^{n+1} + (1 + 2r) u_{N-1}^{n+1} - r u_{N}^{n+1} = u_{N-1}^n\n$$\nSimilarly, $u_N^{n+1}$ is a known boundary value and is moved to the RHS:\n$$\n-r u_{N-2}^{n+1} + (1 + 2r) u_{N-1}^{n+1} = u_{N-1}^n + r u_N^{n+1}\n$$\nThis shows that the last row of the coefficient matrix has $-r$ on the subdiagonal and $(1+2r)$ on the diagonal. The superdiagonal element is effectively zero. The boundary value $u_N^{n+1}$ contributes to the last entry of the RHS vector $\\mathbf{b}$.\n\nThus, the Dirichlet boundary conditions do not alter the three main band entries of the coefficient matrix for the interior unknowns; they only modify the first and last components of the right-hand-side vector. The three distinct, non-zero band entries of the tridiagonal matrix are constant throughout the matrix interior. Expressing them in terms of the given parameters $\\kappa$, $\\Delta t$, and $h$ by substituting back $r = \\frac{\\kappa \\Delta t}{h^2}$:\n- Subdiagonal entry: $-r = -\\frac{\\kappa \\Delta t}{h^2}$\n- Diagonal entry: $1+2r = 1 + \\frac{2\\kappa \\Delta t}{h^2}$\n- Superdiagonal entry: $-r = -\\frac{\\kappa \\Delta t}{h^2}$\n\nThe final answer is a row matrix containing these three entries in the specified order.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{\\kappa \\Delta t}{h^2} & 1 + \\frac{2\\kappa \\Delta t}{h^2} & -\\frac{\\kappa \\Delta t}{h^2}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The remarkable efficiency of the Thomas algorithm, with its linear $O(n)$ complexity, is a direct consequence of its specialized LU factorization for a tridiagonal structure. This exercise delves into the algebraic underpinnings of the algorithm, revealing a powerful connection between the pivots of the forward elimination and the determinant of the matrix. By deriving a recurrence relation for the determinant from first principles, you will gain a deeper appreciation for the algorithm's mechanics and justify its speed in a rigorous way.",
            "id": "3456861",
            "problem": "A finite difference discretization of a scalar, second-order, linear Partial Differential Equation (PDE) on a uniform grid with Dirichlet boundary conditions along a line leads to a linear system with a tridiagonal coefficient matrix. Let $A \\in \\mathbb{R}^{n \\times n}$ be tridiagonal with diagonal entries $\\{a_i\\}_{i=1}^{n}$, superdiagonal entries $\\{b_i\\}_{i=1}^{n-1}$, and subdiagonal entries $\\{c_i\\}_{i=2}^{n}$, i.e.,\n$$\nA \\;=\\; \\begin{pmatrix}\na_1 & b_1 & 0 & \\cdots & 0 \\\\\nc_2 & a_2 & b_2 & \\ddots & \\vdots \\\\\n0 & \\ddots & \\ddots & \\ddots & 0 \\\\\n\\vdots & \\ddots & c_{n-1} & a_{n-1} & b_{n-1} \\\\\n0 & \\cdots & 0 & c_n & a_n\n\\end{pmatrix}.\n$$\nWork from the following fundamental facts only: (i) the determinant is multiplicative over matrix products, (ii) the determinant of a triangular matrix equals the product of its diagonal entries, and (iii) Gaussian elimination realizes a lower-upper factorization (LU) $A = LU$ when all pivots are nonzero, with $L$ unit lower triangular and $U$ upper triangular. Without invoking any pre-stated specialized formulae for tridiagonal matrices, proceed as follows.\n\n- By specializing Gaussian elimination to the tridiagonal sparsity pattern (the Thomas algorithm), symbolically eliminate subdiagonal entries to construct a unit lower triangular matrix $L$ and an upper triangular matrix $U$ with diagonal entries $\\{u_i\\}_{i=1}^{n}$ and superdiagonal entries inherited from $\\{b_i\\}_{i=1}^{n-1}$. Using only the properties listed above, deduce an $O(n)$ method to evaluate $\\det(A)$ and identify the precise scalar quantities that must be computed to obtain it.\n\n- Let $D_k := \\det(A_k)$ denote the leading principal minor of order $k$, where $A_k$ is the $k \\times k$ leading principal submatrix of $A$. Derive, from first principles, a three-term recurrence satisfied by $\\{D_k\\}_{k=0}^{n}$, including explicit initial conditions. Your derivation should rely solely on basic determinant properties and the tridiagonal structure.\n\n- Finally, apply your derivations to the specific strictly diagonally dominant case with $n=6$, $a_i = 3$ for all $i$, $b_i = -1$ for $i = 1,\\dots,5$, and $c_i = -1$ for $i = 2,\\dots,6$. Compute $\\det(A)$ exactly by the $O(n)$ method you justified. Express your final result as an exact integer with no rounding.",
            "solution": "The user has provided a three-part problem concerning the determinant of a tridiagonal matrix. The problem is validated to be self-contained, scientifically grounded in linear algebra, and objectively stated.\n\n**Part 1: Derivation of an $O(n)$ Method for $\\det(A)$ via LU Factorization**\n\nWe are tasked with finding an efficient method to compute the determinant of a tridiagonal matrix $A$ using its LU factorization. The matrix $A$ has the form:\n$$\nA = \\begin{pmatrix}\na_1 & b_1 & 0 & \\cdots & 0 \\\\\nc_2 & a_2 & b_2 & \\ddots & \\vdots \\\\\n0 & \\ddots & \\ddots & \\ddots & 0 \\\\\n\\vdots & \\ddots & c_{n-1} & a_{n-1} & b_{n-1} \\\\\n0 & \\cdots & 0 & c_n & a_n\n\\end{pmatrix}\n$$\nWe seek a factorization $A = LU$, where $L$ is a unit lower triangular matrix and $U$ is an upper triangular matrix. The tridiagonal structure of $A$ implies that $L$ will be unit lower bidiagonal and $U$ will be upper bidiagonal.\n\nLet $L$ and $U$ be represented as:\n$$\nL = \\begin{pmatrix}\n1 & 0 & \\cdots & 0 \\\\\n\\ell_2 & 1 & \\ddots & \\vdots \\\\\n\\vdots & \\ddots & \\ddots & 0 \\\\\n0 & \\cdots & \\ell_n & 1\n\\end{pmatrix}, \\quad\nU = \\begin{pmatrix}\nu_1 & b_1 & 0 & \\cdots & 0 \\\\\n0 & u_2 & b_2 & \\ddots & \\vdots \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & 0 \\\\\n\\vdots & & \\ddots & u_{n-1} & b_{n-1} \\\\\n0 & \\cdots & \\cdots & 0 & u_n\n\\end{pmatrix}\n$$\nwhere we have used the given information that the superdiagonal of $U$ consists of the entries $\\{b_i\\}_{i=1}^{n-1}$ from $A$. By performing the matrix multiplication $LU$ and equating the result to $A$, we can determine the unknown entries $\\{\\ell_i\\}_{i=2}^{n}$ of $L$ and $\\{u_i\\}_{i=1}^{n}$ of $U$.\n\nThe product $LU$ is:\n$$\nLU = \\begin{pmatrix}\nu_1 & b_1 & 0 & \\cdots & 0 \\\\\n\\ell_2 u_1 & \\ell_2 b_1 + u_2 & b_2 & \\ddots & \\vdots \\\\\n0 & \\ell_3 u_2 & \\ell_3 b_2 + u_3 & \\ddots & 0 \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & b_{n-1} \\\\\n0 & \\cdots & 0 & \\ell_n u_{n-1} & \\ell_n b_{n-1} + u_n\n\\end{pmatrix}\n$$\nBy comparing the entries of $LU$ with the entries of $A$ row by row:\n1.  For the first row ($i=1$):\n    -   The diagonal entry is $u_1 = a_1$.\n\n2.  For any subsequent row $i=2, 3, \\dots, n$:\n    -   The subdiagonal entry is $\\ell_i u_{i-1} = c_i$. This implies $\\ell_i = \\frac{c_i}{u_{i-1}}$, which requires $u_{i-1} \\neq 0$. This corresponds to the Gaussian elimination pivot being nonzero.\n    -   The diagonal entry is $\\ell_i b_{i-1} + u_i = a_i$. This implies $u_i = a_i - \\ell_i b_{i-1}$.\n\nSubstituting the expression for $\\ell_i$ into the equation for $u_i$, we obtain a recurrence relation for the diagonal elements of $U$:\n$$\nu_1 = a_1\n$$\n$$\nu_i = a_i - \\frac{c_i b_{i-1}}{u_{i-1}} \\quad \\text{for } i = 2, 3, \\dots, n\n$$\nThis constitutes a sequential algorithm to find the quantities $\\{u_i\\}$. This algorithm is equivalent to the forward elimination phase of the Thomas algorithm.\n\nNow, we use the provided fundamental facts about determinants.\n(i) The determinant is multiplicative: $\\det(A) = \\det(L) \\det(U)$.\n(ii) The determinant of a triangular matrix is the product of its diagonal entries.\nFor matrix $L$, which is unit lower triangular, all diagonal entries are $1$. Thus, $\\det(L) = 1$.\nFor matrix $U$, which is upper triangular, the diagonal entries are $\\{u_i\\}_{i=1}^{n}$. Thus, $\\det(U) = \\prod_{i=1}^{n} u_i$.\nCombining these results, we find the determinant of $A$:\n$$\n\\det(A) = 1 \\cdot \\prod_{i=1}^{n} u_i = \\prod_{i=1}^{n} u_i\n$$\nThe method to evaluate $\\det(A)$ is as follows:\n1. Initialize $u_1 = a_1$.\n2. For $i$ from $2$ to $n$, compute $u_i$ using the recurrence $u_i = a_i - (c_i b_{i-1}) / u_{i-1}$.\n3. The determinant is the product of all the computed $u_i$ values: $\\det(A) = u_1 u_2 \\cdots u_n$.\n\nEach step of the recurrence for $u_i$ requires a constant number of arithmetic operations (one multiplication, one division, one subtraction). Since this is repeated $n-1$ times, the computation of all $\\{u_i\\}$ takes $O(n)$ operations. The final product of the $n$ values also takes $O(n)$ operations. Therefore, this is an $O(n)$ method for computing the determinant. The precise scalar quantities that must be computed are the diagonal entries of $U$, $\\{u_i\\}_{i=1}^{n}$.\n\n**Part 2: Derivation of a Three-Term Recurrence for Leading Principal Minors**\n\nLet $D_k = \\det(A_k)$, where $A_k$ is the $k \\times k$ leading principal submatrix of $A$. We will derive a recurrence relation for $\\{D_k\\}$ using cofactor expansion, a basic property of determinants.\n\nThe submatrix $A_k$ is:\n$$\nA_k = \\begin{pmatrix}\na_1 & b_1 & & & \\\\\nc_2 & a_2 & b_2 & & \\\\\n& \\ddots & \\ddots & \\ddots & \\\\\n& & c_{k-1} & a_{k-1} & b_{k-1} \\\\\n& & & c_k & a_k\n\\end{pmatrix}\n$$\nWe compute $D_k = \\det(A_k)$ by cofactor expansion along the last row (row $k$). The only nonzero entries in this row are $(A_k)_{k, k-1} = c_k$ and $(A_k)_{k, k} = a_k$.\n$$\nD_k = (-1)^{k+(k-1)} (A_k)_{k, k-1} M_{k, k-1} + (-1)^{k+k} (A_k)_{k, k} M_{k, k}\n$$\n$$\nD_k = -c_k M_{k, k-1} + a_k M_{k, k}\n$$\nwhere $M_{i,j}$ is the minor of the element at row $i$ and column $j$.\n\nThe minor $M_{k, k}$ is the determinant of the matrix obtained by removing row $k$ and column $k$ from $A_k$. This resulting matrix is exactly $A_{k-1}$. Therefore, $M_{k, k} = \\det(A_{k-1}) = D_{k-1}$.\n\nThe minor $M_{k, k-1}$ is the determinant of the matrix obtained by removing row $k$ and column $k-1$ from $A_k$. This $(k-1) \\times (k-1)$ matrix is:\n$$\n\\begin{pmatrix}\na_1 & b_1 & \\cdots & 0 & 0 \\\\\nc_2 & a_2 & \\cdots & 0 & 0 \\\\\n\\vdots & \\ddots & \\ddots & & \\vdots \\\\\n0 & \\cdots & c_{k-2} & a_{k-2} & 0 \\\\\n0 & \\cdots & 0 & c_{k-1} & b_{k-1}\n\\end{pmatrix}\n$$\nThis matrix is upper triangular in its last column. Performing a cofactor expansion along the last column reveals that the determinant is $b_{k-1}$ times the determinant of its cofactor matrix, which is $A_{k-2}$. So, $M_{k, k-1} = b_{k-1} \\det(A_{k-2}) = b_{k-1} D_{k-2}$.\n\nSubstituting the expressions for the minors back into the expansion for $D_k$:\n$$\nD_k = a_k D_{k-1} - c_k (b_{k-1} D_{k-2})\n$$\nThis gives the three-term recurrence relation:\n$$\nD_k = a_k D_{k-1} - b_{k-1} c_k D_{k-2} \\quad \\text{for } k \\ge 2\n$$\nTo complete the definition, we need initial conditions for $k=0$ and $k=1$.\n$D_1 = \\det(A_1) = \\det((a_1)) = a_1$.\nFor $k=2$, the recurrence gives $D_2 = a_2 D_1 - b_1 c_2 D_0$.\nDirect calculation gives $D_2 = \\det \\begin{pmatrix} a_1 & b_1 \\\\ c_2 & a_2 \\end{pmatrix} = a_1 a_2 - b_1 c_2$.\nEquating the two expressions for $D_2$: $a_1 a_2 - b_1 c_2 = a_2 a_1 - b_1 c_2 D_0$. Assuming $b_1 c_2 \\neq 0$, this requires $D_0 = 1$. This is the standard convention for the determinant of a $0 \\times 0$ matrix.\nThe initial conditions are $D_0=1$ and $D_1=a_1$.\n\n**Part 3: Application to a Specific Case**\n\nWe are given a specific $6 \\times 6$ matrix with $n=6$, $a_i=3$, $b_i=-1$, and $c_i=-1$. The matrix is strictly diagonally dominant, ensuring that all pivots $u_i$ will be nonzero.\nWe will use the $O(n)$ method derived in Part 1 to compute $\\det(A)$. The recurrence relations are:\n$u_1 = a_1 = 3$.\n$u_i = a_i - \\frac{c_i b_{i-1}}{u_{i-1}} = 3 - \\frac{(-1)(-1)}{u_{i-1}} = 3 - \\frac{1}{u_{i-1}}$ for $i=2, \\dots, 6$.\n\nLet's compute the sequence $\\{u_i\\}_{i=1}^6$:\n- $u_1 = 3$\n- $u_2 = 3 - \\frac{1}{u_1} = 3 - \\frac{1}{3} = \\frac{9-1}{3} = \\frac{8}{3}$\n- $u_3 = 3 - \\frac{1}{u_2} = 3 - \\frac{1}{8/3} = 3 - \\frac{3}{8} = \\frac{24-3}{8} = \\frac{21}{8}$\n- $u_4 = 3 - \\frac{1}{u_3} = 3 - \\frac{1}{21/8} = 3 - \\frac{8}{21} = \\frac{63-8}{21} = \\frac{55}{21}$\n- $u_5 = 3 - \\frac{1}{u_4} = 3 - \\frac{1}{55/21} = 3 - \\frac{21}{55} = \\frac{165-21}{55} = \\frac{144}{55}$\n- $u_6 = 3 - \\frac{1}{u_5} = 3 - \\frac{1}{144/55} = 3 - \\frac{55}{144} = \\frac{432-55}{144} = \\frac{377}{144}$\n\nThe determinant of $A$ is the product of these values:\n$$\n\\det(A) = \\prod_{i=1}^{6} u_i = u_1 \\cdot u_2 \\cdot u_3 \\cdot u_4 \\cdot u_5 \\cdot u_6\n$$\n$$\n\\det(A) = 3 \\times \\frac{8}{3} \\times \\frac{21}{8} \\times \\frac{55}{21} \\times \\frac{144}{55} \\times \\frac{377}{144}\n$$\nThis is a telescoping product. Most terms cancel out:\n$$\n\\det(A) = \\cancel{3} \\times \\frac{\\cancel{8}}{\\cancel{3}} \\times \\frac{\\cancel{21}}{\\cancel{8}} \\times \\frac{\\cancel{55}}{\\cancel{21}} \\times \\frac{\\cancel{144}}{\\cancel{55}} \\times \\frac{377}{\\cancel{144}} = 377\n$$\nThe determinant is exactly $377$. This calculation can be verified using the recurrence from Part 2. Let $D_k = \\det(A_k)$. The recurrence is $D_k = 3D_{k-1} - D_{k-2}$ with $D_0=1, D_1=3$.\n$D_2 = 3(3) - 1 = 8$.\n$D_3 = 3(8) - 3 = 21$.\n$D_4 = 3(21) - 8 = 55$.\n$D_5 = 3(55) - 21 = 144$.\n$D_6 = 3(144) - 55 = 432 - 55 = 377$.\nThe result is consistent.",
            "answer": "$$\\boxed{377}$$"
        },
        {
            "introduction": "While the Thomas algorithm is highly efficient, its stability is not guaranteed for all tridiagonal matrices. This final exercise explores a critical and physically relevant scenario—the convection-dominated convection-diffusion equation—where the choice of discretization scheme can dramatically impact numerical stability. By comparing the behavior of the algorithm's pivots for centered versus upwind differencing, you will investigate how a lack of diagonal dominance can lead to numerical issues and how a physically-informed discretization can restore stability. This practice is essential for developing the critical judgment needed to apply numerical methods reliably.",
            "id": "3456789",
            "problem": "Consider the one-dimensional steady convection–diffusion model equation $-\\epsilon\\,u''(x) + u'(x) = f(x)$ on the interval $x \\in [0,1]$, with Dirichlet boundary conditions $u(0) = 0$ and $u(1) = 1$, where $\\epsilon > 0$ is a small diffusivity parameter and $f$ is a smooth function. A uniform grid with $N+1$ nodes is used, $x_j = jh$ for $j = 0,1,\\dots,N$, with $h = 1/N$, and the unknowns are the interior values $u_j \\approx u(x_j)$ for $j = 1,\\dots,N-1$. Use the standard second-order centered finite difference approximation for $u''$ and compare two discretizations for $u'$:\n- Centered difference: $u'(x_j) \\approx \\left(u_{j+1} - u_{j-1}\\right)/(2h)$.\n- First-order upwind difference (consistent with advection to the right): $u'(x_j) \\approx \\left(u_j - u_{j-1}\\right)/h$.\n\nFor each discretization, the resulting linear system for the interior unknown vector is tridiagonal and is to be solved by the tridiagonal matrix algorithm (TDMA), also known as the Thomas algorithm. Let $d_i$ denote the pivot encountered at step $i$ in the forward elimination of the Thomas algorithm applied to the corresponding tridiagonal system, with $i = 1,2,\\dots,N-1$. Assume $N \\geq 3$ is fixed and consider the singularly perturbed regime $\\epsilon \\to 0$ (boundary-layer-dominated flow).\n\nStarting from the fundamental definitions of the finite difference approximations and the forward elimination process in the Thomas algorithm, derive the leading-order asymptotics of the pivot sequence $\\{d_i\\}$ for each discretization as $\\epsilon \\to 0$. Then, quantify the smallest pivot in each case by evaluating the following two limits:\n$$\nL_{\\mathrm{c}} \\;=\\; \\lim_{\\epsilon \\to 0} \\frac{h^{2}}{\\epsilon} \\,\\min_{1 \\leq i \\leq N-1} d_i^{(\\mathrm{central})}\n\\qquad\\text{and}\\qquad\nL_{\\mathrm{u}} \\;=\\; \\lim_{\\epsilon \\to 0} h \\,\\min_{1 \\leq i \\leq N-1} d_i^{(\\mathrm{upwind})},\n$$\nwhere $d_i^{(\\mathrm{central})}$ and $d_i^{(\\mathrm{upwind})}$ denote the pivot sequences for the centered and upwind discretizations, respectively. Report your final answer as a single row matrix containing $\\left(L_{\\mathrm{c}},\\,L_{\\mathrm{u}}\\right)$, and do not perform any rounding. Discuss, as part of your derivation, the implications for diagonal dominance and stability of the Thomas algorithm in the limit $\\epsilon \\to 0$ for both discretizations.",
            "solution": "The problem asks for an analysis of the pivots generated by the Thomas algorithm for two different finite difference discretizations of the one-dimensional convection-diffusion equation $-\\epsilon\\,u''(x) + u'(x) = f(x)$ on $x \\in [0,1]$, with $u(0) = 0$ and $u(1) = 1$. The analysis is to be performed in the singularly perturbed limit, $\\epsilon \\to 0$, for a fixed grid spacing $h=1/N$.\n\nThe equation is discretized on a uniform grid $x_j = jh$ for $j=0, 1, \\dots, N$. The second derivative is approximated by the standard second-order centered difference:\n$$\nu''(x_j) \\approx \\frac{u_{j+1} - 2u_j + u_{j-1}}{h^2}\n$$\nThe resulting linear system for the interior unknowns $u_j$ ($j=1, \\dots, N-1$) is of the form $a_j u_{j-1} + b_j u_j + c_j u_{j+1} = \\tilde{f}_j$. The Thomas algorithm (TDMA) is equivalent to an $LU$ decomposition of the tridiagonal matrix $A$, where the pivots $d_i$ are the diagonal elements of the upper triangular matrix $U$. The pivots are generated by the recurrence relation:\n$$\nd_1 = b_1, \\qquad d_i = b_i - \\frac{a_i c_{i-1}}{d_{i-1}} \\quad \\text{for } i=2, \\dots, N-1.\n$$\nThe boundary conditions $u_0=0$ and $u_N=1$ are incorporated into the first and last equations of the system, affecting the right-hand side vector but not the matrix entries for a general interior row, which are constant across the mesh.\n\n**Centered Difference Discretization**\n\nFor the centered difference approximation of the first derivative, $u'(x_j) \\approx (u_{j+1} - u_{j-1})/(2h)$, the discrete equation at an interior node $x_j$ is:\n$$\n-\\epsilon \\frac{u_{j+1} - 2u_j + u_{j-1}}{h^2} + \\frac{u_{j+1} - u_{j-1}}{2h} = f_j\n$$\nRearranging terms yields the coefficients for the tridiagonal system:\n$$\n\\left(-\\frac{\\epsilon}{h^2} - \\frac{1}{2h}\\right)u_{j-1} + \\left(\\frac{2\\epsilon}{h^2}\\right)u_j + \\left(-\\frac{\\epsilon}{h^2} + \\frac{1}{2h}\\right)u_{j+1} = f_j\n$$\nFor the interior rows of the matrix (from $i=2$ to $N-2$), the coefficients are uniform. The system matrix $A^{(\\mathrm{c})}$ has coefficients:\n$a_i^{(\\mathrm{c})} = a = -\\frac{\\epsilon}{h^2} - \\frac{1}{2h}$ for $i \\ge 2$.\n$b_i^{(\\mathrm{c})} = b = \\frac{2\\epsilon}{h^2}$ for all $i$.\n$c_i^{(\\mathrm{c})} = c = -\\frac{\\epsilon}{h^2} + \\frac{1}{2h}$ for $i \\le N-2$.\n\nThe condition for strict diagonal dominance is $|b_i| > |a_i| + |c_i|$. For small $\\epsilon$ such that $h > 2\\epsilon$, we have $|c| = \\frac{1}{2h} - \\frac{\\epsilon}{h^2} > 0$. The condition becomes:\n$$\n\\frac{2\\epsilon}{h^2} > \\left(\\frac{\\epsilon}{h^2} + \\frac{1}{2h}\\right) + \\left(\\frac{1}{2h} - \\frac{\\epsilon}{h^2}\\right) = \\frac{1}{h}\n$$\nThis simplifies to $2\\epsilon > h$, or that a cell Péclet number $Pe_h = h/(2\\epsilon)$ must be less than $1$. In the limit $\\epsilon \\to 0$, this condition is violated, so the matrix is not diagonally dominant.\n\nThe pivots $d_i^{(\\mathrm{c})}$ are given by the recurrence: $d_1^{(\\mathrm{c})} = b$ and $d_i^{(\\mathrm{c})} = b - \\frac{ac}{d_{i-1}^{(\\mathrm{c})}}$.\nThe product $ac$ is:\n$$\nac = \\left(-\\frac{\\epsilon}{h^2} - \\frac{1}{2h}\\right)\\left(-\\frac{\\epsilon}{h^2} + \\frac{1}{2h}\\right) = \\left(\\frac{\\epsilon}{h^2}\\right)^2 - \\left(\\frac{1}{2h}\\right)^2 = \\frac{\\epsilon^2}{h^4} - \\frac{1}{4h^2}\n$$\nAs $\\epsilon \\to 0$, $b \\to 0$ and $ac \\to -1/(4h^2)$.\nThe first pivot is $d_1^{(\\mathrm{c})} = b = \\frac{2\\epsilon}{h^2}$.\nThe second pivot is $d_2^{(\\mathrm{c})} = b - \\frac{ac}{d_1^{(\\mathrm{c})}} = \\frac{2\\epsilon}{h^2} - \\frac{\\epsilon^2/h^4 - 1/(4h^2)}{2\\epsilon/h^2} = \\frac{2\\epsilon}{h^2} - \\left(\\frac{\\epsilon}{2h^2} - \\frac{h^2}{8\\epsilon}\\right) = \\frac{3\\epsilon}{2h^2} + \\frac{1}{8\\epsilon}$.\nFor small $\\epsilon$, the leading-order behavior is $d_2^{(\\mathrm{c})} \\approx \\frac{1}{8\\epsilon}$.\nThe third pivot is $d_3^{(\\mathrm{c})} = b - \\frac{ac}{d_2^{(\\mathrm{c})}} \\approx \\frac{2\\epsilon}{h^2} - \\frac{-1/(4h^2)}{1/(8\\epsilon)} = \\frac{2\\epsilon}{h^2} + \\frac{2\\epsilon}{h^2} = \\frac{4\\epsilon}{h^2}$.\nThis suggests a pattern where odd-indexed pivots are $O(\\epsilon)$ and even-indexed pivots are $O(1/\\epsilon)$. The relationship $d_i - d_{i-2} = ac(1/d_{i-3} - 1/d_{i-1})$ with $ac<0$ implies that the sign of $d_i - d_{i-2}$ is opposite to that of $d_{i-1} - d_{i-3}$. Since $d_3 - d_1 > 0$, it follows that $d_4 - d_2  0$, which in turn implies $d_5 - d_3 > 0$. The pivot sequence exhibits an oscillatory, or sawtooth, behavior. The odd-indexed pivots $\\{d_1, d_3, ...\\}$ are all of order $O(\\epsilon)$, while the even-indexed pivots $\\{d_2, d_4, ...\\}$ are all of order $O(1/\\epsilon)$. The minimum pivot in the sequence will therefore be an odd-indexed pivot. Let's inspect the odd subsequence: $d_1 = 2\\epsilon/h^2$, $d_3 = 4\\epsilon/h^2$, $d_5 = 6\\epsilon/h^2$, etc. It appears to be an increasing sequence. The minimum pivot is thus the first one.\n$$\n\\min_{1 \\leq i \\leq N-1} d_i^{(\\mathrm{c})} = d_1^{(\\mathrm{c})} = \\frac{2\\epsilon}{h^2}\n$$\nNow we can evaluate the limit $L_{\\mathrm{c}}$:\n$$\nL_{\\mathrm{c}} = \\lim_{\\epsilon \\to 0} \\frac{h^2}{\\epsilon} \\min_{1 \\leq i \\leq N-1} d_i^{(\\mathrm{c})} = \\lim_{\\epsilon \\to 0} \\frac{h^2}{\\epsilon} \\left(\\frac{2\\epsilon}{h^2}\\right) = 2\n$$\nThe oscillatory behavior of the pivots, alternating between small ($O(\\epsilon)$) and large ($O(1/\\epsilon)$) values, is a sign of numerical instability. Small pivots can amplify round-off errors in finite-precision arithmetic.\n\n**First-Order Upwind Discretization**\n\nFor the upwind approximation $u'(x_j) \\approx (u_j-u_{j-1})/h$, the discrete equation is:\n$$\n-\\epsilon \\frac{u_{j+1} - 2u_j + u_{j-1}}{h^2} + \\frac{u_j - u_{j-1}}{h} = f_j\n$$\nThe coefficients for the tridiagonal system $A^{(\\mathrm{u})}$ are:\n$a_i^{(\\mathrm{u})} = a = -\\frac{\\epsilon}{h^2} - \\frac{1}{h}$\n$b_i^{(\\mathrm{u})} = b = \\frac{2\\epsilon}{h^2} + \\frac{1}{h}$\n$c_i^{(\\mathrm{u})} = c = -\\frac{\\epsilon}{h^2}$\nLet's check for diagonal dominance: $|b_i| = \\frac{2\\epsilon}{h^2} + \\frac{1}{h}$.\n$|a_i| + |c_i| = \\left(\\frac{\\epsilon}{h^2} + \\frac{1}{h}\\right) + \\frac{\\epsilon}{h^2} = \\frac{2\\epsilon}{h^2} + \\frac{1}{h}$.\nSince $|b_i| = |a_i| + |c_i|$, the matrix is diagonally dominant (though not strictly). This guarantees that the TDMA is stable.\n\nThe pivots $d_i^{(\\mathrm{u})}$ follow the recurrence $d_1^{(\\mathrm{u})}=b$, $d_i^{(\\mathrm{u})} = b - \\frac{ac}{d_{i-1}^{(\\mathrm{u})}}$, with $ac = \\frac{\\epsilon}{h^2}\\left(\\frac{\\epsilon}{h^2} + \\frac{1}{h}\\right) = \\frac{\\epsilon(\\epsilon+h)}{h^4}$.\nThe recurrence has fixed points satisfying $d^2 - bd + ac = 0$. The solutions are:\n$$\nd = \\frac{b \\pm \\sqrt{b^2-4ac}}{2} = \\frac{\\frac{2\\epsilon+h}{h^2} \\pm \\sqrt{\\left(\\frac{2\\epsilon+h}{h^2}\\right)^2 - 4\\frac{\\epsilon(\\epsilon+h)}{h^4}}}{2} = \\frac{\\frac{2\\epsilon+h}{h^2} \\pm \\frac{1}{h}}{2}\n$$\nThe two fixed points are $d_+ = \\frac{\\epsilon+h}{h^2}$ and $d_- = \\frac{\\epsilon}{h^2}$.\nThe derivative of the iteration map $F(d)=b-ac/d$ is $F'(d) = ac/d^2$.\nAt $d_+$, $F'(d_+) = \\frac{\\epsilon(\\epsilon+h)/h^4}{((\\epsilon+h)/h^2)^2} = \\frac{\\epsilon}{\\epsilon+h}$. Since $0  \\frac{\\epsilon}{\\epsilon+h}  1$, $d_+$ is a stable fixed point.\nAt $d_-$, $F'(d_-) = \\frac{\\epsilon(\\epsilon+h)/h^4}{(\\epsilon/h^2)^2} = \\frac{\\epsilon+h}{\\epsilon}  1$, so $d_-$ is an unstable fixed point.\nThe initial pivot is $d_1^{(\\mathrm{u})} = b = \\frac{2\\epsilon+h}{h^2}$. We note that $d_1^{(\\mathrm{u})}  d_+$. Since the iteration map is increasing for positive $d$, and $d_2 - d_1 = b - ac/d_1 - d_1  0$, the sequence $\\{d_i^{(\\mathrm{u})}\\}$ is monotonically decreasing and converges to $d_+$.\nThe minimum of the finite sequence $\\{d_1, \\dots, d_{N-1}\\}$ is its last term, $d_{N-1}^{(\\mathrm{u})}$.\nThe sequence converges to its limit $d_+$, so for large $i$, $d_i \\approx d_+$.\n$$\n\\min_{1 \\leq i \\leq N-1} d_i^{(\\mathrm{u})} = d_{N-1}^{(\\mathrm{u})}\n$$\nAs $\\epsilon \\to 0$, $d_{N-1}^{(\\mathrm{u})}$ converges to $\\lim_{\\epsilon \\to 0} d_+ = 1/h$.\nMore precisely, for any fixed $i$, $\\lim_{\\epsilon \\to 0} d_i^{(\\mathrm{u})} = 1/h$. Thus, $\\lim_{\\epsilon \\to 0} \\min d_i^{(\\mathrm{u})} = 1/h$.\nWe can now evaluate the limit $L_{\\mathrm{u}}$:\n$$\nL_{\\mathrm{u}} = \\lim_{\\epsilon \\to 0} h \\min_{1 \\leq i \\leq N-1} d_i^{(\\mathrm{u})} = h \\left(\\lim_{\\epsilon \\to 0} \\min_{1 \\leq i \\leq N-1} d_i^{(\\mathrm{u})}\\right) = h \\left(\\frac{1}{h}\\right) = 1\n$$\nFor the upwind scheme, all pivots are positive and of order $O(1/h)$ as $\\epsilon \\to 0$. There are no pathologically small pivots, reflecting the stability of this method for convection-dominated problems.\n\nThe final results for the two limits are $L_{\\mathrm{c}} = 2$ and $L_{\\mathrm{u}} = 1$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  1\n\\end{pmatrix}\n}\n$$"
        }
    ]
}