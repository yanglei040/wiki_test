{
    "hands_on_practices": [
        {
            "introduction": "To master implicit methods, we must first understand how they are constructed and what their theoretical guarantees are. This foundational exercise  guides you through the derivation of the celebrated Crank-Nicolson scheme from first principles. By analyzing its local truncation error and its behavior on the linear test equation, you will uncover its second-order accuracy and explore the crucial stability concepts of A-stability and L-stability.",
            "id": "3316918",
            "problem": "A semi-discrete formulation in Computational Fluid Dynamics (CFD) obtained from a spatial discretization by the method of lines leads to an Ordinary Differential Equation (ODE) system of the form $M \\dot{\\mathbf{u}}(t) = \\mathbf{r}(\\mathbf{u}(t))$, where $M \\in \\mathbb{R}^{m \\times m}$ is a time-independent, symmetric positive-definite mass matrix and $\\mathbf{r}: \\mathbb{R}^{m} \\to \\mathbb{R}^{m}$ is sufficiently smooth. Consider advancing the solution from time $t_n$ to $t_{n+1} = t_n + \\Delta t$.\n\nTasks:\n1. Starting from the fundamental identity\n$$\nM\\left(\\mathbf{u}(t_{n+1}) - \\mathbf{u}(t_n)\\right) = \\int_{t_n}^{t_{n+1}} \\mathbf{r}(\\mathbf{u}(t)) \\, dt,\n$$\nderive an implicit time-stepping method by applying the trapezoidal quadrature rule to the time integral on the right-hand side. Write the resulting fully discrete one-step method for computing $\\mathbf{u}^{n+1}$ from $\\mathbf{u}^n$.\n\n2. Establish the order $2$ accuracy in time of the method by analyzing the local truncation error. Specifically, define the defect produced when the exact solution is inserted into the discrete formula and, using Taylor expansions in time and the chain rule, determine the order of the leading nonzero term in $\\Delta t$.\n\n3. Consider the linear stiff model problem $\\mathbf{r}(\\mathbf{u}) = A \\mathbf{u}$ with $A \\in \\mathbb{R}^{m \\times m}$ and $M = I$, and analyze the scalar test equation $\\dot{u} = \\lambda u$ with $\\lambda \\in \\mathbb{C}$, $\\operatorname{Re}(\\lambda) < 0$. Derive the scalar amplification factor $R(z)$ with $z = \\lambda \\Delta t$ for the method obtained in part $1$. Discuss the implications of $|R(z)|$ for $\\operatorname{Re}(z) \\le 0$ and the behavior of $R(z)$ as $z \\to -\\infty$ in relation to $A$-stability and $L$-stability, including the possibility of parasitic oscillations in stiff components.\n\nFinally, compute the stiff-limit amplification factor $\\lim_{z \\to -\\infty} R(z)$ for the method derived in part $1$, and report this limit as your final answer. Express the final answer as an exact real number without units.",
            "solution": "The problem as stated is scientifically grounded, well-posed, objective, and contains all necessary information for a rigorous solution. The tasks correspond to a standard analysis of a numerical method for ordinary differential equations (ODEs), covering its derivation, accuracy, and stability.\n\n### Task 1: Derivation of the Implicit Time-Stepping Method\n\nWe begin with the fundamental integral identity that relates the change in the solution vector $\\mathbf{u}$ over a time interval $[t_n, t_{n+1}]$ to the time integral of the residual vector $\\mathbf{r}(\\mathbf{u}(t))$:\n$$\nM\\left(\\mathbf{u}(t_{n+1}) - \\mathbf{u}(t_n)\\right) = \\int_{t_n}^{t_{n+1}} \\mathbf{r}(\\mathbf{u}(t)) \\, dt\n$$\nHere, $t_{n+1} = t_n + \\Delta t$. The task is to derive a discrete one-step method by approximating the integral on the right-hand side using the trapezoidal quadrature rule. The trapezoidal rule for a generic vector-valued function $\\mathbf{f}(t)$ over an interval $[a, b]$ is given by:\n$$\n\\int_a^b \\mathbf{f}(t) \\, dt \\approx \\frac{b-a}{2} \\left( \\mathbf{f}(a) + \\mathbf{f}(b) \\right)\n$$\nApplying this rule to our integral with $\\mathbf{f}(t) = \\mathbf{r}(\\mathbf{u}(t))$, $a = t_n$, and $b = t_{n+1}$, we obtain the approximation:\n$$\n\\int_{t_n}^{t_{n+1}} \\mathbf{r}(\\mathbf{u}(t)) \\, dt \\approx \\frac{t_{n+1} - t_n}{2} \\left( \\mathbf{r}(\\mathbf{u}(t_n)) + \\mathbf{r}(\\mathbf{u}(t_{n+1})) \\right) = \\frac{\\Delta t}{2} \\left( \\mathbf{r}(\\mathbf{u}(t_n)) + \\mathbf{r}(\\mathbf{u}(t_{n+1})) \\right)\n$$\nTo obtain the fully discrete method, we substitute this approximation back into the fundamental identity and replace the exact solution $\\mathbf{u}(t_k)$ with its numerical approximation $\\mathbf{u}^k$ at time $t_k$. This yields:\n$$\nM\\left(\\mathbf{u}^{n+1} - \\mathbf{u}^n\\right) = \\frac{\\Delta t}{2} \\left( \\mathbf{r}(\\mathbf{u}^n) + \\mathbf{r}(\\mathbf{u}^{n+1}) \\right)\n$$\nThis is the one-step method for advancing the solution from $\\mathbf{u}^n$ to $\\mathbf{u}^{n+1}$. It is an implicit method because the unknown $\\mathbf{u}^{n+1}$ appears on both sides of the equation, including as an argument to the (generally nonlinear) function $\\mathbf{r}$. This method is widely known as the trapezoidal rule method or, in some contexts, the Crank-Nicolson method.\n\n### Task 2: Analysis of Local Truncation Error\n\nThe local truncation error (LTE) is the residual, or defect, that arises when the exact solution $\\mathbf{u}(t)$ of the ODE is substituted into the discrete difference equation. We denote the defect at step $n+1$ by $\\boldsymbol{\\tau}^{n+1}$:\n$$\n\\boldsymbol{\\tau}^{n+1} = M\\left(\\mathbf{u}(t_{n+1}) - \\mathbf{u}(t_n)\\right) - \\frac{\\Delta t}{2} \\left( \\mathbf{r}(\\mathbf{u}(t_n)) + \\mathbf{r}(\\mathbf{u}(t_{n+1})) \\right)\n$$\nTo determine the order of the method, we perform Taylor series expansions of the terms around time $t_n$. Let $\\mathbf{u}_n = \\mathbf{u}(t_n)$.\nThe expansion for $\\mathbf{u}(t_{n+1})$ is:\n$$\n\\mathbf{u}(t_{n+1}) = \\mathbf{u}_n + \\Delta t \\dot{\\mathbf{u}}_n + \\frac{(\\Delta t)^2}{2} \\ddot{\\mathbf{u}}_n + \\frac{(\\Delta t)^3}{6} \\dddot{\\mathbf{u}}_n + \\mathcal{O}((\\Delta t)^4)\n$$\nThe expansion for $\\mathbf{r}(\\mathbf{u}(t_{n+1}))$ is an expansion in time:\n$$\n\\mathbf{r}(\\mathbf{u}(t_{n+1})) = \\mathbf{r}(\\mathbf{u}_n) + \\Delta t \\dot{\\mathbf{r}}_n + \\frac{(\\Delta t)^2}{2} \\ddot{\\mathbf{r}}_n + \\mathcal{O}((\\Delta t)^3)\n$$\nwhere $\\dot{\\mathbf{r}}_n = \\frac{d}{dt}\\mathbf{r}(\\mathbf{u}(t))|_{t=t_n}$, and so on.\nNow, we substitute these expansions into the expression for $\\boldsymbol{\\tau}^{n+1}$:\n$$\n\\boldsymbol{\\tau}^{n+1} = M\\left( \\Delta t \\dot{\\mathbf{u}}_n + \\frac{(\\Delta t)^2}{2} \\ddot{\\mathbf{u}}_n + \\frac{(\\Delta t)^3}{6} \\dddot{\\mathbf{u}}_n \\right) - \\frac{\\Delta t}{2} \\left( \\mathbf{r}_n + \\left[ \\mathbf{r}_n + \\Delta t \\dot{\\mathbf{r}}_n + \\frac{(\\Delta t)^2}{2} \\ddot{\\mathbf{r}}_n \\right] \\right) + \\mathcal{O}((\\Delta t)^4)\n$$\n$$\n\\boldsymbol{\\tau}^{n+1} = \\left( M \\Delta t \\dot{\\mathbf{u}}_n + M \\frac{(\\Delta t)^2}{2} \\ddot{\\mathbf{u}}_n + M \\frac{(\\Delta t)^3}{6} \\dddot{\\mathbf{u}}_n \\right) - \\left( \\Delta t \\mathbf{r}_n + \\frac{(\\Delta t)^2}{2} \\dot{\\mathbf{r}}_n + \\frac{(\\Delta t)^3}{4} \\ddot{\\mathbf{r}}_n \\right) + \\mathcal{O}((\\Delta t)^4)\n$$\nThe exact solution satisfies the original ODE, $M \\dot{\\mathbf{u}}(t) = \\mathbf{r}(\\mathbf{u}(t))$, at all times. Since $M$ is time-independent, we can differentiate this relation with respect to time to get:\n$M \\ddot{\\mathbf{u}}(t) = \\dot{\\mathbf{r}}(t)$\n$M \\dddot{\\mathbf{u}}(t) = \\ddot{\\mathbf{r}}(t)$\nSubstituting these relationships at $t=t_n$ into the expression for $\\boldsymbol{\\tau}^{n+1}$:\n$$\n\\boldsymbol{\\tau}^{n+1} = \\left( \\Delta t \\mathbf{r}_n + \\frac{(\\Delta t)^2}{2} \\dot{\\mathbf{r}}_n + \\frac{(\\Delta t)^3}{6} \\ddot{\\mathbf{r}}_n \\right) - \\left( \\Delta t \\mathbf{r}_n + \\frac{(\\Delta t)^2}{2} \\dot{\\mathbf{r}}_n + \\frac{(\\Delta t)^3}{4} \\ddot{\\mathbf{r}}_n \\right) + \\mathcal{O}((\\Delta t)^4)\n$$\nThe terms of order $\\Delta t$ and $(\\Delta t)^2$ cancel out. The leading non-zero term is of order $(\\Delta t)^3$:\n$$\n\\boldsymbol{\\tau}^{n+1} = \\left( \\frac{1}{6} - \\frac{1}{4} \\right) (\\Delta t)^3 \\ddot{\\mathbf{r}}_n + \\mathcal{O}((\\Delta t)^4) = -\\frac{(\\Delta t)^3}{12} \\ddot{\\mathbf{r}}_n + \\mathcal{O}((\\Delta t)^4)\n$$\nThe local truncation error is typically defined as the defect per unit time, $\\boldsymbol{\\tau}^{n+1} / \\Delta t$. The leading term of the LTE is therefore of order $(\\Delta t)^2$. A method with an LTE of order $\\mathcal{O}((\\Delta t)^p)$ is said to be a method of order $p$. Thus, the trapezoidal rule method is of order $2$ in time.\n\n### Task 3: Stability Analysis and Stiff-Limit Amplification Factor\n\nWe consider the linear stiff model problem where $M = I$ (the identity matrix) and $\\mathbf{r}(\\mathbf{u}) = A \\mathbf{u}$. The ODE system becomes $\\dot{\\mathbf{u}} = A \\mathbf{u}$.\nSubstituting these into the discrete scheme from Task $1$:\n$$\nI(\\mathbf{u}^{n+1} - \\mathbf{u}^n) = \\frac{\\Delta t}{2} \\left( A\\mathbf{u}^n + A\\mathbf{u}^{n+1} \\right)\n$$\nRearranging to solve for $\\mathbf{u}^{n+1}$:\n$$\n\\mathbf{u}^{n+1} - \\frac{\\Delta t}{2} A\\mathbf{u}^{n+1} = \\mathbf{u}^n + \\frac{\\Delta t}{2} A\\mathbf{u}^n\n$$\n$$\n\\left(I - \\frac{\\Delta t}{2} A\\right) \\mathbf{u}^{n+1} = \\left(I + \\frac{\\Delta t}{2} A\\right) \\mathbf{u}^n\n$$\nThe stability analysis can be performed by examining the scalar test equation $\\dot{u} = \\lambda u$, where $\\lambda \\in \\mathbb{C}$ with $\\operatorname{Re}(\\lambda) < 0$. This corresponds to setting $A = \\lambda$ and $\\mathbf{u} = u$. The discrete scheme becomes:\n$$\n\\left(1 - \\frac{\\lambda \\Delta t}{2}\\right) u^{n+1} = \\left(1 + \\frac{\\lambda \\Delta t}{2}\\right) u^n\n$$\nThe scalar amplification factor, $R(z)$, is defined by $u^{n+1} = R(z) u^n$, where $z = \\lambda \\Delta t$. From the equation above, we find:\n$$\nR(z) = \\frac{1 + z/2}{1 - z/2}\n$$\nA method is A-stable if its stability region includes the entire left half of the complex plane, i.e., $|R(z)| \\le 1$ for all $z \\in \\mathbb{C}$ with $\\operatorname{Re}(z) \\le 0$. Let $z = x + iy$ where $x = \\operatorname{Re}(z) \\le 0$:\n$$\n|R(z)|^2 = \\left| \\frac{1 + (x+iy)/2}{1 - (x+iy)/2} \\right|^2 = \\frac{|(1+x/2) + i(y/2)|^2}{|(1-x/2) - i(y/2)|^2} = \\frac{(1+x/2)^2 + (y/2)^2}{(1-x/2)^2 + (y/2)^2}\n$$\nThe condition $|R(z)|^2 \\le 1$ is equivalent to $(1+x/2)^2 \\le (1-x/2)^2$, which simplifies to $1+x \\le 1-x$, or $2x \\le 0$, or $x \\le 0$. This is precisely the condition $\\operatorname{Re}(z) \\le 0$. Thus, the method is A-stable.\n\nA method is L-stable if it is A-stable and additionally satisfies $\\lim_{|z| \\to \\infty, \\operatorname{Re}(z) < 0} |R(z)| = 0$. We typically check the limit as $z \\to -\\infty$ along the real axis.\n$$\n\\lim_{z \\to -\\infty} R(z) = \\lim_{z \\to -\\infty} \\frac{1 + z/2}{1 - z/2}\n$$\nDividing the numerator and denominator by $z$:\n$$\n\\lim_{z \\to -\\infty} \\frac{1/z + 1/2}{1/z - 1/2} = \\frac{0 + 1/2}{0 - 1/2} = -1\n$$\nSince this limit is $-1$ and not $0$, the method is not L-stable. The implication is that for very stiff components of the solution (corresponding to eigenvalues $\\lambda$ with large negative real parts, so $z \\to -\\infty$), the numerical solution does not decay; instead, its sign flips at each time step, i.e., $u^{n+1} \\approx -u^n$. This leads to persistent, non-physical high-frequency oscillations known as parasitic oscillations. L-stable methods, such as backward Euler for which $R(z) \\to 0$, are preferred for problems where strong damping of stiff components is desired.\n\nThe final task is to compute the stiff-limit amplification factor, which is the limit calculated above.\n$$\n\\lim_{z \\to -\\infty} R(z) = -1\n$$",
            "answer": "$$\\boxed{-1}$$"
        },
        {
            "introduction": "No single numerical scheme is perfect for all situations; choosing the right one involves understanding critical trade-offs. This practice  delves into this by comparing the Crank-Nicolson and backward Euler methods for a simple wave problem. You will derive and analyze their amplitude and phase errors, which directly correspond to the concepts of numerical dissipation and dispersion—properties that have profound implications for the simulation of phenomena like turbulence.",
            "id": "3316984",
            "problem": "Consider the linear wave equation on a periodic domain, $u_{t} + c\\,u_{x} = 0$, with constant wave speed $c > 0$. Let the spatial derivative be semi-discretized by a skew-symmetric linear operator that is consistent with $\\partial_{x}$, so that for a single Fourier mode with wavenumber $k$, the semi-discrete evolution of its complex amplitude $\\hat{u}(t)$ is governed by the ordinary differential equation\n$$\n\\frac{d\\hat{u}}{dt} = i\\,\\omega\\,\\hat{u},\\quad \\omega = c\\,\\tilde{k},\\quad \\omega > 0,\n$$\nwhere $\\tilde{k}$ is the discrete wavenumber associated with the chosen spatial discretization. Denote the uniform time step by $\\Delta t$ and the dimensionless parameter $z = \\omega\\,\\Delta t$.\n\nApply the backward Euler method and the Crank–Nicolson method to the semi-discrete ordinary differential equation and define, for each method, the one-step amplification factor $g$ by $\\hat{u}^{n+1} = g\\,\\hat{u}^{n}$. For each method:\n- Derive $g$ in closed form as a function of $z$.\n- Define the one-step amplitude error as $|g| - 1$ (relative to the exact solution’s amplitude, which is constant in time for purely imaginary $\\omega$).\n- Define the one-step phase error (in radians) as $\\arg(g) - \\omega\\,\\Delta t$, where $\\arg(g)$ is the principal argument of the complex number $g$.\n- Obtain the leading-order small-$z$ asymptotic expansion of the amplitude error up to and including terms of order $z^{2}$, and the phase error up to and including terms of order $z^{3}$.\n\nThen, using these expansions, compute the ratio of the magnitudes of the leading-order phase error coefficients of backward Euler to Crank–Nicolson (that is, the ratio of the absolute values of the coefficients multiplying $z^{3}$ in the leading-order phase error expansions). Report this ratio as a single real number. Use radians for all phase quantities. No rounding is required.\n\nFinally, explain, based on your derivations, the implications of the amplitude and phase behaviors of these time-stepping strategies for under-resolved turbulence in computational fluid dynamics, explicitly addressing the roles of numerical dissipation and dispersion introduced by time integration in the presence of skew-symmetric spatial operators.",
            "solution": "The linear wave equation $u_{t} + c\\,u_{x} = 0$ on a periodic domain can be expressed in Fourier space. For a single Fourier mode with wavenumber $k$, $u(x,t) = \\hat{u}(t)\\,\\exp(i k x)$, and a skew-symmetric semi-discrete spatial operator (for example, a spectral derivative or centered difference on a periodic grid) maps this mode to a purely imaginary eigenvalue. Therefore the semi-discrete evolution equation for the mode amplitude is\n$$\n\\frac{d\\hat{u}}{dt} = i\\,\\omega\\,\\hat{u},\\quad \\omega = c\\,\\tilde{k},\\quad \\omega > 0.\n$$\nThe exact solution over one time step $\\Delta t$ is $\\hat{u}(t+\\Delta t) = \\exp(i \\omega \\Delta t)\\,\\hat{u}(t)$, which has unit modulus and accumulates phase $\\omega \\Delta t$.\n\nWe analyze backward Euler and Crank–Nicolson applied to $\\frac{d\\hat{u}}{dt} = i\\,\\omega\\,\\hat{u}$.\n\nBackward Euler is defined by\n$$\n\\hat{u}^{n+1} = \\hat{u}^{n} + \\Delta t\\, i\\,\\omega\\,\\hat{u}^{n+1}.\n$$\nSolving for the amplification factor $g_{\\mathrm{BE}}$ gives\n$$\n\\hat{u}^{n+1}\\left(1 - i\\,\\omega\\,\\Delta t\\right) = \\hat{u}^{n}\\quad\\Rightarrow\\quad g_{\\mathrm{BE}} = \\frac{\\hat{u}^{n+1}}{\\hat{u}^{n}} = \\frac{1}{1 - i z},\\quad z = \\omega\\,\\Delta t.\n$$\nIts modulus and argument are\n$$\n|g_{\\mathrm{BE}}| = \\frac{1}{\\sqrt{1 + z^{2}}},\\qquad \\arg(g_{\\mathrm{BE}}) = \\arctan(z).\n$$\nThe one-step amplitude error is\n$$\n|g_{\\mathrm{BE}}| - 1 = \\frac{1}{\\sqrt{1 + z^{2}}} - 1.\n$$\nFor small $z$, using $(1 + z^{2})^{-1/2} = 1 - \\frac{1}{2} z^{2} + \\frac{3}{8} z^{4} + \\mathcal{O}(z^{6})$, we obtain\n$$\n|g_{\\mathrm{BE}}| - 1 = -\\frac{1}{2} z^{2} + \\frac{3}{8} z^{4} + \\mathcal{O}(z^{6}).\n$$\nThe one-step phase error in radians is\n$$\n\\text{Phase error}_{\\mathrm{BE}} = \\arg(g_{\\mathrm{BE}}) - \\omega\\,\\Delta t = \\arctan(z) - z.\n$$\nUsing $\\arctan(z) = z - \\frac{1}{3} z^{3} + \\frac{1}{5} z^{5} + \\mathcal{O}(z^{7})$, the leading-order phase error is\n$$\n\\text{Phase error}_{\\mathrm{BE}} = -\\frac{1}{3} z^{3} + \\frac{1}{5} z^{5} + \\mathcal{O}(z^{7}).\n$$\n\nCrank–Nicolson is defined by\n$$\n\\hat{u}^{n+1} = \\hat{u}^{n} + \\Delta t\\, i\\,\\omega\\,\\frac{\\hat{u}^{n+1} + \\hat{u}^{n}}{2}.\n$$\nSolving for $g_{\\mathrm{CN}}$ gives\n$$\n\\hat{u}^{n+1}\\left(1 - i\\,\\frac{z}{2}\\right) = \\hat{u}^{n}\\left(1 + i\\,\\frac{z}{2}\\right)\\quad\\Rightarrow\\quad g_{\\mathrm{CN}} = \\frac{1 + i\\,\\frac{z}{2}}{1 - i\\,\\frac{z}{2}}.\n$$\nIts modulus is\n$$\n|g_{\\mathrm{CN}}| = \\frac{\\sqrt{1 + \\left(\\frac{z}{2}\\right)^{2}}}{\\sqrt{1 + \\left(\\frac{z}{2}\\right)^{2}}} = 1,\n$$\nso the one-step amplitude error is identically zero:\n$$\n|g_{\\mathrm{CN}}| - 1 = 0.\n$$\nThe argument of $g_{\\mathrm{CN}}$ is the difference of the arguments of numerator and denominator:\n$$\n\\arg\\!\\left(1 + i\\,\\frac{z}{2}\\right) = \\arctan\\!\\left(\\frac{z}{2}\\right),\\qquad \\arg\\!\\left(1 - i\\,\\frac{z}{2}\\right) = -\\arctan\\!\\left(\\frac{z}{2}\\right),\n$$\nhence\n$$\n\\arg(g_{\\mathrm{CN}}) = 2\\,\\arctan\\!\\left(\\frac{z}{2}\\right).\n$$\nThe one-step phase error in radians is\n$$\n\\text{Phase error}_{\\mathrm{CN}} = 2\\,\\arctan\\!\\left(\\frac{z}{2}\\right) - z.\n$$\nUsing the series $\\arctan(\\xi) = \\xi - \\frac{1}{3}\\xi^{3} + \\frac{1}{5}\\xi^{5} + \\mathcal{O}(\\xi^{7})$ with $\\xi = z/2$, we obtain\n$$\n2\\,\\arctan\\!\\left(\\frac{z}{2}\\right) = 2\\left(\\frac{z}{2} - \\frac{1}{3}\\left(\\frac{z}{2}\\right)^{3} + \\frac{1}{5}\\left(\\frac{z}{2}\\right)^{5} + \\mathcal{O}(z^{7})\\right) = z - \\frac{1}{12} z^{3} + \\frac{1}{80} z^{5} + \\mathcal{O}(z^{7}),\n$$\nso\n$$\n\\text{Phase error}_{\\mathrm{CN}} = -\\frac{1}{12} z^{3} + \\frac{1}{80} z^{5} + \\mathcal{O}(z^{7}).\n$$\n\nWe now compute the ratio of the magnitudes of the leading-order phase error coefficients (the coefficients multiplying $z^{3}$):\n- For backward Euler, the magnitude is $\\left|\\,-\\frac{1}{3}\\,\\right| = \\frac{1}{3}$.\n- For Crank–Nicolson, the magnitude is $\\left|\\,-\\frac{1}{12}\\,\\right| = \\frac{1}{12}$.\nTherefore the requested ratio is\n$$\n\\frac{\\frac{1}{3}}{\\frac{1}{12}} = 4.\n$$\n\nImplications for under-resolved turbulence in computational fluid dynamics follow from these amplitude and phase behaviors. The semi-discrete linearized dynamics of advective terms are skew-symmetric, corresponding to purely imaginary eigenvalues. In this setting, Crank–Nicolson introduces no amplitude damping ($|g_{\\mathrm{CN}}| = 1$), preserving the norm of such linear modes while exhibiting a comparatively small dispersive phase error of order $z^{3}$ with coefficient $-\\frac{1}{12}$. Backward Euler introduces unconditional amplitude damping ($|g_{\\mathrm{BE}}| < 1$) with leading-order deficit $-\\frac{1}{2} z^{2}$ and a larger dispersive phase error with coefficient $-\\frac{1}{3}$. For under-resolved turbulence, where small scales cannot be accurately represented by the grid, time-integration-induced dissipation can act as an implicit subgrid regularization. Backward Euler’s time-step-dependent damping preferentially attenuates high-frequency content, analogous to Implicit Large Eddy Simulation (ILES), but at the cost of increased dispersion error and potential overdamping of dynamically relevant near-grid scales. Crank–Nicolson, being non-dissipative for skew-symmetric linear dynamics, preserves energy of these components and has smaller phase error, which is beneficial for accurately propagating waves and vortical structures; however, in the presence of nonlinear interactions, aliasing, and non-normal effects, the absence of time-stepping dissipation can permit energy accumulation at unresolved scales unless complemented by spatial filtering, dealiasing, or explicit subgrid modeling. Consequently, the choice between these strategies involves a trade-off: backward Euler provides robustness via dissipation but distorts both amplitude and phase more strongly; Crank–Nicolson maintains amplitude fidelity and lower dispersion for linear waves, but relies on other mechanisms to control under-resolved dynamics.",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "The theoretical guarantee of \"unconditional stability\" for implicit methods is powerful, but it relies on an often-unspoken assumption: that the resulting algebraic equations are solved exactly. This advanced exercise  challenges this idealization by exploring what happens when an iterative solver only finds an approximate solution. By constructing a formal counterexample, you will discover the critical link between solver tolerance, time step size, and the physical properties of the system, revealing how a theoretically stable method can be driven to instability in practice.",
            "id": "3316997",
            "problem": "Consider the initial value problem for a scalar ordinary differential equation in computational fluid dynamics: $y'(t) = f(y(t))$ with $y(0) = y_0$, where $f$ is globally Lipschitz continuous with Lipschitz constant $L > 0$, meaning $|f(y) - f(z)| \\le L |y - z|$ for all $y$ and $z$. A widely used A-stable one-step implicit method is the backward (implicit) Euler scheme, defined for a time step size $\\Delta t > 0$ by the nonlinear equation\n$$\ny_{n+1} = y_n + \\Delta t\\, f(y_{n+1}),\n$$\nwhich must be solved for $y_{n+1}$ at each step $n$. In practice, the implicit equation is often solved using an iterative linear or nonlinear solver that terminates when a prescribed residual tolerance is met. Let the computed iterate $y_{n+1}^{\\text{(approx)}}$ satisfy a residual condition\n$$\nr_n := y_{n+1}^{\\text{(approx)}} - y_n - \\Delta t\\, f\\!\\left(y_{n+1}^{\\text{(approx)}}\\right),\n$$\nwith a relative tolerance $|r_n| \\le \\zeta\\, |y_n|$ for some $\\zeta \\ge 0$ (dimensionless). Assume the worst-case alignment of the residual with $y_n$ that maximizes growth in the computed solution.\n\nThe task is to formally derive, from first principles, a counterexample that demonstrates loss of unconditional stability in an A-stable implicit method due to an inexact linear/nonlinear solve, and to quantify the tolerance threshold in terms of $\\Delta t$ and $L$. Use the linear test equation $f(y) = -L y$, with $L > 0$, so that the exact implicit Euler update solves\n$$\n(1 + \\Delta t\\, L)\\, y_{n+1} = y_n.\n$$\nWith an inexact solve obeying $|r_n| \\le \\zeta\\, |y_n|$, where $r_n$ is chosen to be aligned with $y_n$ to maximize growth, show that the effective amplification factor is modified and derive the threshold on $\\zeta$ such that the computed iterates $y_n$ diverge. Conclude the precise inequality relating $\\zeta$, $\\Delta t$, and $L$ that separates contraction, neutral behavior, and divergence.\n\nThen implement a program that, for a specified test suite, computes for each case:\n- the threshold $\\zeta_{\\text{th}} = \\Delta t\\, L$,\n- the effective amplification factor $g_{\\text{eff}}$, and\n- whether the numerical sequence diverges under the worst-case residual alignment.\n\nUse the following test suite, which is designed to cover a stable case, a neutral boundary case, divergent cases, and sensitivity at small step sizes. All quantities are unitless. For each case, the program should evolve $N$ steps starting from $y_0$ using the worst-case inexact implicit Euler recurrence derived in the solution section and report the resulting $y_N$:\n1. $(L, \\Delta t, \\zeta, N, y_0) = (10.0, 0.01, 0.05, 50, 1.0)$,\n2. $(L, \\Delta t, \\zeta, N, y_0) = (10.0, 0.01, 0.10, 50, 1.0)$,\n3. $(L, \\Delta t, \\zeta, N, y_0) = (10.0, 0.01, 0.20, 50, 1.0)$,\n4. $(L, \\Delta t, \\zeta, N, y_0) = (1.0, 1.0, 1.01, 50, 1.0)$,\n5. $(L, \\Delta t, \\zeta, N, y_0) = (100.0, 10^{-4}, 0.011, 50, 1.0)$.\n\nFor each test case, the output must be a list of the form $[\\zeta_{\\text{th}}, g_{\\text{eff}}, d, y_N]$ where $d$ is an integer indicator ($1$ if the sequence diverges under worst-case residual alignment, $0$ otherwise). Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each test case’s list in the same order as above and floats rounded to six decimal places, for example, $[[\\cdots],[\\cdots],\\ldots]$.",
            "solution": "The problem requires an analysis of the stability of the backward (implicit) Euler method when the resulting nonlinear algebraic equation is solved inexactly at each time step. We are tasked with deriving a condition that demonstrates a loss of unconditional stability for an A-stable method due to this inexactness and quantifying the threshold for the solution tolerance.\n\nLet's begin by formalizing the problem setup. We are given a scalar ordinary differential equation (ODE) $y'(t) = f(y(t))$ with an initial condition $y(0) = y_0$. The function $f$ is Lipschitz continuous with constant $L > 0$. The backward Euler method discretizes this ODE as:\n$$\n\\frac{y_{n+1} - y_n}{\\Delta t} = f(y_{n+1})\n$$\nwhere $y_n$ is the numerical approximation to $y(n\\Delta t)$ and $\\Delta t$ is the time step size. This can be rewritten as the equation to be solved for $y_{n+1}$:\n$$\ny_{n+1} - y_n - \\Delta t f(y_{n+1}) = 0\n$$\nThe problem states that this equation is solved inexactly. Let the computed solution be denoted $y_{n+1}^{\\text{(approx)}}$. For simplicity, as is common in such analyses, we will drop the superscript and let $y_{n+1}$ represent this computed, inexact value. The inexactness is characterized by a non-zero residual, $r_n$:\n$$\nr_n := y_{n+1} - y_n - \\Delta t f(y_{n+1})\n$$\nThis residual is bounded by a relative tolerance condition:\n$$\n|r_n| \\le \\zeta |y_n|\n$$\nwhere $\\zeta \\ge 0$ is a dimensionless tolerance parameter.\n\nTo analyze stability, we use the standard linear test equation $f(y) = \\lambda y$. For the problem at hand, we are given $f(y) = -L y$, where $L > 0$ is the Lipschitz constant. This corresponds to $\\lambda = -L$, a real and negative value, for which the backward Euler method is known to be A-stable (and L-stable), meaning the exact numerical solution should decay for any choice of $\\Delta t > 0$.\n\nSubstituting $f(y_{n+1}) = -L y_{n+1}$ into the residual definition gives:\n$$\nr_n = y_{n+1} - y_n - \\Delta t (-L y_{n+1})\n$$\n$$\nr_n = y_{n+1} (1 + \\Delta t L) - y_n\n$$\nWe can rearrange this equation to express the next iterate, $y_{n+1}$, in terms of the current iterate, $y_n$, and the residual, $r_n$:\n$$\ny_{n+1} (1 + \\Delta t L) = y_n + r_n\n$$\n$$\ny_{n+1} = \\frac{y_n + r_n}{1 + \\Delta t L}\n$$\nThis equation shows how the solution evolves from one step to the next under the influence of the numerical scheme and the inexact solve residual.\n\nThe problem asks us to consider the \"worst-case alignment\" of the residual that maximizes the growth of the computed solution. The magnitude of the next iterate is $|y_{n+1}| = \\frac{|y_n + r_n|}{|1 + \\Delta t L|}$. Since $L > 0$ and $\\Delta t > 0$, the denominator $1 + \\Delta t L$ is always positive. To maximize $|y_{n+1}|$, we must maximize the numerator $|y_n + r_n|$. The residual $r_n$ is constrained by $|r_n| \\le \\zeta |y_n|$. The value of $|y_n + r_n|$ is maximized when $r_n$ is real and has the same sign as $y_n$. Therefore, the worst-case choice for the residual is $r_n = \\zeta y_n$ (if $y_n > 0$, $r_n = \\zeta y_n$; if $y_n < 0$, $r_n = \\zeta y_n = -\\zeta|y_n|$). This choice saturates the tolerance bound and aligns the residual to cause maximum amplification.\n\nSubstituting this worst-case residual $r_n = \\zeta y_n$ into the recurrence relation for $y_{n+1}$:\n$$\ny_{n+1} = \\frac{y_n + \\zeta y_n}{1 + \\Delta t L} = \\frac{(1 + \\zeta) y_n}{1 + \\Delta t L}\n$$\nThis gives us a linear recurrence relation of the form $y_{n+1} = g_{\\text{eff}} y_n$, where $g_{\\text{eff}}$ is the effective amplification factor:\n$$\ng_{\\text{eff}} = \\frac{1 + \\zeta}{1 + \\Delta t L}\n$$\nThe numerical solution sequence $y_n$ is stable (contracts) if $|g_{\\text{eff}}| < 1$, is neutral if $|g_{\\text{eff}}| = 1$, and is unstable (diverges) if $|g_{\\text{eff}}| > 1$.\n\nSince $\\zeta \\ge 0$, $L > 0$, and $\\Delta t > 0$, the numerator $1 + \\zeta$ and the denominator $1 + \\Delta t L$ are both greater than or equal to $1$. Thus, $g_{\\text{eff}}$ is always positive, and we can drop the absolute value sign in the stability analysis.\n\nThe condition for divergence is $g_{\\text{eff}} > 1$:\n$$\n\\frac{1 + \\zeta}{1 + \\Delta t L} > 1\n$$\nMultiplying by the positive denominator $1 + \\Delta t L$:\n$$\n1 + \\zeta > 1 + \\Delta t L\n$$\n$$\n\\zeta > \\Delta t L\n$$\nThis inequality provides a counterexample to the unconditional stability of the backward Euler method. Even though the method is A-stable when solved exactly, an inexact solve can induce instability if the relative residual tolerance $\\zeta$ is larger than the product of the time step size $\\Delta t$ and the system's characteristic frequency (represented by $L$).\n\nThe threshold tolerance, $\\zeta_{\\text{th}}$, that separates contraction from divergence is the point where the amplification factor is exactly $1$:\n$$\n\\zeta_{\\text{th}} = \\Delta t L\n$$\nWe can summarize the behavior based on the relationship between $\\zeta$ and this threshold:\n- If $\\zeta < \\Delta t L$, then $g_{\\text{eff}} < 1$ and the solution contracts (stable).\n- If $\\zeta = \\Delta t L$, then $g_{\\text{eff}} = 1$ and the solution is neutral (constant magnitude).\n- If $\\zeta > \\Delta t L$, then $g_{\\text{eff}} > 1$ and the solution diverges (unstable).\n\nThe program will implement these findings. For each test case $(L, \\Delta t, \\zeta, N, y_0)$, we calculate:\n1. The threshold tolerance: $\\zeta_{\\text{th}} = \\Delta t L$.\n2. The effective amplification factor: $g_{\\text{eff}} = (1 + \\zeta) / (1 + \\Delta t L)$.\n3. The divergence indicator $d$: $d=1$ if $\\zeta > \\zeta_{\\text{th}}$, and $d=0$ otherwise.\n4. The final value after $N$ steps: $y_N = y_0 \\cdot (g_{\\text{eff}})^N$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the stability properties and final solution value for an inexact\n    implicit Euler method applied to the linear test equation y' = -Ly.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (L, Delta_t, zeta, N, y0)\n        (10.0, 0.01, 0.05, 50, 1.0),\n        (10.0, 0.01, 0.10, 50, 1.0),\n        (10.0, 0.01, 0.20, 50, 1.0),\n        (1.0, 1.0, 1.01, 50, 1.0),\n        (100.0, 1e-4, 0.011, 50, 1.0),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        L, delta_t, zeta, N, y0 = case\n\n        # 1. Calculate the stability threshold zeta_th\n        zeta_th = delta_t * L\n\n        # 2. Calculate the effective amplification factor g_eff\n        g_eff = (1.0 + zeta) / (1.0 + delta_t * L)\n\n        # 3. Determine the divergence indicator d\n        # Divergence occurs for zeta > delta_t * L, which is equivalent to g_eff > 1.\n        # The problem defines divergence for a strict inequality.\n        d = 1 if zeta > zeta_th else 0\n\n        # 4. Calculate y_N using the derived recurrence y_{n+1} = g_eff * y_n\n        # This is a geometric progression: y_N = y0 * (g_eff)^N\n        y_N = y0 * (g_eff ** N)\n        \n        # Store results for this case\n        case_results = [zeta_th, g_eff, d, y_N]\n        all_results.append(case_results)\n\n    # Format the final output string as a list of lists.\n    # Each float must be rounded to six decimal places.\n    formatted_results = []\n    for res in all_results:\n        zeta_th_str = f\"{res[0]:.6f}\"\n        g_eff_str = f\"{res[1]:.6f}\"\n        d_str = str(res[2])\n        y_N_str = f\"{res[3]:.6f}\"\n        formatted_results.append(f\"[{zeta_th_str},{g_eff_str},{d_str},{y_N_str}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}