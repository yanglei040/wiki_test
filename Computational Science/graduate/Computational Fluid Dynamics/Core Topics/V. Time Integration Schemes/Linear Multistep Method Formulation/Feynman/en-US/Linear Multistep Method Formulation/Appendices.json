{
    "hands_on_practices": [
        {
            "introduction": "The fundamental goal in designing a linear multistep method is to select its coefficients to achieve the highest possible order of accuracy for a given number of steps. This exercise provides a direct, hands-on experience in this core design process, starting from first principles. By systematically applying Taylor series expansions to the general form of a linear multistep method, you will derive the set of 'order conditions' and solve for the coefficients that maximize performance, making the abstract theory of numerical accuracy a concrete and practical task. ",
            "id": "3340816",
            "problem": "Consider a semi-discrete formulation of a conservation law arising in computational fluid dynamics where spatial discretization yields an autonomous system of ordinary differential equations of the form $y'(t) = f(t,y(t))$ for $y(t) \\in \\mathbb{R}^{m}$. You wish to advance the solution in time with a linear multistep method of $k=3$ steps written in backward-indexed form\n$$\n\\sum_{j=0}^{3} \\alpha_{j}\\, y_{n-j} \\;=\\; h \\sum_{j=0}^{3} \\beta_{j}\\, f_{n-j},\n$$\nwhere $t_{n} = t_{0} + n h$, $y_{n} \\approx y(t_{n})$, $f_{n-j} = f(t_{n-j}, y_{n-j})$, and $h>0$ is the time step. You are given a candidate explicit 3-step method with coefficients\n$$\n\\alpha = ( \\alpha_{0}, \\alpha_{1}, \\alpha_{2}, \\alpha_{3} ) = (1,\\,-1,\\,0,\\,0), \\qquad \\beta = ( \\beta_{0}, \\beta_{1}, \\beta_{2}, \\beta_{3} ) = (0,\\,\\beta_{1},\\,\\beta_{2},\\,\\beta_{3}).\n$$\nBy “explicit” it is meant that $\\beta_{0} = 0$, so the right-hand side does not depend on $f_{n} = f(t_{n},y_{n})$ at the new time level. Starting from the definition of the local truncation error and the Taylor expansion about $t_{n}$, determine $\\beta_{1}$, $\\beta_{2}$, and $\\beta_{3}$ so that the algebraic order is maximized, and then verify the achieved order by deriving the leading term of the local truncation error. Express your final values of $\\beta_{1}$, $\\beta_{2}$, and $\\beta_{3}$ in exact rational form. No rounding is required. The final answer must be the triplet $(\\beta_{1}, \\beta_{2}, \\beta_{3})$.",
            "solution": "We start from the autonomous ordinary differential equation $y'(t) = f(t,y(t))$ and the backward-indexed linear multistep method\n$$\n\\sum_{j=0}^{3} \\alpha_{j} y_{n-j} \\;=\\; h \\sum_{j=0}^{3} \\beta_{j} f_{n-j}.\n$$\nWith the given coefficients $\\alpha = (1,-1,0,0)$ and $\\beta = (0,\\beta_{1},\\beta_{2},\\beta_{3})$, the scheme reads\n$$\ny_{n} - y_{n-1} \\;=\\; h\\left(\\beta_{1} f_{n-1} + \\beta_{2} f_{n-2} + \\beta_{3} f_{n-3}\\right).\n$$\nTo maximize the algebraic order, we enforce exactness when the exact solution is substituted, expanded in Taylor series about $t_{n}$. Let $y(t)$ be sufficiently smooth. Using Taylor expansions about $t_{n}$,\n$$\ny(t_{n-1}) = y(t_{n} - h) = y(t_{n}) - h y'(t_{n}) + \\frac{h^{2}}{2} y''(t_{n}) - \\frac{h^{3}}{6} y'''(t_{n}) + \\frac{h^{4}}{24} y^{(4)}(t_{n}) - \\frac{h^{5}}{120} y^{(5)}(t_{n}) + \\cdots,\n$$\nhence\n$$\ny_{n} - y_{n-1} = h y'(t_{n}) - \\frac{h^{2}}{2} y''(t_{n}) + \\frac{h^{3}}{6} y'''(t_{n}) - \\frac{h^{4}}{24} y^{(4)}(t_{n}) + \\frac{h^{5}}{120} y^{(5)}(t_{n}) + \\cdots.\n$$\nOn the right-hand side, we use $f_{n-j} = y'(t_{n-j})$ and expand\n$$\ny'(t_{n-j}) = y'(t_{n}) - j h\\, y''(t_{n}) + \\frac{(j h)^{2}}{2} y'''(t_{n}) - \\frac{(j h)^{3}}{6} y^{(4)}(t_{n}) + \\frac{(j h)^{4}}{24} y^{(5)}(t_{n}) + \\cdots.\n$$\nTherefore,\n$$\n\\begin{aligned}\nh \\sum_{j=1}^{3} \\beta_{j} y'(t_{n-j})\n&= h\\Bigg[\\left(\\sum_{j=1}^{3} \\beta_{j}\\right) y'(t_{n})\n- h\\left(\\sum_{j=1}^{3} j \\beta_{j}\\right) y''(t_{n})\n+ \\frac{h^{2}}{2}\\left(\\sum_{j=1}^{3} j^{2} \\beta_{j}\\right) y'''(t_{n}) \\\\\n&\\qquad\\quad - \\frac{h^{3}}{6}\\left(\\sum_{j=1}^{3} j^{3} \\beta_{j}\\right) y^{(4)}(t_{n})\n+ \\frac{h^{4}}{24}\\left(\\sum_{j=1}^{3} j^{4} \\beta_{j}\\right) y^{(5)}(t_{n})\n+ \\cdots \\Bigg].\n\\end{aligned}\n$$\nTo achieve algebraic order $p$, the residual $R_{n}$ obtained by subtracting the right-hand side from the left-hand side must have its first nonvanishing term at order $h^{p+1}$. Equating like powers of $h$ up to the highest possible order yields the order conditions:\n$$\n\\begin{aligned}\nh\\,y':&\\quad 1 = \\sum_{j=1}^{3} \\beta_{j}, \\\\\nh^{2}\\,y'':&\\quad -\\frac{1}{2} = - \\sum_{j=1}^{3} j \\beta_{j} \\;\\;\\Longrightarrow\\;\\; \\sum_{j=1}^{3} j \\beta_{j} = \\frac{1}{2}, \\\\\nh^{3}\\,y''':&\\quad \\frac{1}{6} = \\frac{1}{2} \\sum_{j=1}^{3} j^{2} \\beta_{j} \\;\\;\\Longrightarrow\\;\\; \\sum_{j=1}^{3} j^{2} \\beta_{j} = \\frac{1}{3}, \\\\\nh^{4}\\,y^{(4)}:&\\quad -\\frac{1}{24} = -\\frac{1}{6} \\sum_{j=1}^{3} j^{3} \\beta_{j} \\;\\;\\Longrightarrow\\;\\; \\sum_{j=1}^{3} j^{3} \\beta_{j} = \\frac{1}{4},\n\\end{aligned}\n$$\nand so on. With the three unknowns $\\beta_{1}, \\beta_{2}, \\beta_{3}$, we can satisfy at most the first three equations. Writing these explicitly,\n$$\n\\begin{cases}\n\\beta_{1} + \\beta_{2} + \\beta_{3} = 1, \\\\\n\\beta_{1} + 2 \\beta_{2} + 3 \\beta_{3} = \\frac{1}{2}, \\\\\n\\beta_{1} + 4 \\beta_{2} + 9 \\beta_{3} = \\frac{1}{3}.\n\\end{cases}\n$$\nSubtracting the first from the second and the second from the third yields\n$$\n\\begin{cases}\n\\beta_{2} + 2 \\beta_{3} = -\\frac{1}{2}, \\\\\n2 \\beta_{2} + 6 \\beta_{3} = -\\frac{1}{6}.\n\\end{cases}\n$$\nSolving, from the first we get $\\beta_{2} = -\\frac{1}{2} - 2 \\beta_{3}$. Substituting into the second,\n$$\n2\\left(-\\frac{1}{2} - 2 \\beta_{3}\\right) + 6 \\beta_{3} = -\\frac{1}{6}\n\\;\\;\\Longrightarrow\\;\\;\n-1 - 4 \\beta_{3} + 6 \\beta_{3} = -\\frac{1}{6}\n\\;\\;\\Longrightarrow\\;\\;\n2 \\beta_{3} = \\frac{5}{6}\n\\;\\;\\Longrightarrow\\;\\;\n\\beta_{3} = \\frac{5}{12}.\n$$\nThen\n$$\n\\beta_{2} = -\\frac{1}{2} - 2\\cdot \\frac{5}{12} = -\\frac{1}{2} - \\frac{5}{6} = -\\frac{4}{3},\n$$\nand finally\n$$\n\\beta_{1} = 1 - \\beta_{2} - \\beta_{3} = 1 - \\left(-\\frac{4}{3}\\right) - \\frac{5}{12} = \\frac{23}{12}.\n$$\nThus the unique choice that maximizes the order is\n$$\n\\beta_{1} = \\frac{23}{12}, \\quad \\beta_{2} = -\\frac{4}{3}, \\quad \\beta_{3} = \\frac{5}{12}.\n$$\nTo verify the achieved order, we check the next condition at order $h^{4}$:\n$$\n\\sum_{j=1}^{3} j^{3} \\beta_{j} = 1^{3}\\cdot \\frac{23}{12} + 2^{3}\\cdot \\left(-\\frac{4}{3}\\right) + 3^{3}\\cdot \\frac{5}{12}\n= \\frac{23}{12} - \\frac{128}{12} + \\frac{135}{12} = \\frac{30}{12} = \\frac{5}{2} \\neq \\frac{1}{4}.\n$$\nTherefore the $h^{4}$ condition is not satisfied. The local truncation error residual at order $h^{4}$ is the difference of the coefficients multiplying $y^{(4)}(t_{n})$:\n$$\n\\left(-\\frac{1}{24}\\right) - \\left(-\\frac{1}{6}\\cdot \\frac{5}{2}\\right) = -\\frac{1}{24} + \\frac{5}{12} = \\frac{9}{24} = \\frac{3}{8}.\n$$\nHence the local truncation error is\n$$\n\\tau_{n} = \\frac{3}{8}\\, h^{4}\\, y^{(4)}(t_{n}) + \\mathcal{O}(h^{5}),\n$$\nwhich confirms algebraic order $p=3$. Finally, zero-stability holds because the homogeneous difference equation $y_{n} - y_{n-1} = 0$ has the simple root $1$ and additional roots at $0$ (inside the unit disk), satisfying the root condition, so the method indeed attains order $3$ with the computed coefficients.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{23}{12} & -\\frac{4}{3} & \\frac{5}{12}\\end{pmatrix}}$$"
        },
        {
            "introduction": "High-order methods are efficient, but their full potential in complex CFD simulations is unlocked through adaptive step-size control, which dynamically adjusts the step size $h$ to meet a prescribed error tolerance. This practice demonstrates a powerful technique for achieving adaptivity: the use of an 'embedded pair' of methods of different orders to produce an estimate of the local truncation error. You will construct such a pair and derive the logic for a step-size controller, bridging the gap between the theoretical formulation of a method and its implementation in a robust, practical algorithm. ",
            "id": "3340831",
            "problem": "Consider the method-of-lines semi-discretization of a convection–diffusion partial differential equation in computational fluid dynamics, resulting in a system of ordinary differential equations of the form $\\mathbf{y}'(t)=\\mathbf{f}(t,\\mathbf{y})$, where $\\mathbf{y}(t)\\in\\mathbb{R}^{m}$ and $\\mathbf{f}:\\mathbb{R}\\times\\mathbb{R}^{m}\\rightarrow\\mathbb{R}^{m}$ is sufficiently smooth. You seek an explicit Linear Multistep Method (LMM) of Adams–Bashforth (AB) type with an embedded pair for adaptive step-size control.\n\nStarting from the exact integral relation $\\,\\mathbf{y}(t_{n+1})=\\mathbf{y}(t_n)+\\displaystyle\\int_{t_n}^{t_{n+1}}\\mathbf{f}(t,\\mathbf{y}(t))\\,\\mathrm{d}t\\,$ and approximating $\\mathbf{f}(t,\\mathbf{y}(t))$ by its degree-$k-1$ Lagrange interpolating polynomial through the $k$ equidistant nodes $t_n,t_{n-1},\\dots,t_{n-k+1}$, construct the $k$-step Adams–Bashforth formula and specialize it to the case $k=4$ to obtain the coefficients for the $\\text{AB}4$ method. Similarly, construct the embedded $\\text{AB}3$ formula that uses the same function evaluations and yields a lower-order update at $t_{n+1}$.\n\nDefine the embedded pair outputs by $\\mathbf{y}_{n+1}^{[4]}$ and $\\mathbf{y}_{n+1}^{[3]}$, and use their difference to form an asymptotically consistent estimator of the local truncation error of the higher-order method. For this purpose, assume that the implementation multiplies $\\|\\mathbf{y}_{n+1}^{[4]}-\\mathbf{y}_{n+1}^{[3]}\\|$ by a known calibration factor so that the resulting scalar quantity $\\text{err}$ behaves like $C\\,h^{p+1}$ with $p=4$ for $\\text{AB}4$.\n\nDerive, from first principles, a step-size controller that chooses $h_{\\text{new}}$ so that the predicted local truncation error at the next step matches a user-specified tolerance $\\text{tol}$, and incorporate a multiplicative safety factor $s$ and lower/upper growth limiters $\\alpha_{\\min}$ and $\\alpha_{\\max}$ into your controller via clipping.\n\nFinally, evaluate your controller for the following numerical data:\n- $\\text{AB}4/\\text{AB}3$ embedded pair with $p=4$,\n- current step size $h=1.0\\times 10^{-3}$,\n- tolerance $\\text{tol}=1.0\\times 10^{-6}$,\n- calibrated error estimate $\\text{err}=3.0\\times 10^{-7}$,\n- safety factor $s=0.9$,\n- lower and upper growth limiters $\\alpha_{\\min}=0.5$ and $\\alpha_{\\max}=1.5$.\n\nReport the numerical value of $h_{\\text{new}}$ in standard scientific notation. Round your answer to four significant figures.",
            "solution": "The user has requested the derivation of an Adams-Bashforth Linear Multistep Method (LMM), the formulation of an associated adaptive step-size controller, and the evaluation of this controller for a specific set of numerical data.\n\nThe problem begins with the exact integral representation of the solution to the Ordinary Differential Equation (ODE) system $\\mathbf{y}'(t) = \\mathbf{f}(t, \\mathbf{y})$ over a single time step from $t_n$ to $t_{n+1}$:\n$$\n\\mathbf{y}(t_{n+1}) = \\mathbf{y}(t_n) + \\int_{t_n}^{t_{n+1}} \\mathbf{f}(t, \\mathbf{y}(t)) \\, \\mathrm{d}t\n$$\nAn explicit LMM of Adams-Bashforth (AB) type is derived by approximating the integrand $\\mathbf{f}(t, \\mathbf{y}(t))$ with a polynomial $P(t)$ that interpolates $k$ previously computed values of the function, $\\{ (t_n, \\mathbf{f}_n), (t_{n-1}, \\mathbf{f}_{n-1}), \\dots, (t_{n-k+1}, \\mathbf{f}_{n-k+1}) \\}$, where $\\mathbf{f}_j \\equiv \\mathbf{f}(t_j, \\mathbf{y}_j)$. The resulting numerical formula is:\n$$\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + \\int_{t_n}^{t_{n+1}} P(t) \\, \\mathrm{d}t\n$$\nTo facilitate the integration, we introduce a non-dimensional time variable $s = (t - t_n) / h$, where $h$ is the constant step size. It follows that $\\mathrm{d}t = h \\, \\mathrm{d}s$. The integration interval $[t_n, t_{n+1}]$ transforms to $[0, 1]$ in the $s$ variable. The interpolation nodes $t_{n-j}$ correspond to $s = -j$ for $j = 0, 1, \\dots, k-1$.\n\nThe $(k-1)$-degree Lagrange interpolating polynomial is given by $P(t_n+sh) = \\sum_{j=0}^{k-1} L_j(s) \\mathbf{f}_{n-j}$, where $L_j(s)$ are the Lagrange basis polynomials:\n$$\nL_j(s) = \\prod_{i=0, i \\neq j}^{k-1} \\frac{s - (-i)}{(-j) - (-i)}\n$$\nSubstituting this into the integral and performing the integration yields the general $k$-step AB formula:\n$$\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\sum_{j=0}^{k-1} b_j \\mathbf{f}_{n-j}, \\quad \\text{where} \\quad b_j = \\int_0^1 L_j(s) \\, \\mathrm{d}s\n$$\nFor the $4$-step Adams-Bashforth method (AB4, $k=4$), the interpolating polynomial is of degree $3$ and uses the points corresponding to $s=0, -1, -2, -3$. The coefficients $b_j$ are calculated as follows:\n$b_0 = \\int_0^1 \\frac{(s+1)(s+2)(s+3)}{(1)(2)(3)} \\, \\mathrm{d}s = \\frac{55}{24}$\n$b_1 = \\int_0^1 \\frac{s(s+2)(s+3)}{(-1)(1)(2)} \\, \\mathrm{d}s = -\\frac{59}{24}$\n$b_2 = \\int_0^1 \\frac{s(s+1)(s+3)}{(-2)(-1)(1)} \\, \\mathrm{d}s = \\frac{37}{24}$\n$b_3 = \\int_0^1 \\frac{s(s+1)(s+2)}{(-3)(-2)(-1)} \\, \\mathrm{d}s = -\\frac{9}{24}$\nThis gives the AB4 formula, denoted $\\mathbf{y}_{n+1}^{[4]}$, which is of order $p=4$:\n$$\n\\mathbf{y}_{n+1}^{[4]} = \\mathbf{y}_n + \\frac{h}{24} \\left( 55\\mathbf{f}_n - 59\\mathbf{f}_{n-1} + 37\\mathbf{f}_{n-2} - 9\\mathbf{f}_{n-3} \\right)\n$$\nFor the embedded $3$-step method (AB3, $k=3$), we use a polynomial of degree $2$ interpolating the points corresponding to $s=0, -1, -2$. This method is of order $p=3$. The formula, denoted $\\mathbf{y}_{n+1}^{[3]}$, is:\n$$\n\\mathbf{y}_{n+1}^{[3]} = \\mathbf{y}_n + \\frac{h}{12} \\left( 23\\mathbf{f}_n - 16\\mathbf{f}_{n-1} + 5\\mathbf{f}_{n-2} \\right)\n$$\nThe problem asks for the derivation of a step-size controller. The local truncation error (LTE) of a $p$-th order method is proportional to $h^{p+1}$. The problem states that a calibrated error estimate, $\\text{err}$, for the higher-order method (AB4, with $p=4$) is available. This estimate scales according to the relation:\n$$\n\\text{err} \\approx C h^{p+1} = C h^5\n$$\nwhere $C$ is a constant related to higher-order derivatives of the solution. Our goal is to determine a new step size, $h_{\\text{new}}$, such that the estimated error for the next step, $\\text{err}_{\\text{new}}$, matches a user-defined tolerance, $\\text{tol}$.\nAssuming the same asymptotic relationship holds for the new step, we can write:\n$$\n\\text{tol} \\approx \\text{err}_{\\text{new}} \\approx C h_{\\text{new}}^{p+1} = C h_{\\text{new}}^5\n$$\nBy taking the ratio of the tolerance equation to the current error equation, the unknown constant $C$ is eliminated:\n$$\n\\frac{\\text{tol}}{\\text{err}} \\approx \\frac{C h_{\\text{new}}^5}{C h^5} = \\left( \\frac{h_{\\text{new}}}{h} \\right)^5\n$$\nSolving for $h_{\\text{new}}$ gives the ideal step size:\n$$\nh_{\\text{new}} = h \\left( \\frac{\\text{tol}}{\\text{err}} \\right)^{1/5} = h \\left( \\frac{\\text{tol}}{\\text{err}} \\right)^{1/(p+1)}\n$$\nIn practice, a safety factor $s < 1$ is applied to this estimate to create a more conservative (smaller) step, reducing the likelihood of failed steps. The proposed change factor for the step size, $\\alpha_{\\text{prop}}$, is:\n$$\n\\alpha_{\\text{prop}} = s \\left( \\frac{\\text{tol}}{\\text{err}} \\right)^{1/(p+1)}\n$$\nTo prevent erratic changes in step size, this factor is clipped within a range $[\\alpha_{\\min}, \\alpha_{\\max}]$. The final factor, $\\alpha$, is determined by:\n$$\n\\alpha = \\max(\\alpha_{\\min}, \\min(\\alpha_{\\max}, \\alpha_{\\text{prop}}))\n$$\nThe new step size is then computed as $h_{\\text{new}} = \\alpha \\cdot h$.\n\nNow, we evaluate this controller using the provided numerical data:\n- Type of method: AB4/AB3, with the higher order being $p=4$.\n- Current step size: $h = 1.0 \\times 10^{-3}$.\n- Desired tolerance: $\\text{tol} = 1.0 \\times 10^{-6}$.\n- Calibrated error estimate: $\\text{err} = 3.0 \\times 10^{-7}$.\n- Safety factor: $s = 0.9$.\n- Lower growth limiter: $\\alpha_{\\min} = 0.5$.\n- Upper growth limiter: $\\alpha_{\\max} = 1.5$.\n\nFirst, we calculate the proposed step-size change factor, $\\alpha_{\\text{prop}}$:\n$$\n\\alpha_{\\text{prop}} = s \\left( \\frac{\\text{tol}}{\\text{err}} \\right)^{1/(p+1)} = 0.9 \\left( \\frac{1.0 \\times 10^{-6}}{3.0 \\times 10^{-7}} \\right)^{1/(4+1)} = 0.9 \\left( \\frac{10}{3} \\right)^{1/5}\n$$\nNumerically evaluating this expression:\n$$\n\\alpha_{\\text{prop}} \\approx 0.9 \\times (3.333\\dots)^{0.2} \\approx 0.9 \\times 1.2723651 \\approx 1.1451286\n$$\nNext, we apply the clipping limits:\n$$\n\\alpha = \\max(0.5, \\min(1.5, 1.1451286))\n$$\nSince $0.5 < 1.1451286 < 1.5$, the value of $\\alpha_{\\text{prop}}$ is within the allowed range, so $\\alpha \\approx 1.1451286$.\n\nFinally, we compute the new step size, $h_{\\text{new}}$:\n$$\nh_{\\text{new}} = \\alpha \\cdot h \\approx 1.1451286 \\times (1.0 \\times 10^{-3}) \\approx 1.1451286 \\times 10^{-3}\n$$\nRounding the result to four significant figures as requested gives:\n$$\nh_{\\text{new}} \\approx 1.145 \\times 10^{-3}\n$$",
            "answer": "$$\n\\boxed{1.145 \\times 10^{-3}}\n$$"
        },
        {
            "introduction": "While adaptive step-size control, as explored previously, is essential for efficiency, it introduces a critical challenge: the use of variable step sizes can jeopardize the numerical stability of the method. This advanced exercise delves into the concept of zero-stability for variable-step-size Backward Differentiation Formula (BDF) methods, which are workhorses for stiff systems common in CFD. You will analyze how the stability of the method depends on the step-size ratio $r_{n} = h_{n} / h_{n-1}$, deriving the precise bounds on this ratio that must be respected to prevent catastrophic error growth. ",
            "id": "3340806",
            "problem": "A semi-discretization of a viscous convection–diffusion equation arising in Computational Fluid Dynamics (CFD) via the method of lines leads to a stiff system of ordinary differential equations of the form $y'(t) = g(y(t))$, where $y(t) \\in \\mathbb{R}^{m}$ and $g$ is sufficiently smooth. Consider integrating this system with the variable-step Backward Differentiation Formula (BDF) of order $k$, where the step sizes $\\{h_{n}\\}$ vary but are well-resolved. Let the local step ratio be defined by $r_n = h_n / h_{n-1}$ and assume a locally constant step ratio $r > 0$ over the last $k$ steps at an arbitrary step $t_{n}$ so that the geometric structure of the stencil is fixed.\n\nStarting from first principles of linear multistep method construction—specifically, polynomial interpolation of degree $k$ through the past $k$ solution values $y_{n}, y_{n-1}, \\dots, y_{n-k}$ and identification of the derivative at $t_{n}$ via the derivative of the Lagrange interpolating polynomial—derive the variable-step BDF2 and BDF3 update formulas by expressing\n$$\\sum_{j=0}^{k} \\alpha_{j}(r)\\, y_{n-j} = h_{n}\\, f_{n},$$\nwith $f_{n} = g(y_{n})$, where the coefficients $\\alpha_{j}(r)$ depend on $r$ through the time grid geometry. Using the zero-stability root condition for linear multistep methods with frozen coefficients—that the characteristic polynomial $\\rho(\\zeta) = \\sum_{j=0}^{k} \\alpha_{j}(r)\\, \\zeta^{k-j}$ has the simple root $\\zeta = 1$ and all other roots strictly inside the unit disk $|\\zeta| < 1$—determine the supremum bounds on $r$ that guarantee zero-stability for BDF2 and BDF3 under the locally constant ratio assumption.\n\nThen, analyze the error propagation in the homogeneous error recurrence induced by the method when these bounds are violated. In particular:\n- For BDF2, obtain the exact expression for the nontrivial root as a function of $r$ and deduce the leading-order per-step error growth factor when $r = r^{\\star} + \\epsilon$ with $\\epsilon > 0$ small, where $r^{\\star}$ is the zero-stability bound you derived.\n- For BDF3, use the quadratic factor obtained by dividing out the trivial factor $(\\zeta - 1)$ to interpret how the product and modulus of the two nontrivial roots change when $r$ exceeds its bound, and explain the resulting qualitative behavior of error amplification.\n\nExpress your final answer as the pair of maximal admissible step ratios for BDF2 and BDF3 in closed form. No rounding is required, and no physical units are to be included in the final answer.",
            "solution": "The problem asks for the derivation of variable-step BDF2 and BDF3 methods under a locally constant step size ratio, the determination of their zero-stability bounds, and an analysis of error propagation when these bounds are violated.\n\n### Part 1: General Formulation\n\nA linear $k$-step method for the ODE $y'(t) = g(y(t))$ can be written as $\\sum_{j=0}^{k} \\alpha_{j} y_{n-j} = h_{n} g(y_n)$, where $h_n = t_n - t_{n-1}$ is the current step size. The coefficients $\\alpha_j$ depend on the geometry of the time grid $t_n, t_{n-1}, \\ldots, t_{n-k}$.\n\nWe assume a locally constant step size ratio $r = h_i/h_{i-1}$ for the steps involved. This implies $h_{n-1} = h_n/r$, $h_{n-2} = h_{n-1}/r = h_n/r^2$, and in general $h_{n-j} = h_n/r^j$.\nThe time points relative to $t_n$ are:\n$t_{n-j} = t_n - \\sum_{i=0}^{j-1} h_{n-i}$ for $j \\ge 1$.\nLet's define a local non-dimensional time coordinate $\\theta = (t-t_n)/h_n$. The interpolation nodes in this coordinate are $\\theta_j = (t_{n-j}-t_n)/h_n$.\n$\\theta_0 = 0$\n$\\theta_1 = -h_n/h_n = -1$\n$\\theta_2 = -(h_n+h_{n-1})/h_n = -(1+1/r)$\nFor $j \\geq 1$, $\\theta_j = -\\sum_{i=0}^{j-1} \\frac{h_{n-i}}{h_n} = -\\sum_{i=0}^{j-1} r^{-i} = -\\frac{1-r^{-j}}{1-r^{-1}}$ for $r \\neq 1$. For $r=1$, $\\theta_j = -j$.\n\nThe coefficients $\\alpha_j$ are determined by requiring the method to be exact for polynomials up to degree $k$. This leads to the system of linear equations:\n$\\sum_{j=0}^{k} \\alpha_j = 0$\n$\\sum_{j=0}^{k} \\alpha_j \\theta_j = 1$\n$\\sum_{j=0}^{k} \\alpha_j \\theta_j^m = 0, \\quad \\text{for } m = 2, 3, \\ldots, k$.\n\n### Part 2: BDF2 Analysis ($k=2$)\n\nFor BDF2, we use nodes $\\theta_0=0$, $\\theta_1=-1$, and $\\theta_2 = -(1+1/r) = -(r+1)/r$. The system for $\\alpha_0, \\alpha_1, \\alpha_2$ is:\n$\\alpha_0 + \\alpha_1 + \\alpha_2 = 0$\n$\\alpha_1 \\theta_1 + \\alpha_2 \\theta_2 = 1 \\implies -\\alpha_1 - \\alpha_2 \\frac{r+1}{r} = 1$\n$\\alpha_1 \\theta_1^2 + \\alpha_2 \\theta_2^2 = 0 \\implies \\alpha_1 + \\alpha_2 \\left(\\frac{r+1}{r}\\right)^2 = 0$\n\nFrom the third equation, $\\alpha_1 = -\\alpha_2 \\frac{(r+1)^2}{r^2}$. Substituting this into the second equation:\n$\\alpha_2 \\frac{(r+1)^2}{r^2} - \\alpha_2 \\frac{r+1}{r} = 1 \\implies \\alpha_2 \\frac{(r+1)^2-r(r+1)}{r^2} = 1 \\implies \\alpha_2 \\frac{r+1}{r^2} = 1$.\nThis gives $\\alpha_2 = \\frac{r^2}{r+1}$.\nThen $\\alpha_1 = -\\frac{r^2}{r+1} \\frac{(r+1)^2}{r^2} = -(r+1)$.\nFinally, $\\alpha_0 = -(\\alpha_1+\\alpha_2) = r+1 - \\frac{r^2}{r+1} = \\frac{(r+1)^2-r^2}{r+1} = \\frac{r^2+2r+1-r^2}{r+1} = \\frac{2r+1}{r+1}$.\n\nThe BDF2 formula is:\n$$ \\left(\\frac{2r+1}{r+1}\\right) y_n - (r+1) y_{n-1} + \\left(\\frac{r^2}{r+1}\\right) y_{n-2} = h_n f_n $$\n\nThe characteristic polynomial is $\\rho_2(\\zeta) = \\sum_{j=0}^{2} \\alpha_j \\zeta^{2-j}$:\n$$ \\rho_2(\\zeta) = \\left(\\frac{2r+1}{r+1}\\right) \\zeta^2 - (r+1) \\zeta + \\frac{r^2}{r+1} $$\nFor zero-stability, one root must be $\\zeta_1=1$ (a simple root), and all other roots must satisfy $|\\zeta|<1$.\n$\\rho_2(1) = \\frac{2r+1}{r+1} - (r+1) + \\frac{r^2}{r+1} = \\frac{2r+1 - (r+1)^2 + r^2}{r+1} = 0$, so $\\zeta_1=1$ is a root.\nThe product of roots is $\\zeta_1 \\zeta_2 = \\alpha_2/\\alpha_0 = \\frac{r^2/(r+1)}{(2r+1)/(r+1)} = \\frac{r^2}{2r+1}$.\nSince $\\zeta_1=1$, the non-trivial root is $\\zeta_2(r) = \\frac{r^2}{2r+1}$.\nThe zero-stability condition $|\\zeta_2|<1$ requires, for $r>0$:\n$r^2 < |2r+1| = 2r+1 \\implies r^2 - 2r - 1 < 0$.\nThe roots of $r^2-2r-1=0$ are $r = \\frac{2 \\pm \\sqrt{4-4(-1)}}{2} = 1 \\pm \\sqrt{2}$. Since $r>0$, the inequality holds for $0 < r < 1+\\sqrt{2}$. The supremum bound for the step ratio is $r^{\\star}_{\\text{BDF2}} = 1+\\sqrt{2}$. At this value, $\\zeta_2=1$, so the root $\\zeta=1$ is a double root, violating the simplicity requirement for roots on the unit circle.\n\nFor error analysis when $r = r^{\\star} + \\epsilon$ with $\\epsilon>0$ small, the error growth is governed by $\\zeta_2(r)$. We expand $\\zeta_2(r)$ around $r^{\\star}$:\n$\\zeta_2(r) \\approx \\zeta_2(r^{\\star}) + \\zeta_2'(r^{\\star})(r-r^{\\star})$.\n$\\zeta_2(r^{\\star}) = \\frac{(1+\\sqrt{2})^2}{2(1+\\sqrt{2})+1} = \\frac{1+2\\sqrt{2}+2}{2+2\\sqrt{2}+1} = \\frac{3+2\\sqrt{2}}{3+2\\sqrt{2}} = 1$.\nThe derivative is $\\zeta_2'(r) = \\frac{d}{dr}\\left(\\frac{r^2}{2r+1}\\right) = \\frac{2r(2r+1)-2r^2}{(2r+1)^2} = \\frac{2r^2+2r}{(2r+1)^2}$.\nAt $r=r^{\\star}=1+\\sqrt{2}$, we have $2r^{\\star}+1 = 3+2\\sqrt{2}$ and $r^{\\star}+1=2+\\sqrt{2}$.\n$\\zeta_2'(r^{\\star}) = \\frac{2r^{\\star}(r^{\\star}+1)}{(2r^{\\star}+1)^2} = \\frac{2(1+\\sqrt{2})(2+\\sqrt{2})}{(3+2\\sqrt{2})^2} = \\frac{2(2+3\\sqrt{2}+2)}{9+12\\sqrt{2}+8} = \\frac{2(4+3\\sqrt{2})}{17+12\\sqrt{2}}$.\nRationalizing the denominator:\n$\\zeta_2'(r^{\\star}) = \\frac{8+6\\sqrt{2}}{17+12\\sqrt{2}} \\cdot \\frac{17-12\\sqrt{2}}{17-12\\sqrt{2}} = \\frac{136-96\\sqrt{2}+102\\sqrt{2}-72(2)}{17^2-(12\\sqrt{2})^2} = \\frac{-8+6\\sqrt{2}}{289-288} = 6\\sqrt{2}-8$.\nThe per-step error growth factor is $\\zeta_2(r) \\approx 1+(6\\sqrt{2}-8)\\epsilon$. Since $6\\sqrt{2} = \\sqrt{72} > \\sqrt{64}=8$, the factor is greater than $1$, leading to error amplification.\n\n### Part 3: BDF3 Analysis ($k=3$)\n\nFor BDF3, the nodes are $\\theta_0=0, \\theta_1=-1, \\theta_2=-(1+1/r), \\theta_3=-(1+1/r+1/r^2)$.\nThe coefficients $\\alpha_j(r)$ can be derived, but for stability analysis we focus on the characteristic polynomial $\\rho_3(\\zeta) = \\alpha_0\\zeta^3 + \\alpha_1\\zeta^2 + \\alpha_2\\zeta + \\alpha_3$, which has a root at $\\zeta=1$. We analyze the quadratic factor $Q(\\zeta) = \\rho_3(\\zeta)/(\\zeta-1) = \\alpha_0\\zeta^2 + (\\alpha_0+\\alpha_1)\\zeta + (\\alpha_0+\\alpha_1+\\alpha_2)$. Using $\\sum\\alpha_j=0$, this simplifies to $Q(\\zeta) = \\alpha_0\\zeta^2 + (\\alpha_0+\\alpha_1)\\zeta - \\alpha_3$.\n\nZero-stability is lost when a root of $Q(\\zeta)$ crosses the unit circle. Away from $\\zeta=\\pm 1$, this occurs when a complex conjugate pair of roots $\\zeta, \\bar{\\zeta}$ lands on the circle, i.e., $|\\zeta|=1$. This implies their product $\\zeta\\bar{\\zeta}=1$. From Vieta's formulas, the product of roots of $Q(\\zeta)$ is $-\\alpha_3/\\alpha_0$. Thus, the stability boundary is determined by $|-\\alpha_3/\\alpha_0|=1$. Using the standard formulas for variable-step BDF coefficients, this condition becomes $\\alpha_0 = -\\alpha_3$.\nThe resulting equation for the stability boundary is:\n$$r^4-r^2-2r-1=0$$\nThis polynomial factors as:\n$$(r^2-r-1)(r^2+r+1) = 0$$\nThe term $r^2+r+1$ has no real roots and is positive for all real $r$. Thus, the stability boundary is given by the roots of $r^2-r-1=0$, which are $r = \\frac{1 \\pm \\sqrt{5}}{2}$.\nAs we require $r>0$, the supremum bound is $r^{\\star}_{\\text{BDF3}} = \\frac{1+\\sqrt{5}}{2}$, the golden ratio.\n\nWhen $r$ exceeds this bound $r^{\\star}_{\\text{BDF3}}$, the quantity $|-\\alpha_3/\\alpha_0|$ becomes greater than $1$. This means the product of the moduli of the two non-trivial roots, $|\\zeta_2 \\zeta_3|$, exceeds $1$. Assuming the roots remain a complex conjugate pair just beyond the boundary (which can be confirmed by checking the discriminant of $Q(\\zeta)$), both roots must move outside the unit circle, i.e., $|\\zeta_2| = |\\zeta_3| > 1$. This leads to an unstable error propagation, where the error is amplified at each step with an oscillatory component due to the complex nature of the roots.\n\nThe BDF3 update formula is:\n$$ \\alpha_0(r) y_n + \\alpha_1(r) y_{n-1} + \\alpha_2(r) y_{n-2} + \\alpha_3(r) y_{n-3} = h_n f_n $$\nwhere the coefficients $\\alpha_j(r)$ are complex functions of the step ratio $r$.\n\n### Part 4: Final Answer\n\nThe maximal admissible step ratios for BDF2 and BDF3 are derived to be $1+\\sqrt{2}$ and $\\frac{1+\\sqrt{5}}{2}$, respectively.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix} 1+\\sqrt{2} & \\frac{1+\\sqrt{5}}{2} \\end{pmatrix}\n}\n$$"
        }
    ]
}