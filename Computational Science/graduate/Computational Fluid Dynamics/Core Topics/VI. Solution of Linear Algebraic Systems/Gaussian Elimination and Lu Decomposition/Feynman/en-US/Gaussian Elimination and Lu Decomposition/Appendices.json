{
    "hands_on_practices": [
        {
            "introduction": "This first exercise is about mastering the fundamental, step-by-step process of Gaussian elimination. By working through a small, concrete example derived from a convection-diffusion problem, you will solidify your understanding of how elementary row operations and multipliers transform a system into an upper-triangular form, which is the core of the algorithm . This practice reinforces the essential mechanics before moving to more complex scenarios.",
            "id": "3322964",
            "problem": "A one-dimensional steady convection–diffusion boundary-value problem on a uniform grid with three interior nodes is discretized using central differences for diffusion and first-order upwinding for convection, yielding a nonsymmetric tridiagonal linear system for the interior unknown vector $\\boldsymbol{T} \\in \\mathbb{R}^{3}$. The resulting system has the form $A \\boldsymbol{T} = \\boldsymbol{b}$ with\n$$\nA \\;=\\; \\begin{pmatrix}\n5 & -1 & 0 \\\\\n-4 & 5 & -1 \\\\\n0 & -4 & 5\n\\end{pmatrix}, \n\\qquad\n\\boldsymbol{b} \\;=\\; \\begin{pmatrix}\n1 \\\\ 0 \\\\ 2\n\\end{pmatrix}.\n$$\nIn the context of Computational Fluid Dynamics (CFD), the forward elimination phase of Gaussian elimination transforms $A$ into an upper-triangular matrix $U$ by applying elementary row operations that eliminate subdiagonal entries in column-major order. The row operations used in forward elimination can be parameterized by multipliers $m_{21}$, $m_{31}$, and $m_{32}$, where each multiplier $m_{ij}$ scales the pivot row at step $j$ to eliminate the entry in position $(i,j)$.\n\nStarting from the core definition of linear systems and the rule that elementary row operations preserve the solution set, perform forward elimination without pivoting to transform $A$ into an upper-triangular matrix $U$ and to obtain the transformed right-hand side $\\widehat{\\boldsymbol{b}}$ corresponding to the same sequence of row operations. Explicitly identify the multipliers $m_{21}$, $m_{31}$, and $m_{32}$, and report the resulting $U$ and $\\widehat{\\boldsymbol{b}}$. \n\nFinally, provide the exact value of the second-stage multiplier $m_{32}$ as your answer. Express your final answer in exact rational form. No rounding is required and no units are involved.",
            "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- The linear system is of the form $A \\boldsymbol{T} = \\boldsymbol{b}$.\n- The coefficient matrix $A$ is given by:\n$$\nA \\;=\\; \\begin{pmatrix}\n5 & -1 & 0 \\\\\n-4 & 5 & -1 \\\\\n0 & -4 & 5\n\\end{pmatrix}\n$$\n- The right-hand side vector $\\boldsymbol{b}$ is given by:\n$$\n\\boldsymbol{b} \\;=\\; \\begin{pmatrix}\n1 \\\\ 0 \\\\ 2\n\\end{pmatrix}\n$$\n- The task is to perform forward elimination without pivoting on the system $A \\boldsymbol{T} = \\boldsymbol{b}$ to obtain an upper-triangular system $U \\boldsymbol{T} = \\widehat{\\boldsymbol{b}}$.\n- The process involves identifying multipliers $m_{21}$, $m_{31}$, and $m_{32}$, where $m_{ij}$ is used to eliminate the entry in position $(i,j)$ by scaling the pivot row $j$.\n- The final answer required is the exact value of the multiplier $m_{32}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the specified criteria:\n- **Scientifically Grounded:** The problem is a standard exercise in numerical linear algebra, specifically the application of Gaussian elimination. This is a fundamental algorithm in scientific computing, including Computational Fluid Dynamics (CFD). The context provided about the physical origin of the system (convection-diffusion equation) is appropriate and realistic. The problem is mathematically and scientifically sound.\n- **Well-Posed:** The problem is well-posed. The matrix $A$ is non-singular (its determinant is $5(25 - 4) - (-1)(-20) = 5(21) - 20 = 85 \\neq 0$), guaranteeing a unique solution to the linear system. The instructions to perform forward elimination without pivoting constitute a well-defined, unambiguous algorithm.\n- **Objective:** The problem is stated in precise, objective mathematical language.\n- **Completeness and Consistency:** All necessary information (matrix $A$, vector $\\boldsymbol{b}$, and the procedure) is provided. There are no contradictions.\n- **No other flaws are present.** The problem is neither unrealistic, ill-posed, trivial, nor unverifiable.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A complete solution will be provided.\n\nThe objective is to transform the linear system $A \\boldsymbol{T} = \\boldsymbol{b}$ into an equivalent upper-triangular system $U \\boldsymbol{T} = \\widehat{\\boldsymbol{b}}$ using forward elimination. This is achieved by applying elementary row operations to the augmented matrix $[A | \\boldsymbol{b}]$.\n\nThe initial augmented matrix is:\n$$\n[A | \\boldsymbol{b}]^{(0)} = \\left[\n\\begin{array}{ccc|c}\n5 & -1 & 0 & 1 \\\\\n-4 & 5 & -1 & 0 \\\\\n0 & -4 & 5 & 2\n\\end{array}\n\\right]\n$$\n\n**Step 1: Elimination in column $j=1$**\n\nThe goal is to eliminate the subdiagonal entries in the first column. The pivot element is $a_{11} = 5$.\n\nTo eliminate the entry $a_{21} = -4$, we define the multiplier $m_{21} = \\frac{a_{21}}{a_{11}}$.\n$$\nm_{21} = \\frac{-4}{5}\n$$\nThe corresponding row operation is $R_2 \\leftarrow R_2 - m_{21} R_1$, or $R_2 \\leftarrow R_2 + \\frac{4}{5} R_1$.\nApplying this to the second row of the augmented matrix:\n- New element in position $(2,1)$: $-4 + \\frac{4}{5}(5) = -4 + 4 = 0$.\n- New element in position $(2,2)$: $5 + \\frac{4}{5}(-1) = 5 - \\frac{4}{5} = \\frac{25-4}{5} = \\frac{21}{5}$.\n- New element in position $(2,3)$: $-1 + \\frac{4}{5}(0) = -1$.\n- New element in the right-hand side vector: $0 + \\frac{4}{5}(1) = \\frac{4}{5}$.\n\nThe entry $a_{31}$ is already $0$. Therefore, no row operation is needed to eliminate it. The corresponding multiplier is:\n$$\nm_{31} = \\frac{a_{31}}{a_{11}} = \\frac{0}{5} = 0\n$$\n\nAfter the first step of elimination, the augmented matrix becomes:\n$$\n[A | \\boldsymbol{b}]^{(1)} = \\left[\n\\begin{array}{ccc|c}\n5 & -1 & 0 & 1 \\\\\n0 & \\frac{21}{5} & -1 & \\frac{4}{5} \\\\\n0 & -4 & 5 & 2\n\\end{array}\n\\right]\n$$\n\n**Step 2: Elimination in column $j=2$**\n\nThe goal is to eliminate the subdiagonal entry in the second column. The pivot element is the new entry in the $(2,2)$ position, $a'_{22} = \\frac{21}{5}$.\n\nTo eliminate the entry $a'_{32} = -4$, we define the multiplier $m_{32} = \\frac{a'_{32}}{a'_{22}}$.\n$$\nm_{32} = \\frac{-4}{\\frac{21}{5}} = -4 \\cdot \\frac{5}{21} = -\\frac{20}{21}\n$$\nThe corresponding row operation is $R_3 \\leftarrow R_3 - m_{32} R_2$, or $R_3 \\leftarrow R_3 + \\frac{20}{21} R_2$.\nApplying this to the third row of the matrix $[A | \\boldsymbol{b}]^{(1)}$:\n- New element in position $(3,1)$: $0 + \\frac{20}{21}(0) = 0$.\n- New element in position $(3,2)$: $-4 + \\frac{20}{21}\\left(\\frac{21}{5}\\right) = -4 + \\frac{20}{5} = -4 + 4 = 0$.\n- New element in position $(3,3)$: $5 + \\frac{20}{21}(-1) = 5 - \\frac{20}{21} = \\frac{105-20}{21} = \\frac{85}{21}$.\n- New element in the right-hand side vector: $2 + \\frac{20}{21}\\left(\\frac{4}{5}\\right) = 2 + \\frac{80}{105} = 2 + \\frac{16}{21} = \\frac{42+16}{21} = \\frac{58}{21}$.\n\nThe forward elimination process is now complete. The final augmented matrix $[U | \\widehat{\\boldsymbol{b}}]$ is:\n$$\n[U | \\widehat{\\boldsymbol{b}}] = \\left[\n\\begin{array}{ccc|c}\n5 & -1 & 0 & 1 \\\\\n0 & \\frac{21}{5} & -1 & \\frac{4}{5} \\\\\n0 & 0 & \\frac{85}{21} & \\frac{58}{21}\n\\end{array}\n\\right]\n$$\n\nThe resulting upper-triangular matrix $U$ and transformed right-hand side vector $\\widehat{\\boldsymbol{b}}$ are:\n$$\nU = \\begin{pmatrix}\n5 & -1 & 0 \\\\\n0 & \\frac{21}{5} & -1 \\\\\n0 & 0 & \\frac{85}{21}\n\\end{pmatrix}, \\qquad\n\\widehat{\\boldsymbol{b}} = \\begin{pmatrix}\n1 \\\\\n\\frac{4}{5} \\\\\n\\frac{58}{21}\n\\end{pmatrix}\n$$\n\nThe multipliers identified during the process are:\n- $m_{21} = -\\frac{4}{5}$\n- $m_{31} = 0$\n- $m_{32} = -\\frac{20}{21}$\n\nThe problem asks for the exact value of the second-stage multiplier $m_{32}$.\nThe value is $-\\frac{20}{21}$.",
            "answer": "$$\n\\boxed{-\\frac{20}{21}}\n$$"
        },
        {
            "introduction": "Moving from numerical computation to symbolic analysis allows for deeper insights. This practice explores the profound connection between a matrix's singularity and the behavior of pivots during Gaussian elimination . By symbolically analyzing a perturbed singular matrix $A_{\\varepsilon}$ common in CFD problems with Neumann boundary conditions, you will see exactly how rank deficiency manifests as a pivot that approaches zero, reinforcing the theoretical underpinnings of the method.",
            "id": "3322974",
            "problem": "Consider the steady one-dimensional diffusion operator representative of the pressure Poisson equation in incompressible Computational Fluid Dynamics (CFD), given by the second derivative operator $\\partial_{xx}$ on the interval $[0,1]$ with homogeneous Neumann boundary conditions at both ends. A standard centered second-order finite-difference discretization on $n$ uniformly spaced grid points preserves the constant nullspace of the continuous operator under pure Neumann boundary conditions. For $n=4$ grid points (including the boundary points), the resulting scaled discrete operator (with the common factor $1/h^{2}$ suppressed for algebraic clarity) is the $4 \\times 4$ matrix\n$$\nA \\;=\\;\n\\begin{pmatrix}\n1 & -1 & 0 & 0 \\\\\n-1 & 2 & -1 & 0 \\\\\n0 & -1 & 2 & -1 \\\\\n0 & 0 & -1 & 1\n\\end{pmatrix}.\n$$\nThis matrix models a pure Neumann problem and is singular with a one-dimensional nullspace spanned by the constant vector. To mimic a common CFD practice of weakly pinning the pressure (or potential) to regularize the singular operator while minimally perturbing the physics, consider the perturbed matrix\n$$\nA_{\\varepsilon} \\;=\\; A \\;+\\; \\varepsilon \\, e_{1} e_{1}^{\\top},\n$$\nwhere $\\varepsilon>0$ is small and $e_{1}$ is the first canonical basis vector. Perform Gaussian elimination with partial pivoting on $A_{\\varepsilon}$, and at each stage justify the pivot selection from first principles (i.e., by comparing entry magnitudes in the active pivot column). Derive symbolically the exact expression for the final pivot (the $(4,4)$ diagonal entry of the upper-triangular factor produced by Gaussian elimination with partial pivoting), denoted $u_{44}(\\varepsilon)$, as a function of $\\varepsilon$.\n\nYour final answer must be the single simplified closed-form expression for $u_{44}(\\varepsilon)$. No numerical rounding is required and no units are needed. Explain why the limiting behavior of $u_{44}(\\varepsilon)$ as $\\varepsilon \\to 0^{+}$ reflects the rank deficiency of $A$.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and complete. All necessary information is provided to perform the specified algebraic procedure and analyze the result. The context provided, relating the matrix to a finite-difference discretization of a differential operator from Computational Fluid Dynamics, is physically and mathematically sound. The matrix $A$ possesses the stated properties of being singular with a one-dimensional nullspace spanned by a constant vector. The regularization technique is a standard practice. Therefore, I will proceed with the solution.\n\nThe problem asks to perform Gaussian elimination with partial pivoting on the perturbed matrix $A_{\\varepsilon}$ and find the final pivot $u_{44}(\\varepsilon)$. The matrix $A$ is given by\n$$\nA \\;=\\;\n\\begin{pmatrix}\n1 & -1 & 0 & 0 \\\\\n-1 & 2 & -1 & 0 \\\\\n0 & -1 & 2 & -1 \\\\\n0 & 0 & -1 & 1\n\\end{pmatrix}.\n$$\nThe perturbation is defined by $A_{\\varepsilon} = A + \\varepsilon \\, e_{1} e_{1}^{\\top}$, where $\\varepsilon>0$ is a small parameter and $e_{1} = (1, 0, 0, 0)^{\\top}$ is the first canonical basis vector. The perturbation term is\n$$\n\\varepsilon \\, e_{1} e_{1}^{\\top} \\;=\\; \\varepsilon \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 0 & 0 \\end{pmatrix} \\;=\\; \\begin{pmatrix} \\varepsilon & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix}.\n$$\nThus, the matrix $A_{\\varepsilon}$ is\n$$\nA_{\\varepsilon} \\;=\\; \\begin{pmatrix} 1+\\varepsilon & -1 & 0 & 0 \\\\ -1 & 2 & -1 & 0 \\\\ 0 & -1 & 2 & -1 \\\\ 0 & 0 & -1 & 1 \\end{pmatrix}.\n$$\nLet this matrix be denoted as $A^{(1)}$. We now perform Gaussian elimination with partial pivoting.\n\n**Step 1: Elimination in Column 1**\nThe first column of $A^{(1)}$ is $(1+\\varepsilon, -1, 0, 0)^{\\top}$. We must select the entry with the largest absolute value as the pivot. The candidates are $|1+\\varepsilon|$ and $|-1|=1$. Since $\\varepsilon>0$, we have $1+\\varepsilon > 1$, so $|1+\\varepsilon| > |-1|$. The pivot is $a^{(1)}_{11} = 1+\\varepsilon$. No row interchange is necessary.\nWe eliminate the entry $a^{(1)}_{21}=-1$ by computing the multiplier $m_{21} = \\frac{a^{(1)}_{21}}{a^{(1)}_{11}} = \\frac{-1}{1+\\varepsilon}$.\nThe second row is updated by the operation $R_2 \\leftarrow R_2 - m_{21} R_1$.\nThe new entries of the second row are:\n$a^{(2)}_{21} = a^{(1)}_{21} - m_{21}a^{(1)}_{11} = -1 - \\left(\\frac{-1}{1+\\varepsilon}\\right)(1+\\varepsilon) = -1+1=0$.\n$a^{(2)}_{22} = a^{(1)}_{22} - m_{21}a^{(1)}_{12} = 2 - \\left(\\frac{-1}{1+\\varepsilon}\\right)(-1) = 2 - \\frac{1}{1+\\varepsilon} = \\frac{2(1+\\varepsilon)-1}{1+\\varepsilon} = \\frac{1+2\\varepsilon}{1+\\varepsilon}$.\n$a^{(2)}_{23} = a^{(1)}_{23} - m_{21}a^{(1)}_{13} = -1 - \\left(\\frac{-1}{1+\\varepsilon}\\right)(0) = -1$.\n$a^{(2)}_{24} = a^{(1)}_{24} - m_{21}a^{(1)}_{14} = 0 - \\left(\\frac{-1}{1+\\varepsilon}\\right)(0) = 0$.\nThe matrix after the first step is\n$$\nA^{(2)} \\;=\\; \\begin{pmatrix} 1+\\varepsilon & -1 & 0 & 0 \\\\ 0 & \\frac{1+2\\varepsilon}{1+\\varepsilon} & -1 & 0 \\\\ 0 & -1 & 2 & -1 \\\\ 0 & 0 & -1 & 1 \\end{pmatrix}.\n$$\n\n**Step 2: Elimination in Column 2**\nThe active pivot column is the second column, below the diagonal: $(\\frac{1+2\\varepsilon}{1+\\varepsilon}, -1)^{\\top}$. We compare magnitudes to select the pivot.\n$|a^{(2)}_{22}| = \\left|\\frac{1+2\\varepsilon}{1+\\varepsilon}\\right| = \\frac{1+2\\varepsilon}{1+\\varepsilon}$ since $\\varepsilon>0$.\n$|a^{(2)}_{32}| = |-1| = 1$.\nFor $\\varepsilon>0$, $1+2\\varepsilon > 1+\\varepsilon$, which implies $\\frac{1+2\\varepsilon}{1+\\varepsilon} > 1$. Thus, $|a^{(2)}_{22}| > |a^{(2)}_{32}|$. The pivot is $a^{(2)}_{22} = \\frac{1+2\\varepsilon}{1+\\varepsilon}$. No row interchange is necessary.\nWe eliminate $a^{(2)}_{32}=-1$ with multiplier $m_{32} = \\frac{a^{(2)}_{32}}{a^{(2)}_{22}} = \\frac{-1}{(1+2\\varepsilon)/(1+\\varepsilon)} = -\\frac{1+\\varepsilon}{1+2\\varepsilon}$.\nThe third row is updated by $R_3 \\leftarrow R_3 - m_{32} R_2$.\nNew entries for the third row:\n$a^{(3)}_{32} = a^{(2)}_{32} - m_{32}a^{(2)}_{22} = -1 - \\left(-\\frac{1+\\varepsilon}{1+2\\varepsilon}\\right)\\left(\\frac{1+2\\varepsilon}{1+\\varepsilon}\\right) = -1+1 = 0$.\n$a^{(3)}_{33} = a^{(2)}_{33} - m_{32}a^{(2)}_{23} = 2 - \\left(-\\frac{1+\\varepsilon}{1+2\\varepsilon}\\right)(-1) = 2 - \\frac{1+\\varepsilon}{1+2\\varepsilon} = \\frac{2(1+2\\varepsilon)-(1+\\varepsilon)}{1+2\\varepsilon} = \\frac{1+3\\varepsilon}{1+2\\varepsilon}$.\n$a^{(3)}_{34} = a^{(2)}_{34} - m_{32}a^{(2)}_{24} = -1 - \\left(-\\frac{1+\\varepsilon}{1+2\\varepsilon}\\right)(0) = -1$.\nThe matrix after the second step is\n$$\nA^{(3)} \\;=\\; \\begin{pmatrix} 1+\\varepsilon & -1 & 0 & 0 \\\\ 0 & \\frac{1+2\\varepsilon}{1+\\varepsilon} & -1 & 0 \\\\ 0 & 0 & \\frac{1+3\\varepsilon}{1+2\\varepsilon} & -1 \\\\ 0 & 0 & -1 & 1 \\end{pmatrix}.\n$$\n\n**Step 3: Elimination in Column 3**\nThe active pivot column is the third column, below the diagonal: $(\\frac{1+3\\varepsilon}{1+2\\varepsilon}, -1)^{\\top}$. We compare magnitudes.\n$|a^{(3)}_{33}| = \\left|\\frac{1+3\\varepsilon}{1+2\\varepsilon}\\right| = \\frac{1+3\\varepsilon}{1+2\\varepsilon}$ since $\\varepsilon>0$.\n$|a^{(3)}_{43}| = |-1| = 1$.\nFor $\\varepsilon>0$, $1+3\\varepsilon > 1+2\\varepsilon$, which implies $\\frac{1+3\\varepsilon}{1+2\\varepsilon} > 1$. Thus, $|a^{(3)}_{33}| > |a^{(3)}_{43}|$. The pivot is $a^{(3)}_{33} = \\frac{1+3\\varepsilon}{1+2\\varepsilon}$. No row interchange is necessary.\nWe eliminate $a^{(3)}_{43}=-1$ with multiplier $m_{43} = \\frac{a^{(3)}_{43}}{a^{(3)}_{33}} = \\frac{-1}{(1+3\\varepsilon)/(1+2\\varepsilon)} = -\\frac{1+2\\varepsilon}{1+3\\varepsilon}$.\nThe fourth row is updated by $R_4 \\leftarrow R_4 - m_{43} R_3$.\nThe new entry for the fourth row, fourth column is:\n$a^{(4)}_{44} = a^{(3)}_{44} - m_{43}a^{(3)}_{34} = 1 - \\left(-\\frac{1+2\\varepsilon}{1+3\\varepsilon}\\right)(-1) = 1 - \\frac{1+2\\varepsilon}{1+3\\varepsilon} = \\frac{(1+3\\varepsilon)-(1+2\\varepsilon)}{1+3\\varepsilon} = \\frac{\\varepsilon}{1+3\\varepsilon}$.\nAfter this final step, the process of Gaussian elimination is complete. The resulting upper-triangular matrix, denoted $U$, is\n$$\nU \\;=\\; \\begin{pmatrix} 1+\\varepsilon & -1 & 0 & 0 \\\\ 0 & \\frac{1+2\\varepsilon}{1+\\varepsilon} & -1 & 0 \\\\ 0 & 0 & \\frac{1+3\\varepsilon}{1+2\\varepsilon} & -1 \\\\ 0 & 0 & 0 & \\frac{\\varepsilon}{1+3\\varepsilon} \\end{pmatrix}.\n$$\nThe final pivot is the $(4,4)$ diagonal entry of $U$, which is $u_{44}(\\varepsilon)$.\n$$\nu_{44}(\\varepsilon) = \\frac{\\varepsilon}{1+3\\varepsilon}.\n$$\n\n**Analysis of the Limiting Behavior**\nThe limiting behavior of $u_{44}(\\varepsilon)$ as $\\varepsilon \\to 0^{+}$ is\n$$\n\\lim_{\\varepsilon \\to 0^{+}} u_{44}(\\varepsilon) = \\lim_{\\varepsilon \\to 0^{+}} \\frac{\\varepsilon}{1+3\\varepsilon} = \\frac{0}{1+0} = 0.\n$$\nThis behavior is a direct consequence of the singularity of the original matrix $A$. The determinant of a matrix is the product of the pivots obtained during Gaussian elimination (up to a sign determined by row swaps). Since no row swaps were needed, $\\det(A_{\\varepsilon}) = u_{11}u_{22}u_{33}u_{44}$.\n$$\n\\det(A_{\\varepsilon}) = (1+\\varepsilon)\\left(\\frac{1+2\\varepsilon}{1+\\varepsilon}\\right)\\left(\\frac{1+3\\varepsilon}{1+2\\varepsilon}\\right)\\left(\\frac{\\varepsilon}{1+3\\varepsilon}\\right) = \\varepsilon.\n$$\nAs $\\varepsilon \\to 0^{+}$, $A_{\\varepsilon} \\to A$, and $\\det(A_{\\varepsilon}) \\to \\det(A)$. The limit $\\lim_{\\varepsilon \\to 0^{+}} \\det(A_{\\varepsilon})=0$ confirms that $\\det(A)=0$, so $A$ is a singular matrix.\nThe rank of a matrix is equal to the number of non-zero pivots produced by Gaussian elimination. For any $\\varepsilon>0$, all four pivots of $A_{\\varepsilon}$ are non-zero, so $\\text{rank}(A_{\\varepsilon})=4$. However, in the limit $\\varepsilon \\to 0^{+}$, the pivots of $A_{\\varepsilon}$ converge to the pivots of $A$:\n$$\nu_{11} \\to 1, \\quad u_{22} \\to 1, \\quad u_{33} \\to 1, \\quad u_{44} \\to 0.\n$$\nThe emergence of a zero pivot in the final position for the matrix $A$ indicates that its rank is $3$. For an $n \\times n$ matrix, a rank of $r < n$ implies that the dimension of its nullspace is $n-r$. For the $4 \\times 4$ matrix $A$, a rank of $3$ means its nullspace has dimension $4-3=1$. This is perfectly consistent with the problem statement that $A$ is rank-deficient with a one-dimensional nullspace. The quantity $u_{44}(\\varepsilon)$ approaching zero is the numerical signature of $A_{\\varepsilon}$ being a small perturbation of a singular matrix.",
            "answer": "$$\\boxed{\\frac{\\varepsilon}{1+3\\varepsilon}}$$"
        },
        {
            "introduction": "Real-world CFD problems generate large, sparse linear systems where most matrix entries are zero. This exercise transitions to the practical challenges of applying $LU$ decomposition in this context, focusing on the critical concept of \"fill-in\" . By implementing a structural simulation on a matrix in Compressed Sparse Row (CSR) format, you will gain hands-on experience with how the factorization process can create new non-zero entries, a key factor influencing the memory and computational cost of direct solvers.",
            "id": "3322984",
            "problem": "Consider a sparse linear system that arises from a standard discretization of elliptic operators in Computational Fluid Dynamics (CFD), yielding a large sparse matrix. You are given the matrix in Compressed Sparse Row (CSR) format, defined by three arrays: the row pointer array, the column index array, and the data array. For the purposes of this task, only the row pointer and column index arrays are needed. Compressed Sparse Row (CSR) stores, for each row, the contiguous block of column indices indicating the positions of nonzero entries.\n\nThe fundamental base is the classical Gaussian elimination used to construct a Lower-Upper (LU) factorization of a matrix. At elimination step indexed by $k$, with pivot entry $a_{kk}$ assumed nonzero and without row or column pivoting, the transformation zeroes entries $a_{ik}$ for all rows $i$ with $i > k$ by adding a multiple of the pivot row $k$ to row $i$. Specifically, the multiplier is defined by $l_{ik} = a_{ik} / a_{kk}$, and the row update is the linear operation $a_{ij} \\leftarrow a_{ij} - l_{ik} \\, a_{kj}$ applied for all columns $j$. In structural (pattern-only) analysis used to predict fill-in, numerical cancellation is ignored: if $a_{kj}$ is structurally nonzero and the elimination is performed (meaning $a_{ik}$ is structurally nonzero), then the updated $a_{ij}$ is generically treated as nonzero. In this way, the fill-in induced by the step is governed by the graph-theoretic union of sparsity patterns.\n\nYour task is to simulate a single elimination step that uses the pivot at row $k$ to eliminate the entry in target row $i$ in column $k$, and to update the sparsity pattern of the target row $i$ accordingly. Use zero-based indexing. Follow these rules for the structural simulation:\n- If the target row $i$ does not contain a structurally nonzero entry in column $k$ (that is, there is no index $k$ in the column index list for row $i$), then no elimination is performed and the row’s sparsity pattern remains unchanged.\n- If elimination is performed, remove the pivot column $k$ from the target row’s sparsity pattern, and insert fill-in at all columns $j$ such that $j > k$ and the pivot row $k$ has a structural nonzero at column $j$, provided those columns are not already present in the target row. Retain all other original columns of the target row.\n\nFormally, let the original set of column indices for row $i$ be $S_i$, and for row $k$ be $S_k$. If $k \\in S_i$, the updated structural pattern for row $i$ is\n$$\nS_i^{\\text{new}} = \\big( S_i \\setminus \\{k\\} \\big) \\cup \\{\\, j \\in S_k \\mid j > k \\,\\}.\n$$\nIf $k \\notin S_i$, then $S_i^{\\text{new}} = S_i$.\n\nImplement a program that, for each test case, takes a CSR matrix and the specified $(k,i)$ pair, performs the above structural update for a single elimination step, and outputs the sorted list of updated column indices for row $i$.\n\nNo physical units, angle units, or percentages are involved in this task.\n\nUse the following test suite. Each test case provides the matrix dimension $n$, the CSR row pointer array `indptr`, the CSR column index array `indices`, and the elimination parameters $(k,i)$.\n\nTest case $1$ (fill-in occurs):\n- $n = 6$\n- `indptr` = `[\\, 0,\\, 2,\\, 5,\\, 9,\\, 12,\\, 15,\\, 18 \\,]`\n- `indices` = `[\\, 0,\\, 1,\\, 0,\\, 1,\\, 2,\\, 1,\\, 2,\\, 3,\\, 5,\\, 2,\\, 3,\\, 5,\\, 2,\\, 4,\\, 5,\\, 3,\\, 4,\\, 5 \\,]`\n- $(k,i) = (2,\\, 4)$\n\nTest case $2$ (no fill-in; pivot row’s post-pivot columns already present in the target row):\n- $n = 5$\n- `indptr` = `[\\, 0,\\, 2,\\, 5,\\, 7,\\, 10,\\, 12 \\,]`\n- `indices` = `[\\, 0,\\, 1,\\, 0,\\, 1,\\, 2,\\, 1,\\, 2,\\, 1,\\, 2,\\, 3,\\, 3,\\, 4 \\,]`\n- $(k,i) = (1,\\, 3)$\n\nTest case $3$ (elimination skipped; structural zero in the pivot column of the target row):\n- $n = 6$\n- `indptr` = `[\\, 0,\\, 2,\\, 4,\\, 7,\\, 9,\\, 12,\\, 14 \\,]`\n- `indices` = `[\\, 0,\\, 1,\\, 1,\\, 2,\\, 0,\\, 2,\\, 4,\\, 2,\\, 3,\\, 1,\\, 4,\\, 5,\\, 3,\\, 5 \\,]`\n- $(k,i) = (2,\\, 5)$\n\nTest case $4$ (pivot row has no post-pivot columns; only removal of the pivot column in the target row):\n- $n = 6$\n- `indptr` = `[\\, 0,\\, 2,\\, 5,\\, 7,\\, 9,\\, 11,\\, 14 \\,]`\n- `indices` = `[\\, 0,\\, 1,\\, 1,\\, 2,\\, 4,\\, 2,\\, 3,\\, 3,\\, 4,\\, 1,\\, 4,\\, 2,\\, 4,\\, 5 \\,]`\n- $(k,i) = (4,\\, 5)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result must be the sorted list of updated column indices for row $i$ in the respective test case. For example, the output should look like\n`[\\, [\\dots],\\, [\\dots],\\, [\\dots],\\, [\\dots] \\,]`\nwith no spaces in the lists. Concretely, your program must print exactly one line in the format\n`[[case1],[case2],[case3],[case4]]`\nwhere each `caseX` is a comma-separated list of integers.",
            "solution": "The problem requires implementing a function to simulate one step of structural Gaussian elimination on a sparse matrix in Compressed Sparse Row (CSR) format. The update rule for the target row $i$, using pivot row $k$, is given by $S_i^{\\text{new}} = \\big( S_i \\setminus \\{k\\} \\big) \\cup \\{\\, j \\in S_k \\mid j > k \\,\\}$, which is applied only if the original row $i$ has a nonzero entry in column $k$ (i.e., $k \\in S_i$). The provided Python code in the `<answer>` tag correctly implements this logic using efficient `set` operations.\n\nLet's walk through Test Case 1 to demonstrate the process:\n- **Parameters**: $(k,i) = (2,4)$.\n- **Input Patterns**: From the CSR data, we extract the sparsity patterns as sets of column indices: $S_2 = \\{1, 2, 3, 5\\}$ and $S_4 = \\{2, 4, 5\\}$.\n- **Condition Check**: Since $k=2 \\in S_4$, the update is performed.\n- **Update Rule Application**:\n    - Remove pivot column from target: $S_4 \\setminus \\{k\\} = \\{2, 4, 5\\} \\setminus \\{2\\} = \\{4, 5\\}$.\n    - Determine fill-in from pivot row: $\\{\\, j \\in S_2 \\mid j > k \\,\\} = \\{\\, j \\in \\{1, 2, 3, 5\\} \\mid j > 2 \\,\\} = \\{3, 5\\}$.\n    - Union the sets: $S_4^{\\text{new}} = \\{4, 5\\} \\cup \\{3, 5\\} = \\{3, 4, 5\\}$.\n- **Final Result**: The sorted list is `[3, 4, 5]`.\n\nThe code correctly handles all test cases, which cover all logical branches of the algorithm:\n- **Test Case 2 ($k=1, i=3$):** $S_1=\\{0,1,2\\}$, $S_3=\\{1,2,3\\}$. Update is performed. $S_3^{\\text{new}} = (\\{1,2,3\\} \\setminus \\{1\\}) \\cup \\{j \\in S_1 \\mid j > 1\\} = \\{2,3\\} \\cup \\{2\\} = \\{2,3\\}$. Result: `[2,3]`.\n- **Test Case 3 ($k=2, i=5$):** $S_5=\\{3,5\\}$. Since $k=2 \\notin S_5$, no update is performed. Result: `[3,5]`.\n- **Test Case 4 ($k=4, i=5$):** $S_4=\\{1,4\\}$, $S_5=\\{2,4,5\\}$. Update is performed. The fill-in set from $S_4$ is empty since no $j \\in S_4$ has $j>4$. The update only removes the pivot column: $S_5^{\\text{new}} = \\{2,4,5\\} \\setminus \\{4\\} = \\{2,5\\}$. Result: `[2,5]`.\n\nThe Python script correctly implements this logic, producing the required output format.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates a single structural elimination step in sparse LU factorization\n    for a set of test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"n\": 6,\n            \"indptr\": [0, 2, 5, 9, 12, 15, 18],\n            \"indices\": [0, 1, 0, 1, 2, 1, 2, 3, 5, 2, 3, 5, 2, 4, 5, 3, 4, 5],\n            \"k\": 2, \"i\": 4\n        },\n        {\n            \"n\": 5,\n            \"indptr\": [0, 2, 5, 7, 10, 12],\n            \"indices\": [0, 1, 0, 1, 2, 1, 2, 1, 2, 3, 3, 4],\n            \"k\": 1, \"i\": 3\n        },\n        {\n            \"n\": 6,\n            \"indptr\": [0, 2, 4, 7, 9, 12, 14],\n            \"indices\": [0, 1, 1, 2, 0, 2, 4, 2, 3, 1, 4, 5, 3, 5],\n            \"k\": 2, \"i\": 5\n        },\n        {\n            \"n\": 6,\n            \"indptr\": [0, 2, 5, 7, 9, 11, 14],\n            \"indices\": [0, 1, 1, 2, 4, 2, 3, 3, 4, 1, 4, 2, 4, 5],\n            \"k\": 4, \"i\": 5\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        indptr = np.array(case[\"indptr\"])\n        indices = np.array(case[\"indices\"])\n        k = case[\"k\"]\n        i = case[\"i\"]\n\n        # Extract column indices for pivot row k and target row i.\n        # These represent the sparsity patterns S_k and S_i.\n        s_k_indices = indices[indptr[k]:indptr[k+1]]\n        s_i_indices = indices[indptr[i]:indptr[i+1]]\n\n        # Using sets is natural for the specified operations.\n        S_i = set(s_i_indices)\n        S_k = set(s_k_indices)\n\n        # Check if the elimination step is necessary.\n        # This occurs if the target row i has a nonzero entry in the pivot column k.\n        if k in S_i:\n            # Perform the structural update.\n            # 1. Remove the pivot column index k from the target row's pattern.\n            S_i_prime = S_i - {k}\n\n            # 2. Identify the fill-in columns from the pivot row.\n            # These are columns j > k where the pivot row has a nonzero.\n            fill_in = {j for j in S_k if j > k}\n\n            # 3. The new pattern is the union of the modified target row and the fill-in.\n            S_i_new = S_i_prime.union(fill_in)\n        else:\n            # If no elimination is needed, the pattern is unchanged.\n            S_i_new = S_i\n\n        # The final result must be a sorted list of column indices.\n        updated_row_i = sorted(list(S_i_new))\n        results.append(updated_row_i)\n\n    # Format the output string as per the problem specification.\n    # Ex: [[1,2],[3,4]]\n    string_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n    final_output = f\"[{','.join(string_results)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}