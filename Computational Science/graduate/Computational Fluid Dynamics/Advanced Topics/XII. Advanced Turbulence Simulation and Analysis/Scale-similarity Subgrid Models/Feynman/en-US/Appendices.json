{
    "hands_on_practices": [
        {
            "introduction": "The scale-similarity hypothesis posits that the structure of stress-producing interactions is similar across a range of scales, including those just below the grid resolution. The Bardina model is the most direct application of this idea, modeling the subgrid stress by applying a test filter to the resolved velocity field. This foundational exercise  will guide you through the process of translating the theoretical definition of the scale-similarity stress, $\\tau_{ij}^{\\text{sim}} = \\widetilde{u_i u_j} - \\widetilde{u}_i \\widetilde{u}_j$, into a concrete numerical implementation on a two-dimensional grid, providing an essential first step in understanding and applying these models.",
            "id": "3360696",
            "problem": "Consider Large-Eddy Simulation (LES) of incompressible flow where the resolved velocity field is a two-dimensional field $(u_1(x,y),u_2(x,y))$ defined on a uniform periodic grid. The goal is to compute the scale-similarity estimate of the subgrid stress component $\\tau_{12}^{\\text{sim}}$ using the Bardina model with a box test filter specified by discrete stencil coefficients. Starting from the core definitions of filtering and second-order moments in LES, derive the discrete expression for $\\tau_{12}^{\\text{sim}}$ based on the Bardina scale-similarity principle, and implement it on a synthetic field.\n\nFundamental base:\n- The subgrid stress tensor at the grid-filter level is defined by second-order moments of filtered velocities.\n- A test filter is defined as a linear averaging operator, implemented as a discrete convolution with a normalized stencil on a uniform grid.\n- The Bardina scale-similarity principle models the small-scale stress at the grid-filter level by applying the same second-order structure at the test-filter level to the resolved field.\n\nDiscrete test filter specification:\n- Use a box test filter with a $3 \\times 3$ stencil whose coefficients $w_{a,b}$ for offsets $a,b \\in \\{-1,0,1\\}$ are all equal to $1/9$. That is,\n$$\nw_{a,b} = \\frac{1}{9} \\quad \\text{for} \\quad a,b \\in \\{-1,0,1\\},\n$$\nand the filtered field $\\widetilde{\\phi}_{i,j}$ of a discrete scalar field $\\phi_{i,j}$ is defined by periodic convolution,\n$$\n\\widetilde{\\phi}_{i,j} = \\sum_{a=-1}^{1}\\sum_{b=-1}^{1} w_{a,b}\\, \\phi_{i+a \\bmod N_x,\\; j+b \\bmod N_y}.\n$$\nAll indices are treated with periodic wrap-around and $(N_x,N_y)$ is the grid resolution.\n\nDiscrete grid and fields:\n- The grid is uniform and periodic with $x_i = i\\,\\Delta x$, $y_j = j\\,\\Delta y$, where $\\Delta x = L_x/N_x$ and $\\Delta y = L_y/N_y$, $i \\in \\{0,\\dots,N_x-1\\}$, $j \\in \\{0,\\dots,N_y-1\\}$.\n- Trigonometric functions of $x$ and $y$ use angles measured in radians.\n\nImplementation target:\n- Derive the Bardina scale-similarity expression for $\\tau_{12}^{\\text{sim}}$ from the definitions above without assuming any shortcut formulas.\n- Implement the discrete convolution with the given stencil and periodic wrap-around.\n- Compute $\\tau_{12}^{\\text{sim}}$ at every grid point for each test case below.\n- For each test case, output the spatial root-mean-square (RMS) value of $\\tau_{12}^{\\text{sim}}$ defined by\n$$\n\\text{RMS}(\\tau_{12}^{\\text{sim}}) = \\sqrt{ \\frac{1}{N_x N_y} \\sum_{i=0}^{N_x-1} \\sum_{j=0}^{N_y-1} \\left( \\tau_{12,\\,i,j}^{\\text{sim}} \\right)^2 }.\n$$\n- No physical units are required; all quantities are dimensionless.\n\nTest suite:\n- Case A (general resolved structure):\n    - $N_x = 16$, $N_y = 16$, $L_x = 2\\pi$, $L_y = 2\\pi$,\n    - $u_1(x,y) = \\sin(x) + 0.3\\,\\cos(2y)$,\n    - $u_2(x,y) = \\cos(y) + 0.3\\,\\sin(2x)\\cos(2y)$.\n- Case B (uniform flow boundary case):\n    - $N_x = 8$, $N_y = 8$, $L_x = 1$, $L_y = 1$,\n    - $u_1(x,y) = 1$, $u_2(x,y) = 1$.\n- Case C (high-frequency content near grid resolution):\n    - $N_x = 32$, $N_y = 32$, $L_x = 2\\pi$, $L_y = 2\\pi$,\n    - $u_1(x,y) = \\sin(4x) + 0.2\\,\\sin(8x)\\cos(8y)$,\n    - $u_2(x,y) = \\cos(4y) + 0.2\\,\\sin(8x)\\sin(8y)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of Cases A, B, C, for example, $\\left[\\text{rms}_A,\\text{rms}_B,\\text{rms}_C\\right]$.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of computational fluid dynamics, specifically Large-Eddy Simulation (LES), and is well-posed with a complete and consistent set of definitions and data.\n\nThe objective is to derive the discrete expression for the scale-similarity subgrid stress component $\\tau_{12}^{\\text{sim}}$ based on the Bardina model and implement its computation for given velocity fields.\n\n**1. Foundational Concepts: Subgrid-Scale Stress and Test Filtering**\n\nIn LES, the velocity field $u_i$ is decomposed into a resolved component, $\\bar{u}_i$, and a subgrid-scale component, $u_i'$. The overbar denotes a filtering operation at the grid scale, $\\Delta$. When the incompressible Navier-Stokes equations are filtered, an unclosed term arises, known as the subgrid-scale (SGS) stress tensor, $\\tau_{ij}$:\n$$ \\tau_{ij} = \\overline{u_i u_j} - \\bar{u}_i \\bar{u}_j $$\nThis tensor represents the effect of the unresolved small scales on the resolved large scales and must be modeled. The problem provides resolved velocity fields, which we denote simply as $u_i$ (equivalent to $\\bar{u}_i$ in this context), defined on a discrete grid. As we only have access to this resolved information, $\\tau_{ij}$ cannot be computed directly.\n\n**2. The Bardina Scale-Similarity Principle**\n\nThe Bardina model provides an approximation for $\\tau_{ij}$ based on the principle of scale similarity. This principle hypothesizes that the energetic interactions among the smallest resolved scales are structurally similar to the interactions between the resolved and unresolved scales. To probe the smallest resolved scales, a second, explicit *test filter* is introduced, denoted by a tilde ($\\widetilde{\\cdot}$). This test filter has a characteristic width $\\widetilde{\\Delta}$ that is larger than the grid filter width $\\Delta$.\n\nThe model is constructed by applying the same mathematical form used to define the SGS stress, but at the level of the test filter acting on the resolved field $u_i$:\n$$ \\tau_{ij}^{\\text{sim}} = \\widetilde{u_i u_j} - \\widetilde{u_i} \\widetilde{u_j} $$\nThis quantity, computable entirely from the resolved field, serves as the scale-similarity estimate of the SGS stress. For the component $\\tau_{12}$, the model is:\n$$ \\tau_{12}^{\\text{sim}} = \\widetilde{u_1 u_2} - \\widetilde{u_1} \\widetilde{u_2} $$\nThis expression dictates that we must first compute the pointwise product of the velocity components $u_1$ and $u_2$, then apply the test filter to this product field. From this, we subtract the product of the test-filtered velocity components.\n\n**3. Discretization and Filter Application**\n\nThe problem defines the fields and operations on a uniform, periodic, two-dimensional grid of size $N_x \\times N_y$. The resolved velocity components are discrete arrays $u_{1,i,j}$ and $u_{2,i,j}$. The discrete form of the model at a grid point $(i, j)$ is:\n$$ (\\tau_{12}^{\\text{sim}})_{i,j} = (\\widetilde{u_1 u_2})_{i,j} - (\\widetilde{u_1})_{i,j} (\\widetilde{u_2})_{i,j} $$\nThe test filter is specified as a discrete convolution with a $3 \\times 3$ stencil of weights $w_{a,b} = 1/9$ for $a,b \\in \\{-1,0,1\\}$. For an arbitrary discrete field $\\phi_{i,j}$, the filtering operation is:\n$$ \\widetilde{\\phi}_{i,j} = \\sum_{a=-1}^{1}\\sum_{b=-1}^{1} w_{a,b}\\, \\phi_{i+a \\bmod N_x,\\; j+b \\bmod N_y} = \\frac{1}{9} \\sum_{a=-1}^{1}\\sum_{b=-1}^{1} \\phi_{i+a \\bmod N_x,\\; j+b \\bmod N_y} $$\nThis is a simple arithmetic mean over a $3 \\times 3$ cell neighborhood, with periodic wrap-around at the boundaries.\n\nApplying this filter definition to the terms in the model for $(\\tau_{12}^{\\text{sim}})_{i,j}$:\n- The filtered product field is: $(\\widetilde{u_1 u_2})_{i,j} = \\frac{1}{9} \\sum_{a=-1}^{1}\\sum_{b=-1}^{1} \\left( u_{1, i+a, j+b} \\cdot u_{2, i+a, j+b} \\right)$\n- The filtered component fields are: $(\\widetilde{u_1})_{i,j} = \\frac{1}{9} \\sum_{a=-1}^{1}\\sum_{b=-1}^{1} u_{1, i+a, j+b}$ and $(\\widetilde{u_2})_{i,j} = \\frac{1}{9} \\sum_{a=-1}^{1}\\sum_{b=-1}^{1} u_{2, i+a, j+b}$\n\nSubstituting these into the discrete model equation gives the final explicit expression for each point on the grid:\n$$ (\\tau_{12}^{\\text{sim}})_{i,j} = \\left( \\frac{1}{9} \\sum_{a=-1}^{1}\\sum_{b=-1}^{1} u_{1,i+a,j+b} u_{2,i+a,j+b} \\right) - \\left( \\frac{1}{9} \\sum_{a=-1}^{1}\\sum_{b=-1}^{1} u_{1,i+a,j+b} \\right) \\left( \\frac{1}{9} \\sum_{a=-1}^{1}\\sum_{b=-1}^{1} u_{2,i+a,j+b} \\right) $$\nwhere all indices are evaluated modulo the grid dimensions ($N_x$ for the first index, $N_y$ for the second).\n\n**4. Final Metric: Root-Mean-Square (RMS)**\n\nAfter computing the entire two-dimensional field $(\\tau_{12}^{\\text{sim}})_{i,j}$, the problem requires its spatial root-mean-square (RMS) value. This is a standard measure of the magnitude of the field, defined as:\n$$ \\text{RMS}(\\tau_{12}^{\\text{sim}}) = \\sqrt{ \\frac{1}{N_x N_y} \\sum_{i=0}^{N_x-1} \\sum_{j=0}^{N_y-1} \\left( (\\tau_{12}^{\\text{sim}})_{i,j} \\right)^2 } $$\nThis procedure, from the foundational principle to the final RMS calculation, provides a complete algorithm for solving the problem. The implementation will follow these steps for each specified test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef solve():\n    \"\"\"\n    Computes the RMS of the scale-similarity subgrid stress τ_12 for given test cases.\n    \"\"\"\n    # Define test cases as a list of tuples.\n    # Each tuple contains: (Nx, Ny, Lx, Ly, u1_func, u2_func)\n    test_cases = [\n        # Case A: General resolved structure\n        (16, 16, 2 * np.pi, 2 * np.pi,\n         lambda x, y: np.sin(x) + 0.3 * np.cos(2 * y),\n         lambda x, y: np.cos(y) + 0.3 * np.sin(2 * x) * np.cos(2 * y)),\n        \n        # Case B: Uniform flow boundary case\n        (8, 8, 1.0, 1.0,\n         lambda x, y: np.ones_like(x),  # Uniform flow u1=1\n         lambda x, y: np.ones_like(x)),  # Uniform flow u2=1\n        \n        # Case C: High-frequency content near grid resolution\n        (32, 32, 2 * np.pi, 2 * np.pi,\n         lambda x, y: np.sin(4 * x) + 0.2 * np.sin(8 * x) * np.cos(8 * y),\n         lambda x, y: np.cos(4 * y) + 0.2 * np.sin(8 * x) * np.sin(8 * y))\n    ]\n\n    results = []\n    \n    # Define the discrete 3x3 box test filter kernel.\n    # The weights w_ab are 1/9 for all stencil points.\n    kernel = np.full((3, 3), 1/9.0)\n\n    for case in test_cases:\n        # Unpack case parameters\n        Nx, Ny, Lx, Ly, u1_func, u2_func = case\n\n        # 1. Create the uniform, periodic grid\n        dx = Lx / Nx\n        dy = Ly / Ny\n        x_coords = np.arange(Nx) * dx\n        y_coords = np.arange(Ny) * dy\n        X, Y = np.meshgrid(x_coords, y_coords, indexing='ij')\n\n        # 2. Generate the discrete velocity fields u1 and u2\n        u1 = u1_func(X, Y)\n        u2 = u2_func(X, Y)\n\n        # 3. Apply the test filter\n        # The scale-similarity stress is τ_12^sim = ~(u1*u2) - ~u1 * ~u2\n        # where ~ denotes the test-filtering operation.\n\n        # First, filter the individual velocity components\n        u1_tilde = convolve(u1, kernel, mode='wrap')\n        u2_tilde = convolve(u2, kernel, mode='wrap')\n\n        # Second, form the product field and filter it\n        u1u2 = u1 * u2\n        u1u2_tilde = convolve(u1u2, kernel, mode='wrap')\n\n        # 4. Compute the scale-similarity stress field\n        tau12_sim = u1u2_tilde - u1_tilde * u2_tilde\n\n        # 5. Calculate the root-mean-square (RMS) of the stress field\n        # RMS = sqrt( mean( (τ_12)^2 ) )\n        rms_val = np.sqrt(np.mean(np.square(tau12_sim)))\n        results.append(rms_val)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While the conceptual form of a filter is simple, its discrete implementation carries nuances that are critical for the physical fidelity of a simulation. In computational fluid dynamics, respecting fundamental conservation laws, such as the conservation of momentum, is paramount. A poorly implemented filter can act as an artificial source or sink of momentum, leading to unphysical simulation results. This practice  illuminates how choices in kernel normalization and boundary handling can violate conservation and provides a hands-on method to diagnose and correct these errors, ensuring your numerical tools are robust and reliable.",
            "id": "3360731",
            "problem": "Consider a discrete one-dimensional, incompressible, constant-density flow field used in Large-Eddy Simulation (LES) with a scale-similarity subgrid model, where filtering is used to define both the grid filter and the test filter. Let the domain length be $L=1$ and let the computational mesh have $N$ uniformly spaced nodes at locations $x_n = n/N$ for $n=0,1,\\dots,N-1$, with spacing $\\Delta x = 1/N$. Let the density be $\\rho=1$. The discrete total resolved momentum is\n$$\nM = \\sum_{n=0}^{N-1} u_n \\,\\Delta x.\n$$\nA linear discrete filter with a compact stencil is defined by coefficients $g_m$ for $m=-r,\\dots,r$ and produces a filtered field\n$$\n\\tilde{u}_n = \\sum_{m=-r}^{r} g_m\\, \\mathcal{B}(u_{n+m}),\n$$\nwhere $\\mathcal{B}$ denotes the boundary handling operator. Two boundary handling choices are considered:\n- Periodic wrapping: $\\mathcal{B}(u_{n+m}) = u_{(n+m) \\bmod N}$.\n- Zero padding: $\\mathcal{B}(u_{n+m}) = 0$ if $n+m \\notin \\{0,1,\\dots,N-1\\}$ and $\\mathcal{B}(u_{n+m}) = u_{n+m}$ otherwise.\n\nA nonconservative implementation of the filter is any implementation in which either the kernel does not satisfy $\\sum_{m=-r}^{r} g_m = 1$ or the boundary handling destroys the invariance of the domain average (for example, zero padding without near-boundary renormalization). This can spuriously alter the globally conserved momentum $M$ in a closed or periodic setting.\n\nTask: Starting from conservation of momentum for incompressible flow and the linearity of filtering, derive when the discrete filter preserves the global momentum. Then, for each test case below, compute the absolute global momentum error introduced by the nonconservative filter,\n$$\nE_{\\mathrm{nc}} = \\left| \\sum_{n=0}^{N-1} \\tilde{u}^{(\\mathrm{nc})}_n \\,\\Delta x - \\sum_{n=0}^{N-1} u_n \\,\\Delta x \\right|,\n$$\nand propose and implement a conservative fix that enforces exact global momentum conservation by an a posteriori correction. Specifically, after computing the nonconservative filtered field $\\tilde{u}^{(\\mathrm{nc})}_n$, define a uniform correction $c$ by\n$$\nc = \\frac{1}{N}\\sum_{n=0}^{N-1} \\left(u_n - \\tilde{u}^{(\\mathrm{nc})}_n\\right),\n$$\nand set the corrected filtered field $\\tilde{u}^{(\\mathrm{fix})}_n = \\tilde{u}^{(\\mathrm{nc})}_n + c$. Then compute the post-fix absolute momentum error,\n$$\nE_{\\mathrm{fix}} = \\left| \\sum_{n=0}^{N-1} \\tilde{u}^{(\\mathrm{fix})}_n \\,\\Delta x - \\sum_{n=0}^{N-1} u_n \\,\\Delta x \\right|.\n$$\nYou must produce both $E_{\\mathrm{nc}}$ and $E_{\\mathrm{fix}}$ for each test.\n\nAll quantities are nondimensional; no physical units are required.\n\nTest Suite:\n- Test $1$ (unnormalized kernel, periodic boundary). Parameters: $N=16$; define $u_n = A + B \\sin(2\\pi k x_n)$ with $A=0.3$, $B=1.1$, $k=3$; use kernel $g = [1,2,1]$ (so $r=1$) with periodic wrapping for $\\mathcal{B}$.\n- Test $2$ (normalized kernel, zero padding boundary). Parameters: $N=32$; define $u_n = A + B \\sin(2\\pi k x_n)$ with $A=0.5$, $B=0.7$, $k=5$; use kernel $g = [1,4,6,4,1]/16$ (so $r=2$) with zero padding for $\\mathcal{B}$.\n- Test $3$ (constant field, sub-unity-sum kernel, periodic boundary). Parameters: $N=15$; define $u_n = C$ with $C=0.7$; use kernel $g=[2,5,2]/10$ (so $r=1$) with periodic wrapping for $\\mathcal{B}$.\n\nFor each test, compute $E_{\\mathrm{nc}}$ and $E_{\\mathrm{fix}}$ as defined above. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the following order: $[E_{\\mathrm{nc}}^{(1)},E_{\\mathrm{fix}}^{(1)},E_{\\mathrm{nc}}^{(2)},E_{\\mathrm{fix}}^{(2)},E_{\\mathrm{nc}}^{(3)},E_{\\mathrm{fix}}^{(3)}]$. Each list entry must be a real number (floating-point).",
            "solution": "The problem requires an analysis of momentum conservation for a discrete one-dimensional filter and the implementation of a numerical test to quantify and correct non-conservation errors.\n\n**Part 1: Derivation of the Discrete Momentum Conservation Condition**\n\nThe total discrete momentum $M$ for a constant-density flow with $\\rho=1$ in a domain of length $L=1$ discretized into $N$ nodes is given by\n$$\nM = \\sum_{n=0}^{N-1} u_n \\,\\Delta x,\n$$\nwhere $u_n$ is the velocity at node $x_n = n/N$ and $\\Delta x = 1/N$ is the uniform grid spacing.\n\nA linear filter operates on the field $u_n$ to produce a filtered field $\\tilde{u}_n$ according to\n$$\n\\tilde{u}_n = \\sum_{m=-r}^{r} g_m\\, \\mathcal{B}(u_{n+m}),\n$$\nwhere $g_m$ are the filter kernel coefficients and $\\mathcal{B}$ is the boundary handling operator. The total momentum of the filtered field, $\\tilde{M}$, is\n$$\n\\tilde{M} = \\sum_{n=0}^{N-1} \\tilde{u}_n \\,\\Delta x.\n$$\nSubstituting the filter definition into the expression for $\\tilde{M}$ yields\n$$\n\\tilde{M} = \\sum_{n=0}^{N-1} \\left( \\sum_{m=-r}^{r} g_m\\, \\mathcal{B}(u_{n+m}) \\right) \\Delta x.\n$$\nBy the linearity of summation, we can exchange the order of the sums:\n$$\n\\tilde{M} = \\Delta x \\sum_{m=-r}^{r} g_m \\left( \\sum_{n=0}^{N-1} \\mathcal{B}(u_{n+m}) \\right).\n$$\nFor the filter to be conservative, we must have $\\tilde{M} = M$. Let's analyze the inner sum, $\\sum_{n=0}^{N-1} \\mathcal{B}(u_{n+m})$, for the two specified boundary conditions.\n\n**Case 1: Periodic Wrapping**\nWith periodic boundaries, the operator is defined as $\\mathcal{B}(u_{n+m}) = u_{(n+m) \\bmod N}$. The inner sum becomes\n$$\n\\sum_{n=0}^{N-1} u_{(n+m) \\bmod N}.\n$$\nFor any fixed integer shift $m$, the set of indices $\\{(n+m) \\bmod N \\mid n=0, 1, \\dots, N-1\\}$ is a permutation of the set $\\{0, 1, \\dots, N-1\\}$. Therefore, the sum over the permuted indices is equal to the sum over the original indices:\n$$\n\\sum_{n=0}^{N-1} u_{(n+m) \\bmod N} = \\sum_{j=0}^{N-1} u_j.\n$$\nSubstituting this result back into the expression for $\\tilde{M}$:\n$$\n\\tilde{M} = \\Delta x \\sum_{m=-r}^{r} g_m \\left( \\sum_{j=0}^{N-1} u_j \\right) = \\left( \\sum_{m=-r}^{r} g_m \\right) \\left( \\sum_{j=0}^{N-1} u_j \\Delta x \\right) = \\left( \\sum_{m=-r}^{r} g_m \\right) M.\n$$\nIn this case, momentum is conserved ($\\tilde{M} = M$) if and only if the filter kernel coefficients sum to unity:\n$$\n\\sum_{m=-r}^{r} g_m = 1.\n$$\n\n**Case 2: Zero Padding**\nWith zero padding, $\\mathcal{B}(u_{k}) = 0$ for $k \\notin \\{0, 1, \\dots, N-1\\}$. The inner sum $\\sum_{n=0}^{N-1} \\mathcal{B}(u_{n+m})$ no longer equals $\\sum_j u_j$. For example, if $m > 0$, the sum $\\sum_{n=0}^{N-1} \\mathcal{B}(u_{n+m})$ will be missing terms corresponding to $u_{N-1}, u_{N-2}, \\dots, u_{N-m}$, as their indices $n+m$ would exceed $N-1$ for the last few values of $n$. Specifically, terms are non-zero only for $n$ such that $0 \\le n+m \\le N-1$, i.e., $0 \\le n \\le N-1-m$. The sum becomes $\\sum_{n=0}^{N-1-m} u_{n+m}$. This sum is clearly not equal to the total sum $\\sum_j u_j$. Consequently, even if $\\sum_m g_m = 1$, the total filtered momentum $\\tilde{M}$ will not equal $M$. The filter is inherently non-conservative as it causes a loss of momentum information at the boundaries.\n\n**Part 2: Analysis of the A Posteriori Correction**\n\nThe problem defines a nonconservative filtered field $\\tilde{u}^{(\\mathrm{nc})}_n$ and proposes a correction to create a new field $\\tilde{u}^{(\\mathrm{fix})}_n = \\tilde{u}^{(\\mathrm{nc})}_n + c$, where $c$ is a uniform correction term. The goal is to enforce momentum conservation after the fact. The correction is defined as\n$$\nc = \\frac{1}{N}\\sum_{j=0}^{N-1} \\left(u_j - \\tilde{u}^{(\\mathrm{nc})}_j\\right).\n$$\nThe total momentum of the corrected field, $M_{\\mathrm{fix}}$, is\n$$\nM_{\\mathrm{fix}} = \\sum_{n=0}^{N-1} \\tilde{u}^{(\\mathrm{fix})}_n \\,\\Delta x = \\sum_{n=0}^{N-1} (\\tilde{u}^{(\\mathrm{nc})}_n + c) \\,\\Delta x.\n$$\nSeparating the terms in the sum:\n$$\nM_{\\mathrm{fix}} = \\left( \\sum_{n=0}^{N-1} \\tilde{u}^{(\\mathrm{nc})}_n \\Delta x \\right) + \\left( \\sum_{n=0}^{N-1} c \\Delta x \\right).\n$$\nThe first term is the nonconservative momentum, $M_{\\mathrm{nc}}$. The second term simplifies to\n$$\n\\sum_{n=0}^{N-1} c \\Delta x = c \\sum_{n=0}^{N-1} \\Delta x = c \\cdot N \\cdot \\Delta x.\n$$\nSince $\\Delta x = 1/N$, we have $N \\Delta x = 1$, and the term becomes simply $c$. Thus,\n$$\nM_{\\mathrm{fix}} = M_{\\mathrm{nc}} + c.\n$$\nNow, let's rewrite the definition of $c$ using momentum terms.\n$$\nc = \\frac{1}{N}\\sum_j u_j - \\frac{1}{N}\\sum_j \\tilde{u}^{(\\mathrm{nc})}_j = \\left( \\sum_j u_j \\Delta x \\right) - \\left( \\sum_j \\tilde{u}^{(\\mathrm{nc})}_j \\Delta x \\right) = M - M_{\\mathrm{nc}}.\n$$\nSubstituting this expression for $c$ back into the equation for $M_{\\mathrm{fix}}$:\n$$\nM_{\\mathrm{fix}} = M_{\\mathrm{nc}} + (M - M_{\\mathrm{nc}}) = M.\n$$\nThis proves that the total momentum of the corrected field is analytically identical to the total momentum of the original field. Therefore, the post-fix absolute momentum error,\n$$\nE_{\\mathrm{fix}} = \\left| \\sum_{n=0}^{N-1} \\tilde{u}^{(\\mathrm{fix})}_n \\,\\Delta x - \\sum_{n=0}^{N-1} u_n \\,\\Delta x \\right| = |M_{\\mathrm{fix}} - M|,\n$$\nis analytically zero. Any non-zero value in a numerical implementation will be solely due to floating-point precision limitations.\n\n**Part 3: Numerical Implementation**\n\nThe calculations for each test case will be performed programmatically. A function will be implemented to apply the discrete filter. This is a discrete convolution operation. For the symmetric kernels given in all test cases, the standard convolution function `scipy.ndimage.convolve1d` can be used directly. The `mode` parameter of this function maps directly to the required boundary conditions: `'wrap'` for periodic wrapping and `'constant'` with `cval=0.0` for zero padding.\n\nFor each test case, the following steps are executed:\n1.  The computational grid $x_n$ and the initial velocity field $u_n$ are constructed.\n2.  The nonconservatively filtered field $\\tilde{u}^{(\\mathrm{nc})}_n$ is computed by applying the specified kernel and boundary condition.\n3.  The original momentum $M$ and nonconservative momentum $M_{\\mathrm{nc}}$ are calculated by summing the respective fields and multiplying by $\\Delta x = 1/N$.\n4.  The nonconservative error $E_{\\mathrm{nc}} = |M_{\\mathrm{nc}} - M|$ is computed.\n5.  The correction term $c$ is computed based on its definition, which simplifies to $c = (M - M_{\\mathrm{nc}})$.\n6.  The corrected field $\\tilde{u}^{(\\mathrm{fix})}_n$ is obtained by adding $c$ to $\\tilde{u}^{(\\mathrm{nc})}_n$.\n7.  The corrected momentum $M_{\\mathrm{fix}}$ is calculated and used to find the post-fix error $E_{\\mathrm{fix}} = |M_{\\mathrm{fix}} - M|$, which is expected to be zero to machine precision.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.ndimage import convolve1d\n\ndef solve():\n    \"\"\"\n    Computes momentum errors for several filtering test cases and a conservation-restoring fix.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test 1: Unnormalized kernel, periodic boundary\n        {'N': 16, 'u_func': lambda x: 0.3 + 1.1 * np.sin(2 * np.pi * 3 * x), \n         'kernel': np.array([1, 2, 1]), 'boundary_mode': 'periodic'},\n        \n        # Test 2: Normalized kernel, zero padding boundary\n        {'N': 32, 'u_func': lambda x: 0.5 + 0.7 * np.sin(2 * np.pi * 5 * x),\n         'kernel': np.array([1, 4, 6, 4, 1]) / 16.0, 'boundary_mode': 'zeropadding'},\n        \n        # Test 3: Constant field, sub-unity-sum kernel, periodic boundary\n        {'N': 15, 'u_func': lambda x: 0.7 + 0.0 * x, # u_n = C\n         'kernel': np.array([2, 5, 2]) / 10.0, 'boundary_mode': 'periodic'}\n    ]\n\n    results = []\n\n    for case in test_cases:\n        N = case['N']\n        u_func = case['u_func']\n        kernel = case['kernel']\n        boundary_mode = case['boundary_mode']\n        \n        # 1. Construct the grid and initial velocity field\n        dx = 1.0 / N\n        x = np.arange(N) * dx\n        u = u_func(x)\n        \n        # 2. Apply the nonconservative filter\n        if boundary_mode == 'periodic':\n            # scipy.ndimage.convolve1d 'wrap' mode handles periodic boundaries\n            u_tilde_nc = convolve1d(u, kernel, mode='wrap')\n        elif boundary_mode == 'zeropadding':\n            # 'constant' mode with cval=0.0 handles zero padding\n            u_tilde_nc = convolve1d(u, kernel, mode='constant', cval=0.0)\n        \n        # 3. Calculate original and nonconservative momentum\n        M_orig = np.sum(u) * dx\n        M_nc = np.sum(u_tilde_nc) * dx\n        \n        # 4. Compute the nonconservative error\n        E_nc = np.abs(M_nc - M_orig)\n        \n        # 5. Compute the uniform correction term\n        # c = (1/N) * sum(u - u_tilde_nc) = dx * sum(u - u_tilde_nc)\n        c = dx * np.sum(u - u_tilde_nc) \n        \n        # 6. Apply the correction to get the fixed field\n        u_tilde_fix = u_tilde_nc + c\n        \n        # 7. Calculate the post-fix momentum and error\n        M_fix = np.sum(u_tilde_fix) * dx\n        E_fix = np.abs(M_fix - M_orig)\n        \n        results.extend([E_nc, E_fix])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A limitation of static models is their use of a constant coefficient, which cannot adapt to the diverse conditions within a turbulent flow. The dynamic procedure, rooted in the Germano identity, revolutionizes this by determining the model coefficient \"on the fly\" from the resolved flow field itself. This allows the subgrid-scale model to adjust its intensity based on the local flow characteristics. This advanced exercise  provides a comprehensive walkthrough of implementing the dynamic procedure for a scale-similarity model, from computing the necessary tensor fields to determining both local and globally-averaged coefficients, offering deep insight into the adaptive nature of modern LES.",
            "id": "3360733",
            "problem": "Consider the Large-Eddy Simulation (LES) of an incompressible flow, where the filtered velocity field is denoted by $\\bar{u}_i(x,t)$ and the subgrid-scale (SGS) stress tensor is defined as $\\tau_{ij} = \\overline{u_i u_j} - \\bar{u}_i \\bar{u}_j$. Let the Germano identity be written in terms of a test filter (denoted by a hat) of width $\\hat{\\Delta} = \\alpha \\Delta$, with $\\alpha  1$, as $L_{ij} = \\widehat{\\bar{u}_i \\bar{u}_j} - \\hat{\\bar{u}}_i \\hat{\\bar{u}}_j = T_{ij} - \\widehat{\\tau_{ij}}$. Consider a scale-similarity model with an adjustable coefficient $C$, where the modeled SGS stress at the grid scale is $\\tau^{m}_{ij} = C B_{ij}(\\bar{\\mathbf{u}})$ and the scale-similarity tensor $B_{ij}$ is constructed using an auxiliary Gaussian filter (denoted by a tilde) of width $\\Delta$ applied to the resolved field:\n$$\nB_{ij}(\\bar{\\mathbf{u}}) = \\widetilde{\\bar{u}_i \\bar{u}_j} - \\tilde{\\bar{u}}_i \\tilde{\\bar{u}}_j.\n$$\nAt the test-filter level, the same model form gives $T^{m}_{ij} = C B_{ij}(\\hat{\\bar{\\mathbf{u}}})$. The dynamic procedure determines $C$ by least squares using the identity\n$$\nL_{ij} \\approx C \\left( B_{ij}(\\hat{\\bar{\\mathbf{u}}}) - \\widehat{B_{ij}(\\bar{\\mathbf{u}})} \\right) \\equiv C H_{ij},\n$$\nwhere $H_{ij} = B_{ij}(\\hat{\\bar{\\mathbf{u}}}) - \\widehat{B_{ij}(\\bar{\\mathbf{u}})}$. To remove the isotropic part that is dynamically unresolvable, use the deviatoric projection in $d$ spatial dimensions, $A_{ij}^{\\prime} = A_{ij} - \\frac{1}{d} A_{kk} \\delta_{ij}$, with $d = 2$. The coefficient can be determined locally as\n$$\nC(\\mathbf{x},t) = \\frac{\\sum_{i,j} L_{ij}^{\\prime} H_{ij}^{\\prime}}{\\sum_{i,j} H_{ij}^{\\prime} H_{ij}^{\\prime}},\n$$\nand in the sense of the Germano-Lilly global least-squares average as\n$$\nC_{\\text{Lilly}}(t) = \\frac{\\left\\langle \\sum_{i,j} L_{ij}^{\\prime} H_{ij}^{\\prime} \\right\\rangle}{\\left\\langle \\sum_{i,j} H_{ij}^{\\prime} H_{ij}^{\\prime} \\right\\rangle},\n$$\nwhere $\\langle \\cdot \\rangle$ denotes spatial averaging and the index sums are defined over symmetric components with the convention $\\sum_{i,j} A_{ij} B_{ij} \\equiv A_{11} B_{11} + 2 A_{12} B_{12} + A_{22} B_{22}$ in two dimensions.\n\nAdopt a periodic square domain of side length $L = 2\\pi$, discretized uniformly with $N \\times N$ points. Define the resolved velocity field using the Taylor-Green vortex as\n$$\n\\bar{u}(x,y,t) = U_0 \\sin(k x) \\cos(k y) \\mathrm{e}^{-2 \\nu k^2 t}, \\qquad\n\\bar{v}(x,y,t) = - U_0 \\cos(k x) \\sin(k y) \\mathrm{e}^{-2 \\nu k^2 t},\n$$\nwith parameters $U_0  0$, $k \\in \\mathbb{N}$, and kinematic viscosity $\\nu  0$. Use a Gaussian filter operator of width $\\Delta$ whose Fourier transfer function is\n$$\n\\widehat{G}_\\Delta(\\mathbf{k}) = \\exp\\left( - \\tfrac{1}{2} \\sigma^2 |\\mathbf{k}|^2 \\right), \\quad \\text{with } \\sigma = \\frac{\\Delta}{\\sqrt{12}},\n$$\nso that the filter has the same second moment as a top-hat of width $\\Delta$. Let the grid spacing be $\\Delta x = \\Delta y = L/N$ and set the auxiliary similarity filter width to $\\Delta = 2 \\Delta x$. The test filter width is $\\hat{\\Delta} = \\alpha \\Delta$.\n\nTask: Write a complete program that, for each parameter pair $(\\alpha, t)$ in the test suite below, computes:\n- the global dynamic coefficient $C_{\\text{Lilly}}(t)$,\n- the spatial mean of the local coefficient $\\langle C(\\mathbf{x},t) \\rangle$ restricted to points where the denominator is strictly positive,\n- the spatial standard deviation of the local coefficient over those points.\n\nAll three reported quantities must be dimensionless real numbers. In computing $C(\\mathbf{x},t)$, if the local denominator $\\sum_{i,j} H_{ij}^{\\prime} H_{ij}^{\\prime}$ is smaller than a small threshold $\\varepsilon$, set $C(\\mathbf{x},t) = 0$ at that point to avoid division by zero. Use $\\varepsilon = 10^{-12}$.\n\nUse $N = 64$, $L = 2\\pi$, $U_0 = 1$, $k = 1$, and $\\nu = 10^{-2}$. Angles in trigonometric functions must be in radians. There are no physical units to report for the outputs; all outputs are pure numbers.\n\nTest suite:\n- Case $1$: $(\\alpha, t) = (1.1, 0)$, a near-identity test filter to probe the boundary where the Germano identity becomes ill-conditioned.\n- Case $2$: $(\\alpha, t) = (2.0, 0)$, a canonical dynamic test near initialization.\n- Case $3$: $(\\alpha, t) = (2.0, 1.0)$, same filter ratio at a later time to assess temporal behavior.\n- Case $4$: $(\\alpha, t) = (3.0, 0.5)$, a stronger test filter to probe scale separation effects.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sublist of three floating-point numbers in the order $[C_{\\text{Lilly}}, \\langle C \\rangle, \\mathrm{std}(C)]$. For example, the final output format must be\n$$\n\\texttt{[[c\\_1, m\\_1, s\\_1],[c\\_2, m\\_2, s\\_2],[c\\_3, m\\_3, s\\_3],[c\\_4, m\\_4, s\\_4]]}\n$$\nwith each $c_i$, $m_i$, and $s_i$ a floating-point number.",
            "solution": "The problem requires the implementation of the dynamic procedure for a scale-similarity subgrid-scale (SGS) model. The solution is executed numerically for a specified analytical velocity field (the Taylor-Green vortex) on a periodic 2D domain. The core of the method involves computing several tensor fields using Fourier-based filtering and then using them to solve for the model coefficient.\n\n**1. Numerical Framework and Filtering**\n\nGiven the periodic domain and the definition of the filters as convolutions, all filtering operations are most efficiently performed in Fourier space using the Fast Fourier Transform (FFT). The process for filtering a field `f` is:\n1.  Compute the 2D FFT of the field: $\\mathcal{F}\\{f\\}$.\n2.  Multiply element-wise by the filter's transfer function in Fourier space, e.g., $\\widehat{G}(\\mathbf{k})$.\n3.  Compute the inverse 2D FFT of the result: $\\mathcal{F}^{-1}\\{\\mathcal{F}\\{f\\} \\cdot \\widehat{G}(\\mathbf{k})\\}$.\n\nWe need to construct the transfer functions for the auxiliary filter (`tilde`) and the test filter (`hat`) based on their respective widths, $\\Delta$ and $\\hat{\\Delta}$, and the discrete wavenumber grid.\n\n**2. Computation of Required Tensor Fields**\n\nThe dynamic procedure is based on the Germano identity, which leads to the equation $L_{ij} \\approx C H_{ij}$. We must compute the fields for the Leonard tensor $L_{ij}$ and the model tensor $H_{ij}$.\n\n*   **Leonard Tensor ($L_{ij}$)**:\n    This tensor represents the stresses resolved between the grid and test filter scales. It is defined as $L_{ij} = \\widehat{\\bar{u}_i \\bar{u}_j} - \\hat{\\bar{u}}_i \\hat{\\bar{u}}_j$.\n    The calculation steps are:\n    1.  Compute the product fields $\\bar{u}_i \\bar{u}_j$ (i.e., $\\bar{u}^2, \\bar{u}\\bar{v}, \\bar{v}^2$).\n    2.  Apply the test filter (`hat`) to each product field to get $\\widehat{\\bar{u}_i \\bar{u}_j}$.\n    3.  Apply the test filter (`hat`) to the velocity components $\\bar{u}_i$ to get $\\hat{\\bar{u}}_i$.\n    4.  Compute the products of the filtered velocities, $\\hat{\\bar{u}}_i \\hat{\\bar{u}}_j$.\n    5.  Subtract the results from step 4 from step 2.\n\n*   **Model Tensor ($H_{ij}$)**:\n    This tensor is the difference between the model applied at the test-filter scale and the test-filtered model at the grid scale: $H_{ij} = B_{ij}(\\hat{\\bar{\\mathbf{u}}}) - \\widehat{B_{ij}(\\bar{\\mathbf{u}})}$.\n\n    *   **Term 1: $B_{ij}(\\hat{\\bar{\\mathbf{u}}})$**: This is the scale-similarity model tensor $B$ applied to the test-filtered velocity field $\\hat{\\bar{\\mathbf{u}}}$. The definition is $B_{ij}(\\hat{\\bar{\\mathbf{u}}}) = \\widetilde{\\hat{\\bar{u}}_i \\hat{\\bar{u}}_j} - \\tilde{\\hat{\\bar{u}}}_i \\tilde{\\hat{\\bar{u}}}_j$. The term $\\tilde{\\hat{\\bar{u}}}_i$ requires applying the `tilde` filter to the already `hat`-filtered velocity. This is equivalent to applying a composite filter with transfer function $\\widehat{G}(\\mathbf{k})\\widetilde{G}(\\mathbf{k})$ to the original velocity $\\bar{u}_i$.\n    *   **Term 2: $\\widehat{B_{ij}(\\bar{\\mathbf{u}})}$**: This requires first computing the scale-similarity tensor on the original grid-filtered field, $B_{ij}(\\bar{\\mathbf{u}}) = \\widetilde{\\bar{u}_i \\bar{u}_j} - \\tilde{\\bar{u}}_i \\tilde{\\bar{u}}_j$, and then applying the test filter (`hat`) to each component of the resulting tensor field $B_{ij}$.\n\n**3. Deviatoric Projection and Coefficient Calculation**\n\nFor an incompressible flow, the dynamic procedure can only determine the deviatoric (trace-free) part of the stress. We project $L_{ij}$ and $H_{ij}$ to their deviatoric parts, denoted $L'_{ij}$ and $H'_{ij}$. In 2D, for a symmetric tensor $A$, the projection is $A'_{11} = \\frac{1}{2}(A_{11}-A_{22})$, $A'_{22} = -A'_{11}$, and $A'_{12}=A_{12}$.\n\nThe double contraction (dot product) used in the least-squares procedure is defined as $\\sum_{i,j} A_{ij} B_{ij} = A_{11}B_{11} + 2A_{12}B_{12} + A_{22}B_{22}$. This is computed pointwise to get the fields $N_C(\\mathbf{x}) = \\sum_{i,j} L'_{ij} H'_{ij}$ and $D_C(\\mathbf{x}) = \\sum_{i,j} H'_{ij} H'_{ij}$.\n\n*   **Global Lilly Coefficient ($C_{\\text{Lilly}}$)**: This is the ratio of the spatial averages of the numerator and denominator fields:\n    $$ C_{\\text{Lilly}} = \\frac{\\langle N_C \\rangle}{\\langle D_C \\rangle} $$\n*   **Local Coefficient ($C(\\mathbf{x},t)$)**: This is the pointwise ratio:\n    $$ C(\\mathbf{x},t) = \\frac{N_C(\\mathbf{x})}{D_C(\\mathbf{x})} $$\n    To prevent division by zero or near-zero values, a threshold $\\varepsilon$ is used. If $D_C(\\mathbf{x})  \\varepsilon$, the local coefficient is set to 0.\n\nFinally, the spatial mean and standard deviation of the valid local coefficients (where $D_C \\ge \\varepsilon$) are computed for each test case. This entire procedure is then repeated for each $(\\alpha, t)$ pair specified in the problem.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    \n    # Define problem parameters\n    N = 64\n    L = 2 * np.pi\n    U0 = 1.0\n    k_wave = 1.0  # Renamed from k to avoid conflict with wavenumber arrays\n    nu = 1e-2\n    epsilon = 1e-12\n\n    # Define test cases from the problem statement\n    test_cases = [\n        (1.1, 0.0),\n        (2.0, 0.0),\n        (2.0, 1.0),\n        (3.0, 0.5),\n    ]\n\n    # Setup grid and wavenumbers\n    dx = L / N\n    x_coords = np.arange(N) * dx\n    x, y = np.meshgrid(x_coords, x_coords, indexing='ij')\n    \n    k_coords = np.fft.fftfreq(N, d=dx) * 2 * np.pi\n    kx, ky = np.meshgrid(k_coords, k_coords, indexing='ij')\n    k_sq = kx**2 + ky**2\n\n    # Helper for filtering\n    def filter_field(field, kernel):\n        \"\"\"Applies a filter in Fourier space.\"\"\"\n        return np.fft.ifft2(np.fft.fft2(field) * kernel).real\n\n    results = []\n    for alpha, t in test_cases:\n        # Define filter kernels for the current case\n        delta_aux = 2 * dx\n        sigma_aux = delta_aux / np.sqrt(12)\n        G_tilde = np.exp(-0.5 * sigma_aux**2 * k_sq)\n        \n        delta_test = alpha * delta_aux\n        sigma_test = delta_test / np.sqrt(12)\n        G_hat = np.exp(-0.5 * sigma_test**2 * k_sq)\n        \n        G_hat_tilde = G_hat * G_tilde\n    \n        # Define velocity field at time t\n        decay = np.exp(-2 * nu * k_wave**2 * t)\n        u_bar = U0 * np.sin(k_wave * x) * np.cos(k_wave * y) * decay\n        v_bar = -U0 * np.cos(k_wave * x) * np.sin(k_wave * y) * decay\n        \n        # --- Calculate Leonard Tensor L_ij ---\n        u_bar_u_bar = u_bar * u_bar\n        u_bar_v_bar = u_bar * v_bar\n        v_bar_v_bar = v_bar * v_bar\n    \n        u_bar_hat = filter_field(u_bar, G_hat)\n        v_bar_hat = filter_field(v_bar, G_hat)\n    \n        L11 = filter_field(u_bar_u_bar, G_hat) - u_bar_hat * u_bar_hat\n        L12 = filter_field(u_bar_v_bar, G_hat) - u_bar_hat * v_bar_hat\n        L22 = filter_field(v_bar_v_bar, G_hat) - v_bar_hat * v_bar_hat\n        \n        # --- Calculate Scale-Similarity Tensor B_ij(u_bar) ---\n        u_bar_tilde = filter_field(u_bar, G_tilde)\n        v_bar_tilde = filter_field(v_bar, G_tilde)\n    \n        B11_ubar = filter_field(u_bar_u_bar, G_tilde) - u_bar_tilde * u_bar_tilde\n        B12_ubar = filter_field(u_bar_v_bar, G_tilde) - u_bar_tilde * v_bar_tilde\n        B22_ubar = filter_field(v_bar_v_bar, G_tilde) - v_bar_tilde * v_bar_tilde\n        \n        # --- Calculate Model Tensor H_ij ---\n        # Term 1: B_ij(u_bar_hat)\n        u_bar_hat_u_bar_hat = u_bar_hat * u_bar_hat\n        u_bar_hat_v_bar_hat = u_bar_hat * v_bar_hat\n        v_bar_hat_v_bar_hat = v_bar_hat * v_bar_hat\n        \n        u_bar_hat_tilde = filter_field(u_bar, G_hat_tilde)\n        v_bar_hat_tilde = filter_field(v_bar, G_hat_tilde)\n        \n        B11_of_ubar_hat = filter_field(u_bar_hat_u_bar_hat, G_tilde) - u_bar_hat_tilde * u_bar_hat_tilde\n        B12_of_ubar_hat = filter_field(u_bar_hat_v_bar_hat, G_tilde) - u_bar_hat_tilde * v_bar_hat_tilde\n        B22_of_ubar_hat = filter_field(v_bar_hat_v_bar_hat, G_tilde) - v_bar_hat_tilde * v_bar_hat_tilde\n        \n        # Term 2: hat(B_ij(u_bar))\n        B11_ubar_filtered = filter_field(B11_ubar, G_hat)\n        B12_ubar_filtered = filter_field(B12_ubar, G_hat)\n        B22_ubar_filtered = filter_field(B22_ubar, G_hat)\n\n        # Combine for H_ij\n        H11 = B11_of_ubar_hat - B11_ubar_filtered\n        H12 = B12_of_ubar_hat - B12_ubar_filtered\n        H22 = B22_of_ubar_hat - B22_ubar_filtered\n        \n        # --- Deviatoric Projections ---\n        L11_p = 0.5 * (L11 - L22)\n        H11_p = 0.5 * (H11 - H22)\n        \n        # --- Calculate Dot Products for Coefficients ---\n        # The sum sum_ij A'_ij B'_ij for traceless symmetric 2D tensors is 2*(A'_11*B'_11 + A_12*B_12).\n        # The factor of 2 cancels in the ratio for C.\n        numerator_term = L11_p * H11_p + L12 * H12\n        denominator_term = H11_p**2 + H12**2\n        \n        # --- Calculate Coefficients ---\n        # Global Lilly coefficient\n        mean_denom = np.mean(denominator_term)\n        c_lilly = np.mean(numerator_term) / mean_denom if mean_denom != 0 else 0.0\n        \n        # Local coefficient\n        c_local = np.zeros_like(numerator_term)\n        mask = denominator_term > epsilon\n        c_local[mask] = numerator_term[mask] / denominator_term[mask]\n        \n        # Statistics on valid local coefficients\n        c_local_valid = c_local[mask]\n        if c_local_valid.size > 0:\n            c_mean = np.mean(c_local_valid)\n            c_std = np.std(c_local_valid)\n        else:\n            c_mean = 0.0\n            c_std = 0.0\n            \n        results.append([c_lilly, c_mean, c_std])\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"[{r[0]},{r[1]},{r[2]}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}