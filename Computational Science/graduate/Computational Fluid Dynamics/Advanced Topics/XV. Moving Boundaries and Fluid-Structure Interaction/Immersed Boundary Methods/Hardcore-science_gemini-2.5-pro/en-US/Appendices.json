{
    "hands_on_practices": [
        {
            "introduction": "This exercise goes to the heart of sharp-interface immersed boundary methods by asking you to derive custom finite-difference stencils. When a boundary cuts through a Cartesian grid, standard stencils are no longer valid, and this practice guides you through using polynomial interpolation to construct modified, high-order accurate approximations for derivatives at fluid nodes adjacent to the boundary. Mastering this technique is fundamental to implementing ghost-cell and other sharp-interface methods that accurately enforce boundary conditions without sacrificing the overall order of accuracy of the numerical scheme .",
            "id": "3332789",
            "problem": "Consider a two-dimensional uniform Cartesian grid with spacing $h$ in both the $x$ and $y$ directions. A sharp-interface immersed boundary intersects the grid segment between the fluid node at $x_0$ and the exterior node at $x_{-1} = x_0 - h$. The boundary location is $x_b = x_0 - \\alpha h$ with $0 < \\alpha < 1$. A Dirichlet boundary condition is prescribed at the immersed boundary, so that $u(x_b) = u_b$ is known. Let $u_0 = u(x_0)$ and $u_1 = u(x_1)$ denote the fluid values at $x_0$ and its neighbor $x_1 = x_0 + h$ along the $x$ axis. Assume $u$ is sufficiently smooth.\n\nUsing only definitions of derivatives and Taylor series expansions, derive modified finite-difference stencils appropriate to a sharp-interface immersed boundary method as follows:\n\n- Construct a quadratic interpolant in $x$ that uses the three data points $(x_b, u_b)$, $(x_0, u_0)$, and $(x_1, u_1)$. Use this interpolant to obtain a one-sided, second-order accurate formula for the $x$-gradient $u_x$ at the fluid node $x_0$. Express the resulting stencil coefficients explicitly in terms of $\\alpha$.\n- Using the same quadratic interpolant, derive a modified one-sided approximation for the $x$-second derivative $u_{xx}$ at $x_0$. Combine this with a standard centered second-difference in $y$ to form a discrete Laplacian near the boundary. Determine the leading-order truncation error terms for the $x$-gradient and for the Laplacian. Discuss, in terms of orders and leading coefficients, how the one-sided $x$-discretization induces anisotropy in the truncation error compared to the centered $y$-discretization.\n\nFinally, let the local truncation error of the $x$-gradient approximation at $x_0$ be written in the form\n$$\nu_x(x_0)_{\\text{approx}} - u_x(x_0) = C(\\alpha)\\, h^{2}\\, u_{xxx}(x_0) + \\mathcal{O}(h^{3}),\n$$\nwhere $C(\\alpha)$ is a dimensionless coefficient depending only on $\\alpha$. Provide the closed-form analytic expression for $C(\\alpha)$.",
            "solution": "The problem is well-posed, scientifically grounded, and contains all necessary information for a complete derivation. It is a standard exercise in the development of numerical methods for partial differential equations with immersed boundaries.\n\nThe core of the task is to construct a polynomial interpolant passing through three non-uniformly spaced points and then use its derivatives to approximate the derivatives of the underlying function $u(x)$.\n\nLet the three points be $(x_b, u_b)$, $(x_0, u_0)$, and $(x_1, u_1)$. We define a local coordinate $\\xi$ to simplify the algebra:\n$$\nx = x_0 + \\xi h \\implies \\xi = \\frac{x - x_0}{h}\n$$\nIn this new coordinate system, the locations of our data points are:\n$$\nx_b = x_0 - \\alpha h \\implies \\xi_b = -\\alpha\n$$\n$$\nx_0 \\implies \\xi_0 = 0\n$$\n$$\nx_1 = x_0 + h \\implies \\xi_1 = 1\n$$\nLet the quadratic interpolant be $P(\\xi) = a\\xi^2 + b\\xi + c$. We enforce that $P(\\xi)$ passes through the three given data points:\n$1$. At $\\xi=0$: $P(0) = c = u_0$.\n$2$. At $\\xi=1$: $P(1) = a(1)^2 + b(1) + c = u_1 \\implies a + b + u_0 = u_1 \\implies a + b = u_1 - u_0$.\n$3$. At $\\xi=-\\alpha$: $P(-\\alpha) = a(-\\alpha)^2 + b(-\\alpha) + c = u_b \\implies a\\alpha^2 - b\\alpha + u_0 = u_b \\implies a\\alpha^2 - b\\alpha = u_b - u_0$.\n\nWe have a system of two linear equations for the coefficients $a$ and $b$:\n$$\n\\begin{cases}\na + b = u_1 - u_0 \\\\\na\\alpha^2 - b\\alpha = u_b - u_0\n\\end{cases}\n$$\nFrom the first equation, we have $b = u_1 - u_0 - a$. Substituting this into the second equation:\n$$\na\\alpha^2 - (u_1 - u_0 - a)\\alpha = u_b - u_0\n$$\n$$\na\\alpha^2 - \\alpha(u_1 - u_0) + a\\alpha = u_b - u_0\n$$\n$$\na(\\alpha^2 + \\alpha) = u_b - u_0 + \\alpha(u_1 - u_0)\n$$\n$$\na \\alpha(\\alpha+1) = u_b - (1+\\alpha)u_0 + \\alpha u_1\n$$\nSolving for $a$:\n$$\na = \\frac{u_b - (1+\\alpha)u_0 + \\alpha u_1}{\\alpha(\\alpha+1)}\n$$\nNow, we solve for $b$ using $b = u_1 - u_0 - a$:\n$$\nb = u_1 - u_0 - \\frac{u_b - (1+\\alpha)u_0 + \\alpha u_1}{\\alpha(\\alpha+1)}\n$$\nPutting everything over a common denominator $\\alpha(\\alpha+1)$:\n$$\nb = \\frac{\\alpha(\\alpha+1)(u_1 - u_0) - [u_b - (1+\\alpha)u_0 + \\alpha u_1]}{\\alpha(\\alpha+1)}\n$$\n$$\nb = \\frac{(\\alpha^2+\\alpha)u_1 - (\\alpha^2+\\alpha)u_0 - u_b + (1+\\alpha)u_0 - \\alpha u_1}{\\alpha(\\alpha+1)}\n$$\nGrouping terms by $u_b$, $u_0$, and $u_1$:\n$$\nb = \\frac{-u_b + (-\\alpha^2-\\alpha+1+\\alpha)u_0 + (\\alpha^2+\\alpha-\\alpha)u_1}{\\alpha(\\alpha+1)} = \\frac{-u_b + (1-\\alpha^2)u_0 + \\alpha^2 u_1}{\\alpha(\\alpha+1)}\n$$\n\n**Approximation for the $x$-gradient $u_x$ at $x_0$**\n\nThe first derivative of $u$ with respect to $x$ is related to the derivative of $P$ with respect to $\\xi$ by the chain rule: $\\frac{du}{dx} = \\frac{d P}{d\\xi}\\frac{d\\xi}{dx}$. Since $\\frac{d\\xi}{dx} = \\frac{d}{dx}\\left(\\frac{x-x_0}{h}\\right) = \\frac{1}{h}$, we have $\\frac{du}{dx} = \\frac{1}{h}\\frac{dP}{d\\xi}$.\nThe derivative of the interpolating polynomial is $\\frac{dP}{d\\xi} = 2a\\xi + b$.\nWe approximate $u_x(x_0)$ by evaluating the derivative of the interpolant at $x_0$ (which is $\\xi=0$):\n$$\nu_x(x_0)_{\\text{approx}} = \\frac{1}{h}\\frac{dP}{d\\xi}\\Big|_{\\xi=0} = \\frac{1}{h}(2a(0) + b) = \\frac{b}{h}\n$$\nSubstituting our expression for $b$:\n$$\nu_x(x_0)_{\\text{approx}} = \\frac{1}{h} \\left( \\frac{-u_b + (1-\\alpha^2)u_0 + \\alpha^2 u_1}{\\alpha(\\alpha+1)} \\right)\n$$\nWe can express this as a finite-difference stencil. Noting that $1-\\alpha^2=(1-\\alpha)(1+\\alpha)$ and $\\alpha^2 = \\alpha \\cdot \\alpha$:\n$$\nu_x(x_0)_{\\text{approx}} = \\frac{1}{h} \\left( \\frac{-1}{\\alpha(\\alpha+1)} u_b + \\frac{(1-\\alpha)(1+\\alpha)}{\\alpha(\\alpha+1)} u_0 + \\frac{\\alpha^2}{\\alpha(\\alpha+1)} u_1 \\right)\n$$\n$$\nu_x(x_0)_{\\text{approx}} = \\frac{1}{h} \\left( \\frac{-1}{\\alpha(\\alpha+1)} u_b + \\frac{1-\\alpha}{\\alpha} u_0 + \\frac{\\alpha}{\\alpha+1} u_1 \\right)\n$$\nThis is the required second-order accurate formula for the $x$-gradient at $x_0$.\n\n**Approximation for the $x$-second derivative $u_{xx}$ at $x_0$ and the Laplacian**\n\nSimilarly, for the second derivative, we use $\\frac{d^2u}{dx^2} = \\frac{d}{dx}\\left(\\frac{1}{h}\\frac{dP}{d\\xi}\\right) = \\frac{1}{h}\\frac{d^2P}{d\\xi^2}\\frac{d\\xi}{dx} = \\frac{1}{h^2}\\frac{d^2P}{d\\xi^2}$.\nThe second derivative of the interpolant is $\\frac{d^2P}{d\\xi^2} = 2a$.\nWe approximate $u_{xx}(x_0)$ by evaluating this at $x_0$ (which is $\\xi=0$):\n$$\nu_{xx}(x_0)_{\\text{approx}} = \\frac{2a}{h^2}\n$$\nSubstituting our expression for $a$:\n$$\nu_{xx}(x_0)_{\\text{approx}} = \\frac{2}{h^2} \\left( \\frac{u_b - (1+\\alpha)u_0 + \\alpha u_1}{\\alpha(\\alpha+1)} \\right)\n$$\nThis is the modified one-sided approximation for $u_{xx}$ at $x_0$. A discrete Laplacian near the boundary, at a point $(x_0, y_j)$, is formed by combining this with the standard centered second-difference in $y$:\n$$\n\\nabla^2 u(x_0, y_j)_{\\text{approx}} = u_{xx}(x_0)_{\\text{approx}} + u_{yy}(y_j)_{\\text{approx}}\n$$\n$$\n\\nabla^2 u(x_0, y_j)_{\\text{approx}} = \\frac{2}{h^2\\alpha(\\alpha+1)} \\left( u_b - (1+\\alpha)u_0 + \\alpha u_1 \\right) + \\frac{u(x_0, y_{j+1}) - 2u(x_0, y_j) + u(x_0, y_{j-1})}{h^2}\n$$\nwhere $u_0 = u(x_0, y_j)$, $u_1 = u(x_1, y_j)$, and $u_b = u(x_b, y_j)$.\n\n**Truncation Error Analysis**\n\nTo find the truncation error, we substitute the Taylor series expansions of $u_1$ and $u_b$ around $x_0$ into our stencils. All derivatives hereafter are evaluated at $x_0$.\n$u_1 = u(x_0+h) = u_0 + h u_x + \\frac{h^2}{2} u_{xx} + \\frac{h^3}{6} u_{xxx} + \\frac{h^4}{24} u_{xxxx} + \\mathcal{O}(h^5)$\n$u_b = u(x_0-\\alpha h) = u_0 - \\alpha h u_x + \\frac{(\\alpha h)^2}{2} u_{xx} - \\frac{(\\alpha h)^3}{6} u_{xxx} + \\frac{(\\alpha h)^4}{24} u_{xxxx} + \\mathcal{O}(h^5)$\n\nFor the $x$-gradient, $u_x(x_0)_{\\text{approx}} = (b/h)$. Expanding $b$ using the Taylor series:\n$b \\alpha(\\alpha+1) = -u_b + (1-\\alpha^2)u_0 + \\alpha^2 u_1$\n$= -(u_0 - \\alpha h u_x + \\frac{\\alpha^2 h^2}{2} u_{xx} - \\frac{\\alpha^3 h^3}{6} u_{xxx} + \\dots) + (1-\\alpha^2)u_0 + \\alpha^2(u_0 + h u_x + \\frac{h^2}{2} u_{xx} + \\frac{h^3}{6} u_{xxx} + \\dots)$\nGrouping terms by derivative order:\n$u_0$: $-1+(1-\\alpha^2)+\\alpha^2 = 0$.\n$u_x$: $\\alpha h u_x + \\alpha^2 h u_x = h u_x (\\alpha + \\alpha^2) = h u_x \\alpha(\\alpha+1)$.\n$u_{xx}$: $-\\frac{\\alpha^2 h^2}{2} u_{xx} + \\frac{\\alpha^2 h^2}{2} u_{xx} = 0$.\n$u_{xxx}$: $\\frac{\\alpha^3 h^3}{6} u_{xxx} + \\frac{\\alpha^2 h^3}{6} u_{xxx} = \\frac{h^3}{6} u_{xxx} (\\alpha^3+\\alpha^2) = \\frac{h^3}{6} u_{xxx} \\alpha^2(\\alpha+1)$.\nSo, $b \\alpha(\\alpha+1) = h u_x \\alpha(\\alpha+1) + \\frac{h^3}{6}\\alpha^2(\\alpha+1) u_{xxx} + \\mathcal{O}(h^4)$.\nDividing by $\\alpha(\\alpha+1)$ gives $b = h u_x + \\frac{\\alpha^2 h^3}{6} u_{xxx} + \\mathcal{O}(h^4)$.\nThen $u_x(x_0)_{\\text{approx}} = \\frac{b}{h} = u_x + \\frac{\\alpha^2 h^2}{6} u_{xxx} + \\mathcal{O}(h^3)$.\nThe leading-order truncation error for the $x$-gradient is $\\tau_x = \\frac{\\alpha^2}{6} h^2 u_{xxx}$. The approximation is second-order accurate.\n\nFor the $x$-second derivative, $u_{xx}(x_0)_{\\text{approx}} = 2a/h^2$. Expanding $a$:\n$a \\alpha(\\alpha+1) = u_b - (1+\\alpha)u_0 + \\alpha u_1$\n$= (u_0 - \\alpha h u_x + \\frac{\\alpha^2 h^2}{2} u_{xx} - \\dots) - (1+\\alpha)u_0 + \\alpha(u_0 + h u_x + \\frac{h^2}{2} u_{xx} + \\frac{h^3}{6} u_{xxx} - \\dots)$\n$u_0$: $1-(1+\\alpha)+\\alpha=0$.\n$u_x$: $-\\alpha h u_x + \\alpha h u_x = 0$.\n$u_{xx}$: $\\frac{\\alpha^2 h^2}{2} u_{xx} + \\frac{\\alpha h^2}{2} u_{xx} = \\frac{h^2}{2} u_{xx} (\\alpha^2+\\alpha) = \\frac{h^2}{2} u_{xx} \\alpha(\\alpha+1)$.\n$u_{xxx}$: $-\\frac{\\alpha^3 h^3}{6} u_{xxx} + \\frac{\\alpha h^3}{6} u_{xxx} = \\frac{h^3}{6} u_{xxx} (\\alpha-\\alpha^3) = \\frac{h^3}{6} u_{xxx} \\alpha(1-\\alpha^2) = \\frac{h^3}{6} u_{xxx} \\alpha(1-\\alpha)(1+\\alpha)$.\nSo, $a\\alpha(\\alpha+1) = \\frac{h^2}{2}u_{xx}\\alpha(\\alpha+1) + \\frac{h^3}{6}u_{xxx}\\alpha(1-\\alpha)(1+\\alpha) + \\mathcal{O}(h^4)$.\nDividing by $\\alpha(\\alpha+1)$ gives $a = \\frac{h^2}{2}u_{xx} + \\frac{h^3}{6}(1-\\alpha)u_{xxx} + \\mathcal{O}(h^4)$.\nThen $u_{xx}(x_0)_{\\text{approx}} = \\frac{2a}{h^2} = u_{xx} + \\frac{1-\\alpha}{3}h u_{xxx} + \\mathcal{O}(h^2)$.\nThe leading-order truncation error for the $x$-second derivative is $\\tau_{xx} = \\frac{1-\\alpha}{3} h u_{xxx}$. The approximation is first-order accurate.\n\nThe truncation error for the standard centered difference in $y$ is $\\tau_{yy} = \\frac{h^2}{12}u_{yyyy} + \\mathcal{O}(h^4)$.\nThe truncation error for the Laplacian is $\\tau_{\\nabla^2} = \\tau_{xx} + \\tau_{yy} = \\frac{1-\\alpha}{3} h u_{xxx} + \\mathcal{O}(h^2)$, as the error from the $x$-discretization is dominant.\n\nThe one-sided discretization induces significant anisotropy in the truncation error. The leading error term for the Laplacian, $\\frac{1-\\alpha}{3} h u_{xxx}$, is first-order in $h$ and depends on a third derivative in $x$. In contrast, the discretization in the $y$-direction is second-order, $\\mathcal{O}(h^2)$, and its leading error term depends on a fourth derivative in $y$. This means the error is not symmetric with respect to coordinate directions; it is larger and has a different character in the direction normal to the boundary compared to the tangential direction. The leading error coefficient, $\\frac{1-\\alpha}{3}$, also varies with the sub-grid position of the boundary, unlike the constant coefficient $\\frac{1}{12}$ for the $y$-direction.\n\n**Derivation of the coefficient $C(\\alpha)$**\n\nThe problem states the local truncation error of the $x$-gradient approximation in the form:\n$$\nu_x(x_0)_{\\text{approx}} - u_x(x_0) = C(\\alpha)\\, h^{2}\\, u_{xxx}(x_0) + \\mathcal{O}(h^{3})\n$$\nFrom our truncation error analysis for the $x$-gradient, we found:\n$$\nu_x(x_0)_{\\text{approx}} - u_x(x_0) = \\frac{\\alpha^2}{6} h^2 u_{xxx}(x_0) + \\mathcal{O}(h^3)\n$$\nBy direct comparison of these two expressions, we can identify the coefficient $C(\\alpha)$.\n$$\nC(\\alpha) = \\frac{\\alpha^2}{6}\n$$",
            "answer": "$$\n\\boxed{\\frac{\\alpha^2}{6}}\n$$"
        },
        {
            "introduction": "Moving from local stencils to the global operators that define diffuse-interface methods, this practice focuses on the crucial spread ($S$) and interpolation ($J$) operators. You will construct the discrete matrix representations of these operators and, most importantly, verify their adjoint relationship with respect to the appropriate weighted inner products, which is a discrete analogue of power conservation. Understanding and correctly implementing this symmetry is not merely an academic exercise; it is essential for developing energy-stable schemes and is the foundation for advanced applications like adjoint-based shape optimization and data assimilation .",
            "id": "3332853",
            "problem": "You are given a uniform two-dimensional Cartesian grid with periodic boundaries on the unit square and a set of Lagrangian marker points representing an immersed curve. The immersed boundary method uses a regularized Dirac delta to define two linear operators: a spread operator $S$ that maps Lagrangian forces to Eulerian forces on the grid, and an interpolation operator $J$ that maps Eulerian grid fields to the Lagrangian markers. Your task is to construct discrete matrix representations of these operators, form the correctly weighted adjoint pairs, verify the symmetry relation under a specific quadrature, and quantify how deviations from this symmetry affect gradient accuracy in a simple optimization task.\n\nStart from the following fundamental base and definitions:\n\n- The Eulerian grid is $N \\times N$ with grid spacing $h = 1/N$, with grid coordinates $x_i = i h$, $y_j = j h$ for integers $i,j \\in \\{0,\\dots,N-1\\}$, and periodic boundary conditions on $[0,1)^2$.\n\n- There are $M$ Lagrangian markers at positions $(X_\\ell, Y_\\ell)$ with uniform quadrature weights $w_\\ell = \\Delta s$, where $\\Delta s$ approximates the curve’s arc length spacing.\n\n- The one-dimensional four-point regularized Dirac delta (Peskin kernel) $\\varphi(r)$ is supported on $|r| < 2$ and defined by\n  $$\n  \\varphi(r) = \n  \\begin{cases}\n  \\dfrac{1}{8}\\left(3 - 2|r| + \\sqrt{1 + 4|r| - 4 r^2}\\right), & 0 \\le |r| < 1, \\\\\n  \\dfrac{1}{8}\\left(5 - 2|r| - \\sqrt{-7 + 12|r| - 4 r^2}\\right), & 1 \\le |r| < 2, \\\\\n  0, & |r| \\ge 2,\n  \\end{cases}\n  $$\n  and the two-dimensional regularized delta at grid spacing $h$ is\n  $$\n  \\delta_h(x,y) = \\dfrac{1}{h^2} \\, \\varphi\\!\\left(\\dfrac{x}{h}\\right)\\, \\varphi\\!\\left(\\dfrac{y}{h}\\right).\n  $$\n  Periodicity is enforced by taking minimal-periodic differences for the arguments.\n\n- The discrete spread operator $S_{\\mathrm{phys}}$ maps a Lagrangian vector $F \\in \\mathbb{R}^{M}$ to an Eulerian vector $f \\in \\mathbb{R}^{N^2}$ by\n  $$\n  f_{ij} = \\sum_{\\ell=1}^{M} w_\\ell \\, F_\\ell \\, \\delta_h\\!\\left(x_i - X_\\ell, \\, y_j - Y_\\ell\\right),\n  $$\n  that is, in matrix form $f = S_{\\mathrm{phys}} \\, F$, where $S_{\\mathrm{phys}} \\in \\mathbb{R}^{N^2 \\times M}$.\n\n- The discrete interpolation operator $J_{\\mathrm{phys}}$ maps an Eulerian vector $u \\in \\mathbb{R}^{N^2}$ to a Lagrangian vector $U \\in \\mathbb{R}^{M}$ by\n  $$\n  U_\\ell = \\sum_{i=1}^{N} \\sum_{j=1}^{N} u_{ij}\\, h^2 \\, \\delta_h\\!\\left(x_i - X_\\ell, \\, y_j - Y_\\ell\\right),\n  $$\n  that is, in matrix form $U = J_{\\mathrm{phys}} \\, u$, where $J_{\\mathrm{phys}} \\in \\mathbb{R}^{M \\times N^2}$.\n\n- The Eulerian weighted inner product is $\\langle u, f \\rangle_E = \\sum_{i,j} u_{ij} f_{ij} \\, h^2$ and the Lagrangian weighted inner product is $\\langle U, F \\rangle_L = \\sum_{\\ell} U_\\ell F_\\ell \\, w_\\ell$. Under these weights, the discrete power identity $\\langle u, S_{\\mathrm{phys}} F \\rangle_E = \\langle J_{\\mathrm{phys}} u, F \\rangle_L$ holds, equivalently\n  $$\n  J_{\\mathrm{phys}} = W_L^{-1} \\, S_{\\mathrm{phys}}^\\top \\, W_E,\n  $$\n  where $W_E = h^2 I_{N^2}$ and $W_L = \\mathrm{diag}(w_1,\\dots,w_M)$.\n\n- Define the symmetrically weighted operators\n  $$\n  \\widetilde{S} = W_E^{1/2}\\, S_{\\mathrm{phys}}\\, W_L^{-1/2}, \\qquad\n  \\widetilde{J} = W_L^{1/2}\\, J_{\\mathrm{phys}}\\, W_E^{-1/2}.\n  $$\n  Using the fundamental identity above, one obtains the symmetry relation\n  $$\n  \\widetilde{J} = \\widetilde{S}^\\top.\n  $$\n\nYour program must:\n\n- Construct $S_{\\mathrm{phys}}$ and $J_{\\mathrm{phys}}$ for given $(N,M)$, marker locations $(X_\\ell,Y_\\ell)$ on a circle of radius $R$ and center $(x_c,y_c)$, and quadrature weights $w_\\ell = 2\\pi R / M$.\n\n- Construct the symmetrically weighted pair $(\\widetilde{S}, \\widetilde{J})$ and compute the Frobenius norm of the difference $\\|\\widetilde{J} - \\widetilde{S}^\\top\\|_F$ as a scalar float.\n\n- Construct a deviated interpolation operator $J_{\\mathrm{wrong}}$ that omits the Eulerian quadrature factor $h^2$ (i.e., set $U_\\ell = \\sum_{i,j} u_{ij}\\, \\delta_h(\\cdot)$), and compute $\\|\\widetilde{J}_{\\mathrm{wrong}} - \\widetilde{S}^\\top\\|_F$ using the same symmetric weighting formula for $\\widetilde{J}_{\\mathrm{wrong}} = W_L^{1/2} J_{\\mathrm{wrong}} W_E^{-1/2}$.\n\n- Define the quadratic objective over Lagrangian forces $F \\in \\mathbb{R}^M$,\n  $$\n  \\Phi(F) = \\dfrac{1}{2}\\, \\| A F - b \\|_{W_L}^2, \\quad \\text{where } A = J_{\\mathrm{phys}} S_{\\mathrm{phys}},\n  $$\n  and $\\|v\\|_{W_L}^2 = v^\\top W_L v$. Use a fixed random vector $b \\in \\mathbb{R}^M$ and a fixed random $F \\in \\mathbb{R}^M$ seeded deterministically for reproducibility.\n\n- Compute the exact gradient with respect to $F$ using the adjoint chain implied by the weighted inner products,\n  $$\n  \\nabla \\Phi(F) = S_{\\mathrm{phys}}^\\top\\, J_{\\mathrm{phys}}^\\top\\, \\left(W_L (A F - b)\\right).\n  $$\n  Also compute an incorrect gradient that uses the deviated interpolation operator in the adjoint chain,\n  $$\n  \\nabla_{\\mathrm{wrong}} \\Phi(F) = S_{\\mathrm{phys}}^\\top\\, J_{\\mathrm{wrong}}^\\top\\, \\left(W_L (A F - b)\\right).\n  $$\n\n- Estimate the reference gradient via central finite differences with a perturbation step $\\varepsilon$ applied componentwise to $F$:\n  $$\n  \\left[\\nabla \\Phi(F)\\right]_k \\approx \\dfrac{\\Phi(F + \\varepsilon e_k) - \\Phi(F - \\varepsilon e_k)}{2 \\varepsilon},\n  $$\n  where $e_k$ is the $k$-th basis vector.\n\n- Report the relative $\\ell^2$-errors of the exact and incorrect gradients against finite differences:\n  $$\n  E_{\\mathrm{true}} = \\dfrac{\\|\\nabla \\Phi(F) - \\nabla_{\\mathrm{FD}} \\Phi(F)\\|_2}{\\|\\nabla_{\\mathrm{FD}} \\Phi(F)\\|_2}, \\qquad\n  E_{\\mathrm{wrong}} = \\dfrac{\\|\\nabla_{\\mathrm{wrong}} \\Phi(F) - \\nabla_{\\mathrm{FD}} \\Phi(F)\\|_2}{\\|\\nabla_{\\mathrm{FD}} \\Phi(F)\\|_2}.\n  $$\n\nTest suite and required final output:\n\nYour program must implement the following three test cases and aggregate their outputs into a single list:\n\n- Case $1$ (symmetry verification, matched quadrature): $N = 16$, $M = 20$, circle center $(x_c,y_c) = (0.15, 0.85)$, radius $R = 0.22$. Compute $E_{\\mathrm{sym}}^{\\mathrm{matched}} = \\|\\widetilde{J} - \\widetilde{S}^\\top\\|_F$ as a float.\n\n- Case $2$ (symmetry verification, deviated interpolation quadrature): same parameters as Case $1$, but use $J_{\\mathrm{wrong}}$ that omits the factor $h^2$. Compute $E_{\\mathrm{sym}}^{\\mathrm{wrong}} = \\|\\widetilde{J}_{\\mathrm{wrong}} - \\widetilde{S}^\\top\\|_F$ as a float.\n\n- Case $3$ (gradient accuracy in a quadratic design task): $N = 24$, $M = 28$, circle center $(x_c,y_c) = (0.07, 0.11)$, radius $R = 0.19$, random seed fixed at an integer value, and finite-difference step $\\varepsilon = 10^{-6}$. Compute $E_{\\mathrm{true}}$ and $E_{\\mathrm{wrong}}$ as floats.\n\nFinal output format:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order\n$[E_{\\mathrm{sym}}^{\\mathrm{matched}}, E_{\\mathrm{sym}}^{\\mathrm{wrong}}, E_{\\mathrm{true}}, E_{\\mathrm{wrong}}]$.",
            "solution": "The user wants to validate a problem statement.\n\n### Step 1: Extract Givens\n\n- **Eulerian Grid**: A uniform $N \\times N$ Cartesian grid on the unit square $[0,1)^2$ with periodic boundaries. Grid spacing is $h = 1/N$. Grid point coordinates are $(x_i, y_j)$ where $x_i = i h$ and $y_j = j h$ for $i, j \\in \\{0, \\dots, N-1\\}$.\n- **Lagrangian Markers**: $M$ marker points at positions $(X_\\ell, Y_\\ell)$.\n- **Lagrangian Quadrature**: Uniform quadrature weights $w_\\ell = \\Delta s$. For a circle of radius $R$, $w_\\ell = 2\\pi R / M$.\n- **Regularized Delta Function**: A one-dimensional, four-point Peskin kernel $\\varphi(r)$, and its two-dimensional, tensor-product extension $\\delta_h(x,y) = \\frac{1}{h^2} \\varphi(x/h) \\varphi(y/h)$. Periodicity is enforced via minimal-periodic differences.\n- **Spread Operator ($S_{\\mathrm{phys}}$)**: A linear operator from Lagrangian forces $F \\in \\mathbb{R}^M$ to Eulerian forces $f \\in \\mathbb{R}^{N^2}$, defined by $f_{ij} = \\sum_{\\ell=1}^{M} w_\\ell \\, F_\\ell \\, \\delta_h(x_i - X_\\ell, y_j - Y_\\ell)$. In matrix form, $f = S_{\\mathrm{phys}} F$.\n- **Interpolation Operator ($J_{\\mathrm{phys}}$)**: A linear operator from an Eulerian field $u \\in \\mathbb{R}^{N^2}$ to a Lagrangian field $U \\in \\mathbb{R}^M$, defined by $U_\\ell = \\sum_{i,j} u_{ij}\\, h^2 \\, \\delta_h(x_i - X_\\ell, y_j - Y_\\ell)$. In matrix form, $U = J_{\\mathrm{phys}} u$.\n- **Weighted Inner Products**: Eulerian $\\langle u, f \\rangle_E = \\sum_{i,j} u_{ij} f_{ij} \\, h^2$ and Lagrangian $\\langle U, F \\rangle_L = \\sum_{\\ell} U_\\ell F_\\ell \\, w_\\ell$.\n- **Discrete Adjoint Relation**: The operators are defined to satisfy the power identity $\\langle u, S_{\\mathrm{phys}} F \\rangle_E = \\langle J_{\\mathrm{phys}} u, F \\rangle_L$, which implies the matrix relation $J_{\\mathrm{phys}} = W_L^{-1} S_{\\mathrm{phys}}^\\top W_E$, where $W_E = h^2 I_{N^2}$ and $W_L = \\mathrm{diag}(w_1, \\dots, w_M)$.\n- **Symmetrically Weighted Operators**: $\\widetilde{S} = W_E^{1/2} S_{\\mathrm{phys}} W_L^{-1/2}$ and $\\widetilde{J} = W_L^{1/2} J_{\\mathrm{phys}} W_E^{-1/2}$, which should satisfy $\\widetilde{J} = \\widetilde{S}^\\top$.\n- **Deviated Interpolation Operator ($J_{\\mathrm{wrong}}$)**: Defined by omitting the $h^2$ factor: $U_\\ell = \\sum_{i,j} u_{ij} \\delta_h(x_i - X_\\ell, y_j - Y_\\ell)$.\n- **Objective Function**: $\\Phi(F) = \\frac{1}{2} \\| A F - b \\|_{W_L}^2$ with $A = J_{\\mathrm{phys}} S_{\\mathrm{phys}}$, and fixed random vectors $b, F$.\n- **Gradients**: An \"exact\" gradient $\\nabla \\Phi(F) = S_{\\mathrm{phys}}^\\top J_{\\mathrm{phys}}^\\top (W_L(AF-b))$, an \"incorrect\" gradient $\\nabla_{\\mathrm{wrong}} \\Phi(F) = S_{\\mathrm{phys}}^\\top J_{\\mathrm{wrong}}^\\top (W_L(AF-b))$, and a reference gradient from finite differences, $\\nabla_{\\mathrm{FD}} \\Phi(F)$.\n- **Tasks**:\n  1.  Construct operators and compute $E_{\\mathrm{sym}}^{\\mathrm{matched}} = \\|\\widetilde{J} - \\widetilde{S}^\\top\\|_F$.\n  2.  Construct $J_{\\mathrm{wrong}}$ and compute $E_{\\mathrm{sym}}^{\\mathrm{wrong}} = \\|\\widetilde{J}_{\\mathrm{wrong}} - \\widetilde{S}^\\top\\|_F$.\n  3.  Compute relative errors $E_{\\mathrm{true}}$ and $E_{\\mathrm{wrong}}$ of the analytical gradients against the finite difference approximation.\n- **Parameters**:\n  - Case 1 & 2: $N=16, M=20, (x_c,y_c)=(0.15, 0.85), R=0.22$.\n  - Case 3: $N=24, M=28, (x_c,y_c)=(0.07, 0.11), R=0.19$, fixed integer random seed, $\\varepsilon = 10^{-6}$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is evaluated against the validation criteria.\n\n- **Scientifically Grounded**: The problem is firmly rooted in computational fluid dynamics, specifically the Immersed Boundary Method pioneered by Charles Peskin. The concepts, including the regularized delta function, spread/interpolation operators, and weighted adjoints, are standard and foundational in this field. All mathematical definitions and physical interpretations are correct.\n- **Well-Posed**: The problem is well-posed. It requests the implementation of explicitly defined mathematical objects and the computation of specific, well-defined quantities (matrix norms, vector norms, and relative errors). All necessary parameters and definitions are provided for each task. The existence and uniqueness of the results are guaranteed by the deterministic nature of the calculations.\n- **Objective**: The language is precise, quantitative, and free of any subjective or ambiguous terminology.\n- **Completeness**: The problem is self-contained. All necessary equations, constants, and parameters for the specified test cases are provided. No external information is required.\n- **Consistency**: The definitions are mutually consistent. For instance, the matrix relationship $J_{\\mathrm{phys}} = W_L^{-1} S_{\\mathrm{phys}}^\\top W_E$ is a direct consequence of the definitions of the operators and the weighted inner products, which forms a key verification point in the exercise.\n- **Realism**: The parameters are physically and numerically sensible for a demonstration-scale problem. The task of verifying an adjoint relationship and its impact on gradient computation is a crucial and realistic step in developing and validating numerical optimization codes in engineering and physics.\n\nThe problem does not exhibit any of the invalidity flaws. It is a canonical, didactic, and sound numerical methods exercise.\n\n### Step 3: Verdict and Action\n\nThe problem is **valid**. A solution will be provided.\n\n---\n\n### Solution\n\nThe problem requires a careful implementation of the operators central to the Immersed Boundary (IB) method and an investigation of their adjoint properties. The solution is structured around the principles of operator discretization, weighted adjoints, and their application in gradient-based optimization.\n\n**1. Discretization of Continuous Operators**\n\nThe IB method couples a Lagrangian representation of an immersed structure to an ambient Eulerian fluid grid. This coupling is mediated by integral operators involving the Dirac delta function. In a discrete setting, the Dirac delta is replaced by a regularized kernel $\\delta_h$, and integrals are replaced by summations.\n\n- **Grid and Markers**: The Eulerian domain is a grid of $N^2$ points $(x_i, y_j)$, and the immersed boundary is a set of $M$ Lagrangian markers $(X_\\ell, Y_\\ell)$. Periodic boundary conditions are handled by computing distances on a torus, i.e., $d_{\\text{periodic}}(a,b) = (a-b) - \\lfloor(a-b)+0.5\\rfloor$, assuming a domain of size $1$.\n\n- **Spread Operator $S_{\\mathrm{phys}}$**: This operator spreads a Lagrangian quantity, like force $F$, onto the Eulerian grid. The continuous definition is $f(\\mathbf{x}) = \\int_{\\Gamma} F(s) \\delta(\\mathbf{x} - \\mathbf{X}(s)) ds$. Its discretization is:\n$$ f_{ij} = \\sum_{\\ell=1}^M F_\\ell \\delta_h(x_i - X_\\ell, y_j - Y_\\ell) w_\\ell $$\nHere, $w_\\ell$ (approximating $ds$) is the Lagrangian quadrature weight. The matrix elements of $S_{\\mathrm{phys}}$ that map a vector $F$ to a vector $f$ (with grid points-as-rows and marker points-as-columns) are:\n$$ (S_{\\mathrm{phys}})_{ij, \\ell} = w_\\ell \\, \\delta_h(x_i - X_\\ell, y_j - Y_\\ell) = \\frac{w_\\ell}{h^2} \\varphi\\left(\\frac{x_i - X_\\ell}{h}\\right) \\varphi\\left(\\frac{y_j - Y_\\ell}{h}\\right) $$\n\n- **Interpolation Operator $J_{\\mathrm{phys}}$**: This operator interpolates an Eulerian field, like velocity $u$, to the Lagrangian markers. The continuous definition is $U(s) = \\int_{\\Omega} u(\\mathbf{x}) \\delta(\\mathbf{x} - \\mathbf{X}(s)) d\\mathbf{x}$. Its discretization is:\n$$ U_\\ell = \\sum_{i=1}^N \\sum_{j=1}^N u_{ij} \\delta_h(x_i - X_\\ell, y_j - Y_\\ell) h^2 $$\nHere, $h^2$ is the Eulerian quadrature weight (area element $d\\mathbf{x}$). The matrix elements of $J_{\\mathrm{phys}}$ (with marker points-as-rows and grid points-as-columns) are:\n$$ (J_{\\mathrm{phys}})_{\\ell, ij} = h^2 \\, \\delta_h(x_i - X_\\ell, y_j - Y_\\ell) = \\varphi\\left(\\frac{x_i - X_\\ell}{h}\\right) \\varphi\\left(\\frac{y_j - Y_\\ell}{h}\\right) $$\n\n**2. Adjoint Relationship and Symmetry**\n\nThe operators $S_{\\mathrm{phys}}$ and $J_{\\mathrm{phys}}$ are not matrix transposes of each other. Instead, they are adjoints with respect to specific weighted inner products that represent discrete integrals: $\\langle \\cdot, \\cdot \\rangle_E$ on the grid and $\\langle \\cdot, \\cdot \\rangle_L$ on the markers. The power conservation identity $\\langle u, S_{\\mathrm{phys}} F \\rangle_E = \\langle J_{\\mathrm{phys}} u, F \\rangle_L$ must hold. This is equivalent to the matrix identity $S_{\\mathrm{phys}}^\\top W_E = W_L J_{\\mathrm{phys}}$, or $J_{\\mathrm{phys}} = W_L^{-1} S_{\\mathrm{phys}}^\\top W_E$, where $W_E=h^2 I$ and $W_L=\\mathrm{diag}(w_\\ell)$. Our construction of $(S_{\\mathrm{phys}})_{ij, \\ell}$ and $(J_{\\mathrm{phys}})_{\\ell, ij}$ satisfies this.\n\nTo recover the familiar matrix transpose relationship, we define symmetrically weighted operators:\n$$ \\widetilde{S} = W_E^{1/2} S_{\\mathrm{phys}} W_L^{-1/2} \\quad \\text{and} \\quad \\widetilde{J} = W_L^{1/2} J_{\\mathrm{phys}} W_E^{-1/2} $$\nSubstituting the adjoint relation for $J_{\\mathrm{phys}}$ into the definition of $\\widetilde{J}$ and simplifying confirms that $\\widetilde{J} = \\widetilde{S}^\\top$. The code will verify this numerically by computing $\\|\\widetilde{J} - \\widetilde{S}^\\top\\|_F$, which should be near machine precision.\n\nThe deviated operator $J_{\\mathrm{wrong}}$ omits the Eulerian quadrature weight $h^2$, yielding $(J_{\\mathrm{wrong}})_{\\ell, ij} = \\delta_h(\\dots)$. This breaks the power identity and, consequently, the symmetry of the weighted operators. $\\|\\widetilde{J}_{\\mathrm{wrong}} - \\widetilde{S}^\\top\\|_F$ will be significantly non-zero.\n\n**3. Gradient Computation and Verification**\n\nFor the objective function $\\Phi(F) = \\frac{1}{2} \\| J_{\\mathrm{phys}} S_{\\mathrm{phys}} F - b \\|_{W_L}^2$, the gradient is found using the chain rule. The derivative of $\\|v\\|_{W_L}^2$ with respect to $v$ is $2 W_L v$. Applying the chain rule through the linear operators gives:\n$$ \\nabla \\Phi(F) = (J_{\\mathrm{phys}} S_{\\mathrm{phys}})^\\dagger (J_{\\mathrm{phys}} S_{\\mathrm{phys}} F - b) $$\nwhere $(\\cdot)^\\dagger$ denotes the adjoint with respect to the standard Euclidean inner product on the input space and the $W_L$-weighted inner product on the output space. This simplifies to:\n$$ \\nabla \\Phi(F) = (J_{\\mathrm{phys}} S_{\\mathrm{phys}})^\\top W_L (J_{\\mathrm{phys}} S_{\\mathrm{phys}} F - b) = S_{\\mathrm{phys}}^\\top J_{\\mathrm{phys}}^\\top W_L (A F - b) $$\nThis is the \"exact\" analytical gradient. The formula relies crucially on the adjoint (transpose) of the forward operators. If one mistakenly uses a non-adjoint operator in the gradient formula, such as $J_{\\mathrm{wrong}}^\\top$ in place of $J_{\\mathrm{phys}}^\\top$, the result will be incorrect.\n\nWe verify the analytical gradient against a centered finite difference approximation, a gold standard for gradient checking. The relative error $E_{\\mathrm{true}}$ between the correct analytical gradient and finite differences should be small, limited by floating-point precision and the approximation error of the finite difference scheme. Conversely, the error $E_{\\mathrm{wrong}}$ for the incorrectly computed gradient will be large, demonstrating the critical importance of using the correctly derived adjoint operators in sensitivity analysis and optimization.",
            "answer": "```python\nimport numpy as np\n\ndef phi(r_in):\n    \"\"\"\n    Computes the 4-point Peskin kernel (regularized Dirac delta function).\n    This function is piecewise and continuous, with support over |r| < 2.\n\n    Args:\n        r_in (np.ndarray): Input values.\n\n    Returns:\n        np.ndarray: The kernel values.\n    \"\"\"\n    r = np.abs(r_in)\n    val = np.zeros_like(r, dtype=float)\n    \n    # Case a: 0 <= |r| < 1\n    mask1 = r < 1\n    r1 = r[mask1]\n    val[mask1] = (1/8) * (3 - 2*r1 + np.sqrt(1 + 4*r1 - 4*r1**2))\n    \n    # Case b: 1 <= |r| < 2\n    mask2 = (r >= 1) & (r < 2)\n    r2 = r[mask2]\n    val[mask2] = (1/8) * (5 - 2*r2 - np.sqrt(-7 + 12*r2 - 4*r2**2))\n    \n    # Case c: |r| >= 2 is implicitly zero\n    return val\n\ndef periodic_diff(coords1, coords2, domain_size=1.0):\n    \"\"\"\n    Calculates the shortest periodic difference vector.\n    Handles broadcasting between coordinate arrays.\n\n    Args:\n        coords1 (np.ndarray): First set of coordinates, shape (P, D).\n        coords2 (np.ndarray): Second set of coordinates, shape (Q, D).\n        domain_size (float): The size of the periodic domain.\n\n    Returns:\n        np.ndarray: The difference vectors, shape (P, Q, D).\n    \"\"\"\n    diff = coords1[:, None, :] - coords2[None, :, :]\n    return diff - domain_size * np.round(diff / domain_size)\n\ndef solve_symmetry_cases(N, M, xc, yc, R):\n    \"\"\"\n    Solves for Cases 1 and 2: Symmetry verification of IB operators.\n\n    Args:\n        N (int): Grid dimension.\n        M (int): Number of markers.\n        xc, yc (float): Circle center coordinates.\n        R (float): Circle radius.\n\n    Returns:\n        tuple[float, float]: The Frobenius norms of the differences for\n                             the matched and wrong interpolation operators.\n    \"\"\"\n    h = 1.0 / N\n    \n    # Eulerian grid setup\n    grid_pts = np.arange(N) * h\n    grid_x, grid_y = np.meshgrid(grid_pts, grid_pts, indexing='ij')\n    grid_coords = np.stack((grid_x.ravel(), grid_y.ravel()), axis=-1)\n    \n    # Lagrangian marker setup\n    thetas = 2 * np.pi * np.arange(M) / M\n    marker_coords = np.zeros((M, 2))\n    marker_coords[:, 0] = xc + R * np.cos(thetas)\n    marker_coords[:, 1] = yc + R * np.sin(thetas)\n    \n    # Quadrature weights\n    ds = 2 * np.pi * R / M\n    w_L_vals = np.full(M, ds)\n    \n    # Interaction terms\n    diffs = periodic_diff(grid_coords, marker_coords)\n    phi_x = phi(diffs[..., 0] / h)\n    phi_y = phi(diffs[..., 1] / h)\n    phi_prod = phi_x * phi_y\n    \n    # Operator construction\n    S_phys = (w_L_vals[None, :] / (h**2)) * phi_prod\n    J_phys = phi_prod.T\n    J_wrong = (1 / h**2) * J_phys\n    \n    # Symmetrically weighted operators\n    sqrt_w_L = np.sqrt(w_L_vals)\n    S_tilde = h * S_phys * (1.0 / sqrt_w_L[None, :])\n    J_tilde = (1/h) * sqrt_w_L[:, None] * J_phys\n    J_tilde_wrong = (1/h) * sqrt_w_L[:, None] * J_wrong\n    \n    # Compute Frobenius norms\n    E_sym_matched = np.linalg.norm(J_tilde - S_tilde.T, 'fro')\n    E_sym_wrong = np.linalg.norm(J_tilde_wrong - S_tilde.T, 'fro')\n    \n    return E_sym_matched, E_sym_wrong\n\ndef solve_gradient_case(N, M, xc, yc, R, seed, eps):\n    \"\"\"\n    Solves for Case 3: Gradient accuracy of an objective function.\n\n    Args:\n        N, M, xc, yc, R: Problem parameters.\n        seed (int): Seed for random number generator.\n        eps (float): Step size for finite differences.\n\n    Returns:\n        tuple[float, float]: Relative errors of the 'true' and 'wrong' gradients.\n    \"\"\"\n    h = 1.0 / N\n    \n    # Grid and marker setup\n    grid_pts = np.arange(N) * h\n    grid_x, grid_y = np.meshgrid(grid_pts, grid_pts, indexing='ij')\n    grid_coords = np.stack((grid_x.ravel(), grid_y.ravel()), axis=-1)\n    \n    thetas = 2 * np.pi * np.arange(M) / M\n    marker_coords = np.zeros((M, 2))\n    marker_coords[:, 0] = xc + R * np.cos(thetas)\n    marker_coords[:, 1] = yc + R * np.sin(thetas)\n    \n    # Weights and interaction terms\n    ds = 2 * np.pi * R / M\n    w_L_vals = np.full(M, ds)\n    W_L = np.diag(w_L_vals)\n    \n    diffs = periodic_diff(grid_coords, marker_coords)\n    phi_prod = phi(diffs[..., 0] / h) * phi(diffs[..., 1] / h)\n    \n    # Operator construction\n    S_phys = (w_L_vals[None, :] / (h**2)) * phi_prod\n    J_phys = phi_prod.T\n    J_wrong = (1 / h**2) * J_phys\n    \n    # System operator A\n    A = J_phys @ S_phys\n    \n    # Random vectors for reproducibility\n    rng = np.random.default_rng(seed)\n    b = rng.random(M)\n    F_vec = rng.random(M)\n    \n    def objective_Phi(force_vec):\n        residual = A @ force_vec - b\n        return 0.5 * (residual.T @ W_L @ residual)\n\n    # Analytical gradients\n    residual_at_F = A @ F_vec - b\n    grad_Phi_exact = S_phys.T @ J_phys.T @ (W_L @ residual_at_F)\n    grad_Phi_wrong = S_phys.T @ J_wrong.T @ (W_L @ residual_at_F)\n    \n    # Finite difference gradient\n    grad_Phi_fd = np.zeros(M)\n    for k in range(M):\n        F_plus = F_vec.copy()\n        F_plus[k] += eps\n        F_minus = F_vec.copy()\n        F_minus[k] -= eps\n        \n        phi_plus = objective_Phi(F_plus)\n        phi_minus = objective_Phi(F_minus)\n        \n        grad_Phi_fd[k] = (phi_plus - phi_minus) / (2 * eps)\n        \n    # Relative errors\n    norm_fd = np.linalg.norm(grad_Phi_fd)\n    E_true = np.linalg.norm(grad_Phi_exact - grad_Phi_fd) / norm_fd\n    E_wrong = np.linalg.norm(grad_Phi_wrong - grad_Phi_fd) / norm_fd\n\n    return E_true, E_wrong\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    \n    # Test cases defined in the problem statement.\n    test_cases = {\n        \"case1_2\": {\"N\": 16, \"M\": 20, \"xc\": 0.15, \"yc\": 0.85, \"R\": 0.22},\n        \"case3\": {\"N\": 24, \"M\": 28, \"xc\": 0.07, \"yc\": 0.11, \"R\": 0.19, \"seed\": 42, \"eps\": 1e-6}\n    }\n    \n    # Case 1 & 2\n    params12 = test_cases[\"case1_2\"]\n    E_sym_matched, E_sym_wrong = solve_symmetry_cases(\n        params12[\"N\"], params12[\"M\"], params12[\"xc\"], params12[\"yc\"], params12[\"R\"]\n    )\n    \n    # Case 3\n    params3 = test_cases[\"case3\"]\n    E_true, E_wrong_grad = solve_gradient_case(\n        params3[\"N\"], params3[\"M\"], params3[\"xc\"], params3[\"yc\"], params3[\"R\"], \n        params3[\"seed\"], params3[\"eps\"]\n    )\n    \n    results = [E_sym_matched, E_sym_wrong, E_true, E_wrong_grad]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A powerful way to understand a numerical method is to study its limitations and the artifacts it can produce. This practice directs you to simulate \"parasitic currents,\" a classic numerical artifact in multiphase flow simulations where inaccuracies in computing surface tension forces generate spurious fluid motion even at equilibrium. By implementing a Fourier-spectral solver for the Stokes equations, you will directly observe how an error in the curvature calculation leads to a residual force that drives this non-physical flow, providing invaluable insight into the challenges of accurately modeling interfacial physics on a discrete grid .",
            "id": "3332836",
            "problem": "Consider a static, immiscible two-phase flow with a smooth interface separating two Newtonian fluids of equal viscosity, governed by the incompressible Stokes equations. The fundamental base is the incompressible Stokes momentum balance and the continuity equation, together with the classical Young–Laplace pressure jump for surface tension. Specifically, let the fluid velocity be denoted by $\\mathbf{u}(\\mathbf{x})$ and pressure by $p(\\mathbf{x})$, with dynamic viscosity $\\mu$ and surface tension coefficient $\\sigma$. Assume low Reynolds number so that inertial terms are negligible. The governing equations in the bulk are\n$$\n-\\mu \\nabla^2 \\mathbf{u} + \\nabla p = \\mathbf{0}, \\quad \\nabla \\cdot \\mathbf{u} = 0,\n$$\nand the sharp-interface condition on the interface $\\Gamma$ is a pressure jump equal to surface tension times mean curvature and continuity of velocity,\n$$\n[\\![p]\\!] = \\sigma \\kappa, \\quad [\\![\\mathbf{u}]\\!] = \\mathbf{0},\n$$\nwhere $[\\![\\cdot]\\!]$ denotes the difference of the quantity across the interface, and $\\kappa$ is the mean curvature of the interface. Consider a spherical interface of radius $R$ in three dimensions whose exact mean curvature is $\\kappa_{\\mathrm{true}} = 2/R$. A numerical method that estimates $\\kappa$ with an error $\\epsilon_\\kappa$ will enforce a jump $[\\![p]\\!]_{\\mathrm{num}} = \\sigma (\\kappa_{\\mathrm{true}} + \\epsilon_\\kappa)$, producing a residual interfacial forcing proportional to $\\sigma \\epsilon_\\kappa$. In a distributional sense, the incorrect jump generates an effective singular body force in the momentum equation that can be approximated as\n$$\n\\mathbf{f}_{\\mathrm{res}}(\\mathbf{x}) \\approx \\sigma \\epsilon_\\kappa \\, \\mathbf{n}(\\mathbf{x}) \\, \\delta_{\\Gamma}(\\mathbf{x}),\n$$\nwhere $\\mathbf{n}$ is the unit normal vector on the interface pointing from the inner to the outer fluid, and $\\delta_{\\Gamma}$ is the surface Dirac distribution supported on $\\Gamma$. In a numerical method, $\\delta_{\\Gamma}$ is approximated by a smooth mollifier of width proportional to a grid spacing $h$, and $\\mathbf{n}$ can be computed from a signed-distance function to the interface.\n\nYour task is to implement a program that, for a two-dimensional periodic domain of side length $L$ discretized by a uniform grid of $N \\times N$ points with grid spacing $h = L/N$, models the effect of the residual interfacial force in the incompressible Stokes equations and computes the amplitude of parasitic currents. You should treat the interface as a circle of radius $R$ centered at the domain center and approximate the spherical-interface residual force using a smoothed interfacial delta distribution. The flow is periodic, and you must solve the steady incompressible Stokes equations in Fourier space by projecting the residual force onto divergence-free modes:\n$$\n-\\mu \\nabla^2 \\mathbf{u} + \\nabla p = \\mathbf{f}_{\\mathrm{res}}, \\quad \\nabla \\cdot \\mathbf{u} = 0, \\quad \\mathbf{u} \\text{ periodic on } [0,L]^2.\n$$\nThe residual force should be constructed as $\\mathbf{f}_{\\mathrm{res}}(\\mathbf{x}) = \\sigma \\epsilon_\\kappa \\, \\delta_\\varepsilon(\\phi(\\mathbf{x})) \\, \\mathbf{n}(\\mathbf{x})$, where $\\phi(\\mathbf{x})$ is the signed distance function to the circle, $\\mathbf{n}(\\mathbf{x}) = \\nabla \\phi(\\mathbf{x}) / \\|\\nabla \\phi(\\mathbf{x})\\|$, and $\\delta_\\varepsilon$ is a smooth approximation to the Dirac delta with support of width $\\varepsilon$ comparable to $h$. Use the cosine mollifier\n$$\n\\delta_\\varepsilon(\\phi) = \\begin{cases}\n\\dfrac{1}{2\\varepsilon}\\left(1 + \\cos\\left(\\dfrac{\\pi \\phi}{\\varepsilon}\\right)\\right), & |\\phi| \\le \\varepsilon, \\\\\n0, & \\text{otherwise},\n\\end{cases}\n$$\nwith $\\varepsilon = 1.5 h$. In Fourier space, for each wavevector $\\mathbf{k} = (k_x, k_y) \\neq \\mathbf{0}$, the solution satisfies\n$$\n\\widehat{\\mathbf{u}}(\\mathbf{k}) = \\frac{1}{\\mu \\|\\mathbf{k}\\|^2} \\left( \\mathbf{I} - \\frac{\\mathbf{k}\\mathbf{k}^\\top}{\\|\\mathbf{k}\\|^2} \\right) \\widehat{\\mathbf{f}}_{\\mathrm{res}}(\\mathbf{k}),\n$$\nand $\\widehat{\\mathbf{u}}(\\mathbf{0}) = \\mathbf{0}$.\n\nCompute the velocity field $\\mathbf{u}(\\mathbf{x})$ via inverse Fourier transform, and report the amplitude of parasitic currents defined as\n$$\nU_{\\max} = \\max_{\\mathbf{x}} \\|\\mathbf{u}(\\mathbf{x})\\|.\n$$\nAll physical quantities must be handled with consistent units: $\\sigma$ in $\\mathrm{N/m}$, $\\mu$ in $\\mathrm{Pa\\cdot s}$, $L$, $R$, $h$, and $\\varepsilon$ in $\\mathrm{m}$, $\\epsilon_\\kappa$ in $\\mathrm{m}^{-1}$, and $U_{\\max}$ in $\\mathrm{m/s}$. Angles, if any, must be in radians. Your program must produce numerical values of $U_{\\max}$ for the following test suite of parameter sets:\n\n- Test case 1 (happy path, zero curvature error): $\\sigma = 0.072\\,\\mathrm{N/m}$, $\\mu = 1.0\\times 10^{-3}\\,\\mathrm{Pa\\cdot s}$, $L = 0.04\\,\\mathrm{m}$, $R = 0.01\\,\\mathrm{m}$, $N = 128$, $\\epsilon_\\kappa = 0.0\\,\\mathrm{m}^{-1}$.\n- Test case 2 (nonzero curvature error): $\\sigma = 0.072\\,\\mathrm{N/m}$, $\\mu = 1.0\\times 10^{-3}\\,\\mathrm{Pa\\cdot s}$, $L = 0.04\\,\\mathrm{m}$, $R = 0.01\\,\\mathrm{m}$, $N = 128$, $\\epsilon_\\kappa = 0.5\\,\\mathrm{m}^{-1}$.\n- Test case 3 (refinement edge case): $\\sigma = 0.072\\,\\mathrm{N/m}$, $\\mu = 1.0\\times 10^{-3}\\,\\mathrm{Pa\\cdot s}$, $L = 0.04\\,\\mathrm{m}$, $R = 0.01\\,\\mathrm{m}$, $N = 256$, $\\epsilon_\\kappa = 0.5\\,\\mathrm{m}^{-1}$.\n- Test case 4 (viscosity variation edge case): $\\sigma = 0.072\\,\\mathrm{N/m}$, $\\mu = 1.0\\times 10^{-2}\\,\\mathrm{Pa\\cdot s}$, $L = 0.04\\,\\mathrm{m}$, $R = 0.01\\,\\mathrm{m}$, $N = 128$, $\\epsilon_\\kappa = 0.5\\,\\mathrm{m}^{-1}$.\n\nExpress the final answer in units of $\\mathrm{m/s}$, as a single line containing the results for the four test cases aggregated into a comma-separated list enclosed in square brackets. The output format must be exactly\n$$\n[\\text{result1},\\text{result2},\\text{result3},\\text{result4}],\n$$\nwhere each $\\text{result}$ is a floating-point number representing $U_{\\max}$ in $\\mathrm{m/s}$ for the corresponding test case.",
            "solution": "The problem is valid. It is scientifically grounded in the principles of low-Reynolds-number fluid dynamics (incompressible Stokes flow), well-posed, and provides a complete set of parameters and equations for a solvable numerical task. The objective is to compute the magnitude of non-physical \"parasitic\" currents that arise in numerical simulations of two-phase flow due to errors in curvature estimation, which in turn cause an erroneous surface tension force.\n\nThe solution will be developed by implementing a pseudo-spectral method to solve the governing Stokes equations with the specified residual force term in a two-dimensional periodic domain. The core of the method relies on the efficiency of the Fast Fourier Transform (FFT) for solving linear partial differential equations with constant coefficients on periodic domains.\n\nThe computational procedure is as follows:\n\n**1. Discretization and Force Field Construction**\n\nFirst, we discretize the 2D periodic domain $[0, L] \\times [0, L]$ using a uniform grid of $N \\times N$ points. The grid spacing is $h = L/N$. The coordinates of the grid points $(x_i, y_j)$ are given by $x_i = i h$ and $y_j = j h$ for $i, j \\in \\{0, 1, \\dots, N-1\\}$.\n\nThe residual force, which drives the parasitic currents, is modeled as a continuous field:\n$$\n\\mathbf{f}_{\\mathrm{res}}(\\mathbf{x}) = \\sigma \\epsilon_\\kappa \\, \\delta_\\varepsilon(\\phi(\\mathbf{x})) \\, \\mathbf{n}(\\mathbf{x})\n$$\nThis force is non-zero only in a thin layer around the circular interface. We construct this force field on the discrete grid by evaluating its components at each point $(x_i, y_j)$.\n\nThe components of this formulation are:\n-   **Signed Distance Function, $\\phi(\\mathbf{x})$**: For a circular interface of radius $R$ centered at $(L/2, L/2)$, the signed distance function is given by $\\phi(x,y) = \\sqrt{(x-L/2)^2 + (y-L/2)^2} - R$. A negative value of $\\phi$ indicates a point inside the circle, and a positive value indicates a point outside.\n\n-   **Normal Vector Field, $\\mathbf{n}(\\mathbf{x})$**: The unit normal vector pointing outwards from the interface is the normalized gradient of the signed distance function, $\\mathbf{n}(\\mathbf{x}) = \\nabla\\phi / \\|\\nabla\\phi\\|$. For the circular interface, this evaluates to:\n    $$\n    \\mathbf{n}(x,y) = \\frac{(x-L/2, y-L/2)}{\\sqrt{(x-L/2)^2 + (y-L/2)^2}}\n    $$\n    At the center of the circle, $(L/2, L/2)$, the normal is mathematically undefined. However, the smoothed delta function will be zero at this point as long as the interface width $\\varepsilon$ is smaller than the radius $R$, so the force is zero. Numerically, we can handle the division by zero by ensuring the product is zero.\n\n-   **Smoothed Dirac Delta Function, $\\delta_\\varepsilon(\\phi)$**: The surface Dirac delta is regularized using a cosine mollifier of width $\\varepsilon = 1.5 h$:\n    $$\n    \\delta_\\varepsilon(\\phi) = \\begin{cases}\n    \\frac{1}{2\\varepsilon}\\left(1 + \\cos\\left(\\frac{\\pi \\phi}{\\varepsilon}\\right)\\right), & |\\phi| \\le \\varepsilon \\\\\n    0, & \\text{otherwise}\n    \\end{cases}\n    $$\n    This function localizes the force to a narrow band of thickness $2\\varepsilon$ around the circle where $\\phi=0$.\n\nThe two components of the force field, $f_x(\\mathbf{x})$ and $f_y(\\mathbf{x})$, are computed on the grid. For the test case with $\\epsilon_\\kappa = 0$, the force field is identically zero, leading to a velocity of zero, as expected.\n\n**2. Fourier-Space Solution of the Stokes Equations**\n\nThe governing steady, incompressible Stokes equations with the residual force term are:\n$$\n-\\mu \\nabla^2 \\mathbf{u} + \\nabla p = \\mathbf{f}_{\\mathrm{res}}\n$$\n$$\n\\nabla \\cdot \\mathbf{u} = 0\n$$\nApplying the Fourier transform (denoted by a hat, e.g., $\\widehat{\\mathbf{u}}$) to these equations converts the spatial derivatives into algebraic multiplications with the wavevector $\\mathbf{k} = (k_x, k_y)$:\n$$\n\\mu \\|\\mathbf{k}\\|^2 \\widehat{\\mathbf{u}}(\\mathbf{k}) + i \\mathbf{k} \\widehat{p}(\\mathbf{k}) = \\widehat{\\mathbf{f}}_{\\mathrm{res}}(\\mathbf{k})\n$$\n$$\ni \\mathbf{k} \\cdot \\widehat{\\mathbf{u}}(\\mathbf{k}) = 0\n$$\nThe second equation is the incompressibility constraint in Fourier space. To solve for $\\widehat{\\mathbf{u}}$, we project the momentum equation onto the space of divergence-free vector fields. This is achieved using the projection operator $\\mathbf{P}(\\mathbf{k}) = \\mathbf{I} - \\frac{\\mathbf{k}\\mathbf{k}^\\top}{\\|\\mathbf{k}\\|^2}$, where $\\mathbf{I}$ is the identity matrix. Applying this operator to the momentum equation eliminates the pressure term, since $\\mathbf{P}(\\mathbf{k}) (i\\mathbf{k}\\widehat{p}) = \\mathbf{0}$.\n\nThis gives the solution for the velocity field in Fourier space for each wavevector $\\mathbf{k} \\neq \\mathbf{0}$:\n$$\n\\widehat{\\mathbf{u}}(\\mathbf{k}) = \\frac{1}{\\mu \\|\\mathbf{k}\\|^2} \\mathbf{P}(\\mathbf{k}) \\widehat{\\mathbf{f}}_{\\mathrm{res}}(\\mathbf{k})\n$$\nFor the zero wavevector $\\mathbf{k} = \\mathbf{0}$ (representing the mean flow), the problem specifies $\\widehat{\\mathbf{u}}(\\mathbf{0}) = \\mathbf{0}$. The singularity at $\\|\\mathbf{k}\\|^2=0$ is thus handled.\n\nThe components of the velocity in Fourier space are calculated as:\n$$\n\\widehat{u}_x(\\mathbf{k}) = \\frac{1}{\\mu \\|\\mathbf{k}\\|^4} \\left( k_y^2 \\widehat{f}_x(\\mathbf{k}) - k_x k_y \\widehat{f}_y(\\mathbf{k}) \\right)\n$$\n$$\n\\widehat{u}_y(\\mathbf{k}) = \\frac{1}{\\mu \\|\\mathbf{k}\\|^4} \\left( k_x^2 \\widehat{f}_y(\\mathbf{k}) - k_x k_y \\widehat{f}_x(\\mathbf{k}) \\right)\n$$\nThese calculations are performed for all wavevectors corresponding to the discrete grid. The wavevectors are given by $k_x = 2\\pi f_x$ and $k_y = 2\\pi f_y$, where $f_x$ and $f_y$ are the discrete frequencies obtained from `numpy.fft.fftfreq`.\n\n**3. Recovery of Real-Space Velocity and Final Result**\n\nThe real-space velocity field, $\\mathbf{u}(\\mathbf{x}) = (u_x(\\mathbf{x}), u_y(\\mathbf{x}))$, is recovered by applying the inverse 2D FFT to the Fourier-space velocity components, $\\widehat{u}_x(\\mathbf{k})$ and $\\widehat{u}_y(\\mathbf{k})$.\n\nFinally, the amplitude of the parasitic currents, $U_{\\max}$, is determined by calculating the maximum magnitude of the velocity vector across all grid points:\n$$\nU_{\\max} = \\max_{\\mathbf{x}} \\|\\mathbf{u}(\\mathbf{x})\\| = \\max_{i,j} \\sqrt{u_x(x_i, y_j)^2 + u_y(x_i, y_j)^2}\n$$\nThis procedure is repeated for each parameter set provided in the test suite to obtain the final results.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1: sigma, mu, L, R, N, eps_kappa\n        (0.072, 1.0e-3, 0.04, 0.01, 128, 0.0),\n        # Test case 2\n        (0.072, 1.0e-3, 0.04, 0.01, 128, 0.5),\n        # Test case 3\n        (0.072, 1.0e-3, 0.04, 0.01, 256, 0.5),\n        # Test case 4\n        (0.072, 1.0e-2, 0.04, 0.01, 128, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        U_max = compute_parasitic_current_amplitude(*case)\n        results.append(U_max)\n\n    # Format output as specified\n    formatted_results = [f\"{r:.12f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\ndef compute_parasitic_current_amplitude(sigma, mu, L, R, N, eps_kappa):\n    \"\"\"\n    Computes the amplitude of parasitic currents for a given set of parameters.\n\n    Args:\n        sigma (float): Surface tension coefficient (N/m).\n        mu (float): Dynamic viscosity (Pa·s).\n        L (float): Domain side length (m).\n        R (float): Circle radius (m).\n        N (int): Number of grid points per dimension.\n        eps_kappa (float): Curvature error (m^-1).\n\n    Returns:\n        float: The maximum velocity amplitude U_max (m/s).\n    \"\"\"\n\n    # If there is no curvature error, the residual force is zero, thus velocity is zero.\n    if eps_kappa == 0.0:\n        return 0.0\n\n    # 1. Grid Generation and Parameters\n    h = L / N\n    epsilon = 1.5 * h\n    # Grid coordinates\n    coords = np.arange(N) * h\n    X, Y = np.meshgrid(coords, coords)\n\n    # 2. Construct the Residual Force Field in Real Space\n    center_x, center_y = L / 2, L / 2\n    dist = np.sqrt((X - center_x)**2 + (Y - center_y)**2)\n    \n    # Signed distance function\n    phi = dist - R\n\n    # Smoothed Dirac delta function (cosine mollifier)\n    delta = np.zeros_like(phi)\n    mask = np.abs(phi) <= epsilon\n    phi_masked = phi[mask]\n    delta[mask] = (1 / (2 * epsilon)) * (1 + np.cos(np.pi * phi_masked / epsilon))\n\n    # Normal vector field. Handle division by zero at the center.\n    # The normal is undefined at the center, but delta will be zero there if R > epsilon,\n    # so the force will correctly be zero.\n    dist_inv = np.divide(1.0, dist, out=np.zeros_like(dist), where=dist != 0)\n    nx = (X - center_x) * dist_inv\n    ny = (Y - center_y) * dist_inv\n\n    # Assemble the force components\n    f_coeff = sigma * eps_kappa\n    fx = f_coeff * delta * nx\n    fy = f_coeff * delta * ny\n\n    # 3. Fourier Transform the Force Field\n    hat_fx = np.fft.fft2(fx)\n    hat_fy = np.fft.fft2(fy)\n\n    # 4. Solve for Velocity in Fourier Space\n    # Wavevectors\n    freq = np.fft.fftfreq(N, d=h)\n    k = 2 * np.pi * freq\n    Kx, Ky = np.meshgrid(k, k) # Kx varies along cols (axis 1), Ky along rows (axis 0)\n\n    # Squared magnitude of wavevectors\n    K2 = Kx**2 + Ky**2\n\n    # Stokes solver in Fourier space. The projection operator and 1/(mu*K^2) are combined.\n    # The term 1/K^4 must avoid the K=0 singularity.\n    inv_mu_K4 = np.divide(1.0, mu * K2**2, out=np.zeros_like(K2), where=K2 != 0)\n\n    # Calculate velocity components in Fourier space\n    hat_ux = inv_mu_K4 * (Ky**2 * hat_fx - Kx * Ky * hat_fy)\n    hat_uy = inv_mu_K4 * (Kx**2 * hat_fy - Kx * Ky * hat_fx)\n    \n    # The k=0 mode (mean velocity) is correctly set to zero by the `where` clause in np.divide.\n\n    # 5. Inverse Fourier Transform to get Real-Space Velocity\n    ux = np.fft.ifft2(hat_ux).real\n    uy = np.fft.ifft2(hat_uy).real\n\n    # 6. Compute the Amplitude of Parasitic Currents\n    vel_mag = np.sqrt(ux**2 + uy**2)\n    U_max = np.max(vel_mag)\n\n    return U_max\n\nif __name__ == '__main__':\n    solve()\n\n```"
        }
    ]
}