{
    "hands_on_practices": [
        {
            "introduction": "At the heart of any immersed boundary method is the challenge of representing a boundary that cuts through a fixed grid. This exercise tackles this problem head-on by having you derive custom finite-difference stencils for a fluid node right next to the boundary. Using Taylor series and polynomial interpolation, you will construct a modified stencil that incorporates the known boundary value, a fundamental technique in sharp-interface methods, and analyze its accuracy and anisotropy .",
            "id": "3332789",
            "problem": "Consider a two-dimensional uniform Cartesian grid with spacing $h$ in both the $x$ and $y$ directions. A sharp-interface immersed boundary intersects the grid segment between the fluid node at $x_0$ and the exterior node at $x_{-1} = x_0 - h$. The boundary location is $x_b = x_0 - \\alpha h$ with $0 < \\alpha < 1$. A Dirichlet boundary condition is prescribed at the immersed boundary, so that $u(x_b) = u_b$ is known. Let $u_0 = u(x_0)$ and $u_1 = u(x_1)$ denote the fluid values at $x_0$ and its neighbor $x_1 = x_0 + h$ along the $x$ axis. Assume $u$ is sufficiently smooth.\n\nUsing only definitions of derivatives and Taylor series expansions, derive modified finite-difference stencils appropriate to a sharp-interface immersed boundary method as follows:\n\n- Construct a quadratic interpolant in $x$ that uses the three data points $(x_b, u_b)$, $(x_0, u_0)$, and $(x_1, u_1)$. Use this interpolant to obtain a one-sided, second-order accurate formula for the $x$-gradient $u_x$ at the fluid node $x_0$. Express the resulting stencil coefficients explicitly in terms of $\\alpha$.\n- Using the same quadratic interpolant, derive a modified one-sided approximation for the $x$-second derivative $u_{xx}$ at $x_0$. Combine this with a standard centered second-difference in $y$ to form a discrete Laplacian near the boundary. Determine the leading-order truncation error terms for the $x$-gradient and for the Laplacian. Discuss, in terms of orders and leading coefficients, how the one-sided $x$-discretization induces anisotropy in the truncation error compared to the centered $y$-discretization.\n\nFinally, let the local truncation error of the $x$-gradient approximation at $x_0$ be written in the form\n$$\nu_x(x_0)_{\\text{approx}} - u_x(x_0) = C(\\alpha)\\, h^{2}\\, u_{xxx}(x_0) + \\mathcal{O}(h^{3}),\n$$\nwhere $C(\\alpha)$ is a dimensionless coefficient depending only on $\\alpha$. Provide the closed-form analytic expression for $C(\\alpha)$.",
            "solution": "The problem is well-posed, scientifically grounded, and contains all necessary information for a complete derivation. It is a standard exercise in the development of numerical methods for partial differential equations with immersed boundaries.\n\nThe core of the task is to construct a polynomial interpolant passing through three non-uniformly spaced points and then use its derivatives to approximate the derivatives of the underlying function $u(x)$.\n\nLet the three points be $(x_b, u_b)$, $(x_0, u_0)$, and $(x_1, u_1)$. We define a local coordinate $\\xi$ to simplify the algebra:\n$$\nx = x_0 + \\xi h \\implies \\xi = \\frac{x - x_0}{h}\n$$\nIn this new coordinate system, the locations of our data points are:\n$$\nx_b = x_0 - \\alpha h \\implies \\xi_b = -\\alpha\n$$\n$$\nx_0 \\implies \\xi_0 = 0\n$$\n$$\nx_1 = x_0 + h \\implies \\xi_1 = 1\n$$\nLet the quadratic interpolant be $P(\\xi) = a\\xi^2 + b\\xi + c$. We enforce that $P(\\xi)$ passes through the three given data points:\n$1$. At $\\xi=0$: $P(0) = c = u_0$.\n$2$. At $\\xi=1$: $P(1) = a(1)^2 + b(1) + c = u_1 \\implies a + b + u_0 = u_1 \\implies a + b = u_1 - u_0$.\n$3$. At $\\xi=-\\alpha$: $P(-\\alpha) = a(-\\alpha)^2 + b(-\\alpha) + c = u_b \\implies a\\alpha^2 - b\\alpha + u_0 = u_b \\implies a\\alpha^2 - b\\alpha = u_b - u_0$.\n\nWe have a system of two linear equations for the coefficients $a$ and $b$:\n$$\n\\begin{cases}\na + b = u_1 - u_0 \\\\\na\\alpha^2 - b\\alpha = u_b - u_0\n\\end{cases}\n$$\nFrom the first equation, we have $b = u_1 - u_0 - a$. Substituting this into the second equation:\n$$\na\\alpha^2 - (u_1 - u_0 - a)\\alpha = u_b - u_0\n$$\n$$\na\\alpha^2 - \\alpha(u_1 - u_0) + a\\alpha = u_b - u_0\n$$\n$$\na(\\alpha^2 + \\alpha) = u_b - u_0 + \\alpha(u_1 - u_0)\n$$\n$$\na \\alpha(\\alpha+1) = u_b - (1+\\alpha)u_0 + \\alpha u_1\n$$\nSolving for $a$:\n$$\na = \\frac{u_b - (1+\\alpha)u_0 + \\alpha u_1}{\\alpha(\\alpha+1)}\n$$\nNow, we solve for $b$ using $b = u_1 - u_0 - a$:\n$$\nb = u_1 - u_0 - \\frac{u_b - (1+\\alpha)u_0 + \\alpha u_1}{\\alpha(\\alpha+1)}\n$$\nPutting everything over a common denominator $\\alpha(\\alpha+1)$:\n$$\nb = \\frac{\\alpha(\\alpha+1)(u_1 - u_0) - [u_b - (1+\\alpha)u_0 + \\alpha u_1]}{\\alpha(\\alpha+1)}\n$$\n$$\nb = \\frac{(\\alpha^2+\\alpha)u_1 - (\\alpha^2+\\alpha)u_0 - u_b + (1+\\alpha)u_0 - \\alpha u_1}{\\alpha(\\alpha+1)}\n$$\nGrouping terms by $u_b$, $u_0$, and $u_1$:\n$$\nb = \\frac{-u_b + (-\\alpha^2-\\alpha+1+\\alpha)u_0 + (\\alpha^2+\\alpha-\\alpha)u_1}{\\alpha(\\alpha+1)} = \\frac{-u_b + (1-\\alpha^2)u_0 + \\alpha^2 u_1}{\\alpha(\\alpha+1)}\n$$\n\n**Approximation for the $x$-gradient $u_x$ at $x_0$**\n\nThe first derivative of $u$ with respect to $x$ is related to the derivative of $P$ with respect to $\\xi$ by the chain rule: $\\frac{du}{dx} = \\frac{d P}{d\\xi}\\frac{d\\xi}{dx}$. Since $\\frac{d\\xi}{dx} = \\frac{d}{dx}\\left(\\frac{x-x_0}{h}\\right) = \\frac{1}{h}$, we have $\\frac{du}{dx} = \\frac{1}{h}\\frac{dP}{d\\xi}$.\nThe derivative of the interpolating polynomial is $\\frac{dP}{d\\xi} = 2a\\xi + b$.\nWe approximate $u_x(x_0)$ by evaluating the derivative of the interpolant at $x_0$ (which is $\\xi=0$):\n$$\nu_x(x_0)_{\\text{approx}} = \\frac{1}{h}\\frac{dP}{d\\xi}\\Big|_{\\xi=0} = \\frac{1}{h}(2a(0) + b) = \\frac{b}{h}\n$$\nSubstituting our expression for $b$:\n$$\nu_x(x_0)_{\\text{approx}} = \\frac{1}{h} \\left( \\frac{-u_b + (1-\\alpha^2)u_0 + \\alpha^2 u_1}{\\alpha(\\alpha+1)} \\right)\n$$\nWe can express this as a finite-difference stencil. Noting that $1-\\alpha^2=(1-\\alpha)(1+\\alpha)$ and $\\alpha^2 = \\alpha \\cdot \\alpha$:\n$$\nu_x(x_0)_{\\text{approx}} = \\frac{1}{h} \\left( \\frac{-1}{\\alpha(\\alpha+1)} u_b + \\frac{(1-\\alpha)(1+\\alpha)}{\\alpha(\\alpha+1)} u_0 + \\frac{\\alpha^2}{\\alpha(\\alpha+1)} u_1 \\right)\n$$\n$$\nu_x(x_0)_{\\text{approx}} = \\frac{1}{h} \\left( \\frac{-1}{\\alpha(\\alpha+1)} u_b + \\frac{1-\\alpha}{\\alpha} u_0 + \\frac{\\alpha}{\\alpha+1} u_1 \\right)\n$$\nThis is the required second-order accurate formula for the $x$-gradient at $x_0$.\n\n**Approximation for the $x$-second derivative $u_{xx}$ at $x_0$ and the Laplacian**\n\nSimilarly, for the second derivative, we use $\\frac{d^2u}{dx^2} = \\frac{d}{dx}\\left(\\frac{1}{h}\\frac{dP}{d\\xi}\\right) = \\frac{1}{h}\\frac{d^2P}{d\\xi^2}\\frac{d\\xi}{dx} = \\frac{1}{h^2}\\frac{d^2P}{d\\xi^2}$.\nThe second derivative of the interpolant is $\\frac{d^2P}{d\\xi^2} = 2a$.\nWe approximate $u_{xx}(x_0)$ by evaluating this at $x_0$ (which is $\\xi=0$):\n$$\nu_{xx}(x_0)_{\\text{approx}} = \\frac{2a}{h^2}\n$$\nSubstituting our expression for $a$:\n$$\nu_{xx}(x_0)_{\\text{approx}} = \\frac{2}{h^2} \\left( \\frac{u_b - (1+\\alpha)u_0 + \\alpha u_1}{\\alpha(\\alpha+1)} \\right)\n$$\nThis is the modified one-sided approximation for $u_{xx}$ at $x_0$. A discrete Laplacian near the boundary, at a point $(x_0, y_j)$, is formed by combining this with the standard centered second-difference in $y$:\n$$\n\\nabla^2 u(x_0, y_j)_{\\text{approx}} = u_{xx}(x_0)_{\\text{approx}} + u_{yy}(y_j)_{\\text{approx}}\n$$\n$$\n\\nabla^2 u(x_0, y_j)_{\\text{approx}} = \\frac{2}{h^2\\alpha(\\alpha+1)} \\left( u_b - (1+\\alpha)u_0 + \\alpha u_1 \\right) + \\frac{u(x_0, y_{j+1}) - 2u(x_0, y_j) + u(x_0, y_{j-1})}{h^2}\n$$\nwhere $u_0 = u(x_0, y_j)$, $u_1 = u(x_1, y_j)$, and $u_b = u(x_b, y_j)$.\n\n**Truncation Error Analysis**\n\nTo find the truncation error, we substitute the Taylor series expansions of $u_1$ and $u_b$ around $x_0$ into our stencils. All derivatives hereafter are evaluated at $x_0$.\n$u_1 = u(x_0+h) = u_0 + h u_x + \\frac{h^2}{2} u_{xx} + \\frac{h^3}{6} u_{xxx} + \\frac{h^4}{24} u_{xxxx} + \\mathcal{O}(h^5)$\n$u_b = u(x_0-\\alpha h) = u_0 - \\alpha h u_x + \\frac{(\\alpha h)^2}{2} u_{xx} - \\frac{(\\alpha h)^3}{6} u_{xxx} + \\frac{(\\alpha h)^4}{24} u_{xxxx} + \\mathcal{O}(h^5)$\n\nFor the $x$-gradient, $u_x(x_0)_{\\text{approx}} = (b/h)$. Expanding $b$ using the Taylor series:\n$b \\alpha(\\alpha+1) = -u_b + (1-\\alpha^2)u_0 + \\alpha^2 u_1$\n$= -(u_0 - \\alpha h u_x + \\frac{\\alpha^2 h^2}{2} u_{xx} - \\frac{\\alpha^3 h^3}{6} u_{xxx} + \\dots) + (1-\\alpha^2)u_0 + \\alpha^2(u_0 + h u_x + \\frac{h^2}{2} u_{xx} + \\frac{h^3}{6} u_{xxx} + \\dots)$\nGrouping terms by derivative order:\n$u_0$: $-1+(1-\\alpha^2)+\\alpha^2 = 0$.\n$u_x$: $\\alpha h + \\alpha^2 h = h(\\alpha + \\alpha^2) = h u_x \\alpha(\\alpha+1)$.\n$u_{xx}$: $-\\frac{\\alpha^2 h^2}{2} + \\frac{\\alpha^2 h^2}{2} = 0$.\n$u_{xxx}$: $\\frac{\\alpha^3 h^3}{6} + \\frac{\\alpha^2 h^3}{6} = \\frac{h^3}{6}(\\alpha^3+\\alpha^2) = \\frac{h^3}{6}\\alpha^2(\\alpha+1)$.\nSo, $b \\alpha(\\alpha+1) = h u_x \\alpha(\\alpha+1) + \\frac{h^3}{6}\\alpha^2(\\alpha+1) u_{xxx} + \\mathcal{O}(h^4)$.\nDividing by $\\alpha(\\alpha+1)$ gives $b = h u_x + \\frac{\\alpha h^3}{6} u_{xxx} + \\mathcal{O}(h^4)$.\nThen $u_x(x_0)_{\\text{approx}} = \\frac{b}{h} = u_x + \\frac{\\alpha h^2}{6} u_{xxx} + \\mathcal{O}(h^3)$.\nThe leading-order truncation error for the $x$-gradient is $\\tau_x = \\frac{\\alpha}{6} h^2 u_{xxx}$. The approximation is second-order accurate.\n\nFor the $x$-second derivative, $u_{xx}(x_0)_{\\text{approx}} = 2a/h^2$. Expanding $a$:\n$a \\alpha(\\alpha+1) = u_b - (1+\\alpha)u_0 + \\alpha u_1$\n$= (u_0 - \\alpha h u_x + \\frac{\\alpha^2 h^2}{2} u_{xx} - \\dots) - (1+\\alpha)u_0 + \\alpha(u_0 + h u_x + \\frac{h^2}{2} u_{xx} + \\frac{h^3}{6} u_{xxx} - \\dots)$\n$u_0$: $1-(1+\\alpha)+\\alpha = 0$.\n$u_x$: $-\\alpha h + \\alpha h = 0$.\n$u_{xx}$: $\\frac{\\alpha^2 h^2}{2} + \\frac{\\alpha h^2}{2} = \\frac{h^2}{2}(\\alpha^2+\\alpha) = \\frac{h^2}{2}\\alpha(\\alpha+1)$.\n$u_{xxx}$: $-\\frac{\\alpha^3 h^3}{6} + \\frac{\\alpha h^3}{6} = \\frac{h^3}{6}(\\alpha-\\alpha^3) = \\frac{h^3}{6}\\alpha(1-\\alpha^2) = \\frac{h^3}{6}\\alpha(1-\\alpha)(1+\\alpha)$.\nSo, $a\\alpha(\\alpha+1) = \\frac{h^2}{2}u_{xx}\\alpha(\\alpha+1) + \\frac{h^3}{6}u_{xxx}\\alpha(1-\\alpha)(1+\\alpha) + \\mathcal{O}(h^4)$.\nDividing by $\\alpha(\\alpha+1)$ gives $a = \\frac{h^2}{2}u_{xx} + \\frac{h^3}{6}(1-\\alpha)u_{xxx} + \\mathcal{O}(h^4)$.\nThen $u_{xx}(x_0)_{\\text{approx}} = \\frac{2a}{h^2} = u_{xx} + \\frac{1-\\alpha}{3}h u_{xxx} + \\mathcal{O}(h^2)$.\nThe leading-order truncation error for the $x$-second derivative is $\\tau_{xx} = \\frac{1-\\alpha}{3} h u_{xxx}$. The approximation is first-order accurate.\n\nThe truncation error for the standard centered difference in $y$ is $\\tau_{yy} = \\frac{h^2}{12}u_{yyyy} + \\mathcal{O}(h^4)$.\nThe truncation error for the Laplacian is $\\tau_{\\nabla^2} = \\tau_{xx} + \\tau_{yy} = \\frac{1-\\alpha}{3} h u_{xxx} + \\mathcal{O}(h^2)$, as the error from the $x$-discretization is dominant.\n\nThe one-sided discretization induces significant anisotropy in the truncation error. The leading error term for the Laplacian, $\\frac{1-\\alpha}{3} h u_{xxx}$, is first-order in $h$ and depends on a third derivative in $x$. In contrast, the discretization in the $y$-direction is second-order, $\\mathcal{O}(h^2)$, and its leading error term depends on a fourth derivative in $y$. This means the error is not symmetric with respect to coordinate directions; it is larger and has a different character in the direction normal to the boundary compared to the tangential direction. The leading error coefficient, $\\frac{1-\\alpha}{3}$, also varies with the sub-grid position of the boundary, unlike the constant coefficient $\\frac{1}{12}$ for the $y$-direction.\n\n**Derivation of the coefficient $C(\\alpha)$**\n\nThe problem states the local truncation error of the $x$-gradient approximation in the form:\n$$\nu_x(x_0)_{\\text{approx}} - u_x(x_0) = C(\\alpha)\\, h^{2}\\, u_{xxx}(x_0) + \\mathcal{O}(h^{3})\n$$\nFrom our truncation error analysis for the $x$-gradient, we found:\n$$\nu_x(x_0)_{\\text{approx}} - u_x(x_0) = \\frac{\\alpha}{6} h^2 u_{xxx}(x_0) + \\mathcal{O}(h^3)\n$$\nBy direct comparison of these two expressions, we can identify the coefficient $C(\\alpha)$.\n$$\nC(\\alpha) = \\frac{\\alpha}{6}\n$$",
            "answer": "$$\n\\boxed{\\frac{\\alpha}{6}}\n$$"
        },
        {
            "introduction": "Numerical simulations are not perfect, and understanding their artifacts is as important as understanding the physics they model. This practice delves into the phenomenon of \"parasitic currents,\" unphysical flows that arise in simulations of multiphase systems due to discretization errors in the surface tension force. You will implement a spectral solver for the Stokes equations to quantify how errors in curvature estimation create these spurious velocities, providing a tangible link between numerical accuracy and simulation quality .",
            "id": "3332836",
            "problem": "Consider a static, immiscible two-phase flow with a smooth interface separating two Newtonian fluids of equal viscosity, governed by the incompressible Stokes equations. The fundamental base is the incompressible Stokes momentum balance and the continuity equation, together with the classical Young–Laplace pressure jump for surface tension. Specifically, let the fluid velocity be denoted by $\\mathbf{u}(\\mathbf{x})$ and pressure by $p(\\mathbf{x})$, with dynamic viscosity $\\mu$ and surface tension coefficient $\\sigma$. Assume low Reynolds number so that inertial terms are negligible. The governing equations in the bulk are\n$$\n-\\mu \\nabla^2 \\mathbf{u} + \\nabla p = \\mathbf{0}, \\quad \\nabla \\cdot \\mathbf{u} = 0,\n$$\nand the sharp-interface condition on the interface $\\Gamma$ is a pressure jump equal to surface tension times mean curvature and continuity of velocity,\n$$\n[\\![p]\\!] = \\sigma \\kappa, \\quad [\\![\\mathbf{u}]\\!] = \\mathbf{0},\n$$\nwhere $[\\![\\cdot]\\!]$ denotes the difference of the quantity across the interface, and $\\kappa$ is the mean curvature of the interface. Consider a spherical interface of radius $R$ in three dimensions whose exact mean curvature is $\\kappa_{\\mathrm{true}} = 2/R$. A numerical method that estimates $\\kappa$ with an error $\\epsilon_\\kappa$ will enforce a jump $[\\![p]\\!]_{\\mathrm{num}} = \\sigma (\\kappa_{\\mathrm{true}} + \\epsilon_\\kappa)$, producing a residual interfacial forcing proportional to $\\sigma \\epsilon_\\kappa$. In a distributional sense, the incorrect jump generates an effective singular body force in the momentum equation that can be approximated as\n$$\n\\mathbf{f}_{\\mathrm{res}}(\\mathbf{x}) \\approx \\sigma \\epsilon_\\kappa \\, \\mathbf{n}(\\mathbf{x}) \\, \\delta_{\\Gamma}(\\mathbf{x}),\n$$\nwhere $\\mathbf{n}$ is the unit normal vector on the interface pointing from the inner to the outer fluid, and $\\delta_{\\Gamma}$ is the surface Dirac distribution supported on $\\Gamma$. In a numerical method, $\\delta_{\\Gamma}$ is approximated by a smooth mollifier of width proportional to a grid spacing $h$, and $\\mathbf{n}$ can be computed from a signed-distance function to the interface.\n\nYour task is to implement a program that, for a two-dimensional periodic domain of side length $L$ discretized by a uniform grid of $N \\times N$ points with grid spacing $h = L/N$, models the effect of the residual interfacial force in the incompressible Stokes equations and computes the amplitude of parasitic currents. You should treat the interface as a circle of radius $R$ centered at the domain center and approximate the spherical-interface residual force using a smoothed interfacial delta distribution. The flow is periodic, and you must solve the steady incompressible Stokes equations in Fourier space by projecting the residual force onto divergence-free modes:\n$$\n-\\mu \\nabla^2 \\mathbf{u} + \\nabla p = \\mathbf{f}_{\\mathrm{res}}, \\quad \\nabla \\cdot \\mathbf{u} = 0, \\quad \\mathbf{u} \\text{ periodic on } [0,L]^2.\n$$\nThe residual force should be constructed as $\\mathbf{f}_{\\mathrm{res}}(\\mathbf{x}) = \\sigma \\epsilon_\\kappa \\, \\delta_\\varepsilon(\\phi(\\mathbf{x})) \\, \\mathbf{n}(\\mathbf{x})$, where $\\phi(\\mathbf{x})$ is the signed distance function to the circle, $\\mathbf{n}(\\mathbf{x}) = \\nabla \\phi(\\mathbf{x}) / \\|\\nabla \\phi(\\mathbf{x})\\|$, and $\\delta_\\varepsilon$ is a smooth approximation to the Dirac delta with support of width $\\varepsilon$ comparable to $h$. Use the cosine mollifier\n$$\n\\delta_\\varepsilon(\\phi) = \\begin{cases}\n\\dfrac{1}{2\\varepsilon}\\left(1 + \\cos\\left(\\dfrac{\\pi \\phi}{\\varepsilon}\\right)\\right), & |\\phi| \\le \\varepsilon, \\\\[6pt]\n0, & \\text{otherwise},\n\\end{cases}\n$$\nwith $\\varepsilon = 1.5 h$. In Fourier space, for each wavevector $\\mathbf{k} = (k_x, k_y) \\neq \\mathbf{0}$, the solution satisfies\n$$\n\\widehat{\\mathbf{u}}(\\mathbf{k}) = \\frac{1}{\\mu \\|\\mathbf{k}\\|^2} \\left( \\mathbf{I} - \\frac{\\mathbf{k}\\mathbf{k}^\\top}{\\|\\mathbf{k}\\|^2} \\right) \\widehat{\\mathbf{f}}_{\\mathrm{res}}(\\mathbf{k}),\n$$\nand $\\widehat{\\mathbf{u}}(\\mathbf{0}) = \\mathbf{0}$.\n\nCompute the velocity field $\\mathbf{u}(\\mathbf{x})$ via inverse Fourier transform, and report the amplitude of parasitic currents defined as\n$$\nU_{\\max} = \\max_{\\mathbf{x}} \\|\\mathbf{u}(\\mathbf{x})\\|.\n$$\nAll physical quantities must be handled with consistent units: $\\sigma$ in $\\mathrm{N/m}$, $\\mu$ in $\\mathrm{Pa\\cdot s}$, $L$, $R$, $h$, and $\\varepsilon$ in $\\mathrm{m}$, $\\epsilon_\\kappa$ in $\\mathrm{m}^{-1}$, and $U_{\\max}$ in $\\mathrm{m/s}$. Angles, if any, must be in radians. Your program must produce numerical values of $U_{\\max}$ for the following test suite of parameter sets:\n\n- Test case 1 (happy path, zero curvature error): $\\sigma = 0.072\\,\\mathrm{N/m}$, $\\mu = 1.0\\times 10^{-3}\\,\\mathrm{Pa\\cdot s}$, $L = 0.04\\,\\mathrm{m}$, $R = 0.01\\,\\mathrm{m}$, $N = 128$, $\\epsilon_\\kappa = 0.0\\,\\mathrm{m}^{-1}$.\n- Test case 2 (nonzero curvature error): $\\sigma = 0.072\\,\\mathrm{N/m}$, $\\mu = 1.0\\times 10^{-3}\\,\\mathrm{Pa\\cdot s}$, $L = 0.04\\,\\mathrm{m}$, $R = 0.01\\,\\mathrm{m}$, $N = 128$, $\\epsilon_\\kappa = 0.5\\,\\mathrm{m}^{-1}$.\n- Test case 3 (refinement edge case): $\\sigma = 0.072\\,\\mathrm{N/m}$, $\\mu = 1.0\\times 10^{-3}\\,\\mathrm{Pa\\cdot s}$, $L = 0.04\\,\\mathrm{m}$, $R = 0.01\\,\\mathrm{m}$, $N = 256$, $\\epsilon_\\kappa = 0.5\\,\\mathrm{m}^{-1}$.\n- Test case 4 (viscosity variation edge case): $\\sigma = 0.072\\,\\mathrm{N/m}$, $\\mu = 1.0\\times 10^{-2}\\,\\mathrm{Pa\\cdot s}$, $L = 0.04\\,\\mathrm{m}$, $R = 0.01\\,\\mathrm{m}$, $N = 128$, $\\epsilon_\\kappa = 0.5\\,\\mathrm{m}^{-1}$.\n\nExpress the final answer in units of $\\mathrm{m/s}$, as a single line containing the results for the four test cases aggregated into a comma-separated list enclosed in square brackets. The output format must be exactly\n$$\n[\\text{result1},\\text{result2},\\text{result3},\\text{result4}],\n$$\nwhere each $\\text{result}$ is a floating-point number representing $U_{\\max}$ in $\\mathrm{m/s}$ for the corresponding test case.",
            "solution": "The problem is valid. It is scientifically grounded in the principles of low-Reynolds-number fluid dynamics (incompressible Stokes flow), well-posed, and provides a complete set of parameters and equations for a solvable numerical task. The objective is to compute the magnitude of non-physical \"parasitic\" currents that arise in numerical simulations of two-phase flow due to errors in curvature estimation, which in turn cause an erroneous surface tension force.\n\nThe solution will be developed by implementing a pseudo-spectral method to solve the governing Stokes equations with the specified residual force term in a two-dimensional periodic domain. The core of the method relies on the efficiency of the Fast Fourier Transform (FFT) for solving linear partial differential equations with constant coefficients on periodic domains.\n\nThe computational procedure is as follows:\n\n**1. Discretization and Force Field Construction**\n\nFirst, we discretize the 2D periodic domain $[0, L] \\times [0, L]$ using a uniform grid of $N \\times N$ points. The grid spacing is $h = L/N$. The coordinates of the grid points $(x_i, y_j)$ are given by $x_i = i h$ and $y_j = j h$ for $i, j \\in \\{0, 1, \\dots, N-1\\}$.\n\nThe residual force, which drives the parasitic currents, is modeled as a continuous field:\n$$\n\\mathbf{f}_{\\mathrm{res}}(\\mathbf{x}) = \\sigma \\epsilon_\\kappa \\, \\delta_\\varepsilon(\\phi(\\mathbf{x})) \\, \\mathbf{n}(\\mathbf{x})\n$$\nThis force is non-zero only in a thin layer around the circular interface. We construct this force field on the discrete grid by evaluating its components at each point $(x_i, y_j)$.\n\nThe components of this formulation are:\n-   **Signed Distance Function, $\\phi(\\mathbf{x})$**: For a circular interface of radius $R$ centered at $(L/2, L/2)$, the signed distance function is given by $\\phi(x,y) = \\sqrt{(x-L/2)^2 + (y-L/2)^2} - R$. A negative value of $\\phi$ indicates a point inside the circle, and a positive value indicates a point outside.\n\n-   **Normal Vector Field, $\\mathbf{n}(\\mathbf{x})$**: The unit normal vector pointing outwards from the interface is the normalized gradient of the signed distance function, $\\mathbf{n}(\\mathbf{x}) = \\nabla\\phi / \\|\\nabla\\phi\\|$. For the circular interface, this evaluates to:\n    $$\n    \\mathbf{n}(x,y) = \\frac{(x-L/2, y-L/2)}{\\sqrt{(x-L/2)^2 + (y-L/2)^2}}\n    $$\n    At the center of the circle, $(L/2, L/2)$, the normal is mathematically undefined. However, the smoothed delta function will be zero at this point as long as the interface width $\\varepsilon$ is smaller than the radius $R$, so the force is zero. Numerically, we can handle the division by zero by ensuring the product is zero.\n\n-   **Smoothed Dirac Delta Function, $\\delta_\\varepsilon(\\phi)$**: The surface Dirac delta is regularized using a cosine mollifier of width $\\varepsilon = 1.5 h$:\n    $$\n    \\delta_\\varepsilon(\\phi) = \\begin{cases}\n    \\frac{1}{2\\varepsilon}\\left(1 + \\cos\\left(\\frac{\\pi \\phi}{\\varepsilon}\\right)\\right), & |\\phi| \\le \\varepsilon \\\\\n    0, & \\text{otherwise}\n    \\end{cases}\n    $$\n    This function localizes the force to a narrow band of thickness $2\\varepsilon$ around the circle where $\\phi=0$.\n\nThe two components of the force field, $f_x(\\mathbf{x})$ and $f_y(\\mathbf{x})$, are computed on the grid. For the test case with $\\epsilon_\\kappa = 0$, the force field is identically zero, leading to a velocity of zero, as expected.\n\n**2. Fourier-Space Solution of the Stokes Equations**\n\nThe governing steady, incompressible Stokes equations with the residual force term are:\n$$\n-\\mu \\nabla^2 \\mathbf{u} + \\nabla p = \\mathbf{f}_{\\mathrm{res}}\n$$\n$$\n\\nabla \\cdot \\mathbf{u} = 0\n$$\nApplying the Fourier transform (denoted by a hat, e.g., $\\widehat{\\mathbf{u}}$) to these equations converts the spatial derivatives into algebraic multiplications with the wavevector $\\mathbf{k} = (k_x, k_y)$:\n$$\n\\mu \\|\\mathbf{k}\\|^2 \\widehat{\\mathbf{u}}(\\mathbf{k}) + i \\mathbf{k} \\widehat{p}(\\mathbf{k}) = \\widehat{\\mathbf{f}}_{\\mathrm{res}}(\\mathbf{k})\n$$\n$$\ni \\mathbf{k} \\cdot \\widehat{\\mathbf{u}}(\\mathbf{k}) = 0\n$$\nThe second equation is the incompressibility constraint in Fourier space. To solve for $\\widehat{\\mathbf{u}}$, we project the momentum equation onto the space of divergence-free vector fields. This is achieved using the projection operator $\\mathbf{P}(\\mathbf{k}) = \\mathbf{I} - \\frac{\\mathbf{k}\\mathbf{k}^\\top}{\\|\\mathbf{k}\\|^2}$, where $\\mathbf{I}$ is the identity matrix. Applying this operator to the momentum equation eliminates the pressure term, since $\\mathbf{P}(\\mathbf{k}) (i\\mathbf{k}\\widehat{p}) = \\mathbf{0}$.\n\nThis gives the solution for the velocity field in Fourier space for each wavevector $\\mathbf{k} \\neq \\mathbf{0}$:\n$$\n\\widehat{\\mathbf{u}}(\\mathbf{k}) = \\frac{1}{\\mu \\|\\mathbf{k}\\|^2} \\mathbf{P}(\\mathbf{k}) \\widehat{\\mathbf{f}}_{\\mathrm{res}}(\\mathbf{k})\n$$\nFor the zero wavevector $\\mathbf{k} = \\mathbf{0}$ (representing the mean flow), the problem specifies $\\widehat{\\mathbf{u}}(\\mathbf{0}) = \\mathbf{0}$. The singularity at $\\|\\mathbf{k}\\|^2=0$ is thus handled.\n\nThe components of the velocity in Fourier space are calculated as:\n$$\n\\widehat{u}_x(\\mathbf{k}) = \\frac{1}{\\mu \\|\\mathbf{k}\\|^4} \\left( k_y^2 \\widehat{f}_x(\\mathbf{k}) - k_x k_y \\widehat{f}_y(\\mathbf{k}) \\right)\n$$\n$$\n\\widehat{u}_y(\\mathbf{k}) = \\frac{1}{\\mu \\|\\mathbf{k}\\|^4} \\left( k_x^2 \\widehat{f}_y(\\mathbf{k}) - k_x k_y \\widehat{f}_x(\\mathbf{k}) \\right)\n$$\nThese calculations are performed for all wavevectors corresponding to the discrete grid. The wavevectors are given by $k_x = 2\\pi f_x$ and $k_y = 2\\pi f_y$, where $f_x$ and $f_y$ are the discrete frequencies obtained from `numpy.fft.fftfreq`.\n\n**3. Recovery of Real-Space Velocity and Final Result**\n\nThe real-space velocity field, $\\mathbf{u}(\\mathbf{x}) = (u_x(\\mathbf{x}), u_y(\\mathbf{x}))$, is recovered by applying the inverse 2D FFT to the Fourier-space velocity components, $\\widehat{u}_x(\\mathbf{k})$ and $\\widehat{u}_y(\\mathbf{k})$.\n\nFinally, the amplitude of the parasitic currents, $U_{\\max}$, is determined by calculating the maximum magnitude of the velocity vector across all grid points:\n$$\nU_{\\max} = \\max_{\\mathbf{x}} \\|\\mathbf{u}(\\mathbf{x})\\| = \\max_{i,j} \\sqrt{u_x(x_i, y_j)^2 + u_y(x_i, y_j)^2}\n$$\nThis procedure is repeated for each parameter set provided in the test suite to obtain the final results.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1: sigma, mu, L, R, N, eps_kappa\n        (0.072, 1.0e-3, 0.04, 0.01, 128, 0.0),\n        # Test case 2\n        (0.072, 1.0e-3, 0.04, 0.01, 128, 0.5),\n        # Test case 3\n        (0.072, 1.0e-3, 0.04, 0.01, 256, 0.5),\n        # Test case 4\n        (0.072, 1.0e-2, 0.04, 0.01, 128, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        U_max = compute_parasitic_current_amplitude(*case)\n        results.append(U_max)\n\n    # Format output as specified\n    formatted_results = [f\"{r:.12f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\ndef compute_parasitic_current_amplitude(sigma, mu, L, R, N, eps_kappa):\n    \"\"\"\n    Computes the amplitude of parasitic currents for a given set of parameters.\n\n    Args:\n        sigma (float): Surface tension coefficient (N/m).\n        mu (float): Dynamic viscosity (Pa·s).\n        L (float): Domain side length (m).\n        R (float): Circle radius (m).\n        N (int): Number of grid points per dimension.\n        eps_kappa (float): Curvature error (m^-1).\n\n    Returns:\n        float: The maximum velocity amplitude U_max (m/s).\n    \"\"\"\n\n    # If there is no curvature error, the residual force is zero, thus velocity is zero.\n    if eps_kappa == 0.0:\n        return 0.0\n\n    # 1. Grid Generation and Parameters\n    h = L / N\n    epsilon = 1.5 * h\n    # Grid coordinates\n    coords = np.arange(N) * h\n    X, Y = np.meshgrid(coords, coords)\n\n    # 2. Construct the Residual Force Field in Real Space\n    center_x, center_y = L / 2, L / 2\n    dist = np.sqrt((X - center_x)**2 + (Y - center_y)**2)\n    \n    # Signed distance function\n    phi = dist - R\n\n    # Smoothed Dirac delta function (cosine mollifier)\n    delta = np.zeros_like(phi)\n    mask = np.abs(phi) <= epsilon\n    phi_masked = phi[mask]\n    delta[mask] = (1 / (2 * epsilon)) * (1 + np.cos(np.pi * phi_masked / epsilon))\n\n    # Normal vector field. Handle division by zero at the center.\n    # The normal is undefined at the center, but delta will be zero there if R > epsilon,\n    # so the force will correctly be zero.\n    dist_inv = np.divide(1.0, dist, out=np.zeros_like(dist), where=dist != 0)\n    nx = (X - center_x) * dist_inv\n    ny = (Y - center_y) * dist_inv\n\n    # Assemble the force components\n    f_coeff = sigma * eps_kappa\n    fx = f_coeff * delta * nx\n    fy = f_coeff * delta * ny\n\n    # 3. Fourier Transform the Force Field\n    hat_fx = np.fft.fft2(fx)\n    hat_fy = np.fft.fft2(fy)\n\n    # 4. Solve for Velocity in Fourier Space\n    # Wavevectors\n    freq = np.fft.fftfreq(N, d=h)\n    k = 2 * np.pi * freq\n    Kx, Ky = np.meshgrid(k, k) # Kx varies along cols (axis 1), Ky along rows (axis 0)\n\n    # Squared magnitude of wavevectors\n    K2 = Kx**2 + Ky**2\n\n    # Stokes solver in Fourier space. The projection operator and 1/(mu*K^2) are combined.\n    # The term 1/K^4 must avoid the K=0 singularity.\n    inv_mu_K4 = np.divide(1.0, mu * K2**2, out=np.zeros_like(K2), where=K2 != 0)\n\n    # Calculate velocity components in Fourier space\n    hat_ux = inv_mu_K4 * (Ky**2 * hat_fx - Kx * Ky * hat_fy)\n    hat_uy = inv_mu_K4 * (Kx**2 * hat_fy - Kx * Ky * hat_fx)\n    \n    # The k=0 mode (mean velocity) is correctly set to zero by the `where` clause in np.divide.\n\n    # 5. Inverse Fourier Transform to get Real-Space Velocity\n    ux = np.fft.ifft2(hat_ux).real\n    uy = np.fft.ifft2(hat_uy).real\n\n    # 6. Compute the Amplitude of Parasitic Currents\n    vel_mag = np.sqrt(ux**2 + uy**2)\n    U_max = np.max(vel_mag)\n\n    return U_max\n\nif __name__ == '__main__':\n    solve()\n\n```"
        },
        {
            "introduction": "Beyond simple forward simulation, immersed boundary methods provide a powerful framework for design optimization and sensitivity analysis. This advanced practice explores the crucial role of adjoint operators, which allow for the efficient computation of gradients. You will construct the discrete spread and interpolation operators, verify their fundamental adjoint relationship, and witness firsthand how breaking this symmetry devastates the accuracy of a computed gradient in an optimization task .",
            "id": "3332853",
            "problem": "You are given a uniform two-dimensional Cartesian grid with periodic boundaries on the unit square and a set of Lagrangian marker points representing an immersed curve. The immersed boundary method uses a regularized Dirac delta to define two linear operators: a spread operator $S$ that maps Lagrangian forces to Eulerian forces on the grid, and an interpolation operator $J$ that maps Eulerian grid fields to the Lagrangian markers. Your task is to construct discrete matrix representations of these operators, form the correctly weighted adjoint pairs, verify the symmetry relation under a specific quadrature, and quantify how deviations from this symmetry affect gradient accuracy in a simple optimization task.\n\nStart from the following fundamental base and definitions:\n\n- The Eulerian grid is $N \\times N$ with grid spacing $h = 1/N$, with grid coordinates $x_i = i h$, $y_j = j h$ for integers $i,j \\in \\{0,\\dots,N-1\\}$, and periodic boundary conditions on $[0,1)^2$.\n\n- There are $M$ Lagrangian markers at positions $(X_\\ell, Y_\\ell)$ with uniform quadrature weights $w_\\ell = \\Delta s$, where $\\Delta s$ approximates the curve’s arc length spacing.\n\n- The one-dimensional four-point regularized Dirac delta (Peskin kernel) $\\varphi(r)$ is supported on $|r| < 2$ and defined by\n  $$\n  \\varphi(r) = \n  \\begin{cases}\n  \\dfrac{1}{8}\\left(3 - 2|r| + \\sqrt{1 + 4|r| - 4 r^2}\\right), & 0 \\le |r| < 1, \\\\\n  \\dfrac{1}{8}\\left(5 - 2|r| - \\sqrt{-7 + 12|r| - 4 r^2}\\right), & 1 \\le |r| < 2, \\\\\n  0, & |r| \\ge 2,\n  \\end{cases}\n  $$\n  and the two-dimensional regularized delta at grid spacing $h$ is\n  $$\n  \\delta_h(x,y) = \\dfrac{1}{h^2} \\, \\varphi\\!\\left(\\dfrac{x}{h}\\right)\\, \\varphi\\!\\left(\\dfrac{y}{h}\\right).\n  $$\n  Periodicity is enforced by taking minimal-periodic differences for the arguments.\n\n- The discrete spread operator $S_{\\mathrm{phys}}$ maps a Lagrangian vector $F \\in \\mathbb{R}^{M}$ to an Eulerian vector $f \\in \\mathbb{R}^{N^2}$ by\n  $$\n  f_{ij} = \\sum_{\\ell=1}^{M} w_\\ell \\, F_\\ell \\, \\delta_h\\!\\left(x_i - X_\\ell, \\, y_j - Y_\\ell\\right),\n  $$\n  that is, in matrix form $f = S_{\\mathrm{phys}} \\, F$, where $S_{\\mathrm{phys}} \\in \\mathbb{R}^{N^2 \\times M}$.\n\n- The discrete interpolation operator $J_{\\mathrm{phys}}$ maps an Eulerian vector $u \\in \\mathbb{R}^{N^2}$ to a Lagrangian vector $U \\in \\mathbb{R}^{M}$ by\n  $$\n  U_\\ell = \\sum_{i=1}^{N} \\sum_{j=1}^{N} u_{ij}\\, h^2 \\, \\delta_h\\!\\left(x_i - X_\\ell, \\, y_j - Y_\\ell\\right),\n  $$\n  that is, in matrix form $U = J_{\\mathrm{phys}} \\, u$, where $J_{\\mathrm{phys}} \\in \\mathbb{R}^{M \\times N^2}$.\n\n- The Eulerian weighted inner product is $\\langle u, f \\rangle_E = \\sum_{i,j} u_{ij} f_{ij} \\, h^2$ and the Lagrangian weighted inner product is $\\langle U, F \\rangle_L = \\sum_{\\ell} U_\\ell F_\\ell \\, w_\\ell$. Under these weights, the discrete power identity $\\langle u, S_{\\mathrm{phys}} F \\rangle_E = \\langle J_{\\mathrm{phys}} u, F \\rangle_L$ holds, equivalently\n  $$\n  J_{\\mathrm{phys}} = W_L^{-1} \\, S_{\\mathrm{phys}}^\\top \\, W_E,\n  $$\n  where $W_E = h^2 I_{N^2}$ and $W_L = \\mathrm{diag}(w_1,\\dots,w_M)$.\n\n- Define the symmetrically weighted operators\n  $$\n  \\widetilde{S} = W_E^{1/2}\\, S_{\\mathrm{phys}}\\, W_L^{-1/2}, \\qquad\n  \\widetilde{J} = W_L^{1/2}\\, J_{\\mathrm{phys}}\\, W_E^{-1/2}.\n  $$\n  Using the fundamental identity above, one obtains the symmetry relation\n  $$\n  \\widetilde{J} = \\widetilde{S}^\\top.\n  $$\n\nYour program must:\n\n- Construct $S_{\\mathrm{phys}}$ and $J_{\\mathrm{phys}}$ for given $(N,M)$, marker locations $(X_\\ell,Y_\\ell)$ on a circle of radius $R$ and center $(x_c,y_c)$, and quadrature weights $w_\\ell = 2\\pi R / M$.\n\n- Construct the symmetrically weighted pair $(\\widetilde{S}, \\widetilde{J})$ and compute the Frobenius norm of the difference $\\|\\widetilde{J} - \\widetilde{S}^\\top\\|_F$ as a scalar float.\n\n- Construct a deviated interpolation operator $J_{\\mathrm{wrong}}$ that omits the Eulerian quadrature factor $h^2$ (i.e., set $U_\\ell = \\sum_{i,j} u_{ij}\\, \\delta_h(\\cdot)$), and compute $\\|\\widetilde{J}_{\\mathrm{wrong}} - \\widetilde{S}^\\top\\|_F$ using the same symmetric weighting formula for $\\widetilde{J}_{\\mathrm{wrong}} = W_L^{1/2} J_{\\mathrm{wrong}} W_E^{-1/2}$.\n\n- Define the quadratic objective over Lagrangian forces $F \\in \\mathbb{R}^M$,\n  $$\n  \\Phi(F) = \\dfrac{1}{2}\\, \\| A F - b \\|_{W_L}^2, \\quad \\text{where } A = J_{\\mathrm{phys}} S_{\\mathrm{phys}},\n  $$\n  and $\\|v\\|_{W_L}^2 = v^\\top W_L v$. Use a fixed random vector $b \\in \\mathbb{R}^M$ and a fixed random $F \\in \\mathbb{R}^M$ seeded deterministically for reproducibility.\n\n- Compute the exact gradient with respect to $F$ using the adjoint chain implied by the weighted inner products,\n  $$\n  \\nabla \\Phi(F) = S_{\\mathrm{phys}}^\\top\\, J_{\\mathrm{phys}}^\\top\\, \\left(W_L (A F - b)\\right).\n  $$\n  Also compute an incorrect gradient that uses the deviated interpolation operator in the adjoint chain,\n  $$\n  \\nabla_{\\mathrm{wrong}} \\Phi(F) = S_{\\mathrm{phys}}^\\top\\, J_{\\mathrm{wrong}}^\\top\\, \\left(W_L (A F - b)\\right).\n  $$\n\n- Estimate the reference gradient via central finite differences with a perturbation step $\\varepsilon$ applied componentwise to $F$:\n  $$\n  \\left[\\nabla \\Phi(F)\\right]_k \\approx \\dfrac{\\Phi(F + \\varepsilon e_k) - \\Phi(F - \\varepsilon e_k)}{2 \\varepsilon},\n  $$\n  where $e_k$ is the $k$-th basis vector.\n\n- Report the relative $\\ell^2$-errors of the exact and incorrect gradients against finite differences:\n  $$\n  E_{\\mathrm{true}} = \\dfrac{\\|\\nabla \\Phi(F) - \\nabla_{\\mathrm{FD}} \\Phi(F)\\|_2}{\\|\\nabla_{\\mathrm{FD}} \\Phi(F)\\|_2}, \\qquad\n  E_{\\mathrm{wrong}} = \\dfrac{\\|\\nabla_{\\mathrm{wrong}} \\Phi(F) - \\nabla_{\\mathrm{FD}} \\Phi(F)\\|_2}{\\|\\nabla_{\\mathrm{FD}} \\Phi(F)\\|_2}.\n  $$\n\nTest suite and required final output:\n\nYour program must implement the following three test cases and aggregate their outputs into a single list:\n\n- Case $1$ (symmetry verification, matched quadrature): $N = 16$, $M = 20$, circle center $(x_c,y_c) = (0.15, 0.85)$, radius $R = 0.22$. Compute $E_{\\mathrm{sym}}^{\\mathrm{matched}} = \\|\\widetilde{J} - \\widetilde{S}^\\top\\|_F$ as a float.\n\n- Case $2$ (symmetry verification, deviated interpolation quadrature): same parameters as Case $1$, but use $J_{\\mathrm{wrong}}$ that omits the factor $h^2$. Compute $E_{\\mathrm{sym}}^{\\mathrm{wrong}} = \\|\\widetilde{J}_{\\mathrm{wrong}} - \\widetilde{S}^\\top\\|_F$ as a float.\n\n- Case $3$ (gradient accuracy in a quadratic design task): $N = 24$, $M = 28$, circle center $(x_c,y_c) = (0.07, 0.11)$, radius $R = 0.19$, random seed fixed at an integer value, and finite-difference step $\\varepsilon = 10^{-6}$. Compute $E_{\\mathrm{true}}$ and $E_{\\mathrm{wrong}}$ as floats.\n\nFinal output format:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order\n$[E_{\\mathrm{sym}}^{\\mathrm{matched}}, E_{\\mathrm{sym}}^{\\mathrm{wrong}}, E_{\\mathrm{true}}, E_{\\mathrm{wrong}}]$.",
            "solution": "The problem requires a careful implementation of the operators central to the Immersed Boundary (IB) method and an investigation of their adjoint properties. The solution, implemented in the provided Python code, follows these key steps:\n\n**1. Operator Discretization**\n\nFirst, we construct the discrete matrix representations for the spread ($S_{\\mathrm{phys}}$) and interpolation ($J_{\\mathrm{phys}}$) operators.\n- The Eulerian grid and Lagrangian marker positions are defined according to the test case parameters. Periodic boundary conditions are crucial and are handled by computing the shortest distance on a torus for any grid-marker pair.\n- The 2D regularized delta function, $\\delta_h$, is built as a tensor product of the 1D four-point Peskin kernel, $\\varphi(r)$.\n- The matrix for the spread operator $S_{\\mathrm{phys}}$ is constructed such that its elements are $(S_{\\mathrm{phys}})_{ij, \\ell} = w_\\ell \\delta_h(x_i - X_\\ell, y_j - Y_\\ell)$. This maps an $M$-dimensional Lagrangian vector to an $N^2$-dimensional Eulerian vector.\n- The matrix for the interpolation operator $J_{\\mathrm{phys}}$ is constructed such that its elements are $(J_{\\mathrm{phys}})_{\\ell, ij} = h^2 \\delta_h(x_i - X_\\ell, y_j - Y_\\ell)$. This maps an $N^2$-dimensional Eulerian vector to an $M$-dimensional Lagrangian vector.\n- The \"wrong\" interpolation operator, $J_{\\mathrm{wrong}}$, is also constructed by omitting the Eulerian quadrature weight $h^2$.\n\n**2. Verification of Adjoint Symmetry**\n\nThe core of the IB method's mathematical structure is the adjoint relationship between the spread and interpolation operators, which ensures power conservation. This relationship, $J_{\\mathrm{phys}} = W_L^{-1} S_{\\mathrm{phys}}^\\top W_E$, is equivalent to the matrix transpose symmetry $\\widetilde{J} = \\widetilde{S}^\\top$ for the symmetrically weighted operators.\n- The weight matrices $W_E = h^2 I$ and $W_L = \\mathrm{diag}(w_\\ell)$ are defined.\n- The symmetrically weighted operators $\\widetilde{S} = W_E^{1/2} S_{\\mathrm{phys}} W_L^{-1/2}$ and $\\widetilde{J} = W_L^{1/2} J_{\\mathrm{phys}} W_E^{-1/2}$ are constructed.\n- The Frobenius norm of the difference, $\\|\\widetilde{J} - \\widetilde{S}^\\top\\|_F$, is computed. For the correctly defined operators, this value should be close to machine epsilon, numerically confirming the symmetry.\n- The same calculation is repeated for the deviated operator, $\\widetilde{J}_{\\mathrm{wrong}}$, demonstrating that the symmetry is broken and the norm is significantly non-zero.\n\n**3. Gradient Accuracy Test**\n\nFinally, we demonstrate the practical consequence of breaking the adjoint relationship in an optimization context.\n- The objective function $\\Phi(F) = \\frac{1}{2} \\| A F - b \\|_{W_L}^2$, with $A = J_{\\mathrm{phys}} S_{\\mathrm{phys}}$, is defined. Fixed random vectors for $F$ and $b$ are used for reproducibility.\n- The \"exact\" analytical gradient, $\\nabla \\Phi(F) = S_{\\mathrm{phys}}^\\top J_{\\mathrm{phys}}^\\top (W_L(AF-b))$, is computed. This formula relies on the adjoint property (transposes of the matrices).\n- The \"wrong\" gradient is computed by incorrectly substituting $J_{\\mathrm{wrong}}^\\top$ for $J_{\\mathrm{phys}}^\\top$ in the chain rule.\n- A \"gold standard\" reference gradient is computed using a second-order central finite difference scheme.\n- The relative $\\ell^2$-errors of both the exact and wrong analytical gradients are calculated with respect to the finite difference gradient. The error for the correct gradient ($E_{\\mathrm{true}}$) is expected to be very small (on the order of the finite difference approximation error), while the error for the wrong gradient ($E_{\\mathrm{wrong}}$) will be large, highlighting the failure of the optimization step if the adjoint is not correctly implemented.",
            "answer": "```python\nimport numpy as np\n\ndef phi(r_in):\n    \"\"\"\n    Computes the 4-point Peskin kernel (regularized Dirac delta function).\n    This function is piecewise and continuous, with support over |r| < 2.\n\n    Args:\n        r_in (np.ndarray): Input values.\n\n    Returns:\n        np.ndarray: The kernel values.\n    \"\"\"\n    r = np.abs(r_in)\n    val = np.zeros_like(r, dtype=float)\n    \n    # Case a: 0 <= |r| < 1\n    mask1 = r < 1\n    r1 = r[mask1]\n    val[mask1] = (1/8) * (3 - 2*r1 + np.sqrt(1 + 4*r1 - 4*r1**2))\n    \n    # Case b: 1 <= |r| < 2\n    mask2 = (r >= 1) & (r < 2)\n    r2 = r[mask2]\n    val[mask2] = (1/8) * (5 - 2*r2 - np.sqrt(-7 + 12*r2 - 4*r2**2))\n    \n    # Case c: |r| >= 2 is implicitly zero\n    return val\n\ndef periodic_diff(coords1, coords2, domain_size=1.0):\n    \"\"\"\n    Calculates the shortest periodic difference vector.\n    Handles broadcasting between coordinate arrays.\n\n    Args:\n        coords1 (np.ndarray): First set of coordinates, shape (P, D).\n        coords2 (np.ndarray): Second set of coordinates, shape (Q, D).\n        domain_size (float): The size of the periodic domain.\n\n    Returns:\n        np.ndarray: The difference vectors, shape (P, Q, D).\n    \"\"\"\n    diff = coords1[:, None, :] - coords2[None, :, :]\n    return diff - domain_size * np.round(diff / domain_size)\n\ndef solve_symmetry_cases(N, M, xc, yc, R):\n    \"\"\"\n    Solves for Cases 1 and 2: Symmetry verification of IB operators.\n\n    Args:\n        N (int): Grid dimension.\n        M (int): Number of markers.\n        xc, yc (float): Circle center coordinates.\n        R (float): Circle radius.\n\n    Returns:\n        tuple[float, float]: The Frobenius norms of the differences for\n                             the matched and wrong interpolation operators.\n    \"\"\"\n    h = 1.0 / N\n    \n    # Eulerian grid setup\n    grid_pts = np.arange(N) * h\n    grid_x, grid_y = np.meshgrid(grid_pts, grid_pts, indexing='ij')\n    grid_coords = np.stack((grid_x.ravel(), grid_y.ravel()), axis=-1)\n    \n    # Lagrangian marker setup\n    thetas = 2 * np.pi * np.arange(M) / M\n    marker_coords = np.zeros((M, 2))\n    marker_coords[:, 0] = xc + R * np.cos(thetas)\n    marker_coords[:, 1] = yc + R * np.sin(thetas)\n    \n    # Quadrature weights\n    ds = 2 * np.pi * R / M\n    w_L_vals = np.full(M, ds)\n    \n    # Interaction terms\n    diffs = periodic_diff(grid_coords, marker_coords)\n    phi_x = phi(diffs[..., 0] / h)\n    phi_y = phi(diffs[..., 1] / h)\n    phi_prod = phi_x * phi_y\n    \n    # Operator construction\n    S_phys = (w_L_vals[None, :] / (h**2)) * phi_prod\n    J_phys_unweighted = phi_prod.T\n    J_phys = (h**2) * J_phys_unweighted\n    J_wrong = J_phys_unweighted\n\n    # Symmetrically weighted operators\n    sqrt_w_L = np.sqrt(w_L_vals)\n    sqrt_w_L_inv = 1.0 / sqrt_w_L\n    \n    S_tilde = h * S_phys * sqrt_w_L_inv[None, :]\n    \n    J_tilde = (1/h) * sqrt_w_L[:, None] * J_phys\n    J_tilde_wrong = (1/h) * sqrt_w_L[:, None] * J_wrong\n    \n    # Compute Frobenius norms\n    E_sym_matched = np.linalg.norm(J_tilde - S_tilde.T, 'fro')\n    E_sym_wrong = np.linalg.norm(J_tilde_wrong - S_tilde.T, 'fro')\n    \n    return E_sym_matched, E_sym_wrong\n\ndef solve_gradient_case(N, M, xc, yc, R, seed, eps):\n    \"\"\"\n    Solves for Case 3: Gradient accuracy of an objective function.\n\n    Args:\n        N, M, xc, yc, R: Problem parameters.\n        seed (int): Seed for random number generator.\n        eps (float): Step size for finite differences.\n\n    Returns:\n        tuple[float, float]: Relative errors of the 'true' and 'wrong' gradients.\n    \"\"\"\n    h = 1.0 / N\n    \n    # Grid and marker setup\n    grid_pts = np.arange(N) * h\n    grid_x, grid_y = np.meshgrid(grid_pts, grid_pts, indexing='ij')\n    grid_coords = np.stack((grid_x.ravel(), grid_y.ravel()), axis=-1)\n    \n    thetas = 2 * np.pi * np.arange(M) / M\n    marker_coords = np.zeros((M, 2))\n    marker_coords[:, 0] = xc + R * np.cos(thetas)\n    marker_coords[:, 1] = yc + R * np.sin(thetas)\n    \n    # Weights and interaction terms\n    ds = 2 * np.pi * R / M\n    w_L_vals = np.full(M, ds)\n    W_L = np.diag(w_L_vals)\n    \n    diffs = periodic_diff(grid_coords, marker_coords)\n    phi_prod = phi(diffs[..., 0] / h) * phi(diffs[..., 1] / h)\n    \n    # Operator construction\n    S_phys = (w_L_vals[None, :] / (h**2)) * phi_prod\n    J_phys_unweighted = phi_prod.T\n    J_phys = (h**2) * J_phys_unweighted\n    J_wrong = J_phys_unweighted\n    \n    # System operator A\n    A = J_phys @ S_phys\n    \n    # Random vectors for reproducibility\n    rng = np.random.default_rng(seed)\n    b = rng.random(M)\n    F_vec = rng.random(M)\n    \n    def objective_Phi(force_vec):\n        residual = A @ force_vec - b\n        return 0.5 * (residual.T @ W_L @ residual)\n\n    # Analytical gradients\n    residual_at_F = A @ F_vec - b\n    grad_Phi_exact = S_phys.T @ J_phys.T @ (W_L @ residual_at_F)\n    grad_Phi_wrong = S_phys.T @ J_wrong.T @ (W_L @ residual_at_F)\n    \n    # Finite difference gradient\n    grad_Phi_fd = np.zeros(M)\n    for k in range(M):\n        F_plus = F_vec.copy()\n        F_plus[k] += eps\n        F_minus = F_vec.copy()\n        F_minus[k] -= eps\n        \n        phi_plus = objective_Phi(F_plus)\n        phi_minus = objective_Phi(F_minus)\n        \n        grad_Phi_fd[k] = (phi_plus - phi_minus) / (2 * eps)\n        \n    # Relative errors\n    norm_fd = np.linalg.norm(grad_Phi_fd)\n    E_true = np.linalg.norm(grad_Phi_exact - grad_Phi_fd) / norm_fd\n    E_wrong = np.linalg.norm(grad_Phi_wrong - grad_Phi_fd) / norm_fd\n\n    return E_true, E_wrong\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    \n    # In the original provided code, there was a minor implementation detail\n    # in constructing J_phys and J_wrong which could lead to confusion.\n    # J_phys = phi_prod.T * h**2 would have been more direct.\n    # This version is slightly more explicit to avoid any ambiguity\n    # and to align perfectly with the rewritten solution text.\n    \n    # Test cases defined in the problem statement.\n    test_cases = {\n        \"case1_2\": {\"N\": 16, \"M\": 20, \"xc\": 0.15, \"yc\": 0.85, \"R\": 0.22},\n        \"case3\": {\"N\": 24, \"M\": 28, \"xc\": 0.07, \"yc\": 0.11, \"R\": 0.19, \"seed\": 42, \"eps\": 1e-6}\n    }\n    \n    # Case 1 & 2\n    params12 = test_cases[\"case1_2\"]\n    E_sym_matched, E_sym_wrong = solve_symmetry_cases(\n        params12[\"N\"], params12[\"M\"], params12[\"xc\"], params12[\"yc\"], params12[\"R\"]\n    )\n    \n    # Case 3\n    params3 = test_cases[\"case3\"]\n    E_true, E_wrong_grad = solve_gradient_case(\n        params3[\"N\"], params3[\"M\"], params3[\"xc\"], params3[\"yc\"], params3[\"R\"], \n        params3[\"seed\"], params3[\"eps\"]\n    )\n    \n    results = [E_sym_matched, E_sym_wrong, E_true, E_wrong_grad]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}