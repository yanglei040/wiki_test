{
    "hands_on_practices": [
        {
            "introduction": "The concept of r-adaptation, or moving mesh methods, is built upon the elegant principle of equidistribution. This principle aims to redistribute mesh nodes such that the error is uniform across all elements. This exercise provides a foundational, hands-on derivation of a mesh transformation by applying the equidistribution principle to a monitor function based on the solution's curvature, allowing you to see exactly how a computational grid is stretched and clustered to adapt to solution features. ",
            "id": "3344448",
            "problem": "Consider a one-dimensional mesh adaptation problem arising in computational fluid dynamics (CFD) for a scalar field governed by partial differential equations (PDEs) on a fixed domain. Let the physical coordinate be $x \\in [0,1]$ and the computational coordinate be $\\xi \\in [0,1]$. Suppose the mesh is adapted by equidistributing a monitor function motivated by interpolation error, specifically $m(x) = |u''(x)|^{1/3}$, where $u(x)$ is a sufficiently smooth scalar solution. Starting from the equidistribution principle that defines an $x(\\xi)$ mapping by equalizing the cumulative monitor measure across computational cells, derive the closed-form expression for the mapping $x(\\xi)$ for the specific choice $u(x) = \\exp(3x)$ on $[0,1]$. Then, using this mapping, compute the resulting node locations $x_i$ on $[0,1]$ for a uniform computational mesh with $N=6$ (i.e., $\\xi_i = i/6$ for $i=0,1,\\dots,6$). Provide both the closed-form mapping $x(\\xi)$ and the exact analytic expressions for the seven node locations $x_i$. Express your answers as exact analytic expressions; do not round.",
            "solution": "The problem requires the derivation of a one-dimensional mesh coordinate transformation $x(\\xi)$ and the corresponding node locations for a specific scalar field and monitor function. The foundation for this derivation is the equidistribution principle.\n\nThe equidistribution principle states that the product of the monitor function $m(x)$ and the infinitesimal physical cell size $dx$ is held constant across the computational domain. In continuous form, this can be expressed as an integral relation between the physical coordinate $x$ and the computational coordinate $\\xi$. For a domain normalized to $[0,1]$ for both $x$ and $\\xi$, the principle is given by the equation:\n$$\n\\int_0^{x(\\xi)} m(s) \\, ds = \\xi \\int_0^1 m(s) \\, ds\n$$\nThis equation ensures that the cumulative measure of the monitor function up to a physical point $x$ is proportional to the corresponding computational coordinate $\\xi$. The constant of proportionality is the total measure of the monitor function over the entire domain $[0,1]$.\n\nThe problem provides the scalar field $u(x)$ and the definition of the monitor function $m(x)$.\nFirst, we are given $u(x) = \\exp(3x)$. We need to compute its second derivative, $u''(x)$.\nThe first derivative is:\n$$\nu'(x) = \\frac{d}{dx}(\\exp(3x)) = 3\\exp(3x)\n$$\nThe second derivative is:\n$$\nu''(x) = \\frac{d}{dx}(3\\exp(3x)) = 9\\exp(3x)\n$$\nThe monitor function is defined as $m(x) = |u''(x)|^{1/3}$. Substituting the expression for $u''(x)$:\n$$\nm(x) = |9\\exp(3x)|^{1/3}\n$$\nSince $x \\in [0,1]$, $\\exp(3x)$ is strictly positive, so the absolute value is redundant.\n$$\nm(x) = (9\\exp(3x))^{1/3} = 9^{1/3} (\\exp(3x))^{1/3} = (3^2)^{1/3} \\exp\\left(3x \\cdot \\frac{1}{3}\\right) = 3^{2/3}\\exp(x)\n$$\nNext, we evaluate the two integrals in the equidistribution principle equation. The left-hand side (LHS) integral is:\n$$\n\\int_0^x m(s) \\, ds = \\int_0^x 3^{2/3}\\exp(s) \\, ds = 3^{2/3} \\left[\\exp(s)\\right]_0^x = 3^{2/3}(\\exp(x) - \\exp(0)) = 3^{2/3}(\\exp(x) - 1)\n$$\nThe integral on the right-hand side (RHS), representing the total measure of the monitor function, is:\n$$\n\\int_0^1 m(s) \\, ds = \\int_0^1 3^{2/3}\\exp(s) \\, ds = 3^{2/3} \\left[\\exp(s)\\right]_0^1 = 3^{2/3}(\\exp(1) - \\exp(0)) = 3^{2/3}(e - 1)\n$$\nNow, we substitute these integral results back into the equidistribution principle equation:\n$$\n3^{2/3}(\\exp(x) - 1) = \\xi \\left[3^{2/3}(e - 1)\\right]\n$$\nThe constant factor $3^{2/3}$ cancels from both sides, simplifying the equation to:\n$$\n\\exp(x) - 1 = \\xi(e - 1)\n$$\nTo find the closed-form expression for the mapping $x(\\xi)$, we solve for $x$:\n$$\n\\exp(x) = 1 + \\xi(e - 1)\n$$\nTaking the natural logarithm of both sides yields the mapping function:\n$$\nx(\\xi) = \\ln(1 + (e - 1)\\xi)\n$$\nThis is the first required result.\n\nThe second part of the problem asks for the physical node locations $x_i$ corresponding to a uniform computational mesh with $N=6$ cells. This implies $N+1=7$ nodes, with coordinates $\\xi_i = i/N = i/6$ for $i = 0, 1, 2, 3, 4, 5, 6$. We substitute each $\\xi_i$ into the derived mapping $x(\\xi)$.\n\nFor $i=0$:\n$$x_0 = \\ln\\left(1 + (e-1)\\frac{0}{6}\\right) = \\ln(1) = 0$$\nFor $i=1$:\n$$x_1 = \\ln\\left(1 + (e-1)\\frac{1}{6}\\right) = \\ln\\left(\\frac{6 + e - 1}{6}\\right) = \\ln\\left(\\frac{e+5}{6}\\right)$$\nFor $i=2$:\n$$x_2 = \\ln\\left(1 + (e-1)\\frac{2}{6}\\right) = \\ln\\left(1 + \\frac{e-1}{3}\\right) = \\ln\\left(\\frac{3 + e - 1}{3}\\right) = \\ln\\left(\\frac{e+2}{3}\\right)$$\nFor $i=3$:\n$$x_3 = \\ln\\left(1 + (e-1)\\frac{3}{6}\\right) = \\ln\\left(1 + \\frac{e-1}{2}\\right) = \\ln\\left(\\frac{2 + e - 1}{2}\\right) = \\ln\\left(\\frac{e+1}{2}\\right)$$\nFor $i=4$:\n$$x_4 = \\ln\\left(1 + (e-1)\\frac{4}{6}\\right) = \\ln\\left(1 + \\frac{2(e-1)}{3}\\right) = \\ln\\left(\\frac{3 + 2e - 2}{3}\\right) = \\ln\\left(\\frac{2e+1}{3}\\right)$$\nFor $i=5$:\n$$x_5 = \\ln\\left(1 + (e-1)\\frac{5}{6}\\right) = \\ln\\left(\\frac{6 + 5e - 5}{6}\\right) = \\ln\\left(\\frac{5e+1}{6}\\right)$$\nFor $i=6$:\n$$x_6 = \\ln\\left(1 + (e-1)\\frac{6}{6}\\right) = \\ln(1 + e - 1) = \\ln(e) = 1$$\n\nThe boundary nodes $x_0=0$ and $x_6=1$ correctly map to the domain boundaries, as expected. The derived mapping and the resulting node locations are the required solution.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\ln(1 + (e-1)\\xi) & 0 & \\ln\\left(\\frac{e+5}{6}\\right) & \\ln\\left(\\frac{e+2}{3}\\right) & \\ln\\left(\\frac{e+1}{2}\\right) & \\ln\\left(\\frac{2e+1}{3}\\right) & \\ln\\left(\\frac{5e+1}{6}\\right) & 1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "To effectively resolve anisotropic features like boundary layers and shear layers, isotropic meshes are inefficient. Metric-based anisotropic adaptation directs the meshing process to create elements that are stretched and aligned with the solution's behavior. This practice delves into the theoretical heart of this strategy by asking you to derive, from first principles, how the local curvature of a function, represented by its Hessian matrix, dictates the optimal shape and orientation of a mesh element to minimize interpolation error. ",
            "id": "3344473",
            "problem": "Consider a smooth scalar field $u(\\boldsymbol{x})$ defined on $\\mathbb{R}^{2}$ with a locally constant symmetric positive definite Hessian $H \\in \\mathbb{R}^{2 \\times 2}$ at a point of interest, with ordered eigenpairs $\\{(\\lambda_{1},\\boldsymbol{v}_{1}),(\\lambda_{2},\\boldsymbol{v}_{2})\\}$ and $\\lambda_{1} \\ge \\lambda_{2} > 0$. In a mesh adaptation context for computational fluid dynamics, we approximate $u$ locally using bilinear finite element interpolation on a single rectangular element of fixed area $A_{e}$ whose sides have lengths $a$ and $b$ and can be arbitrarily oriented.\n\nUsing only fundamental facts and definitions:\n- Taylor’s theorem to second order for $u$ in a local orthonormal coordinate system aligned with $\\{\\boldsymbol{v}_{1},\\boldsymbol{v}_{2}\\}$,\n- The definition of nodal bilinear interpolation on a rectangle,\n- The constraint that the element area satisfies $ab = A_{e}$,\n\nderive from first principles the element orientation and aspect ratio that minimize the maximum pointwise interpolation error over the element. Then, among all isotropic elements (rectangles with $a=b$) of the same area $A_{e}$, determine the maximum pointwise interpolation error and compare it with the optimal anisotropic error you derived.\n\nReport as your final answer the ratio of the isotropic error to the optimal anisotropic error, expressed solely in terms of $\\lambda_{1}$ and $\\lambda_{2}$. Do not round; give an exact analytic expression. No units are required.",
            "solution": "Let the point of interest be the origin $\\boldsymbol{x}_{0}=\\boldsymbol{0}$. We define a local orthonormal coordinate system $(\\xi_1, \\xi_2)$ with axes aligned with the eigenvectors $\\boldsymbol{v}_{1}$ and $\\boldsymbol{v}_{2}$ of the Hessian $H$. In this system, Taylor's theorem states that the scalar field $u$ can be expanded around the origin. Since bilinear interpolation is exact for linear functions, the interpolation error is governed by the quadratic part of the function. After shifting the function so $u(\\boldsymbol{0})=0$ and assuming we are at a critical point where $\\nabla u(\\boldsymbol{0})=\\boldsymbol{0}$, the function governing the leading-order error is:\n$$u_{quad}(\\xi_1, \\xi_2) = \\frac{1}{2}(\\lambda_1 \\xi_1^2 + \\lambda_2 \\xi_2^2)$$\n\nTo minimize interpolation error, we align a rectangular element of sides $a$ and $b$ with the $\\xi_1$ and $\\xi_2$ axes. The vertices are at $(\\pm a/2, \\pm b/2)$. The bilinear interpolant $\\Pi u_{quad}$ over this rectangle is a constant equal to the nodal value at the corners: $\\Pi u_{quad} = \\frac{1}{8}(\\lambda_1 a^2 + \\lambda_2 b^2)$. The pointwise interpolation error $E(\\xi_1, \\xi_2) = u_{quad}(\\xi_1, \\xi_2) - \\Pi u_{quad}(\\xi_1, \\xi_2)$ is maximized in magnitude at the center of the element $(\\xi_1, \\xi_2) = (0,0)$. The maximum pointwise error is:\n$$E_{max\\_err} = |E(0,0)| = \\frac{1}{8}(\\lambda_1 a^2 + \\lambda_2 b^2)$$\n\nWe must minimize this error subject to the constraint of fixed area $ab = A_e$, or $b=A_e/a$. Substituting this into the error expression gives:\n$$E_{max\\_err}(a) = \\frac{1}{8}\\left(\\lambda_1 a^2 + \\lambda_2 \\frac{A_e^2}{a^2}\\right)$$\nTo find the minimum, we set the derivative with respect to $a$ to zero, which yields $\\lambda_1 a^4 = \\lambda_2 A_e^2$. This gives the optimal squared side lengths:\n$$a_{opt}^2 = A_e \\sqrt{\\frac{\\lambda_2}{\\lambda_1}} \\quad \\text{and} \\quad b_{opt}^2 = A_e\\sqrt{\\frac{\\lambda_1}{\\lambda_2}}$$\nThe optimal element is therefore aligned with the principal directions of curvature, and its aspect ratio is $a_{opt}/b_{opt} = \\sqrt{\\lambda_2/\\lambda_1}$. Substituting these optimal lengths back into the error expression gives the minimal, or optimal, anisotropic error:\n$$E_{opt} = \\frac{1}{8}\\left(\\lambda_1 \\left(A_e \\sqrt{\\frac{\\lambda_2}{\\lambda_1}}\\right) + \\lambda_2 \\left(A_e \\sqrt{\\frac{\\lambda_1}{\\lambda_2}}\\right)\\right) = \\frac{A_e}{4}\\sqrt{\\lambda_1\\lambda_2}$$\n\nFor an isotropic element (a square), we have $a=b$. The area constraint gives $a=b=\\sqrt{A_e}$. The maximum pointwise error for an isotropic element is independent of its orientation and is given by:\n$$E_{iso} = \\frac{1}{8}(\\lambda_1 a^2 + \\lambda_2 b^2) = \\frac{A_e}{8}(\\lambda_1 + \\lambda_2)$$\n\nFinally, the ratio of the isotropic error to the optimal anisotropic error is:\n$$\\text{Ratio} = \\frac{E_{iso}}{E_{opt}} = \\frac{\\frac{A_e}{8}(\\lambda_1 + \\lambda_2)}{\\frac{A_e}{4}\\sqrt{\\lambda_1\\lambda_2}} = \\frac{\\lambda_1 + \\lambda_2}{2\\sqrt{\\lambda_1\\lambda_2}}$$",
            "answer": "$$\\boxed{\\frac{\\lambda_{1} + \\lambda_{2}}{2\\sqrt{\\lambda_{1}\\lambda_{2}}}}$$"
        },
        {
            "introduction": "A single CFD simulation often contains multiple physical phenomena—such as shocks, boundary layers, and vortices—each demanding its own unique mesh refinement. A robust adaptation strategy must be able to synthesize these competing requirements into a single, coherent mesh. This exercise tackles this practical challenge by implementing the method of metric intersection, a rigorous mathematical framework for combining multiple anisotropic metrics, and enforcing essential mesh conformity constraints. ",
            "id": "3344463",
            "problem": "You are implementing an anisotropic mesh adaptation operator in Computational Fluid Dynamics (CFD). In the Riemannian metric framework for anisotropic adaptation, a symmetric positive definite (SPD) metric tensor $M \\in \\mathbb{R}^{d \\times d}$ induces the squared Riemannian length $L^{2}(v;M) = v^{\\top} M v$ for any vector $v \\in \\mathbb{R}^{d}$. When two independent goal functionals are present (for example, one goal for shock resolution and another for boundary layer resolution), their adaptation requirements can be encoded as two SPD metrics $M_{1}$ and $M_{2}$. The combined anisotropic requirement is defined as the unique SPD matrix $M^{\\star}$ such that, for all $v \\in \\mathbb{R}^{d}$,\n$$\nv^{\\top} M^{\\star} v \\;=\\; \\min\\limits_{v_{1} + v_{2} = v} \\left( v_{1}^{\\top} M_{1} v_{1} + v_{2}^{\\top} M_{2} v_{2} \\right),\n$$\nthat is, the effective quadratic form equals the minimum of the sum of the two quadratic forms over all decompositions $v = v_{1} + v_{2}$. This operator is sometimes called the metric intersection of $M_{1}$ and $M_{2}$.\n\nIn addition to combining goals, mesh conformity imposes size-scale constraints on the metric field. In this problem, the conformity constraint is specified as a bound on the determinant of the combined metric $M^{\\star}$:\n$$\n\\det(M_{\\min}) \\;\\le\\; \\det(M^{\\star}) \\;\\le\\; \\det(M_{\\max}).\n$$\nWhen $\\det(M^{\\star})$ violates these bounds, isotropic scaling by a positive scalar $s$ must be used to enforce them; the scaled metric $s M^{\\star}$ must satisfy the determinant bounds. Recall the determinant scaling property for any $d \\times d$ matrix and scalar $s &gt; 0$: $\\det(s M) = s^{d} \\det(M)$.\n\nTasks:\n- Starting only from the above definitions and the properties of SPD matrices and determinants, derive an explicit computational procedure to obtain $M^{\\star}$ and to enforce the determinant bounds by isotropic scaling $s$.\n- Implement a program that, for each test case below, computes the raw combined metric $M^{\\star}$, checks the determinant bounds, applies isotropic scaling $s$ only if needed, and then reports specific numerical outputs.\n\nAngle unit specification:\n- All angles are given in radians.\n\nTest suite:\nFor each test case, you are given the dimension $d$, two SPD matrices $M_{1}, M_{2}$, and determinant bounds $(\\underline{\\Delta}, \\overline{\\Delta})$ to be enforced on $\\det(M^{\\star})$. Use the following test cases:\n\n- Case A (anisotropic, rotated in $d = 2$):\n  - $d = 2$.\n  - $M_{1} = R(\\theta) \\,\\mathrm{diag}(100, 1)\\, R(\\theta)^{\\top}$ with $\\theta = \\pi/6$, where $R(\\theta) = \\begin{bmatrix}\\cos\\theta &amp; -\\sin\\theta\\\\ \\sin\\theta &amp; \\cos\\theta\\end{bmatrix}$.\n  - $M_{2} = \\mathrm{diag}(0.5, 400)$.\n  - Bounds $(\\underline{\\Delta}, \\overline{\\Delta}) = (10^{-3}, 10^{6})$.\n- Case B (lower bound activation in $d = 2$):\n  - $d = 2$.\n  - $M_{1} = \\mathrm{diag}(10^{-3}, 10^{-3})$, $M_{2} = \\mathrm{diag}(10^{-3}, 10^{-3})$.\n  - Bounds $(\\underline{\\Delta}, \\overline{\\Delta}) = (10^{-2}, 10^{2})$.\n- Case C (upper bound activation in $d = 2$):\n  - $d = 2$.\n  - $M_{1} = \\mathrm{diag}(10^{3}, 10^{3})$, $M_{2} = \\mathrm{diag}(10^{3}, 10^{3})$.\n  - Bounds $(\\underline{\\Delta}, \\overline{\\Delta}) = (10^{-3}, 10^{4})$.\n- Case D (boundary equality in $d = 2$):\n  - $d = 2$.\n  - $M_{1} = \\mathrm{diag}(4, 4)$, $M_{2} = \\mathrm{diag}(4, 4)$.\n  - Bounds $(\\underline{\\Delta}, \\overline{\\Delta}) = (4, 4)$.\n- Case E (three-dimensional, mixed anisotropy, $d = 3$):\n  - $d = 3$.\n  - $M_{1} = \\mathrm{diag}(100, 1, 10)$, $M_{2} = \\mathrm{diag}(1, 50, 0.5)$.\n  - Bounds $(\\underline{\\Delta}, \\overline{\\Delta}) = (0.1, 0.5)$.\n\nOutput requirements:\n- For each test case, compute:\n  1. The raw determinant $\\det(M^{\\star})$ before any scaling.\n  2. The clamped determinant after enforcing bounds (by isotropic scaling if needed).\n  3. A boolean indicating whether scaling was applied.\n  4. The final clamped metric matrix entries in row-major order.\n- All floating-point numbers must be rounded to six decimal places.\n- The program must produce a single line of output containing a list of per-case results. Each per-case result is a list in the form\n  $[d, \\det(M^{\\star})_{\\text{rounded}}, \\det(M^{\\star}_{\\text{clamped}})_{\\text{rounded}}, \\text{scaled\\_flag}, [\\text{row-major entries of } M^{\\star}_{\\text{clamped}} \\text{ rounded}]]$.\n- The single line must be a comma-separated list enclosed in square brackets, containing the results for Cases A through E in order, with no spaces anywhere. For example, an output with two hypothetical cases would look like $[[2,1.234000,1.234000,False,[\\dots]],[3,0.456000,0.400000,True,[\\dots]]]$.\n\nYour program must hard-code the above test suite and produce exactly one line in the specified format. No external input is permitted. No physical units are involved; all quantities are nondimensional. Angles are in radians as stated above. All matrices are to be treated as SPD and computations should use standard linear algebra operations for SPD matrices in $\\mathbb{R}^{d \\times d}$.",
            "solution": "The combined metric $M^{\\star}$ is defined by the quadratic form resulting from a minimization problem. For any vector $v \\in \\mathbb{R}^{d}$, its squared Riemannian length with respect to $M^{\\star}$ is:\n$$\nv^{\\top} M^{\\star} v = \\min_{v_{1} + v_{2} = v} \\left( v_{1}^{\\top} M_{1} v_{1} + v_{2}^{\\top} M_{2} v_{2} \\right)\n$$\nwhere $M_1$ and $M_2$ are symmetric positive definite (SPD) matrices. We solve this constrained optimization problem using Lagrange multipliers. The Lagrangian is:\n$$\n\\mathcal{L}(v_1, v_2, \\lambda) = v_{1}^{\\top} M_{1} v_{1} + v_{2}^{\\top} M_{2} v_{2} - \\lambda^{\\top} (v_1 + v_2 - v)\n$$\nSetting the gradients with respect to $v_1$ and $v_2$ to zero gives the first-order necessary conditions:\n$$\n\\nabla_{v_1} \\mathcal{L} = 2 M_1 v_1 - \\lambda = 0 \\implies v_1 = \\frac{1}{2} M_1^{-1} \\lambda\n$$\n$$\n\\nabla_{v_2} \\mathcal{L} = 2 M_2 v_2 - \\lambda = 0 \\implies v_2 = \\frac{1}{2} M_2^{-1} \\lambda\n$$\nApplying the constraint $v_1 + v_2 = v$ and solving for the Lagrange multiplier vector $\\lambda$ yields $\\lambda = 2 (M_1^{-1} + M_2^{-1})^{-1} v$. Substituting this back into the expressions for $v_1$ and $v_2$ and then into the objective function, we find that $v^{\\top} M^{\\star} v = v^{\\top} (M_1^{-1} + M_2^{-1})^{-1} v$. Since this must hold for all $v$, the explicit formula for the combined metric is:\n$$\nM^{\\star} = (M_1^{-1} + M_2^{-1})^{-1}\n$$\nThis provides a computational procedure: compute the inverses of $M_1$ and $M_2$, sum them, and invert the result.\n\nTo enforce the determinant bounds $\\underline{\\Delta} \\le \\det(M^{\\star}_{\\text{clamped}}) \\le \\overline{\\Delta}$, we apply isotropic scaling if necessary. Let $\\Delta^{\\star} = \\det(M^{\\star})$. The scaled metric is $M^{\\star}_{\\text{clamped}} = s M^{\\star}$ for some scalar $s > 0$. Using the property $\\det(s M) = s^d \\det(M)$, we have $\\det(M^{\\star}_{\\text{clamped}}) = s^d \\Delta^{\\star}$.\n\nThe scaling factor $s$ is determined as follows:\n- If $\\underline{\\Delta} \\le \\Delta^{\\star} \\le \\overline{\\Delta}$, no scaling is needed ($s=1$).\n- If $\\Delta^{\\star} < \\underline{\\Delta}$, the metric is scaled up to meet the lower bound: $s = \\left( \\frac{\\underline{\\Delta}}{\\Delta^{\\star}} \\right)^{1/d}$.\n- If $\\Delta^{\\star} > \\overline{\\Delta}$, the metric is scaled down to meet the upper bound: $s = \\left( \\frac{\\overline{\\Delta}}{\\Delta^{\\star}} \\right)^{1/d}$.\n\nThe final, clamped metric is $M^{\\star}_{\\text{clamped}} = s M^{\\star}$, and its determinant is $s^d \\Delta^{\\star}$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the metric intersection and clamping problem for a suite of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Case A:\n    theta_A = np.pi / 6\n    cos_t, sin_t = np.cos(theta_A), np.sin(theta_A)\n    R_A = np.array([[cos_t, -sin_t], [sin_t, cos_t]])\n    M1_A = R_A @ np.diag([100, 1]) @ R_A.T\n    \n    test_cases = [\n        {\n            \"d\": 2, \n            \"M1\": M1_A,\n            \"M2\": np.diag([0.5, 400]),\n            \"bounds\": (1e-3, 1e6)\n        }, # Case A\n        {\n            \"d\": 2, \n            \"M1\": np.diag([1e-3, 1e-3]),\n            \"M2\": np.diag([1e-3, 1e-3]),\n            \"bounds\": (1e-2, 1e2)\n        }, # Case B\n        {\n            \"d\": 2, \n            \"M1\": np.diag([1e3, 1e3]),\n            \"M2\": np.diag([1e3, 1e3]),\n            \"bounds\": (1e-3, 1e4)\n        }, # Case C\n        {\n            \"d\": 2, \n            \"M1\": np.diag([4, 4]),\n            \"M2\": np.diag([4, 4]),\n            \"bounds\": (4, 4)\n        }, # Case D\n        {\n            \"d\": 3, \n            \"M1\": np.diag([100, 1, 10]),\n            \"M2\": np.diag([1, 50, 0.5]),\n            \"bounds\": (0.1, 0.5)\n        } # Case E\n    ]\n\n    all_results_str = []\n\n    for case in test_cases:\n        d = case[\"d\"]\n        M1 = case[\"M1\"]\n        M2 = case[\"M2\"]\n        delta_min, delta_max = case[\"bounds\"]\n\n        # Step 1: Compute the combined metric M_star = (M1^-1 + M2^-1)^-1\n        M1_inv = np.linalg.inv(M1)\n        M2_inv = np.linalg.inv(M2)\n        M_star = np.linalg.inv(M1_inv + M2_inv)\n\n        # Step 2: Compute its determinant\n        det_raw = np.linalg.det(M_star)\n\n        # Step 3: Check determinant bounds and compute scaling factor s\n        s = 1.0\n        scaled_flag = False\n        \n        # Check for floating point inaccuracies near the bounds\n        if not (delta_min = det_raw = delta_max):\n            if det_raw  delta_min:\n                # Handle cases where det_raw is non-positive, though not expected for SPD\n                if det_raw > 0:\n                    s = (delta_min / det_raw)**(1.0 / d)\n                    scaled_flag = True\n            elif det_raw > delta_max:\n                s = (delta_max / det_raw)**(1.0 / d)\n                scaled_flag = True\n        \n        # Step 4: Apply scaling factor and compute final results\n        M_clamped = s * M_star\n        det_clamped = s**d * det_raw\n\n        # Step 5: Format outputs as specified\n        d_out = d\n        det_raw_out = f\"{det_raw:.6f}\"\n        det_clamped_out = f\"{det_clamped:.6f}\"\n        scaled_flag_out = \"True\" if scaled_flag else \"False\"\n        \n        entries = M_clamped.flatten()\n        entries_out = f\"[{','.join([f'{x:.6f}' for x in entries])}]\"\n\n        case_result_str = f\"[{d_out},{det_raw_out},{det_clamped_out},{scaled_flag_out},{entries_out}]\"\n        all_results_str.append(case_result_str)\n\n    # Final print statement in the exact required format.\n    final_output = f\"[{','.join(all_results_str)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}