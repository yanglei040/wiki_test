## 引言
在科学与工程领域，计算流体力学（CFD）是理解和预测流体行为不可或缺的工具。然而，CFD始终面临着一个核心挑战：在模拟精度与计算成本之间取得平衡。一方面，[直接数值模拟](@entry_id:149543)（DNS）能提供最高保真度的数据，但其巨大的计算开销使其仅限于基础研究；另一方面，[雷诺平均](@entry_id:754341)[Navier-Stokes](@entry_id:276387)（RANS）方法计算效率极高，却因其封闭模型的过度简化假设，在面对分离、旋转等[复杂流动](@entry_id:747569)时精度堪忧。这一“保真度-成本”鸿沟严重制约了[湍流模拟](@entry_id:187401)在工程设计中的应用潜力。

机器学习的崛起为解决这一长期难题提供了全新的途径。通过将高保真数据与物理原理相结合，我们可以“教导”[机器学习模型](@entry_id:262335)去识别并修正传统[湍流](@entry_id:151300)封闭模型的不足之处。本文旨在系统性地介绍机器学习增强[湍流](@entry_id:151300)封闭模型这一前沿领域，为读者构建一个从理论到实践的完整知识框架。

本文将分为三个核心章节，引导读者逐步深入：
*   在**“原理与机制”**一章中，我们将从第一性原理出发，探讨构建物理一致模型所必须遵循的基本约束（如伽利略[不变性](@entry_id:140168)），并详细介绍实现这些约束的关键架构（如张量基[神经网](@entry_id:276355)络）与训练方法。
*   在**“应用与交叉学科联系”**一章中，我们将展示这些模型在修正RANS与LES模型、处理可压缩流与[浮力](@entry_id:144145)效应等真实物理问题中的具体应用，并探讨其在不同学科间的联系。
*   最后，在**“动手实践”**部分，我们将提供一系列精心设计的练习，帮助读者将理论知识转化为解决实际问题的能力。

通过本文的学习，读者将理解如何构建、训练和验证这些先进的[混合模型](@entry_id:266571)，从而掌握开发下一代高效、高精度[湍流](@entry_id:151300)预测工具的核心技术。

## 原理与机制

本章旨在深入探讨机器学习增强[湍流](@entry_id:151300)封闭模型的核心原理与实现机制。继前一章对该领域背景的宏观介绍之后，本章将从第一性原理出发，系统阐述构建物理一致、性能稳健的[机器学习模型](@entry_id:262335)所必须遵循的基本约束，并详细介绍实现这些模型的关键架构与训练方法。我们将通过一系列精心设计的思想实验与计算案例，揭示这些原理与机制的深刻内涵与实际应用价值。

### 增强模型的必要性：弥合保真度与成本的鸿沟

[湍流模拟](@entry_id:187401)的核心挑战在于其跨越多个[数量级](@entry_id:264888)的时空尺度。理想情况下，**[直接数值模拟](@entry_id:149543)（Direct Numerical Simulation, DNS）**通过在极精细的网格上直接求解[Navier-Stokes方程](@entry_id:161487)，能够捕捉所有[湍流](@entry_id:151300)尺度，提供最高保真度的数据。然而，其计算成本高昂到令人望而却步，尤其是在高雷诺数下。作为对比，**[雷诺平均](@entry_id:754341)Navier-Stokes（Reynolds-Averaged [Navier-Stokes](@entry_id:276387), RANS）**方法通过对瞬时量进行时间平均，引入了代表[湍流](@entry_id:151300)脉动效应的[雷诺应力](@entry_id:263788)项，从而只需在粗糙得多的网格上求解平均流场，计算成本极低。但这牺牲了大量物理细节，其准确性完全依赖于对雷诺应力项的**封闭模型（closure model）**。

我们可以通过一个典型的槽道[湍流](@entry_id:151300)案例来定量理解DNS与RANS在计算成本上的巨大差异。考虑一个[摩擦雷诺数](@entry_id:749598)$Re_{\tau} = u_{\tau} \delta / \nu = 1000$的不可压缩槽道流，其中$u_{\tau}$是壁面[摩擦速度](@entry_id:267882)，$\delta$是槽道半高，$\nu$是运动粘度。根据标准的网格解析度要求，DNS需要解析到壁面附近的[Kolmogorov尺度](@entry_id:270763)，其在流向、展向和法向的网格点数$N_{x}, N_{z}, N_{y}$分别与$Re_{\tau}$成比例，即$N_{grid}^{DNS} \propto Re_{\tau}^{3}$。而RANS结合[壁面函数](@entry_id:155079)，其网格点数$N_{grid}^{RANS}$几乎不随$Re_{\tau}$变化。更重要的是，显式时间格式的时间步长$\Delta t$受Courant–Friedrichs–Lewy (CFL)条件限制，对于DNS，$\Delta t$需与最小网格尺寸成正比，而RANS的$\Delta t$则与粗网格尺寸成正比。

综合空间和[时间分辨率](@entry_id:194281)，总计算成本$C \propto N_{\text{grid}} \times N_{t}$（$N_t$为模拟一定物理时间所需的步数）。基于合理的 scaling laws，可以估算出在该雷诺数下，$C^{DNS} / C^{RANS}$的比值高达$10^5$量级。这一惊人的差距清晰地揭示了CFD领域的“保真度-成本”鸿沟：DNS过于昂贵无法用于工程设计，而传统[RANS模型](@entry_id:754068)则因其过度简化的物理假设，在面对[分离流](@entry_id:754694)、[旋转流](@entry_id:276737)或强各向异性等[复杂流动](@entry_id:747569)时，预测精度往往不足。

这正是机器学习增强[湍流](@entry_id:151300)封闭模型应运而生的根本原因。其核心目标是利用高保真度数据（如DNS或实验数据）来“教导”[机器学习模型](@entry_id:262335)，使其能够修正或替代传统封闭模型的不足之处，从而在保持RANS计算成本优势的同时，大幅提升其预测精度，最终实现对复杂[湍流](@entry_id:151300)现象的高效且准确的模拟。

### 物理一致性的基本原理

将机器学习模型引入物理建模领域，一个不可逾越的前提是模型必须遵守基本的物理定律。一个看似在训练数据上表现完美的模型，如果违背了物理守恒律或对称性，其在未知场景下的预测能力将毫无保障，甚至可能产生荒谬的结果。因此，任何成功的机器学习[湍流](@entry_id:151300)封闭模型都必须内嵌以下基本原理。

#### 伽利略[不变性](@entry_id:140168)

**伽利略[不变性](@entry_id:140168)（Galilean Invariance）**要求物理定律在所有[惯性参考系](@entry_id:276742)中形式相同。对于流体[本构关系](@entry_id:186508)（constitutive relations），这意味着模型不能依赖于观察者的绝对速度。若我们将整个系统置于一个以恒定速度$\mathbf{c}$运动的[参考系](@entry_id:169232)中，[瞬时速度](@entry_id:167797)$\mathbf{u}$变为$\mathbf{u}' = \mathbf{u} + \mathbf{c}$，[平均速度](@entry_id:267649)$\mathbf{U}$变为$\mathbf{U}' = \mathbf{U} + \mathbf{c}$。然而，速度脉动量$\mathbf{u}' = \mathbf{u} - \mathbf{U}$保持不变：$(\mathbf{u} + \mathbf{c}) - (\mathbf{U} + \mathbf{c}) = \mathbf{u} - \mathbf{U}$。因此，所有基于速度脉动统计量定义的[湍流](@entry_id:151300)量，如[雷诺应力张量](@entry_id:270803)$R_{ij} = -\overline{u'_i u'_j}$、[湍动能](@entry_id:262712)$k$以及[湍流耗散率](@entry_id:756234)$\varepsilon$，都是伽利略不变的。

这意味着，任何用于预测这些[湍流](@entry_id:151300)量的机器学习模型，其输入特征也必须是伽利略不变的。平均速度$\mathbf{U}$本身不满足此要求，但其空间梯度$\nabla \mathbf{U}$满足，因为常数向量$\mathbf{c}$的梯度为零。因此，一个物理上允许的封闭模型，其函数形式可以是$R_{ij} = \mathcal{F}(\nabla \mathbf{U}, k, \varepsilon, \dots)$，但绝不能是$R_{ij} = \mathcal{F}(\mathbf{U}, \dots)$。

#### 客观性（[坐标系](@entry_id:156346)无关性）

**客观性（Objectivity）**或称**[坐标系](@entry_id:156346)无关性（Frame Invariance）**，要求[本构关系](@entry_id:186508)在[坐标系](@entry_id:156346)发生刚性旋转时应保持其物理形式。这意味着模型不能依赖于[坐标系](@entry_id:156346)的特定方向。如果我们将[坐标系](@entry_id:156346)通过一个正交矩阵$Q$进行旋转（$Q^T Q = I$），那么任何[二阶张量](@entry_id:199780)$T$的各个分量会按照$T' = Q T Q^T$进行变换。一个客观的张量函数$\mathcal{F}$必须满足协变性关系：$\mathcal{F}(T'_1, T'_2, \dots) = Q \mathcal{F}(T_1, T_2, \dots) Q^T$。

这一原理直接否定了使用[速度梯度张量](@entry_id:270928)$A=\nabla \mathbf{U}$的原始分量作为[机器学习模型](@entry_id:262335)输入的做法。原因在于，[神经网](@entry_id:276355)络是一个复杂的[非线性](@entry_id:637147)函数，它不会自动满足上述[协变](@entry_id:634097)性关系。对[坐标系](@entry_id:156346)进行旋转会改变输入$A$的分量值，从而导致输出一个与$Q \mathcal{F}(A) Q^T$完全不符的新张量，这在物理上是不可接受的。

正确的途径是将[速度梯度张量](@entry_id:270928)$A$分解为其对称部分——**[应变率张量](@entry_id:266108)（strain-rate tensor）** $S = \frac{1}{2}(A + A^T)$，和反对称部分——**旋转率张量（rotation-rate tensor）** $\Omega = \frac{1}{2}(A - A^T)$。然后，依据[表示定理](@entry_id:637872)（Representation Theorem），任何客观的张量函数都可以表示为一个张量基的[线性组合](@entry_id:154743)，其系数是输入张量的[标量不变量](@entry_id:193787)的函数。

**[标量不变量](@entry_id:193787)（Scalar Invariants）**是通过迹（trace）运算从$S$和$\Omega$的乘积构造出的标量，它们在[坐标系](@entry_id:156346)旋转下保持不变。例如，$\mathrm{tr}(S^2)$在旋转后的[坐标系](@entry_id:156346)中变为$\mathrm{tr}(S'^2) = \mathrm{tr}((QSQ^T)^2) = \mathrm{tr}(Q S^2 Q^T)$。利用迹的循环不变性（$\mathrm{tr}(XYZ) = \mathrm{tr}(ZXY)$），我们得到$\mathrm{tr}(Q S^2 Q^T) = \mathrm{tr}(Q^T Q S^2) = \mathrm{tr}(I S^2) = \mathrm{tr}(S^2)$。因此，$\mathrm{tr}(S^2)$是一个[标量不变量](@entry_id:193787)。对于三维不可压缩流（$\mathrm{tr}(S)=0$），一个完备的[标量不变量](@entry_id:193787)基包含五个独立的量：
$$
\lambda_1 = \mathrm{tr}(S^2), \quad \lambda_2 = \mathrm{tr}(\Omega^2), \quad \lambda_3 = \mathrm{tr}(S^3), \quad \lambda_4 = \mathrm{tr}(S\Omega^2), \quad \lambda_5 = \mathrm{tr}(S^2\Omega^2)
$$
通过将这些[标量不变量](@entry_id:193787)作为[神经网](@entry_id:276355)络的输入，我们可以保证网络输出的标量系数在[坐标系](@entry_id:156346)旋转下是不变的，从而为构建客观模型奠定了基础 。

#### [量纲一致性](@entry_id:271193)

物理方程必须在任何单位制下都成立，这要求方程具有**[量纲一致性](@entry_id:271193)（Dimensional Consistency）**。[雷诺应力张量](@entry_id:270803)的无量纲形式，即**[各向异性张量](@entry_id:746467)（anisotropy tensor）** $b_{ij} = \frac{-\overline{u'_i u'_j}}{2k} - \frac{1}{3}\delta_{ij}$，是无量纲的。因此，任何用于预测它的模型也必须是无量纲的。这意味着模型的输入特征必须是无量纲组合。例如，应变率张量$S$和旋转率张量$\Omega$的量纲是$[T^{-1}]$。我们可以使用[湍流](@entry_id:151300)时间尺度$\tau_t \propto k/\varepsilon$（量纲为$[T]$）来将其无量纲化，得到$\hat{S} = \tau_t S$和$\hat{\Omega} = \tau_t \Omega$。另一个重要的[无量纲参数](@entry_id:169335)是[湍流](@entry_id:151300)[雷诺数](@entry_id:136372)$Re_t = k^2 / (\nu \varepsilon)$。任何依赖于$k$或$\varepsilon$等有量纲量的模型，都必须通过这种[无量纲化](@entry_id:136704)的方式来引入它们。

#### [可实现性](@entry_id:193701)

**[可实现性](@entry_id:193701)（Realizability）**是一个重要的数学和物理约束，它要求[雷诺应力张量](@entry_id:270803)必须反映其源于速度脉动平方平均的统计性质。具体来说，对于任意向量$v_i$，$(\overline{u'_i v_i})^2 \leq \overline{(u'_i)^2} \overline{(v_i)^2}$ (Cauchy-Schwarz不等式)。这导出了一系列对[雷诺应力张量](@entry_id:270803)分量的约束，其中最核心的是$-\overline{u'_i u'_j}$必须是一个半[正定张量](@entry_id:204409)，即其所有[特征值](@entry_id:154894)必须非负。这意味着湍动能在任何方向上都不能是负的。此外，对角线上的法向应力$\overline{(u'_i)^2}$必须非负。违反[可实现性](@entry_id:193701)约束的模型可能会在模拟中产生非物理的结果，如负的[湍动能](@entry_id:262712)，导致数值不稳定和崩溃。

### 不变性机器学习模型的架构

遵循上述物理原理，我们可以设计出内在满足这些约束的机器学习模型架构。

#### 传统封闭模型的局限性

大多数传统[RANS模型](@entry_id:754068)，如标准的$k$-$\varepsilon$模型，都基于**[Boussinesq假设](@entry_id:272519)**。该假设类比分子粘性，认为[雷诺应力张量](@entry_id:270803)的各向异性部分与平均[应变率张量](@entry_id:266108)成线性关系：
$$
-\overline{u'_i u'_j} + \frac{2}{3}k\delta_{ij} = 2\nu_t S_{ij}
$$
其中，$\nu_t$是标量**涡粘性系数（eddy viscosity）**。这个模型的核心缺陷在于它强制[雷诺应力张量](@entry_id:270803)的主轴与[应变率张量](@entry_id:266108)的[主轴](@entry_id:172691)对齐。然而，在许多[复杂流动](@entry_id:747569)中，如存在[流动分离](@entry_id:143331)、强烈旋转或曲率的区域，DNS和实验均表明雷诺[应力与应变率](@entry_id:263123)之间存在显著的错位和非线性关系。例如，在[旋转流](@entry_id:276737)中，压力-应变相关项会诱导强烈的各向异性，这是标量涡粘性模型无法捕捉的。[Boussinesq假设](@entry_id:272519)的这种结构性缺陷是其在[复杂流动](@entry_id:747569)中预测失败的根本原因。

#### 张量基[神经网](@entry_id:276355)络 (TBNN)

为了克服[Boussinesq假设](@entry_id:272519)的局限性，机器学习模型需要能够表示更一般的[雷诺应力](@entry_id:263788)与平均流场梯度之间的非[线性关系](@entry_id:267880)，同时严格遵守[客观性原理](@entry_id:185412)。**张量基[神经网](@entry_id:276355)络（Tensor Basis Neural Network, TBNN）**提供了一个优雅且强大的解决方案。

TBNN的核心思想是，任何满足客观性的对称、迹为零的二阶张量函数$b(S, \Omega)$都可以被表示为一个张量基$T^{(n)}$的[线性组合](@entry_id:154743)：
$$
b_{ij} = \sum_{n=1}^{10} g_n(\lambda_1, \dots, \lambda_5) T^{(n)}_{ij}(S, \Omega)
$$
这里的关键在于：
1.  **张量基 $T^{(n)}$**：这是一个由$S$和$\Omega$的多项式乘积构成的、固定的张量集合。对于三维[不可压缩流](@entry_id:140301)，这个基包含10个独立的张量，例如$S$, $S^2 - \frac{1}{3}\mathrm{tr}(S^2)I$, $\Omega^2 - \frac{1}{3}\mathrm{tr}(\Omega^2)I$, $S\Omega - \Omega S$等。这个基是完备的，能够表示任何满足对称性和迹为零条件的张量函数。
2.  **标量系数 $g_n$**：这些系数是输入张量$S$和$\Omega$的五个[标量不变量](@entry_id:193787)$\lambda_1, \dots, \lambda_5$的函数。

TBNN的架构完美地实现了物理约束与机器学习的结合：它使用一个标准的[前馈神经网络](@entry_id:635871)来学习标量函数$g_n(\lambda_1, \dots, \lambda_5)$。由于网络的输入（[标量不变量](@entry_id:193787)$\lambda_m$）和输出（标量系数$g_n$）都是标量，它们在[坐标系](@entry_id:156346)旋转下保持不变。而最终的张量$b_{ij}$是通过固定的、具有正确[张量变换](@entry_id:183453)性质的基$T^{(n)}$来重构的。这样，无论[神经网](@entry_id:276355)络内部的函数多么复杂，整个$b_{ij}$的表达式天生就满足客观性（[坐标系](@entry_id:156346)无关性） 。

### 训练方法：融合数据与物理

拥有一个结构上满足物理原理的模型架构只是第一步，如何有效地训练模型以使其既能拟[合数](@entry_id:263553)据又能遵守物理定律是下一个核心挑战。

#### 模型增强形式与[可辨识性](@entry_id:194150)

机器学习对[RANS模型](@entry_id:754068)的增强可以有多种形式，例如，对涡粘性系数$\nu_t$进行修正。常见的修正方式包括**加性修正**（$\nu_t = \nu_t^{(0)} + \Delta\nu_t$）和**乘性修正**（$\nu_t = \alpha \nu_t^{(0)}$），其中$\nu_t^{(0)}$是基准模型的预测值。更一般的形式是**场修正**（$\nu_t = \nu_t^{(0)} f(\mathbf{x})$），其中$f(\mathbf{x})$是由ML模型预测的空间变化函数。

在选择模型形式时，必须考虑**结构[可辨识性](@entry_id:194150)（structural identifiability）**的问题。即可辨识性是指我们能否根据可用的观测数据唯一地确定模型的参数。例如，在一个完全发展的槽道流（fully developed channel flow）中，如果我们的观测数据只有总流量$Q$这样一个全局标量，那么我们可能可以唯一地确定一个全局乘性修正因子$\alpha$，因为$Q$通常是$\alpha$的[单调函数](@entry_id:145115)。但是，我们绝对无法从单一的$Q$值反推出一个完整的函数场$f(y)$，因为存在无穷多个不同的函数$f(y)$可以积分得到相同的流量$Q$。然而，如果我们拥有整个流道内的完整[速度剖面](@entry_id:266404)$u(y)$，那么通过求解[RANS方程](@entry_id:275032)的逆问题，我们原则上可以唯一地确定修正场$f(y)$。这个例子说明，模型架构的选择必须与可用数据的丰富程度相匹配。

#### 用于物理约束训练的复合[损失函数](@entry_id:634569)

单纯地最小化模型预测（如[雷诺应力](@entry_id:263788)）与高保真数据之间的差异（data-driven training）往往会导致[模型过拟合](@entry_id:153455)，并且不能保证其预测结果满足控制方程。一个更稳健的方法是采用**物理约束（physics-informed）**的训练策略，其核心是设计一个**复合[损失函数](@entry_id:634569)（composite loss function）**：
$$
J = J_{\text{data}} + \lambda J_{\text{PDE}} + \gamma J_{\text{cons}}
$$
其中$\lambda$和$\gamma$是超参数，用于平衡不同损失项的权重。
-   **$J_{\text{data}}$**：**数据损失项**。它惩罚模型预测的[湍流](@entry_id:151300)量（如$R_{ij}^{\theta}$）与高保真参考数据（$R_{ij}^{\text{HF}}$）之间的差异。通常采用均方误差（MSE）来度量，例如 $J_{\text{data}} \propto \sum \| R^{\theta} - R^{\text{HF}} \|_F^2$。
-   **$J_{\text{PDE}}$**：**PDE损失项**。它将ML模型嵌入RANS求解器中，得到预测的平均速度场$\bar{\mathbf{u}}^\theta$和压[力场](@entry_id:147325)$\bar{p}^\theta$。然后，将这些场代入RANS动量方程和连续性方程，计算方程的**残差（residual）**。$J_{\text{PDE}}$惩罚这些残差的范数，例如 $J_{\text{PDE}} \propto \sum \| \mathcal{M}(\bar{\mathbf{u}}^\theta, \bar{p}^\theta, R^\theta) \|^2 + \alpha \sum \| \nabla \cdot \bar{\mathbf{u}}^\theta \|^2$。这一项强制模型学习到的[湍流](@entry_id:151300)行为必须与它产生的平均流场一起，共同满足[流体力学](@entry_id:136788)的基本[守恒定律](@entry_id:269268)。
-   **$J_{\text{cons}}$**：**物理约束项**。它直接惩罚模型对已知物理约束的违反。例如，可以通过惩罚雷诺应力[张量的反对称部分](@entry_id:193562)来强制对称性，通过惩罚负[特征值](@entry_id:154894)来强制[可实现性](@entry_id:193701)。

这种复合损失函数将数据驱动的学习与基于物理的约束相结合，使得模型在拟合高保真数据的同时，也能保持物理上的[自洽性](@entry_id:160889)，从而提高其泛化能力。

#### 嵌入式模型的梯度计算：伴随方法

在包含$J_{\text{PDE}}$的训练中，[损失函数](@entry_id:634569)$J$通过一个完整的CFD求解过程依赖于ML模型参数$\theta$。这意味着为了计算梯度$\frac{dJ}{d\theta}$以进行优化，我们需要“[微分](@entry_id:158718)”整个[CFD求解器](@entry_id:747244)。对于一个通过迭代求解得到[稳态解](@entry_id:200351)$U(\theta)$的[隐式求解器](@entry_id:140315)，其满足残差方程$R(U(\theta), \theta) = 0$。

直接计算状态$U$对参数$\theta$的敏感度$\frac{\partial U}{\partial \theta}$（称为**前向敏感度分析法**）需要求解一个维度为$(N_{dof} \times N_{params})$的大型[线性方程组](@entry_id:148943)，其中$N_{dof}$是CFD求解的自由度数，$N_{params}$是ML模型的参数数量。当$N_{params}$很大时（例如对于深度神经网络），这种方法的计算成本是不可接受的。

**伴随方法（Adjoint Method）**提供了一种极其高效的替代方案。通过对残差方程$R(U, \theta)=0$求[全微分](@entry_id:171747)，并引入一个**伴随向量（adjoint vector）** $\boldsymbol{\psi}$，我们可以推导出总梯度的表达式：
$$
\frac{dJ}{d\theta} = \frac{\partial J}{\partial \theta} - \boldsymbol{\psi}^T \frac{\partial R}{\partial \theta}
$$
其中，伴随向量$\boldsymbol{\psi}$通过求解一个与[CFD求解器](@entry_id:747244)[雅可比矩阵](@entry_id:264467)$R_U = \frac{\partial R}{\partial U}$相关的[线性方程组](@entry_id:148943)来获得：
$$
R_U^T \boldsymbol{\psi} = \left(\frac{\partial J}{\partial U}\right)^T
$$
伴随方法的巨大优势在于，无论ML模型的参数$\theta$有多少，我们只需要求解一次伴随方程（一个$N_{dof} \times N_{dof}$的线性系统）就可以得到完整的梯度$\frac{dJ}{d\theta}$。由于求解这个伴随方程的计算成本与求解一次CFD流场的成本相当，因此伴随方法使得对嵌入在大型求解器中的复杂ML模型进行[梯度下降优化](@entry_id:634206)成为可能。

### 验证与泛化

模型训练完成后，最关键的一步是评估其在未见过的新流动条件下的表现，即**泛化能力（generalization capability）**。这一步的严谨性直接决定了我们对模型可靠性的信心。

#### 空间[数据泄漏](@entry_id:260649)问题

在应用于[湍流](@entry_id:151300)场这类空间相关的连续数据时，传统机器学习中“随机打乱、随机划分”的训练/验证/[测试集](@entry_id:637546)划分方法是完全错误的。[湍流](@entry_id:151300)场中的任意两点，如果它们的物理距离小于相关长度$\ell_c$，那么它们的物理量（如速度、[雷诺应力](@entry_id:263788)）是高度相关的。

如果我们将一个流场的所有数据点随机划分为80%的[训练集](@entry_id:636396)和20%的[测试集](@entry_id:637546)，那么几乎每一个测试点周围都会密布着训练点。模型在预测这个测试点时，实际上是在执行插值（interpolation），而不是外插（extrapolation）或推理（reasoning）。它可以通过“记住”邻近训练点的数值来获得一个很低的[测试误差](@entry_id:637307)。这种现象被称为**空间[数据泄漏](@entry_id:260649)（spatial data leakage）**。这种划分方式得到的[测试误差](@entry_id:637307)会极大地低估模型在真正新场景下的真实误差，因为它测试的是模型的插值能力，而非物理泛化能力。

#### 评估泛化能力的正确策略

为了获得对[模型泛化](@entry_id:174365)能力无偏的估计，训练集和[测试集](@entry_id:637546)必须在统计上尽可能独立。对于流场数据，这意味着它们在物理空间上必须是分离的。正确的划分策略是基于**流动配置（flow configuration）**来进行。

例如，如果我们有三种不同类型的流动数据：[平板边界层](@entry_id:749449)（FP-TBL）、[后台阶流](@entry_id:746640)动（BFS）和[翼型](@entry_id:195951)绕流（AF），一个合理的划分策略是：
-   **训练集**：使用[平板边界层](@entry_id:749449)和[后台阶流](@entry_id:746640)动（例如在某个雷诺数下）的全部数据。
-   **验证集**：使用[后台阶流](@entry_id:746640)动在另一个不同[雷诺数](@entry_id:136372)下的数据，用于模型选择和[超参数调整](@entry_id:143653)。
-   **测试集**：完全保留[翼型](@entry_id:195951)绕流的数据作为最终的、从未见过的测试集。

这种划分策略确保了[测试集](@entry_id:637546)在物理上与[训练集](@entry_id:636396)完全不同（不同的几何、不同的流动拓扑结构），从而杜绝了空间[数据泄漏](@entry_id:260649)。在这种严格的测试下获得的误差才能真实地反映模型在面对全新工程问题时的预测能力。只有通过这种方式验证的模型，我们才能对其在实际应用中的表现抱有信心。