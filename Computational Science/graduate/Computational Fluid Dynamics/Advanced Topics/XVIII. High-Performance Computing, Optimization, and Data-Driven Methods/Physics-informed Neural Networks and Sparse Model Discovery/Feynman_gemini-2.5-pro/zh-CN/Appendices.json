{
    "hands_on_practices": [
        {
            "introduction": "本练习将引导您体验稀疏模型发现的核心过程，其目标是从嘈杂的流场数据中自动揭示控制流体行为的物理定律，具体来说是压力泊松方程。通过这项实践，您将学习如何从原始数据构建候选物理项的特征库，并应用稀疏回归技术来辨识出真正起主导作用的控制方程项 。",
            "id": "3351987",
            "problem": "给定一个方形域上的无量纲二维不可压缩流，要求您使用物理信息稀疏回归来发现压力泊松方程的结构。目标是识别内部对流源项的系数，并确定是否存在与壁面法向梯度成比例的边界源项。您的程序必须是一个完整、可运行的程序，能够构建合成数据，从含噪声的速度场计算特征库，执行序贯阈值最小二乘稀疏回归，并报告为每个提供的测试用例发现的系数。\n\n从以下基本原理出发：不可压缩连续性方程 $\\nabla\\cdot\\mathbf{u}=0$ 和单位密度（无量纲变量）的不可压缩动量方程 $$\n\\partial_t \\mathbf{u} + \\mathbf{u}\\cdot\\nabla \\mathbf{u} = -\\nabla p + \\nu \\nabla^2 \\mathbf{u}\n$$，其中 $\\mathbf{u}=(u,v)$ 是速度场，$p$ 是压力。压力场 $p$ 的定义可相差一个常数，压力泊松方程将 $\\nabla^2 p$ 与速度梯度联系起来。壁面处的边界条件将压力的法向导数与运动学量联系起来。您不能对目标模型系数做任何解析形式的假设；相反，您必须仅从速度场及其梯度构建的数据中，通过稀疏回归来恢复它们。\n\n您的程序必须：\n- 为每个测试用例，在单位正方形 $[0,1]\\times[0,1]$ 上构建一个具有 $N_x=N_y=N$ 个点的均匀笛卡尔网格。使用 $x_i=i\\,\\Delta x$ 和 $y_j=j\\,\\Delta y$，其中 $\\Delta x=\\Delta y=1/(N-1)$，$i\\in\\{0,\\dots,N-1\\}$ 且 $j\\in\\{0,\\dots,N-1\\}$。\n- 通过对流函数 $\\psi(x,y)$ 求导来生成一个不可压缩速度场 $\\mathbf{u}(x,y)$，其中 $\\psi(x,y)=\\sin(\\pi x)\\sin(\\pi y)$ 且 $\\mathbf{u}=(\\partial_y\\psi,-\\partial_x\\psi)$。在指定为零流场的测试用例中，恒定地设置 $u=v=0$。\n- 根据每个测试用例的规定，使用标准差为 $\\sigma$（无量纲）的独立零均值高斯噪声来干扰速度分量。\n- 使用内部的二阶精度有限差分和边界上的一阶单边有限差分，从含噪声的速度场构建特征库：\n  1. 内部对流源特征 $f_{\\mathrm{conv}}(x,y)$，由 $-\\nabla\\cdot\\left(\\mathbf{u}\\cdot\\nabla \\mathbf{u}\\right)$ 的离散近似给出。其计算方法为：首先构建对流加速度分量 $a_x=u\\,\\partial_x u + v\\,\\partial_y u$ 和 $a_y=u\\,\\partial_x v + v\\,\\partial_y v$，然后取其离散散度 $-\\left(\\partial_x a_x + \\partial_y a_y\\right)$。\n  2. 边界源候选特征 $f_{\\mathrm{bnd}}(x,y)$，由邻近域边界的网格点上壁面法向速度的壁面法向梯度构建：对于底部和顶部壁面，使用 $j=0$ 和 $j=N-1$ 处 $v$ 在 $y$ 方向上的单边差分，分别定义在 $j=1$ 和 $j=N-2$ 处的贡献；对于左侧和右侧壁面，使用 $i=0$ 和 $i=N-1$ 处 $u$ 在 $x$ 方向上的单边差分，分别定义在 $i=1$ 和 $i=N-2$ 处的贡献。将邻近各壁面的点的贡献相加得到 $f_{\\mathrm{bnd}}(x,y)$，并对所有其他网格点设置 $f_{\\mathrm{bnd}}(x,y)=0$。\n- 为每个测试用例构建一个合成观测目标场 $z(x,y)$，通过将特征进行线性组合得到：$z=f_{\\mathrm{conv}}+\\alpha\\,f_{\\mathrm{bnd}}$，其中 $\\alpha$ 是每个测试用例指定的标量。这模拟了一种情景：压力泊松方程的内部源由对流加速度散度确定，并且存在一个强度未知的额外边界局域源。\n- 使用序贯阈值最小二乘法进行稀疏线性回归，以拟合 $z\\approx c_1\\,f_{\\mathrm{conv}}+c_2\\,f_{\\mathrm{bnd}}$：从所有网格点计算 $(c_1,c_2)$ 的最小二乘解，将任何量级低于阈值 $\\lambda$ 的系数设置为零，然后仅使用剩余的非零系数重新拟合。如果两个系数都被阈值化为零，则返回 $(0,0)$。\n\n所有计算都是无量纲的，不报告任何物理单位。三角函数中出现的角度均以弧度为单位。\n\n测试套件：\n- 案例 $1$（一般情况）：$N=64$，$\\sigma=0.01$，$\\alpha=0.0$，$\\lambda=0.05$，使用流函数生成的流场。\n- 案例 $2$（受边界影响的情况）：$N=64$，$\\sigma=0.02$，$\\alpha=0.4$，$\\lambda=0.05$，使用流函数生成的流场。\n- 案例 $3$（边界情况，零流场）：$N=32$，$\\sigma=0.0$，$\\alpha=1.0$，$\\lambda=0.01$，设置 $u=v=0$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含每个测试用例发现的回归系数，格式为逗号分隔的列表的列表，每个内部列表的顺序为 $[c_1,c_2]$。例如，对于三个测试用例，请严格按照以下格式打印：[[c1_case1,c2_case1],[c1_case2,c2_case2],[c1_case3,c2_case3]]。",
            "solution": "问题陈述已经过严格验证，被认为是具有科学依据、适定且自洽的。它在流体动力学的物理信息模型发现领域提出了一个清晰且可解的计算任务。所有必要的数据、定义和程序都已提供，不存在内部矛盾或违反基本原则之处。因此，我们可以着手解决该问题。\n\n问题的核心是从含噪声的数据中逆向工程一个偏微分方程的结构。具体来说，我们的目标是发现在假定的类压力泊松方程\n$$\n\\nabla^2 p \\approx c_1 f_{\\mathrm{conv}} + c_2 f_{\\mathrm{bnd}}\n$$\n中的系数 $c_1$ 和 $c_2$，其左侧由一个合成的“观测”目标场 $z$ 表示，右侧由从含噪声速度场 $\\mathbf{u}$ 构建的候选特征项组成。真实系数由 $z = f_{\\mathrm{conv}} + \\alpha f_{\\mathrm{bnd}}$ 的构造方式隐式定义，这意味着目标值为 $(c_1, c_2) = (1, \\alpha)$。\n\n解决方案通过以下步骤实现：\n1.  **网格和速度场生成**：对于每个测试用例，我们在域 $[0, 1] \\times [0, 1]$ 上构建一个具有 $N \\times N$ 个点的均匀笛卡尔网格。网格间距为 $\\Delta x = \\Delta y = 1/(N-1)$。一个不可压缩速度场 $\\mathbf{u}=(u,v)$ 由流函数 $\\psi(x,y) = \\sin(\\pi x)\\sin(\\pi y)$ 生成，得到 $u = \\partial_y \\psi = \\pi \\sin(\\pi x)\\cos(\\pi y)$ 和 $v = -\\partial_x \\psi = -\\pi \\cos(\\pi x)\\sin(\\pi y)$。该场是解析无散的（$\\nabla \\cdot \\mathbf{u} = 0$）。对于零流场测试用例，我们设置 $u=v=0$。然后，通过添加具有指定标准差 $\\sigma$ 的独立零均值高斯噪声来干扰速度分量。\n\n2.  **数值微分**：一个关键部分是从离散的、含噪声的速度场计算空间导数。按照规定，我们对内部网格点使用二阶中心差分，对边界点使用一阶单边差分（前向/后向）。对于一个通用场 $g(x_i, y_j)$，其导数近似为：\n$$\n\\left(\\frac{\\partial g}{\\partial x}\\right)_{i,j} =\n\\begin{cases}\n(g_{i+1,j} - g_{i,j}) / \\Delta x & \\text{if } i=0 \\\\\n(g_{i+1,j} - g_{i-1,j}) / (2\\Delta x) & \\text{if } 0 < i < N-1 \\\\\n(g_{i,j} - g_{i-1,j}) / \\Delta x & \\text{if } i=N-1\n\\end{cases}\n$$\n$y$ 方向的导数 $\\partial g / \\partial y$ 也使用类似的公式计算。\n\n3.  **特征库构建**：我们从含噪声的速度数据 $\\mathbf{u}_{\\mathrm{noisy}}$ 中构建两个特征场。\n    -   **内部对流特征 $f_{\\mathrm{conv}}$**：该特征代表对流加速度的散度，它是标准压力泊松方程中的源项。首先，我们计算加速度向量 $\\mathbf{a} = \\mathbf{u}_{\\mathrm{noisy}} \\cdot \\nabla \\mathbf{u}_{\\mathrm{noisy}}$ 的分量：\n        $$\n        a_x = u_{\\mathrm{noisy}} \\frac{\\partial u_{\\mathrm{noisy}}}{\\partial x} + v_{\\mathrm{noisy}} \\frac{\\partial u_{\\mathrm{noisy}}}{\\partial y}\n        $$\n        $$\n        a_y = u_{\\mathrm{noisy}} \\frac{\\partial v_{\\mathrm{noisy}}}{\\partial x} + v_{\\mathrm{noisy}} \\frac{\\partial v_{\\mathrm{noisy}}}{\\partial y}\n        $$\n        该特征即为该加速度场的负散度：\n        $$\n        f_{\\mathrm{conv}} = - \\nabla \\cdot \\mathbf{a} = -\\left( \\frac{\\partial a_x}{\\partial x} + \\frac{\\partial a_y}{\\partial y} \\right)\n        $$\n        所有导数都使用上述的混合阶数有限差分格式计算。\n\n    -   **边界源特征 $f_{\\mathrm{bnd}}$**：这是一个候选特征，旨在捕捉局域于域边界的潜在物理现象。它仅在邻近壁面的网格点上定义，在其他地方为零。它的值由壁面法向速度分量的壁面法向梯度构建。例如，在邻近底壁（$y=0$）的点 $(x_i, y_1)$ 处，该特征值基于法向梯度 $(\\partial v / \\partial y)|_{y=0}$，并用单边差分近似。完整的定义是来自任何相邻壁面的贡献之和：\n        -   在 $j=1$ 处（邻近底壁）：$f_{\\mathrm{bnd}}[i, 1] \\mathrel{+}= (v_{\\mathrm{noisy}}[i, 1] - v_{\\mathrm{noisy}}[i, 0]) / \\Delta y$。\n        -   在 $j=N-2$ 处（邻近顶壁）：$f_{\\mathrm{bnd}}[i, N-2] \\mathrel{+}= (v_{\\mathrm{noisy}}[i, N-1] - v_{\\mathrm{noisy}}[i, N-2]) / \\Delta y$。\n        -   在 $i=1$ 处（邻近左壁）：$f_{\\mathrm{bnd}}[1, j] \\mathrel{+}= (u_{\\mathrm{noisy}}[1, j] - u_{\\mathrm{noisy}}[0, j]) / \\Delta x$。\n        -   在 $i=N-2$ 处（邻近右壁）：$f_{\\mathrm{bnd}}[N-2, j] \\mathrel{+}= (u_{\\mathrm{noisy}}[N-1, j] - u_{\\mathrm{noisy}}[N-2, j]) / \\Delta x$。\n        使用 `+=` 可以正确处理邻近两个壁面的角点。\n\n4.  **稀疏回归**：模型发现的核心是序贯阈值最小二乘法 (STLS)。\n    -   **合成目标**：首先，我们使用为每个测试用例提供的真实系数 $(1, \\alpha)$ 创建合成的“测量”数据 $z$：$z = f_{\\mathrm{conv}} + \\alpha f_{\\mathrm{bnd}}$。\n    -   **线性系统**：我们构建一个线性方程组 $\\mathbf{A}\\mathbf{c} \\approx \\mathbf{b}$，其中 $\\mathbf{A}$ 是特征矩阵，其列是 $f_{\\mathrm{conv}}$ 和 $f_{\\mathrm{bnd}}$ 的展平数组，$\\mathbf{b}$ 是展平的目标数组 $z$，$\\mathbf{c} = [c_1, c_2]^T$ 是我们寻求的未知系数向量。\n    -   **STLS 算法**：\n        1.  求解最小二乘问题以获得 $\\mathbf{c}$ 的初始估计。这通过 `np.linalg.lstsq` 完成。\n        2.  识别量级低于指定阈值 $\\lambda$ 的系数（即 $|c_i| < \\lambda$）。这些系数被认为是可忽略的，并被标记为移除。\n        3.  如果标记了任何系数，则通过移除相应的列来形成一个新的、更稀疏的特征矩阵 $\\mathbf{A}_{\\mathrm{sparse}}$。再次对这个简化的系统求解最小二乘问题，以获得精炼的系数 $\\mathbf{c}_{\\mathrm{sparse}}$。最终的系数向量通过将精炼值放回其原始位置，并将被阈值化的系数设置为 $0$ 来形成。如果所有系数都被阈值化，则结果为 $[0, 0]$。如果没有系数被阈值化，则初始的最小二乘解即为最终解。\n\n将此过程应用于每个测试用例，我们就能在给定数据和候选库的情况下，恢复最可能的模型结构。对于案例 1（$\\alpha=0$），我们期望恢复 $(c_1, c_2) \\approx (1, 0)$。对于案例 2（$\\alpha=0.4$），我们期望恢复 $(c_1, c_2) \\approx (1, 0.4)$。对于案例 3（零流场），所有特征和目标都恒为零，导致平凡解 $(0, 0)$。代码实现了这整个流程。",
            "answer": "```python\nimport numpy as np\n\ndef gradient_2d(f, dx, dy):\n    \"\"\"\n    Computes the gradient of a 2D field using second-order central differences\n    in the interior and first-order one-sided differences at the boundaries.\n    Assumes f[i, j] corresponds to f(x_i, y_j), where x is axis 0 and y is axis 1.\n    \"\"\"\n    N_x, N_y = f.shape\n    dfdx = np.zeros_like(f)\n    dfdy = np.zeros_like(f)\n\n    # Compute df/dx (derivative along axis 0)\n    dfdx[1:-1, :] = (f[2:, :] - f[:-2, :]) / (2 * dx)\n    dfdx[0, :] = (f[1, :] - f[0, :]) / dx\n    dfdx[-1, :] = (f[-1, :] - f[-2, :]) / dx\n\n    # Compute df/dy (derivative along axis 1)\n    dfdy[:, 1:-1] = (f[:, 2:] - f[:, :-2]) / (2 * dy)\n    dfdy[:, 0] = (f[:, 1] - f[:, 0]) / dy\n    dfdy[:, -1] = (f[:, -1] - f[:, -2]) / dy\n    \n    return dfdx, dfdy\n\ndef solve():\n    \"\"\"\n    Main function to run the sparse model discovery for each test case.\n    \"\"\"\n    np.random.seed(0) # for reproducibility\n\n    test_cases = [\n        {'N': 64, 'sigma': 0.01, 'alpha': 0.0, 'lambda': 0.05, 'flow_type': 'stream_func'},\n        {'N': 64, 'sigma': 0.02, 'alpha': 0.4, 'lambda': 0.05, 'flow_type': 'stream_func'},\n        {'N': 32, 'sigma': 0.0, 'alpha': 1.0, 'lambda': 0.01, 'flow_type': 'zero_flow'}\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        N = case['N']\n        sigma = case['sigma']\n        alpha = case['alpha']\n        lambda_thresh = case['lambda']\n        flow_type = case['flow_type']\n\n        # 1. Grid and Velocity Field Generation\n        dx = 1.0 / (N - 1)\n        dy = 1.0 / (N - 1)\n        x = np.linspace(0, 1, N)\n        y = np.linspace(0, 1, N)\n        # With indexing='ij', xx[i,j]=x[i] (axis 0) and yy[i,j]=y[j] (axis 1)\n        xx, yy = np.meshgrid(x, y, indexing='ij')\n\n        u, v = np.zeros((N, N)), np.zeros((N, N))\n        if flow_type == 'stream_func':\n            # u = d(psi)/dy = pi*sin(pi*x)*cos(pi*y)\n            # v = -d(psi)/dx = -pi*cos(pi*x)*sin(pi*y)\n            u = np.pi * np.sin(np.pi * xx) * np.cos(np.pi * yy)\n            v = -np.pi * np.cos(np.pi * xx) * np.sin(np.pi * yy)\n\n        u_noisy = u + np.random.normal(0, sigma, (N, N))\n        v_noisy = v + np.random.normal(0, sigma, (N, N))\n        \n        # 2. Feature Library Construction\n        # Note: gradient_2d returns (df/dx, df/dy)\n        du_dx, du_dy = gradient_2d(u_noisy, dx, dy)\n        dv_dx, dv_dy = gradient_2d(v_noisy, dx, dy)\n\n        # Feature 1: f_conv = -div(u dot grad(u))\n        ax = u_noisy * du_dx + v_noisy * du_dy\n        ay = u_noisy * dv_dx + v_noisy * dv_dy\n        dax_dx, _ = gradient_2d(ax, dx, dy)\n        _, day_dy = gradient_2d(ay, dx, dy)\n        f_conv = -(dax_dx + day_dy)\n        \n        # Feature 2: f_bnd\n        f_bnd = np.zeros((N, N))\n        \n        # Bottom wall (y=0, j=0), affects points at j=1. Grad is in y-dir.\n        grad_v_y_bottom = (v_noisy[:, 1] - v_noisy[:, 0]) / dy\n        f_bnd[:, 1] += grad_v_y_bottom\n        \n        # Top wall (y=1, j=N-1), affects points at j=N-2. Grad is in y-dir.\n        grad_v_y_top = (v_noisy[:, N - 1] - v_noisy[:, N - 2]) / dy\n        f_bnd[:, N - 2] += grad_v_y_top\n        \n        # Left wall (x=0, i=0), affects points at i=1. Grad is in x-dir.\n        grad_u_x_left = (u_noisy[1, :] - u_noisy[0, :]) / dx\n        f_bnd[1, :] += grad_u_x_left\n        \n        # Right wall (x=1, i=N-1), affects points at i=N-2. Grad is in x-dir.\n        grad_u_x_right = (u_noisy[N - 1, :] - u_noisy[N - 2, :]) / dx\n        f_bnd[N - 2, :] += grad_u_x_right\n        \n        # 3. Synthetic Target Field\n        z = f_conv + alpha * f_bnd\n\n        # 4. Sparse Regression (STLS)\n        z_vec = z.flatten()\n        f_conv_vec = f_conv.flatten()\n        f_bnd_vec = f_bnd.flatten()\n        \n        A = np.stack([f_conv_vec, f_bnd_vec], axis=1)\n        \n        # Step 1: Full least squares\n        if np.all(np.isclose(A, 0)): # Handle zero matrix for zero flow case\n            c_initial = np.array([0.0, 0.0])\n        else:\n            try:\n              c_initial, _, _, _ = np.linalg.lstsq(A, z_vec, rcond=None)\n            except np.linalg.LinAlgError:\n              c_initial = np.array([0.0, 0.0])\n\n        # Step 2: Thresholding\n        active_indices = [i for i, c in enumerate(c_initial) if abs(c) >= lambda_thresh]\n        \n        # Step 3: Refit\n        c_final = np.zeros(2)\n        if len(active_indices) > 0:\n            A_sparse = A[:, active_indices]\n            if A_sparse.size > 0 and not np.all(np.isclose(A_sparse, 0)):\n                try:\n                  c_sparse, _, _, _ = np.linalg.lstsq(A_sparse, z_vec, rcond=None)\n                except np.linalg.LinAlgError:\n                   c_sparse = np.zeros(len(active_indices))\n            else:\n                c_sparse = np.zeros(len(active_indices))\n\n            for i, idx in enumerate(active_indices):\n                c_final[idx] = c_sparse[i]\n        \n        final_results.append([c_final[0], c_final[1]])\n        \n    # Format and print the final output\n    result_strings = [f\"[{res[0]},{res[1]}]\" for res in final_results]\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在为流体动力学问题训练物理信息神经网络（PINN）时，一个关键挑战是不同物理项之间的“刚度”或不平衡问题，尤其是在粘性效应减弱时。本练习旨在通过一个简化的伯格斯方程模型，让您深入探究这一现象。您将通过编程计算残差和梯度范数随粘性系数的变化，从而量化并诊断可能导致训练失败的梯度病理问题 。",
            "id": "3352001",
            "problem": "要求您分析物理信息神经网络 (PINNs) 在求解一维粘性 Burgers 方程时的敏感性和潜在的训练失败。您的分析必须实现为一个完整、可运行的程序，该程序能为一个固定的参数化试探场计算残差大小和梯度范数，并随着粘度的降低预测由梯度病态引起的失败。其基本控制律是一维粘性 Burgers 方程，这是计算流体力学 (CFD) 中对流-扩散问题的一个典型模型，写作非线性平流和粘性扩散的平衡定律：$$u_{t} + u\\,u_{x} - \\nu\\,u_{xx} = 0,$$ 其中 $u=u(x,t)$，$x$ 是位置，$t$ 是时间，$\\nu$ 是运动粘度。您的数值计算将以无量纲方式进行，因此不需要物理单位。测试套件包含一组从适中到趋近于零的粘度值 $\\nu$。\n\n您的程序必须基于以下基本基础和定义进行。考虑一个固定的参数化试探场，它模拟一个具有线性输出层和固定基特征的小型神经网络，$$u(x,t;\\boldsymbol{\\theta}) = \\sum_{m=1}^{3}\\theta_{m}\\,\\phi_{m}(x,t),$$ 其中基函数为 $$\\phi_{1}(x,t)=\\sin(\\pi x)\\,e^{-t},\\quad \\phi_{2}(x,t)=\\sin(2\\pi x)\\,e^{-t},\\quad \\phi_{3}(x,t)=\\cos(\\pi x)\\,e^{-2t},$$ 且参数向量固定为 $$\\boldsymbol{\\theta}=\\begin{bmatrix}\\theta_{1}\\\\\\theta_{2}\\\\\\theta_{3}\\end{bmatrix}=\\begin{bmatrix}1.0\\\\-0.5\\\\0.75\\end{bmatrix}.$$ 根据导数的基本定义，计算 $u_{t}=\\sum_{m=1}^{3}\\theta_{m}\\,\\partial_{t}\\phi_{m}$，$u_{x}=\\sum_{m=1}^{3}\\theta_{m}\\,\\partial_{x}\\phi_{m}$，$u_{xx}=\\sum_{m=1}^{3}\\theta_{m}\\,\\partial_{xx}\\phi_{m}$, 并定义逐点的偏微分方程残差 $$\\mathcal{R}(x,t;\\nu,\\boldsymbol{\\theta}) = u_{t} + u\\,u_{x} - \\nu\\,u_{xx}.$$ 将矩形时空配置网格上的均方残差定义为 $$\\mathcal{L}(\\nu,\\boldsymbol{\\theta}) = \\frac{1}{N}\\sum_{i=1}^{N}\\mathcal{R}(x_{i},t_{i};\\nu,\\boldsymbol{\\theta})^{2},$$ 其中 $(x_{i},t_{i})$ 是配置点，$N$ 是总点数。根据链式法则，损失函数关于参数的梯度为 $$\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\nu,\\boldsymbol{\\theta}) = \\frac{2}{N}\\sum_{i=1}^{N}\\mathcal{R}(x_{i},t_{i};\\nu,\\boldsymbol{\\theta})\\,\\nabla_{\\boldsymbol{\\theta}}\\mathcal{R}(x_{i},t_{i};\\nu,\\boldsymbol{\\theta}).$$ 为了分析物理项之间的不平衡，将残差分解为 $\\mathcal{R}=\\mathcal{T}+\\mathcal{A}-\\mathcal{D}$, 其中 $\\mathcal{T}=u_{t}$, $\\mathcal{A}=u\\,u_{x}$, $\\mathcal{D}=\\nu\\,u_{xx}.$ 那么残差关于参数的雅可比矩阵可以精确分解为 $$\\nabla_{\\boldsymbol{\\theta}}\\mathcal{R} = \\underbrace{\\nabla_{\\boldsymbol{\\theta}}\\mathcal{T}}_{\\text{时间}} + \\underbrace{\\nabla_{\\boldsymbol{\\theta}}\\mathcal{A}}_{\\text{平流}} - \\underbrace{\\nabla_{\\boldsymbol{\\theta}}\\mathcal{D}}_{\\text{扩散}}.$$ 利用 $u$ 对 $\\boldsymbol{\\theta}$ 的线性关系，以及对 $\\mathcal{A}=u\\,u_{x}$ 的乘积法则，可得 $$\\nabla_{\\boldsymbol{\\theta}}\\mathcal{T}=\\begin{bmatrix}\\partial_{t}\\phi_{1}\\\\ \\partial_{t}\\phi_{2}\\\\ \\partial_{t}\\phi_{3}\\end{bmatrix},\\quad \\nabla_{\\boldsymbol{\\theta}}\\mathcal{A}=\\begin{bmatrix}\\phi_{1}\\,u_{x}+u\\,\\partial_{x}\\phi_{1}\\\\ \\phi_{2}\\,u_{x}+u\\,\\partial_{x}\\phi_{2}\\\\ \\phi_{3}\\,u_{x}+u\\,\\partial_{x}\\phi_{3}\\end{bmatrix},\\quad \\nabla_{\\boldsymbol{\\theta}}\\mathcal{D}=\\nu\\begin{bmatrix}\\partial_{xx}\\phi_{1}\\\\ \\partial_{xx}\\phi_{2}\\\\ \\partial_{xx}\\phi_{3}\\end{bmatrix}.$$ 因此，损失梯度可以加性地分解为三个分量，$\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}=\\mathbf{g}_{\\mathcal{T}}+\\mathbf{g}_{\\mathcal{A}}+\\mathbf{g}_{\\mathcal{D}}$, 其中 $\\mathbf{g}_{\\mathcal{X}}=\\frac{2}{N}\\sum_{i=1}^{N}\\mathcal{R}(x_{i},t_{i})\\,\\nabla_{\\boldsymbol{\\theta}}\\mathcal{X}(x_{i},t_{i}),$ 对于每个 $\\mathcal{X}\\in\\{\\mathcal{T},\\mathcal{A},-\\mathcal{D}\\}$，其中符号约定已被吸收到 $\\mathbf{g}_{\\mathcal{D}}$ 的定义中。\n\n您的任务是：\n- 使用上述定义，为每个给定的粘度 $\\nu$，在一个均匀网格（$x\\in[0,1]$, $t\\in[0,1]$, $N_{x}=64$, $N_{t}=64$, $N=N_{x}N_{t}$）上计算以下量：\n  - 均方根残差 $\\mathrm{RMS}(\\nu)=\\sqrt{\\mathcal{L}(\\nu,\\boldsymbol{\\theta})}.$\n  - 损失梯度分量的欧几里得范数 $\\|\\mathbf{g}_{\\mathcal{T}}\\|_{2}$、$\\|\\mathbf{g}_{\\mathcal{A}}\\|_{2}$ 和 $\\|\\mathbf{g}_{\\mathcal{D}}\\|_{2}$，以及平流-扩散梯度不平衡比 $\\rho(\\nu)=\\frac{\\|\\mathbf{g}_{\\mathcal{A}}\\|_{2}}{\\max\\{\\|\\mathbf{g}_{\\mathcal{D}}\\|_{2},\\varepsilon\\}},$ 其中 $\\varepsilon=10^{-16}$ 用于避免除以零。\n  - 残差雅可比矩阵 $\\mathbf{J}(\\nu)\\in\\mathbb{R}^{N\\times 3},\\quad \\mathbf{J}_{i,m}=\\left[\\nabla_{\\boldsymbol{\\theta}}\\mathcal{R}(x_{i},t_{i};\\nu,\\boldsymbol{\\theta})\\right]_{m},$ 的条件数，定义为 $\\kappa(\\mathbf{J})=\\frac{\\sigma_{\\max}(\\mathbf{J})}{\\sigma_{\\min}(\\mathbf{J})},$ 其中 $\\sigma_{\\max}$ 和 $\\sigma_{\\min}$ 分别是 $\\mathbf{J}$ 的最大和最小奇异值。\n- 如果满足以下任一条件，则预测 PINNs 因梯度病态而训练失败：$\\rho(\\nu)>\\kappa_{\\mathrm{th}} \\quad \\text{或} \\quad \\kappa(\\mathbf{J}(\\nu))>\\chi_{\\mathrm{th}},$ 其中阈值为 $\\kappa_{\\mathrm{th}}=10^{3}$ 和 $\\chi_{\\mathrm{th}}=10^{8}$。\n\n测试套件与输入：\n- 使用固定的参数向量 $\\boldsymbol{\\theta}=\\begin{bmatrix}1.0\\\\-0.5\\\\0.75\\end{bmatrix}$。\n- 使用粘度值 $\\nu\\in\\{1.0,\\,0.1,\\,0.01,\\,0.001,\\,0.0\\}$。\n\n要求的输出与格式：\n- 对于测试套件中的每个 $\\nu$，计算并收集列表 $[\\nu,\\ \\mathrm{RMS}(\\nu),\\ \\rho(\\nu),\\ f(\\nu)],$ 其中如果预测训练失败，则 $f(\\nu)$ 为 $1$，否则为 $0$。\n- 您的程序应生成单行输出，其中包含一个由这些列表组成的逗号分隔列表，无空格，每个浮点数格式化为六位有效数字，例如，$$[[1,0.123456,789.123,0],\\ldots].$$ 实际数字会有所不同；此格式是强制性的。",
            "solution": "本问题的目标是分析随着粘度参数 $\\nu$ 的减小，用于一维粘性 Burgers 方程的物理信息神经网络 (PINN) 训练过程的敏感性。该分析通过为一个模拟神经网络输出的、固定的、简化的试探解计算几个关键指标来执行。这些指标包括偏微分方程 (PDE) 残差的均方根 (RMS)、损失函数梯度的各个分量的范数，以及残差雅可比矩阵的条件数。这些量用于预测由梯度病态引起的潜在训练失败，特别是不同物理项（平流与扩散）之间的不平衡以及优化曲面的病态条件。\n\n该分析通过以下步骤进行：\n\n1.  **解析公式化**：我们从提供的解析定义开始。试探解 $u(x,t;\\boldsymbol{\\theta})$ 是三个预定义基函数 $\\phi_m(x,t)$ 的线性组合，其参数向量 $\\boldsymbol{\\theta}$ 是固定的。通过对求和项逐项求导，可以解析地计算出 $u$ 关于空间的一阶和二阶偏导数 $u_x$ 和 $u_{xx}$，以及关于时间的偏导数 $u_t$。这些解析表达式对于准确评估 PDE 残差及其梯度至关重要，而不会引入数值微分误差。\n\n2.  **网格离散化**：将连续时空域 $(x,t) \\in [0,1] \\times [0,1]$ 离散化为一个由 $N_x \\times N_t = 64 \\times 64 = 4096$ 个配置点组成的均匀网格。所有后续计算都在此网格上进行。使用 `NumPy` 中的向量化操作可以高效地同时在所有点上进行计算。\n\n3.  **残差和梯度计算**：对于测试套件中的每个粘度值 $\\nu$，我们在每个网格点上计算以下量：\n    -   试探解 $u$ 及其导数 $u_t$、$u_x$ 和 $u_{xx}$。\n    -   PDE 残差 $\\mathcal{R} = u_{t} + u\\,u_{x} - \\nu\\,u_{xx}$，它衡量试探解满足 Burgers 方程的程度。\n    -   残差关于参数 $\\boldsymbol{\\theta}$ 的梯度，称为残差雅可比 $\\nabla_{\\boldsymbol{\\theta}}\\mathcal{R}$。这些梯度被分解为来自时间项 ($\\mathcal{T}=u_t$)、平流项 ($\\mathcal{A}=u\\,u_x$) 和扩散项 ($\\mathcal{D}=\\nu\\,u_{xx}$) 的贡献。试探解在 $\\boldsymbol{\\theta}$ 上的线性特性极大地简化了这些梯度计算。例如，$\\nabla_{\\boldsymbol{\\theta}} u_t$ 就是基函数时间导数的向量 $[\\partial_t\\phi_1, \\partial_t\\phi_2, \\partial_t\\phi_3]^T$。非线性平流项的梯度使用乘积法则计算。\n\n4.  **指标计算**：使用上面计算的逐点量，我们将它们聚合成所需的全局指标：\n    -   **均方根残差, $\\mathrm{RMS}(\\nu)$**：这是所有配置点上残差平方均值的平方根，即 $\\sqrt{\\frac{1}{N}\\sum_i \\mathcal{R}_i^2}$。它为解的准确性提供了一个总体度量。\n    -   **损失梯度分量范数**：均方误差损失函数的梯度 $\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}$ 由三个向量 $\\mathbf{g}_{\\mathcal{T}}$、$\\mathbf{g}_{\\mathcal{A}}$ 和 $\\mathbf{g}_{\\mathcal{D}}$ 加性地组成，分别对应于时间项、平流项和扩散项。每个向量是通过对所有网格点上的残差 $\\mathcal{R}$ 与残差雅可比矩阵相应分量的乘积求和来计算的，即 $\\mathbf{g}_{\\mathcal{X}} \\propto \\sum_i \\mathcal{R}_i \\nabla_{\\boldsymbol{\\theta}}\\mathcal{X}_i$。然后我们计算这三个向量中每一个的欧几里得范数。\n    -   **平流-扩散不平衡比, $\\rho(\\nu)$**：这个比率 $\\lVert\\mathbf{g}_\\mathcal{A}\\rVert_2 / \\max(\\lVert\\mathbf{g}_\\mathcal{D}\\rVert_2, \\varepsilon)$ 量化了平流梯度分量相对于扩散梯度分量的大小。一个大的值表明训练动态由平流项主导，当粘度消失且问题变得由对流主导时，这可能会产生问题。\n    -   **条件数, $\\kappa(\\mathbf{J})$**：残差雅可比矩阵 $\\mathbf{J} \\in \\mathbb{R}^{N\\times 3}$ 是通过堆叠来自 $N$ 个配置点中每个点的梯度向量 $\\nabla_{\\boldsymbol{\\theta}}\\mathcal{R}$ 形成的。其条件数，即最大奇异值与最小奇异值之比，衡量了残差对参数变化的敏感性。高条件数表示一个病态问题，其中参数的微小变化可能导致残差的巨大变化，这通常会减慢或停滞基于梯度的优化。\n\n5.  **失败预测**：基于计算出的指标，如果不平衡比 $\\rho(\\nu)$ 超过阈值 $\\kappa_{\\mathrm{th}}=10^3$ 或条件数 $\\kappa(\\mathbf{J}(\\nu))$ 超过阈值 $\\chi_{\\mathrm{th}}=10^8$，则预测训练失败。这些条件表明潜在的优化问题是病态的，原因要么是严重的梯度不平衡，要么是病态条件，这两者都是 PINNs 在多尺度问题中常见的失败模式。\n\n该实现将这些步骤封装在一个单独的程序中，该程序遍历提供的粘度值列表，为每个值执行计算，并根据指定的输出格式格式化结果。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes sensitivity and predicts training failure for a PINN model of the\n    1D viscous Burgers equation for a range of viscosity values.\n    \"\"\"\n    \n    # Define problem constants and parameters from the problem statement.\n    THETA = np.array([1.0, -0.5, 0.75])\n    NU_VALUES = [1.0, 0.1, 0.01, 0.001, 0.0]\n    NX, NT = 64, 64\n    N = NX * NT\n    KAPPA_TH = 1e3\n    CHI_TH = 1e8\n    EPSILON = 1e-16\n\n    # Create the spatio-temporal grid.\n    x_coords = np.linspace(0, 1, NX)\n    t_coords = np.linspace(0, 1, NT)\n    X, T = np.meshgrid(x_coords, t_coords, indexing='ij')\n\n    # --- Pre-compute basis functions and their symbolic derivatives on the grid ---\n    pi = np.pi\n    \n    # phi_1(x,t) = sin(pi*x) * exp(-t)\n    phi1 = np.sin(pi * X) * np.exp(-T)\n    phi1_t = -phi1\n    phi1_x = pi * np.cos(pi * X) * np.exp(-T)\n    phi1_xx = -pi**2 * phi1\n    \n    # phi_2(x,t) = sin(2*pi*x) * exp(-t)\n    phi2 = np.sin(2 * pi * X) * np.exp(-T)\n    phi2_t = -phi2\n    phi2_x = 2 * pi * np.cos(2 * pi * X) * np.exp(-T)\n    phi2_xx = - (2 * pi)**2 * phi2\n\n    # phi_3(x,t) = cos(pi*x) * exp(-2t)\n    phi3 = np.cos(pi * X) * np.exp(-2 * T)\n    phi3_t = -2 * phi3\n    phi3_x = -pi * np.sin(pi * X) * np.exp(-2 * T)\n    phi3_xx = -pi**2 * phi3\n\n    # Store basis functions and their derivatives in arrays for efficient computation.\n    # Shape: (3, NX, NT) where 3 is the number of basis functions.\n    PHI = np.array([phi1, phi2, phi3])\n    PHI_t = np.array([phi1_t, phi2_t, phi3_t])\n    PHI_x = np.array([phi1_x, phi2_x, phi3_x])\n    PHI_xx = np.array([phi1_xx, phi2_xx, phi3_xx])\n\n    # --- Main calculation loop over viscosity values ---\n    results_list = []\n    \n    for nu in NU_VALUES:\n        # Calculate the trial solution u and its derivatives using Einstein summation.\n        # This computes the sum over the first axis (m=1,2,3).\n        u = np.einsum('i,ijk->jk', THETA, PHI)\n        u_t = np.einsum('i,ijk->jk', THETA, PHI_t)\n        u_x = np.einsum('i,ijk->jk', THETA, PHI_x)\n        u_xx = np.einsum('i,ijk->jk', THETA, PHI_xx)\n        \n        # Calculate components of the PDE residual.\n        term_T = u_t\n        term_A = u * u_x\n        term_D = nu * u_xx\n        \n        # Calculate the pointwise PDE residual R = u_t + u*u_x - nu*u_xx.\n        R = term_T + term_A - term_D\n        \n        # Task 1: Compute root-mean-square residual, RMS(nu).\n        rms_val = np.sqrt(np.mean(R**2))\n        \n        # --- Compute gradients with respect to parameters theta ---\n        \n        # Gradient of the temporal term, grad_theta(T). Shape: (NX, NT, 3)\n        grad_T_theta = np.moveaxis(PHI_t, 0, -1)\n        \n        # Gradient of the advection term, grad_theta(A).\n        # grad_A_theta_m = phi_m * u_x + u * phi_x_m\n        grad_A_theta = np.zeros((NX, NT, 3))\n        for m in range(3):\n            grad_A_theta[:, :, m] = PHI[m, :, :] * u_x + u * PHI_x[m, :, :]\n            \n        # Gradient of the diffusion term, grad_theta(D).\n        grad_D_theta = nu * np.moveaxis(PHI_xx, 0, -1)\n        \n        # --- Compute components of the loss gradient: g_T, g_A, g_D ---\n        # g_X = (2/N) * sum_{i,j} (R * grad_X_theta)\n        R_reshaped = R[:, :, np.newaxis] # Reshape for broadcasting\n        \n        g_T = (2 / N) * np.sum(R_reshaped * grad_T_theta, axis=(0, 1))\n        g_A = (2 / N) * np.sum(R_reshaped * grad_A_theta, axis=(0, 1))\n        # g_D is defined with a negative sign: based on grad_theta(-D)\n        g_D = (2 / N) * np.sum(R_reshaped * (-grad_D_theta), axis=(0, 1))\n        \n        # Task 2: Compute norms of gradient components and the imbalance ratio rho(nu).\n        norm_g_A = np.linalg.norm(g_A)\n        norm_g_D = np.linalg.norm(g_D)\n        \n        rho_val = norm_g_A / max(norm_g_D, EPSILON)\n        \n        # Task 3: Compute the condition number of the residual Jacobian matrix J.\n        # J combines gradients from all terms: J = grad_T + grad_A - grad_D\n        grad_R_theta = grad_T_theta + grad_A_theta - grad_D_theta\n        J_matrix = grad_R_theta.reshape((N, 3))\n        cond_J = np.linalg.cond(J_matrix)\n        \n        # Task 4: Predict training failure based on the given thresholds.\n        failure_predicted = 1 if (rho_val > KAPPA_TH) or (cond_J > CHI_TH) else 0\n        \n        results_list.append([nu, rms_val, rho_val, failure_predicted])\n        \n    # --- Format the output as a single-line string ---\n    formatted_results = []\n    for res in results_list:\n        nu_str = f\"{res[0]:.6g}\"\n        rms_str = f\"{res[1]:.6g}\"\n        rho_str = f\"{res[2]:.6g}\"\n        fail_str = str(res[3])\n        formatted_results.append(f\"[{nu_str},{rms_str},{rho_str},{fail_str}]\")\n        \n    final_output_string = f\"[{','.join(formatted_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "本练习将物理学原理应用于一个具有挑战性的逆问题：从外部流场数据中识别未知障碍物的形状。我们不再仅仅是拟合数据，而是利用物理控制方程（Brinkman惩罚的斯托克斯方程）来约束对障碍物形状的搜索空间。这项实践将演示如何将数值求解器与数据同化相结合，以发现物理系统的隐藏特征，这正是物理信息建模的强大能力所在 。",
            "id": "3352066",
            "problem": "考虑沿线段的一维、稳态、不可压缩流，该流由定义在闭区间 $[0,1]$ 上的标量速度场 $u(x)$ 表示。一个固体障碍物占据了一个未知的子区间 $\\Omega_s = [a,b] \\subset (0,1)$，我们用一个指示场 $\\chi(x)$ 来表示它，该指示场在 $\\Omega_s$ 内等于 $1$，在外部等于 $0$。使用浸入边界法中常用的 Brinkman 惩罚法，低雷诺数极限下的稳态动量平衡简化为\n$$\n-\\nu \\, \\frac{d^2 u}{dx^2} + \\alpha \\, \\chi(x) \\, u(x) = 0,\n$$\n附带 Dirichlet 边界条件\n$$\nu(0) = U_0, \\quad u(1) = U_1,\n$$\n其中 $\\nu > 0$ 是给定的（无量纲）运动粘度，$\\alpha \\gg 1$ 是一个大的惩罚参数，用于在 $\\chi = 1$ 的固体区域内强制实现 $u \\approx 0$。这个 Brinkman 惩罚模型是从 Navier–Stokes 方程的稳态 Stokes 极限与多孔介质项耦合推导出来的，并作为一种物理信息约束。\n\n给定（未知）障碍物外部点上的外部流场数据，这些数据是通过对一个已知的真实障碍物 $[a^\\star, b^\\star]$ 求解上述边值问题而人工生成的。您的任务是通过最小化一个物理信息损失函数来发现指示场 $\\chi(x)$ 的形状（参数化为单个区间 $[a,b]$）。该损失函数在比较预测流场值与数据的同时，强制固体区域的稀疏性。具体来说，对于任何候选区间 $[a,b]$，您必须：\n- 使用具有 $N$ 个节点的均匀网格，通过二阶中心有限差分离散法数值求解该边值问题。对拉普拉斯算子使用标准的三点模板，并在端点处精确施加 Dirichlet 边界条件。\n- 使用线性插值在给定的数据点（所有这些点都位于真实障碍物的流体区域内）处计算预测的 $u(x)$。\n- 最小化目标函数\n$$\n\\mathcal{J}(a,b) = \\frac{1}{M}\\sum_{j=1}^{M} \\left(u(x_j; a,b) - \\tilde{u}_j\\right)^2 \\;+\\; \\lambda \\, (b - a),\n$$\n其中 $x_j$ 是数据位置，$\\tilde{u}_j$ 是观测速度，$M$ 是数据点数量，$\\lambda > 0$ 是一个促进稀疏性的正则化权重，它鼓励固体区域更小。这在指示场 $\\chi$ 上编码了一种稀疏模型发现的偏好。\n\n为了数值稳定性和保持问题的自洽性，不要对 $a$ 和 $b$ 执行基于梯度的优化。而是对候选中心 $c \\in \\mathcal{C}$ 和半长度 $s \\in \\mathcal{S}$ 进行离散搜索，其中 $a=c-s$ 和 $b=c+s$，并且只接受满足 $0 < a < b < 1$ 的候选。对于每个有效的候选，求解离散化的物理模型并计算 $\\mathcal{J}(a,b)$；选择目标函数值最小的候选。这个过程是一种物理信息辨识，因为每个候选预测 $u(\\cdot; a,b)$ 都是通过求解控制方程得到的，因此偏微分方程的残差通过构造得到了控制。\n\n基本基础和离散化要求：\n- 从带有 Brinkman 惩罚的稳态 Stokes 极限开始，\n$$\n-\\nu \\, u''(x) + \\alpha \\, \\chi(x) \\, u(x) = 0,\\quad x\\in(0,1),\n$$\n附带 $u(0)=U_0$ 和 $u(1)=U_1$。\n- 使用 $N$ 个均匀间隔的网格点 $x_i = i h$进行离散化，其中 $h = 1/(N-1)$ 且 $i \\in \\{0,1,\\dots,N-1\\}$。对于内部索引 $i=1,\\dots,N-2$，使用\n$$\n-\\nu \\, \\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2} + \\alpha \\, \\chi_i \\, u_i = 0,\n$$\n其中如果 $x_i \\in [a,b]$，则 $\\chi_i = 1$，否则 $\\chi_i=0$。通过将已知的边界值移到右侧来引入边界条件。\n\n每个测试用例的数据生成协议：\n- 使用 $N_{\\text{true}} = 257$ 进行数据生成，使用 $N = 257$ 进行辨识，以避免“反问题作弊”式的简化，同时保持离散化的兼容性。\n- 使用 $\\nu = 0.01$，$\\alpha = 1000$， $U_0 = 1$， $U_1 = 0$。\n- 通过使用真实障碍物 $[a^\\star,b^\\star]$ 求解离散化问题来生成真实解 $u^\\star(x)$。\n- 在 $[0,1]$ 中选择 $M_{\\text{tot}} = 25$ 个等距候选点，并仅保留真实障碍物外部的点，即 $x_j \\in [0,a^\\star) \\cup (b^\\star,1]$，以获得 $M$ 个数据点。通过 $\\tilde{u}_j = u^\\star(x_j) + \\eta_j$ 形成观测数据，其中 $\\eta_j$ 是标准差为 $\\sigma = 0.001$ 的零均值噪声。\n- 使用线性插值来评估模型在 $x_j$ 处的预测值。\n\n搜索空间和正则化：\n- 使用中心 $c \\in \\mathcal{C} = \\{0.10, 0.12, 0.14, \\dots, 0.90\\}$ 和半长度 $s \\in \\mathcal{S} = \\{0.02, 0.03, 0.04, \\dots, 0.25\\}$。仅考虑满足 $0 < c - s < c + s < 1$ 的候选。\n- 使用 $\\lambda = 0.001$。\n\n测试套件：\n- 情况 1 (理想情况): $[a^\\star,b^\\star] = [0.40, 0.60]$。\n- 情况 2 (小障碍物): $[a^\\star,b^\\star] = [0.20, 0.25]$。\n- 情况 3 (靠近边界): $[a^\\star,b^\\star] = [0.80, 0.95]$。\n\n您的程序必须为每个测试用例实现上述数据生成和辨识过程（使用固定的随机种子以确保噪声的可复现性），并为每个用例返回辨识出的区间端点 $[\\hat{a}, \\hat{b}]$，四舍五入到三位小数。所有量都是无量纲的，因此不需要物理单位。最终输出格式必须是单行，包含一个由三个项目组成的逗号分隔列表，每个项目是一个双元素浮点数列表，对应于按给定顺序排列的各用例的 $[\\hat{a}, \\hat{b}]$。例如，“[ [0.400,0.600],[0.200,0.250],[0.800,0.950] ]”是一个有效的输出格式。您的程序应生成单行输出，其中包含以此精确样式用方括号括起来的、逗号分隔的结果列表，不得包含任何附加文本。",
            "solution": "该问题要求在一维、稳态、粘性流中辨识一个未知的固体障碍物。这是一个经典的反问题，我们将使用物理信息模型发现框架来解决。其核心思想是找到物理模型的参数——在本例中是障碍物的起点和终点 $[a,b]$——这些参数能够最好地解释一组稀疏、带噪声的观测数据，同时一个惩罚项会鼓励模型更简单或更“稀疏”。\n\n物理模型是一维 Brinkman 惩罚稳态 Stokes 方程，这是一种用于模拟含浸入边界流动的成熟公式。其控制方程是一个二阶常微分方程 (ODE)：\n$$\n-\\nu \\, \\frac{d^2 u}{dx^2} + \\alpha \\, \\chi(x) \\, u(x) = 0, \\quad x \\in (0,1)\n$$\n服从 Dirichlet 边界条件 $u(0) = U_0$ 和 $u(1) = U_1$。这里，$u(x)$ 是标量速度场，$\\nu$ 是运动粘度，$\\alpha$ 是一个大的惩罚参数。函数 $\\chi(x)$ 是固体障碍物的指示函数，定义为：如果 $x \\in [a,b]$，则 $\\chi(x) = 1$，否则 $\\chi(x) = 0$。项 $\\alpha \\chi(x) u(x)$ 充当一个“流动阻力”项，它迫使障碍物内的速度 $u(x)$ 接近于零，在 $\\alpha \\to \\infty$ 的极限下模拟无滑移条件。\n\n为了在计算上解决这个问题，我们首先使用一个包含 $N$ 个点的均匀网格来离散化域 $[0,1]$，这些点为 $x_i = i h$，其中 $i \\in \\{0, 1, \\dots, N-1\\}$，网格间距为 $h = 1/(N-1)$。我们将 $u(x_i)$ 的数值近似记为 $u_i$。二阶导数 $u''(x_i)$ 使用二阶中心有限差分模板进行近似：\n$$\n\\frac{d^2 u}{dx^2}\\bigg|_{x=x_i} \\approx \\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2}\n$$\n将此式代入每个内部网格点 $i \\in \\{1, 2, \\dots, N-2\\}$ 的控制 ODE，得到一个线性代数方程组：\n$$\n-\\nu \\left( \\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2} \\right) + \\alpha \\, \\chi_i \\, u_i = 0\n$$\n其中如果 $x_i \\in [a,b]$ 则 $\\chi_i = 1$，否则为 $0$。对一个一般的内部节点 $i$ 重新整理这些项，我们得到：\n$$\n-\\frac{\\nu}{h^2} u_{i-1} + \\left( \\frac{2\\nu}{h^2} + \\alpha \\chi_i \\right) u_i - \\frac{\\nu}{h^2} u_{i+1} = 0\n$$\n这个包含 $N-2$ 个方程的系统是针对 $N-2$ 个未知内部速度 $\\{u_1, u_2, \\dots, u_{N-2}\\}$ 的。边界值 $u_0 = U_0$ 和 $u_{N-1} = U_1$ 是已知的。我们通过修改第一个 ($i=1$) 和最后一个 ($i=N-2$) 内部节点的方程来引入它们：\n对于 $i=1$：\n$$\n\\left( \\frac{2\\nu}{h^2} + \\alpha \\chi_1 \\right) u_1 - \\frac{\\nu}{h^2} u_2 = \\frac{\\nu}{h^2} u_0 = \\frac{\\nu}{h^2} U_0\n$$\n对于 $i=N-2$：\n$$\n-\\frac{\\nu}{h^2} u_{N-3} + \\left( \\frac{2\\nu}{h^2} + \\alpha \\chi_{N-2} \\right) u_{N-2} = \\frac{\\nu}{h^2} u_{N-1} = \\frac{\\nu}{h^2} U_1\n$$\n这产生了一个形式为 $A\\mathbf{v} = \\mathbf{f}$ 的三对角线性系统，其中 $\\mathbf{v} = [u_1, u_2, \\dots, u_{N-2}]^T$ 是未知速度的向量。矩阵 $A$ 是三对角的且对角占优，这保证了存在唯一解，并且可以使用专门的算法非常高效地求出，例如 `scipy.linalg.solve_banded` 提供的算法。\n\n反问题在于找到能够最好地解释在位置 $\\{x_j\\}$ 处的一组带噪声的速度测量值 $\\{\\tilde{u}_j\\}$ 的障碍物参数 $[a,b]$。该辨识通过最小化一个物理信息目标函数 $\\mathcal{J}(a,b)$ 来执行：\n$$\n\\mathcal{J}(a,b) = \\frac{1}{M}\\sum_{j=1}^{M} \\left(u(x_j; a,b) - \\tilde{u}_j\\right)^2 \\;+\\; \\lambda \\, (b - a)\n$$\n第一项是数据保真项，即模型预测 $u(x_j; a,b)$ 与观测数据 $\\tilde{u}_j$ 之间的均方误差。对于每个候选区间 $[a,b]$，通过求解离散化的边值问题 (BVP) 来生成预测 $u(x; a,b)$，从而确保每个候选解都遵循底层物理规律。在非网格数据点处的 $u(x_j; a,b)$ 值是通过对数值解进行线性插值获得的。第二项 $\\lambda(b-a)$ 是一个正则化项，用于惩罚较大的障碍物。该项通过偏好较小的区间来促进“稀疏”解，这是模型发现中受 LASSO 回归等方法启发的一种常用技术。\n\n我们被指示不要使用基于梯度的优化，而是对一组离散的候选区间进行网格搜索。每个候选由其中心 $c$ 和半长度 $s$ 参数化，其中 $a=c-s$ 和 $b=c+s$。搜索空间为 $\\mathcal{C} = \\{0.10, 0.12, \\dots, 0.90\\}$ 和 $\\mathcal{S} = \\{0.02, 0.03, \\dots, 0.25\\}$。我们遍历所有满足约束 $0 < a < b < 1$ 的有效对 $(c,s)$，为每个对计算 $\\mathcal{J}(a,b)$，并选择使目标函数最小的对 $(\\hat{c}, \\hat{s})$。最终辨识出的障碍物是 $[\\hat{a}, \\hat{b}] = [\\hat{c}-\\hat{s}, \\hat{c}+\\hat{s}]$。\n\n每个测试用例的数据生成遵循一个固定的协议。首先，通过求解已知真实障碍物 $[a^\\star, b^\\star]$ 的边值问题来计算一个“真实”速度场 $u^\\star(x)$。然后，从一个均匀网格中选择 $M$ 个观测点，排除真实障碍物内部的点。通过在这些点上评估 $u^\\star$ 并添加少量零均值高斯噪声来创建合成数据 $\\tilde{u}_j$。这个过程真实地模拟了一个实验场景，其中测量是稀疏的、带噪声的，并且仅在可及的流体区域内可用。固定的随机种子确保了噪声的可复现性，从而保证了整个实验的可复现性。\n\n总体算法实现如下：\n1.  对于每个给定的 $[a^\\star, b^\\star]$ 的测试用例：\n    a.  根据指定的协议生成合成数据 $(\\{x_j\\}, \\{\\tilde{u}_j\\})$。\n    b.  将最小目标值初始化为无穷大。\n    c.  遍历所有候选中心 $c \\in \\mathcal{C}$ 和半长度 $s \\in \\mathcal{S}$。\n    d.  对于每对 $(c,s)$，形成候选区间 $[a,b]=[c-s, c+s]$ 并检查其是否有效（即 $0 < a < b < 1$）。\n    e.  如果有效，使用此 $[a,b]$ 求解离散化的偏微分方程，以获得预测的速度场 $u(x; a,b)$。\n    f.  对解进行线性插值，以找到数据点 $x_j$ 处的预测速度。\n    g.  计算目标函数 $\\mathcal{J}(a,b)$。\n    h.  如果计算出的 $\\mathcal{J}$ 低于当前的最小值，则更新最小值并将 $[a,b]$ 存储为找到的最佳区间。\n2.  搜索完成后，记录该测试用例的最佳区间 $[\\hat{a}, \\hat{b}]$。\n3.  最终输出是所有测试用例的已辨识区间的列表，并按要求格式化。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef solve():\n    \"\"\"\n    Solves the physics-informed model discovery problem for three test cases.\n    Identifies the location of an obstacle in a 1D flow by minimizing a\n    physics-informed objective function over a discrete search space.\n    \"\"\"\n\n    # Fixed parameters for all test cases\n    params = {\n        'N': 257,\n        'nu': 0.01,\n        'alpha': 1000.0,\n        'U0': 1.0,\n        'U1': 0.0,\n        'lambda_reg': 0.001,\n        'noise_std': 0.001,\n        'M_tot': 25,\n        'seed': 0,\n    }\n\n    # Test cases: each with a true obstacle [a_star, b_star]\n    test_cases = [\n        [0.40, 0.60],  # Case 1: Ideal case\n        [0.20, 0.25],  # Case 2: Small obstacle\n        [0.80, 0.95],  # Case 3: Near boundary\n    ]\n    \n    # Search space for candidate obstacles\n    centers_c = np.arange(0.10, 0.90 + 1e-9, 0.02)\n    half_lengths_s = np.arange(0.02, 0.25 + 1e-9, 0.01)\n\n    results = []\n\n    for a_star, b_star in test_cases:\n        # Step 1: Data Generation\n        \n        # Grid setup\n        x_grid = np.linspace(0, 1, params['N'])\n        \n        # Generate true solution\n        u_true = solve_bvp(a_star, b_star, x_grid, params)\n        \n        # Generate observation points\n        x_obs_candidates = np.linspace(0, 1, params['M_tot'])\n        data_x = []\n        for x_val in x_obs_candidates:\n            if not (a_star = x_val = b_star):\n                data_x.append(x_val)\n        data_x = np.array(data_x)\n        \n        # Get true velocity at observation points via interpolation\n        u_obs_true = np.interp(data_x, x_grid, u_true)\n        \n        # Add noise\n        rng = np.random.default_rng(params['seed'])\n        noise = rng.normal(0, params['noise_std'], size=u_obs_true.shape)\n        data_u_tilde = u_obs_true + noise\n\n        # Step 2: Identification via Grid Search\n        \n        min_J = float('inf')\n        best_ab = None\n\n        for c in centers_c:\n            for s in half_lengths_s:\n                a_cand = c - s\n                b_cand = c + s\n\n                # Check validity of the candidate interval\n                if not (0  a_cand  b_cand  1):\n                    continue\n\n                # Solve BVP for the candidate interval\n                u_pred = solve_bvp(a_cand, b_cand, x_grid, params)\n                \n                # Interpolate to get predictions at data points\n                u_pred_at_data = np.interp(data_x, x_grid, u_pred)\n                \n                # Calculate objective function J\n                mse = np.mean((u_pred_at_data - data_u_tilde)**2)\n                regularization = params['lambda_reg'] * (b_cand - a_cand)\n                J = mse + regularization\n                \n                # Update best candidate\n                if J  min_J:\n                    min_J = J\n                    best_ab = [a_cand, b_cand]\n\n        # Round results to three decimal places\n        if best_ab:\n            final_a = round(best_ab[0], 3)\n            final_b = round(best_ab[1], 3)\n            results.append([final_a, final_b])\n\n    # Final print statement in the exact required format.\n    # Format the list of lists into the required string representation.\n    print(str(results).replace(\" \", \"\"))\n\n\ndef solve_bvp(a, b, x_grid, params):\n    \"\"\"\n    Solves the 1D Brinkman-penalized BVP using finite differences.\n    -nu * u_xx + alpha * chi * u = 0\n    u(0) = U0, u(1) = U1\n    \"\"\"\n    N = params['N']\n    nu = params['nu']\n    alpha = params['alpha']\n    U0 = params['U0']\n    U1 = params['U1']\n    \n    h = 1.0 / (N - 1)\n    \n    # Indicator function on the grid\n    chi = np.zeros(N)\n    chi[(x_grid >= a)  (x_grid = b)] = 1.0\n    chi_int = chi[1:-1]\n    \n    # Construct the tridiagonal matrix A for the system Av = f\n    # The system is for the N-2 interior points.\n    \n    # Main diagonal\n    main_diag = (2.0 * nu / h**2) + (alpha * chi_int)\n    \n    # Off-diagonals\n    off_diag_val = -nu / h**2\n    upper_diag = np.full(N - 3, off_diag_val)\n    lower_diag = np.full(N - 3, off_diag_val)\n\n    # Scipy's solve_banded expects the matrix in a specific format\n    # (number of bands, length of main diagonal)\n    # Row 0: upper diagonal (padded with a 0 at the start)\n    # Row 1: main diagonal\n    # Row 2: lower diagonal (padded with a 0 at the end)\n    A_banded = np.zeros((3, N - 2))\n    A_banded[0, 1:] = upper_diag\n    A_banded[1, :] = main_diag\n    A_banded[2, :-1] = lower_diag\n    \n    # Construct the right-hand side vector f\n    f = np.zeros(N - 2)\n    f[0] = -off_diag_val * U0\n    f[-1] = -off_diag_val * U1\n\n    # Solve the linear system for interior points\n    u_int = solve_banded((1, 1), A_banded, f)\n    \n    # Combine with boundary conditions to form the full solution\n    u_full = np.concatenate(([U0], u_int, [U1]))\n    \n    return u_full\n\n\n# Execute the main function\nsolve()\n```"
        }
    ]
}