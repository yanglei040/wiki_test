{
    "hands_on_practices": [
        {
            "introduction": "在量化基因表达之前，我们首先必须确保所测量的转录本结构的准确性。这一点在转录本的*de novo*组装中尤为关键，因为在此过程中可能会产生嵌合体（chimera）等错误的组装产物。本练习将引导您基于RNA测序数据的两个基本特性——剪接点读段支持度和双端测序（paired-end）插入片段大小的一致性——来实现一个质量控制模型，以识别并标记潜在的无效转录本。这是一个将图论和测序原理应用于确保数据完整性的实践练习 。",
            "id": "3311781",
            "problem": "您将执行一项基于转录组学和表达谱分析的形式化任务：使用组装转录本的剪接图表示以及源自双端测序读段的约束，设计并实现一个嵌合体检测模型。您的程序必须为每个给定的转录本判定其是否应被标记为无效组装（例如，嵌合体）。该判定必须基于两个原则：剪接节点支持度和双端插入片段大小的一致性。\n\n基本根据和定义：\n- 剪接图是一个有向图，其节点代表外显子片段，其有向边代表允许的转换（连续的外显子连接或剪接）。一个组装的转录本表示为通过该图的一条有向路径。\n- 在RNA测序（RNA-seq）中，双端（PE）测序读段源自一个长度有限的单一互补脱氧核糖核酸（cDNA）片段。其插入片段大小（片段长度）的分布可以很好地用一个均值为 $\\mu$、标准差为 $\\sigma$ 的正态分布来近似。对于一个映射到转录本路径上的给定双端测序读段，其在该路径上推断出的片段长度必须与由区间 $\\left[\\mu - k\\sigma, \\mu + k\\sigma\\right]$ 定义的合理区域一致，其中 $k$ 是一个控制接受宽度的非负标量。此区间被视为闭区间（包含边界）。\n- 每个剪接节点边都有一个非负整数的读段支持数。如果路径上的某个剪接节点支持度不足，该路径应被标记为无效。\n\n模型假设和约束：\n- 设 $P = (v_0, v_1, \\dots, v_m)$ 为通过剪接图的转录本路径，其中每个 $v_i$ 是一个节点索引。设 $\\ell_{v_i}$ 表示节点 $v_i$ 的长度（单位为碱基对，bp）。转录本的坐标长度为 $L_T = \\sum_{i=0}^{m} \\ell_{v_i}$。\n- 一个读段对由 $(p_L, p_R, \\ell_L, \\ell_R)$ 给出，其中 $p_L$ 和 $p_R$ 是左、右读段沿着转录本路径坐标系（从路径的 5' 端，以 0 为起点测量）的起始坐标（单位为碱基对，bp），而 $\\ell_L, \\ell_R$ 是它们的读段长度（单位为碱基对，bp）。推断的片段长度为\n$$\nL_f = (p_R + \\ell_R) - p_L \\, .\n$$\n- 一个读段对在路径上被认为是位置有效的，当且仅当 $0 \\le p_L \\le L_T - \\ell_L$，$0 \\le p_R \\le L_T - \\ell_R$，且 $p_R \\ge p_L$。如果一个读段对位置无效，则计为不兼容。\n- 一个读段对是插入片段大小一致的，当且仅当 $L_f \\in \\left[\\mu - k\\sigma, \\mu + k\\sigma\\right]$。\n- 定义兼容比例 $f$ 如下。如果有 $N$ 个读段对，则 $f$ 是既位置有效又插入片段大小一致的读段对所占的比例。如果 $N = 0$，则定义 $f = 1$（即，在没有可用读段对的情况下，插入片段大小的约束被无意义地满足）。\n- 设 $\\tau$ 为最小所需剪接节点支持度。对于路径 $P$ 上的每条有向边 $(u \\to v)$，如果该边的类型是 “splice”，那么观测到的节点支持度 $c_{u,v}$ 必须满足 $c_{u,v} \\ge \\tau$。\n- 一个转录本路径 $P$ 被标记为无效组装，当且仅当以下任一条件成立：\n  - 在 $P$ 上存在至少一个剪接边 $(u \\to v)$，其 $c_{u,v}  \\tau$；或者\n  - 兼容比例 $f$ 严格小于用户指定的阈值 $\\alpha \\in [0,1]$。\n\n物理和数值单位：\n- 所有长度和位置必须以碱基对（bp）为单位。输出是无单位的布尔值。\n\n角度单位：不适用。\n\n您的任务：\n- 实现一个程序，对于下面指定的一组固定的参数化测试用例，为每个用例计算一个布尔决策，以指示是否应根据上述规则将该转录本标记为无效。\n\n每个用例的输入表示：\n- 外显子长度：一个列表 $[\\ell_0, \\ell_1, \\dots]$，单位为 bp。\n- 边：一个元组列表 $(u, v, \\text{type}, c)$，其中 $u, v$ 是节点索引，$\\text{type}$ 是集合 $\\{\\text{\"splice\"}, \\text{\"concat\"}\\}$ 中的一个字符串，而 $c$ 是节点支持数（一个整数；如果 $\\text{type} = \\text{\"concat\"}$ 则忽略）。\n- 转录本路径：一个节点索引列表 $[v_0, v_1, \\dots, v_m]$。\n- 读段：一个四元组列表 $(p_L, p_R, \\ell_L, \\ell_R)$，单位为 bp。\n- 分布参数和阈值：$\\mu$（bp）、$\\sigma$（bp）、$k$（无单位）、$\\tau$（读段数）和 $\\alpha$（无单位，以小数表示）。\n\n决策规则：\n- 对于每个用例，如果转录本被标记为无效，则输出 $\\text{True}$；否则输出 $\\text{False}$。\n\n测试套件：\n为以下五个案例提供解决方案。在每个案例中，所有长度和坐标均以 bp 为单位，节点索引从 0 开始。\n\n- 案例 1（正常路径：支持的剪接点和足够的兼容比例）：\n  - 外显子长度：$[100, 120, 80]$。\n  - 边：$(0,1,\\text{\"splice\"},20)$, $(1,2,\\text{\"splice\"},18)$。\n  - 转录本路径：$[0,1,2]$。\n  - 读段：$(10,185,75,75)$, $(50,220,75,75)$, $(60,220,75,75)$, $(200,130,75,75)$。\n  - 参数：$\\mu = 250$, $\\sigma = 30$, $k = 2$, $\\tau = 10$, $\\alpha = 0.75$。\n\n- 案例 2（不支持的剪接点导致无效，尽管插入片段良好）：\n  - 外显子长度：$[100, 120, 80]$。\n  - 边：$(0,1,\\text{\"splice\"},20)$, $(1,2,\\text{\"splice\"},5)$。\n  - 转录本路径：$[0,1,2]$。\n  - 读段：$(10,185,75,75)$, $(50,220,75,75)$, $(60,220,75,75)$, $(200,130,75,75)$。\n  - 参数：$\\mu = 250$, $\\sigma = 30$, $k = 2$, $\\tau = 10$, $\\alpha = 0.75$。\n\n- 案例 3（插入片段大小不一致导致兼容比例低于阈值）：\n  - 外显子长度：$[100, 100, 50]$。\n  - 边：$(0,1,\\text{\"splice\"},20)$, $(1,2,\\text{\"splice\"},22)$。\n  - 转录本路径：$[0,1,2]$。\n  - 读段：$(20,115,75,75)$, $(10,165,75,75)$, $(20,145,75,75)$。\n  - 参数：$\\mu = 200$, $\\sigma = 10$, $k = 2$, $\\tau = 10$, $\\alpha = 0.6$。\n\n- 案例 4（没有读段对；仅应用剪接点支持度规则）：\n  - 外显子长度：$[150, 150]$。\n  - 边：$(0,1,\\text{\"splice\"},12)$。\n  - 转录本路径：$[0,1]$。\n  - 读段：$\\,$空列表（即 $N = 0$）。\n  - 参数：$\\mu = 200$, $\\sigma = 30$, $k = 2$, $\\tau = 10$, $\\alpha = 0.5$。\n\n- 案例 5（位于边界 $\\mu \\pm k\\sigma$ 的插入片段大小被接受）：\n  - 外显子长度：$[90, 110, 120]$。\n  - 边：$(0,1,\\text{\"splice\"},15)$, $(1,2,\\text{\"splice\"},14)$。\n  - 转录本路径：$[0,1,2]$。\n  - 读段：$(10,135,75,75)$, $(5,230,75,75)$。\n  - 参数：$\\mu = 250$, $\\sigma = 25$, $k = 2$, $\\tau = 10$, $\\alpha = 1.0$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来，结果按上述案例的顺序排列。例如，如果五个布尔值是 $b_1$ 到 $b_5$，则打印单行字符串 $[b_1,b_2,b_3,b_4,b_5]$。",
            "solution": "所提出的问题要求设计并实现一个计算模型，用以验证来自RNA测序数据的组装转录本。一个转录本表示为通过剪接图的一条路径。验证过程基于源自测序数据性质的两个基本原则：剪接节点的可靠性和双端测序读段的物理约束。如果一个转录本未能满足这两个原则中任何一个的预定义标准，它就会被标记为无效组装。\n\n对给定转录本路径 $P$ 的验证过程是作为一个两步顺序检查来实现的。\n\n首先，算法评估沿转录本路径的剪接节点支持度。一个组装的转录本表示为节点路径 $P = (v_0, v_1, \\dots, v_m)$，其中每个节点 $v_i$ 对应一个外显子片段。该路径隐含了一系列有向边 $(v_i \\to v_{i+1})$，其中 $i \\in \\{0, 1, \\dots, m-1\\}$。剪接图中的每条边被分类为“concat”边（表示外显子区域的连续串联）或“splice”边（表示不连续外显子区域之间的剪接节点）。剪接节点是通过跨越该节点的读段推断出来的。这类读段的数量就是该节点的支持数，对于边 $(u \\to v)$ 表示为 $c_{u,v}$。如果一个转录本的任何组成剪接节点的支持读段数不足，则该转录本被认为是结构可疑的。设 $\\tau$ 为所需的最小支持数。对于路径 $P$ 中类型为“splice”的每条边 $(v_i \\to v_{i+1})$，我们必须验证其支持数 $c_{v_i, v_{i+1}}$ 满足条件：\n$$\nc_{v_i, v_{i+1}} \\ge \\tau\n$$\n如果路径上只要有一个剪接节点违反此条件，该转录本将立即被标记为无效，验证过程终止，并返回决策 $\\text{True}$。\n\n其次，如果路径上所有的剪接节点都得到充分支持，算法将继续验证双端测序读段比对的一致性。双端测序从单个DNA片段的两端生成读段对。这些片段的长度，即插入片段大小，通常遵循一个已知均值为 $\\mu$、标准差为 $\\sigma$ 的正态分布。该模型利用此特性来评估映射到转录本路径上的读段所推断的片段长度是否与该分布一致。\n\n转录本路径 $P$ 的总长度计算为其组成外显子长度 $\\ell_{v_i}$ 的总和：\n$$\nL_T = \\sum_{i=0}^{m} \\ell_{v_i}\n$$\n一个读段对由元组 $(p_L, p_R, \\ell_L, \\ell_R)$ 给出，其中 $p_L$ 和 $p_R$ 是左、右读段沿着转录本坐标系（从5'端，以0为起点）的起始坐标，$\\ell_L$ 和 $\\ell_R$ 是它们各自的长度。在检查插入片段大小一致性之前，一个读段对必须在转录本上位置有效。这要求每个读段完全映射在转录本的边界内，并且右读段的起始位置不早于左读段。位置有效的条件是：\n$0 \\le p_L \\le L_T - \\ell_L$，$0 \\le p_R \\le L_T - \\ell_R$，且 $p_R \\ge p_L$。\n任何未能通过此检查的读段对都被视为不兼容。\n\n对于一个位置有效的读段对，其推断的片段长度 $L_f$ 代表从左读段开始到右读段结束的基因组跨度，计算公式为：\n$$\nL_f = (p_R + \\ell_R) - p_L\n$$\n然后检查这个推断的长度是否与预期的插入片段大小分布一致。如果片段长度 $L_f$ 落在一个由非负标量 $k$ 定义的接受区间内，则认为它是一致的。这个区间是闭区间（包含边界）：\n$$\nL_f \\in \\left[\\mu - k\\sigma, \\mu + k\\sigma\\right]\n$$\n一个读段对被定义为“兼容的”，当且仅当它既是位置有效的，又是插入片段大小一致的。\n\n转录本的整体双端读段一致性由兼容比例 $f$ 来量化。这是兼容读段对的数量 $N_{\\text{compat}}$ 与映射到该转录本的总读段对数量 $N$ 的比值：\n$$\nf = \\frac{N_{\\text{compat}}}{N}\n$$\n根据定义，如果 $N=0$（即没有读段对与该转录本关联），则该约束被无意义地满足，我们设 $f=1$。如果这个兼容比例严格小于指定的阈值 $\\alpha \\in [0,1]$，则该转录本被标记为无效：\n$$\nf  \\alpha\n$$\n如果满足此条件，该转录本将被标记为无效，返回的决策是 $\\text{True}$。\n\n如果转录本路径同时通过了剪接节点支持度检查和兼容比例检查，则它被认为是有效的组装，返回的决策是 $\\text{False}$。",
            "answer": "```python\nimport numpy as np\n\ndef is_transcript_invalid(exon_lengths, edges, transcript_path, reads, mu, sigma, k, tau, alpha):\n    \"\"\"\n    Validates a transcript path based on splice junction support and paired-end read consistency.\n\n    Args:\n        exon_lengths (list[int]): Lengths of the exons (nodes).\n        edges (list[tuple]): Graph edges as (u, v, type, count).\n        transcript_path (list[int]): Node indices defining the transcript path.\n        reads (list[tuple]): Read pairs as (p_L, p_R, l_L, l_R).\n        mu (float): Mean of the insert size distribution.\n        sigma (float): Standard deviation of the insert size distribution.\n        k (float): Scalar for the acceptance interval width.\n        tau (int): Minimum required splice junction support.\n        alpha (float): Minimum required compatible fraction of reads.\n\n    Returns:\n        bool: True if the transcript is flagged as invalid, False otherwise.\n    \"\"\"\n    # Create a lookup map for edges for efficient access.\n    # The key is a tuple (u, v) of node indices.\n    # The value is a tuple (type, support_count).\n    edge_data = {(u, v): (etype, count) for u, v, etype, count in edges}\n\n    # -- Step 1: Check Splice Junction Support --\n    # Iterate through the pairs of adjacent nodes in the transcript path.\n    for i in range(len(transcript_path) - 1):\n        u, v = transcript_path[i], transcript_path[i+1]\n        \n        # This check assumes the path is valid within the graph definition.\n        # A robust implementation would handle KeyError here.\n        edge_type, support_count = edge_data[(u, v)]\n\n        if edge_type == \"splice\":\n            if support_count  tau:\n                # Invalidation condition 1 is met.\n                return True\n\n    # -- Step 2: Check Compatible Fraction of Paired-End Reads --\n    # Calculate total transcript length L_T\n    L_T = sum(exon_lengths[node_idx] for node_idx in transcript_path)\n\n    N = len(reads)\n    # Handle the case of no reads. The constraint is vacuously satisfied.\n    if N == 0:\n        f = 1.0\n    else:\n        compatible_count = 0\n        min_len = mu - k * sigma\n        max_len = mu + k * sigma\n\n        for p_L, p_R, l_L, l_R in reads:\n            # Check positional validity\n            is_pos_valid = (p_R >= p_L) and \\\n                           (0 = p_L = L_T - l_L) and \\\n                           (0 = p_R = L_T - l_R)\n\n            if not is_pos_valid:\n                continue\n\n            # Calculate implied fragment length\n            L_f = (p_R + l_R) - p_L\n\n            # Check insert-size consistency (inclusive interval)\n            is_insert_consistent = (min_len = L_f = max_len)\n\n            if is_insert_consistent:\n                compatible_count += 1\n        \n        f = compatible_count / N\n\n    # Check if the compatible fraction is below the threshold.\n    if f  alpha:\n        # Invalidation condition 2 is met.\n        return True\n\n    # If neither invalidation condition was met, the transcript is valid.\n    return False\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # Case 1 (happy path: supported junctions and sufficient compatible fraction)\n        {\n            \"exon_lengths\": [100, 120, 80],\n            \"edges\": [(0, 1, \"splice\", 20), (1, 2, \"splice\", 18)],\n            \"transcript_path\": [0, 1, 2],\n            \"reads\": [(10, 185, 75, 75), (50, 220, 75, 75), (60, 220, 75, 75), (200, 130, 75, 75)],\n            \"params\": {\"mu\": 250, \"sigma\": 30, \"k\": 2, \"tau\": 10, \"alpha\": 0.75}\n        },\n        # Case 2 (unsupported junction triggers invalidation)\n        {\n            \"exon_lengths\": [100, 120, 80],\n            \"edges\": [(0, 1, \"splice\", 20), (1, 2, \"splice\", 5)],\n            \"transcript_path\": [0, 1, 2],\n            \"reads\": [(10, 185, 75, 75), (50, 220, 75, 75), (60, 220, 75, 75), (200, 130, 75, 75)],\n            \"params\": {\"mu\": 250, \"sigma\": 30, \"k\": 2, \"tau\": 10, \"alpha\": 0.75}\n        },\n        # Case 3 (insert-size inconsistency lowers compatible fraction)\n        {\n            \"exon_lengths\": [100, 100, 50],\n            \"edges\": [(0, 1, \"splice\", 20), (1, 2, \"splice\", 22)],\n            \"transcript_path\": [0, 1, 2],\n            \"reads\": [(20, 115, 75, 75), (10, 165, 75, 75), (20, 145, 75, 75)],\n            \"params\": {\"mu\": 200, \"sigma\": 10, \"k\": 2, \"tau\": 10, \"alpha\": 0.6}\n        },\n        # Case 4 (no read pairs; only junction support applies)\n        {\n            \"exon_lengths\": [150, 150],\n            \"edges\": [(0, 1, \"splice\", 12)],\n            \"transcript_path\": [0, 1],\n            \"reads\": [],\n            \"params\": {\"mu\": 200, \"sigma\": 30, \"k\": 2, \"tau\": 10, \"alpha\": 0.5}\n        },\n        # Case 5 (boundary insert sizes are accepted)\n        {\n            \"exon_lengths\": [90, 110, 120],\n            \"edges\": [(0, 1, \"splice\", 15), (1, 2, \"splice\", 14)],\n            \"transcript_path\": [0, 1, 2],\n            \"reads\": [(10, 135, 75, 75), (5, 230, 75, 75)],\n            \"params\": {\"mu\": 250, \"sigma\": 25, \"k\": 2, \"tau\": 10, \"alpha\": 1.0}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = is_transcript_invalid(\n            case[\"exon_lengths\"],\n            case[\"edges\"],\n            case[\"transcript_path\"],\n            case[\"reads\"],\n            **case[\"params\"]\n        )\n        results.append(result)\n\n    # Format the results into the required string format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在获得了可靠的转录本计数之后，下一个挑战是如何使这些计数在不同样本之间具有可比性，以便进行差异表达分析。本练习旨在解决一个常见而微妙的偏差，即成分偏差（compositional bias），其中少数高表达基因的剧烈变化会系统性地扭曲所有其他基因的表观表达水平。您将亲手计算M值截尾均值（Trimmed Mean of M-values, TMM）归一化因子，从而从第一性原理层面深入理解为何简单的文库大小缩放方法会失效，以及像TMM这样更稳健的归一化策略是如何有效校正这些数据失真的 。",
            "id": "3311834",
            "problem": "一项基于测序的转录组分析实验获得了两个样本（表示为样本 $A$ 和样本 $B$）在 $10$ 个基因上的读数计数数据。假设其基础的测序过程可以建模为从信使核糖核酸 (mRNA) 分子群体中进行的多项式抽样：每个样本的观测计数是随机抽取的，其概率与真实的相对转录本丰度成正比，并按其总文库大小进行缩放。标准化的目的是通过消除测序深度和组分效应来恢复样本间的可比性，从而对于大多数真实丰度在样本间没有变化的基因，其标准化后的表达比率集中在 1 附近。\n\n已知该数据集表现出强烈的组分偏差：两个高丰度的核糖体基因在样本 $B$ 中显著上调，而其余基因的真实丰度没有变化。观测到的计数如下：\n\n- 样本 $A$ 的总文库大小为 $N_{A} = 1{,}000{,}000$，其计数为：\n  基因 $1$：$100{,}000$；基因 $2$：$80{,}000$；基因 $3$：$150{,}000$；基因 $4$：$130{,}000$；基因 $5$：$120{,}000$；基因 $6$：$100{,}000$；基因 $7$：$90{,}000$；基因 $8$：$70{,}000$；基因 $9$：$80{,}000$；基因 $10$：$80{,}000$。\n\n- 样本 $B$ 的总文库大小为 $N_{B} = 1{,}048{,}000$，其计数为：\n  基因 $1$：$400{,}000$；基因 $2$：$320{,}000$；基因 $3$：$60{,}000$；基因 $4$：$52{,}000$；基因 $5$：$48{,}000$；基因 $6$：$40{,}000$；基因 $7$：$36{,}000$；基因 $8$：$28{,}000$；基因 $9$：$32{,}000$；基因 $10$：$32{,}000$。\n\n使用 M 值的修剪均值 (TMM) 标准化方法 (Robinson and Oshlack)，计算样本 $B$ 相对于样本 $A$ 的标准化因子。对于此数据集，对保留的基因采用相等的权重，并通过排除两个具有最大绝对对数表达比率的基因（即基因 $1$ 和 $2$）来进行修剪。将 TMM 标准化因子报告为一个無單位的标量，并四舍五入到四位有效数字。\n\n此外，请基于读数生成的多项式抽样观点以及将大多数未变化基因的表达比率中心化在 1 的目标，从第一性原理出发，解释为什么仅基于 $\\frac{N_{A}}{N_{B}}$ 的简单文库大小缩放方法在这种组分偏差下会失效。\n\n将您的最终数值答案四舍五入到四位有效数字，并以無單位的因子的形式报告。",
            "solution": "首先将根据指定标准验证问题陈述。\n\n### 步骤 1：提取已知条件\n- 样本：样本 $A$，样本 $B$。\n- 基因数量：$10$。\n- 模型：从信使核糖核酸 (mRNA) 分子群体进行的多项式抽样。\n- 组分偏差：两个高丰度的核糖体基因（基因 $1$ 和基因 $2$）在样本 $B$ 中显著上调。其余基因的真实丰度没有变化。\n- 樣本 $A$ 數據：\n  - 总文库大小: $N_{A} = 1,000,000$。\n  - 基因计数 ($C_{gA}$):\n    - 基因 $1$: $100,000$\n    - 基因 $2$: $80,000$\n    - 基因 $3$: $150,000$\n    - 基因 $4$: $130,000$\n    - 基因 $5$: $120,000$\n    - 基因 $6$: $100,000$\n    - 基因 $7$: $90,000$\n    - 基因 $8$: $70,000$\n    - 基因 $9$: $80,000$\n    - 基因 $10$: $80,000$\n- 樣本 $B$ 數據：\n  - 总文库大小: $N_{B} = 1,048,000$。\n  - 基因计数 ($C_{gB}$):\n    - 基因 $1$: $400,000$\n    - 基因 $2$: $320,000$\n    - 基因 $3$: $60,000$\n    - 基因 $4$: $52,000$\n    - 基因 $5$: $48,000$\n    - 基因 $6$: $40,000$\n    - 基因 $7$: $36,000$\n    - 基因 $8$: $28,000$\n    - 基因 $9$: $32,000$\n    - 基因 $10$: $32,000$\n- 标准化方法：M 值的修剪均值 (TMM)。\n- TMM 参数：\n  - 参考样本：样本 $A$。\n  - 目标样本：样本 $B$。\n  - 权重：对保留的基因使用相等权重。\n  - 修剪：排除两个具有最大绝对对数表达比率的基因。\n- 要求输出：样本 $B$ 的 TMM 标准化因子（四舍五入到四位有效数字），以及对简单文库大小缩放方法失效的第一性原理的解释。\n\n### 步骤 2：使用提取的已知条件进行验证\n1.  **科学性：** 该问题牢固地植根于计算系统生物学，特别是转录组学数据 (RNA-seq) 的分析。多项式抽样模型是测序计数的标准理论框架。组分偏差是此类数据中一个有据可查的人为现象，而 TMM 标准化是解决该问题的广泛接受的方法。所提供的数据虽然是为了一个清晰的例子而设计的，但在数值上是一致的（计数总和等于文库大小），并代表了一个合理的、尽管有些夸张的生物学场景。该问题在科学上是合理的。\n2.  **良态问题：** 该问题提供了所有必要的数据，并定义了方法论 (TMM)、参考样本 ($A$)、修剪标准（按绝对 M 值最大的前 2 个基因）和加权方案（相等权重）。这些规范足以计算出唯一的标准化因子。\n3.  **客观性：** 该问题以精确、技术性的语言表述，没有主观性或个人观点。数据和任务都是据实陈述的。\n\n### 步骤 3：结论与行动\n该问题是有效的。将提供一个完整的、有理有据的解答。\n\n### 解答\n\n解答包括两部分：首先，计算 M 值的修剪均值 (TMM) 标准化因子；其次，解释为什么在给定条件下，简单的文库大小缩放是不合适的。\n\n#### 第 1 部分：计算 TMM 标准化因子\n\nTMM 方法旨在估计一个有效的文库大小缩放因子，该因子能解释组分偏差。该过程涉及计算对数倍数变化（$M$ 值）和平均丰度（$A$ 值），修剪在这些指标上处于极端的基因，然后计算剩余基因 $M$ 值的加权平均值以得出标准化因子。\n\n设 $C_{gi}$ 为样本 $i \\in \\{A, B\\}$ 中基因 $g$ 的观测读数计数，设 $N_i$ 为样本 $i$ 的总文库大小。样本 $i$ 中基因 $g$ 的标准化表达比例为 $P_{gi} = C_{gi} / N_i$。\n\n基因 $g$ 的 $M$ 值（对数比率）比较了样本 $B$ 相对于参考样本 $A$ 的表达：\n$$M_g = \\log_2\\left(\\frac{P_{gB}}{P_{gA}}\\right) = \\log_2\\left(\\frac{C_{gB}/N_B}{C_{gA}/N_A}\\right) = \\log_2\\left(\\frac{C_{gB}}{C_{gA}} \\cdot \\frac{N_A}{N_B}\\right)$$\n\n已知 $N_A = 1,000,000$ 和 $N_B = 1,048,000$。文库大小之比为 $\\frac{N_A}{N_B} = \\frac{1,000,000}{1,048,000} \\approx 0.9542$。\n\n我们来计算所有 $10$ 个基因的 $M$ 值。\n\n对于基因 $1$：$C_{1A} = 100,000$, $C_{1B} = 400,000$。计数比为 $\\frac{C_{1B}}{C_{1A}} = 4$。\n$$M_1 = \\log_2\\left(4 \\cdot \\frac{1,000,000}{1,048,000}\\right) \\approx \\log_2(3.8168) \\approx 1.932$$\n\n对于基因 $2$：$C_{2A} = 80,000$, $C_{2B} = 320,000$。计数比为 $\\frac{C_{2B}}{C_{2A}} = 4$。\n$$M_2 = \\log_2\\left(4 \\cdot \\frac{1,000,000}{1,048,000}\\right) \\approx \\log_2(3.8168) \\approx 1.932$$\n\n对于基因 $3$ 到 $10$，问题的构造使得计数比 $C_{gB}/C_{gA}$ 是一个常数。我们来验证基因 $3$：\n$C_{3A} = 150,000$, $C_{3B} = 60,000$。计数比为 $\\frac{C_{3B}}{C_{3A}} = \\frac{60,000}{150,000} = 0.4$。\n对于基因 $4$：$C_{4A} = 130,000$, $C_{4B} = 52,000$。计数比为 $\\frac{C_{4B}}{C_{4A}} = \\frac{52,000}{130,000} = 0.4$。\n这个模式对基因 $g \\in \\{3, 4, \\dots, 10\\}$ 都成立。对于这组基因，$M$ 值为：\n$$M_{g \\in \\{3..10\\}} = \\log_2\\left(0.4 \\cdot \\frac{1,000,000}{1,048,000}\\right) \\approx \\log_2(0.38168) \\approx -1.389$$\n\n问题要求修剪掉两个具有最大绝对 $M$ 值的基因。\n我们有 $|M_1| = |M_2| \\approx 1.932$ 和 $|M_{g \\in \\{3..10\\}}| \\approx 1.389$。\n显然，基因 $1$ 和 $2$ 具有最大的绝对 $M$ 值，因此被修剪掉。\n\n保留的基因集合为 $G' = \\{3, 4, 5, 6, 7, 8, 9, 10\\}$，其中 $|G'| = 8$。\n样本 $B$ 的 TMM 标准化因子，记为 $F_B$，由保留基因的 $M$ 值的加权平均值确定。问题指定使用相等权重，使得计算成为一个简单的算术平均：\n$$\\log_2(F_B) = \\frac{\\sum_{g \\in G'} M_g}{\\sum_{g \\in G'} 1} = \\frac{1}{|G'|} \\sum_{g \\in G'} M_g$$\n由于对于所有 $g \\in G'$，$M_g$ 是常数，所以平均值就是这个常数值：\n$$\\log_2(F_B) = \\log_2\\left(0.4 \\cdot \\frac{N_A}{N_B}\\right)$$\n对两边取以 2 为底的指数，得到标准化因子：\n$$F_B = 2^{\\log_2\\left(0.4 \\cdot \\frac{N_A}{N_B}\\right)} = 0.4 \\cdot \\frac{N_A}{N_B}$$\n代入给定的文库大小：\n$$F_B = 0.4 \\cdot \\frac{1,000,000}{1,048,000} = \\frac{400,000}{1,048,000} \\approx 0.381679389...$$\n四舍五入到四位有效数字，TMM 标准化因子为 $0.3817$。\n\n#### 第 2 部分：简单文库大小缩放方法的失效\n\n在存在组分偏差的情况下，简单文庫大小缩放方法的失效可以用 RNA 测序的多项式抽样模型从第一性原理来解释。\n\n1.  **真实分子丰度与比例：** 设 $\\mu_{gi}$ 为样本 $i \\in \\{A, B\\}$ 生物材料中基因 $g$ 的真实（未观测到的）mRNA 分子数。样本 $i$ 中的 mRNA 分子总数为 $T_i = \\sum_{g} \\mu_{gi}$。基因 $g$ 的真实相对丰度或比例为 $\\pi_{gi} = \\mu_{gi} / T_i$。\n\n2.  **多项式抽样：** 测序过程从这个分子群体中抽取 $N_i$ 个读数（文库大小）。因此，样本 $i$ 中基因 $g$ 的期望计数为 $E[C_{gi}] = N_i \\cdot \\pi_{gi} = N_i \\cdot (\\mu_{gi} / T_i)$。\n\n3.  **组分偏差的影响：** 问题陈述对于基因 $g \\in \\{3, ..., 10\\}$，它们的真实丰度没有改变，这意味着对于这大多数基因，$\\mu_{gA} = \\mu_{gB}$。然而，对于基因 $1$ 和 $2$，在样本 $B$ 中有显著上调，意味着 $\\mu_{1B} \\gg \\mu_{1A}$ 和 $\\mu_{2B} \\gg \\mu_{2A}$。少数高丰度转录本的这种大幅增加，极大地增加了样本 $B$相对于样本 $A$ 的总 mRNA 池的大小。即 $T_B = \\sum_g \\mu_{gB} > \\sum_g \\mu_{gA} = T_A$。\n\n4.  **比例的扭曲：** 对于任何非差异表达的基因 $g'$（其中 $\\mu_{g'A} = \\mu_{g'B}$），其在两个样本之间的真实比例之比为：\n    $$\\frac{\\pi_{g'B}}{\\pi_{g'A}} = \\frac{\\mu_{g'B}/T_B}{\\mu_{g'A}/T_A} = \\frac{\\mu_{g'A}/T_B}{\\mu_{g'A}/T_A} = \\frac{T_A}{T_B}$$\n    由于 $T_B > T_A$，这个比率小于 $1$。这就是组分偏差的本质：某些转录本的大量产生稀释了所有其他转录本的*比例*，即使是那些绝对分子计数未发生变化的转录本。\n\n5.  **简单缩放的失效：** 简单的文库大小缩放方法计算表达比率为 $\\frac{C_{gB}/N_B}{C_{gA}/N_A}$。其基本假设是，对于一个非差异表达的基因，这个比率应该为 $1$。然而，根据我们的模型，这个比率的期望值为：\n    $$\\frac{E[C_{gB}]/N_B}{E[C_{gA}]/N_A} = \\frac{(N_B \\cdot \\pi_{gB})/N_B}{(N_A \\cdot \\pi_{gA})/N_A} = \\frac{\\pi_{gB}}{\\pi_{gA}} = \\frac{T_A}{T_B}$$\n    由于组分的变化，$T_A/T_B  1$。在这个问题中，比率 $T_A/T_B$ 由 TMM 因子 $F_B \\approx 0.3817$ 估计。因此，简单的缩放方法会错误地报告大多数基因被下调了约 $0.3817$ 倍。该方法之所以失效，是因为它错误地假设测序文库大小 $N_i$ 是有效文庫大小的直接且充分的代表，而忽略了组分变化对从中抽样读数的基础比例 ($\\pi_{gi}$) 的深远影响。TMM 正确地估计并补偿了这种由总 RNA 池大小 ($T_i$) 变化引起的扭曲。",
            "answer": "$$\\boxed{0.3817}$$"
        },
        {
            "introduction": "最后，我们将目光投向单细胞转录组学带来的独特挑战。单细胞RNA测序（scRNA-seq）数据的一个显著特征是存在大量的零计数（zeros）。本练习将深入探讨这些计数的统计建模，并提出一个根本性的问题：这些零是主要由技术性脱落（technical dropouts）引起的（此时需要零膨胀模型），还是仅仅源于生物学上的低表达和有限的采样深度（此时标准的负二项分布模型可能就已足够）？这项高级练习要求您从泊松-伽马（Poisson-Gamma）混合模型出发，推导出负二项（Negative Binomial）分布，并构建一个统计检验来回答这个问题，从而帮助您深入掌握现代单细胞数据分析的理论基石 。",
            "id": "3311792",
            "problem": "给定使用单细胞转录组学中的唯一分子标识符 (UMI) 测序技术测量的、单个基因在多个细胞中的计数数据。您必须从第一性原理出发，判断这些 UMI 计数是否有必要使用零膨胀模型，或者一个能够捕捉细胞间异质性的负二项 (NB) 混合模型是否足够。该决策必须通过将观测到的零计数频率与一个从机理采样模型推导出的 NB 混合模型所预测的零频率进行比较来做出。\n\n使用的基础理论：\n- 分子生物学的中心法则描述了信息从 DNA 到 RNA 再到蛋白质的流动过程，在表达谱分析中，信使核糖核酸 (mRNA) 分子被取样和计数。\n- 在 UMI 测序中，定量是基于对捕获并去重的分子进行计数，这可以被建模为一个抽样过程。\n- 对于 UMI 计数，一个典型的假设是，在给定每个细胞的捕获效率的条件下，一个细胞中某个特定基因被捕获的分子数量是一个泊松过程的实现。\n- 真实的潜在表达水平在细胞间的异质性可以通过一个跨细胞的伽马分布来建模，从而得到计数的泊松-伽马混合，即一个负二项 (NB) 分布。\n- 多个细胞亚群的混合（每个亚群都有其自身的 NB 参数）在整个群体上产生一个 NB 混合分布。\n- 零膨胀负二项 (ZINB) 模型在 NB（或 NB 混合）模型预测的基础上，在零点额外增加了一个点质量。\n\n您的推导必须从泊松抽样假设和伽马异质性开始，并逻辑上推导出 NB 分布、NB 分布下零计数的概率，然后聚合成跨细胞亚群和可变文库大小的 NB 混合。您在本问题陈述中不得使用快捷公式；请在您的解决方案中进行推导。\n\n要实现的决策规则：\n- 考虑 $n$ 个细胞，索引为 $i \\in \\{1,\\dots,n\\}$。\n- 令 $s_i$ 表示细胞 $i$ 的规模因子（文库大小缩放），视为已知。\n- 假设有 $m$ 个潜在亚群，索引为 $j \\in \\{1,\\dots,m\\}$，其混合权重为 $w_j$（非负且总和为 1），每个亚群的 NB 参数由一个均值参数 $\\mu_j$ 和一个逆离散参数 $k_j$ 给出。\n- 在 NB 混合模型下，通过对混合成分进行积分，计算每个细胞 $i$ 的预测零概率，然后在所有细胞上取平均，得到一个全局预测零分数 $p_0$。\n- 令 $Z$ 为表示 $n$ 个细胞中零计数数量的随机变量。在 NB 混合模型下，将 $Z$ 视为一个参数为 $(n, p_0)$ 的二项随机变量，作为零数量的第一性原理近似。\n- 给定观测到的零数量 $z_{\\text{obs}}$，计算二项分布右尾概率 $\\mathbb{P}(Z \\ge z_{\\text{obs}})$，并与用户指定的显著性阈值 $\\alpha$ 进行比较。\n- 如果 $\\mathbb{P}(Z \\ge z_{\\text{obs}})  \\alpha$，则断定观测到的零数量超出了 NB 混合模型的预测，有必要使用零膨胀模型；否则，断定零膨胀模型没有必要。\n\n您的程序必须直接基于推导实现此决策规则，并为每个测试用例生成一个布尔决策。\n\n测试套件：\n对于每个测试用例，程序必须通过连接指定数量的零，后跟一个正整数的周期性模式，来构建一个长度为 $n = 100$ 的计数数组，直到数组达到长度 100。数组中的所有数字都是计数，并且是无量纲的整数。对于每种情况，混合参数 $(w_j, \\mu_j, k_j)$、规模因子 $\\{s_i\\}$、显著性水平 $\\alpha$ 以及计数的构建方式如下所述。\n\n- 案例 1 (理想情况：NB 混合模型足够):\n  - $n = 100$\n  - 混合权重: $w = [\\,0.4,\\,0.6\\,]$\n  - 均值: $\\mu = [\\,1.5,\\,5.0\\,]$\n  - 逆离散度: $k = [\\,2.0,\\,2.0\\,]$\n  - 规模因子: 对所有 $i$，$s_i = 1$ (即 $\\{s_i\\} = [\\,1, 1, \\dots, 1\\,]$，长度为 100)\n  - 计数构建: 放置 18 个零，然后将正数模式 $[\\,1,\\,2,\\,1,\\,3,\\,2,\\,4,\\,1,\\,5,\\,2,\\,3\\,]$ 重复八次，并追加 $[\\,4,\\,2\\,]$ 以达到 100 的长度。\n  - 显著性水平: $\\alpha = 0.01$\n\n- 案例 2 (零过多：需要零膨胀模型):\n  - $n = 100$\n  - 混合权重: $w = [\\,0.4,\\,0.6\\,]$\n  - 均值: $\\mu = [\\,1.5,\\,5.0\\,]$\n  - 逆离散度: $k = [\\,2.0,\\,2.0\\,]$\n  - 规模因子: 对所有 $i$，$s_i = 1$\n  - 计数构建: 放置 40 个零，然后将正数模式 $[\\,1,\\,2,\\,3,\\,2,\\,4,\\,3,\\,5,\\,2,\\,4,\\,3\\,]$ 重复六次以达到 100 的长度。\n  - 显著性水平: $\\alpha = 0.01$\n\n- 案例 3 (边界低表达：在 NB 模型下预期有许多零):\n  - $n = 100$\n  - 混合权重: $w = [\\,1.0\\,]$\n  - 均值: $\\mu = [\\,0.2\\,]$\n  - 逆离散度: $k = [\\,5.0\\,]$\n  - 规模因子: 对所有 $i$，$s_i = 1$\n  - 计数构建: 放置 82 个零，然后将正数模式 $[\\,1,\\,1,\\,2,\\,1,\\,1,\\,2,\\,1,\\,2,\\,1\\,]$ 重复两次以达到 100 的长度。\n  - 显著性水平: $\\alpha = 0.01$\n\n- 案例 4 (异构文库大小：带有可变 $s_i$ 的 NB 混合模型):\n  - $n = 100$\n  - 混合权重: $w = [\\,0.5,\\,0.5\\,]$\n  - 均值: $\\mu = [\\,2.0,\\,8.0\\,]$\n  - 逆离散度: $k = [\\,1.2,\\,3.0\\,]$\n  - 规模因子: 前 50 个细胞 $s_i = 1$，后 50 个细胞 $s_i = 0.5$，即 $\\{s_i\\} = [\\,\\underbrace{1, \\dots, 1}_{50}, \\underbrace{0.5, \\dots, 0.5}_{50}\\,]$\n  - 计数构建: 放置 22 个零，然后将正数模式 $[\\,1,\\,2,\\,3,\\,4,\\,5,\\,3,\\,4,\\,2,\\,6,\\,3,\\,2,\\,5,\\,4,\\,3,\\,7\\,]$ 重复五次，并追加 $[\\,4,\\,3,\\,2\\,]$ 以达到 100 的长度。\n  - 显著性水平: $\\alpha = 0.01$\n\n所需输出格式：\n- 您的程序应生成一行输出，其中包含四个案例的布尔决策，形式为方括号内以逗号分隔的列表，例如：$[\\,\\text{False},\\text{True},\\text{False},\\text{False}\\,]$。",
            "solution": "该问题要求基于第一性原理推导和统计检验，来判断单细胞 UMI 计数是否有必要使用零膨胀模型。该决策取决于将观测到的零计数频率与负二项 (NB) 混合模型预测的频率进行比较。\n\n推导从 UMI 测序的基本过程开始。对于单个细胞 $i$ 中的某个特定基因，让其 mRNA 的真实（未观测到的）相对丰度由一个率参数 $\\lambda_i$ 表示。捕获和测序这些分子的过程是一个离散抽样过程。假设存在足够多的分子，那么计数到的唯一分子（UMI）数量 $c_i$ 可以被建模为以此率为条件的泊松随机变量：\n$$c_i | \\lambda_i \\sim \\text{Poisson}(\\lambda_i)$$\n其概率质量函数 (PMF) 由下式给出：\n$$P(c_i=y | \\lambda_i) = \\frac{e^{-\\lambda_i} \\lambda_i^y}{y!} \\quad \\text{for } y \\in \\{0, 1, 2, \\dots\\}$$\n\n基因表达的细胞间变异性是单细胞数据的标志。这种生物异质性意味着率参数 $\\lambda_i$ 在细胞群体中并非恒定，其本身就是一个随机变量。一个常用且数学上方便的选择是使用伽马分布来建模这种变异性。设 $\\lambda$ 在一个同质细胞亚群中的分布为：\n$$\\lambda \\sim \\text{Gamma}(\\text{shape}=k, \\text{rate}=\\beta)$$\n其概率密度函数 (PDF) 为：\n$$f(\\lambda; k, \\beta) = \\frac{\\beta^k}{\\Gamma(k)} \\lambda^{k-1} e^{-\\beta \\lambda}$$\n其中，$\\Gamma(k)$ 是伽马函数。\n\n计数 $c$ 在整个细胞群体中的边际分布是通过对 $\\lambda$ 的分布积分条件泊松概率得到的：\n$$P(c=y) = \\int_0^\\infty P(c=y | \\lambda) f(\\lambda; k, \\beta) \\,d\\lambda$$\n$$P(c=y) = \\int_0^\\infty \\left( \\frac{e^{-\\lambda} \\lambda^y}{y!} \\right) \\left( \\frac{\\beta^k}{\\Gamma(k)} \\lambda^{k-1} e^{-\\beta \\lambda} \\right) \\,d\\lambda$$\n重新整理各项，我们得到：\n$$P(c=y) = \\frac{\\beta^k}{y! \\Gamma(k)} \\int_0^\\infty \\lambda^{y+k-1} e^{-(\\beta+1)\\lambda} \\,d\\lambda$$\n该积分是形状参数为 $y+k$、率参数为 $\\beta+1$ 的伽马分布的核。该积分的值为 $\\frac{\\Gamma(y+k)}{(\\beta+1)^{y+k}}$。将其代回可得：\n$$P(c=y) = \\frac{\\beta^k}{y! \\Gamma(k)} \\frac{\\Gamma(y+k)}{(\\beta+1)^{y+k}} = \\frac{\\Gamma(y+k)}{y! \\Gamma(k)} \\left(\\frac{\\beta}{\\beta+1}\\right)^k \\left(\\frac{1}{\\beta+1}\\right)^y$$\n这是负二项 (NB) 分布的 PMF。这证明了泊松-伽马混合等价于 NB 分布。\n\n问题使用均值参数 $\\mu$ 和逆离散参数 $k$ 来指定 NB 分布。我们必须将这些参数与伽马分布的参数联系起来。NB 分布的均值是其底层伽马分布的均值：\n$$E[c] = \\mu = E[\\lambda] = \\frac{k}{\\beta} \\implies \\beta = \\frac{k}{\\mu}$$\nNB 分布的方差为 $\\text{Var}(c) = \\mu + \\frac{\\mu^2}{k}$。这种参数化将伽马分布的形状参数确定为逆离散参数 $k$。\n\n现在我们可以推导在该 NB 模型下观测到零计数 ($y=0$) 的概率。使用已推导的 PMF：\n$$P(c=0) = \\frac{\\Gamma(0+k)}{0! \\Gamma(k)} \\left(\\frac{\\beta}{\\beta+1}\\right)^k \\left(\\frac{1}{\\beta+1}\\right)^0 = \\left(\\frac{\\beta}{\\beta+1}\\right)^k$$\n代入 $\\beta = k/\\mu$：\n$$P(c=0) = \\left(\\frac{k/\\mu}{k/\\mu + 1}\\right)^k = \\left(\\frac{k/\\mu}{(k+\\mu)/\\mu}\\right)^k = \\left(\\frac{k}{k+\\mu}\\right)^k$$\n\n单细胞实验通常每个细胞具有不同的文库大小（测序深度）。这可以通过一个细胞特异性的规模因子 $s_i$ 来解释，该因子用于缩放均值。因此，细胞 $i$ 的有效均值为 $s_i \\mu$。假设细胞 $i$ 来自一个参数为 $(\\mu, k)$ 的群体，其零计数的概率因此为：\n$$P(c_i=0 | \\mu, k, s_i) = \\left(\\frac{k}{k+s_i\\mu}\\right)^k$$\n\n总细胞群体可能是 $m$ 个不同亚群的混合，每个亚群都有自己的参数 $(\\mu_j, k_j)$ 和在总群体中的比例 $w_j$（其中 $\\sum_{j=1}^m w_j = 1$）。对于一个随机选择的细胞 $i$，其零计数的预测概率是它可能所属的所有亚群的加权平均：\n$$p_{0,i} = P(c_i=0) = \\sum_{j=1}^m w_j P(c_i=0 | \\mu_j, k_j, s_i) = \\sum_{j=1}^m w_j \\left(\\frac{k_j}{k_j+s_i\\mu_j}\\right)^{k_j}$$\n\n为了得到包含 $n$ 个细胞的整个数据集的单一预测零频率，我们对各个概率求平均值：\n$$p_0 = \\frac{1}{n} \\sum_{i=1}^n p_{0,i}$$\n\n最后，决策规则基于一个统计检验。原假设是观测到的零数量 $z_{\\text{obs}}$ 与 NB 混合模型一致。我们将 $n$ 个细胞中的总零计数数量 $Z$ 建模为一个二项随机变量，其平均成功（零计数）概率为 $p_0$：\n$$Z \\sim \\text{Binomial}(n, p_0)$$\n这是一个近似，其中每个细胞不同的概率 $p_{0,i}$ 被它们的平均值所替代。我们通过计算在该原假设下观测到至少 $z_{\\text{obs}}$ 个零的概率来计算 p 值：\n$$\\mathbb{P}(Z \\ge z_{\\text{obs}}) = \\sum_{y=z_{\\text{obs}}}^n \\binom{n}{y} p_0^y (1-p_0)^{n-y}$$\n如果这个右尾概率小于指定的显著性水平 $\\alpha$，即 $\\mathbb{P}(Z \\ge z_{\\text{obs}})  \\alpha$，我们就拒绝原假设。这意味着观测到的零数量显著多于 NB 混合模型的预测，因此有必要使用零膨胀模型。否则，认为 NB 混合模型是足够的。\n\n这个从泊松抽样过程到最终统计检验的逐步推导，为所实现的程序提供了逻辑基础。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import binom\n\ndef solve():\n    \"\"\"\n    Validates if a zero-inflated model is warranted for UMI counts by comparing observed\n    zero counts to those predicted by a Negative Binomial (NB) mixture model.\n    \"\"\"\n\n    # Test suite definition as specified in the problem statement.\n    test_cases = [\n        {\n            \"n\": 100, \"z_obs\": 18, \"alpha\": 0.01,\n            \"mixture_weights\": np.array([0.4, 0.6]),\n            \"means\": np.array([1.5, 5.0]),\n            \"inv_dispersions\": np.array([2.0, 2.0]),\n            \"size_factors\": np.ones(100)\n        },\n        {\n            \"n\": 100, \"z_obs\": 40, \"alpha\": 0.01,\n            \"mixture_weights\": np.array([0.4, 0.6]),\n            \"means\": np.array([1.5, 5.0]),\n            \"inv_dispersions\": np.array([2.0, 2.0]),\n            \"size_factors\": np.ones(100)\n        },\n        {\n            \"n\": 100, \"z_obs\": 82, \"alpha\": 0.01,\n            \"mixture_weights\": np.array([1.0]),\n            \"means\": np.array([0.2]),\n            \"inv_dispersions\": np.array([5.0]),\n            \"size_factors\": np.ones(100)\n        },\n        {\n            \"n\": 100, \"z_obs\": 22, \"alpha\": 0.01,\n            \"mixture_weights\": np.array([0.5, 0.5]),\n            \"means\": np.array([2.0, 8.0]),\n            \"inv_dispersions\": np.array([1.2, 3.0]),\n            \"size_factors\": np.concatenate([np.ones(50), np.full(50, 0.5)])\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        n = case[\"n\"]\n        z_obs = case[\"z_obs\"]\n        alpha = case[\"alpha\"]\n        w = case[\"mixture_weights\"]\n        mu = case[\"means\"]\n        k = case[\"inv_dispersions\"]\n        s = case[\"size_factors\"]\n\n        # Vectorized calculation of predicted zero probabilities\n        # s has shape (n,), mu and k have shape (m,)\n        # Broadcasting s[:, np.newaxis] with mu[np.newaxis, :] creates an (n, m) matrix\n        # of scaled means for each cell and each mixture component.\n        scaled_means = s[:, np.newaxis] * mu[np.newaxis, :]\n\n        # Calculate the probability of zero for each cell under each mixture component.\n        # This results in an (n, m) matrix.\n        # The formula derived is P(c=0) = (k / (k + s*mu))^k\n        component_zero_probs = (k / (k + scaled_means)) ** k\n\n        # Calculate the per-cell zero probability by taking the weighted average\n        # over the mixture components. This results in a vector of shape (n,).\n        per_cell_zero_probs = np.sum(w * component_zero_probs, axis=1)\n\n        # Calculate the global average zero probability p0, as specified.\n        p_zero_predicted = np.mean(per_cell_zero_probs)\n\n        # Calculate the right-tail probability (p-value) under the Binomial model.\n        # P(Z >= z_obs) where Z ~ Binomial(n, p_zero_predicted)\n        # Using survival function sf(k) = P(X > k), so sf(k-1) = P(X >= k)\n        p_value = binom.sf(z_obs - 1, n, p_zero_predicted)\n        \n        # Make the decision based on the significance level alpha.\n        # True means zero-inflation is warranted.\n        decision = p_value  alpha\n        results.append(decision)\n\n    # Format the final output as a comma-separated list of booleans in brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}