{
    "hands_on_practices": [
        {
            "introduction": "贝叶斯分析的一个关键输出是后验分布，它概括了我们关于参数的所有知识。然而，在实际应用中，我们常常需要一个单一的点估计值。本练习将探讨如何通过将后验分布与损失函数相结合来推导这样的估计值，揭示了像均值、中位数和众数这类常用估计量，在不同“好”估计的评判标准下，分别是何种意义上的最优选择。",
            "id": "3340172",
            "problem": "在计算系统生物学的一次单细胞信号传导实验中，每个细胞根据特定通路的转录活跃性被分为活跃或不活跃两类，从而对细胞 $i$ 产生一个二元观察值 $x_{i} \\in \\{0,1\\}$。假设在给定未知激活概率 $\\theta \\in (0,1)$ 的条件下，$x_{1},\\dots,x_{n}$ 是条件独立同分布的，其抽样模型为 $x_{i} \\mid \\theta \\sim \\mathrm{Bernoulli}(\\theta)$。关于 $\\theta$ 的先验信念由一个贝塔分布建模，其密度与 $\\theta^{\\alpha_{0}-1} (1-\\theta)^{\\beta_{0}-1}$ 成正比，其中超参数 $\\alpha_{0} > 0$ 和 $\\beta_{0} > 0$。\n\n仅使用伯努利似然、贝塔先验、用于后验的贝叶斯定理，以及贝叶斯估计量是最小化后验期望损失 $\\mathbb{E}[L(\\theta,a)\\,|\\,x_{1:n}]$ 的行动 $a$ 的定义，完成以下任务：\n\n1.  从第一性原理推导在以下每种损失函数下 $\\theta$ 的贝叶斯估计量 $\\delta^{\\star}(x_{1:n})$：\n    -   平方损失 $L_{2}(\\theta,a) = (\\theta - a)^{2}$。\n    -   绝对损失 $L_{1}(\\theta,a) = |\\theta - a|$。\n    -   零一损失 $L_{01}(\\theta,a) = \\mathbf{1}\\{|\\theta - a| > 0\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 表示指示函数。您的推导必须证明为使零一损失对连续参数有良好定义所需的任何极限或近似论证。\n\n2.  现在特化到均匀先验的情况，即 $\\alpha_{0} = 1$ 和 $\\beta_{0} = 1$，实验数据包含 $n = 3$ 个细胞，观察到 $s = 0$ 个活跃细胞。使用贝叶斯定理求出后验参数 $(\\alpha,\\beta)$，然后计算您在第1部分中为此后验分布推导出的三个贝叶斯估计量的值。\n\n将您的最终答案以单行矩阵的形式给出，矩阵各项的顺序为：平方损失估计量、绝对损失估计量、零一损失估计量。不要四舍五入；请提供精确值。",
            "solution": "该问题要求推导未知参数 $\\theta$ 的三个贝叶斯估计量，并随后为一特定数据集和先验计算它们的值。该过程包括两部分：一个从第一性原理出发的一般性推导和一个具体应用。\n\n首先，我们建立贝叶斯框架。数据 $x_{1}, \\dots, x_{n}$ 是来自参数为 $\\theta$ 的伯努利分布的条件独立同分布样本，即 $x_i|\\theta \\sim \\mathrm{Bernoulli}(\\theta)$。整个数据集 $x_{1:n} = (x_1, \\dots, x_n)$ 的似然函数由各个概率的乘积给出：\n$$P(x_{1:n} | \\theta) = \\prod_{i=1}^{n} P(x_i | \\theta) = \\prod_{i=1}^{n} \\theta^{x_i} (1-\\theta)^{1-x_i} = \\theta^{\\sum x_i} (1-\\theta)^{n - \\sum x_i}$$\n设 $s = \\sum_{i=1}^{n} x_i$ 为成功（活跃细胞）的总数。则似然函数为 $L(\\theta; s, n) = \\theta^s (1-\\theta)^{n-s}$。\n\n关于 $\\theta$ 的先验信念由贝塔分布 $\\theta \\sim \\mathrm{Beta}(\\alpha_0, \\beta_0)$ 建模，其概率密度函数（PDF）为：\n$$p(\\theta) = \\frac{\\theta^{\\alpha_0-1}(1-\\theta)^{\\beta_0-1}}{B(\\alpha_0, \\beta_0)}$$\n其中 $B(\\alpha_0, \\beta_0)$ 是贝塔函数，作为归一化常数。\n\n根据贝叶斯定理，给定数据 $x_{1:n}$ 时 $\\theta$ 的后验分布与似然函数和先验分布的乘积成正比：\n$$p(\\theta|x_{1:n}) \\propto P(x_{1:n}|\\theta) p(\\theta) \\propto \\left( \\theta^s (1-\\theta)^{n-s} \\right) \\left( \\theta^{\\alpha_0-1}(1-\\theta)^{\\beta_0-1} \\right)$$\n$$p(\\theta|x_{1:n}) \\propto \\theta^{s+\\alpha_0-1} (1-\\theta)^{n-s+\\beta_0-1}$$\n这是一个贝塔分布的核，因此后验分布也是一个贝塔分布：\n$$\\theta | x_{1:n} \\sim \\mathrm{Beta}(\\alpha_0+s, \\beta_0+n-s)$$\n我们将后验参数表示为 $\\alpha = \\alpha_0+s$ 和 $\\beta = \\beta_0+n-s$。\n\n$\\theta$ 的贝叶斯估计量 $\\delta^{\\star}(x_{1:n})$ 是一个行动 $a$，它最小化后验期望损失 $\\mathbb{E}[L(\\theta,a)\\,|\\,x_{1:n}]$。\n$$\\delta^{\\star}(x_{1:n}) = \\arg\\min_{a} \\mathbb{E}[L(\\theta,a)\\,|\\,x_{1:n}] = \\arg\\min_{a} \\int_{0}^{1} L(\\theta,a) p(\\theta|x_{1:n}) d\\theta$$\n\n**第1部分：贝叶斯估计量的推导**\n\n我们为三种指定的损失函数分别推导估计量。\n\n1.  **平方损失：$L_{2}(\\theta, a) = (\\theta - a)^{2}$**\n    后验期望损失为 $R(a) = \\mathbb{E}[(\\theta-a)^2 | x_{1:n}] = \\int_0^1 (\\theta-a)^2 p(\\theta|x_{1:n}) d\\theta$。\n    为了找到最小化 $R(a)$ 的 $a$ 值，我们对 $a$ 求导并令其为零。\n    $$\\frac{d R(a)}{da} = \\frac{d}{da} \\int_0^1 (\\theta^2 - 2a\\theta + a^2) p(\\theta|x_{1:n}) d\\theta$$\n    使用莱布尼茨积分法则在积分号下求导：\n    $$\\frac{d R(a)}{da} = \\int_0^1 \\frac{\\partial}{\\partial a} (\\theta-a)^2 p(\\theta|x_{1:n}) d\\theta = \\int_0^1 -2(\\theta-a) p(\\theta|x_{1:n}) d\\theta$$\n    令导数为零：\n    $$-2 \\int_0^1 (\\theta-a) p(\\theta|x_{1:n}) d\\theta = 0$$\n    $$\\int_0^1 \\theta p(\\theta|x_{1:n}) d\\theta - \\int_0^1 a p(\\theta|x_{1:n}) d\\theta = 0$$\n    $$a \\int_0^1 p(\\theta|x_{1:n}) d\\theta = \\int_0^1 \\theta p(\\theta|x_{1:n}) d\\theta$$\n    由于 $p(\\theta|x_{1:n})$ 是一个概率密度函数，$\\int_0^1 p(\\theta|x_{1:n}) d\\theta = 1$。于是：\n    $$a = \\int_0^1 \\theta p(\\theta|x_{1:n}) d\\theta = \\mathbb{E}[\\theta | x_{1:n}]$$\n    二阶导数为 $\\frac{d^2 R(a)}{da^2} = \\int_0^1 2 p(\\theta|x_{1:n}) d\\theta = 2 > 0$，确认这是一个最小值。\n    因此，平方损失下的贝叶斯估计量是后验均值。\n    $\\delta_{L_2}^{\\star}(x_{1:n}) = \\mathbb{E}[\\theta | x_{1:n}]$。\n\n2.  **绝对损失：$L_{1}(\\theta, a) = |\\theta - a|$**\n    后验期望损失为 $R(a) = \\mathbb{E}[|\\theta-a| | x_{1:n}] = \\int_0^1 |\\theta-a| p(\\theta|x_{1:n}) d\\theta$。\n    我们可以在 $a$ 处分割积分：\n    $$R(a) = \\int_0^a (a-\\theta) p(\\theta|x_{1:n}) d\\theta + \\int_a^1 (\\theta-a) p(\\theta|x_{1:n}) d\\theta$$\n    我们使用莱布尼茨法则对 $a$ 求导：\n    $$\\frac{d R(a)}{da} = \\left( (a-a)p(a|x_{1:n}) + \\int_0^a 1 \\cdot p(\\theta|x_{1:n}) d\\theta \\right) - \\left( (a-a)p(a|x_{1:n}) - \\int_a^1 1 \\cdot p(\\theta|x_{1:n}) d\\theta \\right)$$\n    $$\\frac{d R(a)}{da} = \\int_0^a p(\\theta|x_{1:n}) d\\theta - \\int_a^1 p(\\theta|x_{1:n}) d\\theta = P(\\theta \\le a | x_{1:n}) - P(\\theta > a | x_{1:n})$$\n    令导数为零可得：\n    $$P(\\theta \\le a | x_{1:n}) = P(\\theta > a | x_{1:n})$$\n    当概率质量在 $a$ 的两侧均等分配时，此等式成立。这是后验分布中位数的定义。设 $m$ 为后验中位数。那么 $P(\\theta \\le m | x_{1:n}) = 1/2$。\n    因此，绝对损失下的贝叶斯估计量是后验中位数。\n    $\\delta_{L_1}^{\\star}(x_{1:n}) = \\text{median}(\\theta | x_{1:n})$。\n\n3.  **零一损失：$L_{01}(\\theta, a) = \\mathbf{1}\\{|\\theta - a| > 0\\}$**\n    对于连续参数 $\\theta$，所述的损失函数会导致困难，因为对于任何 $a$，都有 $P(\\theta=a|x_{1:n})=0$。期望损失将是 $\\mathbb{E}[\\mathbf{1}\\{\\theta \\neq a\\}|x_{1:n}] = P(\\theta \\neq a|x_{1:n}) = 1$ 对所有 $a$ 成立，这是没有用的。\n    按照指示，我们必须使用一个极限论证。考虑一个修正的损失函数 $L_{\\epsilon}(\\theta, a) = \\mathbf{1}\\{|\\theta - a| > \\epsilon\\}$，对于某个小的 $\\epsilon > 0$。我们希望最小化后验期望损失：\n    $$R(a) = \\mathbb{E}[L_{\\epsilon}(\\theta, a) | x_{1:n}] = \\int_0^1 \\mathbf{1}\\{|\\theta - a| > \\epsilon\\} p(\\theta|x_{1:n}) d\\theta = P(|\\theta - a| > \\epsilon | x_{1:n})$$\n    最小化 $P(|\\theta - a| > \\epsilon | x_{1:n})$ 等价于最大化其补集 $P(|\\theta - a| \\le \\epsilon | x_{1:n})$。\n    $$P(|\\theta - a| \\le \\epsilon | x_{1:n}) = P(a-\\epsilon \\le \\theta \\le a+\\epsilon | x_{1:n}) = \\int_{a-\\epsilon}^{a+\\epsilon} p(\\theta|x_{1:n}) d\\theta$$\n    对于一个小的 $\\epsilon$，并假设 $p(\\theta|x_{1:n})$ 在 $a$ 处是连续的，该积分可以用一个高为 $p(a|x_{1:n})$ 宽为 $2\\epsilon$ 的矩形面积来近似：\n    $$\\int_{a-\\epsilon}^{a+\\epsilon} p(\\theta|x_{1:n}) d\\theta \\approx p(a|x_{1:n}) \\cdot (2\\epsilon)$$\n    为了最大化这个近似概率，我们必须选择 $a$ 为最大化后验密度函数 $p(\\theta|x_{1:n})$ 的值。根据定义，这个值是后验分布的众数。这个论证在 $\\epsilon \\to 0$ 的极限下成立。\n    因此，对于连续参数，零一损失下的贝叶斯估计量是后验众数。\n    $\\delta_{L_{01}}^{\\star}(x_{1:n}) = \\arg\\max_{\\theta} p(\\theta|x_{1:n})$。\n\n**第2部分：具体案例的应用**\n\n我们给定一个均匀先验，对应于 $\\alpha_0 = 1$ 和 $\\beta_0 = 1$。数据包含 $n=3$ 个细胞，其中有 $s=0$ 个活跃细胞。\n\n使用前面推导的后验参数公式：\n- $\\alpha = s + \\alpha_0 = 0 + 1 = 1$\n- $\\beta = n - s + \\beta_0 = 3 - 0 + 1 = 4$\n\n后验分布为 $\\theta | x_{1:n} \\sim \\mathrm{Beta}(1, 4)$。\n后验概率密度函数为 $p(\\theta|x_{1:n}) = \\frac{\\theta^{1-1}(1-\\theta)^{4-1}}{B(1,4)} = \\frac{(1-\\theta)^3}{B(1,4)}$。\n贝塔函数的值为 $B(1,4) = \\frac{\\Gamma(1)\\Gamma(4)}{\\Gamma(1+4)} = \\frac{0! \\cdot 3!}{4!} = \\frac{1 \\cdot 6}{24} = \\frac{1}{4}$。\n所以，$p(\\theta|x_{1:n}) = 4(1-\\theta)^3$ 对于 $\\theta \\in (0,1)$。\n\n现在我们为这个 $\\mathrm{Beta}(1, 4)$ 后验分布计算三个估计量。\n\n1.  **平方损失估计量（后验均值）：**\n    对于 $\\mathrm{Beta}(\\alpha, \\beta)$ 分布，均值为 $\\frac{\\alpha}{\\alpha+\\beta}$。\n    $$\\delta_{L_2}^{\\star} = \\frac{1}{1+4} = \\frac{1}{5}$$\n\n2.  **绝对损失估计量（后验中位数）：**\n    我们需要找到值 $m$ 使得 $\\int_0^m p(\\theta|x_{1:n}) d\\theta = \\frac{1}{2}$。\n    $$\\int_0^m 4(1-\\theta)^3 d\\theta = 4 \\left[ -\\frac{(1-\\theta)^4}{4} \\right]_0^m = - \\left[ (1-\\theta)^4 \\right]_0^m$$\n    $$= -((1-m)^4 - (1-0)^4) = 1 - (1-m)^4$$\n    令此式等于 $\\frac{1}{2}$：\n    $$1 - (1-m)^4 = \\frac{1}{2}$$\n    $$(1-m)^4 = \\frac{1}{2}$$\n    由于 $m \\in(0,1)$，$1-m$ 必须为正。取正四次方根：\n    $$1-m = \\left(\\frac{1}{2}\\right)^{1/4}$$\n    $$\\delta_{L_1}^{\\star} = m = 1 - \\left(\\frac{1}{2}\\right)^{1/4}$$\n\n3.  **零一损失估计量（后验众数）：**\n    我们需要找到使 $p(\\theta|x_{1:n}) = 4(1-\\theta)^3$ 在 $\\theta \\in (0,1)$ 上最大化的 $\\theta$ 值。\n    密度函数关于 $\\theta$ 的导数为 $\\frac{d}{d\\theta} 4(1-\\theta)^3 = -12(1-\\theta)^2$。\n    对于 $\\theta \\in (0,1)$，该导数恒为负，这意味着函数 $p(\\theta|x_{1:n})$ 在其支撑集上是严格递减的。因此，最大值在区间的左边界处取得，即在 $\\theta = 0$ 处。\n    （注：对于 $\\alpha, \\beta > 1$ 的 $\\mathrm{Beta}(\\alpha, \\beta)$ 分布，众数的一般公式是 $\\frac{\\alpha-1}{\\alpha+\\beta-2}$。对于 $\\alpha=1, \\beta>1$ 的情况，众数在 $0$ 处。）\n    $$\\delta_{L_{01}}^{\\star} = 0$$\n\n对于给定案例，三个估计量分别为 $\\frac{1}{5}$，$1 - (\\frac{1}{2})^{1/4}$，和 $0$。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{1}{5}  1 - \\left(\\frac{1}{2}\\right)^{\\frac{1}{4}}  0 \\end{pmatrix} } $$"
        },
        {
            "introduction": "在现实世界的建模中，先验分布的选择是至关重要的一步，它会影响我们的结论，尤其是在数据有限的情况下。本练习提供了一个动手实践，比较了在为转录速率建模时，计算上方便的共轭（伽马）先验与更灵活的非共轭（对数正态）先验。你将使用数值方法来研究后验推断对先验分布特性的敏感度，这是任何应用贝叶斯建模者都需具备的关键技能。",
            "id": "3340205",
            "problem": "在计算系统生物学中，来自同质细胞群体的信使RNA在固定时间窗口内的转录计数，可以被建模为服从泊松过程的独立同分布。设每个细胞的转录速率由 $\\lambda$ 表示，单位为“转录本/分钟”，观测到的计数被建模为 $y_i \\mid \\lambda \\sim \\mathrm{Poisson}(\\lambda)$，其中 $i \\in \\{1,\\dots,N\\}$，$N$ 是样本大小，$y_i \\in \\{0,1,2,\\dots\\}$。任务是比较 $\\lambda$ 的共轭先验与非共轭先验在小样本情况下如何影响后验分布，重点关注对先验尾部行为的敏感性。\n\n分析基于 Bayes 定理，该定理指出后验密度与似然和先验的乘积成正比，即 $p(\\lambda \\mid \\mathbf{y}) \\propto p(\\mathbf{y} \\mid \\lambda)\\,p(\\lambda)$，其中 $\\mathbf{y} = (y_1,\\dots,y_N)$ 且 $p(\\mathbf{y} \\mid \\lambda)$ 是泊松似然的乘积。考虑两种先验：\n- 共轭先验：$\\lambda \\sim \\mathrm{Gamma}(a,b)$，由形状参数 $a>0$ 和速率参数 $b>0$ 参数化。\n- 非共轭先验：$\\log \\lambda \\sim \\mathcal{N}(\\mu,\\sigma^2)$，即 $\\lambda$ 服从参数为 $\\mu \\in \\mathbb{R}$ 和 $\\sigma > 0$ 的对数正态分布。\n\n从第一性原理出发，推导共轭先验的后验分布，以及非共轭先验下后验期望的可计算表达式。然后，为小样本情况定义并计算以下敏感性指标：\n- 对于对数正态先验，当对数尺度标准差在“轻尾”选择 $\\sigma_{\\mathrm{light}}$ 和“重尾”选择 $\\sigma_{\\mathrm{heavy}}$ 之间变化时，后验均值的绝对差。此过程中，通过 $\\mu = \\log(m_0) - \\sigma^2/2$ 相应调整 $\\mu$ 以将先验均值固定在 $m_0$。将此差值记为 $\\Delta_{\\mathrm{logN}} = \\left|\\mathbb{E}[\\lambda \\mid \\mathbf{y}, \\sigma_{\\mathrm{heavy}}] - \\mathbb{E}[\\lambda \\mid \\mathbf{y}, \\sigma_{\\mathrm{light}}]\\right|$。\n- 对于Gamma先验，当形状参数在“轻尾”选择 $a_{\\mathrm{light}}$ 和“重尾”选择 $a_{\\mathrm{heavy}}$ 之间变化时，后验均值的绝对差。此过程中，通过设置 $b = a/m_0$ 以将先验均值固定在 $m_0$。将此差值记为 $\\Delta_{\\mathrm{Gamma}} = \\left|\\mathbb{E}[\\lambda \\mid \\mathbf{y}, a_{\\mathrm{heavy}}] - \\mathbb{E}[\\lambda \\mid \\mathbf{y}, a_{\\mathrm{light}}]\\right|$。\n- 比率 $R = \\Delta_{\\mathrm{logN}} / \\Delta_{\\mathrm{Gamma}}$ 作为相对敏感性的无量纲度量。\n\n所有关于 $\\lambda$ 的后验均值和差异必须以“转录本/分钟”为单位表示。比率 $R$ 是无量纲的。此问题不涉及角度。\n\n实现一个程序，该程序在给定以下测试套件的情况下，为每个测试用例计算 $\\Delta_{\\mathrm{logN}}$、$\\Delta_{\\mathrm{Gamma}}$ 和 $R$ 作为浮点数。对于从 Bayes 定理推导出的非共轭后验期望，使用数值稳定的积分方法。最终输出必须是单行，包含一个列表的列表，其中每个内部列表对应一个测试用例，形式为 $[\\Delta_{\\mathrm{logN}}, \\Delta_{\\mathrm{Gamma}}, R]$。\n\n测试套件（每个用例指定 $\\mathbf{y}$, $m_0$, $\\sigma_{\\mathrm{light}}$, $\\sigma_{\\mathrm{heavy}}$, $a_{\\mathrm{light}}$, $a_{\\mathrm{heavy}}$）：\n1. 用例 1：$N=2$, $\\mathbf{y}=[0,1]$, $m_0=1.0$, $\\sigma_{\\mathrm{light}}=0.25$, $\\sigma_{\\mathrm{heavy}}=1.0$, $a_{\\mathrm{light}}=50.0$, $a_{\\mathrm{heavy}}=1.0$。\n2. 用例 2：$N=5$, $\\mathbf{y}=[0,0,1,0,2]$, $m_0=0.5$, $\\sigma_{\\mathrm{light}}=0.2$, $\\sigma_{\\mathrm{heavy}}=1.2$, $a_{\\mathrm{light}}=40.0$, $a_{\\mathrm{heavy}}=0.5$。\n3. 用例 3：$N=1$, $\\mathbf{y}=[5]$, $m_0=4.0$, $\\sigma_{\\mathrm{light}}=0.3$, $\\sigma_{\\mathrm{heavy}}=0.9$, $a_{\\mathrm{light}}=20.0$, $a_{\\mathrm{heavy}}=1.0$。\n4. 用例 4：$N=3$, $\\mathbf{y}=[0,0,0]$, $m_0=0.2$, $\\sigma_{\\mathrm{light}}=0.3$, $\\sigma_{\\mathrm{heavy}}=1.5$, $a_{\\mathrm{light}}=50.0$, $a_{\\mathrm{heavy}}=0.3$。\n5. 用例 5：$N=2$, $\\mathbf{y}=[50,60]$, $m_0=40.0$, $\\sigma_{\\mathrm{light}}=0.5$, $\\sigma_{\\mathrm{heavy}}=1.0$, $a_{\\mathrm{light}}=30.0$, $a_{\\mathrm{heavy}}=1.0$。\n\n对于每个用例，令 $S=\\sum_{i=1}^{N} y_i$ 表示总计数。您的程序应生成单行输出，其中包含结果，格式为逗号分隔的列表的列表，无空格，并用方括号括起来，例如 `[[x_1,y_1,z_1],[x_2,y_2,z_2],\\dots]`，其中 $x_i$、$y_i$ 和 $z_i$ 是用例 $i$ 的三个浮点数，单位如上所述。",
            "solution": "该问题要求对mRNA转录计数的泊松模型进行贝叶斯分析。我们必须比较转录速率 $\\lambda$ 的后验均值对先验分布选择的敏感性。具体来说，我们比较共轭Gamma先验和非共轭对数正态先验，重点关注在小样本情况下每种先验的尾部行为如何影响后验分布。\n\n分析分两个主要步骤进行。首先，我们推导在两种先验情景下 $\\lambda$ 后验均值的解析形式或可计算形式。其次，我们以数值方式实现这些计算，以便为给定的测试套件计算指定的敏感性指标。\n\n设观测数据为 $\\mathbf{y} = (y_1, \\dots, y_N)$，其中每个 $y_i \\in \\{0, 1, 2, \\dots\\}$ 是从速率为 $\\lambda$ 的泊松分布中独立抽取的值。\n$$y_i \\mid \\lambda \\sim \\mathrm{Poisson}(\\lambda)$$\n整个数据集 $\\mathbf{y}$ 的似然是各个泊松概率质量函数的乘积：\n$$p(\\mathbf{y} \\mid \\lambda) = \\prod_{i=1}^N \\frac{\\lambda^{y_i} e^{-\\lambda}}{y_i!} = \\frac{\\lambda^{\\sum y_i} e^{-N\\lambda}}{\\prod y_i!}$$\n对于贝叶斯推断，我们关心的是作为参数 $\\lambda$ 的函数的似然。我们可以忽略不依赖于 $\\lambda$ 的项。设 $S = \\sum_{i=1}^N y_i$ 为计数总和。那么似然正比于：\n$$p(\\mathbf{y} \\mid \\lambda) \\propto \\lambda^S e^{-N\\lambda}$$\n根据 Bayes 定理，$\\lambda$ 的后验分布为 $p(\\lambda \\mid \\mathbf{y}) \\propto p(\\mathbf{y} \\mid \\lambda) p(\\lambda)$，其中 $p(\\lambda)$ 是 $\\lambda$ 的先验分布。\n\n### 共轭先验分析：Gamma-泊松模型\n\n泊松似然的共轭先验是Gamma分布。设 $\\lambda$ 的先验为：\n$$\\lambda \\sim \\mathrm{Gamma}(a, b)$$\n其中 $a > 0$ 是形状参数，$b > 0$ 是速率参数。其概率密度函数（PDF）为 $p(\\lambda) = \\frac{b^a}{\\Gamma(a)} \\lambda^{a-1} e^{-b\\lambda}$，它正比于 $\\lambda^{a-1} e^{-b\\lambda}$。\n\n后验分布通过将似然与先验相乘得到：\n$$p(\\lambda \\mid \\mathbf{y}) \\propto (\\lambda^S e^{-N\\lambda}) (\\lambda^{a-1} e^{-b\\lambda}) = \\lambda^{a+S-1} e^{-(b+N)\\lambda}$$\n这个表达式是Gamma分布的核。因此，后验分布也是一个Gamma分布：\n$$\\lambda \\mid \\mathbf{y} \\sim \\mathrm{Gamma}(a', b')$$\n其后验形状参数为 $a' = a+S$，后验速率参数为 $b' = b+N$。\n\n$\\mathrm{Gamma}(a', b')$ 分布的均值是 $\\frac{a'}{b'}$。因此，$\\lambda$ 的后验均值是：\n$$\\mathbb{E}[\\lambda \\mid \\mathbf{y}] = \\frac{a+S}{b+N}$$\n问题规定先验均值固定为值 $m_0$。先验 $\\mathrm{Gamma}(a, b)$ 分布的均值是 $\\mathbb{E}[\\lambda] = a/b$。所以，我们有约束 $m_0 = a/b$，这意味着 $b = a/m_0$。将此代入后验均值公式得到：\n$$\\mathbb{E}[\\lambda \\mid \\mathbf{y}] = \\frac{a+S}{(a/m_0) + N}$$\n这就是用于计算Gamma先验的后验均值的表达式。\n\n### 非共轭先验分析：对数正态-泊松模型\n\n$\\lambda$ 的非共轭先验被指定为对数正态分布。这意味着 $\\log \\lambda$ 服从正态分布：\n$$\\log \\lambda \\sim \\mathcal{N}(\\mu, \\sigma^2)$$\n$\\lambda$ 的概率密度函数为 $p(\\lambda) = \\frac{1}{\\lambda \\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\log \\lambda - \\mu)^2}{2\\sigma^2}\\right)$，对于 $\\lambda > 0$。\n\n后验分布同样正比于似然与先验的乘积：\n$$p(\\lambda \\mid \\mathbf{y}) \\propto (\\lambda^S e^{-N\\lambda}) \\left( \\frac{1}{\\lambda} \\exp\\left(-\\frac{(\\log \\lambda - \\mu)^2}{2\\sigma^2}\\right) \\right)$$\n$$p(\\lambda \\mid \\mathbf{y}) \\propto \\lambda^{S-1} e^{-N\\lambda} \\exp\\left(-\\frac{(\\log \\lambda - \\mu)^2}{2\\sigma^2}\\right)$$\n这个后验不是一个标准的、有名称的分布。其后验均值必须根据其定义计算：\n$$\\mathbb{E}[\\lambda \\mid \\mathbf{y}] = \\frac{\\int_0^\\infty \\lambda \\cdot p(\\lambda \\mid \\mathbf{y}) d\\lambda}{\\int_0^\\infty p(\\lambda \\mid \\mathbf{y}) d\\lambda}$$\n代入未归一化的后验密度，我们得到：\n$$\\mathbb{E}[\\lambda \\mid \\mathbf{y}] = \\frac{\\int_0^\\infty \\lambda^S e^{-N\\lambda} \\exp\\left(-\\frac{(\\log \\lambda - \\mu)^2}{2\\sigma^2}\\right) d\\lambda}{\\int_0^\\infty \\lambda^{S-1} e^{-N\\lambda} \\exp\\left(-\\frac{(\\log \\lambda - \\mu)^2}{2\\sigma^2}\\right) d\\lambda}$$\n这些积分没有闭式解，必须进行数值计算。为了提高数值稳定性，我们进行变量替换。令 $x = \\log \\lambda$，这意味着 $\\lambda = e^x$ 且 $d\\lambda = e^x dx$。积分域从 $(0, \\infty)$ 变为 $(-\\infty, \\infty)$。我们将分子积分记为 $I_{\\text{num}}$，分母积分记为 $I_{\\text{den}}$。\n$$I_{\\text{num}} = \\int_{-\\infty}^{\\infty} (e^x)^S e^{-Ne^x} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right) e^x dx = \\int_{-\\infty}^{\\infty} \\exp\\left(x(S+1) - Ne^x - \\frac{(x-\\mu)^2}{2\\sigma^2}\\right) dx$$\n$$I_{\\text{den}} = \\int_{-\\infty}^{\\infty} (e^x)^{S-1} e^{-Ne^x} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right) e^x dx = \\int_{-\\infty}^{\\infty} \\exp\\left(xS - Ne^x - \\frac{(x-\\mu)^2}{2\\sigma^2}\\right) dx$$\n于是后验均值为 $\\mathbb{E}[\\lambda \\mid \\mathbf{y}] = I_{\\text{num}} / I_{\\text{den}}$。这些积分是良态的，可以使用数值求积方法可靠地计算。\n\n问题将先验均值约束为 $m_0$。一个 $\\mathrm{Lognormal}(\\mu, \\sigma^2)$ 分布的均值是 $\\mathbb{E}[\\lambda] = e^{\\mu + \\sigma^2/2}$。将其设为 $m_0$ 并求解 $\\mu$ 得到：\n$$\\mu = \\log(m_0) - \\frac{\\sigma^2}{2}$$\n这个 $\\mu$ 的表达式被代入被积函数中。\n\n### 敏感性指标的计算\n\n对于每个测试用例，我们计算以下量：\n$1$. $\\Delta_{\\mathrm{logN}} = \\left|\\mathbb{E}[\\lambda \\mid \\mathbf{y}, \\sigma_{\\mathrm{heavy}}] - \\mathbb{E}[\\lambda \\mid \\mathbf{y}, \\sigma_{\\mathrm{light}}]\\right|$:\n    - 我们使用对数正态先验计算两个后验均值。\n    - 对于“轻尾”情况，使用 $\\sigma = \\sigma_{\\mathrm{light}}$ 和 $\\mu_{\\mathrm{light}} = \\log(m_0) - \\sigma_{\\mathrm{light}}^2/2$。\n    - 对于“重尾”情况，使用 $\\sigma = \\sigma_{\\mathrm{heavy}}$ 和 $\\mu_{\\mathrm{heavy}} = \\log(m_0) - \\sigma_{\\mathrm{heavy}}^2/2$。\n    - 后验均值通过数值积分求得，$\\Delta_{\\mathrm{logN}}$ 是其绝对差。\n\n$2$. $\\Delta_{\\mathrm{Gamma}} = \\left|\\mathbb{E}[\\lambda \\mid \\mathbf{y}, a_{\\mathrm{heavy}}] - \\mathbb{E}[\\lambda \\mid \\mathbf{y}, a_{\\mathrm{light}}]\\right|$:\n    - 我们使用Gamma先验计算两个后验均值。具有固定均值 $m_0$ 的Gamma先验的方差是 $m_0^2/a$。因此，较小的 $a$ 会产生较重的尾部。\n    - 对于“轻尾”情况，使用 $a = a_{\\mathrm{light}}$ 和 $b_{\\mathrm{light}} = a_{\\mathrm{light}}/m_0$。后验均值为 $\\frac{a_{\\mathrm{light}}+S}{b_{\\mathrm{light}}+N}$。\n    - 对于“重尾”情况，使用 $a = a_{\\mathrm{heavy}}$ 和 $b_{\\mathrm{heavy}} = a_{\\mathrm{heavy}}/m_0$。后验均值为 $\\frac{a_{\\mathrm{heavy}}+S}{b_{\\mathrm{heavy}}+N}$。\n    - $\\Delta_{\\mathrm{Gamma}}$ 是这两个解析值之间的绝对差。\n\n$3$. $R = \\Delta_{\\mathrm{logN}} / \\Delta_{\\mathrm{Gamma}}$:\n    - 这是两个敏感性指标的比率，提供了一个无量纲的比较。\n\n实现将包括一个遍历测试用例的主循环。在循环内部，辅助函数将计算两个先验族在各自的轻尾和重尾参数化下的后验均值。然后计算并存储最终的指标。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef calculate_gamma_posterior_mean(S, N, a, b):\n    \"\"\"\n    Calculates the posterior mean for a Gamma-Poisson model.\n    \n    Args:\n        S (int): Sum of observed counts.\n        N (int): Number of observations.\n        a (float): Shape parameter of the Gamma prior.\n        b (float): Rate parameter of the Gamma prior.\n        \n    Returns:\n        float: The posterior mean of lambda.\n    \"\"\"\n    posterior_shape = a + S\n    posterior_rate = b + N\n    return posterior_shape / posterior_rate\n\ndef calculate_lognormal_posterior_mean(S, N, mu, sigma):\n    \"\"\"\n    Calculates the posterior mean for a Lognormal-Poisson model via numerical integration.\n    \n    Args:\n        S (int): Sum of observed counts.\n        N (int): Number of observations.\n        mu (float): Location parameter of the Lognormal prior.\n        sigma (float): Scale parameter of the Lognormal prior.\n        \n    Returns:\n        float: The posterior mean of lambda.\n    \"\"\"\n    # Numerically unstable to integrate exp(log_integrand) directly.\n    # We define the log of the integrand and integrate its exponential.\n    # The change of variables is x = log(lambda).\n    \n    # log_integrand for the numerator of the posterior mean expectation\n    def log_integrand_num(x):\n        k = S + 1\n        return k * x - N * np.exp(x) - ((x - mu)**2) / (2 * sigma**2)\n\n    # log_integrand for the denominator (normalization constant)\n    def log_integrand_den(x):\n        k = S\n        return k * x - N * np.exp(x) - ((x - mu)**2) / (2 * sigma**2)\n\n    # To avoid overflow/underflow, find the peak of the log integrand and subtract it\n    # This integration is well-behaved, so direct integration is feasible,\n    # but this is a more robust approach if needed. However, quad is robust enough\n    # for these test cases.\n    integrand_num = lambda x: np.exp(log_integrand_num(x))\n    integrand_den = lambda x: np.exp(log_integrand_den(x))\n    \n    # quad returns (integral, error)\n    integral_num, _ = quad(integrand_num, -np.inf, np.inf)\n    integral_den, _ = quad(integrand_den, -np.inf, np.inf)\n    \n    if integral_den == 0:\n        # This case is unlikely with proper priors but is a safeguard.\n        return np.nan\n        \n    return integral_num / integral_den\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        # Case 1: (y, m0, sigma_light, sigma_heavy, a_light, a_heavy)\n        (np.array([0, 1]), 1.0, 0.25, 1.0, 50.0, 1.0),\n        # Case 2\n        (np.array([0, 0, 1, 0, 2]), 0.5, 0.2, 1.2, 40.0, 0.5),\n        # Case 3\n        (np.array([5]), 4.0, 0.3, 0.9, 20.0, 1.0),\n        # Case 4\n        (np.array([0, 0, 0]), 0.2, 0.3, 1.5, 50.0, 0.3),\n        # Case 5\n        (np.array([50, 60]), 40.0, 0.5, 1.0, 30.0, 1.0),\n    ]\n\n    results = []\n    for y, m0, sigma_light, sigma_heavy, a_light, a_heavy in test_cases:\n        S = np.sum(y)\n        N = len(y)\n\n        # Lognormal Prior Calculation\n        mu_light = np.log(m0) - (sigma_light**2) / 2\n        mu_heavy = np.log(m0) - (sigma_heavy**2) / 2\n        \n        mean_logN_light = calculate_lognormal_posterior_mean(S, N, mu_light, sigma_light)\n        mean_logN_heavy = calculate_lognormal_posterior_mean(S, N, mu_heavy, sigma_heavy)\n        \n        delta_logN = abs(mean_logN_heavy - mean_logN_light)\n\n        # Gamma Prior Calculation\n        b_light = a_light / m0\n        b_heavy = a_heavy / m0\n        \n        mean_gamma_light = calculate_gamma_posterior_mean(S, N, a_light, b_light)\n        mean_gamma_heavy = calculate_gamma_posterior_mean(S, N, a_heavy, b_heavy)\n        \n        delta_gamma = abs(mean_gamma_heavy - mean_gamma_light)\n\n        # Ratio Calculation\n        # Avoid division by zero, though unlikely in this problem context.\n        if delta_gamma == 0:\n            ratio = np.inf if delta_logN != 0 else 0.0\n        else:\n            ratio = delta_logN / delta_gamma\n            \n        results.append([delta_logN, delta_gamma, ratio])\n\n    # Format output to a list of lists string with no spaces.\n    # Ex: [[1.0,2.0,3.0],[4.0,5.0,6.0]]\n    formatted_results = []\n    for res in results:\n        formatted_sublist = \"[\" + \",\".join(map(str, res)) + \"]\"\n        formatted_results.append(formatted_sublist)\n    final_output = \"[\" + \",\".join(formatted_results) + \"]\"\n\n    print(final_output)\n\nsolve()\n\n```"
        },
        {
            "introduction": "贝叶斯推断不仅是关于被动学习，它还是在不确定性下做出最优决策的强大引擎。这个高级练习将检测信号通路激活的生物学问题，构建为一个序贯决策任务。你将使用动态规划来确定何时停止实验并得出结论的最优策略，明确地权衡收集更多数据的成本与做出错误判断的风险。",
            "id": "3340138",
            "problem": "单个细胞中的一个信号通路在两种潜在状态之间转换：非激活和激活。要求您在计算系统生物学的框架内，为通路激活设计一个贝叶斯序贯检测器。在每个离散时间步 $t \\in \\{1,2,\\dots\\}$，您会观察到一个整数读数 $y_t$，代表与激活相关的分子事件的计数。在零假设 $H_0$（非激活）下，读数是独立同分布的，服从速率为 $\\lambda_0$ 的泊松分布。在备择假设 $H_1$（激活）下，读数是独立同分布的，服从速率为 $\\lambda_1$ 的泊松分布，其中 $\\lambda_1 > \\lambda_0$。您拥有先验概率 $p(H_1) = \\pi_0 \\in (0,1)$。您还面临每次样本采集的成本 $c > 0$，假阳性决策成本 $C_{10} > 0$（当 $H_0$ 为真时决定为 $H_1$），以及假阴性决策成本 $C_{01} > 0$（当 $H_1$ 为真时决定为 $H_0$）。不产生其他成本。\n\n您的任务是将通路激活检测问题重构为一个贝叶斯序贯决策问题，并实现一个算法，该算法对于给定的参数，计算后验概率 $p(H_1 \\mid y_{1:t})$ 的演变，并应用一个在有限时间范围内最小化预期贝叶斯风险的最优停止规则。该问题需从第一性原理出发，使用以下基本原理来解决：\n\n- 泊松分布的定义以及在每个假设下观测值的独立性。\n- 基于似然比进行后验更新的贝叶斯定理。\n- 在有限时间范围的马尔可夫决策过程（MDP）中用于最优序贯决策的动态规划原理。\n\n将序贯决策问题表述如下。在每个时间点 $t \\in \\{0,1,\\dots,T\\}$，在获取新观测值之前，您持有一个信念 $\\pi_t = p(H_1 \\mid y_{1:t})$，约定 $y_{1:0}$ 为空历史，$\\pi_0 = \\pi_0$。在每个时间点 $t < T$，您可以选择以下行动之一：停止并决策为 $H_0$，停止并决策为 $H_1$，或继续获取一个观测值（产生采样成本 $c$）。在时间 $t=T$ 时，您必须停止并从 $H_0$ 和 $H_1$ 中选择一个。如果在信念为 $\\pi$ 时停止并决策为 $H_0$，终端损失为 $\\pi \\, C_{01}$；如果在信念为 $\\pi$ 时停止并决策为 $H_1$，终端损失为 $(1-\\pi)\\, C_{10}$。如果在信念为 $\\pi$ 时继续，即时成本为 $c$ 加上在下一个观测值的预测分布下，下一个时间步的预期贝叶斯风险。\n\n要求：\n\n1) 推导后验概率 $p(H_1 \\mid y_{1:t})$ 作为 $t$ 的函数表达式，用先验概率 $p(H_1)$ 和累积似然比 $\\Lambda_t = \\dfrac{p(y_{1:t} \\mid H_1)}{p(y_{1:t} \\mid H_0)}$ 表示。使用单次观测的似然比来表达每个时间步的更新，并阐明对于独立观测，$\\Lambda_t$ 是如何随时间累积的。\n\n2) 从基本损失定义和全期望定律出发，推导在信念 $\\pi \\in (0,1)$ 上的最优价值函数 $V_t(\\pi)$ 的有限时间范围动态规划递推关系：\n- 确定在 $t=T$ 时的终端边界条件。\n- 写出在 $t < T$ 时比较停止决策损失与继续观测价值的递推公式。\n- 精确定义下一个观测值的预测分布，以及在给定单个观测值时信念的更新映射 $\\pi \\mapsto \\pi'$。\n- 用动态规划递推的最小化项来陈述每个时间 $t$ 的最优停止规则。\n\n3) 实现一个程序，该程序：\n- 在 $(0,1)$ 区间上使用均匀网格对信念 $\\pi$ 进行离散化。\n- 通过后向归纳法计算价值函数 $\\{V_t\\}_{t=0}^T$ 以及每个网格点上的相关最优行动。\n- 对每个测试用例，从 $\\pi_0 = \\pi_0$ 和提供的观测序列 $\\{y_t\\}$ 开始，应用随时间变化的最优策略，正向模拟序贯过程。如果在观测时间 $t$ 的下一个样本之前策略指示停止，则记录停止时间 $t^\\star = t$、后验概率 $\\pi_{t^\\star}$ 和二元决策（决策为 $H_1$ 编码为 $\\mathrm{True}$，决策为 $H_0$ 编码为 $\\mathrm{False}$）。如果策略建议继续，则用下一个 $y_t$ 更新后验概率并继续。在 $t=T$ 时，使用终端策略强制停止。\n- 对泊松模型，使用基于对数优势比（log-odds）和单次观测对数似然比的数值稳定实现来进行后验递推。\n\n使用以下测试套件。在每个案例中，参数以 $(\\pi_0, \\lambda_0, \\lambda_1, C_{10}, C_{01}, c, T, \\text{sequence})$ 的形式给出：\n\n- 测试用例 1（典型信息序列，中等成本）：($\\pi_0=0.3$, $\\lambda_0=2.0$, $\\lambda_1=5.0$, $C_{10}=2.0$, $C_{01}=1.0$, $c=0.1$, $T=10$, sequence=[4, 6, 7, 3, 5])。\n- 测试用例 2（高采样成本，立即决策）：($\\pi_0=0.3$, $\\lambda_0=2.0$, $\\lambda_1=5.0$, $C_{10}=2.0$, $C_{01}=1.0$, $c=5.0$, $T=10$, sequence=[100])。\n- 测试用例 3（对称成本，高区分度模型）：($\\pi_0=0.5$, $\\lambda_0=1.0$, $\\lambda_1=8.0$, $C_{10}=1.0$, $C_{01}=1.0$, $c=0.05$, $T=10$, sequence=[0, 0, 1, 0, 2, 10])。\n\n您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，其本身是一个形式为 $[t^\\star, \\pi_{t^\\star}, \\text{decision}]$ 的列表，其中 $t^\\star$ 是一个整数，$\\pi_{t^\\star}$ 是一个浮点数，$\\text{decision}$ 是一个布尔值（决策为 $H_1$ 时为 $\\mathrm{True}$，决策为 $H_0$ 时为 $\\mathrm{False}$）。例如，输出必须看起来像 $[[\\dots],[\\dots],[\\dots]]$，不含任何额外文本。",
            "solution": "该问题要求为细胞信号通路设计并实现一个贝叶斯序贯检测器。通路的状态是一个潜在的二元变量（非激活，$H_0$，或激活，$H_1$）。观测值是按序到达的分子计数 $y_t$，建模为从泊松分布中抽样，其速率 $\\lambda$ 取决于真实的假设。这个场景被表述为一个有限时间范围的最优停止问题，可以使用动态规划来解决。\n\n### 1. 后验概率更新规则\n\n贝叶斯序贯程序的核心是根据新证据更新我们的信念。信念由备择假设的后验概率 $\\pi_t = p(H_1 \\mid y_{1:t})$ 来量化，其中 $y_{1:t} = (y_1, y_2, \\dots, y_t)$ 是截至时间 $t$ 的观测序列。\n\n根据贝叶斯定理，后验概率由下式给出：\n$$\n\\pi_t = p(H_1 \\mid y_{1:t}) = \\frac{p(y_{1:t} \\mid H_1) p(H_1)}{p(y_{1:t})}\n$$\n数据的边际似然 $p(y_{1:t})$ 可以使用全概率定律展开：\n$$\np(y_{1:t}) = p(y_{1:t} \\mid H_1) p(H_1) + p(y_{1:t} \\mid H_0) p(H_0)\n$$\n将此代入贝叶斯定理表达式，并使用先验概率 $\\pi_0 = p(H_1)$ 和 $p(H_0) = 1 - \\pi_0$，我们得到：\n$$\n\\pi_t = \\frac{p(y_{1:t} \\mid H_1) \\pi_0}{p(y_{1:t} \\mid H_1) \\pi_0 + p(y_{1:t} \\mid H_0) (1 - \\pi_0)}\n$$\n将分子和分母同除以 $p(y_{1:t} \\mid H_0)$，引入累积似然比 $\\Lambda_t$：\n$$\n\\Lambda_t = \\frac{p(y_{1:t} \\mid H_1)}{p(y_{1:t} \\mid H_0)}\n$$\n后验概率可以紧凑地表示为：\n$$\n\\pi_t = \\frac{\\Lambda_t \\pi_0}{\\Lambda_t \\pi_0 + (1 - \\pi_0)}\n$$\n鉴于在每个假设下，观测值 $y_t$ 是独立同分布的，序列 $y_{1:t}$ 的累积似然是单个似然的乘积：\n$$\np(y_{1:t} \\mid H_k) = \\prod_{i=1}^{t} p(y_i \\mid H_k) \\quad \\text{对于 } k \\in \\{0, 1\\}\n$$\n因此，累积似然比是乘法累积的：\n$$\n\\Lambda_t = \\left(\\prod_{i=1}^{t-1} \\frac{p(y_i \\mid H_1)}{p(y_i \\mid H_0)}\\right) \\cdot \\frac{p(y_t \\mid H_1)}{p(y_t \\mid H_0)} = \\Lambda_{t-1} \\cdot \\frac{p(y_t \\mid H_1)}{p(y_t \\mid H_0)}\n$$\n为了数值稳定性，尤其是在处理长观测序列时，最好使用对数。我们定义后验概率的对数优势比（或称 logit），$L_t = \\ln(\\frac{\\pi_t}{1-\\pi_t})$。从 $\\pi_t$ 以 $\\Lambda_t$ 表示的表达式中，我们发现：\n$$\nL_t = \\ln\\left(\\frac{\\Lambda_t \\pi_0 / (\\Lambda_t \\pi_0 + 1 - \\pi_0)}{(1 - \\pi_0) / (\\Lambda_t \\pi_0 + 1 - \\pi_0)}\\right) = \\ln(\\Lambda_t) + \\ln\\left(\\frac{\\pi_0}{1-\\pi_0}\\right) = \\ln(\\Lambda_t) + L_0\n$$\n因此，对数优势比的递推更新是加法形式的：\n$$\nL_t = L_{t-1} + \\ln\\left(\\frac{p(y_t \\mid H_1)}{p(y_t \\mid H_0)}\\right)\n$$\n对于指定的泊松模型，$p(y \\mid H_k) = \\frac{e^{-\\lambda_k} \\lambda_k^y}{y!}$。单个观测值 $y$ 的对数似然比为：\n$$\n\\ln\\left(\\frac{p(y \\mid H_1)}{p(y \\mid H_0)}\\right) = \\ln\\left(\\frac{e^{-\\lambda_1} \\lambda_1^y / y!}{e^{-\\lambda_0} \\lambda_0^y / y!}\\right) = (\\lambda_0 - \\lambda_1) + y \\ln\\left(\\frac{\\lambda_1}{\\lambda_0}\\right)\n$$\n在对数优势比空间中的这种线性更新为算法提供了数值上鲁棒的基础。\n\n### 2. 有限时间范围动态规划递推\n\n序贯决策问题旨在找到一个最小化总预期成本（贝叶斯风险）的策略。该策略根据当前信念 $\\pi_t$ 在每个时间点 $t$ 决定是停止并做出决策，还是继续采样。我们定义 $V_t(\\pi)$ 为从时间 $t$ 开始、信念为 $\\pi$ 时的最小预期风险（或最优价值函数）。解可以通过后向归纳法找到，从终端时间 $T$ 开始。\n\n**终端条件 ($t=T$):**\n在最后的时间步 $T$，不能选择继续。必须在 $H_0$ 和 $H_1$ 之间做出决策。最优行动是最小化终端损失的那个。\n- 在信念为 $\\pi$ 时决策为 $H_0$ 的损失：$L_{d_0}(\\pi) = E[\\text{cost} \\mid \\text{decide } H_0, \\pi] = p(H_1 \\mid \\pi) C_{01} + p(H_0 \\mid \\pi) \\cdot 0 = \\pi C_{01}$。\n- 在信念为 $\\pi$ 时决策为 $H_1$ 的损失：$L_{d_1}(\\pi) = E[\\text{cost} \\mid \\text{decide } H_1, \\pi] = p(H_0 \\mid \\pi) C_{10} + p(H_1 \\mid \\pi) \\cdot 0 = (1-\\pi) C_{10}$。\n因此，时间 $T$ 的价值函数为：\n$$\nV_T(\\pi) = \\min(L_{d_0}(\\pi), L_{d_1}(\\pi)) = \\min(\\pi C_{01}, (1-\\pi) C_{10})\n$$\n在 $t=T$ 时的决策规则是，如果 $\\pi C_{01} \\le (1-\\pi) C_{10}$，则选择 $H_0$，否则选择 $H_1$。这对应于对 $\\pi$ 的一个阈值：如果 $\\pi > \\frac{C_{10}}{C_{10} + C_{01}}$，则决策为 $H_1$。\n\n**递推步骤 ($t < T$):**\n对于任意时间 $t < T$，代理人可以选择三种行动之一：停止并决策为 $H_0$，停止并决策为 $H_1$，或继续。最优价值函数是与这些行动相关的成本的最小值。\n$$\nV_t(\\pi) = \\min(L_{d_0}(\\pi), L_{d_1}(\\pi), L_{\\text{continue}}(\\pi, t))\n$$\n停止成本与终端损失相同：\n- $L_{d_0}(\\pi) = \\pi C_{01}$\n- $L_{d_1}(\\pi) = (1-\\pi) C_{10}$\n继续观测的成本 $L_{\\text{continue}}(\\pi, t)$ 包括即时采样成本 $c$ 和在时间 $t+1$ 进入下一个状态的期望价值。期望是针对给定当前信念 $\\pi_t$ 的下一个观测值 $y_{t+1}$ 的预测分布计算的：\n$$\nL_{\\text{continue}}(\\pi_t, t) = c + E_{y_{t+1} \\mid \\pi_t} [V_{t+1}(\\pi_{t+1})]\n$$\n下一步的信念 $\\pi_{t+1}$ 是当前信念 $\\pi_t$ 和新观测值 $y_{t+1}$ 的函数。设此更新为 $\\pi_{t+1} = U(\\pi_t, y_{t+1})$。预测分布 $p(y \\mid \\pi_t)$ 为：\n$$\np(y \\mid \\pi_t) = p(y \\mid H_1)\\pi_t + p(y \\mid H_0)(1-\\pi_t)\n$$\n这是一个两个泊松分布的混合分布。因此，期望是关于所有可能的 $y$ 值的求和：\n$$\nE_{y_{t+1} \\mid \\pi_t} [V_{t+1}(\\pi_{t+1})] = \\sum_{y=0}^{\\infty} V_{t+1}(U(\\pi_t, y)) \\cdot p(y \\mid \\pi_t)\n$$\n对于 $t=T-1, \\dots, 0$ 的完整动态规划递推关系为：\n$$\nV_t(\\pi_t) = \\min \\left( \\pi_t C_{01}, (1-\\pi_t) C_{10}, c + \\sum_{y=0}^{\\infty} V_{t+1}(U(\\pi_t, y)) [p(y \\mid H_1)\\pi_t + p(y \\mid H_0)(1-\\pi_t)] \\right)\n$$\n在时间 $t$、信念为 $\\pi$ 时的最优停止规则是选择使上述表达式最小化的那一项所对应的行动。如果第三项是最小值，最优行动是继续；否则，是停止并做出相应的决策。\n\n### 3. 算法实现策略\n\n价值函数 $V_t(\\pi)$ 是定义在连续信念空间 $\\pi \\in [0, 1]$ 上的函数。为了实现动态规划递推，我们必须对这个空间进行离散化。\n\n**后向归纳法：**\n1.  **离散化信念空间：** 为 $\\pi \\in [0, 1]$ 定义一个包含 $N$ 个点的均匀网格，称之为 `pi_grid`。\n2.  **初始化：** 使用终端条件 $V_T(\\pi_k) = \\min(\\pi_k C_{01}, (1-\\pi_k) C_{10})$ 计算 `pi_grid` 上每个点的价值函数 $V_T(\\pi)$。同时为 $t=T$ 初始化一个策略表，存储每个 $\\pi_k$ 对应的决策是 $H_0$ 还是 $H_1$。\n3.  **后向递推：** 我们从 $t = T-1$ 向下迭代到 $0$。对于每个时间 $t$ 和每个网格点 $\\pi_k$：\n    a. 计算停止成本 $\\pi_k C_{01}$ 和 $(1-\\pi_k) C_{10}$。\n    b. 计算继续成本。这涉及到对下一个观测值 $y$ 的期望。无限求和被截断到一个有限范围 $y \\in [0, y_{\\max}]$，其中 $y_{\\max}$ 的选择使得 $y > y_{\\max}$ 时泊松分布的概率质量可以忽略不计。\n    c. 对于此范围内的每个 $y$，使用稳定的对数优势比更新计算下一个信念 $\\pi'_{k,y} = U(\\pi_k, y)$。\n    d. 由于 $\\pi'_{k,y}$ 通常不会落在网格点上，因此使用对 `pi_grid` 上已计算的 $V_{t+1}$ 值进行线性插值来估计 $V_{t+1}(\\pi'_{k,y})$。\n    e. 期望的未来价值通过加权和 $\\sum_{y=0}^{y_{\\max}} V_{t+1}(\\pi'_{k,y}) p(y \\mid \\pi_k)$ 来近似。\n    f. 将 $V_t(\\pi_k)$ 设置为两个停止成本和继续成本中的最小值。将相应的行动（决策为 $H_0$、决策为 $H_1$ 或继续）存储在 $(t, \\pi_k)$ 的策略表中。\n\n**前向模拟：**\n一旦计算出所有 $(t, \\pi_k)$ 的最优策略表，我们就可以对给定的初始先验 $\\pi_0$ 和观测序列进行决策过程模拟。\n1.  初始化时间 $t=0$ 和当前信念 $\\pi = \\pi_0$。\n2.  进入一个时间上向前推进的循环：\n    a. 在当前时间 $t$ 和信念 $\\pi$，通过查询策略表来确定最优行动。由于 $\\pi$ 可能不是一个网格点，因此使用最近网格点的策略。\n    b. 如果 $t \\ge T$ 或提供的观测序列已用尽，则强制停止。通过比较终端损失 $\\pi C_{01}$ 和 $(1-\\pi)C_{10}$ 来做出决策。\n    c. 如果策略指示停止，记录停止时间 $t^\\star = t$、最终后验概率 $\\pi_{t^\\star} = \\pi$ 和决策。模拟终止。\n    d. 如果策略指示继续，则使用序列中下一个可用的观测值将信念 $\\pi$ 更新为 $\\pi' = U(\\pi, y_t)$。将时间 $t$ 增加到 $t+1$ 并继续循环。\n\n这个两阶段过程——首先通过后向归纳法找到最优策略，然后通过前向模拟来应用该策略——为指定问题提供了完整的解决方案。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import poisson\n\ndef solve():\n    \"\"\"\n    Main solver function that runs the Bayesian sequential detection algorithm \n    for all specified test cases.\n    \"\"\"\n\n    test_cases = [\n        # (pi_0, lambda_0, lambda_1, C10, C01, c, T, sequence)\n        (0.3, 2.0, 5.0, 2.0, 1.0, 0.1, 10, [4, 6, 7, 3, 5]),\n        (0.3, 2.0, 5.0, 2.0, 1.0, 5.0, 10, [100]),\n        (0.5, 1.0, 8.0, 1.0, 1.0, 0.05, 10, [0, 0, 1, 0, 2, 10]),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(*case)\n        results.append(result)\n\n    # Format the output string exactly as required, without extra spaces.\n    result_str = '[' + ','.join(\n        [f\"[{r[0]},{r[1]},{'True' if r[2] else 'False'}]\" for r in results]\n    ) + ']'\n    print(result_str)\n\ndef run_test_case(pi_0, lambda_0, lambda_1, C10, C01, c, T, sequence):\n    \"\"\"\n    Solves a single instance of the sequential decision problem.\n    \"\"\"\n    N_GRID = 1001  # Number of points for belief discretization\n    pi_grid = np.linspace(0.0, 1.0, N_GRID)\n\n    # --- Backward Induction (Dynamic Programming) ---\n\n    # Determine a practical upper bound for the observation y for expectation calculation\n    y_max_h0 = poisson.ppf(0.99999, lambda_0)\n    y_max_h1 = poisson.ppf(0.99999, lambda_1)\n    y_max = int(max(20, y_max_h0, y_max_h1)) + 1\n    y_range = np.arange(0, y_max)\n\n    # Pre-calculate PMFs for H0 and H1 for the determined y_range\n    pmf_h0 = poisson.pmf(y_range, lambda_0)\n    pmf_h1 = poisson.pmf(y_range, lambda_1)\n\n    # Pre-calculate single-observation log-likelihood ratio\n    log_lambda_ratio = np.log(lambda_1 / lambda_0)\n    log_lik_ratio = (lambda_0 - lambda_1) + y_range * log_lambda_ratio\n\n    V = np.zeros((T + 1, N_GRID))\n    # Actions: 0 (decide H0), 1 (decide H1), 2 (continue)\n    policy = np.zeros((T + 1, N_GRID), dtype=int)\n\n    # Boundary condition at t=T\n    cost_d0_T = pi_grid * C01\n    cost_d1_T = (1.0 - pi_grid) * C10\n    V[T, :] = np.minimum(cost_d0_T, cost_d1_T)\n    policy[T, :] = np.argmin([cost_d0_T, cost_d1_T], axis=0)\n\n    # DP backward recursion from t=T-1 down to 0\n    for t in range(T - 1, -1, -1):\n        # Calculate stopping costs\n        cost_d0 = pi_grid * C01\n        cost_d1 = (1.0 - pi_grid) * C10\n\n        # Calculate continuation cost\n        # Suppress divide-by-zero warnings for log(0) at endpoints\n        with np.errstate(divide='ignore'):\n            log_odds = np.log(pi_grid / (1.0 - pi_grid))\n        \n        # Broadcasting to calculate updated log-odds for all y and all pi_k\n        updated_log_odds = log_odds[np.newaxis, :] + log_lik_ratio[:, np.newaxis]\n        updated_pi = 1.0 / (1.0 + np.exp(-updated_log_odds))\n        \n        # Interpolate V at t+1 for the updated beliefs\n        V_interp = np.interp(updated_pi, pi_grid, V[t + 1, :])\n        \n        # Calculate predictive probability for each y, for each pi_k\n        pred_prob_y = pmf_h1[:, np.newaxis] * pi_grid[np.newaxis, :] + \\\n                      pmf_h0[:, np.newaxis] * (1.0 - pi_grid[np.newaxis, :])\n                      \n        # Expected future cost\n        expected_future_cost = np.sum(V_interp * pred_prob_y, axis=0)\n        cost_continue = c + expected_future_cost\n        \n        # Bellman equation\n        costs = np.vstack([cost_d0, cost_d1, cost_continue])\n        V[t, :] = np.min(costs, axis=0)\n        policy[t, :] = np.argmin(costs, axis=0)\n\n    # --- Forward Simulation ---\n    \n    pi_current = pi_0\n    t = 0\n    \n    while t = T:\n        # Find the policy for the current belief by finding the nearest grid point\n        idx = np.argmin(np.abs(pi_grid - pi_current))\n        action = policy[t, idx]\n\n        # Forced stop conditions: t=T or observation sequence exhausted\n        if t == T or (action == 2 and t >= len(sequence)):\n            decision = (pi_current * C01) > ((1 - pi_current) * C10)\n            return [t, pi_current, decision]\n\n        if action == 2:  # Continue\n            y_obs = sequence[t]\n            \n            # Update log-odds for the new observation\n            with np.errstate(divide='ignore'):\n                 log_odds_current = np.log(pi_current / (1.0 - pi_current))\n            \n            log_lik_ratio_obs = (lambda_0 - lambda_1) + y_obs * log_lambda_ratio\n            log_odds_new = log_odds_current + log_lik_ratio_obs\n            pi_current = 1.0 / (1.0 + np.exp(-log_odds_new))\n            \n            t += 1\n        else:  # Stop\n            decision = (action == 1)  # True if decision is H1\n            return [t, pi_current, decision]\n            \n    # This return should not be reached due to the t=T loop and forced stops\n    return None \n\nsolve()\n\n```"
        }
    ]
}