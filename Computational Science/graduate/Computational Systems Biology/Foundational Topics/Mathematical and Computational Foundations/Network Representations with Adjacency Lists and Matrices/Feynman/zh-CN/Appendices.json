{
    "hands_on_practices": [
        {
            "introduction": "本练习旨在巩固您使用邻接表这一基本数据结构的能力。您将设计一个算法，直接从邻接表计算有向图中每个节点的入度、出度和交互邻居重叠数，这是分析任何网络拓扑结构的基础步骤。通过这个实践，您将加深对图遍历算法和计算复杂性分析的理解。",
            "id": "3332690",
            "problem": "考虑一个有向基因调控网络，该网络被建模为一个图，其节点集为 $V$，有向边集为 $E$。每个节点代表一个基因，从节点 $i$ 到节点 $j$ 的有向边表示基因 $i$ 对基因 $j$ 进行转录调控。该图由一个邻接表表示，其中对于每个节点 $i$，邻接表 $A[i]$ 包含其出邻居集合 $N_{\\mathrm{out}}(i)$，即满足 $(i,j) \\in E$ 的所有节点 $j$。为确保计算的正确性，$A[i]$ 中的重复边应被忽略（视为单一边），并允许自环 $(i,i)$。\n\n定义：\n- 节点 $i$ 的出度为 $d_{\\mathrm{out}}(i) = |N_{\\mathrm{out}}(i)|$。\n- 节点 $i$ 的入邻居集合为 $N_{\\mathrm{in}}(i) = \\{j \\in V \\mid (j,i) \\in E\\}$，其入度为 $d_{\\mathrm{in}}(i) = |N_{\\mathrm{in}}(i)|$。\n- 节点 $i$ 的互惠邻居重叠大小为 $s(i) = |N_{\\mathrm{out}}(i) \\cap N_{\\mathrm{in}}(i)|$，它计算同时调控 $i$ 并被 $i$ 调控的节点数量。\n- 有向边的总数为 $m = |E|$。\n- 最大度为 $\\Delta_{\\max} = \\max_{i \\in V} \\{\\max(d_{\\mathrm{out}}(i), d_{\\mathrm{in}}(i))\\}$。\n\n任务：\n- 设计并实现一个算法，给定一个包含 $n$ 个节点 $V = \\{0,1,\\dots,n-1\\}$ 的有向图的邻接表表示 $A$，该算法为所有节点 $i \\in V$ 计算其入度 $d_{\\mathrm{in}}(i)$、出度 $d_{\\mathrm{out}}(i)$ 和如上定义的互惠邻居重叠大小 $s(i)$。\n- 该算法的核心计算必须仅使用邻接表，而非邻接矩阵。\n- 从邻接表和度的基本定义出发，根据边的总数 $m$ 和最大度 $\\Delta_{\\max}$ 分析算法的时间复杂度。\n\n为确保通用适用性和可测试性，请使用以下图测试套件。每个测试用例指定了节点数 $n$ 和一个包含 $n$ 个条目的邻接表 $A$。对于没有出边的节点索引 $i$，请包含一个空列表。所有节点索引均从零开始。\n\n测试套件：\n- 测试用例 1（混合了互惠调控和单向调控的一般情况）：\n  - $n = 5$\n  - $A[0] = [1, 2]$, $A[1] = [2, 3]$, $A[2] = [0, 3]$, $A[3] = [2]$, $A[4] = [0, 3]$\n- 测试用例 2（没有边的边界情况）：\n  - $n = 3$\n  - $A[0] = []$, $A[1] = []$, $A[2] = []$\n- 测试用例 3（包含自环和孤立节点的边缘情况）：\n  - $n = 4$\n  - $A[0] = [0, 1]$, $A[1] = [1, 2]$, $A[2] = []$, $A[3] = [3]$\n- 测试用例 4（具有互惠边的高出度中心节点，用于测试 $\\Delta_{\\max}$ 的影响）：\n  - $n = 6$\n  - $A[0] = [1, 2, 3, 4, 5]$, $A[1] = [0]$, $A[2] = [0]$, $A[3] = [0]$, $A[4] = [0]$, $A[5] = [0]$\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含所有测试用例的结果。结果为一个逗号分隔的列表，并用方括号括起来。每个测试用例的结果本身是一个形式为 $[D_{\\mathrm{in}}, D_{\\mathrm{out}}, S, m, \\Delta_{\\max}]$ 的列表。\n- 此处，$D_{\\mathrm{in}}$ 是入度列表 $[d_{\\mathrm{in}}(0), d_{\\mathrm{in}}(1), \\dots, d_{\\mathrm{in}}(n-1)]$，$D_{\\mathrm{out}}$ 是出度列表 $[d_{\\mathrm{out}}(0), d_{\\mathrm{out}}(1), \\dots, d_{\\mathrm{out}}(n-1)]$，$S$ 是互惠邻居重叠大小列表 $[s(0), s(1), \\dots, s(n-1)]$，$m$ 是整数形式的边总数，$\\Delta_{\\max}$ 是整数形式的最大度。\n- 例如，程序应打印出结构为 $[[\\dots],[\\dots],[\\dots],[\\dots]]$ 的单行，其中每个内部列表是按指定格式表示的一个测试用例的结果。\n\n注意：\n- 不涉及物理单位。\n- 角度单位不适用。\n- 所有数值结果均以标准十进制表示法表示为整数。",
            "solution": "对用户提供的问题进行了严格的验证过程。\n\n### 步骤 1：提取已知信息\n\n- **图模型**：一个有向基因调控网络被建模为一个图，其节点集为 $V = \\{0, 1, \\dots, n-1\\}$，有向边集为 $E$。\n- **表示方法**：该图由一个邻接表 $A$ 给出，其中 $A[i]$ 包含每个节点 $i$ 的出邻居集合 $N_{\\mathrm{out}}(i)$。\n- **边处理**：$A[i]$ 中的重复边将被忽略。允许自环 $(i,i)$。\n- **定义**：\n    - 出度：$d_{\\mathrm{out}}(i) = |N_{\\mathrm{out}}(i)|$。\n    - 入邻居集合：$N_{\\mathrm{in}}(i) = \\{j \\in V \\mid (j,i) \\in E\\}$。\n    - 入度：$d_{\\mathrm{in}}(i) = |N_{\\mathrm{in}}(i)|$。\n    - 互惠邻居重叠大小：$s(i) = |N_{\\mathrm{out}}(i) \\cap N_{\\mathrm{in}}(i)|$。\n    - 有向边的总数：$m = |E|$。\n    - 最大度：$\\Delta_{\\max} = \\max_{i \\in V} \\{\\max(d_{\\mathrm{out}}(i), d_{\\mathrm{in}}(i))\\}$。\n- **任务**：\n    1.  设计一个算法，根据邻接表 $A$ 计算所有 $i \\in V$ 的 $d_{\\mathrm{in}}(i)$、$d_{\\mathrm{out}}(i)$ 和 $s(i)$，以及 $m$ 和 $\\Delta_{\\max}$。\n    2.  算法的核心计算必须使用邻接表，而非邻接矩阵。\n    3.  根据 $m$ 和 $\\Delta_{\\max}$ 分析算法的时间复杂度。\n- **测试套件**：提供了四个具体的测试用例，每个用例都给定了节点数 $n$ 和一个邻接表 $A$。\n- **输出格式**：单行输出，包含每个测试用例结果的逗号分隔列表。每个测试用例的结果必须是 $[D_{\\mathrm{in}}, D_{\\mathrm{out}}, S, m, \\Delta_{\\max}]$ 形式的列表，其中 $D_{\\mathrm{in}}$、$D_{\\mathrm{out}}$ 和 $S$ 是每个节点的度量指标列表。\n\n### 步骤 2：使用提取的已知信息进行验证\n\n根据验证标准对问题进行评估。\n\n- **科学依据**：该问题具有充分的科学依据。基于图的调控网络模型是计算系统生物学的基石。所有定义（$d_{\\mathrm{in}}, d_{\\mathrm{out}}$ 等）都是图论中的标准定义。此标准已满足。\n- **适定性**：该问题是适定的。输入（邻接表 $A$，节点数 $n$）定义清晰，所需输出（$D_{\\mathrm{in}}$, $D_{\\mathrm{out}}$, $S$, $m$, $\\Delta_{\\max}$）由数学定义明确规定。对于任何给定的输入，都存在唯一的解。此标准已满足。\n- **客观性**：该问题以客观的数学语言陈述，没有歧义或主观论断。此标准已满足。\n\n该问题没有任何使其无效的缺陷。它在科学上是合理的、可形式化的、完整的，并且是算法上可解的。\n\n### 步骤 3：结论与行动\n\n该问题被判定为**有效**。将提供一个解决方案。\n\n### 算法设计与分析\n\n目标是根据给定的包含 $n$ 个节点的有向图的邻接表表示 $A$，计算五个图论度量指标。任务的核心是设计一个高效的算法，该算法按要求避免使用邻接矩阵所带来的 $O(n^2)$ 空间复杂度。\n\n**1. 数据结构预处理**\n\n输入是一个邻接表 $A$，其中每个 $A[i]$ 是一个出邻居列表。问题规定应忽略重复的边。强制实现唯一性并实现高效查找的最有效方法是将每个列表 $A[i]$ 转换为哈希集。我们构建一个新的数据结构 `A_sets`，它是一个集合列表，其中 `A_sets[i]` 存储节点 $i$ 的唯一出邻居。此预处理步骤会遍历原始邻接表中的所有条目。如果（包括重复项在内的）条目总数为 $M_{raw}$，则此步骤需要 $O(M_{raw})$ 的时间。\n\n**2. 计算出度（$d_{\\mathrm{out}}$）和总边数（$m$）**\n\n一旦我们有了集合列表 `A_sets`，每个节点 $i$ 的出度 $d_{\\mathrm{out}}(i)$ 就是集合 `A_sets[i]` 的大小。这可以在 $O(n)$ 时间内为所有节点计算出来。唯一有向边的总数 $m$ 是所有出度的总和：$m = \\sum_{i=0}^{n-1} d_{\\mathrm{out}}(i)$。在知道所有出度后，这个总和可以在 $O(n)$ 时间内计算出来。\n\n**3. 计算入度（$d_{\\mathrm{in}}$）**\n\n给定的邻接表直接提供了出邻居。要计算入度，我们必须确定对于每个节点 $j$，有多少个其他节点 $i$ 存在边 $(i,j)$。我们可以通过一次遍历所有边来计算所有入度，而无需构建完整的反向图。我们初始化一个大小为 $n$、元素全为零的入度数组 `d_in`。然后，我们遍历从 $0$ 到 $n-1$ 的每个节点 $i$，并对于其每个出邻居 $j \\in \\text{A\\_sets}[i]$，我们增加节点 $j$ 的入度计数器，即 `d_in[j]++`。这个过程恰好接触每条唯一的边一次，因此其时间复杂度为 $O(m)$。\n\n**4. 计算互惠邻居重叠大小（$s(i)$）**\n\n节点 $i$ 的互惠邻居重叠大小定义为 $s(i) = |N_{\\mathrm{out}}(i) \\cap N_{\\mathrm{in}}(i)|$。一个等效的定义是同时存在边 $(i, j)$ 和边 $(j, i)$ 的节点 $j$ 的数量。基于此可以设计一个直接且高效的算法。我们初始化一个大小为 $n$、元素全为零的重叠大小数组 `s`。然后，我们遍历每个节点 $i$ 及其每个出邻居 $j \\in \\text{A\\_sets}[i]$，检查是否存在反向边 $(j, i)$。这个检查等效于测试 $i$ 是否在节点 $j$ 的出邻居集合中，即 `i in A_sets[j]`。因为 `A_sets[j]` 是一个哈希集，这个检查的平均时间复杂度为 $O(1)$。如果条件为真，我们增加 `s[i]` 的计数器。这个过程也涉及遍历所有唯一的边，因此计算所有 $s(i)$ 值的总时间复杂度为 $O(m)$。\n\n**5. 计算最大度（$\\Delta_{\\max}$）**\n\n在计算完所有入度列表 $D_{\\mathrm{in}}$ 和出度列表 $D_{\\mathrm{out}}$ 之后，通过取这两个列表中存在的最大值来找到最大度 $\\Delta_{\\max}$。这需要对两个列表进行单次遍历，耗时 $O(n)$。\n\n**6. 时间复杂度分析**\n\n算法的总体时间复杂度是其各个组成步骤复杂度的总和：\n- 将 $A$ 预处理为 `A_sets`：$O(M_{raw})$，其中 $M_{raw}$ 是 $A$ 中原始条目的数量。\n- 计算所有 $d_{\\mathrm{out}}(i)$：$O(n)$。\n- 计算所有 $d_{\\mathrm{in}}(i)$：$O(m)$。\n- 计算所有 $s(i)$：平均时间复杂度为 $O(m)$。\n- 计算 $m$ 和 $\\Delta_{\\max}$：$O(n)$。\n\n总时间复杂度为 $O(M_{raw} + n + m)$。由于唯一边的数量 $m$ 最多为 $M_{raw}$，因此可以简化为 $O(M_{raw} + n)$。如果假设输入没有重复项，则 $M_{raw} = m$，复杂度为 $O(n+m)$。\n\n问题要求用 $m$ 和 $\\Delta_{\\max}$ 来表示复杂度。边的数量 $m$ 与最大度 $\\Delta_{\\max}$ 通过不等式 $m = \\sum_{i \\in V} d_{\\mathrm{out}}(i) \\le n \\cdot \\Delta_{\\max}$ 相关联。因此，$O(n+m)$ 的复杂度可以用一个上界 $O(n + n \\cdot \\Delta_{\\max}) = O(n \\cdot \\Delta_{\\max})$ 来表示。这个界限正确地反映了算法对节点数和由 $\\Delta_{\\max}$ 表征的图密度的依赖性。空间复杂度为 $O(n+m)$，用于存储清理后的邻接集和结果数组。这符合避免使用邻接矩阵的约束。",
            "answer": "```python\nimport numpy as np\n\ndef calculate_metrics(n, adj_list):\n    \"\"\"\n    Computes graph metrics for a given directed graph.\n\n    Args:\n        n (int): The number of nodes in the graph.\n        adj_list (list of lists): The adjacency list representation of the graph.\n\n    Returns:\n        list: A list containing [D_in, D_out, S, m, Delta_max].\n    \"\"\"\n    if n == 0:\n        return [[], [], [], 0, 0]\n\n    # Step 1: Pre-process adjacency list to handle duplicates and for efficient lookups.\n    # A_sets[i] will store the unique out-neighbors of node i.\n    A_sets = [set(neighbors) for neighbors in adj_list]\n\n    # Step 2: Compute out-degrees.\n    d_out = [len(s) for s in A_sets]\n\n    # Initialize arrays for in-degrees and reciprocal overlap sizes.\n    d_in = [0] * n\n    s = [0] * n\n    \n    # Step 3  4: Compute in-degrees and reciprocal overlaps.\n    # Iterate through each edge (i,j) to update d_in for j and s for i.\n    for i in range(n):\n        for j in A_sets[i]:\n            # Each j is an out-neighbor of i, so this is an edge (i, j).\n            # This contributes to the in-degree of j.\n            d_in[j] += 1\n            \n            # Check for the reciprocal edge (j, i) to calculate s(i).\n            # This check is efficient due to the use of sets.\n            if i in A_sets[j]:\n                s[i] += 1\n\n    # Step 5: Compute total number of edges m.\n    m = sum(d_out)\n\n    # Step 6: Compute maximum degree Delta_max.\n    delta_max = 0\n    if n > 0:\n        max_out = max(d_out) if d_out else 0\n        max_in = max(d_in) if d_in else 0\n        delta_max = max(max_out, max_in)\n\n    return [d_in, d_out, s, m, delta_max]\n\ndef solve():\n    \"\"\"\n    Runs the validation and computation for the problem's test suite.\n    \"\"\"\n    test_cases = [\n        (5, [[1, 2], [2, 3], [0, 3], [2], [0, 3]]),\n        (3, [[], [], []]),\n        (4, [[0, 1], [1, 2], [], [3]]),\n        (6, [[1, 2, 3, 4, 5], [0], [0], [0], [0], [0]])\n    ]\n\n    results = []\n    for n, A in test_cases:\n        result = calculate_metrics(n, A)\n        results.append(result)\n\n    # Format the final output string exactly as required.\n    # The default str() representation of a list is used, e.g., '[1, 2, 3]'.\n    # A comma is used to join the string representations of each test case result.\n    final_output = f\"[{','.join(map(str, results))}]\"\n    \n    # Python's str() adds spaces after commas in lists. Let's remove them for a compact representation.\n    final_output = final_output.replace(\" \", \"\")\n    print(final_output)\n\nsolve()\n\n```"
        },
        {
            "introduction": "在系统生物学中，我们常需处理充满噪声的密集交互网络，网络稀疏化是简化分析的关键预处理步骤。这个实践要求您实现一个基于阈值的稀疏化过程，将一个稠密的邻接矩阵压缩为邻接表，并从数学上分析该近似操作引入的误差。此练习将计算实践与严格的矩阵范数理论相结合，让您学会如何量化数据转换所带来的影响。",
            "id": "3332692",
            "problem": "考虑一个有向加权的生物分子相互作用网络（例如，转录因子对基因的影响），该网络由一个稠密邻接矩阵 $W \\in \\mathbb{R}^{n \\times n}$ 表示，其中每个条目 $w_{ij}$ 表示从节点 $i$ 到节点 $j$ 的带符号影响强度。每个有序对 $(i,j)$ 还带有一个分类边属性 $a_{ij} \\in \\mathbb{Z}$（例如，$a_{ij} = 1$ 表示激活，$a_{ij} = -1$ 表示抑制，$a_{ij} = 0$ 表示缺失或未知），该属性在一个并行的属性矩阵 $A \\in \\mathbb{Z}^{n \\times n}$ 中提供。该网络将通过使用阈值 $\\tau \\in \\mathbb{R}_{\\ge 0}$ 丢弃小幅值的影响来进行稀疏化。\n\n从网络邻接矩阵和矩阵范数的基础定义出发，设计并实现一个程序，该程序能够：\n1. 将 $W$ 和 $A$ 转换为一个压缩邻接列表，该列表仅包含稀疏化后保留的边，并保留其属性。使用规则“如果 $|w_{ij}|  \\tau$ 且 $w_{ij} \\neq 0$ 则丢弃；否则保留”，这样恰好等于 $\\tau$ 的边将被保留，而零值不会被列出。\n2. 通过将所有被阈值丢弃的条目置零来形成稀疏化矩阵 $W^{(\\tau)}$，即如果 $|w_{ij}| \\ge \\tau$ 且 $w_{ij} \\neq 0$，则 $w^{(\\tau)}_{ij} = w_{ij}$，否则 $w^{(\\tau)}_{ij} = 0$。\n3. 推导并计算基于阈值的稀疏化在弗罗贝尼乌斯范数下引入的矩阵近似误差的上界，并验证一个通用的谱范数不等式。具体来说，令 $E = W - W^{(\\tau)}$ 表示误差矩阵。令 $m$ 表示被丢弃的非零条目的数量（即满足 $w_{ij} \\neq 0$ 且 $|w_{ij}|  \\tau$ 的 $(i,j)$ 的计数）。证明\n$$\\lVert E \\rVert_F^2 = \\sum_{(i,j):\\, |w_{ij}|  \\tau} w_{ij}^2 \\le \\sum_{(i,j):\\, |w_{ij}|  \\tau} \\tau^2 = m \\tau^2,$$\n并因此得出\n$$\\lVert E \\rVert_F \\le \\sqrt{m}\\,\\tau.$$\n同时，论证并计算\n$$\\lVert E \\rVert_2 \\le \\lVert E \\rVert_F,$$\n其中 $\\lVert \\cdot \\rVert_2$ 是由欧几里得向量范数诱导的谱范数，$\\lVert \\cdot \\rVert_F$ 是弗罗贝尼乌斯范数。\n\n您的程序必须为保留的边构建四元组 $(i,j,w_{ij},a_{ij})$ 的压缩邻接列表，计算 $m$、$\\lVert E \\rVert_F$、上界 $\\sqrt{m}\\,\\tau$ 和 $\\lVert E \\rVert_2$，并通过生成布尔值来验证这两个不等式。属性保留必须通过检查邻接列表中的每个保留边的属性 $a_{ij}$ 是否等于 $A$ 中相应的条目来验证。\n\n使用以下测试套件。每个案例明确提供了 $(W,A,\\tau)$。所有数值条目都是无量纲的，不涉及角度。\n\n测试案例 1（正常路径，混合符号，中等阈值）：\n$$\nW_1 =\n\\begin{bmatrix}\n0  0.21  -0.05  0.11 \\\\\n0.03  0  0.41  -0.12 \\\\\n-0.21  0.08  0  0.07 \\\\\n0.15  -0.09  0.20  0\n\\end{bmatrix},\\quad\nA_1 =\n\\begin{bmatrix}\n0  1  -1  1 \\\\\n1  0  1  -1 \\\\\n-1  1  0  1 \\\\\n1  -1  1  0\n\\end{bmatrix},\\quad\n\\tau_1 = 0.15.\n$$\n\n测试案例 2（边界情况，$\\tau = 0$ 保留所有非零边）：\n$$\nW_2 =\n\\begin{bmatrix}\n0  -0.20  0 \\\\\n0.18  0  0.05 \\\\\n0  -0.04  0\n\\end{bmatrix},\\quad\nA_2 =\n\\begin{bmatrix}\n0  -1  0 \\\\\n1  0  1 \\\\\n0  -1  0\n\\end{bmatrix},\\quad\n\\tau_2 = 0.\n$$\n\n测试案例 3（边缘情况，阈值超过所有权重，丢弃所有非零边）：\n$$\nW_3 =\n\\begin{bmatrix}\n0  0.30  -0.10  0  0.20 \\\\\n-0.25  0  0.05  -0.40  0 \\\\\n0.10  -0.20  0  0.30  -0.05 \\\\\n0  0  -0.15  0  0.10 \\\\\n-0.20  0.25  0  -0.05  0\n\\end{bmatrix},\\quad\nA_3 =\n\\begin{bmatrix}\n0  1  -1  0  1 \\\\\n-1  0  1  -1  0 \\\\\n1  -1  0  1  -1 \\\\\n0  0  -1  0  1 \\\\\n-1  1  0  -1  0\n\\end{bmatrix},\\quad\n\\tau_3 = 0.5.\n$$\n\n对于每个测试案例，您的程序必须按顺序输出一个包含以下条目的列表：\n- 保留边的整数数量 $k$，\n- 被丢弃的非零条目的整数数量 $m$，\n- 浮点数值 $\\lVert E \\rVert_F$，\n- 浮点上界值 $\\sqrt{m}\\,\\tau$，\n- 浮点数值 $\\lVert E \\rVert_2$，\n- 一个布尔值，指示是否 $\\lVert E \\rVert_F \\le \\sqrt{m}\\,\\tau$，\n- 一个布尔值，指示是否 $\\lVert E \\rVert_2 \\le \\lVert E \\rVert_F$，\n- 一个布尔值，指示在压缩邻接列表中属性是否被完全保留。\n\n您的程序应生成单行输出，其中包含一个逗号分隔的列表，该列表包含在方括号内，每个测试案例一个列表，顺序排列，例如 $[\\text{case1},\\text{case2},\\text{case3}]$，其中每个 $\\text{case}$ 本身是如上所述的列表。",
            "solution": "所提出的问题是计算网络分析和线性代数中一个定义明确的练习，其基础是系统生物学的既定实践。它要求实现一个基于阈值的网络稀疏化过程，并验证与矩阵范数相关的标准数学不等式。该问题是自包含的、科学上合理的，并且所有提供的数据和条件都是一致的。因此，我们可以进行形式化的求解。\n\n问题的核心是分析对由邻接矩阵 $W \\in \\mathbb{R}^{n \\times n}$ 表示的加权有向网络进行稀疏化的后果。稀疏化是通过消除影响强度 $w_{ij}$ 低于某个幅值阈值 $\\tau \\in \\mathbb{R}_{\\ge 0}$ 的边来实现的。还必须处理一个相关的属性矩阵 $A \\in \\mathbb{Z}^{n \\times n}$。\n\n该过程可以分解为以下逻辑步骤：\n\n**1. 网络稀疏化和邻接列表生成**\n\n网络由邻接矩阵 $W$ 和属性矩阵 $A$ 定义。稀疏化规则是，如果边的权重 $w_{ij}$ 满足 $0  |w_{ij}|  \\tau$，则丢弃该边 $(i, j)$。权重满足 $|w_{ij}| \\ge \\tau$ 的边被保留，权重 $w_{ij} = 0$ 的条目（表示不存在边，并保持原样）也被保留。\n\n首先，我们构建稀疏化的邻接列表。此列表将仅包含保留的边，即那些权重满足 $|w_{ij}| \\ge \\tau$ 的边。对于每个这样的边，我们存储一个四元组 $(i, j, w_{ij}, a_{ij})$，其中 $i$ 是源节点索引，$j$ 是目标节点索引，$w_{ij}$ 是来自 $W$ 的权重，$a_{ij}$ 是来自 $A$ 的相应属性。保留边的总数用 $k$ 表示。\n\n同时，我们识别被丢弃的非零边集。这些是满足 $0  |w_{ij}|  \\tau$ 的边。我们对这些边进行计数，该计数用 $m$ 表示。\n\n**2. 误差矩阵的构建**\n\n稀疏化过程将原始矩阵 $W$ 转换为稀疏化矩阵 $W^{(\\tau)}$。$W^{(\\tau)}$ 的条目定义为：\n$$\nw^{(\\tau)}_{ij} =\n\\begin{cases}\nw_{ij}  \\text{if } |w_{ij}| \\ge \\tau \\\\\n0  \\text{if } |w_{ij}|  \\tau\n\\end{cases}\n$$\n这个定义正确地处理了 $w_{ij} = 0$ 的情况，它在 $W^{(\\tau)}$ 中仍然为 $0$。此过程引入的近似误差由误差矩阵 $E = W - W^{(\\tau)}$ 捕获。$E$ 的条目是 $e_{ij} = w_{ij} - w^{(\\tau)}_{ij}$。根据 $W^{(\\tau)}$ 的定义，误差矩阵的条目是：\n$$\ne_{ij} =\n\\begin{cases}\n0  \\text{if } |w_{ij}| \\ge \\tau \\text{ or } w_{ij} = 0 \\\\\nw_{ij}  \\text{if } 0  |w_{ij}|  \\tau\n\\end{cases}\n$$\n因此，$E$ 的非零条目恰好是被丢弃边的权重。\n\n**3. 弗罗贝尼乌斯范数误差界的推导**\n\n问题要求我们证明 $\\lVert E \\rVert_F \\le \\sqrt{m}\\,\\tau$，其中 $\\lVert \\cdot \\rVert_F$ 是弗罗贝尼乌斯范数。矩阵 $E$ 的弗罗贝尼乌斯范数定义为其元素平方和的平方根：$\\lVert E \\rVert_F = \\sqrt{\\sum_{i,j} |e_{ij}|^2}$。\n\n让我们从弗罗贝尼乌斯范数的平方 $\\lVert E \\rVert_F^2$ 开始：\n$$\n\\lVert E \\rVert_F^2 = \\sum_{i=1}^n \\sum_{j=1}^n e_{ij}^2\n$$\n根据 $E$ 的定义，该和仅对 $m$ 个被丢弃的边集合非零，其中 $e_{ij} = w_{ij}$。\n$$\n\\lVert E \\rVert_F^2 = \\sum_{(i,j):\\, 0  |w_{ij}|  \\tau} w_{ij}^2\n$$\n这就证明了我们被要求证明的恒等式的第一部分。对于这个和中的每一项，成为被丢弃边的条件是 $0  |w_{ij}|  \\tau$，这意味着 $w_{ij}^2  \\tau^2$。通过将每一项 $w_{ij}^2$ 替换为更大的值 $\\tau^2$，我们得到了该和的一个上界。因为恰好有 $m$ 个这样的项：\n$$\n\\sum_{(i,j):\\, 0  |w_{ij}|  \\tau} w_{ij}^2 \\le \\sum_{k=1}^m \\tau^2 = m\\tau^2\n$$\n问题陈述使用了一个非严格不等式 $\\lVert E \\rVert_F^2 \\le m\\tau^2$，这是一个有效的且更通用的上界。对两边取平方根（并且由于范数是非负的）得到期望的结果：\n$$\n\\lVert E \\rVert_F \\le \\sqrt{m\\tau^2} = \\sqrt{m}\\,\\tau\n$$\n\n**4. 谱范数不等式的论证**\n\n我们还必须论证众所周知的矩阵范数不等式 $\\lVert E \\rVert_2 \\le \\lVert E \\rVert_F$，其中 $\\lVert \\cdot \\rVert_2$ 是谱范数。矩阵 $E$ 的谱范数定义为其最大奇异值，$\\sigma_{\\max}(E)$。弗罗贝尼乌斯范数也可以用矩阵的奇异值 $\\{\\sigma_k\\}$ 来表示：\n$$\n\\lVert E \\rVert_F^2 = \\sum_{k=1}^{\\text{rank}(E)} \\sigma_k(E)^2\n$$\n谱范数的平方就是最大奇异值的平方：\n$$\n\\lVert E \\rVert_2^2 = (\\sigma_{\\max}(E))^2\n$$\n由于所有奇异值都是非负的，它们的平方和必须大于或等于任何单个奇异值的平方，包括最大的那个：\n$$\n(\\sigma_{\\max}(E))^2 \\le \\sum_{k=1}^{\\text{rank}(E)} \\sigma_k(E)^2\n$$\n将范数定义代回得到：\n$$\n\\lVert E \\rVert_2^2 \\le \\lVert E \\rVert_F^2\n$$\n由于范数是非负的，我们可以对两边取平方根，得到最终的不等式：\n$$\n\\lVert E \\rVert_2 \\le \\lVert E \\rVert_F\n$$\n这个不等式对任何矩阵 $E$ 都成立，我们将对测试案例生成的误差矩阵进行计算验证。\n\n**5. 属性保留检查**\n\n最后的任务是验证保留边的属性在生成的邻接列表中是否被正确保留。这是一个关键的数据完整性检查。对于生成列表中的每个四元组 $(i, j, w_{ij}, a'_{ij})$，我们将验证存储的属性 $a'_{ij}$ 与输入属性矩阵中的原始属性 $A_{ij}$ 相同。如果这对所有 $k$ 个保留边都成立，则检查成功。\n\n实现将为每个测试案例执行这些计算，并报告所要求的量：$k$、$m$、$\\lVert E \\rVert_F$、$\\sqrt{m}\\,\\tau$、$\\lVert E \\rVert_2$，以及两个不等式检查和属性保留验证的布尔结果。",
            "answer": "```python\nimport numpy as np\n\ndef solve_case(W: np.ndarray, A: np.ndarray, tau: float):\n    \"\"\"\n    Processes a single test case for network sparsification and error analysis.\n\n    Args:\n        W: The weight matrix (n x n).\n        A: The attribute matrix (n x n).\n        tau: The sparsification threshold.\n\n    Returns:\n        A list containing the eight required output values for the case.\n    \"\"\"\n    n = W.shape[0]\n    adj_list = []\n    k = 0  # Number of retained edges\n    m = 0  # Number of dropped nonzero entries\n    E = np.zeros_like(W, dtype=float)\n\n    for i in range(n):\n        for j in range(n):\n            weight = W[i, j]\n            # An edge is a non-zero weight.\n            if weight != 0:\n                abs_weight = np.abs(weight)\n                if abs_weight >= tau:\n                    # Retained edge\n                    k += 1\n                    adj_list.append((i, j, weight, A[i, j]))\n                else: # 0  abs_weight  tau\n                    # Dropped nonzero edge\n                    m += 1\n                    E[i, j] = weight\n    \n    # Compute norms\n    frobenius_norm_E = np.linalg.norm(E, 'fro')\n    spectral_norm_E = np.linalg.norm(E, 2)\n    \n    # Compute upper bound for the Frobenius norm\n    bound_frobenius = np.sqrt(m) * tau if m > 0 else 0.0\n\n    # Verify inequalities\n    # Using np.isclose for robust floating-point comparison\n    inequality1_verified = frobenius_norm_E = bound_frobenius or np.isclose(frobenius_norm_E, bound_frobenius)\n    inequality2_verified = spectral_norm_E = frobenius_norm_E or np.isclose(spectral_norm_E, frobenius_norm_E)\n\n    # Verify attribute preservation\n    attributes_preserved = True\n    if not adj_list: # Vacuously true if no edges are retained\n        attributes_preserved = True\n    else:\n        for src, dst, w, attr in adj_list:\n            if attr != A[src, dst]:\n                attributes_preserved = False\n                break\n    \n    return [\n        k, \n        m, \n        float(frobenius_norm_E), \n        float(bound_frobenius), \n        float(spectral_norm_E), \n        inequality1_verified, \n        inequality2_verified, \n        attributes_preserved\n    ]\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        (\n            np.array([\n                [0, 0.21, -0.05, 0.11],\n                [0.03, 0, 0.41, -0.12],\n                [-0.21, 0.08, 0, 0.07],\n                [0.15, -0.09, 0.20, 0]\n            ]),\n            np.array([\n                [0, 1, -1, 1],\n                [1, 0, 1, -1],\n                [-1, 1, 0, 1],\n                [1, -1, 1, 0]\n            ]),\n            0.15\n        ),\n        (\n            np.array([\n                [0, -0.20, 0],\n                [0.18, 0, 0.05],\n                [0, -0.04, 0]\n            ]),\n            np.array([\n                [0, -1, 0],\n                [1, 0, 1],\n                [0, -1, 0]\n            ]),\n            0.0\n        ),\n        (\n            np.array([\n                [0, 0.30, -0.10, 0, 0.20],\n                [-0.25, 0, 0.05, -0.40, 0],\n                [0.10, -0.20, 0, 0.30, -0.05],\n                [0, 0, -0.15, 0, 0.10],\n                [-0.20, 0.25, 0, -0.05, 0]\n            ]),\n            np.array([\n                [0, 1, -1, 0, 1],\n                [-1, 0, 1, -1, 0],\n                [1, -1, 0, 1, -1],\n                [0, 0, -1, 0, 1],\n                [-1, 1, 0, -1, 0]\n            ]),\n            0.5\n        )\n    ]\n\n    results = []\n    for W, A, tau in test_cases:\n        result = solve_case(W, A, tau)\n        results.append(result)\n\n    # Format the final output string exactly as required\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "本练习模拟了一个高级研究场景：如何整合来自不同实验、可能相互矛盾的数据来构建一个一致的生物网络模型。您将通过定义和优化一个一致性目标函数来解决这个问题，该函数旨在奖励与高可靠性数据源的一致性，同时通过稀疏性惩罚来控制模型复杂度。这个实践将向您展示如何将复杂的生物学问题转化为一个可解的数学优化问题，并推导出最优的决策规则。",
            "id": "3332735",
            "problem": "考虑一个具有 $n$ 个节点（分子）的有符号有向分子相互作用网络，其中每个数据源 $k \\in \\{1,\\dots,K\\}$ 提供一个有符号边集，该边集以邻接表 (AL) 或有符号邻接矩阵 (AM) 的形式编码。在一个有符号网络中，一条边 $(i,j)$ 带有一个值 $A_{ij}^{(k)} \\in \\{-1,0,+1\\}$，分别表示抑制 ($-1$)、缺失或未知 ($0$) 或激活 ($+1$)。每个数据源被分配一个非负可靠性权重 $w_k \\in \\mathbb{R}_{\\ge 0}$。目标是通过优化一个一致性目标函数，将来自不同数据源的冲突边符号整合到一个单一的有符号邻接矩阵 $S \\in \\{-1,0,+1\\}^{n \\times n}$ 中。该目标函数奖励与数据源的一致性，同时通过惩罚边的包含来强制稀疏性。\n\n基本依据与定义：\n- 一个有符号邻接矩阵 $A^{(k)} \\in \\{-1,0,+1\\}^{n \\times n}$ 代表数据源 $k$ 的一个有向有符号图，其中 $A^{(k)}_{ij}$ 是从节点 $i$ 到节点 $j$ 的边的符号，并且对所有 $i$ 都有 $A^{(k)}_{ii} = 0$。\n- 数据源 $k$ 的邻接表 (AL) 是一组有序三元组 $(i,j,s)$，其中 $i \\neq j$，$0 \\le i,j  n$ 且 $s \\in \\{-1,+1\\}$，表示 $A^{(k)}_{ij} = s$。任何未列出的 $(i,j)$ 对应的 $A^{(k)}_{ij} = 0$。\n- 设边 $(i,j)$ 的聚合投票为 $v_{ij} = \\sum_{k=1}^K w_k A^{(k)}_{ij}$。\n- 设整合后的有符号邻接矩阵为 $S$，其中 $S_{ij} \\in \\{-1,0,+1\\}$ 且对所有 $i$ 都有 $S_{ii} = 0$。\n\n待优化的一致性目标：\n定义目标函数\n$$\nJ(S) = \\sum_{i \\neq j} \\left( \\sum_{k=1}^K w_k \\, S_{ij} \\, A^{(k)}_{ij} \\;-\\; \\lambda \\, |S_{ij}| \\right),\n$$\n其中 $\\lambda \\in \\mathbb{R}_{\\ge 0}$ 是一个稀疏性参数，用于惩罚非零的整合边。问题在于设计一个算法，在给定 $n$、权重 $w_k$ 以及数据源边集（ALs 或 AMs）的条件下，构建一个能在 $S \\in \\{-1,0,+1\\}^{n \\times n}$ 空间上优化 $J(S)$ 的矩阵 $S$，并分析该算法关于 $n$、$K$ 和提供的总边数的计算复杂度。\n\n算法要求和输出规范：\n- 您的算法必须从第一性原理出发，使用上述定义，直接从数学目标构建 $S$，而不依赖任何预先指定的快捷公式。\n- 您的推导必须基于 $J(S)$ 的显式结构以及有符号邻接矩阵和列表的属性。\n- 最终程序必须为下面定义的固定测试套件实现该算法，并为每个测试用例生成整合后的矩阵 $S$，该矩阵应按行主序展平为一个包含 $n^2$ 个整数的列表。每个整数必须是 $-1$、$0$ 或 $+1$ 中的一个。\n- 每个输出中的对角线元素必须为 $0$，与 $S_{ii} = 0$ 一致。\n\n测试套件：\n使用以下四个测试用例，节点索引从 $0$ 开始，且对于边严格满足 $i \\neq j$。对于邻接表，任何未列出的边都视为 $0$。\n\n1. 包含冲突符号和中等稀疏性的正常路径：\n   - $n = 4$, $K = 3$, $\\lambda = 0.2$, 权重 $w = [0.6, 0.3, 0.1]$,\n   - 数据源 1 AL: $(0,1,+1)$, $(1,2,-1)$, $(2,3,+1)$, $(0,3,-1)$,\n   - 数据源 2 AL: $(0,1,-1)$, $(1,2,-1)$, $(3,2,-1)$, $(0,3,+1)$,\n   - 数据源 3 AL: $(0,1,+1)$, $(2,3,+1)$, $(0,3,-1)$.\n\n2. 强稀疏性的边界条件：\n   - $n = 4$, $K = 3$, $\\lambda = 0.75$, 权重 $w = [0.6, 0.3, 0.1]$,\n   - 数据源与测试 1 相同。\n\n3. 阈值处的边缘情况平局：\n   - $n = 4$, $K = 3$, $\\lambda = 0.4$, 权重 $w = [0.6, 0.3, 0.1]$,\n   - 数据源与测试 1 相同。\n\n4. 两个冲突源之间的高可靠性主导：\n   - $n = 3$, $K = 2$, $\\lambda = 0.0$, 权重 $w = [0.9, 0.1]$,\n   - 数据源 1 AL: $(0,1,-1)$, $(1,2,+1)$,\n   - 数据源 2 AL: $(0,1,+1)$, $(1,2,-1)$.\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。列表中的每个元素是一个测试用例的展平后的整合邻接矩阵 $S$，表示为一个由方括号括起来的、包含 $n^2$ 个整数的逗号分隔列表。例如，输出必须具有以下形式\n$$\n[\\,[s^{(1)}_0,\\dots,s^{(1)}_{n^2-1}],\\,[s^{(2)}_0,\\dots,s^{(2)}_{n^2-1}],\\,\\dots\\,],\n$$\n打印行中无空格。每个 $s^{(t)}_m$ 是 $\\{-1,0,+1\\}$ 中的一个整数。此问题不涉及物理单位或角度。程序不得读取任何外部输入。",
            "solution": "该问题已经过验证，被确定为计算系统生物学中一个良构的、有科学依据的问题。该问题是自洽的，提供了所有必要的参数和定义。目标函数在数学上是合理的，其优化是可解的。\n\n问题的核心是确定整合后的有符号邻接矩阵 $S \\in \\{-1, 0, +1\\}^{n \\times n}$，以最大化目标函数：\n$$\nJ(S) = \\sum_{i \\neq j} \\left( \\sum_{k=1}^K w_k \\, S_{ij} \\, A^{(k)}_{ij} \\;-\\; \\lambda \\, |S_{ij}| \\right)\n$$\n问题陈述将边 $(i, j)$ 的聚合投票定义为 $v_{ij} = \\sum_{k=1}^K w_k A^{(k)}_{ij}$。将此代入目标函数，我们得到：\n$$\nJ(S) = \\sum_{i \\neq j} \\left( v_{ij} \\, S_{ij} - \\lambda \\, |S_{ij}| \\right)\n$$\n该目标函数的结构是一系列项的总和，其中每一项 $J_{ij}(S_{ij}) = v_{ij} S_{ij} - \\lambda |S_{ij}|$ 仅依赖于矩阵 $S$ 的单个条目 $S_{ij}$。因此，我们可以通过为所有满足 $i \\neq j$ 的对 $(i, j)$ 独立地最大化每一项 $J_{ij}(S_{ij})$ 来最大化总目标 $J(S)$。对于所有对角元素，约束 $S_{ii} = 0$ 是固定的。\n\n对于每个非对角条目 $S_{ij}$，我们必须从集合 $\\{-1, 0, +1\\}$ 中选择一个值来最大化 $J_{ij}(S_{ij})$。我们可以通过对以下三种可能性分别计算 $J_{ij}$ 来分析此问题：\n$1$. 如果我们选择 $S_{ij} = +1$：\n$$\nJ_{ij}(+1) = v_{ij}(+1) - \\lambda |+1| = v_{ij} - \\lambda\n$$\n$2$. 如果我们选择 $S_{ij} = -1$：\n$$\nJ_{ij}(-1) = v_{ij}(-1) - \\lambda |-1| = -v_{ij} - \\lambda\n$$\n$3$. 如果我们选择 $S_{ij} = 0$：\n$$\nJ_{ij}(0) = v_{ij}(0) - \\lambda |0| = 0\n$$\n为了找到 $S_{ij}$ 的最优值，我们比较这三种结果。\n首先，考虑 $v_{ij} > 0$ 的情况。在这种情况下，$v_{ij} > -v_{ij}$，这意味着 $v_{ij} - \\lambda > -v_{ij} - \\lambda$。因此，$S_{ij}=+1$ 优于 $S_{ij}=-1$。现在的选择是在 $S_{ij}=+1$ 和 $S_{ij}=0$ 之间。如果 $J_{ij}(+1) > J_{ij}(0)$，即 $v_{ij} - \\lambda > 0$ 或 $v_{ij} > \\lambda$，我们选择 $S_{ij}=+1$。否则，我们选择 $S_{ij}=0$。\n\n其次，考虑 $v_{ij}  0$ 的情况。此时，$-v_{ij} > v_{ij}$，这意味着 $-v_{ij} - \\lambda > v_{ij} - \\lambda$。因此，$S_{ij}=-1$ 优于 $S_{ij}=+1$。选择是在 $S_{ij}=-1$ 和 $S_{ij}=0$ 之间。如果 $J_{ij}(-1) > J_{ij}(0)$，即 $-v_{ij} - \\lambda > 0$ 或 $v_{ij}  -\\lambda$，我们选择 $S_{ij}=-1$。否则，我们选择 $S_{ij}=0$。\n\n最后，如果 $v_{ij}=0$，则 $J_{ij}(+1) = -\\lambda$，$J_{ij}(-1) = -\\lambda$，而 $J_{ij}(0)=0$。由于问题规定 $\\lambda \\ge 0$，最大值为 $0$，在 $S_{ij}=0$ 时取得。\n\n在打破平局时需要特别考虑。如果 $v_{ij} = \\lambda$，那么 $J_{ij}(+1) = \\lambda - \\lambda = 0$，这等于 $J_{ij}(0)$。类似地，如果 $v_{ij} = -\\lambda$，那么 $J_{ij}(-1) = -(-\\lambda) - \\lambda = 0$，这也等于 $J_{ij}(0)$。在这些平局的情况下，选择 $S_{ij}=0$ 是标准惯例，这促进了惩罚项 $-\\lambda|S_{ij}|$ 所期望的稀疏性。\n\n综合这些观察，我们可以为每个 $i \\neq j$ 的 $S_{ij}$ 制定一个明确的决策规则：\n$$\nS_{ij} =\n\\begin{cases}\n+1  \\text{if } v_{ij} > \\lambda \\\\\n-1  \\text{if } v_{ij}  -\\lambda \\\\\n0   \\text{if } -\\lambda \\le v_{ij} \\le \\lambda\n\\end{cases}\n$$\n\n基于此推导，构建矩阵 $S$ 的算法如下：\n$1$. 初始化一个 $n \\times n$ 的聚合投票矩阵，记为 $V$，所有元素为零。条目 $V_{ij}$ 将存储值 $v_{ij}$。\n$2$. 对于每个权重为 $w_k$ 的数据源 $k \\in \\{1, \\dots, K\\}$：\n   a. 如果数据源以邻接表形式给出，则遍历每个指定的边 $(i, j, s)$。\n   b. 更新投票矩阵：$V_{ij} \\leftarrow V_{ij} + w_k \\cdot s$。\n$3$. 初始化 $n \\times n$ 的整合矩阵 $S$，所有元素为零。这自动满足了 $S_{ii}=0$ 的约束。\n$4$. 遍历投票矩阵 $V$ 的每个非对角条目 $(i, j)$ (即，对所有 $i \\neq j$ 的 $i, j$)：\n   a. 应用推导出的决策规则：如果 $V_{ij} > \\lambda$，设置 $S_{ij} = +1$；如果 $V_{ij}  -\\lambda$，设置 $S_{ij} = -1$。否则，$S_{ij}$ 保持为 $0$。\n$5$. 得到的矩阵 $S$ 就是优化目标函数 $J(S)$ 的解。\n\n该算法的计算复杂度可分析如下。设 $E_k$ 是数据源 $k$ 提供的边数，设 $E_{total} = \\sum_{k=1}^K E_k$ 是所有数据源的总边数。\n- 步骤 1：初始化 $n \\times n$ 的投票矩阵 $V$ 需要 $O(n^2)$ 时间。\n- 步骤 2：从所有以邻接表形式给出的数据源聚合投票，需要对所有提供的边进行单次遍历。这需要 $O(E_{total})$ 时间。\n- 步骤 3：初始化 $n \\times n$ 的解矩阵 $S$ 需要 $O(n^2)$ 时间。\n- 步骤 4：应用阈值规则需要遍历所有 $n^2-n$ 个非对角元素。此步骤需要 $O(n^2)$ 时间。\n主要步骤是矩阵的初始化和阈值处理，以及投票聚合。因此，总时间复杂度为 $O(n^2 + E_{total})$。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the network reconciliation problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        {\n            \"n\": 4, \"K\": 3, \"lambda\": 0.2, \"weights\": [0.6, 0.3, 0.1],\n            \"sources\": [\n                [(0, 1, 1), (1, 2, -1), (2, 3, 1), (0, 3, -1)],  # Source 1 AL\n                [(0, 1, -1), (1, 2, -1), (3, 2, -1), (0, 3, 1)], # Source 2 AL\n                [(0, 1, 1), (2, 3, 1), (0, 3, -1)]              # Source 3 AL\n            ]\n        },\n        {\n            \"n\": 4, \"K\": 3, \"lambda\": 0.75, \"weights\": [0.6, 0.3, 0.1],\n            \"sources\": [\n                [(0, 1, 1), (1, 2, -1), (2, 3, 1), (0, 3, -1)],\n                [(0, 1, -1), (1, 2, -1), (3, 2, -1), (0, 3, 1)],\n                [(0, 1, 1), (2, 3, 1), (0, 3, -1)]\n            ]\n        },\n        {\n            \"n\": 4, \"K\": 3, \"lambda\": 0.4, \"weights\": [0.6, 0.3, 0.1],\n            \"sources\": [\n                [(0, 1, 1), (1, 2, -1), (2, 3, 1), (0, 3, -1)],\n                [(0, 1, -1), (1, 2, -1), (3, 2, -1), (0, 3, 1)],\n                [(0, 1, 1), (2, 3, 1), (0, 3, -1)]\n            ]\n        },\n        {\n            \"n\": 3, \"K\": 2, \"lambda\": 0.0, \"weights\": [0.9, 0.1],\n            \"sources\": [\n                [(0, 1, -1), (1, 2, 1)],\n                [(0, 1, 1), (1, 2, -1)]\n            ]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        n = case[\"n\"]\n        lambda_param = case[\"lambda\"]\n        weights = case[\"weights\"]\n        sources = case[\"sources\"]\n\n        # Step 1  2: Initialize vote matrix and aggregate votes\n        # V_ij will store the aggregated vote v_ij\n        V = np.zeros((n, n), dtype=float)\n        for k, source_al in enumerate(sources):\n            w_k = weights[k]\n            for i, j, s in source_al:\n                V[i, j] += w_k * s\n\n        # Step 3  4: Initialize reconciled matrix S and apply decision rule\n        # S is initialized to zeros, satisfying S_ii = 0\n        S = np.zeros((n, n), dtype=int)\n        \n        # Apply the derived decision rule using vectorized numpy operations\n        # S_ij = +1 if v_ij > lambda\n        S[V > lambda_param] = 1\n        \n        # S_ij = -1 if v_ij  -lambda\n        S[V  -lambda_param] = -1\n        \n        # S_ij = 0 if -lambda = v_ij = lambda (already set by np.zeros)\n\n        # Flatten the resulting matrix S into a list in row-major order\n        flat_S = S.flatten().tolist()\n        results.append(flat_S)\n\n    # Format the final output according to the problem specification\n    # e.g., [[-1,0,...],[0,1,...]]\n    output_str = f\"[{','.join([f'[{\",\".join(map(str, r))}]' for r in results])}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}