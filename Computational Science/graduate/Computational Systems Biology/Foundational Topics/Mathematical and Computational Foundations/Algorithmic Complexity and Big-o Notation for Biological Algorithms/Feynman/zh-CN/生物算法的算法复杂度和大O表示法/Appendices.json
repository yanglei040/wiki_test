{
    "hands_on_practices": [
        {
            "introduction": "在计算生物学中，我们经常面临在计算效率和结果精确性之间的权衡。此练习将引导您探索隐马尔可夫模型（HMM）基因注释中的一个典型场景：比较精确但计算密集的维特比（Viterbi）算法与快速但为近似的集束搜索（Beam Search）算法。通过此实践，您将学习如何量化这种权衡，并根据预设的准确度要求，从数学上推导出启发式算法的关键参数，这是算法设计与工程中的一项核心技能。",
            "id": "3288378",
            "problem": "考虑一个用于基因注释的隐马尔可夫模型（HMM），其具有 $S$ 个隐状态和一个长度为 $T$ 的基因组观测序列。HMM 由状态的初始分布、一个转移概率矩阵和发射概率分布定义。Viterbi 解码通过对所有状态转移进行动态规划，计算给定观测值下最可能的隐状态序列。根据大O表示法的基本定义，算法成本是根据作为输入大小函数的基本算术或比较操作的数量来衡量的。在一个全连接的HMM中，在每个时间步 $t \\in \\{1,\\dots,T\\}$，针对每个目标状态的Viterbi递归会考虑所有 $S$ 个可能的前驱状态，从而导致渐近成本与 $O(T S^2)$ 成正比。集束搜索是一种启发式方法，它在每个时间步通过仅保留按部分路径得分排名的前 $b$ 个状态来对状态空间进行剪枝；转移仅从该集束评估到所有 $S$ 个目标状态，从而导致成本与 $O(T b S)$ 成正比，当 $b$ 独立于 $S$ 有界时，该成本简化为 $O(T S)$。\n\n为了保持解码准确率，剪枝后的集束必须在每一步都包含最优路径上的前驱状态。使用基于顺序统计量的概率排名模型来形式化准确率：令 $R_t$ 为在时间 $t$ 导致全局最优Viterbi路径的前驱状态的随机排名（在 $S$ 个状态中，排名1为最佳）。假设排名 $R_t$ 在时间 $t$ 上是独立同分布的（i.i.d.），并满足由 $p \\in (0,1)$ 参数化的几何尾部界，即对于整数 $r \\ge 0$，有 $\\mathbb{P}(R_t  r) = (1-p)^r$，并在 $S$ 处截断。这个尾部界与HMM解码中广泛使用的得分差距模型一致，在这些模型中，给定竞争者优于最优前驱的概率随排名呈指数衰减。在此模型下，在单一步骤中最优前驱处于前 $b$ 位之内的概率为 $\\mathbb{P}(R_t \\le b) = 1 - (1-p)^b$。假设在 $T$ 个步骤中是独立的，则最优路径在所有 $T$ 个步骤的剪枝后存活的概率是 $\\left(1 - (1-p)^b\\right)^T$。\n\n你的任务是：\n- 从动态规划递归和大O表示法的定义出发，依据第一性原理和定义推导出Viterbi算法的渐近成本 $O(T S^2)$ 和集束搜索的渐近成本 $O(T b S)$。\n- 使用上述概率排名模型，推导出最小整数集束宽度 $b(T,S,p,\\varepsilon)$，该宽度保证对于指定的准确率容差 $\\varepsilon \\in (0,1)$（以小数而非百分比表示），满足 $\\left(1 - (1-p)^b\\right)^T \\ge 1 - \\varepsilon$，且受约束 $b \\le S$。明确说明当不受约束的最小整数超过 $S$ 时如何选择 $b$。\n- 实现一个程序，对于以下参数值 $(T,S,p,\\varepsilon)$ 的测试套件，计算每种情况下的 $b$，并为每种情况返回一个数对，该数对由所选的 $b$ 和一个布尔值组成，该布尔值指示是否同时满足以下两个条件：准确率得到保证（即 $\\left(1 - (1-p)^b\\right)^T \\ge 1 - \\varepsilon$）以及渐近成本相对于 $O(T S^2)$ 有所降低（即 $b  S$，因此 $O(T b S) = o(T S^2)$）：\n    1. $T = 1000$, $S = 50$, $p = 0.3$, $\\varepsilon = 0.01$。\n    2. $T = 1$, $S = 1000$, $p = 0.3$, $\\varepsilon = 0.01$。\n    3. $T = 10000$, $S = 10000$, $p = 0.1$, $\\varepsilon = 0.1$。\n    4. $T = 500$, $S = 200$, $p = 0.25$, $\\varepsilon = 0.000001$。\n    5. $T = 1000$, $S = 500$, $p = 0.01$, $\\varepsilon = 0.01$。\n\n你的程序应该生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个元素本身都是一个形如 $[b,\\text{boolean}]$ 的双元素列表。例如，一个有效的输出格式是 $[[b_1,\\text{boolean}_1],[b_2,\\text{boolean}_2],\\dots]$。本问题不涉及物理单位。不使用角度。所有概率（如 $\\varepsilon$）都必须以小数形式提供和解释。",
            "solution": "该问题被评估为有效，因为它在科学上基于算法分析和概率建模的既定原则，是良定的、客观的，并包含获得唯一解所需的所有必要信息。\n\n### 第1部分：渐近成本的推导\n\n#### Viterbi 算法复杂度：$O(T S^2)$\n\nViterbi 算法用于在给定观测序列的情况下，找出最可能的隐状态序列。它是一种动态规划算法。设 $S$ 为隐状态的数量，$T$ 为观测序列的长度。设 $\\delta_t(j)$ 为长度为 $t$ 且结束于状态 $j$ 的最可能路径的概率。该算法的核心是以下递归关系：\n$$ \\delta_t(j) = \\left( \\max_{i=1,\\dots,S} \\left[ \\delta_{t-1}(i) \\cdot a_{ij} \\right] \\right) \\cdot e_j(o_t) \\quad \\text{for } j=1,\\dots,S \\text{ and } t=1,\\dots,T $$\n其中 $a_{ij}$ 是从状态 $i$ 到状态 $j$ 的转移概率，而 $e_j(o_t)$ 是从状态 $j$ 发射观测值 $o_t$ 的概率。\n\n为了分析计算成本，我们计算基本算术操作的数量。为了数值稳定性，计算通常在对数空间中进行，此时乘法变为加法。递归关系变为：\n$$ \\log \\delta_t(j) = \\left( \\max_{i=1,\\dots,S} \\left[ \\log \\delta_{t-1}(i) + \\log a_{ij} \\right] \\right) + \\log e_j(o_t) $$\n\n我们来分析单个时间步 $t$ 的成本：\n1.  为了计算单个目标状态 $j$ 的值，我们必须为每个可能的前驱状态 $i \\in \\{1, \\dots, S\\}$ 评估 $\\max$ 算子内的表达式。\n2.  对于每个 $i$，这涉及一次加法：$\\log \\delta_{t-1}(i) + \\log a_{ij}$。对于一个固定的 $j$，此操作将执行 $S$ 次。\n3.  然后，我们必须找到这 $S$ 个值的最大值。这需要 $S-1$ 次比较。\n4.  最后，再进行一次加法，以加上对数发射概率。\n5.  因此，对于每个目标状态 $j$，操作次数与 $S$（用于加法）加上 $S-1$（用于比较）成正比，即 $O(S)$。\n\n由于必须对所有 $S$ 个目标状态（$j=1, \\dots, S$）执行此计算，因此单个时间步 $t$ 的总成本为 $S \\times O(S) = O(S^2)$。\n\n这个过程对从 $t=1$ 到 $t=T$ 的每个时间步重复进行。根据大O表示法的定义，它描述了当输入大小（$T, S$）增长时的极限行为，总渐近成本是每个时间步的成本乘以时间步数。\n$$ \\text{Total Cost} = T \\times O(S^2) = O(T S^2) $$\n\n#### 集束搜索算法复杂度：$O(T b S)$\n\n集束搜索是一种通过剪枝搜索空间来降低复杂度的启发式方法。在每个时间步，它只保留一个由 $b$ 个最有利状态组成的“集束”，其中 $b$ 是集束宽度。\n\n设 $\\mathcal{B}_{t-1}$ 为在时间 $t-1$ 时具有最高得分 $\\delta_{t-1}(i)$ 的 $b$ 个状态的集合。递归关系被修改为仅考虑来自此集束内状态的转移：\n$$ \\log \\delta_t(j) = \\left( \\max_{i \\in \\mathcal{B}_{t-1}} \\left[ \\log \\delta_{t-1}(i) + \\log a_{ij} \\right] \\right) + \\log e_j(o_t) $$\n\n我们来分析单个时间步 $t$ 的成本：\n1.  为了计算单个目标状态 $j$ 的得分，我们现在只对集束 $\\mathcal{B}_{t-1}$ 中的 $b$ 个状态进行迭代。\n2.  这涉及 $b$ 次加法和找到 $b$ 个值的最大值（需要 $b-1$ 次比较）。因此，每个目标状态 $j$ 的成本为 $O(b)$。\n3.  这个计算对所有 $S$ 个可能的目标状态执行，因此计算时间 $t$ 的所有候选得分的成本是 $S \\times O(b) = O(bS)$。\n4.  在计算出 $S$ 个新得分后，我们必须识别出排名前 $b$ 的状态以形成下一个集束 $\\mathcal{B}_t$。这可以使用线性时间选择算法（例如 Quickselect）在 $O(S)$ 时间内高效完成，以找到第 $b$ 大的得分然后进行筛选。\n5.  一个时间步的总成本是这两步之和：$O(bS) + O(S)$。由于 $b \\ge 1$，这可以简化为 $O(bS)$。\n\n这个过程对所有 $T$ 个时间步重复。总渐近成本为：\n$$ \\text{Total Cost} = T \\times O(bS) = O(T b S) $$\n当 $b  S$ 时，$O(T b S)$ 是对 $O(T S^2)$ 的一个渐近改进。形式上，如果 $b = o(S)$，那么 $T b S = o(T S^2)$。\n\n### 第2部分：最小集束宽度 $b$ 的推导\n\n我们得到的要求是，最优路径在所有 $T$ 个步骤中经过剪枝后存活的概率必须至少为 $1-\\varepsilon$：\n$$ \\left(1 - (1-p)^b\\right)^T \\ge 1 - \\varepsilon $$\n其中 $p \\in (0,1)$ 是排名模型的参数，$b$ 是集束宽度，而 $\\varepsilon \\in (0,1)$ 是准确率容差。我们需要找到满足此不等式的最小整数 $b$，且该 $b$ 需满足约束 $b \\le S$。\n\n1.  对两边取 $T$ 次方根。由于两边都为正，不等号方向保持不变。\n    $$ 1 - (1-p)^b \\ge (1 - \\varepsilon)^{1/T} $$\n2.  重新整理各项以分离出含有 $b$ 的项：\n    $$ (1-p)^b \\le 1 - (1 - \\varepsilon)^{1/T} $$\n3.  对两边取对数。由于 $p \\in (0,1)$，我们有 $0  1-p  1$，这意味着 $\\log(1-p)$ 是负数。因此，当我们取对数并在之后除以 $\\log(1-p)$ 时，我们必须反转不等号。\n    $$ b \\log(1-p) \\le \\log\\left(1 - (1 - \\varepsilon)^{1/T}\\right) $$\n4.  除以 $\\log(1-p)$ 并反转不等号：\n    $$ b \\ge \\frac{\\log\\left(1 - (1 - \\varepsilon)^{1/T}\\right)}{\\log(1-p)} $$\n    对数的底可以是任何大于1的值；自然对数是标准选择。\n\n由于 $b$ 必须是整数，最小的无约束整数集束宽度（我们称之为 $b_{req}$）是满足此条件的最小整数，由上取整函数给出：\n$$ b_{req} = \\left\\lceil \\frac{\\ln\\left(1 - (1 - \\varepsilon)^{1/T}\\right)}{\\ln(1-p)} \\right\\rceil $$\n\n问题施加了物理约束，即集束宽度不能超过状态总数，即 $b \\le S$。因此，所选的集束宽度 $b_{chosen}$ 必须是：\n$$ b_{chosen} = \\min(S, b_{req}) $$\n\n如果计算出的所需集束宽度 $b_{req}$ 超过了状态数 $S$，我们只能被迫选择 $b_{chosen} = S$。在这种情况下，所选的集束宽度 $b_{chosen}$ 小于所需的宽度 $b_{req}$，因此准确率保证 $\\left(1 - (1-p)^{b_{chosen}}\\right)^T \\ge 1 - \\varepsilon$ 将无法满足。此外，由于 $b_{chosen} = S$，与完整的 Viterbi 算法相比，没有渐近成本的降低（$O(TBS) = O(TS^2)$）。\n\n### 第3部分：实现逻辑\n\n对于每个测试用例 $(T, S, p, \\varepsilon)$：\n1.  使用推导出的公式计算所需的集束宽度 $b_{req}$。为了在 $\\varepsilon$ 很小时保持数值稳定性，表达式 $(1-\\varepsilon)^{1/T}$ 可以计算为 $\\exp(\\frac{1}{T}\\ln(1-\\varepsilon))$。项 $1 - \\exp(\\dots)$ 和 $\\ln(1-p)$ 最好分别使用 `expm1` 和 `log1p` 函数来计算，以保持对接近 $0$ 的参数的精度。\n    $$ b_{req} = \\left\\lceil \\frac{\\ln(-\\text{expm1}(\\frac{1}{T}\\ln(1-\\varepsilon)))}{\\ln(1-p)} \\right\\rceil = \\left\\lceil \\frac{\\ln(-\\text{expm1}(\\frac{\\text{log1p}(-\\varepsilon)}{T}))}{\\text{log1p}(-p)} \\right\\rceil$$\n2.  确定所选的集束宽度 $b_{chosen} = \\min(S, b_{req})$。\n3.  为布尔标志评估两个条件：\n    a.  **准确率保证**：当且仅当所选的集束宽度足够时（即 $b_{chosen} \\ge b_{req}$），准确率才能得到保证。这等价于检查是否 $S \\ge b_{req}$。\n    b.  **渐近成本降低**：如果 $b_{chosen}  S$，则成本得到降低。\n4.  如果两个条件都满足，最终的布尔值为 `True`，否则为 `False`。这可以简化为单个条件 $b_{req}  S$。如果 $b_{req}  S$，我们选择 $b_{chosen} = b_{req}$，这样既满足 $b_{chosen}  S$ 也满足 $b_{chosen} \\ge b_{req}$。如果 $b_{req} \\ge S$，则不可能同时满足这两个条件。\n5.  返回数对 $[b_{chosen}, \\text{boolean}]$。",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the beam search parameter problem for a suite of test cases.\n    For each case, it computes the minimal beam width 'b' that guarantees\n    a certain accuracy and determines if this choice also reduces\n    asymptotic complexity relative to the Viterbi algorithm.\n    \"\"\"\n\n    # Test suite of parameters (T, S, p, epsilon)\n    test_cases = [\n        (1000, 50, 0.3, 0.01),\n        (1, 1000, 0.3, 0.01),\n        (10000, 10000, 0.1, 0.1),\n        (500, 200, 0.25, 0.000001),\n        (1000, 500, 0.01, 0.01),\n    ]\n\n    results = []\n    for T, S, p, epsilon in test_cases:\n        # Using numerically stable functions for calculations involving\n        # numbers close to 0 or 1.\n        # log(1-x) => log1p(-x)\n        # exp(x)-1 => expm1(x)\n        #\n        # Derivation:\n        # (1 - (1-p)^b)^T >= 1 - epsilon\n        # 1 - (1-p)^b >= (1 - epsilon)^(1/T)\n        # (1-p)^b = 1 - (1 - epsilon)^(1/T)\n        # b * log(1-p) = log(1 - (1-epsilon)^(1/T))\n        # b >= log(1 - (1-epsilon)^(1/T)) / log(1-p)  (log(1-p) is negative)\n        \n        # (1-epsilon)^(1/T) = exp(log((1-epsilon)^(1/T))) = exp( (1/T) * log(1-epsilon) )\n        # Using log1p for log(1-epsilon) and expm1 for exp(x)-1:\n        # log(1 - exp( (1/T) * log1p(-epsilon) ))\n        # let term_in_log = -expm1((1/T) * log1p(-epsilon))\n        try:\n            log_numerator_arg = -math.expm1(math.log1p(-epsilon) / T)\n            \n            # Handle potential domain error if log_numerator_arg is not positive.\n            # This can happen if T is extremely large and epsilon is close to 1,\n            # but is unlikely with the given test cases.\n            if log_numerator_arg = 0:\n                # This case implies an effectively infinite required beam width,\n                # which is unrealistic but we handle it.\n                b_required_float = float('inf')\n            else:\n                numerator = math.log(log_numerator_arg)\n                denominator = math.log1p(-p)\n                b_required_float = numerator / denominator\n\n        except (ValueError, OverflowError):\n            b_required_float = float('inf')\n\n        # The required beam width must be an integer, so we take the ceiling.\n        if math.isinf(b_required_float) or math.isnan(b_required_float):\n            b_required = S + 1 # Effectively infinite, force to be > S\n        else:\n            b_required = int(math.ceil(b_required_float))\n\n        # The chosen beam width is constrained by the number of states S.\n        b_chosen = min(S, b_required)\n\n        # The accuracy is guaranteed if the chosen b is at least the required b.\n        # This is equivalent to S being large enough (S >= b_required).\n        is_accuracy_guaranteed = (b_chosen >= b_required)\n\n        # The asymptotic cost is reduced if b_chosen  S.\n        is_cost_reduced = (b_chosen  S)\n\n        # The final boolean flag is True only if BOTH conditions are met.\n        success_flag = is_accuracy_guaranteed and is_cost_reduced\n\n        # Append the pair [chosen_b, boolean_flag] to results.\n        results.append([b_chosen, success_flag])\n    \n    # Format the output as a string representing a list of lists without spaces.\n    output_str = f\"[{','.join([str(r).replace(' ', '') for r in results])}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "将理论算法分析应用于前沿生物技术是计算系统生物学的重要组成部分。本练习聚焦于CRISPR基因编辑技术中的一个关键挑战：全基因组范围内的脱靶效应扫描。您将通过对一个基于Aho-Corasick自动机和“种子-延伸”策略的搜索算法进行建模，从第一性原理出发，推导其在随机基因组模型下的期望运行时间。这个过程将帮助您深刻理解算法设计（如种子策略）如何直接影响其在海量生物数据上的性能表现。",
            "id": "3288372",
            "problem": "一个研究团队正在使用 Aho–Corasick 自动机构建一个精确多模式索引，以加速对一组固定长度的成簇规律间隔短回文重复序列 (CRISPR) 指导核糖核酸 (RNA) 序列的脱靶扫描。基因组被建模为一个在大小为 $a$（对于 DNA，$a=4$）的脱氧核糖核酸 (DNA) 字母表上的独立同分布序列。他们希望报告所有基因组位点，这些位点对于 $r$ 条长度为 $L$ 的指导序列中的任意一条，在 $L$ 核苷酸长度的指导序列上，当汉明错配预算最多为 $d$ 时，可能是其脱靶位点。\n\n为避免在使用 Aho–Corasick 自动机进行精确匹配时出现假阴性，他们采用了一种“种子-延伸”(seed-and-extend)策略：对于每条指导序列，他们选择一组不相交的连续种子，这些种子在基因组中的精确匹配会触发在错配预算下对完整指导序列的验证。他们将注意力限制在以下这类种子设计上：\n- 每条指导序列恰好有 $d+1$ 个不相交的连续种子，\n- 种子长度相等，\n- 种子划分了指导序列的 $L$ 个位置。\n\n假设 $L$ 可被 $d+1$ 整除，因此共同的种子长度为 $s=L/(d+1)$。该团队将基于所有 $r$ 条指导序列的所有种子的多重集构建一个 Aho–Corasick 自动机，并用它扫描一个长度为 $n$ 的基因组。设 $z$ 表示自动机在扫描过程中输出的种子出现总次数；自动机忽略验证成本，每个精确的种子匹配输出一次出现。\n\n从第一性原理和标准定义（有限自动机以均摊 $O(1)$ 的时间处理每个字符，以及用于错配分布的鸽巢原理）出发，在独立同分布的基因组模型下，推导 $z$ 的期望值，并用它来表示扫描时间的预期渐近主导项，该项是 $n$、$r$、$L$、$d$ 和 $a$ 的函数，其中忽略预处理和验证成本，但将每次输出计为常数时间。你的答案必须是使用这些符号表示的单一封闭形式表达式，能够捕捉预期运行时间的主导阶项。不要提供不等式，不要提供大O或大$\\Theta$界，最终答案中也不要包含任何单位。",
            "solution": "以下简要概述了推导过程，该过程导出了 `answer` 代码块中的最终 `boxed` 表达式。\n    1.  陈述扫描时间 `T` 的模型。`T` 由一个与基因组长度 `n` 成正比的项和一个与匹配数 `z` 成正比的项组成。根据问题陈述，操作数的一个自然模型是 `n+z`。\n    2.  推导 `E[z]`。\n        - 确定种子总数：`r(d+1)`。\n        - 确定种子长度：`s = L/(d+1)`。\n        - 使用独立同分布(i.i.d.)模型找到一个种子在某个位置匹配的概率：`a^{-s}`。\n        - 对所有种子和所有 `n-s+1` 个位置，利用期望的线性性质。\n        - `E[z] = (n-s+1)r(d+1)a^{-s}`。\n    3.  构造期望时间 `E[T] = E[n+z] = n+E[z]`。\n    4.  代入 `E[z]`：`n + (n-s+1)r(d+1)a^{-s}`。\n    5.  展开并识别随 `n` 增长的项。这是渐近主导项。`E[T] = n + n \\cdot r(d+1)a^{-s} - (s-1)r(d+1)a^{-s}`。主导项是 `n(1 + r(d+1)a^{-s})`。\n    6.  代入 `s = L/(d+1)`，以获得使用所需变量表示的最终表达式。`n\\left(1 + r(d+1)a^{-L/(d+1)}\\right)`。\n\n    所有内容看起来都一致且正确。推理是合理的，并且如要求的那样遵循了第一性原理。最终表达式的格式是正确的。我现在将写出解。",
            "answer": "$$\n\\boxed{n \\left(1 + r (d+1) a^{-\\frac{L}{d+1}}\\right)}\n$$"
        },
        {
            "introduction": "许多生物网络分析中的核心问题在理论上是计算困难的（NP-hard），但生物网络的稀疏和结构化特性为精确求解提供了可能。本练习将向您介绍参数化复杂性的强大概念，特别是以图的“树宽”（treewidth）作为参数。您将学习如何通过启发式算法估算生物网络的树宽，并推导出精确推断算法的运行时间如何依赖于该参数，从而理解为何对于结构良好的（低树宽）网络，看似棘手的问题实际上是可解的。",
            "id": "3288367",
            "problem": "给定一些无向交互图，这些图抽象了稀疏的生物化学反应或信号通路。考虑在这些网络上进行精确的概率推断，网络被建模为因子图，其中每个分子种类的状态是一个域大小为 $k$ 的随机变量，而交互作用会在相应的变量范围内引入因子。通过变量消除进行的精确推断会逐一处理变量，用其边缘化结果替换包含被消除变量的因子。每个消除步骤的计算成本主要取决于将被消除变量所在的所有因子相乘，然后对该变量进行求和消元。\n\n基本基础和定义：\n- 一个因子图会导出一个关于变量 $V$ 的无向图 $G = (V,E)$，其中 $E$ 中的一条边连接了在某个因子范围内共同出现的两个变量。\n- 对于 $V$ 上的一个消除排序 $\\pi$，其导出图的形成过程是：在每次消除一个顶点 $v$ 时，添加填充边，使得 $v$ 的当前邻域成为一个团，然后再移除 $v$。$\\pi$ 的导出宽度是在所有被消除的顶点中，其在消除时当前度的最大值。$G$ 的树宽 $t$ 是所有排序中最小的导出宽度。\n- 如果每个变量的域大小为 $k$，那么在消除一个其当前邻域构成大小为 $w$ 的团的变量时，该步骤的主要算术成本与 $k^{w+1}$ 成正比。\n\n任务概述：\n1. 从第一性原理出发，为一个包含 $n$ 个变量且树宽为 $t$ 的因子图上的变量消除精确推断推导出一个渐近运行时限。该界限的形式应为 $O(f(t)\\,n)$，其中函数 $f$ 是 $t$ 的指数函数。不要假设任何专门的公式；仅使用上述定义以及每个消除步骤中的作用域大小受导出团大小限制这一事实来推导表达式。\n2. 实现一个程序，该程序：\n   - 使用关于无向图 $G$ 的最小填充启发式算法计算树宽 $t$ 的一个上界 $\\hat{t}$。该启发式算法重复消除一个顶点，该顶点的邻居成为团所需的填充边数量最少（平局时选择当前度较小的，再次平局时选择顶点索引较小的），添加必要的填充边，并记录遇到的最大邻域大小；最终的最大邻域大小即为 $\\hat{t}$。\n   - 对于 $k=2$ 的二元变量，将变量消除的每个实例的渐近操作次数上界计算为 $n \\cdot 2^{\\hat{t}+1}$。\n3. 使用以下模拟了经过整理的通路模块的无向图测试套件。顶点索引从 $0$ 到 $n-1$。每个测试项由序对 $(n,\\text{edges})$ 指定，其中 `edges` 是一组无序对：\n   - 边界情况（孤立变量）：$(n,\\text{edges}) = \\left(1,\\ \\varnothing\\right)$。\n   - 具有 $n=10$ 的类通路线性链：$(n,\\text{edges}) = \\left(10,\\ \\{(0,1),(1,2),(2,3),(3,4),(4,5),(5,6),(6,7),(7,8),(8,9)\\}\\right)$。\n   - 具有 $n=10$ 且中心在 $0$ 的星形模块：$(n,\\text{edges}) = \\left(10,\\ \\{(0,1),(0,2),(0,3),(0,4),(0,5),(0,6),(0,7),(0,8),(0,9)\\}\\right)$。\n   - 具有 $n=8$ 的环状基序：$(n,\\text{edges}) = \\left(8,\\ \\{(0,1),(1,2),(2,3),(3,4),(4,5),(5,6),(6,7),(7,0)\\}\\right)$。\n   - 两行网格模块（$2\\times 4$），$n=8$：$(n,\\text{edges}) = \\left(8,\\ \\{(0,1),(1,2),(2,3),(4,5),(5,6),(6,7),(0,4),(1,5),(2,6),(3,7)\\}\\right)$。\n   - 带尾巴的团核心（模块内的密集中心）：$(n,\\text{edges}) = \\left(7,\\ \\{(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(3,4),(4,5),(5,6)\\}\\right)$。\n4. 假设所有测试用例均为 $k=2$ 的二元变量。您的程序应按上述顺序列出的顺序处理测试套件，并为每个测试用例输出序对 $[\\hat{t}, n \\cdot 2^{\\hat{t}+1}]$。\n5. 最终输出格式要求：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个元素本身是一个包含两个元素的列表。例如，三个用例的输出应类似于 $[[a_1,b_1],[a_2,b_2],[a_3,b_3]]$，其中 $a_i$ 和 $b_i$ 为整数。\n\n此任务不涉及物理单位。所有角度（如果出现）应以弧度为单位理解，但此处并未使用。所有要求的数值输出均为整数。",
            "solution": "用户提供了一个有效的问题陈述。它在概率图模型和计算复杂性的原理上有科学依据，定义和目标清晰明确，并且没有说明中列出的任何使其无效的缺陷。我现在将继续提供完整的解决方案。\n\n### 第 1 部分：渐近运行时限的推导\n\n任务是为一个包含 $n$ 个变量且树宽为 $t$ 的因子图上的变量消除精确推断推导出一个渐近运行时限。该界限必须为 $O(f(t)\\,n)$ 的形式，其中 $f$ 是 $t$ 的指数函数，并且从给定的第一性原理推导得出。\n\n1.  **总计算成本**：变量消除算法根据一个特定的消除排序 $\\pi = (v_1, v_2, \\dots, v_n)$ 来处理图 $G=(V, E)$ 中的 $n$ 个变量。总计算成本是消除每个变量的成本之和。\n    $$ \\text{Total Cost}(\\pi) = \\sum_{i=1}^{n} \\text{Cost}(\\text{eliminate } v_i) $$\n\n2.  **单步消除成本**：问题陈述指出，消除单个变量 $v_i$ 的成本与 $k^{w_i+1}$ 成正比，其中 $k$ 是每个变量的域大小，$w_i$ 是在 $v_i$ 消除时其邻域所形成的团的大小。这个大小 $w_i$ 正是第 $i$ 步之前图中顶点 $v_i$ 的度。设 $d_i(v_i)$ 为此度。因此，消除 $v_i$ 的成本为 $C \\cdot k^{d_i(v_i)+1}$，其中 $C$ 是某个比例常数。\n\n3.  **用导出宽度限定成本上界**：消除排序 $\\pi$ 的导出宽度，记为 $w^*(\\pi)$，定义为在整个过程中任何顶点在其消除时的度的最大值。\n    $$ w^*(\\pi) = \\max_{i \\in \\{1, \\dots, n\\}} d_i(v_i) $$\n    因此，对于排序 $\\pi$ 中的任何变量 $v_i$，其在消除时的度受导出宽度的限制：$d_i(v_i) \\leq w^*(\\pi)$。我们可以用这个来为给定排序 $\\pi$ 的总成本建立一个上界：\n    $$ \\text{Total Cost}(\\pi) = \\sum_{i=1}^{n} C \\cdot k^{d_i(v_i)+1} \\leq \\sum_{i=1}^{n} C \\cdot k^{w^*(\\pi)+1} $$\n    由于项 $C \\cdot k^{w^*(\\pi)+1}$ 对于 $n$ 个变量的求和是常数，我们有：\n    $$ \\text{Total Cost}(\\pi) \\leq n \\cdot C \\cdot k^{w^*(\\pi)+1} $$\n\n4.  **引入树宽**：变量消除算法的效率关键在于找到一个好的消除排序。一个最优的排序是使导出宽度最小化的排序。图 $G$ 的树宽 $t$ 定义为所有可能消除排序中最小的导出宽度。\n    $$ t = \\min_{\\pi} w^*(\\pi) $$\n    如果我们使用一个最优的消除排序 $\\pi_{\\text{opt}}$，那么它的导出宽度等于图的树宽，即 $w^*(\\pi_{\\text{opt}}) = t$。\n\n5.  **最终渐近界限**：通过将树宽 $t$ 代入我们对最优排序的成本不等式中，我们得到了最佳情况下变量消除复杂度的上界：\n    $$ \\text{Total Cost}(\\pi_{\\text{opt}}) \\leq n \\cdot C \\cdot k^{t+1} $$\n    在渐近复杂度的意义上，我们忽略了常数因子 $C$。因此，运行时间受以下界限约束：\n    $$ O(n \\cdot k^{t+1}) $$\n    这个表达式符合要求的 $O(f(t) \\cdot n)$ 形式，其中 $f(t) = k^{t+1}$ 是树宽 $t$ 的一个指数函数。推导至此完成。\n\n### 第 2 部分：算法实现\n\n任务的第二部分涉及实现一个算法，使用最小填充启发式算法计算树宽的上界 $\\hat{t}$，然后用这个界限计算总成本。\n\n**最小填充启发式算法逻辑**\n该算法迭代进行，每一步消除一个顶点。在每一步中，我们必须从剩余的顶点集合中选择要消除的顶点。选择遵循一套严格的规则：\n1.  **主要标准（最小填充）**：选择那个使其当前邻域成为一个团所需“填充”边数量最少的顶点。对于一个有 $d$ 个邻居的顶点，填充边的数量为 $\\frac{d(d-1)}{2} - m$，其中 $m$ 是其邻居对之间已存在的边数。\n2.  **第一平局决胜规则（最小度）**：如果多个顶点具有相同的最小填充数，则从此子集中选择当前度最小的那个。\n3.  **第二平局决胜规则（最小索引）**：如果仍然存在平局，则选择整数索引最小的顶点。\n\n**过程：**\n1.  根据给定的顶点数 $n$ 和边集初始化图。邻接表表示（例如 Python 中的字典套集合）是合适的。\n2.  维护一个剩余顶点集合，初始时包含从 $0$ 到 $n-1$ 的所有顶点。\n3.  初始化一个变量 `max_degree_encountered` 为 $0$。\n4.  循环 $n$ 次以消除每个顶点：\n    a.  在所有剩余顶点中，通过应用带平局决胜规则的最小填充启发式算法，找到要消除的最佳顶点。一个简洁的实现方式是遍历候选顶点，为每个顶点计算一个元组 `(fill_count, degree, index)`，并找到字典序最小的元组。\n    b.  一旦选择了要消除的顶点 $v$，记录其当前度 $d_v$。更新 `max_degree_encountered = max(max_degree_encountered, d_v)`。\n    c.  修改图：在 $v$ 的邻居之间添加所有必要的填充边，使它们成为一个团。\n    d.  从图结构中移除 $v$：将其从剩余顶点集合中移除，并从其前邻居的邻接表中移除。\n5.  循环结束后，`max_degree_encountered` 持有的值即为 $\\hat{t}$，即该启发式算法找到的排序的导出宽度。这作为真实树宽 $t$ 的一个上界。\n\n**成本计算：**\n对于每个具有 $n$ 个变量、二元域大小（$k=2$）和计算出的树宽上界 $\\hat{t}$ 的测试用例，总算术操作数计算为 $n \\cdot 2^{\\hat{t}+1}$。\n最终的程序为每个测试用例实现此逻辑，并将输出格式化为 `[t_hat, cost]` 对的列表。",
            "answer": "```python\nimport sys\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    It computes an upper bound on treewidth using the min-fill heuristic\n    and then calculates the corresponding complexity bound for variable elimination.\n    \"\"\"\n\n    # The problem specifies that numpy and scipy are allowed, but they are not\n    # necessary for this specific implementation. Using only standard libraries.\n\n    test_cases = [\n        (1, set()),\n        (10, {(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9)}),\n        (10, {(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9)}),\n        (8, {(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 0)}),\n        (8, {(0, 1), (1, 2), (2, 3), (4, 5), (5, 6), (6, 7), (0, 4), (1, 5), (2, 6), (3, 7)}),\n        (7, {(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3), (3, 4), (4, 5), (5, 6)}),\n    ]\n\n    results = []\n    for n, edges in test_cases:\n        t_hat = compute_treewidth_upper_bound(n, edges)\n        # Using k=2 as specified for binary variables\n        # Cost is n * 2^(t_hat + 1). Use bit shift for efficiency and to handle large numbers.\n        cost = n * (1  (t_hat + 1))\n        results.append([t_hat, cost])\n\n    # Format the final output string as specified without spaces\n    output_str = f\"[{','.join([str(r).replace(' ', '') for r in results])}]\"\n    print(output_str)\n\ndef compute_treewidth_upper_bound(n, edges_set):\n    \"\"\"\n    Computes an upper bound on treewidth (the induced width) for a given graph\n    using the min-fill heuristic.\n\n    Args:\n        n (int): The number of vertices in the graph.\n        edges_set (set): A set of tuples representing the undirected edges.\n\n    Returns:\n        int: The computed treewidth upper bound (t_hat).\n    \"\"\"\n    if n == 1:\n        return 0\n\n    # Adjacency list representation using a dictionary of sets\n    adj = {i: set() for i in range(n)}\n    for u, v in edges_set:\n        adj[u].add(v)\n        adj[v].add(u)\n\n    remaining_nodes = set(range(n))\n    max_width_encountered = 0\n\n    # Eliminate one node in each iteration\n    for _ in range(n):\n        # Store (fill_count, degree, index) to find the best node to eliminate.\n        # Python's tuple comparison handles the tie-breaking logic automatically.\n        best_node_info = (float('inf'), float('inf'), -1)\n\n        # Iterate through remaining nodes in sorted order to ensure deterministic tie-breaking.\n        for node in sorted(list(remaining_nodes)):\n            neighbors = adj[node]\n            degree = len(neighbors)\n            \n            fill_count = 0\n            if degree > 1:\n                neighbor_list = list(neighbors)\n                for i in range(degree):\n                    for j in range(i + 1, degree):\n                        u, v = neighbor_list[i], neighbor_list[j]\n                        if v not in adj[u]:\n                            fill_count += 1\n            \n            current_node_info = (fill_count, degree, node)\n            if current_node_info  best_node_info:\n                best_node_info = current_node_info\n\n        _, degree_at_elimination, node_to_eliminate = best_node_info\n        \n        max_width_encountered = max(max_width_encountered, degree_at_elimination)\n        \n        # Add fill-in edges (triangulate the neighbors)\n        neighbors_to_connect = list(adj[node_to_eliminate])\n        for i in range(len(neighbors_to_connect)):\n            for j in range(i + 1, len(neighbors_to_connect)):\n                u, v = neighbors_to_connect[i], neighbors_to_connect[j]\n                adj[u].add(v)\n                adj[v].add(u)\n        \n        # Remove the node from the graph\n        for neighbor in neighbors_to_connect:\n            adj[neighbor].remove(node_to_eliminate)\n        del adj[node_to_eliminate]\n        remaining_nodes.remove(node_to_eliminate)\n        \n    return max_width_encountered\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}