{
    "hands_on_practices": [
        {
            "introduction": "在系统生物学中，将复杂的生化网络抽象为图是分析信息流和物质转化的核心方法。一个基本问题是确定从一组初始分子出发，通过哪些反应步骤才能合成一个特定的目标产物，例如一个转录因子。本练习将引导你解决这一问题，通过在一个反应超图 (reaction hypergraph) 上实现一种带约束的广度优先搜索 (Breadth-First Search, BFS) 算法，来找到激活目标所需的最少反应集合 。这个实践的核心挑战在于，你需要将经典的图遍历算法进行改造，以整合生物系统中至关重要的化学计量约束 (stoichiometric constraints)，从而确保找到的路径在生物化学上是可行的。",
            "id": "3317626",
            "problem": "考虑一个计算系统生物学中生物化学网络的反应超图。设分子种类的集合为 $\\mathcal{S}$，反应的集合为 $\\mathcal{R}$。每个反应 $r \\in \\mathcal{R}$都有一个底物多重集 $\\mathrm{Subs}(r) = \\{(s_i, \\alpha_i)\\}$ 和一个产物多重集 $\\mathrm{Prods}(r) = \\{(p_j, \\beta_j)\\}$，其中 $s_i, p_j \\in \\mathcal{S}$ 且 $\\alpha_i, \\beta_j \\in \\mathbb{N}$ 是化学计量系数。设 $A_0$ 是一个初始可用分子种类的多重集，其计数为 $c_0 : \\mathcal{S} \\to \\mathbb{N}$。将关联图 $\\mathcal{G}$ 定义为一个二分图，其节点集为 $\\mathcal{S} \\cup \\mathcal{R}$，当 $(s, \\alpha) \\in \\mathrm{Subs}(r)$ 时存在从分子种类到反应的边 $(s \\to r)$，当 $(p, \\beta) \\in \\mathrm{Prods}(r)$ 时存在从反应到分子种类的边 $(r \\to p)$。\n\n我们的目标是在以下单调可用性语义下，计算能够到达指定转录因子 $t \\in \\mathcal{S}$ 的最小反应集：反应发生时分子种类不被消耗；存在性在广度优先层上是单调的。化学计量约束通过边可行性检查来引入：一个反应节点 $r$ 是可遍历的，当且仅当对于其每个底物 $(s, \\alpha) \\in \\mathrm{Subs}(r)$，至少有 $\\alpha$ 个 $s$ 的令牌（token）通过初始集 $A_0$ 或先前遍历过的反应的产物而变得可用。定义一个分子种类的深度为使其从 $A_0$ 开始变为可用所需的最小反应数，一个反应的深度为启用它的底物令牌中的最大深度加一。\n\n基本假设和定义：\n- 化学计量矩阵 $N \\in \\mathbb{Z}^{|\\mathcal{S}| \\times |\\mathcal{R}|}$ 的元素为 $N_{s,r} = \\beta_{s,r} - \\alpha_{s,r}$，其中 $\\alpha_{s,r}$ 是分子种类 $s$ 在反应 $r$ 中的底物系数（如果不存在则为零），$\\beta_{s,r}$ 是产物系数（如果不存在则为零）。\n- 在无权图上进行关联图的广度优先搜索（BFS）可以得到遍历边数最少的路径。在二分关联结构中，任何从一个分子种类到另一个分子种类的路径都交替出现分子种类节点和反应节点；只要可遍历性由底物可用性决定，最小化路径长度就等同于最小化所遍历的反应节点数量。\n- 在信号转导和转录调控中典型的单调可用性语义下（即分子种类起催化作用且不被消耗），$t$ 的可达性取决于在没有耗尽的情况下满足底物的多重性。\n\n任务：\n设计一个程序，给定反应定义、初始分子种类计数和目标转录因子 $t$，在关联图上执行受约束的广度优先搜索，以找到到达 $t$ 的最小反应集。一个反应只有在对于其每个 $(s, \\alpha) \\in \\mathrm{Subs}(r)$，至少有 $\\alpha$ 份 $s$ 已经在早期或当前的 BFS 层中出现时，才有资格发生。当一个反应在深度 $d_r$ 发生时，它在相同的深度 $d_r$ 产生乘积事件 $(p, \\beta)$。最小反应集必须通过追溯用于启用每个反应的实际底物令牌来重构，从而将化学计量约束纳入依赖链中。如果 $t$ 在初始集 $A_0$ 中就可用，则最小反应集为空列表。如果 $t$ 不可达，则返回布尔值 false 和空列表。\n\n您的程序必须解决以下测试套件。每个测试用例由反应列表、初始计数映射和目标 $t$ 指定。反应标识符是每个测试用例中从零开始的索引，反应以多重集 $(\\mathrm{Subs}, \\mathrm{Prods})$ 的有序对给出，编码为从分子种类名称到整数化学计量系数的映射。\n\n测试套件：\n1. 具有不同底物和产物的正常路径链。\n   - 分子种类：$\\{A, B, C, D, E, TF\\}$。\n   - 反应：\n     - $r_0$: $\\mathrm{Subs}(r_0) = \\{(A, 1), (B, 1)\\}$, $\\mathrm{Prods}(r_0) = \\{(C, 1)\\}$。\n     - $r_1$: $\\mathrm{Subs}(r_1) = \\{(C, 1)\\}$, $\\mathrm{Prods}(r_1) = \\{(D, 1)\\}$。\n     - $r_2$: $\\mathrm{Subs}(r_2) = \\{(D, 1), (E, 1)\\}$, $\\mathrm{Prods}(r_2) = \\{(TF, 1)\\}$。\n   - 初始计数：$c_0(A) = 1$, $c_0(B) = 1$, $c_0(E) = 1$；所有其他为 $0$。\n   - 目标：$t = TF$。\n   - 预期结果类型：一个列表，包含一个布尔值和一个按反应深度非递减顺序排列的反应标识符列表。\n\n2. 目标在初始时就可用的边界情况。\n   - 与情况1相同的反应。\n   - 初始计数：$c_0(A) = 1$, $c_0(B) = 1$, $c_0(E) = 1$, $c_0(TF) = 1$；所有其他为 $0$。\n   - 目标：$t = TF$。\n\n3. 需要多个底物副本的化学计量边界情况。\n   - 分子种类：$\\{X, Y, Z\\}$。\n   - 反应：\n     - $r_0$: $\\mathrm{Subs}(r_0) = \\{(Z, 1)\\}$, $\\mathrm{Prods}(r_0) = \\{(X, 1)\\}$。\n     - $r_1$: $\\mathrm{Subs}(r_1) = \\{(X, 2)\\}$, $\\mathrm{Prods}(r_1) = \\{(Y, 1)\\}$。\n   - 初始计数：$c_0(X) = 1$, $c_0(Z) = 1$；所有其他为 $0$。\n   - 目标：$t = Y$。\n\n4. 在给定反应下目标不可达。\n   - 分子种类：$\\{U, TF, A\\}$。\n   - 反应：\n     - $r_0$: $\\mathrm{Subs}(r_0) = \\{(U, 1)\\}$, $\\mathrm{Prods}(r_0) = \\{(TF, 1)\\}$。\n   - 初始计数：$c_0(A) = 1$；所有其他为 $0$。\n   - 目标：$t = TF$。\n\n5. 目标的分支先决条件。\n   - 分子种类：$\\{A, P, Q, TF\\}$。\n   - 反应：\n     - $r_0$: $\\mathrm{Subs}(r_0) = \\{(A, 1)\\}$, $\\mathrm{Prods}(r_0) = \\{(P, 1)\\}$。\n     - $r_1$: $\\mathrm{Subs}(r_1) = \\{(A, 1)\\}$, $\\mathrm{Prods}(r_1) = \\{(Q, 1)\\}$。\n     - $r_2$: $\\mathrm{Subs}(r_2) = \\{(P, 1), (Q, 1)\\}$, $\\mathrm{Prods}(r_2) = \\{(TF, 1)\\}$。\n   - 初始计数：$c_0(A) = 1$；所有其他为 $0$。\n   - 目标：$t = TF$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含五个测试用例的结果，格式为方括号括起来的逗号分隔列表，其中每个结果本身都是 $[\\text{reachable}, \\text{reaction\\_id\\_list}]$ 形式的双元素列表。例如，输出必须类似于\n$[[\\text{True},[0,1,2]],[\\text{True},[]],[\\text{True},[0,1]],[\\text{False},[]],[\\text{True},[0,1,2]]]$。\n不涉及物理单位，输出是无单位的。角度不适用，也不使用百分比。",
            "solution": "该问题要求从一组初始可用的分子种类开始，确定产生目标分子种类所需的最小反应集。该系统在一个非消耗性、单调可用性模型下运行，意味着分子种类计数随时间只增不减。这个问题最好被建模为反应网络上的受约束可达性分析，可以通过使用类似广度优先搜索（BFS）的迭代算法来确定反应深度，然后使用一个依赖感知的回溯算法来构建最小反应集来解决。\n\n整体方法包括两个主要阶段：一个用于确定可达性和最小深度的前向传播阶段，以及一个用于重构特定反应路径的反向传播阶段。\n\n**阶段 1：前向传播（可达性与深度分析）**\n\n前向传播阶段逐层模拟反应网络，类似于 BFS。每个“层”对应于从初始状态开始的反应步骤数的增加。\n\n1.  **初始化**：\n    - 为了高效处理，所有唯一的分子种类名称被映射到从 $0$ 到 $|\\mathcal{S}|-1$ 的整数索引。反应由它们的索引 $0$ 到 $|\\mathcal{R}|-1$ 标识。\n    - 一个大小为 $|\\mathcal{S}|$ 的数组 `species_counts` 用初始计数 $c_0$ 进行初始化。\n    - 一个数组 `species_depth`，用于跟踪产生每种分子种类所需的最小反应数，对所有分子种类初始化为无穷大（一个哨兵值，如 $-1$），对于初始集 $A_0$ 中存在的分子种类则初始化为 $0$。\n    - 一个大小为 $|\\mathcal{R}|$ 的数组 `reaction_depth` 初始化为无穷大。\n    - 使用一个集合 `fired_reactions` 来跟踪所有已触发的反应。\n\n2.  **迭代触发**：该算法以迭代方式进行。在每次迭代中，它扫描所有反应，以找到那些新近变得有资格触发的反应。\n    - 一个反应 $r$ 被视为有资格，如果：\n        1.  它在之前的迭代中没有被触发过。\n        2.  对于每个底物 $(s, \\alpha) \\in \\mathrm{Subs}(r)$，分子种类 $s$ 的当前总数至少为 $\\alpha$。\n        3.  所有底物 $s$ 本身都是可用的（即 `species_depth[s]` 不是无穷大）。\n    - 如果在一轮迭代中有一组新的反应变得有资格，它们被认为在当前的“层”中同时触发。\n    - 对于每个新触发的反应 $r$：\n        - 它被添加到 `fired_reactions` 集合中。\n        - 其深度 `reaction_depth[r]` 计算为 $1 + \\max_{s \\in \\mathrm{Subs}(r)} \\{\\text{species\\_depth}[s]\\}$。\n        - 对于每个产物 $(p, \\beta) \\in \\mathrm{Prods}(r)$，总数 `species_counts[p]` 增加 $\\beta$。\n        - 如果这条新路径比任何先前找到的产生 $p$ 的路径都短，则产物 `species_depth[p]` 的深度将更新为 `reaction_depth[r]`。\n\n3.  **终止**：迭代过程持续进行，直到对所有反应的一次完整遍历不再产生新的可触发反应。此时，系统达到一个不动点。如果目标分子种类 $t$ 的 `species_depth` 仍为无穷大，则目标不可达。\n\n**阶段 2：反向传播（依赖重构）**\n\n如果目标 $t$ 是可达的，则从 $t$ 开始进行反向搜索，以识别最小反应集。这不是简单的路径跟踪，因为必须满足化学计量要求。重构过程必须追溯每个所需底物“令牌”的来源。\n\n1.  **初始化**：\n    - 创建一个字典 `needed_species` 来跟踪所需的分子种类计数，初始化为 `{t: 1}`。\n    - 一个集合 `required_reactions` 初始化为空。\n\n2.  **递归依赖解析**：该算法迭代处理 `needed_species` 列表。\n    - 对于一个需要数量为 $k$ 的分子种类 $s$：\n        - 从 $k$ 中减去初始集 $c_0(s)$ 中可用的数量，得到一个 `deficit`（缺口）。\n        - 如果 `deficit` 为正，我们必须找到产生 $s$ 的反应来弥补这个缺口。\n        - 算法查询前向传播阶段的 `fired_reactions` 集合，找到所有产生 $s$ 的反应。这些反应按其 `reaction_depth` 排序，以确保我们首先使用“最快”的生产路径，这与最小路径目标一致。\n        - 从这个排序后的列表中逐个将反应添加到 `required_reactions` 集合中，直到缺口被弥补。\n        - 对于添加到集合中的每个反应，其自身的底物需求被添加到 `needed_species` 字典中，从而传播回溯过程。\n\n3.  **完成**：当 `needed_species` 字典为空时，过程终止。得到的 `required_reactions` 集合被转换为列表，并按反应深度非递减顺序排序（以反应索引作为决胜条件），如规定。",
            "answer": "```python\nimport numpy as np\n\ndef find_minimal_reactions(reactions_def, initial_counts_def, target_species):\n    \"\"\"\n    Finds a minimal set of reactions to produce a target species.\n    \"\"\"\n    # 1. Initialization and mapping\n    all_species = set(initial_counts_def.keys())\n    all_species.add(target_species)\n    for subs, prods in reactions_def:\n        all_species.update(subs.keys())\n        all_species.update(prods.keys())\n    \n    sorted_species_list = sorted(list(all_species))\n    species_to_id = {name: i for i, name in enumerate(sorted_species_list)}\n    id_to_species = {i: name for i, name in enumerate(sorted_species_list)}\n    num_species = len(sorted_species_list)\n    num_reactions = len(reactions_def)\n\n    if not all_species:\n        return [False, []]\n    \n    reactions = []\n    for subs, prods in reactions_def:\n        reactions.append({\n            'subs': {species_to_id[s]: v for s, v in subs.items()},\n            'prods': {species_to_id[p]: v for p, v in prods.items()}\n        })\n\n    # Phase 1: Forward Propagation\n    species_counts = np.zeros(num_species, dtype=int)\n    for s, c in initial_counts_def.items():\n        if s in species_to_id:\n            species_counts[species_to_id[s]] = c\n\n    species_depth = np.full(num_species, -1, dtype=int)\n    for i in range(num_species):\n        if species_counts[i] > 0:\n            species_depth[i] = 0\n\n    reaction_depth = np.full(num_reactions, -1, dtype=int)\n    fired_reactions = set()\n\n    while True:\n        newly_eligible = []\n        for r_id in range(num_reactions):\n            if r_id in fired_reactions:\n                continue\n\n            is_eligible = True\n            max_sub_depth = 0\n            if not reactions[r_id]['subs']:\n                pass\n            else:\n                for s_id, stoich in reactions[r_id]['subs'].items():\n                    if species_counts[s_id]  stoich or species_depth[s_id] == -1:\n                        is_eligible = False\n                        break\n                    max_sub_depth = max(max_sub_depth, species_depth[s_id])\n            \n            if is_eligible:\n                newly_eligible.append((r_id, max_sub_depth))\n        \n        if not newly_eligible:\n            break\n\n        for r_id, max_sub_depth in newly_eligible:\n            fired_reactions.add(r_id)\n            r_depth = 1 + max_sub_depth\n            reaction_depth[r_id] = r_depth\n            \n            for p_id, stoich in reactions[r_id]['prods'].items():\n                species_counts[p_id] += stoich\n                if species_depth[p_id] == -1 or r_depth  species_depth[p_id]:\n                    species_depth[p_id] = r_depth\n\n    # Check reachability of the target\n    target_id = species_to_id.get(target_species)\n    if target_id is None or species_depth[target_id] == -1:\n        return [False, []]\n    \n    if species_depth[target_id] == 0:\n        return [True, []]\n\n    # Phase 2: Backward Propagation\n    required_reactions = set()\n    needed_species = {target_id: 1}\n    \n    # Using a list as a stack for deterministic processing\n    agenda = list(needed_species.items())\n\n    while agenda:\n        s_id, num_needed = agenda.pop(0)\n\n        initial_avail = initial_counts_def.get(id_to_species[s_id], 0)\n        deficit = num_needed - initial_avail\n        \n        if deficit = 0:\n            continue\n            \n        producers = []\n        for r_id in fired_reactions:\n            if s_id in reactions[r_id]['prods']:\n                producers.append(r_id)\n        \n        producers.sort(key=lambda r_id: (reaction_depth[r_id], r_id))\n        \n        covered_deficit = 0\n        for p_rid in producers:\n            if p_rid in required_reactions:\n                # If we've already included this reaction for other needs,\n                # just account for its production without re-adding its substrates\n                amount_made = reactions[p_rid]['prods'][s_id]\n                covered_deficit += amount_made\n                if covered_deficit >= deficit: break\n                continue\n\n            required_reactions.add(p_rid)\n            amount_made = reactions[p_rid]['prods'][s_id]\n            covered_deficit += amount_made\n            \n            for sub_id, stoich in reactions[p_rid]['subs'].items():\n                # Naive addition to a dictionary `needed_species` could be non-deterministic.\n                # To handle cumulative needs, let's update a separate dictionary.\n                current_needs_map = dict(agenda)\n                current_needs_map[sub_id] = current_needs_map.get(sub_id, 0) + stoich\n                agenda = list(current_needs_map.items())\n\n            if covered_deficit >= deficit:\n                break\n    \n    sorted_reqs = sorted(list(required_reactions), key=lambda r: (reaction_depth[r], r))\n    \n    return [True, sorted_reqs]\n\ndef solve():\n    test_cases = [\n        # 1. Happy path chain\n        ([({'A': 1, 'B': 1}, {'C': 1}), ({'C': 1}, {'D': 1}), ({'D': 1, 'E': 1}, {'TF': 1})],\n         {'A': 1, 'B': 1, 'E': 1}, 'TF'),\n        # 2. Target initially available\n        ([({'A': 1, 'B': 1}, {'C': 1}), ({'C': 1}, {'D': 1}), ({'D': 1, 'E': 1}, {'TF': 1})],\n         {'A': 1, 'B': 1, 'E': 1, 'TF': 1}, 'TF'),\n        # 3. Stoichiometric edge case\n        ([({'Z': 1}, {'X': 1}), ({'X': 2}, {'Y': 1})],\n         {'X': 1, 'Z': 1}, 'Y'),\n        # 4. Unreachable target\n        ([({'U': 1}, {'TF': 1})], \n         {'A': 1}, 'TF'),\n        # 5. Branching prerequisites\n        ([({'A': 1}, {'P': 1}), ({'A': 1}, {'Q': 1}), ({'P': 1, 'Q': 1}, {'TF': 1})],\n         {'A': 1}, 'TF')\n    ]\n\n    results = []\n    for reactions_def, initial_counts_def, target_species in test_cases:\n        result = find_minimal_reactions(reactions_def, initial_counts_def, target_species)\n        results.append(result)\n\n    result_strings = []\n    for r in results:\n        reachable_str = str(r[0])\n        reactions_str = str(r[1]).replace(\" \", \"\")\n        result_strings.append(f'[{reachable_str},{reactions_str}]')\n    \n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "除了寻找单一路径，计算系统生物学的一个更深层次的任务是识别网络中反复出现的、具有特定功能的连接模式，即“网络基序”(network motifs)。例如，前馈环 (feed-forward loop) 是一种在基因调控网络中被广泛研究的重要基序。本练习将带你动手实现一个基序发现算法，在一个给定的基因调控网络中枚举所有前馈环结构 。更重要的是，本练习将探索在处理真实的、带有统计不确定性的生物数据时，如何通过调整显著性阈值 $\\alpha$ 来过滤互作，并分析这种过滤对基序发现率和假阴性结果的直接影响，从而让你深刻理解统计决策在网络分析中的关键作用。",
            "id": "3317654",
            "problem": "一个有向基因调控相互作用网络可以被建模为一个有向图 $G = (V,E)$，其中 $V$ 是一个有限的基因集合，$E \\subseteq V \\times V$ 是一个有向边集合。每条有向边 $e \\in E$ 都关联一个统计显著性值 $p_e \\in (0,1]$，该值源于在零假设模型下对相互作用存在性进行的假设检验。受限遍历规定，一条边只有在满足显著性约束 $p_e  \\alpha$ 时才是可遍历的，其中 $\\alpha \\in (0,1]$ 是用户选择的显著性阈值。在网络基序分析中，一个前馈环基序（此处定义为一个三节点有向基序）由一个有序三元组 $(u,v,w) \\in V^3$ 构成，其中 $u,v,w$ 互不相同，并且满足 $(u,v) \\in E$、$(u,w) \\in E$ 和 $(v,w) \\in E$。该结构是计算系统生物学中转录网络里一个被广泛研究的调控基序。\n\n考虑以下特定实例。设 $V = \\{A,B,C,D,E,F,G\\}$，并且 $E$ 和边显著性值 $p_e$ 由以下给出：\n- $A \\to B$，其 $p_{A\\to B} = 0.004$\n- $A \\to C$，其 $p_{A\\to C} = 0.02$\n- $A \\to D$，其 $p_{A\\to D} = 0.001$\n- $A \\to E$，其 $p_{A\\to E} = 0.2$\n- $A \\to F$，其 $p_{A\\to F} = 0.05$\n- $B \\to C$，其 $p_{B\\to C} = 0.03$\n- $B \\to D$，其 $p_{B\\to D} = 0.008$\n- $B \\to E$，其 $p_{B\\to E} = 0.06$\n- $B \\to F$，其 $p_{B\\to F} = 0.5$\n- $C \\to E$，其 $p_{C\\to E} = 0.0005$\n- $C \\to F$，其 $p_{C\\to F} = 0.07$\n- $C \\to G$，其 $p_{C\\to G} = 0.09$\n- $D \\to E$，其 $p_{D\\to E} = 0.015$\n- $D \\to F$，其 $p_{D\\to F} = 0.04$\n- $E \\to F$，其 $p_{E\\to F} = 0.009$\n- $E \\to G$，其 $p_{E\\to G} = 0.012$\n- $F \\to G$，其 $p_{F\\to G} = 0.02$\n\n将基准前馈环基序定义为在不应用剪枝时存在的所有基序，即，在上述指定的完整图 $G$ 中，所有满足 $u,v,w$ 互不相同且 $(u,v),(u,w),(v,w) \\in E$ 的有序三元组 $(u,v,w)$，无论其 $p_e$ 值如何。对于给定的阈值 $\\alpha$，定义剪枝后的图为 $G_{\\alpha} = (V,E_{\\alpha})$，其中 $E_{\\alpha} = \\{ e \\in E \\mid p_e  \\alpha \\}$，并将在阈值 $\\alpha$ 下发现的基序定义为在 $G_{\\alpha}$ 中满足基序条件的那些三元组 $(u,v,w)$。设 $M_{\\text{true}}$ 为基准基序的总数，设 $M_{\\text{disc}}(\\alpha)$ 为在阈值 $\\alpha$ 下剪枝后发现的基序数量。将发现率定义为 $r(\\alpha) = M_{\\text{disc}}(\\alpha) / M_{\\text{true}}$（一个在 $[0,1]$ 区间内的小数），并将假阴性定义为 $FN(\\alpha) = M_{\\text{true}} - M_{\\text{disc}}(\\alpha)$（一个整数）。\n\n任务。编写一个完整的程序，该程序能够：\n- 使用指定的 $V$、$E$ 和 $p_e$ 值构建图 $G$。\n- 通过使用一种仅检查邻接关系并遵循有向基序定义的基于遍历的搜索方法，枚举完整图中的所有前馈环基序，从而计算 $M_{\\text{true}}$。\n- 对于给定测试套件中的每个阈值 $\\alpha$，通过剪除 $p_e \\ge \\alpha$ 的边来构建 $G_{\\alpha}$，枚举发现的基序，并计算 $r(\\alpha)$ 和 $FN(\\alpha)$。\n- 使用图遍历和搜索算法来枚举基序，方法是对于每个节点 $u \\in V$，探索所有不同的出邻居有序对 $(v,w)$，并检查有向边 $(v,w)$ 是否存在。\n\n测试套件。使用以下阈值作为 $\\alpha$：$\\{1.0, 0.1, 0.05, 0.02, 0.012, 0.009, 0.0\\}$。这些情况包括无剪枝情景（$\\alpha = 1.0$）、中等剪枝（$\\alpha = 0.1$）、常规截断值（$\\alpha = 0.05$）、与某些边 $p_e$ 值完全相等的阈值以测试严格不等式条件（$\\alpha = 0.02$、$\\alpha = 0.012$、$\\alpha = 0.009$），以及完全剪枝（$\\alpha = 0.0$）。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，每个条目对应给定顺序中的一个测试用例，并且本身是一个双元素列表 $[r(\\alpha), FN(\\alpha)]$。发现率 $r(\\alpha)$ 必须表示为四舍五入到小数点后三位的小数，$FN(\\alpha)$ 必须是一个整数。例如，一个包含两个假设案例的有效输出格式为 $[[0.750,2],[0.333,4]]$。此问题不涉及物理单位或角度。",
            "solution": "用户提供的问题陈述经过了严格的验证过程。\n\n### 步骤 1：提取已知条件\n\n- **图定义**：一个有向图 $G = (V,E)$，其中 $V$ 是基因集合，$E$ 是有向边集合。\n- **顶点集**：$V = \\{A,B,C,D,E,F,G\\}$。\n- **边集和显著性值 ($p_e$)**：\n  - $(A,B)$, $p=0.004$\n  - $(A,C)$, $p=0.02$\n  - $(A,D)$, $p=0.001$\n  - $(A,E)$, $p=0.2$\n  - $(A,F)$, $p=0.05$\n  - $(B,C)$, $p=0.03$\n  - $(B,D)$, $p=0.008$\n  - $(B,E)$, $p=0.06$\n  - $(B,F)$, $p=0.5$\n  - $(C,E)$, $p=0.0005$\n  - $(C,F)$, $p=0.07$\n  - $(C,G)$, $p=0.09$\n  - $(D,E)$, $p=0.015$\n  - $(D,F)$, $p=0.04$\n  - $(E,F)$, $p=0.009$\n  - $(E,G)$, $p=0.012$\n  - $(F,G)$, $p=0.02$\n- **遍历约束**：一条边 $e$ 是可遍历的，如果其显著性 $p_e$ 满足 $p_e  \\alpha$，其中 $\\alpha \\in (0,1]$ 是一个显著性阈值。\n- **前馈环 (FFL) 基序定义**：一个由互不相同的顶点组成的有序三元组 $(u,v,w) \\in V^3$，满足 $(u,v) \\in E$、$(u,w) \\in E$ 和 $(v,w) \\in E$。\n- **基准基序 ($M_{\\text{true}}$)**：完整图 $G$ 中 FFL 基序的总数，不论 $p_e$ 值如何。\n- **剪枝后的图 ($G_{\\alpha}$)**：$G_{\\alpha} = (V,E_{\\alpha})$，其中 $E_{\\alpha} = \\{ e \\in E \\mid p_e  \\alpha \\}$。\n- **发现的基序 ($M_{\\text{disc}}(\\alpha)$)**：剪枝后的图 $G_{\\alpha}$ 中存在的 FFL 基序数量。\n- **发现率 ($r(\\alpha)$)**：$r(\\alpha) = M_{\\text{disc}}(\\alpha) / M_{\\text{true}}$，四舍五入到三位小数。\n- **假阴性 ($FN(\\alpha)$)**：$FN(\\alpha) = M_{\\text{true}} - M_{\\text{disc}}(\\alpha)$，一个整数。\n- **任务要求**：实现一个程序，使用基于遍历的搜索进行 FFL 枚举，为给定的 $\\alpha$ 值测试套件计算 $r(\\alpha)$ 和 $FN(\\alpha)$。\n- **测试套件**：$\\alpha \\in \\{1.0, 0.1, 0.05, 0.02, 0.012, 0.009, 0.0\\}$。\n- **输出格式**：单行 `[[r1,fn1],[r2,fn2],...]`。\n\n### 步骤 2：使用提取的已知条件进行验证\n\n该问题根据既定标准进行评估：\n- **科学依据**：该问题使用了计算系统生物学和图论中标准且广为接受的概念。将基因网络建模为有向图、使用p值表示边的置信度以及分析像前馈环这样的网络基序，都是该领域的基础实践。该设置在科学上是合理的。\n- **适定性**：所有术语（$G, V, E, p_e, \\alpha$, FFL 基序, $M_{\\text{true}}, M_{\\text{disc}}, r, FN$）都有精确的数学定义。输入集（图结构、测试阈值）是完整的，所需的输出也被明确指定。存在唯一的解，并且可以通过算法确定。\n- **客观性**：问题陈述不含主观性、推测或意见。它以正式、客观的语言呈现。\n- **完整性和一致性**：问题是自洽的。解决方案所需的所有数据（节点集、边集、p值、阈值）都已提供。定义或约束中没有矛盾。严格不等式 $p_e  \\alpha$ 已明确说明。\n- **现实性**：网络结构和相关的p值对于小规模生物网络分析是合理的。\n- **结构性和非平凡性**：问题结构良好，需要非平凡的算法实现。该任务涉及图表示、在不同约束下的基序枚举以及派生指标的计算，这构成了一个合法的计算问题。\n\n### 步骤 3：结论与行动\n\n问题是 **有效的**。它具有科学依据、适定性、客观性和完整性。将提供一个解决方案。\n\n### 解法\n\n该问题的解决方案需要在一个有向图中，在变化的边剪枝条件下，系统地枚举前馈环（FFL）基序。该方法的核心是一种为寻找特定三节点FFL结构而定制的图遍历算法。\n\n**1. 图表示**\n一个带有相关边权重（在此例中为p值）的有向图可以高效地使用邻接表来表示。在 Python 中，嵌套字典是一个合适的实现，其中 `graph[u][v]` 存储从节点 $u$ 到节点 $v$ 的有向边的p值。完整的节点集 $V$ 也被存储。\n\n**2. FFL 枚举算法**\n问题将 FFL 定义为一个由不同节点组成的有序三元组 $(u,v,w)$，使得边 $(u,v)$、$(u,w)$ 和 $(v,w)$ 存在。一个直接的算法来找到这些基序，如问题所建议的，如下所示：\n- 遍历每个节点 $u \\in V$。此节点 $u$ 是 FFL 的一个候选源头。\n- 对于每个 $u$，获取其直接出邻居的集合。\n- 遍历所有不同的出邻居有序对 $(v,w)$。\n- 对于每对，检查是否存在有向边 $(v,w)$。\n- 如果边 $(v,w)$ 存在，则三元组 $(u,v,w)$ 形成一个 FFL。\n\n这个过程被封装在一个函数 `count_ffls(adj_list)` 中，它接受一个邻接表作为输入并返回 FFL 的总数。该函数的邻接表将每个节点映射到其出邻居的集合。\n\n**3. 基准计算 ($M_{\\text{true}}$)**\n首先，我们必须确定未剪枝的完整图 $G$ 中 FFL 的总数。这个数就是 $M_{\\text{true}}$。我们构建一个代表完整图的邻接表，其中无论其p值如何，边都存在。然后将 `count_ffls` 函数应用于这个完整的邻接表。\n\n让我们手动枚举 $M_{\\text{true}}$ 以验证算法的基线。\n- 对于 $u=A$，出邻居是 $\\{B, C, D, E, F\\}$。检查节点对：\n  - $(B,C)$: $A \\to B, A \\to C$。边 $B \\to C$ 存在。 **FFL: (A,B,C)**\n  - $(B,D)$: $A \\to B, A \\to D$。边 $B \\to D$ 存在。 **FFL: (A,B,D)**\n  - $(B,E)$: $A \\to B, A \\to E$。边 $B \\to E$ 存在。 **FFL: (A,B,E)**\n  - $(B,F)$: $A \\to B, A \\to F$。边 $B \\to F$ 存在。 **FFL: (A,B,F)**\n  - $(C,E)$: $A \\to C, A \\to E$。边 $C \\to E$ 存在。 **FFL: (A,C,E)**\n  - $(C,F)$: $A \\to C, A \\to F$。边 $C \\to F$ 存在。 **FFL: (A,C,F)**\n  - $(D,E)$: $A \\to D, A \\to E$。边 $D \\to E$ 存在。 **FFL: (A,D,E)**\n  - $(D,F)$: $A \\to D, A \\to F$。边 $D \\to F$ 存在。 **FFL: (A,D,F)**\n  - $(E,F)$: $A \\to E, A \\to F$。边 $E \\to F$ 存在。 **FFL: (A,E,F)**\n  (来自 A 的总数: $9$)\n- 对于 $u=B$，出邻居是 $\\{C, D, E, F\\}$。检查节点对：\n  - $(C,E)$: $B \\to C, B \\to E$。边 $C \\to E$ 存在。 **FFL: (B,C,E)**\n  - $(C,F)$: $B \\to C, B \\to F$。边 $C \\to F$ 存在。 **FFL: (B,C,F)**\n  - $(D,E)$: $B \\to D, B \\to E$。边 $D \\to E$ 存在。 **FFL: (B,D,E)**\n  - $(D,F)$: $B \\to D, B \\to F$。边 $D \\to F$ 存在。 **FFL: (B,D,F)**\n  (来自 B 的总数: $4$)\n- 对于 $u=C$，出邻居是 $\\{E, F, G\\}$。检查节点对：\n  - $(E,F)$: $C \\to E, C \\to F$。边 $E \\to F$ 存在。 **FFL: (C,E,F)**\n  - $(E,G)$: $C \\to E, C \\to G$。边 $E \\to G$ 存在。 **FFL: (C,E,G)**\n  - $(F,G)$: $C \\to F, C \\to G$。边 $F \\to G$ 存在。 **FFL: (C,F,G)**\n  (来自 C 的总数: $3$)\n- 对于 $u=D$，出邻居是 $\\{E, F\\}$。检查节点对：\n  - $(E,F)$: $D \\to E, D \\to F$。边 $E \\to F$ 存在。 **FFL: (D,E,F)**\n  (来自 D 的总数: $1$)\n- 对于 $u=E$，出邻居是 $\\{F, G\\}$。检查节点对：\n  - $(F,G)$: $E \\to F, E \\to G$。边 $F \\to G$ 存在。 **FFL: (E,F,G)**\n  (来自 E 的总数: $1$)\n- 节点 F 和 G 的出邻居少于两个，不能作为 FFL 的源头。\n基准基序总数: $M_{\\text{true}} = 9 + 4 + 3 + 1 + 1 = 18$。\n\n**4. 对每个阈值 $\\alpha$ 进行计算**\n主循环遍历所提供测试套件中的每个 $\\alpha$。对于每个 $\\alpha$：\n- 构建一个新的、剪枝后的 $G_{\\alpha}$ 邻接表。这通过遍历原始完整图中的所有边 $(u, v)$ 来完成，只有当其p值 $p_{u \\to v}$ 严格小于 $\\alpha$ 时，才将该边包含在剪枝后的列表中。\n- 使用这个剪枝后的邻接表调用 `count_ffls` 函数来计算 $M_{\\text{disc}}(\\alpha)$。\n- 计算发现率 $r(\\alpha) = M_{\\text{disc}}(\\alpha) / M_{\\text{true}}$ 和假阴性 $FN(\\alpha) = M_{\\text{true}} - M_{\\text{disc}}(\\alpha)$。如果 $M_{\\text{true}}$ 为 $0$，则 $r(\\alpha)$ 定义为 $0$ 以避免除以零。\n- 存储结果对 $[r(\\alpha), FN(\\alpha)]$，其中 $r(\\alpha)$ 格式化为三位小数。\n\n**5. 最终输出生成**\n处理完所有 $\\alpha$ 值后，将结果对列表格式化为指定的单行字符串格式：`[[r1,fn1],[r2,fn2],...]`。例如，比率 $1.0$ 会被格式化为 $1.000$。\n\n这种系统化的程序确保每个测试用例都根据问题的严格定义得到正确评估。使用一个作用于动态生成的剪枝图的专用 FFL 计数函数，将关注点分离，从而实现清晰且正确的实现。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the graph theory problem for computational systems biology.\n    - Constructs the gene regulatory network.\n    - Computes ground-truth feed-forward loop (FFL) motifs.\n    - For each alpha threshold, computes discovered motifs, discovery rate, \n      and false negatives.\n    - Formats the output as specified.\n    \"\"\"\n\n    # Step 1: Define the graph V, E, and p-values\n    V = {'A', 'B', 'C', 'D', 'E', 'F', 'G'}\n    \n    # Store the graph with p-values in a adjacency list-style dictionary\n    graph_data = {\n        'A': {'B': 0.004, 'C': 0.02, 'D': 0.001, 'E': 0.2, 'F': 0.05},\n        'B': {'C': 0.03, 'D': 0.008, 'E': 0.06, 'F': 0.5},\n        'C': {'E': 0.0005, 'F': 0.07, 'G': 0.09},\n        'D': {'E': 0.015, 'F': 0.04},\n        'E': {'F': 0.009, 'G': 0.012},\n        'F': {'G': 0.02},\n        'G': {}\n    }\n\n    test_alphas = [1.0, 0.1, 0.05, 0.02, 0.012, 0.009, 0.0]\n\n    def count_ffls(adj_list):\n        \"\"\"\n        Counts the number of feed-forward loops in a graph represented\n        by an adjacency list.\n        An FFL is a motif (u,v,w) where u-v, u-w, and v-w.\n        \"\"\"\n        motif_count = 0\n        nodes = list(adj_list.keys())\n        \n        for u in nodes:\n            # A node needs at least two out-neighbors to be the source of an FFL\n            if u not in adj_list or len(adj_list[u])  2:\n                continue\n            \n            out_neighbors_u = list(adj_list[u])\n            # Iterate over all ordered pairs of distinct out-neighbors\n            for i in range(len(out_neighbors_u)):\n                for j in range(len(out_neighbors_u)):\n                    if i == j:\n                        continue\n                    \n                    v = out_neighbors_u[i]\n                    w = out_neighbors_u[j]\n                    \n                    # Check for the closing edge v-w\n                    if v in adj_list and w in adj_list[v]:\n                        motif_count += 1\n                        \n        return motif_count\n\n    # Step 2: Compute M_true (ground-truth motifs in the full graph)\n    # The full adjacency list includes all defined edges.\n    full_adj_list = {u: set(targets.keys()) for u, targets in graph_data.items()}\n    # Ensure all nodes are in the adj list, even if they have no outgoing edges\n    for node in V:\n        if node not in full_adj_list:\n            full_adj_list[node] = set()\n\n    M_true = count_ffls(full_adj_list)\n    \n    results = []\n\n    # Step 3: Iterate through test cases\n    for alpha in test_alphas:\n        # Construct the pruned graph G_alpha\n        pruned_adj_list = {node: set() for node in V}\n        for u, targets in graph_data.items():\n            for v, p_val in targets.items():\n                if p_val  alpha:\n                    pruned_adj_list[u].add(v)\n        \n        # Compute M_disc(alpha)\n        M_disc = count_ffls(pruned_adj_list)\n        \n        # Compute FN(alpha)\n        FN = M_true - M_disc\n        \n        # Compute r(alpha)\n        if M_true > 0:\n            r = M_disc / M_true\n        else:\n            r = 0.0\n\n        # Store the formatted results for this alpha\n        results.append([r, FN])\n\n    # Step 4: Format the final output string\n    # e.g., [[0.750,2],[0.333,4]]\n    output_parts = []\n    for r_val, fn_val in results:\n        # Use f-string formatting to ensure three decimal places, e.g., 0.750\n        output_parts.append(f'[{r_val:.3f},{fn_val}]')\n        \n    final_output_string = f\"[{','.join(output_parts)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "在巨大的生物网络中寻找最优路径时，无信息搜索算法（如BFS）的效率可能很低。A* (A-star) 等启发式搜索算法通过一个“启发函数”$h(v)$ 来估计从当前节点到目标的剩余成本，从而能够更智能地指导搜索方向。本高级练习将探索一个前沿课题：如何利用图嵌入 (graph embeddings) 等现代机器学习技术为A*算法设计启发函数 。你将从一个基于嵌入向量的原始启发函数出发，系统地分析其是否满足可容许性 (admissibility) 和一致性 (consistency) 这两个关键理论属性，并亲手实现修正程序，最终得到一个理论上保证最优解的、高效的启发函数。",
            "id": "3317688",
            "problem": "您将获得一些带权图，这些图模拟了计算系统生物学中常见的相互作用或反应连通性，其中节点代表生物实体，边代表具有非负成本的可能转换。请考虑这样一个问题：从连续图嵌入中为 A-star (A*) 算法设计启发式函数，并分析其可采纳性和一致性。请完全在图和向量的数学背景下进行研究。假设所有边的权重都是非负的，并且所有节点都可以到达指定的目标。\n\n基本定义如下：\n- 一个具有非负边权重的有限有向或无向图是一个对 $(V,E)$，带有一个权重函数 $w : E \\to \\mathbb{R}_{\\ge 0}$。最短路径距离 $d_G(u,v)$ 是从 $u$ 到 $v$ 的所有路径中的最小总权重。如果没有路径，则定义 $d_G(u,v) = +\\infty$，但在此问题中，对于指定的目标 $t$ 和所有 $u \\in V$，所有测试用例都满足 $d_G(u,t)  +\\infty$。\n- A-star (A*) 搜索使用一个评估函数 $f(x) = g(x) + h(x)$，其中 $g(x)$ 是从起点到 $x$ 的已知最优成本，而 $h(x)$ 是到指定目标 $t$ 的剩余成本的启发式估计。\n- 如果对于所有节点 $v$，都有 $h(v) \\le d_G(v,t)$，则启发式函数 $h$ 是可采纳的。如果对于每条边 $(u,v) \\in E$，都有 $h(u) \\le w(u,v) + h(v)$，并且 $h(t) = 0$，则启发式函数 $h$ 是一致的（也称为单调的）。\n\n基于嵌入的启发式函数：\n- 每个节点 $v \\in V$都有一个由图嵌入方法（例如 node2vec）生成的向量嵌入 $z(v) \\in \\mathbb{R}^d$。将原始嵌入启发式函数 $h_{\\text{raw}}(v)$ 定义为 $z(v)$ 与目标 $t$ 的嵌入 $z(t)$ 在潜在空间中的欧几里得距离。请使用标准欧几里得范数。\n\n您的任务：\n1. 对于每个测试用例图和指定的目标 $t$，从嵌入中构建原始启发式函数 $h_{\\text{raw}}(v)$ 并计算：\n   - 可采纳性违例的数量，定义为满足 $h_{\\text{raw}}(v)  d_G(v,t)$ 的节点 $v$ 的数量。\n   - 一致性违例的数量，定义为满足 $h_{\\text{raw}}(u)  w(u,v) + h_{\\text{raw}}(v)$ 的边 $(u,v)$ 的数量，并约定 $h_{\\text{raw}}(t) = 0$。\n2. 设计并实现一种保持可采纳性的原始启发式函数重缩放方法。选择最大的全局标量 $\\alpha \\in \\mathbb{R}_{\\ge 0}$，使得对于所有与目标嵌入距离严格为正的节点 $v$，缩放后的启发式函数 $h_{\\text{scaled}}(v) = \\alpha \\cdot h_{\\text{raw}}(v)$ 满足 $h_{\\text{scaled}}(v) \\le d_G(v,t)$。对于与目标嵌入距离为零的节点，将其缩放后的启发式函数值设为零。按照任务1的方式，计算 $h_{\\text{scaled}}$ 的可采纳性和一致性违例数量。\n3. 设计并实现一个修复程序，该程序在保持可采纳性的同时强制实现一致性。从一个可采纳的启发式函数（例如 $h_{\\text{scaled}}$）开始，沿边迭代应用基于边的三角不等式闭包，并固定 $h(t) = 0$，直到没有违例为止。最终得到一个既一致又可采纳的启发式函数 $h_{\\text{repaired}}$。按照任务1的方式，计算 $h_{\\text{repaired}}$ 的可采纳性和一致性违例数量。\n\n测试套件：\n提供一个程序，为以下测试用例计算上述值。所有图都由用整数标记的节点集、带权边和一个目标节点索引 $t$ 给出。所有嵌入坐标都以实数形式给出。对于无向图，每条权重为 $w$ 的无向边 $\\{u,v\\}$ 等价于两条权重均为 $w$ 的有向边 $(u,v)$ 和 $(v,u)$。\n\n- 测试用例A（无向，带权）：\n  - 节点：$V = \\{0,1,2,3,4,5\\}$，目标 $t = 5$。\n  - 带权边（无向）：$(0,1,2)$, $(1,2,2)$, $(2,5,3)$, $(0,3,5)$, $(3,4,1)$, $(4,5,1)$, $(1,4,4)$。\n  - 在 $\\mathbb{R}^2$ 中的嵌入：$z(0) = (5.0,0.0)$, $z(1) = (8.0,0.0)$, $z(2) = (0.5,0.2)$, $z(3) = (4.6,0.1)$, $z(4) = (0.9,0.1)$, $z(5) = (0.0,0.0)$。\n\n- 测试用例B（有向，带权）：\n  - 节点：$V = \\{0,1,2,3,4\\}$，目标 $t = 4$。\n  - 带权有向边：$(0,1,1)$, $(1,2,1)$, $(2,4,5)$, $(0,3,2)$, $(3,4,2)$, $(1,4,10)$。\n  - 在 $\\mathbb{R}^2$ 中的嵌入：$z(0) = (1.9,0.0)$, $z(1) = (9.0,0.0)$, $z(2) = (10.0,0.0)$, $z(3) = (1.9,0.1)$, $z(4) = (0.0,0.0)$。\n\n- 测试用例C（无向，路径图）：\n  - 节点：$V = \\{0,1,2,3\\}$，目标 $t = 3$。\n  - 带权无向边：$(0,1,1)$, $(1,2,1)$, $(2,3,1)$。\n  - 在 $\\mathbb{R}^2$ 中的嵌入：$z(0) = (10.0,0.0)$, $z(1) = (6.0,0.0)$, $z(2) = (3.2,0.0)$, $z(3) = (0.0,0.0)$。\n\n- 测试用例D（无向，零距离边情况）：\n  - 节点：$V = \\{0,1,2,3\\}$，目标 $t = 3$。\n  - 带权无向边：$(0,3,5)$, $(0,1,2)$, $(1,3,2)$, $(2,3,1)$, $(1,2,3)$。\n  - 在 $\\mathbb{R}^2$ 中的嵌入：$z(0) = (5.0,0.0)$, $z(1) = (0.0,0.0)$, $z(2) = (0.0,0.0)$, $z(3) = (0.0,0.0)$。\n\n要求的最终输出格式：\n- 对于每个测试用例，输出一个包含六个整数的列表 $[v_1,v_2,v_3,v_4,v_5,v_6]$，其中：\n  - $v_1$ 是 $h_{\\text{raw}}$ 的可采纳性违例数量，\n  - $v_2$ 是 $h_{\\text{raw}}$ 的一致性违例数量，\n  - $v_3$ 是 $h_{\\text{scaled}}$ 的可采纳性违例数量，\n  - $v_4$ 是 $h_{\\text{scaled}}$ 的一致性违例数量，\n  - $v_5$ 是 $h_{\\text{repaired}}$ 的可采纳性违例数量，\n  - $v_6$ 是 $h_{\\text{repaired}}$ 的一致性违例数量。\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，格式为一个用方括号括起来的逗号分隔列表。列表中的每个元素是对应一个测试用例的六整数列表，顺序为 A、B、C、D。例如：$[[a_1,a_2,a_3,a_4,a_5,a_6],[b_1,b_2,b_3,b_4,b_5,b_6],[c_1,c_2,c_3,c_4,c_5,c_6],[d_1,d_2,d_3,d_4,d_5,d_6]]$。",
            "solution": "用户提供了一个关于为 A* 搜索算法设计和分析启发式函数的问题。这是一个在人工智能和计算科学中的基础课题，其背景来自于系统生物学。该问题定义明确，数学上合理，并提出了一套清晰的计算任务。我将着手提供一个完整的解决方案。\n\n### 步骤 1：问题验证\n\n**1. 提取已知条件：**\n- **图**：带权、有向或无向图 $(V,E)$，带有一个权重函数 $w : E \\to \\mathbb{R}_{\\ge 0}$。\n- **最短路径距离**：$d_G(u,v)$ 是从 $u$ 到 $v$ 的路径的最小总权重。已知对于任何节点 $u$，都存在一条到目标节点 $t$ 的路径，因此 $d_G(u,t)  +\\infty$。\n- **A* 评估函数**：$f(x) = g(x) + h(x)$。\n- **可采纳性**：如果对于所有 $v \\in V$ 都有 $h(v) \\le d_G(v,t)$，则启发式函数 $h$ 是可采纳的。\n- **一致性（单调性）**：如果对于每条边 $(u,v) \\in E$ 都有 $h(u) \\le w(u,v) + h(v)$，并且 $h(t) = 0$，则启发式函数 $h$ 是一致的。\n- **节点嵌入**：每个节点 $v$ 都有一个向量嵌入 $z(v) \\in \\mathbb{R}^d$。\n- **原始启发式函数**：$h_{\\text{raw}}(v)$ 是欧几里得距离 $\\|z(v) - z(t)\\|_2$。\n- **任务 1**：计算 $h_{\\text{raw}}$ 的可采纳性和一致性违例数量。\n- **任务 2**：通过找到确保所有节点可采纳性的最大 $\\alpha \\ge 0$，设计一个保持可采纳性的缩放启发式函数 $h_{\\text{scaled}}(v) = \\alpha \\cdot h_{\\text{raw}}(v)$。计算 $h_{\\text{scaled}}$ 的违例数量。\n- **任务 3**：设计一个强制一致性的修复程序，从一个可采纳的启发式函数创建 $h_{\\text{repaired}}$，使其既可采纳又一致。计算 $h_{\\text{repaired}}$ 的违例数量。\n- **测试用例**：提供了四个具体的测试用例（A, B, C, D），包含图结构、边权重、节点嵌入和目标节点。\n- **输出格式**：一个列表的列表，其中每个内部列表包含六个整数违例计数：$[v_1, v_2, v_3, v_4, v_5, v_6]$，分别对应于（adm-raw, con-raw, adm-scaled, con-scaled, adm-repaired, con-repaired）。\n\n**2. 使用提取的已知条件进行验证：**\n- **科学依据**：该问题基于图论和计算机科学中已建立的基础概念（A* 搜索、启发式函数、最短路径算法）。没有科学上的不合理之处。\n- **适定性**：这些任务是具有具体目标的明确定义的算法。给定输入，可以唯一确定所需的输出。所有节点都能到达目标的条件确保了所有最短路径距离 $d_G(v,t)$ 都是有限的。\n- **客观性**：语言精确且数学化。定义是标准的。\n- **完整性**：为测试用例提供了所有必要的数据（图、权重、嵌入、目标）。定义是自包含的。\n- **其他标准**：该问题不是隐喻性的、琐碎的或不可验证的。这是一个标准的算法问题。\n\n**3. 结论与行动：**\n问题是**有效的**。我将继续开发一个完整的解决方案。\n\n### 步骤 2：解决方案设计\n\n解决方案将构造成针对每个测试用例的一系列计算。\n\n**第 0 部分：最短路径距离的预计算**\n评估启发式函数的基准真相是到目标的真实最短路径距离 $d_G(v,t)$。由于所有边权重都是非负的，Dijkstra 算法是合适的方法。要计算从所有节点*到*单个目标节点 $t$ 的最短距离，我们可以在所有边都反转的图上从 $t$ 开始运行 Dijkstra 算法。对于无向图，反转后的图与原始图相同。我们将这些距离的向量表示为 $\\mathbf{d}_t$。\n\n**第 1 部分：原始启发式函数 ($h_{\\text{raw}}$) 的分析**\n1.  **计算 $h_{\\text{raw}}$**：对于每个节点 $v \\in V$，原始启发式函数计算为其嵌入与目标节点嵌入之差的欧几里得范数：\n    $$h_{\\text{raw}}(v) = \\|z(v) - z(t)\\|_2$$\n2.  **计算可采纳性违例**：如果 $h_{\\text{raw}}(v)  d_G(v,t)$，则节点 $v$ 发生可采纳性违例。我们计算满足此不等式的节点数量。\n    $$v_1 = |\\{v \\in V \\mid h_{\\text{raw}}(v)  d_G(v,t)\\}|$$\n3.  **计算一致性违例**：如果有向边 $(u,v) \\in E$ 满足 $h_{\\text{raw}}(u)  w(u,v) + h_{\\text{raw}}(v)$，则发生一致性违例。我们计算满足此不等式的边的数量。注意，对于无向边，我们必须对两个对应的有向边都检查该条件。问题陈述了约定 $h(t)=0$，这通过 $h_{\\text{raw}}$ 的定义自然得到满足。\n    $$v_2 = |\\{(u,v) \\in E \\mid h_{\\text{raw}}(u)  w(u,v) + h_{\\text{raw}}(v)\\}|$$\n\n**第 2 部分：缩放后启发式函数 ($h_{\\text{scaled}}$) 的分析**\n1.  **计算缩放因子 $\\alpha$**：我们需要找到最大的非负标量 $\\alpha$，使得缩放后的启发式函数 $h_{\\text{scaled}}(v) = \\alpha \\cdot h_{\\text{raw}}(v)$ 是可采纳的。可采纳性条件是对于所有 $v \\in V$ 都有 $\\alpha \\cdot h_{\\text{raw}}(v) \\le d_G(v,t)$。对于 $h_{\\text{raw}}(v)  0$ 的节点，这意味着 $\\alpha \\le \\frac{d_G(v,t)}{h_{\\text{raw}}(v)}$。为了对所有此类节点都满足此条件，$\\alpha$ 必须是这些比率中的最小值。\n    $$\\alpha = \\min_{v \\in V, h_{\\text{raw}}(v)  0} \\left\\{ \\frac{d_G(v,t)}{h_{\\text{raw}}(v)} \\right\\}$$\n    如果集合 $\\{v \\in V \\mid h_{\\text{raw}}(v)  0\\}$ 为空，则所有非目标节点都与目标具有相同的嵌入。在这种情况下，$h_{\\text{raw}}$ 恒等于零，并且已经具备可采纳性和一致性。对 $\\alpha$ 的条件对于任何 $\\alpha \\ge 0$ 都无意义地为真。在这种无意义的情况下，一个实用的约定是设置 $\\alpha = 1.0$。\n2.  **计算 $h_{\\text{scaled}}$**：使用计算出的 $\\alpha$，我们为所有节点找到缩放后的启发式函数：\n    $$h_{\\text{scaled}}(v) = \\alpha \\cdot h_{\\text{raw}}(v)$$\n3.  **计算可采纳性违例**：根据构造，$h_{\\text{scaled}}$ 是可采纳的。因此，可采纳性违例的数量为零。\n    $$v_3 = 0$$\n4.  **计算一致性违例**：我们为所有边检查一致性条件，与 $h_{\\text{raw}}$ 的情况相同。\n    $$v_4 = |\\{(u,v) \\in E \\mid h_{\\text{scaled}}(u)  w(u,v) + h_{\\text{scaled}}(v)\\}|$$\n\n**第 3 部分：修复后启发式函数 ($h_{\\text{repaired}}$) 的分析**\n1.  **计算 $h_{\\text{repaired}}$**：我们从可采纳的启发式函数 $h_{\\text{repaired}}^{(0)}(v) = h_{\\text{scaled}}(v)$ 开始。修复过程迭代地强制执行一致性约束，直到没有违例为止。这是一个类似于 Bellman-Ford 算法的松弛过程。我们重复遍历所有边并更新启发式函数值。最终的启发式函数必须满足 $h_{\\text{repaired}}(t)=0$。过程如下：\n    a. 对于所有 $v \\in V$，初始化 $h(v) \\leftarrow h_{\\text{scaled}}(v)$。\n    b. 设置一个标志 `changed = true`。\n    c. 当 `changed` 为真时循环：\n        i. 设置 `changed = false`。\n        ii. 对于每条边 $(u,v) \\in E$：\n            - 如果 $h(u)  w(u,v) + h(v)$：\n                - 更新 $h(u) \\leftarrow w(u,v) + h(v)$。\n                - 设置 `changed = true`。\n    该过程保证会终止，因为启发式函数值是非递增的，并且有下界 $0$。最终的启发式函数 $h_{\\text{repaired}}$ 就是这个过程的结果。\n2.  **计算可采纳性违例**：修复过程只会减小启发式函数的值。由于我们从一个可采纳的启发式函数 ($h_{\\text{scaled}}(v) \\le d_G(v,t)$) 开始，最终的启发式函数也必定是可采纳的 ($h_{\\text{repaired}}(v) \\le h_{\\text{scaled}}(v) \\le d_G(v,t)$)。违例数量为零。\n    $$v_5 = 0$$\n3.  **计算一致性违例**：根据构造，当没有一致性违例时算法终止。违例数量为零。\n    $$v_6 = 0$$\n\n这个完整的程序将使用 Python 实现，其中 `numpy` 用于向量计算，`scipy.sparse.csgraph.dijkstra` 用于计算最短路径。",
            "answer": "```python\nimport numpy as np\nfrom scipy.sparse import csr_matrix\nfrom scipy.sparse.csgraph import dijkstra\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final results.\n    \"\"\"\n    test_cases = [\n        {\n            \"name\": \"A\",\n            \"nodes\": 6,\n            \"goal\": 5,\n            \"directed\": False,\n            \"edges\": [(0, 1, 2), (1, 2, 2), (2, 5, 3), (0, 3, 5), (3, 4, 1), (4, 5, 1), (1, 4, 4)],\n            \"embeddings\": {0: (5.0, 0.0), 1: (8.0, 0.0), 2: (0.5, 0.2), 3: (4.6, 0.1), 4: (0.9, 0.1), 5: (0.0, 0.0)},\n        },\n        {\n            \"name\": \"B\",\n            \"nodes\": 5,\n            \"goal\": 4,\n            \"directed\": True,\n            \"edges\": [(0, 1, 1), (1, 2, 1), (2, 4, 5), (0, 3, 2), (3, 4, 2), (1, 4, 10)],\n            \"embeddings\": {0: (1.9, 0.0), 1: (9.0, 0.0), 2: (10.0, 0.0), 3: (1.9, 0.1), 4: (0.0, 0.0)},\n        },\n        {\n            \"name\": \"C\",\n            \"nodes\": 4,\n            \"goal\": 3,\n            \"directed\": False,\n            \"edges\": [(0, 1, 1), (1, 2, 1), (2, 3, 1)],\n            \"embeddings\": {0: (10.0, 0.0), 1: (6.0, 0.0), 2: (3.2, 0.0), 3: (0.0, 0.0)},\n        },\n        {\n            \"name\": \"D\",\n            \"nodes\": 4,\n            \"goal\": 3,\n            \"directed\": False,\n            \"edges\": [(0, 3, 5), (0, 1, 2), (1, 3, 2), (2, 3, 1), (1, 2, 3)],\n            \"embeddings\": {0: (5.0, 0.0), 1: (0.0, 0.0), 2: (0.0, 0.0), 3: (0.0, 0.0)},\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        results.append(process_case(case))\n\n    # Format the final output string\n    output_str = f\"[\" + \",\".join([str(r) for r in results]) + \"]\"\n    output_str = output_str.replace(\" \", \"\") # Remove spaces for compact representation\n    print(output_str)\n\ndef process_case(case):\n    \"\"\"\n    Processes a single test case and returns the 6 violation counts.\n    \"\"\"\n    num_nodes = case[\"nodes\"]\n    goal_node = case[\"goal\"]\n    is_directed = case[\"directed\"]\n    \n    # Store all directed edges for consistency checking\n    all_edges = []\n    \n    # Build graph for Dijkstra\n    row, col, data = [], [], []\n    for u, v, w in case[\"edges\"]:\n        row.append(u)\n        col.append(v)\n        data.append(w)\n        all_edges.append((u, v, w))\n        if not is_directed:\n            row.append(v)\n            col.append(u)\n            data.append(w)\n            all_edges.append((v, u, w))\n    \n    graph_matrix = csr_matrix((data, (row, col)), shape=(num_nodes, num_nodes))\n\n    # --- Part 0: Calculate shortest path distances to goal ---\n    # To get distances TO goal t, run Dijkstra from t on the transposed graph.\n    graph_transposed = graph_matrix.transpose() if is_directed else graph_matrix\n    d_G = dijkstra(csgraph=graph_transposed, directed=True, indices=goal_node)\n\n    # --- Part 1: Raw Heuristic ---\n    z_goal = np.array(case[\"embeddings\"][goal_node])\n    h_raw = np.array([np.linalg.norm(np.array(case[\"embeddings\"][v]) - z_goal) for v in range(num_nodes)])\n    \n    # Admissibility violations for h_raw\n    adm_violations_raw = np.sum(h_raw > d_G)\n    \n    # Consistency violations for h_raw\n    con_violations_raw = 0\n    for u, v, w in all_edges:\n        if h_raw[u] > w + h_raw[v]:\n            con_violations_raw += 1\n            \n    # --- Part 2: Scaled Heuristic ---\n    h_scaled = np.zeros(num_nodes)\n    \n    # Nodes where raw heuristic is positive\n    positive_h_raw_indices = np.where(h_raw > 1e-9)[0]\n    \n    if len(positive_h_raw_indices) > 0:\n        ratios = d_G[positive_h_raw_indices] / h_raw[positive_h_raw_indices]\n        alpha = np.min(ratios)\n        h_scaled = alpha * h_raw\n    else:\n        # If all h_raw are 0, heuristic is already admissible/consistent. Alpha can be 1.\n        alpha = 1.0 # Or 0.0, either gives h_scaled = 0.\n        h_scaled = h_raw.copy()\n\n    # Admissibility violations for h_scaled (should be 0 by construction)\n    adm_violations_scaled = np.sum(h_scaled > d_G + 1e-9) # Use tolerance for float comparison\n    \n    # Consistency violations for h_scaled\n    con_violations_scaled = 0\n    for u, v, w in all_edges:\n        if h_scaled[u] > w + h_scaled[v] + 1e-9: # Use tolerance\n            con_violations_scaled += 1\n            \n    # --- Part 3: Repaired Heuristic ---\n    h_repaired = h_scaled.copy()\n    \n    # Iteratively enforce consistency until convergence\n    changed = True\n    while changed:\n        changed = False\n        for u, v, w in all_edges:\n            # The heuristic at the goal is fixed at 0.\n            # Do not update h(t) even if there are outgoing edges from t.\n            # The consistency check h(t) = w(t,v)+h(v) becomes 0 = w+h(v) which always holds.\n            if h_repaired[u] > w + h_repaired[v] + 1e-9:\n                h_repaired[u] = w + h_repaired[v]\n                changed = True\n                \n    # Admissibility violations for h_repaired (should be 0)\n    adm_violations_repaired = np.sum(h_repaired > d_G + 1e-9)\n    \n    # Consistency violations for h_repaired (should be 0)\n    con_violations_repaired = 0\n    for u, v, w in all_edges:\n        if h_repaired[u] > w + h_repaired[v] + 1e-9:\n            con_violations_repaired += 1\n            \n    return [\n        int(adm_violations_raw), int(con_violations_raw),\n        int(adm_violations_scaled), int(con_violations_scaled),\n        int(adm_violations_repaired), int(con_violations_repaired)\n    ]\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}