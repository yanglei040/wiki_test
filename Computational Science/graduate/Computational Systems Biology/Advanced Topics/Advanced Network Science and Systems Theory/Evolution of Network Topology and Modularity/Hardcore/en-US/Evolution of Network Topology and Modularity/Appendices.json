{
    "hands_on_practices": [
        {
            "introduction": "To understand how complex biological networks came to be, we can build and analyze generative models that simulate their evolution. The duplication-divergence mechanism is a cornerstone model, inspired by gene duplication events, that explains how networks grow and acquire new connections over time. This practice will guide you through a mean-field analysis to derive key topological properties, such as the degree distribution, directly from the model's parameters . Mastering this analytical approach is fundamental to connecting microscopic evolutionary events to macroscopic network structure.",
            "id": "3306719",
            "problem": "Consider an undirected, simple network that evolves via the following duplication–divergence mechanism, motivated by gene regulatory and protein interaction network evolution. Let the initial network at discrete time $t= t_{0}$ have $N(t_{0}) = N_{0} \\ge 2$ nodes and $E(t_{0}) = E_{0}$ edges. For $t = t_{0}, t_{0}+1, \\dots$, perform one growth step consisting of:\n1. Choose a target node $v_{t}$ uniformly at random from the current node set of size $N(t)$.\n2. Add a new node $u_{t+1}$. For each neighbor $w$ of $v_{t}$, independently add the edge $\\{u_{t+1}, w\\}$ with probability $p \\in (0,1)$ (edge retention under divergence).\n3. Independently of step 2, add the edge $\\{u_{t+1}, v_{t}\\}$ with probability $q \\in [0,1]$ (innovation).\n\nNo other edges are added, and no edges are deleted except implicitly through non-retention in step 2. Let $k_{i}(t)$ denote the degree of a pre-existing node $i$ at time $t$, and let $\\langle k \\rangle(t) = 2 E(t)/N(t)$ denote the average degree at time $t$.\n\nWorking in the continuum mean-field limit in which $N(t) \\approx t$ for large $t$, answer the following:\n(a) Starting from linearity of expectation and uniform target selection, derive a mean-field ordinary differential equation (ODE) for the expected evolution of the degree of a fixed pre-existing node $i$,\n$$\n\\frac{ \\mathrm{d} \\,\\mathbb{E}[k_{i}(t)] }{ \\mathrm{d} t } \\, ,\n$$\nexpressed in terms of $p$, $q$, $t$, and $\\mathbb{E}[k_{i}(t)]$.\n(b) Solve the ODE from part (a) to obtain $\\mathbb{E}[k_{i}(t)]$ for $t \\gg t_{i}$, where $t_{i}$ is the birth time of node $i$, in terms of its initial condition at $t_{i}$.\n(c) Using the solution from part (b) and the fact that birth times are asymptotically uniform, derive the asymptotic tail exponent $\\gamma$ of the stationary degree distribution $P(k) \\sim k^{-\\gamma}$, if it exists, as a function of $p$ and $q$.\n(d) Derive a mean-field ODE for $E(t)$ and obtain the large-$t$ asymptotics of the average degree $\\langle k \\rangle(t)$. From this, determine the range of $p$ for which the network remains sparse, defined by $\\sup_{t} \\langle k \\rangle(t) < \\infty$, and discuss how $q$ enters this condition.\n(e) For the clustering structure at birth of the new node $u_{t+1}$, let $C(v_{t})$ denote the local clustering coefficient of $v_{t}$ prior to duplication. Derive an expression for the expected number of triangles incident to $u_{t+1}$ at birth in terms of $p$, $q$, $k_{v_{t}}$, and $C(v_{t})$, and use a mean-field approximation to argue how the expected local clustering coefficient of $u_{t+1}$ compares to $C(v_{t})$ for large $k_{v_{t}}$.\n\nProvide all derivations explicitly. Express your final answer as a single closed-form analytical expression for the asymptotic degree-distribution exponent $\\gamma$ in terms of $p$ and $q$. No numerical approximation or rounding is required.",
            "solution": "The problem asks for an analysis of a network evolving via a duplication–divergence mechanism. I will first validate the problem statement and then proceed to solve the five parts in sequence as requested.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Network model:** Undirected, simple network.\n- **Initial conditions:** At time $t= t_{0}$, the network has $N(t_{0}) = N_{0} \\ge 2$ nodes and $E(t_{0}) = E_{0}$ edges.\n- **Growth process (for $t = t_{0}, t_{0}+1, \\dots$):**\n    1. A target node $v_{t}$ is chosen uniformly at random from the current set of $N(t)$ nodes.\n    2. A new node $u_{t+1}$ is added. For each neighbor $w$ of $v_{t}$, an edge $\\{u_{t+1}, w\\}$ is added with probability $p \\in (0,1)$.\n    3. An edge $\\{u_{t+1}, v_{t}\\}$ is added with probability $q \\in [0,1]$.\n- **Notation:** $k_{i}(t)$ is the degree of node $i$ at time $t$. $\\langle k \\rangle(t) = 2 E(t)/N(t)$ is the average degree.\n- **Approximation:** Continuum mean-field limit where $N(t) \\approx t$ for large $t$.\n- **Tasks:**\n    (a) Derive an ODE for $\\frac{ \\mathrm{d} \\,\\mathbb{E}[k_{i}(t)] }{ \\mathrm{d} t }$.\n    (b) Solve the ODE for $\\mathbb{E}[k_{i}(t)]$.\n    (c) Derive the asymptotic degree distribution tail exponent $\\gamma$.\n    (d) Derive an ODE for $E(t)$, find the asymptotics of $\\langle k \\rangle(t)$, and determine the condition for sparseness.\n    (e) Analyze the clustering of the new node $u_{t+1}$.\n- **Final Answer Requirement:** A single closed-form analytical expression for $\\gamma$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically well-grounded, employing a standard duplication-divergence model common in computational biology and network science. The mathematical framework, using mean-field continuum approximations and ordinary differential equations, is a standard and appropriate technique for analyzing such models. The problem is well-posed; all parameters and processes are clearly defined, and the questions are specific and formalizable. The assumptions are explicitly stated. The problem is objective and free of any non-scientific content. It does not violate any of the invalidity criteria.\n\n**Step 3: Verdict and Action**\nThe problem is valid. I will now proceed with a full derivation.\n\n### Derivations\n\n**(a) Derivation of the ODE for the expected degree of a pre-existing node**\n\nLet $i$ be a fixed node in the network that was present at time $t$. We consider the change in its degree, $k_i$, in a single time step from $t$ to $t+1$. The degree of node $i$ increases by $1$ if and only if the newly added node, $u_{t+1}$, forms an edge with node $i$. This can happen in two mutually exclusive ways, since the network is simple and a node cannot be its own neighbor.\n\n1.  The target node $v_t$ is node $i$ itself. This occurs with probability $1/N(t)$ because the target is chosen uniformly at random. If $v_t=i$, the edge $\\{u_{t+1}, i\\}$ is added with probability $q$. The probability of this combined event is $\\frac{1}{N(t)} \\cdot q$.\n2.  The target node $v_t$ is a neighbor of node $i$. Let $\\mathcal{N}_i(t)$ be the set of neighbors of node $i$ at time $t$, so $|\\mathcal{N}_i(t)| = k_i(t)$. Let $w \\in \\mathcal{N}_i(t)$ be a neighbor. The probability of choosing $w$ as the target is $1/N(t)$. If $v_t = w$, then $i$ is a neighbor of the target node. By step $2$ of the growth process, the edge $\\{u_{t+1}, i\\}$ is added with probability $p$. Since there are $k_i(t)$ such neighbors, and the choice of each is a disjoint event, the total probability for this case is $\\sum_{w \\in \\mathcal{N}_i(t)} \\frac{1}{N(t)} \\cdot p = \\frac{k_i(t) p}{N(t)}$.\n\nThe total probability that the degree of node $i$ increases by $1$ in this time step is the sum of probabilities from these two cases:\n$$\nP(\\Delta k_i(t) = 1) = \\frac{q}{N(t)} + \\frac{p k_i(t)}{N(t)}\n$$\nThe expected change in the degree of node $i$ at time $t$, conditional on its current degree $k_i(t)$, is:\n$$\n\\mathbb{E}[\\Delta k_i(t) | k_i(t)] = 1 \\cdot P(\\Delta k_i(t)=1) + 0 \\cdot P(\\Delta k_i(t)=0) = \\frac{q + p k_i(t)}{N(t)}\n$$\nTo find the unconditional expected change, we take the expectation over the distribution of $k_i(t)$:\n$$\n\\mathbb{E}[\\Delta k_i(t)] = \\mathbb{E}[\\mathbb{E}[\\Delta k_i(t) | k_i(t)]] = \\mathbb{E}\\left[\\frac{q + p k_i(t)}{N(t)}\\right] = \\frac{q + p \\mathbb{E}[k_i(t)]}{N(t)}\n$$\nIn the continuum mean-field limit, we approximate the discrete time step $\\Delta t = 1$ with a differential $\\mathrm{d}t$, $N(t) \\approx t$, and $\\mathbb{E}[\\Delta k_i(t)] \\approx \\frac{\\mathrm{d}\\mathbb{E}[k_i(t)]}{\\mathrm{d}t}$. This gives the ordinary differential equation:\n$$\n\\frac{ \\mathrm{d} \\,\\mathbb{E}[k_{i}(t)] }{ \\mathrm{d} t } = \\frac{q + p\\, \\mathbb{E}[k_{i}(t)]}{t}\n$$\n\n**(b) Solution of the ODE**\n\nThe ODE from part (a) is a first-order linear differential equation. Let $y(t) = \\mathbb{E}[k_i(t)]$. The equation is:\n$$\n\\frac{\\mathrm{d}y}{\\mathrm{d}t} = \\frac{p}{t}y + \\frac{q}{t} \\quad \\implies \\quad \\frac{\\mathrm{d}y}{\\mathrm{d}t} - \\frac{p}{t}y = \\frac{q}{t}\n$$\nWe solve this using an integrating factor $I(t)$:\n$$\nI(t) = \\exp\\left( \\int -\\frac{p}{t} \\mathrm{d}t \\right) = \\exp(-p \\ln t) = t^{-p}\n$$\nMultiplying the ODE by $I(t)$:\n$$\nt^{-p} \\frac{\\mathrm{d}y}{\\mathrm{d}t} - p t^{-p-1} y = q t^{-p-1}\n$$\nThe left side is the derivative of the product $y(t)I(t)$:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t} (t^{-p} y) = q t^{-p-1}\n$$\nIntegrating both sides with respect to $t$:\n$$\nt^{-p} y(t) = \\int q t^{-p-1} \\mathrm{d}t = q \\frac{t^{-p}}{-p} + C = -\\frac{q}{p} t^{-p} + C\n$$\nwhere $C$ is the constant of integration. Solving for $y(t)$:\n$$\ny(t) = -\\frac{q}{p} + C t^{p}\n$$\nThe constant $C$ is determined by the initial condition. Let $t_i$ be the time when node $i$ is created. Let its initial expected degree be $\\mathbb{E}[k_i(t_i)] = k_{i,0}$. At $t=t_i$:\n$$\nk_{i,0} = -\\frac{q}{p} + C t_i^{p} \\implies C = \\left(k_{i,0} + \\frac{q}{p}\\right) t_i^{-p}\n$$\nSubstituting $C$ back into the solution for $y(t) = \\mathbb{E}[k_i(t)]$, we get:\n$$\n\\mathbb{E}[k_{i}(t)] = -\\frac{q}{p} + \\left(k_{i,0} + \\frac{q}{p}\\right) t_i^{-p} t^{p} = -\\frac{q}{p} + \\left(k_{i,0} + \\frac{q}{p}\\right) \\left(\\frac{t}{t_i}\\right)^{p}\n$$\nThis is the solution for the expected degree of a node $i$ born at time $t_i$ with initial expected degree $k_{i,0}$, for $t \\ge t_i$.\n\n**(c) Derivation of the degree distribution exponent $\\gamma$**\n\nTo find the exponent of the stationary degree distribution $P(k) \\sim k^{-\\gamma}$, we use the result from part (b) and relate a node's degree to its age. The mean-field approximation assumes that the degree of a node $i$ at time $t$, $k_i(t)$, follows the evolution of its expectation:\n$$\nk(t_i, t) \\approx -\\frac{q}{p} + \\left(k_{i,0} + \\frac{q}{p}\\right) \\left(\\frac{t}{t_i}\\right)^{p}\n$$\nWe are interested in the tail of the distribution, i.e., large degrees $k$. Large degrees are attained by nodes that were born early (small $t_i$) and have had a long time to acquire edges.\nThe problem states that birth times $t_i$ are asymptotically uniform. In a network growing by one node per time step up to time $t$, the probability density of a randomly chosen node having been born at $t_{birth}$ is $f(t_{birth}) \\approx 1/t$ for $t_0 \\ll t_{birth} \\le t$. The cumulative distribution function is $F(t_{birth} \\le \\tau) = P(\\text{node is born by time } \\tau) \\approx \\tau/t$.\n\nThe fraction of nodes with degree greater than $k$, denoted $P(K > k)$, corresponds to the fraction of nodes that were born early enough to have grown to a degree exceeding $k$. We can find the birth time $t_i(k)$ of a node that would have a degree of exactly $k$ at time $t$ by inverting the degree evolution equation:\n$$\nk = -\\frac{q}{p} + \\left(k_{i,0} + \\frac{q}{p}\\right) \\left(\\frac{t}{t_i(k)}\\right)^{p} \\implies \\left(\\frac{t}{t_i(k)}\\right)^{p} = \\frac{k + q/p}{k_{i,0} + q/p}\n$$\nSolving for $t_i(k)$:\n$$\nt_i(k) = t \\left(\\frac{k + q/p}{k_{i,0} + q/p}\\right)^{-1/p}\n$$\nThe probability that a random node has a degree greater than $k$ is the probability that its birth time was less than $t_i(k)$:\n$$\nP(K > k) = P(t_{birth} < t_i(k)) \\approx \\frac{t_i(k)}{t} = \\left(\\frac{k + q/p}{k_{i,0} + q/p}\\right)^{-1/p}\n$$\nFor large $k$, we can approximate $k+q/p \\approx k$. The term $(k_{i,0} + q/p)$ is a constant. Thus, the asymptotic behavior of the complementary cumulative distribution function is:\n$$\nP(K > k) \\propto k^{-1/p}\n$$\nThe probability density function $P(k)$ is obtained by differentiating $P(K \\le k) = 1 - P(K > k)$ with respect to $k$, or simply $P(k) = - \\frac{\\mathrm{d}}{\\mathrm{d}k} P(K > k)$.\n$$\nP(k) \\propto -\\frac{\\mathrm{d}}{\\mathrm{d}k} (k^{-1/p}) = -(-1/p) k^{-1/p - 1} \\propto k^{-(1+1/p)}\n$$\nComparing this to the form $P(k) \\sim k^{-\\gamma}$, we identify the tail exponent as:\n$$\n\\gamma = 1 + \\frac{1}{p}\n$$\nNote that the innovation probability $q$ affects the pre-factor and crossover behavior but not the asymptotic power-law exponent.\n\n**(d) Asymptotics of the average degree $\\langle k \\rangle(t)$ and sparsity**\n\nWe first derive an ODE for the total number of edges $E(t)$. At each time step, one new node $u_{t+1}$ is added. The change in the number of edges, $\\Delta E(t) = E(t+1) - E(t)$, is the degree of this new node. This degree is a random variable. Its expected value, conditional on the choice of the parent node $v_t$, is:\n$$\n\\mathbb{E}[\\Delta E(t) | v_t] = \\mathbb{E}[\\text{edges from divergence}] + \\mathbb{E}[\\text{edge from innovation}] = p k_{v_t}(t) + q\n$$\nTo find the unconditional expectation, we average over the uniform random choice of $v_t$ from the $N(t)$ nodes. The expectation of $k_{v_t}(t)$ is the average degree of the network, $\\langle k \\rangle(t) = 2E(t)/N(t)$.\n$$\n\\mathbb{E}[\\Delta E(t)] = p \\, \\mathbb{E}[k_{v_t}(t)] + q = p \\frac{2E(t)}{N(t)} + q\n$$\nIn the continuum limit, with $N(t) \\approx t$ and $\\mathbb{E}[\\Delta E(t)] \\approx \\frac{\\mathrm{d}E}{\\mathrm{d}t}$:\n$$\n\\frac{\\mathrm{d}E}{\\mathrm{d}t} = \\frac{2p}{t} E(t) + q\n$$\nThis is a linear ODE of the form $\\frac{\\mathrm{d}E}{\\mathrm{d}t} - \\frac{2p}{t}E = q$. The integrating factor is $I(t) = \\exp(\\int -2p/t \\, \\mathrm{d}t) = t^{-2p}$.\nSolving this similarly to part (b), we get for $p \\neq 1/2$:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t} (t^{-2p} E) = q t^{-2p} \\implies t^{-2p} E(t) = \\int q t^{-2p} \\mathrm{d}t = \\frac{q}{1-2p} t^{1-2p} + C\n$$\n$$\nE(t) = \\frac{q}{1-2p} t + C t^{2p}\n$$\nThe average degree is $\\langle k \\rangle(t) = 2E(t)/N(t) \\approx 2E(t)/t$:\n$$\n\\langle k \\rangle(t) \\approx \\frac{2}{t} \\left(\\frac{q}{1-2p} t + C t^{2p}\\right) = \\frac{2q}{1-2p} + 2C t^{2p-1}\n$$\nThe network remains sparse if its average degree remains bounded as $t \\to \\infty$, i.e., $\\sup_t \\langle k \\rangle(t) < \\infty$. Analysing the asymptotic behavior:\n- If $2p-1 > 0$, i.e., $p > 1/2$, then $\\langle k \\rangle(t) \\to \\infty$. The network becomes dense.\n- If $2p-1 < 0$, i.e., $p < 1/2$, then $t^{2p-1} \\to 0$ and $\\langle k \\rangle(t) \\to \\frac{2q}{1-2p}$, a finite constant. The network is sparse.\n- If $2p-1=0$, i.e., $p = 1/2$, the ODE for $E(t)$ is $\\frac{\\mathrm{d}E}{\\mathrm{d}t} - \\frac{1}{t}E = q$. This gives $E(t) = q t \\ln t + C t$, and $\\langle k \\rangle(t) \\approx 2q \\ln t + 2C$, which diverges.\nTherefore, the network remains sparse for $p \\in (0, 1/2)$. The condition for sparsity does not depend on $q$. However, $q$ determines the value of the asymptotic average degree $\\langle k \\rangle_\\infty = \\frac{2q}{1-2p}$ in the sparse regime.\n\n**(e) Analysis of the clustering of a new node**\n\nLet $v_t$ be the parent node with degree $k_{v_t}$ and local clustering coefficient $C(v_t) = \\frac{2 T(v_t)}{k_{v_t}(k_{v_t}-1)}$, where $T(v_t)$ is the number of triangles incident to $v_t$. We want to find the expected number of triangles incident to a new node $u_{t+1}$ at its birth, $\\mathbb{E}[T(u_{t+1})]$, conditional on the parent choice $v_t$.\nA triangle involving $u_{t+1}$ must have the form $\\{u_{t+1}, x, y\\}$, where $x, y$ are neighbors of $u_{t+1}$ and are connected by an edge. The neighbors of $u_{t+1}$ are a random subset of $\\{v_t\\} \\cup \\mathcal{N}(v_t)$.\nTriangles can be formed in two ways:\n1.  On an edge between the parent and one of its neighbors: Consider an edge $\\{v_t, w\\}$ where $w \\in \\mathcal{N}(v_t)$. A triangle $\\{u_{t+1}, v_t, w\\}$ is formed if $u_{t+1}$ connects to both $v_t$ (with probability $q$) and $w$ (with probability $p$). The events are independent. The probability is $p q$. There are $k_{v_t}$ such edges. The expected number of such triangles is $p q k_{v_t}$.\n2.  On an edge between two neighbors of the parent: Consider an edge $\\{w_1, w_2\\}$ where both $w_1, w_2 \\in \\mathcal{N}(v_t)$. This is an edge that closes a triangle with $v_t$. The number of such edges is $T(v_t)$. A triangle $\\{u_{t+1}, w_1, w_2\\}$ is formed if $u_{t+1}$ connects to both $w_1$ (with probability $p$) and $w_2$ (also with probability $p$). As these events are independent, the probability is $p^2$. The expected number of such triangles is $p^2 T(v_t)$.\n\nSumming these contributions gives the expected number of triangles incident to $u_{t+1}$:\n$$\n\\mathbb{E}[T(u_{t+1})|v_t] = p q k_{v_t} + p^2 T(v_t)\n$$\nUsing the definition of $C(v_t)$, we have $T(v_t) = \\frac{C(v_t) k_{v_t}(k_{v_t}-1)}{2}$. Substituting this gives:\n$$\n\\mathbb{E}[T(u_{t+1})|v_t] = p q k_{v_t} + p^2 \\frac{C(v_t) k_{v_t}(k_{v_t}-1)}{2}\n$$\nTo compare the expected clustering of the new node, $\\mathbb{E}[C(u_{t+1})|v_t]$, with $C(v_t)$, we use a mean-field approximation: $\\mathbb{E}[C(u_{t+1})] \\approx \\frac{2\\mathbb{E}[T(u_{t+1})]}{\\mathbb{E}[k_{u_{t+1}}](\\mathbb{E}[k_{u_{t+1}}]-1)}$.\nThe expected degree of the new node is $\\mathbb{E}[k_{u_{t+1}}|v_t] = p k_{v_t} + q$.\nSo,\n$$\n\\mathbb{E}[C(u_{t+1})|v_t] \\approx \\frac{2 \\left( p q k_{v_t} + p^2 \\frac{C(v_t) k_{v_t}(k_{v_t}-1)}{2} \\right)}{(p k_{v_t} + q)(p k_{v_t} + q - 1)} = \\frac{2 p q k_{v_t} + p^2 C(v_t) k_{v_t}(k_{v_t}-1)}{(p k_{v_t} + q)(p k_{v_t} + q - 1)}\n$$\nFor large $k_{v_t}$, we examine the leading-order terms:\n- Numerator $\\approx p^2 C(v_t) k_{v_t}^2$\n- Denominator $\\approx (p k_{v_t})(p k_{v_t}) = p^2 k_{v_t}^2$\nThe ratio of the leading terms is:\n$$\n\\lim_{k_{v_t} \\to \\infty} \\mathbb{E}[C(u_{t+1})|v_t] \\approx \\frac{p^2 C(v_t) k_{v_t}^2}{p^2 k_{v_t}^2} = C(v_t)\n$$\nThis indicates that for a high-degree parent node, the newly created node is expected to have a local clustering coefficient similar to its parent. This mechanism allows the network to maintain non-trivial clustering even for high-degree nodes.\n\nAll parts of the problem have been addressed. The final answer required is the expression for $\\gamma$ derived in part (c).",
            "answer": "$$\\boxed{1 + \\frac{1}{p}}$$"
        },
        {
            "introduction": "Beyond understanding the mechanisms of growth, a central question is *why* networks evolve specific features like modularity. This practice explores the powerful hypothesis that network organization is shaped by physical constraints, specifically the metabolic cost of synthesizing and maintaining connections. By calculating the expected \"wiring cost\" reduction in a spatially embedded modular network compared to a homogeneous one, you will quantify a key selective pressure that can drive the evolution of community structure . This exercise highlights the interplay between abstract topology and concrete biophysical economics.",
            "id": "3306708",
            "problem": "Consider a population of $N$ molecular interaction sites embedded in a two-dimensional plane and arranged into $k \\geq 2$ spatially localized modules of equal size $n = N/k$ (assume $N$ is divisible by $k$). Modules are modeled as non-overlapping disks of radius $r$ whose centers lie at the vertices of a regular $k$-gon inscribed in a circle of radius $R$, with $r < R \\sin(\\pi/k)$ and $r \\ll R$ so that inter-module distances are dominated by center-to-center separations. Edges represent physical wiring between sites, and the expected wiring cost of an edge is defined as the expected Euclidean length between its incident sites. Edge formation follows a Stochastic Block Model (SBM): any intra-module pair forms an edge independently with probability $p_{in}$, and any inter-module pair forms an edge independently with probability $p_{out}$, with $p_{in}, p_{out} \\in [0,1]$.\n\nDefine the baseline “homogeneous” network as a random graph on the same $N$ sites in the same geometry with a single edge probability $p$ for all site pairs, chosen so that the expected total number of edges equals that of the modular SBM network described above. Use the following geometric facts:\n- The expected distance between two independent points uniformly distributed in a disk of radius $r$ is $\\frac{128 r}{45 \\pi}$.\n- The expected center-to-center distance between two distinct module centers on the circle of radius $R$ equals the average chord length across all unordered pairs of vertices of the regular $k$-gon, and all angular quantities are measured in radians.\n\nUnder these assumptions, compute the expected reduction in total wiring cost, defined as the expected baseline total wiring cost minus the expected SBM modular total wiring cost, as a closed-form analytic expression in terms of $N$, $k$, $p_{in}$, $p_{out}$, $R$, and $r$. Express your final answer symbolically; no numerical rounding is required, and no physical units are to be reported in the final expression. Angles must be treated in radians.",
            "solution": "The user wants me to solve a problem. I will first validate the problem statement.\n\n### Step 1: Extract Givens\n- Population of $N$ sites in a 2D plane.\n- $k \\geq 2$ modules of equal size $n = N/k$, where $N$ is divisible by $k$.\n- Modules are non-overlapping disks of radius $r$.\n- Module centers lie on the vertices of a regular $k$-gon inscribed in a circle of radius $R$.\n- Geometric constraints: $r < R \\sin(\\pi/k)$ and $r \\ll R$.\n- Edge formation probability for intra-module pairs: $p_{in} \\in [0,1]$.\n- Edge formation probability for inter-module pairs: $p_{out} \\in [0,1]$.\n- A baseline homogeneous network has a single edge probability $p$ for all pairs.\n- The expected total number of edges in the baseline network equals that of the modular SBM network.\n- Expected distance between two points in a disk of radius $r$: $E[L_{intra, site}] = \\frac{128 r}{45 \\pi}$.\n- Expected distance between centers of two distinct modules: $\\bar{d}$, the average chord length of the regular $k$-gon.\n- The task is to compute the expected reduction in total wiring cost, $\\Delta C = E[C_{baseline}] - E[C_{SBM}]$, in terms of $N, k, p_{in}, p_{out}, R, r$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem uses standard models from network science (Stochastic Block Model, Random Graphs) and principles from probability and geometry. The setup is a stylized but valid model used in computational systems biology to study principles of biological network organization.\n- **Well-Posed:** The problem is clearly defined with all necessary parameters and constraints. The objective (calculating an expected value) is a well-defined mathematical task. The given geometric facts and constraints ensure a unique solution can be derived.\n- **Objective:** The problem is stated in precise, mathematical language, free from subjectivity or ambiguity.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is scientifically grounded, well-posed, and objective. I will now proceed with the solution.\n\n### Solution Derivation\nThe total expected wiring cost, $E[C]$, of a network is the sum of the expected costs of all potential edges. By linearity of expectation, this can be written as the sum over all pairs of sites $(i,j)$ of the probability of an edge existing, $p_{ij}$, multiplied by the expected length of that edge, $E[L_{ij}]$.\n$$E[C] = \\sum_{i<j} p_{ij} E[L_{ij}]$$\nThe approximation $r \\ll R$ implies that the distance between two sites in different modules can be approximated by the distance between the module centers. The expected distance between two sites within the same module is given.\n\nLet's first calculate the number of intra-module and inter-module pairs.\nThe number of sites per module is $n = N/k$.\nThe number of pairs within a single module is $\\binom{n}{2} = \\frac{n(n-1)}{2}$.\nTotal number of intra-module pairs, $N_{intra}$, across all $k$ modules:\n$$N_{intra} = k \\binom{n}{2} = k \\frac{\\frac{N}{k}(\\frac{N}{k}-1)}{2} = \\frac{N(\\frac{N-k}{k})}{2} = \\frac{N(N-k)}{2k}$$\nThe total number of pairs of sites in the network is $N_{total} = \\binom{N}{2} = \\frac{N(N-1)}{2}$.\nThe number of inter-module pairs, $N_{inter}$, is the total number of pairs minus the intra-module pairs:\n$$N_{inter} = N_{total} - N_{intra} = \\frac{N(N-1)}{2} - \\frac{N(N-k)}{2k} = \\frac{N}{2} \\left( (N-1) - \\frac{N-k}{k} \\right) = \\frac{N}{2} \\left( \\frac{kN-k-N+k}{k} \\right) = \\frac{N^2(k-1)}{2k}$$\n\nNext, we establish the expected edge lengths.\nThe expected length of an intra-module edge, $E[L_{intra}]$, is given as the expected distance between two random points in a disk of radius $r$:\n$$E[L_{intra}] = \\frac{128r}{45\\pi}$$\nThe expected length of an inter-module edge, $E[L_{inter}]$, is the expected distance between the centers of two distinct modules, which is the average chord length of a regular $k$-gon of radius $R$. The distance between two vertices separated by an angle $\\theta$ is $2R\\sin(\\theta/2)$. For a regular $k$-gon, the angles are $\\theta_j = \\frac{2\\pi j}{k}$ for $j=1, 2, ..., k-1$. The average chord length from a single vertex is $\\frac{1}{k-1}\\sum_{j=1}^{k-1} 2R\\sin(\\frac{\\pi j}{k})$. By symmetry, this is the average over all pairs of vertices.\n$$E[L_{inter}] = \\frac{2R}{k-1} \\sum_{j=1}^{k-1} \\sin\\left(\\frac{\\pi j}{k}\\right)$$\nUsing the identity for the sum of sines, $\\sum_{j=1}^{M} \\sin(j\\theta) = \\frac{\\sin(M\\theta/2)\\sin((M+1)\\theta/2)}{\\sin(\\theta/2)}$, with $M=k-1$ and $\\theta=\\pi/k$:\n$$\\sum_{j=1}^{k-1} \\sin\\left(\\frac{\\pi j}{k}\\right) = \\frac{\\sin\\left(\\frac{(k-1)\\pi}{2k}\\right)\\sin\\left(\\frac{k\\pi}{2k}\\right)}{\\sin\\left(\\frac{\\pi}{2k}\\right)} = \\frac{\\sin(\\frac{\\pi}{2}-\\frac{\\pi}{2k})\\sin(\\frac{\\pi}{2})}{\\sin(\\frac{\\pi}{2k})} = \\frac{\\cos(\\frac{\\pi}{2k})}{\\sin(\\frac{\\pi}{2k})} = \\cot\\left(\\frac{\\pi}{2k}\\right)$$\nThus, the expected inter-module length is:\n$$E[L_{inter}] = \\frac{2R}{k-1} \\cot\\left(\\frac{\\pi}{2k}\\right)$$\n\nNow, we compute the expected total cost for the SBM network, $E[C_{SBM}]$.\n$$E[C_{SBM}] = N_{intra} p_{in} E[L_{intra}] + N_{inter} p_{out} E[L_{inter}]$$\nSubstituting the expressions for $N_{intra}$, $N_{inter}$, $E[L_{intra}]$, and $E[L_{inter}]$:\n$$E[C_{SBM}] = \\frac{N(N-k)}{2k} p_{in} \\frac{128r}{45\\pi} + \\frac{N^2(k-1)}{2k} p_{out} \\frac{2R}{k-1} \\cot\\left(\\frac{\\pi}{2k}\\right)$$\n$$E[C_{SBM}] = \\frac{64N(N-k)}{45\\pi k} p_{in} r + \\frac{N^2 R}{k} p_{out} \\cot\\left(\\frac{\\pi}{2k}\\right)$$\n\nNext, we address the baseline homogeneous network. The edge probability $p$ is set such that the expected total number of edges is conserved.\n$$E[\\text{Edges}_{SBM}] = N_{intra}p_{in} + N_{inter}p_{out}$$\n$$E[\\text{Edges}_{baseline}] = N_{total}p$$\nEquating these gives $p = \\frac{N_{intra}p_{in} + N_{inter}p_{out}}{N_{total}}$.\nThe expected cost for the baseline network is:\n$$E[C_{baseline}] = \\sum_{i<j} p E[L_{ij}] = p \\sum_{i<j} E[L_{ij}] = p (N_{intra}E[L_{intra}] + N_{inter}E[L_{inter}])$$\n\nThe problem asks for the expected reduction in total wiring cost, $\\Delta C = E[C_{baseline}] - E[C_{SBM}]$.\n$$\\Delta C = p (N_{intra}E[L_{intra}] + N_{inter}E[L_{inter}]) - (N_{intra} p_{in} E[L_{intra}] + N_{inter} p_{out} E[L_{inter}])$$\n$$\\Delta C = (p - p_{in})N_{intra}E[L_{intra}] + (p - p_{out})N_{inter}E[L_{inter}]$$\nWe express the probability differences in terms of $p_{in}$ and $p_{out}$:\n$$p - p_{in} = \\frac{N_{intra}p_{in} + N_{inter}p_{out}}{N_{total}} - p_{in} = \\frac{(N_{intra}-N_{total})p_{in} + N_{inter}p_{out}}{N_{total}} = \\frac{-N_{inter}p_{in} + N_{inter}p_{out}}{N_{total}} = \\frac{N_{inter}(p_{out}-p_{in})}{N_{total}}$$\n$$p - p_{out} = \\frac{N_{intra}p_{in} + N_{inter}p_{out}}{N_{total}} - p_{out} = \\frac{N_{intra}p_{in} + (N_{inter}-N_{total})p_{out}}{N_{total}} = \\frac{N_{intra}p_{in} - N_{intra}p_{out}}{N_{total}} = \\frac{N_{intra}(p_{in}-p_{out})}{N_{total}}$$\nSubstituting these into the expression for $\\Delta C$:\n$$\\Delta C = \\frac{N_{inter}(p_{out}-p_{in})}{N_{total}} N_{intra}E[L_{intra}] + \\frac{N_{intra}(p_{in}-p_{out})}{N_{total}} N_{inter}E[L_{inter}]$$\n$$\\Delta C = \\frac{N_{intra}N_{inter}(p_{in}-p_{out})}{N_{total}} (-E[L_{intra}] + E[L_{inter}])$$\n$$\\Delta C = \\frac{N_{intra}N_{inter}}{N_{total}} (p_{in}-p_{out}) (E[L_{inter}] - E[L_{intra}])$$\nThis elegant result shows the cost reduction is proportional to the degree of structural modularity ($p_{in}-p_{out}$) and spatial modularity ($E[L_{inter}] - E[L_{intra}]$). Now we substitute the full expressions.\nThe prefactor is:\n$$\\frac{N_{intra}N_{inter}}{N_{total}} = \\frac{\\frac{N(N-k)}{2k} \\frac{N^2(k-1)}{2k}}{\\frac{N(N-1)}{2}} = \\frac{N^3(N-k)(k-1)}{4k^2} \\frac{2}{N(N-1)} = \\frac{N^2(N-k)(k-1)}{2k^2(N-1)}$$\nThe difference in expected lengths is:\n$$E[L_{inter}] - E[L_{intra}] = \\frac{2R}{k-1} \\cot\\left(\\frac{\\pi}{2k}\\right) - \\frac{128r}{45\\pi}$$\nCombining these parts:\n$$\\Delta C = \\frac{N^2(N-k)(k-1)}{2k^2(N-1)} (p_{in}-p_{out}) \\left(\\frac{2R}{k-1} \\cot\\left(\\frac{\\pi}{2k}\\right) - \\frac{128r}{45\\pi}\\right)$$\nWe can simplify by distributing the $(k-1)$ term from the prefactor into the parenthesis:\n$$\\Delta C = \\frac{N^2(N-k)}{2k^2(N-1)} (p_{in}-p_{out}) \\left((k-1)\\frac{2R}{k-1} \\cot\\left(\\frac{\\pi}{2k}\\right) - (k-1)\\frac{128r}{45\\pi}\\right)$$\n$$\\Delta C = \\frac{N^2(N-k)}{2k^2(N-1)} (p_{in}-p_{out}) \\left(2R \\cot\\left(\\frac{\\pi}{2k}\\right) - \\frac{128r(k-1)}{45\\pi}\\right)$$\nThis is the final closed-form expression for the expected reduction in total wiring cost.",
            "answer": "$$\\boxed{\\frac{N^2(N-k)}{2k^2(N-1)} (p_{in}-p_{out}) \\left(2R \\cot\\left(\\frac{\\pi}{2k}\\right) - \\frac{128r(k-1)}{45\\pi}\\right)}$$"
        },
        {
            "introduction": "If natural selection shapes network topology for functional reasons, we should be able to find its signature in the structure of real-world networks. Network motifs—statistically overrepresented subgraphs—are considered a key piece of such evidence. This practice provides a concrete, hands-on application of motif analysis by having you calculate the Z-score for a feed-forward loop in a small network . By comparing the observed count to that expected by chance, you will learn the fundamental statistical method used to infer that certain network patterns are not random artifacts but are likely conserved modules with specific functional roles.",
            "id": "3306746",
            "problem": "Consider a directed gene-regulatory network on $N=5$ labeled nodes $\\{1,2,3,4,5\\}$ with total edge count $M=10$. The out-degree and in-degree sequences are\n$$(k_{1}^{\\text{out}},k_{2}^{\\text{out}},k_{3}^{\\text{out}},k_{4}^{\\text{out}},k_{5}^{\\text{out}})=(3,2,2,1,2), \\quad (k_{1}^{\\text{in}},k_{2}^{\\text{in}},k_{3}^{\\text{in}},k_{4}^{\\text{in}},k_{5}^{\\text{in}})=(1,3,2,2,2),$$\nso that $\\sum_{i=1}^{5} k_{i}^{\\text{out}}=\\sum_{i=1}^{5} k_{i}^{\\text{in}}=M=10$. Assume the Directed Configuration Model (DCM), defined as follows: given the fixed in-degree and out-degree sequences, the presence of each directed edge $i \\to j$ for $i \\neq j$ is modeled as an independent Bernoulli random variable with success probability\n$$p_{ij}=\\frac{k_{i}^{\\text{out}}\\,k_{j}^{\\text{in}}}{M},$$\nin the sparse limit where edge dependencies and multiple edges can be neglected. A feed-forward loop (FFL) is defined here as an ordered triple $(i,j,k)$ with $i,j,k$ all distinct such that the directed edges $i \\to j$, $i \\to k$, and $j \\to k$ all exist.\n\nThe observed network realization (consistent with the specified degree sequences) has the following directed edges:\n$$1 \\to 2,\\; 1 \\to 3,\\; 1 \\to 5,\\; 2 \\to 3,\\; 2 \\to 1,\\; 3 \\to 5,\\; 3 \\to 4,\\; 4 \\to 2,\\; 5 \\to 2,\\; 5 \\to 4.$$\n\nStarting from the DCM definition and first principles of expectation and variance of sums of indicator random variables, do the following:\n\n1. Derive an expression for the expected number of ordered feed-forward loops under the DCM in terms of the degree sequences, and evaluate it exactly for the given network.\n2. Using the same independence assumptions and the sparse-network approximation that covariances between distinct motif indicators are negligible, derive an expression for the approximate variance of the FFL count and evaluate it exactly for the given network.\n3. Compute the observed number of ordered FFLs for the given network realization.\n4. Compute the Z-score\n$$Z=\\frac{N_{\\text{obs}}-\\mathbb{E}[N_{\\text{FFL}}]}{\\sqrt{\\mathrm{Var}(N_{\\text{FFL}})}},$$\nwhere $N_{\\text{obs}}$ is the observed FFL count, $\\mathbb{E}[N_{\\text{FFL}}]$ is the expected count under the DCM, and $\\mathrm{Var}(N_{\\text{FFL}})$ is the approximate variance derived in Part 2.\n\nProvide the final Z-score as a pure number (unitless). Round your final answer to four significant figures. Explain in your derivation how an overrepresented motif (large positive $Z$) can be interpreted as evidence of selection pressures shaping network topology and modularity in computational systems biology.",
            "solution": "The problem asks for the calculation of a Z-score for the frequency of feed-forward loops (FFLs) in a given directed network. This involves comparing the observed count of FFLs to the expected count under a null model, the Directed Configuration Model (DCM), and normalizing by the standard deviation of the count under that model.\n\nFirst, we define the necessary variables and indicator functions. A feed-forward loop (FFL) is an ordered triple of distinct nodes $(i,j,k)$ where the edges $i \\to j$, $i \\to k$, and $j \\to k$ all exist. Let $A_{uv}$ be the indicator variable for the existence of a directed edge from node $u$ to node $v$. The problem states that under the DCM, these are independent Bernoulli random variables with success probability $p_{uv} = \\frac{k_{u}^{\\text{out}}\\,k_{v}^{\\text{in}}}{M}$ for $u \\neq v$.\n\nLet $I_{ijk}$ be the indicator variable for the existence of an FFL on the ordered, distinct triple of nodes $(i,j,k)$. Thus, $I_{ijk} = A_{ij}A_{ik}A_{jk}$. The total number of FFLs in the network is $N_{\\text{FFL}} = \\sum_{i \\neq j \\neq k \\neq i} I_{ijk}$, where the sum is over all ordered triples of distinct nodes.\n\n### Part 1: Expected Number of FFLs\n\nBy the linearity of expectation, the expected number of FFLs is:\n$$ \\mathbb{E}[N_{\\text{FFL}}] = \\mathbb{E}\\left[\\sum_{i \\neq j \\neq k} I_{ijk}\\right] = \\sum_{i \\neq j \\neq k} \\mathbb{E}[I_{ijk}] $$\nThe expectation of the indicator $I_{ijk}$ is the probability of the corresponding FFL existing. Due to the assumed independence of edges in the DCM:\n$$ \\mathbb{E}[I_{ijk}] = P(A_{ij}=1 \\text{ and } A_{ik}=1 \\text{ and } A_{jk}=1) = P(A_{ij}=1)P(A_{ik}=1)P(A_{jk}=1) = p_{ij}p_{ik}p_{jk} $$\nSubstituting the expression for $p_{uv}$:\n$$ \\mathbb{E}[I_{ijk}] = \\left(\\frac{k_{i}^{\\text{out}}\\,k_{j}^{\\text{in}}}{M}\\right) \\left(\\frac{k_{i}^{\\text{out}}\\,k_{k}^{\\text{in}}}{M}\\right) \\left(\\frac{k_{j}^{\\text{out}}\\,k_{k}^{\\text{in}}}{M}\\right) = \\frac{(k_{i}^{\\text{out}})^2 \\, k_{j}^{\\text{out}}\\,k_{j}^{\\text{in}} \\, (k_{k}^{\\text{in}})^2}{M^3} $$\nThe total expected number is the sum over all distinct triples $(i,j,k)$:\n$$ \\mathbb{E}[N_{\\text{FFL}}] = \\frac{1}{M^3} \\sum_{i \\neq j \\neq k} (k_{i}^{\\text{out}})^2 \\, (k_{j}^{\\text{out}}\\,k_{j}^{\\text{in}}) \\, (k_{k}^{\\text{in}})^2 $$\nTo evaluate this sum, let $a_i = (k_i^{\\text{out}})^2$, $b_j = k_j^{\\text{out}}k_j^{\\text{in}}$, and $c_k = (k_k^{\\text{in}})^2$. The sum becomes $\\sum_{i \\neq j \\neq k} a_i b_j c_k$. This can be computed exactly using the inclusion-exclusion principle:\n$$ \\sum_{i \\neq j \\neq k} a_i b_j c_k = (\\sum_i a_i)(\\sum_j b_j)(\\sum_k c_k) - (\\sum_i a_i b_i)(\\sum_k c_k) - (\\sum_i a_i c_i)(\\sum_j b_j) - (\\sum_i b_i c_i)(\\sum_j a_j) + 2\\sum_i a_i b_i c_i $$\nThe givens are $N=5$, $M=10$, $k^{\\text{out}}=(3,2,2,1,2)$, and $k^{\\text{in}}=(1,3,2,2,2)$. We first compute the components $a_i, b_i, c_i$:\n- $a_i = (k_i^{\\text{out}})^2$: $(3^2, 2^2, 2^2, 1^2, 2^2) = (9, 4, 4, 1, 4)$.\n- $b_i = k_i^{\\text{out}}k_i^{\\text{in}}$: $(3 \\cdot 1, 2 \\cdot 3, 2 \\cdot 2, 1 \\cdot 2, 2 \\cdot 2) = (3, 6, 4, 2, 4)$.\n- $c_i = (k_i^{\\text{in}})^2$: $(1^2, 3^2, 2^2, 2^2, 2^2) = (1, 9, 4, 4, 4)$.\n\nNext, we compute the sums required for the formula:\n- $\\sum a_i = 9+4+4+1+4 = 22$.\n- $\\sum b_i = 3+6+4+2+4 = 19$.\n- $\\sum c_i = 1+9+4+4+4 = 22$.\n- $\\sum a_i b_i = \\sum (k_i^{\\text{out}})^3 k_i^{\\text{in}} = 9 \\cdot 3 + 4 \\cdot 6 + 4 \\cdot 4 + 1 \\cdot 2 + 4 \\cdot 4 = 27+24+16+2+16 = 85$.\n- $\\sum a_i c_i = \\sum (k_i^{\\text{out}}k_i^{\\text{in}})^2 = 9 \\cdot 1 + 4 \\cdot 9 + 4 \\cdot 4 + 1 \\cdot 4 + 4 \\cdot 4 = 9+36+16+4+16 = 81$.\n- $\\sum b_i c_i = \\sum k_i^{\\text{out}} (k_i^{\\text{in}})^3 = 3 \\cdot 1 + 6 \\cdot 9 + 4 \\cdot 4 + 2 \\cdot 4 + 4 \\cdot 4 = 3+54+16+8+16 = 97$.\n- $\\sum a_i b_i c_i = \\sum (k_i^{\\text{out}})^3 (k_i^{\\text{in}})^3 = (3\\cdot1)^3 + (2\\cdot3)^3 + (2\\cdot2)^3 + (1\\cdot2)^3 + (2\\cdot2)^3 = 3^3+6^3+4^3+2^3+4^3 = 27+216+64+8+64 = 379$.\n\nPlugging these into the summation formula:\n$$ \\sum_{i \\neq j \\neq k} a_i b_j c_k = (22)(19)(22) - (85)(22) - (81)(19) - (97)(22) + 2(379) $$\n$$ = 9196 - 1870 - 1539 - 2134 + 758 = 4411 $$\nFinally, we find the expected number of FFLs:\n$$ \\mathbb{E}[N_{\\text{FFL}}] = \\frac{4411}{M^3} = \\frac{4411}{10^3} = 4.411 $$\n\n### Part 2: Approximate Variance of FFL Count\n\nThe variance of the total count is $\\mathrm{Var}(N_{\\text{FFL}}) = \\mathrm{Var}(\\sum_{i \\neq j \\neq k} I_{ijk})$. The problem states to use the approximation that covariances between distinct motif indicators are negligible. This means we assume $\\mathrm{Cov}(I_{ijk}, I_{lmn}) \\approx 0$ for $(i,j,k) \\neq (l,m,n)$. With this approximation, the variance becomes the sum of individual variances:\n$$ \\mathrm{Var}(N_{\\text{FFL}}) \\approx \\sum_{i \\neq j \\neq k} \\mathrm{Var}(I_{ijk}) $$\nAs $I_{ijk}$ is a Bernoulli random variable, its variance is $\\mathrm{Var}(I_{ijk}) = \\mathbb{E}[I_{ijk}](1 - \\mathbb{E}[I_{ijk}])$. Let $\\pi_{ijk} = \\mathbb{E}[I_{ijk}]$.\n$$ \\mathrm{Var}(N_{\\text{FFL}}) \\approx \\sum_{i \\neq j \\neq k} \\pi_{ijk}(1 - \\pi_{ijk}) = \\sum_{i \\neq j \\neq k} \\pi_{ijk} - \\sum_{i \\neq j \\neq k} \\pi_{ijk}^2 = \\mathbb{E}[N_{\\text{FFL}}] - \\sum_{i \\neq j \\neq k} (\\pi_{ijk})^2 $$\nThe second term is:\n$$ \\sum_{i \\neq j \\neq k} (\\pi_{ijk})^2 = \\frac{1}{M^6} \\sum_{i \\neq j \\neq k} (k_{i}^{\\text{out}})^4 \\, (k_{j}^{\\text{out}}\\,k_{j}^{\\text{in}})^2 \\, (k_{k}^{\\text{in}})^4 $$\nWe use the same summation formula with $a'_i = (k_i^{\\text{out}})^4$, $b'_j = (k_j^{\\text{out}}k_j^{\\text{in}})^2$, and $c'_k = (k_k^{\\text{in}})^4$.\n- $a'_i$: $(3^4, 2^4, 2^4, 1^4, 2^4) = (81, 16, 16, 1, 16)$. $\\sum a' = 130$.\n- $b'_i$: $(3^2, 6^2, 4^2, 2^2, 4^2) = (9, 36, 16, 4, 16)$. $\\sum b' = 81$.\n- $c'_k$: $(1^4, 3^4, 2^4, 2^4, 2^4) = (1, 81, 16, 16, 16)$. $\\sum c' = 130$.\nAnd the higher-order sums:\n- $\\sum a'_i b'_i = \\sum (k_i^{\\text{out}})^6 (k_i^{\\text{in}})^2 = 729 \\cdot 1 + 64 \\cdot 9 + 64 \\cdot 4 + 1 \\cdot 4 + 64 \\cdot 4 = 729+576+256+4+256 = 1821$.\n- $\\sum a'_i c'_i = \\sum (k_i^{\\text{out}}k_i^{\\text{in}})^4 = 81 \\cdot 1 + 16 \\cdot 81 + 16 \\cdot 16 + 1 \\cdot 16 + 16 \\cdot 16 = 81+1296+256+16+256 = 1905$.\n- $\\sum b'_i c'_i = \\sum (k_i^{\\text{out}})^2 (k_i^{\\text{in}})^6 = 9 \\cdot 1 + 4 \\cdot 729 + 4 \\cdot 64 + 1 \\cdot 64 + 4 \\cdot 64 = 9+2916+256+64+256 = 3501$.\n- $\\sum a'_i b'_i c'_i = \\sum (k_i^{\\text{out}}k_i^{\\text{in}})^6 = 3^6+6^6+4^6+2^6+4^6 = 729+46656+4096+64+4096 = 55641$.\nPlugging into the summation formula:\n$$ \\sum_{i \\neq j \\neq k} a'_i b'_j c'_k = (130)(81)(130) - (1821)(130) - (1905)(81) - (3501)(130) + 2(55641) $$\n$$ = 1368900 - 236730 - 154305 - 455130 + 111282 = 634017 $$\nThe second term in the variance expression is $\\frac{634017}{M^6} = \\frac{634017}{10^6} = 0.634017$.\nThe approximate variance is:\n$$ \\mathrm{Var}(N_{\\text{FFL}}) \\approx 4.411 - 0.634017 = 3.776983 $$\n\n### Part 3: Observed Number of FFLs\n\nWe enumerate the FFLs $(i,j,k)$ in the observed network by checking for each node $i$ all pairs of its outgoing edges $(i \\to j, i \\to k)$ and then checking for the existence of the closing edge $j \\to k$.\nThe observed edges are: $\\{1 \\to 2, 1 \\to 3, 1 \\to 5, 2 \\to 1, 2 \\to 3, 3 \\to 4, 3 \\to 5, 4 \\to 2, 5 \\to 2, 5 \\to 4\\}$.\n- FFLs starting from node $1$ (out-edges to $2,3,5$):\n  - $(i,j,k) = (1,2,3)$: $1 \\to 2, 1 \\to 3$. Check for $2 \\to 3$. Yes. $\\implies (1,2,3)$ is an FFL.\n  - $(i,j,k) = (1,3,5)$: $1 \\to 3, 1 \\to 5$. Check for $3 \\to 5$. Yes. $\\implies (1,3,5)$ is an FFL.\n  - $(i,j,k) = (1,5,2)$: $1 \\to 5, 1 \\to 2$. Check for $5 \\to 2$. Yes. $\\implies (1,5,2)$ is an FFL.\n- FFLs starting from node $2$ (out-edges to $1,3$):\n  - $(i,j,k) = (2,1,3)$: $2 \\to 1, 2 \\to 3$. Check for $1 \\to 3$. Yes. $\\implies (2,1,3)$ is an FFL.\n- FFLs starting from node $3$ (out-edges to $4,5$):\n  - $(i,j,k) = (3,5,4)$: $3 \\to 5, 3 \\to 4$. Check for $5 \\to 4$. Yes. $\\implies (3,5,4)$ is an FFL.\n- FFLs starting from node $4$ (out-edge to $2$): None, requires at least two out-edges.\n- FFLs starting from node $5$ (out-edges to $2,4$):\n  - $(i,j,k) = (5,4,2)$: $5 \\to 4, 5 \\to 2$. Check for $4 \\to 2$. Yes. $\\implies (5,4,2)$ is an FFL.\nThe observed FFLs are $(1,2,3)$, $(1,3,5)$, $(1,5,2)$, $(2,1,3)$, $(3,5,4)$, and $(5,4,2)$.\nThe total observed count is $N_{\\text{obs}} = 6$.\n\n### Part 4: The Z-score and its Interpretation\n\nThe Z-score is a standardized measure of how much the observed count $N_{\\text{obs}}$ deviates from the expected count $\\mathbb{E}[N_{\\text{FFL}}]$ under the null model, measured in units of standard deviation $\\sigma = \\sqrt{\\mathrm{Var}(N_{\\text{FFL}})}$.\n$$ Z = \\frac{N_{\\text{obs}} - \\mathbb{E}[N_{\\text{FFL}}]}{\\sqrt{\\mathrm{Var}(N_{\\text{FFL}})}} $$\nSubstituting the values we calculated:\n$$ Z = \\frac{6 - 4.411}{\\sqrt{3.776983}} \\approx \\frac{1.589}{1.943446} \\approx 0.817623 $$\nRounding to four significant figures, we get $Z \\approx 0.8176$.\n\nIn computational systems biology, the Z-score is a crucial tool for identifying network motifs, which are subgraph patterns that occur significantly more often in a real biological network than in a randomized one. A large positive Z-score (e.g., $Z > 2$ or $Z > 3$) indicates that the motif is \"overrepresented\". This overrepresentation is interpreted not as a random artifact, but as a signal of evolutionary selection. The logic is that if a particular circuit design (a motif) confers a functional advantage—such as filtering noise, generating oscillations, or speeding up response times—natural selection will favor organisms whose networks incorporate this design. The motif thus becomes a conserved, modular building block of the network topology. The FFL, for instance, is one of the most famous motifs in gene regulation, known to perform diverse signal-processing tasks. Discovering its overrepresentation through a high Z-score would be strong evidence that its specific function is important for the organism and has shaped the network's evolution. In this specific case, the Z-score of $\\approx 0.8176$ is not large enough to conclude that the FFL is a significant motif in this particular network.",
            "answer": "$$\\boxed{0.8176}$$"
        }
    ]
}