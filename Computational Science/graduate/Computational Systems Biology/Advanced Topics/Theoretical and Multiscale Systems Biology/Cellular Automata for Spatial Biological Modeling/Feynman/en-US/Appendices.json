{
    "hands_on_practices": [
        {
            "introduction": "A crucial first step in analyzing any cellular automaton model is to understand the direct consequences of its update rules. This foundational exercise guides you through the process of deriving the expected change in a global quantity—the total cell number—from the local, stochastic rules governing cell division and death. By applying the law of total expectation, you will discover how carefully balanced rules can lead to emergent conservation principles, a key concept for validating model behavior and ensuring biological plausibility .",
            "id": "3293881",
            "problem": "Consider a two-dimensional square lattice cellular automaton (CA) with periodic boundary conditions representing an epithelial tissue monolayer. Each lattice site $j$ has a binary state $x_{j} \\in \\{0,1\\}$, where $x_{j} = 1$ denotes a living cell and $x_{j} = 0$ denotes an empty site. Let $N = \\sum_{j} x_{j}$ be the total number of cells. Each site has a fixed neighborhood of size $k$ (for example, the Moore neighborhood of radius one has $k = 8$), and for any occupied site $i$ define $e_{i} \\in \\{0,1,\\dots,k\\}$ as the number of empty neighbors of site $i$.\n\nAt each update, the CA evolves asynchronously by selecting one occupied site $i$ uniformly at random from the set of all occupied sites. Given the selected site $i$, define a local event probability\n$$\nr_{i} = r_{0} \\frac{e_{i}}{k},\n$$\nwhere $r_{0} \\in (0, \\tfrac{1}{2}]$ is a fixed parameter. The update at site $i$ then proceeds by drawing a single outcome from the following mutually exclusive possibilities:\n- With probability $r_{i}$, the cell at $i$ divides into one of its $e_{i}$ empty neighboring sites chosen uniformly at random, thereby increasing $N$ by $1$.\n- With probability $r_{i}$, the cell at $i$ undergoes apoptosis (programmed cell death), thereby decreasing $N$ by $1$.\n- With probability $1 - 2 r_{i}$, no change occurs at $i$ and $N$ is unchanged.\n\nThese rules reflect two well-tested biological facts: (i) cell division is limited by the availability of free space, and (ii) loss of contact-mediated survival signals (anoikis) increases the likelihood of apoptosis in sparsely occupied neighborhoods.\n\nStarting from the definitions of expected value and conditioning on the random choice of the focal site and the stochastic outcome of the update at that site, derive the expected change in the total number of cells per update, denoted $\\mathbb{E}[\\Delta N]$, as a closed-form analytic expression in terms of the current configuration $\\{x_{j}\\}$, the neighborhood emptiness counts $\\{e_{i}\\}$, and the parameter $r_{0}$. Express your final answer as a single analytic expression with no units. No rounding is required.",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded as a standard cellular automaton model in computational biology, is well-posed with all necessary parameters and rules defined, and is objective and free of contradictions. The constraint $r_0 \\in (0, \\tfrac{1}{2}]$ ensures that all probabilities are well-defined and non-negative, as $r_i = r_0 \\frac{e_i}{k} \\le r_0 \\le \\frac{1}{2}$, which implies $1 - 2r_i \\ge 0$. We proceed with the derivation.\n\nThe objective is to derive the expected change in the total number of cells per update, denoted $\\mathbb{E}[\\Delta N]$. The total number of cells is $N = \\sum_j x_j$, where $x_j=1$ for an occupied site and $x_j=0$ for an empty site. We assume the process starts with a non-zero number of cells, i.e., $N > 0$.\n\nThe update process consists of two stages of random selection:\n1.  An occupied site $i$ is selected uniformly at random from the set of all $N$ occupied sites.\n2.  A stochastic event (division, apoptosis, or no change) occurs at site $i$ according to the given probabilities.\n\nLet $\\mathcal{O} = \\{ j \\mid x_j = 1 \\}$ be the set of indices of all occupied sites. The size of this set is $|\\mathcal{O}| = N$. Let $I$ be the random variable representing the index of the site selected for update. According to the problem statement, for any site $i \\in \\mathcal{O}$, the probability of it being selected is:\n$$\nP(I=i) = \\frac{1}{N}\n$$\nTo find the expected change in the cell number, $\\mathbb{E}[\\Delta N]$, we can use the law of total expectation, conditioning on the selection of site $I$. The formula is:\n$$\n\\mathbb{E}[\\Delta N] = \\sum_{i \\in \\mathcal{O}} \\mathbb{E}[\\Delta N \\mid I=i] P(I=i)\n$$\nwhere $\\mathbb{E}[\\Delta N \\mid I=i]$ is the expected change in $N$ given that site $i$ has been selected for the update.\n\nWe now compute this conditional expectation for an arbitrary occupied site $i \\in \\mathcal{O}$. The change in the total cell number, $\\Delta N$, can take on three distinct values based on the event at site $i$:\n*   **Division**: The number of cells increases by one, so $\\Delta N = +1$. This event occurs with probability $r_i$.\n*   **Apoptosis**: The number of cells decreases by one, so $\\Delta N = -1$. This event occurs with probability $r_i$.\n*   **No change**: The number of cells remains the same, so $\\Delta N = 0$. This event occurs with probability $1 - 2r_i$.\n\nThe expected value of $\\Delta N$, conditioned on the selection of site $i$, is the sum of each possible value of $\\Delta N$ multiplied by its corresponding probability:\n$$\n\\mathbb{E}[\\Delta N \\mid I=i] = (+1) \\cdot P(\\text{division at } i) + (-1) \\cdot P(\\text{apoptosis at } i) + (0) \\cdot P(\\text{no change at } i)\n$$\nSubstituting the probabilities given in the problem:\n$$\n\\mathbb{E}[\\Delta N \\mid I=i] = (+1) \\cdot r_i + (-1) \\cdot r_i + (0) \\cdot (1 - 2r_i)\n$$\nThis simplifies to:\n$$\n\\mathbb{E}[\\Delta N \\mid I=i] = r_i - r_i + 0 = 0\n$$\nThis result demonstrates that for any occupied site $i$ that is chosen, the expected change in the total cell population is exactly zero. This is a direct consequence of the model's design, where the probability of a cell-number-increasing event (division) is specified to be identical to the probability of a cell-number-decreasing event (apoptosis). The local neighborhood-dependent factor $r_i = r_0 \\frac{e_i}{k}$ modulates both rates equally, so their respective contributions to the expected change cancel each other out perfectly at the level of a single event.\n\nNow, we substitute this conditional expectation back into the law of total expectation:\n$$\n\\mathbb{E}[\\Delta N] = \\sum_{i \\in \\mathcal{O}} (0) \\cdot P(I=i)\n$$\nSince $P(I=i) = \\frac{1}{N}$, this becomes:\n$$\n\\mathbb{E}[\\Delta N] = \\sum_{i \\in \\mathcal{O}} (0) \\cdot \\frac{1}{N}\n$$\nThe sum consists of $N$ terms, each of which is zero. Therefore, the total sum is zero:\n$$\n\\mathbb{E}[\\Delta N] = 0\n$$\nThe expected change in the total number of cells per update is $0$. This is a closed-form analytic expression, a constant that is independent of the current configuration $\\{x_j\\}$, the neighborhood emptiness counts $\\{e_i\\}$, and the parameter $r_0$.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "While direct simulation reveals the behavior of a specific instance of a model, analytical approximations provide deeper, more general insights into the collective dynamics and phase transitions of a system. This practice explores two powerful techniques: the mean-field approximation, which ignores spatial correlations, and the more refined pair approximation, which accounts for nearest-neighbor interactions. By deriving the recurrence relations for both and comparing their predictions to a direct Monte Carlo simulation, you will gain a hands-on understanding of how to bridge the gap between microscopic rules and macroscopic emergent behavior .",
            "id": "3293915",
            "problem": "Consider a single-species Probabilistic Cellular Automaton (PCA) on a periodic square lattice with von Neumann neighborhood (each site has $z=4$ nearest neighbors). Each lattice site at discrete time $t$ is either occupied by a cell ($1$) or empty ($0$). The synchronous update from time $t$ to time $t+1$ consists of the following sub-steps applied in order to the entire lattice: (i) death, (ii) birth, (iii) movement. All events are conditionally independent given the current configuration where stated, and all random choices are uniform.\n\nDeath sub-step: each occupied site independently becomes empty with probability $d \\in [0,1]$.\n\nBirth sub-step: for each empty site, let $K$ denote the number of occupied nearest neighbors after the death sub-step. The site becomes occupied with probability $1 - (1 - \\beta)^{K}$, where $\\beta \\in [0,1]$ is the per-neighbor colonization probability.\n\nMovement sub-step: each occupied site independently attempts to move to a uniformly random empty nearest neighbor with probability $m \\in [0,1]$. If multiple occupied sites target the same empty neighbor, one of them is chosen uniformly at random to move and the others stay. The movement sub-step conserves the total number of occupied sites.\n\nLet $u_t$ denote the occupancy fraction, that is, the probability that a uniformly random site is occupied at time $t$. Let $C_{NN,t}$ denote the nearest-neighbor occupancy correlation, that is, the probability that both ends of a uniformly random undirected nearest-neighbor edge are occupied at time $t$.\n\nTask A (derivation of the mean-field recurrence): Starting from the statistical independence assumption between sites (no spatial correlations) and the binomial law for the number of occupied neighbors under independence, derive a recurrence for $u_{t+1}$ as a function of $u_t$, $d$, $\\beta$, and $z$ under the above update order. Your derivation must explicitly start from the death and birth mechanisms and must not assume any pre-existing formula for $u_{t+1}$.\n\nTask B (pair approximation including nearest-neighbor correlation): Relax the independence assumption by incorporating the nearest-neighbor correlation $C_{NN,t}$. Let $u_t^D = u_t (1 - d)$ and $C_{NN,t}^D = C_{NN,t} (1 - d)^2$ denote the occupancy fraction and nearest-neighbor correlation immediately after the death sub-step. Under the pair approximation that assumes conditional independence of the $z-1$ neighbors other than a specified neighbor given the state of the focal site, express the conditional probability $q_t^D$ that a nearest neighbor of an empty site is occupied as $q_t^D = (u_t^D - C_{NN,t}^D) / (1 - u_t^D)$, and derive:\n- a recurrence for $u_{t+1}$ in terms of $u_t^D$, $q_t^D$, and $z$ using the binomial law for $K$ under the pair approximation,\n- a recurrence for $C_{NN,t+1}$ for the special case $m=0$ constructed by enumerating all nearest-neighbor pair types immediately after death and their transitions after birth. Use the following decomposition with $z=4$: letting $p_{11}^D=C_{NN,t}^D$, $p_{10}^D = u_t^D - C_{NN,t}^D$, and $p_{00}^D = 1 - 2 u_t^D + C_{NN,t}^D$, define\n$E_t = 1 - [1 - \\beta q_t^D]^{z-1}$, and $\\Phi_t = 1 - (1 - \\beta) [1 - \\beta q_t^D]^{z-1}$, then approximate\n$C_{NN,t+1} \\approx C_{NN,t}^{B} = p_{11}^D + 2 p_{10}^D \\,\\Phi_t + p_{00}^D \\, E_t^2$,\nwhich assumes independence of colonization events for both sites of a $00$ pair given the surrounding neighborhood (this is exact for the von Neumann neighborhood because adjacent sites have no common neighbors other than each other). For general $m \\in [0,1]$, argue a simple decorrelation-by-mixing approximation for the movement sub-step of the form $C_{NN,t+1} \\approx (1 - m)\\, C_{NN,t}^{B} + m \\, u_{t+1}^2$ that preserves the marginal occupancy fraction and interpolates between purely birth–death dynamics ($m=0$) and fully mixed edges ($m=1$).\n\nTask C (quantification of improvement): Implement a program that:\n- computes the mean-field fixed point $u^\\ast_{\\mathrm{MF}}$ by iterating the mean-field recurrence from an initial $u_0 \\in (0,1)$ until convergence,\n- computes the pair-approximation fixed point $u^\\ast_{\\mathrm{PA}}$ by iterating the coupled $(u_t, C_{NN,t})$ recurrences from an initial $(u_0, C_{NN,0})$ until convergence, with $C_{NN,0}$ initialized to $u_0^2$,\n- runs a Monte Carlo simulation of the PCA on a periodic square lattice of side length $L$ for $T$ steps from a random initial occupancy fraction $u_0$, averages the occupancy fraction over the last $B$ steps to estimate $u^\\ast_{\\mathrm{sim}}$ (averaging over $R$ independent runs), and\n- reports, for each parameter set, the improvement in absolute error achieved by the pair approximation relative to the mean-field approximation, defined as $\\Delta = |u^\\ast_{\\mathrm{MF}} - u^\\ast_{\\mathrm{sim}}| - |u^\\ast_{\\mathrm{PA}} - u^\\ast_{\\mathrm{sim}}|$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases below. Each result must be a real number.\n\nUse the following test suite of parameter sets, expressed in terms of $(\\beta, d, m, L, T, B, R)$:\n- Case A (general nontrivial occupancy): $(0.25, 0.2, 0, 64, 600, 400, 3)$\n- Case B (near extinction): $(0.05, 0.5, 0, 64, 600, 400, 3)$\n- Case C (high occupancy): $(0.6, 0.05, 0, 64, 600, 400, 3)$\n- Case D (near the mean-field threshold $\\beta z \\approx d$): $(0.1, 0.4, 0, 64, 600, 400, 3)$\n\nAngle units are not applicable. No physical units are involved. The final output format must be a single line of the form $[r_1,r_2,r_3,r_4]$ where each $r_i$ is the improvement $\\Delta$ for the corresponding case.",
            "solution": "The problem is valid as it presents a well-defined, scientifically grounded task in computational systems biology, free from contradictions or ambiguities.\n\nThe problem asks for a three-part analysis of a Probabilistic Cellular Automaton (PCA) model for a single biological species on a lattice. The tasks involve analytical derivations under mean-field and pair approximations, and a numerical comparison with direct simulation.\n\n### Task A: Mean-Field Recurrence Derivation\n\nThe goal is to derive a recurrence relation for the occupancy fraction $u_{t+1}$ as a function of $u_t$, the death probability $d$, the colonization probability $\\beta$, and the number of neighbors $z$. The mean-field approximation assumes that the states of all lattice sites are statistically independent.\n\nLet $u_t$ be the probability that a random site is occupied at time $t$. The dynamics proceed in sub-steps.\n\n1.  **Death Sub-step:** Each occupied site becomes empty with probability $d$. An occupied site at time $t$ remains occupied after the death sub-step with probability $1-d$. Due to the independence assumption, the density of occupied sites immediately after death, denoted $u_t^D$, is:\n    $$u_t^D = u_t (1 - d)$$\n    The density of empty sites after death is $1 - u_t^D$.\n\n2.  **Birth Sub-step:** An empty site can become occupied. The movement sub-step occurs after birth and conserves the total number of occupied sites. Therefore, the density $u_{t+1}$ is fully determined by the state of the system after the birth sub-step.\n    \n    A site that is empty after the death sub-step will become occupied at time $t+1$ if it is successfully colonized by at least one of its occupied neighbors. Let $K$ be the number of occupied neighbors of an empty site. The probability of colonization is given as $1-(1-\\beta)^K$.\n\n    Under the mean-field assumption, the state of each neighbor is independent of the others and of the focal site. The probability that any given neighbor is occupied (after the death step) is $u_t^D$. For a neighborhood of size $z$, the number of occupied neighbors $K$ follows a binomial distribution, $K \\sim B(z, u_t^D)$, with probability mass function $P(K=k) = \\binom{z}{k} (u_t^D)^k (1 - u_t^D)^{z-k}$.\n\n    The probability that an empty site (post-death) *remains* empty is the probability of not being colonized, averaged over all possible values of $K$:\n    $$P(\\text{empty remains empty}) = \\sum_{k=0}^{z} P(K=k) (1-\\beta)^k$$\n    $$P(\\text{empty remains empty}) = \\sum_{k=0}^{z} \\binom{z}{k} (u_t^D)^k (1 - u_t^D)^{z-k} (1-\\beta)^k$$\n    This sum can be recognized as a binomial expansion:\n    $$P(\\text{empty remains empty}) = \\sum_{k=0}^{z} \\binom{z}{k} [u_t^D(1-\\beta)]^k (1 - u_t^D)^{z-k} = [u_t^D(1-\\beta) + (1-u_t^D)]^z = [1 - \\beta u_t^D]^z$$\n    Therefore, the probability that an empty site becomes occupied is:\n    $$P(\\text{birth}) = 1 - [1 - \\beta u_t^D]^z$$\n\n3.  **Full Recurrence:** The total occupancy at time $t+1$ is the sum of sites that were occupied and survived death, plus sites that were empty after death and then experienced a birth event.\n    $$u_{t+1} = (\\text{density of survivors}) + (\\text{density of empty sites}) \\times P(\\text{birth})$$\n    $$u_{t+1} = u_t^D + (1 - u_t^D) \\left( 1 - [1 - \\beta u_t^D]^z \\right)$$\n    Substituting $u_t^D = u_t(1-d)$, we obtain the final mean-field recurrence relation:\n    $$u_{t+1} = u_t(1-d) + (1 - u_t(1-d)) \\left( 1 - \\left[1 - \\beta u_t(1-d)\\right]^z \\right)$$\n\n### Task B: Pair Approximation\n\nThis task relaxes the mean-field assumption by including nearest-neighbor correlations, $C_{NN,t}$. The von Neumann neighborhood has $z=4$.\n\n1.  **Recurrence for $u_{t+1}$:**\n    The structure of the derivation is analogous to the mean-field case, but the probability of a neighbor being occupied is now conditional.\n    After the death step, the occupancy fraction is $u_t^D = u_t(1-d)$, and the nearest-neighbor correlation is $C_{NN,t}^D = C_{NN,t}(1-d)^2$.\n\n    We consider an empty site. The pair approximation assumes that its $z$ neighbors are conditionally independent given the state of the focal site. The crucial quantity is $q_t^D$, the conditional probability that a neighbor of an empty site is occupied, after the death step. The problem provides the standard expression for this:\n    $$q_t^D = P(\\text{neighbor is } 1 | \\text{focal is } 0) = \\frac{P(1, 0)}{P(0)} = \\frac{u_t^D - C_{NN,t}^D}{1 - u_t^D}$$\n    The number of occupied neighbors $K$ for an empty site thus follows a binomial distribution $K \\sim B(z, q_t^D)$.\n    \n    The probability that this empty site becomes occupied (birth event) is:\n    $$P(\\text{birth}) = 1 - \\sum_{k=0}^{z} \\binom{z}{k} (q_t^D)^k (1-q_t^D)^{z-k} (1-\\beta)^k = 1 - [1 - \\beta q_t^D]^z$$\n    The recurrence for the occupancy fraction $u_{t+1}$ under the pair approximation is:\n    $$u_{t+1} = u_t^D + (1 - u_t^D) \\left( 1 - [1 - \\beta q_t^D]^z \\right)$$\n\n2.  **Recurrence for $C_{NN,t+1}$ (for $m=0$):**\n    For the case with no movement ($m=0$), the correlation after birth, $C_{NN,t}^B$, is the final correlation $C_{NN,t+1}$. The problem provides the formula for $C_{NN,t}^B$ built from the probabilities of pair configurations after death ($p_{11}^D, p_{10}^D, p_{00}^D$) and terms related to colonization probabilities ($E_t, \\Phi_t$).\n\n    The complete iterative system for the pair approximation with $m=0$ is as follows:\n    Given $(u_t, C_{NN,t})$ and parameters $(d, \\beta, z=4)$:\n    a. Calculate post-death quantities:\n        $$u_t^D = u_t(1-d)$$\n        $$C_{NN,t}^D = C_{NN,t}(1-d)^2$$\n    b. Calculate auxiliary quantities:\n        - If $u_t^D < 1$: $q_t^D = (u_t^D - C_{NN,t}^D) / (1 - u_t^D)$. Otherwise, $q_t^D=0$ as there are no empty sites.\n        - $p_{11}^D = C_{NN,t}^D$\n        - $p_{10}^D = u_t^D - C_{NN,t}^D$\n        - $p_{00}^D = 1 - 2u_t^D + C_{NN,t}^D$\n        - $E_t = 1 - [1 - \\beta q_t^D]^{z-1}$ (Prob. of colonizing an empty site next to an empty site)\n        - $\\Phi_t = 1 - (1 - \\beta) [1 - \\beta q_t^D]^{z-1}$ (Prob. of colonizing an empty site next to an occupied site)\n    c. Update state variables for time $t+1$:\n        $$u_{t+1} = u_t^D + (1 - u_t^D) \\left( 1 - [1 - \\beta q_t^D]^z \\right)$$\n        $$C_{NN,t+1} = p_{11}^D + 2 p_{10}^D \\Phi_t + p_{00}^D E_t^2$$\n\n3.  **Argument for Movement Step ($m > 0$):**\n    For a general movement probability $m$, the problem suggests the approximation:\n    $$C_{NN,t+1} \\approx (1 - m)\\, C_{NN,t}^{B} + m \\, u_{t+1}^2$$\n    This equation can be justified as a simple linear mixing model.\n    -   $C_{NN,t}^B$ represents the correlation established by the birth-death dynamics, before any movement occurs.\n    -   The movement step involves a fraction $m$ of occupied cells attempting to move to a random empty neighbor. This process breaks existing spatial correlations and forms new ones.\n    -   The term $(1 - m) C_{NN,t}^B$ represents the contribution to the final correlation from cell pairs that are assumed to be \"unaffected\" by movement. It models a fraction $(1-m)$ of the pre-movement correlation being preserved.\n    -   The term $m u_{t+1}^2$ represents the contribution from pairs that have been \"remixed\" by movement. It assumes that when a cell in a pair moves, the local correlation is destroyed and reset to the mean-field value, which is the square of the global density, $u_{t+1}^2$. The density $u_{t+1}$ is the correct one because movement conserves the number of occupied sites.\n    -   This model correctly interpolates between the two extreme cases:\n        -   If $m=0$ (no movement), $C_{NN,t+1} = C_{NN,t}^B$, recovering the birth-death dynamics.\n        -   If $m=1$ (maximal mixing), $C_{NN,t+1} = u_{t+1}^2$, which corresponds to a spatially uncorrelated (random) distribution of cells with density $u_{t+1}$.\n    This heuristic provides a plausible and computationally simple way to account for the decorrelating effect of cell movement.\n\n### Task C: Quantification of Improvement\nThe implementation of the mean-field solver, the pair-approximation solver, and the Monte Carlo simulation is provided in the final answer block. The code computes the steady-state occupancy fraction $u^\\ast$ from each of the three methods and reports the improvement in absolute error $\\Delta = |u^\\ast_{\\mathrm{MF}} - u^\\ast_{\\mathrm{sim}}| - |u^\\ast_{\\mathrm{PA}} - u^\\ast_{\\mathrm{sim}}|$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import signal\n\ndef solve_mf(beta, d, z=4, u0=0.5, tol=1e-10, max_iter=100000):\n    \"\"\"\n    Computes the mean-field fixed point occupancy fraction.\n    \"\"\"\n    u = u0\n    for _ in range(max_iter):\n        u_old = u\n        uD = u * (1 - d)\n        if uD >= 1.0: # Extinction or full occupancy\n            return uD\n        \n        # Prob that an empty site becomes occupied\n        prob_birth = 1 - (1 - beta * uD)**z\n        \n        # Recurrence for u\n        u = uD + (1 - uD) * prob_birth\n        \n        if abs(u - u_old) < tol:\n            break\n    return u\n\ndef solve_pa(beta, d, m, z=4, u0=0.5, tol=1e-10, max_iter=100000):\n    \"\"\"\n    Computes the pair-approximation fixed point occupancy fraction.\n    \"\"\"\n    u = u0\n    C_NN = u0**2  # Initial uncorrelated assumption\n    \n    for _ in range(max_iter):\n        u_old = u\n        \n        # 1. Post-death quantities\n        uD = u * (1 - d)\n        C_NN_D = C_NN * (1 - d)**2\n        \n        if uD >= 1.0: # Saturation\n             u_next = 1.0\n             C_NN_next = 1.0\n        elif uD <= 1e-12: # Extinction\n             u_next = 0.0\n             C_NN_next = 0.0\n        else:\n            # 2. Auxiliary quantities for birth step\n            # Conditional probability P(1|0) after death\n            qD = (uD - C_NN_D) / (1 - uD)\n            qD = max(0, qD) # Ensure non-negative from numerical error\n\n            # 3. Update u\n            prob_birth_empty_site = 1 - (1 - beta * qD)**z\n            u_next = uD + (1 - uD) * prob_birth_empty_site\n\n            # 4. Update C_NN for m=0\n            p11D = C_NN_D\n            p10D = uD - C_NN_D\n            p00D = 1 - 2 * uD + C_NN_D\n\n            z_minus_1 = z - 1\n            term_qD = (1 - beta * qD)**z_minus_1\n\n            E_t = 1 - term_qD\n            Phi_t = 1 - (1 - beta) * term_qD\n\n            C_NN_B = p11D + 2 * p10D * Phi_t + p00D * E_t**2\n            \n            # 5. Movement step\n            C_NN_next = (1 - m) * C_NN_B + m * u_next**2\n\n        u = u_next\n        C_NN = C_NN_next\n\n        if abs(u - u_old) < tol:\n            break\n            \n    return u\n\ndef run_simulation(beta, d, m, L, T, B, R, z=4, u0_sim=0.5):\n    \"\"\"\n    Runs a Monte Carlo simulation of the PCA.\n    This implementation is for m=0, as per the test cases.\n    \"\"\"\n    if m != 0:\n        raise NotImplementedError(\"Simulation is implemented for m=0 only.\")\n        \n    u_estimates_per_run = []\n    kernel = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]], dtype=np.uint8)\n\n    for _ in range(R):\n        # Initialize grid with random occupancy\n        grid = np.random.choice([0, 1], size=(L, L), p=[1 - u0_sim, u0_sim])\n        occupancy_trace = []\n\n        for step in range(T):\n            # --- Death sub-step ---\n            grid_after_death = grid.copy()\n            occupied_indices = np.argwhere(grid == 1)\n            if len(occupied_indices) > 0:\n                rand_nums = np.random.rand(len(occupied_indices))\n                dying_mask = rand_nums < d\n                dying_indices = occupied_indices[dying_mask]\n                if len(dying_indices) > 0:\n                    grid_after_death[dying_indices[:, 0], dying_indices[:, 1]] = 0\n\n            # --- Birth sub-step ---\n            # Count occupied neighbors for all sites using convolution\n            neighbor_counts = signal.convolve2d(grid_after_death, kernel, mode='same', boundary='wrap')\n            \n            # Calculate birth probability for each site based on its neighbor count\n            birth_probs = 1 - (1 - beta)**neighbor_counts\n            \n            # Apply birth only to empty sites\n            empty_mask = (grid_after_death == 0)\n            rand_nums_birth = np.random.rand(L, L)\n            birth_mask = empty_mask & (rand_nums_birth < birth_probs)\n            \n            grid_after_birth = grid_after_death.copy()\n            grid_after_birth[birth_mask] = 1\n            \n            # --- Movement sub-step ---\n            # For m=0, grid for next step is grid_after_birth\n            grid = grid_after_birth\n\n            if step >= T - B:\n                occupancy_trace.append(np.mean(grid))\n\n        u_estimates_per_run.append(np.mean(occupancy_trace))\n\n    return np.mean(u_estimates_per_run)\n\ndef solve():\n    \"\"\"\n    Main function to run all tasks and print the result.\n    \"\"\"\n    # Parameters from the problem statement: (beta, d, m, L, T, B, R)\n    test_cases = [\n        (0.25, 0.2, 0, 64, 600, 400, 3), # Case A\n        (0.05, 0.5, 0, 64, 600, 400, 3), # Case B\n        (0.6, 0.05, 0, 64, 600, 400, 3), # Case C\n        (0.1, 0.4, 0, 64, 600, 400, 3), # Case D\n    ]\n\n    results = []\n    \n    # Set a consistent initial condition for theories and simulations\n    u0_theory = 0.5\n    u0_sim = 0.5\n    z = 4\n\n    for case in test_cases:\n        beta, d, m, L, T, B, R = case\n        \n        # Calculate mean-field fixed point\n        u_mf = solve_mf(beta, d, z, u0=u0_theory)\n        \n        # Calculate pair-approximation fixed point\n        u_pa = solve_pa(beta, d, m, z, u0=u0_theory)\n        \n        # Run simulation to get an estimate of the true fixed point\n        u_sim = run_simulation(beta, d, m, L, T, B, R, z, u0_sim=u0_sim)\n        \n        # Calculate improvement in absolute error\n        error_mf = abs(u_mf - u_sim)\n        error_pa = abs(u_pa - u_sim)\n        improvement = error_mf - error_pa\n        \n        results.append(improvement)\n\n    # Format and print the final output as a single line\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A central challenge in using cellular automata for biological modeling is the faithful representation of continuous physical processes on a discrete lattice. This exercise tackles this issue head-on by investigating how an agent's ability to sense a chemical gradient is affected by the discrete geometry of its neighborhood. You will implement a computational experiment to quantify the bias in gradient estimation arising from different neighborhood structures (von Neumann vs. Moore) and the symmetry-breaking effects of boundaries, providing critical insight into the sources of discretization error in models of chemotaxis .",
            "id": "3293950",
            "problem": "Consider a two-dimensional lattice used in Cellular Automata (CA) for spatial biological modeling, with grid spacing $\\Delta$ and a scalar chemoattractant concentration field $c(x,y)$ sensed by an agent located at $(x_0,y_0)$. The agent estimates the local gradient $\\nabla c$ using only samples in a specified neighborhood and a linear plane fit. The neighborhoods considered are the von Neumann neighborhood (four cardinal neighbors) and the Moore neighborhood (eight neighbors including diagonals). Let the estimation method be defined by ordinary least squares fitting of a local plane to the measured concentrations:\n$$\nc(x_0 + \\delta x, y_0 + \\delta y) \\approx \\beta_0 + g_x \\cdot \\delta x + g_y \\cdot \\delta y,\n$$\nwhere $\\beta_0$ is an intercept and $(g_x, g_y)$ is the estimated gradient vector. The fit is performed over all available offsets $(\\delta x, \\delta y)$ in the chosen neighborhood, including the center point $(\\delta x, \\delta y) = (0,0)$.\n\nAssume the scalar field $c(x,y)$ is a smooth function modeled as\n$$\nc(x,y) = c_0 + \\alpha x + \\beta y + \\frac{1}{2}\\kappa_x x^2 + \\frac{1}{2}\\kappa_y y^2 + \\gamma x y,\n$$\nand that measurements are corrupted by independent additive noise $\\eta$ with zero mean and finite variance, specifically $\\eta \\sim \\mathcal{N}(0,\\sigma^2)$, so observed values are $\\tilde{c}(x,y) = c(x,y) + \\eta$. The true gradient at $(x_0,y_0)$ is\n$$\n\\nabla c(x_0,y_0) = \\left(\\alpha + \\kappa_x x_0 + \\gamma y_0,\\ \\beta + \\kappa_y y_0 + \\gamma x_0\\right).\n$$\n\nYou must quantify the discrete approximation error of gradient sensing due to neighborhood geometry by computing the bias of the estimator for $\\nabla c$ under the two neighborhoods. Define the bias vector as\n$$\nb = \\mathbb{E}[\\hat{g}] - \\nabla c(x_0,y_0),\n$$\nwhere $\\hat{g} = (g_x, g_y)$ is the estimator obtained from the least squares fit using $\\tilde{c}$ over the given neighborhood. Because the estimator is linear in the measured concentrations, the expected bias for the noisy field equals the bias for the noise-free field. Nevertheless, you must compute the expected bias using the exact least squares formula over the specified neighborhood geometry. Report the Euclidean norm of the bias, $\\|b\\|_2$, for each neighborhood and each test case.\n\nUse a lattice with spacing $\\Delta = 1$ for all cases. For the von Neumann neighborhood, the offsets are $(0,0)$, $(\\Delta,0)$, $(-\\Delta,0)$, $(0,\\Delta)$, $(0,-\\Delta)$. For the Moore neighborhood, the offsets are $(0,0)$ plus all eight combinations $(\\pm\\Delta,0)$, $(0,\\pm\\Delta)$, and $(\\pm\\Delta,\\pm\\Delta)$. In boundary-limited cases, only include offsets that remain within the domain after translating by $(x_0,y_0)$.\n\nThe test suite consists of the following four parameter sets, covering a general case, curvature-induced bias, cross-term anisotropy, and a boundary truncation edge case:\n\n- Test case $1$ (general linear field):\n  - $\\alpha = 1.25$, $\\beta = -0.75$, $\\kappa_x = 0.0$, $\\kappa_y = 0.0$, $\\gamma = 0.0$, $c_0 = 0.0$, $\\sigma = 0.2$,\n  - $(x_0,y_0) = (0.3,-0.2)$,\n  - Domain: infinite plane (no truncation).\n\n- Test case $2$ (anisotropic curvature):\n  - $\\alpha = 0.8$, $\\beta = -0.3$, $\\kappa_x = 0.6$, $\\kappa_y = -0.4$, $\\gamma = 0.0$, $c_0 = 1.0$, $\\sigma = 0.2$,\n  - $(x_0,y_0) = (-0.1,0.25)$,\n  - Domain: infinite plane.\n\n- Test case $3$ (cross-term anisotropy with offset center):\n  - $\\alpha = -0.4$, $\\beta = 0.9$, $\\kappa_x = 0.0$, $\\kappa_y = 0.0$, $\\gamma = 0.8$, $c_0 = 0.5$, $\\sigma = 0.3$,\n  - $(x_0,y_0) = (0.5,-0.5)$,\n  - Domain: infinite plane.\n\n- Test case $4$ (boundary truncation in a quarter-plane):\n  - $\\alpha = 0.2$, $\\beta = 0.7$, $\\kappa_x = 1.2$, $\\kappa_y = -0.9$, $\\gamma = 0.3$, $c_0 = -0.1$, $\\sigma = 0.25$,\n  - $(x_0,y_0) = (0.0,0.0)$,\n  - Domain: quarter-plane with constraints $x \\ge 0$, $y \\ge 0$.\n\nImplementation requirements:\n- Construct the design matrix $X$ with rows $[1,\\ \\delta x,\\ \\delta y]$ for each included offset $(\\delta x,\\delta y)$ in the selected neighborhood. Construct the response vector $y$ using the noise-free $c(x_0+\\delta x, y_0+\\delta y)$. The least squares solution is\n$$\n\\begin{bmatrix}\n\\hat{\\beta}_0 \\\\\n\\hat{g}_x \\\\\n\\hat{g}_y\n\\end{bmatrix}\n=\n(X^\\top X)^{-1} X^\\top y.\n$$\n- Compute the true gradient at $(x_0,y_0)$ using the analytic expression for $\\nabla c(x_0,y_0)$ above.\n- Compute the bias vector $b = \\hat{g} - \\nabla c(x_0,y_0)$ and report the Euclidean norm $\\|b\\|_2$ for each neighborhood.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order:\n$$\n[\\|b\\|_2^{\\text{VN},1},\\ \\|b\\|_2^{\\text{MO},1},\\ \\|b\\|_2^{\\text{VN},2},\\ \\|b\\|_2^{\\text{MO},2},\\ \\|b\\|_2^{\\text{VN},3},\\ \\|b\\|_2^{\\text{MO},3},\\ \\|b\\|_2^{\\text{VN},4},\\ \\|b\\|_2^{\\text{MO},4}],\n$$\nwhere $\\text{VN}$ denotes the von Neumann neighborhood and $\\text{MO}$ denotes the Moore neighborhood, and superscripts index the test case number. Express each floating-point value rounded to six decimal places. No other output should be printed.",
            "solution": "The problem requires the quantification of the bias in a local gradient estimator for a two-dimensional scalar field. The estimator is derived from a linear plane fit using ordinary least squares (OLS) over two distinct cellular automata neighborhoods: the von Neumann and Moore neighborhoods.\n\nFirst, we formalize the problem. The scalar field is given by a second-order polynomial:\n$$\nc(x,y) = c_0 + \\alpha x + \\beta y + \\frac{1}{2}\\kappa_x x^2 + \\frac{1}{2}\\kappa_y y^2 + \\gamma x y\n$$\nThe true gradient at a point $(x_0, y_0)$ is the vector of first partial derivatives evaluated at that point:\n$$\n\\nabla c(x_0,y_0) = \\left( \\frac{\\partial c}{\\partial x}, \\frac{\\partial c}{\\partial y} \\right)\\bigg|_{(x_0, y_0)} = \\begin{pmatrix} \\alpha + \\kappa_x x_0 + \\gamma y_0 \\\\ \\beta + \\kappa_y y_0 + \\gamma x_0 \\end{pmatrix}\n$$\nThe gradient is estimated by sampling the field at a set of points in a neighborhood around $(x_0, y_0)$. These sample points are indexed by their offsets $(\\delta x_i, \\delta y_i)$ from the center, such that a measurement is taken at $(x_0 + \\delta x_i, y_0 + \\delta y_i)$. A linear plane is fitted to these measurements:\n$$\nc(x_0 + \\delta x_i, y_0 + \\delta y_i) \\approx \\hat{\\beta}_0 + \\hat{g}_x \\delta x_i + \\hat{g}_y \\delta y_i\n$$\nThis constitutes a linear regression problem. Let the vector of estimated parameters be $\\hat{\\theta} = [\\hat{\\beta}_0, \\hat{g}_x, \\hat{g}_y]^\\top$. The design matrix, $X$, is constructed such that its $i$-th row is $[1, \\delta x_i, \\delta y_i]$. The response vector, $y$, contains the field values $y_i = c(x_0 + \\delta x_i, y_0 + \\delta y_i)$ at the sample points. The OLS solution for the parameters is:\n$$\n\\hat{\\theta} = (X^\\top X)^{-1} X^\\top y\n$$\nThe estimated gradient is $\\hat{g} = [\\hat{g}_x, \\hat{g}_y]^\\top$, which corresponds to the second and third components of $\\hat{\\theta}$.\n\nThe problem states that while measurements are noisy, $\\tilde{c} = c + \\eta$ with $\\mathbb{E}[\\eta]=0$, the bias can be computed using the noise-free field $c(x,y)$. This is because the OLS estimator is linear, so the expectation of the estimator applied to noisy data is the estimator applied to the expected value of the data: $\\mathbb{E}[\\hat{\\theta}] = (X^\\top X)^{-1} X^\\top \\mathbb{E}[\\tilde{y}] = (X^\\top X)^{-1} X^\\top y$. Thus, the bias vector is $b = \\hat{g} - \\nabla c(x_0,y_0)$, where $\\hat{g}$ is computed using the noise-free field values.\n\nThe bias arises from model misspecification: we are fitting a linear model to data generated by a quadratic function. Let's analyze the response values $y_i$:\n$$\ny_i = c(x_0 + \\delta x_i, y_0 + \\delta y_i) = c_0 + \\alpha(x_0+\\delta x_i) + \\beta(y_0+\\delta y_i) + \\frac{1}{2}\\kappa_x(x_0+\\delta x_i)^2 + \\frac{1}{2}\\kappa_y(y_0+\\delta y_i)^2 + \\gamma(x_0+\\delta x_i)(y_0+\\delta y_i)\n$$\nExpanding this and grouping by powers of $\\delta x_i$ and $\\delta y_i$:\n$$\ny_i = c(x_0, y_0) + (\\alpha + \\kappa_x x_0 + \\gamma y_0)\\delta x_i + (\\beta + \\kappa_y y_0 + \\gamma x_0)\\delta y_i + \\left( \\frac{1}{2}\\kappa_x \\delta x_i^2 + \\frac{1}{2}\\kappa_y \\delta y_i^2 + \\gamma \\delta x_i \\delta y_i \\right)\n$$\nThis can be written as $y_i = \\theta_{\\text{true}}^\\top [1, \\delta x_i, \\delta y_i]^\\top + E_i$, where $\\theta_{\\text{true}} = [c(x_0,y_0), \\nabla c(x_0,y_0)_x, \\nabla c(x_0,y_0)_y]^\\top$ and $E_i$ is the error term from the unmodeled quadratic components. The bias in the estimator is $b_\\theta = \\hat{\\theta} - \\theta_{\\text{true}} = (X^\\top X)^{-1} X^\\top E$, where $E$ is the vector of error terms $E_i$.\n\nFor the infinite domain cases (Test cases $1$, $2$, and $3$), both the von Neumann and Moore neighborhoods are symmetric with respect to the origin. The set of offsets $\\{\\delta x_i\\}$ and $\\{\\delta y_i\\}$ have properties such as $\\sum_i \\delta x_i^p \\delta y_i^q = 0$ if $p$ or $q$ is odd. This symmetry causes the off-diagonal terms of $X^\\top X$ to be zero, making it a diagonal matrix. More importantly, the terms in $X^\\top E$ that would create a bias in the gradient components become zero. For example, the bias in $\\hat{g}_x$ depends on $\\sum_i \\delta x_i E_i$:\n$$\n\\sum_i \\delta x_i E_i = \\sum_i \\delta x_i \\left( \\frac{1}{2}\\kappa_x \\delta x_i^2 + \\frac{1}{2}\\kappa_y \\delta y_i^2 + \\gamma \\delta x_i \\delta y_i \\right) = \\frac{\\kappa_x}{2} \\sum_i \\delta x_i^3 + \\frac{\\kappa_y}{2} \\sum_i \\delta x_i \\delta y_i^2 + \\gamma \\sum_i \\delta x_i^2 \\delta y_i\n$$\nDue to point symmetry of the neighborhoods, all these sums are zero. Consequently, for symmetric stencils, the OLS estimate of the gradient of a quadratic field is exact, and the bias is zero. This applies to test cases $1$, $2$, and $3$ for both neighborhoods.\n\nFor test case $4$, the agent is at $(x_0,y_0) = (0,0)$ in a domain restricted to the first quadrant ($x \\ge 0, y \\ge 0$). This truncates the neighborhoods, breaking their symmetry.\n- Von Neumann (VN): The offsets are $\\{(0,0), (\\Delta,0), (-\\Delta,0), (0,\\Delta), (0,-\\Delta)\\}$ with $\\Delta=1$. The points must satisfy $x_0+\\delta x \\ge 0$ and $y_0+\\delta y \\ge 0$. With $(x_0,y_0)=(0,0)$, this means $\\delta x \\ge 0$ and $\\delta y \\ge 0$. The valid offsets are $\\{(0,0), (1,0), (0,1)\\}$.\n- Moore (MO): All eight neighbors plus the center. The valid offsets are $\\{(0,0), (1,0), (0,1), (1,1)\\}$.\n\nSince these truncated neighborhoods are asymmetric, the sums in the bias calculation are no longer zero, leading to a non-zero bias that depends on the quadratic coefficients $\\kappa_x, \\kappa_y, \\gamma$.\n\nThe computational procedure is as follows:\n1. For each test case, define the parameters $(\\alpha, \\beta, \\kappa_x, \\kappa_y, \\gamma, c_0)$ and the central point $(x_0, y_0)$. Define the domain constraints.\n2. For each neighborhood type (VN, MO):\n   a. Define the full set of offsets $(\\delta x, \\delta y)$ with $\\Delta=1$.\n   b. Filter the offsets to include only those where $(x_0+\\delta x, y_0+\\delta y)$ is within the specified domain.\n   c. Construct the design matrix $X$ with rows $[1, \\delta x_i, \\delta y_i]$ for each valid offset.\n   d. Construct the response vector $y$ by calculating $y_i = c(x_0+\\delta x_i, y_0+\\delta y_i)$ for each valid offset.\n   e. Solve the linear least squares problem for the coefficients $\\hat{\\theta} = [\\hat{\\beta}_0, \\hat{g}_x, \\hat{g}_y]^\\top$. A numerically robust method like `numpy.linalg.lstsq` is appropriate.\n   f. Extract the estimated gradient $\\hat{g} = [\\hat{g}_x, \\hat{g}_y]^\\top$.\n   g. Calculate the true gradient $\\nabla c(x_0,y_0)$ using its analytical formula.\n   h. Compute the bias vector $b = \\hat{g} - \\nabla c(x_0,y_0)$.\n   i. Calculate the Euclidean norm of the bias, $\\|b\\|_2$, and store it.\n3. Collect all $8$ resulting bias norms and format them as specified.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the bias norm for a least-squares gradient estimator in different scenarios.\n    \"\"\"\n    # Grid spacing\n    delta = 1.0\n\n    # Define neighborhoods by their offsets (dx, dy)\n    vn_offsets = np.array([\n        [0, 0], [delta, 0], [-delta, 0], [0, delta], [0, -delta]\n    ])\n    mo_offsets = np.array([\n        [0, 0], [delta, 0], [-delta, 0], [0, delta], [0, -delta],\n        [delta, delta], [-delta, delta], [delta, -delta], [-delta, -delta]\n    ])\n    neighborhoods = {'VN': vn_offsets, 'MO': mo_offsets}\n\n    test_cases = [\n        # Test case 1 (general linear field)\n        {'params': {'c0': 0.0, 'alpha': 1.25, 'beta': -0.75, 'kappa_x': 0.0, 'kappa_y': 0.0, 'gamma': 0.0},\n         'x0y0': (0.3, -0.2), 'domain_fn': lambda x, y: True},\n        # Test case 2 (anisotropic curvature)\n        {'params': {'c0': 1.0, 'alpha': 0.8, 'beta': -0.3, 'kappa_x': 0.6, 'kappa_y': -0.4, 'gamma': 0.0},\n         'x0y0': (-0.1, 0.25), 'domain_fn': lambda x, y: True},\n        # Test case 3 (cross-term anisotropy)\n        {'params': {'c0': 0.5, 'alpha': -0.4, 'beta': 0.9, 'kappa_x': 0.0, 'kappa_y': 0.0, 'gamma': 0.8},\n         'x0y0': (0.5, -0.5), 'domain_fn': lambda x, y: True},\n        # Test case 4 (boundary truncation)\n        {'params': {'c0': -0.1, 'alpha': 0.2, 'beta': 0.7, 'kappa_x': 1.2, 'kappa_y': -0.9, 'gamma': 0.3},\n         'x0y0': (0.0, 0.0), 'domain_fn': lambda x, y: x >= 0 and y >= 0},\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        p = case['params']\n        x0, y0 = case['x0y0']\n        domain_fn = case['domain_fn']\n\n        # Define the concentration field function for this case\n        def c_field(x, y):\n            return (p['c0'] + p['alpha'] * x + p['beta'] * y +\n                    0.5 * p['kappa_x'] * x**2 + 0.5 * p['kappa_y'] * y**2 +\n                    p['gamma'] * x * y)\n\n        # Calculate the true gradient at (x0, y0)\n        true_grad_x = p['alpha'] + p['kappa_x'] * x0 + p['gamma'] * y0\n        true_grad_y = p['beta'] + p['kappa_y'] * y0 + p['gamma'] * x0\n        true_gradient = np.array([true_grad_x, true_grad_y])\n\n        for name, base_offsets in neighborhoods.items():\n            # Filter offsets based on domain constraints\n            valid_offsets = []\n            for dx, dy in base_offsets:\n                if domain_fn(x0 + dx, y0 + dy):\n                    valid_offsets.append([dx, dy])\n            valid_offsets = np.array(valid_offsets)\n\n            # Construct the design matrix X and response vector y\n            X = np.ones((len(valid_offsets), 3))\n            X[:, 1:] = valid_offsets\n            \n            sample_points_x = x0 + valid_offsets[:, 0]\n            sample_points_y = y0 + valid_offsets[:, 1]\n            y = c_field(sample_points_x, sample_points_y)\n            \n            # Perform least squares regression\n            # theta = [beta_0, g_x, g_y]\n            theta, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n            \n            estimated_gradient = theta[1:]\n            \n            # Compute bias and its norm\n            bias_vector = estimated_gradient - true_gradient\n            bias_norm = np.linalg.norm(bias_vector)\n            \n            all_results.append(bias_norm)\n\n    # Format the final output string\n    formatted_results = [f\"{res:.6f}\" for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}