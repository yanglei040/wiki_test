{
    "hands_on_practices": [
        {
            "introduction": "The bedrock of large deviation theory is understanding the 'cost' of observing an empirical average that deviates from its expected value. This first exercise takes us back to fundamental principles, using a simple model of counting discrete promoter states to derive the large deviation rate function from scratch. By applying Stirling's approximation to the multinomial probability formula, you will reveal how the Kullback-Leibler divergence naturally emerges as the mathematical measure of improbability for observing a non-typical empirical distribution .",
            "id": "3322434",
            "problem": "In a snapshot assay of a clonal bacterial population, each cell’s promoter is observed to be in exactly one of $K$ distinct conformational states at the instant of measurement. Assume the promoter state of each of $n$ independently sampled cells is an independent and identically distributed draw from an unknown but fixed stationary distribution $p = (p_{1},\\dots,p_{K})$ with $p_{k} \\in (0,1)$ and $\\sum_{k=1}^{K} p_{k} = 1$. Let $N_{k}$ denote the number of cells observed in state $k$ and define the empirical histogram $f = (f_{1},\\dots,f_{K})$ by $f_{k} = N_{k}/n$, so that $f_{k} \\ge 0$ and $\\sum_{k=1}^{K} f_{k} = 1$. \n\nUsing only first principles for independent categorical sampling, the multinomial counting formula, and asymptotic approximation based on Stirling’s formula for factorials, derive the large deviation rate function $I(f)$ that governs the exponential decay in $n$ of the probability that the empirical histogram $f$ deviates from the true distribution $p$. In particular, show that there exists a function $I(f)$ such that the probability that the empirical histogram lies in a small neighborhood of $f$ obeys an exponential scaling of the form $\\exp(-n\\,I(f) + o(n))$ as $n \\to \\infty$, and determine the explicit closed-form expression for $I(f)$ under the constraint $\\sum_{k=1}^{K} f_{k} = 1$ with $f_{k} \\ge 0$ and $p_{k} \\in (0,1)$. \n\nYour derivation must begin from the probability of observing counts $(N_{1},\\dots,N_{K})$ under the multinomial model and proceed by asymptotically evaluating its logarithm using Stirling’s approximation to leading order in $n$, carefully justifying the emergence of the simplex constraint and identifying the term that remains at exponential scale. Provide the final expression for $I(f)$ in closed form. No numerical evaluation is required, and no units are needed. The final answer must be a single closed-form analytic expression.",
            "solution": "The problem requires the derivation of the large deviation rate function for the empirical histogram of independent and identically distributed (i.i.d.) categorical samples. I will first validate the problem statement.\n\n### Step 1: Extract Givens\n- A system of $n$ independently sampled cells from a clonal bacterial population.\n- Each cell's promoter is in one of $K$ distinct conformational states.\n- The state of each cell is an i.i.d. draw from a stationary distribution $p = (p_{1},\\dots,p_{K})$.\n- For the true distribution, $p_{k} \\in (0,1)$ for all $k \\in \\{1, \\dots, K\\}$, and $\\sum_{k=1}^{K} p_{k} = 1$.\n- $N_{k}$ is the number of cells observed in state $k$, so that $\\sum_{k=1}^{K} N_{k} = n$.\n- The empirical histogram is $f = (f_{1},\\dots,f_{K})$ where $f_{k} = N_{k}/n$.\n- For the empirical histogram, $f_{k} \\ge 0$ for all $k$, and $\\sum_{k=1}^{K} f_{k} = 1$.\n- The task is to derive the large deviation rate function $I(f)$ governing the asymptotic probability $P(f) \\sim \\exp(-n\\,I(f))$.\n- The derivation must start from the multinomial counting formula and use Stirling’s approximation for factorials.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded. The model of i.i.d. categorical trials is a cornerstone of probability theory and statistical mechanics, and its application to promoter states in biology is a standard example in computational systems biology. The question asks for the derivation of the rate function associated with Sanov's theorem for a finite alphabet, which is a classic and fundamental result in large deviation theory. All terms are well-defined in mathematics and physics. The problem is well-posed, with a clear objective and sufficient information to reach a unique, meaningful solution. The language is objective and precise. Therefore, the problem is valid.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full derivation will be provided.\n\n### Derivation of the Rate Function $I(f)$\n\nWe begin from first principles. The system consists of $n$ independent trials, where each trial (observing a cell's promoter state) results in one of $K$ outcomes. The probability of outcome $k$ is given by $p_k$.\n\nThe probability of observing a specific sequence of outcomes (e.g., cell $1$ in state $k_1$, cell $2$ in state $k_2$, ..., cell $n$ in state $k_n$) is given by the product of individual probabilities, due to independence:\n$$P(\\text{sequence}) = \\prod_{i=1}^{n} p_{k_i}$$\nIf this sequence results in a set of counts $(N_1, N_2, \\dots, N_K)$ where $N_k$ is the number of times state $k$ appeared in the sequence, then this probability can be written as:\n$$P(\\text{sequence}) = \\prod_{k=1}^{K} p_k^{N_k}$$\nHowever, we are interested in the probability of observing the set of counts $(N_1, \\dots, N_K)$, not a specific sequence. Many different sequences can lead to the same set of counts. The number of such distinct sequences is given by the multinomial coefficient:\n$$\\binom{n}{N_1, N_2, \\dots, N_K} = \\frac{n!}{N_1! N_2! \\dots N_K!}$$\nThe total probability of observing the counts $(N_1, \\dots, N_K)$ is the product of the number of ways to achieve these counts and the probability of any one specific sequence that does so. This defines the multinomial distribution:\n$$P(N_1, \\dots, N_K) = \\frac{n!}{N_1! N_2! \\dots N_K!} \\prod_{k=1}^{K} p_k^{N_k}$$\nThe problem asks for the rate function $I(f)$ associated with the empirical histogram $f = (f_1, \\dots, f_K)$, where $f_k = N_k/n$. We analyze the asymptotic behavior of this probability for large $n$. It is more convenient to work with the logarithm of the probability. Let us denote the probability of a specific empirical histogram $f$ as $P_n(f)$, which is equivalent to $P(N_1=nf_1, \\dots, N_K=nf_K)$, assuming that each $nf_k$ is an integer.\n$$\\ln(P_n(f)) = \\ln(n!) - \\sum_{k=1}^{K} \\ln(N_k!) + \\sum_{k=1}^{K} N_k \\ln(p_k)$$\nTo evaluate this expression for large $n$, we employ Stirling's approximation for the logarithm of a factorial, $\\ln(m!) \\approx m \\ln(m) - m$ for large $m$. This is the leading-order approximation. Applying this to $\\ln(n!)$ and each $\\ln(N_k!)$ gives:\n$$\\ln(P_n(f)) \\approx (n \\ln(n) - n) - \\sum_{k=1}^{K} (N_k \\ln(N_k) - N_k) + \\sum_{k=1}^{K} N_k \\ln(p_k)$$\nWe can simplify the terms involving subtractions of $n$ and $N_k$. Since $\\sum_{k=1}^{K} N_k = n$, we have:\n$$-n - \\sum_{k=1}^{K} (-N_k) = -n + \\sum_{k=1}^{K} N_k = -n + n = 0$$\nThus, these terms cancel out, leaving:\n$$\\ln(P_n(f)) \\approx n \\ln(n) - \\sum_{k=1}^{K} N_k \\ln(N_k) + \\sum_{k=1}^{K} N_k \\ln(p_k)$$\nNow, we substitute $N_k = n f_k$. The expression becomes fully in terms of $n$ and the empirical frequencies $f_k$:\n$$\\ln(P_n(f)) \\approx n \\ln(n) - \\sum_{k=1}^{K} (n f_k) \\ln(n f_k) + \\sum_{k=1}^{K} (n f_k) \\ln(p_k)$$\nUsing the property of logarithms $\\ln(ab) = \\ln(a) + \\ln(b)$, we expand the term $\\ln(n f_k)$:\n$$\\ln(P_n(f)) \\approx n \\ln(n) - \\sum_{k=1}^{K} n f_k (\\ln(n) + \\ln(f_k)) + \\sum_{k=1}^{K} n f_k \\ln(p_k)$$\nLet's distribute and rearrange the sums:\n$$\\ln(P_n(f)) \\approx n \\ln(n) - \\left(\\sum_{k=1}^{K} n f_k \\ln(n)\\right) - \\left(\\sum_{k=1}^{K} n f_k \\ln(f_k)\\right) + \\left(\\sum_{k=1}^{K} n f_k \\ln(p_k)\\right)$$\nFactor out the common terms $n$ and $n \\ln(n)$:\n$$\\ln(P_n(f)) \\approx n \\ln(n) - n \\ln(n) \\left(\\sum_{k=1}^{K} f_k\\right) - n \\left(\\sum_{k=1}^{K} f_k \\ln(f_k)\\right) + n \\left(\\sum_{k=1}^{K} f_k \\ln(p_k)\\right)$$\nBy definition of the empirical histogram, the frequencies must sum to one: $\\sum_{k=1}^{K} f_k = 1$. This is the simplex constraint. Applying this constraint, the first two terms cancel:\n$$n \\ln(n) - n \\ln(n) (1) = 0$$\nThe expression for $\\ln(P_n(f))$ simplifies to:\n$$\\ln(P_n(f)) \\approx - n \\sum_{k=1}^{K} f_k \\ln(f_k) + n \\sum_{k=1}^{K} f_k \\ln(p_k)$$\nCombining the two sums:\n$$\\ln(P_n(f)) \\approx -n \\sum_{k=1}^{K} \\left( f_k \\ln(f_k) - f_k \\ln(p_k) \\right)$$\nUsing the property $\\ln(a) - \\ln(b) = \\ln(a/b)$:\n$$\\ln(P_n(f)) \\approx -n \\sum_{k=1}^{K} f_k \\ln\\left(\\frac{f_k}{p_k}\\right)$$\nThe problem statement posits that the probability has the asymptotic form $P_n(f) \\approx \\exp(-n I(f) + o(n))$. Our derivation shows that $\\ln(P_n(f)) = -n \\sum_{k=1}^{K} f_k \\ln\\left(\\frac{f_k}{p_k}\\right) + \\text{subleading terms}$. A more careful application of Stirling's formula, $\\ln(m!) = m\\ln m - m + \\frac{1}{2}\\ln(2\\pi m) + O(1/m)$, reveals that the subleading terms are of order $\\mathcal{O}(\\ln n)$. Since $\\lim_{n\\to\\infty} \\frac{\\ln n}{n} = 0$, these terms correspond to the $o(n)$ term in the exponent.\nSpecifically, we have:\n$$\\frac{1}{n} \\ln(P_n(f)) \\approx -\\sum_{k=1}^{K} f_k \\ln\\left(\\frac{f_k}{p_k}\\right)$$\nTherefore, in the limit as $n \\to \\infty$, we can identify the rate function $I(f)$ as the term that scales linearly with $n$ in the exponent:\n$$I(f) = \\lim_{n\\to\\infty} -\\frac{1}{n}\\ln(P_n(f)) = \\sum_{k=1}^{K} f_k \\ln\\left(\\frac{f_k}{p_k}\\right)$$\nThis expression is the Kullback-Leibler (KL) divergence, or relative entropy, between the empirical distribution $f$ and the true distribution $p$, often denoted $D_{KL}(f || p)$. It is a non-negative function, $I(f) \\ge 0$, and $I(f)=0$ if and only if $f_k = p_k$ for all $k$. This is consistent with the law of large numbers, which states that the probability of observing an empirical histogram different from the true one becomes exponentially small as the number of samples increases. The function $I(f)$ quantifies the \"cost\" of this deviation.\nThe final closed-form expression for the rate function is thus determined.",
            "answer": "$$\\boxed{\\sum_{k=1}^{K} f_{k} \\ln\\left(\\frac{f_{k}}{p_{k}}\\right)}$$"
        },
        {
            "introduction": "While discrete sampling is foundational, many cellular processes unfold continuously in time. This practice extends the core ideas of large deviations to a dynamic context using a canonical model of transcriptional bursting, where a gene's promoter switches stochastically between ON and OFF states. Your task is to compute the scaled cumulant generating function (SCGF), the dynamic analogue of the cumulant generating function, by constructing and analyzing a 'tilted' generator matrix, a key technique in the Feynman–Kac formalism for continuous-time Markov processes .",
            "id": "3322460",
            "problem": "Consider a two-state promoter model for a single gene in a well-mixed cell. The promoter state is a continuous-time Markov chain $X_{t}\\in\\{0,1\\}$ with $0$ denoting an inactive state (OFF) and $1$ denoting an active state (ON). The promoter switches from OFF to ON at rate $k_{\\mathrm{on}}$ and from ON to OFF at rate $k_{\\mathrm{off}}$, so the infinitesimal generator of $X_{t}$ is\n$$\nQ \\;=\\; \\begin{pmatrix}\n-\\,k_{\\mathrm{on}} & k_{\\mathrm{on}} \\\\\nk_{\\mathrm{off}} & -\\,k_{\\mathrm{off}}\n\\end{pmatrix}.\n$$\nWhen the promoter is ON, transcription initiations occur in bursts: burst initiation events form a Poisson process of rate $\\beta$ that is active only while $X_{t}=1$. Each burst produces a random number $B\\in\\{1,2,\\dots\\}$ of messenger ribonucleic acid (mRNA) molecules, independently across bursts, with a zero-truncated geometric distribution with parameter $p\\in(0,1]$, that is $\\mathbb{P}(B=n) = p\\,(1-p)^{n-1}$ for $n\\in\\{1,2,\\dots\\}$. When the promoter is OFF, no mRNA is produced. Let $N_{t}$ denote the total number of mRNA molecules produced up to time $t$ (counting all molecules within all bursts).\n\nDefine the scaled cumulant generating function (SCGF) $\\lambda(\\theta)$ for the time-additive counting observable $N_{t}$ by\n$$\n\\lambda(\\theta) \\;=\\; \\lim_{t\\to\\infty} \\frac{1}{t}\\,\\ln \\mathbb{E}\\!\\left[\\exp\\!\\left(\\theta\\,N_{t}\\right)\\right],\n$$\nfor those real $\\theta$ for which the moment generating function is finite. Use the Feynman–Kac representation for continuous-time Markov chains together with the moment generating function of a compound Poisson process to construct the tilted generator $L_{\\theta}$ governing the moment-generating semigroup associated with $\\exp(\\theta N_{t})$, and then compute the principal eigenvalue explicitly. Your answer must be a single, closed-form analytic expression for $\\lambda(\\theta)$ in terms of $k_{\\mathrm{on}}$, $k_{\\mathrm{off}}$, $\\beta$, $p$, and $\\theta$. State no intermediate results in the final answer. You may assume that $\\theta$ satisfies the condition needed for the geometric burst moment generating function to exist.\n\nThe final answer must be a single analytic expression. No numerical evaluation is required.",
            "solution": "The problem asks for the scaled cumulant generating function (SCGF) $\\lambda(\\theta)$ for the total number of mRNA molecules $N_t$ produced by a gene with a stochastically switching promoter. The SCGF is defined as $\\lambda(\\theta) = \\lim_{t\\to\\infty} \\frac{1}{t}\\,\\ln \\mathbb{E}[\\exp(\\theta N_t)]$. According to large deviation theory for continuous-time Markov chains, this SCGF is the principal eigenvalue of the tilted generator matrix $L_{\\theta}$.\n\nThe state of the system can be described by the promoter state $X_t \\in \\{0, 1\\}$. The evolution of expectations conditioned on the promoter state is governed by a tilted generator. Let $u_i(t, \\theta) = \\mathbb{E}[\\exp(\\theta N_t) | X_0 = i]$ for $i \\in \\{0, 1\\}$. The vector of these expectations $\\mathbf{u}(t, \\theta) = (u_0(t, \\theta), u_1(t, \\theta))^T$ follows the differential equation $\\frac{d}{dt}\\mathbf{u}(t,\\theta) = L_{\\theta} \\mathbf{u}(t,\\theta)$. For large $t$, the solution is dominated by the largest eigenvalue of $L_{\\theta}$, which is $\\lambda(\\theta)$.\n\nThe tilted generator $L_{\\theta}$ is constructed by adding a diagonal matrix $V(\\theta)$ to the infinitesimal generator $Q$ of the promoter switching process, $L_{\\theta} = Q + V(\\theta)$. The matrix $Q$ is given as:\n$$\nQ = \\begin{pmatrix} -k_{\\mathrm{on}} & k_{\\mathrm{on}} \\\\ k_{\\mathrm{off}} & -k_{\\mathrm{off}} \\end{pmatrix}\n$$\nThe diagonal matrix $V(\\theta) = \\mathrm{diag}(V_{00}(\\theta), V_{11}(\\theta))$ accounts for the production of mRNA in each state. The entry $V_{ii}(\\theta)$ is the cumulant generating function of the production process when the promoter is in state $i$.\n\n1.  **State $0$ (OFF):** No mRNA is produced. This means the number of molecules $N_t$ does not increase when $X_t=0$. The production rate is $0$, so the corresponding contribution to the SCGF is zero.\n    $$\n    V_{00}(\\theta) = 0\n    $$\n\n2.  **State $1$ (ON):** Transcription occurs as a compound Poisson process. Bursts are initiated with rate $\\beta$, and each burst produces a random number $B$ of mRNA molecules. The distribution of $B$ is a zero-truncated geometric distribution, $\\mathbb{P}(B=n) = p(1-p)^{n-1}$ for $n \\in \\{1, 2, \\dots\\}$. The cumulant generating function for a compound Poisson process is given by $\\beta (\\mathbb{E}[\\exp(\\theta B)] - 1)$. This gives the tilting term $V_{11}(\\theta)$.\n    First, we compute the moment generating function (MGF) of the burst size $B$, $M_B(\\theta) = \\mathbb{E}[\\exp(\\theta B)]$.\n    $$\n    M_B(\\theta) = \\sum_{n=1}^{\\infty} \\exp(\\theta n) \\mathbb{P}(B=n) = \\sum_{n=1}^{\\infty} \\exp(\\theta n) p(1-p)^{n-1}\n    $$\n    We can rewrite this as a geometric series:\n    $$\n    M_B(\\theta) = p \\exp(\\theta) \\sum_{n=1}^{\\infty} [\\exp(\\theta)(1-p)]^{n-1} = p \\exp(\\theta) \\sum_{k=0}^{\\infty} [\\exp(\\theta)(1-p)]^k\n    $$\n    The geometric series converges provided $|\\exp(\\theta)(1-p)| < 1$, a condition assumed in the problem statement. The sum is $\\frac{1}{1-\\exp(\\theta)(1-p)}$.\n    $$\n    M_B(\\theta) = \\frac{p \\exp(\\theta)}{1 - (1-p)\\exp(\\theta)}\n    $$\n    Now, we find $V_{11}(\\theta)$:\n    $$\n    V_{11}(\\theta) = \\beta (M_B(\\theta) - 1) = \\beta \\left( \\frac{p \\exp(\\theta)}{1 - (1-p)\\exp(\\theta)} - 1 \\right)\n    $$\n    Simplifying the expression in the parenthesis:\n    $$\n    V_{11}(\\theta) = \\beta \\left( \\frac{p \\exp(\\theta) - [1 - (1-p)\\exp(\\theta)]}{1 - (1-p)\\exp(\\theta)} \\right) = \\beta \\left( \\frac{p \\exp(\\theta) - 1 + \\exp(\\theta) - p\\exp(\\theta)}{1 - (1-p)\\exp(\\theta)} \\right)\n    $$\n    $$\n    V_{11}(\\theta) = \\beta \\frac{\\exp(\\theta) - 1}{1 - (1-p)\\exp(\\theta)}\n    $$\n\nNow we can write the full tilted generator $L_{\\theta}$:\n$$\nL_{\\theta} = Q + V(\\theta) = \\begin{pmatrix} -k_{\\mathrm{on}} & k_{\\mathrm{on}} \\\\ k_{\\mathrm{off}} & -k_{\\mathrm{off}} \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & V_{11}(\\theta) \\end{pmatrix} = \\begin{pmatrix} -k_{\\mathrm{on}} & k_{\\mathrm{on}} \\\\ k_{\\mathrm{off}} & -k_{\\mathrm{off}} + V_{11}(\\theta) \\end{pmatrix}\n$$\nThe SCGF $\\lambda(\\theta)$ is the principal (largest) eigenvalue of $L_{\\theta}$. The eigenvalues are the roots of the characteristic equation $\\det(L_{\\theta} - \\lambda I) = 0$.\n$$\n\\det\\begin{pmatrix} -k_{\\mathrm{on}} - \\lambda & k_{\\mathrm{on}} \\\\ k_{\\mathrm{off}} & -k_{\\mathrm{off}} + V_{11}(\\theta) - \\lambda \\end{pmatrix} = 0\n$$\n$$\n(-k_{\\mathrm{on}} - \\lambda)(-k_{\\mathrm{off}} + V_{11}(\\theta) - \\lambda) - k_{\\mathrm{on}}k_{\\mathrm{off}} = 0\n$$\nExpanding this gives a quadratic equation for $\\lambda$:\n$$\n\\lambda^2 - (-k_{\\mathrm{on}} - k_{\\mathrm{off}} + V_{11}(\\theta))\\lambda + (-k_{\\mathrm{on}})(-k_{\\mathrm{off}} + V_{11}(\\theta)) - k_{\\mathrm{on}}k_{\\mathrm{off}} = 0\n$$\n$$\n\\lambda^2 + (k_{\\mathrm{on}} + k_{\\mathrm{off}} - V_{11}(\\theta))\\lambda + k_{\\mathrm{on}}k_{\\mathrm{off}} - k_{\\mathrm{on}}V_{11}(\\theta) - k_{\\mathrm{on}}k_{\\mathrm{off}} = 0\n$$\n$$\n\\lambda^2 + (k_{\\mathrm{on}} + k_{\\mathrm{off}} - V_{11}(\\theta))\\lambda - k_{\\mathrm{on}}V_{11}(\\theta) = 0\n$$\nUsing the quadratic formula $\\lambda = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$ with $a=1$, $b=k_{\\mathrm{on}} + k_{\\mathrm{off}} - V_{11}(\\theta)$, and $c=-k_{\\mathrm{on}}V_{11}(\\theta)$:\n$$\n\\lambda = \\frac{-(k_{\\mathrm{on}} + k_{\\mathrm{off}} - V_{11}(\\theta)) \\pm \\sqrt{(k_{\\mathrm{on}} + k_{\\mathrm{off}} - V_{11}(\\theta))^2 - 4(1)(-k_{\\mathrm{on}}V_{11}(\\theta))}}{2}\n$$\n$$\n\\lambda = \\frac{1}{2} \\left[ V_{11}(\\theta) - k_{\\mathrm{on}} - k_{\\mathrm{off}} \\pm \\sqrt{(k_{\\mathrm{on}} + k_{\\mathrm{off}} - V_{11}(\\theta))^2 + 4k_{\\mathrm{on}}V_{11}(\\theta)} \\right]\n$$\nThe principal eigenvalue $\\lambda(\\theta)$ is the larger of the two roots, which corresponds to the '$+$' sign.\n$$\n\\lambda(\\theta) = \\frac{1}{2} \\left[ V_{11}(\\theta) - k_{\\mathrm{on}} - k_{\\mathrm{off}} + \\sqrt{(k_{\\mathrm{on}} + k_{\\mathrm{off}} - V_{11}(\\theta))^2 + 4k_{\\mathrm{on}}V_{11}(\\theta)} \\right]\n$$\nSubstituting the expression for $V_{11}(\\theta) = \\beta \\frac{\\exp(\\theta) - 1}{1 - (1-p)\\exp(\\theta)}$ gives the final closed-form answer. For brevity in the final expression, let us define $v(\\theta) = V_{11}(\\theta)$.\nThe final expression is:\n$$\n\\lambda(\\theta) = \\frac{1}{2} \\left[ \\beta \\frac{\\exp(\\theta) - 1}{1 - (1-p)\\exp(\\theta)} - k_{\\mathrm{on}} - k_{\\mathrm{off}} + \\sqrt{\\left(k_{\\mathrm{on}} + k_{\\mathrm{off}} - \\beta \\frac{\\exp(\\theta) - 1}{1 - (1-p)\\exp(\\theta)}\\right)^2 + 4k_{\\mathrm{on}}\\beta \\frac{\\exp(\\theta) - 1}{1 - (1-p)\\exp(\\theta)}} \\right]\n$$",
            "answer": "$$\n\\boxed{\\frac{1}{2} \\left( \\beta \\frac{\\exp(\\theta) - 1}{1 - (1-p)\\exp(\\theta)} - k_{\\mathrm{on}} - k_{\\mathrm{off}} + \\sqrt{\\left(k_{\\mathrm{on}} + k_{\\mathrm{off}} - \\beta \\frac{\\exp(\\theta) - 1}{1 - (1-p)\\exp(\\theta)}\\right)^{2} + 4k_{\\mathrm{on}}\\beta \\frac{\\exp(\\theta) - 1}{1 - (1-p)\\exp(\\theta)}} \\right)}\n$$"
        },
        {
            "introduction": "Theoretical derivations provide insight, but the true power of large deviation theory in computational biology is often realized through simulation. This final hands-on practice guides you through building a complete computational workflow to study rare transcriptional events that are inaccessible to standard simulation methods. You will implement the construction of tilted operators and use their eigenmodes to design an efficient importance sampling algorithm, known as the Doob h-transform, thereby bridging the gap between abstract theory and practical rare-event simulation .",
            "id": "3322416",
            "problem": "Consider a continuous-time transcriptional bursting model for messenger ribonucleic acid (mRNA) production in a single gene with a two-state promoter. The promoter state is either inactive ($0$) or active ($1$), and the mRNA copy number is a nonnegative integer. The process is modeled as a Continuous-Time Markov Chain (CTMC) on a finite state space constructed by truncating the mRNA copy number at a maximum $N_{\\max}$ to ensure computational tractability while maintaining scientific realism. All transition rates are expressed in $\\text{min}^{-1}$ and all outputs must be expressed in $\\text{min}^{-1}$.\n\nThe biologically grounded transitions are as follows, with state denoted by $(s,n)$ where $s\\in\\{0,1\\}$ is the promoter state and $n\\in\\{0,1,\\dots,N_{\\max}\\}$ is the mRNA copy number:\n- Promoter activation: $(0,n)\\to(1,n)$ with rate $\\alpha$.\n- Promoter deactivation: $(1,n)\\to(0,n)$ with rate $\\beta$.\n- Transcription (birth) when promoter is active and $n<N_{\\max}$: $(1,n)\\to(1,n+1)$ with rate $r$.\n- Degradation (death): $(s,n)\\to(s,n-1)$ with rate $\\gamma n$ for $n\\ge 1$.\nNo transcription occurs when $n=N_{\\max}$, and no degradation occurs when $n=0$.\n\nDefine the additive jump functional $A_T$ that counts the total number of transcription (birth) events up to time $T$. The Large Deviation Principle (LDP) for $A_T/T$ is studied via the Scaled Cumulant Generating Function (SCGF), which in the CTMC jump-functional setting is characterized by the dominant eigenvalue of a tilted generator. The tilted generator $L_k$ is defined via exponential tilting of the jump contributions relevant to $A_T$ (only transcription events contribute). For each transition $x\\to y$ with rate $W(x\\to y)$ and jump increment $g(x\\to y)$ for the observable $A_T$, the tilted operator acts on functions according to the Feynman–Kac formalism for jump processes and must be constructed from first principles. The dominant eigenmode (eigenvalue and strictly positive eigenvector) of $L_k$ governs asymptotic rare-event statistics and induces a driven process (also called the Doob $h$-transform) that targets rare trajectories consistent with the large deviations.\n\nYour tasks:\n1. Construct the finite state space and the original CTMC generator $L_0$ from the fundamental biological transitions and truncation rules. The generator must have nonnegative off-diagonals and rows that sum to zero.\n2. Construct the tilted generator $L_k$ corresponding to the observable $A_T$ that counts transcription events. Only transcription transitions should be exponentially tilted; all other transitions must remain physically unaltered according to the definition of the exponential tilt for jump observables. Ensure scientific realism by maintaining the proper operator structure required by the Feynman–Kac representation of moment generating functions in CTMCs.\n3. Compute the dominant eigenvalue $\\lambda(k)$ of $L_k$ (the SCGF) and its associated right and left eigenvectors. Normalize the eigenvectors in a scientifically meaningful way and ensure their entries are strictly positive when required by irreducibility.\n4. Design and instantiate the importance sampling scheme using the Doob $h$-transform induced by the dominant right eigenvector of $L_k$. Construct the driven CTMC generator $\\widehat{L}_k$ that asymptotically targets rare high-expression trajectories consistent with large deviation theory.\n5. Compute the stationary distribution of the driven generator $\\widehat{L}_k$ and use it to evaluate the expected transcription event rate under the driven process, denoted $\\mu_k$, expressed in $\\text{min}^{-1}$.\n6. Using the left and right eigenvectors of $L_k$ and the parametric derivative $\\mathrm{d}L_k/\\mathrm{d}k$, compute $\\mathrm{d}\\lambda/\\mathrm{d}k$ from first principles with appropriate normalization. Compare $\\mu_k$ to $\\mathrm{d}\\lambda/\\mathrm{d}k$ and report a relative error defined as $\\left|\\mu_k - \\mathrm{d}\\lambda/\\mathrm{d}k\\right|/\\max\\left(10^{-12},\\left|\\mathrm{d}\\lambda/\\mathrm{d}k\\right|\\right)$.\n7. All physical rates and outputs must be expressed in $\\text{min}^{-1}$. No angles or percentages are involved. All outputs must be numeric floats.\n\nTest Suite:\nImplement your program to run the following test cases, each specified by $(\\alpha,\\beta,r,\\gamma,N_{\\max},k)$ with all rates in $\\text{min}^{-1}$.\n- Case 1 (baseline consistency at zero tilt): $(0.5,0.3,2.0,0.2,20,0.0)$.\n- Case 2 (moderate tilt, moderate bursting): $(0.5,0.3,2.0,0.2,20,0.5)$.\n- Case 3 (rare high-expression tilt with strong degradation): $(0.1,1.0,5.0,1.5,15,1.0)$.\n- Case 4 (boundary-limited capacity with strong degradation): $(0.05,0.2,1.0,3.0,5,0.8)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output the three floats in order: $[\\lambda(k), \\mu_k, \\text{relative error}]$, flattened across the four test cases into a single list. For example, the final output must look like\n\"[$ \\ell_1, \\mu_1, \\epsilon_1, \\ell_2, \\mu_2, \\epsilon_2, \\ell_3, \\mu_3, \\epsilon_3, \\ell_4, \\mu_4, \\epsilon_4 $]\"\nwith numerical values replacing the symbols. All values must be expressed in $\\text{min}^{-1}$ where applicable.",
            "solution": "The user-provided problem is a valid and well-posed scientific question rooted in the computational systems biology of gene expression. It asks for the analysis of a transcriptional bursting model using large deviation theory, which is a standard and powerful framework for studying rare events in stochastic systems. All necessary parameters and model definitions are provided, and the tasks are logically sequential and computationally tractable. The problem is scientifically grounded, objective, and complete. I will now proceed with a full solution.\n\n### Principle-Based Solution Design\n\nThe problem requires a multi-step analysis of a Continuous-Time Markov Chain (CTMC) model for gene expression. The core of the problem lies in applying concepts from large deviation theory to compute rare event statistics.\n\n#### 1. State Space and Generator Matrix ($L_0$)\n\nThe state of the system is given by the pair $(s, n)$, where $s \\in \\{0, 1\\}$ is the promoter state (inactive/active) and $n \\in \\{0, 1, \\dots, N_{\\max}\\}$ is the mRNA copy number. To represent this system mathematically, we first map these state pairs to a single integer index. A convenient mapping is:\n- State $(0, n) \\to i = n$\n- State $(1, n) \\to i = n + (N_{\\max} + 1)$\n\nThe state space thus has a total dimension of $M = 2(N_{\\max} + 1)$. The dynamics are governed by the generator matrix $L_0$, an $M \\times M$ matrix where an off-diagonal element $(L_0)_{ij}$ is the transition rate from state $i$ to state $j$, and a diagonal element $(L_0)_{ii}$ is the negative sum of all outgoing rates from state $i$, ensuring that each row sums to zero.\n\nThe non-zero off-diagonal elements of $L_0$ are determined by the specified biological transitions:\n- Promoter activation: $(0,n) \\to (1,n)$ corresponds to $(L_0)_{n, n+N_{\\max}+1} = \\alpha$.\n- Promoter deactivation: $(1,n) \\to (0,n)$ corresponds to $(L_0)_{n+N_{\\max}+1, n} = \\beta$.\n- Transcription: $(1,n) \\to (1,n+1)$ for $n < N_{\\max}$ corresponds to $(L_0)_{n+N_{\\max}+1, n+1+N_{\\max}+1} = r$.\n- Degradation: $(s,n) \\to (s,n-1)$ for $n \\ge 1$ corresponds to $(L_0)_{n+s(N_{\\max}+1), n-1+s(N_{\\max}+1)} = \\gamma n$.\n\n#### 2. Tilted Operator ($L_k$)\n\nThe large deviation statistics of an additive functional, here the transcription count $A_T$, are governed by the Scaled Cumulant Generating Function (SCGF), $\\lambda(k)$. The SCGF is the dominant eigenvalue of a \"tilted\" operator, $L_k$. According to the Feynman-Kac formalism for jump processes, this operator is constructed by modifying the original generator. For a transition $i \\to j$ with rate $W(i \\to j)$ and an associated jump increment $g(i \\to j)$ for the observable, the action of $L_k$ on a function $f$ is:\n$$ (L_k f)(i) = \\sum_{j \\neq i} W(i \\to j) \\left( e^{k g(i \\to j)} f(j) - f(i) \\right) $$\nThis translates into a matrix $L_k$ with elements:\n- $(L_k)_{ij} = W(i \\to j) e^{k g(i \\to j)}$ for $i \\neq j$.\n- $(L_k)_{ii} = -\\sum_{j \\neq i} W(i \\to j) = (L_0)_{ii}$.\n\nIn our problem, $g(i \\to j) = 1$ only for transcription events and is $0$ otherwise. Consequently, only the off-diagonal elements corresponding to transcription are multiplied by $e^k$, while all other elements, including the diagonals, remain identical to those in $L_0$. Note that $L_k$ is not a generator matrix as its rows do not sum to zero.\n\n#### 3. Dominant Eigenmode and SCGF\n\nThe SCGF, $\\lambda(k)$, is the eigenvalue of $L_k$ with the largest real part. For an irreducible CTMC, the Perron-Frobenius theorem guarantees that this eigenvalue is real and simple, and its corresponding right ($v_k$) and left ($u_k$) eigenvectors can be chosen to have strictly positive components. These are found by solving the eigen-equations:\n$$ L_k v_k = \\lambda(k) v_k \\quad \\text{and} \\quad u_k^T L_k = \\lambda(k) u_k^T $$\nWe will use numerical libraries to solve this eigensystem. A scientifically meaningful normalization for the eigenvectors, required for subsequent calculations, is to enforce $u_k^T v_k = 1$.\n\n#### 4. The Driven Process and Importance Sampling\n\nThe Doob $h$-transform, using the dominant right eigenvector $v_k$ (often called the $h$-function), defines a new \"driven\" CTMC that is conditioned to produce the rare events of interest. The generator of this driven process, $\\widehat{L}_k$, is given by:\n$$ (\\widehat{L}_k)_{ij} = \\frac{(L_k)_{ij} (v_k)_j}{(v_k)_i} - \\delta_{ij} \\lambda(k) $$\nThis construction ensures that $\\widehat{L}_k$ is a valid generator matrix (its rows sum to zero). This driven process is fundamental to importance sampling algorithms for rare event simulation.\n\n#### 5. Stationary Properties of the Driven Process\n\nThe driven process has a unique stationary distribution, $\\pi_k$, which is the normalized left eigenvector of $\\widehat{L}_k$ for the eigenvalue $0$. A more direct way to compute it is via the eigenvectors of $L_k$:\n$$ (\\pi_k)_i = \\frac{(u_k)_i (v_k)_i}{\\sum_j (u_k)_j (v_k)_j} $$\nThe expected transcription rate under this driven process, $\\mu_k$, is the sum of all instantaneous transcription rates weighted by their stationary probabilities:\n$$ \\mu_k = \\sum_{\\text{transcription } i \\to j} (\\pi_k)_i (\\widehat{L}_k)_{ij} $$\n\n#### 6. Consistency Check: Gärtner-Ellis Theorem\n\nA key result in large deviation theory (related to the Gärtner-Ellis theorem) states that the derivative of the SCGF is equal to the expected value of the observable's rate in the driven process:\n$$ \\frac{\\mathrm{d}\\lambda}{\\mathrm{d}k} = \\mu_k $$\nThe derivative can be computed independently using matrix perturbation theory, which gives the formula:\n$$ \\frac{\\mathrm{d}\\lambda}{\\mathrm{d}k} = \\frac{u_k^T (\\mathrm{d}L_k/\\mathrm{d}k) v_k}{u_k^T v_k} $$\nIn our specific construction of $L_k$, the derivative matrix $\\mathrm{d}L_k/\\mathrm{d}k$ has non-zero elements only at the off-diagonal positions corresponding to transcription, where $(\\mathrm{d}L_k/\\mathrm{d}k)_{ij} = r e^k$. Evaluating the expressions for $\\mathrm{d}\\lambda/\\mathrm{d}k$ and $\\mu_k$ algebraically confirms their equality. Computing both numerically provides a powerful validation of the entire theoretical framework and implementation. The relative error between these two computations should be close to machine precision.\n\nThe following Python code implements this complete workflow.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (alpha, beta, r, gamma, N_max, k)\n        (0.5, 0.3, 2.0, 0.2, 20, 0.0),\n        (0.5, 0.3, 2.0, 0.2, 20, 0.5),\n        (0.1, 1.0, 5.0, 1.5, 15, 1.0),\n        (0.05, 0.2, 1.0, 3.0, 5, 0.8),\n    ]\n\n    results = []\n    for params in test_cases:\n        lambda_k, mu_k, rel_error = _calculate_for_case(*params)\n        results.extend([lambda_k, mu_k, rel_error])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _calculate_for_case(alpha, beta, r, gamma, N_max, k):\n    \"\"\"\n    Implements the full large deviation analysis for a single set of parameters.\n\n    Args:\n        alpha (float): Promoter activation rate.\n        beta (float): Promoter deactivation rate.\n        r (float): Transcription rate.\n        gamma (float): mRNA degradation rate constant.\n        N_max (int): Maximum mRNA copy number for truncation.\n        k (float): Tilting parameter.\n\n    Returns:\n        tuple: A tuple containing (lambda(k), mu_k, relative_error).\n    \"\"\"\n    dim = 2 * (N_max + 1)\n    \n    # --- Task 1: Construct the original CTMC generator L_0 ---\n    # State mapping: (0, n) -> n, (1, n) -> n + N_max + 1\n    L0 = np.zeros((dim, dim))\n    \n    # Transitions\n    idx_offset = N_max + 1\n    for n in range(N_max + 1):\n        # Promoter activation: (0,n) -> (1,n)\n        L0[n, n + idx_offset] = alpha\n        \n        # Promoter deactivation: (1,n) -> (0,n)\n        L0[n + idx_offset, n] = beta\n\n    for s in [0, 1]:\n        offset = s * idx_offset\n        for n in range(1, N_max + 1):\n            # Degradation: (s,n) -> (s,n-1)\n            L0[n + offset, n - 1 + offset] = gamma * n\n            \n    # Transcription (active promoter only): (1,n) -> (1,n+1)\n    for n in range(N_max):\n        L0[n + idx_offset, n + 1 + idx_offset] = r\n\n    # Set diagonal elements so rows sum to zero\n    np.fill_diagonal(L0, -L0.sum(axis=1))\n\n    # --- Task 2: Construct the tilted operator L_k ---\n    # As per Feynman-Kac, off-diagonals are tilted, diagonals are from L0.\n    Lk = np.copy(L0)\n    exp_k = np.exp(k)\n    \n    for n in range(N_max):\n        # Tilt only transcription events\n        idx_from = n + idx_offset\n        idx_to = n + 1 + idx_offset\n        Lk[idx_from, idx_to] = r * exp_k\n        \n    # --- Task 3: Compute the dominant eigenmode of L_k ---\n    eigenvalues, left_eigenvectors, right_eigenvectors = linalg.eig(Lk, left=True, right=True)\n    \n    dominant_idx = np.argmax(np.real(eigenvalues))\n    lambda_k = np.real(eigenvalues[dominant_idx])\n    \n    v_k = np.real(right_eigenvectors[:, dominant_idx])\n    u_k = np.real(left_eigenvectors[:, dominant_idx])\n\n    # Ensure eigenvectors are positive (Perron-Frobenius guarantee)\n    if np.sum(v_k)  0: v_k = -v_k\n    if np.sum(u_k)  0: u_k = -u_k\n\n    # Normalize eigenvectors such that u_k^T * v_k = 1\n    dot_product = np.dot(u_k, v_k)\n    u_k /= dot_product\n    \n    # --- Task 6 (Part 1): Compute d(lambda)/dk from perturbation theory ---\n    # d(lambda)/dk = u_k^T * (dLk/dk) * v_k (with u_k^T*v_k=1)\n    # dLk/dk is non-zero only for the off-diagonal transcription elements.\n    sum_term = 0.0\n    for n in range(N_max):\n        idx_from = n + idx_offset\n        idx_to = n + 1 + idx_offset\n        sum_term += u_k[idx_from] * v_k[idx_to]\n    d_lambda_dk = r * exp_k * sum_term\n    \n    # --- Tasks 4  5: Compute mu_k from the driven process ---\n    # Stationary distribution of driven process: pi_k ~ u_k * v_k\n    pi_k = u_k * v_k\n    pi_k /= np.sum(pi_k) \n\n    # Expected transcription rate under driven process\n    mu_k = 0.0\n    for n in range(N_max):\n        idx_from = n + idx_offset\n        idx_to = n + 1 + idx_offset\n        \n        # Rate of transcription jump in driven process\n        rate_driven = Lk[idx_from, idx_to] * v_k[idx_to] / v_k[idx_from]\n        \n        # Contribution to expected rate\n        mu_k += pi_k[idx_from] * rate_driven\n    \n    # --- Task 6 (Part 2): Compute relative error ---\n    # Theory predicts d_lambda_dk = mu_k.\n    denominator = max(1e-12, np.abs(d_lambda_dk))\n    rel_error = np.abs(mu_k - d_lambda_dk) / denominator\n      \n    return lambda_k, mu_k, rel_error\n\nsolve()\n```"
        }
    ]
}