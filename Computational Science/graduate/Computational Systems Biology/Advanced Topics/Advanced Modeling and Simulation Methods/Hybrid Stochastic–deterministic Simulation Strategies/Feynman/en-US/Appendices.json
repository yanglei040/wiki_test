{
    "hands_on_practices": [
        {
            "introduction": "Hybrid simulation strategies often rely on operator splitting techniques, such as the Lie-Trotter method, to decouple and separately solve the stochastic and deterministic parts of a system over a small time step. While powerful, this decoupling is an approximation that introduces a numerical error. This first exercise provides a rigorous, hands-on analytical workout, guiding you through the derivation of this splitting error for a simple linear network . By explicitly calculating the difference between the exact mean and the split-step approximation, you will develop a fundamental understanding of the local accuracy of hybrid methods and the source of their numerical errors.",
            "id": "3319355",
            "problem": "Consider the linear reaction network in computational systems biology\n$$\nA \\xrightarrow{k_{1}} B \\xrightarrow{k_{2}} \\emptyset,\n$$\nwhere $A$ is treated deterministically and $B$ is treated stochastically. Let $t \\geq 0$ be a reference time and denote the initial molecular counts by $A(t)=a$ and $B(t)=b$, with $a \\geq 0$ and $b \\geq 0$. The deterministic species $A$ evolves according to the ordinary differential equation (ODE)\n$$\n\\frac{dA}{dt} = -k_{1} A,\n$$\nand the stochastic species $B$ is modeled as a Continuous-Time Markov Chain (CTMC) governed by the Chemical Master Equation (CME) with time-dependent birth propensity $k_{1} A(t)$ and linear death propensity $k_{2} B(t)$. Assume $k_{1}  0$, $k_{2}  0$, and $k_{1} \\neq k_{2}$.\n\nA hybrid Lie–Trotter splitting step of size $h0$ is defined as follows: first evolve $A$ deterministically for a duration $h$ to obtain $\\tilde{A} = a \\exp(-k_{1} h)$; then, holding $A$ fixed at $\\tilde{A}$ for the duration of the stochastic substep, evolve $B$ stochastically over the same duration $h$ as a linear birth–death process with constant birth rate $k_{1} \\tilde{A}$ and linear death rate $k_{2} B$.\n\nStarting from the fundamental laws and core definitions above (ODE dynamics for $A$ and CME-driven mean dynamics for $B$), derive:\n\n1. The exact mean of $B$ at time $t+h$, denoted $\\mathbb{E}[B(t+h)]$, under the fully coupled hybrid model where $A(t+s) = a \\exp(-k_{1} s)$ drives the birth process of $B$ for $s \\in [0,h]$.\n2. The split-step mean of $B$ at time $t+h$, denoted $\\mathbb{E}_{\\mathrm{split}}[B(t+h)]$, produced by the Lie–Trotter hybrid step described above.\n3. The splitting error in the mean over one step $h$, defined as\n$$\nE(h) = \\mathbb{E}_{\\mathrm{split}}[B(t+h)] - \\mathbb{E}[B(t+h)].\n$$\n\nThen, using a series expansion in $h$ derived from first principles and without invoking any shortcut formulas, verify the predicted local order of accuracy of the Lie–Trotter splitting for the mean of $B$ by explicitly identifying the lowest nonzero power of $h$ in $E(h)$. Your final answer must be the closed-form analytic expression for $E(h)$, simplified as far as possible. No rounding is required, and no physical units should be included in the final expression.",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded in the principles of computational systems biology, well-posed with a complete and consistent set of definitions and constraints, mathematically formalizable, and objective. We may therefore proceed with the solution.\n\nThe problem asks for the derivation of the exact mean evolution of species $B$, the mean evolution under a Lie-Trotter splitting scheme, and the resulting single-step error. The analysis will be performed over a time interval of duration $h$, from a reference time $t$ to $t+h$. Let $s$ be the time elapsed since $t$, so $s \\in [0,h]$. The initial conditions at $s=0$ (time $t$) are $A(0)=a$ and $B(0)=b$.\n\nFirst, we establish the governing equation for the mean of the stochastic species $B$. The number of molecules of $B$, denoted by the random variable $B(t+s)$, changes due to two reactions: a birth reaction $A \\to B$ and a death reaction $B \\to \\emptyset$. The time evolution of the mean $\\mu_B(s) = \\mathbb{E}[B(t+s)]$ is given by the sum of the expected rates of change. The change for the birth reaction is $+1$ with propensity $k_1 A(t+s)$, and for the death reaction is $-1$ with propensity $k_2 B(t+s)$. The exact ODE for the mean is therefore:\n$$\n\\frac{d\\mu_B}{ds} = (+1) \\mathbb{E}[k_1 A(t+s)] + (-1) \\mathbb{E}[k_2 B(t+s)]\n$$\nSince $A$ is a deterministic species, $\\mathbb{E}[k_1 A(t+s)] = k_1 A(t+s)$. Since the death propensity is linear in $B$, the expectation operator commutes with the propensity function, i.e., $\\mathbb{E}[k_2 B(t+s)] = k_2 \\mathbb{E}[B(t+s)] = k_2 \\mu_B(s)$. The initial condition is $\\mu_B(0) = \\mathbb{E}[B(t)] = \\mathbb{E}[b] = b$.\n\nThus, the ODE for the mean of $B$ is:\n$$\n\\frac{d\\mu_B}{ds} = k_1 A(t+s) - k_2 \\mu_B(s)\n$$\n\n**1. Exact Mean of $B$ at time $t+h$**\n\nFor the fully coupled hybrid model, the evolution of $A$ is given by $\\frac{dA}{dt'} = -k_1 A$ with $A(t)=a$. The solution over the interval $[t, t+h]$ is $A(t+s) = a \\exp(-k_1 s)$ for $s \\in [0,h]$. Substituting this into the ODE for $\\mu_B(s)$ yields:\n$$\n\\frac{d\\mu_B}{ds} + k_2 \\mu_B(s) = k_1 a \\exp(-k_1 s)\n$$\nThis is a first-order linear non-homogeneous differential equation. We solve it using an integrating factor $I(s) = \\exp(\\int k_2 ds) = \\exp(k_2 s)$.\n$$\n\\frac{d}{ds} \\left( \\mu_B(s) \\exp(k_2 s) \\right) = k_1 a \\exp(-k_1 s) \\exp(k_2 s) = k_1 a \\exp((k_2 - k_1)s)\n$$\nIntegrating from $s=0$ to $s=h$:\n$$\n\\int_{0}^{h} \\frac{d}{ds'} \\left( \\mu_B(s') \\exp(k_2 s') \\right) ds' = \\int_{0}^{h} k_1 a \\exp((k_2 - k_1)s') ds'\n$$\n$$\n\\left[ \\mu_B(s') \\exp(k_2 s') \\right]_{0}^{h} = k_1 a \\left[ \\frac{\\exp((k_2 - k_1)s')}{k_2 - k_1} \\right]_{0}^{h}\n$$\nThe integration is valid since $k_1 \\neq k_2$.\n$$\n\\mu_B(h) \\exp(k_2 h) - \\mu_B(0) \\exp(0) = \\frac{k_1 a}{k_2 - k_1} \\left( \\exp((k_2 - k_1)h) - 1 \\right)\n$$\nUsing $\\mu_B(0) = b$ and $\\mathbb{E}[B(t+h)] = \\mu_B(h)$:\n$$\n\\mathbb{E}[B(t+h)] \\exp(k_2 h) - b = \\frac{k_1 a}{k_2 - k_1} \\left( \\exp(k_2 h)\\exp(-k_1 h) - 1 \\right)\n$$\nSolving for $\\mathbb{E}[B(t+h)]$:\n$$\n\\mathbb{E}[B(t+h)] = b \\exp(-k_2 h) + \\frac{k_1 a}{k_2 - k_1} \\left( \\exp(-k_1 h) - \\exp(-k_2 h) \\right)\n$$\n\n**2. Split-step Mean of $B$ at time $t+h$**\n\nThe Lie-Trotter splitting method decouples the evolution into two substeps over the interval of duration $h$.\nSubstep 1: Evolve $A$ deterministically for $h$.\nThe value of $A$ at the end of this substep is $\\tilde{A} = A(t) \\exp(-k_1 h) = a \\exp(-k_1 h)$.\n\nSubstep 2: Evolve $B$ stochastically for $h$, but with the birth rate held constant at the value determined by $\\tilde{A}$. The birth propensity is $k_1 \\tilde{A} = k_1 a \\exp(-k_1 h)$. Let $\\mu_{\\mathrm{split}}(s) = \\mathbb{E}_{\\mathrm{split}}[B(t+s)]$. The governing ODE for the mean of $B$ in this substep is:\n$$\n\\frac{d\\mu_{\\mathrm{split}}}{ds} + k_2 \\mu_{\\mathrm{split}}(s) = k_1 a \\exp(-k_1 h)\n$$\nThis is a linear ODE with a constant forcing term. The initial condition is $\\mu_{\\mathrm{split}}(0) = b$. The solution is:\n$$\n\\mu_{\\mathrm{split}}(s) = \\left( b - \\frac{k_1 a \\exp(-k_1 h)}{k_2} \\right) \\exp(-k_2 s) + \\frac{k_1 a \\exp(-k_1 h)}{k_2}\n$$\nWe evaluate this at $s=h$ to find the mean at time $t+h$:\n$$\n\\mathbb{E}_{\\mathrm{split}}[B(t+h)] = \\mu_{\\mathrm{split}}(h) = \\left( b - \\frac{k_1 a \\exp(-k_1 h)}{k_2} \\right) \\exp(-k_2 h) + \\frac{k_1 a \\exp(-k_1 h)}{k_2}\n$$\n$$\n\\mathbb{E}_{\\mathrm{split}}[B(t+h)] = b \\exp(-k_2 h) + \\frac{k_1 a \\exp(-k_1 h)}{k_2} \\left( 1 - \\exp(-k_2 h) \\right)\n$$\n\n**3. Splitting Error $E(h)$ and Order of Accuracy**\n\nThe splitting error in the mean after one step is $E(h) = \\mathbb{E}_{\\mathrm{split}}[B(t+h)] - \\mathbb{E}[B(t+h)]$.\n$$\nE(h) = \\left[ b \\exp(-k_2 h) + \\frac{k_1 a \\exp(-k_1 h)}{k_2} (1 - \\exp(-k_2 h)) \\right] - \\left[ b \\exp(-k_2 h) + \\frac{k_1 a}{k_2 - k_1} (\\exp(-k_1 h) - \\exp(-k_2 h)) \\right]\n$$\nThe terms involving $b$ cancel out.\n$$\nE(h) = k_1 a \\left[ \\frac{\\exp(-k_1 h) - \\exp(-(k_1+k_2)h)}{k_2} - \\frac{\\exp(-k_1 h) - \\exp(-k_2 h)}{k_2 - k_1} \\right]\n$$\nTo simplify, we find a common denominator $k_2(k_2 - k_1)$:\n$$\nE(h) = \\frac{k_1 a}{k_2(k_2-k_1)} \\left[ (k_2-k_1)(\\exp(-k_1 h) - \\exp(-(k_1+k_2)h)) - k_2(\\exp(-k_1 h) - \\exp(-k_2 h)) \\right]\n$$\nExpanding the terms in the square brackets:\n$$\n(k_2-k_1)\\exp(-k_1 h) - (k_2-k_1)\\exp(-(k_1+k_2)h) - k_2\\exp(-k_1 h) + k_2\\exp(-k_2 h)\n$$\n$$\n= -k_1 \\exp(-k_1 h) + k_2 \\exp(-k_2 h) - (k_2-k_1)\\exp(-(k_1+k_2)h)\n$$\nSo the closed-form expression for the error is:\n$$\nE(h) = \\frac{k_1 a}{k_2(k_2 - k_1)} \\left[ k_2 \\exp(-k_2 h) - k_1 \\exp(-k_1 h) - (k_2 - k_1) \\exp(-(k_1+k_2)h) \\right]\n$$\nTo verify the local order of accuracy, we perform a Taylor series expansion of $E(h)$ for small $h$. Let $T(h) = k_2 \\exp(-k_2 h) - k_1 \\exp(-k_1 h) - (k_2 - k_1) \\exp(-(k_1+k_2)h)$.\nWe use the expansion $\\exp(x) = 1 + x + \\frac{x^2}{2} + O(x^3)$.\nThe constant term ($h^0$) of $T(h)$ is:\n$k_2(1) - k_1(1) - (k_2-k_1)(1) = k_2 - k_1 - k_2 + k_1 = 0$.\nThe linear term ($h^1$) of $T(h)$ is:\n$k_2(-k_2 h) - k_1(-k_1 h) - (k_2 - k_1)(-(k_1+k_2)h) = (-k_2^2 + k_1^2 + (k_2 - k_1)(k_1+k_2))h = (-k_2^2 + k_1^2 + k_2^2 - k_1^2)h = 0$.\nSince the $h^0$ and $h^1$ terms are zero, we proceed to the $h^2$ term. The coefficient of $h^2/2$ in $T(h)$ is:\n$k_2(-k_2)^2 - k_1(-k_1)^2 - (k_2 - k_1)(-(k_1+k_2))^2 = k_2^3 - k_1^3 - (k_2-k_1)(k_1+k_2)^2$\n$= k_2^3 - k_1^3 - (k_2-k_1)(k_1^2 + 2k_1 k_2 + k_2^2)$\n$= k_2^3 - k_1^3 - (k_2k_1^2 + 2k_1k_2^2 + k_2^3 - k_1^3 - 2k_1^2 k_2 - k_1k_2^2)$\n$= k_2^3 - k_1^3 - (k_2^3 - k_1^3 - k_1^2k_2 + k_1k_2^2)$\n$= k_1^2k_2 - k_1k_2^2 = k_1k_2(k_1-k_2)$.\nSo, for small $h$, $T(h) \\approx \\frac{h^2}{2} k_1 k_2 (k_1-k_2)$.\nSubstituting this into the expression for $E(h)$:\n$$\nE(h) \\approx \\frac{k_1 a}{k_2(k_2 - k_1)} \\left( \\frac{h^2}{2} k_1 k_2 (k_1-k_2) \\right) = \\frac{k_1 a}{k_2(k_2 - k_1)} \\left( -\\frac{h^2}{2} k_1 k_2 (k_2-k_1) \\right) = -\\frac{1}{2} k_1^2 a h^2\n$$\nThe lowest non-zero power of $h$ in the error expansion is $h^2$. This shows that the local error in the mean is of order $2$, which is characteristic of first-order splitting schemes like the Lie-Trotter method. The problem asks for the closed-form analytic expression for $E(h)$, which was derived above.",
            "answer": "$$\n\\boxed{\\frac{k_1 a}{k_2(k_2 - k_1)} \\left[ k_2 \\exp(-k_2 h) - k_1 \\exp(-k_1 h) - (k_2 - k_1) \\exp(-(k_1+k_2)h) \\right]}\n$$"
        },
        {
            "introduction": "The power of hybrid methods comes from intelligently partitioning a system to capture essential stochastic phenomena while efficiently handling more predictable dynamics. The genetic toggle switch is a cornerstone model in systems biology where bistability arises from the stochastic binding and unbinding of a few repressor molecules to single promoter sites. In this practical coding exercise, you will implement a hybrid simulator for this benchmark system, treating the low-copy-number promoter states stochastically while modeling the more abundant mRNA and protein species with deterministic equations . This practice will give you direct experience in designing a simulation that preserves critical, noise-driven biological behavior that would be missed by a purely deterministic model, yet runs much faster than a full stochastic simulation.",
            "id": "3319361",
            "problem": "You are tasked with designing and implementing a hybrid simulation algorithm for a benchmark genetic toggle-switch network in computational systems biology that uses a combination of stochastic and deterministic methods to preserve bistability while improving computational performance. The network consists of two genes, denoted by $A$ and $B$, that mutually repress each other's transcription via binding to promoter sites.\n\nThe species are as follows:\n- Promoter states for gene $A$: $P_A^{\\mathrm{free}}$ and $P_A^{\\mathrm{bound}}$.\n- Promoter states for gene $B$: $P_B^{\\mathrm{free}}$ and $P_B^{\\mathrm{bound}}$.\n- Messenger RNA: $m_A$ and $m_B$ (molecules).\n- Protein: $A$ and $B$ (molecules).\n\nThe reactions (following the law of mass action) are:\n- Promoter binding and unbinding (stochastic):\n  - $B + P_A^{\\mathrm{free}} \\xrightarrow{k_{\\mathrm{on},A}} P_A^{\\mathrm{bound}}$,\n  - $P_A^{\\mathrm{bound}} \\xrightarrow{k_{\\mathrm{off},A}} B + P_A^{\\mathrm{free}}$,\n  - $A + P_B^{\\mathrm{free}} \\xrightarrow{k_{\\mathrm{on},B}} P_B^{\\mathrm{bound}}$,\n  - $P_B^{\\mathrm{bound}} \\xrightarrow{k_{\\mathrm{off},B}} A + P_B^{\\mathrm{free}}$.\n- Transcription (deterministic), dependent on promoter occupancy:\n  - If $P_A^{\\mathrm{free}}$, transcription rate $r_A = \\alpha_A$; if $P_A^{\\mathrm{bound}}$, transcription rate $r_A = \\ell_A$ (leak).\n  - If $P_B^{\\mathrm{free}}$, transcription rate $r_B = \\alpha_B$; if $P_B^{\\mathrm{bound}}$, transcription rate $r_B = \\ell_B$ (leak).\n- Translation and degradation (deterministic):\n  - $m_A \\xrightarrow{\\beta_A} A$,\n  - $m_B \\xrightarrow{\\beta_B} B$,\n  - Degradation $m_A \\xrightarrow{\\delta_{m,A}} \\varnothing$, $m_B \\xrightarrow{\\delta_{m,B}} \\varnothing$, $A \\xrightarrow{\\delta_{p,A}} \\varnothing$, $B \\xrightarrow{\\delta_{p,B}} \\varnothing$.\n\nYou must partition the reactions such that promoter binding and unbinding are simulated stochastically, while transcription, translation, and degradation are simulated deterministically. The deterministic part should be integrated using a fixed-step explicit method, and the stochastic part should be simulated using a discrete-time approximation of an inhomogeneous Poisson process based on instantaneous propensities. Specifically, during each time step of size $\\Delta t$:\n- For $P_A$:\n  - If $P_A^{\\mathrm{free}}$, the binding propensity is $a_{\\mathrm{bind},A}(t) = k_{\\mathrm{on},A} \\, B(t)$ and the binding probability over $\\Delta t$ is $p_{\\mathrm{bind},A} = 1 - e^{-a_{\\mathrm{bind},A}(t)\\,\\Delta t}$.\n  - If $P_A^{\\mathrm{bound}}$, the unbinding propensity is $a_{\\mathrm{unbind},A} = k_{\\mathrm{off},A}$ and the unbinding probability over $\\Delta t$ is $p_{\\mathrm{unbind},A} = 1 - e^{-a_{\\mathrm{unbind},A}\\,\\Delta t}$.\n- For $P_B$:\n  - If $P_B^{\\mathrm{free}}$, the binding propensity is $a_{\\mathrm{bind},B}(t) = k_{\\mathrm{on},B} \\, A(t)$ with probability $p_{\\mathrm{bind},B} = 1 - e^{-a_{\\mathrm{bind},B}(t)\\,\\Delta t}$.\n  - If $P_B^{\\mathrm{bound}}$, the unbinding propensity is $a_{\\mathrm{unbind},B} = k_{\\mathrm{off},B}$ with probability $p_{\\mathrm{unbind},B} = 1 - e^{-a_{\\mathrm{unbind},B}\\,\\Delta t}$.\n\nThe deterministic updates for $m_A$, $m_B$, $A$, and $B$ must use explicit Euler integration:\n$$\nm_A(t+\\Delta t) = m_A(t) + \\Delta t \\left(r_A(t) - \\delta_{m,A} \\, m_A(t)\\right), \\quad\nA(t+\\Delta t) = A(t) + \\Delta t \\left(\\beta_A \\, m_A(t) - \\delta_{p,A} \\, A(t)\\right),\n$$\n$$\nm_B(t+\\Delta t) = m_B(t) + \\Delta t \\left(r_B(t) - \\delta_{m,B} \\, m_B(t)\\right), \\quad\nB(t+\\Delta t) = B(t) + \\Delta t \\left(\\beta_B \\, m_B(t) - \\delta_{p,B} \\, B(t)\\right).\n$$\nClamp $m_A$, $m_B$, $A$, and $B$ to be nonnegative after each update.\n\nScientific basis and constraints for your design:\n- The hybrid scheme is a piecewise deterministic Markov process (PDMP), derived by partitioning the Chemical Master Equation (CME) into a stochastic subsystem for discrete promoter states and a deterministic subsystem for large-copy-number species under the reaction-rate approximation.\n- To preserve bistability, stochasticity must be retained in the promoter-binding dynamics, which mediate noise-driven switching between attractor states.\n- Deterministic integration of $m_A$, $m_B$, $A$, and $B$ improves performance and is justified when their copy numbers are moderate to large.\n\nInitial conditions for all simulations:\n- At time $t=0$, set $m_A(0) = 0$, $m_B(0) = 0$, $A(0) = 0$, $B(0) = 0$ (all in molecules), and $P_A^{\\mathrm{free}}$, $P_B^{\\mathrm{free}}$.\n- Time step is $\\Delta t = 1\\,\\mathrm{s}$.\n- Total simulation horizon is $T = 2000\\,\\mathrm{s}$.\n- For each parameter set, run $N = 100$ independent replicate simulations to form the empirical distribution of the final protein difference $D = A(T) - B(T)$, recorded in molecules.\n\nYour program must estimate the number of modes in the empirical distribution of $D$ by:\n- Computing a histogram using the Freedman–Diaconis rule for bin width, smoothing the counts with a short symmetric kernel, and counting local maxima above a fraction of the global maximum.\n\nDesign the following test suite of parameter sets (all rates in $\\mathrm{s^{-1}}$, and $k_{\\mathrm{on}}$ values are per molecule per second so that $k_{\\mathrm{on}} \\times$ concentration yields $\\mathrm{s^{-1}}$):\n1. Symmetric, bistable benchmark (happy path):\n   - $\\alpha_A = \\alpha_B = 5$, $\\ell_A = \\ell_B = 0.02$, $\\beta_A = \\beta_B = 0.5$,\n   - $\\delta_{m,A} = \\delta_{m,B} = 0.1$, $\\delta_{p,A} = \\delta_{p,B} = 0.005$,\n   - $k_{\\mathrm{on},A} = k_{\\mathrm{on},B} = 2\\times 10^{-4}$, $k_{\\mathrm{off},A} = k_{\\mathrm{off},B} = 5\\times 10^{-4}$.\n   Expected behavior: two well-separated modes in $D$ due to mutually exclusive promoter occupancy.\n2. Weakened repression (boundary condition approaching unimodality):\n   - $\\alpha_A = \\alpha_B = 5$, $\\ell_A = \\ell_B = 0.02$, $\\beta_A = \\beta_B = 0.5$,\n   - $\\delta_{m,A} = \\delta_{m,B} = 0.1$, $\\delta_{p,A} = \\delta_{p,B} = 0.005$,\n   - $k_{\\mathrm{on},A} = k_{\\mathrm{on},B} = 1\\times 10^{-4}$, $k_{\\mathrm{off},A} = k_{\\mathrm{off},B} = 2\\times 10^{-2}$.\n   Expected behavior: frequent unbinding leads to frequent switching and a single broad mode around $D \\approx 0$.\n3. Strong repression and persistence (edge case with highly stable modes):\n   - $\\alpha_A = \\alpha_B = 5$, $\\ell_A = \\ell_B = 0.02$, $\\beta_A = \\beta_B = 0.5$,\n   - $\\delta_{m,A} = \\delta_{m,B} = 0.1$, $\\delta_{p,A} = \\delta_{p,B} = 0.005$,\n   - $k_{\\mathrm{on},A} = k_{\\mathrm{on},B} = 4\\times 10^{-4}$, $k_{\\mathrm{off},A} = k_{\\mathrm{off},B} = 2\\times 10^{-4}$.\n   Expected behavior: two modes with larger separation and longer residence times.\n\nUnits:\n- Time must be in $\\mathrm{s}$.\n- Molecular counts are in molecules (dimensionless counts).\n\nFinal output specification:\n- For each parameter set, compute the integer number of modes detected in the empirical distribution of $D$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For instance, if the three cases have $2$, $1$, and $2$ modes respectively, the output must be exactly formatted as $[2,1,2]$.",
            "solution": "The problem requires the design and implementation of a hybrid stochastic–deterministic simulation algorithm for a genetic toggle-switch network. The problem is scientifically sound, well-posed, and provides sufficient detail to construct a unique and meaningful solution. The model is a standard representation of a genetic toggle switch, and the proposed hybrid simulation strategy, a form of a Piecewise Deterministic Markov Process (PDMP), is an established method in computational systems biology. The parameters and initial conditions are fully specified. The minor ambiguity in the mode-counting procedure will be resolved by making standard, explicit assumptions as detailed below.\n\nThe core of the problem is to simulate a system where some events (promoter binding/unbinding) are rare and fundamentally stochastic, driving system-level state switching (bistability), while other processes (transcription, translation, degradation) involve larger numbers of molecules and can be approximated deterministically for computational efficiency.\n\nThe system state at any time $t$ is described by the tuple $(m_A(t), m_B(t), A(t), B(t), P_A(t), P_B(t))$, where $m_A, m_B, A, B$ are the molecular counts of mRNA and proteins, and $P_A, P_B$ represent the discrete states of the promoters (free or bound). We will represent the free state as $0$ and the bound state as $1$.\n\nThe simulation proceeds in discrete time steps of size $\\Delta t = 1\\,\\mathrm{s}$ for a total duration of $T = 2000\\,\\mathrm{s}$. At each step, from time $t$ to $t+\\Delta t$, we update the system state according to the partitioned dynamics.\n\nFirst, we address the stochastic update of the promoter states, $P_A$ and $P_B$. The transition between free and bound states is modeled as an inhomogeneous Poisson process, approximated over the discrete time interval $\\Delta t$. The probability of a state change depends on the current state of the system.\n\n- For promoter $A$:\n  - If it is free at time $t$ ($P_A(t)=0$), it can be bound by a molecule of protein $B$. The propensity for this reaction is $a_{\\mathrm{bind},A}(t) = k_{\\mathrm{on},A} B(t)$. The probability of this event occurring in the interval $[t, t+\\Delta t]$ is $p_{\\mathrm{bind},A} = 1 - \\exp(-a_{\\mathrm{bind},A}(t)\\Delta t)$.\n  - If it is bound at time $t$ ($P_A(t)=1$), it can unbind. The propensity for this is constant: $a_{\\mathrm{unbind},A} = k_{\\mathrm{off},A}$. The probability of unbinding is $p_{\\mathrm{unbind},A} = 1 - \\exp(-a_{\\mathrm{unbind},A}\\Delta t)$.\n- A symmetric set of rules applies to promoter $B$, with its state transitions depending on the concentration of protein $A$.\n\nSecond, we perform the deterministic update of the continuous-valued species (mRNA and protein molecule counts) using the explicit Euler method. The problem specifies that the rates $r_A(t)$ and $r_B(t)$ for the Euler step are determined by the promoter states at the beginning of the interval, time $t$.\n\n- The transcription rates are:\n  - $r_A(t) = \\alpha_A$ if $P_A(t)=0$ (free), and $r_A(t) = \\ell_A$ if $P_A(t)=1$ (bound).\n  - $r_B(t) = \\alpha_B$ if $P_B(t)=0$ (free), and $r_B(t) = \\ell_B$ if $P_B(t)=1$ (bound).\n- The Euler-discretized ordinary differential equations are:\n$$\nm_A(t+\\Delta t) = m_A(t) + \\Delta t \\left(r_A(t) - \\delta_{m,A} \\, m_A(t)\\right)\n$$\n$$\nA(t+\\Delta t) = A(t) + \\Delta t \\left(\\beta_A \\, m_A(t) - \\delta_{p,A} \\, A(t)\\right)\n$$\nAnd similarly for $m_B$ and $B$. After each update, the molecular counts are clamped to be non-negative, ensuring physical realism.\n\nThe overall algorithm for a single simulation trajectory is as follows:\n1. Initialize the state at $t=0$: $m_A(0)=0$, $m_B(0)=0$, $A(0)=0$, $B(0)=0$, and promoters $P_A(0)=0, P_B(0)=0$ (free).\n2. For each time step $i$ from $0$ to $(T/\\Delta t) - 1$, with $t_i = i \\Delta t$:\n    a. Determine transcription rates $r_A(t_i)$ and $r_B(t_i)$ based on $P_A(t_i)$ and $P_B(t_i)$.\n    b. Calculate the new molecular counts $m_A(t_{i+1}), A(t_{i+1}), m_B(t_{i+1}), B(t_{i+1})$ using the explicit Euler formulae and the values at $t_i$. Enforce non-negativity.\n    c. Calculate the transition probabilities for the promoters based on the state at $t_i$.\n    d. Generate a random number for each promoter to decide if its state flips, determining $P_A(t_{i+1})$ and $P_B(t_{i+1})$.\n3. After the loop completes, record the final protein difference $D = A(T) - B(T)$.\n\nThis process is repeated $N=100$ times for each of the three parameter sets, yielding an empirical distribution of $D$ for each case.\n\nFinally, we analyze this distribution to count its modes. The problem outlines a procedure which we specify completely as follows:\n1.  **Binning**: A histogram of the $N=100$ values of $D$ is computed. The bin width $h$ is determined by the Freedman-Diaconis rule: $h = 2 \\frac{\\mathrm{IQR}(D)}{N^{1/3}}$, where $\\mathrm{IQR}$ is the interquartile range of the data.\n2.  **Smoothing**: The histogram counts are smoothed to reduce noise. We will use a 3-point symmetric triangular kernel $[0.25, 0.5, 0.25]$ applied via convolution.\n3.  **Peak Detection**: Local maxima in the smoothed histogram are identified. A point is a local maximum if its value is strictly greater than its two immediate neighbors.\n4.  **Thresholding**: To filter out minor fluctuations, only local maxima with a height greater than $10\\%$ of the global maximum height in the smoothed histogram are counted. This threshold is a reasonable choice for distinguishing significant modes from noise.\n\nThe final output is the number of modes detected for each of the three parameter sets.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the hybrid simulation for the three test cases\n    and print the detected number of modes for each.\n    \"\"\"\n\n    # Define the three test cases as dictionaries of parameters.\n    # Base parameters common to all cases\n    base_params = {\n        'alpha_A': 5.0, 'alpha_B': 5.0, 'ell_A': 0.02, 'ell_B': 0.02,\n        'beta_A': 0.5, 'beta_B': 0.5, 'delta_m_A': 0.1, 'delta_m_B': 0.1,\n        'delta_p_A': 0.005, 'delta_p_B': 0.005,\n    }\n\n    test_cases = [\n        # Case 1: Symmetric, bistable benchmark\n        {**base_params, 'k_on_A': 2e-4, 'k_on_B': 2e-4, 'k_off_A': 5e-4, 'k_off_B': 5e-4},\n        # Case 2: Weakened repression (unimodal)\n        {**base_params, 'k_on_A': 1e-4, 'k_on_B': 1e-4, 'k_off_A': 2e-2, 'k_off_B': 2e-2},\n        # Case 3: Strong repression (highly stable modes)\n        {**base_params, 'k_on_A': 4e-4, 'k_on_B': 4e-4, 'k_off_A': 2e-4, 'k_off_B': 2e-4},\n    ]\n\n    # Simulation constants\n    T = 2000.0\n    DT = 1.0\n    N_REPLICATES = 100\n    \n    # Mode counting parameters\n    MODE_THRESHOLD_FRACTION = 0.1\n    SMOOTHING_KERNEL = np.array([0.25, 0.5, 0.25])\n\n    rng = np.random.default_rng(seed=42) # for reproducible results\n\n    results = []\n    for params in test_cases:\n        final_diffs = []\n        for _ in range(N_REPLICATES):\n            d = run_simulation(params, T, DT, rng)\n            final_diffs.append(d)\n        \n        n_modes = count_modes(\n            np.array(final_diffs), \n            SMOOTHING_KERNEL, \n            MODE_THRESHOLD_FRACTION\n        )\n        results.append(n_modes)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(params, T, dt, rng):\n    \"\"\"\n    Runs a single trajectory of the hybrid simulation.\n    \n    Args:\n        params (dict): Dictionary of model parameters.\n        T (float): Total simulation time.\n        dt (float): Time step.\n        rng (np.random.Generator): Random number generator instance.\n\n    Returns:\n        float: The final difference D = A(T) - B(T).\n    \"\"\"\n    # Initial conditions\n    m_a, m_b = 0.0, 0.0\n    prot_a, prot_b = 0.0, 0.0\n    p_a_free, p_b_free = 1, 1 # 1 for free, 0 for bound\n\n    num_steps = int(T / dt)\n\n    for _ in range(num_steps):\n        # Store current state for calculations within this time step\n        m_a_t, m_b_t = m_a, m_b\n        prot_a_t, prot_b_t = prot_a, prot_b\n        p_a_free_t, p_b_free_t = p_a_free, p_b_free\n\n        # --- Stochastic update of promoter states ---\n        # Based on state at time t\n        \n        # Promoter A\n        if p_a_free_t == 1: # free -> bound?\n            propensity = params['k_on_A'] * prot_b_t\n            prob_bind = 1.0 - np.exp(-propensity * dt)\n            if rng.random()  prob_bind:\n                p_a_free = 0\n        else: # bound -> free?\n            propensity = params['k_off_A']\n            prob_unbind = 1.0 - np.exp(-propensity * dt)\n            if rng.random()  prob_unbind:\n                p_a_free = 1\n        \n        # Promoter B\n        if p_b_free_t == 1: # free -> bound?\n            propensity = params['k_on_B'] * prot_a_t\n            prob_bind = 1.0 - np.exp(-propensity * dt)\n            if rng.random()  prob_bind:\n                p_b_free = 0\n        else: # bound -> free? \n            propensity = params['k_off_B']\n            prob_unbind = 1.0 - np.exp(-propensity * dt)\n            if rng.random()  prob_unbind:\n                p_b_free = 1\n\n        # --- Deterministic update of mRNA and proteins ---\n        # Based on state at time t\n        r_a = params['alpha_A'] if p_a_free_t == 1 else params['ell_A']\n        r_b = params['alpha_B'] if p_b_free_t == 1 else params['ell_B']\n\n        # Update mRNA\n        m_a = m_a_t + dt * (r_a - params['delta_m_A'] * m_a_t)\n        m_b = m_b_t + dt * (r_b - params['delta_m_B'] * m_b_t)\n        \n        # Update proteins\n        prot_a = prot_a_t + dt * (params['beta_A'] * m_a_t - params['delta_p_A'] * prot_a_t)\n        prot_b = prot_b_t + dt * (params['beta_B'] * m_b_t - params['delta_p_B'] * prot_b_t)\n\n        # Clamp to non-negative\n        m_a = max(0.0, m_a)\n        m_b = max(0.0, m_b)\n        prot_a = max(0.0, prot_a)\n        prot_b = max(0.0, prot_b)\n        \n    return prot_a - prot_b\n\n\ndef count_modes(data, kernel, threshold_frac):\n    \"\"\"\n    Counts the number of modes in a 1D data array using a histogram-based method.\n    \n    Args:\n        data (np.ndarray): Array of data points.\n        kernel (np.ndarray): Smoothing kernel.\n        threshold_frac (float): Fraction of the global max for peak thresholding.\n\n    Returns:\n        int: The number of detected modes.\n    \"\"\"\n    if len(data)  3:\n        return 1\n        \n    # 1. Binning using Freedman-Diaconis rule\n    try:\n        counts, bin_edges = np.histogram(data, bins='fd')\n    except ValueError:\n        # Fallback if 'fd' fails (e.g., zero variance)\n        counts, bin_edges = np.histogram(data, bins=10)\n\n    if len(counts)  3:\n      # Not enough bins to find local maxima with a 3-point kernel\n      return 1 if len(counts) > 0 else 0\n\n    # 2. Smoothing\n    smoothed_counts = np.convolve(counts, kernel, mode='same')\n    \n    # 3. Peak Finding  4. Thresholding\n    global_max = np.max(smoothed_counts)\n    if global_max == 0:\n        return 0\n        \n    threshold = threshold_frac * global_max\n    \n    modes = 0\n    # Iterate from the second to the second-to-last bin to check for local maxima\n    for i in range(1, len(smoothed_counts) - 1):\n        is_local_max = smoothed_counts[i] > smoothed_counts[i-1] and \\\n                       smoothed_counts[i] > smoothed_counts[i+1]\n        \n        if is_local_max and smoothed_counts[i] > threshold:\n            modes += 1\n            \n    # Handle edge case where a single peak might exist at the edge\n    # or the data is monotonic, producing no peaks in the center.\n    if modes == 0 and np.any(smoothed_counts > 0):\n        return 1\n        \n    return modes\n\nsolve()\n```"
        },
        {
            "introduction": "After developing a hybrid algorithm, a critical final step is to verify its accuracy and validate its performance. This final practice moves from implementation to the essential skill of quantitative validation. You will build a hybrid simulator for a linear birth-death process, a system for which we can derive an exact analytical steady-state solution . You will then implement a rigorous statistical framework to compare your simulator's empirical output distribution against the exact solution using the total variation distance, complete with a finite-sample confidence bound. This exercise provides a complete workflow for making a principled, data-driven decision on whether a numerical method is acceptable for a given scientific purpose.",
            "id": "3319370",
            "problem": "Design and implement a program that quantifies the discrepancy between a hybrid stochastic–deterministic simulator and an analytic Chemical Master Equation (CME) steady-state solution for a linear birth–death network, and then decides whether the hybrid simulator is acceptable under a principled criterion. The network under study is the single-species immigration–death process with reactions $\\varnothing \\to X$ at rate $k_{0}$ and $X \\to \\varnothing$ at rate $k_{1} \\, X$. The hybrid simulation strategy is defined as follows: simulate with the Stochastic Simulation Algorithm (SSA) when the copy number $x$ satisfies $x \\le H$, and simulate deterministically via the ordinary differential equation $\\mathrm{d}x/\\mathrm{d}t = k_{0} - k_{1} x$ when $x  H$, switching regimes upon threshold crossings. In the deterministic regime, use the exact analytical flow to propagate $x(t)$ forward in time and permit switching back to the stochastic regime when the flow crosses $H$ downward. Assume a well-mixed volume and unitless molecular counts; time is expressed in seconds.\n\nStarting from fundamental definitions of the CME and steady state for this linear network, derive the analytic stationary distribution suitable for comparison. Define and implement an estimator for the total variation distance between the analytic steady-state distribution $p$ and the empirical distribution $\\hat{q}$ obtained by running the hybrid simulator for many independent replicates, each started at $x(0) = 0$ and run until time $T_{\\mathrm{final}}$. To make the estimator numerically tractable, truncate the state space to $\\{0,1,\\dots,K\\}$ and aggregate all probability mass beyond $K$ into a single tail bin. For a chosen nonnegative integer $K$, the total variation estimator is\n$$\n\\widehat{\\mathrm{TV}} \\;=\\; \\tfrac{1}{2} \\left( \\sum_{k=0}^{K} \\left| p(k) - \\hat{q}(k) \\right| \\;+\\; \\left| 1 - \\sum_{k=0}^{K} p(k) \\;-\\; \\sum_{k=0}^{K} \\hat{q}(k) \\right| \\right).\n$$\nSelect $K$ adaptively as $K = \\lceil \\lambda + L \\sqrt{\\lambda} \\rceil$ with $\\lambda$ the analytic steady-state mean and $L$ a positive constant, and include one aggregated tail bin, so the total number of bins is $B = K + 2$. Using concentration of measure for multinomial frequencies and a union bound over $B$ bins, derive a finite-sample margin $\\Delta$ such that, with confidence at least $1 - \\alpha$, the unknown true total variation distance $\\mathrm{TV}(p,\\hat{q})$ is at most $\\widehat{\\mathrm{TV}} + \\Delta$, where\n$$\n\\Delta \\;=\\; \\tfrac{1}{2} \\, B \\, \\varepsilon, \n\\qquad\n\\varepsilon \\;=\\; \\sqrt{ \\dfrac{\\ln \\left( \\dfrac{2B}{\\alpha} \\right)}{2 n} },\n$$\nand $n$ is the number of independent replicates. Formulate an acceptance decision rule: accept the hybrid simulator if $\\widehat{\\mathrm{TV}} + \\Delta \\le \\tau$, where $\\tau$ is a user-specified tolerance.\n\nYour task is to implement a complete program that:\n- Simulates the hybrid process for each parameter set in the test suite below, using $n$ independent replicates, time horizon $T_{\\mathrm{final}}$, threshold $H$, and support multiplier $L$ as specified.\n- Computes the analytic CME steady-state distribution and its mean $\\lambda$ from first principles for this linear network.\n- Constructs the truncated total variation estimator $\\widehat{\\mathrm{TV}}$ on $\\{0,\\dots,K\\}$ plus a tail bin as defined above.\n- Computes the margin $\\Delta$ using the finite-sample bound stated above with confidence level $\\alpha$ and total bins $B = K + 2$.\n- Returns the acceptance decision for each test case as a boolean according to the rule $\\widehat{\\mathrm{TV}} + \\Delta \\le \\tau$.\n\nThe hybrid simulator must implement the following regime switching precisely:\n- If $x \\le H$, use the Stochastic Simulation Algorithm with total hazard $a_{0}(x) = k_{0} + k_{1} x$ and exponential waiting times of mean $1/a_{0}(x)$, and jump $x \\mapsto x + 1$ with probability $k_{0}/a_{0}(x)$, or $x \\mapsto \\max\\{0,x-1\\}$ with probability $k_{1} x / a_{0}(x)$.\n- If $x  H$, propagate deterministically using the exact flow $x(t+\\Delta t) = \\lambda + \\left( x(t) - \\lambda \\right) e^{-k_{1} \\Delta t}$ and compute the exact time to hit $H$ from above when $\\lambda  H$, namely the first $\\Delta t$ such that $x(t+\\Delta t) = H$, then switch to SSA at that time; if $\\lambda \\ge H$, remain in the deterministic regime until $T_{\\mathrm{final}}$.\n- At $T_{\\mathrm{final}}$, round the continuous $x$ to the nearest nonnegative integer to produce a sample for the empirical distribution.\n\nTest suite and required output:\n- Use the following four test cases, each specified by $(k_{0}, k_{1}, H, T_{\\mathrm{final}}, n, L, \\tau, \\alpha)$:\n    - Case $1$: $(5.0, 1.0, 100, 50.0, 600, 8.0, 0.05, 0.01)$.\n    - Case $2$: $(40.0, 1.0, 5, 50.0, 600, 8.0, 0.05, 0.01)$.\n    - Case $3$: $(1.0, 1.0, 5, 50.0, 600, 8.0, 0.05, 0.01)$.\n    - Case $4$: $(5.0, 0.2, 10, 50.0, 600, 8.0, 0.05, 0.01)$.\n- For each case, compute and store a single boolean indicating whether the acceptance criterion is met at confidence level $1 - \\alpha$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases above (e.g., \"[True,False,True,False]\"). No other text should be printed.\n\nAssumptions and constraints:\n- All random sampling must be independent across replicates.\n- Use a fixed random seed for reproducibility.\n- Angles are not involved; no angle unit is required.\n- No physical unit conversion is required beyond the time unit already stated in seconds.",
            "solution": "The problem requires the design and implementation of a computational procedure to validate a hybrid stochastic–deterministic simulator against an exact analytical solution for a fundamental biochemical reaction network. The validation is performed by quantifying the statistical discrepancy between the simulator's output and the analytically known steady-state distribution, and applying a principled decision rule for acceptance. The procedure involves three main components: deriving the analytical solution, implementing the specified hybrid simulation algorithm, and performing a rigorous statistical comparison.\n\n### 1. Analytic Steady-State Solution\n\nThe system is a single-species immigration–death process, described by the reactions:\n$$\n\\varnothing \\xrightarrow{k_0} X \\\\\nX \\xrightarrow{k_1} \\varnothing\n$$\nThe state of the system is the number of molecules of species $X$, denoted by the non-negative integer $x$. The first reaction is an immigration (or birth) process occurring at a constant rate $k_0$. The second is a degradation (or death) process occurring at a rate $k_1 x$, proportional to the number of molecules present.\n\nThe evolution of the probability distribution over the states, $p(k, t) = \\mathrm{Prob}(X(t)=k)$, is governed by the Chemical Master Equation (CME). At steady state, the net flow of probability into any state $k$ is zero, i.e., $\\mathrm{d}p(k, t)/\\mathrm{d}t = 0$. This leads to the balance equation, which equates the rate of probability flow into state $k$ with the rate of flow out of state $k$:\n$$\n\\text{Rate In} = \\text{Rate Out}\n$$\nFor a generic state $k  0$, the system can enter from state $k-1$ (via birth) or state $k+1$ (via death). It can leave by a birth (to state $k+1$) or a death (to state $k-1$). The steady-state balance equation for state $k$ is:\n$$\nk_0 \\, p(k-1) + k_1 (k+1) \\, p(k+1) = (k_0 + k_1 k) \\, p(k)\n$$\nFor the boundary state $k=0$, the equation is:\n$$\nk_1 (1) \\, p(1) = k_0 \\, p(0)\n$$\nThis gives $p(1) = (k_0/k_1) p(0)$. Let us define the parameter $\\lambda = k_0/k_1$. Then $p(1) = \\lambda p(0)$. We can solve the general balance equation recursively. For $k=1$:\n$$\nk_0 p(0) + k_1 (2) p(2) = (k_0 + k_1) p(1)\n$$\nSubstituting $p(1) = (k_0/k_1) p(0)$:\n$$\nk_0 p(0) + 2k_1 p(2) = (k_0 + k_1) (k_0/k_1) p(0) = (k_0^2/k_1 + k_0) p(0)\n$$\n$$\n2k_1 p(2) = (k_0^2/k_1) p(0) \\implies p(2) = \\frac{k_0^2}{2 k_1^2} p(0) = \\frac{\\lambda^2}{2} p(0)\n$$\nBy induction, one can show that the general solution is:\n$$\np(k) = \\frac{\\lambda^k}{k!} p(0)\n$$\nTo find $p(0)$, we use the normalization condition $\\sum_{k=0}^{\\infty} p(k) = 1$:\n$$\n\\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!} p(0) = p(0) \\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!} = p(0) e^{\\lambda} = 1\n$$\nThis implies $p(0) = e^{-\\lambda}$. Therefore, the analytic steady-state distribution is a Poisson distribution with mean $\\lambda$:\n$$\np(k) = \\frac{e^{-\\lambda} \\lambda^k}{k!} \\quad \\text{where} \\quad \\lambda = \\frac{k_0}{k_1}\n$$\n\n### 2. Hybrid Simulation Algorithm\n\nThe simulator combines the exact Stochastic Simulation Algorithm (SSA) with a deterministic approximation based on the system's rate equation. The switch between regimes is governed by a threshold copy number, $H$.\n\n-   **Stochastic Regime ($x \\le H$):** When the copy number $x$ is at or below the threshold $H$, the simulation proceeds using Gillespie's Direct Method (a form of SSA).\n    1.  The total propensity (hazard) of all possible reactions is $a_0(x) = k_0 + k_1 x$.\n    2.  A waiting time $\\Delta t$ until the next reaction is drawn from an exponential distribution with mean $1/a_0(x)$.\n    3.  The time is advanced by $\\Delta t$. If the new time exceeds the final time $T_{\\mathrm{final}}$, the simulation for the replicate terminates.\n    4.  A reaction is chosen based on its relative propensity. A uniform random number $u \\in [0,1)$ is drawn. If $u  k_0/a_0(x)$, a birth occurs ($x \\to x+1$); otherwise, a death occurs ($x \\to x-1$).\n    5.  The integer copy number $x$ is updated, and the logic repeats.\n\n-   **Deterministic Regime ($x  H$):** When a reaction causes the copy number $x$ to exceed $H$, the simulation switches to a deterministic model. The evolution of the mean copy number is described by the ordinary differential equation (ODE) $\\mathrm{d}x/\\mathrm{d}t = k_0 - k_1 x$.\n    1.  The analytical solution to this linear ODE, starting from $x(t_s)$ at switch time $t_s$, is $x(t) = \\lambda + (x(t_s) - \\lambda)e^{-k_1(t-t_s)}$, where $\\lambda = k_0/k_1$ is the deterministic fixed point.\n    2.  The behavior of the trajectory depends on the relationship between the fixed point $\\lambda$ and the threshold $H$:\n        -   If $\\lambda \\ge H$, any trajectory starting with $x  H$ will approach $\\lambda$ from below or above but will never cross back below $H$. The simulation can be fast-forwarded directly to $T_{\\mathrm{final}}$. The final state is $x(T_{\\mathrm{final}}) = \\lambda + (x(t_s) - \\lambda)e^{-k_1(T_{\\mathrm{final}}-t_s)}$.\n        -   If $\\lambda  H$, a trajectory starting with $x  H$ will decay towards $\\lambda$ and will cross $H$. We calculate the exact time $\\Delta t_H$ to reach $H$:\n            $$\n            H = \\lambda + (x(t_s) - \\lambda)e^{-k_1 \\Delta t_H} \\implies \\Delta t_H = \\frac{1}{k_1} \\ln \\left( \\frac{x(t_s) - \\lambda}{H - \\lambda} \\right)\n            $$\n            If $t_s + \\Delta t_H \\ge T_{\\mathrm{final}}$, the simulation ends before or upon reaching $H$. The final state is computed at $T_{\\mathrm{final}}$ using the ODE solution. Otherwise, the time is advanced to $t_s + \\Delta t_H$, the state is set to the integer $x=H$, and the simulation switches back to the stochastic regime.\n\n-   **Final Sample Generation:** Each of the $n$ independent replicates starts at $x(0)=0$ and runs until $t=T_{\\mathrm{final}}$. If a replicate ends in the deterministic regime, its final continuous state $x(T_{\\mathrm{final}})$ is rounded to the nearest non-negative integer. These $n$ integer values constitute the samples for the empirical distribution.\n\n### 3. Statistical Discrepancy Framework\n\nTo compare the empirical distribution $\\hat{q}$ from the simulator with the analytic Poisson distribution $p$, we use the total variation (TV) distance on a truncated state space.\n\n-   **State-Space Truncation:** The infinite state space $\\{0, 1, 2, \\dots \\}$ is truncated to a finite set of $B$ bins for practical computation. The bins are $\\{0\\}, \\{1\\}, \\dots, \\{K\\}$, plus a single aggregated tail bin for all states greater than $K$. The truncation point $K$ is chosen adaptively to cover the bulk of the analytic distribution's mass: $K = \\lceil \\lambda + L \\sqrt{\\lambda} \\rceil$, for a given multiplier $L$. The total number of bins is $B = K + 2$.\n\n-   **Total Variation Estimator ($\\widehat{\\mathrm{TV}}$):** The empirical distribution $\\hat{q}$ is formed by counting the fraction of the $n$ samples that fall into each of the $B$ bins. The estimator for the TV distance is half the $L_1$ distance between the binned probability vectors:\n    $$\n    \\widehat{\\mathrm{TV}} = \\frac{1}{2} \\sum_{i=1}^{B} |\\hat{q}_i - p_i|\n    $$\n    where $p_i$ and $\\hat{q}_i$ are the probabilities of the $i$-th bin under the analytic and empirical distributions, respectively. This corresponds exactly to the formula provided in the problem statement.\n\n-   **Finite-Sample Confidence Bound:** The estimator $\\widehat{\\mathrm{TV}}$ is computed from a finite number of samples $n$ and is itself a random variable. To make a robust decision, we must account for this sampling error. We construct a one-sided confidence interval for the true (unknown) TV distance between the analytic distribution $p$ and the true underlying distribution of the hybrid simulator, which we call $q_{true}$. With confidence at least $1-\\alpha$, this distance is bounded by $\\mathrm{TV}(p, q_{true}) \\le \\widehat{\\mathrm{TV}} + \\Delta$. The margin of error, $\\Delta$, accounts for the statistical uncertainty in $\\hat{q}$. It is derived using Hoeffding's inequality for multinomial frequencies combined with a union bound over the $B$ bins. This yields:\n    $$\n    \\Delta = \\frac{1}{2} B \\varepsilon, \\quad \\text{where} \\quad \\varepsilon = \\sqrt{ \\frac{\\ln (2B/\\alpha)}{2n} }\n    $$\n\n### 4. Acceptance Criterion\n\nThe hybrid simulator is deemed an acceptable approximation of the true stochastic process if its worst-case discrepancy from the analytic solution is tolerably small. The decision rule is:\n$$\n\\text{Accept if } \\widehat{\\mathrm{TV}} + \\Delta \\le \\tau\n$$\nThis means we accept the simulator only if the upper bound of the $(1-\\alpha)$-confidence interval for the true TV distance does not exceed a user-specified tolerance $\\tau$. This provides a statistically principled basis for validating the numerical method. The final implementation will execute this entire procedure for each test case and return a boolean decision.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import poisson\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # A fixed random seed is used for reproducibility as per the problem statement.\n    np.random.seed(42)\n\n    # Test suite: (k0, k1, H, T_final, n, L, tau, alpha)\n    test_cases = [\n        (5.0, 1.0, 100, 50.0, 600, 8.0, 0.05, 0.01),\n        (40.0, 1.0, 5, 50.0, 600, 8.0, 0.05, 0.01),\n        (1.0, 1.0, 5, 50.0, 600, 8.0, 0.05, 0.01),\n        (5.0, 0.2, 10, 50.0, 600, 8.0, 0.05, 0.01),\n    ]\n\n    results = [_run_validation_case(*case) for case in test_cases]\n\n    # Format the output as specified: a single line \"[bool,bool,...]\"\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _run_validation_case(k0, k1, H, T_final, n, L, tau, alpha):\n    \"\"\"\n    Runs the full validation procedure for a single parameter set.\n    \"\"\"\n    # 1. Generate n samples from the hybrid simulator.\n    samples = [_simulate_replicate(k0, k1, H, T_final) for _ in range(n)]\n    \n    # 2. Perform statistical analysis and make an acceptance decision.\n    return _analyze_discrepancy(samples, k0, k1, n, L, tau, alpha)\n\ndef _simulate_replicate(k0, k1, H, T_final):\n    \"\"\"\n    Simulates a single trajectory of the hybrid process from t=0 to t=T_final.\n    \"\"\"\n    t = 0.0\n    x = 0  # State is an integer copy number.\n\n    while t  T_final:\n        if x = H:\n            # Stochastic Simulation Algorithm (SSA) regime\n            propensity = k0 + k1 * x\n            if propensity = 1e-9:  # System is stuck (e.g., x=0, k0=0)\n                t = T_final\n                continue\n            \n            # Time to next event\n            dt = np.random.exponential(1.0 / propensity)\n            \n            if t + dt >= T_final:\n                # Event occurs after T_final, so state does not change\n                t = T_final\n                break\n                \n            t += dt\n            \n            # Choose event\n            if np.random.uniform(0, 1)  k0 / propensity:\n                x += 1  # Birth\n            else:\n                x -= 1  # Death\n            # State x remains an integer for the next loop iteration check\n        else:\n            # Deterministic regime (x > H)\n            lambda_val = k0 / k1\n            t_det_start = t\n            x_det_start = float(x)\n\n            if lambda_val >= H:\n                # Trajectory will not cross back below H. Fast-forward to T_final.\n                x_final_det = lambda_val + (x_det_start - lambda_val) * np.exp(-k1 * (T_final - t_det_start))\n                return int(np.round(x_final_det))\n            else:\n                # Trajectory will decay towards lambda  H and will cross H.\n                # Compute time to hit H. Since x_det_start > H > lambda_val, the log argument is > 1.\n                dt_H = (1.0 / k1) * np.log((x_det_start - lambda_val) / (H - lambda_val))\n                \n                if t_det_start + dt_H >= T_final:\n                    # Does not reach H before simulation ends.\n                    x_final_det = lambda_val + (x_det_start - lambda_val) * np.exp(-k1 * (T_final - t_det_start))\n                    return int(np.round(x_final_det))\n                else:\n                    # Reaches H. Update state and switch back to stochastic.\n                    t = t_det_start + dt_H\n                    x = int(H) # State is now exactly H.\n                    # The loop will continue in the stochastic regime.\n\n    # If the loop completes, the final state is the integer x.\n    return x\n\ndef _analyze_discrepancy(samples, k0, k1, n, L, tau, alpha):\n    \"\"\"\n    Computes discrepancy metrics and returns the acceptance decision.\n    \"\"\"\n    # 1. Define analytic and empirical distributions on a truncated space.\n    lambda_val = k0 / k1\n    \n    # Define truncation K and number of bins B\n    if lambda_val > 0:\n        K = int(np.ceil(lambda_val + L * np.sqrt(lambda_val)))\n    else:\n        K = 0\n    B = K + 2\n\n    # Analytic distribution (p)\n    k_vals = np.arange(0, K + 1)\n    p_analytic_pmf = poisson.pmf(k_vals, lambda_val)\n    p_analytic_tail = poisson.sf(K, lambda_val)\n    p_vec = np.append(p_analytic_pmf, p_analytic_tail)\n\n    # Empirical distribution (q_hat)\n    counts = np.zeros(K + 2, dtype=np.int64)\n    for s in samples:\n        if s = K:\n            counts[s] += 1\n        else:\n            counts[K + 1] += 1  # Tail bin\n    q_hat_vec = counts / n\n\n    # 2. Compute the total variation distance estimator.\n    tv_hat = 0.5 * np.sum(np.abs(p_vec - q_hat_vec))\n    \n    # 3. Compute the finite-sample margin.\n    epsilon = np.sqrt(np.log(2 * B / alpha) / (2 * n))\n    delta = 0.5 * B * epsilon\n    \n    # 4. Apply the acceptance decision rule.\n    return (tv_hat + delta) = tau\n\n# This pattern ensures the code runs when the script is executed.\nif __name__ == '__main__':\n    solve()\n\n```"
        }
    ]
}