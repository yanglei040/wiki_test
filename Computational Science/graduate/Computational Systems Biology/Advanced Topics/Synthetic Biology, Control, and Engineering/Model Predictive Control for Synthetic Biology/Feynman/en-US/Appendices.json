{
    "hands_on_practices": [
        {
            "introduction": "Many synthetic biology systems are described by nonlinear dynamics, yet the powerful framework of linear Model Predictive Control (MPC) requires a linear model. This practice focuses on the essential first step of bridging this gap: linearization. By working through this exercise , you will apply Taylor series expansion to a classic chemostat model, a cornerstone of bioprocess engineering, to derive the linear state-space matrices ($A$ and $B$) that approximate the system's behavior around a specific operating point. This skill is fundamental for applying a vast array of linear control techniques to complex biological systems.",
            "id": "3326409",
            "problem": "You are designing a linear Model Predictive Control (MPC) strategy for a continuous stirred-tank bioreactor (chemostat) hosting a synthetic gene circuit. The linearization must be carried out on the host biomass and substrate sub-dynamics that constrain circuit behavior. Consider the classical chemostat model with Monod kinetics for microbial growth:\n$$\n\\begin{aligned}\n\\frac{d x_1}{dt} &= \\big(\\mu(x_2) - u\\big)\\,x_1, \\\\\n\\frac{d x_2}{dt} &= u\\,(S_{\\mathrm{in}} - x_2) - \\frac{1}{Y}\\,\\mu(x_2)\\,x_1,\n\\end{aligned}\n$$\nwhere $x_1$ is the biomass concentration, $x_2$ is the limiting substrate concentration, $u$ is the dilution rate (the manipulated input), $S_{\\mathrm{in}}$ is the influent substrate concentration, $Y$ is the yield coefficient, and $\\mu(x_2)$ is the specific growth rate given by the Monod relation\n$$\n\\mu(x_2) = \\mu_{\\max}\\,\\frac{x_2}{K_S + x_2}.\n$$\nUse the following physically consistent parameter values: $\\mu_{\\max} = 0.6$ h$^{-1}$, $K_S = 0.1$ g L$^{-1}$, $Y = 0.5$ g g$^{-1}$, $S_{\\mathrm{in}} = 10$ g L$^{-1}$, and a nominal dilution rate $u^{\\star} = 0.3$ h$^{-1}$. Work at the non-washout steady state $(x_1^{\\star}, x_2^{\\star})$ associated with $u^{\\star}$.\n\nTasks:\n1) Compute the positive steady state $(x_1^{\\star}, x_2^{\\star})$ consistent with $u^{\\star}$.\n2) Linearize the dynamics about $(x_1^{\\star}, x_2^{\\star}, u^{\\star})$ to obtain the continuous-time state-space linear model\n$$\n\\delta \\dot{x} = A\\,\\delta x + B\\,\\delta u,\n$$\nand provide the explicit matrices $A$ and $B$ in terms of the given parameters evaluated at the steady state.\n3) Justify the validity of the linear approximation for small deviations using Taylor’s theorem with remainder. In particular, by computing the second derivatives of the right-hand side with respect to the state, show that the neglected remainder satisfies a quadratic bound of the form\n$$\n\\|\\mathcal{R}(\\delta x)\\|_2 \\le \\frac{1}{2}\\,L\\,\\|\\delta x\\|_2^2\n$$\nin a neighborhood of the steady state, and explain how such a bound implies local validity of the linearization for sufficiently small $\\|\\delta x\\|_2$ when $\\delta u = 0$.\n4) Finally, compute the spectral radius $\\rho(A)$ of the linearized matrix $A$ at the given steady state.\n\nAnswer specification: Report only the numerical value of the spectral radius $\\rho(A)$ as the final answer. Express the result in h$^{-1}$ and round your answer to four significant figures. Do not include units in your final boxed answer.",
            "solution": "The problem is evaluated and found to be valid. It is scientifically grounded in standard bioprocess engineering principles (chemostat dynamics with Monod kinetics), well-posed with all necessary parameters provided, and objective in its formulation. The tasks are mathematically formalizable and lead to a unique solution. We proceed with the solution.\n\nThe system of ordinary differential equations for the chemostat is given by:\n$$\n\\begin{aligned}\n\\frac{d x_1}{dt} &= f_1(x_1, x_2, u) = \\big(\\mu(x_2) - u\\big)\\,x_1 \\\\\n\\frac{d x_2}{dt} &= f_2(x_1, x_2, u) = u\\,(S_{\\mathrm{in}} - x_2) - \\frac{1}{Y}\\,\\mu(x_2)\\,x_1\n\\end{aligned}\n$$\nwhere the specific growth rate $\\mu(x_2)$ is given by the Monod equation:\n$$\n\\mu(x_2) = \\mu_{\\max}\\,\\frac{x_2}{K_S + x_2}\n$$\nThe provided parameter values are: $\\mu_{\\max} = 0.6$ h$^{-1}$, $K_S = 0.1$ g L$^{-1}$, $Y = 0.5$ g g$^{-1}$, $S_{\\mathrm{in}} = 10$ g L$^{-1}$. The nominal dilution rate is $u^{\\star} = 0.3$ h$^{-1}$.\n\n**1) Computation of the non-washout steady state $(x_1^{\\star}, x_2^{\\star})$**\nAt steady state, the time derivatives are zero:\n$$\n\\begin{aligned}\n\\frac{d x_1}{dt} &= 0 \\implies \\big(\\mu(x_2^{\\star}) - u^{\\star}\\big)\\,x_1^{\\star} = 0 \\\\\n\\frac{d x_2}{dt} &= 0 \\implies u^{\\star}\\,(S_{\\mathrm{in}} - x_2^{\\star}) - \\frac{1}{Y}\\,\\mu(x_2^{\\star})\\,x_1^{\\star} = 0\n\\end{aligned}\n$$\nFor a non-washout steady state, we must have $x_1^{\\star} > 0$. The first equation then implies:\n$$\n\\mu(x_2^{\\star}) - u^{\\star} = 0 \\implies \\mu(x_2^{\\star}) = u^{\\star}\n$$\nSubstituting the Monod expression and the given parameters:\n$$\n\\mu_{\\max}\\,\\frac{x_2^{\\star}}{K_S + x_2^{\\star}} = u^{\\star} \\implies 0.6\\,\\frac{x_2^{\\star}}{0.1 + x_2^{\\star}} = 0.3\n$$\nSolving for $x_2^{\\star}$:\n$$\n\\frac{x_2^{\\star}}{0.1 + x_2^{\\star}} = \\frac{0.3}{0.6} = 0.5\n$$\n$$\nx_2^{\\star} = 0.5\\,(0.1 + x_2^{\\star}) = 0.05 + 0.5\\,x_2^{\\star}\n$$\n$$\n0.5\\,x_2^{\\star} = 0.05 \\implies x_2^{\\star} = 0.1 \\text{ g L}^{-1}\n$$\nNow, we use the second steady-state equation and substitute $\\mu(x_2^{\\star}) = u^{\\star}$:\n$$\nu^{\\star}\\,(S_{\\mathrm{in}} - x_2^{\\star}) - \\frac{1}{Y}\\,u^{\\star}\\,x_1^{\\star} = 0\n$$\nSince $u^{\\star} = 0.3 \\neq 0$, we can divide by $u^{\\star}$:\n$$\n(S_{\\mathrm{in}} - x_2^{\\star}) - \\frac{1}{Y}\\,x_1^{\\star} = 0 \\implies x_1^{\\star} = Y\\,(S_{\\mathrm{in}} - x_2^{\\star})\n$$\nSubstituting the known values:\n$$\nx_1^{\\star} = 0.5 \\times (10 - 0.1) = 0.5 \\times 9.9 = 4.95 \\text{ g L}^{-1}\n$$\nThe non-washout steady state is $(x_1^{\\star}, x_2^{\\star}) = (4.95, 0.1)$.\n\n**2) Linearization of the dynamics**\nWe linearize the system $\\dot{x} = f(x, u)$ around the steady state $(x^{\\star}, u^{\\star})$, where $x = [x_1, x_2]^T$ and $u$ is the scalar input. The linearized model is $\\delta \\dot{x} = A\\,\\delta x + B\\,\\delta u$, where the matrices $A$ (Jacobian) and $B$ are given by:\n$$\nA = \\frac{\\partial f}{\\partial x}\\bigg|_{\\star} = \\begin{pmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} \\\\ \\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} \\end{pmatrix}\\bigg|_{\\star}, \\quad B = \\frac{\\partial f}{\\partial u}\\bigg|_{\\star} = \\begin{pmatrix} \\frac{\\partial f_1}{\\partial u} \\\\ \\frac{\\partial f_2}{\\partial u} \\end{pmatrix}\\bigg|_{\\star}\n$$\nThe partial derivatives are:\n$\\frac{\\partial f_1}{\\partial x_1} = \\mu(x_2) - u$\n$\\frac{\\partial f_1}{\\partial x_2} = x_1 \\frac{d\\mu}{dx_2}$\n$\\frac{\\partial f_2}{\\partial x_1} = -\\frac{1}{Y}\\mu(x_2)$\n$\\frac{\\partial f_2}{\\partial x_2} = -u - \\frac{1}{Y}x_1\\frac{d\\mu}{dx_2}$\n$\\frac{\\partial f_1}{\\partial u} = -x_1$\n$\\frac{\\partial f_2}{\\partial u} = S_{\\mathrm{in}} - x_2$\n\nThe derivative of the Monod function is $\\frac{d\\mu}{dx_2} = \\frac{\\mu_{\\max} K_S}{(K_S + x_2)^2}$.\nWe evaluate these derivatives at the steady state $(x_1^{\\star}, x_2^{\\star}, u^{\\star}) = (4.95, 0.1, 0.3)$.\nFirst, we compute $\\frac{d\\mu}{dx_2}$ at $x_2^{\\star}=0.1$:\n$$\n\\frac{d\\mu}{dx_2}\\bigg|_{x_2^{\\star}} = \\frac{0.6 \\times 0.1}{(0.1 + 0.1)^2} = \\frac{0.06}{0.2^2} = \\frac{0.06}{0.04} = 1.5 \\text{ h}^{-1} (\\text{g L}^{-1})^{-1}\n$$\nNow we compute the elements of matrix $A$:\n$A_{11} = \\mu(x_2^{\\star}) - u^{\\star} = u^{\\star} - u^{\\star} = 0$\n$A_{12} = x_1^{\\star} \\frac{d\\mu}{dx_2}\\bigg|_{x_2^{\\star}} = 4.95 \\times 1.5 = 7.425$\n$A_{21} = -\\frac{1}{Y}\\mu(x_2^{\\star}) = -\\frac{u^{\\star}}{Y} = -\\frac{0.3}{0.5} = -0.6$\n$A_{22} = -u^{\\star} - \\frac{1}{Y}x_1^{\\star}\\frac{d\\mu}{dx_2}\\bigg|_{x_2^{\\star}} = -u^{\\star} - \\frac{1}{Y}A_{12} = -0.3 - \\frac{1}{0.5}(7.425) = -0.3 - 14.85 = -15.15$\nThe state matrix $A$ is:\n$$\nA = \\begin{pmatrix} 0 & 7.425 \\\\ -0.6 & -15.15 \\end{pmatrix}\n$$\nNow we compute the elements of matrix $B$:\n$B_{1} = -x_1^{\\star} = -4.95$\n$B_{2} = S_{\\mathrm{in}} - x_2^{\\star} = 10 - 0.1 = 9.9$\nThe input matrix $B$ is:\n$$\nB = \\begin{pmatrix} -4.95 \\\\ 9.9 \\end{pmatrix}\n$$\n\n**3) Justification of the linear approximation**\nLet $x = x^{\\star} + \\delta x$. For the autonomous case ($\\delta u = 0$), the dynamics are $\\dot{x} = f(x)$. Taylor's theorem with integral remainder for the vector function $f$ expanded around $x^{\\star}$ is:\n$$\nf(x^{\\star} + \\delta x) = f(x^{\\star}) + \\frac{\\partial f}{\\partial x}\\bigg|_{x^{\\star}}\\delta x + \\mathcal{R}(\\delta x)\n$$\nwhere $\\mathcal{R}(\\delta x) = \\int_0^1 (1-s) H_f(x^{\\star}+s\\delta x)(\\delta x, \\delta x) ds$, with $H_f$ being the tensor of second partial derivatives of $f$. Since $\\dot{x} = \\delta \\dot{x}$ and $f(x^{\\star})=0$, we have $\\delta \\dot{x} = A \\delta x + \\mathcal{R}(\\delta x)$.\nThe validity of the linear approximation $\\delta \\dot{x} \\approx A \\delta x$ depends on the remainder term $\\mathcal{R}(\\delta x)$ being negligible compared to the linear term $A \\delta x$ for small $\\|\\delta x\\|_2$.\nThe components of the remainder term are quadratically bounded if the second partial derivatives of $f$ are bounded in a neighborhood of $x^{\\star}$. We verify this by computing them:\n$\\frac{\\partial^2 f_1}{\\partial x_1^2} = 0$, $\\frac{\\partial^2 f_2}{\\partial x_1^2} = 0$\n$\\frac{\\partial^2 f_1}{\\partial x_1 \\partial x_2} = \\frac{d\\mu}{dx_2} = \\frac{\\mu_{\\max} K_S}{(K_S + x_2)^2}$\n$\\frac{\\partial^2 f_2}{\\partial x_1 \\partial x_2} = -\\frac{1}{Y}\\frac{d\\mu}{dx_2} = -\\frac{\\mu_{\\max} K_S}{Y(K_S + x_2)^2}$\n$\\frac{d^2\\mu}{dx_2^2} = \\frac{-2 \\mu_{\\max} K_S}{(K_S + x_2)^3}$\n$\\frac{\\partial^2 f_1}{\\partial x_2^2} = x_1 \\frac{d^2\\mu}{dx_2^2} = \\frac{-2 x_1 \\mu_{\\max} K_S}{(K_S + x_2)^3}$\n$\\frac{\\partial^2 f_2}{\\partial x_2^2} = -\\frac{1}{Y}x_1 \\frac{d^2\\mu}{dx_2^2} = \\frac{2 x_1 \\mu_{\\max} K_S}{Y(K_S + x_2)^3}$\nSince $K_S > 0$ and we consider a neighborhood of the positive steady state where $x_1 > 0$ and $x_2 > 0$, all denominators are non-zero. The second derivatives are continuous, rational functions of $x_1$ and $x_2$. Thus, in any compact (closed and bounded) neighborhood of $x^{\\star}$, they are bounded. This boundedness guarantees the existence of a constant $L > 0$ such that the remainder as a whole satisfies $\\|\\mathcal{R}(\\delta x)\\|_2 \\le \\frac{1}{2} L \\|\\delta x\\|_2^2$.\nThe linear approximation is valid for small $\\|\\delta x\\|_2$ because the error, which is of order $O(\\|\\delta x\\|_2^2)$, becomes negligible relative to the linear term, which is of order $O(\\|\\delta x\\|_2)$. Specifically, the ratio of the norms $\\frac{\\|\\mathcal{R}(\\delta x)\\|_2}{\\|A \\delta x\\|_2} \\le \\frac{\\frac{1}{2} L \\|\\delta x\\|_2^2}{\\sigma_{\\min}(A)\\|\\delta x\\|_2} = \\frac{L}{2\\sigma_{\\min}(A)}\\|\\delta x\\|_2$, which tends to $0$ as $\\|\\delta x\\|_2 \\to 0$ (assuming the system is not degenerate, i.e., $\\sigma_{\\min}(A) > 0$). This confirms the local validity of the linearization.\n\n**4) Computation of the spectral radius $\\rho(A)$**\nThe spectral radius is the maximum absolute value of the eigenvalues of $A$. The eigenvalues $\\lambda$ are the roots of the characteristic equation $\\det(A - \\lambda I) = 0$.\n$$\n\\det \\begin{pmatrix} 0-\\lambda & 7.425 \\\\ -0.6 & -15.15-\\lambda \\end{pmatrix} = 0\n$$\n$$\n(-\\lambda)(-15.15-\\lambda) - (7.425)(-0.6) = 0\n$$\n$$\n15.15\\lambda + \\lambda^2 + 4.455 = 0\n$$\n$$\n\\lambda^2 + 15.15\\lambda + 4.455 = 0\n$$\nWe solve this quadratic equation for $\\lambda$:\n$$\n\\lambda = \\frac{-15.15 \\pm \\sqrt{15.15^2 - 4(1)(4.455)}}{2} = \\frac{-15.15 \\pm \\sqrt{229.5225 - 17.82}}{2}\n$$\n$$\n\\lambda = \\frac{-15.15 \\pm \\sqrt{211.7025}}{2} = \\frac{-15.15 \\pm 14.55}{2}\n$$\nThe two eigenvalues are:\n$$\n\\lambda_1 = \\frac{-15.15 + 14.55}{2} = \\frac{-0.6}{2} = -0.3\n$$\n$$\n\\lambda_2 = \\frac{-15.15 - 14.55}{2} = \\frac{-29.7}{2} = -14.85\n$$\nThe eigenvalues are $\\lambda_1 = -0.3$ h$^{-1}$ and $\\lambda_2 = -14.85$ h$^{-1}$. Both are real and negative, indicating that the steady state is a stable node.\nThe spectral radius $\\rho(A)$ is:\n$$\n\\rho(A) = \\max(|\\lambda_1|, |\\lambda_2|) = \\max(|-0.3|, |-14.85|) = \\max(0.3, 14.85) = 14.85\n$$\nThe value $14.85$ is already expressed with four significant figures as required.",
            "answer": "$$\\boxed{14.85}$$"
        },
        {
            "introduction": "After obtaining a state-space model, we must assess its fundamental properties before designing a controller. This practice addresses two critical questions: can the system's state be steered by the inputs (controllability), and can the internal state be inferred from the available measurements (observability)? This exercise  provides a concrete application of these core control theory concepts to a synthetic gene expression module. You will learn to construct and evaluate the rank of controllability and observability matrices, gaining insight into how a system's structure—including the choice of reporters—dictates our ability to control and monitor it.",
            "id": "3326458",
            "problem": "A synthetic gene expression module is operated under Model Predictive Control (MPC) to regulate protein abundance in a microbial chassis. The module is linearized around an operating point to yield a continuous-time linear time-invariant (LTI) model with two states: messenger ribonucleic acid (mRNA) concentration $x_{1}$ and protein concentration $x_{2}$. The single control input $u$ is the inducer level affecting transcription, and the single measured output $y$ is the protein fluorescence. The linearized dynamics and measurement are given by\n$$\n\\dot{x}_{1} = -\\gamma_{m} x_{1} + \\alpha u,\\quad \\dot{x}_{2} = k_{t} x_{1} - \\gamma_{p} x_{2},\\quad y = x_{2},\n$$\nwith parameter values $\\gamma_{m} = 0.24\\,\\text{min}^{-1}$, $\\gamma_{p} = 0.06\\,\\text{min}^{-1}$, $k_{t} = 0.12\\,\\text{min}^{-1}$, and $\\alpha = 0.80\\,\\text{min}^{-1}$.\n\nTo improve assay stability, a reporter is added that binds proportionally to the protein and has its own degradation. This introduces a third state $x_{3}$ (reporter concentration) with dynamics and measurement\n$$\n\\dot{x}_{3} = k_{r} x_{2} - \\gamma_{r} x_{3},\\quad y_{\\text{rep}} = x_{3},\n$$\nwith $k_{r} = 0.50\\,\\text{min}^{-1}$ and $\\gamma_{r} = 0.02\\,\\text{min}^{-1}$. The input $u$ remains the single actuator, and the output is changed to the single reporter fluorescence $y_{\\text{rep}}$.\n\nStarting from the standard definitions of controllability and observability for continuous-time LTI systems, compute:\n- the controllability matrix and observability matrix for the original two-state system, and determine their ranks;\n- the observability matrix for the augmented three-state reporter system, and determine its rank.\n\nDecide whether adding the reporter, while keeping a single measured output (now the reporter), degrades observability relative to the original system. For the final answer, report the result as the row matrix\n$$\\begin{pmatrix} r_{c}^{(2)} & r_{o}^{(2)} & r_{o}^{(3)} & d \\end{pmatrix},$$\nwhere $r_{c}^{(2)}$ is the rank of the two-state controllability matrix, $r_{o}^{(2)}$ is the rank of the two-state observability matrix, $r_{o}^{(3)}$ is the rank of the three-state observability matrix with reporter output, and $d$ equals $1$ if observability is degraded by adding the reporter and $0$ otherwise. Express the final row matrix entries as integers with no units. No rounding is required.",
            "solution": "The problem requires an analysis of the controllability and observability of two related linear time-invariant (LTI) systems derived from a synthetic gene expression module. Let the general form of a continuous-time LTI system be\n$$\n\\dot{\\mathbf{x}}(t) = A\\mathbf{x}(t) + B\\mathbf{u}(t)\n$$\n$$\n\\mathbf{y}(t) = C\\mathbf{x}(t) + D\\mathbf{u}(t)\n$$\nwhere $\\mathbf{x}$ is the state vector of dimension $n$, $\\mathbf{u}$ is the input vector, and $\\mathbf{y}$ is the output vector. For the systems in this problem, the feedthrough matrix $D$ is zero.\n\nThe controllability of the pair $(A, B)$ is determined by the rank of the controllability matrix $\\mathcal{C}$. For a single-input system, this matrix is given by\n$$\n\\mathcal{C} = \\begin{pmatrix} B & AB & A^2B & \\cdots & A^{n-1}B \\end{pmatrix}\n$$\nThe system is fully controllable if $\\text{rank}(\\mathcal{C}) = n$.\n\nThe observability of the pair $(A, C)$ is determined by the rank of the observability matrix $\\mathcal{O}$. For a single-output system, this matrix is given by\n$$\n\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\\\ CA^2 \\\\ \\vdots \\\\ CA^{n-1} \\end{pmatrix}\n$$\nThe system is fully observable if $\\text{rank}(\\mathcal{O}) = n$.\n\nFirst, we analyze the original two-state system. The state vector is $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$. The dynamics are given by $\\dot{x}_{1} = -\\gamma_{m} x_{1} + \\alpha u$ and $\\dot{x}_{2} = k_{t} x_{1} - \\gamma_{p} x_{2}$, with the output $y = x_2$.\nThe state-space matrices are:\n$$\nA^{(2)} = \\begin{pmatrix} -\\gamma_m & 0 \\\\ k_t & -\\gamma_p \\end{pmatrix}, \\quad B^{(2)} = \\begin{pmatrix} \\alpha \\\\ 0 \\end{pmatrix}, \\quad C^{(2)} = \\begin{pmatrix} 0 & 1 \\end{pmatrix}\n$$\nSubstituting the given parameter values $\\gamma_{m} = 0.24$, $\\gamma_{p} = 0.06$, $k_{t} = 0.12$, and $\\alpha = 0.80$:\n$$\nA^{(2)} = \\begin{pmatrix} -0.24 & 0 \\\\ 0.12 & -0.06 \\end{pmatrix}, \\quad B^{(2)} = \\begin{pmatrix} 0.80 \\\\ 0 \\end{pmatrix}, \\quad C^{(2)} = \\begin{pmatrix} 0 & 1 \\end{pmatrix}\n$$\nThe dimension of this system is $n=2$.\n\nTo determine controllability, we compute the controllability matrix $\\mathcal{C}^{(2)} = \\begin{pmatrix} B^{(2)} & A^{(2)}B^{(2)} \\end{pmatrix}$.\nFirst, we calculate the product $A^{(2)}B^{(2)}$:\n$$\nA^{(2)}B^{(2)} = \\begin{pmatrix} -0.24 & 0 \\\\ 0.12 & -0.06 \\end{pmatrix} \\begin{pmatrix} 0.80 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} (-0.24)(0.80) \\\\ (0.12)(0.80) \\end{pmatrix} = \\begin{pmatrix} -0.192 \\\\ 0.096 \\end{pmatrix}\n$$\nThe controllability matrix is:\n$$\n\\mathcal{C}^{(2)} = \\begin{pmatrix} 0.80 & -0.192 \\\\ 0 & 0.096 \\end{pmatrix}\n$$\nThe rank of $\\mathcal{C}^{(2)}$ is found by computing its determinant:\n$$\n\\det(\\mathcal{C}^{(2)}) = (0.80)(0.096) - (-0.192)(0) = 0.0768\n$$\nSince $\\det(\\mathcal{C}^{(2)}) \\neq 0$, the matrix is full rank. The rank of the controllability matrix is $r_c^{(2)} = 2$. The system is fully controllable.\n\nNext, to determine observability, we compute the observability matrix $\\mathcal{O}^{(2)} = \\begin{pmatrix} C^{(2)} \\\\ C^{(2)}A^{(2)} \\end{pmatrix}$.\nFirst, we calculate the product $C^{(2)}A^{(2)}$:\n$$\nC^{(2)}A^{(2)} = \\begin{pmatrix} 0 & 1 \\end{pmatrix} \\begin{pmatrix} -0.24 & 0 \\\\ 0.12 & -0.06 \\end{pmatrix} = \\begin{pmatrix} 0.12 & -0.06 \\end{pmatrix}\n$$\nThe observability matrix is:\n$$\n\\mathcal{O}^{(2)} = \\begin{pmatrix} 0 & 1 \\\\ 0.12 & -0.06 \\end{pmatrix}\n$$\nThe rank of $\\mathcal{O}^{(2)}$ is found by computing its determinant:\n$$\n\\det(\\mathcal{O}^{(2)}) = (0)(-0.06) - (1)(0.12) = -0.12\n$$\nSince $\\det(\\mathcal{O}^{(2)}) \\neq 0$, the matrix is full rank. The rank of the observability matrix is $r_o^{(2)} = 2$. The system is fully observable.\n\nNow, we analyze the augmented three-state system with the reporter. The state vector is $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}$. The dynamics are extended with $\\dot{x}_{3} = k_{r} x_{2} - \\gamma_{r} x_{3}$, and the output is changed to $y_{\\text{rep}} = x_3$. The dimension of this system is $n=3$.\nThe new state-space matrices are:\n$$\nA^{(3)} = \\begin{pmatrix} -\\gamma_m & 0 & 0 \\\\ k_t & -\\gamma_p & 0 \\\\ 0 & k_r & -\\gamma_r \\end{pmatrix}, \\quad C^{(3)} = \\begin{pmatrix} 0 & 0 & 1 \\end{pmatrix}\n$$\nSubstituting the new parameter values $k_r = 0.50$ and $\\gamma_r = 0.02$:\n$$\nA^{(3)} = \\begin{pmatrix} -0.24 & 0 & 0 \\\\ 0.12 & -0.06 & 0 \\\\ 0 & 0.50 & -0.02 \\end{pmatrix}, \\quad C^{(3)} = \\begin{pmatrix} 0 & 0 & 1 \\end{pmatrix}\n$$\nWe are asked for the rank of the observability matrix $\\mathcal{O}^{(3)} = \\begin{pmatrix} C^{(3)} \\\\ C^{(3)}A^{(3)} \\\\ C^{(3)}(A^{(3)})^2 \\end{pmatrix}$.\nWe compute the rows of $\\mathcal{O}^{(3)}$:\nThe first row is $C^{(3)} = \\begin{pmatrix} 0 & 0 & 1 \\end{pmatrix}$.\nThe second row is $C^{(3)}A^{(3)}$:\n$$\nC^{(3)}A^{(3)} = \\begin{pmatrix} 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} -0.24 & 0 & 0 \\\\ 0.12 & -0.06 & 0 \\\\ 0 & 0.50 & -0.02 \\end{pmatrix} = \\begin{pmatrix} 0 & 0.50 & -0.02 \\end{pmatrix}\n$$\nThe third row is $C^{(3)}(A^{(3)})^2$. First we compute $(A^{(3)})^2$:\n$$\n(A^{(3)})^2 = \\begin{pmatrix} -0.24 & 0 & 0 \\\\ 0.12 & -0.06 & 0 \\\\ 0 & 0.50 & -0.02 \\end{pmatrix} \\begin{pmatrix} -0.24 & 0 & 0 \\\\ 0.12 & -0.06 & 0 \\\\ 0 & 0.50 & -0.02 \\end{pmatrix} = \\begin{pmatrix} 0.0576 & 0 & 0 \\\\ -0.036 & 0.0036 & 0 \\\\ 0.06 & -0.04 & 0.0004 \\end{pmatrix}\n$$\nThen, we compute $C^{(3)}(A^{(3)})^2$:\n$$\nC^{(3)}(A^{(3)})^2 = \\begin{pmatrix} 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0.0576 & 0 & 0 \\\\ -0.036 & 0.0036 & 0 \\\\ 0.06 & -0.04 & 0.0004 \\end{pmatrix} = \\begin{pmatrix} 0.06 & -0.04 & 0.0004 \\end{pmatrix}\n$$\nThe observability matrix for the three-state system is:\n$$\n\\mathcal{O}^{(3)} = \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 0.50 & -0.02 \\\\ 0.06 & -0.04 & 0.0004 \\end{pmatrix}\n$$\nTo find its rank, we compute the determinant:\n$$\n\\det(\\mathcal{O}^{(3)}) = 0 \\cdot \\det\\begin{pmatrix} 0.50 & -0.02 \\\\ -0.04 & 0.0004 \\end{pmatrix} - 0 \\cdot \\det\\begin{pmatrix} 0 & -0.02 \\\\ 0.06 & 0.0004 \\end{pmatrix} + 1 \\cdot \\det\\begin{pmatrix} 0 & 0.50 \\\\ 0.06 & -0.04 \\end{pmatrix}\n$$\n$$\n\\det(\\mathcal{O}^{(3)}) = 1 \\cdot ((0)(-0.04) - (0.50)(0.06)) = -0.03\n$$\nSince $\\det(\\mathcal{O}^{(3)}) \\neq 0$, the matrix is full rank. The rank of the observability matrix for the three-state system is $r_o^{(3)} = 3$.\n\nFinally, we must decide if observability is degraded. The original two-state system is fully observable since $r_o^{(2)} = 2$, which equals its number of states. The augmented three-state system is also fully observable since $r_o^{(3)} = 3$, which equals its number of states. Since the system remains fully observable after the addition of the reporter and the change in measurement, observability is not degraded in the sense of being lost. Therefore, the degradation indicator $d$ is $0$.\n\nThe required results are: $r_c^{(2)} = 2$, $r_o^{(2)} = 2$, $r_o^{(3)} = 3$, and $d = 0$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 & 2 & 3 & 0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Model Predictive Control is, at its heart, a repeated optimization process. This exercise delves into the mathematical machinery that drives MPC by asking you to formulate the control task as a formal Nonlinear Program (NLP). Starting from a nonlinear model of a common genetic circuit, you will discretize the dynamics and construct the cost function and constraints that define the optimal control problem. By deriving the Karush-Kuhn-Tucker (KKT) conditions , you will uncover the necessary conditions for optimality and gain a deeper appreciation for how an optimal control law is calculated from first principles.",
            "id": "3326415",
            "problem": "Consider a single-gene negative autoregulation circuit where the normalized protein concentration $x(t)$ represses its own production through a Hill function. The protein dynamics are modeled as the ordinary differential equation (ODE)\n$$\n\\frac{dx(t)}{dt} \\;=\\; \\frac{\\alpha}{1 + \\left(\\frac{x(t)}{K}\\right)^{n}} \\;-\\; \\beta\\,x(t) \\;+\\; u(t),\n$$\nwhere $\\alpha>0$ is the maximal synthesis rate, $K>0$ is the dissociation constant, $n \\ge 1$ is the Hill coefficient, $\\beta>0$ is the effective first-order degradation rate, and $u(t)$ is an external actuation input that modulates the synthesis rate. All variables are dimensionless and time is in normalized units. In a Model Predictive Control (MPC) setting, over a single-step prediction horizon of length $N=1$ with sampling time $h>0$, we discretize the ODE with a forward Euler scheme to obtain a discrete-time model suitable for direct multiple shooting. Let the decision variables be the shooting node states $z_0, z_1 \\in \\mathbb{R}$ and the input $u_0 \\in \\mathbb{R}$. The measured initial state $x_{\\mathrm{init}} \\in \\mathbb{R}$ and reference $r \\in \\mathbb{R}$ are given constants. The stage cost and terminal cost are quadratic with positive weights $Q>0$, $R>0$, and $P>0$, respectively.\n\nTasks:\n1. Starting from the ODE and the forward Euler discretization, write the single-interval direct multiple shooting transcription consisting of:\n   - the discrete dynamics constraint connecting $z_0$, $u_0$, and $z_1$, and\n   - the initial condition consistency constraint enforcing $z_0 = x_{\\mathrm{init}}$,\n   together with the cost function\n   $$\n   J(z_0,u_0,z_1) \\;=\\; Q\\,(z_0 - r)^2 \\;+\\; R\\,u_0^2 \\;+\\; P\\,(z_1 - r)^2,\n   $$\n   and with box constraints on the input $0 \\le u_0 \\le u_{\\max}$, where $u_{\\max}>0$.\n2. Form the Lagrangian for this constrained nonlinear program by introducing Lagrange multipliers $\\mu \\in \\mathbb{R}$ for the initial condition constraint, $\\lambda \\in \\mathbb{R}$ for the discrete dynamics constraint, and nonnegative multipliers $\\gamma_{\\ell} \\ge 0$ and $\\gamma_{u} \\ge 0$ for the lower and upper input bounds, respectively.\n3. Derive the Karush-Kuhn-Tucker (KKT) conditions, including primal feasibility, dual feasibility, stationarity, and complementary slackness, in symbolic form.\n4. Assume that at the optimizer the input is strictly interior, i.e., $0 < u_0^{\\star} < u_{\\max}$ so that the inequality constraints are inactive at optimality. Using the KKT system, eliminate the multipliers to obtain an explicit closed-form expression for the optimal input $u_0^{\\star}$ as a function of $x_{\\mathrm{init}}$, $r$, $h$, $P$, $R$, $\\alpha$, $\\beta$, $K$, and $n$. Your final answer must be a single analytic expression. Do not provide any numerical approximations.",
            "solution": "The solution proceeds by following the four tasks outlined in the problem statement.\n\n**Task 1: Direct Multiple Shooting Transcription**\nFirst, we discretize the continuous-time ODE using the forward Euler method with a step size of $h$. The state at time $t_{k+1}$ is approximated from the state at $t_k$ as $x_{k+1} \\approx x_k + h \\cdot \\frac{dx}{dt}\\Big|_{t_k}$.\nIn the single-step ($N=1$) direct multiple shooting framework, we have decision variables for the state at the start and end of the interval, $z_0$ and $z_1$, and for the control input over the interval, $u_0$.\n\nThe discrete-time dynamics constraint connects these variables:\n$$\nz_1 - z_0 - h \\left( \\frac{\\alpha}{1 + \\left(\\frac{z_0}{K}\\right)^{n}} - \\beta z_0 + u_0 \\right) = 0\n$$\nThe initial condition consistency constraint links the first shooting node state $z_0$ to the measured initial state $x_{\\mathrm{init}}$:\n$$\nz_0 - x_{\\mathrm{init}} = 0\n$$\nThe cost function to be minimized is given as:\n$$\nJ(z_0,u_0,z_1) = Q\\,(z_0 - r)^2 + R\\,u_0^2 + P\\,(z_1 - r)^2\n$$\nThe box constraints on the input are written as two inequality constraints:\n$$\n-u_0 \\le 0 \\quad \\text{and} \\quad u_0 - u_{\\max} \\le 0\n$$\nThis completes the formulation of the constrained nonlinear program.\n\n**Task 2: Lagrangian Formulation**\nThe Lagrangian function $\\mathcal{L}$ for this NLP is constructed by adding the cost function and the constraints, each multiplied by its corresponding Lagrange multiplier.\n$$\n\\begin{align*}\n\\mathcal{L}(z_0, u_0, z_1, \\mu, \\lambda, \\gamma_{\\ell}, \\gamma_{u}) = & Q\\,(z_0 - r)^2 + R\\,u_0^2 + P\\,(z_1 - r)^2 \\\\\n& + \\mu(z_0 - x_{\\mathrm{init}}) \\\\\n& + \\lambda \\left[ z_1 - z_0 - h \\left( \\frac{\\alpha}{1 + \\left(\\frac{z_0}{K}\\right)^{n}} - \\beta z_0 + u_0 \\right) \\right] \\\\\n& + \\gamma_{\\ell}(-u_0) + \\gamma_{u}(u_0 - u_{\\max})\n\\end{align*}\n$$\nHere, $\\mu$ and $\\lambda$ are the multipliers for the equality constraints, and $\\gamma_{\\ell}, \\gamma_{u}$ are the multipliers for the inequality constraints, which must be non-negative.\n\n**Task 3: Karush-Kuhn-Tucker (KKT) Conditions**\nThe KKT conditions are necessary conditions for optimality. They are categorized as primal feasibility, dual feasibility, complementary slackness, and stationarity. Let the optimal solution be denoted by $(z_0^{\\star}, u_0^{\\star}, z_1^{\\star})$.\n\n1.  **Primal Feasibility:** The optimal solution must satisfy all constraints.\n    -   $z_0^{\\star} - x_{\\mathrm{init}} = 0$\n    -   $z_1^{\\star} - z_0^{\\star} - h \\left( \\frac{\\alpha}{1 + \\left(\\frac{z_0^{\\star}}{K}\\right)^{n}} - \\beta z_0^{\\star} + u_0^{\\star} \\right) = 0$\n    -   $0 \\le u_0^{\\star} \\le u_{\\max}$\n\n2.  **Dual Feasibility:** The multipliers for the inequality constraints must be non-negative.\n    -   $\\gamma_{\\ell} \\ge 0$\n    -   $\\gamma_{u} \\ge 0$\n\n3.  **Complementary Slackness:** The product of an inequality multiplier and its corresponding constraint value must be zero at the optimum.\n    -   $\\gamma_{\\ell}(-u_0^{\\star}) = 0 \\implies \\gamma_{\\ell}u_0^{\\star} = 0$\n    -   $\\gamma_{u}(u_0^{\\star} - u_{\\max}) = 0$\n\n4.  **Stationarity:** The gradient of the Lagrangian with respect to the primal variables must be zero at the optimum.\n    -   $\\frac{\\partial \\mathcal{L}}{\\partial z_1} = 2P(z_1^{\\star} - r) + \\lambda = 0$\n    -   $\\frac{\\partial \\mathcal{L}}{\\partial u_0} = 2Ru_0^{\\star} - \\lambda h - \\gamma_{\\ell} + \\gamma_{u} = 0$\n    -   $\\frac{\\partial \\mathcal{L}}{\\partial z_0} = 2Q(z_0^{\\star} - r) + \\mu - \\lambda \\left[ 1 + h \\frac{\\partial}{\\partial z_0}\\left( \\frac{\\alpha}{1 + \\left(\\frac{z_0}{K}\\right)^{n}} - \\beta z_0 \\right) \\right]_{z_0=z_0^{\\star}} = 0$\n        Let's evaluate the derivative term:\n        $$\n        \\frac{\\partial}{\\partial z_0}\\left( \\frac{\\alpha}{1 + \\left(\\frac{z_0}{K}\\right)^{n}} - \\beta z_0 \\right) = -\\frac{\\alpha n z_0^{n-1}}{K^n \\left(1 + \\left(\\frac{z_0}{K}\\right)^n\\right)^2} - \\beta\n        $$\n        So the third stationarity condition is:\n        $$\n        2Q(z_0^{\\star} - r) + \\mu - \\lambda \\left[ 1 - h \\left( \\frac{\\alpha n (z_0^{\\star})^{n-1}}{K^n \\left(1 + \\left(\\frac{z_0^{\\star}}{K}\\right)^n\\right)^2} + \\beta \\right) \\right] = 0\n        $$\n\n**Task 4: Derivation of the Optimal Input $u_0^{\\star}$**\nWe are given the assumption that the optimal input $u_0^{\\star}$ is strictly interior to its bounds, i.e., $0 < u_0^{\\star} < u_{\\max}$.\n\nFrom the complementary slackness conditions:\n-   Since $u_0^{\\star} > 0$, we must have $\\gamma_{\\ell} = 0$.\n-   Since $u_0^{\\star} < u_{\\max}$, we have $u_0^{\\star} - u_{\\max} < 0$, so we must have $\\gamma_{u} = 0$.\n\nWith $\\gamma_{\\ell}=0$ and $\\gamma_{u}=0$, the stationarity condition for $u_0$ simplifies to:\n$$\n2Ru_0^{\\star} - \\lambda h = 0 \\implies u_0^{\\star} = \\frac{\\lambda h}{2R}\n$$\nFrom the stationarity condition for $z_1$, we can express $\\lambda$ in terms of $z_1^{\\star}$:\n$$\n2P(z_1^{\\star} - r) + \\lambda = 0 \\implies \\lambda = -2P(z_1^{\\star} - r)\n$$\nSubstituting this expression for $\\lambda$ into the equation for $u_0^{\\star}$:\n$$\nu_0^{\\star} = \\frac{(-2P(z_1^{\\star} - r))h}{2R} = -\\frac{Ph(z_1^{\\star} - r)}{R} = \\frac{Ph(r - z_1^{\\star})}{R}\n$$\nNow we use the primal feasibility conditions to eliminate $z_1^{\\star}$. From the initial condition constraint, $z_0^{\\star} = x_{\\mathrm{init}}$. Substituting this into the dynamics constraint:\n$$\nz_1^{\\star} = x_{\\mathrm{init}} + h \\left( \\frac{\\alpha}{1 + \\left(\\frac{x_{\\mathrm{init}}}{K}\\right)^{n}} - \\beta x_{\\mathrm{init}} + u_0^{\\star} \\right)\n$$\nWe now substitute this expression for $z_1^{\\star}$ into our equation for $u_0^{\\star}$:\n$$\nu_0^{\\star} = \\frac{Ph}{R} \\left( r - \\left[ x_{\\mathrm{init}} + h \\left( \\frac{\\alpha}{1 + \\left(\\frac{x_{\\mathrm{init}}}{K}\\right)^{n}} - \\beta x_{\\mathrm{init}} + u_0^{\\star} \\right) \\right] \\right)\n$$\nThis equation is linear in $u_0^{\\star}$ and can be solved. Let's expand and collect terms involving $u_0^{\\star}$:\n$$\nu_0^{\\star} = \\frac{Ph}{R} \\left( r - x_{\\mathrm{init}} - h \\left( \\frac{\\alpha}{1 + \\left(\\frac{x_{\\mathrm{init}}}{K}\\right)^{n}} - \\beta x_{\\mathrm{init}} \\right) \\right) - \\frac{Ph^2}{R} u_0^{\\star}\n$$\n$$\nu_0^{\\star} + \\frac{Ph^2}{R} u_0^{\\star} = \\frac{Ph}{R} \\left( r - x_{\\mathrm{init}} - h \\left( \\frac{\\alpha}{1 + \\left(\\frac{x_{\\mathrm{init}}}{K}\\right)^{n}} - \\beta x_{\\mathrm{init}} \\right) \\right)\n$$\n$$\nu_0^{\\star} \\left( 1 + \\frac{Ph^2}{R} \\right) = \\frac{Ph}{R} \\left( r - x_{\\mathrm{init}} - h \\left( \\frac{\\alpha}{1 + \\left(\\frac{x_{\\mathrm{init}}}{K}\\right)^{n}} - \\beta x_{\\mathrm{init}} \\right) \\right)\n$$\n$$\nu_0^{\\star} \\left( \\frac{R + Ph^2}{R} \\right) = \\frac{Ph}{R} \\left( r - x_{\\mathrm{init}} - h \\left( \\frac{\\alpha}{1 + \\left(\\frac{x_{\\mathrm{init}}}{K}\\right)^{n}} - \\beta x_{\\mathrm{init}} \\right) \\right)\n$$\nFinally, solving for $u_0^{\\star}$ by multiplying both sides by $\\frac{R}{R+Ph^2}$ yields the explicit closed-form expression:\n$$\nu_0^{\\star} = \\frac{Ph}{R+Ph^2} \\left( r - x_{\\mathrm{init}} - h \\left( \\frac{\\alpha}{1 + \\left(\\frac{x_{\\mathrm{init}}}{K}\\right)^{n}} - \\beta x_{\\mathrm{init}} \\right) \\right)\n$$\nThis expression depends only on the given parameters and initial state, as requested. The stationarity condition with respect to $z_0$ and the multiplier $\\mu$ were not needed for this derivation, as the variable $z_0$ is fixed to $x_{\\mathrm{init}}$ by a hard constraint.",
            "answer": "$$\n\\boxed{\n\\frac{Ph}{R + Ph^2} \\left( r - x_{\\mathrm{init}} - h \\left( \\frac{\\alpha}{1 + \\left(\\frac{x_{\\mathrm{init}}}{K}\\right)^{n}} - \\beta x_{\\mathrm{init}} \\right) \\right)\n}\n$$"
        }
    ]
}