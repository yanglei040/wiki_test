{
    "hands_on_practices": [
        {
            "introduction": "This first practice provides a foundational exercise in applying the observability rank condition. Using a two-species biochemical network with cooperative interactions, you will directly compute the successive Lie derivatives of the output function. This exercise  reinforces the core mathematical techniques and demonstrates how to assess local observability at a critical state, where one species concentration approaches zero.",
            "id": "3334957",
            "problem": "Consider a two-species biochemical regulatory module with cooperative activation, modeled by the nonlinear ordinary differential equations\n$$\n\\dot{x}_1 \\;=\\; \\alpha_1\\,\\frac{x_2^2}{K_1^2 + x_2^2} \\;-\\; \\beta_1\\,x_1, \n\\qquad\n\\dot{x}_2 \\;=\\; \\alpha_2\\,\\frac{x_1^m}{K_2^m + x_1^m} \\;-\\; \\beta_2\\,x_2,\n$$\nwhere $x_1$ and $x_2$ are concentrations, $\\alpha_1, \\alpha_2, \\beta_1, \\beta_2, K_1, K_2$ are strictly positive constants, and $m \\geq 1$ is an integer Hill exponent capturing cooperativity of $x_1$ on the production of $x_2$. Assume that only the first species is measured, with output \n$$\nh(x) \\;=\\; x_1.\n$$\nUse the definition of the Lie derivative of a scalar function $h$ along a vector field $f$, namely $L_f h(x) = \\nabla h(x)\\cdot f(x)$, and its recursion $L_f^{k+1} h(x) = \\nabla \\big(L_f^k h(x)\\big)\\cdot f(x)$ for $k \\geq 0$. Explicitly compute $h(x)$, $L_f h(x)$, and $L_f^2 h(x)$, together with their gradients $\\nabla h(x)$, $\\nabla \\big(L_f h(x)\\big)$, and $\\nabla \\big(L_f^2 h(x)\\big)$. Then, form the observability matrix $\\mathcal{O}(x)$ whose rows are these gradients and evaluate its rank at the state \n$$\nx^\\star \\;=\\; (K_2,\\,0),\n$$\nwhich represents the second species near zero while the first species is at a nonzero baseline. Provide the integer value of the rank of $\\mathcal{O}(x^\\star)$ as your final answer.",
            "solution": "The problem requires an analysis of the local observability of a nonlinear biochemical system at a specific point in the state space. The system is described by the state vector $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$ and its dynamics are governed by the vector field $f(x) = \\begin{pmatrix} f_1(x) \\\\ f_2(x) \\end{pmatrix}$, where\n$$\nf_1(x) = \\alpha_1\\,\\frac{x_2^2}{K_1^2 + x_2^2} - \\beta_1\\,x_1\n$$\n$$\nf_2(x) = \\alpha_2\\,\\frac{x_1^m}{K_2^m + x_1^m} - \\beta_2\\,x_2\n$$\nThe output function is $h(x) = x_1$.\n\nObservability is assessed using the observability matrix $\\mathcal{O}(x)$, which is constructed from the gradients of successive Lie derivatives of the output function $h(x)$. The rows of the matrix are the transposed gradients.\n$$\n\\mathcal{O}(x) = \\begin{pmatrix} (\\nabla h(x))^T \\\\ (\\nabla (L_f h(x)))^T \\\\ (\\nabla (L_f^2 h(x)))^T \\end{pmatrix}\n$$\nWe are asked to find the rank of this matrix at the point $x^\\star = (K_2, 0)$.\n\nFirst, we compute the required Lie derivatives and their gradients in symbolic form.\n\n**Step 1: Zeroth-order term, $h(x)$**\n\nThe output function is given as $h(x) = x_1$.\nThe gradient of $h(x)$ is a constant vector:\n$$\n\\nabla h(x) = \\begin{pmatrix} \\frac{\\partial h}{\\partial x_1} \\\\ \\frac{\\partial h}{\\partial x_2} \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\nThe first row of the observability matrix is $(\\nabla h(x))^T = \\begin{pmatrix} 1 & 0 \\end{pmatrix}$. This row is constant and thus the same at $x^\\star$.\n\n**Step 2: First-order term, $L_f h(x)$**\n\nThe first Lie derivative is defined as $L_f h(x) = \\nabla h(x) \\cdot f(x)$.\n$$\nL_f h(x) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\cdot \\begin{pmatrix} f_1(x) \\\\ f_2(x) \\end{pmatrix} = f_1(x) = \\alpha_1\\,\\frac{x_2^2}{K_1^2 + x_2^2} - \\beta_1\\,x_1\n$$\nNext, we compute the gradient of $L_f h(x)$:\n$$\n\\frac{\\partial (L_f h)}{\\partial x_1} = \\frac{\\partial}{\\partial x_1} \\left( \\alpha_1\\,\\frac{x_2^2}{K_1^2 + x_2^2} - \\beta_1\\,x_1 \\right) = -\\beta_1\n$$\n$$\n\\frac{\\partial (L_f h)}{\\partial x_2} = \\frac{\\partial}{\\partial x_2} \\left( \\alpha_1\\,\\frac{x_2^2}{K_1^2 + x_2^2} - \\beta_1\\,x_1 \\right) = \\alpha_1 \\frac{(2x_2)(K_1^2 + x_2^2) - x_2^2(2x_2)}{(K_1^2 + x_2^2)^2} = \\frac{2 \\alpha_1 K_1^2 x_2}{(K_1^2 + x_2^2)^2}\n$$\nSo, the gradient is $\\nabla(L_f h(x)) = \\begin{pmatrix} -\\beta_1 \\\\ \\frac{2 \\alpha_1 K_1^2 x_2}{(K_1^2 + x_2^2)^2} \\end{pmatrix}$.\nThe second row of the observability matrix is $(\\nabla (L_f h(x)))^T = \\begin{pmatrix} -\\beta_1 & \\frac{2 \\alpha_1 K_1^2 x_2}{(K_1^2 + x_2^2)^2} \\end{pmatrix}$.\n\n**Step 3: Second-order term, $L_f^2 h(x)$**\n\nThe second Lie derivative is $L_f^2 h(x) = \\nabla(L_f h(x)) \\cdot f(x)$.\n$$\nL_f^2 h(x) = \\begin{pmatrix} -\\beta_1 \\\\ \\frac{2 \\alpha_1 K_1^2 x_2}{(K_1^2 + x_2^2)^2} \\end{pmatrix} \\cdot \\begin{pmatrix} f_1(x) \\\\ f_2(x) \\end{pmatrix} = -\\beta_1 f_1(x) + \\frac{2 \\alpha_1 K_1^2 x_2}{(K_1^2 + x_2^2)^2} f_2(x)\n$$\nTo find the third row of the observability matrix, we need to compute the gradient $\\nabla(L_f^2 h(x))$. Rather than computing the full symbolic expression, it is more efficient to evaluate the gradient at the specified point $x^\\star = (K_2, 0)$.\nThe third row is $(\\nabla (L_f^2 h(x^\\star)))^T = \\begin{pmatrix} \\frac{\\partial (L_f^2 h)}{\\partial x_1}\\Big|_{x^\\star} & \\frac{\\partial (L_f^2 h)}{\\partial x_2}\\Big|_{x^\\star} \\end{pmatrix}$.\n\nLet us denote $C(x_2) = \\frac{2 \\alpha_1 K_1^2 x_2}{(K_1^2 + x_2^2)^2}$. So $L_f^2 h(x) = -\\beta_1 f_1(x) + C(x_2) f_2(x)$.\nThen $\\nabla(L_f^2 h(x)) = -\\beta_1 \\nabla f_1(x) + \\nabla(C(x_2) f_2(x))$.\nUsing the product rule for gradients, $\\nabla(C f_2) = C \\nabla f_2 + f_2 \\nabla C$.\nSo, $\\nabla(L_f^2 h(x)) = -\\beta_1 \\nabla f_1(x) + C(x_2) \\nabla f_2(x) + f_2(x) \\nabla C(x_2)$.\n\nWe evaluate each term at $x^\\star = (K_2, 0)$:\n1. At $x_2=0$, $C(0) = 0$. Thus the term $C(x_2) \\nabla f_2(x)$ vanishes at $x^\\star$.\n2. $\\nabla f_1(x)$ is $\\nabla(L_f h(x))$. At $x^\\star$, $\\nabla f_1(x^\\star) = \\begin{pmatrix} -\\beta_1 \\\\ 0 \\end{pmatrix}$. So, $-\\beta_1 \\nabla f_1(x^\\star) = \\begin{pmatrix} \\beta_1^2 \\\\ 0 \\end{pmatrix}$.\n3. We need $f_2(x^\\star)$ and $\\nabla C(x_2)|_{x^\\star}$.\n$$\nf_2(x^\\star) = \\alpha_2\\,\\frac{K_2^m}{K_2^m + K_2^m} - \\beta_2(0) = \\frac{\\alpha_2}{2}\n$$\nThe gradient of $C(x_2)$ is $\\nabla C(x_2) = \\begin{pmatrix} 0 \\\\ C'(x_2) \\end{pmatrix}$.\n$$\nC'(x_2) = \\frac{d}{d x_2} \\left( \\frac{2 \\alpha_1 K_1^2 x_2}{(K_1^2 + x_2^2)^2} \\right) = 2 \\alpha_1 K_1^2 \\frac{(K_1^2 + x_2^2)^2 - x_2 \\cdot 2(K_1^2+x_2^2)(2x_2)}{(K_1^2 + x_2^2)^4} = 2 \\alpha_1 K_1^2 \\frac{K_1^2 - 3x_2^2}{(K_1^2 + x_2^2)^3}\n$$\nEvaluating at $x_2=0$:\n$$\nC'(0) = 2 \\alpha_1 K_1^2 \\frac{K_1^2}{(K_1^2)^3} = \\frac{2 \\alpha_1}{K_1^2}\n$$\nSo, $\\nabla C(x_2)|_{x^\\star} = \\begin{pmatrix} 0 \\\\ \\frac{2 \\alpha_1}{K_1^2} \\end{pmatrix}$.\n4. The last term becomes $f_2(x^\\star) \\nabla C(x_2)|_{x^\\star} = \\frac{\\alpha_2}{2} \\begin{pmatrix} 0 \\\\ \\frac{2 \\alpha_1}{K_1^2} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\frac{\\alpha_1 \\alpha_2}{K_1^2} \\end{pmatrix}$.\n\nCombining the parts, the gradient of the second Lie derivative at $x^\\star$ is:\n$$\n\\nabla(L_f^2 h(x^\\star)) = \\begin{pmatrix} \\beta_1^2 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ \\frac{\\alpha_1 \\alpha_2}{K_1^2} \\end{pmatrix} = \\begin{pmatrix} \\beta_1^2 \\\\ \\frac{\\alpha_1 \\alpha_2}{K_1^2} \\end{pmatrix}\n$$\nThe third row of the observability matrix at $x^\\star$ is $\\begin{pmatrix} \\beta_1^2 & \\frac{\\alpha_1 \\alpha_2}{K_1^2} \\end{pmatrix}$.\n\n**Step 4: Assemble and evaluate the rank of $\\mathcal{O}(x^\\star)$**\n\nWe assemble the observability matrix by evaluating each row at $x^\\star=(K_2, 0)$:\n- Row 1: $\\begin{pmatrix} 1 & 0 \\end{pmatrix}$\n- Row 2: $\\begin{pmatrix} -\\beta_1 & \\frac{2 \\alpha_1 K_1^2 x_2}{(K_1^2 + x_2^2)^2} \\end{pmatrix}\\Big|_{x_2=0} = \\begin{pmatrix} -\\beta_1 & 0 \\end{pmatrix}$\n- Row 3: $\\begin{pmatrix} \\beta_1^2 & \\frac{\\alpha_1 \\alpha_2}{K_1^2} \\end{pmatrix}$\n\nThe matrix is:\n$$\n\\mathcal{O}(x^\\star) = \\begin{pmatrix} 1 & 0 \\\\ -\\beta_1 & 0 \\\\ \\beta_1^2 & \\frac{\\alpha_1 \\alpha_2}{K_1^2} \\end{pmatrix}\n$$\nTo find the rank of this $3 \\times 2$ matrix, we check the linear independence of its rows.\nThe second row is $-\\beta_1$ times the first row, so they are linearly dependent. The rank of the matrix is determined by the span of the first and third rows.\nThe first row is $R_1 = \\begin{pmatrix} 1 & 0 \\end{pmatrix}$.\nThe third row is $R_3 = \\begin{pmatrix} \\beta_1^2 & \\frac{\\alpha_1 \\alpha_2}{K_1^2} \\end{pmatrix}$.\n\nThese two rows are linearly independent if and only if the determinant of the matrix they form is non-zero:\n$$\n\\det \\begin{pmatrix} 1 & 0 \\\\ \\beta_1^2 & \\frac{\\alpha_1 \\alpha_2}{K_1^2} \\end{pmatrix} = (1) \\left( \\frac{\\alpha_1 \\alpha_2}{K_1^2} \\right) - (0) (\\beta_1^2) = \\frac{\\alpha_1 \\alpha_2}{K_1^2}\n$$\nAccording to the problem statement, the parameters $\\alpha_1$, $\\alpha_2$, and $K_1$ are all strictly positive. Therefore, their product and ratio $\\frac{\\alpha_1 \\alpha_2}{K_1^2}$ is strictly positive and non-zero.\nSince the determinant is non-zero, the vectors $\\begin{pmatrix} 1 & 0 \\end{pmatrix}$ and $\\begin{pmatrix} \\beta_1^2 & \\frac{\\alpha_1 \\alpha_2}{K_1^2} \\end{pmatrix}$ are linearly independent.\nThe row space of $\\mathcal{O}(x^\\star)$ is spanned by these two vectors, so its dimension is $2$.\nThe rank of the matrix $\\mathcal{O}(x^\\star)$ is therefore $2$. This implies that the system is locally observable at the state $x^\\star$, even though $x_2$ is unmeasured and its direct impact on the measurement derivative $\\dot{x}_1$ vanishes at $x_2=0$.",
            "answer": "$$\n\\boxed{2}\n$$"
        },
        {
            "introduction": "Building on the foundational calculations, this exercise explores the constructive power of observability analysis. You will transform a classic gene expression model into observer canonical form, a special structure where the dynamics are expressed in terms of the measured output and its time derivatives. This practice  reveals the deep connection between observability and the ability to design state estimators, and prompts reflection on the biological meaning of the new, observer-friendly coordinates.",
            "id": "3334919",
            "problem": "Consider a nonlinear gene expression module with messenger ribonucleic acid (mRNA) and protein as state variables. Let the state vector be $x = (m, p)^{\\top}$, where $m$ is the mRNA concentration and $p$ is the protein concentration. The dynamics are given by\n$$\n\\frac{dm}{dt} \\;=\\; \\frac{\\alpha}{1 + \\left(\\frac{p}{K}\\right)^{n}} \\;-\\; \\delta_{m}\\, m,\n\\qquad\n\\frac{dp}{dt} \\;=\\; \\beta\\, m \\;-\\; \\delta_{p}\\, p,\n$$\nwith strictly positive parameters $\\alpha, K, n, \\delta_{m}, \\delta_{p}, \\beta$. The measured output is $y = h(x) = p$. Work entirely from first principles based on the definitions of Lie derivatives and the observability rank condition for nonlinear systems.\n\nTasks:\n- Using only the definition of the Lie derivative $L_{f} h(x)$ of an output function $h(x)$ along a vector field $f(x)$, construct the observability mapping $\\Phi(x) = \\big(h(x),\\, L_{f} h(x)\\big)$ for this system and compute its Jacobian. Determine conditions under which the mapping is a local diffeomorphism by evaluating the determinant symbolically.\n- Define the observer canonical coordinates (also called the output-derivative coordinates) $z_{1} = h(x)$ and $z_{2} = L_{f} h(x)$. Starting from the chain rule and the definition of higher-order Lie derivatives, derive the dynamics in these coordinates of the form\n$$\n\\dot{z}_{1} \\;=\\; z_{2}, \n\\qquad\n\\dot{z}_{2} \\;=\\; \\Psi(z_{1}, z_{2}),\n$$\nwhere $\\Psi$ depends only on $z_{1}, z_{2}$ and the positive parameters $\\alpha, K, n, \\delta_{m}, \\delta_{p}, \\beta$, and not directly on $m$ or $p$.\n- Briefly discuss the biological interpretability of the coordinates $z_{1}$ and $z_{2}$ in terms of measurable quantities and fluxes in gene expression.\n\nAnswer requirement: Provide, as your final answer, the explicit closed-form analytic expression for $\\Psi(z_{1}, z_{2})$. No numerical evaluation is required. The final answer must be a single analytic expression. Do not include units and do not round.",
            "solution": "**Detailed Solution**\n\nThe analysis proceeds by applying the definitions of Lie derivatives and coordinate transformation to the given nonlinear system.\n\n**Part 1: Observability Mapping and Local Diffeomorphism**\n\nThe state vector is $x = (m, p)^{\\top}$ and the vector field is given by\n$$ f(x) = \\begin{pmatrix} f_m(x) \\\\ f_p(x) \\end{pmatrix} = \\begin{pmatrix} \\frac{\\alpha}{1 + \\left(\\frac{p}{K}\\right)^{n}} - \\delta_{m}\\, m \\\\ \\beta\\, m - \\delta_{p}\\, p \\end{pmatrix} $$\nThe output function is $h(x) = p$.\n\nThe observability mapping is defined as $\\Phi(x) = \\big( h(x), L_{f} h(x) \\big)^{\\top}$.\nThe first component is $h(x) = p$.\nThe second component is the Lie derivative of $h(x)$ along the vector field $f(x)$, defined as $L_f h(x) = \\nabla h(x) \\cdot f(x)$.\nFirst, we compute the gradient of $h(x)$:\n$$ \\nabla h(x) = \\left( \\frac{\\partial h}{\\partial m}, \\frac{\\partial h}{\\partial p} \\right) = \\left( \\frac{\\partial p}{\\partial m}, \\frac{\\partial p}{\\partial p} \\right) = (0, 1) $$\nNow, we compute the Lie derivative:\n$$ L_{f} h(x) = (0, 1) \\begin{pmatrix} \\frac{\\alpha}{1 + \\left(\\frac{p}{K}\\right)^{n}} - \\delta_{m}\\, m \\\\ \\beta\\, m - \\delta_{p}\\, p \\end{pmatrix} = \\beta m - \\delta_p p $$\nThus, the observability mapping $\\Phi(x)$ is:\n$$ \\Phi(x) = \\begin{pmatrix} h(x) \\\\ L_f h(x) \\end{pmatrix} = \\begin{pmatrix} p \\\\ \\beta m - \\delta_p p \\end{pmatrix} $$\nTo determine the conditions under which this mapping is a local diffeomorphism, we must compute its Jacobian matrix, $J_{\\Phi}(x)$, and check where its determinant is non-zero.\n$$ J_{\\Phi}(x) = \\frac{\\partial \\Phi}{\\partial x} = \\begin{pmatrix} \\frac{\\partial}{\\partial m}(p) & \\frac{\\partial}{\\partial p}(p) \\\\ \\frac{\\partial}{\\partial m}(\\beta m - \\delta_p p) & \\frac{\\partial}{\\partial p}(\\beta m - \\delta_p p) \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ \\beta & -\\delta_p \\end{pmatrix} $$\nThe determinant of the Jacobian is:\n$$ \\det(J_{\\Phi}(x)) = (0)(-\\delta_p) - (1)(\\beta) = -\\beta $$\nFor the mapping $\\Phi(x)$ to be a local diffeomorphism, the Jacobian matrix must be invertible, which means its determinant must be non-zero. The condition is $\\det(J_{\\Phi}(x)) \\neq 0$, which implies $-\\beta \\neq 0$.\nThe problem statement specifies that all parameters, including $\\beta$, are strictly positive. Therefore, $\\beta > 0$, and the condition $-\\beta \\neq 0$ is always satisfied. The mapping is a global diffeomorphism, as the Jacobian is a constant invertible matrix, meaning the coordinate transformation is a linear isomorphism.\n\n**Part 2: Dynamics in Observer Canonical Coordinates**\n\nWe define the new coordinates, also known as output-derivative coordinates, as:\n$$ z_1 = h(x) = p $$\n$$ z_2 = L_f h(x) = \\beta m - \\delta_p p $$\nOur goal is to find the dynamics $\\dot{z}_1$ and $\\dot{z}_2$ in terms of $z_1$ and $z_2$.\n\nFirst, we compute $\\dot{z}_1$:\n$$ \\dot{z}_1 = \\frac{d z_1}{dt} = \\frac{d p}{dt} $$\nFrom the original system dynamics, $\\frac{dp}{dt} = \\beta m - \\delta_p p$. By definition of $z_2$, this is exactly $z_2$.\n$$ \\dot{z}_1 = z_2 $$\nNext, we compute $\\dot{z}_2$. This corresponds to the second Lie derivative, $L_f^2 h(x)$.\n$$ \\dot{z}_2 = \\frac{d z_2}{dt} = \\frac{d}{dt} (\\beta m - \\delta_p p) = \\beta \\frac{dm}{dt} - \\delta_p \\frac{dp}{dt} $$\nSubstitute the expressions for $\\frac{dm}{dt}$ and $\\frac{dp}{dt}$ from the original system:\n$$ \\dot{z}_2 = \\beta \\left( \\frac{\\alpha}{1 + \\left(\\frac{p}{K}\\right)^{n}} - \\delta_{m}\\, m \\right) - \\delta_p \\left( \\beta\\, m - \\delta_{p}\\, p \\right) $$\nExpanding this expression gives:\n$$ \\dot{z}_2 = \\frac{\\alpha\\beta}{1 + \\left(\\frac{p}{K}\\right)^{n}} - \\beta\\delta_m m - \\beta\\delta_p m + \\delta_p^2 p $$\n$$ \\dot{z}_2 = \\frac{\\alpha\\beta}{1 + \\left(\\frac{p}{K}\\right)^{n}} - (\\delta_m + \\delta_p)\\beta m + \\delta_p^2 p $$\nTo get the dynamics in the new coordinates, we must express the original state variables $m$ and $p$ in terms of $z_1$ and $z_2$. The coordinate transformation is:\n$p = z_1$\n$z_2 = \\beta m - \\delta_p p \\implies z_2 = \\beta m - \\delta_p z_1 \\implies \\beta m = z_2 + \\delta_p z_1 \\implies m = \\frac{z_2 + \\delta_p z_1}{\\beta}$\nNow, substitute these expressions for $m$ and $p$ into the equation for $\\dot{z}_2$:\n$$ \\dot{z}_2 = \\frac{\\alpha\\beta}{1 + \\left(\\frac{z_1}{K}\\right)^{n}} - (\\delta_m + \\delta_p)\\beta \\left( \\frac{z_2 + \\delta_p z_1}{\\beta} \\right) + \\delta_p^2 z_1 $$\nThe parameter $\\beta$ cancels in the second term:\n$$ \\dot{z}_2 = \\frac{\\alpha\\beta}{1 + \\left(\\frac{z_1}{K}\\right)^{n}} - (\\delta_m + \\delta_p)(z_2 + \\delta_p z_1) + \\delta_p^2 z_1 $$\nExpand and simplify the expression:\n$$ \\dot{z}_2 = \\frac{\\alpha\\beta}{1 + \\left(\\frac{z_1}{K}\\right)^{n}} - (\\delta_m + \\delta_p)z_2 - (\\delta_m + \\delta_p)\\delta_p z_1 + \\delta_p^2 z_1 $$\n$$ \\dot{z}_2 = \\frac{\\alpha\\beta}{1 + \\left(\\frac{z_1}{K}\\right)^{n}} - (\\delta_m + \\delta_p)z_2 - \\delta_m\\delta_p z_1 - \\delta_p^2 z_1 + \\delta_p^2 z_1 $$\n$$ \\dot{z}_2 = \\frac{\\alpha\\beta}{1 + \\left(\\frac{z_1}{K}\\right)^{n}} - (\\delta_m + \\delta_p)z_2 - \\delta_m\\delta_p z_1 $$\nThis is the desired function $\\Psi(z_1, z_2)$.\nThe complete dynamics in the observer canonical form are:\n$$ \\dot{z}_1 = z_2 $$\n$$ \\dot{z}_2 = \\Psi(z_1, z_2) = \\frac{\\alpha\\beta}{1 + \\left(\\frac{z_1}{K}\\right)^{n}} - (\\delta_m + \\delta_p)z_2 - \\delta_m\\delta_p z_1 $$\n\n**Part 3: Biological Interpretation**\n\n- **Interpretation of $z_1$**: The coordinate $z_1$ is defined as $z_1 = p$. This is the concentration of the protein. Since the output of the system is given as $y=p$, $z_1$ is the directly measured quantity. It represents the current abundance of the final product of the gene expression process.\n\n- **Interpretation of $z_2$**: The coordinate $z_2$ is defined as $z_2 = L_f h(x)$. As shown in the derivation of the transformed dynamics, $\\dot{z}_1 = z_2$, which means $z_2 = \\frac{dp}{dt}$. Biologically, $\\frac{dp}{dt}$ is the net rate of change of the protein concentration. The original equation for this rate is $\\frac{dp}{dt} = \\beta m - \\delta_p p$, which represents the balance between the total rate of protein synthesis from mRNA (translation), $\\beta m$, and the total rate of protein degradation, $\\delta_p p$. Therefore, $z_2$ is the net flux for the protein pool. A positive $z_2$ indicates that protein synthesis is dominant over degradation, leading to an increase in protein levels, while a negative $z_2$ indicates the opposite. $z_2=0$ signifies a state of dynamic equilibrium where synthesis and degradation rates are equal. The pair $(z_1, z_2)$ thus represents the state of the protein in a phase space of its concentration and its net rate of change. The fact that the system is observable in these coordinates implies that by measuring the protein level ($z_1$) and its rate of change ($z_2$), one can uniquely determine the concentration of the unmeasured mRNA, $m$.",
            "answer": "$$\n\\boxed{\\frac{\\alpha \\beta}{1 + \\left(\\frac{z_{1}}{K}\\right)^{n}} - (\\delta_{m} + \\delta_{p}) z_{2} - \\delta_{m} \\delta_{p} z_{1}}\n$$"
        },
        {
            "introduction": "Our final practice delves into a more advanced and crucial concept: the difference between local and global observability. Using a symmetric genetic toggle-switch, a classic example of a bistable system, you will demonstrate why structural observability does not guarantee that you can distinguish between all possible initial states. This exercise  highlights how inherent system properties like symmetry and multistability can lead to fundamentally ambiguous outputs, a key consideration when interpreting experimental data from complex biological circuits.",
            "id": "3334899",
            "problem": "Consider a symmetric mutual-repression genetic toggle-switch model without external input, a standard motif in computational systems biology, with state vector $x = (x_1, x_2)$ representing the concentrations of two transcription factors that repress each other. The dynamics are given by\n$$\n\\begin{aligned}\n\\dot{x}_1 &= \\frac{\\alpha}{1 + \\left(\\frac{x_2}{K}\\right)^{n}} - \\delta\\, x_1,\\\\\n\\dot{x}_2 &= \\frac{\\alpha}{1 + \\left(\\frac{x_1}{K}\\right)^{n}} - \\delta\\, x_2,\n\\end{aligned}\n$$\nwhere $\\alpha > 0$ is a maximal synthesis rate, $\\delta > 0$ is a first-order degradation/dilution rate, $K > 0$ is a dissociation constant, and $n \\ge 2$ is a Hill coefficient describing cooperativity. Assume parameters are chosen in a regime known to produce bistability (two linearly stable off-diagonal equilibria and one unstable equilibrium on the diagonal), which is a well-documented property of such toggles for sufficiently large $n$ and $\\alpha/\\delta$.\n\nSuppose the sole measured output is the total concentration\n$$\ny = h(x) = x_1 + x_2.\n$$\n\nUsing only foundational definitions from nonlinear systems theory (the local observability rank condition based on Lie derivatives, and the concept of structural observability as a generic property with respect to parameters), do the following:\n\n1. Construct the $2 \\times 2$ local observability matrix at a generic state $x$ by stacking the gradients of $h(x)$ and its first Lie derivative along the vector field $f(x)$, where $f(x)$ denotes the right-hand side of the state equations. Compute the determinant of this matrix explicitly as a function of $x_1$, $x_2$, $\\alpha$, $\\delta$, $K$, and $n$.\n\n2. Using your expression, argue from first principles why the system is structurally observable, that is, why the local observability rank condition holds on a full-measure subset of the state space for an open dense set of parameter values.\n\n3. Exploit the exchange symmetry $x_1 \\leftrightarrow x_2$ and the assumed bistability to justify that the inputâ€“output map $x_0 \\mapsto y(t \\mid x_0)$ is not globally injective, because there exist distinct initial conditions that generate identical output trajectories for all $t \\ge 0$, and, in particular, distinct stable steady states with identical steady-state output. Define $m$ as the generic cardinality of the set of indistinguishable initial conditions $x_0$ and $x_0'$ that yield identical output trajectories $y(t)$ for all $t \\ge 0$ under the given output $h(x) = x_1 + x_2$.\n\nReport the value of $m$ as a single number with no units. No rounding is required.",
            "solution": "The problem requires an analysis of the observability properties of a symmetric genetic toggle-switch model. The analysis hinges on the local observability rank condition, derived from Lie derivatives, and the system's inherent exchange symmetry.\n\nLet the state of the system be $x = (x_1, x_2)^T \\in \\mathbb{R}^2$, where $x_1 \\ge 0$ and $x_2 \\ge 0$. The dynamics are governed by the vector field $f(x) = (f_1(x), f_2(x))^T$, where\n$$\n\\begin{aligned}\nf_1(x) &= \\frac{\\alpha}{1 + \\left(\\frac{x_2}{K}\\right)^{n}} - \\delta\\, x_1 \\\\\nf_2(x) &= \\frac{\\alpha}{1 + \\left(\\frac{x_1}{K}\\right)^{n}} - \\delta\\, x_2\n\\end{aligned}\n$$\nThe output is given by the function $y = h(x) = x_1 + x_2$.\n\nThe local observability of a nonlinear system $\\dot{x} = f(x)$, $y = h(x)$ at a point $x$ is assessed using the observability matrix, $\\mathcal{O}(x)$, which is constructed from the gradients of successive Lie derivatives of the output function $h(x)$. For a two-dimensional system, we typically need to check the rank of the matrix formed by the gradients of $h(x)$ and its first Lie derivative, $L_f h(x)$.\n\n**1. Construction of the Observability Matrix and its Determinant**\n\nThe $2 \\times 2$ local observability matrix is given by:\n$$\n\\mathcal{O}(x) = \\begin{pmatrix} \\nabla h(x) \\\\ \\nabla(L_f h(x)) \\end{pmatrix}\n$$\nFirst, we compute the gradient of the output function $h(x) = x_1 + x_2$:\n$$\n\\nabla h(x) = \\left[ \\frac{\\partial h}{\\partial x_1} \\quad \\frac{\\partial h}{\\partial x_2} \\right] = \\begin{pmatrix} 1 & 1 \\end{pmatrix}\n$$\nNext, we compute the first Lie derivative of $h(x)$ along the vector field $f(x)$:\n$$\nL_f h(x) = \\nabla h(x) \\cdot f(x) = 1 \\cdot f_1(x) + 1 \\cdot f_2(x)\n$$\n$$\nL_f h(x) = \\left( \\frac{\\alpha}{1 + \\left(\\frac{x_2}{K}\\right)^{n}} - \\delta\\, x_1 \\right) + \\left( \\frac{\\alpha}{1 + \\left(\\frac{x_1}{K}\\right)^{n}} - \\delta\\, x_2 \\right) = \\frac{\\alpha}{1 + (x_2/K)^n} + \\frac{\\alpha}{1 + (x_1/K)^n} - \\delta(x_1 + x_2)\n$$\nNow, we compute the gradient of $L_f h(x)$. We find its partial derivatives with respect to $x_1$ and $x_2$:\n$$\n\\frac{\\partial}{\\partial x_1} (L_f h(x)) = \\frac{\\partial}{\\partial x_1} \\left( \\frac{\\alpha}{1 + (x_1/K)^n} - \\delta x_1 \\right) = \\alpha \\frac{-\\frac{n}{K} \\left(\\frac{x_1}{K}\\right)^{n-1}}{\\left(1 + (x_1/K)^n\\right)^2} - \\delta = -\\frac{\\alpha n K^n x_1^{n-1}}{(K^n + x_1^n)^2} - \\delta\n$$\n$$\n\\frac{\\partial}{\\partial x_2} (L_f h(x)) = \\frac{\\partial}{\\partial x_2} \\left( \\frac{\\alpha}{1 + (x_2/K)^n} - \\delta x_2 \\right) = \\alpha \\frac{-\\frac{n}{K} \\left(\\frac{x_2}{K}\\right)^{n-1}}{\\left(1 + (x_2/K)^n\\right)^2} - \\delta = -\\frac{\\alpha n K^n x_2^{n-1}}{(K^n + x_2^n)^2} - \\delta\n$$\nWe can now assemble the observability matrix $\\mathcal{O}(x)$:\n$$\n\\mathcal{O}(x) = \\begin{pmatrix} 1 & 1 \\\\ -\\frac{\\alpha n K^n x_1^{n-1}}{(K^n + x_1^n)^2} - \\delta & -\\frac{\\alpha n K^n x_2^{n-1}}{(K^n + x_2^n)^2} - \\delta \\end{pmatrix}\n$$\nThe determinant of this matrix is:\n$$\n\\det(\\mathcal{O}(x)) = 1 \\cdot \\left(-\\frac{\\alpha n K^n x_2^{n-1}}{(K^n + x_2^n)^2} - \\delta\\right) - 1 \\cdot \\left(-\\frac{\\alpha n K^n x_1^{n-1}}{(K^n + x_1^n)^2} - \\delta\\right)\n$$\n$$\n\\det(\\mathcal{O}(x)) = -\\frac{\\alpha n K^n x_2^{n-1}}{(K^n + x_2^n)^2} - \\delta + \\frac{\\alpha n K^n x_1^{n-1}}{(K^n + x_1^n)^2} + \\delta\n$$\n$$\n\\det(\\mathcal{O}(x)) = \\alpha n K^n \\left( \\frac{x_1^{n-1}}{(K^n + x_1^n)^2} - \\frac{x_2^{n-1}}{(K^n + x_2^n)^2} \\right)\n$$\n\n**2. Argument for Structural Observability**\n\nA system is locally observable at a state $x$ if the observability matrix $\\mathcal{O}(x)$ has full rank. For this $2$-dimensional system, this means $\\text{rank}(\\mathcal{O}(x)) = 2$, which is equivalent to $\\det(\\mathcal{O}(x)) \\neq 0$. The system is structurally observable if the set of states $x$ where the rank condition fails (i.e., $\\det(\\mathcal{O}(x)) = 0$) is a set of measure zero in the state space for an open dense set of parameters.\n\nThe determinant is zero if and only if:\n$$\n\\frac{x_1^{n-1}}{(K^n + x_1^n)^2} = \\frac{x_2^{n-1}}{(K^n + x_2^n)^2}\n$$\nThis equation is clearly satisfied for all points on the line $x_1 = x_2$. This line is a one-dimensional submanifold in the two-dimensional state space, and thus has Lebesgue measure zero. The function $g(z) = \\frac{z^{n-1}}{(K^n + z^n)^2}$ is not monotonic for $z \\ge 0$, so there may be other curves of solutions where $g(x_1)=g(x_2)$ for $x_1 \\neq x_2$. However, the set of all such points $(x_1, x_2)$ forms a lower-dimensional algebraic variety in $\\mathbb{R}^2$. As the parameters $\\alpha, n, K, \\delta$ are non-zero, the determinant is a non-trivial analytic function of $x_1$ and $x_2$. Its zero-set is therefore a set of measure zero. This fulfills the condition for structural observability. The system is locally observable for almost all states $x$.\n\n**3. Global Non-Injectivity and the Cardinality of Indistinguishable States**\n\nThe system is not globally observable, meaning the map from an initial condition $x_0$ to the entire output trajectory $y(t \\mid x_0)$ is not injective. This is a direct consequence of the system's symmetry.\n\nLet $S$ be the swap operator: $S(x_1, x_2) = (x_2, x_1)$.\nThe vector field $f(x)$ is equivariant with respect to $S$. To see this, let $x' = S(x) = (x_2, x_1)$.\n$$\nf(x') = f(x_2, x_1) = \\begin{pmatrix} \\frac{\\alpha}{1 + (x_1/K)^n} - \\delta x_2 \\\\ \\frac{\\alpha}{1 + (x_2/K)^n} - \\delta x_1 \\end{pmatrix} = \\begin{pmatrix} f_2(x_1, x_2) \\\\ f_1(x_1, x_2) \\end{pmatrix} = S(f(x))\n$$\nThe output function $h(x) = x_1 + x_2$ is invariant under $S$:\n$$\nh(S(x)) = h(x_2, x_1) = x_2 + x_1 = x_1 + x_2 = h(x)\n$$\nNow, consider a solution trajectory $x(t)$ starting from an initial condition $x_0$, such that $\\dot{x}(t) = f(x(t))$ and $x(0)=x_0$. Let us define a new trajectory $z(t) = S(x(t))$. The initial condition for $z(t)$ is $z(0) = S(x(0)) = S(x_0)$. The dynamics of $z(t)$ are given by:\n$$\n\\dot{z}(t) = \\frac{d}{dt} S(x(t)) = S(\\dot{x}(t)) = S(f(x(t)))\n$$\nUsing the equivariance of $f$, we have $S(f(x(t))) = f(S(x(t))) = f(z(t))$. Thus, $\\dot{z}(t) = f(z(t))$. This shows that if $x(t)$ is a valid trajectory starting at $x_0$, then $z(t) = S(x(t))$ is a valid trajectory starting at the distinct initial point $S(x_0)$ (provided $x_0$ is not on the symmetry line $x_1=x_2$).\n\nLet's compare the outputs generated from initial conditions $x_0$ and $S(x_0)$.\nThe output from $x_0$ is $y(t) = h(x(t))$.\nThe output from $S(x_0)$ is $y'(t) = h(z(t)) = h(S(x(t)))$.\nDue to the invariance of $h$, we have $h(S(x(t))) = h(x(t))$.\nTherefore, $y'(t) = y(t)$ for all $t \\ge 0$.\n\nThis proves that any two initial conditions $x_0$ and $S(x_0)$ that are different (i.e., $x_0$ does not lie on the line $x_1=x_2$) are indistinguishable from the output $y(t)$.\n\nThe problem's assumption of bistability provides a concrete example. The two stable steady states, call them $x_A^* = (x_{hi}, x_{lo})$ and $x_B^* = (x_{lo}, x_{hi})$, are related by this symmetry: $x_B^* = S(x_A^*)$. The steady-state output for both is $y^* = x_{hi} + x_{lo}$, making them indistinguishable. An initial condition at $x_A^*$ yields a constant output $y^*$, and an initial condition at $x_B^*$ also yields the constant output $y^*$.\n\nThe question asks for $m$, the generic cardinality of the set of indistinguishable initial conditions. A \"generic\" initial condition $x_0$ is one that does not lie on any special, lower-dimensional manifold. In this case, this means $x_0$ does not lie on the set of unobservable points, and specifically not on the symmetry line $x_1=x_2$. For such a generic $x_0 = (x_{1,0}, x_{2,0})$ with $x_{1,0} \\neq x_{2,0}$, the set of initial conditions that produce the same output trajectory is $\\{x_0, S(x_0)\\} = \\{(x_{1,0}, x_{2,0}), (x_{2,0}, x_{1,0})\\}$.\nThe cardinality of this set is $2$.\nTherefore, $m=2$.",
            "answer": "$$\n\\boxed{2}\n$$"
        }
    ]
}