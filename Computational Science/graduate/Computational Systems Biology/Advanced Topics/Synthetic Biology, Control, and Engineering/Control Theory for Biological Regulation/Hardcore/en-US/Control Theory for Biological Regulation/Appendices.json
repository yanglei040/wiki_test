{
    "hands_on_practices": [
        {
            "introduction": "Before we can design sophisticated controllers for biological circuits, we must first answer two fundamental questions: can we actually influence all relevant molecular species, and can we deduce their concentrations from our measurements? This exercise introduces the core concepts of controllability and observability using a simple, linearized model of gene expression . Mastering this analysis is the first step toward understanding the theoretical limits of biological intervention and monitoring.",
            "id": "3297625",
            "problem": "Consider a minimal two-state model of gene expression under mass-action kinetics. Messenger ribonucleic acid (mRNA) is produced at a transcription rate controlled by an external input and degraded with a first-order rate constant, while protein is produced by translation from mRNA and degraded with a first-order rate constant. Protein fluorescence is measured and is proportional to the protein concentration.\n\nLet the states be $x_{1}(t)$ for mRNA concentration and $x_{2}(t)$ for protein concentration. The input is the transcription rate $u(t)$, and the output is fluorescence $y(t)$ proportional to protein concentration. Assume first-order degradation for mRNA and protein with positive rate constants $\\gamma_{m} > 0$ and $\\gamma_{p} > 0$, respectively, a positive translation rate $k_{t} > 0$, and a positive fluorescence gain $c > 0$. The dynamics and measurement are\n$$\n\\frac{d}{dt}\\begin{pmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{pmatrix}\n=\n\\begin{pmatrix}\n-\\gamma_{m}  0 \\\\\nk_{t}  -\\gamma_{p}\n\\end{pmatrix}\n\\begin{pmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{pmatrix}\n+\n\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} u(t),\n\\qquad\ny(t) = \\begin{pmatrix} 0  c \\end{pmatrix} \\begin{pmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{pmatrix}.\n$$\n\nUsing the definitions of controllability and observability for Linear Time-Invariant (LTI) systems, compute the ranks of the controllability and observability matrices of this system in terms of the parameters, and determine whether the system is controllable and observable under the stated conditions. Provide a brief biological interpretation of your result.\n\nExpress your final answer as a row matrix with two entries, where the first entry is the rank of the controllability matrix and the second entry is the rank of the observability matrix. No rounding is required.",
            "solution": "The problem presents a linear time-invariant (LTI) state-space model for gene expression. The state vector is $x(t) = \\begin{pmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{pmatrix}$, where $x_{1}(t)$ is the mRNA concentration and $x_{2}(t)$ is the protein concentration. The system is described by the equations:\n$$ \\frac{dx}{dt} = Ax + Bu, \\quad y = Cx $$\nwhere the matrices $A$, $B$, and $C$ are given by:\n$$ A = \\begin{pmatrix} -\\gamma_{m}  0 \\\\ k_{t}  -\\gamma_{p} \\end{pmatrix}, \\quad B = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 0  c \\end{pmatrix} $$\nThe parameters $\\gamma_{m}$, $\\gamma_{p}$, $k_{t}$, and $c$ are all strictly positive constants. The dimension of the state space is $n=2$.\n\nFirst, we will analyze the controllability of the system. A system is controllable if and only if its controllability matrix, $\\mathcal{C}$, has full rank. For a system of dimension $n$, the rank must be equal to $n$. Here, $n=2$. The controllability matrix is constructed as:\n$$ \\mathcal{C} = \\begin{pmatrix} B  AB  \\dots  A^{n-1}B \\end{pmatrix} $$\nFor this second-order system ($n=2$), the controllability matrix is $\\mathcal{C} = \\begin{pmatrix} B  AB \\end{pmatrix}$. We must compute the product $AB$:\n$$ AB = \\begin{pmatrix} -\\gamma_{m}  0 \\\\ k_{t}  -\\gamma_{p} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} (-\\gamma_{m})(1) + (0)(0) \\\\ (k_{t})(1) + (-\\gamma_{p})(0) \\end{pmatrix} = \\begin{pmatrix} -\\gamma_{m} \\\\ k_{t} \\end{pmatrix} $$\nNow, we can construct the controllability matrix $\\mathcal{C}$:\n$$ \\mathcal{C} = \\begin{pmatrix} B  AB \\end{pmatrix} = \\begin{pmatrix} 1  -\\gamma_{m} \\\\ 0  k_{t} \\end{pmatrix} $$\nThe rank of $\\mathcal{C}$ is determined by its determinant. A $2 \\times 2$ matrix has full rank ($2$) if and only if its determinant is non-zero.\n$$ \\det(\\mathcal{C}) = (1)(k_{t}) - (-\\gamma_{m})(0) = k_{t} $$\nAccording to the problem statement, the translation rate $k_{t}$ is positive, i.e., $k_{t} > 0$. Since $\\det(\\mathcal{C}) = k_{t} \\neq 0$, the matrix $\\mathcal{C}$ has full rank. Therefore, the rank of the controllability matrix is $2$. This means the system is fully controllable.\n\nNext, we will analyze the observability of the system. A system is observable if and only if its observability matrix, $\\mathcal{O}$, has full rank, which is $n=2$ in this case. The observability matrix is constructed as:\n$$ \\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\\\ \\vdots \\\\ CA^{n-1} \\end{pmatrix} $$\nFor this second-order system ($n=2$), the observability matrix is $\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\end{pmatrix}$. We must compute the product $CA$:\n$$ CA = \\begin{pmatrix} 0  c \\end{pmatrix} \\begin{pmatrix} -\\gamma_{m}  0 \\\\ k_{t}  -\\gamma_{p} \\end{pmatrix} = \\begin{pmatrix} (0)(-\\gamma_{m}) + (c)(k_{t})  (0)(0) + (c)(-\\gamma_{p}) \\end{pmatrix} = \\begin{pmatrix} c k_{t}  -c \\gamma_{p} \\end{pmatrix} $$\nNow, we can construct the observability matrix $\\mathcal{O}$:\n$$ \\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\end{pmatrix} = \\begin{pmatrix} 0  c \\\\ c k_{t}  -c \\gamma_{p} \\end{pmatrix} $$\nThe rank of $\\mathcal{O}$ is determined by its determinant.\n$$ \\det(\\mathcal{O}) = (0)(-c \\gamma_{p}) - (c)(c k_{t}) = -c^{2}k_{t} $$\nThe problem states that the fluorescence gain $c > 0$ and the translation rate $k_{t} > 0$. Thus, $c^{2} > 0$ and their product $c^{2}k_{t}$ is strictly positive. Consequently, $\\det(\\mathcal{O}) = -c^{2}k_{t} \\neq 0$. This indicates that the matrix $\\mathcal{O}$ has full rank. Therefore, the rank of the observability matrix is $2$. This means the system is fully observable.\n\nThe biological interpretation of these results is as follows:\nControllability (Rank = $2$): The system being fully controllable means that by manipulating the transcription rate $u(t)$, it is possible to drive the concentrations of both mRNA ($x_{1}$) and protein ($x_{2}$) from any initial state to any desired final state within a finite time. The input $u(t)$ directly influences the rate of change of mRNA. Because there is a non-zero translation rate ($k_{t} > 0$), the control authority over the mRNA state is passed on to the protein state. If $k_{t}$ were zero, the protein level would be independent of the input, and the system would not be controllable as we could not influence $x_{2}$.\n\nObservability (Rank = $2$): The system being fully observable means that by measuring the fluorescence output $y(t)$ over time, it is possible to uniquely determine the initial state of the system, i.e., the initial concentrations of both mRNA ($x_{1}(0)$) and protein ($x_{2}(0)$). We directly measure protein concentration (as $y(t) = cx_{2}(t)$ and $c > 0$). The dynamics of the protein level depend on the mRNA level through the term $k_{t}x_{1}$. Since $k_{t} > 0$, the time evolution of the measured protein concentration inherently contains information about the unmeasured mRNA concentration, allowing for its reconstruction. If either $k_{t}$ or $c$ were zero, information about the mRNA state would be lost, and the system would not be observable.\n\nIn summary, the rank of the controllability matrix is $2$, and the rank of the observability matrix is $2$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2  2 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Deterministic models provide a useful-but-incomplete picture of cellular processes, which are fundamentally stochastic. This practice delves into the noisy nature of gene expression by analyzing the fluctuations in molecular counts for a canonical transcription-translation model . By deriving the variance and the Fano factor, you will learn to quantify the \"noisiness\" of a circuit and understand how molecular randomness propagates through a simple biochemical cascade.",
            "id": "3297565",
            "problem": "Consider a constitutive transcription–translation module in a single, well-mixed cell of constant volume where molecular counts are modeled as discrete random variables and reaction kinetics follow mass-action. The species are messenger ribonucleic acid ($m$) and protein ($p$). The reactions are:\n- Transcription: $\\varnothing \\xrightarrow{k_m} m$ with rate $k_m$,\n- Messenger ribonucleic acid (mRNA) degradation: $m \\xrightarrow{\\gamma_m} \\varnothing$ with rate $\\gamma_m$ per mRNA,\n- Translation: $m \\xrightarrow{k_p} m + p$ with rate $k_p$ per mRNA,\n- Protein degradation/dilution: $p \\xrightarrow{\\gamma_p} \\varnothing$ with rate $\\gamma_p$ per protein.\n\nAssume a continuous-time Markov chain description with the Chemical Master Equation (CME), and use that for linear reaction networks the first and second moments are closed and coincide with those obtained by the Linear Noise Approximation (LNA). Starting from these principles, derive from first principles the steady-state mean and covariance of $(m,p)$ and then compute:\n- the steady-state variance of protein counts, $\\operatorname{Var}[p]$,\n- the steady-state Fano factor of protein counts, defined as $F = \\operatorname{Var}[p]/\\mathbb{E}[p]$.\n\nCompare your stochastic results to the deterministic mass-action ordinary differential equation model (no fluctuations) by discussing whether the mean matches and what the deterministic model predicts for the variance. Express your final answers symbolically in terms of $k_m$, $\\gamma_m$, $k_p$, and $\\gamma_p$. Provide the final answer as a row matrix with two entries in the order $\\operatorname{Var}[p]$ and $F$. No numerical rounding is required. No units are required because the answer is to be expressed symbolically.",
            "solution": "We begin by formalizing the problem. Let the state vector of molecular counts be $X = (m, p)^T$. The system involves $4$ chemical reactions. The change in the state vector for the $j$-th reaction is given by the stoichiometry vector $S_j$, and the rate of the $j$-th reaction is given by its propensity function $a_j(X)$.\n\nThe reactions are:\n$1$. Transcription: $\\varnothing \\xrightarrow{k_m} m$. Stoichiometry $S_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, propensity $a_1(X) = k_m$.\n$2$. mRNA degradation: $m \\xrightarrow{\\gamma_m} \\varnothing$. Stoichiometry $S_2 = \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix}$, propensity $a_2(X) = \\gamma_m m$.\n$3$. Translation: $m \\xrightarrow{k_p} m + p$. Stoichiometry $S_3 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, propensity $a_3(X) = k_p m$.\n$4$. Protein degradation: $p \\xrightarrow{\\gamma_p} \\varnothing$. Stoichiometry $S_4 = \\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix}$, propensity $a_4(X) = \\gamma_p p$.\n\nThe stoichiometric matrix is $S = \\begin{pmatrix} S_1  S_2  S_3  S_4 \\end{pmatrix} = \\begin{pmatrix} 1  -1  0  0 \\\\ 0  0  1  -1 \\end{pmatrix}$.\nThe propensity vector is $a(X) = (k_m, \\gamma_m m, k_p m, \\gamma_p p)^T$.\n\nFirst, for comparison, we consider the deterministic mass-action ordinary differential equation (ODE) model, where the variables represent concentrations. Let $\\langle m \\rangle$ and $\\langle p \\rangle$ denote these concentrations.\n$$ \\frac{d\\langle m \\rangle}{dt} = k_m - \\gamma_m \\langle m \\rangle $$\n$$ \\frac{d\\langle p \\rangle}{dt} = k_p \\langle m \\rangle - \\gamma_p \\langle p \\rangle $$\nAt steady state, the time derivatives are zero. Solving for the steady-state means, denoted $\\langle m \\rangle_{ss}$ and $\\langle p \\rangle_{ss}$:\nFrom the first equation: $k_m - \\gamma_m \\langle m \\rangle_{ss} = 0 \\implies \\langle m \\rangle_{ss} = \\frac{k_m}{\\gamma_m}$.\nFrom the second equation: $k_p \\langle m \\rangle_{ss} - \\gamma_p \\langle p \\rangle_{ss} = 0 \\implies \\langle p \\rangle_{ss} = \\frac{k_p}{\\gamma_p} \\langle m \\rangle_{ss} = \\frac{k_p k_m}{\\gamma_p \\gamma_m}$.\nThe deterministic model predicts these average values but provides no information about fluctuations, implying a variance of zero.\n\nNext, we analyze the stochastic model. The time evolution of the mean, $\\mathbb{E}[X] = \\langle X \\rangle$, is given by $\\frac{d\\langle X \\rangle}{dt} = S \\langle a(X) \\rangle$. Since all reactions are at most first-order, the propensities are linear in the state variables, so $\\langle a(X) \\rangle = a(\\langle X \\rangle)$. The equations for the means are identical to the deterministic ODEs, and thus the steady-state means are the same: $\\mathbb{E}[m] = \\langle m \\rangle_{ss} = \\frac{k_m}{\\gamma_m}$ and $\\mathbb{E}[p] = \\langle p \\rangle_{ss} = \\frac{k_p k_m}{\\gamma_p \\gamma_m}$.\n\nTo find the variance, we use the equation for the time evolution of the covariance matrix $\\Sigma = \\operatorname{Cov}(X, X) = \\langle (X-\\langle X \\rangle)(X-\\langle X \\rangle)^T \\rangle$. For linear reaction networks, this equation is exact and is given by the Lyapunov equation:\n$$ \\frac{d\\Sigma}{dt} = J \\Sigma + \\Sigma J^T + D $$\nwhere $J$ is the Jacobian matrix and $D$ is the diffusion matrix. At steady state, $\\frac{d\\Sigma}{dt}=0$, so we must solve $J \\Sigma_{ss} + \\Sigma_{ss} J^T + D = 0$.\n\nThe vector of macroscopic rates is $F(X) = S a(X) = \\begin{pmatrix} k_m - \\gamma_m m \\\\ k_p m - \\gamma_p p \\end{pmatrix}$.\nThe Jacobian matrix $J$ is the derivative of $F$ with respect to $X$, evaluated at the mean:\n$$ J = \\begin{pmatrix} -\\gamma_m  0 \\\\ k_p  -\\gamma_p \\end{pmatrix} $$\nThe diffusion matrix $D$ is given by $D = S \\operatorname{diag}(\\langle a(X) \\rangle_{ss}) S^T$. The steady-state propensities are:\n$\\langle a_1 \\rangle_{ss} = k_m$\n$\\langle a_2 \\rangle_{ss} = \\gamma_m \\langle m \\rangle_{ss} = \\gamma_m \\frac{k_m}{\\gamma_m} = k_m$\n$\\langle a_3 \\rangle_{ss} = k_p \\langle m \\rangle_{ss} = k_p \\frac{k_m}{\\gamma_m}$\n$\\langle a_4 \\rangle_{ss} = \\gamma_p \\langle p \\rangle_{ss} = \\gamma_p \\frac{k_p k_m}{\\gamma_p \\gamma_m} = \\frac{k_p k_m}{\\gamma_m}$\nThe diffusion matrix is calculated as $D = \\sum_{j=1}^{4} S_j S_j^T \\langle a_j \\rangle_{ss}$:\n$D = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\begin{pmatrix} 1  0 \\end{pmatrix}k_m + \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix}\\begin{pmatrix} -1  0 \\end{pmatrix}k_m + \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\\begin{pmatrix} 0  1 \\end{pmatrix}\\frac{k_p k_m}{\\gamma_m} + \\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix}\\begin{pmatrix} 0  -1 \\end{pmatrix}\\frac{k_p k_m}{\\gamma_m}$\n$D = \\begin{pmatrix} k_m  0 \\\\ 0  0 \\end{pmatrix} + \\begin{pmatrix} k_m  0 \\\\ 0  0 \\end{pmatrix} + \\begin{pmatrix} 0  0 \\\\ 0  \\frac{k_p k_m}{\\gamma_m} \\end{pmatrix} + \\begin{pmatrix} 0  0 \\\\ 0  \\frac{k_p k_m}{\\gamma_m} \\end{pmatrix} = \\begin{pmatrix} 2k_m  0 \\\\ 0  2 \\frac{k_p k_m}{\\gamma_m} \\end{pmatrix}$\n\nLet the steady-state covariance matrix be $\\Sigma_{ss} = \\begin{pmatrix} \\sigma_{mm}  \\sigma_{mp} \\\\ \\sigma_{mp}  \\sigma_{pp} \\end{pmatrix}$. The steady-state Lyapunov equation $J \\Sigma_{ss} + \\Sigma_{ss} J^T + D = 0$ yields a system of linear equations for the elements of $\\Sigma_{ss}$:\n$$ \\begin{pmatrix} -\\gamma_m  0 \\\\ k_p  -\\gamma_p \\end{pmatrix} \\begin{pmatrix} \\sigma_{mm}  \\sigma_{mp} \\\\ \\sigma_{mp}  \\sigma_{pp} \\end{pmatrix} + \\begin{pmatrix} \\sigma_{mm}  \\sigma_{mp} \\\\ \\sigma_{mp}  \\sigma_{pp} \\end{pmatrix} \\begin{pmatrix} -\\gamma_m  k_p \\\\ 0  -\\gamma_p \\end{pmatrix} + \\begin{pmatrix} 2k_m  0 \\\\ 0  2 \\frac{k_p k_m}{\\gamma_m} \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix} $$\n$$ \\begin{pmatrix} -2\\gamma_m \\sigma_{mm}  k_p \\sigma_{mm} - (\\gamma_m+\\gamma_p)\\sigma_{mp} \\\\ k_p \\sigma_{mm} - (\\gamma_m+\\gamma_p)\\sigma_{mp}  2k_p \\sigma_{mp} - 2\\gamma_p \\sigma_{pp} \\end{pmatrix} + \\begin{pmatrix} 2k_m  0 \\\\ 0  2 \\frac{k_p k_m}{\\gamma_m} \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix} $$\nFrom the $(1,1)$ entry:\n$-2\\gamma_m \\sigma_{mm} + 2k_m = 0 \\implies \\sigma_{mm} = \\frac{k_m}{\\gamma_m}$. This is $\\operatorname{Var}[m] = \\mathbb{E}[m]$, indicating a Poisson distribution for mRNA.\n\nFrom the $(1,2)$ entry:\n$k_p \\sigma_{mm} - (\\gamma_m+\\gamma_p)\\sigma_{mp} = 0 \\implies \\sigma_{mp} = \\frac{k_p \\sigma_{mm}}{\\gamma_m+\\gamma_p} = \\frac{k_p k_m}{\\gamma_m(\\gamma_m+\\gamma_p)}$.\n\nFrom the $(2,2)$ entry:\n$2k_p \\sigma_{mp} - 2\\gamma_p \\sigma_{pp} + 2 \\frac{k_p k_m}{\\gamma_m} = 0 \\implies \\gamma_p \\sigma_{pp} = k_p \\sigma_{mp} + \\frac{k_p k_m}{\\gamma_m}$.\n$\\sigma_{pp} = \\frac{k_p}{\\gamma_p} \\sigma_{mp} + \\frac{k_p k_m}{\\gamma_p \\gamma_m}$.\nSubstituting the expression for $\\sigma_{mp}$:\n$\\sigma_{pp} = \\frac{k_p}{\\gamma_p} \\left( \\frac{k_p k_m}{\\gamma_m(\\gamma_m+\\gamma_p)} \\right) + \\frac{k_p k_m}{\\gamma_p \\gamma_m}$.\nWe can factor out $\\frac{k_p k_m}{\\gamma_p \\gamma_m} = \\mathbb{E}[p]$:\n$\\sigma_{pp} = \\frac{k_p k_m}{\\gamma_p \\gamma_m} \\left( \\frac{k_p}{\\gamma_m+\\gamma_p} + 1 \\right) = \\mathbb{E}[p] \\left( 1 + \\frac{k_p}{\\gamma_m+\\gamma_p} \\right)$.\nThis is the steady-state variance of protein counts, $\\operatorname{Var}[p]$.\n\nThe steady-state Fano factor for the protein is $F = \\frac{\\operatorname{Var}[p]}{\\mathbb{E}[p]}$:\n$$ F = \\frac{\\mathbb{E}[p] \\left( 1 + \\frac{k_p}{\\gamma_m+\\gamma_p} \\right)}{\\mathbb{E}[p]} = 1 + \\frac{k_p}{\\gamma_m+\\gamma_p} $$\nThe Fano factor is greater than $1$, indicating that the protein distribution is super-Poissonian (noisier than a Poisson process). This additional noise, often called extrinsic noise in this context, arises from the fluctuations in the number of mRNA molecules, which act as a fluctuating template for protein production.\n\nThe first required quantity is the protein variance:\n$\\operatorname{Var}[p] = \\sigma_{pp} = \\frac{k_p k_m}{\\gamma_p \\gamma_m} \\left( 1 + \\frac{k_p}{\\gamma_m+\\gamma_p} \\right)$.\nThe second required quantity is the Fano factor:\n$F = 1 + \\frac{k_p}{\\gamma_m+\\gamma_p}$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{k_p k_m}{\\gamma_p \\gamma_m} \\left( 1 + \\frac{k_p}{\\gamma_m+\\gamma_p} \\right)  1 + \\frac{k_p}{\\gamma_m+\\gamma_p}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Feedback is a ubiquitous regulatory strategy in biology, but it can also introduce instabilities such as unwanted oscillations or runaway behavior. This exercise uses the Routh-Hurwitz criterion to analyze the stability of a genetic network with positive feedback, a common motif in developmental switches and signaling pathways . By analytically determining the precise conditions under which the system remains stable, you will gain a deeper understanding of how network architecture constrains its dynamic behavior.",
            "id": "3297620",
            "problem": "Consider a three-species regulatory module in a cell comprising messenger ribonucleic acid (mRNA), enzyme (protein), and a downstream metabolite. Near a steady state, linearization of the mass-action ordinary differential equation (ODE) model yields a linear time-invariant (LTI) system for deviations $\\mathbf{x}(t) = (x_{1}(t), x_{2}(t), x_{3}(t))^{\\top}$ of the form $\\dot{\\mathbf{x}}(t) = A \\mathbf{x}(t)$, with Jacobian\n$$\nA \\;=\\;\n\\begin{pmatrix}\n-\\gamma_{m}  0  g \\\\\n\\alpha  -\\gamma_{p}  0 \\\\\n0  \\nu  -\\gamma_{x}\n\\end{pmatrix},\n$$\nwhere $\\gamma_{m} > 0$, $\\gamma_{p} > 0$, and $\\gamma_{x} > 0$ are first-order degradation (or dilution) rates for mRNA, protein, and metabolite, respectively; $\\alpha > 0$ is the translation coupling rate from mRNA to protein; $\\nu > 0$ is the catalytic rate by which protein influences metabolite; and $g \\ge 0$ is the effective linearized strength of a positive transcriptional feedback of the metabolite onto mRNA synthesis. Each parameter has units of inverse time $\\mathrm{s}^{-1}$. Assume all parameters are constant and positive, and that the linearization is valid in the neighborhood of the steady state.\n\nStarting from first principles of linearized dynamics and using the Routh–Hurwitz criterion for third-order polynomials, determine the exact closed-form expression for the largest admissible positive feedback strength $g_{\\max}$ (in $\\mathrm{s}^{-1}$) in terms of $\\gamma_{m}$, $\\gamma_{p}$, $\\gamma_{x}$, $\\alpha$, and $\\nu$ that guarantees the linearized system is asymptotically stable (all eigenvalues of $A$ have strictly negative real parts). Express your final answer as a symbolic formula. No numerical evaluation is required, and no rounding is needed. Use $\\mathrm{s}^{-1}$ as the unit for $g_{\\max}$.",
            "solution": "The problem requires finding the maximum positive feedback strength, denoted as $g_{\\max}$, for which the given linear time-invariant (LTI) system remains asymptotically stable. The system dynamics are described by the ordinary differential equation (ODE) $\\dot{\\mathbf{x}}(t) = A \\mathbf{x}(t)$, where the Jacobian matrix is\n$$\nA \\;=\\;\n\\begin{pmatrix}\n-\\gamma_{m}  0  g \\\\\n\\alpha  -\\gamma_{p}  0 \\\\\n0  \\nu  -\\gamma_{x}\n\\end{pmatrix}\n$$\nThe parameters $\\gamma_{m}, \\gamma_{p}, \\gamma_{x}, \\alpha, \\nu$ are all strictly positive constants, and the feedback strength $g$ is non-negative, i.e., $g \\ge 0$.\n\nFor the system to be asymptotically stable, all eigenvalues of the matrix $A$ must have strictly negative real parts. The eigenvalues, denoted by $\\lambda$, are the roots of the characteristic equation, which is given by $\\det(A - \\lambda I) = 0$, where $I$ is the $3 \\times 3$ identity matrix.\n\nLet us first compute the characteristic polynomial $P(\\lambda) = \\det(A - \\lambda I)$:\n$$\nP(\\lambda) \\;=\\; \\det\n\\begin{pmatrix}\n-\\gamma_{m} - \\lambda  0  g \\\\\n\\alpha  -\\gamma_{p} - \\lambda  0 \\\\\n0  \\nu  -\\gamma_{x} - \\lambda\n\\end{pmatrix}\n$$\nExpanding the determinant along the first row gives:\n$$\nP(\\lambda) \\;=\\; (-\\gamma_{m} - \\lambda) \\begin{vmatrix} -\\gamma_{p} - \\lambda  0 \\\\ \\nu  -\\gamma_{x} - \\lambda \\end{vmatrix} - (0) \\begin{vmatrix} \\alpha  0 \\\\ 0  -\\gamma_{x} - \\lambda \\end{vmatrix} + g \\begin{vmatrix} \\alpha  -\\gamma_{p} - \\lambda \\\\ 0  \\nu \\end{vmatrix}\n$$\n$$\nP(\\lambda) \\;=\\; -(\\lambda + \\gamma_{m}) [(\\lambda + \\gamma_{p})(\\lambda + \\gamma_{x})] + g(\\alpha\\nu)\n$$\n$$\nP(\\lambda) \\;=\\; -(\\lambda + \\gamma_{m}) [\\lambda^2 + (\\gamma_{p} + \\gamma_{x})\\lambda + \\gamma_{p}\\gamma_{x}] + \\alpha\\nu g\n$$\nExpanding this further:\n$$\nP(\\lambda) \\;=\\; -[\\lambda^3 + (\\gamma_{p} + \\gamma_{x})\\lambda^2 + \\gamma_{p}\\gamma_{x}\\lambda + \\gamma_{m}\\lambda^2 + \\gamma_{m}(\\gamma_{p} + \\gamma_{x})\\lambda + \\gamma_{m}\\gamma_{p}\\gamma_{x}] + \\alpha\\nu g\n$$\n$$\nP(\\lambda) \\;=\\; -[\\lambda^3 + (\\gamma_{m} + \\gamma_{p} + \\gamma_{x})\\lambda^2 + (\\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x})\\lambda + \\gamma_{m}\\gamma_{p}\\gamma_{x}] + \\alpha\\nu g\n$$\nThe characteristic equation $P(\\lambda) = 0$ is conventionally written with a leading coefficient of $1$:\n$$\n\\lambda^3 + (\\gamma_{m} + \\gamma_{p} + \\gamma_{x})\\lambda^2 + (\\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x})\\lambda + (\\gamma_{m}\\gamma_{p}\\gamma_x - \\alpha\\nu g) = 0\n$$\nThis is a third-order polynomial of the form $a_3 \\lambda^3 + a_2 \\lambda^2 + a_1 \\lambda + a_0 = 0$, with coefficients:\n- $a_3 = 1$\n- $a_2 = \\gamma_{m} + \\gamma_{p} + \\gamma_{x}$\n- $a_1 = \\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x}$\n- $a_0 = \\gamma_{m}\\gamma_{p}\\gamma_x - \\alpha\\nu g$\n\nTo guarantee asymptotic stability, the Routh-Hurwitz criterion must be satisfied. For a third-order polynomial, the necessary and sufficient conditions are:\n1. $a_3 > 0$\n2. $a_2 > 0$\n3. $a_1 > 0$\n4. $a_0 > 0$\n5. $a_2 a_1 - a_3 a_0 > 0$\n\nLet us examine each condition based on the given parameters:\n1. $a_3 = 1 > 0$. This condition is satisfied.\n2. $a_2 = \\gamma_{m} + \\gamma_{p} + \\gamma_{x}$. Since $\\gamma_{m} > 0$, $\\gamma_{p} > 0$, and $\\gamma_{x} > 0$, their sum is strictly positive. Thus, $a_2 > 0$ is satisfied.\n3. $a_1 = \\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x}$. As all $\\gamma$ parameters are positive, each term in the sum is positive. Thus, $a_1 > 0$ is satisfied.\n4. $a_0 = \\gamma_{m}\\gamma_{p}\\gamma_x - \\alpha\\nu g > 0$. This condition imposes a constraint on $g$. Since $\\alpha > 0$ and $\\nu > 0$, we can solve for $g$:\n$$\n\\alpha\\nu g  \\gamma_{m}\\gamma_{p}\\gamma_{x} \\quad \\implies \\quad g  \\frac{\\gamma_{m}\\gamma_{p}\\gamma_{x}}{\\alpha\\nu}\n$$\n5. $a_2 a_1 - a_3 a_0 > 0$. Substituting the coefficients and $a_3 = 1$:\n$$\n(\\gamma_{m} + \\gamma_{p} + \\gamma_{x})(\\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x}) - (\\gamma_{m}\\gamma_{p}\\gamma_x - \\alpha\\nu g) > 0\n$$\nLet's analyze the product $a_2 a_1$:\n$$\na_2 a_1 = (\\gamma_{m} + \\gamma_{p} + \\gamma_{x})(\\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x})\n$$\nThis expansion yields:\n$$\na_2 a_1 = (\\gamma_m^2\\gamma_p + \\gamma_m\\gamma_p^2) + (\\gamma_m^2\\gamma_x + \\gamma_m\\gamma_x^2) + (\\gamma_p^2\\gamma_x + \\gamma_p\\gamma_x^2) + 3\\gamma_m\\gamma_p\\gamma_x\n$$\nSubstituting this back into the inequality:\n$$\n[(\\gamma_m^2\\gamma_p + \\gamma_m\\gamma_p^2) + \\dots + 3\\gamma_m\\gamma_p\\gamma_x] - \\gamma_{m}\\gamma_{p}\\gamma_x + \\alpha\\nu g > 0\n$$\n$$\n(\\gamma_m^2\\gamma_p + \\gamma_m\\gamma_p^2) + (\\gamma_m^2\\gamma_x + \\gamma_m\\gamma_x^2) + (\\gamma_p^2\\gamma_x + \\gamma_p\\gamma_x^2) + 2\\gamma_m\\gamma_p\\gamma_x + \\alpha\\nu g > 0\n$$\nThe problem states that $\\gamma_m, \\gamma_p, \\gamma_x, \\alpha, \\nu$ are all positive and $g \\ge 0$. Every term in the expression on the left-hand side is therefore non-negative. In fact, the terms involving only $\\gamma$ parameters are strictly positive. The term $\\alpha\\nu g$ is non-negative. Consequently, the sum is strictly positive for any $g \\ge 0$. This means the condition $a_2 a_1 - a_3 a_0 > 0$ is always satisfied for any physically permissible value of $g$.\n\nTherefore, the only condition that constrains the value of $g$ for stability is $a_0 > 0$. For the system to be asymptotically stable, $g$ must satisfy:\n$$\ng  \\frac{\\gamma_{m}\\gamma_{p}\\gamma_{x}}{\\alpha\\nu}\n$$\nThe problem asks for the largest admissible positive feedback strength $g_{\\max}$ that *guarantees* asymptotic stability. This corresponds to the supremum of the interval of values of $g$ for which the system is stable. At the boundary $g = \\frac{\\gamma_{m}\\gamma_{p}\\gamma_{x}}{\\alpha\\nu}$, we have $a_0 = 0$, leading to one eigenvalue being $\\lambda=0$. This renders the system stable in the sense of Lyapunov, but not asymptotically stable. Thus, the strict inequality defines the region of asymptotic stability. The largest admissible value, or the stability boundary, is the supremum.\n\n$$\ng_{\\max} = \\frac{\\gamma_{m}\\gamma_{p}\\gamma_{x}}{\\alpha\\nu}\n$$\nThis expression provides the exact closed-form symbolic formula for the maximum feedback strength.\nThe units of $g_{\\max}$ are $(\\mathrm{s}^{-1} \\cdot \\mathrm{s}^{-1} \\cdot \\mathrm{s}^{-1}) / (\\mathrm{s}^{-1} \\cdot \\mathrm{s}^{-1}) = \\mathrm{s}^{-1}$, which is consistent with the problem statement.",
            "answer": "$$\n\\boxed{\\frac{\\gamma_{m}\\gamma_{p}\\gamma_{x}}{\\alpha\\nu}}\n$$"
        }
    ]
}