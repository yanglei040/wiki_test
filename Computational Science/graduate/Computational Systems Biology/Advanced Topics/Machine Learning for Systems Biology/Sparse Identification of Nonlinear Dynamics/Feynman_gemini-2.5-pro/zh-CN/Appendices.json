{
    "hands_on_practices": [
        {
            "introduction": "SINDy方法的核心是求解一个线性回归问题。该解的可靠性在很大程度上取决于候选库矩阵 $\\Theta$ 的数值属性。一个病态的矩阵会放大噪声，导致系数估计不可靠。本练习  旨在让您亲手实践，探索矩阵条件数 $\\kappa_2(\\Theta)$ 的概念，并展示一个简单而强大的技术——特征缩放——如何能够显著改善问题的数值稳定性。这是任何稳健模型发现中至关重要的预处理步骤。",
            "id": "3349468",
            "problem": "您正在研究特征缩放如何影响非线性动力学稀疏辨识 (SINDy) 中所用库矩阵的数值条件。考虑一个在 $N$ 个点上采样的单一标量状态变量 $\\{x_i\\}_{i=1}^N$。此问题的 SINDy 库包含两个特征：$x$ 和 $x^2$。将库矩阵 $\\Theta(x) \\in \\mathbb{R}^{N \\times 2}$ 定义为\n$$\n\\Theta(x) = \\begin{bmatrix}\nx_1  x_1^2 \\\\\nx_2  x_2^2 \\\\\n\\vdots  \\vdots \\\\\nx_N  x_N^2\n\\end{bmatrix}.\n$$\n$\\Theta(x)$ 的数值条件通过 2-范数条件数来衡量，该条件数由奇异值分解 (SVD) 定义为\n$$\n\\kappa_2(\\Theta) = \\frac{\\sigma_{\\max}(\\Theta)}{\\sigma_{\\min}(\\Theta)},\n$$\n其中 $\\sigma_{\\max}(\\Theta)$ 是最大奇异值，而 $\\sigma_{\\min}(\\Theta)$ 是最小奇异值。较大的 $\\kappa_2(\\Theta)$ 表示病态条件。\n\n为了扩展特征的动态范围并可能改善条件，对输入数据应用标量重缩放：\n$$\nz_i = s \\, x_i, \\quad s = \\frac{1}{\\operatorname{std}(x)},\n$$\n其中 $\\operatorname{std}(x)$ 是样本 $\\{x_i\\}_{i=1}^N$ 的总体标准差，计算时分母为 $N$。构建缩放后的库\n$$\n\\Theta(z) = \\begin{bmatrix}\nz_1  z_1^2 \\\\\nz_2  z_2^2 \\\\\n\\vdots  \\vdots \\\\\nz_N  z_N^2\n\\end{bmatrix}.\n$$\n注意，这是对输入变量的纯粹重缩放，意味着通过对角矩阵 $\\operatorname{diag}(s, s^2)$ 对 $\\Theta(x)$ 进行列式缩放。\n\n任务：\n- 对于每个指定的测试用例，在闭区间 $[a,b]$ 内生成 $N$ 个等间距样本：\n$$\nx_i = a + \\frac{i-1}{N-1}(b-a), \\quad i = 1,2,\\ldots,N,\n$$\n其中 $N \\ge 2$ 且 $a \\le b$。\n- 使用双精度 SVD 计算 $\\kappa_2(\\Theta(x))$ 和 $\\kappa_2(\\Theta(z))$。\n- 确定一个布尔标志 $\\mathrm{improved}$，如果 $\\kappa_2(\\Theta(z))  \\kappa_2(\\Theta(x))$ 则定义为 $\\mathrm{True}$，否则为 $\\mathrm{False}$。\n\n实现细节和约束：\n- 对 $\\operatorname{std}(x)$ 使用分母为 $N$ 的总体标准差。\n- 如果 $\\sigma_{\\min}(\\Theta)$ 在数值上为 $0$，则将条件数视为 $+\\infty$。\n- 所有计算必须使用标准双精度浮点运算进行。\n- 本问题不涉及物理单位。\n- 本问题不涉及角度。\n- 不要将任何值表示为百分比。\n\n测试套件：\n- 用例 A：$a = 0$, $b = 10^{-3}$, $N = 100$。\n- 用例 B：$a = -10^{-3}$, $b = 10^{-3}$, $N = 100$。\n- 用例 C：$a = 0$, $b = 10^{-6}$, $N = 50$。\n- 用例 D：$a = -\\tfrac{1}{2}$, $b = \\tfrac{1}{2}$, $N = 200$。\n\n程序要求输出：\n- 生成单行输出，包含一个用方括号括起来的逗号分隔列表。\n- 对于每个测试用例，按 $A, B, C, D$ 的顺序，依次附加三个值：$\\kappa_2(\\Theta(x))$、$\\kappa_2(\\Theta(z))$ 和布尔值 $\\mathrm{improved}$。\n- 浮点值必须四舍五入到恰好 $6$ 位小数。\n- 因此，最终输出格式为\n$$\n[\\kappa_{A,\\mathrm{raw}},\\kappa_{A,\\mathrm{scaled}},\\mathrm{improved}_A,\\kappa_{B,\\mathrm{raw}},\\kappa_{B,\\mathrm{scaled}},\\mathrm{improved}_B,\\kappa_{C,\\mathrm{raw}},\\kappa_{C,\\mathrm{scaled}},\\mathrm{improved}_C,\\kappa_{D,\\mathrm{raw}},\\kappa_{D,\\mathrm{scaled}},\\mathrm{improved}_D].\n$$",
            "solution": "用户希望分析数据缩放对非线性动力学稀疏辨识 (SINDy) 方法中所用库矩阵数值条件的影响。该问题是自洽的、科学上合理的且适定的。我将着手提供一个解决方案。\n\n问题的核心在于比较两个相关矩阵的 2-范数条件数 $\\kappa_2$。条件数定义为最大奇异值与最小奇异值的比率，即 $\\kappa_2(\\Theta) = \\frac{\\sigma_{\\max}(\\Theta)}{\\sigma_{\\min}(\\Theta)}$，是衡量矩阵对数值误差敏感度的标准度量。大的条件数表示矩阵是病态的，这在诸如求解线性系统等数值计算中可能导致不可靠的结果。\n\n解决此问题的方法涉及针对由参数 $a$、$b$ 和 $N$ 指定的每个测试用例执行一系列明确定义的计算步骤。\n\n首先，我们生成状态变量样本。对于每个测试用例，使用提供的公式在闭区间 $[a,b]$ 上生成 $N$ 个等间距点 $\\{x_i\\}_{i=1}^N$：\n$$\nx_i = a + \\frac{i-1}{N-1}(b-a), \\quad i = 1,2,\\ldots,N\n$$\n这等同于使用像 `numpy.linspace(a, b, N)` 这样的标准数值库函数。生成的样本构成一个向量 $\\mathbf{x} = [x_1, x_2, \\ldots, x_N]^T$。\n\n第二，我们构建未缩放的库矩阵 $\\Theta(\\mathbf{x})$。该矩阵包含在每个样本点上求值的基函数。对于此问题，基函数为 $f_1(x) = x$ 和 $f_2(x) = x^2$。库矩阵 $\\Theta(\\mathbf{x}) \\in \\mathbb{R}^{N \\times 2}$ 由两列构成：向量 $\\mathbf{x}$ 本身，以及其元素逐个平方的向量 $\\mathbf{x}^2 = [x_1^2, x_2^2, \\ldots, x_N^2]^T$。\n$$\n\\Theta(\\mathbf{x}) = \\begin{bmatrix} \\mathbf{x}  \\mathbf{x}^2 \\end{bmatrix}\n$$\n\n第三，我们计算条件数 $\\kappa_2(\\Theta(\\mathbf{x}))$。这需要对 $\\Theta(\\mathbf{x})$ 执行奇异值分解 (SVD)。SVD 提供了奇异值 $\\sigma_1 \\geq \\sigma_2 \\geq \\ldots \\geq 0$。对于我们的 $N \\times 2$ 矩阵（其中 $N \\ge 2$），有两个奇异值，$\\sigma_{\\max} = \\sigma_1$ 和 $\\sigma_{\\min} = \\sigma_2$。然后将条件数计算为它们的比率。根据问题规范，如果 $\\sigma_{\\min}$ 在数值上为零，则条件数被视为无穷大。\n\n第四，我们执行数据缩放。通过将每个样本 $x_i$ 乘以一个缩放因子 $s$，创建数据的缩放版本 $\\mathbf{z}$。\n$$\nz_i = s \\cdot x_i, \\quad \\text{where} \\quad s = \\frac{1}{\\operatorname{std}(\\mathbf{x})}\n$$\n标准差 $\\operatorname{std}(\\mathbf{x})$ 是总体标准差，计算时分母为 $N$：\n$$\n\\operatorname{std}(\\mathbf{x}) = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}, \\quad \\text{where} \\quad \\mu = \\frac{1}{N} \\sum_{i=1}^N x_i\n$$\n这种缩放确保了生成的数据向量 $\\mathbf{z}$ 的总体标准差恰好为 $1$。\n\n第五，我们构建缩放后的库矩阵 $\\Theta(\\mathbf{z})$ 并计算其条件数 $\\kappa_2(\\Theta(\\mathbf{z}))$。其过程与处理 $\\Theta(\\mathbf{x})$ 的过程相同，但使用的是缩放后的数据向量 $\\mathbf{z}$。\n$$\n\\Theta(\\mathbf{z}) = \\begin{bmatrix} \\mathbf{z}  \\mathbf{z}^2 \\end{bmatrix}\n$$\n\n最后，我们确定缩放是否有益。我们定义一个布尔标志 $\\mathrm{improved}$，如果 $\\kappa_2(\\Theta(\\mathbf{z}))  \\kappa_2(\\Theta(\\mathbf{x}))$，则其值为 $\\mathrm{True}$，否则为 $\\mathrm{False}$。\n\n对四个测试用例中的每一个重复此完整过程。将每个用例的结果——$\\kappa_2(\\Theta(\\mathbf{x}))$、$\\kappa_2(\\Theta(\\mathbf{z}))$ 和 $\\mathrm{improved}$——收集起来，并按要求格式化为单个输出字符串。\n\n这种缩放背后的基本原理是减轻因库矩阵各列数量级巨大差异而引起的病态条件。例如，在用例 A ($[0, 10^{-3}]$) 和 C ($[0, 10^{-6}]$) 中，第一列 ($x$) 的值很小，而第二列 ($x^2$) 的值要小几个数量级。这种尺度上的差异通常会导致非常大的条件数。通过缩放数据使得 $\\operatorname{std}(\\mathbf{z})=1$，我们将状态变量置于一个“自然”的单位系统中。这倾向于平衡最终库矩阵各列（例如 $\\mathbf{z}$ 和 $\\mathbf{z}^2$）的范数，从而降低条件数。对于所有测试用例，包括那些数据居中的用例（用例 B 和 D），这种缩放预计都将改善条件，从而得到 $\\mathrm{improved} = \\mathrm{True}$。实现将使用 `numpy` 进行所有数值计算，利用其双精度浮点算术和优化的线性代数例程。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and compares condition numbers of SINDy library matrices\n    before and after feature scaling for four test cases.\n    \"\"\"\n\n    def get_condition_number(data_vector: np.ndarray) -> float:\n        \"\"\"\n        Constructs a library matrix from a data vector and computes its 2-norm\n        condition number using SVD.\n        \n        Args:\n            data_vector: A 1D numpy array of state variable samples.\n\n        Returns:\n            The condition number of the library matrix. Returns np.inf if the\n            matrix is singular.\n        \"\"\"\n        # Problem constraints ensure data_vector.size >= 2\n        \n        # Construct the library matrix from columns [v, v^2]\n        library_matrix = np.stack([data_vector, data_vector**2], axis=1)\n        \n        # Calculate singular values. SVD returns them in descending order.\n        singular_values = np.linalg.svd(library_matrix, compute_uv=False)\n        \n        sigma_max = singular_values[0]\n        # For an N x 2 matrix, there are 2 singular values.\n        sigma_min = singular_values[1]\n        \n        # Per problem spec, if sigma_min is numerically 0, kappa is +inf.\n        # We use a small epsilon for a robust floating-point comparison.\n        if sigma_min  np.finfo(np.float64).eps:\n            return np.inf\n        \n        return sigma_max / sigma_min\n\n    # Test cases defined in the problem statement\n    test_cases = [\n        # (a, b, N)\n        (0.0, 1e-3, 100),       # Case A\n        (-1e-3, 1e-3, 100),    # Case B\n        (0.0, 1e-6, 50),       # Case C\n        (-0.5, 0.5, 200),      # Case D\n    ]\n\n    all_results = []\n    for a, b, N in test_cases:\n        # Generate N equally spaced samples in [a, b] using double precision\n        x = np.linspace(a, b, N, dtype=np.float64)\n\n        # Calculate condition number for the unscaled (raw) library matrix\n        kappa_x = get_condition_number(x)\n\n        # Calculate the population standard deviation of x.\n        # numpy.std defaults to ddof=0, which corresponds to the denominator N.\n        std_x = np.std(x)\n\n        kappa_z = np.inf\n        # Scale the data only if it has a non-zero standard deviation.\n        # This avoids division by zero if all samples are identical (a=b).\n        if std_x > np.finfo(np.float64).eps:\n            s = 1.0 / std_x\n            z = s * x\n            # Calculate condition number for the scaled library matrix\n            kappa_z = get_condition_number(z)\n\n        # Determine if scaling improved the condition number\n        improved = kappa_z  kappa_x\n\n        # Append formatted results for this case to the list\n        all_results.append(f\"{kappa_x:.6f}\")\n        all_results.append(f\"{kappa_z:.6f}\")\n        all_results.append(str(improved))\n\n    # Print the final output in the specified single-line format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了数值条件的概念后，我们现在可以构建一个完整的端到端SINDy工作流。本练习  将让您沉浸于一个典型的系统生物学任务中：从带噪声的模拟时间序列数据中揭示细胞种群的控制动态。您将实现从生成具有阿利效应（Allee effect）的种群数据，到从噪声测量中稳健地估计导数，最后应用稀疏回归发现潜在的稀疏非线性模型结构的整个流程。",
            "id": "3349431",
            "problem": "本任务要求您实现一个完整的程序，该程序在计算系统生物学领域中，对一个单变量细胞种群模型执行非线性动力学的稀疏辨识 (SINDy)。假设未知动力学由一个关于种群密度的平滑函数控制，其机理图景是低密度下的合作与高密度下的拥挤共同决定了净增长率。您必须使用从此机理图景模拟出的时间序列数据，推导出一个数据驱动的、稀疏的、最高为三次方的状态多项式模型，然后评估所辨识的稀疏模型是否与不同扰动水平下由底层生死过程所蕴含的预期三次典范形式一致。程序必须是自包含的，并且无需用户输入即可运行。\n\n基本假设：\n- 设 $x(t)$ 表示无量纲细胞密度，$t$ 表示时间，单位为秒。\n- 种群动力学遵循 $\\frac{dx}{dt} = f(x)$，其中 $f$ 是一个确定性的平滑函数，并且在感兴趣的范围内，一个最高为三次的多项式近似是有效的低阶代理模型。\n- 稀疏建模方法旨在通过从一个候选库中选择一个最小的活性项集合，来寻求 $f$ 的一个数据驱动的简约表示。\n- 候选特征库被限制为三个多项式项 $\\{x, x^2, x^3\\}$。\n\n要求的建模流程：\n1. 从一个机理上合理的、同时存在低密度合作和高密度拥挤的增长模型中，模拟时间序列数据 $\\{t_i, x_i\\}_{i=0}^{N-1}$。机理参数包括内禀增长率 $r$、环境承载力 $K$ 和一个合作阈值 $A$ (阿利阈值)，每个参数都严格为正。使用真实动力学生成 $x(t)$，然后对观测值 $x(t)$ 施加指定标准差的附加零均值高斯噪声，以模拟测量噪声。\n2. 使用适用于含噪数据的数值稳定微分器，从含噪观测值中估计 $\\frac{dx}{dt}$。您可以使用具有可调窗口长度和多项式阶数的多项式平滑微分器。\n3. 从平滑后的 $x(t)$ 构建以 $x$、$x^2$ 和 $x^3$ 为列的设计矩阵，并执行序列阈值最小二乘法以获得稀疏系数向量 $\\boldsymbol{\\theta} = [\\theta_1,\\theta_2,\\theta_3]^\\top$，使得\n$$\n\\frac{dx}{dt} \\approx \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3.\n$$\n序列阈值处理过程必须迭代地移除幅值低于指定阈值的系数，并在剩余的活性集上重新拟合，直到收敛或达到最大迭代次数。\n\n每个测试用例的评估标准：\n- 通过展开由 $(r,K,A)$ 表征的合作与拥挤效应组合所产生的典范三次增长，解析地计算真实系数 $\\boldsymbol{\\theta}^{\\star}$。该展开基于一个第一性原理的生死过程公式，其中合作性出生受拥挤限制，竞争性损失随密度增加。\n- 使用由下式定义的逐分量相对误差，将辨识出的系数 $\\boldsymbol{\\theta}$ 与 $\\boldsymbol{\\theta}^{\\star}$ 进行比较\n$$\n\\varepsilon_j = \\frac{|\\theta_j - \\theta_j^{\\star}|}{\\max\\{10^{-12}, |\\theta_j^{\\star}|\\}}, \\quad j \\in \\{1,2,3\\}.\n$$\n- 为每个测试用例报告一个布尔值，该值指示是否所有三个系数都满足 $\\varepsilon_j \\leq \\text{tol}$ (对于指定的容差)，并且其符号与 $\\theta_j^{\\star}$ 的符号相同。\n\n单位：\n- 时间 $t$ 的单位必须是秒。状态 $x$ 是无量纲的。不使用角度单位。\n\n您的程序必须实现以下测试套件。对于每个元组，参数为 $(r, K, A, x_0, T, \\Delta t, \\sigma, \\lambda, \\text{tol}, \\alpha)$，其中 $x_0$ 是初始条件，$T$ 是总模拟时间（秒），$\\Delta t$ 是采样间隔（秒），$\\sigma$ 是 $x$ 上的附加高斯噪声的标准差，$\\lambda$ 是序列阈值最小二乘法的阈值，$\\text{tol}$ 是用于接受的相对误差容差，$\\alpha$ 是用于选择平滑窗口长度的样本数量的分数（窗口长度必须是奇数并与样本大小相适应）。\n- 测试用例 1 (理想路径，低噪声): $(1.0, 1.0, 0.2, 0.05, 8.0, 0.01, 0.001, 1\\times 10^{-3}, 0.05, 0.07)$。\n- 测试用例 2 (较高噪声): $(0.8, 1.5, 0.4, 0.02, 8.0, 0.01, 0.02, 5\\times 10^{-3}, 0.15, 0.11)$。\n- 测试用例 3 (更稀疏的采样和近阈值初始化): $(1.2, 1.0, 0.8, 0.9, 6.0, 0.05, 0.005, 2\\times 10^{-3}, 0.10, 0.21)$。\n- 测试用例 4 (边界挑战，弱吸引): $(0.4, 1.0, 0.95, 0.96, 10.0, 0.02, 0.01, 3\\times 10^{-3}, 0.20, 0.15)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，\"[result1,result2,result3,result4]\"），其中每个“result”是根据上述描述计算的相应测试用例的布尔接受值。",
            "solution": "我们从一个有原则的生死过程图景中推导辨识策略，在该图景中，低密度下的合作和高密度下的拥挤结合成一个净增长定律。设 $x(t)$ 为充分混合环境中的无量纲细胞密度，并设 $\\frac{dx}{dt} = f(x)$ 是平滑的。其机理是：人均出生率最初因合作而随密度上升，但在高密度时受拥挤限制；而人均损失率因竞争而随密度增加。一个能同时捕捉这两种效应的常用典范形式是三个因子的乘积：一个与密度 $x$ 成正比的因子，一个形式为 $(1 - x/K)$ 的限制项（捕捉了环境承载力 $K$），以及一个合作项 $(x/A - 1)$（引入了一个阈值 $A$，即阿利阈值），低于此阈值净增长变为负值。\n\n基于此机理，我们考虑典范增长定律\n$$\n\\frac{dx}{dt} = r\\,x\\,(1 - x/K)\\,(x/A - 1),\n$$\n其中 $r0$ 是内禀增长率，$K0$ 是环境承载力，$A0$ 是合作阈值。尽管问题描述没有指定目标公式，但上述形式是从一个基本假设推导出来的，即净增长是密度、拥挤限制因子和合作因子的乘积，并且它是一个经过充分检验的阿利效应模型。\n\n为了使用非线性动力学的稀疏辨识 (SINDy) 拟合一个稀疏模型，我们构建一个包含三个单项式 $\\{x, x^2, x^3\\}$ 的候选函数库，并寻求系数 $\\boldsymbol{\\theta} = [\\theta_1,\\theta_2,\\theta_3]^\\top$ 使得\n$$\n\\frac{dx}{dt} \\approx \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3.\n$$\n展开机理定律可以得到这个三次表示中的显式系数。首先，展开乘积\n$$\n(1 - x/K)\\,(x/A - 1) = \\frac{x}{A} - 1 - \\frac{x^2}{A K} + \\frac{x}{K} = \\left(\\frac{1}{A} + \\frac{1}{K}\\right)x - 1 - \\frac{x^2}{A K}.\n$$\n乘以 $r x$ 得到\n$$\n\\frac{dx}{dt} = r\\,x\\left[\\left(\\frac{1}{A} + \\frac{1}{K}\\right)x^2 - x - \\frac{x^2}{A K}\\right]\n= r\\left[\\left(\\frac{1}{A} + \\frac{1}{K}\\right)x^2 - x - \\frac{1}{A K}x^3\\right].\n$$\n因此，真实的三次系数为\n$$\n\\theta_1^{\\star} = -r, \\quad \\theta_2^{\\star} = r\\left(\\frac{1}{A} + \\frac{1}{K}\\right), \\quad \\theta_3^{\\star} = -\\frac{r}{A K}.\n$$\n\n算法设计：\n1. 数据生成。对于给定的 $(r,K,A,x_0)$，我们使用指定的采样间隔 $\\Delta t$ 在 $t \\in [0,T]$ 上模拟确定性系统 $\\frac{dx}{dt} = r\\,x\\,(1 - x/K)\\,(x/A - 1)$，初始条件为 $x(0)=x_0$。我们使用一个高阶积分器。观测到的轨迹受到施加在 $x$ 上的标准差为 $\\sigma$ 的附加零均值高斯噪声的污染，以模拟测量噪声。这在生物测量中是现实的，因为计数误差和荧光强度会在观测密度中引入噪声。\n\n2. 从含噪数据中估计导数。直接有限差分会放大噪声。一个经过充分检验的方法是使用多项式平滑微分器，例如 Savitzky–Golay 滤波器，它在一个移动窗口上拟合一个选定阶数的局部多项式，以同时生成平滑信号及其导数。我们通过一个分数 $\\alpha$ 和固定的多项式阶数，选择一个与样本数量成比例的奇数窗口长度，以确保窗口的可行性。这为回归分析生成了关于 $\\frac{dx}{dt}$ 和 $x$ 的鲁棒估计。\n\n3. 使用序列阈值最小二乘法进行稀疏辨识。设 $\\Theta(x)$ 是由平滑信号构建的、列为 $[x, x^2, x^3]$ 的设计矩阵。初始的最小二乘拟合\n$$\n\\boldsymbol{\\theta}^{(0)} = \\arg\\min_{\\boldsymbol{\\theta}}\\|\\Theta \\boldsymbol{\\theta} - \\dot{x}\\|_2^2\n$$\n然后被迭代地稀疏化：对于一个阈值 $\\lambda  0$，我们将满足 $|\\theta_j^{(k)}|  \\lambda$ 的项设为零，并仅对活性集进行重新拟合。重复此过程会产生一个简约模型，该模型能抑制由噪声和过拟合引入的虚假小系数。\n\n4. 与真实值进行评估。对于每个测试用例，我们计算解析的三次系数 $\\boldsymbol{\\theta}^{\\star} = [-r,\\; r(1/A + 1/K),\\; -r/(A K)]^\\top$。如果对于所有分量 $j \\in \\{1,2,3\\}$，相对误差\n$$\n\\varepsilon_j = \\frac{|\\theta_j - \\theta_j^{\\star}|}{\\max\\{10^{-12},|\\theta_j^{\\star}|\\}}\n$$\n小于或等于指定的容差，并且 $\\theta_j$ 的符号与 $\\theta_j^{\\star}$ 的符号相匹配，则辨识出的系数被接受。符号检查确保推断出的模型保留了机理上的增减方向性：抑制性线性项 ($\\theta_1^{\\star}  0$)、促进性二次项 ($\\theta_2^{\\star}  0$，源于合作与拥挤的结合)，以及抑制性三次项 ($\\theta_3^{\\star}  0$，源于拥挤饱和)。\n\n测试套件覆盖范围：\n- 第一个案例是具有低噪声和密集采样的标称场景，期望能够直接恢复模型。\n- 第二个案例增加了测量噪声，需要鲁棒的平滑和阈值处理；容差也相应放宽。\n- 第三个案例使用更稀疏的采样，并在合作阈值附近初始化，强调了在更窄的动态范围内进行正确微分和保证模型可辨识性的重要性。\n- 第四个案例是一个边界挑战，其中 $A$ 接近 $K$，初始条件接近 $K$，这降低了合作因子的信号幅度，对可辨识性提出了挑战；容差也相应放宽。\n\n实现细节：\n- 使用一个可靠的常微分方程求解器来生成干净的轨迹。\n- 使用 Savitzky–Golay 滤波器进行平滑和导数估计，其奇数窗口长度为 $w = \\max\\{w_{\\min}, 2\\lfloor(\\alpha N)/2\\rfloor + 1\\}$，并被裁剪以适应数据长度，其中 $N$ 是样本数量，$w_{\\min}$ 确保多项式的可行性。\n- 实现序列阈值最小二乘法，设置固定的最大迭代次数，并以活性集的稳定性作为收敛判据。\n- 通过固定随机数生成器种子来确保可复现性。\n\n最终程序计算四个测试用例的接受布尔值，并以指定的单行格式打印它们。",
            "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom scipy.signal import savgol_filter\n\n# Seed the random number generator for reproducibility\nrng = np.random.default_rng(42)\n\ndef logistic_allee_rhs(t, x, r, K, A):\n    # x may be array; ensure element-wise computation\n    return r * x * (1.0 - x / K) * (x / A - 1.0)\n\ndef simulate_time_series(r, K, A, x0, T, dt):\n    # Solve the ODE dx/dt = r x (1 - x/K)(x/A - 1) from t=0 to t=T\n    t_eval = np.arange(0.0, T + 1e-12, dt)\n    sol = solve_ivp(fun=lambda t, y: logistic_allee_rhs(t, y, r, K, A),\n                    t_span=(0.0, T),\n                    y0=[x0],\n                    t_eval=t_eval,\n                    method='RK45',\n                    rtol=1e-8,\n                    atol=1e-10)\n    t = sol.t\n    x = sol.y[0]\n    return t, x\n\ndef add_noise(x, sigma):\n    if sigma == 0.0:\n        return x.copy()\n    noise = rng.normal(loc=0.0, scale=sigma, size=x.shape)\n    return x + noise\n\ndef choose_window_length(n, alpha, polyorder):\n    # Compute an odd window length proportional to sample size,\n    # clipped to be feasible for Savitzky-Golay\n    # Start from alpha*n rounded to nearest odd\n    wlen = int(max(5, int(n * alpha)))\n    # Enforce odd\n    if wlen % 2 == 0:\n        wlen += 1\n    # Minimum window for polyorder\n    min_wlen = polyorder + 3\n    if min_wlen % 2 == 0:\n        min_wlen += 1\n    if wlen  min_wlen:\n        wlen = min_wlen\n    # Clip to data length - must be = n\n    if wlen > n:\n        wlen = n - 1 if (n - 1) % 2 == 1 else n - 2\n    # Final guard: ensure odd and at least polyorder+2\n    if wlen % 2 == 0:\n        wlen -= 1\n    if wlen  polyorder + 2:\n        wlen = polyorder + 3\n        if wlen % 2 == 0:\n            wlen += 1\n        if wlen > n:\n            wlen = n - 1 if (n - 1) % 2 == 1 else n - 2\n    return max(5, wlen)\n\ndef estimate_derivative(y, dt, alpha, polyorder=3):\n    n = len(y)\n    wlen = choose_window_length(n, alpha, polyorder)\n    # Smooth signal\n    y_smooth = savgol_filter(y, window_length=wlen, polyorder=polyorder, deriv=0)\n    # Derivative\n    dy_dt = savgol_filter(y, window_length=wlen, polyorder=polyorder, deriv=1, delta=dt)\n    return y_smooth, dy_dt\n\ndef stlsq(Theta, ydot, threshold, max_iter=10, rcond=None):\n    # Sequential thresholded least squares\n    # Initial least squares\n    coef, *_ = np.linalg.lstsq(Theta, ydot, rcond=rcond)\n    active = np.ones_like(coef, dtype=bool)\n    for _ in range(max_iter):\n        # Threshold small coefficients\n        new_active = np.abs(coef) >= threshold\n        # If active set hasn't changed, break\n        if np.array_equal(new_active, active):\n            break\n        active = new_active\n        if not np.any(active):\n            coef[:] = 0.0\n            break\n        # Refit on active set\n        Theta_active = Theta[:, active]\n        coef_active, *_ = np.linalg.lstsq(Theta_active, ydot, rcond=rcond)\n        # Update coefficients\n        coef = np.zeros_like(coef)\n        coef[active] = coef_active\n    return coef\n\ndef true_coefficients(r, K, A):\n    # From expansion: dx/dt = (-r) x + r(1/A + 1/K) x^2 + ( - r/(A K) ) x^3\n    return np.array([-r, r * (1.0 / A + 1.0 / K), -r / (A * K)], dtype=float)\n\ndef run_case(params):\n    r, K, A, x0, T, dt, sigma, lam, tol, alpha = params\n    # Simulate clean dynamics\n    t, x_clean = simulate_time_series(r, K, A, x0, T, dt)\n    # Add measurement noise\n    x_noisy = add_noise(x_clean, sigma)\n    # Estimate derivative from noisy data\n    x_smooth, dxdt_est = estimate_derivative(x_noisy, dt, alpha=alpha, polyorder=3)\n    # Build library Theta = [x, x^2, x^3]\n    Theta = np.column_stack([x_smooth, x_smooth**2, x_smooth**3])\n    # Fit sparse model\n    theta_hat = stlsq(Theta, dxdt_est, threshold=lam, max_iter=10, rcond=None)\n    # Ground-truth coefficients\n    theta_true = true_coefficients(r, K, A)\n    # Relative errors and sign checks\n    denom = np.maximum(1e-12, np.abs(theta_true))\n    rel_err = np.abs(theta_hat - theta_true) / denom\n    signs_match = np.all(np.sign(theta_hat) == np.sign(theta_true))\n    accepted = bool(np.all(rel_err = tol) and signs_match)\n    return accepted\n\ndef solve():\n    # Define the test cases from the problem statement:\n    # (r, K, A, x0, T, dt, sigma, lambda, tol, alpha)\n    test_cases = [\n        (1.0, 1.0, 0.2, 0.05, 8.0, 0.01, 0.001, 1e-3, 0.05, 0.07),\n        (0.8, 1.5, 0.4, 0.02, 8.0, 0.01, 0.02, 5e-3, 0.15, 0.11),\n        (1.2, 1.0, 0.8, 0.9, 6.0, 0.05, 0.005, 2e-3, 0.10, 0.21),\n        (0.4, 1.0, 0.95, 0.96, 10.0, 0.02, 0.01, 3e-3, 0.20, 0.15),\n    ]\n    results = []\n    for case in test_cases:\n        res = run_case(case)\n        results.append(res)\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "成功辨识出一个与数据拟合的稀疏模型是重要的一步，但这是否保证我们找到了唯一真实的底层机制？最后一个练习  探讨了模型可辨识性与观测等价性这一深刻的概念性挑战。通过这个练习，您将展示两个结构上完全不同的模型如何在有限的实验方案下产生相同的输出，然后设计新的实验策略来打破这种模糊性，从而揭示实验设计与成功进行系统辨识之间密不可分的关系。",
            "id": "3349463",
            "problem": "考虑一个单一测量的分子种类，其浓度表示为 $y(t)$，受外部诱导物输入 $u(t)$ 的影响，其中 $t$ 是以秒为单位的时间。假设其动力学由确定性常微分方程 (ODE) 控制，该方程源于净生成减去降解，这是化学动力学和基因调控中的一个标准假设：$y$ 的变化率等于生成项之和减去降解项之和。在非线性动力学的稀疏辨识 (SINDy) 框架下，$f(y,u)$ 的候选函数库包含低阶多项式和交互项的稀疏组合。如果两个模型的支撑集（即具有非零系数的活动库项的集合）不同，则这两个模型是非同构的。\n\n您必须构建和分析两个稀疏模型，每个模型都使用相同的候选函数库表示为 $y(t)$ 的 ODE，但具有不同的支撑集，并证明它们在指定的实验方案下是观测等价的。然后，您必须模拟对该方案的拟议更改，以打破这种观测等价性。观测等价性意味着模型 A 和 B 的测量轨迹 $y_A(t)$ 和 $y_B(t)$ 在实验窗口内在指定容差范围内是无法区分的。\n\n使用以下数学上指定的设置：\n\n- 候选库 $\\Theta(y,u)$ 包含项 $\\{y, y^3, u, y\\,u\\}$。\n- 定义模型 A，其稀疏右侧项为\n$$\\frac{dy}{dt} = -\\delta\\,y + \\alpha\\,u + \\beta\\,y^3,$$\n并定义模型 B，其稀疏右侧项为\n$$\\frac{dy}{dt} = -\\delta\\,y + \\alpha\\,u + \\gamma\\,y\\,u.$$\n- 参数固定为 $ \\delta = 0.5 $ (每秒)，$ \\alpha = 1.0 $ (任意单位/秒)，$ \\beta = 0.1 $ (每秒每 $(\\text{任意单位})^2$)，以及 $ \\gamma = 0.2 $ (每秒)。输入 $u(t)$ 是无量纲的。浓度 $y$ 的单位为任意单位 (a.u.)。时间单位为秒。对于正弦输入，角频率 $ \\omega $ 必须以弧度/秒为单位指定。\n- 实验方案 $\\mathcal{P}_0$ (基线等价性)：$y(0)=0$ 且对于所有 $t \\in [0,T]$，$u(t)=0$，其中 $T=10$ 秒。\n- 定义观测等价性容差为 $ \\varepsilon = 10^{-12} $ (a.u. 单位)。\n\n您的任务是编写一个完整的、可运行的程序，在以下五个协议（测试套件）下对两个模型进行数值模拟，计算时间窗口内轨迹 $y_A(t)$ 和 $y_B(t)$ 之间的均方根误差 (RMSE)，并汇总结果：\n\n1. 方案 $\\mathcal{P}_0$：$y(0)=0$, $u(t)=0$, $t \\in [0, T]$，其中 $T=10$ 秒。输出一个布尔值，指示 RMSE 是否小于或等于 $ \\varepsilon $（即观测等价性成立）。\n2. 方案 $\\mathcal{P}_1$：$y(0)=10^{-3}$, $u(t)=0$, $t \\in [0, T]$，其中 $T=10$ 秒。以浮点数形式输出 RMSE，单位为 a.u.。\n3. 方案 $\\mathcal{P}_2$：$y(0)=0$, $u(t)=10^{-3}$ (常数), $t \\in [0, T]$，其中 $T=10$ 秒。以浮点数形式输出 RMSE，单位为 a.u.。\n4. 方案 $\\mathcal{P}_3$：$y(0)=0.5$, $u(t)=0$, $t \\in [0, T]$，其中 $T=10$ 秒。以浮点数形式输出 RMSE，单位为 a.u.。\n5. 方案 $\\mathcal{P}_4$：$y(0)=0.1$, $u(t)=\\sin(\\omega t)$，其中 $ \\omega = 1 $ 弧度/秒, $t \\in [0, T]$，其中 $T=10$ 秒。以浮点数形式输出 RMSE，单位为 a.u.。\n\n数值模拟要求：\n- 在 $[0, T]$ 上的 $N=1001$ 个点的均匀时间网格上求解每个初值问题。\n- 使用适合光滑右侧项的高精度 ODE 积分器。\n- 使用以下公式计算 RMSE\n$$\\mathrm{RMSE} = \\sqrt{\\frac{1}{N}\\sum_{k=1}^{N}\\left(y_A(t_k) - y_B(t_k)\\right)^2},$$\n以 a.u. 为单位表示。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为上述五个协议的结果，顺序完全一致，第一个元素为布尔值，其余四个为浮点数（例如，$ [ \\text{True}, 0.00123, 0.0456, 0.78, 0.12 ]$）。所有基于 $y$ 的数值输出必须以任意单位 (a.u.) 为单位，时间以秒为单位。正弦输入使用弧度/秒作为 $ \\omega $ 的单位。",
            "solution": "该问题是有效的。它具有科学依据、提法恰当、客观，并为计算系统生物学中的一个数值实验提供了完整且一致的设置。任务是分析两种不同的非线性动力学模型在各种实验方案下的观测等价性，这是系统辨识和模型验证中的一个核心概念。\n\n解决方案首先分析观测等价性的条件，然后实施数值模拟，以量化在旨在打破这种等价性的方案下模型之间的差异。\n\n所考虑的系统是受外部输入 $u(t)$ 影响的单一分子种类，其浓度为 $y(t)$。其动力学由形式为 $\\frac{dy}{dt} = f(y, u)$ 的常微分方程 (ODE) 描述。\n\n提出的两个模型，模型 A 和模型 B，是在非线性动力学的稀疏辨识 (SINDy) 框架内从候选库 $\\Theta(y,u) = \\{y, y^3, u, y\\,u\\}$ 中推导出来的。它们的控制方程是：\n- **模型 A**:\n$$\n\\frac{dy_A}{dt} = -\\delta\\,y_A + \\alpha\\,u + \\beta\\,y_A^3\n$$\n- **模型 B**:\n$$\n\\frac{dy_B}{dt} = -\\delta\\,y_B + \\alpha\\,u + \\gamma\\,y_B\\,u\n$$\n\n这两个模型共享线性项 ($-\\delta y$ 和 $\\alpha u$)，但它们的非线性项不同：模型 A 具有一个立方自相互作用项 ($\\beta y_A^3$)，而模型 B 有一个与输入相互作用的双线性项 ($\\gamma y_B u$)。给定的参数为 $\\delta = 0.5\\,\\text{s}^{-1}$，$\\alpha = 1.0\\,\\text{a.u.}\\cdot\\text{s}^{-1}$，$\\beta = 0.1\\,\\text{s}^{-1}\\cdot\\text{a.u.}^{-2}$，以及 $\\gamma = 0.2\\,\\text{s}^{-1}$。\n\n问题的核心是研究五个实验方案（$\\mathcal{P}_0$ 到 $\\mathcal{P}_4$），并确定所得轨迹 $y_A(t)$ 和 $y_B(t)$ 是否是观测等价的。\n\n**方案 $\\mathcal{P}_0$：基线等价性**\n该方案指定了初始条件 $y(0) = 0$ 和在所有时间 $t \\in [0, T]$（其中 $T=10$ 秒）内的零输入 $u(t) = 0$。\n对于模型 A，ODE 变为：\n$$\n\\frac{dy_A}{dt} = -\\delta\\,y_A + \\alpha(0) + \\beta\\,y_A^3 = -0.5\\,y_A + 0.1\\,y_A^3\n$$\n在初始条件 $y_A(0) = 0$ 下，很明显 $y_A(t) = 0$ 是一个不动点。由于方程右侧是局部利普希茨连续的，该初值问题的解是唯一的。因此，对于所有 $t \\geq 0$，$y_A(t) = 0$。\n对于模型 B，ODE 变为：\n$$\n\\frac{dy_B}{dt} = -\\delta\\,y_B + \\alpha(0) + \\gamma\\,y_B(0) = -0.5\\,y_B\n$$\n在初始条件 $y_B(0) = 0$ 下，唯一解同样是对于所有 $t \\geq 0$，$y_B(t) = 0$。\n由于在整个时间过程中 $y_A(t) = y_B(t) = 0$，均方根误差 (RMSE) 为：\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{N}\\sum_{k=1}^{N}\\left(0 - 0\\right)^2} = 0\n$$\n该值小于指定的容差 $\\varepsilon = 10^{-12}$，因此在方案 $\\mathcal{P}_0$ 下，这两个模型是观测等价的。这展示了系统辨识中的一个关键挑战：不够丰富的实验方案可能无法区分结构上不同的模型。\n\n**方案 $\\mathcal{P}_1$ - $\\mathcal{P}_4$：打破等价性**\n这些方案旨在激活不同的非线性项，从而打破等价性。需要采用数值方法来求解非线性 ODE，并量化它们轨迹之间的差异。\n\n数值模拟将使用高精度方法进行。`scipy.integrate.solve_ivp` 函数实现了诸如 5(4) 阶显式龙格-库塔法 (`RK45`) 之类的方法，非常适合求解这些光滑、非刚性的 ODE。我们将在从 $t=0$ 到 $t=10$ 秒的 $N=1001$ 个点的均匀时间网格上求解每个初值问题。\n\n- **对于方案 $\\mathcal{P}_1$ ($y(0)=10^{-3}, u(t)=0$)：** 输入 $u(t)$ 为零，因此 ODE 简化为 $\\frac{dy_A}{dt} = -0.5\\,y_A + 0.1\\,y_A^3$ 和 $\\frac{dy_B}{dt} = -0.5\\,y_B$。模型 A 中存在 $\\beta y_A^3$ 项，而模型 B 中没有，这将导致它们的轨迹从共同的非零初始条件开始发散。\n- **对于方案 $\\mathcal{P}_2$ ($y(0)=0, u(t)=10^{-3}$):** 两个模型都由常数输入 $u(t) = 10^{-3}$ 驱动。在 $t=0$ 时，两个 $\\frac{dy}{dt}$ 都等于 $\\alpha u = 1.0 \\times 10^{-3}$。然而，随着 $y(t)$ 变为非零，非线性项 $\\beta y_A^3$ 和 $\\gamma y_B u$ 将被激活。由于 $u$ 是常数，模型 B 中的项 ($\\gamma y_B u$) 将随 $y_B$ 线性增长，而模型 A 中的项 ($\\beta y_A^3$) 将随 $y_A$ 立方增长。这种函数形式的差异将导致轨迹发散。\n- **对于方案 $\\mathcal{P}_3$ ($y(0)=0.5, u(t)=0$):** 这与 $\\mathcal{P}_1$ 类似，但初始条件大得多。立方项 $\\beta y_A^3$ 的贡献对 $y_A$ 的大小高度敏感。更大的 $y_A(0)$ 将导致该项产生更大的初始效应，与 $\\mathcal{P}_1$ 相比，会产生显著更大的 RMSE。\n- **对于方案 $\\mathcal{P}_4$ ($y(0)=0.1, u(t)=\\sin(\\omega t)$ 且 $\\omega=1$):** 该方案涉及非零初始条件和时变输入。两个不同的非线性项 $\\beta y_A^3$ 和 $\\gamma y_B u$ 都将被激活并随时间变化。正弦输入提供了一个丰富的激励信号，它将持续探测两个模型不同的动态响应，从而揭示出显著的差异。\n\n接下来的程序实现了这一策略。它为两个模型的 ODE 右侧项定义了函数。然后，它依次执行五个协议中的每一个，为每个模型调用 `solve_ivp`，计算所得轨迹 $y_A(t_k)$ 和 $y_B(t_k)$ 之间的 RMSE，并按规定格式化结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Simulates two SINDy-identified models under five experimental protocols\n    to test for observational equivalence and computes the RMSE between their\n    trajectories.\n    \"\"\"\n\n    # Define model parameters\n    delta = 0.5  # Degradation rate (per second)\n    alpha = 1.0  # Input-driven production rate (a.u. per second)\n    beta = 0.1   # Cubic self-interaction rate (per second per a.u.^2)\n    gamma = 0.2  # Bilinear interaction rate (per second)\n\n    # General simulation settings\n    sim_time = 10.0  # Total simulation time in seconds\n    num_points = 1001  # Number of points in the time grid\n    equivalence_tolerance = 1e-12  # Tolerance for observational equivalence\n\n    # Define the right-hand side (RHS) of the ODE for Model A\n    def model_A_rhs(t, y, u_func):\n        \"\"\"RHS for dy/dt = -delta*y + alpha*u + beta*y^3.\"\"\"\n        y_val = y[0]\n        u_val = u_func(t)\n        return [-delta * y_val + alpha * u_val + beta * y_val**3]\n\n    # Define the RHS of the ODE for Model B\n    def model_B_rhs(t, y, u_func):\n        \"\"\"RHS for dy/dt = -delta*y + alpha*u + gamma*y*u.\"\"\"\n        y_val = y[0]\n        u_val = u_func(t)\n        return [-delta * y_val + alpha * u_val + gamma * y_val * u_val]\n\n    # Define the five experimental protocols (test suite)\n    protocols = [\n        {'id': 'P0', 'y0': [0.0], 'u_func': lambda t: 0.0},\n        {'id': 'P1', 'y0': [1e-3], 'u_func': lambda t: 0.0},\n        {'id': 'P2', 'y0': [0.0], 'u_func': lambda t: 1e-3},\n        {'id': 'P3', 'y0': [0.5], 'u_func': lambda t: 0.0},\n        {'id': 'P4', 'y0': [0.1], 'u_func': lambda t: np.sin(1.0 * t)},\n    ]\n\n    results = []\n    \n    # Common time span and evaluation points for all protocols\n    t_span = [0, sim_time]\n    t_eval = np.linspace(0, sim_time, num_points)\n\n    # High-accuracy solver options\n    solver_options = {'method': 'RK45', 'rtol': 1e-8, 'atol': 1e-8}\n\n    for i, p in enumerate(protocols):\n        y0 = p['y0']\n        u_func = p['u_func']\n\n        # Solve for Model A\n        sol_A = solve_ivp(\n            model_A_rhs, t_span, y0, args=(u_func,), t_eval=t_eval, **solver_options\n        )\n        # Flatten the output array for 1D analysis\n        y_A = sol_A.y.flatten()\n\n        # Solve for Model B\n        sol_B = solve_ivp(\n            model_B_rhs, t_span, y0, args=(u_func,), t_eval=t_eval, **solver_options\n        )\n        # Flatten the output array for 1D analysis\n        y_B = sol_B.y.flatten()\n\n        # Ensure solvers were successful and returned arrays of expected shape\n        if y_A.shape[0] != num_points or y_B.shape[0] != num_points:\n            raise RuntimeError(f\"ODE solver failed for protocol {p['id']}.\")\n\n        # Compute Root-Mean-Square Error (RMSE)\n        rmse = np.sqrt(np.mean((y_A - y_B)**2))\n\n        # For the first protocol, check for observational equivalence\n        if i == 0:\n            results.append(rmse = equivalence_tolerance)\n        else:\n            results.append(rmse)\n\n    # Format the results into the required single-line string output\n    formatted_results = []\n    for r in results:\n        if isinstance(r, bool):\n            formatted_results.append(str(r))\n        else:\n            # Format floats to a reasonable precision for output consistency\n            formatted_results.append(f\"{r:.15g}\")\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}