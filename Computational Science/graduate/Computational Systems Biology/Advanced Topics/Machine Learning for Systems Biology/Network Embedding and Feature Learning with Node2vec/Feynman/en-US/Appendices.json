{
    "hands_on_practices": [
        {
            "introduction": "The core innovation of `node2vec` lies in its flexible, biased random walk strategy. Before we can appreciate its broader impact, we must first understand the mechanics at a single step. This practice challenges you to compute the transition probabilities on a simple network motif, providing a concrete understanding of how the return parameter $p$ and the in-out parameter $q$ directly control the walker's decision-making process .",
            "id": "3331426",
            "problem": "In a computational systems biology study, consider a Protein–Protein Interaction (PPI) network motif consisting of three proteins labeled $a$, $b$, and $c$, connected in an undirected triangle with unit edge weights $1$ on edges $a$–$b$, $b$–$c$, and $c$–$a$. To learn network embeddings with node2vec, a second-order biased random walk is used with return parameter $p$ and in–out parameter $q$.\n\nSuppose a walk is currently at node $b$ and the immediately previous node was $a$. Using node2vec with parameters $(p,q)=(2,0.5)$ on this unweighted triangle, compute the transition probabilities at the next step from $b$ to each of its neighbors $a$ and $c$. Express your answer as a row vector $\\left(P_{b\\to a}\\;\\;P_{b\\to c}\\right)$ in exact fractional form. Do not approximate or round.",
            "solution": "The problem is valid. It is scientifically grounded in the established `node2vec` algorithm from computational network science, well-posed with all necessary information provided, and stated objectively. We can proceed with the solution.\n\nThe core of the `node2vec` algorithm is a biased second-order random walk. The probability of transitioning from a current node $v$ to a next node $x$, given that the walk just came from a previous node $t$, is defined by a specific weighting scheme.\n\nLet the walk have just traversed the edge $(t, v)$, landing on the current node $v$. The unnormalized transition probability from $v$ to one of its neighbors $x$ is given by:\n$$\n\\pi_{vx} = \\alpha_{pq}(t, x) \\cdot w_{vx}\n$$\nwhere $w_{vx}$ is the static weight of the edge $(v, x)$, and $\\alpha_{pq}(t, x)$ is the `node2vec` search bias. The search bias depends on the return parameter $p$ and the in-out parameter $q$, and is defined as:\n$$\n\\alpha_{pq}(t, x) =\n\\begin{cases}\n    \\frac{1}{p} & \\text{if } d_{tx} = 0 \\\\\n    1 & \\text{if } d_{tx} = 1 \\\\\n    \\frac{1}{q} & \\text{if } d_{tx} = 2\n\\end{cases}\n$$\nHere, $d_{tx}$ represents the shortest path distance between the previous node $t$ and the potential next node $x$.\n\nThe normalized transition probability $P(v \\to x)$ is then calculated by dividing the unnormalized probability by the sum of unnormalized probabilities over all neighbors of $v$:\n$$\nP(v \\to x) = \\frac{\\pi_{vx}}{\\sum_{x' \\in N(v)} \\pi_{vx'}}\n$$\nwhere $N(v)$ is the set of neighbors of node $v$.\n\nIn the given problem, the network is an unweighted triangle of nodes $a$, $b$, and $c$. This means the weight of all existing edges is $1$, so $w_{ab} = w_{bc} = w_{ca} = 1$. The walk is currently at node $v=b$, and the previous node was $t=a$. The neighbors of the current node $b$ are $N(b) = \\{a, c\\}$. We must compute the transition probabilities from $b$ to $a$ and from $b$ to $c$. The parameters are given as $p=2$ and $q=0.5$.\n\nWe need to calculate the unnormalized transition probability $\\pi_{bx}$ for each neighbor $x \\in N(b)$.\n\n**1. Transition from $b$ to $a$ ($x=a$):**\nThe potential next node is $a$. We must determine the shortest path distance $d_{tx}$ between the previous node $t=a$ and the next node $x=a$. The distance from a node to itself is $d_{aa} = 0$.\nAccording to the formula for the search bias, for $d_{tx}=0$, we have $\\alpha_{pq}(a, a) = \\frac{1}{p}$.\nThe edge weight is $w_{ba} = 1$.\nThe unnormalized transition probability is:\n$$\n\\pi_{ba} = \\alpha_{pq}(a, a) \\cdot w_{ba} = \\frac{1}{p} \\cdot 1 = \\frac{1}{2}\n$$\n\n**2. Transition from $b$ to $c$ ($x=c$):**\nThe potential next node is $c$. We must determine the shortest path distance $d_{tx}$ between the previous node $t=a$ and the next node $x=c$. In the triangular motif, nodes $a$ and $c$ are directly connected by an edge. Therefore, the shortest path distance is $d_{ac} = 1$.\nAccording to the formula for the search bias, for $d_{tx}=1$, we have $\\alpha_{pq}(a, c) = 1$.\nThe edge weight is $w_{bc} = 1$.\nThe unnormalized transition probability is:\n$$\n\\pi_{bc} = \\alpha_{pq}(a, c) \\cdot w_{bc} = 1 \\cdot 1 = 1\n$$\nNote that the in-out parameter $q$ is not used in this specific calculation, as there is no neighbor of $b$ that is at a distance of $2$ from the previous node $a$.\n\nNow, we compute the normalization constant, which is the sum of the unnormalized probabilities for all possible next steps from $b$:\n$$\nZ = \\sum_{x' \\in N(b)} \\pi_{bx'} = \\pi_{ba} + \\pi_{bc} = \\frac{1}{2} + 1 = \\frac{3}{2}\n$$\n\nFinally, we calculate the normalized transition probabilities by dividing each unnormalized probability by the normalization constant $Z$.\n\nThe probability of transitioning from $b$ to $a$ is:\n$$\nP_{b \\to a} = \\frac{\\pi_{ba}}{Z} = \\frac{1/2}{3/2} = \\frac{1}{2} \\cdot \\frac{2}{3} = \\frac{1}{3}\n$$\n\nThe probability of transitioning from $b$ to $c$ is:\n$$\nP_{b \\to c} = \\frac{\\pi_{bc}}{Z} = \\frac{1}{3/2} = 1 \\cdot \\frac{2}{3} = \\frac{2}{3}\n$$\n\nThe resulting transition probabilities are $P_{b\\to a} = \\frac{1}{3}$ and $P_{b\\to c} = \\frac{2}{3}$. The question asks for the answer as a row vector $(P_{b\\to a}\\;\\;P_{b\\to c})$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{3} & \\frac{2}{3} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Having mastered the calculation of a single transition, we now scale up our thinking to algorithm-level strategy. The power of `node2vec` comes from its ability to generate embeddings that capture either local community structure (homophily) or broader structural roles (structural equivalence). This exercise asks you to reason about how to set the hyperparameters $p$ and $q$ to achieve these different goals, a critical skill for tailoring the algorithm to specific biological questions .",
            "id": "3331387",
            "problem": "Consider a Protein–Protein Interaction (PPI) network that is undirected and unweighted, with dense intra-modular communities and relatively few connector proteins bridging these communities. You are using node2vec to learn node embeddings for downstream classification tasks and you must choose the return parameter $p$ and the in–out parameter $q$ to prioritize either community detection (homophily-oriented embeddings) or role discovery (structural-equivalence-oriented embeddings). Assume standard node2vec biased second-order random walks on the given graph and that the downstream embedding model (for example, a Skip-gram with negative sampling) captures co-occurrence statistics produced by these walks.\n\nWhich choice of $(p,q)$ best emphasizes community detection versus role discovery in this PPI setting?\n\nA. Community detection: $p<1$, $q>1$; Role discovery: $p>1$, $q<1$.\n\nB. Community detection: $p>1$, $q<1$; Role discovery: $p<1$, $q>1$.\n\nC. Community detection: $p\\approx 1$, $q\\approx 1$; Role discovery: $p\\approx 1$, $q\\approx 1$.\n\nD. Community detection: $p\\gg 1$, $q\\gg 1$; Role discovery: $p\\ll 1$, $q\\ll 1$.\n\nE. Community detection: $p>1$, $q>1$; Role discovery: $p<1$, $q<1$.\n\nSelect the single best option and be prepared to justify the choice from first principles of the node2vec transition mechanism, taking into account how dense communities and few connectors shape distances among nodes encountered during the biased random walks.",
            "solution": "The problem as stated is valid. It is scientifically grounded in the fields of network science and machine learning, specifically concerning the node2vec algorithm. The terminology is standard and well-defined, and the problem is self-contained and well-posed, admitting a unique logical solution based on the principles of the algorithm.\n\nThe core of the problem is to understand how the node2vec parameters, the return parameter $p$ and the in-out parameter $q$, govern the exploration strategy of the underlying second-order random walks, and to map these strategies to the objectives of community detection (homophily) and role discovery (structural equivalence).\n\nLet's begin by formalizing the node2vec transition mechanism. Assume a random walk has just traversed an edge $(t, v)$ and is currently at node $v$. The next node in the walk, $x$, is chosen from the neighbors of $v$, $N(v)$. The unnormalized transition probability $\\pi_{vx}$ for moving from $v$ to an adjacent node $x$ is given by:\n$$ \\pi_{vx} = \\alpha_{pq}(t, x) \\cdot w_{vx} $$\nSince the graph is unweighted, the edge weight $w_{vx} = 1$ for all existing edges. The bias of the walk is therefore entirely determined by the search-bias factor $\\alpha_{pq}(t, x)$, which is defined based on the shortest path distance $d_{tx}$ between the previous node $t$ and the candidate next node $x$:\n$$ \\alpha_{pq}(t, x) = \\begin{cases} 1/p & \\text{if } d_{tx} = 0 \\\\ 1 & \\text{if } d_{tx} = 1 \\\\ 1/q & \\text{if } d_{tx} = 2 \\end{cases} $$\nHere, $d_{tx} = 0$ means $x = t$, so the walk returns to the previous node. $d_{tx} = 1$ means $x$ is also a neighbor of $t$. $d_{tx} = 2$ means $x$ is a neighbor of $v$ but not of $t$.\n\nThe parameters $p$ and $q$ control the nature of the exploration:\n1.  **Return Parameter $p$**: This parameter controls the likelihood of immediate backtracking.\n    -   A low value of $p$ (i.e., $p < 1$) increases the probability of returning to the previous node $t$. This keeps the walk tightly localized in the vicinity of the starting node.\n    -   A high value of $p$ (i.e., $p > 1$) decreases the probability of backtracking, encouraging the walk to move away and explore more distant nodes.\n\n2.  **In-Out Parameter $q$**: This parameter controls the tendency to move \"inward\" versus \"outward\". It interpolates between Breadth-First Search (BFS) and Depth-First Search (DFS).\n    -   A low value of $q$ (i.e., $q < 1$) increases the probability of visiting nodes $x$ for which $d_{tx} = 2$. This encourages the walk to move further away from the previous node $t$, promoting a DFS-like, global exploration of the graph structure.\n    -   A high value of $q$ (i.e., $q > 1$) decreases the probability of visiting nodes $x$ where $d_{tx} = 2$. This biases the walk to stay close to the previous node $t$, promoting a BFS-like, local exploration of the neighborhood.\n\nNow, we relate these exploration strategies to the specified objectives:\n\n**1. Community Detection (Homophily-oriented Embeddings):**\nThe goal is to generate embeddings where nodes belonging to the same community are close in the embedding space. Homophily is the principle that similar nodes (e.g., nodes in the same community) are connected. To capture this, the random walks must densely sample the local neighborhood of a node. In a graph with dense communities, this means the walk should be biased to stay *within* a community. This requires a local exploration strategy, akin to BFS.\n- To achieve a BFS-like behavior, we must discourage the walk from moving to nodes far from the previous node $t$. This is accomplished by setting $q > 1$, which penalizes transitions to nodes $x$ where $d_{tx}=2$.\n- To further confine the walk to a very local region, making it sample the neighborhood exhaustively, we can encourage backtracking or short-range exploration. A low value of $p$ (i.e., $p < 1$) makes it more likely for the walk to revisit the node $t$ and its immediate vicinity.\n- Therefore, to emphasize community detection, the appropriate setting is **$p < 1$ and $q > 1$**.\n\n**2. Role Discovery (Structural-Equivalence-oriented Embeddings):**\nThe goal is to generate embeddings where nodes having the same structural role (e.g., being a bridge node between two communities, or a hub within a community) are close in the embedding space, regardless of their network distance. To capture this, the random walks must identify structural similarities, which often requires a broader view of the graph. The walk must be able to explore diverse neighborhoods and jump between structurally similar regions. This requires a global exploration strategy, akin to DFS.\n- To achieve a DFS-like behavior, we must encourage the walk to move outward and explore new parts of the graph. This is accomplished by setting $q < 1$, which favors transitions to nodes $x$ where $d_{tx}=2$.\n- To complement this outward search, we must discourage the walk from getting stuck in one area by backtracking. This is achieved by setting $p > 1$, which penalizes returns to the previous node $t$, pushing the walk to explore further.\n- Therefore, to emphasize role discovery, the appropriate setting is **$p > 1$ and $q < 1$**.\n\nWith this derived understanding, we can now evaluate the given options.\n\n**A. Community detection: $p<1$, $q>1$; Role discovery: $p>1$, $q<1$**.\n- The setting for community detection ($p<1$, $q>1$) correctly pair a low return parameter for local confinement with a high in-out parameter for a BFS-like search. This matches our derivation for capturing homophily.\n- The setting for role discovery ($p>1$, $q<1$) correctly pair a high return parameter to prevent backtracking with a low in-out parameter for a DFS-like search. This matches our derivation for capturing structural equivalence.\n- **Verdict: Correct.**\n\n**B. Community detection: $p>1$, $q<1$; Role discovery: $p<1$, $q>1$**.\n- This option exactly inverts the correct logic derived above. It suggests a DFS-like search for communities and a BFS-like search for roles, which is fundamentally incorrect.\n- **Verdict: Incorrect.**\n\n**C. Community detection: $p\\approx 1$, $q\\approx 1$; Role discovery: $p\\approx 1$, $q\\approx 1$**.\n- When $p \\approx 1$ and $q \\approx 1$, the bias term $\\alpha_{pq}(t, x) \\approx 1$ for all cases. The walk becomes a standard unbiased second-order random walk, which is the procedure used in the DeepWalk algorithm. While DeepWalk is effective at capturing homophily, it does not specifically *emphasize* it over structural equivalence in the tunable way that node2vec does. Crucially, this setting does not emphasize role discovery. Therefore, it is not the *best* choice for either emphasized objective.\n- **Verdict: Incorrect.**\n\n**D. Community detection: $p\\gg 1$, $q\\gg 1$; Role discovery: $p\\ll 1$, $q\\ll 1$**.\n- For community detection, $p \\gg 1$ strongly discourages backtracking, which is not optimal for dense local sampling. While $q \\gg 1$ promotes local search, the combination is suboptimal compared to the canonical $p<1, q>1$ setting.\n- For role discovery, $p \\ll 1$ strongly encourages backtracking, which directly conflicts with the goal of global exploration. $q \\ll 1$ correctly encourages DFS-like moves. The combination of parameters is contradictory and ineffective for the stated goal.\n- **Verdict: Incorrect.**\n\n**E. Community detection: $p>1$, $q>1$; Role discovery: $p<1$, $q<1$**.\n- For community detection, $p > 1$ discourages backtracking, which is a feature of DFS (exploration), not BFS (local sampling). While $q>1$ is appropriate, the choice of $p>1$ is not optimal for emphasizing homophily.\n- For role discovery, $p < 1$ encourages backtracking and local confinement, which is the opposite of the required global exploration. While $q<1$ is appropriate, the choice of $p<1$ makes the strategy self-defeating.\n- **Verdict: Incorrect.**\n\nBased on the first-principles analysis of the node2vec algorithm, only Option A provides the correct parameter settings to emphasize the distinct goals of community detection and role discovery.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Once the biased random walks have generated sequences of nodes, the final step is to learn the embeddings themselves. The `node2vec` framework adopts the skip-gram with negative sampling (SGNS) model, an efficient method for learning vector representations from local contexts. This practice provides a hands-on look into the learning process by having you perform a single stochastic gradient update, revealing how embeddings are adjusted to make observed node co-occurrences more likely .",
            "id": "3331408",
            "problem": "In a protein–protein interaction network from computational systems biology, suppose we train node representations using the node2vec skip-gram model with negative sampling. Let the source (node) embedding be a vector $\\mathbf{z}_u \\in \\mathbb{R}^2$ and the context (node) embeddings be vectors $\\mathbf{z}'_x \\in \\mathbb{R}^2$. For a single stochastic update step, consider the following setting derived from a second-order random walk that visits node $u$ and observes context node $v$:\n- The positive co-occurrence pair is $(u,v)$.\n- Two negative samples are $n_1$ and $n_2$.\n\nUse the following core definitions as the starting point:\n- The logistic sigmoid function is $\\sigma(t) = \\frac{1}{1+\\exp(-t)}$.\n- The single-sample log-likelihood objective with two negative samples is\n$$\nL(u,v,n_1,n_2) \\;=\\; \\ln\\!\\big(\\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_v)\\big) \\;+\\; \\sum_{i=1}^{2} \\ln\\!\\big(\\sigma(-\\,\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i})\\big).\n$$\n\nAssume the following current embeddings and learning rate:\n- $\\mathbf{z}_u = (1,0)$,\n- $\\mathbf{z}'_v = (0,1)$,\n- $\\mathbf{z}'_{n_1} = (1,1)$,\n- $\\mathbf{z}'_{n_2} = (-1,0)$,\n- learning rate $\\eta = 0.05$.\n\nTreat $\\mathbf{z}'_v$, $\\mathbf{z}'_{n_1}$, and $\\mathbf{z}'_{n_2}$ as constants for this step. Perform one step of stochastic gradient ascent on $L(u,v,n_1,n_2)$ with respect to $\\mathbf{z}_u$, starting from the given $\\mathbf{z}_u$. Compute the updated source embedding vector $\\mathbf{z}_u^{\\text{new}}$ after this single step. Round each component of the final vector to six significant figures. Provide your final answer as a single row vector.",
            "solution": "The objective of this problem is to perform a single step of stochastic gradient ascent to update the source node embedding $\\mathbf{z}_u$. The update rule for stochastic gradient ascent is given by:\n$$\n\\mathbf{z}_u^{\\text{new}} = \\mathbf{z}_u + \\eta \\nabla_{\\mathbf{z}_u} L\n$$\nwhere $\\eta$ is the learning rate and $\\nabla_{\\mathbf{z}_u} L$ is the gradient of the log-likelihood objective function $L$ with respect to the source embedding $\\mathbf{z}_u$.\n\nThe log-likelihood objective function is provided as:\n$$\nL(u,v,n_1,n_2) = \\ln(\\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_v)) + \\sum_{i=1}^{2} \\ln(\\sigma(-\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i}))\n$$\n\nFirst, we must compute the gradient $\\nabla_{\\mathbf{z}_u} L$. We will compute the gradient of each term in $L$ separately. The derivative of the logistic sigmoid function $\\sigma(t) = (1+\\exp(-t))^{-1}$ is $\\sigma'(t) = \\sigma(t)(1-\\sigma(t))$.\n\nFor any scalar-valued function $f(x)$, the derivative of $\\ln(f(x))$ is $\\frac{f'(x)}{f(x)}$. Thus, the derivative of $\\ln(\\sigma(t))$ with respect to $t$ is:\n$$\n\\frac{d}{dt}\\ln(\\sigma(t)) = \\frac{\\sigma'(t)}{\\sigma(t)} = \\frac{\\sigma(t)(1-\\sigma(t))}{\\sigma(t)} = 1-\\sigma(t)\n$$\n\nNow, we apply the chain rule to find the gradient of each term in $L$ with respect to the vector $\\mathbf{z}_u$.\n\n1.  **Gradient of the positive sample term**:\n    Let the first term be $L_{pos} = \\ln(\\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_v))$.\n    Using the chain rule, its gradient is:\n    $$\n    \\nabla_{\\mathbf{z}_u} L_{pos} = \\frac{d}{d(\\mathbf{z}_u^{\\top}\\mathbf{z}'_v)} \\ln(\\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_v)) \\cdot \\nabla_{\\mathbf{z}_u}(\\mathbf{z}_u^{\\top}\\mathbf{z}'_v)\n    $$\n    This simplifies to:\n    $$\n    \\nabla_{\\mathbf{z}_u} L_{pos} = (1 - \\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_v)) \\mathbf{z}'_v\n    $$\n\n2.  **Gradient of the negative sample terms**:\n    Let a negative sample term be $L_{neg,i} = \\ln(\\sigma(-\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i}))$.\n    Using the chain rule, its gradient is:\n    $$\n    \\nabla_{\\mathbf{z}_u} L_{neg,i} = \\frac{d}{d(-\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i})} \\ln(\\sigma(-\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i})) \\cdot \\nabla_{\\mathbf{z}_u}(-\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i})\n    $$\n    This simplifies to:\n    $$\n    \\nabla_{\\mathbf{z}_u} L_{neg,i} = (1 - \\sigma(-\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i})) (-\\mathbf{z}'_{n_i})\n    $$\n    Using the identity $\\sigma(-x) = 1 - \\sigma(x)$, we can rewrite the term $(1 - \\sigma(-\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i}))$ as $1 - (1 - \\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i})) = \\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i})$.\n    Therefore, the gradient for a negative sample term is:\n    $$\n    \\nabla_{\\mathbf{z}_u} L_{neg,i} = -\\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i})\\mathbf{z}'_{n_i}\n    $$\n\nCombining these results, the full gradient of $L$ is:\n$$\n\\nabla_{\\mathbf{z}_u} L = (1 - \\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_v))\\mathbf{z}'_v - \\sum_{i=1}^{2} \\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_i})\\mathbf{z}'_{n_i}\n$$\n$$\n\\nabla_{\\mathbf{z}_u} L = (1 - \\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_v))\\mathbf{z}'_v - \\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_1})\\mathbf{z}'_{n_1} - \\sigma(\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_2})\\mathbf{z}'_{n_2}\n$$\n\nNext, we substitute the given numerical values:\n$\\mathbf{z}_u = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, $\\mathbf{z}'_v = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, $\\mathbf{z}'_{n_1} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$, $\\mathbf{z}'_{n_2} = \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix}$.\n\nWe calculate the dot products:\n- $\\mathbf{z}_u^{\\top}\\mathbf{z}'_v = (1)(0) + (0)(1) = 0$\n- $\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_1} = (1)(1) + (0)(1) = 1$\n- $\\mathbf{z}_u^{\\top}\\mathbf{z}'_{n_2} = (1)(-1) + (0)(0) = -1$\n\nNow, we evaluate the sigmoid function for these values:\n- $\\sigma(0) = \\frac{1}{1+\\exp(0)} = \\frac{1}{1+1} = \\frac{1}{2}$\n- $\\sigma(1) = \\frac{1}{1+\\exp(-1)}$\n- $\\sigma(-1) = \\frac{1}{1+\\exp(1)}$\n\nSubstitute these into the gradient expression:\n$$\n\\nabla_{\\mathbf{z}_u} L = \\left(1 - \\frac{1}{2}\\right)\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} - \\frac{1}{1+\\exp(-1)}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} - \\frac{1}{1+\\exp(1)}\\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\nabla_{\\mathbf{z}_u} L = \\frac{1}{2}\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} - \\frac{1}{1+\\exp(-1)}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} - \\frac{1}{1+\\exp(1)}\\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix}\n$$\nLet's find the components of the gradient vector:\nx-component:\n$0 \\cdot \\frac{1}{2} - 1 \\cdot \\frac{1}{1+\\exp(-1)} - (-1) \\cdot \\frac{1}{1+\\exp(1)} = -\\frac{1}{1+\\exp(-1)} + \\frac{1}{1+\\exp(1)}$\nUsing $\\exp(-1) = 1/e$, this becomes $-\\frac{1}{1+1/e} + \\frac{1}{1+e} = -\\frac{e}{e+1} + \\frac{1}{e+1} = \\frac{1-e}{e+1}$.\ny-component:\n$1 \\cdot \\frac{1}{2} - 1 \\cdot \\frac{1}{1+\\exp(-1)} - 0 \\cdot \\frac{1}{1+\\exp(1)} = \\frac{1}{2} - \\frac{e}{e+1} = \\frac{e+1-2e}{2(e+1)} = \\frac{1-e}{2(e+1)}$.\n\nSo, the gradient vector is:\n$$\n\\nabla_{\\mathbf{z}_u} L = \\begin{pmatrix} \\frac{1-e}{e+1} \\\\ \\frac{1-e}{2(e+1)} \\end{pmatrix}\n$$\nNumerically, $\\frac{1-e}{e+1} \\approx \\frac{1-2.7182818}{1+2.7182818} \\approx -0.46211716$.\nSo, $\\nabla_{\\mathbf{z}_u} L \\approx \\begin{pmatrix} -0.46211716 \\\\ -0.23105858 \\end{pmatrix}$.\n\nNow we perform the update step with $\\eta = 0.05$:\n$$\n\\mathbf{z}_u^{\\text{new}} = \\mathbf{z}_u + \\eta \\nabla_{\\mathbf{z}_u} L = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + 0.05 \\begin{pmatrix} \\frac{1-e}{e+1} \\\\ \\frac{1-e}{2(e+1)} \\end{pmatrix}\n$$\n$$\n\\mathbf{z}_u^{\\text{new}} = \\begin{pmatrix} 1 + 0.05\\left(\\frac{1-e}{e+1}\\right) \\\\ 0.05\\left(\\frac{1-e}{2(e+1)}\\right) \\end{pmatrix}\n$$\nCalculate the numerical values for the components:\nx-component: $1 + 0.05 \\times (-0.46211716) = 1 - 0.023105858 \\approx 0.976894142$.\ny-component: $0.05 \\times (-0.23105858) = -0.011552929$.\n\nRounding each component to six significant figures:\n- The first component $0.976894142$ becomes $0.976894$.\n- The second component $-0.011552929$ becomes $-0.0115529$.\n\nThe updated source embedding vector is $\\mathbf{z}_u^{\\text{new}} = (0.976894, -0.0115529)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.976894 & -0.0115529\n\\end{pmatrix}\n}\n$$"
        }
    ]
}