{
    "hands_on_practices": [
        {
            "introduction": "Biological systems are fundamentally networks of interacting components, from protein interactions to metabolic pathways. Graph Neural Networks (GNNs) provide a natural framework for learning representations of such systems. This exercise walks through the core \"message passing\" mechanism of a Graph Convolutional Network (GCN), giving you a concrete understanding of how a node's features are updated by aggregating information from its local neighborhood.",
            "id": "3299390",
            "problem": "Consider a small protein signaling network represented as an undirected graph where nodes correspond to proteins and edges indicate experimentally observed physical interactions. Let the network have $3$ proteins labeled $P_1$, $P_2$, and $P_3$, with the symmetric adjacency matrix $\\mathbf{A}$ given by\n$$\n\\mathbf{A}=\\begin{pmatrix}\n0 & 1 & 0 \\\\\n1 & 0 & 1 \\\\\n0 & 1 & 0\n\\end{pmatrix}.\n$$\nIn a Graph Convolutional Network (GCN), messages are propagated with self-loops and symmetric normalization. Self-loops are added by forming $\\tilde{\\mathbf{A}}=\\mathbf{A}+\\mathbf{I}$, and the degree matrix $\\tilde{\\mathbf{D}}$ is defined by $\\tilde{D}_{ii}=\\sum_{j} \\tilde{A}_{ij}$. Symmetric normalization uses the operator $\\tilde{\\mathbf{D}}^{-1/2}\\tilde{\\mathbf{A}}\\tilde{\\mathbf{D}}^{-1/2}$. The node feature matrix $\\mathbf{H}\\in\\mathbb{R}^{3\\times 2}$ collects two biologically meaningful features per protein (for instance, a basal activity and a phosphorylation-associated activity), and the layer’s weight matrix is $\\mathbf{W}\\in\\mathbb{R}^{2\\times 1}$. The nonlinear activation is the Rectified Linear Unit (ReLU), defined by $\\sigma(x)=\\max\\{0,x\\}$.\n\nSuppose the initial node feature matrix and the weight matrix are\n$$\n\\mathbf{H}=\\begin{pmatrix}\n2 & 0 \\\\\n1 & 1 \\\\\n0 & 2\n\\end{pmatrix},\n\\qquad\n\\mathbf{W}=\\begin{pmatrix}\n1 \\\\\n-2\n\\end{pmatrix}.\n$$\nUsing one GCN layer with self-loops and symmetric normalization as described, compute the single activated scalar feature of protein $P_2$ (the second node) after the layer. Express your answer exactly as a closed-form real number. No rounding is required, and no units are needed.",
            "solution": "The problem asks for the computation of the activated scalar feature for protein $P_2$ after a single layer of a Graph Convolutional Network (GCN). The layer's operation is defined by the propagation rule:\n$$\n\\mathbf{H}' = \\sigma(\\tilde{\\mathbf{D}}^{-1/2}\\tilde{\\mathbf{A}}\\tilde{\\mathbf{D}}^{-1/2} \\mathbf{H} \\mathbf{W})\n$$\nwhere $\\mathbf{H}$ is the input feature matrix, $\\mathbf{W}$ is the weight matrix, $\\sigma$ is the ReLU activation function, and the term $\\tilde{\\mathbf{D}}^{-1/2}\\tilde{\\mathbf{A}}\\tilde{\\mathbf{D}}^{-1/2}$ is the symmetrically normalized adjacency matrix with self-loops.\n\nFirst, we establish the given matrices. The adjacency matrix $\\mathbf{A}$ for the $3$-protein network is:\n$$\n\\mathbf{A}=\\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix}\n$$\nThe initial node feature matrix $\\mathbf{H} \\in \\mathbb{R}^{3\\times 2}$ and the weight matrix $\\mathbf{W} \\in \\mathbb{R}^{2\\times 1}$ are:\n$$\n\\mathbf{H}=\\begin{pmatrix}\n2 & 0 \\\\\n1 & 1 \\\\\n0 & 2\n\\end{pmatrix},\n\\qquad\n\\mathbf{W}=\\begin{pmatrix}\n1 \\\\\n-2\n\\end{pmatrix}\n$$\n\nThe calculation proceeds in several steps:\n\n1.  **Add self-loops to the adjacency matrix.**\n    This is done by computing $\\tilde{\\mathbf{A}} = \\mathbf{A} + \\mathbf{I}$, where $\\mathbf{I}$ is the $3 \\times 3$ identity matrix.\n    $$\n    \\tilde{\\mathbf{A}} = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix} + \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix}\n    $$\n\n2.  **Compute the degree matrix $\\tilde{\\mathbf{D}}$.**\n    The diagonal entries of $\\tilde{\\mathbf{D}}$ are the row sums of $\\tilde{\\mathbf{A}}$.\n    -   $\\tilde{D}_{11} = 1 + 1 + 0 = 2$\n    -   $\\tilde{D}_{22} = 1 + 1 + 1 = 3$\n    -   $\\tilde{D}_{33} = 0 + 1 + 1 = 2$\n    So, the degree matrix is:\n    $$\n    \\tilde{\\mathbf{D}} = \\begin{pmatrix} 2 & 0 & 0 \\\\ 0 & 3 & 0 \\\\ 0 & 0 & 2 \\end{pmatrix}\n    $$\n\n3.  **Compute the symmetrically normalized adjacency matrix $\\hat{\\mathbf{A}} = \\tilde{\\mathbf{D}}^{-1/2}\\tilde{\\mathbf{A}}\\tilde{\\mathbf{D}}^{-1/2}$.**\n    First, we find $\\tilde{\\mathbf{D}}^{-1/2}$ by taking the inverse square root of the diagonal elements of $\\tilde{\\mathbf{D}}$.\n    $$\n    \\tilde{\\mathbf{D}}^{-1/2} = \\begin{pmatrix} 2^{-1/2} & 0 & 0 \\\\ 0 & 3^{-1/2} & 0 \\\\ 0 & 0 & 2^{-1/2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & 0 & 0 \\\\ 0 & \\frac{1}{\\sqrt{3}} & 0 \\\\ 0 & 0 & \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n    $$\n    Now we perform the matrix multiplication:\n    $$\n    \\hat{\\mathbf{A}} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & 0 & 0 \\\\ 0 & \\frac{1}{\\sqrt{3}} & 0 \\\\ 0 & 0 & \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 1 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & 0 & 0 \\\\ 0 & \\frac{1}{\\sqrt{3}} & 0 \\\\ 0 & 0 & \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n    $$\n    $$\n    \\hat{\\mathbf{A}} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} & 0 \\\\ \\frac{1}{\\sqrt{3}} & \\frac{1}{\\sqrt{3}} & \\frac{1}{\\sqrt{3}} \\\\ 0 & \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} & 0 & 0 \\\\ 0 & \\frac{1}{\\sqrt{3}} & 0 \\\\ 0 & 0 & \\frac{1}{\\sqrt{2}} \\end{pmatrix}\n    $$\n    $$\n    \\hat{\\mathbf{A}} = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{\\sqrt{6}} & 0 \\\\ \\frac{1}{\\sqrt{6}} & \\frac{1}{3} & \\frac{1}{\\sqrt{6}} \\\\ 0 & \\frac{1}{\\sqrt{6}} & \\frac{1}{2} \\end{pmatrix}\n    $$\n\n4.  **Compute the linear transformation part, $\\mathbf{Z} = \\hat{\\mathbf{A}}\\mathbf{H}\\mathbf{W}$.**\n    It is computationally efficient to first calculate the product $\\mathbf{X} = \\mathbf{H}\\mathbf{W}$.\n    $$\n    \\mathbf{X} = \\begin{pmatrix} 2 & 0 \\\\ 1 & 1 \\\\ 0 & 2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} (2)(1) + (0)(-2) \\\\ (1)(1) + (1)(-2) \\\\ (0)(1) + (2)(-2) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -1 \\\\ -4 \\end{pmatrix}\n    $$\n    Now we compute $\\mathbf{Z} = \\hat{\\mathbf{A}}\\mathbf{X}$.\n    $$\n    \\mathbf{Z} = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{\\sqrt{6}} & 0 \\\\ \\frac{1}{\\sqrt{6}} & \\frac{1}{3} & \\frac{1}{\\sqrt{6}} \\\\ 0 & \\frac{1}{\\sqrt{6}} & \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -1 \\\\ -4 \\end{pmatrix}\n    $$\n    The problem only requires the feature for protein $P_2$, which corresponds to the second element of the final output vector. We compute the second element of $\\mathbf{Z}$, denoted $Z_2$.\n    $$\n    Z_2 = \\left(\\frac{1}{\\sqrt{6}}\\right)(2) + \\left(\\frac{1}{3}\\right)(-1) + \\left(\\frac{1}{\\sqrt{6}}\\right)(-4)\n    $$\n    $$\n    Z_2 = \\frac{2}{\\sqrt{6}} - \\frac{1}{3} - \\frac{4}{\\sqrt{6}} = -\\frac{2}{\\sqrt{6}} - \\frac{1}{3}\n    $$\n\n5.  **Apply the ReLU activation function.**\n    The activation function is $\\sigma(x) = \\max\\{0, x\\}$. We need to apply this to $Z_2$.\n    The value of $Z_2$ is $-\\frac{2}{\\sqrt{6}} - \\frac{1}{3}$. Since both terms are negative, their sum is negative.\n    $$\n    Z_2 < 0\n    $$\n    The activated feature for protein $P_2$, denoted $H'_{2}$, is:\n    $$\n    H'_{2} = \\sigma(Z_2) = \\max\\{0, -\\frac{2}{\\sqrt{6}} - \\frac{1}{3}\\} = 0\n    $$\nThe single activated scalar feature of protein $P_2$ is $0$.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "A primary goal of systems biology is to predict the outcomes of interventions, such as a gene knockdown or a drug treatment. However, models trained on purely observational data learn correlations, which can be confounded by unobserved factors and fail to predict causal effects. This practice uses a Structural Causal Model (SCM) to provide a hands-on demonstration of this critical distinction, calculating the difference between a naive observational prediction and the true interventional outcome.",
            "id": "3299366",
            "problem": "Consider a gene regulatory module modeled as a linear Structural Causal Model (SCM) with a known Directed Acyclic Graph (DAG). The DAG has nodes $C$ (an unobserved cellular context variable), $G_1$ (a transcription factor subject to knockdown), $G_2$ (a downstream gene), and $Y$ (a phenotypic output). The directed edges are $C \\rightarrow G_1$, $C \\rightarrow Y$, $G_1 \\rightarrow G_2$, and $G_1 \\rightarrow Y$, $G_2 \\rightarrow Y$. The SCM is specified by the following linear-Gaussian structural equations:\n$$\nC \\sim \\mathcal{N}(\\mu_C,\\sigma_C^2), \\quad G_1 = a_{CG_1} C + \\varepsilon_1, \\quad G_2 = a_{12} G_1 + \\varepsilon_2, \\quad Y = b_{2Y} G_2 + b_{1Y} G_1 + b_{CY} C + \\varepsilon_Y,\n$$\nwhere $\\varepsilon_1 \\sim \\mathcal{N}(0,\\sigma_1^2)$, $\\varepsilon_2 \\sim \\mathcal{N}(0,\\sigma_2^2)$, and $\\varepsilon_Y \\sim \\mathcal{N}(0,\\sigma_Y^2)$ are mutually independent and independent of $C$. All variables represent steady-state levels, measured in consistent unitless relative expression or activity units.\n\nYou are given numerical parameters: $\\mu_C = 0.5$, $\\sigma_C^2 = 1.0$, $a_{CG_1} = 1.3$, $\\sigma_1^2 = 0.4$, $a_{12} = 0.8$, $\\sigma_2^2 = 0.3$, $b_{2Y} = 2.0$, $b_{1Y} = 0.5$, $b_{CY} = 1.1$, and $\\sigma_Y^2 = 0.2$.\n\nA systematic knockdown sets the transcription factor $G_1$ to the fixed level $g^* = 0.2$. Using the truncated factorization definition of interventional distributions for SCMs, derive the interventional expectation $\\mathbb{E}[Y \\mid do(G_1 = g^*)]$ for this knockdown.\n\nSeparately, consider a deep neural predictor trained purely on observational data pairs $(G_1,Y)$ to minimize expected squared error. Assume infinite data and sufficient capacity so that the learned predictor converges to the observational conditional expectation $\\mathbb{E}[Y \\mid G_1 = g^*]$. Derive this observational expectation under the given SCM.\n\nFinally, compute the numerical difference between the observational predictor and the interventional effect under the knockdown, defined as\n$$\n\\Delta \\equiv \\mathbb{E}[Y \\mid G_1 = g^*] - \\mathbb{E}[Y \\mid do(G_1 = g^*)].\n$$\nProvide the value of $\\Delta$ as a unitless real number. Round your answer to four significant figures.",
            "solution": "To compute the difference $\\Delta$, we must derive two quantities: the interventional expectation $\\mathbb{E}[Y \\mid do(G_1 = g^*)]$ and the observational conditional expectation $\\mathbb{E}[Y \\mid G_1 = g^*]$.\n\n**Derivation of the Interventional Expectation**\n\nThe interventional expectation $\\mathbb{E}[Y \\mid do(G_1 = g^*)]$ is calculated using a modified SCM where the structural equation for $G_1$ is replaced by the assignment $G_1 = g^*$. This removes the influence of its parent, $C$.\nThe modified SCM is:\n$C \\sim \\mathcal{N}(\\mu_C, \\sigma_C^2)$\n$G_1 = g^*$\n$G_2 = a_{12} G_1 + \\varepsilon_2 = a_{12} g^* + \\varepsilon_2$\n$Y = b_{2Y} G_2 + b_{1Y} G_1 + b_{CY} C + \\varepsilon_Y$\n\nWe compute the expectation of $Y$ under this new model. By the linearity of expectation:\n$$\n\\mathbb{E}[Y \\mid do(G_1 = g^*)] = \\mathbb{E}[b_{2Y} G_2 + b_{1Y} G_1 + b_{CY} C + \\varepsilon_Y] = b_{2Y} \\mathbb{E}[G_2] + b_{1Y} \\mathbb{E}[G_1] + b_{CY} \\mathbb{E}[C] + \\mathbb{E}[\\varepsilon_Y]\n$$\nThe expectations of the individual components are $\\mathbb{E}[G_1] = g^*$, $\\mathbb{E}[C] = \\mu_C$, $\\mathbb{E}[\\varepsilon_Y] = 0$, and $\\mathbb{E}[G_2] = \\mathbb{E}[a_{12} g^* + \\varepsilon_2] = a_{12} g^*$. Substituting these in:\n$$\n\\mathbb{E}[Y \\mid do(G_1 = g^*)] = b_{2Y} (a_{12} g^*) + b_{1Y} g^* + b_{CY} \\mu_C = (a_{12}b_{2Y} + b_{1Y}) g^* + b_{CY} \\mu_C\n$$\nThis expression represents the true causal effect of setting $G_1$ to $g^*$ on $Y$.\n\n**Derivation of the Observational Conditional Expectation**\n\nThe observational conditional expectation $\\mathbb{E}[Y \\mid G_1 = g^*]$ is calculated using the original SCM. By linearity of conditional expectation:\n$$\n\\mathbb{E}[Y \\mid G_1 = g^*] = b_{2Y} \\mathbb{E}[G_2 \\mid G_1 = g^*] + b_{1Y} \\mathbb{E}[G_1 \\mid G_1 = g^*] + b_{CY} \\mathbb{E}[C \\mid G_1 = g^*] + \\mathbb{E}[\\varepsilon_Y \\mid G_1 = g^*]\n$$\nWe evaluate each term: $\\mathbb{E}[G_1 \\mid G_1 = g^*] = g^*$; $\\mathbb{E}[\\varepsilon_Y \\mid G_1 = g^*] = \\mathbb{E}[\\varepsilon_Y] = 0$ (by independence); $\\mathbb{E}[G_2 \\mid G_1 = g^*] = \\mathbb{E}[a_{12}G_1 + \\varepsilon_2 \\mid G_1 = g^*] = a_{12}g^*$ (by independence of $\\varepsilon_2$). The key term is $\\mathbb{E}[C \\mid G_1 = g^*]$, which accounts for the confounding path. Since $C$ and $G_1$ are jointly Gaussian, we use the standard formula for conditional expectation:\n$$\n\\mathbb{E}[C \\mid G_1 = g^*] = \\mathbb{E}[C] + \\frac{\\text{Cov}(C, G_1)}{\\text{Var}(G_1)} (g^* - \\mathbb{E}[G_1])\n$$\nWe compute the necessary moments: $\\mathbb{E}[C]=\\mu_C$, $\\mathbb{E}[G_1] = a_{CG_1}\\mu_C$, $\\text{Var}(G_1) = a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2$, and $\\text{Cov}(C, G_1) = a_{CG_1}\\sigma_C^2$.\nSubstituting these gives:\n$$\n\\mathbb{E}[C \\mid G_1 = g^*] = \\mu_C + \\frac{a_{CG_1}\\sigma_C^2}{a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2} (g^* - a_{CG_1}\\mu_C)\n$$\nAssembling the full expression:\n$$\n\\mathbb{E}[Y \\mid G_1 = g^*] = (a_{12}b_{2Y} + b_{1Y})g^* + b_{CY}\\left(\\mu_C + \\frac{a_{CG_1}\\sigma_C^2}{a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2} (g^* - a_{CG_1}\\mu_C)\\right)\n$$\nThis expression represents the prediction based on observation, which includes confounding bias from the unobserved common cause $C$.\n\n**Calculation of the Difference $\\Delta$**\n\nThe difference $\\Delta = \\mathbb{E}[Y \\mid G_1 = g^*] - \\mathbb{E}[Y \\mid do(G_1 = g^*)]$. Subtracting the interventional expression from the observational one, most terms cancel, leaving only the confounding bias term:\n$$\n\\Delta = b_{CY}\\frac{a_{CG_1}\\sigma_C^2}{a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2} (g^* - a_{CG_1}\\mu_C)\n$$\nThis term arises from the \"backdoor path\" $G_1 \\leftarrow C \\rightarrow Y$.\n\n**Numerical Computation**\n\nWe substitute the given numerical values: $\\mu_C = 0.5$, $\\sigma_C^2 = 1.0$, $a_{CG_1} = 1.3$, $\\sigma_1^2 = 0.4$, $b_{CY} = 1.1$, and $g^* = 0.2$.\nThe term $(g^* - a_{CG_1}\\mu_C) = 0.2 - (1.3 \\times 0.5) = -0.45$.\nThe fractional term $\\frac{a_{CG_1}\\sigma_C^2}{a_{CG_1}^2 \\sigma_C^2 + \\sigma_1^2} = \\frac{1.3 \\times 1.0}{1.3^2 \\times 1.0 + 0.4} = \\frac{1.3}{1.69 + 0.4} = \\frac{1.3}{2.09}$.\nFinally, we compute $\\Delta$:\n$$\n\\Delta = 1.1 \\times \\left(\\frac{1.3}{2.09}\\right) \\times (-0.45) = \\frac{1.1 \\times 1.3 \\times (-0.45)}{2.09} = \\frac{-0.6435}{2.09} \\approx -0.3078947...\n$$\nRounding to four significant figures, we get $\\Delta = -0.3079$.",
            "answer": "$$\n\\boxed{-0.3079}\n$$"
        },
        {
            "introduction": "Modern computational models can do more than just analyze existing data; they can actively guide future research by suggesting the most informative experiments to perform. This exercise delves into the principles of active learning within a Bayesian deep learning framework. You will apply the principles of optimal experimental design to select a CRISPR perturbation that maximizes the expected information gain, thereby learning how to quantify which experiment is predicted to most effectively reduce uncertainty about your model's parameters.",
            "id": "3299340",
            "problem": "You are given a Bayesian Deep State-Space Model (DSSM) of single-step dynamics under a CRISPR perturbation. The latent state is a vector $x \\in \\mathbb{R}^n$, the perturbation is $u \\in \\mathbb{R}^m$, and the unknown model parameters $\\theta \\in \\mathbb{R}^p$ have a Gaussian prior. Your task is to formulate and implement an active learning strategy that, for each provided test case, selects the perturbation $u$ that maximizes the expected information gain $\\mathbb{E}[\\Delta I(\\theta; \\mathcal{D} \\cup (x,u))]$ about $\\theta$ after observing the next single measurement. Use zero-based indexing for perturbation selection.\n\nThe DSSM is specified as follows. The latent dynamics are given by a one-step deep mapping\n$$\nx' = f(x, u) = W_2 \\,\\tanh\\!\\left(W_1 \\begin{bmatrix} x \\\\ u \\end{bmatrix}\\right),\n$$\nwhere $\\tanh(\\cdot)$ is applied elementwise. The observation model is a deep emission with linear parameterization,\n$$\ny = \\theta^\\top \\psi(x') + \\varepsilon, \\quad \\psi(x') = \\tanh(A x'),\n$$\nwhere $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_y^2)$ is Gaussian measurement noise.\n\nYou must base your derivation on principled definitions: Bayes' rule, the definition of Mutual Information (MI) as the expected Kullback–Leibler (KL) divergence between posterior and prior, and the standard properties of Gaussian distributions. Do not invoke any shortcut formulas not derived from these bases. Under the given model, the expected information gain for a single observation is to be computed by appropriately linearizing the observation with respect to $\\theta$ and using the Gaussian prior and noise assumptions.\n\nThe DSSM weight matrices used across all test cases are:\n$$\nW_1 = \\begin{bmatrix}\n0.8 & -0.5 & 0.3 & 1.0 & -0.7 \\\\\n0.1 & 0.9 & -1.2 & 0.5 & 0.3 \\\\\n-0.6 & 0.4 & 0.8 & -0.9 & 1.1 \\\\\n1.2 & -0.8 & 0.2 & 0.3 & -0.4\n\\end{bmatrix}, \\quad\nW_2 = \\begin{bmatrix}\n0.5 & -0.2 & 0.1 & 0.7 \\\\\n-0.3 & 0.8 & -0.5 & 0.2 \\\\\n0.4 & 0.0 & 0.6 & -0.1\n\\end{bmatrix}, \\quad\nA = \\begin{bmatrix}\n1.0 & -0.5 & 0.2 \\\\\n-0.3 & 0.7 & -0.9 \\\\\n0.6 & 0.1 & 0.4\n\\end{bmatrix}.\n$$\nThese correspond to $n=3$, $m=2$, $h=4$, $p=3$, with $W_1 \\in \\mathbb{R}^{h \\times (n+m)}$, $W_2 \\in \\mathbb{R}^{n \\times h}$, and $A \\in \\mathbb{R}^{p \\times n}$. The prior over $\\theta$ is $\\mathcal{N}(\\mu, \\Sigma)$ with mean $\\mu \\in \\mathbb{R}^p$ (not needed for the expected information gain in this setup) and covariance $\\Sigma \\in \\mathbb{R}^{p \\times p}$.\n\nFormulate the expected information gain for a single measurement under this model from first principles, and implement the following selection algorithm: for each candidate perturbation $u$, compute $x' = f(x,u)$, then compute $\\psi(x')$, then compute the expected information gain based on the Gaussian prior covariance $\\Sigma$ and noise variance $\\sigma_y^2$, and pick the $u$ that maximizes it.\n\nYour program must use the following test suite, which covers typical and edge scenarios. For each test case, you will receive a current state $x$, prior covariance $\\Sigma$, measurement noise standard deviation $\\sigma_y$, and a list of candidate perturbations $u$.\n\nTest case $1$ (happy path):\n- $x = \\begin{bmatrix} 0.5 \\\\ -0.3 \\\\ 0.1 \\end{bmatrix}$\n- $\\Sigma = \\mathrm{diag}\\!\\big(\\begin{bmatrix} 0.4 \\\\ 0.3 \\\\ 0.2 \\end{bmatrix}\\big)$\n- $\\sigma_y = 0.1$\n- Candidates $u$: $\\left\\{ \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}, \\begin{bmatrix} 0.5 \\\\ -0.5 \\end{bmatrix}, \\begin{bmatrix} 1.0 \\\\ 0.2 \\end{bmatrix}, \\begin{bmatrix} -0.8 \\\\ 0.9 \\end{bmatrix} \\right\\}$\n\nTest case $2$ (high-noise regime):\n- $x = \\begin{bmatrix} 0.2 \\\\ 0.9 \\\\ -1.2 \\end{bmatrix}$\n- $\\Sigma = \\mathrm{diag}\\!\\big(\\begin{bmatrix} 0.8 \\\\ 0.1 \\\\ 0.05 \\end{bmatrix}\\big)$\n- $\\sigma_y = 1.0$\n- Candidates $u$: $\\left\\{ \\begin{bmatrix} -0.3 \\\\ 0.7 \\end{bmatrix}, \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}, \\begin{bmatrix} 1.5 \\\\ -1.5 \\end{bmatrix}, \\begin{bmatrix} -2.0 \\\\ 2.0 \\end{bmatrix} \\right\\}$\n\nTest case $3$ (near-degenerate prior covariance and saturation test):\n- $x = \\begin{bmatrix} -0.1 \\\\ 0.0 \\\\ 0.05 \\end{bmatrix}$\n- $\\Sigma = \\mathrm{diag}\\!\\big(\\begin{bmatrix} 10^{-6} \\\\ 10^{-6} \\\\ 10^{-6} \\end{bmatrix}\\big)$\n- $\\sigma_y = 0.2$\n- Candidates $u$: $\\left\\{ \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}, \\begin{bmatrix} 3.0 \\\\ -3.0 \\end{bmatrix}, \\begin{bmatrix} -5.0 \\\\ 5.0 \\end{bmatrix}, \\begin{bmatrix} 0.1 \\\\ 0.1 \\end{bmatrix} \\right\\}$\n\nYour program should evaluate all candidate $u$ for each test case, select the perturbation maximizing the expected information gain, and output, for each test case, the zero-based index of the selected $u$ followed by the expected information gain value for that selected $u$ rounded to six decimal places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\texttt{[i_1,g_1,i_2,g_2,i_3,g_3]}$), where $i_k$ is an integer and $g_k$ is a float.\n\nNo physical units or angle units apply in this problem. All outputs must be numeric primitives as specified above.",
            "solution": "The objective is to select a perturbation $u$ that maximizes the expected information gain about the parameters $\\theta$. This gain is quantified by the mutual information $I(\\theta; Y | x, u)$ between the parameters and the future observation $Y$, conditioned on the current state $x$ and chosen action $u$.\n\nThe problem is framed in a Bayesian context. The parameters $\\theta$ have a Gaussian prior $p(\\theta) = \\mathcal{N}(\\theta | \\mu, \\Sigma)$, and the observation model $y = \\psi^\\top\\theta + \\varepsilon$ gives a Gaussian likelihood $p(y | \\theta, \\psi) = \\mathcal{N}(y | \\psi^\\top\\theta, \\sigma_y^2)$.\n\nThe mutual information is the reduction in the entropy of the parameters after observing the data: $I(\\theta; Y | \\psi) = H(\\theta) - H(\\theta | Y)$, where $H(\\theta|Y)$ is the conditional entropy.\n\nFor a Gaussian prior and likelihood (in $\\theta$), the posterior $p(\\theta|y)$ is also Gaussian. A key property of this Bayesian linear regression model is that the posterior covariance, $\\Sigma_{\\text{post}} = \\left( \\Sigma^{-1} + \\frac{1}{\\sigma_y^2} \\psi \\psi^\\top \\right)^{-1}$, does not depend on the specific measurement outcome $y$. This means the posterior entropy is also independent of $y$, so $H(\\theta|Y)$ is simply the posterior entropy.\n\nThe mutual information is therefore the difference between the prior and posterior entropies:\n$$\nI(\\theta; Y | \\psi) = H(\\mathcal{N}(\\mu, \\Sigma)) - H(\\mathcal{N}(\\mu_{\\text{post}}, \\Sigma_{\\text{post}})) = \\frac{1}{2} \\ln \\left( \\frac{\\det(\\Sigma)}{\\det(\\Sigma_{\\text{post}})} \\right)\n$$\nSubstituting the expression for $\\Sigma_{\\text{post}}$ and using the properties of determinants (specifically, $\\det(AB) = \\det(A)\\det(B)$ and the matrix determinant lemma $\\det(I+uv^\\top)=1+v^\\top u$), the expression simplifies to:\n$$\nI(u) = \\frac{1}{2} \\ln \\left( 1 + \\frac{1}{\\sigma_y^2} \\psi(u)^\\top \\Sigma \\psi(u) \\right)\n$$\nThis final expression gives the expected information gain for a given perturbation $u$, which determines the feature vector $\\psi(u)$.\n\nThe computational algorithm for each test case is:\n1. Initialize a maximum gain variable and a best index.\n2. For each candidate perturbation $u_i$:\n    a. Compute the next latent state: $x' = W_2 \\,\\tanh\\!\\left(W_1 \\begin{bmatrix} x \\\\ u_i \\end{bmatrix} \\right)$.\n    b. Compute the observation feature vector: $\\psi = \\tanh(A x')$.\n    c. Compute the quadratic form: $q = \\psi^\\top \\Sigma \\psi$.\n    d. Calculate the information gain: $G_i = \\frac{1}{2} \\ln \\left( 1 + q / \\sigma_y^2 \\right)$.\n    e. If $G_i$ is greater than the current maximum, update the maximum gain and best index.\n3. After iterating through all candidates, the best index and its corresponding maximum gain are the result for that test case. This is repeated for all test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the active learning problem for the given DSSM and test cases.\n    \"\"\"\n    # Define constant model matrices\n    W1 = np.array([\n        [0.8, -0.5, 0.3, 1.0, -0.7],\n        [0.1, 0.9, -1.2, 0.5, 0.3],\n        [-0.6, 0.4, 0.8, -0.9, 1.1],\n        [1.2, -0.8, 0.2, 0.3, -0.4]\n    ])\n    W2 = np.array([\n        [0.5, -0.2, 0.1, 0.7],\n        [-0.3, 0.8, -0.5, 0.2],\n        [0.4, 0.0, 0.6, -0.1]\n    ])\n    A = np.array([\n        [1.0, -0.5, 0.2],\n        [-0.3, 0.7, -0.9],\n        [0.6, 0.1, 0.4]\n    ])\n\n    # Define test cases\n    test_cases = [\n        {\n            \"x\": np.array([0.5, -0.3, 0.1]),\n            \"Sigma\": np.diag([0.4, 0.3, 0.2]),\n            \"sigma_y\": 0.1,\n            \"candidates_u\": [\n                np.array([0.0, 0.0]),\n                np.array([0.5, -0.5]),\n                np.array([1.0, 0.2]),\n                np.array([-0.8, 0.9])\n            ]\n        },\n        {\n            \"x\": np.array([0.2, 0.9, -1.2]),\n            \"Sigma\": np.diag([0.8, 0.1, 0.05]),\n            \"sigma_y\": 1.0,\n            \"candidates_u\": [\n                np.array([-0.3, 0.7]),\n                np.array([0.0, 0.0]),\n                np.array([1.5, -1.5]),\n                np.array([-2.0, 2.0])\n            ]\n        },\n        {\n            \"x\": np.array([-0.1, 0.0, 0.05]),\n            \"Sigma\": np.diag([1e-6, 1e-6, 1e-6]),\n            \"sigma_y\": 0.2,\n            \"candidates_u\": [\n                np.array([0.0, 0.0]),\n                np.array([3.0, -3.0]),\n                np.array([-5.0, 5.0]),\n                np.array([0.1, 0.1])\n            ]\n        }\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        x = case[\"x\"]\n        Sigma = case[\"Sigma\"]\n        sigma_y = case[\"sigma_y\"]\n        candidates_u = case[\"candidates_u\"]\n        \n        sigma_y_sq = sigma_y**2\n        \n        best_u_index = -1\n        max_info_gain = -1.0\n\n        for i, u in enumerate(candidates_u):\n            # Step 1: Compute next state x'\n            v = np.concatenate((x, u))\n            h = np.tanh(W1 @ v)\n            x_prime = W2 @ h\n            \n            # Step 2: Compute feature vector psi\n            psi = np.tanh(A @ x_prime)\n            \n            # Step 3: Compute quadratic form psi^T * Sigma * psi\n            quad_form = psi.T @ Sigma @ psi\n            \n            # Step 4: Compute expected information gain\n            info_gain = 0.5 * np.log(1 + quad_form / sigma_y_sq)\n            \n            # Step 5: Update best perturbation\n            if info_gain > max_info_gain:\n                max_info_gain = info_gain\n                best_u_index = i\n\n        final_results.append(str(best_u_index))\n        # Round and format gain to six decimal places\n        final_results.append(f\"{max_info_gain:.6f}\")\n        \n    print(f\"[{','.join(final_results)}]\")\n\nsolve()\n```"
        }
    ]
}