{
    "hands_on_practices": [
        {
            "introduction": "要掌握哈密尔顿蒙特卡洛（HMC）方法，一个有效的起点是研究其在理想化场景下的行为。本练习探讨了一个完美的情形：当动能度量与高斯后验分布的协方差相匹配时，动力学系统会发生什么变化。通过解决这个问题，你将分析并证明复杂的哈密顿流如何简化为一组解耦的、可精确求解的谐振子，从而为理解HMC为何高效提供一个重要的理论基准。",
            "id": "3318349",
            "problem": "考虑一个计算系统生物学中的参数推断任务，其中 $d$ 维参数向量 $\\theta$ 的后验分布为高斯分布 $\\pi(\\theta) = \\mathcal{N}(0, \\Sigma)$，$\\Sigma \\in \\mathbb{R}^{d \\times d}$ 是一个对称正定协方差矩阵。为设计一个高效的采样器，我们在正则相空间 $(q,p) \\in \\mathbb{R}^{d} \\times \\mathbb{R}^{d}$ 上采用哈密顿蒙特卡洛（HMC, Hamiltonian Monte Carlo），其哈密顿量为 $H(q,p) = U(q) + K(p)$。其中，势能 $U(q)$ 由负对数后验定义，即 $U(q) = \\frac{1}{2} q^{\\top} \\Sigma^{-1} q$，动能则选择为 $K(p) = \\frac{1}{2} p^{\\top} \\Sigma p$。这种选择使用相同的度量 $\\Sigma$ 来建模参数空间几何和动量空间几何，这对于其线性化涨落共享相同协方差结构的动力学系统是合理的。\n\n仅从哈密顿动力学的基本定义出发，即哈密顿方程 $\\dot{q} = \\partial H/\\partial p$ 和 $\\dot{p} = - \\partial H/\\partial q$，推导由 $H(q,p)$ 导出的精确、连续时间的哈密顿流，并证明它是一组具有单位角频率的解耦谐振子。然后，提供将初始状态 $(q(0), p(0))$ 映射到 $(q(t), p(t))$ 的精确时间-$t$ 流映射 $\\Phi_{t}$，并将其表示为关于 $t$ 和 $\\Sigma$ 的单个闭式 $2d \\times 2d$ 分块矩阵。\n\n答案规格：\n- 使用 $t$ 的三角函数表示最终的流映射 $\\Phi_{t}$，其中 $t$ 以弧度为单位。\n- 你的最终答案必须是单个闭式解析表达式。\n- 无需进行舍入；请提供精确表达式。",
            "solution": "解决方案的步骤是：首先为给定的哈密顿量推导哈密顿方程，然后证明所得的线性常微分方程组对应于一组解耦的谐振子，最后求解这些方程以找到流映射。\n\n哈密顿量由 $H(q, p) = U(q) + K(p) = \\frac{1}{2} q^{\\top} \\Sigma^{-1} q + \\frac{1}{2} p^{\\top} \\Sigma p$ 给出。\n\n首先，我们计算 $H(q,p)$ 关于 $q$ 和 $p$ 的梯度。对于对称矩阵 $A$，二次型 $x^{\\top} A x$ 关于 $x$ 的梯度是 $2 A x$。因此，偏导数为：\n$$\n\\frac{\\partial H}{\\partial p} = \\frac{\\partial}{\\partial p} \\left( \\frac{1}{2} p^{\\top} \\Sigma p \\right) = \\frac{1}{2} (2 \\Sigma p) = \\Sigma p\n$$\n$$\n\\frac{\\partial H}{\\partial q} = \\frac{\\partial}{\\partial q} \\left( \\frac{1}{2} q^{\\top} \\Sigma^{-1} q \\right) = \\frac{1}{2} (2 \\Sigma^{-1} q) = \\Sigma^{-1} q\n$$\n这里，我们利用了这样一个事实：由于 $\\Sigma$ 是对称的，其逆矩阵 $\\Sigma^{-1}$ 也是对称的。\n\n将这些梯度代入哈密顿方程 $\\dot{q} = \\frac{\\partial H}{\\partial p}$ 和 $\\dot{p} = - \\frac{\\partial H}{\\partial q}$，我们得到控制动力学的方程组：\n$$\n\\dot{q} = \\Sigma p\n$$\n$$\n\\dot{p} = -\\Sigma^{-1} q\n$$\n这是一个包含 $2d$ 个耦合的一阶线性常微分方程组。\n\n为了证明该系统描述了一组解耦的谐振子，我们进行坐标变换。由于 $\\Sigma$ 是一个实对称正定矩阵，它可以进行谱分解 $\\Sigma = V \\Lambda V^{\\top}$，其中 $V$ 是一个正交矩阵（$V^{\\top}V = VV^{\\top} = I$，其中 $I$ 是 $d \\times d$ 单位矩阵），其列是 $\\Sigma$ 的特征向量，$\\Lambda$ 是一个包含相应正特征值 $\\lambda_i$ 的对角矩阵。其逆矩阵则为 $\\Sigma^{-1} = V \\Lambda^{-1} V^{\\top}$。\n\n让我们通过以下变换定义一组新坐标 $(\\tilde{q}, \\tilde{p})$：\n$$\n\\tilde{q} = V^{\\top} q \\quad \\implies \\quad q = V \\tilde{q}\n$$\n$$\n\\tilde{p} = V^{\\top} p \\quad \\implies \\quad p = V \\tilde{p}\n$$\n时间导数通过 $\\dot{q} = V \\dot{\\tilde{q}}$ 和 $\\dot{p} = V \\dot{\\tilde{p}}$ 相关联。将这些代入运动方程：\n对于 $\\dot{q}$ 方程：\n$$\nV \\dot{\\tilde{q}} = \\Sigma (V \\tilde{p}) = (V \\Lambda V^{\\top}) V \\tilde{p} = V \\Lambda \\tilde{p}\n$$\n从左侧乘以 $V^{\\top}$ 得到：\n$$\n\\dot{\\tilde{q}} = \\Lambda \\tilde{p}\n$$\n对于 $\\dot{p}$ 方程：\n$$\nV \\dot{\\tilde{p}} = -\\Sigma^{-1} (V \\tilde{q}) = -(V \\Lambda^{-1} V^{\\top}) V \\tilde{q} = -V \\Lambda^{-1} \\tilde{q}\n$$\n从左侧乘以 $V^{\\top}$ 得到：\n$$\n\\dot{\\tilde{p}} = -\\Lambda^{-1} \\tilde{q}\n$$\n因为 $\\Lambda$ 是一个对角矩阵，$\\Lambda = \\text{diag}(\\lambda_1, \\dots, \\lambda_d)$，该系统解耦为 $d$ 对独立的方程，每个分量 $i \\in \\{1, \\dots, d\\}$ 对应一对：\n$$\n\\dot{\\tilde{q}}_i = \\lambda_i \\tilde{p}_i\n$$\n$$\n\\dot{\\tilde{p}}_i = -\\frac{1}{\\lambda_i} \\tilde{q}_i\n$$\n为了看出这些是谐振子，我们可以对第一个方程关于时间求导，并代入第二个方程：\n$$\n\\ddot{\\tilde{q}}_i = \\lambda_i \\dot{\\tilde{p}}_i = \\lambda_i \\left(-\\frac{1}{\\lambda_i} \\tilde{q}_i\\right) = -\\tilde{q}_i\n$$\n这就得到了简谐振子的方程 $\\ddot{\\tilde{q}}_i + \\tilde{q}_i = 0$。标准形式是 $\\ddot{x} + \\omega^2 x = 0$，因此对于所有 $i=1, \\dots, d$，角频率都是 $\\omega_i = 1$。这证实了该动力学是一组具有单位角频率的 $d$ 个解耦谐振子的动力学。\n\n现在，我们求解时间-$t$ 流映射。$\\ddot{\\tilde{q}}_i + \\tilde{q}_i = 0$ 的解的形式为 $\\tilde{q}_i(t) = A \\cos(t) + B \\sin(t)$。应用初始条件：\n$\\tilde{q}_i(0) = A$。\n$\\dot{\\tilde{q}}_i(0) = B$。从一阶方程可知，$\\dot{\\tilde{q}}_i(0) = \\lambda_i \\tilde{p}_i(0)$。\n所以，$\\tilde{q}_i(t)$ 的解是：\n$$\n\\tilde{q}_i(t) = \\tilde{q}_i(0) \\cos(t) + \\lambda_i \\tilde{p}_i(0) \\sin(t)\n$$\n对于 $\\tilde{p}_i(t)$，我们有 $\\tilde{p}_i(t) = \\frac{1}{\\lambda_i} \\dot{\\tilde{q}}_i(t) = \\frac{1}{\\lambda_i} \\left( -\\tilde{q}_i(0) \\sin(t) + \\lambda_i \\tilde{p}_i(0) \\cos(t) \\right)$：\n$$\n\\tilde{p}_i(t) = -\\frac{1}{\\lambda_i} \\tilde{q}_i(0) \\sin(t) + \\tilde{p}_i(0) \\cos(t)\n$$\n我们可以将此写成变换后变量的向量形式：\n$$\n\\tilde{q}(t) = \\cos(t) \\tilde{q}(0) + \\sin(t) \\Lambda \\tilde{p}(0)\n$$\n$$\n\\tilde{p}(t) = -\\sin(t) \\Lambda^{-1} \\tilde{q}(0) + \\cos(t) \\tilde{p}(0)\n$$\n最后，我们变换回原始坐标 $(q,p)$：\n$q(t) = V\\tilde{q}(t) = V(\\cos(t) \\tilde{q}(0) + \\sin(t) \\Lambda \\tilde{p}(0))$\n使用 $\\tilde{q}(0) = V^{\\top}q(0)$ 和 $\\tilde{p}(0) = V^{\\top}p(0)$：\n$q(t) = V(\\cos(t) V^{\\top}q(0) + \\sin(t) \\Lambda V^{\\top}p(0)) = \\cos(t) (VV^{\\top})q(0) + \\sin(t) (V \\Lambda V^{\\top})p(0)$\n由于 $VV^{\\top}=I$ 且 $\\Sigma = V \\Lambda V^{\\top}$，我们得到：\n$$\nq(t) = \\cos(t) q(0) + \\sin(t) \\Sigma p(0)\n$$\n类似地，对于 $p(t)$：\n$p(t) = V\\tilde{p}(t) = V(-\\sin(t) \\Lambda^{-1} \\tilde{q}(0) + \\cos(t) \\tilde{p}(0))$\n$p(t) = V(-\\sin(t) \\Lambda^{-1} V^{\\top}q(0) + \\cos(t) V^{\\top}p(0)) = -\\sin(t) (V \\Lambda^{-1} V^{\\top})q(0) + \\cos(t) (VV^{\\top})p(0)$\n由于 $\\Sigma^{-1} = V \\Lambda^{-1} V^{\\top}$，我们得到：\n$$\np(t) = -\\sin(t) \\Sigma^{-1} q(0) + \\cos(t) p(0)\n$$\n这定义了时间-$t$ 流映射 $\\Phi_t$，使得 $\\begin{pmatrix} q(t) \\\\ p(t) \\end{pmatrix} = \\Phi_t \\begin{pmatrix} q(0) \\\\ p(0) \\end{pmatrix}$。将其写成 $2d \\times 2d$ 分块矩阵形式：\n$$\n\\begin{pmatrix} q(t) \\\\ p(t) \\end{pmatrix} = \\begin{pmatrix} \\cos(t) I  & \\sin(t) \\Sigma \\\\ -\\sin(t) \\Sigma^{-1} & \\cos(t) I \\end{pmatrix} \\begin{pmatrix} q(0) \\\\ p(0) \\end{pmatrix}\n$$\n因此，流映射 $\\Phi_t$ 就是右侧的 $2d \\times 2d$ 矩阵。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\cos(t) I & \\sin(t) \\Sigma \\\\\n-\\sin(t) \\Sigma^{-1} & \\cos(t) I\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在运行HMC采样器之后，评估结果的质量是至关重要的一步。本练习将指导你计算两个基石级的MCMC诊断统计量：Gelman-Rubin统计量（$\\widehat{R}$）和有效样本量（$N_{eff}$）。通过处理一个实际的动力学系统参数推断场景，你将掌握量化采样链收敛性和效率的实用技能，这对于任何可靠的贝叶斯推断都是必不可少的。",
            "id": "3318340",
            "problem": "在一项系统生物学研究中，一个由非线性常微分方程描述的转录调控模型，使用哈密顿蒙特卡洛（HMC）方法对时程数据进行拟合。令 $\\boldsymbol{\\theta}$ 表示动力学参数，定义感兴趣的导出量 $g(\\boldsymbol{\\theta})$ 为在模型动态平衡决定的固定诱导剂浓度下，预测的稳态蛋白质丰度。运行四个独立的 HMC 链，并获得 $g(\\boldsymbol{\\theta})$ 的预热后抽样。对于每个链 $k \\in \\{1,2,3,4\\}$，将其抽样表示为 $y_{k,1},\\dots,y_{k,n}$，其中 $n$ 是每个链的预热后迭代次数。\n\n给定 $m=4$ 和 $n=2000$。$g(\\boldsymbol{\\theta})$ 的各链摘要统计如下：\n- 链1：样本均值 $42.5$，样本方差 $9.1$。\n- 链2：样本均值 $41.5$，样本方差 $8.9$。\n- 链3：样本均值 $42.2$，样本方差 $9.2$。\n- 链4：样本均值 $41.8$，样本方差 $9.0$。\n\n在每个链内部，$y_{k,i}$ 的边际动态可以由一个一阶自回归过程近似，变换后序列 $y_{k,i}$ 的滞后一阶自相关系数为 $\\phi_{k}$：\n- 链1：$\\phi_{1} = 0.70$。\n- 链2：$\\phi_{2} = 0.65$。\n- 链3：$\\phi_{3} = 0.72$。\n- 链4：$\\phi_{4} = 0.68$。\n\n仅使用这些摘要信息：\n1. 从第一性原理出发，计算 $g(\\boldsymbol{\\theta})$ 的经典（非分割）Gelman–Rubin 潜在尺度缩减因子 $\\widehat{R}$。\n2. 通过在每个滞后点上对链内自相关进行跨链简单平均来聚合自相关，并使用聚合自相关的一阶自回归近似下的积分自相关时间，计算 $g(\\boldsymbol{\\theta})$ 的多链有效样本量。\n3. 根据普遍采用的标准 $\\widehat{R} < 1.01$ 和 $g(\\boldsymbol{\\theta})$ 的有效样本量至少为 $1000$，判断此导出量的抽样是否已令人满意地收敛。\n\n将计算出的 $\\widehat{R}$ 值作为最终答案，四舍五入到四位有效数字。最终答案不需要单位。",
            "solution": "该问题需要三部分分析：(1) 计算 Gelman–Rubin 统计量 $\\widehat{R}$，(2) 计算多链有效样本量 $N_{eff}$，以及 (3) 基于这两个指标对抽样收敛性做出结论。\n\n### 步骤1：计算 Gelman–Rubin 统计量 $\\widehat{R}$\n\nGelman–Rubin 潜在尺度缩减因子 $\\widehat{R}$ 是通过比较 MCMC 抽样的链内方差和链间方差来诊断收敛性的。所提供的数据如下：\n- 链数，$m=4$。\n- 每条链的预热后抽样数，$n=2000$。\n- 各链均值 $(\\bar{y}_k)$: $\\bar{y}_1=42.5$, $\\bar{y}_2=41.5$, $\\bar{y}_3=42.2$, $\\bar{y}_4=41.8$。\n- 各链方差 $(s_k^2)$: $s_1^2=9.1$, $s_2^2=8.9$, $s_3^2=9.2$, $s_4^2=9.0$。\n\n首先，我们计算链内方差的平均值，记为 $W$。\n$$W = \\frac{1}{m} \\sum_{k=1}^{m} s_k^2$$\n代入给定值：\n$$W = \\frac{1}{4}(9.1 + 8.9 + 9.2 + 9.0) = \\frac{36.2}{4} = 9.05$$\n\n接下来，我们计算链间方差 $B$，它是各链均值的方差，并按 $n$进行缩放。首先，我们计算总均值 $\\bar{\\bar{y}}$，即所有链中所有抽样的均值。\n$$\\bar{\\bar{y}} = \\frac{1}{m} \\sum_{k=1}^{m} \\bar{y}_k$$\n$$\\bar{\\bar{y}} = \\frac{1}{4}(42.5 + 41.5 + 42.2 + 41.8) = \\frac{168}{4} = 42.0$$\n现在，我们计算 $B$：\n$$B = \\frac{n}{m-1} \\sum_{k=1}^{m} (\\bar{y}_k - \\bar{\\bar{y}})^2$$\n$$B = \\frac{2000}{4-1} \\left( (42.5-42.0)^2 + (41.5-42.0)^2 + (42.2-42.0)^2 + (41.8-42.0)^2 \\right)$$\n$$B = \\frac{2000}{3} \\left( (0.5)^2 + (-0.5)^2 + (0.2)^2 + (-0.2)^2 \\right)$$\n$$B = \\frac{2000}{3} (0.25 + 0.25 + 0.04 + 0.04) = \\frac{2000}{3} (0.58) = \\frac{1160}{3}$$\n\n待估量的估计边际后验方差 $\\widehat{\\text{var}}^+$ 是 $W$ 和 $B$ 的加权平均。\n$$\\widehat{\\text{var}}^+ = \\frac{n-1}{n} W + \\frac{B}{n}$$\n$$\\widehat{\\text{var}}^+ = \\frac{2000-1}{2000} (9.05) + \\frac{1}{2000} \\left( \\frac{1160}{3} \\right) = \\frac{1999}{2000} (9.05) + \\frac{1160}{6000} \\approx 9.2388$$\n\n最后，潜在尺度缩减因子 $\\widehat{R}$ 是总估计方差与链内方差之比的平方根。\n$$\\widehat{R} = \\sqrt{\\frac{\\widehat{\\text{var}}^+}{W}}$$\n$$\\widehat{R} = \\sqrt{\\frac{9.238808...}{9.05}} \\approx \\sqrt{1.02086} \\approx 1.0103775...$$\n\n### 步骤2：计算多链有效样本量 $N_{eff}$\n\n有效样本量 $N_{eff}$ 是对 MCMC 抽样中存在的自相关性进行调整后的总样本数，$N=mn$。$N_{eff} = N / \\tau$，其中 $\\tau$ 是积分自相关时间。\n问题要求通过在每个滞后 $t$ 处进行平均来聚合链内自相关。对于一个 AR(1) 过程，链 $k$ 在滞后 $t$ 处的自相关为 $\\rho_t^{(k)} = \\phi_k^t$。\n聚合后的滞后 $t$ 处的自相关为 $\\bar{\\rho}_t = \\frac{1}{m} \\sum_{k=1}^{m} \\rho_t^{(k)} = \\frac{1}{m} \\sum_{k=1}^{m} \\phi_k^t$。\n那么，积分自相关时间 $\\tau$ 为：\n$$\\tau = 1 + 2 \\sum_{t=1}^{\\infty} \\bar{\\rho}_t = 1 + 2 \\sum_{t=1}^{\\infty} \\left( \\frac{1}{m} \\sum_{k=1}^{m} \\phi_k^t \\right)$$\n通过交换求和顺序：\n$$\\tau = 1 + \\frac{2}{m} \\sum_{k=1}^{m} \\left( \\sum_{t=1}^{\\infty} \\phi_k^t \\right)$$\n内部的和是一个几何级数：$\\sum_{t=1}^{\\infty} \\phi_k^t = \\frac{\\phi_k}{1-\\phi_k}$。 因此：\n$$\\tau = 1 + \\frac{2}{m} \\sum_{k=1}^{m} \\frac{\\phi_k}{1-\\phi_k}$$\n给定的自相关系数为 $\\phi_1=0.70$, $\\phi_2=0.65$, $\\phi_3=0.72$, $\\phi_4=0.68$。\n我们来计算 $\\frac{\\phi_k}{1-\\phi_k}$ 这些项：\n- $k=1$: $\\frac{0.70}{1-0.70} = \\frac{0.70}{0.30} = \\frac{7}{3}$\n- $k=2$: $\\frac{0.65}{1-0.65} = \\frac{0.65}{0.35} = \\frac{13}{7}$\n- $k=3$: $\\frac{0.72}{1-0.72} = \\frac{0.72}{0.28} = \\frac{18}{7}$\n- $k=4$: $\\frac{0.68}{1-0.68} = \\frac{0.68}{0.32} = \\frac{17}{8}$\n现在，我们计算 $\\tau$：\n$$\\tau = 1 + \\frac{2}{4} \\left( \\frac{7}{3} + \\frac{13}{7} + \\frac{18}{7} + \\frac{17}{8} \\right) = 1 + \\frac{1}{2} \\left( \\frac{7}{3} + \\frac{31}{7} + \\frac{17}{8} \\right) \\approx 5.44345$$\n总样本数为 $N = m \\times n = 4 \\times 2000 = 8000$。\n有效样本量为：\n$$N_{eff} = \\frac{N}{\\tau} = \\frac{8000}{5.44345} \\approx 1469.65$$\n\n### 步骤3：关于抽样收敛性的结论\n\n收敛标准给定为 $\\widehat{R} < 1.01$ 和 $N_{eff} \\ge 1000$。\n- 我们计算出的 $\\widehat{R}$ 约为 $1.0104$。这个值不满足条件 $\\widehat{R} < 1.01$。\n- 我们计算出的 $N_{eff}$ 约为 $1470$。这个值满足条件 $N_{eff} \\ge 1000$。\n\n由于两个标准之一（$\\widehat{R} < 1.01$）未被满足，根据指定的标准，导出量 $g(\\boldsymbol{\\theta})$ 的抽样尚未令人满意地收敛。链间方差相对于链内方差仍然略高，这表明各链尚未完全探索相同的后验分布。\n\n最终要求回答的是将 $\\widehat{R}$ 的值四舍五入到四位有效数字。\n$\\widehat{R} = 1.0103775...$\n四舍五入到四位有效数字为 $1.010$。",
            "answer": "$$\\boxed{1.010}$$"
        },
        {
            "introduction": "真实的生物系统常常表现出异质性，这可以通过混合模型进行建模。这项动手编程挑战深入探讨了这样一个混合动力学模型，并特别关注“标签交换”问题——这是混合模型推断中一个常见的陷阱。你将需要实现HMC采样器的核心组件（后验梯度和蛙跳积分），并用它来诊断这种模型对称性对采样器行为的具体影响，从而将抽象的理论性质与具体的计算实践联系起来。",
            "id": "3318302",
            "problem": "考虑一个用于单细胞亚群的混合动力学模型，其中每个亚群索引 $k \\in \\{1,\\dots,K\\}$ 都有一组参数 $\\theta^{(k)} = (a_k, x_{0,k})$，这些参数控制一个标量线性常微分方程 $dx/dt = -a_k x$，其解为 $x_k(t) = x_{0,k} \\exp(-a_k t)$。我们在时间点 $t_i$（$i \\in \\{1,\\dots,N\\}$）观测到标量测量值 $y_i$，这些测量值是从一个有限混合模型中独立抽取的。该模型的混合权重为 $\\pi_k$，满足 $\\sum_{k=1}^K \\pi_k = 1$ 和对所有 $k$ 都有 $\\pi_k \\ge 0$，观测噪声的标准差 $\\sigma$ 已知。形式上，数据模型为\n$$\np(y_i \\mid \\{\\theta^{(k)}\\}_{k=1}^K, \\{\\pi_k\\}_{k=1}^K) \\;=\\; \\sum_{k=1}^K \\pi_k \\, \\mathcal{N}\\big(y_i \\,\\big|\\, x_{0,k}\\exp(-a_k t_i), \\, \\sigma^2 \\big),\n$$\n且对于不同的 $i$ 是独立的。\n\n为应用哈密顿蒙特卡洛（HMC），我们将采用一种无约束的参数化方法。令 $\\alpha_k = \\log a_k$（因此 $a_k = \\exp(\\alpha_k)$），并设 $z \\in \\mathbb{R}^K$ 为混合权重的 logits，其 softmax 映射为\n$$\n\\pi_k(z) = \\frac{\\exp(z_k)}{\\sum_{j=1}^K \\exp(z_j)}.\n$$\n我们对无约束参数设置独立的高斯先验：\n$$\n\\alpha_k \\sim \\mathcal{N}(\\mu_\\alpha, \\sigma_\\alpha^2), \\quad x_{0,k} \\sim \\mathcal{N}(\\mu_x, \\sigma_x^2), \\quad z_k \\sim \\mathcal{N}(0, \\tau^2),\n$$\n在 $k \\in \\{1,\\dots,K\\}$ 上独立。这一选择保留了标签对称性，因为先验在所有 $k$ 上是可交换的。\n\n将无约束变量 $(\\{\\alpha_k\\}, \\{x_{0,k}\\}, z)$ 中的后验密度（忽略归一化常数）定义为似然与先验的乘积。用 $\\log p(\\alpha, x_0, z \\mid \\{(t_i,y_i)\\}_{i=1}^N)$ 表示对数后验，其中 $\\alpha = (\\alpha_1,\\dots,\\alpha_K)$ 且 $x_0 = (x_{0,1},\\dots,x_{0,K})$。对于单位质量矩阵的 HMC，其哈密顿量为\n$$\nH(q, r) \\;=\\; -\\log p(q) \\;+\\; \\frac{1}{2}\\, r^\\top r,\n$$\n其中 $q$ 堆叠了所有无约束参数，$r$ 是维度匹配的动量，其元素在每个 HMC 迭代中独立地服从标准正态分布。\n\n您需要处理由组分标签上的置换群引起的标签交换对称性。对于 $K=2$，令 $P$ 为标签交换置换，它将\n$$\n(\\alpha_1,\\alpha_2, x_{0,1},x_{0,2}, z_1, z_2) \\mapsto (\\alpha_2,\\alpha_1, x_{0,2},x_{0,1}, z_2, z_1),\n$$\n并对分组的动量分量应用相同的交换。因为似然和先验对于重新标记都是对称的，所以后验、其梯度以及哈密顿向量场在 $P$ 作用下都是不变的。\n\n仅从 (i) 贝叶斯法则，(ii) softmax 函数和高斯对数密度的定义，(iii) 线性常微分方程的解 $x_k(t) = x_{0,k} \\exp(-a_k t)$（其中 $a_k = \\exp(\\alpha_k)$），以及 (iv) 哈密顿蒙特卡洛（HMC）蛙跳积分的定义出发，推导计算对数后验及其关于无约束变量的梯度所需的表达式。使用这些表达式构建一个程序，用于评估 HMC 的对称性诱导诊断指标。\n\n使用以下固定且科学上合理的设置：\n- 混合组分数：$K = 2$。\n- 观测数量：$N = 5$。\n- 观测时间：$t = [\\,0.0,\\, 0.5,\\, 1.0,\\, 1.5,\\, 2.0\\,]$。\n- 观测数据：$y = [\\,1.95,\\, 1.50,\\, -0.40,\\, 0.90,\\, 0.70\\,]$。\n- 观测噪声标准差（已知）：$\\sigma = 0.1$。\n- 先验超参数：$\\mu_\\alpha = 0.0$, $\\sigma_\\alpha = 1.0$, $\\mu_x = 0.0$, $\\sigma_x = 2.0$, $\\tau = 1.0$。\n\n定义基础无约束参数向量\n$$\nq_{\\mathrm{base}} = \\big(\\alpha_1, \\alpha_2, x_{0,1}, x_{0,2}, z_1, z_2\\big) \\\\\n= \\big(\\,-0.5108256238,\\; -0.1053605157,\\; 1.8,\\; -1.1,\\; 0.3,\\; -0.3 \\,\\big).\n$$\n定义相关的动量向量\n$$\nr_{\\mathrm{base}} = \\big(\\,0.10,\\; -0.20,\\; 0.30,\\; -0.10,\\; 0.05,\\; -0.05\\,\\big).\n$$\n如上所述，定义交换组分标签的置换 $P$。定义使用蛙跳法的哈密顿蒙特卡洛（HMC）积分器，步长 $\\varepsilon = 0.01$，步数 $L = 25$。必须使用单位质量矩阵。\n\n您的程序必须：\n- 针对 $K=2$ 以及指定的数据和先验，使用所定义的混合似然，实现对数后验及其关于无约束参数 $(\\alpha, x_0, z)$ 的梯度。\n- 实现哈密顿量、蛙跳积分器以及作用于参数和动量（通过交换组分标签）的置换算子 $P$。\n- 计算以下测试量，它们将用作测试套件：\n    1. $T_1$：绝对差 $|\\log p(q_{\\mathrm{base}}) - \\log p(P q_{\\mathrm{base}})|$。\n    2. $T_2$：绝对差 $|H(q_{\\mathrm{base}}, r_{\\mathrm{base}}) - H(P q_{\\mathrm{base}}, P r_{\\mathrm{base}})|$。\n    3. $T_3$：确定性地初始化两个 HMC 提议：一个从 $(q_{\\mathrm{base}}, r_{\\mathrm{base}})$ 开始，另一个从 $(P q_{\\mathrm{base}}, P r_{\\mathrm{base}})$ 开始，每个都用步长 $\\varepsilon$ 进行 $L$ 步蛙跳积分。计算接受概率\n       $$\n       a_1 = \\min\\left(1, \\exp\\big(-H(q', r') + H(q_{\\mathrm{base}}, r_{\\mathrm{base}})\\big)\\right), \\quad\n       a_2 = \\min\\left(1, \\exp\\big(-H(P q', P r') + H(P q_{\\mathrm{base}}, P r_{\\mathrm{base}})\\big)\\right),\n       $$\n       其中 $(q',r')$ 是从 $(q_{\\mathrm{base}}, r_{\\mathrm{base}})$ 得到的提议，而 $P q', P r'$ 表示对置换后的初始值进行积分后得到的置换提议。报告 $T_3 = |a_1 - a_2|$。\n    4. $T_4$：在 $q_{\\mathrm{base}}$ 处的梯度与在 $P q_{\\mathrm{base}}$ 处进行逆置换后的梯度之差的欧几里得范数，即\n       $$\n       T_4 = \\left\\|\\nabla \\log p(q_{\\mathrm{base}}) - P^{-1}\\big(\\nabla \\log p(P q_{\\mathrm{base}})\\big) \\right\\|_2.\n       $$\n    5. $T_5$：在混合权重接近退化的边缘情况下的稳定性诊断。令 $q_{\\mathrm{edge}} = \\big(\\alpha_1, \\alpha_2, x_{0,1}, x_{0,2}, z_1, z_2\\big)$，其中 $(\\alpha_1, \\alpha_2, x_{0,1}, x_{0,2})$ 与 $q_{\\mathrm{base}}$ 中的相同，而 $(z_1, z_2) = (-20.0, 0.0)$。计算梯度 $\\nabla \\log p(q_{\\mathrm{edge}})$ 并返回一个布尔值 $T_5$，指示所有分量是否均为有限值（没有非数值（Not-a-Number）或无穷大）。\n\n您的程序应生成单行输出，其中包含这些结果，格式为逗号分隔的列表并用方括号括起，顺序为 $[T_1, T_2, T_3, T_4, T_5]$。所有浮点量都应以其默认字符串表示形式输出，最终的布尔值应为 True 或 False。此问题不涉及角度或物理单位；因此，无需进行单位换算。该程序不得接受任何输入，并且必须使用所提供的常数确定性地运行。",
            "solution": "### I. 数学公式\n\n无约束参数向量为 $q = (\\alpha_1, \\alpha_2, x_{0,1}, x_{0,2}, z_1, z_2) \\in \\mathbb{R}^6$。后验密度由贝叶斯法则给出：$p(q \\mid \\text{data}) \\propto p(\\text{data} \\mid q) p(q)$。我们使用未归一化的对数后验，记为 $\\log p(q)$。\n\n$\\log p(q) = \\log \\mathcal{L}(q) + \\log p_{\\text{prior}}(q)$\n\n**1. 对数先验密度**\n\n无约束参数的先验是独立的高斯分布：$\\alpha_k \\sim \\mathcal{N}(\\mu_\\alpha, \\sigma_\\alpha^2)$， $x_{0,k} \\sim \\mathcal{N}(\\mu_x, \\sigma_x^2)$，以及 $z_k \\sim \\mathcal{N}(0, \\tau^2)$。忽略常数项，对数先验密度为：\n$$\n\\log p_{\\text{prior}}(q) = -\\sum_{k=1}^2 \\left( \\frac{(\\alpha_k - \\mu_\\alpha)^2}{2\\sigma_\\alpha^2} + \\frac{(x_{0,k} - \\mu_x)^2}{2\\sigma_x^2} + \\frac{z_k^2}{2\\tau^2} \\right)\n$$\n\n**2. 对数似然函数**\n\n$N$ 个独立观测值的似然是每个观测值似然的乘积，因此对数似然是一个和：\n$$\n\\log \\mathcal{L}(q) = \\sum_{i=1}^N \\log p(y_i \\mid q)\n$$\n其中单个观测值 $y_i$ 的似然是两个高斯密度的混合：\n$$\np(y_i \\mid q) = \\sum_{k=1}^2 \\pi_k(z) \\, \\mathcal{N}(y_i \\mid \\mu_{ik}, \\sigma^2)\n$$\n第 $i$ 个观测值的第 $k$ 个组分的均值由常微分方程的解给出：\n$$\n\\mu_{ik} = x_{0,k} \\exp(-a_k t_i) = x_{0,k} \\exp(-\\exp(\\alpha_k) t_i)\n$$\n混合权重 $\\pi_k$ 由 softmax 函数给出：\n$$\n\\pi_k(z) = \\frac{\\exp(z_k)}{\\sum_{j=1}^2 \\exp(z_j)}\n$$\n因此，忽略高斯归一化常数，对数似然为：\n$$\n\\log \\mathcal{L}(q) = \\sum_{i=1}^N \\log \\left( \\sum_{k=1}^2 \\pi_k(z) \\exp\\left(-\\frac{(y_i - \\mu_{ik})^2}{2\\sigma^2}\\right) \\right)\n$$\n为了数值稳定性，该表达式应使用 log-sum-exp 技巧进行计算。\n\n**3. 对数后验的梯度**\n\nHMC 蛙跳积分器需要梯度 $\\nabla_q \\log p(q)$。我们计算关于每个参数的偏导数。\n一个关键量是责任 $w_{ik}$，即观测值 $i$ 由组分 $k$ 生成的后验概率：\n$$\nw_{ik} = \\frac{\\pi_k \\mathcal{N}(y_i \\mid \\mu_{ik}, \\sigma^2)}{\\sum_{j=1}^2 \\pi_j \\mathcal{N}(y_i \\mid \\mu_{ij}, \\sigma^2)}\n$$\n对数似然的梯度为 $\\nabla_q \\log \\mathcal{L}(q) = \\sum_i \\sum_k w_{ik} \\nabla_q \\log(\\pi_k \\mathcal{N}(y_i \\mid \\mu_{ik}, \\sigma^2))$。\n\n- **关于 $\\alpha_j$ 的梯度**：\n  $$\n  \\frac{\\partial \\log p(q)}{\\partial \\alpha_j} = \\left( \\sum_{i=1}^N w_{ij} \\frac{y_i - \\mu_{ij}}{\\sigma^2} \\frac{\\partial \\mu_{ij}}{\\partial \\alpha_j} \\right) - \\frac{\\alpha_j - \\mu_\\alpha}{\\sigma_\\alpha^2}\n  $$\n  其中 $\\frac{\\partial \\mu_{ij}}{\\partial \\alpha_j} = -t_i \\exp(\\alpha_j) \\mu_{ij}$。\n\n- **关于 $x_{0,j}$ 的梯度**：\n  $$\n  \\frac{\\partial \\log p(q)}{\\partial x_{0,j}} = \\left( \\sum_{i=1}^N w_{ij} \\frac{y_i - \\mu_{ij}}{\\sigma^2} \\frac{\\partial \\mu_{ij}}{\\partial x_{0,j}} \\right) - \\frac{x_{0,j} - \\mu_x}{\\sigma_x^2}\n  $$\n  其中 $\\frac{\\partial \\mu_{ij}}{\\partial x_{0,j}} = \\exp(-\\exp(\\alpha_j) t_i)$。\n\n- **关于 $z_j$ 的梯度**：\n  对数 softmax 的梯度为 $\\frac{\\partial \\log \\pi_k}{\\partial z_j} = \\delta_{kj} - \\pi_j$。\n  $$\n  \\frac{\\partial \\log p(q)}{\\partial z_j} = \\left( \\sum_{i=1}^N \\sum_{k=1}^2 w_{ik} (\\delta_{kj} - \\pi_j) \\right) - \\frac{z_j}{\\tau^2} = \\left( \\sum_{i=1}^N (w_{ij} - \\pi_j) \\right) - \\frac{z_j}{\\tau^2}\n  $$\n\n这些表达式构成了梯度计算的基础。\n\n### II. 算法实现\n\n以下 Python 代码实现了计算所需诊断指标的程序。\n\n```python\nimport numpy as np\nfrom scipy import special\n\ndef solve():\n    \"\"\"\n    Computes a set of symmetry-based diagnostics for a Hamiltonian Monte Carlo\n    implementation on a mixture-of-dynamics model.\n    \"\"\"\n    # Fixed parameters for the single test case\n    K = 2\n    t = np.array([0.0, 0.5, 1.0, 1.5, 2.0])\n    y = np.array([1.95, 1.50, -0.40, 0.90, 0.70])\n    sigma = 0.1\n    mu_alpha, sigma_alpha = 0.0, 1.0\n    mu_x, sigma_x = 0.0, 2.0\n    tau = 1.0\n    q_base = np.array([-0.5108256238, -0.1053605157, 1.8, -1.1, 0.3, -0.3])\n    r_base = np.array([0.10, -0.20, 0.30, -0.10, 0.05, -0.05])\n    epsilon = 0.01\n    L = 25\n\n    # Numerically stable helper functions\n    def logsumexp(x, axis=None):\n        return special.logsumexp(x, axis=axis)\n    \n    def softmax(x):\n        # Subtract max for numerical stability\n        e_x = np.exp(x - np.max(x))\n        return e_x / np.sum(e_x)\n\n    def get_log_posterior(q):\n        \"\"\"Computes the log posterior density (up to a constant).\"\"\"\n        alpha, x0, z = q[0:K], q[K:2*K], q[2*K:3*K]\n        \n        # Log likelihood term\n        a = np.exp(alpha)\n        mu = x0 * np.exp(-a * t[:, np.newaxis])\n        pi = softmax(z)\n        residuals = y[:, np.newaxis] - mu\n        log_gauss_contrib = -(residuals**2) / (2 * sigma**2)\n        log_lik_terms = np.log(pi) + log_gauss_contrib\n        total_log_lik = np.sum(logsumexp(log_lik_terms, axis=1))\n\n        # Log prior term\n        log_prior_alpha = -np.sum((alpha - mu_alpha)**2) / (2 * sigma_alpha**2)\n        log_prior_x0 = -np.sum((x0 - mu_x)**2) / (2 * sigma_x**2)\n        log_prior_z = -np.sum(z**2) / (2 * tau**2)\n        total_log_prior = log_prior_alpha + log_prior_x0 + log_prior_z\n        \n        return total_log_lik + total_log_prior\n\n    def get_grad_log_posterior(q):\n        \"\"\"Computes the gradient of the log posterior density.\"\"\"\n        alpha, x0, z = q[0:K], q[K:2*K], q[2*K:3*K]\n\n        # Common quantities for likelihood gradient\n        a = np.exp(alpha)\n        mu = x0 * np.exp(-a * t[:, np.newaxis])\n        pi = softmax(z)\n        \n        # Responsibilities (w_ik)\n        residuals = y[:, np.newaxis] - mu\n        log_gauss_contrib = -(residuals**2) / (2 * sigma**2)\n        log_lik_terms = np.log(pi) + log_gauss_contrib\n        log_lik_per_obs = logsumexp(log_lik_terms, axis=1)\n        responsibilities = np.exp(log_lik_terms - log_lik_per_obs[:, np.newaxis])\n\n        # Gradient of log likelihood\n        grad_lik_alpha = np.sum(responsibilities * (residuals / sigma**2) * (-t[:, np.newaxis] * a * mu), axis=0)\n        grad_lik_x0 = np.sum(responsibilities * (residuals / sigma**2) * np.exp(-a * t[:, np.newaxis]), axis=0)\n        grad_lik_z = np.sum(responsibilities - pi, axis=0)\n\n        # Gradient of log prior\n        grad_prior_alpha = -(alpha - mu_alpha) / sigma_alpha**2\n        grad_prior_x0 = -(x0 - mu_x) / sigma_x**2\n        grad_prior_z = -z / tau**2\n        \n        return np.concatenate([grad_lik_alpha + grad_prior_alpha, grad_lik_x0 + grad_prior_x0, grad_lik_z + grad_prior_z])\n\n    def get_hamiltonian(q, r):\n        \"\"\"Computes the Hamiltonian.\"\"\"\n        potential_energy = -get_log_posterior(q)\n        kinetic_energy = 0.5 * np.dot(r, r)\n        return potential_energy + kinetic_energy\n\n    def leapfrog(q_init, r_init, eps, num_steps, grad_func):\n        \"\"\"Performs L leapfrog steps.\"\"\"\n        q, r = q_init.copy(), r_init.copy()\n        \n        # Half step for momentum at the beginning\n        r += 0.5 * eps * grad_func(q)\n        # Full steps for position and momentum\n        for _ in range(num_steps - 1):\n            q += eps * r\n            r += eps * grad_func(q)\n        # Last full step for position\n        q += eps * r\n        # Last half step for momentum\n        r += 0.5 * eps * grad_func(q)\n        \n        return q, r\n\n    def permute(v):\n        \"\"\"Applies the label-swapping permutation P.\"\"\"\n        return np.array([v[1], v[0], v[3], v[2], v[5], v[4]])\n\n    # T1: Absolute difference in log posterior due to permutation\n    T1 = abs(get_log_posterior(q_base) - get_log_posterior(permute(q_base)))\n    \n    # T2: Absolute difference in Hamiltonian due to permutation\n    T2 = abs(get_hamiltonian(q_base, r_base) - get_hamiltonian(permute(q_base), permute(r_base)))\n    \n    # T3: Absolute difference in HMC acceptance probabilities\n    q_prime, r_prime = leapfrog(q_base, r_base, epsilon, L, get_grad_log_posterior)\n    H_init1 = get_hamiltonian(q_base, r_base)\n    H_final1 = get_hamiltonian(q_prime, r_prime)\n    a1 = min(1.0, np.exp(-H_final1 + H_init1))\n    \n    H_init2 = get_hamiltonian(permute(q_base), permute(r_base))\n    # Due to symmetry, integrating from permuted start is same as permuting the result of original integration\n    q_prime_p, r_prime_p = leapfrog(permute(q_base), permute(r_base), epsilon, L, get_grad_log_posterior)\n    H_final2 = get_hamiltonian(q_prime_p, r_prime_p)\n    a2 = min(1.0, np.exp(-H_final2 + H_init2))\n    T3 = abs(a1 - a2)\n    \n    # T4: Norm of gradient difference under permutation (equivariance check)\n    grad_base = get_grad_log_posterior(q_base)\n    grad_permuted_q = get_grad_log_posterior(permute(q_base))\n    # For this permutation, P^-1 = P\n    T4 = np.linalg.norm(grad_base - permute(grad_permuted_q))\n\n    # T5: Stability diagnostic for gradient calculation\n    q_edge = q_base.copy()\n    q_edge[4:6] = [-20.0, 0.0]\n    grad_edge = get_grad_log_posterior(q_edge)\n    T5 = bool(np.all(np.isfinite(grad_edge)))\n    \n    results = [T1, T2, T3, T4, T5]\n    return f\"[{','.join(map(str, results))}]\"\n\n# The problem asks for the output of the program, which is generated below.\n# print(solve())\n```",
            "answer": "[0.0,0.0,0.0,5.551115123125783e-17,True]"
        }
    ]
}