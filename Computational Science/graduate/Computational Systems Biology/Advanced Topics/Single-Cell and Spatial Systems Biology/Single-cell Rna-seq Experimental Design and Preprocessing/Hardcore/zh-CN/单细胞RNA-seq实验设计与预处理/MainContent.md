## 引言
[单细胞RNA测序](@entry_id:142269)（[scRNA-seq](@entry_id:155798)）技术已经彻底改变了生物学研究，它使我们能够在前所未有的分辨率下解析复杂组织中的[细胞异质性](@entry_id:262569)。然而，这项强大技术的背后，是同样复杂且充满挑战的实验设计和[数据预处理](@entry_id:197920)流程。一个细微的设计缺陷或不当的计算处理，都可能引入系统性偏差，最终导致错误的生物学结论。因此，“输入的是垃圾，输出的也是垃圾”这句警言在[scRNA-seq](@entry_id:155798)领域尤为适用。本文旨在填补从实验台到计算分析之间的关键知识鸿沟，系统性地阐述从实验规划到生成清洁数据矩阵的全过程中的核心原理与最佳实践。

在接下来的章节中，我们将引导您完成这一关键旅程。在“原理与机制”部分，您将学习到scRNA-seq实验设计的基石，理解细胞数量、[测序深度](@entry_id:178191)与生物学重复之间的权衡，并掌握不同测序技术（如10x Genomics与Smart-seq2）的内在机制及其对数据产生的影响，同时深入探讨描述UMI计数的[统计模型](@entry_id:165873)。随后，在“应用与跨学科交叉”部分，我们将通过具体的应用案例，展示这些原理如何用于确保[统计功效](@entry_id:197129)、处理复杂的[批次效应](@entry_id:265859)，并推动系统生物学等前沿领域的探索。最后，通过“动手实践”部分，您将有机会亲手实现关键的预处理算法，将理论知识转化为实践技能。通过本章的学习，您将为进行严谨、可重复的scRNA-seq研究奠定坚实的基础。

## 原理与机制

### 单细胞实验的基石：从生物学问题到实验设计

在[单细胞RNA测序 (scRNA-seq)](@entry_id:754902) 研究中，一项精心设计的实验是得出可靠生物学结论的先决条件。实验设计并非一成不变，而是必须根据核心生物学目标进行精确调整。不同的科学问题对实验参数的优先级提出了截然不同的要求。这些参数主要包括分析的**细胞数量** ($N$)、每个细胞的**[测序深度](@entry_id:178191)**（即每个细胞的读数，$r$），以及每个实验条件的**生物学重复**数量 ($B$)。在总测序读数 $R_{\text{tot}}$（即预算）固定的前提下，细胞数量 $N$ 和[测序深度](@entry_id:178191) $r$ 之间存在一个基本的权衡关系，即 $N \cdot r \approx R_{\text{tot}}$。

#### 针对不同科学目标的策略权衡

根据具体的生物学目标，我们需要战略性地分配测序资源：

1.  **细胞类型发现与图谱构建**：这类研究旨在全面描绘一个组织或样本中所有细胞群体的[转录组](@entry_id:274025)特征，包括那些非常稀有的细胞类型。其首要挑战在于采样。根据基本采样原理，要高概率地捕获到一个丰度仅为 $0.1\%$ 的稀有细胞群，就必须分析数千乃至数万个细胞。因此，这类实验设计的**首要制约因素是确保足够大的细胞数量 $N$**。相对而言，[测序深度](@entry_id:178191) $r$ 只需达到中等水平，足以检测到区分不同细胞簇的标记基因即可。过高的 $r$ 会不必要地消耗预算，从而限制可分析的细胞总数 $N$。同时，为了防止[批次效应](@entry_id:265859)（例如，因特定试剂批次或操作流程产生的技术偏差）导致发现“假”的细胞类型，设置最少数量（但必须大于1）的生物学重复 $B$ 是至关重要的预防措施 。

2.  **跨条件[差异表达分析](@entry_id:266370)**：这类研究的核心目标是量化基因表达水平在不同条件（如药物处理 vs. [对照组](@entry_id:747837)）下的变化。统计推断的有效性在这里至关重要。任何统计检验都依赖于对组内生物学变异的可靠估计。这种变异只能通过独立的生物学重复来衡量。若没有足够的生物学重复，我们将无法区分[处理效应](@entry_id:636010)与样本间的固有随机波动，从而导致“假重复”的统计谬误。因此，[差异表达分析](@entry_id:266370)的**首要制约因素是足够大的生物学重复数量 $B$**。在每个重复样本内部，需要中等数量的细胞 $N$ 和中等水平的[测序深度](@entry_id:178191) $r$，以获得稳定可靠的基因表达均值估计（无论是通过“伪批量”方法还是基于模型的估计）。

3.  **[轨迹推断](@entry_id:176370)**：此类研究旨在重建一个连续的生物学过程，例如细胞分化或细胞周期，通过将细胞沿着一条“伪时间”路径排序。其根本挑战在于确保所采样的细胞能够密集地覆盖整个生物学过程的连续“[流形](@entry_id:153038)”。如果采样过于稀疏，在细胞状态之间留下大的“缺口”，[轨迹推断](@entry_id:176370)算法将无法准确重建路径。因此，[轨迹推断](@entry_id:176370)的**首要制约因素是确保足够大的细胞数量 $N$**，以确保[流形](@entry_id:153038)的密集覆盖和对分化分支的充分采样。与细胞类型发现类似，中等[测序深度](@entry_id:178191) $r$ 通常足以根据关键基因的相对表达来确定细胞在轨迹上的位置。虽然生物学重复 $B$ 对于验证轨迹的稳健性或比较不同条件下的轨迹很有价值，但其重要性次于确保单个轨迹得以重建所需的细胞密度 。

#### 实验设计中的混淆与[批次效应](@entry_id:265859)

在设计实验时，一个核心概念是区分**[批次效应](@entry_id:265859) (batch effects)** 和**混淆变量 (confounders)**。[批次效应](@entry_id:265859)是指由样本处理的技术性差异（如不同的实验日期、试剂批次或测序仪通道）引起的、影响许多基因测量的系统性非生物学变异。混淆变量则是指一个变量，它既与我们关心的暴露因素（如药物处理）相关，又影响我们测量的结果（基因表达），从而在不加调整的情况下导致对暴露效应的估计产生偏倚。

一个良好的实验设计可以消除混淆。例如，在一个比较处理组与对照组的实验中，如果在两个不同的捕获日（批次）上进行处理，且**每个捕获日都均衡地包含了处理组和对照组的样本**，那么捕获日就是一个[批次效应](@entry_id:265859)，但它**不是**[处理效应](@entry_id:636010)的[混淆变量](@entry_id:199777)。我们可以用一个[线性模型](@entry_id:178302)来形式化这个概念。假设 $Y_{ig}$ 是细胞 $i$ 中基因 $g$ 的标准化表达量， $T_i$ 是处理[指示变量](@entry_id:266428)，$B_i$ 是批次[指示变量](@entry_id:266428)。观察到的[处理效应](@entry_id:636010) $\Delta_g$ 可以分解为：
$$
\Delta_g \;\equiv\; \mathbb{E}[Y_{ig}\mid T_i=1]-\mathbb{E}[Y_{ig}\mid T_i=0] \;=\; \beta_g \;+\; \gamma_g \Big(\mathbb{E}[B_i\mid T_i=1]-\mathbb{E}[B_i\mid T_i=0]\Big) + \dots
$$
其中 $\beta_g$ 是真实的治疗效应，$\gamma_g$ 是[批次效应](@entry_id:265859)。在一个均衡设计中，$\mathbb{E}[B_i\mid T_i=1] \approx \mathbb{E}[B_i\mid T_i=0]$，因此[批次效应](@entry_id:265859)项被抵消，$\Delta_g \approx \beta_g$。相反，如果所有处理组细胞都在一天处理，而所有对照组细胞都在另一天处理，那么批次 $B_i$ 与处理 $T_i$ 就完全**混淆**了。在这种情况下，$\mathbb{E}[B_i\mid T_i=1]-\mathbb{E}[B_i\mid T_i=0]$ 不为零，我们观察到的差异 $\Delta_g$ 将是真实效应 $\beta_g$ 和批次效应 $\gamma_g$ 的混合体，两者在没有额外假设的情况下是无法区分的。这种设计使得我们无法确定观察到的基因表达变化是由处理引起的，还是仅仅由实验日期不同造成的。

因此，平衡的实验设计是分离生物学信号与技术噪音的关键。即使存在批次效应，只要它与我们关心的生物学变量是正交的（不相关的），我们就可以在下游分析中通过统计方法（如在[回归模型](@entry_id:163386)中加入批次[协变](@entry_id:634097)量）来校正它，而不会影响对生物学效应的估计 。

### 从细胞到序列：核心技术与数据生成

[scRNA-seq](@entry_id:155798)数据的特性深刻地根植于其生成技术。两种主流的技术策略——高通量的**基于液滴的方法**和高深度的**基于平板的方法**——在细胞标签、分子标签和转录本覆盖范围上存在根本差异，这些差异直接影响下游的生物信息学分析。

#### 基于液滴的方法（如10x Genomics）

基于液滴的技术，以10x Genomics平台为代表，通过将单个细胞与带有特殊寡[核苷酸](@entry_id:275639)的凝胶珠包裹在油包水液滴中，实现了大规模的细胞并行处理。

*   **机制与标签**：每个凝胶珠上都附着有数百万条寡[核苷酸](@entry_id:275639)，这些寡[核苷酸](@entry_id:275639)包含三个关键部分：一个**[细胞条形码](@entry_id:171163) (cell barcode)**，用于在所有液滴混合后识别每个转录本的来源细胞；一个**[唯一分子标识符](@entry_id:192673) (Unique Molecular Identifier, UMI)**，一个短的随机序列，用于标记每个被捕获的原始mRNA分子；以及一个通常是oligo(dT)的引物，用于捕获带有[poly(A)尾](@entry_id:274750)的mRNA。在液滴内部完成[逆转录](@entry_id:141572)后，[细胞条形码](@entry_id:171163)和UMI就被添加到了cDNA的第一条链上 。

*   **数据特征**：由于使用[oligo(dT)引物](@entry_id:202920)，测序读数主要集中在转录本的 $3'$ 端（或某些方案中的 $5'$ 端）。这种“标签测序 (tag-based sequencing)”策略的优点是能够以较低的成本实现极高的细胞通量。其核心优势在于UMI的使用，它允许我们通过计算[生物信息学方法](@entry_id:172578)精确地量化原始mRNA分子的数量，而非PCR扩增后的cDNA读数数量。缺点是，由于只测序转录本的一端，我们丢失了大部分关于[剪接异构体](@entry_id:167419)（isoform）的信息。

*   **读数结构**：在标准的10x Genomics 3'端实验中，采用[双端测序](@entry_id:272784)会产生两种读数。**Read 1** 包含人工合成的序列：[细胞条形码](@entry_id:171163)和UMI。它不用于比对基因组，而是用于确定读数的细胞来源和分子来源。**Read 2** 包含来自转录本本身的cDNA序列，它被比对到[参考基因组](@entry_id:269221)或[转录组](@entry_id:274025)上，以确定其所属的基因。理解这一结构至关重要，因为预处理流程必须分别处理这两种读数以正确地构建基因-细胞表达矩阵 。

#### 基于平板的方法（如Smart-seq2）

基于平板的方法，以Smart-seq2为代表，则采取了不同的策略。单个细胞被分选到微孔板（如96孔板或384孔板）的独立孔中。

*   **机制与标签**：每个细胞的身份由其所在的物理孔位置来定义。在每个孔中，通过模板转换（template switching）机制，可以生成覆盖mRNA全长的cDNA。值得注意的是，经典的Smart-seq2方案**不使用UMI**。这意味着，我们无法通过计算方法区分PCR扩增产生的重复读数和来自不同原始分子的读数 。

*   **数据特征**：该方法的主要优势在于提供了**全长转录本覆盖**。测序读数会[分布](@entry_id:182848)在整个基因体上，这使得研究人员能够分析[可变剪接](@entry_id:142813)和发现新的基因异构体。然而，其细胞通量远低于液滴法。由于没有UMI，基因表达的量化依赖于原始读数计数，这会受到PCR扩增效率偏倚和转录本[长度偏倚](@entry_id:269579)（更长的转录本可能产生更多读数）的影响，使得定量分析更具挑战性。

总之，方法的选择是一个权衡：如果研究目标是高通量地进行细胞分型或计数，液滴法是理想选择；如果目标是深入研究单个细胞的转录本多样性，如[剪接异构体](@entry_id:167419)，那么平板法更为合适。

### UMI计数的统计本质：从分子到模型

scRNA-seq数据分析的核心是理解我们观察到的UMI计数是如何产生的。这些离散的计数值是多个[随机过程](@entry_id:159502)层层叠加的结果，从细胞内mRNA分子的[动态平衡](@entry_id:136767)到实验中的捕获和测序。为这些计数建立合适的统计模型是所有下游分析（如[差异表达](@entry_id:748396)、[聚类](@entry_id:266727)）的理论基础。

#### UMI的力量：校正PCR扩增偏倚

在没有UMI的scRNA-seq方法中，一个高度表达或在PCR过程中被高效扩增的mRNA分子可能会产生数千个测序读数，而另一个表达水平相似但扩增效率较低的分子可能只产生几十个读数。这种由PCR随机性引入的巨大噪音使得基于读数计数的定量分析变得不可靠。

**[唯一分子标识符 (UMI)](@entry_id:265196)** 通过在PCR扩增前为每个捕获的mRNA分子（准确地说是其cDNA拷贝）打上一个独特的随机序列标签，从根本上解决了这个问题。在数据分析阶段，所有具有相同[细胞条形码](@entry_id:171163)、比对到相同基因且拥有相同UMI序列的读数，都被认为是源于同一个原始mRNA分子的扩增副本。通过将这些读数**塌缩 (collapsing)** 为一个单一的UMI计数，我们实现了从“计算读数”到“计算分子”的转变，从而极大地消除了PCR扩增偏倚 。

在实践中，由于测序错误，UMI序列本身可能发生变异。因此，简单的按UMI序列进行唯一化计数会高估分子数量。成熟的[预处理](@entry_id:141204)流程会采用纠错策略。例如，对于某个细胞-基因组合，将所有观察到的UMI分组，如果一个低计数的UMI与一个高计数的UMI只有一个碱基的差异（即**汉明距离 (Hamming distance)** 为1），则认为前者是后者的测序错误产物，并将其计数合并到后者中。例如，假设基因 $g^*$ 在细胞 $b^*$ 中有15个相关读数，其UMI序列及计数分别为 $\{u_A:7,\;u_B:5,\;u_C:2,\;u_D:1\}$。若已知 $d(u_B, u_C)=1$ 且 $d(u_B, u_D)=1$，而其他UMI对之间的距离都大于等于2，那么根据“将汉明距离为1的低计数UMI合并到高计数UMI”的规则，$u_C$ 和 $u_D$ 的计数都会被归入 $u_B$。最终，我们只剩下两个独立的分[子群](@entry_id:146164)组，由 $u_A$ 和合并后的 $u_B$ 代表，因此该基因在该细胞中的最终UMI计数为 $2$ 。

#### 统计模型的演进

1.  **泊松模型 (Poisson Model) 作为基准**：最简单的模型假设，在理想化的**同质采样 (homogeneous sampling)** 条件下（即所有细胞的基因表达速率和捕获效率都恒定），捕获mRNA分子是一个独立的随机事件。在这种情况下，观测到的UMI计数 $Y_{cg}$（基因 $g$ 在细胞 $c$ 中）可以被一个**泊松分布**很好地描述。泊松分布的一个关键特性是其均值等于[方差](@entry_id:200758)（$\mathrm{Var}(Y_{cg}) = \mathbb{E}[Y_{cg}]$）。这意味着数据的变异完全由随机采样噪声决定 。

2.  **过离散现象与负[二项模型](@entry_id:275034) (Negative Binomial Model)**：然而，真实的scRNA-seq数据几乎总是表现出**过离散 (overdispersion)** 的现象，即数据的[方差](@entry_id:200758)远大于其均值。这种额外的变异来源是多方面的：
    *   **生物学异质性**：即使是同一类型的细胞，也存在固有的差异。**外在异质性 (extrinsic heterogeneity)** 来自于细胞大小、[细胞周期阶段](@entry_id:170415)或微环境信号的不同，这些因素会导致不同细胞的基因表达速率或mRNA捕获效率不同。**内在异质性 (intrinsic heterogeneity)** 则源于转录过程本身的随机性，即所谓的**[转录爆发](@entry_id:156205) (transcriptional bursting)**。基因[启动子](@entry_id:156503)在“开启”和“关闭”状态之间[随机切换](@entry_id:197998)，导致mRNA分子成批次地产生。这两种生物学异质性都会导致细胞间的表达水平出现超出泊松采样噪声的波动 。
    *   **技术[异质性](@entry_id:275678)**：不同液滴或孔中的[逆转录](@entry_id:141572)效率、细胞裂解效率等技术因素也会引入额外的变异。

    为了捕捉这种过离散现象，**[负二项分布](@entry_id:262151) (Negative Binomial, NB)** 成为了scRNA-seq[数据建模](@entry_id:141456)的标准。NB[分布](@entry_id:182848)可以被看作是一个[复合分布](@entry_id:150903)（Gamma-Poisson混合）：如果我们假设每个细胞的基因表达速率本身不是一个固定的值，而是遵循一个Gamma[分布](@entry_id:182848)，那么在这些变化的速率下进行泊松采样，最终得到的计数就遵循NB[分布](@entry_id:182848)。NB[分布](@entry_id:182848)的[方差](@entry_id:200758)大于其均值，从而能够灵活地对过离散数据进行建模 。

3.  **零计数的挑战与[零膨胀模型](@entry_id:756817) (Zero-Inflated Models)**：scRNA-seq数据矩阵的一个显著特征是其高度的稀疏性，即充满了大量的零值。这些零可以分为两类：
    *   **采样零 (Sampling Zeros)**：对于低表达或中等表达的基因，由于捕获效率有限（通常只有5-20%的mRNA被捕获），一个细胞中即使真实存在某个基因的mRNA，也可能在测序中一个都没有被捕获到。这种零是泊松或NB[分布](@entry_id:182848)自然就能产生的结果。
    *   **结构零 (Structural Zeros)**：这类零代表了超越采样噪声的“真实”缺失。其来源可以是生物学上的（如在[转录爆发](@entry_id:156205)模型中，一个基因的[启动子](@entry_id:156503)在整个观测窗口内都处于“关闭”状态）或技术上的（如某个特定基因的逆转录[引物](@entry_id:192496)失效，导致无论该基因有多少mRNA都无法被转换成cDNA）。

    当数据中存在过多的“结构零”，以至于标准的NB[分布](@entry_id:182848)也无法充分拟合时，**[零膨胀模型](@entry_id:756817) (Zero-Inflated models)** 就应运而生。[零膨胀模型](@entry_id:756817)是一个两部分的[混合模型](@entry_id:266571)：一部分是一个伯努利过程，以一定的概率直接产生“结构零”；另一部分则是一个标准的计数[分布](@entry_id:182848)（如泊松或NB），它也会产生“采样零”。需要强调的是，UMI的使用并不能消除所有技术来源的零，例如[逆转录](@entry_id:141572)失败。因此，认为UMI数据就不需要[零膨胀模型](@entry_id:756817)是一个误解。然而，NB[分布](@entry_id:182848)本身通过其过离散参数也可以产生大量的零，因此在应用[零膨胀模型](@entry_id:756817)前，应仔细判断是否有额外的、独立的“结构零”产生机制存在的证据 。

### 从原始数据到清洁矩阵：标准的[预处理](@entry_id:141204)工作流

将测序仪产生的原始数据转化为一个可用于下游生物学分析的、经过质量控制和标准化的表达矩阵，需要一个严谨、可重复的计算工作流程。这个流程中的每一步都至关重要，旨在消除技术噪音并保留生物学信号。

#### 核心流程步骤

一个标准的基于UMI的[scRNA-seq](@entry_id:155798)[数据预处理](@entry_id:197920)流程通常包括以下几个阶段：

1.  **碱基识别与样本拆分 (Basecalling  Demultiplexing)**：测序仪输出的是原始的图像文件（如BCL文件）。流程的第一步是**碱基识别**，将这些图像中的荧光信号转化为[核苷酸](@entry_id:275639)序列（A, T, C, G）及其对应的质量得分，生成[FASTQ](@entry_id:201775)格式的文件。随后，对于多样本混合上样的实验，需要进行**样本拆分**，即根据读数中的样本索引序列（Sample Index）将读数分配到各自的样本中。在此阶段，也会从Read 1中解析出[细胞条形码](@entry_id:171163)和UMI序列 。

2.  **比对与计数 (Alignment  Counting)**：下一步是将包含cDNA序列的Read 2比对到[参考基因组](@entry_id:269221)或转录组上，以确定每个转录本所属的基因。比对完成后，流程将根据[细胞条形码](@entry_id:171163)、[基因注释](@entry_id:164186)和UMI序列进行计数。如前所述，所有具有相同“细胞-基因-UMI”组合的读数被塌缩成一个单一计数，以校正PCR扩增偏倚。这个过程最终生成一个原始的**基因-细胞计数矩阵**，其中每个元素代表一个特定基因在特定细胞中的UMI数量  。

#### 原始矩阵的质量控制 (Quality Control, QC)

原始计数矩阵包含了高质量的细胞、低质量的细胞、空液滴以及潜在的多细胞液滴（doublets）。QC的目的就是识别并过滤掉这些不理想的数据点。常用的QC指标均在单细胞水平上计算：

*   **总UMI计数 (Total Counts)**：每个细胞中检测到的UMI总数。这个指标主要反映了细胞的mRNA总量和测序捕获效率。**异常低的UMI总数**通常表示这是一个空的液滴或一个濒死的、mRNA已大量降解的细胞。**异常高的UMI总数**则可能是一个**[多胞体](@entry_id:635589) (doublet)**，即一个液滴中包裹了两个或更多细胞，导致其mRNA总量异常增加 。

*   **检测到的基因数 (Number of Detected Genes)**：每个细胞中UMI计数大于零的基因数量。这个指标反映了文库的**复杂度**。在固定的总UMI计数下，检测到的基因数越多，说明[转录组](@entry_id:274025)越复杂、多样。极低的基因数可能同样指向低质量细胞。总UMI计数和检测到的基因数之间通常存在强烈的正相关关系 。

*   **线粒体基因比例 (Mitochondrial Fraction)**：映射到线粒体基因组的UMI计数占该细胞总UMI计数的比例。在细胞解离过程中，[细胞膜](@entry_id:146704)的破损会导致胞质中的mRNA流失，而线粒体相对完整，其转录本会被保留下来。因此，**异常高的线粒体基因比例**通常被认为是细胞**应激或凋亡**的标志。需要注意的是，不同细胞类型其基础[代谢水](@entry_id:173353)平不同，因此正常的线粒体基因比例也不同，设定过滤阈值时应考虑细胞类型的[异质性](@entry_id:275678) 。

*   **[核糖体](@entry_id:147360)基因比例 (Ribosomal Fraction)**：映射到[核糖体蛋白](@entry_id:194604)基因的UMI计数比例。高比例可能反映了细胞处于旺盛的[蛋白质合成](@entry_id:147414)状态（生物学原因），但也可能与技术偏倚有关。与其他指标结合解读，可以更全面地评估细胞状态 。

#### 技术伪影的识别与校正

除了基于上述指标过滤细胞，[预处理](@entry_id:141204)还需处理更细微的技术伪影。

*   **环境RNA污染 (Ambient RNA Contamination)**：在细胞解离和悬浮过程中，一些细胞会破裂，释放其mRNA到悬浮液中。这些“环境RNA”会作为背景信号被随机包裹进所有的液滴中，包括那些真正含有细胞的液滴和空液滴。这种污染的典型特征是，在被判定为“空液滴”的条形码中，我们仍然能检测到一个与高表达细胞群相似的基因表达谱。例如，如果一个样本中[B细胞](@entry_id:203517)高度富集，那么在分析A样本的数据时，可能会在A样本的空液滴和细胞中都检测到[B细胞](@entry_id:203517)标记基因的低水平表达。这种信号的强度远超测序仪的**样本标签跳跃 (index hopping)** 所能解释的范畴，后者的发生率通常在 $0.1-1\%$ 的量级，而环境RNA污染可能贡献显著的计数。通过分析空液滴的表达谱，可以估计出环境RNA的组成，并从真实细胞的表达谱中将其扣除 。

*   **[批次效应校正](@entry_id:269846)**：如前所述，来自不同批次的样本会带有系统性的技术差异。在QC和过滤之后，通常需要应用计算方法来校正[批次效应](@entry_id:265859)。如果实验设计是平衡的，那么可以在[回归模型](@entry_id:163386)中包含批次作为[协变](@entry_id:634097)量，或者使用专门的批次校正算法来对齐不同批次的数据，从而消除技术差异，凸显生物学差异 。

#### 标准化与[方差](@entry_id:200758)稳定

由于每个细胞的[测序深度](@entry_id:178191)（或总UMI计数）不同，直接比较原始UMI计数是没有意义的。**[标准化](@entry_id:637219) (Normalization)** 的目标就是去除这种技术性的“文库大小”差异。

1.  **文库大小标准化 (Library Size Normalization)**：最简单的方法是将每个细胞的UMI计数除以该细胞的总UMI计数，再乘以一个统一的[比例因子](@entry_id:266678)（如一百万，得到每百万转录本计数, CPM）。这种方法的假设是，大部分基因在细胞间是不变的，因此总UMI计数可以作为[测序深度](@entry_id:178191)的良好代理。然而，当细胞间存在强烈的**组成偏倚**（compositional bias，即少数基因的剧烈变化主导了总UMI计数的变化）时，该方法会失效 。

2.  **基于解卷积的[标准化](@entry_id:637219) (Deconvolution-based Normalization, e.g., scran)**：为了克服组成偏倚，`scran`等方法采取了更稳健的策略。它通过将细胞分组形成“伪批量样本”来计算尺寸因子。在这些细胞池中，单个细胞的特异性表达被平均掉，使得尺寸因子的估计更加稳定和不受稀疏性影响。然后通过一个解卷积的数学过程，从这些池因子中反推出每个单细胞的尺寸因子 。

3.  **基于模型的[标准化](@entry_id:637219)与[方差](@entry_id:200758)稳定 (Model-based Normalization, e.g., SCTransform)**：现代方法，如`SCTransform`，将标准化和[方差](@entry_id:200758)稳定合二为一。它不再是简单地缩放原始计数，而是为每个基因拟合一个**正则化的负二项[广义线性模型](@entry_id:171019)**。该模型将UMI计数与细胞[测序深度](@entry_id:178191)等协变量关联起来。通过这个模型，SCTransform不仅移除了[测序深度](@entry_id:178191)的影响，还同时稳定了数据的[方差](@entry_id:200758)。它输出的不再是“标准化的计数”，而是**皮尔逊残差 (Pearson residuals)**。这些残差近似服从[标准正态分布](@entry_id:184509)，其[方差](@entry_id:200758)不再依赖于均值，因此可以直接用于下游的线性[降维](@entry_id:142982)分析（如PCA）和聚类，而无需额外的缩放或对数转换步骤 。

#### 确保计算的[可重复性](@entry_id:194541)

最后，科学的严谨性要求整个预处理流程是**完全可重复的**。这意味着，另一个研究者使用相同的原始数据和代码，必须能够得到一模一样的最终结果。为此，必须详尽地记录：
*   所有使用的软件工具及其**精确版本号**。
*   所有参考文件（如基因组序列、[基因注释](@entry_id:164186)文件）的来源和**校验和 (checksums)**。
*   所有命令和脚本中使用的**全部参数**，特别是那些非默认的参数。
*   对于任何包含随机步骤的算法（如[聚类](@entry_id:266727)、降维），必须固定**随机数种子**。
*   最理想的情况是，使用容器技术（如[Docker](@entry_id:262723)或Singularity）打包整个计算环境，并记录容器镜像的**唯一摘要 (digest)**，以确保运行环境的绝对一致 。