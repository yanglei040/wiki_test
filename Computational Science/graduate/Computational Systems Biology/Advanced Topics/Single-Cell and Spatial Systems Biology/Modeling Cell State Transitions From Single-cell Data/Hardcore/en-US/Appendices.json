{
    "hands_on_practices": [
        {
            "introduction": "A common first step in analyzing single-cell data is to partition cells into discrete states or clusters. A natural next step is to model the transitions between these states, for which the discrete-time Markov chain is a foundational tool. This exercise  moves beyond model fitting to address the critical task of evaluation: how can we be sure our model has genuine predictive power? You will derive and apply a principled log-likelihood scoring metric within a cross-validation scheme, developing essential skills for robustly assessing and comparing models of cellular dynamics.",
            "id": "3327667",
            "problem": "A single-cell time-course experiment measures cell states at discrete times $\\{t_{0}, t_{1}, t_{2}, t_{3}\\}$ with $t_{0} = 0$, $t_{1} = 1$, $t_{2} = 2$, and $t_{3} = 4$ hours. Each cell is assigned to one of $K=3$ transcriptional states based on clustering of gene expression profiles, producing state-count vectors $\\mathbf{c}^{(m)} = (c_{1}^{(m)}, c_{2}^{(m)}, c_{3}^{(m)})$ at time $t_{m}$ for $m \\in \\{0,1,2,3\\}$, with a total of $N_{m} = \\sum_{i=1}^{3} c_{i}^{(m)}$ cells observed at time $t_{m}$. Assume cells within a time point are independent draws from a categorical distribution over the $3$ states. To model cell state transitions, assume a time-homogeneous, discrete-time Markov chain with a single-step transition matrix $\\mathbf{P}$ between successive unit-hour times, and let $\\mathbf{p}(t)$ denote the population-level state probability vector at time $t$. The model predicts $\\mathbf{p}(t_{m})$ from $\\mathbf{p}(t_{0})$ and $\\mathbf{P}$ by forward propagation across unit steps.\n\nYou will design a Leave-One-Time-Point-Out Cross-Validation (LOTO-CV) protocol to evaluate predictive performance of the transition model and derive a log-likelihood-based scoring metric for a held-out time point. Specifically, in one fold, hold out the entire time point $t_{2}$, fit the transition model on $\\{t_{0}, t_{1}, t_{3}\\}$, and obtain a predicted state probability vector $\\widehat{\\mathbf{p}}(t_{2})$ for the held-out time. The observed counts at $t_{2}$ are $\\mathbf{c}^{(2)} = (52, 29, 19)$, so $N_{2} = 100$, and the trained model’s predicted probabilities at $t_{2}$ are $\\widehat{\\mathbf{p}}(t_{2}) = (0.5, 0.3, 0.2)$.\n\nStarting from the definitions of the categorical distribution for independent samples and the principle of maximum likelihood for model assessment, derive a suitable log-likelihood-based scoring metric for the held-out time point that is appropriate for comparing models across folds where $N_{m}$ may differ. Then, for this fold, compute the numerical value of this metric using the provided $\\mathbf{c}^{(2)}$ and $\\widehat{\\mathbf{p}}(t_{2})$. Use the natural logarithm and express the final score in nats per cell. Round your answer to four significant figures.",
            "solution": "The problem asks for the derivation of a log-likelihood-based scoring metric for a held-out time point in a cross-validation setting and its subsequent calculation. The metric must be suitable for comparing models across folds with potentially different sample sizes ($N_m$).\n\nFirst, we derive the scoring metric. The problem states that the cells observed at a given time point $t_m$ are considered $N_m$ independent draws from a categorical distribution over $K=3$ states. The parameters of this distribution are the state probabilities $\\mathbf{p}^{(m)} = (p_1^{(m)}, p_2^{(m)}, p_3^{(m)})$. A trained model provides a prediction for these probabilities, denoted as $\\widehat{\\mathbf{p}}^{(m)} = (\\widehat{p}_1^{(m)}, \\widehat{p}_2^{(m)}, \\widehat{p}_3^{(m)})$.\n\nLet the observed data at the held-out time point $t_m$ be the cell counts in each state, $\\mathbf{c}^{(m)} = (c_1^{(m)}, c_2^{(m)}, c_3^{(m)})$, where $\\sum_{i=1}^{3} c_i^{(m)} = N_m$. According to the assumption of independent draws from a categorical distribution, the likelihood of observing this specific set of $N_m$ cell states, given the model's predicted probabilities $\\widehat{\\mathbf{p}}^{(m)}$, is the product of the probabilities for each individual cell observation. This product can be grouped by state, resulting in the following likelihood function, $L$:\n$$L(\\widehat{\\mathbf{p}}^{(m)}; \\mathbf{c}^{(m)}) = \\prod_{i=1}^{3} (\\widehat{p}_i^{(m)})^{c_i^{(m)}}$$\nThis expression gives the probability of the observed data under the model's predictions. The log-likelihood, $\\mathcal{L}$, is the natural logarithm of this function:\n$$\\mathcal{L}(\\widehat{\\mathbf{p}}^{(m)}; \\mathbf{c}^{(m)}) = \\ln(L) = \\ln\\left(\\prod_{i=1}^{3} (\\widehat{p}_i^{(m)})^{c_i^{(m)}}\\right) = \\sum_{i=1}^{3} c_i^{(m)} \\ln(\\widehat{p}_i^{(m)})$$\nThis log-likelihood is the appropriate measure of how well the model's predicted probabilities $\\widehat{\\mathbf{p}}^{(m)}$ explain the observed counts $\\mathbf{c}^{(m)}$. A higher log-likelihood indicates a better fit.\n\nNote that if we had modeled the counts $\\mathbf{c}^{(m)}$ as a single draw from a multinomial distribution, the log-likelihood would include an additional combinatorial term, $\\ln(N_m!) - \\sum_{i=1}^{3} \\ln(c_i^{(m)}!)$. However, this term depends only on the observed data, not on the model's parameters $\\widehat{\\mathbf{p}}^{(m)}$. Therefore, for the purpose of comparing different models on the same dataset, this term is an irrelevant additive constant and is conventionally omitted. The formulation based on independent categorical draws directly yields the kernel of the log-likelihood that is relevant for model evaluation.\n\nThe problem requires a metric suitable for comparing models across different cross-validation folds, where the number of cells $N_m$ at the held-out time point $t_m$ might differ. The total log-likelihood $\\mathcal{L}$ is an extensive quantity that scales with $N_m$. To obtain an intensive quantity that is comparable across folds, we must normalize by the number of observations. The standard approach is to calculate the average log-likelihood per cell. This leads to the scoring metric $S_m$:\n$$S_m = \\frac{1}{N_m} \\mathcal{L}(\\widehat{\\mathbf{p}}^{(m)}; \\mathbf{c}^{(m)}) = \\frac{1}{N_m} \\sum_{i=1}^{3} c_i^{(m)} \\ln(\\widehat{p}_i^{(m)})$$\nThis metric is expressed in \"nats per cell,\" as the natural logarithm is used. It represents the average contribution of each cell to the total log-likelihood.\n\nNext, we compute the numerical value of this metric for the specified fold where time point $t_2$ is held out.\nThe given data for this fold are:\n\\begin{itemize}\n    \\item Observed counts: $\\mathbf{c}^{(2)} = (52, 29, 19)$\n    \\item Predicted probabilities from the trained model: $\\widehat{\\mathbf{p}}(t_2) = (0.5, 0.3, 0.2)$\n\\end{itemize}\nFirst, we calculate the total number of cells at $t_2$:\n$$N_2 = c_1^{(2)} + c_2^{(2)} + c_3^{(2)} = 52 + 29 + 19 = 100$$\nNow, we apply the derived formula for the scoring metric $S_2$:\n$$S_2 = \\frac{1}{N_2} \\sum_{i=1}^{3} c_i^{(2)} \\ln(\\widehat{p}_i(t_2))$$\nSubstituting the numerical values:\n$$S_2 = \\frac{1}{100} \\left[ 52 \\ln(0.5) + 29 \\ln(0.3) + 19 \\ln(0.2) \\right]$$\nWe compute the terms inside the bracket:\n\\begin{itemize}\n    \\item $52 \\ln(0.5) \\approx 52 \\times (-0.693147) \\approx -36.043644$\n    \\item $29 \\ln(0.3) \\approx 29 \\times (-1.203973) \\approx -34.915217$\n    \\item $19 \\ln(0.2) \\approx 19 \\times (-1.609438) \\approx -30.579322$\n\\end{itemize}\nSumming these values gives the total log-likelihood:\n$$\\sum_{i=1}^{3} c_i^{(2)} \\ln(\\widehat{p}_i(t_2)) \\approx -36.043644 - 34.915217 - 30.579322 = -101.538183$$\nFinally, we divide by $N_2 = 100$ to get the score in nats per cell:\n$$S_2 = \\frac{-101.538183}{100} = -1.01538183$$\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $1$, $0$, $1$, and $5$. The fifth significant figure is $3$, so we round down.\n$$S_2 \\approx -1.015$$",
            "answer": "$$\\boxed{-1.015}$$"
        },
        {
            "introduction": "While discrete states are a useful simplification, many biological processes like differentiation unfold along a continuous trajectory. This practice  introduces the Fokker–Planck equation, a powerful framework from statistical physics for modeling the evolution of cell population density $\\rho(x,t)$ in a continuous state space. You will learn how to build a model that captures directed movement (drift), stochastic fluctuations (diffusion), and net cell growth, and then infer the model's parameters by integrating information from both population-level snapshots and clonal lineage data.",
            "id": "3327656",
            "problem": "You are modeling cell state transitions along a one-dimensional latent trajectory representing a continuous cell state variable $x \\in [0,1]$ from single-cell data. The cell density $ \\rho(x,t)$ evolves under drift $ b(x)$, diffusion $ D(x)$, and net source $ g(x) = r(x) - d(x)$ capturing proliferation ($r$) and apoptosis ($d$). The governing partial differential equation is the Fokker–Planck equation with sources, building on the continuity equation with sources and constitutive drift-diffusion relations:\n$$\n\\partial_t \\rho(x,t) = -\\nabla \\cdot \\big(b(x)\\rho(x,t)\\big) + \\nabla \\cdot \\big(D(x)\\nabla \\rho(x,t)\\big) + g(x)\\rho(x,t),\n$$\nin one dimension with $x \\in [0,1]$ and zero-flux boundary conditions (no net flux across the boundaries). In addition, you are given a scalar cell-cycle feature $ s(x)$ that correlates with proliferation and clonal barcodes that track fold-changes in clone sizes over a short time interval $ \\tau$ hours.\n\nStarting from the conservation law with sources and drift-diffusion flux, and without assuming any shortcut formulas, perform the following:\n\n1. Derive a finite-volume discretization in one dimension on a uniform grid with $ N$ cells, cell centers $ x_i$, spacing $ \\Delta x$, and zero-flux boundaries. Your derivation must begin from the continuity principle and constitutive relations, and produce a consistent, explicit formula for the discrete divergence of the advective term $ -\\nabla \\cdot (b\\rho)$ and the diffusive term $ \\nabla \\cdot (D \\nabla \\rho)$ at the cell centers, in terms of face-centered fluxes computed from cell-centered quantities and face-centered coefficients. This discretization must be valid for nonuniform $ b(x)$ and $ D(x)$ and must satisfy the zero-flux boundary condition by construction.\n\n2. Use the short-time expansion of the conservation law to construct, at each grid point, an estimator for the net source $ g(x)$ based on the discrete time difference $ (\\rho(x,t+\\tau) - \\rho(x,t))$ and your derived discrete drift-diffusion divergence evaluated at time $ t$. Independently, derive a measurement model for clonal fold changes $ m(x) = \\frac{c(x,t+\\tau)}{c(x,t)}$ by showing how the net source $ g(x)$ over the interval $ \\tau$ produces $ g(x) \\approx \\frac{1}{\\tau}\\log m(x)$ under the assumption of exponential growth or decay within each bin.\n\n3. Propose a parametric model $ g(x) = a_0 + a_1 s(x)$ and derive a combined weighted least squares estimator for $ a_0$ and $ a_1$ that integrates both the partial differential equation-based $ g$ estimates and the clonal-log fold-change-based $ g$ measurements. Provide the explicit normal equations for this estimator.\n\n4. Implement a program that generates self-consistent synthetic data and computes the mean absolute error (MAE) between the reconstructed $ g(x)$ and the ground truth $ g_{\\text{true}}(x)$ for a small test suite. Use the following test suite, and for each case, construct $ \\rho(x,0)$, $ b(x)$, $ D(x)$, $ s(x)$, and $ g_{\\text{true}}(x)$ as specified, then obtain $ \\rho(x,\\tau)$ by a single explicit time step using your discretization, and compute the clonal fold changes $ m(x) = \\exp\\big(g_{\\text{true}}(x)\\tau\\big)$.\n\nAll time quantities are in hours, and all growth rates such as $ g(x)$ are in per hour units. Express the final numerical answers in per hour units.\n\nTest Suite (each case uses zero-flux boundary conditions at $ x=0$ and $ x=1$, a uniform grid, and a short step $ \\tau$):\n\n- Case A (happy path):\n  - $ N = 50$, $ \\tau = 0.001$ hours.\n  - $ s(x) = x$.\n  - $ b(x) = -0.5\\,(x - 0.5)$.\n  - $ D(x) = 0.01$.\n  - $ g_{\\text{true}}(x) = 0.1 + 0.4\\,s(x)$.\n  - $ \\rho(x,0) = \\exp\\Big(-\\frac{(x - 0.6)^2}{2\\cdot 0.1^2}\\Big)$.\n- Case B (boundary condition and identifiability edge case):\n  - $ N = 50$, $ \\tau = 0.001$ hours.\n  - $ s(x) = \\sin(2\\pi x) + 1$.\n  - $ b(x) = 0$.\n  - $ D(x) = 0.005$.\n  - $ g_{\\text{true}}(x) = 0.2$ (constant).\n  - $ \\rho(x,0) = 1$.\n- Case C (nonuniform diffusion and drift):\n  - $ N = 80$, $ \\tau = 0.001$ hours.\n  - $ s(x) = x^2$.\n  - $ b(x) = 0.8\\,\\sin(\\pi x)$.\n  - $ D(x) = 0.02 + 0.02\\,x$.\n  - $ g_{\\text{true}}(x) = 0.05 + 0.3\\,s(x)$.\n  - $ \\rho(x,0) = \\exp\\Big(-\\frac{(x - 0.3)^2}{2\\cdot 0.05^2}\\Big) + 0.8\\,\\exp\\Big(-\\frac{(x - 0.8)^2}{2\\cdot 0.07^2}\\Big)$.\n\nAlgorithmic requirements:\n\n- Use a uniform grid with cell centers $ x_i$ and spacing $ \\Delta x$.\n- Compute face-centered coefficients by averaging adjacent cell-centered values.\n- Implement zero-flux boundaries by setting boundary face fluxes to zero consistently in your derived scheme.\n- Use a single explicit time step to compute $ \\rho(x,\\tau)$.\n- Estimate $ g(x)$ from both the partial differential equation residual and the clonal fold changes using your parametric model and least squares estimator.\n- Compute the mean absolute error $ \\text{MAE} = \\frac{1}{N}\\sum_{i=1}^{N} \\left| g_{\\text{est}}(x_i) - g_{\\text{true}}(x_i) \\right|$ for each case.\n\nFinal Output Format:\n\nYour program should produce a single line of output containing the mean absolute errors for Case A, Case B, and Case C, as a comma-separated list enclosed in square brackets, rounded to six decimal places, for example, \"[maeA,maeB,maeC]\". The values represent per hour units.",
            "solution": "The problem asks for the derivation and implementation of a method to estimate the net cell growth rate, $g(x)$, along a one-dimensional cell state trajectory, $x$. The method must integrate two sources of information: snapshots of cell density, $\\rho(x,t)$, governed by a Fokker-Planck-type partial differential equation (PDE), and clonal fold-change data, $m(x)$.\n\n### Part 1: Finite-Volume Discretization\nThe governing PDE for the cell density $\\rho(x,t)$ on the domain $x \\in [0,1]$ is given by:\n$$ \\partial_t \\rho(x,t) = -\\nabla \\cdot \\big(b(x)\\rho(x,t)\\big) + \\nabla \\cdot \\big(D(x)\\nabla \\rho(x,t)\\big) + g(x)\\rho(x,t) $$\nThis can be rewritten using the flux $J(x,t) = b(x)\\rho(x,t) - D(x)\\nabla \\rho(x,t)$ as a continuity equation with a source term:\n$$ \\partial_t \\rho = -\\nabla \\cdot J + g\\rho $$\nWe are given zero-flux boundary conditions, $J(0,t) = J(1,t) = 0$.\n\nTo discretize this equation, we use the finite volume method. We divide the domain $[0,1]$ into $N$ uniform cells, or control volumes, $C_i = [x_{i-1/2}, x_{i+1/2}]$ for $i=1, \\dots, N$. The center of cell $C_i$ is $x_i$, and its width is $\\Delta x = 1/N$. The faces of the cell are at $x_{i-1/2}$ and $x_{i+1/2}$.\n\nWe integrate the PDE over the control volume $C_i$:\n$$ \\int_{x_{i-1/2}}^{x_{i+1/2}} \\partial_t \\rho \\,dx = - \\int_{x_{i-1/2}}^{x_{i+1/2}} \\nabla \\cdot J \\,dx + \\int_{x_{i-1/2}}^{x_{i+1/2}} g\\rho \\,dx $$\nApplying the divergence theorem to the flux term and approximating the integrals, we get a semi-discrete equation for the average density $\\rho_i(t)$ in cell $i$:\n$$ \\Delta x \\frac{d\\rho_i}{dt} \\approx - \\left( J(x_{i+1/2}, t) - J(x_{i-1/2}, t) \\right) + g(x_i)\\rho_i(t) \\Delta x $$\nDividing by $\\Delta x$:\n$$ \\frac{d\\rho_i}{dt} = - \\frac{J_{i+1/2} - J_{i-1/2}}{\\Delta x} + g_i \\rho_i $$\nwhere $J_{i \\pm 1/2}$ are the fluxes at the cell faces, and we use the notation $g_i = g(x_i)$ and $\\rho_i = \\rho(x_i, t)$.\n\nThe flux $J_{i+1/2}$ is composed of an advective part, $J_{\\text{adv}}$, and a diffusive part, $J_{\\text{diff}}$.\n$J_{i+1/2} = J_{\\text{adv}, i+1/2} - J_{\\text{diff}, i+1/2}$ based on the definition of $J$.\nWait, the PDE is $\\partial_t \\rho = -\\nabla \\cdot (b \\rho) + \\nabla \\cdot (D \\nabla \\rho) + g \\rho$. Let's rewrite this as $\\partial_t \\rho = -\\nabla \\cdot (b \\rho - D \\nabla \\rho) + g \\rho$. The flux is $J=b\\rho - D\\nabla\\rho$. This matches my initial assessment.\n\nThe diffusive part of the flux at face $i+1/2$ is $D(x_{i+1/2})\\nabla \\rho$. We approximate this using a central difference for the gradient and averaging for the coefficient:\n$$ J_{\\text{diff}, i+1/2} \\approx D_{i+1/2} \\frac{\\rho_{i+1} - \\rho_i}{\\Delta x} = \\frac{D_i + D_{i+1}}{2} \\frac{\\rho_{i+1} - \\rho_i}{\\Delta x} $$\nThe advective flux is $b(x_{i+1/2})\\rho(x_{i+1/2})$. We use a first-order upwind scheme for stability. The density at the face is taken from the \"upwind\" cell, determined by the sign of the drift $b$ at the face.\n$$ J_{\\text{adv}, i+1/2} \\approx b_{i+1/2} \\rho_{i+1/2} = \\frac{b_i + b_{i+1}}{2} \\times \\begin{cases} \\rho_i & \\text{if } b_{i+1/2} \\ge 0 \\\\ \\rho_{i+1} & \\text{if } b_{i+1/2} < 0 \\end{cases} $$\nThe total flux at face $i+1/2$ is:\n$$ J_{i+1/2} = \\left(\\frac{b_i+b_{i+1}}{2}\\right)^{+} \\rho_i + \\left(\\frac{b_i+b_{i+1}}{2}\\right)^{-} \\rho_{i+1} - \\left(\\frac{D_i+D_{i+1}}{2}\\right) \\frac{\\rho_{i+1}-\\rho_i}{\\Delta x} $$\nwhere $v^+ = \\max(v, 0)$ and $v^- = \\min(v, 0)$.\nThe zero-flux boundary conditions are naturally imposed by setting the fluxes at the domain boundaries to zero: $J_{1/2} = 0$ and $J_{N+1/2} = 0$.\n\nThe divergence of the advective term is $-\\frac{J_{\\text{adv}, i+1/2} - J_{\\text{adv}, i-1/2}}{\\Delta x}$ and the divergence of the diffusive term is $+\\frac{J_{\\text{diff}, i+1/2} - J_{\\text{diff}, i-1/2}}{\\Delta x}$. This provides the full discretization.\n\n### Part 2: Estimators for $g(x)$\n\n**PDE-based Estimator:**\nThe semi-discrete PDE is $\\frac{d\\rho_i}{dt} = \\mathcal{L}(\\rho)_i + g_i \\rho_i$, where $\\mathcal{L}(\\rho)_i = - \\frac{J_{i+1/2} - J_{i-1/2}}{\\Delta x}$.\nUsing a first-order forward difference for the time derivative over a short interval $\\tau$, we have $\\frac{d\\rho_i}{dt} \\approx \\frac{\\rho_i(t+\\tau) - \\rho_i(t)}{\\tau}$.\nSubstituting this and solving for $g_i$ (assuming $\\rho_i > 0$):\n$$ g_{\\text{PDE}, i} \\approx \\frac{1}{\\rho_i(t)} \\left( \\frac{\\rho_i(t+\\tau) - \\rho_i(t)}{\\tau} - \\mathcal{L}(\\rho(t))_i \\right) $$\n\n**Clonal Data-based Estimator:**\nIgnoring cell movement (drift and diffusion), the change in the number of cells $c(x,t)$ of a specific clone at position $x$ is governed by local net growth: $\\frac{dc}{dt} = g(x) c(x,t)$.\nIntegrating over a short time $\\tau$ gives $c(x, t+\\tau) = c(x,t) e^{g(x)\\tau}$.\nThe clonal fold change is $m(x) = \\frac{c(x, t+\\tau)}{c(x,t)} = e^{g(x)\\tau}$.\nSolving for $g(x)$ provides the second estimator:\n$$ g_{\\text{clonal}, i} \\approx \\frac{1}{\\tau} \\log m(x_i) $$\n\n### Part 3: Combined Weighted Least Squares Estimator\nWe are given a parametric model $g(x_i) = a_0 + a_1 s(x_i)$, where $s(x)$ is a cell-cycle feature. We have two estimates for $g(x_i)$ at each grid point $i$: $g_{\\text{PDE}, i}$ and $g_{\\text{clonal}, i}$.\n\nThe PDE-based estimator involves division by $\\rho_i$, which can be numerically unstable if cell density is low. To create a robust estimator, we formulate a weighted least squares problem that avoids this division. Instead of minimizing the error in $g_i$, we can minimize errors in quantities that are well-behaved. Let $Y_{1,i} = \\rho_i(t) g_{\\text{PDE}, i}$ and $Y_{2,i} = g_{\\text{clonal}, i}$. From the derivation of $g_{\\text{PDE}, i}$, we see that $Y_{1,i} = \\frac{\\rho_i(t+\\tau) - \\rho_i(t)}{\\tau} - \\mathcal{L}(\\rho(t))_i$, which does not involve division by $\\rho_i(t)$.\n\nWe define the loss function $L(a_0, a_1)$ to be minimized:\n$$ L(a_0, a_1) = \\sum_{i=1}^N \\left( Y_{1,i} - \\rho_i (a_0 + a_1 s_i) \\right)^2 + \\sum_{i=1}^N \\left( Y_{2,i} - (a_0 + a_1 s_i) \\right)^2 $$\nThis corresponds to a weighted least squares problem. To find the optimal $a_0$ and $a_1$, we set the partial derivatives of $L$ with respect to $a_0$ and $a_1$ to zero.\nLet $g_{\\text{model}, i} = a_0 + a_1 s_i$. The loss is $L = \\sum(\\rho_i g_{\\text{model},i} - Y_{1,i})^2 + \\sum(g_{\\text{model},i} - Y_{2,i})^2$. The derivatives are:\n$$ \\frac{\\partial L}{\\partial a_0} = \\sum 2(\\rho_i g_{\\text{model},i} - Y_{1,i}) \\rho_i + \\sum 2(g_{\\text{model},i} - Y_{2,i}) = 0 $$\n$$ \\frac{\\partial L}{\\partial a_1} = \\sum 2(\\rho_i g_{\\text{model},i} - Y_{1,i}) \\rho_i s_i + \\sum 2(g_{\\text{model},i} - Y_{2,i}) s_i = 0 $$\nRearranging gives the normal equations:\n$$ \\sum (\\rho_i^2+1) g_{\\text{model},i} = \\sum (\\rho_i Y_{1,i} + Y_{2,i}) $$\n$$ \\sum (\\rho_i^2+1) s_i g_{\\text{model},i} = \\sum s_i(\\rho_i Y_{1,i} + Y_{2,i}) $$\nSubstituting $g_{\\text{model},i} = a_0 + a_1 s_i$ yields a $2 \\times 2$ linear system for the parameter vector $\\mathbf{a} = [a_0, a_1]^T$: $\\mathbf{M} \\mathbf{a} = \\mathbf{v}$, where:\n$$ \\mathbf{M} = \\begin{pmatrix} \\sum_{i=1}^N (\\rho_i^2+1) & \\sum_{i=1}^N (\\rho_i^2+1)s_i \\\\ \\sum_{i=1}^N (\\rho_i^2+1)s_i & \\sum_{i=1}^N (\\rho_i^2+1)s_i^2 \\end{pmatrix} $$\n$$ \\mathbf{v} = \\begin{pmatrix} \\sum_{i=1}^N (\\rho_i Y_{1,i} + Y_{2,i}) \\\\ \\sum_{i=1}^N s_i (\\rho_i Y_{1,i} + Y_{2,i}) \\end{pmatrix} $$\nSolving this system gives the estimated parameters $a_0$ and $a_1$.\n\n### Part 4: Implementation and Synthetic Data\nThe implementation will follow the steps outlined. Synthetic data for $\\rho(x, \\tau)$ is generated by applying a single explicit forward Euler time step to the initial density $\\rho(x, 0)$ using the derived finite-volume scheme and the known ground truth $g_{\\text{true}}(x)$. The clonal fold changes $m(x)$ are generated directly from $g_{\\text{true}}(x)$. These synthetic data are then used with the derived estimators to find $a_0$ and $a_1$ and compute the estimated $\\hat{g}(x) = \\hat{a}_0 + \\hat{a}_1 s(x)$. The performance is measured by the Mean Absolute Error (MAE) between $\\hat{g}(x)$ and $g_{\\text{true}}(x)$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n\n    def solve_case(N, tau, s_func, b_func, D_func, g_true_func, rho0_func):\n        \"\"\"\n        Solves a single case of the problem.\n\n        Args:\n            N (int): Number of grid cells.\n            tau (float): Short time interval.\n            s_func (callable): Function for the cell-cycle feature s(x).\n            b_func (callable): Function for the drift b(x).\n            D_func (callable): Function for the diffusion D(x).\n            g_true_func (callable): Function for the ground truth net source g(x).\n            rho0_func (callable): Function for the initial cell density rho(x, 0).\n\n        Returns:\n            float: The mean absolute error (MAE) between the estimated and true g(x).\n        \"\"\"\n        # 1. Grid setup\n        dx = 1.0 / N\n        x = np.linspace(dx / 2, 1.0 - dx / 2, N)\n\n        # 2. Evaluate parameters and initial conditions\n        s = s_func(x)\n        b = b_func(x)\n        D = D_func(x)\n        rho0 = rho0_func(x)\n        g_true = g_true_func(x, s)\n\n        # 3. Compute rho(x, tau) with one explicit Euler step\n        # This requires calculating the flux J at t=0\n        J = np.zeros(N + 1)  # N+1 faces, J[0] and J[N] are zero by B.C.\n\n        # Compute fluxes at interior faces (j=1 to N-1)\n        b_face = (b[:-1] + b[1:]) / 2.0\n        D_face = (D[:-1] + D[1:]) / 2.0\n        rho_left = rho0[:-1]\n        rho_right = rho0[1:]\n\n        # Advective flux using first-order upwind scheme\n        J_adv_interior = np.where(b_face >= 0, b_face * rho_left, b_face * rho_right)\n        \n        # Diffusive flux\n        J_diff_interior = -D_face * (rho_right - rho_left) / dx\n        \n        # Total flux\n        J[1:-1] = J_adv_interior + J_diff_interior\n        \n        # Compute the discrete operator L(rho) = -div(J)\n        L_rho = -(J[1:] - J[:-1]) / dx\n        \n        # Evolve rho for one time step\n        drho_dt = L_rho + g_true * rho0\n        rho_tau = rho0 + tau * drho_dt\n        \n        # 4. Calculate the two estimators for g(x)\n        \n        # Estimator from clonal data \n        # (synthetically generated from g_true)\n        m = np.exp(g_true * tau)\n        g_clonal = (1.0 / tau) * np.log(m)\n        \n        # Estimator from PDE\n        # We work with Y1 = rho0 * g_pde to avoid division by small rho0\n        # Y1 = (rho_tau - rho0)/tau - L_rho\n        Y1 = (rho_tau - rho0) / tau - L_rho\n        Y2 = g_clonal\n\n        # 5. Perform weighted least squares\n        # The linear system is M * [a0, a1]^T = v\n        \n        # Build the matrix M\n        w = rho0**2 + 1\n        M = np.zeros((2, 2))\n        M[0, 0] = np.sum(w)\n        M[0, 1] = np.sum(w * s)\n        M[1, 0] = M[0, 1]\n        M[1, 1] = np.sum(w * s**2)\n\n        # Build the vector v\n        rhs_summand = rho0 * Y1 + Y2\n        v = np.zeros(2)\n        v[0] = np.sum(rhs_summand)\n        v[1] = np.sum(s * rhs_summand)\n        \n        # Solve for parameters a = [a0, a1]\n        try:\n            a = np.linalg.solve(M, v)\n        except np.linalg.LinAlgError:\n            # Fallback to pseudo-inverse if singular\n            a = np.linalg.pinv(M) @ v\n            \n        a0_est, a1_est = a[0], a[1]\n\n        # 6. Calculate estimated g and MAE\n        g_est = a0_est + a1_est * s\n        mae = np.mean(np.abs(g_est - g_true))\n        \n        return mae\n\n    # Test Suite\n    test_cases = {\n        'A': {\n            'N': 50, 'tau': 0.001,\n            's_func': lambda x: x,\n            'b_func': lambda x: -0.5 * (x - 0.5),\n            'D_func': lambda x: 0.01 + np.zeros_like(x),\n            'g_true_func': lambda x, s: 0.1 + 0.4 * s,\n            'rho0_func': lambda x: np.exp(-(x - 0.6)**2 / (2 * 0.1**2))\n        },\n        'B': {\n            'N': 50, 'tau': 0.001,\n            's_func': lambda x: np.sin(2 * np.pi * x) + 1.0,\n            'b_func': lambda x: np.zeros_like(x),\n            'D_func': lambda x: 0.005 + np.zeros_like(x),\n            'g_true_func': lambda x, s: 0.2 + np.zeros_like(s), # Constant g\n            'rho0_func': lambda x: np.ones_like(x)\n        },\n        'C': {\n            'N': 80, 'tau': 0.001,\n            's_func': lambda x: x**2,\n            'b_func': lambda x: 0.8 * np.sin(np.pi * x),\n            'D_func': lambda x: 0.02 + 0.02 * x,\n            'g_true_func': lambda x, s: 0.05 + 0.3 * s,\n            'rho0_func': lambda x: (np.exp(-(x - 0.3)**2 / (2 * 0.05**2)) + \n                                     0.8 * np.exp(-(x - 0.8)**2 / (2 * 0.07**2)))\n        }\n    }\n\n    results = []\n    for case_id in ['A', 'B', 'C']:\n        params = test_cases[case_id]\n        mae = solve_case(\n            params['N'], params['tau'], params['s_func'],\n            params['b_func'], params['D_func'], params['g_true_func'],\n            params['rho0_func']\n        )\n        results.append(round(mae, 6))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The vector fields inferred from single-cell data, which represent the landscape of cellular transitions, can hide complex dynamics. This exercise  introduces the discrete Hodge decomposition, a sophisticated tool from algebraic topology, to dissect these vector fields into biologically meaningful components. By separating the flow into a gradient part, often associated with directed differentiation, and a curl part, linked to cyclical processes like the cell cycle, you will learn to extract deeper quantitative insights into the geometry of cell fate decisions.",
            "id": "3327702",
            "problem": "Consider a finite, simple, undirected graph whose vertices represent single cells and whose edges connect transcriptionally similar cells. A directed edge flow is used to approximate a continuous cell-state vector field from single-cell measurements; specifically, the flow on each undirected edge is assigned an orientation by the ascending node labels. Let the oriented edge flow be denoted by a vector $y \\in \\mathbb{R}^{m}$, where $m$ is the number of edges. The oriented incidence matrix $B \\in \\mathbb{R}^{m \\times n}$, where $n$ is the number of nodes, is defined so that for each edge oriented from node $i$ to node $j$ with $i<j$, the row corresponding to that edge has entry $-1$ at column $i$, entry $+1$ at column $j$, and $0$ elsewhere. The set of all $3$-cliques (triangles) induces a simplicial $2$-complex; define the edge-to-triangle incidence matrix $D_{1} \\in \\mathbb{R}^{m \\times t}$, where $t$ is the number of triangles, so that for each triangle $(i,j,k)$ with $i<j<k$ and boundary orientation\n$$\n\\partial (i,j,k) = (i,j) + (j,k) - (i,k),\n$$\nthe column of $D_{1}$ corresponding to this triangle has entries $+1$ at edges $(i,j)$ and $(j,k)$ if their orientations match the boundary, and entry $-1$ at edge $(i,k)$ if its orientation is opposite to the boundary. All other entries are $0$. Using the standard Euclidean inner product on edge flows, the fundamental fact of discrete Hodge decomposition on graphs states that any edge flow $y$ can be written uniquely as an orthogonal sum\n$$\ny = y_{\\mathrm{grad}} + y_{\\mathrm{curl}} + y_{\\mathrm{harm}},\n$$\nwhere $y_{\\mathrm{grad}} \\in \\mathrm{col}(B)$, $y_{\\mathrm{curl}} \\in \\mathrm{col}(D_{1})$, and $y_{\\mathrm{harm}}$ is orthogonal to both $\\mathrm{col}(B)$ and $\\mathrm{col}(D_{1})$. In this setting, $y_{\\mathrm{grad}}$ is the gradient-like (potential) component, $y_{\\mathrm{curl}}$ is the curl-like (circulation) component supported by triangles, and $y_{\\mathrm{harm}}$ captures cycle flows not explained by triangles. From first principles in linear algebra, the orthogonal projection of $y$ onto a column space (with respect to the standard inner product) is given by the least-squares solution against the corresponding design matrix.\n\nTask. Derive and implement a procedure that, given a graph and an edge flow $y$, separates $y$ into its gradient, curl, and harmonic components using orthogonal projections onto $\\mathrm{col}(B)$ and $\\mathrm{col}(D_{1})$. Then, evaluate biological correlates as follows:\n- For differentiation: compute a potential vector $\\phi \\in \\mathbb{R}^{n}$ that yields $y_{\\mathrm{grad}} = B \\phi$. Quantify the concordance between $\\phi$ and a provided pseudotime vector $p \\in \\mathbb{R}^{n}$ by the Pearson correlation coefficient defined as\n$$\nr_{\\mathrm{grad}} = \\frac{\\sum_{i=1}^{n} (\\phi_{i}-\\bar{\\phi})(p_{i}-\\bar{p})}{\\sqrt{\\sum_{i=1}^{n} (\\phi_{i}-\\bar{\\phi})^{2}} \\, \\sqrt{\\sum_{i=1}^{n} (p_{i}-\\bar{p})^{2}}}.\n$$\n- For cell cycle: convert the curl edge flow $y_{\\mathrm{curl}}$ to a node-level curl exposure $c \\in \\mathbb{R}^{n}$ by assigning to each node $u$ the root-mean-square of the magnitudes of $y_{\\mathrm{curl}}$ over its incident edges. Quantify the concordance between $c$ and a provided cell-cycle score vector $s \\in \\mathbb{R}^{n}$ by the Pearson correlation coefficient\n$$\nr_{\\mathrm{curl}} = \\frac{\\sum_{i=1}^{n} (c_{i}-\\bar{c})(s_{i}-\\bar{s})}{\\sqrt{\\sum_{i=1}^{n} (c_{i}-\\bar{c})^{2}} \\, \\sqrt{\\sum_{i=1}^{n} (s_{i}-\\bar{s})^{2}}}.\n$$\n\nFor numerical stability, if any standard deviation in the denominator is exactly zero, define the corresponding correlation as $0$.\n\nFor each test case below, compute and report:\n- The fraction of energy in each component,\n$$\nf_{\\mathrm{grad}} = \\frac{\\lVert y_{\\mathrm{grad}} \\rVert_{2}^{2}}{\\lVert y \\rVert_{2}^{2}}, \\quad f_{\\mathrm{curl}} = \\frac{\\lVert y_{\\mathrm{curl}} \\rVert_{2}^{2}}{\\lVert y \\rVert_{2}^{2}}, \\quad f_{\\mathrm{harm}} = \\frac{\\lVert y_{\\mathrm{harm}} \\rVert_{2}^{2}}{\\lVert y \\rVert_{2}^{2}},\n$$\nwith the convention that if $\\lVert y \\rVert_{2}=0$ then set all three fractions to $0$.\n- The correlation metrics $r_{\\mathrm{grad}}$ and $r_{\\mathrm{curl}}$ as defined above.\n\nYou must implement the following from first principles of linear algebra:\n- Construct $B$ from the oriented edges as defined.\n- Identify all triangles by enumerating all $3$-cliques in the undirected graph, then construct $D_{1}$ using the boundary orientation rule $\\partial (i,j,k) = (i,j) + (j,k) - (i,k)$ with $i<j<k$.\n- Compute $y_{\\mathrm{grad}}$ as the orthogonal projection of $y$ onto $\\mathrm{col}(B)$ by least squares. That is, find $\\phi$ minimizing $\\lVert B \\phi - y \\rVert_{2}^{2}$ and set $y_{\\mathrm{grad}} = B \\phi$.\n- Compute $y_{\\mathrm{curl}}$ as the orthogonal projection of $y$ onto $\\mathrm{col}(D_{1})$ by least squares. That is, find $\\alpha$ minimizing $\\lVert D_{1} \\alpha - y \\rVert_{2}^{2}$ and set $y_{\\mathrm{curl}} = D_{1} \\alpha$. If there are no triangles (i.e., $t=0$ so $D_{1}$ has zero columns), define $y_{\\mathrm{curl}}=0$.\n- Compute $y_{\\mathrm{harm}} = y - y_{\\mathrm{grad}} - y_{\\mathrm{curl}}$.\n\nTest suite. For each test, the node set is $\\{0,1,\\dots,n-1\\}$, edges are undirected but oriented by the rule $i<j$ for edge $(i\\to j)$, and the pseudotime $p$ and cell-cycle score $s$ are given per node. The edge flow $y$ is specified either by composing gradient and curl generators or directly per edge as noted.\n\n- Test $1$ (mixed gradient and curl on a triangle-with-branch graph):\n  - Nodes: $n=6$.\n  - Edges: $(0,1)$, $(1,2)$, $(0,2)$, $(2,3)$, $(3,4)$, $(4,5)$.\n  - Gradient potential: $\\phi = [0.00, 0.20, 0.40, 0.60, 0.80, 1.00]$.\n  - Triangle amplitudes (per triangle tuple): $\\alpha\\{(0,1,2)\\} = 1.00$.\n  - Curl mixing coefficient: $\\gamma = 0.50$.\n  - Edge flow construction: $y = B \\phi + \\gamma \\, D_{1} \\alpha$.\n  - Pseudotime: $p = [0.00, 0.22, 0.39, 0.62, 0.81, 0.98]$.\n  - Cell-cycle score: $s = [1.00, 0.90, 0.80, 0.20, 0.10, 0.05]$.\n\n- Test $2$ (pure gradient on the same graph):\n  - Nodes: $n=6$.\n  - Edges: $(0,1)$, $(1,2)$, $(0,2)$, $(2,3)$, $(3,4)$, $(4,5)$.\n  - Gradient potential: $\\phi = [0.00, 0.20, 0.40, 0.60, 0.80, 1.00]$.\n  - Triangle amplitudes: $\\alpha\\{(0,1,2)\\} = 0.00$.\n  - Edge flow construction: $y = B \\phi$.\n  - Pseudotime: $p = [0.00, 0.20, 0.40, 0.60, 0.80, 1.00]$.\n  - Cell-cycle score: $s = [0.30, 0.50, 0.40, 0.60, 0.70, 0.20]$.\n\n- Test $3$ (pure curl on a two-triangle complex):\n  - Nodes: $n=4$.\n  - Edges: $(0,1)$, $(1,2)$, $(2,3)$, $(0,3)$, $(0,2)$.\n  - Triangle amplitudes: $\\alpha\\{(0,1,2)\\} = 1.00$, $\\alpha\\{(0,2,3)\\} = 0.20$.\n  - Gradient potential: $\\phi = [0.00, 0.00, 0.00, 0.00]$.\n  - Edge flow construction: $y = D_{1} \\alpha$.\n  - Pseudotime: $p = [0.10, 0.40, 0.20, 0.30]$.\n  - Cell-cycle score: $s = [1.00, 0.95, 0.90, 0.60]$.\n\n- Test $4$ (harmonic cycle on a $4$-cycle with no triangles):\n  - Nodes: $n=4$.\n  - Edges: $(0,1)$, $(1,2)$, $(2,3)$, $(0,3)$.\n  - Edge flow specified directly to represent a unit circulation following $0 \\to 1 \\to 2 \\to 3 \\to 0$:\n    - $y(0,1) = 1.00$, $y(1,2) = 1.00$, $y(2,3) = 1.00$, $y(0,3) = -1.00$.\n  - Pseudotime: $p = [0.00, 0.30, 0.60, 0.90]$.\n  - Cell-cycle score: $s = [0.20, 0.20, 0.20, 0.20]$.\n\nOutput requirements.\n- For each test, compute $[f_{\\mathrm{grad}}, f_{\\mathrm{curl}}, f_{\\mathrm{harm}}, r_{\\mathrm{grad}}, r_{\\mathrm{curl}}]$.\n- Round each value to exactly $4$ decimal places using standard rounding to nearest, with halfway cases rounded to the nearest even representable float.\n- Your program should produce a single line of output containing the results as a comma-separated list of lists enclosed in square brackets, in the order of the tests $1$ through $4$. For example, a valid format is\n\"[ [0.1234,0.2345,0.6421,0.8765,0.0123], [ ... ], [ ... ], [ ... ] ]\".\nNo physical units are involved in this problem, and angles are not used. All numerical answers are unitless floats.",
            "solution": "The problem requires the decomposition of a given edge flow vector $y \\in \\mathbb{R}^{m}$ on a graph into three orthogonal components: a gradient component $y_{\\mathrm{grad}}$, a curl component $y_{\\mathrm{curl}}$, and a harmonic component $y_{\\mathrm{harm}}$. This decomposition is known as the discrete Hodge decomposition. The procedure and subsequent analyses will be derived from first principles of linear algebra as specified.\n\nThe graph has $n$ vertices (nodes) and $m$ edges. By convention, each undirected edge is assigned an orientation from the lower-indexed node to the higher-indexed node.\n\n**1. Matrix Representations**\n\nThe relationships between nodes, edges, and triangles (3-cliques) are captured by two incidence matrices, $B$ and $D_1$.\n\nThe **oriented incidence matrix**, $B \\in \\mathbb{R}^{m \\times n}$, maps node-based potentials to gradient flows on edges. For an edge $e_k$ oriented from node $i$ to node $j$ (with $i<j$), its corresponding row in $B$ has $B_{k,i} = -1$ and $B_{k,j} = +1$, with all other entries being zero. The column space of $B$, $\\mathrm{col}(B)$, is the space of all gradient flows. An edge flow $v$ is a gradient flow if it can be written as $v = B\\phi$ for some potential vector $\\phi \\in \\mathbb{R}^n$.\n\nThe **edge-to-triangle incidence matrix**, $D_1 \\in \\mathbb{R}^{m \\times t}$, where $t$ is the number of triangles, represents elementary curl flows supported on each triangle. For a triangle $(i,j,k)$ with $i<j<k$, the problem defines a boundary orientation $\\partial(i,j,k) = (i,j) + (j,k) - (i,k)$, which corresponds to the cycle $i \\to j \\to k \\to i$. The corresponding column of $D_1$ is a vector representing this cycle flow in the basis of oriented edges. This vector has:\n- A $+1$ for edge $(i,j)$ (since its orientation matches the cycle).\n- A $+1$ for edge $(j,k)$ (since its orientation matches the cycle).\n- A $-1$ for edge $(i,k)$ (since its orientation is opposite to the cycle's required $k \\to i$ path).\nThe column space of $D_1$, $\\mathrm{col}(D_1)$, is the space of curl flows that are generated by triangles.\n\nA fundamental property of these matrices is that their column spaces are orthogonal, i.e., $D_1^T B = 0$. This ensures that the gradient and curl components are orthogonal.\n\n**2. Orthogonal Decomposition via Least Squares**\n\nThe problem states that the components $y_{\\mathrm{grad}}$ and $y_{\\mathrm{curl}}$ are orthogonal projections of $y$ onto $\\mathrm{col}(B)$ and $\\mathrm{col}(D_1)$, respectively. The orthogonal projection of a vector $y$ onto the column space of a matrix $A$ is given by $P_A y = Ax^*$, where $x^*$ is the solution to the linear least-squares problem:\n$$\nx^* = \\arg\\min_{x} \\lVert Ax - y \\rVert_2^2\n$$\nThis solution is found by solving the normal equations, $(A^T A)x = A^T y$. Modern-day numerical solvers for least squares, such as `numpy.linalg.lstsq`, robustly find a solution even when $A^T A$ is singular.\n\nThe **gradient component** $y_{\\mathrm{grad}}$ is the projection of $y$ onto $\\mathrm{col}(B)$. We find the potential vector $\\phi$ that minimizes $\\lVert B\\phi - y \\rVert_2^2$ and then set $y_{\\mathrm{grad}} = B\\phi$.\n\nThe **curl component** $y_{\\mathrm{curl}}$ is the projection of $y$ onto $\\mathrm{col}(D_1)$. We find the triangle amplitude vector $\\alpha$ that minimizes $\\lVert D_1\\alpha - y \\rVert_2^2$ and then set $y_{\\mathrm{curl}} = D_1\\alpha$. If the graph is triangle-free ($t=0$), then $D_1$ has no columns, its column space is the zero vector, and thus $y_{\\mathrm{curl}} = 0$.\n\nThe **harmonic component** $y_{\\mathrm{harm}}$ captures the part of the flow that is neither a gradient nor a triangle-based curl. Since $y_{\\mathrm{grad}}$ and $y_{\\mathrm{curl}}$ are orthogonal, it is computed as the residual:\n$$\ny_{\\mathrm{harm}} = y - y_{\\mathrm{grad}} - y_{\\mathrm{curl}}\n$$\nBy construction, $y_{\\mathrm{harm}}$ is orthogonal to both $y_{\\mathrm{grad}}$ and $y_{\\mathrm{curl}}$. The orthogonality of all three components implies the Pythagorean-like property for their energies (squared $L_2$ norms): $\\lVert y \\rVert_2^2 = \\lVert y_{\\mathrm{grad}} \\rVert_2^2 + \\lVert y_{\\mathrm{curl}} \\rVert_2^2 + \\lVert y_{\\mathrm{harm}} \\rVert_2^2$.\n\n**3. Calculation of Metrics**\n\nOnce the decomposition is complete, we compute the required metrics.\n\n**Energy fractions**: The fraction of the total energy $\\lVert y \\rVert_2^2$ contributed by each component is calculated as:\n$$\nf_{\\mathrm{grad}} = \\frac{\\lVert y_{\\mathrm{grad}} \\rVert_{2}^{2}}{\\lVert y \\rVert_{2}^{2}}, \\quad f_{\\mathrm{curl}} = \\frac{\\lVert y_{\\mathrm{curl}} \\rVert_{2}^{2}}{\\lVert y \\rVert_{2}^{2}}, \\quad f_{\\mathrm{harm}} = \\frac{\\lVert y_{\\mathrm{harm}} \\rVert_{2}^{2}}{\\lVert y \\rVert_{2}^{2}}\n$$\nIf $\\lVert y \\rVert_{2}=0$, all fractions are defined as $0$.\n\n**Differentiation Concordance ($r_{\\mathrm{grad}}$)**: The concordance between the computed node potential $\\phi$ and the provided pseudotime vector $p$ is measured by the Pearson correlation coefficient. The potential $\\phi$ is only determined up to an additive constant for each connected component of the graph, but the Pearson correlation is invariant to such shifts, making it a well-defined metric.\n$$\nr_{\\mathrm{grad}} = \\frac{\\mathrm{cov}(\\phi, p)}{\\sigma_{\\phi} \\sigma_{p}} = \\frac{\\sum_{i=1}^{n} (\\phi_{i}-\\bar{\\phi})(p_{i}-\\bar{p})}{\\sqrt{\\sum_{i=1}^{n} (\\phi_{i}-\\bar{\\phi})^{2}} \\, \\sqrt{\\sum_{i=1}^{n} (p_{i}-\\bar{p})^{2}}}\n$$\n\n**Cell Cycle Concordance ($r_{\\mathrm{curl}}$)**: The curl flow is summarized at the node level by the curl exposure vector $c \\in \\mathbb{R}^n$. For each node $u$, $c_u$ is the root-mean-square (RMS) of the magnitudes of the curl flow $y_{\\mathrm{curl}}$ on its incident edges $E_u$:\n$$\nc_u = \\sqrt{\\frac{1}{|E_u|} \\sum_{e \\in E_u} (y_{\\mathrm{curl},e})^2}\n$$\nThe concordance between $c$ and the cell-cycle score vector $s$ is then computed using the Pearson correlation coefficient, $r_{\\mathrm{curl}}$.\n\nFor both correlation calculations, if the standard deviation of either vector is zero, the correlation is defined to be $0$.\n\nThe implementation will systematically follow these steps for each test case provided.\n1.  Construct canonical representations of the graph's edges.\n2.  Build matrices $B$ and $D_1$ based on the graph's topology.\n3.  Construct the input flow vector $y$ as specified.\n4.  Solve the least-squares problems to find $y_{\\mathrm{grad}}$ and $y_{\\mathrm{curl}}$.\n5.  Calculate $y_{\\mathrm{harm}}$ and all derived metrics.\n6.  Format the results as required.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print results.\n    \"\"\"\n\n    def _pearson_corr(x, y):\n        \"\"\"Computes Pearson correlation, handling zero standard deviation.\"\"\"\n        mean_x, mean_y = np.mean(x), np.mean(y)\n        std_x, std_y = np.std(x), np.std(y)\n\n        if std_x == 0 or std_y == 0:\n            return 0.0\n\n        cov = np.mean((x - mean_x) * (y - mean_y))\n        return cov / (std_x * std_y)\n\n    def _construct_matrices_and_y(case):\n        \"\"\"Constructs graph matrices and the flow vector y for a given test case.\"\"\"\n        n = case['n']\n        edges_raw = case['edges']\n        \n        nodes = list(range(n))\n        edges = sorted([tuple(sorted(e)) for e in edges_raw])\n        m = len(edges)\n        edge_map = {edge: i for i, edge in enumerate(edges)}\n\n        # Construct B matrix\n        B = np.zeros((m, n))\n        for i, edge in enumerate(edges):\n            u, v = edge\n            B[i, u] = -1\n            B[i, v] = 1\n        \n        # Find triangles\n        adj = {i: set() for i in nodes}\n        for u, v in edges:\n            adj[u].add(v)\n            adj[v].add(u)\n        \n        triangles = []\n        for i in nodes:\n            for j in adj[i]:\n                if j > i:\n                    for k in adj[j]:\n                        if k > j and k in adj[i]:\n                            triangles.append((i, j, k))\n        triangles = sorted(triangles)\n        t = len(triangles)\n\n        # Construct D1 matrix\n        D1 = np.zeros((m, 0))\n        if t > 0:\n            D1 = np.zeros((m, t))\n            for k_idx, tri in enumerate(triangles):\n                i, j, k = tri  # i < j < k\n                D1[edge_map[(i, j)], k_idx] = 1\n                D1[edge_map[(j, k)], k_idx] = 1\n                D1[edge_map[(i, k)], k_idx] = -1\n\n        # Construct y vector\n        if 'y_direct' in case:\n            y = np.zeros(m)\n            for edge, val in case['y_direct'].items():\n                u, v = tuple(sorted(edge))\n                y[edge_map[(u, v)]] = val\n        else:\n            y_grad_gen = B @ np.array(case['phi_gen'])\n            \n            y_curl_gen = np.zeros(m)\n            if t > 0 and 'alpha_gen' in case:\n                alpha_vec = np.zeros(t)\n                for tri, amp in case['alpha_gen'].items():\n                    try:\n                        k_idx = triangles.index(tuple(sorted(tri)))\n                        alpha_vec[k_idx] = amp\n                    except ValueError:\n                        pass # Triangle not in graph\n                \n                gamma = case.get('gamma', 1.0)\n                y_curl_gen = gamma * (D1 @ alpha_vec)\n            \n            y = y_grad_gen + y_curl_gen\n            \n        return n, m, edges, edge_map, B, D1, t, y, np.array(case['p']), np.array(case['s'])\n\n\n    def process_case(case):\n        \"\"\"Performs Hodge decomposition and calculates metrics for a single case.\"\"\"\n        n, m, edges, edge_map, B, D1, t, y, p, s = _construct_matrices_and_y(case)\n\n        # Orthogonal projections\n        phi, _, _, _ = np.linalg.lstsq(B, y, rcond=None)\n        y_grad = B @ phi\n\n        if t > 0:\n            alpha, _, _, _ = np.linalg.lstsq(D1, y, rcond=None)\n            y_curl = D1 @ alpha\n        else:\n            y_curl = np.zeros(m)\n        \n        y_harm = y - y_grad - y_curl\n\n        # Energy fractions\n        norm_y_sq = np.linalg.norm(y)**2\n        if norm_y_sq == 0:\n            f_grad, f_curl, f_harm = 0.0, 0.0, 0.0\n        else:\n            f_grad = np.linalg.norm(y_grad)**2 / norm_y_sq\n            f_curl = np.linalg.norm(y_curl)**2 / norm_y_sq\n            f_harm = np.linalg.norm(y_harm)**2 / norm_y_sq\n\n        # Correlation r_grad\n        r_grad = _pearson_corr(phi, p)\n\n        # Correlation r_curl\n        c = np.zeros(n)\n        adj_edge_indices = {i: [] for i in range(n)}\n        for edge_idx, edge in enumerate(edges):\n            u, v = edge\n            adj_edge_indices[u].append(edge_idx)\n            adj_edge_indices[v].append(edge_idx)\n\n        for i in range(n):\n            indices = adj_edge_indices[i]\n            if len(indices) > 0:\n                y_curl_incident_sq = y_curl[indices]**2\n                c[i] = np.sqrt(np.mean(y_curl_incident_sq))\n        \n        r_curl = _pearson_corr(c, s)\n\n        return [round(val, 4) for val in [f_grad, f_curl, f_harm, r_grad, r_curl]]\n\n    test_cases = [\n        {\n            \"n\": 6, \"edges\": [(0,1), (1,2), (0,2), (2,3), (3,4), (4,5)],\n            \"phi_gen\": [0.00, 0.20, 0.40, 0.60, 0.80, 1.00],\n            \"alpha_gen\": {(0,1,2): 1.00}, \"gamma\": 0.50,\n            \"p\": [0.00, 0.22, 0.39, 0.62, 0.81, 0.98],\n            \"s\": [1.00, 0.90, 0.80, 0.20, 0.10, 0.05],\n        },\n        {\n            \"n\": 6, \"edges\": [(0,1), (1,2), (0,2), (2,3), (3,4), (4,5)],\n            \"phi_gen\": [0.00, 0.20, 0.40, 0.60, 0.80, 1.00],\n            \"alpha_gen\": {(0,1,2): 0.00},\n            \"p\": [0.00, 0.20, 0.40, 0.60, 0.80, 1.00],\n            \"s\": [0.30, 0.50, 0.40, 0.60, 0.70, 0.20],\n        },\n        {\n            \"n\": 4, \"edges\": [(0,1), (1,2), (2,3), (0,3), (0,2)],\n            \"phi_gen\": [0.00, 0.00, 0.00, 0.00],\n            \"alpha_gen\": {(0,1,2): 1.00, (0,2,3): 0.20},\n            \"p\": [0.10, 0.40, 0.20, 0.30],\n            \"s\": [1.00, 0.95, 0.90, 0.60],\n        },\n        {\n            \"n\": 4, \"edges\": [(0,1), (1,2), (2,3), (0,3)],\n            \"p\": [0.00, 0.30, 0.60, 0.90],\n            \"s\": [0.20, 0.20, 0.20, 0.20],\n            \"y_direct\": {(0,1): 1.00, (1,2): 1.00, (2,3): 1.00, (0,3): -1.00},\n        }\n    ]\n\n    all_results = [process_case(case) for case in test_cases]\n    \n    # Format output as a string representation of a list of lists.\n    result_str = \"[\" + \", \".join([str(res) for res in all_results]) + \"]\"\n    print(result_str)\n\nsolve()\n```"
        }
    ]
}