## 引言
在[单细胞测序](@entry_id:198847)技术揭示的前所未有的[细胞异质性](@entry_id:262569)图景中，如何从海量、高维的数据中准确识别出不同的细胞类型，是[计算系统生物学](@entry_id:747636)面临的核心挑战。传统的[聚类方法](@entry_id:747401)在处理单细胞数据的[稀疏性](@entry_id:136793)和技术噪声时往往力不从心。[基于图的聚类](@entry_id:174462)方法应运而生，它通过将细胞关系抽象为一个网络，巧妙地将细胞分型问题转化为一个寻找网络社群的[图论](@entry_id:140799)问题，成为当前[单细胞分析](@entry_id:274805)领域的基石技术之一。

本文旨在系统性地剖析[基于图的聚类](@entry_id:174462)与细胞类型鉴定的完整流程，填补从理论原理到应用实践之间的知识鸿沟。通过学习，您将不仅理解算法的数学基础，更能掌握其在真实生物学问题中的灵活应用。

- 在**第一章：原理与机制**中，我们将深入探讨从原始基因计数矩阵到构建高质量细胞相似性图的每一步，并剖析谱聚类与[模块度优化](@entry_id:752101)等核心社群检测算法的内部工作原理。
- 在**第二章：应用与[交叉](@entry_id:147634)学科联系**中，我们将视野扩展到下游分析，学习如何对聚类结果进行生物学诠释、质量验证，并探索其在[轨迹推断](@entry_id:176370)、多模态整合等前沿领域的应用。
- 在**第三章：动手实践**中，您将通过具体计算问题，亲手实践SNN权重计算和模块度分析等关键步骤，巩固理论知识。

现在，让我们从构建有意义的细胞表示开始，踏上这段从数据到洞见的探索之旅。

## 原理与机制

在单细胞[测序数据分析](@entry_id:162667)中，[基于图的聚类](@entry_id:174462)是一种强大的无监督方法，用于识别和注释细胞类型。该方法将复杂的、高维度的基因表达数据转化为一个网络结构，其中节点代表单个细胞，边代表它们之间的相似性。通过分析这个网络的社[群结构](@entry_id:146855)，我们可以将细胞划分为不同的群体，这些群体对应于不同的生物学状态或类型。本章将深入探讨构建和分析这些细胞相似性图的核心原理和机制，涵盖从原始数据处理到最终社群识别的整个流程。

### 从原始计数到有意义的表示

原始的[单细胞RNA测序](@entry_id:142269)（[scRNA-seq](@entry_id:155798)）数据通常以一个计数矩阵 $X \in \mathbb{N}^{n \times p}$ 的形式存在，其中 $n$ 是细胞数量，$p$ 是基因数量，$x_{ig}$ 表示细胞 $i$ 中基因 $g$ 的独特分子标识（UMI）计数。直接在这个原始计数矩阵上计算细胞间的距离是不可行的，因为数据中存在着固有的技术偏差和统计特性，它们会掩盖真实的生物学信号。

#### 原始scRNA-seq数据的挑战

首先，**[测序深度](@entry_id:178191)**或**文库大小**（$n_i = \sum_{g=1}^{p} x_{ig}$）在不同细胞间差异很大。文库大小较大的细胞，其基因计数值会系统性地偏高，导致其在基因表达空间中的欧几里得范数也更大。这种纯粹由技术因素引起的变化，会主导距离计算，使得[测序深度](@entry_id:178191)相近的细胞聚在一起，而非生物学功能相似的细胞。

其次，scRNA-seq数据是计数数据，其固有特性是**[异方差性](@entry_id:136378)**（heteroskedasticity），即[方差](@entry_id:200758)随均值的增加而增加。对于泊松或[负二项分布](@entry_id:262151)等常见模型，高表达基因的表达值在细胞间不仅均值高，其变异也更大。在计算[欧几里得距离](@entry_id:143990)时，这些高表达、高[方差](@entry_id:200758)基因的绝对差异会不成比例地主导[距离度量](@entry_id:636073)，从而掩盖了来自低表达但功能关键的基因（如[转录因子](@entry_id:137860)）的生物学信号。

#### 标准化与变换

为了解决这些问题，必须对原始计数矩阵进行一系列的[预处理](@entry_id:141204)步骤，将其转换到一个新的几何空间，使得细胞间的距离能更准确地反映生物学上的相似性。

**文库大小标准化**
这是最基本也是最关键的一步。该步骤通过将每个细胞的基因计数除以其总文库大小，再乘以一个统一的[比例因子](@entry_id:266678)（如 $10,000$），来校正[测序深度](@entry_id:178191)的差异。几何上，这个过程将每个细胞的表达向量 $x_i$ 通过一个正标量进行缩放。例如，使用比例因子 $s$ 进行[标准化](@entry_id:637219)，相当于将每个细胞向量 $x_i = (x_{i1}, \dots, x_{ip})$ 乘以 $s/n_i$。经过此操作后，所有细胞向量的 $\ell_1$ 范数变为一个常数 $s$ (即 $\sum_g x'_{ig} = s$)，意味着它们被投影到了一个高维的仿射超平面上。这个变换消除了由[测序深度](@entry_id:178191)差异引起的径向分离，即细胞不再仅仅因为总UMI数多而离原点更远。值得注意的是，由于余弦相似度仅依赖于向量的方向而非其范数，文库大小标准化不会改变任意两个细胞向量之间的余弦相似度 。

**[对数变换](@entry_id:267035)**
在生物学上，我们更关心基因表达的相对差异（[倍数变化](@entry_id:272598)，fold-change）而非绝对差异。对数函数具有将乘法关系近似转换为加法关系的特性。因此，在文库大小[标准化](@entry_id:637219)之后，通常会应用一个[对数变换](@entry_id:267035)，例如 $y_{ig} = \log(1 + \text{scaled_count})$。这里的“+1”是一个伪计数，用于处理零值并稳定低计数值的变换。经过[对数变换](@entry_id:267035)后，计算两个细胞 $i$ 和 $j$ 之间的欧几里得距离的平方 $\|y_i - y_j\|_2^2 = \sum_g (y_{ig} - y_{jg})^2$，其每一项 $(y_{ig} - y_{jg})$ 都近似于基因 $g$ 表达水平的[对数倍数变化](@entry_id:272578)。这样，欧几里得距离就汇总了所有基因的平方[对数倍数变化](@entry_id:272578)，从而使得一个从1到2的计数变化与一个从50到100的计数变化在几何上具有同等的重要性，优先考虑了相对表达差异 。

**[方差](@entry_id:200758)稳定化变换（VST）**
虽然[对数变换](@entry_id:267035)在一定程度上缓解了[异方差性](@entry_id:136378)，但更高级的方法旨在直接解决这个问题。[方差](@entry_id:200758)稳定化变换的目标是找到一个函数 $f$，使得变换后的数据 $f(X)$ 的[方差近似](@entry_id:268585)独立于其均值。例如，基于泊松或负[二项模型](@entry_id:275034)的皮尔逊残差（Pearson residuals）就是一种VST。皮尔逊残差定义为 $r_{ig} = (x_{ig} - \mu_{ig}) / \sqrt{V(\mu_{ig})}$，其中 $\mu_{ig}$ 和 $V(\mu_{ig})$ 分别是基于模型估计的基因表达的均值和[方差](@entry_id:200758)。通过构造，这些残差的理论[方差近似](@entry_id:268585)为1。这极大地降低了数据中的[异方差性](@entry_id:136378)，使得每个基因在计算[欧几里得距离](@entry_id:143990)时贡献更加均衡。经过这样的变换后，细胞间的相似性不再被少数高表达基因主导，而是更能反映多组基因协同作用的生物学程序，这对于后续构建有意义的细胞图至关重要 。

#### [距离度量](@entry_id:636073)的选择：捕获生物学相似性

[数据表示](@entry_id:636977)准备就绪后，下一步是选择一个合适的距离或相似性度量。这个选择深刻地影响着最终的聚类结果。

**欧几里得距离** ($d_E(u,v) = \|u - v\|_2$) 衡量了向量间的绝对差异。即便在[对数变换](@entry_id:267035)后，它仍然对表达谱的整体幅度（magnitude）敏感。如果两个细胞具有相同的表达模式但整体表达水平（或由于标准化不完美导致的残余尺度效应）不同，它们的[欧几里得距离](@entry_id:143990)可能很大。

**余弦相似度** ($1 - \frac{u \cdot v}{\|u\|_2 \|v\|_2}$) 衡量向量间的夹角，因此它对向量的尺度不敏感。这意味着它关注的是基因表达的相对比例，而非绝对计数值。例如，考虑两个细胞A和B，其表达向量分别为 $x = (300, 1200, 450, 600, 150)$ 和 $y = (30, 110, 42, 61, 14)$。尽管它们的文库大小相差悬殊（$2700$ vs $257$），但它们的余弦相似度计算结果约为 $0.9991$，非常接近1 。这表明它们的表达谱在方向上高度一致，即基因表达的相对比例非常相似。这种对尺度的不变性使得余弦相似度成为校正[测序深度](@entry_id:178191)差异的有效补充。

**[皮尔逊相关](@entry_id:260880)距离** ($1 - r(u,v)$) 是一个更为强大的度量。[皮尔逊相关系数](@entry_id:270276)在数学上等价于对两个向量进行均值中心化后的余弦相似度。这意味着它同时对**尺度**和**平移**（shift）不敏感。如果一个细胞的表达谱可以由另一个细胞的表达谱通过[线性变换](@entry_id:149133) $au+b$（其中 $a > 0$）得到，那么它们的[皮尔逊相关系数](@entry_id:270276)为1。这种不变性在生物学上极为重要，因为它允许我们匹配表达“模式”或“形状”，而忽略整体表达水平的基线差异和幅度差异。在许多分析流程中，对经过基因中心化的对数[标准化](@entry_id:637219)数据使用[皮尔逊相关](@entry_id:260880)距离，能够有效地分离出定义细胞类型的共表达模式，同时降低由于技术噪声、细胞周期效应或代谢活性差异引起的全局表达变化的干扰 。

#### 用主成分分析（PCA）进行降维

即使经过了标准化和变换，基因表达数据通常也具有非常高的维度（数万个基因）。在这种高维空间中，[距离度量](@entry_id:636073)的表现会下降（所谓的“[维度灾难](@entry_id:143920)”），并且计算成本高昂。此外，大部分维度可能只包含噪声。因此，[降维](@entry_id:142982)是必不可少的一步。

**主成分分析 (PCA)** 是一种广泛使用的线性[降维技术](@entry_id:169164)，它将数据投影到一个保留最大[方差](@entry_id:200758)的低维[子空间](@entry_id:150286)上。其背后的数学原理是，PCA寻找的低秩近似矩阵是所有相同秩的矩阵中，最小化弗罗贝尼乌斯（Frobenius）重构误差的那一个。根据**[Eckart-Young-Mirsky定理](@entry_id:149772)**，对于一个数据矩阵 $X$ (此处指预处理后的矩阵)，其最佳 $r$ 秩近似 $X_r$ 是由其[奇异值分解](@entry_id:138057)（SVD）$X = U S V^{\top}$ 的前 $r$ 个奇异值和对应的奇异向量给出的：$X_r = U_r S_r V_r^{\top}$。最小化的重构误差平方为 $\sum_{i=r+1}^{m} \sigma_{i}^{2}$，其中 $\sigma_i$ 是[奇异值](@entry_id:152907)， $m$ 是 $X$ 的秩 。

在[单细胞分析](@entry_id:274805)的语境中，PCA之所以有效，是基于一个核心假设：区分细胞类型的主要生物学变异存在于数据[方差](@entry_id:200758)最大的方向上，而[方差](@entry_id:200758)较小的方向主要由技术噪声或次要的生物学波动构成。通过保留前 $r$ 个主成分（通常为10-50个），我们将数据投影到一个“信号丰富”的[子空间](@entry_id:150286)。这个过程通过滤除噪声维度来增强[信噪比](@entry_id:185071)，从而使得在[降维](@entry_id:142982)空间中计算的欧几里得距离更能反映细胞间的真实生物学关系，为构建一个鲁棒的近邻图奠定了基础 。

### 构建细胞-细胞相似性图

在获得了细胞在低维空间的表示后，下一步是构建一个图 $G=(V, E)$，其中节点 $V$ 是细胞，边 $E$ 连接相似的细胞。图的拓扑结构和边的权重方案对最终的聚类结果有决定性影响。

#### 定义邻域：图的拓扑结构

多种方法可用于定义细胞间的连接关系，每种方法都有其独特的属性和适用场景。

**$\epsilon$-邻域图**
最简单的方法是连接距离小于某个全局阈值 $\epsilon$ 的所有细胞对。然而，这种方法对细胞密度的异质性非常敏感。对于一个全局固定的 $\epsilon$，它会在高密度区域（如一个紧凑的细胞簇）产生过多的连接，形成所谓的“毛球”，而在稀疏区域则可能导致节点孤立，使图变得支离破碎 。

**$k$-最近邻（kNN）图**
[kNN图](@entry_id:751051)通过为每个[细胞连接](@entry_id:146782)其最近的 $k$ 个邻居来克服全局阈值的问题。这是一种自适应的方法，因为它根据局部密度调整邻域的“尺度”：在密集区域，邻域范围小；在稀疏区域，邻域范围大。这使得[kNN图](@entry_id:751051)对全局缩放不敏感，因为它们依赖于距离的排序而非[绝对值](@entry_id:147688)。然而，[kNN图](@entry_id:751051)也存在问题。它天生是有向的（“A是B的邻居”不意味着“B是A的邻居”），并且在密度差异巨大的区域之间，稀疏区域的节点可能会“被迫”连接到邻近的密集区域，从而在不同细胞类型之间形成伪边 。

**共同$k$-最近邻（Mutual kNN）和共享最近邻（SNN）图**
为了提高[kNN图](@entry_id:751051)的鲁棒性，发展出了多种变体。**共同[kNN图](@entry_id:751051)**要求两个细胞必须相互成为对方的 $k$ 个最近邻之一，才会建立一条无向边。这种对称性要求非常严格，能有效剪除连接不同密度簇的伪边，因为密集簇中的节点其 $k$ 个邻居很可能全在簇内，不会将外部稀疏节点包含进来 。

**共享最近邻（SNN）图**则采用了更为精妙的思路。它不直接使用距离，而是通过比较两个细胞的邻居列表的重合度来重新定义它们的相似性。两个细胞 $i$ 和 $j$ 之间的SNN相似性 $w_{ij}$ 定义为它们各自的kNN邻居集合的交集大小：$w_{ij} = |N_k(i) \cap N_k(j)|$。只有当两个细胞共享了足够多的邻居时（即 $w_{ij}$ 超过某个阈值），它们之间才会形成一条边。这个方法非常强大，因为它利用了邻域的局部结构信息。如果两个细胞因技术伪影（如[批次效应](@entry_id:265859)）而被错误地拉近，它们的邻居集合通常仍会分属各自真实的生物学群体，因此共享的邻居会很少。SNN方法因此能有效地滤除噪声，保留[流形](@entry_id:153038)内部的连接，增强真实生物簇的信号 。

#### 高级边权重方案：自适应核函数

除了决定边的存在与否，我们还可以为边赋予权重，以表示相似性的强度。高斯核函数是一种常见的选择，它将距离平滑地转换为相似性权重：$w_{ij}=\exp(-\|x_i-x_j\|^2/\sigma^2)$。这里的带宽参数 $\sigma$ 控制了距离的衰减速度。

与 $\epsilon$-邻域图类似，使用一个**全局带宽** $\sigma$ 在细胞密度异质的数据中会遇到问题。一个合适的 $\sigma$ 对于稀疏区域可能太小，而对于密集区域又可能太大。解决方案是使用**局部自适应带宽**。一种有效的方法是令每个点 $x_i$ 的带宽 $\sigma_i$ 等于它到其第 $k$ 个最近邻的距离。这个 $\sigma_i$ 可以作为局部密度的估计，因为在密集区域 $\sigma_i$ 会很小，而在稀疏区域会很大。

为了构建一个对称的权重矩阵，可以结合两个点的局部带宽。一个特别有效且有理论支持的构造方式是：
$w_{ij}=\exp(-\|x_i-x_j\|^2/(\sigma_i \sigma_j))$
这种构造方式的精妙之处在于，它能近似地使图中每个节点的期望加权度（expected weighted degree）保持恒定，从而平衡不同密度区域的连通性。其原理如下：一个节点 $x_i$ 的期望加权度约等于其局部密度 $\rho_i$ 乘以其周围相似性函数的积分。该积分的尺度由[有效带宽](@entry_id:748805)决定，对于上述权重公式，在 $x_i$ 附近的[有效带宽](@entry_id:748805)是 $\sigma_i$。因此，期望加权度 $\mathbb{E}[d_i] \propto \rho_i \sigma_i^d$（在 $d$ 维空间中）。又因为局部密度与 $k$-NN距离的关系为 $\sigma_i \propto \rho_i^{-1/d}$，代入后可得 $\mathbb{E}[d_i] \propto \rho_i (\rho_i^{-1/d})^d = \rho_i \rho_i^{-1} = 1$。这意味着，无论一个细胞处于高密度还是低密度区域，通过这种[自适应加权](@entry_id:638030)，它的总连接强度在期望上是恒定的。这完美地解决了[异方差性](@entry_id:136378)问题，确保了图的结构能公平地反映所有细胞状态 。

### 划分图以识别细胞类型

构建了细胞相似性图之后，识别细胞类型的任务就转化为一个图论问题：将[图划分](@entry_id:152532)为若干个社群（communities），其中社群内部的连接远比社群之间的连接要密集。目前主要有两大类方法：谱聚类和[模块度最大化](@entry_id:752100)。

#### 谱聚类：基于图谱的划分

谱聚类是一类利用图的拉普拉斯矩阵的谱（即[特征值](@entry_id:154894)和[特征向量](@entry_id:151813)）进行聚类的方法。其核心思想是将离散的[图划分](@entry_id:152532)问题松弛为连续的[特征向量计算](@entry_id:170884)问题。

首先定义图的**[拉普拉斯矩阵](@entry_id:152110)**。对于一个邻接矩阵为 $A$、度矩阵为 $D$ 的图，组合拉普拉斯矩阵定义为 $L = D - A$。对于任意向量 $f \in \mathbb{R}^n$，二次型 $f^T L f = \frac{1}{2} \sum_{i,j=1}^n A_{ij}(f_i - f_j)^2$ 衡量了向量 $f$ 在图上的平滑度。这个二次型与图的**切分（cut）**密切相关。

一个理想的[图划分](@entry_id:152532)应该使不同簇之间的切边数量（或权重和）尽可能小，同时避免产生过小的簇。这引出了两个经典的[目标函数](@entry_id:267263)：
1.  **Ratio Cut**: $\mathrm{RCut}(S,\bar{S}) = \mathrm{cut}(S,\bar{S}) ( \frac{1}{|S|} + \frac{1}{|\bar{S}|} )$，惩罚大小不均衡的划分。
2.  **Normalized Cut (Ncut)**: $\mathrm{Ncut}(S,\bar{S}) = \mathrm{cut}(S,\bar{S}) ( \frac{1}{\mathrm{vol}(S)} + \frac{1}{\mathrm{vol}(\bar{S})} )$，其中 $\mathrm{vol}(S)$ 是簇 $S$ 中所有节点的度之和。它惩罚了度不均衡的划分。

直接最小化这两个目标是[NP难问题](@entry_id:146946)。谱[聚类](@entry_id:266727)的关键在于**谱松弛**（spectral relaxation）。可以证明，最小化Ratio Cut近似等价于求解组合[拉普拉斯矩阵](@entry_id:152110) $L$ 的第二小[特征值](@entry_id:154894)对应的[特征向量](@entry_id:151813)（称为**[Fiedler向量](@entry_id:148200)**）。类似地，最小化Normalized Cut近似等价于求解对称归一化[拉普拉斯矩阵](@entry_id:152110) $L_{\mathrm{sym}} = I - D^{-1/2} A D^{-1/2}$ 的第二小[特征向量](@entry_id:151813) 。

通过计算这些[特征向量](@entry_id:151813)（例如，对于 $k$ 个簇，计算前 $k$ 个[特征向量](@entry_id:151813)），每个细胞（节点）就获得了一个新的低维表示（谱嵌入）。然后，在这个低维的谱空间中应用简单的[聚类算法](@entry_id:146720)（如k-means），即可得到最终的细胞分群。重要的是，谱聚类提供的是一个近似解，而非[全局最优解](@entry_id:175747) 。

#### [模块度最大化](@entry_id:752100)：寻找密集的社群

另一大类流行的方法是基于**模块度（modularity）**的优化。模块度是一个衡量[图划分](@entry_id:152532)质量的指标，它度量了社群内部边的数量与在一个保持节点[度序列](@entry_id:267850)不变的[随机图](@entry_id:270323)（即**配置模型**）中期望的内部边数量之差。一个高质量的划分应该有远多于随机期望的内部边。

对于一个给定的划分，模块度 $Q$ 的[标准形式](@entry_id:153058)为：
$$Q = \frac{1}{2m} \sum_{i,j} \left( A_{ij} - \frac{k_i k_j}{2m} \right) \delta(c_i, c_j)$$
其中 $m$ 是图的总边权重， $k_i$ 是节点 $i$ 的度， $c_i$ 是节点 $i$ 所属的社群，$A_{ij}$ 是邻接矩阵，$\delta$ 是克罗内克函数 。

由于在所有可能的划分中找到使 $Q$ 最大的划分是[NP难](@entry_id:264825)的，因此实际中采用[贪心启发式算法](@entry_id:167880)，如**[Louvain算法](@entry_id:270022)**和**[Leiden算法](@entry_id:751237)**。

**Louvain和[Leiden算法](@entry_id:751237)**
这两个算法都采用迭代的方式，每轮包含两个阶段：
1.  **局部移动阶段**：遍历所有节点，将每个节点尝试性地移动到其邻居所在的社群中，并计算模块度的增益。节点被最终移动到能使其模块度增益最大的社群中。此过程反复进行，直到没有单个节点的移动能再增加模块度。
2.  **聚合阶段**：将第一阶段形成的每个社群“压缩”成一个超级节点，构建一个权重为社群间总连接权重的新图。然后，在新图上重复第一阶段。

[Louvain算法](@entry_id:270022)虽然快速高效，但有一个严重的缺陷：它可能产生内部不连通的“破碎”社群。**[Leiden算法](@entry_id:751237)**通过在局部移动和聚合之间插入一个**精化阶段**（refinement phase）来解决此问题。在精化阶段，算法会检查每个社群的内部连通性，并尝试将其细分为更小的、保证连通的子社群。只有这些经过精炼且保证连通的子社群才会被聚合到下一轮。这个关键的改进使得[Leiden算法](@entry_id:751237)能够产出更稳定、更有意义的社群结构 。

**模块度的分辨率限制**
[模块度优化](@entry_id:752101)有一个固有的局限性，称为**分辨率限制**（resolution limit）。即它可能无法分辨出那些虽然结构清晰、但在整个大图中尺寸相对较小的社群。其根源在于模块度的定义本身。当两个社群 $r$ 和 $s$ 被合并时，模块度的变化量 $\Delta Q$ 正比于 $L_{rs} - \frac{\gamma K_r K_s}{2m}$，其中 $L_{rs}$ 是它们之间的连接边数，$K_r, K_s$ 是它们的总度数，$\gamma$ 是分辨[率参数](@entry_id:265473) 。合并与否取决于观察到的连接数 $L_{rs}$ 是否大于期望的连接数 $\frac{\gamma K_r K_s}{2m}$。

对于两个总度数均为 $K$ 的小社群，即使它们之间只有一条连接边（$L_{rs}=1$），当图的总边数 $m$ 变得非常大时，合并的条件 $1 > \frac{\gamma K^2}{2m}$ 也很容易满足。这导致算法倾向于将小而独立的社群合并到大社群中。为了克服这个问题，引入了**多分辨率模块度**，通过调整分辨率参数 $\gamma$ 来控制检测的尺度。增大 $\gamma$ 会增加对社群存在的惩罚，从而倾向于产生更小、更细粒度的社群 。通过系统性地选择 $\gamma$（例如，设置 $\gamma = 2/c^2$），可以确保算法能够稳定地解析出总度数规模约为 $K=c\sqrt{m}$ 的社群，从而在一定程度上缓解了分辨率限制问题 。

综上所述，从原始基因计数到最终的细胞类型鉴定，每一步都涉及关键的原理和权衡。理解数据变换的几何意义、图构建策略的优劣以及社群检测算法的内在机制，对于从单细胞数据中准确地提取生物学洞见至关重要。