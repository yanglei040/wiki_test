{
    "hands_on_practices": [
        {
            "introduction": "在基于图的聚类分析中，构建细胞相似性图是第一步。虽然一个简单的$k$-最近邻（kNN）图可以捕捉局部邻近关系，但其连接可能包含噪声。共享最近邻（SNN）方法通过根据邻域集合的重叠度为边加权，从而改进了这一点，这加强了密集区域内细胞间的连接。本练习将通过计算基于Jaccard相似度的SNN边权重，帮助您巩固对这一核心概念的理解。",
            "id": "3318020",
            "problem": "在用于细胞类型识别的单细胞核糖核酸测序（scRNA-seq）分析中，细胞被嵌入到一个潜在空间中，并通过一个 $k$-最近邻（kNN）图连接起来。一种广泛使用的策略是根据邻域集的重叠来分配边权重，这通常被称为共享最近邻（SNN）图。仅使用两个有限集之间 Jaccard 相似度的集合论定义以及 $k$-最近邻图的核心定义，推导 SNN 边权重 $w_{ij}$ 关于 kNN 图中细胞 $i$ 和 $j$ 的邻域 $N_{k}(i)$ 和 $N_{k}(j)$ 的显式表达式。然后，针对一个具体例子计算该权重。\n\n假设一个数据集包含 $8$ 个标记为 $\\{1,2,3,4,5,6,7,8\\}$ 的细胞，以及一个 $k=5$ 的 kNN 图，其中邻域不包括细胞本身。考虑细胞 $i=1$ 和 $j=2$，其邻域为\n$$\nN_{k}(1)=\\{2,3,4,5,7\\},\\quad N_{k}(2)=\\{1,3,4,6,7\\}.\n$$\n仅使用 Jaccard 相似度的集合论定义和上述信息，首先推导 $w_{ij}$ 的封闭形式表达式，然后计算其在指定的 $N_{k}(1)$ 和 $N_{k}(2)$ 下的值。将最终数值表示为最简分数。",
            "solution": "问题陈述被评估为有效。它在科学上基于计算系统生物学的既定方法，特别是使用共享最近邻（SNN）图对单细胞数据进行聚类。该问题设定良好，为得到唯一解提供了所有必要的定义和数据。语言客观，设置自洽且一致。\n\n任务是首先推导共享最近邻（SNN）边权重 $w_{ij}$ 的通用表达式，然后为一对特定的细胞计算其值。问题明确指出，边权重由邻域集的 Jaccard 相似度定义。\n\n首先，让我们形式化推导过程。两个有限非空集合 $A$ 和 $B$ 之间的 Jaccard 相似性指数 $J(A, B)$ 定义为它们交集的基数与并集的基数之比：\n$$\nJ(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}\n$$\n问题指定，SNN 图中两个细胞 $i$ 和 $j$ 之间的边权重 $w_{ij}$ 由它们各自的 $k$-最近邻集 $N_{k}(i)$ 和 $N_{k}(j)$ 的 Jaccard 相似度给出。因此，我们将 $A = N_{k}(i)$ 和 $B = N_{k}(j)$ 代入 Jaccard 指数公式：\n$$\nw_{ij} = J(N_{k}(i), N_{k}(j)) = \\frac{|N_{k}(i) \\cap N_{k}(j)|}{|N_{k}(i) \\cup N_{k}(j)|}\n$$\n这就是以邻域集表示的 SNN 边权重的显式表达式。使用集合基数的容斥原理，分母可以重新表示为 $|A \\cup B| = |A| + |B| - |A \\cap B|$。应用此原理，我们得到该表达式的另一种同样有效的形式：\n$$\nw_{ij} = \\frac{|N_{k}(i) \\cap N_{k}(j)|}{|N_{k}(i)| + |N_{k}(j)| - |N_{k}(i) \\cap N_{k}(j)|}\n$$\n这完成了任务的第一部分。\n\n接下来，我们为给定的具体例子计算这个权重。参数和数据如下：\n- 关注的细胞是 $i=1$ 和 $j=2$。\n- 最近邻的数量是 $k=5$。\n- 细胞 $1$ 的邻域是 $N_{k}(1) = \\{2, 3, 4, 5, 7\\}$。\n- 细胞 $2$ 的邻域是 $N_{k}(2) = \\{1, 3, 4, 6, 7\\}$。\n\n我们必须计算这两个集合的交集和并集的基数。\n\n首先，我们求这两个邻域集的交集：\n$$\nN_{k}(1) \\cap N_{k}(2) = \\{2, 3, 4, 5, 7\\} \\cap \\{1, 3, 4, 6, 7\\}\n$$\n两个集合共有的元素是 $3$、$4$ 和 $7$。因此，\n$$\nN_{k}(1) \\cap N_{k}(2) = \\{3, 4, 7\\}\n$$\n交集的基数是该集合中元素的数量：\n$$\n|N_{k}(1) \\cap N_{k}(2)| = 3\n$$\n这个值表示细胞 $1$ 和细胞 $2$ 之间共享的最近邻的数量。\n\n接下来，我们求这两个邻域集的并集：\n$$\nN_{k}(1) \\cup N_{k}(2) = \\{2, 3, 4, 5, 7\\} \\cup \\{1, 3, 4, 6, 7\\}\n$$\n并集是存在于任一集合中的所有唯一元素的集合：\n$$\nN_{k}(1) \\cup N_{k}(2) = \\{1, 2, 3, 4, 5, 6, 7\\}\n$$\n并集的基数是该集合中元素的数量：\n$$\n|N_{k}(1) \\cup N_{k}(2)| = 7\n$$\n作为验证，我们可以使用容斥原理。单个邻域集的基数是 $|N_{k}(1)| = 5$ 和 $|N_{k}(2)| = 5$，这与 $k=5$ 一致。\n$$\n|N_{k}(1) \\cup N_{k}(2)| = |N_{k}(1)| + |N_{k}(2)| - |N_{k}(1) \\cap N_{k}(2)| = 5 + 5 - 3 = 7\n$$\n结果是一致的。\n\n最后，我们将计算出的基数代入 Jaccard 相似度公式，计算边权重 $w_{12}$：\n$$\nw_{12} = \\frac{|N_{k}(1) \\cap N_{k}(2)|}{|N_{k}(1) \\cup N_{k}(2)|} = \\frac{3}{7}\n$$\n问题要求最终值以最简分数形式表示。分数 $\\frac{3}{7}$ 已经是其最简形式，因为 $3$ 和 $7$ 都是质数。",
            "answer": "$$\\boxed{\\frac{3}{7}}$$"
        },
        {
            "introduction": "一旦将图划分成不同的社区（即假定的细胞类型），我们如何客观地衡量划分的质量？模块度（$Q$）通过将社区内部的连接密度与随机网络中的期望值进行比较，为此提供了一个强有力的答案。本练习将指导您计算一个假设划分的模块度增益（$\\Delta Q$），让您能够量化地评估分离一个稀有细胞群是否构成一个有意义的划分。",
            "id": "3317980",
            "problem": "一项单细胞核糖核酸测序（scRNA-seq）实验生成了一个细胞-细胞相似性图。该图通过$k$-最近邻（$k$-NN）算法构建，然后对称化为一个无向、无权重的图。您怀疑存在一个罕见的细胞状态，它形成了一个小的、密集的子图，并与一个更大、更异构的社群相连。请考虑以下从经过质量控制的数据中得出的、与此情景一致的图级别摘要：\n\n- 该图是无向图，共有 $m = 100$ 条边。\n- 一个候选的罕见子图 $S$ 包含 $l_{S} = 30$ 条内部边。\n- 大社群 $L$ 包含 $l_{L} = 60$ 条内部边。\n- 有 $e_{SL} = 10$ 条边连接子图 $S$ 中的节点和社群 $L$ 中的节点。\n\n假设使用 Newman–Girvan 模块度，并采用针对无向图的配置模型作为零模型。计算将图划分为两个社群 $\\{S, L\\}$ 相对于将所有节点视为单个社群时的模块度增益 $\\Delta Q$。根据 $\\Delta Q$ 的符号，简要判断在模块度最大化的情况下，罕见子图 $S$ 是否构成其自身的簇。将 $\\Delta Q$ 的最终答案表示为一个精确分数，不进行四舍五入，也不带单位。",
            "solution": "首先对问题陈述进行严格的验证过程。\n\n### 第 1 步：提取已知条件\n- 该图是无向、无权重的。\n- 总边数：$m = 100$。\n- 图被划分为两个社群：一个候选的罕见子图 $S$ 和一个大社群 $L$。\n- 社群 $S$ 的内部边数：$l_{S} = 30$。\n- 社群 $L$ 的内部边数：$l_{L} = 60$。\n- 连接社群 $S$ 和社群 $L$ 的边数：$e_{SL} = 10$。\n- 零模型是针对无向图的配置模型。\n- 任务是计算划分 $\\{S, L\\}$ 相对于单个社群时的模块度增益 $\\Delta Q$。\n\n### 第 2 步：使用提取的已知条件进行验证\n- **科学依据**：该问题在计算系统生物学和网络科学领域有充分的依据。由 Newman 和 Girvan 定义的模块度是社群检测的标准度量，而配置模型是标准的零模型。所描述的情景是 scRNA-seq 数据分析中的一个常见问题。\n- **适定性**：该问题是适定的。它为计算指定划分的模块度提供了所有必要信息。问题是明确的。\n- **一致性**：问题的已知条件是内部一致的。总边数 $m$ 必须是每个社群内部边数与连接社群的边数之和。我们可以验证这一点：$l_{S} + l_{L} + e_{SL} = 30 + 60 + 10 = 100$，这与给定的总数 $m=100$ 相符。\n- **客观性**：问题以精确、客观的语言陈述。\n- **结论**：该问题是有效的，因为它科学合理、信息自足、一致且适定。\n\n### 求解推导\n一个已划分的图的模块度 $Q$ 定义为：落入给定社群内部的边所占的比例，减去在一个具有相同度序列的随机图（配置模型）中，该比例的期望值。对于一个划分为社群集合 $\\{c\\}$ 的情况，其公式为：\n$$Q = \\sum_{c} \\left[ \\frac{l_c}{m} - \\left(\\frac{d_c}{2m}\\right)^2 \\right]$$\n其中：\n- $m$ 是图中的总边数。\n- $l_c$ 是完全在社群 $c$ 内部的边数。\n- $d_c$ 是社群 $c$ 中所有节点的度之和。\n\n问题要求计算将图划分为两个社群 $\\{S, L\\}$ 相对于将所有节点视为一个单一社群 $\\{U\\}$ 这一基准的模块度增益 $\\Delta Q$。\n$$\\Delta Q = Q_{\\{S,L\\}} - Q_{\\{U\\}}$$\n首先，我们考虑包含所有节点的单一社群 $U$ 的情况。在这种情况下，所有边都是内部边，因此 $l_U = m$。所有节点的度之和为 $d_U = 2m$。其模块度为：\n$$Q_{\\{U\\}} = \\frac{l_U}{m} - \\left(\\frac{d_U}{2m}\\right)^2 = \\frac{m}{m} - \\left(\\frac{2m}{2m}\\right)^2 = 1 - 1^2 = 0$$\n一个未划分的图的模块度总是 $0$。因此，模块度增益就是所提议划分的模块度：\n$$\\Delta Q = Q_{\\{S,L\\}} - 0 = Q_{\\{S,L\\}}$$\n现在，我们计算 $Q_{\\{S,L\\}}$。该公式展开为：\n$$Q_{\\{S,L\\}} = \\left[ \\frac{l_S}{m} - \\left(\\frac{d_S}{2m}\\right)^2 \\right] + \\left[ \\frac{l_L}{m} - \\left(\\frac{d_L}{2m}\\right)^2 \\right]$$\n我们已知 $m=100$，$l_S=30$ 和 $l_L=60$。我们需要求出 $d_S$ 和 $d_L$。一个社群的节点度之和 $d_c$ 可以通过对其成员节点的度求和来计算。这个和等于内部边数的两倍加上该社群连接到其他社群的边数。\n\n对于社群 $S$：\n内部边数为 $l_S = 30$。外部边数为 $e_{SL} = 10$。\n度之和为 $d_S = 2l_S + e_{SL} = 2(30) + 10 = 60 + 10 = 70$。\n\n对于社群 $L$：\n内部边数为 $l_L = 60$。外部边数也为 $e_{SL} = 10$。\n度之和为 $d_L = 2l_L + e_{SL} = 2(60) + 10 = 120 + 10 = 130$。\n\n作为一致性检查，图中度的总和必须是 $d_S + d_L = 70 + 130 = 200$。这等于 $2m = 2(100) = 200$，所以我们的计算是正确的。\n\n现在，我们将这些值代入模块度公式：\n$$\\Delta Q = Q_{\\{S,L\\}} = \\left[ \\frac{30}{100} - \\left(\\frac{70}{2 \\cdot 100}\\right)^2 \\right] + \\left[ \\frac{60}{100} - \\left(\\frac{130}{2 \\cdot 100}\\right)^2 \\right]$$\n$$\\Delta Q = \\left[ \\frac{3}{10} - \\left(\\frac{70}{200}\\right)^2 \\right] + \\left[ \\frac{6}{10} - \\left(\\frac{130}{200}\\right)^2 \\right]$$\n$$\\Delta Q = \\left[ \\frac{3}{10} - \\left(\\frac{7}{20}\\right)^2 \\right] + \\left[ \\frac{6}{10} - \\left(\\frac{13}{20}\\right)^2 \\right]$$\n$$\\Delta Q = \\left[ \\frac{3}{10} - \\frac{49}{400} \\right] + \\left[ \\frac{6}{10} - \\frac{169}{400} \\right]$$\n合并各项：\n$$\\Delta Q = \\frac{3}{10} + \\frac{6}{10} - \\frac{49}{400} - \\frac{169}{400}$$\n$$\\Delta Q = \\frac{9}{10} - \\frac{49 + 169}{400}$$\n$$\\Delta Q = \\frac{9}{10} - \\frac{218}{400}$$\n为了进行减法，我们找到一个公分母，即 $400$：\n$$\\Delta Q = \\frac{9 \\cdot 40}{10 \\cdot 40} - \\frac{218}{400} = \\frac{360}{400} - \\frac{218}{400}$$\n$$\\Delta Q = \\frac{360 - 218}{400} = \\frac{142}{400}$$\n最后，我们通过将分子和分母除以它们的最大公约数 $2$ 来简化分数：\n$$\\Delta Q = \\frac{71}{200}$$\n问题还要求根据 $\\Delta Q$ 的符号来判断 $S$ 是否构成其自身的簇。由于 $\\Delta Q = \\frac{71}{200} > 0$，划分 $\\{S, L\\}$ 的模块度为正。这意味着社群 $S$ 和 $L$ 内部的边密度高于在配置模型下随机预期的密度。模块度最大化算法旨在寻找具有高正 $Q$ 值的划分。相对于未划分状态，一个正的 $\\Delta Q$ 表明所提议的划分在结构上是一个有意义的改进。因此，基于此度量，子图 $S$ 确实构成了其自身的独立簇。",
            "answer": "$$\\boxed{\\frac{71}{200}}$$"
        },
        {
            "introduction": "在聚类分析中，一个关键的挑战是确定最佳的聚类数量以及图的连接性参数$k$。这个高级实践介绍了一个完整的、数据驱动的工作流程，利用谱图理论来解决这个问题。您将探索如何利用图拉普拉斯算子的特征值，特别是“谱隙”，来选择合适的$k$值，并同时从数据结构中推断出细胞类型的数量。",
            "id": "3317968",
            "problem": "您的任务是设计一个程序，该程序针对模拟单细胞RNA测序（scRNA-seq）嵌入的合成数据集，构建$k$-近邻图，评估对称归一化图拉普拉斯谱，并通过最大化一个明确定义的“第一个非平凡谱隙”来选择一个合适的$k$。目标是分析在包含已知谱系连续体的数据集上，所选的$k$如何在过聚类和欠聚类之间进行权衡。该问题必须通过实现一个完整的、可运行的程序来解决，该程序无需任何用户输入即可生成所需的最终输出。\n\n从以下基本定义和经过充分检验的事实开始：\n\n1. 在$\\mathbb{R}^d$中的$n$个点上的一个$k$-近邻（k-NN）图，通过欧几里得距离将每个点$i$连接到其最近的$k$个点集。为了获得一个无向图，使用对称化并集规则：如果$i$在$j$的$k$个最近邻居之中，或者$j$在$i$的$k$个最近邻居之中，则连接$i$和$j$。\n\n2. 设$W \\in \\mathbb{R}^{n \\times n}$是k-NN图的一个对称、非负的加权邻接矩阵，设$D \\in \\mathbb{R}^{n \\times n}$是对角度矩阵，其对角元素为$D_{ii} = \\sum_{j=1}^n W_{ij}$。对称归一化拉普拉斯算子定义为\n$$\nL_{\\mathrm{sym}} = I - D^{-\\frac{1}{2}} W D^{-\\frac{1}{2}}。\n$$\n已知$L_{\\mathrm{sym}}$是一个对称半正定矩阵，其特征值为$0 = \\lambda_1 \\le \\lambda_2 \\le \\cdots \\le \\lambda_n \\le 2$。特征值$\\lambda = 0$的重数等于图的连通分量数。谱聚类利用有序谱$\\{\\lambda_i\\}$中的谱隙，通过划分的稳定性来推断簇的数量。\n\n3. 对于给定的$k$，设$\\lambda_1 \\le \\lambda_2 \\le \\cdots \\le \\lambda_n$是$L_{\\mathrm{sym}}$的有序特征值。为该$k$定义“第一个非平凡谱隙”如下。固定\n$$\nr_{\\max} = \\min(10, n - 2).\n$$\n对于$i \\in \\{1,2,\\dots,r_{\\max}\\}$，定义谱隙$g_i = \\lambda_{i+1} - \\lambda_i$。确定\n$$\ni^\\star(k) = \\arg\\min\\{ i \\in \\{1,\\dots,r_{\\max}\\} \\,:\\, g_i = \\max_{1 \\le j \\le r_{\\max}} g_j \\},\n$$\n即达到最大谱隙的最小索引。在此$k$下预测的簇数定义为$c(k) = i^\\star(k)$。定义“谱隙大小”为$G(k) = g_{i^\\star(k)}$。\n\n4. 选择\n$$\nk^\\star = \\arg\\min\\{ k \\in \\mathcal{K} \\,:\\, G(k) = \\max_{k' \\in \\mathcal{K}} G(k') \\},\n$$\n其中$\\mathcal{K}$是一个指定的候选$k$值的有限集合，决胜规则选择达到最大谱隙的最小$k$。最终预测的簇数是$c^\\star = c(k^\\star)$。\n\n5. 使用每个数据集的真实离散簇数来评估过聚类和欠聚类。设$c_{\\mathrm{true}}$为真实簇数（对于纯谱系连续体情景，设$c_{\\mathrm{true}} = 1$）。定义布尔指标：\n- 过聚类：$c^\\star > c_{\\mathrm{true}}$。\n- 欠聚类：$c^\\star  c_{\\mathrm{true}}$。\n\n图的构建与权重。在$\\mathbb{R}^2$中使用欧几里得距离。对于每个$k$，构建无向对称k-NN图，并使用高斯核为每条边$(i,j)$加权\n$$\nW_{ij} = \\exp\\!\\left(-\\frac{\\|x_i - x_j\\|^2}{2 \\sigma^2}\\right),\n$$\n其中$\\sigma$是每个点到其$k$个最近邻居的欧几里得距离的中位数，该中位数在所有点上汇总得到。如果任何节点的度为零，则在$L_{\\mathrm{sym}}$中对该节点使用约定$(D^{-\\frac{1}{2}})_{ii} = 0$。\n\n您的程序必须实现上述过程，并将其应用于以下合成数据集测试套件（全部在$\\mathbb{R}^2$中），并使用固定的随机种子以确保确定性。这些数据集旨在模仿多样的scRNA-seq嵌入，包括离散类型和谱系连续体。\n\n数据集A（理想情况：分离良好的离散簇）：\n- 总点数$n = 90$，由3个大小相等（均为30）的各向同性高斯斑点混合生成，标准差为$0.4$，中心分别位于$(-4, 0)$、$(0, 0)$和$(4, 0)$。\n- 真实簇数$c_{\\mathrm{true}} = 3$。\n- 候选集$\\mathcal{K} = \\{3, 5, 7, 9, 11, 13, 15\\}$。\n\n数据集B（连续体：线性谱系）：\n- 总点数$n = 120$，沿带有加性噪声的线段放置：在$[-5, 5]$中均匀取值$t$，并设置$x = (t, \\epsilon)$，其中$\\epsilon$是标准差为$0.1$的独立高斯偏差。\n- 真实簇数$c_{\\mathrm{true}} = 1$。\n- 候选集$\\mathcal{K} = \\{3, 5, 7, 9, 11, 13, 15\\}$。\n\n数据集C（分支连续体：Y形流形）：\n- 总点数$n = 150$，由三条从原点发出、角度分别为$0$、$2\\pi/3$和$4\\pi/3$的带噪声的射线形成。对每条射线，在$[0.3, 5.0]$区间内均匀采样50个等距的半径值，向两个坐标添加标准差为$0.15$的各向同性高斯噪声，然后将三条射线连接起来。\n- 真实簇数$c_{\\mathrm{true}} = 3$。\n- 候选集$\\mathcal{K} = \\{3, 5, 7, 9, 11, 13, 15, 17, 19\\}$。\n\n程序要求：\n- 对所有随机组件使用固定的随机种子$42$。\n- 对于每个数据集，执行如上定义的$k$选择，并计算所选$k^\\star$下的预测簇数$c^\\star$。\n- 对于每个数据集，计算相对于$c_{\\mathrm{true}}$的过聚类和欠聚类的布尔值。\n- 最终输出必须是单行，包含A、B、C三个数据集的结果列表。每个结果是一个形如$[k^\\star, c^\\star, \\text{over}, \\text{under}]$的列表，其中$k^\\star$和$c^\\star$是整数，$\\text{over}$和$\\text{under}$是布尔值。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素都是$[k^\\star, c^\\star, \\text{over}, \\text{under}]$形式的列表。例如，结构必须严格如$[[3,2,False,True],[\\dots],[\\dots]]$，不含任何多余字符或文本。",
            "solution": "所提出的问题是基于图的数据分析领域中一个明确定义的计算任务，专门针对类似于单细胞RNA测序数据分析的聚类问题。它要求基于谱图理论实现一个特定算法，以估计几个合成数据集中的簇数。该过程在科学上是合理的，在数学上是明确的，并且可以通过编程来形式化。\n\n核心原则是利用图拉普拉斯算子的谱，这是一个编码了图的连通性结构的矩阵。接近于零的特征值的数量与数据中连通分量或“簇”的数量有关。通过系统地改变图的连通性（通过改变邻域大小$k$）并观察谱隙的稳定性，可以推断出最优的簇数。\n\n详细的分步过程如下：\n\n首先，对于三个指定的数据集（A、B和C）中的每一个，我们根据所提供的随机模型生成点坐标$X \\in \\mathbb{R}^{n \\times 2}$。固定的随机种子$42$确保了这些数据集的可复现性。每种情况下的真实簇数$c_{\\mathrm{true}}$都是给定的。\n\n主要分析过程遍历一个预定义的候选邻域大小集合$\\mathcal{K}$。对于每个候选$k \\in \\mathcal{K}$，执行以下计算序列：\n\n1.  **k-NN图构建**：计算所有$n$个点的成对欧几里得距离矩阵。对于每个点$x_i$，识别其$k$个最近邻。如果点$x_j$在$x_i$的$k$个最近邻之中，或者$x_i$在$x_j$的$k$个最近邻之中，则创建一条边$(i, j)$，从而形成一个无向图。这定义了图的拓扑结构。\n\n2.  **自适应边加权**：对图中的连接进行加权，以形成一个对称邻接矩阵$W \\in \\mathbb{R}^{n \\times n}$。对于现有边$(i, j)$，其权重$W_{ij}$使用高斯核计算：\n    $$ W_{ij} = \\exp\\left(-\\frac{\\|x_i - x_j\\|^2}{2 \\sigma^2}\\right) $$\n    缩放因子$\\sigma$是为每个$k$自适应地确定的。它被设置为数据集中每个点到其各自$k$个最近邻居的距离集合的中位数。这种局部密度归一化是一种处理不同形状和密度簇的常用技术。对于没有边连接的对$(i, j)$，$W_{ij} = 0$。\n\n3.  **对称归一化拉普拉斯算子**：从加权邻接矩阵$W$计算对角度矩阵$D$，其中$D_{ii} = \\sum_{j=1}^n W_{ij}$。然后构建对称归一化拉普拉斯算子$L_{\\mathrm{sym}}$：\n    $$ L_{\\mathrm{sym}} = I - D^{-\\frac{1}{2}} W D^{-\\frac{1}{2}} $$\n    其中$I$是单位矩阵。一个特殊的约定处理度为零的节点（孤立点）：如果$D_{ii} = 0$，则对应的条目$(D^{-\\frac{1}{2}})_{ii}$也设置为$0$。\n\n4.  **特征值计算与谱隙分析**：计算对称半正定矩阵$L_{\\mathrm{sym}}$的特征值，并按非递减顺序排序：$0 \\le \\lambda_1 \\le \\lambda_2 \\le \\cdots \\le \\lambda_n$。使用“特征间隙启发式方法”来估计簇数。我们分析前几个连续特征值之间的谱隙。谱隙定义为$g_i = \\lambda_{i+1} - \\lambda_i$，其中$i \\in \\{1, 2, \\dots, r_{\\max}\\}$，$r_{\\max} = \\min(10, n - 2)$。识别出对应最大谱隙的索引$i^\\star(k)$：\n    $$ i^\\star(k) = \\arg\\min\\{ i \\in \\{1,\\dots,r_{\\max}\\} \\,:\\, g_i = \\max_{1 \\le j \\le r_{\\max}} g_j \\} $$\n    使用$\\arg\\min$确保如果最大谱隙出现在多个索引处，则选择最小的那个索引。这个索引$i^\\star(k)$是给定$k$下预测的簇数，记为$c(k)$。此最大谱隙的大小记为$G(k) = g_{i^\\star(k)}$。\n\n在对所有$k \\in \\mathcal{K}$完成此过程后，选择最优邻域大小$k^\\star$。它被定义为使谱隙大小$G(k)$最大化的$k$值：\n$$ k^\\star = \\arg\\min\\{ k \\in \\mathcal{K} \\,:\\, G(k) = \\max_{k' \\in \\mathcal{K}} G(k') \\} $$\n此处的决胜规则是选择达到最大谱隙的最小$k$，这倾向于更简单的图模型。数据集的最终预测簇数是$c^\\star = c(k^\\star)$。\n\n最后，将这个预测与真实簇数$c_{\\mathrm{true}}$进行比较。计算两个布尔指标：\n-   过聚类：如果$c^\\star  c_{\\mathrm{true}}$则为真。\n-   欠聚类：如果$c^\\star  c_{\\mathrm{true}}$则为真。\n\n这整个过程独立地应用于三个数据集中的每一个，结果以$[k^\\star, c^\\star, \\text{Over-clustering}, \\text{Under-clustering}]$的格式汇总，用于最终输出。",
            "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis on all datasets and print the final result.\n    \"\"\"\n    np.random.seed(42)\n\n    test_cases_params = [\n        {\n            \"name\": \"A\",\n            \"n\": 90,\n            \"c_true\": 3,\n            \"K_set\": [3, 5, 7, 9, 11, 13, 15],\n            \"generator\": \"gaussians\"\n        },\n        {\n            \"name\": \"B\",\n            \"n\": 120,\n            \"c_true\": 1,\n            \"K_set\": [3, 5, 7, 9, 11, 13, 15],\n            \"generator\": \"line\"\n        },\n        {\n            \"name\": \"C\",\n            \"n\": 150,\n            \"c_true\": 3,\n            \"K_set\": [3, 5, 7, 9, 11, 13, 15, 17, 19],\n            \"generator\": \"y_shape\"\n        },\n    ]\n\n    final_results = []\n    for params in test_cases_params:\n        if params[\"generator\"] == \"gaussians\":\n            centers = np.array([[-4, 0], [0, 0], [4, 0]])\n            n_per_cluster = 30\n            std_dev = 0.4\n            points = np.vstack([\n                np.random.randn(n_per_cluster, 2) * std_dev + center\n                for center in centers\n            ])\n        elif params[\"generator\"] == \"line\":\n            n = params[\"n\"]\n            t = np.linspace(-5, 5, n)\n            epsilon = np.random.randn(n) * 0.1\n            points = np.vstack((t, epsilon)).T\n        elif params[\"generator\"] == \"y_shape\":\n            n_per_ray = 50\n            radii = np.linspace(0.3, 5.0, n_per_ray)\n            angles = [0, 2 * np.pi / 3, 4 * np.pi / 3]\n            std_dev = 0.15\n            all_rays = []\n            for angle in angles:\n                x = radii * np.cos(angle)\n                y = radii * np.sin(angle)\n                ray = np.vstack((x, y)).T\n                noise = np.random.randn(n_per_ray, 2) * std_dev\n                all_rays.append(ray + noise)\n            points = np.concatenate(all_rays, axis=0)\n\n        result = analyze_dataset(points, params[\"K_set\"], params[\"c_true\"])\n        final_results.append(result)\n        \n    # Format the final output string\n    result_str = \",\".join(map(str, final_results))\n    print(f\"[{result_str}]\")\n\n\ndef analyze_dataset(X, K_set, c_true):\n    \"\"\"\n    Performs the full k-selection and clustering analysis for a single dataset.\n    \"\"\"\n    n, d = X.shape\n\n    # Pre-compute pairwise distances\n    dist_matrix = np.zeros((n, n))\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(X[i] - X[j])\n            dist_matrix[i, j] = dist\n            dist_matrix[j, i] = dist\n\n    results_per_k = []\n\n    for k in K_set:\n        # 1. Find k-NN for each point\n        # Add a large value to the diagonal to prevent selecting self\n        dist_matrix_no_self = dist_matrix + np.identity(n) * 1e9\n        knn_indices = np.argsort(dist_matrix_no_self, axis=1)[:, :k]\n        \n        # 2. Collect distances to k-NNs to compute sigma\n        knn_distances_flat = dist_matrix[np.arange(n)[:, None], knn_indices].flatten()\n        sigma = np.median(knn_distances_flat)\n        if sigma == 0: sigma = 1e-9 # Avoid division by zero\n\n        # 3. Construct symmetrized adjacency matrix `A`\n        A = np.zeros((n, n), dtype=bool)\n        for i in range(n):\n            A[i, knn_indices[i]] = True\n        A = np.logical_or(A, A.T)\n        \n        # 4. Construct weighted matrix `W`\n        W = np.zeros((n, n))\n        edge_indices = np.where(A)\n        edge_dists = dist_matrix[edge_indices]\n        W[edge_indices] = np.exp(-edge_dists**2 / (2 * sigma**2))\n\n        # 5. Compute symmetric normalized Laplacian `L_sym`\n        D_diag = np.sum(W, axis=1)\n        D_inv_sqrt_diag = np.zeros_like(D_diag)\n        non_zero_mask = D_diag  0\n        D_inv_sqrt_diag[non_zero_mask] = 1.0 / np.sqrt(D_diag[non_zero_mask])\n        D_inv_sqrt = np.diag(D_inv_sqrt_diag)\n        \n        L_sym = np.identity(n) - D_inv_sqrt @ W @ D_inv_sqrt\n        \n        # 6. Compute eigenvalues and find the largest gap\n        # We need at most r_max+1 eigenvalues.\n        r_max = min(10, n - 2)\n        eigvals = linalg.eigh(L_sym, eigvals_only=True, subset_by_index=[0, r_max + 1])\n\n        # 7. Analyze gaps\n        gaps = eigvals[1:] - eigvals[:-1]\n        \n        if len(gaps) == 0:\n            # This can happen if n is very small and r_max=0\n            G_k = 0\n            c_k = 1\n        else:\n            max_gap_index_0based = np.argmax(gaps)\n            # The cluster count is the 1-based index of the largest gap\n            c_k = max_gap_index_0based + 1\n            G_k = gaps[max_gap_index_0based]\n\n        results_per_k.append({\"k\": k, \"G\": G_k, \"c\": c_k})\n\n    # 8. Select optimal k*\n    max_G = -1.0\n    for res in results_per_k:\n        if res[\"G\"]  max_G:\n            max_G = res[\"G\"]\n\n    best_k_candidates = [res[\"k\"] for res in results_per_k if np.isclose(res[\"G\"], max_G)]\n    k_star = min(best_k_candidates)\n\n    # 9. Find final cluster count c*\n    c_star = 0\n    for res in results_per_k:\n        if res[\"k\"] == k_star:\n            c_star = res[\"c\"]\n            break\n\n    # 10. Evaluate clustering\n    over_clustering = c_star  c_true\n    under_clustering = c_star  c_true\n\n    return [k_star, c_star, over_clustering, under_clustering]\n\nsolve()\n```"
        }
    ]
}