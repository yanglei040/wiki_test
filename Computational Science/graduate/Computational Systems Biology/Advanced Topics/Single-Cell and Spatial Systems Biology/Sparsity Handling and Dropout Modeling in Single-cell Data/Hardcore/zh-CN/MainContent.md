## 引言
[单细胞RNA测序](@entry_id:142269)（scRNA-seq）技术彻底改变了我们探索[生物系统](@entry_id:272986)的能力，使我们能够在单个细胞的分辨率下剖析复杂的组织和动态过程。然而，这项强大技术也带来了一个独特的计算挑战：数据的极端稀疏性。scRNA-seq数据矩阵中充斥着大量的零值，这些零值可能代表真实的生物学不表达，也可能源于技术限制导致的“脱扣”（dropout）事件。简单地忽略或不当处理这些零值会严重扭曲下游分析，导致错误的生物学结论。因此，建立一个严谨的统计框架来理解和建模稀疏性的来源，是进行可靠[单细胞分析](@entry_id:274805)的先决条件。

本文旨在系统性地解决这一核心问题。在接下来的内容中，我们将首先深入“原理与机制”部分，剖析单细胞计数数据的生成过程，阐明泊松、负二项及零膨胀等关键模型的统计基础，并探讨如何区分不同类型的零。随后，在“应用与跨学科联系”部分，我们将展示这些理论如何在从[数据预处理](@entry_id:197920)到高级系统生物学分析的整个工作流程中得到应用，解决[差异表达](@entry_id:748396)、[轨迹推断](@entry_id:176370)等实际问题。最后，“动手实践”部分将提供具体的练习，帮助读者将理论知识转化为实践技能。通过这一结构化的学习路径，读者将掌握处理[单细胞数据稀疏性](@entry_id:754900)的核心思想和方法，为自己的研究打下坚实的基础。

## 原理与机制

### 单细胞计数数据的生成过程

为了有效处理[单细胞测序](@entry_id:198847)数据中的[稀疏性](@entry_id:136793)，我们必须首先理解这些数据是如何产生的。[单细胞RNA测序](@entry_id:142269)（scRNA-seq）实验的核心目标是量化单个细胞内每个基因的信使RNA（mRNA）分子数量。这个过程可以被概念化为一个多阶段的抽样过程。

假设一个细胞 $c$ 对于基因 $g$ 含有 $m_{gc}$ 个真实的mRNA分子。在典型的基于微液滴和[唯一分子标识符](@entry_id:192673)（UMI）的实验方案中，这些分子首先被捕获，然后进行逆转录、扩增和测序。在理想情况下，经过重复[序列数据](@entry_id:636380)去重后，我们观察到的UMI计数 $Y_{gc}$ 对应于最初被成功捕获和测序的mRNA分子数量。

我们可以将每个分子的捕获[过程建模](@entry_id:183557)为一个独立的**[伯努利试验](@entry_id:268355)**。如果细胞 $c$ 中每个mRNA分子被成功捕获、[逆转录](@entry_id:141572)并最终计数的概率为 $p_c$，那么观测到的UMI计数 $Y_{gc}$ 就遵循一个**二项分布**：
$$
Y_{gc} \sim \text{Binomial}(m_{gc}, p_c)
$$
这个简单的模型构成了我们理解单细胞计数数据统计特性的基石 。该模型的[期望计数](@entry_id:162854)值为 $\mathbb{E}[Y_{gc}] = m_{gc} p_c$。

在实践中，真实的分子数 $m_{gc}$ 通常很大，而捕获效率 $p_c$ 则非常低（通常在 $0.05$到$0.20$之间）。在这种情况下，[二项分布](@entry_id:141181)可以被一个具有相同均值的**[泊松分布](@entry_id:147769)**很好地近似：
$$
Y_{gc} \sim \text{Poisson}(m_{gc} p_c)
$$
这个[泊松近似](@entry_id:265225)在计算上更为方便，并构成了许多下游分析方法的基础 。

为了在不同细胞间进行有意义的比较，我们必须校正捕获效率 $p_c$ 和细胞总RNA含量 $M_c = \sum_g m_{gc}$ 的差异。为此，我们引入两个关键概念：**组成比例** $\theta_{gc} = m_{gc} / M_c$，它代表基因 $g$ 在细胞 $c$ 的总转录组中所占的生物学比例；以及**大小因子** $s_c$，它代表细胞 $c$ 的总采样强度。从我们[生成模型](@entry_id:177561)的基本原理出发，我们可以将期望UMI计数表示为：
$$
\mathbb{E}[Y_{gc}] = m_{gc} p_c = \left( \frac{m_{gc}}{M_c} \right) (M_c p_c) = \theta_{gc} s_c
$$
由此，我们推导出大小因子 $s_c = M_c p_c$，它等于该细胞中预期观察到的总UMI计数 $\mathbb{E}[n_c] = \mathbb{E}[\sum_g Y_{gc}]$。在[广义线性模型](@entry_id:171019)（GLM）中，例如泊松或负二项回归，通常使用[对数连接函数](@entry_id:163146)来对[期望值](@entry_id:153208)建模。该模型可以表示为：
$$
\ln(\mathbb{E}[Y_{gc}]) = \ln(\theta_{gc}) + \ln(s_c)
$$
在这里，$\ln(s_c)$ 作为一个**偏移量**（offset）进入模型。这是一个已知的值（通常根据细胞的总UMI计数来估计），它允许模型直接对我们感兴趣的生物学量 $\ln(\theta_{gc})$ 进行建模，从而有效地对细胞间的技术差异进行归一化 。

### 零值的本质：抽样零与结构零

单细胞数据矩阵的一个显著特征是其高度的**稀疏性**，即矩阵中含有大量的零值。正确地解释这些零的来源对于准确的生物学推断至关重要。这些零值主要可以分为两大类。

1.  **抽样零（Sampling Zeros）**：当一个基因真实表达（即 $m_{gc} > 0$），但由于表达水平低和/或捕获效率有限，在[随机抽样](@entry_id:175193)过程中偶然没有捕获到任何分子时，就会产生抽样零。这是泊松或二项抽样过程的固有特性。例如，在一个均值为 $\mu$ 的泊松模型中，观察到零的概率为 $P(Y=0) = \exp(-\mu)$ 。这个概率即使在 $\mu>0$ 时也非零。

2.  **结构零（Structural Zeros）**：这些零值代表了真实的“信号缺失”，而非随机抽样波动的结果。它们可以进一步细分为：
    *   **生物学零**：基因 $g$ 在细胞 $c$ 中确实不表达（$m_{gc}=0$）。这是细胞状态或类型的生物学特征。
    *   **技术零或“dropout”**：基因确实表达（$m_{gc}>0$），但由于样本制备或测序过程中的特定技术故障（超出了简单的泊松抽样噪声），导致其未能被检测到。

为了在统计模型中区分这两种零，**零膨胀（Zero-Inflated, ZI）**模型被提出。一个[零膨胀模型](@entry_id:756817)假设观测值来自两个过程的混合：一个是以概率 $\pi$ 产生结构零的“零过程”，另一个是以概率 $1-\pi$ 从某个标准计数[分布](@entry_id:182848)（如泊松或负二项）中抽样的“[计数过程](@entry_id:260664)”。因此，观测到零的总概率是：
$$
P(Y=0) = \pi + (1-\pi)P_{\text{count}}(0)
$$
其中 $P_{\text{count}}(0)$ 是计数[分布](@entry_id:182848)自身产生零的概率 。这个框架允许我们明确地为“多余的”零（即超出标准计数[分布](@entry_id:182848)所预期的零）建模。例如，我们可以通过比较观测到的零比例 $\hat{p}_0$ 和计数[分布](@entry_id:182848)预期的零比例 $P_{\text{count}}(0)$ 来估算零膨胀参数 $\pi$。如果一个基因的负二项分布参数为均值 $\mu=2$ 和大小参数 $r=1$，其抽样零概率为 $P_{\text{count}}(0) = (1+2/1)^{-1} = 1/3$。如果观测到的零比例为 $\hat{p}_0=0.6$，我们可以通过求解 $0.6 = \pi + (1-\pi)(1/3)$ 来估计额外的技术零概率，得到 $\pi=0.4$ 。

### 过度分散及其在[稀疏性](@entry_id:136793)中的作用

单细胞基因表达数据通常表现出**过度分散（overdispersion）**的特性，即数据的[方差](@entry_id:200758)远大于其均值。这主要是由基因表达的内在随机性（如[转录爆发](@entry_id:156205)）驱动的。泊松分布的[方差](@entry_id:200758)等于其均值，因此无法捕捉到这种额外的生物学变异。

**负二项（Negative Binomial, NB）[分布](@entry_id:182848)**是处理过度分散计数数据的标准模型。它可以被看作是一个**伽马-泊松混合模型**：我们假设每个细胞的真实表达率本身是一个遵循伽马[分布](@entry_id:182848)的[随机变量](@entry_id:195330)，而观测到的计数则是在给定该表达率下的泊松抽样结果 。这个两层模型优雅地整合了生物学变异（伽马[分布](@entry_id:182848)）和技术抽样噪声（[泊松分布](@entry_id:147769)）。

NB[分布](@entry_id:182848)通常由其均值 $\mu$ 和一个**分散参数** $\theta$（在某些文献中也称为大小参数 $r$）来[参数化](@entry_id:272587)。$\theta$ 控制着过度分散的程度：随着 $\theta \to \infty$，NB[分布](@entry_id:182848)收敛于[泊松分布](@entry_id:147769)；$\theta$ 越小，过度分散程度越高。

一个至关重要的见解是，**过度分散本身就能产生高度的[稀疏性](@entry_id:136793)**。NB[分布](@entry_id:182848)产生零的概率为：
$$
P(X=0) = \left( \frac{\theta}{\theta + \mu} \right)^{\theta}
$$
分析这个表达式可以发现，对于一个固定的均值 $\mu$，当分散参数 $\theta$ 趋向于0时（即极度过度分散），零的概率 $P(X=0)$ 会趋向于1  。这意味着，即使一个基因的平均表达水平不为零，强烈的细胞间表达[异质性](@entry_id:275678)也可能导致大部分细胞的观测值为零。

这一性质对单细胞[数据建模](@entry_id:141456)具有深远的影响。它表明，对于现代基于UMI的测[序数](@entry_id:150084)据，许多所谓的“dropout”事件可能并非需要一个独立的零膨胀机制来解释的技术伪影，而仅仅是具有显著过度分散的[计数过程](@entry_id:260664)的自然结果。因此，在许多情况下，一个考虑了大小因子和基因特异性过度分散的N[B模型](@entry_id:159413)，就已经足以解释观测到的高比例零值，而无需引入更复杂的[ZINB模型](@entry_id:756826) 。

### 缺失数据的统计框架

将技术性dropout视为一种数据缺失问题，可以为我们提供一个更严谨的理论视角。在统计学中，Rubin的框架根据缺失过程对完整数据和观测数据的依赖关系，将缺失机制分为三类 ：

1.  **[完全随机缺失](@entry_id:170286)（Missing Completely At Random, MCAR）**：缺失的概率与任何数据（无论是观测到的还是未观测到的）都无关。
2.  **[随机缺失](@entry_id:168632)（Missing At Random, MAR）**：缺失的概率可以完全由观测数据来解释。换句话说，在给定观测数据后，缺失的概率与未观测到的数据无关。
3.  **[非随机缺失](@entry_id:163489)（Missing Not At Random, MNAR）**：缺失的概率依赖于未观测到的数据本身，即使在给定所有观测数据之后也是如此。

在[scRNA-seq](@entry_id:155798)的背景下，“缺失”事件对应于当真实分子数 $X_{gc}>0$ 时却观测到零。未观测的数据正是这个真实的分子数 $X_{gc}$。一个合理的物理模型是，分子的捕获概率（即被检测到的概率）可能依赖于其自身的丰度。例如，丰度非常低的基因可能由于动力学或化学原因更难被捕获。

如果检测概率 $p_{gc}$ 依赖于真实的、未被观测的表达量 $X_{gc}$，那么根据定义，这种缺失机制就是**MNAR** 。例如，在一个二项稀释模型 $Y_{gc} \sim \text{Binomial}(X_{gc}, p_{gc})$ 中，观测到零的概率是 $(1-p_{gc})^{X_{gc}}$。这个概率明显依赖于未观测值 $X_{gc}$，因此是MNAR。MNAR是scRNA-seq dropout最现实的描述，但它也给统计推断带来了最大的挑战，因为标准的[缺失数据](@entry_id:271026)处理方法（如仅使用完整观测值的分析）在MNAR下通常会导致有偏见的结果。这激励了专门为处理此类MNAR数据而设计的模型的开发，例如使用[期望最大化](@entry_id:273892)（EM）算法的复杂模型 。

### 建模与区分零类型

为了在实践中处理和解释零值，研究人员开发了多种统计模型和实验策略。

#### [模型选择](@entry_id:155601)：零膨胀与Hurdle模型

除了前述的**[零膨胀模型](@entry_id:756817)（ZINB/ZIP）**，**Hurdle模型**是另一种流行的两部分模型。它将数据生成过程分解为：
1.  一个**二元过程**，决定一个观测值是否为零（即，是否“越过栏架”）。这通常用逻辑[回归建模](@entry_id:170726)。
2.  一个**截断[计数过程](@entry_id:260664)**，用于对所有正值进行建模。这通常使用一个在零点截断的泊松或NB[分布](@entry_id:182848)。

例如，MAST（Model-based Analysis of Single-cell Transcriptomics）框架使用了一个Hurdle模型，其中正值计数的对数转换值（$\ln(y+c)$）被近似地用一个高斯[线性模型](@entry_id:178302)来建模。这种近似可以通过[一阶delta方法](@entry_id:168803)从更基本的NB Hurdle模型中推导出来，但在低表达、高[离散度](@entry_id:168823)的[稀疏数据](@entry_id:636194)中，[高斯和](@entry_id:196588)同[方差](@entry_id:200758)假设可能会失效 。

#### 实验与统计区分

我们如何判断一个基因的零值主要是抽样零、生物零还是技术零，并选择合适的模型呢？

*   **实验设计**：为了从经验上区分技术零和生物零，我们可以设计一个包含“地面真实值”的实验。**ERCC spike-ins**是一组已知浓度的外源RNA分子，被添加到细胞裂解液中。由于它们在生物学上不存在于细胞中，任何观测到的spike-in零值都必须归因于技术原因。通过在多个浓度水平上添加spike-ins并结合细胞RNA输入的**稀释系列**，我们可以系统地研究检测效率与分子丰度及文库大小之间的定量关系 。

*   **统计检验**：为了检验一个基因中是否存在超出N[B模型](@entry_id:159413)预期的“额外”零，我们可以使用**[似然比检验](@entry_id:268070)（LRT）**。该检验比较了两个[嵌套模型](@entry_id:635829)的[拟合优度](@entry_id:637026)：一个简单的N[B模型](@entry_id:159413)（[零假设](@entry_id:265441) $H_0$）和一个更复杂的[ZINB模型](@entry_id:756826)（备择假设 $H_1$）。$H_0$ 是 $H_1$ 中零膨胀参数 $\pi_g=0$ 的特例。一个关键的统计细节是，由于 $\pi_g=0$ 位于参数空间的边界上，标准的[卡方检验](@entry_id:174175)理论不适用。在这种情况下，LRT统计量的[零分布](@entry_id:195412)应使用 $0.5\chi^2_0 + 0.5\chi^2_1$ 的[混合分布](@entry_id:276506)或通过[参数化](@entry_id:272587)自举（parametric bootstrap）来校准 。

#### 挑战：模型混淆

在低表达量的基因中，过度分散（由N[B模型](@entry_id:159413)捕捉）和零膨胀（由ZIP/[ZINB模型](@entry_id:756826)捕捉）在统计上可能难以区分。可以证明，仅使用数据的正值部分（零[截断数据](@entry_id:163004)）的前两个矩（均值和[方差](@entry_id:200758)），我们无法唯一地确定N[B模型](@entry_id:159413)的参数，这意味着一系列不同的过度分散和零膨胀组合可以产生几乎相同的观测数据模式。这凸显了仅依赖统计拟合来区分这两种机制的内在局限性，并强调了使用更[高阶矩](@entry_id:266936)或[分布](@entry_id:182848)尾部信息的诊断方法的重要性 。

作为一个简单的诊断标准，我们可以评估一个零值更有可能是抽样零还是结构零。在一个ZIP模型中，如果一个基因的有效表达率 $p_c \lambda_{gc}$ 低于一个阈值 $T_g = \ln((1-\pi_g)/\pi_g)$（即该基因存在的先验[对数优势比](@entry_id:141427)），那么观测到的零更有可能是由于抽样噪声而非真实的生物学缺失 。

### 处理[稀疏性](@entry_id:136793)：插补与[不确定性传播](@entry_id:146574)

鉴于数据的稀疏性，一个常见的策略是**[插补](@entry_id:270805)（imputation）**，即估计缺失或“不可靠”的零计数的潜在真实表达值。然而，必须以严谨的统计方式来理解和执行[插补](@entry_id:270805)。

插补不应被视为简单地“填充”数据矩阵中的空白，而应被视为一个**[统计估计](@entry_id:270031)问题**。在一个贝叶斯框架下，我们的目标是估计给定观测数据 $X_{gc}$ 的潜在真实表达丰度 $\theta_{gc}$ 的后验分布 $p(\theta_{gc} | X_{gc})$。例如，在一个伽马-泊松模型中，如果 $\theta_{gc}$ 的[先验分布](@entry_id:141376)是 $\text{Gamma}(a_g, b_g)$，观测模型是 $X_{gc} \sim \text{Poisson}(s_c \theta_{gc})$，那么其后验分布是 $\text{Gamma}(a_g + X_{gc}, b_g + s_c)$ 。

在贝叶斯决策理论中，[平方误差损失](@entry_id:178358)下的最优单[点估计量](@entry_id:171246)是[后验均值](@entry_id:173826)。在这个例子中，[插补](@entry_id:270805)值将是 $\mathbb{E}[\theta_{gc} | X_{gc}] = \frac{a_g+X_{gc}}{b_g+s_c}$。

一个主要的陷阱是所谓的**单点[插补](@entry_id:270805)**：用单个[点估计](@entry_id:174544)值（如[后验均值](@entry_id:173826)）替换观测数据，然后在下游分析（如[差异表达](@entry_id:748396)或PCA）中将这些[插补](@entry_id:270805)值视为无误差的真实观测值。这种做法系统性地**忽略了[插补](@entry_id:270805)过程本身的不确定性**。结果是，下游分析中计算出的[方差](@entry_id:200758)和标准误会被严重低估，导致[置信区间](@entry_id:142297)过窄和[假阳性](@entry_id:197064)结果增多 。

一个更符合统计原理的方法是**传播不确定性**。这可以通过在下游分析中使用完整的后验分布，或使用像**[多重插补](@entry_id:177416)（multiple imputation）**这样的技术来实现。根据[全方差定律](@entry_id:184705)，任何统计量的总[方差](@entry_id:200758)都应包含两部分：后验内部的变异（within-posterior variability）和[后验均值](@entry_id:173826)之间的变异（between-posterior mean variability）。值得注意的是，[插补](@entry_id:270805)的不确定性对于那些信息较少的观测值（例如，来自[测序深度](@entry_id:178191)较低的细胞，即 $s_c$ 较小）会更大，因为它们的后验分布更宽 。