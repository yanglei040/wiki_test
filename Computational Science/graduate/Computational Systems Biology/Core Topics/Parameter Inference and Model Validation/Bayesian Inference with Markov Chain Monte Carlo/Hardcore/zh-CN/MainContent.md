## 引言
贝叶斯推断为我们提供了一个严谨的框架，用以在观测到数据后更新我们对模型参数的认知。在[计算系统生物学](@entry_id:747636)中，这对于量化描述复杂生物过程的机理模型至关重要。然而，对于大多数实际的生物学模型而言，其参数的[后验概率](@entry_id:153467)[分布](@entry_id:182848)往往维度极高、形式复杂，无法通过解析方法直接分析，我们仅能评估其在任意一点的相对概率。因此，我们面临一个核心挑战：如何从这个无法被精确写出，却可以进行点态评估的[分布](@entry_id:182848)中有效地进行探索和抽样？

本文将系统地介绍解决这一挑战的主流方法——[马尔可夫链蒙特卡洛](@entry_id:138779)（MCMC）。我们将通过三个章节的篇幅，引领读者从理论走向实践。在“原理与机制”一章中，我们将深入探讨构建[后验分布](@entry_id:145605)的基本要素，并揭示[MCMC算法](@entry_id:751788)背后的核心数学原理，包括Metropolis-Hastings和[哈密顿蒙特卡洛](@entry_id:144208)（HMC）等关键算法。接下来，在“应用与跨学科联系”一章中，我们将展示这些方法如何应用于解决系统生物学中的真实问题，例如处理随机模型的[难解似然](@entry_id:140896)函数和分析高维单细胞数据，并将其视野拓展至[进化生物学](@entry_id:145480)等相关领域。最后，“动手实践”部分将提供一系列编程练习，帮助读者将理论知识转化为实践技能。

## 原理与机制

在上一章中，我们介绍了贝叶斯推断的基本哲学：在观测到数据后，利用贝叶斯定理更新我们对模型参数的信念。这引导我们得到了[后验分布](@entry_id:145605) $p(\theta \mid y)$，它封装了关于参数 $\theta$ 的所有可用信息。然而，在[计算系统生物学](@entry_id:747636)中遇到的大多数有趣模型中，[后验分布](@entry_id:145605)都是一个高维、形状复杂的函数，无法通过解析方法直接分析。我们通常只能计算其在任意一点 $\theta$ 的值（且往往只能计算到一个未知的归一化常数）。因此，我们的核心挑战转变为：如何从这个我们无法完全写出、却可以进行点态评估的[分布](@entry_id:182848)中生成样本？

本章将深入探讨解决这一挑战的主流方法——马尔可夫链蒙特卡洛（Markov chain [Monte Carlo](@entry_id:144354), MCMC）的原理和机制。我们将从如何为生物学模型构建后验分布开始，然后揭示[MCMC算法](@entry_id:751788)背后的核心理论，接着介绍几种关键算法的运作方式，最后讨论如何诊断和解释MCMC的输出，以确保我们的推断是可靠和高效的。

### 构建后验分布

在启动[MCMC采样](@entry_id:751801)器之前，我们必须首先精确定义[目标分布](@entry_id:634522)，即后验分布 $p(\theta \mid y) \propto p(y \mid \theta)p(\theta)$。这需要我们审慎地选择似然函数 $p(y \mid \theta)$ 和先验分布 $p(\theta)$。

#### [似然函数](@entry_id:141927)：连接模型与数据

似然函数是连接我们的理论模型与实验数据的数学桥梁。它的形式由模型的内在随机性和测量过程共同决定。一个经典的例子是在单细胞水平上对基因表达进行建模 。

考虑一个简单的模型，其中一个基因以恒定的速率 $k_{\mathrm{syn}}$（[零级反应](@entry_id:176293)倾向）产生[信使RNA](@entry_id:262893)（mRNA），而已有的每个mRNA分子则以速率 $k_{\mathrm{deg}}$（一级反应倾向）独立降解。这是一个基本的“[生灭过程](@entry_id:168595)”。在统计[稳态](@entry_id:182458)下，即产生和降解的速率达到平衡时，细胞内mRNA分子数量的[概率分布](@entry_id:146404)是什么？通过求解[化学主方程](@entry_id:161378)的[稳态解](@entry_id:200351)，我们可以证明，分子数 $y$ 服从[泊松分布](@entry_id:147769)：
$$
P(y \mid \lambda) = \frac{\lambda^y \exp(-\lambda)}{y!}
$$
其中，[分布](@entry_id:182848)的均值参数 $\lambda$ 是合成速率与降解速率之比，即 $\lambda = k_{\mathrm{syn}} / k_{\mathrm{deg}}$。

因此，如果我们从 $n$ 个处于[稳态](@entry_id:182458)的独立细胞中分别测量它们的mRNA拷贝数，得到数据集 $y = (y_1, \dots, y_n)$，那么在给定参数 $\theta = (k_{\mathrm{syn}}, k_{\mathrm{deg}})$ 的情况下，整个数据集的[似然函数](@entry_id:141927)就是各个独立测量的似然的乘积：
$$
p(y \mid \theta) = \prod_{i=1}^n \mathrm{Poisson}(y_i \mid \lambda = k_{\mathrm{syn}}/k_{\mathrm{deg}}) \propto \left(\frac{k_{\mathrm{syn}}}{k_{\mathrm{deg}}}\right)^{\sum_{i=1}^{n} y_{i}} \exp\left(-n \frac{k_{\mathrm{syn}}}{k_{\mathrm{deg}}}\right)
$$
在贝叶斯推断中，任何不依赖于参数 $\theta$ 的项（如 $1/y_i!$）都可以被吸收到归一化常数中。

然而，对于更复杂的随机模型，导出似然函数本身就是一个巨大的挑战。例如，在一个包含mRNA和蛋白质两个物种的[基因表达模型](@entry_id:178501)中，如果我们只能在部[分时](@entry_id:274419)间点噪声地观测到蛋白质水平，而mRNA水平是完全潜在的，那么似然函数 $p(y_{1:T} \mid \theta)$ 需要对所有可能的潜在mRNA路径和完整的反应历史进行积分或求和 。这个积分是在一个无限维的路径空间上进行的，其组合复杂性使得精确计算通常是“不可解的”(intractable)。

在这种情况下，我们需要依赖于一些近似方法来获得一个可计算的代理[似然](@entry_id:167119)。一个强有力的工具是**[线性噪声近似](@entry_id:190628)**（Linear Noise Approximation, [LNA](@entry_id:150014)）。[LNA](@entry_id:150014)源于对[化学主方程](@entry_id:161378)的系统大小展开，它将物种数量分解为一个宏观的、确定性的部分和一个随机的、涨落的部分。其结果是，系统的状态转移概率被近似为高斯分布。当测量噪声也为高斯分布时，整个系统就变成了一个线性高斯状态空间模型。对于这类模型，我们可以使用**卡尔曼滤波器**（Kalman filter）等高效算法来精确地计算近似似然值，从而使其能够在MCMC框架内使用 。

#### [先验分布](@entry_id:141376)：编码先验知识

先验分布 $p(\theta)$ 捕捉了我们在看到数据之前对参数的了解和信念。选择先验时，必须尊重参数的物理约束。例如，对于生物[化学反应速率常数](@entry_id:184828)如 $k_{\mathrm{syn}}$ 和 $k_{\mathrm{deg}}$，它们必须是正数。因此，选择一个只在正实数上有支撑的[分布](@entry_id:182848)至关重要。

在上述[基因表达模型](@entry_id:178501)中，**伽马[分布](@entry_id:182848)**（Gamma distribution）和**[对数正态分布](@entry_id:261888)**（Log-Normal distribution）都是合适的选择，因为它们的支撑域都是 $(0, \infty)$。相反，使用在整个[实轴](@entry_id:148276)上都有支撑的正态分布（Normal distribution）作为先验则是不恰当的，因为它会赋予非物理的负速率值以非零概率 。

当[似然函数](@entry_id:141927)与某个[先验分布](@entry_id:141376)家族结合时，如果得到的后验分布仍然属于同一个家族，我们就称该先验为[似然](@entry_id:167119)的**[共轭先验](@entry_id:262304)**（conjugate prior）。共轭性在数学上非常方便，尽管在复杂模型中不常见。一个典型的例子是泊松似然与伽马先验的组合 。

假设我们观察到一组来自泊松分布的[独立同分布](@entry_id:169067)计数 $y_{1:T} \sim \mathrm{Poisson}(\lambda)$，并为未知速[率参数](@entry_id:265473) $\lambda$ 选择一个伽马先验 $\lambda \sim \mathrm{Gamma}(\alpha, \beta)$。后验分布为：
$$
p(\lambda \mid y_{1:T}) \propto p(y_{1:T} \mid \lambda) p(\lambda) \propto \left( \lambda^{\sum y_t} \exp(-T\lambda) \right) \left( \lambda^{\alpha-1} \exp(-\beta\lambda) \right)
$$
$$
p(\lambda \mid y_{1T}) \propto \lambda^{\left(\alpha + \sum y_t\right) - 1} \exp(-(\beta+T)\lambda)
$$
我们发现，[后验分布](@entry_id:145605)的函数形式依然是一个伽马[分布](@entry_id:182848)的核，具体来说是 $\mathrm{Gamma}(\alpha + \sum_{t=1}^{T} y_t, \beta + T)$。数据通过其**充分统计量**（sufficient statistic）——总计数 $\sum y_t$ ——来更新先验的参数。

#### 后验分布与可识别性挑战

将[似然](@entry_id:167119)和先验结合，我们便得到了后验分布。以使用独立伽马先验的[基因表达模型](@entry_id:178501)为例 ，后验分布（未归一化）为：
$$
p(k_{\mathrm{syn}},k_{\mathrm{deg}}\mid y) \propto \underbrace{\left(\frac{k_{\mathrm{syn}}}{k_{\mathrm{deg}}}\right)^{\sum y_{i}}\exp\left(-n\frac{k_{\mathrm{syn}}}{k_{\mathrm{deg}}}\right)}_{\text{Likelihood}} \cdot \underbrace{k_{\mathrm{syn}}^{\alpha_{s}-1}\exp(-\beta_{s}k_{\mathrm{syn}}) \cdot k_{\mathrm{deg}}^{\alpha_{d}-1}\exp(-\beta_{d}k_{\mathrm{deg}})}_{\text{Prior}}
$$
即使有了这个表达式，挑战也才刚刚开始。一个关键问题是**参数可识别性**（parameter identifiability）。如果仅从模型的输出无法唯一确定参数的值，那么参数就是不可识别的。**结构性不可识别**（structural non-identifiability）源于模型本身的数学结构。

考虑一个更简单的确定性ODE模型 $dx/dt = k_{\mathrm{syn}} - k_{\mathrm{deg}} x$ 。如果我们只能观测到其[稳态](@entry_id:182458)浓度 $x^* = k_{\mathrm{syn}}/k_{\mathrm{deg}}$，那么任何能产生相同比率的 $(k_{\mathrm{syn}}, k_{\mathrm{deg}})$ 组合（例如，$(c \cdot k_{\mathrm{syn}}, c \cdot k_{\mathrm{deg}})$ 对任意 $c>0$）都是无法区分的。这意味着[似然函数](@entry_id:141927)在参数空间中沿着 $k_{\mathrm{syn}}/k_{\mathrm{deg}} = \text{const}$ 的射线上是恒定的。这会在[后验分布](@entry_id:145605)中形成一个狭长的“山脊”（ridge），给[MCMC采样](@entry_id:751801)带来巨大困难。

一个有效的策略是进行**重参数化**（reparameterization），将参数变换到一个新的[坐标系](@entry_id:156346)，在这个[坐标系](@entry_id:156346)中，可识别与不可识别的部分被分离开来。例如，我们可以定义新参数 $(\theta_1, \theta_2) = (k_{\mathrm{syn}}/k_{\mathrm{deg}}, k_{\mathrm{deg}})$。这里，$\theta_1$ 是从[稳态](@entry_id:182458)数据中可识别的组合，而 $\theta_2$ 则是不可识别的（其后验完全由先验决定）[@problem_id:3289315, @problem_id:3289315_C]。当进行这种变量变换时，我们必须通过乘以[雅可比行列式](@entry_id:137120)来正确地转换概率密度 [@problem_id:3289315, @problem_id:3289315_B]。这种策略可以极大地简化后验的几何形状，从而提高MCMC的效率 [@problem_id:3289315, @problem_id:3289315_D]。

### 核心机制：[马尔可夫链蒙特卡洛](@entry_id:138779)

一旦定义了目标[后验分布](@entry_id:145605) $\pi(\theta) \equiv p(\theta|y)$，MCMC的目标就是构建一个[马尔可夫链](@entry_id:150828)，其状态 $\theta_1, \theta_2, \dots$ 最终会收敛到从 $\pi(\theta)$ 中抽取的样本。

#### [细致平衡原理](@entry_id:200508)

马尔可夫链由一个**转移核**（transition kernel）$K(\theta, \theta')$ 定义，它给出了从当前状态 $\theta$ 转移到下一个状态 $\theta'$ 的概率密度。为了让这条链的[平稳分布](@entry_id:194199)恰好是我们的目标后验 $\pi(\theta)$，一个充分（但非必要）的条件是该转移核满足**[细致平衡条件](@entry_id:265158)**（detailed balance condition），也称为**[可逆性](@entry_id:143146)**（reversibility）。

该条件要求，在平稳状态下，从状态 $\theta$ 流向 $\theta'$ 的“概率通量”等于从 $\theta'$ 反向流回 $\theta$ 的通量：
$$
\pi(\theta) K(\theta, \theta') = \pi(\theta') K(\theta', \theta)
$$
这个[局部平衡](@entry_id:156295)条件保证了全局平衡。通过对上式两边关于 $\theta$ 积分，我们可以证明它蕴含了[平稳性条件](@entry_id:191085) $\pi(\theta') = \int \pi(\theta) K(\theta, \theta') d\theta$。[MCMC算法](@entry_id:751788)设计的核心思想，就是构造一个满足[细致平衡条件](@entry_id:265158)的转移核 $K$。

### [MCMC算法](@entry_id:751788)实践

有多种方法可以构建满足细致平衡的转移核。下面我们介绍几种最重要的方法。

#### Metropolis-Hastings 算法

Metropolis-Hastings（MH）算法是一个通用框架。它分两步进行转移：

1.  **提议 (Propose)**：根据一个我们选择的**[提议分布](@entry_id:144814)**（proposal distribution） $q(\theta' \mid \theta)$，从当前状态 $\theta$ 生成一个候选状态 $\theta'$。
2.  **接受/拒绝 (Accept/Reject)**：以一定的概率 $\alpha(\theta, \theta')$ 接受这个提议，即令下一个状态为 $\theta'$；否则，拒绝提议，下一个状态保持为 $\theta$。

为了满足细致平衡，接受概率 $\alpha$ 被巧妙地设计为：
$$
\alpha(\theta, \theta') = \min\left\{1, \frac{\pi(\theta') q(\theta \mid \theta')}{\pi(\theta) q(\theta' \mid \theta)}\right\}
$$
这个比率的关键在于它只依赖于后验密度的比值 $\pi(\theta')/\pi(\theta)$，因此我们不需要知道[后验分布](@entry_id:145605)的归一化常数。

一个最简单的MH算法是**[随机游走Metropolis](@entry_id:754036)算法**，它使用一个对称的提议分布，如以当前点为中心的高斯分布 $q(\theta' \mid \theta) = \mathcal{N}(\theta, \Sigma)$。由于 $q(\theta' \mid \theta) = q(\theta \mid \theta')$，[接受概率](@entry_id:138494)简化为 $\alpha(\theta, \theta') = \min\{1, \pi(\theta')/\pi(\theta)\}$。

尽管简单，但该算法的效率极度依赖于提议协方差矩阵 $\Sigma$ 的选择 。如果后验分布是各向异性的（例如，在前述的不可识别性问题中出现的“山脊”状），选择一个合适的 $\Sigma$ 将变得非常棘手：
*   如果使用各向同性的提议 $\Sigma = \sigma^2 I$，并将步长 $\sigma$ 调整到适应后验最窄的方向，那么链的接受率会很高，但在宽阔的方向上移动极其缓慢，混合效率极差。
*   如果将步长 $\sigma$ 调整到适应最宽的方向，那么在窄的方向上提议的步子会过大，几乎总是跳到低概率区域而被拒绝，导致链“卡住不动”。

解决这个问题有几种策略 ：
1.  **[自适应MCMC](@entry_id:746254)**：在采样过程中动态调整 $\Sigma$ 以匹配后验的协[方差](@entry_id:200758)结构。
2.  **重参数化**：如前所述，通过变量变换（如[对数变换](@entry_id:267035)）来降低参数间的相关性和尺度差异。
3.  **分量式/分块更新**：不一次性更新所有参数，而是逐个参数或将相关的参数分成“块”进行更新，并为每个分量或块使用独立调整的步长。

#### [基于梯度的采样](@entry_id:749987)器

[随机游走](@entry_id:142620)类算法是“盲目”的，因为它们不使用关于后验分布形状的任何信息。**[基于梯度的采样](@entry_id:749987)器**通过利用后验对[数密度](@entry_id:268986)的梯度 $\nabla \log \pi(\theta)$ 来提出更智能的移动，从而显著提高效率。

**Metropolis调整的朗之万算法 (MALA)**
该算法的灵感来源于物理学中的**[朗之万随机微分方程](@entry_id:633963)**（[Langevin SDE](@entry_id:633963)），它描述了一个粒子在[势能](@entry_id:748988)场 $U(\theta) = -\log \pi(\theta)$ 中的布朗运动。通过对该SDE进行离散化，我们得到一个提议机制 ：
$$
\theta' = \theta + \frac{\delta^2}{2}\nabla\log \pi(\theta) + \delta\eta, \quad \text{其中 } \eta \sim \mathcal{N}(0, I)
$$
这里，提议不仅包含一个随机的[扩散](@entry_id:141445)项（$\delta\eta$），还包含一个“漂移项”，该项将提议推向后验概率更高的方向。由于这个提议分布不再对称，我们必须使用完整的MH接受概率，其中包含提议密度的比率 $q(\theta \mid \theta') / q(\theta' \mid \theta)$。

**[哈密顿蒙特卡洛](@entry_id:144208) (HMC)**
HMC是MALA思想的进一步延伸，它通过引入一个辅助的“动量”变量 $r$，将采样问题置于[哈密顿力学](@entry_id:146202)的框架中 。我们将后验对数密度视为“势能” $U(\theta) = -\log\pi(\theta \mid y)$，并定义一个“动能” $K(r) = \frac{1}{2}r^\top M^{-1}r$，其中 $M$ 是一个“质量”矩阵。总能量，即**[哈密顿量](@entry_id:172864)**，为 $H(\theta, r) = U(\theta) + K(r)$。

HMC的每次迭代包含以下步骤：
1.  从一个标准[分布](@entry_id:182848)（如[高斯分布](@entry_id:154414) $\mathcal{N}(0,M)$）中随机抽取一个新的动量 $r$。
2.  从当前位置 $(\theta, r)$ 开始，沿着[哈密顿量守恒](@entry_id:164570)的[轨迹模拟](@entry_id:140160)系统的演化一段时间。这个模拟是通过求解[哈密顿方程](@entry_id:156213)来进行的。
3.  将模拟结束时的状态 $(\theta', r')$ 作为提议。

由于[数值积分](@entry_id:136578)存在误差，[哈密顿量](@entry_id:172864)并非完全守恒。因此，我们仍需一个Metropolis接受/拒绝步骤来精确地纠正误差。幸运的是，使用一种称为**[蛙跳法](@entry_id:751210)**（leapfrog method）的特殊[数值积分器](@entry_id:752799)，可以实现两个优异的性质 ：
1.  **[体积保持](@entry_id:141001)**：[蛙跳法](@entry_id:751210)变换的[雅可比行列式](@entry_id:137120)恰好为1，这意味着它在相空间中保持体积。
2.  **近似[能量守恒](@entry_id:140514)**：[蛙跳法](@entry_id:751210)是时间可逆的，并且对能量的模拟误差非常小（对于步长 $\epsilon$，误差阶数为 $O(\epsilon^3)$）。

这两个性质使得HMC可以提出距离当前点很远但能量几乎不变的候选点，从而获得非常高的接受率。这使得HMC能够高效地探索高维和复杂的后验分布，避免了[随机游走](@entry_id:142620)的缓[慢扩散](@entry_id:161635)。

### MCMC输出的解释与诊断

运行[MCMC算法](@entry_id:751788)后，我们会得到一长串参数样本。如何利用这些样本，并确信它们是可靠的？

#### 总结[后验分布](@entry_id:145605)：[点估计](@entry_id:174544)的陷阱

一个常见的诱惑是仅用一个点来总结[后验分布](@entry_id:145605)，例如**[最大后验概率](@entry_id:268939)**（Maximum a Posteriori, MAP）估计，即后验分布的众数。然而，当后验分布复杂时，这种做法可能极具误导性，尤其是在存在**多峰性**（multimodality）的情况下 。

在某些[基因表达模型](@entry_id:178501)中，由于爆发频率（burst frequency）和爆发大小（burst size）之间的权衡，后验分布可能呈现双峰。一个峰对应“频繁但小”的[转录爆发](@entry_id:156205)，另一个对应“罕见但大”的爆发，而两个峰的后验概率可能相近。
*   **MAP的缺陷**：选择[MAP估计](@entry_id:751667)意味着武断地挑选其中一个峰，并完全忽略另一个同样合理的生物学解释。这会严重低估参数的不确定性，并导致基于该[点估计](@entry_id:174544)的预测未能涵盖所有可能的系统行为。
*   **全后验推断的优势**：与之相对，**全后验推断**利用整个MCMC样本集。这可以揭示后验分布的完整结构。例如，**可信区域**（credible regions）可能是两个不相连的集合，每个集合包围一个峰。[后验均值](@entry_id:173826)甚至可能位于两个峰之间的低概率“山谷”中。**[后验预测分布](@entry_id:167931)**会自然地成为来自不同动力学机制的预测的混合体，从而忠实地反映了我们的[模型不确定性](@entry_id:265539) [@problem_BCE_3289324]。

#### 收敛性诊断

我们如何判断MCMC链是否已经“忘记”其初始状态并收敛到平稳分布？一个可靠的方法是并行运行多条（例如，$m \ge 4$）从参数空间中不同、过度分散的位置开始的链。如果所有链都收敛到相同的[分布](@entry_id:182848)，那么它们应该看起来彼此不可区分。

**[潜在尺度缩减因子](@entry_id:753645)（$\hat{R}$）**，也称为[Gelman-Rubin诊断](@entry_id:749773)，量化了这一思想 。它比较了链间[方差](@entry_id:200758)（between-chain variance, $B$）和链内[方差](@entry_id:200758)（within-chain variance, $W$）。$W$ 是每条链[方差](@entry_id:200758)的平均值，而 $B$ 是各链均值的[方差](@entry_id:200758)（经过样本量 $n$ 的缩放）。
$$
W = \frac{1}{m}\sum_{j=1}^m s_j^2 \quad \text{and} \quad B = \frac{n}{m-1}\sum_{j=1}^m (\bar{\theta}_j - \bar{\theta}_\cdot)^2
$$
总后验[方差](@entry_id:200758)的一个估计是 $\hat{\sigma}_+^2 = \frac{n-1}{n}W + \frac{1}{n}B$。$\hat{R}$ 被定义为：
$$
\hat{R} = \sqrt{\frac{\hat{\sigma}_+^2}{W}}
$$
当链收敛时，$B$ 趋于零，$\hat{\sigma}_+^2$ 趋于 $W$，因此 $\hat{R}$ 趋于1。通常，我们要求所有参数的 $\hat{R}$ 值都接近1（例如，小于1.01）才认为收敛性得到了保证。

#### 评估采样器效率与“稀疏化”的误区

MCMC样本不是独立的，它们存在自相关。**[有效样本量](@entry_id:271661)**（Effective Sample Size, ESS）衡量了 $N$ 个相关的MCMC样本所包含的[信息量](@entry_id:272315)相当于多少个独立的样本。ESS由下式给出 ：
$$
\operatorname{ESS} = \frac{N}{1 + 2\sum_{k=1}^\infty \rho_k}
$$
其中 $\rho_k$ 是样本的滞后-$k$ [自相关](@entry_id:138991)。ESS越接近总样本数 $N$，采样器的效率就越高。

一个历史上常见的做法是**稀疏化**（thinning），即每隔 $m$ 个样本才保留一个，以期“减少自相关”和节省存储空间。然而，这是一个普遍的误区 。对于固定的[模拟计算](@entry_id:273038)预算（即固定的总样本数 $N$），稀疏化会丢弃信息。虽然稀疏化后的样本[自相关](@entry_id:138991)性确实降低了，但样本总数也减少了 $m$ 倍。精确的[数学分析](@entry_id:139664)表明，稀疏化几乎总是导致ESS的净损失，从而降低了估计的[统计效率](@entry_id:164796)（即增加了[蒙特卡洛](@entry_id:144354)误差）[@problem_id:3289317, @problem_id:BCE_3289317]。

那么，如果存储空间是一个问题，我们该怎么办？现代的推荐做法是 [@problem_id:3289317, @problem_id:BCE_3289317]：
*   **不进行稀疏化**：保留所有样本以最大化ESS。
*   **流式处理和批处理**：如果无法将所有样本载入内存，可以“流式”处理它们，即顺序读取并在线计算所需的统计量。例如，可以使用**[批均值](@entry_id:746697)**（batch means）方法来估计[蒙特卡洛标准误差](@entry_id:752176)（MCSE）。将整个链分成若干个不重叠的批次，计算每个批次的均值，然后计算这些[批均值](@entry_id:746697)的[方差](@entry_id:200758)。这是一种估计真实采样[方差](@entry_id:200758)的有效方法。
*   **压缩存储**：使用高效的二进制格式和压缩算法来存储原始样本。

通过遵循这些原则，我们可以在不牺牲[统计效率](@entry_id:164796)的前提下，处理大规模MCMC的输出，并对我们的[贝叶斯推断](@entry_id:146958)结果的准确性和不确定性做出可靠的评估。