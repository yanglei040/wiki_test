{
    "hands_on_practices": [
        {
            "introduction": "The journey from a set of fitted models to a principled model choice begins with a core calculation. This exercise guides you through converting a model's maximized log-likelihood and its complexity, measured by the number of parameters, into the Akaike and Bayesian Information Criteria (AIC and BIC). By working through a realistic scenario from single-cell transcriptomics, you will practice computing these criteria and the resulting Akaike weights to quantitatively compare competing statistical models for gene expression .",
            "id": "3326796",
            "problem": "A single-cell transcriptomics experiment measures molecule counts for a single gene across $n$ cells. You are tasked with selecting among three candidate count models for this gene, each fitted by maximum likelihood as a Generalized Linear Model (GLM): a Poisson GLM, a Negative Binomial GLM, and a Zero-Inflated Negative Binomial GLM. Let the sample size be $n = 300$. For these candidates, the maximized log-likelihoods and the numbers of free parameters are as follows (all fits are to the same data, and all models use a log-link with a gene-specific intercept; the Negative Binomial GLM includes a dispersion parameter, and the Zero-Inflated Negative Binomial GLM further includes a zero-inflation parameter):\n- Poisson GLM: maximized log-likelihood $\\ell_{\\mathrm{P}} = -1185.7$, parameter count $k_{\\mathrm{P}} = 1$.\n- Negative Binomial GLM: maximized log-likelihood $\\ell_{\\mathrm{NB}} = -805.3$, parameter count $k_{\\mathrm{NB}} = 2$.\n- Zero-Inflated Negative Binomial GLM: maximized log-likelihood $\\ell_{\\mathrm{ZINB}} = -799.9$, parameter count $k_{\\mathrm{ZINB}} = 3$.\n\nStarting from the definition of the Kullback–Leibler divergence between the unknown true data-generating density and a candidate model, and using the large-sample behavior of maximum likelihood estimators together with the Laplace approximation to the marginal likelihood, proceed as follows:\n1. Derive the comparative forms of the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) appropriate for models fitted by maximum likelihood on the same dataset of size $n$, justifying each penalty term from first principles.\n2. Using your derived expressions, compute the AIC and BIC values for each model, then compute the AIC differences $\\Delta \\mathrm{AIC}_{i}$ and BIC differences $\\Delta \\mathrm{BIC}_{i}$ by subtracting the minimum value across models for each criterion.\n3. Using the $\\Delta \\mathrm{AIC}_{i}$ values, compute the Akaike weights for each model to quantify their relative support.\n4. Finally, report the Akaike weight of the model with the strongest support. Round your final reported value to four significant figures. Do not include any units.",
            "solution": "The problem statement is scientifically grounded, self-contained, and well-posed, permitting a rigorous solution. It concerns the selection of statistical models for count data, a standard task in computational systems biology, using established information criteria. All necessary data are provided.\n\n**1. Derivation of AIC and BIC**\n\nThe goal of model selection is to choose a model that best approximates the true, unknown data-generating process. This is often framed as selecting the model that minimizes the information lost when approximating the true distribution, a quantity measured by the Kullback–Leibler (KL) divergence.\n\nLet the true, unknown density of the data be $f(x)$. Let a candidate model be represented by the density $g(x|\\theta)$, where $\\theta$ is a vector of $k$ parameters. The KL divergence from $g$ to $f$ is:\n$$D_{\\mathrm{KL}}(f || g) = \\int f(x) \\ln\\left(\\frac{f(x)}{g(x|\\theta)}\\right) dx = \\mathbb{E}_{f}[\\ln(f(x))] - \\mathbb{E}_{f}[\\ln(g(x|\\theta))]$$\nSince $\\mathbb{E}_{f}[\\ln(f(x))]$ is constant across all candidate models, minimizing $D_{\\mathrm{KL}}(f || g)$ is equivalent to maximizing the expected log-likelihood of the model, $\\mathbb{E}_{f}[\\ln(g(x|\\theta))]$. The parameter vector $\\theta$ is unknown and is estimated from the data, typically by maximizing the log-likelihood function, which yields the maximum likelihood estimate (MLE), $\\hat{\\theta}$. The quantity we wish to estimate is the predictive accuracy of the fitted model $g(x|\\hat{\\theta})$ on new data drawn from $f(x)$.\n\n**Akaike Information Criterion (AIC)**\nThe AIC is derived as an asymptotically unbiased estimator of the relative expected KL divergence. The maximized log-likelihood, $\\ell(\\hat{\\theta}) = \\sum_{i=1}^{n} \\ln(g(x_i|\\hat{\\theta}))$, based on the training data $\\{x_i\\}_{i=1}^n$, is a biased estimator of the expected log-likelihood on new data. Akaike showed that, for large samples, the expected bias is approximately equal to the number of free parameters, $k$.\n$$\\mathbb{E}[\\ell(\\hat{\\theta}) - \\mathbb{E}_{y}[\\ln g(y|\\hat{\\theta})]] \\approx k$$\nwhere the outer expectation is over datasets of size $n$ from $f$, and the inner expectation is over a new data point $y$ from $f$. An approximately unbiased estimator for the target quantity, $\\mathbb{E}_{y}[\\ln g(y|\\hat{\\theta})]$, is therefore $\\ell(\\hat{\\theta}) - k$.\nAs information criteria are conventionally defined as quantities to be minimized, Akaike defined his criterion by multiplying this by $-2$:\n$$\\mathrm{AIC} = -2 (\\ell(\\hat{\\theta}) - k) = -2\\ell(\\hat{\\theta}) + 2k$$\nThe penalty term $2k$ corrects for the optimistic bias of the in-sample maximized log-likelihood.\n\n**Bayesian Information Criterion (BIC)**\nThe BIC is derived from a Bayesian perspective, aiming to select the model with the highest posterior probability. Given a set of models $\\{M_j\\}$, we want to find the one that maximizes $P(M_j | \\text{data})$. By Bayes' theorem, $P(M_j | \\text{data}) \\propto P(\\text{data} | M_j) P(M_j)$, where $P(\\text{data} | M_j)$ is the marginal likelihood (or model evidence) and $P(M_j)$ is the prior probability of the model. Assuming equal priors, selecting the best model is equivalent to maximizing the marginal likelihood:\n$$P(\\text{data} | M_j) = \\int P(\\text{data} | \\theta_j, M_j) P(\\theta_j | M_j) d\\theta_j$$\nwhere $\\theta_j$ is the parameter vector for model $M_j$, $P(\\text{data} | \\theta_j, M_j)$ is the likelihood $L(\\theta_j)$, and $P(\\theta_j | M_j)$ is the parameter prior. This integral is often intractable. For a large sample size $n$, we can approximate it using the Laplace approximation. The logarithm of the integrand, $\\ln(L(\\theta_j)P(\\theta_j))$, is Taylor-expanded around the maximum a posteriori (MAP) estimate $\\tilde{\\theta}_j$. For large $n$, the likelihood dominates the prior, so $\\tilde{\\theta}_j \\approx \\hat{\\theta}_j$ (the MLE), and we can approximate $\\ln(L(\\theta_j)P(\\theta_j)) \\approx \\ln(L(\\theta_j)) = \\ell(\\theta_j)$.\nThe approximation for the log marginal likelihood becomes:\n$$\\ln P(\\text{data} | M_j) \\approx \\ell(\\hat{\\theta}_j) - \\frac{k_j}{2} \\ln(n)$$\nwhere $k_j$ is the number of parameters in model $M_j$. This approximation discards terms that do not increase with $n$. Like AIC, BIC is conventionally defined to be minimized and is scaled by $-2$:\n$$\\mathrm{BIC} = -2 \\ln P(\\text{data} | M_j) \\approx -2\\ell(\\hat{\\theta}_j) + k_j \\ln(n)$$\nThe penalty term $k_j \\ln(n)$ penalizes model complexity more strongly than AIC for any $n > e^2 \\approx 7.4$.\n\n**2. Calculation of AIC, BIC, and their Differences**\n\nThe given data are:\n- Sample size: $n = 300$.\n- Poisson (P): $\\ell_{\\mathrm{P}} = -1185.7$, $k_{\\mathrm{P}} = 1$.\n- Negative Binomial (NB): $\\ell_{\\mathrm{NB}} = -805.3$, $k_{\\mathrm{NB}} = 2$.\n- Zero-Inflated Negative Binomial (ZINB): $\\ell_{\\mathrm{ZINB}} = -799.9$, $k_{\\mathrm{ZINB}} = 3$.\n\nWe first calculate the AIC values using $\\mathrm{AIC} = -2\\ell + 2k$:\n- $\\mathrm{AIC}_{\\mathrm{P}} = -2(-1185.7) + 2(1) = 2371.4 + 2 = 2373.4$\n- $\\mathrm{AIC}_{\\mathrm{NB}} = -2(-805.3) + 2(2) = 1610.6 + 4 = 1614.6$\n- $\\mathrm{AIC}_{\\mathrm{ZINB}} = -2(-799.9) + 2(3) = 1599.8 + 6 = 1605.8$\n\nThe minimum AIC value is $\\mathrm{AIC}_{\\min} = 1605.8$, corresponding to the ZINB model. The AIC differences are $\\Delta \\mathrm{AIC}_{i} = \\mathrm{AIC}_{i} - \\mathrm{AIC}_{\\min}$:\n- $\\Delta \\mathrm{AIC}_{\\mathrm{P}} = 2373.4 - 1605.8 = 767.6$\n- $\\Delta \\mathrm{AIC}_{\\mathrm{NB}} = 1614.6 - 1605.8 = 8.8$\n- $\\Delta \\mathrm{AIC}_{\\mathrm{ZINB}} = 1605.8 - 1605.8 = 0$\n\nNext, we calculate the BIC values using $\\mathrm{BIC} = -2\\ell + k \\ln(n)$. For $n=300$, $\\ln(300) \\approx 5.70378$.\n- $\\mathrm{BIC}_{\\mathrm{P}} = -2(-1185.7) + (1)\\ln(300) \\approx 2371.4 + 5.70378 = 2377.10378$\n- $\\mathrm{BIC}_{\\mathrm{NB}} = -2(-805.3) + (2)\\ln(300) \\approx 1610.6 + 2(5.70378) = 1610.6 + 11.40756 = 1622.00756$\n- $\\mathrm{BIC}_{\\mathrm{ZINB}} = -2(-799.9) + (3)\\ln(300) \\approx 1599.8 + 3(5.70378) = 1599.8 + 17.11134 = 1616.91134$\n\nThe minimum BIC value is $\\mathrm{BIC}_{\\min} = 1616.91134$, also corresponding to the ZINB model. The BIC differences are $\\Delta \\mathrm{BIC}_{i} = \\mathrm{BIC}_{i} - \\mathrm{BIC}_{\\min}$:\n- $\\Delta \\mathrm{BIC}_{\\mathrm{P}} \\approx 2377.10378 - 1616.91134 = 760.19244$\n- $\\Delta \\mathrm{BIC}_{\\mathrm{NB}} \\approx 1622.00756 - 1616.91134 = 5.09622$\n- $\\Delta \\mathrm{BIC}_{\\mathrm{ZINB}} \\approx 1616.91134 - 1616.91134 = 0$\n\n**3. Calculation of Akaike Weights**\n\nThe Akaike weight $w_i$ for model $i$ quantifies the relative likelihood of the model being the best approximating model, given the data and the set of candidate models. It is calculated from the $\\Delta \\mathrm{AIC}_i$ values:\n$$w_i = \\frac{\\exp(-\\frac{1}{2}\\Delta \\mathrm{AIC}_i)}{\\sum_{j=1}^{3} \\exp(-\\frac{1}{2}\\Delta \\mathrm{AIC}_j)}$$\nThe sum in the denominator is:\n$$S = \\exp(-\\frac{1}{2}\\Delta \\mathrm{AIC}_{\\mathrm{P}}) + \\exp(-\\frac{1}{2}\\Delta \\mathrm{AIC}_{\\mathrm{NB}}) + \\exp(-\\frac{1}{2}\\Delta \\mathrm{AIC}_{\\mathrm{ZINB}})$$\n$$S = \\exp(-\\frac{1}{2}(767.6)) + \\exp(-\\frac{1}{2}(8.8)) + \\exp(-\\frac{1}{2}(0))$$\n$$S = \\exp(-383.8) + \\exp(-4.4) + \\exp(0)$$\nThe term $\\exp(-383.8)$ is negligibly small (effectively zero).\n$$S \\approx 0 + 0.012277 + 1 = 1.012277$$\nNow we compute the individual weights:\n- $w_{\\mathrm{P}} = \\frac{\\exp(-383.8)}{S} \\approx 0$\n- $w_{\\mathrm{NB}} = \\frac{\\exp(-4.4)}{S} \\approx \\frac{0.012277}{1.012277} \\approx 0.012128$\n- $w_{\\mathrm{ZINB}} = \\frac{\\exp(0)}{S} = \\frac{1}{S} \\approx \\frac{1}{1.012277} \\approx 0.987872$\n\n**4. Final Answer**\n\nThe model with the strongest support is the ZINB model, as it has the lowest AIC (and BIC) value, and consequently the highest Akaike weight. The Akaike weight for the ZINB model is approximately $0.987872$. Rounding this value to four significant figures gives $0.9879$. This indicates that, given the data and the three candidate models, there is a $98.79\\%$ probability that the ZINB model is the best approximating model among the choices.",
            "answer": "$$\n\\boxed{0.9879}\n$$"
        },
        {
            "introduction": "Model selection should not be an all-or-nothing decision, as simply choosing the model with the best score and discarding the others ignores the uncertainty inherent in the selection process. This practice introduces model averaging, a powerful technique that uses Akaike weights to create a composite prediction from an entire set of candidate models. This approach often leads to more robust and accurate results by hedging against the risk of choosing the wrong model .",
            "id": "3326746",
            "problem": "A mitogen-activated protein kinase (MAPK) cascade model is used to predict the fraction of phosphorylated extracellular signal-regulated kinase (ERK) at time $t = 10$ minutes following stimulation with epidermal growth factor. Three mechanistic candidate models are considered: $M_1$ (mass-action without feedback), $M_2$ (mass-action with negative feedback), and $M_3$ (scaffold-mediated sequestration). Each model was previously calibrated on a distinct training dataset; the resulting Akaike Information Criterion (AIC) scores yield differences relative to the best model of $\\Delta \\mathrm{AIC}$ values: $M_1$ has $\\Delta_1 = 0$, $M_2$ has $\\Delta_2 = 2$, and $M_3$ has $\\Delta_3 = 4$. For the present condition (stimulus concentration fixed and matched across models), the point predictions for the fraction of phosphorylated ERK at $t = 10$ minutes are:\n- $M_1$: $0.70$ (arbitrary units),\n- $M_2$: $0.55$ (arbitrary units),\n- $M_3$: $0.60$ (arbitrary units).\n\nUsing a principled information-theoretic approach grounded in the Akaike Information Criterion, compute the Akaike weights for the three models and then form the model-averaged prediction of the phosphorylated ERK fraction at $t = 10$ minutes by weighting each model’s prediction by its corresponding weight. Report only the final model-averaged phosphorylation level as a pure number, rounded to four significant figures. Express the conceptual unit as arbitrary units (a.u.), but do not include units in your final numerical answer.",
            "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information to compute a unique solution. It is a direct application of model averaging using the Akaike Information Criterion (AIC).\n\nThe three candidate models are denoted as $M_1$, $M_2$, and $M_3$. The problem provides the differences in AIC scores relative to the best model in the set ($\\mathrm{AIC}_{\\min}$), denoted as $\\Delta_i = \\mathrm{AIC}_i - \\mathrm{AIC}_{\\min}$. The given values are:\n- For model $M_1$: $\\Delta_1 = 0$\n- For model $M_2$: $\\Delta_2 = 2$\n- For model $M_3$: $\\Delta_3 = 4$\n\nThe point predictions for the fraction of phosphorylated ERK at time $t = 10$ minutes are:\n- For model $M_1$: $y_1 = 0.70$\n- For model $M_2$: $y_2 = 0.55$\n- For model $M_3$: $y_3 = 0.60$\n\nThe first step is to calculate the Akaike weight, $w_i$, for each model $i$. The Akaike weight represents the probability that model $i$ is the best model in the set of candidate models, given the data. The formula for the Akaike weight of model $i$ is:\n$$w_i = \\frac{\\exp(-\\frac{1}{2} \\Delta_i)}{\\sum_{j=1}^{R} \\exp(-\\frac{1}{2} \\Delta_j)}$$\nwhere $R$ is the total number of candidate models. In this case, $R = 3$.\n\nWe first calculate the term $\\exp(-\\frac{1}{2} \\Delta_i)$ for each model. This term is proportional to the relative likelihood of the model.\n- For $M_1$: $\\exp(-\\frac{1}{2} \\Delta_1) = \\exp(-\\frac{1}{2} \\cdot 0) = \\exp(0) = 1$.\n- For $M_2$: $\\exp(-\\frac{1}{2} \\Delta_2) = \\exp(-\\frac{1}{2} \\cdot 2) = \\exp(-1)$.\n- For $M_3$: $\\exp(-\\frac{1}{2} \\Delta_3) = \\exp(-\\frac{1}{2} \\cdot 4) = \\exp(-2)$.\n\nNext, we calculate the sum in the denominator, which is the normalization factor ensuring that the weights sum to $1$:\n$$S = \\sum_{j=1}^{3} \\exp(-\\frac{1}{2} \\Delta_j) = \\exp(-\\frac{1}{2} \\Delta_1) + \\exp(-\\frac{1}{2} \\Delta_2) + \\exp(-\\frac{1}{2} \\Delta_3)$$\n$$S = 1 + \\exp(-1) + \\exp(-2)$$\n\nNow we can compute the individual Akaike weights:\n- $w_1 = \\frac{\\exp(-\\frac{1}{2} \\Delta_1)}{S} = \\frac{1}{1 + \\exp(-1) + \\exp(-2)}$\n- $w_2 = \\frac{\\exp(-\\frac{1}{2} \\Delta_2)}{S} = \\frac{\\exp(-1)}{1 + \\exp(-1) + \\exp(-2)}$\n- $w_3 = \\frac{\\exp(-\\frac{1}{2} \\Delta_3)}{S} = \\frac{\\exp(-2)}{1 + \\exp(-1) + \\exp(-2)}$\n\nThe final step is to compute the model-averaged prediction for the phosphorylated ERK fraction, $\\hat{y}_{\\text{avg}}$. This is the weighted average of the predictions from each model, where the weights are the Akaike weights:\n$$\\hat{y}_{\\text{avg}} = \\sum_{i=1}^{3} w_i y_i = w_1 y_1 + w_2 y_2 + w_3 y_3$$\n\nSubstituting the expressions for the weights and the given predictions:\n$$\\hat{y}_{\\text{avg}} = \\left(\\frac{1}{S}\\right) y_1 + \\left(\\frac{\\exp(-1)}{S}\\right) y_2 + \\left(\\frac{\\exp(-2)}{S}\\right) y_3$$\n$$\\hat{y}_{\\text{avg}} = \\frac{y_1 + y_2 \\exp(-1) + y_3 \\exp(-2)}{1 + \\exp(-1) + \\exp(-2)}$$\n\nWe now substitute the numerical values for the predictions $y_1=0.70$, $y_2=0.55$, and $y_3=0.60$:\n$$\\hat{y}_{\\text{avg}} = \\frac{0.70 \\cdot 1 + 0.55 \\cdot \\exp(-1) + 0.60 \\cdot \\exp(-2)}{1 + \\exp(-1) + \\exp(-2)}$$\n\nTo obtain the final numerical answer, we use the approximate values for the exponential function:\n$\\exp(-1) \\approx 0.367879$\n$\\exp(-2) \\approx 0.135335$\n\nThe denominator is:\n$S \\approx 1 + 0.367879 + 0.135335 = 1.503214$\n\nThe numerator is:\n$N \\approx 0.70 + 0.55 \\cdot (0.367879) + 0.60 \\cdot (0.135335)$\n$N \\approx 0.70 + 0.20233345 + 0.081201$\n$N \\approx 0.98353445$\n\nThe model-averaged prediction is:\n$$\\hat{y}_{\\text{avg}} = \\frac{N}{S} \\approx \\frac{0.98353445}{1.503214} \\approx 0.654289$$\n\nThe problem requires the answer to be rounded to four significant figures. The fifth significant figure is $8$, so we round up the fourth digit.\n$$\\hat{y}_{\\text{avg}} \\approx 0.6543$$\nThis is the model-averaged prediction for the fraction of phosphorylated ERK at $t=10$ minutes, expressed in arbitrary units.",
            "answer": "$$\\boxed{0.6543}$$"
        },
        {
            "introduction": "The choice between information criteria is not always straightforward and can depend critically on the size of your dataset, a common issue in systems biology where data can be sparse. This exercise delves into the important small-sample regime by comparing the Bayesian Information Criterion (BIC) with the corrected Akaike Information Criterion (AICc), which is specifically designed for situations where the number of data points $n$ is not much larger than the number of parameters $p$. By implementing these criteria, you will investigate how their different penalty terms can lead to different conclusions and learn when to apply the small-sample correction .",
            "id": "3326821",
            "problem": "Consider fitting two candidate nonlinear Ordinary Differential Equation (ODE) models to sparse single-cell time-course data in computational systems biology. Let the observed data be $\\{(t_i, y_i)\\}_{i=1}^n$ from a single cell, where $t_i$ are time points and $y_i$ are measured molecular abundances. Each model $M_j$ with parameter vector $\\theta_j \\in \\mathbb{R}^{p_j}$ yields a numerical solution $x_{\\theta_j}(t)$ of an ODE system and corresponding predicted values $x_{\\theta_j}(t_i)$ at measurement times. Assume the residuals are independent and identically distributed Gaussian with zero mean and unknown variance, i.e., $y_i = x_{\\theta_j}(t_i) + \\varepsilon_i$ with $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$, and define the residual sum of squares $\\mathrm{SSE}_j = \\sum_{i=1}^n (y_i - x_{\\theta_j}(t_i))^2$ for model $M_j$.\n\nStarting from the principles of maximum likelihood under the Gaussian noise model and information-theoretic model selection, derive simplified expressions (up to additive constants that are the same across competing models) for the Bayesian Information Criterion (BIC) and the small-sample corrected Akaike Information Criterion ($\\mathrm{AIC}_c$) as functions of $n$, $p_j$, and $\\mathrm{SSE}_j$. Use these expressions to implement a program that, for each test case, determines:\n- which model is selected by BIC between $M_1$ and $M_2$,\n- which model is selected by $\\mathrm{AIC}_c$ between $M_1$ and $M_2$ (declare $\\mathrm{AIC}_c$ undefined if $n \\le p_j + 1$ for either candidate),\n- whether $\\mathrm{AIC}_c$ reverses the selection made by BIC due to small-sample penalties, defined as a boolean that is $true$ if BIC and $\\mathrm{AIC}_c$ select different models and $\\mathrm{AIC}_c$ is defined, and $false$ otherwise.\n\nFundamental base to use:\n- Maximum likelihood estimation for independent Gaussian residuals with unknown variance.\n- Information criteria definitions based on expected Kullback–Leibler divergence for Akaike Information Criterion (AIC) and on Laplace approximation to the marginal likelihood for Bayesian Information Criterion (BIC).\n- The small-sample correction leading to $\\mathrm{AIC}_c$.\n\nYour program should implement the derived formulas and apply them to the following test suite of parameter values. Each test case is a $5$-tuple $(n, p_1, p_2, \\mathrm{SSE}_1, \\mathrm{SSE}_2)$:\n\n- Case $1$: $(n, p_1, p_2, \\mathrm{SSE}_1, \\mathrm{SSE}_2) = (\\,60,\\,5,\\,9,\\,120.0,\\,95.0\\,)$.\n- Case $2$: $(n, p_1, p_2, \\mathrm{SSE}_1, \\mathrm{SSE}_2) = (\\,12,\\,3,\\,9,\\,120.0,\\,32.0\\,)$.\n- Case $3$: $(n, p_1, p_2, \\mathrm{SSE}_1, \\mathrm{SSE}_2) = (\\,20,\\,7,\\,8,\\,110.0,\\,90.0\\,)$.\n- Case $4$: $(n, p_1, p_2, \\mathrm{SSE}_1, \\mathrm{SSE}_2) = (\\,100,\\,6,\\,9,\\,200.0,\\,150.0\\,)$.\n- Case $5$: $(n, p_1, p_2, \\mathrm{SSE}_1, \\mathrm{SSE}_2) = (\\,10,\\,3,\\,9,\\,80.0,\\,60.0\\,)$.\n- Case $6$: $(n, p_1, p_2, \\mathrm{SSE}_1, \\mathrm{SSE}_2) = (\\,15,\\,5,\\,10,\\,100.0,\\,85.0\\,)$.\n\nDesign for coverage:\n- The test suite includes a general case where $n$ moderately exceeds $p_j$, boundary cases where $p_j$ approaches $n$, and a case where $\\mathrm{AIC}_c$ is undefined due to $n \\le p_j + 1$.\n\nFinal output format:\n- Your program should produce a single line of output containing the reversal booleans for the six cases as a comma-separated list enclosed in square brackets, for example $\\texttt{[true,false,...]}$. Use Python boolean literals $\\texttt{True}$ and $\\texttt{False}$ in the output.\n\nNo external input should be read; all computations must be performed using the provided test suite values.",
            "solution": "The problem requires the derivation of simplified expressions for the Bayesian Information Criterion (BIC) and the small-sample corrected Akaike Information Criterion ($\\mathrm{AIC}_c$) for the purpose of selecting between two nonlinear Ordinary Differential Equation (ODE) models fitted to time-course data. The derivation begins from the principle of maximum likelihood under the assumption of independent and identically distributed Gaussian noise.\n\nLet the observed data be $\\{ (t_i, y_i) \\}_{i=1}^n$. For a given model $M_j$ with parameter vector $\\theta_j$ of dimension $p_j$, the predicted value at time $t_i$ is $x_{\\theta_j}(t_i)$. The residuals are assumed to follow a normal distribution, $\\varepsilon_i = y_i - x_{\\theta_j}(t_i) \\sim \\mathcal{N}(0, \\sigma^2)$, with unknown variance $\\sigma^2$.\n\nFirst, we formulate the likelihood function. The probability density for a single observation $y_i$ is:\n$$\nP(y_i | \\theta_j, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - x_{\\theta_j}(t_i))^2}{2\\sigma^2}\\right)\n$$\nAssuming independence, the likelihood for the entire dataset $\\mathbf{y} = \\{y_1, \\dots, y_n\\}$ is the product of individual probabilities:\n$$\nL(\\theta_j, \\sigma^2 | \\mathbf{y}) = \\prod_{i=1}^n P(y_i | \\theta_j, \\sigma^2) = (2\\pi\\sigma^2)^{-n/2} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - x_{\\theta_j}(t_i))^2\\right)\n$$\nUsing the definition of the residual sum of squares, $\\mathrm{SSE}_j = \\sum_{i=1}^n (y_i - x_{\\theta_j}(t_i))^2$, the likelihood becomes:\n$$\nL(\\theta_j, \\sigma^2 | \\mathbf{y}) = (2\\pi\\sigma^2)^{-n/2} \\exp\\left(-\\frac{\\mathrm{SSE}_j}{2\\sigma^2}\\right)\n$$\nThe log-likelihood function, $\\ln L$, is more convenient for maximization:\n$$\n\\ln L(\\theta_j, \\sigma^2 | \\mathbf{y}) = -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln(\\sigma^2) - \\frac{\\mathrm{SSE}_j}{2\\sigma^2}\n$$\nTo find the maximum likelihood estimates (MLEs), we maximize this function with respect to the parameters. The problem provides $\\mathrm{SSE}_j$ which is evaluated at the MLE of the model parameters, $\\hat{\\theta}_j$. We must also find the MLE for the variance, $\\hat{\\sigma}^2$. Taking the partial derivative with respect to $\\sigma^2$ and setting it to zero yields:\n$$\n\\frac{\\partial (\\ln L)}{\\partial (\\sigma^2)} = -\\frac{n}{2\\sigma^2} + \\frac{\\mathrm{SSE}_j}{2(\\sigma^2)^2} = 0 \\implies \\hat{\\sigma}_j^2 = \\frac{\\mathrm{SSE}_j}{n}\n$$\nSubstituting the MLEs $\\hat{\\theta}_j$ (which gives $\\mathrm{SSE}_j$) and $\\hat{\\sigma}_j^2$ back into the log-likelihood function gives the maximized log-likelihood, $\\mathcal{L}_j$:\n$$\n\\mathcal{L}_j = \\ln L(\\hat{\\theta}_j, \\hat{\\sigma}_j^2 | \\mathbf{y}) = -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln\\left(\\frac{\\mathrm{SSE}_j}{n}\\right) - \\frac{\\mathrm{SSE}_j}{2(\\mathrm{SSE}_j/n)} = -\\frac{n}{2}\\left( \\ln(2\\pi) + \\ln\\left(\\frac{\\mathrm{SSE}_j}{n}\\right) + 1 \\right)\n$$\nThis maximized log-likelihood, $\\mathcal{L}_j$, is the fundamental quantity for both information criteria. The total number of estimated parameters for model $M_j$ is $k_j = p_j + 1$, which includes the $p_j$ parameters in $\\theta_j$ and the variance $\\sigma^2$.\n\nThe Bayesian Information Criterion (BIC) is defined as:\n$$\n\\mathrm{BIC}_j = -2\\mathcal{L}_j + k_j \\ln(n)\n$$\nSubstituting the expressions for $\\mathcal{L}_j$ and $k_j$:\n$$\n\\mathrm{BIC}_j = n\\left( \\ln(2\\pi) + \\ln\\left(\\frac{\\mathrm{SSE}_j}{n}\\right) + 1 \\right) + (p_j+1)\\ln(n)\n$$\n$$\n\\mathrm{BIC}_j = n\\ln(2\\pi) + n\\ln(\\mathrm{SSE}_j) - n\\ln(n) + n + (p_j+1)\\ln(n)\n$$\nFor comparing models $M_1$ and $M_2$ on the same dataset (fixed $n$), terms that are constant across models can be dropped. These terms are $n\\ln(2\\pi)$, $-n\\ln(n)$, and $n$. This leaves a simplified expression proportional to the true BIC, sufficient for model selection:\n$$\n\\mathrm{BIC}_j \\propto n\\ln(\\mathrm{SSE}_j) + (p_j+1)\\ln(n)\n$$\nThe model with the lower BIC value is preferred.\n\nThe small-sample corrected Akaike Information Criterion ($\\mathrm{AIC}_c$) is defined as:\n$$\n\\mathrm{AIC}_{c,j} = \\mathrm{AIC}_j + \\frac{2k_j(k_j+1)}{n-k_j-1}\n$$\nwhere $\\mathrm{AIC}_j = -2\\mathcal{L}_j + 2k_j$. Substituting for $\\mathcal{L}_j$ and $k_j$:\n$$\n\\mathrm{AIC}_{c,j} = n\\left( \\ln(2\\pi) + \\ln\\left(\\frac{\\mathrm{SSE}_j}{n}\\right) + 1 \\right) + 2(p_j+1) + \\frac{2(p_j+1)(p_j+2)}{n-(p_j+1)-1}\n$$\nAgain, we simplify for comparison by dropping terms constant across models ($n\\ln(2\\pi)$, $-n\\ln(n)$, and $n$):\n$$\n\\mathrm{AIC}_{c,j} \\propto n\\ln(\\mathrm{SSE}_j) + 2(p_j+1) + \\frac{2(p_j+1)(p_j+2)}{n-p_j-2}\n$$\nThe model with the lower $\\mathrm{AIC}_c$ value is preferred. As specified, $\\mathrm{AIC}_c$ is considered undefined if $n \\le p_j+1$ for either model under consideration. A reversal occurs if BIC and $\\mathrm{AIC}_c$ select different models and $\\mathrm{AIC}_c$ is defined for the comparison.\n\nTo implement the solution, the following formulas will be used for each test case $(n, p_1, p_2, \\mathrm{SSE}_1, \\mathrm{SSE}_2)$:\n1. Calculate $\\mathrm{BIC}_1$ and $\\mathrm{BIC}_2$ using $\\mathrm{BIC}_j \\propto n\\ln(\\mathrm{SSE}_j) + (p_j+1)\\ln(n)$ and determine the model with the minimum value.\n2. Check if $\\mathrm{AIC}_c$ is defined for the comparison, i.e., if $n > p_1+1$ and $n > p_2+1$.\n3. If defined, calculate $\\mathrm{AIC}_{c,1}$ and $\\mathrm{AIC}_{c,2}$ using $\\mathrm{AIC}_{c,j} \\propto n\\ln(\\mathrm{SSE}_j) + 2(p_j+1) + \\frac{2(p_j+1)(p_j+2)}{n-p_j-2}$ and determine the model with the minimum value.\n4. Compare the selections. If $\\mathrm{AIC}_c$ is defined and the selections differ, a reversal has occurred. Otherwise, it has not.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates model selection outcomes for a series of test cases using BIC and AICc,\n    and determines if AICc reverses the selection made by BIC.\n    \"\"\"\n    # Test cases as 5-tuples: (n, p1, p2, SSE1, SSE2)\n    # n: number of data points\n    # p1, p2: number of parameters for model 1 and model 2\n    # SSE1, SSE2: residual sum of squares for model 1 and model 2\n    test_cases = [\n        (60, 5, 9, 120.0, 95.0),\n        (12, 3, 9, 120.0, 32.0),\n        (20, 7, 8, 110.0, 90.0),\n        (100, 6, 9, 200.0, 150.0),\n        (10, 3, 9, 80.0, 60.0),\n        (15, 5, 10, 100.0, 85.0),\n    ]\n\n    reversal_results = []\n\n    for case in test_cases:\n        n, p1, p2, sse1, sse2 = case\n\n        # The total number of estimated parameters for model j, k_j, is p_j + 1\n        # (p_j model parameters + 1 variance parameter sigma^2).\n        k1 = p1 + 1\n        k2 = p2 + 1\n\n        # --- BIC Selection ---\n        # The simplified BIC formula for model comparison is:\n        # BIC_j = n * ln(SSE_j) + k_j * ln(n)\n        bic1 = n * np.log(sse1) + k1 * np.log(n)\n        bic2 = n * np.log(sse2) + k2 * np.log(n)\n        bic_selection = 1 if bic1 < bic2 else 2\n\n        # --- AICc Selection ---\n        # The problem states AICc is undefined if n = p_j + 1 for either model.\n        # This also implies n > k_j for both models.\n        # The denominator of the correction term is n - k_j - 1.\n        # The condition n > p_j + 1 means n >= p_j + 2, or n >= k_j + 1.\n        # This ensures the denominator n - k_j - 1 >= 0.\n        # The standard definition requires n - k_j - 1 > 0, which is n > p_j + 2.\n        # Case 5 has n=10, p2=9, so n = p2+1 and AICc is undefined as per problem.\n        aicc_is_defined = (n > p1 + 1) and (n > p2 + 1)\n\n        aicc_selection = None\n        if aicc_is_defined:\n            # The simplified AICc formula for model comparison is:\n            # AICc_j = n * ln(SSE_j) + 2*k_j + (2*k_j*(k_j+1)) / (n-k_j-1)\n            \n            # Check for non-positive denominator to avoid division by zero or negative.\n            # This is a safeguard, though the problem condition n > p_j + 1\n            # handles the provided test cases.\n            if (n - k1 - 1) = 0 or (n - k2 - 1) = 0:\n                 # This branch is not expected to be hit with problem's test data\n                 # and the n = p_j + 1 rule, but is good practice.\n                 aicc_is_defined = False\n            else:\n                aicc1_penalty = (2 * k1 * (k1 + 1)) / (n - k1 - 1)\n                aicc1 = n * np.log(sse1) + 2 * k1 + aicc1_penalty\n\n                aicc2_penalty = (2 * k2 * (k2 + 1)) / (n - k2 - 1)\n                aicc2 = n * np.log(sse2) + 2 * k2 + aicc2_penalty\n                \n                aicc_selection = 1 if aicc1  aicc2 else 2\n\n        # --- Reversal Check ---\n        # Reversal is true if AICc is defined and selects a different model than BIC.\n        is_reversal = False\n        if aicc_is_defined:\n            if bic_selection != aicc_selection:\n                is_reversal = True\n        \n        reversal_results.append(is_reversal)\n\n    # Print the final result in the specified format\n    print(f\"[{','.join(map(str, reversal_results))}]\")\n\nsolve()\n\n```"
        }
    ]
}