{
    "hands_on_practices": [
        {
            "introduction": "在现代生物学，尤其是在转录组学和基因组学中，我们经常遇到“高维”数据集，其中特征（基因）的数量 $p$ 远远大于样本（细胞或个体）的数量 $n$。这种 $p \\gg n$ 的情况给数据分析带来了独特的挑战和限制。本练习将引导你通过基本的线性代数原理，揭示在这种高维设定下，样本协方差矩阵的一个内在属性，从而理解主成分分析（PCA）能够提取的有效维度上限。 这不仅仅是一个理论推导，它解释了为什么在分析高通量测序数据时，我们能发现的独立变化模式（主成分）的数量会受到样本量的严格限制。",
            "id": "3302515",
            "problem": "您正在计算系统生物学中分析一个转录组学数据集，其中测量了 $n$ 个生物样本中 $p$ 个基因的基因表达水平，且 $p \\gg n$。令 $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ 表示样本-基因数据矩阵，其 $(i,j)$ 元是样本 $i$ 中基因 $j$ 的表达水平。令 $\\mathbf{X}_{c}$ 表示列中心化矩阵，该矩阵通过从 $\\mathbf{X}$ 中减去每个基因 $j$ 的样本均值得到，因此 $\\mathbf{X}_{c}$ 的每一列在样本上的均值为 $0$。考虑特征-特征样本协方差矩阵\n$$\n\\mathbf{S} \\;=\\; \\frac{1}{n-1}\\,\\mathbf{X}_{c}^{\\top}\\mathbf{X}_{c} \\;\\in\\; \\mathbb{R}^{p \\times p},\n$$\n该矩阵在主成分分析（PCA）中被对角化，其中主成分分析（PCA）是特征方差沿着由 $\\mathbf{S}$ 的特征向量定义的主方向上的正交分解。仅使用基本的线性代数定义以及中心化和协方差的性质，确定在 $p \\gg n$ 的情况下，$\\mathbf{S}$ 的非零特征值的最大可能数量。通过明确解释在 $n$ 个样本上进行中心化所引起的 $\\mathbf{X}_{c}$ 各列之间的线性相关结构来证明此限制。以一个关于 $n$ 和 $p$ 的封闭形式表达式给出您的最终答案，并针对 $p \\gg n$ 的情况进行特化。无需四舍五入，也不涉及单位。",
            "solution": "目标是确定特征-特征样本协方差矩阵 $\\mathbf{S} = \\frac{1}{n-1}\\mathbf{X}_{c}^{\\top}\\mathbf{X}_{c}$ 的非零特征值的最大可能数量。\n\n线性代数中的一个基本定理指出，任何方阵的非零特征值的数量等于其秩。因此，问题等价于确定矩阵 $\\mathbf{S}$ 的最大可能秩。\n\n矩阵 $\\mathbf{S}$ 定义为 $\\mathbf{S} = \\frac{1}{n-1}\\mathbf{X}_{c}^{\\top}\\mathbf{X}_{c}$。标量因子 $\\frac{1}{n-1}$ 是非零的（假设 $n > 1$，这是计算协方差所必需的），并且不影响矩阵的秩。因此，我们有：\n$$\n\\text{rank}(\\mathbf{S}) = \\text{rank}\\left(\\frac{1}{n-1}\\mathbf{X}_{c}^{\\top}\\mathbf{X}_{c}\\right) = \\text{rank}(\\mathbf{X}_{c}^{\\top}\\mathbf{X}_{c})\n$$\n线性代数的另一个基本性质指出，对于任何矩阵 $\\mathbf{A}$，$\\mathbf{A}^{\\top}\\mathbf{A}$ 的秩等于 $\\mathbf{A}$ 的秩。即 $\\text{rank}(\\mathbf{A}^{\\top}\\mathbf{A}) = \\text{rank}(\\mathbf{A})$。将此性质应用于矩阵 $\\mathbf{X}_{c} \\in \\mathbb{R}^{n \\times p}$，我们得到：\n$$\n\\text{rank}(\\mathbf{S}) = \\text{rank}(\\mathbf{X}_{c}^{\\top}\\mathbf{X}_{c}) = \\text{rank}(\\mathbf{X}_{c})\n$$\n问题现在简化为求列中心化数据矩阵 $\\mathbf{X}_{c}$ 的最大可能秩。\n\n矩阵 $\\mathbf{X}_{c}$ 的维度是 $n \\times p$。任何矩阵的秩不能超过其行数和列数的最小值。因此，$\\text{rank}(\\mathbf{X}_{c}) \\le \\min(n, p)$。在给定的 $p \\gg n$ 情况下，这意味着 $\\min(n, p) = n$，所以我们有一个初始上限：\n$$\n\\text{rank}(\\mathbf{X}_{c}) \\le n\n$$\n然而，我们必须考虑列中心化操作所施加的约束。问题指出，$\\mathbf{X}_{c}$ 是通过从原始数据矩阵 $\\mathbf{X}$ 的每一列中减去样本均值得到的。令 $\\mathbf{x}_{c,j}$ 表示 $\\mathbf{X}_{c}$ 的第 $j$ 列，它是一个 $\\mathbb{R}^n$ 中的向量。中心化条件意味着每一列向量中元素的和为零：\n$$\n\\sum_{i=1}^{n} (\\mathbf{X}_{c})_{ij} = 0 \\quad \\text{for all } j \\in \\{1, 2, \\dots, p\\}\n$$\n这可以用向量表示法来表达。令 $\\mathbf{1}_{n} \\in \\mathbb{R}^n$ 是一个由 $n$ 个 1 组成的列向量。中心化条件等价于每个列向量 $\\mathbf{x}_{c,j}$ 都与 $\\mathbf{1}_{n}$ 正交：\n$$\n\\mathbf{1}_{n}^{\\top}\\mathbf{x}_{c,j} = 0 \\quad \\text{for all } j \\in \\{1, 2, \\dots, p\\}\n$$\n这个约束有一个关键的几何解释：矩阵 $\\mathbf{X}_{c}$ 的所有 $p$ 个列向量都必须位于 $\\mathbb{R}^n$ 中与向量 $\\mathbf{1}_{n}$ 正交的子空间内。这个子空间，通常表示为 $\\mathbf{1}_{n}^{\\perp}$，其维度为 $n-1$。\n\n矩阵的秩定义为其列空间的维度。$\\mathbf{X}_{c}$ 的列空间是由其 $p$ 个列向量 $\\text{span}\\{\\mathbf{x}_{c,1}, \\mathbf{x}_{c,2}, \\dots, \\mathbf{x}_{c,p}\\}$ 张成的向量空间。由于这些向量中的每一个都被限制在一个 $(n-1)$ 维的子空间内，它们张成的空间的维度不能超过 $n-1$。因此，$\\mathbf{X}_{c}$ 的秩的上限为 $n-1$：\n$$\n\\text{rank}(\\mathbf{X}_{c}) \\le n-1\n$$\n如果 $\\mathbf{X}$ 中的原始数据足够通用，这个上限是可以达到的。例如，如果我们取 $\\mathbf{X}$ 的 $n-1$ 列，使它们线性无关且不完全位于 $\\mathbf{1}_n$ 的张成空间中，那么它们在子空间 $\\mathbf{1}_{n}^{\\perp}$ 上的投影也将是线性无关的。因此，$\\mathbf{X}_{c}$ 的*最大可能*秩恰好是 $n-1$。\n\n$p \\gg n$ 的情况是关键的。由于 $p > n-1$，我们有一组 $p$ 个向量位于一个 $(n-1)$ 维空间中。这保证了 $\\mathbf{X}_{c}$ 的列向量集合必须是线性相关的，并且矩阵的秩受限于这个子空间的维度（$n-1$），而不是特征的数量（$p$）。\n\n总结如下：\n1. $\\mathbf{S}$ 的非零特征值的数量等于 $\\text{rank}(\\mathbf{S})$。\n2. $\\text{rank}(\\mathbf{S}) = \\text{rank}(\\mathbf{X}_{c})$。\n3. 中心化操作将 $\\mathbf{X}_{c}$ 的列向量约束在 $\\mathbb{R}^n$ 的一个 $(n-1)$ 维子空间中。\n4. 因此，$\\mathbf{X}_{c}$ 的最大可能秩是 $n-1$。\n\n在 $p \\gg n$ 的情况下，$\\mathbf{S}$ 的非零特征值的最大可能数量是 $n-1$。",
            "answer": "$$\n\\boxed{n-1}\n$$"
        },
        {
            "introduction": "主成分分析（PCA）作为一种强大的降维工具，常常在监督学习任务（如分类）中用作预处理步骤。然而，在通过交叉验证来评估模型性能时，一个常见的陷阱是“数据泄漏”，即测试集的信息无意中泄露到了模型训练过程中。本练习模拟了一个在生物信息学中极为常见的场景，旨在阐明为何即便是无监督的PCA也必须在每个交叉验证折叠的训练集上重新拟合，以保证评估的公正性。 通过辨析正确的和错误的处理流程，你将深刻理解避免数据泄漏对于获得可靠性能估计和可信生物学解释的至关重要性。",
            "id": "3321102",
            "problem": "一个研究团队正在分析一个单细胞核糖核酸测序（RNA-seq）数据集，以发现与免疫刺激相关的通路水平的变异。该数据集包含一个基因表达矩阵，其中有 $n = 2000$ 个细胞和 $p = 10000$ 个基因，以及一个指示刺激组与对照组的二元条件标签。他们计划使用主成分分析（PCA）进行降维，然后使用一个通过 $K=5$ 的 $K$-折交叉验证进行评估的分类器。预处理流程包括对每个基因进行中心化和缩放。\n\n考虑了两种流程：\n\n- 流程 $\\mathcal{T}$：在每一折中，仅使用训练折的数据重新拟合PCA，以估计载荷和中心化/缩放参数。通过应用训练折的中心化/缩放参数，并将数据投影到训练折的载荷上，来转换留出的细胞，从而获得主成分得分。分类器在训练折的得分上进行训练，并在留出集的得分上进行评估。\n\n- 流程 $\\mathcal{L}$：使用所有 $n$ 个细胞拟合一次PCA，以估计载荷和中心化/缩放参数。在每一折中，训练集和留出集的细胞都使用这些全局参数和载荷进行转换。分类器的训练和评估方式与流程 $\\mathcal{T}$ 中相同。\n\n经验上，当使用 $m=20$ 个主成分时，流程 $\\mathcal{L}$ 产生的交叉验证的受试者工作特征曲线下面积（AUROC）略高于流程 $\\mathcal{T}$，并且研究团队还观察到前几个主成分与条件标签高度相关。\n\n根据PCA的核心定义（即训练数据协方差的方差最大化的标准正交方向），以及交叉验证估计要求训练衍生的转换与留出集评估之间保持独立性的原则，回答以下多项选择题：\n\n关于为什么PCA必须仅在训练折上重新拟合，并通过投影计算留出集的得分，以及数据泄露如何引入解释性偏差，以下哪些陈述是正确的？\n\nA. 在 $K$-折交叉验证中，对所有 $n$ 个样本拟合PCA会导致数据泄露，因为特征向量依赖于留出集的数据，这使得下游的性能估计（例如，AUROC）产生乐观偏差。\n\nB. 获取留出集主成分得分的有效方法是：使用训练折的统计数据对留出集样本进行中心化和缩放，然后投影到训练折的载荷向量上；这保留了无偏风险估计所需的独立性。\n\nC. 因为PCA是无监督的且不使用标签，所以在交叉验证中对完整数据集拟合PCA是可以接受的，不会引入数据泄露。\n\nD. PCA中的数据泄露会使生物学解释产生偏差：绝对载荷值大的基因可能被过分强调其对于条件分离的生物学重要性，因为载荷受到了留出集数据结构的影响，从而混淆了探索性分析和验证性分析。\n\nE. 在每折的训练数据上重新拟合PCA，使得各折之间的主成分方向不具可比性，即使存在跨折一致的模式，也使得通路水平的解释在形式上无效。\n\n选择所有适用项。",
            "solution": "问题陈述提出了一个场景，比较了在 $K$-折交叉验证框架下，针对单细胞RNA-seq数据集的两种数据分析流程 $\\mathcal{T}$ 和 $\\mathcal{L}$。问题的核心在于如何正确地应用主成分分析（PCA）作为后续分类任务的预处理步骤，以及不正确应用（数据泄露）对性能评估和生物学解释的影响。\n\n首先，让我们将过程形式化。数据集是一个矩阵 $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$，其中有 $n=2000$ 个细胞和 $p=10000$ 个基因。每个细胞都有一个二元标签。$K$-折交叉验证的目标是将数据划分为 $K$ 折，对于每一折 $k \\in \\{1, ..., K\\}$，将第 $k$ 折作为留出测试集，其余 $K-1$ 折作为训练集。这个过程重复 $K$ 次，并将性能指标（例如，AUROC）在各折上取平均。其基本原则是，任何一折的测试集都必须完全独立于整个模型拟合过程，这包括任何依赖于数据的预处理步骤。\n\n流程 $\\mathcal{L}$ 违反了这一原则。它在交叉验证循环*之前*对整个数据集 $\\mathbf{X}$ 拟合PCA。这意味着中心化参数（均值 $\\boldsymbol{\\mu}$）、缩放参数（标准差 $\\boldsymbol{\\sigma}$）和PCA载荷向量（整个数据集协方差矩阵的特征向量，我们可以表示为 $\\mathbf{W}$）都是使用所有 $n$ 个细胞的信息来确定的。在每个交叉验证折中，留出集的数据是用于计算 $\\boldsymbol{\\mu}$、$\\boldsymbol{\\sigma}$ 和 $\\mathbf{W}$ 的数据集的一部分。这就构成了数据泄露。\n\n流程 $\\mathcal{T}$ 代表了正确的程序。在每一折 $k$ 中，中心化参数 $\\boldsymbol{\\mu}^{(k)}$、缩放参数 $\\boldsymbol{\\sigma}^{(k)}$ 和载荷向量 $\\mathbf{W}^{(k)}$ 都*仅*使用该折的训练数据来估计。然后，使用这些预先确定的、特定于训练折的参数来转换留出集数据。这模仿了一个真实世界的应用场景：在可用数据上训练一个模型流程，然后将其应用于新的、未见过的数据，从而为模型的泛化性能提供一个无偏估计。\n\n经验观察到流程 $\\mathcal{L}$ 比流程 $\\mathcal{T}$ 产生更高的AUROC，这是数据泄露的一个典型症状。流程 $\\mathcal{L}$ 中的模型具有不公平的优势，因为它使用的特征空间（主成分）是在部分了解测试集数据结构的情况下构建的。\n\n在建立了这些原则之后，我们来评估每个陈述。\n\n**A. 在 $K$-折交叉验证中，对所有 $n$ 个样本拟合PCA会导致数据泄露，因为特征向量依赖于留出集的数据，这使得下游的性能估计（例如，AUROC）产生乐观偏差。**\n\n这个陈述是正确的。PCA找到数据协方差矩阵的特征向量（载荷）。在流程 $\\mathcal{L}$ 中，协方差矩阵是根据所有 $n$ 个样本计算的。因此，对于任何给定的折，留出集中的数据都影响了这些特征向量的计算。这些特征向量定义了所有数据（包括留出集数据）被投影到的坐标系。因为应用于留出集数据的变换依赖于该数据本身，所以无偏性能估计所需的独立性被破坏了。这种从测试集到模型训练过程的信息泄露通常会导致过于乐观的性能估计。观察到流程 $\\mathcal{L}$ 具有更高的AUROC是这种乐观偏差的直接后果。\n**结论：正确。**\n\n**B. 获取留出集主成分得分的有效方法是：使用训练折的统计数据对留出集样本进行中心化和缩放，然后投影到训练折的载荷向量上；这保留了无偏风险估计所需的独立性。**\n\n这个陈述是正确的。为了获得泛化误差（或风险）的无偏估计，整个模型拟合过程必须对测试集“视而不见”。这个“过程”包括所有依赖于数据的转换。因此，用于中心化和缩放的统计数据（均值和标准差）以及PCA载荷向量必须仅从给定折的训练数据中计算。然后，使用这些固定的、从训练集派生的参数来转换留出集数据。这个程序保留了模型开发生态系统与用于评估的数据之间的关键独立性，这是有效交叉验证的基石。\n**结论：正确。**\n\n**C. 因为PCA是无监督的且不使用标签，所以在交叉验证中对完整数据集拟合PCA是可以接受的，不会引入数据泄露。**\n\n这个陈述是错误的，它阐述了一个常见但至关重要的谬误。PCA是“无监督的”（即它不使用类别标签 $\\mathbf{y}$）这一事实与此处的数据泄露问题无关。泄露的发生是因为关于测试集*特征*的信息（其分布和协方差结构）被用来定义特征变换（主成分）。任何数据驱动的转换，无论是否是有监督的，都必须包含在交叉验证循环中，并且仅从数据的训练部分学习，以确保性能估计的无偏性。主成分是特征工程步骤的参数，和所有模型参数一样，它们必须在不接触测试集的情况下学习。\n**结论：错误。**\n\n**D. PCA中的数据泄露会使生物学解释产生偏差：绝对载荷值大的基因可能被过分强调其对于条件分离的生物学重要性，因为载荷受到了留出集数据结构的影响，从而混淆了探索性分析和验证性分析。**\n\n这个陈述是正确的。数据泄露的后果不仅限于虚高的性能指标，还会影响从模型中得出的科学结论。在生物信息学中，PCA载荷通常被用来解释，以确定哪些原始变量（基因）驱动了主成分所捕获的方差。问题陈述中提到，前几个主成分与条件标签相关。在存在泄露的流程 $\\mathcal{L}$ 中，这些主成分是在*整个*数据集上最大化方差来定义的。因此，由于它们是在预先知道测试数据结构的情况下构建的，它们会“不自然地”与分离条件的方向对齐。当研究人员解释这样一个“泄露的”主成分的基因载荷时，他们可能会错误地将强大的生物学重要性归因于那些看起来能够分离条件的基因。这个结论是有偏的，因为主成分本身已经被测试集的信息污染了。它混淆了探索性阶段（在训练数据中寻找模式）和验证性阶段（在测试数据上验证模式），可能导致不可重复的科学主张。\n**结论：正确。**\n\n**E. 在每折的训练数据上重新拟合PCA，使得各折之间的主成分方向不具可比性，即使存在跨折一致的模式，也使得通路水平的解释在形式上无效。**\n\n这个陈述是错误的。虽然在 $K$ 折的每一折中重新拟合PCA确实会产生 $K$ 组不同的载荷向量（即，第1折的PC1与第2折的PC1不完全相同），但这并不会使解释失效。交叉验证（流程 $\\mathcal{T}$）的主要目的是为整个建模策略的*性能*获得一个稳健的估计。模型的生物学意义的解释通常是在建模策略得到验证后，对在*整个数据集*上训练的最终模型进行的。此外，如果在不同折之间观察到一致的模式（例如，如果每折中的PC1都持续地分离条件，并且由相似的基因集驱动），这实际上会*增强*对生物学解释的信心，因为它表明该发现对于训练数据的特定抽样是稳健的。声称这个程序使得解释“形式上无效”是一种夸大其词，并且曲解了最佳实践。\n**结论：错误。**",
            "answer": "$$\\boxed{ABD}$$"
        },
        {
            "introduction": "标准的主成分分析（PCA）寻找的是在欧几里得空间中最大化数据方差的方向，它隐含地假设所有特征（基因）的度量标准和噪声水平是相同的。然而在实际测量中，不同特征的可靠性或重要性可能不同。本练习将引导你探索广义主成分分析（gPCA），它通过引入马氏（Mahalanobis）度量来推广PCA框架，从而能够根据已知的噪声结构或特征权重来调整主成分的定义。 你将从第一性原理出发，推导该问题的优化形式，并将其转化为一个可解的广义特征值问题，从而将PCA的几何直觉与更灵活的代数框架联系起来。",
            "id": "3302534",
            "problem": "在一项通过单细胞RNA测序 (scRNA-seq) 分析三基因信号模块的研究中，假设这些基因在细胞间的对数表达量的样本协方差由一个对称正定矩阵 $S \\in \\mathbb{R}^{3 \\times 3}$ 建模，并且已知的基因特异性测量噪声水平定义了一个正定的马氏度量 (Mahalanobis metric) $M \\in \\mathbb{R}^{3 \\times 3}$。在马氏度量下的第一个广义主成分被定义为在归一化约束 $v^{\\top} M v = 1$ 下，使样本方差 $v^{\\top} S v$ 最大化的方向 $v \\in \\mathbb{R}^{3}$。\n\n仅从方差、协方差和马氏范数的定义出发，推导在马氏度量下广义主成分分析 (PCA) 的约束最大化原理，然后通过适当的白化变换将其简化为标准特征值问题。最后，计算给定特定矩阵\n$$\nS \\;=\\; \\begin{pmatrix}\n3.2  1.2  0.0 \\\\\n1.2  2.5  0.0 \\\\\n0.0  0.0  1.6\n\\end{pmatrix},\n\\qquad\nM \\;=\\; \\begin{pmatrix}\n1.0  0.0  0.0 \\\\\n0.0  0.5  0.0 \\\\\n0.0  0.0  2.0\n\\end{pmatrix}\n$$\n的最大广义方差（即最大的广义主成分方差）。\n将你的最终答案以最大广义方差的单个闭式解析表达式的形式给出。不要包含单位，也不要四舍五入。",
            "solution": "目标是找到一个向量 $v \\in \\mathbb{R}^3$，在归一化约束 $g(v) = v^{\\top} M v - 1 = 0$ 的条件下，使由二次型 $f(v) = v^{\\top} S v$ 给出的广义方差最大化。\n\n**第一部分：约束最大化原理的推导**\n\n这是一个约束优化问题，可以使用拉格朗日乘子法解决。我们定义拉格朗日函数 $\\mathcal{L}(v, \\lambda)$ 为：\n$$\n\\mathcal{L}(v, \\lambda) = f(v) - \\lambda g(v) = v^{\\top} S v - \\lambda(v^{\\top} M v - 1)\n$$\n其中 $\\lambda$ 是一个拉格朗日乘子。为了找到极值，我们必须将 $\\mathcal{L}$ 对 $v$ 的梯度设为零。鉴于 $S$ 和 $M$ 是对称矩阵，二次型的梯度为 $\\nabla_v(v^{\\top} S v) = 2Sv$ 和 $\\nabla_v(v^{\\top} M v) = 2Mv$。\n\n将拉格朗日函数的梯度设为零：\n$$\n\\nabla_v \\mathcal{L}(v, \\lambda) = 2Sv - \\lambda (2Mv) = 0\n$$\n$$\nSv - \\lambda Mv = 0\n$$\n$$\nSv = \\lambda Mv\n$$\n这是一个广义特征值问题。满足此方程的向量 $v$ 是广义特征向量，对应的标量 $\\lambda$ 是矩阵对 $(S, M)$ 的广义特征值。\n\n为了查看目标函数在这些驻点处的值，我们用 $v^{\\top}$ 左乘方程 $Sv = \\lambda Mv$：\n$$\nv^{\\top} S v = v^{\\top} (\\lambda Mv) = \\lambda (v^{\\top} M v)\n$$\n应用约束条件 $v^{\\top} M v = 1$，我们得到：\n$$\nv^{\\top} S v = \\lambda\n$$\n这表明，沿着广义特征向量 $v$ 的方差等于相应的广义特征值 $\\lambda$。因此，要最大化方差 $v^{\\top} S v$，我们必须选择最大的广义特征值 $\\lambda_{\\text{max}}$。对应的广义特征向量 $v_{\\text{max}}$ 就是第一个广义主成分。\n\n**第二部分：简化为标准特征值问题**\n\n广义特征值问题 $Sv = \\lambda Mv$ 可以转换为一个标准特征值问题。由于 $M$ 是一个对称正定矩阵，它有一个唯一的对称正定平方根 $M^{1/2}$，并且它也允许进行乔列斯基分解 (Cholesky decomposition) $M = LL^{\\top}$，其中 $L$ 是一个下三角矩阵。\n\n将 $M = LL^{\\top}$ 代入广义特征值方程：\n$$\nSv = \\lambda LL^{\\top}v\n$$\n由于 $L$ 是可逆的（因为 $M$ 是正定的），我们可以用 $L^{-1}$ 左乘：\n$$\nL^{-1}Sv = \\lambda L^{\\top}v\n$$\n现在，我们定义一个新的“白化”向量 $u$ 为 $u = L^{\\top}v$。这意味着 $v = (L^{\\top})^{-1}u = L^{-\\top}u$。将 $v$ 的这个表达式代入方程中得到：\n$$\nL^{-1}S(L^{-\\top}u) = \\lambda u\n$$\n$$\n(L^{-1}SL^{-\\top})u = \\lambda u\n$$\n让我们定义一个新矩阵 $S' = L^{-1}SL^{-\\top}$。方程变为 $S'u = \\lambda u$，这是矩阵 $S'$ 的一个标准特征值问题。矩阵 $S'$ 是对称的，因为 $(L^{-1}SL^{-\\top})^{\\top} = (L^{-\\top})^{\\top}S^{\\top}(L^{-1})^{\\top} = L^{-1}SL^{-\\top} = S'$。\n$S'$ 的特征值 $\\lambda$ 与矩阵对 $(S, M)$ 的广义特征值相同。原始的约束优化问题被转化为在约束 $u^{\\top}u = 1$ 下最大化 $u^{\\top}S'u$，根据瑞利-里兹定理 (Rayleigh-Ritz theorem)，其最大值是 $S'$ 的最大特征值。\n\n**第三部分：最大广义方差的计算**\n\n我们需要通过求解特征方程 $\\det(S - \\lambda M) = 0$ 来找到最大的广义特征值 $\\lambda$。\n给定：\n$$\nS \\;=\\; \\begin{pmatrix}\n3.2  1.2  0.0 \\\\\n1.2  2.5  0.0 \\\\\n0.0  0.0  1.6\n\\end{pmatrix},\n\\qquad\nM \\;=\\; \\begin{pmatrix}\n1.0  0.0  0.0 \\\\\n0.0  0.5  0.0 \\\\\n0.0  0.0  2.0\n\\end{pmatrix}\n$$\n首先，我们计算 $S - \\lambda M$：\n$$\nS - \\lambda M = \\begin{pmatrix}\n3.2 - 1.0\\lambda  & 1.2  & 0.0 \\\\\n1.2  & 2.5 - 0.5\\lambda  & 0.0 \\\\\n0.0  & 0.0  & 1.6 - 2.0\\lambda\n\\end{pmatrix}\n$$\n其行列式为：\n$$\n\\det(S - \\lambda M) = (1.6 - 2.0\\lambda) \\left| \\begin{matrix} 3.2 - \\lambda  & 1.2 \\\\ 1.2  & 2.5 - 0.5\\lambda \\end{matrix} \\right|\n$$\n如果任一因子为零，则行列式为零。\n\n情况 1：线性因子为零。\n$$\n1.6 - 2.0\\lambda = 0 \\implies 2\\lambda = 1.6 \\implies \\lambda_1 = 0.8\n$$\n\n情况 2：$2 \\times 2$ 子矩阵的行列式为零。\n$$\n(3.2 - \\lambda)(2.5 - 0.5\\lambda) - (1.2)^2 = 0\n$$\n$$\n(8.0 - 1.6\\lambda - 2.5\\lambda + 0.5\\lambda^2) - 1.44 = 0\n$$\n$$\n0.5\\lambda^2 - 4.1\\lambda + 6.56 = 0\n$$\n乘以 2 以消除分数：\n$$\n\\lambda^2 - 8.2\\lambda + 13.12 = 0\n$$\n我们使用二次公式来找到另外两个特征值 $\\lambda_2$ 和 $\\lambda_3$：\n$$\n\\lambda = \\frac{-(-8.2) \\pm \\sqrt{(-8.2)^2 - 4(1)(13.12)}}{2(1)} = \\frac{8.2 \\pm \\sqrt{67.24 - 52.48}}{2} = \\frac{8.2 \\pm \\sqrt{14.76}}{2}\n$$\n简化平方根下的项：\n$$\n\\sqrt{14.76} = \\sqrt{\\frac{1476}{100}} = \\frac{\\sqrt{1476}}{10} = \\frac{\\sqrt{36 \\times 41}}{10} = \\frac{6\\sqrt{41}}{10} = \\frac{3\\sqrt{41}}{5}\n$$\n将此代回二次公式解中：\n$$\n\\lambda = \\frac{8.2 \\pm \\frac{3\\sqrt{41}}{5}}{2} = 4.1 \\pm \\frac{3\\sqrt{41}}{10}\n$$\n将 $4.1$ 写成分数形式 $41/10$：\n$$\n\\lambda = \\frac{41}{10} \\pm \\frac{3\\sqrt{41}}{10} = \\frac{41 \\pm 3\\sqrt{41}}{10}\n$$\n所以，另外两个特征值是：\n$$\n\\lambda_2 = \\frac{41 + 3\\sqrt{41}}{10} \\quad \\text{和} \\quad \\lambda_3 = \\frac{41 - 3\\sqrt{41}}{10}\n$$\n三个广义特征值为 $\\lambda_1 = 0.8$、$\\lambda_2 = \\frac{41 + 3\\sqrt{41}}{10}$ 和 $\\lambda_3 = \\frac{41 - 3\\sqrt{41}}{10}$。\n\n我们需要找到这三个值中的最大值。\n由于 $\\sqrt{41} > \\sqrt{36} = 6$，所以 $3\\sqrt{41} > 18$。\n$$\n\\lambda_2 = \\frac{41 + 3\\sqrt{41}}{10} > \\frac{41 + 18}{10} = 5.9\n$$\n$$\n\\lambda_3 = \\frac{41 - 3\\sqrt{41}}{10}  \\frac{41 - 18}{10} = 2.3\n$$\n显然，$\\lambda_2$ 是最大值。\n我们来确认一下 $\\lambda_3 > \\lambda_1$。我们需要检查 $\\frac{41 - 3\\sqrt{41}}{10} > 0.8 = \\frac{8}{10}$ 是否成立。\n这等价于检查 $41 - 3\\sqrt{41} > 8$，或 $33 > 3\\sqrt{41}$，或 $11 > \\sqrt{41}$。\n两边平方得到 $121 > 41$，这是成立的。所以 $\\lambda_3 > \\lambda_1$。\n特征值的顺序是 $\\lambda_2 > \\lambda_3 > \\lambda_1$。\n\n最大广义方差是最大的广义特征值，$\\lambda_{\\text{max}} = \\lambda_2$。\n$$\n\\lambda_{\\text{max}} = \\frac{41 + 3\\sqrt{41}}{10}\n$$\n这是最终的闭式解析表达式。",
            "answer": "$$\\boxed{\\frac{41 + 3\\sqrt{41}}{10}}$$"
        }
    ]
}