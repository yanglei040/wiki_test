{
    "hands_on_practices": [
        {
            "introduction": "现代增强决策树通常通过梯度提升进行训练。该过程的核心在于如何构建每一棵新树（或叶节点）来修正现有模型的误差。这个练习  深入探讨了单个叶节点的基本优化步骤，基于损失函数的一阶导数（梯度）与二阶导数（Hessian）来推导其最优输出值，并引入了对于防止过拟合和确保数值稳定性至关重要的正则化项 $\\lambda$。",
            "id": "3506549",
            "problem": "考虑在计算高能物理中使用提升决策树（BDTs）进行二元分类，其中生成一棵树来划分事件，每个终端节点（叶节点）输出一个恒定分数，加到当前模型上。在采用二阶可导凸损失函数的梯度提升中，对于输出为 $v$ 的单个叶节点，其正则化目标函数是在当前间隔（margin）附近，对分配到该叶节点的事件 $i$ 进行二阶泰勒展开来近似的。设 $g_i$ 表示事件 $i$ 的损失函数关于间隔（margin）的一阶导数（梯度），$h_i$ 表示事件 $i$ 的二阶导数（Hessian矩阵），$\\lambda$ 为作用于叶节点输出的平方 $\\ell_2$ 正则化的强度。从正则化目标函数的二阶展开式出发，利用凸损失函数可得出 $h_i \\ge 0$ 的事实，推导出以 $\\{g_i\\}$、$\\{h_i\\}$ 和 $\\lambda$ 表示的唯一最小化器 $v$，并解释为什么当 $\\sum_i h_i$ 很小时该选择在数值上是稳定的，以及 $\\lambda$ 如何控制过拟合的趋势。\n\n实现一个程序，该程序为每个测试用例接收一个有限实数列表 $\\{g_i\\}$、一个有限实数列表 $\\{h_i\\}$（其中每个 $h_i \\ge 0$）和一个实数 $\\lambda \\ge 0$，并返回推导出的正则化叶节点输出 $v$。为了数值鲁棒性，请采用以下规则：定义 $S_g = \\sum_i g_i$ 和 $S_h = \\sum_i h_i$，如果 $S_h + \\lambda \\le \\varepsilon$ 且 $\\varepsilon = 10^{-12}$，则输出 $0.0$；否则输出推导出的唯一最小化器。此规则确保在曲率和正则化消失或极小的情况下有安全的输出。\n\n您的程序必须评估以下测试套件：\n-   情况 1：$\\{g_i\\} = [\\,0.8,\\,-0.5,\\,0.1\\,]$, $\\{h_i\\} = [\\,0.25,\\,0.2,\\,0.1\\,]$, $\\lambda = 1.0$。\n-   情况 2：$\\{g_i\\} = [\\,0.1,\\,0.1,\\,-0.1\\,]$, $\\{h_i\\} = [\\,10^{-12},\\,2\\times 10^{-12},\\,0.0\\,]$, $\\lambda = 0.0$。\n-   情况 3：$\\{g_i\\} = [\\,0.1,\\,0.1,\\,-0.1\\,]$, $\\{h_i\\} = [\\,10^{-12},\\,2\\times 10^{-12},\\,0.0\\,]$, $\\lambda = 10^{-6}$。\n-   情况 4：$\\{g_i\\} = [\\,-2.0,\\,1.0,\\,-0.5,\\,0.3\\,]$, $\\{h_i\\} = [\\,0.5,\\,0.4,\\,0.3,\\,0.2\\,]$, $\\lambda = 1000.0$。\n-   情况 5：$\\{g_i\\} = [\\,1000.0,\\,-950.0,\\,25.0,\\,-10.0\\,]$, $\\{h_i\\} = [\\,0.01,\\,0.01,\\,0.01,\\,0.01\\,]$, $\\lambda = 1.0$。\n-   情况 6：$\\{g_i\\} = [\\,0.0,\\,0.0,\\,0.0\\,]$, $\\{h_i\\} = [\\,0.2,\\,0.3,\\,0.1\\,]$, $\\lambda = 0.5$。\n-   情况 7：$\\{g_i\\} = [\\,0.5,\\,-0.5\\,]$, $\\{h_i\\} = [\\,0.0,\\,0.0\\,]$, $\\lambda = 0.0$。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[\\,\\text{result}_1,\\text{result}_2,\\ldots\\,]$）。每个结果都必须是实数（浮点数）。此计算不涉及任何物理单位或角度，也不需要百分比。",
            "solution": "在进行求解之前，对问题陈述的有效性进行了严格评估。\n\n### 步骤1：提取已知条件\n- **主题**：在计算高能物理中使用提升决策树（BDTs）进行二元分类。\n- **模型组件**：决策树中的单个终端节点（叶节点）。\n- **目标函数**：叶节点的正则化目标是通过在当前间隔（margin）附近的二阶泰勒展开来近似的。\n- **变量**：\n    - $v$：叶节点的恒定输出分数。\n    - $i$：路由到该叶节点的事件的索引。\n    - $g_i$：事件 $i$ 的损失函数关于间隔（margin）的一阶导数（梯度）。\n    - $h_i$：事件 $i$ 的损失函数关于间隔（margin）的二阶导数（Hessian矩阵）。\n- **常数和条件**：\n    - 损失函数是二阶可导和凸的，这意味着 $h_i \\ge 0$。\n    - $\\lambda$：作用于叶节点输出的平方 $\\ell_2$ 正则化的强度，$\\lambda \\ge 0$。\n- **任务**：\n    1.  用 $\\{g_i\\}$、$\\{h_i\\}$ 和 $\\lambda$ 表示，推导出唯一的最小化器 $v$。\n    2.  解释当 $\\sum_i h_i$ 很小时，此选择的数值稳定性。\n    3.  解释 $\\lambda$ 如何控制过拟合。\n    4.  实现一个程序来计算多个测试用例的 $v$。\n- **数值鲁棒性规则**：\n    - 定义 $S_g = \\sum_i g_i$ 和 $S_h = \\sum_i h_i$。\n    - 如果 $S_h + \\lambda \\le \\varepsilon$ 且 $\\varepsilon = 10^{-12}$，则输出 $v$ 必须为 $0.0$。\n    - 否则，输出推导出的唯一最小化器。\n- **测试套件**：\n    - 情况 1：$\\{g_i\\} = [\\,0.8,\\,-0.5,\\,0.1\\,]$, $\\{h_i\\} = [\\,0.25,\\,0.2,\\,0.1\\,]$, $\\lambda = 1.0$。\n    - 情况 2：$\\{g_i\\} = [\\,0.1,\\,0.1,\\,-0.1\\,]$, $\\{h_i\\} = [\\,10^{-12},\\,2\\times 10^{-12},\\,0.0\\,]$, $\\lambda = 0.0$。\n    - 情况 3：$\\{g_i\\} = [\\,0.1,\\,0.1,\\,-0.1\\,]$, $\\{h_i\\} = [\\,10^{-12},\\,2\\times 10^{-12},\\,0.0\\,]$, $\\lambda = 10^{-6}$。\n    - 情况 4：$\\{g_i\\} = [\\,-2.0,\\,1.0,\\,-0.5,\\,0.3\\,]$, $\\{h_i\\} = [\\,0.5,\\,0.4,\\,0.3,\\,0.2\\,]$, $\\lambda = 1000.0$。\n    - 情况 5：$\\{g_i\\} = [\\,1000.0,\\,-950.0,\\,25.0,\\,-10.0\\,]$, $\\{h_i\\} = [\\,0.01,\\,0.01,\\,0.01,\\,0.01\\,]$, $\\lambda = 1.0$。\n    - 情况 6：$\\{g_i\\} = [\\,0.0,\\,0.0,\\,0.0\\,]$, $\\{h_i\\} = [\\,0.2,\\,0.3,\\,0.1\\,]$, $\\lambda = 0.5$。\n    - 情况 7：$\\{g_i\\} = [\\,0.5,\\,-0.5\\,]$, $\\{h_i\\} = [\\,0.0,\\,0.0\\,]$, $\\lambda = 0.0$。\n\n### 步骤2：使用提取的已知条件进行验证\n根据指定标准对问题进行验证。\n- **科学基础**：该问题描述了在梯度提升机（一种标准且广泛使用的机器学习算法）中确定叶节点权重的核心优化步骤。使用二阶泰勒近似损失函数、梯度（$g_i$）、Hessian矩阵（$h_i$）和 $\\ell_2$ 正则化是像 XGBoost 这样的算法的基础。将其应用于高能物理是 BDTs 的一个常见且适当的用例。该问题在科学上和数学上都是合理的。\n- **适定性**：该问题要求推导一个二次函数的最小化器，这是一个明确定义的数学任务。所有必需的量（$g_i, h_i, \\lambda$）和条件（$h_i \\ge 0, \\lambda \\ge 0$）都已提供。只要二次项的系数为正，就保证存在唯一最小值。数值规则处理了系数为零或接近零的情况。因此，存在一个唯一且有意义的解。\n- **客观性**：问题以精确、无歧义的数学术语陈述。没有主观或基于观点的内容。\n\n该问题没有表现出任何列出的无效性缺陷。它是自洽、一致且有科学依据的。\n\n### 步骤3：结论与行动\n问题是有效的。将提供完整的解决方案。\n\n### 解题推导与说明\n\n设路由到特定叶节点的事件集由 $i$ 索引。该叶节点的总目标函数 $J(v)$ 是每个事件的近似损失之和，再加上对叶节点输出值 $v$ 的正则化项。每个事件 $i$ 的损失通过二阶泰勒展开来近似。正则化项是叶节点输出的平方 $\\ell_2$ 范数，由 $\\lambda$ 缩放。通常，为了数学上的方便，两项中都包含一个因子 $1/2$，以简化求导。\n\n待优化的关于 $v$ 的目标函数为：\n$$\nJ(v) = \\sum_{i \\in \\text{leaf}} \\left( g_i v + \\frac{1}{2} h_i v^2 \\right) + \\frac{1}{2} \\lambda v^2\n$$\n其中，$g_i v + \\frac{1}{2} h_i v^2$ 是事件 $i$ 对损失函数贡献的二阶泰勒近似，不包括与 $v$ 的优化无关的常数项。项 $\\frac{1}{2} \\lambda v^2$ 是 $\\ell_2$ 正则化惩罚项。\n\n为了找到最小化 $J(v)$ 的最优值 $v$，我们可以重新组合这些项：\n$$\nJ(v) = \\left( \\sum_i g_i \\right) v + \\frac{1}{2} \\left( \\sum_i h_i + \\lambda \\right) v^2\n$$\n设 $S_g = \\sum_i g_i$ 和 $S_h = \\sum_i h_i$。目标函数简化为：\n$$\nJ(v) = S_g v + \\frac{1}{2} (S_h + \\lambda) v^2\n$$\n这是一个关于 $v$ 的二次函数。为求其极值，我们计算它关于 $v$ 的一阶导数并令其为零：\n$$\n\\frac{dJ}{dv} = S_g + (S_h + \\lambda) v = 0\n$$\n求解 $v$ 可得最优叶节点值：\n$$\nv (S_h + \\lambda) = -S_g \\implies v = - \\frac{S_g}{S_h + \\lambda}\n$$\n为确认这是一个最小值，我们考察其二阶导数：\n$$\n\\frac{d^2J}{dv^2} = S_h + \\lambda = \\sum_i h_i + \\lambda\n$$\n问题陈述指出损失函数是凸的，因此其二阶导数非负，即对所有 $i$ 都有 $h_i \\ge 0$。正则化强度也是非负的，$\\lambda \\ge 0$。因此，它们的和 $\\sum_i h_i$ 以及 $\\sum_i h_i + \\lambda$ 也都是非负的。如果 $\\sum_i h_i + \\lambda > 0$，则二阶导数为正，推导出的 $v$ 是一个唯一的最小值。如果 $\\sum_i h_i + \\lambda = 0$，目标函数是关于 $v$ 的线性函数（如果 $S_g$ 也为 $0$ 则为常数），除非 $S_g=0$，否则不存在唯一的有限最小值。\n\n**数值稳定性：**\n推导出的 $v$ 的表达式涉及除以 $S_h + \\lambda$。如果这个分母非常接近于零， $v$ 的值可能会变得极大，导致数值不稳定和大的更新，从而使提升过程发散。这种情况通常发生在由叶节点定义的特征空间区域包含的数据点非常少，或者在该区域损失函数的曲率非常小（$h_i \\approx 0$），并且没有使用正则化（$\\lambda = 0$）时。正则化参数 $\\lambda$ 在确保稳定性方面起着至关重要的作用。作为一个非负常数，它将分母“抬离”零，防止除以一个非常小的数。问题中明确的数值规则——如果 $S_h + \\lambda \\le 10^{-12}$ 则设置 $v = 0.0$——是防止这种不稳定的直接且实用的保障措施，有效地将曲率或正则化不足的情况视为不进行更新。\n\n**过拟合控制：**\nBDTs 中的过拟合发生在模型过度适应训练数据（包括其噪声），从而在未见过的数据上表现不佳时。这通常表现为单棵树做出非常大的贡献（大的 $|v|$）来纠正少数训练样本的错误分类。$\\ell_2$ 正则化项 $\\frac{1}{2} \\lambda v^2$ 对大的叶节点值进行惩罚。从公式 $v = -S_g / (S_h + \\lambda)$ 可以明显看出，增加正则化强度 $\\lambda$ 会增加分母的量级。这反过来又将 $v$ 的最优值“收缩”到零。这种收缩降低了每棵单独树的影响，迫使算法依赖于更多数量的弱学习器的共识。这个过程使模型对训练集中的噪声不那么敏感，并提高了其泛化能力，从而控制了过拟合。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the BDT leaf value problem for a suite of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {'g': [0.8, -0.5, 0.1], 'h': [0.25, 0.2, 0.1], 'lambda': 1.0},\n        # Case 2\n        {'g': [0.1, 0.1, -0.1], 'h': [1e-12, 2e-12, 0.0], 'lambda': 0.0},\n        # Case 3\n        {'g': [0.1, 0.1, -0.1], 'h': [1e-12, 2e-12, 0.0], 'lambda': 1e-6},\n        # Case 4\n        {'g': [-2.0, 1.0, -0.5, 0.3], 'h': [0.5, 0.4, 0.3, 0.2], 'lambda': 1000.0},\n        # Case 5\n        {'g': [1000.0, -950.0, 25.0, -10.0], 'h': [0.01, 0.01, 0.01, 0.01], 'lambda': 1.0},\n        # Case 6\n        {'g': [0.0, 0.0, 0.0], 'h': [0.2, 0.3, 0.1], 'lambda': 0.5},\n        # Case 7\n        {'g': [0.5, -0.5], 'h': [0.0, 0.0], 'lambda': 0.0},\n    ]\n\n    def calculate_leaf_output(g_list, h_list, lam):\n        \"\"\"\n        Calculates the regularized leaf output value v.\n\n        Args:\n            g_list: A list of gradient values {g_i}.\n            h_list: A list of Hessian values {h_i}.\n            lam: The L2 regularization strength lambda.\n\n        Returns:\n            The calculated leaf output value v as a float.\n        \"\"\"\n        # Epsilon for the numerical stability check, as defined in the problem.\n        epsilon = 1e-12\n        \n        # Calculate the sum of gradients (S_g) and Hessians (S_h).\n        # Convert lists to numpy arrays for efficient summation.\n        S_g = np.sum(np.array(g_list))\n        S_h = np.sum(np.array(h_list))\n        \n        denominator = S_h + lam\n        \n        # Apply the numerical robustness rule.\n        if denominator = epsilon:\n            return 0.0\n        else:\n            # Calculate the unique minimizer for the leaf value v.\n            v = -S_g / denominator\n            return v\n\n    results = []\n    for case in test_cases:\n        g = case['g']\n        h = case['h']\n        lam = case['lambda']\n        result = calculate_leaf_output(g, h, lam)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个训练好的增强决策树为每个事例提供一个连续的输出分数，但物理分析最终需要一个离散的决策：这个事例是信号还是背景？这个练习  旨在连接这一理论与实践的鸿沟。它模拟了一个真实的分析场景，你必须在 BDT 输出分数上选择一个最佳切割点，以最大化一个与物理分析相关的指标（如 $F_1$ 分数），同时还要考虑源于横截面和积分亮度的权重。",
            "id": "3506489",
            "problem": "在计算高能物理中的一项分类分析使用了一个提升决策树（BDT），其输出经过校准以表示信号类的后验概率，记为 $s \\in [0,1]$。考虑一个质子-质子碰撞事件的测试样本，包含两个类别：信号和背景。每个事件带有一个物理权重，该权重由截面、积分亮度和选择效率的乘积得出。测试样本中信号和背景的总加权产额分别由 $W_{S}$ 和 $W_{B}$ 给出。信号事件的BDT输出 $s$ 由密度 $f_{S}(s) = 2s$（在 $[0,1]$ 上）建模，而背景事件则由密度 $f_{B}(s) = 2(1-s)$（在 $[0,1]$ 上）建模，这与一个校准的分类器一致，即该分类器更倾向于为信号事件产生较大的 $s$ 值，为背景事件产生较小的 $s$ 值。\n\n使用以下具有物理动机的参数来计算总加权产额：\n- 积分亮度 $L = 100\\,\\mathrm{fb}^{-1}$。\n- 信号截面 $\\sigma_{S} = 0.5\\,\\mathrm{pb}$ 和选择效率 $\\epsilon_{S} = 0.4$。\n- 背景截面 $\\sigma_{B} = 2.0\\,\\mathrm{pb}$ 和选择效率 $\\epsilon_{B} = 0.3$。\n\n假设 $1\\,\\mathrm{pb} = 10^{-12}\\,\\mathrm{b}$ 且 $1\\,\\mathrm{fb}^{-1} = 10^{15}\\,\\mathrm{b}^{-1}$，因此 $W_{S} = \\sigma_{S} L \\epsilon_{S}$ 和 $W_{B} = \\sigma_{B} L \\epsilon_{B}$ 是无量纲的预期事件产额。\n\n对于阈值 $t \\in [0,1]$，定义加权真正例 $\\mathrm{TP}(t)$、假正例 $\\mathrm{FP}(t)$ 和假反例 $\\mathrm{FN}(t)$，其分类规则为：如果 $s \\geq t$，则事件被分类为信号，否则为背景。加权 $F_{1}$ 分数由 $F_{1}(t) = \\dfrac{2\\,\\mathrm{TP}(t)}{2\\,\\mathrm{TP}(t) + \\mathrm{FP}(t) + \\mathrm{FN}(t)}$ 给出。从这些定义和给定的密度出发，推导出使 $F_{1}(t)$ 最大化的阈值 $t^{\\star}$，并使用所提供的参数计算其数值。将最终阈值表示为一个四舍五入到四位有效数字的小数。该阈值是无量纲的。",
            "solution": "这个问题是有效的，因为它具有科学依据、提法恰当且客观。它为高能物理领域机器学习背景下的一个标准优化问题提供了一个完整且一致的框架。\n\n目标是找到使加权 $F_{1}$ 分数最大化的阈值 $t^{\\star}$，该分数定义为 $F_{1}(t) = \\dfrac{2\\,\\mathrm{TP}(t)}{2\\,\\mathrm{TP}(t) + \\mathrm{FP}(t) + \\mathrm{FN}(t)}$，其中 $\\mathrm{TP}(t)$、$\\mathrm{FP}(t)$ 和 $\\mathrm{FN}(t)$ 是对于分类阈值 $t \\in [0,1]$ 的加权真正例、假正例和假反例。\n\n首先，我们使用给定的参数计算信号（$W_S$）和背景（$W_B$）的总加权产额：\n积分亮度 $L = 100\\,\\mathrm{fb}^{-1}$\n信号截面 $\\sigma_{S} = 0.5\\,\\mathrm{pb}$\n信号选择效率 $\\epsilon_{S} = 0.4$\n背景截面 $\\sigma_{B} = 2.0\\,\\mathrm{pb}$\n背景选择效率 $\\epsilon_{B} = 0.3$\n\n产额由公式 $W = \\sigma L \\epsilon$ 给出。使用提供的转换因子 $1\\,\\mathrm{pb} = 10^{-12}\\,\\mathrm{b}$ 和 $1\\,\\mathrm{fb}^{-1} = 10^{15}\\,\\mathrm{b}^{-1}$：\n$$W_{S} = \\sigma_{S} L \\epsilon_{S} = (0.5 \\times 10^{-12}\\,\\mathrm{b}) \\times (100 \\times 10^{15}\\,\\mathrm{b}^{-1}) \\times 0.4 = 20000$$\n$$W_{B} = \\sigma_{B} L \\epsilon_{B} = (2.0 \\times 10^{-12}\\,\\mathrm{b}) \\times (100 \\times 10^{15}\\,\\mathrm{b}^{-1}) \\times 0.3 = 60000$$\n\n接下来，我们将 $\\mathrm{TP}(t)$、$\\mathrm{FP}(t)$ 和 $\\mathrm{FN}(t)$ 表示为阈值 $t$ 的函数。如果一个事件的 BDT 分数 $s$ 满足 $s \\geq t$，则该事件被分类为信号。\n\n加权真正例的数量 $\\mathrm{TP}(t)$ 是被分类为信号的信号事件的加权数量。这是总信号产额 $W_S$ 乘以信号事件得分 $s \\geq t$ 的概率：\n$$\\mathrm{TP}(t) = W_{S} \\int_{t}^{1} f_{S}(s) \\,ds = W_{S} \\int_{t}^{1} 2s \\,ds = W_{S} [s^2]_{t}^{1} = W_{S}(1 - t^2)$$\n\n加权假正例的数量 $\\mathrm{FP}(t)$ 是被分类为信号的背景事件的加权数量。这是总背景产额 $W_B$ 乘以背景事件得分 $s \\geq t$ 的概率：\n$$\\mathrm{FP}(t) = W_{B} \\int_{t}^{1} f_{B}(s) \\,ds = W_{B} \\int_{t}^{1} 2(1-s) \\,ds = W_{B} [2s - s^2]_{t}^{1} = W_{B}((2-1) - (2t-t^2)) = W_{B}(1 - 2t + t^2) = W_{B}(1-t)^2$$\n\n加权假反例的数量 $\\mathrm{FN}(t)$ 是被分类为背景的信号事件（$s  t$）的加权数量。这可以计算为总信号产额减去真正例：\n$$\\mathrm{FN}(t) = W_{S} - \\mathrm{TP}(t) = W_{S} - W_{S}(1-t^2) = W_{S}t^2$$\n\n现在我们构建 $F_1(t)$ 函数：\n$$F_{1}(t) = \\frac{2\\,\\mathrm{TP}(t)}{2\\,\\mathrm{TP}(t) + \\mathrm{FP}(t) + \\mathrm{FN}(t)} = \\frac{2 W_{S}(1-t^2)}{2 W_{S}(1-t^2) + W_{B}(1-t)^2 + W_{S}t^2}$$\n为了找到最大值，我们将导数 $\\frac{dF_1(t)}{dt}$ 设为 $0$。令分子为 $N(t) = 2 W_{S}(1-t^2)$，分母为 $D(t) = 2 W_{S}(1-t^2) + W_{B}(1-t)^2 + W_{S}t^2$。当 $N'(t)D(t) - N(t)D'(t) = 0$ 时，导数为零。\n分母可以简化为：\n$$D(t) = 2W_{S} - 2W_{S}t^2 + W_{B}(1-2t+t^2) + W_{S}t^2 = (W_{B} - W_{S})t^2 - 2W_{B}t + (2W_{S} + W_{B})$$\n导数是：\n$$N'(t) = -4W_{S}t$$\n$$D'(t) = 2(W_{B} - W_{S})t - 2W_{B}$$\n将商法则导数的分子设为零：\n$$(-4W_{S}t)[(W_{B} - W_{S})t^2 - 2W_{B}t + (2W_{S} + W_{B})] - [2W_{S}(1-t^2)][2(W_{B} - W_{S})t - 2W_{B}] = 0$$\n假设 $W_S  0$ 且 $t \\neq 1$，我们可以两边同除以 $-4W_S$：\n$$t[(W_{B} - W_{S})t^2 - 2W_{B}t + (2W_{S} + W_{B})] + (1-t^2)[(W_{B}-W_{S})t - W_B] = 0$$\n展开并合并同类项：\n$$(W_{B}-W_{S})t^3 - 2W_{B}t^2 + (2W_{S}+W_{B})t + (W_{B}-W_{S})t - W_B - (W_{B}-W_{S})t^3 + W_{B}t^2 = 0$$\n三次项相互抵消。我们得到一个二次方程：\n$$(-2W_{B}+W_{B})t^2 + (2W_{S}+W_{B} + W_{B}-W_{S})t - W_B = 0$$\n$$-W_{B}t^2 + (W_{S} + 2W_{B})t - W_{B} = 0$$\n$$W_{B}t^2 - (W_{S} + 2W_{B})t + W_{B} = 0$$\n我们使用二次公式求解 $t$：\n$$t = \\frac{(W_{S} + 2W_{B}) \\pm \\sqrt{(-(W_{S} + 2W_{B}))^2 - 4(W_{B})(W_{B})}}{2W_{B}}$$\n$$t = \\frac{W_{S} + 2W_{B} \\pm \\sqrt{W_{S}^2 + 4W_{S}W_{B} + 4W_{B}^2 - 4W_{B}^2}}{2W_{B}}$$\n$$t = \\frac{W_{S} + 2W_{B} \\pm \\sqrt{W_{S}(W_{S} + 4W_{B})}}{2W_{B}}$$\n解必须在区间 $[0,1]$ 内。\n考虑带加号的解：\n$$t_{+} = \\frac{W_{S} + 2W_{B} + \\sqrt{W_{S}^2 + 4W_{S}W_{B}}}{2W_{B}} = \\frac{W_{S}}{2W_{B}} + 1 + \\frac{\\sqrt{W_{S}^2 + 4W_{S}W_{B}}}{2W_{B}}$$\n因为 $W_S  0$ 且 $W_B  0$，所以 $t_{+}  1$。这个解没有物理意义。\n考虑带减号的解：\n$$t^{\\star} = t_{-} = \\frac{W_{S} + 2W_{B} - \\sqrt{W_{S}(W_{S} + 4W_{B})}}{2W_{B}}$$\n为了验证 $t^{\\star} \\in [0,1]$，我们观察到 $\\sqrt{W_{S}^2 + 4W_{S}W_{B}}  \\sqrt{W_{S}^2 + 4W_{S}W_{B} + 4W_{B}^2} = W_{S} + 2W_{B}$，所以分子为正，且 $t^{\\star}  0$。此外，$\\sqrt{W_{S}^2 + 4W_{S}W_{B}}  \\sqrt{W_{S}^2} = W_{S}$，所以 $W_{S} - \\sqrt{W_{S}(W_{S} + 4W_{B})}  0$，这意味着 $W_{S} + 2W_{B} - \\sqrt{W_{S}(W_{S} + 4W_{B})}  2W_{B}$。因此，$t^{\\star}  1$。这是正确的物理解。\n\n现在，我们代入数值 $W_{S}=20000$ 和 $W_{B}=60000$：\n$$t^{\\star} = \\frac{20000 + 2(60000) - \\sqrt{20000(20000 + 4 \\cdot 60000)}}{2(60000)}$$\n$$t^{\\star} = \\frac{140000 - \\sqrt{20000(260000)}}{120000} = \\frac{140000 - \\sqrt{5.2 \\times 10^9}}{120000}$$\n$$t^{\\star} = \\frac{140000 - 10^4\\sqrt{52}}{120000} = \\frac{14 - 2\\sqrt{13}}{12} = \\frac{7 - \\sqrt{13}}{6}$$\n计算最终数值：\n$$t^{\\star} \\approx \\frac{7 - 3.605551275}{6} \\approx \\frac{3.394448725}{6} \\approx 0.56574145$$\n四舍五入到四位有效数字，我们得到 $0.5657$。",
            "answer": "$$\\boxed{0.5657}$$"
        }
    ]
}