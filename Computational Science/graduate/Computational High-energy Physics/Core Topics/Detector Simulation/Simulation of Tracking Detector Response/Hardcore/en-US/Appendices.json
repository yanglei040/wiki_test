{
    "hands_on_practices": [
        {
            "introduction": "A realistic simulation of a tracking detector begins with modeling its most fundamental response: the decision to register a hit. This exercise delves into the heart of this process by exploring how a channel's hit efficiency is determined by the interplay of deposited charge, electronic noise, and threshold variations. By deriving and implementing the classic \"S-curve\" for detector efficiency, you will gain hands-on experience with the probabilistic nature of signal detection and understand how detector non-idealities are mathematically modeled to predict performance .",
            "id": "3536201",
            "problem": "Consider a binary-threshold tracking detector module where each readout channel produces a hit if the sum of the deposited charge and the electronic noise exceeds the channel’s threshold. Let the deposited charge be denoted by $q$, measured in kilo-electron charge $(\\mathrm{ke})$, where $1\\,\\mathrm{ke} = 10^{3}$ electrons. The per-channel electronic noise is modeled as a Gaussian random variable $n \\sim \\mathcal{N}(0,\\sigma_{n}^{2})$, with $\\sigma_{n}$ in $\\mathrm{ke}$. Channel thresholds across the module are not identical; instead, they are dispersed according to a Gaussian distribution $T \\sim \\mathcal{N}(T_{0},\\sigma_{T}^{2})$, with $T_{0}$ in $\\mathrm{ke}$ and $\\sigma_{T}$ in $\\mathrm{ke}$. Assume $n$ and $T$ are statistically independent.\n\nA single channel with a fixed threshold $T$ registers a hit if $q + n  T$. The per-channel response, that is, the probability of a hit given $q$ and $T$, is therefore defined by the event that the noisy signal exceeds the threshold. The mean module efficiency turn-on curve, denoted $\\bar{\\epsilon}(q)$, is the expected per-channel response averaged over the threshold dispersion, which can be written as a convolution of the per-channel response with the threshold distribution:\n$$\n\\bar{\\epsilon}(q) = \\int_{-\\infty}^{+\\infty} \\epsilon(q \\mid T)\\, p_{T}(T)\\, dT,\n$$\nwhere $\\epsilon(q \\mid T)$ is the per-channel response at threshold $T$, and $p_{T}(T)$ is the probability density function of $T$. The cumulative distribution function (CDF) refers to the integral of a probability density function from $-\\infty$ to a given value.\n\nYour task is to derive, from the fundamental definitions of Gaussian random variables and independence, a closed-form expression for $\\bar{\\epsilon}(q)$, by interpreting the convolution in terms of the probability that the sum of independent Gaussian random variables exceeds zero. Then implement a program that computes $\\bar{\\epsilon}(q)$ for specified parameter sets and charge samples.\n\nUnits and numerical specification:\n- Input parameters $q$, $T_{0}$, $\\sigma_{n}$, and $\\sigma_{T}$ are in $\\mathrm{ke}$.\n- The output $\\bar{\\epsilon}(q)$ is unitless and must be reported as real numbers between $0$ and $1$.\n- All reported numerical results must be rounded to $6$ decimal places.\n\nTest suite:\nCompute $\\bar{\\epsilon}(q)$ for the following three parameter sets and lists of $q$ values. Append the results across all $q$ in the order given, and across all test cases in the order listed.\n\n1. General case (happy path): $T_{0} = 20$, $\\sigma_{n} = 0.8$, $\\sigma_{T} = 2$, with $q \\in \\{15, 18, 20, 22, 25\\}$.\n2. No threshold dispersion (boundary case): $T_{0} = 20$, $\\sigma_{n} = 1$, $\\sigma_{T} = 0$, with $q \\in \\{19, 20, 21\\}$.\n3. Dominant threshold dispersion (edge case): $T_{0} = 20$, $\\sigma_{n} = 0.01$, $\\sigma_{T} = 5$, with $q \\in \\{10, 15, 20, 25, 30\\}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with the elements ordered by the test cases and then by the $q$ values as specified (for example, $[r_{1},r_{2},\\dots]$). Each $r_{i}$ must be a float rounded to $6$ decimal places.",
            "solution": "The problem asks for a closed-form expression for the mean module efficiency, $\\bar{\\epsilon}(q)$, and its numerical evaluation for specified parameters. The analysis begins with a rigorous validation of the problem statement.\n\nThe givens are:\n- Deposited charge: $q$ (in $\\mathrm{ke}$).\n- Per-channel electronic noise: $n$, a Gaussian random variable with distribution $n \\sim \\mathcal{N}(0, \\sigma_{n}^{2})$.\n- Per-channel threshold: $T$, a Gaussian random variable with distribution $T \\sim \\mathcal{N}(T_{0}, \\sigma_{T}^{2})$.\n- Statistical independence: $n$ and $T$ are independent random variables.\n- Hit condition for a fixed threshold $T$: $q + n  T$.\n- Per-channel response given $T$: $\\epsilon(q \\mid T) = P(q + n  T \\mid T)$.\n- Mean module efficiency: $\\bar{\\epsilon}(q) = \\int_{-\\infty}^{+\\infty} \\epsilon(q \\mid T)\\, p_{T}(T)\\, dT$, where $p_{T}(T)$ is the probability density function (PDF) of $T$.\n\nThe problem is scientifically grounded, as this model is a standard representation of detector response. It is well-posed, with all variables, parameters, and distributions clearly defined, ensuring a unique solution can be derived. The language is objective and formal. All conditions for a valid problem are met.\n\nThe derivation proceeds as follows. The mean module efficiency $\\bar{\\epsilon}(q)$ is defined as the expectation of the per-channel response $\\epsilon(q \\mid T)$ over the distribution of thresholds $T$.\n$$\n\\bar{\\epsilon}(q) = E_{T}[\\epsilon(q \\mid T)] = E_{T}[P(q + n  T \\mid T)]\n$$\nBy the law of total probability (or iterated expectation), this is equivalent to the unconditional probability that a hit occurs:\n$$\n\\bar{\\epsilon}(q) = P(q + n  T)\n$$\nThis interpretation avoids the direct, and more complex, calculation of the convolution integral. The problem can be solved by analyzing the probability of the event $q + n  T$. To facilitate this, we rearrange the inequality to group the random variables $n$ and $T$:\n$$\nq + n - T  0\n$$\nLet us define a new random variable $S = n - T$. The problem is now to find the probability $P(q + S  0)$, which is equivalent to $P(S  -q)$.\n\nThe variable $S$ is a linear combination of two independent Gaussian random variables. The properties of such combinations are well-established.\n1. The random variable $n$ follows the distribution $n \\sim \\mathcal{N}(\\mu_{n}, \\sigma_{n}^{2})$ with $\\mu_{n}=0$.\n2. The random variable $T$ follows the distribution $T \\sim \\mathcal{N}(\\mu_{T}, \\sigma_{T}^{2})$ with $\\mu_{T}=T_{0}$.\n3. The random variable $-T$ is also Gaussian. If a random variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, then $aX+b \\sim \\mathcal{N}(a\\mu+b, a^2\\sigma^2)$. Therefore, $-T = (-1)T + 0$ follows the distribution $-T \\sim \\mathcal{N}(-T_{0}, (-1)^2\\sigma_{T}^{2}) = \\mathcal{N}(-T_{0}, \\sigma_{T}^{2})$.\n\nSince $n$ and $T$ are independent, $n$ and $-T$ are also independent. The sum $S = n + (-T)$ is therefore a Gaussian random variable. Its mean, $\\mu_{S}$, is the sum of the means of its components:\n$$\n\\mu_{S} = E[n - T] = E[n] - E[T] = 0 - T_{0} = -T_{0}\n$$\nIts variance, $\\sigma_{S}^{2}$, is the sum of the variances of its independent components:\n$$\n\\sigma_{S}^{2} = \\mathrm{Var}(n - T) = \\mathrm{Var}(n) + \\mathrm{Var}(-T) = \\sigma_{n}^{2} + \\sigma_{T}^{2}\n$$\nThus, the random variable $S$ follows the distribution $S \\sim \\mathcal{N}(-T_{0}, \\sigma_{n}^{2} + \\sigma_{T}^{2})$. Let us define an effective total standard deviation $\\sigma_{\\mathrm{eff}} = \\sqrt{\\sigma_{n}^{2} + \\sigma_{T}^{2}}$.\n\nWe now compute the probability $P(S  -q)$. To do this, we standardize the variable $S$ by defining a new variable $Z$:\n$$\nZ = \\frac{S - \\mu_{S}}{\\sigma_{S}} = \\frac{S - (-T_{0})}{\\sigma_{\\mathrm{eff}}} = \\frac{S + T_{0}}{\\sigma_{\\mathrm{eff}}}\n$$\nThe variable $Z$ follows the standard normal distribution, $Z \\sim \\mathcal{N}(0, 1)$. We transform the inequality $S  -q$ into an inequality for $Z$:\n$$\nS  -q \\implies S + T_{0}  -q + T_{0} \\implies \\frac{S + T_{0}}{\\sigma_{\\mathrm{eff}}}  \\frac{T_{0} - q}{\\sigma_{\\mathrm{eff}}}\n$$\nSo, we have:\n$$\n\\bar{\\epsilon}(q) = P(S  -q) = P\\left(Z  \\frac{T_{0} - q}{\\sigma_{\\mathrm{eff}}}\\right)\n$$\nThe probability $P(Z  z)$ for a standard normal variable $Z$ is given by $1 - \\Phi(z)$, where $\\Phi(z)$ is the cumulative distribution function (CDF) of the standard normal distribution.\n$$\n\\bar{\\epsilon}(q) = 1 - \\Phi\\left(\\frac{T_{0} - q}{\\sigma_{\\mathrm{eff}}}\\right)\n$$\nDue to the symmetry of the standard normal distribution, $\\Phi(-z) = 1 - \\Phi(z)$. Applying this property, we obtain the final compact expression:\n$$\n\\bar{\\epsilon}(q) = \\Phi\\left(-\\frac{T_{0} - q}{\\sigma_{\\mathrm{eff}}}\\right) = \\Phi\\left(\\frac{q - T_{0}}{\\sigma_{\\mathrm{eff}}}\\right)\n$$\nSubstituting the definition of $\\sigma_{\\mathrm{eff}}$, the closed-form solution for the mean module efficiency is:\n$$\n\\bar{\\epsilon}(q) = \\Phi\\left(\\frac{q - T_{0}}{\\sqrt{\\sigma_{n}^{2} + \\sigma_{T}^{2}}}\\right)\n$$\nThis expression is known as the \"S-curve\" or turn-on curve in detector physics. The standard normal CDF is related to the error function, $\\mathrm{erf}(x)$, by $\\Phi(z) = \\frac{1}{2}\\left[1 + \\mathrm{erf}\\left(\\frac{z}{\\sqrt{2}}\\right)\\right]$. This allows for numerical computation using standard library functions.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes the mean module efficiency for given detector parameters and charge values.\n    \"\"\"\n\n    # Test suite:\n    # Each tuple contains (T0, sigma_n, sigma_T, list_of_q_values)\n    # All charge and threshold parameters are in units of kilo-electron charge (ke).\n    test_cases = [\n        # 1. General case (happy path)\n        (20.0, 0.8, 2.0, [15.0, 18.0, 20.0, 22.0, 25.0]),\n\n        # 2. No threshold dispersion (boundary case)\n        (20.0, 1.0, 0.0, [19.0, 20.0, 21.0]),\n\n        # 3. Dominant threshold dispersion (edge case)\n        (20.0, 0.01, 5.0, [10.0, 15.0, 20.0, 25.0, 30.0]),\n    ]\n\n    all_results = []\n\n    for T0, sigma_n, sigma_T, q_values in test_cases:\n        # The total effective standard deviation is the quadrature sum of the\n        # noise and threshold standard deviations.\n        # sigma_eff = sqrt(sigma_n^2 + sigma_T^2)\n        # Using np.hypot is numerically stable for cases where one term is much larger.\n        sigma_eff = np.hypot(sigma_n, sigma_T)\n\n        for q in q_values:\n            # The argument of the CDF. If sigma_eff is zero, this can lead to division by zero.\n            # However, sigma_eff can only be zero if both sigma_n and sigma_T are zero,\n            # which would make the response a step function. The test cases avoid this singularity.\n            if sigma_eff  0:\n                z = (q - T0) / sigma_eff\n                # The mean efficiency is the CDF of the standard normal distribution\n                # evaluated at z.\n                efficiency = norm.cdf(z)\n            else:\n                # Handle the deterministic case where all noise/dispersion is zero.\n                # The response is a Heaviside step function.\n                efficiency = 1.0 if q  T0 else (0.5 if q == T0 else 0.0)\n\n            # Round the result to 6 decimal places as required.\n            all_results.append(round(efficiency, 6))\n\n    # Format the final output as a comma-separated list in brackets.\n    # Using map(str, ...) ensures float representation without scientific notation\n    # for small numbers after rounding.\n    output_str = f\"[{','.join(map(str, all_results))}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Connecting individual hits to form a particle's trajectory requires accurately propagating its state through the detector's magnetic field. This practice addresses a core numerical challenge in this process: how to manage the error that accumulates when we approximate a continuously varying field with a series of discrete steps. By deriving an upper bound for the step size from first principles, you will develop a critical understanding of the trade-off between computational accuracy and efficiency that underpins modern track reconstruction algorithms .",
            "id": "3536223",
            "problem": "In computational propagation of charged tracks through a solenoidal barrel detector, a common first-order stepper approximates the magnetic field as constant over a finite step of path length $\\Delta s$, taking the field equal to its value at the step start. In a barrel region where the magnetic field magnitude has a measured spatial gradient of $0.05\\ \\mathrm{T/m}$, assume that over any single step the field magnitude varies linearly along the step direction. Consider a singly charged particle of transverse momentum $p_{T}=5\\ \\mathrm{GeV}/c$ moving in the transverse plane. The tracking code constrains the absolute error in the curvature magnitude per step, defined as the difference between the true step-averaged curvature and the stepper’s constant-field curvature, to be below $\\delta\\kappa_{\\max}=10^{-4}\\ \\mathrm{m^{-1}}$. You may assume worst-case orientation such that the step is aligned with the direction of steepest field increase.\n\nStarting only from the Lorentz force law and the definition of curvature of a charged particle in a magnetic field, and treating the magnetic field variation along the step as linear, derive an upper bound on $\\Delta s$ such that the curvature error bound is satisfied. Then evaluate the numerical value of the maximum allowable step size.\n\nUse the following fundamental constants as needed: the speed of light $c=2.99792458\\times 10^{8}\\ \\mathrm{m/s}$, the elementary charge magnitude $|e|=1.602176634\\times 10^{-19}\\ \\mathrm{C}$, and $1\\ \\mathrm{eV}=1.602176634\\times 10^{-19}\\ \\mathrm{J}$. Express your final answer for $\\Delta s$ in centimeters and round to three significant figures. Your final answer must be a single real number.",
            "solution": "The problem requires deriving an upper bound on the step size, $\\Delta s$, for a particle tracking simulation, based on a constraint on the error in curvature. The problem is self-contained, scientifically grounded in classical electromagnetism and mechanics, and well-posed. Therefore, it is deemed valid and a full solution can be constructed.\n\nThe foundation of this problem is the Lorentz force law, which describes the force $\\vec{F}$ on a particle of charge $q$ and velocity $\\vec{v}$ moving in a magnetic field $\\vec{B}$:\n$$ \\vec{F} = q(\\vec{v} \\times \\vec{B}) $$\nFor a particle moving in the transverse plane, perpendicular to a magnetic field $\\vec{B}$, the magnitude of the force is $F = |q| v_T B$, where $v_T$ is the transverse speed and $B$ is the magnetic field magnitude. This force acts as the centripetal force, $F_c = \\frac{mv_T^2}{R}$, responsible for the particle's circular trajectory. The radius of this circle is $R$, and $m$ is the relativistic mass. In terms of transverse momentum, $p_T = m v_T$, the centripetal force is $F_c = \\frac{p_T v_T}{R}$.\n\nEquating the Lorentz force and the centripetal force gives:\n$$ |q| v_T B = \\frac{p_T v_T}{R} $$\nThe curvature, $\\kappa$, is defined as the reciprocal of the radius of curvature, $\\kappa = \\frac{1}{R}$. Solving for $\\kappa$ yields the fundamental relationship between curvature, magnetic field, and transverse momentum:\n$$ \\kappa = \\frac{|q| B}{p_T} $$\nIt is convenient in high-energy physics to express momentum in units of energy divided by the speed of light, such as $\\mathrm{GeV}/c$. Let $E_T = p_T c$ be the transverse energy. The given transverse momentum is $p_T = 5\\ \\mathrm{GeV}/c$, which means $E_T = 5\\ \\mathrm{GeV}$. We can rewrite the curvature equation as:\n$$ \\kappa = \\frac{|q| c B}{p_T c} = \\frac{|q| c B}{E_T} $$\nHere, all quantities must be in a consistent system of units, such as the International System of Units (SI).\n\nThe problem states that the magnetic field magnitude, $B$, varies linearly along the step direction. The step is oriented along the direction of the steepest field increase, so the gradient is given by $G = 0.05\\ \\mathrm{T/m}$. Let $s$ be the path length along the step, from $s=0$ to $s=\\Delta s$. The magnetic field at any point $s$ along the step is:\n$$ B(s) = B_0 + G s $$\nwhere $B_0$ is the magnetic field at the start of the step ($s=0$). Consequently, the true curvature also varies linearly along the step:\n$$ \\kappa(s) = \\frac{|q| c (B_0 + G s)}{E_T} $$\n\nThe numerical stepper algorithm approximates the curvature as constant over the step, using the field value at the beginning of the step, $B_0$. The stepper's curvature, $\\kappa_{step}$, is therefore:\n$$ \\kappa_{step} = \\kappa(0) = \\frac{|q| c B_0}{E_T} $$\n\nThe \"true step-averaged curvature\", $\\bar{\\kappa}_{true}$, is the average of the true curvature function $\\kappa(s)$ over the interval $[0, \\Delta s]$:\n$$ \\bar{\\kappa}_{true} = \\frac{1}{\\Delta s} \\int_{0}^{\\Delta s} \\kappa(s) \\,ds = \\frac{1}{\\Delta s} \\int_{0}^{\\Delta s} \\frac{|q| c (B_0 + G s)}{E_T} \\,ds $$\nPerforming the integration:\n$$ \\bar{\\kappa}_{true} = \\frac{|q| c}{E_T \\Delta s} \\left[ B_0 s + \\frac{1}{2} G s^2 \\right]_0^{\\Delta s} = \\frac{|q| c}{E_T \\Delta s} \\left( B_0 \\Delta s + \\frac{1}{2} G (\\Delta s)^2 \\right) $$\n$$ \\bar{\\kappa}_{true} = \\frac{|q| c}{E_T} \\left( B_0 + \\frac{1}{2} G \\Delta s \\right) $$\nThis result is equivalent to the true curvature evaluated at the midpoint of the step, $s = \\frac{\\Delta s}{2}$, as expected for a linear function.\n\nThe absolute error in the curvature magnitude per step, $\\delta\\kappa$, is the difference between the true average curvature and the stepper's approximation:\n$$ \\delta\\kappa = |\\bar{\\kappa}_{true} - \\kappa_{step}| = \\left| \\frac{|q| c}{E_T} \\left( B_0 + \\frac{1}{2} G \\Delta s \\right) - \\frac{|q| c B_0}{E_T} \\right| $$\n$$ \\delta\\kappa = \\left| \\frac{|q| c B_0}{E_T} + \\frac{|q| c G \\Delta s}{2 E_T} - \\frac{|q| c B_0}{E_T} \\right| = \\frac{|q| c G \\Delta s}{2 E_T} $$\nThe problem imposes an upper bound on this error, $\\delta\\kappa \\le \\delta\\kappa_{\\max}$, where $\\delta\\kappa_{\\max} = 10^{-4}\\ \\mathrm{m^{-1}}$. We can use this to find the maximum allowed step size, $\\Delta s_{\\max}$:\n$$ \\frac{|q| c G \\Delta s}{2 E_T} \\le \\delta\\kappa_{\\max} \\implies \\Delta s \\le \\frac{2 E_T \\delta\\kappa_{\\max}}{|q| c G} $$\nThus, the upper bound on the step size is:\n$$ \\Delta s_{\\max} = \\frac{2 E_T \\delta\\kappa_{\\max}}{|q| c G} $$\nTo evaluate this expression numerically, we must use SI units. The givens are:\n-   A singly charged particle, so $|q|$ is the elementary charge, $|e| = 1.602176634 \\times 10^{-19}\\ \\mathrm{C}$.\n-   Transverse energy $E_T = 5\\ \\mathrm{GeV} = 5 \\times 10^9\\ \\mathrm{eV}$. To convert to Joules, we use $1\\ \\mathrm{eV} = 1.602176634 \\times 10^{-19}\\ \\mathrm{J}$. So, $E_T = 5 \\times 10^9 \\times (1.602176634 \\times 10^{-19})\\ \\mathrm{J}$.\n-   Maximum curvature error $\\delta\\kappa_{\\max} = 10^{-4}\\ \\mathrm{m^{-1}}$.\n-   Magnetic field gradient $G = 0.05\\ \\mathrm{T/m}$.\n-   Speed of light $c = 2.99792458 \\times 10^8\\ \\mathrm{m/s}$.\n\nSubstituting these values into the expression for $\\Delta s_{\\max}$:\n$$ \\Delta s_{\\max} = \\frac{2 \\times (5 \\times 10^9 \\times 1.602176634 \\times 10^{-19}\\ \\mathrm{J}) \\times (10^{-4}\\ \\mathrm{m^{-1}})}{(1.602176634 \\times 10^{-19}\\ \\mathrm{C}) \\times (2.99792458 \\times 10^8\\ \\mathrm{m/s}) \\times (0.05\\ \\mathrm{T/m})} $$\nThe numerical value of the elementary charge, $1.602176634 \\times 10^{-19}$, appears in both the numerator (from the eV to J conversion) and the denominator (as the charge in Coulombs). These terms cancel, simplifying the calculation significantly:\n$$ \\Delta s_{\\max} = \\frac{2 \\times (5 \\times 10^9) \\times (10^{-4}\\ \\mathrm{m^{-1}})}{(2.99792458 \\times 10^8\\ \\mathrm{m/s}) \\times (0.05\\ \\mathrm{T/m})} $$\n$$ \\Delta s_{\\max} = \\frac{10 \\times 10^5}{(2.99792458 \\times 10^8) \\times 0.05} \\cdot \\frac{\\mathrm{J} \\cdot \\mathrm{m}^{-1}}{\\mathrm{C} \\cdot (\\mathrm{m/s}) \\cdot (\\mathrm{T/m})} $$\nLet's check the units: $\\mathrm{J/(C \\cdot T \\cdot s^{-1})} = \\mathrm{J/(C \\cdot (J \\cdot s \\cdot C^{-1} m^{-2}) \\cdot s^{-1}}) = \\mathrm{J/(J \\cdot m^{-2})} = \\mathrm{m}^2$. This is incorrect. Re-evaluating the symbolic expression and units.\nThe error was in the units reasoning. The formula $\\Delta s_{\\max} = \\frac{2 E_T \\delta\\kappa_{\\max}}{|q| c G}$ is dimensionally correct:\n$\\frac{[\\mathrm{J}][\\mathrm{m}^{-1}]}{[\\mathrm{C}][\\mathrm{m/s}][\\mathrm{T/m}]} = \\frac{[\\mathrm{N} \\cdot \\mathrm{m}][\\mathrm{m}^{-1}]}{[\\mathrm{C}][\\mathrm{m/s}][\\mathrm{N \\cdot s / (C \\cdot m)}][\\mathrm{m}^{-1}]} = \\frac{[\\mathrm{N}]}{[\\mathrm{N}][\\mathrm{m}^{-1}]} = [\\mathrm{m}]$. The expression is valid.\n\nContinuing the numerical calculation:\n$$ \\Delta s_{\\max} = \\frac{10^6}{2.99792458 \\times 10^8 \\times 0.05}\\ \\mathrm{m} $$\n$$ \\Delta s_{\\max} = \\frac{10^6}{0.149896229 \\times 10^8}\\ \\mathrm{m} = \\frac{10^6}{1.49896229 \\times 10^7}\\ \\mathrm{m} $$\n$$ \\Delta s_{\\max} = \\frac{1}{14.9896229}\\ \\mathrm{m} \\approx 0.0667128\\ \\mathrm{m} $$\nThe problem asks for the result in centimeters, so we multiply by $100$:\n$$ \\Delta s_{\\max} \\approx 6.67128\\ \\mathrm{cm} $$\nRounding to three significant figures, we get:\n$$ \\Delta s_{\\max} \\approx 6.67\\ \\mathrm{cm} $$",
            "answer": "$$\\boxed{6.67}$$"
        },
        {
            "introduction": "Beyond simply reconstructing tracks, simulation is a critical tool for quantifying detector performance and understanding systematic uncertainties. This exercise demonstrates how simulation can be used to study the impact of primary vertex mismeasurement on crucial track observables like the transverse ($d_0$) and longitudinal ($z_0$) impact parameters. You will implement an analytical error propagation technique, providing a powerful and computationally efficient method to estimate biases and resolutions that are vital for physics analyses such as heavy-flavor tagging .",
            "id": "3536226",
            "problem": "Consider a tracking detector in a uniform magnetic field where, over small lever arms near the interaction point, charged particle trajectories can be approximated as straight lines. The true primary vertex is taken to be at the origin. The measured primary vertex position is modeled as a random vector $\\delta \\mathbf{r} = (\\delta x, \\delta y, \\delta z)$ representing the mismeasurement of the vertex position relative to the origin. The mismeasurement is modeled by a multivariate normal distribution with mean vector $\\boldsymbol{\\mu}$ (in meters) and covariance matrix $\\Sigma$ (in square meters), which may include correlations between components. In dense environments, both $\\boldsymbol{\\mu}$ and $\\Sigma$ may deviate from ideal low-density values due to reconstruction biases and degraded resolutions.\n\nA track is represented near the origin by a straight line through the origin with unit direction vector $\\hat{\\mathbf{u}}(\\phi, \\theta) = (\\cos \\phi \\sin \\theta, \\sin \\phi \\sin \\theta, \\cos \\theta)$, where $\\phi$ is the azimuthal angle in the transverse plane (in radians) and $\\theta$ is the polar angle measured from the $z$ axis (in radians). Define the transverse unit tangent and normal vectors by $\\hat{\\mathbf{t}}(\\phi) = (\\cos \\phi, \\sin \\phi)$ and $\\hat{\\mathbf{n}}(\\phi) = (-\\sin \\phi, \\cos \\phi)$, respectively.\n\nThe signed transverse impact parameter $d_0$ is defined as the signed transverse distance of closest approach between the track and the measured primary vertex, using the transverse normal $\\hat{\\mathbf{n}}(\\phi)$ for sign convention in a right-handed coordinate system. The longitudinal impact parameter $z_0$ is defined as the difference between the track’s $z$ coordinate at the transverse point of closest approach and the measured primary vertex’s $z$ coordinate.\n\nAssume small primary vertex displacements and small local track curvature so that the impact parameter biases may be linearized with respect to $\\delta \\mathbf{r}$. Treat $\\delta \\mathbf{r}$ as multivariate normal with the provided $\\boldsymbol{\\mu}$ and $\\Sigma$. For an ensemble of tracks, compute:\n1. The ensemble mean $d_0$ bias (in meters).\n2. The ensemble mean $z_0$ bias (in meters).\n3. The ensemble root-mean-square (RMS) of $d_0$ bias (in meters), defined as the square root of the ensemble average of $d_0^2$ over the primary vertex distribution and the track sample.\n4. The ensemble root-mean-square (RMS) of $z_0$ bias (in meters), defined analogously.\n\nAngles must be in radians. All distances must be expressed in meters. Your program must not perform any event-level Monte Carlo sampling; instead, you must use analytical propagation based on the linearization and properties of the multivariate normal distribution. The ensemble averages must be computed over the provided finite track sets using their specified weights.\n\nTest Suite:\nFor each test case, a set of track angles and weights is given along with $\\boldsymbol{\\mu}$ and $\\Sigma$. The covariance matrix $\\Sigma$ is symmetric and specified by its entries in meters squared. In all cases, answer in meters.\n\n- Test Case 1 (low-density baseline):\n  - $\\boldsymbol{\\mu} = (0,\\ 0,\\ 0)$.\n  - $\\Sigma$ with entries:\n    - $\\Sigma_{xx} = (20 \\times 10^{-6})^2$, $\\Sigma_{yy} = (20 \\times 10^{-6})^2$, $\\Sigma_{zz} = (40 \\times 10^{-6})^2$,\n    - $\\Sigma_{xy} = \\Sigma_{xz} = \\Sigma_{yz} = 0$.\n  - Tracks (each with weight $1$):\n    - $(\\phi,\\ \\theta) = (0.0,\\ 1.3)$,\n    - $(\\phi,\\ \\theta) = (1.0,\\ 1.0)$,\n    - $(\\phi,\\ \\theta) = (2.3,\\ 0.8)$,\n    - $(\\phi,\\ \\theta) = (3.0,\\ \\frac{\\pi}{2})$,\n    - $(\\phi,\\ \\theta) = (4.2,\\ 1.2)$.\n\n- Test Case 2 (dense environment with anisotropic transverse resolution and nonzero mean bias):\n  - $\\boldsymbol{\\mu} = (10 \\times 10^{-6},\\ -5 \\times 10^{-6},\\ 30 \\times 10^{-6})$.\n  - $\\Sigma$ with entries:\n    - $\\Sigma_{xx} = (60 \\times 10^{-6})^2$, $\\Sigma_{yy} = (40 \\times 10^{-6})^2$, $\\Sigma_{zz} = (80 \\times 10^{-6})^2$,\n    - $\\Sigma_{xy} = 0.3 \\times (60 \\times 10^{-6}) \\times (40 \\times 10^{-6})$,\n    - $\\Sigma_{xz} = \\Sigma_{yz} = 0$.\n  - Tracks (each with weight $1$):\n    - $(\\phi,\\ \\theta) = (0.2,\\ 1.4)$,\n    - $(\\phi,\\ \\theta) = (1.1,\\ 0.9)$,\n    - $(\\phi,\\ \\theta) = (2.5,\\ 1.1)$,\n    - $(\\phi,\\ \\theta) = (3.7,\\ 1.2)$,\n    - $(\\phi,\\ \\theta) = (5.0,\\ 0.7)$,\n    - $(\\phi,\\ \\theta) = (0.8,\\ 1.3)$.\n\n- Test Case 3 (forward track mix with $x$–$z$ correlation):\n  - $\\boldsymbol{\\mu} = (0,\\ 0,\\ 15 \\times 10^{-6})$.\n  - $\\Sigma$ with entries:\n    - $\\Sigma_{xx} = (50 \\times 10^{-6})^2$, $\\Sigma_{yy} = (50 \\times 10^{-6})^2$, $\\Sigma_{zz} = (70 \\times 10^{-6})^2$,\n    - $\\Sigma_{xy} = -0.2 \\times (50 \\times 10^{-6}) \\times (50 \\times 10^{-6})$,\n    - $\\Sigma_{xz} = 0.2 \\times (50 \\times 10^{-6}) \\times (70 \\times 10^{-6})$,\n    - $\\Sigma_{yz} = 0$.\n  - Tracks (each with weight $1$):\n    - $(\\phi,\\ \\theta) = (0.0,\\ 0.25)$,\n    - $(\\phi,\\ \\theta) = (1.5,\\ 0.35)$,\n    - $(\\phi,\\ \\theta) = (\\pi,\\ 0.5)$,\n    - $(\\phi,\\ \\theta) = (4.0,\\ 0.9)$.\n\n- Test Case 4 (deterministic bias, zero covariance):\n  - $\\boldsymbol{\\mu} = (30 \\times 10^{-6},\\ -30 \\times 10^{-6},\\ -20 \\times 10^{-6})$.\n  - $\\Sigma$ is the zero matrix (all entries $0$).\n  - Tracks (each with weight $1$):\n    - $(\\phi,\\ \\theta) = (0.3,\\ 1.0)$,\n    - $(\\phi,\\ \\theta) = (2.7,\\ 1.2)$,\n    - $(\\phi,\\ \\theta) = (5.5,\\ 0.8)$.\n\nComputation and Output Specification:\n- For each test case, compute the four quantities listed above: ensemble mean $d_0$, ensemble mean $z_0$, ensemble RMS $d_0$, ensemble RMS $z_0$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,...]\"), concatenating the four results for Test Case 1, followed by the four results for Test Case 2, then Test Case 3, then Test Case 4. All outputs must be in meters.",
            "solution": "The problem requires the calculation of ensemble-averaged biases and root-mean-square (RMS) values for the transverse ($d_0$) and longitudinal ($z_0$) impact parameters of particle tracks, given a statistical model for the mismeasurement of the primary vertex position. We are to perform an analytical calculation, propagating the uncertainty from the vertex measurement to the impact parameters.\n\n### Problem Formalization\n\nThe true primary vertex is at the origin, $\\mathbf{r}_{true} = (0, 0, 0)$. The measured primary vertex position, $\\mathbf{r}_v$, is offset from the true vertex by a random displacement vector $\\delta \\mathbf{r} = (\\delta x, \\delta y, \\delta z)$. This displacement is modeled as a $3$-dimensional multivariate normal distribution, $\\delta \\mathbf{r} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\Sigma)$, with mean vector $\\boldsymbol{\\mu} = (\\mu_x, \\mu_y, \\mu_z)^T$ and covariance matrix $\\Sigma$.\n\nA track is approximated as a straight line passing through the true origin with a unit direction vector $\\hat{\\mathbf{u}}(\\phi, \\theta) = (\\sin\\theta \\cos\\phi, \\sin\\theta \\sin\\phi, \\cos\\theta)$, where $\\phi$ is the azimuthal angle and $\\theta$ is the polar angle.\n\n### Derivation of Impact Parameters\n\nFirst, we express the impact parameters $d_0$ and $z_0$ as linear functions of the vertex displacement components $\\delta x$, $\\delta y$, and $\\delta z$.\n\n1.  **Transverse Impact Parameter ($d_0$)**: The signed transverse impact parameter $d_0$ is the signed distance of closest approach in the transverse ($x$-$y$) plane between the track's path (a line through the origin) and the measured vertex's transverse position $\\mathbf{r}_{v,T} = (\\delta x, \\delta y)$. The sign is determined by the projection onto the transverse normal vector $\\hat{\\mathbf{n}}(\\phi) = (-\\sin\\phi, \\cos\\phi)$.\n    $d_0 = \\mathbf{r}_{v,T} \\cdot \\hat{\\mathbf{n}}(\\phi) = (\\delta x, \\delta y) \\cdot (-\\sin\\phi, \\cos\\phi)$\n    $d_0 = -\\delta x \\sin\\phi + \\delta y \\cos\\phi$\n    This is a linear function of $\\delta \\mathbf{r}$. We can write $d_0 = \\mathbf{c}_{d_0}^T \\delta \\mathbf{r}$, where the coefficient vector is $\\mathbf{c}_{d_0} = (-\\sin\\phi, \\cos\\phi, 0)^T$.\n\n2.  **Longitudinal Impact Parameter ($z_0$)**: The longitudinal impact parameter $z_0$ is defined as $z_0 = z_{track} - z_v$, where $z_v = \\delta z$ is the measured vertex $z$-coordinate, and $z_{track}$ is the track's $z$-coordinate at the point of closest transverse approach. The transverse path length $s_T$ from the origin to this point is the projection of $\\mathbf{r}_{v,T}$ onto the transverse track direction $\\hat{\\mathbf{t}}(\\phi) = (\\cos\\phi, \\sin\\phi)$:\n    $s_T = \\mathbf{r}_{v,T} \\cdot \\hat{\\mathbf{t}}(\\phi) = \\delta x \\cos\\phi + \\delta y \\sin\\phi$\n    The corresponding $3$D path length along the track is $s = s_T / \\sin\\theta$, assuming $\\sin\\theta \\neq 0$. The track's $z$-coordinate at this point is $z_{track} = s \\cos\\theta = s_T \\cot\\theta$.\n    $z_{track} = (\\delta x \\cos\\phi + \\delta y \\sin\\phi) \\cot\\theta$\n    Therefore, $z_0$ is:\n    $z_0 = (\\delta x \\cos\\phi + \\delta y \\sin\\phi) \\cot\\theta - \\delta z$\n    This is also a linear function of $\\delta \\mathbf{r}$, with $z_0 = \\mathbf{c}_{z_0}^T \\delta \\mathbf{r}$ and the coefficient vector $\\mathbf{c}_{z_0} = (\\cos\\phi \\cot\\theta, \\sin\\phi \\cot\\theta, -1)^T$.\n\n### Bias and RMS Calculation\n\nFor a generic quantity $Q = \\mathbf{c}^T \\delta \\mathbf{r}$, where $\\delta \\mathbf{r} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\Sigma)$, its expectation value (mean) and variance are given by the standard rules for affine transformations of random vectors:\n-   Mean: $E[Q] = \\mathbf{c}^T E[\\delta \\mathbf{r}] = \\mathbf{c}^T \\boldsymbol{\\mu}$\n-   Variance: $\\text{Var}(Q) = \\mathbf{c}^T \\text{Cov}(\\delta \\mathbf{r}) \\mathbf{c} = \\mathbf{c}^T \\Sigma \\mathbf{c}$\n\nThe mean square is related to the mean and variance by $E[Q^2] = \\text{Var}(Q) + (E[Q])^2$. The subscript $v$ will denote expectation over the vertex distribution.\n\n**For a single track with parameters $(\\phi, \\theta)$:**\n\n-   **Mean Biases**:\n    $E_v[d_0] = \\mathbf{c}_{d_0}^T \\boldsymbol{\\mu} = -\\mu_x \\sin\\phi + \\mu_y \\cos\\phi$\n    $E_v[z_0] = \\mathbf{c}_{z_0}^T \\boldsymbol{\\mu} = (\\mu_x \\cos\\phi + \\mu_y \\sin\\phi) \\cot\\theta - \\mu_z$\n\n-   **Variances**:\n    $\\text{Var}_v(d_0) = \\mathbf{c}_{d_0}^T \\Sigma \\mathbf{c}_{d_0} = \\Sigma_{xx} \\sin^2\\phi + \\Sigma_{yy} \\cos^2\\phi - 2\\Sigma_{xy} \\sin\\phi \\cos\\phi$\n    $\\text{Var}_v(z_0) = \\mathbf{c}_{z_0}^T \\Sigma \\mathbf{c}_{z_0} = \\cot^2\\theta(\\Sigma_{xx}\\cos^2\\phi + \\Sigma_{yy}\\sin^2\\phi + 2\\Sigma_{xy}\\sin\\phi\\cos\\phi) - 2\\cot\\theta(\\Sigma_{xz}\\cos\\phi + \\Sigma_{yz}\\sin\\phi) + \\Sigma_{zz}$\n\n-   **Mean Squares**:\n    $E_v[d_0^2] = \\text{Var}_v(d_0) + (E_v[d_0])^2$\n    $E_v[z_0^2] = \\text{Var}_v(z_0) + (E_v[z_0])^2$\n\n### Ensemble Averaging\n\nThe problem asks for quantities averaged over both the vertex distribution and a finite sample of $N$ tracks, $\\{(\\phi_i, \\theta_i)\\}_{i=1}^N$, each with a weight $w_i$. The total weight is $W = \\sum_{i=1}^N w_i$. The ensemble average of a quantity $X$, denoted $\\langle X \\rangle$, is calculated as:\n$$\\langle X \\rangle = \\frac{1}{W} \\sum_{i=1}^N w_i E_v[X_i]$$\nwhere $X_i$ is the quantity evaluated for track $i$.\n\nThe four required quantities are:\n1.  Ensemble Mean $d_0$ Bias: $\\langle d_0 \\rangle = \\frac{1}{W} \\sum_{i=1}^N w_i E_v[d_{0, i}]$\n2.  Ensemble Mean $z_0$ Bias: $\\langle z_0 \\rangle = \\frac{1}{W} \\sum_{i=1}^N w_i E_v[z_{0, i}]$\n3.  Ensemble RMS of $d_0$: $\\text{RMS}(d_0) = \\sqrt{\\langle d_0^2 \\rangle} = \\sqrt{\\frac{1}{W} \\sum_{i=1}^N w_i E_v[d_{0, i}^2]}$\n4.  Ensemble RMS of $z_0$: $\\text{RMS}(z_0) = \\sqrt{\\langle z_0^2 \\rangle} = \\sqrt{\\frac{1}{W} \\sum_{i=1}^N w_i E_v[z_{0, i}^2]}$\n\nThese formulas provide a complete analytical prescription for computing the required results for each test case without Monte Carlo simulation. The implementation involves applying these formulas to the given numerical data for $\\boldsymbol{\\mu}$, $\\Sigma$, and the track samples.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the results.\n    \"\"\"\n\n    def build_sigma(params):\n        \"\"\"\n        Builds the 3x3 symmetric covariance matrix from a dictionary of parameters.\n        \"\"\"\n        sigma = np.zeros((3, 3))\n        sigma[0, 0] = params.get('xx', 0.0)\n        sigma[1, 1] = params.get('yy', 0.0)\n        sigma[2, 2] = params.get('zz', 0.0)\n        sigma[0, 1] = sigma[1, 0] = params.get('xy', 0.0)\n        sigma[0, 2] = sigma[2, 0] = params.get('xz', 0.0)\n        sigma[1, 2] = sigma[2, 1] = params.get('yz', 0.0)\n        return sigma\n\n    def calculate_ensemble_stats(mu, sigma, tracks):\n        \"\"\"\n        Calculates ensemble statistics for a given mu, sigma, and set of tracks.\n        \"\"\"\n        sum_mean_d0 = 0.0\n        sum_mean_z0 = 0.0\n        sum_mean_sq_d0 = 0.0\n        sum_mean_sq_z0 = 0.0\n        total_weight = 0.0\n\n        mu_x, mu_y, mu_z = mu\n        s_xx, s_xy, s_xz = sigma[0, 0], sigma[0, 1], sigma[0, 2]\n        s_yy, s_yz = sigma[1, 1], sigma[1, 2]\n        s_zz = sigma[2, 2]\n\n        for phi, theta, weight in tracks:\n            sin_phi = np.sin(phi)\n            cos_phi = np.cos(phi)\n            \n            # Handle cot(theta) carefully for theta near multiples of pi.\n            # For this problem's inputs, this is safe.\n            sin_theta = np.sin(theta)\n            if np.isclose(sin_theta, 0):\n                # For tracks along the z-axis, cot(theta) is infinite.\n                # z0 definition is ill-defined. However, test cases avoid this.\n                # If needed, a special handling would be placed here.\n                # For this problem, we can assume sin_theta is not zero.\n                cot_theta = np.inf if np.cos(theta)  0 else -np.inf\n            else:\n                cot_theta = np.cos(theta) / sin_theta\n\n            # Mean biases for this track\n            mean_d0 = -mu_x * sin_phi + mu_y * cos_phi\n            mean_z0 = (mu_x * cos_phi + mu_y * sin_phi) * cot_theta - mu_z\n\n            # Variances for this track\n            var_d0 = s_xx * sin_phi**2 + s_yy * cos_phi**2 - 2 * s_xy * sin_phi * cos_phi\n            \n            var_z0_term1 = (s_xx * cos_phi**2 + s_yy * sin_phi**2 + 2 * s_xy * sin_phi * cos_phi) * cot_theta**2\n            var_z0_term2 = -2 * (s_xz * cos_phi + s_yz * sin_phi) * cot_theta\n            var_z0_term3 = s_zz\n            var_z0 = var_z0_term1 + var_z0_term2 + var_z0_term3\n            \n            # Mean squares for this track\n            mean_sq_d0 = var_d0 + mean_d0**2\n            mean_sq_z0 = var_z0 + mean_z0**2\n\n            # Accumulate weighted sums\n            sum_mean_d0 += weight * mean_d0\n            sum_mean_z0 += weight * mean_z0\n            sum_mean_sq_d0 += weight * mean_sq_d0\n            sum_mean_sq_z0 += weight * mean_sq_z0\n            total_weight += weight\n\n        # Final ensemble averages\n        ensemble_mean_d0 = sum_mean_d0 / total_weight\n        ensemble_mean_z0 = sum_mean_z0 / total_weight\n        ensemble_mean_sq_d0 = sum_mean_sq_d0 / total_weight\n        ensemble_mean_sq_z0 = sum_mean_sq_z0 / total_weight\n\n        # RMS values\n        ensemble_rms_d0 = np.sqrt(ensemble_mean_sq_d0)\n        ensemble_rms_z0 = np.sqrt(ensemble_mean_sq_z0)\n\n        return [ensemble_mean_d0, ensemble_mean_z0, ensemble_rms_d0, ensemble_rms_z0]\n\n    # Test Case Definitions\n    test_cases = [\n        # Test Case 1\n        {\n            \"mu\": np.array([0.0, 0.0, 0.0]),\n            \"sigma_params\": {\n                'xx': (20e-6)**2, 'yy': (20e-6)**2, 'zz': (40e-6)**2,\n                'xy': 0.0, 'xz': 0.0, 'yz': 0.0\n            },\n            \"tracks\": [\n                (0.0, 1.3, 1.0), (1.0, 1.0, 1.0), (2.3, 0.8, 1.0),\n                (3.0, np.pi/2, 1.0), (4.2, 1.2, 1.0)\n            ]\n        },\n        # Test Case 2\n        {\n            \"mu\": np.array([10e-6, -5e-6, 30e-6]),\n            \"sigma_params\": {\n                'xx': (60e-6)**2, 'yy': (40e-6)**2, 'zz': (80e-6)**2,\n                'xy': 0.3 * (60e-6) * (40e-6), 'xz': 0.0, 'yz': 0.0\n            },\n            \"tracks\": [\n                (0.2, 1.4, 1.0), (1.1, 0.9, 1.0), (2.5, 1.1, 1.0),\n                (3.7, 1.2, 1.0), (5.0, 0.7, 1.0), (0.8, 1.3, 1.0)\n            ]\n        },\n        # Test Case 3\n        {\n            \"mu\": np.array([0.0, 0.0, 15e-6]),\n            \"sigma_params\": {\n                'xx': (50e-6)**2, 'yy': (50e-6)**2, 'zz': (70e-6)**2,\n                'xy': -0.2 * (50e-6) * (50e-6), 'xz': 0.2 * (50e-6) * (70e-6), 'yz': 0.0\n            },\n            \"tracks\": [\n                (0.0, 0.25, 1.0), (1.5, 0.35, 1.0), (np.pi, 0.5, 1.0), (4.0, 0.9, 1.0)\n            ]\n        },\n        # Test Case 4\n        {\n            \"mu\": np.array([30e-6, -30e-6, -20e-6]),\n            \"sigma_params\": {\n                'xx': 0.0, 'yy': 0.0, 'zz': 0.0, 'xy': 0.0, 'xz': 0.0, 'yz': 0.0\n            },\n            \"tracks\": [\n                (0.3, 1.0, 1.0), (2.7, 1.2, 1.0), (5.5, 0.8, 1.0)\n            ]\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        mu = case['mu']\n        sigma = build_sigma(case['sigma_params'])\n        tracks = case['tracks']\n        results = calculate_ensemble_stats(mu, sigma, tracks)\n        all_results.extend(results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}