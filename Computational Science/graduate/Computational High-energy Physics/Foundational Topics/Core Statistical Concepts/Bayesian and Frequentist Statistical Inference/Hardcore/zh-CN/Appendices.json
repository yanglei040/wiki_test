{
    "hands_on_practices": [
        {
            "introduction": "在高能物理实验中，一个核心任务是从背景噪声中估计出信号的大小。本练习模拟了一个典型的计数实验场景，其中信号和背景事件同时存在，并且我们有一个独立的测量来帮助我们约束背景的大小。通过解决这个问题，您将练习构建联合似然函数并应用最大似然估计来同时确定信号和背景的最佳估计值，并进一步计算它们的不确定性及其相关性。这套方法是频率学派统计推断的基石，也是粒子物理数据分析中的标准操作。",
            "id": "3506272",
            "problem": "在大型强子对撞机（LHC）上，为了寻找双μ子通道中的一个重共振，进行了一项单箱计数实验。该分析在以下生成模型下进行：信号区域中观测到的计数（记为 $n$）被假定服从泊松分布，其均值为 $s + b$，其中 $s \\ge 0$ 是未知的平均信号产额，$b \\ge 0$ 是未知的平均本底产额。一个独立的辅助本底校准产生了一个对本底的单一高斯测量值 $x$，其标准差 $\\sigma$ 已知，模型为 $x \\sim \\mathcal{N}(b, \\sigma^{2})$。假设在给定 $b$ 和 $s$ 的条件下，泊松计数和高斯校准是相互独立的。\n\n将要使用的经过充分检验的事实和定义包括：对于整数 $n \\ge 0$ 和均值 $\\lambda > 0$，泊松概率质量函数为 $P(n \\mid \\lambda) = \\exp(-\\lambda)\\lambda^{n}/n!$；对于 $x \\in \\mathbb{R}$，高斯概率密度函数为 $f(x \\mid \\mu,\\sigma^{2}) = (2\\pi\\sigma^{2})^{-1/2}\\exp\\!\\big(- (x - \\mu)^{2}/(2\\sigma^{2})\\big)$；以及最大似然估计（MLE）的定义，即最大化似然函数的参数值。MLE 的渐近协方差矩阵是通过对观测信息矩阵求逆得到的，该矩阵定义为在标准正则性条件下，在 MLE 处评估的对数似然函数的负海森矩阵（二阶导数矩阵）。\n\n给定观测数据 $n = 35$，辅助测量值 $x = 28$，以及已知的标准差 $\\sigma = 6$。仅从上述定义和事实出发，推导出 $(s,b)$ 的联合 MLE，并通过对在 MLE 处的观测信息求逆来获得它们的渐近协方差矩阵。假设对于所提供的数据，内部解 $s > 0$ 和 $b > 0$ 是有效的。将你的最终答案表示为一个单行矩阵，按顺序包含 $s^{\\ast}$、$b^{\\ast}$、$\\operatorname{Var}(s^{\\ast})$、$\\operatorname{Cov}(s^{\\ast}, b^{\\ast})$、$\\operatorname{Cov}(b^{\\ast}, s^{\\ast})$ 和 $\\operatorname{Var}(b^{\\ast})$。最终数值不需要四舍五入，也不包含任何物理单位。",
            "solution": "问题陈述经过正式验证，是自洽的、有科学依据的、且定义良好的。所有必要的数据、模型和定义都已提供，没有内部矛盾或歧义。该问题是最大似然估计在典型高能物理数据分析背景下的标准应用。因此，我们可以开始求解。\n\n目标是找到参数 $s$（信号）和 $b$（本底）的最大似然估计（MLEs）及其渐近协方差矩阵。数据包括一个观测计数 $n$ 和一个辅助测量值 $x$。\n\n统计模型由两个部分定义：\n1.  计数 $n$ 服从均值为 $s+b$ 的泊松分布：$n \\sim \\text{Poisson}(s+b)$。其概率质量函数为 $P(n \\mid s, b) = \\frac{\\exp(-(s+b))(s+b)^n}{n!}$。\n2.  辅助测量值 $x$ 服从均值为 $b$、已知方差为 $\\sigma^2$ 的高斯分布：$x \\sim \\mathcal{N}(b, \\sigma^2)$。其概率密度函数为 $f(x \\mid b, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-b)^2}{2\\sigma^2}\\right)$。\n\n鉴于两次测量是条件独立的，观测到数据对 $(n, x)$ 的联合似然函数 $L(s, b)$ 是各个概率函数的乘积：\n$$L(s, b) = P(n \\mid s, b) \\times f(x \\mid b, \\sigma^2) = \\frac{\\exp(-(s+b))(s+b)^n}{n!} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-b)^2}{2\\sigma^2}\\right)$$\n在计算上，使用似然函数的自然对数，即对数似然函数 $\\ell(s, b) = \\ln L(s, b)$，更为方便：\n$$\\ell(s, b) = -(s+b) + n\\ln(s+b) - \\ln(n!) - \\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{(x-b)^2}{2\\sigma^2}$$\n为了找到 MLEs，我们针对 $s$ 和 $b$ 最大化此函数。我们可以忽略 $-\\ln(n!)$ 和 $-\\frac{1}{2}\\ln(2\\pi\\sigma^2)$ 这两项，因为它们是不依赖于参数 $s$ 和 $b$ 的常数。对数似然函数的相关部分是：\n$$\\ell(s, b) = -(s+b) + n\\ln(s+b) - \\frac{(x-b)^2}{2\\sigma^2}$$\nMLEs，记为 $s^*$ 和 $b^*$，通过求解 $\\ell(s, b)$ 的一阶偏导数为零的方程组得到：\n$$\\frac{\\partial\\ell}{\\partial s} = 0 \\quad \\text{and} \\quad \\frac{\\partial\\ell}{\\partial b} = 0$$\n我们来计算偏导数：\n$$\\frac{\\partial\\ell}{\\partial s} = -1 + \\frac{n}{s+b}$$\n$$\\frac{\\partial\\ell}{\\partial b} = -1 + \\frac{n}{s+b} + \\frac{x-b}{\\sigma^2}$$\n令第一个方程为零得到：\n$$-1 + \\frac{n}{s^*+b^*} = 0 \\implies s^*+b^* = n$$\n将此结果代入第二个设为零的方程中：\n$$-1 + \\frac{n}{n} + \\frac{x-b^*}{\\sigma^2} = 0 \\implies -1 + 1 + \\frac{x-b^*}{\\sigma^2} = 0 \\implies \\frac{x-b^*}{\\sigma^2} = 0 \\implies b^* = x$$\n在第一个条件中使用 $b^*$ 的这个结果，我们求得 $s^*$：\n$$s^* + x = n \\implies s^* = n-x$$\nMLEs 为 $s^* = n-x$ 和 $b^*=x$。给定 $n=35$ 和 $x=28$。\n$$s^* = 35 - 28 = 7$$\n$$b^* = 28$$\n问题陈述要求假设一个内部解（$s>0, b>0$），这与这些结果是一致的。\n\n接下来，我们推导 MLEs 的渐近协方差矩阵。它由观测信息矩阵 $I(s^*, b^*)$ 的逆矩阵给出，该矩阵是对数似然函数的海森矩阵在 MLEs 处的负值。海森矩阵 $H$ 是二阶偏导数矩阵。\n\n我们来计算 $\\ell(s,b)$ 的二阶偏导数：\n$$\\frac{\\partial^2\\ell}{\\partial s^2} = \\frac{\\partial}{\\partial s} \\left(-1 + \\frac{n}{s+b}\\right) = -\\frac{n}{(s+b)^2}$$\n$$\\frac{\\partial^2\\ell}{\\partial b^2} = \\frac{\\partial}{\\partial b} \\left(-1 + \\frac{n}{s+b} + \\frac{x-b}{\\sigma^2}\\right) = -\\frac{n}{(s+b)^2} - \\frac{1}{\\sigma^2}$$\n$$\\frac{\\partial^2\\ell}{\\partial s \\partial b} = \\frac{\\partial}{\\partial b} \\left(-1 + \\frac{n}{s+b}\\right) = -\\frac{n}{(s+b)^2}$$\n根据 Clairaut 定理，$\\frac{\\partial^2\\ell}{\\partial b \\partial s} = \\frac{\\partial^2\\ell}{\\partial s \\partial b}$。海森矩阵为：\n$$H(s,b) = \\begin{pmatrix} \\frac{\\partial^2\\ell}{\\partial s^2} & \\frac{\\partial^2\\ell}{\\partial s \\partial b} \\\\ \\frac{\\partial^2\\ell}{\\partial b \\partial s} & \\frac{\\partial^2\\ell}{\\partial b^2} \\end{pmatrix} = \\begin{pmatrix} -\\frac{n}{(s+b)^2} & -\\frac{n}{(s+b)^2} \\\\ -\\frac{n}{(s+b)^2} & -\\frac{n}{(s+b)^2} - \\frac{1}{\\sigma^2} \\end{pmatrix}$$\n我们在 MLEs 处评估此矩阵，其中 $s^*+b^* = n$：\n$$H(s^*, b^*) = \\begin{pmatrix} -\\frac{n}{n^2} & -\\frac{n}{n^2} \\\\ -\\frac{n}{n^2} & -\\frac{n}{n^2} - \\frac{1}{\\sigma^2} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{n} & -\\frac{1}{n} \\\\ -\\frac{1}{n} & -\\frac{1}{n} - \\frac{1}{\\sigma^2} \\end{pmatrix}$$\n在 MLE 处的观测信息矩阵为 $I(s^*, b^*) = -H(s^*, b^*)$：\n$$I(s^*, b^*) = \\begin{pmatrix} \\frac{1}{n} & \\frac{1}{n} \\\\ \\frac{1}{n} & \\frac{1}{n} + \\frac{1}{\\sigma^2} \\end{pmatrix}$$\n渐近协方差矩阵 $C$ 是 $I(s^*, b^*)$ 的逆矩阵。对于一个 $2 \\times 2$ 矩阵 $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$，其逆矩阵为 $A^{-1} = \\frac{1}{ad-bc}\\begin{pmatrix} d & -b \\\\ -c & a \\end{pmatrix}$。\n$I(s^*, b^*)$ 的行列式是：\n$$\\det(I) = \\left(\\frac{1}{n}\\right)\\left(\\frac{1}{n} + \\frac{1}{\\sigma^2}\\right) - \\left(\\frac{1}{n}\\right)\\left(\\frac{1}{n}\\right) = \\frac{1}{n^2} + \\frac{1}{n\\sigma^2} - \\frac{1}{n^2} = \\frac{1}{n\\sigma^2}$$\n现在我们计算逆矩阵 $C$：\n$$C = [I(s^*, b^*)]^{-1} = \\frac{1}{1/(n\\sigma^2)} \\begin{pmatrix} \\frac{1}{n} + \\frac{1}{\\sigma^2} & -\\frac{1}{n} \\\\ -\\frac{1}{n} & \\frac{1}{n} \\end{pmatrix} = n\\sigma^2 \\begin{pmatrix} \\frac{\\sigma^2+n}{n\\sigma^2} & -\\frac{1}{n} \\\\ -\\frac{1}{n} & \\frac{1}{n} \\end{pmatrix}$$\n$$C = \\begin{pmatrix} n\\sigma^2 \\left(\\frac{\\sigma^2+n}{n\\sigma^2}\\right) & n\\sigma^2 \\left(-\\frac{1}{n}\\right) \\\\ n\\sigma^2 \\left(-\\frac{1}{n}\\right) & n\\sigma^2 \\left(\\frac{1}{n}\\right) \\end{pmatrix} = \\begin{pmatrix} n+\\sigma^2 & -\\sigma^2 \\\\ -\\sigma^2 & \\sigma^2 \\end{pmatrix}$$\n协方差矩阵 $C$ 包含估计量的方差和协方差：\n$$C = \\begin{pmatrix} \\operatorname{Var}(s^*) & \\operatorname{Cov}(s^*, b^*) \\\\ \\operatorname{Cov}(b^*, s^*) & \\operatorname{Var}(b^*) \\end{pmatrix}$$\n所以，我们有：\n$\\operatorname{Var}(s^*) = n+\\sigma^2$\n$\\operatorname{Cov}(s^*, b^*) = \\operatorname{Cov}(b^*, s^*) = -\\sigma^2$\n$\\operatorname{Var}(b^*) = \\sigma^2$\n\n给定 $n=35$ 和 $\\sigma=6$，所以 $\\sigma^2=36$。代入这些值：\n$\\operatorname{Var}(s^*) = 35 + 36 = 71$\n$\\operatorname{Cov}(s^*, b^*) = -36$\n$\\operatorname{Var}(b^*) = 36$\n\n需要在单行矩阵中报告的六个值是 $s^{\\ast}$、$b^{\\ast}$、$\\operatorname{Var}(s^{\\ast})$、$\\operatorname{Cov}(s^{\\ast}, b^{\\ast})$、$\\operatorname{Cov}(b^{\\ast}, s^{\\ast})$ 和 $\\operatorname{Var}(b^{\\ast})$。\n这些值是：\n$s^* = 7$\n$b^* = 28$\n$\\operatorname{Var}(s^*) = 71$\n$\\operatorname{Cov}(s^*, b^*) = -36$\n$\\operatorname{Cov}(b^*, s^*) = -36$\n$\\operatorname{Var}(b^*) = 36$\n这些将以指定格式呈现。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 7 & 28 & 71 & -36 & -36 & 36 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "测量探测器效率或筛选效率是实验物理中的一项基本任务，其结果通常遵循二项分布。本练习旨在为这样一个效率参数 $\\epsilon$ 构建置信区间，但它会引导您从贝叶斯和频率学派两种不同的视角来解决这个问题。您将首先推导并应用 Jeffreys 先验——一种基于 Fisher 信息论的原则性方法来选择无信息先验，然后构建贝叶斯可信区间。通过将贝叶斯区间与经典的 Clopper–Pearson 区间进行比较，并评估它们的频率学覆盖范围，您将深刻理解两种推断范式在实践中的表现差异及其背后的哲学思想。",
            "id": "3506258",
            "problem": "给定一个二项模型，其中在 $n$ 次试验中观测到的成功次数 $k$ 被建模为 $k \\sim \\mathrm{Bin}(n,\\epsilon)$，其中效率参数 $\\epsilon \\in [0,1]$ 未知。从统计推断和信息几何的第一性原理出发，执行以下任务：\n\n- 对于参数为 $\\epsilon$ 且 $n$ 固定的二项模型，推导其 Fisher 信息 $I(\\epsilon)$。使用定义 $I(\\epsilon) = \\mathbb{E}\\left[-\\frac{\\partial^2}{\\partial \\epsilon^2} \\log p(k \\mid n,\\epsilon)\\right]$，其中 $p(k \\mid n,\\epsilon)$ 是二项似然函数。\n- 使用 Jeffreys 先验的定义 $\\pi(\\epsilon) \\propto \\sqrt{I(\\epsilon)}$，推导二项模型中 $\\epsilon$ 的 Jeffreys 先验的形式。\n- 应用 Bayes 定理，在 Jeffreys 先验和二项似然下，推导后验分布 $p(\\epsilon \\mid k,n)$。将名义水平为 $1-\\alpha$ 的等尾贝叶斯可信区间定义为后验分布的 $\\alpha/2$ 和 $1-\\alpha/2$ 分位数之间的区间。\n- 通过对水平为 $\\alpha$ 的双边检验的二项累积分布函数进行反演来定义 Clopper–Pearson (CP) 置信区间，并将其端点表示为合适的 Beta 分布的分位数。CP 区间被用作频率学派的基准。\n\n实现一个完整的程序，该程序：\n1. 对于每个 $k \\in \\{0,1,\\dots,n\\}$，计算在 Jeffreys 先验下、名义水平为 $1-\\alpha$ 时 $\\epsilon$ 的等尾贝叶斯可信区间。\n2. 对于每个 $k \\in \\{0,1,\\dots,n\\}$，计算在相同名义水平 $1-\\alpha$ 下的 Clopper–Pearson (CP) 置信区间。\n3. 对于指定的真实效率 $\\epsilon$ 值的网格，通过对区间包含真实 $\\epsilon$ 的那些 $k$ 的二项概率求和，来评估每个区间的精确频率学派覆盖率。对于固定的真实 $\\epsilon$，将覆盖率定义为 $C(\\epsilon) = \\sum_{k=0}^{n} \\mathbb{I}\\{\\epsilon \\in [L(k),U(k)]\\} \\cdot \\mathrm{Bin}(k;n,\\epsilon)$，其中 $[L(k),U(k)]$ 是为 $k$ 计算的区间，$\\mathbb{I}\\{\\cdot\\}$ 是指示函数。\n4. 对于每个测试用例，为每种区间类型计算两个摘要指标： \n   - 相对于名义覆盖率的最差情况下的不足，定义为 $\\min_{\\epsilon \\text{ in grid}} \\left( C(\\epsilon) - (1-\\alpha) \\right)$。\n   - 网格上的平均绝对覆盖误差，定义为 $\\frac{1}{M}\\sum_{i=1}^{M} \\left| C(\\epsilon_i) - (1-\\alpha) \\right|$，其中 $M$ 是网格点的数量。\n\n使用以下参数值测试套件，这些测试套件探测了典型条件和边缘情况：\n- 情况 1：$n=10$，$\\alpha=0.1$，以及一个包含 21 个效率值的网格 $\\epsilon \\in \\{0.00,0.05,\\dots,1.00\\}$。\n- 情况 2：$n=20$，$\\alpha=0.1$，以及一个包含 11 个效率值的网格 $\\epsilon \\in \\{0.00,0.10,\\dots,1.00\\}$。\n- 情况 3：$n=20$，$\\alpha=0.32$，以及一个包含 21 个效率值的网格 $\\epsilon \\in \\{0.00,0.05,\\dots,1.00\\}$。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，输出一个包含四个浮点数的列表：[贝叶斯区间的最大不足，Clopper–Pearson 区间的最大不足，贝叶斯区间的平均绝对覆盖误差，Clopper–Pearson 区间的平均绝对覆盖误差]。将三个测试用例的结果列表聚合到一个顶级列表中并打印出来。例如，$\\left[\\left[a_1,b_1,c_1,d_1\\right],\\left[a_2,b_2,c_2,d_2\\right],\\left[a_3,b_3,c_3,d_3\\right]\\right]$。所有的覆盖率和不足量必须表示为小数值，不带百分号。",
            "solution": "该问题要求对二项比例参数 $\\epsilon$ 的贝叶斯可信区间和频率学派置信区间进行透彻的分析和比较。验证证实了该问题具有科学依据、是适定的、客观的，并包含得出唯一解所需的所有信息。其中的定义和方法论是统计推断领域的标准。\n\n### 理论推导\n\n首先，我们按照要求从第一性原理出发推导必要的理论部分。\n\n**1. 二项模型的 Fisher 信息**\n\nFisher 信息 $I(\\epsilon)$ 量化了可观测随机变量 $k$ 所携带的关于未知参数 $\\epsilon$ 的信息量。对于二项模型，在 $n$ 次试验中观测到 $k$ 次成功的似然由概率质量函数给出：\n$$p(k \\mid n,\\epsilon) = \\binom{n}{k} \\epsilon^k (1-\\epsilon)^{n-k}$$\n对数似然 $\\ell(\\epsilon) = \\log p(k \\mid n,\\epsilon)$ 为：\n$$\\ell(\\epsilon) = \\log\\binom{n}{k} + k \\log \\epsilon + (n-k) \\log(1-\\epsilon)$$\n为了求出 Fisher 信息，我们计算对数似然关于 $\\epsilon$ 的二阶偏导数：\n$$\\frac{\\partial \\ell}{\\partial \\epsilon} = \\frac{k}{\\epsilon} - \\frac{n-k}{1-\\epsilon}$$\n$$\\frac{\\partial^2 \\ell}{\\partial \\epsilon^2} = -\\frac{k}{\\epsilon^2} - \\frac{n-k}{(1-\\epsilon)^2}$$\nFisher 信息定义为该二阶导数负值的期望：\n$$I(\\epsilon) = \\mathbb{E}\\left[-\\frac{\\partial^2 \\ell}{\\partial \\epsilon^2}\\right] = \\mathbb{E}\\left[\\frac{k}{\\epsilon^2} + \\frac{n-k}{(1-\\epsilon)^2}\\right]$$\n利用期望的线性性质以及对于二项分布 $\\mathbb{E}[k] = n\\epsilon$ 这一事实，我们得到：\n$$I(\\epsilon) = \\frac{\\mathbb{E}[k]}{\\epsilon^2} + \\frac{n-\\mathbb{E}[k]}{(1-\\epsilon)^2} = \\frac{n\\epsilon}{\\epsilon^2} + \\frac{n-n\\epsilon}{(1-\\epsilon)^2}$$\n$$I(\\epsilon) = \\frac{n}{\\epsilon} + \\frac{n(1-\\epsilon)}{(1-\\epsilon)^2} = \\frac{n}{\\epsilon} + \\frac{n}{1-\\epsilon} = \\frac{n(1-\\epsilon) + n\\epsilon}{\\epsilon(1-\\epsilon)}$$\n$$I(\\epsilon) = \\frac{n}{\\epsilon(1-\\epsilon)}$$\n\n**2. 二项参数的 Jeffreys 先验**\n\nJeffreys 先验是一种从 Fisher 信息推导出的无信息先验，定义为 $\\pi(\\epsilon) \\propto \\sqrt{I(\\epsilon)}$。它的设计使其在参数重整化下保持不变。\n使用推导出的 Fisher 信息：\n$$\\pi(\\epsilon) \\propto \\sqrt{\\frac{n}{\\epsilon(1-\\epsilon)}} \\propto \\frac{1}{\\sqrt{\\epsilon(1-\\epsilon)}} = \\epsilon^{-1/2} (1-\\epsilon)^{-1/2}$$\n该函数形式与 Beta 分布的概率密度函数 $\\mathrm{Beta}(\\epsilon; \\alpha, \\beta) \\propto \\epsilon^{\\alpha-1} (1-\\epsilon)^{\\beta-1}$ 成正比。通过比较指数，我们发现：\n$$\\alpha - 1 = -1/2 \\implies \\alpha = 1/2$$\n$$\\beta - 1 = -1/2 \\implies \\beta = 1/2$$\n因此，二项参数 $\\epsilon$ 的 Jeffreys 先验是一个 $\\mathrm{Beta}(1/2, 1/2)$ 分布。\n\n**3. 贝叶斯后验和可信区间**\n\n后验分布 $p(\\epsilon \\mid k,n)$ 是通过应用 Bayes 定理得到的，该定理指出后验与似然和先验的乘积成正比：\n$$p(\\epsilon \\mid k,n) \\propto p(k \\mid n,\\epsilon) \\pi(\\epsilon)$$\n代入二项似然和 Jeffreys 先验：\n$$p(\\epsilon \\mid k,n) \\propto \\left(\\epsilon^k (1-\\epsilon)^{n-k}\\right) \\cdot \\left(\\epsilon^{1/2-1} (1-\\epsilon)^{1/2-1}\\right)$$\n$$p(\\epsilon \\mid k,n) \\propto \\epsilon^{k+1/2-1} (1-\\epsilon)^{n-k+1/2-1}$$\n这是一个具有更新后参数的 Beta 分布的核。$\\epsilon$ 的后验分布是：\n$$p(\\epsilon \\mid k,n) = \\mathrm{Beta}(\\epsilon; k+1/2, n-k+1/2)$$\n名义水平为 $1-\\alpha$ 的等尾贝叶斯可信区间是由该后验分布的 $\\alpha/2$ 和 $1-\\alpha/2$ 分位数定义的区间 $[\\epsilon_L, \\epsilon_U]$。\n\n**4. Clopper–Pearson 置信区间**\n\nClopper–Pearson (CP) 区间是一种频率学派方法，它保证对于所有可能的 $\\epsilon$ 值，覆盖概率至少为 $1-\\alpha$。它是通过对一系列双边二项检验进行反演来构建的。对于观测到的成功次数 $k$，区间 $[\\epsilon_L, \\epsilon_U]$ 是通过求解以下关于 $\\epsilon$ 的方程得到的：\n$$ \\text{对于下界 } \\epsilon_L: \\quad P(X \\ge k \\mid n, \\epsilon_L) = \\sum_{j=k}^{n} \\binom{n}{j} \\epsilon_L^j (1-\\epsilon_L)^{n-j} = \\frac{\\alpha}{2} $$\n$$ \\text{对于上界 } \\epsilon_U: \\quad P(X \\le k \\mid n, \\epsilon_U) = \\sum_{j=0}^{k} \\binom{n}{j} \\epsilon_U^j (1-\\epsilon_U)^{n-j} = \\frac{\\alpha}{2} $$\n这些方程可以用 Beta 分布的分位数来表示。下界 $\\epsilon_L$ 是 $\\mathrm{Beta}(k, n-k+1)$ 分布的 $\\alpha/2$ 分位数。上界 $\\epsilon_U$ 是 $\\mathrm{Beta}(k+1, n-k)$ 分布的 $1-\\alpha/2$ 分位数。对于边缘情况，当 $k=0$ 时，$\\epsilon_L = 0$；当 $k=n$ 时，$\\epsilon_U = 1$。\n\n### 计算策略\n\n实现将遵循这些理论结果来计算和比较这两种区间类型。\n\n1.  **区间计算**：对于给定的测试用例 $(n, \\alpha)$，我们首先遍历所有可能的成功次数 $k \\in \\{0, 1, \\dots, n\\}$。对于每个 $k$，我们计算贝叶斯区间和 Clopper-Pearson 区间。\n    *   **贝叶斯区间**：端点是后验分布 $\\mathrm{Beta}(k+0.5, n-k+0.5)$ 的 $\\alpha/2$ 和 $1-\\alpha/2$ 分位数。\n    *   **Clopper–Pearson 区间**：端点是 $\\mathrm{Beta}(k, n-k+1)$ 的 $\\alpha/2$ 分位数和 $\\mathrm{Beta}(k+1, n-k)$ 的 $1-\\alpha/2$ 分位数，并对 $k=0$（下界为 0）和 $k=n$（上界为 1）进行特殊处理。\n\n2.  **覆盖率评估**：对于指定网格中的每个真实效率值 $\\epsilon$，我们计算每种区间类型的频率学派覆盖率。覆盖率 $C(\\epsilon)$ 是随机区间 $[L(k), U(k)]$ 包含真实 $\\epsilon$ 的概率。这是通过对所有真实 $\\epsilon$ 落在为该 $k$ 计算出的区间内的结果 $k$ 的二项概率 $\\mathrm{Bin}(k; n, \\epsilon)$ 求和来计算的：\n    $$C(\\epsilon) = \\sum_{k=0}^{n} \\mathbb{I}\\{\\epsilon \\in [L(k), U(k)]\\} \\cdot \\mathrm{Bin}(k; n, \\epsilon)$$\n    其中 $\\mathbb{I}\\{\\cdot\\}$ 是指示函数。\n\n3.  **指标计算**：在计算完网格中所有 $M$ 个点的覆盖率 $C(\\epsilon_i)$ 后，我们为每种区间类型计算两个摘要指标：\n    *   **最差情况下的不足**：网格上实际覆盖率与名义覆盖率 $1-\\alpha$ 之间的最小差值：$\\min_{\\epsilon_i} (C(\\epsilon_i) - (1-\\alpha))$。负值表示覆盖不足。\n    *   **平均绝对覆盖误差**：覆盖率与名义水平的平均绝对偏差：$\\frac{1}{M}\\sum_{i=1}^{M} |C(\\epsilon_i) - (1-\\alpha)|$。\n\n对问题中定义的三个测试用例中的每一个重复此过程。最终程序将汇总并打印每个测试用例的四个计算指标。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import beta, binom\n\ndef compute_metrics(n: int, alpha: float, epsilon_grid: np.ndarray):\n    \"\"\"\n    Computes and evaluates Bayesian and Clopper-Pearson intervals.\n\n    Args:\n        n: The number of trials.\n        alpha: The significance level.\n        epsilon_grid: A grid of true efficiency values to evaluate coverage.\n\n    Returns:\n        A list containing four floats:\n        [worst-case deficit for Bayesian, worst-case deficit for CP,\n         mean absolute error for Bayesian, mean absolute error for CP].\n    \"\"\"\n    ks = np.arange(n + 1)\n    \n    # 1. Compute intervals for all possible outcomes k\n    bayesian_intervals = np.zeros((n + 1, 2))\n    cp_intervals = np.zeros((n + 1, 2))\n\n    for k in ks:\n        # Bayesian interval with Jeffreys prior (Posterior is Beta(k+0.5, n-k+0.5))\n        post_a = k + 0.5\n        post_b = n - k + 0.5\n        bayesian_intervals[k, :] = beta.ppf([alpha / 2, 1 - alpha / 2], post_a, post_b)\n\n        # Clopper-Pearson interval\n        cp_lower = 0.0 if k == 0 else beta.ppf(alpha / 2, k, n - k + 1)\n        cp_upper = 1.0 if k == n else beta.ppf(1 - alpha / 2, k + 1, n - k)\n        cp_intervals[k, :] = [cp_lower, cp_upper]\n\n    # 2. Compute frequentist coverage for each epsilon in the grid\n    nominal_coverage = 1.0 - alpha\n    bayesian_coverages = []\n    cp_coverages = []\n\n    for eps in epsilon_grid:\n        # Binomial probabilities for all k given the true epsilon\n        binom_probs = binom.pmf(ks, n, eps)\n        \n        # Check which k's result in an interval that covers the true epsilon\n        is_covered_bayes = (bayesian_intervals[:, 0] <= eps) & (eps <= bayesian_intervals[:, 1])\n        is_covered_cp = (cp_intervals[:, 0] <= eps) & (eps <= cp_intervals[:, 1])\n        \n        # Sum the probabilities of the k's that produce a covering interval\n        bayesian_coverages.append(np.sum(binom_probs[is_covered_bayes]))\n        cp_coverages.append(np.sum(binom_probs[is_covered_cp]))\n    \n    bayesian_coverages = np.array(bayesian_coverages)\n    cp_coverages = np.array(cp_coverages)\n    \n    # 3. Compute summary metrics\n    # Worst-case deficit relative to nominal coverage\n    bayesian_deficit = np.min(bayesian_coverages - nominal_coverage)\n    cp_deficit = np.min(cp_coverages - nominal_coverage)\n    \n    # Mean absolute coverage error\n    bayesian_mae = np.mean(np.abs(bayesian_coverages - nominal_coverage))\n    cp_mae = np.mean(np.abs(cp_coverages - nominal_coverage))\n\n    return [bayesian_deficit, cp_deficit, bayesian_mae, cp_mae]\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test cases and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'n': 10, 'alpha': 0.1, 'grid_points': 21},\n        {'n': 20, 'alpha': 0.1, 'grid_points': 11},\n        {'n': 20, 'alpha': 0.32, 'grid_points': 21},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        n = case['n']\n        alpha = case['alpha']\n        epsilon_grid = np.linspace(0.0, 1.0, case['grid_points'])\n        \n        result = compute_metrics(n, alpha, epsilon_grid)\n        all_results.append(result)\n\n    # Format the final output string to match the problem specification\n    # e.g., [[a1,b1,c1,d1],[a2,b2,c2,d2],[a3,b3,c3,d3]] with no spaces.\n    case_strings = []\n    for res in all_results:\n        case_strings.append(f\"[{','.join(map(str, res))}]\")\n    \n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "在寻找新物理信号的过程中，当观测数据未显示显著超出时，我们需要为该信号的强度设定一个上限。本练习将引导您使用两种精密的方法来解决这个前沿问题：一种是高能物理领域广泛采用的 $\\mathrm{CL_s}$ 方法，另一种是考虑了非高斯系统误差的完整贝叶斯分析。这个实践不仅能锻炼您处理带有讨厌参数的复杂模型的数值计算能力，还将揭示这两种看似不同的统计方法之间深刻而有趣的内在联系，加深您对统计推断本质的理解。",
            "id": "3506302",
            "problem": "考虑一个在计算高能物理中典型的单计数区间计数实验。观测到的计数值 $n$ 被建模为一个均值为 $\\mu_s + \\mu_b$ 的泊松随机变量，其中 $\\mu_s \\ge 0$ 是未知的信号强度，$\\mu_b > 0$ 是一个受非高斯先验不确定度影响的本底贡献。讨厌参数 $\\mu_b$ 服从对数正态先验分布，其对数服从正态分布，即 $\\log \\mu_b \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$。\n\n从第一性原理出发：\n- 泊松概率质量函数为 $P(N=n \\mid \\lambda) = \\exp(-\\lambda) \\lambda^n / n!$，其中整数 $n \\ge 0$，率 $\\lambda > 0$。\n- 贝叶斯定理指出 $p(\\mu_s \\mid n) \\propto p(n \\mid \\mu_s) \\, \\pi(\\mu_s)$，其中 $p(n \\mid \\mu_s) = \\int P(N=n \\mid \\mu_s + \\mu_b) \\, \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b$，$\\pi(\\mu_s)$ 和 $\\pi(\\mu_b)$ 是先验。\n- $\\mu_b$ 的对数正态先验由 $t=\\log \\mu_b$ 的正态密度定义，其均值为 $\\mu_t$，标准差为 $\\sigma_t$，即 $\\phi(t; \\mu_t, \\sigma_t) = \\frac{1}{\\sqrt{2\\pi}\\sigma_t} \\exp\\left( -\\frac{(t-\\mu_t)^2}{2\\sigma_t^2} \\right)$。\n\n将置信水平 (CL) 度量 $\\mathrm{CL_s}$（用于在水平 $\\alpha$ 下给出 $\\mu_s$ 的上限）定义为比率\n$$\n\\mathrm{CL_s}(\\mu_s; n) = \\frac{p_{\\mathrm{sb}}(n; \\mu_s)}{p_{\\mathrm{b}}(n)},\n$$\n其中 $p_{\\mathrm{sb}}(n; \\mu_s)$ 是在信号加本底假设下的单边向下尾部概率，$p_{\\mathrm{b}}(n)$ 是在唯本底假设下相应的尾部概率：\n$$\np_{\\mathrm{sb}}(n; \\mu_s) = \\int \\left[ \\sum_{k=0}^{n} \\exp\\left( -(\\mu_s+\\mu_b) \\right) \\frac{(\\mu_s+\\mu_b)^k}{k!} \\right] \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b,\n$$\n$$\np_{\\mathrm{b}}(n) = \\int \\left[ \\sum_{k=0}^{n} \\exp\\left( -\\mu_b \\right) \\frac{\\mu_b^k}{k!} \\right] \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b.\n$$\n上限 $\\mu_s^{95}$ 定义为满足 $\\mathrm{CL_s}(\\mu_s; n) \\le \\alpha$ 的最小 $\\mu_s$，其中 $\\alpha$ 是固定的（本问题中取 $\\alpha = 0.05$）。\n\n对于贝叶斯分析，对信号采用 $\\mu_s \\ge 0$ 上的非适用的无信息先验 $\\pi(\\mu_s) \\propto 1$，对讨厌参数 $\\mu_b$ 采用上述的对数正态先验。后验 $p(\\mu_s \\mid n)$ 与通过对 $\\mu_b$ 积分得到的边缘似然 $p(n \\mid \\mu_s)$ 成正比。$\\mu_s$ 的等尾 $(1-\\alpha)$ 贝叶斯可信区间为 $[\\mu_{s,\\mathrm{lo}}, \\mu_{s,\\mathrm{hi}}]$，满足\n$$\n\\int_{0}^{\\mu_{s,\\mathrm{lo}}} p(\\mu_s \\mid n) \\, \\mathrm{d}\\mu_s = \\frac{\\alpha}{2}, \\quad \\int_{0}^{\\mu_{s,\\mathrm{hi}}} p(\\mu_s \\mid n) \\, \\mathrm{d}\\mu_s = 1 - \\frac{\\alpha}{2}.\n$$\n需要报告的区间长度为 $\\mu_{s,\\mathrm{hi}} - \\mu_{s,\\mathrm{lo}}$。\n\n实现一个程序，为每个测试用例计算：\n1. $\\mathrm{CL_s}$ $95\\%$ 上限 $\\mu_s^{95}$（无单位），定义为使得 $\\mathrm{CL_s}(\\mu_s; n) \\le 0.05$ 的最小 $\\mu_s$，使用上述的向下尾部定义。\n2. $\\mu_s$ 的 $(1-0.05)=0.95$ 等尾贝叶斯可信区间的长度 $\\mu_{s,\\mathrm{hi}} - \\mu_{s,\\mathrm{lo}}$（无单位）。\n\n所有量都是无量纲的；不需要物理单位。不涉及角度。区间概率以 $[0,1]$ 内的小数表示。\n\n您的实现必须从上述定义推导而来，使用 $\\log \\mu_b \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$ 对 $\\mu_b$ 进行对数正态先验参数化。程序不应依赖任何未从这些定义推导出的封闭形式的快捷公式；它必须基于严谨的推导和数值稳健的算法。\n\n测试套件参数集：\n- 情况 $1$：$n=0$，$\\mu_t=\\ln(2)$，$\\sigma_t=0.6$。\n- 情况 $2$：$n=3$，$\\mu_t=\\ln(1)$，$\\sigma_t=1.0$。\n- 情况 $3$：$n=7$，$\\mu_t=\\ln(5)$，$\\sigma_t=0.3$。\n- 情况 $4$：$n=10$，$\\mu_t=\\ln(2)$，$\\sigma_t=0.8$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，并且本身是一个双元素列表 $[\\mu_s^{95}, \\ell]$，其中 $\\ell = \\mu_{s,\\mathrm{hi}} - \\mu_{s,\\mathrm{lo}}$。例如，一个有效的输出行格式为 $[[x_1,y_1],[x_2,y_2],[x_3,y_3],[x_4,y_4]]$。",
            "solution": "用户提供的问题陈述已经过仔细验证。\n\n### 第 1 步：提取已知条件\n- **模型**：单计数区间计数实验。\n- **观测值**：一个整数计数值 $n \\ge 0$。\n- **似然**：计数值 $n$ 是一个泊松随机变量，$N \\sim \\text{Poisson}(\\lambda)$，其概率质量函数为 $P(N=n \\mid \\lambda) = \\exp(-\\lambda) \\lambda^n / n!$。率是 $\\lambda = \\mu_s + \\mu_b$。\n- **信号参数**：$\\mu_s \\ge 0$ 是未知的信号强度。\n- **讨厌参数**：$\\mu_b > 0$ 是本底贡献。\n- **$\\mu_b$ 的先验**：$\\mu_b$ 服从对数正态先验，由 $\\log \\mu_b \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$ 指定。$t = \\log \\mu_b$ 的密度为 $\\phi(t; \\mu_t, \\sigma_t) = \\frac{1}{\\sqrt{2\\pi}\\sigma_t} \\exp\\left( -\\frac{(t-\\mu_t)^2}{2\\sigma_t^2} \\right)$。\n- **频率学派度量**：$\\mathrm{CL_s}(\\mu_s; n) = \\frac{p_{\\mathrm{sb}}(n; \\mu_s)}{p_{\\mathrm{b}}(n)}$。\n  - $p_{\\mathrm{sb}}(n; \\mu_s) = \\int \\left[ \\sum_{k=0}^{n} \\exp\\left( -(\\mu_s+\\mu_b) \\right) \\frac{(\\mu_s+\\mu_b)^k}{k!} \\right] \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b$。\n  - $p_{\\mathrm{b}}(n) = \\int \\left[ \\sum_{k=0}^{n} \\exp\\left( -\\mu_b \\right) \\frac{\\mu_b^k}{k!} \\right] \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b$。\n- **频率学派上限**：$95\\%$ 上限 $\\mu_s^{95}$ 是使得 $\\mathrm{CL_s}(\\mu_s; n) \\le \\alpha$ 的最小 $\\mu_s$，其中 $\\alpha = 0.05$。\n- **$\\mu_s$ 的贝叶斯先验**：对于 $\\mu_s \\ge 0$ 的非适用的无信息先验 $\\pi(\\mu_s) \\propto 1$。\n- **贝叶斯可信区间**：等尾 $(1-\\alpha)$ 可信区间 $[\\mu_{s,\\mathrm{lo}}, \\mu_{s,\\mathrm{hi}}]$ 由 $\\int_{0}^{\\mu_{s,\\mathrm{lo}}} p(\\mu_s \\mid n) \\, \\mathrm{d}\\mu_s = \\alpha/2$ 和 $\\int_{0}^{\\mu_{s,\\mathrm{hi}}} p(\\mu_s \\mid n) \\, \\mathrm{d}\\mu_s = 1 - \\alpha/2$ 定义，其中 $\\alpha=0.05$。\n- **要求的贝叶斯输出**：区间长度 $\\mu_{s,\\mathrm{hi}} - \\mu_{s,\\mathrm{lo}}$。\n- **测试用例**：\n  1. $n=0$，$\\mu_t=\\ln(2)$，$\\sigma_t=0.6$。\n  2. $n=3$，$\\mu_t=\\ln(1)$，$\\sigma_t=1.0$。\n  3. $n=7$，$\\mu_t=\\ln(5)$，$\\sigma_t=0.3$。\n  4. $n=10$，$\\mu_t=\\ln(2)$，$\\sigma_t=0.8$。\n\n### 第 2 步：使用提取的已知条件进行验证\n- **科学依据充分**：该问题是高能物理中统计推断的一个典型例子，采用了标准的泊松模型、用于系统不确定度的对数正态先验，以及成熟的频率学派 ($\\mathrm{CL_s}$) 和贝叶斯方法。其前提在事实上是合理的，并根植于概率论。\n- **适定的**：该问题为确定每个测试用例的唯一解提供了所有必要的定义、数据和约束。\n- **客观的**：该问题使用精确、无歧义的数学和统计语言陈述。\n\n该问题没有表现出任何无效性缺陷。\n\n### 第 3 步：结论与行动\n该问题是**有效的**。将构建一个有原则的解决方案。\n\n### 解法推导\n\n该问题要求计算频率学派上限和贝叶斯可信区间长度。这两种计算都依赖于对讨厌参数 $\\mu_b$ 进行平均，该参数具有对数正态先验分布。\n\n**1. 频率学派 $\\mathrm{CL_s}$ 上限计算**\n\n核心量是 $\\mathrm{CL_s}(\\mu_s; n) = p_{\\mathrm{sb}}(n; \\mu_s) / p_{\\mathrm{b}}(n)$。项 $p_{\\mathrm{sb}}$ 和 $p_{\\mathrm{b}}$ 被定义为积分。方括号内的表达式是泊松分布的累积分布函数 (CDF)，$F_{\\text{Poisson}}(n; \\lambda) = \\sum_{k=0}^{n} e^{-\\lambda} \\lambda^k / k!$。\n因此，我们有：\n$$\np_{\\mathrm{sb}}(n; \\mu_s) = \\int_0^\\infty F_{\\text{Poisson}}(n; \\mu_s + \\mu_b) \\, \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b\n$$\n$$\np_{\\mathrm{b}}(n) = \\int_0^\\infty F_{\\text{Poisson}}(n; \\mu_b) \\, \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b\n$$\n$\\mu_b$ 的先验是对数正态的，意味着 $t = \\log \\mu_b$ 服从均值为 $\\mu_t$、方差为 $\\sigma_t^2$ 的正态分布。$t$ 的概率密度是 $\\phi(t; \\mu_t, \\sigma_t)$。为了计算这些积分，我们将积分变量从 $\\mu_b$ 变为 $t = \\log\\mu_b$。这得到 $\\mu_b = e^t$ 和 $\\mathrm{d}\\mu_b = e^t \\, \\mathrm{d}t$。$\\mu_b$ 的先验密度是 $\\pi(\\mu_b) = \\phi(\\log \\mu_b; \\mu_t, \\sigma_t) / \\mu_b$。积分变为：\n$$\np_{\\mathrm{sb}}(n; \\mu_s) = \\int_{-\\infty}^\\infty F_{\\text{Poisson}}(n; \\mu_s + e^t) \\, \\phi(t; \\mu_t, \\sigma_t) \\, \\mathrm{d}t\n$$\n这些在高斯核上的积分非常适合使用高斯-埃尔米特求积法。我们进行一次替换以匹配标准的高斯-埃尔米特权重函数 $e^{-x^2}$。令 $x = (t - \\mu_t) / (\\sqrt{2}\\sigma_t)$，则 $t = \\sqrt{2}\\sigma_t x + \\mu_t$ 且 $\\phi(t; \\mu_t, \\sigma_t) \\, \\mathrm{d}t = \\frac{1}{\\sqrt{\\pi}} e^{-x^2} \\, \\mathrm{d}x$。$p_{\\mathrm{sb}}$ 的积分（$p_{\\mathrm{b}}$ 也类似）变为：\n$$\np_{\\mathrm{sb}}(n; \\mu_s) = \\frac{1}{\\sqrt{\\pi}} \\int_{-\\infty}^\\infty F_{\\text{Poisson}}(n; \\mu_s + e^{\\sqrt{2}\\sigma_t x + \\mu_t}) \\, e^{-x^2} \\, \\mathrm{d}x\n$$\n这可以通过求积和来近似：\n$$\np_{\\mathrm{sb}}(n; \\mu_s) \\approx \\frac{1}{\\sqrt{\\pi}} \\sum_{i=1}^{N_{GH}} w_i F_{\\text{Poisson}}(n; \\mu_s + e^{\\sqrt{2}\\sigma_t x_i + \\mu_t})\n$$\n其中 $x_i$ 和 $w_i$ 是 $N_{GH}$ 阶高斯-埃尔米特求积的节点和权重。因子 $1/\\sqrt{\\pi}$ 在 $\\mathrm{CL_s}$ 比率中被抵消，简化了计算。\n\n上限 $\\mu_s^{95}$ 是方程 $\\mathrm{CL_s}(\\mu_s; n) - 0.05 = 0$ 的根。函数 $\\mathrm{CL_s}(\\mu_s; n)$ 在 $\\mu_s$ 上是单调递减的，确保了存在唯一的根，可以使用像 Brent 方法这样的数值求解器高效地找到这个根。\n\n**2. 贝叶斯可信区间计算**\n\n$\\mu_s$ 的后验概率密度由贝叶斯定理给出：$p(\\mu_s \\mid n) \\propto p(n \\mid \\mu_s) \\pi(\\mu_s)$。对于 $\\mu_s \\ge 0$ 的平坦先验 $\\pi(\\mu_s) \\propto 1$，后验与边缘似然成正比，$p(\\mu_s \\mid n) \\propto p(n \\mid \\mu_s)$。边缘似然通过对讨厌参数 $\\mu_b$ 积分得到：\n$$\np(n \\mid \\mu_s) = \\int_0^\\infty P(N=n \\mid \\mu_s + \\mu_b) \\, \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b\n$$\n后验累积分布函数 (CDF) 是 $C(\\mu_s) = \\int_0^{\\mu_s} p(\\mu_s' \\mid n) \\, \\mathrm{d}\\mu_s'$。要计算这个，我们通常会面临一个具有挑战性的二重积分。然而，通过交换积分顺序，我们发现了一个显著的简化：\n$$\n\\int_0^{\\mu_s} p(n \\mid \\mu_s') \\, \\mathrm{d}\\mu_s' = \\int_0^\\infty \\pi(\\mu_b) \\left( \\int_0^{\\mu_s} P(N=n \\mid \\mu_s' + \\mu_b) \\, \\mathrm{d}\\mu_s' \\right) \\mathrm{d}\\mu_b\n$$\n对 $\\mu_s'$ 的内层积分可以解析求解。令 $\\lambda' = \\mu_s'+\\mu_b$。该积分为 $\\int_{\\mu_b}^{\\mu_s+\\mu_b} P(N=n \\mid \\lambda') \\, \\mathrm{d}\\lambda' = \\int_{\\mu_b}^{\\mu_s+\\mu_b} \\frac{(\\lambda')^n e^{-\\lambda'}}{n!} \\, \\mathrm{d}\\lambda'$。这等于 $F_{\\text{Poisson}}(n; \\mu_b) - F_{\\text{Poisson}}(n; \\mu_s + \\mu_b)$。将其代回得到：\n$$\n\\int_0^{\\mu_s} p(n \\mid \\mu_s') \\, \\mathrm{d}\\mu_s' = \\int_0^\\infty \\left[ F_{\\text{Poisson}}(n; \\mu_b) - F_{\\text{Poisson}}(n; \\mu_s + \\mu_b) \\right] \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b = p_{\\mathrm{b}}(n) - p_{\\mathrm{sb}}(n; \\mu_s)\n$$\n后验的归一化常数是积分到 $\\mu_s \\to \\infty$ 的结果，此时 $p_{\\mathrm{sb}} \\to 0$。因此，归一化常数是 $p_{\\mathrm{b}}(n)$。所以后验 CDF 是：\n$$\nC(\\mu_s) = \\frac{p_{\\mathrm{b}}(n) - p_{\\mathrm{sb}}(n; \\mu_s)}{p_{\\mathrm{b}}(n)} = 1 - \\mathrm{CL_s}(\\mu_s; n)\n$$\n这个优美的结果将贝叶斯后验 CDF 直接与频率学派的 $\\mathrm{CL_s}$ 度量联系起来。等尾可信区间界 $[\\mu_{s,\\mathrm{lo}}, \\mu_{s,\\mathrm{hi}}]$ 通过求解以下方程找到：\n- $C(\\mu_{s,\\mathrm{lo}}) = \\alpha/2 \\implies 1 - \\mathrm{CL_s}(\\mu_{s,\\mathrm{lo}}; n) = 0.025 \\implies \\mathrm{CL_s}(\\mu_{s,\\mathrm{lo}}; n) = 0.975$\n- $C(\\mu_{s,\\mathrm{hi}}) = 1-\\alpha/2 \\implies 1 - \\mathrm{CL_s}(\\mu_{s,\\mathrm{hi}}; n) = 0.975 \\implies \\mathrm{CL_s}(\\mu_{s,\\mathrm{hi}}; n) = 0.025$\n\n用于找到 $\\mu_s^{95}$ 的相同数值机制可以用来找到 $\\mu_{s,\\mathrm{lo}}$ 和 $\\mu_{s,\\mathrm{hi}}$。\n\n**3. 特殊情况：$n=0$**\n\n对于观测计数值 $n=0$ 的情况，泊松 CDF 为 $F_{\\text{Poisson}}(0; \\lambda) = e^{-\\lambda}$。积分显著简化：\n- $p_{\\mathrm{sb}}(0; \\mu_s) = \\int e^{-(\\mu_s+\\mu_b)} \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b = e^{-\\mu_s} \\int e^{-\\mu_b} \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b$\n- $p_{\\mathrm{b}}(0) = \\int e^{-\\mu_b} \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b$\n比值为 $\\mathrm{CL_s}(\\mu_s; 0) = e^{-\\mu_s}$，这与本底先验无关。这使得测试用例 1 可以得到解析解：\n- $\\mu_s^{95}: e^{-\\mu_s} = 0.05 \\implies \\mu_s^{95} = -\\ln(0.05)$。\n- $\\mu_{s,\\mathrm{lo}}: e^{-\\mu_s} = 0.975 \\implies \\mu_{s,\\mathrm{lo}} = -\\ln(0.975)$。\n- $\\mu_{s,\\mathrm{hi}}: e^{-\\mu_s} = 0.025 \\implies \\mu_{s,\\mathrm{hi}} = -\\ln(0.025)$。\n区间长度为 $\\ell = \\mu_{s,\\mathrm{hi}} - \\mu_{s,\\mathrm{lo}} = -\\ln(0.025) + \\ln(0.975) = \\ln(0.975/0.025) = \\ln(39)$。\n\n实现将对 $n=0$ 使用这些解析形式，对 $n>0$ 使用数值方法。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import poisson\nfrom scipy.special import roots_hermite\nfrom scipy.optimize import brentq\nimport math\n\n# Global constants for numerical precision and calculations\nN_GH = 64  # Degree of Gauss-Hermite quadrature\nNODES, WEIGHTS = roots_hermite(N_GH)\n\ndef calculate_cls(mu_s, n, mu_t, sigma_t):\n    \"\"\"\n    Calculates the CLs value for a given signal strength mu_s.\n    \n    The calculation is based on the ratio of two integrals, p_sb/p_b, which are\n    evaluated using Gauss-Hermite quadrature.\n    \"\"\"\n    # For n=0, CLs has a simple analytic form, exp(-mu_s), independent of the\n    # background prior. This avoids numerical integration and is exact.\n    if n == 0:\n        # mu_s must be non-negative.\n        if mu_s < 0:\n            return 1.0 # By continuous extension as CLs(0)=1\n        return np.exp(-mu_s)\n\n    # Change of variables for Gauss-Hermite quadrature.\n    # The integration is over a standard normal variable 'x', which is related\n    # to t=log(mu_b) by t = sqrt(2)*sigma_t*x + mu_t.\n    t_values = math.sqrt(2) * sigma_t * NODES + mu_t\n    mu_b_values = np.exp(t_values)\n    \n    # Calculate Poisson CDF values for signal+background and background-only hypotheses\n    # at each quadrature node.\n    # poisson.cdf(k, mu) calculates sum_{i=0 to k} exp(-mu) * mu^i / i!\n    poisson_cdf_sb = poisson.cdf(n, mu_s + mu_b_values)\n    poisson_cdf_b = poisson.cdf(n, mu_b_values)\n\n    # The integrals for p_sb and p_b are approximated by the weighted sums.\n    # The factor 1/sqrt(pi) from the change of variables cancels in the ratio.\n    p_sb_integral_sum = np.sum(WEIGHTS * poisson_cdf_sb)\n    p_b_integral_sum = np.sum(WEIGHTS * poisson_cdf_b)\n    \n    # Handle the case where the denominator integral is numerically zero.\n    # This might occur if mu_b is very large, making the Poisson CDF vanish.\n    if p_b_integral_sum == 0.0:\n        return 0.0\n\n    return p_sb_integral_sum / p_b_integral_sum\n\ndef find_mu_s_for_cls_target(cls_target, n, mu_t, sigma_t):\n    \"\"\"\n    Finds the value of mu_s for which CLs(mu_s) equals a given target value.\n    This is achieved by finding the root of f(mu_s) = CLs(mu_s) - cls_target.\n    \"\"\"\n    \n    # Define the function whose root we want to find.\n    def root_func(mu_s):\n        return calculate_cls(mu_s, n, mu_t, sigma_t) - cls_target\n\n    # The CLs function is monotonic decreasing from 1 to 0.\n    # The root must be bracketed for the solver.\n    # root_func(0) = 1 - cls_target, which is > 0 for cls_target < 1.\n    lower_bound = 0.0\n    upper_bound = 1.0 # Initial guess for the upper bracket boundary.\n    \n    # Expand the search interval until the root is bracketed.\n    # Failsafe limit to prevent infinite loops.\n    max_search_val = 1000.0\n    while root_func(upper_bound) > 0:\n        upper_bound *= 2.0\n        if upper_bound > max_search_val:\n            raise RuntimeError(f\"Failed to bracket root for CLs target {cls_target}\")\n    \n    # Use Brent's method to find the root with high precision.\n    return brentq(root_func, lower_bound, upper_bound)\n\ndef solve_case(n, mu_t, sigma_t):\n    \"\"\"\n    Computes the CLs 95% upper limit and the Bayesian 95% credible interval length\n    for a single test case.\n    \"\"\"\n    # 1. Compute the CLs 95% upper limit (mu_s^95).\n    # This is the value of mu_s where CLs(mu_s) = 0.05.\n    mu_s_95 = find_mu_s_for_cls_target(0.05, n, mu_t, sigma_t)\n\n    # 2. Compute the Bayesian 95% credible interval length.\n    # Due to the flat prior on mu_s, the posterior CDF C(mu_s) = 1 - CLs(mu_s).\n    # The 95% equal-tailed interval [lo, hi] is found by solving:\n    # C(lo) = 0.025 => CLs(lo) = 0.975\n    # C(hi) = 0.975 => CLs(hi) = 0.025\n    \n    mu_s_lo_bayes = find_mu_s_for_cls_target(0.975, n, mu_t, sigma_t)\n    mu_s_hi_bayes = find_mu_s_for_cls_target(0.025, n, mu_t, sigma_t)\n\n    interval_length = mu_s_hi_bayes - mu_s_lo_bayes\n    \n    return [mu_s_95, interval_length]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0, math.log(2), 0.6),\n        (3, math.log(1), 1.0),\n        (7, math.log(5), 0.3),\n        (10, math.log(2), 0.8),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, mu_t, sigma_t = case\n        result = solve_case(n, mu_t, sigma_t)\n        results.append(result)\n\n    # Format the output exactly as specified: [[x1,y1],[x2,y2],...]\n    formatted_results = [f\"[{r[0]},{r[1]}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}