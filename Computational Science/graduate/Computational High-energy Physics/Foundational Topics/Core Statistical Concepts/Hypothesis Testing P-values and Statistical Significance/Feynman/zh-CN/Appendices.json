{
    "hands_on_practices": [
        {
            "introduction": "在高能物理实验中，量化一项观测的统计显著性是核心任务之一，这要求我们构建一个精确的统计模型。这个实践将挑战您从第一性原理出发，为一个假设的CP破坏搜索推导p值。您将学习一种优雅而强大的技术——通过对辅助统计量（总事件数）进行条件化，来消除诸如探测效率之类的讨厌参数，从而获得一个稳健且精确的统计检验。这项技能是许多真实高能物理分析的基础。",
            "id": "3517328",
            "problem": "在强子对撞机上寻找重味衰变道中的电荷-宇称（CP）破坏时，一项分析对重建到电荷共轭末态的衰变进行计数，得到观测计数 $N^{+}$ 和 $N^{-}$。CP不对称性估计量定义为 $A=\\frac{N^{+}-N^{-}}{N^{+}+N^{-}}$。假设在粒子产生和衰变层面，衰变到两种电荷共轭末态的事件数分别由独立的泊松过程生成，其均值分别为 $\\frac{\\mu(1+A_{0})}{2}$ 和 $\\frac{\\mu(1-A_{0})}{2}$，其中 $\\mu>0$ 是一个未知的总率参数，而 $A_{0}$ 是真实的物理CP不对称性。每个产生的衰变都以一个共同的探测效率 $\\epsilon\\in(0,1]$ 被独立地重建，该效率是未知的，且可能随时间变化，但在与这些计数相关的数据采集期间是恒定的。不存在本底。\n\n你的任务是使用精确的有限样本分布，检验零假设 $H_{0}:A_{0}=0$（备择假设为双边假设）。将未知的探测效率 $\\epsilon$ 视为一个讨厌参数，并使用适用于计算高能物理的、基于似然的论证，通过剖析（profiling）来消除 $\\epsilon$。在 $H_{0}$ 下，构建一个基于 $|A|$（等价于 $|N^{+}-N^{-}|$）的极端性的检验。从关于泊松过程、独立伯努利探测、以及给定总和时一个泊松分量的条件分布的第一性原理出发，推导出一个双边 $p$ 值的精确闭式表达式，记为 $p(A)$。该表达式是在对 $\\epsilon$ 进行剖析后，作为观测到的 $A$ 和总计数 $N=N^{+}+N^{-}$ 的函数。\n\n你的最终答案必须是 $p(A)$ 关于 $A$ 和 $N$ 的单个闭式解析表达式。不要提供任何数值计算或近似，也不要包含物理单位。清楚地定义你所引入的任何符号。双边 $p$ 值必须使用 $H_{0}$ 下的精确分布来构建，并且必须通过包含所有相对于 $|A|$ 而言至少与观测结果一样极端的结果来正确地考虑数据的离散性。",
            "solution": "用户希望在一个计数实验中，为检验无电荷-宇称（CP）不对称性的零假设（$H_0: A_0=0$），推导出一个精确的双边 $p$ 值。\n\n### 第1步：观测计数的统计模型\n\n令 $n^{+}$ 和 $n^{-}$ 为衰变到电荷共轭末态的真实事件数。根据问题陈述，它们是从泊松分布中抽取的独立随机变量：\n$$ n^{+} \\sim \\text{Pois}\\left(\\lambda^{+} = \\frac{\\mu(1+A_{0})}{2}\\right) $$\n$$ n^{-} \\sim \\text{Pois}\\left(\\lambda^{-} = \\frac{\\mu(1-A_{0})}{2}\\right) $$\n这里，$\\mu$ 是总产生率，$A_0$ 是真实的物理不对称性。\n\n这些衰变中的每一个都以一个共同的效率 $\\epsilon \\in (0,1]$ 被探测到。任何单个衰变的观测都是一次独立的伯努利试验。泊松分布的一个已知性质是，如果我们用一个伯努利过程（一个称为“稀疏化”的过程）对其进行抽样，得到的计数分布也是泊松分布。因此，观测到的计数 $N^{+}$ 和 $N^{-}$ 也是独立的泊松随机变量，其均值经过修正：\n$$ N^{+} \\sim \\text{Pois}\\left(\\mu_{+} = \\epsilon \\lambda^{+} = \\frac{\\epsilon\\mu(1+A_{0})}{2}\\right) $$\n$$ N^{-} \\sim \\text{Pois}\\left(\\mu_{-} = \\epsilon \\lambda^{-} = \\frac{\\epsilon\\mu(1-A_{0})}{2}\\right) $$\n我们可观测量 $N^{+}$ 和 $N^{-}$ 的模型依赖于感兴趣的参数 $A_0$ 和两个讨厌参数 $\\mu$ 和 $\\epsilon$。我们可以将讨厌参数合并成一个单一的未知总观测率 $\\mu_{\\text{obs}} = \\epsilon \\mu$。这样，均值变为 $\\mu_{\\pm} = \\frac{\\mu_{\\text{obs}}(1\\pm A_0)}{2}$。\n\n### 第2步：通过条件检验消除讨厌参数\n\n问题要求在消除讨厌参数 $\\epsilon$（进而也消除 $\\mu$）后，使用一个精确的有限样本分布进行检验。在这种情况下，为实现这一目标，一个标准且严谨的方法（也是问题明确建议的）是，构建一个以总观测事件数 $N = N^{+} + N^{-}$ 为条件的检验。\n\n两个独立泊松变量的和也是一个泊松变量。因此，总计数 $N$ 服从均值为 $\\mu_{+}+\\mu_{-}$ 的泊松分布：\n$$ \\mu_{+}+\\mu_{-} = \\frac{\\mu_{\\text{obs}}(1+A_{0})}{2} + \\frac{\\mu_{\\text{obs}}(1-A_{0})}{2} = \\mu_{\\text{obs}} $$\n所以，$N \\sim \\text{Pois}(\\mu_{\\text{obs}})$。\n\n我们现在推导在总计数 $N=k_{tot}$ 的条件下 $N^{+}$ 的分布。对于任何可能的计数 $k \\in \\{0, 1, ..., k_{tot}\\}$，条件概率是：\n$$ P(N^{+} = k | N^{+} + N^{-} = k_{tot}) = \\frac{P(N^{+} = k \\text{ and } N^{-} = k_{tot}-k)}{P(N^{+} + N^{-} = k_{tot})} $$\n由于独立性，这等于：\n$$ P(N^{+} = k | N = k_{tot}) = \\frac{P(N^{+} = k) P(N^{-} = k_{tot}-k)}{P(N = k_{tot})} $$\n代入泊松概率质量函数（PMF）：\n$$ P(N^{+} = k | N = k_{tot}) = \\frac{\\left(\\frac{\\mu_{+}^{k} e^{-\\mu_{+}}}{k!}\\right) \\left(\\frac{\\mu_{-}^{k_{tot}-k} e^{-\\mu_{-}}}{(k_{tot}-k)!}\\right)}{\\frac{(\\mu_{+}+\\mu_{-})^{k_{tot}} e^{-(\\mu_{+}+\\mu_{-})}}{k_{tot}!}} $$\n指数项被消去。重新整理各项可得：\n$$ P(N^{+} = k | N = k_{tot}) = \\frac{k_{tot}!}{k!(k_{tot}-k)!} \\frac{\\mu_{+}^{k} \\mu_{-}^{k_{tot}-k}}{(\\mu_{+}+\\mu_{-})^{k_{tot}}} = \\binom{k_{tot}}{k} \\left(\\frac{\\mu_{+}}{\\mu_{+}+\\mu_{-}}\\right)^{k} \\left(1 - \\frac{\\mu_{+}}{\\mu_{+}+\\mu_{-}}\\right)^{k_{tot}-k} $$\n这是二项分布 $\\text{Binomial}(k_{tot}, p)$ 的概率质量函数。成功概率 $p$ 是：\n$$ p = \\frac{\\mu_{+}}{\\mu_{+}+\\mu_{-}} = \\frac{\\frac{\\mu_{\\text{obs}}(1+A_{0})}{2}}{\\mu_{\\text{obs}}} = \\frac{1+A_{0}}{2} $$\n关键在于，这个概率 $p$ 只依赖于感兴趣的参数 $A_0$，而不依赖于讨厌参数 $\\mu_{\\text{obs}} = \\epsilon \\mu$。因此，通过以总观测事件数 $N$ 为条件，我们成功地构建了一个独立于未知率和效率的检验框架。\n\n### 第3步：构建 p 值\n\n零假设是 $H_{0}: A_{0}=0$。在 $H_0$ 下，二项概率变为 $p_0 = \\frac{1+0}{2} = \\frac{1}{2}$。因此，在零假设下，给定总计数 $N$ 时 $N^{+}$ 的条件分布是：\n$$ (N^{+} | N, H_0) \\sim \\text{Binomial}\\left(N, \\frac{1}{2}\\right) $$\n该检验基于观测到的CP不对称性估计量 $A = \\frac{N^{+}-N^{-}}{N^{+}+N^{-}}$ 的极端性。我们可以用 $N^{+}$ 和固定的总计数 $N$ 来表示 $A$：\n$$ A = \\frac{N^{+} - (N-N^{+})}{N} = \\frac{2N^{+} - N}{N} $$\n因此，$|A|$ 的极端性等价于 $|2N^{+} - N|$ 的极端性，这又等价于检验那些远离 $H_0$ 下期望值 $E[N^{+}|N, H_0] = N \\times p_0 = \\frac{N}{2}$ 的 $N^{+}$ 值。\n\n双边 $p$ 值是在 $H_0$ 下计算出的、观测到一个至少与实际观测结果一样极端的结果的概率。设观测到的计数为 $N^{+}_{\\text{obs}}$。该观测的极端性由其与均值的距离 $|N^{+}_{\\text{obs}} - N/2|$ 来衡量。$p$ 值是所有与均值距离至少一样远的可能结果 $k$（对于随机变量 $N^{+}$）的概率之和：\n$$ p = P_{H_0}\\left(\\left|N^{+} - \\frac{N}{2}\\right| \\ge \\left|N^{+}_{\\text{obs}} - \\frac{N}{2}\\right| \\Big| N\\right) $$\n我们可以用观测到的不对称性 $A$ 和总计数 $N$ 来表示观测到的计数 $N^{+}_{\\text{obs}}$：\n$$ AN = 2N^{+}_{\\text{obs}} - N \\implies N^{+}_{\\text{obs}} = \\frac{N(1+A)}{2} $$\n将此代入极端性条件：\n$$ \\left|N^{+}_{\\text{obs}} - \\frac{N}{2}\\right| = \\left|\\frac{N(1+A)}{2} - \\frac{N}{2}\\right| = \\left|\\frac{NA}{2}\\right| = \\frac{N|A|}{2} $$\n所以，一个结果 $k$ 至少与观测结果一样极端的条件是 $\\left|k - \\frac{N}{2}\\right| \\ge \\frac{N|A|}{2}$。\n\n$p$ 值是所有这些 $k$ 的二项概率之和：\n$$ p(A) = \\sum_{k=0}^{N} P(N^{+}=k | N, H_0) \\cdot I\\left(\\left|k - \\frac{N}{2}\\right| \\ge \\frac{N|A|}{2}\\right) $$\n其中 $I(\\cdot)$ 是指示函数，当其参数为真时为 1，否则为 0。代入二项概率 $P(N^{+}=k | N, H_0) = \\binom{N}{k}(\\frac{1}{2})^{N}$：\n$$ p(A) = \\sum_{k=0}^{N} \\binom{N}{k} \\left(\\frac{1}{2}\\right)^{N} I\\left(\\left|k - \\frac{N}{2}\\right| \\ge \\frac{N|A|}{2}\\right) $$\n该表达式可以写为：\n$$ p(A) = \\left(\\frac{1}{2}\\right)^{N} \\sum_{k=0}^{N} \\binom{N}{k} I\\left(\\left|k - \\frac{N}{2}\\right| \\ge \\frac{N|A|}{2}\\right) $$\n这是双边 $p$ 值的最终、精确、闭式表达式。正如所要求的，它是观测到的不对称性 $A$ 和总计数 $N$ 的函数。有限和被认为是闭式形式，因为它不涉及极限、积分或递归。",
            "answer": "$$ \\boxed{ \\left(\\frac{1}{2}\\right)^{N} \\sum_{k=0}^{N} \\binom{N}{k} I\\left(\\left|k - \\frac{N}{2}\\right| \\ge \\frac{N|A|}{2}\\right) } $$"
        },
        {
            "introduction": "在检验一个假设之后，我们通常需要报告一个感兴趣参数的置信区间。基于Wilks定理的剖面似然比方法是一个功能强大且被广泛使用的工具，但它对渐近近似的依赖可能带来问题。这个动手编程练习将让您执行一个关键的验证步骤：使用蒙特卡洛模拟来检查这些渐近区间的经验覆盖范围。您将发现在低计数场景下出现的“欠覆盖”（undercoverage）现象，从而加深一个重要教训：理论近似必须在分析的具体应用场景下进行验证。",
            "id": "3517351",
            "problem": "您的任务是量化计算高能物理中典型的低计数统计实验中，信号强度参数的渐近剖面似然置信区间的经验覆盖率。考虑一个简单的搜索通道，其具有单箱计数测量，其中观测值 $n$ 服从泊松分布，均值为 $\\mu = s + b$，其中 $s \\ge 0$ 是非负信号产额，$b \\ge 0$ 是已知本底产额。单次观测的似然函数为 $L(n \\mid s) \\propto (s + b)^{n} e^{-(s+b)}$，相应的对数似然函数为 $\\ell(n \\mid s) = n \\log(s+b) - (s+b)$，两者相差一个不依赖于 $s$ 的加性常数。最大似然估计量 (MLE) 满足 $\\hat{s} = \\max(0, n - b)$。剖面似然比为 $\\lambda(s) = L(n \\mid s) / L(n \\mid \\hat{s})$，相应的似然比检验统计量为 $q(s) = -2 \\log \\lambda(s) = 2 [\\ell(n \\mid \\hat{s}) - \\ell(n \\mid s)]$。根据威尔克斯定理，在正则性条件下且在渐近状态下，对于固定的 $s$，$q(s)$ 在分布上收敛于一个自由度为1的卡方分布。\n\n在实践中，当计数值较低且存在非负边界 $s \\ge 0$ 时，通过反演检验 $q(s) \\le c_{\\alpha}$ (其中 $c_{\\alpha}$ 是自由度为1的卡方分布的 $(1 - \\alpha)$ 分位数) 构建的双边渐近置信区间可能会出现覆盖不足的情况。您的任务是使用蒙特卡洛模拟，以真实信号 $s$ 为函数，凭经验测量这些渐近区间在低计数下的覆盖率。\n\n您的程序必须从第一性原理出发实现以下内容：\n- 具有已知本底 $b$ 和非负信号强度 $s$ 的单次计数实验的泊松模型。\n- 剖面似然比检验统计量 $q(s) = 2 [\\ell(n \\mid \\hat{s}) - \\ell(n \\mid s)]$，其中 $\\hat{s} = \\max(0, n - b)$。\n- 将双边集合 $\\{ s \\ge 0 : q(s) \\le c_{\\alpha} \\}$ 定义为 $s$ 的 $(1 - \\alpha)$ 置信区间的渐近反演规则，其中 $c_{\\alpha}$ 是自由度为1的卡方分布的 $(1-\\alpha)$ 临界值。\n- 通过求解 $q(s) = c_{\\alpha}$ 来数值确定给定观测计数 $n$、本底 $b$ 和水平 $\\alpha$ 的区间端点，以获得满足 $s \\ge 0$ 的下端点和上端点。不允许使用任何封闭形式的快捷方式；需对 $q(s) - c_{\\alpha}$ 使用单调区间法和求根法，并正确处理边界 $s = 0$。\n- 蒙特卡洛覆盖率估计：对于给定的真实 $s$ 和 $b$，模拟 $N$ 次独立的观测 $n \\sim \\text{Poisson}(s + b)$，为每个观测到的 $n$ 计算渐近区间，并将真实 $s$ 位于所构建区间内（含端点）的模拟次数比例作为经验覆盖率。为保证可复现性，请使用固定的随机种子 $123456$。\n\n您的推导和实现只能基于以下基本要素：独立计数的泊松似然、剖面似然比的定义及其渐近卡方行为（威尔克斯定理），以及最大似然估计量的基本性质。请勿使用任何预制表格的区间公式或针对特定问题的启发式方法。\n\n测试套件：\n实现并运行以下三个测试用例。对于每个用例，按照指定网格中 $s$ 值的顺序列出其经验覆盖率。\n\n- 情况A（极低本底）：本底 $b = 0.5$，名义置信水平 $1 - \\alpha = 0.95$ (即 $\\alpha = 0.05$)，信号网格 $s \\in \\{0.0, 0.2, 0.5, 1.0, 2.0\\}$，蒙特卡洛重复次数 $N = 4000$。\n- 情况B（中等本底）：本底 $b = 3.0$，名义置信水平 $1 - \\alpha = 0.95$ (即 $\\alpha = 0.05$)，信号网格 $s \\in \\{0.0, 1.0, 2.0, 5.0\\}$，蒙特卡洛重复次数 $N = 4000$。\n- 情况C（无本底，边界主导）：本底 $b = 0.0$，名义置信水平 $1 - \\alpha = 0.90$ (即 $\\alpha = 0.10$)，信号网格 $s \\in \\{0.0, 0.5, 1.0\\}$，蒙特卡洛重复次数 $N = 6000$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果本身应该是一个浮点数经验覆盖率列表，与该用例的 $s$ 网格相对应。例如，输出应类似于 $[[c_{A,1}, c_{A,2}, \\dots],[c_{B,1}, \\dots],[c_{C,1}, \\dots]]$，其中每个 $c_{\\cdot,\\cdot}$ 是一个表示为小数的 $[0,1]$ 范围内的浮点数。不应打印任何其他文本。",
            "solution": "该问题要求对在单箱泊松计数实验中，通过剖面似然比方法得到的渐近置信区间的覆盖属性进行经验验证。任务的核心是执行蒙特卡洛模拟，以量化所构建的置信区间包含信号参数 $s$ 真实值的频率，尤其是在渐近近似可能不太准确的低计数区域。\n\n该解决方案从第一性原理出发，遵循一系列逻辑步骤：定义统计模型、构建检验统计量、推导置信区间程序，以及实现蒙特卡洛模拟以评估其性能。\n\n**1. 统计模型与似然函数**\n\n实验在单个计数箱中观测到 $n$ 个事件。假设该计数值服从泊松分布，其均值 $\\mu$ 是未知非负信号产额 $s \\ge 0$ 与已知非负本底产额 $b \\ge 0$ 之和。\n观测到 $n$ 个事件的概率由泊松概率质量函数给出：\n$$ P(n \\mid s, b) = \\frac{(s+b)^n e^{-(s+b)}}{n!} $$\n对于固定的观测值 $n$，参数 $s$ 的似然函数与此概率成正比：\n$$ L(s \\mid n) \\propto (s+b)^n e^{-(s+b)} $$\n在计算上，使用对数似然函数 $\\ell(s \\mid n) = \\log L(s \\mid n)$ 更为方便。忽略不依赖于 $s$ 的项，我们得到：\n$$ \\ell(s \\mid n) = n \\log(s+b) - (s+b) $$\n$s$ 的最大似然估计量 (MLE)，记为 $\\hat{s}$，是在物理约束 $s \\ge 0$ 下使 $\\ell(s \\mid n)$ 最大化的 $s$ 值。通过将导数 $\\frac{d\\ell}{ds} = \\frac{n}{s+b} - 1$ 设为零，我们发现无约束估计量为 $s = n-b$。结合边界条件 $s \\ge 0$，最大似然估计量为：\n$$ \\hat{s} = \\max(0, n-b) $$\n\n**2. 剖面似然比检验统计量**\n\n为了构建 $s$ 的置信区间，我们使用剖面似然比检验。检验统计量 $q(s)$ 将假设值 $s$ 处的似然与最大可能似然（即在 $\\hat{s}$ 处的似然）进行比较。剖面似然比 $\\lambda(s)$ 定义为：\n$$ \\lambda(s) = \\frac{L(s \\mid n)}{L(\\hat{s} \\mid n)} $$\n检验统计量 $q(s)$ 则由下式给出：\n$$ q(s) = -2 \\log \\lambda(s) = -2 (\\ell(s \\mid n) - \\ell(\\hat{s} \\mid n)) $$\n代入对数似然的表达式，可得：\n$$ q(s) = 2 \\left[ (n \\log(\\hat{s}+b) - (\\hat{s}+b)) - (n \\log(s+b) - (s+b)) \\right] $$\n根据威尔克斯定理，在大样本（渐近）极限下，对于固定的真实值 $s$，$q(s)$ 的分布收敛于一个自由度的卡方（$\\chi^2$）分布，这对应于单个感兴趣的参数。\n\n**3. 通过检验反演构建置信区间**\n\n通过“反演”假设检验来构建 $s$ 的 $(1-\\alpha)$ 置信区间。该区间包含所有使得原假设 $H_0: s=s_0$ 在显著性水平 $\\alpha$ 下不会被拒绝的 $s_0$ 值。检验的拒绝域为 $q(s_0)  c_\\alpha$，其中 $c_\\alpha$ 是 $\\chi^2_1$ 分布的 $(1-\\alpha)$ 分位数（即 $P(\\chi^2_1 \\le c_\\alpha) = 1-\\alpha$）。因此，接受域，也就是置信区间，是满足以下条件的所有 $s$ 值的集合：\n$$ \\{ s \\ge 0 \\mid q(s) \\le c_\\alpha \\} $$\n此区间的端点 $s_{\\text{low}}$ 和 $s_{\\text{up}}$ 通过求解以下方程得到：\n$$ q(s) - c_\\alpha = 0 $$\n由于 $q(s)$ 通常不是一个简单的函数，其根必须通过数值方法找到。算法设计如下：\n- **求根函数**：我们定义一个函数 $f(s) = q(s) - c_\\alpha$，并寻求其根。\n- **下界, $s_{\\text{low}}$**：函数 $q(s)$ 在 $s=\\hat{s}$ 处有最小值 $q(\\hat{s}) = 0$。如果 $\\hat{s}=0$，则最小值在边界上，因此区间必须从 $s_{\\text{low}}=0$ 开始。如果 $\\hat{s}  0$，我们在边界 $s=0$ 处评估 $q(s)$。如果 $q(0) \\le c_\\alpha$，则边界包含在区间内，所以 $s_{\\text{low}}=0$。如果 $q(0)  c_\\alpha$，则在 $(0, \\hat{s})$ 中必定存在一个根 $s_{\\text{low}}$。该根可使用区间法算法（如 Brent 方法）在区间 $[0, \\hat{s}]$ 上进行数值求解。\n- **上界, $s_{\\text{up}}$**：对于 $s  \\hat{s}$，函数 $q(s)$ 单调递增。上界 $s_{\\text{up}}$ 是 $s  \\hat{s}$ 时 $f(s)=0$ 的根。为找到此根，我们首先确定一个区间 $[\\ s_a, s_b ]$ 使得 $f(s_a)  0$ 且 $f(s_b)  0$。我们可以设置 $s_a = \\hat{s}$ (因为 $f(\\hat{s}) = -c_\\alpha  0$)。然后，我们通过一个合理的猜测（例如，$s_{\\text{guess}} = \\hat{s} + \\sqrt{\\hat{s}+b+1}$）开始，并扩展搜索范围（例如，通过将步长加倍）直到 $f(s_b)  0$，来寻找合适的 $s_b$。一旦找到区间，就使用相同的数值求根器。\n\n**4. 用于计算经验覆盖率的蒙特卡洛模拟**\n\n模拟的目的是检查名义置信水平 $(1-\\alpha)$ 是否与该过程产生包含 $s$ 真实值的区间的实际比例相匹配。这个比例就是经验覆盖率。对于每个由真实信号 $s_{\\text{true}}$、本底 $b$ 和置信水平 $(1-\\alpha)$ 定义的测试用例，其过程如下：\n1. 固定参数 $s_{\\text{true}}$、$b$ 和 $\\alpha$。预先计算临界值 $c_\\alpha$。\n2. 使用固定的种子初始化随机数生成器以保证可复现性。\n3. 重复 $N$ 次（对于 $N$ 个蒙特卡洛“玩具”实验）：\n    a. 通过从均值为 $\\mu_{\\text{true}} = s_{\\text{true}} + b$ 的泊松分布中抽样，生成单个伪观测值 $n$。\n    b. 对于这个生成的 $n$，使用前一节描述的数值程序计算置信区间 $[s_{\\text{low}}, s_{\\text{up}}]$。\n    c. 检查真实信号值是否位于此计算出的区间内：$s_{\\text{low}} \\le s_{\\text{true}} \\le s_{\\text{up}}$。\n4. 经验覆盖率是成功的“覆盖”总数（来自步骤3c）除以总重复次数 $N$。\n5. 对于每个测试用例中指定的 $s_{\\text{true}}$ 网格中的每个值，重复此过程。\n\n最终的 Python 实现将这些步骤封装到不同的函数中：一个用于对数似然，一个用于构建检验统计量 $q(s)$，一个用于为给定观测值计算置信区间，以及一个主模拟函数用于计算多次重复的经验覆盖率。这种模块化设计直接反映了基于原理的推导过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\nfrom scipy.optimize import brentq\n\n# Define global seed for reproducibility as required by the problem\nSEED = 123456\n\ndef log_likelihood(s, n, b):\n    \"\"\"Computes the log-likelihood l(s|n) = n*log(s+b) - (s+b).\"\"\"\n    mu = s + b\n    # Use a small epsilon to avoid log(0) issues when s+b is effectively zero\n    if mu = 1e-15:\n        if n == 0:\n            return 0.0\n        else:\n            return -np.inf  # Effectively infinite -log(L)\n    return n * np.log(mu) - mu\n\ndef get_q_s_and_s_hat(n, b):\n    \"\"\"Returns a function for the test statistic q(s) and the MLE s_hat.\"\"\"\n    s_hat = max(0.0, n - b)\n    ll_s_hat = log_likelihood(s_hat, n, b)\n\n    def q_s(s):\n        \"\"\"Computes q(s) = 2 * (l(s_hat) - l(s)).\"\"\"\n        if s  0:\n            # For root finder robustness, signal strength s must be non-negative\n            return np.inf\n        \n        ll_s = log_likelihood(s, n, b)\n        if not np.isfinite(ll_s):\n            return np.inf # If log_likelihood is -inf, q becomes +inf\n            \n        test_statistic = 2 * (ll_s_hat - ll_s)\n        # By definition q(s) >= 0. Floating point precision might result in a small negative value.\n        return max(0.0, test_statistic)\n        \n    return q_s, s_hat\n\ndef compute_interval(n, b, c_alpha):\n    \"\"\"\n    Computes the (1-alpha) confidence interval [s_low, s_up] for a given\n    observation n, background b, and critical value c_alpha.\n    \"\"\"\n    q_s, s_hat = get_q_s_and_s_hat(n, b)\n\n    def root_func(s):\n        return q_s(s) - c_alpha\n\n    # --- Lower bound s_low ---\n    s_low = 0.0\n    # A root for the lower bound only exists if s_hat > 0 and q(0) > c_alpha.\n    if s_hat > 1e-9:\n        if root_func(0.0) > 1e-9: # Add tolerance for FP comparison\n            try:\n                # The root is between 0 and s_hat. brentq requires opposite signs.\n                # root_func(0) > 0 and root_func(s_hat) = -c_alpha  0\n                s_low = brentq(root_func, 0.0, s_hat)\n            except ValueError:\n                # Fallback for rare numerical precision issues at the boundaries.\n                if abs(root_func(0.0))  1e-9: s_low = 0.0\n                elif abs(root_func(s_hat))  1e-9: s_low = s_hat\n                else: s_low = 0.0\n\n    # --- Upper bound s_up ---\n    # The upper root is always > s_hat. Start search for a bracket [s_a, s_b].\n    s_a = s_hat\n    \n    # Find an upper search bracket s_b where root_func(s_b) > 0.\n    # The step size should scale with the expected width. sqrt(s_hat+b) ~ sqrt(n) is a good choice.\n    step = np.sqrt(s_hat + b + 1.0)\n    s_b = s_hat + step\n    \n    # Exponentially increase search range until bracket is found.\n    max_bracket_iters = 30\n    for _ in range(max_bracket_iters):\n        if root_func(s_b) > 0:\n            break\n        step *= 2.0\n        s_b = s_hat + step\n    else: # This else executes if the for-loop completes without a break.\n        return s_low, np.inf\n\n    try:\n        s_up = brentq(root_func, s_a, s_b)\n    except ValueError:\n        # Fallback for rare numerical precision issues at the boundaries.\n        if abs(root_func(s_a))  1e-9: s_up = s_a\n        elif abs(root_func(s_b))  1e-9: s_up = s_b\n        else: s_up = s_b\n    \n    return s_low, s_up\n\n\ndef run_mc_for_coverage(s_true_grid, b, alpha, N, rng):\n    \"\"\"\n    Runs the Monte Carlo simulation to estimate empirical coverage.\n    \"\"\"\n    c_alpha = chi2.ppf(1.0 - alpha, df=1)\n    coverages = []\n\n    for s_true in s_true_grid:\n        mu_true = s_true + b\n        \n        # Generate all toy observations at once for efficiency\n        observations = rng.poisson(lam=mu_true, size=N)\n        \n        coverage_count = 0\n        for n_obs in observations:\n            s_low, s_up = compute_interval(n_obs, b, c_alpha)\n            # Check if the true signal value is within the computed interval\n            if s_low = s_true = s_up:\n                coverage_count += 1\n        \n        coverages.append(coverage_count / N)\n    \n    return coverages\n\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs the solver, and prints the final result in the specified format.\n    \"\"\"\n    test_cases = [\n        # Case A: very low background\n        {'b': 0.5, 'alpha': 0.05, 's_grid': [0.0, 0.2, 0.5, 1.0, 2.0], 'N': 4000},\n        # Case B: moderate background\n        {'b': 3.0, 'alpha': 0.05, 's_grid': [0.0, 1.0, 2.0, 5.0], 'N': 4000},\n        # Case C: no background, boundary-dominated\n        {'b': 0.0, 'alpha': 0.10, 's_grid': [0.0, 0.5, 1.0], 'N': 6000},\n    ]\n\n    # Initialize the random number generator with the specified seed for reproducibility\n    rng = np.random.default_rng(SEED)\n    \n    all_results = []\n    for case in test_cases:\n        results = run_mc_for_coverage(\n            s_true_grid=case['s_grid'],\n            b=case['b'],\n            alpha=case['alpha'],\n            N=case['N'],\n            rng=rng\n        )\n        all_results.append(results)\n\n    # Required output format: [[c_A_1,...],[c_B_1,...],[c_C_1,...]]\n    # Using str() on a list of lists produces this format but with spaces, which are then removed.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "前一个实践揭示了标准渐近方法可能会失效，尤其是在参数的物理边界附近（例如，信号产额 $s \\ge 0$）。在寻找新物理现象的分析中，这是一个常见而严肃的问题。本练习介绍了著名的 Feldman-Cousins 统一方法，这是一种专门为解决此类问题而设计的频率主义构造。通过实现该方法独特的排序规则，您不仅将构建出保证至少达到标称覆盖率的置信区间，还将理解其特征行为（例如在边界处的“过覆盖”）的根源。",
            "id": "3517293",
            "problem": "考虑一个在计算高能物理中常见的计数实验，其中观测到的事件计数 $n \\in \\{0,1,2,\\dots\\}$ 来自一个均值为 $\\mu = s + b$ 的泊松过程。信号强度 $s$ 是一个未知的非负参数，受物理边界 $s \\ge 0$ 的约束，而本底 $b \\ge 0$ 是已知的。目标是研究统一的费尔德曼-考辛斯(Feldman–Cousins, FC)置信区间在边界 $s \\ge 0$ 附近的覆盖率，并将观察到的边界行为与FC构造固有的排序属性联系起来。\n\n定义和要求：\n- 数据模型为 $N \\sim \\mathrm{Poisson}(s + b)$。\n- 对于每个假设的 $s \\ge 0$，定义似然 $L(n \\mid s) \\propto (s+b)^n e^{-(s+b)}$，其中 $n \\in \\{0,1,2,\\dots\\}$。\n- 令 $\\hat{s}(n)$ 表示在约束 $s \\ge 0$ 下，给定 $n$ 时 $s$ 的受约束最大似然估计（maximum likelihood estimate (MLE)）。对于已知的 $b$ 的泊松模型，该估计为 $\\hat{s}(n) = \\max\\{0, n - b\\}$。\n- 费尔德曼-考辛斯(FC)统一排序使用似然比\n$$\nR(n; s) \\equiv \\frac{L(n \\mid s)}{L\\bigl(n \\mid \\hat{s}(n)\\bigr)},\n$$\n并为每个固定的 $s$ 构建一个接受域 $\\mathcal{A}_s \\subset \\{0,1,2,\\dots\\}$。构建方法是：按 $R(n; s)$ 从大到小对结果 $n$ 进行排序，并不断纳入结果，直到在 $N \\sim \\mathrm{Poisson}(s + b)$ 下的累积概率达到或超过目标置信水平(CL)。如果在纳入阈值处有多个结果共享相同的似然比值（排序并列），则将整个排序并列的组全部纳入，以避免任意的并列处理。这样可以得到一个非随机化的接受域，其在 $s$ 下的概率至少为目标置信水平。\n- 对于一个观测值 $n_{\\mathrm{obs}}$，FC构造报告的置信集是所有其接受域 $\\mathcal{A}_s$ 包含 $n_{\\mathrm{obs}}$ 的 $s$ 的集合。\n- 在一个固定的真实信号 $s_0$ 下的覆盖率，是指从一个 $N \\sim \\mathrm{Poisson}(s_0 + b)$ 的抽样中构造出的FC区间包含 $s_0$ 的长期概率。通过对位于 $s_0$ 接受域中的计数结果的概率进行求和来精确计算此覆盖率。不要使用蒙特卡罗模拟。通过选择一个足够大的求和上限 $n_{\\max}$ 来截断无穷泊松和，使得被忽略的泊松尾部概率最多为 $10^{-15}$；在代码中对这种截断进行数值上的论证，并确保接受域的构建考虑了截断边界处的排序并列，从而使最终覆盖率的绝对误差在 $10^{-12}$ 以内。\n\n任务：\n1. 实现一个程序，对于每个测试用例 $(s_0, b, \\mathrm{CL})$，根据上述排序规则构建FC接受域 $\\mathcal{A}_{s_0}$，并计算覆盖率\n$$\n\\mathrm{Cov}(s_0; b, \\mathrm{CL}) = \\sum_{n \\in \\mathcal{A}_{s_0}} \\Pr\\{N=n \\mid s_0 + b\\},\n$$\n使用精确的泊松概率，并在必要时通过对数对下溢进行数值安全的处理。使用确定性的排序并列处理规则，该规则纳入在阈值处共享相同似然比的所有结果，以确保非随机化覆盖率至少为目标置信水平。\n2. 通过以下方式确保科学真实性和数值鲁棒性：\n   - 使用对 $R(n; s_0)$ 的完整排序来构建接受域，在对数比值 $10^{-12}$ 的数值容差内将比值完全相等的项分组。\n   - 在 $n_{\\max}$ 处截断泊松分布的支撑集，使得在 $N \\sim \\mathrm{Poisson}(s_0 + b)$ 下被忽略的尾部概率最多为 $10^{-15}$，并为 $n_{\\max}$ 增加一个小的整数安全余量，以保证没有排序并列的组在边界处被人为分割。\n   - 验证所构建的接受集的累积概率至少为目标 $\\mathrm{CL}$（容差为 $10^{-12}$）；如果不满足，则自适应地增加 $n_{\\max}$ 直至满足此条件。\n3. 在你的解答报告中，解释排序规则如何与边界条件 $s \\ge 0$ 相互作用，以及为何这会导致在 $s \\approx 0$ 附近的特征性覆盖行为。\n\n测试套件：\n为以下参数集 $(s_0, b, \\mathrm{CL})$ 计算覆盖率，其中所有数字均为实数，并以小数形式给出：\n- $(0.0, 3.0, 0.90)$\n- $(0.1, 3.0, 0.90)$\n- $(0.5, 3.0, 0.90)$\n- $(1.0, 3.0, 0.90)$\n- $(0.0, 0.5, 0.90)$\n- $(0.0, 3.0, 0.95)$\n- $(3.0, 3.0, 0.90)$\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含测试套件的覆盖率值，顺序与测试套件相同，四舍五入到小数点后六位，格式为逗号分隔的列表并用方括号括起来，例如 $\\texttt{[0.912345,0.901234,\\dots]}$。\n- 无需报告物理单位。不涉及角度。所有报告的覆盖率值必须是小数。",
            "solution": "该问题要求计算一个带已知本底的泊松过程中费尔德曼-考辛斯(FC)置信区间的覆盖率，特别关注信号参数 $s=0$ 物理边界附近的行为。该解决方案涉及对接受域的FC构造的精确实现，以及对基本统计原理的解释。\n\n### 基于原理的设计\n\n问题的核心在于为给定的信号假设 $s_0$ 构造接受域 $\\mathcal{A}_s$。此构造受费尔德曼-考辛斯排序原理的支配，该原理基于似然比对可能的观测结果 $n$ 进行排序。\n\n1.  **模型和似然**：观测到的事件数 $n$ 服从泊松分布，其均值为 $\\mu = s + b$，其中 $s$ 是信号强度， $b$ 是已知本底。概率质量函数(PMF)为 $P(n \\mid s, b) = \\frac{e^{-(s+b)}(s+b)^n}{n!}$。对于固定的观测值 $n$，作为 $s$ 的函数的似然函数为 $L(n \\mid s) \\propto (s+b)^n e^{-(s+b)}$。\n\n2.  **排序原理**：FC方法使用似然比对固定的假设信号 $s$ 的结果 $n$ 进行排序：\n    $$\n    R(n; s) = \\frac{L(n \\mid s)}{L(n \\mid \\hat{s}(n))}\n    $$\n    其中 $\\hat{s}(n)$ 是观测值 $n$ 的 $s$ 的最大似然估计(MLE)，受物理约束 $s \\ge 0$ 的限制。对于泊松均值 $\\mu = s+b$，$\\mu$ 的无约束MLE是 $n$，这导致 $s$ 的无约束估计为 $n-b$。结合约束 $s \\ge 0$ 得到受约束MLE：\n    $$\n    \\hat{s}(n) = \\max\\{0, n - b\\}\n    $$\n    比率的分母 $L(n \\mid \\hat{s}(n))$ 表示在最佳拟合的物理允许假设下数据 $n$ 的似然。较大的比率 $R(n; s)$ 表明，与最佳可能解释相比，假设的 $s$ 能够相对较好地解释数据 $n$。\n\n3.  **比率的数值计算**：为保持数值稳定性，我们使用比率的对数。似然中与 $1/n!$ 成比例的项被消去，剩下：\n    $$\n    \\log R(n; s) = \\log\\left( \\frac{(s+b)^n e^{-(s+b)}}{(\\hat{s}(n)+b)^n e^{-(\\hat{s}(n)+b)}} \\right) = n \\log\\left(\\frac{s+b}{\\hat{s}(n)+b}\\right) - (s - \\hat{s}(n))\n    $$\n    令 $\\mu_0 = s_0 + b$ 为假设的均值，$\\hat{\\mu}(n) = \\hat{s}(n) + b = \\max\\{b, n\\}$ 为观测值 $n$ 的最佳拟合均值。对于测试假设 $s_0$，对数比为：\n    $$\n    \\log R(n; s_0) = n \\log\\left(\\frac{\\mu_0}{\\hat{\\mu}(n)}\\right) - (\\mu_0 - \\hat{\\mu}(n))\n    $$\n    只要 $\\mu_0  0$ 且 $b \\ge 0$（这意味着对于给定的测试用例 $\\hat{\\mu}(n)  0$），该形式就是鲁棒的。\n\n4.  **构造接受域 $\\mathcal{A}_{s_0}$**：\n    a.  **定义 $n$ 的搜索空间**：泊松分布是为所有 $n \\in \\{0, 1, 2, \\dots\\}$ 定义的。我们必须截断这个无限集合。我们找到一个整数 $n_{\\max}$，使得尾部概率 $\\sum_{n=n_{\\max}+1}^{\\infty} P(n \\mid s_0, b) \\le 10^{-15}$。这可以通过使用泊松分布的逆生存函数找到。为 $n_{\\max}$ 增加一个小的安全余量，以确保在截断处的任何具有并列排序值的组不会被人为地分割。\n    b.  **对结果排序**：对于从 $0$ 到 $n_{\\max}$ 的每个整数 $n$，我们计算对数比 $\\log R(n; s_0)$。\n    c.  **按排序值分组和排序**：我们识别 $\\log R(n; s_0)$ 的唯一值（在 $10^{-12}$ 的数值容差内），并按降序对这些唯一的排序值进行排序。\n    d.  **累积概率**：我们遍历排序后的排序值。对于每个排序值，我们收集所有共享此排序值的 $n$ 值。我们将它们对应的泊松概率 $P(n \\mid s_0, b)$ 的和加到一个运行的累积概率中。我们将所有这些 $n$ 值添加到接受域 $\\mathcal{A}_{s_0}$。一旦累积概率达到或超过目标置信水平(CL)，该过程就停止。排序并列处理规则要求纳入阈值排序上的整组成果，这确保了覆盖率至少为CL。\n\n5.  **计算覆盖率**：对于一个真实信号 $s_0$，覆盖率是指一次实验产生的结果 $n$ 落入接受域 $\\mathcal{A}_{s_0}$ 内的概率。根据构造，这恰好是上一步中计算的最终累积概率。\n    $$\n    \\mathrm{Cov}(s_0; b, \\mathrm{CL}) = \\sum_{n \\in \\mathcal{A}_{s_0}} P(N=n \\mid s_0 + b)\n    $$\n\n### 与边界条件 $s \\ge 0$ 的相互作用\n\nFC方法在物理边界 $s=0$ 附近的独特性行为是排序规则与受约束MLE $\\hat{s}(n)$ 相互作用的直接结果。\n\n-   **在边界处 ($s_0=0$)**：假设是没有信号。假设的均值为 $\\mu_0 = b$。\n    -   对于观测计数 $n \\le b$，最佳拟合信号为 $\\hat{s}(n) = \\max\\{0, n-b\\} = 0$。最佳拟合假设与零假设($s=0$)相同。\n    -   因此，对于所有 $n \\le \\lfloor b \\rfloor$，似然比为 $R(n; s_0=0) = 1$。\n    -   这会产生大量的排序并列：所有结果 $n \\in \\{0, 1, \\dots, \\lfloor b \\rfloor\\}$ 都具有最高的可能排序值。\n    -   根据排序并列处理规则，$\\mathcal{A}_{s_0=0}$ 的构造必须从包含这整个结果块开始。初始的累积概率是 $\\sum_{n=0}^{\\lfloor b \\rfloor} P(n \\mid b)$。如果这个和小于置信水平CL，则根据排序值添加更多的结果（$n  b$ 的结果，其 $R  1$），直到超过CL。\n    -   因为在第一步就加入了大量的概率质量块，最终的累积概率——即覆盖率——通常明显大于名义CL。这种效应被称为过覆盖。\n\n-   **远离边界 ($s_0  0$)**：即使对于一个非常小的正信号 $s_0  0$，这种完全的排序并列也会被打破。\n    -   假设的均值为 $\\mu_0 = s_0 + b$。\n    -   对于 $n \\le b$，我们仍然有 $\\hat{s}(n) = 0$。对数比变为 $\\log R(n; s_0) = n\\log\\left(\\frac{s_0+b}{b}\\right) - s_0$。由于 $\\log((s_0+b)/b)0$，这是 $n$ 的一个严格递增的线性函数。\n    -   结果 $n=0, 1, \\dots, \\lfloor b \\rfloor$ 现在被唯一地排序：$n=0$ 最高，然后是 $n=1$，依此类推。\n    -   接受域可以通过逐个添加结果来构建。这种更细的粒度使得累积概率可以在更接近名义CL值时停止。\n    -   结果是，对于 $s_0  0$ 的覆盖率会从 $s_0=0$ 处的过覆盖急剧下降到一个非常接近（但保证至少是）CL的值。\n\n这种行为展示了费尔德曼-考辛斯方法的关键特性：它自动地从边界处的单侧区间（在此处它防止了错误地排除 $s=0$）过渡到远离边界的双侧区间，在整个参数空间内提供正确的覆盖率，而不会出现“翻转”问题。在 $s=0$ 处的过覆盖是为了在边界处严格执行频率学派覆盖原理，同时避免对较小的 $n$ 产生空置信集而付出的代价。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\nfrom collections import defaultdict\n\ndef solve():\n    \"\"\"\n    Computes the coverage of Feldman-Cousins confidence intervals for a Poisson\n    process with known background, for a suite of test cases.\n    \"\"\"\n    \n    # Test cases: (s0, b, CL)\n    test_cases = [\n        (0.0, 3.0, 0.90),\n        (0.1, 3.0, 0.90),\n        (0.5, 3.0, 0.90),\n        (1.0, 3.0, 0.90),\n        (0.0, 0.5, 0.90),\n        (0.0, 3.0, 0.95),\n        (3.0, 3.0, 0.90),\n    ]\n\n    results = []\n    for s0, b, cl in test_cases:\n        coverage = compute_fc_coverage(s0, b, cl)\n        results.append(f\"{coverage:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef compute_fc_coverage(s0, b, cl):\n    \"\"\"\n    Calculates the exact coverage for a given signal hypothesis s0, background b,\n    and confidence level CL.\n\n    Args:\n        s0 (float): The true (hypothesized) signal strength.\n        b (float): The known background.\n        cl (float): The target confidence level.\n\n    Returns:\n        float: The exact coverage probability.\n    \"\"\"\n    mu0 = s0 + b\n    \n    # Determine the upper limit for n summation.\n    # We choose n_max such that the omitted Poisson tail probability is at most 1e-15.\n    # P(N > n_max) = 1 - P(N = n_max), so we want P(N = n_max) >= 1 - 1e-15.\n    # The Percent Point Function (ppf) is the inverse of the CDF.\n    if mu0 > 0:\n        n_max_crit = stats.poisson.ppf(1 - 1e-15, mu0)\n    else: # Handle mu0=0 case (only n=0 has non-zero probability)\n        n_max_crit = 5\n        \n    # Add a safety margin to ensure no tied group is split at the boundary.\n    # This also helps satisfy the a-posteriori check on coverage >= CL.\n    n_max = int(n_max_crit) + 20\n    \n    n_values = np.arange(0, n_max + 1)\n\n    # Calculate the constrained MLE for s and the corresponding mean mu_hat.\n    s_hat = np.maximum(0, n_values - b)\n    mu_hat = s_hat + b  # This is equivalent to np.maximum(b, n_values)\n\n    # Calculate the log of the likelihood ratio R(n; s0) for ordering.\n    # log R = n*log(mu0/mu_hat) - (mu0-mu_hat)\n    # Handle mu_hat=0: occurs only if b=0 and n=0.\n    # Handle mu0=0: occurs if s0=0 and b=0.\n    with np.errstate(divide='ignore', invalid='ignore'):\n        log_mu0 = np.log(mu0) if mu0 > 0 else -np.inf\n        log_mu_hat = np.log(mu_hat)\n        log_R = n_values * (log_mu0 - log_mu_hat) - (mu0 - mu_hat)\n    \n    # Clean up NaNs and Infs that may result from log(0)\n    log_R[np.isneginf(log_R)] = -np.inf # Preserve -inf\n    log_R[np.isnan(log_R)] = 0.0 # This case (0*log(0/0)) corresponds to n=b=s0=0, where mu0=mu_hat, so logR=0.\n\n    # Get the Poisson probabilities for each n under the hypothesis s0.\n    poisson_probs = stats.poisson.pmf(n_values, mu0)\n\n    # Group outcomes n by their rank (log_R value) to handle ties correctly.\n    # A tolerance of 1e-12 is used as per the problem description.\n    # We group by rounding the log_R value to a certain precision.\n    tie_tolerance = 1e-12\n    # Using integer casting after scaling is a robust way to group floats.\n    scaled_log_R = np.round(log_R / tie_tolerance).astype(np.int64)\n    \n    # Use a dictionary to group probabilities by their rank (scaled_log_R value).\n    # defaultdict is convenient for this.\n    ranked_prob_groups = defaultdict(float)\n    for i in range(len(n_values)):\n        rank_val = scaled_log_R[i]\n        ranked_prob_groups[rank_val] += poisson_probs[i]\n        \n    # Sort the ranks in descending order.\n    sorted_ranks = sorted(ranked_prob_groups.keys(), reverse=True)\n\n    # Build the acceptance region by adding groups of tied ranks\n    # until the cumulative probability exceeds the confidence level.\n    cumulative_prob = 0.0\n    for rank in sorted_ranks:\n        prob_of_group = ranked_prob_groups[rank]\n        if cumulative_prob  cl and not np.isclose(cumulative_prob, cl):\n            cumulative_prob += prob_of_group\n        else:\n            break\n            \n    # The final cumulative probability is the coverage.\n    # A check ensures that the implementation correctly yields coverage >= CL.\n    # Small floating point errors can make it slightly less, so a small\n    # tolerance is used in the assertion.\n    assert cumulative_prob >= cl - 1e-12, f\"Coverage {cumulative_prob} is less than CL {cl}\"\n    \n    return cumulative_prob\n\nsolve()\n```"
        }
    ]
}