{
    "hands_on_practices": [
        {
            "introduction": "在设计新的物理学实验时，一个核心问题是预估其发现新信号的潜力。Asimov 数据集是一个强大的理论工具，它使我们能够计算中位数预期发现显著性，而无需进行大量的模拟实验。这项练习 () 将通过一个简单的计数实验，让你亲手推导这个关键公式，从而加深对实验灵敏度评估的理解。",
            "id": "3526337",
            "problem": "为寻找新的高能物理信号，进行了一项单箱计数实验。观测到的事件数被建模为泊松随机变量，其均值为 $\\nu(\\mu)=\\mu s + b$，其中 $\\mu \\geq 0$ 是用于缩放名义预期信号产额 $s$ 的信号强度参数，而 $b$ 是已知的预期本底产额。对于观测到的计数 $n$，其似然函数是泊松概率质量函数 $L(n \\mid \\mu)=\\text{Pois}\\!\\left(n \\mid \\mu s + b\\right)$。为了检验发现假设，原假设为 $H_{0}:\\mu=0$，备择假设为 $H_{1}:\\mu>0$。用于发现的单边剖面似然比检验统计量定义为 $q_{0}=-2\\ln\\lambda(0)$，其中 $\\lambda(0)=\\dfrac{L(n \\mid \\mu=0)}{L(n \\mid \\hat{\\mu})}$，$\\hat{\\mu}$ 是在物理约束 $\\mu\\geq 0$ 条件下 $\\mu$ 的最大似然估计。\n\n在此背景下定义 Asimov 数据集。然后，在信号加本底假设的 Asimov 假定下（即，数据被视为其在 $\\mu=1$ 时的期望值），推导中位数预期发现检验统计量 $q_{0}$ 以及相应的中位数预期显著性 $Z=\\sqrt{q_{0}}$ 作为 $s$ 和 $b$ 的函数的封闭形式解析表达式。您的最终答案必须是一个单一的封闭形式表达式或一对一起呈现的封闭形式表达式，并且不得包含任何数值代入。无需四舍五入。将最终显著性表示为无单位的纯数。",
            "solution": "该问题要求在信号加本底假设（$\\mu=1$）的 Asimov 假定下，求出中位数预期发现检验统计量 $q_{0}$ 和相应的中位数预期显著性 $Z$。推导过程分四步进行：(1) 定义 Asimov 数据集，(2) 为该数据集找到最大似然估计（$\\hat{\\mu}$），(3) 计算检验统计量 $q_{0}$，以及 (4) 推导显著性 $Z$。\n\n首先，我们定义 Asimov 数据集。Asimov 数据集是一个代表性数据集，其中观测数据被设置为在特定假设下的期望值。对于本问题，该假设是信号强度 $\\mu=1$ 的信号加本底假设。预期事件数 $\\nu(\\mu)$ 由 $\\nu(\\mu) = \\mu s + b$ 给出。在假设 $\\mu=1$ 下，预期事件数为 $\\nu(1) = (1)s + b = s+b$。因此，Asimov 数据集包含一个单一的观测计数 $n_{A} = s+b$。请注意，虽然观测计数必须是整数，但 Asimov 数据集是一个理论构造，其中 $n_A$ 可以是非整数的实数，因为泊松概率质量函数可以使用伽马函数推广到非整数参数。\n\n其次，我们针对给定的 Asimov 观测值 $n = n_{A} = s+b$，确定信号强度参数 $\\mu$ 的最大似然估计（MLE）$\\hat{\\mu}$。似然函数是泊松概率 $L(n \\mid \\mu) = \\frac{(\\mu s + b)^{n} \\exp(-(\\mu s + b))}{n!}$。使用对数似然函数 $\\ln L$ 更为方便：\n$$ \\ln L(n \\mid \\mu) = n \\ln(\\mu s + b) - (\\mu s + b) - \\ln(n!) $$\n为了找到无约束的最大似然估计 $\\tilde{\\mu}$，我们将 $\\ln L$ 对 $\\mu$ 求导并令其为零：\n$$ \\frac{\\partial}{\\partial \\mu} \\ln L(n \\mid \\mu) = \\frac{ns}{\\mu s + b} - s = 0 $$\n假设 $s>0$，我们可以解出 $\\mu$：\n$$ \\frac{ns}{\\tilde{\\mu} s + b} = s \\implies n = \\tilde{\\mu} s + b \\implies \\tilde{\\mu} = \\frac{n-b}{s} $$\n将 Asimov 数据 $n = n_{A} = s+b$ 代入此表达式，得到 Asimov 数据集的无约束最大似然估计：\n$$ \\tilde{\\mu}_{A} = \\frac{(s+b) - b}{s} = \\frac{s}{s} = 1 $$\n问题陈述了物理约束 $\\mu \\geq 0$。因此，有约束的最大似然估计 $\\hat{\\mu}$ 由 $\\hat{\\mu} = \\max(0, \\tilde{\\mu})$ 给出。由于我们发现 $\\tilde{\\mu}_{A}=1$，它大于 $0$，所以 Asimov 数据集的有约束最大似然估计是 $\\hat{\\mu}_{A} = 1$。\n\n第三，我们计算检验统计量 $q_{0}$。该检验统计量定义为 $q_{0} = -2\\ln\\lambda(0)$，其中剖面似然比 $\\lambda(0)$ 由下式给出：\n$$ \\lambda(0) = \\frac{L(n \\mid \\mu=0)}{L(n \\mid \\hat{\\mu})} $$\n我们针对 Asimov 数据集 $n=n_A=s+b$ 及其对应的最大似然估计 $\\hat{\\mu}=\\hat{\\mu}_A=1$ 计算该值。\n分子中的似然函数在原假设（$H_{0}: \\mu=0$）下计算：\n$$ L(n_{A} \\mid \\mu=0) = \\text{Pois}(s+b \\mid b) = \\frac{b^{s+b} \\exp(-b)}{(s+b)!} $$\n分母中的似然函数在最大似然估计 $\\hat{\\mu}=1$ 处计算：\n$$ L(n_{A} \\mid \\hat{\\mu}=1) = \\text{Pois}(s+b \\mid s+b) = \\frac{(s+b)^{s+b} \\exp(-(s+b))}{(s+b)!} $$\n那么，比率 $\\lambda(0)$ 为：\n$$ \\lambda(0) = \\frac{b^{s+b} \\exp(-b)}{(s+b)^{s+b} \\exp(-(s+b))} = \\left(\\frac{b}{s+b}\\right)^{s+b} \\exp(s) $$\n现在，我们通过对该表达式取 $-2\\ln$ 来计算 $q_{0}$：\n$$ q_{0} = -2\\ln\\left[ \\left(\\frac{b}{s+b}\\right)^{s+b} \\exp(s) \\right] = -2 \\left[ (s+b)\\ln\\left(\\frac{b}{s+b}\\right) + s \\right] $$\n使用性质 $\\ln(x/y) = -\\ln(y/x)$，我们可以将其重写为：\n$$ q_{0} = -2 \\left[ -(s+b)\\ln\\left(\\frac{s+b}{b}\\right) + s \\right] = 2(s+b)\\ln\\left(\\frac{s+b}{b}\\right) - 2s $$\n提出因子 $2$ 并重写对数的参数，得到中位数预期检验统计量的最终表达式，通常表示为 $q_{0,A}$：\n$$ q_{0} = 2 \\left[ (s+b)\\ln\\left(1+\\frac{s}{b}\\right) - s \\right] $$\n此表达式在 $s>0$ 和 $b>0$ 时有效。\n\n最后，中位数预期显著性 $Z$ 定义为 $Z = \\sqrt{q_{0}}$。对 $q_{0}$ 的表达式取平方根，得到：\n$$ Z = \\sqrt{2 \\left[ (s+b)\\ln\\left(1+\\frac{s}{b}\\right) - s \\right]} $$\n这就是著名的用于简单计数实验中位数显著性的“Asimov 公式”。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} q_0 = 2 \\left[ (s+b)\\ln\\left(1+\\frac{s}{b}\\right) - s \\right] \\\\ Z = \\sqrt{2 \\left[ (s+b)\\ln\\left(1+\\frac{s}{b}\\right) - s \\right]} \\end{pmatrix} } $$"
        },
        {
            "introduction": "从预期灵敏度转向实际数据分析，参数估计的下一个关键步骤是量化测量的不确定性。在高能物理中，测量触发器或探测器效率是一项基本任务，通常用二项分布来建模。这项练习 () 将引导你通过一项计算研究，比较不同置信区间构建方法的性能，揭示它们在小样本情况下的重要特性，如覆盖范围和保守性。",
            "id": "3526356",
            "problem": "您正在设计一项与高能碰撞实验中探测器和触发器效率测量相关的计算研究，其中效率通过重复的独立伯努利试验来估计。考虑一个二项数据生成过程，其成功概率 $p \\in (0,1)$ 未知，试验次数 $N \\in \\mathbb{N}$ 固定。对于任意观测到的成功次数 $k \\in \\{0,1,\\dots,N\\}$，一个置信区间构造会产生一个区间 $I(k;N,\\alpha) = [\\ell(k;N,\\alpha), u(k;N,\\alpha)]$，旨在以名义覆盖概率 $1-\\alpha$ 包含真实的 $p$ 值，其中 $\\alpha \\in (0,1)$ 是显著性水平。我们关注两类区间：\n- 通过反演等尾二项检验得到的精确区间（Clopper–Pearson）。\n- 源自大样本近似的渐近区间，包括围绕最大似然估计量的正态近似和分数检验的反演（Wilson）。\n\n您的任务是实现精确覆盖率的计算，并比较这三种方法在小样本情况下的覆盖特性。您的实现必须基于原理，并从以下基本事实出发：\n- 二项概率质量函数为 $P(K=k \\mid p,N) = \\binom{N}{k} p^k (1-p)^{N-k}$。\n- 在二项模型下，$p$ 的最大似然估计量为 $\\hat{p} = k/N$。\n- 一个将 $k$ 映射到区间 $I(k;N,\\alpha)$ 的方法的覆盖率，是指当 $K \\sim \\text{Binomial}(N,p)$ 时，$p \\in I(K;N,\\alpha)$ 的概率，这可以通过对所有满足 $p \\in I(k;N,\\alpha)$ 的 $k$ 值，将其对应的二项概率求和来精确计算，即：\n$$ \\text{Cov}(p;N,\\alpha) = \\sum_{k=0}^{N} \\mathbf{1}\\!\\left\\{ p \\in I(k;N,\\alpha) \\right\\} \\binom{N}{k} p^k (1-p)^{N-k}. $$\n不提供其他公式。您可以使用标准的特殊函数和数值方法来实现任何必要的检验反演或渐近近似。\n\n将以下区间方法实现为关于 $k$、$N$ 和 $\\alpha$ 的函数：\n- 精确的 Clopper–Pearson 等尾区间，通过反演每条尾部的二项累积分布来定义。\n- 渐近 Wald 区间，通过在最大似然估计量 $\\hat{p}$ 周围应用正态近似，并使用观测到的 Fisher 信息作为方差代理来获得。\n- 渐近 Wilson 分数区间，通过反演大样本分数检验来获得。\n\n对于下面定义的每个测试用例，通过如上述方程所示对 $k \\in \\{0,\\dots,N\\}$ 求和，计算每种方法在指定的真实 $p$ 值下的精确频率学派覆盖率。然后报告其保守性或覆盖不足，定义为与名义值的偏差：\n$$ \\Delta(p;N,\\alpha) = \\text{Cov}(p;N,\\alpha) - (1-\\alpha). $$\n正的 $\\Delta$ 表示保守性；负的 $\\Delta$ 表示覆盖不足。所有概率必须以小数形式表示。将每个报告的偏差四舍五入到六位小数。\n\n测试套件输入（每个元组为 $(N,p,\\alpha)$）：\n- 用例 1：$N=1$, $p=0.5$, $\\alpha=0.32$。\n- 用例 2：$N=5$, $p=0.05$, $\\alpha=0.32$。\n- 用例 3：$N=5$, $p=0.5$, $\\alpha=0.32$。\n- 用例 4：$N=10$, $p=0.5$, $\\alpha=0.05$。\n- 用例 5：$N=10$, $p=0.95$, $\\alpha=0.10$。\n- 用例 6：$N=10$, $p=0.01$, $\\alpha=0.32$。\n\n您的程序必须：\n- 对于每个用例，计算三个偏差 $\\Delta_{\\text{CP}}$、$\\Delta_{\\text{Wald}}$ 和 $\\Delta_{\\text{Wilson}}$，分别对应 Clopper–Pearson、Wald 和 Wilson 方法。\n- 将每个用例的结果汇总到一个浮点数列表的列表中，每个用例的顺序为 $[\\Delta_{\\text{CP}},\\Delta_{\\text{Wald}},\\Delta_{\\text{Wilson}}]$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，每个元素本身是针对一个测试用例的三个四舍五入偏差的、由方括号括起来的逗号分隔列表，不含空格。例如：“[[x11,x12,x13],[x21,x22,x23],...]”，其中每个 $x_{ij}$ 是一个四舍五入到六位小数的十进制数。",
            "solution": "该问题要求实现并比较三种用于二项比例 $p$ 的不同置信区间方法。比较将通过在一组指定的测试用例上，为每种方法计算精确的频率学派覆盖概率来进行。需要报告的结果是此精确覆盖率与名义覆盖水平 $1-\\alpha$ 的偏差。\n\n首先，我们形式化待评估的三种区间构造方法：Clopper-Pearson（精确）区间、Wald（渐近）区间和 Wilson（分数）区间。设 $N$ 为试验次数，$k \\in \\{0, 1, \\dots, N\\}$ 为观测到的成功次数，$\\alpha \\in (0,1)$ 为显著性水平。名义置信水平为 $1-\\alpha$。\n\n**1. Clopper-Pearson (CP) 区间**\nClopper-Pearson 区间是通过反演两个独立的单边二项检验构造的，每个检验的显著性水平均为 $\\alpha/2$。区间 $[\\ell_{CP}, u_{CP}]$ 的端点由以下方程定义：\n$$ P(K \\ge k \\mid p=\\ell_{CP}) = \\sum_{i=k}^{N} \\binom{N}{i} \\ell_{CP}^i (1-\\ell_{CP})^{N-i} = \\frac{\\alpha}{2} $$\n$$ P(K \\le k \\mid p=u_{CP}) = \\sum_{i=0}^{k} \\binom{N}{i} u_{CP}^i (1-u_{CP})^{N-i} = \\frac{\\alpha}{2} $$\n必须解这两个方程以求得 $\\ell_{CP}$ 和 $u_{CP}$。这些和式与正则化不完全贝塔函数有关，而该函数又将它们与贝塔分布的累积分布函数（CDF）联系起来。这使得可以使用贝塔分布的分位数（或百分点函数，PPF）直接求解端点。\n\n对于 $k \\in \\{1, \\dots, N-1\\}$：\n下界 $\\ell_{CP}$ 是参数为 $(k, N-k+1)$ 的贝塔分布的 $\\alpha/2$ 分位数。\n$$ \\ell_{CP}(k, N, \\alpha) = \\text{Beta.ppf}(\\alpha/2; k, N-k+1) $$\n上界 $u_{CP}$ 是参数为 $(k+1, N-k)$ 的贝塔分布的 $1-\\alpha/2$ 分位数。\n$$ u_{CP}(k, N, \\alpha) = \\text{Beta.ppf}(1-\\alpha/2; k+1, N-k) $$\n对于观测空间的边界存在特殊情况：\n- 如果 $k=0$，下界为 $\\ell_{CP} = 0$。上界由 $(1-u_{CP})^N = \\alpha/2$ 推导得出，即 $u_{CP} = 1 - (\\alpha/2)^{1/N}$。\n- 如果 $k=N$，上界为 $u_{CP} = 1$。下界由 $\\ell_{CP}^N = \\alpha/2$ 推导得出，即 $\\ell_{CP} = (\\alpha/2)^{1/N}$。\n\n根据构造，Clopper-Pearson 区间保证对于所有 $p$ 值，其覆盖概率至少为 $1-\\alpha$。此特性使其具有“保守性”。\n\n**2. Wald 区间**\nWald 区间源于对 $p$ 的最大似然估计量（MLE）$\\hat{p} = k/N$ 的抽样分布的正态近似。对于大 $N$，中心极限定理表明 $\\hat{p}$ 近似服从均值为 $p$、方差为 $p(1-p)/N$ 的正态分布。Wald 方法通过用 $\\hat{p}$ 替代 $p$ 来估计此方差，使用“观测 Fisher 信息”，得到标准误 $SE = \\sqrt{\\hat{p}(1-\\hat{p})/N}$。\n近似的 $1-\\alpha$ 置信区间则由下式给出：\n$$ [\\ell_W, u_W] = \\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N}} $$\n其中 $z_{\\alpha/2}$ 是标准正态分布的临界值，使得 $P(|Z| > z_{\\alpha/2}) = \\alpha$，这对应于 $1-\\alpha/2$ 分位数。此方法计算简单，但已知在 $N$ 较小或 $p$ 接近 0 或 1 时表现不佳。当 $k=0$ 或 $k=N$ 时，会出现一个显著的病态问题，此时 $\\hat{p}$ 分别为 0 或 1。在这些情况下，估计的标准误变为 0，导致零宽度的区间 $[0,0]$ 或 $[1,1]$，这通常无法覆盖真实的 $p$。\n\n**3. Wilson (分数) 区间**\nWilson 分数区间也基于正态近似，但它是通过反演分数检验推导出来的。它不是用 $\\hat{p}$ 替换方差项中的 $p$，而是使用假设的 $p$ 值本身来构建检验统计量：\n$$ Z(p) = \\frac{\\hat{p}-p}{\\sqrt{p(1-p)/N}} $$\n置信区间是所有使得检验在水平 $\\alpha$ 下不会被拒绝的 $p_0$ 值的集合，即 $|Z(p_0)| \\leq z_{\\alpha/2}$。这个条件是关于 $p$ 的一个二次不等式：\n$$ (\\hat{p}-p)^2 \\le z_{\\alpha/2}^2 \\frac{p(1-p)}{N} $$\n解出 $p$ 即可得到 Wilson 区间 $[\\ell_{Wils}, u_{Wils}]$ 的端点：\n$$ \\frac{1}{1 + z_{\\alpha/2}^2/N} \\left( \\hat{p} + \\frac{z_{\\alpha/2}^2}{2N} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N} + \\frac{z_{\\alpha/2}^2}{4N^2}} \\right) $$\n该区间比 Wald 区间具有更好的小样本特性。它不围绕 $\\hat{p}$ 对称，且宽度从不为零，即使在 $k=0$ 或 $k=N$ 时也能产生合理的区间。\n\n**覆盖率计算**\n对于给定的真实参数 $p$，一个区间方法 $I(k;N,\\alpha)$ 的精确频率学派覆盖率，是随机区间 $I(K;N,\\alpha)$ 包含 $p$ 的概率，其中随机变量 $K$ 服从二项分布 $K \\sim \\text{Binomial}(N,p)$。这可以通过对所有使得结果区间覆盖 $p$ 的结果 $k$ 的概率求和来计算：\n$$ \\text{Cov}(p;N,\\alpha) = \\sum_{k=0}^{N} \\mathbf{1}\\!\\left\\{ p \\in I(k;N,\\alpha) \\right\\} P(K=k \\mid p,N) $$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数，$P(K=k \\mid p,N) = \\binom{N}{k} p^k (1-p)^{N-k}$ 是二项概率质量函数。\n\n对于每个测试用例 $(N, p, \\alpha)$ 和三种区间方法中的每一种，我们对所有可能的 $k$ 值（从 0到 $N$）执行此求和。我们首先计算给定 $k$ 的区间，然后检查真实 $p$ 是否在其中。如果是，则将相应的二项概率加到一个累加器中，最终得到覆盖率。然后，与名义值的偏差计算为 $\\Delta = \\text{Cov}(p;N,\\alpha) - (1-\\alpha)$，这表示保守性（$\\Delta > 0$）或覆盖不足（$\\Delta  0$）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef clopper_pearson_interval(k, N, alpha):\n    \"\"\"\n    Computes the Clopper-Pearson (exact) confidence interval for a binomial proportion.\n    \"\"\"\n    if k == 0:\n        lower = 0.0\n        upper = 1 - (alpha / 2)**(1 / N)\n    elif k == N:\n        lower = (alpha / 2)**(1 / N)\n        upper = 1.0\n    else:\n        lower = stats.beta.ppf(alpha / 2, k, N - k + 1)\n        upper = stats.beta.ppf(1 - alpha / 2, k + 1, N - k)\n    return lower, upper\n\ndef wald_interval(k, N, alpha):\n    \"\"\"\n    Computes the Wald (normal approximation) confidence interval.\n    \"\"\"\n    if N == 0:\n        return 0.0, 1.0\n    p_hat = k / N\n    z = stats.norm.ppf(1 - alpha / 2)\n    se = np.sqrt(p_hat * (1 - p_hat) / N)\n    lower = p_hat - z * se\n    upper = p_hat + z * se\n    return lower, upper\n\ndef wilson_score_interval(k, N, alpha):\n    \"\"\"\n    Computes the Wilson score confidence interval.\n    \"\"\"\n    if N == 0:\n        return 0.0, 1.0\n    p_hat = k / N\n    z = stats.norm.ppf(1 - alpha / 2)\n    z2 = z**2\n    \n    denominator = 1 + z2 / N\n    center = p_hat + z2 / (2 * N)\n    \n    term_under_sqrt = (p_hat * (1 - p_hat) / N) + (z2 / (4 * N**2))\n    half_width = z * np.sqrt(term_under_sqrt)\n    \n    lower = (center - half_width) / denominator\n    upper = (center + half_width) / denominator\n    \n    return lower, upper\n\ndef compute_coverage(N, p, alpha, interval_func):\n    \"\"\"\n    Computes the exact coverage probability for a given interval procedure.\n    \"\"\"\n    coverage = 0.0\n    for k in range(N + 1):\n        lower, upper = interval_func(k, N, alpha)\n        # Add a small epsilon for floating point comparisons at the boundary\n        epsilon = 1e-9\n        if (p >= lower - epsilon) and (p = upper + epsilon):\n            prob = stats.binom.pmf(k, N, p)\n            coverage += prob\n    return coverage\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and compute deviations.\n    \"\"\"\n    # Test suite input (each tuple is (N, p, alpha))\n    test_cases = [\n        (1, 0.5, 0.32),\n        (5, 0.05, 0.32),\n        (5, 0.5, 0.32),\n        (10, 0.5, 0.05),\n        (10, 0.95, 0.10),\n        (10, 0.01, 0.32),\n    ]\n\n    results = []\n    interval_methods = {\n        'CP': clopper_pearson_interval,\n        'Wald': wald_interval,\n        'Wilson': wilson_score_interval\n    }\n    \n    method_order = ['CP', 'Wald', 'Wilson']\n\n    for N, p, alpha in test_cases:\n        case_results = []\n        nominal_coverage = 1 - alpha\n\n        for method_name in method_order:\n            interval_func = interval_methods[method_name]\n            coverage = compute_coverage(N, p, alpha, interval_func)\n            deviation = coverage - nominal_coverage\n            case_results.append(round(deviation, 6))\n        \n        results.append(case_results)\n\n    # Format the final output string as specified\n    inner_strings = [f\"[{','.join(map(str, row))}]\" for row in results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "尽管二次（高斯）近似下的对数似然函数图像非常直观，但在实际分析中，这种理想情况可能并不成立。当似然函数在最大值附近变得平坦时，就会出现鞍点问题，导致基于曲率的误差估计方法失效。这项高级练习 () 将展示这一病态情况，并将失效的方法与更稳健的技术（如似然比扫描和自助法）进行对比，这些都是物理学家工具箱中不可或缺的工具。",
            "id": "3526375",
            "problem": "您将设计并实现一个完整、可运行的程序，用于在一个简化的高能物理计数实验中，为一个单一信号强度参数构建并比较三种区间估计量。实验的背景是一个弱耦合相互作用，其事件产额与一个实数非负振幅参数呈二次方关系。关键的挑战在于似然鞍点附近的区域，在该区域，对数似然关于参数的二阶导数近似为零，导致基于曲率的不确定性估计失效。\n\n物理设置是理想化的，但在计算高能物理中是标准的：一个单箱计数实验，具有已知的本底，其信号产额与一个非负振幅的平方成正比。数据是单个整数计数 $n$，来自一个泊松分布，其均值为\n$$\n\\lambda(\\theta) \\equiv b + s\\,\\theta^2,\n$$\n其中 $b \\ge 0$ 是已知的预期本底计数，$s  0$ 是已知的信号归一化系数，$\\theta \\ge 0$ 是我们感兴趣的实数振幅参数。所有量都是无量纲的事件计数，因此不需要物理单位。您的程序必须为 $\\theta$ 实现三种区间构建方法，中心概率质量为 $0.6827$（对于高斯分布，通常称为一个标准差），并比较它们的行为，特别是在鞍点区域附近，此时对数似然在其最大值处的观测曲率接近于零。\n\n基本原理和定义：\n- 在给定 $\\theta$ 的情况下观测到 $n$ 的似然为\n$$\nL(\\theta; n, b, s) = \\mathrm{Pois}\\big(n \\mid \\lambda(\\theta)\\big) = \\frac{\\lambda(\\theta)^n e^{-\\lambda(\\theta)}}{n!}.\n$$\n- 对数似然（不含与 $\\theta$ 无关的加性常数）为\n$$\n\\ell(\\theta) = n \\log \\lambda(\\theta) - \\lambda(\\theta).\n$$\n- 最大似然估计 (MLE) $\\hat{\\theta}$ 是在 $\\theta \\ge 0$ 约束下 $\\ell(\\theta)$ 的任何一个最大化者。\n- 观测到的Fisher信息定义为 $J(\\theta) \\equiv -\\frac{\\partial^2 \\ell(\\theta)}{\\partial \\theta^2}$ 在MLE处的值，即 $J(\\hat{\\theta})$。\n- 对于给定 $\\theta$ 的似然比统计量为\n$$\nq(\\theta) \\equiv 2\\left[\\ell(\\hat{\\theta}) - \\ell(\\theta)\\right].\n$$\n\n您的程序必须：\n1. 通过在 $\\theta \\ge 0$ 上最大化 $\\ell(\\theta)$ 来计算MLE $\\hat{\\theta}$。\n2. 为 $\\theta$ 构建以下三种中心概率质量为 $0.6827$ 的区间：\n   - 基于曲率（Wald）的区间：使用观测到的Fisher信息 $J(\\hat{\\theta})$ 形成一个正态近似区间。将目标视为一个双侧中心区间。如果 $J(\\hat{\\theta}) \\le 0$ 或在数值上与零无法区分（低于一个严格的正容差），则基于曲率的区间是未定义的；在这种情况下，您必须将基于曲率的区间报告为 $[0, +\\infty)$。\n   - 似然比扫描区间：基于 $q(\\theta)$ 反演检验，找到 $\\theta \\ge 0$ 的连通区间，使得 $q(\\theta) \\le c$，其中 $c$ 对应于高斯近似下 $0.6827$ 的一维中心概率质量。使用标准选择 $c = 1$。通过扫描 $q(\\theta)$ 并严格地为每个端点设定界限，然后调用一个稳健的求解器来实现数值求根。如果下端点为负，则报告为 $0$。\n   - 参数化自助法区间：使用固定的随机种子生成伪实验 $n^\\star \\sim \\mathrm{Pois}\\big(b + s \\hat{\\theta}^2\\big)$ 以确保可复现性。对于每个伪实验，计算自助法MLE $\\hat{\\theta}^\\star$。报告由 $0.15865$ 和 $0.84135$ 处的下分位数和上分位数定义的经验中心区间。为每个测试用例使用至少 $10000$ 次自助法重复，以确保稳定性。\n\n3. 为以下不同情况的测试套件提供结果：\n   - 情况A（鞍点情况）：$n = 25$，$b = 25.0$，$s = 100.0$。\n   - 情况B（鞍点附近的轻微超出）：$n = 27$，$b = 25.0$，$s = 100.0$。\n   - 情况C（存在亏损且MLE在边界上）：$n = 20$，$b = 25.0$，$s = 100.0$。\n   - 情况D（低计数情况）：$n = 1$，$b = 0.5$，$s = 5.0$。\n\n算法和数值要求：\n- 从上述基本定义出发，根据需要从 $\\ell(\\theta)$ 计算导数。不要假设任何预先提供的公式；从第一性原理推导您所需要的一切。\n- 所有数值求解器必须处理约束 $\\theta \\ge 0$。在判断 $J(\\hat{\\theta})$ 是否为非正值时，使用一个明确的有限容差。\n- 对任何伪随机数生成使用固定种子以确保确定性。\n- 将每个区间报告为一个有序对 $[\\text{lower}, \\text{upper}]$，必要时下界在 $0$ 处截断。如果上界是 $+\\infty$，必须明确报告为一个无穷大浮点数值。\n\n最终输出格式：\n- 对于指定顺序（A, B, C, D）中的每种情况，生成一个列表，其中包含按顺序排列的三个区间（基于曲率的区间、似然比扫描区间、参数化自助法区间），每个区间表示为两个四舍五入到 $6$ 位小数的浮点数。因此，最终输出必须是单行，包含一个有四个元素（每个测试用例一个）的列表，其中每个元素是按以下顺序排列的六个浮点数的列表\n$$\n[\\text{wald\\_low}, \\text{wald\\_high}, \\text{lr\\_low}, \\text{lr\\_high}, \\text{boot\\_low}, \\text{boot\\_high}].\n$$\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，例如 $[\\,[\\cdots], [\\cdots], [\\cdots], [\\cdots]\\,]$。\n\n所有量都是无量纲的，不需要物理单位。所有角度（如果出现）必须以弧度为单位；然而，本问题不涉及角度。",
            "solution": "我们从最大似然原理和适用于高能物理单箱计数实验的泊松模型开始。实验观测到一个计数 $n$，其模型为泊松分布，均值为 $\\lambda(\\theta) = b + s \\theta^2$，其中 $\\theta$ 为非负数。似然函数为 $L(\\theta) = \\mathrm{Pois}(n \\mid \\lambda(\\theta))$，对数似然（舍去与 $\\theta$ 无关的加性常数）为\n$$\n\\ell(\\theta) = n \\log \\lambda(\\theta) - \\lambda(\\theta), \\quad \\lambda(\\theta) \\equiv b + s \\theta^2.\n$$\n\n最大似然估计：\n因为泊松似然函数在其均值处最大化，即 $\\hat{\\lambda} = n$，所以在 $\\theta \\ge 0$ 上的受约束最大化者必须满足\n$$\n\\hat{\\theta}^2 = \\max\\left( \\frac{n - b}{s}, 0 \\right), \\quad \\hat{\\theta} = \\sqrt{\\max\\left( \\frac{n - b}{s}, 0 \\right)}.\n$$\n这是通过将 $\\ell(\\theta)$ 作为 $\\lambda(\\theta)$ 的函数，然后关于 $\\theta$ 进行最大化，并考虑到单调性和非负性约束得出的。如果 $n \\le b$，则 $\\hat{\\theta} = 0$（边界MLE）。如果 $n  b$，则 $\\hat{\\theta} = \\sqrt{(n - b)/s}$（内部MLE），此时对应的 $\\hat{\\lambda} = n$。\n\n观测到的Fisher信息和基于曲率（Wald）的区间：\n观测到的Fisher信息是 $J(\\theta) \\equiv -\\ell''(\\theta)$，其中撇号表示关于 $\\theta$ 的微分。我们从第一性原理计算导数。首先，\n$$\n\\ell'(\\theta) = \\frac{n}{\\lambda(\\theta)} \\cdot \\lambda'(\\theta) - \\lambda'(\\theta) = \\left(\\frac{n - \\lambda(\\theta)}{\\lambda(\\theta)}\\right) \\lambda'(\\theta).\n$$\n因为 $\\lambda'(\\theta) = 2 s \\theta$，我们有\n$$\n\\ell'(\\theta) = \\left(\\frac{n - \\lambda(\\theta)}{\\lambda(\\theta)}\\right) 2 s \\theta.\n$$\n再次求导，使用乘法法则以及\n$$\n\\frac{d}{d\\theta}\\left(\\frac{n - \\lambda(\\theta)}{\\lambda(\\theta)}\\right) = -\\lambda'(\\theta)\\left(\\frac{1}{\\lambda(\\theta)} + \\frac{n - \\lambda(\\theta)}{\\lambda(\\theta)^2}\\right) = -\\lambda'(\\theta) \\frac{n}{\\lambda(\\theta)^2},\n$$\n我们得到\n$$\n\\ell''(\\theta) = 2 s \\frac{n - \\lambda(\\theta)}{\\lambda(\\theta)} - 4 s^2 \\theta^2 \\frac{n}{\\lambda(\\theta)^2}.\n$$\n在内部MLE处（即 $\\lambda(\\hat{\\theta}) = n$）求值，此式简化为\n$$\n\\ell''(\\hat{\\theta}) = - \\frac{4 s (n - b)}{n}, \\quad J(\\hat{\\theta}) = -\\ell''(\\hat{\\theta}) = \\frac{4 s (n - b)}{n}.\n$$\n在边界MLE处（即 $\\hat{\\theta} = 0$），我们有 $\\lambda(0) = b$ 且\n$$\n\\ell''(0) = 2 s \\frac{n - b}{b}, \\quad J(0) = -\\ell''(0) = 2 s \\frac{b - n}{b}.\n$$\n鞍点情况发生在 $n \\approx b$ 时，此时 $\\ell''(\\hat{\\theta}) \\approx 0$，因此 $J(\\hat{\\theta}) \\approx 0$。在这种情况下，二次（高斯）近似失效，因为它会预测一个任意大的方差，或者在数值噪声下当 $J(\\hat{\\theta}) \\le 0$ 时无法定义方差。\n\n基于曲率（Wald）的 $0.6827$ 概率质量区间是双侧正态近似区间\n$$\n\\left[ \\max\\left(0, \\hat{\\theta} - \\frac{1}{\\sqrt{J(\\hat{\\theta})}}\\right), \\ \\hat{\\theta} + \\frac{1}{\\sqrt{J(\\hat{\\theta})}} \\right],\n$$\n需要理解的是，如果 $J(\\hat{\\theta}) \\le 0$ 或在严格的容差范围内数值上与零无法区分，则此构建方法无效，我们报告 $[0, +\\infty)$。\n\n似然比扫描区间：\n定义似然比统计量\n$$\nq(\\theta) \\equiv 2 \\left[\\ell(\\hat{\\theta}) - \\ell(\\theta)\\right].\n$$\n我们通过在阈值 $c = 1$（高斯近似下一个标准差对应的标准一维阈值）处反演检验来构建 $0.6827$ 概率质量区间。该区间是集合\n$$\n\\{\\theta \\ge 0 \\mid q(\\theta) \\le 1\\}.\n$$\n操作上，我们通过对 $q(\\theta) - 1 = 0$ 进行求根来找到 $\\hat{\\theta}$ 周围的连通区间。下端点是 $(0, \\hat{\\theta})$ 中存在的唯一根，或者在其他情况下为 $0$（例如，如果 $q(0) \\le 1$ 或 $\\hat{\\theta} = 0$）。上端点是 $(\\hat{\\theta}, \\infty)$ 中的唯一根，其存在性是因为当 $\\theta \\to \\infty$ 时 $\\ell(\\theta) \\to -\\infty$，因此 $q(\\theta) \\to \\infty$。我们通过向外扫描为每个根设定界限，并应用一个基于二分法的稳健求解器。\n\n参数化自助法区间：\n我们在代入的参数值 $\\hat{\\theta}$ 处进行参数化自助法。使用固定种子生成 $N_{\\mathrm{boot}}$ 个伪实验 $n^\\star \\sim \\mathrm{Pois}(b + s \\hat{\\theta}^2)$。对于每个 $n^\\star$，计算自助法MLE\n$$\n\\hat{\\theta}^\\star = \\sqrt{\\max\\left(\\frac{n^\\star - b}{s}, 0\\right)}.\n$$\n自助法 $0.6827$ 概率质量中心区间由概率为 $0.15865$ 和 $0.84135$ 处的经验分位数给出。因为 $\\theta \\ge 0$，在边界情况下，下分位数通常可能为 $0$。\n\n测试套件和实现细节：\n我们将上述构建方法应用于四种情况：$(n, b, s) \\in \\{(25, 25.0, 100.0), (27, 25.0, 100.0), (20, 25.0, 100.0), (1, 0.5, 5.0)\\}$。对于每种情况，我们计算\n- 如上所述从第一性原理计算的MLE $\\hat{\\theta}$；\n- 使用从 $\\ell''(\\theta)$ 推导出的 $J(\\hat{\\theta})$ 计算基于曲率的区间；\n- 通过使用界限设定和一个稳健的求根器求解 $q(\\theta) = 1$ 来计算似然比区间；\n- 使用 $N_{\\mathrm{boot}} \\ge 10000$ 次重复和固定种子计算参数化自助法区间。\n\n数值稳定性考虑：\n- 我们使用 $\\ell''(\\theta)$ 的解析表达式来精确地在MLE处评估 $J(\\hat{\\theta})$。当 $b$ 非常小时，我们通过确保测试套件中 $b  0$ 来避免除以零的计算。\n- 我们对 $J(\\hat{\\theta})$ 使用严格的正容差。如果 $J(\\hat{\\theta})$ 是非正值或低于容差，我们声明Wald区间未定义，并报告 $[0, +\\infty)$。\n- 对于似然比的界限设定，我们指数级增加界限，直到 $q(\\theta)$ 超过 $1$，以保证上根的存在性。仅当 $q(0)  1$ 且 $\\hat{\\theta}  0$ 时才寻找下根。\n\n最终输出：\n对于每种情况，我们报告六个数字\n$$\n[\\text{wald\\_low}, \\text{wald\\_high}, \\text{lr\\_low}, \\text{lr\\_high}, \\text{boot\\_low}, \\text{boot\\_high}],\n$$\n四舍五入到 $6$ 位小数，生成一个包含四个此类列表的单行列表。此设计展示了基于曲率的区间在鞍点附近（$J(\\hat{\\theta}) \\approx 0$）的失效，通过扫描精确似然获得的似然比区间的稳健性，以及自助法区间的数据驱动行为，尤其是在边界和低计数情况下。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef loglik(n, b, s, theta):\n    # Log-likelihood up to additive constant independent of theta\n    # Ensure theta = 0\n    if theta  0:\n        return -np.inf\n    lam = b + s * theta**2\n    if lam = 0:\n        return -np.inf\n    return n * np.log(lam) - lam\n\ndef mle_theta(n, b, s):\n    # Constrained MLE theta = 0\n    if n > b:\n        val = (n - b) / s\n        # numerical safeguard\n        val = max(val, 0.0)\n        return np.sqrt(val)\n    else:\n        return 0.0\n\ndef ell_pp(n, b, s, theta):\n    # Second derivative of log-likelihood wrt theta\n    lam = b + s * theta**2\n    if lam = 0:\n        return np.nan\n    term1 = 2.0 * s * (n - lam) / lam\n    term2 = 4.0 * s**2 * theta**2 * n / (lam**2)\n    return term1 - term2\n\ndef observed_info(n, b, s, theta_hat):\n    # Observed Fisher information J = -ell''\n    lpp = ell_pp(n, b, s, theta_hat)\n    if not np.isfinite(lpp):\n        return np.nan\n    return -lpp\n\ndef wald_interval(n, b, s, theta_hat, tol=1e-12):\n    J = observed_info(n, b, s, theta_hat)\n    if not np.isfinite(J) or J = tol:\n        # Undefined curvature interval near saddle or negative curvature\n        return (0.0, float('inf'))\n    sigma = 1.0 / np.sqrt(J)\n    low = max(0.0, theta_hat - sigma)\n    high = theta_hat + sigma\n    return (low, high)\n\ndef q_stat(n, b, s, theta, theta_hat):\n    return 2.0 * (loglik(n, b, s, theta_hat) - loglik(n, b, s, theta))\n\ndef lr_interval(n, b, s, theta_hat, c=1.0):\n    # Find interval {theta = 0 | q(theta) = c}\n    # Lower endpoint\n    def f(th):\n        return q_stat(n, b, s, th, theta_hat) - c\n\n    # Handle lower endpoint\n    if theta_hat = 0.0:\n        lower = 0.0\n    else:\n        q0 = q_stat(n, b, s, 0.0, theta_hat)\n        if q0 = c:\n            lower = 0.0\n        else:\n            # Find root in (0, theta_hat)\n            a, bnd = 0.0, theta_hat\n            # f(bnd) = -c  0; f(a) >= 0\n            # For numerical stability, ensure sign change\n            fa = f(a + 1e-16)  # slightly above zero\n            fb = f(bnd)\n            # Ensure fb  0 (should be true)\n            if fb >= 0:\n                # fallback: shrink bnd slightly\n                bnd = theta_hat * 0.999999\n                fb = f(bnd)\n            if fa = 0 or fb >= 0:\n                # If still not a valid bracket due to numerical issues, set lower to 0\n                lower = 0.0\n            else:\n                lower = brentq(f, a + 1e-16, bnd, maxiter=1000, xtol=1e-12, rtol=1e-10)\n    # Upper endpoint\n    # Bracket by expanding until f(high) >= 0 (i.e., q(high) >= c)\n    lo = max(theta_hat, 0.0)\n    hi = max(lo * 2.0, 1e-9) if lo > 0 else 1e-6\n    # Ensure f(lo)  0 (since q(lo) = 0 at theta_hat)\n    flo = f(lo)\n    # For boundary MLE lo = 0, q(0) may be 0; adjust slightly above 0\n    if lo == 0.0:\n        lo = 1e-12\n        flo = f(lo)\n    # Increase hi until sign change\n    fhi = f(hi)\n    iters = 0\n    while not np.isfinite(fhi) or fhi  0.0:\n        hi *= 2.0\n        fhi = f(hi)\n        iters += 1\n        if iters > 200:\n            break\n    if not np.isfinite(fhi) or fhi  0.0:\n        # As a last resort, use a very large upper bound\n        hi = max(1.0, hi)\n        for _ in range(1000):\n            hi *= 1.5\n            fhi = f(hi)\n            if np.isfinite(fhi) and fhi >= 0.0:\n                break\n    if np.isfinite(fhi) and flo  0.0 and fhi >= 0.0:\n        upper = brentq(f, lo, hi, maxiter=1000, xtol=1e-12, rtol=1e-10)\n    else:\n        upper = float('inf')\n    return (max(0.0, lower), upper)\n\ndef bootstrap_interval(n, b, s, theta_hat, n_boot=10000, seed=12345, qlow=0.15865, qhigh=0.84135):\n    rng = np.random.default_rng(seed)\n    lam_hat = b + s * theta_hat**2\n    # Draw Poisson pseudo data\n    samples = rng.poisson(lam=lam_hat, size=n_boot)\n    # Compute bootstrap MLEs\n    thetas = np.sqrt(np.maximum(samples - b, 0.0) / s)\n    # Empirical quantiles\n    low = float(np.quantile(thetas, qlow, method='linear'))\n    high = float(np.quantile(thetas, qhigh, method='linear'))\n    return (max(0.0, low), max(0.0, high))\n\ndef format_float(x):\n    if np.isinf(x):\n        return \"inf\"\n    if np.isnan(x):\n        return \"nan\"\n    return f\"{x:.6f}\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is (n, b, s)\n    test_cases = [\n        (25, 25.0, 100.0),  # Case A: saddle regime (n ~ b)\n        (27, 25.0, 100.0),  # Case B: slight excess near saddle\n        (20, 25.0, 100.0),  # Case C: deficit with boundary MLE\n        (1, 0.5, 5.0),      # Case D: low-count regime\n    ]\n\n    results = []\n    for (n, b, s) in test_cases:\n        theta_hat = mle_theta(n, b, s)\n        w_low, w_high = wald_interval(n, b, s, theta_hat)\n        lr_low, lr_high = lr_interval(n, b, s, theta_hat, c=1.0)\n        # Increase bootstrap replicates modestly in low-count regimes to stabilize\n        n_boot = 20000 if n = 1 else 10000\n        b_low, b_high = bootstrap_interval(n, b, s, theta_hat, n_boot=n_boot, seed=123456)\n        # Append formatted results\n        results.append([\n            format_float(w_low), format_float(w_high),\n            format_float(lr_low), format_float(lr_high),\n            format_float(b_low), format_float(b_high)\n        ])\n\n    # Final print statement in the exact required format.\n    # We need a single-line list of lists of 6 floats (as strings).\n    # Construct the string manually to ensure exact formatting.\n    inner_strs = []\n    for res in results:\n        inner_strs.append(\"[\" + \",\".join(res) + \"]\")\n    print(\"[\" + \",\".join(inner_strs) + \"]\")\n\nsolve()\n```"
        }
    ]
}