{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握频率学派的置信区间，我们必须从其最基础的奈曼构造（Neyman construction）入手。这项练习将指导你通过数值方法反演假设检验，为一个简单的泊松（Poisson）信号构建“精确”区间，这是统计推断的基石。 通过进一步计算区间的实际覆盖率，你将对由离散数据引起的过覆盖（over-coverage）这一微妙但重要的特性有更具体的理解。",
            "id": "3509404",
            "problem": "考虑一个计算高能物理中的计数实验，其中观测到的事件数 $n$ 被建模为 $n \\sim \\text{Poisson}(s+b)$，其中信号平均值 $s \\ge 0$，已知本底平均值 $b \\ge 0$。目标是通过反演泊松分布的累积分布函数 (CDF) 为参数 $s$ 构建一个置信水平 (CL) 为 $1-\\alpha$ 的精确双边置信区间，然后量化在小计数情况下的频率论覆盖率和过覆盖行为。\n\n从基本定义出发：模型似然基于可观测量 $n$ 的泊松分布，而 $s$ 的 Neyman 置信区间是通过使用 $n$ 的抽样分布来反演参数检验得到的。在可观测量空间中使用等尾构造法，并通过数值方法反演以获得参数空间中的置信区间。\n\n实现以下任务：\n1. 对于给定的观测计数 $n$、本底 $b$ 和显著性水平 $\\alpha$，通过对 $n \\sim \\text{Poisson}(s+b)$ 的泊松 CDF 进行数值反演，在可观测量 $n$ 中使用大小为 $\\alpha/2$ 的等尾，来构建 $s$ 的精确双边置信区间。如有必要，通过将下端点截断为 $0$ 来强制执行物理约束 $s \\ge 0$。将区间端点表示为不带单位的实数。\n2. 对于给定的真实信号 $s_{\\text{true}}$，计算该区间构造方法的频率论覆盖率。计算方法为：对所有 $n \\in \\{0,1,2,\\dots\\}$，将“$s_{\\text{true}}$ 位于从 $n$ 构建的区间内”的指示函数乘以 $n \\sim \\text{Poisson}(s_{\\text{true}}+b)$ 的概率质量函数，然后求和。将过覆盖率量化为覆盖率与名义置信水平 $1-\\alpha$ 之间的差值。将此差值表示为一个小数（而非百分比），并四舍五入到指定的精度。\n3. 使用鲁棒的数值求根方法进行反演，其合理性由泊松 CDF 在均值上的单调性保证。对于覆盖率的求和，在一个足够大的上限处截断无穷级数，以确保剩余的尾部概率可以忽略不计，从而保证数值精度。\n\n您的程序必须实现上述内容，并运行以下参数集测试套件：\n- 测试用例 1：$b=0.5$，$\\alpha=0.10$，$n_{\\text{obs}}=0$，$s_{\\text{true}}=0.0$。\n- 测试用例 2：$b=1.0$，$\\alpha=0.05$，$n_{\\text{obs}}=1$，$s_{\\text{true}}=0.2$。\n- 测试用例 3：$b=2.3$，$\\alpha=0.05$，$n_{\\text{obs}}=3$，$s_{\\text{true}}=0.0$。\n- 测试用例 4：$b=0.0$，$\\alpha=0.05$，$n_{\\text{obs}}=5$，$s_{\\text{true}}=1.5$。\n\n对于每个测试用例，您的程序必须输出一个包含三个值的列表 $[s_{\\text{L}}, s_{\\text{U}}, \\Delta]$，其中 $s_{\\text{L}}$ 是 $s$ 的置信区间下端点，$s_{\\text{U}}$ 是 $s$ 的置信区间上端点，而 $\\Delta$ 是过覆盖率，定义为覆盖率减去 $1-\\alpha$。所有三个值都必须四舍五入到六位小数。\n\n最终输出格式：您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果本身也是一个用方括号括起来的逗号分隔列表。例如，输出应类似于 $[[x_1,y_1,z_1],[x_2,y_2,z_2],[x_3,y_3,z_3],[x_4,y_4,z_4]]$，其中每个 $x_i$、$y_i$ 和 $z_i$ 都是四舍五入到六位的小数。",
            "solution": "问题陈述经评估是有效的。它在科学上基于应用于高能物理领域的频率论统计学原理，特别是关于为带本底的泊松过程构建置信区间。该问题是良置的，提供了所有必要的参数和定义，并且不包含内部矛盾或不科学的前提。这些任务在计算上是可行的，并测试了一种用于设定限值的标准（尽管是简化的）程序。\n\n本解决方案将首先详细阐述用于构建置信区间和计算其频率论覆盖率的理论框架，然后概述数值实现方法。\n\n### 理论框架\n\n#### 1. 统计模型\n实验观测到一个计数 $n$，假设其服从泊松分布。事件的期望数 $\\mu$ 是一个未知的非负信号平均值 $s$ 和一个已知的非负本底平均值 $b$ 的和。观测到 $n$ 个事件的似然由泊松概率质量函数 (PMF) 给出：\n$$\nP(n | s, b) = \\frac{e^{-(s+b)}(s+b)^n}{n!}\n$$\n感兴趣的参数是 $s$，其约束条件为 $s \\ge 0$。\n\n#### 2. 置信区间构建\n$s$ 在置信水平 (CL) 为 $1-\\alpha$ 的置信区间是通过对每个可能的 $s$ 值进行假设检验的反演来构建的。问题指定了一种基于对服从泊松分布的可观测量 $n$ 的累积分布函数 (CDF) 进行数值反演的方法。对于给定的观测值 $n_{\\text{obs}}$，区间 $[s_L, s_U]$ 被定义为所有使得 $n_{\\text{obs}}$ 不在分布 $P(n|s,b)$ 的极端尾部的 $s$ 值的集合。“等尾”构造法通过寻找均值 $\\mu = s+b$ 的值来定义端点，该均值使得观测值 $n_{\\text{obs}}$ 恰好位于大小各为 $\\alpha/2$ 的下尾部和上尾部的边缘。\n\n**上端点 $s_U$：**\n上限 $s_U$ 对应于一个足够大的信号强度，以至于观测到像 $n_{\\text{obs}}$ 这样低的计数是不太可能的。我们找到均值 $\\mu_U = s_U + b$，使得观测到 $n_{\\text{obs}}$ 或更少事件的概率恰好为 $\\alpha/2$：\n$$\nP(n \\le n_{\\text{obs}} | \\mu_U) = \\sum_{k=0}^{n_{\\text{obs}}} \\frac{e^{-\\mu_U}\\mu_U^k}{k!} = \\frac{\\alpha}{2}\n$$\n这就是泊松 CDF。因为泊松 CDF 是其均值 $\\mu$ 的单调递减函数，所以对于任何 $\\alpha \\in (0,1)$，$\\mu_U$ 的唯一解都存在，并且可以使用数值求根算法找到。一旦找到 $\\mu_U$，信号的上端点就是 $s_U = \\mu_U - b$。\n\n**下端点 $s_L$：**\n下限 $s_L$ 对应于一个足够小的信号强度，以至于观测到像 $n_{\\text{obs}}$ 这样高的计数是不太可能的。我们找到均值 $\\mu_L = s_L + b$，使得观测到 $n_{\\text{obs}}$ 或更多事件的概率恰好为 $\\alpha/2$：\n$$\nP(n \\ge n_{\\text{obs}} | \\mu_L) = \\sum_{k=n_{\\text{obs}}}^{\\infty} \\frac{e^{-\\mu_L}\\mu_L^k}{k!} = \\frac{\\alpha}{2}\n$$\n这可以使用 CDF 重写为 $1 - P(n \\le n_{\\text{obs}}-1 | \\mu_L) = \\alpha/2$，或者：\n$$\nP(n \\le n_{\\text{obs}}-1 | \\mu_L) = 1 - \\frac{\\alpha}{2}\n$$\n求解此方程得到 $\\mu_L$，然后求出 $s_L = \\mu_L - b$。\n\n当 $n_{\\text{obs}} = 0$ 时会出现一种特殊情况。下限的条件变为 $P(n \\ge 0 | \\mu_L) = 1 = \\alpha/2$，这是不可能的。在这种情况下，数据没有提供反对任意小的均值的证据，所以我们取 $\\mu_L = 0$。这得出一个原始下限 $s_L = -b$。\n\n**物理约束：**\n信号参数 $s$ 必须为非负。问题要求通过将下端点截断为 $0$ 来强制执行此约束。因此，最终的下限由 $s_L = \\max(0, \\mu_L - b)$ 给出。上限 $s_U$ 没有被明确截断，这允许在 $s_U  s_L$ 的情况下出现空区间的可能性。\n\n#### 3. 频率论覆盖率\n置信区间构造方法的频率论覆盖率是指在长期试验中，构造出的区间包含参数真实值 $s_{\\text{true}}$ 的概率。对于像 $n$ 这样的离散可观测量，覆盖率的计算方法是，将所有导致构造出的区间 $[s_L(n), s_U(n)]$ 包含 $s_{\\text{true}}$ 的结果 $n$ 的概率相加：\n$$\n\\text{Coverage}(s_{\\text{true}}) = \\sum_{n=0}^{\\infty} I(s_L(n) \\le s_{\\text{true}} \\le s_U(n)) \\cdot P(n | s_{\\text{true}}, b)\n$$\n其中 $I(\\cdot)$ 是指示函数，如果其参数为真，则为1，否则为0。概率 $P(n|s_{\\text{true}}, b)$ 是使用均值为 $\\mu_{\\text{true}} = s_{\\text{true}} + b$ 的泊松 PMF 计算的。\n\n由于泊松分布的离散性，“精确”区间构造方法的实际覆盖率不保证恰好为 $1-\\alpha$。它保证至少为 $1-\\alpha$（即它会过覆盖）。过覆盖的量由以下公式量化：\n$$\n\\Delta = \\text{Coverage}(s_{\\text{true}}) - (1-\\alpha)\n$$\n\n### 数值实现策略\n解决方案使用 `numpy` 和 `scipy` 库在 Python 中实现。\n\n1.  **区间计算 (`get_interval`)**：\n    -   创建一个函数，用于为给定的 $n_{\\text{obs}}$、$b$ 和 $\\alpha$ 计算 $[s_L, s_U]$。\n    -   使用 `scipy.optimize.brentq` 求根算法求解 $\\mu_L$ 和 $\\mu_U$ 的方程。这一选择是合理的，因为泊松 CDF 相对于其均值参数是单调的，这保证了在有界区间内存在唯一根。`brentq` 的目标函数是包装了 `scipy.stats.poisson.cdf` 的 lambda 函数。\n    -   对于下限的计算，显式处理了 $n_{\\text{obs}}=0$ 的特殊情况。\n    -   将物理约束 $s_L \\ge 0$ 作为下限计算的最后一步应用。\n\n2.  **覆盖率计算 (`calculate_coverage`)**：\n    -   一个函数为给定的 $s_{\\text{true}}$、$b$ 和 $\\alpha$ 计算覆盖率。\n    -   无穷级数在一个足够大的值 $N_{\\max}$ 处被截断，该值的确定使得剩余的尾部概率 $P(n  N_{\\max} | \\mu_{\\text{true}})$ 可以忽略不计（例如，小于 $10^{-16}$）。$N_{\\max}$ 是使用泊松分布的百分点函数 (`ppf`) 找到的。\n    -   该函数从 $n=0$ 迭代到 $N_{\\max}$。在每次迭代中，它调用 `get_interval` 来找到该 $n$ 对应的区间，检查 $s_{\\text{true}}$ 是否被覆盖，如果是，则将相应的概率 `scipy.stats.poisson.pmf(n, mu_true)` 加到总覆盖率上。\n\n3.  **主程序 (`solve`)**：\n    -   主函数遍历所提供的测试用例。\n    -   对于每个用例，它调用区间计算函数（使用 $n_{\\text{obs}}$）和覆盖率计算函数（使用 $s_{\\text{true}}$）。\n    -   它计算过覆盖率 $\\Delta$。\n    -   结果 $[s_L, s_U, \\Delta]$ 被格式化为六位小数并收集起来。\n    -   最终输出以指定的列表的列表格式打印为单行。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import poisson\nfrom scipy.optimize import brentq\n\ndef get_interval(n_obs: int, b: float, alpha: float) - list[float]:\n    \"\"\"\n    Constructs the exact two-sided confidence interval for the signal s.\n    \n    Args:\n        n_obs: The observed event count.\n        b: The known background mean.\n        alpha: The significance level (e.g., 0.10 for 90% CL).\n        \n    Returns:\n        A list [s_L, s_U] with the lower and upper interval endpoints.\n    \"\"\"\n    alpha_2 = alpha / 2.0\n\n    # Upper Endpoint s_U from mu_U\n    # Solve P(n = n_obs | mu_U) = alpha/2, which is poisson.cdf(n_obs, mu_U) = alpha/2.\n    # The function f(mu) = poisson.cdf(n_obs, mu) is monotonic, decreasing from ~1 to 0.\n    # A root must exist for alpha_2 in (0, 1).\n    # We need a search interval [a, c] for brentq where f(a)*f(c)  0.\n    # f(1e-9) is > 0. We need a c where f(c)  0.\n    # A generous upper search bound is robust.\n    upper_search_bound = n_obs + b + 500\n    try:\n        mu_U = brentq(lambda mu: poisson.cdf(n_obs, mu) - alpha_2, 1e-9, upper_search_bound)\n    except ValueError:\n        # Should not be reached with a sufficiently large search bound.\n        mu_U = np.inf\n    s_U = mu_U - b\n\n    # Lower Endpoint s_L from mu_L\n    # Solve P(n >= n_obs | mu_L) = alpha/2 => P(n = n_obs-1 | mu_L) = 1 - alpha/2.\n    if n_obs == 0:\n        # P(n >= 0 | mu_L) = 1. The equation 1 = alpha/2 has no solution for mu_L.\n        # The limit is mu_L -> 0.\n        mu_L = 0.0\n    else:\n        # The function g(mu) = poisson.cdf(n_obs-1, mu) - (1-alpha/2) is monotonic.\n        # g(1e-9) is  0. A large enough upper bound ensures g(c) > 0.\n        try:\n            mu_L = brentq(lambda mu: poisson.cdf(n_obs - 1, mu) - (1.0 - alpha_2), 1e-9, upper_search_bound)\n        except ValueError:\n            # Should not be reached.\n            mu_L = 0.0\n            \n    s_L_raw = mu_L - b\n\n    # Enforce physical constraint s >= 0 by truncating the lower endpoint.\n    s_L = max(0.0, s_L_raw)\n    \n    return [s_L, s_U]\n\ndef calculate_coverage(s_true: float, b: float, alpha: float) - float:\n    \"\"\"\n    Computes the frequentist coverage for a given true signal s_true.\n    \n    Args:\n        s_true: The true value of the signal parameter.\n        b: The known background mean.\n        alpha: The significance level.\n        \n    Returns:\n        The coverage probability.\n    \"\"\"\n    mu_true = s_true + b\n    \n    # The sum is over all n, truncated at n_max where the tail is negligible.\n    if mu_true > 1e-9:\n        n_max = int(poisson.ppf(1.0 - 1e-16, mu=mu_true)) + 10\n    else:\n        # If mu_true is 0, only n=0 has non-zero probability.\n        n_max = 10\n\n    total_coverage = 0.0\n    for n_iter in range(n_max + 1):\n        s_L, s_U = get_interval(n_iter, b, alpha)\n        \n        # Check if s_true is inside the calculated interval [s_L, s_U].\n        if s_L = s_true = s_U:\n            total_coverage += poisson.pmf(n_iter, mu=mu_true)\n            \n    return total_coverage\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        # (b, alpha, n_obs, s_true)\n        (0.5, 0.10, 0, 0.0),\n        (1.0, 0.05, 1, 0.2),\n        (2.3, 0.05, 3, 0.0),\n        (0.0, 0.05, 5, 1.5),\n    ]\n\n    all_results = []\n    for b, alpha, n_obs, s_true in test_cases:\n        # Task 1: Construct the confidence interval for the given n_obs.\n        s_L, s_U = get_interval(n_obs, b, alpha)\n        \n        # Task 2: Compute the frequentist coverage and over-coverage for s_true.\n        coverage = calculate_coverage(s_true, b, alpha)\n        over_coverage = coverage - (1.0 - alpha)\n        \n        # Store results rounded to six decimal places.\n        all_results.append([s_L, s_U, over_coverage])\n\n    # Format the final output string exactly as specified.\n    results_str_parts = []\n    for res in all_results:\n        # Use a formatter to ensure 6 decimal places, including trailing zeros.\n        formatted_res = ','.join(f'{v:.6f}' for v in res)\n        results_str_parts.append(f'[{formatted_res}]')\n        \n    final_output = f\"[{','.join(results_str_parts)}]\"\n    print(final_output)\n\nsolve()\n\n```"
        },
        {
            "introduction": "经典的奈曼构造在处理物理边界附近的问题时，有时会产生非物理的结果（例如空区间）。作为高能物理领域的标准工具，费尔德曼-卡曾斯（Feldman-Cousins）方法通过引入基于似然比的排序原则，优雅地解决了这一难题。 这项动手实践要求你从零开始实现这一强大的方法，构建置信带（confidence belt），并理解它如何为设定置信区间提供一个统一且稳健的框架。",
            "id": "3509483",
            "problem": "考虑一个计数实验，其产生一个观测到的非负整数计数 $n$，该计数被建模为一个均值为 $\\mu = s + b$ 的泊松随机变量，其中 $s \\ge 0$ 是未知的非负信号率，$b$ 是一个已知的非负本底率。您需要使用通常称为 Feldman–Cousins 方法的似然比排序程序来构建置信区间。该方法需要：(i) 泊松概率质量函数 $P(n \\mid \\mu)$，(ii) 在 $s \\ge 0$ 约束下信号 $s$ 的最大似然估计，以及 (iii) 对于每个固定的 $s$，基于似然比的接受排序。使用 $0.9$ 的置信水平 (CL)（表示为小数 $0.9$）。本底是已知的，固定为 $b = 0.5$。\n\n从基本定义出发，不使用任何预先解出的快捷公式，实现以下内容：\n\n- 对于每个固定的 $s \\ge 0$，通过似然比 $R(n \\mid s) = \\dfrac{P(n \\mid s+b)}{P(n \\mid s_{\\text{best}}(n)+b)}$ 为所有可能的计数 $n \\in \\{0,1,2,\\dots\\}$ 定义一个排序，其中 $s_{\\text{best}}(n)$ 是在 $s \\ge 0$ 约束下使似然 $P(n \\mid s+b)$ 最大化的 $s$ 值。按照 $R(n \\mid s)$ 的降序将 $n$ 值纳入接受域，直到累积概率 $\\sum_{n \\in \\mathcal{A}(s)} P(n \\mid s+b)$ 首次达到或超过置信水平 $0.9$。这就为该 $s$ 得到了一个接受域 $\\mathcal{A}(s)$。\n- Feldman–Cousins 置信带是通过反转此构造过程获得的：对于给定的观测计数 $n_{\\text{obs}}$，$s$ 的 $0.9$ 置信区间是所有满足 $n_{\\text{obs}} \\in \\mathcal{A}(s)$ 的 $s \\ge 0$ 的集合。\n\n您的任务是计算上实现此置信带的构建，并使用已知的本底 $b = 0.5$ 报告三个观测计数：$n = 0$，$n = 3$ 和 $n = 7$ 的 $0.9$ 置信区间。\n\n要求和约束：\n\n- 仅使用泊松概率质量函数和在 $s \\ge 0$ 约束下的最大似然作为基础出发点。除了为确保概率质量的数值完备性而对 $s$ 进行系统数值离散化和对计数范围进行截断之外，避免引入任何特别的近似。\n- 通过为 $n$ 选择足够大的上界以及为 $s$ 选择足够宽和足够精细的网格来确保科学真实性，以精确地捕捉接受域。然后通过稳健的一维搜索来提炼区间端点，以达到数值精度。\n- 不涉及物理单位；所有值都是无量纲的计数或率。置信水平必须作为小数 $0.9$ 处理。\n- 设计一个包含以下观测计数的测试套件：\n    - $n = 0$（统计量极低的边界情况），\n    - $n = 3$（中等统计量），以及\n    - $n = 7$（较高统计量）。\n  该套件探究了不同的方面：近边界行为、典型的中等范围行为和较大计数行为。\n- 输出规范：您的程序应产生单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个元素是对应观测值 $n$ 的双元素列表 $[s_{\\text{low}}, s_{\\text{high}}]$，顺序为 $n = 0$、$n = 3$、$n = 7$。每个数值端点必须四舍五入到 $4$ 位小数。例如，输出格式必须如下所示：$[[s_{0,\\text{low}},s_{0,\\text{high}}],[s_{3,\\text{low}},s_{3,\\text{high}}],[s_{7,\\text{low}},s_{7,\\text{high}}]]$。\n\n您的实现必须是一个完整、可运行的程序，该程序在上述约束条件下根据第一性原理计算这些区间，并以指定的确切格式打印单行输出。",
            "solution": "该问题要求使用 Feldman-Cousins 方法为未知信号率 $s$ 构建置信区间。这是高能物理学中用于计数实验的标准程序，在这种实验中，给定一个已知的本底率 $b$，观测到的计数 $n$ 服从均值为 $\\mu = s+b$ 的泊松分布。\n\n### 1. 理论框架\n\n该方法的基础在于泊松概率质量函数 (PMF)、最大似然原理，以及用于构建接受域的特定似然比排序。\n\n**1.1. 统计模型**\n观测到 $n$ 个事件的概率由泊松 PMF 给出：\n$$ P(n \\mid \\mu) = \\frac{\\mu^n e^{-\\mu}}{n!} $$\n其中均值 $\\mu$ 是未知信号率 $s$ 和已知本底率 $b$ 的和，因此 $\\mu(s) = s+b$。信号率受到物理约束，为非负值，即 $s \\ge 0$。\n\n**1.2. 最大似然估计**\n对于给定的观测值 $n$，似然函数为 $L(s) = P(n \\mid s+b)$。为了找到最能解释数据的 $s$ 值，我们最大化此似然。等价且更简单的方法是最大化对数似然：\n$$ \\ln L(s) = n \\ln(s+b) - (s+b) - \\ln(n!) $$\n对 $s$ 求导并令结果为零可得：\n$$ \\frac{d}{ds} \\ln L(s) = \\frac{n}{s+b} - 1 = 0 \\implies \\hat{s} = n - b $$\n这是无约束的最大似然估计 (MLE)。然而，信号率 $s$ 必须是非负的。因此，有物理约束的 MLE（我们记为 $s_{\\text{best}}(n)$）是：\n$$ s_{\\text{best}}(n) = \\max(0, n-b) $$\n相应的最佳拟合均值参数是 $\\mu_{\\text{best}}(n) = s_{\\text{best}}(n) + b = \\max(n, b)$。\n\n**1.3. 似然比排序**\nFeldman-Cousins 方法使用似然比 $R(n \\mid s)$ 对给定假设的真实信号 $s$ 的可能观测值 $n$ 进行排序：\n$$ R(n \\mid s) = \\frac{P(n \\mid s+b)}{P(n \\mid s_{\\text{best}}(n)+b)} = \\frac{P(n \\mid \\mu(s))}{P(n \\mid \\mu_{\\text{best}}(n))} $$\n该比率比较了在给定真实信号 $s$ 的情况下观测到 $n$ 的似然，与在任何有效的物理假设下该 $n$ 的最大可能似然。较高的 $R$ 值表示观测值 $n$ 与假设的 $s$ 更为一致。\n\n### 2. 接受域和置信区的构建\n\n**2.1. 接受域**\n对于真实信号 $s$ 的每个固定值，都会构建一个接受域 $\\mathcal{A}(s)$。该区域是一组可观测计数 $n$ 的集合，这些计数被认为与该 $s$ 一致。构建过程如下：\n1.  对于给定的 $s$，计算所有可能的整数计数 $n=0, 1, 2, \\dots$ 的排序值 $R(n \\mid s)$。\n2.  按照其排序值 $R(n \\mid s)$ 的降序将计数 $n$ 添加到接受域 $\\mathcal{A}(s)$ 中。\n3.  继续添加计数，直到累积概率首次达到或超过指定的置信水平 (CL)。\n$$ \\sum_{n \\in \\mathcal{A}(s)} P(n \\mid s+b) \\ge \\text{CL} $$\n问题指定了 $0.9$ 的 CL 和 $b=0.5$ 的本底。\n\n**2.2. 通过反演构建置信区间**\n对于给定的实际观测值 $n_{\\text{obs}}$，$s$ 的置信区间是通过“反演”接受域集合来找到的。该区间包含所有使得观测计数 $n_{\\text{obs}}$ 落入其相应接受域的 $s$ 值：\n$$ [s_{\\text{low}}, s_{\\text{high}}] = \\{ s \\ge 0 \\mid n_{\\text{obs}} \\in \\mathcal{A}(s) \\} $$\n\n### 3. 计算策略\n\n区间边界 $[s_{\\text{low}}, s_{\\text{high}}]$ 是指 $n_{\\text{obs}}$ 恰好处于被包含在接受域 $\\mathcal{A}(s)$ 内或被排除在外的临界点上的特定 $s$ 值。这种情况发生在所有排序严格高于 $n_{\\text{obs}}$ 的结果 $n'$ 的概率之和等于置信水平时。这个条件定义了区间的边界。我们可以定义一个函数，其根对应于这些边界：\n$$ f(s; n_{\\text{obs}}) = \\left( \\sum_{n' \\text{ s.t. } R(n'|s)  R(n_{\\text{obs}}|s)} P(n'|s+b) \\right) - \\text{CL} = 0 $$\n解决方案涉及实现一个数值程序，为每个给定的 $n_{\\text{obs}} \\in \\{0, 3, 7\\}$ 找到此方程的根。\n\n-   **数值评估：** 该求和在一个足够大的整数计数范围（例如，$n' \\in [0, 100]$）上计算，以确保被截断的概率可以忽略不计。为了数值稳定性，似然比 $R$ 使用对数似然计算：\n    $$ \\ln R(n \\mid s) = n \\left(\\ln(s+b) - \\ln(\\max(n,b))\\right) - (s- \\max(0, n-b)) $$\n-   **求根：** 采用稳健的一维求根算法（例如 Brent 方法）来求解 $f(s; n_{\\text{obs}}) = 0$ 以得到 $s$。\n    -   对于 $n_{\\text{obs}}  b$，函数 $f(s)$ 在 $s$ 非常小和非常大时通常为正，在中间为负。因此它有两个根，即 $s_{\\text{low}}$ 和 $s_{\\text{high}}$。对这些根的搜索在 $f(s)$ 最小的点 $s \\approx n_{\\text{obs}} - b$ 附近分开进行。\n    -   对于 $n_{\\text{obs}}=0$ 的特殊情况，可以证明 $s_{\\text{low}}=0$。函数 $f(s; 0)$ 在 $s \\ge 0$ 时是单调的，并且只有一个根，该根对应于 $s_{\\text{high}}$。\n-   **实现：** 该算法使用 Python 实现，利用 `numpy` 库进行数值运算，利用 `scipy` 库实现其泊松 PMF 和 `brentq` 求根函数。最终的区间端点按要求四舍五入到四位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import poisson\nfrom scipy.optimize import brentq\nimport sys\n\n# Suppress potential RuntimeWarning from log(0) in edge cases, which are handled.\nnp.seterr(divide='ignore', invalid='ignore')\n\ndef solve():\n    \"\"\"\n    Computes Feldman-Cousins confidence intervals for a Poisson signal\n    with known background.\n    \"\"\"\n    \n    # Problem definition\n    B = 0.5  # Known background rate\n    CL = 0.9 # Confidence Level\n    OBSERVED_COUNTS = [0, 3, 7] # Test cases for n_obs\n\n    # Numerical parameters\n    N_MAX = 100 # Range of n to sum over, must be large enough\n    \n    def get_boundary_function(n_obs: int, b: float, cl: float, n_max: int):\n        \"\"\"\n        Returns a function f(s) whose roots are the confidence interval boundaries.\n        f(s) = (sum of P(n') for n' with rank > rank of n_obs) - CL\n        \"\"\"\n\n        def boundary_func(s: float) -> float:\n            \"\"\"\n            The function to find roots of.\n            s: The hypothesized signal strength.\n            \"\"\"\n            # Physical constraint s >= 0. Root finder is bounded to this.\n            if s  0:\n                return 1.0  # Return a large positive value to constrain search\n            \n            mu_true = s + b\n\n            # Calculate log of the rank for the observed count n_obs\n            # ln(R) = n*ln(mu_true/mu_best) - (mu_true-mu_best)\n            mu_best_obs = max(n_obs, b)\n            \n            # Use logs for numerical stability. Handle s=0 where mu_true = b.\n            if np.isclose(mu_true, mu_best_obs):\n                log_R_obs = 0.0\n            else:\n                log_R_obs = n_obs * (np.log(mu_true) - np.log(mu_best_obs)) - (mu_true - mu_best_obs)\n\n            prob_sum_greater = 0.0\n            \n            # Sum probabilities for all n' with a higher rank than n_obs\n            for n_prime in range(n_max + 1):\n                if n_prime == n_obs:\n                    continue\n\n                mu_best_n_prime = max(n_prime, b)\n                \n                if np.isclose(mu_true, mu_best_n_prime):\n                    log_R_n_prime = 0.0\n                else:\n                    log_R_n_prime = n_prime * (np.log(mu_true) - np.log(mu_best_n_prime)) - (mu_true - mu_best_n_prime)\n\n                # Add probability if rank is strictly greater.\n                # A small tolerance helps with floating point comparisons.\n                if log_R_n_prime > log_R_obs + 1e-12:\n                    prob_sum_greater += poisson.pmf(n_prime, mu_true)\n\n            return prob_sum_greater - cl\n\n        return boundary_func\n\n    results = []\n    for n_obs in OBSERVED_COUNTS:\n        boundary_func = get_boundary_function(n_obs, B, CL, N_MAX)\n        s_low, s_high = 0.0, 0.0\n\n        if n_obs == 0:\n            # For n_obs=0, the lower bound is always s_low=0.\n            # The boundary function is monotonic, so there's one root for s_high.\n            s_low = 0.0\n            try:\n                s_high = brentq(boundary_func, 0, 15)\n            except ValueError:\n                # Should not happen for this well-posed problem\n                s_high = np.nan\n        else: # For n_obs > 0\n            # The boundary function typically has two roots (for s_low and s_high)\n            # which we find by splitting the search domain around the minimum.\n            # The minimum occurs approximately where s_best = n_obs - b.\n            s_peak_approx = max(1e-5, n_obs - B)\n\n            # --- Find s_low ---\n            # Check if s=0 is included in the interval. If f(0)0, it is.\n            if boundary_func(1e-9)  0:\n                s_low = 0.0\n            else:\n                # Search for the root between 0 and the peak approximation\n                try:\n                    s_low = brentq(boundary_func, 1e-9, s_peak_approx)\n                except ValueError:\n                    s_low = np.nan\n            \n            # --- Find s_high ---\n            # Search for the root from the peak approximation upwards\n            try:\n                # A sufficiently large upper bracket for the search\n                s_high = brentq(boundary_func, s_peak_approx, n_obs + 40)\n            except ValueError:\n                s_high = np.nan\n\n        results.append([round(s_low, 4), round(s_high, 4)])\n\n    # Format the output exactly as specified\n    output_str = \"[\"\n    for i, res in enumerate(results):\n        output_str += f\"[{res[0]:.4f},{res[1]:.4f}]\"\n        if i  len(results) - 1:\n            output_str += \",\"\n    output_str += \"]\"\n        \n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "现代物理分析很少只涉及单个计数，而是综合多个分析通道（bins）的信息，并且必须考虑系统不确定性的影响。这项实践让你接触一个更真实的分析场景，引入了包含讨厌参数（nuisance parameters）的多箱拟合（multi-bin fit）来模拟这些不确定性。 你将学习如何计算轮廓似然比检验统计量 $q_\\mu$，这是在复杂模型中设定置信上限的核心。",
            "id": "3509408",
            "problem": "考虑一个划分为多个分析区间的计数实验，其中观测到的计数被建模为独立的泊松随机变量。设有 $N_{\\mathrm{bins}}$ 个区间，由 $i \\in \\{1,\\dots,N_{\\mathrm{bins}}\\}$ 索引。对于每个区间 $i$，令 $n_i$ 表示观测到的计数，$s_i$ 表示单位信号强度下的标称信号模板产额，$b_i$ 表示标称本底模板产额。感兴趣的参数是非负信号强度 $\\mu \\ge 0$。通过高斯约束的讨厌参数引入了两种系统效应：全局信号效率讨厌参数 $\\theta_s$ 和全局本底归一化讨厌参数 $\\theta_b$，每个都由标准正态分布约束。为了在存在乘性系统效应时确保正定性和数值稳定性，采用对数正态形变，其中信号的分数尺度为 $k_s$，本底的分数尺度为 $k_b$。具体来说，定义区间 $i$ 中的预期产额为\n$$\n\\lambda_i(\\mu,\\theta_s,\\theta_b) = \\mu\\, s_i \\,\\exp(k_s \\theta_s) + b_i\\, \\exp(k_b \\theta_b).\n$$\n假设独立的泊松计数和对讨厌参数的独立高斯约束，完整的似然函数（在似然比中会抵消的、与区间无关的泊松常数除外）为\n$$\nL(\\mu,\\theta_s,\\theta_b) \\propto \\left[\\prod_{i=1}^{N_{\\mathrm{bins}}} \\mathrm{Pois}\\big(n_i \\mid \\lambda_i(\\mu,\\theta_s,\\theta_b)\\big)\\right] \\times \\exp\\!\\left(-\\frac{\\theta_s^2}{2}\\right) \\times \\exp\\!\\left(-\\frac{\\theta_b^2}{2}\\right),\n$$\n其对数似然函数（舍去与 $(\\mu,\\theta_s,\\theta_b)$ 无关的加性常数）为\n$$\n\\ell(\\mu,\\theta_s,\\theta_b) = \\sum_{i=1}^{N_{\\mathrm{bins}}} \\big[n_i \\ln \\lambda_i(\\mu,\\theta_s,\\theta_b) - \\lambda_i(\\mu,\\theta_s,\\theta_b)\\big] - \\frac{1}{2}\\big(\\theta_s^2 + \\theta_b^2\\big).\n$$\n定义剖面似然比\n$$\n\\lambda(\\mu) = \\frac{\\max_{\\theta_s,\\theta_b}\\, L(\\mu,\\theta_s,\\theta_b)}{\\max_{\\mu \\ge 0,\\ \\theta_s,\\theta_b} \\, L(\\mu,\\theta_s,\\theta_b)},\n$$\n以及用于计算上限的单边检验统计量\n$$\nq_\\mu = \n\\begin{cases}\n-2 \\ln \\lambda(\\mu),  \\hat{\\mu} \\le \\mu,\\\\\n0,  \\hat{\\mu}  \\mu,\n\\end{cases}\n$$\n其中 $(\\hat{\\mu},\\hat{\\theta}_s,\\hat{\\theta}_b)$ 是在约束 $\\mu \\ge 0$ 下使 $L(\\mu,\\theta_s,\\theta_b)$ 最大化的无条件最大似然估计量，而 $(\\hat{\\theta}_s(\\mu),\\hat{\\theta}_b(\\mu))$ 是在固定 $\\mu$ 时，使 $L(\\mu,\\theta_s,\\theta_b)$ 关于 $(\\theta_s,\\theta_b)$ 最大化的剖面讨厌参数估计量。\n\n您的任务是基于上述模型，为几个指定的伪数据集实现 $q_\\mu$ 的完整数值计算。该计算必须：\n- 使用给定的 $n_i$、$s_i$、$b_i$、$k_s$ 和 $k_b$ 构建 $\\ell(\\mu,\\theta_s,\\theta_b)$。\n- 执行约束数值优化以获得 $(\\hat{\\mu},\\hat{\\theta}_s,\\hat{\\theta}_b)$ 和 $(\\hat{\\theta}_s(\\mu),\\hat{\\theta}_b(\\mu))$。\n- 根据上述单边定义评估 $q_\\mu$。\n- 在数值稳定性和优化初始化方面具有鲁棒性，并包含合理的边界以防止上溢，同时保持物理真实性。\n\n使用以下分数尺度进行对数正态形变：$k_s = \\ln(1 + 0.10)$ 和 $k_b = \\ln(1 + 0.20)$，分别代表 $10\\%$ 和 $20\\%$ 的一倍标准差分数不确定度。\n\n实现您的程序以处理以下测试套件，每个案例由 $(\\{s_i\\},\\{b_i\\},\\{n_i\\},\\mu)$ 组成：\n\n- 案例 A（通用多区间拟合，中等计数）：\n  - $N_{\\mathrm{bins}} = 4$\n  - $s = [\\,5.0,\\,9.0,\\,4.0,\\,2.0\\,]$\n  - $b = [\\,20.0,\\,15.0,\\,10.0,\\,5.0\\,]$\n  - $n = [\\,27,\\,25,\\,15,\\,8\\,]$\n  - $\\mu = 1.0$\n\n- 案例 B（全局最大值可能偏向 $\\hat{\\mu} = 0$ 的边界行为）：\n  - $N_{\\mathrm{bins}} = 4$\n  - $s = [\\,8.0,\\,12.0,\\,5.0,\\,1.0\\,]$\n  - $b = [\\,18.0,\\,14.0,\\,11.0,\\,6.0\\,]$\n  - $n = [\\,13,\\,10,\\,7,\\,4\\,]$\n  - $\\mu = 1.0$\n\n- 案例 C（低计数和零计数，测试数值稳定性）：\n  - $N_{\\mathrm{bins}} = 4$\n  - $s = [\\,0.5,\\,1.0,\\,0.2,\\,0.1\\,]$\n  - $b = [\\,0.2,\\,0.5,\\,0.2,\\,0.05\\,]$\n  - $n = [\\,0,\\,1,\\,0,\\,2\\,]$\n  - $\\mu = 0.5$\n\n您的程序应计算每个案例的 $q_\\mu$，并生成一行输出，其中包含用方括号括起来的逗号分隔结果列表（例如 `\"[q_{\\mu,A},q_{\\mu,B},q_{\\mu,C}]\"`）。所有输出必须是浮点数。不涉及物理单位，任何可能出现的角度都必须解释为无量纲实数。程序必须完全自包含，不需要用户输入，并遵守指定的执行环境。",
            "solution": "该问题陈述已经过验证，被认为是高能物理领域中计算统计学应用的一个定义明确、有科学依据的任务。它是自包含的、客观的，并且没有矛盾或含糊之处。\n\n目标是为给定的信号强度假设 $\\mu$ 计算单边检验统计量 $q_\\mu$。该检验统计量由剖面似然比 $\\lambda(\\mu)$ 定义：\n$$\nq_\\mu = \n\\begin{cases}\n-2 \\ln \\lambda(\\mu),  \\hat{\\mu} \\le \\mu,\\\\\n0,  \\hat{\\mu}  \\mu.\n\\end{cases}\n$$\n剖面似然比由下式给出\n$$\n\\lambda(\\mu) = \\frac{\\max_{\\theta_s,\\theta_b}\\, L(\\mu,\\theta_s,\\theta_b)}{\\max_{\\mu' \\ge 0,\\ \\theta_s,\\theta_b} \\, L(\\mu',\\theta_s,\\theta_b)}.\n$$\n这里，$L(\\mu,\\theta_s,\\theta_b)$ 是似然函数，$(\\hat{\\mu}, \\hat{\\theta}_s, \\hat{\\theta}_b)$ 是在约束 $\\mu \\ge 0$ 下全局最大化 $L$ 的最大似然估计量 (MLE)。\n\n代入对数似然 $\\ell = \\ln L$ 的定义，检验统计量可以写成：\n$$\nq_\\mu = -2 \\left[ \\ell(\\mu, \\hat{\\theta}_s(\\mu), \\hat{\\theta}_b(\\mu)) - \\ell(\\hat{\\mu}, \\hat{\\theta}_s, \\hat{\\theta}_b) \\right], \\quad \\text{for } \\hat{\\mu} \\le \\mu,\n$$\n其中 $(\\hat{\\theta}_s(\\mu), \\hat{\\theta}_b(\\mu))$ 是在固定值 $\\mu$ 下使似然函数最大化的讨厌参数 $(\\theta_s, \\theta_b)$ 的估计量。\n\n对于数值计算，标准做法是执行负对数似然（NLL）的最小化，记为 $f = -\\ell$。NLL 函数为：\n$$\nf(\\mu, \\theta_s, \\theta_b) = -\\ell(\\mu, \\theta_s, \\theta_b) = \\sum_{i=1}^{N_{\\mathrm{bins}}} \\left[ \\lambda_i(\\mu,\\theta_s,\\theta_b) - n_i \\ln \\lambda_i(\\mu,\\theta_s,\\theta_b) \\right] + \\frac{1}{2}(\\theta_s^2 + \\theta_b^2),\n$$\n其中 $\\lambda_i(\\mu,\\theta_s,\\theta_b) = \\mu\\, s_i \\,\\exp(k_s \\theta_s) + b_i\\, \\exp(k_b \\theta_b)$。当 $n_i=0$ 时，项 $n_i \\ln \\lambda_i$ 取为 $0$，这在实现中得到了稳健的处理。\n\n用 NLL 表示，检验统计量变为：\n$$\nq_\\mu = 2 \\left[ f_{\\text{cond}}(\\mu) - f_{\\text{global}} \\right], \\quad \\text{for } \\hat{\\mu} \\le \\mu,\n$$\n其中 $f_{\\text{cond}}(\\mu)$ 是在固定 $\\mu$ 时 NLL 的最小值，而 $f_{\\text{global}}$ 是 NLL 的全局最小值。\n\n因此，$q_\\mu$ 的计算涉及两个不同的数值优化步骤：\n$1$. **无条件（全局）最小化：** 我们通过最小化 $f(\\mu, \\theta_s, \\theta_b)$ 关于所有三个参数 $(\\mu, \\theta_s, \\theta_b)$（受物理约束 $\\mu \\ge 0$）来找到 NLL 函数的全局最小值 $f_{\\text{global}}$。此最小值处的 $\\mu$ 值即为 MLE $\\hat{\\mu}$。\n$$\nf_{\\text{global}} = \\min_{\\mu \\ge 0, \\, \\theta_s, \\, \\theta_b} f(\\mu, \\theta_s, \\theta_b)\n$$\n这将得到 $f_{\\text{global}}$ 和 $\\hat{\\mu}$。\n\n$2$. **条件（剖面）最小化：** 对于正在检验的特定值 $\\mu$，我们通过仅对讨厌参数 $(\\theta_s, \\theta_b)$ 最小化 $f(\\mu, \\theta_s, \\theta_b)$ 来找到 NLL 的条件最小值 $f_{\\text{cond}}(\\mu)$。\n$$\nf_{\\text{cond}}(\\mu) = \\min_{\\theta_s, \\, \\theta_b} f(\\mu, \\theta_s, \\theta_b)\n$$\n\n最后，我们组装检验统计量。首先，我们将全局拟合的 $\\hat{\\mu}$ 与检验值 $\\mu$ 进行比较。如果 $\\hat{\\mu}  \\mu$，则数据偏向于一个比被检验的信号强度更大的值，因此根据定义，$q_\\mu=0$。否则，如果 $\\hat{\\mu} \\le \\mu$，则该值计算为 $q_\\mu = 2(f_{\\text{cond}}(\\mu) - f_{\\text{global}})$。我们确保结果为非负，以处理真实值为零时可能出现的微小浮点不精确性。\n\n这些最小化是使用 `scipy.optimize.minimize` 函数和 `L-BFGS-B` 算法执行的，该算法非常适合带边界约束的拟牛顿优化。对讨厌参数 $\\theta_s$ 和 $\\theta_b$ 施加了合理的边界，如 $[-5, 5]$，以提高数值稳定性，这反映了它们不太可能偏离中心值 $0$ 超过 $5$ 个标准差的预期。\n常数 $k_s$ 和 $k_b$ 按规定设置为 $k_s = \\ln(1 + 0.10)$ 和 $k_b = \\ln(1 + 0.20)$。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Computes the q_mu test statistic for several counting experiments.\n    \"\"\"\n\n    # Define fractional scales for systematics from the problem statement.\n    # k_s corresponds to a 10% uncertainty, k_b to a 20% uncertainty.\n    k_s = np.log(1.0 + 0.10)\n    k_b = np.log(1.0 + 0.20)\n\n    # Test cases as defined in the problem.\n    # Each case is a tuple: (s_i, b_i, n_i, mu_test)\n    test_cases = [\n        # Case A\n        (\n            np.array([5.0, 9.0, 4.0, 2.0]),\n            np.array([20.0, 15.0, 10.0, 5.0]),\n            np.array([27, 25, 15, 8]),\n            1.0\n        ),\n        # Case B\n        (\n            np.array([8.0, 12.0, 5.0, 1.0]),\n            np.array([18.0, 14.0, 11.0, 6.0]),\n            np.array([13, 10, 7, 4]),\n            1.0\n        ),\n        # Case C\n        (\n            np.array([0.5, 1.0, 0.2, 0.1]),\n            np.array([0.2, 0.5, 0.2, 0.05]),\n            np.array([0, 1, 0, 2]),\n            0.5\n        )\n    ]\n\n    def neg_log_likelihood(params, s, b, n, ks, kb):\n        \"\"\"\n        Calculates the negative log-likelihood.\n        This function is the core objective function for minimization.\n        \n        params: Tuple or array of parameters (mu, theta_s, theta_b).\n        s, b, n: Signal, background, and observed counts arrays.\n        ks, kb: Log-normal morphing scales for systematics.\n        \"\"\"\n        mu, theta_s, theta_b = params\n\n        # Calculate expected yields per bin\n        # The model ensures lambda_i > 0 for mu >= 0 and b_i >= 0\n        lambda_i = mu * s * np.exp(ks * theta_s) + b * np.exp(kb * theta_b)\n        \n        # Guard against non-positive lambda_i which can occur during optimization steps\n        # If any lambda_i is non-positive where n_i is positive, log-likelihood is -inf, NLL is +inf.\n        if np.any(lambda_i = 0):\n             if np.any(n[lambda_i = 0] > 0):\n                 return np.inf\n\n        # Calculate Poisson part of NLL: sum(lambda_i - n_i * log(lambda_i))\n        # This implementation is numerically stable for n_i = 0 cases.\n        log_lambda_terms = np.where(n > 0, n * np.log(lambda_i), 0.)\n        poisson_nll = np.sum(lambda_i - log_lambda_terms)\n\n        # Add Gaussian constraint terms for nuisance parameters\n        constraints_nll = 0.5 * (theta_s**2 + theta_b**2)\n\n        return poisson_nll + constraints_nll\n    \n    def calculate_q_mu(s, b, n, mu_test, ks, kb):\n        \"\"\"\n        Performs the full calculation of q_mu for a single case.\n        \"\"\"\n        # --- 1. Unconditional (Global) Minimization ---\n        # Objective function for global fit, taking a single parameter vector.\n        def objective_global(p):\n            return neg_log_likelihood(p, s, b, n, ks, kb)\n\n        # Initial guess and bounds for [mu, theta_s, theta_b]\n        # Bounds on thetas are for stability; mu>=0 is a physical constraint.\n        x0_global = [1.0, 0.0, 0.0]\n        bounds_global = [(0, None), (-5, 5), (-5, 5)]\n\n        res_global = minimize(\n            objective_global,\n            x0=x0_global,\n            method='L-BFGS-B',\n            bounds=bounds_global\n        )\n        \n        nll_global = res_global.fun\n        mu_hat = res_global.x[0]\n\n        # --- 2. Conditional (Profiled) Minimization ---\n        # Objective function for conditional fit at fixed mu_test.\n        def objective_conditional(p):\n            # p is [theta_s, theta_b]\n            params = (mu_test, p[0], p[1])\n            return neg_log_likelihood(params, s, b, n, ks, kb)\n\n        # Initial guess and bounds for [theta_s, theta_b]\n        x0_cond = [0.0, 0.0]\n        bounds_cond = [(-5, 5), (-5, 5)]\n\n        res_cond = minimize(\n            objective_conditional,\n            x0=x0_cond,\n            method='L-BFGS-B',\n            bounds=bounds_cond\n        )\n        \n        nll_conditional = res_cond.fun\n\n        # --- 3. Compute q_mu ---\n        if mu_hat > mu_test:\n            q_mu = 0.0\n        else:\n            # Ensure q_mu >= 0 to handle potential floating-point inaccuracies\n            q_mu = max(0.0, 2 * (nll_conditional - nll_global))\n        \n        return q_mu\n\n    results = []\n    for case in test_cases:\n        s_case, b_case, n_case, mu_test_case = case\n        q_mu_val = calculate_q_mu(s_case, b_case, n_case, mu_test_case, k_s, k_b)\n        results.append(q_mu_val)\n\n    # Format and print the final output as a single line.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}