{
    "hands_on_practices": [
        {
            "introduction": "A numerical method's power is fundamentally linked to its order of accuracy, which quantifies how closely it approximates the true solution. This practice delves into the theoretical heart of Runge-Kutta methods by tasking you with deriving the \"order conditions\" from first principles. By matching the method's algebraic expansion to the Taylor series of the exact solution, you will construct the entire family of second-order, two-stage explicit methods, providing a deep understanding of what makes a method accurate .",
            "id": "3537359",
            "problem": "In computational high-energy physics, many dynamical quantities are evolved by integrating ordinary differential equations, such as the renormalization group flow of a coupling under a logarithmic energy-scale variable. Consider an autonomous scalar flow $g(s)$ governed by\n$$\n\\frac{dg}{ds} = \\beta(g),\n$$\nwhere $s = \\ln(\\mu/\\mu_{0})$, $\\mu$ is the energy scale, and $\\beta$ is a sufficiently smooth beta function. To integrate from $s$ to $s+h$ numerically, construct a two-stage explicit Runge–Kutta (RK) method with a single free stage abscissa parameter $c_{2}$:\n$$\nk_{1} = \\beta\\!\\big(g(s)\\big), \\quad k_{2} = \\beta\\!\\big(g(s) + h\\,a_{21}\\,k_{1}\\big),\n$$\nand the update\n$$\ng(s+h) \\approx g(s) + h\\big(b_{1}\\,k_{1} + b_{2}\\,k_{2}\\big).\n$$\nImpose the second-order accuracy requirement by matching the method’s one-step expansion to the Taylor expansion of the exact solution through terms of order $h^{2}$, starting only from the core definitions of the derivative, the chain rule, and Taylor’s theorem. Solve the resulting order conditions to obtain a family of second-order explicit RK schemes parameterized by $c_{2}$, and derive analytical expressions for $(a_{21}, b_{1}, b_{2})$ in terms of $c_{2}$. State any necessary constraint on $c_{2}$ that ensures the coefficients are well-defined. Express your final answer as a single closed-form analytical expression for the triple $(a_{21}, b_{1}, b_{2})$. No rounding is required and no units should be included in the final expression.",
            "solution": "The problem requires the derivation of the coefficients for a general two-stage explicit Runge-Kutta (RK) method that achieves second-order accuracy for an autonomous ordinary differential equation (ODE) of the form $\\frac{dg}{ds} = \\beta(g)$. The derivation must proceed from first principles by matching the method's one-step expansion to the Taylor series of the exact solution.\n\nFirst, we establish the Taylor series expansion for the exact solution $g(s+h)$ around the point $s$. The expansion up to terms of order $h^2$ is given by\n$$\ng(s+h) = g(s) + h \\frac{dg}{ds} \\bigg|_s + \\frac{h^2}{2!} \\frac{d^2g}{ds^2} \\bigg|_s + O(h^3).\n$$\nWe use the given ODE, $\\frac{dg}{ds} = \\beta(g)$, to express the derivatives of $g$ in terms of the function $\\beta$ and its derivatives with respect to $g$. Let's denote $g(s)$ as $g_s$ for conciseness.\nThe first derivative is\n$$\n\\frac{dg}{ds} \\bigg|_s = \\beta(g_s).\n$$\nThe second derivative is found using the chain rule:\n$$\n\\frac{d^2g}{ds^2} \\bigg|_s = \\frac{d}{ds} \\left( \\beta(g(s)) \\right) \\bigg|_s = \\frac{d\\beta}{dg} \\bigg|_{g_s} \\frac{dg}{ds} \\bigg|_s = \\beta'(g_s) \\beta(g_s).\n$$\nHere, $\\beta'(g_s)$ denotes the derivative of $\\beta$ with respect to its argument $g$, evaluated at $g_s$. Substituting these derivatives into the Taylor expansion yields the exact solution's expansion:\n$$\ng(s+h) = g_s + h \\beta(g_s) + \\frac{h^2}{2} \\beta'(g_s) \\beta(g_s) + O(h^3).\n$$\n\nNext, we expand the numerical approximation provided by the specified two-stage RK method. The method is defined by the stages\n$$\nk_{1} = \\beta(g_s),\n$$\n$$\nk_{2} = \\beta(g_s + h a_{21} k_{1}),\n$$\nand the update rule\n$$\ng_{s+h} \\approx g_s + h(b_{1} k_{1} + b_{2} k_{2}).\n$$\nTo analyze the accuracy, we expand $k_{2}$ using a Taylor series in the variable $h$ around $h=0$. The argument of $\\beta$ in $k_2$ is $g_s + h a_{21} \\beta(g_s)$.\n$$\nk_2 = \\beta(g_s) + \\big(h a_{21} \\beta(g_s)\\big) \\beta'(g_s) + \\frac{1}{2!} \\big(h a_{21} \\beta(g_s)\\big)^2 \\beta''(g_s) + \\dots\n$$\nTruncating to the same order as the exact solution's expansion, we only need terms up to $O(h)$:\n$$\nk_2 = \\beta(g_s) + h a_{21} \\beta(g_s) \\beta'(g_s) + O(h^2).\n$$\nNow, we substitute the expressions for $k_1$ and the expansion of $k_2$ into the update rule:\n$$\ng_{s+h} \\approx g_s + h \\left( b_1 \\beta(g_s) + b_2 \\left[ \\beta(g_s) + h a_{21} \\beta(g_s) \\beta'(g_s) + O(h^2) \\right] \\right).\n$$\nDistributing the terms, we get the expansion for the numerical method:\n$$\ng_{s+h} \\approx g_s + h (b_1 + b_2) \\beta(g_s) + h^2 (b_2 a_{21}) \\beta(g_s) \\beta'(g_s) + O(h^3).\n$$\n\nFor the method to be second-order accurate, this expansion must match the exact Taylor expansion of $g(s+h)$ through terms of order $h^2$. By comparing the coefficients of the terms involving $\\beta(g_s)$ and $\\beta(g_s)\\beta'(g_s)$, we derive the order conditions.\nComparing the terms of order $h^1$:\n$$\n(b_1 + b_2) \\beta(g_s) = 1 \\cdot \\beta(g_s) \\implies b_1 + b_2 = 1.\n$$\nThis is the first order condition.\nComparing the terms of order $h^2$:\n$$\n(b_2 a_{21}) \\beta(g_s) \\beta'(g_s) = \\frac{1}{2} \\beta(g_s) \\beta'(g_s) \\implies b_2 a_{21} = \\frac{1}{2}.\n$$\nThis is the second order condition.\n\nThe problem specifies that the method has a single free stage abscissa parameter $c_2$. In the standard formulation of Runge-Kutta methods, the stage abscissae $c_i$ are related to the coefficients $a_{ij}$ by the relation $c_i = \\sum_{j=1}^{i-1} a_{ij}$. For a two-stage method, this gives $c_2 = a_{21}$. We use this standard definition to express the coefficients in terms of $c_2$.\nThe system of order conditions becomes:\n1. $b_1 + b_2 = 1$\n2. $b_2 c_2 = \\frac{1}{2}$\n3. $a_{21} = c_2$\n\nWe solve this system for $(a_{21}, b_1, b_2)$ in terms of $c_2$.\nFrom the second equation, we can express $b_2$:\n$$\nb_2 = \\frac{1}{2c_2}.\n$$\nThis expression immediately reveals a necessary constraint on the parameter $c_2$: for the coefficient $b_2$ to be well-defined, we must have $c_2 \\neq 0$.\n\nSubstituting this expression for $b_2$ into the first equation, we solve for $b_1$:\n$$\nb_1 = 1 - b_2 = 1 - \\frac{1}{2c_2}.\n$$\nThe coefficient $a_{21}$ is simply equal to $c_2$.\nThus, the family of second-order explicit two-stage Runge-Kutta methods, parameterized by $c_2$, is defined by the coefficients:\n$$\na_{21} = c_2\n$$\n$$\nb_1 = 1 - \\frac{1}{2c_2}\n$$\n$$\nb_2 = \\frac{1}{2c_2}\n$$\nThe constraint for these coefficients to be well-defined is $c_2 \\neq 0$. The problem asks for the triple $(a_{21}, b_1, b_2)$ as a single closed-form analytical expression.\n\nThe solution is the ordered triple:\n$$\n(a_{21}, b_{1}, b_{2}) = \\left( c_2, 1 - \\frac{1}{2c_2}, \\frac{1}{2c_2} \\right).\n$$\nThis provides a complete family of solutions, from which well-known methods such as the midpoint method ($c_2 = 1/2$) and Heun's method ($c_2 = 1$) can be recovered.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} c_{2}  1 - \\frac{1}{2c_{2}}  \\frac{1}{2c_{2}} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Beyond accuracy, numerical stability is paramount, especially when simulating systems with vastly different time scales, a common feature in high-energy physics. This exercise introduces the concept of absolute stability by analyzing how a method behaves on the standard test equation $y' = \\lambda y$. You will derive the stability function $R(z)$ for the classical fourth-order Runge-Kutta method (RK4), a polynomial that completely characterizes the method's stability and is essential for predicting its performance on stiff or oscillatory problems .",
            "id": "3537385",
            "problem": "In computational high-energy physics simulations, semi-discrete evolution equations for linearized fluctuations around a background often reduce mode-by-mode to the scalar test ordinary differential equation (ODE) $y^{\\prime}(t)=\\lambda\\,y(t)$, where $\\lambda\\in\\mathbb{C}$ arises from dispersion and damping after spatial discretization of a relativistic field equation. Consider advancing this ODE over one time step of size $h>0$ using the classical $4$-stage explicit Runge–Kutta (RK) method defined by the stage system\n$$\n\\begin{aligned}\nk_{1}=f(t_{n},y_{n}),\\\\\nk_{2}=f\\!\\left(t_{n}+\\tfrac{h}{2},\\,y_{n}+\\tfrac{h}{2}k_{1}\\right),\\\\\nk_{3}=f\\!\\left(t_{n}+\\tfrac{h}{2},\\,y_{n}+\\tfrac{h}{2}k_{2}\\right),\\\\\nk_{4}=f\\!\\left(t_{n}+h,\\,y_{n}+h\\,k_{3}\\right),\n\\end{aligned}\n$$\nwith the update\n$$\ny_{n+1}=y_{n}+\\tfrac{h}{6}\\left(k_{1}+2\\,k_{2}+2\\,k_{3}+k_{4}\\right).\n$$\nHere $f(t,y)=\\lambda\\,y$. The absolute stability function $R(z)$ of a one-step method is defined by the scalar relation $y_{n+1}=R(z)\\,y_{n}$ when the method is applied to $y^{\\prime}=\\lambda\\,y$ with $z=\\lambda\\,h$. Starting only from these definitions and using algebraic manipulation of the stages, derive $R(z)$ as a closed-form polynomial in $z$. Provide your final answer as the exact expression for $R(z)$. No rounding is required, and no units are to be reported.",
            "solution": "The objective is to derive the absolute stability function, $R(z)$, for the classical $4$-stage Runge-Kutta (RK4) method when applied to the scalar test equation $y^{\\prime}(t) = \\lambda y(t)$. The stability function is defined by the relation $y_{n+1} = R(z) y_n$, where $z = \\lambda h$.\n\nThe function for the right-hand side of the ODE is $f(t,y) = \\lambda y$. Since $f$ is independent of $t$, we can write $f(y) = \\lambda y$. We systematically compute the stages $k_i$.\n\nStep 1: Compute the first stage, $k_1$.\n$$\nk_1 = f(t_n, y_n) = \\lambda y_n\n$$\n\nStep 2: Compute the second stage, $k_2$, using the result for $k_1$.\n$$\nk_2 = f\\left(t_n + \\frac{h}{2}, y_n + \\frac{h}{2}k_1\\right) = \\lambda \\left(y_n + \\frac{h}{2}k_1\\right)\n$$\nSubstituting $k_1 = \\lambda y_n$:\n$$\nk_2 = \\lambda \\left(y_n + \\frac{h}{2}(\\lambda y_n)\\right) = \\lambda y_n \\left(1 + \\frac{\\lambda h}{2}\\right)\n$$\n\nStep 3: Compute the third stage, $k_3$, using the result for $k_2$.\n$$\nk_3 = f\\left(t_n + \\frac{h}{2}, y_n + \\frac{h}{2}k_2\\right) = \\lambda \\left(y_n + \\frac{h}{2}k_2\\right)\n$$\nSubstituting the expression for $k_2$:\n$$\nk_3 = \\lambda \\left(y_n + \\frac{h}{2} \\left[\\lambda y_n \\left(1 + \\frac{\\lambda h}{2}\\right)\\right]\\right) = \\lambda y_n \\left(1 + \\frac{\\lambda h}{2}\\left(1 + \\frac{\\lambda h}{2}\\right)\\right)\n$$\n$$\nk_3 = \\lambda y_n \\left(1 + \\frac{\\lambda h}{2} + \\frac{(\\lambda h)^2}{4}\\right)\n$$\n\nStep 4: Compute the fourth stage, $k_4$, using the result for $k_3$.\n$$\nk_4 = f(t_n + h, y_n + h k_3) = \\lambda (y_n + h k_3)\n$$\nSubstituting the expression for $k_3$:\n$$\nk_4 = \\lambda \\left(y_n + h \\left[\\lambda y_n \\left(1 + \\frac{\\lambda h}{2} + \\frac{(\\lambda h)^2}{4}\\right)\\right]\\right) = \\lambda y_n \\left(1 + \\lambda h \\left(1 + \\frac{\\lambda h}{2} + \\frac{(\\lambda h)^2}{4}\\right)\\right)\n$$\n$$\nk_4 = \\lambda y_n \\left(1 + \\lambda h + \\frac{(\\lambda h)^2}{2} + \\frac{(\\lambda h)^3}{4}\\right)\n$$\n\nStep 5: Substitute the expressions for all four stages into the final update formula.\nThe update rule is given by:\n$$\ny_{n+1} = y_n + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)\n$$\nWe substitute the derived expressions for $k_1, k_2, k_3,$ and $k_4$:\n$$\ny_{n+1} = y_n + \\frac{h}{6} \\left[ \\lambda y_n + 2\\lambda y_n \\left(1 + \\frac{\\lambda h}{2}\\right) + 2\\lambda y_n \\left(1 + \\frac{\\lambda h}{2} + \\frac{(\\lambda h)^2}{4}\\right) + \\lambda y_n \\left(1 + \\lambda h + \\frac{(\\lambda h)^2}{2} + \\frac{(\\lambda h)^3}{4}\\right) \\right]\n$$\nFactor out the common term $\\lambda y_n$ from the bracketed expression:\n$$\ny_{n+1} = y_n + \\frac{h \\lambda y_n}{6} \\left[ 1 + 2\\left(1 + \\frac{\\lambda h}{2}\\right) + 2\\left(1 + \\frac{\\lambda h}{2} + \\frac{(\\lambda h)^2}{4}\\right) + \\left(1 + \\lambda h + \\frac{(\\lambda h)^2}{2} + \\frac{(\\lambda h)^3}{4}\\right) \\right]\n$$\nNow, substitute $z = \\lambda h$:\n$$\ny_{n+1} = y_n + \\frac{z y_n}{6} \\left[ 1 + 2\\left(1 + \\frac{z}{2}\\right) + 2\\left(1 + \\frac{z}{2} + \\frac{z^2}{4}\\right) + \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{4}\\right) \\right]\n$$\nExpand the terms inside the brackets:\n$$\ny_{n+1} = y_n + \\frac{z y_n}{6} \\left[ 1 + (2 + z) + \\left(2 + z + \\frac{z^2}{2}\\right) + \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{4}\\right) \\right]\n$$\nCollect like powers of $z$ within the brackets:\nThe constant term is $1 + 2 + 2 + 1 = 6$.\nThe coefficient of $z$ is $1 + 1 + 1 = 3$.\nThe coefficient of $z^2$ is $\\frac{1}{2} + \\frac{1}{2} = 1$.\nThe coefficient of $z^3$ is $\\frac{1}{4}$.\nSo, the expression in the brackets simplifies to $6 + 3z + z^2 + \\frac{z^3}{4}$.\n\nSubstitute this back into the equation for $y_{n+1}$:\n$$\ny_{n+1} = y_n + \\frac{z y_n}{6} \\left(6 + 3z + z^2 + \\frac{z^3}{4}\\right)\n$$\nDistribute the $\\frac{z}{6}$ term:\n$$\ny_{n+1} = y_n + y_n \\left(\\frac{6z}{6} + \\frac{3z^2}{6} + \\frac{z^3}{6} + \\frac{z^4}{24}\\right)\n$$\n$$\ny_{n+1} = y_n + y_n \\left(z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24}\\right)\n$$\nFinally, factor out $y_n$:\n$$\ny_{n+1} = y_n \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24}\\right)\n$$\nBy definition, $y_{n+1} = R(z) y_n$. Comparing this with the derived expression, we identify the stability function $R(z)$:\n$$\nR(z) = 1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24}\n$$\nThis polynomial is the truncation of the Taylor series for $\\exp(z)$ after the $z^4$ term, consistent with the fourth-order accuracy of the method.\nNoting that $2! = 2$, $3! = 6$, and $4! = 24$, we can write this as:\n$$\nR(z) = 1 + \\frac{z}{1!} + \\frac{z^2}{2!} + \\frac{z^3}{3!} + \\frac{z^4}{4!}\n$$\nThe problem asks for the closed-form polynomial.",
            "answer": "$$\n\\boxed{1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24}}\n$$"
        },
        {
            "introduction": "Many fundamental theories in physics are described by Hamiltonian mechanics, which imposes deep structural constraints on the dynamics, such as the conservation of energy and phase-space volume (symplecticity). While standard high-order methods like RK4 are accurate, they do not generally respect this structure, leading to unphysical long-term drifts. This capstone practice guides you to compare RK4 against a structure-preserving symplectic integrator (Störmer-Verlet) on a Hamiltonian lattice field theory model, revealing the profound importance of choosing an integrator that preserves the underlying geometry of the physical system .",
            "id": "3537380",
            "problem": "Consider a truncated one-dimensional lattice of a two-component real scalar field in natural units, where $\\hbar=c=1$. Let the lattice contain $N$ sites with periodic boundary conditions and field coordinates $\\boldsymbol{\\phi}_n(t) \\in \\mathbb{R}^2$ and conjugate momenta $\\boldsymbol{\\pi}_n(t) \\in \\mathbb{R}^2$ at site $n \\in \\{0,1,\\dots,N-1\\}$. Define the Hamiltonian\n$$\nH(\\{\\boldsymbol{\\phi}_n,\\boldsymbol{\\pi}_n\\}) \\equiv \\sum_{n=0}^{N-1} \\left( \\frac{1}{2}\\lVert \\boldsymbol{\\pi}_n \\rVert^2 + \\frac{1}{2} m^2 \\lVert \\boldsymbol{\\phi}_n \\rVert^2 + \\frac{1}{2} c^2 \\lVert \\boldsymbol{\\phi}_{n+1}-\\boldsymbol{\\phi}_n \\rVert^2 + \\frac{\\lambda}{4} \\lVert \\boldsymbol{\\phi}_n \\rVert^4 \\right),\n$$\nwhere $\\lVert \\cdot \\rVert$ denotes the Euclidean norm in $\\mathbb{R}^2$, and the index $n+1$ is taken modulo $N$.\n\nThe canonical equations of motion are the Hamiltonian ordinary differential equations (ODEs)\n$$\n\\dot{\\boldsymbol{\\phi}}_n(t) = \\boldsymbol{\\pi}_n(t), \\quad \\dot{\\boldsymbol{\\pi}}_n(t) = - \\nabla_{\\boldsymbol{\\phi}_n} V(\\{\\ \\boldsymbol{\\phi}_k\\ \\}),\n$$\nwith the potential\n$$\nV(\\{\\ \\boldsymbol{\\phi}_k\\ \\}) \\equiv \\sum_{n=0}^{N-1} \\left( \\frac{1}{2} m^2 \\lVert \\boldsymbol{\\phi}_n \\rVert^2 + \\frac{1}{2} c^2 \\lVert \\boldsymbol{\\phi}_{n+1}-\\boldsymbol{\\phi}_n \\rVert^2 + \\frac{\\lambda}{4} \\lVert \\boldsymbol{\\phi}_n \\rVert^4 \\right).\n$$\nEquivalently, with the phase-space vector $y(t)$ collecting all $\\boldsymbol{\\phi}_n$ and $\\boldsymbol{\\pi}_n$, the system has the Hamiltonian form $\\dot y(t) = J \\nabla H(y(t))$, where $J$ is the canonical symplectic matrix with $J^\\top = -J$ and $J^2 = -I$.\n\nThis Hamiltonian is invariant under internal $\\mathrm{O}(2)$ rotations of the two field components, which implies conservation of the Noether charge\n$$\nQ(\\{\\boldsymbol{\\phi}_n,\\boldsymbol{\\pi}_n\\}) \\equiv \\sum_{n=0}^{N-1} \\left( \\phi_{n,1}\\,\\pi_{n,2} - \\phi_{n,2}\\,\\pi_{n,1} \\right),\n$$\nwhere $\\phi_{n,1}$ and $\\phi_{n,2}$ denote the two components of $\\boldsymbol{\\phi}_n$, and $\\pi_{n,1}$ and $\\pi_{n,2}$ denote the two components of $\\boldsymbol{\\pi}_n$.\n\nStarting from fundamental Hamiltonian dynamics and canonical definitions, implement and compare two time-integration schemes for the above system:\n- The standard explicit fourth-order Runge–Kutta method (RK4), where Runge–Kutta (RK) refers to classical explicit stage-based integrators.\n- A symplectic, partitioned Runge–Kutta scheme suitable for separable Hamiltonians $H(\\boldsymbol{\\phi},\\boldsymbol{\\pi}) = T(\\boldsymbol{\\pi}) + V(\\boldsymbol{\\phi})$, specifically the Störmer–Verlet (also known as leapfrog) method.\n\nUse the following deterministic initial conditions with amplitude parameter $A$:\n$$\n\\boldsymbol{\\phi}_n(0) = A \\begin{bmatrix} \\cos\\left( \\frac{2\\pi n}{N} \\right) \\\\ \\sin\\left( \\frac{2\\pi n}{N} \\right) \\end{bmatrix}, \\quad\n\\boldsymbol{\\pi}_n(0) = \\begin{bmatrix} 0 \\\\ A \\cos\\left( \\frac{2\\pi n}{N} \\right) \\end{bmatrix}.\n$$\nThis choice ensures a nonzero initial charge $Q(0)$ and a bounded, physically realistic energy for the specified parameters below.\n\nFor each integrator and each test case, evolve the system from $t=0$ to $t=T$ with uniform timestep $\\Delta t$, and report the maximum relative drift over the entire integration interval for both the energy $H$ and the charge $Q$,\n$$\n\\delta_H \\equiv \\max_{0 \\le t \\le T} \\frac{\\left|H(t) - H(0)\\right|}{\\left|H(0)\\right|}, \\qquad\n\\delta_Q \\equiv \\max_{0 \\le t \\le T} \\frac{\\left|Q(t) - Q(0)\\right|}{\\max\\left( \\left|Q(0)\\right|, 10^{-12} \\right)},\n$$\nexpressed as decimal floats (unitless in natural units). The maximum operation should be approximated by evaluating $H$ and $Q$ at each discrete timestep.\n\nTest suite:\n- Case A (nonlinear, coupled): $N=16$, $m=1.0$, $c=1.0$, $\\lambda=0.1$, $A=0.2$, $\\Delta t = 0.01$, $T = 50.0$.\n- Case B (linear, uncoupled oscillators): $N=16$, $m=0.5$, $c=0.0$, $\\lambda=0.0$, $A=0.2$, $\\Delta t = 0.02$, $T = 50.0$.\n- Case C (stiffer nonlinear, coupled): $N=16$, $m=2.0$, $c=1.0$, $\\lambda=0.5$, $A=0.2$, $\\Delta t = 0.005$, $T = 30.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, return a list of four floats $\\left[\\delta_H^{\\mathrm{RK4}}, \\delta_Q^{\\mathrm{RK4}}, \\delta_H^{\\mathrm{Verlet}}, \\delta_Q^{\\mathrm{Verlet}}\\right]$. Therefore, the final output must be a list of three lists, one per test case, for example:\n$$\n\\left[ [d_{1,1}, d_{1,2}, d_{1,3}, d_{1,4}], [d_{2,1}, d_{2,2}, d_{2,3}, d_{2,4}], [d_{3,1}, d_{3,2}, d_{3,3}, d_{3,4}] \\right],\n$$\nwhere each $d_{\\cdot,\\cdot}$ is a decimal float. There are no physical units to report because the problem is posed in natural units ($\\hbar=c=1$).",
            "solution": "The problem requires the implementation and comparison of two numerical integration schemes—the fourth-order explicit Runge-Kutta method (RK4) and the Störmer-Verlet method—for a Hamiltonian system describing a two-component real scalar field on a one-dimensional lattice. The performance of these integrators will be evaluated based on their ability to conserve the system's total energy $H$ and a specific Noether charge $Q$.\n\nFirst, we must formalize the equations of motion. The state of the system at time $t$ is defined by the set of $N$ field coordinates $\\boldsymbol{\\phi}_n(t) \\in \\mathbb{R}^2$ and their conjugate momenta $\\boldsymbol{\\pi}_n(t) \\in \\mathbb{R}^2$, for each lattice site $n \\in \\{0, 1, \\dots, N-1\\}$. The Hamiltonian is given as:\n$$\nH = \\sum_{n=0}^{N-1} \\left( \\underbrace{\\frac{1}{2}\\lVert \\boldsymbol{\\pi}_n \\rVert^2}_{T(\\boldsymbol{\\pi})} + \\underbrace{\\frac{1}{2} m^2 \\lVert \\boldsymbol{\\phi}_n \\rVert^2 + \\frac{1}{2} c^2 \\lVert \\boldsymbol{\\phi}_{n+1}-\\boldsymbol{\\phi}_n \\rVert^2 + \\frac{\\lambda}{4} \\lVert \\boldsymbol{\\phi}_n \\rVert^4}_{V(\\boldsymbol{\\phi})} \\right)\n$$\nThis Hamiltonian is separable, meaning it can be written as a sum of a kinetic energy term $T(\\boldsymbol{\\pi})$ that depends only on the momenta and a potential energy term $V(\\boldsymbol{\\phi})$ that depends only on the coordinates. This property is crucial for the applicability of the Störmer-Verlet method.\n\nThe dynamics are governed by Hamilton's equations:\n$$\n\\dot{\\boldsymbol{\\phi}}_n = \\frac{\\partial H}{\\partial \\boldsymbol{\\pi}_n}, \\qquad \\dot{\\boldsymbol{\\pi}}_n = -\\frac{\\partial H}{\\partial \\boldsymbol{\\phi}_n}\n$$\nThe first equation yields $\\dot{\\boldsymbol{\\phi}}_n = \\boldsymbol{\\pi}_n$. For the second equation, we must compute the gradient of the potential $V(\\boldsymbol{\\phi})$ with respect to $\\boldsymbol{\\phi}_n$. The potential terms involving $\\boldsymbol{\\phi}_n$ are those for index $n$ and the coupling terms for indices $n-1$ and $n$. Considering the periodic boundary conditions ($n \\pm 1$ are taken modulo $N$), the gradient is:\n$$\n\\nabla_{\\boldsymbol{\\phi}_n} V = \\frac{\\partial V}{\\partial \\boldsymbol{\\phi}_n} = m^2 \\boldsymbol{\\phi}_n + \\lambda \\lVert\\boldsymbol{\\phi}_n\\rVert^2 \\boldsymbol{\\phi}_n + c^2(\\boldsymbol{\\phi}_n - \\boldsymbol{\\phi}_{n-1}) + c^2(\\boldsymbol{\\phi}_n - \\boldsymbol{\\phi}_{n+1})\n$$\nThe force on the field at site $n$ is $F_n = -\\nabla_{\\boldsymbol{\\phi}_n} V$. Rearranging the terms, we identify the discrete lattice Laplacian $\\Delta \\boldsymbol{\\phi}_n = \\boldsymbol{\\phi}_{n+1} + \\boldsymbol{\\phi}_{n-1} - 2\\boldsymbol{\\phi}_n$:\n$$\nF_n(\\{\\boldsymbol{\\phi}_k\\}) = - \\left( (m^2 + \\lambda \\lVert\\boldsymbol{\\phi}_n\\rVert^2) \\boldsymbol{\\phi}_n - c^2(\\boldsymbol{\\phi}_{n+1} - 2\\boldsymbol{\\phi}_n + \\boldsymbol{\\phi}_{n-1}) \\right)\n$$\nThus, the full system of first-order ordinary differential equations (ODEs) is:\n$$\n\\dot{\\boldsymbol{\\phi}}_n(t) = \\boldsymbol{\\pi}_n(t)\n$$\n$$\n\\dot{\\boldsymbol{\\pi}}_n(t) = F_n(\\{\\boldsymbol{\\phi}_k(t)\\})\n$$\nThis constitutes a system of $4N$ coupled first-order ODEs, where $N$ is the number of lattice sites.\n\nNow we describe the numerical integration schemes. Let the state vector be $y(t) = (\\boldsymbol{\\phi}_0(t), \\dots, \\boldsymbol{\\phi}_{N-1}(t), \\boldsymbol{\\pi}_0(t), \\dots, \\boldsymbol{\\pi}_{N-1}(t))$ and the system of ODEs be $\\dot{y} = f(y)$.\n\n**1. Fourth-Order Runge-Kutta (RK4)**\nRK4 is a general-purpose, explicit, single-step ODE solver. For a timestep $\\Delta t$, the update from $y_t$ to $y_{t+\\Delta t}$ is:\n$$\n\\begin{align*}\nk_1 = \\Delta t \\cdot f(y_t) \\\\\nk_2 = \\Delta t \\cdot f(y_t + k_1/2) \\\\\nk_3 = \\Delta t \\cdot f(y_t + k_2/2) \\\\\nk_4 = \\Delta t \\cdot f(y_t + k_3) \\\\\ny_{t+\\Delta t} = y_t + \\frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4)\n\\end{align*}\n$$\nRK4 is widely used due to its high accuracy (local truncation error $\\mathcal{O}(\\Delta t^5)$, global error $\\mathcal{O}(\\Delta t^4)$) and stability for a reasonable range of $\\Delta t$. However, it is not a symplectic integrator, which means that for Hamiltonian systems, conserved quantities like energy, a priori, are not well-preserved over long integration times. The energy error typically exhibits a secular drift.\n\n**2. Störmer-Verlet (Leapfrog) Method**\nThis method is a geometric integrator specifically designed for separable Hamiltonians. It belongs to the class of symplectic partitioned Runge-Kutta methods. The \"leapfrog\" variant updates positions and momenta at staggered times:\n$$\n\\begin{align*}\n\\boldsymbol{\\pi}_{n, t+\\Delta t/2} = \\boldsymbol{\\pi}_{n, t} + \\frac{\\Delta t}{2} F_n(\\{\\boldsymbol{\\phi}_{k, t}\\}) \\\\\n\\boldsymbol{\\phi}_{n, t+\\Delta t} = \\boldsymbol{\\phi}_{n, t} + \\Delta t \\cdot \\boldsymbol{\\pi}_{n, t+\\Delta t/2} \\\\\n\\boldsymbol{\\pi}_{n, t+\\Delta t} = \\boldsymbol{\\pi}_{n, t+\\Delta t/2} + \\frac{\\Delta t}{2} F_n(\\{\\boldsymbol{\\phi}_{k, t+\\Delta t}\\})\n\\end{align*}\n$$\nThis method is second-order accurate ($\\mathcal{O}(\\Delta t^2)$). Its key advantage is its symplectic nature. For Hamiltonian systems, this property ensures the preservation of phase-space volume and leads to bounded energy error over long periods, making it superior to non-symplectic methods like RK4 for long-term simulations of conservative systems.\n\n**Conservation of Noether Charge $Q$**\nThe Hamiltonian is invariant under $\\mathrm{O}(2)$ rotations in the internal field space, i.e., transformations of the form $(\\boldsymbol{\\phi}_n, \\boldsymbol{\\pi}_n) \\to (g\\boldsymbol{\\phi}_n, g\\boldsymbol{\\pi}_n)$ for any rotation matrix $g \\in \\mathrm{O}(2)$. This symmetry gives rise to the conserved Noether charge:\n$$\nQ = \\sum_{n=0}^{N-1} \\left( \\phi_{n,1}\\,\\pi_{n,2} - \\phi_{n,2}\\,\\pi_{n,1} \\right)\n$$\nAn integrator is called equivariant if its update map commutes with the symmetry action. The force function $F_n(\\{\\boldsymbol{\\phi}_k\\})$ is equivariant because $\\lVert g\\boldsymbol{\\phi}\\rVert = \\lVert\\boldsymbol{\\phi}\\rVert$ and matrix multiplication distributes over addition. A careful analysis shows that both the Störmer-Verlet method and any classical Runge-Kutta method (including RK4) are equivariant if the force function is. Consequently, both integrators should conserve the charge $Q$ up to machine floating-point precision. Any significant numerical drift in $Q$ would likely indicate an implementation error. The primary difference between the two methods is therefore expected to manifest in the long-term conservation of energy $H$.\n\nThe implementation will proceed by defining Python functions to compute the forces, the Hamiltonian $H$, and the charge $Q$. For each test case, the system is initialized and then evolved using both RK4 and Verlet integrators from $t=0$ to $t=T$. At each timestep, the relative drifts $\\delta_H$ and $\\delta_Q$ are calculated and their maximum values are recorded.\nThe specific initial conditions are:\n$$\n\\boldsymbol{\\phi}_n(0) = A \\begin{bmatrix} \\cos\\left( \\frac{2\\pi n}{N} \\right) \\\\ \\sin\\left( \\frac{2\\pi n}{N} \\right) \\end{bmatrix}, \\quad\n\\boldsymbol{\\pi}_n(0) = \\begin{bmatrix} 0 \\\\ A \\cos\\left( \\frac{2\\pi n}{N} \\right) \\end{bmatrix}\n$$\nThe program will systematically execute the simulations for the three specified test cases and report the four measured drift values for each.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulations for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case A (nonlinear, coupled)\n        {'N': 16, 'm': 1.0, 'c': 1.0, 'lambda_val': 0.1, 'A': 0.2, 'dt': 0.01, 'T': 50.0},\n        # Case B (linear, uncoupled oscillators)\n        {'N': 16, 'm': 0.5, 'c': 0.0, 'lambda_val': 0.0, 'A': 0.2, 'dt': 0.02, 'T': 50.0},\n        # Case C (stiffer nonlinear, coupled)\n        {'N': 16, 'm': 2.0, 'c': 1.0, 'lambda_val': 0.5, 'A': 0.2, 'dt': 0.005, 'T': 30.0},\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        N, m, c, lambda_val, A, dt, T = case.values()\n\n        # Initial conditions\n        n_indices = np.arange(N)\n        angles = 2 * np.pi * n_indices / N\n        cos_angles = np.cos(angles)\n        sin_angles = np.sin(angles)\n\n        phi0 = A * np.vstack((cos_angles, sin_angles)).T\n        pi0 = A * np.vstack((np.zeros(N), cos_angles)).T\n        \n        y0 = np.concatenate((phi0.flatten(), pi0.flatten()))\n        \n        # Run simulations\n        rk4_results = run_rk4_simulation(y0, N, m, c, lambda_val, dt, T)\n        verlet_results = run_verlet_simulation(phi0, pi0, N, m, c, lambda_val, dt, T)\n        \n        case_results = [*rk4_results, *verlet_results]\n        all_results.append(case_results)\n\n    # Format and print the final output\n    output_str = \"[\" + \", \".join([f\"[{', '.join(map(str, res))}]\" for res in all_results]) + \"]\"\n    print(output_str)\n\ndef compute_H(phi, pi, m, c, lambda_val, N):\n    \"\"\"Computes the Hamiltonian H.\"\"\"\n    kinetic_energy = 0.5 * np.sum(pi**2)\n    \n    phi_norm_sq = np.sum(phi**2, axis=1)\n    mass_term = 0.5 * m**2 * np.sum(phi_norm_sq)\n    interaction_term = 0.25 * lambda_val * np.sum(phi_norm_sq**2)\n    \n    phi_next = np.roll(phi, -1, axis=0)\n    diff_phi = phi_next - phi\n    coupling_term = 0.5 * c**2 * np.sum(diff_phi**2)\n    \n    return kinetic_energy + mass_term + interaction_term + coupling_term\n\ndef compute_Q(phi, pi):\n    \"\"\"Computes the Noether charge Q.\"\"\"\n    return np.sum(phi[:, 0] * pi[:, 1] - phi[:, 1] * pi[:, 0])\n\ndef compute_forces(phi, m, c, lambda_val, N):\n    \"\"\"Computes the force F = -dV/dphi.\"\"\"\n    phi_norm_sq = np.sum(phi**2, axis=1, keepdims=True)\n    \n    phi_next = np.roll(phi, -1, axis=0)\n    phi_prev = np.roll(phi, 1, axis=0)\n    laplacian = phi_next + phi_prev - 2 * phi\n    \n    force_on_site = (m**2 + lambda_val * phi_norm_sq) * phi\n    force_coupling = -c**2 * laplacian\n    \n    return -(force_on_site + force_coupling)\n\ndef get_derivatives(y, N, m, c, lambda_val):\n    \"\"\"Computes the time derivative of the state vector y for RK4.\"\"\"\n    phi = y[:2*N].reshape((N, 2))\n    pi = y[2*N:].reshape((N, 2))\n    \n    d_phi_dt = pi\n    d_pi_dt = compute_forces(phi, m, c, lambda_val, N)\n    \n    return np.concatenate((d_phi_dt.flatten(), d_pi_dt.flatten()))\n\ndef run_rk4_simulation(y0, N, m, c, lambda_val, dt, T):\n    \"\"\"Evolves the system using the RK4 method.\"\"\"\n    y = y0.copy()\n    num_steps = int(round(T / dt))\n    \n    phi_init = y[:2*N].reshape((N, 2))\n    pi_init = y[2*N:].reshape((N, 2))\n    \n    H0 = compute_H(phi_init, pi_init, m, c, lambda_val, N)\n    Q0 = compute_Q(phi_init, pi_init)\n    \n    H0_abs = np.abs(H0)\n    Q0_abs_norm = max(np.abs(Q0), 1e-12)\n\n    max_delta_H = 0.0\n    max_delta_Q = 0.0\n    \n    for _ in range(num_steps):\n        k1 = dt * get_derivatives(y, N, m, c, lambda_val)\n        k2 = dt * get_derivatives(y + 0.5 * k1, N, m, c, lambda_val)\n        k3 = dt * get_derivatives(y + 0.5 * k2, N, m, c, lambda_val)\n        k4 = dt * get_derivatives(y + k3, N, m, c, lambda_val)\n        y += (k1 + 2 * k2 + 2 * k3 + k4) / 6\n        \n        phi = y[:2*N].reshape((N, 2))\n        pi = y[2*N:].reshape((N, 2))\n        \n        H_t = compute_H(phi, pi, m, c, lambda_val, N)\n        Q_t = compute_Q(phi, pi)\n        \n        delta_H = np.abs(H_t - H0) / H0_abs if H0_abs > 0 else 0\n        delta_Q = np.abs(Q_t - Q0) / Q0_abs_norm\n        \n        if delta_H > max_delta_H:\n            max_delta_H = delta_H\n        if delta_Q > max_delta_Q:\n            max_delta_Q = delta_Q\n            \n    return max_delta_H, max_delta_Q\n\ndef run_verlet_simulation(phi0, pi0, N, m, c, lambda_val, dt, T):\n    \"\"\"Evolves the system using the Störmer-Verlet method.\"\"\"\n    phi = phi0.copy()\n    pi = pi0.copy()\n    num_steps = int(round(T / dt))\n\n    H0 = compute_H(phi, pi, m, c, lambda_val, N)\n    Q0 = compute_Q(phi, pi)\n\n    H0_abs = np.abs(H0)\n    Q0_abs_norm = max(np.abs(Q0), 1e-12)\n\n    max_delta_H = 0.0\n    max_delta_Q = 0.0\n    \n    # First half-step for momentum to align with leapfrog scheme\n    force = compute_forces(phi, m, c, lambda_val, N)\n    pi_half = pi + 0.5 * dt * force\n\n    for _ in range(num_steps):\n        # Full step for position\n        phi += dt * pi_half\n        \n        # Full step for momentum\n        force = compute_forces(phi, m, c, lambda_val, N)\n        pi = pi_half + 0.5 * dt * force\n        \n        # to calculate H, Q we need phi and pi at the same time `t`\n        # current pi is at t + dt. current phi is at t + dt.\n        # current pi_half is at t + dt/2. So we can sync pi back to t+dt.\n        \n        H_t = compute_H(phi, pi, m, c, lambda_val, N)\n        Q_t = compute_Q(phi, pi)\n        \n        delta_H = np.abs(H_t - H0) / H0_abs if H0_abs > 0 else 0\n        delta_Q = np.abs(Q_t - Q0) / Q0_abs_norm\n        \n        if delta_H > max_delta_H:\n            max_delta_H = delta_H\n        if delta_Q > max_delta_Q:\n            max_delta_Q = delta_Q\n        \n        # Update for next iteration\n        pi_half = pi + 0.5 * dt * force\n\n    return max_delta_H, max_delta_Q\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}