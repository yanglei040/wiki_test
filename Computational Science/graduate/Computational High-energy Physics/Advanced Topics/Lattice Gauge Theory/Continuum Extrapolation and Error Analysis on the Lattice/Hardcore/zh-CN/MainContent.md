## 引言
[格点场论](@entry_id:751173)是研究基本粒子强相互作用的非微扰[第一性原理方法](@entry_id:268553)，其威力在于能够通过大规模[数值模拟](@entry_id:137087)直接计算[量子色动力学](@entry_id:143869)（QCD）的物理预言。然而，这些计算本质上是在一个离散的、有限大小的四维时空[晶格](@entry_id:196752)上进行的。因此，模拟直接产生的原始数据本身并非物理可观测量，它们受到了由有限格点间距（$a$）和有限体积（$L$）引入的系统误差的“污染”。如何弥合这个从离散、有限的计算世界到连续、无限的物理现实之间的鸿沟，正是本篇文章所要解决的核心问题。一个不完整或不正确的误差处理会直接导致物理结论的偏差，因此，对连续外推和[误差分析](@entry_id:142477)的深刻理解是所有高精度格点计算的基石。

本文将系统性地引导读者掌握这一关键技能。在第一章“原理与机制”中，我们将深入挖掘[Symanzik有效理论](@entry_id:755707)，揭示[离散化误差](@entry_id:748522)的理论根源，并学习如何通过“改进”方案来系统性地控制它们。我们还将探讨[有限体积效应](@entry_id:749371)、手征外推等其他系统误差，以及处理它们之间复杂相互作用的策略。随后的第二章“应用与交叉学科联系”将通过丰富的实例，展示这些理论和方法在[强子谱学](@entry_id:155019)、标准模型基本参数确定等前沿研究中的具体应用，并探讨其与计算流体力学等其他领域的联系。最后，在“动手实践”部分，读者将有机会通过解决实际问题来巩固所学知识，掌握从处理原始数据到执行复杂[模型平均](@entry_id:635177)的完整分析流程。

## 原理与机制

在[格点场论](@entry_id:751173)的计算中，我们通过[数值模拟](@entry_id:137087)获得的是在有限格点间距 $a$ 和有限体积 $L$ 下的物理量。为了得到能够与实验结果直接比较的物理预测，我们必须将这些数值结果外推至连续时空（$a \to 0$）和无限体积（$L \to \infty$）的极限。本章将深入探讨连续外推的理论基础、核心原理以及在实践中处理各种系统误差的机制。我们将从 Symanzik [有效理论](@entry_id:155490)出发，系统地阐述[离散化误差](@entry_id:748522)的来源和形式，进而介绍如何通过“改进”方案来系统性地减小这些误差，并最终讨论在实际分析中如何执行稳健的连续外推和[误差分析](@entry_id:142477)。

### Symanzik [有效理论](@entry_id:155490)：[离散化误差](@entry_id:748522)的理论框架

所有连续外推方法的基础是 **Symanzik 有效理论 (Symanzik Effective Theory, SET)**。其核心思想是，一个在格点间距为 $a$ 的超[立方晶格](@entry_id:148452)上定义的局域[格点场论](@entry_id:751173)，其在低能区（即动量 $p \ll 1/a$）的物理效应，可以等效地由一个连续时空中的局域有效[拉格朗日量](@entry_id:174593) $\mathcal{L}_{\mathrm{eff}}$ 来描述。这个有效[拉格朗日量](@entry_id:174593)是标准连续理论（如QCD）的拉格朗日量 $\mathcal{L}_{\mathrm{QCD}}$ 加上一系列由格点间距 $a$ 压制的高维算符所构成的无穷级数 。

在四维欧几里得时空中，作用量 $S = \int d^4 x \mathcal{L}$ 是无量纲的，而[拉格朗日量密度](@entry_id:156695) $\mathcal{L}$ 的[质量量纲](@entry_id:160525)为 $4$。因此，有效[拉格朗日量](@entry_id:174593) $\mathcal{L}_{\mathrm{eff}}$ 也必须具有相同的量纲。其一般形式可以写为：
$$
\mathcal{L}_{\mathrm{eff}} = \mathcal{L}_{\mathrm{QCD}} + \sum_{d > 4} \sum_i a^{d-4} c_i(g) \mathcal{O}_i^{(d)}
$$
这里，$\mathcal{O}_i^{(d)}$ 是一个[质量量纲](@entry_id:160525)为 $d$ 的局域算符，由连续场（夸克和胶子场）及其[协变导数](@entry_id:152476)构成。系数 $c_i(g)$ 是无量纲的，通常依赖于裸耦合常数 $g$。$a^{d-4}$ 这个因子的出现是[量纲分析](@entry_id:140259)的直接结果，它确保了每一项的[质量量纲](@entry_id:160525)都是 $4$。

这个展开式告诉我们，格点计算结果与真实连续理论的偏差，表现为一系列关于格点间距 $a$ 的幂次修正。对于一个[物理可观测量](@entry_id:154692) $O$ 的格点计算结果 $O(a)$，其[期望值](@entry_id:153208)也存在类似的展开：
$$
\langle O(a) \rangle = \langle O \rangle_{\mathrm{cont}} + \sum_{d > 4} \sum_i a^{d-4} C_i \langle O_i^{(d)} \rangle_{\mathrm{cont}} + \dots
$$
其中 $\langle O \rangle_{\mathrm{cont}}$ 是我们希望得到的[连续极限](@entry_id:162780)下的物理值。对于小的 $a$，截断误差将由求和中具有最小维数 $d_{\min}$ 且系数不为零的算符所主导，其行为是 $\mathcal{O}(a^{d_{\min}-4})$。

至关重要的是，并非所有高维算符都可以出现在 $\mathcal{L}_{\mathrm{eff}}$ 中。一个算符 $\mathcal{O}_i^{(d)}$ 能否出现，取决于它是否与底层的格点作用量具有完全相同的对称性。这些对称性包括[规范不变性](@entry_id:137857)、[电荷共轭](@entry_id:158278) ($C$)、宇称 ($P$)、[时间反演](@entry_id:182076) ($T$)，以及离散的超立方对称性群 $H(4)$（它是连续时空旋转群 $O(4)$ 的一个[子群](@entry_id:146164)）。因此，通过分析特定格点作用量的对称性，我们就能预测其主要的[离散化误差](@entry_id:748522)的形式。

### 常见格点作用量的[离散化误差](@entry_id:748522)

基于 Symanzik [有效理论](@entry_id:155490)的[对称性分析](@entry_id:174795)，我们可以预测不同格点作用量的主导[截断误差](@entry_id:140949)形式 。

*   **纯规范理论 (Wilson 作用量)**：对于只包含胶子的纯[规范理论](@entry_id:142992)，若使用标准的 Wilson 矩形（plaquette）作用量，其具备规范不变性、超立方对称性以及 $C, P, T$ 对称性。在纯[杨-米尔斯理论](@entry_id:137401)中，不存在任何具有[规范不变性](@entry_id:137857)、局域性且在[电荷共轭](@entry_id:158278)下为偶性的维度-5 算符。所有满足对称性要求的无关算符的维度都是偶数，最低维度为 $6$。因此，对壳（on-shell）物理量的[离散化误差](@entry_id:748522)由维度-6 算符主导，其形式为 $\mathcal{O}(a^{6-4}) = \mathcal{O}(a^2)$。

*   **Wilson [费米子](@entry_id:146235) (未改进)**：标准的 Wilson [费米子](@entry_id:146235)作用量为了解决[费米子](@entry_id:146235)“加倍”问题，引入了一个与 $a$ 成正比的 Wilson 项 $ (ar/2) \bar{\psi} D^2 \psi $。这个项具有维度-5 的形式，并显式地破坏了手征对称性。由于手征对称性不再是格点作用量的精确对称性，有效[拉格朗日量](@entry_id:174593)中便不再禁止出现破坏手征对称性的算符。其中一个关键的算符就是维度-5 的 **泡利项 (Pauli term)** $\mathcal{O}_P = \bar{\psi} \sigma_{\mu\nu} F^{\mu\nu} \psi$。该算符满足除手征对称性之外的所有其他对称性要求，因此它会出现在 $\mathcal{L}_{\mathrm{eff}}$ 中，导致 $\mathcal{O}(a)$ 的主导[离散化误差](@entry_id:748522)。

*   **[交错费米子](@entry_id:755338) (Staggered Fermions)**：[交错费米子](@entry_id:755338)保留了一部分手征对称性（一种 $U(1)$ 亚群），这足以禁止维度-5 算符的出现，从而避免了 $\mathcal{O}(a)$ 误差。[交错费米子](@entry_id:755338)最著名的问题是所谓的“味[对称性破缺](@entry_id:158994)”，即在有限格点间距上，连续理论中的 $SU(4)$ [味对称性](@entry_id:152851)被破坏为一个离散[子群](@entry_id:146164)。然而，导致这种破缺的算符是维度-6 的，因此味[对称性破缺](@entry_id:158994)效应本身是 $\mathcal{O}(a^2)$ 的，而非 $\mathcal{O}(a)$。因此，[交错费米子](@entry_id:755338)被认为是“自动” $\mathcal{O}(a)$ 改进的。

*   **具有精确手征对称性的[费米子](@entry_id:146235)**：如 **重叠[费米子](@entry_id:146235) (Overlap Fermions)** 或 **最大扭曲质量 Wilson [费米子](@entry_id:146235) (Maximally Twisted Mass Wilson Fermions)** 等现代[费米子](@entry_id:146235)作用量，它们在格点上满足一种精确的手征对称性（即 Ginsparg-Wilson 关系）或通过特殊调节自动实现 $\mathcal{O}(a)$ 改进。这种强大的对称性严格禁止了任何维度-5 费米算符（包括泡利项）的出现。因此，当与一个本身没有 $\mathcal{O}(a)$ 误差的规范作用量（如 Wilson 规范作用量）结合使用时，整个理论的主导[离散化误差](@entry_id:748522)是 $\mathcal{O}(a^2)$ 。

### “改进”纲领：系统性地减小[离散化误差](@entry_id:748522)

既然我们知道了[离散化误差](@entry_id:748522)的来源，自然会问：能否主动地消除它们？Symanzik 的“改进”纲领 (improvement program) 提供了一套系统性的方法来减小甚至消除低阶的截断误差。

#### 壳上 $\mathcal{O}(a)$ 改进与 Clover 项

对于 Wilson [费米子](@entry_id:146235)，其 $\mathcal{O}(a)$ 误差的根源是维度-5 的泡利项。**壳上 $\mathcal{O}(a)$ 改进 (On-shell $\mathcal{O}(a)$ improvement)** 的目标就是消除这个算符对物理[矩阵元](@entry_id:186505)（即在外部态满足连续理论运动方程的情况下计算的矩阵元）的贡献 。

这一目标通过在 Wilson 作用量中添加一个“抵消”项来实现，这个项被称为 **Sheikholeslami-Wohlert (SW) 项**，或更通俗地称为 **Clover 项**。它的形式正是泡利项的格点离散化版本：
$$
S_{\mathrm{clover}} = -i c_{\mathrm{SW}} \frac{a}{4} \sum_x \bar{\psi}(x) \sigma_{\mu\nu} F_{\mu\nu}(x) \psi(x)
$$
其中 $F_{\mu\nu}(x)$ 是由围绕格点 $x$ 的四个最小矩形（形如三叶草，故名 "clover"）构造出的规范协变的[场强张量](@entry_id:159746)离散形式 。通过精确调节无量纲系数 $c_{\mathrm{SW}}$ 的值，可以使得在[有效理论](@entry_id:155490)中，维度-5 算符的总系数在壳上为零。这样，Wilson [费米子](@entry_id:146235)理论的主导误差就从 $\mathcal{O}(a)$ 提升到了 $\mathcal{O}(a^2)$ 。调节 $c_{\mathrm{SW}}$ 的过程可以通过微扰论计算，也可以通过非微扰的数值方法来完成。

值得注意的是 **壳上 (on-shell)** 和 **壳外 (off-shell)** 改进的区别。壳上改进依赖于连续理论的[运动方程](@entry_id:170720)，这些方程使得某些算符在物理矩阵元中的贡献为零。然而，对于一般的[格林函数](@entry_id:147802)（例如在中间动量或短距离下的关联函数），这些算符的贡献不为零。消除这些壳外误差需要一个更复杂的“壳外改进”方案，它不仅要改进作用量，还必须改进[费米子](@entry_id:146235)场和[复合算符](@entry_id:152160)本身，以处理算符混合和接触项 (contact terms) 等问题 。

#### [树图](@entry_id:276372)级与平均场改进

除了非微扰地调节 $c_{\mathrm{SW}}$ 来完全消除壳上 $\mathcal{O}(a)$ 误差外，还有一些更简单、更具启发性的改进方法 。

*   **[树图](@entry_id:276372)级改进 (Tree-level improvement)**：这种方法旨在经典理论层面（即[耦合常数](@entry_id:747980) $g=0$ 时，对应于微扰论中的[树图](@entry_id:276372)级别）消除主导误差。例如，对于 Clover 项，[树图](@entry_id:276372)级改进就是简单地设置 $c_{\mathrm{SW}}=1$。这可以在没有量子修正的情况下消除 $\mathcal{O}(a)$ 误差。然而，一旦考虑量子[圈图修正](@entry_id:150150)，维度-5 算符的系数会重新出现一个与耦合常数相关的部分，导致残余的误差项形式为 $\mathcal{O}(\alpha_s a)$，其中 $\alpha_s = g^2/(4\pi)$。

*   **平均场改进 (Mean-field improvement)**：这是由 Lepage 和 Mackenzie 提出的一种旨在改善格点微扰论收敛性的实用技巧。格点微扰论之所以收敛性差，一个重要原因在于规范链 接变量 $U_\mu(x)$ 的[量子涨落](@entry_id:154889)非常大（所谓的“蝌蚪图”贡献）。平均场改进通过将作用量和算符中的规范链接 $U_\mu(x)$ 重新标度为 $U_\mu(x) / u_0$ 来部分地[重求和](@entry_id:275405)这些主要的量子修正。这里的 $u_0$ 是一个衡量平均链接的非微扰量，通常取为平均 plaquette 值的四次方根，即 $u_0 = \langle \frac{1}{3} \mathrm{Re} \mathrm{Tr} U_{\mathrm{plaq}} \rangle^{1/4}$。这种方法虽然不能改变[离散化误差](@entry_id:748522)的幂次（例如从 $\mathcal{O}(a)$ 变为 $\mathcal{O}(a^2)$），但它能有效地减小各阶误差项的系数，从而在实际的格点间距范围内，使得离散化效应变得更小，外推曲线更平缓。

### 连续外推的实践

理论分析为我们指明了[离散化误差](@entry_id:748522)的形式，这直接决定了我们在进行连续外推时应该选择何种拟合函数。

#### 拟合函数的形式：幂次与对数修正

对于一个已经 $\mathcal{O}(a)$ 改进的理论，其主导误差为 $\mathcal{O}(a^2)$。因此，一个最简单的外推拟合函数是关于 $a^2$ 的多项式：
$$
O(a) = O(0) + C_1 a^2 + C_2 a^4 + \dots
$$
其中 $O(0)$ 就是我们寻求的[连续极限](@entry_id:162780)值。然而，在追求[高精度计算](@entry_id:200567)时，我们必须考虑更细微的效应 。

在相互作用理论中，Symanzik [有效理论](@entry_id:155490)中的高维算符本身也需要被重整化。这意味着它们的系数 $c_i$ 会依赖于[重整化标度](@entry_id:153146) $\mu$。这些系数的 **[反常维度](@entry_id:147674) (anomalous dimensions)** 描述了它们随标度变化的“跑动”行为。由于格点理论的内禀标度是截断 $1/a$，因此在将[有效理论](@entry_id:155490)与格点理论在 $\mu \sim 1/a$ 处进行匹配时，系数的标度依赖性会转化为对外推函数中 $a$ 的显式依赖。

具体来说，如果一个主导的维度-6 算符具有非零的[反常维度](@entry_id:147674)，其系数的跑动将引入对数项。这导致外推函数中出现形如 $a^2 \ln(a)$ 的项。因此，一个更完备、理论上更严谨的拟合函数形式应为：
$$
O(a) = O(0) + C_1 a^2 + C_2 a^2 \ln(a^2 \Lambda_{\mathrm{QCD}}^2) + C_3 a^4 + \dots
$$
在实际拟合中，是否包含对数项取决于计算的精度要求以及数据点对这种细微曲率的敏感度 。

### 与其他系统误差的相互作用

连续外推并非在真空中进行。[离散化误差](@entry_id:748522)只是多种系统误差之一，并且它常常与其他误差相互纠缠，使得分析变得复杂。

#### [有限体积效应](@entry_id:749371)

格点计算在有限的四维体积中进行，这会引入 **有限体积 (Finite-Volume, FV) 效应**。这种效应源于红外 (IR) 物理，与由紫外 (UV) 截断 $a$ 引起的[离散化误差](@entry_id:748522)有着本质区别 。

*   **有质量鸿沟的理论**：如果理论中所有粒子的质量都大于零（即存在质量鸿沟），例如在 QCD 中，最轻的强子是 pion，其质量为 $m_\pi$。此时，[有限体积效应](@entry_id:749371)对局域可观测量的修正主要来自于[虚粒子](@entry_id:147959)“环绕”有限空间所致，其大小由理论中最轻粒子的质量决定，并随体积 $L$ 指数衰减，形式为 $\mathcal{O}(e^{-m_\pi L})$。

*   **无质量鸿沟的理论**：如果理论中存在无质量粒子（如 QED 中的[光子](@entry_id:145192)，或手征极限下的 pion），[长程相互作用](@entry_id:140725)会导致幂次形式的[有限体积修正](@entry_id:749370)，如 $\mathcal{O}(1/L^n)$。

在实际模拟中，格点数 $N$ 和格点间距 $a$ 决定了物理体积 $L=Na$。这意味着当改变 $a$ 进行连续外推时，如果保持 $N$ 不变， $L$ 也会随之改变，从而将[离散化误差](@entry_id:748522)和有限体积误差耦合在一起。更复杂的是，Symanzik 展开中的系数本身也可能依赖于红外物理（即 $L$），从而产生形如 $a^2 e^{-m_\pi L}$ 的混合项。因此，为了可靠地分离这两种效应，最稳健的方法是进行[全局拟合](@entry_id:200953)，使用一个同时包含 $a$ 和 $L$ 依赖关系的函数模型，例如：
$$
O(a, L) = O(\infty, 0) + B e^{-m_\pi L} + C a^2 + \dots
$$

#### 手征外推

在许多计算中，为了节约计算资源，模拟是在非物理的、较大的夸克质量 $m_q$ 下进行的，然后需要将结果外推到物理夸克质量。这一过程称为 **手征外推 (Chiral Extrapolation)**，其理论基础是 **手征微扰理论 (Chiral Perturbation Theory, ChPT)** 。

当我们需要同时进行连续外推和手征外推时，问题变得更加复杂。一个物理量 $O(a, m_q)$ 不仅依赖于 $a$ 和 $m_q$，而且这两种依赖关系是相互关联的。我们可以将手征展开的系数看作是 $a$ 的函数：
$$
O(a, m_q) = C_0(a) + C_1(a) m_q + C_2(a) m_q \ln(m_q) + \dots
$$
而每个系数 $C_i(a)$ 本身又可以根据 Symanzik 理论进行展开：
$$
C_i(a) = C_i(0) + K_i a^2 + \dots
$$
将两者结合，我们发现总的展开式中必然包含[交叉](@entry_id:147634)项，例如 $K_1 a^2 m_q$。这种交叉项意味着 $m_q$ 依赖关系的曲率会随着 $a$ 的变化而变化。因此，简单的“顺序外推”（例如，先在每个固定的 $a$ 上进行手征外推至物理质量，然后再对得到的几个点进行连续外推）在方法论上是不完备的，因为它忽略了这种关联曲率。正确的做法是进行一个二元的[全局拟合](@entry_id:200953)，使用一个同时描述 $a$ 和 $m_q$ 依赖关系的统一函数模型，以可靠地控制这两种相互交织的系统误差 。

#### 重整化常数中的离散效应

对于[复合算符](@entry_id:152160)的[矩阵元](@entry_id:186505)，其最终的物理结果需要乘以一个 **[重整化](@entry_id:143501)常数 (renormalization constant)** $Z_O$ 来消除[紫外发散](@entry_id:183379)。这个过程表示为 $M_R(\mu, a) = Z_O(a, \mu) M_B(a)$，其中 $M_B$ 是裸矩阵元， $M_R$ 是在[重整化标度](@entry_id:153146) $\mu$ 下的重整化矩阵元 。

重要的是，重整化常数 $Z_O(a, \mu)$ 本身也是通过格点计算得到的，通常是从一些壳外的[格林函数](@entry_id:147802)中提取（例如在 RI/MOM 等动量相减方案中）。因此，$Z_O(a, \mu)$ 自身也受到[离散化误差](@entry_id:748522)的影响。
$$
M_R(\mu, a) = \left[Z_O^{\mathrm{cont}}(\mu)(1 + \mathcal{O}((a\mu)^2, a^2 p_i^4/p^4, \dots))\right] \times \left[M_B^{\mathrm{cont}}(1 + \mathcal{O}(a^2))\right]
$$
这意味着最终的[重整化](@entry_id:143501)[矩阵元](@entry_id:186505) $M_R(\mu, a)$ 的总[离散化误差](@entry_id:748522)是两部分误差的卷积：一部分来自裸[矩阵元](@entry_id:186505) $M_B(a)$ 的计算（通常是壳上误差，如 $\mathcal{O}(a^2)$），另一部分来自[重整化](@entry_id:143501)常数 $Z_O(a, \mu)$ 的计算（通常是壳外误差，可能包含与动量相关的项，如 $(a\mu)^2$ 和破坏旋转对称性的超立方[不变量](@entry_id:148850)）。在进行高精度的连续外推时，必须同时考虑并正确模这些来源的误差。此外，对于像 Wilson [费米子](@entry_id:146235)这样破坏手征对称性的作用量，算符在重整化时还可能与低维算符发生混合，其混合系数可能随 $a$ 发散（如 $1/a$），这需要进行额外的“幂次发散减除”，使得问题更加复杂 。

### 连续外推中的不确定度量化

最后，一个完整的分析不仅要得到中心值，还必须可靠地评估其统计不确定度。

#### 相关拟合

在现代格点计算中，不同格点间距下的数据集往往不是完全独立的。例如，它们可能共享相同的规范场系综生成策略，或者使用共同的标度设定程序。这导致不同 $a$ 处的物理量估计值 $y_i$ 之间存在[统计相关性](@entry_id:267552)，由一个非对角的协方差矩阵 $C$ 描述。

在这种情况下，正确的拟合方法是最小化 **相关卡方 (correlated chi-squared)** ：
$$
\chi^2(\theta) = (y - f(\theta))^\top C^{-1} (y - f(\theta))
$$
其中 $y$ 是数据点向量，$f(\theta)$ 是拟合模型向量，$\theta$ 是拟合参数。这个形式直接源于[多元正态分布](@entry_id:175229)的最大似然估计原理。

忽略数据间的相关性（即只使用[协方差矩阵](@entry_id:139155)的对角元）会带来严重后果：
1.  **参数估计偏差**：如果拟合模型本身不完美（例如，由于截断了高阶项），忽略相关性会改变拟合对不同数据点的权重方式，从而导致最终外推参数产生系统性偏差。
2.  **不确定度低估**：正相关意味着数据点提供的信息部分重叠。忽略这一点相当于高估了[独立数](@entry_id:260943)据点的有效数量，从而导致对拟合参数不确定度的严重低估。
3.  **[拟合优度检验](@entry_id:267868)失效**：基于不相关卡方值的[拟合优度](@entry_id:637026)（Goodness-of-fit）检验（如 p-值）是无效的，因为其统计量的[零分布](@entry_id:195412)不再是标准的[卡方分布](@entry_id:165213)。

#### [重采样方法](@entry_id:144346)

连续外推拟合通常是一个[非线性](@entry_id:637147)过程，将输入的多个可观测量平均值映射到最终的[连续极限](@entry_id:162780)值。通过这种复杂的、[非线性](@entry_id:637147)的函数传播[统计误差](@entry_id:755391)是困难的。**重采样 (resampling)** 方法，如 **[自助法](@entry_id:139281) (Bootstrap)** 和 **[刀切法](@entry_id:174793) (Jackknife)**，为这一问题提供了稳健的、非参数的解决方案 。

然而，原始的[蒙特卡洛](@entry_id:144354)时间序列数据存在 **[自相关](@entry_id:138991) (autocorrelation)**，即相邻的测量值不是独立的。直接对单个测量值进行重采样会破坏这种关联结构，导致不确定度的严重低估。正确的做法是采用 **分块 (blocking)** 技术：

1.  将每个系综的[马尔可夫链](@entry_id:150828)时间序列分割成若干个[数据块](@entry_id:748187)，块的长度 $b$ 必须远大于该序列的[积分自相关时间](@entry_id:637326) $\tau_{\mathrm{int}}$。这样，不同块的平均值可以近似认为是相互独立的。
2.  **[分块自助法](@entry_id:136334) (Block Bootstrap)**：通过有放回地对[数据块](@entry_id:748187)进行[重采样](@entry_id:142583)来构造新的“伪数据集”。
3.  **[分块刀切法](@entry_id:142964) (Blocked Jackknife)**：通过依次移除一个[数据块](@entry_id:748187)来构造“留一”数据集。

对于每一个由重采样生成的伪数据集，我们都重复整个分析流程——计算各系综的平均值、构造[协方差矩阵](@entry_id:139155)、执行相关卡方拟合，并得到一个连续外推值。最后，从所有重采样得到的外推值集合的统计分布（如[标准差](@entry_id:153618)或[分位数](@entry_id:178417)），我们就可以得到最终结果的可靠统计不确定度。这个过程自动地、[非线性](@entry_id:637147)地传播了从最底层的蒙特卡洛数据到最终物理结果的所有统计涨落 。