{
    "hands_on_practices": [
        {
            "introduction": "This exercise provides a concrete foundation for understanding the look-elsewhere effect in a discretized search. By modeling a series of binned measurements with a correlation matrix $\\mathbf{C}$, you will compute the effective number of trials, $M_{\\mathrm{eff}}$, a crucial concept that quantifies how correlations reduce the number of independent places a new signal could appear. This practice demonstrates how to handle correlated tests using the matrix spectrum and adjust the global probability $p_{\\mathrm{glob}}$ accordingly. ",
            "id": "3539414",
            "problem": "Consider a sequence of local hypothesis tests indexed by mass-bin index, each producing a local tail probability $p_{\\mathrm{loc}} \\in [0,1]$ for a fixed test statistic under the null hypothesis. Adjacent mass bins are correlated due to finite mass resolution and overlapping windows. Model this correlation by an $M \\times M$ symmetric tridiagonal correlation matrix $\\mathbf{C}$ with entries\n- $C_{ii} = 1$ for all $i$,\n- $C_{i,i+1} = C_{i+1,i} = \\rho$ for $i = 1,\\dots,M-1$,\n- $C_{ij} = 0$ otherwise,\nwhere $\\rho \\in (-1,1)$ is the correlation between adjacent bins. You may assume $\\mathbf{C}$ is positive definite for the values of $\\rho$ and $M$ in the test suite below.\n\nThe global look-elsewhere adjusted probability $p_{\\mathrm{glob}}$ is defined as the probability to observe at least one local fluctuation as significant as observed across the full search range. When tests are independent, the exact relationship between $p_{\\mathrm{glob}}$ and $p_{\\mathrm{loc}}$ for $N$ trials is given by $p_{\\mathrm{glob}} = 1 - (1 - p_{\\mathrm{loc}})^{N}$. In the presence of correlations, replace $N$ by an effective number of independent trials $M_{\\mathrm{eff}}$ that depends on $\\mathbf{C}$. Compute $M_{\\mathrm{eff}}$ numerically from the spectrum of $\\mathbf{C}$, and then compute $p_{\\mathrm{glob}}$ by substituting $M_{\\mathrm{eff}}$ into the independent-trials formula.\n\nYour program must:\n- Construct $\\mathbf{C}$ for each provided $(M,\\rho)$.\n- Numerically compute $M_{\\mathrm{eff}}$ from the eigenvalues of $\\mathbf{C}$ using a principled effective-dimensionality measure derived from the spectrum.\n- Compute $p_{\\mathrm{glob}}$ for each case from $p_{\\mathrm{loc}}$ and $M_{\\mathrm{eff}}$ using the independent-trials combination with $M_{\\mathrm{eff}}$ in place of an integer count. All probabilities must be treated as dimensionless numbers in $[0,1]$ and reported as decimals, not percentages.\n\nTest suite:\n1. $M = 100$, $\\rho = 0.5$, $p_{\\mathrm{loc}} = 2.87 \\times 10^{-7}$.\n2. $M = 100$, $\\rho = 0.0$, $p_{\\mathrm{loc}} = 2.87 \\times 10^{-7}$.\n3. $M = 100$, $\\rho = 0.45$, $p_{\\mathrm{loc}} = 10^{-3}$.\n4. $M = 50$, $\\rho = -0.45$, $p_{\\mathrm{loc}} = 0.05$.\n5. $M = 1000$, $\\rho = 0.2$, $p_{\\mathrm{loc}} = 10^{-9}$.\n6. $M = 100$, $\\rho = 0.49$, $p_{\\mathrm{loc}} = 10^{-6}$.\n\nOutput specification:\n- For each test case, output a two-element list $[M_{\\mathrm{eff}}, p_{\\mathrm{glob}}]$.\n- Aggregate all test case results into a single list, preserving the order above.\n- Round each numeric entry to twelve significant digits.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For example, the final output must look like\n$[ [M_{\\mathrm{eff}}^{(1)},p_{\\mathrm{glob}}^{(1)}], [M_{\\mathrm{eff}}^{(2)},p_{\\mathrm{glob}}^{(2)}], \\dots ]$\nwith no extra whitespace requirements beyond standard commas and brackets.\n\nNo external input should be read; all parameters are as specified above, and the program must be self-contained and deterministic.",
            "solution": "The user-provided problem is valid. It is scientifically grounded in the statistical methods of high-energy physics, well-posed under a standard interpretation of its terms, and objective in its formulation. We will therefore proceed with a complete solution.\n\nThe problem requires the computation of the global, or \"look-elsewhere\" corrected, p-value ($p_{\\mathrm{glob}}$) from a local p-value ($p_{\\mathrm{loc}}$) in a series of $M$ correlated hypothesis tests. The standard formula for combining $N$ independent tests, $p_{\\mathrm{glob}} = 1 - (1 - p_{\\mathrm{loc}})^{N}$, can be adapted for correlated tests by introducing an effective number of independent trials, $M_{\\mathrm{eff}}$. The core of the problem is to determine $M_{\\mathrm{eff}}$ from the provided correlation model.\n\n**1. The Correlation Model and Effective Number of Trials**\n\nThe correlation between adjacent tests is described by an $M \\times M$ symmetric tridiagonal correlation matrix $\\mathbf{C}$ with entries:\n$$\nC_{ij} =\n\\begin{cases}\n1  \\text{if } i=j \\\\\n\\rho  \\text{if } |i-j|=1 \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nwhere $\\rho \\in (-1, 1)$ is the correlation coefficient between adjacent bins.\n\nThe problem specifies that $M_{\\mathrm{eff}}$ should be a \"principled effective-dimensionality measure derived from the spectrum\" of $\\mathbf{C}$. A standard and principled measure for the effective number of parameters, or degrees of freedom, from a set of correlated variables is derived from the eigenvalues $\\{\\lambda_i\\}_{i=1}^M$ of the correlation matrix. This measure, sometimes related to the participation ratio, is defined as:\n$$\nM_{\\mathrm{eff}} = \\frac{\\left(\\sum_{i=1}^M \\lambda_i\\right)^2}{\\sum_{i=1}^M \\lambda_i^2}\n$$\nFor any correlation matrix, the sum of its eigenvalues equals its trace. The trace of $\\mathbf{C}$ is $\\mathrm{Tr}(\\mathbf{C}) = \\sum_{i=1}^M C_{ii} = \\sum_{i=1}^M 1 = M$. Therefore, the formula for $M_{\\mathrm{eff}}$ simplifies to:\n$$\nM_{\\mathrm{eff}} = \\frac{M^2}{\\sum_{i=1}^M \\lambda_i^2}\n$$\nThis expression correctly reproduces the expected limits: for independent tests ($\\rho=0$), $\\mathbf{C}=\\mathbf{I}$, all $\\lambda_i=1$, and $M_{\\mathrm{eff}} = M^2/M = M$. For fully correlated tests, $M_{\\mathrm{eff}} \\to 1$.\n\n**2. Analytical Calculation of Eigenvalues and $M_{\\mathrm{eff}}$**\n\nThe matrix $\\mathbf{C}$ is a specific type of symmetric tridiagonal Toeplitz matrix. The eigenvalues of such a matrix have a known analytical form. For an $M \\times M$ matrix with $a$ on the main diagonal and $b$ on the first off-diagonals, the eigenvalues are $\\lambda_k = a + 2b \\cos\\left(\\frac{k\\pi}{M+1}\\right)$ for $k=1, \\dots, M$. In our case, $a=1$ and $b=\\rho$, so the eigenvalues of $\\mathbf{C}$ are:\n$$\n\\lambda_k = 1 + 2\\rho \\cos\\left(\\frac{k\\pi}{M+1}\\right), \\quad k=1, \\dots, M\n$$\nWhile one could numerically compute these eigenvalues, an analytical calculation of the sum of their squares, $\\sum_{i=1}^M \\lambda_i^2$, provides a more elegant, efficient, and precise solution.\n\nWe compute the sum of squared eigenvalues:\n$$\n\\sum_{k=1}^M \\lambda_k^2 = \\sum_{k=1}^M \\left(1 + 2\\rho \\cos\\left(\\frac{k\\pi}{M+1}\\right)\\right)^2\n$$\n$$\n= \\sum_{k=1}^M \\left(1 + 4\\rho \\cos\\left(\\frac{k\\pi}{M+1}\\right) + 4\\rho^2 \\cos^2\\left(\\frac{k\\pi}{M+1}\\right)\\right)\n$$\n$$\n= M + 4\\rho \\sum_{k=1}^M \\cos\\left(\\frac{k\\pi}{M+1}\\right) + 4\\rho^2 \\sum_{k=1}^M \\cos^2\\left(\\frac{k\\pi}{M+1}\\right)\n$$\nThe sums can be evaluated analytically. The first sum is zero: $\\sum_{k=1}^M \\cos\\left(\\frac{k\\pi}{M+1}\\right) = 0$. For the second sum, we use the identity $\\cos^2(x) = \\frac{1}{2}(1+\\cos(2x))$:\n$$\n\\sum_{k=1}^M \\cos^2\\left(\\frac{k\\pi}{M+1}\\right) = \\sum_{k=1}^M \\frac{1}{2}\\left(1 + \\cos\\left(\\frac{2k\\pi}{M+1}\\right)\\right) = \\frac{M}{2} + \\frac{1}{2}\\sum_{k=1}^M \\cos\\left(\\frac{2k\\pi}{M+1}\\right)\n$$\nThe remaining sum evaluates to $\\sum_{k=1}^M \\cos\\left(\\frac{2k\\pi}{M+1}\\right) = -1$.\nTherefore, $\\sum_{k=1}^M \\cos^2\\left(\\frac{k\\pi}{M+1}\\right) = \\frac{M}{2} - \\frac{1}{2} = \\frac{M-1}{2}$.\n\nSubstituting these results back into the expression for the sum of squared eigenvalues:\n$$\n\\sum_{k=1}^M \\lambda_k^2 = M + 4\\rho(0) + 4\\rho^2\\left(\\frac{M-1}{2}\\right) = M + 2\\rho^2(M-1)\n$$\nThis yields a closed-form analytical expression for $M_{\\mathrm{eff}}$:\n$$\nM_{\\mathrm{eff}} = \\frac{M^2}{M + 2\\rho^2(M-1)}\n$$\nThis formula depends only on the given parameters $M$ and $\\rho$.\n\n**3. Calculation of the Global p-value**\n\nWith $M_{\\mathrm{eff}}$ determined, the global p-value is calculated by substituting $M_{\\mathrm{eff}}$ into the independent-trials formula:\n$$\np_{\\mathrm{glob}} = 1 - (1 - p_{\\mathrm{loc}})^{M_{\\mathrm{eff}}}\n$$\nFor numerical stability, especially when $p_{\\mathrm{loc}}$ is small, this is better computed using logarithmic and exponential functions. Let $x = -p_{\\mathrm{loc}}$. The term $(1 - p_{\\mathrm{loc}})^{M_{\\mathrm{eff}}} = (1+x)^{M_{\\mathrm{eff}}} = \\exp(M_{\\mathrm{eff}} \\ln(1+x))$. Using library functions `log1p` (which calculates $\\ln(1+x)$) and `expm1` (which calculates $e^y-1$) provides higher precision. The computation becomes:\n$$\np_{\\mathrm{glob}} = 1 - \\exp(M_{\\mathrm{eff}} \\cdot \\mathrm{log1p}(-p_{\\mathrm{loc}})) = -\\mathrm{expm1}(M_{\\mathrm{eff}} \\cdot \\mathrm{log1p}(-p_{\\mathrm{loc}}))\n$$\n\n**4. Algorithmic Summary**\n\nFor each test case defined by $(M, \\rho, p_{\\mathrm{loc}})$:\n1.  Calculate $M_{\\mathrm{eff}}$ using the derived analytical formula: $M_{\\mathrm{eff}} = M^2 / (M + 2\\rho^2(M-1))$.\n2.  Calculate $p_{\\mathrm{glob}}$ using the numerically stable formula: $p_{\\mathrm{glob}} = -\\mathrm{expm1}(M_{\\mathrm{eff}} \\cdot \\mathrm{log1p}(-p_{\\mathrm{loc}}))$.\n3.  Round both $M_{\\mathrm{eff}}$ and $p_{\\mathrm{glob}}$ to $12$ significant digits.\n4.  Format the results as a two-element list and aggregate them for the final output.\n\nThis approach bypasses numerical matrix diagonalization, providing a direct, exact, and efficient computation of the required quantities.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the look-elsewhere effect problem for a set of test cases.\n    \"\"\"\n\n    test_cases = [\n        # (M, rho, p_loc)\n        (100, 0.5, 2.87e-7),\n        (100, 0.0, 2.87e-7),\n        (100, 0.45, 1e-3),\n        (50, -0.45, 0.05),\n        (1000, 0.2, 1e-9),\n        (100, 0.49, 1e-6),\n    ]\n\n    def round_to_sf(x, sf):\n        \"\"\"\n        Rounds a number x to a specified number of significant figures (sf).\n        \"\"\"\n        if x == 0:\n            return 0.0\n        # Calculate the number of decimal places to round to\n        order_of_magnitude = np.floor(np.log10(np.abs(x)))\n        decimal_places = sf - 1 - int(order_of_magnitude)\n        return np.round(x, decimal_places)\n\n    results_pairs = []\n    for M, rho, p_loc in test_cases:\n        # Step 1: Calculate the effective number of trials, M_eff.\n        # This is the analytical solution derived from the eigenvalues of the\n        # specified tridiagonal correlation matrix.\n        if M == 1:\n            m_eff = 1.0\n        else:\n            m_eff = M**2 / (M + 2 * rho**2 * (M - 1))\n\n        # Step 2: Calculate the global p-value, p_glob.\n        # Use a numerically stable formula to avoid precision loss for small p_loc.\n        # p_glob = 1 - (1 - p_loc)**M_eff\n        #        = -expm1(M_eff * log1p(-p_loc))\n        p_glob = -np.expm1(m_eff * np.log1p(-p_loc))\n\n        # Step 3: Round results to 12 significant figures.\n        m_eff_rounded = round_to_sf(m_eff, 12)\n        p_glob_rounded = round_to_sf(p_glob, 12)\n\n        results_pairs.append([m_eff_rounded, p_glob_rounded])\n\n    # Step 4: Format the output as specified.\n    # We construct the string manually to ensure the exact format is met,\n    # including number representation and brackets.\n    output_parts = []\n    for pair in results_pairs:\n        # Use a general format with sufficient precision to represent the\n        # rounded numbers correctly, including scientific notation.\n        meff_str = f\"{pair[0]:.15g}\"\n        pglob_str = f\"{pair[1]:.15g}\"\n        output_parts.append(f\"[{meff_str},{pglob_str}]\")\n\n    print(f\"[{','.join(output_parts)}]\")\n\n\nsolve()\n```"
        },
        {
            "introduction": "Moving beyond discrete bins, this problem explores the look-elsewhere effect from the perspective of random field theory, a powerful framework for continuous searches. You will model the test statistic as a Gaussian random field and use the expected Euler characteristic to derive a leading-order approximation for the global p-value, $p_{\\mathrm{glob}}(u)$. This advanced technique provides a direct route to the global significance for a high threshold $u$ without relying on an intermediate $M_{\\mathrm{eff}}$, showcasing a more fundamental approach used in cutting-edge analyses. ",
            "id": "3539405",
            "problem": "Consider a one-dimensional bump hunt for a narrow resonance in a mass spectrum over a search interval of width $L=100\\,\\mathrm{GeV}$ with detector-limited correlation length $\\ell=2\\,\\mathrm{GeV}$. Under the null hypothesis, the local discovery test statistic $Z(m)$ as a function of mass $m$ can be modeled as a smooth, stationary, unit-variance Gaussian random field (GRF) on the interval. The Look-Elsewhere Effect refers to the inflation of the global false positive probability $\\mathbb{P}\\!\\left(\\sup_{m \\in [0,L]} Z(m) \\ge u\\right)$ compared to a local tail probability at a fixed $m$ due to scanning over the mass range.\n\nStarting from the definition of the excursion set $A_u=\\{m\\in[0,L]: Z(m)\\ge u\\}$ and the expected Euler characteristic (EC) heuristic for Gaussian random fields at high thresholds, derive the leading-order approximation to the global exceedance probability $p_{\\mathrm{glob}}(u)\\equiv \\mathbb{P}(\\sup Z \\ge u)$ in one dimension. Express the approximation in terms of the number of resolution elements $R$ of the search interval, where $R$ is defined by the ratio $R=L/\\ell$, and the high-threshold asymptotic density for the excursion set.\n\nUse this leading-order approximation to compute $p_{\\mathrm{glob}}(u)$ for $u=20$, with the given $L$ and $\\ell$, assuming the one-dimensional leading term dominates at such a high threshold. You may estimate $R$ directly from $L$ and $\\ell$. Provide your final numerical answer for $p_{\\mathrm{glob}}(20)$ as a dimensionless decimal in standard scientific notation, rounded to four significant figures.",
            "solution": "The user wants me to solve the following problem:\n**Problem Statement:** Consider a one-dimensional bump hunt for a narrow resonance in a mass spectrum over a search interval of width $L=100\\,\\mathrm{GeV}$ with detector-limited correlation length $\\ell=2\\,\\mathrm{GeV}$. Under the null hypothesis, the local discovery test statistic $Z(m)$ as a function of mass $m$ can be modeled as a smooth, stationary, unit-variance Gaussian random field (GRF) on the interval. The Look-Elsewhere Effect refers to the inflation of the global false positive probability $\\mathbb{P}\\!\\left(\\sup_{m \\in [0,L]} Z(m) \\ge u\\right)$ compared to a local tail probability at a fixed $m$ due to scanning over the mass range.\n\nStarting from the definition of the excursion set $A_u=\\{m\\in[0,L]: Z(m)\\ge u\\}$ and the expected Euler characteristic (EC) heuristic for Gaussian random fields at high thresholds, derive the leading-order approximation to the global exceedance probability $p_{\\mathrm{glob}}(u)\\equiv \\mathbb{P}(\\sup Z \\ge u)$ in one dimension. Express the approximation in terms of the number of resolution elements $R$ of the search interval, where $R$ is defined by the ratio $R=L/\\ell$, and the high-threshold asymptotic density for the excursion set.\n\nUse this leading-order approximation to compute $p_{\\mathrm{glob}}(u)$ for $u=20$, with the given $L$ and $\\ell$, assuming the one-dimensional leading term dominates at such a high threshold. You may estimate $R$ directly from $L$ and $\\ell$. Provide your final numerical answer for $p_{\\mathrm{glob}}(20)$ as a dimensionless decimal in standard scientific notation, rounded to four significant figures.\n\n### Step 1: Extract Givens\n-   Search interval width: $L=100\\,\\mathrm{GeV}$\n-   Correlation length: $\\ell=2\\,\\mathrm{GeV}$\n-   Test statistic $Z(m)$ is a smooth, stationary, unit-variance Gaussian random field (GRF) on the interval $[0, L]$.\n-   Excursion set: $A_u=\\{m\\in[0,L]: Z(m)\\ge u\\}$\n-   Global exceedance probability: $p_{\\mathrm{glob}}(u)=\\mathbb{P}(\\sup_{m \\in [0,L]} Z(m) \\ge u)$\n-   Number of resolution elements: $R=L/\\ell$\n-   Threshold for calculation: $u=20$\n-   Task 1: Derive the leading-order approximation for $p_{\\mathrm{glob}}(u)$ using the Euler characteristic (EC) heuristic.\n-   Task 2: Compute the numerical value of $p_{\\mathrm{glob}}(20)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded. The modeling of a test statistic distribution as a Gaussian random field and the use of the expected Euler characteristic (or, in one dimension, the Kac-Rice formula for upcrossings) to approximate the global p-value considering the look-elsewhere effect is a standard and well-established method in statistics and its application in high-energy physics. The problem is well-posed, providing all necessary information ($L$, $\\ell$, the GRF model, the approximation method) to derive a unique solution. The language is objective and precise. The problem is complete and internally consistent.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Derivation and Solution\nThe problem asks for the leading-order approximation of the global exceedance probability, $p_{\\mathrm{glob}}(u) = \\mathbb{P}(\\sup_{m \\in [0,L]} Z(m) \\ge u)$, using the expected Euler characteristic (EC) heuristic. For a sufficiently high threshold $u$, the probability is well-approximated by the expected EC of the excursion set $A_u = \\{m \\in [0,L] : Z(m) \\ge u\\}$.\n$$ p_{\\mathrm{glob}}(u) \\approx \\mathbb{E}[\\chi(A_u)] $$\nFor a one-dimensional domain, the Euler characteristic $\\chi(A_u)$ of the excursion set is the number of its disjoint connected components. At a high threshold, these components are typically small, isolated intervals, and their number is equal to the number of times the process $Z(m)$ crosses the level $u$ from below (an \"upcrossing\"). Therefore, the leading-order approximation is given by the expected number of upcrossings, $\\mathbb{E}[N_u]$.\n$$ p_{\\mathrm{glob}}(u) \\approx \\mathbb{E}[N_u] $$\nThis is the leading term in the expansion of $\\mathbb{E}[\\chi(A_u)]$, which is proportional to the size of the search region $L$. The problem statement confirms we should use this term, as it \"dominates at such a high threshold.\"\n\nThe expected number of upcrossings is given by the Kac-Rice formula. For a stationary process $Z(m)$ on an interval of length $L$, this is:\n$$ \\mathbb{E}[N_u] = L \\int_0^\\infty z' p(u, z') \\, dz' $$\nwhere $p(z, z')$ is the joint probability density function (PDF) of the process $Z(m)$ and its derivative $Z'(m)$ at any given point $m$.\n\nFor a stationary, unit-variance ($ \\mathrm{Var}(Z)=1 $) GRF, $Z(m)$ and its derivative $Z'(m)$ are independent Gaussian random variables. We have $Z(m) \\sim \\mathcal{N}(0, 1)$ and $Z'(m) \\sim \\mathcal{N}(0, \\sigma'^2)$, where $\\sigma'^2 = \\mathrm{Var}(Z'(m))$. Their respective PDFs are $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2)$ and $p(z') = \\frac{1}{\\sigma'\\sqrt{2\\pi}} \\exp(-\\frac{1}{2}(z'/\\sigma')^2)$.\nThe joint PDF is $p(z, z') = p(z)p(z') = \\phi(z) \\frac{1}{\\sigma'} \\phi(z'/\\sigma')$.\n\nSubstituting this into the Kac-Rice formula at $z=u$:\n$$ \\mathbb{E}[N_u] = L \\, \\phi(u) \\int_0^\\infty z' \\frac{1}{\\sigma'\\sqrt{2\\pi}} \\exp\\left(-\\frac{z'^2}{2\\sigma'^2}\\right) \\, dz' $$\nThe integral can be solved by substitution. Let $y = z'/\\sigma'$, so $dz' = \\sigma' dy$.\n$$ \\int_0^\\infty z' p(z') \\, dz' = \\int_0^\\infty (\\sigma'y) \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{y^2}{2}\\right) \\, dy = \\frac{\\sigma'}{\\sqrt{2\\pi}} \\int_0^\\infty y \\exp\\left(-\\frac{y^2}{2}\\right) \\, dy $$\nThe integral evaluates to $\\left[-\\exp(-y^2/2)\\right]_0^\\infty = 1$. Thus, the integral part of the expression is $\\sigma'/\\sqrt{2\\pi}$.\nSubstituting this result back, we get:\n$$ \\mathbb{E}[N_u] = L \\, \\phi(u) \\frac{\\sigma'}{\\sqrt{2\\pi}} = L \\left(\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{u^2}{2}\\right)\\right) \\frac{\\sigma'}{\\sqrt{2\\pi}} = L \\frac{\\sigma'}{2\\pi} \\exp\\left(-\\frac{u^2}{2}\\right) $$\nThe variance of the derivative, $\\sigma'^2$, is related to the autocorrelation function of the process, $C(\\Delta m) = \\mathbb{E}[Z(m)Z(m+\\Delta m)]$, by $\\sigma'^2 = -C''(0)$. For a smooth process with correlation length $\\ell$, a canonical choice for the correlation function is a Gaussian kernel:\n$$ C(\\Delta m) = \\exp\\left(-\\frac{(\\Delta m)^2}{2\\ell^2}\\right) $$\nThe first and second derivatives with respect to $\\Delta m$ are:\n$$ C'(\\Delta m) = -\\frac{\\Delta m}{\\ell^2} \\exp\\left(-\\frac{(\\Delta m)^2}{2\\ell^2}\\right) $$\n$$ C''(\\Delta m) = \\left(-\\frac{1}{\\ell^2} + \\frac{(\\Delta m)^2}{\\ell^4}\\right) \\exp\\left(-\\frac{(\\Delta m)^2}{2\\ell^2}\\right) $$\nEvaluating at $\\Delta m = 0$:\n$$ C''(0) = -\\frac{1}{\\ell^2} $$\nTherefore, the variance of the derivative is $\\sigma'^2 = -C''(0) = 1/\\ell^2$, which implies $\\sigma' = 1/\\ell$.\n\nSubstituting $\\sigma' = 1/\\ell$ into the expression for $\\mathbb{E}[N_u]$:\n$$ p_{\\mathrm{glob}}(u) \\approx \\mathbb{E}[N_u] = \\frac{L}{\\ell} \\frac{1}{2\\pi} \\exp\\left(-\\frac{u^2}{2}\\right) $$\nThe problem defines the number of resolution elements as $R = L/\\ell$. The final derived expression for the leading-order approximation is:\n$$ p_{\\mathrm{glob}}(u) \\approx \\frac{R}{2\\pi} \\exp\\left(-\\frac{u^2}{2}\\right) $$\nThis expression relates the global probability to the number of effective independent search regions $R$ and a Gaussian suppression factor.\n\nNow, we compute the numerical value for the given parameters: $L=100\\,\\mathrm{GeV}$, $\\ell=2\\,\\mathrm{GeV}$, and $u=20$.\nFirst, calculate the number of resolution elements $R$:\n$$ R = \\frac{L}{\\ell} = \\frac{100}{2} = 50 $$\nNext, substitute $R=50$ and $u=20$ into the derived formula:\n$$ p_{\\mathrm{glob}}(20) \\approx \\frac{50}{2\\pi} \\exp\\left(-\\frac{20^2}{2}\\right) = \\frac{25}{\\pi} \\exp\\left(-\\frac{400}{2}\\right) = \\frac{25}{\\pi} \\exp(-200) $$\nUsing a calculator for the numerical values:\n$$ \\frac{25}{\\pi} \\approx 7.95774715459... $$\n$$ \\exp(-200) \\approx 1.3838965267 \\times 10^{-87} $$\nMultiplying these values:\n$$ p_{\\mathrm{glob}}(20) \\approx (7.95774715459) \\times (1.3838965267 \\times 10^{-87}) \\approx 11.01186 \\times 10^{-87} $$\nExpressing this in standard scientific notation ($a \\times 10^b$ where $1 \\le |a|  10$):\n$$ p_{\\mathrm{glob}}(20) \\approx 1.101186 \\times 10^{-86} $$\nRounding to four significant figures as requested:\n$$ p_{\\mathrm{glob}}(20) \\approx 1.101 \\times 10^{-86} $$",
            "answer": "$$\\boxed{1.101 \\times 10^{-86}}$$"
        },
        {
            "introduction": "This final practice connects the abstract concepts of the look-elsewhere effect to the practical realm of experimental sensitivity studies. You will calculate the \"cost\" of a search by determining the minimum signal strength $\\mu$ required to achieve a discovery, given an effective trials factor $M_{\\mathrm{eff}}$. This exercise translates the statistical penalty of the look-elsewhere effect into a tangible requirement on the signal strength, quantifying the sensitivity loss inherent in searching for a signal of unknown location. ",
            "id": "3539395",
            "problem": "You are tasked with quantifying the sensitivity loss from the look-elsewhere effect in a one-dimensional bump hunt typical of computational high-energy physics. Consider a search that scans over a mass spectrum with an effective number of independent trials denoted by $M_{\\mathrm{eff}}$, in which each mass hypothesis is treated as a counting experiment with expected background yield $b$ and a signal model with expected yield $s_{0}$ at unit signal strength. The actual signal strength multiplier is denoted by $\\mu$, giving an expected signal yield $s(\\mu) = \\mu s_{0}$. Assume that the search employs a likelihood-ratio-based local test at each mass value and aggregates across the scan using an effective trials factor characterized by $M_{\\mathrm{eff}}$.\n\nStarting from the definitions of the Poisson likelihood for counts, the concept of the profile likelihood ratio, and the standard mapping from tail probabilities to Gaussian-equivalent significance via the Cumulative Distribution Function (CDF) of the standard normal distribution, derive a method to compute the minimal signal strength $\\mu$ such that the global significance $Z_{\\mathrm{glob}}(\\mu)$ reaches or exceeds the discovery threshold of $5$ (five sigma). Then, quantify the corresponding local median significance $Z_{\\mathrm{loc}}(\\mu)$ at that same minimal $\\mu$ to illustrate the sensitivity gap introduced by the look-elsewhere effect.\n\nScientific realism and universal applicability requirements:\n- Treat $b$ and $s_{0}$ as dimensionless expected counts.\n- The angle unit does not apply.\n- The program must implement a numerically stable and logically sound procedure that starts from the definitions of Poisson likelihood-based testing and the standard normal tail probability mapping, without relying on ad hoc or purely empirical shortcuts.\n\nYour program should implement the following tasks in a fully deterministic way:\n1. For each test case $(M_{\\mathrm{eff}}, b, s_{0})$, compute the minimal $\\mu$ such that $Z_{\\mathrm{glob}}(\\mu) \\ge 5$, and report that minimal $\\mu$ along with the corresponding $Z_{\\mathrm{loc}}(\\mu)$ evaluated at that $\\mu$.\n2. Use a robust numerical search method justified from the monotonicity properties of the likelihood-based significance with respect to $\\mu$.\n\nTest suite:\n- Case $1$: $M_{\\mathrm{eff}} = 1$, $b = 100$, $s_{0} = 5$.\n- Case $2$: $M_{\\mathrm{eff}} = 100$, $b = 100$, $s_{0} = 5$.\n- Case $3$: $M_{\\mathrm{eff}} = 10000$, $b = 1000$, $s_{0} = 10$.\n- Case $4$: $M_{\\mathrm{eff}} = 500$, $b = 1$, $s_{0} = 1$.\n- Case $5$: $M_{\\mathrm{eff}} = 1000$, $b = 10000$, $s_{0} = 50$.\n\nAnswer specification:\n- For each test case, produce a list containing two floats: the minimal $\\mu$ and $Z_{\\mathrm{loc}}(\\mu)$ evaluated at that $\\mu$.\n- All outputs must be unitless.\n- Express floats in decimal form rounded to six digits after the decimal point.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the five test cases as a comma-separated list of lists, enclosed in square brackets, for example: $[\\,[\\mu_{1}, Z_{\\mathrm{loc},1}], [\\mu_{2}, Z_{\\mathrm{loc},2}], \\dots\\,]$.",
            "solution": "The user-provided problem has been critically validated and is determined to be scientifically grounded, well-posed, and objective. It outlines a standard, albeit non-trivial, sensitivity calculation in high-energy physics. The problem is free of scientific flaws, contradictions, or ambiguities. All provided parameters are sufficient for deriving a unique and meaningful solution.\n\nThe problem requires us to quantify the loss of sensitivity due to the look-elsewhere effect in a one-dimensional search. This involves finding the minimal signal strength $\\mu$ that yields a global significance of $5\\sigma$ and determining the corresponding local significance. The solution proceeds by first establishing the statistical framework for a local search and then extending it to a global context using the provided effective trials factor $M_{\\mathrm{eff}}$.\n\nThe core of a local search (a \"bump hunt\" at a fixed mass) is a counting experiment. The number of observed events $n$ is modeled as a Poisson-distributed random variable. The mean of this distribution is the sum of the expected background events, $b$, and the expected signal events, $s(\\mu) = \\mu s_0$. The parameter $\\mu$ is the signal strength multiplier. The problem assumes $b$ and $s_0$ are known constants. The Poisson likelihood function for observing $n$ events given a signal strength $\\mu$ is:\n$$ L(\\mu) = \\frac{(\\mu s_0 + b)^n e^{-(\\mu s_0 + b)}}{n!} $$\n\nTo test for the presence of a signal, we compare the background-only hypothesis ($\\mathcal{H}_0$, where $\\mu=0$) to the signal-plus-background hypothesis ($\\mathcal{H}_1$, where $\\mu0$). The standard test statistic for discovery is the profile likelihood ratio, $q_0$:\n$$ q_0 = -2 \\ln \\frac{L(\\mu=0)}{L(\\hat{\\mu})} $$\nwhere $\\hat{\\mu}$ is the value of $\\mu$ that maximizes the likelihood $L(\\mu)$ for the given data $n$. The value $\\hat{\\mu}$ is constrained to be non-negative, as a negative signal strength is unphysical. Maximizing $L(\\mu)$ is equivalent to maximizing $\\ln L(\\mu)$. The derivative of $\\ln L(\\mu)$ with respect to $\\mu$ is:\n$$ \\frac{d}{d\\mu} \\ln L(\\mu) = \\frac{n s_0}{\\mu s_0 + b} - s_0 $$\nSetting the derivative to zero gives $\\hat{\\mu} s_0 + b = n$, or $\\hat{\\mu} = (n-b)/s_0$. If $n \\le b$, the unconstrained maximum is at a negative $\\mu$, so the maximum in the physical region $\\mu \\ge 0$ is at $\\hat{\\mu}=0$.\nThus, the test statistic is:\n$$ q_0 = \\begin{cases} -2 \\ln \\frac{L(0)}{L(\\hat{\\mu})}  \\text{if } n  b \\\\ 0  \\text{if } n \\le b \\end{cases} $$\nSubstituting the likelihood expressions, for $nb$ we have $L(\\hat{\\mu}) = \\frac{n^n e^{-n}}{n!}$ and $L(0) = \\frac{b^n e^{-b}}{n!}$. The ratio becomes $\\frac{L(0)}{L(\\hat{\\mu})} = \\left(\\frac{b}{n}\\right)^n e^{n-b}$.\nThis gives:\n$$ q_0 = -2 \\left[ n \\ln\\left(\\frac{b}{n}\\right) + n-b \\right] = 2 \\left[ n \\ln\\left(\\frac{n}{b}\\right) - (n-b) \\right] $$\n\nTo calculate the *median* significance for a given true signal strength $\\mu$, we use the Asimov dataset. In this procedure, the observed data $n$ is replaced by its expected value under the hypothesis of a signal with strength $\\mu$, i.e., $n_A = \\mu s_0 + b$. Since discovery sensitivity studies assume $\\mu0$ (and $s_00$), we have $n_A  b$, and we can use the main formula for $q_0$. Substituting $n_A$ for $n$ gives the Asimov test statistic $q_{0,A}$:\n$$ q_{0,A}(\\mu) = 2 \\left[ (\\mu s_0 + b) \\ln\\left(\\frac{\\mu s_0 + b}{b}\\right) - ((\\mu s_0 + b) - b) \\right] $$\n$$ q_{0,A}(\\mu) = 2 \\left[ (\\mu s_0 + b) \\ln\\left(1 + \\frac{\\mu s_0}{b}\\right) - \\mu s_0 \\right] $$\nThe local significance, $Z_{\\mathrm{loc}}$, is related to the test statistic by $Z_{\\mathrm{loc}} = \\sqrt{q_0}$ (a result from Wilks' Theorem). The median local significance is therefore:\n$$ Z_{\\mathrm{loc}}(\\mu) = \\sqrt{q_{0,A}(\\mu)} = \\sqrt{2 \\left[ (\\mu s_0 + b) \\ln\\left(1 + \\frac{\\mu s_0}{b}\\right) - \\mu s_0 \\right]} $$\nThis function is monotonically increasing with $\\mu$ for $\\mu  0$.\n\nNext, we relate local significance to global significance. Significance $Z$ is defined via the tail probability (p-value) of the standard normal distribution $\\Phi(Z)$:\n$$ p = 1 - \\Phi(Z) $$\nwhere $p$ is the probability of a background-only fluctuation producing a result at least as signal-like as the one observed. The inverse relation is $Z = \\Phi^{-1}(1-p)$.\n\nThe look-elsewhere effect is accounted for using the effective number of independent trials, $M_{\\mathrm{eff}}$. The global p-value $p_{\\mathrm{glob}}$ is related to the local p-value $p_{\\mathrm{loc}}$\nby the Bonferroni correction:\n$$ p_{\\mathrm{glob}} \\approx M_{\\mathrm{eff}} \\cdot p_{\\mathrm{loc}} $$\nThis approximation is valid for small p-values, which is the case for high-significance searches. The problem provides $M_{\\mathrm{eff}}$ as an input, making this relationship definitional.\nCombining these relations, we get a mapping between local and global significance:\n$$ 1 - \\Phi(Z_{\\mathrm{glob}}) = M_{\\mathrm{eff}} \\left[ 1 - \\Phi(Z_{\\mathrm{loc}}) \\right] $$\n\nThe problem requires finding the minimal $\\mu$ that achieves a global significance $Z_{\\mathrm{glob}} \\ge 5$. We solve for the boundary case, $Z_{\\mathrm{glob}} = 5$.\nFirst, we find the required local significance, $Z_{\\mathrm{loc}}^{\\mathrm{req}}$, that corresponds to a global significance of $5$.\n1.  Calculate the target global p-value: $p_{\\mathrm{glob}}^{\\mathrm{target}} = 1 - \\Phi(5)$.\n2.  Calculate the required local p-value: $p_{\\mathrm{loc}}^{\\mathrm{req}} = p_{\\mathrm{glob}}^{\\mathrm{target}} / M_{\\mathrm{eff}}$.\n3.  Calculate the required local significance: $Z_{\\mathrm{loc}}^{\\mathrm{req}} = \\Phi^{-1}(1 - p_{\\mathrm{loc}}^{\\mathrm{req}})$.\n\nFinally, we must find the signal strength $\\mu$ that produces this required local significance. We solve the following equation for $\\mu$:\n$$ Z_{\\mathrm{loc}}(\\mu) = Z_{\\mathrm{loc}}^{\\mathrm{req}} $$\nSquaring both sides to simplify the numerical search:\n$$ 2 \\left[ (\\mu s_0 + b) \\ln\\left(1 + \\frac{\\mu s_0}{b}\\right) - \\mu s_0 \\right] = (Z_{\\mathrm{loc}}^{\\mathrm{req}})^2 $$\nThis is a transcendental equation for $\\mu$. Since the left-hand side is monotonic in $\\mu$, we can employ a robust numerical root-finding method like bisection. We seek the root of the function:\n$$ f(\\mu) = 2 \\left[ (\\mu s_0 + b) \\ln\\left(1 + \\frac{\\mu s_0}{b}\\right) - \\mu s_0 \\right] - (Z_{\\mathrm{loc}}^{\\mathrm{req}})^2 $$\nThe search interval for $\\mu$ can be established by noting that $f(0)  0$ and then finding an upper bound $\\mu_{\\mathrm{high}}$ for which $f(\\mu_{\\mathrm{high}})  0$. The root of $f(\\mu)=0$ is the minimal signal strength $\\mu^*$ we seek. The corresponding local significance is $Z_{\\mathrm{loc}}(\\mu^*) = Z_{\\mathrm{loc}}^{\\mathrm{req}}$.\n\nThe procedure for each test case $(M_{\\mathrm{eff}}, b, s_0)$ is:\n1.  Calculate $Z_{\\mathrm{loc}}^{\\mathrm{req}}$ from $M_{\\mathrm{eff}}$ and the target $Z_{\\mathrm{glob}}=5$.\n2.  Numerically solve the equation $f(\\mu)=0$ to find $\\mu^*$.\n3.  Report the pair $[\\mu^*, Z_{\\mathrm{loc}}^{\\mathrm{req}}]$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes the minimal signal strength mu for a 5-sigma global discovery\n    and the corresponding local significance, accounting for the look-elsewhere effect.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 100, 5),     # M_eff, b, s0\n        (100, 100, 5),\n        (10000, 1000, 10),\n        (500, 1, 1),\n        (1000, 10000, 50),\n    ]\n\n    results = []\n    \n    # The discovery threshold for global significance\n    Z_GLOB_TARGET = 5.0\n\n    def calculate_mu_and_z_loc(M_eff, b, s0):\n        \"\"\"\n        Calculates the minimal mu and corresponding Z_loc for a single case.\n        \"\"\"\n        # 1. Calculate the target global p-value for Z_glob = 5\n        # Use norm.sf (survival function, 1-cdf) for better precision in the far tail\n        p_glob_target = norm.sf(Z_GLOB_TARGET)\n\n        # 2. Calculate the required local p-value using the trials factor\n        # If M_eff makes p_loc = 1, it's an unphysical scenario, but the code handles it.\n        p_loc_req = min(p_glob_target / M_eff, 1.0)\n\n        # 3. Calculate the required local significance from the local p-value\n        # Use norm.isf (inverse survival function) for precision\n        Z_loc_req = norm.isf(p_loc_req)\n\n        # 4. Define the function whose root we need to find.\n        # This function represents Z_loc_squared(mu) - Z_loc_req_squared = 0\n        Z_loc_req_sq = Z_loc_req**2\n        \n        def objective_func(mu):\n            if mu = 0:\n                return -Z_loc_req_sq\n            \n            s = mu * s0\n            \n            # The Asimov test statistic q_{0,A} is Z_loc_squared\n            # q_0A = 2 * ((s + b) * ln(1 + s/b) - s)\n            term1 = s + b\n            term2 = np.log1p(s / b) # log1p(x) is ln(1+x), more accurate for small x\n            q_0A = 2 * (term1 * term2 - s)\n            \n            return q_0A - Z_loc_req_sq\n\n        # 5. Use a bisection method to find the root mu.\n        # Bisection is robust due to the monotonicity of the objective function.\n        mu_low = 0.0\n        mu_high = 1.0\n        \n        # Find an upper bound for the search interval\n        # The objective function is monotonic, so g(mu_high) must be  0\n        while objective_func(mu_high)  0:\n            mu_high *= 2.0\n            if mu_high  1e6: # Safety break for pathological cases\n                raise RuntimeError(\"Failed to bracket root for mu.\")\n\n        # Bisection search\n        tolerance = 1e-9\n        max_iterations = 100\n        for _ in range(max_iterations):\n            mu_mid = (mu_low + mu_high) / 2\n            if mu_mid == mu_low or mu_mid == mu_high: # Reached precision limit\n                break\n            \n            g_mid = objective_func(mu_mid)\n            \n            if g_mid  0:\n                mu_low = mu_mid\n            else:\n                mu_high = mu_mid\n            \n            if (mu_high - mu_low)  tolerance:\n                break\n        \n        minimal_mu = (mu_low + mu_high) / 2\n        \n        return [minimal_mu, Z_loc_req]\n\n    for case in test_cases:\n        M_eff, b, s0 = case\n        mu, z_loc = calculate_mu_and_z_loc(M_eff, b, s0)\n        # Format the numbers to six decimal places as required.\n        results.append(f\"[{mu:.6f},{z_loc:.6f}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}