{
    "hands_on_practices": [
        {
            "introduction": "The first step in understanding any physical concept is to apply its definition in a simple, well-understood context. This practice grounds the abstract definition of a Marginally Outer Trapped Surface (MOTS) by requiring a direct, analytical calculation for the static Schwarzschild spacetime. By starting from the fundamental expression for the outgoing null expansion $\\Theta_{(\\ell)}$ and the metric in isotropic coordinates, you will derive the location of the apparent horizon from first principles, a foundational skill in gravitational physics .",
            "id": "3464010",
            "problem": "Consider the Schwarzschild spacetime expressed in isotropic coordinates on a time-symmetric slice, where the extrinsic curvature $K_{ij}$ of the slice vanishes. The spatial three-metric on a constant-time hypersurface is conformally flat and can be written as\n$$\n\\gamma_{ij}\\,dx^{i}\\,dx^{j} = \\psi(r)^{4}\\left(dr^{2} + r^{2}\\,d\\Omega^{2}\\right),\n$$\nwith conformal factor $\\psi(r) = 1 + \\frac{M}{2 r}$ for mass parameter $M0$. In the language of apparent horizon finding, the outgoing null expansion $\\Theta_{(\\ell)}$ of a closed two-surface $\\mathcal{S}$ embedded in the slice is defined by the fundamental relation\n$$\n\\Theta_{(\\ell)} = D_{i} s^{i} + K_{ij} s^{i} s^{j} - K,\n$$\nwhere $D_{i}$ is the covariant derivative compatible with $\\gamma_{ij}$, $s^{i}$ is the outward-pointing unit normal to $\\mathcal{S}$ within the slice, and $K = \\gamma^{ij} K_{ij}$ is the trace of the extrinsic curvature. A Marginally Outer Trapped Surface (MOTS) is a closed two-surface for which $\\Theta_{(\\ell)} = 0$.\n\nUsing only these definitions and the given metric, take the spherically symmetric ansatz $\\mathcal{S}$ given by a coordinate sphere at constant isotropic radius $r = \\text{const}$. Derive an explicit expression for $\\Theta_{(\\ell)}(r)$ on the time-symmetric slice, and solve the MOTS equation $\\Theta_{(\\ell)}(r) = 0$ to obtain the isotropic radius $r_{\\text{AH}}$ of the apparent horizon as a function of $M$. Then numerically verify your analytic result by evaluating your derived $\\Theta_{(\\ell)}(r)$ at $r = r_{\\text{AH}}$ for the specific choice $M = 1$ using geometric units.\n\nReport the final answer as the closed-form analytic expression for $r_{\\text{AH}}$ in terms of $M$. No rounding is required, and no units should be included in the final answer.",
            "solution": "The problem as stated is valid. It is scientifically grounded in the principles of general relativity, specifically concerning the Schwarzschild metric and the concept of apparent horizons (Marginally Outer Trapped Surfaces, or MOTS). The problem is well-posed, providing a clear, self-contained set of definitions and a metric, leading to a request for a specific derivation and solution. There are no contradictions, ambiguities, or factual unsoundness.\n\nWe are asked to find the isotropic radius of the apparent horizon on a time-symmetric slice of the Schwarzschild spacetime.\n\nFirst, we simplify the given expression for the outgoing null expansion, $\\Theta_{(\\ell)}$. The slice is time-symmetric, which means the extrinsic curvature tensor $K_{ij}$ is zero. This implies that its trace, $K = \\gamma^{ij}K_{ij}$, is also zero. The formula for the expansion thus reduces to:\n$$\n\\Theta_{(\\ell)} = D_{i} s^{i}\n$$\nwhere $D_{i}$ is the covariant derivative associated with the spatial three-metric $\\gamma_{ij}$, and $s^{i}$ is the outward-pointing unit normal vector to the two-surface $\\mathcal{S}$ within the slice. This expression, $D_i s^i$, is the divergence of the unit normal field.\n\nThe spatial metric is given in isotropic coordinates $(r, \\theta, \\phi)$ as:\n$$\n\\gamma_{ij}\\,dx^{i}\\,dx^{j} = \\psi(r)^{4}\\left(dr^{2} + r^{2}\\,d\\Omega^{2}\\right) = \\psi(r)^{4} dr^2 + \\psi(r)^4 r^2 d\\theta^2 + \\psi(r)^4 r^2 \\sin^2\\theta d\\phi^2\n$$\nwith the conformal factor $\\psi(r) = 1 + \\frac{M}{2r}$. This metric is diagonal, with components:\n$$\n\\gamma_{rr} = \\psi(r)^{4}, \\quad \\gamma_{\\theta\\theta} = \\psi(r)^{4} r^{2}, \\quad \\gamma_{\\phi\\phi} = \\psi(r)^{4} r^{2} \\sin^{2}\\theta\n$$\nThe determinant of the metric is $\\gamma = \\det(\\gamma_{ij}) = \\gamma_{rr}\\gamma_{\\theta\\theta}\\gamma_{\\phi\\phi} = \\psi(r)^{12} r^{4} \\sin^{2}\\theta$. Its square root is $\\sqrt{\\gamma} = \\psi(r)^{6} r^{2} \\sin\\theta$.\n\nThe surface $\\mathcal{S}$ is a sphere of constant coordinate radius, which can be described by the level-set function $f(r, \\theta, \\phi) = r - \\text{const} = 0$. The covariant normal vector $n_i$ is given by the gradient of $f$:\n$$\nn_i = \\partial_i f = (1, 0, 0)\n$$\nThe contravariant components $n^i$ are found by raising the index with the inverse metric, $n^i = \\gamma^{ij}n_j$. The non-zero components of the inverse metric $\\gamma^{ij}$ are $\\gamma^{rr} = \\psi(r)^{-4}$, $\\gamma^{\\theta\\theta} = \\psi(r)^{-4}r^{-2}$, and $\\gamma^{\\phi\\phi} = \\psi(r)^{-4}r^{-2}\\sin^{-2}\\theta$. This gives:\n$$\nn^r = \\gamma^{rr} n_r = \\psi(r)^{-4} \\times 1 = \\psi(r)^{-4}\n$$\nand $n^\\theta = n^\\phi = 0$. The magnitude-squared of this normal vector is $|n|^2 = \\gamma_{ij}n^i n^j = \\gamma_{rr}(n^r)^2 = \\psi(r)^{4}(\\psi(r)^{-4})^2 = \\psi(r)^{-4}$. The magnitude is thus $|n| = \\psi(r)^{-2}$. The outward-pointing unit normal vector $s^i$ is $s^i = n^i/|n|$:\n$$\ns^i = \\frac{(\\psi(r)^{-4}, 0, 0)}{\\psi(r)^{-2}} = (\\psi(r)^{-2}, 0, 0)\n$$\n\nNow we can compute the divergence $\\Theta_{(\\ell)} = D_i s^i$. Using the standard formula for divergence in curvilinear coordinates:\n$$\nD_i s^i = \\frac{1}{\\sqrt{\\gamma}} \\partial_j (\\sqrt{\\gamma} s^j)\n$$\nSince only the $r$-component of $s^i$ is non-zero, this simplifies to:\n$$\n\\Theta_{(\\ell)} = \\frac{1}{\\sqrt{\\gamma}} \\partial_r (\\sqrt{\\gamma} s^r) = \\frac{1}{\\psi^6 r^2 \\sin\\theta} \\partial_r(\\psi^6 r^2 \\sin\\theta \\cdot \\psi^{-2}) = \\frac{1}{\\psi^6 r^2 \\sin\\theta} \\partial_r(\\psi^4 r^2 \\sin\\theta)\n$$\nThe term $\\sin\\theta$ is constant with respect to $r$. We use the product rule to differentiate $\\psi^4 r^2$:\n$$\n\\partial_r(\\psi^4 r^2) = (\\partial_r \\psi^4) r^2 + \\psi^4 (\\partial_r r^2) = (4\\psi^3 \\psi') r^2 + \\psi^4(2r)\n$$\nwhere $\\psi' = \\frac{d\\psi}{dr} = \\frac{d}{dr}\\left(1 + \\frac{M}{2r}\\right) = -\\frac{M}{2r^2}$. Substituting this in:\n$$\n\\partial_r(\\psi^4 r^2) = 4\\psi^3 \\left(-\\frac{M}{2r^2}\\right) r^2 + 2r\\psi^4 = -2M\\psi^3 + 2r\\psi^4 = 2\\psi^3(r\\psi - M)\n$$\nWe now substitute the expression for $\\psi(r)$ into the parenthetical term:\n$$\nr\\psi - M = r\\left(1+\\frac{M}{2r}\\right) - M = r + \\frac{M}{2} - M = r - \\frac{M}{2}\n$$\nTherefore, the derivative is $\\partial_r(\\psi^4 r^2) = 2\\psi^3(r - \\frac{M}{2})$.\nPutting everything back into the expression for $\\Theta_{(\\ell)}$:\n$$\n\\Theta_{(\\ell)}(r) = \\frac{1}{\\psi^6 r^2 \\sin\\theta} \\left[ 2\\psi^3\\left(r - \\frac{M}{2}\\right) \\sin\\theta \\right] = \\frac{2(r - \\frac{M}{2})}{\\psi^3 r^2}\n$$\nThis is the required explicit expression for the outgoing null expansion $\\Theta_{(\\ell)}(r)$ on the surface of a sphere of isotropic radius $r$.\n\nA MOTS (the apparent horizon) is defined by the condition $\\Theta_{(\\ell)}(r) = 0$. We solve the equation for the apparent horizon radius, $r_{\\text{AH}}$:\n$$\n\\frac{2(r_{\\text{AH}} - \\frac{M}{2})}{\\psi(r_{\\text{AH}})^3 r_{\\text{AH}}^2} = 0\n$$\nFor a physical black hole, we are interested in solutions with $r_{\\text{AH}}  0$ and $M  0$. In this regime, the denominator is strictly positive, since $\\psi(r) = 1 + \\frac{M}{2r}  1$. The equation is satisfied if and only if the numerator is zero:\n$$\n2\\left(r_{\\text{AH}} - \\frac{M}{2}\\right) = 0\n$$\nThis yields the solution for the isotropic radius of the apparent horizon:\n$$\nr_{\\text{AH}} = \\frac{M}{2}\n$$\n\nFinally, we verify this result as requested. For the case $M=1$, we have $r_{\\text{AH}}=\\frac{1}{2}$. We evaluate our derived expression for $\\Theta_{(\\ell)}(r)$ at $r=r_{\\text{AH}}$ with $M=1$:\n$$\n\\Theta_{(\\ell)}\\left(r=\\frac{1}{2}\\right) = \\frac{2\\left(\\frac{1}{2} - \\frac{M}{2}\\right)}{\\psi\\left(\\frac{1}{2}\\right)^3 \\left(\\frac{1}{2}\\right)^2} \\Bigg|_{M=1} = \\frac{2\\left(\\frac{1}{2} - \\frac{1}{2}\\right)}{\\psi\\left(\\frac{1}{2}\\right)^3 \\left(\\frac{1}{4}\\right)} = \\frac{2(0)}{\\left(1+\\frac{1}{2(1/2)}\\right)^3 \\left(\\frac{1}{4}\\right)} = 0\n$$\nThe result is indeed zero, which numerically verifies the analytic solution.",
            "answer": "$$\n\\boxed{\\frac{M}{2}}\n$$"
        },
        {
            "introduction": "Moving from idealized coordinates to those used in modern simulations, this exercise explores the apparent horizon on a 'trumpet' slice, which is characteristic of the moving puncture method for evolving black holes. While the physical size of the horizon, given by the areal radius $R=2M$, is independent of the coordinate system, its location in those coordinates is not. This practice will guide you through deriving this coordinate location for a non-trivial slice and implementing a numerical root-finder to locate it, bridging the gap between analytical theory and computational practice .",
            "id": "3464001",
            "problem": "Consider a non-spinning Schwarzschild black hole of mass $M$ in geometrized units where the gravitational constant $G$ and the speed of light $c$ satisfy $G=c=1$. In the $3+1$ formulation of General Relativity, define the apparent horizon as the outermost closed two-surface on a spatial slice for which the outgoing null expansion is zero. For spherically symmetric spacetimes, the outgoing null expansion $\\Theta_+$ of a round two-sphere of areal radius $R$ is determined by the Misner-Sharp mass $m(R)$ through the invariant relation $$1 - \\frac{2 m(R)}{R} = g^{ab} \\nabla_a R \\nabla_b R,$$ and in vacuum Schwarzschild spacetime one has $m(R)=M$ (constant). Conclude that the apparent horizon is located at areal radius $R=2M$ independent of the slicing.\n\nIn trumpet slicing used in moving puncture evolutions, the stationary slice geometry near the puncture exhibits a conformal factor that diverges like $1/\\sqrt{r}$, which leads to a finite limiting areal radius at the puncture. Consider the following analytically specified spherically symmetric, conformally flat spatial metric on a slice,\n$$\\gamma_{ij} = \\psi^4(r)\\,\\delta_{ij},\\qquad \\psi(r) = 1 + \\frac{b}{\\sqrt{r}},$$\nwhere $r$ is the isotropic coordinate radius, and $b0$ is a constant controlling the trumpet’s cylindrical end radius. The areal radius of coordinate spheres is given by\n$$R(r) = \\psi^2(r)\\,r = \\big(\\sqrt{r} + b\\big)^2.$$\nThis slice captures the characteristic trumpet behavior near the puncture ($\\psi \\sim b/\\sqrt{r}$) and is asymptotically flat ($\\psi \\to 1$ as $r \\to \\infty$).\n\nYour tasks are:\n1. Starting from the definition of the apparent horizon via vanishing outgoing expansion and the Misner-Sharp relation, explain why the apparent horizon in Schwarzschild must satisfy $R=2M$ for any spherically symmetric slice.\n2. Using the analytic slice geometry above, derive the condition for the coordinate radius $r_h$ of the apparent horizon on this slice, and determine criteria for existence of a solution $r_h \\ge 0$.\n3. Implement a horizon finder that, given $(M,b)$, searches for a root of the function $$f(r) = R(r) - 2M = \\big(\\sqrt{r} + b\\big)^2 - 2M$$ in $r \\ge 0$ using a robust bracketing and bisection method on the variable $x = \\sqrt{r} \\ge 0$. If a valid root exists, return the coordinate radius $r_h$; otherwise return $-1$ to indicate no apparent horizon on this slice.\n4. Validate the numerical horizon finder output against the derived analytic expression, and ensure consistency within a small tolerance for all cases where a horizon exists.\n\nUnits: Express radii in the same geometrized units as $M$ (unitless in this convention). No angles are involved.\n\nTest Suite:\nUse the following set of parameter values $(M,b)$:\n- Case 1 (happy path): $(1.0,\\,1.1)$.\n- Case 2 (boundary, horizon at puncture): $(1.0,\\,\\sqrt{2})$.\n- Case 3 (no horizon): $(1.0,\\,1.5)$.\n- Case 4 (happy path with larger mass): $(2.0,\\,1.8)$.\n- Case 5 (no horizon with larger mass): $(2.0,\\,2.2)$.\n\nFor each case, the program must output a single floating-point number: the coordinate radius $r_h$ if the horizon exists, or $-1$ otherwise.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4,result5]\"). Each result must be a floating-point number.",
            "solution": "The problem statement is scientifically grounded, well-posed, and objective. It presents a standard problem in numerical relativity concerning the location of an apparent horizon on a specific \"trumpet\" slice of a Schwarzschild spacetime. All provided equations and definitions are standard in the field. The tasks are logically structured, leading from fundamental principles to analytical derivation and finally to numerical implementation and validation. The problem is therefore deemed valid.\n\nHere is the step-by-step solution.\n\n**1. Apparent Horizon Condition in Schwarzschild Spacetime**\n\nThe apparent horizon is defined as the outermost marginally trapped surface on a given spatial slice, which is a closed $2$-surface where the expansion of outgoing null geodesics, $\\Theta_+$, vanishes. The condition for an apparent horizon is thus $\\Theta_+ = 0$.\n\nIn a spherically symmetric spacetime, the expansion $\\Theta_+$ is related to the geometry of the $2$-spheres of symmetry. The problem provides the fundamental invariant relation connecting the Misner-Sharp mass $m(R)$ enclosed within an areal radius $R$ to the spatial gradient of the areal radius function $R$:\n$$1 - \\frac{2 m(R)}{R} = g^{ab} \\nabla_a R \\nabla_b R$$\nHere, $g^{ab}$ is the inverse of the full $4$-dimensional spacetime metric $g_{ab}$, and $\\nabla_a$ is the covariant derivative compatible with it. The term on the right-hand side, $g^{ab} \\nabla_a R \\nabla_b R$, is the squared norm of the gradient of the areal radius. For a null vector field $l^a$ generating the outgoing null geodesics orthogonal to the $2$-sphere, the expansion is given by $\\Theta_+ = \\frac{1}{R} \\nabla_a(R l^a)$. For spherically symmetric systems, this can be shown to be directly related to the gradient term. The outgoing null geodesics have $ds^2=0$, and their expansion must be non-negative, which implies that a non-tachyonic expansion is determined by $\\sqrt{g^{ab} \\nabla_a R \\nabla_b R}$. The condition for a marginally trapped surface, $\\Theta_+ = 0$, is therefore equivalent to the condition that the gradient of $R$ is null:\n$$g^{ab} \\nabla_a R \\nabla_b R = 0$$\nSubstituting this into the Misner-Sharp relation yields:\n$$1 - \\frac{2 m(R)}{R} = 0$$\nThe problem states that for a vacuum Schwarzschild spacetime of mass $M$, the Misner-Sharp mass is constant for any radius, $m(R) = M$. This is a statement of Birkhoff's theorem. The apparent horizon condition thus becomes:\n$$1 - \\frac{2 M}{R} = 0$$\nSolving for the areal radius $R$ gives the unique result:\n$$R = 2M$$\nThis result depends only on the definition of the apparent horizon ($\\Theta_+ = 0$) and the fact that the spacetime is Schwarzschild ($m(R) = M$). It does not depend on the specific coordinate system or the slicing (i.e., the choice of time coordinate and the decomposition of the metric into spatial and temporal parts). Therefore, the apparent horizon is always located at the surface with areal radius $R=2M$, regardless of the choice of a spherically symmetric slicing.\n\n**2. Apparent Horizon on the Trumpet Slice**\n\nWe now apply the general condition $R=2M$ to the specific trumpet slice provided. The geometry of this slice is given by the conformally flat spatial metric $\\gamma_{ij} = \\psi^4(r)\\,\\delta_{ij}$, with the conformal factor $\\psi(r) = 1 + \\frac{b}{\\sqrt{r}}$. For this metric, the areal radius $R$ of a coordinate sphere of radius $r$ is given by:\n$$R(r) = \\psi^2(r) \\, r = \\left(1 + \\frac{b}{\\sqrt{r}}\\right)^2 r = \\left(\\sqrt{r}\\left(1 + \\frac{b}{\\sqrt{r}}\\right)\\right)^2 = \\left(\\sqrt{r} + b\\right)^2$$\nTo find the coordinate radius $r_h$ of the apparent horizon, we set its areal radius $R(r_h)$ equal to $2M$:\n$$R(r_h) = \\left(\\sqrt{r_h} + b\\right)^2 = 2M$$\nTo solve for $r_h$, we first solve for $\\sqrt{r_h}$. Since the coordinate radius $r$ must be non-negative, $r_h \\ge 0$, its square root $\\sqrt{r_h}$ must also be real and non-negative. The parameter $b$ is given as positive, $b0$. The sum $\\sqrt{r_h} + b$ is therefore strictly positive. Taking the square root of both sides of the equation yields:\n$$\\sqrt{r_h} + b = \\sqrt{2M}$$\nWe have chosen the positive square root on the right-hand side because the left-hand side must be positive.\nIsolating the term $\\sqrt{r_h}$, we find:\n$$\\sqrt{r_h} = \\sqrt{2M} - b$$\nFor a physical solution for $r_h$ to exist, the value of $\\sqrt{r_h}$ must be real and non-negative. This imposes a critical condition on the parameter $b$:\n$$\\sqrt{2M} - b \\ge 0 \\implies b \\le \\sqrt{2M}$$\nThis is the criterion for the existence of an apparent horizon on this slice.\n- If $b  \\sqrt{2M}$, the right-hand side is negative, so there is no real solution for $\\sqrt{r_h}$. In this case, no apparent horizon exists on the slice. The function $R(r)$ has a minimum value at $r \\to 0$, where $R(r) \\approx (b)^2 = b^2$. If $b^2  2M$, then $R(r)  2M$ for all $r \\ge 0$, and the condition $R=2M$ can never be met.\n- If $b \\le \\sqrt{2M}$, a non-negative solution for $\\sqrt{r_h}$ exists. We can square both sides to find the coordinate radius $r_h$:\n$$r_h = \\left(\\sqrt{2M} - b\\right)^2$$\nThe boundary case occurs when $b = \\sqrt{2M}$, which gives $r_h = 0$. This corresponds to the apparent horizon being located at the puncture, $r=0$. For $b  \\sqrt{2M}$, we have $r_h  0$.\n\n**3. Numerical Horizon Finder Design**\n\nThe task is to implement a numerical root-finder for the equation $f(r) = R(r) - 2M = 0$, which is:\n$$f(r) = \\left(\\sqrt{r} + b\\right)^2 - 2M = 0$$\nfor $r \\ge 0$. The problem specifies using a bisection method on the variable $x = \\sqrt{r}$, where $x \\ge 0$. Let's define a new function $g(x)$ corresponding to $f(r)$:\n$$g(x) = (x + b)^2 - 2M$$\nWe need to find the root of $g(x)=0$ for $x \\ge 0$.\nThe algorithm proceeds as follows:\n1.  First, check the existence condition derived analytically: $b \\le \\sqrt{2M}$. This is equivalent to $b^2 \\le 2M$. If $b^2  2M$, no root exists, and the finder should return $-1$.\n2.  If a root exists ($b^2 \\le 2M$), we need to establish a bracket $[x_a, x_b]$ for the bisection method, such that $g(x_a)$ and $g(x_b)$ have opposite signs.\n    -   Let's evaluate $g(x)$ at the lower bound of our domain, $x = 0$.\n        $$g(0) = (0 + b)^2 - 2M = b^2 - 2M$$\n        Since we established a root exists ($b^2 \\le 2M$), we know that $g(0) \\le 0$. So, we can set the lower end of our bracket to $x_a = 0$.\n    -   For the upper bound $x_b$, we need a value such that $g(x_b)  0$. The derivative of $g(x)$ is $g'(x) = 2(x+b)$, which is always positive for $x \\ge 0$ and $b  0$. Thus, $g(x)$ is a monotonically increasing function. A suitable upper bound can be chosen by noting the analytical root is $x_h = \\sqrt{2M} - b$. A simple, robust choice for the upper bracket that is guaranteed to be greater than the root is $x_b = \\sqrt{2M}$. Let's verify:\n        $$g(\\sqrt{2M}) = (\\sqrt{2M} + b)^2 - 2M = (2M + 2b\\sqrt{2M} + b^2) - 2M = 2b\\sqrt{2M} + b^2$$\n        Since $b0$ and $M0$, this value is always positive.\n    -   Therefore, if a root exists, it is guaranteed to lie within the interval $[0, \\sqrt{2M}]$ for $x$.\n3.  With the bracket $[x_a, x_b] = [0, \\sqrt{2M}]$ established, we can apply the bisection algorithm:\n    -   Iterate a fixed number of times (e.g., $100$ iterations provide sufficient precision for standard floating-point numbers).\n    -   In each iteration, calculate the midpoint $x_m = (x_a + x_b)/2$.\n    -   Evaluate $g(x_m)$. If $g(x_m)  0$, the root is in the upper half-interval, so we update $x_a = x_m$. Otherwise, the root is in the lower half-interval, and we update $x_b = x_m$.\n4.  After the iterations, the root is approximated as $x_h \\approx (x_a + x_b)/2$.\n5.  The final result is the coordinate radius $r_h = x_h^2$.\n\n**4. Validation**\n\nThe numerical implementation will be validated against the analytical solution $r_h = (\\sqrt{2M} - b)^2$ for the cases where a horizon exists ($b \\le \\sqrt{2M}$).\n- Case 1: $(M,b) = (1.0, 1.1)$. We have $b = 1.1  \\sqrt{2 \\cdot 1.0} \\approx 1.414$. A horizon exists. Analytical $r_h = (\\sqrt{2} - 1.1)^2 \\approx 0.098728$. The numerical solver should converge to this value.\n- Case 2: $(M,b) = (1.0, \\sqrt{2})$. We have $b = \\sqrt{2M}$. A horizon exists at the puncture. Analytical $r_h = (\\sqrt{2} - \\sqrt{2})^2 = 0$. The numerical solver should return $0$.\n- Case 3: $(M,b) = (1.0, 1.5)$. We have $b = 1.5  \\sqrt{2}$. No horizon exists. The algorithm should return $-1$.\n- Case 4: $(M,b) = (2.0, 1.8)$. We have $b = 1.8  \\sqrt{2 \\cdot 2.0} = 2.0$. A horizon exists. Analytical $r_h = (2.0 - 1.8)^2 = (0.2)^2 = 0.04$. The numerical solver should converge to this value.\n- Case 5: $(M,b) = (2.0, 2.2)$. We have $b = 2.2  2.0$. No horizon exists. The algorithm should return $-1$.\n\nThe proposed numerical method is robust and consistent with the analytical derivation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef find_horizon(M, b):\n    \"\"\"\n    Finds the coordinate radius of the apparent horizon for a trumpet slice.\n\n    The apparent horizon is located where the areal radius R(r) = 2M.\n    For the given slice, R(r) = (sqrt(r) + b)^2.\n    The equation to solve is (sqrt(r) + b)^2 = 2M.\n    Let x = sqrt(r), so the equation becomes (x + b)^2 = 2M for x = 0.\n\n    Args:\n        M (float): The mass of the Schwarzschild black hole.\n        b (float): The parameter of the trumpet slice.\n\n    Returns:\n        float: The coordinate radius r_h of the apparent horizon, or -1 if none exists.\n    \"\"\"\n    if M = 0 or b = 0:\n        # Physical parameters must be positive.\n        return -1.0\n        \n    sqrt_2M = np.sqrt(2.0 * M)\n\n    # Criterion for horizon existence: b = sqrt(2M)\n    # This is equivalent to b^2 = 2M. We check b  sqrt(2M) to avoid\n    # floating point issues with direct comparison.\n    if b  sqrt_2M:\n        return -1.0\n        \n    # Handle the boundary case where the horizon is at the puncture r=0\n    if np.isclose(b, sqrt_2M):\n        return 0.0\n\n    # Define the function g(x) = (x + b)^2 - 2M, where x = sqrt(r).\n    # We need to find the root of g(x) = 0 for x  0.\n    g = lambda x: (x + b)**2 - 2.0 * M\n\n    # Set up the bracket for bisection on the variable x = sqrt(r).\n    # From the analysis, g(0) = b^2 - 2M = 0, so xa=0 is a valid lower bound.\n    # The analytical solution for x is sqrt(2M) - b, which is less than sqrt(2M).\n    # So, xb = sqrt(2M) serves as a robust upper bound since g(sqrt(2M))  0.\n    xa = 0.0\n    xb = sqrt_2M\n    \n    # Bisection method for finding the root x_h.\n    # 100 iterations is more than sufficient for double precision.\n    for _ in range(100):\n        xm = (xa + xb) / 2.0\n        # If g(xm) has the same sign as g(xa) (which is negative),\n        # then the root is in [xm, xb].\n        if g(xm)  0:\n            xa = xm\n        # Otherwise, the root is in [xa, xm].\n        else:\n            xb = xm\n            \n    # The root for x=sqrt(r) is approximated by the midpoint of the final interval.\n    xh = (xa + xb) / 2.0\n    \n    # The coordinate radius of the horizon is r_h = x_h^2.\n    rh = xh**2\n    \n    return rh\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.0, 1.1),\n        (1.0, np.sqrt(2.0)),\n        (1.0, 1.5),\n        (2.0, 1.8),\n        (2.0, 2.2),\n    ]\n\n    results = []\n    for M, b in test_cases:\n        result = find_horizon(M, b)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Using a format specifier to ensure consistent output representation.\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The choice of numerical algorithm can be as important as the physical model itself, especially when dealing with the stiff, nonlinear equations of general relativity. This exercise provides a look under the hood of horizon-finding algorithms by analyzing the stability of two common approaches: direct elliptic solvers and iterative parabolic flows. Using simplified matrix representations of the linearized MOTS operator, you will use tools from numerical linear algebra to quantify and compare the stability of these methods, revealing the mathematical trade-offs that are critical for designing robust numerical relativity codes .",
            "id": "3463976",
            "problem": "Consider the task of locating a Marginally Outer Trapped Surface (MOTS) in a given spacelike hypersurface in numerical relativity. The MOTS is defined by the vanishing of the expansion of outgoing null geodesics, namely the functional equation $\\theta_{(\\ell)}[F]=0$, where $F(\\theta,\\phi)$ represents a smooth, star-shaped embedding function of a candidate $2$-surface in spherical coordinates and $\\theta_{(\\ell)}[F]$ denotes the null expansion computed from the induced metric and extrinsic curvature. The apparent horizon corresponds to a MOTS that is outermost with respect to the topology of the hypersurface, and its numerical identification is a core subroutine in simulations relevant to gravitational radiation from compact object mergers.\n\nTwo algorithmic strategies are frequently employed to solve $\\theta_{(\\ell)}[F]=0$:\n- A direct elliptic solve for the stationary equation, based on linearization about a candidate surface $F_0$ and discretization of the MOTS stability operator, resulting in a matrix representation $L$ of the Fréchet derivative $D\\theta_{(\\ell)}[F_0]$.\n- A pseudo-time parabolic flow (also termed curvature flow or residual descent), which constructs a dissipative evolution equation in an artificial time $\\tau$ that drives the embedding $F(\\tau)$ toward a configuration with decreasing residual $\\|\\theta_{(\\ell)}[F(\\tau)]\\|$.\n\nStarting from fundamental definitions: \n- The MOTS condition $\\theta_{(\\ell)}[F]=0$ defines a root-finding problem in function space.\n- The direct elliptic approach linearizes the residual around an iterate and solves $L \\,\\delta F = -\\theta_{(\\ell)}[F]$ for an update $\\delta F$, where $L$ is the discrete linearization of the MOTS stability operator.\n- The pseudo-time flow descends the residual norm by setting $\\partial_\\tau F = - \\nabla J(F)$ with $J(F)=\\tfrac{1}{2}\\|\\theta_{(\\ell)}[F]\\|^2$, yielding a gradient flow in function space. Near a solution $F^\\star$ where $\\theta_{(\\ell)}[F^\\star]=0$, the linearization of the flow is governed by the Hessian $H = L^\\top L$ under the standard $L^2$ inner product on the discretization space.\n\nTo assess stability, we adopt the following mathematically justified metrics derived from spectral properties:\n- For the direct elliptic solve, the conditioning of the update with respect to residual or data perturbations is governed by the matrix $2$-norm condition number $\\kappa_2(L) = \\sigma_{\\max}(L)/\\sigma_{\\min}(L)$, where $\\sigma_{\\max}(L)$ and $\\sigma_{\\min}(L)$ denote the largest and smallest singular values of $L$. A small value of $\\kappa_2(L)$ indicates robust stability of the direct inversion, while a large value indicates potential amplification of perturbations.\n- For the pseudo-time parabolic flow discretized by forward Euler with a positive definite mass matrix and unit preconditioning, the linearized error dynamics near $F^\\star$ is $\\partial_\\tau \\delta F = - H \\delta F$, where $H = L^\\top L$ is symmetric positive semidefinite. The maximum provably stable time step for forward Euler is $\\Delta \\tau_{\\max} = \\tfrac{2}{\\lambda_{\\max}(H)}$, where $\\lambda_{\\max}(H)$ is the largest eigenvalue of $H$. On a strictly convex quadratic (which holds when $L$ has full column rank), the optimal per-step contraction factor for gradient descent with best constant step size is $q_{\\mathrm{opt}} = \\tfrac{\\kappa_2(H)-1}{\\kappa_2(H)+1}$, where $\\kappa_2(H) = \\lambda_{\\max}(H)/\\lambda_{\\min}(H)$; smaller $q_{\\mathrm{opt}}$ indicates stronger contraction per iteration.\n\nWe quantify and compare stability in terms of two indices:\n- The direct-solve stability index $S_{\\mathrm{direct}} = \\tfrac{1}{\\kappa_2(L)}$ if $L$ is symmetric positive definite (SPD) and invertible; otherwise $S_{\\mathrm{direct}} = 0$.\n- The flow stability index $S_{\\mathrm{flow}} = 1 - q_{\\mathrm{opt}}$ when $H$ is positive definite; in the rank-deficient case where $\\lambda_{\\min}(H)=0$, we set $q_{\\mathrm{opt}}=1$ and $S_{\\mathrm{flow}}=0$.\n\nWe declare the pseudo-time parabolic flow \"provably more stable\" when $S_{\\mathrm{flow}}  S_{\\mathrm{direct}}$, and otherwise prefer the direct elliptic solve. Additionally, if $L$ is not SPD, the direct elliptic method via Conjugate Gradient is not applicable, and the pseudo-time flow is preferred by necessity.\n\nImplement a program that, given a set of discrete linearizations $L$ (each representing a Galerkin-truncated, axisymmetric discretization of $D\\theta_{(\\ell)}[F]$ at some iterate), computes for each case:\n- A boolean flag $\\mathrm{isSPD}$ indicating whether $L$ is symmetric (within numerical tolerance) and has strictly positive eigenvalues.\n- The $2$-norm condition number $\\kappa_2(L)$.\n- The maximum stable forward Euler time step $\\Delta \\tau_{\\max} = \\tfrac{2}{\\lambda_{\\max}(H)}$ with $H=L^\\top L$.\n- The optimal per-step contraction factor $q_{\\mathrm{opt}} = \\tfrac{\\kappa_2(H)-1}{\\kappa_2(H)+1}$, with the convention $q_{\\mathrm{opt}}=1$ when $\\lambda_{\\min}(H)=0$.\n- An integer $\\mathrm{preferred}$ that is $0$ if the direct elliptic method is more stable under the above indices, and $1$ otherwise.\n\nAll floating-point outputs must be rounded to $6$ decimal places.\n\nTest Suite:\nUse the following matrices:\n- Case $\\mathrm{A}$ (well-conditioned symmetric positive definite): $L = \\begin{bmatrix} 1.5  0  0 \\\\ 0  1.2  0 \\\\ 0  0  0.8 \\end{bmatrix}$.\n- Case $\\mathrm{B}$ (ill-conditioned symmetric positive definite): $L = \\begin{bmatrix} 2  0  0 \\\\ 0  1  0 \\\\ 0  0  10^{-4} \\end{bmatrix}$.\n- Case $\\mathrm{C}$ (non-symmetric, skew-like coupling): $L = \\begin{bmatrix} 0  1 \\\\ -3  0 \\end{bmatrix}$.\n- Case $\\mathrm{D}$ (rank-deficient): $L = \\begin{bmatrix} 1  0 \\\\ 0  0 \\end{bmatrix}$.\n- Case $\\mathrm{E}$ (symmetric indefinite): $L = \\begin{bmatrix} 1  0 \\\\ 0  -0.5 \\end{bmatrix}$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each case contributes a list in the form $[\\mathrm{isSPD}, \\kappa_2(L), \\Delta \\tau_{\\max}, q_{\\mathrm{opt}}, \\mathrm{preferred}]$. For example: $[[\\mathrm{True},\\dots],[\\mathrm{False},\\dots],\\dots]$. All floating-point entries must be rounded to $6$ decimal places, there must be no spaces in the printed string, and booleans must be printed as either $\\mathrm{True}$ or $\\mathrm{False}$.",
            "solution": "The user has provided a problem from the domain of numerical relativity, specifically concerning the stability analysis of algorithms for finding a Marginally Outer Trapped Surface (MOTS). I will first validate the problem statement and then, if valid, proceed with a full solution.\n\n### Step 1: Problem Validation\n\nI have extracted the givens, definitions, and requirements from the problem statement. These include the definitions of two numerical methods (direct elliptic solve and pseudo-time parabolic flow), the mathematical forms of their associated linear operators ($L$ and $H=L^\\top L$), the stability metrics ($\\kappa_2(L)$, $\\Delta\\tau_{\\max}$, $q_{\\mathrm{opt}}$), the stability indices ($S_{\\mathrm{direct}}$, $S_{\\mathrm{flow}}$), and a rule for preferring one method over the other. The task is to compute a set of five quantities for several given matrices $L$.\n\nThe problem is evaluated against the validation criteria:\n\n1.  **Scientific Grounding**: The problem is well-grounded in numerical relativity and numerical analysis. The concepts of MOTS, apparent horizons, direct versus iterative solvers, and stability analysis via condition numbers and spectral radii are standard in the field. The provided equations for $\\Delta \\tau_{\\max}$ and $q_{\\mathrm{opt}}$ are correct for the forward Euler discretization of a gradient flow. The problem is scientifically and mathematically sound.\n\n2.  **Well-Posedness**: The problem is well-posed. It provides all necessary inputs (a test suite of matrices $L$), clear definitions for all quantities to be computed, and unambiguous rules for the final classification (`preferred`). The edge cases, such as rank-deficient matrices, are handled by explicit conventions ($q_{\\mathrm{opt}}=1$).\n\n3.  **Objectivity**: The problem is stated in precise, objective, and technical language, free from any subjective or opinion-based claims.\n\n4.  **No Flaws Identified**: The problem does not violate any fundamental principles, is not based on false premises, and does not contain contradictory constraints. While the output formatting rules are highly specific and require careful handling of special floating-point values (like infinity), they do not render the problem invalid; they merely impose a strict implementation challenge. The logic for determining the preferred method is consistent. It correctly prioritizes the applicability of the direct solver (requiring $L$ to be Symmetric Positive Definite) before comparing stability indices. A quick derivation confirms the logic: For an SPD matrix $L$, letting $k = \\kappa_2(L) \\ge 1$, we compare $S_{\\mathrm{direct}} = 1/k$ with $S_{\\mathrm{flow}} = 2/(k^2+1)$. The inequality $S_{\\mathrm{flow}}  S_{\\mathrm{direct}}$ is equivalent to $2/(\\kappa^2+1)  1/k$, or $2k  k^2+1$, which simplifies to $0  (k-1)^2$. This inequality is never satisfied for real $k$. Thus, $S_{\\mathrm{flow}} \\le S_{\\mathrm{direct}}$ always holds for an SPD matrix, meaning the direct method is always preferred when applicable. This confirms that the two-part rule (check applicability, then compare indices) simplifies to `preferred = 0` if $L$ is SPD and `preferred = 1` otherwise.\n\n**Verdict**: The problem is **valid**. I will proceed with the solution.\n\n### Step 2: Solution Derivation\n\nThe task is to implement a procedure that takes a square matrix $L$ and computes five specific quantities. This procedure will be applied to each of the matrices in the provided test suite.\n\n**Let $L$ be the input matrix.** A numerical tolerance, $\\epsilon = 10^{-9}$, will be used for floating-point comparisons to zero.\n\n1.  **Compute `isSPD`**: A matrix $L$ is symmetric positive definite (SPD) if it is symmetric ($L = L^\\top$) and all its eigenvalues are strictly positive.\n    -   First, check for symmetry: `numpy.allclose(L, L.T)`.\n    -   If symmetric, compute its eigenvalues, $\\lambda_i(L)$. Since the matrix is real and symmetric, its eigenvalues are real.\n    -   Check if all eigenvalues are strictly greater than $\\epsilon$.\n    -   `isSPD` is `True` if both conditions are met, otherwise it is `False`.\n\n2.  **Compute $\\kappa_2(L)$**: The $2$-norm condition number of $L$ is the ratio of its largest to its smallest singular value, $\\kappa_2(L) = \\sigma_{\\max}(L) / \\sigma_{\\min}(L)$.\n    -   Singular values are computed using Singular Value Decomposition (SVD).\n    -   If $\\sigma_{\\min}(L)  \\epsilon$, the matrix is numerically singular, and $\\kappa_2(L)$ is infinite. This will be represented by `numpy.inf`.\n    -   Otherwise, the ratio is computed directly. The function `numpy.linalg.cond(L, 2)` performs this calculation.\n\n3.  **Compute $\\Delta \\tau_{\\max}$**: The maximum stable time step is given by $\\Delta \\tau_{\\max} = 2 / \\lambda_{\\max}(H)$, where $H = L^\\top L$.\n    -   First, compute $H = L^\\top L$. The resulting matrix is always symmetric and positive semi-definite.\n    -   Compute the eigenvalues of $H$. Since $H$ is symmetric, `numpy.linalg.eigvalsh` is efficient.\n    -   Find the maximum eigenvalue, $\\lambda_{\\max}(H)$. Since none of the test matrices $L$ are the zero matrix, $\\lambda_{\\max}(H)  0$.\n    -   Calculate $\\Delta \\tau_{\\max} = 2 / \\lambda_{\\max}(H)$.\n\n4.  **Compute $q_{\\mathrm{opt}}$**: The optimal contraction factor is $q_{\\mathrm{opt}} = \\frac{\\kappa_2(H)-1}{\\kappa_2(H)+1}$. We are given the convention that if $\\lambda_{\\min}(H)=0$, then $q_{\\mathrm{opt}}=1$.\n    -   From the eigenvalues of $H$ computed in the previous step, find the minimum eigenvalue, $\\lambda_{\\min}(H)$.\n    -   If $\\lambda_{\\min}(H)  \\epsilon$, the matrix is considered rank-deficient for this purpose, and we set $q_{\\mathrm{opt}} = 1.0$.\n    -   Otherwise, compute the condition number of $H$, $\\kappa_2(H) = \\lambda_{\\max}(H) / \\lambda_{\\min}(H)$.\n    -   Calculate $q_{\\mathrm{opt}} = (\\kappa_2(H)-1) / (\\kappa_2(H)+1)$.\n\n5.  **Compute `preferred`**: The logic, as established during validation, is determined by whether $L$ is SPD. The direct method (via Conjugate Gradient) is only applicable for SPD matrices. By necessity, the flow method is preferred if $L$ is not SPD. If $L$ is SPD, the direct method's stability index is always greater than or equal to the flow's, so the direct method is preferred.\n    -   `preferred = 1` if `isSPD` is `False`.\n    -   `preferred = 0` if `isSPD` is `True`.\n\nThis complete procedure will be applied to each test case. All floating-point results will be formatted to $6$ decimal places, and infinite values will be represented as `inf`. The final output will be a single string representing a list of lists.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the apparent horizon finder stability problem for a given test suite.\n    \"\"\"\n    # Numerical tolerance for checking against zero.\n    TOLERANCE = 1e-9\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: well-conditioned symmetric positive definite\n        np.array([[1.5, 0.0, 0.0], [0.0, 1.2, 0.0], [0.0, 0.0, 0.8]]),\n        # Case B: ill-conditioned symmetric positive definite\n        np.array([[2.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1e-4]]),\n        # Case C: non-symmetric, skew-like coupling\n        np.array([[0.0, 1.0], [-3.0, 0.0]]),\n        # Case D: rank-deficient\n        np.array([[1.0, 0.0], [0.0, 0.0]]),\n        # Case E: symmetric indefinite\n        np.array([[1.0, 0.0], [0.0, -0.5]]),\n    ]\n\n    all_results_str = []\n\n    for L in test_cases:\n        # 1. Compute isSPD\n        is_spd = False\n        is_symmetric = np.allclose(L, L.T, atol=TOLERANCE)\n        if is_symmetric:\n            try:\n                # Use eigvalsh for symmetric matrices\n                eigenvalues_L = np.linalg.eigvalsh(L)\n                if np.all(eigenvalues_L  TOLERANCE):\n                    is_spd = True\n            except np.linalg.LinAlgError:\n                # This case is unlikely for the given inputs but is good practice.\n                is_spd = False\n        \n        # 2. Compute kappa_2(L)\n        kappa_L = np.linalg.cond(L, 2)\n        \n        # 3. Compute H and delta_tau_max\n        H = L.T @ L\n        # H is symmetric positive semi-definite. Use eigvalsh for stability and performance.\n        eigenvalues_H = np.linalg.eigvalsh(H)\n        lambda_max_H = eigenvalues_H.max()\n        \n        if lambda_max_H  TOLERANCE:\n            # This occurs only if L is the zero matrix.\n            delta_tau_max = np.inf\n        else:\n            delta_tau_max = 2.0 / lambda_max_H\n            \n        # 4. Compute q_opt\n        lambda_min_H = eigenvalues_H.min()\n        if lambda_min_H  TOLERANCE:\n            # Rank-deficient case as per problem specification.\n            q_opt = 1.0\n        else:\n            kappa_H = lambda_max_H / lambda_min_H\n            q_opt = (kappa_H - 1.0) / (kappa_H + 1.0)\n            \n        # 5. Compute preferred method\n        # If L is not SPD, the direct solver (CG) is not applicable, so flow is preferred by necessity.\n        # If L is SPD, S_direct = S_flow, so direct method is preferred.\n        preferred = 0 if is_spd else 1\n\n        # Format the results for this case into a string as per specification.\n        # Booleans are 'True' or 'False'.\n        # Floats are rounded to 6 decimal places, except 'inf'.\n        # No spaces are used.\n        current_result = [\n            str(is_spd),\n            f\"{kappa_L:.6f}\" if np.isfinite(kappa_L) else \"inf\",\n            f\"{delta_tau_max:.6f}\" if np.isfinite(delta_tau_max) else \"inf\",\n            f\"{q_opt:.6f}\",\n            str(preferred)\n        ]\n        all_results_str.append(f\"[{','.join(current_result)}]\")\n\n    # Final print statement must produce a single line in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n\n```"
        }
    ]
}