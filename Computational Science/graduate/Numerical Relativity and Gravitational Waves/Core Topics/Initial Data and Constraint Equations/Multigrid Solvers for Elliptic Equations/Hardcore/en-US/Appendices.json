{
    "hands_on_practices": [
        {
            "introduction": "The heart of a multigrid solver is the smoother, an iterative method that is not meant to solve the system but rather to efficiently damp high-frequency components of the error. This hands-on exercise allows you to directly observe and quantify this critical property. By applying the Gauss-Seidel smoother to a specific error mode, you will numerically compute its amplification factor and see why such methods are effective at preparing the problem for coarse-grid correction .",
            "id": "3480320",
            "problem": "Consider the two-dimensional Poisson equation on the unit square with homogeneous Dirichlet boundary conditions, written as $$\\nabla^2 u(x,y) = 0 \\quad \\text{for} \\quad (x,y)\\in(0,1)\\times(0,1), \\quad \\text{with} \\quad u(x,y)=0 \\quad \\text{on} \\quad \\partial\\Omega.$$ Use the standard second-order central difference scheme on an $N\\times N$ interior grid with uniform spacing $h=1/(N+1)$ to obtain the discrete linear system $$A \\mathbf{u} = \\mathbf{f},$$ where $A$ is the five-point discrete Laplacian operator and $\\mathbf{u}$ is the array of interior unknowns. In multigrid methods, Gauss-Seidel (GS) relaxation is employed as a smoother to damp high-frequency error components. The smoothing property can be quantified by the amplification factor of Fourier-like error modes.\n\nYour task is to start from the basic discrete operator and the linear iteration splitting for Gauss-Seidel, derive the pointwise update for lexicographic Gauss-Seidel relaxation on the homogeneous system (that is, with $\\mathbf{f}=\\mathbf{0}$ so that the exact solution is $\\mathbf{u}^\\ast=\\mathbf{0}$), and then implement two pre-smoothing and two post-smoothing steps (total of four GS sweeps) applied to an initial error given by a single discrete sine mode. Specifically:\n\n- Construct the discrete sine mode $$\\phi_{i,j}^{(k,\\ell)} = \\sin\\!\\bigg(\\frac{k\\pi i}{N+1}\\bigg)\\,\\sin\\!\\bigg(\\frac{\\ell\\pi j}{N+1}\\bigg),\\quad 1\\le i,j\\le N,$$ and normalize it in the discrete $\\ell^2$ norm so that $$\\sum_{i=1}^N\\sum_{j=1}^N \\left(\\phi_{i,j}^{(k,\\ell)}\\right)^2 = 1.$$ Use this normalized mode as the initial error $\\mathbf{e}^{(0)}=\\phi^{(k,\\ell)}$.\n\n- Apply lexicographic Gauss-Seidel relaxation derived from the matrix splitting of the discrete Laplacian to the homogeneous system $A\\mathbf{u}=\\mathbf{0}$ for a total of four sweeps, starting from $\\mathbf{u}^{(0)}=\\mathbf{e}^{(0)}$. Let $\\mathbf{u}^{(4)}$ denote the result after four sweeps.\n\n- Quantify the reduction in the selected mode by projecting the final error $\\mathbf{u}^{(4)}$ onto the original mode and defining the mode-specific amplification factor as $$\\alpha_{k,\\ell}(N) = \\left|\\frac{\\sum_{i=1}^N\\sum_{j=1}^N \\phi_{i,j}^{(k,\\ell)}\\,u^{(4)}_{i,j}}{\\sum_{i=1}^N\\sum_{j=1}^N \\phi_{i,j}^{(k,\\ell)}\\,u^{(0)}_{i,j}}\\right|.$$ Because the initial mode is normalized, the denominator equals $1$ up to numerical roundoff. Report the absolute value to measure damping irrespective of any phase inversion.\n\nUse this construction to evaluate the amplification factor for a set of representative modes that probe high-frequency and anisotropic behavior. Your program must implement the lexicographic Gauss-Seidel update starting from first principles (the discrete operator and the iteration splitting) and compute the amplification factors for the following test suite:\n\n- Case 1 (happy path, low-frequency reference): $N=32$, $k=1$, $\\ell=1$.\n- Case 2 (mid-high-frequency, isotropic): $N=32$, $k=16$, $\\ell=16$.\n- Case 3 (near-Nyquist, isotropic extreme): $N=32$, $k=32$, $\\ell=32$.\n- Case 4 (anisotropic high-frequency in $x$): $N=32$, $k=32$, $\\ell=1$.\n- Case 5 (larger grid, mid-high-frequency, isotropic): $N=64$, $k=32$, $\\ell=32$.\n- Case 6 (small grid edge case, near-Nyquist): $N=4$, $k=4$, $\\ell=4$.\n\nAll computations are purely numerical with no physical units. Angles in the sine modes are in radians. Your program should produce a single line of output containing the six amplification factors as a comma-separated list enclosed in square brackets, rounded to six decimal places, in the same order as the cases above. For example, the output format must be exactly like \"[result1,result2,result3,result4,result5,result6]\".",
            "solution": "The user has provided a problem in the domain of numerical analysis, specifically concerning the evaluation of a Gauss-Seidel smoother's performance, which is a key component of multigrid solvers for elliptic partial differential equations. The problem is scientifically and mathematically sound, well-posed, and all necessary parameters and definitions are provided for its resolution.\n\nThe core of the problem is to numerically evaluate the damping properties of a lexicographic Gauss-Seidel (GS) relaxation scheme for the two-dimensional Poisson equation. This is achieved by measuring the reduction of specific error modes after a fixed number of GS sweeps.\n\nThe problem begins with the homogeneous Poisson equation on a unit square, $\\nabla^2 u(x,y) = 0$, with homogeneous Dirichlet boundary conditions $u=0$ on the boundary. We discretize this equation on a uniform grid with $N \\times N$ interior points and grid spacing $h=1/(N+1)$. The standard five-point central difference approximation to the Laplacian at a grid point $(i,j)$ is:\n$$ (L_h u)_{i,j} = \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} $$\nSetting $(L_h u)_{i,j} = 0$ for all interior points $1 \\le i,j \\le N$ gives the discrete linear system $A\\mathbf{u} = \\mathbf{0}$. The equation for each point $(i,j)$ is:\n$$ 4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1} = 0 $$\nwhere the factor of $h^2$ has been dropped as it scales the entire system.\n\nGauss-Seidel is an iterative method for solving such linear systems. For a system $A\\mathbf{u}=\\mathbf{f}$, the matrix $A$ is split into its diagonal ($D$), strict lower triangular ($L$), and strict upper triangular ($U$) parts, $A=L+D+U$. The GS iteration is then defined as $(L+D)\\mathbf{u}^{(m+1)} = \\mathbf{f} - U\\mathbf{u}^{(m)}$. In our case, the right-hand side is zero, so $(L+D)\\mathbf{u}^{(m+1)} = -U\\mathbf{u}^{(m)}$.\n\nThis matrix form can be expressed as a pointwise update rule. To compute the new value $u_{i,j}^{(m+1)}$ at iteration step $m+1$, we rearrange the discrete equation:\n$$ u_{i,j} = \\frac{1}{4}\\left( u_{i-1,j} + u_{i+1,j} + u_{i,j-1} + u_{i,j+1} \\right) $$\nIn a lexicographic (row-by-row, column-by-column) sweep, when we update $u_{i,j}$, the values for \"past\" neighbors (e.g., $u_{i-1,j}$ and $u_{i,j-1}$) have already been updated in the current sweep, while values for \"future\" neighbors (e.g., $u_{i+1,j}$ and $u_{i,j+1}$) are from the previous sweep. This leads to the update rule:\n$$ u_{i,j}^{(m+1)} = \\frac{1}{4}\\left( u_{i-1,j}^{(m+1)} + u_{i,j-1}^{(m+1)} + u_{i+1,j}^{(m)} + u_{i,j+1}^{(m)} \\right) $$\nThis is implemented by iterating through the grid points $i=1,\\dots,N$ and $j=1,\\dots,N$ and updating the grid values in place.\n\nThe initial error is given by a single discrete sine mode, which are the eigenfunctions of the discrete Laplacian operator on this grid:\n$$ \\phi_{i,j}^{(k,\\ell)} = \\sin\\!\\bigg(\\frac{k\\pi i}{N+1}\\bigg)\\,\\sin\\!\\bigg(\\frac{\\ell\\pi j}{N+1}\\bigg), \\quad 1 \\le i,j,k,\\ell \\le N $$\nThis initial mode $\\mathbf{e}^{(0)}$ is first normalized in the discrete $\\ell^2$ norm, yielding $\\boldsymbol{\\phi}^{(k,\\ell)}$ such that $\\sum_{i,j} (\\phi_{i,j}^{(k,\\ell)})^2 = 1$. This normalized mode serves as the initial state of the grid for the iteration, $\\mathbf{u}^{(0)} = \\boldsymbol{\\phi}^{(k,\\ell)}$.\n\nWe then apply four full sweeps of the lexicographic Gauss-Seidel relaxation to this initial state, producing the final state $\\mathbf{u}^{(4)}$. The problem asks to quantify the damping of the original mode by projecting the final error field $\\mathbf{u}^{(4)}$ back onto the initial normalized mode $\\boldsymbol{\\phi}^{(k,\\ell)}$. The mode-specific amplification factor is defined as:\n$$ \\alpha_{k,\\ell}(N) = \\left|\\frac{\\langle \\mathbf{u}^{(4)}, \\boldsymbol{\\phi}^{(k,\\ell)} \\rangle}{\\langle \\mathbf{u}^{(0)}, \\boldsymbol{\\phi}^{(k,\\ell)} \\rangle}\\right| $$\nwhere $\\langle \\cdot, \\cdot \\rangle$ denotes the discrete inner product $\\sum_{i,j} a_{i,j}b_{i,j}$. Since $\\mathbf{u}^{(0)} = \\boldsymbol{\\phi}^{(k,\\ell)}$ and $\\boldsymbol{\\phi}^{(k,\\ell)}$ is normalized, the denominator is $\\langle \\boldsymbol{\\phi}^{(k,\\ell)}, \\boldsymbol{\\phi}^{(k,\\ell)} \\rangle=1$. Therefore, the amplification factor simplifies to the magnitude of the projection:\n$$ \\alpha_{k,\\ell}(N) = \\left| \\sum_{i=1}^N\\sum_{j=1}^N u^{(4)}_{i,j}\\,\\phi_{i,j}^{(k,\\ell)} \\right| $$\nThis procedure is carried out numerically for each of the specified test cases $(N,k,\\ell)$. An $(N+2) \\times (N+2)$ grid is used to naturally incorporate the homogeneous Dirichlet boundary conditions by fixing the values on the border to $0$. The iteration and projection are performed only on the $N \\times N$ interior grid points.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Gauss-Seidel amplification factor for specific sine modes.\n\n    This function iterates through a set of test cases, each defined by a grid\n    size N and mode numbers (k, l). For each case, it:\n    1. Constructs the initial error as a normalized discrete sine mode.\n    2. Applies four sweeps of lexicographic Gauss-Seidel relaxation.\n    3. Computes the amplification factor by projecting the final error onto\n       the initial mode.\n    The results are collected and printed in the specified format.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (32, 1, 1),    # Case 1: Low-frequency reference\n        (32, 16, 16),  # Case 2: Mid-high-frequency, isotropic\n        (32, 32, 32),  # Case 3: Near-Nyquist, isotropic extreme\n        (32, 32, 1),   # Case 4: Anisotropic high-frequency\n        (64, 32, 32),  # Case 5: Larger grid, mid-high-frequency\n        (4, 4, 4),     # Case 6: Small grid edge case, near-Nyquist\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N, k, l = case\n\n        # Grid spacing h.\n        h = 1.0 / (N + 1)\n        \n        # 1. Construct the initial error mode on an (N+2)x(N+2) grid to\n        #    include boundaries. Boundaries are initialized to 0.\n        \n        # Create coordinate arrays for the interior grid.\n        i_vals = np.arange(1, N + 1)\n        j_vals = np.arange(1, N + 1)\n        ii, jj = np.meshgrid(i_vals, j_vals, indexing='ij')\n\n        # Calculate the un-normalized sine mode on the interior.\n        phi_interior = np.sin(k * np.pi * ii * h) * np.sin(l * np.pi * jj * h)\n\n        # 2. Normalize the mode in the discrete l2 norm.\n        norm = np.linalg.norm(phi_interior)\n        \n        # Check for zero norm to prevent division by zero, although not expected here.\n        if norm == 0:\n            normalized_phi_interior = phi_interior\n        else:\n            normalized_phi_interior = phi_interior / norm\n\n        # The initial state u_0 is the normalized mode.\n        # This grid will be modified by the GS sweeps.\n        u = np.zeros((N + 2, N + 2))\n        u[1:N+1, 1:N+1] = normalized_phi_interior\n\n        # Store a copy of the normalized initial mode for the final projection.\n        phi_normalized = u.copy()\n        \n        # 3. Apply four sweeps of lexicographic Gauss-Seidel relaxation.\n        num_sweeps = 4\n        for _ in range(num_sweeps):\n            # The loops must be in lexicographic order (row-by-row, col-by-col).\n            # The update is done in-place, which is the definition of GS.\n            for i in range(1, N + 1):\n                for j in range(1, N + 1):\n                    # Pointwise update rule derived from the 5-point stencil.\n                    u[i, j] = 0.25 * (u[i-1, j] + u[i+1, j] + u[i, j-1] + u[i, j+1])\n\n        # 4. Quantify the amplification factor.\n        # The final state of the grid is u (which is u^(4)).\n        # We project u^(4) onto the initial normalized mode phi_normalized.\n        # The denominator is 1 due to normalization.\n        numerator = np.sum(phi_normalized * u)\n        \n        amplification_factor = np.abs(numerator)\n        \n        results.append(amplification_factor)\n\n    # Final print statement in the exact required format.\n    # Round results to six decimal places.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once high-frequency errors are smoothed, the remaining smooth error must be solved for on a coarser grid. A crucial step is defining the coarse-grid operator, $A_c$. This practice contrasts two fundamental approaches: direct rediscretization of the partial differential equation and the more sophisticated Galerkin construction, $A_c = R A_f P$. For the variable-coefficient problems common in numerical relativity, these methods are not equivalent, and this exercise will guide you in implementing both to quantify their difference .",
            "id": "3480295",
            "problem": "Consider the variable-coefficient Poisson-like operator that arises in elliptic constraints of numerical relativity, for example in constructing gravitational wave initial data, given by the partial differential equation $- \\nabla \\cdot (\\kappa(x,y) \\nabla u(x,y)) = f(x,y)$ on the open unit square $\\Omega = (0,1) \\times (0,1)$ with homogeneous Dirichlet boundary conditions $u(x,y) = 0$ on $\\partial \\Omega$. Define a uniform nodal grid of size $N \\times N$ (including boundary nodes) with spacing $h = 1/(N-1)$ and interior index set $\\{1,2,\\dots,N-2\\} \\times \\{1,2,\\dots,N-2\\}$. Use the conservative second-order finite-difference discretization based on face-centered coefficients to construct a symmetric positive-definite matrix operator $A_f \\in \\mathbb{R}^{n_f \\times n_f}$ with $n_f = (N_f-2)^2$ acting on the fine-grid interior unknown vector, where $N_f$ is the fine-grid nodal count.\n\nThe discrete operator at an interior node $(i,j)$ is defined by the flux form\n$$\n(L_h u)_{i,j} = -\\frac{1}{h^2} \\Big( \\kappa_{i+\\frac{1}{2},j} (u_{i+1,j} - u_{i,j}) - \\kappa_{i-\\frac{1}{2},j} (u_{i,j} - u_{i-1,j}) + \\kappa_{i,j+\\frac{1}{2}} (u_{i,j+1} - u_{i,j}) - \\kappa_{i,j-\\frac{1}{2}} (u_{i,j} - u_{i,j-1}) \\Big),\n$$\nwhere the face-centered coefficients are given by $\\kappa_{i+\\frac{1}{2},j} = \\kappa(x_{i+\\frac{1}{2}}, y_j)$ and $\\kappa_{i,j+\\frac{1}{2}} = \\kappa(x_i, y_{j+\\frac{1}{2}})$, with $x_{i+\\frac{1}{2}} = x_i + h/2$ and $y_{j+\\frac{1}{2}} = y_j + h/2$. The continuous coefficient is defined as\n$$\n\\kappa(x,y) = 1 + a \\sin(2\\pi m x)\\cos(2\\pi m y),\n$$\nwith amplitude $a \\in [0,1)$ and integer frequency $m \\geq 1$, ensuring $\\kappa(x,y) > 0$.\n\nLet the coarse grid be geometrically nested with nodal count $N_c = (N_f + 1)/2$, spacing $H = 1/(N_c-1)$, and interior size $n_c = (N_c - 2)^2$. Define the standard bilinear interpolation (prolongation) operator $P \\in \\mathbb{R}^{n_f \\times n_c}$ from coarse interior unknowns to fine interior unknowns as follows: for each fine interior node $(i,j)$, the interpolated value is the bilinear combination of the surrounding coarse-grid nodal values; when a required coarse-grid node lies on the boundary, its contribution is zero due to homogeneous Dirichlet boundary conditions. Define the full-weighting restriction operator $R \\in \\mathbb{R}^{n_c \\times n_f}$ using the $3 \\times 3$ stencil weights\n$$\n\\frac{1}{16}\n\\begin{bmatrix}\n1 & 2 & 1 \\\\\n2 & 4 & 2 \\\\\n1 & 2 & 1\n\\end{bmatrix}\n$$\ncentered at the fine node that coincides with the coarse node.\n\nUsing these, the Galerkin coarse-grid operator is $A_c^{\\mathrm{Gal}} = R A_f P \\in \\mathbb{R}^{n_c \\times n_c}$. The rediscretized coarse-grid operator $A_c^{\\mathrm{Red}} \\in \\mathbb{R}^{n_c \\times n_c}$ is obtained by applying the same conservative second-order scheme on the coarse grid with spacing $H$ and evaluating the continuous $\\kappa(x,y)$ at coarse faces.\n\nYour tasks:\n- Construct $A_f$ on the fine grid using the specified flux-form discretization with face-centered coefficients evaluated from $\\kappa(x,y)$.\n- Construct $P$ using bilinear interpolation consistent with homogeneous Dirichlet boundaries and $R$ using full weighting as specified.\n- Compute the Galerkin coarse operator $A_c^{\\mathrm{Gal}} = R A_f P$.\n- Construct $A_c^{\\mathrm{Red}}$ by rediscretization on the coarse grid using the same scheme and face-centered coefficients from the same $\\kappa(x,y)$.\n- For each test case, compute the relative Frobenius-norm difference\n$$\n\\delta = \\frac{\\lVert A_c^{\\mathrm{Gal}} - A_c^{\\mathrm{Red}} \\rVert_F}{\\lVert A_c^{\\mathrm{Red}} \\rVert_F}.\n$$\n\nFundamental base requirements for derivation and algorithm:\n- Begin from the definition of the conservative second-order discretization for $- \\nabla \\cdot (\\kappa \\nabla u)$ on a structured grid.\n- Use the geometric multigrid definitions of Galerkin coarse-grid operator, bilinear interpolation, and full-weighting restriction.\n- Ensure consistency with homogeneous Dirichlet boundary conditions through zero boundary contributions where applicable.\n\nTest suite:\n- Case 1 (general variable coefficient, moderate grid): $N_f = 33$, $a = 0.5$, $m = 1$.\n- Case 2 (constant coefficient, baseline): $N_f = 33$, $a = 0.0$, $m = 1$.\n- Case 3 (variable coefficient, smaller grid): $N_f = 17$, $a = 0.9$, $m = 1$.\n- Case 4 (higher-frequency coefficient, moderate grid): $N_f = 33$, $a = 0.7$, $m = 4$.\n\nOutput specification:\n- Your program should produce a single line of output containing a comma-separated list enclosed in square brackets of the four floating-point values $\\delta$ corresponding to the four test cases in the order listed above. For example, the format must be exactly like $[\\delta_1,\\delta_2,\\delta_3,\\delta_4]$, with each $\\delta$ printed as a Python float.",
            "solution": "The problem requires a comparison between two different coarse-grid operators used in multigrid methods for solving a variable-coefficient elliptic partial differential equation. The comparison is based on the relative Frobenius-norm difference between the Galerkin coarse-grid operator, $A_c^{\\mathrm{Gal}}$, and the rediscretized coarse-grid operator, $A_c^{\\mathrm{Red}}$.\n\nThe problem is well-posed and scientifically grounded in the field of numerical analysis, particularly as it applies to solving elliptic constraint equations in numerical relativity. All parameters and definitions are provided, allowing for a direct and unambiguous implementation. I will proceed with a systematic construction of the required matrices.\n\n### 1. Discretization of the Continuous Operator\n\nThe continuous problem is to solve the partial differential equation (PDE)\n$$\n- \\nabla \\cdot (\\kappa(x,y) \\nabla u(x,y)) = f(x,y)\n$$\non the unit square $\\Omega = (0,1) \\times (0,1)$ with homogeneous Dirichlet boundary conditions $u(x,y) = 0$ on the boundary $\\partial \\Omega$. The coefficient $\\kappa(x,y)$ is given by $\\kappa(x,y) = 1 + a \\sin(2\\pi m x)\\cos(2\\pi m y)$.\n\nWe discretize this equation on a uniform grid with $N \\times N$ nodes and spacing $h = 1/(N-1)$. Let $u_{i,j}$ denote the value of the solution at the grid node $(x_i, y_j) = (ih, jh)$. The problem specifies a conservative second-order finite-difference scheme. The discrete operator $L_h$ at an interior node $(i,j)$, for $i,j \\in \\{1, \\dots, N-2\\}$, is\n$$\n(L_h u)_{i,j} = -\\frac{1}{h^2} \\Big( \\kappa_{i+\\frac{1}{2},j} (u_{i+1,j} - u_{i,j}) - \\kappa_{i-\\frac{1}{2},j} (u_{i,j} - u_{i-1,j}) + \\kappa_{i,j+\\frac{1}{2}} (u_{i,j+1} - u_{i,j}) - \\kappa_{i,j-\\frac{1}{2}} (u_{i,j} - u_{i,j-1}) \\Big).\n$$\nThe face-centered coefficients are evaluations of $\\kappa(x,y)$ at midpoints between nodes, e.g., $\\kappa_{i+\\frac{1}{2},j} = \\kappa(x_i + h/2, y_j)$.\n\nThe discrete system of equations is $A \\mathbf{u} = \\mathbf{f}$, where $\\mathbf{u}$ is the vector of unknown values at the $n = (N-2)^2$ interior grid points. The matrix $A$ represents the negative of the discrete operator, $-L_h$. By re-arranging the terms of $(L_h u)_{i,j}$, we can identify the stencil for the matrix $A$:\n$$\n(A \\mathbf{u})_{i,j} = \\frac{1}{h^2} \\Big[ (\\kappa_{i+\\frac{1}{2},j} + \\kappa_{i-\\frac{1}{2},j} + \\kappa_{i,j+\\frac{1}{2}} + \\kappa_{i,j-\\frac{1}{2}}) u_{i,j} - \\kappa_{i+\\frac{1}{2},j} u_{i+1,j} - \\kappa_{i-\\frac{1}{2},j} u_{i-1,j} - \\kappa_{i,j+\\frac{1}{2}} u_{i,j+1} - \\kappa_{i,j-\\frac{1}{2}} u_{i,j-1} \\Big].\n$$\nThe vector $\\mathbf{u}$ is formed by arranging the $u_{i,j}$ values in a specific order, typically row-major. For interior indices $i,j \\in \\{1, \\dots, N-2\\}$, the mapping from a 2D grid index $(i,j)$ to a 1D vector index $k$ is $k = (i-1)(N-2) + (j-1)$. This structure defines a sparse, symmetric positive-definite matrix $A$ of size $n \\times n$. The homogeneous Dirichlet boundary conditions are handled by noting that any $u_{i,j}$ where $i$ or $j$ is $0$ or $N-1$ is zero, and thus these terms drop out of the equations for interior nodes adjacent to the boundary.\n\nBoth the fine-grid operator $A_f$ and the coarse-grid rediscretized operator $A_c^{\\mathrm{Red}}$ are constructed using this method, but with different grid parameters ($N_f, h$) and ($N_c, H$), respectively.\n\n### 2. Inter-Grid Transfer Operators: Prolongation and Restriction\n\nWe are given a fine grid with $N_f$ points per dimension and a coarse grid with $N_c = (N_f+1)/2$ points. The corresponding interior problem sizes are $n_f = (N_f-2)^2$ and $n_c = (N_c-2)^2$.\n\n**Prolongation (Interpolation) $P$**: The prolongation operator $P \\in \\mathbb{R}^{n_f \\times n_c}$ maps a vector of coarse-grid interior values to a vector of fine-grid interior values. We use bilinear interpolation. For a fine-grid interior point $(i_f, j_f)$, its value is an interpolation of the surrounding four coarse-grid points. The weights depend on the position of the fine point relative to the coarse grid.\n- A fine point coinciding with a coarse point $(2i_c, 2j_c)$ takes the value from that coarse point.\n- A fine point on a grid edge, e.g., $(2i_c+1, 2j_c)$, is the average of two adjacent coarse points.\n- A fine point at a cell center, $(2i_c+1, 2j_c+1)$, is the average of four surrounding coarse points.\nContributions from coarse-grid boundary points are zero due to the homogeneous Dirichlet conditions. Each row of the matrix $P$ is constructed by determining these weights for the corresponding fine-grid point.\n\n**Restriction $R$**: The restriction operator $R \\in \\mathbb{R}^{n_c \\times n_f}$ maps a fine-grid vector to a coarse-grid vector. We use full-weighting restriction. The value at a coarse-grid interior point $(i_c, j_c)$ is a weighted average of the values at the $3 \\times 3$ block of fine-grid points centered at its corresponding fine-grid location $(2i_c, 2j_c)$. The weights are given by the stencil:\n$$\n\\frac{1}{16}\n\\begin{bmatrix}\n1 & 2 & 1 \\\\\n2 & 4 & 2 \\\\\n1 & 2 & 1\n\\end{bmatrix}.\n$$\nAs with prolongation, fine-grid points on the boundary have a value of zero and do not contribute to the sum.\n\n### 3. Coarse-Grid Operators and Comparison\n\nTwo methods are used to define the coarse-grid operator.\n\n**Rediscretized Operator $A_c^{\\mathrm{Red}}$**: This operator is constructed by applying the same finite-difference discretization scheme directly on the coarse grid with spacing $H = 1/(N_c-1)$. The coefficient function $\\kappa(x,y)$ is evaluated at the face centers of the coarse-grid cells. This approach is simple but may fail to capture fine-scale variations in $\\kappa(x,y)$ that are aliased on the coarse grid.\n\n**Galerkin Operator $A_c^{\\mathrm{Gal}}$**: This operator is defined by the so-called Galerkin projection: $A_c^{\\mathrm{Gal}} = R A_f P$. It represents the fine-grid operator as \"viewed\" from the coarse grid. This construction is more computationally expensive but is guaranteed to capture the properties of the fine-grid operator $A_f$, making it robust for problems with complex or rapidly varying coefficients.\n\nThe fundamental difference between these two operators is the source of the numerical error. $A_c^{\\mathrm{Red}}$ inherits its properties from the truncation error of the discretization on the coarse grid. $A_c^{\\mathrm{Gal}}$ inherits its properties from the fine-grid operator via projection. For a constant coefficient $\\kappa$, the two are not identical; $A_c^{\\mathrm{Red}}$ typically has a 5-point stencil, while $A_c^{\\mathrm{Gal}}$ has a 9-point stencil. For variable $\\kappa$, the difference can be more pronounced.\n\nThe quantity to compute is the relative Frobenius-norm difference:\n$$\n\\delta = \\frac{\\lVert A_c^{\\mathrm{Gal}} - A_c^{\\mathrm{Red}} \\rVert_F}{\\lVert A_c^{\\mathrm{Red}} \\rVert_F},\n$$\nwhere $\\lVert M \\rVert_F = \\sqrt{\\sum_{i,j} |M_{ij}|^2}$. This metric quantifies the discrepancy between the two coarse-grid operator definitions.\n\nThe algorithm proceeds by implementing functions to construct each of the four matrices ($A_f$, $A_c^{\\mathrm{Red}}$, $P$, $R$) for the given parameters, then performing the matrix multiplication to obtain $A_c^{\\mathrm{Gal}}$, and finally computing $\\delta$. This process is repeated for each of the four test cases.",
            "answer": "```python\nimport numpy as np\n\ndef kappa(x, y, a, m):\n    \"\"\"Computes the continuous coefficient kappa(x,y).\"\"\"\n    return 1.0 + a * np.sin(2 * np.pi * m * x) * np.cos(2 * np.pi * m * y)\n\ndef construct_operator(N, a, m):\n    \"\"\"\n    Constructs the discrete operator matrix A for a given grid size N\n    and coefficient parameters a, m.\n    \"\"\"\n    if N <= 2:\n        return np.array([[]])\n    \n    n = (N - 2)**2\n    h = 1.0 / (N - 1)\n    A = np.zeros((n, n))\n    \n    width = N - 2\n    coords = np.linspace(0, 1, N)\n\n    for i in range(1, N - 1):      # 1-based row index\n        for j in range(1, N - 1):  # 1-based column index\n            k = (i - 1) * width + (j - 1) # 0-based 1D index\n            \n            x_i, y_j = coords[i], coords[j]\n            \n            k_ip12 = kappa(x_i + h / 2.0, y_j, a, m)\n            k_im12 = kappa(x_i - h / 2.0, y_j, a, m)\n            k_jp12 = kappa(x_i, y_j + h / 2.0, a, m)\n            k_jm12 = kappa(x_i, y_j - h / 2.0, a, m)\n\n            # Diagonal entry\n            A[k, k] = (k_ip12 + k_im12 + k_jp12 + k_jm12) / h**2\n            \n            # Off-diagonal entries (connections to neighbors)\n            # Connection to u_{i, j+1} (North)\n            if j < N - 2:\n                A[k, k + 1] = -k_jp12 / h**2\n            # Connection to u_{i, j-1} (South)\n            if j > 1:\n                A[k, k - 1] = -k_jm12 / h**2\n            # Connection to u_{i+1, j} (East)\n            if i < N - 2:\n                A[k, k + width] = -k_ip12 / h**2\n            # Connection to u_{i-1, j} (West)\n            if i > 1:\n                A[k, k - width] = -k_im12 / h**2\n                \n    return A\n\ndef construct_prolongation(N_f, N_c):\n    \"\"\"Constructs the bilinear interpolation (prolongation) operator P.\"\"\"\n    n_f = (N_f - 2)**2\n    n_c = (N_c - 2)**2\n    if n_f == 0 or n_c == 0:\n        return np.zeros((n_f, n_c))\n\n    P = np.zeros((n_f, n_c))\n    width_f = N_f - 2\n    width_c = N_c - 2\n    \n    for i_f in range(1, N_f - 1):\n        for j_f in range(1, N_f - 1):\n            k_f = (i_f - 1) * width_f + (j_f - 1)\n            \n            is_i_f_even = (i_f % 2 == 0)\n            is_j_f_even = (j_f % 2 == 0)\n\n            if is_i_f_even and is_j_f_even:\n                # Type 1: Fine node coincides with a coarse node\n                i_c, j_c = i_f // 2, j_f // 2\n                if 1 <= i_c <= N_c - 2 and 1 <= j_c <= N_c - 2:\n                    k_c = (i_c - 1) * width_c + (j_c - 1)\n                    P[k_f, k_c] = 1.0\n\n            elif not is_i_f_even and is_j_f_even:\n                # Type 2: Fine node on a vertical coarse-grid edge\n                j_c = j_f // 2\n                i_c_lo = (i_f - 1) // 2\n                i_c_hi = i_c_lo + 1\n                if 1 <= j_c <= N_c - 2:\n                    if 1 <= i_c_lo <= N_c - 2:\n                        k_c1 = (i_c_lo - 1) * width_c + (j_c - 1)\n                        P[k_f, k_c1] = 0.5\n                    if 1 <= i_c_hi <= N_c - 2:\n                        k_c2 = (i_c_hi - 1) * width_c + (j_c - 1)\n                        P[k_f, k_c2] = 0.5\n            \n            elif is_i_f_even and not is_j_f_even:\n                # Type 3: Fine node on a horizontal coarse-grid edge\n                i_c = i_f // 2\n                j_c_lo = (j_f - 1) // 2\n                j_c_hi = j_c_lo + 1\n                if 1 <= i_c <= N_c - 2:\n                    if 1 <= j_c_lo <= N_c - 2:\n                        k_c1 = (i_c - 1) * width_c + (j_c_lo - 1)\n                        P[k_f, k_c1] = 0.5\n                    if 1 <= j_c_hi <= N_c - 2:\n                        k_c2 = (i_c - 1) * width_c + (j_c_hi - 1)\n                        P[k_f, k_c2] = 0.5\n\n            elif not is_i_f_even and not is_j_f_even:\n                # Type 4: Fine node at a coarse-cell center\n                i_c_lo, j_c_lo = (i_f - 1) // 2, (j_f - 1) // 2\n                i_c_hi, j_c_hi = i_c_lo + 1, j_c_lo + 1\n                \n                nodes = [(i_c_lo, j_c_lo), (i_c_hi, j_c_lo), \n                         (i_c_lo, j_c_hi), (i_c_hi, j_c_hi)]\n                for i_c, j_c in nodes:\n                    if 1 <= i_c <= N_c - 2 and 1 <= j_c <= N_c - 2:\n                        k_c = (i_c - 1) * width_c + (j_c - 1)\n                        P[k_f, k_c] = 0.25\n    return P\n\ndef construct_restriction(N_f, N_c):\n    \"\"\"Constructs the full-weighting restriction operator R.\"\"\"\n    n_f = (N_f - 2)**2\n    n_c = (N_c - 2)**2\n    if n_f == 0 or n_c == 0:\n        return np.zeros((n_c, n_f))\n        \n    R = np.zeros((n_c, n_f))\n    width_f = N_f - 2\n    width_c = N_c - 2\n    \n    weights = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16.0\n    \n    for i_c in range(1, N_c - 1):\n        for j_c in range(1, N_c - 1):\n            k_c = (i_c - 1) * width_c + (j_c - 1)\n            i_f_center, j_f_center = 2 * i_c, 2 * j_c\n            \n            for di in range(-1, 2):\n                for dj in range(-1, 2):\n                    i_f, j_f = i_f_center + di, j_f_center + dj\n                    \n                    if 1 <= i_f <= N_f - 2 and 1 <= j_f <= N_f - 2:\n                        k_f = (i_f - 1) * width_f + (j_f - 1)\n                        R[k_c, k_f] = weights[di + 1, dj + 1]\n    return R\n\ndef compute_delta(N_f, a, m):\n    \"\"\"\n    Computes the relative Frobenius-norm difference for a given test case.\n    \"\"\"\n    # Grid parameters\n    N_c = (N_f + 1) // 2\n    \n    # Construct operators\n    A_f = construct_operator(N_f, a, m)\n    P = construct_prolongation(N_f, N_c)\n    R = construct_restriction(N_f, N_c)\n    A_c_red = construct_operator(N_c, a, m)\n    \n    # Compute Galerkin operator\n    A_c_gal = R @ A_f @ P\n    \n    # Compute relative difference\n    diff_norm = np.linalg.norm(A_c_gal - A_c_red, 'fro')\n    red_norm = np.linalg.norm(A_c_red, 'fro')\n    \n    if red_norm == 0:\n        return 0.0 if diff_norm == 0 else np.inf\n        \n    return diff_norm / red_norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (33, 0.5, 1),\n        (33, 0.0, 1),\n        (17, 0.9, 1),\n        (33, 0.7, 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        Nf, a, m = case\n        delta = compute_delta(Nf, a, m)\n        results.append(delta)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Having explored the key components of a multigrid solver, we now analyze its overall computational cost to understand its power. The method's efficiency stems from performing most of the work on much smaller coarse grids. This analytical exercise asks you to derive the total computational work for a W-cycle by setting up and solving a recurrence relation, proving that the cost is nearly proportional to the number of unknowns on the finest grid alone .",
            "id": "3480278",
            "problem": "In the construction of constraint-satisfying initial data for compact-object binaries in General Relativity (GR), one often solves a linear elliptic Partial Differential Equation (PDE) on a uniform, rectangular grid by Geometric Multigrid (MG). Consider such a discretization on a fine grid with $N_x \\times N_y$ interior degrees of freedom (DOF) in the $x$- and $y$-directions, respectively. A geometric grid hierarchy is formed by uniform coarsening, halving each dimension at every level, down to a minimal coarse grid of size $N_{x,c} \\times N_{y,c}$. Assume the coarsening is isotropic in the sense that $N_x / N_{x,c} = N_y / N_{y,c} = 2^L$ for some integer $L \\geq 0$, so the hierarchy has $L+1$ levels indexed by $\\ell = 0,1,\\dots,L$, with $\\ell=0$ the fine level and $\\ell=L$ the minimal coarse level.\n\nA Multigrid W-cycle is performed starting from the fine level: at each non-coarsest level, the algorithm descends to the next coarser level twice before returning upward. Define one \"work unit\" as the processing of one DOF once, and assume that the total local operations at level $\\ell$ (including smoothing, residual formation, restriction, prolongation, and correction) during one visit to that level cost $\\mathcal{O}(N^{(\\ell)})$ work units, where $N^{(\\ell)}$ is the number of DOF on level $\\ell$. Take the proportionality constant to be $1$, so the cost per visit to level $\\ell$ is exactly $N^{(\\ell)}$ work units, and the cost on the minimal coarse level is also $N^{(L)}$.\n\nConstruct the grid hierarchy explicitly in terms of $N_x$, $N_y$, $N_{x,c}$, $N_{y,c}$, and $L$, and then, starting from these definitions and the recursive structure of the W-cycle, derive a closed-form analytic expression for the total number of work units $C^{(0)}$ required by one W-cycle that starts on the fine level $\\ell=0$. Express your final answer as a single analytic expression in terms of $N_x$, $N_y$, and $L$; you may use the definition $L = \\log_2\\!\\big(N_x/N_{x,c}\\big) = \\log_2\\!\\big(N_y/N_{y,c}\\big)$ to relate $L$ to the grid sizes. No numerical evaluation or rounding is required.",
            "solution": "### Step 1: Extract Givens\n- The problem domain is a uniform, rectangular grid for solving a linear elliptic PDE.\n- The fine grid has $N_x \\times N_y$ interior degrees of freedom (DOF).\n- A geometric grid hierarchy is formed by uniform coarsening, halving each dimension at every level.\n- The minimal coarse grid has size $N_{x,c} \\times N_{y,c}$.\n- The coarsening is isotropic: $N_x / N_{x,c} = N_y / N_{y,c} = 2^L$ for an integer $L \\ge 0$.\n- The hierarchy has $L+1$ levels, indexed by $\\ell = 0, 1, \\dots, L$. Level $\\ell=0$ is the fine grid, $\\ell=L$ is the coarsest grid.\n- A Multigrid W-cycle descends to the next coarser level twice from any non-coarsest level.\n- One \"work unit\" is one operation on one DOF.\n- The cost of total local operations at level $\\ell$ during one visit is $N^{(\\ell)}$ work units, where $N^{(\\ell)}$ is the number of DOF on level $\\ell$.\n- The cost of solving on the minimal coarse level is $N^{(L)}$.\n- The task is to find the total work units $C^{(0)}$ for one W-cycle starting at the fine level $\\ell=0$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a well-defined exercise in algorithm analysis, specifically applied to the widely-used multigrid method in numerical analysis.\n- **Scientifically Grounded:** The context and methodology (multigrid solvers for elliptic equations in numerical relativity) are standard and represent a core topic in computational science and physics. The model for computational cost is a common simplification used for theoretical analysis. The problem is free of pseudoscience or factual inaccuracies.\n- **Well-Posed:** The problem provides all necessary information to construct and solve a recurrence relation for the computational cost. The definitions are clear, leading to a unique analytical solution.\n- **Objective:** The language is precise and technical, free from ambiguity or subjective claims.\n\nThe problem does not violate any of the invalidity criteria. It is a formalizable, relevant, complete, and well-structured question rooted in established scientific computing principles.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\n### Solution Derivation\n\nThe solution proceeds by first defining the number of degrees of freedom (DOF) at each level of the grid hierarchy, then establishing a recurrence relation for the computational cost of a W-cycle, and finally solving this recurrence to obtain a closed-form expression.\n\n**1. Grid Hierarchy Construction**\nLet $N^{(\\ell)}$ be the number of DOF at level $\\ell$ of the grid hierarchy.\nThe fine grid, at level $\\ell=0$, has $N^{(0)} = N_x N_y$ DOF.\nAccording to the problem, the grid at level $\\ell+1$ is formed by halving each dimension of the grid at level $\\ell$. For a 2D grid, this means the number of DOF is reduced by a factor of $2 \\times 2 = 4$.\nThus, the relationship between DOF at successive levels is:\n$$N^{(\\ell+1)} = \\frac{N^{(\\ell)}}{4}$$\nBy repeated application, we can express the number of DOF at any level $\\ell$ in terms of the fine-grid DOF, $N^{(0)}$:\n$$N^{(\\ell)} = \\frac{N^{(0)}}{4^\\ell} = \\frac{N_x N_y}{4^\\ell}$$\nThis holds for all levels $\\ell = 0, 1, \\dots, L$.\n\n**2. Recurrence Relation for W-cycle Cost**\nLet $C^{(\\ell)}$ denote the total number of work units for one W-cycle starting at level $\\ell$.\nA W-cycle at a non-coarsest level $\\ell$ (where $\\ell < L$) consists of:\n- Local operations on level $\\ell$ (smoothing, residual calculation, restriction, prolongation, correction). The problem states the total cost for these operations is $N^{(\\ell)}$.\n- Two recursive calls to a W-cycle on the next coarser level, $\\ell+1$. The cost of each of these calls is $C^{(\\ell+1)}$.\n\nThis structure gives the following recurrence relation for the total cost $C^{(\\ell)}$ for $\\ell \\in \\{0, 1, \\dots, L-1\\}$:\n$$C^{(\\ell)} = N^{(\\ell)} + 2 C^{(\\ell+1)}$$\nAt the coarsest level, $\\ell=L$, the problem is solved directly (e.g., by a direct solver or iterated smoothing). The problem specifies this cost as $N^{(L)}$. This provides the base case for our recursion:\n$$C^{(L)} = N^{(L)}$$\n\n**3. Solving the Recurrence Relation**\nWe want to find $C^{(0)}$, the cost of a W-cycle starting from the fine grid. We can solve the recurrence relation by unrolling it, starting from $\\ell=0$:\n$$C^{(0)} = N^{(0)} + 2 C^{(1)}$$\nSubstituting the expression for $C^{(1)}$:\n$$C^{(0)} = N^{(0)} + 2 \\left( N^{(1)} + 2 C^{(2)} \\right) = N^{(0)} + 2 N^{(1)} + 4 C^{(2)}$$\nContinuing this substitution until we reach the coarsest level $L$:\n$$C^{(0)} = N^{(0)} + 2 N^{(1)} + 4 N^{(2)} + \\dots + 2^{L-1} N^{(L-1)} + 2^L C^{(L)}$$\nNow, we substitute the base case $C^{(L)} = N^{(L)}$:\n$$C^{(0)} = N^{(0)} + 2 N^{(1)} + 4 N^{(2)} + \\dots + 2^{L-1} N^{(L-1)} + 2^L N^{(L)}$$\nThis can be expressed compactly using summation notation:\n$$C^{(0)} = \\sum_{j=0}^{L} 2^j N^{(j)}$$\n\n**4. Final Closed-Form Expression**\nTo get a closed-form expression, we substitute the formula for $N^{(j)}$ from step 1, $N^{(j)} = N^{(0)} / 4^j$:\n$$C^{(0)} = \\sum_{j=0}^{L} 2^j \\left( \\frac{N^{(0)}}{4^j} \\right)$$\nFactor out the constant $N^{(0)}$:\n$$C^{(0)} = N^{(0)} \\sum_{j=0}^{L} \\frac{2^j}{4^j} = N^{(0)} \\sum_{j=0}^{L} \\left( \\frac{2}{4} \\right)^j = N^{(0)} \\sum_{j=0}^{L} \\left( \\frac{1}{2} \\right)^j$$\nThe summation is a finite geometric series $\\sum_{k=0}^{n} r^k$ with $n=L$ terms and a common ratio $r=1/2$. The sum of such a series is given by the formula $\\frac{1-r^{n+1}}{1-r}$.\nApplying this formula, we get:\n$$\\sum_{j=0}^{L} \\left( \\frac{1}{2} \\right)^j = \\frac{1 - \\left(\\frac{1}{2}\\right)^{L+1}}{1 - \\frac{1}{2}} = \\frac{1 - \\frac{1}{2^{L+1}}}{\\frac{1}{2}} = 2 \\left( 1 - \\frac{1}{2^{L+1}} \\right) = 2 - \\frac{2}{2^{L+1}} = 2 - \\frac{1}{2^L}$$\nSubstituting this result back into the expression for $C^{(0)}$:\n$$C^{(0)} = N^{(0)} \\left( 2 - \\frac{1}{2^L} \\right)$$\nFinally, replacing $N^{(0)}$ with its definition $N_x N_y$, we obtain the total number of work units for one W-cycle:\n$$C^{(0)} = N_x N_y \\left( 2 - \\frac{1}{2^L} \\right)$$\nThis expression is in terms of the required variables $N_x$, $N_y$, and $L$.",
            "answer": "$$\n\\boxed{\nN_x N_y \\left( 2 - 2^{-L} \\right)\n}\n$$"
        }
    ]
}