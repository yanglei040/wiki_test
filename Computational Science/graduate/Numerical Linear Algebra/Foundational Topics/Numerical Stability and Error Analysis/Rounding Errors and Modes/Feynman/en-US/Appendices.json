{
    "hands_on_practices": [
        {
            "introduction": "To fully grasp the origins of rounding errors, we must first understand the fundamental structure of the floating-point number system. This practice guides you through calculating the key boundaries of a hypothetical system, from the smallest representable positive number to the largest. By defining the smallest normalized and subnormal numbers , you will build a concrete mental model of the discrete number line and see firsthand how gradual underflow bridges the gap between the normalized range and zero.",
            "id": "3575435",
            "problem": "Consider a floating-point system denoted by $F(\\beta,p,e_{\\min},e_{\\max})$, where a normalized floating-point number has the form $\\pm \\beta^{e}\\left(d_{0} + d_{1}\\beta^{-1} + d_{2}\\beta^{-2} + \\cdots + d_{p-1}\\beta^{-(p-1)}\\right)$ with $1 \\leq d_{0} \\leq \\beta - 1$, $0 \\leq d_{i} \\leq \\beta - 1$ for $i \\geq 1$, and $e_{\\min} \\leq e \\leq e_{\\max}$. When gradual underflow is supported, subnormal numbers are defined to have the fixed exponent $e=e_{\\min}$ and permit $d_{0}=0$, so that their significands can be as small as $d_{p-1}\\beta^{-(p-1)}$ with $d_{p-1} \\geq 1$.\n\nAssume the rounding mode is round-to-nearest, ties to even, as standardized in the Institute of Electrical and Electronics Engineers Standard for Floating-Point Arithmetic (IEEE 754). Let $\\beta=4$, $p=3$, $e_{\\min}=-6$, and $e_{\\max}=5$.\n\nUsing only the above definitions and well-established properties of floating-point representations, compute:\n- the smallest positive normalized representable number in $F(4,3,-6,5)$,\n- the largest positive normalized representable number in $F(4,3,-6,5)$,\n- the smallest positive subnormal number when gradual underflow is allowed.\n\nThen, explain how these values demonstrate the notion of gradual underflow by quantifying the spacing of subnormal numbers and its continuity with the normalized range at the underflow boundary under the specified rounding mode.\n\nExpress your final answer as a row vector of the three quantities in exact form. No rounding is required.",
            "solution": "The problem is well-posed and scientifically grounded in the principles of floating-point arithmetic as defined by the IEEE 754 standard. All necessary parameters for the floating-point system $F(\\beta, p, e_{\\min}, e_{\\max})$ are provided. The definitions of normalized and subnormal numbers are standard and unambiguous. Therefore, a valid solution can be derived.\n\nThe specified floating-point system is $F(\\beta, p, e_{\\min}, e_{\\max})$ with base $\\beta=4$, precision $p=3$, minimum exponent $e_{\\min}=-6$, and maximum exponent $e_{\\max}=5$.\n\nA positive normalized floating-point number $x$ in this system has the form:\n$$x = \\left(d_{0} + d_{1}\\beta^{-1} + d_{2}\\beta^{-2}\\right) \\times \\beta^{e} = (d_{0}.d_{1}d_{2})_{\\beta} \\times \\beta^{e}$$\nwhere the digits $d_i$ satisfy $1 \\leq d_{0} \\leq 3$ and $0 \\leq d_{1}, d_{2} \\leq 3$, and the exponent $e$ is in the range $-6 \\leq e \\leq 5$.\n\nA positive subnormal floating-point number $x_{sub}$ (with gradual underflow) has the form:\n$$x_{sub} = \\left(0 + d_{1}\\beta^{-1} + d_{2}\\beta^{-2}\\right) \\times \\beta^{e_{\\min}} = (0.d_{1}d_{2})_{\\beta} \\times \\beta^{-6}$$\nwhere at least one of the digits $d_1$ or $d_2$ must be non-zero.\n\nWe now compute the required quantities.\n\n**1. Smallest Positive Normalized Representable Number**\nTo find the smallest positive normalized number, we must select the minimum possible significand and the minimum possible exponent.\nThe minimum exponent is $e = e_{\\min} = -6$.\nFor a normalized number, the leading digit $d_0$ must be at least $1$. To minimize the significand, we choose the smallest possible digits: $d_{0} = 1$, $d_{1} = 0$, and $d_{2} = 0$.\nThe smallest normalized significand is $(1.00)_{4} = 1 + 0 \\cdot 4^{-1} + 0 \\cdot 4^{-2} = 1$.\nTherefore, the smallest positive normalized number, denoted $x_{\\min\\_norm}$, is:\n$$x_{\\min\\_norm} = 1 \\times 4^{e_{\\min}} = 1 \\times 4^{-6} = 4^{-6}$$\n\n**2. Largest Positive Normalized Representable Number**\nTo find the largest positive normalized number, we must select the maximum possible significand and the maximum possible exponent.\nThe maximum exponent is $e = e_{\\max} = 5$.\nTo maximize the significand, we choose the largest possible digits, which are $\\beta-1=3$. Thus, $d_0=3$, $d_1=3$, and $d_2=3$.\nThe largest normalized significand is $(3.33)_{4} = 3 + 3 \\cdot 4^{-1} + 3 \\cdot 4^{-2}$.\nThis can be calculated as:\n$$M_{\\max\\_norm} = 3 + \\frac{3}{4} + \\frac{3}{16} = \\frac{48 + 12 + 3}{16} = \\frac{63}{16}$$\nAlternatively, this significand is the largest number in the system with $p=3$ digits before the base point shifts, which is $4 - 4^{-(p-1)} = 4 - 4^{-2}$.\n$$M_{\\max\\_norm} = 4 - \\frac{1}{16} = \\frac{63}{16}$$\nTherefore, the largest positive normalized number, denoted $x_{\\max\\_norm}$, is:\n$$x_{\\max\\_norm} = \\left(4 - 4^{-2}\\right) \\times 4^{e_{\\max}} = \\left(4 - 4^{-2}\\right) \\times 4^{5} = 4^{6} - 4^{3}$$\n$$x_{\\max\\_norm} = 4096 - 64 = 4032$$\n\n**3. Smallest Positive Subnormal Number**\nFor subnormal numbers, the exponent is fixed at $e = e_{\\min} = -6$, and the leading digit is $d_0 = 0$. The number's form is $(0.d_{1}d_{2})_{4} \\times 4^{-6}$.\nTo find the smallest positive value, we must find the smallest non-zero significand. This occurs when we choose the smallest possible non-zero values for the digits. We set $d_1=0$ and the last digit $d_2=1$.\nThe smallest subnormal significand is $(0.01)_{4} = 0 + 0 \\cdot 4^{-1} + 1 \\cdot 4^{-2} = 4^{-2}$.\nTherefore, the smallest positive subnormal number, denoted $x_{\\min\\_sub}$, is:\n$$x_{\\min\\_sub} = 4^{-2} \\times 4^{e_{\\min}} = 4^{-2} \\times 4^{-6} = 4^{-8}$$\n\n**Explanation of Gradual Underflow**\nGradual underflow is a mechanism that allows for a graceful loss of precision when a result is smaller in magnitude than the smallest normalized number. The values computed above illustrate this concept perfectly by examining the spacing of representable numbers around the underflow boundary.\n\nThe fundamental unit of spacing for a floating-point number is the \"unit in the last place\" (ULP). For a number with exponent $e$, the ULP is $\\beta^{e-(p-1)}$. In our system $F(4,3,-6,5)$, the ULP is $4^{e-2}$.\n\nLet's consider the spacing of normalized numbers near the underflow threshold. The smallest normalized number is $x_{\\min\\_norm} = (1.00)_4 \\times 4^{-6} = 4^{-6}$. The exponent is $e=-6$.\nThe ULP for this exponent is $4^{-6-2} = 4^{-8}$.\nThe next representable normalized number is $(1.01)_4 \\times 4^{-6} = (1 + 4^{-2}) \\times 4^{-6} = 4^{-6} + 4^{-8}$.\nThe absolute gap between the first two normalized numbers is $(4^{-6} + 4^{-8}) - 4^{-6} = 4^{-8}$.\n\nNow, let's examine the subnormal numbers. They are of the form $(0.d_1 d_2)_4 \\times 4^{-6}$. This can be rewritten as:\n$$(d_1 \\cdot 4^{-1} + d_2 \\cdot 4^{-2}) \\times 4^{-6} = (4d_1 + d_2) \\cdot 4^{-2} \\cdot 4^{-6} = (4d_1 + d_2) \\cdot 4^{-8}$$\nSince $d_1, d_2 \\in \\{0, 1, 2, 3\\}$, the integer value $4d_1 + d_2$ can range from $1$ (for $d_1=0, d_2=1$) up to $15$ (for $d_1=3, d_2=3$).\nThis means the positive subnormal numbers are precisely the integer multiples of $4^{-8}$:\n$$1 \\cdot 4^{-8}, 2 \\cdot 4^{-8}, 3 \\cdot 4^{-8}, \\dots, 15 \\cdot 4^{-8}$$\nThe smallest of these is $x_{\\min\\_sub} = 1 \\cdot 4^{-8} = 4^{-8}$. The spacing between any two consecutive subnormal numbers is uniformly $4^{-8}$.\n\nThe \"gradual\" nature of the underflow is demonstrated by the seamless transition in spacing at the boundary between subnormal and normalized numbers.\nThe largest subnormal number is $(0.33)_4 \\times 4^{-6} = (4 \\cdot 3 + 3) \\cdot 4^{-8} = 15 \\cdot 4^{-8}$.\nThe smallest normalized number is $(1.00)_4 \\times 4^{-6} = 1 \\cdot 4^{-6} = 16 \\cdot 4^{-8}$.\nThe gap between the largest subnormal and the smallest normalized number is $(16 \\cdot 4^{-8}) - (15 \\cdot 4^{-8}) = 4^{-8}$.\n\nThis spacing, $4^{-8}$, is identical to the spacing between consecutive subnormal numbers and also identical to the spacing between the first few normalized numbers. Without gradual underflow, any result less than $x_{\\min\\_norm} = 4^{-6}$ would be flushed to $0$, creating a large gap between $0$ and the first representable number. Gradual underflow fills this gap with subnormal numbers that maintain the same absolute spacing as the nearby normalized numbers, ensuring that the distance between adjacent representable numbers decreases smoothly all the way to zero. This prevents the undesirable property where `x - y` could be $0$ even when `x` and `y` are not equal, by ensuring that $x-y$ is representable as a subnormal number if it falls in that range.",
            "answer": "$$\\boxed{\\begin{pmatrix} 4^{-6} & 4032 & 4^{-8} \\end{pmatrix}}$$"
        },
        {
            "introduction": "Having mapped the boundaries of a floating-point system, we now explore what occurs when an arithmetic operation yields a result that falls into the subnormal region. This exercise  presents a multiplication whose exact product is not representable, forcing a rounding decision involving subnormal numbers. Working through this example will solidify your understanding of gradual underflow and the application of tie-breaking rules in the delicate region near zero.",
            "id": "3575479",
            "problem": "In the Institute of Electrical and Electronics Engineers (IEEE) Standard 754 binary64 (double-precision) format, the radix is $2$, the precision is $t=53$ bits in the significand (including the implicit leading bit for normalized numbers), and the unbiased exponent range for normalized numbers is $e \\in \\{-1022, -1021, \\dots, 1023\\}$. Subnormal numbers are those with magnitude strictly less than $2^{-1022}$, represented with an implicit leading $0$ in the significand and a fixed exponent $e_{\\min}=-1022$. The rounding mode is round-to-nearest, ties-to-even.\n\nConsider the two exactly representable double-precision numbers\n$x = 1.5 \\times 2^{-500}$ and $y = 2^{-574}$.\nAssume that floating-point multiplication is performed as exact real multiplication followed by a single rounding to a representable double-precision number under the given rounding mode, with subnormals allowed.\n\nStarting only from the foundational definitions of the IEEE 754 binary64 format (including normalized and subnormal representations and the round-to-nearest, ties-to-even rule), determine the exact rounded product $\\operatorname{fl}(x\\,y)$ when $x$ and $y$ are multiplied, and assess the rounding error relative to the exact real product $x\\,y$.\n\nProvide, as your final answer, the absolute rounding error $|\\operatorname{fl}(x\\,y)-x\\,y|$ expressed exactly as a single power of $2$. No rounding is required for the final answer. Do not include units. If you choose to express any intermediate quantities numerically, you may do so, but the final reported quantity must be the exact power of $2$ requested.",
            "solution": "The problem asks for the absolute rounding error resulting from the multiplication of two double-precision floating-point numbers, $x = 1.5 \\times 2^{-500}$ and $y = 2^{-574}$, under the rules of IEEE 754 binary64 format with round-to-nearest, ties-to-even rounding.\n\nFirst, we confirm that the input numbers $x$ and $y$ are themselves exactly representable in the specified format.\nThe general form of a normalized binary64 number is $(-1)^s \\times (1.f)_2 \\times 2^e$, where $s$ is the sign bit, $(1.f)_2$ is the significand with a total precision of $t=53$ bits (1 implicit, 52 fractional), and the unbiased exponent $e$ is in the range $[-1022, 1023]$.\nThe number $x = 1.5 \\times 2^{-500}$ can be written as $(1 + 0.5) \\times 2^{-500} = (1.1)_2 \\times 2^{-500}$. The significand $(1.1)_2$ is representable using $2$ of the available $53$ bits, and the exponent $e = -500$ is within the valid range $[-1022, 1023]$. Thus, $x$ is a representable normalized number.\nThe number $y = 2^{-574}$ can be written as $1.0 \\times 2^{-574}$. The significand $(1.0)_2$ is representable, and the exponent $e=-574$ is also within the valid range. Thus, $y$ is a representable normalized number.\n\nThe process involves first computing the exact real product of $x$ and $y$, and then rounding this result to the nearest representable binary64 number.\n\nStep 1: Calculate the exact product.\nLet $z$ be the exact real product of $x$ and $y$.\n$$z = x \\cdot y = (1.5 \\times 2^{-500}) \\times (2^{-574})$$\n$$z = 1.5 \\times 2^{-500 - 574}$$\n$$z = 1.5 \\times 2^{-1074}$$\nIn binary, this is $z = (1.1)_2 \\times 2^{-1074}$.\n\nStep 2: Analyze the exact product $z$.\nThe exponent of $z$ is $e = -1074$. The minimum exponent for a normalized number in binary64 is $e_{\\min, \\text{norm}} = -1022$. Since $e < e_{\\min, \\text{norm}}$, the result $z$ falls within the subnormal range.\nSubnormal numbers in binary64 are represented with a fixed exponent equal to the minimum normalized exponent, $e_{\\min} = -1022$, and an implicit leading bit of $0$ in the significand. The form is $(0.f)_2 \\times 2^{-1022}$, where $f$ is the $52$-bit fraction.\nWe must re-express $z$ with an exponent of $-1022$:\n$$z = 1.5 \\times 2^{-1074} = 1.5 \\times 2^{-1074 + 1022} \\times 2^{-1022} = 1.5 \\times 2^{-52} \\times 2^{-1022}$$\nThe significand of $z$ would be $M_z = 1.5 \\times 2^{-52}$. Let's express this in binary:\n$$M_z = (1+0.5) \\times 2^{-52} = 2^{-52} + 2^{-53}$$\n$$M_z = (0.\\underbrace{00\\dots0}_{51 \\text{ zeros}}1)_2 + (0.\\underbrace{00\\dots0}_{52 \\text{ zeros}}1)_2 = (0.\\underbrace{00\\dots0}_{51 \\text{ zeros}}11)_2$$\nThe significand $M_z$ requires $53$ bits after the binary point to be represented exactly. However, the fraction field in the binary64 format for subnormal numbers only provides $52$ bits. Therefore, $z$ is not an exactly representable number and must be rounded.\n\nStep 3: Identify the bracketing representable numbers.\nThe representable subnormal numbers are integer multiples of the smallest possible subnormal increment, which corresponds to the value of the least significant bit (LSB) of the fraction. This value is $2^{-52} \\times 2^{-1022} = 2^{-1074}$. Let's call this the subnormal unit in the last place (ulp), $\\epsilon_{\\text{sub}} = 2^{-1074}$.\nThe exact product is $z = 1.5 \\times 2^{-1074} = 1.5 \\times \\epsilon_{\\text{sub}}$.\nThe two representable binary64 numbers that bracket $z$ are:\n$z_{-} = 1 \\times \\epsilon_{\\text{sub}} = 1 \\times 2^{-1074}$. This number corresponds to a subnormal representation with a significand fraction having its LSB set to $1$ and all other bits to $0$. The integer value of its $52$-bit fraction is $1$.\n$z_{+} = 2 \\times \\epsilon_{\\text{sub}} = 2 \\times 2^{-1074}$. This corresponds to a subnormal representation where the integer value of its $52$-bit fraction is $2$.\n\nStep 4: Apply the rounding mode.\nThe exact value $z = 1.5 \\times 2^{-1074}$ lies exactly halfway between $z_-$ and $z_+$. This is a tie case.\nThe rounding mode is round-to-nearest, ties-to-even. In a tie, we must round to the number for which the LSB of the significand is $0$. The significand here is considered as the integer represented by the 52 fraction bits.\nFor $z_{-}$, the integer value of the fraction part of the significand is $1$, which is odd.\nFor $z_{+}$, the integer value of the fraction part of the significand is $2$, which is even.\nTherefore, the rule dictates rounding up to $z_{+}$.\nThe rounded product is $\\operatorname{fl}(x\\,y) = z_{+}$.\n$$\\operatorname{fl}(x\\,y) = 2 \\times 2^{-1074} = 2^{-1073}$$\n\nStep 5: Calculate the absolute rounding error.\nThe absolute rounding error is the magnitude of the difference between the rounded value and the exact value.\n$$\\text{Absolute Error} = |\\operatorname{fl}(x\\,y) - z|$$\n$$\\text{Absolute Error} = |2 \\times 2^{-1074} - 1.5 \\times 2^{-1074}|$$\n$$\\text{Absolute Error} = |(2 - 1.5)| \\times 2^{-1074}$$\n$$\\text{Absolute Error} = 0.5 \\times 2^{-1074}$$\n$$\\text{Absolute Error} = 2^{-1} \\times 2^{-1074}$$\n$$\\text{Absolute Error} = 2^{-1075}$$\n\nThe absolute rounding error is exactly $2^{-1075}$.",
            "answer": "$$\\boxed{2^{-1075}}$$"
        },
        {
            "introduction": "While many floating-point operations introduce unavoidable rounding errors, some computations can be exact. This practice explores a crucial condition, formalized in a result known as Sterbenz's lemma, that guarantees the exact representability of the difference between two floating-point numbers. By deriving the threshold and testing it with carefully chosen examples , you will gain insight into a fundamental property that underpins the error analysis of many numerical algorithms.",
            "id": "3575443",
            "problem": "Consider the Institute of Electrical and Electronics Engineers (IEEE) Standard 754 binary64 floating-point arithmetic with base $\\beta = 2$, precision $p = 53$ (including the implicit leading bit), and rounding to nearest, ties to even. Work only with normalized floating-point numbers and exact real arithmetic when reasoning about representability. Use the following foundational facts as your starting point: in base-$2$ normalized floating-point, any nonzero number $x$ can be written uniquely as $x = m \\cdot 2^{E}$ with integer $m$ satisfying $2^{p-1} \\leq m < 2^{p}$, and for any fixed exponent $E$, the distance between consecutive representable numbers in the binade $[2^{E}, 2^{E+1})$ equals $2^{E-(p-1)}$. Define the unit in the last place (ULP) at $x$ as the distance to the next larger representable number at the scale of $x$.\n1) Derive, from these principles and without quoting any theorems, the sharp multiplicative threshold $T \\geq 1$ with the following property: for any two normalized floating-point numbers $x$ and $y$ with $y \\neq 0$ and\n$$\nT^{-1} \\leq \\frac{x}{y} \\leq T,\n$$\nthe exact real difference $x - y$ is itself a normalized floating-point number in this system (hence subtraction is exact under any rounding mode). Your derivation should identify the necessary alignment of exponents, characterize the integer significands before and after alignment, and show that no rounding is needed in this regime.\n2) Give concrete double-precision (binary64) examples illustrating both exact and inexact subtraction outcomes under rounding to nearest, ties to even, and explain each outcome from first principles (ULP and binade structure):\n- Example A (candidate for exact): take $x_{A} = 1 + 2^{-52}$ and $y_{A} = 1$.\n- Example B (candidate for inexact): take $x_{B} = 1$ and $y_{B} = 2^{-53}$.\n- Example C (candidate for exact): take $x_{C} = \\frac{11}{8}$ and $y_{C} = \\frac{3}{4}$.\nFor each example, compute the exact real difference and the floating-point result $\\mathrm{fl}(x - y)$ under the given rounding mode, and state whether subtraction is exact or inexact, justifying your claim by analyzing ULP-scale spacing and the ratio condition relative to your derived threshold.\nReport only the exact value of the threshold $T$ as your final answer. No rounding is required.",
            "solution": "The problem is divided into two parts. The first part requires the derivation of a sharp multiplicative threshold $T$ for exact floating-point subtraction. The second part requires the analysis of three specific examples.\n\nPart 1: Derivation of the Threshold $T$\n\nLet $x$ and $y$ be two normalized floating-point numbers in the specified system, with base $\\beta=2$ and precision $p=53$. According to the problem statement, any such number $z \\neq 0$ can be uniquely written as $z = m \\cdot 2^E$, where $m$ is an integer satisfying $2^{p-1} \\leq m  2^p$, and $E$ is an integer exponent. This representation can be mapped to the more standard form $z = f \\cdot 2^e$, where $1 \\le f  2$ is the significand and $e$ is the exponent, by setting $f=m/2^{p-1}$ and $e=E+p-1$. The significand $f$ of any such number is a rational number of the form $M/2^{p-1}$ for some integer $M \\in [2^{p-1}, 2^p)$.\n\nWe seek the sharp threshold $T \\geq 1$ such that if $T^{-1} \\leq x/y \\leq T$, the difference $x-y$ is an exactly representable normalized floating-point number. Subtraction being exact means no rounding is necessary to store the result.\n\nWithout loss of generality, let's assume $x \\geq y > 0$. The condition then simplifies to $1 \\leq x/y \\leq T$. The case $y > x > 0$ is symmetric: if $y-x$ is exact, then $x-y = -(y-x)$ is also exact.\n\nLet the representations of $x$ and $y$ be:\n$x = m_x \\cdot 2^{E_x}$\n$y = m_y \\cdot 2^{E_y}$\nwhere $m_x$ and $m_y$ are $p$-bit integers such that $2^{p-1} \\leq m_x, m_y  2^p$.\n\nThe exact difference is $x-y = m_x \\cdot 2^{E_x} - m_y \\cdot 2^{E_y}$. To perform the subtraction, the exponents must be aligned. Let $k = E_x - E_y$. Since $x \\geq y$, we have $x = m_x 2^{E_x} \\ge y = m_y 2^{E_y}$. The ratio $x/y = (m_x/m_y) 2^k$. Given that $1/2  m_x/m_y  2$, we have $2^{k-1}  x/y  2^{k+1}$. Since $x/y \\ge 1$, we must have $k+1 > \\log_2(1) = 0$, so $k > -1$, which implies $k \\ge 0$.\n\nThe difference can be written with a common exponent $E_y$ as:\n$x-y = (m_x \\cdot 2^{E_x - E_y} - m_y) \\cdot 2^{E_y} = (m_x 2^k - m_y) \\cdot 2^{E_y}$.\nLet $D = m_x 2^k - m_y$. $D$ is an integer. The difference $x-y$ is exactly representable if it can be written in the form $m_d \\cdot 2^{E_d}$ for some integers $m_d, E_d$ with $2^{p-1} \\leq m_d  2^p$. This is possible if and only if the integer $D$ can be expressed as $m_d \\cdot 2^s$ for some integer $s$, where $m_d$ is an integer requiring at most $p$ bits for its binary representation and falls within the normalized range once shifted. More formally, let $D = \\tilde{D} \\cdot 2^s$ where $\\tilde{D}$ is an odd integer. The result is exactly representable if $\\tilde{D}$ can be stored in a $p$-bit significand, which requires $\\tilde{D}  2^p$.\n\nThe condition on the ratio is $1 \\leq x/y \\leq T$. We will test the hypothesis that the sharp threshold is $T=2$. So, we analyze the condition $1 \\leq x/y \\leq 2$.\nFrom $2^{k-1}  x/y \\le 2$, we must have $k-1  \\log_2(2) = 1$, which implies $k2$. As established, $k \\ge 0$. So, $k$ can only be $0$ or $1$.\n\nCase 1: $k=0$ ($E_x = E_y$).\nThe condition $1 \\leq x/y \\leq 2$ becomes $1 \\leq m_x/m_y  2$. Since $m_x, m_y \\ge 2^{p-1}$, this is always satisfied when $x \\ge y$ and $k=0$.\nThe integer difference is $D = m_x - m_y$. Since $x \\ge y$, we have $D \\ge 0$.\nThe integer significands are bounded: $2^{p-1} \\leq m_y \\leq m_x  2^p$.\nThus, $D = m_x - m_y  2^p - 2^{p-1} = 2^{p-1}$.\nThe odd part of $D$, $\\tilde{D}$, must be less than $D$, so $\\tilde{D}  2^{p-1}$. This is strictly less than $2^p$. Therefore, $D$ can be normalized to a $p$-bit significand, and the subtraction is always exact.\n\nCase 2: $k=1$ ($E_x = E_y+1$).\nThe condition $1 \\leq x/y \\leq 2$ becomes $1 \\leq (m_x/m_y) \\cdot 2 \\leq 2$, which implies $1/2 \\leq m_x/m_y \\leq 1$.\nThe integer difference is $D = m_x 2^1 - m_y$. From $m_x/m_y \\leq 1$, we have $m_x \\leq m_y$.\nThen $D = 2m_x - m_y \\leq 2m_x - m_x = m_x$.\nSince $m_x  2^p$, we have $D  2^p$.\nThe odd part of $D$, $\\tilde{D}$, must be less than or equal to $D$, so $\\tilde{D}  2^p$. This condition guarantees that the result is exactly representable.\n\nCombining the cases, if $1 \\le x/y \\le 2$, the subtraction $x-y$ is exact.\nIf we consider $y > x > 0$, the condition $T^{-1} \\le x/y \\le T$ becomes $1/2 \\le x/y  1$. Let $x' = y$ and $y'=x$. Then $1  x'/y' \\le 2$. From the analysis above, $x'-y' = y-x$ is exact. Therefore, $x-y=-(y-x)$ is also exact.\nThus, for any two normalized floating-point numbers $x,y$, if $1/2 \\leq x/y \\leq 2$, the difference $x-y$ is exact. This shows that $T=2$ is a valid threshold.\n\nTo prove that $T=2$ is the sharpest possible threshold, we must show that for any $T > 2$, there exist $x, y$ such that $2  x/y \\le T$ and $x-y$ is not exactly representable.\nConsider a ratio just above $2$. Let $k = E_x - E_y = 2$. Then $x/y = (m_x/m_y) \\cdot 4$. To make this just above $2$, we need $m_x/m_y$ to be just above $1/2$.\nLet's choose $m_x = 2^{p-1}$ (the smallest $p$-bit normalized integer significand) and $m_y = 2^p-1$ (the largest one).\nWith $p=53$:\n$x = 2^{52} \\cdot 2^{E_x}$\n$y = (2^{53}-1) \\cdot 2^{E_y}$\nSet $E_x = E_y+2$, so $k=2$.\nThe ratio is $x/y = \\frac{2^{52}}{2^{53}-1} \\cdot 2^2 = \\frac{2^{54}}{2^{53}-1} = \\frac{2(2^{53}-1)+2}{2^{53}-1} = 2 + \\frac{2}{2^{53}-1}$. This ratio is slightly greater than $2$.\nLet's compute the integer form of the difference:\n$D = m_x 2^k - m_y = 2^{52} \\cdot 2^2 - (2^{53}-1) = 2^{54} - 2^{53} + 1 = 2 \\cdot 2^{53} - 2^{53} + 1 = 2^{53}+1$.\nThe integer result is $D=2^{53}+1$. In binary, this is a $1$ followed by $52$ zeros and then a $1$. It requires $p+1=54$ bits to represent. The odd part is $\\tilde{D}=D=2^{53}+1$.\nSince $\\tilde{D} > 2^{53}$, it cannot be represented by a $p=53$ bit significand. The result $x-y=D \\cdot 2^{E_y}=(2^{53}+1) \\cdot 2^{E_y}$ is not exactly representable. It must be rounded.\nThis demonstrates that for any ratio $x/y > 2$, exact subtraction is not guaranteed. Thus, the threshold $T=2$ is sharp.\n\nPart 2: Analysis of Examples\n\nWe use $p=53$ for binary64.\n\nExample A: $x_{A} = 1 + 2^{-52}$, $y_{A} = 1$.\n$x_A$ and $y_A$ are consecutive normalized floating-point numbers in the binade $[1, 2)$. The unit in the last place (ULP) in this binade is $2^{0-(p-1)} = 2^{-52}$.\n$x_A = (1+2^{-52}) \\cdot 2^0$. This has significand $1+2^{-52}$ and exponent $0$. It is a valid binary64 number.\n$y_A = 1 = 1.0 \\cdot 2^0$. Also a valid binary64 number.\nThe ratio is $x_A/y_A = 1+2^{-52}$. This lies in the interval $[1/2, 2]$. Our derived theorem predicts exact subtraction.\nThe exact real difference is $x_A - y_A = (1+2^{-52}) - 1 = 2^{-52}$.\nThe number $2^{-52}$ can be written as $1.0 \\cdot 2^{-52}$, which is a normalized binary64 number (significand is $1.0$, exponent is $-52$).\nThe result $\\mathrm{fl}(x_A - y_A)$ is exactly $2^{-52}$. The subtraction is **exact**.\n\nExample B: $x_{B} = 1$, $y_{B} = 2^{-53}$.\n$x_B = 1 = 1.0 \\cdot 2^0$. Normalized.\n$y_B = 2^{-53} = 1.0 \\cdot 2^{-53}$. Normalized.\nThe ratio is $x_B/y_B = 1 / 2^{-53} = 2^{53}$. This is much larger than the threshold $T=2$. The theorem does not guarantee exact subtraction.\nThe exact real difference is $x_B - y_B = 1 - 2^{-53}$.\nLet's check if this is an exactly representable binary64 number.\n$1 - 2^{-53} = (2-2^{-52}) \\cdot 2^{-1}$.\nThe significand would be $f_d = 2-2^{-52} = 1 + (1-2^{-52}) = 1 + \\sum_{i=1}^{52} 2^{-i}$. This corresponds to a binary representation of $1.11...1$ with $52$ ones after the binary point. This is a valid $p=53$ bit significand. The exponent is $e_d = -1$, which is a valid exponent.\nThus, $1-2^{-53}$ is an exactly representable binary64 number. It is, in fact, the largest representable number strictly less than $1$.\nSince the exact result is a representable number, no rounding is needed. The calculated floating-point result is $\\mathrm{fl}(x_B - y_B) = 1-2^{-53}$. The subtraction is **exact**. This demonstrates that the Sterbenz condition ($T^{-1} \\le x/y \\le T$) is sufficient, not necessary, for exact subtraction.\n\nExample C: $x_{C} = \\frac{11}{8}$, $y_{C} = \\frac{3}{4}$.\n$x_C = \\frac{11}{8} = 1.375 = (1.011)_2 = 1.375 \\cdot 2^0$. This is a normalized binary64 number.\n$y_C = \\frac{3}{4} = 0.75 = (0.11)_2 = 1.5 \\cdot 2^{-1}$. This is a normalized binary64 number.\nThe ratio is $x_C/y_C = (\\frac{11}{8}) / (\\frac{3}{4}) = \\frac{11}{8} \\cdot \\frac{4}{3} = \\frac{11}{6} \\approx 1.833$.\nThis ratio lies in the interval $[1, 2]$, so it satisfies the condition $1/2 \\leq x_C/y_C \\leq 2$. The theorem predicts exact subtraction.\nThe exact real difference is $x_C - y_C = \\frac{11}{8} - \\frac{6}{8} = \\frac{5}{8}$.\nThe number $\\frac{5}{8} = 0.625 = (0.101)_2 = 1.25 \\cdot 2^{-1}$. The significand $1.25$ and exponent $-1$ form a valid normalized binary64 number.\nThe result $\\mathrm{fl}(x_C - y_C)$ is exactly $\\frac{5}{8}$. The subtraction is **exact**.\nThis can also be seen by noting that both operands and the result are integer multiples of a common smaller value, $\\frac{1}{8}$, which is itself a floating-point number.\n$x_C=11 \\cdot (\\frac{1}{8})$, $y_C=6 \\cdot (\\frac{1}{8})$, so $x_C-y_C=5 \\cdot (\\frac{1}{8}) = \\frac{5}{8}$.\n\nThe final answer required is only the value of the threshold $T$.",
            "answer": "$$\n\\boxed{2}\n$$"
        }
    ]
}