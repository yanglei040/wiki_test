{
    "hands_on_practices": [
        {
            "introduction": "在数值计算中，我们通常只能轻易计算出残差 $r = b - A\\hat{x}$，而无法直接得知真实的“前向误差” $x - \\hat{x}$。本练习提供了一个具体的计算实践，旨在推导并应用一个基本不等式，该不等式利用残差和矩阵的条件数来约束前向误差。通过这个练习，你将深刻理解为何病态问题（即条件数大的问题）在数值求解中如此具有挑战性 。",
            "id": "3581515",
            "problem": "考虑线性系统 $A x = b$，其中\n$$A = \\mathrm{diag}(1, 10, 100), \\quad b = \\begin{pmatrix} 6 \\\\ 8 \\\\ 0 \\end{pmatrix}$$\n一个数值算法产生了一个近似解 $\\hat{x}$，其残差 $r$ 经测量为\n$$r = b - A \\hat{x} = \\begin{pmatrix} 1 \\times 10^{-6} \\\\ -2 \\times 10^{-6} \\\\ 2 \\times 10^{-6} \\end{pmatrix}$$\n使用欧几里得向量范数 $\\|\\cdot\\|_{2}$ 和相关的诱导矩阵范数，并视该矩阵 $A$ 在谱范数下的条件数 $\\kappa_{2}(A)$ 为已知，从第一性原理推导相对前向误差 $\\dfrac{\\|x - \\hat{x}\\|_{2}}{\\|x\\|_{2}}$ 的一个先验上界（仅依赖于 $\\kappa_{2}(A)$、$\\|r\\|_{2}$ 和 $\\|b\\|_{2}$），其中 $x$ 是 $A x = b$ 的精确解。然后，对给定的数据，数值计算这个上界。将你最终的数值上界四舍五入到四位有效数字。",
            "solution": "本解答旨在推导一个线性系统近似解的相对前向误差的先验上界，并数值计算该上界。\n\n### 步骤 1：问题验证\n\n**1.1. 提取已知条件：**\n- 线性系统: $A x = b$\n- 矩阵 $A$: $A = \\mathrm{diag}(1, 10, 100)$\n- 向量 $b$: $b = \\begin{pmatrix} 6 \\\\ 8 \\\\ 0 \\end{pmatrix}$\n- 精确解: $x$\n- 近似解: $\\hat{x}$\n- 残差向量 $r$: $r = b - A \\hat{x} = \\begin{pmatrix} 1 \\times 10^{-6} \\\\ -2 \\times 10^{-6} \\\\ 2 \\times 10^{-6} \\end{pmatrix}$\n- 范数: 欧几里得向量范数 $\\|\\cdot\\|_{2}$ 和相关的诱导矩阵范数（谱范数）。\n- 已知常数: 条件数 $\\kappa_{2}(A)$。\n- 目标: 以 $\\kappa_{2}(A)$、$\\|r\\|_{2}$ 和 $\\|b\\|_{2}$ 表示相对前向误差 $\\dfrac{\\|x - \\hat{x}\\|_{2}}{\\|x\\|_{2}}$ 的上界，然后计算其数值。\n\n**1.2. 使用提取的已知条件进行验证：**\n- **科学依据：** 该问题是数值线性代数中的一个标准练习，涉及残差与前向误差之间的关系。这是分析求解线性系统的数值算法中的一个基本概念。所涉及的原理是公认的。\n- **适定性：** 矩阵 $A$ 是对角矩阵，且对角线元素非零，因此它是可逆的，保证了唯一解 $x$ 的存在。问题要求推导一个标准的上界，这是一个明确定义的推导过程。所有必要的数据都已提供。\n- **客观性：** 问题使用精确的数学语言和定义进行陈述，没有歧义或主观论断。\n- **其他标准：** 问题是自洽的、一致的且科学上可行的。它不违反任何指定的无效性标准。\n\n**1.3. 结论与行动：**\n该问题是有效的。将提供完整的解答。\n\n### 步骤 2：上界的推导\n\n相对前向误差定义为 $\\dfrac{\\|x - \\hat{x}\\|_{2}}{\\|x\\|_{2}}$。我们需要找到这个量的上界。\n\n令 $e = x - \\hat{x}$ 为前向误差向量。\n残差由 $r = b - A \\hat{x}$ 给出。\n精确解 $x$ 满足方程 $A x = b$。\n将 $b = A x$ 代入残差的表达式，我们得到：\n$$r = A x - A \\hat{x} = A(x - \\hat{x}) = A e$$\n由于矩阵 $A$ 是可逆的，我们可以用残差 $r$ 来表示误差 $e$：\n$$e = A^{-1} r$$\n对两边取欧几里得范数，并应用诱导矩阵范数的性质 $\\|Mv\\|_{2} \\le \\|M\\|_{2}\\|v\\|_{2}$，我们得到绝对前向误差的一个界：\n$$\\|e\\|_{2} = \\|x - \\hat{x}\\|_{2} = \\|A^{-1} r\\|_{2} \\le \\|A^{-1}\\|_{2} \\|r\\|_{2}$$\n这给出了误差向量范数的一个上界。为了找到相对误差的界，我们需要找到 $\\|x\\|_{2}$ 的一个下界。\n从原始方程 $A x = b$ 出发，我们对两边取范数：\n$$\\|b\\|_{2} = \\|A x\\|_{2}$$\n使用相同的诱导矩阵范数性质，我们有：\n$$\\|b\\|_{2} \\le \\|A\\|_{2} \\|x\\|_{2}$$\n由于 $A$ 可逆且 $b \\neq 0$，解 $x$ 是非零的，因此 $\\|x\\|_{2} > 0$。我们可以重新整理不等式，得到 $\\|x\\|_{2}$ 的一个下界：\n$$\\|x\\|_{2} \\ge \\frac{\\|b\\|_{2}}{\\|A\\|_{2}}$$\n取倒数，我们得到 $\\dfrac{1}{\\|x\\|_{2}}$ 的一个上界：\n$$\\frac{1}{\\|x\\|_{2}} \\le \\frac{\\|A\\|_{2}}{\\|b\\|_{2}}$$\n现在，我们可以结合 $\\|x - \\hat{x}\\|_{2}$ 和 $\\dfrac{1}{\\|x\\|_{2}}$ 的界来界定相对前向误差：\n$$\\frac{\\|x - \\hat{x}\\|_{2}}{\\|x\\|_{2}} \\le (\\|A^{-1}\\|_{2} \\|r\\|_{2}) \\left( \\frac{\\|A\\|_{2}}{\\|b\\|_{2}} \\right)$$\n重新整理各项，我们得到：\n$$\\frac{\\|x - \\hat{x}\\|_{2}}{\\|x\\|_{2}} \\le \\|A\\|_{2} \\|A^{-1}\\|_{2} \\frac{\\|r\\|_{2}}{\\|b\\|_{2}}$$\n根据定义， $A$ 在谱范数下的条件数是 $\\kappa_{2}(A) = \\|A\\|_{2} \\|A^{-1}\\|_{2}$。将此代入不等式，得到所需的先验上界：\n$$\\frac{\\|x - \\hat{x}\\|_{2}}{\\|x\\|_{2}} \\le \\kappa_{2}(A) \\frac{\\|r\\|_{2}}{\\|b\\|_{2}}$$\n\n### 步骤 3：上界的数值计算\n\n为了计算这个上界，我们必须计算 $\\kappa_{2}(A)$、$\\|b\\|_{2}$ 和 $\\|r\\|_{2}$ 的值。\n\n**1. $\\kappa_{2}(A)$ 的计算：**\n矩阵 $A$ 是一个对角矩阵：$A = \\mathrm{diag}(1, 10, 100)$。对于对称矩阵（包括对角矩阵），谱范数 $\\|A\\|_{2}$ 等于其谱半径，即其特征值的最大绝对值。对角矩阵的特征值是其对角线上的元素。\n$A$ 的特征值为 $\\lambda_1 = 1$、$\\lambda_2 = 10$ 和 $\\lambda_3 = 100$。\n因此，$A$ 的谱范数为：\n$$\\|A\\|_{2} = \\max\\{|1|, |10|, |100|\\} = 100$$\n$A$ 的逆是 $A^{-1} = \\mathrm{diag}(1^{-1}, 10^{-1}, 100^{-1}) = \\mathrm{diag}(1, 0.1, 0.01)$。\n$A^{-1}$ 的特征值为 $1$、$0.1$ 和 $0.01$。\n$A^{-1}$ 的谱范数为：\n$$\\|A^{-1}\\|_{2} = \\max\\{|1|, |0.1|, |0.01|\\} = 1$$\n条件数 $\\kappa_{2}(A)$ 是这些范数的乘积：\n$$\\kappa_{2}(A) = \\|A\\|_{2} \\|A^{-1}\\|_{2} = 100 \\times 1 = 100$$\n或者，对于对称正定矩阵，$\\kappa_{2}(A) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\frac{100}{1} = 100$。\n\n**2. $\\|b\\|_{2}$ 的计算：**\n向量 $b$ 给出为 $b = \\begin{pmatrix} 6 \\\\ 8 \\\\ 0 \\end{pmatrix}$。其欧几里得范数为：\n$$\\|b\\|_{2} = \\sqrt{6^2 + 8^2 + 0^2} = \\sqrt{36 + 64} = \\sqrt{100} = 10$$\n\n**3. $\\|r\\|_{2}$ 的计算：**\n残差向量 $r$ 给出为 $r = \\begin{pmatrix} 1 \\times 10^{-6} \\\\ -2 \\times 10^{-6} \\\\ 2 \\times 10^{-6} \\end{pmatrix}$。其欧几里得范数为：\n$$\\|r\\|_{2} = \\sqrt{(1 \\times 10^{-6})^2 + (-2 \\times 10^{-6})^2 + (2 \\times 10^{-6})^2}$$\n$$\\|r\\|_{2} = \\sqrt{1 \\times 10^{-12} + 4 \\times 10^{-12} + 4 \\times 10^{-12}} = \\sqrt{9 \\times 10^{-12}} = 3 \\times 10^{-6}$$\n\n**4. 上界的最终计算：**\n将计算出的值代入推导出的不等式：\n$$\\frac{\\|x - \\hat{x}\\|_{2}}{\\|x\\|_{2}} \\le \\kappa_{2}(A) \\frac{\\|r\\|_{2}}{\\|b\\|_{2}} = 100 \\times \\frac{3 \\times 10^{-6}}{10}$$\n$$\\frac{\\|x - \\hat{x}\\|_{2}}{\\|x\\|_{2}} \\le 10 \\times (3 \\times 10^{-6}) = 3 \\times 10^{-5}$$\n问题要求将数值上界四舍五入到四位有效数字。\n$$3 \\times 10^{-5} = 3.000 \\times 10^{-5}$$\n因此，相对前向误差的上界为 $3.000 \\times 10^{-5}$。",
            "answer": "$$\n\\boxed{3.000 \\times 10^{-5}}\n$$"
        },
        {
            "introduction": "从一般性原则转向具体算法，我们来研究应用广泛的高斯消元法。高斯消元法的稳定性并非理所当然，它依赖于一个关键量——“增长因子”——的大小。本练习要求你亲手实现带部分主元的高斯消元法 (GEPP)，观察增长因子的大小，并将其与理论误差界联系起来，从而深入理解理论分析与算法实际数值行为之间的关系 。",
            "id": "3581484",
            "problem": "考虑对一个大小为 $n \\times n$ 的非奇异方阵应用部分主元高斯消元法（GEPP）。令 $\\rho$ 表示增长因子，其定义为消元过程中产生的最大绝对值元素与原始矩阵中最大绝对值元素之比。以下任务旨在建立后向稳定性、前向误差、条件数和增长因子之间的基本关系，并构造能在双精度算术中产生大增长因子但仍表现出后向稳定性的显式矩阵。\n\n任务1（原理推导）。从后向误差和前向误差的定义以及标准浮点模型 $fl(a \\,\\circ\\, b) = (a \\,\\circ\\, b)(1 + \\delta)$（其中对于任何基本算术运算 $\\circ$，都有 $|\\delta| \\le u$，$u$ 为单位舍入误差）出发，推导部分主元高斯消元法（GEPP）的范数形式后向误差界。具体来说，证明计算出的解 $\\widehat{x}$ 满足 $(A + \\Delta A)\\widehat{x} = b$，其中扰动 $\\Delta A$ 服从以下形式的界：\n$$\n\\frac{\\|\\Delta A\\|}{\\|A\\|} \\le c\\, n\\, \\rho\\, u + \\mathcal{O}(u^2),\n$$\n其中 $c$ 是一个与 $A$ 无关的温和常数，$n$ 是维度，$\\rho$ 是消元过程产生的增长因子。然后，利用对于可逆矩阵 $A$，前向误差可以通过次乘矩阵范数下的条件数 $\\kappa$ 与后向误差相关联这一事实，得到以下形式的界：\n$$\n\\frac{\\|\\widehat{x} - x\\|}{\\|x\\|} \\le \\frac{\\kappa(A) \\cdot \\frac{\\|\\Delta A\\|}{\\|A\\|}}{1 - \\kappa(A) \\cdot \\frac{\\|\\Delta A\\|}{\\|A\\|}},\n$$\n其中 $x$ 是 $A x = b$ 的精确解，$\\kappa(A) = \\|A\\| \\cdot \\|A^{-1}\\|$.\n\n任务2（最坏情况构造）。对于给定的 $n$，构造一个矩阵 $W_n$，其元素为\n$$\n(W_n)_{ij} = \n\\begin{cases}\n1,  j \\ge i, \\\\\n-1,  j  i,\n\\end{cases}\n$$\n以及右端项 $b = \\mathbf{1}$（全为1的向量）。已知该矩阵在GEPP下会引起接近最坏情况的增长因子。实现GEPP以在双精度下计算近似解 $\\widehat{x}$，并跟踪增长因子 $\\rho$，其定义为消元过程中观察到的最大绝对值元素除以原始矩阵中的最大绝对值元素。同时，计算残差 $r = b - A\\widehat{x}$、范数形式的相对后向误差\n$$\n\\beta = \\frac{\\|r\\|}{\\|A\\| \\cdot \\|\\widehat{x}\\| + \\|b\\|},\n$$\n并通过将界 $\\|\\Delta A\\| / \\|A\\| \\le c\\, n\\, \\rho\\, u$ 代入任务1中的不等式来估计前向误差界。所有范数均使用无穷范数。\n\n任务3（影响量化）。基于任务1和任务2，量化增长因子 $\\rho$ 如何通过项 $c\\, n\\, \\rho\\, u$ 和条件数 $\\kappa(A)$ 影响前向误差界。对于每个测试用例，报告观察到的增长因子 $\\rho$、理论上界 $2^{n-1}$、比率 $\\rho / 2^{n-1}$、实际相对后向误差 $\\beta$、界代理 $c\\, n\\, \\rho\\, u$ 以及从任务1得到的最终前向误差界。取 $c = 3$，$u$ 等于双精度单位舍入误差。\n\n实现要求。你的程序必须显式实现GEPP以：\n- 根据部分主元法执行行交换。\n- 累积并报告观察到的增长因子 $\\rho$。\n- 通过计算出的LU因子求解线性系统。\n- 计算残差 $r$、无穷范数 $\\|A\\|_{\\infty}$、$\\|A^{-1}\\|_{\\infty}$ 以及条件数 $\\kappa_{\\infty}(A)$。\n- 计算上述要求的量。\n\n测试套件。在以下矩阵大小上运行程序：\n- $n = 2$（边界情况），\n- $n = 5$（小规模情况），\n- $n = 10$（中等规模情况），\n- $n = 15$（较大规模情况），\n- $n = 20$（压力情况）。\n\n对于每个 $n$，使用 $W_n$ 构造和 $b = \\mathbf{1}$。所有报告值都应在双精度浮点算术中计算。不涉及物理单位或角度。\n\n最终输出格式。你的程序应生成单行输出，其中包含一个逗号分隔的测试套件结果列表，并用方括号括起来。每个测试用例的结果必须是按以下顺序排列的六个浮点数列表\n$$\n[\\rho,\\;2^{n-1},\\;\\rho/2^{n-1},\\;\\beta,\\;c\\,n\\,\\rho\\,u,\\;\\text{forward\\_bound}],\n$$\n因此，总输出是一个列表的列表，例如\n$$\n\\big[ [\\cdots], [\\cdots], [\\cdots], [\\cdots], [\\cdots] \\big].\n$$",
            "solution": "该问题要求对部分主元高斯消元法（GEPP）进行误差界的理论推导，并通过数值实现来研究一类特定矩阵的行为。该问题是适定的，并且在科学上基于数值线性代数的原理。需要稍作说明的是，将矩阵 $W_n$ 描述为导致“接近最坏情况的增长因子”是不准确的；对于指定的结构，增长因子 $\\rho$ 保持很小（具体来说，当 $n>1$ 时，$\\rho=2$）。然而，这并不影响计算任务的有效性，该任务是构造此矩阵，观察其实际增长因子，并分析由此产生的误差，从而在一个具体案例和理论最坏情况界之间提供有价值的比较。\n\n### 任务1：原理推导\n\n我们首先推导通过GEPP求解线性系统 $Ax=b$ 的解的范数形式后向误差界和前向误差界。\n\n**范数形式的后向误差界**\n\n在浮点算术中使用GEPP求解 $Ax=b$ 的过程可以看作是一系列步骤，每一步都会引入舍入误差。主要步骤是置换矩阵 $PA$ 的LU分解和两个三角系统的求解。\n\n1.  **LU分解：** GEPP算法计算三角因子 $\\widehat{L}$ 和 $\\widehat{U}$ 以及一个置换矩阵 $P$，使得它们是一个扰动矩阵的精确因子：\n    $$ \\widehat{L}\\widehat{U} = PA + E $$\n    其中 $E$ 是消元步骤中由舍入产生的误差矩阵。由Wilkinson建立的高斯消元法后向误差分析中的一个基石性结果，为 $E$ 的元素大小提供了一个界。在标准浮点算术模型中，其中 $fl(a \\circ b) = (a \\circ b)(1+\\delta)$ 且 $|\\delta| \\le u$（单位舍入误差），误差矩阵 $E$ 可以被界定。该界的一个常见形式是 $|E| \\le \\gamma_n |\\widehat{L}||\\widehat{U}|$，其中 $|M|$ 表示 $M$ 元素绝对值构成的矩阵，且 $\\gamma_n = \\frac{nu}{1-nu}$。\n\n2.  **三角系统求解：** 解 $\\widehat{x}$ 是通过求解 $\\widehat{L}y=Pb$（前向代入）和 $\\widehat{U}\\widehat{x}=y$（回代）得到的。这些步骤同样会引入舍入误差。可以证明，计算出的解 $\\widehat{x}$ 是一个扰动三角系统 $(\\widehat{U}+\\Delta\\widehat{U})\\widehat{x} = y$ 的精确解。\n\n3.  **组合效应：** 当所有误差源组合在一起时，可以证明计算出的解 $\\widehat{x}$ 是一个扰动原始系统的精确解：\n    $$ (A+\\Delta A)\\widehat{x} = b $$\n    扰动矩阵 $\\Delta A$ 的范数是有界的。这个界取决于计算出的因子的性质。部分主元法确保计算出的下三角因子 $\\widehat{L}$ 的所有元素满足 $|\\widehat{l}_{ij}| \\le 1$。上三角因子 $\\widehat{U}$ 的元素大小与**增长因子** $\\rho$ 相关，其定义为：\n    $$ \\rho = \\frac{\\max_{i,j,k} |a_{ij}^{(k)}|}{\\max_{i,j} |a_{ij}^{(1)}|} $$\n    其中 $a_{ij}^{(k)}$ 是经过 $k-1$ 步消元后矩阵的元素。具体来说，$\\max_{i,j}|\\widehat{u}_{ij}| \\le \\rho \\max_{i,j}|a_{ij}|$。\n\n4.  **误差界：** 一个完整的推导整合了来自因子分解和代入的误差，从而界定 $\\|\\Delta A\\|$。一个经典结果给出了一个类似 $\\|\\Delta A\\|_{\\infty} \\le f(n) \\rho \\|A\\|_{\\infty} u + \\mathcal{O}(u^2)$ 的界，其中 $f(n)$ 是一个关于 $n$ 的低次多项式（例如，$f(n) \\approx 3n^2$）。问题陈述提出了一个简化的界：\n    $$ \\frac{\\|\\Delta A\\|}{\\|A\\|} \\le c\\, n\\, \\rho\\, u + \\mathcal{O}(u^2) $$\n    这种形式体现了对增长因子 $\\rho$ 和单位舍入误差 $u$ 的线性依赖，以及对维度 $n$ 的简化线性依赖。我们接受问题给定的这种形式。这个不等式表明，只要增长因子 $\\rho$ 不过大，GEPP就是范数意义上的后向稳定的。\n\n**范数形式的前向误差界**\n\n给定后向误差关系，我们可以推导出前向误差 $\\frac{\\|\\widehat{x}-x\\|}{\\|x\\|}$ 的界。\n\n1.  令 $x$ 为 $Ax=b$ 的精确解，$\\widehat{x}$ 为满足 $(A+\\Delta A)\\widehat{x}=b$ 的计算解。我们假设 $A$ 是可逆的。\n2.  由 $(A+\\Delta A)\\widehat{x}=b$ 可得 $A\\widehat{x} + \\Delta A \\widehat{x} = b$。代入 $b=Ax$，我们得到 $A\\widehat{x} + \\Delta A \\widehat{x} = Ax$。\n3.  整理可得 $A(\\widehat{x}-x) = -\\Delta A \\widehat{x}$。左乘 $A^{-1}$ 得到误差方程：\n    $$ \\widehat{x}-x = -A^{-1} \\Delta A \\widehat{x} $$\n4.  为了表示相对于 $\\|x\\|$ 的误差，我们将 $\\widehat{x} = x + (\\widehat{x}-x)$ 代入右侧：\n    $$ \\widehat{x}-x = -A^{-1} \\Delta A (x + (\\widehat{x}-x)) $$\n5.  然后我们求解误差向量 $\\widehat{x}-x$：\n    $$ (\\widehat{x}-x) + A^{-1} \\Delta A (\\widehat{x}-x) = -A^{-1} \\Delta A x $$\n    $$ (I + A^{-1} \\Delta A)(\\widehat{x}-x) = -A^{-1} \\Delta A x $$\n6.  如果扰动足够小，使得 $\\|A^{-1}\\Delta A\\|  1$，则矩阵 $(I + A^{-1}\\Delta A)$ 是可逆的。我们可以写成：\n    $$ \\widehat{x}-x = -(I + A^{-1} \\Delta A)^{-1} A^{-1} \\Delta A x $$\n7.  对两边取次乘矩阵范数：\n    $$ \\|\\widehat{x}-x\\| \\le \\|(I + A^{-1} \\Delta A)^{-1}\\| \\|A^{-1}\\| \\|\\Delta A\\| \\|x\\| $$\n8.  使用性质 $\\|(I+B)^{-1}\\| \\le \\frac{1}{1-\\|B\\|}$（对于 $\\|B\\|1$，该性质可由诺伊曼级数得出），我们得到：\n    $$ \\|\\widehat{x}-x\\| \\le \\frac{1}{1 - \\|A^{-1}\\Delta A\\|} \\|A^{-1}\\| \\|\\Delta A\\| \\|x\\| $$\n9.  两边除以 $\\|x\\|$（假设 $x\\neq 0$）：\n    $$ \\frac{\\|\\widehat{x}-x\\|}{\\|x\\|} \\le \\frac{\\|A^{-1}\\| \\|\\Delta A\\|}{1 - \\|A^{-1}\\| \\|\\Delta A\\|} $$\n10. 项 $\\|A^{-1}\\| \\|\\Delta A\\|$ 可以用条件数 $\\kappa(A) = \\|A\\| \\|A^{-1}\\|$ 和相对后向误差 $\\frac{\\|\\Delta A\\|}{\\|A\\|}$ 来表示：\n    $$ \\|A^{-1}\\| \\|\\Delta A\\| = (\\|A\\|\\|A^{-1}\\|) \\left(\\frac{\\|\\Delta A\\|}{\\|A\\|}\\right) = \\kappa(A) \\frac{\\|\\Delta A\\|}{\\|A\\|} $$\n11. 将此代入不等式，得到最终的前向误差界：\n    $$ \\frac{\\|\\widehat{x} - x\\|}{\\|x\\|} \\le \\frac{\\kappa(A) \\frac{\\|\\Delta A\\|}{\\|A\\|}}{1 - \\kappa(A) \\frac{\\|\\Delta A\\|}{\\|A\\|}} $$\n这个关键结果表明，相对前向误差由条件数与相对后向误差的乘积控制。一个小的后向误差（如果 $\\rho$ 很小，GEPP可以保证）在矩阵是病态的（即 $\\kappa(A)$ 很大）情况下，并不能保证一个小的前向误差。\n\n### 任务2和3：实现与量化\n\n以下Python代码实现了GEPP，用于求解指定矩阵 $W_n$ 的系统 $W_n x = \\mathbf{1}$。它计算了给定测试用例的增长因子 $\\rho$、后向误差 $\\beta$ 和理论前向误差界。",
            "answer": "```python\nimport numpy as np\n\ndef gepp(A, b):\n    \"\"\"\n    Solves the linear system Ax=b using Gaussian elimination with partial pivoting.\n    \n    Args:\n        A (np.ndarray): The n x n coefficient matrix.\n        b (np.ndarray): The n x 1 right-hand side vector.\n        \n    Returns:\n        tuple: A tuple containing:\n            - np.ndarray: The solution vector x.\n            - float: The observed growth factor rho.\n    \"\"\"\n    n = A.shape[0]\n    # Work on copies to preserve original matrices\n    A_copy = A.astype(np.float64)\n    b_copy = b.astype(np.float64)\n\n    max_abs_A = np.max(np.abs(A_copy))\n    if max_abs_A == 0:\n        # A is a zero matrix, handle as a special case\n        rho = 1.0 # Or undefined. In this problem, A is nonsingular.\n    else:\n        # Keep track of the maximum absolute value seen during elimination\n        max_abs_val_during_elimination = max_abs_A\n\n    # Elimination phase\n    for k in range(n - 1):\n        # Find pivot row (the one with the largest element in the current column)\n        pivot_row_idx = k + np.argmax(np.abs(A_copy[k:, k]))\n        \n        # Swap rows in A and b if necessary\n        if pivot_row_idx != k:\n            A_copy[[k, pivot_row_idx]] = A_copy[[pivot_row_idx, k]]\n            b_copy[[k, pivot_row_idx]] = b_copy[[pivot_row_idx, k]]\n            \n        # Check for singularity\n        if A_copy[k, k] == 0:\n            raise np.linalg.LinAlgError(\"Matrix is singular or near-singular.\")\n\n        # Update rows below the pivot\n        for i in range(k + 1, n):\n            multiplier = A_copy[i, k] / A_copy[k, k]\n            # Store multiplier in the lower-triangular part of A\n            A_copy[i, k] = multiplier\n            # Update the rest of the row\n            A_copy[i, k + 1:] -= multiplier * A_copy[k, k + 1:]\n        \n        # Update the maximum absolute value for growth factor calculation.\n        # This is a key step for tracking rho.\n        current_max = np.max(np.abs(A_copy))\n        if current_max > max_abs_val_during_elimination:\n            max_abs_val_during_elimination = current_max\n\n    if max_abs_A > 0:\n        rho = max_abs_val_during_elimination / max_abs_A\n    \n    # At this point, A_copy contains U in its upper triangle and L (excluding\n    # the main diagonal of 1s) in its strict lower triangle.\n\n    # Forward substitution to solve Ly = b\n    y = np.zeros(n, dtype=np.float64)\n    for i in range(n):\n        y[i] = b_copy[i] - np.dot(A_copy[i, :i], y[:i])\n        \n    # Backward substitution to solve Ux = y\n    x = np.zeros(n, dtype=np.float64)\n    for i in range(n - 1, -1, -1):\n        x[i] = (y[i] - np.dot(A_copy[i, i + 1:], x[i + 1:])) / A_copy[i, i]\n        \n    return x, rho\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and compute the required quantities.\n    \"\"\"\n    test_cases = [2, 5, 10, 15, 20]\n    all_results_str = []\n    \n    # Unit roundoff for double precision (IEEE 754)\n    u = np.finfo(np.float64).eps / 2.0\n    c = 3.0\n    \n    for n in test_cases:\n        # Task 2: Construct the matrix W_n and vector b\n        W_n = np.ones((n, n), dtype=np.float64)\n        # Set j  i entries to -1\n        rows, cols = np.tril_indices(n, k=-1)\n        W_n[rows, cols] = -1.0\n        \n        b = np.ones(n, dtype=np.float64)\n        \n        # Perform GEPP and get solution and growth factor\n        x_hat, rho = gepp(W_n, b)\n        \n        # Task 3: Quantify influence\n        \n        # 1. Observed growth factor rho (already computed)\n        \n        # 2. Theoretical upper bound for rho\n        rho_bound = 2.0**(n - 1)\n        \n        # 3. Ratio rho / 2^(n-1)\n        rho_ratio = rho / rho_bound\n        \n        # 4. Actual relative backward error beta\n        r = b - W_n @ x_hat\n        norm_A_inf = np.linalg.norm(W_n, ord=np.inf)\n        norm_x_hat_inf = np.linalg.norm(x_hat, ord=np.inf)\n        norm_b_inf = np.linalg.norm(b, ord=np.inf)\n        norm_r_inf = np.linalg.norm(r, ord=np.inf)\n        \n        denominator_beta = norm_A_inf * norm_x_hat_inf + norm_b_inf\n        beta = norm_r_inf / denominator_beta if denominator_beta > 0 else 0.0\n\n        # 5. Bound proxy c*n*rho*u\n        bound_proxy = c * n * rho * u\n        \n        # 6. Resulting forward error bound\n        # First, compute condition number kappa_inf(A)\n        # Note: In a real application, one would use a condition number estimator\n        # instead of computing the inverse explicitly. For this problem, it's fine.\n        norm_A_inv_inf = np.linalg.norm(np.linalg.inv(W_n), ord=np.inf)\n        kappa_inf = norm_A_inf * norm_A_inv_inf\n        \n        # Use the bound from Task 1\n        rel_back_err_term = kappa_inf * bound_proxy\n        \n        if rel_back_err_term >= 1.0:\n            forward_bound = np.inf\n        else:\n            forward_bound = rel_back_err_term / (1.0 - rel_back_err_term)\n            \n        case_results = [\n            rho, \n            rho_bound, \n            rho_ratio, \n            beta, \n            bound_proxy, \n            forward_bound\n        ]\n        all_results_str.append(str(case_results))\n\n    # Print the final output in the specified format\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们将注意力从直接解法转向迭代方法，后者对于求解大规模问题至关重要。对称 Lanczos 过程是一个典型的例子，但在有限精度下，其生成的基向量会逐渐失去正交性，导致计算结果不准确。这个编程练习旨在探索这种不稳定性，并演示如何通过一种修正策略——选择性正交化——来恢复精度，从而让你权衡计算成本与数值稳定性之间的利弊 。",
            "id": "3581514",
            "problem": "设计并实现一个程序，通过应用选择性重正交化策略来维持Krylov基向量间的正交性，并量化其对Ritz值精度的影响，从而研究对称Lanczos过程在有限精度算术下的稳定性。您的程序必须实现三种针对实对称矩阵的Lanczos迭代变体：无重正交化、选择性重正交化和完全重正交化。实证比较必须遵循以下规范。\n\n基本基础和假设：\n- 使用binary64算术的标准浮点舍入模型：对于任何基本运算，$\\mathrm{fl}(x \\circ y) = (x \\circ y) (1 + \\delta)$，其中 $|\\delta| \\leq \\epsilon_{\\mathrm{mach}}$，$\\epsilon_{\\mathrm{mach}}$ 表示双精度的机器ε。\n- 对于一个实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 和一个起始向量 $v_{1}$（满足 $\\|v_{1}\\|_{2} = 1$），其$k$阶Krylov子空间为 $\\mathcal{K}_{k}(A, v_{1}) = \\mathrm{span}\\{v_{1}, A v_{1}, \\dots, A^{k-1} v_{1} \\}$。Lanczos过程试图为 $\\mathcal{K}_{k}(A, v_{1})$ 生成一个标准正交基 $\\{v_{1}, \\dots, v_{k}\\}$，从而产生一个实对称三对角矩阵 $T_{k} \\in \\mathbb{R}^{k \\times k}$，其特征值为相对于 $(A, \\mathcal{K}_{k})$ 的Ritz值。\n- 在精确算术中，Lanczos向量是标准正交的，一个三项递推关系就足够了。在有限精度算术中，可能会发生正交性损失；重正交化可以减轻这种不稳定性。\n\n选择性重正交化指令：\n- 实现一个基于正交性损失测量的选择性重正交化准则。设 $\\eta = c \\sqrt{\\epsilon_{\\mathrm{mach}}}$，其中 $c = 10$。在Lanczos的第 $j$ 步，形成候选向量 $w$ 后，计算内积 $h_{i} = v_{i}^{\\top} w$，其中 $i = 1, \\dots, j$。如果对于任何 $i$，有 $|h_{i}|  \\eta$，则对那些满足该不等式的 $v_{i}$ 执行修正的Gram–Schmidt重正交化，并重复此检查最多 $2$ 遍，以将 $|h_{i}|$ 减小到接近 $\\mathcal{O}(\\epsilon_{\\mathrm{mach}})$ 的水平。\n- 对于完全重正交化变体，在每一步 $j$ 都对所有先前计算出的Lanczos向量 $\\{v_{1}, \\dots, v_{j}\\}$ 执行修正的Gram–Schmidt重正交化，最多执行 $2$ 遍。\n- 对于无重正交化变体，仅执行三项递推，不进行任何Gram–Schmidt步骤。\n\n精度度量：\n- 对于给定的对称矩阵 $A$、目标子空间维度 $k$ 和目标数量 $r \\leq k$，计算从 $T_{k}$ 得到的 $r$ 个最大的Ritz值（按代数顺序），并将它们与 $A$ 的 $r$ 个最大的真实特征值（按代数顺序）进行比较。将误差定义为两组值按降序排序后的最大绝对偏差：\n$$\nE = \\max_{1 \\leq i \\leq r} \\left| \\lambda^{(A)}_{(i)} - \\theta^{(T)}_{(i)} \\right|,\n$$\n其中 $\\lambda^{(A)}_{(i)}$ 是 $A$ 的 $r$ 个最大特征值，$\\theta^{(T)}_{(i)}$ 是 $r$ 个最大Ritz值。\n- 将选择性重正交化带来的改进因子定义为\n$$\n\\mathcal{I} = \\frac{E_{\\mathrm{none}}}{E_{\\mathrm{sel}}},\n$$\n其中 $E_{\\mathrm{none}}$ 是无重正交化下的误差，$E_{\\mathrm{sel}}$ 是选择性重正交化下的误差。如果 $E_{\\mathrm{sel}} = 0$，则报告 $\\mathcal{I} = 10^{16}$。\n\n实现要求：\n- 实现对称Lanczos过程，为上述三种变体分别返回三对角矩阵 $T_{k}$。\n- 对每个测试用例使用固定的、可复现的随机起始向量 $v_{1}$，并满足 $\\|v_{1}\\|_{2} = 1$。\n- 使用数值稳定的对称特征值求解器计算 $A$ 的真实特征值。\n\n测试套件：\n- 您的程序必须运行以下三个测试用例，并为每个用例报告如上定义的改进因子 $\\mathcal{I}$。在所有用例中，均使用双精度算术，不涉及物理单位，也不使用角度。\n    1. 谱间距良好的理想情况：\n        - $n = 80$, $k = 30$, $r = 5$。\n        - 构建 $A = Q \\Lambda Q^{\\top}$，其中 $\\Lambda = \\mathrm{diag}(\\ell_{1}, \\dots, \\ell_{n})$，$\\ell_{i}$ 在 $1$ 到 $100$ 之间线性分布，而 $Q$ 是一个种子为 $0$ 的随机高斯矩阵进行 $\\mathrm{QR}$ 分解得到的正交因子。\n        - 使用种子为 $1$ 的随机高斯起始向量，并归一化至单位 $2$-范数。\n    2. 谱顶端的挑战性密集特征值簇：\n        - $n = 120$, $k = 60$, $r = 8$。\n        - 构建 $A = Q \\Lambda Q^{\\top}$，其中 $\\Lambda$ 有 $10$ 个接近 $10$ 的特征值，形式为 $10 + \\delta_{i}$，$\\delta_{i}$ 在 $[-10^{-8}, 10^{-8}]$ 内独立同分布均匀采样得到；其余 $110$ 个特征值在 $[0.1, 9.9]$ 内线性分布。使用种子 $2$ 生成 $Q$ 和均匀样本。\n        - 使用种子为 $3$ 的随机高斯起始向量，并归一化至单位 $2$-范数。\n    3. 长程运行和结构化算子的边界情况：\n        - $n = 90$, $k = 90$, $r = 10$。\n        - 构建 $A$ 为三对角Toeplitz矩阵，其主对角线为零，第一副对角线和第一超对角线为一，即 $A_{i,i} = 0$ 且 $A_{i,i+1} = A_{i+1,i} = 1$，其中 $i = 1, \\dots, n-1$。\n        - 使用种子为 $4$ 的随机高斯起始向量，并归一化至单位 $2$-范数。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，包含一个由方括号括起来的逗号分隔列表。该列表必须恰好包含 $3$ 个浮点数，按顺序对应测试用例 $1$、$2$ 和 $3$ 的改进因子 $\\mathcal{I}$。例如，格式必须严格如 $[x_{1},x_{2},x_{3}]$，不含多余空格，其中 $x_{i}$ 是十进制字符串。\n\n评分和接受标准：\n- 程序必须是自包含的，无需用户输入即可运行。\n- 选择性重正交化必须使用阈值 $\\eta = 10 \\sqrt{\\epsilon_{\\mathrm{mach}}}$，并且每步最多进行 $2$ 次Gram–Schmidt遍。\n- 每个 $\\mathcal{I}$ 必须是一个有限非负浮点数，并遵循 $E_{\\mathrm{sel}} = 0$ 时 $\\mathcal{I} = 10^{16}$ 的规则。",
            "solution": "本解答旨在实现并分析对称Lanczos过程，重点关注其数值稳定性。具体任务是比较在无重正交化情况下计算的Ritz值与使用选择性重正交化策略计算的Ritz值的精度。这种比较通过一个改进因子 $\\mathcal{I}$ 来量化。该问题定义明确，科学上合理，并提供了所有必要的参数，包括矩阵构造、算法规范和评估指标，使其成为一个有效且可验证的数值实验。\n\n我将通过首先实现核心的Lanczos迭代来构建解决方案，该迭代可以以两种模式运行：`none`（无重正交化）和`selective`（选择性重正交化）。然后，我将创建辅助函数来为三个测试用例中的每一个构造特定的矩阵和起始向量。一个主函数将协调每个测试用令的执行，计算所需的误差和改进因子，并按指定格式输出结果。\n\n### 对称Lanczos算法\n\nLanczos过程为Krylov子空间 $\\mathcal{K}_k(A, v_1)$ 生成一个标准正交基 $\\{v_1, v_2, \\dots, v_k\\}$ 和一个对称三对角矩阵 $T_k$。递推关系为：\n$$ \\beta_j v_{j+1} = A v_j - \\alpha_j v_j - \\beta_{j-1} v_{j-1} $$\n其中 $\\alpha_j = v_j^\\top A v_j$ 且 $\\beta_j = \\|A v_j - \\alpha_j v_j - \\beta_{j-1} v_{j-1}\\|_2$。在有限精度算术中，向量 $\\{v_j\\}$ 的正交性会迅速丧失，导致Ritz值（$T_k$ 的特征值）不准确。\n\n### 重正交化策略\n\n为了应对这种不稳定性，采用了重正交化方法。\n1.  **无重正交化 (`none`)**: 使用基本的递推关系，不进行任何校正。这种方法计算成本低，但对于长迭代来说数值上不稳定。\n2.  **选择性重正交化 (`selective`)**: 有选择地强制保持正交性。在每一步 $j$，检查新向量 $w_j = A v_j - \\alpha_j v_j - \\beta_{j-1} v_{j-1}$（该向量应与 $v_1, \\dots, v_j$ 正交）。如果它在任何先前向量 $v_i$ 上的投影大于阈值 $\\eta = c \\sqrt{\\epsilon_{\\mathrm{mach}}}$（其中 $c=10$），我们就对那些特定的向量 $v_i$ 对 $w_j$ 进行重正交化。问题指定使用修正的Gram-Schmidt（MGS）方法进行此校正，最多重复两次以确保恢复正交性。这在完全重正交化的成本和无重正交化的不稳定性之间取得了平衡。\n\n### 实现细节\n\n将实现一个函数 `lanczos_iteration(A, v1, k, mode)`。它将接收矩阵 $A$、起始向量 $v_1$、迭代次数 $k$ 和一个 `mode` 字符串（`'none'` 或 `'selective'`）。\n\n-   循环将从 $j=0$ 迭代到 $k-1$。\n-   在循环内部，对每个新向量应用三项递推。\n-   如果 `mode` 是 `'selective'`，将触发重正交化逻辑。这涉及计算内积 $h_i = v_i^\\top w$，如果 $|h_i| > \\eta$，则应用MGS步骤：$w \\leftarrow w - (v_i^\\top w)v_i$。此检查和校正过程最多进行两遍。\n-   函数返回 $k \\times k$ 的三对角矩阵 $T_k$。\n\n### 评估\n\n对于每个测试用例：\n1.  构造指定的 $n \\times n$ 矩阵 $A$ 和起始向量 $v_1$。\n2.  使用稳定的特征值求解器（`numpy.linalg.eigh`）计算 $A$ 的 $r$ 个最大真实特征值，记为 $\\lambda^{(A)}_{(i)}$。\n3.  对 `mode='none'` 和 `mode='selective'` 两种模式运行Lanczos迭代，以获得 $T_{k, \\text{none}}$ 和 $T_{k, \\text{sel}}$。\n4.  使用高效的三对角特征值求解器（`scipy.linalg.eigh_tridiagonal`）计算每个 $T_k$ 矩阵的 $r$ 个最大特征值（Ritz值），记为 $\\theta^{(T)}_{(i)}$。\n5.  误差 $E_{\\mathrm{none}}$ 和 $E_{\\mathrm{sel}}$ 计算为对应的排序后真实特征值列表和Ritz值列表之间的最大绝对差：\n    $$ E = \\max_{1 \\leq i \\leq r} \\left| \\lambda^{(A)}_{(i)} - \\theta^{(T)}_{(i)} \\right| $$\n6.  计算改进因子 $\\mathcal{I} = E_{\\mathrm{none}} / E_{\\mathrm{sel}}$。对于 $E_{\\mathrm{sel}}=0$ 的特殊情况，通过设置 $\\mathcal{I}=10^{16}$ 来处理。\n\n对三个定义的测试用例重复此过程，并收集最终的改进因子进行打印。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh_tridiagonal\n\ndef lanczos_iteration(A, v1, k, mode='none'):\n    \"\"\"\n    Performs the symmetric Lanczos iteration for a matrix A and starting vector v1.\n\n    Args:\n        A (np.ndarray): The symmetric matrix.\n        v1 (np.ndarray): The starting vector of unit norm.\n        k (int): The number of Lanczos steps (dimension of Krylov subspace).\n        mode (str): Reorthogonalization mode: 'none' or 'selective'.\n\n    Returns:\n        np.ndarray: The symmetric tridiagonal matrix T_k of size k x k.\n    \"\"\"\n    n = A.shape[0]\n    V = np.zeros((n, k + 1))\n    alphas = np.zeros(k)\n    betas = np.zeros(k)\n\n    eps_mach = np.finfo(float).eps\n    eta = 10.0 * np.sqrt(eps_mach)\n    breakdown_tol = 1e-14\n\n    V[:, 0] = v1\n\n    for j in range(k):\n        v_curr = V[:, j]\n        w = A @ v_curr\n\n        if j > 0:\n            w -= betas[j - 1] * V[:, j - 1]\n\n        alphas[j] = v_curr.T @ w\n        w -= alphas[j] * v_curr\n\n        if mode == 'selective':\n            # Perform selective reorthogonalization with at most 2 MGS passes\n            for _ in range(2):\n                # Projections of w onto the basis V\n                h = V[:, :j + 1].T @ w\n                indices_to_reortho = np.where(np.abs(h) > eta)[0]\n                \n                if len(indices_to_reortho) == 0:\n                    break  # Orthogonality is sufficient\n                \n                # Apply MGS steps for the vectors that lost orthogonality\n                for i in indices_to_reortho:\n                    w -= (V[:, i].T @ w) * V[:, i]\n\n        betas[j] = np.linalg.norm(w)\n\n        if betas[j]  breakdown_tol:\n            # Breakdown: Krylov subspace is invariant or exhausted.\n            k_actual = j + 1\n            T_k = np.zeros((k, k))\n            sub_T_alphas = alphas[:k_actual]\n            sub_T_betas = betas[:k_actual - 1]\n            T_k_sub = np.diag(sub_T_alphas) + np.diag(sub_T_betas, 1) + np.diag(sub_T_betas, -1)\n            T_k[:k_actual, :k_actual] = T_k_sub\n            return T_k\n            \n        V[:, j + 1] = w / betas[j]\n\n    T_k = np.diag(alphas) + np.diag(betas[:k - 1], 1) + np.diag(betas[:k - 1], -1)\n    return T_k\n\ndef run_test_case(case_id):\n    \"\"\"\n    Sets up and runs a single test case, returning the improvement factor.\n    \"\"\"\n    if case_id == 1:\n        n, k, r = 80, 30, 5\n        rng_Q = np.random.default_rng(0)\n        G = rng_Q.standard_normal((n, n))\n        Q, _ = np.linalg.qr(G)\n        lambda_vals = np.linspace(1, 100, n)\n        A = Q @ np.diag(lambda_vals) @ Q.T\n        rng_v1 = np.random.default_rng(1)\n        v1 = rng_v1.standard_normal(n)\n    elif case_id == 2:\n        n, k, r = 120, 60, 8\n        rng = np.random.default_rng(2)\n        cluster_vals = 10.0 + rng.uniform(-1e-8, 1e-8, size=10)\n        other_vals = np.linspace(0.1, 9.9, n - 10)\n        lambda_vals = np.concatenate((other_vals, cluster_vals))\n        G = rng.standard_normal((n, n))\n        Q, _ = np.linalg.qr(G)\n        A = Q @ np.diag(lambda_vals) @ Q.T\n        rng_v1 = np.random.default_rng(3)\n        v1 = rng_v1.standard_normal(n)\n    elif case_id == 3:\n        n, k, r = 90, 90, 10\n        A = np.diag(np.ones(n - 1), 1) + np.diag(np.ones(n - 1), -1)\n        rng_v1 = np.random.default_rng(4)\n        v1 = rng_v1.standard_normal(n)\n    else:\n        raise ValueError(\"Invalid case ID\")\n        \n    v1 /= np.linalg.norm(v1)\n\n    # Compute true eigenvalues of A\n    true_eigvals = np.linalg.eigh(A)[0]\n    largest_true_eigvals = np.sort(true_eigvals)[-r:][::-1] # descending order\n\n    # Run Lanczos with no reorthogonalization\n    T_none = lanczos_iteration(A, v1, k, mode='none')\n    ritz_vals_none = eigh_tridiagonal(np.diag(T_none), np.diag(T_none, 1))[0]\n    largest_ritz_none = np.sort(ritz_vals_none)[-r:][::-1]\n\n    # Run Lanczos with selective reorthogonalization\n    T_sel = lanczos_iteration(A, v1, k, mode='selective')\n    ritz_vals_sel = eigh_tridiagonal(np.diag(T_sel), np.diag(T_sel, 1))[0]\n    largest_ritz_sel = np.sort(ritz_vals_sel)[-r:][::-1]\n\n    # Compute errors\n    E_none = np.max(np.abs(largest_true_eigvals - largest_ritz_none))\n    E_sel = np.max(np.abs(largest_true_eigvals - largest_ritz_sel))\n    \n    # Compute improvement factor\n    if E_sel == 0.0:\n        if E_none == 0.0:\n            return 1.0\n        return 1e16\n    \n    return E_none / E_sel\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [1, 2, 3]\n\n    results = []\n    for case_id in test_cases:\n        improvement_factor = run_test_case(case_id)\n        results.append(improvement_factor)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}