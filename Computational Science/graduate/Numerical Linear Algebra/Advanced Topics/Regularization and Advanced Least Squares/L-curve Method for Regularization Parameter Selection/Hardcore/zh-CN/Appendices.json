{
    "hands_on_practices": [
        {
            "introduction": "识别 L 曲线的拐角需要计算其曲率，而这又依赖于从一组离散的噪声点中准确估计一阶和二阶导数。本练习直面此项任务的核心数值挑战，要求在不同的采样与平滑策略之间做出选择，以平衡近似误差与噪声放大效应。对于任何需要实现 L 曲线方法的人来说，这是一项基础性的实践练习。",
            "id": "3554613",
            "problem": "考虑带有 Tikhonov 正则化的线性反问题：对于给定的矩阵 $A \\in \\mathbb{R}^{m \\times n}$、数据向量 $b \\in \\mathbb{R}^{m}$ 和正则化矩阵 $L \\in \\mathbb{R}^{p \\times n}$，Tikhonov 解 $x_{\\lambda}$ 通过在 $x \\in \\mathbb{R}^{n}$ 上最小化 $\\|A x - b\\|_{2}^{2} + \\lambda^{2} \\|L x\\|_{2}^{2}$ 来定义，其中 $\\lambda > 0$ 是正则化参数。定义残差范数 $\\rho(\\lambda) = \\|A x_{\\lambda} - b\\|_{2}$ 和半范数 $\\eta(\\lambda) = \\|L x_{\\lambda}\\|_{2}$。L-曲线是在对数坐标轴上绘制的 $(\\log \\rho(\\lambda), \\log \\eta(\\lambda))$ 相对于 $\\lambda$ 的参数图，而识别其拐角通常需要对 $\\log \\rho(\\lambda)$ 和 $\\log \\eta(\\lambda)$ 关于 $\\log \\lambda$ 的一阶和二阶导数进行稳健估计。\n\n假设以下设置基于标准的数值线性代数事实。首先，映射 $\\lambda \\mapsto \\rho(\\lambda)$ 和 $\\lambda \\mapsto \\eta(\\lambda)$ 是光滑且单调的，并且当用广义奇异值分解表示时，它们成为关于 $\\lambda^{2}$ 的光滑有理函数，这意味着 $\\xi \\mapsto \\log \\rho(e^{\\xi})$ 和 $\\xi \\mapsto \\log \\eta(e^{\\xi})$ 是关于 $\\xi = \\log \\lambda$ 的光滑函数。其次，假设 $\\rho(\\lambda)$ 和 $\\eta(\\lambda)$ 的计算值受到数据和求解误差引起的小的乘性扰动的影响：对于采样的 $\\lambda_{i}$，观测值满足 $\\rho_{\\mathrm{obs}}(\\lambda_{i}) = \\rho(\\lambda_{i}) (1 + \\delta_{i}^{\\rho})$ 和 $\\eta_{\\mathrm{obs}}(\\lambda_{i}) = \\eta(\\lambda_{i}) (1 + \\delta_{i}^{\\eta})$，其中 $|\\delta_{i}^{\\rho}| \\ll 1$ 和 $|\\delta_{i}^{\\eta}| \\ll 1$，且可能随 $i$ 变化。因此，对数变换后的观测值 $r_{i}^{\\mathrm{obs}} = \\log \\rho_{\\mathrm{obs}}(\\lambda_{i})$ 和 $e_{i}^{\\mathrm{obs}} = \\log \\eta_{\\mathrm{obs}}(\\lambda_{i})$ 满足 $r_{i}^{\\mathrm{obs}} = \\log \\rho(\\lambda_{i}) + \\varepsilon_{i}^{r}$ 和 $e_{i}^{\\mathrm{obs}} = \\log \\eta(\\lambda_{i}) + \\varepsilon_{i}^{e}$，其中加性误差 $\\varepsilon_{i}^{r} \\approx \\delta_{i}^{\\rho}$ 和 $\\varepsilon_{i}^{e} \\approx \\delta_{i}^{\\eta}$。对含噪数据求导会放大噪声是众所周知的：一阶导数的有限差分估计大致将噪声放大一个因子 $1/h$，二阶导数则放大 $1/h^{2}$，其中 $h$ 是自变量的采样步长。\n\n你的目标是为 $\\lambda$ 选择一个采样网格，并为 $(\\log \\rho, \\log \\eta)$ 选择一种平滑策略，以得到关于 $\\xi = \\log \\lambda$ 的稳健的一阶和二阶导数估计。具体来说，你必须平衡离散化带来的截断误差与求导带来的噪声放大。你可以假设正则化参数的范围跨越 $d$ 个数量级，即 $\\lambda_{\\max}/\\lambda_{\\min} = 10^{d}$，其中 $d$ 在 $3$ 和 $8$ 之间，并且计算预算允许进行 $50$ 到 $200$ 次求解。\n\n哪个选项为 $\\lambda$ 提供了一个科学上合理的对数间隔网格选择，并提供了一种平滑策略，该策略能最好地控制在估计 $(\\log \\rho(\\lambda), \\log \\eta(\\lambda))$ 作为 $\\xi = \\log \\lambda$ 的函数的一阶和二阶导数时产生的截断误差和噪声放大？\n\nA. 在对数间隔网格 $\\{\\lambda_{i}\\}_{i=1}^{n}$ 上采样 $\\lambda$，在 $\\xi = \\log \\lambda$ 中具有常数步长 $h$，每个数量级选择大约 $20$ 到 $30$ 个点（因此 $h \\approx \\log 10 / 20$ 到 $\\log 10 / 30$），并分别对 $(\\xi_{i}, r_{i}^{\\mathrm{obs}})$ 和 $(\\xi_{i}, e_{i}^{\\mathrm{obs}})$ 拟合加权三次平滑样条 $s_{r}(\\xi)$ 和 $s_{e}(\\xi)$。使用 $\\varepsilon_{i}^{r}$ 和 $\\varepsilon_{i}^{e}$ 的方差估计值 $\\sigma_{i}^{2}$ 设置权重 $w_{i} \\propto 1/\\sigma_{i}^{2}$，并通过广义交叉验证 (GCV) 选择平滑参数。在内部点评估一阶和二阶导数 $s_{r}^{\\prime}(\\xi)$、$s_{r}^{\\prime \\prime}(\\xi)$、$s_{e}^{\\prime}(\\xi)$ 和 $s_{e}^{\\prime \\prime}(\\xi)$，并丢弃一些边界样本以减轻端点效应。\n\nB. 在原始 $\\lambda$ 尺度上，在线性间隔网格上用 $n$ 个点采样 $\\lambda$，并使用二阶中心有限差分计算 $r_{i}^{\\mathrm{obs}}$ 和 $e_{i}^{\\mathrm{obs}}$ 的一阶和二阶导数，不进行任何平滑。这确保了 $\\lambda$ 中的均匀截断误差，并避免了样条偏差。\n\nC. 在一个有数千个点的非常密集的对数间隔网格上采样 $\\lambda$（因此 $\\xi$ 中的 $h$ 极小），并拟合精确穿过所有 $(\\xi_{i}, r_{i}^{\\mathrm{obs}})$ 和 $(\\xi_{i}, e_{i}^{\\mathrm{obs}})$ 点的插值自然三次样条，以保留所有特征。计算插值函数的导数以获得一阶和二阶导数。\n\nD. 在对数间隔网格上用少量点（例如，在 $d \\approx 5$ 个数量级上取 $n \\approx 30$ 个点）采样 $\\lambda$，并通过最小二乘法对 $r_{i}^{\\mathrm{obs}}$ 和 $e_{i}^{\\mathrm{obs}}$ 拟合一个关于 $\\xi$ 的高阶全局多项式（阶数接近 $n-1$）。对该多项式进行解析求导以获得一阶和二阶导数。\n\nE. 在每个数量级有 $20$ 到 $30$ 个点的对数间隔网格上采样 $\\lambda$，但在原始尺度上进行平滑，方法是对 $(\\lambda_{i}, \\rho_{\\mathrm{obs}}(\\lambda_{i}))$ 和 $(\\lambda_{i}, \\eta_{\\mathrm{obs}}(\\lambda_{i}))$ 拟合三次平滑样条，平滑参数由 GCV 选择，然后通过取对数和使用链式法则求导进行变换，以获得关于 $\\xi = \\log \\lambda$ 的导数。\n\n根据所述假设选择最合适的选项，并基于截断误差缩放、求导下的噪声放大以及平滑模型对观测值误差结构的适用性来证明你的选择。",
            "solution": "在进行求解之前，首先对问题陈述进行验证，以确保其科学上合理、适定且完整。\n\n### 第1步：提取已知条件\n- **问题表述**：通过在 $x \\in \\mathbb{R}^{n}$ 上最小化 $\\|A x - b\\|_{2}^{2} + \\lambda^{2} \\|L x\\|_{2}^{2}$ 来找到 Tikhonov 解 $x_{\\lambda}$。\n- **已知量**：矩阵 $A \\in \\mathbb{R}^{m \\times n}$、数据向量 $b \\in \\mathbb{R}^{m}$、正则化矩阵 $L \\in \\mathbb{R}^{p \\times n}$ 和正则化参数 $\\lambda > 0$。\n- **定义的函数**：残差范数 $\\rho(\\lambda) = \\|A x_{\\lambda} - b\\|_{2}$ 和解的半范数 $\\eta(\\lambda) = \\|L x_{\\lambda}\\|_{2}$。\n- **L-曲线**：$(\\log \\rho(\\lambda), \\log \\eta(\\lambda))$ 在对数坐标轴上的参数图。\n- **目标**：找到L-曲线的拐角，这需要对 $\\log \\rho(\\lambda)$ 和 $\\log \\eta(\\lambda)$ 关于 $\\xi = \\log \\lambda$ 的一阶和二阶导数进行稳健估计。\n- **假设**：\n    1. 函数 $\\rho(\\lambda)$ 和 $\\eta(\\lambda)$ 是光滑且单调的。用广义奇异值分解 (GSVD) 表示时，它们是关于 $\\lambda^{2}$ 的光滑有理函数。因此，$r(\\xi) = \\log \\rho(e^{\\xi})$ 和 $e(\\xi) = \\log \\eta(e^{\\xi})$ 是关于 $\\xi = \\log \\lambda$ 的光滑函数。\n    2. 观测值受到小的乘性扰动影响：$\\rho_{\\mathrm{obs}}(\\lambda_{i}) = \\rho(\\lambda_{i}) (1 + \\delta_{i}^{\\rho})$ 和 $\\eta_{\\mathrm{obs}}(\\lambda_{i}) = \\eta(\\lambda_{i}) (1 + \\delta_{i}^{\\eta})$，其中 $|\\delta_{i}^{\\rho}| \\ll 1$ 且 $|\\delta_{i}^{\\eta}| \\ll 1$。\n    3. 在对数尺度下，这对应于加性误差：$r_{i}^{\\mathrm{obs}} = \\log \\rho(\\lambda_{i}) + \\varepsilon_{i}^{r}$ 和 $e_{i}^{\\mathrm{obs}} = \\log \\eta(\\lambda_{i}) + \\varepsilon_{i}^{e}$，其中 $\\varepsilon_{i}^{r} \\approx \\delta_{i}^{\\rho}$ 和 $\\varepsilon_{i}^{e} \\approx \\delta_{i}^{\\eta}$。\n    4. 对步长为 $h$ 的含噪数据进行数值微分，会将一阶导数的噪声放大约 $1/h$ 倍，二阶导数的噪声放大约 $1/h^{2}$ 倍。\n- **约束**：\n    1. $\\lambda$ 的范围跨越 $d$ 个数量级，即 $\\lambda_{\\max}/\\lambda_{\\min} = 10^{d}$，其中 $d$ 在 $3$ 和 $8$ 之间。\n    2. 计算预算允许 $50$ 到 $200$ 次求解，这对应于样本点的数量。\n\n### 第2步：使用提取的已知条件进行验证\n该问题陈述是数值线性代数和反问题领域中一个提法良好的问题。\n- **科学依据**：对 Tikhonov 正则化、L-曲线、$\\rho(\\lambda)$ 和 $\\eta(\\lambda)$ 的性质、乘性到加性噪声模型的转换以及数值微分的不适定性的描述，都是数值分析中的标准和正确概念。\n- **适定性**：问题要求在一组给定的选项中选择最合适的数值策略，这是评估对数值权衡理解的标准方式。目标明确定义：平衡截断误差和噪声放大，以获得稳健的导数估计。\n- **目标**：语言精确且专业。所有术语都是该学科内的标准术语。\n- **完整性和一致性**：问题提供了所有必要的信息，包括数学设置、噪声模型、目标和实际约束（计算预算、参数范围）。信息内部一致。\n\n### 第3步：结论与行动\n问题是有效的。它在科学上是合理的、适定的，并且包含足够的信息来回答。将继续求解过程。\n\n### 推导与分析\n问题的核心是设计一种用于对含噪数据进行微分的稳健数值策略。关键的权衡在于截断误差（随着采样步长 $h$ 减小而减小）和噪声放大（随着 $h$ 减小而增大）之间。任务是从含噪样本 $(r_{i}^{\\mathrm{obs}}, e_{i}^{\\mathrm{obs}})$ 中估计函数 $r(\\xi) = \\log \\rho(e^\\xi)$ 和 $e(\\xi) = \\log \\eta(e^\\xi)$ 的一阶和二阶导数。\n\n1.  **采样策略**：需要计算关于 $\\xi = \\log \\lambda$ 的导数。为了简化数值方法（如有限差分或样条拟合）并使截断误差和噪声放大的分析变得直接，非常理想的做法是在自变量 $\\xi$ 的均匀网格上采样数据。一个步长为常数 $h = \\xi_{i+1} - \\xi_i$ 的均匀网格 $\\{\\xi_i\\}$ 对应于 $\\lambda$ 的对数间隔网格，其中 $\\lambda_{i+1}/\\lambda_i$ 是常数。在 $\\lambda$ 上的线性网格会导致在 $\\xi$ 上的高度非均匀网格，使数值过程复杂化。规定的 $50-200$ 个点覆盖 $3-8$ 个数量级的 $\\lambda$ 范围，意味着采样密度大约在每个数量级 $50/8 \\approx 6$ 个点到 $200/3 \\approx 67$ 个点之间，因此选择每个数量级 $20-30$ 个点是一个合理的折中方案。\n\n2.  **噪声模型与平滑**：问题指出，噪声在 $\\rho$ 和 $\\eta$ 上是乘性的，这在其对数 $r = \\log \\rho$ 和 $e = \\log \\eta$ 上变为加性噪声。标准的数据平滑技术，如平滑样条，是为处理加性噪声而设计的。因此，任何平滑都应该在对数变换后的数据上进行，即对数据对 $(\\xi_i, r_{i}^{\\mathrm{obs}})$ 和 $(\\xi_i, e_{i}^{\\mathrm{obs}})$ 进行。在原始的 $(\\lambda, \\rho)$ 尺度上进行平滑对于给定的噪声模型来说在统计上是不合适的。\n\n3.  **微分策略**：使用有限差分直接对含噪数据进行微分是一个不适定问题，因为它会严重放大高频噪声。标准且稳健的方法是首先将一个光滑函数拟合到数据上，以滤除大部分噪声，然后对这个光滑函数进行解析求导。三次平滑样条是实现此目的的绝佳选择。对于一个数据集 $(\\xi_i, y_i)$，三次平滑样条 $s(\\xi)$ 是罚化平方和的唯一最小化子：\n    $$ \\sum_{i=1}^{n} w_i (y_i - s(\\xi_i))^2 + \\alpha \\int (s''(\\xi))^2 d\\xi $$\n    第一项强制对数据的保真度，而第二项则惩罚不光滑性。平滑参数 $\\alpha > 0$ 控制着两者之间的权衡。选择 $\\alpha$ 的一个可靠的数据驱动方法是广义交叉验证 (GCV)。如果噪声方差在样本间不是恒定的，使用与误差项（$\\varepsilon_i$）方差成反比的权重 $w_i$ 是统计上最优的方法。\n\n基于这些原则，我们评估给定的选项。\n\n### 逐项分析\n\n**A. 在对数间隔网格 $\\{\\lambda_{i}\\}_{i=1}^{n}$ 上采样 $\\lambda$，在 $\\xi = \\log \\lambda$ 中具有常数步长 $h$，每个数量级选择大约 $20$ 到 $30$ 个点（因此 $h \\approx \\log 10 / 20$ 到 $\\log 10 / 30$），并分别对 $(\\xi_{i}, r_{i}^{\\mathrm{obs}})$ 和 $(\\xi_{i}, e_{i}^{\\mathrm{obs}})$ 拟合加权三次平滑样条 $s_{r}(\\xi)$ 和 $s_{e}(\\xi)$。使用 $\\varepsilon_{i}^{r}$ 和 $\\varepsilon_{i}^{e}$ 的方差估计值 $\\sigma_{i}^{2}$ 设置权重 $w_{i} \\propto 1/\\sigma_{i}^{2}$，并通过广义交叉验证 (GCV) 选择平滑参数。在内部点评估一阶和二阶导数 $s_{r}^{\\prime}(\\xi)$、$s_{r}^{\\prime \\prime}(\\xi)$、$s_{e}^{\\prime}(\\xi)$ 和 $s_{e}^{\\prime \\prime}(\\xi)$，并丢弃一些边界样本以减轻端点效应。**\n此选项提出了一种全面且科学合理的策略。\n- 网格在 $\\lambda$ 上是对数的，这在正确的自变量 $\\xi$ 中是均匀的。\n- 采样密度是合理的，并与预算一致。\n- 使用三次平滑样条是正则化微分问题的适当技术。\n- 平滑在对数-对数域中进行，这对于该域中的加性噪声模型是正确的。\n- 使用 GCV 选择平滑参数和权重处理非恒定方差代表了最佳实践。\n- 对得到的样条进行微分是获得稳健导数估计的正确方法。\n- 承认并减轻边界效应表明了对该方法实际局限性的深入理解。\n因此，这个选项是关于如何正确解决这个问题的教科书式例子。\n\n**结论：正确**\n\n**B. 在原始 $\\lambda$ 尺度上，在线性间隔网格上用 $n$ 个点采样 $\\lambda$，并使用二阶中心有限差分计算 $r_{i}^{\\mathrm{obs}}$ 和 $e_{i}^{\\mathrm{obs}}$ 的一阶和二阶导数，不进行任何平滑。这确保了 $\\lambda$ 中的均匀截断误差，并避免了样条偏差。**\n此选项有多个严重缺陷。\n- 在 $\\lambda$ 上的线性网格是不合适的，因为它在 $\\xi = \\log \\lambda$ 中创建了一个高度非均匀的网格，使关于 $\\xi$ 的微分变得复杂。\n- 它建议不进行平滑，而是直接对含噪数据应用有限差分。如问题中所述以及数值分析中所知，这将灾难性地放大噪声，使得导数估计毫无用处，特别是对于二阶导数。\n- 其理由是有缺陷的：“在 $\\lambda$ 中的均匀截断误差”是无关紧要的，而“避免样条偏差”是一个糟糕的权衡，因为它用巨大的、不受控制的方差取代了微小、可控的偏差。\n\n**结论：不正确**\n\n**C. 在一个有数千个点的非常密集的对数间隔网格上采样 $\\lambda$（因此 $\\xi$ 中的 $h$ 极小），并拟合精确穿过所有 $(\\xi_{i}, r_{i}^{\\mathrm{obs}})$ 和 $(\\xi_{i}, e_{i}^{\\mathrm{obs}})$ 点的插值自然三次样条，以保留所有特征。计算插值函数的导数以获得一阶和二阶导数。**\n此选项的核心逻辑和可行性存在缺陷。\n- “数千个点”的采样密度违反了规定的 $50-200$ 次求解的计算预算。\n- 它使用*插值*样条，其设计目的是穿过每一个数据点。对于含噪数据，这意味着样条会跟随噪声，导致点之间出现高度振荡的行为。这种样条的导数将非常嘈杂，无法代表真实函数的导数。目标是*平滑*掉噪声，而不是对其进行插值。\n\n**结论：不正确**\n\n**D. 在对数间隔网格上用少量点（例如，在 $d \\approx 5$ 个数量级上取 $n \\approx 30$ 个点）采样 $\\lambda$，并通过最小二乘法对 $r_{i}^{\\mathrm{obs}}$ 和 $e_{i}^{\\mathrm{obs}}$ 拟合一个关于 $\\xi$ 的高阶全局多项式（阶数接近 $n-1$）。对该多项式进行解析求导以获得一阶和二阶导数。**\n此选项提出了一个在数值上很差的平滑器选择。\n- 虽然网格是合适的，但选择高阶全局多项式来拟合含噪数据是出了名地有问题的。这类多项式容易出现剧烈振荡（龙格现象），尤其是在区间端点附近，并且不太可能为底层的光滑函数提供良好的全局近似。它们倾向于过拟合数据。像样条这样的局部逼近方法对于这类任务要稳定和稳健得多。对于 $n$ 个点，使用一个阶数接近 $n-1$ 的多项式将近似于一个插值多项式，这不适合含噪数据。\n\n**结论：不正确**\n\n**E. 在每个数量级有 $20$ 到 $30$ 个点的对数间隔网格上采样 $\\lambda$，但在原始尺度上进行平滑，方法是对 $(\\lambda_{i}, \\rho_{\\mathrm{obs}}(\\lambda_{i}))$ 和 $(\\lambda_{i}, \\eta_{\\mathrm{obs}}(\\lambda_{i}))$ 拟合三次平滑样条，平滑参数由 GCV 选择，然后通过取对数和使用链式法则求导进行变换，以获得关于 $\\xi = \\log \\lambda$ 的导数。**\n此选项在错误的域中执行了关键的平滑步骤。\n- 噪声模型在 $(\\rho, \\eta)$ 上是乘性的，即误差方差不是常数，而是取决于函数的大小。标准的平滑样条最小化平方误差和，是为加性、常数方差的噪声模型设计的。在原始尺度上应用它们在统计上是次优的，可能导致拟合效果差，因为算法会隐含地更努力地去拟合函数值大的点。正确的程序是将数据转换到噪声是加性的且具有更简单统计特性的域——在这种情况下是对数-对数域——然后进行平滑。\n\n**结论：不正确**\n\n总而言之，选项A是唯一一个结合了正确的采样策略、适当的噪声模型、稳健的平滑技术和正确的数值微分程序的选项，反映了解决此类问题的最新方法。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在学习了如何寻找拐角之后，一个关键问题随之而来：一个清晰、明确的拐角是否总是存在？本练习通过研究一个算子奇异值平坦的、可解析求解的案例，探讨了 L 曲线方法的一个根本性限制。通过显式推导曲率，您将看到问题的谱特性如何直接影响 L 曲线的几何形状，并可能导致一个模糊不清的结果，从而深刻理解该方法在何种情况下最为有效。",
            "id": "3554649",
            "problem": "考虑由吉洪诺夫（Tikhonov）正则化最小二乘目标函数定义的 $\\mathbb{R}^{n}$ 中的线性反问题\n$$\nJ_{\\lambda}(x) \\;=\\; \\|A x - b\\|_{2}^{2} \\;+\\; \\lambda^{2} \\|x\\|_{2}^{2},\n$$\n其中 $A \\in \\mathbb{R}^{n \\times n}$，$b \\in \\mathbb{R}^{n}$ 非零，$\\lambda > 0$ 是正则化参数。L-曲线是残差范数对解范数的参数化双对数图，\n$$\n\\big(\\ln \\rho(\\lambda), \\, \\ln \\eta(\\lambda)\\big), \\quad \\text{其中} \\quad \\rho(\\lambda) := \\|A x_{\\lambda} - b\\|_{2}, \\quad \\eta(\\lambda) := \\|x_{\\lambda}\\|_{2},\n$$\n其中 $x_{\\lambda}$ 是 $J_{\\lambda}(x)$ 的最小化子。通过采用解析上易于处理的极限情况 $A = \\sigma I_{n}$（其中 $\\sigma > 0$），构造一个奇异值近乎平坦的矩阵 $A$，并分析由此产生的L-曲线。\n\n仅从基本定义出发——即最小化子 $x_{\\lambda}$ 的正规方程和平面曲线的曲率定义——推导：\n1. 用 $\\sigma$、$\\lambda$ 和 $\\|b\\|_{2}$ 表示的 $\\rho(\\lambda)$ 和 $\\eta(\\lambda)$ 的表达式。\n2. 参数平面曲线 $c(\\lambda) = \\big(\\ln \\rho(\\lambda), \\ln \\eta(\\lambda)\\big)$ 及其曲率 $\\kappa(\\lambda)$（作为 $\\lambda$ 的函数），该曲率通过参数化表示的平面曲线的标准曲率定义计算得出。\n3. 使 $\\kappa(\\lambda)$ 最大化的值 $\\lambda_{\\star} > 0$，以及最大曲率 $\\kappa_{\\max} := \\max_{\\lambda > 0} \\kappa(\\lambda)$。\n\n根据你对 $\\kappa(\\lambda)$ 的解析表达式，解释为什么在这种奇异值平坦的情况下，L-曲线缺少一个尖锐的角点，从而导致 $\\lambda$ 的选择不明确。\n\n以精确解析形式提供最终结果对 $\\big(\\lambda_{\\star}, \\kappa_{\\max}\\big)$。不需要四舍五入。",
            "solution": "我们从吉洪诺夫（Tikhonov）正则化的第一性原理开始。\n$$\nJ_{\\lambda}(x) \\;=\\; \\|A x - b\\|_{2}^{2} \\;+\\; \\lambda^{2} \\|x\\|_{2}^{2}\n$$\n的最小化子 $x_{\\lambda}$ 满足正规方程\n$$\nA^{\\top} (A x_{\\lambda} - b) \\;+\\; \\lambda^{2} x_{\\lambda} \\;=\\; 0,\n$$\n可将其重排为\n$$\n\\big(A^{\\top} A + \\lambda^{2} I\\big) x_{\\lambda} \\;=\\; A^{\\top} b.\n$$\n在奇异值近乎平坦的解析上易于处理的极限情况下，我们设 $A = \\sigma I_{n}$，其中 $\\sigma > 0$。于是 $A^{\\top} A = \\sigma^{2} I_{n}$ 且 $A^{\\top} b = \\sigma b$，因此正规方程简化为\n$$\n\\big(\\sigma^{2} I_{n} + \\lambda^{2} I_{n}\\big) x_{\\lambda} \\;=\\; \\sigma b\n\\quad\\Longrightarrow\\quad\nx_{\\lambda} \\;=\\; \\frac{\\sigma}{\\sigma^{2} + \\lambda^{2}} \\, b.\n$$\n残差为\n$$\nr_{\\lambda} \\;=\\; A x_{\\lambda} - b\n\\;=\\; \\sigma x_{\\lambda} - b\n\\;=\\; \\left( \\frac{\\sigma^{2}}{\\sigma^{2} + \\lambda^{2}} - 1 \\right) b\n\\;=\\; - \\frac{\\lambda^{2}}{\\sigma^{2} + \\lambda^{2}} \\, b.\n$$\n因此，残差范数和解范数分别为\n$$\n\\rho(\\lambda) \\;=\\; \\|r_{\\lambda}\\|_{2}\n\\;=\\; \\frac{\\lambda^{2}}{\\sigma^{2} + \\lambda^{2}} \\, \\|b\\|_{2},\n\\qquad\n\\eta(\\lambda) \\;=\\; \\|x_{\\lambda}\\|_{2}\n\\;=\\; \\frac{\\sigma}{\\sigma^{2} + \\lambda^{2}} \\, \\|b\\|_{2}.\n$$\n在双对数坐标系中定义L-曲线\n$$\ns(\\lambda) \\;=\\; \\ln \\rho(\\lambda)\n\\;=\\; \\ln \\|b\\|_{2} + \\ln \\lambda^{2} - \\ln (\\sigma^{2} + \\lambda^{2}),\n\\qquad\nt(\\lambda) \\;=\\; \\ln \\eta(\\lambda)\n\\;=\\; \\ln \\|b\\|_{2} + \\ln \\sigma - \\ln (\\sigma^{2} + \\lambda^{2}).\n$$\n接下来，计算曲率所需的导数。我们有\n$$\ns'(\\lambda) \\;=\\; \\frac{2}{\\lambda} - \\frac{2\\lambda}{\\sigma^{2} + \\lambda^{2}}\n\\;=\\; \\frac{2 \\sigma^{2}}{\\lambda (\\sigma^{2} + \\lambda^{2})},\n$$\n$$\nt'(\\lambda) \\;=\\; - \\frac{2\\lambda}{\\sigma^{2} + \\lambda^{2}}.\n$$\n再次求导可得\n$$\ns''(\\lambda) \\;=\\; - \\frac{2}{\\lambda^{2}} - \\frac{2(\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{2}},\n\\qquad\nt''(\\lambda) \\;=\\; - \\frac{2(\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{2}}.\n$$\n对于一个平面参数曲线 $(x(\\lambda), y(\\lambda))$，其曲率作为参数 $\\lambda$ 的函数为\n$$\n\\kappa(\\lambda) \\;=\\;\n\\frac{\\left| x'(\\lambda) y''(\\lambda) - y'(\\lambda) x''(\\lambda) \\right|}\n{\\left( x'(\\lambda)^{2} + y'(\\lambda)^{2} \\right)^{3/2}}.\n$$\n将此应用于 $x(\\lambda) = s(\\lambda)$ 和 $y(\\lambda) = t(\\lambda)$，我们计算分子\n$$\nN(\\lambda) \\;=\\; s'(\\lambda) t''(\\lambda) - t'(\\lambda) s''(\\lambda).\n$$\n使用上述表达式，\n\\begin{align*}\ns'(\\lambda) t''(\\lambda)\n=\\; \\frac{2 \\sigma^{2}}{\\lambda (\\sigma^{2} + \\lambda^{2})} \\cdot \\left( - \\frac{2(\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{2}} \\right)\n\\;=\\; - \\frac{4 \\sigma^{2} (\\sigma^{2} - \\lambda^{2})}{\\lambda (\\sigma^{2} + \\lambda^{2})^{3}}, \\\\\nt'(\\lambda) s''(\\lambda)\n=\\; \\left( - \\frac{2 \\lambda}{\\sigma^{2} + \\lambda^{2}} \\right) \\left( - \\frac{2}{\\lambda^{2}} - \\frac{2(\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{2}} \\right) \\\\\n=\\; \\frac{4}{\\lambda (\\sigma^{2} + \\lambda^{2})} + \\frac{4 \\lambda (\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{3}}.\n\\end{align*}\n相减得到\n\\begin{align*}\nN(\\lambda)\n=\\; - \\frac{4 \\sigma^{2} (\\sigma^{2} - \\lambda^{2})}{\\lambda (\\sigma^{2} + \\lambda^{2})^{3}}\n\\;-\\; \\frac{4}{\\lambda (\\sigma^{2} + \\lambda^{2})}\n\\;-\\; \\frac{4 \\lambda (\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{3}} \\\\\n=\\; - \\frac{8 \\sigma^{2}}{\\lambda (\\sigma^{2} + \\lambda^{2})^{2}}.\n\\end{align*}\n因此 $\\left|N(\\lambda)\\right| = \\dfrac{8 \\sigma^{2}}{\\lambda (\\sigma^{2} + \\lambda^{2})^{2}}$。\n\n分母为\n\\begin{align*}\nD(\\lambda)\n=\\; \\left( s'(\\lambda)^{2} + t'(\\lambda)^{2} \\right)^{3/2}\n\\;=\\; \\left( \\frac{4 \\sigma^{4}}{\\lambda^{2} (\\sigma^{2} + \\lambda^{2})^{2}} + \\frac{4 \\lambda^{2}}{(\\sigma^{2} + \\lambda^{2})^{2}} \\right)^{3/2} \\\\\n=\\; \\left( \\frac{4}{(\\sigma^{2} + \\lambda^{2})^{2}} \\left( \\frac{\\sigma^{4}}{\\lambda^{2}} + \\lambda^{2} \\right) \\right)^{3/2}\n\\;=\\; \\frac{8}{(\\sigma^{2} + \\lambda^{2})^{3}} \\left( \\frac{\\sigma^{4}}{\\lambda^{2}} + \\lambda^{2} \\right)^{3/2}.\n\\end{align*}\n因此，曲率为\n\\begin{align*}\n\\kappa(\\lambda)\n=\\; \\frac{\\left|N(\\lambda)\\right|}{D(\\lambda)}\n\\;=\\; \\frac{\\dfrac{8 \\sigma^{2}}{\\lambda (\\sigma^{2} + \\lambda^{2})^{2}}}{\\dfrac{8}{(\\sigma^{2} + \\lambda^{2})^{3}} \\left( \\dfrac{\\sigma^{4}}{\\lambda^{2}} + \\lambda^{2} \\right)^{3/2}} \\\\\n=\\; \\frac{\\sigma^{2} (\\sigma^{2} + \\lambda^{2})}{\\lambda \\left( \\dfrac{\\sigma^{4}}{\\lambda^{2}} + \\lambda^{2} \\right)^{3/2}}\n\\;=\\; \\frac{\\sigma^{2} (\\sigma^{2} + \\lambda^{2}) \\lambda^{2}}{(\\sigma^{4} + \\lambda^{4})^{3/2}}.\n\\end{align*}\n引入无量纲变量 $y := \\lambda^{2} / \\sigma^{2}$（其中 $y > 0$）。那么\n$$\n\\kappa(\\lambda) \\;=\\; \\frac{y(1 + y)}{(1 + y^{2})^{3/2}}.\n$$\n为在 $\\lambda > 0$ 上最大化 $\\kappa(\\lambda)$，我们在 $y > 0$ 上最大化 $g(y) := \\dfrac{y(1 + y)}{(1 + y^{2})^{3/2}}$。求导，\n\\begin{align*}\ng'(y)\n=\\; (1 + 2 y) (1 + y^{2})^{-3/2} - 3 y (y + y^{2}) (1 + y^{2})^{-5/2} \\\\\n=\\; (1 + y^{2})^{-5/2} \\left[ (1 + 2 y)(1 + y^{2}) - 3 y (y + y^{2}) \\right] \\\\\n=\\; (1 + y^{2})^{-5/2} \\left( 1 + 2 y - 2 y^{2} - y^{3} \\right).\n\\end{align*}\n令 $g'(y) = 0$ 得到三次方程\n$$\n1 + 2 y - 2 y^{2} - y^{3} \\;=\\; 0,\n$$\n等价于\n$$\ny^{3} + 2 y^{2} - 2 y - 1 \\;=\\; 0.\n$$\n一个根是 $y = 1$，而 $y^{2} + 3 y + 1 = 0$ 的其余根为负。由于 $y > 0$，唯一的临界点是 $y = 1$。当 $y \\to 0^{+}$ 时，$g(y) \\sim y \\to 0$；当 $y \\to \\infty$ 时，$g(y) \\sim y^{2}/y^{3} = 1/y \\to 0$，因此 $y = 1$ 是全局最大化子。因此，\n$$\n\\lambda_{\\star}^{2} / \\sigma^{2} \\;=\\; 1\n\\quad\\Longrightarrow\\quad\n\\lambda_{\\star} \\;=\\; \\sigma,\n\\qquad\n\\kappa_{\\max} \\;=\\; g(1) \\;=\\; \\frac{2}{(1 + 1)^{3/2}} \\;=\\; \\frac{1}{\\sqrt{2}}.\n$$\n曲率 $\\kappa(\\lambda)$ 受 $\\dfrac{1}{\\sqrt{2}}$ 的限制，并在 $\\lambda = \\sigma$ 处达到其最大值，但这个最大值是适中的并且是宽泛的，而不是尖锐的峰值。因此，在这种奇异值平坦的情况下，L-曲线没有表现出明显的角点，导致通过L-曲线准则选择 $\\lambda$ 时存在模糊性：没有一个几何上特别突出的参数值。",
            "answer": "$$\\boxed{\\begin{pmatrix}\\sigma & \\frac{1}{\\sqrt{2}}\\end{pmatrix}}$$"
        },
        {
            "introduction": "最后的这项实践将进入一个高级的防御性场景，在此场景中 L 曲线可能会产生主动的误导。您将研究结构化的，即“对抗性”噪声，是如何制造一个并不对应于良好解的欺骗性拐角。该练习将理论分析与完整的计算实现相结合，挑战您不仅要理解其失效机制，还要基于主角度分析设计并编写一个诊断工具，以标记出这些危险情况。",
            "id": "3554612",
            "problem": "考虑一个带 Tikhonov 正则化的线性逆问题。设 $A \\in \\mathbb{R}^{m \\times n}$，其奇异值分解为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 的对角线元素为 $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_{\\min(m,n)} > 0$。给定数据 $b \\in \\mathbb{R}^{m}$，对于参数 $\\lambda > 0$ 的 Tikhonov 正则化解定义为 $\\|A x - b\\|_2^2 + \\lambda^2 \\|x\\|_2^2$ 的最小化子，记作 $x_{\\lambda} \\in \\mathbb{R}^{n}$。L 曲线是当 $\\lambda$ 变化时 $(\\log \\|A x_{\\lambda} - b\\|_2, \\log \\|x_{\\lambda}\\|_2)$ 的参数图，一个常用的参数选择是此曲线上曲率最大的点。您的任务是研究能够产生误导性 L 曲线拐角的对抗性噪声，并基于 $x_{\\lambda}$ 与主导右奇异子空间之间的主角分析设计一种诊断方法。\n\n从数值线性代数的核心定义出发，完成以下任务。\n\n1.  以奇异值分解为基础，将 Tikhonov 解表示为滤波因子形式。设 $b = \\sum_{i} \\beta_i u_i$，其中 $\\beta_i = u_i^{\\top} b$，并定义滤波因子 $\\phi_i(\\lambda) = \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda^2}$。推导出表达式\n    $$\n    x_{\\lambda} = \\sum_{i=1}^{\\min(m,n)} \\phi_i(\\lambda) \\beta_i v_i,\n    $$\n    并证明残差 $r_{\\lambda} = A x_{\\lambda} - b$ 在左奇异向量基中的系数为\n    $$\n    \\gamma_i(\\lambda) = \\beta_i \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2}\n    $$\n    即 $r_{\\lambda} = \\sum_i \\gamma_i(\\lambda) u_i$。\n\n2.  定义 L 曲线参数化 $X(\\lambda) = \\log \\|r_{\\lambda}\\|_2$ 和 $Y(\\lambda) = \\log \\|x_{\\lambda}\\|_2$。将曲线 $\\lambda \\mapsto (X(\\lambda), Y(\\lambda))$ 视为平面曲线，使用标准的平面曲率公式，推导该参数曲线关于平滑参数 $t$ 的曲率。如果通过 $t = \\log \\lambda$ 进行重新参数化，那么对于 $x(t) = X(\\mathrm{e}^{t})$ 和 $y(t) = Y(\\mathrm{e}^{t})$，证明可以使用数值微分计算出数值稳定的曲率\n    $$\n    \\kappa(t) = \\frac{|x'(t) y''(t) - y'(t) x''(t)|}{\\left(x'(t)^2 + y'(t)^2\\right)^{3/2}},\n    $$\n    并解释为什么通过 $t = \\log \\lambda$ 进行重新参数化可以提高不适定问题的数值稳定性。\n\n3.  考虑与前导左奇异向量对齐的对抗性噪声。假设数据为 $b = A x_{\\mathrm{true}} + e$，其中 $e = \\eta \\|A x_{\\mathrm{true}}\\|_2 u_1$ 对于某个 $\\eta > 0$，即噪声与第一个左奇异向量 $u_1$ 对齐。使用 $\\beta_i$ 和 $\\gamma_i(\\lambda)$ 的表达式，定性地论证为什么这种对齐会产生一个在某个参数 $\\lambda$ 处有拐角的 L 曲线，该参数会强调主导奇异子空间，并可能偏离用于重构 $x_{\\mathrm{true}}$ 的最优权衡。\n\n4.  提出一种基于 L 曲线拐角 $\\lambda_{\\ast}$ 处的解 $x_{\\lambda_{\\ast}}$ 与主导右奇异子空间 $\\mathcal{V}_k = \\mathrm{span}\\{v_1,\\dots,v_k\\}$ 之间主角分析的诊断方法。向量 $x$ 与子空间 $\\mathcal{V}_k$ 之间的最小主角 $\\theta$ 由下式表征：\n    $$\n    \\cos \\theta = \\frac{\\|P_{\\mathcal{V}_k} x\\|_2}{\\|x\\|_2},\n    $$\n    其中 $P_{\\mathcal{V}_k}$ 是到 $\\mathcal{V}_k$ 上的正交投影算子。此外，定义一个数据主导性度量\n    $$\n    f_{\\mathrm{top}} = \\frac{\\sum_{i=1}^{k} \\beta_i^2}{\\sum_{i=1}^{\\min(m,n)} \\beta_i^2},\n    $$\n    用于衡量数据能量在前 $k$ 个左奇异方向上的分数。提出一个规则，当 $\\cos \\theta$ 接近 $1$ 且 $f_{\\mathrm{top}}$ 很大时，标记可能存在误导性的 L 曲线拐角，并指定适合数值实现的定量阈值。所有计算出的角度（若有）必须以弧度为单位。\n\n5.  实现一个程序，该程序构建合成问题，通过数值曲率最大化计算 L 曲线拐角，评估所提出的诊断方法，并为每个测试用例输出一个布尔值，指示该 L 曲线拐角是否被诊断方法标记为可能具有误导性。使用以下测试套件，该套件旨在覆盖典型和对抗性条件：\n\n    - 矩阵构建：设置 $m = n = 60$。令奇异值从 $10^0$ 对数衰减到 $10^{-6}$，即 $\\sigma_i = 10^{-\\alpha_i}$，其中 $\\alpha_i$ 在 $0$ 到 $6$ 之间线性间隔，对于 $i = 1,\\dots,60$。将 $U$ 和 $V$ 构建为从具有固定随机种子的高斯矩阵的 $\\mathrm{QR}$ 分解中获得的独立随机正交矩阵。设置 $A = U \\Sigma V^{\\top}$。\n    - 真值构建：对于 $i \\le \\lfloor 0.4 n \\rfloor$，设置 $c_i = 0$；对于 $i > \\lfloor 0.4 n \\rfloor$，设置 $c_i = 1/(i - \\lfloor 0.4 n \\rfloor)$。将 $c$ 归一化为单位 $\\ell_2$-范数，并设置 $x_{\\mathrm{true}} = V c$。定义 $b_{\\mathrm{clean}} = A x_{\\mathrm{true}}$。\n    - L 曲线计算：在一系列在 $[10^{-10}, 10^{2}]$ 上对数间隔的 $\\lambda$ 值网格上评估 L 曲线。使用参数 $t = \\log \\lambda$ 和有限差分计算曲率。选择使曲率最大化的 $\\lambda$ 作为拐角 $\\lambda_{\\ast}$。\n    - 诊断具体参数：为主导子空间 $\\mathcal{V}_k$ 和 $\\mathcal{U}_k$ 选择 $k = 3$，使用阈值 $\\cos \\theta \\ge 0.995$ 和 $f_{\\mathrm{top}} \\ge 0.2$ 来标记可疑的 L 曲线拐角。\n    - 噪声模型和水平（使用固定的随机种子以保证可复现性）：\n        1.  良性白噪声：$e = \\delta \\|b_{\\mathrm{clean}}\\|_2 z$，其中 $z \\sim \\mathcal{N}(0, I_m)$ 被归一化为单位范数，$\\delta = 0.05$。\n        2.  对抗性前导方向噪声：$e = \\delta \\|b_{\\mathrm{clean}}\\|_2 u_1$，$\\delta = 0.5$。\n        3.  对抗性末尾方向噪声：$e = \\delta \\|b_{\\mathrm{clean}}\\|_2 u_{n}$，$\\delta = 0.5$。\n        4.  近无噪声情况：白噪声，$\\delta = 10^{-8}$，如情况 1。\n\n    对于每种情况，令 $b = b_{\\mathrm{clean}} + e$，计算 L 曲线拐角 $\\lambda_{\\ast}$，然后在 $x_{\\lambda_{\\ast}}$ 和相应的 $\\beta_i = u_i^{\\top} b$ 处评估 $\\cos \\theta$ 和 $f_{\\mathrm{top}}$。输出一个布尔值，指示诊断是否将该情况标记为可疑。\n\n    您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，\"[True,False,False,True]\"），分别对应上述四种情况。任何内部计算的角度（若有）必须以弧度为单位；最终输出是无单位的布尔值。不允许用户输入。\n\n    最终输出格式必须是精确的一行：一个不带逗号后空格的 Python 风格的布尔值列表。",
            "solution": "所给问题是数值线性代数中一个定义良好且有科学依据的练习，具体涉及 Tikhonov 正则化和 L 曲线方法。其对残差向量系数的定义存在一个微小的不一致之处，我们将予以指出，但这并不影响问题的核心逻辑。我们将继续提供完整的解答。\n\n### 第 1 部分：滤波因子形式的 Tikhonov 解\n\nTikhonov 正则化解 $x_{\\lambda}$ 是最小化泛函 $J(x) = \\|A x - b\\|_2^2 + \\lambda^2 \\|x\\|_2^2$ 的向量。通过将 $J(x)$ 对 $x$ 的梯度设为零来找到最小化子。这会得到正规方程：\n$$\n(A^{\\top} A + \\lambda^2 I) x = A^{\\top} b\n$$\n我们使用奇异值分解 $A = U \\Sigma V^{\\top}$，这意味着 $A^{\\top} A = V \\Sigma^{\\top} \\Sigma V^{\\top}$ 且 $A^{\\top} b = V \\Sigma^{\\top} U^{\\top} b$。正规方程变为：\n$$\n(V \\Sigma^{\\top} \\Sigma V^{\\top} + \\lambda^2 V I V^{\\top}) x_{\\lambda} = V \\Sigma^{\\top} U^{\\top} b\n$$\n利用 $V$ 的正交性（即 $V^{\\top}V = I$），我们可以从左侧乘以 $V^{\\top}$：\n$$\n(\\Sigma^{\\top} \\Sigma + \\lambda^2 I) V^{\\top} x_{\\lambda} = \\Sigma^{\\top} U^{\\top} b\n$$\n我们定义变换后的解向量 $y = V^{\\top} x_{\\lambda}$ 和变换后的数据向量 $d = U^{\\top} b$。$d$ 的分量是 $d_i = u_i^{\\top} b$，即给定的 $\\beta_i$。矩阵 $\\Sigma^{\\top} \\Sigma + \\lambda^2 I$ 是一个 $n \\times n$ 的对角矩阵，其对角线元素为 $\\sigma_i^2 + \\lambda^2$，其中 $i=1, \\dots, \\min(m,n)$。$y$ 的第 $i$ 个分量的方程是：\n$$\n(\\sigma_i^2 + \\lambda^2) y_i = \\sigma_i \\beta_i\n$$\n解出 $y_i$ 得 $y_i = \\frac{\\sigma_i \\beta_i}{\\sigma_i^2 + \\lambda^2}$。为了恢复 $x_{\\lambda}$，我们通过 $x_{\\lambda} = V y = \\sum_{i=1}^{\\min(m,n)} y_i v_i$ 进行逆变换。代入 $y_i$ 的表达式：\n$$\nx_{\\lambda} = \\sum_{i=1}^{\\min(m,n)} \\frac{\\sigma_i \\beta_i}{\\sigma_i^2 + \\lambda^2} v_i\n$$\n这可以用给定的滤波因子 $\\phi_i(\\lambda) = \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda^2}$ 表示，从而得到所需的形式：\n$$\nx_{\\lambda} = \\sum_{i=1}^{\\min(m,n)} \\phi_i(\\lambda) \\beta_i v_i\n$$\n接下来，我们推导残差 $r_{\\lambda} = A x_{\\lambda} - b$ 的系数。我们在左奇异向量基 $\\{u_i\\}$ 中展开 $A x_{\\lambda}$：\n$$\nA x_{\\lambda} = (U \\Sigma V^{\\top}) \\left( \\sum_{j=1}^{\\min(m,n)} y_j v_j \\right) = U \\Sigma \\left( \\sum_{j=1}^{\\min(m,n)} y_j (V^{\\top} v_j) \\right) = U \\Sigma y = \\sum_{i=1}^{\\min(m,n)} \\sigma_i y_i u_i\n$$\n代入 $y_i$：\n$$\nA x_{\\lambda} = \\sum_{i=1}^{\\min(m,n)} \\frac{\\sigma_i^2 \\beta_i}{\\sigma_i^2 + \\lambda^2} u_i\n$$\n数据向量为 $b = \\sum_{i=1}^{m} \\beta_i u_i$。因此，残差为：\n$$\nr_{\\lambda} = A x_{\\lambda} - b = \\sum_{i=1}^{\\min(m,n)} \\frac{\\sigma_i^2 \\beta_i}{\\sigma_i^2 + \\lambda^2} u_i - \\sum_{i=1}^{m} \\beta_i u_i\n$$\n在一个共同的求和下合并各项（假设当 $i > \\min(m,n)$ 时 $\\sigma_i=0$）：\n$$\nr_{\\lambda} = \\sum_{i=1}^{m} \\left( \\frac{\\sigma_i^2}{\\sigma_i^2 + \\lambda^2} - 1 \\right) \\beta_i u_i = \\sum_{i=1}^{m} \\left( \\frac{\\sigma_i^2 - (\\sigma_i^2 + \\lambda^2)}{\\sigma_i^2 + \\lambda^2} \\right) \\beta_i u_i = \\sum_{i=1}^{m} \\frac{-\\lambda^2}{\\sigma_i^2 + \\lambda^2} \\beta_i u_i\n$$\n问题陈述中存在一个形式上的不一致。它定义了 $r_{\\lambda} = A x_{\\lambda} - b$，但给出的系数是 $\\gamma_i(\\lambda) = \\beta_i \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2}$，这是正数。我们的推导表明系数是 $-\\gamma_i(\\lambda)$。$\\gamma_i(\\lambda)$ 的表达式对应于另一种残差定义 $r=b - A x_{\\lambda}$。这个可能的符号错误不影响范数 $\\|r_{\\lambda}\\|_2$，因此不会改变 L 曲线的几何形状。我们继续使用所推导系数的绝对值。\n\n### 第 2 部分：L 曲线曲率\n\nL 曲线是 $(\\log \\|r_{\\lambda}\\|_2, \\log \\|x_{\\lambda}\\|_2)$ 的参数图。我们定义 $\\rho(\\lambda) = \\|r_{\\lambda}\\|_2$ 和 $\\eta(\\lambda) = \\|x_{\\lambda}\\|_2$。对数-对数尺度上的 L 曲线由 $\\lambda \\mapsto (X(\\lambda), Y(\\lambda))$ 参数化，其中 $X(\\lambda) = \\log \\rho(\\lambda)$ 且 $Y(\\lambda) = \\log \\eta(\\lambda)$。对于由 $t$ 参数化的一般平面曲线 $c(t) = (x(t), y(t))$，其曲率由问题中给出的公式给出：\n$$\n\\kappa(t) = \\frac{|x'(t) y''(t) - y'(t) x''(t)|}{\\left(x'(t)^2 + y'(t)^2\\right)^{3/2}}\n$$\n对于不适定问题，重新参数化 $t = \\log \\lambda$（即 $\\lambda = e^t$）在数值上是有利的。奇异值 $\\sigma_i$ 通常跨越多个数量级，导致解范数 $\\eta(\\lambda)$ 和残差范数 $\\rho(\\lambda)$ 在 $\\lambda$ 较小时变化迅速，而在 $\\lambda$ 较大时变化缓慢。$\\lambda$ 上的均匀网格无法很好地采样快速变化的区域。$\\lambda$ 上的对数网格，对应于参数 $t=\\log\\lambda$ 上的均匀网格，能够更有效地在所有尺度上分布采样点。数值微分方法，例如实现中使用的有限差分，在均匀网格上求值时能提供更准确的导数近似。因此，在这个均匀网格上计算关于 $t$ 的导数 $x'(t)$、$y'(t)$、$x''(t)$ 和 $y''(t)$，会产生更稳定可靠的曲率计算结果。\n\n### 第 3 部分：对抗性噪声分析\n\n当数据被与主导左奇异向量对齐的噪声污染时，即 $b = A x_{\\mathrm{true}} + e$，其中 $e = \\eta \\|A x_{\\mathrm{true}}\\|_2 u_1$，数据系数 $\\beta_i = u_i^{\\top} b$ 会受到如下影响：\n$$\n\\beta_i = u_i^{\\top}(A x_{\\mathrm{true}} + e) = u_i^{\\top} A x_{\\mathrm{true}} + \\eta \\|A x_{\\mathrm{true}}\\|_2 (u_i^{\\top} u_1) = (u_i^{\\top} A x_{\\mathrm{true}}) + (\\eta \\|A x_{\\mathrm{true}}\\|_2) \\delta_{i1}\n$$\n其中 $\\delta_{i1}$ 是克罗内克 δ。噪声仅扰动第一个系数 $\\beta_1$，使其被人为地放大。解范数 $\\|x_{\\lambda}\\|_2^2 = \\sum_i (\\phi_i(\\lambda) \\beta_i)^2$ 和残差范数 $\\|r_{\\lambda}\\|_2^2 = \\sum_i (\\gamma_i(\\lambda))^2$ 现在都由其涉及 $\\beta_1$ 的第一项主导。\nL 曲线的拐角通常标志着 $\\lambda$ 在数据拟合和解的大小之间取得平衡的过渡点。当 $\\beta_1$ 过大时，这种平衡被打破。曲线的动态由第一个 SVD 分量控制，权衡拐角将被推向 $\\lambda_{\\ast} \\approx \\sigma_1$。这个 $\\lambda_{\\ast}$ 的选择会严重过滤所有奇异值 $\\sigma_i \\ll \\sigma_1$ 的分量。由此产生的解 $x_{\\lambda_{\\ast}}$ 将由 $v_1$ 分量主导，实质上是将大的、含噪声的数据分量投影回解空间。这个解无法准确地表示 $x_{\\mathrm{true}}$，特别是如果其本质特征编码在 $i>1$ 的奇异向量 $v_i$ 中。因此，L 曲线拐角具有误导性，因为它识别出的参数是为了捕捉主导噪声而最优，而不是为了重构真实信号。\n\n### 第 4 部分：诊断方法提议\n\n第 3 部分的分析表明，一个具有误导性的拐角 $\\lambda_{\\ast}$ 会产生一个与主导右奇异子空间高度对齐的解 $x_{\\lambda_{\\ast}}$。这启发我们设计一种诊断方法来检测这种情况。\n\n1.  **解的对齐度**：我们使用主角的余弦值 $\\cos \\theta$ 来衡量 $x_{\\lambda_{\\ast}}$ 与主导子空间 $\\mathcal{V}_k = \\mathrm{span}\\{v_1, \\dots, v_k\\}$ 的对齐程度：\n    $$\n    \\cos \\theta = \\frac{\\|P_{\\mathcal{V}_k} x_{\\lambda_{\\ast}}\\|_2}{\\|x_{\\lambda_{\\ast}}\\|_2}\n    $$\n    其中 $P_{\\mathcal{V}_k}$ 是到 $\\mathcal{V}_k$ 上的正交投影算子。接近 $1$ 的 $\\cos \\theta$ 值表示强对齐。\n\n2.  **数据主导性**：我们使用度量 $f_{\\mathrm{top}}$ 来衡量数据向量 $b$ 的能量在相应的主导左奇异子空间 $\\mathcal{U}_k = \\mathrm{span}\\{u_1, \\dots, u_k\\}$ 中的集中程度：\n    $$\n    f_{\\mathrm{top}} = \\frac{\\sum_{i=1}^{k} \\beta_i^2}{\\sum_{i=1}^{\\min(m,n)} \\beta_i^2} = \\frac{\\sum_{i=1}^{k} (u_i^{\\top}b)^2}{\\|b\\|_2^2}\n    $$\n    一个大的 $f_{\\mathrm{top}}$ 值表明少数主导分量驱动着数据。\n\n**诊断规则**：如果解的对齐度高且数据能量集中，则 L 曲线拐角 $\\lambda_{\\ast}$ 被标记为可能具有误导性。对于一个 $k=3$ 的实际实现，我们提出以下阈值：\n如果满足以下条件，则标记为可疑：\n$$\n\\cos \\theta \\ge 0.995 \\quad \\text{且} \\quad f_{\\mathrm{top}} \\ge 0.2\n$$\n这个规则识别了正则化参数可能反映了主导（且可能被污染）的数据分量，而不是找到一个有意义的解的情况。",
            "answer": "```python\nimport numpy as np\n\ndef construct_problem(m, n, seed):\n    \"\"\"Constructs the test problem matrix A and true solution x_true.\"\"\"\n    rng = np.random.default_rng(seed=seed)\n    \n    # Singular values\n    s = np.logspace(0, -6, n)\n    \n    # Orthogonal matrices U and V\n    H1 = rng.standard_normal((m, m))\n    U, _ = np.linalg.qr(H1)\n    \n    H2 = rng.standard_normal((n, n))\n    V, _ = np.linalg.qr(H2)\n        \n    # Full A matrix\n    Sigma_mat = np.zeros((m, n))\n    np.fill_diagonal(Sigma_mat, s)\n    A = U @ Sigma_mat @ V.T\n    \n    # True solution x_true\n    n_cutoff = int(np.floor(0.4 * n))\n    c = np.zeros(n)\n    indices = np.arange(n_cutoff, n)\n    c[indices] = 1.0 / (indices - n_cutoff + 1)\n    c /= np.linalg.norm(c)\n    \n    x_true = V @ c\n    \n    return A, U, s, V, x_true\n\ndef get_lcurve_corner(U, s, b, lambda_grid):\n    \"\"\"Computes the L-curve and finds the lambda at maximum curvature.\"\"\"\n    m = U.shape[0]\n    n = len(s)\n    \n    # Data coefficients in U basis\n    beta_full = U.T @ b\n    beta = beta_full[:n]\n\n    log_res_norms = []\n    log_sol_norms = []\n    \n    s2 = s**2\n    beta2 = beta**2\n    \n    for lam in lambda_grid:\n        lam2 = lam**2\n        den = s2 + lam2\n        \n        # Solution norm calculation\n        sol_coeffs_sq = (s2 * beta2) / (den**2)\n        norm_x2 = np.sum(sol_coeffs_sq)\n        \n        # Residual norm calculation\n        res_coeffs_sq = (lam2**2 * beta2) / (den**2)\n        # Add residual from components of b orthogonal to U's first n columns\n        if m > n:\n            norm_r2 = np.sum(res_coeffs_sq) + np.sum(beta_full[n:]**2)\n        else:\n            norm_r2 = np.sum(res_coeffs_sq)\n        \n        # Avoid log(0) for extremely small norms\n        if norm_x2 > 1e-300 and norm_r2 > 1e-300:\n            log_sol_norms.append(0.5 * np.log(norm_x2))\n            log_res_norms.append(0.5 * np.log(norm_r2))\n        else: # Mark as invalid\n            log_sol_norms.append(np.nan) \n            log_res_norms.append(np.nan)\n\n    log_res_norms = np.array(log_res_norms)\n    log_sol_norms = np.array(log_sol_norms)\n    t = np.log(lambda_grid)\n    \n    # Filter out invalid (nan) values from numerical issues\n    valid_indices = ~np.isnan(log_sol_norms)  ~np.isnan(log_res_norms)\n    t_valid = t[valid_indices]\n    log_res_valid = log_res_norms[valid_indices]\n    log_sol_valid = log_sol_norms[valid_indices]\n    \n    # Compute derivatives w.r.t. t = log(lambda)\n    x_prime = np.gradient(log_res_valid, t_valid)\n    y_prime = np.gradient(log_sol_valid, t_valid)\n    \n    x_double_prime = np.gradient(x_prime, t_valid)\n    y_double_prime = np.gradient(y_prime, t_valid)\n    \n    # Curvature calculation\n    numerator = np.abs(x_prime * y_double_prime - y_prime * x_double_prime)\n    denominator = (x_prime**2 + y_prime**2)**1.5\n    \n    # Avoid division by zero\n    curvature = np.zeros_like(denominator)\n    valid_denom = denominator > 1e-12\n    curvature[valid_denom] = numerator[valid_denom] / denominator[valid_denom]\n    \n    idx_max_curv = np.argmax(curvature)\n    lambda_star = (lambda_grid[valid_indices])[idx_max_curv]\n    \n    return lambda_star\n\ndef evaluate_diagnostic(U, s, V, b, lambda_star, k, cos_theta_thresh, f_top_thresh):\n    \"\"\"Evaluates the diagnostic for a given b and lambda_star.\"\"\"\n    m, n = U.shape[0], V.shape[0]\n    \n    beta_full = U.T @ b\n    beta = beta_full[:n]\n        \n    s2 = s**2\n    lam_star2 = lambda_star**2\n    x_coeffs_V = (s * beta) / (s2 + lam_star2)\n    \n    # Calculate cos(theta)\n    norm_x = np.linalg.norm(x_coeffs_V)\n    norm_proj_x = np.linalg.norm(x_coeffs_V[:k])\n    \n    cos_theta = 0.0\n    if norm_x > 1e-16:\n      cos_theta = norm_proj_x / norm_x\n      \n    # Calculate f_top\n    norm_beta_full_sq = np.sum(beta_full**2)\n    norm_beta_top_k_sq = np.sum(beta[:k]**2)\n    \n    f_top = 0.0\n    if norm_beta_full_sq > 1e-16:\n      f_top = norm_beta_top_k_sq / norm_beta_full_sq\n\n    is_suspect = (cos_theta >= cos_theta_thresh) and (f_top >= f_top_thresh)\n    \n    return is_suspect\n\ndef solve():\n    \"\"\"Main function to run the test suite and print results.\"\"\"\n    m, n = 60, 60\n    k = 3\n    matrix_seed = 0\n    noise_seed = 1\n\n    cos_theta_thresh = 0.995\n    f_top_thresh = 0.2\n    \n    A, U, s, V, x_true = construct_problem(m, n, matrix_seed)\n    b_clean = A @ x_true\n    norm_b_clean = np.linalg.norm(b_clean)\n    \n    lambda_grid = np.logspace(-10, 2, 400)\n    \n    rng_noise = np.random.default_rng(noise_seed)\n    \n    e_white = rng_noise.standard_normal(m)\n    e_white /= np.linalg.norm(e_white)\n    \n    noise_cases = [\n        (0.05 * norm_b_clean * e_white),    # 1. Benign white noise\n        (0.5 * norm_b_clean * U[:, 0]),     # 2. Adversarial leading-direction\n        (0.5 * norm_b_clean * U[:, -1]),    # 3. Adversarial trailing-direction\n        (1e-8 * norm_b_clean * e_white)     # 4. Near noise-free\n    ]\n    \n    results = []\n    \n    for e in noise_cases:\n        b = b_clean + e\n        lambda_star = get_lcurve_corner(U, s, b, lambda_grid)\n        is_suspect = evaluate_diagnostic(U, s, V, b, lambda_star, k, cos_theta_thresh, f_top_thresh)\n        results.append(is_suspect)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}