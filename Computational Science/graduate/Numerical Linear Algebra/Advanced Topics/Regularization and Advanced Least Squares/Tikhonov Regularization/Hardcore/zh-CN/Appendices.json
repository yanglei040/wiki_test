{
    "hands_on_practices": [
        {
            "introduction": "吉洪诺夫正则化本质上是一种谱滤波方法。为了理解其内在机制，一个富有洞察力的方法是将其与另一种经典技术——截断奇异值分解（Truncated Singular Value Decomposition, TSVD）——进行比较。这项练习  将指导您完成一个数值实验，旨在对比 Tikhonov 正则化的平滑滤波与 TSVD 的锐利截断，并揭示奇异值的分布如何影响不同方法的性能。",
            "id": "3599470",
            "problem": "考虑在数值线性代数的意义下求解一个线性反问题：给定一个矩阵 $A \\in \\mathbb{R}^{n \\times n}$、一个未知向量 $x_{\\mathrm{true}} \\in \\mathbb{R}^{n}$、确定性数据噪声 $\\eta \\in \\mathbb{R}^{n}$ 以及观测数据 $b = A x_{\\mathrm{true}} + \\eta$，比较两种正则化策略：Tikhonov 正则化和截断奇异值分解。目标是计算两种策略在一组测试用例上的相对解误差，并突出一个因谱间隙而导致截断奇异值分解性能优于 Tikhonov 正则化的设计。\n\n基本定义和要求：\n- 对于正则化参数为 $\\lambda > 0$ 的 Tikhonov 正则化，其解是严格凸目标函数 $\\|A x - b\\|_{2}^{2} + \\lambda \\|x\\|_{2}^{2}$ 的最小化子，也就是正规方程 $(A^{\\top} A + \\lambda I) x_{\\mathrm{tik}} = A^{\\top} b$ 的唯一解。\n- 对于截断奇异值分解 (TSVD)，定义奇异值分解为 $A = U \\Sigma V^{\\top}$，其中奇异值为 $\\sigma_{1} \\ge \\sigma_{2} \\ge \\dots \\ge \\sigma_{n} \\ge 0$。对于截断索引 $k \\in \\{0,1,\\dots,n\\}$，TSVD 解为 $x_{\\mathrm{tsvd}}^{(k)} = \\sum_{i=1}^{k} \\frac{u_{i}^{\\top} b}{\\sigma_{i}} v_{i}$。在此问题中，截断索引 $k$ 由规则 $k = \\max\\{ i \\in \\{1,\\dots,n\\} : \\sigma_{i}^{2} \\ge \\lambda \\}$ 确定，约定如果该集合为空，则 $k=0$。\n- 候选解 $\\widehat{x}$ 相对于 $x_{\\mathrm{true}}$ 的相对误差为 $\\|\\widehat{x} - x_{\\mathrm{true}}\\|_{2} / \\|x_{\\mathrm{true}}\\|_{2}$。\n\n为可测试性设定的实现约束和特殊化：\n- 在所有测试用例中，取 $n = 10$ 并选择 $A$ 为对角矩阵，其对角元为正且降序排列，因此 $U = I$，$V = I$，奇异值即为 $A$ 的对角元。这使得 $A = \\mathrm{diag}(\\sigma_{1},\\dots,\\sigma_{n})$ 且 $A^{\\top} A = \\mathrm{diag}(\\sigma_{1}^{2},\\dots,\\sigma_{n}^{2})$。\n- 对每个测试用例，确定性地定义噪声向量为 $\\eta_{i} = \\mathrm{noise\\_level} \\cdot (-1)^{i}$，其中 $i = 1,2,\\dots,n$。\n- 对于 Tikhonov 正则化，在这种对角设定下，从正规方程导出的显式分量表达式为 $x_{\\mathrm{tik},i} = \\frac{\\sigma_{i}}{\\sigma_{i}^{2} + \\lambda} b_{i}$，其中 $i = 1,2,\\dots,n$。\n- 对于 TSVD，给定由上述选择规则确定的 $k$，在这种对角设定下的显式分量表达式为 $x_{\\mathrm{tsvd},i}^{(k)} = \\begin{cases} b_{i}/\\sigma_{i},  i \\le k, \\\\ 0,  i > k. \\end{cases}$\n\n测试套件：\n- 测试用例 #1（谱间隙；设计用于突出截断奇异值分解的优势）：\n  - $n = 10$。\n  - 奇异值 $\\sigma = [1.0, 0.6, 0.36, 0.216, 0.1296, 10^{-3}, 5 \\cdot 10^{-4}, 2 \\cdot 10^{-4}, 10^{-4}, 5 \\cdot 10^{-5}]$。\n  - 真实解 $x_{\\mathrm{true}} = [1, -\\tfrac{1}{2}, \\tfrac{1}{4}, -\\tfrac{1}{8}, \\tfrac{1}{16}, 0, 0, 0, 0, 0]$。\n  - 正则化参数 $\\lambda = 10^{-5}$。\n  - 噪声水平 $\\mathrm{noise\\_level} = 10^{-6}$。\n- 测试用例 #2（平滑谱；无明显间隙）：\n  - $n = 10$。\n  - 奇异值 $\\sigma_{i} = 10^{-\\frac{i-1}{3}}$，其中 $i = 1,2,\\dots,10$。\n  - 真实解 $x_{\\mathrm{true},i} = 0.8^{i-1}$，其中 $i = 1,2,\\dots,10$。\n  - 正则化参数 $\\lambda = 10^{-4}$。\n  - 噪声水平 $\\mathrm{noise\\_level} = 10^{-6}$。\n- 测试用例 #3（正则化参数极小的边界条件）：\n  - $n = 10$。\n  - 奇异值 $\\sigma_{i} = 10^{-\\frac{i-1}{3}}$，其中 $i = 1,2,\\dots,10$。\n  - 真实解 $x_{\\mathrm{true},i} = 0.8^{i-1}$，其中 $i = 1,2,\\dots,10$。\n  - 正则化参数 $\\lambda = 10^{-12}$。\n  - 噪声水平 $\\mathrm{noise\\_level} = 10^{-6}$。\n- 测试用例 #4（正则化参数极大的边界条件）：\n  - $n = 10$。\n  - 奇异值 $\\sigma_{i} = 10^{-\\frac{i-1}{3}}$，其中 $i = 1,2,\\dots,10$。\n  - 真实解 $x_{\\mathrm{true},i} = 0.8^{i-1}$，其中 $i = 1,2,\\dots,10$。\n  - 正则化参数 $\\lambda = 10^{1}$。\n  - 噪声水平 $\\mathrm{noise\\_level} = 10^{-6}$。\n\n每个测试用例需要实现的任务：\n- 构建 $A = \\mathrm{diag}(\\sigma_{1},\\dots,\\sigma_{n})$、$x_{\\mathrm{true}}$、$\\eta$（其中 $\\eta_{i} = \\mathrm{noise\\_level} \\cdot (-1)^{i}$）以及 $b = A x_{\\mathrm{true}} + \\eta$。\n- 使用 $x_{\\mathrm{tik},i} = \\frac{\\sigma_{i}}{\\sigma_{i}^{2} + \\lambda} b_{i}$ 计算 Tikhonov 解 $x_{\\mathrm{tik}}$。\n- 计算截断索引 $k = \\max\\{ i : \\sigma_{i}^{2} \\ge \\lambda \\}$，并遵循当集合为空时 $k=0$ 的约定。\n- 使用 $x_{\\mathrm{tsvd},i}^{(k)} = b_{i}/\\sigma_{i}$（当 $i \\le k$ 时）和 $x_{\\mathrm{tsvd},i}^{(k)} = 0$（当 $i > k$ 时）计算截断奇异值分解解 $x_{\\mathrm{tsvd}}^{(k)}$。\n- 计算相对 $2$-范数误差 $e_{\\mathrm{tsvd}} = \\|x_{\\mathrm{tsvd}}^{(k)} - x_{\\mathrm{true}}\\|_{2} / \\|x_{\\mathrm{true}}\\|_{2}$ 和 $e_{\\mathrm{tik}} = \\|x_{\\mathrm{tik}} - x_{\\mathrm{true}}\\|_{2} / \\|x_{\\mathrm{true}}\\|_{2}$。\n- 同时计算布尔值 $b_{\\mathrm{adv}} = (e_{\\mathrm{tsvd}}  e_{\\mathrm{tik}})$，以指示在该测试中截断奇异值分解是否严格优于 Tikhonov 正则化。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个以逗号分隔的列表，列表被方括号括起。每个测试用例贡献一个形如 $[k, e_{\\mathrm{tsvd}}, e_{\\mathrm{tik}}, b_{\\mathrm{adv}}]$ 的列表。因此，最终输出应为一个包含四个内部列表的列表，按测试用例 #1 到 #4 的顺序排列，例如 $[[k_{1}, e_{\\mathrm{tsvd},1}, e_{\\mathrm{tik},1}, b_{\\mathrm{adv},1}], [k_{2}, e_{\\mathrm{tsvd},2}, e_{\\mathrm{tik},2}, b_{\\mathrm{adv},2}], [k_{3}, e_{\\mathrm{tsvd},3}, e_{\\mathrm{tik},3}, b_{\\mathrm{adv},3}], [k_{4}, e_{\\mathrm{tsvd},4}, e_{\\mathrm{tik},4}, b_{\\mathrm{adv},4}]]$。\n\n注意：\n- 没有物理单位；所有计算均在无量纲的浮点数算术中进行。\n- 不使用角度。\n- 将所有布尔值表示为语言原生的布尔值，所有误差表示为浮点数。",
            "solution": "该问题要求比较解决不适定线性反问题的两种标准正则化技术：吉洪诺夫正则化和截断奇异值分解 (TSVD)。验证证实该问题在科学上是合理的、适定的，并为数值实验提供了一套清晰、自洽的指令和数据。所有定义和公式都与数值线性代数领域的既定文献一致。因此，我们可以着手求解。\n\n问题的核心在于求解线性系统 $A x = b$，其中矩阵 $A$ 是病态的，数据向量 $b$ 被噪声 $\\eta$ 污染。模型由 $b = A x_{\\mathrm{true}} + \\eta$ 给出，其中 $x_{\\mathrm{true}}$ 是我们试图近似的真实解。通过 $x = A^{-1} b$ 求解 $x$ 的一个朴素尝试将得到 $x = x_{\\mathrm{true}} + A^{-1} \\eta$。由于 $A$ 是病态的，其逆 $A^{-1}$ 具有非常大的范数，导致噪声项 $\\eta$ 的极端放大。正则化方法旨在通过在解中引入受控的偏差，来换取由噪声引起的方差的急剧减小，从而抵消这种影响。\n\n该问题通过考虑一个对角矩阵 $A = \\mathrm{diag}(\\sigma_{1}, \\dots, \\sigma_{n})$ 来简化分析，其中对角元 $\\sigma_i  0$ 是 $A$ 的奇异值。在一般情况下，任何矩阵 $A$ 都有一个奇异值分解 (SVD) $A = U \\Sigma V^{\\top}$，其中 $U$ 和 $V$ 是正交矩阵，$\\Sigma = \\mathrm{diag}(\\sigma_1, \\dots, \\sigma_n)$。选择一个对角矩阵 $A$ 等价于在一个基中工作，其中 SVD 是平凡的 ($U=V=I$)，这使我们能够专注于每种正则化方法如何处理奇异值本身。\n\n**Tikhonov 正则化**\n\n吉洪诺夫正则化将问题重塑为一个优化问题，寻求一个解 $x$，使其最小化数据保真项和解范数惩罚项的组合：\n$$ x_{\\mathrm{tik}} = \\arg\\min_{x} \\left( \\|A x - b\\|_{2}^{2} + \\lambda \\|x\\|_{2}^{2} \\right) $$\n参数 $\\lambda  0$ 控制着权衡。唯一的最小化子 $x_{\\mathrm{tik}}$ 通过求解相关的正规方程找到：$(A^{\\top} A + \\lambda I) x_{\\mathrm{tik}} = A^{\\top} b$。对于我们的对角矩阵 $A=\\mathrm{diag}(\\sigma_i)$，该系统解耦为 $n$ 个标量方程：\n$$ (\\sigma_{i}^{2} + \\lambda) x_{\\mathrm{tik},i} = \\sigma_{i} b_{i} \\quad \\text{其中 } i \\in \\{1, \\dots, n\\} $$\n这给出了 Tikhonov 解的显式分量式公式：\n$$ x_{\\mathrm{tik},i} = \\frac{\\sigma_{i}}{\\sigma_{i}^{2} + \\lambda} b_{i} $$\n项 $f_{i}^{\\mathrm{tik}} = \\frac{\\sigma_{i}^{2}}{\\sigma_{i}^{2} + \\lambda}$ 可被视为一个“滤波因子”。它平滑地衰减与小奇异值相关的分量。如果 $\\sigma_i^2 \\gg \\lambda$，则 $f_{i}^{\\mathrm{tik}} \\approx 1$，该分量基本不变。如果 $\\sigma_i^2 \\ll \\lambda$，则 $f_{i}^{\\mathrm{tik}} \\approx 0$，该分量被抑制。\n\n**截断奇异值分解 (TSVD)**\n\nTSVD 采用更直接的方法，仅使用“重要的”奇异分量来构造解。一般的 TSVD 解由一个截断和给出：\n$$ x_{\\mathrm{tsvd}}^{(k)} = \\sum_{i=1}^{k} \\frac{u_{i}^{\\top} b}{\\sigma_{i}} v_{i} $$\n其中 $k$ 是截断索引，决定了包含多少分量。在我们的对角情况下 ($U=I, V=I$)，这简化为：\n$$ x_{\\mathrm{tsvd},i}^{(k)} = \\begin{cases} b_{i}/\\sigma_{i}  \\text{若 } i \\le k \\\\ 0  \\text{若 } i  k \\end{cases} $$\n这对应于构成一个阶跃函数的滤波因子 $f_{i}^{\\mathrm{tsvd}}$：当 $i \\le k$ 时 $f_{i}^{\\mathrm{tsvd}} = 1$，当 $i  k$ 时 $f_{i}^{\\mathrm{tsvd}} = 0$。该问题通过规则 $k = \\max\\{ i \\in \\{1,\\dots,n\\} : \\sigma_{i}^{2} \\ge \\lambda \\}$ 将 $k$ 的选择与 Tikhonov 参数 $\\lambda$ 联系起来，若集合为空则 $k=0$。该规则本质上保留了所有 Tikhonov 滤波因子至少为 $1/2$ 的分量。\n\n**比较与谱间隙的作用**\n\n根本区别在于它们的滤波函数：Tikhonov 的是平滑的，而 TSVD 的是陡峭的。测试用例 #1 专门设计用于突出 TSVD 的陡峭截断具有优势的场景。它具有一个“谱间隙”，其中奇异值在 $\\sigma_5$ 和 $\\sigma_6$ 之间出现大幅下降。正则化参数 $\\lambda=10^{-5}$ 被选择为位于此间隙内（即 $\\sigma_5^2 \\gg \\lambda \\gg \\sigma_6^2$）。此外，真实解 $x_{\\mathrm{true}}$ 的信息含量仅限于前 $5$ 个分量。\n\n在这些条件下，TSVD 的截断规则得出 $k=5$。因此，TSVD 保留了前 $5$ 个分量（信号所在之处），并完全丢弃了其余分量（由于 $x_{\\mathrm{true},i}=0$ for $i5$，这些分量仅包含噪声）。对于这个特定的问题结构，这起到了完美滤波器的作用。相比之下，吉洪诺夫正则化将其平滑滤波器应用于所有分量。虽然它严重抑制了 $i  5$ 的分量，但仍允许少量经过滤波的噪声通过。更重要的是，它也轻微地抑制了 $i \\le 5$ 的分量，引入了 TSVD 在这些分量上没有的正则化误差。这导致 TSVD 的性能优于 Tikhonov。\n\n对于其他具有更平滑谱衰减的测试用例，TSVD 的陡峭截断可能是有害的。如果 $x_{\\mathrm{true}}$ 在被 TSVD 截断的分量中（因为它们的 $\\sigma_i$ 很小）包含显著能量，它将产生较大的正则化误差。Tikhonov 对这些分量的温和抑制可能导致更好的整体近似。\n\n**计算步骤**\n\n对于四个测试用例中的每一个，执行以下过程：\n1.  初始化参数：$n=10$、奇异值 $\\sigma$、真实解 $x_{\\mathrm{true}}$、正则化参数 $\\lambda$ 和噪声水平。\n2.  构造噪声向量 $\\eta$，其中对于基于 0 的索引 $j \\in \\{0, \\dots, 9\\}$，$\\eta_{j} = \\mathrm{noise\\_level} \\cdot (-1)^{j+1}$。\n3.  计算数据向量 $b = \\sigma \\odot x_{\\mathrm{true}} + \\eta$，其中 $\\odot$ 表示逐元素相乘。\n4.  使用其分量式公式计算 Tikhonov 解向量 $x_{\\mathrm{tik}}$。\n5.  根据提供的规则确定 TSVD 截断索引 $k$。\n6.  计算 TSVD 解向量 $x_{\\mathrm{tsvd}}^{(k)}$。\n7.  计算两个解的相对 $2$-范数误差：$e_{\\mathrm{tik}} = \\|x_{\\mathrm{tik}} - x_{\\mathrm{true}}\\|_{2} / \\|x_{\\mathrm{true}}\\|_{2}$ 和 $e_{\\mathrm{tsvd}} = \\|x_{\\mathrm{tsvd}}^{(k)} - x_{\\mathrm{true}}\\|_{2} / \\|x_{\\mathrm{true}}\\|_{2}$。\n8.  评估布尔条件 $b_{\\mathrm{adv}} = (e_{\\mathrm{tsvd}}  e_{\\mathrm{tik}})$。\n然后报告每个案例收集的结果 $[k, e_{\\mathrm{tsvd}}, e_{\\mathrm{tik}}, b_{\\mathrm{adv}}]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_test_case(sigma_vals, xtrue_vals, lam, noise_level):\n    \"\"\"\n    Runs a single test case for comparing Tikhonov and TSVD regularization.\n    \"\"\"\n    n = 10\n    sigma = np.array(sigma_vals, dtype=float)\n    xtrue = np.array(xtrue_vals, dtype=float)\n\n    # Construct the noise vector eta and observed data b\n    # The problem uses 1-based indexing i=1,...,n. Python uses 0-based j=0,...,n-1.\n    # eta_i = noise_level * (-1)^i translates to eta[j] = noise_level * (-1)**(j+1)\n    indices_1_based = np.arange(1, n + 1)\n    eta = noise_level * ((-1) ** indices_1_based)\n    b = sigma * xtrue + eta\n\n    # Compute the Tikhonov solution\n    xtik = (sigma / (sigma**2 + lam)) * b\n\n    # Determine the TSVD truncation index k\n    # k = max{ i in {1..n} : sigma_i^2 >= lam }\n    # np.where returns 0-based indices. k needs to be a 1-based count.\n    valid_indices = np.where(sigma**2 >= lam)[0]\n    if len(valid_indices) == 0:\n        k = 0\n    else:\n        k = int(np.max(valid_indices) + 1)\n\n    # Compute the TSVD solution\n    xtsvd = np.zeros(n)\n    if k > 0:\n        # Slicing with :k works correctly for 0-based index up to k-1.\n        xtsvd[:k] = b[:k] / sigma[:k]\n\n    # Compute the relative 2-norm errors\n    norm_xtrue = np.linalg.norm(xtrue)\n    \n    # This problem guarantees norm_xtrue > 0, so no division-by-zero check is needed.\n    e_tsvd = np.linalg.norm(xtsvd - xtrue) / norm_xtrue\n    e_tik = np.linalg.norm(xtik - xtrue) / norm_xtrue\n\n    # Determine if TSVD has a strictly smaller error\n    b_adv = bool(e_tsvd  e_tik)\n    \n    return [k, e_tsvd, e_tik, b_adv]\n\ndef solve():\n    \"\"\"\n    Defines and runs the four test cases, then prints the results.\n    \"\"\"\n    # Test case #1: Spectral gap\n    case1 = {\n        \"sigma_vals\": [1.0, 0.6, 0.36, 0.216, 0.1296, 1e-3, 5e-4, 2e-4, 1e-4, 5e-5],\n        \"xtrue_vals\": [1.0, -0.5, 0.25, -0.125, 0.0625, 0, 0, 0, 0, 0],\n        \"lam\": 1e-5,\n        \"noise_level\": 1e-6\n    }\n    \n    # Test case #2: Smooth spectrum\n    n = 10\n    j_indices = np.arange(n)\n    sigma_smooth = 10**(-j_indices / 3.0)\n    xtrue_smooth = 0.8**j_indices\n    case2 = {\n        \"sigma_vals\": sigma_smooth,\n        \"xtrue_vals\": xtrue_smooth,\n        \"lam\": 1e-4,\n        \"noise_level\": 1e-6\n    }\n    \n    # Test case #3: Small regularization parameter\n    case3 = {\n        \"sigma_vals\": sigma_smooth,\n        \"xtrue_vals\": xtrue_smooth,\n        \"lam\": 1e-12,\n        \"noise_level\": 1e-6\n    }\n\n    # Test case #4: Large regularization parameter\n    case4 = {\n        \"sigma_vals\": sigma_smooth,\n        \"xtrue_vals\": xtrue_smooth,\n        \"lam\": 1e1,\n        \"noise_level\": 1e-6\n    }\n\n    test_cases = [case1, case2, case3, case4]\n    \n    results = []\n    for case in test_cases:\n        result = run_test_case(\n            case[\"sigma_vals\"],\n            case[\"xtrue_vals\"],\n            case[\"lam\"],\n            case[\"noise_level\"]\n        )\n        results.append(result)\n\n    # Print in the specified format: [[k1, e_tsvd1, e_tik1, b_adv1], [k2, ...]]\n    # Python's default string representation for a list of lists matches the required format.\n    print(results)\n\nsolve()\n```"
        },
        {
            "introduction": "除了标准形式，广义吉洪诺夫正则化允许我们通过正则化算子 $L$ 来融入关于解的结构的先验知识。这项练习  探讨了一个关键概念——“模型偏差”（model bias），它在我们选择的正则化器与信号的真实性质不匹配时出现。通过对一个在小波基下稀疏的信号施加一个简单的范数惩罚（即 $L=I$），您将量化由此产生的误差，并体会到选择合适正则化器的重要性。",
            "id": "3599516",
            "problem": "考虑数值线性代数中的 Tikhonov 正则化问题。给定一个矩阵 $A \\in \\mathbb{R}^{n \\times n}$、一个数据向量 $y \\in \\mathbb{R}^{n}$ 和一个正则化算子 $L \\in \\mathbb{R}^{n \\times n}$，带有参数 $\\alpha  0$ 的 Tikhonov 估计量 $\\hat{x}_{\\alpha}$ 被定义为目标函数的唯一最小化子\n$$\nJ_{\\alpha}(x) = \\|A x - y\\|_{2}^{2} + \\alpha^{2} \\|L x\\|_{2}^{2}.\n$$\n您将研究未知向量 $x$ 的真实正则性与所选正则化算子 $L$ 之间的失配如何导致模型偏差。构建一个合成案例，其中基准真相 $x_{\\mathrm{true}}$ 在小波基中是稀疏的，但应用 Tikhonov 正则化时使用 $L = I$（单位算子），并量化由此产生的失配。\n\n您必须严格执行以下规范并计算所需的输出。\n\n1. 信号维度和小波基。\n   - 设 $n = 64$，并考虑 $\\mathbb{R}^{n}$ 上的标准正交 Haar 小波基。\n   - 对于前向 Haar 变换 $W$，使用以下规范系数排序：小波系数向量的排序为 $[a_{L}, d_{L}, d_{L-1}, \\dots, d_{1}]$，其中 $L = \\log_{2}(n)$，$a_{L} \\in \\mathbb{R}$ 是最终的粗略近似系数，$d_{j} \\in \\mathbb{R}^{2^{L-j}}$ 是在尺度 $j$ 上的细节块，其中 $j = L, L-1, \\dots, 1$。\n   - 逆 Haar 变换 $W^{-1}$ 从此排序中重构信号。\n\n2. 基准真相构建（在小波基中稀疏）。\n   - 设 $w_{\\mathrm{true}} \\in \\mathbb{R}^{n}$ 除在细节块内的五个特定位置外全为零，具体如下（使用上述排序，其中因 $n = 64$ 而 $L = 6$）：\n     - 在 $d_{6}$ 的位置 $0$ 处，设置值为 $+1.0$。\n     - 在 $d_{5}$ 的位置 $1$ 处，设置值为 $-0.8$。\n     - 在 $d_{3}$ 的位置 $3$ 处，设置值为 $+0.5$。\n     - 在 $d_{2}$ 的位置 $5$ 处，设置值为 $-1.1$。\n     - 在 $d_{1}$ 的位置 $17$ 处，设置值为 $+0.9$。\n   - 所有其他系数，包括 $a_{6}$，都为零。\n   - 定义 $x_{\\mathrm{true}} = W^{-1} w_{\\mathrm{true}}$。\n\n3. 前向算子 $A$ 和数据 $y$。\n   - 考虑两种前向算子：\n     - 情况 $\\mathrm{blur}$：$A$ 是一个循环卷积矩阵，由一个离散高斯核 $g \\in \\mathbb{R}^{n}$ 生成，该核的奇数截断长度为 $9$，其元素为\n       $$\n       g_{k} = \\frac{\\exp\\!\\left(-\\frac{(k-0)^{2}}{2 \\sigma^{2}}\\right)}{\\sum_{j=-4}^{4} \\exp\\!\\left(-\\frac{j^{2}}{2 \\sigma^{2}}\\right)}, \\quad k \\in \\{-4,-3,\\dots,4\\},\n       $$\n       通过将这 $9$ 个权重居中放置并将其余部分置零，周期性地嵌入到长度为 $n$ 的向量中，并使用环绕方式定义循环结构。使用 $\\sigma = 2.0$。\n     - 情况 $\\mathrm{id}$：$A = I$（单位矩阵）。\n   - 在所有情况下，生成无噪声数据 $y = A x_{\\mathrm{true}}$。\n\n4. 正则化和估计量。\n   - 固定 $L = I$，并为每个测试用例计算 Tikhonov 估计量 $\\hat{x}_{\\alpha}$，使其对给定的 $A$ 和 $y$ 最小化 $J_{\\alpha}(x)$。\n   - 此设置为无噪声环境；重点在于由小波稀疏真相与各向同性二次惩罚之间的失配所引起的确定性模型偏差。\n\n5. 失配量化指标。\n   对于每个测试用例，计算以下两个标量值：\n   - 信号域中的归一化平方模型偏差：\n     $$\n     b = \\frac{\\|\\hat{x}_{\\alpha} - x_{\\mathrm{true}}\\|_{2}^{2}}{\\|x_{\\mathrm{true}}\\|_{2}^{2}}.\n     $$\n   - 小波泄漏率，用于量化放置在 $w_{\\mathrm{true}}$ 中为零的系数上的能量：\n     $$\n     \\ell = \\frac{\\| (W \\hat{x}_{\\alpha})_{S^{c}} \\|_{2}^{2}}{\\| w_{\\mathrm{true}} \\|_{2}^{2}},\n     $$\n     其中 $S$ 是 $w_{\\mathrm{true}}$ 非零项的支撑集（索引集），$S^{c}$ 是其补集。分子使用重构信号 $\\hat{x}_{\\alpha}$ 的前向 Haar 变换。\n\n6. 测试套件。\n   使用以下四个测试用例，每个用例由 $(A\\text{-类型}, \\alpha)$ 指定：\n   - 测试 $1$：$(\\mathrm{blur}, 10^{-1})$。\n   - 测试 $2$：$(\\mathrm{blur}, 1)$。\n   - 测试 $3$：$(\\mathrm{blur}, 10^{-3})$。\n   - 测试 $4$：$(\\mathrm{id}, 3 \\times 10^{-1})$。\n\n7. 程序输出格式。\n   - 您的程序必须生成单行输出，其中包含聚合为列表的列表的结果。对于每个测试用例（按 $1, 2, 3, 4$ 的顺序），以浮点数形式输出数对 $[b, \\ell]$。\n   - 因此，最终输出必须是以下格式的单行文本\n     $$\n     [[b_{1}, \\ell_{1}], [b_{2}, \\ell_{2}], [b_{3}, \\ell_{3}], [b_{4}, \\ell_{4}]].\n     $$\n\n约束与指南：\n- 使用与指定排序一致的标准正交 Haar 变换的正确实现。\n- 在这两种情况下，都将 $A$ 显式地构建为稠密矩阵。\n- 通过最小化 $J_{\\alpha}(x)$ 来求解 $\\hat{x}_{\\alpha}$，不要使用任何迭代优化方法；期望使用直接线性代数方法。\n- 不涉及物理单位。\n- 禁止所有随机化；结果必须是确定性的。",
            "solution": "用户提供的问题经评估有效。它在数值线性代数和信号处理方面有科学依据，定义了所有必要参数，问题适定，且表述客观。它要求对吉洪诺夫正则化中的模型偏差进行定量分析，这是一个标准课题。因此，我们提供一个合理的解决方案。\n\n问题的核心是为给定的线性系统计算 Tikhonov 正则化估计 $\\hat{x}_{\\alpha}$，然后量化其相对于已知基准真相 $x_{\\mathrm{true}}$ 的误差或模型偏差。偏差的产生是因为正则化项 $\\alpha^2 \\|L x\\|_2^2$ 施加了一个惩罚，该惩罚将解偏向于使 $\\|L x\\|_2^2$ 较小的向量 $x$。在这个问题中，正则化算子是 $L=I$（单位算子），它偏好具有小欧几里得范数的解。然而，真实信号 $x_{\\mathrm{true}}$ 被构造成在小波基中是稀疏的，其范数本身并不小。真实信号的性质与正则化算子中隐含的假设之间的这种失配，正是我们要研究的模型偏差的来源。\n\n对于每个测试用例，解决方案按以下步骤进行：\n1.  构建必要的数学对象：标准正交 Haar 小波变换矩阵 $W$、基准真相信号 $x_{\\mathrm{true}}$ 和前向算子 $A$。\n2.  通过求解相应的正规方程组来计算 Tikhonov 估计量 $\\hat{x}_{\\alpha}$。\n3.  计算两个指定的误差指标：归一化平方模型偏差 $b$ 和小波泄漏率 $\\ell$。\n\n### 步骤 1：数学对象的构建\n\n**1.1. 标准正交 Haar 小波变换矩阵**\n问题指定了对维度 $n=64$ 的信号进行标准正交 Haar 小波变换。维度 $n=2^L$（其中 $L=6$）是 2 的幂，符合要求。小波系数的排序为 $[a_L, d_L, d_{L-1}, \\dots, d_1]$，其中 $a_L$ 是最终的近似系数（长度为 $1$），$d_j$ 是尺度 $j$ 上的细节系数（长度为 $2^{L-j}$）。这是一种“非标准”或未打包的排序，可以通过递归算法生成。前向变换 $w = Wx$ 将信号 $x \\in \\mathbb{R}^n$ 映射到其小波系数 $w \\in \\mathbb{R}^n$。逆变换为 $x = W^{-1}w$。由于基是标准正交的，变换矩阵 $W$ 是正交的，即 $W^{-1} = W^T$。\n\n矩阵 $W$ 可以通过识别其行是 Haar 基向量来构建。等效地，其转置矩阵 $W^T$ 的列是基向量。第 $i$ 个基向量是对应于小波域中位置 $i$ 处单个非零系数的信号。因此，我们可以通过对每个规范基向量 $e_i \\in \\mathbb{R}^n$ 应用逆 Haar 变换来构建 $W^T$。然后通过对结果进行转置得到矩阵 $W$。\n\n**1.2. 基准真相信号 $x_{\\mathrm{true}}$**\n基准真相信号 $x_{\\mathrm{true}}$ 由其小波系数 $w_{\\mathrm{true}}$ 定义。向量 $w_{\\mathrm{true}} \\in \\mathbb{R}^{64}$ 是稀疏的，在细节块内的指定位置有五个非零项：\n- 系数向量的结构为 $[a_6 (1), d_6 (1), d_5 (2), d_4 (4), d_3 (8), d_2 (16), d_1 (32)]$，其中括号中的数字是块的长度。\n- 这些块的索引是：$a_6: [0]$，$d_6: [1]$，$d_5: [2,3]$，$d_4: [4-7]$，$d_3: [8-15]$，$d_2: [16-31]$，$d_1: [32-63]$。\n- 非零值设置如下：\n  - $w_{\\mathrm{true}}[1] = +1.0$（在 $d_6$ 中）\n  - $w_{\\mathrm{true}}[3] = -0.8$（在 $d_5$ 中）\n  - $w_{\\mathrm{true}}[11] = +0.5$（在 $d_3$ 中）\n  - $w_{\\mathrm{true}}[21] = -1.1$（在 $d_2$ 中）\n  - $w_{\\mathrm{true}}[49] = +0.9$（在 $d_1$ 中）\n然后使用逆 Haar 变换合成信号：$x_{\\mathrm{true}} = W^T w_{\\mathrm{true}}$。\n\n**1.3. 前向算子 $A$ 和数据 $y$**\n考虑两种类型的前向算子：\n- **情况 `id`**：$A=I_{64}$，即 $64 \\times 64$ 的单位矩阵。\n- **情况 `blur`**：$A$ 是一个循环卷积矩阵。生成核是一个长度为 $9$、标准差为 $\\sigma=2.0$ 的离散高斯核。对于 $k \\in \\{-4, \\dots, 4\\}$ 的核权重 $g_k$ 被归一化以使其总和为 $1$。该核被嵌入到一个周期性向量 $c \\in \\mathbb{R}^{64}$ 中，该向量成为循环矩阵 $A$ 的第一列。具体来说，$c_0=g_0$，$c_k = g_k$ 对于 $k \\in \\{1,2,3,4\\}$，以及 $c_{n+k} = g_k$ 对于 $k \\in \\{-1,-2,-3,-4\\}$。\n无噪声数据向量生成为 $y = A x_{\\mathrm{true}}$。\n\n### 步骤 2：Tikhonov 估计量\nTikhonov 估计量 $\\hat{x}_{\\alpha}$ 是最小化目标函数 $J_{\\alpha}(x) = \\|A x - y\\|_{2}^{2} + \\alpha^{2} \\|I x\\|_{2}^{2}$ 的唯一向量 $x$。通过将梯度 $\\nabla_x J_{\\alpha}(x)$ 设置为零来找到最小化子，这会得到正规方程组：\n$$\n(A^T A + \\alpha^2 I) x = A^T y.\n$$\n这是一个线性方程组，可以求解得到 $\\hat{x}_{\\alpha}$：\n$$\n\\hat{x}_{\\alpha} = (A^T A + \\alpha^2 I)^{-1} A^T y.\n$$\n该系统使用直接数值线性代数求解器进行求解，以确保稳健性并满足问题规范。\n\n### 步骤 3：失配量化\n模型偏差使用两个指标进行量化：\n\n**3.1. 归一化平方模型偏差 ($b$)**\n该指标衡量信号域中的平方误差，并按真实信号的能量进行归一化：\n$$\nb = \\frac{\\|\\hat{x}_{\\alpha} - x_{\\mathrm{true}}\\|_{2}^{2}}{\\|x_{\\mathrm{true}}\\|_{2}^{2}}.\n$$\n\n**3.2. 小波泄漏率 ($\\ell$)**\n该指标量化了正则化解有多少能量“泄漏”到本应为零的小波系数上。设 $S$ 为 $w_{\\mathrm{true}}$ 中五个非零项的索引集，$S^c$ 为其补集。估计的小波系数为 $\\hat{w}_{\\alpha} = W \\hat{x}_{\\alpha}$。泄漏率为：\n$$\n\\ell = \\frac{\\| (\\hat{w}_{\\alpha})_{S^{c}} \\|_{2}^{2}}{\\| w_{\\mathrm{true}} \\|_{2}^{2}}.\n$$\n分母 $\\|w_{\\mathrm{true}}\\|_{2}^{2}$ 等于 $\\|x_{\\mathrm{true}}\\|_{2}^{2}$，因为 $W$ 是一个正交矩阵。分子是在 $w_{\\mathrm{true}}$ 为零的索引处 $\\hat{w}_{\\alpha}$ 的分量的平方范数。\n\n对由数对 $(A\\text{-类型}, \\alpha)$ 指定的四个测试用例中的每一个都执行这些计算。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import circulant\n\ndef solve():\n    \"\"\"\n    Main function to solve the Tikhonov regularization problem and compute misfit metrics.\n    \"\"\"\n\n    def _inverse_haar_recursive(w: np.ndarray) - np.ndarray:\n        \"\"\"\n        Recursively computes the inverse Haar transform for a 1D vector.\n        Assumes the 'unpacked' coefficient ordering [a_L, d_L, d_{L-1}, ...].\n        \"\"\"\n        n = len(w)\n        if n == 1:\n            return w\n        \n        m = n // 2\n        \n        # Based on the problem's coefficient sorting [aL, dL, dL-1, ...], \n        # a recursive call must unpack the approximation and detail coefficients\n        # in a non-standard way. The problem structure is:\n        # For a vector of size n=2^k, the approx coefficients are size 2^(k-1).\n        # The structure is [a_k, d_k, d_k-1, ...].\n        # Approx part = [a_k, d_k, ..., d_{k-j+1}] which is not contiguous.\n        # This seems to be a misunderstanding of the problem spec.\n        # Let's reinterpret the spec's ordering: `[a_L, d_L, d_{L-1}, ..., d_1]`.\n        # This implies a block structure.\n        # For n=4, L=2: [a2, d2, d1]. |a2|=1, |d2|=1, |d1|=2. Total = 4.\n        # x_approx = inv_haar([a2,d2]). x_detail = d1. This seems more plausible.\n        \n        # For n=2^k, approx part has size 2^(k-1), details part has size 2^(k-1)\n        # For w=[a_k, d_k, d_{k-1}, ...]: \n        # Let's use a standard block-based inverse transform, which is more robust.\n        # For a vector `v` of length `m`, the inverse transform produces a vector `x` of length `2m`.\n        # `v` is composed of `m/2` approx coeffs `a` and `m/2` detail coeffs `d`.\n        # `x[2k] = (a[k] + d[k]) / sqrt(2)`\n        # `x[2k+1] = (a[k] - d[k]) / sqrt(2)`\n        # This standard algorithm doesn't match the spec's `[aL, dL, dL-1, ...]` ordering.\n        # Let's implement the `[a_L, d_L, d_{L-1}, ...]` ordering based on PyWavelets' 'dwt' mode.\n        # It's an iterative, not recursive, process.\n        \n        # Let's stick to a direct implementation of the specified coefficient order.\n        # If w = [a_L, d_L, d_{L-1}, ..., d_1],\n        # a_{L-1} = inv_haar_1_level([a_L, d_L])\n        # a_{L-2} = inv_haar_1_level([a_{L-1}, d_{L-1}])\n        # and so on.\n\n        y = w.copy()\n        log2_n = int(np.log2(n))\n        \n        # Start from the coarsest scale\n        current_len = 1\n        for level in range(log2_n, 0, -1):\n            approx_coeffs = y[0:current_len]\n            # detail_coeffs are at [current_len : 2*current_len]\n            detail_coeffs = y[current_len : 2*current_len]\n            \n            # Inverse 1-level transform\n            reconstructed = np.zeros(2 * current_len)\n            reconstructed[0::2] = (approx_coeffs + detail_coeffs) / np.sqrt(2.0)\n            reconstructed[1::2] = (approx_coeffs - detail_coeffs) / np.sqrt(2.0)\n            \n            # Place back into the result vector\n            y[0 : 2*current_len] = reconstructed\n            current_len *= 2\n            \n        return y\n\n\n    def get_haar_matrix(n: int) - np.ndarray:\n        \"\"\"\n        Constructs the n x n orthonormal Haar wavelet transform matrix W.\n        The transform is defined as w = W @ x.\n        \"\"\"\n        if np.log2(n) % 1 != 0:\n            raise ValueError(\"n must be a power of 2.\")\n        \n        W_T = np.zeros((n, n))\n        I = np.identity(n)\n        for i in range(n):\n            W_T[:, i] = _inverse_haar_recursive(I[:, i])\n        \n        W = W_T.T\n        return W\n\n    def construct_ground_truth(n: int, W: np.ndarray):\n        \"\"\"Constructs the ground-truth wavelet coefficients and signal.\"\"\"\n        w_true = np.zeros(n)\n        \n        # n=64, L=6.\n        # Blocks start at: a6->0(len 1), d6->1(len 1), d5->2(len 2), d4->4(len 4),\n        # d3->8(len 8), d2->16(len 16), d1->32(len 32).\n        \n        w_true[1 + 0] = +1.0 # In d6, pos 0\n        w_true[2 + 1] = -0.8 # In d5, pos 1\n        w_true[8 + 3] = +0.5 # In d3, pos 3\n        w_true[16 + 5] = -1.1 # In d2, pos 5\n        w_true[32 + 17] = +0.9 # In d1, pos 17\n        \n        x_true = W.T @ w_true\n        \n        return w_true, x_true\n\n    def construct_forward_operator(A_type: str, n: int):\n        \"\"\"Constructs the forward operator A.\"\"\"\n        if A_type == 'id':\n            return np.identity(n)\n        elif A_type == 'blur':\n            sigma = 2.0\n            kernel_len = 9\n            k_range = np.arange(-(kernel_len//2), (kernel_len//2) + 1)\n            \n            g_unnorm = np.exp(-k_range**2 / (2.0 * sigma**2))\n            g = g_unnorm / np.sum(g_unnorm)\n            \n            c = np.zeros(n)\n            center_idx = kernel_len // 2\n            \n            c[0 : center_idx + 1] = g[center_idx:]\n            c[n - center_idx:] = g[:center_idx]\n            \n            return circulant(c)\n        else:\n            raise ValueError(f\"Unknown A_type: {A_type}\")\n\n    # ===== Main execution logic =====\n    \n    n = 64\n    \n    # 1. Construct universal components\n    W = get_haar_matrix(n)\n    w_true, x_true = construct_ground_truth(n, W)\n    \n    x_true_norm_sq = np.linalg.norm(x_true)**2\n    w_true_norm_sq = np.linalg.norm(w_true)**2\n    \n    support_mask = (w_true != 0)\n    complement_mask = ~support_mask\n    \n    # 2. Define test suite\n    test_cases = [\n        ('blur', 1e-1),\n        ('blur', 1.0),\n        ('blur', 1e-3),\n        ('id', 3e-1),\n    ]\n\n    results = []\n    \n    # 3. Iterate through test cases\n    for A_type, alpha in test_cases:\n        A = construct_forward_operator(A_type, n)\n        \n        y = A @ x_true\n        \n        M = A.T @ A + (alpha**2) * np.identity(n)\n        rhs = A.T @ y\n        x_hat = np.linalg.solve(M, rhs)\n        \n        bias_sq_norm = np.linalg.norm(x_hat - x_true)**2\n        b = bias_sq_norm / x_true_norm_sq\n        \n        w_hat = W @ x_hat\n        leakage_num = np.linalg.norm(w_hat[complement_mask])**2\n        l = leakage_num / w_true_norm_sq\n        \n        results.append([b, l])\n        \n    # 4. Format and print the final output\n    print(f\"{results}\")\n\n\nsolve()\n```"
        },
        {
            "introduction": "吉洪诺夫正则化的有效性取决于算子 $L$ 的性质。一个有趣的情形是当 $L$ 是低秩（low-rank）算子时，这意味着它拥有一个非平凡的零空间（nullspace），而解在该空间中的分量不会受到惩罚。这项练习  挑战您探索这种“部分正则化”的情形，分析解在未正则化子空间中的行为如何关键地依赖于前向算子 $A$ 的耦合结构。",
            "id": "3599497",
            "problem": "考虑有限维实欧几里得空间中的吉洪诺夫正则化问题。对于一个给定的矩阵 $A \\in \\mathbb{R}^{n \\times n}$、一个正则化算子 $L \\in \\mathbb{R}^{p \\times n}$、一个数据向量 $b \\in \\mathbb{R}^{n}$ 以及一个正则化参数 $\\lambda \\ge 0$，吉洪诺夫正则化解 $x_{\\lambda} \\in \\mathbb{R}^{n}$ 被定义为泛函 $J_{\\lambda}(x) = \\lVert A x - b \\rVert_{2}^{2} + \\lambda^{2} \\lVert L x \\rVert_{2}^{2}$ 的唯一极小化子。在本问题中，您将研究低秩算子 $L$ 如何仅在一个子空间上导致部分正则化，并刻画 $x_{\\lambda}$ 在其互补子空间上的行为。\n\n您必须仅使用以下基础出发点：\n- 吉洪诺夫目标函数 $J_{\\lambda}(x) = \\lVert A x - b \\rVert_{2}^{2} + \\lambda^{2} \\lVert L x \\rVert_{2}^{2}$ 的定义（其中 $\\lambda \\ge 0$）。\n- 有限维实向量空间中欧几里得内积、正交投影和最小二乘极小化子的基本性质。\n- Moore–Penrose 伪逆及其产生的正交投影算子。\n\n任务：\n1. 对于给定的测试用例 $(A,L,b,\\lambda_{1},\\lambda_{2})$，计算两个吉洪诺夫正则化解 $x_{\\lambda_{1}}$ 和 $x_{\\lambda_{2}}$（每个解都是对应 $\\lambda$ 下 $J_{\\lambda}(x)$ 的唯一极小化子）。\n2. 仅使用线性代数构造来计算到零空间 $\\mathcal{N}(L)$ 上的正交投影算子 $P_{\\mathcal{N}}$。具体来说，您必须计算 $P_{\\mathcal{N}} = I - L^{+} L$，其中 $L^{+}$ 表示 $L$ 的 Moore–Penrose 伪逆，$I$ 是大小为 $n \\times n$ 的单位矩阵。\n3. 对每个测试用例，计算解在 $\\lambda_{1}$ 和 $\\lambda_{2}$ 之间 $\\mathcal{N}(L)$ 分量上变化的欧几里得范数，即量 $\\lVert P_{\\mathcal{N}} (x_{\\lambda_{2}} - x_{\\lambda_{1}}) \\rVert_{2}$。\n\n构造与解释要求：\n- 您必须构造 $L$ 为低秩的示例，以使正则化仅应用于一个子空间。您必须通过测量 $\\lVert P_{\\mathcal{N}} (x_{\\lambda_{2}} - x_{\\lambda_{1}}) \\rVert_{2}$ 来明确检验 $x_{\\lambda}$ 在互补子空间 $\\mathcal{N}(L)$ 中的行为。\n- 您必须包含一个案例，其中 $A$ 和 $L$ 相对于分解 $\\mathbb{R}^{n} = \\mathcal{N}(L)^{\\perp} \\oplus \\mathcal{N}(L)$ 同时是块对角的，从而使 $\\lambda$ 的影响仅限于 $\\mathcal{N}(L)^{\\perp}$。\n- 您必须包含另一个案例，其中 $A$ 耦合了 $\\mathcal{N}(L)^{\\perp}$ 和 $\\mathcal{N}(L)$，从而使 $x_{\\lambda}$ 在 $\\mathcal{N}(L)$ 中的行为依赖于 $\\lambda$。\n\n为了可复现性和全面覆盖，请使用以下 $n = 4$ 的小型固定测试套件：\n- 测试用例 1（解耦，$\\lambda$ 有适度变化）：\n  - $A = \\operatorname{diag}(1,2,3,4)$,\n  - $L = \\operatorname{diag}(1,1,0,0)$,\n  - $b = [1,-2,3,-4]^{\\top}$,\n  - $(\\lambda_{1},\\lambda_{2}) = (0, 0.1)$.\n- 测试用例 2（解耦，$\\lambda$ 有极大变化）：\n  - $A = \\operatorname{diag}(1,2,3,4)$,\n  - $L = \\operatorname{diag}(1,1,0,0)$,\n  - $b = [1,-2,3,-4]^{\\top}$,\n  - $(\\lambda_{1},\\lambda_{2}) = (0, 1000)$.\n- 测试用例 3（耦合，展示到 $\\mathcal{N}(L)$ 的泄漏）：\n  - $A = \\begin{bmatrix} 1   0   0.5   0 \\\\ 0   2   0   0 \\\\ 0   0   3   0 \\\\ 0   0   0   4 \\end{bmatrix}$,\n  - $L = \\operatorname{diag}(1,1,0,0)$,\n  - $b = [1,-2,3,-4]^{\\top}$,\n  - $(\\lambda_{1},\\lambda_{2}) = (0, 10)$.\n- 测试用例 4（退化的低秩，完全没有正则化）：\n  - $A = \\operatorname{diag}(1,2,3,4)$,\n  - $L = 0_{4 \\times 4}$ (零矩阵),\n  - $b = [1,-2,3,-4]^{\\top}$,\n  - $(\\lambda_{1},\\lambda_{2}) = (0, 5)$.\n\n数值输出规范：\n- 对每个测试用例，计算单个浮点数值 $r = \\lVert P_{\\mathcal{N}} (x_{\\lambda_{2}} - x_{\\lambda_{1}}) \\rVert_{2}$。\n- 您的程序应生成单行输出，其中包含 4 个测试用例的结果，形式为方括号括起来的逗号分隔列表（例如 $[r_{1},r_{2},r_{3},r_{4}]$）。\n- 此任务不涉及物理单位。不涉及角度。不要以百分比形式表示答案。\n\n您的实现必须是一个独立的单个程序，该程序在内部构建指定的测试套件，按描述执行计算，并以指定格式精确打印一行输出。不允许任何外部输入。",
            "solution": "该问题要求分析吉洪诺夫正则化解及其在正则化算子零空间上的行为。对每个测试用例，求解过程分为三个主要的理论步骤：首先，求出吉洪诺夫正则化解 $x_{\\lambda}$；其次，构建到正则化算子 $L$ 的零空间上的正交投影算子；第三，计算指定的范数。\n\n第 1 步：推导吉洪诺夫正则化解 $x_{\\lambda}$\n\n吉洪诺夫正则化解 $x_{\\lambda}$ 被定义为泛函的唯一极小化子：\n$$J_{\\lambda}(x) = \\lVert A x - b \\rVert_{2}^{2} + \\lambda^{2} \\lVert L x \\rVert_{2}^{2}$$\n其中 $A \\in \\mathbb{R}^{n \\times n}$，$L \\in \\mathbb{R}^{p \\times n}$，$b \\in \\mathbb{R}^{n}$，且 $\\lambda \\ge 0$。欧几里得范数的平方可以用向量转置表示：\n$$J_{\\lambda}(x) = (A x - b)^{\\top}(A x - b) + \\lambda^{2} (L x)^{\\top}(L x)$$\n展开此表达式得到一个关于 $x$ 的二次函数：\n$$J_{\\lambda}(x) = x^{\\top}A^{\\top}A x - x^{\\top}A^{\\top}b - b^{\\top}A x + b^{\\top}b + \\lambda^{2} x^{\\top}L^{\\top}L x$$\n由于 $b^{\\top}A x$ 是一个标量，它等于其转置 $x^{\\top}A^{\\top}b$。因此，该泛函可化简为：\n$$J_{\\lambda}(x) = x^{\\top}(A^{\\top}A + \\lambda^{2} L^{\\top}L)x - 2 b^{\\top}A x + b^{\\top}b$$\n为求得极小化子，我们计算 $J_{\\lambda}(x)$ 关于 $x$ 的梯度并将其设为零向量。梯度为：\n$$\\nabla_x J_{\\lambda}(x) = 2(A^{\\top}A + \\lambda^{2} L^{\\top}L)x - 2 A^{\\top}b$$\n令 $\\nabla_x J_{\\lambda}(x) = 0$ 可得到吉洪诺夫正规方程：\n$$(A^{\\top}A + \\lambda^{2} L^{\\top}L) x_{\\lambda} = A^{\\top}b$$\n矩阵 $H_{\\lambda} = A^{\\top}A + \\lambda^{2} L^{\\top}L$ 是该泛函的海森矩阵。由于 $A^{\\top}A$ 和 $L^{\\top}L$ 都是半正定的，因此 $H_{\\lambda}$ 也是半正定的。对于所有给定的测试用例，矩阵 $A$ 都是可逆的，这意味着 $A^{\\top}A$ 是正定的。因此，$H_{\\lambda}$ 是一个正定矩阵与一个半正定矩阵之和，这使得 $H_{\\lambda}$ 对所有 $\\lambda \\ge 0$ 都是正定的。这保证了唯一解 $x_{\\lambda}$ 的存在，该解可通过求解以下线性系统得到：\n$$x_{\\lambda} = (A^{\\top}A + \\lambda^{2} L^{\\top}L)^{-1} A^{\\top}b$$\n对每个测试用例，我们通过分别对 $\\lambda = \\lambda_1$ 和 $\\lambda = \\lambda_2$ 应用此公式来计算解 $x_{\\lambda_{1}}$ 和 $x_{\\lambda_{2}}$。\n\n第 2 步：构建投影算子 $P_{\\mathcal{N}}$\n\n问题要求构建到 $L$ 的零空间（记作 $\\mathcal{N}(L)$）上的正交投影算子 $P_{\\mathcal{N}}$。指定的公式是：\n$$P_{\\mathcal{N}} = I - L^{+}L$$\n其中 $L^{+}$ 是 $L$ 的 Moore-Penrose 伪逆，$I$ 是单位矩阵。此公式源于伪逆的性质。矩阵乘积 $L^{+}L$ 是到 $L$ 的行空间（记作 $\\mathcal{R}(L^{\\top})$）上的正交投影算子。在有限维实向量空间中，行空间和零空间是正交补：$\\mathcal{R}(L^{\\top}) = \\mathcal{N}(L)^{\\perp}$。因此，$P_{\\mathcal{R}(L^{\\top})} = L^{+}L$。到互补子空间 $\\mathcal{N}(L)$ 上的投影算子由 $I - P_{\\mathcal{R}(L^{\\top})}$ 给出，这直接导出了所提供的公式。\n\n第 3 步：计算零空间分量的变化\n\n最后一步是计算量 $r = \\lVert P_{\\mathcal{N}} (x_{\\lambda_{2}} - x_{\\lambda_{1}}) \\rVert_{2}$。该值衡量了当正则化参数从 $\\lambda_1$ 变为 $\\lambda_2$ 时，解在 $L$ 的零空间内的分量变化的幅度。\n\n这个量的行为取决于由算子 $A$ 引起的子空间 $\\mathcal{N}(L)$ 与其正交补 $\\mathcal{N}(L)^{\\perp}$ 之间的耦合。\n- 如果 $A$ 相对于正交分解 $\\mathbb{R}^{n} = \\mathcal{N}(L)^{\\perp} \\oplus \\mathcal{N}(L)$ 是块对角的，则最小化问题解耦。正则化参数 $\\lambda$ 只影响 $x$ 在 $\\mathcal{N}(L)^{\\perp}$ 中的分量。$x$ 在 $\\mathcal{N}(L)$ 中的分量是独立于 $\\lambda$ 确定的。因此，$P_{\\mathcal{N}}x_{\\lambda_1} = P_{\\mathcal{N}}x_{\\lambda_2}$，结果为 $r=0$。测试用例 1 和 2 证明了这一点。\n- 如果 $A$ 不是块对角的（即它耦合了这两个子空间），那么改变 $\\lambda$ 会改变 $\\mathcal{N}(L)^{\\perp}$ 中的最优分量，而这种变化会传播到 $\\mathcal{N}(L)$ 中的分量，以保持 $J_{\\lambda}(x)$ 的全局最小值。在这种情况下，$P_{\\mathcal{N}}x_{\\lambda}$ 将依赖于 $\\lambda$，从而导致非零结果 $r  0$。测试用例 3 旨在说明这种耦合。\n- 对于 $L=0$ 的退化情况，$\\mathcal{N}(L)=\\mathbb{R}^n$，正则化项 $\\lambda^2 \\lVert Lx \\rVert^2$ 恒为零。解 $x_\\lambda$ 与 $\\lambda$ 无关，导致 $r=0$。测试用例 4 证实了这一点。\n\n每个测试用例的算法如下：\n1.  构建矩阵 $A$、$L$ 和向量 $b$。\n2.  计算 $A^\\top A$、$L^\\top L$ 和 $A^\\top b$。\n3.  对 $\\lambda_1$ 和 $\\lambda_2$，求解各自的正规方程以求得 $x_{\\lambda_1}$ 和 $x_{\\lambda_2}$。\n4.  使用 $L$ 的 Moore-Penrose 伪逆计算投影算子 $P_{\\mathcal{N}} = I - L^{+}L$。\n5.  计算差分向量 $\\Delta x = x_{\\lambda_2} - x_{\\lambda_1}$。\n6.  将差分向量投影到零空间上：$v = P_{\\mathcal{N}} \\Delta x$。\n7.  计算并记录欧几里得范数 $r = \\lVert v \\rVert_2$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Tikhonov regularization problem for a suite of test cases.\n\n    For each case (A, L, b, lambda1, lambda2), it computes:\n    1. The Tikhonov solutions x_lambda1 and x_lambda2.\n    2. The orthogonal projector P_N onto the nullspace of L.\n    3. The norm ||P_N * (x_lambda2 - x_lambda1)||_2.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Test case 1 (decoupled, moderate change in lambda)\n    A1 = np.diag([1.0, 2.0, 3.0, 4.0])\n    L1 = np.diag([1.0, 1.0, 0.0, 0.0])\n    b1 = np.array([1.0, -2.0, 3.0, -4.0])\n    lambda1_1, lambda1_2 = 0.0, 0.1\n\n    # Test case 2 (decoupled, extreme change in lambda)\n    A2 = np.diag([1.0, 2.0, 3.0, 4.0])\n    L2 = np.diag([1.0, 1.0, 0.0, 0.0])\n    b2 = np.array([1.0, -2.0, 3.0, -4.0])\n    lambda2_1, lambda2_2 = 0.0, 1000.0\n\n    # Test case 3 (coupled, demonstrating leakage into N(L))\n    A3 = np.array([[1.0, 0.0, 0.5, 0.0],\n                   [0.0, 2.0, 0.0, 0.0],\n                   [0.0, 0.0, 3.0, 0.0],\n                   [0.0, 0.0, 0.0, 4.0]])\n    L3 = np.diag([1.0, 1.0, 0.0, 0.0])\n    b3 = np.array([1.0, -2.0, 3.0, -4.0])\n    lambda3_1, lambda3_2 = 0.0, 10.0\n\n    # Test case 4 (degenerate low-rank, no regularization at all)\n    A4 = np.diag([1.0, 2.0, 3.0, 4.0])\n    L4 = np.zeros((4, 4))\n    b4 = np.array([1.0, -2.0, 3.0, -4.0])\n    lambda4_1, lambda4_2 = 0.0, 5.0\n\n    test_cases = [\n        (A1, L1, b1, lambda1_1, lambda1_2),\n        (A2, L2, b2, lambda2_1, lambda2_2),\n        (A3, L3, b3, lambda3_1, lambda3_2),\n        (A4, L4, b4, lambda4_1, lambda4_2)\n    ]\n\n    results = []\n    for A, L, b, lam1, lam2 in test_cases:\n        # Pre-compute matrix products for efficiency\n        AT = A.T\n        LT = L.T\n        ATA = AT @ A\n        LTL = LT @ L\n        ATb = AT @ b\n        \n        # --- Solve for x_lambda1 ---\n        # Form the matrix for the normal equations: (A^T A + lambda^2 L^T L)\n        M1 = ATA + (lam1**2) * LTL\n        # Solve the system M1 * x = ATb\n        x_lam1 = np.linalg.solve(M1, ATb)\n\n        # --- Solve for x_lambda2 ---\n        M2 = ATA + (lam2**2) * LTL\n        x_lam2 = np.linalg.solve(M2, ATb)\n        \n        # --- Compute projector onto the nullspace of L ---\n        # P_N = I - L^+ L\n        n = A.shape[0]\n        I = np.identity(n)\n        # np.linalg.pinv computes the Moore-Penrose pseudoinverse L^+\n        L_pinv = np.linalg.pinv(L)\n        P_N = I - L_pinv @ L\n        \n        # --- Final calculation ---\n        # Compute the change in the solution vector\n        delta_x = x_lam2 - x_lam1\n        # Project the change onto the nullspace of L\n        proj_delta_x = P_N @ delta_x\n        # Compute the Euclidean norm of the projected change\n        result = np.linalg.norm(proj_delta_x)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Using a format specifier for consistent floating point output.\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}