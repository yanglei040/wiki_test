{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides a foundational, hands-on opportunity to see Weyl's inequalities in action. By explicitly calculating the eigenvalues for a pair of simple $2 \\times 2$ symmetric matrices and their sum, you will be able to verify each of the applicable inequalities. This practice is designed to ground the abstract theory in concrete numerical results and build confidence in applying the eigenvalue bounds. ",
            "id": "3601579",
            "problem": "Let $A=\\begin{pmatrix}2&1\\\\1&0\\end{pmatrix}$ and $B=\\begin{pmatrix}1&-1\\\\-1&3\\end{pmatrix}$ be real symmetric matrices. Using only foundational results for real symmetric matrices, namely the spectral theorem and the Courant–Fischer (Rayleigh–Ritz) variational characterization of eigenvalues, do the following:\n\n- Compute the ordered eigenvalues $\\lambda_{1}(A)\\geq \\lambda_{2}(A)$, $\\lambda_{1}(B)\\geq \\lambda_{2}(B)$, and $\\lambda_{1}(A+B)\\geq \\lambda_{2}(A+B)$ exactly.\n\n- Using the standard ordering of eigenvalues and the statement of Weyl’s inequalities for sums of Hermitian matrices specialized to the real symmetric case, enumerate all admissible inequalities for the case $n=2$ relating $\\lambda_{k}(A+B)$ to $\\lambda_{i}(A)$ and $\\lambda_{j}(B)$, and verify each inequality numerically by direct substitution of the computed eigenvalues.\n\nDefine the slack of an inequality of the form $x\\leq y$ as $y-x$, and the slack of an inequality of the form $x\\geq y$ as $x-y$. Let $s_{1},\\dots,s_{m}$ be the slacks of all admissible Weyl inequalities in this $n=2$ setting (counting both upper and lower bounds that apply). Compute the sum of squares $S=\\sum_{\\ell=1}^{m} s_{\\ell}^{2}$. Express the final value of $S$ in exact form with no rounding.",
            "solution": "The problem is well-defined, mathematically sound, and self-contained. It is based on established principles of linear algebra, specifically the properties of real symmetric matrices and Weyl's inequalities for their eigenvalues. The problem is valid and a solution can be constructed.\n\nThe problem asks for several interconnected calculations involving two $2 \\times 2$ real symmetric matrices, $A$ and $B$. The steps are:\n1.  Compute the eigenvalues of $A$, $B$, and their sum $A+B$.\n2.  Enumerate all applicable Weyl's inequalities for the $n=2$ case.\n3.  Verify these inequalities with the computed eigenvalues.\n4.  Calculate the slack for each inequality.\n5.  Compute the sum of the squares of these slacks.\n\nLet the given matrices be\n$$ A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 1 & -1 \\\\ -1 & 3 \\end{pmatrix} $$\nBoth are real symmetric matrices. Their eigenvalues are real, as guaranteed by the spectral theorem.\n\nFirst, we compute the eigenvalues of $A$. The characteristic equation is $\\det(A - \\lambda I) = 0$.\n$$ \\det \\begin{pmatrix} 2-\\lambda & 1 \\\\ 1 & -\\lambda \\end{pmatrix} = (2-\\lambda)(-\\lambda) - (1)(1) = -2\\lambda + \\lambda^2 - 1 = 0 $$\nThe characteristic polynomial is $\\lambda^2 - 2\\lambda - 1 = 0$. Using the quadratic formula, the eigenvalues are:\n$$ \\lambda = \\frac{-(-2) \\pm \\sqrt{(-2)^2 - 4(1)(-1)}}{2(1)} = \\frac{2 \\pm \\sqrt{4+4}}{2} = \\frac{2 \\pm \\sqrt{8}}{2} = \\frac{2 \\pm 2\\sqrt{2}}{2} = 1 \\pm \\sqrt{2} $$\nThe eigenvalues of $A$, ordered in descending order $\\lambda_1(A) \\geq \\lambda_2(A)$, are:\n$$ \\lambda_1(A) = 1 + \\sqrt{2} $$\n$$ \\lambda_2(A) = 1 - \\sqrt{2} $$\n\nNext, we compute the eigenvalues of $B$. The characteristic equation is $\\det(B - \\lambda I) = 0$.\n$$ \\det \\begin{pmatrix} 1-\\lambda & -1 \\\\ -1 & 3-\\lambda \\end{pmatrix} = (1-\\lambda)(3-\\lambda) - (-1)(-1) = 3 - 4\\lambda + \\lambda^2 - 1 = 0 $$\nThe characteristic polynomial is $\\lambda^2 - 4\\lambda + 2 = 0$. The eigenvalues are:\n$$ \\lambda = \\frac{-(-4) \\pm \\sqrt{(-4)^2 - 4(1)(2)}}{2(1)} = \\frac{4 \\pm \\sqrt{16-8}}{2} = \\frac{4 \\pm \\sqrt{8}}{2} = \\frac{4 \\pm 2\\sqrt{2}}{2} = 2 \\pm \\sqrt{2} $$\nThe ordered eigenvalues of $B$, $\\lambda_1(B) \\geq \\lambda_2(B)$, are:\n$$ \\lambda_1(B) = 2 + \\sqrt{2} $$\n$$ \\lambda_2(B) = 2 - \\sqrt{2} $$\n\nNow, we compute the matrix sum $A+B$ and its eigenvalues.\n$$ C = A+B = \\begin{pmatrix} 2 & 1 \\\\ 1 & 0 \\end{pmatrix} + \\begin{pmatrix} 1 & -1 \\\\ -1 & 3 \\end{pmatrix} = \\begin{pmatrix} 3 & 0 \\\\ 0 & 3 \\end{pmatrix} $$\nThe resulting matrix $C=A+B$ is a diagonal matrix, $3I$, where $I$ is the $2 \\times 2$ identity matrix. Its eigenvalues are the diagonal entries.\nThe ordered eigenvalues of $A+B$, $\\lambda_1(A+B) \\geq \\lambda_2(A+B)$, are:\n$$ \\lambda_1(A+B) = 3 $$\n$$ \\lambda_2(A+B) = 3 $$\n\nThe problem asks to enumerate and verify Weyl's inequalities for sums of symmetric matrices. For $n \\times n$ real symmetric matrices $A$ and $B$, these inequalities relate the eigenvalues of $A+B$ to the eigenvalues of $A$ and $B$. Let the eigenvalues be ordered decreasingly. The complete set of inequalities for $n=2$ relating $\\lambda_k(A+B)$ to sums of individual eigenvalues $\\lambda_i(A)$ and $\\lambda_j(B)$ are:\n1.  $\\lambda_1(A+B) \\leq \\lambda_1(A) + \\lambda_1(B)$\n2.  $\\lambda_1(A+B) \\geq \\lambda_1(A) + \\lambda_2(B)$\n3.  $\\lambda_1(A+B) \\geq \\lambda_2(A) + \\lambda_1(B)$\n4.  $\\lambda_2(A+B) \\leq \\lambda_1(A) + \\lambda_2(B)$\n5.  $\\lambda_2(A+B) \\leq \\lambda_2(A) + \\lambda_1(B)$\n6.  $\\lambda_2(A+B) \\geq \\lambda_2(A) + \\lambda_2(B)$\n\nWe now verify each of these $m=6$ inequalities and compute the corresponding slack $s_\\ell$. The slack for $x \\leq y$ is $y-x$, and for $x \\geq y$ is $x-y$.\n\n1.  $\\lambda_1(A+B) \\leq \\lambda_1(A) + \\lambda_1(B)$\n    $3 \\leq (1+\\sqrt{2}) + (2+\\sqrt{2})$\n    $3 \\leq 3 + 2\\sqrt{2}$. This is true, as $2\\sqrt{2} > 0$.\n    Slack $s_1 = (\\lambda_1(A) + \\lambda_1(B)) - \\lambda_1(A+B) = (3+2\\sqrt{2}) - 3 = 2\\sqrt{2}$.\n\n2.  $\\lambda_1(A+B) \\geq \\lambda_1(A) + \\lambda_2(B)$\n    $3 \\geq (1+\\sqrt{2}) + (2-\\sqrt{2})$\n    $3 \\geq 3$. This is true (the inequality is sharp).\n    Slack $s_2 = \\lambda_1(A+B) - (\\lambda_1(A) + \\lambda_2(B)) = 3 - 3 = 0$.\n\n3.  $\\lambda_1(A+B) \\geq \\lambda_2(A) + \\lambda_1(B)$\n    $3 \\geq (1-\\sqrt{2}) + (2+\\sqrt{2})$\n    $3 \\geq 3$. This is true (the inequality is sharp).\n    Slack $s_3 = \\lambda_1(A+B) - (\\lambda_2(A) + \\lambda_1(B)) = 3 - 3 = 0$.\n\n4.  $\\lambda_2(A+B) \\leq \\lambda_1(A) + \\lambda_2(B)$\n    $3 \\leq (1+\\sqrt{2}) + (2-\\sqrt{2})$\n    $3 \\leq 3$. This is true (the inequality is sharp).\n    Slack $s_4 = (\\lambda_1(A) + \\lambda_2(B)) - \\lambda_2(A+B) = 3 - 3 = 0$.\n\n5.  $\\lambda_2(A+B) \\leq \\lambda_2(A) + \\lambda_1(B)$\n    $3 \\leq (1-\\sqrt{2}) + (2+\\sqrt{2})$\n    $3 \\leq 3$. This is true (the inequality is sharp).\n    Slack $s_5 = (\\lambda_2(A) + \\lambda_1(B)) - \\lambda_2(A+B) = 3 - 3 = 0$.\n\n6.  $\\lambda_2(A+B) \\geq \\lambda_2(A) + \\lambda_2(B)$\n    $3 \\geq (1-\\sqrt{2}) + (2-\\sqrt{2})$\n    $3 \\geq 3 - 2\\sqrt{2}$. This is true, as $2\\sqrt{2} > 0$.\n    Slack $s_6 = \\lambda_2(A+B) - (\\lambda_2(A) + \\lambda_2(B)) = 3 - (3-2\\sqrt{2}) = 2\\sqrt{2}$.\n\nFinally, we compute the sum of squares $S = \\sum_{\\ell=1}^{6} s_{\\ell}^{2}$.\nThe slacks are $s_1 = 2\\sqrt{2}$, $s_2=0$, $s_3=0$, $s_4=0$, $s_5=0$, and $s_6 = 2\\sqrt{2}$.\n$$ S = s_1^2 + s_2^2 + s_3^2 + s_4^2 + s_5^2 + s_6^2 $$\n$$ S = (2\\sqrt{2})^2 + 0^2 + 0^2 + 0^2 + 0^2 + (2\\sqrt{2})^2 $$\n$$ S = (4 \\times 2) + 0 + 0 + 0 + 0 + (4 \\times 2) = 8 + 8 = 16 $$\nThe sum of squares of the slacks is $16$.",
            "answer": "$$\n\\boxed{16}\n$$"
        },
        {
            "introduction": "Building on direct verification, this next practice explores a special case where Weyl's bounds become perfectly sharp. By analyzing a perturbation in the form of a scalar matrix, $B = \\beta I$, you will uncover the conditions that lead to equality across the entire spectrum. This exercise  connects the inequalities to the fundamental concept of commuting matrices and provides a clear illustration of how a simple shift of a matrix results in a corresponding shift of its eigenvalues.",
            "id": "3601566",
            "problem": "Let $A \\in \\mathbb{R}^{n \\times n}$ be a symmetric matrix with real eigenvalues ordered as $\\lambda_{1}(A) \\geq \\lambda_{2}(A) \\geq \\cdots \\geq \\lambda_{n}(A)$ and corresponding orthogonal eigenspaces. Consider the Rayleigh quotient $R_{M}(x) = \\frac{x^{\\top} M x}{x^{\\top} x}$ and the Courant–Fischer min–max characterization of the eigenvalues of a symmetric matrix, which states that for each $k \\in \\{1,\\dots,n\\}$,\n$$\n\\lambda_{k}(M) = \\min_{\\dim(\\mathcal{S}) = n - k + 1} \\max_{\\substack{x \\in \\mathcal{S} \\\\ x \\neq 0}} R_{M}(x) = \\max_{\\dim(\\mathcal{U}) = k} \\min_{\\substack{x \\in \\mathcal{U} \\\\ x \\neq 0}} R_{M}(x).\n$$\nUsing only this variational characterization and basic properties of symmetric matrices and orthogonal decompositions, analyze how repeated eigenvalues (eigenvalue multiplicity) influence the sharpness of eigenvalue bounds under additive perturbations. In particular, reason about why a perturbation with a maximally degenerate spectrum can cause the extremal variational envelopes for all indices to coincide, thereby enabling multiple equalities to hold simultaneously in the family of eigenvalue bounds associated with additive perturbations.\n\nThen, construct such a maximally degenerate perturbation explicitly and apply your reasoning to the following concrete instance. Let $n = 6$ and suppose $A$ has ordered spectrum\n$$\n\\lambda_{1}(A) = 7,\\quad \\lambda_{2}(A) = 7,\\quad \\lambda_{3}(A) = 4,\\quad \\lambda_{4}(A) = 0,\\quad \\lambda_{5}(A) = 0,\\quad \\lambda_{6}(A) = -3.\n$$\nLet $B = \\beta I$ with $\\beta = 5$, where $I$ is the $6 \\times 6$ identity matrix. Determine the exact value of $\\lambda_{4}(A+B)$. No rounding is necessary. Express your final answer as a single real number.",
            "solution": "The problem is first validated to be a well-posed and scientifically sound question in the field of numerical linear algebra. It is complete, consistent, and requires a rigorous application of fundamental principles.\n\nThe problem asks for an analysis of how eigenvalue multiplicity and a specific type of perturbation interact, and then for a concrete calculation. We will first provide the general reasoning and then apply it to the specific case.\n\nLet $A$ and $B$ be two $n \\times n$ real symmetric matrices. Let their eigenvalues, and those of their sum $A+B$, be ordered in descending order: $\\lambda_{1}(\\cdot) \\geq \\lambda_{2}(\\cdot) \\geq \\cdots \\geq \\lambda_{n}(\\cdot)$. The Courant–Fischer theorem provides a variational characterization for these eigenvalues. One of the fundamental results that can be derived from this theorem is the set of Weyl's inequalities, which bound the eigenvalues of the sum $A+B$. For any index $k \\in \\{1, \\dots, n\\}$, these inequalities state:\n$$\n\\lambda_{k}(A) + \\lambda_{n}(B) \\leq \\lambda_{k}(A+B) \\leq \\lambda_{k}(A) + \\lambda_{1}(B)\n$$\nThe \"sharpness\" of these bounds refers to the conditions under which one or both of the inequalities become equalities.\n\nEquality is achieved under specific conditions relating the eigenspaces of $A$ and $B$. A sufficient condition for $\\lambda_k(A+B)$ to be a simple sum of eigenvalues is that $A$ and $B$ commute, i.e., $AB = BA$. In this case, they are simultaneously diagonalizable, meaning there exists a single orthonormal basis of eigenvectors $\\{v_i\\}_{i=1}^n$ for both matrices. If $Av_i = \\lambda_i(A) v_i$ and $Bv_i = \\lambda_{\\pi(i)}(B) v_i$ for some permutation $\\pi$, then $(A+B)v_i = (\\lambda_i(A) + \\lambda_{\\pi(i)}(B))v_i$. The eigenvalues of $A+B$ are sums of eigenvalues of $A$ and $B$.\n\nThe problem asks us to consider a \"maximally degenerate perturbation\". This corresponds to a matrix $B$ whose eigenvalues are all identical. Such a matrix must be of the form $B = \\beta I$ for some scalar $\\beta \\in \\mathbb{R}$, where $I$ is the $n \\times n$ identity matrix. For this matrix $B$, all its eigenvalues are equal: $\\lambda_{1}(B) = \\lambda_{2}(B) = \\cdots = \\lambda_{n}(B) = \\beta$. Its eigenspace corresponding to the eigenvalue $\\beta$ is the entire space $\\mathbb{R}^n$.\n\nThis choice of $B$ has profound consequences for Weyl's inequalities. Substituting $\\lambda_{1}(B) = \\beta$ and $\\lambda_{n}(B) = \\beta$ into the inequalities, we get for each $k \\in \\{1, \\dots, n\\}$:\n$$\n\\lambda_{k}(A) + \\beta \\leq \\lambda_{k}(A+B) \\leq \\lambda_{k}(A) + \\beta\n$$\nThis pair of inequalities forces an equality for every index $k$:\n$$\n\\lambda_{k}(A+B) = \\lambda_{k}(A) + \\beta\n$$\nThis means that for the special perturbation $B = \\beta I$, the bounds are maximally sharp for all eigenvalues simultaneously. The entire spectrum of $A$ is simply shifted by the constant $\\beta$.\n\nThe reason this occurs can be understood through the shared eigenspace structure. The perturbation $B = \\beta I$ commutes with any matrix $A$, since $A(\\beta I) = \\beta A = (\\beta I)A$. Thus, $A$ and $B$ are simultaneously diagonalizable. Let $\\{v_k\\}_{k=1}^n$ be any orthonormal basis of eigenvectors for $A$, such that $Av_k = \\lambda_k(A) v_k$. Note that the presence of repeated eigenvalues in $A$ means some eigenspaces have dimension greater than $1$, but we can always construct such an orthonormal basis. Since every non-zero vector is an eigenvector of $B = \\beta I$ with eigenvalue $\\beta$, it follows that $Bv_k = \\beta v_k$.\nApplying the sum $A+B$ to these eigenvectors, we find:\n$$\n(A+B)v_k = Av_k + Bv_k = \\lambda_k(A) v_k + \\beta v_k = (\\lambda_k(A) + \\beta) v_k\n$$\nThis demonstrates that each eigenvector $v_k$ of $A$ is also an eigenvector of $A+B$, with the corresponding eigenvalue simply shifted by $\\beta$. The set of eigenvalues of $A+B$ is therefore $\\{\\lambda_k(A)+\\beta\\}_{k=1}^n$. Since the ordering is preserved by adding a constant, we have confirmed that $\\lambda_k(A+B) = \\lambda_k(A) + \\beta$ for all $k$.\n\nFrom the perspective of the Rayleigh quotient, the effect is also clear. The Rayleigh quotient for $A+B$ is:\n$$\nR_{A+B}(x) = \\frac{x^{\\top}(A+B)x}{x^{\\top}x} = \\frac{x^{\\top}Ax + x^{\\top}(\\beta I)x}{x^{\\top}x} = \\frac{x^{\\top}Ax}{x^{\\top}x} + \\frac{\\beta x^{\\top}x}{x^{\\top}x} = R_A(x) + \\beta\n$$\nThe entire \"variational landscape\" defined by the Rayleigh quotient is simply shifted vertically by a constant $\\beta$. Therefore, the min-max and max-min values given by the Courant–Fischer theorem are also shifted by $\\beta$, meaning $\\lambda_k(A+B) = \\lambda_k(A) + \\beta$.\n\nNow, we apply this reasoning to the concrete instance provided.\nWe are given $n=6$. The matrix $A$ has the ordered spectrum:\n$$\n\\lambda_{1}(A) = 7, \\quad \\lambda_{2}(A) = 7, \\quad \\lambda_{3}(A) = 4, \\quad \\lambda_{4}(A) = 0, \\quad \\lambda_{5}(A) = 0, \\quad \\lambda_{6}(A) = -3\n$$\nThe perturbation matrix is $B = \\beta I$ with $\\beta = 5$. So, $B = 5I$.\nBased on the derivation above, the eigenvalues of the perturbed matrix $A+B$ are given by $\\lambda_k(A+B) = \\lambda_k(A) + 5$ for $k=1, \\dots, 6$.\nThe ordered spectrum of $A+B$ is therefore:\n$\\lambda_{1}(A+B) = \\lambda_{1}(A) + 5 = 7 + 5 = 12$\n$\\lambda_{2}(A+B) = \\lambda_{2}(A) + 5 = 7 + 5 = 12$\n$\\lambda_{3}(A+B) = \\lambda_{3}(A) + 5 = 4 + 5 = 9$\n$\\lambda_{4}(A+B) = \\lambda_{4}(A) + 5 = 0 + 5 = 5$\n$\\lambda_{5}(A+B) = \\lambda_{5}(A) + 5 = 0 + 5 = 5$\n$\\lambda_{6}(A+B) = \\lambda_{6}(A) + 5 = -3 + 5 = 2$\n\nThe problem asks for the exact value of $\\lambda_{4}(A+B)$. From the ordered list of eigenvalues for $A+B$, the fourth eigenvalue is $5$. The presence of repeated eigenvalues in the original matrix $A$ (at $7$ and $0$) does not alter this simple additive relationship because the perturbation $B=5I$ acts uniformly across all eigenspaces.\nThus, the value of $\\lambda_4(A+B)$ is $5$.",
            "answer": "$$\\boxed{5}$$"
        },
        {
            "introduction": "In contrast to the previous exercise where bounds were sharp, this final practice demonstrates a scenario where Weyl's inequalities can be quite loose. You will analyze a specific lower bound for a matrix perturbed by a rank-one matrix with a large negative eigenvalue. This thought experiment  is crucial for developing an intuition for why these powerful bounds, while always true, are not always tight, highlighting the role of eigenvector alignment.",
            "id": "3601618",
            "problem": "Let $A \\in \\mathbb{R}^{10 \\times 10}$ and $B \\in \\mathbb{R}^{10 \\times 10}$ be real symmetric matrices. Throughout, order eigenvalues of any real symmetric matrix $M$ in nonincreasing order as $\\lambda_{1}(M) \\geq \\lambda_{2}(M) \\geq \\cdots \\geq \\lambda_{10}(M)$. Consider the explicit choices\n$$\nA = \\operatorname{diag}(10,9,8,7,6,5,4,3,2,1),\n\\quad\nB = -100\\, e_{10} e_{10}^{\\top},\n$$\nwhere $e_{10} \\in \\mathbb{R}^{10}$ is the standard basis vector with a $1$ in the tenth position and zeros elsewhere. Note that $B$ is negative semidefinite and $\\lambda_{10}(B) = -100$.\n\nUsing only fundamental principles (in particular, the Courant–Fischer min–max characterization of eigenvalues and basic properties of Rayleigh quotients), derive a general lower bound for $\\lambda_{5}(A+B)$ that depends solely on the eigenvalues of $A$ and $B$, and then evaluate that bound numerically for the given $A$ and $B$. Finally, compare the bound to $\\lambda_{5}(A)$ to explain why the lower bound can lie far below a mid-spectrum eigenvalue of $A$, but report only the numerical value of the derived lower bound as your final answer. No rounding is required.",
            "solution": "The problem is to derive a general lower bound for $\\lambda_{k}(A+B)$ for symmetric matrices $A$ and $B$, evaluate it for $k=5$ with specific matrices $A$ and $B$, and explain its behavior. The derivation must use the Courant-Fischer min-max theorem and properties of the Rayleigh quotient.\n\nFirst, we derive the general lower bound. Let $A$ and $B$ be $n \\times n$ real symmetric matrices. Their eigenvalues are ordered non-increasingly: $\\lambda_1(M) \\ge \\lambda_2(M) \\ge \\dots \\ge \\lambda_n(M)$.\n\nThe Courant-Fischer min-max theorem states that for any $n \\times n$ symmetric matrix $M$, its $k$-th eigenvalue is given by:\n$$\n\\lambda_k(M) = \\max_{\\mathcal{S}_k} \\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} x^\\top M x\n$$\nwhere the maximum is taken over all $k$-dimensional subspaces $\\mathcal{S}_k$ of $\\mathbb{R}^n$. The term $R_M(x) = x^\\top M x$ for a unit vector $x$ is the Rayleigh quotient.\n\nWe apply this theorem to the matrix sum $A+B$:\n$$\n\\lambda_k(A+B) = \\max_{\\mathcal{S}_k} \\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} x^\\top(A+B)x\n$$\nThe Rayleigh quotient of the sum can be separated:\n$$\n\\lambda_k(A+B) = \\max_{\\mathcal{S}_k} \\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} (x^\\top A x + x^\\top B x)\n$$\nFor any unit vector $x \\in \\mathbb{R}^n$, the Rayleigh quotient of $B$ is bounded below by the smallest eigenvalue of $B$, $\\lambda_n(B)$. That is, $x^\\top B x \\ge \\lambda_n(B)$. This fundamental property of the Rayleigh quotient allows us to establish a lower bound on the expression inside the minimum:\n$$\nx^\\top A x + x^\\top B x \\ge x^\\top A x + \\lambda_n(B)\n$$\nThis inequality holds for any unit vector $x$. Therefore, for any given $k$-dimensional subspace $\\mathcal{S}_k$, it must also hold for the minimum value over all unit vectors in that subspace:\n$$\n\\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} (x^\\top A x + x^\\top B x) \\ge \\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} (x^\\top A x + \\lambda_n(B))\n$$\nSince $\\lambda_n(B)$ is a scalar constant with respect to the minimization over $x$, it can be separated:\n$$\n\\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} (x^\\top A x + \\lambda_n(B)) = \\left(\\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} x^\\top A x\\right) + \\lambda_n(B)\n$$\nThis gives us the inequality for any subspace $\\mathcal{S}_k$:\n$$\n\\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} x^\\top(A+B)x \\ge \\left(\\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} x^\\top A x\\right) + \\lambda_n(B)\n$$\nTo find $\\lambda_k(A+B)$, we must take the maximum of the left-hand side over all $k$-dimensional subspaces $\\mathcal{S}_k$. The inequality must be preserved after taking this maximum:\n$$\n\\max_{\\mathcal{S}_k} \\left( \\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} x^\\top(A+B)x \\right) \\ge \\max_{\\mathcal{S}_k} \\left( \\left(\\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} x^\\top A x\\right) + \\lambda_n(B) \\right)\n$$\nThe left side is by definition $\\lambda_k(A+B)$. On the right side, since $\\lambda_n(B)$ is a constant, we can take it out of the maximization:\n$$\n\\max_{\\mathcal{S}_k} \\left( \\left(\\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} x^\\top A x\\right) + \\lambda_n(B) \\right) = \\left(\\max_{\\mathcal{S}_k} \\min_{x \\in \\mathcal{S}_k, \\|x\\|_2=1} x^\\top A x\\right) + \\lambda_n(B)\n$$\nThe first term on the right is, by the Courant-Fischer theorem, $\\lambda_k(A)$.\nThus, we arrive at the general lower bound, which is one of Weyl's inequalities:\n$$\n\\lambda_k(A+B) \\ge \\lambda_k(A) + \\lambda_n(B)\n$$\nThis bound depends solely on the eigenvalues of $A$ and $B$, as required.\n\nNext, we evaluate this bound for the specific case given in the problem, where $n=10$ and we are interested in $\\lambda_5(A+B)$. The bound is:\n$$\n\\lambda_5(A+B) \\ge \\lambda_5(A) + \\lambda_{10}(B)\n$$\nThe matrix $A$ is given as $A = \\operatorname{diag}(10,9,8,7,6,5,4,3,2,1)$. For a diagonal matrix, the eigenvalues are its diagonal entries. These are already sorted in non-increasing order. Thus, the eigenvalues of $A$ are $\\lambda_i(A) = 11-i$ for $i=1, \\dots, 10$. For $i=5$, we have $\\lambda_5(A)=6$.\n\nThe matrix $B$ is given as $B = -100\\, e_{10} e_{10}^{\\top}$. The matrix $e_{10} e_{10}^{\\top}$ is a matrix of zeros except for a $1$ in the $(10,10)$ position. So, $B$ is the diagonal matrix $B = \\operatorname{diag}(0,0,0,0,0,0,0,0,0,-100)$. The eigenvalues of $B$ are its diagonal entries. Ordering them non-increasingly gives $\\lambda_1(B) = \\dots = \\lambda_9(B) = 0$ and $\\lambda_{10}(B) = -100$. This is consistent with the problem statement.\n\nWe can now compute the numerical value of the lower bound:\n$$\n\\text{Lower Bound} = \\lambda_5(A) + \\lambda_{10}(B) = 6 + (-100) = -94\n$$\nFinally, we compare this bound to $\\lambda_5(A)=6$. The lower bound of $-94$ is substantially smaller than $\\lambda_5(A)$. This large discrepancy can be explained by the nature of the bound. The derivation replaced the term $x^\\top B x$ with its global minimum value, $\\lambda_{10}(B)$. This represents a \"worst-case\" scenario, where the perturbation from $B$ has the maximum possible negative effect. This worst case would occur if the subspace relevant to computing $\\lambda_5(A+B)$ were to contain the eigenvector corresponding to $\\lambda_{10}(B)$.\n\nIn this specific problem, $A$ and $B$ are both diagonal, so they share the standard basis vectors $\\{e_i\\}_{i=1}^{10}$ as eigenvectors. The eigenvalue $\\lambda_5(A)=6$ corresponds to the eigenvector $e_5$. The crucial part of the spectrum of $A$ for determining $\\lambda_5(A)$ involves the subspace $\\text{span}\\{e_1, \\dots, e_5\\}$. However, the perturbation $B$ is entirely concentrated in the direction of the eigenvector $e_{10}$, which corresponds to its most negative eigenvalue $\\lambda_{10}(B)=-100$. Because the eigenvector $e_{10}$ is orthogonal to the subspace $\\text{span}\\{e_1, \\dots, e_5\\}$, the perturbation has no impact on the Rayleigh quotients of vectors in that subspace. In fact, for this specific problem, $A+B = \\operatorname{diag}(10,9,8,7,6,5,4,3,2,-99)$, and the true value of $\\lambda_5(A+B)$ is $6$, which is equal to $\\lambda_5(A)$. The general bound must hold for any orientation of eigenvectors, and since it is ignorant of the (in this case, orthogonal) relationship between the eigenvectors of $A$ and $B$, it provides a very loose estimate. This example perfectly illustrates why such general eigenvalue bounds, while universally true, can be far from tight for specific matrices.",
            "answer": "$$\\boxed{-94}$$"
        }
    ]
}