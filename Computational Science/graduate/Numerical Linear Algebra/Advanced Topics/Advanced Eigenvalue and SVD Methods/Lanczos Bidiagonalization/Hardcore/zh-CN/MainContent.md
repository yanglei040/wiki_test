## 引言
在现代科学与工程计算中，处理大规模矩阵是司空见惯的挑战。直接求解这些矩阵的[奇异值分解](@entry_id:138057)（SVD）或相关的[线性系统](@entry_id:147850)往往因其巨大的计算和存储开销而变得不可行。Lanczos 双[对角化方法](@entry_id:273007)作为一种高效的迭代投影技术，为解决这一难题提供了关键性的工具，它能够将庞大的问题转化为在小型、结构化的[子空间](@entry_id:150286)上的计算。

本文旨在全面解析 Lanczos 双[对角化方法](@entry_id:273007)，从其深刻的数学原理到广泛的实际应用。通过本文的学习，读者将能够掌握这一强大算法的核心思想与实现细节。
- 在“**原理与机制**”一章中，我们将深入其算法构建的基础，揭示其与克里罗夫[子空间方法](@entry_id:200957)的联系，并探讨有限精度计算带来的挑战。
- 接着，在“**应用与[交叉](@entry_id:147634)学科联系**”一章中，我们将展示该方法如何成为解决大规模 SVD、[线性反问题](@entry_id:751313)以及高级数值诊断任务的基石，并探索其与数值积分等领域的有趣联系。
- 最后，在“**动手实践**”部分，读者将通过一系列精心设计的编程练习，将理论知识转化为解决实际问题的能力，从构建基础算法到处理[数值稳定性](@entry_id:146550)等高级主题。

## 原理与机制

在本章中，我们将深入探讨 Lanczos 双[对角化方法](@entry_id:273007)的数学原理和算法机制。作为一种强大的迭代方法，它通过将一个大规模、稀疏的矩阵投影到一个低维的克里罗夫[子空间](@entry_id:150286)（Krylov subspace），从而为[求解大型线性系统](@entry_id:145591)和特征值问题提供了高效的途径。我们将从其算法构建的基础出发，揭示其与克里罗夫[子空间方法](@entry_id:200957)的深刻联系，阐明其在[奇异值分解](@entry_id:138057)（SVD）和最小二乘问题中的核心应用，并讨论在实际计算中必须考虑的[有限精度效应](@entry_id:193932)。

### Lanczos [双对角化](@entry_id:746789)的算法基础

Lanczos [双对角化](@entry_id:746789)的核心思想是，对于一个给定的 $m \times n$ 实矩阵 $A$，我们希望构建两个[正交向量](@entry_id:142226)序列，$\{u_i\}_{i=1}^k \subset \mathbb{R}^m$ 和 $\{v_i\}_{i=1}^k \subset \mathbb{R}^n$，使得矩阵 $A$ 在这些基上的作用呈现出一种极其简单的结构——具体来说，是双对角结构。这种简化是该方法[计算效率](@entry_id:270255)的关键。

存在两种密切相关的算法变体：一种生成上双对角矩阵，另一种生成下双[对角矩阵](@entry_id:637782)（通常称为 Golub-Kahan [双对角化](@entry_id:746789)）。这里，我们重点介绍生成上双对角矩阵的变体。

该过程是一个迭代算法，通过交替乘以 $A$ 和 $A^\top$ 来生成这两个[正交基](@entry_id:264024)。让我们从一个初始的单位向量 $v_1 \in \mathbb{R}^n$（即 $\|v_1\|_2 = 1$）开始，逐步构建这些序列。整个过程可以精确地描述如下 ：

**Lanczos [双对角化](@entry_id:746789)算法（上双[对角形式](@entry_id:264850)）**

1.  **初始化**:
    选择一个[单位向量](@entry_id:165907) $v_1 \in \mathbb{R}^n$。设置 $u_0 = 0 \in \mathbb{R}^m$，$\beta_1 = 0$。

2.  **迭代**:
    对于 $i = 1, 2, \dots, k$：
    a.  **生成下一个 $u$ 向量**:
        计算未归一化向量 $\hat{u}_i = A v_i - \beta_i u_{i-1}$。
        计算标量 $\alpha_i = \|\hat{u}_i\|_2$。如果 $\alpha_i = 0$，[算法终止](@entry_id:143996)。
        否则，令 $u_i = \hat{u}_i / \alpha_i$。

    b.  **生成下一个 $v$ 向量**:
        计算未归一化向量 $\hat{v}_{i+1} = A^\top u_i - \alpha_i v_i$。
        计算标量 $\beta_{i+1} = \|\hat{v}_{i+1}\|_2$。如果 $\beta_{i+1} = 0$，[算法终止](@entry_id:143996)。
        否则，令 $v_{i+1} = \hat{v}_{i+1} / \beta_{i+1}$。

经过 $k$ 步迭代，我们得到两组[正交向量](@entry_id:142226) $\{u_1, \dots, u_k\}$ 和 $\{v_1, \dots, v_k\}$，它们分别构成了矩阵 $U_k = [u_1, \dots, u_k] \in \mathbb{R}^{m \times k}$ 和 $V_k = [v_1, \dots, v_k] \in \mathbb{R}^{n \times k}$ 的列。

这些步骤中的[递推关系](@entry_id:189264)可以被重新整理为：
$A v_i = \beta_i u_{i-1} + \alpha_i u_i$
$A^\top u_i = \alpha_i v_i + \beta_{i+1} v_{i+1}$

将第一组关系以矩阵形式写出，我们得到一个至关重要的恒等式：
$A V_k = U_k B_k$
这里 $B_k \in \mathbb{R}^{k \times k}$ 是一个上双[对角矩阵](@entry_id:637782)，其主对角[线元](@entry_id:196833)素为 $(\alpha_1, \dots, \alpha_k)$，上对角[线元](@entry_id:196833)素为 $(\beta_2, \dots, \beta_k)$。

$$
B_k = \begin{pmatrix}
\alpha_1 & \beta_2 & & \\
 & \alpha_2 & \ddots & \\
 & & \ddots & \beta_k \\
 & & & \alpha_k
\end{pmatrix}
$$

将第二组关系写成矩阵形式，则得到：
$A^\top U_k = V_k B_k^\top + \beta_{k+1} v_{k+1} e_k^\top$
其中 $e_k$ 是第 $k$ 个[标准基向量](@entry_id:152417)。这些关系式精确地捕捉了矩阵 $A$ 在生成的[子空间](@entry_id:150286)上的作用，将一个可能非常庞大和复杂的矩阵 $A$ 的行为，用一个小型的、结构简单的双对角矩阵 $B_k$ 来近似。

### 与克里罗夫[子空间](@entry_id:150286)及其他方法的联系

Lanczos [双对角化](@entry_id:746789)并非孤立的算法，它与其他数值线性代数中的核心方法有着深刻的联系，尤其是克里罗夫[子空间方法](@entry_id:200957)。

对于一个方阵 $M$ 和一个向量 $r$，由它们生成的 $k$ 阶克里罗夫[子空间](@entry_id:150286)定义为 $\mathcal{K}_k(M, r) = \operatorname{span}\{r, Mr, M^2 r, \dots, M^{k-1} r\}$。尽管 Lanczos [双对角化](@entry_id:746789)直接作用于矩形矩阵 $A$，但它生成的正交基 $U_k$ 和 $V_k$ 实际上是与矩阵 $A A^\top$ 和 $A^\top A$ 相关的克里罗夫[子空间](@entry_id:150286)的正交基。具体而言，可以证明  ：
- 左 Lanczos 向量 $\{u_i\}_{i=1}^k$ 构成了克里罗夫[子空间](@entry_id:150286) $\mathcal{K}_k(A A^\top, u_1)$ 的一个[标准正交基](@entry_id:147779)（其中 $u_1$ 与 $Av_1$ 共线）。
- 右 Lanczos 向量 $\{v_i\}_{i=1}^k$ 构成了克里罗夫[子空间](@entry_id:150286) $\mathcal{K}_k(A^\top A, v_1)$ 的一个[标准正交基](@entry_id:147779)。

这一联系揭示了该方法的本质：它是一种**投影方法**，将原问题投影到由 $A$ 和 $A^\top$ 交替作用生成的[子空间](@entry_id:150286)上。

**与 Householder [双对角化](@entry_id:746789)的对比**

理解 Lanczos [双对角化](@entry_id:746789)的一个有效方式是将其与另一种实现[双对角化](@entry_id:746789)的方法——Householder [双对角化](@entry_id:746789)——进行对比 。
- **方法类型**: Lanczos [双对角化](@entry_id:746789)是一种**迭代方法**，它逐步构建[子空间](@entry_id:150286)和投影。而 Householder [双对角化](@entry_id:746789)是一种**直接方法**，它通过一系列确定性的[正交变换](@entry_id:155650)（Householder 反射）在有限步内将整个矩阵 $A$ 化为双[对角形式](@entry_id:264850)。
- **计算方式**: Lanczos 方法仅依赖于矩阵向量乘积（matvecs），即计算 $Ax$ 和 $A^\top y$ 的能力。这使得它对于[大型稀疏矩阵](@entry_id:144372)尤其高效，因为我们无需存储或修改矩阵 $A$ 本身。相反，Householder 方法需要对矩阵的列和行进行全局修改。
- **对初始向量的依赖**: Lanczos 方法的结果（即生成的[子空间](@entry_id:150286)）完全取决于**初始向量**的选择。不同的初始向量会探索 $A$ 的不同部分，从而影响收敛性。Householder 方法则不依赖于任何外部的初始向量。

**与 Lanczos/Arnoldi 方法的对比**

Lanczos [双对角化](@entry_id:746789)与处理方阵的 Arnoldi 和 Lanczos 算法密切相关  。
- **适用性**: Arnoldi 算法适用于一般方阵，生成一个上海森堡（upper Hessenberg）矩阵；对称 Lanczos 算法是其特例，适用于[对称矩阵](@entry_id:143130)，生成一个[对称三对角矩阵](@entry_id:755732)。Lanczos [双对角化](@entry_id:746789)则巧妙地通过交替作用于两个不同的空间，将这个思想推广到了**任意矩形矩阵**。
- **[递推关系](@entry_id:189264)**: Arnoldi 算法在一般情况下需要**长[递推关系](@entry_id:189264)**（即为了正交化，需要与所有先前生成的[基向量](@entry_id:199546)进行计算），而对称 Lanczos 和 Lanczos [双对角化](@entry_id:746789)都受益于**短[递推关系](@entry_id:189264)**（仅需与前一两个向量相关），这极大地节省了计算和存储成本。
- **[数值稳定性](@entry_id:146550)**: 我们可以通过对 $A^\top A$ 应用对称 Lanczos 算法来计算 $A$ 的[奇异值](@entry_id:152907)的平方。然而，计算 $A^\top A$ 会使矩阵的条件数平方，即 $\kappa(A^\top A) = \kappa(A)^2$。这可能导致数值信息的严重损失，特别是对于小[奇异值](@entry_id:152907)。Lanczos [双对角化](@entry_id:746789)的一大优势在于它直接作用于 $A$ 和 $A^\top$，**避免了显式或隐式地形成 $A^\top A$**，从而获得了更优的数值稳定性  。

事实上，这两种方法在代数上是等价的。由 Lanczos [双对角化](@entry_id:746789)生成的双[对角矩阵](@entry_id:637782) $B_k$ 和对 $A^\top A$ 应用对称 Lanczos 算法生成的[三对角矩阵](@entry_id:138829) $T_k$ 之间存在一个简单而优美的关系：$T_k = B_k^\top B_k$（在初始向量匹配的情况下）。这揭示了 Lanczos [双对角化](@entry_id:746789)可以看作是一种计算 $T_k$ 的“平方根”的、数值上更稳健的方式。

### 核心应用：求解大规模问题

Lanczos [双对角化](@entry_id:746789)的真正威力在于它能够将大规模问题转化为小规模、易于处理的问题。

**[奇异值分解 (SVD)](@entry_id:172448)**

对于大型矩阵 $A$，直接计算其完整的 SVD 是不切实际的。通常我们只关心其最大的若干个[奇异值](@entry_id:152907)及其对应的[奇异向量](@entry_id:143538)。Lanczos [双对角化](@entry_id:746789)为此提供了一个完美的框架 。
经过 $k$ 步后，我们得到了小型双[对角矩阵](@entry_id:637782) $B_k$。我们可以轻松地计算 $B_k$ 的 SVD：$B_k = P_k \Sigma_k Q_k^\top$。$B_k$ 的[奇异值](@entry_id:152907)（即 $\Sigma_k$ 的对角元素）被称为 **Ritz 值**，它们是对 $A$ 的[奇异值](@entry_id:152907)的极佳近似，特别是对那些位于谱两端的奇异值。
近似的[奇异向量](@entry_id:143538)（**Ritz 向量**）则可以通过 Lanczos 基进行恢复：
- $A$ 的近似[左奇异向量](@entry_id:751233)由 $\hat{U}_k = U_k P_k$ 的列给出。
- $A$ 的近似[右奇异向量](@entry_id:754365)由 $\hat{V}_k = V_k Q_k$ 的列给出。
随着迭代步数 $k$ 的增加，这些近似的质量通常会迅速提高。

**最小二乘问题**

考虑大型最小二乘问题 $\min_{x} \|Ax - b\|_2$。当 $A$ 巨大时，求解[正规方程](@entry_id:142238) $A^\top A x = A^\top b$ 可能由于 $A^\top A$ 的病态性而数值不稳定，或者由于其稠密性而计算成本高昂。

基于 Lanczos [双对角化](@entry_id:746789)的方法，如 LSQR，提供了一个优雅的解决方案 。值得注意的是，标准的 LSQR 算法利用了 Lanczos [双对角化](@entry_id:746789)的下双对角变体（即 Golub-Kahan 过程）。该过程从 $u_1 = b/\|b\|_2$ 开始，生成关系式 $A V_k = U_{k+1} \underline{L}_k$，其中 $\underline{L}_k$ 是一个 $(k+1) \times k$ 的下双对角矩阵。在第 $k$ 步时，在克里罗夫[子空间](@entry_id:150286) $\operatorname{span}(V_k)$ 中寻找近似解 $x_k = V_k y_k$。这需要求解投影后的最小二乘问题：
$$ \min_{y_k \in \mathbb{R}^k} \|A(V_k y_k) - b\|_2 $$
利用 Lanczos 关系 $A V_k = U_{k+1} \underline{L}_k$ 以及 $b = \|b\|_2 u_1 = \beta_1 u_1 = \beta_1 U_{k+1} e_1$，并利用 $U_{k+1}$ 的列是正交的这一性质，原问题可以被转化为一个等价的、但规模小得多的[最小二乘问题](@entry_id:164198)：
$$ \min_{y_k \in \mathbb{R}^k} \|\underline{L}_k y_k - \beta_1 e_1\|_2 $$
这个问题可以用高效稳定的方法（如 QR 分解）求解 $y_k$，然后恢复近似解 $x_k = V_k y_k$。这种方法从不形成 $A^\top A$，从而保持了良好的数值特性。此外，它与应用于正规方程的共轭梯度法（CGLS）在精确算术下是等价的，两者在每一步都产生相同的迭代解 。

### 实际计算中的考虑

理论上的完美性质在面对有限精度计算机时会遇到挑战。成功的实现必须考虑这些实际问题。

**初始向量的选择与适用性**

Lanczos [双对角化](@entry_id:746789)过程可以应用于**任何**实数矩阵 $A$，无论其形状或秩如何 。算法的适用性不依赖于矩阵的任何特殊属性。然而，算法的**行为**和**收敛性**强烈依赖于**初始向量**的选择。
- **启动条件**: 在我们描述的从 $v_1$ 开始的变体中，算法的第一步要求计算 $A v_1$ 并进行归一化。这只有在 $A v_1 \neq 0$ 时才可能，即 $v_1$ 不能位于 $A$ 的零空间 $\mathcal{N}(A)$ 中。
- **收敛影响**: 初始向量决定了生成的克里罗夫[子空间](@entry_id:150286)的内容。如果初始向量 $v_1$ 恰好与 $A$ 的某个[右奇异向量](@entry_id:754365)正交，那么在精确算术中，对应的奇异值和[奇异向量](@entry_id:143538)将永远不会在迭代中被发现。因此，为了有效地逼近特定的[奇异模](@entry_id:183903)式，初始向量最好包含这些模式的分量。在没有先验知识的情况下，通常会选择一个随机向量作为初始向量，因为它很可能与所有[奇异向量](@entry_id:143538)都有非零的投影。

**中断条件 (Breakdowns)**

在精确算术中，迭代过程可能会在 $k  \min(m, n)$ 步时提前终止。这发生在归一化因子 $\alpha_i$ 或 $\beta_{i+1}$ 之一变为零时。这种情况被称为“中断”，分为两种截然不同的类型 。
- **幸运中断 (Happy Breakdown)**: 当 $\beta_{k+1} = 0$ 时发生。这看似是问题，实则是一个非常理想的结果。它意味着递推关系 $A^\top U_k = V_k B_k^\top + \beta_{k+1} v_{k+1} e_k^\top$ 中的残差项消失了，我们得到了一对封闭的关系：$A V_k = U_k B_k$ 和 $A^\top U_k = V_k B_k^\top$。这表明 $\operatorname{span}(V_k)$ 和 $\operatorname{span}(U_k)$ 分别是 $A^\top A$ 和 $A A^\top$ 的**不变子空间**。此时，通过计算小型双[对角矩阵](@entry_id:637782) $B_k$ 的 SVD，我们可以得到 $A$ 的**精确**[奇异值](@entry_id:152907)和[奇异向量](@entry_id:143538)[子集](@entry_id:261956)。
- **严重中断 (Serious Breakdown)**: 当 $\alpha_k = 0$（但 $\beta_k \neq 0$）时发生。这意味着 $A v_k = \beta_k u_{k-1}$。在这种情况下，我们无法通过归一化来定义 $u_k$，算法无法继续。与幸运中断不同，这种情况本身并不直接提供 $A$ 的精确奇异信息，通常需要更复杂的策略（如 look-ahead Lanczos）来处理。

**有限精度与[再正交化](@entry_id:754248)**

在浮点运算中，Lanczos [双对角化](@entry_id:746789)的短[递推关系](@entry_id:189264)有一个众所周知的缺陷：计算出的向量 $\{u_i\}$ 和 $\{v_i\}$ 会逐渐失去它们理论上的正交性。这种正交性的丧失是由于[舍入误差](@entry_id:162651)的累积造成的，它会污染生成的克里罗夫[子空间](@entry_id:150286)，导致收敛变慢，甚至出现“幽灵”奇异值（即同一个奇异值的多个副本）。

为了解决这个问题，必须引入**[再正交化](@entry_id:754248)**步骤 。
- **完全[再正交化](@entry_id:754248) (Full Reorthogonalization, FRO)**: 在每一步生成一个新的候选向量（例如 $\hat{u}_k$）后，使用格拉姆-施密特（Gram-Schmidt）等方法强制它与所有先前生成的向量（$U_{k-1}$）正交。这能将正交性维持在机器精度水平，但计算成本很高。在第 $k$ 步，其成本与 $O(k \cdot m + k \cdot n)$ 成正比。
- **部分[再正交化](@entry_id:754248) (Partial Reorthogonalization, PRO)**: 一种折衷方案，它只在检测到正交性可能丢失时才进行选择性的[再正交化](@entry_id:754248)。这比 FRO 经济，但需要复杂的监控策略。
- **无[再正交化](@entry_id:754248)**: 这是最快但最不可靠的选项。

[再正交化](@entry_id:754248)的成本可能相当可观。在第 $k$ 步，对 $u_k$ 和 $v_{k+1}$ 进行完全[再正交化](@entry_id:754248)的浮点运算（flops）大约是 $4m(k-1) + 4n k$。对于一个稀疏度为 $\tau$ 的矩阵，一次矩阵向量乘积的成本约为 $2\tau$ flops。因此，[再正交化](@entry_id:754248)的成本与矩阵向量乘积成本的比率 $R(k) = \frac{2m(k-1) + 2n k}{\tau}$ 。当 $k$ 增大时，这个比率会[线性增长](@entry_id:157553)，意味着[再正交化](@entry_id:754248)的成本可能很快就会超过核心的矩阵向量乘积的成本。

正交性的丧失也可以从[后向误差](@entry_id:746645)的角度来理解 。在有限精度下计算出的近似 $\widehat{A}_k$ 可以被看作是某个扰动后矩阵 $A + \Delta A$ 的精确低秩近似。[再正交化](@entry_id:754248)策略直接影响这种扰动的大小。例如，不进行[再正交化](@entry_id:754248)导致的[基向量](@entry_id:199546)不正交性，其对[后向误差](@entry_id:746645)的贡献可能与 $k$ 成比例，而完全[再正交化](@entry_id:754248)则可将其降低到与[机器精度](@entry_id:756332) $u$ 同一[数量级](@entry_id:264888)的常数。选择合适的[再正交化](@entry_id:754248)策略是在计算成本和数值可靠性之间进行的关键权衡。