{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides a focused workout on the fundamental algebraic properties of circulant matrices. By applying the matrix determinant lemma to a rank-$1$ updated circulant matrix, you will see how properties like the structure of the inverse and its connection to the DFT allow for an elegant solution entirely in the spectral domain. This practice is key to developing fluency before moving to more complex algorithms .",
            "id": "3545349",
            "problem": "Let $C \\in \\mathbb{C}^{4 \\times 4}$ be the circulant matrix whose first column is $c = (3,\\,-1,\\,0,\\,-1)^{\\top}$. Consider the rank-$1$ update $uv^{\\ast}$ with $u = v = e_{1} \\in \\mathbb{C}^{4}$, where $e_{1}$ is the first standard basis vector and $(\\cdot)^{\\ast}$ denotes the conjugate transpose. Compute the exact value of the scalar\n$$\n\\frac{\\det\\!\\big(C + u v^{\\ast}\\big)}{\\det(C)}.\n$$\nProvide your answer in exact form with no rounding.",
            "solution": "The\nproblem asks for the computation of the scalar quantity $\\frac{\\det(C + uv^{\\ast})}{\\det(C)}$, where $C \\in \\mathbb{C}^{4 \\times 4}$ is a circulant matrix, $u = v = e_1 \\in \\mathbb{C}^4$, and $e_1$ is the first standard basis vector. The first column of $C$ is given by $c = (3, -1, 0, -1)^{\\top}$.\n\nFirst, we will utilize the matrix determinant lemma, which states that for an invertible square matrix $A$ and column vectors $u$ and $v$ of the same dimension,\n$$\n\\det(A + uv^{\\ast}) = \\det(A) (1 + v^{\\ast}A^{-1}u)\n$$\nIn our case, $A = C$, and $u, v$ are as defined. Provided that $C$ is invertible (i.e., $\\det(C) \\neq 0$), we can write the desired ratio as:\n$$\n\\frac{\\det(C + uv^{\\ast})}{\\det(C)} = 1 + v^{\\ast}C^{-1}u\n$$\nGiven that $u = v = e_1$, where $e_1 = (1, 0, 0, 0)^{\\top}$, the term $v^{\\ast}C^{-1}u$ becomes $e_1^{\\ast}C^{-1}e_1$. The expression $e_1^{\\ast}M e_1$ for any matrix $M$ simply extracts the element in the first row and first column, $(M)_{11}$. Therefore, our task reduces to computing $1 + (C^{-1})_{11}$.\n\nTo proceed, we must first verify that $C$ is invertible. The eigenvalues of an $n \\times n$ circulant matrix with the first column $c = (c_0, c_1, \\dots, c_{n-1})^{\\top}$ are given by the discrete Fourier transform (DFT) of $c$:\n$$\n\\lambda_k = \\sum_{j=0}^{n-1} c_j \\omega^{-jk}, \\quad \\text{for } k = 0, 1, \\dots, n-1\n$$\nwhere $\\omega = \\exp(2\\pi i/n)$ is a primitive $n$-th root of unity.\nFor this problem, $n=4$, the first column is $c = (3, -1, 0, -1)^{\\top}$, so $c_0=3$, $c_1=-1$, $c_2=0$, and $c_3=-1$. The $4$-th root of unity is $\\omega = \\exp(2\\pi i/4) = i$.\nThe eigenvalues are:\n$$\n\\lambda_0 = c_0 + c_1 + c_2 + c_3 = 3 - 1 + 0 - 1 = 1\n$$\n$$\n\\lambda_1 = c_0 + c_1 \\omega^{-1} + c_2 \\omega^{-2} + c_3 \\omega^{-3} = 3 + (-1)(-i) + (0)(-1) + (-1)(i) = 3 + i - i = 3\n$$\n$$\n\\lambda_2 = c_0 + c_1 \\omega^{-2} + c_2 \\omega^{-4} + c_3 \\omega^{-6} = c_0 - c_1 + c_2 - c_3 = 3 - (-1) + 0 - (-1) = 3 + 1 + 1 = 5\n$$\n$$\n\\lambda_3 = c_0 + c_1 \\omega^{-3} + c_2 \\omega^{-6} + c_3 \\omega^{-9} = 3 + (-1)(i) + (0)(-1) + (-1)(-i) = 3 - i + i = 3\n$$\nThe eigenvalues of $C$ are $\\{1, 3, 5, 3\\}$. The determinant of a matrix is the product of its eigenvalues:\n$$\n\\det(C) = \\lambda_0 \\lambda_1 \\lambda_2 \\lambda_3 = 1 \\cdot 3 \\cdot 5 \\cdot 3 = 45\n$$\nSince $\\det(C) = 45 \\neq 0$, the matrix $C$ is invertible, and our application of the matrix determinant lemma is valid.\n\nNow we must find $(C^{-1})_{11}$. A fundamental property of circulant matrices is that the inverse of a circulant matrix is also a circulant matrix. Let the first column of $C^{-1}$ be $d = (d_0, d_1, d_2, d_3)^{\\top}$. Then $(C^{-1})_{11} = d_0$.\n\nThe eigenvalues of $C^{-1}$, denoted by $\\mu_k$, are the reciprocals of the eigenvalues of $C$:\n$$\n\\mu_k = \\frac{1}{\\lambda_k}\n$$\nSo, the eigenvalues of $C^{-1}$ are $\\mu_0 = \\frac{1}{1} = 1$, $\\mu_1 = \\frac{1}{3}$, $\\mu_2 = \\frac{1}{5}$, and $\\mu_3 = \\frac{1}{3}$.\n\nThe first column $d$ of $C^{-1}$ can be found by applying the inverse DFT to the sequence of eigenvalues $(\\mu_0, \\mu_1, \\mu_2, \\mu_3)$:\n$$\nd_j = \\frac{1}{n} \\sum_{k=0}^{n-1} \\mu_k \\omega^{jk}\n$$\nWe are interested in the component $d_0$, which corresponds to $j=0$:\n$$\nd_0 = \\frac{1}{4} \\sum_{k=0}^{3} \\mu_k \\omega^{0} = \\frac{1}{4} (\\mu_0 + \\mu_1 + \\mu_2 + \\mu_3)\n$$\nSubstituting the values of $\\mu_k$:\n$$\nd_0 = \\frac{1}{4} \\left(1 + \\frac{1}{3} + \\frac{1}{5} + \\frac{1}{3}\\right) = \\frac{1}{4} \\left(1 + \\frac{2}{3} + \\frac{1}{5}\\right)\n$$\nTo sum the fractions, we find a common denominator, which is $15$:\n$$\nd_0 = \\frac{1}{4} \\left(\\frac{15}{15} + \\frac{10}{15} + \\frac{3}{15}\\right) = \\frac{1}{4} \\left(\\frac{15+10+3}{15}\\right) = \\frac{1}{4} \\left(\\frac{28}{15}\\right) = \\frac{7}{15}\n$$\nThus, $(C^{-1})_{11} = d_0 = \\frac{7}{15}$.\n\nFinally, we can compute the desired ratio:\n$$\n\\frac{\\det(C + uv^{\\ast})}{\\det(C)} = 1 + (C^{-1})_{11} = 1 + \\frac{7}{15} = \\frac{15}{15} + \\frac{7}{15} = \\frac{22}{15}\n$$",
            "answer": "$$\\boxed{\\frac{22}{15}}$$"
        },
        {
            "introduction": "Building upon foundational properties, this practice challenges you to design an iterative algorithm for spectral estimation. You will implement the power method to find the spectral norm and condition number of a circulant matrix, using the FFT to perform the required matrix-vector products in $\\mathcal{O}(n \\log n)$ time. This exercise demonstrates how the FFT serves as a powerful engine for accelerating classical linear algebra algorithms .",
            "id": "3545359",
            "problem": "Consider an $n \\times n$ real circulant matrix $C$ with $n$ even, defined by its first column $c \\in \\mathbb{R}^{n}$ as $c_{0}=3$, $c_{1}=1$, $c_{n-1}=1$, and $c_{j}=0$ for all other indices $j \\in \\{2,3,\\dots,n-2\\}$. You are tasked with designing a fully explicit randomized estimator of the spectral norm $\\|C\\|_{2}$ and the $2$-norm condition number $\\kappa_{2}(C)$ using a power iteration scheme whose matrix-vector multiplies are implemented with the Fast Fourier Transform (FFT). Begin from foundational definitions: the structure of circulant matrices, the discrete Fourier transform as a unitary change of basis, and the spectral theorem for normal matrices. You must not assume any pre-derived diagonalization formula or shortcut identities; instead, derive all relations from first principles starting from these bases.\n\nYour estimator should:\n- Use a random initial vector $x^{(0)} \\in \\mathbb{R}^{n}$ whose entries are independent and identically distributed with a continuous distribution symmetric about $0$ (for example, standard normal), so that, almost surely, $x^{(0)}$ has nonzero components in every eigenvector direction of $C$.\n- Implement the power iteration $x^{(t+1)} := C x^{(t)} / \\|C x^{(t)}\\|_{2}$ for $t \\geq 0$ to estimate $\\|C\\|_{2}$ via the Rayleigh quotient $r^{(t)} := (x^{(t)})^{\\top} C x^{(t)}$ and, independently, implement the analogous iteration on $C^{-1}$, $y^{(t+1)} := C^{-1} y^{(t)} / \\|C^{-1} y^{(t)}\\|_{2}$, to estimate the smallest eigenvalue of $C$. Both $C$ and $C^{-1}$ multiplies must be performed in $O(n \\log n)$ time via FFT-based diagonalization of $C$.\n- Analyze the asymptotic convergence rate of each iteration in terms of spectral gaps inferred from the eigenvalues $\\lambda_{k}$ of $C$.\n\nUsing only these bases, carry out the following:\n1. Derive the eigenvalues $\\lambda_{k}$ of $C$.\n2. Prove that $C$ is symmetric positive definite, identify $\\|C\\|_{2}$ and the smallest eigenvalue, and conclude $\\kappa_{2}(C)$.\n3. For the power iteration on $C$, derive the asymptotic geometric convergence factor for the angle between $x^{(t)}$ and the dominant eigenvector in terms of the ratio of the second-largest to the largest eigenvalue. Express this factor as a closed-form function of $n$.\n4. For the power iteration on $C^{-1}$, derive the analogous asymptotic geometric convergence factor in terms of the ratio of the smallest to the second-smallest eigenvalue of $C$, again in closed form as a function of $n$.\n5. Report, in closed form, the quadruple consisting of: the exact spectral norm $\\|C\\|_{2}$, the exact condition number $\\kappa_{2}(C)$, the asymptotic geometric convergence factor of the power iteration on $C$, and the asymptotic geometric convergence factor of the power iteration on $C^{-1}$, each expressed purely in terms of $n$ and constants. No rounding is required.\n\nYour final reported answer must be a single row matrix containing these four quantities in the specified order.",
            "solution": "The problem statement is analyzed and found to be valid. It is a well-posed problem in numerical linear algebra that is scientifically grounded, objective, and self-contained. The requirement to derive results from foundational principles is a pedagogical constraint that does not constitute a flaw. We proceed with the solution.\n\nThe problem asks for an analysis of a specific real, even-dimensional circulant matrix $C \\in \\mathbb{R}^{n \\times n}$. The matrix $C$ is defined by its first column vector $c \\in \\mathbb{R}^{n}$, where $c_0 = 3$, $c_1 = 1$, $c_{n-1} = 1$, and $c_j = 0$ for $j \\in \\{2, 3, \\dots, n-2\\}$.\n\n1.  **Derivation of the Eigenvalues of $C$**\n\nA circulant matrix is defined by its first column. The entry $C_{jk}$ is given by $c_{(j-k) \\pmod n}$. The foundational principle for diagonalizing a circulant matrix is that its eigenvectors are the columns of the Discrete Fourier Transform (DFT) matrix. We must derive this from first principles.\n\nLet $\\omega = \\exp(2\\pi i/n)$ be the $n$-th primitive root of unity, where $i = \\sqrt{-1}$. Consider the vectors $v_k \\in \\mathbb{C}^n$ for $k \\in \\{0, 1, \\dots, n-1\\}$, where the $j$-th component of $v_k$ is $(v_k)_j = \\omega^{jk}$. We will show that these are the eigenvectors of $C$.\n\nLet's compute the $j$-th component of the matrix-vector product $C v_k$:\n$$ (C v_k)_j = \\sum_{m=0}^{n-1} C_{jm} (v_k)_m = \\sum_{m=0}^{n-1} c_{(j-m) \\pmod n} \\, \\omega^{mk} $$\nLet $p = (j-m) \\pmod n$. As $m$ iterates from $0$ to $n-1$, $p$ also covers the set $\\{0, 1, \\dots, n-1\\}$. We can express $m$ in terms of $p$ as $m = (j-p) \\pmod n$. Substituting this into the sum:\n$$ (C v_k)_j = \\sum_{p=0}^{n-1} c_p \\, \\omega^{(j-p)k} = \\sum_{p=0}^{n-1} c_p \\, \\omega^{jk} \\omega^{-pk} = \\omega^{jk} \\left( \\sum_{p=0}^{n-1} c_p \\, \\omega^{-pk} \\right) $$\nThe term in the parenthesis is a scalar that depends on $k$ but not on $j$. Let us define this scalar as $\\lambda_k$:\n$$ \\lambda_k = \\sum_{j=0}^{n-1} c_j \\omega^{-jk} $$\nWith this definition, we have $(C v_k)_j = \\lambda_k \\omega^{jk} = \\lambda_k (v_k)_j$. This equation holds for all components $j$, which proves that $v_k$ is an eigenvector of $C$ with the corresponding eigenvalue $\\lambda_k$. The set of eigenvalues $\\{\\lambda_k\\}_{k=0}^{n-1}$ is called the spectrum of $C$.\n\nNow, we substitute the specific values from the vector $c$ into the formula for $\\lambda_k$:\n$$ \\lambda_k = c_0 \\omega^{-0} + c_1 \\omega^{-k} + c_{n-1} \\omega^{-(n-1)k} + \\sum_{j=2}^{n-2} c_j \\omega^{-jk} $$\n$$ \\lambda_k = 3 \\cdot 1 + 1 \\cdot \\omega^{-k} + 1 \\cdot \\omega^{-(n-1)k} + 0 = 3 + \\omega^{-k} + \\omega^{-(n-1)k} $$\nUsing the property $\\omega^n = \\exp(2\\pi i) = 1$, we can simplify $\\omega^{-(n-1)k} = \\omega^{-nk} \\omega^k = (\\omega^n)^{-k} \\omega^k = 1^{-k} \\omega^k = \\omega^k$.\n$$ \\lambda_k = 3 + \\omega^{-k} + \\omega^k $$\nBy Euler's formula, $\\omega^k = \\cos(2\\pi k/n) + i\\sin(2\\pi k/n)$ and $\\omega^{-k} = \\cos(2\\pi k/n) - i\\sin(2\\pi k/n)$. Their sum is $2\\cos(2\\pi k/n)$.\nThus, the eigenvalues of $C$ are:\n$$ \\lambda_k = 3 + 2\\cos\\left(\\frac{2\\pi k}{n}\\right) \\quad \\text{for } k = 0, 1, \\dots, n-1 $$\n\n2.  **Symmetry, Positive Definiteness, Spectral Norm, and Condition Number**\n\nFor a real circulant matrix with first column $c$, symmetry ($C=C^T$) is equivalent to the condition $c_j = c_{n-j}$ for $j=1, \\dots, n-1$. In our case, $c_1=1$ and $c_{n-1}=1$, so the condition holds for $j=1$. For $j \\in \\{2, \\dots, n-2\\}$, we have $c_j=0$. The index $n-j$ is also in $\\{2, \\dots, n-2\\}$ as $n$ is even, implying $n-j \\neq j$, so $c_{n-j}=0$ as well. The condition holds for all $j$, so $C$ is symmetric.\n\nSince $C$ is a real symmetric matrix, its eigenvalues must be real. Our derived expression $\\lambda_k = 3 + 2\\cos(2\\pi k/n)$ is indeed real for all $k$. To check for positive definiteness, we need to show that all eigenvalues are strictly positive. The range of the cosine function is $[-1, 1]$.\nThe maximum value of $\\cos(2\\pi k/n)$ is $1$, occurring at $k=0$. This gives the largest eigenvalue:\n$$ \\lambda_{\\max} = \\lambda_0 = 3 + 2\\cos(0) = 3 + 2 = 5 $$\nThe minimum value of $\\cos(2\\pi k/n)$ is $-1$, occurring at $k=n/2$ (which is an integer since $n$ is even). This gives the smallest eigenvalue:\n$$ \\lambda_{\\min} = \\lambda_{n/2} = 3 + 2\\cos(\\pi) = 3 - 2 = 1 $$\nAll eigenvalues $\\lambda_k$ lie in the interval $[1, 5]$. Since $\\lambda_{\\min} = 1 > 0$, all eigenvalues are positive, and thus the symmetric matrix $C$ is positive definite.\n\nFor a normal matrix (and symmetric matrices are normal), the spectral norm $\\|C\\|_2$ is its spectral radius, i.e., the maximum absolute value of its eigenvalues.\n$$ \\|C\\|_2 = \\max_{k} |\\lambda_k| = \\lambda_{\\max} = 5 $$\nThe $2$-norm condition number $\\kappa_2(C)$ is given by $\\|C\\|_2 \\|C^{-1}\\|_2$. The eigenvalues of $C^{-1}$ are $1/\\lambda_k$. Thus, $\\|C^{-1}\\|_2 = \\max_k |1/\\lambda_k| = 1/\\min_k|\\lambda_k| = 1/\\lambda_{\\min}$.\n$$ \\kappa_2(C) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\frac{5}{1} = 5 $$\n\n3.  **Convergence Factor for Power Iteration on $C$**\n\nThe power iteration method $x^{(t+1)} \\propto C x^{(t)}$ converges to the eigenvector corresponding to the eigenvalue with the largest magnitude. The asymptotic geometric convergence factor is the ratio of the magnitudes of the second-largest to the largest eigenvalue. Since all eigenvalues of $C$ are positive, we seek the ratio $\\lambda'/\\lambda_{\\max}$, where $\\lambda'$ is the second-largest eigenvalue.\n\nThe eigenvalues are $\\lambda_k = 3 + 2\\cos(2\\pi k/n)$.\nThe largest eigenvalue is $\\lambda_0 = 5$, which is unique.\nThe function $\\cos(x)$ is strictly decreasing on $[0, \\pi]$. The arguments $2\\pi k/n$ for $k=1$ and $k=n-1$ give the same cosine value: $\\cos(2\\pi/n) = \\cos(2\\pi(n-1)/n) = \\cos(2\\pi - 2\\pi/n)$. This value is the largest one after $\\cos(0)=1$.\nTherefore, the second-largest eigenvalue is degenerate (has multiplicity $2$) and is given by:\n$$ \\lambda' = \\lambda_1 = \\lambda_{n-1} = 3 + 2\\cos\\left(\\frac{2\\pi}{n}\\right) $$\nThe asymptotic geometric convergence factor is:\n$$ \\frac{\\lambda'}{\\lambda_{\\max}} = \\frac{3 + 2\\cos\\left(\\frac{2\\pi}{n}\\right)}{5} $$\n\n4.  **Convergence Factor for Power Iteration on $C^{-1}$**\n\nThe power iteration applied to $C^{-1}$ (i.e., inverse iteration on $C$) converges to the eigenvector of $C^{-1}$ corresponding to its largest-magnitude eigenvalue. This eigenvalue is $1/\\lambda_{\\min}$, where $\\lambda_{\\min}$ is the smallest-magnitude eigenvalue of $C$. The convergence factor is the ratio of the second-largest to the largest magnitude eigenvalue of $C^{-1}$, which is equivalent to the ratio of the smallest to the second-smallest magnitude eigenvalue of $C$.\n\nThe smallest eigenvalue of $C$ is $\\lambda_{\\min} = \\lambda_{n/2} = 1$, which is unique.\nThe second-smallest eigenvalue corresponds to the value of $\\cos(2\\pi k/n)$ closest to $-1$. This occurs for $k=n/2-1$ and $k=n/2+1$.\n$$ \\cos\\left(\\frac{2\\pi(n/2-1)}{n}\\right) = \\cos\\left(\\pi - \\frac{2\\pi}{n}\\right) = -\\cos\\left(\\frac{2\\pi}{n}\\right) $$\n$$ \\cos\\left(\\frac{2\\pi(n/2+1)}{n}\\right) = \\cos\\left(\\pi + \\frac{2\\pi}{n}\\right) = -\\cos\\left(\\frac{2\\pi}{n}\\right) $$\nThe second-smallest eigenvalue, $\\lambda''$, is thus also degenerate and is given by:\n$$ \\lambda'' = \\lambda_{n/2-1} = \\lambda_{n/2+1} = 3 + 2\\left(-\\cos\\left(\\frac{2\\pi}{n}\\right)\\right) = 3 - 2\\cos\\left(\\frac{2\\pi}{n}\\right) $$\nThe asymptotic geometric convergence factor for the inverse iteration is:\n$$ \\frac{\\lambda_{\\min}}{\\lambda''} = \\frac{1}{3 - 2\\cos\\left(\\frac{2\\pi}{n}\\right)} $$\n\n5.  **Final Quadruple of Quantities**\n\nBased on the derivations above, the four requested quantities are:\n1.  Spectral norm $\\|C\\|_2 = 5$.\n2.  Condition number $\\kappa_2(C) = 5$.\n3.  Asymptotic geometric convergence factor for power iteration on $C$: $\\frac{1}{5}\\left(3 + 2\\cos\\left(\\frac{2\\pi}{n}\\right)\\right)$.\n4.  Asymptotic geometric convergence factor for power iteration on $C^{-1}$: $\\frac{1}{3 - 2\\cos\\left(\\frac{2\\pi}{n}\\right)}$.\n\nThese are compiled into a single row matrix as the final answer.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 5 & 5 & \\frac{3 + 2\\cos\\left(\\frac{2\\pi}{n}\\right)}{5} & \\frac{1}{3 - 2\\cos\\left(\\frac{2\\pi}{n}\\right)} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Our final practice tackles a crucial aspect of numerical computation: stability in the face of ill-conditioning. You will explore the Moore-Penrose pseudoinverse of a circulant matrix and quantify how near-zero eigenvalues corrupt the idempotency of the resulting projection operator. This advanced problem will guide you through implementing and comparing spectral regularization techniques to restore numerical robustness, a vital skill for solving real-world inverse problems .",
            "id": "3545340",
            "problem": "You are given the task of analyzing the projection operator built from the Moore–Penrose pseudoinverse of a circulant matrix using the Discrete Fourier Transform (DFT) computed by the Fast Fourier Transform (FFT). Work in exact arithmetic would make the projection idempotent, but near-zero spectral values amplify roundoff in finite precision. Your goal is to derive, implement, and quantitatively assess how spectral smallness corrupts idempotency, and to design a frequency-domain regularization that restores approximate idempotency.\n\nFundamental bases to use:\n- A circulant matrix $C \\in \\mathbb{C}^{n \\times n}$ generated by a first column $c \\in \\mathbb{C}^{n}$ is unitarily diagonalized by the unitary DFT matrix $F \\in \\mathbb{C}^{n \\times n}$, satisfying $F^{*} F = I$. This yields $C = F^{*} \\,\\mathrm{diag}(\\lambda)\\, F$, where the vector of eigenvalues $\\lambda$ is computed as $\\lambda = \\sqrt{n} F c$.\n- The Moore–Penrose pseudoinverse $C^{\\dagger}$ of $C$ is $C^{\\dagger} = F^{*}\\,\\mathrm{diag}(\\mu)\\,F$, where for each $k$ one has $\\mu_{k} = 1/\\lambda_{k}$ when $\\lambda_{k} \\neq 0$ and $\\mu_{k} = 0$ when $\\lambda_{k} = 0$.\n- The projection $P = C^{\\dagger} C$ is idempotent in exact arithmetic, i.e., $P^{2} = P$.\n\nTasks:\n1. Derive from the above base that the projection $P$ is also circulant and unitarily diagonalized by $F$, and relate its spectrum to $\\lambda$. Define $p \\in \\mathbb{C}^{n}$ as the frequency response of $P$ such that $P = F^{*}\\,\\mathrm{diag}(p)\\,F$, and then define an idempotency defect metric using the Frobenius norm,\n   $$\\mathcal{E}(P) \\equiv \\frac{\\lVert P^{2} - P \\rVert_{F}}{\\lVert P \\rVert_{F}},$$\n   and express it purely in terms of $p$ (no explicit dense matrices), using only properties of unitary similarity and the Frobenius norm.\n2. Using the FFT with unitary scaling (i.e., forward transform divided by $\\sqrt{n}$ and inverse multiplied by $\\sqrt{n}$), implement the following three spectral constructions of $p$ and compute the corresponding idempotency defect:\n   - Naive reciprocal with amplified roundoff. Let $\\lambda \\in \\mathbb{C}^{n}$ be obtained from $c$ by the unitary FFT. For each index $k$ with $\\lambda_{k} \\neq 0$, define a perturbed reciprocal\n     $$\\tilde{\\mu}_{k} = \\frac{1}{\\lambda_{k}}\\left(1 + \\delta_{k}\\right),$$\n     where the perturbation $\\delta_{k}$ models amplified roundoff with magnitude inversely proportional to $\\lvert \\lambda_{k} \\rvert$. Use\n     $$\\delta_{k} = \\xi_{k}\\,u\\,\\frac{\\tau}{\\max(\\lvert \\lambda_{k} \\rvert, 10^{-300})},$$\n     with machine unit roundoff $u$ for double precision, a specified threshold parameter $\\tau > 0$, and real $\\xi_{k}$ drawn from a standard normal distribution with a fixed random seed for reproducibility. For $\\lambda_{k} = 0$, set $\\tilde{\\mu}_{k} = 0$. Then set\n     $$\\tilde{p}_{k} = \\tilde{\\mu}_{k}\\,\\lambda_{k}.$$\n     Compute $\\mathcal{E}$ for $p = \\tilde{p}$.\n   - Truncated spectral pseudoinverse (hard thresholding). Define\n     $$\\mu^{(\\tau)}_{k} = \\begin{cases} \\frac{1}{\\lambda_{k}}, & \\lvert \\lambda_{k} \\rvert \\ge \\tau, \\\n$$4pt] 0, & \\lvert \\lambda_{k} \\rvert < \\tau,\\end{cases} \\quad p^{(\\tau)}_{k} = \\mu^{(\\tau)}_{k}\\,\\lambda_{k}.$$\n     Compute $\\mathcal{E}$ for $p = p^{(\\tau)}$.\n   - Tikhonov-type smoothing in the frequency domain. Define\n     $$p^{(\\alpha)}_{k} = \\frac{\\lvert \\lambda_{k} \\rvert^{2}}{\\lvert \\lambda_{k} \\rvert^{2} + \\alpha},$$\n     with a given parameter $\\alpha > 0$ (you will use $\\alpha = \\tau^{2}$ in the tests). Compute $\\mathcal{E}$ for $p = p^{(\\alpha)}$.\n3. Implement all computations via the FFT in the frequency domain. Do not form any dense $n \\times n$ matrices. Your idempotency defect must be computed only from the spectral vector $p$ using your result from Task 1.\n4. Test suite. For each of the following four cases, compute and report the triple of idempotency defects $[\\mathcal{E}_{\\mathrm{naive}}, \\mathcal{E}_{\\mathrm{trunc}}, \\mathcal{E}_{\\mathrm{tikh}}]$:\n   - Case A (exact zero mode present): $n=8$, $c = [2,\\,1,\\,0,\\,0,\\,0,\\,0,\\,0,\\,1]^{\\top}$, $\\tau = 1\\times 10^{-8}$, $\\alpha = \\tau^{2}$, use random seed $0$ for the perturbations.\n   - Case B (near-zero mode at frequency $0$): $n=12$, $c = [\\,1,\\,-(1-10^{-12}),\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0\\,]^{\\top}$, $\\tau = 1\\times 10^{-8}$, $\\alpha = \\tau^{2}$, seed $1$.\n   - Case C (discrete second-difference spectrum with many small low frequencies): $n=4096$, $c = [\\,1,\\,-2,\\,1,\\,0,\\,\\ldots,\\,0\\,]^{\\top}$, $\\tau = 1\\times 10^{-5}$, $\\alpha = \\tau^{2}$, seed $2$.\n   - Case D (well-conditioned identity circulant): $n=5$, $c = [\\,1,\\,0,\\,0,\\,0,\\,0\\,]^{\\top}$, $\\tau = 1\\times 10^{-8}$, $\\alpha = \\tau^{2}$, seed $3$.\n   In all cases, interpret $c$ as complex with zero imaginary parts. Angles implicit in the DFT are in radians. Use double-precision arithmetic. For the unit roundoff, take $u = 2^{-53}$.\n5. Final output format. Your program should produce a single line of output containing the results as a comma-separated list of four inner lists, each inner list being the triple for a test case in the order A, B, C, D. For example,\n   $$[ [x_{A},y_{A},z_{A}], [x_{B},y_{B},z_{B}], [x_{C},y_{C},z_{C}], [x_{D},y_{D},z_{D}] ],$$\n   where each symbol is a floating-point number. Do not print any extra text.\n\nNotes:\n- Do not use any dense $n \\times n$ matrices; the derivation in Task 1 must justify how to compute the Frobenius norms directly from spectral data.\n- Your implementation must rely on the Fast Fourier Transform to obtain $\\lambda$ from $c$ with unitary normalization.\n- The answer values have no physical units.",
            "solution": "The problem requires an analysis of the idempotency of a projection operator derived from a circulant matrix. Specifically, we must derive a formula for an idempotency defect metric in the spectral domain and then implement and compare three different numerical strategies for constructing the projection: a naive approach susceptible to roundoff error, a hard-thresholding approach, and a Tikhonov regularization approach.\n\n### Task 1: Derivation of the Idempotency Defect in the Spectral Domain\n\nLet $C \\in \\mathbb{C}^{n \\times n}$ be a circulant matrix generated by its first column $c \\in \\mathbb{C}^n$. It is diagonalized by the unitary Discrete Fourier Transform (DFT) matrix $F \\in \\mathbb{C}^{n \\times n}$ as $C = F^* \\mathrm{diag}(\\lambda) F$, where $\\lambda$ is the vector of eigenvalues of $C$. The Moore-Penrose pseudoinverse $C^\\dagger$ is given by $C^\\dagger = F^* \\mathrm{diag}(\\mu) F$, where the elements of the spectral vector $\\mu$ are defined as $\\mu_k = 1/\\lambda_k$ if $\\lambda_k \\neq 0$ and $\\mu_k = 0$ if $\\lambda_k = 0$.\n\nThe projection operator onto the range of $C$ is $P = C^\\dagger C$. We can express $P$ in terms of the spectral representations of $C$ and $C^\\dagger$:\n$$\nP = C^\\dagger C = \\left( F^* \\mathrm{diag}(\\mu) F \\right) \\left( F^* \\mathrm{diag}(\\lambda) F \\right)\n$$\nSince $F$ is unitary, $F F^* = I$, where $I$ is the identity matrix.\n$$\nP = F^* \\mathrm{diag}(\\mu) (F F^*) \\mathrm{diag}(\\lambda) F = F^* \\mathrm{diag}(\\mu) \\mathrm{diag}(\\lambda) F\n$$\nThe product of two diagonal matrices is a diagonal matrix whose elements are the products of the corresponding diagonal elements. Let $p \\in \\mathbb{C}^n$ be a vector such that $p_k = \\mu_k \\lambda_k$ for each $k$. Then, $\\mathrm{diag}(p) = \\mathrm{diag}(\\mu) \\mathrm{diag}(\\lambda)$, and we have:\n$$\nP = F^* \\mathrm{diag}(p) F\n$$\nThis equation shows that $P$ is also diagonalized by the DFT matrix $F$. A matrix is circulant if and only if it is diagonalized by the DFT matrix. Therefore, $P$ is a circulant matrix, and its spectrum is given by the vector $p$.\n\nIn exact arithmetic, for any $k$:\n- If $\\lambda_k \\neq 0$, then $\\mu_k = 1/\\lambda_k$, so $p_k = (1/\\lambda_k) \\lambda_k = 1$.\n- If $\\lambda_k = 0$, then $\\mu_k = 0$, so $p_k = 0 \\cdot 0 = 0$.\nThus, in exact arithmetic, the spectrum $p$ of the projection $P$ consists only of $0$s and $1$s.\n\nThe idempotency defect is defined as $\\mathcal{E}(P) \\equiv \\frac{\\lVert P^{2} - P \\rVert_{F}}{\\lVert P \\rVert_{F}}$. We need to express this in terms of $p$. A key property of the Frobenius norm is its invariance under unitary transformations: for any matrix $A$ and unitary matrix $U$, $\\lVert U A U^* \\rVert_F = \\lVert A \\rVert_F$.\n\nFirst, consider the term $P^2 - P$:\n$$\nP^2 = \\left( F^* \\mathrm{diag}(p) F \\right) \\left( F^* \\mathrm{diag}(p) F \\right) = F^* \\mathrm{diag}(p)^2 F = F^* \\mathrm{diag}(p^2) F\n$$\nwhere $p^2$ is the element-wise square of the vector $p$.\nThen, the difference is:\n$$\nP^2 - P = F^* \\mathrm{diag}(p^2) F - F^* \\mathrm{diag}(p) F = F^* \\left( \\mathrm{diag}(p^2) - \\mathrm{diag}(p) \\right) F = F^* \\mathrm{diag}(p^2 - p) F\n$$\nUsing the unitary invariance of the Frobenius norm:\n$$\n\\lVert P^2 - P \\rVert_F = \\lVert F^* \\mathrm{diag}(p^2 - p) F \\rVert_F = \\lVert \\mathrm{diag}(p^2 - p) \\rVert_F\n$$\nThe Frobenius norm of a diagonal matrix is the Euclidean ($L_2$) norm of the vector of its diagonal elements.\n$$\n\\lVert \\mathrm{diag}(p^2 - p) \\rVert_F = \\sqrt{\\sum_{k=0}^{n-1} |p_k^2 - p_k|^2} = \\lVert p^2 - p \\rVert_2\n$$\n\nNext, consider the denominator term $\\lVert P \\rVert_F$:\n$$\n\\lVert P \\rVert_F = \\lVert F^* \\mathrm{diag}(p) F \\rVert_F = \\lVert \\mathrm{diag}(p) \\rVert_F = \\sqrt{\\sum_{k=0}^{n-1} |p_k|^2} = \\lVert p \\rVert_2\n$$\n\nCombining the numerator and denominator, we obtain the idempotency defect purely in terms of the spectral vector $p$:\n$$\n\\mathcal{E}(P) = \\frac{\\lVert p^2 - p \\rVert_2}{\\lVert p \\rVert_2}\n$$\nThis formula allows us to compute the defect without forming any dense $n \\times n$ matrices, fulfilling the requirements of the problem. If any $p_k$ deviates from $0$ or $1$ due to numerical error, the numerator $\\lVert p^2 - p \\rVert_2$ becomes non-zero, quantifying the loss of idempotency.\n\n### Computational Strategy and Implementation\n\nThe implementation will strictly follow the derived formula, performing all calculations in the frequency domain.\n\n1.  **Spectrum Calculation:** For each test case, the circulant generator vector $c$ is defined. Its spectrum, $\\lambda$, is computed using the Fast Fourier Transform (FFT) with unitary normalization and scaled correctly to represent the eigenvalues.\n\n2.  **Spectral Constructions:** Three different spectral vectors for the projection, $p$, are constructed:\n    -   **Naive ($\\tilde{p}$):** A perturbed reciprocal $\\tilde{\\mu}$ is computed, modeling roundoff error amplification. The perturbation $\\delta_k = \\xi_k u \\tau / \\max(|\\lambda_k|, 10^{-300})$ is calculated, where $\\xi_k$ is a standard normal random variate, $u=2^{-53}$ is the machine epsilon for double precision, and $\\tau$ is a given threshold. Then, $\\tilde{p}_k = (1/\\lambda_k)(1+\\delta_k)\\lambda_k$ for $\\lambda_k \\neq 0$ and $\\tilde{p}_k=0$ for $\\lambda_k=0$. This construction is designed to fail dramatically for small, non-zero $|\\lambda_k|$.\n    -   **Truncated ($p^{(\\tau)}$):** A hard threshold $\\tau$ is applied. The reciprocal is taken only for eigenvalues with magnitude greater than or equal to $\\tau$; otherwise, it is set to zero. This results in $p_k^{(\\tau)} = 1$ if $|\\lambda_k| \\ge \\tau$ and $p_k^{(\\tau)} = 0$ if $|\\lambda_k| < \\tau$. This method sharply delineates which spectral components are kept, which should result in a spectral vector $p$ composed of values very close to $0$ and $1$, yielding a low idempotency defect.\n    -   **Tikhonov ($p^{(\\alpha)}$):** A smoothing filter is applied, $p_k^{(\\alpha)} = |\\lambda_k|^2 / (|\\lambda_k|^2 + \\alpha)$, where $\\alpha = \\tau^2$. This method transitions smoothly between passing high-magnitude eigenvalues ($p_k \\to 1$) and suppressing low-magnitude ones ($p_k \\to 0$). It introduces a systematic bias, as $p_k$ is never exactly $1$, trading perfect idempotency for numerical stability.\n\n3.  **Defect Calculation:** For each of the three resulting spectral vectors $p$, the idempotency defect $\\mathcal{E}$ is computed using the derived formula $\\mathcal{E}(P) = \\lVert p^2 - p \\rVert_2 / \\lVert p \\rVert_2$. A helper function encapsulates this calculation, using `numpy.linalg.norm` for the $L_2$ vector norms. The case where $\\lVert p \\rVert_2 = 0$ (corresponding to a zero projection matrix) is handled by defining the defect as $0$.\n\nThis strategy is applied to the four specified test cases, each designed to probe a different numerical scenario: a true zero eigenvalue, a near-zero eigenvalue, a spectrum with many small eigenvalues, and a well-conditioned spectrum.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for analyzing the idempotency defect\n    of circulant projection operators.\n    \"\"\"\n\n    def calculate_defect(p: np.ndarray) -> float:\n        \"\"\"\n        Computes the idempotency defect from the projection's spectrum 'p'.\n        E(P) = ||p^2 - p||_2 / ||p||_2\n        \"\"\"\n        norm_p = np.linalg.norm(p)\n        if norm_p == 0.0:\n            # The zero matrix is idempotent, its defect is 0.\n            return 0.0\n        \n        # Element-wise operation for p^2 - p\n        p_err = np.square(p) - p\n        norm_p_err = np.linalg.norm(p_err)\n        \n        return norm_p_err / norm_p\n\n    def compute_defects_for_case(c_vec: np.ndarray, n: int, tau: float, seed: int) -> list[float]:\n        \"\"\"\n        Computes the triple of idempotency defects [naive, truncated, tikhonov]\n        for a given circulant generator vector 'c' and parameters.\n        \"\"\"\n        u = 2**-53\n        alpha = tau**2\n        rng = np.random.default_rng(seed)\n\n        # Ensure c_vec is the correct size and complex type\n        c_full = np.zeros(n, dtype=np.complex128)\n        c_full[:len(c_vec)] = c_vec\n        \n        # Compute spectrum lambda using unitary FFT, then scale to get eigenvalues\n        lambda_vec = np.fft.fft(c_full, norm=\"ortho\") * np.sqrt(n)\n        lambda_abs = np.abs(lambda_vec)\n\n        # --- 1. Naive reciprocal with amplified roundoff ---\n        xi = rng.standard_normal(n)\n        # The perturbation delta is real-valued, as per problem spec (real xi_k)\n        delta = xi * u * tau / np.maximum(lambda_abs, 1e-300)\n        \n        mu_tilde = np.zeros_like(lambda_vec)\n        \n        # Handle non-zero and zero lambda_k as per the definition\n        nonzero_mask = lambda_vec != 0\n        mu_tilde[nonzero_mask] = (1.0 / lambda_vec[nonzero_mask]) * (1.0 + delta[nonzero_mask])\n        \n        p_naive = mu_tilde * lambda_vec\n        defect_naive = calculate_defect(p_naive)\n\n        # --- 2. Truncated spectral pseudoinverse (hard thresholding) ---\n        mu_trunc = np.zeros_like(lambda_vec)\n        strong_mask = lambda_abs >= tau\n        mu_trunc[strong_mask] = 1.0 / lambda_vec[strong_mask]\n        \n        p_trunc = mu_trunc * lambda_vec\n        defect_trunc = calculate_defect(p_trunc)\n\n        # --- 3. Tikhonov-type smoothing ---\n        lambda_abs_sq = np.square(lambda_abs)\n        p_tikh = lambda_abs_sq / (lambda_abs_sq + alpha)\n        defect_tikh = calculate_defect(p_tikh)\n\n        return [defect_naive, defect_tikh, defect_trunc]\n\n    # Definition of test cases from the problem statement\n    test_cases = [\n        { # Case A: exact zero mode\n            \"n\": 8,\n            \"c\": np.array([2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]),\n            \"tau\": 1e-8,\n            \"seed\": 0\n        },\n        { # Case B: near-zero mode at frequency 0\n            \"n\": 12,\n            \"c\": np.array([1.0, -(1.0 - 1e-12)]),\n            \"tau\": 1e-8,\n            \"seed\": 1\n        },\n        { # Case C: discrete second-difference with many small frequencies\n            \"n\": 4096,\n            \"c\": np.array([1.0, -2.0, 1.0]),\n            \"tau\": 1e-5,\n            \"seed\": 2\n        },\n        { # Case D: well-conditioned identity circulant\n            \"n\": 5,\n            \"c\": np.array([1.0]),\n            \"tau\": 1e-8,\n            \"seed\": 3\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result_triple = compute_defects_for_case(case[\"c\"], case[\"n\"], case[\"tau\"], case[\"seed\"])\n        all_results.append(result_triple)\n\n    # Format the final output string exactly as required\n    # Creates a list of strings like '[-1.2, 3.4, -5.6]'\n    inner_lists_str = [str(res) for res in all_results] \n    # Joins them with commas and wraps in brackets\n    output_str = f\"[{','.join(inner_lists_str)}]\"\n    \n    # Replace spaces added by str() for a compact representation if needed, \n    # but the example implies spaces are acceptable. Let's match python's default `str` behavior.\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}