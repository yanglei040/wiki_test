## 引言
随着数据科学和机器学习的飞速发展，我们处理的数据日益复杂，呈现出多维度、多模态的特性。从视频分析、神经科学到[推荐系统](@entry_id:172804)，数据不再是简单的表格，而是具有丰富内部结构的高阶对象。传统的线性代数以矩阵（[二阶张量](@entry_id:199780)）为核心，虽功能强大，但在直接处理这些高维数据时却显得力不从心，强制将其“压平”为矩阵往往会破坏其固有的多维关联性，导致信息丢失。多线性代数，作为线性代数的自然推广，为我们理解和操作这些被称为“张量”的[多维数据](@entry_id:189051)提供了严谨的数学语言和强大的分析工具。

本文旨在系统地介绍多线性代数的基础知识，填补从标[准线性](@entry_id:637689)代数到[高阶张量](@entry_id:200122)分析之间的知识鸿沟。通过学习本文，您将掌握驾驭[多维数据](@entry_id:189051)的核心技能。文章将分为三个主要部分展开：

首先，在**“原理与机制”**一章中，我们将奠定理论基石。您将学习张量的形式化定义，理解其作为多维数组和抽象多[线性映射](@entry_id:185132)的双重本质。我们将引入“展开”（matricization）这一关键技术，它如同一座桥梁，将[高阶张量](@entry_id:200122)与我们熟悉的矩阵世界连接起来，并在此基础上深入探讨[张量秩](@entry_id:266558)的不同概念以及CANDECOMP/[PARAFAC](@entry_id:753095) (CP)分[解的唯一性](@entry_id:143619)奥秘。

接着，在**“应用与跨学科交叉”**一章中，我们将理论付诸实践。您将看到这些抽象的原理如何在信号处理、数据科学等领域大放异彩，用于[数据去噪](@entry_id:155449)、[模式识别](@entry_id:140015)和[异常检测](@entry_id:635137)。此外，我们还将探索张量理论与代数几何等纯数学领域的深刻联系，展示其理论深度和广度。

最后，在**“动手实践”**部分，我们提供了一系列精心设计的练习，旨在帮助您巩固对张量运算和分解的理解，将理论知识转化为解决实际计算问题的能力。

现在，让我们从多线性代数的核心原理出发，共同开启这段探索[高维数据](@entry_id:138874)结构奥秘的旅程。

## 原理与机制

本章在前一章介绍性概述的基础上，深入探讨了多线性代数的核心原理与机制。我们将从张量的基本定义出发，建立其作为多维数组和抽象多[线性映射](@entry_id:185132)的双重身份。随后，我们将引入“展开”（matricization）这一关键工具，它构成了连接[高阶张量](@entry_id:200122)与成熟的线性代数理论之间的桥梁。我们将展示如何利用展开来理解和执行张量运算，并阐明[张量秩](@entry_id:266558)的不同概念。最后，我们将探讨[张量分解](@entry_id:173366)，特别是CANDECOMP/[PARAFAC](@entry_id:753095) (CP)分[解的唯一性](@entry_id:143619)问题，揭示其背后深刻而精妙的数学结构。

### 张量：一种多线性对象

从最直观的层面来看，一个$N$阶张量$\mathcal{X}$可以被理解为一个$N$维数组，其元素由$N$个索引$i_1, i_2, \dots, i_N$来指定。我们用$\mathcal{X} \in \mathbb{R}^{I_1 \times I_2 \times \cdots \times I_N}$表示一个实数张量，其中$N$是张量的**阶 (order)**，第$n$个**模 (mode)** 的维度是$I_n$。

#### 形式化定义与坐标表示

尽管多维数组的观点在计算中非常实用，但一个更深刻、更根本的理解来自于将张量视为一个抽象的数学对象。形式上，一个$N$阶张量是$N$个[向量空间](@entry_id:151108)$V_1, \dots, V_N$的张量积空间$V_1 \otimes \dots \otimes V_N$中的一个元素。如果我们在每个[向量空间](@entry_id:151108)$V_n$中选择一组基$\{\mathbf{e}_i^{(n)}\}_{i=1}^{I_n}$，那么张量积空间$V_1 \otimes \dots \otimes V_N$的基就由所有可能的[基向量](@entry_id:199546)外积$\mathbf{e}_{i_1}^{(1)} \otimes \dots \otimes \mathbf{e}_{i_N}^{(N)}$构成。因此，任何张量$\mathcal{T} \in V_1 \otimes \dots \otimes V_N$都可以唯一地表示为这些基张量的[线性组合](@entry_id:154743)：
$$
\mathcal{T} = \sum_{i_1=1}^{I_1} \cdots \sum_{i_N=1}^{I_N} t_{i_1 \dots i_N} (\mathbf{e}_{i_1}^{(1)} \otimes \cdots \otimes \mathbf{e}_{i_N}^{(N)})
$$
这里的标量系数$t_{i_1 \dots i_N}$正是我们直观上所说的张量的“元素”，它们共同组成了一个$I_1 \times \dots \times I_N$的坐标数组。

这种抽象观点揭示了一个至关重要的对偶视角：张量可以被等同地视为一个多线性映射。对于[有限维向量空间](@entry_id:265491)，存在一个[典范同构](@entry_id:202335)（canonical isomorphism），它将张量空间$V_1 \otimes \dots \otimes V_N$与作用于[对偶空间](@entry_id:146945)乘积$V_1^* \times \dots \times V_N^*$上的多线性映射空间$\mathcal{L}(V_1^*, \dots, V_N^*; \mathbb{R})$等同起来 。这个同构是独立于基的选择而存在的，它源于[向量空间](@entry_id:151108)与其[二次对偶空间](@entry_id:264977)$V^{**}$之间的[典范同构](@entry_id:202335)。具体来说，一个纯张量$\mathbf{v}_1 \otimes \dots \otimes \mathbf{v}_N$对应于这样一个多[线性映射](@entry_id:185132)$\Phi$：它将一组[对偶向量](@entry_id:161217)（或称[余向量](@entry_id:157727)）$(\boldsymbol{\alpha}_1, \dots, \boldsymbol{\alpha}_N)$映射为一个标量，其值为每个[对偶向量](@entry_id:161217)作用于其对应原向量上所得标量的乘积：
$$
\Phi(\boldsymbol{\alpha}_1, \dots, \boldsymbol{\alpha}_N) = \prod_{n=1}^N \boldsymbol{\alpha}_n(\mathbf{v}_n)
$$
通过线性扩张，任何张量$\mathcal{T}$都对应一个唯一的多[线性映射](@entry_id:185132)$\Phi_{\mathcal{T}}$。

这个形式化的观点完美地解释了坐标的来源。如果我们考虑与基$\{\mathbf{e}_i^{(n)}\}$相对应的对偶基$\{\boldsymbol{\varepsilon}_i^{(n)}\}$（满足$\boldsymbol{\varepsilon}_i^{(n)}(\mathbf{e}_{i'}^{(n)}) = \delta_{ii'}$），并将$\Phi_{\mathcal{T}}$作用于对偶[基向量](@entry_id:199546)的特定组合上，我们就能精确地恢复张量的坐标 ：
$$
t_{i_1 \dots i_N} = \Phi_{\mathcal{T}}(\boldsymbol{\varepsilon}_{i_1}^{(1)}, \dots, \boldsymbol{\varepsilon}_{i_N}^{(N)})
$$
这表明，我们通常操作的那个数字数组，实际上是抽象张量在特定对偶基“网格”上求值的结果。

#### 纤维、切片与子张量

为了研究张量的内部结构，我们定义了一些重要的子结构。

- **纤维 (Fiber)**：通过固定除一个模以外的所有索引而得到的向量。例如，一个三阶张量$\mathcal{X}$的**模-1纤维**是通过固定索引$j$和$k$得到的向量$\mathcal{X}(:, j, k)$。

- **切片 (Slice)**：通过固定一个索引而得到的矩阵（即一个二阶张量）。例如，固定第三个索引为$k$得到的矩阵$\mathcal{X}(:, :, k)$是一个模-3切片。

- **子张量 (Subtensor)**：通过限制每个模的索引范围而得到的更小的张量。

这些概念可以通过一个具体的例子来加深理解。考虑一个由三个向量$\mathbf{a} \in \mathbb{R}^2$, $\mathbf{b} \in \mathbb{R}^3$, $\mathbf{c} \in \mathbb{R}^4$的外积定义的秩-1张量$\mathcal{X} = \mathbf{a} \circ \mathbf{b} \circ \mathbf{c} \in \mathbb{R}^{2 \times 3 \times 4}$，其元素为$\mathcal{X}_{ijk} = a_i b_j c_k$ 。

- **切片** $S = \mathcal{X}(:, 2, :)$ 是一个$2 \times 4$的矩阵。它的元素由$S_{ik} = \mathcal{X}_{i,2,k} = a_i b_2 c_k$给出。这可以看作是向量$\mathbf{a}$和$\mathbf{c}$的外积，并由标量$b_2$进行缩放，即$S = b_2 (\mathbf{a} \mathbf{c}^T)$。其[弗罗贝尼乌斯范数](@entry_id:143384)(Frobenius norm)为$\|S\|_F = |b_2| \|\mathbf{a}\|_2 \|\mathbf{c}\|_2$。

- **纤维** $\mathbf{f} = \mathcal{X}(:, 2, 3)$ 是一个$2 \times 1$的列向量（即模-1纤维）。它的元素由$f_i = \mathcal{X}_{i,2,3} = a_i b_2 c_3$给出。这个向量是向量$\mathbf{a}$被标量$b_2 c_3$缩放的结果，即$\mathbf{f} = (b_2 c_3) \mathbf{a}$。其[欧几里得范数](@entry_id:172687)(Euclidean norm)为$\|\mathbf{f}\|_2 = |b_2| |c_3| \|\mathbf{a}\|_2$。

从抽象的角度来看，一个切片，例如模-$n$切片$S_{i_n}$，可以被看作是原始张量$\mathcal{T}$与第$n$个对偶[基向量](@entry_id:199546)$\boldsymbol{\varepsilon}_{i_n}^{(n)}$进行**[张量缩并](@entry_id:193373) (tensor contraction)** 或部分配对的结果 。这个操作产生了一个$N-1$阶张量，其坐标恰好是原始张量坐标数组中第$n$个索引固定为$i_n$的那些元素。

### 展开（Matricization）：通往线性代数的桥梁

尽管张量具有丰富的多线性结构，但直接处理高阶对象在算法上可能非常复杂。**展开**，或称**[矩阵化](@entry_id:751739) (matricization)**，是一种极其强大的技术，它通过将张量的元素重新[排列](@entry_id:136432)成一个矩阵，从而允许我们应用线性代数中成熟的理论和工具。

#### 定义与目的

**模-$n$展开**（mode-$n$ unfolding）是将一个$N$阶张量$\mathcal{X} \in \mathbb{R}^{I_1 \times \cdots \times I_N}$转换为一个矩阵$X_{(n)}$的过程。最常用和最有用的一种约定是，将所有的模-$n$纤维作为矩阵的列。这产生一个大小为$I_n \times (\prod_{k \neq n} I_k)$的矩阵$X_{(n)}$ 。矩阵的$I_n$行对应于张量的第$n$个模，而$\prod_{k \neq n} I_k$列则对应于所有其他模的索引组合。为了完全确定展开，我们需要为这些列规定一个次序，通常使用字典序。

#### 展开与[基本子空间](@entry_id:190076)

展开操作的核心价值在于它揭示了张量的[基本子空间](@entry_id:190076)结构。

根据定义，$X_{(n)}$的列由$\mathcal{X}$的所有模-$n$纤维构成。因此，$X_{(n)}$的**[列空间](@entry_id:156444) (column space)**，记为$\mathrm{col}(X_{(n)})$，恰好是所有模-$n$纤维张成的[线性子空间](@entry_id:151815) 。这个[子空间](@entry_id:150286)是$\mathbb{R}^{I_n}$的一个[子空间](@entry_id:150286)。

这一发现使我们能够给出一个关于张量“秩”的关键定义。**多线性秩 (multilinear rank)**，也称为[塔克秩](@entry_id:756214) (Tucker rank)，是一个向量$(r_1, r_2, \dots, r_N)$，其中每一个分量$r_n$定义为模-$n$纤维所张成的[子空间](@entry_id:150286)的维度：
$$
r_n = \dim(\mathrm{span}\{\text{mode-}n\text{ fibers of }\mathcal{X}\})
$$
结合展开的定义，我们立即得到一个至关重要的关系：
$$
r_n = \dim(\mathrm{col}(X_{(n)})) = \mathrm{rank}(X_{(n)})
$$
换言之，张量的模-$n$多线性秩就是其模-$n$展开矩阵的秩。

根据线性代数的基本定理，一个矩阵的秩等于其非零[奇异值](@entry_id:152907)的数量。因此，$r_n$也等于$X_{(n)}$进行奇异值分解（SVD）后得到的非零奇异值的个数。这个结论是[高阶奇异值分解](@entry_id:197696)（[HOSVD](@entry_id:197696)）等算法的理论基石 。另一种理解方式是，与非零[奇异值](@entry_id:152907)相关的[左奇异向量](@entry_id:751233)构成了矩阵[列空间](@entry_id:156444)的一组标准正交基。这个基的向量数量（即[基数](@entry_id:754020)）定义了列空间的维度，也就是$r_n$ 。

#### 展开与张量运算

展开的真正威力在于它能够将复杂的多线性运算“线性化”，即转化为我们熟悉的矩阵运算。

**模-$n$积 (Mode-n Product)**
张量$\mathcal{X}$与一个矩阵$U \in \mathbb{R}^{J_n \times I_n}$的模-$n$积，记为$\mathcal{Y} = \mathcal{X} \times_n U$，是一个$I_1 \times \dots \times J_n \times \dots \times I_N$大小的张量，其定义为：
$$
\mathcal{Y}_{i_1 \dots j_n \dots i_N} = \sum_{i_n=1}^{I_n} \mathcal{X}_{i_1 \dots i_n \dots i_N} U_{j_n, i_n}
$$
这个操作的本质是，$\mathcal{X}$的每一个模-$n$纤维（一个$\mathbb{R}^{I_n}$中的向量）都被矩阵$U$左乘，变换为一个$\mathbb{R}^{J_n}$中的新向量。采用我们将模-$n$纤维作为列的展开约定，这个操作可以极其简洁地表示为 ：
$$
Y_{(n)} = U X_{(n)}
$$
这个优美的公式是“纤维作为列”这一约定之所以“自然”的根本原因。它将一个抽象的张量运算直接映射为一个简单的[矩阵乘法](@entry_id:156035)，这对于理论分析和算法实现都至关重要。

**[张量缩并](@entry_id:193373) (Tensor Contraction)**
类似地，展开也可以简化[张量缩并](@entry_id:193373)。考虑一个三阶张量$\mathcal{X} \in \mathbb{R}^{I \times J \times K}$与一个矩阵$Y \in \mathbb{R}^{J \times L}$沿着共享的第2个模进行的缩并，产生一个张量$\mathcal{Z} \in \mathbb{R}^{I \times L \times K}$，其元素由爱因斯坦求和约定 (Einstein summation convention) 给出：$\mathcal{Z}_{i\ell k} = \sum_j \mathcal{X}_{ijk} Y_{j\ell}$。如果我们对这个表达式进行模-2展开，可以推导出一个同样简洁的矩阵关系 ：
$$
Z_{(2)} = Y^T X_{(2)}
$$
这里，$X_{(2)} \in \mathbb{R}^{J \times IK}$ 和 $Z_{(2)} \in \mathbb{R}^{L \times IK}$ 分别是$\mathcal{X}$和$\mathcal{Z}$的模-2展开。这个恒等式再次展示了展开如何将一个涉及索引求和的复杂操作转化为一个矩阵乘积。这个关系进一步可以用于计算结果张量的范数，例如，$\|\mathcal{Z}\|_F^2 = \|\mathcal{Z}_{(2)}\|_F^2 = \mathrm{tr}(\mathcal{Z}_{(2)} \mathcal{Z}_{(2)}^T) = \mathrm{tr}(Y^T X_{(2)} X_{(2)}^T Y)$ 。

更一般地，任何通过索引求和定义的[张量网络](@entry_id:142149)缩并，原则上都可以通过展开和向量化 (vectorization) 转化为矩阵和[克罗内克积](@entry_id:182766) (Kronecker product) 的形式。例如，考虑表达式$Y_{i\ell} = \sum_{j,k} A_{ij} X_{jk} B_{\ell k}$，其中$A, X, B$是矩阵。通过索引操作，可以证明这等价于标准的[矩阵乘法](@entry_id:156035)$Y = AXB^T$。通过[向量化](@entry_id:193244)，这又可以表示为$\mathrm{vec}(Y) = (B \otimes A) \mathrm{vec}(X)$ 。这种在索引表示、矩阵表示和向量化表示之间的灵活转换，是现代张量计算的核心技能之一。这种转换也可以从[线性映射](@entry_id:185132)的角度来理解，例如，一个矩阵-向量乘积$y = X_{(1)}u$可以被解释为张量$\mathcal{X}$的切片与向量$u$的矩阵形式$B$之间的缩并 。

### [张量秩](@entry_id:266558)与分解

与[矩阵秩](@entry_id:153017)的概念相比，[张量的秩](@entry_id:204291)更为复杂，存在多种不等价的定义。

#### 秩-1张量

最基本的张量是**秩-1张量**，它可以表示为$N$个向量的[外积](@entry_id:147029)：
$$
\mathcal{X} = \mathbf{a}^{(1)} \circ \mathbf{a}^{(2)} \circ \cdots \circ \mathbf{a}^{(N)}
$$
其元素为$\mathcal{X}_{i_1 \dots i_N} = a_{i_1}^{(1)} a_{i_2}^{(2)} \cdots a_{i_N}^{(N)}$。秩-1张量具有非常特殊的结构。它的任何一个模-$n$纤维都是向量$\mathbf{a}^{(n)}$的标量倍。因此，所有模-$n$纤维张成的空间都是一维的（除非$\mathcal{X}$是零张量）。这意味着一个非零的秩-1张量的多线性秩恒为$(1, 1, \dots, 1)$ 。

#### CANDECOMP/[PARAFAC](@entry_id:753095) (CP)分解

张量最重要的性质之一是它的**[CP秩](@entry_id:748030)**（也称典范秩或[PARAFAC](@entry_id:753095)秩），记为$\mathrm{rank}(\mathcal{X})$。它被定义为将张量$\mathcal{X}$表示为秩-1张量之和所需的最少项数$R$：
$$
\mathcal{X} = \sum_{r=1}^R \mathbf{a}_r^{(1)} \circ \mathbf{a}_r^{(2)} \circ \cdots \circ \mathbf{a}_r^{(N)}
$$
这个表示被称为$\mathcal{X}$的**CANDECOMP/[PARAFAC](@entry_id:753095) (CP)分解**。收集每个模的向量分量，我们可以得到因子矩阵$A^{(n)} = [\mathbf{a}_1^{(n)} \cdots \mathbf{a}_R^{(n)}] \in \mathbb{R}^{I_n \times R}$。

必须强调，[CP秩](@entry_id:748030)$R$（一个标量）和多线性秩$(r_1, \dots, r_N)$（一个向量）是完全不同的概念。一个[CP秩](@entry_id:748030)为$R>1$的张量，其多线性秩可能远小于$R$。

[CP分解](@entry_id:203488)在展开后具有一个特殊的结构。$\mathcal{X}$的模-$n$展开可以表示为因子矩阵和[哈特里-拉奥积](@entry_id:751014) (Khatri-Rao product, $\odot$) 的形式：
$$
X_{(n)} = A^{(n)} (A^{(N)} \odot \cdots \odot A^{(n+1)} \odot A^{(n-1)} \odot \cdots \odot A^{(1)})^T
$$
[哈特里-拉奥积](@entry_id:751014)是矩阵的逐列克罗内克积。这个恒等式是分析[CP分解](@entry_id:203488)性质和开发相关算法的基础。

#### CP分[解的唯一性](@entry_id:143619)与不确定性

与矩阵分解（如SVD）不同，[CP分解](@entry_id:203488)在非常温和的条件下通常是**本质唯一 (essentially unique)** 的，这是它在数据分析中备受青睐的一个关键原因。然而，理解这种唯一性需要我们首先认识其固有的不确定性。

**1. [排列](@entry_id:136432)与缩放不确定性**：[CP分解](@entry_id:203488)的定义是一个求和式，因此求和的顺序无关紧要。这意味着我们可以任意[置换](@entry_id:136432)$R$个秩-1分量，而张量$\mathcal{X}$保持不变。这对应于同时对所有因子矩阵$A^{(n)}$的列进行相同的[排列](@entry_id:136432)。此外，对于任意一个秩-1分量$\mathbf{a}_r^{(1)} \circ \cdots \circ \mathbf{a}_r^{(N)}$，我们可以用一组标量$\lambda_1, \dots, \lambda_N$（满足$\prod_n \lambda_n = 1$）来缩放其因子向量，即$\tilde{\mathbf{a}}_r^{(n)} = \lambda_n \mathbf{a}_r^{(n)}$，其[外积](@entry_id:147029)结果不变。这些[排列](@entry_id:136432)和缩放的不确定性是CP模型的内在属性。在展开形式$X_{(n)} = A^{(n)} (C^{\setminus n})^T$中，这些不确定性表现为对因子矩阵$A^{(n)}$和$C^{\setminus n}$的变换，但这些变换的效果会相互抵消，使得最终的展开矩阵$X_{(n)}$保持不变 。

**2. 本质唯一性与Kruskal定理**：除上述平凡的不确定性外，[CP分解](@entry_id:203488)的因子矩阵在何种条件下是唯一的？答案由Kruskal定理给出。该定理引入了**k-秩 (k-rank)** 的概念。一个矩阵$M$的k-秩，记为$k_M$，是指该矩阵中任意$k$列都线性无关的最大整数$k$。

对于一个三阶张量，Kruskal的充分条件指出，如果其因子矩阵$A, B, C$的k-秩满足：
$$
k_A + k_B + k_C \ge 2R + 2
$$
那么该张量的[CP分解](@entry_id:203488)在去除[排列](@entry_id:136432)和缩放不确定性后是唯一的 。对于$N$阶张量，该条件推广为 $\sum_{n=1}^N k_n \ge 2R + N - 1$。

k-秩是一个比[标准矩阵](@entry_id:151240)秩更强的概念。一个矩阵可以有满的[矩阵秩](@entry_id:153017)，但k-秩可能很低（例如，如果它包含重复的列）。这一点解释了为什么仅仅考察展开矩阵的秩不足以保证CP分[解的唯一性](@entry_id:143619)。从展开式$X_{(n)} = A^{(n)} (C^{\setminus n})^T$可以看出，$\mathrm{rank}(X_{(n)}) \le R$是分解存在的必要条件，但这只是一个关于[矩阵秩](@entry_id:153017)的普通约束。它无法排除非唯一的可能性，因为矩阵分解本身就存在由[可逆矩阵](@entry_id:171829)$T$导致的不确定性（即$A^{(n)} (C^{\setminus n})^T = (A^{(n)}T)(T^{-1}C^{\setminus n})^T$）。CP分[解的唯一性](@entry_id:143619)来源于所有模的展开式所施加的**联合约束 (joint constraint)**，这种约束排除了任意可逆矩阵$T$的可能性，只留下了[排列](@entry_id:136432)和缩放。

我们可以构造一个具体的例子来阐明这一点 。考虑一个$2 \times 2 \times 2$张量，其[CP秩](@entry_id:748030)为$R=3$。通过精心选择因子矩阵$A, B, C \in \mathbb{R}^{2 \times 3}$，使得它们都具有满的[矩阵秩](@entry_id:153017)（即秩为2），并且它们的展开矩阵$X_{(1)}, X_{(2)}, X_{(3)}$也都是满秩的。然而，如果其中一个因子矩阵（例如$C$）包含两个相同的列，那么它的k-秩就只有1（即$k_C=1$）。此时，Kruskal条件$k_A + k_B + k_C \ge 2(3) + 2 = 8$无法满足。由于$C$中的两列相同，相应的两个秩-1分量可以在它们的公共[子空间](@entry_id:150286)中自由“混合”，从而产生无穷多组不同的因子矩阵，但它们生成的张量$\mathcal{X}$却是同一个。这个例子有力地证明了，即使所有展开都具有“良好”的秩属性，CP分[解的唯一性](@entry_id:143619)仍可能被破坏，其关键在于因子矩阵的更精细的[线性无关](@entry_id:148207)结构，而这正是由k-秩所刻画的。