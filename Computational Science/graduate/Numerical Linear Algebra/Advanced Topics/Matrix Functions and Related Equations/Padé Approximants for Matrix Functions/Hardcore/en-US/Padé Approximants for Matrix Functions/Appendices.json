{
    "hands_on_practices": [
        {
            "introduction": "To truly understand Padé approximants, we must start from the ground up. This first exercise guides you through the explicit construction of the well-known $[2/2]$ Padé approximant for the exponential function, $f(z) = e^z$, directly from its defining properties. By matching series coefficients, you will uncover the rational structure that provides a much higher order of accuracy than a simple Taylor polynomial of the same degree, a foundational concept that extends directly to matrix functions. ",
            "id": "3564074",
            "problem": "Let $f(z) = \\exp(z)$ denote the scalar exponential function, defined by its Taylor series $f(z) = \\sum_{k=0}^{\\infty} \\frac{z^{k}}{k!}$, and let $\\exp(A)$ for a square matrix $A$ be defined by the same series with $z$ replaced by $A$. The $[m/n]$ Padé approximant to a function $f(z)$ is the rational function $r_{mn}(z) = \\frac{p_{m}(z)}{q_{n}(z)}$ with $\\deg p_{m} \\leq m$, $\\deg q_{n} \\leq n$, $q_{n}(0) = 1$, such that the Maclaurin series of $q_{n}(z) f(z) - p_{m}(z)$ vanishes up to and including the term of order $z^{m+n}$.\n\nStarting only from these definitions, construct explicitly the $[2/2]$ Padé approximant $r_{22}(z)$ for $f(z) = \\exp(z)$ by determining the coefficients of $p_{2}(z)$ and $q_{2}(z)$ through series matching. Then, verify that the truncation error satisfies $\\exp(z) - r_{22}(z) = O(z^{5})$ as $z \\to 0$ by identifying the first nonzero term in the expansion of $q_{2}(z)\\exp(z) - p_{2}(z)$. Finally, explain why the same rational function $r_{22}(A)$ serves as an $O(\\|A\\|^{5})$ approximation to $\\exp(A)$ for matrices $A$ of sufficiently small norm in any consistent submultiplicative matrix norm, provided $q_{2}(A)$ is invertible.\n\nProvide the explicit rational function $r_{22}(z)$ as your final answer in closed form. No numerical rounding is required.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It is based on standard definitions from numerical analysis and approximation theory and presents a formalizable task with a unique solution.\n\nThe problem asks for the construction and verification of the $[2/2]$ Padé approximant to $f(z) = \\exp(z)$, and an explanation of its application to matrix exponentials.\n\nLet the $[2/2]$ Padé approximant be denoted by $r_{22}(z) = \\frac{p_{2}(z)}{q_{2}(z)}$.\nAccording to the problem definition, the degrees of the polynomials are $\\deg p_{2} \\leq 2$ and $\\deg q_{2} \\leq 2$. Let their forms be:\n$p_{2}(z) = a_0 + a_1 z + a_2 z^2$\n$q_{2}(z) = b_0 + b_1 z + b_2 z^2$\n\nThe normalization condition is $q_{2}(0) = 1$, which implies $b_0 = 1$. Thus, the denominator is $q_{2}(z) = 1 + b_1 z + b_2 z^2$.\n\nThe core defining property of the Padé approximant is that the series expansion of the error function $q_{n}(z)f(z) - p_{m}(z)$ has its leading terms equal to zero. For the $[2/2]$ case (with $m=2, n=2$), we require:\n$q_{2}(z) \\exp(z) - p_{2}(z) = C z^{m+n+1} + \\dots = O(z^{5})$\nThis means that the coefficients of the terms $z^0, z^1, z^2, z^3, z^4$ in the Maclaurin series of $q_{2}(z) \\exp(z) - p_{2}(z)$ must all be zero.\n\nFirst, we write out the Maclaurin series for $\\exp(z)$:\n$\\exp(z) = 1 + z + \\frac{z^2}{2!} + \\frac{z^3}{3!} + \\frac{z^4}{4!} + \\dots = 1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24} + O(z^5)$\n\nNext, we expand the product $q_{2}(z) \\exp(z)$:\n$q_{2}(z) \\exp(z) = (1 + b_1 z + b_2 z^2) \\left( 1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24} + O(z^5) \\right)$\n\nWe collect the coefficients of the powers of $z$ in this product, up to order $z^4$:\nCoefficient of $z^0$: $1$\nCoefficient of $z^1$: $1 + b_1$\nCoefficient of $z^2$: $\\frac{1}{2} + b_1 + b_2$\nCoefficient of $z^3$: $\\frac{1}{6} + \\frac{b_1}{2} + b_2$\nCoefficient of $z^4$: $\\frac{1}{24} + \\frac{b_1}{6} + \\frac{b_2}{2}$\n\nNow we enforce the condition $q_{2}(z)\\exp(z) - p_{2}(z) = O(z^5)$. This implies that $p_2(z)$ must be the polynomial part of the series for $q_2(z)\\exp(z)$ up to degree $2$, and the subsequent coefficients of $z^3$ and $z^4$ must be zero.\n\nMatching coefficients for $p_2(z) = a_0 + a_1 z + a_2 z^2$:\n- Coeff of $z^0$: $a_0 = 1$\n- Coeff of $z^1$: $a_1 = 1 + b_1$\n- Coeff of $z^2$: $a_2 = \\frac{1}{2} + b_1 + b_2$\n\nSetting the next two coefficients to zero to determine $b_1$ and $b_2$:\n- Coeff of $z^3$: $\\frac{1}{6} + \\frac{b_1}{2} + b_2 = 0$\n- Coeff of $z^4$: $\\frac{1}{24} + \\frac{b_1}{6} + \\frac{b_2}{2} = 0$\n\nThis is a system of two linear equations for $b_1$ and $b_2$:\n1. $\\frac{1}{2} b_1 + b_2 = -\\frac{1}{6}$\n2. $\\frac{1}{6} b_1 + \\frac{1}{2} b_2 = -\\frac{1}{24}$\n\nMultiply the second equation by $2$: $\\frac{1}{3} b_1 + b_2 = -\\frac{1}{12}$.\nSubtract this new equation from the first equation:\n$(\\frac{1}{2} b_1 - \\frac{1}{3} b_1) + (b_2 - b_2) = -\\frac{1}{6} - (-\\frac{1}{12})$\n$\\frac{3-2}{6} b_1 = -\\frac{2}{12} + \\frac{1}{12}$\n$\\frac{1}{6} b_1 = -\\frac{1}{12} \\implies b_1 = -\\frac{6}{12} = -\\frac{1}{2}$\n\nSubstitute $b_1 = -1/2$ into the first equation:\n$\\frac{1}{2} \\left(-\\frac{1}{2}\\right) + b_2 = -\\frac{1}{6}$\n$-\\frac{1}{4} + b_2 = -\\frac{1}{6} \\implies b_2 = \\frac{1}{4} - \\frac{1}{6} = \\frac{3-2}{12} = \\frac{1}{12}$\n\nNow we have the coefficients for $q_2(z)$: $b_1 = -1/2$ and $b_2 = 1/12$.\n$q_{2}(z) = 1 - \\frac{1}{2}z + \\frac{1}{12}z^2$\n\nWe can find the coefficients for $p_2(z)$:\n$a_0 = 1$\n$a_1 = 1 + b_1 = 1 - \\frac{1}{2} = \\frac{1}{2}$\n$a_2 = \\frac{1}{2} + b_1 + b_2 = \\frac{1}{2} - \\frac{1}{2} + \\frac{1}{12} = \\frac{1}{12}$\n\nThus, the numerator polynomial is:\n$p_{2}(z) = 1 + \\frac{1}{2}z + \\frac{1}{12}z^2$\n\nThe $[2/2]$ Padé approximant $r_{22}(z)$ for $\\exp(z)$ is therefore:\n$r_{22}(z) = \\frac{1 + \\frac{1}{2}z + \\frac{1}{12}z^2}{1 - \\frac{1}{2}z + \\frac{1}{12}z^2}$\n\nTo verify the truncation error, we identify the first nonzero term in the expansion of $q_{2}(z)\\exp(z) - p_{2}(z)$. By construction, the terms up to $z^4$ are zero. We compute the coefficient of $z^5$ in the product $q_{2}(z)\\exp(z)$:\nCoeff of $z^5$: (coeff $z^0$ in $q_2$) $\\cdot$ (coeff $z^5$ in $\\exp$) + (coeff $z^1$ in $q_2$) $\\cdot$ (coeff $z^4$ in $\\exp$) + (coeff $z^2$ in $q_2$) $\\cdot$ (coeff $z^3$ in $\\exp$)\n$= 1 \\cdot \\frac{1}{5!} + b_1 \\cdot \\frac{1}{4!} + b_2 \\cdot \\frac{1}{3!}$\n$= 1 \\cdot \\frac{1}{120} + \\left(-\\frac{1}{2}\\right) \\cdot \\frac{1}{24} + \\left(\\frac{1}{12}\\right) \\cdot \\frac{1}{6}$\n$= \\frac{1}{120} - \\frac{1}{48} + \\frac{1}{72}$\nThe least common multiple of $120$, $48$, and $72$ is $720$.\n$= \\frac{6}{720} - \\frac{15}{720} + \\frac{10}{720} = \\frac{6 - 15 + 10}{720} = \\frac{1}{720}$\n\nSo, $q_{2}(z)\\exp(z) - p_{2}(z) = \\frac{1}{720}z^5 + O(z^6)$.\nThe error of the Padé approximant itself is $\\exp(z) - r_{22}(z) = \\frac{q_2(z)\\exp(z) - p_2(z)}{q_2(z)}$.\nSince $q_2(z) \\to 1$ as $z \\to 0$, the error is:\n$\\exp(z) - r_{22}(z) = \\frac{\\frac{1}{720}z^5 + O(z^6)}{1 + O(z)} = \\frac{1}{720}z^5 + O(z^6)$.\nThis confirms that the error is indeed $O(z^5)$.\n\nFinally, we explain why $r_{22}(A)$ is an $O(\\|A\\|^5)$ approximation to $\\exp(A)$ for a square matrix $A$ with sufficiently small norm.\nThe definitions of $\\exp(A)$ and the polynomials $p_2(A)$ and $q_2(A)$ are given by substituting the matrix $A$ for the scalar $z$ in the respective series and polynomial expressions. The scalar identity $q_2(z)\\exp(z) - p_2(z) = \\frac{1}{720}z^5 + O(z^6)$ is an identity between convergent power series. This identity holds true when $z$ is replaced by a matrix $A$:\n$q_2(A)\\exp(A) - p_2(A) = \\frac{1}{720}A^5 + \\sum_{k=6}^{\\infty} c_k A^k$, where the series converges if $\\|A\\|$ is within the radius of convergence.\nSince $p_2(A)$, $q_2(A)$, and $\\exp(A)$ are all power series in $A$, they commute with each other. Thus, $\\exp(A)q_2(A) = q_2(A)\\exp(A)$.\nIf $q_2(A) = I - \\frac{1}{2}A + \\frac{1}{12}A^2$ is invertible, we can define $r_{22}(A) = p_2(A)[q_2(A)]^{-1}$.\nThe error is $\\exp(A) - r_{22}(A)$. We can write:\n$\\exp(A) - r_{22}(A) = [\\exp(A)q_2(A) - p_2(A)][q_2(A)]^{-1} = [q_2(A)\\exp(A) - p_2(A)][q_2(A)]^{-1}$\nSubstituting the series expansion for the error term:\n$\\exp(A) - r_{22}(A) = \\left( \\frac{1}{720}A^5 + \\sum_{k=6}^{\\infty} c_k A^k \\right) [q_2(A)]^{-1}$\nNow we take a consistent, submultiplicative matrix norm $\\| \\cdot \\|$:\n$\\|\\exp(A) - r_{22}(A)\\| \\leq \\left\\| \\frac{1}{720}A^5 + \\sum_{k=6}^{\\infty} c_k A^k \\right\\| \\cdot \\left\\| [q_2(A)]^{-1} \\right\\|$\nFor the first term, as $\\|A\\| \\to 0$:\n$\\left\\| \\frac{1}{720}A^5 + \\dots \\right\\| \\leq \\frac{1}{720}\\|A\\|^5 + \\sum_{k=6}^{\\infty} |c_k| \\|A\\|^k = O(\\|A\\|^5)$\nFor the inverse term, $q_2(A) = I - (\\frac{1}{2}A - \\frac{1}{12}A^2)$. If $\\|\\frac{1}{2}A - \\frac{1}{12}A^2\\|  1$, which is true for sufficiently small $\\|A\\|$, then $q_2(A)$ is invertible and its inverse can be represented by a convergent Neumann series. As $\\|A\\| \\to 0$, $q_2(A) \\to I$, so $\\|[q_2(A)]^{-1}\\| \\to \\|I\\| = 1$. This means $\\|[q_2(A)]^{-1}\\|$ is bounded for small $\\|A\\|$.\nCombining these results, we get:\n$\\|\\exp(A) - r_{22}(A)\\| \\leq O(\\|A\\|^5) \\cdot (\\text{a bounded quantity})$\nTherefore, $\\|\\exp(A) - r_{22}(A)\\| = O(\\|A\\|^5)$.",
            "answer": "$$\n\\boxed{\\frac{1 + \\frac{1}{2}z + \\frac{1}{12}z^2}{1 - \\frac{1}{2}z + \\frac{1}{12}z^2}}\n$$"
        },
        {
            "introduction": "Evaluating a function on a matrix is not always as simple as plugging it into a scalar formula, especially when the matrix is not diagonalizable. This practice explores the fascinating case of defective matrices by focusing on a Jordan block, the fundamental building block for such matrices. You will compute a rational function of a $3 \\times 3$ Jordan block and see how the derivatives of the scalar function explicitly determine the entries of the resulting matrix, revealing a deep connection between local analytic behavior and global matrix structure. ",
            "id": "3564125",
            "problem": "Let $A \\in \\mathbb{C}^{3 \\times 3}$ be a defective matrix with a single Jordan block of size $3$ for the eigenvalue $\\lambda = 0$, explicitly $A = J_{3}(0)$, where\n$$\nA = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  1 \\\\\n0  0  0\n\\end{pmatrix}.\n$$\nConsider the rational Padé approximant $r$ of the function $\\log(1+z)$ centered at $z=0$, defined by\n$$\nr(z) = \\frac{2z}{2+z}.\n$$\nUsing the definition of matrix functions via analytic continuation around the eigenvalue and the Jordan canonical structure, compute $r(A)$ and explicitly quantify how the derivatives $r^{(k)}(\\lambda)$ contribute to the entries of $r(A)$ for this $3 \\times 3$ Jordan block. Express your final answer as a single closed-form matrix expression. No rounding is required.",
            "solution": "The problem is valid as it is scientifically grounded in the theory of matrix functions, well-posed with all necessary information provided, and stated objectively. We can proceed with a formal solution.\n\nThe problem asks for the computation of $r(A)$, where $A$ is a $3 \\times 3$ Jordan block with eigenvalue $\\lambda=0$, and $r(z)$ is a given rational function. The definition of a function $f$ of a Jordan block $J_k(\\lambda) \\in \\mathbb{C}^{k \\times k}$ is given by a specific upper triangular Toeplitz matrix structure. For a Jordan block of size $k=3$ corresponding to an eigenvalue $\\lambda$, this definition is:\n$$\nf(J_3(\\lambda)) =\n\\begin{pmatrix}\nf(\\lambda)  \\frac{f^{(1)}(\\lambda)}{1!}  \\frac{f^{(2)}(\\lambda)}{2!} \\\\\n0  f(\\lambda)  \\frac{f^{(1)}(\\lambda)}{1!} \\\\\n0  0  f(\\lambda)\n\\end{pmatrix}\n$$\nThe entries of this matrix, $(f(J_3(\\lambda)))_{i,j}$, are determined by the derivatives of the function $f$ evaluated at the eigenvalue $\\lambda$. Specifically, for $j \\ge i$, the entry is given by $\\frac{f^{(j-i)}(\\lambda)}{(j-i)!}$.\n\nIn this problem, the matrix is $A = J_3(0)$, which means the block size is $k=3$ and the eigenvalue is $\\lambda=0$. The function is the rational Padé approximant $r(z) = \\frac{2z}{2+z}$. Therefore, to compute $r(A)$, we must evaluate $r(z)$ and its first two derivatives at $z=\\lambda=0$.\n\nThe matrix $r(A)$ will have the form:\n$$\nr(A) = r(J_3(0)) =\n\\begin{pmatrix}\nr(0)  r'(0)  \\frac{r''(0)}{2!} \\\\\n0  r(0)  r'(0) \\\\\n0  0  r(0)\n\\end{pmatrix}\n$$\nThis structure explicitly quantifies how the derivatives $r^{(k)}(\\lambda)$ contribute to the entries of $r(A)$. The diagonal entries are determined by $r(0)$, the first superdiagonal by $r'(0)$, and the second superdiagonal by $\\frac{r''(0)}{2}$.\n\nWe now compute the required derivatives of $r(z)$. It is convenient to first rewrite $r(z)$ using polynomial long division or algebraic manipulation:\n$$\nr(z) = \\frac{2z}{2+z} = \\frac{2(z+2) - 4}{z+2} = 2 - \\frac{4}{2+z} = 2 - 4(2+z)^{-1}\n$$\nThis form simplifies differentiation.\n\nFirst, we evaluate the function itself at $z=0$:\n$$\nr(0) = 2 - 4(2+0)^{-1} = 2 - \\frac{4}{2} = 2 - 2 = 0\n$$\n\nNext, we compute the first derivative, $r'(z)$:\n$$\nr'(z) = \\frac{d}{dz} \\left( 2 - 4(2+z)^{-1} \\right) = -4(-1)(2+z)^{-2} = 4(2+z)^{-2} = \\frac{4}{(2+z)^2}\n$$\nEvaluating at $z=0$:\n$$\nr'(0) = \\frac{4}{(2+0)^2} = \\frac{4}{4} = 1\n$$\n\nThen, we compute the second derivative, $r''(z)$:\n$$\nr''(z) = \\frac{d}{dz} \\left( 4(2+z)^{-2} \\right) = 4(-2)(2+z)^{-3} = -8(2+z)^{-3} = \\frac{-8}{(2+z)^3}\n$$\nEvaluating at $z=0$:\n$$\nr''(0) = \\frac{-8}{(2+0)^3} = \\frac{-8}{8} = -1\n$$\n\nNow we have all the components needed to construct the matrix $r(A)$. The required values are:\n- $r(0) = 0$\n- $r'(0) = 1$\n- $r''(0) = -1$\n- $2! = 2$\n\nSubstituting these values into the matrix structure for $r(J_3(0))$:\n$$\nr(A) =\n\\begin{pmatrix}\n0  1  \\frac{-1}{2} \\\\\n0  0  1 \\\\\n0  0  0\n\\end{pmatrix}\n$$\n\nThis is the final closed-form matrix expression for $r(A)$. As an alternative check, since $A$ is nilpotent with $A^3=0$, we can use the Taylor series expansion of $r(z)$ around $z=0$:\n$r(A) = r(0)I + r'(0)A + \\frac{r''(0)}{2!}A^2$.\nWith $A = \\begin{pmatrix} 0  1  0 \\\\ 0  0  1 \\\\ 0  0  0 \\end{pmatrix}$ and $A^2 = \\begin{pmatrix} 0  0  1 \\\\ 0  0  0 \\\\ 0  0  0 \\end{pmatrix}$, we get:\n$r(A) = 0 \\cdot I + 1 \\cdot A + \\frac{-1}{2} \\cdot A^2 = A - \\frac{1}{2}A^2$.\n$$\nr(A) = \\begin{pmatrix} 0  1  0 \\\\ 0  0  1 \\\\ 0  0  0 \\end{pmatrix} - \\frac{1}{2} \\begin{pmatrix} 0  0  1 \\\\ 0  0  0 \\\\ 0  0  0 \\end{pmatrix} = \\begin{pmatrix} 0  1  -\\frac{1}{2} \\\\ 0  0  1 \\\\ 0  0  0 \\end{pmatrix}\n$$\nThis confirms our result.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0  1  -\\frac{1}{2} \\\\\n0  0  1 \\\\\n0  0  0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While knowing how to construct a Padé approximant is essential, a critical question in practice is *which* approximant offers the best accuracy for a specific matrix $A$. This advanced exercise tackles this problem by developing an adaptive algorithm. You will learn to use the matrix's numerical range—a set that contains its eigenvalues—to define a region in the complex plane over which the approximation must be accurate, and then select the optimal Padé order from a set of candidates to minimize the uniform error. ",
            "id": "3564070",
            "problem": "You are given the task of designing and implementing an adaptive procedure for selecting a Padé approximant order that uniformly approximates the complex exponential over an ellipse that encloses the numerical range. The foundational base for this task consists of the following well-tested definitions and facts from numerical linear algebra and complex analysis.\n\n- The numerical range (also called the field of values) of a matrix $A \\in \\mathbb{C}^{n \\times n}$ is $W(A) = \\{ x^{*} A x : x \\in \\mathbb{C}^{n}, \\|x\\|_{2} = 1 \\}$. It is a convex set. If $H = (A + A^{*}) / 2$ and $K = (A - A^{*}) / (2 i)$ are the Hermitian and skew-Hermitian parts of $A$, then for any unit vector $x$, $\\operatorname{Re}(x^{*} A x) = x^{*} H x$ and $\\operatorname{Im}(x^{*} A x) = x^{*} K x$. Therefore, the real axis projection of $W(A)$ lies in the interval $[\\lambda_{\\min}(H), \\lambda_{\\max}(H)]$, and the imaginary axis projection lies in $[\\lambda_{\\min}(K), \\lambda_{\\max}(K)]$, where $\\lambda_{\\min}(\\cdot)$ and $\\lambda_{\\max}(\\cdot)$ denote the smallest and largest eigenvalues of a Hermitian matrix.\n\n- The complex exponential function $e^{z}$ is entire (analytic on $\\mathbb{C}$). A Padé approximant $r_{m,n}(z)$ is a rational function with a numerator of degree at most $m$ and a denominator of degree at most $n$, constructed to match the Maclaurin series of $e^{z}$ to the highest possible order.\n\nYour goal is to construct an axis-aligned ellipse $\\mathcal{E}$ that encloses $W(A)$, based on the intervals above, and then adaptively select integers $m, n \\in \\mathbb{N}$ from a prescribed candidate set to minimize the uniform approximation error of the scalar complex exponential by $r_{m,n}$ on $\\mathcal{E}$. The uniform error target is\n$$\n\\max_{z \\in \\mathcal{E}} \\left| e^{z} - r_{m,n}(z) \\right|.\n$$\n\nThe design constraints are:\n\n- Use the Hermitian and skew-Hermitian parts $H$ and $K$ of the given matrix $A$ to bound $\\operatorname{Re}(W(A))$ and $\\operatorname{Im}(W(A))$ by intervals. Let $a = (\\lambda_{\\max}(H) - \\lambda_{\\min}(H))/2$, $b = (\\lambda_{\\max}(K) - \\lambda_{\\min}(K))/2$, and the center $c = \\left( \\lambda_{\\min}(H) + \\lambda_{\\max}(H) \\right)/2 + i \\left( \\lambda_{\\min}(K) + \\lambda_{\\max}(K) \\right)/2$. Construct the axis-aligned ellipse with semiaxes $\\alpha = \\sqrt{2} \\, a$ and $\\beta = \\sqrt{2} \\, b$ and center $c$, defined parametrically as $z(\\theta) = c + \\alpha \\cos \\theta + i \\, \\beta \\sin \\theta$ for $\\theta \\in [0, 2\\pi)$. This ellipse encloses the rectangle $[\\lambda_{\\min}(H), \\lambda_{\\max}(H)] + i[\\lambda_{\\min}(K), \\lambda_{\\max}(K)]$ and thus encloses $W(A)$.\n\n- Construct $r_{m,n}(z)$ strictly from the Maclaurin series coefficients of $e^{z}$, namely $c_{k} = 1/k!$, using the defining Padé relations without assuming any pretabulated special cases: $r_{m,n}$ must be derived by enforcing that the Taylor expansion of $e^{z} q(z) - p(z)$ has vanishing coefficients from $z^{m+1}$ through $z^{m+n}$, with $q(0) = 1$, $\\deg(p) \\le m$, and $\\deg(q) \\le n$.\n\n- Approximate the uniform error by sampling points along the boundary of $\\mathcal{E}$; justify your sampling choice based on the analytic properties involved. Ensure robust handling when any semiaxis is zero (degenerating $\\mathcal{E}$ to a line segment or a point).\n\n- From a given finite candidate set $\\mathcal{S}$ of pairs $(m,n)$, select the pair that minimizes the approximated uniform error over $\\mathcal{E}$.\n\nImplement a complete program that performs this adaptive selection for each matrix in the test suite below. No external input is permitted; the program must define the test cases internally. The test suite is:\n\n- Test case $1$: $A_{1} = \\begin{bmatrix} 0  4  -1 \\\\ 0  -2  2 \\\\ 1  0  1 \\end{bmatrix} + i \\begin{bmatrix} 0  0.5  0 \\\\ -0.5  0  0.25 \\\\ 0  -0.25  0 \\end{bmatrix}$.\n\n- Test case $2$: $A_{2} = \\begin{bmatrix} 2  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  2 \\end{bmatrix}$.\n\n- Test case $3$: $A_{3} = i \\begin{bmatrix} 0  2  0 \\\\ -2  0  3 \\\\ 0  -3  0 \\end{bmatrix}$.\n\n- Test case $4$: $A_{4} = \\begin{bmatrix} 5  10  0 \\\\ -3  -7  4 \\\\ 0  1  0 \\end{bmatrix} + i \\begin{bmatrix} 0  0  6 \\\\ 0  0  0 \\\\ -6  0  0 \\end{bmatrix}$.\n\nUse the candidate set $\\mathcal{S} = \\{ (2,2), (3,3), (4,4), (5,5), (6,6), (7,7), (8,8), (4,6), (6,4) \\}$, and approximate the uniform error by sampling $N = 512$ points uniformly spaced on the parameter $\\theta \\in [0, 2\\pi)$ for the ellipse boundary. If both semiaxes are zero, take $N = 1$ point at $z = c$.\n\nFor each test case, your program must output the selected pair $[m,n]$ that minimizes the approximated uniform error. The final output format must be a single line containing the results as a comma-separated list enclosed in square brackets, where each element is the pair for a test case, represented as a list of two integers. For example, the format should be $[[m_{1},n_{1}], [m_{2},n_{2}], [m_{3},n_{3}], [m_{4},n_{4}]]$. No additional text or lines may be printed.",
            "solution": "We begin from the definitions and properties of the numerical range and the Padé approximant. For a matrix $A \\in \\mathbb{C}^{n \\times n}$, the numerical range is $W(A) = \\{ x^{*} A x : x \\in \\mathbb{C}^{n}, \\|x\\|_{2} = 1 \\}$. Writing $A$ as $A = H + i K$, where $H = (A + A^{*})/2$ and $K = (A - A^{*})/(2 i)$ are Hermitian matrices, we have for any unit vector $x$ that $\\operatorname{Re}(x^{*} A x) = x^{*} H x$ and $\\operatorname{Im}(x^{*} A x) = x^{*} K x$. The Rayleigh quotient characterization implies $x^{*} H x \\in [\\lambda_{\\min}(H), \\lambda_{\\max}(H)]$ and $x^{*} K x \\in [\\lambda_{\\min}(K), \\lambda_{\\max}(K)]$, hence $W(A)$ lies within the axis-aligned rectangle\n$$\n[\\lambda_{\\min}(H), \\lambda_{\\max}(H)] + i \\, [\\lambda_{\\min}(K), \\lambda_{\\max}(K)].\n$$\nLet $a = (\\lambda_{\\max}(H) - \\lambda_{\\min}(H))/2$ and $b = (\\lambda_{\\max}(K) - \\lambda_{\\min}(K))/2$, and the center\n$$\nc = \\frac{\\lambda_{\\min}(H) + \\lambda_{\\max}(H)}{2} + i \\, \\frac{\\lambda_{\\min}(K) + \\lambda_{\\max}(K)}{2}.\n$$\nWe construct an axis-aligned ellipse $\\mathcal{E}$ that encloses this rectangle by choosing semiaxes $\\alpha = \\sqrt{2} \\, a$ and $\\beta = \\sqrt{2} \\, b$, and parameterizing the boundary by\n$$\nz(\\theta) = c + \\alpha \\cos \\theta + i \\, \\beta \\sin \\theta, \\quad \\theta \\in [0, 2\\pi).\n$$\nTo see that this ellipse encloses the rectangle, consider any corner point of the rectangle relative to its center: it has coordinates $(\\pm a, \\pm b)$. In the scaled ellipse coordinates, the quadratic form evaluates to\n$$\n\\frac{(\\pm a)^{2}}{\\alpha^{2}} + \\frac{(\\pm b)^{2}}{\\beta^{2}} = \\frac{a^{2}}{2 a^{2}} + \\frac{b^{2}}{2 b^{2}} = 1,\n$$\nwhich places the rectangle corners on the ellipse boundary; thus, the entire rectangle lies within or on the ellipse.\n\nNext, we recall the construction of the Padé approximant $r_{m,n}$ to the complex exponential. Let $f(z) = e^{z} = \\sum_{k=0}^{\\infty} c_{k} z^{k}$ with $c_{k} = 1/k!$. A Padé approximant of type $(m,n)$ is a rational function $r_{m,n}(z) = p(z)/q(z)$ with $\\deg(p) \\le m$, $\\deg(q) \\le n$, and $q(0) = 1$, such that the Maclaurin series of $f(z) q(z) - p(z)$ has zero coefficients from $z^{m+1}$ through $z^{m+n}$. Let $q(z) = 1 + q_{1} z + \\cdots + q_{n} z^{n}$. The coefficient of $z^{k}$ in $f(z) q(z)$ is $\\sum_{j=0}^{\\min(k,n)} q_{j} c_{k-j}$, with $q_{0} = 1$. Enforcing vanishing of the coefficients for $k = m+1, \\ldots, m+n$ yields the linear system\n$$\n\\sum_{j=1}^{n} c_{m+i-j} \\, q_{j} = - c_{m+i}, \\quad i = 1,2,\\ldots,n.\n$$\nSolving for $(q_{1}, \\ldots, q_{n})$ gives the denominator coefficients together with $q_{0} = 1$. The numerator coefficients are recovered by truncating $f(z) q(z)$ to degree $m$:\n$$\np_{k} = \\sum_{j=0}^{\\min(k,n)} q_{j} c_{k-j}, \\quad k = 0,1,\\ldots,m.\n$$\nThis construction emerges directly from the defining conditions of the Padé approximant and the Maclaurin series without recourse to any special-case shortcuts.\n\nWe now define the uniform approximation error of $r_{m,n}$ to $e^{z}$ over the ellipse $\\mathcal{E}$:\n$$\nE_{m,n} = \\max_{z \\in \\mathcal{E}} \\left| e^{z} - r_{m,n}(z) \\right|.\n$$\nBy the maximum modulus principle for analytic functions, if $r_{m,n}$ has no poles within or on $\\mathcal{E}$, the maximum of $\\left| e^{z} - r_{m,n}(z) \\right|$ over the compact, simply connected region bounded by $\\mathcal{E}$ occurs on its boundary. Even when poles are present outside but near the ellipse, sampling the boundary provides a reasonable numerical proxy for the uniform error over the region. Therefore, we approximate $E_{m,n}$ by uniform sampling of $\\theta$ on $[0, 2\\pi)$ and evaluating the maximum pointwise error over the sampled points on the ellipse boundary. Robustness considerations include guarding against near-zero values of $q(z)$ on sampled points by declaring a large error when $|q(z)|$ is below a small threshold, ensuring that potential numerical instabilities in evaluating $r_{m,n}$ do not mislead the selection.\n\nFor degenerate cases where $\\alpha = 0$ and/or $\\beta = 0$, the ellipse collapses to a line segment or a single point. The parameterization $z(\\theta) = c + \\alpha \\cos \\theta + i \\, \\beta \\sin \\theta$ still generates the correct boundary points. If both $\\alpha = 0$ and $\\beta = 0$, the set $\\mathcal{E}$ is the point $\\{c\\}$, and we sample only $z = c$.\n\nThe adaptive selection procedure is:\n\n- For a given $A$, compute $H = (A + A^{*})/2$ and $K = (A - A^{*})/(2 i)$.\n\n- Compute $\\lambda_{\\min}(H)$, $\\lambda_{\\max}(H)$, $\\lambda_{\\min}(K)$, and $\\lambda_{\\max}(K)$.\n\n- Form $a$, $b$, $c$, and $\\alpha = \\sqrt{2} a$, $\\beta = \\sqrt{2} b$.\n\n- For each $(m,n)$ in the candidate set $\\mathcal{S}$, construct $r_{m,n}(z)$ from the Maclaurin series coefficients $c_{k} = 1/k!$ using the Padé defining system, evaluate the sampled uniform error over the ellipse boundary, and record the maximum error.\n\n- Select the $(m,n)$ that minimizes the recorded maximum error.\n\nThe program implements this selection for the four prescribed test matrices. For each test case, it outputs the selected $[m,n]$ pair. The final output is a single line in the format\n$$\n[[m_{1},n_{1}], [m_{2},n_{2}], [m_{3},n_{3}], [m_{4},n_{4}]],\n$$\nwith no extra lines or text. This approach adheres to the core definitions of numerical range and Padé approximants and applies well-tested principles to yield a practical algorithm for adaptive order selection in rational approximation of matrix functions.",
            "answer": "```python\nimport numpy as np\n\ndef pade_exp_coeffs(m: int, n: int):\n    \"\"\"\n    Construct the Pade approximant [m/n] to exp(z) from its Maclaurin series.\n    Returns numerator and denominator coefficients in ascending powers.\n    \"\"\"\n    # Series coefficients c_k = 1/k! up to m+n\n    total_deg = m + n\n    c = np.empty(total_deg + 1, dtype=np.float64)\n    c[0] = 1.0\n    for k in range(1, total_deg + 1):\n        c[k] = c[k - 1] / k  # 1/k! via recursion\n\n    if n == 0:\n        # Pure polynomial case: numerator is truncated series, denominator is 1\n        p = c[:m + 1].copy()\n        q = np.array([1.0], dtype=np.float64)\n        return p, q\n\n    # Build linear system for q1..qn enforcing vanishing of coefficients m+1..m+n\n    # Sum_{j=1..n} c[m+i - j] q_j = -c[m+i], for i=1..n\n    A = np.empty((n, n), dtype=np.float64)\n    b = np.empty(n, dtype=np.float64)\n    for i in range(1, n + 1):\n        b[i - 1] = -c[m + i]\n        for j in range(1, n + 1):\n            A[i - 1, j - 1] = c[m + i - j]\n    # Solve for q1..qn\n    try:\n        q_tail = np.linalg.solve(A, b)\n    except np.linalg.LinAlgError:\n        # Ill-conditioned or singular; fallback to least squares\n        q_tail, *_ = np.linalg.lstsq(A, b, rcond=None)\n    q = np.concatenate(([1.0], q_tail))\n\n    # Numerator p_k = sum_{j=0..min(k,n)} q_j * c[k-j], for k=0..m\n    p = np.empty(m + 1, dtype=np.float64)\n    for k in range(0, m + 1):\n        jmax = min(k, n)\n        s = 0.0\n        for j in range(0, jmax + 1):\n            s += q[j] * c[k - j]\n        p[k] = s\n\n    return p, q\n\ndef eval_rational(p_coefs_asc, q_coefs_asc, z):\n    \"\"\"\n    Evaluate r(z) = p(z)/q(z) where p and q are given by ascending-power coefficients.\n    z may be scalar or vector (numpy).\n    \"\"\"\n    # Convert to descending-power order for numpy.polyval\n    p_desc = p_coefs_asc[::-1]\n    q_desc = q_coefs_asc[::-1]\n    # Use numpy.polyval for complex z\n    pz = np.polyval(p_desc, z)\n    qz = np.polyval(q_desc, z)\n    return pz / qz, qz\n\ndef ellipse_params_from_matrix(A):\n    \"\"\"\n    Compute ellipse parameters (center c, semiaxes alpha, beta) that enclose W(A),\n    using bounds from Hermitian and skew-Hermitian parts.\n    \"\"\"\n    H = (A + A.conj().T) / 2.0\n    K = (A - A.conj().T) / (2.0j)\n    # Eigenvalues of Hermitian matrices are real\n    lamH = np.linalg.eigvalsh(H)\n    lamK = np.linalg.eigvalsh(K)\n    lamH_min = np.min(lamH).real\n    lamH_max = np.max(lamH).real\n    lamK_min = np.min(lamK).real\n    lamK_max = np.max(lamK).real\n    a = (lamH_max - lamH_min) / 2.0\n    b = (lamK_max - lamK_min) / 2.0\n    c = (lamH_min + lamH_max) / 2.0 + 1j * (lamK_min + lamK_max) / 2.0\n    alpha = np.sqrt(2.0) * a\n    beta = np.sqrt(2.0) * b\n    return c, alpha, beta\n\ndef max_uniform_error_on_ellipse(m, n, c, alpha, beta, N=512, q_eps=1e-14):\n    \"\"\"\n    Approximate max_{z in ellipse} |exp(z) - r_{m,n}(z)| by sampling N points on ellipse boundary.\n    If both semiaxes are zero, sample the single point z=c.\n    \"\"\"\n    p, q = pade_exp_coeffs(m, n)\n    if alpha == 0.0 and beta == 0.0:\n        z = np.array([c], dtype=np.complex128)\n    else:\n        thetas = np.linspace(0.0, 2.0 * np.pi, num=N, endpoint=False, dtype=np.float64)\n        z = c + alpha * np.cos(thetas) + 1j * beta * np.sin(thetas)\n    rz, qz = eval_rational(p, q, z)\n    ez = np.exp(z)\n    # Guard against near-zero denominator\n    mask_bad = np.abs(qz)  q_eps\n    err = np.abs(ez - rz)\n    if np.any(mask_bad):\n        # Assign a large penalty to points near poles\n        err[mask_bad] = np.inf\n    return float(np.max(err))\n\ndef adaptive_select_pade_order(A, candidates, N=512):\n    c, alpha, beta = ellipse_params_from_matrix(A)\n    best_pair = None\n    best_err = np.inf\n    for (m, n) in candidates:\n        err = max_uniform_error_on_ellipse(m, n, c, alpha, beta, N=N)\n        if err  best_err:\n            best_err = err\n            best_pair = (m, n)\n    return best_pair\n\ndef solve():\n    # Define test cases matrices (complex where specified)\n    A1_real = np.array([[0.0, 4.0, -1.0],\n                        [0.0, -2.0, 2.0],\n                        [1.0, 0.0, 1.0]], dtype=np.float64)\n    A1_imag = np.array([[0.0, 0.5, 0.0],\n                        [-0.5, 0.0, 0.25],\n                        [0.0, -0.25, 0.0]], dtype=np.float64)\n    A1 = A1_real + 1j * A1_imag\n\n    A2 = np.array([[2.0, -1.0, 0.0],\n                   [-1.0, 2.0, -1.0],\n                   [0.0, -1.0, 2.0]], dtype=np.float64)\n\n    A3_base = np.array([[0.0, 2.0, 0.0],\n                        [-2.0, 0.0, 3.0],\n                        [0.0, -3.0, 0.0]], dtype=np.float64)\n    A3 = 1j * A3_base\n\n    A4_real = np.array([[5.0, 10.0, 0.0],\n                        [-3.0, -7.0, 4.0],\n                        [0.0, 1.0, 0.0]], dtype=np.float64)\n    A4_imag = np.array([[0.0, 0.0, 6.0],\n                        [0.0, 0.0, 0.0],\n                        [-6.0, 0.0, 0.0]], dtype=np.float64)\n    A4 = A4_real + 1j * A4_imag\n\n    test_cases = [A1, A2, A3, A4]\n\n    candidates = [(2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (4, 6), (6, 4)]\n    N = 512\n\n    results = []\n    for A in test_cases:\n        m, n = adaptive_select_pade_order(A, candidates, N=N)\n        results.append([m, n])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}