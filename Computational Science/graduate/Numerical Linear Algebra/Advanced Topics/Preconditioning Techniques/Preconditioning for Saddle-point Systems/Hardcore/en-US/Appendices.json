{
    "hands_on_practices": [
        {
            "introduction": "Understanding preconditioning begins with hands-on practice. This first exercise guides you through the process of constructing a saddle-point system from scratch for a mixed-discretized Poisson equation, a fundamental model problem. By implementing and testing different block-diagonal preconditioners, you will compute the eigenvalues of the resulting operators and directly observe how the quality of the Schur complement approximation impacts spectral clustering, a key factor for iterative solver performance .",
            "id": "3566630",
            "problem": "Design and implement a complete, runnable program that constructs a discrete mixed formulation of the Poisson equation on a uniform $2\\times 2$ Cartesian grid using a lowest-order mixed method with flux unknowns located on interior edges and cell-centered pressures. Your objective is to assemble a symmetric saddle-point matrix, define three block-diagonal preconditioners, and compute the eigenvalues of the symmetrically preconditioned operator to illustrate spectral clustering.\n\nBegin from the following fundamental base:\n- The mixed formulation of the Poisson equation introduces a flux variable $\\boldsymbol{q}$ and a scalar pressure $u$ satisfying $ \\boldsymbol{q} + \\nabla u = \\boldsymbol{0}$ and $ \\nabla \\cdot \\boldsymbol{q} = g$, which after discretization yields a symmetric saddle-point system of the form\n$$\n\\begin{bmatrix}\n\\boldsymbol{M}  \\boldsymbol{B}^{\\top} \\\\\n\\boldsymbol{B}  \\boldsymbol{0}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\boldsymbol{q} \\\\\n\\boldsymbol{u}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\boldsymbol{f} \\\\\n\\boldsymbol{g}\n\\end{bmatrix},\n$$\nwhere $\\boldsymbol{M}$ is a symmetric positive definite (SPD) flux mass matrix and $\\boldsymbol{B}$ is a discrete divergence operator.\n- Preconditioning uses a block-diagonal SPD matrix $\\boldsymbol{P} = \\operatorname{diag}(\\boldsymbol{M}, \\boldsymbol{S}_{\\text{approx}})$, where $\\boldsymbol{S}_{\\text{approx}}$ is an SPD approximation to the Schur complement $\\boldsymbol{S} = \\boldsymbol{B}\\,\\boldsymbol{M}^{-1}\\boldsymbol{B}^{\\top}$.\n\nUse a uniform grid on the unit square with $2\\times 2$ cells. Treat only interior edge fluxes as unknowns (zero normal flux on boundary edges), and enforce a zero-mean pressure by removing one cell pressure degree of freedom to eliminate the nullspace. Index the four cells as $c_0$ (bottom-left), $c_1$ (bottom-right), $c_2$ (top-left), and $c_3$ (top-right). Index the four interior edges as follows:\n- $e_0$: vertical edge between $c_0$ and $c_1$ with positive orientation from $c_0$ to $c_1$,\n- $e_1$: vertical edge between $c_2$ and $c_3$ with positive orientation from $c_2$ to $c_3$,\n- $e_2$: horizontal edge between $c_0$ and $c_2$ with positive orientation from $c_0$ to $c_2$,\n- $e_3$: horizontal edge between $c_1$ and $c_3$ with positive orientation from $c_1$ to $c_3$.\n\nLet the flux mass matrix be $\\boldsymbol{M}=\\boldsymbol{I}_{4}$ (identity on the $4$ interior edges). Construct the discrete divergence $\\boldsymbol{B}\\in\\mathbb{R}^{3\\times 4}$ by removing the equation for $c_3$ to enforce the zero-mean constraint, with columns corresponding to edges $(e_0,e_1,e_2,e_3)$ and rows corresponding to cells $(c_0,c_1,c_2)$:\n- For $e_0$ (between $c_0$ and $c_1$): place $+1$ in the row of $c_0$ and $-1$ in the row of $c_1$,\n- For $e_1$ (between $c_2$ and $c_3$): place $+1$ in the row of $c_2$,\n- For $e_2$ (between $c_0$ and $c_2$): place $+1$ in the row of $c_0$ and $-1$ in the row of $c_2$,\n- For $e_3$ (between $c_1$ and $c_3$): place $+1$ in the row of $c_1$.\n\nAssemble the saddle-point matrix\n$$\n\\boldsymbol{K}=\n\\begin{bmatrix}\n\\boldsymbol{M}  \\boldsymbol{B}^{\\top} \\\\\n\\boldsymbol{B}  \\boldsymbol{0}\n\\end{bmatrix}\n\\in \\mathbb{R}^{7\\times 7}.\n$$\n\nDefine three block-diagonal SPD preconditioners\n$$\n\\boldsymbol{P}=\\operatorname{diag}(\\boldsymbol{M},\\boldsymbol{S}_{\\text{approx}}),\n$$\ncorresponding to the following test suite of Schur complement approximations $\\boldsymbol{S}_{\\text{approx}}$:\n- Test $1$: the exact Schur complement $\\boldsymbol{S}=\\boldsymbol{B}\\,\\boldsymbol{M}^{-1}\\boldsymbol{B}^{\\top}$,\n- Test $2$: the Jacobi approximation $\\boldsymbol{S}_{\\text{diag}}=\\operatorname{diag}(\\boldsymbol{S})$,\n- Test $3$: the pressure mass approximation $\\boldsymbol{S}_{\\text{mass}}=(h^2)\\,\\boldsymbol{I}_{3}$ with $h=1/2$ the cell width, so $\\boldsymbol{S}_{\\text{mass}}=\\frac{1}{4}\\,\\boldsymbol{I}_{3}$.\n\nFor each test, compute the real eigenvalues of the symmetrically preconditioned operator\n$$\n\\boldsymbol{C} = \\boldsymbol{P}^{-1/2}\\,\\boldsymbol{K}\\,\\boldsymbol{P}^{-1/2},\n$$\nwhere the symmetric square root and inverse square root of $\\boldsymbol{P}$ are taken blockwise, using the spectral decomposition for the pressure block. Sort the eigenvalues in ascending order.\n\nYour program must implement the above construction, perform the three tests, and output the lists of eigenvalues (as floating-point numbers). There are no physical units to report. Angles are not used. Percentages are not used.\n\nTest Suite:\n- Input is implicit; construct and evaluate the three cases corresponding to test identifiers $1,2,3$ as defined above.\n\nExpected Output Type and Format:\n- For each test case, produce the sorted list of eigenvalues as a list of floating-point numbers.\n- Aggregate the three lists into a single line of output as a JSON-like nested list without spaces, for example, $[ [\\cdot],[\\cdot],[\\cdot] ]$ but without spaces after commas.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each eigenvalue formatted as a floating-point number (e.g., $-1.00000000$). Precisely: the program must print a single line of the form $[[\\text{vals\\_for\\_test\\_1}],[\\text{vals\\_for\\_test\\_2}],[\\text{vals\\_for\\_test\\_3}]]$ with no extra text.",
            "solution": "The problem is valid. It presents a well-defined numerical linear algebra task grounded in the established theory of preconditioning for saddle-point systems arising from mixed finite element methods. All necessary data and definitions are provided, and the problem is self-contained, consistent, and scientifically sound.\n\nThe objective is to analyze the spectral properties of a saddle-point system derived from a mixed discretization of the Poisson equation on a $2 \\times 2$ grid. This analysis is performed by computing the eigenvalues of the system after applying three distinct symmetric block-diagonal preconditioners.\n\nFirst, we construct the matrices of the discrete saddle-point system:\n$$\n\\boldsymbol{K}\\begin{bmatrix} \\boldsymbol{q} \\\\ \\boldsymbol{u} \\end{bmatrix} = \\begin{bmatrix} \\boldsymbol{M}  \\boldsymbol{B}^{\\top} \\\\ \\boldsymbol{B}  \\boldsymbol{0} \\end{bmatrix} \\begin{bmatrix} \\boldsymbol{q} \\\\ \\boldsymbol{u} \\end{bmatrix} = \\begin{bmatrix} \\boldsymbol{f} \\\\ \\boldsymbol{g} \\end{bmatrix}\n$$\nThe flux degrees of freedom $\\boldsymbol{q} \\in \\mathbb{R}^4$ correspond to the $4$ interior edges, and the pressure degrees of freedom $\\boldsymbol{u} \\in \\mathbb{R}^3$ correspond to the pressures in cells $c_0, c_1, c_2$, with the pressure in cell $c_3$ eliminated to enforce a zero-mean constraint.\n\nThe flux mass matrix $\\boldsymbol{M}$ is given as the $4 \\times 4$ identity matrix, $\\boldsymbol{M} = \\boldsymbol{I}_4$.\n\nThe discrete divergence operator $\\boldsymbol{B} \\in \\mathbb{R}^{3 \\times 4}$ maps fluxes on edges $(e_0, e_1, e_2, e_3)$ to cell-centered divergences for cells $(c_0, c_1, c_2)$. Based on the specified orientations and connectivity:\n- Edge $e_0$ (from $c_0$ to $c_1$): contributes $+1$ to cell $c_0$ and $-1$ to cell $c_1$.\n- Edge $e_1$ (from $c_2$ to $c_3$): contributes $+1$ to cell $c_2$ (contribution to $c_3$ is omitted).\n- Edge $e_2$ (from $c_0$ to $c_2$): contributes $+1$ to cell $c_0$ and $-1$ to cell $c_2$.\n- Edge $e_3$ (from $c_1$ to $c_3$): contributes $+1$ to cell $c_1$ (contribution to $c_3$ is omitted).\nThis yields the matrix:\n$$\n\\boldsymbol{B} = \\begin{bmatrix}\n1  0  1  0 \\\\\n-1  0  0  1 \\\\\n0  1  -1  0\n\\end{bmatrix}\n$$\nThe full $7 \\times 7$ saddle-point matrix $\\boldsymbol{K}$ is then:\n$$\n\\boldsymbol{K} =\n\\begin{bmatrix}\n\\boldsymbol{I}_4  \\boldsymbol{B}^{\\top} \\\\\n\\boldsymbol{B}  \\boldsymbol{0}_{3\\times3}\n\\end{bmatrix}\n=\n\\left[\n\\begin{array}{cccc|ccc}\n1  0  0  0  1  -1  0 \\\\\n0  1  0  0  0  0  1 \\\\\n0  0  1  0  1  0  -1 \\\\\n0  0  0  1  0  1  0 \\\\\n\\hline\n1  0  1  0  0  0  0 \\\\\n-1  0  0  1  0  0  0 \\\\\n0  1  -1  0  0  0  0\n\\end{array}\n\\right]\n$$\nWe analyze the eigenvalues of the symmetrically preconditioned operator $\\boldsymbol{C} = \\boldsymbol{P}^{-1/2} \\boldsymbol{K} \\boldsymbol{P}^{-1/2}$, where $\\boldsymbol{P} = \\operatorname{diag}(\\boldsymbol{M}, \\boldsymbol{S}_{\\text{approx}})$ is the block-diagonal preconditioner. Given $\\boldsymbol{M} = \\boldsymbol{I}_4$, the preconditioner is $\\boldsymbol{P} = \\operatorname{diag}(\\boldsymbol{I}_4, \\boldsymbol{S}_{\\text{approx}})$ and its inverse square root is $\\boldsymbol{P}^{-1/2} = \\operatorname{diag}(\\boldsymbol{I}_4, \\boldsymbol{S}_{\\text{approx}}^{-1/2})$. The preconditioned matrix simplifies to:\n$$\n\\boldsymbol{C} = \\begin{bmatrix} \\boldsymbol{I}_4  \\boldsymbol{B}^{\\top} \\boldsymbol{S}_{\\text{approx}}^{-1/2} \\\\ \\boldsymbol{S}_{\\text{approx}}^{-1/2} \\boldsymbol{B}  \\boldsymbol{0}_{3\\times3} \\end{bmatrix}\n$$\nThis is a symmetric matrix, so its eigenvalues are real. We compute them for three choices of $\\boldsymbol{S}_{\\text{approx}}$.\n\nTest 1: Exact Schur complement preconditioner.\nHere, $\\boldsymbol{S}_{\\text{approx}} = \\boldsymbol{S} = \\boldsymbol{B}\\boldsymbol{M}^{-1}\\boldsymbol{B}^{\\top} = \\boldsymbol{B}\\boldsymbol{B}^{\\top}$.\n$$\n\\boldsymbol{S} = \\begin{bmatrix}\n1  0  1  0 \\\\\n-1  0  0  1 \\\\\n0  1  -1  0\n\\end{bmatrix}\n\\begin{bmatrix}\n1  -1  0 \\\\\n0  0  1 \\\\\n1  0  -1 \\\\\n0  1  0\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n2  -1  -1 \\\\\n-1  2  0 \\\\\n-1  0  2\n\\end{bmatrix}\n$$\nThe inverse square root $\\boldsymbol{S}^{-1/2}$ is computed via spectral decomposition: $\\boldsymbol{S} = \\boldsymbol{V}\\boldsymbol{\\Lambda}\\boldsymbol{V}^{\\top}$, so $\\boldsymbol{S}^{-1/2} = \\boldsymbol{V}\\boldsymbol{\\Lambda}^{-1/2}\\boldsymbol{V}^{\\top}$. The eigenvalues of the resulting matrix $\\boldsymbol{C}_1$ are known theoretically to be $1$ (with multiplicity $4-3=1$) and $\\frac{1 \\pm \\sqrt{5}}{2}$ (each with multiplicity $3$).\n\nTest 2: Jacobi preconditioner.\nThe approximation is the diagonal of the exact Schur complement: $\\boldsymbol{S}_{\\text{approx}} = \\boldsymbol{S}_{\\text{diag}} = \\operatorname{diag}(\\boldsymbol{S})$.\n$$\n\\boldsymbol{S}_{\\text{diag}} = \\operatorname{diag}(2, 2, 2) = 2\\boldsymbol{I}_3\n$$\nThe inverse square root is $\\boldsymbol{S}_{\\text{diag}}^{-1/2} = (2\\boldsymbol{I}_3)^{-1/2} = \\frac{1}{\\sqrt{2}}\\boldsymbol{I}_3$. The matrix $\\boldsymbol{C}_2$ is then constructed, and its eigenvalues are computed numerically.\n\nTest 3: Pressure mass matrix preconditioner.\nThe approximation is $\\boldsymbol{S}_{\\text{approx}} = \\boldsymbol{S}_{\\text{mass}} = h^2 \\boldsymbol{I}_3$. With cell width $h = 1/2$, this becomes $\\boldsymbol{S}_{\\text{mass}} = \\frac{1}{4}\\boldsymbol{I}_3$.\nThe inverse square root is $\\boldsymbol{S}_{\\text{mass}}^{-1/2} = (\\frac{1}{4}\\boldsymbol{I}_3)^{-1/2} = 2\\boldsymbol{I}_3$. The matrix $\\boldsymbol{C}_3$ is constructed, and its eigenvalues are computed.\n\nFor each of the three cases, the seven real eigenvalues of the corresponding matrix $\\boldsymbol{C}$ are computed and sorted in ascending order. These lists of eigenvalues are then reported as the final result.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Constructs a saddle-point system for a mixed-FEM discretization of the\n    Poisson equation on a 2x2 grid, applies three different block-diagonal\n    preconditioners, and computes the eigenvalues of the preconditioned systems.\n    \"\"\"\n    \n    # Define the flux mass matrix M (4x4 identity) and the discrete divergence B (3x4).\n    # M is for 4 interior edge fluxes.\n    # B maps fluxes to divergences in cells c0, c1, c2.\n    M = np.eye(4)\n    B = np.array([\n        [1.0, 0.0, 1.0, 0.0],   # Divergence in cell c0\n        [-1.0, 0.0, 0.0, 1.0],  # Divergence in cell c1\n        [0.0, 1.0, -1.0, 0.0]   # Divergence in cell c2\n    ])\n\n    test_cases_defs = []\n\n    # Test 1: Exact Schur complement preconditioner\n    # S_approx = S = B * M^-1 * B.T. Since M=I, S = B * B.T\n    S = B @ B.T\n    # Calculate S_approx^{-1/2} using spectral decomposition (eigh)\n    w_s, v_s = linalg.eigh(S)\n    if np.any(w_s = 0):\n        # This should not happen for a valid problem setup\n        raise ValueError(\"Schur complement S is not positive definite.\")\n    S_inv_sqrt_1 = v_s @ np.diag(1.0 / np.sqrt(w_s)) @ v_s.T\n    test_cases_defs.append(S_inv_sqrt_1)\n\n    # Test 2: Jacobi preconditioner\n    # S_approx = diag(S)\n    S_diag = np.diag(np.diag(S))\n    # S_diag is diagonal, so its inverse square root is easy to compute\n    S_inv_sqrt_2 = np.diag(1.0 / np.sqrt(np.diag(S_diag)))\n    test_cases_defs.append(S_inv_sqrt_2)\n\n    # Test 3: Pressure mass matrix preconditioner\n    # S_approx = h^2 * I, with h=1/2.\n    h = 0.5\n    S_mass = (h**2) * np.eye(3)\n    # S_mass is a multiple of identity, inverse square root is scalar operation.\n    S_inv_sqrt_3 = (1.0 / h) * np.eye(3)\n    test_cases_defs.append(S_inv_sqrt_3)\n\n    results = []\n    num_flux_dofs = M.shape[0]\n    num_pressure_dofs = B.shape[0]\n    total_dofs = num_flux_dofs + num_pressure_dofs\n\n    for S_approx_inv_sqrt in test_cases_defs:\n        # Construct the symmetrically preconditioned matrix C\n        # C = [ I,            B.T @ S_approx^{-1/2} ]\n        #     [ S_approx^{-1/2} @ B,  0          ]\n        # Since M=I, the (1,1) block is M^{-1/2} @ M @ M^{-1/2} = I\n        C = np.zeros((total_dofs, total_dofs))\n        \n        # Top-left block (flux-flux)\n        C[0:num_flux_dofs, 0:num_flux_dofs] = np.eye(num_flux_dofs)\n        \n        # Top-right block (flux-pressure)\n        C[0:num_flux_dofs, num_flux_dofs:total_dofs] = B.T @ S_approx_inv_sqrt\n        \n        # Bottom-left block (pressure-flux)\n        C[num_flux_dofs:total_dofs, 0:num_flux_dofs] = S_approx_inv_sqrt @ B\n        \n        # Bottom-right block is zero.\n\n        # C is symmetric, so use eigh for efficiency and guaranteed real eigenvalues.\n        # linalg.eigh returns eigenvalues in ascending order.\n        eigenvalues = linalg.eigvalsh(C)\n        results.append(eigenvalues.tolist())\n\n    # Format the final output string as a JSON-like nested list with no spaces.\n    results_str = []\n    for eig_list in results:\n        formatted_eigs = [f\"{eig:.8f}\" for eig in eig_list]\n        results_str.append(\"[\" + \",\".join(formatted_eigs) + \"]\")\n    final_output = \"[\" + \",\".join(results_str) + \"]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "After observing the numerical effects of preconditioning, we now turn to the underlying algebraic structure that governs its success. This practice moves from numerical implementation to analytical derivation, focusing on a small system where the properties can be seen exactly . By comparing the spectra of systems preconditioned with block-diagonal and block-triangular operators using an ideal Schur complement, you will uncover why the block-triangular form is structurally superior and leads to a perfect clustering of eigenvalues.",
            "id": "3566697",
            "problem": "Consider the saddle-point system with symmetric positive definite (SPD) block $A \\in \\mathbb{R}^{2 \\times 2}$ and full-row-rank constraint block $B \\in \\mathbb{R}^{1 \\times 2}$ given by\n$$\nA = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix}, \\qquad B = \\begin{pmatrix} 1  -2 \\end{pmatrix},\n$$\nand the $3 \\times 3$ KKT (Karush–Kuhn–Tucker) matrix\n$$\nK = \\begin{pmatrix} A  B^{\\top} \\\\ B  0 \\end{pmatrix}.\n$$\nDefine the ideal Schur complement $S_{\\star} = B A^{-1} B^{\\top}$ and the two preconditioners:\n- the block-diagonal preconditioner\n$$\nM_{D} = \\begin{pmatrix} A  0 \\\\ 0  S_{\\star} \\end{pmatrix},\n$$\n- the block-triangular preconditioner\n$$\nM_{T} = \\begin{pmatrix} A  0 \\\\ B  -S_{\\star} \\end{pmatrix}.\n$$\nStarting from core definitions of the Schur complement, preconditioning, and block matrix operations, first compute the spectrum (the multiset of eigenvalues) of the preconditioned operator $M_{D}^{-1} K$ for the given $A$ and $B$. Then, repeat the computation for the block-triangular preconditioner, i.e., compute the spectrum of $M_{T}^{-1} K$ with the same $A$ and $B$. Compare the two spectra by explaining the structural reasons for any differences in clustering, including the impact of exact Schur complement use and block factorization properties.\n\nProvide your final answer as the eigenvalues of $M_{T}^{-1} K$ listed in a single row (include multiplicities), in exact form. No rounding is required.",
            "solution": "The problem statement is first subjected to validation.\n\n### Step 1: Extract Givens\n- Symmetric positive definite (SPD) block $A \\in \\mathbb{R}^{2 \\times 2}$ is $A = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix}$.\n- Full-row-rank constraint block $B \\in \\mathbb{R}^{1 \\times 2}$ is $B = \\begin{pmatrix} 1  -2 \\end{pmatrix}$.\n- The Karush–Kuhn–Tucker (KKT) matrix is $K = \\begin{pmatrix} A  B^{\\top} \\\\ B  0 \\end{pmatrix}$.\n- The ideal Schur complement is defined as $S_{\\star} = B A^{-1} B^{\\top}$.\n- The block-diagonal preconditioner is $M_{D} = \\begin{pmatrix} A  0 \\\\ 0  S_{\\star} \\end{pmatrix}$.\n- The block-triangular preconditioner is $M_{T} = \\begin{pmatrix} A  0 \\\\ B  -S_{\\star} \\end{pmatrix}$.\n- The tasks are to compute the spectrum of $M_{D}^{-1} K$, compute the spectrum of $M_{T}^{-1} K$, and compare them with a structural explanation.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific Grounding**: The problem is rooted in numerical linear algebra, specifically the preconditioning of saddle-point systems. All definitions and matrices are standard in this field.\n2.  **Well-Posedness**: The matrix $A$ is symmetric. Its determinant is $\\det(A) = (4)(3) - (1)(1) = 11  0$, and the leading principal minor is $4  0$, so $A$ is positive definite as stated. The matrix $B$ is a non-zero row vector, so it has full row rank. These conditions ensure that the KKT matrix $K$ is non-singular and the Schur complement $S_{\\star}$ is well-defined and invertible. The problem is self-contained and specifies clear computational tasks.\n3.  **Objectivity**: The problem is stated in precise mathematical language, free of ambiguity or subjective claims.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is well-posed, scientifically grounded, and objective. A complete solution will be provided.\n\n### Solution\n\nThe solution proceeds by first calculating the necessary components, then analyzing each preconditioned system, and finally providing a structural comparison.\n\n**1. Preliminary Calculations**\n\nFirst, we compute the inverse of matrix $A$:\n$$\nA^{-1} = \\frac{1}{\\det(A)} \\begin{pmatrix} 3  -1 \\\\ -1  4 \\end{pmatrix} = \\frac{1}{11} \\begin{pmatrix} 3  -1 \\\\ -1  4 \\end{pmatrix}\n$$\nNext, we compute the transpose of $B$:\n$$\nB^{\\top} = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}\n$$\nNow, we can compute the ideal Schur complement $S_{\\star} = B A^{-1} B^{\\top}$. Since $B$ is a $1 \\times 2$ matrix, $S_{\\star}$ will be a $1 \\times 1$ matrix (a scalar).\n$$\nS_{\\star} = \\begin{pmatrix} 1  -2 \\end{pmatrix} \\left( \\frac{1}{11} \\begin{pmatrix} 3  -1 \\\\ -1  4 \\end{pmatrix} \\right) \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}\n$$\n$$\nS_{\\star} = \\frac{1}{11} \\begin{pmatrix} 1  -2 \\end{pmatrix} \\begin{pmatrix} 3(1) + (-1)(-2) \\\\ -1(1) + 4(-2) \\end{pmatrix} = \\frac{1}{11} \\begin{pmatrix} 1  -2 \\end{pmatrix} \\begin{pmatrix} 5 \\\\ -9 \\end{pmatrix}\n$$\n$$\nS_{\\star} = \\frac{1}{11} \\left( 1(5) + (-2)(-9) \\right) = \\frac{1}{11} (5 + 18) = \\frac{23}{11}\n$$\n\n**2. Spectrum of the Block-Diagonal Preconditioned System $M_{D}^{-1} K$**\n\nThe block-diagonal preconditioner is $M_{D} = \\begin{pmatrix} A  0 \\\\ 0  S_{\\star} \\end{pmatrix}$. Its inverse is $M_{D}^{-1} = \\begin{pmatrix} A^{-1}  0 \\\\ 0  S_{\\star}^{-1} \\end{pmatrix}$.\nThe preconditioned matrix is:\n$$\nM_{D}^{-1} K = \\begin{pmatrix} A^{-1}  0 \\\\ 0  S_{\\star}^{-1} \\end{pmatrix} \\begin{pmatrix} A  B^{\\top} \\\\ B  0 \\end{pmatrix} = \\begin{pmatrix} A^{-1}A  A^{-1}B^{\\top} \\\\ S_{\\star}^{-1}B  0 \\end{pmatrix} = \\begin{pmatrix} I  A^{-1}B^{\\top} \\\\ S_{\\star}^{-1}B  0 \\end{pmatrix}\n$$\nTo find the eigenvalues $\\lambda$, we solve the characteristic equation $\\det(M_{D}^{-1} K - \\lambda I) = 0$.\nThe characteristic polynomial is given by $\\det \\begin{pmatrix} (1-\\lambda)I  A^{-1}B^{\\top} \\\\ S_{\\star}^{-1}B  -\\lambda I_p \\end{pmatrix} = 0$, where $I$ is the $2 \\times 2$ identity and $I_p$ is the $1 \\times 1$ identity.\nUsing the formula for the determinant of a block matrix, for $\\lambda \\neq 1$:\n$$\n\\det((1-\\lambda)I) \\det(-\\lambda I_p - (S_{\\star}^{-1}B) ((1-\\lambda)I)^{-1} (A^{-1}B^{\\top})) = 0\n$$\n$$\n(1-\\lambda)^{2} \\det(-\\lambda - \\frac{1}{1-\\lambda} S_{\\star}^{-1} (B A^{-1} B^{\\top})) = 0\n$$\n$$\n(1-\\lambda)^{2} (-\\lambda - \\frac{1}{1-\\lambda} S_{\\star}^{-1} S_{\\star}) = 0\n$$\n$$\n(1-\\lambda)^{2} (-\\lambda - \\frac{1}{1-\\lambda}) = 0\n$$\nMultiplying by $(1-\\lambda)$, we get $(1-\\lambda) [-\\lambda(1-\\lambda) - 1] = 0$. This is valid for $\\lambda \\neq 1$. If $\\lambda=1$ is a root, we must check it separately. In this formulation, we find that we have:\n$$\n(1-\\lambda) (\\lambda^2 - \\lambda - 1) = 0\n$$\nThis equation gives three distinct eigenvalues:\n- $\\lambda_1 = 1$\n- The roots of $\\lambda^2 - \\lambda - 1 = 0$, which from the quadratic formula are $\\lambda = \\frac{1 \\pm \\sqrt{1 - 4(1)(-1)}}{2} = \\frac{1 \\pm \\sqrt{5}}{2}$.\nSo, $\\lambda_2 = \\frac{1+\\sqrt{5}}{2}$ and $\\lambda_3 = \\frac{1-\\sqrt{5}}{2}$.\nThe spectrum of $M_{D}^{-1} K$ is $\\left\\{ 1, \\frac{1+\\sqrt{5}}{2}, \\frac{1-\\sqrt{5}}{2} \\right\\}$.\n\n**3. Spectrum of the Block-Triangular Preconditioned System $M_{T}^{-1} K$**\n\nThe block-triangular preconditioner is $M_{T} = \\begin{pmatrix} A  0 \\\\ B  -S_{\\star} \\end{pmatrix}$. To find its inverse, $M_{T}^{-1} = \\begin{pmatrix} X  Y \\\\ Z  W \\end{pmatrix}$, we solve $M_{T} M_{T}^{-1} = I$:\n$$\n\\begin{pmatrix} A  0 \\\\ B  -S_{\\star} \\end{pmatrix} \\begin{pmatrix} X  Y \\\\ Z  W \\end{pmatrix} = \\begin{pmatrix} AX  AY \\\\ BX-S_{\\star}Z  BY-S_{\\star}W \\end{pmatrix} = \\begin{pmatrix} I  0 \\\\ 0  I \\end{pmatrix}\n$$\nThis gives $AX=I \\implies X=A^{-1}$; $AY=0 \\implies Y=0$; $-S_{\\star}W=I \\implies W=-S_{\\star}^{-1}$; and $BX-S_{\\star}Z=0 \\implies Z=S_{\\star}^{-1}BX=S_{\\star}^{-1}BA^{-1}$.\nSo, $M_{T}^{-1} = \\begin{pmatrix} A^{-1}  0 \\\\ S_{\\star}^{-1}BA^{-1}  -S_{\\star}^{-1} \\end{pmatrix}$.\nThe preconditioned matrix is:\n$$\nM_{T}^{-1} K = \\begin{pmatrix} A^{-1}  0 \\\\ S_{\\star}^{-1}BA^{-1}  -S_{\\star}^{-1} \\end{pmatrix} \\begin{pmatrix} A  B^{\\top} \\\\ B  0 \\end{pmatrix}\n$$\n$$\nM_{T}^{-1} K = \\begin{pmatrix} A^{-1}A  A^{-1}B^{\\top} \\\\ S_{\\star}^{-1}BA^{-1}A - S_{\\star}^{-1}B  S_{\\star}^{-1}BA^{-1}B^{\\top} \\end{pmatrix} = \\begin{pmatrix} I  A^{-1}B^{\\top} \\\\ S_{\\star}^{-1}B - S_{\\star}^{-1}B  S_{\\star}^{-1}S_{\\star} \\end{pmatrix}\n$$\n$$\nM_{T}^{-1} K = \\begin{pmatrix} I  A^{-1}B^{\\top} \\\\ 0  1 \\end{pmatrix}\n$$\nwhere $I$ is the $2 \\times 2$ identity matrix and $1$ is the scalar $1$. This is a block upper triangular matrix. The eigenvalues of a block triangular matrix are the eigenvalues of its diagonal blocks.\n- The eigenvalues of the top-left block, $I = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$, are $1$ and $1$.\n- The eigenvalue of the bottom-right block, the scalar $1$, is $1$.\nTherefore, the spectrum of $M_{T}^{-1} K$ is $\\{1, 1, 1\\}$.\n\n**4. Comparison and Structural Explanation**\n\nThe spectrum of $M_{D}^{-1} K$ is $\\left\\{ 1, \\frac{1+\\sqrt{5}}{2}, \\frac{1-\\sqrt{5}}{2} \\right\\}$, while the spectrum of $M_{T}^{-1} K$ is $\\{1, 1, 1\\}$. The difference is significant and stems from the structural properties of the preconditioners.\n\nThe KKT matrix $K$ admits a block LU-like factorization:\n$$\nK = \\begin{pmatrix} A  B^{\\top} \\\\ B  0 \\end{pmatrix} = \\begin{pmatrix} I  0 \\\\ B A^{-1}  I \\end{pmatrix} \\begin{pmatrix} A  0 \\\\ 0  -S_{\\star} \\end{pmatrix} \\begin{pmatrix} I  A^{-1} B^{\\top} \\\\ 0  I \\end{pmatrix}\n$$\nThe block-triangular preconditioner $M_T$ is defined as:\n$$\nM_{T} = \\begin{pmatrix} A  0 \\\\ B  -S_{\\star} \\end{pmatrix} = \\begin{pmatrix} I  0 \\\\ B A^{-1}  I \\end{pmatrix} \\begin{pmatrix} A  0 \\\\ 0  -S_{\\star} \\end{pmatrix}\n$$\n$M_T$ is constructed to be exactly the product of the first two matrices in the factorization of $K$. Consequently, when we form the preconditioned operator $M_T^{-1} K$, these two factors cancel perfectly:\n$$\nM_{T}^{-1} K = \\left( \\left( \\begin{pmatrix} I  0 \\\\ B A^{-1}  I \\end{pmatrix} \\begin{pmatrix} A  0 \\\\ 0  -S_{\\star} \\end{pmatrix} \\right)^{-1} \\right) \\left( \\begin{pmatrix} I  0 \\\\ B A^{-1}  I \\end{pmatrix} \\begin{pmatrix} A  0 \\\\ 0  -S_{\\star} \\end{pmatrix} \\begin{pmatrix} I  A^{-1} B^{\\top} \\\\ 0  I \\end{pmatrix} \\right) = \\begin{pmatrix} I  A^{-1} B^{\\top} \\\\ 0  I \\end{pmatrix}\n$$\nThe result is a matrix with ones on its main diagonal and a zero block in the lower left. Such a matrix is unipotent, and all its eigenvalues are $1$. This is why the spectrum of $M_{T}^{-1} K$ is perfectly clustered at $1$. In practice, using an exact Schur complement makes $M_T$ an ideal preconditioner, leading to convergence of iterative methods like GMRES in a predictably low number of iterations.\n\nThe block-diagonal preconditioner $M_D = \\begin{pmatrix} A  0 \\\\ 0  S_{\\star} \\end{pmatrix}$ does not fully capture the structure of the factorization of $K$. It correctly preconditions the diagonal block $A$, but its handling of the $(2,2)$ block with $S_{\\star}$ differs in sign from the factorization term $-S_{\\star}$ and, more importantly, it ignores the off-diagonal coupling inherent in the L and U factors (represented by $B$ and $B^{\\top}$). The resulting preconditioned operator $M_{D}^{-1} K$ is not triangular and has eigenvalues that are generally not $1$. For the case where the exact $A$ and exact $S_{\\star}$ are used, it is a known theoretical result that the eigenvalues are always $1$ (with multiplicity equal to the size of $A$ minus the rank of $B$) and the roots of $\\lambda^2 - \\lambda - 1 = 0$ (each with multiplicity equal to the rank of $B$). Our calculation confirms this general theory for the specific $2 \\times 2$ case with a rank-$1$ constraint.\n\nIn summary, $M_T$ is a structurally superior preconditioner because it is based on a block factorization of $K$, leading to an ideal spectrum. $M_D$ is simpler to construct but less effective as it neglects the off-diagonal block structure, resulting in a less clustered spectrum.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1  1  1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Real-world problems often present challenges beyond those seen in simple symmetric systems. This advanced practice explores the preconditioning of the Oseen equations, a cornerstone of computational fluid dynamics, which leads to a non-normal saddle-point operator . You will move beyond simple eigenvalue analysis to use more powerful tools like pseudospectra and matrix exponentials to quantify non-normality and its practical consequence, transient growth, while exploring how damping in the preconditioner can mitigate these adverse effects.",
            "id": "3566655",
            "problem": "Consider the saddle-point system arising from the linearized Oseen equations discretized on a one-dimensional uniform grid of $n$ interior velocity nodes with grid spacing $h$, producing the block matrix\n$$\n\\mathbf{K} = \\begin{bmatrix}\n\\mathbf{A}  \\mathbf{B}^\\top \\\\\n\\mathbf{B}  \\mathbf{0}\n\\end{bmatrix},\n$$\nwhere $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is a discrete Oseen operator composed of a symmetric positive definite diffusion part and a skew-symmetric convection part, and $\\mathbf{B} \\in \\mathbb{R}^{m \\times n}$ with $m=n-1$ is a discrete divergence operator. The diffusion operator is modeled by the second-order centered-difference Laplacian with Dirichlet boundaries, and the convection operator is modeled by a centered-difference discretization of $c\\,\\partial_x$ with $c \\in \\mathbb{R}$, yielding a skew-symmetric tridiagonal matrix. Let the viscosity be $\\nu  0$ and the convection intensity be $c \\ge 0$. The discrete operators are:\n- Diffusion: $\\mathbf{L} \\in \\mathbb{R}^{n \\times n}$, tridiagonal with $2/h^2$ on the diagonal and $-1/h^2$ on the first sub- and super-diagonals.\n- Convection: $\\mathbf{C} \\in \\mathbb{R}^{n \\times n}$, tridiagonal with $\\mathbf{C}_{i,i+1} = c/(2h)$ and $\\mathbf{C}_{i+1,i} = -c/(2h)$, yielding a skew-symmetric matrix.\n- Velocity block: $\\mathbf{A} = \\nu \\mathbf{L} + \\mathbf{C}$.\n- Divergence: $\\mathbf{B} \\in \\mathbb{R}^{m \\times n}$, with rows $i=1,\\dots,m$ acting as $(\\mathbf{B} \\mathbf{u})_i = \\frac{-u_i + u_{i+1}}{h}$.\n\nConsider the block-diagonal preconditioner\n$$\n\\mathbf{P} = \\begin{bmatrix}\n\\mathbf{A}  \\mathbf{0} \\\\\n\\mathbf{0}  \\widehat{\\mathbf{S}}\n\\end{bmatrix},\n$$\nwhere $\\widehat{\\mathbf{S}} \\in \\mathbb{R}^{m \\times m}$ approximates the Schur complement $\\mathbf{S} = -\\mathbf{B} \\mathbf{A}^{-1} \\mathbf{B}^\\top$. We study the left-preconditioned operator\n$$\n\\mathbf{M} = \\mathbf{P}^{-1} \\mathbf{K} = \\begin{bmatrix}\n\\mathbf{I}  \\mathbf{A}^{-1}\\mathbf{B}^\\top \\\\\n\\widehat{\\mathbf{S}}^{-1}\\mathbf{B}  \\mathbf{0}\n\\end{bmatrix}.\n$$\n\nThe aim is to quantify and mitigate non-normality induced by the skew-symmetric convection part in $\\mathbf{A}$ via damping in $\\widehat{\\mathbf{S}}$. We use an algebraic approximation\n$$\n\\widehat{\\mathbf{S}} = \\mathbf{B}\\,\\mathrm{diag}(\\mathbf{A})^{-1}\\mathbf{B}^\\top + \\tau\\,\\mathbf{I},\n$$\nwith $\\tau \\ge 0$ a damping parameter.\n\nStarting from core definitions in numerical linear algebra:\n- The $\\varepsilon$-pseudospectrum of $\\mathbf{M}$ consists of those $z \\in \\mathbb{C}$ for which $\\|(z\\mathbf{I} - \\mathbf{M})^{-1}\\|_2  1/\\varepsilon$, equivalently the smallest singular value $\\sigma_{\\min}(z\\mathbf{I} - \\mathbf{M})  \\varepsilon$.\n- Transient growth is assessed via the operator norm $\\|\\exp(t\\mathbf{M})\\|_2$ for a fixed $t0$.\n- The field of values (numerical range) is $W(\\mathbf{M}) = \\{ \\mathbf{x}^* \\mathbf{M} \\mathbf{x}/(\\mathbf{x}^*\\mathbf{x}) : \\mathbf{x} \\in \\mathbb{C}^{n+m}\\setminus\\{\\mathbf{0}\\} \\}$, and the resolvent norm satisfies the bound $\\|(z\\mathbf{I} - \\mathbf{M})^{-1}\\|_2 \\leq 1/\\mathrm{dist}(z, W(\\mathbf{M}))$ for all $z \\not\\in W(\\mathbf{M})$.\n\nYour task:\n1. Construct $\\mathbf{A}$, $\\mathbf{B}$, $\\widehat{\\mathbf{S}}$, $\\mathbf{P}$, and $\\mathbf{M}$ as specified for given parameters $(n,\\nu,c,\\tau)$ with $h = 1/(n+1)$.\n2. On a rectangular complex grid $\\mathcal{G}$ defined by real parts uniformly spaced in $[-1.5, 1.5]$ with $21$ points and imaginary parts uniformly spaced in $[-0.75, 0.75]$ with $11$ points, compute the pseudospectral peak\n$$\np_{\\max} = \\max_{z \\in \\mathcal{G}} \\left\\| (z\\mathbf{I} - \\mathbf{M})^{-1} \\right\\|_2 = \\max_{z \\in \\mathcal{G}} \\frac{1}{\\sigma_{\\min}(z\\mathbf{I} - \\mathbf{M})}.\n$$\n3. Compute a transient growth indicator at time $t_0 = 0.5$,\n$$\ng = \\left\\|\\exp(t_0 \\mathbf{M})\\right\\|_2.\n$$\n4. Validate the field-of-values (numerical range) bound by sampling $S=200$ random unit vectors $\\mathbf{x}_j \\in \\mathbb{C}^{n+m}$ to compute points $w_j = \\mathbf{x}_j^* \\mathbf{M} \\mathbf{x}_j$. For each $z \\in \\mathcal{G}$ define the sampled bound\n$$\nb(z) = \\left( \\min_{1 \\le j \\le S} |z - w_j| \\right)^{-1},\n$$\nand check the inequality $\\|(z\\mathbf{I} - \\mathbf{M})^{-1}\\|_2 \\le b(z)$ across the grid. Report a boolean $q$ indicating whether the inequality holds for at least $90\\%$ of the points in $\\mathcal{G}$.\n\nImplement a program that performs the above computations for the following test suite of parameter values:\n- Case 1 (baseline symmetric diffusion): $n=30$, $\\nu=1.0$, $c=0.0$, $\\tau=0.0$.\n- Case 2 (moderate convection, no damping): $n=30$, $\\nu=1.0$, $c=10.0$, $\\tau=0.0$.\n- Case 3 (moderate convection, damping in $\\widehat{\\mathbf{S}}$): $n=30$, $\\nu=1.0$, $c=10.0$, $\\tau=5.0$.\n- Case 4 (strong convection, increased damping): $n=30$, $\\nu=1.0$, $c=25.0$, $\\tau=12.5$.\n\nFor each case, compute and return a list $[p_{\\max}, g, q]$.\n\nFinal output format: Your program should produce a single line of output containing the results for the four cases as a comma-separated list of lists enclosed in square brackets (e.g., \"[[p1,g1,q1],[p2,g2,q2],[p3,g3,q3],[p4,g4,q4]]\"). No additional text should be printed. No physical units are involved in this problem.",
            "solution": "The user-provided problem is evaluated and found to be valid. It is scientifically grounded in numerical linear algebra, well-posed, objective, and contains a complete and consistent set of definitions and parameters for a solvable numerical experiment.\n\n### Method and Implementation\n\nThe problem requires the analysis of a preconditioned saddle-point system for four distinct parameter sets. The core of the task is to construct the specified matrices and then compute three quantities: a pseudospectral peak $p_{\\max}$, a transient growth indicator $g$, and a boolean $q$ evaluating a field-of-values-based resolvent norm bound.\n\nThe overall approach is to implement a procedure that, for each parameter set $(n, \\nu, c, \\tau)$:\n1.  Constructs the necessary matrices $\\mathbf{A}$, $\\mathbf{B}$, $\\widehat{\\mathbf{S}}$, and the final preconditioned operator $\\mathbf{M}$.\n2.  Computes the metrics $p_{\\max}$, $g$, and $q$ based on $\\mathbf{M}$.\n\nAll computations are performed using standard numerical libraries, adhering to the definitions provided.\n\n#### 1. Matrix Construction\n\nFor a given number of interior nodes $n$, the grid spacing is $h = 1/(n+1)$ and the dimension of the pressure-related space is $m = n-1$. The total dimension of the system is $N = n+m$.\n\n-   **Diffusion Operator ($\\mathbf{L}$):** The discrete Laplacian $\\mathbf{L} \\in \\mathbb{R}^{n \\times n}$ is a symmetric tridiagonal matrix. For $1$-based indexing, its entries are:\n    $$\n    \\mathbf{L}_{ij} = \\frac{1}{h^2} \\begin{cases}\n    2,   i=j \\\\\n    -1,  |i-j|=1 \\\\\n    0,   \\text{otherwise}\n    \\end{cases}\n    $$\n\n-   **Convection Operator ($\\mathbf{C}$):** The discrete convection operator $\\mathbf{C} \\in \\mathbb{R}^{n \\times n}$ is a skew-symmetric tridiagonal matrix:\n    $$\n    \\mathbf{C}_{ij} = \\frac{c}{2h} \\begin{cases}\n    1,   j=i+1 \\\\\n    -1,  j=i-1 \\\\\n    0,   \\text{otherwise}\n    \\end{cases}\n    $$\n\n-   **Velocity Block ($\\mathbf{A}$):** The $(1,1)$ block of the saddle-point matrix is $\\mathbf{A} = \\nu \\mathbf{L} + \\mathbf{C}$. Given that $\\mathbf{L}$ is symmetric positive definite and $\\nu  0$, the symmetric part of $\\mathbf{A}$ is $\\nu\\mathbf{L}$, which is positive definite. This ensures $\\mathbf{A}$ is invertible.\n\n-   **Divergence Operator ($\\mathbf{B}$):** The discrete divergence operator $\\mathbf{B} \\in \\mathbb{R}^{m \\times n}$ is a bidiagonal matrix representing a forward finite difference. For row $i \\in \\{1, \\dots, m\\}$:\n    $$\n    \\mathbf{B}_{ij} = \\frac{1}{h} \\begin{cases}\n    -1,  j=i \\\\\n    1,   j=i+1 \\\\\n    0,   \\text{otherwise}\n    \\end{cases}\n    $$\n\n-   **Approximate Schur Complement ($\\widehat{\\mathbf{S}}$):** The approximation to the Schur complement $\\mathbf{S} = -\\mathbf{B} \\mathbf{A}^{-1} \\mathbf{B}^\\top$ is given by:\n    $$\n    \\widehat{\\mathbf{S}} = \\mathbf{B}\\,\\mathrm{diag}(\\mathbf{A})^{-1}\\mathbf{B}^\\top + \\tau\\,\\mathbf{I}_m\n    $$\n    where $\\mathbf{I}_m$ is the $m \\times m$ identity matrix and $\\tau \\ge 0$ is a damping parameter. The diagonal matrix $\\mathrm{diag}(\\mathbf{A})$ has positive diagonal entries (from the diffusion term), so its inverse is well-defined. The term $\\mathbf{B}\\,\\mathrm{diag}(\\mathbf{A})^{-1}\\mathbf{B}^\\top$ is symmetric positive semi-definite, and for $\\tau  0$, $\\widehat{\\mathbf{S}}$ is symmetric positive definite and thus invertible. Even for $\\tau=0$, the first term is rank $m=n-1$, making it invertible.\n\n-   **Preconditioned Operator ($\\mathbf{M}$):** The left-preconditioned operator $\\mathbf{M} \\in \\mathbb{R}^{(n+m) \\times (n+m)}$ is formed as a block matrix:\n    $$\n    \\mathbf{M} = \\mathbf{P}^{-1} \\mathbf{K} = \\begin{bmatrix} \\mathbf{I}_n  \\mathbf{A}^{-1}\\mathbf{B}^\\top \\\\ \\widehat{\\mathbf{S}}^{-1}\\mathbf{B}  \\mathbf{0}_{m \\times m} \\end{bmatrix}\n    $$\n    This construction requires the computation of $\\mathbf{A}^{-1}$ and $\\widehat{\\mathbf{S}}^{-1}$.\n\n#### 2. Pseudospectral Peak ($p_{\\max}$)\n\nThe pseudospectral peak is calculated over a specified complex grid $\\mathcal{G}$. The grid consists of $21 \\times 11 = 231$ points $z = x+iy$, where $x \\in [-1.5, 1.5]$ (21 points) and $y \\in [-0.75, 0.75]$ (11 points). For each $z \\in \\mathcal{G}$, we compute the resolvent norm $\\|(z\\mathbf{I} - \\mathbf{M})^{-1}\\|_2$, which is equivalent to the reciprocal of the smallest singular value of the matrix $(z\\mathbf{I} - \\mathbf{M})$:\n$$\n\\left\\| (z\\mathbf{I} - \\mathbf{M})^{-1} \\right\\|_2 = \\frac{1}{\\sigma_{\\min}(z\\mathbf{I} - \\mathbf{M})}\n$$\nThe peak value $p_{\\max}$ is the maximum of these norms over all $z \\in \\mathcal{G}$. The singular values are computed using a standard Singular Value Decomposition (SVD) algorithm.\n\n#### 3. Transient Growth Indicator ($g$)\n\nTransient growth is a hallmark of non-normal operators. It is measured by the norm of the matrix exponential, $\\|\\exp(t\\mathbf{M})\\|_2$. For this problem, we evaluate this quantity at a fixed time $t_0 = 0.5$. The matrix exponential $\\exp(t_0 \\mathbf{M})$ is computed using a Padé approximant-based algorithm, and its $2$-norm is found by computing the largest singular value of the resulting matrix. The growth indicator is thus $g = \\|\\exp(t_0 \\mathbf{M})\\|_2$.\n\n#### 4. Field-of-Values Bound Validation ($q$)\n\nThe field of values (or numerical range) $W(\\mathbf{M})$ provides a bound on the resolvent norm. The problem asks to validate a sampled version of this bound. The procedure is as follows:\n1.  Generate $S=200$ random unit vectors $\\mathbf{x}_j \\in \\mathbb{C}^{n+m}$. For reproducibility, a fixed random seed is used.\n2.  Compute $S$ points $w_j = \\mathbf{x}_j^* \\mathbf{M} \\mathbf{x}_j$ to form a sample set $\\{w_j\\}_{j=1}^S \\subset W(\\mathbf{M})$.\n3.  For each point $z \\in \\mathcal{G}$, compute the distance to the sample set, $\\mathrm{dist}(z, \\{w_j\\}) = \\min_j |z - w_j|$.\n4.  Form the sampled bound $b(z) = (\\mathrm{dist}(z, \\{w_j\\}))^{-1}$.\n5.  Check if the inequality $\\|(z\\mathbf{I} - \\mathbf{M})^{-1}\\|_2 \\le b(z)$ holds.\n6.  The boolean $q$ is set to true if this inequality is satisfied for at least $90\\%$ of the points in the grid $\\mathcal{G}$, and false otherwise. This accounts for the possibility that the finite sample $\\{w_j\\}$ does not perfectly represent the boundary of $W(\\mathbf{M})$.\n\nThe entire process is repeated for each of the four test cases provided in the problem statement, and the results $[p_{\\max}, g, q]$ for each case are collected.",
            "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef compute_matrices(n, nu, c, h):\n    \"\"\"Constructs and returns the matrices A and B.\"\"\"\n    m = n - 1\n\n    # Diffusion operator L\n    diag_L = np.full(n, 2.0 / h**2)\n    off_diag_L = np.full(n - 1, -1.0 / h**2)\n    L = np.diag(off_diag_L, k=-1) + np.diag(diag_L, k=0) + np.diag(off_diag_L, k=1)\n\n    # Convection operator C\n    off_diag_C = np.full(n - 1, c / (2.0 * h))\n    C = np.diag(off_diag_C, k=1) - np.diag(off_diag_C, k=-1)\n\n    # Velocity block A\n    A = nu * L + C\n\n    # Divergence operator B\n    diag_B = np.full(m, -1.0 / h)\n    off_diag_B = np.full(m, 1.0 / h)\n    # B has shape (m, n) = (n-1, n)\n    B = np.zeros((m, n))\n    for i in range(m):\n        B[i, i] = -1.0 / h\n        B[i, i+1] = 1.0 / h\n        \n    return A, B\n\ndef compute_for_case(n, nu, c, tau):\n    \"\"\"\n    Performs all computations for a single parameter set (n, nu, c, tau).\n    Returns a list [p_max, g, q].\n    \"\"\"\n    h = 1.0 / (n + 1)\n    m = n - 1\n    N_total = n + m\n\n    # 1. Construct matrices\n    A, B = compute_matrices(n, nu, c, h)\n\n    # Approximate Schur complement S_hat\n    diag_A_inv = np.diag(1.0 / np.diag(A))\n    S_hat = B @ diag_A_inv @ B.T + tau * np.eye(m)\n\n    # Preconditioned operator M\n    A_inv = np.linalg.inv(A)\n    S_hat_inv = np.linalg.inv(S_hat)\n\n    M = np.block([\n        [np.eye(n), A_inv @ B.T],\n        [S_hat_inv @ B, np.zeros((m, m))]\n    ])\n\n    # 2. Compute pseudospectral peak p_max\n    real_parts = np.linspace(-1.5, 1.5, 21)\n    imag_parts = np.linspace(-0.75, 0.75, 11)\n    grid_G = [r + 1j * i for r in real_parts for i in imag_parts]\n    \n    p_max = 0.0\n    resolvent_norms = {}\n    for z in grid_G:\n        zI_minus_M = z * np.eye(N_total) - M\n        # Smallest singular value\n        sigma_min = np.linalg.svd(zI_minus_M, compute_uv=False).min()\n        norm_val = 1.0 / sigma_min if sigma_min > 1e-16 else 1e16\n        resolvent_norms[z] = norm_val\n        if norm_val > p_max:\n            p_max = norm_val\n\n    # 3. Compute transient growth indicator g\n    t0 = 0.5\n    exp_tM = linalg.expm(t0 * M)\n    g = np.linalg.norm(exp_tM, ord=2)\n\n    # 4. Validate field-of-values bound and compute q\n    S = 200\n    # Use a fixed seed for reproducibility\n    np.random.seed(0)\n    \n    # Generate random unit vectors\n    rand_vecs = np.random.randn(S, N_total) + 1j * np.random.randn(S, N_total)\n    rand_vecs /= np.linalg.norm(rand_vecs, axis=1)[:, np.newaxis]\n\n    # Sample field of values\n    w_samples = np.array([x.conj().T @ M @ x for x in rand_vecs])\n\n    valid_count = 0\n    for z in grid_G:\n        dist_z = np.min(np.abs(z - w_samples))\n        \n        # If dist_z is very small, the bound is effectively infinite and holds.\n        if dist_z  1e-15:\n            bound_z = np.inf\n        else:\n            bound_z = 1.0 / dist_z\n            \n        if resolvent_norms[z] = bound_z:\n            valid_count += 1\n            \n    q = (valid_count / len(grid_G)) >= 0.9\n    \n    return [p_max, g, q]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    test_cases = [\n        # (n, nu, c, tau)\n        (30, 1.0, 0.0, 0.0),    # baseline symmetric diffusion\n        (30, 1.0, 10.0, 0.0),   # moderate convection, no damping\n        (30, 1.0, 10.0, 5.0),   # moderate convection, damping\n        (30, 1.0, 25.0, 12.5),  # strong convection, increased damping\n    ]\n\n    results = []\n    for case in test_cases:\n        res = compute_for_case(*case)\n        results.append(res)\n    \n    # Format the output string precisely as required.\n    output_parts = []\n    for res in results:\n        # res is [p_max, g, q]\n        # Format boolean as 'True' or 'False' lower/upper case is not specified, Python default is fine.\n        part = f\"[{res[0]},{res[1]},{res[2]}]\"\n        output_parts.append(part)\n    \n    final_output = f\"[{','.join(output_parts)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}