{
    "hands_on_practices": [
        {
            "introduction": "Domain decomposition methods are built upon a set of core algebraic operators that transfer information between a global problem and local subdomains. This first exercise focuses on these fundamental building blocks: the restriction and prolongation (injection) operators. By explicitly constructing these matrices and observing their collective action, you will uncover why a simple summation of local contributions is inadequate and discover the necessity of a 'partition of unity' to properly reassemble the global solution .",
            "id": "3544213",
            "problem": "Consider the canonical one-dimensional Poisson operator with homogeneous Dirichlet boundary conditions on a uniform grid with $7$ interior points. Its stiffness matrix is the $7 \\times 7$ Symmetric Positive Definite (SPD) tridiagonal matrix\n$$\nA \\;=\\;\n\\begin{pmatrix}\n2 & -1 & 0 & 0 & 0 & 0 & 0 \\\\\n-1 & 2 & -1 & 0 & 0 & 0 & 0 \\\\\n0 & -1 & 2 & -1 & 0 & 0 & 0 \\\\\n0 & 0 & -1 & 2 & -1 & 0 & 0 \\\\\n0 & 0 & 0 & -1 & 2 & -1 & 0 \\\\\n0 & 0 & 0 & 0 & -1 & 2 & -1 \\\\\n0 & 0 & 0 & 0 & 0 & -1 & 2\n\\end{pmatrix}.\n$$\nPartition the global index set $\\{1,2,3,4,5,6,7\\}$ into two overlapping subdomains\n$$\n\\Omega_1 \\;=\\; \\{1,2,3,4\\}, \\qquad \\Omega_2 \\;=\\; \\{4,5,6,7\\},\n$$\nwith one-node overlap at index $4$. Let $R_i \\in \\mathbb{R}^{4 \\times 7}$ denote the restriction that extracts the components in $\\Omega_i$ from a global vector in $\\mathbb{R}^7$, and let $P_i \\in \\mathbb{R}^{7 \\times 4}$ be the corresponding natural injection (i.e., $P_i = R_i^{\\top}$). \n\nTasks:\n- Explicitly write $R_1$, $R_2$, $P_1$, and $P_2$ as $0$-$1$ matrices.\n- Using only the definitions of restriction and injection, verify that $\\sum_{i=1}^{2} P_i R_i \\neq I_7$.\n- Now introduce diagonal scalings $D_1 = \\mathrm{diag}(1,1,1,w) \\in \\mathbb{R}^{4 \\times 4}$ and $D_2 = \\mathrm{diag}(w,1,1,1) \\in \\mathbb{R}^{4 \\times 4}$, where $w \\in \\mathbb{R}$ is a single overlap weight applied symmetrically to the shared node in each subdomain and all non-overlapping nodes have weight $1$. Determine the unique real value of $w$ (under this symmetry assumption) such that the partition-of-unity identity\n$$\n\\sum_{i=1}^{2} P_i D_i R_i \\;=\\; I_7\n$$\nholds exactly.\n\nYour final answer must be the value of $w$ as an exact number. No rounding is required.",
            "solution": "The problem is well-posed and scientifically grounded within the field of numerical linear algebra, specifically concerning domain decomposition methods. All definitions and data are self-contained and consistent. The stiffness matrix $A$ provides context for the origin of such a problem, but its specific values are not required for the tasks, which focus on the geometric decomposition and the construction of a partition of unity. We may therefore proceed with a complete solution.\n\nThe problem requires us to perform three tasks related to a domain decomposition of a $7$-node grid. The global index set is $\\{1, 2, 3, 4, 5, 6, 7\\}$.\n\n**Task 1: Explicitly write $R_1$, $R_2$, $P_1$, and $P_2$**\n\nThe restriction operator $R_i \\in \\mathbb{R}^{m_i \\times n}$ for a subdomain $\\Omega_i$ with $m_i$ indices, drawn from a global domain with $n$ indices, is a matrix that extracts the components corresponding to $\\Omega_i$. Here, the global dimension is $n=7$ and the local dimension for both subdomains is $m_1=m_2=4$.\n\nFor the first subdomain $\\Omega_1 = \\{1, 2, 3, 4\\}$, the restriction operator $R_1 \\in \\mathbb{R}^{4 \\times 7}$ extracts the first four components of a global vector in $\\mathbb{R}^7$. Its rows are the standard basis vectors $e_1^{\\top}, e_2^{\\top}, e_3^{\\top}, e_4^{\\top}$ of $\\mathbb{R}^7$.\n$$\nR_1 \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 & 0 & 0\n\\end{pmatrix}\n$$\nThe corresponding injection operator $P_1 \\in \\mathbb{R}^{7 \\times 4}$ is the transpose of $R_1$:\n$$\nP_1 = R_1^{\\top} \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0\n\\end{pmatrix}\n$$\n\nFor the second subdomain $\\Omega_2 = \\{4, 5, 6, 7\\}$, the restriction operator $R_2 \\in \\mathbb{R}^{4 \\times 7}$ extracts components $4, 5, 6, 7$. Its rows are the standard basis vectors $e_4^{\\top}, e_5^{\\top}, e_6^{\\top}, e_7^{\\top}$ of $\\mathbb{R}^7$.\n$$\nR_2 \\;=\\;\n\\begin{pmatrix}\n0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 1\n\\end{pmatrix}\n$$\nThe corresponding injection operator $P_2 \\in \\mathbb{R}^{7 \\times 4}$ is the transpose of $R_2$:\n$$\nP_2 = R_2^{\\top} \\;=\\;\n\\begin{pmatrix}\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n$$\n\n**Task 2: Verify that $\\sum_{i=1}^{2} P_i R_i \\neq I_7$**\n\nWe compute the products $P_1 R_1$ and $P_2 R_2$ and sum them.\nThe product $P_1 R_1$ is a $7 \\times 7$ matrix:\n$$\nP_1 R_1 \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 & 0 & 0\n\\end{pmatrix} \\;=\\; \\mathrm{diag}(1, 1, 1, 1, 0, 0, 0)\n$$\nThe product $P_2 R_2$ is also a $7 \\times 7$ matrix:\n$$\nP_2 R_2 \\;=\\;\n\\begin{pmatrix}\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 1\n\\end{pmatrix} \\;=\\; \\mathrm{diag}(0, 0, 0, 1, 1, 1, 1)\n$$\nThe sum is:\n$$\n\\sum_{i=1}^{2} P_i R_i = P_1 R_1 + P_2 R_2 = \\mathrm{diag}(1, 1, 1, 1, 0, 0, 0) + \\mathrm{diag}(0, 0, 0, 1, 1, 1, 1) = \\mathrm{diag}(1, 1, 1, 2, 1, 1, 1)\n$$\nThis resulting matrix is not the $7 \\times 7$ identity matrix $I_7 = \\mathrm{diag}(1, 1, 1, 1, 1, 1, 1)$, because the fourth diagonal entry is $2$ instead of $1$. This is a direct consequence of the node with global index $4$ belonging to both subdomains. Thus, we have verified that $\\sum_{i=1}^{2} P_i R_i \\neq I_7$.\n\n**Task 3: Determine $w$ for the partition-of-unity identity**\n\nWe are asked to find the value of $w \\in \\mathbb{R}$ such that $\\sum_{i=1}^{2} P_i D_i R_i = I_7$, where $D_1 = \\mathrm{diag}(1, 1, 1, w)$ and $D_2 = \\mathrm{diag}(w, 1, 1, 1)$. We compute the terms $P_1 D_1 R_1$ and $P_2 D_2 R_2$.\n\nFor the first term:\n$$\nP_1 D_1 R_1 = P_1 \\left( \\begin{pmatrix} 1&0&0&0 \\\\ 0&1&0&0 \\\\ 0&0&1&0 \\\\ 0&0&0&w \\end{pmatrix} R_1 \\right) = P_1 \\begin{pmatrix}\n1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & w & 0 & 0 & 0\n\\end{pmatrix} = \\mathrm{diag}(1, 1, 1, w, 0, 0, 0)\n$$\nFor the second term:\n$$\nP_2 D_2 R_2 = P_2 \\left( \\begin{pmatrix} w&0&0&0 \\\\ 0&1&0&0 \\\\ 0&0&1&0 \\\\ 0&0&0&1 \\end{pmatrix} R_2 \\right) = P_2 \\begin{pmatrix}\n0 & 0 & 0 & w & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 1\n\\end{pmatrix} = \\mathrm{diag}(0, 0, 0, w, 1, 1, 1)\n$$\nThe sum is:\n$$\n\\sum_{i=1}^{2} P_i D_i R_i = \\mathrm{diag}(1, 1, 1, w, 0, 0, 0) + \\mathrm{diag}(0, 0, 0, w, 1, 1, 1) = \\mathrm{diag}(1, 1, 1, w+w, 1, 1, 1)\n$$\n$$\n= \\mathrm{diag}(1, 1, 1, 2w, 1, 1, 1)\n$$\nFor this matrix to be equal to the identity matrix $I_7 = \\mathrm{diag}(1, 1, 1, 1, 1, 1, 1)$, their corresponding entries must be equal. The entries for indices $1, 2, 3, 5, 6, 7$ are already $1$. For the fourth diagonal entry, we must have:\n$$\n2w = 1\n$$\nSolving for $w$ yields:\n$$\nw = \\frac{1}{2}\n$$\nThis is the unique value of $w$ that satisfies the partition-of-unity condition. This weighting scheme ensures that the contribution of the overlapping node, which is counted twice, is scaled by one-half in each subdomain, so that its total contribution sums to unity.",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        },
        {
            "introduction": "Building upon the algebraic framework of restriction and prolongation, we can now construct a complete preconditioner. This practice guides you through the assembly of the one-level Additive Schwarz (AS) preconditioner, where local problems are solved independently on each subdomain and their solutions are additively combined . You will gain a concrete understanding of this parallel procedure by forming the local matrices $A_i = R_i A R_i^{\\top}$, computing their inverses, and assembling the full operator $M^{-1}$ to see how local solves approximate the global inverse.",
            "id": "3544279",
            "problem": "Consider the one-dimensional Poisson equation with homogeneous Dirichlet boundary conditions discretized by the standard second-order centered finite difference (FD) method on a uniform grid with $8$ interior points. This yields a symmetric positive definite matrix $A \\in \\mathbb{R}^{8 \\times 8}$ with entries $2$ on the main diagonal and $-1$ on the first sub- and super-diagonals. Two overlapping subdomains are defined by the index sets $\\mathcal{I}_{1}=\\{1,2,3,4,5\\}$ and $\\mathcal{I}_{2}=\\{4,5,6,7,8\\}$. Let the restriction operators $R_{1} \\in \\mathbb{R}^{5 \\times 8}$ and $R_{2} \\in \\mathbb{R}^{5 \\times 8}$ extract the components of a global vector corresponding to the indices in $\\mathcal{I}_{1}$ and $\\mathcal{I}_{2}$, respectively. Form the local operators $A_{1}=R_{1} A R_{1}^{\\top} \\in \\mathbb{R}^{5 \\times 5}$ and $A_{2}=R_{2} A R_{2}^{\\top} \\in \\mathbb{R}^{5 \\times 5}$. Define the one-level Additive Schwarz (AS) preconditioner by the canonical formula\n$$\nM^{-1} \\;=\\; R_{1}^{\\top} A_{1}^{-1} R_{1} \\;+\\; R_{2}^{\\top} A_{2}^{-1} R_{2}.\n$$\nCompute $R_{1}$ and $R_{2}$ explicitly, compute $A_{1}$ and $A_{2}$ explicitly, and assemble $M^{-1}$ and the preconditioned operator $M^{-1}A$ in algebraic form from first principles of domain decomposition. Finally, report the exact value of the entry in position $(4,4)$ of the matrix $M^{-1}A$. Provide the final answer as an exact number. No rounding is required, and no units are involved.",
            "solution": "The problem statement is a well-posed and self-contained exercise in numerical linear algebra, specifically concerning the construction of a one-level Additive Schwarz (AS) preconditioner for a model problem. All parameters and definitions are clear, scientifically sound, and standard in the field of domain decomposition methods. The problem is therefore valid.\n\nWe proceed with the solution by following the steps outlined in the problem.\n\n**Step 1: Construct the Global Matrix $A$**\n\nThe problem describes the discretization of the one-dimensional Poisson equation on a uniform grid with $8$ interior points using a centered finite difference scheme. This results in an $8 \\times 8$ symmetric tridiagonal matrix $A$ with $2$ on the main diagonal and $-1$ on the first sub-diagonal and super-diagonal.\n\n$$\nA = \\begin{pmatrix}\n2 & -1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n-1 & 2 & -1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & -1 & 2 & -1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & -1 & 2 & -1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & -1 & 2 & -1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & -1 & 2 & -1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & -1 & 2 & -1 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & -1 & 2\n\\end{pmatrix}\n$$\n\n**Step 2: Construct the Restriction Operators $R_1$ and $R_2$**\n\nThe subdomains are defined by the index sets $\\mathcal{I}_{1}=\\{1,2,3,4,5\\}$ and $\\mathcal{I}_{2}=\\{4,5,6,7,8\\}$. The restriction operator $R_k$ is a matrix that extracts the components of a global vector corresponding to the indices in $\\mathcal{I}_k$.\n\nThe operator $R_1 \\in \\mathbb{R}^{5 \\times 8}$ maps a vector in $\\mathbb{R}^8$ to a vector in $\\mathbb{R}^5$ by selecting the first $5$ components. This is represented by a matrix containing the first $5$ rows of the $8 \\times 8$ identity matrix.\n\n$$\nR_1 = \\begin{pmatrix}\n1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & 0\n\\end{pmatrix}\n$$\n\nThe operator $R_2 \\in \\mathbb{R}^{5 \\times 8}$ maps a vector in $\\mathbb{R}^8$ to a vector in $\\mathbb{R}^5$ by selecting components $4, 5, 6, 7, 8$.\n\n$$\nR_2 = \\begin{pmatrix}\n0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n\\end{pmatrix}\n$$\n\n**Step 3: Construct the Local Operators $A_1$ and $A_2$**\n\nThe local operators are defined as $A_k = R_k A R_k^{\\top}$.\n\nFor $A_1 = R_1 A R_1^{\\top}$, $R_1 A$ selects the first $5$ rows of $A$, and right-multiplication by $R_1^{\\top}$ selects the first $5$ columns of the result. This corresponds to extracting the principal submatrix of $A$ associated with indices $\\{1,2,3,4,5\\}$.\n\n$$\nA_1 = R_1 A R_1^{\\top} = \\begin{pmatrix}\n2 & -1 & 0 & 0 & 0 \\\\\n-1 & 2 & -1 & 0 & 0 \\\\\n0 & -1 & 2 & -1 & 0 \\\\\n0 & 0 & -1 & 2 & -1 \\\\\n0 & 0 & 0 & -1 & 2\n\\end{pmatrix}\n$$\n\nFor $A_2 = R_2 A R_2^{\\top}$, the operation extracts the principal submatrix of $A$ associated with indices $\\{4,5,6,7,8\\}$.\n\n$$\nA_2 = R_2 A R_2^{\\top} = \\begin{pmatrix}\n2 & -1 & 0 & 0 & 0 \\\\\n-1 & 2 & -1 & 0 & 0 \\\\\n0 & -1 & 2 & -1 & 0 \\\\\n0 & 0 & -1 & 2 & -1 \\\\\n0 & 0 & 0 & -1 & 2\n\\end{pmatrix}\n$$\n\nThus, $A_1$ and $A_2$ are identical $5 \\times 5$ matrices.\n\n**Step 4: Compute the Inverses of the Local Operators**\n\nWe need to compute $A_1^{-1}$ and $A_2^{-1}$. Since $A_1=A_2$, their inverses are also identical. For an $n \\times n$ matrix $T_n$ with $2$s on the diagonal and $-1$s on the off-diagonals, the entries of its inverse are given by the formula $(T_n^{-1})_{ij} = \\frac{\\min(i,j)(n+1-\\max(i,j))}{n+1}$.\nFor our $5 \\times 5$ matrices, $n=5$. Thus, $(A_1^{-1})_{ij} = \\frac{\\min(i,j)(6-\\max(i,j))}{6}$.\n\n$$\nA_1^{-1} = A_2^{-1} = \\frac{1}{6} \\begin{pmatrix}\n5 & 4 & 3 & 2 & 1 \\\\\n4 & 8 & 6 & 4 & 2 \\\\\n3 & 6 & 9 & 6 & 3 \\\\\n2 & 4 & 6 & 8 & 4 \\\\\n1 & 2 & 3 & 4 & 5\n\\end{pmatrix}\n$$\n\n**Step 5: Assemble the Preconditioner $M^{-1}$**\n\nThe Additive Schwarz preconditioner is given by $M^{-1} = R_{1}^{\\top} A_{1}^{-1} R_{1} + R_{2}^{\\top} A_{2}^{-1} R_{2}$.\n\nThe term $R_{1}^{\\top} A_{1}^{-1} R_{1}$ \"prolongates\" the local inverse $A_1^{-1}$ back to the global $8 \\times 8$ space, padding it with zeros. This results in $A_1^{-1}$ occupying the top-left $5 \\times 5$ block corresponding to indices $\\{1,2,3,4,5\\}$.\nThe term $R_{2}^{\\top} A_{2}^{-1} R_{2}$ similarly prolongates $A_2^{-1}$ into the $8 \\times 8$ block corresponding to indices $\\{4,5,6,7,8\\}$.\n\nWe add these two matrices. The overlap occurs on the block corresponding to indices $\\{4,5\\}$.\n\n$$\n6 M^{-1} =\n\\begin{pmatrix}\n5 & 4 & 3 & 2 & 1 & 0 & 0 & 0 \\\\\n4 & 8 & 6 & 4 & 2 & 0 & 0 & 0 \\\\\n3 & 6 & 9 & 6 & 3 & 0 & 0 & 0 \\\\\n2 & 4 & 6 & 8 & 4 & 0 & 0 & 0 \\\\\n1 & 2 & 3 & 4 & 5 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 5 & 4 & 3 & 2 & 1 \\\\\n0 & 0 & 0 & 4 & 8 & 6 & 4 & 2 \\\\\n0 & 0 & 0 & 3 & 6 & 9 & 6 & 3 \\\\\n0 & 0 & 0 & 2 & 4 & 6 & 8 & 4 \\\\\n0 & 0 & 0 & 1 & 2 & 3 & 4 & 5\n\\end{pmatrix}\n$$\n\n$$\n6 M^{-1} =\n\\begin{pmatrix}\n5 & 4 & 3 & 2 & 1 & 0 & 0 & 0 \\\\\n4 & 8 & 6 & 4 & 2 & 0 & 0 & 0 \\\\\n3 & 6 & 9 & 6 & 3 & 0 & 0 & 0 \\\\\n2 & 4 & 6 & 13 & 8 & 3 & 2 & 1 \\\\\n1 & 2 & 3 & 8 & 13 & 6 & 4 & 2 \\\\\n0 & 0 & 0 & 3 & 6 & 9 & 6 & 3 \\\\\n0 & 0 & 0 & 2 & 4 & 6 & 8 & 4 \\\\\n0 & 0 & 0 & 1 & 2 & 3 & 4 & 5\n\\end{pmatrix}\n$$\n\nThus, we have the algebraic form of $M^{-1}$.\n\n**Step 6: Compute the Entry $(M^{-1}A)_{4,4}$**\n\nThe entry $(M^{-1}A)_{4,4}$ of the preconditioned operator $M^{-1}A$ is the inner product of the $4$-th row of $M^{-1}$ and the $4$-th column of $A$.\n\nThe $4$-th row of $M^{-1}$ is:\n$$ (M^{-1})_{4,*} = \\frac{1}{6} \\begin{pmatrix} 2 & 4 & 6 & 13 & 8 & 3 & 2 & 1 \\end{pmatrix} $$\n\nThe $4$-th column of $A$ is:\n$$ (A)_{*,4} = \\begin{pmatrix} 0 & 0 & -1 & 2 & -1 & 0 & 0 & 0 \\end{pmatrix}^{\\top} $$\n\nNow, we compute the inner product:\n$$ (M^{-1}A)_{4,4} = \\left( \\frac{1}{6} \\begin{pmatrix} 2 & 4 & 6 & 13 & 8 & 3 & 2 & 1 \\end{pmatrix} \\right) \\cdot \\begin{pmatrix} 0 \\\\ 0 \\\\ -1 \\\\ 2 \\\\ -1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\n$$ (M^{-1}A)_{4,4} = \\frac{1}{6} \\left[ (2)(0) + (4)(0) + (6)(-1) + (13)(2) + (8)(-1) + (3)(0) + (2)(0) + (1)(0) \\right] $$\n$$ (M^{-1}A)_{4,4} = \\frac{1}{6} \\left[ 0 + 0 - 6 + 26 - 8 + 0 + 0 + 0 \\right] $$\n$$ (M^{-1}A)_{4,4} = \\frac{1}{6} \\left[ 26 - 14 \\right] $$\n$$ (M^{-1}A)_{4,4} = \\frac{12}{6} = 2 $$\n\nAlternatively, we can use the structure of $A$: $(M^{-1}A)_{4,4} = (M^{-1}( -e_3 + 2e_4 - e_5 ))_4 = -(M^{-1})_{4,3} + 2(M^{-1})_{4,4} - (M^{-1})_{4,5}$, where $e_j$ are standard basis vectors. Using the entries from the $4$-th row of $M^{-1}$ we computed:\n$$ (M^{-1})_{4,3} = \\frac{6}{6} = 1 $$\n$$ (M^{-1})_{4,4} = \\frac{13}{6} $$\n$$ (M^{-1})_{4,5} = \\frac{8}{6} $$\nThus:\n$$ (M^{-1}A)_{4,4} = -1 + 2\\left(\\frac{13}{6}\\right) - \\frac{8}{6} = -\\frac{6}{6} + \\frac{26}{6} - \\frac{8}{6} = \\frac{26 - 14}{6} = \\frac{12}{6} = 2 $$\nBoth methods yield the same result. The value of $2$ for the diagonal entry of $M^{-1}A$ at an overlap node reflects the fact that this degree of freedom is part of two subproblems, and a simple additive combination of local solutions leads to a \"double\" correction at that node.",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "While additive methods combine corrections simultaneously, multiplicative methods apply them sequentially, which can lead to faster convergence but is inherently serial. This exercise delves into the convergence analysis of the Multiplicative Schwarz method by guiding you to derive its error-propagation operator from first principles . By explicitly computing this operator and its spectral radius, $\\rho(E)$, you will establish a direct, quantitative link between the algebraic definition of the iteration and its asymptotic rate of convergence.",
            "id": "3544255",
            "problem": "Consider the one-dimensional Poisson boundary value problem $-u''(x)=f(x)$ on $[0,1]$ with homogeneous Dirichlet boundary conditions $u(0)=u(1)=0$. Discretize using the standard second-order centered finite difference with $N=5$ interior grid points. For the linear system $A u = b$, take the stiffness matrix $A \\in \\mathbb{R}^{5 \\times 5}$ to be the unscaled Dirichlet discrete Laplacian\n$$\nA \\;=\\; \\begin{pmatrix}\n2 & -1 & 0 & 0 & 0 \\\\\n-1 & 2 & -1 & 0 & 0 \\\\\n0 & -1 & 2 & -1 & 0 \\\\\n0 & 0 & -1 & 2 & -1 \\\\\n0 & 0 & 0 & -1 & 2\n\\end{pmatrix}.\n$$\nPartition the index set $\\{1,2,3,4,5\\}$ into two overlapping subdomains $\\Omega_{1}=\\{1,2,3\\}$ and $\\Omega_{2}=\\{3,4,5\\}$. Define the restriction operators $R_{1},R_{2} \\in \\mathbb{R}^{3 \\times 5}$ to extract the components on $\\Omega_{1}$ and $\\Omega_{2}$, respectively, and set the prolongations to be $P_{i}=R_{i}^{\\top}$ for $i \\in \\{1,2\\}$. Define the local operators by $A_{i} = R_{i} A P_{i}$, which correspond to exact subdomain solves with homogeneous Dirichlet conditions on the artificial subdomain boundaries. Consider the multiplicative Alternating Schwarz Method (ASM), which applies an exact solve on $\\Omega_{1}$ followed by an exact solve on $\\Omega_{2}$ at each iteration, and view it as a stationary method acting linearly on the current error vector.\n\nStarting from these definitions only, first derive the one-step error-propagation operator of the two-subdomain multiplicative Schwarz iteration in terms of $A$, $R_{i}$, $P_{i}$, and $A_{i}^{-1}$, explaining each step of the derivation from first principles in numerical linear algebra and domain decomposition. Then, for the concrete data above, form the explicit $5 \\times 5$ iteration matrix and compute its spectral radius $\\rho(E)$.\n\nProvide the exact value of $\\rho(E)$ as your final answer. No rounding is required and no units are to be reported.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, objective, and complete. It presents a standard exercise in the numerical analysis of domain decomposition methods. I will proceed with the solution, which consists of two main parts as requested: first, the derivation of the error-propagation operator, and second, its explicit computation and the calculation of its spectral radius for the given data.\n\n**Part 1: Derivation of the Multiplicative Schwarz Error-Propagation Operator**\n\nLet the exact solution to the linear system be $u$, such that $A u = b$. Let $u^{(k)}$ be the approximate solution at iteration $k$. The error at this iteration is defined as $e^{(k)} = u - u^{(k)}$. The residual is $r^{(k)} = b - A u^{(k)} = A u - A u^{(k)} = A(u - u^{(k)}) = A e^{(k)}$.\n\nThe multiplicative Alternating Schwarz Method (ASM) consists of sequential corrections on the subdomains $\\Omega_1$ and $\\Omega_2$.\n\n**Step 1: Correction on Subdomain $\\Omega_1$**\n\nStarting with the approximation $u^{(k)}$, we compute a correction restricted to the degrees of freedom in $\\Omega_1$. The correction is determined by solving the local problem for the current residual. The residual on $\\Omega_1$ is $r_1^{(k)} = R_1 r^{(k)}$. The local correction $c_1$ in the coordinates of $\\Omega_1$ is found by solving the local system $A_1 c_1 = r_1^{(k)}$, which corresponds to an exact solve on the subdomain. Thus, $c_1 = A_1^{-1} r_1^{(k)} = A_1^{-1} R_1 r^{(k)}$.\n\nThis local correction is then prolonged back to the global grid and added to the current solution to produce an intermediate solution $u^{(k+1/2)}$:\n$$ u^{(k+1/2)} = u^{(k)} + P_1 c_1 = u^{(k)} + P_1 A_1^{-1} R_1 r^{(k)} $$\nTo find the error-propagation operator for this step, we analyze the transformation of the error. The new error is $e^{(k+1/2)} = u - u^{(k+1/2)}$.\n$$ e^{(k+1/2)} = u - \\left(u^{(k)} + P_1 A_1^{-1} R_1 r^{(k)}\\right) $$\nSubstituting $u-u^{(k)} = e^{(k)}$ and $r^{(k)}=A e^{(k)}$:\n$$ e^{(k+1/2)} = (u - u^{(k)}) - P_1 A_1^{-1} R_1 (A e^{(k)}) $$\n$$ e^{(k+1/2)} = e^{(k)} - P_1 A_1^{-1} R_1 A e^{(k)} = (I - P_1 A_1^{-1} R_1 A) e^{(k)} $$\nWe define the error-propagation operator for the first half-step as $E_1 = I - P_1 A_1^{-1} R_1 A$.\n\n**Step 2: Correction on Subdomain $\\Omega_2$**\n\nNext, we start with the intermediate approximation $u^{(k+1/2)}$ and apply a similar correction for subdomain $\\Omega_2$. The residual is now $r^{(k+1/2)} = b - A u^{(k+1/2)} = A e^{(k+1/2)}$. The local residual is $r_2^{(k+1/2)} = R_2 r^{(k+1/2)}$, and the local correction is $c_2 = A_2^{-1} r_2^{(k+1/2)}$. The final updated solution for iteration $k$ is:\n$$ u^{(k+1)} = u^{(k+1/2)} + P_2 c_2 = u^{(k+1/2)} + P_2 A_2^{-1} R_2 r^{(k+1/2)} $$\nThe corresponding error transformation is:\n$$ e^{(k+1)} = u - u^{(k+1)} = u - \\left(u^{(k+1/2)} + P_2 A_2^{-1} R_2 r^{(k+1/2)}\\right) $$\nSubstituting $u-u^{(k+1/2)} = e^{(k+1/2)}$ and $r^{(k+1/2)}=A e^{(k+1/2)}$:\n$$ e^{(k+1)} = e^{(k+1/2)} - P_2 A_2^{-1} R_2 A e^{(k+1/2)} = (I - P_2 A_2^{-1} R_2 A) e^{(k+1/2)} $$\nWe define the error-propagation operator for the second half-step as $E_2 = I - P_2 A_2^{-1} R_2 A$.\n\n**Step 3: Combined Operator**\n\nBy composing the two steps, we find the total error propagation for one full iteration:\n$$ e^{(k+1)} = E_2 e^{(k+1/2)} = E_2 (E_1 e^{(k)}) = (E_2 E_1) e^{(k)} $$\nTherefore, the one-step error-propagation operator for the multiplicative Schwarz method is $E = E_2 E_1$, which is:\n$$ E = (I - P_2 A_2^{-1} R_2 A) (I - P_1 A_1^{-1} R_1 A) $$\nThis completes the derivation.\n\n**Part 2: Computation for the Given Problem**\n\nThe global stiffness matrix is $A \\in \\mathbb{R}^{5 \\times 5}$:\n$$ A = \\begin{pmatrix} 2 & -1 & 0 & 0 & 0 \\\\ -1 & 2 & -1 & 0 & 0 \\\\ 0 & -1 & 2 & -1 & 0 \\\\ 0 & 0 & -1 & 2 & -1 \\\\ 0 & 0 & 0 & -1 & 2 \\end{pmatrix} $$\nThe subdomains are $\\Omega_1=\\{1,2,3\\}$ and $\\Omega_2=\\{3,4,5\\}$. The restriction operators $R_1, R_2$ and prolongation operators $P_1=R_1^\\top, P_2=R_2^\\top$ are:\n$$ R_1 = \\begin{pmatrix} 1 & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 0 \\end{pmatrix}, \\quad P_1 = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} $$\n$$ R_2 = \\begin{pmatrix} 0 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 & 1 \\end{pmatrix}, \\quad P_2 = \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} $$\nThe local operators $A_i = R_i A P_i$ are the principal submatrices of $A$:\n$$ A_1 = R_1 A P_1 = \\begin{pmatrix} 2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 2 \\end{pmatrix}, \\quad A_2 = R_2 A P_2 = \\begin{pmatrix} 2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 2 \\end{pmatrix} $$\nThe inverse of this $3 \\times 3$ matrix is required. Let $B = A_1=A_2$. The determinant is $\\det(B) = 2(4-1) - (-1)(-2) = 4$.\n$$ B^{-1} = \\frac{1}{4} \\begin{pmatrix} 3 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix} $$\nSo, $A_1^{-1} = A_2^{-1} = \\frac{1}{4} \\begin{pmatrix} 3 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix}$.\n\nNow, we construct $E_1 = I - P_1 A_1^{-1} R_1 A$.\n$$ R_1 A = \\begin{pmatrix} 2 & -1 & 0 & 0 & 0 \\\\ -1 & 2 & -1 & 0 & 0 \\\\ 0 & -1 & 2 & -1 & 0 \\end{pmatrix} $$\n$$ A_1^{-1} (R_1 A) = \\frac{1}{4} \\begin{pmatrix} 3 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix} \\begin{pmatrix} 2 & -1 & 0 & 0 & 0 \\\\ -1 & 2 & -1 & 0 & 0 \\\\ 0 & -1 & 2 & -1 & 0 \\end{pmatrix} = \\frac{1}{4} \\begin{pmatrix} 4 & 0 & 0 & -1 & 0 \\\\ 0 & 4 & 0 & -2 & 0 \\\\ 0 & 0 & 4 & -3 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 & -1/4 & 0 \\\\ 0 & 1 & 0 & -1/2 & 0 \\\\ 0 & 0 & 1 & -3/4 & 0 \\end{pmatrix} $$\n$$ P_1 (A_1^{-1} R_1 A) = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 0 & -1/4 & 0 \\\\ 0 & 1 & 0 & -1/2 & 0 \\\\ 0 & 0 & 1 & -3/4 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 & -1/4 & 0 \\\\ 0 & 1 & 0 & -1/2 & 0 \\\\ 0 & 0 & 1 & -3/4 & 0 \\\\ 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 \\end{pmatrix} $$\n$$ E_1 = I - P_1 A_1^{-1} R_1 A = \\begin{pmatrix} 0 & 0 & 0 & 1/4 & 0 \\\\ 0 & 0 & 0 & 1/2 & 0 \\\\ 0 & 0 & 0 & 3/4 & 0 \\\\ 0 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 & 1 \\end{pmatrix} $$\nNext, we construct $E_2 = I - P_2 A_2^{-1} R_2 A$.\n$$ R_2 A = \\begin{pmatrix} 0 & -1 & 2 & -1 & 0 \\\\ 0 & 0 & -1 & 2 & -1 \\\\ 0 & 0 & 0 & -1 & 2 \\end{pmatrix} $$\n$$ A_2^{-1} (R_2 A) = \\frac{1}{4} \\begin{pmatrix} 3 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix} \\begin{pmatrix} 0 & -1 & 2 & -1 & 0 \\\\ 0 & 0 & -1 & 2 & -1 \\\\ 0 & 0 & 0 & -1 & 2 \\end{pmatrix} = \\frac{1}{4} \\begin{pmatrix} 0 & -3 & 4 & 0 & 0 \\\\ 0 & -2 & 0 & 4 & 0 \\\\ 0 & -1 & 0 & 0 & 4 \\end{pmatrix} = \\begin{pmatrix} 0 & -3/4 & 1 & 0 & 0 \\\\ 0 & -1/2 & 0 & 1 & 0 \\\\ 0 & -1/4 & 0 & 0 & 1 \\end{pmatrix} $$\n$$ P_2 (A_2^{-1} R_2 A) = \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & -3/4 & 1 & 0 & 0 \\\\ 0 & -1/2 & 0 & 1 & 0 \\\\ 0 & -1/4 & 0 & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 \\\\ 0 & -3/4 & 1 & 0 & 0 \\\\ 0 & -1/2 & 0 & 1 & 0 \\\\ 0 & -1/4 & 0 & 0 & 1 \\end{pmatrix} $$\n$$ E_2 = I - P_2 A_2^{-1} R_2 A = \\begin{pmatrix} 1 & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 & 0 \\\\ 0 & 3/4 & 0 & 0 & 0 \\\\ 0 & 1/2 & 0 & 0 & 0 \\\\ 0 & 1/4 & 0 & 0 & 0 \\end{pmatrix} $$\nNow we compute the final iteration matrix $E = E_2 E_1$:\n$$ E = \\begin{pmatrix} 1 & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 & 0 \\\\ 0 & 3/4 & 0 & 0 & 0 \\\\ 0 & 1/2 & 0 & 0 & 0 \\\\ 0 & 1/4 & 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 & 0 & 1/4 & 0 \\\\ 0 & 0 & 0 & 1/2 & 0 \\\\ 0 & 0 & 0 & 3/4 & 0 \\\\ 0 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 0 & 1/4 & 0 \\\\ 0 & 0 & 0 & 1/2 & 0 \\\\ 0 & 0 & 0 & (3/4)(1/2) & 0 \\\\ 0 & 0 & 0 & (1/2)(1/2) & 0 \\\\ 0 & 0 & 0 & (1/4)(1/2) & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 0 & 1/4 & 0 \\\\ 0 & 0 & 0 & 1/2 & 0 \\\\ 0 & 0 & 0 & 3/8 & 0 \\\\ 0 & 0 & 0 & 1/4 & 0 \\\\ 0 & 0 & 0 & 1/8 & 0 \\end{pmatrix} $$\nFinally, we compute the spectral radius $\\rho(E)$, which is the maximum absolute value of the eigenvalues of $E$. The eigenvalues $\\lambda$ are the roots of the characteristic equation $\\det(E - \\lambda I) = 0$.\n$$ E - \\lambda I = \\begin{pmatrix} -\\lambda & 0 & 0 & 1/4 & 0 \\\\ 0 & -\\lambda & 0 & 1/2 & 0 \\\\ 0 & 0 & -\\lambda & 3/8 & 0 \\\\ 0 & 0 & 0 & 1/4-\\lambda & 0 \\\\ 0 & 0 & 0 & 1/8 & -\\lambda \\end{pmatrix} $$\nWe can compute the determinant of this matrix by successive cofactor expansions along the first three columns. This process shows that the determinant is simply the product of the diagonal entries:\n$$ \\det(E - \\lambda I) = (-\\lambda)(-\\lambda)(-\\lambda)(1/4 - \\lambda)(-\\lambda) = \\lambda^4 (1/4 - \\lambda) $$\nThe roots of the characteristic equation $\\lambda^4 (1/4 - \\lambda)=0$ are $\\lambda_1=\\lambda_2=\\lambda_3=\\lambda_4=0$ and $\\lambda_5 = 1/4$.\nThe set of eigenvalues of $E$ is $\\sigma(E) = \\{0, 1/4\\}$.\nThe spectral radius is the maximum modulus of these eigenvalues:\n$$ \\rho(E) = \\max_{\\lambda \\in \\sigma(E)} |\\lambda| = \\max\\{|0|, |1/4|\\} = 1/4 $$\nThis is the exact value of the spectral radius of the iteration matrix.",
            "answer": "$$\\boxed{\\frac{1}{4}}$$"
        }
    ]
}