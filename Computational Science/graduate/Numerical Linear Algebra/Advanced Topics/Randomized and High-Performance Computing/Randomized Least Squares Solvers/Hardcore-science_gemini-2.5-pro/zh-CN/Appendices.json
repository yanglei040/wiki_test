{
    "hands_on_practices": [
        {
            "introduction": "采用随机求解器的主要动机是其在处理大规模问题时可能带来的显著计算节省。本次实践为此提供了量化依据。通过分析浮点运算计数，您将直接比较“勾画求解”（sketch-and-solve）流程与经典Householder QR分解方法的成本，从而揭示其中的计算权衡。",
            "id": "3570172",
            "problem": "考虑一个高瘦最小二乘问题，其矩阵为 $A \\in \\mathbb{R}^{n \\times d}$（$n \\gg d$），向量为 $b \\in \\mathbb{R}^{n}$。令 $\\operatorname{nnz}(A)$ 表示 $A$ 的非零元个数。你采用一个降维求解流水线，使用一个无关稀疏子空间嵌入 $S \\in \\mathbb{R}^{m \\times n}$，该嵌入每列恰好有 $s$ 个非零元，其符号在 $\\{-1,+1\\}$ 中，且行位置是均匀随机的。你构建降维后的设计矩阵 $SA \\in \\mathbb{R}^{m \\times d}$，并通过对 $SA$ 进行 Householder 正交三角(QR)分解来求解降维后的问题 $\\min_{x \\in \\mathbb{R}^{d}} \\|SAx - Sb\\|_{2}$。假设以下来自数值线性代数的经过充分检验的性能模型和事实：\n- 通过稀疏嵌入应用计算 $SA = SA(A)$ 时，$A$ 的每个非零元对 $SA$ 的相应条目贡献 $s$ 次更新，因此形成 $SA$ 的算术成本与 $s \\cdot \\operatorname{nnz}(A)$ 成正比。\n- 对于 $m \\ge d$ 的稠密矩阵 $\\mathbb{R}^{m \\times d}$，其 Householder 正交三角(QR)分解的成本为 $2md^{2} - \\frac{2}{3}d^{3}$ 次浮点运算。\n- 对原始矩阵 $A \\in \\mathbb{R}^{n \\times d}$（在填充后通常是稠密的）进行经典的 Householder 正交三角(QR)分解，其成本为 $2nd^{2} - \\frac{2}{3}d^{3}$ 次浮点运算。\n\n基于这些基础，推导出以下两项的精确算术运算次数，以 $n$、$d$、$m$、$s$ 和 $\\operatorname{nnz}(A)$ 的符号表达式表示：\n1. 形成 $SA$ 并通过对 $SA$ 进行 Householder 正交三角(QR)分解来求解降维后问题的总浮点运算次数。\n2. 对 $A$ 进行经典 Householder 正交三角(QR)分解的浮点运算次数。\n\n将你的最终答案表示为一个单行矩阵，包含对应于上述项目1和2的两个条目。你的答案应是以 $n$、$d$、$m$、$s$ 和 $\\operatorname{nnz}(A)$ 表示的闭式解析表达式，单位为浮点运算次数。无需四舍五入。",
            "solution": "在进行求解之前，先评估问题陈述的有效性。\n\n### 步骤1：提取已知条件\n- 一个高瘦最小二乘问题，其矩阵为 $A \\in \\mathbb{R}^{n \\times d}$，向量为 $b \\in \\mathbb{R}^{n}$。\n- 条件：$n \\gg d$。\n- 记号：$\\operatorname{nnz}(A)$ 是 $A$ 的非零元个数。\n- 方法：一个使用无关稀疏子空间嵌入 $S \\in \\mathbb{R}^{m \\times n}$ 的降维求解流水线。\n- $S$ 的性质：每列恰好有 $s$ 个非零元，其值在 $\\{-1,+1\\}$ 中，且行位置是均匀随机的。\n- 降维后的问题：$\\min_{x \\in \\mathbb{R}^{d}} \\|SAx - Sb\\|_{2}$。\n- 降维后问题的求解方法：对矩阵 $SA \\in \\mathbb{R}^{m \\times d}$ 进行 Householder 正交三角(QR)分解。\n- 成本模型1：形成 $SA$ 的算术成本与 $s \\cdot \\operatorname{nnz}(A)$ 成正比，基于 $A$ 的每个非零元贡献 $s$ 次更新这一事实。\n- 成本模型2：对于 $m \\ge d$ 的稠密矩阵 $\\mathbb{R}^{m \\times d}$，其 Householder QR 分解的成本为 $2md^{2} - \\frac{2}{3}d^{3}$ 次浮点运算。\n- 成本模型3：对 $A \\in \\mathbb{R}^{n \\times d}$ 进行经典的 Householder QR 分解的成本为 $2nd^{2} - \\frac{2}{3}d^{3}$ 次浮点运算。\n- 要求：推导以下两项的精确算术运算次数：\n  1. 形成 $SA$ 并通过对 $SA$ 进行 Householder QR 分解来求解降维后问题。\n  2. 对 $A$ 进行经典的 Householder QR 分解。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题定义明确且科学上合理。它基于随机数值线性代数的既定原则，特别是用于超定最小二乘问题的“降维求解”方法。所提供的 Householder QR 分解的成本模型是标准的，代表了运算次数中的主导项。关于稀疏嵌入及其应用成本模型的描述与前沿文献（例如 Clarkson-Woodruff 草图）一致。所有必要的变量（$n, d, m, s, \\operatorname{nnz}(A)$）都已定义。该问题是客观且可形式化的。\n\n“求解降维后的问题”这一短语需要仔细解释。完整的求解过程包括形成 $Sb$、对 $SA$ 进行 QR 分解、将正交变换应用于 $Sb$ 以及求解得到的三角方程组。问题仅为分解步骤（$2md^2 - \\frac{2}{3}d^3$）提供了特定的成本模型。问题的并行结构（其中经典方法的成本也仅给出分解的成本）强烈暗示“通过 QR 求解”指的是这个占主导地位的分解阶段。然而，建立降维后的问题还需要形成 $Sb$。形成 $Sb$ 的成本没有明确给出，但可以以类似于形成 $SA$ 的方式从 $S$ 的性质中直接推导出来。一个有能力的学生应该能够推导出这个成本。因此，该问题被认为是完整且适定的。\n\n### 步骤3：结论与行动\n该问题是**有效的**。将根据所提供的模型和逻辑推导得出解决方案。\n\n### 运算次数的推导\n\n该问题要求计算两个不同的运算次数。\n\n**1. 降维求解方法的总运算次数**\n\n此方法的总浮点运算次数是三个组成部分的总和：\n(a) 形成降维矩阵 $SA$ 的成本。\n(b) 形成降维向量 $Sb$ 的成本。\n(c) 使用对 $SA$ 的 Householder QR 分解来求解降维最小二乘问题的成本。\n\n(a) 形成 $SA$ 的成本：\n降维矩阵 $S \\in \\mathbb{R}^{m \\times n}$ 每列有 $s$ 个非零元，其值为 $+1$ 或 $-1$。乘积 $SA$ 的形成可以从 $A$ 的非零元的角度来看。对于每个非零元 $A_{ij}$，它参与了 $SA$ 第 $j$ 列的计算。具体来说，值 $A_{ij}$ 与 $S$ 的第 $i$ 列相乘。由于 $S$ 的第 $i$ 列有 $s$ 个非零元，$A_{ij}$ 对 $SA$ 第 $j$ 列中的 $s$ 个条目有贡献。每个这样的贡献都是一次形式为 $(SA)_{k,j} \\leftarrow (SA)_{k,j} + S_{k,i}A_{ij}$ 的更新。由于 $S_{k,i} \\in \\{-1, +1\\}$，这是一个加法或减法，计为一次浮点运算。因为 $A$ 中有 $\\operatorname{nnz}(A)$ 个非零元，总成本为：\n$$ \\text{Cost}(SA) = s \\cdot \\operatorname{nnz}(A) $$\n\n(b) 形成 $Sb$ 的成本：\n这个成本必须作为建立降维后问题的一部分。向量 $b \\in \\mathbb{R}^n$ 通常是稠密的。乘积 $Sb$ 是通过将稀疏矩阵 $S$ 乘以向量 $b$ 来计算的。对于向量 $b$ 的每个元素 $b_i$（对于 $i=1, \\dots, n$），它与 $S$ 的第 $i$ 列相乘。该列有 $s$ 个非零元。因此，$b_i$ 会被加到或减到结果向量 $Sb$ 中的 $s$ 个条目上。对 $b$ 的所有 $n$ 个元素重复此过程。总浮点运算次数为：\n$$ \\text{Cost}(Sb) = s \\cdot n $$\n\n(c) 通过对 $SA$ 进行QR分解求解的成本：\n矩阵 $SA$ 属于 $\\mathbb{R}^{m \\times d}$。问题明确给出了对此类矩阵进行 Householder QR 分解的成本为 $2md^{2} - \\frac{2}{3}d^{3}$。正如在验证过程中所论证的，我们使用这个成本作为通过 QR “求解”系统的成本。\n$$ \\text{Cost}(\\text{QR on } SA) = 2md^{2} - \\frac{2}{3}d^{3} $$\n\n第一部分的总成本是这三个组成部分的总和：\n$$ \\text{Total Cost}_1 = \\text{Cost}(SA) + \\text{Cost}(Sb) + \\text{Cost}(\\text{QR on } SA) = s \\cdot \\operatorname{nnz}(A) + sn + 2md^{2} - \\frac{2}{3}d^{3} $$\n\n**2. 经典 Householder QR 方法的运算次数**\n\n问题要求计算对原始矩阵 $A \\in \\mathbb{R}^{n \\times d}$ 进行经典 Householder QR 分解的浮点运算次数。此成本已在问题陈述中直接给出：\n$$ \\text{Total Cost}_2 = 2nd^{2} - \\frac{2}{3}d^{3} $$\n\n这两个表达式代表了问题两个部分的最终答案。它们将按要求以行矩阵的形式呈现。",
            "answer": "$$ \\boxed{\\begin{pmatrix} s \\cdot \\operatorname{nnz}(A) + sn + 2md^{2} - \\frac{2}{3}d^{3}  2nd^{2} - \\frac{2}{3}d^{3} \\end{pmatrix}} $$"
        },
        {
            "introduction": "虽然随机勾画能提供普适的加速效果，但通过采用更“智能”的、依赖于数据的采样策略，其效率可以得到显著提升。本次实践将要求您构建一个具有高度非均匀杠杆分数（leverage scores）的矩阵，以展示杠杆分数采样的威力。通过计算该矩阵的“相干性”（coherence）以及由此带来的样本复杂度，您将具体理解为何根据数据几何特性来调整勾画是一种至关重要的优化手段。",
            "id": "3570188",
            "problem": "考虑一个超定最小二乘问题，其设计矩阵为 $A \\in \\mathbb{R}^{n \\times k}$，响应向量为 $b \\in \\mathbb{R}^{n}$，目标是计算 $x^{\\star} \\in \\arg\\min_{x \\in \\mathbb{R}^{k}} \\|A x - b\\|_{2}$。假设采用一种“勾画-求解” (sketch-and-solve)方法，其中使用一个采样与重加权矩阵 $S \\in \\mathbb{R}^{m \\times n}$ 来构建一个勾画问题 $\\min_{x \\in \\mathbb{R}^{k}} \\|S A x - S b\\|_{2}$。采样概率记为 $p_{i}$（其中 $i \\in \\{1,2,\\dots,n\\}$），每个选定的行都通过因子 $(m p_{i})^{-1/2}$ 进行重加权。\n\n将行杠杆分数 $\\ell_{i}$ 定义为到 $A$ 的列空间的正交投影算子的对角线元素，等价地，$\\ell_{i} = \\|U_{i,:}\\|_{2}^{2}$，其中 $A = U R$ 是瘦QR分解，$U \\in \\mathbb{R}^{n \\times k}$ 具有标准正交列，$R \\in \\mathbb{R}^{k \\times k}$ 是上三角矩阵。$A$ 的相干性定义为 $\\mu(A) = \\frac{n}{k} \\max_{i} \\ell_{i}$。\n\n使用多项式特征构建一个最坏情况的相干设计：取 $k = 2$，并让 $A$ 由1次单项式特征构成，即 $A$ 的两列分别对应于函数 $x \\mapsto 1$ 和 $x \\mapsto x$。设 $n$ 个输入位置为 $x_{1}, \\dots, x_{n} \\in \\{-1, +1\\}$，其中恰好有一个位置等于 $-1$，其余 $n-1$ 个位置等于 $+1$。利用最小二乘、杠杆分数和相干性的基本定义，确定此设计的相干性 $\\mu(A)$。\n\n使用子空间嵌入的概念（对于失真度为 $(1 \\pm \\varepsilon)$ 且失败概率至多为 $\\delta$），以及标准的采样与重加权构造方法，从第一性原理出发，论证均匀采样（即对所有 $i$，$p_i=1/n$）的最小充分样本量与 $m_{\\mathrm{unif}} \\propto k \\ln(k/\\delta) \\mu(A) \\varepsilon^{-2}$ 成比例，而杠杆分数采样（即 $p_i = \\ell_i/k$）的最小充分样本量与 $m_{\\mathrm{lev}} \\propto k \\ln(k/\\delta) \\varepsilon^{-2}$ 成比例。对于上述多项式设计，在 $(\\varepsilon, \\delta)$ 相同的情况下，推导出精确的渐近增益因子，其定义为比率 $m_{\\mathrm{unif}}/m_{\\mathrm{lev}}$，并将最终答案表示为仅含 $n$ 的单个闭式解析表达式。不涉及物理单位。无需四舍五入。",
            "solution": "用户希望针对一个特定的最小二乘问题，找出杠杆分数采样相对于均匀采样的渐近增益因子。\n\n### 第1步：提取已知条件\n- 问题类型：超定最小二乘，$\\min_{x \\in \\mathbb{R}^{k}} \\|A x - b\\|_{2}$。\n- 设计矩阵：$A \\in \\mathbb{R}^{n \\times k}$。\n- 响应向量：$b \\in \\mathbb{R}^{n}$。\n- 勾画矩阵：$S \\in \\mathbb{R}^{m \\times n}$，一个采样与重加权矩阵。\n- 勾画问题：$\\min_{x \\in \\mathbb{R}^{k}} \\|S A x - S b\\|_{2}$。\n- 采样概率：$p_{i}$，其中 $i \\in \\{1, 2, \\dots, n\\}$。\n- 重加权因子：$(m p_{i})^{-1/2}$。\n- 杠杆分数：$\\ell_{i} = \\|U_{i,:}\\|_{2}^{2}$，其中 $A=UR$ 是 $A$ 的瘦QR分解，且 $U \\in \\mathbb{R}^{n \\times k}$ 具有标准正交列。\n- 相干性：$\\mu(A) = \\frac{n}{k} \\max_{i} \\ell_{i}$。\n- 具体设计：\n    - $k=2$。\n    - $A$ 的列是基函数 $x \\mapsto 1$ 和 $x \\mapsto x$。\n    - 输入位置 $x_{1}, \\dots, x_{n} \\in \\{-1, +1\\}$。\n    - 恰好有一个位置是 $-1$，其余 $n-1$ 个是 $+1$。令 $x_{1}=-1$ 且对于 $i=2, \\dots, n$ 有 $x_{i}=+1$。\n- 对于失真度为 $(1 \\pm \\varepsilon)$ 且失败概率为 $\\delta$ 的样本量缩放关系：\n    - 均匀采样 ($p_{i} = 1/n$): $m_{\\mathrm{unif}} \\propto k \\ln(k/\\delta) \\mu(A) \\varepsilon^{-2}$。\n    - 杠杆分数采样 ($p_{i} = \\ell_{i}/k$): $m_{\\mathrm{lev}} \\propto k \\ln(k/\\delta) \\varepsilon^{-2}$。\n- 目标：确定精确的渐近增益因子，定义为比率 $m_{\\mathrm{unif}}/m_{\\mathrm{lev}}$。\n\n### 第2步：使用提取的已知条件进行验证\n该问题在科学上和数学上都是合理的。它基于数值线性代数和随机算法中标准的、成熟的概念，包括最小二乘、QR分解、统计杠杆分数、相干性以及勾画-求解方法（特别是采样和重加权）。所提供的定义是该领域的标准定义。设计矩阵 $A$ 的设置是明确的，可以直接进行计算。问题提得很好，要求计算一个具体的、可计算的量（相干性 $\\mu(A)$）以及一个基于既有理论结果的后续比率。问题是自洽的，没有矛盾或歧义。因此，这是一个有效的问题。\n\n### 第3步：开始求解\n\n求解过程包括三个主要部分：\n1.  构建矩阵 $A$ 并计算其瘦QR分解以求得矩阵 $U$。\n2.  使用 $U$ 的行来计算杠杆分数 $\\ell_{i}$，然后计算相干性 $\\mu(A)$。\n3.  使用给定的样本量缩放定律来确定渐近增益因子 $m_{\\mathrm{unif}}/m_{\\mathrm{lev}}$。\n\n**第1部分：构建 $A$ 并求解 $U$**\n\n矩阵 $A$ 有 $n$ 行和 $k=2$ 列。第一列是全1向量，对应于基函数 $x \\mapsto 1$。第二列对应于基函数 $x \\mapsto x$ 在点 $x_1 = -1, x_2 = 1, \\dots, x_n = 1$ 处的取值。\n$$\nA = \\begin{pmatrix}\n1  x_1 \\\\\n1  x_2 \\\\\n\\vdots  \\vdots \\\\\n1  x_n\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1  -1 \\\\\n1  1 \\\\\n1  1 \\\\\n\\vdots  \\vdots \\\\\n1  1\n\\end{pmatrix}\n$$\n设 $A$ 的列为 $a_1$ 和 $a_2$。我们使用 Gram-Schmidt 过程来找到 $A$ 的列空间的一组标准正交基，从而得到矩阵 $U$ 的列 $u_1, u_2$。\n\nA的第一列是 $a_1 = [1, 1, \\dots, 1]^T$。其范数的平方是 $\\|a_1\\|_2^2 = \\sum_{i=1}^n 1^2 = n$。\n第一个标准正交向量 $u_1$ 是：\n$$\nu_1 = \\frac{a_1}{\\|a_1\\|_2} = \\frac{1}{\\sqrt{n}} \\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}\n$$\n$A$的第二列是 $a_2 = [-1, 1, \\dots, 1]^T$。我们首先找到 $a_2$ 与 $u_1$ 正交的分量，记为 $w_2$。\n$$\nw_2 = a_2 - \\langle a_2, u_1 \\rangle u_1\n$$\n内积是：\n$$\n\\langle a_2, u_1 \\rangle = a_2^T u_1 = \\frac{1}{\\sqrt{n}} \\left( (-1)(1) + (n-1)(1)(1) \\right) = \\frac{n-2}{\\sqrt{n}}\n$$\n所以，$w_2$ 是：\n$$\nw_2 = a_2 - \\frac{n-2}{\\sqrt{n}} u_1 = a_2 - \\frac{n-2}{n} a_1 = \\begin{pmatrix} -1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} - \\frac{n-2}{n} \\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -1 - \\frac{n-2}{n} \\\\ 1 - \\frac{n-2}{n} \\\\ \\vdots \\\\ 1 - \\frac{n-2}{n} \\end{pmatrix} = \\begin{pmatrix} \\frac{-n-n+2}{n} \\\\ \\frac{n-n+2}{n} \\\\ \\vdots \\\\ \\frac{2}{n} \\end{pmatrix} = \\frac{2}{n} \\begin{pmatrix} 1-n \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}\n$$\n接下来，我们将 $w_2$ 标准化以得到 $u_2$。$w_2$ 的范数的平方是：\n$$\n\\|w_2\\|_2^2 = \\left(\\frac{2}{n}\\right)^2 \\left( (1-n)^2 + \\sum_{i=2}^n 1^2 \\right) = \\frac{4}{n^2} \\left( (n-1)^2 + n-1 \\right) = \\frac{4}{n^2} (n-1)(n-1+1) = \\frac{4(n-1)n}{n^2} = \\frac{4(n-1)}{n}\n$$\n范数是 $\\|w_2\\|_2 = \\sqrt{\\frac{4(n-1)}{n}} = \\frac{2\\sqrt{n-1}}{\\sqrt{n}}$。\n第二个标准正交向量 $u_2$ 是：\n$$\nu_2 = \\frac{w_2}{\\|w_2\\|_2} = \\frac{\\frac{2}{n} \\begin{pmatrix} 1-n \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}}{\\frac{2\\sqrt{n-1}}{\\sqrt{n}}} = \\frac{\\sqrt{n}}{n\\sqrt{n-1}} \\begin{pmatrix} 1-n \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sqrt{n(n-1)}} \\begin{pmatrix} 1-n \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}\n$$\n具有标准正交列的矩阵 $U$ 是 $U = [u_1 | u_2]$。\n\n**第2部分：计算杠杆分数和相干性**\n\n杠杆分数 $\\ell_i$ 是 $U$ 的第 $i$ 行（记作 $U_{i,:}$）的欧几里得范数的平方。\n$U$ 的第一行，对应于 $x_1 = -1$，是：\n$$\nU_{1,:} = \\left( \\frac{1}{\\sqrt{n}}, \\frac{1-n}{\\sqrt{n(n-1)}} \\right)\n$$\n其杠杆分数 $\\ell_1$ 是：\n$$\n\\ell_1 = \\|U_{1,:}\\|_2^2 = \\left(\\frac{1}{\\sqrt{n}}\\right)^2 + \\left(\\frac{1-n}{\\sqrt{n(n-1)}}\\right)^2 = \\frac{1}{n} + \\frac{(1-n)^2}{n(n-1)} = \\frac{1}{n} + \\frac{(n-1)^2}{n(n-1)} = \\frac{1}{n} + \\frac{n-1}{n} = \\frac{n}{n} = 1\n$$\n对于任何其他行 $i \\in \\{2, \\dots, n\\}$，对应于 $x_i=1$，$U$ 的该行为：\n$$\nU_{i,:} = \\left( \\frac{1}{\\sqrt{n}}, \\frac{1}{\\sqrt{n(n-1)}} \\right)\n$$\n对于 $i1$ 的杠杆分数 $\\ell_i$ 是：\n$$\n\\ell_i = \\|U_{i,:}\\|_2^2 = \\left(\\frac{1}{\\sqrt{n}}\\right)^2 + \\left(\\frac{1}{\\sqrt{n(n-1)}}\\right)^2 = \\frac{1}{n} + \\frac{1}{n(n-1)} = \\frac{n-1+1}{n(n-1)} = \\frac{n}{n(n-1)} = \\frac{1}{n-1}\n$$\n作为健全性检查，杠杆分数的总和必须等于秩 $k=2$：$\\sum_{i=1}^n \\ell_i = \\ell_1 + \\sum_{i=2}^n \\ell_i = 1 + (n-1) \\left(\\frac{1}{n-1}\\right) = 1+1=2$。这是正确的。\n\n现在，我们计算相干性 $\\mu(A)$。\n对于 $n \\ge 3$，我们有 $n-1 \\ge 2$，所以 $\\frac{1}{n-1} \\le \\frac{1}{2}  1$。对于 $n=2$，$\\frac{1}{n-1}=1$。因此，对于任何 $n \\ge 2$，有 $\\max_i \\ell_i = \\ell_1 = 1$。\n$$\n\\mu(A) = \\frac{n}{k} \\max_{i} \\ell_{i} = \\frac{n}{2} \\cdot 1 = \\frac{n}{2}\n$$\n\n**第3部分：确定渐近增益因子**\n\n问题给出了均匀采样和杠杆分数采样的充分样本量的缩放关系。我们需要从第一性原理出发对此进行论证。论证的核心在于矩阵集中不等式。对于一个采样与重加权方案，实现子空间嵌入所需的样本复杂度 $m$ 主要由项 $m \\propto (\\max_i \\frac{\\ell_i}{p_i}) \\frac{\\log(k/\\delta)}{\\varepsilon^2}$ 决定。\n\n对于均匀采样，$p_i = 1/n$ 对所有 $i$ 成立。复杂度因子变为：\n$$\n\\max_i \\frac{\\ell_i}{p_i} = \\max_i \\frac{\\ell_i}{1/n} = n \\max_i \\ell_i\n$$\n使用相干性的定义 $\\mu(A) = \\frac{n}{k} \\max_i \\ell_i$，我们可以写出 $n \\max_i \\ell_i = k \\, \\mu(A)$。因此，$m_{\\mathrm{unif}} \\propto k \\, \\mu(A) \\frac{\\log(k/\\delta)}{\\varepsilon^2}$，这与问题陈述相符。\n\n对于杠杆分数采样，$p_i = \\ell_i / \\sum_j \\ell_j = \\ell_i/k$。复杂度因子变为：\n$$\n\\max_i \\frac{\\ell_i}{p_i} = \\max_i \\frac{\\ell_i}{\\ell_i/k} = \\max_i k = k\n$$\n因此，$m_{\\mathrm{lev}} \\propto k \\frac{\\log(k/\\delta)}{\\varepsilon^2}$，这也与问题陈述相符。\n\n渐近增益因子是比率 $m_{\\mathrm{unif}}/m_{\\mathrm{lev}}$。假设比例常数相同（这在此类分析中是标准做法），我们有：\n$$\n\\frac{m_{\\mathrm{unif}}}{m_{\\mathrm{lev}}} = \\frac{k \\ln(k/\\delta) \\mu(A) \\varepsilon^{-2}}{k \\ln(k/\\delta) \\varepsilon^{-2}} = \\mu(A)\n$$\n代入我们为指定的多项式设计计算出的 $\\mu(A)$ 值：\n$$\n\\frac{m_{\\mathrm{unif}}}{m_{\\mathrm{lev}}} = \\mu(A) = \\frac{n}{2}\n$$\n对于这个最坏情况的相干设计，该比率表示均匀采样为达到与最优杠杆分数采样相同的近似保证，所需样本量是后者的多少倍。",
            "answer": "$$\n\\boxed{\\frac{n}{2}}\n$$"
        },
        {
            "introduction": "随机算法提供的是概率性而非确定性的保证，因此理解其潜在的失效模式至关重要。本次实践探讨了一个病态案例，其中一个选择不当（或运气不佳）的勾画导致了“过拟合”：勾画后的问题得到了完美解决，但其解对于原始问题却效果很差。通过分析这个例子，您将建立起关于勾画风险的直觉，并体会到验证技术和恰当的重加权方案作为防范措施的重要性。",
            "id": "3570209",
            "problem": "考虑一个超定最小二乘问题，其中包含矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和向量 $b \\in \\mathbb{R}^{m}$，目标是计算 $x^\\star \\in \\mathbb{R}^{n}$ 以最小化 $\\|A x - b\\|_{2}$。一种标准的随机化“勾画-求解” (sketch-and-solve)方法是构建一个勾画矩阵 $S \\in \\mathbb{R}^{s \\times m}$（其中 $s \\ll m$），并求解勾画后的问题 $\\min_{x \\in \\mathbb{R}^{n}} \\|S A x - S b\\|_{2}$。根据定义，列空间 $\\mathrm{col}(A)$ 是集合 $\\{A x : x \\in \\mathbb{R}^{n}\\}$，并且当 $A^{\\top} A$ 可逆时，最小二乘解可以通过求解正规方程 $A^{\\top} A x = A^{\\top} b$ 得到。\n\n构建以下具体示例，从第一性原理出发进行推理。设 $m = 3$ 和 $n = 2$，并定义\n$$\nA = \\begin{bmatrix}\n1  0 \\\\\n0  1 \\\\\n1  1\n\\end{bmatrix},\n\\quad\nb = \\begin{bmatrix}\n1 \\\\\n1 \\\\\n0\n\\end{bmatrix}.\n$$\n注意到 $b \\notin \\mathrm{col}(A)$，因为不存在满足 $A x = b$ 的 $x \\in \\mathbb{R}^{2}$。设勾画矩阵 $S \\in \\mathbb{R}^{2 \\times 3}$ 对 $A$ 和 $b$ 的前两行进行采样：\n$$\nS = \\begin{bmatrix}\n1  0  0 \\\\\n0  1  0\n\\end{bmatrix}.\n$$\n于是有 $S A = I_{2}$ 和 $S b = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$，因此 $S b \\in \\mathrm{col}(S A)$ 恰好成立。勾画解 $x_{S}$ 最小化 $\\|S A x - S b\\|_{2}$，而完整最小二乘解 $x^{\\star}$ 最小化 $\\|A x - b\\|_{2}$。这个设置展示了一种病态情况，即尽管 $b \\notin \\mathrm{col}(A)$（因此完整残差不能为零），但 $S b$ 却位于 $\\mathrm{col}(S A)$ 中（因此勾画残差可以为零）。\n\n回答以下关于此构造以及其对“勾画-求解”最小二乘法的更广泛意义的多项选择题。选择所有正确的陈述。\n\nA. 在此构造中，勾画解实现了零勾画残差，但在 $x_{S}$ 处的完整残差不为零且等于 $\\|A x_{S} - b\\|_{2}^{2} = 4$，这说明了由于残差方向被 $S$ 湮灭而导致的对勾画的过拟合。\n\nB. 如果使用逆采样概率对勾画的行进行重加权，并使用杠杆分数采样，则在所有情况下都能消除对勾画过拟合的可能性。\n\nC. 使用一个独立的留出勾画 $T \\in \\mathbb{R}^{t \\times m}$，通过检查 $\\|T(A x_{S} - b)\\|_{2}$ 来进行验证，这提供了一种防止过拟合的概率性保障：如果 $T$ 是 $\\mathrm{col}([A \\;\\; b])$ 的一个子空间嵌入，那么 $\\|T(A x - b)\\|_{2}$ 将以高概率对所有 $x$ 一致地逼近 $\\|A x - b\\|_{2}$。\n\nD. 在此示例中，增加勾画大小 $s$ 没有任何帮助，因为残差方向完全位于 $A$ 的零空间中。\n\nE. 在勾画求解中使用岭正则化，即对于某个 $\\lambda  0$ 最小化 $\\|S A x - S b\\|_{2}^{2} + \\lambda \\|x\\|_{2}^{2}$，必然会产生比精确的完整最小二乘解 $x^{\\star}$ 更小的完整残差。\n\nF. 如果勾画 $S$ 是通过对 $s$ 次有放回的独立采样形成的，每次以概率 $p_{i}$ 采样第 $i$ 行并将其重新缩放 $1/\\sqrt{s p_{i}}$，那么对于任何 $y \\in \\mathbb{R}^{m}$，我们有 $\\mathbb{E}[\\|S y\\|_{2}^{2}] = \\|y\\|_{2}^{2}$。将此应用于 $y = A x - b$，这种重加权在期望上消除了勾画残差的偏差，尽管单次实现仍可能发生过拟合。",
            "solution": "### 步骤 1：提取已知条件\n问题陈述提供了以下信息：\n- 超定最小二乘问题是找到 $x^\\star \\in \\mathbb{R}^{n}$ 以最小化 $\\|A x - b\\|_{2}$，其中 $A \\in \\mathbb{R}^{m \\times n}$，$b \\in \\mathbb{R}^{m}$。\n- 一种随机化“勾画-求解”方法使用勾画矩阵 $S \\in \\mathbb{R}^{s \\times m}$（其中 $s \\ll m$）求解勾画问题 $\\min_{x \\in \\mathbb{R}^{n}} \\|S A x - S b\\|_{2}$。\n- $A$ 的列空间是 $\\mathrm{col}(A) = \\{A x : x \\in \\mathbb{R}^{n}\\}$。\n- 当 $A^{\\top} A$ 可逆时，最小二乘解可以通过求解正规方程 $A^{\\top} A x = A^{\\top} b$ 得到。\n- 构造了一个具体示例，其中 $m = 3$ 和 $n = 2$：\n$$\nA = \\begin{bmatrix}\n1  0 \\\\\n0  1 \\\\\n1  1\n\\end{bmatrix},\n\\quad\nb = \\begin{bmatrix}\n1 \\\\\n1 \\\\\n0\n\\end{bmatrix}.\n$$\n- 陈述中说明了 $b \\notin \\mathrm{col}(A)$。\n- 勾画矩阵给定为 $S \\in \\mathbb{R}^{2 \\times 3}$：\n$$\nS = \\begin{bmatrix}\n1  0  0 \\\\\n0  1  0\n\\end{bmatrix}.\n$$\n- 陈述中说明了 $S A = I_{2}$ 和 $S b = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$，因此 $S b \\in \\mathrm{col}(S A)$。\n- 勾画解记为 $x_{S}$，完整最小二乘解记为 $x^{\\star}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n问题陈述在科学上基于数值线性代数领域，特别是用于最小二乘问题的随机化算法。其定义和设置都是标准的。我将验证构造中提出的具体声明。\n\n1.  **检查 $b \\notin \\mathrm{col}(A)$ 是否成立：** 我们寻找 $x = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}$ 使得 $Ax = b$。这得到方程组：\n    $1 \\cdot x_1 + 0 \\cdot x_2 = 1 \\implies x_1 = 1$\n    $0 \\cdot x_1 + 1 \\cdot x_2 = 1 \\implies x_2 = 1$\n    $1 \\cdot x_1 + 1 \\cdot x_2 = 0 \\implies x_1 + x_2 = 0$\n    将前两个方程代入第三个方程得到 $1 + 1 = 0$，即 $2=0$，这是一个矛盾。因此，该方程组是不相容的，且 $b \\notin \\mathrm{col}(A)$。该声明是正确的。\n\n2.  **检查 $SA$、$Sb$ 以及 $Sb \\in \\mathrm{col}(SA)$：**\n    $$\n    SA = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\end{bmatrix} \\begin{bmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\end{bmatrix} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix} = I_{2}.\n    $$\n    $$\n    Sb = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}.\n    $$\n    条件 $Sb \\in \\mathrm{col}(SA)$ 要求解关于 $x$ 的方程 $SAx = Sb$。这就是 $I_2 x = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$，它有一个唯一解 $x = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$。因此，$Sb \\in \\mathrm{col}(SA)$ 是正确的。\n\n问题陈述是内部一致、数学上合理且适定的。它提出了一个有效且标准的例子，用于说明朴素勾画方法的一个潜在陷阱。\n\n### 步骤 3：结论和行动\n该问题是有效的。我现在将推导解答并评估每个选项。\n\n**针对具体示例的计算：**\n\n**1. 完整最小二乘解, $x^{\\star}$：**\n解 $x^{\\star}$ 最小化 $\\|Ax-b\\|_2$ 并且是正规方程 $A^{\\top}Ax = A^{\\top}b$ 的解。\n$$\nA^{\\top}A = \\begin{bmatrix} 1  0  1 \\\\ 0  1  1 \\end{bmatrix} \\begin{bmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\end{bmatrix} = \\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix}.\n$$\n$$\nA^{\\top}b = \\begin{bmatrix} 1  0  1 \\\\ 0  1  1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}.\n$$\n待求解的系统是 $\\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix} x^{\\star} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$。\n$A^{\\top}A$ 的逆是 $(A^{\\top}A)^{-1} = \\frac{1}{(2)(2) - (1)(1)} \\begin{bmatrix} 2  -1 \\\\ -1  2 \\end{bmatrix} = \\frac{1}{3} \\begin{bmatrix} 2  -1 \\\\ -1  2 \\end{bmatrix}$。\n$$\nx^{\\star} = \\frac{1}{3} \\begin{bmatrix} 2  -1 \\\\ -1  2 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} = \\frac{1}{3} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1/3 \\\\ 1/3 \\end{bmatrix}.\n$$\n\n**2. 勾画解, $x_{S}$：**\n解 $x_S$ 最小化 $\\|SAx - Sb\\|_2$。\n如前所示，这等价于最小化 $\\|I_2 x - \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\|_2$。\n该目标函数为零当且仅当 $x = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$。因此，勾画解是\n$$\nx_S = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}.\n$$\n\n**选项的详细分析：**\n\n**A.** 在此构造中，勾画解实现了零勾画残差，但在 $x_{S}$ 处的完整残差不为零且等于 $\\|A x_{S} - b\\|_{2}^{2} = 4$，这说明了由于残差方向被 $S$ 湮灭而导致的对勾画的过拟合。\n\n- **勾画残差：** 勾画残差为 $\\|SAx_S - Sb\\|_2 = \\|I_2 \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} - \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\|_2 = \\|\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\\|_2 = 0$。陈述的第一部分是正确的。\n- **$x_S$ 处的完整残差：** 我们计算残差向量 $r_S = Ax_S - b$。\n$$\nr_S = \\begin{bmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} - \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 2 \\end{bmatrix} - \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 2 \\end{bmatrix}.\n$$\n该残差的范数平方为 $\\|r_S\\|_2^2 = 0^2 + 0^2 + 2^2 = 4$。这个值不为零且等于 $4$。这部分也是正确的。\n- **解释：** 勾画解 $x_S$ 完美地拟合了勾画数据，但在完整数据上表现不佳。这是一个明显的过拟合案例。给出的原因是残差方向被 $S$ 湮灭。我们来检查一下：\n$$\nS r_S = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 0 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}.\n$$\n残差向量 $r_S$ 确实在勾画矩阵 $S$ 的零空间中。勾画对这个误差分量是“盲目”的。整个陈述是对所构造示例的正确且富有洞察力的分析。\n- **结论：** **正确**。\n\n**B.** 如果使用逆采样概率对勾画的行进行重加权，并使用杠杆分数采样，则在所有情况下都能消除对勾画过拟合的可能性。\n\n- 杠杆分数采样是一种复杂的随机化方法，旨在给予“有影响力的”行更多的重要性，使得示例中看到的这种病态错误变得不那么可能。采样概率被选择为与 $A$ 的行的统计杠杆分数成正比。\n- 然而，该声明声称此方法“在所有情况下都消除了过拟合的可能性”。随机化算法提供的是概率性保证，而不是确定性保证。对于任何给定的勾画大小 $s  m$，总存在一个非零概率（无论多小）选中一组“坏”的行，从而导致一个低质量的解。其保证的形式是“以高概率，解的质量是有界的”。“在所有情况下”这一短语使该陈述变得绝对化，因此是错误的。\n- **结论：** **不正确**。\n\n**C.** 使用一个独立的留出勾画 $T \\in \\mathbb{R}^{t \\times m}$，通过检查 $\\|T(A x_{S} - b)\\|_{2}$ 来进行验证，这提供了一种防止过拟合的概率性保障：如果 $T$ 是 $\\mathrm{col}([A \\;\\; b])$ 的一个子空间嵌入，那么 $\\|T(A x - b)\\|_{2}$ 将以高概率对所有 $x$ 一致地逼近 $\\|A x - b\\|_{2}$。\n\n- 该陈述描述了一种验证策略。在使用一个勾画 $S$ 找到候选解 $x_S$ 后，其质量（完整残差范数）是使用第二个独立的勾画 $T$ 来估计的。\n- 其理论依据是子空间嵌入的概念。如果矩阵 $T$ 近似地保持了子空间 $W$ 中所有向量的范数，那么它就是 $W$ 的一个子空间嵌入。形式上，以高概率，对于所有 $y \\in W$ 都有 $(1-\\epsilon)\\|y\\|_2 \\le \\|Ty\\|_2 \\le (1+\\epsilon)\\|y\\|_2$。\n- 所有可能的残差向量 $\\{A x - b : x \\in \\mathbb{R}^{n}\\}$ 的集合是仿射子空间 $b + \\mathrm{col}(A)$ 的一个子集。所有这些向量都位于 $A$ 的列和向量 $b$ 所张成的空间中，即 $\\mathrm{col}([A \\;\\; b])$。设 $W = \\mathrm{col}([A \\;\\; b])$。\n- 如果 $T$ 是 $W$ 的一个子空间嵌入，那么它将以高概率近似地保持 $W$ 中所有向量的范数。这包括所有的残差向量 $A x - b$。保证是“一致的”，因为相同的常数 $1 \\pm \\epsilon$ 同时适用于子空间中的所有向量。\n- 因此，检查 $\\|T(A x_S - b)\\|_2$ 将提供对真实残差范数 $\\|A x_S - b\\|_2$ 的可靠估计，如果 $S$ 是一个病态的勾画，这将暴露其过拟合。这是一种标准且合理的技术。\n- **结论：** **正确**。\n\n**D.** 在此示例中，增加勾画大小 $s$ 没有任何帮助，因为残差方向完全位于 $A$ 的零空间中。\n\n- 让我们分析这个前提：“残差方向完全位于 $A$ 的零空间中。”勾画解的残差向量是 $r_S = \\begin{bmatrix} 0  0  2 \\end{bmatrix}^{\\top}$。$A$ 的零空间 $N(A)$ 包含使得 $Az=0$ 的向量 $z$。由于 $A$ 的列是线性无关的，所以 $N(A) = \\{0\\}$。显然，$r_S \\neq 0$，所以 $r_S \\notin N(A)$。前提是错误的。也许意指的是 $A^\\top$ 的零空间。*最优*解的残差 $r^\\star = A x^\\star - b$ 必须与 $\\mathrm{col}(A)$ 正交，即 $A^\\top r^\\star = 0$。然而，这里有问题的残差是 $r_S$，且 $A^\\top r_S = \\begin{bmatrix} 1  0  1 \\\\ 0  1  1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 0 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix} \\neq 0$。所以无论在哪种解释下，这个前提都是错误的。\n- 让我们分析结论：“在此示例中，增加勾画大小 $s$ 没有任何帮助。”在本例中，$m=3$，使用了大小为 $s=2$ 的勾画。如果我们将勾画大小增加到 $s=3$，任何满秩的 $3 \\times 3$ 勾画 $S$ 都会使勾画问题等价于原始问题（最多相差行缩放），从而得到真实解 $x^\\star$。例如，如果 $S=I_3$，勾画问题就与完整问题完全相同。因此，增加勾画大小当然有帮助。结论也是错误的。\n- **结论：** **不正确**。\n\n**E.** 在勾画求解中使用岭正则化，即对于某个 $\\lambda  0$ 最小化 $\\|S A x - S b\\|_{2}^{2} + \\lambda \\|x\\|_{2}^{2}$，必然会产生比精确的完整最小二乘解 $x^{\\star}$ 更小的完整残差。\n\n- 根据定义，精确的完整最小二乘解 $x^\\star$ 是使 $\\|Ax - b\\|_2$ 达到最小可能值的向量。任何其他向量 $x$ 都不能产生一个严格更小的残差范数 $\\|Ax - b\\|_2$。\n- 令 $x_\\lambda$ 为正则化勾画问题的解。该陈述声称，对于某个 $\\lambda > 0$，有 $\\|A x_\\lambda - b\\|_2  \\|A x^\\star - b\\|_2$。根据 $x^\\star$ 的定义，这在数学上是不可能的。最多，我们可能有 $\\|A x_\\lambda - b\\|_2 = \\|A x^\\star - b\\|_2$，这当且仅当 $x_\\lambda$ 也是一个最小二乘解时才会发生。在我们的具体示例中，$A$ 具有满列秩，这意味着我们需要 $x_\\lambda = x^\\star$。\n- 在这个具体案例中，对于 $\\lambda=2$，正则化勾画解为 $x_2 = [1/3, 1/3]^\\top = x^\\star$，达到了相等。对于任何其他 $\\lambda > 0$，$x_\\lambda \\neq x^\\star$，因此 $\\|A x_\\lambda - b\\|_2 > \\|A x^\\star - b\\|_2$。\n- “更小”一词意味着严格不等式，这是不可能的。\n- **结论：** **不正确**。\n\n**F.** 如果勾画 $S$ 是通过对 $s$ 次有放回的独立采样形成的，每次以概率 $p_{i}$ 采样第 $i$ 行并将其重新缩放 $1/\\sqrt{s p_{i}}$，那么对于任何 $y \\in \\mathbb{R}^{m}$，我们有 $\\mathbb{E}[\\|S y\\|_{2}^{2}] = \\|y\\|_{2}^{2}$。将此应用于 $y = A x - b$，这种重加权在期望上消除了勾画残差的偏差，尽管单次实现仍可能发生过拟合。\n\n- 这描述了一种常见的随机化勾画方法。我们来验证一下期望值。令 $\\|Sy\\|_2^2 = \\sum_{j=1}^s (S_j y)^2$，其中 $S_j$ 是 $S$ 的行。每个 $S_j$ 是通过以概率 $p_k$ 选择单位矩阵的第 $k$ 行并将其缩放 $1/\\sqrt{sp_k}$ 来形成的。所以 $S_j = \\frac{1}{\\sqrt{sp_k}} e_k^\\top$ 的概率为 $p_k$。\n- $(S_j y)^2$ 的期望值为：\n$$\n\\mathbb{E}[(S_j y)^2] = \\sum_{k=1}^m p_k \\left( \\frac{1}{\\sqrt{sp_k}} e_k^\\top y \\right)^2 = \\sum_{k=1}^m p_k \\frac{y_k^2}{sp_k} = \\frac{1}{s} \\sum_{k=1}^m y_k^2 = \\frac{1}{s}\\|y\\|_2^2.\n$$\n- 由于这 $s$ 个样本是独立同分布的，根据期望的线性性质：\n$$\n\\mathbb{E}[\\|Sy\\|_2^2] = \\sum_{j=1}^s \\mathbb{E}[(S_j y)^2] = \\sum_{j=1}^s \\frac{1}{s}\\|y\\|_2^2 = s \\left( \\frac{1}{s}\\|y\\|_2^2 \\right) = \\|y\\|_2^2.\n$$\n- 陈述的第一部分是正确的。这个性质被称为对范数平方的无偏估计，因为 $\\mathbb{E}[y^\\top S^\\top S y] = y^\\top \\mathbb{E}[S^\\top S] y = y^\\top I y = \\|y\\|_2^2$。\n- 将此应用于 $y = Ax - b$，我们得到 $\\mathbb{E}[\\|S(Ax-b)\\|_2^2] = \\|Ax-b\\|_2^2$。这意味着勾画的目标函数是真实目标函数的无偏估计量。这“在期望上消除了偏差”。\n- 最后的条款，“尽管单次实现仍可能发生过拟合”，是一个关键的警告。期望是随机抽样所有可能结果的平均值。任何单一的结果（实现）都可能是不幸的，导致一个糟糕的勾画，就像问题设置中的确定性情况一样。\n- 整个陈述是对这种勾画方法性质的正确描述。\n- **结论：** **正确**。",
            "answer": "$$\\boxed{ACF}$$"
        }
    ]
}