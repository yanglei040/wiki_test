{
    "hands_on_practices": [
        {
            "introduction": "理论模型是分析和预测并行算法性能的基石。其中，Hockney $α-β$ 模型因其简洁性与洞察力而被广泛使用。本练习将引导你应用 $α-β$ 模型来分析一个在分布式线性代数计算中至关重要的步骤：全局格拉姆矩阵（Gram matrix）的构建。通过比较两种不同的集合通信策略 ，你将亲身体会到延迟（latency）和带宽（bandwidth）两个因素在不同问题规模下如何影响最优算法的选择。",
            "id": "3537871",
            "problem": "考虑一个高瘦矩阵 $A \\in \\mathbb{R}^{m \\times n}$ (其中 $m \\gg n$) 在一个分布式内存系统上的基于Cholesky的QR分解 (CholeskyQR)。该系统有 $P$ 个处理器，并采用消息传递接口 (MPI) 编程模型进行组织。假设 $A$ 是按块行分布的，因此处理器 $p$ 拥有 $A_p \\in \\mathbb{R}^{m_p \\times n}$，并形成其局部Gram矩阵 $G_p = A_p^{T} A_p \\in \\mathbb{R}^{n \\times n}$。全局Gram矩阵为 $G = \\sum_{p=1}^{P} G_p = R^{T} R$，其中 $R$ 是 $G$ 的上三角Cholesky因子。每个 $G_p$ 都是对称的；假设它以大小为每个处理器 $s = \\frac{n(n+1)}{2}$ 个双精度浮点数的上三角压缩格式存储。\n\n你需要使用标准的双参数通信时间模型 (Hockney模型) 来比较两种用于从 $\\{G_p\\}$ 形成 $G$ 的集体通信策略：发送一个包含 $w$ 个双精度浮点数的消息所需的时间为 $T_{\\text{msg}}(w) = \\alpha + \\beta w$，其中 $\\alpha$ 是延迟（单位：秒/消息），$\\beta$ 是逆带宽（单位：秒/双精度浮点数）。忽略任何计算成本以及通信与计算之间的任何重叠。假设集体操作采用以下算法选择：\n\n- allreduce (求和) 操作通过 Rabenseifner 方法实现，即先通过递归减半实现 reduce-scatter，再通过递归加倍实现 allgather，每个阶段都产生 $\\log_{2} P$ 个通信步骤。\n- reduce-scatter (求和归约并对归约结果进行等大小散播) 操作通过环形算法实现，即它使用 $P-1$ 个近邻步骤，每一步的消息大小均等划分。\n\n假设此阶段的最终目标是使全局归约后的Gram矩阵以分布式形式（而非复制形式）可用，因此 allreduce 执行的复制操作所产生的通信量严格多于此阶段所必需的通信量。\n\n仅从Hockney模型和所述的算法结构出发，推导出两种策略的总通信时间关于 $n$、$P$、$\\alpha$ 和 $\\beta$ 的符号表达式，然后找出两种策略通信时间相等时的交叉点列维度 $n^{\\ast}$ 的精确闭式表达式。你的最终答案必须是用 $P$、$\\alpha$ 和 $\\beta$ 表示的 $n^{\\ast}$。最终表达式中不应包含单位。如果表达式中包含 $P$ 的对数，请明确使用以2为底的对数。不需要进行数值计算。",
            "solution": "我们从Hockney模型开始，该模型指出，发送一个包含 $w$ 个双精度浮点数的消息所需时间为 $T_{\\text{msg}}(w) = \\alpha + \\beta w$，其中 $\\alpha$ 是延迟，$\\beta$ 是逆带宽。我们将通过计算给定算法下每个集体操作的通信步数和每步的数据量来计算其通信时间，然后比较得出的表达式。\n\n每个处理器持有 $s = \\frac{n(n+1)}{2}$ 个双精度浮点数，代表 $G_p$ 的上三角压缩存储。目标是在 $P$ 个处理器上以分布式形式形成 $G = \\sum_{p=1}^{P} G_p$。\n\n首先，考虑通过环形算法实现的 reduce-scatter。在用于等大小分区的环形 reduce-scatter 中，有 $P-1$ 个通信步骤。在每一步中，每个处理器发送和接收一个包含 $\\frac{s}{P}$ 个双精度浮点数的连续数据块。根据Hockney模型，每一步的成本为 $\\alpha + \\beta \\cdot \\frac{s}{P}$，总共有 $P-1$ 步。因此，总时间为\n$$\nT_{\\text{RS,ring}}(n,P,\\alpha,\\beta) \\;=\\; (P-1)\\,\\alpha \\;+\\; (P-1)\\,\\beta \\cdot \\frac{s}{P}\n\\;=\\; (P-1)\\,\\alpha \\;+\\; \\frac{P-1}{P}\\,\\beta \\cdot \\frac{n(n+1)}{2}.\n$$\n\n其次，考虑通过 Rabenseifner 方法实现的 allreduce，它包括一个通过递归减半实现的 reduce-scatter，后跟一个通过递归加倍实现的 allgather。在递归减半（和加倍）下，每个阶段的步数为 $\\log_{2} P$。对于带宽成本，在整个 reduce-scatter 阶段，每个处理器通信的双精度浮点数总数等于 $\\frac{P-1}{P}\\,s$，allgather 阶段也是如此。因此，总的 allreduce 时间是这两个阶段的总和：\n$$\nT_{\\text{AR,Rab}}(n,P,\\alpha,\\beta) \\;=\\; \\underbrace{\\log_{2} P \\cdot \\alpha}_{\\text{reduce-scatter latency}} \\;+\\; \\underbrace{\\frac{P-1}{P}\\,\\beta\\,s}_{\\text{reduce-scatter bandwidth}}\n\\;+\\; \\underbrace{\\log_{2} P \\cdot \\alpha}_{\\text{allgather latency}} \\;+\\; \\underbrace{\\frac{P-1}{P}\\,\\beta\\,s}_{\\text{allgather bandwidth}}.\n$$\n合并各项并代入 $s = \\frac{n(n+1)}{2}$，我们得到\n$$\nT_{\\text{AR,Rab}}(n,P,\\alpha,\\beta) \\;=\\; 2\\,\\alpha\\,\\log_{2} P \\;+\\; 2\\,\\frac{P-1}{P}\\,\\beta \\cdot \\frac{n(n+1)}{2}\n\\;=\\; 2\\,\\alpha\\,\\log_{2} P \\;+\\; \\frac{P-1}{P}\\,\\beta \\cdot n(n+1).\n$$\n\n我们现在求解两种时间相等时的交叉点 $n^{\\ast}$。令 $T_{\\text{RS,ring}} = T_{\\text{AR,Rab}}$：\n$$\n(P-1)\\,\\alpha \\;+\\; \\frac{P-1}{P}\\,\\beta \\cdot \\frac{n(n+1)}{2}\n\\;=\\; 2\\,\\alpha\\,\\log_{2} P \\;+\\; \\frac{P-1}{P}\\,\\beta \\cdot n(n+1).\n$$\n重新整理以分离出包含 $n(n+1)$ 的项：\n$$\n(P-1)\\,\\alpha \\;-\\; 2\\,\\alpha\\,\\log_{2} P \\;=\\; \\frac{P-1}{P}\\,\\beta \\left( n(n+1) \\;-\\; \\frac{n(n+1)}{2} \\right)\n\\;=\\; \\frac{P-1}{P}\\,\\beta \\cdot \\frac{n(n+1)}{2}.\n$$\n求解 $n(n+1)$：\n$$\n\\frac{n(n+1)}{2} \\;=\\; \\frac{P}{P-1}\\,\\frac{\\alpha}{\\beta}\\,\\bigl( (P-1) \\;-\\; 2\\,\\log_{2} P \\bigr).\n$$\n定义\n$$\nC \\;=\\; \\frac{P}{P-1}\\,\\frac{\\alpha}{\\beta}\\,\\bigl( (P-1) \\;-\\; 2\\,\\log_{2} P \\bigr).\n$$\n那么等式条件变为 $\\frac{n(n+1)}{2} = C$。解二次方程 $n^{2} + n - 2C = 0$ 得\n$$\nn^{\\ast} \\;=\\; \\frac{-1 + \\sqrt{\\,1 + 8C\\,}}{2}\n\\;=\\; \\frac{-1 + \\sqrt{\\,1 + 8\\,\\frac{P}{P-1}\\,\\frac{\\alpha}{\\beta}\\,\\bigl( (P-1) - 2\\,\\log_{2} P \\bigr)\\,}}{2}.\n$$\n\n这个 $n^{\\ast}$ 是 Hockney 模型中唯一的非负交叉点。当 $n  n^{\\ast}$ 时，延迟项较小的 allreduce 更快；当 $n > n^{\\ast}$ 时，带宽系数较小的 reduce-scatter 更快。当 $\\bigl( (P-1) - 2\\,\\log_{2} P \\bigr) \\le 0$ 时，量 $C \\le 0$，交叉点出现在一个非正的 $s$ 值处，这表明在这种延迟主导的情况下，对于此模型中所有非负的 $n$，allreduce 始终是更优的选择；反之，当 $C > 0$ 时，对于足够大的 $n$，reduce-scatter 变得更优。",
            "answer": "$$\\boxed{\\frac{-1 + \\sqrt{\\,1 + 8\\,\\frac{P}{P-1}\\,\\frac{\\alpha}{\\beta}\\,\\bigl((P-1) - 2\\,\\log_{2} P\\bigr)\\,}}{2}}$$"
        },
        {
            "introduction": "在掌握了分析基本通信操作的技能后，下一步是将其应用于评估和比较完整的算法。对于同一个计算问题，例如 QR 分解，存在多种算法，它们在计算量、通信模式和数值稳定性方面各有优劣。本练习  提供了一个绝佳的案例研究，要求你对四种经典的 QR 分解方法进行全面的性能剖析。通过这项练习，你将学会如何权衡不同算法在并行环境下的浮点运算次数（flops）、同步次数和通信数据量，从而做出明智的算法选择。",
            "id": "3537877",
            "problem": "考虑一个高瘦矩阵 $A \\in \\mathbb{R}^{m \\times n}$（其中 $m \\gg n$），该矩阵以行分块的方式分布在使用消息传递接口 (MPI) 的分布式内存系统中的 $p$ 个进程上。目标是使用以下算法之一计算瘦 $QR$ 分解, $A = QR$：经典 Gram-Schmidt (CGS)、修正 Gram-Schmidt (MGS)、带重正交化的 CGS (CGS2) 和 CholeskyQR。假设采用以下在数值线性代数通信分析中广泛用作基线的标准实现选择：\n\n- 对于 CGS 的第 $k$ 列，与先前计算出的 $Q$ 的 $k-1$ 列的内积在本地计算，并通过对一个长度为 $k-1$ 的向量进行单次 MPI Allreduce 来聚合，然后进行本地更新，接着使用另一次单独的 MPI Allreduce 来计算欧几里得范数。\n- 对于 MGS 的第 $k$ 列，算法依次对 $q_{1}, q_{2}, \\dots, q_{k-1}$进行正交化，每一步执行一次全局点积（每次都是对一个标量进行 MPI Allreduce），最后使用一次单独的 MPI Allreduce 计算欧几里得范数；不假设使用流水线或通信聚合的变体。\n- 对于 CGS2 的第 $k$ 列，执行两次 CGS 过程（每次都对一个长度为 $k-1$ 的向量进行单次 MPI Allreduce），然后使用一次 MPI Allreduce 计算欧几里得范数。\n- 对于 CholeskyQR，首先形成格拉姆矩阵 $G = A^{T} A$ 并进行一次全局归约（例如，通过对对称 $n \\times n$ 矩阵或其包含 $\\frac{n(n+1)}{2}$ 个标量的压缩上三角进行单次 MPI Allreduce），然后在本地计算 $R = \\text{chol}(G)$，并通过本地三角求解形成 $Q = A R^{-1}$。不使用重正交化步骤。\n\n仅使用关于分布式点积和范数的基本原理，以及矩阵-向量和矩阵-矩阵运算的标准浮点运算 (flop) 计数，选择能够正确描述每种方法的以下特征的选项：关于 $m$ 和 $n$ 的主阶 flop 计数、全局同步的次数以及典型的 MPI 集合通信规模。你可以假设 $m \\gg n$，因此低阶项可以被陈述但不占主导地位。\n\nA. CGS 和 MGS 各自的成本约为 $2 m n^{2}$ 次浮点运算；CGS2 的成本约为 $4 m n^{2}$ 次浮点运算；CholeskyQR 的成本约为 $2 m n^{2} + \\frac{1}{3} n^{3}$ 次浮点运算。对于每一列 $k$，CGS 执行 $2$ 次同步（一次是对长度为 $k-1$ 的向量进行 MPI Allreduce 以计算内积，另一次是对一个标量进行 MPI Allreduce 以计算范数）；MGS 执行 $k$ 次同步（$k-1$ 次点积中的每一次都需要一次标量 MPI Allreduce，再加上一次计算范数的标量 MPI Allreduce）；CGS2 执行 $3$ 次同步（两次 CGS 过程需要两次对长度为 $k-1$ 的向量进行 MPI Allreduce，再加上一次计算范数的标量 MPI Allreduce）。CholeskyQR 在整个分解过程中总共执行 $1$ 次全局同步（对对称的 $n \\times n$ 格拉姆矩阵进行一次 MPI Allreduce，例如，对 $\\frac{n(n+1)}{2}$ 个标量），之后所有的计算都是本地的。\n\nB. CGS 和 MGS 各自的成本约为 $2 m n^{2}$ 次浮点运算；CGS2 的成本约为 $2 m n^{2}$ 次浮点运算；CholeskyQR 的成本约为 $m n^{2}$ 次浮点运算。对于每一列 $k$，CGS 和 MGS 都可以通过批处理点积以 $2$ 次同步（一次向量 MPI Allreduce，长度为 $k-1$，和一次标量 MPI Allreduce 用于范数）来实现；CGS2 每列也只需要 $2$ 次同步；CholeskyQR 需要 $n$ 次同步（每列一次标量 MPI Allreduce）来累积格拉姆矩阵。\n\nC. CGS 的成本约为 $2 m n^{2}$ 次浮点运算；MGS 的成本约为 $4 m n^{2}$ 次浮点运算；CGS2 的成本约为 $2 m n^{2}$ 次浮点运算；CholeskyQR 的成本约为 $2 m n^{2}$ 次浮点运算。对于每一列 $k$，CGS 需要 $k$ 次同步（每个内积需要一次标量 MPI Allreduce，再加上一次用于范数），MGS 需要 $2$ 次同步（一次向量 MPI Allreduce 和一次标量 MPI Allreduce），CGS2 需要 $2$ 次同步，而 CholeskyQR 需要 $O(n)$ 次同步，因为 Cholesky 需要迭代求精。\n\nD. CGS 和 MGS 各自的成本约为 $2 m n^{2}$ 次浮点运算；CGS2 的成本约为 $4 m n^{2}$ 次浮点运算；CholeskyQR 的成本约为 $2 m n^{2} + \\frac{1}{3} n^{3}$ 次浮点运算。对于每一列 $k$，CGS 执行 $1$ 次同步（一次对长度为 $k-1$ 的向量进行 MPI Allreduce，并将范数计算合并到同一次集合通信中）；MGS 执行 $2$ 次同步（一次向量 MPI Allreduce 和一次标量 MPI Allreduce）；CGS2 执行 $2$ 次同步（两次向量 MPI Allreduce）；CholeskyQR 在整个分解过程中需要 $2$ 次同步（一次用于 $A^{T} A$ 的 MPI Allreduce，一次用于分发 $R$）。",
            "solution": "该问题要求对计算高瘦矩阵 $A \\in \\mathbb{R}^{m \\times n}$（其中 $m \\gg n$）的瘦 $QR$ 分解的四种不同算法进行批判性分析。矩阵 $A$ 以行分块的方式分布在 $p$ 个进程上。分析必须基于为每种算法提供的具体实现细节：经典 Gram-Schmidt (CGS)、修正 Gram-Schmidt (MGS)、带重正交化的 CGS (CGS2) 和 CholeskyQR。我们将评估每种方法的浮点运算 (flop) 主阶计数、全局同步次数以及 MPI 集合通信中的数据大小。\n\n设 $A = [a_1, a_2, \\dots, a_n]$ 为输入矩阵，$Q=[q_1, q_2, \\dots, q_n]$ 和 $R \\in \\mathbb{R}^{n \\times n}$ 为输出矩阵。$p$ 个进程中的每一个都持有 $A$ 和 $Q$ 的 $m/p$ 行。一次全局点积或范数计算需要每个进程计算一个局部和，然后参与一个集合 `MPI_Allreduce` 操作以获得全局结果。一次同步计为一次 `MPI_Allreduce` 调用。\n\n**经典 Gram-Schmidt (CGS)**\n\n该算法一次处理一列 $a_k$，其中 $k=1, \\dots, n$。\n1.  **正交化：** 向量 $a_k$ 与先前计算出的正交单位向量 $q_1, \\dots, q_{k-1}$ 进行正交化。系数为 $R_{jk} = q_j^T a_k$，其中 $j=1, \\dots, k-1$。问题陈述这 $k-1$ 个点积是通过“对一个长度为 $k-1$ 的向量进行单次 MPI Allreduce”来计算的。这构成 1 次同步。这些点积的浮点运算计数为 $(k-1) \\times (2m-1) \\approx 2m(k-1)$。随后的更新 $v_k = a_k - \\sum_{j=1}^{k-1} R_{jk} q_j$ 的成本约为 $2m(k-1)$ 次浮点运算，并且是一个本地操作。每列 $k$ 正交化的总浮点运算次数约为 $4m(k-1)$。\n2.  **归一化：** 对得到的向量 $v_k$ 进行归一化。这需要计算其欧几里得范数 $R_{kk} = \\|v_k\\|_2$。问题陈述这是通过“一次单独的 MPI Allreduce”完成的。这是第 $k$ 列的第 2 次同步，操作对象是一个标量值。归一化的浮点运算量很小（点积需要 $m$ 次乘法和 $m-1$ 次加法，再加上 $m$ 次除法）。\n3.  **总浮点运算次数：** 对所有列的主导成本求和：$\\sum_{k=1}^n 4m(k-1) = 4m \\frac{(n-1)n}{2} \\approx 2mn^2$。\n4.  **总同步次数：** 对于每一列 $k$，有 2 次同步。\n5.  **集合通信规模：** 对于每一列 $k$，一次对长度为 $k-1$ 的向量进行 `MPI_Allreduce`，以及一次对一个标量进行 `MPI_Allreduce`。\n\n**修正 Gram-Schmidt (MGS)**\n\n问题指定了一种特定的实现方式：“对于第 $k$ 列，算法依次对 $q_{1}, q_{2}, \\dots, q_{k-1}$进行正交化，每一步执行一次全局点积（每次都是对一个标量进行 MPI Allreduce）”。设正在处理的向量为 $v$，初始化为 $a_k$。\n1.  **正交化：** 对于 $j=1, \\dots, k-1$，算法计算 $R_{jk} = q_j^T v$ 并更新 $v \\leftarrow v - R_{jk} q_j$。每个点积都需要对一个标量进行 `MPI_Allreduce`，因此这个循环涉及 $k-1$ 次同步。每一步 $j$ 的浮点运算成本约为 $2m$（用于点积）和 $2m$（用于更新），总计约为 $4m$。在整个循环中，这是约 $4m(k-1)$ 次浮点运算。\n2.  **归一化：** 最后对范数 $R_{kk} = \\|v\\|_2$ 执行一次对标量的 `MPI_Allreduce`。这是第 $k$ 列的第 $k$ 次同步。\n3.  **总浮点运算次数：** 浮点运算计数与 CGS 相同：$\\sum_{k=1}^{n} 4m(k-1) \\approx 2mn^2$。\n4.  **总同步次数：** 对于每一列 $k$，有 $k-1+1 = k$ 次同步。\n5.  **集合通信规模：** 第 $k$ 列的所有 $k$ 次同步都操作于标量。\n\n**带重正交化的 CGS (CGS2)**\n\n该算法对每列执行两次 CGS 过程以提高数值稳定性。\n1.  **正交化：** 问题陈述“执行两次 CGS 过程（每次都对一个长度为 $k-1$ 的向量进行单次 MPI Allreduce）”。这意味着对于第 $k$ 列，我们执行一个 CGS 步骤，然后对结果再执行一个 CGS 步骤。\n    - 过程 1：$v' = a_k - Q_{1:k-1}(Q_{1:k-1}^T a_k)$。这涉及 1 次同步（向量 `MPI_Allreduce`）和约 $4m(k-1)$ 次浮点运算。\n    - 过程 2：$v'' = v' - Q_{1:k-1}(Q_{1:k-1}^T v')$。这涉及另一次同步（向量 `MPI_Allreduce`）和另外约 $4m(k-1)$ 次浮点运算。\n2.  **归一化：** 最终的归一化 $R_{kk} = \\|v''\\|_2$ 需要第三次同步（标量 `MPI_Allreduce`）。\n3.  **总浮点运算次数：** 浮点运算次数是 CGS 的两倍：$\\approx 2 \\times (2mn^2) = 4mn^2$。\n4.  **总同步次数：** 对于每一列 $k$，有 $2+1 = 3$ 次同步。\n5.  **集合通信规模：** 对于每一列 $k$，两次对长度为 $k-1$ 的向量进行 `MPI_Allreduce` 调用，以及一次对一个标量进行 `MPI_Allreduce`。\n\n**CholeskyQR**\n\n该算法避免了直接对向量进行正交化。\n1.  **格拉姆矩阵形成：** 首先，计算格拉姆矩阵 $G = A^T A$。这个 $n \\times n$ 矩阵是通过计算 $A$ 的列之间所有 $n(n+1)/2$ 个唯一的点积形成的。计算 $G$ 的上三角的成本是 $\\frac{n(n+1)}{2} \\times 2m \\approx mn^2$ 次浮点运算。问题陈述本地贡献 $A_p^T A_p$ 是通过“对对称 $n \\times n$ 矩阵或其包含 $\\frac{n(n+1)}{2}$ 个标量的压缩上三角进行单次 MPI Allreduce”来求和的。这是整个分解过程中的 1 次全局同步。\n2.  **Cholesky 分解：** 计算 Cholesky 分解 $G=R^T R$。矩阵 $G$ 很小（$n \\times n$），在归约后所有进程上都可用。这一步在本地执行（或在所有地方复制执行），成本约为 $\\frac{1}{3}n^3$ 次浮点运算。它不需要通信。\n3.  **形成 Q：** 矩阵 $Q$ 计算为 $Q = AR^{-1}$。这是一个以 $A$ 的 $n$ 列作为多右端项的三角求解。由于 $A$ 是按行分布的 ($A_p$)，每个进程通过本地操作 $Q_p=A_p R^{-1}$ 来计算其对应的 $Q$ 的行 ($Q_p$)。在所有进程上，这总共花费约 $mn^2$ 次浮点运算，并且不需要通信，因为 $R$ 是复制的。\n4.  **总浮点运算次数：** 总浮点运算次数是各步骤之和：$mn^2$（用于 $A^T A$）$+ \\frac{1}{3}n^3$（用于 Cholesky 分解）$+ mn^2$（用于 $AR^{-1}$），可简化为 $2mn^2 + \\frac{1}{3}n^3$。\n5.  **总同步次数：** 整个算法只有 1 次全局同步。\n6.  **集合通信规模：** 单次 `MPI_Allreduce` 操作于约 $n^2/2$ 个标量。\n\n**选项评估**\n\n*   **选项 A:**\n    - **浮点运算次数：** 陈述 CGS/MGS 成本约为 $2mn^2$，CGS2 成本约为 $4mn^2$，CholeskyQR 成本约为 $2mn^2 + \\frac{1}{3}n^3$。这与我们的推导相符。\n    - **同步与规模：** 陈述 CGS 每列有 $2$ 次同步（$k-1$ 长度的向量，标量），MGS 每列有 $k$ 次同步（均为标量），CGS2 每列有 $3$ 次同步（两个 $k-1$ 长度的向量，一个标量），而 CholeskyQR 总共有 $1$ 次同步（$\\frac{n(n+1)}{2}$ 个标量的矩阵）。这完全符合我们基于问题明确假设的分析。\n    - **结论：** **正确**。\n\n*   **选项 B:**\n    - **浮点运算次数：** 陈述 CGS2 成本约为 $2mn^2$，CholeskyQR 成本约为 $mn^2$。两者都不正确。\n    - **同步：** 陈述 MGS 可以通过批处理以 $2$ 次同步完成，这与问题对 MGS 的前提相矛盾。它还陈述 CholeskyQR 需要 $n$ 次同步，这也与 CholeskyQR 的前提相矛盾。\n    - **结论：** **不正确**。\n\n*   **选项 C:**\n    - **浮点运算次数：** 陈述 MGS 成本约为 $4mn^2$，CGS2 成本约为 $2mn^2$。两者都不正确。\n    - **同步：** 交换了 CGS 和 MGS 的同步次数，即便如此，描述也与问题陈述不一致。CGS2 的次数是错误的（$2$ 次而非 $3$ 次）。CholeskyQR 的次数是错误的（$O(n)$ 而非 $1$）。\n    - **结论：** **不正确**。\n\n*   **选项 D:**\n    - **浮点运算次数：** 浮点运算次数陈述正确。\n    - **同步：** 陈述 CGS 每列 $1$ 次同步，MGS $2$ 次，CGS2 $2$ 次，CholeskyQR 总共 $2$ 次。所有这些计数都是不正确的，并且与基于问题明确陈述的推导相冲突。例如，它假设了一个问题中未描述的优化版 CGS 实现，错误地描述了 MGS，并且不完整地计算了 CGS2 和 CholeskyQR 的同步次数。\n    - **结论：** **不正确**。\n\n基于从基本原理出发的透彻分析，并严格遵守问题陈述中提供的实现细节，只有选项 A 对所有四种算法提供了完全准确的描述。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "通信避免算法的设计往往需要在降低通信开销和保证数值稳定性之间做出权衡，这是一个深刻且具挑战性的主题。LU 分解中的主元选择策略便是这一权衡的典型例证。本练习  将带你探索更前沿的话题，比较为通信避免设计的竞赛主元法（tournament pivoting）和分布式环境下的车马象主元法（rook pivoting）。你将需要分析这些策略的通信消息数，并评估它们对数值稳定性的影响（以增长因子为度量），从而深入理解在设计高性能数值算法时所面临的复杂约束。",
            "id": "3537861",
            "problem": "考虑一个稠密矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 在大小为 $p_r \\times p_c$ 的二维 (2D) 进程网格上，使用板块宽度为 $b$ 的块循环分布进行带主元选择的 LU 分解的分布式内存实现。我们比较两种通信避免主元选择策略：带锦标赛主元选择的通信避免 LU (CALU-TP) 和一种在分布式环境中试图模拟经典车马象主元选择 (RP) 的实现。我们使用标准的 $\\alpha$–$\\beta$ 通信模型，但只关注消息计数（即与归约和广播相关的延迟项），并假设在 $p$ 个进程上的集体操作使用高度为 $\\Theta(\\log p)$ 的归约树。\n\n定义和模型假设：\n- LU 分解的增长因子 $\\rho(A)$ 定义为 $\\rho(A) = \\dfrac{\\max_{i,j} |u_{ij}|}{\\max_{i,j} |a_{ij}|}$，其中 $U$ 是在精确算术下计算出的上三角因子，$A = P L U$，$P$ 是置换矩阵，$L$ 是单位下三角矩阵。\n- 众所周知，经典的部分主元选择存在一个对抗族 $W_n$（例如，Wilkinson 矩阵族），其增长因子为 $\\rho(W_n) = 2^{n-1}$。\n- 带锦标赛主元选择的通信避免 LU (CALU) 通过对所属进程列中的 $p_r$ 个进程上本地选择的候选者进行分层归约，为每个板块选择 $b$ 个主元行，使用高度为 $\\Theta(\\log p_r)$ 的归约树；该选择过程在应用板块更新之前完成。\n- 在车马象主元选择的一个板块的分布式实现中，主元搜索在列最大值和行最大值查询之间交替进行，直到找到一个“车象主元”，即一个在其所在列和所在行中（在当前 Schur 补内）绝对值最大的元素。全局列最大值需要在进程列中的 $p_r$ 个进程上进行集体操作，而全局行最大值需要在进程行中的 $p_c$ 个进程上进行集体操作。我们计算每次这样的集体操作分别产生 $\\Theta(\\log p_r)$ 或 $\\Theta(\\log p_c)$ 条消息。\n- 如果在一个板块内，交替的行/列搜索在板块的 $b$ 个主元中平均每个主元需要常数数量 $\\Theta(1)$ 的交替（因此板块中的总交替次数为 $\\Theta(b)$），我们称该矩阵为“对车马象搜索具有对抗性”的矩阵。如果一个矩阵引发了与部分主元选择已知的最坏情况增长行为相同的行为，我们称其为“对锦标赛稳定性具有对抗性”的矩阵。\n\n在这些假设下，评估以下关于 CALU-TP 和分布式车马象主元选择 (RP) 的消息计数和增长因子的陈述。选择所有正确的陈述。\n\nA. 对于宽度为 $b$ 的单个板块，CALU-TP 使用一个跨越所属进程列中 $p_r$ 个进程的归约树来选择所有 $b$ 个主元，导致每个板块的主元选择消息计数为 $\\Theta(\\log p_r)$，且与 $b$ 无关。\n\nB. 对于宽度为 $b$ 的单个板块，在一个如上文所定义的对车马象搜索具有对抗性的矩阵上，任何遵循经典交替搜索且不带推测性预查的分布式 RP 实现，在该板块的主元选择中必须执行至少 $\\Omega\\!\\big(b \\, (\\log p_r + \\log p_c)\\big)$ 条消息。\n\nC. 在部分主元选择下增长因子为 $\\rho(W_n) = 2^{n-1}$ 的对抗族 $W_n$ 上，CALU-TP 保证能实现严格次指数增长，即 $\\rho(W_n) = o(2^{n})$，因为分层锦标赛避免了最坏情况的主元选择。\n\nD. 对于每个 $n \\times n$ 矩阵 $A$，车马象主元选择保证一个多项式增长因子界 $\\rho(A) \\le n^{c}$，其中 $c$ 是一个与 $A$ 和 $n$ 无关的绝对常数；因此，RP 总是能渐进地改善部分主元选择的最坏情况界。\n\n答案选项：\n- A\n- B\n- C\n- D",
            "solution": "### 步骤 1：提取已知条件\n- 矩阵：稠密矩阵 $A \\in \\mathbb{R}^{n \\times n}$。\n- 并行设置：$p_r \\times p_c$ 的二维进程网格。\n- 数据分布：块循环分布，板块宽度为 $b$。\n- 算法：带锦标赛主元选择的通信避免 LU (CALU-TP) 和车象主元选择 (RP) 的分布式版本。\n- 通信模型：$\\alpha-\\beta$ 模型，关注消息数量（延迟）。在 $p$ 个进程上的集体操作耗费 $\\Theta(\\log p)$ 条消息。\n- 增长因子：对于 $A = P L U$，$\\rho(A) = \\dfrac{\\max_{i,j} |u_{ij}|}{\\max_{i,j} |a_{ij}|}$。\n- 部分主元选择行为：对抗族 $W_n$ 的增长因子为 $\\rho(W_n) = 2^{n-1}$。\n- CALU-TP 定义：通过在 $p_r$ 个进程上进行分层归约，为每个板块选择 $b$ 个主元行，耗费 $\\Theta(\\log p_r)$ 条消息。\n- 分布式 RP 定义：在列最大值（在 $p_r$ 个进程上进行集体操作，成本为 $\\Theta(\\log p_r)$ 条消息）和行最大值（在 $p_c$ 个进程上进行集体操作，成本为 $\\Theta(\\log p_c)$ 条消息）查询之间交替进行。\n- RP 的对抗矩阵：平均每个主元需要 $\\Theta(1)$ 次交替，一个板块总共需要 $\\Theta(b)$ 次交替。\n- CALU-TP 的对抗矩阵：引发与部分主元选择类似的最坏情况增长。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在科学上植根于高性能计算的数值线性代数这一成熟领域。所有术语，如 LU 分解、主元选择策略、增长因子、进程网格和通信模型，都是标准的。所提供的 CALU-TP 和分布式 RP 的描述与科学文献中的高层算法概念一致。关于通信成本和对抗矩阵的假设是明确的，并允许进行适定性分析。该问题是客观的，定义严谨，不包含科学缺陷、矛盾或歧义。\n\n### 步骤 3：结论与行动\n问题陈述有效。我将继续进行解题并评估每个选项。\n\n### 单个板块分析\n该问题涉及宽度为 $b$ 的一个板块的分解。这包括选择 $b$ 个主元并应用相应的变换。这些陈述比较了完成此任务的两种不同主元选择策略的通信成本和稳定性。\n\n### 逐项分析\n\n**A. 对于宽度为 $b$ 的单个板块，CALU-TP 使用一个跨越所属进程列中 $p_r$ 个进程的归约树来选择所有 $b$ 个主元，导致每个板块的主元选择消息计数为 $\\Theta(\\log p_r)$，且与 $b$ 无关。**\n\n让我们分析所述的 CALU-TP 的通信模式。目标是为当前板块选择 $b$ 个主元行。算法流程如下：\n1.  拥有该板块的进程列中的每个 $p_r$ 进程在本地识别一组其最佳候选主元行（例如，在其拥有的板块部分中具有最大元素的 $b$ 行）。\n2.  在这 $p_r$ 个进程之间执行单个集体归约操作，以确定全局的 $b$ 个主元行集合。这可以实现为“锦标赛”形式，在归约树的每一步，进程合并它们的候选者列表并选择最佳的组合集。\n\n我们需要计算消息数量，这对应于 $\\alpha-\\beta$ 模型中的延迟项。对于涉及 $p_r$ 个进程并用归约树实现的集体操作，通信步骤的数量由树的高度决定，即 $\\Theta(\\log p_r)$。尽管传递的消息大小可能取决于 $b$（因为交换的是 $b$ 个候选者的列表），但每个进程发送的消息数量与 $b$ 无关，仅取决于其在归约树中的位置。问题明确指出要关注消息计数。因此，这个单一的、板块范围的主元选择阶段的总消息数为 $\\Theta(\\log p_r)$。它与板块宽度 $b$ 无关。\n\n结论：**正确**。\n\n**B. 对于宽度为 $b$ 的单个板块，在一个如上文所定义的对车象搜索具有对抗性的矩阵上，任何遵循经典交替搜索且不带推测性预查的分布式 RP 实现，在该板块的主元选择中必须执行至少 $\\Omega\\!\\big(b \\, (\\log p_r + \\log p_c)\\big)$ 条消息。**\n\n我们来分析分布式车象主元选择的成本。经典的车象主元选择是为每个主元执行的迭代过程。对于宽度为 $b$ 的板块，我们必须找到 $b$ 个主元，通常是一个接一个地找。\n\n为了找到单个“车象主元”：\n1.  在当前主元列中搜索绝对值最大的元素。这需要在进程列中的 $p_r$ 个进程上进行归约，耗费 $\\Theta(\\log p_r)$ 条消息。\n2.  然后，在步骤 1 中找到的元素的行中搜索绝对值最大的元素。这需要在进程行中的 $p_c$ 个进程上进行归约，耗费 $\\Theta(\\log p_c)$ 条消息。\n3.  如果步骤 2 中找到的元素与步骤 1 中的相同，则找到了一个车象主元。否则，搜索继续，在新元素的列中寻找最大值，依此类推。\n\n每次完整的交替（一次列搜索后跟一次行搜索）耗费 $\\Theta(\\log p_r) + \\Theta(\\log p_c) = \\Theta(\\log p_r + \\log p_c)$ 条消息。\n问题将“对车象搜索具有对抗性”的矩阵定义为平均找到一个主元需要 $\\Theta(1)$ 次此类交替的矩阵。因此，找到一个主元的成本是 $\\Theta(1) \\times \\Theta(\\log p_r + \\log p_c) = \\Theta(\\log p_r + \\log p_c)$。\n\n由于经典方法是顺序地为板块找到 $b$ 个主元，总消息数是每个主元的成本乘以主元数量 $b$。\n总消息数 = $b \\times \\Theta(\\log p_r + \\log p_c) = \\Theta(b(\\log p_r + \\log p_c))$。\n该陈述声称消息数的下界为 $\\Omega(b(\\log p_r + \\log p_c))$。由于我们的推导表明成本是 $\\Theta(b(\\log p_r + \\log p_c))$，这个下界是正确的。\n\n结论：**正确**。\n\n**C. 在部分主元选择下增长因子为 $\\rho(W_n) = 2^{n-1}$ 的对抗族 $W_n$ 上，CALU-TP 保证能实现严格次指数增长，即 $\\rho(W_n) = o(2^{n})$，因为分层锦标赛避免了最坏情况的主元选择。**\n\n这个陈述关系到带锦标赛主元选择的 CALU 的数值稳定性。标准的部分主元选择 (GEPP) 对某些矩阵（如 Wilkinson 矩阵族 $W_n$）表现出 $\\rho(A) \\approx 2^{n-1}$ 的最坏情况指数增长。\n锦标赛主元选择，如 CALU 中所使用的，是部分主元选择的块泛化。它不是在一列中找到单个最佳主元，而是为 $b$ 列的板块找到一组 $b$ 个主元。选择仍然基于元素大小。虽然主元的搜索空间更大（一次考虑 $b$ 列），但没有确凿的证据表明该策略能避免 GEPP 在像 $W_n$ 这样的矩阵上的病态行为。事实上，文献中对 CALU-TP 的稳定性分析表明，其最坏情况增长因子界也是 $2^{n-1}$，与 GEPP 相同。锦标赛先验地选择绝对值大的主元，这与 GEPP 的启发式方法相同。对于 $W_n$ 矩阵，正是这种启发式方法导致了灾难性的元素增长。锦标赛很可能会选择与 GEPP 相同的的主元序列，从而导致相同的指数增长。问题甚至提供了一个“对锦标赛稳定性具有对抗性”的矩阵的定义，它“引发了相同的最坏情况增长行为”，这意味着这类矩阵是存在的。\n声称 CALU-TP 在 $W_n$ 上“保证”实现“严格次指数”增长是一个非常强的断言，与该算法的既定理论分析相悖。所提供的理由（“因为分层锦标赛避免了最坏情况的主元选择”）是一个未经证实且不正确的说法。\n\n结论：**不正确**。\n\n**D. 对于每个 $n \\times n$ 矩阵 $A$，车象主元选择保证一个多项式增长因子界 $\\rho(A) \\le n^{c}$，其中 $c$ 是一个与 $A$ 和 $n$ 无关的绝对常数；因此，RP 总是能渐进地改善部分主元选择的最坏情况界。**\n\n该陈述对车象主元选择的稳定性做出了强有力的断言。\n陈述的第一部分，“车象主元选择保证一个多项式增长因子界 $\\rho(A) \\le n^{c}$，其中 $c$ 是一个绝对常数”，是数值分析中一个著名的、长期存在的开放问题。这是一个猜想，而非已证明的定理。事实上，有证据表明情况可能并非如此。一些矩阵示例表现出指数增长（例如，$\\approx 2.57^{n/2}$），尽管其基数小于部分主元选择的最坏情况。已知的已证明上界不是多项式的；它们是准多项式的（例如，形式为 $n^{O(\\log n)}$）。根据当前的数学知识，声称一个多项式界是“有保证的”在事实上是不正确的。作为一名对科学正确性毫不妥协的人，我必须将此断言标记为科学上不健全的。\n\n由于该陈述的前提是错误的（它将一个开放的猜想陈述为事实），整个陈述是无效的。其结论“因此，RP 总是能渐进地改善部分主元选择的最坏情况界”在精神上可能是正确的（RP 的最坏情况比 PP 好得多），但它是作为一个错误前提的逻辑推论而提出的。因此，整个陈述是谬误的。\n\n结论：**不正确**。",
            "answer": "$$\\boxed{AB}$$"
        }
    ]
}