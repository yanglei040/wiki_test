{
    "hands_on_practices": [
        {
            "introduction": "在设计新算法之前，理解现有算法的性能瓶颈至关重要。本练习将指导您对四种不同的QR分解方法进行比较分析，从业界经典的方法到避免通信的CholeskyQR算法 。通过剖析它们的计算成本、通信模式和同步开销，您将清晰地认识到为什么最小化通信（尤其是延迟）是现代数值线性代数的核心目标之一。",
            "id": "3537877",
            "problem": "考虑一个高瘦矩阵 $A \\in \\mathbb{R}^{m \\times n}$（其中 $m \\gg n$），该矩阵在使用消息传递接口 (MPI) 的分布式内存系统中，以行分块布局分布在 $p$ 个进程上。目标是使用以下算法之一计算瘦 $QR$ 分解 $A = QR$：经典 Gram-Schmidt (CGS)、修正 Gram-Schmidt (MGS)、带再正交化的 CGS (CGS2) 和 CholeskyQR。假设采用以下在数值线性代数中广泛用作通信分析基准的标准实现选择：\n\n- 对于 CGS 的第 $k$ 列，与先前计算出的 $Q$ 的 $k-1$ 列的内积在本地计算，并通过对一个长度为 $k-1$ 的向量进行单次 MPI Allreduce 来聚合，然后进行本地更新，最后再通过一次单独的 MPI Allreduce 来计算欧几里得范数。\n- 对于 MGS 的第 $k$ 列，算法依次对 $q_1, q_2, \\dots, q_{k-1}$ 进行正交化，每一步执行一次全局点积（每次都是对一个标量进行 MPI Allreduce），最后再通过一次单独的 MPI Allreduce 计算欧几里得范数；不假设使用流水线或通信聚合的变体。\n- 对于 CGS2 的第 $k$ 列，执行两遍 CGS（每遍都对一个长度为 $k-1$ 的向量进行单次 MPI Allreduce），然后通过一次 MPI Allreduce 计算欧几里得范数。\n- 对于 CholeskyQR，首先构建 Gram 矩阵 $G = A^{T} A$ 并进行一次全局归约（例如，通过对对称 $n \\times n$ 矩阵或其包含 $\\frac{n(n+1)}{2}$ 个标量的压缩上三角进行单次 MPI Allreduce），然后在本地计算 $R = \\text{chol}(G)$，并通过本地三角求解构建 $Q = A R^{-1}$。不使用再正交化步骤。\n\n仅使用关于分布式点积和范数的基本原理，以及矩阵-向量和矩阵-矩阵运算的标准浮点运算 (flop) 计数，选择为每种方法正确描述以下特征的选项：关于 $m$ 和 $n$ 的浮点运算计数主导项、全局同步的次数以及典型的 MPI 集合通信大小。您可以假设 $m \\gg n$，因此可以陈述低阶项，但它们不占主导地位。\n\nA. CGS 和 MGS 各自的成本约为 $2 m n^{2}$ 次浮点运算；CGS2 的成本约为 $4 m n^{2}$ 次浮点运算；CholeskyQR 的成本约为 $2 m n^{2} + \\frac{1}{3} n^{3}$ 次浮点运算。对于每列 $k$，CGS 执行 $2$ 次同步（一次对长度为 $k-1$ 的向量进行 MPI Allreduce 以计算内积，一次对标量进行 MPI Allreduce 以计算范数）；MGS 执行 $k$ 次同步（$k-1$ 次点积每次各需一次标量 MPI Allreduce，再加上一次计算范数的标量 MPI Allreduce）；CGS2 执行 $3$ 次同步（两次 CGS 过程各需一次长度为 $k-1$ 的向量 MPI Allreduce，再加上一次计算范数的标量 MPI Allreduce）。CholeskyQR 在整个分解过程中总共执行 $1$ 次全局同步（对对称 $n \\times n$ Gram 矩阵，例如 $\\frac{n(n+1)}{2}$ 个标量，进行一次 MPI Allreduce），此后所有计算均为本地计算。\n\nB. CGS 和 MGS 各自的成本约为 $2 m n^{2}$ 次浮点运算；CGS2 的成本约为 $2 m n^{2}$ 次浮点运算；CholeskyQR 的成本约为 $m n^{2}$ 次浮点运算。对于每列 $k$，通过批量处理点积，CGS 和 MGS 都可以用 $2$ 次同步实现（一次长度为 $k-1$ 的向量 MPI Allreduce 和一次计算范数的标量 MPI Allreduce）；CGS2 每列也只需要 $2$ 次同步；CholeskyQR 需要 $n$ 次同步（每列一次标量 MPI Allreduce）来累加 Gram 矩阵。\n\nC. CGS 的成本约为 $2 m n^{2}$ 次浮点运算；MGS 的成本约为 $4 m n^{2}$ 次浮点运算；CGS2 的成本约为 $2 m n^{2}$ 次浮点运算；CholeskyQR 的成本约为 $2 m n^{2}$ 次浮点运算。对于每列 $k$，CGS 需要 $k$ 次同步（每次内积一次标量 MPI Allreduce，再加上一次范数计算），MGS 需要 $2$ 次同步（一次向量 MPI Allreduce 和一次标量 MPI Allreduce），CGS2 需要 $2$ 次同步，而 CholeskyQR 需要 $O(n)$ 次同步，因为 Cholesky 需要迭代求精。\n\nD. CGS 和 MGS 各自的成本约为 $2 m n^{2}$ 次浮点运算；CGS2 的成本约为 $4 m n^{2}$ 次浮点运算；CholeskyQR 的成本约为 $2 m n^{2} + \\frac{1}{3} n^{3}$ 次浮点运算。对于每列 $k$，CGS 执行 $1$ 次同步（一次长度为 $k-1$ 的向量 MPI Allreduce，并将范数计算合并到同一次集合通信中）；MGS 执行 $2$ 次同步（一次向量 MPI Allreduce 和一次标量 MPI Allreduce）；CGS2 执行 $2$ 次同步（两次向量 MPI Allreduce）；CholeskyQR 在整个分解过程中需要 $2$ 次同步（一次用于 $A^{T} A$ 的 MPI Allreduce，一次用于分发 $R$）。",
            "solution": "这个问题要求对计算一个高瘦矩阵 $A \\in \\mathbb{R}^{m \\times n}$（其中 $m \\gg n$）的瘦 $QR$ 分解的四种不同算法进行批判性分析。矩阵 $A$ 以行分块的方式分布在 $p$ 个进程上。分析必须基于为每种算法提供的具体实现细节：经典 Gram-Schmidt (CGS)、修正 Gram-Schmidt (MGS)、带再正交化的 CGS (CGS2) 和 CholeskyQR。我们将为每种方法评估浮点运算 (flop) 计数的主导项、全局同步的次数以及 MPI 集合通信中的数据大小。\n\n设 $A = [a_1, a_2, \\dots, a_n]$ 为输入矩阵，$Q=[q_1, q_2, \\dots, q_n]$ 和 $R \\in \\mathbb{R}^{n \\times n}$ 为输出矩阵。$p$ 个进程中的每一个都持有 $A$ 和 $Q$ 的 $m/p$ 行。一次全局点积或范数计算需要每个进程计算一个本地和，然后参与一次集合 `MPI_Allreduce` 操作以获得全局结果。一次同步计为一次 `MPI_Allreduce` 调用。\n\n**经典 Gram-Schmidt (CGS)**\n\n该算法一次处理一列 $a_k$，其中 $k=1, \\dots, n$。\n1.  **正交化：** 向量 $a_k$ 与先前计算出的标准正交向量 $q_1, \\dots, q_{k-1}$ 进行正交化。系数为 $R_{jk} = q_j^T a_k$，其中 $j=1, \\dots, k-1$。问题陈述这 $k-1$ 个点积是通过“对一个长度为 $k-1$ 的向量进行单次 MPI Allreduce”来计算的。这构成 $1$ 次同步。这些点积的浮点运算计数为 $(k-1) \\times (2m-1) \\approx 2m(k-1)$。随后的更新 $v_k = a_k - \\sum_{j=1}^{k-1} R_{jk} q_j$ 的成本约为 $2m(k-1)$ 次浮点运算，并且是本地操作。每列 $k$ 的正交化总浮点运算次数约为 $4m(k-1)$。\n2.  **归一化：** 对得到的向量 $v_k$ 进行归一化。这需要计算其欧几里得范数 $R_{kk} = \\|v_k\\|_2$。问题陈述这是通过“一次单独的 MPI Allreduce”完成的。这是第 $k$ 列的第 2 次同步，操作对象是一个标量值。归一化的浮点运算计数较小（点积需要 $m$ 次乘法和 $m-1$ 次加法，再加上 $m$ 次除法）。\n3.  **总浮点运算：** 对所有列的主导成本求和：$\\sum_{k=1}^n 4m(k-1) = 4m \\frac{(n-1)n}{2} \\approx 2mn^2$。\n4.  **总同步次数：** 对于每列 $k$，有 $2$ 次同步。\n5.  **集合通信大小：** 对于每列 $k$，一次对长度为 $k-1$ 的向量的 `MPI_Allreduce`，和一次对标量的 `MPI_Allreduce`。\n\n**修正 Gram-Schmidt (MGS)**\n\n问题指定了一种特定的实现：“对于第 $k$ 列，算法依次对 $q_{1}, q_{2}, \\dots, q_{k-1}$ 进行正交化，每一步执行一次全局点积（每次都是对一个标量进行 MPI Allreduce）”。设正在处理的向量为 $v$，初始化为 $a_k$。\n1.  **正交化：** 对于 $j=1, \\dots, k-1$，算法计算 $R_{jk} = q_j^T v$ 并更新 $v \\leftarrow v - R_{jk} q_j$。每个点积都需要对一个标量进行 `MPI_Allreduce`，因此这个循环涉及 $k-1$ 次同步。每一步 $j$ 的浮点运算成本约为 $2m$（用于点积）和 $2m$（用于更新），总计约为 $4m$。在整个循环中，这是 $4m(k-1)$ 次浮点运算。\n2.  **归一化：** 为计算范数 $R_{kk} = \\|v\\|_2$ 执行最后一次对标量的 `MPI_Allreduce`。这是第 $k$ 列的第 $k$ 次同步。\n3.  **总浮点运算：** 浮点运算计数与 CGS 相同：$\\sum_{k=1}^{n} 4m(k-1) \\approx 2mn^2$。\n4.  **总同步次数：** 对于每列 $k$，有 $k-1+1 = k$ 次同步。\n5.  **集合通信大小：** 第 $k$ 列的所有 $k$ 次同步都对标量进行操作。\n\n**带再正交化的 CGS (CGS2)**\n\n该算法为每列执行两遍 CGS 以提高数值稳定性。\n1.  **正交化：** 问题陈述“执行两遍 CGS（每遍都对一个长度为 $k-1$ 的向量进行单次 MPI Allreduce）”。这意味着对于第 $k$ 列，我们执行一个 CGS 步骤，然后对结果再执行一个 CGS 步骤。\n    - 第 1 遍：$v' = a_k - Q_{1:k-1}(Q_{1:k-1}^T a_k)$。这涉及 $1$ 次同步（向量 `MPI_Allreduce`）和 $\\approx 4m(k-1)$ 次浮点运算。\n    - 第 2 遍：$v'' = v' - Q_{1:k-1}(Q_{1:k-1}^T v')$。这涉及另一次同步（向量 `MPI_Allreduce`）和另外 $\\approx 4m(k-1)$ 次浮点运算。\n2.  **归一化：** 最终的归一化 $R_{kk} = \\|v''\\|_2$ 需要第三次同步（标量 `MPI_Allreduce`）。\n3.  **总浮点运算：** 浮点运算计数是 CGS 的两倍：$\\approx 2 \\times (2mn^2) = 4mn^2$。\n4.  **总同步次数：** 对于每列 $k$，有 $2+1 = 3$ 次同步。\n5.  **集合通信大小：** 对于每列 $k$，两次对长度为 $k-1$ 的向量的 `MPI_Allreduce` 调用，和一次对标量的 `MPI_Allreduce`。\n\n**CholeskyQR**\n\n该算法避免直接对向量进行正交化。\n1.  **Gram 矩阵构建：** 首先，计算 Gram 矩阵 $G = A^T A$。这个 $n \\times n$ 的矩阵是通过计算 $A$ 的列之间的所有 $\\frac{n(n+1)}{2}$ 个唯一的点积来形成的。计算 $G$ 的上三角的成本约为 $\\frac{n(n+1)}{2} \\times 2m \\approx mn^2$ 次浮点运算。问题陈述本地贡献 $A_p^T A_p$ 是通过“对对称 $n \\times n$ 矩阵或其包含 $\\frac{n(n+1)}{2}$ 个标量的压缩上三角进行单次 MPI Allreduce”来求和的。这是整个分解过程中的 $1$ 次全局同步。\n2.  **Cholesky 分解：** 计算 Cholesky 分解 $G=R^T R$。矩阵 $G$ 很小（$n \\times n$），在归约后所有进程上都可用。此步骤在本地执行（或在所有地方复制执行），成本约为 $\\frac{1}{3}n^3$ 次浮点运算。它不需要通信。\n3.  **构建 Q：** 矩阵 $Q$ 计算为 $Q = AR^{-1}$。这是一个以 $A$ 的 $n$ 列作为多个右侧向量的三角求解。由于 $A$ 是按行分布的 ($A_p$)，每个进程通过本地操作 $Q_p=A_p R^{-1}$ 计算其对应的 $Q$ 的行 ($Q_p$)。由于 $R$ 是复制的，这在所有进程上总共需要约 $mn^2$ 次浮点运算，并且不需要通信。\n4.  **总浮点运算：** 总浮点运算计数是各步骤的总和：$mn^2$ (用于 $A^T A$) $+ \\frac{1}{3}n^3$ (用于 Cholesky) $+ mn^2$ (用于 $AR^{-1}$)，简化为 $2mn^2 + \\frac{1}{3}n^3$。\n5.  **总同步次数：** 整个算法只有 $1$ 次全局同步。\n6.  **集合通信大小：** 单次 `MPI_Allreduce` 对 $\\approx n^2/2$ 个标量进行操作。\n\n**选项评估**\n\n*   **选项 A:**\n    - **浮点运算：** 陈述 CGS/MGS 的成本约为 $2mn^2$，CGS2 成本约为 $4mn^2$，CholeskyQR 成本约为 $2mn^2 + \\frac{1}{3}n^3$。这与我们的推导相符。\n    - **同步与大小：** 陈述 CGS 每列有 $2$ 次同步（$k-1$ 长度的向量，标量），MGS 每列有 $k$ 次同步（全部为标量），CGS2 每列有 $3$ 次同步（两个 $k-1$ 长度的向量，一个标量），而 CholeskyQR 总共有 $1$ 次同步（$\\frac{n(n+1)}{2}$ 个标量的矩阵）。这完全符合我们基于问题明确假设的分析。\n    - **结论：** **正确**。\n\n*   **选项 B:**\n    - **浮点运算：** 陈述 CGS2 成本约为 $2mn^2$，CholeskyQR 成本约为 $mn^2$。两者都错误。\n    - **同步：** 陈述 MGS 可以通过批量处理以 $2$ 次同步完成，这与问题对 MGS 的前提相矛盾。它还陈述 CholeskyQR 需要 $n$ 次同步，这与对 CholeskyQR 的前提相矛盾。\n    - **结论：** **错误**。\n\n*   **选项 C:**\n    - **浮点运算：** 陈述 MGS 成本约为 $4mn^2$，CGS2 成本约为 $2mn^2$。两者都错误。\n    - **同步：** 交换了 CGS 和 MGS 的同步计数，即便如此，描述也与问题陈述不一致。CGS2 的计数是错误的（$2$ 而不是 $3$）。CholeskyQR 的计数是错误的（$O(n)$ 而不是 $1$）。\n    - **结论：** **错误**。\n\n*   **选项 D:**\n    - **浮点运算：** 浮点运算计数陈述正确。\n    - **同步：** 陈述 CGS 每列有 $1$ 次同步，MGS 有 $2$ 次，CGS2 有 $2$ 次，CholeskyQR 总共有 $2$ 次。所有这些计数都是错误的，并且与基于问题明确陈述的推导相冲突。例如，它假设了一个问题中未描述的优化 CGS 实现，错误地描述了 MGS，并且不完整地计算了 CGS2 和 CholeskyQR 的同步次数。\n    - **结论：** **错误**。\n\n基于从基本原理出发并严格遵守问题陈述中提供的实现细节的透彻分析，只有选项 A 对所有四种算法提供了完全准确的描述。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "上一个练习将CholeskyQR算法确定为一种同步开销较低的算法。然而，其性能仍然依赖于其关键通信步骤——全局规约Gram矩阵——的有效实现。本实践  要求您应用基础的延迟-带宽（$\\alpha$-$\\beta$）通信模型，来比较两种不同的MPI集合通信策略以完成此任务。您的分析将揭示最佳选择如何依赖于机器特性和问题规模，这是高性能计算中性能工程的一项核心技能。",
            "id": "3537871",
            "problem": "考虑一个高瘦矩阵 $A \\in \\mathbb{R}^{m \\times n}$（其中 $m \\gg n$）在具有 $P$ 个处理器、基于消息传递接口 (MPI) 编程模型组织的分布式内存系统上进行基于Cholesky的QR分解 (CholeskyQR)。假设 $A$ 是按块行分布的，因此处理器 $p$ 拥有 $A_p \\in \\mathbb{R}^{m_p \\times n}$，并形成其本地Gram矩阵 $G_p = A_p^{T} A_p \\in \\mathbb{R}^{n \\times n}$。全局Gram矩阵为 $G = \\sum_{p=1}^{P} G_p = R^{T} R$，其中 $R$ 是 $G$ 的上三角Cholesky因子。每个 $G_p$ 都是对称的；假设它以每个处理器 $s = \\frac{n(n+1)}{2}$ 个双精度浮点数的上三角紧凑格式存储。\n\n你需要比较两种用于从 $\\{G_p\\}$ 形成 $G$ 的集体通信策略，使用标准的双参数通信时间模型 (Hockney模型)：发送一个包含 $w$ 个双精度浮点数的消息所需的时间为 $T_{\\text{msg}}(w) = \\alpha + \\beta w$，其中 $\\alpha$ 是延迟（单位：秒/消息），$\\beta$ 是逆带宽（单位：秒/双精度浮点数）。忽略任何计算成本以及通信与计算之间的任何重叠。假设集体操作采用以下算法选择：\n\n- allreduce (求和) 操作通过 Rabenseifner 方法实现，即先通过递归减半进行 reduce-scatter，然后通过递归加倍进行 allgather，每个阶段都产生 $\\log_{2} P$ 个通信步骤。\n- reduce-scatter (求和归约并将归约结果等大小地散播) 操作通过环形算法实现，即它使用 $P-1$ 个最近邻步骤，每一步的消息大小均分。\n\n假设此阶段的最终目标是使全局归约后的Gram矩阵以分布式形式（而非复制形式）可用，因此 allreduce 执行的复制操作所产生的通信量严格多于此阶段所必需的。\n\n仅从 Hockney 模型和所述的算法结构出发，推导出两种策略的总通信时间关于 $n$、$P$、$\\alpha$ 和 $\\beta$ 的符号表达式，然后找出两种策略通信时间相等时的交叉点列维度 $n^{\\ast}$ 的精确闭式表达式。你的最终答案必须是用 $P, \\alpha, \\beta$ 表示的 $n^{\\ast}$。最终表达式中不要包含单位。如果表达式中涉及 $P$ 的对数，请明确使用以2为底的对数。不需要进行数值计算。",
            "solution": "我们从 Hockney 模型开始，该模型指出发送一个包含 $w$ 个双精度浮点数的消息所需时间为 $T_{\\text{msg}}(w) = \\alpha + \\beta w$，其中 $\\alpha$ 是延迟，$\\beta$ 是逆带宽。我们将通过计算在给定算法下每个集体操作的通信步骤数和每步的数据量来计算通信时间，然后比较得出的表达式。\n\n每个处理器持有 $s = \\frac{n(n+1)}{2}$ 个双精度浮点数，代表 $G_p$ 的上三角紧凑存储。目标是在 $P$ 个处理器上以分布式形式形成 $G = \\sum_{p=1}^{P} G_p$。\n\n首先，考虑通过环形算法实现的 reduce-scatter。在用于等大小分区的环形 reduce-scatter 中，有 $P-1$ 个通信步骤。在每一步中，每个处理器发送和接收一个由 $\\frac{s}{P}$ 个双精度浮点数组成的连续数据块。根据 Hockney 模型，每一步的成本为 $\\alpha + \\beta \\cdot \\frac{s}{P}$，共有 $P-1$ 步。因此，总时间为\n$$\nT_{\\text{RS,ring}}(n,P,\\alpha,\\beta) \\;=\\; (P-1)\\,\\alpha \\;+\\; (P-1)\\,\\beta \\cdot \\frac{s}{P}\n\\;=\\; (P-1)\\,\\alpha \\;+\\; \\frac{P-1}{P}\\,\\beta \\cdot \\frac{n(n+1)}{2}.\n$$\n\n其次，考虑通过 Rabenseifner 方法实现的 allreduce，它包括一个通过递归减半实现的 reduce-scatter，后跟一个通过递归加倍实现的 allgather。在递归减半（和加倍）下，每个阶段的步骤数为 $\\log_{2} P$。对于带宽成本，在整个 reduce-scatter 阶段，每个处理器通信的双精度浮点数总数等于 $\\frac{P-1}{P}\\,s$，allgather 阶段也是如此。因此，总的 allreduce 时间是两个阶段的和：\n$$\nT_{\\text{AR,Rab}}(n,P,\\alpha,\\beta) \\;=\\; \\underbrace{\\log_{2} P \\cdot \\alpha}_{\\text{reduce-scatter latency}} \\;+\\; \\underbrace{\\frac{P-1}{P}\\,\\beta\\,s}_{\\text{reduce-scatter bandwidth}}\n\\;+\\; \\underbrace{\\log_{2} P \\cdot \\alpha}_{\\text{allgather latency}} \\;+\\; \\underbrace{\\frac{P-1}{P}\\,\\beta\\,s}_{\\text{allgather bandwidth}}.\n$$\n合并各项并代入 $s = \\frac{n(n+1)}{2}$，我们得到\n$$\nT_{\\text{AR,Rab}}(n,P,\\alpha,\\beta) \\;=\\; 2\\,\\alpha\\,\\log_{2} P \\;+\\; 2\\,\\frac{P-1}{P}\\,\\beta \\cdot \\frac{n(n+1)}{2}\n\\;=\\; 2\\,\\alpha\\,\\log_{2} P \\;+\\; \\frac{P-1}{P}\\,\\beta \\cdot n(n+1).\n$$\n\n我们现在求两个时间相等时的交叉点 $n^{\\ast}$。令 $T_{\\text{RS,ring}} = T_{\\text{AR,Rab}}$：\n$$\n(P-1)\\,\\alpha \\;+\\; \\frac{P-1}{P}\\,\\beta \\cdot \\frac{n(n+1)}{2}\n\\;=\\; 2\\,\\alpha\\,\\log_{2} P \\;+\\; \\frac{P-1}{P}\\,\\beta \\cdot n(n+1).\n$$\n重新排列以分离出含有 $n(n+1)$ 的项：\n$$\n(P-1)\\,\\alpha \\;-\\; 2\\,\\alpha\\,\\log_{2} P \\;=\\; \\frac{P-1}{P}\\,\\beta \\left( n(n+1) \\;-\\; \\frac{n(n+1)}{2} \\right)\n\\;=\\; \\frac{P-1}{P}\\,\\beta \\cdot \\frac{n(n+1)}{2}.\n$$\n求解 $n(n+1)$：\n$$\n\\frac{n(n+1)}{2} \\;=\\; \\frac{P}{P-1}\\,\\frac{\\alpha}{\\beta}\\,\\bigl( (P-1) \\;-\\; 2\\,\\log_{2} P \\bigr).\n$$\n定义\n$$\nC \\;=\\; \\frac{P}{P-1}\\,\\frac{\\alpha}{\\beta}\\,\\bigl( (P-1) \\;-\\; 2\\,\\log_{2} P \\bigr).\n$$\n那么，等式条件变为 $\\frac{n(n+1)}{2} = C$。求解二次方程 $n^{2} + n - 2C = 0$ 得出\n$$\nn^{\\ast} \\;=\\; \\frac{-1 + \\sqrt{\\,1 + 8C\\,}}{2}\n\\;=\\; \\frac{-1 + \\sqrt{\\,1 + 8\\,\\frac{P}{P-1}\\,\\frac{\\alpha}{\\beta}\\,\\bigl( (P-1) - 2\\,\\log_{2} P \\bigr)\\,}}{2}.\n$$\n\n在 Hockney 模型中，这个 $n^{\\ast}$ 是唯一的非负交叉点。当 $n  n^{\\ast}$ 时，具有较低延迟项的 allreduce 更快；当 $n > n^{\\ast}$ 时，具有较低带宽系数的 reduce-scatter 更快。当 $\\bigl( (P-1) - 2\\,\\log_{2} P \\bigr) \\le 0$ 时，量 $C \\le 0$，交叉点出现在非正的 $s$ 处，这表明在这个延迟主导的区域内，对于此模型中的所有非负 $n$，allreduce 始终是更优的选择；相反，当 $C > 0$ 时，对于足够大的 $n$，reduce-scatter 变得更优。",
            "answer": "$$\\boxed{\\frac{-1 + \\sqrt{\\,1 + 8\\,\\frac{P}{P-1}\\,\\frac{\\alpha}{\\beta}\\,\\bigl((P-1) - 2\\,\\log_{2} P\\bigr)\\,}}{2}}$$"
        }
    ]
}