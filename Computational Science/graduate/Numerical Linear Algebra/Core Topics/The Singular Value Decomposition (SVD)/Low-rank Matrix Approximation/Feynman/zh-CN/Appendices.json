{
    "hands_on_practices": [
        {
            "introduction": "一个矩阵能够被低秩矩阵近似的优劣程度，从根本上取决于其奇异值的分布。本练习将从理论上深入探讨这一关系，探索奇异值的衰减速率如何直接决定近似误差的收敛速度 。通过解决这个问题，你将对什么使得一个矩阵“容易”或“难以”近似获得一个定量的理解。",
            "id": "3557759",
            "problem": "设 $A$ 是一个无穷实对角矩阵（等价地，可分希尔伯特空间 $\\ell^{2}$ 上的一个紧算子），定义为 $A = \\operatorname{diag}(\\sigma_{1}, \\sigma_{2}, \\dots)$，其奇异值 $\\sigma_{i} = i^{-\\alpha}$，适用于所有整数 $i \\geq 1$ 和一个固定参数 $\\alpha > 0$。令 $A_{k}$ 表示通过将 $A$ 的奇异值分解（SVD）截断为其最大的 $k$ 个奇异值而得到的 $A$ 的最佳 $k$ 秩逼近，并令 $\\|\\cdot\\|_{F}$ 表示弗罗贝尼乌斯范数（在无穷维情况下也称为希尔伯特-施密特范数）。\n\n从弗罗贝尼乌斯范数和奇异值分解（SVD）的定义出发，并仅使用诸如弗罗贝尼乌斯范数的正交不变性和用于级数的单调积分比较等基本事实，推导当 $k \\to \\infty$ 时弗罗贝尼乌斯范数误差 $E_{k}(\\alpha) = \\|A - A_{k}\\|_{F}$ 的精确首项渐近式，并解释其行为如何依赖于 $\\alpha$。您的推导必须证明首项中的常数和指数的合理性。\n\n将您的最终答案表示为单个闭式表达式，给出在 $E_{k}(\\alpha)$ 为有限值的范围内 $E_{k}(\\alpha)$ 的首项。无需四舍五入。",
            "solution": "该问题要求在用最佳 $k$ 秩逼近 $A_k$ 来逼近无穷对角矩阵 $A$ 时，弗罗贝尼乌斯范数误差 $E_{k}(\\alpha) = \\|A - A_{k}\\|_{F}$ 的首项渐近行为。\n\n首先，我们确定矩阵 $A$ 和 $A_k$ 的结构。给定矩阵为 $A = \\operatorname{diag}(\\sigma_{1}, \\sigma_{2}, \\dots)$，其奇异值 $\\sigma_{i} = i^{-\\alpha}$，适用于整数 $i \\ge 1$ 和参数 $\\alpha > 0$。由于 $\\sigma_i$ 的值是正的并且按降序排列（$\\sigma_1 > \\sigma_2 > \\dots > 0$），这个对角表示已经是 $A$ 的奇异值分解（SVD）。具体来说，如果我们将 $A$ 的 SVD 写为 $A = U \\Sigma V^*$，那么 $U$ 和 $V$ 是希尔伯特空间 $\\ell^2$ 上的单位算子，而 $\\Sigma$ 是对角项为 $\\sigma_i$ 的对角算子。\n\n推广到希尔伯特空间上紧算子的 Eckart-Young-Mirsky 定理指出，在任何酉不变范数（包括弗罗贝尼乌斯范数）下，$A$ 的最佳 $k$ 秩逼近可以通过截断其 SVD 得到。这是通过保留最大的 $k$ 个奇异值并将其他奇异值设为零来实现的。因此，最佳 $k$ 秩逼近 $A_k$ 由下式给出：\n$$\nA_k = \\operatorname{diag}(\\sigma_1, \\sigma_2, \\dots, \\sigma_k, 0, 0, \\dots)\n$$\n因此，误差矩阵 $A - A_k$ 为：\n$$\nA - A_k = \\operatorname{diag}(0, \\dots, 0, \\sigma_{k+1}, \\sigma_{k+2}, \\dots)\n$$\n这是一个对角算子，其非零项从第 $(k+1)$ 个位置开始。\n\n接下来，我们计算这个误差矩阵的弗罗贝尼乌斯范数。对于一个对角算子 $D = \\operatorname{diag}(d_1, d_2, \\dots)$，弗罗贝尼乌斯范数（或希尔伯特-施密特范数），记为 $\\|\\cdot\\|_F$，定义为：\n$$\n\\|D\\|_{F} = \\sqrt{\\sum_{i=1}^{\\infty} |d_i|^2}\n$$\n将此定义应用于误差矩阵 $A - A_k$，我们得到误差 $E_k(\\alpha)$：\n$$\nE_k(\\alpha)^2 = \\|A - A_k\\|_{F}^2 = \\sum_{i=k+1}^{\\infty} \\sigma_i^2\n$$\n代入给定的奇异值形式 $\\sigma_i = i^{-\\alpha}$：\n$$\nE_k(\\alpha)^2 = \\sum_{i=k+1}^{\\infty} (i^{-\\alpha})^2 = \\sum_{i=k+1}^{\\infty} i^{-2\\alpha}\n$$\n误差 $E_k(\\alpha)$ 是该和的平方根：\n$$\nE_k(\\alpha) = \\left( \\sum_{i=k+1}^{\\infty} i^{-2\\alpha} \\right)^{1/2}\n$$\n该表达式是有限的，当且仅当该级数收敛。级数 $\\sum_{i=1}^{\\infty} i^{-p}$ 是一个 p-级数，它收敛的充要条件是 $p > 1$。在我们的例子中，指数是 $p = 2\\alpha$。因此，总误差 $\\|A\\|_F$ 是有限的，从而对于所有 $k$，尾项和 $E_k(\\alpha)^2$ 都是有意义的，当且仅当 $2\\alpha > 1$，即 $\\alpha > \\frac{1}{2}$。问题要求的是在 $E_k(\\alpha)$ 为有限值的范围内的渐近行为，所以我们在 $\\alpha > \\frac{1}{2}$ 的假设下进行。\n\n为了找到当 $k \\to \\infty$ 时 $E_k(\\alpha)$ 的首项渐近行为，我们需要逼近和 $S_k(\\alpha) = \\sum_{i=k+1}^{\\infty} i^{-2\\alpha}$。我们使用积分比较法。函数 $f(x) = x^{-2\\alpha}$ 对于 $x \\ge 1$ 是一个正、连续且严格递减的函数。对于任何整数 $i \\ge 1$，我们可以在一个区间上界定函数的值：\n$$\n\\int_{i}^{i+1} x^{-2\\alpha} dx \\le i^{-2\\alpha} \\le \\int_{i-1}^{i} x^{-2\\alpha} dx\n$$\n将这些不等式从 $i = k+1$ 到 $\\infty$ 求和，我们得到级数 $S_k(\\alpha)$ 的界：\n$$\n\\int_{k+1}^{\\infty} x^{-2\\alpha} dx \\le \\sum_{i=k+1}^{\\infty} i^{-2\\alpha} \\le \\int_{k}^{\\infty} x^{-2\\alpha} dx\n$$\n现在我们计算该积分。由于我们假设了 $2\\alpha > 1$，该积分是收敛的：\n$$\n\\int x^{-2\\alpha} dx = \\frac{x^{-2\\alpha+1}}{-2\\alpha+1} + C\n$$\n$$\n\\int_{a}^{\\infty} x^{-2\\alpha} dx = \\left[ \\frac{x^{1-2\\alpha}}{1-2\\alpha} \\right]_{a}^{\\infty} = 0 - \\frac{a^{1-2\\alpha}}{1-2\\alpha} = \\frac{a^{1-2\\alpha}}{2\\alpha-1}\n$$\n将此结果代入我们对 $S_k(\\alpha)$ 的界中：\n$$\n\\frac{(k+1)^{1-2\\alpha}}{2\\alpha-1} \\le S_k(\\alpha) \\le \\frac{k^{1-2\\alpha}}{2\\alpha-1}\n$$\n对于大的 $k$，我们有渐近等价关系 $(k+1)^{1-2\\alpha} \\sim k^{1-2\\alpha}$。更正式地说：\n$$\n(k+1)^{1-2\\alpha} = k^{1-2\\alpha} \\left(1 + \\frac{1}{k}\\right)^{1-2\\alpha} = k^{1-2\\alpha} \\left(1 + \\frac{1-2\\alpha}{k} + O(k^{-2})\\right)\n$$\n因此，上下界都渐近等价于 $\\frac{k^{1-2\\alpha}}{2\\alpha-1}$。根据渐近行为的夹逼定理，该和的首项是：\n$$\nS_k(\\alpha) = \\sum_{i=k+1}^{\\infty} i^{-2\\alpha} \\sim \\frac{k^{1-2\\alpha}}{2\\alpha-1} \\quad \\text{as } k \\to \\infty\n$$\n记号 $g(k) \\sim h(k)$ 表示 $\\lim_{k\\to\\infty} g(k)/h(k) = 1$。\n\n现在，我们可以找到误差 $E_k(\\alpha) = \\sqrt{S_k(\\alpha)}$ 的渐近行为：\n$$\nE_k(\\alpha) \\sim \\left( \\frac{k^{1-2\\alpha}}{2\\alpha-1} \\right)^{1/2} = \\frac{(k^{1-2\\alpha})^{1/2}}{\\sqrt{2\\alpha-1}} = \\frac{k^{(1-2\\alpha)/2}}{\\sqrt{2\\alpha-1}}\n$$\n化简指数可得：\n$$\nE_k(\\alpha) \\sim \\frac{1}{\\sqrt{2\\alpha-1}} k^{\\frac{1}{2} - \\alpha}\n$$\n这个表达式给出了当 $k \\to \\infty$ 时误差的首项渐近式，对 $\\alpha > \\frac{1}{2}$ 有效。常数为 $\\frac{1}{\\sqrt{2\\alpha-1}}$，$k$ 的指数为 $\\frac{1}{2} - \\alpha$。\n\n逼近误差的行为取决于 $\\alpha$：\n- 该分析仅对 $\\alpha > \\frac{1}{2}$ 有效，因为对于 $\\alpha \\le \\frac{1}{2}$，算子 $A$ 不属于希尔伯特-施密特类（即 $\\|A\\|_F = \\infty$）。\n- $k$ 的指数为 $\\frac{1}{2} - \\alpha$，对于 $\\alpha > \\frac{1}{2}$，该指数为负。这证实了当 $k \\to \\infty$ 时，误差 $E_k(\\alpha)$ 趋于 $0$。\n- 随着 $\\alpha$ 的增加，奇异值衰减得更快。指数 $\\frac{1}{2} - \\alpha$ 变得更负，表明 $k$ 秩逼近的收敛速度更快。\n- 当 $\\alpha$ 从上方趋近于临界值 $\\frac{1}{2}$ 时，常数项 $\\frac{1}{\\sqrt{2\\alpha-1}}$ 发散到无穷大，收敛速度 $k^{\\frac{1}{2} - \\alpha}$ 变得非常慢（指数趋于 $0$）。这标志着在希尔伯特-施密特类的边界附近，良好的可逼近性失效。",
            "answer": "$$\n\\boxed{\\frac{1}{\\sqrt{2\\alpha-1}} k^{\\frac{1}{2} - \\alpha}}\n$$"
        },
        {
            "introduction": "尽管截断SVD在Frobenius范数下提供了最优的低秩近似，但其性能可能会因数据中的异常值而严重下降。本实践旨在揭示这一关键弱点，并引入使用 $\\ell_1$ 范数目标的鲁棒近似概念，这是现代数据分析的基石 。你将定量地比较两种方法的“崩溃点”，从而揭示为何在处理现实世界中的不完美数据时，鲁棒的替代方法至关重要。",
            "id": "3557735",
            "problem": "考虑下列为显式定义的一族数据矩阵，其设计旨在孤立地研究单个大数值离群点对低秩近似的影响。对于整数 $n \\geq 3$ 和参数 $M \\geq 0$，定义矩阵 $A(M) \\in \\mathbb{R}^{2 \\times n}$ 如下\n$$\nA(M) \\;=\\; \\begin{bmatrix}\n0  0  \\cdots  0  M \\\\\n1  1  \\cdots  1  0\n\\end{bmatrix},\n$$\n也就是说，其前 $n-1$ 列等于内点向量 $e_{2} = \\left[\\begin{smallmatrix} 0 \\\\ 1 \\end{smallmatrix}\\right]$，最后一列是离群点 $M e_{1} = \\left[\\begin{smallmatrix} M \\\\ 0 \\end{smallmatrix}\\right]$。在没有离群点的情况下，“真实”的潜在低秩结构是秩为 $1$ 的矩阵 $L^{\\star} = e_{2} \\mathbf{1}^{\\top}$，其中 $\\mathbf{1} \\in \\mathbb{R}^{n-1}$ 是全1向量。\n\n你需要从第一性原理出发，分析两种秩-1近似策略：\n\n1. 截断奇异值分解 (SVD)：根据 Eckart–Young–Mirsky 定理，在弗罗贝尼乌斯范数意义下的最佳秩-1近似由 $A(M)$ 的首个奇异三元组给出。顶层左奇异向量是 $A(M) A(M)^{\\top}$ 的主特征向量。\n\n2. 一种基于 $\\ell_{1}$ 范数的秩-1近似：在秩-1约束条件下，最小化逐元素的绝对偏差，\n$$\n\\min_{u \\in \\mathbb{R}^{2},\\, v \\in \\mathbb{R}^{n}} \\;\\sum_{i=1}^{2} \\sum_{j=1}^{n} \\left| A(M)_{ij} - (u v^{\\top})_{ij} \\right| \\quad \\text{subject to } \\|u\\|_{2} = 1.\n$$\n这是一种稳健的、逐元素的 $\\ell_{1}$ 损失准则。\n\n从奇异值分解 (SVD) 和 $\\ell_1$ 目标的定义出发，并且仅使用基本的线性代数知识（例如奇异向量与 $A(M) A(M)^{\\top}$ 的特征结构之间的关系），回答以下问题：\n\n(a) 推导 $A(M)$ 的主左奇异向量，将其表示为 $M$ 和 $n$ 的函数，并计算当 $M \\to \\infty$ 时，该向量与基准方向 $e_2$ 之间主角的余弦值的极限。\n\n(b) 确定精确的数值阈值 $M_{2}(n)$，在该阈值下，截断SVD的顶层左奇异向量从 $e_2$ 切换到 $e_1$。\n\n(c) 对于基于 $\\ell_{1}$ 的问题，在分别对 $v \\in \\mathbb{R}^{n}$ 进行优化后，计算由两个候选方向 $u = e_{2}$ (拟合内点) 和 $u = e_{1}$ (拟合离群点) 所达到的最优目标值。根据这些结果，确定精确的数值阈值 $M_{1}(n)$，在该阈值下，基于 $\\ell_{1}$ 的估计器从 $e_2$ 切换到 $e_1$。\n\n以单个行向量的形式提供你的最终答案，其中包含按此顺序排列的三个条目：\n$$\n\\left(\\lim_{M \\to \\infty} \\cos \\theta(M),\\; M_{2}(n),\\; M_{1}(n)\\right),\n$$\n其中 $\\theta(M)$ 是 SVD 的顶层左奇异向量与 $e_2$ 之间的夹角。无需四舍五入。请以仅含 $n$ 的闭合形式表示你的答案。",
            "solution": "用户希望分析两种不同的秩-1近似方法，用于处理一个包含单个大离群点的矩阵 $A(M)$。分析必须从第一性原理出发。问题分为三个部分：(a) 分析基于奇异值分解 (SVD) 的近似，(b) 寻找SVD方法的击穿阈值，(c) 寻找基于 $\\ell_1$ 范数的稳健方法的击穿阈值。\n\n首先，我们确定矩阵 $A(M) \\in \\mathbb{R}^{2 \\times n}$ 的结构。其前 $n-1$ 列是 $e_{2} = \\left[\\begin{smallmatrix} 0 \\\\ 1 \\end{smallmatrix}\\right]$，最后一列是 $M e_{1} = \\left[\\begin{smallmatrix} M \\\\ 0 \\end{smallmatrix}\\right]$。矩阵的显式形式为：\n$$\nA(M) = \\begin{bmatrix}\n0  0  \\cdots  0  M \\\\\n1  1  \\cdots  1  0\n\\end{bmatrix}\n$$\n基准方向给定为 $e_2$。\n\n(a) 推导 $A(M)$ 的主左奇异向量并计算一个相关极限。\n\n$A(M)$ 的主左奇异向量是矩阵 $A(M)A(M)^{\\top}$ 最大特征值对应的特征向量。我们来计算这个 $2 \\times 2$ 矩阵：\n$$\nA(M)A(M)^{\\top} = \\begin{bmatrix}\n0  0  \\cdots  0  M \\\\\n1  1  \\cdots  1  0\n\\end{bmatrix}\n\\begin{bmatrix}\n0  1 \\\\\n0  1 \\\\\n\\vdots  \\vdots \\\\\n0  1 \\\\\nM  0\n\\end{bmatrix}\n$$\n所得矩阵的元素如下：\n(1,1) 元素是 $A(M)$ 的第一行与自身的点积：$(n-1) \\cdot 0^2 + M^2 = M^2$。\n(2,2) 元素是 $A(M)$ 的第二行与自身的点积：$(n-1) \\cdot 1^2 + 0^2 = n-1$。\n非对角线元素是第一行和第二行的点积：$(n-1) \\cdot (0 \\cdot 1) + (M \\cdot 0) = 0$。\n因此，该矩阵是对角矩阵：\n$$\nA(M)A(M)^{\\top} = \\begin{bmatrix}\nM^2  0 \\\\\n0  n-1\n\\end{bmatrix}\n$$\n对角矩阵的特征值是其对角线元素：$\\lambda_a = M^2$ 和 $\\lambda_b = n-1$。对应的特征向量分别是标准基向量 $e_1 = \\left[\\begin{smallmatrix} 1 \\\\ 0 \\end{smallmatrix}\\right]$ 和 $e_2 = \\left[\\begin{smallmatrix} 0 \\\\ 1 \\end{smallmatrix}\\right]$。\n\n主左奇异向量，我们记为 $u_{SVD}(M)$，是与最大特征值相关联的特征向量。我们必须比较 $M^2$ 和 $n-1$：\n\\begin{itemize}\n    \\item 如果 $M^2  n-1$ (即 $M  \\sqrt{n-1}$ 因为 $M \\geq 0$)，最大特征值是 $n-1$。主左奇异向量是 $u_{SVD}(M) = e_2$。\n    \\item 如果 $M^2 > n-1$ (即 $M > \\sqrt{n-1}$)，最大特征值是 $M^2$。主左奇异向量是 $u_{SVD}(M) = e_1$。\n    \\item 如果 $M^2 = n-1$，特征值相等，该特征值对应的特征空间是整个 $\\mathbb{R}^2$。任何单位向量都是主左奇异向量。\n\\end{itemize}\n所以，主左奇异向量作为 $M$ 和 $n$ 的函数是：\n$$\nu_{SVD}(M) = \\begin{cases}\ne_2  \\text{如果 } M  \\sqrt{n-1} \\\\\ne_1  \\text{如果 } M > \\sqrt{n-1}\n\\end{cases}\n$$\n问题要求当 $M \\to \\infty$ 时，$u_{SVD}(M)$ 与基准方向 $e_2$ 之间夹角 $\\theta(M)$ 的余弦值的极限。两个单位向量之间夹角的余弦是它们的点积。\n当 $M \\to \\infty$ 时，我们处于 $M > \\sqrt{n-1}$ 的情况。对于任何这样的 $M$，$u_{SVD}(M) = e_1$。因此，\n$$\n\\cos(\\theta(M)) = u_{SVD}(M) \\cdot e_2 = e_1 \\cdot e_2 = \\left[\\begin{smallmatrix} 1 \\\\ 0 \\end{smallmatrix}\\right] \\cdot \\left[\\begin{smallmatrix} 0 \\\\ 1 \\end{smallmatrix}\\right] = 0\n$$\n因此极限是：\n$$\n\\lim_{M \\to \\infty} \\cos(\\theta(M)) = \\lim_{M \\to \\infty} 0 = 0\n$$\n\n(b) 确定 SVD 估计器的阈值 $M_2(n)$。\n\nSVD 估计器是主左奇异向量。当 $A(M)A(M)^{\\top}$ 的主导特征值改变时，它从基准方向 $e_2$ 切换到离群点方向 $e_1$。如上所述，这发生在 $M^2 = n-1$ 时。由于 $M \\geq 0$，阈值是 $M = \\sqrt{n-1}$。\n因此，基于 SVD 的近似的切换阈值是：\n$$\nM_2(n) = \\sqrt{n-1}\n$$\n\n(c) 确定基于 $\\ell_1$ 的估计器的阈值 $M_1(n)$。\n\n问题是在 $\\|u\\|_2 = 1$ 的约束下最小化 $J(u,v) = \\|A(M) - uv^{\\top}\\|_{\\ell_1} = \\sum_{i,j} |A_{ij} - (uv^{\\top})_{ij}|$。我们被要求评估两个候选方向 $u=e_2$ 和 $u=e_1$ 的最小代价，并找出何时一个优于另一个。\n\n情况 1：$u = e_2 = \\left[\\begin{smallmatrix} 0 \\\\ 1 \\end{smallmatrix}\\right]$。\n近似为 $uv^{\\top} = e_2 v^{\\top} = \\begin{bmatrix} 0  0  \\cdots  0 \\\\ v_1  v_2  \\cdots  v_n \\end{bmatrix}$。残差矩阵是：\n$$\nA(M) - e_2 v^{\\top} = \\begin{bmatrix}\n0  0  \\cdots  0  M \\\\\n1-v_1  1-v_2  \\cdots  1-v_{n-1}  0-v_n\n\\end{bmatrix}\n$$\n$\\ell_1$ 误差是 $J(e_2, v) = |M| + \\sum_{j=1}^{n-1} |1-v_j| + |v_n|$。\n为了在 $v \\in \\mathbb{R}^n$ 上最小化这个代价，我们可以独立地最小化每一项。当 $v_j=1$ (对于 $j=1, \\dots, n-1$) 且 $v_n=0$ 时达到最小值。这是因为一组数的中位数可以最小化绝对差之和。$\\{1, 1, \\dots, 1\\}$ 的中位数是 $1$，$\\{0\\}$ 的中位数是 $0$。\n对于 $u=e_2$ 的最小代价是：\n$$\nJ_2 = \\min_v J(e_2, v) = M + \\sum_{j=1}^{n-1} |1-1| + |0| = M\n$$\n(注意：给定 $M \\geq 0$)。\n\n情况 2：$u = e_1 = \\left[\\begin{smallmatrix} 1 \\\\ 0 \\end{smallmatrix}\\right]$。\n近似为 $uv^{\\top} = e_1 v^{\\top} = \\begin{bmatrix} v_1  v_2  \\cdots  v_n \\\\ 0  0  \\cdots  0 \\end{bmatrix}$。残差矩阵是：\n$$\nA(M) - e_1 v^{\\top} = \\begin{bmatrix}\n0-v_1  0-v_2  \\cdots  0-v_{n-1}  M-v_n \\\\\n1  1  \\cdots  1  0\n\\end{bmatrix}\n$$\n$\\ell_1$ 误差是 $J(e_1, v) = \\left(\\sum_{j=1}^{n-1} |-v_j| + |M-v_n|\\right) + \\left(\\sum_{j=1}^{n-1} |1| + |0|\\right)$。\n$J(e_1, v) = \\sum_{j=1}^{n-1} |v_j| + |M-v_n| + (n-1)$。\n为了在 $v$ 上最小化这个代价，我们再次独立地最小化各项。当 $v_j=0$ (对于 $j=1, \\dots, n-1$) 且 $v_n=M$ 时达到最小值。\n对于 $u=e_1$ 的最小代价是：\n$$\nJ_1 = \\min_v J(e_1, v) = \\sum_{j=1}^{n-1} |0| + |M-M| + (n-1) = n-1\n$$\n\n基于 $\\ell_1$ 的估计器将选择导致更低最小代价的方向 $u$。从 $e_2$ 到 $e_1$ 的切换发生在 $J_1$ 小于 $J_2$ 时。阈值是代价相等的地方：\n$$\nJ_1 = J_2 \\implies n-1 = M\n$$\n如果 $M  n-1$，那么 $J_2  J_1$，估计器选择 $u=e_2$。\n如果 $M > n-1$，那么 $J_1  J_2$，估计器选择 $u=e_1$。\n因此，切换阈值是：\n$$\nM_1(n) = n-1\n$$\n\n最终答案是包含按顺序排列的三个所求量的行向量：\n1. $\\lim_{M \\to \\infty} \\cos \\theta(M) = 0$\n2. $M_2(n) = \\sqrt{n-1}$\n3. $M_1(n) = n-1$\n\n基于 SVD 的方法对离群点的平方大小 ($M^2$) 敏感，而基于 $\\ell_1$ 的方法对线性大小 ($M$) 敏感。这使得 $\\ell_1$ 方法显著更稳健，因为对于 $n>2$，其击穿阈值 $M_1(n)=n-1$ 远大于 SVD 的击穿阈值 $M_2(n)=\\sqrt{n-1}$。\n\n最终答案组合：$(\\lim_{M \\to \\infty} \\cos \\theta(M), M_2(n), M_1(n)) = (0, \\sqrt{n-1}, n-1)$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0  \\sqrt{n-1}  n-1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "研究低秩结构的主要动机之一是其带来的巨大计算效率。本练习为此原理提供了一个具体的例子，展示了如何利用矩阵的低秩分解，以远高于常规方法的效率计算矩阵的高次幂 。掌握这项技术是理解在机器学习和科学计算等领域中，如何利用低秩模型来扩展复杂计算的关键。",
            "id": "3249560",
            "problem": "设 $A \\in \\mathbb{R}^{d \\times d}$ 是一个具有低秩分解 $A = U V^{T}$ 的矩阵，其中 $U \\in \\mathbb{R}^{d \\times r}$ 和 $V \\in \\mathbb{R}^{d \\times r}$ 且 $r \\ll d$。考虑利用矩阵求幂的原理和其低秩结构，计算一个正整数 $n$ 的矩阵幂 $A^{n}$。仅使用矩阵乘法的基本定义和矩阵乘积的结合律来推断 $A^{n}$ 的结构，并且不要直接展开 $A$ 的稠密幂。\n\n对于一个具体实例，设 $d = 4$，$r = 2$，且\n$$\nU = \\begin{pmatrix}\n1  0 \\\\\n1  0 \\\\\n0  1 \\\\\n0  1\n\\end{pmatrix},\n\\qquad\nV = \\begin{pmatrix}\n2  0 \\\\\n0  0 \\\\\n0  3 \\\\\n0  0\n\\end{pmatrix}.\n$$\n通过利用低秩结构而不形成稠密的中间幂，以 $n$ 的闭式表达式（其中 $n \\in \\mathbb{N}$）精确计算 $A^{n}$。在您的推理中，请在 $r \\ll d$ 的假设下，推导出一个算法路径，其渐进时间复杂度严格优于 $\\mathcal{O}(d^{3} \\log n)$。最终答案必须是 $A^{n}$ 的显式 $4 \\times 4$ 矩阵，其元素用 $n$ 表示（无需四舍五入）。",
            "solution": "该问题要求计算一个具有特定低秩结构 $A = U V^{T}$ 的矩阵 $A \\in \\mathbb{R}^{d \\times d}$ 的 $n$ 次幂，其中 $U, V \\in \\mathbb{R}^{d \\times r}$ 且 $r \\ll d$。我们必须为一个具体实例推导出 $A^n$ 的闭式表达式，并展示一种在计算上比处理稠密矩阵的标准方法更高效的算法。\n\n首先，我们来确定 $A^n$ 的一般形式。给定 $A = U V^{T}$，我们可以通过重复应用此定义并使用矩阵乘法的结合律来表示 $A$ 的幂。\n对于 $n=2$，我们有：\n$$A^{2} = A A = (U V^{T})(U V^{T})$$\n根据结合律，我们可以重新组合这些项：\n$$A^{2} = U (V^{T} U) V^{T}$$\n注意到乘积 $V^{T} U$ 的结果是一个 $r \\times r$ 矩阵，由于 $r \\ll d$，它比原始矩阵 $A$ 小得多。我们将这个内部矩阵定义为 $M = V^{T} U$。\n因此，$A^{2} = U M V^{T}$。\n\n我们继续计算 $n=3$ 的情况：\n$$A^{3} = A^{2} A = (U M V^{T})(U V^{T})$$\n再次使用结合律：\n$$A^{3} = U M (V^{T} U) V^{T} = U M M V^{T} = U M^{2} V^{T}$$\n\n通过归纳法，我们可以推广这个模式。假设对于某个整数 $k \\ge 1$，$A^{k} = U M^{k-1} V^{T}$ 成立。那么对于 $k+1$：\n$$A^{k+1} = A^{k} A = (U M^{k-1} V^{T})(U V^{T}) = U M^{k-1} (V^{T} U) V^{T} = U M^{k-1} M V^{T} = U M^{k} V^{T}$$\n$n=1$ 的基础情况是 $A^1 = U M^{1-1} V^T = U M^0 V^T = U I_r V^T = U V^T = A$，这是正确的。因此，该公式对所有正整数 $n \\in \\mathbb{N}$ 成立：\n$$A^{n} = U (V^{T} U)^{n-1} V^{T}$$\n\n这种表示法提供了显著的计算优势。对稠密的 $d \\times d$ 矩阵 $A$ 使用二进制求幂（或称快速幂）计算 $A^n$ 的朴素算法将涉及大约 $\\log_{2}(n)$ 次 $d \\times d$ 规模的矩阵乘法。每次这样的乘法耗时为 $\\mathcal{O}(d^3)$，导致总复杂度为 $\\mathcal{O}(d^3 \\log n)$。\n\n低秩方法的步骤如下：\n1. 计算 $r \\times r$ 矩阵 $M = V^{T} U$。由于 $V^T$ 是 $r \\times d$ 矩阵，$U$ 是 $d \\times r$ 矩阵，此步骤的成本是 $\\mathcal{O}(r d r) = \\mathcal{O}(d r^2)$。\n2. 计算 $r \\times r$ 矩阵 $M$ 的 $(n-1)$ 次幂。使用二进制求幂，这需要 $\\mathcal{O}(\\log(n-1))$ 次 $r \\times r$ 矩阵的乘法。每次这样的乘法耗时为 $\\mathcal{O}(r^3)$，因此此步骤的成本为 $\\mathcal{O}(r^3 \\log n)$。\n3. 计算最终乘积 $A^n = U (M^{n-1}) V^{T}$。这可以通过先计算 $U M^{n-1}$（一个 $(d \\times r)$ 矩阵与一个 $(r \\times r)$ 矩阵的乘法，成本为 $\\mathcal{O}(d r^2)$），然后将结果与 $V^T$ 相乘（一个 $(d \\times r)$ 矩阵与一个 $(r \\times d)$ 矩阵的乘法，成本为 $\\mathcal{O}(d^2 r)$）来完成。此步骤的总成本为 $\\mathcal{O}(d r^2 + d^2 r)$。\n\n低秩算法的总复杂度为 $\\mathcal{O}(d r^2 + d^2 r + r^3 \\log n)$。由于 $r \\ll d$，主导项是 $\\mathcal{O}(d^2 r)$。这严格优于稠密矩阵方法的 $\\mathcal{O}(d^3 \\log n)$ 复杂度，符合要求。\n\n现在我们将此方法应用于所提供的具体实例：$d=4$，$r=2$，其中\n$$U = \\begin{pmatrix} 1  0 \\\\ 1  0 \\\\ 0  1 \\\\ 0  1 \\end{pmatrix}, \\qquad V = \\begin{pmatrix} 2  0 \\\\ 0  0 \\\\ 0  3 \\\\ 0  0 \\end{pmatrix}$$\n首先，我们计算 $V$ 的转置：\n$$V^{T} = \\begin{pmatrix} 2  0  0  0 \\\\ 0  0  3  0 \\end{pmatrix}$$\n接下来，我们计算内部矩阵 $M = V^{T} U$：\n$$M = \\begin{pmatrix} 2  0  0  0 \\\\ 0  0  3  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 1  0 \\\\ 0  1 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} (2)(1)  (2)(0) \\\\ (3)(0)  (3)(1) \\end{pmatrix} = \\begin{pmatrix} 2  0 \\\\ 0  3 \\end{pmatrix}$$\n矩阵 $M$ 是一个对角矩阵。对角矩阵的 $(n-1)$ 次幂就是其对角线元素取 $(n-1)$ 次幂后形成的矩阵：\n$$M^{n-1} = \\begin{pmatrix} 2^{n-1}  0 \\\\ 0  3^{n-1} \\end{pmatrix}$$\n这对所有 $n \\ge 1$ 成立。\n\n最后，我们计算 $A^n = U M^{n-1} V^{T}$：\n$$A^{n} = \\begin{pmatrix} 1  0 \\\\ 1  0 \\\\ 0  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 2^{n-1}  0 \\\\ 0  3^{n-1} \\end{pmatrix} \\begin{pmatrix} 2  0  0  0 \\\\ 0  0  3  0 \\end{pmatrix}$$\n我们首先将 $U$ 乘以 $M^{n-1}$：\n$$U M^{n-1} = \\begin{pmatrix} 1  0 \\\\ 1  0 \\\\ 0  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 2^{n-1}  0 \\\\ 0  3^{n-1} \\end{pmatrix} = \\begin{pmatrix} 2^{n-1}  0 \\\\ 2^{n-1}  0 \\\\ 0  3^{n-1} \\\\ 0  3^{n-1} \\end{pmatrix}$$\n然后我们将这个结果乘以 $V^{T}$：\n$$A^{n} = (U M^{n-1}) V^{T} = \\begin{pmatrix} 2^{n-1}  0 \\\\ 2^{n-1}  0 \\\\ 0  3^{n-1} \\\\ 0  3^{n-1} \\end{pmatrix} \\begin{pmatrix} 2  0  0  0 \\\\ 0  0  3  0 \\end{pmatrix}$$\n执行最后的矩阵乘法：\n$$A^{n} = \\begin{pmatrix}\n(2^{n-1})(2)  (2^{n-1})(0)  (0)(0)  (0)(0) \\\\\n(2^{n-1})(2)  (2^{n-1})(0)  (0)(0)  (0)(0) \\\\\n(0)(2)  (0)(0)  (3^{n-1})(3)  (3^{n-1})(0) \\\\\n(0)(2)  (0)(0)  (3^{n-1})(3)  (3^{n-1})(0)\n\\end{pmatrix}$$\n简化各项得到 $A^n$ 的最终闭式表达式：\n$$A^{n} = \\begin{pmatrix}\n2^{n}  0  0  0 \\\\\n2^{n}  0  0  0 \\\\\n0  0  3^{n}  0 \\\\\n0  0  3^{n}  0\n\\end{pmatrix}$$\n这就是所要求的 $A^n$ 作为正整数 $n$ 的函数的表达式。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2^{n}  0  0  0 \\\\\n2^{n}  0  0  0 \\\\\n0  0  3^{n}  0 \\\\\n0  0  3^{n}  0\n\\end{pmatrix}\n}\n$$"
        }
    ]
}