{
    "hands_on_practices": [
        {
            "introduction": "The Bauer-Fike theorem provides an upper bound on eigenvalue perturbation. A natural first question is whether this bound is tight. This exercise  demonstrates that for the well-behaved class of normal matrices, where the eigenvector matrix is perfectly conditioned ($\\kappa_2(V)=1$), the bound can be achieved exactly, confirming its sharpness in this ideal scenario.",
            "id": "3585033",
            "problem": "Let $n \\geq 2$ and let $A \\in \\mathbb{C}^{n \\times n}$ be a normal matrix, so there exists a unitary matrix $U \\in \\mathbb{C}^{n \\times n}$ and a diagonal matrix $\\Lambda = \\operatorname{diag}(\\lambda_{1},\\ldots,\\lambda_{n})$ such that $A = U \\Lambda U^{*}$. Fix an index $k \\in \\{1,\\ldots,n\\}$ and a real scalar $t > 0$. Construct a perturbation $E \\in \\mathbb{C}^{n \\times n}$ that is rank one and aligned with the $k$-th eigenvector of $A$ so that the spectral norm satisfies $\\|E\\|_{2} = t$, and verify from first principles that the spectrum of $A + E$ is obtained by shifting exactly one eigenvalue of $A$ by a real amount of magnitude $t$ while leaving the remaining eigenvalues unchanged. Conclude that the radius prescribed by the Bauer-Fike theorem for $A$ (the “Bauer-Fike radius” when $A$ is normal) is achieved exactly by an eigenvalue shift for your construction.\n\nProvide the exact value of the achieved shift magnitude as a closed-form expression in terms of $t$. No numerical rounding is required, and no units are involved.",
            "solution": "The problem statement is parsed and validated as being scientifically grounded, well-posed, and complete. We proceed with the solution.\n\nLet $A \\in \\mathbb{C}^{n \\times n}$ be a normal matrix with $n \\geq 2$. By the spectral theorem for normal matrices, there exists a unitary matrix $U \\in \\mathbb{C}^{n \\times n}$ and a diagonal matrix $\\Lambda = \\operatorname{diag}(\\lambda_{1},\\ldots,\\lambda_{n})$ such that $A = U \\Lambda U^{*}$. The columns of $U$, denoted by $u_1, u_2, \\ldots, u_n$, form an orthonormal basis of eigenvectors for $A$. That is, $A u_j = \\lambda_j u_j$ for each $j \\in \\{1,\\ldots,n\\}$, and the orthonormality condition is $u_i^* u_j = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta.\n\nThe problem requires the construction of a rank-one perturbation $E \\in \\mathbb{C}^{n \\times n}$ that is \"aligned with the $k$-th eigenvector of $A$\" for a fixed index $k \\in \\{1,\\ldots,n\\}$, such that its spectral norm is $\\|E\\|_{2} = t$ for a given real scalar $t > 0$.\n\nWe construct the matrix $E$. The $k$-th eigenvector of $A$ is $u_k$. A rank-one matrix that is aligned with $u_k$ can be constructed as an outer product involving $u_k$. The most direct construction that is also Hermitian is of the form $E = \\alpha u_k u_k^*$ for some scalar $\\alpha \\in \\mathbb{C}$.\n\nWe verify the properties of this constructed matrix $E$:\n1.  **Rank**: Since $u_k$ is a non-zero vector (as it is a column of a unitary matrix), the matrix $E = \\alpha u_k u_k^*$ has rank one, provided $\\alpha \\neq 0$.\n2.  **Spectral Norm**: We must satisfy the condition $\\|E\\|_2 = t$. The spectral norm of $E$ is given by\n    $$ \\|E\\|_2 = \\|\\alpha u_k u_k^*\\|_2 = |\\alpha| \\|u_k u_k^*\\|_2 $$\n    The matrix $P_k = u_k u_k^*$ is the orthogonal projector onto the one-dimensional subspace spanned by $u_k$. Since $u_k$ is a unit vector ($u_k^* u_k = 1$), $P_k$ is a Hermitian and idempotent matrix ($P_k^2 = P_k$). Its eigenvalues are $1$ (with eigenvector $u_k$) and $0$ (with multiplicity $n-1$, corresponding to the subspace orthogonal to $u_k$). The singular values of a positive semidefinite Hermitian matrix are its eigenvalues. Thus, the largest singular value of $P_k$ is $1$, which means $\\|P_k\\|_2 = 1$.\n    Therefore, we have $\\|E\\|_2 = |\\alpha|$. The given condition is $\\|E\\|_2 = t$, which implies $|\\alpha| = t$. The problem suggests the eigenvalue shift is a real amount. A simple choice for $\\alpha$ that satisfies this is to take $\\alpha$ to be real. As we are given $t>0$, we can choose $\\alpha = t$.\n    Thus, we define the perturbation matrix as $E = t u_k u_k^*$. This matrix is rank one and satisfies $\\|E\\|_2 = t$.\n\nNext, we must verify from first principles the effect of this perturbation on the spectrum of $A$. Let the perturbed matrix be $A' = A + E = A + t u_k u_k^*$. We will find the eigenvalues of $A'$ by testing its action on the eigenvectors of $A$.\n\nFor any eigenvector $u_j$ of $A$ with $j \\neq k$:\n$$ A' u_j = (A + t u_k u_k^*) u_j = A u_j + t u_k (u_k^* u_j) $$\nSince the set $\\{u_1, \\ldots, u_n\\}$ is orthonormal, the inner product $u_k^* u_j = 0$ for $j \\neq k$. Consequently, the second term vanishes:\n$$ A' u_j = A u_j = \\lambda_j u_j $$\nThis shows that for each $j \\in \\{1,\\ldots,n\\} \\setminus \\{k\\}$, $\\lambda_j$ is an eigenvalue of $A'$, with the same corresponding eigenvector $u_j$. This accounts for $n-1$ eigenvalues of $A'$.\n\nNow, we consider the eigenvector $u_k$:\n$$ A' u_k = (A + t u_k u_k^*) u_k = A u_k + t u_k (u_k^* u_k) $$\nSince $u_k$ is a unit vector, $u_k^* u_k = \\|u_k\\|_2^2 = 1$. The expression simplifies to:\n$$ A' u_k = A u_k + t u_k = \\lambda_k u_k + t u_k = (\\lambda_k + t) u_k $$\nThis shows that $(\\lambda_k + t)$ is an eigenvalue of $A'$, with $u_k$ as the corresponding eigenvector.\n\nIn summary, the spectrum of the perturbed matrix $A+E$ is precisely\n$$ \\sigma(A+E) = \\{\\lambda_1, \\ldots, \\lambda_{k-1}, \\lambda_k + t, \\lambda_{k+1}, \\ldots, \\lambda_n\\} $$\nExactly one eigenvalue of $A$, namely $\\lambda_k$, has been shifted by a real amount $t$, while the other $n-1$ eigenvalues remain unchanged. The magnitude of this shift is $|t|$, which is equal to $t$ because we are given $t > 0$.\n\nFinally, we relate this result to the Bauer-Fike theorem. For a diagonalizable matrix $A=V\\Lambda V^{-1}$, the theorem states that for any eigenvalue $\\mu$ of the perturbed matrix $A+E$, there exists an eigenvalue $\\lambda$ of $A$ such that $|\\lambda - \\mu| \\le \\kappa_2(V) \\|E\\|_2$, where $\\kappa_2(V)$ is the spectral condition number of $V$. For a normal matrix $A$, the matrix of eigenvectors $V$ can be chosen to be unitary, i.e., $V=U$. For a unitary matrix, $\\kappa_2(U) = \\|U\\|_2 \\|U^{-1}\\|_2 = 1 \\cdot 1 = 1$. The theorem thus simplifies to: for any eigenvalue $\\mu$ of $A+E$, there exists an eigenvalue $\\lambda$ of $A$ such that\n$$ |\\lambda - \\mu| \\le \\|E\\|_2 $$\nIn our case, $\\|E\\|_2 = t$, so the theorem guarantees that for any $\\mu \\in \\sigma(A+E)$, we have $\\min_{\\lambda_j \\in \\sigma(A)} |\\lambda_j - \\mu| \\le t$. The quantity $t$ is the \"Bauer-Fike radius\".\n\nOur constructed perturbation $E = t u_k u_k^*$ results in a new eigenvalue $\\mu' = \\lambda_k + t$. We now check the distance from this new eigenvalue to the original spectrum of $A$:\n$$ \\min_{\\lambda_j \\in \\sigma(A)} |\\lambda_j - \\mu'| = \\min_{\\lambda_j \\in \\sigma(A)} |\\lambda_j - (\\lambda_k+t)| $$\nThe minimum value is clearly achieved when we select $\\lambda_j = \\lambda_k$, yielding a distance of\n$$ |\\lambda_k - (\\lambda_k+t)| = |-t| = t $$\nThis distance is exactly equal to the upper bound $t = \\|E\\|_2$ provided by the Bauer-Fike theorem. This construction thus demonstrates that the bound for normal matrices is sharp, as it is achieved exactly. The magnitude of the shift for the eigenvalue $\\lambda_k$ is $t$.\n\nThe problem asks for the exact value of the achieved shift magnitude. The shift itself is the difference between the new eigenvalue and the old one, which is $(\\lambda_k + t) - \\lambda_k = t$. The magnitude of this shift is $|t|$. Since we are given $t>0$, the magnitude is simply $t$.",
            "answer": "$$\n\\boxed{t}\n$$"
        },
        {
            "introduction": "While normal matrices are well-behaved, the real power of the Bauer-Fike theorem is in diagnosing the potential instability of non-normal matrices. This practice  explores a nearly defective matrix, where eigenvectors are almost parallel, to provide a concrete numerical example of how a large eigenvector condition number, $\\kappa_2(V)$, can amplify a tiny perturbation into a large eigenvalue shift.",
            "id": "3585025",
            "problem": "Let $A \\in \\mathbb{C}^{2 \\times 2}$ be the matrix $A = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 + \\delta \\end{pmatrix}$ with a small positive parameter $\\delta$, and consider the rank-$1$ perturbation $E = \\begin{pmatrix} 0 & 0 \\\\ \\varepsilon & 0 \\end{pmatrix}$ with a small positive parameter $\\varepsilon$. The matrix $A$ is diagonalizable because it has two distinct eigenvalues $1$ and $1 + \\delta$, yet it is nearly defective in the sense that its eigenvectors become nearly linearly dependent as $\\delta \\to 0^{+}$. Work in the induced operator $2$-norm (the spectral norm).\n\nTasks:\n- Using only the spectral properties of a diagonalizable matrix and norm submultiplicativity, derive from first principles a bound on how far the eigenvalues of $A + E$ can move from those of $A$ in terms of the condition number $\\kappa_{2}(V) = \\|V\\|_{2} \\,\\|V^{-1}\\|_{2}$ of the eigenvector matrix $V$ for $A$ and the perturbation size $\\|E\\|_{2}$.\n- Construct the eigenvector matrix $V$ for $A$ explicitly, and compute $\\kappa_{2}(V)$ exactly in terms of $\\delta$ via the Singular Value Decomposition (SVD; Singular Value Decomposition).\n- Compute the exact eigenvalues of $A + E$ and the exact shift of each eigenvalue of $A$ under the perturbation $E$ by solving the characteristic equation of a $2 \\times 2$ matrix.\n- Specialize to $\\delta = 10^{-8}$ and $\\varepsilon = 10^{-6}$, and evaluate numerically the ratio $R$ defined as\n$$\nR = \\frac{\\text{predicted upper bound on eigenvalue movement from the diagonalization-based norm argument}}{\\text{actual eigenvalue shift computed from the exact $2 \\times 2$ formula}}.\n$$\n\nReturn $R$ as a pure number. Round your final answer to four significant figures. No units are to be reported.",
            "solution": "The problem is validated as scientifically grounded, well-posed, objective, and complete. It is a standard problem in numerical linear algebra concerning eigenvalue perturbation theory. We may proceed with the solution.\n\nThe solution is structured into four parts as requested by the problem statement.\n\n**Part 1: Derivation of the Eigenvalue Perturbation Bound**\n\nLet $A \\in \\mathbb{C}^{n \\times n}$ be a diagonalizable matrix. Then there exists an invertible matrix $V$, whose columns are the eigenvectors of $A$, and a diagonal matrix $\\Lambda$, whose diagonal entries are the corresponding eigenvalues $\\lambda_1, \\dots, \\lambda_n$, such that $A = V \\Lambda V^{-1}$.\n\nLet $E$ be a perturbation matrix, and let $\\mu$ be an eigenvalue of the perturbed matrix $A+E$ with a corresponding eigenvector $x \\neq 0$. The defining relation is:\n$$(A+E)x = \\mu x$$\nThis can be rewritten as:\n$$(\\mu I - A)x = Ex$$\nIf $\\mu$ is an eigenvalue of $A$, i.e., $\\mu \\in \\sigma(A)$, then the distance $\\min_{\\lambda \\in \\sigma(A)} |\\mu-\\lambda| = 0$. The bound we seek to derive, being non-negative, will hold trivially.\n\nAssume $\\mu$ is not an eigenvalue of $A$. In this case, the matrix $\\mu I - A$ is invertible. We can thus write:\n$$x = (\\mu I - A)^{-1} Ex$$\nWe substitute the diagonalization of $A$ into the expression for the inverse:\n$$\\mu I - A = \\mu I - V \\Lambda V^{-1} = V(\\mu I)V^{-1} - V \\Lambda V^{-1} = V(\\mu I - \\Lambda)V^{-1}$$\nThe inverse is:\n$$(\\mu I - A)^{-1} = (V(\\mu I - \\Lambda)V^{-1})^{-1} = V(\\mu I - \\Lambda)^{-1}V^{-1}$$\nSubstituting this back into the equation for $x$:\n$$x = V(\\mu I - \\Lambda)^{-1}V^{-1}Ex$$\nNow, we take the induced operator $2$-norm (spectral norm, denoted $\\|\\cdot\\|_2$) of both sides. Since $x \\neq 0$, $\\|x\\|_2 > 0$.\n$$\\|x\\|_2 = \\|V(\\mu I - \\Lambda)^{-1}V^{-1}Ex\\|_2$$\nUsing the submultiplicative property of matrix norms ($\\|AB\\|_2 \\le \\|A\\|_2 \\|B\\|_2$):\n$$\\|x\\|_2 \\le \\|V\\|_2 \\|(\\mu I - \\Lambda)^{-1}\\|_2 \\|V^{-1}\\|_2 \\|E\\|_2 \\|x\\|_2$$\nSince $\\|x\\|_2 > 0$, we can divide by it:\n$$1 \\le \\|V\\|_2 \\|V^{-1}\\|_2 \\|(\\mu I - \\Lambda)^{-1}\\|_2 \\|E\\|_2$$\nThe condition number of the eigenvector matrix $V$ in the $2$-norm is $\\kappa_2(V) = \\|V\\|_2 \\|V^{-1}\\|_2$. The inequality becomes:\n$$1 \\le \\kappa_2(V) \\|(\\mu I - \\Lambda)^{-1}\\|_2 \\|E\\|_2$$\nThe matrix $\\mu I - \\Lambda$ is a diagonal matrix:\n$$\\mu I - \\Lambda = \\text{diag}(\\mu-\\lambda_1, \\dots, \\mu-\\lambda_n)$$\nIts inverse is also diagonal:\n$$(\\mu I - \\Lambda)^{-1} = \\text{diag}\\left(\\frac{1}{\\mu-\\lambda_1}, \\dots, \\frac{1}{\\mu-\\lambda_n}\\right)$$\nThe $2$-norm of a diagonal matrix is the maximum of the absolute values of its diagonal entries:\n$$\\|(\\mu I - \\Lambda)^{-1}\\|_2 = \\max_{i} \\left|\\frac{1}{\\mu-\\lambda_i}\\right| = \\frac{1}{\\min_{i} |\\mu-\\lambda_i|}$$\nSubstituting this into our main inequality yields:\n$$1 \\le \\kappa_2(V) \\frac{1}{\\min_{i} |\\mu-\\lambda_i|} \\|E\\|_2$$\nRearranging to isolate the eigenvalue distance gives the desired bound, known as the Bauer-Fike theorem:\n$$\\min_{i} |\\mu-\\lambda_i| \\le \\kappa_2(V) \\|E\\|_2$$\nThis provides an upper bound on how far any eigenvalue $\\mu$ of the perturbed matrix $A+E$ can be from the set of eigenvalues of $A$. The maximum possible shift is thus bounded by $\\kappa_2(V) \\|E\\|_2$.\n\n**Part 2: Eigenvector Matrix and its Condition Number**\n\nThe given matrix is $A = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 + \\delta \\end{pmatrix}$. The eigenvalues are the diagonal entries since $A$ is upper triangular: $\\lambda_1 = 1$ and $\\lambda_2 = 1+\\delta$.\n\nFor $\\lambda_1 = 1$: $(A-\\lambda_1 I)v_1 = 0 \\implies \\begin{pmatrix} 0 & 1 \\\\ 0 & \\delta \\end{pmatrix}v_1 = 0$. A suitable eigenvector is $v_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$.\nFor $\\lambda_2 = 1+\\delta$: $(A-\\lambda_2 I)v_2 = 0 \\implies \\begin{pmatrix} -\\delta & 1 \\\\ 0 & 0 \\end{pmatrix}v_2 = 0$. A suitable eigenvector is $v_2 = \\begin{pmatrix} 1 \\\\ \\delta \\end{pmatrix}$.\n\nThe eigenvector matrix $V$ and its inverse $V^{-1}$ are:\n$$V = \\begin{pmatrix} 1 & 1 \\\\ 0 & \\delta \\end{pmatrix}, \\quad V^{-1} = \\frac{1}{\\delta} \\begin{pmatrix} \\delta & -1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & -1/\\delta \\\\ 0 & 1/\\delta \\end{pmatrix}$$\nTo compute $\\kappa_2(V) = \\sigma_{\\max}(V) / \\sigma_{\\min}(V)$, where $\\sigma$ are the singular values of $V$, we find the square roots of the eigenvalues of $V^TV$:\n$$V^TV = \\begin{pmatrix} 1 & 0 \\\\ 1 & \\delta \\end{pmatrix} \\begin{pmatrix} 1 & 1 \\\\ 0 & \\delta \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\\\ 1 & 1+\\delta^2 \\end{pmatrix}$$\nThe characteristic equation is $\\det(V^TV - \\lambda I)=0$:\n$$(1-\\lambda)(1+\\delta^2-\\lambda) - 1 = 0 \\implies \\lambda^2 - (2+\\delta^2)\\lambda + \\delta^2 = 0$$\nThe eigenvalues of $V^TV$ are the squared singular values of $V$:\n$$\\sigma(V)^2 = \\frac{(2+\\delta^2) \\pm \\sqrt{(2+\\delta^2)^2 - 4\\delta^2}}{2} = \\frac{2+\\delta^2 \\pm \\sqrt{4+\\delta^4}}{2}$$\nThe singular values are $\\sigma_{\\max}(V)=\\sqrt{\\frac{2+\\delta^2+\\sqrt{4+\\delta^4}}{2}}$ and $\\sigma_{\\min}(V)=\\sqrt{\\frac{2+\\delta^2-\\sqrt{4+\\delta^4}}{2}}$.\nThe condition number is the ratio:\n$$\\kappa_2(V) = \\frac{\\sigma_{\\max}(V)}{\\sigma_{\\min}(V)} = \\sqrt{\\frac{2+\\delta^2+\\sqrt{4+\\delta^4}}{2+\\delta^2-\\sqrt{4+\\delta^4}}}$$\nRationalizing the denominator:\n$$\\kappa_2(V) = \\sqrt{\\frac{(2+\\delta^2+\\sqrt{4+\\delta^4})^2}{(2+\\delta^2)^2-(4+\\delta^4)}} = \\frac{2+\\delta^2+\\sqrt{4+\\delta^4}}{\\sqrt{4+4\\delta^2+\\delta^4-4-\\delta^4}} = \\frac{2+\\delta^2+\\sqrt{4+\\delta^4}}{2\\delta}$$\nThis is the exact expression for $\\kappa_2(V)$.\n\n**Part 3: Exact Eigenvalues and Shift of the Perturbed Matrix**\n\nThe perturbed matrix is $A+E = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1+\\delta \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ \\varepsilon & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\\\ \\varepsilon & 1+\\delta \\end{pmatrix}$.\nThe characteristic equation $\\det(A+E - \\mu I) = 0$ is:\n$$\\det\\begin{pmatrix} 1-\\mu & 1 \\\\ \\varepsilon & 1+\\delta-\\mu \\end{pmatrix} = (1-\\mu)(1+\\delta-\\mu) - \\varepsilon = 0$$\n$$\\mu^2 - (2+\\delta)\\mu + (1+\\delta-\\varepsilon) = 0$$\nSolving this quadratic equation for the eigenvalues $\\mu$:\n$$\\mu = \\frac{(2+\\delta) \\pm \\sqrt{(2+\\delta)^2 - 4(1+\\delta-\\varepsilon)}}{2} = \\frac{2+\\delta \\pm \\sqrt{4+4\\delta+\\delta^2 - 4-4\\delta+4\\varepsilon}}{2}$$\n$$\\mu = \\frac{2+\\delta \\pm \\sqrt{\\delta^2+4\\varepsilon}}{2}$$\nThe eigenvalues of $A+E$ are $\\mu_1 = \\frac{2+\\delta - \\sqrt{\\delta^2+4\\varepsilon}}{2}$ and $\\mu_2 = \\frac{2+\\delta + \\sqrt{\\delta^2+4\\varepsilon}}{2}$. For small $\\varepsilon$, $\\mu_1 \\approx 1 = \\lambda_1$ and $\\mu_2 \\approx 1+\\delta=\\lambda_2$.\nThe shift for $\\lambda_1$ is $|\\mu_1 - \\lambda_1| = |\\frac{2+\\delta - \\sqrt{\\delta^2+4\\varepsilon}}{2} - 1| = |\\frac{\\delta - \\sqrt{\\delta^2+4\\varepsilon}}{2}| = \\frac{\\sqrt{\\delta^2+4\\varepsilon}-\\delta}{2}$.\nThe shift for $\\lambda_2$ is $|\\mu_2 - \\lambda_2| = |\\frac{2+\\delta + \\sqrt{\\delta^2+4\\varepsilon}}{2} - (1+\\delta)| = |\\frac{\\sqrt{\\delta^2+4\\varepsilon}-\\delta}{2}| = \\frac{\\sqrt{\\delta^2+4\\varepsilon}-\\delta}{2}$.\nThe actual eigenvalue shift is the same for both eigenvalues.\n\n**Part 4: Numerical Evaluation of the Ratio R**\n\nThe ratio $R$ is defined as the predicted upper bound divided by the actual shift.\nThe perturbation matrix is $E = \\begin{pmatrix} 0 & 0 \\\\ \\varepsilon & 0 \\end{pmatrix}$. Its $2$-norm is $\\|E\\|_2 = \\sigma_{\\max}(E) = \\varepsilon$.\nPredicted bound: $\\kappa_2(V) \\|E\\|_2 = \\left(\\frac{2+\\delta^2+\\sqrt{4+\\delta^4}}{2\\delta}\\right)\\varepsilon$.\nActual shift: $\\frac{\\sqrt{\\delta^2+4\\varepsilon}-\\delta}{2}$.\n\nThe ratio is:\n$$R = \\frac{\\left(\\frac{2+\\delta^2+\\sqrt{4+\\delta^4}}{2\\delta}\\right)\\varepsilon}{\\frac{\\sqrt{\\delta^2+4\\varepsilon}-\\delta}{2}} = \\frac{(2+\\delta^2+\\sqrt{4+\\delta^4})\\varepsilon}{\\delta(\\sqrt{\\delta^2+4\\varepsilon}-\\delta)}$$\nTo simplify, we rationalize the denominator by multiplying the numerator and denominator by $(\\sqrt{\\delta^2+4\\varepsilon}+\\delta)$:\n$$R = \\frac{(2+\\delta^2+\\sqrt{4+\\delta^4})\\varepsilon(\\sqrt{\\delta^2+4\\varepsilon}+\\delta)}{\\delta((\\delta^2+4\\varepsilon)-\\delta^2)} = \\frac{(2+\\delta^2+\\sqrt{4+\\delta^4})\\varepsilon(\\sqrt{\\delta^2+4\\varepsilon}+\\delta)}{4\\varepsilon\\delta}$$\nCanceling $\\varepsilon$, we get a simplified exact expression for $R$:\n$$R = \\left(\\frac{2+\\delta^2+\\sqrt{4+\\delta^4}}{2\\delta}\\right) \\left(\\frac{\\sqrt{\\delta^2+4\\varepsilon}+\\delta}{2}\\right) = \\kappa_2(V) \\left(\\frac{\\sqrt{\\delta^2+4\\varepsilon}+\\delta}{2}\\right)$$\nWe now substitute the numerical values $\\delta = 10^{-8}$ and $\\varepsilon = 10^{-6}$.\nThe first term is $\\kappa_2(V)$. Since $\\delta=10^{-8}$ is very small, $\\delta^2=10^{-16}$ and $\\delta^4=10^{-32}$ are negligible compared to the constants.\n$$\\kappa_2(V) = \\frac{2+10^{-16}+\\sqrt{4+10^{-32}}}{2 \\times 10^{-8}} \\approx \\frac{2+2}{2 \\times 10^{-8}} = \\frac{4}{2 \\times 10^{-8}} = 2 \\times 10^8$$\nMore precisely, using the binomial approximation $\\sqrt{4+x} \\approx 2+x/4$ for small $x$:\n$\\kappa_2(V) \\approx \\frac{2+\\delta^2+2+\\delta^4/4}{2\\delta} = \\frac{4+\\delta^2+\\delta^4/4}{2\\delta} = \\frac{2}{\\delta}+\\frac{\\delta}{2}+\\frac{\\delta^3}{8} = 2 \\times 10^8 + 0.5 \\times 10^{-8} + \\dots$\n\nThe second term is $\\frac{\\sqrt{\\delta^2 + 4\\varepsilon} + \\delta}{2}$. We have $\\delta^2 = 10^{-16}$ and $4\\varepsilon = 4 \\times 10^{-6}$. Since $\\delta^2 \\ll 4\\varepsilon$:\n$$\\sqrt{\\delta^2+4\\varepsilon} = \\sqrt{10^{-16} + 4 \\times 10^{-6}} = \\sqrt{4 \\times 10^{-6} (1 + 0.25 \\times 10^{-10})} = 2 \\times 10^{-3} \\sqrt{1+0.25 \\times 10^{-10}}$$\nUsing $\\sqrt{1+y} \\approx 1+y/2$ for small $y$:\n$$\\sqrt{\\delta^2+4\\varepsilon} \\approx 2 \\times 10^{-3} (1 + 0.125 \\times 10^{-10}) = 2 \\times 10^{-3} + 0.25 \\times 10^{-13}$$\nThe second term of $R$ is:\n$$\\frac{(2 \\times 10^{-3} + 0.25 \\times 10^{-13}) + 10^{-8}}{2} \\approx \\frac{2 \\times 10^{-3} + 10^{-8}}{2} = 10^{-3} + 0.5 \\times 10^{-8}$$\nNow, we multiply the two terms to find $R$:\n$$R \\approx (2 \\times 10^8 + 0.5 \\times 10^{-8}) (10^{-3} + 0.5 \\times 10^{-8})$$\n$$R \\approx (2 \\times 10^8)(10^{-3}) + (2 \\times 10^8)(0.5 \\times 10^{-8}) + (0.5 \\times 10^{-8})(10^{-3}) + \\dots$$\n$$R \\approx 2 \\times 10^5 + 1 + 0.5 \\times 10^{-11} + \\dots$$\n$$R \\approx 200001$$\nThe value is $R = 200001.0000025...$. We are asked to round this to four significant figures.\nThe number is $2.00001 \\times 10^5$. The first four significant figures are $2$, $0$, $0$, $0$. The fifth digit is $0$, so we round down (i.e., keep the fourth digit as is).\nThe result, to four significant figures, is $2.000 \\times 10^5$.",
            "answer": "$$\\boxed{2.000 \\times 10^{5}}$$"
        },
        {
            "introduction": "Theoretical understanding is best solidified through computational experiment. This final practice  guides you to write a program that explores the full spectrum of eigenvalue sensitivity, from well-conditioned normal matrices to ill-conditioned non-normal ones. By constructing matrices and designing \"adversarial\" perturbations, you will computationally verify the role of the condition number $\\kappa_2(V)$ and test the sharpness of the Bauer-Fike bound in various scenarios.",
            "id": "3585060",
            "problem": "You are to implement a complete program that constructs, analyzes, and verifies eigenvalue perturbation behavior for diagonalizable matrices using the concept commonly known as the Bauer-Fike radius. All mathematical objects must be treated in purely mathematical terms with explicit definitions. The fundamental base for the derivation and algorithm must start from the following principles and definitions: the definition of a diagonalizable matrix, the spectral (two) norm, the two-norm condition number, and the Singular Value Decomposition (SVD) of a matrix. You must not rely on any unproven shortcut formulas beyond these definitions, and your program must compute all quantities exactly as specified.\n\nDefinitions and tasks:\n1. A square matrix $A \\in \\mathbb{R}^{3 \\times 3}$ is diagonalizable if there exists an invertible matrix $V \\in \\mathbb{R}^{3 \\times 3}$ and a diagonal matrix $\\Lambda \\in \\mathbb{R}^{3 \\times 3}$ such that $A = V \\Lambda V^{-1}$. The diagonal entries of $\\Lambda$ are the eigenvalues of $A$.\n2. The spectral two norm of a matrix $M \\in \\mathbb{R}^{n \\times n}$ is defined as $\\lVert M \\rVert_2 = \\sigma_{\\max}(M)$, where $\\sigma_{\\max}(M)$ is the largest singular value of $M$ and singular values are the nonnegative square roots of the eigenvalues of $M^\\top M$. Use the Singular Value Decomposition (SVD) to compute singular values.\n3. The two-norm condition number of an invertible matrix $V$ is defined as $\\kappa_2(V) = \\lVert V \\rVert_2 \\, \\lVert V^{-1} \\rVert_2$. Equivalently, if $\\sigma_{\\max}(V)$ and $\\sigma_{\\min}(V)$ denote the largest and smallest singular values of $V$, then $\\kappa_2(V) = \\sigma_{\\max}(V)/\\sigma_{\\min}(V)$.\n4. Given a perturbation matrix $E \\in \\mathbb{R}^{3 \\times 3}$ and its spectral two norm $\\lVert E \\rVert_2$, define the Bauer-Fike radius for $V$ and $\\lVert E \\rVert_2$ to be $r_{\\mathrm{BF}}(V, \\lVert E \\rVert_2) \\coloneqq \\kappa_2(V) \\, \\lVert E \\rVert_2$. This quantity is traditionally used to bound possible eigenvalue displacements of $A$ under the perturbation $E$.\n5. For a diagonalizable $A = V \\Lambda V^{-1}$ and a diagonal matrix $\\Delta = \\mathrm{diag}(\\delta_1,\\delta_2,\\delta_3)$, consider the structured perturbation $E = V \\Delta V^{-1}$. In this case one has $A + E = V (\\Lambda + \\Delta) V^{-1}$, so the eigenvalues of $A + E$ are exactly shifted by the diagonal entries of $\\Delta$. For a given $V$ and a chosen diagonal direction $d = (d_1, d_2, d_3)$ with $\\max_i |d_i| = 1$, set $E(d,\\alpha) = V \\,\\mathrm{diag}(\\alpha d_1, \\alpha d_2, \\alpha d_3)\\, V^{-1}$ and scale $\\alpha$ so that $\\lVert E(d,\\alpha) \\rVert_2$ equals the prescribed value. This constructs an adversarial perturbation aligned with a chosen diagonal direction.\n\nYour program must:\n- Construct three diagonalizable matrices $A \\in \\mathbb{R}^{3 \\times 3}$ with specified spectra and deliberately designed diagonalizers $V$ to explore different regimes of the two-norm condition number. You must build $V$ through a fixed-angle rotation in the $x\\text{-}z$ plane followed by anisotropic diagonal scaling to induce large $\\kappa_2(V)$, moderate $\\kappa_2(V)$, and, in a baseline case, $\\kappa_2(V) = 1$ by using an orthogonal diagonalizer. The rotation angle must be specified in radians.\n- For each case, compute $A = V \\Lambda V^{-1}$ for the specified spectrum, compute $\\kappa_2(V)$ from the SVD of $V$, and compute $r_{\\mathrm{BF}}(V, \\lVert E \\rVert_2)$ for the given $\\lVert E \\rVert_2$.\n- Implement a search over diagonal directions $d$ satisfying $\\max_i |d_i| = 1$ to find an adversarial direction that minimizes the quantity $\\lVert V \\,\\mathrm{diag}(d)\\, V^{-1} \\rVert_2$. For the selected direction, scale $\\alpha$ so that $\\lVert E(d,\\alpha) \\rVert_2$ matches the prescribed value, form $E(d,\\alpha)$, and compute the eigenvalues of $A$ and $A + E(d,\\alpha)$. Quantify the maximal eigenvalue displacement observed as $s = \\max_j \\min_i \\left| \\lambda_j(A+E) - \\lambda_i(A) \\right|$ (pair each perturbed eigenvalue with the closest original eigenvalue in absolute value and take the maximum of these minimal distances).\n- Return, for each case, the ratio $s / r_{\\mathrm{BF}}(V, \\lVert E \\rVert_2)$ as a floating-point number. This ratio quantifies how close the adversarial perturbation comes to the Bauer-Fike radius.\n\nAngle unit specification: all rotation angles must be expressed in radians.\n\nTest suite:\n- Case 1 (large $\\kappa_2(V)$):\n  - Spectrum: $\\{\\lambda_1, \\lambda_2, \\lambda_3\\} = \\{1.0, -2.0, 4.0\\}$, so $\\Lambda = \\mathrm{diag}(1.0, -2.0, 4.0)$.\n  - Rotation angle: $\\theta = \\pi/4$ (in radians). Use the $y$-axis rotation matrix \n    $$W(\\theta) = \\begin{bmatrix}\n    \\cos\\theta & 0 & \\sin\\theta \\\\\n    0 & 1 & 0 \\\\\n    -\\sin\\theta & 0 & \\cos\\theta\n    \\end{bmatrix}.$$\n  - Diagonal scaling: $\\Sigma = \\mathrm{diag}(1, s, s^2)$ with $s = 10^{-2}$.\n  - Diagonalizer: $V = \\Sigma \\, W(\\theta)^\\top$.\n  - Prescribed spectral norm of perturbation: $\\lVert E \\rVert_2 = \\varepsilon = 10^{-2}$.\n- Case 2 (moderate $\\kappa_2(V)$):\n  - Spectrum: $\\{\\lambda_1, \\lambda_2, \\lambda_3\\} = \\{0.5, -1.5, 3.0\\}$, so $\\Lambda = \\mathrm{diag}(0.5, -1.5, 3.0)$.\n  - Rotation angle: $\\theta = \\pi/4$ (in radians).\n  - Diagonal scaling: $\\Sigma = \\mathrm{diag}(1, s, s^2)$ with $s = 0.3$.\n  - Diagonalizer: $V = \\Sigma \\, W(\\theta)^\\top$.\n  - Prescribed spectral norm of perturbation: $\\lVert E \\rVert_2 = \\varepsilon = 5 \\times 10^{-3}$.\n- Case 3 (baseline orthogonal diagonalizer, $\\kappa_2(V) = 1$):\n  - Spectrum: $\\{\\lambda_1, \\lambda_2, \\lambda_3\\} = \\{2.0, 0.0, -1.0\\}$, so $\\Lambda = \\mathrm{diag}(2.0, 0.0, -1.0)$.\n  - Diagonalizer: $V = I_3$, the $3 \\times 3$ identity matrix, so no rotation is applied.\n  - Prescribed spectral norm of perturbation: $\\lVert E \\rVert_2 = \\varepsilon = 10^{-3}$.\n\nAlgorithmic requirements:\n- For each case, compute $\\kappa_2(V)$ via the SVD of $V$ using the ratio $\\sigma_{\\max}(V)/\\sigma_{\\min}(V)$.\n- Compute $r_{\\mathrm{BF}}(V, \\varepsilon) = \\kappa_2(V)\\,\\varepsilon$.\n- Search over diagonal directions $d$ satisfying $\\max_i |d_i| = 1$, including a deterministic set of canonical patterns and a randomized set with a fixed seed, to approximately minimize $\\lVert V \\,\\mathrm{diag}(d)\\, V^{-1} \\rVert_2$.\n- For the minimizing $d$, set $\\alpha = \\varepsilon / \\lVert V \\,\\mathrm{diag}(d)\\, V^{-1} \\rVert_2$ to enforce $\\lVert E(d,\\alpha) \\rVert_2 = \\varepsilon$, construct $E(d,\\alpha)$, compute the eigenvalues of $A$ and $A + E(d,\\alpha)$, and calculate $s$.\n- Output a single line with a comma-separated list enclosed in square brackets containing the three ratios $s / r_{\\mathrm{BF}}(V, \\varepsilon)$ for the three cases, in the order of Case 1, Case 2, Case 3, respectively. Each item must be a floating-point number.\n\nYour program must produce exactly one line of output in the format: \"[r1,r2,r3]\".",
            "solution": "The user has provided a valid problem statement.\n\nThe problem requires a computational investigation into the sharpness of the Bauer-Fike theorem for diagonalizable matrices. Specifically, we are to construct three matrices with varying conditioning of their eigenvector matrices, apply a structured adversarial perturbation, and compare the resulting maximal eigenvalue displacement to the theoretical upper bound provided by the Bauer-Fike radius.\n\nThe theoretical foundation of this problem rests on several key concepts in numerical linear algebra. Let $A \\in \\mathbb{R}^{n \\times n}$ be a diagonalizable matrix. By definition, there exists an invertible matrix $V$ and a diagonal matrix $\\Lambda$ such that:\n$$ A = V \\Lambda V^{-1} $$\nThe columns of $V$ are the eigenvectors of $A$, and the diagonal entries of $\\Lambda$, denoted $\\lambda_1, \\lambda_2, \\ldots, \\lambda_n$, are the corresponding eigenvalues.\n\nWhen $A$ is perturbed by another matrix $E$, the resulting matrix is $A+E$. The Bauer-Fike theorem provides a bound on how much the eigenvalues of $A$ can shift. It states that for any eigenvalue $\\mu$ of $A+E$, there exists an eigenvalue $\\lambda_i$ of $A$ such that:\n$$ |\\mu - \\lambda_i| \\le \\kappa_2(V) \\lVert E \\rVert_2 $$\nHere, $\\lVert E \\rVert_2$ is the spectral norm (or 2-norm) of $E$, defined as the largest singular value of $E$, $\\sigma_{\\max}(E)$. The quantity $\\kappa_2(V)$ is the 2-norm condition number of the eigenvector matrix $V$, defined as:\n$$ \\kappa_2(V) = \\lVert V \\rVert_2 \\lVert V^{-1} \\rVert_2 = \\frac{\\sigma_{\\max}(V)}{\\sigma_{\\min}(V)} $$\nwhere $\\sigma_{\\max}(V)$ and $\\sigma_{\\min}(V)$ are the largest and smallest singular values of $V$, respectively. The product $\\kappa_2(V) \\lVert E \\rVert_2$ is defined in the problem as the Bauer-Fike radius, $r_{\\mathrm{BF}}(V, \\lVert E \\rVert_2)$.\n\nThe problem investigates a special class of structured perturbations of the form $E = V \\Delta V^{-1}$, where $\\Delta = \\mathrm{diag}(\\delta_1, \\delta_2, \\ldots, \\delta_n)$ is a diagonal matrix. For such a perturbation, the perturbed matrix is:\n$$ A + E = V \\Lambda V^{-1} + V \\Delta V^{-1} = V (\\Lambda + \\Delta) V^{-1} $$\nThis shows that $A+E$ has the same eigenvector matrix $V$ as $A$, and its eigenvalues are $\\mu_j = \\lambda_j + \\delta_j$. The problem asks to construct $E$ with a prescribed spectral norm, $\\lVert E \\rVert_2 = \\varepsilon$. We define the perturbation direction via a diagonal matrix $\\mathrm{diag}(d)$, where $d=(d_1, d_2, d_3)$ and $\\max_i |d_i|=1$. The full perturbation is then scaled by a factor $\\alpha$, so $\\Delta = \\alpha \\, \\mathrm{diag}(d)$. The perturbation matrix is $E(d, \\alpha) = V \\, (\\alpha \\, \\mathrm{diag}(d)) \\, V^{-1} = \\alpha (V \\, \\mathrm{diag}(d) \\, V^{-1})$.\nTo enforce $\\lVert E(d, \\alpha) \\rVert_2 = \\varepsilon$, we must have:\n$$ |\\alpha| \\lVert V \\, \\mathrm{diag}(d) \\, V^{-1} \\rVert_2 = \\varepsilon $$\nWe choose a positive $\\alpha$, so $\\alpha = \\varepsilon / \\lVert V \\, \\mathrm{diag}(d) \\, V^{-1} \\rVert_2$.\n\nFor this structured perturbation, the maximal eigenvalue displacement is measured by $s = \\max_j \\min_i |\\mu_j - \\lambda_i|$. Since $\\mu_j = \\lambda_j + \\alpha d_j$, and assuming $\\alpha$ is sufficiently small, the closest original eigenvalue to $\\mu_j$ is $\\lambda_j$ itself. The distance is $|\\mu_j - \\lambda_j| = |\\alpha d_j|$. The maximal displacement is then:\n$$ s = \\max_j |\\alpha d_j| = \\alpha \\max_j|d_j| = \\alpha $$\nThe last equality holds because we chose $d$ such that $\\max_j|d_j|=1$.\n\nThe final quantity of interest is the ratio of the observed maximal displacement $s$ to the Bauer-Fike bound $r_{\\mathrm{BF}}$:\n$$ \\frac{s}{r_{\\mathrm{BF}}} = \\frac{\\alpha}{\\kappa_2(V) \\varepsilon} = \\frac{\\varepsilon / \\lVert V \\, \\mathrm{diag}(d) \\, V^{-1} \\rVert_2}{\\kappa_2(V) \\varepsilon} = \\frac{1}{\\kappa_2(V) \\lVert V \\, \\mathrm{diag}(d) \\, V^{-1} \\rVert_2} $$\nThe problem requires finding an adversarial direction $d$ by performing a search to minimize the quantity $\\lVert V \\, \\mathrm{diag}(d) \\, V^{-1} \\rVert_2$. This choice of $d$ will maximize the ratio $s/r_{\\mathrm{BF}}$, thereby creating a perturbation that comes as close as possible to saturating the Bauer-Fike bound for this structured class.\n\nThe computational procedure for each test case is as follows:\n1.  **Construct Matrices**: Based on the provided spectrum $\\Lambda$ and parameters for the diagonalizer $V$ (rotation angle $\\theta$, scaling parameter $s$), construct $V$ and then $A = V \\Lambda V^{-1}$. For Case 3, $V$ is given directly as the identity matrix $I_3$.\n2.  **Compute Condition Number and Bound**: Calculate the singular values of $V$ to find $\\kappa_2(V) = \\sigma_{\\max}(V) / \\sigma_{\\min}(V)$. Use the given perturbation norm $\\varepsilon$ to compute the Bauer-Fike radius $r_{\\mathrm{BF}} = \\kappa_2(V) \\varepsilon$.\n3.  **Find Adversarial Direction**: Numerically search for a direction vector $d$ with $\\max_i |d_i|=1$ that approximately minimizes $\\lVert V \\, \\mathrm{diag}(d) \\, V^{-1} \\rVert_2$. The search space is sampled using a combination of deterministic vectors (face centers and vertices of the unit cube) and a set of random vectors, ensuring a thorough exploration.\n4.  **Construct Perturbation**: Using the optimal direction $d^*$ found in the previous step, calculate the scaling factor $\\alpha = \\varepsilon / \\lVert V \\, \\mathrm{diag}(d^*) \\, V^{-1} \\rVert_2$. The perturbation matrix is then $E = V \\, \\mathrm{diag}(\\alpha d^*) \\, V^{-1}$.\n5.  **Calculate Displacement and Ratio**: Compute the eigenvalues of $A$ and $A+E$. The maximal displacement $s = \\max_j \\min_i |\\lambda_j(A+E) - \\lambda_i(A)|$ is found by pairing each perturbed eigenvalue with the closest original one. Finally, the ratio $s / r_{\\mathrm{BF}}$ is computed.\n\nThis procedure will be applied to all three specified test cases, which are designed to explore regimes of high condition number, moderate condition number, and the ideal orthogonal case ($\\kappa_2(V)=1$).",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the full analysis for the three test cases as specified in the problem.\n    \"\"\"\n\n    test_cases = [\n        # Case 1 (large kappa_2(V))\n        {\n            \"lambdas\": [1.0, -2.0, 4.0],\n            \"theta\": np.pi / 4,\n            \"s_scale\": 1e-2,\n            \"epsilon\": 1e-2,\n            \"v_is_identity\": False\n        },\n        # Case 2 (moderate kappa_2(V))\n        {\n            \"lambdas\": [0.5, -1.5, 3.0],\n            \"theta\": np.pi / 4,\n            \"s_scale\": 0.3,\n            \"epsilon\": 5e-3,\n            \"v_is_identity\": False\n        },\n        # Case 3 (baseline, kappa_2(V)=1)\n        {\n            \"lambdas\": [2.0, 0.0, -1.0],\n            \"theta\": 0.0, # Not used, but for completeness\n            \"s_scale\": 1.0, # Not used\n            \"epsilon\": 1e-3,\n            \"v_is_identity\": True\n        }\n    ]\n\n    results = []\n    \n    # Generate candidate directions 'd' for the search\n    # Deterministic candidates: face centers and vertices of the unit cube\n    det_candidates = []\n    # Face centers\n    for i in range(3):\n        for sign in [-1, 1]:\n            d = np.zeros(3)\n            d[i] = sign\n            det_candidates.append(d)\n    # Vertices\n    for i in [-1, 1]:\n        for j in [-1, 1]:\n            for k in [-1, 1]:\n                det_candidates.append(np.array([i, j, k], dtype=float))\n    \n    # Random candidates\n    rng = np.random.default_rng(seed=42)\n    rand_candidates = rng.uniform(-1, 1, size=(1000, 3))\n    max_abs = np.max(np.abs(rand_candidates), axis=1, keepdims=True)\n    rand_candidates /= max_abs\n    \n    all_candidates_d = np.unique(np.vstack(det_candidates + list(rand_candidates)), axis=0)\n\n    for case in test_cases:\n        Lambda = np.diag(case[\"lambdas\"])\n        epsilon = case[\"epsilon\"]\n\n        # Step 1: Construct Matrices\n        if case[\"v_is_identity\"]:\n            V = np.identity(3)\n        else:\n            theta = case[\"theta\"]\n            s_param = case[\"s_scale\"]\n            W_theta = np.array([\n                [np.cos(theta),  0, np.sin(theta)],\n                [0,              1, 0            ],\n                [-np.sin(theta), 0, np.cos(theta)]\n            ])\n            Sigma = np.diag([1, s_param, s_param**2])\n            V = Sigma @ W_theta.T\n        \n        A = V @ Lambda @ np.linalg.inv(V)\n\n        # Step 2: Compute Condition Number and Bound\n        singular_values_V = np.linalg.svd(V, compute_uv=False)\n        kappa_2_V = singular_values_V[0] / singular_values_V[-1]\n        r_bf = kappa_2_V * epsilon\n\n        # Step 3: Find Adversarial Direction\n        V_inv = np.linalg.inv(V)\n        min_norm_M_d = np.inf\n        best_d = None\n\n        for d in all_candidates_d:\n            M_d = V @ np.diag(d) @ V_inv\n            norm_M_d = np.linalg.norm(M_d, 2)\n            if norm_M_d  min_norm_M_d:\n                min_norm_M_d = norm_M_d\n                best_d = d\n        \n        # Step 4: Construct Perturbation\n        alpha = epsilon / min_norm_M_d\n        Delta = np.diag(alpha * best_d)\n        E = V @ Delta @ V_inv\n        \n        # Verify norm of E\n        # norm_E = np.linalg.norm(E, 2)\n        # assert np.isclose(norm_E, epsilon)\n\n        A_plus_E = A + E\n\n        # Step 5: Calculate Displacement and Ratio\n        # Eigenvalues of A are known, but we recompute for robustness.\n        # They may not be sorted, so we sort them.\n        eigvals_A = np.sort(np.linalg.eigvals(A).real)\n        eigvals_A_plus_E = np.sort(np.linalg.eigvals(A_plus_E).real)\n        \n        # Calculate s = max_j min_i |lambda_j(A+E) - lambda_i(A)|\n        dist_matrix = np.abs(eigvals_A_plus_E[:, np.newaxis] - eigvals_A[np.newaxis, :])\n        min_dists = np.min(dist_matrix, axis=1)\n        s = np.max(min_dists)\n\n        # In this specific structured perturbation, s should be ~alpha.\n        # We use the rigorously computed s as per problem statement.\n        \n        ratio = s / r_bf\n        results.append(ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}