{
    "hands_on_practices": [
        {
            "introduction": "不可对角化的亏损矩阵在数值计算中带来了巨大挑战。本练习将引导你进行一次亲手实践的解析探索，计算一个微小扰动如何影响一个包含若尔当块的矩阵。通过从第一性原理推导其特征向量矩阵的条件数，你将揭示数值不稳定性的数学根源。",
            "id": "3576868",
            "problem": "考虑一个带有2阶若尔当块的非正规矩阵的秩-1扰动。设\n$$\nA \\in \\mathbb{R}^{3 \\times 3}, \\quad A = \\begin{pmatrix} 0  1  0 \\\\ 0  0  0 \\\\ 0  0  3 \\end{pmatrix}, \\quad u = \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix}, \\quad v = \\begin{pmatrix} 3 \\\\ 0 \\\\ 0 \\end{pmatrix},\n$$\n并定义，对于 $\\varepsilon > 0$，\n$$\nA(\\varepsilon) \\coloneqq A + \\varepsilon\\, u v^{\\top}.\n$$\n完全从第一性原理出发：只使用特征值和特征向量的定义、相似对角化、谱范数（最大奇异值）以及标准的代数运算。不要假设任何现成的扰动理论结果，也不要引用任何未经证明的渐近公式。\n\n对于所有足够小的 $\\varepsilon > 0$，矩阵 $A(\\varepsilon)$ 是可对角化的。定义 $S(\\varepsilon) \\in \\mathbb{R}^{3 \\times 3}$ 为一个矩阵，其列是 $A(\\varepsilon)$ 的右特征向量，并按如下方式归一化：对于与从0处的亏损特征值分岔出来的两个特征值相关联的两个特征向量，将它们的第一个分量归一化为1；第三列取标准基向量 $e_{3}$。在这种归一化下，$S(\\varepsilon)$ 是唯一的，并且满足 $S(\\varepsilon)^{-1} A(\\varepsilon) S(\\varepsilon)$ 是对角矩阵。\n\n令 $\\kappa_{2}(S(\\varepsilon))$ 表示 $S(\\varepsilon)$ 的谱范数条件数，即 $\\kappa_{2}(S(\\varepsilon)) \\coloneqq \\|S(\\varepsilon)\\|_{2}\\,\\|S(\\varepsilon)^{-1}\\|_{2}$，其中 $\\|\\cdot\\|_{2}$ 是由欧几里得范数诱导的算子范数。\n\n计算当 $\\varepsilon \\to 0^{+}$ 时，$\\kappa_{2}(S(\\varepsilon))$ 的渐近标度中的首项系数 $C$ 的精确值，该系数由以下极限定义：\n$$\nC \\coloneqq \\lim_{\\varepsilon \\to 0^{+}} \\varepsilon^{1/2}\\, \\kappa_{2}(S(\\varepsilon)).\n$$\n你的最终答案必须是单一的封闭形式表达式。不需要四舍五入。",
            "solution": "问题要求计算扰动矩阵 $A(\\varepsilon)$ 的特征向量矩阵 $S(\\varepsilon)$ 的条件数 $\\kappa_{2}(S(\\varepsilon))$ 的渐近标度中的首项系数 $C$。分析将从第一性原理出发。\n\n首先，我们定义矩阵 $A(\\varepsilon)$。给定的矩阵是：\n$$\nA = \\begin{pmatrix} 0  1  0 \\\\ 0  0  0 \\\\ 0  0  3 \\end{pmatrix}, \\quad u = \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix}, \\quad v = \\begin{pmatrix} 3 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n秩-1扰动项为\n$$\n\\varepsilon u v^{\\top} = \\varepsilon \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 3  0  0 \\end{pmatrix} = \\begin{pmatrix} 3\\varepsilon  0  0 \\\\ 6\\varepsilon  0  0 \\\\ 0  0  0 \\end{pmatrix}.\n$$\n因此，对于 $\\varepsilon > 0$，扰动矩阵 $A(\\varepsilon)$ 是\n$$\nA(\\varepsilon) = A + \\varepsilon u v^{\\top} = \\begin{pmatrix} 3\\varepsilon  1  0 \\\\ 6\\varepsilon  0  0 \\\\ 0  0  3 \\end{pmatrix}.\n$$\n为了找到特征向量矩阵 $S(\\varepsilon)$，我们首先需要 $A(\\varepsilon)$ 的特征值。它们是特征方程 $\\det(A(\\varepsilon) - \\lambda I) = 0$ 的根：\n$$\n\\det \\begin{pmatrix} 3\\varepsilon - \\lambda  1  0 \\\\ 6\\varepsilon  -\\lambda  0 \\\\ 0  0  3 - \\lambda \\end{pmatrix} = 0.\n$$\n沿第三行展开行列式可得：\n$$\n(3 - \\lambda) \\det \\begin{pmatrix} 3\\varepsilon - \\lambda  1 \\\\ 6\\varepsilon  -\\lambda \\end{pmatrix} = (3 - \\lambda) \\big( (-\\lambda)(3\\varepsilon - \\lambda) - 6\\varepsilon \\big) = (3 - \\lambda)(\\lambda^2 - 3\\varepsilon\\lambda - 6\\varepsilon) = 0.\n$$\n特征值为 $\\lambda_3 = 3$ 以及二次方程 $\\lambda^2 - 3\\varepsilon\\lambda - 6\\varepsilon = 0$ 的两个根。使用二次公式，这两个根是：\n$$\n\\lambda_{1,2} = \\frac{3\\varepsilon \\pm \\sqrt{(3\\varepsilon)^2 - 4(1)(-6\\varepsilon)}}{2} = \\frac{3\\varepsilon \\pm \\sqrt{9\\varepsilon^2 + 24\\varepsilon}}{2}.\n$$\n对于足够小的 $\\varepsilon > 0$，判别式 $9\\varepsilon^2 + 24\\varepsilon$ 为正，所以 $\\lambda_1$ 和 $\\lambda_2$ 是实数且不相等。当 $\\varepsilon \\to 0$ 时，$\\lambda_1$ 和 $\\lambda_2$ 都趋近于0，这是 $A$ 的亏损特征值。\n\n接下来，我们求相应的特征向量。\n对于 $\\lambda_3 = 3$，一个特征向量 $x = (x_1, x_2, x_3)^{\\top}$ 满足 $(A(\\varepsilon) - 3I)x = 0$：\n$$\n\\begin{pmatrix} 3\\varepsilon-3  1  0 \\\\ 6\\varepsilon  -3  0 \\\\ 0  0  0 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n对于小的 $\\varepsilon > 0$，左上角的 $2 \\times 2$ 子矩阵是非奇异的，这意味着 $x_1=0$ 且 $x_2=0$。因此，特征向量的形式为 $(0, 0, x_3)^{\\top}$。问题指定将此特征向量取为标准基向量 $e_3 = (0, 0, 1)^{\\top}$。\n\n对于来自 $\\{\\lambda_1, \\lambda_2\\}$ 的特征值 $\\lambda$，一个特征向量 $x = (x_1, x_2, x_3)^{\\top}$ 满足 $(A(\\varepsilon) - \\lambda I)x = 0$：\n$$\n\\begin{pmatrix} 3\\varepsilon - \\lambda  1  0 \\\\ 6\\varepsilon  -\\lambda  0 \\\\ 0  0  3 - \\lambda \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n因为当 $\\varepsilon \\to 0$ 时 $\\lambda_{1,2} \\to 0$，所以对于小的 $\\varepsilon$，有 $\\lambda \\neq 3$。第三个方程 $(3-\\lambda)x_3=0$ 暗示 $x_3=0$。前两个方程是：\n$$\n(3\\varepsilon - \\lambda)x_1 + x_2 = 0.\n$$\n$$\n6\\varepsilon x_1 - \\lambda x_2 = 0.\n$$\n问题指定将这两个特征向量的第一个分量归一化为1。设 $x_1 = 1$，第一个方程给出 $x_2 = \\lambda - 3\\varepsilon$。（第二个方程 $6\\varepsilon - \\lambda(\\lambda-3\\varepsilon) = -\\lambda^2+3\\varepsilon\\lambda+6\\varepsilon = 0$ 是满足的，因为 $\\lambda$ 是该多项式的一个根）。\n所以，对应于 $\\lambda_1$ 和 $\\lambda_2$ 的特征向量是：\n$$\nx_1(\\varepsilon) = \\begin{pmatrix} 1 \\\\ \\lambda_1 - 3\\varepsilon \\\\ 0 \\end{pmatrix}, \\quad x_2(\\varepsilon) = \\begin{pmatrix} 1 \\\\ \\lambda_2 - 3\\varepsilon \\\\ 0 \\end{pmatrix}.\n$$\n特征向量矩阵 $S(\\varepsilon)$ 由这些归一化的特征向量作为列构成：\n$$\nS(\\varepsilon) = \\begin{pmatrix} 1  1  0 \\\\ \\lambda_1 - 3\\varepsilon  \\lambda_2 - 3\\varepsilon  0 \\\\ 0  0  1 \\end{pmatrix}.\n$$\n为了分析条件数，我们研究 $S(\\varepsilon)$ 的奇异值，它们是 $S(\\varepsilon)^{\\top}S(\\varepsilon)$ 的特征值的平方根。令 $y_1 = \\lambda_1 - 3\\varepsilon$ 和 $y_2 = \\lambda_2 - 3\\varepsilon$。\n$$\nS(\\varepsilon)^{\\top}S(\\varepsilon) = \\begin{pmatrix} 1  y_1  0 \\\\ 1  y_2  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} 1  1  0 \\\\ y_1  y_2  0 \\\\ 0  0  1 \\end{pmatrix} = \\begin{pmatrix} 1+y_1^2  1+y_1y_2  0 \\\\ 1+y_1y_2  1+y_2^2  0 \\\\ 0  0  1 \\end{pmatrix}.\n$$\n$S(\\varepsilon)^{\\top}S(\\varepsilon)$ 的一个特征值是 $1$。另外两个，我们称之为 $\\mu$，是左上角 $2 \\times 2$ 子矩阵 $M = \\begin{pmatrix} 1+y_1^2  1+y_1y_2 \\\\ 1+y_1y_2  1+y_2^2 \\end{pmatrix}$ 的特征值。其特征方程为 $\\mu^2 - \\text{tr}(M)\\mu + \\det(M) = 0$。\n迹为 $\\text{tr}(M) = 2 + y_1^2+y_2^2$。\n行列式为 $\\det(M) = (1+y_1^2)(1+y_2^2) - (1+y_1y_2)^2 = 1+y_1^2+y_2^2+y_1^2y_2^2 - (1+2y_1y_2+y_1^2y_2^2) = y_1^2+y_2^2-2y_1y_2=(y_1-y_2)^2$。\n\n我们需要用 $\\varepsilon$ 来表示这些项。根据韦达定理，对于 $\\lambda^2 - 3\\varepsilon\\lambda - 6\\varepsilon = 0$，我们有 $\\lambda_1+\\lambda_2 = 3\\varepsilon$ 和 $\\lambda_1\\lambda_2 = -6\\varepsilon$。\n$y_1+y_2 = (\\lambda_1-3\\varepsilon)+(\\lambda_2-3\\varepsilon) = (\\lambda_1+\\lambda_2)-6\\varepsilon = 3\\varepsilon-6\\varepsilon = -3\\varepsilon$。\n$y_1y_2 = (\\lambda_1-3\\varepsilon)(\\lambda_2-3\\varepsilon) = \\lambda_1\\lambda_2 - 3\\varepsilon(\\lambda_1+\\lambda_2) + 9\\varepsilon^2 = -6\\varepsilon - 3\\varepsilon(3\\varepsilon) + 9\\varepsilon^2 = -6\\varepsilon$。\n$y_1^2+y_2^2 = (y_1+y_2)^2-2y_1y_2 = (-3\\varepsilon)^2 - 2(-6\\varepsilon) = 9\\varepsilon^2+12\\varepsilon$。\n$(y_1-y_2)^2 = (\\lambda_1-\\lambda_2)^2 = (\\lambda_1+\\lambda_2)^2-4\\lambda_1\\lambda_2 = (3\\varepsilon)^2-4(-6\\varepsilon) = 9\\varepsilon^2+24\\varepsilon$。\n\n所以，$\\text{tr}(M) = 2+12\\varepsilon+9\\varepsilon^2$ 且 $\\det(M) = 24\\varepsilon+9\\varepsilon^2$。\n$\\mu$ 的特征方程为：\n$$\n\\mu^2 - (2+12\\varepsilon+9\\varepsilon^2)\\mu + (24\\varepsilon+9\\varepsilon^2) = 0.\n$$\n设其根为 $\\mu_{max}(\\varepsilon)$ 和 $\\mu_{min}(\\varepsilon)$。当 $\\varepsilon \\to 0^+$ 时，该方程变为 $\\mu^2 - 2\\mu = 0$，其根为 $0$ 和 $2$。因此，$\\lim_{\\varepsilon\\to 0^+} \\mu_{max}(\\varepsilon) = 2$ 且 $\\lim_{\\varepsilon\\to 0^+} \\mu_{min}(\\varepsilon) = 0$。\n\n$S(\\varepsilon)$ 的奇异值为 $\\sigma_i(\\varepsilon) = \\sqrt{\\mu_i}$，其中 $\\mu_i$ 是 $S(\\varepsilon)^\\top S(\\varepsilon)$ 的特征值。三个特征值是 $1$、$\\mu_{max}(\\varepsilon)$ 和 $\\mu_{min}(\\varepsilon)$。对于小的 $\\varepsilon > 0$，我们有 $0 < \\mu_{min}(\\varepsilon) < 1 < \\mu_{max}(\\varepsilon)$。最大和最小奇异值分别为 $\\sigma_{max}(S(\\varepsilon)) = \\sqrt{\\mu_{max}(\\varepsilon)}$ 和 $\\sigma_{min}(S(\\varepsilon)) = \\sqrt{\\mu_{min}(\\varepsilon)}$。\n\n条件数为 $\\kappa_2(S(\\varepsilon)) = \\frac{\\sigma_{max}(S(\\varepsilon))}{\\sigma_{min}(S(\\varepsilon))}$。\n我们有 $\\lim_{\\varepsilon\\to 0^+} \\sigma_{max}(S(\\varepsilon)) = \\lim_{\\varepsilon\\to 0^+} \\sqrt{\\mu_{max}(\\varepsilon)} = \\sqrt{2}$。\n\n为了找到 $\\sigma_{min}(S(\\varepsilon))$ 的渐近行为，我们研究 $\\mu_{min}(\\varepsilon)$。根据 $\\mu$ 的二次方程，两根之积等于常数项：$\\mu_{max}(\\varepsilon)\\mu_{min}(\\varepsilon) = 24\\varepsilon+9\\varepsilon^2$。\n因此，$\\mu_{min}(\\varepsilon) = \\frac{24\\varepsilon+9\\varepsilon^2}{\\mu_{max}(\\varepsilon)}$。\n两边除以 $\\varepsilon$ 并取 $\\varepsilon \\to 0^+$ 的极限：\n$$\n\\lim_{\\varepsilon\\to 0^+} \\frac{\\mu_{min}(\\varepsilon)}{\\varepsilon} = \\lim_{\\varepsilon\\to 0^+} \\frac{24+9\\varepsilon}{\\mu_{max}(\\varepsilon)} = \\frac{24+0}{2} = 12.\n$$\n这意味着对于小的 $\\varepsilon$，$\\mu_{min}(\\varepsilon) \\sim 12\\varepsilon$。\n所以，$\\sigma_{min}(S(\\varepsilon)) = \\sqrt{\\mu_{min}(\\varepsilon)} \\sim \\sqrt{12\\varepsilon} = 2\\sqrt{3}\\varepsilon^{1/2}$。\n\n现在我们可以计算系数 $C$ 的所需极限：\n$$\nC = \\lim_{\\varepsilon \\to 0^{+}} \\varepsilon^{1/2}\\, \\kappa_{2}(S(\\varepsilon)) = \\lim_{\\varepsilon \\to 0^{+}} \\varepsilon^{1/2} \\frac{\\sigma_{max}(S(\\varepsilon))}{\\sigma_{min}(S(\\varepsilon))}.\n$$\n我们可以将其重新排列为：\n$$\nC = \\frac{\\lim_{\\varepsilon \\to 0^{+}} \\sigma_{max}(S(\\varepsilon))}{\\lim_{\\varepsilon \\to 0^{+}} (\\sigma_{min}(S(\\varepsilon)) / \\varepsilon^{1/2})}.\n$$\n代入我们求得的极限：\n分子是 $\\lim_{\\varepsilon\\to 0^+} \\sigma_{max}(S(\\varepsilon)) = \\sqrt{2}$。\n分母是 $\\lim_{\\varepsilon\\to 0^+} \\frac{\\sigma_{min}(S(\\varepsilon))}{\\varepsilon^{1/2}} = \\lim_{\\varepsilon\\to 0^+} \\frac{\\sqrt{12\\varepsilon+O(\\varepsilon^2)}}{\\varepsilon^{1/2}} = \\sqrt{12} = 2\\sqrt{3}$。\n$$\nC = \\frac{\\sqrt{2}}{2\\sqrt{3}} = \\frac{\\sqrt{2}}{2\\sqrt{3}} \\cdot \\frac{\\sqrt{3}}{\\sqrt{3}} = \\frac{\\sqrt{6}}{6}.\n$$\n首项系数的值为 $\\frac{\\sqrt{6}}{6}$。",
            "answer": "$$\\boxed{\\frac{\\sqrt{6}}{6}}$$"
        },
        {
            "introduction": "在我们解析理解的基础上，本练习转向一个计算实验，以直观地展示近似亏损系统的脆弱性。你将实现一个测试，度量一个可对角化矩阵的特征向量在其特征值靠得很近时如何对扰动变得极其敏感。这个实验生动地揭示了病态特征向量矩阵与数值稳定性丧失之间的联系。",
            "id": "3576932",
            "problem": "您需要设计并实现一个数值实验，用以探究当对角化在理论上可行但因特征向量近似线性相关而导致数值上脆弱时，相似变换的稳定性。此项研究必须基于线性代数中相似性和可对角化性的核心定义。一个方阵 $A \\in \\mathbb{R}^{n \\times n}$ 是可对角化的，如果存在一个可逆矩阵 $S \\in \\mathbb{R}^{n \\times n}$ 和一个对角矩阵 $\\Lambda \\in \\mathbb{R}^{n \\times n}$，使得 $A = S \\Lambda S^{-1}$。$S$ 的列是 $A$ 的特征向量，$\\Lambda$ 的对角线元素是相应的特征值。当 $S$ 的列近似线性相关时，$S$ 在精确计算中仍然是可逆的，但 $S$ 会变得病态，使得相似变换在 $A$ 受到扰动时数值上不稳定。\n\n构建一个实数 $2 \\times 2$ 矩阵的参数族\n$$\nA(\\delta) = \\begin{bmatrix}\n1  1 \\\\\n0  1+\\delta\n\\end{bmatrix},\n$$ \n参数为 $\\delta > 0$，并考虑微小的确定性扰动\n$$\nE(\\varepsilon) = \\begin{bmatrix}\n0  0 \\\\\n\\varepsilon  0\n\\end{bmatrix},\n$$ \n参数为 $\\varepsilon \\ge 0$，定义 $B(\\delta,\\varepsilon) = A(\\delta) + E(\\varepsilon)$。对于每个三元组 $(\\delta,\\varepsilon,\\tau)$，您必须执行以下计算任务：\n\n1. 对 $A(\\delta)$ 和 $B(\\delta,\\varepsilon)$ 进行数值特征分解，以分别获得特征向量矩阵 $S_A$ 和 $S_B$ 及其特征值。将特征向量按特征值升序排列以构成 $S_A$ 和 $S_B$。将每个特征向量归一化为单位欧几里得长度，并通过强制第一个非零项为非负来固定符号，以消除任意的缩放和符号模糊性。\n2. 计算 $S_A$ 在矩阵 $2$-范数下的谱条件数，\n$$\n\\kappa_2(S_A) = \\|S_A\\|_2 \\cdot \\|S_A^{-1}\\|_2,\n$$\n其中 $\\|\\cdot\\|_2$ 表示由向量 $2$-范数诱导的算子范数。\n3. 对于来自 $S_A$ 和 $S_B$ 的相应有序且归一化的特征向量 $v_i$ 和 $w_i$（其中 $i \\in \\{1,2\\}$），计算主角\n$$\n\\theta_i = \\arccos\\!\\left(\\frac{|v_i^\\top w_i|}{\\|v_i\\|_2 \\cdot \\|w_i\\|_2}\\right),\n$$\n（以弧度表示），并报告每个三元组 $(\\delta,\\varepsilon,\\tau)$ 的最大角 $\\max\\{\\theta_1,\\theta_2\\}$。\n4. 通过将最大角与阈值 $\\tau$ 进行比较，将稳健性判定声明为布尔值：如果 $\\max\\{\\theta_1,\\theta_2\\} \\le \\tau$，则实验是稳健的，否则为非稳健的。\n\n您的程序必须为以下旨在测试不同情况的参数三元组 $(\\delta,\\varepsilon,\\tau)$ 测试套件实现上述操作：\n\n- $(\\delta,\\varepsilon,\\tau) = (10^{-1}, 10^{-8}, 0.05)$，\n- $(\\delta,\\varepsilon,\\tau) = (10^{-4}, 10^{-6}, 0.05)$，\n- $(\\delta,\\varepsilon,\\tau) = (10^{-8}, 10^{-12}, 0.05)$，\n- $(\\delta,\\varepsilon,\\tau) = (10^{-8}, 10^{-8}, 0.05)$，\n- $(\\delta,\\varepsilon,\\tau) = (10^{-6}, 5 \\cdot 10^{-6}, 0.05)$。\n\n所有角度必须以弧度表示。整个测试套件的最终输出必须是单行，包含一个顶级列表，其中每个元素本身是一个形式为 $[\\theta_{\\max}, \\kappa_2(S_A), \\text{robust}]$ 的列表，其中 $\\theta_{\\max}$ 是一个浮点数，$\\kappa_2(S_A)$ 是一个浮点数，而 $\\text{robust}$ 是一个布尔值。您的程序应生成一行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$[[ \\theta_1, \\kappa_1, \\text{True}], [\\theta_2, \\kappa_2, \\text{False}]]$）。不允许外部输入；所有参数均按上述给定值固定。",
            "solution": "问题陈述是有效的。它提出了一个适定的线性代数数值实验，该实验基于矩阵理论的既定原则，特别是关于特征系统的可对角化性和稳定性。所有术语都有正式定义，参数是完整的，并且任务在计算上是可行的。\n\n目标是研究一个接近亏损（即不可对角化）的矩阵其特征向量的数值稳定性。如果一个矩阵具有重复的特征值和数量不足的线性无关特征向量，则该矩阵是亏损的。所提供的矩阵族 $A(\\delta)$ 被设计为当参数 $\\delta$ 趋近于 $0$ 时，它会趋近一个亏损矩阵。\n\n该矩阵族由下式给出\n$$ A(\\delta) = \\begin{bmatrix} 1  1 \\\\ 0  1+\\delta \\end{bmatrix}, \\quad \\delta > 0 $$\n由于 $A(\\delta)$ 是一个上三角矩阵，其特征值是其对角线元素，即 $\\lambda_{A,1} = 1$ 和 $\\lambda_{A,2} = 1+\\delta$。对于 $\\delta > 0$，这些特征值是不同的，这保证了 $A(\\delta)$ 是可对角化的。\n\n相应的右特征向量通过求解 $(A(\\delta) - \\lambda I)v = 0$ 得到。\n对于 $\\lambda_{A,1} = 1$：\n$$ (A(\\delta) - 1 \\cdot I)v = \\begin{bmatrix} 0  1 \\\\ 0  \\delta \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\implies y=0 $$\n特征向量是 $v_1 = [1, 0]^\\top$ 的任意倍数。\n\n对于 $\\lambda_{A,2} = 1+\\delta$：\n$$ (A(\\delta) - (1+\\delta)I)v = \\begin{bmatrix} -\\delta  1 \\\\ 0  0 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\implies -\\delta x + y = 0 $$\n特征向量是 $v_2 = [1, \\delta]^\\top$ 的任意倍数。\n\n当 $\\delta \\to 0$ 时，两个特征值在 $\\lambda=1$ 处合并。同时，特征向量 $v_2$ 趋近于 $v_1$，变得近似线性相关。$v_1$ 和 $v_2$ 之间的夹角约为 $\\delta$ 弧度。\n\n特征向量矩阵 $S_A$ 由归一化且有序的特征向量构成。按照问题的规定（按特征值升序排列，归一化为单位长度，并固定符号使第一个非零项为非负），我们得到：\n$$ v_1^{\\text{norm}} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, \\quad v_2^{\\text{norm}} = \\frac{1}{\\sqrt{1+\\delta^2}} \\begin{bmatrix} 1 \\\\ \\delta \\end{bmatrix} $$\n$$ S_A = \\begin{bmatrix} 1  \\frac{1}{\\sqrt{1+\\delta^2}} \\\\ 0  \\frac{\\delta}{\\sqrt{1+\\delta^2}} \\end{bmatrix} $$\n当 $\\delta \\to 0$ 时，该矩阵变得病态，这从其行列式 $\\det(S_A) = \\frac{\\delta}{\\sqrt{1+\\delta^2}}$ 趋近于 $0$ 可以明显看出。对于小的 $\\delta$，条件数 $\\kappa_2(S_A) = \\|S_A\\|_2 \\|S_A^{-1}\\|_2$ 预计会很大。解析上可以发现 $\\|S_A^{-1}\\|_2$ 的尺度为 $O(1/\\delta)$，因此 $\\kappa_2(S_A)$ 的增长速度为 $1/\\delta$。大的条件数意味着特征向量基对扰动敏感。\n\n该实验对 $A(\\delta)$ 引入了一个扰动 $E(\\varepsilon)$，得到的矩阵为：\n$$ B(\\delta, \\varepsilon) = A(\\delta) + E(\\varepsilon) = \\begin{bmatrix} 1  1 \\\\ \\varepsilon  1+\\delta \\end{bmatrix} $$\n任务的核心是对于给定的参数集 $(\\delta, \\varepsilon, \\tau)$，数值计算 $A(\\delta)$ 和 $B(\\delta, \\varepsilon)$ 的特征系统，并量化特征向量的变化。该变化通过相应特征向量之间的最大主角来衡量。\n\n对于每个参数三元组 $(\\delta, \\varepsilon, \\tau)$ 的计算过程如下：\n1.  构造矩阵 $A(\\delta)$ 和 $B(\\delta, \\varepsilon)$。\n2.  使用标准的特征求解器（例如，来自 NumPy 库）为两个矩阵数值计算特征值和特征向量。\n3.  对每个矩阵，按升序对特征值进行排序，并重新排列相应的特征向量，以构成特征向量矩阵 $S_A$ 和 $S_B$ 的列。\n4.  为保证唯一性，对每个特征向量进行标准化：\n    a. 将向量归一化，使其欧几里得范数为 $1$。\n    b. 如果归一化向量的第一个非零元素为负，则将该向量乘以 $-1$。\n5.  使用矩阵 $2$-范数计算所得矩阵 $S_A$ 的谱条件数：$\\kappa_2(S_A) = \\|S_A\\|_2 \\|S_A^{-1}\\|_2$。\n6.  处理后的矩阵 $S_A = [v_1, v_2]$ 和 $S_B = [w_1, w_2]$ 的列是标准化的特征向量。计算主角 $\\theta_1 = \\arccos(|v_1^\\top w_1|)$ 和 $\\theta_2 = \\arccos(|v_2^\\top w_2|)$。取点积的绝对值，由于向量是单位范数，这直接给出了角度。必须注意浮点运算，以确保 $\\arccos$ 的参数在有效范围 $[-1, 1]$ 内。\n7.  确定最大角 $\\theta_{\\max} = \\max\\{\\theta_1, \\theta_2\\}$。\n8.  如果 $\\theta_{\\max} \\le \\tau$，则将结果分类为稳健的，否则为非稳健的。\n\n此过程将系统地应用于提供的测试套件，以生成所需的输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_standardized_eigensystem(matrix):\n    \"\"\"\n    Computes eigenvalues and eigenvectors of a matrix, then standardizes them.\n\n    1. Eigenvectors are sorted according to ascending eigenvalues.\n    2. Each eigenvector is normalized to unit L2 norm.\n    3. The sign of each eigenvector is fixed by making its first non-zero\n       element non-negative.\n    \n    Args:\n        matrix (np.ndarray): A square matrix.\n\n    Returns:\n        np.ndarray: The standardized eigenvector matrix S, where columns are\n                    the standardized eigenvectors.\n    \"\"\"\n    eigvals, eigvecs = np.linalg.eig(matrix)\n    \n    # 1. Sort eigenvectors based on ascending eigenvalues\n    sort_indices = np.argsort(eigvals)\n    sorted_eigvecs = eigvecs[:, sort_indices]\n    \n    standardized_S = np.zeros_like(sorted_eigvecs, dtype=float)\n    \n    for i in range(sorted_eigvecs.shape[1]):\n        vec = sorted_eigvecs[:, i]\n        \n        # 2. Normalize to unit Euclidean length\n        norm = np.linalg.norm(vec, 2)\n        if norm > 0:\n            vec_normalized = vec / norm\n        else:\n            # Should not happen for eigenvectors, but handle gracefully.\n            vec_normalized = vec\n        \n        # 3. Fix sign by enforcing a non-negative first non-zero entry\n        first_nonzero_indices = np.flatnonzero(np.round(vec_normalized, 15))\n        if first_nonzero_indices.size > 0:\n            first_nonzero_idx = first_nonzero_indices[0]\n            if vec_normalized[first_nonzero_idx] < 0:\n                vec_normalized *= -1\n        \n        standardized_S[:, i] = vec_normalized\n        \n    return standardized_S\n\ndef solve():\n    \"\"\"\n    Main function to run the numerical experiment for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (delta, epsilon, tau)\n        (1e-1, 1e-8, 0.05),\n        (1e-4, 1e-6, 0.05),\n        (1e-8, 1e-12, 0.05),\n        (1e-8, 1e-8, 0.05),\n        (1e-6, 5e-6, 0.05),\n    ]\n\n    results = []\n    for delta, epsilon, tau in test_cases:\n        # Construct matrices A(delta) and B(delta, epsilon)\n        A_delta = np.array([[1.0, 1.0], \n                             [0.0, 1.0 + delta]], dtype=float)\n        \n        B_delta_eps = np.array([[1.0, 1.0], \n                                [epsilon, 1.0 + delta]], dtype=float)\n\n        # Task 1: Compute standardized eigen-decompositions\n        S_A = compute_standardized_eigensystem(A_delta)\n        S_B = compute_standardized_eigensystem(B_delta_eps)\n        \n        # Task 2: Compute spectral condition number of S_A\n        kappa_2_SA = np.linalg.cond(S_A, 2)\n        \n        # Task 3: Compute maximum principal angle\n        v1, v2 = S_A[:, 0], S_A[:, 1]\n        w1, w2 = S_B[:, 0], S_B[:, 1]\n        \n        # Clip dot product to handle potential floating point inaccuracies\n        dot1 = np.clip(np.abs(v1.T @ w1), -1.0, 1.0)\n        dot2 = np.clip(np.abs(v2.T @ w2), -1.0, 1.0)\n        \n        theta1 = np.arccos(dot1)\n        theta2 = np.arccos(dot2)\n        \n        theta_max = max(theta1, theta2)\n        \n        # Task 4: Declare robustness decision\n        is_robust = theta_max <= tau\n        \n        results.append([theta_max, kappa_2_SA, is_robust])\n\n    # Final print statement in the exact required format.\n    # [ [theta_max1, kappa1, robust1], [theta_max2, kappa2, robust2], ... ]\n    sublist_strings = []\n    for res in results:\n        # Format each sublist as a string \"[val1,val2,val3]\"\n        sublist_str = f\"[{res[0]},{res[1]},{res[2]}]\"\n        sublist_strings.append(sublist_str)\n    \n    final_output = f\"[{','.join(sublist_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "当直接计算若尔当范式本身是一个不稳定过程时，我们如何能可靠地确定一个矩阵的结构？这最后一个练习将介绍一种基于相似不变量的稳健诊断工具。你将开发一个程序，通过计算矩阵幂 $(A-\\lambda I)^k$ 的核空间维度链，来区分真正的亏损矩阵和仅仅是病态的矩阵，这是一种更稳定且富有洞察力的方法。",
            "id": "3576934",
            "problem": "您需要设计并实现一个程序，该程序能够构建具有相同谱（特征值的多重集）但具有不同若尔当结构（Jordan structures）的方阵对，然后在不计算任何若尔当标准型（Jordan normal form）的情况下，数值地辨别它们的相似不变量属性。您的程序必须展示如何使用相似变换下的不变量来检测不可对角化性，并区分尽管具有相同谱但并不相似的矩阵。\n\n基本原理：使用相似变换、特征值和特征向量、代数重数、几何重数、秩、零度以及若尔当标准型的核心定义。任何复数域上的方阵都存在若尔当标准型，其相似不变量包括带有代数重数的谱、最小多项式，以及与每个特征值相关的幂零部分的核空间的维数。具体来说，对于一个特征值 $\\lambda$ 和一个矩阵 $A$，核空间维数序列 $\\dim \\ker (A - \\lambda I)^k$（其中 $k = 1, 2, \\dots, m$，$m$ 是 $\\lambda$ 的代数重数）是一个相似不变量，它编码了对应于 $\\lambda$ 的若尔当块的大小和数量。一个矩阵在复数域上可对角化，当且仅当对于每个特征值 $\\lambda$，其核空间 $\\ker (A - \\lambda I)$ 的维数等于 $\\lambda$ 的代数重数。\n\n任务：\n1. 为每个测试用例构建一对大小相同、谱相同但若尔当结构不同的矩阵 $(A,B)$。选择实数矩阵以确保特征值为实数，并构建至少一个亏损矩阵（不可对角化）及其具有相同谱的可对角化对应矩阵。\n2. 实现数值程序来计算以下相似不变量，而无需构建任何若尔当标准型：\n   - 将矩阵 $A$ 的特征值使用数值容差 $\\tau_{\\mathrm{eig}}$ 聚类成相等特征值的组（即，在 $\\tau_{\\mathrm{eig}}$ 范围内的特征值被视为相同）。对于每个代数重数为 $m$ 的聚类代表 $\\lambda$，使用奇异值分解计算数值秩，从而计算零度链 $\\nu_k = \\dim \\ker (A - \\lambda I)^k$（$k=1,2,\\dots,m$）。使用绝对秩容差 $\\tau_{\\mathrm{rank}}$，即如果奇异值 $s \\le \\tau_{\\mathrm{rank}}$，则将其视为零。零度为 $n - \\mathrm{rank}$，其中 $n$ 是矩阵的大小。\n   - 通过验证对于每个代数重数为 $m$ 的聚类特征值 $\\lambda$，准则 $\\dim \\ker (A - \\lambda I) = m$ 是否成立，来判断 $A$ 是否在复数域上可对角化。\n3. 在两种不同的秩容差下应用上述计算，以突显数值敏感性：\n   - 严格容差 $\\tau_{\\mathrm{rank}}^{\\mathrm{strict}} = 10^{-14}$。\n   - 宽松容差 $\\tau_{\\mathrm{rank}}^{\\mathrm{relaxed}} = 10^{-8}$。\n   在所有运行中，使用 $\\tau_{\\mathrm{eig}} = 10^{-12}$ 进行特征值聚类。\n4. 对于每个测试用例 $(A,B)$，输出六项内容：\n   - 在 $\\tau_{\\mathrm{rank}}^{\\mathrm{strict}}$ 下 $A$ 的布尔可对角化性。\n   - 在 $\\tau_{\\mathrm{rank}}^{\\mathrm{strict}}$ 下 $B$ 的布尔可对角化性。\n   - 在 $\\tau_{\\mathrm{rank}}^{\\mathrm{relaxed}}$ 下 $A$ 的布尔可对角化性。\n   - 在 $\\tau_{\\mathrm{rank}}^{\\mathrm{relaxed}}$ 下 $B$ 的布尔可对角化性。\n   - 在 $\\tau_{\\mathrm{rank}}^{\\mathrm{strict}}$ 下 $A$ 的相似不变量签名，定义为一个由 $[\\lambda, [\\nu_1,\\dots,\\nu_m]]$ 对组成的列表，其中每个 $\\lambda$ 表示为实数浮点数，每个 $\\nu_k$ 表示为整数。\n   - 在 $\\tau_{\\mathrm{rank}}^{\\mathrm{strict}}$ 下 $B$ 的相似不变量签名，格式相同。\n\n测试套件：\n- 案例 1 (理想情况，小型 $3\\times 3$)： \n  - $A_1 = \\begin{bmatrix} 1  1  0 \\\\ 0  1  0 \\\\ 0  0  2 \\end{bmatrix}$ (亏损，在 $\\lambda=1$ 处有一个尺寸为 2 的若尔当块)。\n  - $B_1 = \\mathrm{diag}(1,1,2)$ (可对角化)。\n- 案例 2 (覆盖代数重数为 2 的不同特征值，大小 $4\\times 4$)：\n  - $A_2 = \\begin{bmatrix} 0  1  0  0 \\\\ 0  0  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  2 \\end{bmatrix}$ (亏损，在 $\\lambda=0$ 处有一个尺寸为 2 的若尔当块)。\n  - $B_2 = \\mathrm{diag}(0,0,1,2)$ (可对角化)。\n- 案例 3 (边界情况，近亏损，大小 $2\\times 2$)：\n  - $A_3 = \\begin{bmatrix} 1  \\epsilon \\\\ 0  1 \\end{bmatrix}$，其中 $\\epsilon = 10^{-12}$ (亏损，但数值上很微妙)。\n  - $B_3 = \\mathrm{diag}(1,1)$ (可对角化)。\n\n角度单位不适用，也不涉及任何物理单位。所有输出必须是布尔值、整数、浮点数或这些类型的列表。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例一项，其中每一项本身就是上述六个元素的列表。具体来说，输出必须是 Python 风格的字面量，形式为\n$[[d_{A_1}^{\\mathrm{strict}}, d_{B_1}^{\\mathrm{strict}}, d_{A_1}^{\\mathrm{relaxed}}, d_{B_1}^{\\mathrm{relaxed}}, \\mathrm{sig}(A_1), \\mathrm{sig}(B_1)], [d_{A_2}^{\\mathrm{strict}}, d_{B_2}^{\\mathrm{strict}}, d_{A_2}^{\\mathrm{relaxed}}, d_{B_2}^{\\mathrm{relaxed}}, \\mathrm{sig}(A_2), \\mathrm{sig}(B_2)], [d_{A_3}^{\\mathrm{strict}}, d_{B_3}^{\\mathrm{strict}}, d_{A_3}^{\\mathrm{relaxed}}, d_{B_3}^{\\mathrm{relaxed}}, \\mathrm{sig}(A_3), \\mathrm{sig}(B_3)]]$，其中每个 $\\mathrm{sig}(A)$ 是一个 $[\\lambda, [\\nu_1,\\dots,\\nu_m]]$ 对的列表。不应打印任何额外文本。",
            "solution": "该问题要求设计一个数值程序，以区分具有相同谱（特征值的多重集）但并不相似的方阵。这种区分需要在不显式计算若尔当标准型（JNF）的情况下进行。任务的核心在于计算和比较一组更精细的相似不变量。\n\n相似变换将一个方阵 $A$ 映射为 $P^{-1}AP$，其中 $P$ 是某个可逆矩阵。在所有此类变换下保持不变的量称为相似不变量。最常见的不变量是谱，但正如问题所规定的，它不是一个完备的不变量。两个矩阵可以有相同的谱，但几何结构不同，从而导致它们不相似。\n\n矩阵在相似关系下的完全分类由若尔当标准型提供。若尔当标准型定理指出，任何方阵 $A \\in \\mathbb{C}^{n \\times n}$ 都相似于一个分块对角矩阵 $J = \\mathrm{diag}(J_1, J_2, \\ldots, J_p)$，其中每个 $J_i$ 是一个若尔当块。一个对应于特征值 $\\lambda$ 的大小为 $k$ 的若尔当块是一个形如下式的上双对角矩阵：\n$$ J_k(\\lambda) = \\begin{bmatrix} \\lambda  1   \\\\  \\lambda  \\ddots  \\\\   \\ddots  1 \\\\    \\lambda \\end{bmatrix} \\in \\mathbb{C}^{k \\times k} $$\n两个矩阵相似当且仅当它们具有相同的若尔当标准型（在若尔当块的排列上可能不同）。这意味着它们必须有相同的特征值，并且对于每个特征值 $\\lambda$，其对应的若尔当块的数量和大小必须完全相同。\n\n一个矩阵可对角化当且仅当其所有的若尔当块的大小都是 $1 \\times 1$。在这种情况下，它的若尔当标准型是一个对角矩阵。\n\n问题在于如何在不计算 $J$ 或相似变换矩阵 $P$ 的情况下，确定这些结构属性——若尔当块的数量和大小。这可以通过分析矩阵 $T_\\lambda = A - \\lambda I$ 的幂的核空间来实现。这些核空间的维数是相似不变量。设 $\\lambda$ 是 $A$ 的一个特征值，其代数重数为 $m$（即，它是特征多项式的一个重数为 $m$ 的根）。我们定义零度序列 $\\nu_k$ 如下：\n$$ \\nu_k = \\dim \\ker( (A - \\lambda I)^k ) \\quad \\text{for } k = 1, 2, \\ldots, m $$\n这个整数序列编码了与 $\\lambda$ 相关的整个若尔当结构。具体来说：\n- $\\lambda$ 的若尔当块的数量是 $\\nu_1$。这正是 $\\lambda$ 的几何重数。\n- 尺寸至少为 $k$ 的若尔当块的数量由差值 $\\nu_k - \\nu_{k-1}$ 给出（其中 $\\nu_0 = 0$）。\n- 序列 $(\\nu_1, \\nu_2, \\ldots, \\nu_m)$ 是非递减的，并在 $\\nu_p = \\nu_{p+1} = \\ldots = m$ 处稳定，其中 $p$ 是与 $\\lambda$ 相关的最大若尔当块的尺寸。\n\n由此可知，一个矩阵 $A$ 可对角化，当且仅当对于每个代数重数为 $m$ 的特征值 $\\lambda$，其几何重数 $\\nu_1$ 等于 $m$。如果 $\\nu_1 = m$，这意味着有 $m$ 个若尔当块，并且由于它们的大小之和必须为 $m$，因此每个块的大小都必须为 1。\n\n解决该问题的算法步骤如下：\n\n1.  **特征值计算与聚类**：对于给定的矩阵 $A$，我们首先使用标准的数值算法（如 QR 算法，由 `numpy.linalg.eigvals` 提供）计算其特征值。由于浮点运算，理论上相同的特征值可能会被计算为一簇相近的数值。我们使用容差 $\\tau_{\\mathrm{eig}}$ 将这些数值特征值分组。对于每个聚类，我们计算其代表特征值 $\\lambda$（例如，均值）及其代数重数 $m$（聚类的大小）。\n\n2.  **零度链计算**：对于每个代数重数为 $m$ 的不同特征值 $\\lambda$，我们计算零度链 $\\nu_1, \\nu_2, \\ldots, \\nu_m$。矩阵 $M$ 的零度由 $\\mathrm{nullity}(M) = n - \\mathrm{rank}(M)$ 给出，其中 $n$ 是矩阵的维数。矩阵 $(A - \\lambda I)^k$ 的秩必须进行数值计算。\n\n3.  **数值秩计算**：对于包含浮点项的矩阵，计算秩是一个不适定问题。最稳健的方法是使用奇异值分解 (SVD)。对于任何矩阵 $M$，其秩是其非零奇异值的数量。在数值上，我们计算大于指定绝对容差 $\\tau_{\\mathrm{rank}}$ 的奇异值 $s_i$ 的数量。\n    $$ \\mathrm{rank}(M) \\approx |\\{ s_i \\mid s_i > \\tau_{\\mathrm{rank}} \\}| $$\n    $\\tau_{\\mathrm{rank}}$ 的选择至关重要，它会影响结果，特别是对于问题中探讨的“近亏损”矩阵。\n\n4.  **可对角化性检查**：对于每个代数重数为 $m$ 的特征值 $\\lambda$，我们检查是否 $\\nu_1 = m$。当且仅当此条件对其所有不同特征值都成立时，矩阵 $A$ 才被声明为可对角化。\n\n5.  **签名生成**：$A$ 的相似不变量签名被构建为一个对的列表，其中每对由一个代表特征值 $\\lambda$ 及其对应的零度链 $[\\nu_1, \\ldots, \\nu_m]$ 组成。这个签名唯一地刻画了 $A$ 的若尔当标准型结构。两个矩阵相似当且仅当它们的签名相同时（不考虑特征值的排序）。\n\n问题要求使用两种不同的秩容差 $\\tau_{\\mathrm{rank}}^{\\mathrm{strict}} = 10^{-14}$ 和 $\\tau_{\\mathrm{rank}}^{\\mathrm{relaxed}} = 10^{-8}$ 进行此分析，以展示数值秩的敏感性，以及由此带来的对若尔当结构判定的影响。对于像 $A_3 = \\begin{bmatrix} 1  \\epsilon \\\\ 0  1 \\end{bmatrix}$ 这样 $\\epsilon=10^{-12}$ 非常小的矩阵，矩阵 $A_3-I$ 有一个大小为 $10^{-12}$ 的奇异值。严格的容差会正确地将其识别为非零值，从而揭示其秩为1，因此矩阵是亏损的。而宽松的容差会错误地将该奇异值归类为零，导致表观秩为0，并得出矩阵可对角化的误导性结论。这凸显了数值线性代数中的一个根本性挑战。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to construct and analyze matrix pairs.\n    \"\"\"\n\n    def analyze_matrix(A, tau_eig, tau_rank):\n        \"\"\"\n        Computes the diagonalizability and similarity-invariant signature of a matrix.\n\n        Args:\n            A (np.ndarray): The input square matrix.\n            tau_eig (float): Tolerance for clustering eigenvalues.\n            tau_rank (float): Tolerance for numerical rank calculation via SVD.\n\n        Returns:\n            tuple: A tuple containing:\n                - is_diagonalizable (bool): True if the matrix is numerically diagonalizable.\n                - signature (list): A list of [eigenvalue, nullity_chain] pairs.\n        \"\"\"\n        n = A.shape[0]\n        if n == 0:\n            return True, []\n        \n        try:\n            eigs = np.linalg.eigvals(A)\n        except np.linalg.LinAlgError:\n            # Handle cases where eigenvalue computation fails, though unlikely for test cases.\n            return False, []\n\n        # Sort eigenvalues to facilitate clustering\n        eigs = sorted(eigs, key=lambda x: (x.real, x.imag))\n\n        # Cluster eigenvalues\n        clusters = []\n        i = 0\n        while i < len(eigs):\n            j = i + 1\n            while j < len(eigs) and abs(eigs[j] - eigs[i]) <= tau_eig:\n                j += 1\n            \n            cluster_eigs = eigs[i:j]\n            lambda_rep = np.mean(cluster_eigs)\n            m = len(cluster_eigs)\n            clusters.append((lambda_rep, m))\n            i = j\n        \n        is_diagonalizable = True\n        signature = []\n\n        I = np.eye(n)\n\n        for lambda_val, m in clusters:\n            nullity_chain = []\n            \n            # Compute T = A - lambda*I\n            T = A - lambda_val * I\n            \n            # Use np.linalg.matrix_power for T^k\n            Tk = np.copy(T)\n            for k in range(1, m + 1):\n                if k > 1:\n                    Tk = Tk @ T\n                \n                # Compute numerical rank using SVD\n                s = np.linalg.svd(Tk, compute_uv=False)\n                rank_k = np.sum(s > tau_rank)\n                nullity_k = n - rank_k\n                nullity_chain.append(int(nullity_k))\n            \n            # Check diagonalizability condition for this eigenvalue\n            # Geometric multiplicity (nu_1) must equal algebraic multiplicity (m)\n            if nullity_chain[0] != m:\n                is_diagonalizable = False\n\n            signature.append([lambda_val.real, nullity_chain])\n\n        # Sort signature by eigenvalue for deterministic output\n        signature.sort(key=lambda x: x[0])\n\n        return is_diagonalizable, signature\n\n    # Define tolerances\n    tau_eig = 1e-12\n    tau_rank_strict = 1e-14\n    tau_rank_relaxed = 1e-8\n    \n    # Define test cases\n    A1 = np.array([[1, 1, 0], [0, 1, 0], [0, 0, 2]], dtype=float)\n    B1 = np.diag([1, 1, 2]).astype(float)\n    \n    A2 = np.array([[0, 1, 0, 0], [0, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 2]], dtype=float)\n    B2 = np.diag([0, 0, 1, 2]).astype(float)\n    \n    epsilon = 1e-12\n    A3 = np.array([[1, epsilon], [0, 1]], dtype=float)\n    B3 = np.diag([1, 1]).astype(float)\n\n    test_cases = [\n        (A1, B1),\n        (A2, B2),\n        (A3, B3)\n    ]\n\n    all_results = []\n    for A, B in test_cases:\n        # Analyze with strict tolerance\n        d_A_strict, sig_A = analyze_matrix(A, tau_eig, tau_rank_strict)\n        d_B_strict, sig_B = analyze_matrix(B, tau_eig, tau_rank_strict)\n\n        # Analyze with relaxed tolerance (only need diagonalizability)\n        d_A_relaxed, _ = analyze_matrix(A, tau_eig, tau_rank_relaxed)\n        d_B_relaxed, _ = analyze_matrix(B, tau_eig, tau_rank_relaxed)\n\n        case_result = [\n            d_A_strict, d_B_strict,\n            d_A_relaxed, d_B_relaxed,\n            sig_A, sig_B\n        ]\n        all_results.append(case_result)\n\n    # Format the final output string to match the required Python literal format\n    # Using a direct mapping to string handles booleans, floats, and lists correctly.\n    result_str = \"[\" + \",\".join(map(str, all_results)) + \"]\"\n    \n    print(result_str)\n\n```"
        }
    ]
}