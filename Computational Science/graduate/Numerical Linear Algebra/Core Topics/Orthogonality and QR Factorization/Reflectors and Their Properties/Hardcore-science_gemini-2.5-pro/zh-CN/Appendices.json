{
    "hands_on_practices": [
        {
            "introduction": "理论学习与动手实践相结合是掌握数值线性代数精髓的关键。本章将通过一系列精心设计的实践项目，引导您深入探索反射变换（或称Householder变换）的性质及其在数值计算中的应用。我们的第一个实践  将作为一个基础性实验，旨在通过编码直观地验证反射变换的核心几何性质——即它们作为正交变换，在理想情况下应保持向量的欧几里得范数和向量间的距离。同时，本练习将揭示在有限精度浮点运算下，这些理想性质会如何产生微小偏差，帮助您建立对数值误差来源和影响的深刻理解。",
            "id": "3572839",
            "problem": "您需要实现一个数值线性代数领域内完全可复现的数值实验，以研究反射算子在有限精度算术下的行为及其性质。该实验必须构造一个随机正交反射算子的乘积，该乘积会打乱数据，同时在理想情况下保持欧几里得成对距离，然后使用其转置进行重构以撤销打乱。最后，实验必须量化由浮点误差引入的漂移，这种漂移表现为 $Q^\\top Q$ 与单位矩阵的偏差。\n\n本实验的基本基础是以下一组关于欧几里得向量空间和正交变换的经过充分检验的定义和事实：\n- 正交矩阵保持欧几里得 $2$-范数以及向量间的欧几里得距离。\n- 反射算子（Householder 变换）是一种正交线性算子，它将一个向量映射到其关于一个与单位方向正交的超平面的反射。\n- 在精确算术中，正交矩阵的乘积是正交的。在浮点算术中，舍入和累积误差可能导致与精确正交性的微小偏差。\n\n您的程序必须：\n1. 生成一个实数矩阵 $X \\in \\mathbb{R}^{n \\times m}$，其列向量 $x_i$ 从标准正态分布中独立采样，并使用固定的随机种子以保证可复现性。\n2. 构造 $r$ 个随机反射算子并形成它们的乘积 $Q \\in \\mathbb{R}^{n \\times n}$，然后计算被打乱的数据 $Y = Q X$，其中列向量为 $y_i = Q x_i$。\n3. 计算以下三个量化指标：\n   - 正交性缺陷：$E_{\\mathrm{orth}} = \\lVert Q^\\top Q - I \\rVert_F$，其中 $\\lVert \\cdot \\rVert_F$ 表示 Frobenius 范数。\n   - 打乱后的最大相对成对距离误差：\n     $$E_{\\mathrm{dist}}^{\\mathrm{scramble}} = \\max_{1 \\le i  j \\le m} \\frac{\\left| \\lVert y_i - y_j \\rVert_2 - \\lVert x_i - x_j \\rVert_2 \\right|}{\\max(\\lVert x_i - x_j \\rVert_2, \\varepsilon)},$$\n     其中 $\\varepsilon$ 是一个小的正常数，取为双精度浮点数的机器精度，以确保分母接近零时的数值稳定性。\n   - 重构漂移：$E_{\\mathrm{recon}} = \\frac{\\lVert Q^\\top (Q X) - X \\rVert_F}{\\lVert X \\rVert_F}$。\n\n4. 对所有随机数生成使用固定的随机种子 $123456789$。\n\n5. 以符合其作为跨超平面正交反射的定义的方式，实现反射算子及其乘积的构造。不要依赖预构建的正交化例程；而是直接构造反射算子的乘积。\n\n6. 提供一个包含以下参数集 $(n,m,r)$ 的测试套件，这些参数集被选择用于检验各种行为，包括单位矩阵情况、单个和多个反射算子，以及为累积舍入误差而设置的大量反射算子的情况：\n   - 测试用例 A：$(n,m,r) = (8,20,0)$。\n   - 测试用例 B：$(n,m,r) = (32,50,32)$。\n   - 测试用例 C：$(n,m,r) = (64,80,320)$。\n   - 测试用例 D：$(n,m,r) = (16,40,1)$。\n\n7. 对于每个测试用例，按顺序计算并返回浮点数三元组 $(E_{\\mathrm{orth}}, E_{\\mathrm{dist}}^{\\mathrm{scramble}}, E_{\\mathrm{recon}})$。\n\n您的程序应生成单行输出，其中包含所有测试用例的结果，格式为方括号括起来的逗号分隔列表。列表必须先包含测试 A 的三个浮点数，然后是测试 B 的三个浮点数，接着是测试 C 的三个浮点数，最后是测试 D 的三个浮点数，并保持所述顺序；即，输出必须为以下形式\n$[E_{\\mathrm{orth}}^{A}, E_{\\mathrm{dist}}^{\\mathrm{scramble},A}, E_{\\mathrm{recon}}^{A}, E_{\\mathrm{orth}}^{B}, E_{\\mathrm{dist}}^{\\mathrm{scramble},B}, E_{\\mathrm{recon}}^{B}, E_{\\mathrm{orth}}^{C}, E_{\\mathrm{dist}}^{\\mathrm{scramble},C}, E_{\\mathrm{recon}}^{C}, E_{\\mathrm{orth}}^{D}, E_{\\mathrm{dist}}^{\\mathrm{scramble},D}, E_{\\mathrm{recon}}^{D}]$。\n不涉及物理单位；所有值都是无量纲的实数。",
            "solution": "问题陈述是一个在数值线性代数领域中有效且适定的数值实验。它在科学上基于正交变换理论和有限精度算术的实践现实。目标明确，所有必要的参数和定义都已提供，并且设置是可复现的。因此，我们可以着手解决问题。\n\n该实验旨在研究作为 Householder 反射算子乘积构造的正交矩阵的性质。一个 Householder 反射算子，或称 Householder 变换，是形为\n$$H = I - 2vv^\\top$$\n的正交矩阵，其中 $v$ 是一个欧几里得范数 $\\lVert v \\rVert_2 = 1$ 的列向量。在几何上，$H$ 将向量关于与 $v$ 正交的超平面进行反射。由于是正交的，$H$ 满足 $H^\\top H = H H^\\top = I$ 并且保持欧几里得范数和距离，即对于任何向量 $x$，都有 $\\lVert Hx \\rVert_2 = \\lVert x \\rVert_2$。\n\n该实验涉及以下关键步骤：\n\n**1. 随机反射算子及其乘积的生成**\n对于要构造的 $r$ 个反射算子中的每一个，我们首先生成一个随机向量 $u \\in \\mathbb{R}^n$，其分量从标准正态分布中抽取。然后将该向量归一化以产生单位向量 $v = u / \\lVert u \\rVert_2$。这个向量 $v$ 定义了第 $k$ 个反射算子 $H_k = I - 2v_k v_k^\\top$，其中 $k \\in \\{1, 2, \\dots, r\\}$。\n总变换矩阵 $Q$ 是这 $r$ 个反射算子的乘积：\n$$Q = H_r H_{r-1} \\cdots H_1$$\n在精确算术中，正交矩阵的乘积本身也是正交的。因此，理论上，$Q^\\top Q = I$。该数值实验将评估由于浮点误差导致的与此恒等式的偏差。矩阵 $Q$ 是迭代构造的，从单位矩阵 $Q_0 = I$ 开始，并依次应用每个反射算子：$Q_k = H_k Q_{k-1}$，其中 $k=1, \\dots, r$。最终的矩阵是 $Q = Q_r$。对于 $r=0$ 的基本情况，不应用任何变换，$Q$ 保持为单位矩阵 $I$。\n\n**2. 数据生成与变换**\n生成一个数据矩阵 $X \\in \\mathbb{R}^{n \\times m}$，其 $m$ 个列向量中的每一个都是从标准正态分布中独立采样的 $\\mathbb{R}^n$ 向量。指定的固定随机种子 $123456789$ 确保了矩阵 $X$ 和随机反射算子的可复现性。然后将变换 $Q$ 应用于数据矩阵，以产生“被打乱”的数据 $Y = QX$。\n\n**3. 数值误差的量化**\n计算三个指标来量化有限精度算术的影响：\n\n   - **正交性缺陷，$E_{\\mathrm{orth}}$**：该指标衡量计算出的矩阵 $Q$ 与完全正交的偏离程度。它定义为 $Q^\\top Q$ 与单位矩阵 $I$ 之差的 Frobenius 范数：\n     $$E_{\\mathrm{orth}} = \\lVert Q^\\top Q - I \\rVert_F$$\n     在完美的理论设置中，$E_{\\mathrm{orth}}$ 将为 $0$。非零值归因于在构造 $Q$ 期间浮点舍入误差的累积。\n\n   - **最大相对成对距离误差，$E_{\\mathrm{dist}}^{\\mathrm{scramble}}$**：由于正交变换必须保持欧几里得距离，因此 $X$ 的任意两列 $x_i$ 和 $x_j$ 之间的距离应与 $Y$ 的相应两列 $y_i$ 和 $y_j$ 之间的距离相同。该指标捕获了所有列对的成对距离中的最大相对误差：\n     $$E_{\\mathrm{dist}}^{\\mathrm{scramble}} = \\max_{1 \\le i  j \\le m} \\frac{\\left| \\lVert y_i - y_j \\rVert_2 - \\lVert x_i - x_j \\rVert_2 \\right|}{\\max(\\lVert x_i - x_j \\rVert_2, \\varepsilon)}$$\n     在此，$\\varepsilon$ 是双精度浮点数的机器精度，用于防止除以接近零的分母。任何非零值都表示与理想距离保持性质的偏离。\n\n   - **重构漂移，$E_{\\mathrm{recon}}$**：正交矩阵 $Q$ 的逆是其转置 $Q^\\top$。因此，将 $Q^\\top$ 应用于被打乱的数据 $Y$ 应该能重构出原始数据 $X$，即 $Q^\\top Y = Q^\\top(QX) = (Q^\\top Q)X = IX = X$。该指标量化了此重构过程中的相对误差：\n     $$E_{\\mathrm{recon}} = \\frac{\\lVert Q^\\top Y - X \\rVert_F}{\\lVert X \\rVert_F} = \\frac{\\lVert Q^\\top (Q X) - X \\rVert_F}{\\lVert X \\rVert_F}$$\n     这个值衡量了与完美重构的漂移，并由原始数据的大小进行归一化。它受到计算出的 $Q$ 的非正交性以及两次连续的矩阵-矩阵乘法所累积的误差的影响。\n\n实现将通过迭代给定的参数集 $(n,m,r)$ 来进行，为每个参数集执行这些计算步骤，并收集结果三元组 $(E_{\\mathrm{orth}}, E_{\\mathrm{dist}}^{\\mathrm{scramble}}, E_{\\mathrm{recon}})$。对于 $r=0$ 的测试用例，我们预计所有三个误差指标都将精确为 $0$，因为 $Q$ 将是单位矩阵，并且不会有来自变换的浮点误差累积。对于 $r  0$ 的情况，我们预计会出现非零误差，并且这些误差会随着反射算子数量 $r$ 的增加而增加，因为更多的运算会导致更大的累积误差。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial.distance import pdist\n\ndef solve():\n    \"\"\"\n    Implements a numerical experiment to study the properties of reflectors\n    under finite-precision arithmetic.\n    \"\"\"\n\n    # Fixed random seed for reproducibility as required by the problem statement.\n    seed = 123456789\n    rng = np.random.default_rng(seed)\n\n    # Machine epsilon for double precision, for numerical stability.\n    epsilon = np.finfo(np.float64).eps\n\n    # Test cases defined by the parameter sets (n, m, r).\n    test_cases = [\n        (8, 20, 0),    # Test case A\n        (32, 50, 32),   # Test case B\n        (64, 80, 320),  # Test case C\n        (16, 40, 1),    # Test case D\n    ]\n\n    results = []\n    for n, m, r in test_cases:\n        # 1. Generate the real data matrix X.\n        X = rng.standard_normal(size=(n, m))\n\n        # 2. Construct the product of r random reflectors, Q.\n        Q = np.identity(n)\n        for _ in range(r):\n            # Generate a random vector u from a standard normal distribution.\n            u = rng.standard_normal(size=(n, 1))\n            \n            # Normalize u to get a unit vector v.\n            norm_u = np.linalg.norm(u)\n            # In the unlikely event norm_u is 0, skip this reflector.\n            if norm_u == 0:\n                continue\n            v = u / norm_u\n            \n            # Construct the Householder reflector H = I - 2*v*v^T.\n            H = np.identity(n) - 2 * (v @ v.T)\n            \n            # Apply the new reflector to the product Q.\n            # Q_new = H_k * Q_old, so Q = H_r * ... * H_1 * I\n            Q = H @ Q\n\n        # Compute the scrambled data Y = QX.\n        Y = Q @ X\n\n        # 3. Compute the three quantitative metrics.\n\n        # Orthogonality defect: E_orth = ||Q^T Q - I||_F\n        e_orth = np.linalg.norm(Q.T @ Q - np.identity(n), 'fro')\n\n        # Maximum relative pairwise-distance error: E_dist\n        if m > 1:\n            # pdist computes pairwise distances between rows. We need it for columns.\n            dists_x = pdist(X.T, metric='euclidean')\n            dists_y = pdist(Y.T, metric='euclidean')\n            \n            abs_diff = np.abs(dists_y - dists_x)\n            denominator = np.maximum(dists_x, epsilon)\n            \n            # Handle the case where all pairwise distances are zero.\n            if np.all(denominator == epsilon):\n                e_dist = 0.0\n            else:\n                rel_errors = abs_diff / denominator\n                e_dist = np.max(rel_errors)\n        else:\n            e_dist = 0.0 # No pairs to compare if m = 1.\n\n        # Reconstruction drift: E_recon = ||Q^T (QX) - X||_F / ||X||_F\n        norm_X_fro = np.linalg.norm(X, 'fro')\n        # norm_X_fro will be non-zero with virtual certainty for the given parameters.\n        if norm_X_fro == 0:\n            e_recon = 0.0\n        else:\n            e_recon = np.linalg.norm(Q.T @ Y - X, 'fro') / norm_X_fro\n\n        results.extend([e_orth, e_dist, e_recon])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "最后的实践练习  将带我们深入到算法实现的最底层，探讨在现代并行计算架构（如图形处理器GPU）上高效且精确地应用反射变换的挑战。本练习分为两个部分：首先，您将分析不同内存布局（列主序与行主序）对访存模式的影响，并量化“合并访问”（coalesced access）的效率，这是决定GPU计算性能的关键因素。其次，您将比较两种不同的求和算法——顺序累加和配对（平衡）递归求和——在计算反射变换所需的核心点积操作时的数值稳定性差异。通过这个练习，您将深刻体会到算法设计、硬件特性与数值精度三者之间错综复杂的相互作用。",
            "id": "3572864",
            "problem": "您需要从第一性原理出发，对数值线性代数中的反射器进行推理，然后实现一个程序，用于评估对反射器进行批处理应用时的图形处理器（GPU）执行的简化模型。请使用纯数学术语，并明确推导出内存访问模式和舍入误差模型。只能使用以下基本依据：Householder反射器的定义、用于矩阵更新的线性代数恒等式、带有单位舍入量的浮点舍入基本模型，以及用于行主序和列主序数组存储的简单地址函数模型。除此处定义的内容外，不要假设任何专门的硬件行为。\n\nHouseholder反射器的定义如下。给定一个非零向量 $v \\in \\mathbb{R}^m$，定义\n$$\n\\tau \\equiv \\frac{2}{v^\\top v}, \\qquad H \\equiv I - \\tau \\, v v^\\top.\n$$\n在精确算术中，$H$ 是正交且对称的。将 $H$ 左乘于一个分块 $A \\in \\mathbb{R}^{m \\times n}$ 可由下式给出\n$$\nA \\leftarrow H A = A - \\tau \\, v \\left(v^\\top A\\right),\n$$\n该过程可分解为计算 $w \\equiv v^\\top A \\in \\mathbb{R}^{1 \\times n}$，然后进行一次秩-1更新 $A \\leftarrow A - \\tau \\, v w$。\n\n您必须完成两项任务：\n\n1) 为将 $H$ 应用于分块推导并实现一个内存访问模型，并量化合并访问。假设分块以标量扁平数组的形式存储，具有以下两种布局之一：\n\n- 列主序：按元素的地址函数\n$$\n\\operatorname{addr}_{\\mathrm{col}}(i,j,b) \\equiv b \\cdot \\operatorname{tile\\_stride}_{\\mathrm{col}} + i + j \\cdot \\operatorname{ld}, \\qquad \\operatorname{tile\\_stride}_{\\mathrm{col}} \\equiv \\operatorname{ld} \\cdot n,\n$$\n其中行索引 $i \\in \\{0,\\dots,m-1\\}$，列索引 $j \\in \\{0,\\dots,n-1\\}$，批次索引 $b \\in \\{0,\\dots,B-1\\}$，领头维度 $\\operatorname{ld} \\ge m$。\n\n- 行主序：按元素的地址函数\n$$\n\\operatorname{addr}_{\\mathrm{row}}(i,j,b) \\equiv b \\cdot \\operatorname{tile\\_stride}_{\\mathrm{row}} + j + i \\cdot \\operatorname{ld}, \\qquad \\operatorname{tile\\_stride}_{\\mathrm{row}} \\equiv \\operatorname{ld} \\cdot m,\n$$\n领头维度 $\\operatorname{ld} \\ge n$。\n\n假设标量类型为单精度，因此每个元素占用 $4$ 字节，规范的全局内存事务（在本模型中即“缓存行”粒度）为 $128$ 字节，等于 $32$ 个标量。一个warp由 $32$ 个线程组成。考虑 $w = v^\\top A$ 的评估，对于固定的列索引 $j$，该操作读取元素 $\\{ A(i,j) : i = 0,1,\\dots,m-1 \\}$。将一个warp建模为在固定的列 $j$ 和固定的批次 $b$ 下，读取索引 $i = 0,1,\\dots,\\min(31,m-1)$ 的线程。对于每个这样的访问组，将被访问的缓存行索引集合定义为\n$$\n\\mathcal{L} \\equiv \\left\\{ \\left\\lfloor \\frac{\\operatorname{addr}(i,j,b)}{32} \\right\\rfloor : i \\in \\{0,\\dots,\\min(31,m-1)\\} \\right\\}.\n$$\n此处 $\\operatorname{addr}$ 根据布局为 $\\operatorname{addr}_{\\mathrm{col}}$ 或 $\\operatorname{addr}_{\\mathrm{row}}$，除数 $32$ 将元素地址转换为以标量为单位的缓存行索引。将活动线程数定义为 $t_\\mathrm{act} \\equiv \\min(32, m)$，并将该组的合并访问效率定义为\n$$\nE(j,b) \\equiv \\frac{t_\\mathrm{act} / |\\mathcal{L}|}{32}.\n$$\n将此值在所有列和批次上取平均：\n$$\nE_{\\mathrm{avg}} \\equiv \\frac{1}{n B} \\sum_{b=0}^{B-1} \\sum_{j=0}^{n-1} E(j,b).\n$$\n您必须为每个测试用例计算 $E_{\\mathrm{avg}}$。除了上述地址函数所隐含的对齐方式外，不要假设任何额外的对齐。\n\n2) 通过对比在浮点运算中计算 $w = v^\\top A$ 的两种累加顺序，评估在 $Q$ 形成过程中内存访问合并与舍入误差累积的关联性。使用单精度（IEEE 754 32位浮点数）进行计算。设单位舍入量为 $u$（您无需显式计算 $u$）。考虑将 $k$ 个反射器左乘于初始分块 $Q_0 \\in \\mathbb{R}^{m \\times n}$ 来形成 $Q$，其中 $Q_0$ 是单位矩阵 $I_m$ 的前 $n$ 列。反射器由一个可复现的、确定性的向量序列 $v_1,\\dots,v_k \\in \\mathbb{R}^m$ 及其对应的 $\\tau_\\ell \\equiv 2/(v_\\ell^\\top v_\\ell)$ 构建，使得在精确算术中，结果的列向量将是标准正交的。在形成 $Q_\\ell = Q_{\\ell-1} - \\tau_\\ell v_\\ell w_\\ell$ 时，为计算 $w_\\ell = v_\\ell^\\top Q_{\\ell-1}$ 实现两种方案：\n\n- 顺序累加：对于列向量 $q$，通过对 $i = 0,\\dots,m-1$ 进行从左到右的循环，以单精度标量更新的方式计算每个点积 $v_\\ell^\\top q$。\n\n- 成对（平衡）归约：通过在一个平衡二叉树中递归地对乘积求和来计算每个点积，从而相对于顺序循环减少数值误差。\n\n以单精度计算每种方案得到的最终 $Q$，然后报告弗罗贝尼乌斯范数正交性缺陷\n$$\n\\rho \\equiv \\left\\| Q^\\top Q - I_n \\right\\|_F,\n$$\n其中，为计算 $\\rho$ 所需的范数和矩阵乘积应在双精度下进行评估，以便在没有进一步污染的情况下测量单精度结果的缺陷。\n\n随机性与确定性。对于每个从零开始的索引为 $s \\in \\{0,1,\\dots\\}$ 的测试用例，使用种子 $1234567 + s$ 初始化一个伪随机数生成器，并生成 $k$ 个独立向量 $v_\\ell$，其分量从标准正态分布中抽取。在 $Q$ 的形成过程中，所有计算均使用单精度。对于给定的测试用例，在两种累加方案中使用相同的 $\\{v_\\ell\\}$。\n\n测试套件。实现您的程序以评估以下五个测试用例，每个用例都是一个元组 $(m,n,k,\\operatorname{layout},\\operatorname{ld},B)$，其中 $\\operatorname{layout} \\in \\{\\text{列主序}, \\text{行主序}\\}$，B是批处理大小：\n\n- 用例 A: $(m,n,k,\\operatorname{layout},\\operatorname{ld},B) = (64, 8, 32, \\text{列主序}, 64, 1)$。\n- 用例 B: $(64, 8, 32, \\text{行主序}, 8, 1)$。\n- 用例 C: $(128, 16, 64, \\text{列主序}, 160, 2)$。\n- 用例 D: $(128, 16, 64, \\text{行主序}, 192, 2)$。\n- 用例 E: $(24, 6, 12, \\text{行主序}, 8, 3)$。\n\n每个测试用例的必需输出。对于每个测试用例，计算并返回一个包含三个浮点数的列表\n$$\n\\left[E_{\\mathrm{avg}}, \\; \\rho_{\\mathrm{seq}}, \\; \\rho_{\\mathrm{pair}}\\right],\n$$\n其中 $E_{\\mathrm{avg}}$ 是上面定义的合并访问效率，$\\rho_{\\mathrm{seq}}$ 是顺序累加方案的正交性缺陷，$\\rho_{\\mathrm{pair}}$ 是成对方案的正交性缺陷。\n\n最终输出格式。您的程序应生成一行输出，其中包含所有五个测试用例的结果，格式为方括号括起来的逗号分隔列表，其中每个元素本身是按上述顺序排列的、包含三个浮点数的列表，且不含空格。例如，一个有效的输出格式是\n$$\n\\text{[}[e_1,\\rho_{1,\\mathrm{seq}},\\rho_{1,\\mathrm{pair}}],[e_2,\\rho_{2,\\mathrm{seq}},\\rho_{2,\\mathrm{pair}}],\\dots\\text{]}.\n$$\n不应打印任何额外文本。此问题不涉及角度；不涉及物理单位，所有量均为无量纲实数。",
            "solution": "该问题经评估是有效的。它在科学上是合理的、良构的，并包含了获得唯一、可验证解所需的所有信息。该问题要求开发两个与Householder反射器应用相关的不同模型，Householder反射器是数值线性代数中的一个基本工具。第一部分涉及在简化的GPU模型中分析内存访问模式，第二部分涉及比较两种不同向量点积求和算法的数值稳定性。\n\n### 第1部分：内存访问合并效率 ($E_{\\mathrm{avg}}$)\n\n目标是在计算 $w = v^\\top A$ 过程中访问矩阵分块 $A \\in \\mathbb{R}^{m \\times n}$ 的元素时，推导并计算平均内存合并效率 $E_{\\mathrm{avg}}$。我们将一个由32个线程组成的warp访问分块第一列的情况进行建模。具体来说，对于固定的列 $j$ 和批次 $b$，这些线程访问元素 $A(i,j,b)$，其线程索引对应于行索引 $i \\in \\{0, \\dots, \\min(31, m-1)\\}$。\n\n在这样一个warp中，活动线程的数量为 $t_{\\mathrm{act}} \\equiv \\min(32, m)$。该访问组的效率定义为 $E(j,b) \\equiv \\frac{t_\\mathrm{act} / |\\mathcal{L}|}{32}$，其中 $|\\mathcal{L}|$ 是访问的唯一128字节缓存行的数量。由于每个单精度标量占用4字节，一个缓存行包含32个标量。被访问的缓存行索引集合是\n$$\n\\mathcal{L} \\equiv \\left\\{ \\left\\lfloor \\frac{\\operatorname{addr}(i,j,b)}{32} \\right\\rfloor : i \\in \\{0,\\dots,t_{\\mathrm{act}}-1\\} \\right\\}\n$$\n最终的度量指标是在所有列和批次上的平均效率：\n$$\nE_{\\mathrm{avg}} \\equiv \\frac{1}{n B} \\sum_{b=0}^{B-1} \\sum_{j=0}^{n-1} E(j,b)\n$$\n$|\\mathcal{L}|$ 的计算取决于存储布局。\n\n**列主序布局**\n批次 $b$ 中元素 $(i,j)$ 的地址由下式给出：\n$$\n\\operatorname{addr}_{\\mathrm{col}}(i,j,b) \\equiv b \\cdot (\\operatorname{ld} \\cdot n) + i + j \\cdot \\operatorname{ld}\n$$\n对于固定的批次 $b$ 和列 $j$，warp访问的地址为：\n$$\n\\operatorname{addr}_{\\mathrm{col}}(i,j,b) = C_{j,b} + i, \\quad \\text{for } i \\in \\{0, \\dots, t_{\\mathrm{act}}-1\\}\n$$\n其中 $C_{j,b} \\equiv b \\cdot \\operatorname{ld} \\cdot n + j \\cdot \\operatorname{ld}$ 是一个常量偏移。内存访问是连续的。缓存行索引的集合是 $\\mathcal{L} = \\{ \\lfloor (C_{j,b}+i)/32 \\rfloor : i=0, \\dots, t_{\\mathrm{act}}-1 \\}$。由于地址是顺序的，唯一缓存行的数量由最后一次访问和第一次访问的行索引之差再加一给出：\n$$\n|\\mathcal{L}| = \\left\\lfloor \\frac{C_{j,b} + t_{\\mathrm{act}}-1}{32} \\right\\rfloor - \\left\\lfloor \\frac{C_{j,b}}{32} \\right\\rfloor + 1\n$$\n这种访问模式是高效的（合并的），因为连续的线程访问连续的内存位置。$|\\mathcal{L}|$ 会很小，通常是1或2，从而导致较高的 $E(j,b)$ 值。\n\n**行主序布局**\n批次 $b$ 中元素 $(i,j)$ 的地址由下式给出：\n$$\n\\operatorname{addr}_{\\mathrm{row}}(i,j,b) \\equiv b \\cdot (\\operatorname{ld} \\cdot m) + j + i \\cdot \\operatorname{ld}\n$$\n对于固定的批次 $b$ 和列 $j$，warp访问的地址为：\n$$\n\\operatorname{addr}_{\\mathrm{row}}(i,j,b) = C'_{j,b} + i \\cdot \\operatorname{ld}, \\quad \\text{for } i \\in \\{0, \\dots, t_{\\mathrm{act}}-1\\}\n$$\n其中 $C'_{j,b} \\equiv b \\cdot \\operatorname{ld} \\cdot m + j$。内存访问是跨步的，步长为 $\\operatorname{ld}$ 个元素。唯一缓存行的数量 $|\\mathcal{L}|$ 是集合 $\\{ \\lfloor (C'_{j,b} + i \\cdot \\operatorname{ld})/32 \\rfloor \\text{ for } i=0, \\dots, t_{\\mathrm{act}}-1 \\}$ 的基数。这个值对步长 $\\operatorname{ld}$ 高度敏感。如果 $\\operatorname{ld}$ 很大，每个线程可能会访问一个不同的缓存行，导致 $|\\mathcal{L}| \\approx t_{\\mathrm{act}}$ 和非常低的效率。这模拟了一个非合并的内存访问模式。\n\n实现将遍历 $b$ 和 $j$，根据指定的布局计算 $|\\mathcal{L}|$，计算 $E(j,b)$，并求出平均值 $E_{\\mathrm{avg}}$。\n\n### 第2部分：正交性中的数值误差\n\n第二个任务是量化在形成正交矩阵 $Q \\in \\mathbb{R}^{m \\times n}$ 过程中累积的数值误差。该过程从 $Q_0$（$m \\times m$ 单位矩阵的前 $n$ 列）开始，并相继应用 $k$ 个Householder反射器：\n$$\nQ_\\ell = H_\\ell Q_{\\ell-1} = Q_{\\ell-1} - \\tau_\\ell v_\\ell (v_\\ell^\\top Q_{\\ell-1}), \\quad \\ell = 1, \\dots, k\n$$\n所有形成 $Q$ 的计算都在单精度下执行。数值误差产生差异的核心操作是矩阵-向量积 $w_\\ell = v_\\ell^\\top Q_{\\ell-1}$ 的计算，它由 $n$ 个独立的点积组成。我们比较了两种累加方案。\n\n**方案1：顺序累加**\n对于 $Q_{\\ell-1}$ 的每一列 $q$，点积 $s = v_\\ell^\\top q$ 通过标准迭代循环计算为 $s = \\sum_{i=0}^{m-1} (v_\\ell)_i q_i$。在浮点运算中，这对应于 $s_0=0, s_{j+1} = \\operatorname{fl}(s_j + \\operatorname{fl}((v_\\ell)_j q_j))$。该方法的误差随 $m$ 增长。一个标准的误差模型表明，前向误差由一个与 $m \\cdot u$ 成正比的项所界定，其中 $u$ 是单位舍入量。\n\n**方案2：成对（平衡）归约**\n该方案通过递归地将项集一分为二并对结果求和来计算总和。对于一个项序列 $x_0, \\dots, x_{m-1}$，其和计算为 $S(x_0, \\dots, x_{m-1}) = S(x_0, \\dots, x_{\\lfloor m/2 \\rfloor-1}) + S(x_{\\lfloor m/2 \\rfloor}, \\dots, x_{m-1})$。基本情况是一个或零个元素的和。这种方法将计算图中最长路径上的顺序操作次数从 $m-1$ 减少到 $\\lceil \\log_2 m \\rceil$。因此，前向误差要小得多，其界限与 $\\log_2(m) \\cdot u$ 成正比。这种方法通常更精确。\n\n**正交性缺陷，$\\rho$**\n经过 $k$ 步后，我们在单精度下获得最终矩阵 $Q$（$Q_{\\mathrm{seq}}$ 或 $Q_{\\mathrm{pair}}$）。正交性的损失由缺陷 $\\rho \\equiv \\| Q^\\top Q - I_n \\|_F$ 来衡量。为了准确地测量单精度结果中的缺陷，此计算在双精度下执行：将 $Q$ 转换为双精度，然后计算矩阵乘积 $Q^\\top Q$ 和弗罗贝尼乌斯范数。\n\n每个测试用例的总体算法如下：\n1. 使用特定种子初始化一个伪随机数生成器。\n2. 生成 $k$ 个 `float32` 类型的向量 $v_1, \\dots, v_k \\in \\mathbb{R}^m$，其分量从标准正态分布中抽取。\n3. 对于顺序和成对方案：\n    a. 初始化 $Q = Q_0$ 为 $I_m$ 的前 $n$ 列。\n    b. 对于 $\\ell=1, \\dots, k$，使用来自 $v_\\ell$ 的反射器和对应的 $w_\\ell$ 累加方案来更新 $Q$。所有这些步骤都使用单精度。\n4. 对于每个结果矩阵 $Q_{\\mathrm{seq}}$ 和 $Q_{\\mathrm{pair}}$，在双精度下计算正交性缺陷 $\\rho_{\\mathrm{seq}}$ 和 $\\rho_{\\mathrm{pair}}$。\n5. 同时，根据内存模型计算平均合并效率 $E_{\\mathrm{avg}}$。\n6. 测试用例的最终结果是三元组 $[E_{\\mathrm{avg}}, \\rho_{\\mathrm{seq}}, \\rho_{\\mathrm{pair}}]$。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n\n    test_cases = [\n        # Case A: (m, n, k, layout, ld, B)\n        (64, 8, 32, 'column-major', 64, 1),\n        # Case B\n        (64, 8, 32, 'row-major', 8, 1),\n        # Case C\n        (128, 16, 64, 'column-major', 160, 2),\n        # Case D\n        (128, 16, 64, 'row-major', 192, 2),\n        # Case E\n        (24, 6, 12, 'row-major', 8, 3),\n    ]\n\n    all_results = []\n    for i, case in enumerate(test_cases):\n        result = run_test_case(case, s=i)\n        all_results.append(result)\n\n    # Format the final output string as specified, with no spaces.\n    results_str = [f\"[{res[0]},{res[1]},{res[2]}]\" for res in all_results]\n    print(f\"[{','.join(results_str)}]\")\n\n\ndef run_test_case(case, s):\n    \"\"\"\n    Runs a single test case, computing coalescing efficiency and orthogonality defects.\n    \"\"\"\n    m, n, k, layout, ld, B = case\n\n    # Task 1: Calculate average coalescing efficiency\n    e_avg = calculate_e_avg(m, n, layout, ld, B)\n\n    # Task 2: Calculate orthogonality defects\n    \n    # Setup for Q formation\n    rng = np.random.default_rng(1234567 + s)\n    # Generate all vectors v in single precision\n    v_vectors = rng.standard_normal(size=(k, m), dtype=np.float32)\n\n    # Run for sequential accumulation\n    rho_seq = form_q_and_get_defect(m, n, k, v_vectors, 'sequential')\n    \n    # Run for pairwise accumulation\n    rho_pair = form_q_and_get_defect(m, n, k, v_vectors, 'pairwise')\n\n    return [e_avg, rho_seq, rho_pair]\n\n\ndef calculate_e_avg(m, n, layout, ld, B):\n    \"\"\"\n    Calculates the average coalescing efficiency E_avg.\n    \"\"\"\n    t_act = min(32, m)\n    if t_act == 0:\n        return 0.0\n\n    total_e = 0.0\n    indices = np.arange(t_act, dtype=np.int64)\n\n    for b in range(B):\n        for j in range(n):\n            if layout == 'column-major':\n                tile_stride = ld * n\n                addr_base = b * tile_stride + j * ld\n                addrs = addr_base + indices\n            elif layout == 'row-major':\n                tile_stride = ld * m\n                addr_base = b * tile_stride + j\n                addrs = addr_base + indices * ld\n            else:\n                raise ValueError(\"Invalid layout specified\")\n\n            cache_lines = addrs // 32\n            num_unique_lines = len(np.unique(cache_lines))\n            \n            if num_unique_lines > 0:\n                e_jb = (t_act / num_unique_lines) / 32.0\n                total_e += e_jb\n\n    return total_e / (n * B) if (n * B > 0) else 0.0\n\n\ndef pairwise_sum_recursive(arr):\n    \"\"\"\n    Computes the sum of a 1D array using pairwise (balanced) reduction.\n    Assumes input `arr` is a NumPy array of dtype float32.\n    \"\"\"\n    n_elems = arr.shape[0]\n    if n_elems == 0:\n        return np.float32(0.0)\n    if n_elems == 1:\n        return arr[0]\n    \n    mid = n_elems // 2\n    return pairwise_sum_recursive(arr[:mid]) + pairwise_sum_recursive(arr[mid:])\n\n\ndef form_q_and_get_defect(m, n, k, v_vectors, mode):\n    \"\"\"\n    Forms the matrix Q by applying k reflectors and computes the orthogonality defect.\n    \"\"\"\n    \n    # Initialize Q0 as the first n columns of the identity matrix in single precision.\n    Q = np.zeros((m, n), dtype=np.float32)\n    Q[:n, :n] = np.eye(n, dtype=np.float32)\n\n    for i in range(k):\n        v = v_vectors[i]\n        \n        # Compute tau in single precision\n        v_dot_v = np.dot(v, v)\n        if v_dot_v == 0.0: continue\n        tau = np.float32(2.0) / v_dot_v\n        \n        # Compute w = v^T * Q\n        w = np.empty(n, dtype=np.float32)\n        if mode == 'sequential':\n            for j in range(n):\n                w[j] = np.dot(v, Q[:, j])\n        elif mode == 'pairwise':\n            for j in range(n):\n                products = v * Q[:, j]\n                w[j] = pairwise_sum_recursive(products)\n        \n        # Update Q - Q - tau * v * w^T\n        Q -= tau * np.outer(v, w)\n\n    # Compute defect in double precision\n    Q_dp = Q.astype(np.float64)\n    I_n_dp = np.eye(n, dtype=np.float64)\n    defect_matrix = Q_dp.T @ Q_dp - I_n_dp\n    rho = np.linalg.norm(defect_matrix, 'fro')\n    \n    return rho\n\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}