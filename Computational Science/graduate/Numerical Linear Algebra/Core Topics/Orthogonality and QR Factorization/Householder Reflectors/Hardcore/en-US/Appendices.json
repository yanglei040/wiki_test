{
    "hands_on_practices": [
        {
            "introduction": "The core application of Householder reflectors in numerical linear algebra is to selectively introduce zeros into a vector. This exercise provides fundamental, hands-on practice in constructing a reflector that transforms a vector into a multiple of a standard basis vector, a key step in QR factorization. Pay close attention to the choice of sign when defining the target vector, as this is not arbitrary but a crucial decision for ensuring the numerical stability of the algorithm .",
            "id": "3549727",
            "problem": "Consider the construction of a Householder reflector used in the Householder QR (orthogonal-triangular) factorization. Let $x \\in \\mathbb{R}^{4}$ be given by $x = \\begin{pmatrix} 3 \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix}$. Construct a Householder reflector of the form $H = I - \\tau v v^{\\mathsf{T}}$, with $\\tau \\in \\mathbb{R}$ and $v \\in \\mathbb{R}^{4}$, that maps $x$ to $\\alpha e_{1}$, where $e_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$ and $\\alpha \\in \\mathbb{R}$. Your construction should start from the fundamental characterization of Householder reflectors as orthogonal reflections across hyperplanes in $\\mathbb{R}^{n}$ and use only basic properties of orthogonal projections and norms. Adopt the standard sign convention for numerical stability in Householder QR construction when choosing $\\alpha$, justified from first principles, and verify by explicit computation that $H x = \\alpha e_{1}$. Give the exact value of $\\tau$ as a simplified rational number. Do not round.",
            "solution": "The problem statement is analyzed and found to be valid. It presents a standard, well-posed problem in numerical linear algebra, providing all necessary information and containing no scientific or logical inconsistencies.\n\nThe objective is to construct a Householder reflector $H$ of the form $H = I - \\tau v v^{\\mathsf{T}}$ that transforms a given vector $x$ into a multiple of the first standard basis vector $e_1$. The vector $x \\in \\mathbb{R}^{4}$ is given as $x = \\begin{pmatrix} 3 \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix}$. The target vector is $\\alpha e_{1}$, where $e_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$ and $\\alpha \\in \\mathbb{R}$.\n\nFirst, we establish the value of $\\alpha$. A Householder reflector $H$ is an orthogonal matrix, meaning $H^{\\mathsf{T}}H = I$. A fundamental property of orthogonal transformations is that they preserve the Euclidean norm (length) of a vector. Therefore, it must be that $\\|Hx\\|_2 = \\|x\\|_2$.\nThe Euclidean norm of $x$ is:\n$$ \\|x\\|_2 = \\sqrt{3^2 + 4^2 + 0^2 + 0^2} = \\sqrt{9 + 16} = \\sqrt{25} = 5 $$\nThe norm of the target vector $Hx = \\alpha e_1$ is:\n$$ \\|\\alpha e_1\\|_2 = |\\alpha| \\|e_1\\|_2 = |\\alpha| \\sqrt{1^2 + 0^2 + 0^2 + 0^2} = |\\alpha| \\cdot 1 = |\\alpha| $$\nEquating the norms, we get $|\\alpha| = 5$, which implies that $\\alpha$ can be either $5$ or $-5$.\n\nNext, we choose the sign of $\\alpha$ based on the standard convention for numerical stability. The Householder vector, which we will denote as $u$, is constructed from the difference between the original vector $x$ and its target image $\\alpha e_1$. This vector $u$ is normal to the hyperplane of reflection.\n$$ u = x - \\alpha e_1 $$\nA Householder transformation reflects $x$ across the hyperplane orthogonal to $u$. The transformation sends $x$ to $\\alpha e_1$.\nThe vector $u$ is given by:\n$$ u = \\begin{pmatrix} 3 \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix} - \\alpha \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 3 - \\alpha \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nFor numerical stability, it is crucial to avoid subtractive cancellation when computing the components of $u$. This can occur if we subtract two nearly equal floating-point numbers. In our case, the first component of $u$ is $u_1 = 3 - \\alpha$.\nLet's examine the two possible choices for $\\alpha$:\nIf we choose $\\alpha = 5$, then $u_1 = 3 - 5 = -2$.\nIf we choose $\\alpha = -5$, then $u_1 = 3 - (-5) = 8$.\nThe standard sign convention, designed to prevent loss of precision, is to choose the sign of $\\alpha$ to be the opposite of the sign of the corresponding component of $x$. This choice maximizes the magnitude of that component of $u$. The first component of $x$ is $x_1 = 3$, which is positive. Therefore, we should choose a negative $\\alpha$.\nThe general formula for this choice is $\\alpha = -\\text{sgn}(x_1)\\|x\\|_2$.\nApplying this, we get $\\alpha = -\\text{sgn}(3) \\cdot 5 = -1 \\cdot 5 = -5$.\nThis choice ensures that $x_1$ and $-\\alpha$ are added, maximizing the magnitude of $u_1$ and avoiding cancellation.\n\nWith $\\alpha = -5$, we construct the vector $u$:\n$$ u = x - (-5)e_1 = x + 5e_1 = \\begin{pmatrix} 3 \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix} + 5 \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 8 \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nThe Householder matrix is defined by $H = I - 2 \\frac{u u^{\\mathsf{T}}}{u^{\\mathsf{T}}u}$. The problem provides the form $H = I - \\tau v v^{\\mathsf{T}}$. By choosing the vector $v$ in the formula to be our constructed vector $u$, we can find $\\tau$.\nLet $v = u = \\begin{pmatrix} 8 \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix}$.\nThen the formula for $H$ becomes $H = I - \\tau v v^{\\mathsf{T}}$. Comparing this with the standard definition $H = I - 2 \\frac{v v^{\\mathsf{T}}}{v^{\\mathsf{T}}v}$, we identify $\\tau$ as:\n$$ \\tau = \\frac{2}{v^{\\mathsf{T}}v} = \\frac{2}{\\|v\\|_2^2} $$\nWe now compute $\\|v\\|_2^2$:\n$$ \\|v\\|_2^2 = v^{\\mathsf{T}}v = 8^2 + 4^2 + 0^2 + 0^2 = 64 + 16 = 80 $$\nThe value of $\\tau$ is therefore:\n$$ \\tau = \\frac{2}{80} = \\frac{1}{40} $$\n\nFinally, we verify by explicit computation that the constructed reflector $H = I - \\frac{1}{40} v v^{\\mathsf{T}}$ maps $x$ to $\\alpha e_1 = -5 e_1$.\n$$ Hx = (I - \\tau v v^{\\mathsf{T}})x = x - \\tau v (v^{\\mathsf{T}}x) $$\nWe first compute the inner product $v^{\\mathsf{T}}x$:\n$$ v^{\\mathsf{T}}x = \\begin{pmatrix} 8 & 4 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix} = (8)(3) + (4)(4) + (0)(0) + (0)(0) = 24 + 16 = 40 $$\nNow, we substitute this back into the expression for $Hx$:\n$$ Hx = x - \\tau v (40) = \\begin{pmatrix} 3 \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix} - \\frac{1}{40} \\begin{pmatrix} 8 \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix} (40) $$\n$$ Hx = \\begin{pmatrix} 3 \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 8 \\\\ 4 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 3 - 8 \\\\ 4 - 4 \\\\ 0 - 0 \\\\ 0 - 0 \\end{pmatrix} = \\begin{pmatrix} -5 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nThis result is exactly $\\alpha e_1 = -5 \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$, which verifies the correctness of our construction.\n\nThe value of $\\tau$ as a simplified rational number is $\\frac{1}{40}$.",
            "answer": "$$\\boxed{\\frac{1}{40}}$$"
        },
        {
            "introduction": "A true test of understanding is the ability to adapt a tool to a new situation. This problem challenges the standard recipe for QR factorization by asking you to build a reflector that targets the last component of a vector instead of the first . This exercise not only reinforces the geometric principles of reflection but also demonstrates how the same core idea can be used to derive related matrix decompositions, such as the QL factorization.",
            "id": "3240041",
            "problem": "Consider the task of constructing a Householder reflector that maps a given vector in $\\mathbb{R}^{m}$ to a scalar multiple of the last standard basis vector so that all entries except the last are zeroed. A Householder reflector is an orthogonal transformation defined as a reflection across the hyperplane orthogonal to some unit vector; it preserves Euclidean norms and can be used to orthogonalize matrices via the orthogonal-triangular (QR) factorization. In standard usage for QR, one maps a column vector to a multiple of the first basis vector to zero all entries below the first. Here, you will instead map to the last basis vector and adapt the factorization procedure accordingly.\n\nLet\n$$\nA \\in \\mathbb{R}^{4 \\times 3}, \\quad\nA =\n\\begin{pmatrix}\n6 & 0 & 2 \\\\\n-2 & 5 & -1 \\\\\n1 & -3 & 4 \\\\\n-4 & 2 & 0\n\\end{pmatrix},\n$$\nand let the first column be $x = \\begin{pmatrix} 6 \\\\ -2 \\\\ 1 \\\\ -4 \\end{pmatrix} \\in \\mathbb{R}^{4}$.\n\nUsing only the defining properties of Householder reflections (orthogonality, norm preservation, and reflection across a hyperplane orthogonal to a unit vector), derive a construction for a Householder reflector that transforms $x$ into a vector of the form $\\alpha e_{4}$, where $e_{4}$ is the fourth standard basis vector in $\\mathbb{R}^{4}$. Choose the sign of $\\alpha$ to avoid catastrophic cancellation in the construction. Briefly state how the column-wise orthogonal-triangular (QR) factorization must be adapted when using such “last-element” reflectors in successive steps on subproblems.\n\nThen, implement the first step by determining the exact value of the scalar $\\alpha$ for the given $x$. Your final answer must be the single closed-form expression for $\\alpha$. No rounding is required.",
            "solution": "The problem statement is critically validated and found to be valid. It is scientifically grounded in the established theory of numerical linear algebra, specifically concerning Householder transformations. The problem is well-posed, providing all necessary information—the matrix $A$, the vector $x$, and the target form of the transformation—to determine a unique, meaningful solution for the scalar $\\alpha$. The language is objective and unambiguous.\n\nWe begin by recalling the fundamental properties of a Householder reflector. A Householder transformation is a linear transformation $H$ that reflects a vector across a hyperplane. It is represented by a matrix of the form:\n$$\nH = I - 2vv^{\\mathsf{T}}\n$$\nwhere $v$ is a unit vector orthogonal to the hyperplane of reflection, and $I$ is the identity matrix. The matrix $H$ is both orthogonal ($H^{\\mathsf{T}} H = I$) and an involution ($H^2 = I$). A key property of any orthogonal transformation is that it preserves the Euclidean norm (the $\\ell_2$-norm) of a vector.\n\nThe problem requires constructing a Householder reflector $H$ that transforms a given vector $x \\in \\mathbb{R}^m$ into a vector $y$ that is a scalar multiple of the last standard basis vector $e_m$. In this specific problem, $m=4$, so $y$ must have the form $y = \\alpha e_4$ for some scalar $\\alpha \\in \\mathbb{R}$.\n\nSince $H$ is an orthogonal matrix, we must have $\\|Hx\\|_2 = \\|x\\|_2$. This implies:\n$$\n\\|y\\|_2 = \\|x\\|_2\n$$\nWe can compute the norm of $y$:\n$$\n\\|y\\|_2 = \\|\\alpha e_4\\|_2 = |\\alpha| \\|e_4\\|_2 = |\\alpha| \\cdot 1 = |\\alpha|\n$$\nTherefore, the magnitude of the scalar $\\alpha$ is determined by the norm of $x$:\n$$\n|\\alpha| = \\|x\\|_2 \\implies \\alpha = \\pm \\|x\\|_2\n$$\nThe vector $v$ defining the reflection hyperplane is chosen such that the reflection of $x$ results in $y$. The vector connecting the original point $x$ to the reflected point $y$, which is $x-y$, must be orthogonal to the reflection hyperplane. Thus, $v$ must be parallel to $x-y$. We define a vector $u = x - y$. The unit vector $v$ is then given by $v = \\frac{u}{\\|u\\|_2}$. The Householder matrix is typically expressed in terms of $u$ as:\n$$\nH = I - \\frac{2}{u^{\\mathsf{T}} u} u u^{\\mathsf{T}}\n$$\nFor our specific problem, $x = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix}$ and $y = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ \\alpha \\end{pmatrix}$. The vector $u$ is:\n$$\nu = x - y = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 - \\alpha \\end{pmatrix}\n$$\nA crucial aspect of the construction is numerical stability. If we compute the last component of $u$, $u_4 = x_4 - \\alpha$, and if $x_4$ and $\\alpha$ are nearly equal (which implies they have the same sign, as $|\\alpha| = \\|x\\|_2 \\ge |x_4|$), we would face catastrophic cancellation, leading to a loss of significant digits and numerical instability. To prevent this, we must choose the sign of $\\alpha$ to maximize the magnitude of $u_4$. This is achieved by selecting the sign of $\\alpha$ to be the opposite of the sign of $x_4$. The standard robust formula for $\\alpha$ is thus:\n$$\n\\alpha = -\\text{sgn}(x_4) \\|x\\|_2\n$$\nwhere $\\text{sgn}(z)$ is the sign function. If $x_4=0$, the sign can be chosen arbitrarily, often as $+1$ by convention.\n\nRegarding the adaptation of the QR factorization process, a standard algorithm uses Householder reflectors to introduce zeros into a matrix column *below* the main diagonal. For an $m \\times n$ matrix $A$, a sequence of reflectors $H_1, H_2, \\dots, H_{\\min(m-1, n)}$ is applied, resulting in $H_k \\dots H_1 A = R$, where $R$ is an upper triangular matrix. This yields the factorization $A=QR$, with $Q = H_1 \\dots H_k$.\n\nIf we use the \"last-element\" reflectors as described, the procedure is altered. In the first step, we apply a reflector $H_1$ to the first column of $A$ to zero out all entries except the last one. In the second step, we consider the $(m-1) \\times (n-1)$ submatrix in the upper-left corner and apply a reflector to its first column to zero out all entries except its last one (which corresponds to the $(m-1)$-th entry of the second column of the full transformed matrix). Continuing this process generates a *lower* triangular matrix, let's call it $L$. The resulting factorization is $A=QL$, where $Q$ is orthogonal and $L$ is lower triangular. This is known as a QL factorization, which is a different but equally valid matrix decomposition.\n\nNow, we apply this to the specific vector provided in the problem:\n$$\nx = \\begin{pmatrix} 6 \\\\ -2 \\\\ 1 \\\\ -4 \\end{pmatrix}\n$$\nFirst, we compute the Euclidean norm of $x$:\n$$\n\\|x\\|_2 = \\sqrt{6^2 + (-2)^2 + 1^2 + (-4)^2} = \\sqrt{36 + 4 + 1 + 16} = \\sqrt{57}\n$$\nThe fourth component of $x$ is $x_4 = -4$.\nThe sign of $x_4$ is $\\text{sgn}(-4) = -1$.\nUsing the formula derived for numerical stability, we determine the value of $\\alpha$:\n$$\n\\alpha = -\\text{sgn}(x_4) \\|x\\|_2 = -(-1) \\sqrt{57} = \\sqrt{57}\n$$\nThis choice ensures that the fourth component of the vector $u = x - \\alpha e_4$ is $u_4 = -4 - \\sqrt{57}$, where the magnitudes add, avoiding cancellation. The reflector constructed with this $\\alpha$ will transform $x$ to $(0, 0, 0, \\sqrt{57})^{\\mathsf{T}}$.\n\nThe final answer required is the exact value of $\\alpha$.",
            "answer": "$$\n\\boxed{\\sqrt{57}}\n$$"
        },
        {
            "introduction": "Many powerful algorithms in linear algebra generalize elegantly from real to complex vector spaces, a transition essential in fields like quantum mechanics and signal processing. This problem explores the extension of the Householder tridiagonalization method to complex Hermitian matrices . You will need to consider how concepts like orthogonality and symmetry are generalized to unitarity and Hermitian structure, and how the construction of the reflector itself must be adapted for complex arithmetic.",
            "id": "2401954",
            "problem": "In computational physics, Householder transformations are used to reduce a matrix to tridiagonal form before eigenvalue computations. Consider applying the Householder tridiagonalization algorithm to an input matrix $A \\in \\mathbb{C}^{n \\times n}$. In the standard real case, $A$ is real symmetric, meaning $A^{\\mathsf{T}} = A$, and one uses orthogonal Householder reflections to compute a tridiagonal $T$ such that $Q^{\\mathsf{T}} A Q = T$ with $Q$ orthogonal. What happens if the input matrix $A$ is complex Hermitian, meaning $A^{*} = A$, instead of real symmetric?\n\nSelect the option that most accurately describes the correct behavior and necessary modifications.\n\nA. The algorithm fails because Householder reflectors are only defined over $\\mathbb{R}$. For complex Hermitian matrices, a different class of transformations must be used.\n\nB. The algorithm proceeds analogously by using unitary Householder reflectors $H = I - \\dfrac{2 v v^{*}}{v^{*} v}$ constructed with a phase choice so that $H x = \\alpha e_{1}$ for a column segment $x$, where $\\alpha = -\\mathrm{e}^{\\mathrm{i}\\phi} \\lVert x \\rVert_{2}$ with $\\phi = \\arg(x_{1})$. One applies the unitary similarity $A \\leftarrow H^{*} A H$ (which equals $H A H$ because $H$ is Hermitian), preserving the Hermitian structure and yielding a Hermitian tridiagonal matrix; if desired, additional diagonal unitary scalings can make subdiagonals real. The arithmetic cost remains $\\mathcal{O}(n^{3})$ up to complex-versus-real constant factors.\n\nC. One must switch to Givens rotations because Householder transformations destroy Hermitian structure in the complex case; using Householder updates would generally produce a non-Hermitian banded matrix.\n\nD. No changes are required at all: use the same real formulas and transposes, and the result is a real tridiagonal matrix even if $A$ is complex.\n\nE. The Householder procedure still works but its computational complexity increases from $\\mathcal{O}(n^{3})$ to $\\mathcal{O}(n^{4})$ because complex arithmetic requires nested similarity updates.",
            "solution": "The problem statement will first be validated for scientific soundness, self-consistency, and clarity.\n\n### Step 1: Extract Givens\n\n-   **Context**: Householder tridiagonalization of a matrix $A \\in \\mathbb{C}^{n \\times n}$ in computational physics.\n-   **Input Matrix Property**: $A$ is complex Hermitian, satisfying $A^{*} = A$, where $A^{*}$ is the conjugate transpose of $A$.\n-   **Analogy**: The standard algorithm for a real symmetric matrix ($A^{\\mathsf{T}} = A$) uses orthogonal Householder reflections to compute a tridiagonal matrix $T$ via an orthogonal similarity transformation $Q^{\\mathsf{T}} A Q = T$.\n-   **Question**: What is the correct behavior and what modifications are necessary for a complex Hermitian input matrix $A$?\n\n### Step 2: Validate Using Extracted Givens\n\n-   **Scientific Grounding**: The problem is grounded in the well-established field of numerical linear algebra, a cornerstone of computational science and physics. The extension of real matrix algorithms, such as Householder tridiagonalization, to complex matrices (specifically Hermitian) is a standard and fundamental topic. All concepts—Hermitian matrices, unitary transformations, Householder reflectors, and computational complexity—are rigorously defined. The problem is scientifically sound.\n-   **Well-Posedness**: The question is well-posed. It asks for the correct adaptation of a standard algorithm to a more general but well-defined case. A unique and correct procedure exists and is taught in standard literature on the subject.\n-   **Objectivity**: The problem is stated in precise, objective mathematical language. It is free from ambiguity, subjectivity, or non-scientific claims.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is a standard, well-posed question in numerical linear algebra. The solution will proceed by deriving the correct method and evaluating the given options.\n\n### Solution Derivation\n\nThe goal of tridiagonalization is to find a similarity transformation that converts a dense matrix into a tridiagonal one, preserving its eigenvalues. For a real symmetric matrix $A$ ($A^{\\mathsf{T}} = A$), the transformation must be orthogonal ($Q^{\\mathsf{T}}Q = I$) to preserve symmetry, since $(Q^{\\mathsf{T}}AQ)^{\\mathsf{T}} = Q^{\\mathsf{T}}A^{\\mathsf{T}}Q = Q^{\\mathsf{T}}AQ$.\n\nFor a complex Hermitian matrix $A$ ($A^{*} = A$), the analogous property to preserve is the Hermitian structure. The class of transformations that preserves eigenvalues and Hermitian structure are unitary similarity transformations. A matrix $U$ is unitary if $U^{*}U=I$. Applying such a transformation $A \\rightarrow U^{*}AU$ preserves the Hermitian property:\n$$\n(U^{*}AU)^{*} = U^{*}A^{*}(U^{*})^{*} = U^{*}AU\n$$\nThis confirms that a sequence of unitary similarity transformations must be used.\n\nThe Householder reflector is the elementary transformation of choice. A real Householder reflector is an orthogonal matrix. Its generalization to the complex space must be a unitary matrix. The complex Householder reflector that maps a vector $x \\in \\mathbb{C}^{m}$ to a multiple of the first standard basis vector $e_1$ has the form:\n$$\nH = I - \\beta v v^{*}\n$$\nwhere $v \\in \\mathbb{C}^{m}$ is the Householder vector and $\\beta$ is a scalar. For $H$ to be unitary, we require $H^{*}H = I$. First, for $H$ to be Hermitian ($H=H^{*}$), $\\beta$ must be real. Assuming this, we find:\n$$\nH^2 = (I - \\beta v v^{*})(I - \\beta v v^{*}) = I - 2\\beta v v^{*} + \\beta^2 v v^{*} v v^{*} = I - (2\\beta - \\beta^2(v^{*}v))v v^{*}\n$$\nFor $H^2=I$, we need $2\\beta - \\beta^2(v^{*}v) = 0$. For a non-trivial reflection ($\\beta \\neq 0$), this implies $\\beta = \\frac{2}{v^{*}v}$. Thus, the unitary and Hermitian Householder reflector is:\n$$\nH = I - \\frac{2 v v^{*}}{v^{*}v}\n$$\nThe algorithm proceeds in $n-2$ steps. At step $k$ ($k=1, \\dots, n-2$), we aim to introduce zeros in the $k$-th column below the first subdiagonal entry. Let the current matrix be $A_{k-1}$. We consider the subvector $x = A_{k-1}(k+1:n, k)$. We construct an $m \\times m$ ($m=n-k$) Householder reflector $H'_{k}$ to transform $x$. We require $H'_{k}x = \\alpha e_1$. Since $H'_{k}$ is unitary, it preserves the $L_2$-norm, so $|\\alpha| = \\lVert x \\rVert_2$. To avoid numerical instability from subtractive cancellation, $\\alpha$ is chosen to point in the opposite direction of the first component of $x$, $x_1$, in the complex plane. Let $x_1 = |x_1|e^{i\\phi}$. The optimal choice is $\\alpha = -e^{i\\phi}\\lVert x \\rVert_2$. The Householder vector is then $v = x - \\alpha e_1$.\n\nThe full $n \\times n$ transformation matrix is $H_k = \\mathrm{diag}(I_k, H'_{k})$. The matrix is updated via the similarity transformation $A_k = H_k^{*} A_{k-1} H_k$. Since $H_k$ is Hermitian ($H_k^{*} = H_k$), this simplifies to $A_k = H_k A_{k-1} H_k$. This transformation preserves the Hermitian structure of $A_{k-1}$ and introduces the desired zeros in both column $k$ and, by the Hermitian property, row $k$.\n\nAfter $n-2$ steps, the result is a Hermitian tridiagonal matrix $T$. The diagonal entries of any Hermitian matrix must be real. The off-diagonal entries $t_{j,j+1}$ can be complex, but must satisfy $t_{j+1,j} = \\overline{t_{j,j+1}}$. If a real symmetric tridiagonal matrix is required, a final diagonal unitary scaling $D = \\mathrm{diag}(d_1, \\dots, d_n)$ with $|d_i|=1$ can be applied: $T' = D^{*}TD$. The phases of the $d_i$ can be chosen sequentially to make all subdiagonal (and thus superdiagonal) elements real and non-negative.\n\nThe computational cost at each step $k$ is dominated by the update of the lower-right $(n-k) \\times (n-k)$ submatrix. This update can be performed efficiently in $\\mathcal{O}((n-k)^2)$ complex operations. Summing over all steps gives a total complexity of $\\sum_{k=1}^{n-2} c(n-k)^2 = \\mathcal{O}(n^3)$. The arithmetic is complex, so the constant factor is larger than in the real case, but the asymptotic complexity remains $\\mathcal{O}(n^3)$.\n\n### Option-by-Option Analysis\n\n**A. The algorithm fails because Householder reflectors are only defined over $\\mathbb{R}$. For complex Hermitian matrices, a different class of transformations must be used.**\nThis statement is false. As derived above, the Householder reflector has a standard and widely used generalization to complex vector spaces, which results in a unitary and Hermitian transformation matrix $H = I - 2vv^{*}/(v^{*}v)$. These are precisely the correct transformations for this problem.\n**Verdict: Incorrect.**\n\n**B. The algorithm proceeds analogously by using unitary Householder reflectors $H = I - \\dfrac{2 v v^{*}}{v^{*} v}$ constructed with a phase choice so that $H x = \\alpha e_{1}$ for a column segment $x$, where $\\alpha = -\\mathrm{e}^{\\mathrm{i}\\phi} \\lVert x \\rVert_{2}$ with $\\phi = \\arg(x_{1})$. One applies the unitary similarity $A \\leftarrow H^{*} A H$ (which equals $H A H$ because $H$ is Hermitian), preserving the Hermitian structure and yielding a Hermitian tridiagonal matrix; if desired, additional diagonal unitary scalings can make subdiagonals real. The arithmetic cost remains $\\mathcal{O}(n^{3})$ up to complex-versus-real constant factors.**\nThis option accurately describes the entire process. It correctly identifies the form of the unitary Householder reflector, the numerically stable phase choice for the transformation, the use of a unitary similarity transformation that preserves the Hermitian structure, the nature of the resulting matrix, the optional final scaling step, and the computational complexity. Every detail aligns with the standard algorithm for Hermitian tridiagonalization.\n**Verdict: Correct.**\n\n**C. One must switch to Givens rotations because Householder transformations destroy Hermitian structure in the complex case; using Householder updates would generally produce a non-Hermitian banded matrix.**\nThis statement is false. A unitary similarity transformation $A \\rightarrow H^{*}AH$ with a Hermitian matrix $A$ always preserves the Hermitian property. Householder transformations are designed to be unitary, so they maintain the structure. While complex Givens rotations can also be used for tridiagonalization, the premise that Householder transformations fail is incorrect.\n**Verdict: Incorrect.**\n\n**D. No changes are required at all: use the same real formulas and transposes, and the result is a real tridiagonal matrix even if $A$ is complex.**\nThis is incorrect on multiple levels. First, one must use complex arithmetic. Second, the matrix transpose $(\\cdot)^{\\mathsf{T}}$ must be replaced by the conjugate transpose $(\\cdot)^{*}$ to ensure transformations are unitary and preserve Hermitian structure. Using the simple transpose on complex vectors does not produce a unitary matrix. Third, the resulting tridiagonal matrix is Hermitian, which means its diagonal is real but its off-diagonals are generally complex. It is not a real tridiagonal matrix without an additional scaling step.\n**Verdict: Incorrect.**\n\n**E. The Householder procedure still works but its computational complexity increases from $\\mathcal{O}(n^{3})$ to $\\mathcal{O}(n^{4})$ because complex arithmetic requires nested similarity updates.**\nThe premise that the procedure works is correct, but the complexity analysis is wrong. The algorithm's structure remains a sequence of $n-2$ steps, each operating on a shrinking submatrix with a cost proportional to the square of its size. This leads to a total cost of $\\mathcal{O}(n^3)$. Complex arithmetic only affects the constant pre-factor, not the asymptotic scaling. The term \"nested similarity updates\" is not standard and does not describe a process that would lead to $\\mathcal{O}(n^4)$ complexity.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{B}$$"
        }
    ]
}