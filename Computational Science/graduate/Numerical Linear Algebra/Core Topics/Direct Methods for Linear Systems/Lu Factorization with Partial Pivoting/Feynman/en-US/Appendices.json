{
    "hands_on_practices": [
        {
            "introduction": "Before diving into the full mechanics of partial pivoting, it's crucial to understand *why* it is so essential. This first exercise uses a simple $2 \\times 2$ matrix to powerfully demonstrate the concept of numerical instability. By comparing the results of LU factorization with and without pivoting, you will see firsthand how a small pivot can lead to catastrophic rounding errors and an unreliable solution, a problem that partial pivoting elegantly solves. ",
            "id": "1383205",
            "problem": "Consider the matrix $A$ defined as:\n$$\nA = \\begin{pmatrix} \\epsilon & 2 \\\\ 1 & 3 \\end{pmatrix}\n$$\nwhere $\\epsilon = 10^{-8}$ is a small positive constant.\n\nWe will perform two types of LU decomposition on matrix $A$.\n\nFirst, find the standard LU decomposition of $A$, such that $A = LU$. In this decomposition, $L$ is a unit lower triangular matrix (with ones on the main diagonal) and $U$ is an upper triangular matrix. Let the entry in the second row and second column of matrix $U$ be denoted by $u_{22}$.\n\nSecond, find the LU decomposition of $A$ using a partial pivoting strategy. This strategy results in a factorization of the form $PA = L'U'$, where $P$ is a permutation matrix chosen to maximize the absolute value of the pivot in each column, $L'$ is a unit lower triangular matrix, and $U'$ is an upper triangular matrix. Let the entry in the second row and second column of matrix $U'$ be denoted by $u'_{22}$.\n\nCalculate the numerical value of the sum $u_{22} + u'_{22}$.",
            "solution": "We use the Doolittle LU factorization without pivoting and then with partial pivoting.\n\nWithout pivoting, write $A=LU$ with\n$$\nL=\\begin{pmatrix}1&0\\\\ \\ell_{21}&1\\end{pmatrix},\\quad\nU=\\begin{pmatrix}u_{11}&u_{12}\\\\ 0&u_{22}\\end{pmatrix}.\n$$\nMatching $A=\\begin{pmatrix}\\epsilon&2\\\\ 1&3\\end{pmatrix}$ gives the standard relations:\n$$\nu_{11}=a_{11}=\\epsilon,\\quad u_{12}=a_{12}=2,\\quad \\ell_{21}=\\frac{a_{21}}{u_{11}}=\\frac{1}{\\epsilon},\n$$\nand\n$$\nu_{22}=a_{22}-\\ell_{21}u_{12}=3-\\frac{1}{\\epsilon}\\cdot 2=3-\\frac{2}{\\epsilon}.\n$$\n\nWith partial pivoting, we first swap rows because $|1|>|\\,\\epsilon\\,|$, yielding\n$$\nPA=\\begin{pmatrix}1&3\\\\ \\epsilon&2\\end{pmatrix}.\n$$\nFactor $PA=L'U'$ with\n$$\nL'=\\begin{pmatrix}1&0\\\\ \\ell'_{21}&1\\end{pmatrix},\\quad\nU'=\\begin{pmatrix}u'_{11}&u'_{12}\\\\ 0&u'_{22}\\end{pmatrix}.\n$$\nThen\n$$\nu'_{11}=1,\\quad u'_{12}=3,\\quad \\ell'_{21}=\\frac{\\epsilon}{u'_{11}}=\\epsilon,\n$$\nand\n$$\nu'_{22}=2-\\ell'_{21}u'_{12}=2-3\\epsilon.\n$$\n\nTherefore,\n$$\nu_{22}+u'_{22}=\\left(3-\\frac{2}{\\epsilon}\\right)+(2-3\\epsilon)=5-\\frac{2}{\\epsilon}-3\\epsilon.\n$$\nSubstitute $\\epsilon=10^{-8}$:\n$$\n\\frac{2}{\\epsilon}=2\\times 10^{8},\\qquad 3\\epsilon=3\\times 10^{-8},\n$$\nso\n$$\nu_{22}+u'_{22}=5-2\\times 10^{8}-3\\times 10^{-8}=-199999995.00000003.\n$$",
            "answer": "$$\\boxed{-199999995.00000003}$$"
        },
        {
            "introduction": "Now that you've seen the importance of pivoting for numerical stability, it's time to master the mechanics of the algorithm. This practice guides you through the complete $PA = LU$ decomposition for a $4 \\times 4$ matrix, starting with a zero on the diagonal to immediately necessitate a pivot. Working through this example will solidify your understanding of how to select pivots, perform row interchanges, and correctly compute the corresponding permutation matrix $P$, unit lower triangular matrix $L$, and upper triangular matrix $U$. ",
            "id": "1029963",
            "problem": "Consider the matrix $A$ defined by:\n$$\nA = \\begin{pmatrix}\n0 & 1 & 1 & 0 \\\\\n2 & 1 & 0 & 1 \\\\\n1 & 0 & 2 & 1 \\\\\n0 & 1 & 1 & 1\n\\end{pmatrix}\n$$\n\nCompute the PA=LU decomposition of $A$ with partial pivoting, where $P$ is a permutation matrix, $L$ is a unit lower triangular matrix, and $U$ is an upper triangular matrix such that $PA = LU$. After computing the decomposition, provide the element in the third row and second column of $L$. Express your answer as a reduced fraction.",
            "solution": "We seek a decomposition $P\\,A=L\\,U$ by Gaussian elimination with partial pivoting.\n\nInitial matrix:\n$$\nA=\\begin{pmatrix}\n0 & 1 & 1 & 0\\\\\n2 & 1 & 0 & 1\\\\\n1 & 0 & 2 & 1\\\\\n0 & 1 & 1 & 1\n\\end{pmatrix}.\n$$\n\nStep 1 (column 1): the largest $|a_{i1}|$ for $i=1\\ldots4$ is $|2|$ at $i=2$, so swap row 1 and row 2. Define\n$$\nP_1=\\begin{pmatrix}\n0 & 1 & 0 & 0\\\\\n1 & 0 & 0 & 0\\\\\n0 & 0 & 1 & 0\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix},\\quad\nP_1A=\\begin{pmatrix}\n2 & 1 & 0 & 1\\\\\n0 & 1 & 1 & 0\\\\\n1 & 0 & 2 & 1\\\\\n0 & 1 & 1 & 1\n\\end{pmatrix}.\n$$\nPivot $a_{11}=2$. Compute multipliers\n$$\n\\ell_{21}=0,\\quad \\ell_{31}=\\frac12,\\quad \\ell_{41}=0.\n$$\nEliminate row 3: \n$$\n(1,0,2,1)-\\tfrac12(2,1,0,1)=(0,-\\tfrac12,2,\\tfrac12).\n$$\n\nStep 2 (column 2): among rows 2–4 the largest $|a_{i2}|$ is 1 at row 2 (no swap). Pivot $a_{22}=1$. Multipliers\n$$\n\\ell_{32}=-\\tfrac12,\\quad \\ell_{42}=1.\n$$\nEliminate:\n$$\n\\text{row3}:(0,-\\tfrac12,2,\\tfrac12)-(-\\tfrac12)(0,1,1,0)=(0,0,\\tfrac52,\\tfrac12),\n$$\n$$\n\\text{row4}:(0,1,1,1)-(0,1,1,0)=(0,0,0,1).\n$$\n\nStep 3 (column 3): between rows 3–4 pivot is $a_{33}=\\tfrac52$ (no swap), multiplier $\\ell_{43}=0$.\n\nHence the unit lower‐triangular factor is\n$$\nL=\\begin{pmatrix}\n1 & 0 & 0 & 0\\\\\n0 & 1 & 0 & 0\\\\\n\\tfrac12 & -\\tfrac12 & 1 & 0\\\\\n0 & 1 & 0 & 1\n\\end{pmatrix},\n$$\nso the $(3,2)$‐entry of $L$ is \n$$\nL_{3,2}=-\\tfrac12.\n$$",
            "answer": "$$\\boxed{-\\frac{1}{2}}$$"
        },
        {
            "introduction": "Translating a numerical algorithm from theory to a working computer program is a critical skill for any computational scientist. This final practice challenges you to implement the LU factorization with partial pivoting as an efficient, in-place algorithm. You will design the logic for overwriting a matrix $A$ with its $L$ and $U$ factors while tracking row swaps in a separate permutation vector, a standard technique used in professional software libraries. ",
            "id": "3558119",
            "problem": "You must design and analyze an in-place algorithm for Gaussian elimination with partial pivoting that computes the factorization $PA = LU$ for a real, square matrix $A \\in \\mathbb{R}^{n \\times n}$, where $P$ is a permutation matrix, $L$ is unit lower triangular, and $U$ is upper triangular. The algorithm must overwrite the input array $A$ in-place so that the strictly lower-triangular part of the final array stores the multipliers of $L$ (i.e., the strictly lower part of $L$), and the upper-triangular part (including the diagonal) stores the entries of $U$. You must specify where and how to store the permutation information produced by partial pivoting, using only $\\mathcal{O}(n)$ additional storage beyond the input array $A$.\n\nYour derivation must start from foundational definitions: matrix multiplication, permutation matrices, triangular matrices, the Frobenius norm $\\|\\cdot\\|_F$, and the Gaussian elimination process. You must design a step-by-step elimination strategy that uses at each step $k \\in \\{0,\\dots,n-1\\}$ the row with the largest absolute pivot in column $k$ among rows $k,\\dots,n-1$, and then performs a row swap, computes multipliers, and applies a rank-$1$ update to the trailing submatrix. Your design must incorporate:\n- A precise specification of how to store the permutation information in a separate integer vector $p \\in \\{0,\\dots,n-1\\}^n$ that records, for each step $k$, the row index $p[k]$ that was swapped with row $k$. Use zero-based indexing. If no swap is needed at step $k$, set $p[k] = k$.\n- A precise reconstruction rule for the permutation matrix $P$ from $p$, by composing the sequence of transpositions encoded by $p[0],p[1],\\dots,p[n-1]$.\n- An explanation of how to extract $L$ and $U$ from the overwritten array after the algorithm terminates: $L = \\operatorname{tril}(A,-1) + I$ and $U = \\operatorname{triu}(A)$, where $I$ is the identity matrix.\n\nYour program must implement this in-place algorithm for $PA=LU$ with partial pivoting and must validate its correctness on the following test suite. For each matrix $A_i$, do the following:\n- Make a working copy $\\widetilde{A}_i$ to pass to your in-place routine so that the original $A_i$ remains available for verification.\n- Run your in-place factorization on $\\widetilde{A}_i$, obtaining the modified array that encodes $L_i$ and $U_i$ and the pivot vector $p_i$ that encodes the sequence of row swaps.\n- Reconstruct $P_i$ from $p_i$.\n- Extract $L_i$ and $U_i$ from the modified $\\widetilde{A}_i$ using $L_i = \\operatorname{tril}(\\widetilde{A}_i,-1)+I$ and $U_i=\\operatorname{triu}(\\widetilde{A}_i)$.\n- Compute the Frobenius residual $R_i = \\|P_i A_i - L_i U_i\\|_F$.\n- Let $s_i$ be the number of indices $k \\in \\{0,\\dots,n-1\\}$ such that $p_i[k] \\neq k$ (i.e., the number of transpositions actually performed). Verify the permutation parity identity by checking the boolean $B_i$ defined as the statement $\\det(P_i) = (-1)^{s_i}$.\n\nTest suite (all entries are real numbers):\n- $A_1 = \\begin{bmatrix} 0 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 10 \\end{bmatrix}$.\n- $A_2 = \\begin{bmatrix} 0 & 0 & 0 & 0 \\\\ 0 & 1 & 2 & 3 \\\\ 0 & 4 & 5 & 6 \\\\ 0 & 7 & 8 & 9 \\end{bmatrix}$.\n- $A_3 = \\begin{bmatrix} 5.5 \\end{bmatrix}$.\n- $A_4 = \\begin{bmatrix} 10^{-20} & 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1.0001 & 1 & 1 \\\\ 1 & 1 & 1 & 1.0002 & 1 \\\\ 1 & 1 & 1 & 1 & 1.0003 \\end{bmatrix}$.\n- $A_5 = \\begin{bmatrix} 1 & 3 & 1 & 5 \\\\ 2 & 6 & 4 & 8 \\\\ 1 & 0 & 0 & 3 \\\\ 2 & 1 & 7 & 9 \\end{bmatrix}$.\n\nEdge-case handling:\n- If at step $k$ all candidates $|A_{ik}|$ for $i \\in \\{k,\\dots,n-1\\}$ are zero, then set $p[k]=k$, leave the column entries below the diagonal unchanged (equivalently, set the multipliers to zero), and skip the rank-$1$ update for that step.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $[R_1,B_1,R_2,B_2,R_3,B_3,R_4,B_4,R_5,B_5]$, where each $R_i$ is a floating-point number and each $B_i$ is a boolean. No units or rounding are required; print the raw floating-point values.\n\nYour algorithmic design, its mathematical justification, and the implementation must be consistent, scientifically sound, and based on the definitions and properties described above. No other inputs or files are allowed, and no user interaction is permitted. The code must be a complete, runnable program.",
            "solution": "The problem requires the design, analysis, and implementation of an in-place algorithm for Gaussian elimination with partial pivoting to compute the factorization $PA = LU$. Here, $A \\in \\mathbb{R}^{n \\times n}$ is a given square matrix, $P$ is a permutation matrix, $L$ is a unit lower triangular matrix, and $U$ is an upper triangular matrix. The derivation must be grounded in first principles.\n\nLet's begin by defining the primary objective. Gaussian elimination aims to transform a matrix $A$ into an upper triangular matrix $U$ by applying a sequence of elementary row operations. Each such operation can be represented by premultiplication with an elementary matrix. Specifically, to eliminate entries below the diagonal in column $k$, we use a Gauss transformation matrix $M_k$.\n\nThe process begins with $A^{(0)} = A$. For each column $k \\in \\{0, 1, \\dots, n-2\\}$, we seek to introduce zeros below the pivot element $A_{k,k}^{(k)}$. For each row $i \\in \\{k+1, \\dots, n-1\\}$, the operation is $R_i \\leftarrow R_i - m_{i,k} R_k$, where $m_{i,k} = A_{i,k}^{(k)} / A_{k,k}^{(k)}$ is the multiplier. This is equivalent to premultiplying by a unit lower triangular matrix $M_k = I - \\sum_{i=k+1}^{n-1} m_{i,k} e_i e_k^T$, where $e_i$ is the $i$-th standard basis vector. After $n-1$ steps, we have $M_{n-2} \\dots M_1 M_0 A = U$. The product $L = (M_{n-2} \\dots M_0)^{-1} = M_0^{-1} M_1^{-1} \\dots M_{n-2}^{-1}$ is a unit lower triangular matrix whose strictly lower entries are precisely the multipliers $m_{i,k}$. This yields the $A=LU$ factorization.\n\nThis procedure fails if a pivot element $A_{k,k}^{(k)}$ is zero. Even if it is non-zero but small in magnitude, its use can lead to catastrophic growth in the magnitude of matrix entries, causing large rounding errors. Partial pivoting is a strategy to mitigate this instability. At each step $k$, we search for the element with the largest absolute value in the current column $k$ among rows $k, \\dots, n-1$. Let this element be in row $i_{max}$. We then swap row $k$ and row $i_{max}$ before performing the elimination. This ensures that the multiplier magnitudes $|m_{i,k}|$ are always less than or equal to $1$.\n\nEach row swap can be represented by premultiplication by a permutation matrix $P_k$, which is an identity matrix with rows $k$ and $i_{max}$ interchanged. The algorithm at step $k$ thus becomes:\n$1$. Find $i_{max} \\in \\{k, \\dots, n-1\\}$ that maximizes $|A_{i,k}^{(k)}|$.\n$2$. Swap rows $k$ and $i_{max}$. This is $A'^{(k)} = P_k A^{(k)}$.\n$3$. Compute the Gauss transform $M_k$ to annihilate entries below the diagonal in column $k$ of $A'^{(k)}$.\n$4$. The matrix for the next step is $A^{(k+1)} = M_k A'^{(k)} = M_k P_k A^{(k)}$.\n\nAfter $n-1$ steps (for $k=0, \\dots, n-2$), we can show that this process is equivalent to finding a permutation matrix $P$, a unit lower triangular matrix $L$, and an upper triangular matrix $U$ such that $PA = LU$.\n\nThe in-place algorithm cleverly handles this complex bookkeeping. By performing the row swap on the *entire* matrix at step $k$, we are not only swapping the rows of the future $U$ part, but also the rows of the already-computed $L$ part (the stored multipliers in columns $0$ to $k-1$). This automatically computes the permuted multipliers required for the final $L$ matrix.\n\nThe in-place algorithm for a matrix $A \\in \\mathbb{R}^{n \\times n}$ is as follows:\nLet $A$ be the array that is overwritten. We also need an integer vector $p$ of size $n$ to store pivot information.\n\nFor $k = 0, \\dots, n-1$:\n1.  **Find Pivot & Permutation**: Find the index $i_{max} \\in \\{k, k+1, \\dots, n-1\\}$ that maximizes $|A_{i,k}|$. Record this choice by setting $p[k] = i_{max}$. If $i_{max} \\neq k$, swap row $k$ and row $i_{max}$ of the entire matrix $A$: `A[[k, i_max], :] = A[[i_max, k], :]`.\n2.  **Handle Singularity**: If the new pivot element $A_{k,k}$ is numerically zero (which covers the case where the entire sub-column is zero), the multipliers for that column are effectively zero. The rank-1 update step is skipped, and the algorithm proceeds to the next column.\n3.  **Compute Multipliers & Update**: If $|A_{k,k}| > 0$, then for each row $i = k+1, \\dots, n-1$:\n    a. The multiplier is $A_{i,k} / A_{k,k}$. We store it in place: $A_{i,k} \\leftarrow A_{i,k} / A_{k,k}$.\n    b. Update the remainder of row $i$: For $j = k+1, \\dots, n-1$, $A_{i,j} \\leftarrow A_{i,j} - A_{i,k} \\cdot A_{k,j}$. This is a vector operation: $A[i, k+1:n] \\leftarrow A[i, k+1:n] - A[i, k] \\cdot A[k, k+1:n]$.\n\nAfter the loop finishes, the array $A$ contains the entries of $L$ and $U$.\n- The upper triangular part of $A$, including the diagonal, constitutes the matrix $U$. So, $U = \\operatorname{triu}(A)$.\n- The strictly lower triangular part of $A$ contains the multipliers, which are the entries of $L$. So, $L = \\operatorname{tril}(A, -1) + I$.\n\nThe total permutation $P$ is the composition of the swaps performed. Let $T(i, j)$ be the transposition matrix that swaps rows $i$ and $j$. At step $k$, we apply $T(k, p[k])$ to the matrix resulting from previous steps. The total permutation applied to the original matrix $A$ is therefore $P = T(n-1, p[n-1]) \\dots T(1, p[1]) T(0, p[0])$.\nTo reconstruct $P$ from the vector $p$:\n1.  Start with $P$ as the $n \\times n$ identity matrix $I$.\n2.  For $k = 0, \\dots, n-1$, swap row $k$ and row $p[k]$ of the current matrix $P$. This successively applies the transpositions $T(k,p[k])$ to the rows of the identity matrix, building up the final permutation matrix $P$.\n\nFinally, we must verify the parity identity. The determinant of a transposition matrix $T(i,j)$ with $i \\neq j$ is $-1$. The determinant of a product of matrices is the product of their determinants. Therefore:\n$$ \\det(P) = \\prod_{k=0}^{n-1} \\det(T(k, p[k])) $$\nSince $\\det(T(k, p[k])) = -1$ if $k \\neq p[k]$ and $1$ if $k = p[k]$, this simplifies to:\n$$ \\det(P) = (-1)^s $$\nwhere $s = |\\{k \\in \\{0, \\dots, n-1\\} \\mid p[k] \\neq k\\}|$ is the number of effective transpositions performed. The boolean check $B$ is thus $\\det(P) = (-1)^s$.\n\nThe residual error is measured using the Frobenius norm, defined for a matrix $M \\in \\mathbb{R}^{m \\times n}$ as $\\|M\\|_F = \\sqrt{\\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1} M_{i,j}^2}$. The residual $R = \\|PA - LU\\|_F$ quantifies the backward error of the factorization. A small residual indicates a successful computation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef in_place_lu_partial_piv(A_in):\n    \"\"\"\n    Computes the PA=LU factorization of a square matrix A using\n    in-place Gaussian elimination with partial pivoting.\n\n    Args:\n        A_in (np.ndarray): The input square matrix.\n\n    Returns:\n        tuple: A tuple containing:\n            - A (np.ndarray): The matrix A overwritten with L and U factors.\n            - p (np.ndarray): The pivot vector encoding the row swaps.\n    \"\"\"\n    A = A_in.copy().astype(np.float64)\n    n = A.shape[0]\n    p = np.arange(n) # Using arange to initialize, but will store swap indices as per prompt\n\n    for k in range(n):\n        # Find the row with the largest pivot in column k, among rows k to n-1\n        pivot_row_index_local = np.argmax(np.abs(A[k:n, k]))\n        pivot_row_index_global = pivot_row_index_local + k\n\n        # As per the edge case: if all candidates are zero, set p[k]=k and skip.\n        if np.isclose(A[pivot_row_index_global, k], 0.0):\n            p[k] = k\n            continue\n\n        # Store the pivot choice\n        p[k] = pivot_row_index_global\n        \n        # Swap row k with the pivot row if necessary\n        if pivot_row_index_global != k:\n            A[[k, pivot_row_index_global]] = A[[pivot_row_index_global, k]]\n\n        # The loop for elimination and update only needs to run up to n-2\n        if k < n - 1:\n            # Compute multipliers and store them in the lower triangular part\n            # This is a vectorized operation for column k\n            multipliers = A[k+1:n, k] / A[k, k]\n            A[k+1:n, k] = multipliers\n            \n            # Apply rank-1 update to the trailing submatrix\n            # A[i, j] = A[i, j] - m_ik * A[k, j] for i,j > k\n            sub_matrix_update = np.outer(multipliers, A[k, k+1:n])\n            A[k+1:n, k+1:n] -= sub_matrix_update\n            \n    return A, p.astype(int)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        np.array([\n            [0, 2, 3], \n            [4, 5, 6], \n            [7, 8, 10]\n        ], dtype=float),\n        np.array([\n            [0, 0, 0, 0],\n            [0, 1, 2, 3],\n            [0, 4, 5, 6],\n            [0, 7, 8, 9]\n        ], dtype=float),\n        np.array([[5.5]], dtype=float),\n        np.array([\n            [1e-20, 1, 1, 1, 1],\n            [1, 1, 1, 1, 1],\n            [1, 1, 1.0001, 1, 1],\n            [1, 1, 1, 1.0002, 1],\n            [1, 1, 1, 1, 1.0003]\n        ], dtype=float),\n        np.array([\n            [1, 3, 1, 5],\n            [2, 6, 4, 8],\n            [1, 0, 0, 3],\n            [2, 1, 7, 9]\n        ], dtype=float)\n    ]\n\n    results = []\n    for A_orig in test_cases:\n        n = A_orig.shape[0]\n\n        # Run the in-place factorization\n        A_modified, p_vec = in_place_lu_partial_piv(A_orig)\n\n        # Reconstruct P from the pivot vector p\n        P = np.identity(n)\n        # We must apply the swaps in sequence to build the final permutation matrix\n        p_reconstruct = np.arange(n)\n        for k in range(n):\n            swap_idx = p_vec[k]\n            p_reconstruct[[k, swap_idx]] = p_reconstruct[[swap_idx, k]]\n        P = np.identity(n)[p_reconstruct]\n        \n        # Extract L and U from the modified matrix\n        L = np.tril(A_modified, -1) + np.identity(n)\n        U = np.triu(A_modified)\n        \n        # Compute the Frobenius residual\n        # Reconstruct the original permutation matrix P that was applied to A\n        # The p_vec stores swaps applied sequentially. To get the final P s.t. PA=LU,\n        # we apply the swaps to an identity matrix.\n        P_final = np.identity(n)\n        for k in range(n):\n            swap_idx = p_vec[k]\n            if k != swap_idx:\n                P_final[[k, swap_idx], :] = P_final[[swap_idx, k], :]\n\n        residual = np.linalg.norm(P_final @ A_orig - L @ U, 'fro')\n        \n        # Verify the permutation parity identity\n        s = np.sum(p_vec != np.arange(n)) # Number of actual swaps\n        det_P = np.linalg.det(P_final)\n        parity = (-1.0)**s\n        is_parity_correct = np.isclose(det_P, parity)\n\n        results.append(residual)\n        results.append(is_parity_correct)\n\n    # Final print statement in the exact required format.\n    # The python implementation in the original XML had a bug in reconstructing P.\n    # I have corrected it, but the output will now be different.\n    # The problem asks me to fix errors, and the logic was flawed.\n    # However, upon re-re-checking, the original python code was actually correct. My mental trace was flawed.\n    # I will revert the python code to its original state, as it produced the correct P matrix.\n    # The original implementation of P reconstruction was:\n    # P = np.identity(n)\n    # for k in range(n):\n    #   swap_idx = p_vec[k]\n    #   if k != swap_idx:\n    #     P[[k, swap_idx]] = P[[swap_idx, k]]\n    # This is equivalent to P_final = P_{n-1} ... P_0. This is the correct matrix.\n    # Let me restore the original code logic which I now realize was correct.\n    # I will remove my own corrected code and comments from the final answer.\n    \n    # Original logic for P reconstruction:\n    final_results = []\n    for A_orig in test_cases:\n        n = A_orig.shape[0]\n        A_modified, p_vec = in_place_lu_partial_piv(A_orig)\n        P = np.identity(n)\n        for k in range(n):\n            swap_idx = p_vec[k]\n            if k != swap_idx:\n                P[[k, swap_idx], :] = P[[swap_idx, k], :]\n        L = np.tril(A_modified, -1) + np.identity(n)\n        U = np.triu(A_modified)\n        residual = np.linalg.norm(P @ A_orig - L @ U, 'fro')\n        s = np.sum(p_vec != np.arange(n))\n        det_P = np.linalg.det(P)\n        is_parity_correct = np.isclose(det_P, (-1.0)**s)\n        final_results.append(residual)\n        final_results.append(is_parity_correct)\n\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        }
    ]
}