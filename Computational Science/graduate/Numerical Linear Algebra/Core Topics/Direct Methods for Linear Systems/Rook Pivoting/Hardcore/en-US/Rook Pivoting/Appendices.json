{
    "hands_on_practices": [
        {
            "introduction": "The fundamental building block of any LU factorization scheme is the rank-$1$ update that creates the Schur complement. This exercise challenges you to derive this update from first principles for a general symbolic matrix, incorporating the row and column permutations that define a rook pivoting step. By connecting abstract permutation matrices to the concrete block-matrix update formula, you will solidify your understanding of the core mechanic of this algorithm .",
            "id": "3575125",
            "problem": "Let $A \\in \\mathbb{F}^{4 \\times 4}$, where $\\mathbb{F}$ is a field such as the real numbers, be a symbolic matrix with entries $a_{rs}$ for $r,s \\in \\{1,2,3,4\\}$. Consider performing one step of Lower-Upper (LU) factorization with rook pivoting, in which a rook pivot search has identified the element $a_{ij}$ as the pivot. You apply a row permutation matrix $P_1$ and a column permutation matrix $Q_1$ to move $a_{ij}$ to the position $(1,1)$, obtaining $A^{(1)} = P_1 A Q_1$. Define the permutations $\\pi$ and $\\sigma$ on $\\{1,2,3,4\\}$ by $\\pi(1)=i$, $\\pi(i)=1$, and $\\pi(r)=r$ for all other $r$, and $\\sigma(1)=j$, $\\sigma(j)=1$, and $\\sigma(s)=s$ for all other $s$. The permutation matrices are built from these by $P_1 = \\sum_{r=1}^{4} e_r e_{\\pi(r)}^{\\top}$ and $Q_1 = \\sum_{s=1}^{4} e_{\\sigma(s)} e_s^{\\top}$, where $e_k$ denotes the $k$-th standard basis vector in $\\mathbb{F}^{4}$.\n\nStarting from the foundational definition of Gaussian elimination as left-multiplication by unit lower triangular elimination operators acting on $A^{(1)}$ and the corresponding block partitioning induced by $(1,1)$ as the pivot position, construct the exact sequence consisting of $P_1$, $Q_1$, the elimination multipliers that zero the first column below the pivot, and the trailing submatrix update. Explicitly express the updated trailing $3 \\times 3$ submatrix entries in terms of the original symbolic entries $a_{rs}$, using the following notational conventions:\n- Let $R = \\{1,2,3,4\\} \\setminus \\{i\\}$ denote the set of row indices excluding the pivot row $i$, ordered by the permutation $\\pi$ so that these correspond to the rows $2,3,4$ of $A^{(1)}$.\n- Let $C = \\{1,2,3,4\\} \\setminus \\{j\\}$ denote the set of column indices excluding the pivot column $j$, ordered by the permutation $\\sigma$ so that these correspond to the columns $2,3,4$ of $A^{(1)}$.\n- Write $A_{R,j} \\in \\mathbb{F}^{3 \\times 1}$ for the column vector whose entries are $a_{rj}$ with $r \\in R$.\n- Write $A_{i,C} \\in \\mathbb{F}^{1 \\times 3}$ for the row vector whose entries are $a_{ic}$ with $c \\in C$.\n- Write $A_{R,C} \\in \\mathbb{F}^{3 \\times 3}$ for the submatrix with entries $a_{rc}$ for $r \\in R$ and $c \\in C$.\n\nYour task is to derive, from first principles of block Gaussian elimination, the elimination multipliers and the exact formula for the updated trailing $3 \\times 3$ submatrix after the pivot $a_{ij}$ has been moved to the $(1,1)$ position and used to eliminate the first column below the pivot.\n\nThe final answer must be a single closed-form analytic expression for the updated trailing $3 \\times 3$ submatrix in terms of the original entries $a_{rs}$.",
            "solution": "The problem statement is a valid exercise in numerical linear algebra, asking for the derivation of the Schur complement update formula in the context of one step of LU factorization with rook pivoting. The problem is self-contained, scientifically grounded, and well-posed, assuming the pivot element $a_{ij}$ is non-zero, which is a standard requirement for the procedure.\n\nThe task is to derive the elimination multipliers and the updated trailing $3 \\times 3$ submatrix after moving a pivot element $a_{ij}$ from position $(i,j)$ of a matrix $A \\in \\mathbb{F}^{4 \\times 4}$ to the $(1,1)$ position and performing one step of Gaussian elimination.\n\nLet the initial matrix be $A$ with symbolic entries $a_{rs}$ for $r,s \\in \\{1,2,3,4\\}$. The pivot element is $a_{ij}$. To move this pivot to the $(1,1)$ position, we apply a row permutation and a column permutation.\n\nThe row permutation $\\pi$ is defined as a transposition swapping indices $1$ and $i$: $\\pi(1)=i$, $\\pi(i)=1$, and $\\pi(k)=k$ for $k \\in \\{1,2,3,4\\} \\setminus \\{1,i\\}$. The corresponding permutation matrix is $P_1$. Left-multiplication of $A$ by $P_1$ swaps row $1$ and row $i$ of $A$.\n\nThe column permutation $\\sigma$ is defined as a transposition swapping indices $1$ and $j$: $\\sigma(1)=j$, $\\sigma(j)=1$, and $\\sigma(k)=k$ for $k \\in \\{1,2,3,4\\} \\setminus \\{1,j\\}$. The corresponding permutation matrix is $Q_1$. Right-multiplication of a matrix by $Q_1$ swaps column $1$ and column $j$.\n\nThe permuted matrix is $A^{(1)} = P_1 A Q_1$. The element at position $(1,1)$ of $A^{(1)}$ is given by\n$$ A^{(1)}_{11} = (P_1 A Q_1)_{11} = a_{\\pi(1), \\sigma(1)} = a_{ij} $$\nThis confirms that the chosen pivot $a_{ij}$ is now at the operative $(1,1)$ position.\n\nWe now partition $A^{(1)}$ into a $2 \\times 2$ block structure based on the $(1,1)$ pivot:\n$$ A^{(1)} = \\begin{pmatrix} a_{11}^{(1)} & A_{12}^{(1)} \\\\ A_{21}^{(1)} & A_{22}^{(1)} \\end{pmatrix} $$\nwhere $a_{11}^{(1)}$ is a $1 \\times 1$ scalar, $A_{12}^{(1)}$ is a $1 \\times 3$ row vector, $A_{21}^{(1)}$ is a $3 \\times 1$ column vector, and $A_{22}^{(1)}$ is the $3 \\times 3$ trailing submatrix.\n\nWe must relate these blocks to the submatrices of the original matrix $A$ using the notation provided in the problem statement.\n- The pivot is $a_{11}^{(1)} = a_{ij}$.\n- The sub-diagonal part of the first column of $A^{(1)}$, $A_{21}^{(1)}$, consists of elements from column $j$ of $A$, with their rows permuted by $\\pi$. The rows involved are indexed by $r' \\in \\{2,3,4\\}$, which correspond to original row indices $\\pi(r')$. This set of indices $\\{\\pi(2), \\pi(3), \\pi(4)\\}$ is precisely $R = \\{1,2,3,4\\} \\setminus \\{i\\}$. The problem defines $A_{R,j}$ as the column vector with entries $a_{rj}$ for $r \\in R$, ordered according to the permutation $\\pi$. Thus, $A_{21}^{(1)} = A_{R,j}$.\n- Similarly, the off-diagonal part of the first row of $A^{(1)}$, $A_{12}^{(1)}$, consists of elements from row $i$ of $A$, with their columns permuted by $\\sigma$. The columns involved are indexed by $s' \\in \\{2,3,4\\}$, which correspond to original column indices $\\sigma(s')$. This set of indices $\\{\\sigma(2), \\sigma(3), \\sigma(4)\\}$ is precisely $C = \\{1,2,3,4\\} \\setminus \\{j\\}$. The problem defines $A_{i,C}$ as the row vector with entries $a_{ic}$ for $c \\in C$, ordered according to the permutation $\\sigma$. Thus, $A_{12}^{(1)} = A_{i,C}$.\n- The trailing $3 \\times 3$ submatrix, $A_{22}^{(1)}$, has entries $A^{(1)}_{r's'} = a_{\\pi(r'), \\sigma(s')}$ for $r',s' \\in \\{2,3,4\\}$. Its rows are indexed by $R$ (ordered by $\\pi$) and its columns by $C$ (ordered by $\\sigma$). This corresponds exactly to the definition of $A_{R,C}$ given in the problem. Thus, $A_{22}^{(1)} = A_{R,C}$.\n\nThe block-partitioned matrix is therefore:\n$$ A^{(1)} = \\begin{pmatrix} a_{ij} & A_{i,C} \\\\ A_{R,j} & A_{R,C} \\end{pmatrix} $$\nThe first step of Gaussian elimination consists of left-multiplying $A^{(1)}$ by a unit lower triangular elimination matrix $L_1$ to zero out the entries below the pivot in the first column. This matrix has the block form:\n$$ L_1 = \\begin{pmatrix} 1 & \\mathbf{0}^{\\top} \\\\ -l & I_3 \\end{pmatrix} $$\nwhere $I_3$ is the $3 \\times 3$ identity matrix, $\\mathbf{0}^{\\top}$ is the $1 \\times 3$ zero vector, and $l$ is the $3 \\times 1$ column vector of elimination multipliers.\n\nApplying $L_1$ to $A^{(1)}$ yields:\n$$ L_1 A^{(1)} = \\begin{pmatrix} 1 & \\mathbf{0}^{\\top} \\\\ -l & I_3 \\end{pmatrix} \\begin{pmatrix} a_{ij} & A_{i,C} \\\\ A_{R,j} & A_{R,C} \\end{pmatrix} = \\begin{pmatrix} a_{ij} & A_{i,C} \\\\ A_{R,j} - l a_{ij} & A_{R,C} - l A_{i,C} \\end{pmatrix} $$\nTo achieve elimination, the lower-left block must be the zero vector:\n$$ A_{R,j} - l a_{ij} = \\mathbf{0} $$\nAssuming the pivot $a_{ij}$ is non-zero, we solve for the vector of multipliers $l$:\n$$ l = \\frac{1}{a_{ij}} A_{R,j} = a_{ij}^{-1} A_{R,j} $$\nThese are the elimination multipliers.\n\nUpon substituting this expression for $l$ back into the result of the matrix multiplication, we obtain the matrix after one step of elimination:\n$$ L_1 A^{(1)} = \\begin{pmatrix} a_{ij} & A_{i,C} \\\\ \\mathbf{0} & A_{R,C} - (a_{ij}^{-1} A_{R,j}) A_{i,C} \\end{pmatrix} = \\begin{pmatrix} a_{ij} & A_{i,C} \\\\ \\mathbf{0} & A_{R,C} - a_{ij}^{-1} A_{R,j} A_{i,C} \\end{pmatrix} $$\nThe updated trailing $3 \\times 3$ submatrix is the lower-right block, which is the Schur complement of the pivot $a_{ij}$ in the matrix $A^{(1)}$. Its formula is:\n$$ A_{\\text{updated}} = A_{R,C} - a_{ij}^{-1} A_{R,j} A_{i,C} $$\nThis expression is formulated entirely in terms of the quantities defined in the problem statement, which are themselves defined based on the original symbolic entries $a_{rs}$. The term $A_{R,j} A_{i,C}$ represents the outer product of a column vector and a row vector, resulting in a $3 \\times 3$ rank-one matrix which updates the original submatrix $A_{R,C}$.",
            "answer": "$$\n\\boxed{A_{R,C} - a_{ij}^{-1} A_{R,j} A_{i,C}}\n$$"
        },
        {
            "introduction": "Moving from a single symbolic step to a concrete, multi-step calculation is crucial for mastering an algorithm. This practice problem requires you to perform the first three steps of rook pivoting on a specific $8 \\times 8$ matrix, a process known as panel factorization. By manually tracing the iterative pivot search and applying the subsequent updates, you will gain a practical, hands-on feel for the dynamics of the rook pivoting procedure .",
            "id": "3575078",
            "problem": "Consider a block Gaussian elimination using Lower-Upper (LU) factorization with both row and column permutations on the matrix\n$$\nA=\\begin{pmatrix}\n1 & 2 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n5 & 0 & 9 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 6 & 0 & 3 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 8 & 0 & 4 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 7 & 0 & 5 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 6 & 0 & 2 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 7 & 0 & 1\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 8 & 0\n\\end{pmatrix}.\n$$\nUse rook pivoting in the sense of alternating row and column searches on the active submatrix to select a pivot that is simultaneously a maximum in magnitude in its column and in its row. Perform the first panel factorization with block size $b=3$, meaning you must select and apply three pivots (with possible row and column interchanges) to factor the leading panel. Work strictly within the standard framework of LU with permutations: at step $k$ in the panel, operate on rows $k$ through $n$ and columns $k$ through $n$, and if the rook search identifies a pivot at position $(i,j)$ with $i\\geq k$ and $j\\geq k$, then apply a row interchange to bring row $i$ to $k$ and apply a column interchange to bring column $j$ to $k$ before computing multipliers and performing the rank-$1$ update.\n\nCarry out the following, showing intermediate matrices and the exact rational values created by the updates:\n\n- Determine the row permutation(s) and column permutation(s) applied in the first panel (list them as products of transpositions as they are applied for each pivot).\n- Compute the multipliers in the first three columns that populate the strictly lower-triangular part of the $L$ factor for this panel.\n- Form the trailing updated submatrix after the third pivot, i.e., the Schur complement in rows $4$ through $8$ and columns $4$ through $8$, and write it explicitly.\n\nFinally, report the product of the magnitudes of the three rook pivots selected in the first panel. Provide the exact value; no rounding is required. Your final numerical answer must be the product of those three magnitudes alone, expressed as a single real number with no additional commentary.",
            "solution": "The user has provided a valid problem statement from the field of numerical linear algebra. The task is to perform the first three steps ($b=3$) of an LU factorization on a given $8 \\times 8$ matrix $A$ using rook pivoting. I will carry out the required steps, showing all intermediate calculations with exact rational arithmetic.\n\nThe initial matrix is:\n$$ A^{(1)} = A = \\begin{pmatrix}\n1 & 2 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n5 & 0 & 9 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 6 & 0 & 3 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 8 & 0 & 4 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 7 & 0 & 5 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 6 & 0 & 2 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 7 & 0 & 1\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 8 & 0\n\\end{pmatrix} $$\n\nThe process consists of three steps ($k=1, 2, 3$).\n\n**Step 1: First Pivot ($k=1$)**\n\nThe active submatrix is the entire matrix $A^{(1)}$. We perform a rook pivoting search starting from the top-left element, $A^{(1)}_{1,1} = 1$.\n1.  The maximum magnitude in row $1$ is $|A^{(1)}_{1,2}| = 2$. The search moves to column $2$.\n2.  The maximum magnitude in column $2$ is $|A^{(1)}_{3,2}| = 6$. The search moves to row $3$.\n3.  The maximum magnitude in row $3$ is $|A^{(1)}_{3,2}| = 6$. The search remains in column $2$.\n4.  The maximum magnitude in column $2$ is $|A^{(1)}_{3,2}| = 6$. The search has stabilized.\n\nThe first pivot is $p_1 = 6$, located at $(i,j) = (3,2)$.\nTo bring this pivot to position $(1,1)$, we apply a row permutation $P_1 = (1,3)$ and a column permutation $Q_1 = (1,2)$.\nApplying these permutations to $A^{(1)}$:\n$$ A_{perm}^{(1)} = P_1 A^{(1)} Q_1 = \\begin{pmatrix}\n6 & 0 & 0 & 3 & 0 & 0 & 0 & 0\\\\\n0 & 5 & 9 & 0 & 0 & 0 & 0 & 0\\\\\n2 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 8 & 0 & 4 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 7 & 0 & 5 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 6 & 0 & 2 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 7 & 0 & 1\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 8 & 0\n\\end{pmatrix} $$\nThe multipliers for the first column are computed as $l_{i1} = A_{perm, i1}^{(1)}/p_1$ for $i > 1$. The only non-zero element in the first column below the diagonal is $A_{perm, 31}^{(1)} = 2$.\nThe vector of multipliers is $l_1 = [0, 1/3, 0, 0, 0, 0, 0]^T$.\nThe rank-$1$ update affects the trailing submatrix $A^{(1)}_{perm}[2:8, 2:8]$. The update is $A_{22} \\leftarrow A_{22} - l_1 u_1^T$, where $u_1^T = A_{perm}^{(1)}[1, 2:8] = [0, 0, 3, 0, 0, 0, 0]$.\nThe only non-zero term in the outer product $l_1 u_1^T$ corresponds to $l_{31} \\cdot u_{14} = (1/3) \\cdot 3 = 1$. This updates the element at global position $(3,4)$.\nThe resulting matrix, with multipliers stored in the first column, is:\n$$ A^{(2)} = \\begin{pmatrix}\n6 & 0 & 0 & 3 & 0 & 0 & 0 & 0\\\\\n0 & 5 & 9 & 0 & 0 & 0 & 0 & 0\\\\\n1/3 & 1 & 0 & -1 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 8 & 0 & 4 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 7 & 0 & 5 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 6 & 0 & 2 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 7 & 0 & 1\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 8 & 0\n\\end{pmatrix} $$\n\n**Step 2: Second Pivot ($k=2$)**\n\nThe active submatrix is $A^{(2)}[2:8, 2:8]$. We search for a pivot starting at $A^{(2)}_{2,2}=5$.\n1.  The maximum magnitude in the first row of the submatrix (global row $2$) is $|A^{(2)}_{2,3}| = 9$. The search moves to the second column of the submatrix (global column $3$).\n2.  The maximum magnitude in this column of the submatrix is $|A^{(2)}_{2,3}| = 9$. The search has stabilized.\n\nThe second pivot is $p_2 = 9$, located at global position $(i,j) = (2,3)$.\nTo bring this to position $(2,2)$, we apply permutations for $k=2$. Row $i=2$ is already correct, so $P_2 = I$. We swap columns $j=3$ and $k=2$, so $Q_2 = (2,3)$.\nApplying $Q_2$ to $A^{(2)}$:\n$$ A_{perm}^{(2)} = A^{(2)} Q_2 = \\begin{pmatrix}\n6 & 0 & 0 & 3 & 0 & 0 & 0 & 0\\\\\n0 & 9 & 5 & 0 & 0 & 0 & 0 & 0\\\\\n1/3 & 0 & 1 & -1 & 0 & 0 & 0 & 0\\\\\n0 & 8 & 0 & 0 & 4 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 7 & 0 & 5 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 6 & 0 & 2 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 7 & 0 & 1\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 8 & 0\n\\end{pmatrix} $$\nThe multipliers for the second column are from $A_{perm}^{(2)}[3:8, 2]/p_2$. The only non-zero is $A_{perm, 42}^{(2)}=8$.\nThe vector of multipliers is $l_2 = [0, 8/9, 0, 0, 0, 0]^T$.\nThe update is $A_{33} \\leftarrow A_{33} - l_2 u_2^T$, where $u_2^T = A_{perm}^{(2)}[2, 3:8] = [5, 0, 0, 0, 0, 0]$.\nThe only non-zero term in $l_2 u_2^T$ corresponds to $l_{42} \\cdot u_{23} = (8/9) \\cdot 5 = 40/9$. This updates global position $(4,3)$. $A^{(3)}_{4,3} = A_{perm, 43}^{(2)} - 40/9 = 0 - 40/9 = -40/9$.\nThe matrix becomes:\n$$ A^{(3)} = \\begin{pmatrix}\n6 & 0 & 0 & 3 & 0 & 0 & 0 & 0\\\\\n0 & 9 & 5 & 0 & 0 & 0 & 0 & 0\\\\\n1/3 & 0 & 1 & -1 & 0 & 0 & 0 & 0\\\\\n0 & 8/9 & -40/9 & 0 & 4 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 7 & 0 & 5 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 6 & 0 & 2 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 7 & 0 & 1\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 8 & 0\n\\end{pmatrix} $$\n\n**Step 3: Third Pivot ($k=3$)**\n\nThe active submatrix is $A^{(3)}[3:8, 3:8]$. We search for a pivot starting at $A^{(3)}_{3,3}=1$.\n1.  Maximum magnitude in the first row of submatrix (global row $3$) is $|-1|=1$, a tie. We can remain in the first column (global column $3$).\n2.  Maximum magnitude in this column of the submatrix is $|A^{(3)}_{4,3}| = |-40/9| \\approx 4.44$. Search moves to the second row of the submatrix (global row $4$).\n3.  Maximum magnitude in this row of the submatrix (global row $4$) is $|-40/9|$, as $|-40/9|>|4|$. The search remains in the current column.\n4.  The search has stabilized.\n\nThe third pivot is $p_3 = -40/9$, located at global position $(i,j) = (4,3)$.\nTo bring this to position $(3,3)$, we swap rows $i=4$ and $k=3$, so $P_3=(3,4)$. Column $j=3$ is correct, so $Q_3=I$.\nApplying $P_3$ to $A^{(3)}$ swaps rows $3$ and $4$, including the stored multipliers:\n$$ A_{perm}^{(3)} = P_3 A^{(3)} = \\begin{pmatrix}\n6 & 0 & 0 & 3 & 0 & 0 & 0 & 0\\\\\n0 & 9 & 5 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 8/9 & -40/9 & 0 & 4 & 0 & 0 & 0\\\\\n1/3 & 0 & 1 & -1 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 7 & 0 & 5 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 6 & 0 & 2 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 7 & 0 & 1\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 8 & 0\n\\end{pmatrix} $$\nThe multipliers are $l_{i3} = A_{perm, i3}^{(3)}/p_3$ for $i > 3$. The only non-zero is $A_{perm, 43}^{(3)}=1$.\nThe vector of multipliers is $l_3 = [1/(-40/9), 0, ...]^T = [-9/40, 0, 0, 0, 0]^T$.\nThe update is $A_{44} \\leftarrow A_{44} - l_3 u_3^T$, where $u_3^T = A_{perm}^{(3)}[3, 4:8] = [0, 4, 0, 0, 0]$.\nThe only non-zero term in $l_3 u_3^T$ is $l_{43} \\cdot u_{35} = (-9/40) \\cdot 4 = -36/40 = -9/10$. This updates global position $(4,5)$. $A^{(4)}_{4,5} = A_{perm, 45}^{(3)} - (-9/10) = 0 + 9/10 = 9/10$.\n\n**Summary of Results**\n\n1.  **Row and Column Permutations**:\n    - Step 1 ($k=1$): Row permutation $P_1=(1,3)$, Column permutation $Q_1=(1,2)$.\n    - Step 2 ($k=2$): Row permutation $P_2=I$ (identity), Column permutation $Q_2=(2,3)$.\n    - Step 3 ($k=3$): Row permutation $P_3=(3,4)$, Column permutation $Q_3=I$ (identity).\n\n2.  **Multipliers in the L factor**:\n    The multipliers populating the strictly lower-triangular part of the $L$ factor for the first three columns are:\n    - Column 1: $l_{41}=1/3$. All other $l_{i1}=0$ for $i>1$.\n    - Column 2: $l_{32}=8/9$. All other $l_{i2}=0$ for $i>2$.\n    - Column 3: $l_{43}=-9/40$. All other $l_{i3}=0$ for $i>3$.\n\n3.  **Trailing Updated Submatrix (Schur Complement)**:\n    This is the submatrix $A^{(4)}[4:8, 4:8]$. From the final update, this is:\n    $$ S = \\begin{pmatrix}\n    -1 & 9/10 & 0 & 0 & 0\\\\\n    7 & 0 & 5 & 0 & 0\\\\\n    0 & 6 & 0 & 2 & 0\\\\\n    0 & 0 & 7 & 0 & 1\\\\\n    0 & 0 & 0 & 8 & 0\n    \\end{pmatrix} $$\n\n**Final Calculation**\n\nThe three pivots selected are $p_1=6$, $p_2=9$, and $p_3=-40/9$.\nThe product of their magnitudes is:\n$$ |p_1| \\cdot |p_2| \\cdot |p_3| = |6| \\cdot |9| \\cdot \\left|-\\frac{40}{9}\\right| = 6 \\cdot 9 \\cdot \\frac{40}{9} = 6 \\cdot 40 = 240 $$\nThis is the final numerical answer requested.",
            "answer": "$$\n\\boxed{240}\n$$"
        },
        {
            "introduction": "The true value of a numerical algorithm is revealed through its implementation and performance on challenging problems. This capstone exercise requires you to write your own LU solvers for both partial and rook pivoting and use them as experimental tools. By testing your solvers against a suite of known ill-conditioned matrices, you will empirically verify the superior stability of rook pivoting and understand the trade-offs between computational cost and numerical robustness .",
            "id": "3575115",
            "problem": "Implement two Gaussian elimination solvers for square, nonsingular matrices: one using partial (row) pivoting and one using rook pivoting. Start from the fundamental definition that Gaussian elimination factors a matrix $A \\in \\mathbb{R}^{n \\times n}$ into triangular factors and permutations so that either $P A = L U$ (partial pivoting) or $P A Q = L U$ (rook pivoting), where $P$ and $Q$ are permutation matrices, $L$ is unit lower triangular, and $U$ is upper triangular. The rook pivoting strategy selects a pivot that is simultaneously the maximum magnitude in its current column and, upon alternating search, also the maximum in its corresponding row within the active submatrix. You must implement both strategies from first principles, without calling a library decomposition routine.\n\nUsing these two solvers, empirically investigate a curriculum of increasingly ill-conditioned matrices and identify cases where partial pivoting “fails” while rook pivoting maintains an acceptable normwise backward error. The notion of failure must be derived from first principles grounded in backward error and element growth. Specifically:\n\n- For a computed solution $\\hat{x}$ to $A x = b$, define the normwise backward error\n$$\n\\eta(A,b,\\hat{x}) = \\frac{\\lVert b - A \\hat{x}\\rVert_{2}}{\\lVert A\\rVert_{2}\\,\\lVert \\hat{x}\\rVert_{2} + \\lVert b\\rVert_{2}},\n$$\nwhich measures the minimal relative perturbation that would make $\\hat{x}$ an exact solution. This is the foundational metric of acceptable numerical behavior.\n\n- Define the element growth factor\n$$\n\\rho = \\frac{\\max_{i,j} |U_{ij}|}{\\max_{i,j} |A_{ij}|},\n$$\nwhich measures amplification of elements during elimination and serves as a practical risk indicator.\n\nFor each test case, use the exact right-hand side $b = A \\,\\mathbf{1}$, where $\\mathbf{1} \\in \\mathbb{R}^{n}$ is the vector of all ones. Compute $\\hat{x}_{\\mathrm{pp}}$ using partial pivoting and $\\hat{x}_{\\mathrm{rook}}$ using rook pivoting, and evaluate $\\eta(A,b,\\hat{x}_{\\mathrm{pp}})$, $\\eta(A,b,\\hat{x}_{\\mathrm{rook}})$, and the growth factor $\\rho_{\\mathrm{pp}}$ observed during the partial-pivoting factorization. Declare that partial pivoting “fails” if either the backward error exceeds a fixed tolerance or the observed growth factor exceeds a fixed bound, while rook pivoting is “acceptable” if its backward error is within the tolerance. Use the following acceptance criteria:\n- Acceptable backward error tolerance: $\\eta \\le 5\\times 10^{-12}$.\n- Partial pivoting failure growth threshold: $\\rho_{\\mathrm{pp}} > 10^{3}$.\n\nFamilies of test matrices. Construct the following parametrized, deterministic families (with $1$-based indexing in their definitions, which must be carefully mapped to $0$-based program indices):\n\n- Wilkinson matrix $W_{n}$ of order $n$: \n$$\n(W_n)_{ij} = \\begin{cases}\n1, & \\text{if } i=j \\text{ or } j=n, \\\\\n-1, & \\text{if } i > j, \\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\n\n- Lotkin matrix $L_{n}$ of order $n$:\n$$\n(L_n)_{1j} = 1 \\text{ for } 1 \\le j \\le n, \\quad (L_n)_{ij} = \\frac{1}{i + j - 1} \\text{ for } 2 \\le i \\le n, \\, 1 \\le j \\le n.\n$$\n\n- Vandermonde matrix $V_{n}(\\alpha)$ of order $n$ with nodes $\\{t_i\\}_{i=1}^n$:\n$$\nt_i = \\alpha_0 + \\frac{i-1}{n-1}(\\alpha_1 - \\alpha_0), \\quad 0 < \\alpha_0 < \\alpha_1 < 1, \\quad V_{ij} = t_i^{\\,j-1}.\n$$\nUse $(\\alpha_0,\\alpha_1)=(0.9,1.0)$ for all Vandermonde tests.\n\n- Kahan-type upper-triangular family $K_{n}(s)$ of order $n$ with a parameter $s \\in (0,1)$ and $c = \\sqrt{1 - s^{2}}$:\n$$\n(K_n(s))_{ii} = 1 \\text{ for } 1 \\le i \\le n,\\quad (K_n(s))_{ij} = -c \\text{ for } 1 \\le i < j \\le n,\\quad (K_n(s))_{i1} = s^{\\,i-1} \\text{ for } 1 \\le i \\le n.\n$$\nThis family is explicitly defined here to provide an additional, tunable triangular case.\n\nYour program must implement:\n- A partial-pivoting Gaussian elimination that returns $P$, $L$, $U$, the row permutation as an index map, and the element growth factor $\\rho_{\\mathrm{pp}}$.\n- A rook-pivoting Gaussian elimination that returns $P$, $Q$, $L$, $U$, the row and column index maps, and its element growth factor $\\rho_{\\mathrm{rook}}$.\n\nUse forward and backward substitution to solve the triangular systems implied by the factorizations, taking care to correctly apply $P$ and $Q$ according to $P A = L U$ (partial) and $P A Q = L U$ (rook). Compute $\\eta$ for both solvers on each test.\n\nTest suite. To ensure coverage across benign, borderline, and adversarial regimes, run the following seven cases:\n\n- Case $1$: Wilkinson, $n=8$.\n- Case $2$: Wilkinson, $n=16$.\n- Case $3$: Lotkin, $n=8$.\n- Case $4$: Lotkin, $n=12$.\n- Case $5$: Vandermonde, $n=10$, $(\\alpha_0,\\alpha_1)=(0.9,1.0)$.\n- Case $6$: Vandermonde, $n=12$, $(\\alpha_0,\\alpha_1)=(0.95,1.0)$.\n- Case $7$: Kahan-type, $n=12$, $s=0.99$.\n\nFor each case, output the indicator\n$$\n\\mathsf{flag} = \\begin{cases}\n1, & \\text{if partial pivoting fails and rook pivoting has acceptable backward error},\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\nConcretely, “partial pivoting fails” means $\\eta(A,b,\\hat{x}_{\\mathrm{pp}}) > 5\\times 10^{-12}$ or $\\rho_{\\mathrm{pp}} > 10^{3}$, and “rook pivoting acceptable” means $\\eta(A,b,\\hat{x}_{\\mathrm{rook}}) \\le 5\\times 10^{-12}$.\n\nFinal output format. Your program should produce a single line of output containing the seven flags, as a comma-separated list enclosed in square brackets (e.g., “[0,1,0,0,0,0,0]”), corresponding in order to Cases $1$ through $7$. There are no physical units or angles involved in this task. All numeric comparisons are to be performed in standard double precision.",
            "solution": "The user-provided problem is assessed to be valid. It is a well-posed, scientifically grounded problem in numerical linear algebra with clear, objective criteria and a complete set of specifications. The task is to implement and empirically compare Gaussian elimination with partial pivoting and rook pivoting, focusing on scenarios where the former exhibits numerical instability while the latter remains stable.\n\n### 1. Principle of Gaussian Elimination with Pivoting\n\nGaussian elimination is a fundamental algorithm for solving a linear system $A x = b$, where $A \\in \\mathbb{R}^{n \\times n}$ is a square, nonsingular matrix. The core idea is to factor the matrix $A$ into a product of a lower triangular matrix $L$ and an upper triangular matrix $U$. To ensure numerical stability, especially when dealing with ill-conditioned matrices, this process is augmented with pivoting, which involves interchanging rows and/or columns of the matrix.\n\nThe factorization takes the form $P A = L U$ for partial (row) pivoting or $P A Q = L U$ for strategies involving column interchanges, such as rook pivoting. Here, $P$ and $Q$ are permutation matrices, $L$ is a unit lower triangular matrix (with ones on its diagonal), and $U$ is an upper triangular matrix. The process is performed in-place on a copy of $A$. After $k-1$ steps, the matrix $A^{(k-1)}$ has the form where the first $k-1$ columns are finalized. At step $k$ (for $k=0, \\dots, n-2$), a pivot element is selected from the active submatrix $A^{(k-1)}_{k:n, k:n}$. After row and/or column swaps, the pivot is located at position $(k,k)$. Multipliers are then computed from the elements below the pivot in column $k$, and these are used to introduce zeros into column $k$ below the diagonal by subtracting multiples of the pivot row from subsequent rows.\n\n### 2. Pivoting Strategies\n\n#### 2.1. Partial (Row) Pivoting\n\nPartial pivoting is the most common strategy. At each step $k$ of the elimination, the algorithm searches for the element with the largest absolute value in the current pivot column, on or below the diagonal.\nLet the active matrix be $A$. At step $k \\in \\{0, \\dots, n-2\\}$, we find an index $p \\ge k$ such that:\n$$ |A_{pk}| = \\max_{i=k, \\dots, n-1} |A_{ik}| $$\nRow $k$ and row $p$ are then interchanged. This permutation is recorded in a permutation matrix $P$ (or more efficiently, a permutation vector). The goal is to make the multipliers $m_{ik} = A_{ik}/A_{kk}$ as small as possible in magnitude (i.e., $|m_{ik}| \\le 1$), which helps to control the growth of elements during elimination.\n\nThe factorization obtained is $PA = LU$.\n\n#### 2.2. Rook Pivoting\n\nRook pivoting is a stronger, though more computationally expensive, pivoting strategy. It aims to find a pivot element that is the largest in both its row and its column within the active submatrix. This is achieved through an iterative search. At step $k$, let the active submatrix be $A_{k:n, k:n}$.\n\nThe search proceeds as follows:\n1.  Initialize a candidate pivot, for instance, at $(p, q) = (k, k)$.\n2.  Search for the element with the maximum magnitude in the current pivot's column $q$ (among rows $i \\ge k$). Let this be at position $(p', q)$. If this element is larger than the current pivot $|A_{pq}|$, update the pivot row: $p \\leftarrow p'$.\n3.  Search for the element with the maximum magnitude in the newly updated pivot's row $p$ (among columns $j \\ge k$). Let this be at position $(p, q')$.\n4.  If this element is larger than the current pivot $|A_{pq}|$, update the pivot column: $q \\leftarrow q'$, and return to step 2.\n5.  If the pivot $|A_{pq}|$ is the largest magnitude element in its column (from step 2), the search stabilizes and terminates. The element $A_{pq}$ is chosen as the pivot.\n\nOnce the pivot at $(p, q)$ is selected, row $k$ is swapped with row $p$, and column $k$ is swapped with column $q$. These permutations are recorded in matrices $P$ and $Q$. The factorization obtained is $PAQ = LU$.\n\n### 3. Solving the Linear System\n\nOnce the LU factorization is computed, solving $Ax=b$ proceeds in two stages using forward and backward substitution.\n\n- **For Partial Pivoting ($PA=LU$)**: The system $Ax=b$ is rewritten as $LUx = Pb$.\n    1.  Compute the permuted right-hand side vector $b' = Pb$.\n    2.  Solve the lower triangular system $Ly = b'$ for $y$ (forward substitution).\n    3.  Solve the upper triangular system $Ux = y$ for $x$ (backward substitution).\n\n- **For Rook Pivoting ($PAQ=LU$)**: The system $Ax=b$ is rewritten as $LU(Q^T x) = Pb$. Let $z = Q^T x$.\n    1.  Compute $b' = Pb$.\n    2.  Solve $Lz = b'$ for $z$ (forward substitution).\n    3.  Solve $Uy = z$ for $y$ (backward substitution).\n    4.  Recover the solution $x$ by applying the column permutation: $x = Qy$.\n\n### 4. Numerical Stability Assessment\n\nThe quality and stability of the numerical solution are assessed using two metrics.\n\n- **Element Growth Factor ($\\rho$)**: Defined as\n  $$ \\rho = \\frac{\\max_{i,j} |U_{ij}|}{\\max_{i,j} |A_{ij}|} $$\n  A large growth factor indicates that intermediate values during elimination became much larger than the initial matrix elements, which is a primary source of round-off error amplification. The problem specifies a failure threshold $\\rho_{\\mathrm{pp}} > 10^3$ for partial pivoting.\n\n- **Normwise Backward Error ($\\eta$)**: For a computed solution $\\hat{x}$, the backward error is\n  $$ \\eta(A,b,\\hat{x}) = \\frac{\\lVert b - A \\hat{x}\\rVert_{2}}{\\lVert A\\rVert_{2}\\,\\lVert \\hat{x}\\rVert_{2} + \\lVert b\\rVert_{2}} $$\n  This measures the smallest relative perturbation to the problem $(A, b)$ that would make $\\hat{x}$ an exact solution. It is a direct measure of the quality of the computed solution, independent of the problem's condition number. The problem specifies an acceptable tolerance of $\\eta \\le 5 \\times 10^{-12}$.\n\n### 5. Methodology\n\nFor each of the seven test cases, the following procedure is executed:\n1.  The specified test matrix $A$ of size $n \\times n$ is constructed.\n2.  The right-hand side vector is set to $b = A\\mathbf{1}$, where $\\mathbf{1}$ is the vector of all ones. The exact solution is thus $x = \\mathbf{1}$.\n3.  The system is solved using the implemented Gaussian elimination with partial pivoting, yielding $\\hat{x}_{\\mathrm{pp}}$ and the growth factor $\\rho_{\\mathrm{pp}}$.\n4.  The system is solved using Gaussian elimination with rook pivoting, yielding $\\hat{x}_{\\mathrm{rook}}$.\n5.  The backward errors $\\eta_{\\mathrm{pp}} = \\eta(A,b,\\hat{x}_{\\mathrm{pp}})$ and $\\eta_{\\mathrm{rook}} = \\eta(A,b,\\hat{x}_{\\mathrm{rook}})$ are computed.\n6.  A flag is set to $1$ if partial pivoting is deemed to have \"failed\" while rook pivoting was \"acceptable\", and $0$ otherwise. \"Failure\" for partial pivoting is defined as $\\eta_{\\mathrm{pp}} > 5 \\times 10^{-12}$ or $\\rho_{\\mathrm{pp}} > 10^3$. \"Acceptable\" for rook pivoting is defined as $\\eta_{\\mathrm{rook}} \\le 5 \\times 10^{-12}$. This logic determines the final output for each case.",
            "answer": "$$\n\\boxed{[1,1,0,0,1,1,1]}\n$$"
        }
    ]
}