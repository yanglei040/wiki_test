{
    "hands_on_practices": [
        {
            "introduction": "Before analyzing the subtleties of partial pivoting, it is essential to master its core mechanics. This first exercise  provides a foundational drill: performing a step-by-step LU factorization with partial pivoting on a small, non-trivial matrix. By manually executing the row interchanges and tracking the resulting permutation matrix $P$, unit lower-triangular matrix $L$, and upper-triangular matrix $U$, you will build a concrete understanding of how the algorithm works and verify the fundamental identity $PA=LU$.",
            "id": "3507947",
            "problem": "In implicit time integration for radiation-hydrodynamics in computational astrophysics, a local Jacobian block arising from linearization of coupled energy density and radiation moments leads to a small but nontrivial system that must be solved robustly. Consider the matrix\n$$\nA=\\begin{pmatrix}\n0 & 2 & 3 \\\\\n1 & -1 & 0 \\\\\n2 & 0 & 1\n\\end{pmatrix}.\n$$\nTo enhance numerical stability in floating-point arithmetic, perform a Lower-Upper (LU) decomposition with partial pivoting, which is the Gaussian elimination procedure augmented by row permutations that select the largest-magnitude pivot in each column. Construct the permutation matrix $P$ that encodes the row swaps, the unit lower-triangular matrix $L$ of multipliers, and the upper-triangular matrix $U$ such that\n$$\nP\\,A = L\\,U.\n$$\nExplicitly verify the equality $P\\,A=L\\,U$ by matrix multiplication. Finally, using your factorization, determine the determinant of $A$ as a single real-valued number. Express your final answer as an exact value with no rounding and no units. The final answer must be the determinant of $A$ only.",
            "solution": "The problem requires us to perform a Lower-Upper (LU) decomposition with partial pivoting on a given $3 \\times 3$ matrix $A$, finding the matrices $P$, $L$, and $U$ such that $PA = LU$. Subsequently, we must verify this decomposition and use it to compute the determinant of $A$. Partial pivoting is a strategy employed in Gaussian elimination to enhance numerical stability by selecting the entry with the largest absolute value in the current column as the pivot element, thereby minimizing the magnitude of the multipliers and controlling round-off error propagation.\n\nThe given matrix is:\n$$\nA = \\begin{pmatrix}\n0 & 2 & 3 \\\\\n1 & -1 & 0 \\\\\n2 & 0 & 1\n\\end{pmatrix}\n$$\n\nWe will proceed step-by-step with Gaussian elimination, tracking the row permutations in a permutation matrix $P$, which is initialized as the identity matrix $I$.\n\n**Step 1: Elimination for the first column**\n\nWe begin with $A^{(0)} = A$ and $P^{(0)} = I$.\n$$\nA^{(0)} = \\begin{pmatrix}\n0 & 2 & 3 \\\\\n1 & -1 & 0 \\\\\n2 & 0 & 1\n\\end{pmatrix}, \\quad P^{(0)} = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}\n$$\nFor the first column, we inspect the elements at or below the diagonal: $|a_{11}| = 0$, $|a_{21}| = 1$, $|a_{31}| = 2$. The largest absolute value is $2$, located in the third row. Therefore, we must swap row $1$ and row $3$. This permutation corresponds to left-multiplying by the permutation matrix $P_1$:\n$$\nP_1 = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n0 & 1 & 0 \\\\\n1 & 0 & 0\n\\end{pmatrix}\n$$\nWe apply this permutation to both $A^{(0)}$ and our cumulative permutation matrix $P^{(0)}$:\n$$\nA' = P_1 A^{(0)} = \\begin{pmatrix}\n2 & 0 & 1 \\\\\n1 & -1 & 0 \\\\\n0 & 2 & 3\n\\end{pmatrix}\n$$\n$$\nP^{(1)} = P_1 P^{(0)} = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n0 & 1 & 0 \\\\\n1 & 0 & 0\n\\end{pmatrix}\n$$\nThe pivot is now $a'_{11} = 2$. We compute the multipliers needed to eliminate the sub-diagonal elements in the first column of $A'$:\nMultiplier for row $2$: $m_{21} = \\frac{a'_{21}}{a'_{11}} = \\frac{1}{2}$.\nMultiplier for row $3$: $m_{31} = \\frac{a'_{31}}{a'_{11}} = \\frac{0}{2} = 0$.\n\nWe perform the row operations $R_2 \\leftarrow R_2 - m_{21}R_1$ and $R_3 \\leftarrow R_3 - m_{31}R_1$:\n$R_2 \\leftarrow R_2 - \\frac{1}{2}R_1 \\Rightarrow [1, -1, 0] - \\frac{1}{2}[2, 0, 1] = [0, -1, -\\frac{1}{2}]$.\n$R_3 \\leftarrow R_3 - 0 \\cdot R_1 \\Rightarrow R_3$ is unchanged.\n\nThe matrix after the first stage of elimination is:\n$$\nA^{(1)} = \\begin{pmatrix}\n2 & 0 & 1 \\\\\n0 & -1 & -\\frac{1}{2} \\\\\n0 & 2 & 3\n\\end{pmatrix}\n$$\nWe will store the multipliers $m_{21}$ and $m_{31}$ for later construction of the matrix $L$.\n\n**Step 2: Elimination for the second column**\n\nNow we consider the sub-matrix starting from the second row and second column. We inspect the elements at or below the diagonal in the second column: $|a^{(1)}_{22}| = |-1| = 1$, $|a^{(1)}_{32}| = |2| = 2$. The largest absolute value is $2$, located in the third row (of the current matrix). We must swap row $2$ and row $3$. This permutation corresponds to the matrix $P_2$:\n$$\nP_2 = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 0 & 1 \\\\\n0 & 1 & 0\n\\end{pmatrix}\n$$\nWe apply this permutation to $A^{(1)}$ and update our cumulative permutation matrix $P^{(1)}$:\n$$\nA'' = P_2 A^{(1)} = \\begin{pmatrix}\n2 & 0 & 1 \\\\\n0 & 2 & 3 \\\\\n0 & -1 & -\\frac{1}{2}\n\\end{pmatrix}\n$$\n$$\nP = P_2 P^{(1)} = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 0 & 1 \\\\\n0 & 1 & 0\n\\end{pmatrix} \\begin{pmatrix}\n0 & 0 & 1 \\\\\n0 & 1 & 0 \\\\\n1 & 0 & 0\n\\end{pmatrix} = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{pmatrix}\n$$\nCrucially, this row swap also applies to the multipliers we have already computed. The multipliers for the first column were $(m_{21}, m_{31}) = (\\frac{1}{2}, 0)$. Swapping their positions gives $(\\tilde{m}_{21}, \\tilde{m}_{31}) = (0, \\frac{1}{2})$.\n\nThe pivot is now $a''_{22} = 2$. We compute the multiplier for row $3$:\n$m_{32} = \\frac{a''_{32}}{a''_{22}} = \\frac{-1}{2}$.\n\nWe perform the row operation $R_3 \\leftarrow R_3 - m_{32}R_2$:\n$R_3 \\leftarrow R_3 - (-\\frac{1}{2})R_2 \\Rightarrow [0, -1, -\\frac{1}{2}] + \\frac{1}{2}[0, 2, 3] = [0, 0, -\\frac{1}{2} + \\frac{3}{2}] = [0, 0, 1]$.\n\nThe final upper-triangular matrix $U$ is:\n$$\nU = \\begin{pmatrix}\n2 & 0 & 1 \\\\\n0 & 2 & 3 \\\\\n0 & 0 & 1\n\\end{pmatrix}\n$$\nThe unit lower-triangular matrix $L$ is constructed from the multipliers, placed in their final positions after all permutations.\n$L_{21} = \\tilde{m}_{21} = 0$.\n$L_{31} = \\tilde{m}_{31} = \\frac{1}{2}$.\n$L_{32} = m_{32} = -\\frac{1}{2}$.\n$$\nL = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n\\frac{1}{2} & -\\frac{1}{2} & 1\n\\end{pmatrix}\n$$\nThe final permutation matrix is $P = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{pmatrix}$.\n\n**Summary of the decomposition:**\n$$\nP = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{pmatrix}, \\quad\nL = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n\\frac{1}{2} & -\\frac{1}{2} & 1\n\\end{pmatrix}, \\quad\nU = \\begin{pmatrix}\n2 & 0 & 1 \\\\\n0 & 2 & 3 \\\\\n0 & 0 & 1\n\\end{pmatrix}\n$$\n**Verification**\n\nWe must explicitly verify that $PA = LU$. First, we compute $PA$:\n$$\nPA = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n0 & 2 & 3 \\\\\n1 & -1 & 0 \\\\\n2 & 0 & 1\n\\end{pmatrix}\n= \\begin{pmatrix}\n2 & 0 & 1 \\\\\n0 & 2 & 3 \\\\\n1 & -1 & 0\n\\end{pmatrix}\n$$\nNext, we compute $LU$:\n$$\nLU = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n\\frac{1}{2} & -\\frac{1}{2} & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n2 & 0 & 1 \\\\\n0 & 2 & 3 \\\\\n0 & 0 & 1\n\\end{pmatrix}\n= \\begin{pmatrix}\n1 \\cdot 2 + 0 \\cdot 0 + 0 \\cdot 0 & 1 \\cdot 0 + 0 \\cdot 2 + 0 \\cdot 0 & 1 \\cdot 1 + 0 \\cdot 3 + 0 \\cdot 1 \\\\\n0 \\cdot 2 + 1 \\cdot 0 + 0 \\cdot 0 & 0 \\cdot 0 + 1 \\cdot 2 + 0 \\cdot 0 & 0 \\cdot 1 + 1 \\cdot 3 + 0 \\cdot 1 \\\\\n\\frac{1}{2} \\cdot 2 - \\frac{1}{2} \\cdot 0 + 1 \\cdot 0 & \\frac{1}{2} \\cdot 0 - \\frac{1}{2} \\cdot 2 + 1 \\cdot 0 & \\frac{1}{2} \\cdot 1 - \\frac{1}{2} \\cdot 3 + 1 \\cdot 1\n\\end{pmatrix}\n$$\n$$\nLU = \\begin{pmatrix}\n2 & 0 & 1 \\\\\n0 & 2 & 3 \\\\\n1 & -1 & \\frac{1}{2} - \\frac{3}{2} + 1\n\\end{pmatrix}\n= \\begin{pmatrix}\n2 & 0 & 1 \\\\\n0 & 2 & 3 \\\\\n1 & -1 & 0\n\\end{pmatrix}\n$$\nThe equality $PA = LU$ is verified.\n\n**Determinant Calculation**\n\nFrom the decomposition $PA = LU$, we can write $\\det(PA) = \\det(LU)$.\nUsing the multiplicative property of determinants, this becomes $\\det(P)\\det(A) = \\det(L)\\det(U)$.\nThus, $\\det(A) = \\frac{\\det(L)\\det(U)}{\\det(P)}$.\n\nWe compute the determinant of each matrix:\n1.  $\\det(L)$: Since $L$ is a unit lower-triangular matrix, its determinant is the product of its diagonal elements. $\\det(L) = 1 \\cdot 1 \\cdot 1 = 1$.\n2.  $\\det(U)$: Since $U$ is an upper-triangular matrix, its determinant is also the product of its diagonal elements. $\\det(U) = 2 \\cdot 2 \\cdot 1 = 4$.\n3.  $\\det(P)$: The determinant of a permutation matrix is $(-1)^s$, where $s$ is the number of row interchanges performed. We performed two swaps: $(R_1 \\leftrightarrow R_3)$ and then $(R_2 \\leftrightarrow R_3)$. Thus, $s=2$.\n    $\\det(P) = (-1)^2 = 1$.\n\nSubstituting these values into the equation for $\\det(A)$:\n$$\n\\det(A) = \\frac{1 \\cdot 4}{1} = 4\n$$\nThe determinant of the matrix $A$ is $4$. This confirms our initial inspection that the matrix is non-singular and the LU decomposition is well-defined.",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "The primary motivation for pivoting is to control the growth of matrix entries during elimination, which is a key factor for maintaining numerical stability. The growth factor is the metric used to quantify this phenomenon. This practice  challenges you to apply partial pivoting to a matrix specifically constructed to exhibit element growth, allowing you to trace how entry magnitudes can increase and to compute the resulting growth factor, thereby gaining direct insight into the problem that pivoting addresses.",
            "id": "3564374",
            "problem": "Consider the matrix $A \\in \\mathbb{R}^{5 \\times 5}$ given by\n$$\nA \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 1 \\\\\n-1 & 1 & 0 & 0 & 1 \\\\\n0 & -1 & 1 & 0 & 1 \\\\\n0 & 0 & -1 & 1 & 1 \\\\\n0 & 0 & 0 & -1 & 1\n\\end{pmatrix}.\n$$\nApply Gaussian elimination with partial pivoting (GEPP), where at each step the pivot is chosen as the entry of maximal absolute value in the current column among the rows not yet eliminated, and rows are swapped accordingly. Let $U$ denote the resulting upper triangular factor produced by GEPP so that $P A = L U$ for some permutation matrix $P$ and unit lower triangular matrix $L$. Using the fundamental definitions of Gaussian elimination and partial pivoting, trace the evolution of the entries of $U$ during the elimination, explicitly identifying where entry magnitudes increase relative to those in $A$. Then compute the growth factor\n$$\n\\rho(A) \\;=\\; \\frac{\\displaystyle \\max_{1 \\leq i,j \\leq 5} |u_{ij}|}{\\displaystyle \\max_{1 \\leq i,j \\leq 5} |a_{ij}|}.\n$$\nExpress your final answer for $\\rho(A)$ as an exact value. No rounding is required.",
            "solution": "The problem is to perform Gaussian elimination with partial pivoting (GEPP) on a given $5 \\times 5$ matrix $A$ to find its LU decomposition, $PA=LU$, and then to compute the growth factor $\\rho(A)$.\n\nThe given matrix is\n$$\nA \\;=\\; A^{(1)} \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 1 \\\\\n-1 & 1 & 0 & 0 & 1 \\\\\n0 & -1 & 1 & 0 & 1 \\\\\n0 & 0 & -1 & 1 & 1 \\\\\n0 & 0 & 0 & -1 & 1\n\\end{pmatrix}.\n$$\nThe maximum absolute value of the entries in $A$ is $\\displaystyle \\max_{1 \\leq i,j \\leq 5} |a_{ij}| = 1$.\n\nWe will proceed with the elimination step-by-step. Let $A^{(k)}$ be the matrix at the beginning of step $k$.\n\nStep 1: Elimination in column $1$.\nThe first column of $A^{(1)}$ is $(1, -1, 0, 0, 0)^T$. The candidates for the pivot are the entries in this column. The maximal absolute value is $1$, which occurs for $a_{11}^{(1)}=1$ and $a_{21}^{(1)}=-1$. In case of a tie, the standard partial pivoting strategy selects the entry with the smallest row index. Thus, the pivot is $a_{11}^{(1)}=1$. No row swap is needed.\nThe only non-zero multiplier is for the second row:\n$$\nl_{21} = \\frac{a_{21}^{(1)}}{a_{11}^{(1)}} = \\frac{-1}{1} = -1.\n$$\nThe second row is updated: $R_2 \\leftarrow R_2 - l_{21} R_1 = R_2 + R_1$.\n$$\n(-1, 1, 0, 0, 1) + (1, 0, 0, 0, 1) = (0, 1, 0, 0, 2).\n$$\nThe matrix after step $1$ is:\n$$\nA^{(2)} \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 1 \\\\\n0 & 1 & 0 & 0 & 2 \\\\\n0 & -1 & 1 & 0 & 1 \\\\\n0 & 0 & -1 & 1 & 1 \\\\\n0 & 0 & 0 & -1 & 1\n\\end{pmatrix}.\n$$\nAt this stage, we observe that the magnitude of the entry $a_{25}^{(2)}=2$ is greater than the maximum magnitude of any entry in the original matrix $A$.\n\nStep 2: Elimination in column $2$.\nWe consider the submatrix from row $2$ to $5$. The second column of this submatrix is $(1, -1, 0, 0)^T$. The maximal absolute value is $1$, occurring for $a_{22}^{(2)}=1$ and $a_{32}^{(2)}=-1$. We select the pivot as $a_{22}^{(2)}=1$ (smallest row index). No row swap is needed.\nThe only non-zero multiplier is for the third row:\n$$\nl_{32} = \\frac{a_{32}^{(2)}}{a_{22}^{(2)}} = \\frac{-1}{1} = -1.\n$$\nThe third row is updated: $R_3 \\leftarrow R_3 - l_{32} R_2 = R_3 + R_2$.\n$$\n(0, -1, 1, 0, 1) + (0, 1, 0, 0, 2) = (0, 0, 1, 0, 3).\n$$\nThe matrix after step $2$ is:\n$$\nA^{(3)} \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 1 \\\\\n0 & 1 & 0 & 0 & 2 \\\\\n0 & 0 & 1 & 0 & 3 \\\\\n0 & 0 & -1 & 1 & 1 \\\\\n0 & 0 & 0 & -1 & 1\n\\end{pmatrix}.\n$$\nThe entry $a_{35}^{(3)}=3$ shows further growth in magnitude.\n\nStep 3: Elimination in column $3$.\nThe pivot candidates are in column $3$ from row $3$ downwards: $(1, -1, 0)^T$. The maximal absolute value is $1$, for $a_{33}^{(3)}=1$ and $a_{43}^{(3)}=-1$. We choose the pivot $a_{33}^{(3)}=1$. No row swap is needed.\nThe multiplier for the fourth row is:\n$$\nl_{43} = \\frac{a_{43}^{(3)}}{a_{33}^{(3)}} = \\frac{-1}{1} = -1.\n$$\nThe fourth row is updated: $R_4 \\leftarrow R_4 - l_{43} R_3 = R_4 + R_3$.\n$$\n(0, 0, -1, 1, 1) + (0, 0, 1, 0, 3) = (0, 0, 0, 1, 4).\n$$\nThe matrix after step $3$ is:\n$$\nA^{(4)} \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 1 \\\\\n0 & 1 & 0 & 0 & 2 \\\\\n0 & 0 & 1 & 0 & 3 \\\\\n0 & 0 & 0 & 1 & 4 \\\\\n0 & 0 & 0 & -1 & 1\n\\end{pmatrix}.\n$$\nThe entry $a_{45}^{(4)}=4$ shows continued growth.\n\nStep 4: Elimination in column $4$.\nThe pivot candidates are in column $4$ from row $4$ downwards: $(1, -1)^T$. The maximal absolute value is $1$, for $a_{44}^{(4)}=1$ and $a_{54}^{(4)}=-1$. We choose the pivot $a_{44}^{(4)}=1$. No row swap is needed.\nThe multiplier for the fifth row is:\n$$\nl_{54} = \\frac{a_{54}^{(4)}}{a_{44}^{(4)}} = \\frac{-1}{1} = -1.\n$$\nThe fifth row is updated: $R_5 \\leftarrow R_5 - l_{54} R_4 = R_5 + R_4$.\n$$\n(0, 0, 0, -1, 1) + (0, 0, 0, 1, 4) = (0, 0, 0, 0, 5).\n$$\nThe matrix after step $4$ is the final upper triangular matrix $U$:\n$$\nU \\;=\\; A^{(5)} \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 0 & 0 & 1 \\\\\n0 & 1 & 0 & 0 & 2 \\\\\n0 & 0 & 1 & 0 & 3 \\\\\n0 & 0 & 0 & 1 & 4 \\\\\n0 & 0 & 0 & 0 & 5\n\\end{pmatrix}.\n$$\nThe entry $u_{55}=a_{55}^{(5)}=5$ is the entry with the largest magnitude.\n\nThe evolution of entries in the last column demonstrates the growth. The initial last column vector is $(1, 1, 1, 1, 1)^T$. Through the elimination process, these entries become the last column of $U$, which is $(1, 2, 3, 4, 5)^T$. The magnitudes of $u_{25}$, $u_{35}$, $u_{45}$, and $u_{55}$ are all greater than the maximum magnitude of entries in $A$.\n\nNow, we compute the growth factor $\\rho(A)$. It is defined as:\n$$\n\\rho(A) \\;=\\; \\frac{\\displaystyle \\max_{1 \\leq i,j \\leq 5} |u_{ij}|}{\\displaystyle \\max_{1 \\leq i,j \\leq 5} |a_{ij}|}.\n$$\nFrom the matrix $U$, the maximum absolute value of its entries is:\n$$\n\\max_{1 \\leq i,j \\leq 5} |u_{ij}| = |u_{55}| = 5.\n$$\nFrom the original matrix $A$, the maximum absolute value of its entries is:\n$$\n\\max_{1 \\leq i,j \\leq 5} |a_{ij}| = 1.\n$$\nTherefore, the growth factor is:\n$$\n\\rho(A) = \\frac{5}{1} = 5.\n$$",
            "answer": "$$\n\\boxed{5}\n$$"
        },
        {
            "introduction": "While partial pivoting is a widely used and effective heuristic, it is not the only available strategy, nor is it always optimal. This exercise  offers a comparative analysis between partial pivoting and the more exhaustive complete pivoting. By computing and contrasting the growth factors for both Gaussian Elimination with Partial Pivoting (GEPP) and Complete Pivoting (GECP) on a carefully chosen matrix, you will see firsthand how different policies can lead to different levels of element growth, highlighting the fundamental trade-offs between computational cost and numerical robustness.",
            "id": "3564346",
            "problem": "Consider the following matrix $A \\in \\mathbb{R}^{4 \\times 4}$:\n$$\nA \\;=\\;\n\\begin{bmatrix}\n1 & 0 & 0 & 1 \\\\\n-1 & 1 & 0 & 1 \\\\\n0 & -1 & 1 & 1 \\\\\n0 & 0 & -1 & 1\n\\end{bmatrix}.\n$$\nThroughout, interpret Gaussian elimination as the standard algorithm that performs successive Schur complements of the leading principal block, with the freedom to permute rows and/or columns according to the pivoting rule before each Schur complement step.\n\nDefine the growth factor $\\rho(A,\\mathcal{P})$ for a given pivoting policy $\\mathcal{P}$ as\n$$\n\\rho(A,\\mathcal{P}) \\;=\\; \\frac{\\displaystyle \\max_{k} \\max_{i,j} \\left| a_{ij}^{(k)} \\right|}{\\displaystyle \\max_{i,j} \\left| a_{ij}^{(0)} \\right|},\n$$\nwhere $a_{ij}^{(0)}$ are the entries of the initial matrix $A$, and $a_{ij}^{(k)}$ are the entries of the matrix after the $k$-th elimination step (with the chosen pivoting). The numerator scans all entries that appear at any intermediate stage of the elimination, including after any row/column permutations; the denominator is the maximum absolute value of the entries of $A$ at the start.\n\nConsider two pivoting policies:\n- Gaussian elimination with partial pivoting (GEPP): at the $k$-th step, permute rows to place the entry with largest absolute value in column $k$ (among rows $k,k+1,\\ldots$) into position $(k,k)$. For ties, choose the smallest row index.\n- Gaussian elimination with complete pivoting (GECP): at the $k$-th step, permute rows and columns to place the entry with largest absolute value in the trailing submatrix (rows and columns $k,k+1,\\ldots$) into position $(k,k)$. For ties, choose the smallest row index and then the smallest column index.\n\nStarting only from the definitions of Gaussian elimination, partial and complete pivoting, and the growth factor above, compute the two growth factors $\\rho(A,\\text{GEPP})$ and $\\rho(A,\\text{GECP})$ for the matrix $A$ given. The final answer must be the pair of values written as a single row matrix. No rounding is needed, and no units are involved.",
            "solution": "The problem asks for the computation of the growth factors for a given $4 \\times 4$ matrix $A$ under Gaussian elimination with partial pivoting (GEPP) and with complete pivoting (GECP).\n\nThe given matrix is:\n$$\nA = A^{(0)} =\n\\begin{bmatrix}\n1 & 0 & 0 & 1 \\\\\n-1 & 1 & 0 & 1 \\\\\n0 & -1 & 1 & 1 \\\\\n0 & 0 & -1 & 1\n\\end{bmatrix}\n$$\nThe growth factor is defined as $\\rho(A,\\mathcal{P}) = \\frac{\\displaystyle \\max_{k,i,j} \\left| a_{ij}^{(k)} \\right|}{\\displaystyle \\max_{i,j} \\left| a_{ij}^{(0)} \\right|}$, where the numerator is the maximum absolute value of any entry appearing in any intermediate matrix, and the denominator is the maximum absolute value of any entry in the initial matrix.\n\nFirst, we determine the denominator. The entries of $A^{(0)}$ are from the set $\\{1, 0, -1\\}$. The maximum absolute value of these entries is:\n$$\n\\max_{i,j} |a_{ij}^{(0)}| = 1\n$$\nThus, the growth factor for any pivoting strategy $\\mathcal{P}$ simplifies to:\n$$\n\\rho(A,\\mathcal{P}) = \\max_{k,i,j} |a_{ij}^{(k)}|\n$$\nThis is the largest magnitude of any element encountered during the elimination process, including the initial and all intermediate matrices. We will track this maximum value, let's call it $M$, initialized to $M=1$.\n\n### Gaussian Elimination with Partial Pivoting (GEPP)\n\n**Step $k=1$:**\nWe examine the first column of $A^{(0)}$: $[1, -1, 0, 0]^T$. The maximum absolute value is $1$, which occurs in row $1$ and row $2$. The GEPP tie-breaking rule selects the row with the smallest index, so we choose $a_{11}^{(0)}=1$ as the pivot. No row permutation is needed.\nThe multipliers are $m_{21} = \\frac{-1}{1} = -1$, $m_{31}=0$, and $m_{41}=0$. The elimination step consists of updating row $2$: $R_2 \\to R_2 - m_{21} R_1 = R_2 + R_1$.\n$R_2' = [-1, 1, 0, 1] + [1, 0, 0, 1] = [0, 1, 0, 2]$.\nThe matrix after step $1$ is:\n$$\nA^{(1)} = \\begin{bmatrix}\n1 & 0 & 0 & 1 \\\\\n0 & 1 & 0 & 2 \\\\\n0 & -1 & 1 & 1 \\\\\n0 & 0 & -1 & 1\n\\end{bmatrix}\n$$\nThe entries of $A^{(1)}$ include a new value, $2$. The maximum absolute value seen so far is $M = \\max(1, |2|) = 2$.\n\n**Step $k=2$:**\nWe search for the pivot in the second column, from row $2$ downwards: $[1, -1, 0]^T$. The maximum absolute value is $1$, occurring in rows $2$ and $3$. The tie-breaking rule selects row $2$, so the pivot is $a_{22}^{(1)}=1$. No row permutation is necessary.\nThe multipliers are $m_{32} = \\frac{-1}{1} = -1$ and $m_{42}=0$. The elimination step is $R_3 \\to R_3 - m_{32} R_2 = R_3 + R_2$.\n$R_3' = [0, -1, 1, 1] + [0, 1, 0, 2] = [0, 0, 1, 3]$.\nThe matrix after step $2$ is:\n$$\nA^{(2)} = \\begin{bmatrix}\n1 & 0 & 0 & 1 \\\\\n0 & 1 & 0 & 2 \\\\\n0 & 0 & 1 & 3 \\\\\n0 & 0 & -1 & 1\n\\end{bmatrix}\n$$\nThe new entry is $3$. The running maximum absolute value is now $M = \\max(2, |3|) = 3$.\n\n**Step $k=3$:**\nWe search for the pivot in the third column, from row $3$ downwards: $[1, -1]^T$. The maximum absolute value is $1$, occurring in rows $3$ and $4$. The tie-breaking rule selects row $3$, so the pivot is $a_{33}^{(2)}=1$. No row permutation is needed.\nThe multiplier is $m_{43} = \\frac{-1}{1} = -1$. The elimination step is $R_4 \\to R_4 - m_{43}R_3 = R_4 + R_3$.\n$R_4' = [0, 0, -1, 1] + [0, 0, 1, 3] = [0, 0, 0, 4]$.\nThe final upper triangular matrix is:\n$$\nA^{(3)} = U = \\begin{bmatrix}\n1 & 0 & 0 & 1 \\\\\n0 & 1 & 0 & 2 \\\\\n0 & 0 & 1 & 3 \\\\\n0 & 0 & 0 & 4\n\\end{bmatrix}\n$$\nThe new entry is $4$. The running maximum absolute value becomes $M = \\max(3, |4|) = 4$.\n\nThe maximum absolute value across all matrices $A^{(0)}, A^{(1)}, A^{(2)}, A^{(3)}$ is $4$.\nThus, the growth factor for GEPP is $\\rho(A,\\text{GEPP}) = 4$.\n\n### Gaussian Elimination with Complete Pivoting (GECP)\n\n**Step $k=1$:**\nWe search the entire matrix $A^{(0)}$ for the entry with the largest absolute value. The maximum absolute value is $1$. There are multiple such entries. The GECP tie-breaking rule says to select the one with the smallest row index, and then the smallest column index. This corresponds to $a_{11}^{(0)}=1$. So, the pivot is $1$. No permutations are needed.\nThis step is identical to GEPP. The matrix after step $1$ is:\n$$\nA^{(1)} = \\begin{bmatrix}\n1 & 0 & 0 & 1 \\\\\n0 & 1 & 0 & 2 \\\\\n0 & -1 & 1 & 1 \\\\\n0 & 0 & -1 & 1\n\\end{bmatrix}\n$$\nThe maximum absolute value encountered is $M = 2$.\n\n**Step $k=2$:**\nWe search for the pivot in the trailing submatrix $A^{(1)}_{2:4, 2:4}$:\n$$\nS_2 = \\begin{bmatrix} 1 & 0 & 2 \\\\ -1 & 1 & 1 \\\\ 0 & -1 & 1 \\end{bmatrix}\n$$\nThe entry with the largest absolute value in $S_2$ is $2$, located at position $(2,4)$ in the full matrix $A^{(1)}$. We must move this entry to the pivot position $(2,2)$. This requires swapping column $2$ and column $4$. No row swap is needed as the element is already in the minimal row index (row $2$). Let's denote the permuted matrix by $\\tilde{A}^{(1)}$:\n$$\n\\tilde{A}^{(1)} = \\begin{bmatrix}\n1 & 1 & 0 & 0 \\\\\n0 & 2 & 0 & 1 \\\\\n0 & 1 & 1 & -1 \\\\\n0 & 1 & -1 & 0\n\\end{bmatrix}\n$$\nThe maximum absolute value in this matrix is still $2$. The pivot is $p_2 = 2$.\nThe multipliers are $m_{32} = \\frac{1}{2}$ and $m_{42} = \\frac{1}{2}$.\n$R_3 \\to R_3 - \\frac{1}{2}R_2$: $[0, 1, 1, -1] - \\frac{1}{2}[0, 2, 0, 1] = [0, 0, 1, -3/2]$.\n$R_4 \\to R_4 - \\frac{1}{2}R_2$: $[0, 1, -1, 0] - \\frac{1}{2}[0, 2, 0, 1] = [0, 0, -1, -1/2]$.\nThe matrix after step $2$ is:\n$$\nA^{(2)} = \\begin{bmatrix}\n1 & 1 & 0 & 0 \\\\\n0 & 2 & 0 & 1 \\\\\n0 & 0 & 1 & -3/2 \\\\\n0 & 0 & -1 & -1/2\n\\end{bmatrix}\n$$\nThe new entries have magnitudes $|1|, |-3/2|=1.5, |-1|=1, |-1/2|=0.5$. The maximum magnitude of all entries seen so far is still $M = 2$.\n\n**Step $k=3$:**\nWe search the submatrix $A^{(2)}_{3:4, 3:4}$:\n$$\nS_3 = \\begin{bmatrix} 1 & -3/2 \\\\ -1 & -1/2 \\end{bmatrix}\n$$\nThe maximum absolute value is $|-3/2| = 1.5$, at position $(3,4)$ of $A^{(2)}$. This entry becomes the pivot. We swap columns $3$ and $4$ to bring it to the $(3,3)$ position.\nThe permuted matrix is:\n$$\n\\tilde{A}^{(2)} = \\begin{bmatrix}\n1 & 1 & 0 & 0 \\\\\n0 & 2 & 1 & 0 \\\\\n0 & 0 & -3/2 & 1 \\\\\n0 & 0 & -1/2 & -1\n\\end{bmatrix}\n$$\nThe max absolute value in this matrix is still $2$. The pivot is $p_3 = -3/2$.\nThe multiplier is $m_{43} = \\frac{-1/2}{-3/2} = 1/3$.\n$R_4 \\to R_4 - \\frac{1}{3}R_3$: $[0, 0, -1/2, -1] - \\frac{1}{3}[0, 0, -3/2, 1] = [0, 0, 0, -4/3]$.\nThe final matrix is:\n$$\nA^{(3)} = U = \\begin{bmatrix}\n1 & 1 & 0 & 0 \\\\\n0 & 2 & 1 & 0 \\\\\n0 & 0 & -3/2 & 1 \\\\\n0 & 0 & 0 & -4/3\n\\end{bmatrix}\n$$\nThe new entry is $-4/3$. Its absolute value is approximately $1.33$. The maximum absolute value in $A^{(3)}$ is $2$.\nThe set of all matrices encountered during GECP are $A^{(0)}, A^{(1)}, \\tilde{A}^{(1)}, A^{(2)}, \\tilde{A}^{(2)}, A^{(3)}$. The maximum absolute value across all entries of all these matrices is $2$.\nThus, the growth factor for GECP is $\\rho(A,\\text{GECP}) = 2$.\n\nThe two computed growth factors are $\\rho(A,\\text{GEPP}) = 4$ and $\\rho(A,\\text{GECP}) = 2$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n4 & 2\n\\end{pmatrix}\n}\n$$"
        }
    ]
}