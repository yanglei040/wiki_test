{
    "hands_on_practices": [
        {
            "introduction": "To truly understand LU factorization, we must first be comfortable with its fundamental mechanics. This first exercise provides a direct, hands-on opportunity to compute the LU factorization of a simple $3 \\times 3$ matrix using the Doolittle method, where $L$ is a unit lower triangular matrix. This foundational practice  is essential for building an intuitive feel for how the row-reduction steps of Gaussian elimination are systematically encoded into the $L$ and $U$ factors.",
            "id": "2186375",
            "problem": "In numerical linear algebra, the factorization of a matrix into a product of a lower triangular matrix and an upper triangular matrix is a fundamental operation. This factorization is known as LU decomposition and is used in various algorithms, such as solving systems of linear equations.\n\nConsider the matrix $A$ given by:\n$$\nA = \\begin{pmatrix} 3 & -1 & 2 \\\\ 6 & 1 & 9 \\\\ -9 & 5 & -5 \\end{pmatrix}\n$$\nThis matrix can be uniquely factorized into the product $A = LU$, where $L$ is a unit lower triangular matrix (i.e., with ones on the diagonal) and $U$ is an upper triangular matrix. The general forms for these $3 \\times 3$ matrices are:\n$$\nL = \\begin{pmatrix} 1 & 0 & 0 \\\\ l_{21} & 1 & 0 \\\\ l_{31} & l_{32} & 1 \\end{pmatrix}, \\quad U = \\begin{pmatrix} u_{11} & u_{12} & u_{13} \\\\ 0 & u_{22} & u_{23} \\\\ 0 & 0 & u_{33} \\end{pmatrix}\n$$\nDetermine the numerical values for the off-diagonal elements of matrix $L$ and all elements of matrix $U$ for the given matrix $A$. Express your final answer as a single row matrix containing these nine values in the specific order $(l_{21}, l_{31}, l_{32}, u_{11}, u_{12}, u_{13}, u_{22}, u_{23}, u_{33})$. Express all fractional values in their simplest form.",
            "solution": "We use the Doolittle LU factorization with $L$ unit lower triangular and $U$ upper triangular, satisfying $A=LU$. With\n$$\nL=\\begin{pmatrix}1&0&0\\\\ l_{21}&1&0\\\\ l_{31}&l_{32}&1\\end{pmatrix},\\quad\nU=\\begin{pmatrix}u_{11}&u_{12}&u_{13}\\\\ 0&u_{22}&u_{23}\\\\ 0&0&u_{33}\\end{pmatrix},\n$$\nthe product $LU$ gives, row by row:\n- Row 1: $[u_{11},u_{12},u_{13}]=[3,-1,2]$, hence $u_{11}=3$, $u_{12}=-1$, $u_{13}=2$.\n- Row 2, column 1: $l_{21}u_{11}=a_{21}=6$, so $l_{21}=\\frac{a_{21}}{u_{11}}=\\frac{6}{3}=2$.\n- Row 3, column 1: $l_{31}u_{11}=a_{31}=-9$, so $l_{31}=\\frac{a_{31}}{u_{11}}=\\frac{-9}{3}=-3$.\n- Row 2, column 2: $l_{21}u_{12}+u_{22}=a_{22}=1$, so $u_{22}=a_{22}-l_{21}u_{12}=1-2(-1)=3$.\n- Row 2, column 3: $l_{21}u_{13}+u_{23}=a_{23}=9$, so $u_{23}=a_{23}-l_{21}u_{13}=9-2\\cdot 2=5$.\n- Row 3, column 2: $l_{31}u_{12}+l_{32}u_{22}=a_{32}=5$, so $l_{32}=\\frac{a_{32}-l_{31}u_{12}}{u_{22}}=\\frac{5-(-3)(-1)}{3}=\\frac{5-3}{3}=\\frac{2}{3}$.\n- Row 3, column 3: $l_{31}u_{13}+l_{32}u_{23}+u_{33}=a_{33}=-5$, so\n$$\nu_{33}=a_{33}-l_{31}u_{13}-l_{32}u_{23}=-5-(-3\\cdot 2)-\\left(\\frac{2}{3}\\cdot 5\\right)=-5+6-\\frac{10}{3}=1-\\frac{10}{3}=-\\frac{7}{3}.\n$$\n\nTherefore, in the required order $(l_{21}, l_{31}, l_{32}, u_{11}, u_{12}, u_{13}, u_{22}, u_{23}, u_{33})$, the values are\n$$\n\\begin{pmatrix}\n2 & -3 & \\frac{2}{3} & 3 & -1 & 2 & 3 & 5 & -\\frac{7}{3}\n\\end{pmatrix}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}2 & -3 & \\frac{2}{3} & 3 & -1 & 2 & 3 & 5 & -\\frac{7}{3}\\end{pmatrix}}$$"
        },
        {
            "introduction": "The basic LU factorization algorithm, performed without pivoting, is not guaranteed to succeed even for a nonsingular matrix. This critical thought experiment  challenges you to explore this limitation by constructing a matrix for which the factorization fails and to explain this failure from first principles. By connecting the algorithmic breakdown to the properties of the matrix's leading principal minors, you will gain a deeper appreciation for the theoretical conditions underpinning the factorization and the necessity of pivoting strategies in robust numerical solvers.",
            "id": "3578142",
            "problem": "Let $A \\in \\mathbb{R}^{3 \\times 3}$ be a real matrix. Consider the attempt to compute a Lower-Upper (LU) factorization without row permutations, that is, to find a unit lower triangular matrix $L$ and an upper triangular matrix $U$ such that $A = L U$, using the row operations of Gaussian elimination (GE) without pivoting. Denote by $\\Delta_{k}$ the determinant of the leading $k \\times k$ principal submatrix of $A$.\n\n1. Construct explicitly a real $3 \\times 3$ matrix $A$ satisfying $\\Delta_{1} \\neq 0$ and $\\Delta_{2} = 0$, and for which the second elimination step of Gaussian elimination without pivoting would require division by the second pivot. Your construction must be explicit and justified from first principles (namely, the definition of GE and the induced Schur complement at each step).\n\n2. Starting only from the definition of Gaussian elimination and block-partitioned matrix multiplication, derive a necessary condition for the existence of an $A = L U$ factorization without pivoting in terms of the leading principal minors $\\Delta_{k}$ and the elimination pivots $p_{k}$. Your derivation must begin with the first elimination step on a $2 \\times 2$ leading block and proceed via the Schur complement, fully justifying each step.\n\n3. Apply your derivation to your explicit matrix $A$ to explain rigorously why $A = L U$ with unit diagonal $L$ and no row permutations cannot exist. Additionally, determine the numerical value of the second pivot $p_{2}$ that GE without pivoting would attempt to use on your constructed $A$.\n\nProvide the numerical value of $p_{2}$ as your final answer. No rounding is required.",
            "solution": "This problem comprises three parts concerning the existence of a Lower-Upper (LU) factorization of a matrix $A \\in \\mathbb{R}^{3 \\times 3}$ without row permutations. We address each part sequentially.\n\n1. Construction of the matrix $A$.\n\nWe are tasked with constructing a $3 \\times 3$ real matrix $A$ such that the determinant of its leading principal submatrices satisfy $\\Delta_{1} \\neq 0$ and $\\Delta_{2} = 0$, and for which Gaussian elimination (GE) without pivoting fails at the second step.\n\nLet the matrix $A$ be denoted by\n$$A = \\begin{pmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\end{pmatrix}$$\nThe leading $1 \\times 1$ principal submatrix is $[a_{11}]$, and its determinant is $\\Delta_{1} = a_{11}$. The condition $\\Delta_{1} \\neq 0$ implies $a_{11} \\neq 0$. The value $a_{11}$ serves as the first pivot, $p_1$. For simplicity, let us choose $a_{11} = 1$.\n\nThe leading $2 \\times 2$ principal submatrix is $\\begin{pmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{pmatrix}$, with determinant $\\Delta_{2} = a_{11}a_{22} - a_{12}a_{21}$. The condition is $\\Delta_{2} = 0$. With $a_{11} = 1$, this becomes $a_{22} - a_{12}a_{21} = 0$. We can satisfy this by choosing, for instance, $a_{12} = 1$, $a_{21} = 1$, and $a_{22} = 1$.\n\nSo far, the top-left $2 \\times 2$ block of $A$ is $\\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix}$. Let us choose the remaining entries to create a simple, non-trivial matrix. Let $a_{13}=1$, $a_{23}=2$, $a_{31}=1$, $a_{32}=2$, and $a_{33}=3$. This gives the matrix\n$$A = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix}$$\nLet us verify the conditions. $\\Delta_{1} = \\det([1]) = 1 \\neq 0$.\n$\\Delta_{2} = \\det \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} = (1)(1) - (1)(1) = 0$. The conditions are met.\n\nNow, we must justify from first principles that GE fails at the second step. The first step of GE uses the pivot $p_1 = a_{11} = 1$ to eliminate the entries below it.\nThe multiplier for the second row is $l_{21} = \\frac{a_{21}}{p_1} = \\frac{1}{1} = 1$.\nThe multiplier for the third row is $l_{31} = \\frac{a_{31}}{p_1} = \\frac{1}{1} = 1$.\nThe matrix after the first elimination step, $A^{(1)}$, is:\n$$A^{(1)} = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 - (1)(1) & 1 - (1)(1) & 2 - (1)(1) \\\\ 1 - (1)(1) & 2 - (1)(1) & 3 - (1)(1) \\end{pmatrix} = \\begin{pmatrix} 1 & 1 & 1 \\\\ 0 & 0 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix}$$\nThe second pivot is the $(2,2)$ entry of $A^{(1)}$, which is $p_2 = a_{22}^{(1)} = 0$. To proceed with the second step of GE, we would need to eliminate the entry $a_{32}^{(1)}=1$ by using the pivot $p_2$. This would require computing a multiplier $l_{32} = \\frac{a_{32}^{(1)}}{p_2} = \\frac{1}{0}$, which involves division by zero. Thus, GE without pivoting fails at the second step.\n\nTo justify this via the Schur complement, we partition $A$:\n$$A = \\begin{pmatrix} a_{11} & \\mathbf{a}_{12}^T \\\\ \\mathbf{a}_{21} & A_{22} \\end{pmatrix} = \\begin{pmatrix} 1 & \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\\\ \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} & \\begin{pmatrix} 1 & 2 \\\\ 2 & 3 \\end{pmatrix} \\end{pmatrix}$$\nThe first step of block LU decomposition yields:\n$$A = \\begin{pmatrix} 1 & \\mathbf{0}^T \\\\ \\mathbf{l}_{21} & I \\end{pmatrix} \\begin{pmatrix} a_{11} & \\mathbf{a}_{12}^T \\\\ \\mathbf{0} & A_{22} - \\mathbf{l}_{21} \\mathbf{a}_{12}^T \\end{pmatrix}$$\nwhere $\\mathbf{l}_{21} = \\frac{\\mathbf{a}_{21}}{a_{11}} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. The lower-right block is the Schur complement $S$ of $a_{11}$ in $A$:\n$$S = A_{22} - \\frac{\\mathbf{a}_{21} \\mathbf{a}_{12}^T}{a_{11}} = \\begin{pmatrix} 1 & 2 \\\\ 2 & 3 \\end{pmatrix} - \\frac{1}{1}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 1 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 2 \\\\ 2 & 3 \\end{pmatrix} - \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 1 & 2 \\end{pmatrix}$$\nThe matrix after one step of GE has the Schur complement in its lower-right part: $A^{(1)} = \\begin{pmatrix} a_{11} & \\mathbf{a}_{12}^T \\\\ \\mathbf{0} & S \\end{pmatrix}$. The second pivot of GE is the $(1,1)$ entry of this Schur complement, $p_2 = S_{11} = 0$. This confirms the failure.\n\n2. Derivation of the necessary condition.\n\nWe are asked to derive a necessary condition for the existence of $A = LU$ (without pivoting) in terms of the leading principal minors $\\Delta_k$ and the pivots $p_k$. The derivation must start from the definition of GE.\n\nLet $A$ be an $n \\times n$ matrix. Gaussian elimination without pivoting produces a sequence of matrices $A=A^{(0)}, A^{(1)}, \\dots, A^{(n-1)}=U$, where $U$ is upper triangular. The pivots are $p_k = a_{kk}^{(k-1)}$.\n\nFor the first step to be possible, the first pivot $p_1 = a_{11}^{(0)} = a_{11}$ must be non-zero. The first leading principal minor is $\\Delta_1 = \\det([a_{11}]) = a_{11}$. Thus, a necessary condition is $p_1 = \\Delta_1 \\neq 0$.\n\nNow, let us consider the second pivot, $p_2$. This is the $(2,2)$-entry of the matrix $A^{(1)}$ obtained after the first step of elimination. The entries of $A^{(1)}$ are given by $a_{ij}^{(1)} = a_{ij}^{(0)} - \\frac{a_{i1}^{(0)}}{a_{11}^{(0)}} a_{1j}^{(0)}$ for $i,j > 1$. Specifically for the second pivot:\n$$p_2 = a_{22}^{(1)} = a_{22}^{(0)} - \\frac{a_{21}^{(0)}}{a_{11}^{(0)}} a_{12}^{(0)}$$\nUsing the original matrix entries $a_{ij}^{(0)}=a_{ij}$, we have:\n$$p_2 = a_{22} - \\frac{a_{21}a_{12}}{a_{11}} = \\frac{a_{11}a_{22} - a_{12}a_{21}}{a_{11}}$$\nThe numerator is the determinant of the leading $2 \\times 2$ principal submatrix of $A$, which is $\\Delta_2$. The denominator is the first leading principal minor, $\\Delta_1$. Therefore, we have the relation:\n$$p_2 = \\frac{\\Delta_2}{\\Delta_1}$$\nFor the second step of GE to proceed, the pivot $p_2$ must be non-zero. Since we already established the necessity of $\\Delta_1 \\neq 0$, the condition $p_2 \\neq 0$ is equivalent to $\\Delta_2 \\neq 0$.\n\nThis argument can be generalized. If the LU factorization exists, $A=LU$, then for any $k \\in \\{1, \\dots, n\\}$, the leading $k \\times k$ principal submatrix $A_k$ satisfies $A_k = L_k U_k$. Taking determinants, $\\det(A_k) = \\det(L_k) \\det(U_k)$. Since $L$ is unit lower triangular, $L_k$ is also, and $\\det(L_k) = 1$. The determinant of the upper triangular matrix $U_k$ is the product of its diagonal entries, which are the first $k$ pivots: $\\det(U_k) = p_1 p_2 \\cdots p_k$.\nThus, $\\Delta_k = p_1 p_2 \\cdots p_k$.\nThis gives $\\Delta_k = \\Delta_{k-1} p_k$ for $k \\ge 2$, which implies $p_k = \\frac{\\Delta_k}{\\Delta_{k-1}}$. For GE without pivoting to be successful through step $n-1$, all pivots $p_1, \\dots, p_{n-1}$ must be non-zero. This requires $\\Delta_k \\neq 0$ for all $k = 1, \\dots, n-1$. This is the necessary condition for the existence of an LU factorization without pivoting. (Note that $p_n$ can be zero, which corresponds to $\\Delta_n = \\det(A) = 0$; this is permissible as no divisions by $p_n$ are performed).\n\n3. Application to the constructed matrix $A$.\n\nWe apply the derived condition to the constructed matrix $A = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix}$.\nThe necessary condition for a $3 \\times 3$ matrix to have an LU factorization without pivoting is that $\\Delta_1 \\neq 0$ and $\\Delta_2 \\neq 0$.\nLet's compute these minors for our matrix $A$:\n$\\Delta_1 = \\det([1]) = 1$. This satisfies $\\Delta_1 \\neq 0$.\n$\\Delta_2 = \\det\\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} = (1)(1) - (1)(1) = 0$.\nSince $\\Delta_2 = 0$, the necessary condition is violated. Therefore, an LU factorization with a unit diagonal $L$ and no row permutations cannot exist for this matrix $A$.\n\nFinally, we must determine the numerical value of the second pivot $p_2$. Using the formula derived in Part 2:\n$$p_2 = \\frac{\\Delta_2}{\\Delta_1}$$\nSubstituting the calculated values for our matrix $A$:\n$$p_2 = \\frac{0}{1} = 0$$\nThis is consistent with our direct calculation in Part 1, where the $(2,2)$ entry of the matrix $A^{(1)}$ was found to be $0$. The value of the second pivot that GE without pivoting attempts to use is exactly $0$.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "A primary motivation for computing a matrix factorization is the immense efficiency it offers when solving a linear system for multiple right-hand sides, such as in $AX=B$ where $B$ is a matrix. This problem  transitions from algorithmic mechanics to computational performance analysis, asking you to derive and compare the arithmetic intensity of two strategies: reusing a single LU factorization versus recomputing it for each right-hand side. This analysis rigorously quantifies the significant performance gains of the \"factor-then-solve\" paradigm, a core principle in the design of high-performance scientific computing libraries.",
            "id": "3578124",
            "problem": "Consider a dense, nonsingular $n \\times n$ real matrix $A$ and an $n \\times m$ matrix $B$ collecting $m$ Right-Hand Sides (RHS). We want to solve $A X = B$ using the Lower-Upper (LU) factorization with partial pivoting and then two triangular solves per RHS. Use the following cost models and assumptions:\n\n- Floating-point operation (flop) count model: count one flop for each floating-point addition, subtraction, multiplication, or division. Ignore comparisons and data movement overhead in this flop count.\n- LU factorization is performed in-place with a unit diagonal in $L$; the trailing matrix updates are accounted for as multiply-subtract pairs.\n- Triangular solves consist of forward substitution with unit lower-triangular $L$ and back substitution with upper-triangular $U$; include one division per row in back substitution.\n- Memory traffic model: count one word of traffic for each read or write of a matrix or vector element between the processor and Random Access Memory (RAM). For the LU factorization, assume the entire matrix $A$ is streamed in once and overwritten in-place with $L$ and $U$, streaming out once. For the solves, in the \"factor reuse\" strategy assume $L$ and $U$ reside in fast memory after the factorization, so only $B$ (read) and $X$ (write) are streamed. In the \"repeated solves\" strategy, assume the factorization is recomputed for each RHS, streaming $A$ in and $LU$ out each time, and $B$ and $X$ are streamed for each RHS. Ignore traffic for the pivot index vector and any metadata.\n\nDefine the arithmetic intensity (AI) as $\\mathrm{AI} = \\text{flops}/\\text{words moved}$. Let $\\mathrm{AI}_{\\mathrm{reuse}}$ denote the arithmetic intensity for solving $A X = B$ by computing the LU factorization once and reusing it across $m$ RHS, and let $\\mathrm{AI}_{\\mathrm{repeat}}$ denote the arithmetic intensity for solving by recomputing the LU factorization independently for each RHS. Derive, from first principles under the models above, an exact closed-form expression for the improvement factor\n$$\\Phi(n,m) = \\frac{\\mathrm{AI}_{\\mathrm{reuse}}}{\\mathrm{AI}_{\\mathrm{repeat}}}.$$\nProvide your final answer as a single simplified symbolic expression in terms of $n$ and $m$. No rounding is required and no units should be included in the final expression.",
            "solution": "We begin from the definitions of the Lower-Upper (LU) factorization and triangular solves, and the given flop and memory traffic models.\n\nFlop count for LU factorization (in-place, partial pivoting, unit diagonal in $L$):\nAt elimination step $k$, with $1 \\leq k \\leq n-1$, we compute $(n-k)$ multipliers $l_{i,k}$ via divisions, which costs $(n-k)$ flops, and update the trailing submatrix of size $(n-k) \\times (n-k)$. Each trailing matrix element update has the form $a_{ij} \\leftarrow a_{ij} - l_{ik} \\, u_{kj}$, costing $2$ flops (one multiplication and one subtraction). Thus the update costs $2 (n-k)^{2}$ flops at step $k$. Summing over $k$,\n\n$$\nF_{\\mathrm{LU}}(n)\n= \\sum_{k=1}^{n-1} \\bigl[(n-k) + 2 (n-k)^{2}\\bigr]\n= \\sum_{r=1}^{n-1} \\bigl[r + 2 r^{2}\\bigr],\n$$\n\nwith $r = n-k$. Using $\\sum_{r=1}^{n-1} r = \\frac{n(n-1)}{2}$ and $\\sum_{r=1}^{n-1} r^{2} = \\frac{(n-1)n(2n-1)}{6}$,\n\n$$\nF_{\\mathrm{LU}}(n)\n= \\frac{n(n-1)}{2} + 2 \\cdot \\frac{(n-1)n(2n-1)}{6}\n= \\frac{n(n-1)(4n+1)}{6}.\n$$\n\n\nFlop count for one RHS triangular solve:\nForward substitution with unit lower-triangular $L$ computes $y_{i} = b_{i} - \\sum_{j=1}^{i-1} L_{ij} y_{j}$, costing $(i-1)$ multiplications and $(i-1)$ subtractions for row $i$. Summing over $i$ yields\n\n$$\nF_{\\mathrm{fwd}}(n) = \\sum_{i=1}^{n} 2(i-1) = n(n-1).\n$$\n\nBack substitution with upper-triangular $U$ computes $x_{i} = \\bigl(y_{i} - \\sum_{j=i+1}^{n} U_{ij} x_{j}\\bigr) / U_{ii}$, costing $(n-i)$ multiplications, $(n-i)$ subtractions, and $1$ division per row $i$. Summing over $i$,\n\n$$\nF_{\\mathrm{bwd}}(n) = \\sum_{i=1}^{n} \\bigl[2(n-i) + 1\\bigr] = n(n-1) + n = n^{2}.\n$$\n\nTherefore, the total flop count per RHS is\n\n$$\nF_{\\mathrm{solve,\\,per\\,RHS}}(n) = F_{\\mathrm{fwd}}(n) + F_{\\mathrm{bwd}}(n) = \\bigl[n(n-1)\\bigr] + \\bigl[n^{2}\\bigr] = 2n^{2} - n.\n$$\n\n\nTotal flop counts for the two strategies:\n- Factor reuse across $m$ RHS:\n\n$$\nF_{\\mathrm{reuse}}(n,m) = F_{\\mathrm{LU}}(n) + m \\, F_{\\mathrm{solve,\\,per\\,RHS}}(n)\n= \\frac{n(n-1)(4n+1)}{6} + m(2n^{2} - n).\n$$\n\n- Repeated factorization for each RHS:\n\n$$\nF_{\\mathrm{repeat}}(n,m) = m \\bigl[F_{\\mathrm{LU}}(n) + F_{\\mathrm{solve,\\,per\\,RHS}}(n)\\bigr]\n= m \\left(\\frac{n(n-1)(4n+1)}{6} + 2n^{2} - n\\right).\n$$\n\n\nMemory traffic under the stated model:\n- For the LU factorization, stream $A$ in once and overwrite in-place with $L$ and $U$, streaming out once. This costs $n^{2}$ words read plus $n^{2}$ words written, i.e., $2n^{2}$ words moved.\n- For the solves with factor reuse, assume $L$ and $U$ stay resident in fast memory; only $B$ and $X$ are streamed. Reading $B$ and writing $X$ across $m$ RHS costs $n m$ words read and $n m$ words written, i.e., $2 n m$ words moved.\nHence,\n\n$$\nW_{\\mathrm{reuse}}(n,m) = 2 n^{2} + 2 n m = 2n(n+m).\n$$\n\n- For the repeated factorization strategy, the LU factorization is recomputed for each RHS, streaming $A$ in and the overwritten $LU$ out each time, for a total of $2 n^{2}$ words per RHS; the $B$ and $X$ streams per RHS add $2 n$ words per RHS. Across $m$ RHS,\n\n$$\nW_{\\mathrm{repeat}}(n,m) = m \\cdot 2 n^{2} + m \\cdot 2 n = 2 m n^{2} + 2 m n = 2 m n (n+1).\n$$\n\n\nArithmetic intensity (AI) for each strategy:\n\n$$\n\\mathrm{AI}_{\\mathrm{reuse}}(n,m) = \\frac{F_{\\mathrm{reuse}}(n,m)}{W_{\\mathrm{reuse}}(n,m)}\n= \\frac{\\frac{n(n-1)(4n+1)}{6} + m(2n^{2} - n)}{2n(n+m)}.\n$$\n\n\n$$\n\\mathrm{AI}_{\\mathrm{repeat}}(n,m) = \\frac{F_{\\mathrm{repeat}}(n,m)}{W_{\\mathrm{repeat}}(n,m)}\n= \\frac{m \\left(\\frac{n(n-1)(4n+1)}{6} + 2n^{2} - n\\right)}{2 m n (n+1)}\n= \\frac{\\frac{n(n-1)(4n+1)}{6} + 2n^{2} - n}{2 n (n+1)}.\n$$\n\n\nImprovement factor $\\Phi(n,m)$:\n\n$$\n\\Phi(n,m) = \\frac{\\mathrm{AI}_{\\mathrm{reuse}}(n,m)}{\\mathrm{AI}_{\\mathrm{repeat}}(n,m)}\n= \\frac{\\frac{n(n-1)(4n+1)}{6} + m(2n^{2} - n)}{2n(n+m)}\n\\cdot\n\\frac{2 n (n+1)}{\\frac{n(n-1)(4n+1)}{6} + 2n^{2} - n}.\n$$\n\nCanceling $2n$ and simplifying yields\n\n$$\n\\Phi(n,m) = \\frac{n+1}{n+m} \\cdot\n\\frac{\\frac{n(n-1)(4n+1)}{6} + m(2n^{2} - n)}{\\frac{n(n-1)(4n+1)}{6} + 2n^{2} - n}.\n$$\n\n\nThis is the exact closed-form expression under the stated models. As a sanity check, consider $m \\to \\infty$ with $n$ fixed. Then\n\n$$\n\\Phi(n,m) \\sim \\frac{n+1}{n+m} \\cdot \\frac{m(2n^{2} - n)}{\\frac{n(n-1)(4n+1)}{6} + 2n^{2} - n}\n\\sim \\frac{n+1}{m} \\cdot \\frac{m(2n^{2} - n)}{\\frac{4n^3-3n^2-n}{6} + 2n^{2} - n}\n\\sim \\frac{2n^3}{\\frac{4n^3}{6}} = 3\n$$\n\nfor large $n$, recovering the intuitive improvement that reuse asymptotically triples the arithmetic intensity relative to repeated factorization in this simplified streaming model.\n\nThe required final expression is therefore\n\n$$\n\\Phi(n,m) = \\frac{n+1}{n+m} \\cdot\n\\frac{\\frac{n(n-1)(4n+1)}{6} + m(2n^{2} - n)}{\\frac{n(n-1)(4n+1)}{6} + 2n^{2} - n}.\n$$",
            "answer": "$$\\boxed{\\frac{n+1}{n+m}\\cdot\\frac{\\frac{n(n-1)(4n+1)}{6}+m\\left(2n^{2}-n\\right)}{\\frac{n(n-1)(4n+1)}{6}+2n^{2}-n}}$$"
        }
    ]
}