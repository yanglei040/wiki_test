{
    "hands_on_practices": [
        {
            "introduction": "我们从一个基础的计算问题开始，旨在揭示秩亏最小二乘问题的核心挑战。当一个线性系统的解不唯一时，我们需要一个额外的准则来挑选出唯一的“最佳”解。这个练习将引导你通过一个具体的例子，找到所有最小二乘解的集合，并从中确定具有最小欧几里得范数的那个解，这是理解伪逆概念的第一步。",
            "id": "1031768",
            "problem": "考虑秩亏线性系统 $A\\mathbf{x} = \\mathbf{b}$，其中：\n$$\nA = \\begin{bmatrix}\n1  1 \\\\\n1  1 \\\\\n0  0\n\\end{bmatrix}, \\quad\n\\mathbf{b} = \\begin{bmatrix}\n1 \\\\\n2 \\\\\n0\n\\end{bmatrix}.\n$$\n矩阵 $A$ 的秩为 $r=1$。使用完全正交分解，求最小范数最小二乘解 $\\mathbf{x} \\in \\mathbb{R}^2$，并计算其欧几里得范数 $\\|\\mathbf{x}\\|$。请给出精确值。",
            "solution": "我们寻求秩亏最小二乘问题的最小范数解\n$$\\min_x\\|Ax-b\\|^2,\\qquad \nA=\\begin{pmatrix}1  1\\\\1  1\\\\0  0\\end{pmatrix},\\;\nb=\\begin{pmatrix}1\\\\2\\\\0\\end{pmatrix}.$$\n\n1. 正规方程：\n$$A^TAx=A^Tb,\\quad \nA^T=\\begin{pmatrix}1  1  0\\\\1  1  0\\end{pmatrix}.$$\n计算\n$$A^TA=\\begin{pmatrix}2  2\\\\2  2\\end{pmatrix},\\quad\nA^Tb=\\begin{pmatrix}3\\\\3\\end{pmatrix}.$$\n因此\n$$\\begin{pmatrix} 2  2 \\\\ 2  2 \\end{pmatrix} x = \\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix}$$\n有无穷多解，满足 $x_1+x_2=\\tfrac32$。\n\n2. 参数化 $s=x_1+x_2$。通过拉格朗日乘子法，在约束条件 $x_1+x_2=s=\\tfrac32$ 下最小化 \n$$\\|x\\|^2=x_1^2+x_2^2$$\n可得\n$$x_1=x_2=\\frac{s}{2}=\\frac{3}{4}.$$\n\n3. 因此，最小范数解为\n$$x=\\begin{pmatrix} 3/4 \\\\ 3/4 \\end{pmatrix},$$\n其欧几里得范数为\n$$\\|x\\|=\\sqrt{\\Bigl(\\frac34\\Bigr)^2+\\Bigl(\\frac34\\Bigr)^2}\n=\\sqrt{\\frac{9}{8}}\n=\\frac{3}{2\\sqrt2}\n=\\frac{3\\sqrt2}{4}.$$",
            "answer": "$$\\boxed{\\frac{3\\sqrt2}{4}}$$"
        },
        {
            "introduction": "在掌握了最小范数解的基本概念后，我们将探讨一个更微妙但至关重要的性质：解对矩阵微小变化的敏感性。这个练习设计了一个场景，通过从矩阵中删除列来改变其秩，你会发现最小范数解会发生不连续的“跳跃”。这个结果揭示了伪逆操作的内在不稳定性，并强调了在实践中处理秩亏问题时需要格外小心的原因。",
            "id": "3571427",
            "problem": "考虑秩亏最小二乘问题，其矩阵 $A \\in \\mathbb{R}^{2 \\times 3}$ 和右侧向量 $b \\in \\mathbb{R}^{2}$ 如下所示：\n$$\nA \\;=\\; \\begin{pmatrix}\n1  1  0 \\\\\n0  0  1\n\\end{pmatrix}, \n\\qquad\nb \\;=\\; \\begin{pmatrix}\n1 \\\\\n0\n\\end{pmatrix}.\n$$\n$A$ 的三列分别为 $a_{1} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$，$a_{2} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$ 和 $a_{3} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$。最小二乘的目标是最小化 $\\|A x - b\\|_{2}$（对于 $x \\in \\mathbb{R}^{3}$），并将 $x^{\\dagger}$ 定义为最小范数解（即在所有最小化解中具有最小欧几里得范数的唯一解）。列删除序列的定义是：首先移除第 3 列以构成 $A^{(1)} \\in \\mathbb{R}^{2 \\times 2}$，然后移除第 2 列以构成 $A^{(2)} \\in \\mathbb{R}^{2 \\times 1}$。为了在不同删除步骤间进行比较，通过在已删除列的位置填充零，将解嵌入到 $\\mathbb{R}^{3}$ 中。\n\n仅使用 Moore–Penrose 伪逆、到列空间的正交投影算子和正规方程的核心定义，并从基本的最小二乘关系出发，推导删除序列中每个矩阵的 $x^{\\dagger}$。确定每次删除后零空间维数的变化。通过在每一步跟踪 Gram 矩阵（预解式）的 Moore–Penrose 伪逆，即 $(A^{\\top}A)^{\\dagger}$，来追踪最小范数解的变化，以解释第二次删除引起的 $x^{\\dagger}$ 的不连续性。\n\n计算在上述序列中删除第 2 列前后，嵌入的最小范数解之间的跳跃的精确欧几里得范数。请以单个精确值的形式提供最终答案，无需四舍五入。",
            "solution": "该问题是适定的、有科学依据的，并包含了唯一解所需的所有信息。我们按要求进行推导。\n\n最小二乘问题旨在寻找一个向量 $x$ 来最小化残差的欧几里得范数 $\\|Ax-b\\|_2$。所有此类最小化子的集合由正规方程 $A^\\top A x = A^\\top b$ 的解给出。如果系统是秩亏的，则存在无穷多个解。最小范数解，记作 $x^{\\dagger}$，是同时最小化 $\\|x\\|_2$ 的唯一解。该解位于 $A$ 的行空间 $\\mathcal{R}(A^\\top)$ 中，由 $x^\\dagger = A^\\dagger b$ 给出，其中 $A^\\dagger$ 是 $A$ 的 Moore-Penrose 伪逆。伪逆的一个核心恒等式是 $A^\\dagger = (A^\\top A)^\\dagger A^\\top$。\n\n**步骤 1：分析原始矩阵 $A$**\n\n初始矩阵和向量为：\n$$\nA = \\begin{pmatrix} 1  1  0 \\\\ 0  0  1 \\end{pmatrix} \\in \\mathbb{R}^{2 \\times 3}, \\quad b = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\in \\mathbb{R}^{2}\n$$\n$A$ 的列是 $a_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$，$a_2 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ 和 $a_3 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。由于 $a_1 = a_2$，这些列是线性相关的。$A$ 的秩为 $\\text{rank}(A) = 2$，因为 $\\{a_1, a_3\\}$ 构成了 $\\mathbb{R}^2$ 的一组基。该矩阵是秩亏的，因为它的秩小于列数（$2  3$）。零空间维数为 $\\dim(\\mathcal{N}(A)) = n - \\text{rank}(A) = 3 - 2 = 1$。为了找到零空间，我们求解 $Ax=0$，得到方程 $x_1+x_2 = 0$ 和 $x_3=0$。因此，$\\mathcal{N}(A) = \\text{span}\\left\\{ \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix} \\right\\}$。\n\n由于 $b = a_1$，$b$ 位于 $A$ 的列空间中，因此系统 $Ax=b$ 是相容的，最小残差为 $0$。解集为 $\\{x \\in \\mathbb{R}^3 \\mid x_1+x_2=1, x_3=0\\}$。任意解都可以写成 $x(c) = x_p + x_h = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} + c \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}$ 的形式，其中 $c \\in \\mathbb{R}$ 为某个标量。为了找到最小范数解 $x^\\dagger_A$，我们最小化 $\\|x(c)\\|_2^2$：\n$$\n\\|x(c)\\|_2^2 = (1+c)^2 + (-c)^2 + 0^2 = 1 + 2c + 2c^2\n$$\n对 $c$ 进行最小化：$\\frac{d}{dc}(1+2c+2c^2) = 2+4c = 0 \\implies c = -1/2$。\n原始问题的最小范数解为：\n$$\nx^\\dagger_A = \\begin{pmatrix} 1 - 1/2 \\\\ -(-1/2) \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 0 \\end{pmatrix}\n$$\n\n**步骤 2：第一次删除后（矩阵 $A^{(1)}$）的分析**\n\n从 $A$ 中移除第 3 列以构成 $A^{(1)} \\in \\mathbb{R}^{2 \\times 2}$：\n$$\nA^{(1)} = \\begin{pmatrix} 1  1 \\\\ 0  0 \\end{pmatrix}\n$$\n$A^{(1)}$ 的列是相同的，所以 $\\text{rank}(A^{(1)})=1$。零空间维数为 $\\dim(\\mathcal{N}(A^{(1)})) = 2-1 = 1$。零空间为 $\\mathcal{N}(A^{(1)}) = \\text{span}\\left\\{ \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} \\right\\}$。零空间维数保持不变，但其所处的环境空间从 $\\mathbb{R}^3$ 变为 $\\mathbb{R}^2$。\n对于 $A^{(1)}$ 和右侧向量 $b$ 的最小二乘问题也是相容的。解集为 $\\{x \\in \\mathbb{R}^2 \\mid x_1+x_2=1\\}$。最小范数解的计算与 $x_A^\\dagger$ 的前两个分量的计算相同，得到：\n$$\nx^{\\dagger}_{A^{(1)}} = \\begin{pmatrix} 1/2 \\\\ 1/2 \\end{pmatrix}\n$$\n通过将已删除的第三个分量用零填充，将此解嵌入到 $\\mathbb{R}^3$ 中，得到：\n$$\nx^{(1)} = \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 0 \\end{pmatrix}\n$$\n我们观察到 $x^{(1)} = x^\\dagger_A$。第一次删除没有改变最小范数解。\n\n**步骤 3：第二次删除后（矩阵 $A^{(2)}$）的分析**\n\n从 $A^{(1)}$ 中移除第 2 列以构成 $A^{(2)} \\in \\mathbb{R}^{2 \\times 1}$：\n$$\nA^{(2)} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n该矩阵由单个非零列组成，因此是列满秩的，其秩为 $\\text{rank}(A^{(2)})=1$。零空间维数发生显著变化：$\\dim(\\mathcal{N}(A^{(2)})) = n - \\text{rank}(A^{(2)}) = 1-1=0$。零空间是平凡的，$\\mathcal{N}(A^{(2)}) = \\{0\\}$。\n对于一个满秩矩阵，最小二乘问题有唯一解，由正规方程给出：$(A^{(2)})^\\top A^{(2)} x_1 = (A^{(2)})^\\top b$。\n$(A^{(2)})^\\top A^{(2)} = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 1$。\n$(A^{(2)})^\\top b = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 1$。\n正规方程为 $1 \\cdot x_1 = 1$，得出唯一解 $x_1=1$。这就是最小范数解。\n$$\nx^{\\dagger}_{A^{(2)}} = \\begin{pmatrix} 1 \\end{pmatrix}\n$$\n通过将已删除的第二和第三列用零填充，将此解嵌入到 $\\mathbb{R}^3$ 中，得到：\n$$\nx^{(2)} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n解从 $x^{(1)}$ 不连续地跳跃到了 $x^{(2)}$。\n\n**步骤 4：通过预解式 $(A^\\top A)^\\dagger$ 解释不连续性**\n\n我们在每一步分析 Gram 矩阵（预解式）的伪逆。\n对于 $A^{(1)}$，其 Gram 矩阵为 $G^{(1)} = (A^{(1)})^\\top A^{(1)} = \\begin{pmatrix} 1  0 \\\\ 1  0 \\end{pmatrix}\\begin{pmatrix} 1  1 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix}$。这个矩阵是奇异的。其特征值为 $\\lambda_1=2, \\lambda_2=0$，对应的特征向量为 $u_1 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ 和 $u_2 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$。伪逆由非零特征值及其特征向量构造：\n$$\n(G^{(1)})^\\dagger = \\frac{1}{\\lambda_1} u_1 u_1^\\top = \\frac{1}{2}\\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\right)\\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1  1 \\end{pmatrix}\\right) = \\frac{1}{4}\\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix}\n$$\n对于 $A^{(2)}$，其 Gram 矩阵为 $G^{(2)} = (A^{(2)})^\\top A^{(2)} = \\begin{pmatrix} 1 \\end{pmatrix}$。这是一个满秩矩阵。它的伪逆就是它的逆：$(G^{(2)})^\\dagger = (1)^{-1} = 1$。\n\n解 $x^\\dagger$ 的不连续性是矩阵伪逆运算在秩不恒定的矩阵处不连续的直接后果。从 $A^{(1)}$ 中删除第 2 列使其从一个秩亏矩阵变为一个满秩矩阵。这对应于 Gram 矩阵从 $G^{(1)}$ 到 $G^{(2)}$ 的变化。$G^{(1)}$ 的伪逆不是某个更大矩阵伪逆的一个简单子块，并且其元素与它子矩阵的伪逆没有连续关系。具体来说，$(G^{(1)})^\\dagger_{11} = 1/4$，而 $(G^{(2)})^\\dagger = 1$。因为解 $x^\\dagger$ 直接依赖于这个预解式，所以 $(A^\\top A)^\\dagger$ 的不连续性会传播到解上。\n\n从根本上说，对于秩亏问题 $A^{(1)}$ 的最小范数解通过分配解的分量来最小化 $\\|x\\|_2$ 来满足 $x_1+x_2=1$，从而得到 $x_1=x_2=1/2$。删除第 2 列后，对应的变量 $x_2$ 被约束为 $0$。对于 $A^{(2)}$ 的问题将全部“负载”施加到 $x_1$ 上，从而得到 $x_1=1$。这种从秩亏情况下的分布式解到满秩情况下的局部化解的变化导致了跳跃。\n\n**步骤 5：计算跳跃幅度**\n解的跳跃是删除第 2 列前后嵌入的最小范数解之间的差值。\n删除前的解：$x^{(1)} = \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 0 \\end{pmatrix}$。\n删除后的解：$x^{(2)} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$。\n跳跃向量为 $\\Delta x = x^{(2)} - x^{(1)} = \\begin{pmatrix} 1 - 1/2 \\\\ 0 - 1/2 \\\\ 0 - 0 \\end{pmatrix} = \\begin{pmatrix} 1/2 \\\\ -1/2 \\\\ 0 \\end{pmatrix}$。\n这个跳跃的欧几里得范数为：\n$$\n\\|\\Delta x\\|_2 = \\sqrt{\\left(\\frac{1}{2}\\right)^2 + \\left(-\\frac{1}{2}\\right)^2 + 0^2} = \\sqrt{\\frac{1}{4} + \\frac{1}{4}} = \\sqrt{\\frac{2}{4}} = \\sqrt{\\frac{1}{2}} = \\frac{\\sqrt{2}}{2}\n$$",
            "answer": "$$\n\\boxed{\\frac{\\sqrt{2}}{2}}\n$$"
        },
        {
            "introduction": "面对秩亏问题带来的不确定性和不稳定性，我们需要一种在数值上稳健可靠的通用方法。这个实践任务将指导你使用奇异值分解（SVD）来构建一个强大的最小二乘求解器。通过实现这个求解器并应用于一系列精心设计的测试案例，你将学会如何处理数值秩的确定，并理解SVD为何是解决此类问题的黄金标准方法。",
            "id": "3271561",
            "problem": "您的任务是设计并实现一个稳健的求解器，用于解决秩亏最小二乘问题。该求解器需使用奇异值分解（SVD），其中奇异值分解（SVD）定义为将一个实矩阵分解为正交因子和对角因子的过程。该数学问题描述如下：给定一个实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和一个实向量 $b \\in \\mathbb{R}^{m}$，计算一个向量 $x \\in \\mathbb{R}^{n}$，以最小化残差的欧几里得范数，即 $\\lVert A x - b \\rVert_2$，即使当 $A$ 是秩亏或近似秩亏时也同样适用。您的实现必须通过基于 SVD 的方法以数值稳定的方式解决此问题，并且必须返回最小欧几里得范数解。求解器必须通过选择一个与机器精度和问题规模相关的、有原则的数值容差来处理秩亏情况，以决定哪些奇异值被视作零。不允许使用正规方程或任何会使条件数平方的方法。\n\n此任务的基本原理包括：\n- 最小二乘的欧几里得范数最小化定义，$\\min_{x \\in \\mathbb{R}^n} \\lVert A x - b \\rVert_2$。\n- 通过奇异值分解（SVD）对实矩阵进行分解，$A = U \\Sigma V^\\top$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 的对角元为非负数，称为奇异值。\n- 与机器精度 $\\epsilon$ 下的浮点运算相关的数值秩和条件性概念。\n\n实现一个程序，该程序：\n- 使用基于 SVD 的伪逆计算最小欧几里得范数最小二乘解，该伪逆通过将与 $\\epsilon$ 和 $A$ 的尺度相关的容差下被视为数值上可忽略的奇异值置零，从而稳健地处理秩亏情况。\n- 将此求解器应用于以下由固定矩阵和向量组成的测试套件。对于每个测试用例，返回解向量 $x$ 的分量，四舍五入到8位小数。\n\n测试套件：\n- 案例 1（秩亏，相容）：\n  $$A_1 = \\begin{bmatrix} 1  2 \\\\ 2  4 \\\\ 3  6 \\end{bmatrix}, \\quad b_1 = \\begin{bmatrix} 3 \\\\ 6 \\\\ 9 \\end{bmatrix}.$$\n- 案例 2（秩亏，不相容）：\n  $$A_2 = \\begin{bmatrix} 1  2 \\\\ 2  4 \\\\ 3  6 \\end{bmatrix}, \\quad b_2 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}.$$\n- 案例 3（零矩阵边界情况）：\n  $$A_3 = \\begin{bmatrix} 0  0 \\\\ 0  0 \\\\ 0  0 \\end{bmatrix}, \\quad b_3 = \\begin{bmatrix} 1 \\\\ -2 \\\\ 3 \\end{bmatrix}.$$\n- 案例 4（近似秩亏，需仔细处理数值上的小奇异值）：\n  $$A_4 = \\begin{bmatrix} 1  (1 + 10^{-16}) \\\\ 2  (2 + 2 \\cdot 10^{-16}) \\\\ 3  (3 + 3 \\cdot 10^{-16}) \\end{bmatrix}, \\quad b_4 = \\begin{bmatrix} 2 \\\\ 4 \\\\ 6 \\end{bmatrix}.$$\n- 案例 5（满秩，超定）：\n  $$A_5 = \\begin{bmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\end{bmatrix}, \\quad b_5 = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}.$$\n\n最终输出规范：\n- 您的程序应生成单行输出，其中包含一个由逗号分隔并用方括号括起来的结果列表（例如，$[result_1,result_2,\\dots]$）。\n- 每个元素 $result_k$ 本身必须是一个列表，表示第 $k$ 个案例的解向量 $x$，其分量需四舍五入到8位小数并以十进制数（而非分数）形式呈现。\n- 因此，输出格式必须为 $[[x_{1,1},x_{1,2}], [x_{2,1},x_{2,2}], [x_{3,1},x_{3,2}], [x_{4,1},x_{4,2}], [x_{5,1},x_{5,2}]]$，并且行内任何地方都不能有空格。",
            "solution": "目标是为给定的实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和实向量 $b \\in \\mathbb{R}^m$，找到最小二乘问题 $\\min_{x} \\lVert A x - b \\rVert_2$ 的最小欧几里得范数解 $x \\in \\mathbb{R}^n$。该问题需使用基于奇异值分解（SVD）的数值稳健方法来解决，当矩阵 $A$ 秩亏或病态时，该方法尤其有效。明确禁止使用会使条件数平方的方法，例如构建正规方程 $A^\\top A x = A^\\top b$。\n\n该方法的基础是矩阵 $A$ 的奇异值分解（SVD）：\n$$A = U \\Sigma V^\\top$$\n其中：\n- $U \\in \\mathbb{R}^{m \\times m}$ 是一个正交矩阵（$U^\\top U = I_m$），其列向量 $\\mathbf{u}_i$ 是左奇异向量。\n- $V \\in \\mathbb{R}^{n \\times n}$ 是一个正交矩阵（$V^\\top V = I_n$），其列向量 $\\mathbf{v}_i$ 是右奇异向量。\n- $\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个矩形对角矩阵，其对角线上的非负实数被称为奇异值 $\\sigma_i$。它们按顺序排列，使得 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_r  0$，其中 $r$ 是 $A$ 的秩。所有其他奇异值均为零。\n\n将SVD代入最小二乘目标函数，我们寻求最小化：\n$$\\lVert A x - b \\rVert_2 = \\lVert U \\Sigma V^\\top x - b \\rVert_2$$\n欧几里得范数在与正交矩阵相乘时保持不变。因此，我们可以将范数内的项乘以 $U^\\top$ 而不改变其值：\n$$\\lVert U \\Sigma V^\\top x - b \\rVert_2 = \\lVert U^\\top (U \\Sigma V^\\top x - b) \\rVert_2 = \\lVert (U^\\top U) \\Sigma V^\\top x - U^\\top b \\rVert_2 = \\lVert \\Sigma V^\\top x - U^\\top b \\rVert_2$$\n为简化此表达式，我们引入变量替换。令 $y = V^\\top x$。因为 $V$ 是正交的，所以我们有 $x = V y$。此外，$x$ 的范数得以保持：$\\lVert x \\rVert_2 = \\lVert V y \\rVert_2 = \\lVert y \\rVert_2$。因此，找到 $x$ 的最小范数解等价于找到 $y$ 的最小范数解。\n令 $\\hat{b} = U^\\top b$。问题转化为最小化 $\\lVert \\Sigma y - \\hat{b} \\rVert_2$。\n\n其范数的平方由下式给出：\n$$\\lVert \\Sigma y - \\hat{b} \\rVert_2^2 = \\sum_{i=1}^{\\min(m, n)} (\\sigma_i y_i - \\hat{b}_i)^2 + \\sum_{i=\\min(m, n)+1}^{m} \\hat{b}_i^2$$\n第二项是最终残差的一部分，且与 $y$ 无关。为了最小化范数，我们必须最小化第一项。\n- 对于奇异值 $\\sigma_i  0$ 的索引 $i$（即 $i=1, \\dots, r$），通过将该项设为零来达到最小值：$\\sigma_i y_i - \\hat{b}_i = 0$，从而得出 $y_i = \\hat{b}_i / \\sigma_i$。\n- 对于 $\\sigma_i = 0$ 的索引 $i$（即 $i=r+1, \\dots, n$），该项变为 $(0 \\cdot y_i - \\hat{b}_i)^2 = \\hat{b}_i^2$。$y_i$ 的值是任意的，不影响残差范数。\n\n为了找到具有最小欧几里得范数 $\\lVert x \\rVert_2 = \\lVert y \\rVert_2$ 的解，我们必须选择 $y$ 的分量来最小化 $\\lVert y \\rVert_2^2 = \\sum_{i=1}^n y_i^2$。对于 $i=1, \\dots, r$，$y_i = \\hat{b}_i / \\sigma_i$ 的值是固定的。为了最小化平方和，$y$ 的其余任意分量必须设为零。因此，对于 $i=r+1, \\dots, n$，我们设 $y_i=0$。\n\n最小范数解 $y$ 的分量为：\n$$y_i = \\begin{cases} \\hat{b}_i / \\sigma_i,  \\text{若 } \\sigma_i  0 \\\\ 0,  \\text{若 } \\sigma_i = 0 \\end{cases}$$\n这个结果可以用 $A$ 的 Moore-Penrose 伪逆来表示，记为 $A^+ = V \\Sigma^+ U^\\top$。其中，$\\Sigma^+ \\in \\mathbb{R}^{n \\times m}$ 是 $\\Sigma$ 的伪逆，其非零对角元为 $(\\Sigma^+)_{ii} = 1/\\sigma_i$（当 $\\sigma_i  0$ 时）。解则为 $x = A^+ b = V \\Sigma^+ U^\\top b$。\n\n在数值计算中，由于浮点表示误差，理论上为零的奇异值可能会计算为非常小的非零数。用这些小数来除会导致数值不稳定。为解决此问题，我们通过引入一个容差 $\\tau$ 来定义数值秩。任何小于 $\\tau$ 的奇异值 $\\sigma_i$ 都被视为零。此容差的一个有原则的选择是将其与机器精度 $\\epsilon_{\\text{machine}}$ 和问题规模联系起来：\n$$\\tau = \\max(m, n) \\cdot \\sigma_1 \\cdot \\epsilon_{\\text{machine}}$$\n其中 $\\sigma_1$ 是最大的奇异值。\n\n算法如下：\n$1$. 给定 $A$ 和 $b$，计算 SVD：$A = U \\Sigma V^\\top$。这将得到 $U$、奇异值向量 $s$ 和 $V^\\top$。\n$2$. 如果 $A$ 是零矩阵（即所有奇异值均为零），则最小范数解为 $x=0$。\n$3$. 否则，确定容差 $\\tau = \\max(m, n) \\cdot s[0] \\cdot \\epsilon_{\\text{machine}}$。\n$4$. 确定数值秩 $r$，即大于或等于 $\\tau$ 的奇异值 $s_i$ 的数量。\n$5$. 对于每个满足 $s_i \\ge \\tau$ 的奇异值 $s_i$，我们计算解基向量 $\\mathbf{v}_i$ 对应的系数：$c_i = (\\mathbf{u}_i^\\top b) / s_i$。\n$6$. 最终解是前 $r$ 个右奇异向量的线性组合，并由这些系数加权：\n$$x = \\sum_{i=1}^{r} \\frac{\\mathbf{u}_i^\\top b}{\\sigma_i} \\mathbf{v}_i$$\n此过程以数值稳定的方式构建了最小范数最小二乘解，通过截断可忽略的奇异值，正确处理了秩亏和病态的情况。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a set of rank-deficient least squares problems using SVD.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (rank-deficient, consistent)\n        (np.array([[1.0, 2.0], [2.0, 4.0], [3.0, 6.0]]),\n         np.array([3.0, 6.0, 9.0])),\n\n        # Case 2 (rank-deficient, inconsistent)\n        (np.array([[1.0, 2.0], [2.0, 4.0], [3.0, 6.0]]),\n         np.array([1.0, 1.0, 1.0])),\n\n        # Case 3 (zero matrix boundary)\n        (np.array([[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]),\n         np.array([1.0, -2.0, 3.0])),\n\n        # Case 4 (nearly rank-deficient, numerically treat small singular values carefully)\n        (np.array([[1.0, 1.0 + 1e-16], \n                   [2.0, 2.0 + 2e-16], \n                   [3.0, 3.0 + 3e-16]]),\n         np.array([2.0, 4.0, 6.0])),\n\n        # Case 5 (full rank, overdetermined)\n        (np.array([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]]),\n         np.array([1.0, 2.0, 3.0]))\n    ]\n\n    results = []\n    \n    for A, b in test_cases:\n        m, n = A.shape\n        \n        # Compute the Singular Value Decomposition\n        U, s, Vt = np.linalg.svd(A)\n\n        # Handle the case of a zero matrix or matrix with no non-zero singular values.\n        # The SVD of a zero matrix might result in an empty 's' array if m or n is 0,\n        # or s[0] will be 0.\n        if not s.size or np.isclose(s[0], 0):\n            x = np.zeros(n)\n            results.append(np.round(x, 8).tolist())\n            continue\n\n        # Define the tolerance for treating singular values as zero.\n        # This is a standard choice in numerical linear algebra.\n        tol = np.max(A.shape) * s[0] * np.finfo(float).eps\n        \n        # Determine the numerical rank by counting singular values above the tolerance.\n        rank = np.sum(s  tol)\n        \n        if rank == 0:\n            # If all singular values are below tolerance, treat as a zero matrix.\n            x = np.zeros(n)\n        else:\n            # The solution x is given by sum_{i=1 to r} (u_i^T * b / s_i) * v_i\n            # This is equivalent to V_r @ diag(1/s_r) @ U_r.T @ b\n            \n            # 1. Take the first 'rank' singular values and invert them.\n            s_inv = 1.0 / s[:rank]\n            \n            # 2. Compute U.T @ b and take the first 'rank' components.\n            # U has shape (m, m), b has shape (m,), so U.T @ b has shape (m,).\n            c = U.T @ b\n            c = c[:rank]\n            \n            # 3. Compute coefficients for the linear combination of V's columns.\n            # This is equivalent to diag(1/s_r) @ U_r.T @ b\n            x_coeffs = s_inv * c\n            \n            # 4. Compute the solution x by combining the first 'rank' columns of V (which are rows of Vt).\n            # Vt has shape (n, n). Vt[:rank].T gives the first 'rank' columns of V.\n            x = Vt[:rank].T @ x_coeffs\n        \n        # Round the components of the solution vector to 8 decimal places.\n        rounded_x = np.round(x, 8).tolist()\n        results.append(rounded_x)\n\n    # Format the final output string according to the specification.\n    # The str() representation of a list includes spaces, which need to be removed.\n    output_str = f\"[{','.join(str(r) for r in results)}]\"\n    output_str = output_str.replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}