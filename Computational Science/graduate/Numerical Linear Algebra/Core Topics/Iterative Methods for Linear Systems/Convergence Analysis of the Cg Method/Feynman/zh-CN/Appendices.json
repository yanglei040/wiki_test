{
    "hands_on_practices": [
        {
            "introduction": "理解共轭梯度（CG）方法的收敛性，始于其与多项式逼近理论的深刻联系。本练习旨在通过应用经典的、基于切比雪夫多项式的误差界，将矩阵的抽象谱特性（如条件数 $\\kappa(A)$）转化为对达到特定精度所需迭代次数的具体估计 。这项技能不仅是预测CG方法性能的基础，也是理解预处理技术为何有效的关键。",
            "id": "3541532",
            "problem": "考虑一个实对称正定矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其谱 $\\sigma(A) \\subset [1,100]$。设 $x^{\\star}$ 是 $Ax=b$ 的唯一解，并设 $e_k := x_k - x^{\\star}$ 表示共轭梯度（CG）方法迭代 $k$ 次后的误差。利用CG作为多项式方法的基于切比雪夫多项式的最优性刻画和谱定理，推导出一个关于误差的$A$-范数的先验界，形式为 $\\|e_k\\|_{A} \\leq \\gamma_k \\|e_0\\|_{A}$，其中 $\\gamma_k$ 由在区间 $[1,100]$ 上满足 $p(0)=1$ 约束的 $k$ 次多项式对零函数的最佳一致逼近确定。从第一性原理出发，通过将区间 $[1,100]$ 映射到 $[-1,1]$，利用切比雪夫多项式的极小化极大性质，构造该界，并将所得表达式简化为谱条件数的闭式形式。然后，利用这个基于切比雪夫的估计，确定保证下式成立的最小整数迭代次数 $k \\in \\mathbb{N}$：\n$$\n\\frac{\\|e_k\\|_{A}}{\\|e_0\\|_{A}} \\leq 10^{-6}.\n$$\n将最终答案表示为单个整数。无需进行超出最小整数要求之外的舍入。",
            "solution": "该问题要求推导共轭梯度（CG）方法的先验误差界，并应用它来找到一个特定的迭代次数。\n\n首先，我们验证问题陈述的有效性。\n**步骤1：提取已知条件**\n- 矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 是实对称正定（SPD）矩阵。\n- $A$ 的谱，记为 $\\sigma(A)$，是区间 $[1, 100]$ 的一个子集。\n- $x^{\\star}$ 是线性系统 $Ax=b$ 的唯一解。\n- $e_k = x_k - x^{\\star}$ 是第 $k$ 次迭代时的误差向量。\n- 该方法是共轭梯度（CG）方法。\n- 任务涉及使用CG作为多项式方法的刻画以及切比雪夫多项式的性质。\n- 目标是找到最小的整数 $k$，使得 $A$-范数下的相对误差 $\\|e_k\\|_{A}/\\|e_0\\|_{A}$ 以 $10^{-6}$为界。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题在数值线性代数的成熟理论，特别是克雷洛夫子空间方法的收敛性分析中有坚实的科学基础。所有前提，包括矩阵 $A$ 的性质和CG误差的表述，都是标准且正确的。该问题是适定的，提供了所有必要信息（谱范围和误差容限）以确定 $k$ 的唯一整数解。其语言客观而精确。该问题是该领域一个标准的、非平凡的练习。因此，该问题被认为是有效的。\n\n**步骤3：结论与行动**\n问题有效。我们继续进行求解。\n\n**基于切比雪夫的误差界的推导：**\n\n用于求解 $Ax=b$ 的共轭梯度法，从一个初始猜测 $x_0$ 开始，生成一个近似序列 $x_k$。误差向量 $e_k = x_k - x^{\\star}$ 可以用一个多项式通过初始误差 $e_0 = x_0 - x^{\\star}$ 来表示。具体来说，迭代向量满足 $x_k - x_0 \\in \\mathcal{K}_k(A, r_0)$，其中 $r_0 = b - Ax_0 = -Ae_0$ 是初始残差，$\\mathcal{K}_k$ 是 $k$ 阶克雷洛夫子空间。这意味着误差 $e_k$ 可以写成：\n$$ e_k = p_k(A) e_0 $$\n其中 $p_k$ 是一个次数至多为 $k$ 的多项式，属于集合 $\\mathcal{P}_k$，且满足约束 $p_k(0) = 1$。CG方法具有最优性：它能找到那个特定的多项式 $p_k$，该多项式使得在 $A$-范数下的误差最小化，其中 $A$-范数定义为 $\\|v\\|_A = \\sqrt{v^T A v}$。\n$$ \\|e_k\\|_A = \\min_{q_k \\in \\mathcal{P}_k, q_k(0)=1} \\|q_k(A)e_0\\|_A $$\n为了获得一个独立于初始误差 $e_0$ 的先验界，我们使用 $A$ 的谱分解。设 $A=V\\Lambda V^T$ 是 $A$ 的特征分解，其中 $\\Lambda = \\text{diag}(\\lambda_1, \\dots, \\lambda_n)$ 包含 $A$ 的所有特征值。误差的 $A$-范数可以如下界定：\n$$ \\|e_k\\|_A = \\|p_k(A) e_0\\|_A \\le \\left( \\min_{q_k \\in \\mathcal{P}_k, q_k(0)=1} \\max_{\\lambda \\in \\sigma(A)} |q_k(\\lambda)| \\right) \\|e_0\\|_A $$\n问题陈述了 $\\sigma(A) \\subset [1, 100]$。设 $\\alpha = \\lambda_{\\min}(A)$ 和 $\\beta = \\lambda_{\\max}(A)$。当谱覆盖整个给定区间时，这个界是最保守的，因此我们考虑 $\\lambda \\in [\\alpha, \\beta]$，并取 $\\alpha=1$ 和 $\\beta=100$。问题简化为一个经典的多项式逼近问题：\n$$ \\frac{\\|e_k\\|_A}{\\|e_0\\|_A} \\le \\min_{q_k \\in \\mathcal{P}_k, q_k(0)=1} \\max_{\\lambda \\in [\\alpha, \\beta]} |q_k(\\lambda)| $$\n为了解决这个极小化极大问题，我们使用仿射变换将区间 $[\\alpha, \\beta]$ 映射到标准区间 $[-1, 1]$：\n$$ x(\\lambda) = \\frac{2\\lambda - (\\beta+\\alpha)}{\\beta-\\alpha} $$\n在这个映射下，一个 $k$ 次多项式 $q_k(\\lambda)$ 变成一个 $k$ 次多项式 $Q_k(x)$。约束 $q_k(0)=1$ 变为对 $Q_k$ 在点 $x_0 = x(0)$ 处的约束：\n$$ x_0 = \\frac{2(0) - (\\beta+\\alpha)}{\\beta-\\alpha} = -\\frac{\\beta+\\alpha}{\\beta-\\alpha} $$\n问题现在是要在 $Q_k(x_0)=1$ 的约束下，找到 $\\min \\max_{x \\in [-1, 1]} |Q_k(x)|$。解由一个经过缩放的第一类切比雪夫多项式 $T_k(x)$ 给出：\n$$ Q_k(x) = \\frac{T_k(x)}{T_k(x_0)} $$\n在 $[-1, 1]$ 上 $|Q_k(x)|$ 的最大值是 $\\frac{\\max_{x \\in [-1, 1]}|T_k(x)|}{|T_k(x_0)|} = \\frac{1}{|T_k(x_0)|}$。由于 $\\alpha, \\beta > 0$，我们有 $x_0 < -1$。对于 $z < -1$，有 $|T_k(z)| = T_k(|z|)$。因此，界变为：\n$$ \\frac{\\|e_k\\|_A}{\\|e_0\\|_A} \\le \\frac{1}{T_k\\left(\\frac{\\beta+\\alpha}{\\beta-\\alpha}\\right)} $$\n这个表达式可以用谱条件数 $\\kappa = \\beta/\\alpha$ 来表示：\n$$ \\frac{\\beta+\\alpha}{\\beta-\\alpha} = \\frac{(\\beta/\\alpha)+1}{(\\beta/\\alpha)-1} = \\frac{\\kappa+1}{\\kappa-1} $$\n所以，该界的最终形式是：\n$$ \\frac{\\|e_k\\|_A}{\\|e_0\\|_A} \\le \\frac{1}{T_k\\left(\\frac{\\kappa+1}{\\kappa-1}\\right)} $$\n\n**迭代次数 $k$ 的计算：**\n\n给定 $\\sigma(A) \\subset [1, 100]$，所以我们设 $\\alpha=1$ 和 $\\beta=100$。条件数为 $\\kappa = 100/1 = 100$。我们希望找到最小的整数 $k$，使得：\n$$ \\frac{\\|e_k\\|_A}{\\|e_0\\|_A} \\le 10^{-6} $$\n使用我们推导出的界，我们必须满足：\n$$ \\frac{1}{T_k\\left(\\frac{100+1}{100-1}\\right)} \\le 10^{-6} \\implies T_k\\left(\\frac{101}{99}\\right) \\ge 10^6 $$\n对于自变量 $|z| \\ge 1$，切比雪夫多项式可以用双曲余弦函数表示：$T_k(z) = \\cosh(k \\, \\text{arccosh}(z))$。该不等式变为：\n$$ \\cosh\\left(k \\, \\text{arccosh}\\left(\\frac{101}{99}\\right)\\right) \\ge 10^6 $$\n由于 $\\cosh(y)$ 对于 $y > 0$ 是一个严格递增函数，我们可以对两边取反双曲余弦：\n$$ k \\, \\text{arccosh}\\left(\\frac{101}{99}\\right) \\ge \\text{arccosh}(10^6) $$\n解出 $k$：\n$$ k \\ge \\frac{\\text{arccosh}(10^6)}{\\text{arccosh}\\left(\\frac{101}{99}\\right)} $$\n我们可以使用恒等式 $\\text{arccosh}\\left(\\frac{\\kappa+1}{\\kappa-1}\\right) = 2 \\, \\text{artanh}\\left(\\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1}\\right)$，或者更直接地，使用对数形式 $\\text{arccosh}(z) = \\ln(z + \\sqrt{z^2-1})$。\n对于分母，我们使用另一个恒等式 $\\text{arccosh}\\left(\\frac{\\kappa+1}{\\kappa-1}\\right) = \\ln\\left(\\frac{\\sqrt{\\kappa}+1}{\\sqrt{\\kappa}-1}\\right)$。对于 $\\kappa=100$：\n$$ \\text{arccosh}\\left(\\frac{101}{99}\\right) = \\ln\\left(\\frac{\\sqrt{100}+1}{\\sqrt{100}-1}\\right) = \\ln\\left(\\frac{10+1}{10-1}\\right) = \\ln\\left(\\frac{11}{9}\\right) $$\n所以，关于 $k$ 的不等式是：\n$$ k \\ge \\frac{\\text{arccosh}(10^6)}{\\ln(11/9)} $$\n现在我们对此表达式进行数值计算。\n$$ \\text{arccosh}(10^6) = \\ln(10^6 + \\sqrt{(10^6)^2 - 1}) = \\ln(10^6 + \\sqrt{10^{12} - 1}) $$\n对于大的 $z$，$\\text{arccosh}(z) \\approx \\ln(2z)$。更精确地：\n$$ \\text{arccosh}(10^6) \\approx \\ln(2 \\times 10^6) \\approx 14.508658 $$\n分母是：\n$$ \\ln(11/9) \\approx 0.200671 $$\n因此，\n$$ k \\ge \\frac{14.508658}{0.200671} \\approx 72.3005 $$\n由于迭代次数 $k$ 必须是整数，满足此条件的最小整数值为 $k=73$。",
            "answer": "$$\n\\boxed{73}\n$$"
        },
        {
            "introduction": "尽管CG方法在理论上保证了误差的A-范数（$\\|e_k\\|_A$）是单调递减的，但一个在实践中更易于监控的量——残差的欧几里得范数（$\\|r_k\\|_2$）——却不具备此特性。这个编程练习将引导您构建一个具体的反例，从而直观地揭示这种与直觉相悖的现象及其背后的几何成因 。掌握这一知识点对于正确解读CG方法的收敛过程以及设计更为稳健的算法终止准则至关重要。",
            "id": "3541518",
            "problem": "您必须编写一个完整、可运行的程序，以演示和分析共轭梯度（CG）方法在求解对称正定（SPD）线性系统时的单调性行为。其科学背景是数值线性代数和共轭梯度方法的收敛性分析。目标是构建一个具体的反例，在该反例中，欧几里得残差范数 $\\|r_k\\|_2$ 并非单调递减，而误差的能量范数 $\\|e_k\\|_A$ 严格递减，并通过一个小规模的测试套件来量化其行为。\n\n用作基础的定义和核心事实：\n- 一个矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 是对称正定（SPD）的，如果 $A^\\top = A$ 且对于所有非零 $x \\in \\mathbb{R}^n$ 都有 $x^\\top A x > 0$。\n- 共轭梯度（CG）方法旨在通过迭代生成 $x_k \\in x_0 + \\mathcal{K}_k(A, r_0)$ 来求解 $A$ 为 SPD 的 $A x = b$，其中 $r_k = b - A x_k$ 是残差，$e_k = x^\\star - x_k$ 是误差（$x^\\star$ 为精确解），$\\mathcal{K}_k(A, r_0) = \\mathrm{span}\\{r_0, A r_0, \\dots, A^{k-1} r_0\\}$ 是第 $k$ 个克雷洛夫子空间。\n- $A$-能量内积和范数分别为 $\\langle u, v \\rangle_A = u^\\top A v$ 和 $\\|u\\|_A = \\sqrt{u^\\top A u}$。CG 方法是关于 $\\langle \\cdot, \\cdot \\rangle_A$ 在 $x_0 + \\mathcal{K}_k(A, r_0)$ 上的伽辽金投影，这意味着 $\\|e_k\\|_A$ 是单调递减的（除非达到精确解，否则是严格递减）。\n- 欧几里得范数 $\\|\\cdot\\|_2$ 用于度量 $\\|r_k\\|_2$，但该量在CG方法中不保证是单调的。\n\n您的程序必须：\n1.  为给定的 SPD 矩阵 $A$、右端项 $b$ 和初始猜测值 $x_0$ 实现共轭梯度（CG）方法，生成迭代值 $x_k$、残差 $r_k$，并通过直接求解器计算精确解 $x^\\star$ 以度量 $\\|e_k\\|_A$。\n2.  对于每个测试用例，运行 CG 直到 $k$ 达到矩阵维度 $n$ 或 $\\|r_k\\|_2$ 低于停止容差。在欧几里得范数下使用 $10^{-12}\\,\\|b\\|_2$ 的停止容差。\n3.  计算序列 $\\{\\|r_k\\|_2\\}_{k=0}^{k_{\\mathrm{end}}}$ 和 $\\{\\|e_k\\|_A\\}_{k=0}^{k_{\\mathrm{end}}}$，其中 $k_{\\mathrm{end}}$ 是最后一次计算的迭代次数。\n4.  判断残差序列是否非增：对于所有连续的迭代值，是否有 $\\|r_{k+1}\\|_2 \\le \\|r_k\\|_2$，并找到最小的索引 $k$（使用从零开始的索引）使得 $\\|r_{k+1}\\|_2 > \\|r_k\\|_2$，如果不存在这样的索引，则返回 $-1$。使用带有数值容差 $10^{-14}$ 的严格比较，即仅当 $\\|r_{k+1}\\|_2 > \\|r_k\\|_2 + 10^{-14}$ 时才视为增加。\n5.  判断能量范数序列是否严格递减：在终止前的所有连续迭代中，是否有 $\\|e_{k+1}\\|_A < \\|e_k\\|_A$。使用带有数值容差 $10^{-14}$ 的严格比较，即要求每一步都满足 $\\|e_{k+1}\\|_A \\le \\|e_k\\|_A - 10^{-14}$。\n\n几何解释要求：\n- 虽然不要求您打印几何解释，但您的程序必须包含一个展示此现象的测试用例：一个反例，其中 $\\|r_k\\|_2$ 并非单调递减，即使 $\\|e_k\\|_A$ 严格递减。其构造应基于特征值高度各向异性且偏离坐标轴旋转的 SPD 矩阵，以在残差和 A-缩放的子空间之间产生非平凡的角度，这会影响残差的欧几里得范数。\n\n矩阵构造：\n- 构造形式为 $A = R^\\top \\Lambda R$ 的 SPD 矩阵 $A$，其中 $\\Lambda$ 是对角线上为正项的对角矩阵，$R$ 是由平面旋转构建的正交旋转矩阵。使用在 $(1,2)$ 和 $(3,4)$ 坐标平面上作用的块对角旋转，角度以弧度表示。\n\n测试套件：\n提供以下四个测试用例：\n- 测试用例 1（通用，各向异性，可能非单调残差）：$n=4$，$\\Lambda=\\mathrm{diag}(1, 20, 200, 5000)$，$R$ 是角度为 $\\theta_{12}=0.7$ 和 $\\theta_{34}=0.5$ 的块对角旋转矩阵，$b=[1,1,1,1]^\\top$，$x_0=[0,0,0,0]^\\top$。\n- 测试用例 2（边界条件与特征向量对齐，一步收敛）：$n=4$，$\\Lambda=\\mathrm{diag}(2,5,7,11)$，$R=I$，$b=[1,0,0,0]^\\top$，$x_0=[0,0,0,0]^\\top$。\n- 测试用例 3（良态，近似各向同性）：$n=4$，$\\Lambda=\\mathrm{diag}(1,1.5,2,2.5)$，$R$ 的角度为 $\\theta_{12}=0.2$ 和 $\\theta_{34}=0.0$，$b=[1,-1,2,-2]^\\top$，$x_0=[0,0,0,0]^\\top$。\n- 测试用例 4（系统性地在角度上搜索反例）：$n=4$，$\\Lambda=\\mathrm{diag}(1,50,500,10000)$，$R$ 由 $\\theta_{12}\\in\\{0.1,0.25,0.5,0.75,1.0,1.2\\}$（按顺序扫描）和固定的 $\\theta_{34}=0.9$ 形成；$b=[1,1,0.1,0.1]^\\top$，$x_0=[0,0,0,0]^\\top$；选择第一个表现出残差增大而能量范数严格递减的 $\\theta_{12}$，否则报告没有增大。\n\n角度单位规定：\n- 所有角度均以弧度为单位。\n\n您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，输出四元组 $[\\mathrm{res\\_noninc}, \\mathrm{energy\\_strict}, k_{\\mathrm{inc}}, \\theta]$，其中：\n- $\\mathrm{res\\_noninc}$ 是一个布尔值，指示在计算的迭代过程中 $\\|r_k\\|_2$ 是否非增。\n- $\\mathrm{energy\\_strict}$ 是一个布尔值，指示在计算的迭代过程中 $\\|e_k\\|_A$ 是否严格递减。\n- $k_{\\mathrm{inc}}$ 是满足 $\\|r_{k+1}\\|_2 > \\|r_k\\|_2 + 10^{-14}$ 的最小整数 $k \\ge 0$，如果不存在这样的索引，则为 $-1$。\n- $\\theta$ 是用于构建该测试用例中 $R$ 的角度 $\\theta_{12}$；如果测试用例未使用 $(1,2)$ 旋转，则此字段输出 $0.0$。\n\n因此，您最终打印的行必须如下所示：\n$[[\\mathrm{res\\_noninc}_1,\\mathrm{energy\\_strict}_1,k_{\\mathrm{inc},1},\\theta_1],[\\mathrm{res\\_noninc}_2,\\mathrm{energy\\_strict}_2,k_{\\mathrm{inc},2},\\theta_2],[\\mathrm{res\\_noninc}_3,\\mathrm{energy\\_strict}_3,k_{\\mathrm{inc},3},\\theta_3],[\\mathrm{res\\_noninc}_4,\\mathrm{energy\\_strict}_4,k_{\\mathrm{inc},4},\\theta_4]]$。",
            "solution": "该问题被评估为有效。它在科学上基于数值线性代数的原理，特别是共轭梯度（CG）方法的收敛理论。该问题是适定的，提供了所有必要的数据、定义和约束，并且没有歧义、主观性或任何事实或逻辑上的不一致。\n\n问题的核心是展示共轭梯度（CG）方法的一个众所周知的性质：虽然它保证误差的 $A$-范数单调递减，但残差的欧几里得范数不保证单调递减。\n\nCG方法是一种用于求解线性系统 $Ax=b$ 的迭代算法，其中矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 是对称正定（SPD）的。该方法构造一个近似精确解 $x^\\star$ 的序列 $x_k$。在每次迭代 $k$ 中，从仿射克雷洛夫子空间 $x_0 + \\mathcal{K}_k(A, r_0)$ 中选择新的近似值 $x_k$，使得误差的 $A$-范数 $\\|e_k\\|_A = \\|x^\\star - x_k\\|_A$ 被最小化。$A$-范数定义为 $\\|v\\|_A = \\sqrt{v^\\top A v}$。\n\n这种最小化性质确保了误差范数序列 $\\{\\|e_k\\|_A\\}$ 是严格递减的，除非找到精确解，此时误差范数变为并保持为零：\n$$ \\|e_{k+1}\\|_A < \\|e_k\\|_A \\quad \\text{若 } e_k \\neq 0 $$\n这是CG方法的一个基本收敛性质。\n\n残差定义为 $r_k = b - A x_k$。它与误差的关系是 $r_k = A e_k$。残差的欧几里得范数 $\\|r_k\\|_2$ 是终止迭代的常用实践度量。然而，与 $\\|e_k\\|_A$ 不同，序列 $\\{\\|r_k\\|_2\\}$ 不保证是单调的。在某些情况下，残差范数可能会出现增加，即 $\\|r_{k+1}\\|_2 > \\|r_k\\|_2$。\n\n这一现象可以通过分析残差更新步骤来理解。在CG的标准实现中，更新由下式给出：\n$$ r_{k+1} = r_k - \\alpha_k A p_k $$\n其中 $p_k$ 是搜索方向，$\\alpha_k$ 是步长。新残差的范数平方为：\n$$ \\|r_{k+1}\\|_2^2 = \\|r_k - \\alpha_k A p_k\\|_2^2 = \\|r_k\\|_2^2 - 2\\alpha_k r_k^\\top A p_k + \\alpha_k^2 \\|A p_k\\|_2^2 $$\n为使范数减小，必须满足条件 $2\\alpha_k r_k^\\top A p_k > \\alpha_k^2 \\|A p_k\\|_2^2$，这可以简化为 $2 r_k^\\top A p_k > \\alpha_k \\|A p_k\\|_2^2$。使用最优步长的标准公式 $\\alpha_k = \\frac{r_k^\\top r_k}{p_k^\\top A p_k}$ 以及将搜索方向 $p_k$ 与残差 $r_k$ 联系起来的性质，可以证明这个不等式依赖于矩阵 $A$ 的性质以及当前向量 $p_k$ 和 $r_k$。具体来说，如果矩阵 $A$ 的条件数很大（特征值分布范围广），并且搜索方向 $p_k$ 在对应于大特征值的特征向量上有显著分量，那么项 $\\alpha_k^2 \\|A p_k\\|_2^2$ 可能会大到足以导致 $\\|r_{k+1}\\|_2$ 增加。从几何上看，算法采取的步长在减小 $A$-范数环境下的误差方面是最优的，但就最小化欧几里得残差而言，这一步可能会“过冲”，导致暂时的增加。\n\n程序将实现CG算法并构造形式为 $A = R^\\top \\Lambda R$ 的测试矩阵，其中 $\\Lambda = \\mathrm{diag}(\\lambda_1, \\dots, \\lambda_n)$ 是特征值的对角矩阵，$R$ 是正交旋转矩阵。这种构造允许精确控制特征值（通过 $\\Lambda$）和特征向量的方向（通过 $R$）。通过选择大的特征值比率并将特征系统旋转偏离标准基，我们可以创建可靠地展示非单调残差行为的测试用例。\n\n解决方案将按以下步骤进行：\n1.  创建一个函数，根据给定的特征值和旋转角度构造矩阵 $A = R^\\top \\Lambda R$。旋转矩阵 $R$ 被构建为平面（Givens）旋转的复合。对于 $n=4$，我们使用一个块对角旋转矩阵：\n    $$ R(\\theta_{12}, \\theta_{34}) = \\begin{pmatrix} \\cos\\theta_{12} & -\\sin\\theta_{12} & 0 & 0 \\\\ \\sin\\theta_{12} & \\cos\\theta_{12} & 0 & 0 \\\\ 0 & 0 & \\cos\\theta_{34} & -\\sin\\theta_{34} \\\\ 0 & 0 & \\sin\\theta_{34} & \\cos\\theta_{34} \\end{pmatrix} $$\n2.  实现标准的CG算法。算法从初始猜测值 $x_0$ 开始，并计算：\n    - $r_0 = b - Ax_0$\n    - $p_0 = r_0$\n    - 对于 $k = 0, 1, 2, \\ldots$:\n      - $\\alpha_k = \\frac{r_k^\\top r_k}{p_k^\\top A p_k}$\n      - $x_{k+1} = x_k + \\alpha_k p_k$\n      - $r_{k+1} = r_k - \\alpha_k A p_k$\n      - 如果 $\\|r_{k+1}\\|_2$ 低于容差，则停止。\n      - $\\beta_{k+1} = \\frac{r_{k+1}^\\top r_{k+1}}{r_k^\\top r_k}$\n      - $p_{k+1} = r_{k+1} + \\beta_{k+1} p_k$\n3.  对于每次迭代，计算并存储范数 $\\|r_k\\|_2$ 和 $\\|e_k\\|_A$。计算 $e_k=x^\\star - x_k$ 所需的精确解 $x^\\star$ 将使用直接求解器预先计算。\n4.  CG迭代终止后，分析存储的范数序列，以使用指定的数值容差（$10^{-14}$）检查所需的单调性。具体来说，我们检查是否 $\\|r_{k+1}\\|_2 > \\|r_k\\|_2 + 10^{-14}$ 以找到残差首次增加的实例，并检查是否对所有步骤都满足 $\\|e_{k+1}\\|_A \\le \\|e_k\\|_A - 10^{-14}$ 以确认能量范数的严格递减。\n5.  将此过程应用于所有指定的测试用例，包括用例4中的搜索，并按要求格式化结果。",
            "answer": "```python\nimport numpy as np\n\ndef construct_matrix(n, lambdas, theta12, theta34):\n    \"\"\"\n    Constructs an SPD matrix A = R.T @ Lambda @ R of size n x n.\n    R is a block-diagonal rotation matrix.\n    \"\"\"\n    if n != 4:\n        raise ValueError(\"This matrix construction is defined for n=4.\")\n    \n    Lambda = np.diag(lambdas)\n    \n    R = np.identity(n)\n    \n    # Rotation in the (1,2) plane (indices 0, 1)\n    if theta12 != 0.0:\n        c12, s12 = np.cos(theta12), np.sin(theta12)\n        R12 = np.array([[c12, -s12], [s12, c12]])\n        R[0:2, 0:2] = R12\n\n    # Rotation in the (3,4) plane (indices 2, 3)\n    if theta34 != 0.0:\n        c34, s34 = np.cos(theta34), np.sin(theta34)\n        R34 = np.array([[c34, -s34], [s34, c34]])\n        R[2:4, 2:4] = R34\n\n    A = R.T @ Lambda @ R\n    return A\n\ndef run_cg_analysis(A, b, x0, theta12_val, max_iter_n):\n    \"\"\"\n    Runs the Conjugate Gradient method and analyzes norm behavior.\n    \"\"\"\n    n = A.shape[0]\n    \n    # Tolerances\n    stop_tol = 1e-12 * np.linalg.norm(b)\n    increase_tol = 1e-14\n    decrease_tol = 1e-14\n\n    # Compute exact solution to measure error\n    x_star = np.linalg.solve(A, b)\n\n    r_norms = []\n    e_norms = []\n\n    # CG Initialization\n    x = x0.copy()\n    r = b - A @ x\n    p = r.copy()\n    rs_old = np.dot(r, r)\n\n    # Store initial norms (k=0)\n    e = x_star - x\n    r_norms.append(np.linalg.norm(r))\n    e_norms.append(np.sqrt(e.T @ A @ e))\n\n    if np.linalg.norm(r)  stop_tol:\n        max_iter_n = 0\n\n    for k in range(max_iter_n):\n        Ap = A @ p\n        alpha = rs_old / np.dot(p, Ap)\n        \n        x = x + alpha * p\n        r = r - alpha * Ap\n        \n        # Store norms for step k+1\n        e = x_star - x\n        r_norms.append(np.linalg.norm(r))\n        e_norms.append(np.sqrt(e.T @ A @ e))\n        \n        rs_new = np.dot(r, r)\n        \n        if np.sqrt(rs_new)  stop_tol:\n            break\n            \n        beta = rs_new / rs_old\n        p = r + beta * p\n        rs_old = rs_new\n\n    # Analyze norm sequences\n    # 1. Residual norm non-increase check\n    k_inc = -1\n    res_noninc = True\n    for k in range(len(r_norms) - 1):\n        if r_norms[k+1] > r_norms[k] + increase_tol:\n            k_inc = k\n            res_noninc = False\n            break\n\n    # 2. Energy norm strict decrease check\n    energy_strict = True\n    # If the method converges exactly, error norm becomes 0 and stays 0.\n    # This is not a violation of strict decrease.\n    for k in range(len(e_norms) - 1):\n        if e_norms[k] > 1e-15: # Avoid issues with floating point zero\n             # Check if e_norms[k+1]  e_norms[k] respecting tolerance\n            if e_norms[k+1] > e_norms[k] - decrease_tol:\n                energy_strict = False\n                break\n    \n    return [res_noninc, energy_strict, k_inc, theta12_val]\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    results = []\n    n = 4\n\n    # Test case 1\n    lambdas1 = [1., 20., 200., 5000.]\n    theta12_1, theta34_1 = 0.7, 0.5\n    b1 = np.array([1., 1., 1., 1.])\n    x0_1 = np.zeros(n)\n    A1 = construct_matrix(n, lambdas1, theta12_1, theta34_1)\n    results.append(run_cg_analysis(A1, b1, x0_1, theta12_1, n))\n\n    # Test case 2\n    lambdas2 = [2., 5., 7., 11.]\n    theta12_2, theta34_2 = 0.0, 0.0\n    b2 = np.array([1., 0., 0., 0.])\n    x0_2 = np.zeros(n)\n    A2 = construct_matrix(n, lambdas2, theta12_2, theta34_2)\n    # The initial residual is an eigenvector, so it converges in 1 step.\n    # The loop will run once (k=0), norms list will have length 2.\n    results.append(run_cg_analysis(A2, b2, x0_2, theta12_2, n))\n\n    # Test case 3\n    lambdas3 = [1., 1.5, 2., 2.5]\n    theta12_3, theta34_3 = 0.2, 0.0\n    b3 = np.array([1., -1., 2., -2.])\n    x0_3 = np.zeros(n)\n    A3 = construct_matrix(n, lambdas3, theta12_3, theta34_3)\n    results.append(run_cg_analysis(A3, b3, x0_3, theta12_3, n))\n\n    # Test case 4\n    lambdas4 = [1., 50., 500., 10000.]\n    theta12_vals_4 = [0.1, 0.25, 0.5, 0.75, 1.0, 1.2]\n    theta34_4 = 0.9\n    b4 = np.array([1., 1., 0.1, 0.1])\n    x0_4 = np.zeros(n)\n    \n    found_increase = False\n    last_result = None\n    for theta12 in theta12_vals_4:\n        A4 = construct_matrix(n, lambdas4, theta12, theta34_4)\n        current_result = run_cg_analysis(A4, b4, x0_4, theta12, n)\n        last_result = current_result\n        # The result's k_inc is at index 2\n        if current_result[2] != -1:\n            results.append(current_result)\n            found_increase = True\n            break\n    \n    if not found_increase:\n        results.append(last_result)\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "CG方法的诸多优美理论性质，如残差向量的正交性和搜索方向的A-共轭性，都建立在精确算术的理想假设之上。在实际计算中，浮点舍入误差会不可避免地破坏这些性质，进而影响算法的收敛效率。本练习通过一个计算实验，让您模拟并量化这些舍入误差所带来的影响，从而展示为何即便是微小的计算扰动，也可能导致算法收敛速度显著下降，尤其是在求解病态线性系统时 。",
            "id": "3541548",
            "problem": "你的任务是分析和论证浮点舍入误差对求解对称正定线性系统的共轭梯度法的影响。考虑线性系统 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是对称正定矩阵，$b \\in \\mathbb{R}^{n}$。共轭梯度法生成迭代值 $\\{x_k\\}$、残差 $\\{r_k\\}$ 和搜索方向 $\\{p_k\\}$，这些量依赖于通过内积和二次型计算出的标量系数 $\\alpha_k$ 和 $\\beta_k$。在有限精度算术中，这些计算会受到舍入误差的影响。你的任务是：\n\n1. 从标准浮点模型 $ \\mathrm{fl}(a \\,\\mathrm{op}\\, b) = (a \\,\\mathrm{op}\\, b)(1 + \\delta) $（其中对于每个基本运算，都有 $|\\delta| \\le u$，$u$ 是单位舍入）出发，推导计算标量 \n   $$\\alpha_k = \\frac{ r_k^T r_k }{ p_k^T A p_k } \\quad \\text{和} \\quad \\beta_k = \\frac{ r_{k+1}^T r_{k+1} }{ r_k^T r_k }$$ \n   时的相对舍入误差的上界。假设点积是通过对 $n$ 个乘积进行直接求和来计算的，并且矩阵-向量积是通过与 $A$ 的行进行 $n$ 次点积来计算的。使用广为接受的点积和矩阵-向量积中累积舍入误差的界，例如对于一个 $n$ 项和的相对误差，其界的形式为 $ \\gamma_n = \\frac{n u}{1 - n u} $，并推导出仅依赖于 $u$、$n$ 以及相关向量和矩阵的范数的界。除了 $A$ 的对称性和正定性外，不作任何特殊结构假设。为每个标量提供能清晰区分分子和分母计算贡献的界。\n\n2. 根据你得到的界和共轭梯度法的结构，解释 $\\alpha_k$ 和 $\\beta_k$ 中的小相对误差如何破坏搜索方向的 $A$-共轭性和残差的相互正交性，以及为什么这种破坏在实践中会减慢收敛速度。你的解释应明确地将 $\\alpha_k$ 和 $\\beta_k$ 中的误差项与 $ p_{k+1}^T A p_k $ 和 $ r_{k+1}^T r_k $ 的非零值联系起来，并应论证为什么即使相对于 $1$ 而言很小的误差，当 $A$ 的条件数很大时也可能产生可测量的影响。\n\n3. 实现一个程序，构建一个 $n \\times n$ 的对称正定矩阵 $A$ 和一个向量 $b$，然后运行共轭梯度法的两种变体：\n   - 一种未扰动变体，直接使用计算出的 $\\alpha_k$ 和 $\\beta_k$。\n   - 一种扰动变体，在 $\\alpha_k$ 和 $\\beta_k$ 中引入受控的乘性相对误差，形式为 $\\tilde{\\alpha}_k = \\alpha_k (1 + \\delta_{\\alpha,k})$ 和 $\\tilde{\\beta}_k = \\beta_k (1 + \\delta_{\\beta,k})$，其中扰动 $\\delta_{\\alpha,k}$ 和 $\\delta_{\\beta,k}$ 根据下面的测试套件选择。\n\n   通过残差的欧几里得范数来衡量收敛性，并报告对于给定的容差 $\\tau$，达到 $ \\| r_k \\|_2 \\le \\tau \\| b \\|_2 $ 所需的迭代次数。\n\n使用以下测试套件以确保覆盖范围：\n- 测试用例 1（基线，理想情况）：维度 $n = 200$，容差 $\\tau = 10^{-8}$，使用固定的伪随机种子生成确定性向量 $b$，且无扰动，即对所有 $k$ 都有 $\\delta_{\\alpha,k} = 0$ 和 $\\delta_{\\beta,k} = 0$。\n- 测试用例 2（接近单位舍入的边界情况）：与测试用例 1 相同的 $A$、$b$ 和 $\\tau$，但有确定性的小扰动 $\\delta_{\\alpha,k} = \\eta$ 和 $\\delta_{\\beta,k} = \\eta$，其中 $\\eta = 10^{-12}$ 对所有 $k$ 均为常数。\n- 测试用例 3（随机扰动）：相同的 $A$、$b$ 和 $\\tau$，随机的混合符号扰动 $\\delta_{\\alpha,k}$ 和 $\\delta_{\\beta,k}$ 在每次迭代时从 $\\{ -\\eta, +\\eta \\}$ 中独立等概率抽取，其中 $\\eta = 10^{-8}$，并由一个固定的伪随机种子控制符号。\n- 测试用例 4（导致减速的微小偏置扰动）：相同的 $A$、$b$ 和 $\\tau$，确定性的正扰动 $\\delta_{\\alpha,k} = \\eta$ 和 $\\delta_{\\beta,k} = \\eta$，其中 $\\eta = 5 \\times 10^{-4}$ 对所有 $k$ 均为常数。\n\n将 $A$ 构建为大小为 $n$ 的一维狄利克雷拉普拉斯算子，即对角线上为 $2$，第一条次对角线和超对角线上为 $-1$ 的三对角矩阵，该矩阵已知为对称正定。通过使用固定的伪随机种子抽取独立的标准正态分布项来构建 $b$。设置初始猜测值 $x_0 = 0$，并将最大迭代次数限制为 $n$。\n\n你的程序必须生成一行输出，其中包含每个测试用例收敛所需的迭代次数，按上述顺序列出，聚合为一个用方括号括起来的逗号分隔列表，例如 $[i_1,i_2,i_3,i_4]$，其中每个 $i_j$ 是一个整数。不涉及物理单位。不出现角度。不使用百分比；所有量均为无量纲实数。程序必须是自包含的，仅使用指定的库，并且不得需要任何用户输入或文件访问。",
            "solution": "该问题陈述是数值线性代数中一个有效练习，专注于共轭梯度（CG）方法的舍入误差分析。它具有科学依据、提法恰当，并为可复现的计算实验提供了所有必要的参数和条件。\n\n用于求解对称正定（SPD）线性系统 $A x = b$ 的共轭梯度算法初始化为 $x_0 = 0$，$r_0 = b$ 和 $p_0 = r_0$。对于 $k = 0, 1, 2, \\dots$，其迭代如下：\n$$\n\\alpha_k = \\frac{r_k^T r_k}{p_k^T A p_k}\n$$\n$$\nx_{k+1} = x_k + \\alpha_k p_k\n$$\n$$\nr_{k+1} = r_k - \\alpha_k A p_k\n$$\n$$\n\\beta_k = \\frac{r_{k+1}^T r_{k+1}}{r_k^T r_k}\n$$\n$$\np_{k+1} = r_{k+1} + \\beta_k p_k\n$$\n\n### 1. $\\alpha_k$ 和 $\\beta_k$ 的舍入误差界\n\n我们分析在有限精度算术中计算 $\\alpha_k$ 和 $\\beta_k$ 时的误差。我们使用标准浮点算术模型 $\\mathrm{fl}(a \\ \\mathrm{op} \\ b) = (a \\ \\mathrm{op} \\ b)(1 + \\delta)$，其中 $|\\delta| \\le u$，$u$ 是单位舍入。对于一个 $n$ 项和，累积相对误差由 $\\gamma_n = \\frac{nu}{1-nu}$ 界定。令 $\\hat{v}$ 表示向量或标量 $v$ 的计算出的浮点表示。以下分析考虑了从已经计算出的向量 $\\hat{r}_k$、$\\hat{p}_k$ 和 $\\hat{r}_{k+1}$ 计算 $\\alpha_k$ 和 $\\beta_k$ 时产生的误差。\n\n**$\\alpha_k = \\frac{r_k^T r_k}{p_k^T A p_k}$ 的分析**\n\n$\\hat{\\alpha}_k$ 的计算涉及两个点积、一个矩阵-向量积和一个除法。\n\n**分子：** 分子是 $N_k = r_k^T r_k$。其计算值 $\\hat{N}_k = \\mathrm{fl}(\\hat{r}_k^T \\hat{r}_k)$ 涉及一个长度为 $n$ 的内积。点积 $x^T y$ 的舍入误差由 $|\\mathrm{fl}(x^T y) - x^T y| \\le \\gamma_n |x|^T |y|$ 界定。对于 $x=y$，这给出：\n$$\n|\\hat{N}_k - \\hat{r}_k^T \\hat{r}_k| \\le \\gamma_n |\\hat{r}_k|^T |\\hat{r}_k| = \\gamma_n \\|\\hat{r}_k\\|_2^2\n$$\n这可以写成 $\\hat{N}_k = (\\hat{r}_k^T \\hat{r}_k)(1 + \\delta_N)$，其中分子计算的相对误差由 $|\\delta_N| \\le \\gamma_n$ 界定。\n\n**分母：** 分母是 $D_k = p_k^T A p_k$。其计算涉及一个矩阵-向量积，后跟一个点积。\n步骤 1：计算矩阵-向量积 $\\hat{v}_k = \\mathrm{fl}(A \\hat{p}_k)$。误差 $e_v = \\hat{v}_k - A \\hat{p}_k$ 的分量由 $|(e_v)_i| \\le \\gamma_n (|A| |\\hat{p}_k|)_i$ 界定，假设 $A$ 是稠密的。\n步骤 2：计算点积 $\\hat{D}_k = \\mathrm{fl}(\\hat{p}_k^T \\hat{v}_k)$。这会引入其自身的误差。\n关于整个操作的一个标准结果给出了绝对误差的界：\n$$\n|\\hat{D}_k - \\hat{p}_k^T A \\hat{p}_k| \\le \\gamma_n |\\hat{p}_k|^T |A| |\\hat{p}_k| + \\gamma_n |\\hat{p}_k^T \\mathrm{fl}(A \\hat{p}_k)|\n$$\n简化并结合这些误差源，得到一个相对误差 $\\delta_D$，使得 $\\hat{D}_k = (\\hat{p}_k^T A \\hat{p}_k)(1+\\delta_D)$，其界的形式为：\n$$\n|\\delta_D| \\le \\gamma_n \\left(1 + \\frac{|\\hat{p}_k|^T |A| |\\hat{p}_k|}{\\hat{p}_k^T A \\hat{p}_k}\\right)\n$$\n这个界区分了最终点积产生的误差（$\\gamma_n$ 项）和矩阵-向量积产生的误差，后者由涉及矩阵和向量范数的因子缩放。\n\n**$\\alpha_k$ 的总相对误差：** 最终的计算是除法，$\\hat{\\alpha}_k = \\mathrm{fl}(\\hat{N}_k / \\hat{D}_k) = (\\hat{N}_k / \\hat{D}_k)(1 + \\delta_{div})$，其中 $|\\delta_{div}| \\le u$。总相对误差为：\n$$\n\\frac{\\hat{\\alpha}_k - \\alpha_k^{\\mathrm{computed}}}{\\alpha_k^{\\mathrm{computed}}} = \\frac{(1+\\delta_N)(1+\\delta_{div})}{1+\\delta_D} - 1 \\approx \\delta_N - \\delta_D + \\delta_{div}\n$$\n总相对误差的上界约为 $|\\delta_N| + |\\delta_D| + u$。因此，来自分子和分母的贡献界分别为：\n- 分子贡献界：$\\gamma_n$。\n- 分母贡献界：$\\gamma_n \\left(1 + \\frac{|p_k|^T |A| |p_k|}{p_k^T A p_k}\\right)$。\n\n**$\\beta_k = \\frac{r_{k+1}^T r_{k+1}}{r_k^T r_k}$ 的分析**\n\n$\\hat{\\beta}_k$ 的计算是两个点积之比。\n**分子：** $\\hat{N}_{k+1} = \\mathrm{fl}(\\hat{r}_{k+1}^T \\hat{r}_{k+1}) = (\\hat{r}_{k+1}^T \\hat{r}_{k+1})(1 + \\delta_{N,k+1})$，其中 $|\\delta_{N,k+1}| \\le \\gamma_n$。\n**分母：** $\\hat{D}_k = \\mathrm{fl}(\\hat{r}_k^T \\hat{r}_k) = (\\hat{r}_k^T \\hat{r}_k)(1 + \\delta_{D,k})$，其中 $|\\delta_{D,k}| \\le \\gamma_n$。\n\n**$\\beta_k$ 的总相对误差：** 最终的除法得到 $\\hat{\\beta}_k = (\\hat{N}_{k+1} / \\hat{D}_k)(1 + \\delta_{div})$。总相对误差为：\n$$\n\\frac{\\hat{\\beta}_k - \\beta_k^{\\mathrm{computed}}}{\\beta_k^{\\mathrm{computed}}} \\approx \\delta_{N,k+1} - \\delta_{D,k} + \\delta_{div}\n$$\n此相对误差幅值的上界约为 $2\\gamma_n + u$。贡献为：\n- 分子贡献界：$\\gamma_n$。\n- 分母贡献界：$\\gamma_n$。\n\n### 2. 正交性的破坏与收敛性\n\n在精确算术中，CG 方法生成的搜索方向 $\\{p_k\\}$ 是 A-共轭的（对于 $i \\ne j$，有 $p_i^T A p_j = 0$），残差 $\\{r_k\\}$ 是相互正交的（对于 $i \\ne j$，有 $r_i^T r_j = 0$）。这些性质保证了在至多 $n$ 次迭代内收敛。浮点误差会破坏这些性质，可能减慢收敛速度。\n\n搜索方向的更新公式为 $p_{k+1} = r_{k+1} + \\beta_k p_k$。选择 $\\beta_k$ 是为了确保 $p_{k+1}$ 与 $p_k$ 是 A-共轭的。我们来分析 $\\alpha_k$ 和 $\\beta_k$ 中的误差如何破坏这一点。在下文中，令 $\\hat{\\alpha}_k = \\alpha_k^{\\mathrm{true}}(1+\\delta_\\alpha)$ 和 $\\hat{\\beta}_k = \\beta_k^{\\mathrm{true}}(1+\\delta_\\beta)$，其中“true”值表示应用于已计算向量的精确公式，而 $\\delta_\\alpha, \\delta_\\beta$ 是有效相对误差。需要检查的量是 $\\hat{p}_{k+1}^T A \\hat{p}_k$：\n$$\n\\hat{p}_{k+1}^T A \\hat{p}_k = (\\hat{r}_{k+1} + \\hat{\\beta}_k \\hat{p}_k)^T A \\hat{p}_k = \\hat{r}_{k+1}^T A \\hat{p}_k + \\hat{\\beta}_k \\hat{p}_k^T A \\hat{p}_k\n$$\n从残差更新 $\\hat{r}_{k+1} \\approx \\hat{r}_k - \\hat{\\alpha}_k A \\hat{p}_k$，我们有 $A \\hat{p}_k \\approx (\\hat{r}_k - \\hat{r}_{k+1}) / \\hat{\\alpha}_k$。代入此式得到：\n$$\n\\hat{r}_{k+1}^T A \\hat{p}_k \\approx \\frac{1}{\\hat{\\alpha}_k} \\hat{r}_{k+1}^T (\\hat{r}_k - \\hat{r}_{k+1}) = \\frac{1}{\\hat{\\alpha}_k} (\\hat{r}_{k+1}^T \\hat{r}_k - \\|\\hat{r}_{k+1}\\|_2^2)\n$$\n即使在有限精度下，计算出的残差 $\\hat{r}_{k+1}$ 在构造上几乎与 $\\hat{r}_k$ 正交，因此 $\\hat{r}_{k+1}^T \\hat{r}_k \\approx 0$。于是，$\\hat{r}_{k+1}^T A \\hat{p}_k \\approx -\\|\\hat{r}_{k+1}\\|_2^2 / \\hat{\\alpha}_k$。A-共轭性检查变为：\n$$\n\\hat{p}_{k+1}^T A \\hat{p}_k \\approx -\\frac{\\|\\hat{r}_{k+1}\\|_2^2}{\\hat{\\alpha}_k} + \\hat{\\beta}_k \\hat{p}_k^T A \\hat{p}_k\n$$\n用带有误差项的“true”对应项替换 $\\hat{\\alpha}_k$ 和 $\\hat{\\beta}_k$ 的表达式：\n$$\n\\hat{p}_{k+1}^T A \\hat{p}_k \\approx -\\frac{\\|\\hat{r}_{k+1}\\|_2^2}{\\alpha_k^{\\mathrm{true}}(1+\\delta_\\alpha)} + \\beta_k^{\\mathrm{true}}(1+\\delta_\\beta)\\hat{p}_k^T A \\hat{p}_k\n$$\n使用 $\\alpha_k^{\\mathrm{true}} = \\frac{\\|\\hat{r}_k\\|_2^2}{\\hat{p}_k^T A \\hat{p}_k}$ 和 $\\beta_k^{\\mathrm{true}} = \\frac{\\|\\hat{r}_{k+1}\\|_2^2}{\\|\\hat{r}_k\\|_2^2}$：\n$$\n\\hat{p}_{k+1}^T A \\hat{p}_k \\approx -\\frac{\\|\\hat{r}_{k+1}\\|_2^2 (\\hat{p}_k^T A \\hat{p}_k)}{\\|\\hat{r}_k\\|_2^2(1+\\delta_\\alpha)} + \\frac{\\|\\hat{r}_{k+1}\\|_2^2}{\\|\\hat{r}_k\\|_2^2}(1+\\delta_\\beta)\\hat{p}_k^T A \\hat{p}_k\n$$\n提取公因式得到：\n$$\n\\hat{p}_{k+1}^T A \\hat{p}_k \\approx \\frac{\\|\\hat{r}_{k+1}\\|_2^2 \\hat{p}_k^T A \\hat{p}_k}{\\|\\hat{r}_k\\|_2^2} \\left[ -\\frac{1}{1+\\delta_\\alpha} + (1+\\delta_\\beta) \\right]\n$$\n对于小的 $\\delta_\\alpha$，使用近似 $1/(1+\\delta_\\alpha) \\approx 1-\\delta_\\alpha$，这简化为：\n$$\n\\hat{p}_{k+1}^T A \\hat{p}_k \\approx \\frac{\\|\\hat{r}_{k+1}\\|_2^2}{\\alpha_k^{\\mathrm{true}}} (\\delta_\\alpha + \\delta_\\beta)\n$$\n这个结果明确地将 A-共轭性的丧失与 $\\alpha_k$ 和 $\\beta_k$ 中相对误差之和联系起来。当这些误差非零时，新的搜索方向就不再与前一个方向 A-共轭。这种损失会累积，意味着搜索方向失去了作为克雷洛夫子空间的 A-正交基的性质。因此，算法可能会重新引入本应被消除的方向上的误差分量，从而减慢收敛速度。\n\n当条件数 $\\kappa(A) = \\frac{\\lambda_{\\max}(A)}{\\lambda_{\\min}(A)}$ 很大时，CG 的收敛可能会很慢。即使误差 $x-x_k$ 仍然显著，残差的范数也可能变得非常小。在这种情况下，机器精度的固有舍入误差相对于像 $\\|r_k\\|_2^2$ 这样的量可能会变得很大。这使得计算出的 $\\alpha_k$ 和 $\\beta_k$ 的准确性降低，导致更严重的正交性丧失。算法的性能从其理论上的超线性收敛退化为像最速下降法那样慢得多的线性收敛，常常导致停滞或需要远超 $n$ 次迭代才能达到所需的容差。",
            "answer": "```python\nimport numpy as np\n\nclass RandomPerturb:\n    \"\"\"\n    A stateful callable object to generate sequences of random perturbations.\n    \"\"\"\n    def __init__(self, seed, eta):\n        # Use a dedicated RNG for perturbations to isolate its state\n        self.rng = np.random.default_rng(seed)\n        self.eta = eta\n        self.choices = [-self.eta, self.eta]\n\n    def __call__(self, k):\n        # On each call, return a random pair of perturbations. k is unused.\n        delta_alpha = self.rng.choice(self.choices)\n        delta_beta = self.rng.choice(self.choices)\n        return delta_alpha, delta_beta\n\ndef conjugate_gradient(A, b, tau, max_iter, pert_gen_func):\n    \"\"\"\n    Implements the Conjugate Gradient method for solving Ax=b.\n\n    Args:\n        A (np.ndarray): The symmetric positive definite matrix.\n        b (np.ndarray): The right-hand side vector.\n        tau (float): The relative tolerance for convergence.\n        max_iter (int): The maximum number of iterations.\n        pert_gen_func (callable): A function that takes iteration k and returns\n                                  a tuple (delta_alpha, delta_beta) of\n                                  multiplicative relative perturbations.\n    Returns:\n        int: The number of iterations required to converge.\n    \"\"\"\n    n = A.shape[0]\n    x = np.zeros(n)\n    \n    # Initialize CG algorithm with x_0 = 0\n    r = b.copy()  # r_0 = b - A@x_0 = b\n    p = r.copy()  # p_0 = r_0\n    \n    rs_old_sq = r.T @ r\n    \n    b_norm = np.linalg.norm(b)\n    convergence_threshold = tau * b_norm\n\n    for k in range(max_iter):\n        # Check for convergence at the beginning of the iteration\n        if np.sqrt(rs_old_sq) = convergence_threshold:\n            return k\n\n        Ap = A @ p\n        \n        # Standard CG computation for alpha\n        # Note: p.T @ Ap can be near zero if p is close to an eigenvector\n        # associated with a zero eigenvalue, but A is SPD, so this is > 0 for p!=0\n        alpha = rs_old_sq / (p.T @ Ap)\n        \n        # Apply controlled perturbation\n        delta_alpha, delta_beta = pert_gen_func(k)\n        alpha = alpha * (1.0 + delta_alpha)\n\n        # Update solution and residual\n        x = x + alpha * p\n        r = r - alpha * Ap\n        \n        rs_new_sq = r.T @ r\n        \n        # Standard CG computation for beta\n        beta = rs_new_sq / rs_old_sq\n        beta = beta * (1.0 + delta_beta)\n        \n        # Update search direction\n        p = r + beta * p\n        \n        # Prepare for next iteration\n        rs_old_sq = rs_new_sq\n\n    # If max_iter is reached without convergence\n    return max_iter\n\n\ndef solve():\n    \"\"\"\n    Sets up and runs the test suite for the Conjugate Gradient analysis.\n    \"\"\"\n    # Problem parameters\n    n = 200\n    tau = 1.0e-8\n    max_iter = n\n\n    # Construct the 1D Dirichlet Laplacian matrix A\n    A = np.diag(2.0 * np.ones(n)) - np.diag(np.ones(n - 1), 1) - np.diag(np.ones(n - 1), -1)\n\n    # Generate the vector b using a fixed seed for reproducibility\n    b_seed = 42\n    rng_b = np.random.default_rng(b_seed)\n    b = rng_b.standard_normal(n)\n\n    # Define the perturbation generators for each test case\n    test_cases = [\n        # Case 1: Unperturbed (baseline)\n        {'name': 'Unperturbed', 'pert_gen': lambda k: (0.0, 0.0)},\n        \n        # Case 2: Small constant perturbations\n        {'name': 'Small Constant Perturbation', 'pert_gen': lambda k: (1.0e-12, 1.0e-12)},\n        \n        # Case 3: Random mixed-sign perturbations\n        {'name': 'Random Perturbation', 'pert_gen': RandomPerturb(seed=123, eta=1.0e-8)},\n        \n        # Case 4: Larger biased perturbations\n        {'name': 'Biased Perturbation', 'pert_gen': lambda k: (5.0e-4, 5.0e-4)}\n    ]\n\n    iteration_counts = []\n    for case in test_cases:\n        iterations = conjugate_gradient(A, b, tau, max_iter, case['pert_gen'])\n        iteration_counts.append(iterations)\n    \n    # Print the results in the specified format\n    print(f\"[{','.join(map(str, iteration_counts))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        }
    ]
}