## 应用与[交叉](@entry_id:147634)学科联系

在前面的章节中，我们已经详细探讨了 Arnoldi 迭代的基本原理和核心机制，包括其如何构建 [Krylov 子空间](@entry_id:751067)并生成 Arnoldi 分解。这些构成了理解该方法的核心。然而，Arnoldi 迭代的真正威力在于其广泛的适用性和深刻的跨学科联系。它不仅是求解[标准特征值问题](@entry_id:755346)的工具，更是众多计算科学与工程领域中先进算法的基石。

本章旨在超越基础理论，展示 Arnoldi 迭代在不同应用背景下的强大功能、扩展及其与其他学科的融合。我们将探讨该方法如何被改造和应用于解决[线性系统](@entry_id:147850)、[微分方程](@entry_id:264184)、控制理论、网络分析和数据驱动的动力系统等问题。我们的目标不是重复核心概念，而是阐明这些核心概念如何在实际的、往往是跨学科的挑战中发挥作用，从而揭示其作为一种[通用计算](@entry_id:275847)[范式](@entry_id:161181)的深刻价值。

### 先进的[特征值计算](@entry_id:145559)技术

虽然基础的 Arnoldi 迭代善于逼近矩阵谱的“外围”[特征值](@entry_id:154894)（即模最大的[特征值](@entry_id:154894)），但许多科学和工程问题要求我们探测谱的内部。Arnoldi 迭代的框架具有足够的灵活性，可以通过谱变换等技术来精确地“瞄准”我们感兴趣的任何谱区域。

#### 谱变换：位移求逆法

在许多应用中，我们关心的并非模最大的[特征值](@entry_id:154894)，而是那些最接近某个特定复数值 $\sigma$ 的[特征值](@entry_id:154894)。例如，在[结构动力学](@entry_id:172684)中，$\sigma$ 可能对应于一个外部激励频率，而我们希望找到系统的固有频率（[特征值](@entry_id:154894)）是否与其接近，以避免共振。标准的 Arnoldi 迭代无法直接实现这一目标。

一个极其有效的策略是**位移求逆（shift-and-invert）**谱变换。其思想是，我们不对矩阵 $A$ 本身应用 Arnoldi 迭代，而是将其应用于变换后的算子 $T = (A - \sigma I)^{-1}$。矩阵 $A$ 的[特征值](@entry_id:154894) $\lambda$ 与算子 $T$ 的[特征值](@entry_id:154894) $\mu$ 之间存在一个简单的映射关系。若 $(\lambda, x)$ 是 $A$ 的一个特征对，即 $Ax = \lambda x$，则有 $(A - \sigma I)x = (\lambda - \sigma)x$。若 $\lambda \neq \sigma$，两边取逆可得 $(A - \sigma I)^{-1}x = (\lambda - \sigma)^{-1}x$，即 $Tx = \mu x$，其中 $\mu = (\lambda - \sigma)^{-1}$。

这个变换的关键在于，当 $A$ 的[特征值](@entry_id:154894) $\lambda$ 非常接近位移 $\sigma$ 时，对应的 $T$ 的[特征值](@entry_id:154894) $\mu$ 的模 $|\mu| = |\lambda - \sigma|^{-1}$ 将会非常大。由于 Arnoldi 迭代天然地倾向于首先收敛到模最大的[特征值](@entry_id:154894)，因此对 $T$ 应用 Arnoldi 迭代，就能高效地计算出其谱的外围[特征值](@entry_id:154894)。通过反向变换 $\lambda = \sigma + 1/\mu$，这些从 $T$ 得到的 Ritz 值近似 $\theta$ 就可以映射回对 $A$ 在 $\sigma$ 附近[特征值](@entry_id:154894)的精确近似 $\lambda \approx \sigma + 1/\theta$。位移求逆法巧妙地将寻找[内部特征值](@entry_id:750739)的问题转化为了寻找外部[特征值](@entry_id:154894)的问题，极大地扩展了 Arnoldi 迭代的应用范围。

#### 加速收敛：[多项式滤波](@entry_id:753578)

在某些情况下，我们希望将 [Krylov 子空间](@entry_id:751067)“引导”到谱的特定区域，例如包含多个期望[特征值](@entry_id:154894)的区域，而不仅仅是单个最大[特征值](@entry_id:154894)。**[多项式滤波](@entry_id:753578)（Polynomial filtering）**提供了一种实现此目标的优雅方法。其核心思想是，用一个精心选择的起始向量来代替标准的起始向量 $v_1$。

具体而言，我们不从 $v_1 = b/\|b\|_2$ 开始 Arnoldi 迭代，而是从一个经过“滤波”的向量 $v'_1 = p(A)b / \|p(A)b\|_2$ 开始。其中，$p(z)$ 是一个特定的多项式。如果多项式 $p(z)$ 在我们感兴趣的谱区域 $|p(z)|$ 的值较大，而在其他区域的值较小，那么向量 $p(A)b$ 将会放大 $b$ 在与期望[特征值](@entry_id:154894)相关的[特征向量](@entry_id:151813)方向上的分量。因此，以 $p(A)b$ 为起始向量构建的 Krylov 子空间将“富含”期望的谱信息，从而使得 Ritz 值向目标[特征值](@entry_id:154894)的[收敛速度](@entry_id:636873)大大加快。

如何选择多项式 $p(z)$ 呢？一种常见的方法是通过求解一个[最小二乘问题](@entry_id:164198)来构造它。例如，我们可以定义一个[目标函数](@entry_id:267263) $t(\lambda)$，在期望的[特征值](@entry_id:154894)处取值为 $1$，在其他[特征值](@entry_id:154894)处取值为 $0$。然后，我们寻找一个次数为 $d$ 的多项式 $p(z)$，使其在整个谱上最佳逼近 $t(\lambda)$。通过这种方式预处理起始向量，我们可以显著提高 Arnoldi 迭代在[大型特征值问题](@entry_id:141326)中（如[电子结构计算](@entry_id:748901)或[稳定性分析](@entry_id:144077)）的效率和精度。

### 求解大规模[线性系统](@entry_id:147850)

Arnoldi 迭代最重要的应用之一是作为求解大规模非对称[线性方程组](@entry_id:148943) $Ax=b$ 的迭代方法的核心引擎。其中最著名的是**[广义最小残差](@entry_id:637119)方法（GMRES）**。

GMRES 在第 $m$ 步寻找一个近似解 $x_m$，该解位于初始猜测 $x_0$ 平移的 [Krylov 子空间](@entry_id:751067) $x_0 + \mathcal{K}_m(A, r_0)$ 中（其中 $r_0=b-Ax_0$），并使得残差的欧几里得范数 $\|r_m\|_2 = \|b-Ax_m\|_2$ 最小。Arnoldi 迭代在这里扮演了关键角色：它为 $\mathcal{K}_m(A, r_0)$ 提供了一个标准正交基 $V_m$。利用 Arnoldi 分解 $AV_m = V_{m+1}\underline{H}_m$，原始的大规模最小化问题可以转化为一个小的、稠密的 $(m+1) \times m$ 维[最小二乘问题](@entry_id:164198)，该问题可以被高效且稳定地求解。

#### 理解 GMRES 的收敛与停滞

尽管 GMRES 在理论上保证收敛，但其实际行为，尤其是对于[非正规矩阵](@entry_id:752668)（即 $A^H A \neq A A^H$）而言，可能相当复杂。Arnoldi 分解为我们提供了深入理解其行为的窗口。

GMRES 的收敛速度与一系列最小化多项式有关。在第 $m$ 步，其[残差范数](@entry_id:754273)可以表示为 $\|r_m\|_2 = \min_{p \in \Pi_m, p(0)=1} \|p(A)r_0\|_2$，其中 $\Pi_m$ 是所有次数不超过 $m$ 的多项式集合。当 $A$ 为[正规矩阵](@entry_id:185943)时，收敛界可以由其[特征值分布](@entry_id:194746)很好地刻画。然而，对于[非正规矩阵](@entry_id:752668)，仅仅依靠谱信息往往会产生误导。一个更强大的工具是矩阵的**[数值范围](@entry_id:752817)（field of values）** $W(A) = \{x^H A x : \|x\|_2=1\}$。Crouzeix 定理指出，$\|p(A)\|_2 \le C \sup_{z \in W(A)}|p(z)|$ 对所有多项式 $p$ 成立，其中 $C$ 是一个常数（已证明 $C=2$）。这为 GMRES 的收敛性提供了一个不依赖于[特征值](@entry_id:154894)、仅依赖于[数值范围](@entry_id:752817)的界。通过构建特定的[非正规矩阵](@entry_id:752668)，我们可以构造出 GMRES 的收敛曲线几乎“饱和”这个理论界的情形，这深刻地揭示了[非正规性](@entry_id:752585)如何通过影响 Arnoldi 过程来影响 GMRES 的性能。

在实际应用中，由于内存和计算成本的限制，GMRES 通常以**重启动（restarted GMRES）**的形式实现，记作 GMRES($m$)。即每当 [Krylov 子空间](@entry_id:751067)的维数达到 $m$ 时，就将当前的近似解作为新的初始猜测，然后重新开始新一轮的 Arnoldi 迭代。虽然这节省了资源，但也可能导致收敛变慢甚至**停滞（stagnation）**。停滞现象，即[残差范数](@entry_id:754273)在多次重启动后不再下降，可以通过 Arnoldi 分解来精确理解。通过构造一个[循环置换](@entry_id:272913)矩阵，我们可以创建一个系统，使得 GMRES($m$) 在每轮迭代中找到的最优解更新量都为零。在这种情况下，Arnoldi 过程生成的 Hessenberg 矩阵具有特殊结构，导致最小二乘问题的解为[零向量](@entry_id:156189)，从而残差向量在循环之间保持不变。这揭示了重启动破坏了 GMRES 的全局最优性，并且残差多项式在每个循环中都是平凡的 $p_m(z)=1$。

#### 灵活预处理：[FGMRES](@entry_id:749308)

为了加速收敛，GMRES 常常与**[预处理](@entry_id:141204)（preconditioning）**技术结合使用。在标准（右）预处理中，我们求解等价的系统 $(AM^{-1})(Mx)=b$，其中 $M$ 是一个近似于 $A$ 且其逆易于计算的矩阵。这要求我们在整个迭代过程中使用一个固定的[预处理器](@entry_id:753679) $M$。

然而，在许多复杂的多物理场耦合问题中，构造一个在所有阶段都有效的单一[预处理器](@entry_id:753679)可能很困难或不切实际。**灵活的 GMRES（[FGMRES](@entry_id:749308)）**应运而生，它允许预处理器 $M_j$ 在每次迭代 $j$ 中发生变化。这种灵活性是以牺牲标准 Arnoldi 结构的代价换来的。在 [FGMRES](@entry_id:749308) 中，Arnoldi 过程不再为标准的 Krylov 子空间 $\mathcal{K}_k(AM^{-1}, v_1)$ 构建一个单一的正交基。取而代之的是，它构建了两个不同的基：一个由[正交向量](@entry_id:142226) $v_j$ 构成的**测试空间** $\mathcal{W}_k = \text{span}\{v_1, \dots, v_k\}$，以及一个由[预处理](@entry_id:141204)后的向量 $z_j = M_j^{-1}v_j$ 构成的**试验空间** $\mathcal{U}_k = \text{span}\{z_1, \dots, z_k\}$。

这种分离导致了一个**[彼得罗夫-伽辽金](@entry_id:174072)（[Petrov-Galerkin](@entry_id:174072)）**条件，而不是标准的伽辽金（Galerkin）条件。因此，Ritz 值的计算不再是求解[标准特征值问题](@entry_id:755346) $H_k y = \theta y$，而是求解一个**[广义特征值问题](@entry_id:151614)** $(V_k^H A Z_k) y = \theta (V_k^H Z_k) y$。[FGMRES](@entry_id:749308) 的这种结构虽然更复杂，但为设计高度自适应和问题驱动的预处理器（例如，在内循环中使用另一种迭代方法作为[预处理器](@entry_id:753679)）开辟了道路，使其成为求解挑战性[非线性](@entry_id:637147)问题和多尺度问题的强大工具。

### 科学计算与动力系统中的应用

Arnoldi 迭代的应用远不止于[特征值](@entry_id:154894)和线性系统。它是模拟物理和工程系统中时间演化的核心算法，也是从数据中提取动力学模式的有力工具。

#### 逼近矩阵指数函数

形如 $y' = Ay, y(0)=b$ 的[线性常微分方程组](@entry_id:163837)（ODEs）在科学计算中无处不在，其形式解为 $y(t) = \exp(tA)b$。对于大型矩阵 $A$，直接计算[矩阵指数](@entry_id:139347) $\exp(tA)$ 是不可行的。Arnoldi 迭代提供了一种高效计算[矩阵指数](@entry_id:139347)函数作用于向量（即 $\exp(tA)b$）的近似方法。

其基本思想是，在 [Krylov 子空间](@entry_id:751067) $\mathcal{K}_k(A, b)$ 中寻找解的近似。利用 Arnoldi 分解 $AV_k \approx V_k H_k$，我们可以得到近似 $\exp(tA)b \approx \|b\|_2 V_k \exp(tH_k) e_1$。这个近似将原问题转化为计算一个小的 $k \times k$ 矩阵 $H_k$ 的指数，这在计算上是可行的。这种方法的误差可以通过一个与所谓的**$\phi$-函数**（与[矩阵指数](@entry_id:139347)密切相关）相关的可计算指标来估计。基于这个[误差指标](@entry_id:173250)，可以设计出**[自适应算法](@entry_id:142170)**，该算法从一个小的 $k$ 开始，逐步增加 [Krylov 子空间](@entry_id:751067)的维数，直到[误差估计](@entry_id:141578)满足给定的容差为止。这种自适应的 Krylov 方法是现代[科学计算](@entry_id:143987)软件库中求解大型[刚性微分方程](@entry_id:139505)组的标准工具。

#### 模型降阶与控制理论

在控制理论和系统科学中，我们经常遇到由大规模[状态空间模型](@entry_id:137993)描述的**[线性时不变](@entry_id:276287)（LTI）系统**。这些模型由于维度过高，难以进行仿真、控制设计和分析。**[模型降阶](@entry_id:171175)（Model order reduction）**的目标是找到一个低维模型，使其能精确地复现原始高维系统的输入-输出行为。

Arnoldi 迭代是实现这一目标的一种核心技术，因为它具有所谓的**[矩匹配](@entry_id:144382)（moment matching）**特性。对于一个由矩阵三元组 $(A, B, C)$ 定义的 LTI 系统，其输入-输出行为由**马尔可夫参数（Markov parameters）**序列 $m_j = CA^jB$ 决定，这些参数也被称为系统的“矩”。可以证明，通过对 $A$ 和起始块 $B$ 应用块 Arnoldi 迭代产生的低维模型，其马尔可夫参数与原始系统的前 $k$ 个马尔可夫参数完全匹配（其中 $k$ 是迭代步数）。这意味着基于 Arnoldi 的[降阶模型](@entry_id:754172)在初始时刻的脉冲响应与原始系统完全相同。这个性质保证了降阶模型在短时动态响应上的高保真度，使其在[电路仿真](@entry_id:271754)、[结构力学](@entry_id:276699)和[流体动力学](@entry_id:136788)等领域的模型简化中得到了广泛应用。

#### 数据驱动的动力学与 Koopman 算子

在当代数据科学的浪潮下，一个核心挑战是如何从观测到的[时间序列数据](@entry_id:262935)中发现其背后潜在的动力学规律。对于一个由[非线性映射](@entry_id:272931) $x_{k+1} = f(x_k)$ 描述的动力系统，**Koopman 算子**理论提供了一个强大的分析框架，它将非线性动力学转化为一个作用于无穷维观测函数空间上的线性算子。

在实践中，我们可以通过数据来近似这个线性的 Koopman 算子。一种直接的方法是，收集系统状态的时间快照 $\{x_0, x_1, \dots, x_m\}$，并寻找一个矩阵 $A$ 来最小化 $\|X' - AX\|_F^2$，其中 $X = [x_0, \dots, x_{m-1}]$ 和 $X' = [x_1, \dots, x_m]$。这个通过[线性最小二乘法](@entry_id:165427)得到的矩阵 $A$ 可以看作是 Koopman 算子在恒等可观测量上的一个有限维近似。

一旦我们从数据中“学习”到了这个[线性算子](@entry_id:149003) $A$，Arnoldi 迭代就可以被用来分析其谱特性。通过对 $A$ 应用 Arnoldi 迭代，我们可以识别出其主要的[特征值](@entry_id:154894)和特征模态（Ritz 值和 Ritz 向量），这些模态揭示了系统动力学中的主导频率和衰减率。这种“数据驱动的 Krylov 方法”与另一种流行的技术——**动态[模态分解](@entry_id:637725)（Dynamic Mode Decomposition, DMD）**——密切相关。事实上，可以证明，在无噪声的情况下，DMD 计算出的[特征值](@entry_id:154894)与通过 Arnoldi 迭代应用于数据驱动的 Koopman 算子 $A$ 所得到的 Ritz 值在理论上是等价的。这一联系将经典的 [Krylov 子空间方法](@entry_id:144111)与现代数据分析技术紧密地联系在了一起。

### 算法扩展与[性能工程](@entry_id:270797)

除了上述应用，Arnoldi 迭代本身也可以被扩展和优化，以适应更复杂的场景或提升计算性能。

#### 块 Arnoldi 方法

标准的 Arnoldi 迭代从单个向量开始。然而，在许多应用中，例如求解具有多个右端项的线性系统或寻找[特征值](@entry_id:154894)的[重数](@entry_id:136466)时，同时处理一组向量会更有效。**块 Arnoldi 方法（Block Arnoldi method）**正是为此目的而设计的。它将标量操作推广到块操作，从一个由 $s$ 个向量组成的初始块 $V_1 \in \mathbb{R}^{n \times s}$ 开始，生成一系列正交块 $V_1, V_2, \dots$，其列的并集构成了对**块 [Krylov 子空间](@entry_id:751067)** $\mathcal{K}_m(A, V_1) = \text{span}\{V_1, AV_1, \dots, A^{m-1}V_1\}$ 的标准正交基。其结果是一个块上 Hessenberg 矩阵，其[特征值](@entry_id:154894)同样可以作为 $A$ 的[特征值](@entry_id:154894)的近似。

在实际应用中，块 Arnoldi 方法面临一个独特的挑战：在迭代过程中，块内的向量可能会变得[线性相关](@entry_id:185830)或近似线性相关。这种情况被称为**块内[秩亏](@entry_id:754065)（rank deficiency）**。例如，如果初始块 $B = [b_1, \dots, b_p]$ 的列本身就几乎是共线的，那么直接对其进行[正交化](@entry_id:149208)就会出现问题。一个健壮的块 Arnoldi 算法必须能够检测并处理这种[秩亏](@entry_id:754065)。这通常通过在每一步对候选块进行[奇异值分解](@entry_id:138057)（SVD）来实现。小于给定容差的奇异值所对应的方向被认为是数值上冗余的，并被**剔除（deflation）**。通过这种自适应的剔除策略，算法可以保持基的良好数值性质，并只在有意义的方向上扩展[子空间](@entry_id:150286)。

块方法的一个特别强大的应用场景是处理具有**张量结构**的问题。例如，当一个线性算子 $A$ 是由两个较小矩阵 $B$ 和 $C$ 的 [Kronecker 和](@entry_id:182294)定义时（$A = I \otimes B + C \otimes I$），它天然地作用于向量化的矩阵上。在这种情况下，使用块 Arnoldi 方法，其中每个块的向量被重新组织成一个矩阵，可以更自然地利用这种结构。研究表明，通过选择合适的块结构，块 Arnoldi 方法可以比标量 Arnoldi 方法更有效地捕获由 $B$ 和 $C$ 的[特征向量](@entry_id:151813)张量积构成的可分离[不变子空间](@entry_id:152829)。这使得块方法在求解源于[偏微分方程](@entry_id:141332)在规则网格上离散化等问题的特征值问题时，具有显著的优势。

#### 计算成本与优化

Arnoldi 迭代的计算成本主要由两部分组成：矩阵-向量乘积（mat-vecs）和向量正交化（Gram-Schmidt 过程）。在标准实现中，每一步的 mat-vec 成本为 $\mathcal{O}(n^2)$ 或由 $A$ 的稀疏度决定，而第 $j$ 步的[正交化](@entry_id:149208)成本为 $\mathcal{O}(nj)$。

然而，在某些应用中，矩阵-向量乘积的成本可以被显著降低。一个典型的例子是当 $A$ 是一个**托普利兹（Toeplitz）**矩阵时。利用[快速傅里叶变换](@entry_id:143432)（FFT），托普利兹矩阵与向量的乘积可以在 $\mathcal{O}(n \log n)$ 的时间内完成，远快于通常的 $\mathcal{O}(n^2)$。在这种情况下，随着 Krylov 子空间维数 $k$ 的增长，总的[正交化](@entry_id:149208)成本（约为 $\mathcal{O}(nk^2)$）将迅速超过总的 mat-vec 成本（约为 $\mathcal{O}(k n \log n)$）。[正交化](@entry_id:149208)从次要开销变为了计算瓶颈。这种成本结构的转变为[性能优化](@entry_id:753341)提供了新的视角。我们可以通过建立一个[计算成本模型](@entry_id:747607)来分析 mat-vec 和正交化之间的权衡，并据此提出一个合理的策略来**限制（cap）** Krylov 子空间的维数 $k$。例如，我们可以选择一个 $k_{\text{cap}}$，使得一步正交化的成本约等于一次快速 mat-vec 的成本，从而在每次迭代的成本构成之间取得平衡。这对于设计在特定硬件和问题结构下最优的迭代方法至关重要。

#### 参数[延拓问题](@entry_id:150521)

在许多现代科学与工程应用中，我们面临的是**参数化问题**，即矩阵 $A(\mu)$ 依赖于一个或多个参数 $\mu$。一个常见的任务是追踪当参数 $\mu$ 变化时，某些[特征值](@entry_id:154894)或[不变子空间](@entry_id:152829)是如何演变的。一个朴素的方法是在每个参数点 $\mu_i$ 都从头开始运行一次完整的 Arnoldi 迭代，但这在计算上是极其浪费的。

一个更智能的策略是**参数延拓（parameter continuation）**，即尝试重用在参数点 $\mu$ 计算得到的 Krylov 子空间信息来加速在邻近点 $\mu + \Delta\mu$ 的计算。关键问题在于：我们如何判断在 $\mu$ 处生成的[子空间](@entry_id:150286) $\text{span}(Q_k(\mu))$ 对于 $\mu+\Delta\mu$ 仍然是一个“好的”近似[子空间](@entry_id:150286)？我们可以设计一些量化指标来回答这个问题。例如，我们可以计算两个[子空间](@entry_id:150286)之间的**最大主夹角（principal angle）**来衡量它们的几何相似度。同时，我们也可以比较它们各自的 Ritz 值谱，通过计算一个**谱漂移（spectral drift）**指标来衡量谱的变化程度。通过设定合理的阈值，我们可以建立一个决策规则：如果[子空间](@entry_id:150286)夹角和谱漂移都足够小，我们就重用或更新旧的[子空间](@entry_id:150286)；否则，我们就放弃旧信息，完全重新启动 Arnoldi 迭代。这种自适应策略在[不确定性量化](@entry_id:138597)、优化和[分岔分析](@entry_id:199661)等领域中扮演着核心角色。

### [交叉](@entry_id:147634)学科连接：[网络分析](@entry_id:139553)与 PageRank

Arnoldi 迭代最著名和最引人注目的跨学科应用之一无疑是在**[网络科学](@entry_id:139925)**领域，特别是用于计算谷歌的 **PageRank** 算法。[PageRank](@entry_id:139603) 的核心是为万维网中的每个页面分配一个重要性得分，这个得分对应于一个巨大马尔可夫链的[平稳分布](@entry_id:194199)。在数学上，这等价于寻找一个矩阵（称为[谷歌矩阵](@entry_id:156135) $G$）的模为 $1$ 的[主特征向量](@entry_id:264358)。

[谷歌矩阵](@entry_id:156135) $G$ 的规模是万维网页面的数量，可达数百亿甚至更多，因此直接求解特征问题是不可想象的。标准的 PageRank 算法使用**幂法（power iteration）**，即反复将矩阵 $G^T$ 乘以一个初始向量。[幂法的收敛速度](@entry_id:753655)由 $G^T$ 的次主导[特征值](@entry_id:154894) $\lambda_2$ 的模决定，具体来说，收敛因子为 $|\lambda_2|/|\lambda_1| = |\lambda_2|$（因为[主特征值](@entry_id:142677) $\lambda_1=1$）。

然而，Arnoldi 迭代提供了一种更强大的替代方案。通过对 $G^T$ 应用 Arnoldi 迭代，我们可以构建一个小的 Hessenberg 矩阵 $H_m$，其[特征值](@entry_id:154894)（Ritz 值）能很好地逼近 $G^T$ 的主导[特征值](@entry_id:154894)。特别是，最接近 $1$ 的 Ritz 值所对应的 Ritz 向量，为 PageRank 向量提供了一个高质量的近似。与幂法相比，Arnoldi 方法通常能以更少的矩阵-向量乘积获得更高精度的结果，因为它在整个 [Krylov 子空间](@entry_id:751067)中寻找最优近似，而不仅仅是依赖于序列的最后一项。此外，对 Arnoldi 生成的 $H_m$ 的谱分析，还能提供对次主导[特征值](@entry_id:154894) $|\lambda_2|$ 的估计，从而能够预测[幂法的收敛速度](@entry_id:753655)。对于具有显著[非正规性](@entry_id:752585)的网络（这在真实网络中很常见），[幂法](@entry_id:148021)可能会经历漫长的“预渐近”收敛阶段，而 Arnoldi 方法通常能更稳健地处理这种情况。