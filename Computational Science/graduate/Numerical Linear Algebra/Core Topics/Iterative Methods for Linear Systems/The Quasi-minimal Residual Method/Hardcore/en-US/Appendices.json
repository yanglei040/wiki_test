{
    "hands_on_practices": [
        {
            "introduction": "The practical utility of any iterative algorithm is fundamentally tied to its computational cost. This first exercise provides a practical lesson in algorithmic analysis by asking you to perform a \"cost accounting\" for the bi-Lanczos process, the engine at the heart of QMR. By calculating the floating-point operations (flops) and memory requirements per iteration, you will develop the essential skill of evaluating the efficiency of numerical methods .",
            "id": "3594292",
            "problem": "Consider the Quasi-Minimal Residual (QMR) method for solving a linear system with a real, nonsymmetric sparse matrix $A \\in \\mathbb{R}^{n \\times n}$. The bi-Lanczos process simultaneously builds right and left Krylov bases $V_{k}$ and $W_{k}$ such that the $(k+1)$-st step extends $V_{k}$ to $V_{k+1}$ and $W_{k}$ to $W_{k+1}$ using short three-term recurrences. Assume the following per-iteration work model for this single bi-Lanczos extension step:\n- Exactly one sparse matrix-vector multiplication with $A$ and one with $A^{\\mathsf{T}}$ occur per iteration.\n- A fixed number of inner products is performed per iteration, namely $s=4$ inner products of vectors in $\\mathbb{R}^{n}$.\n- A fixed number of axpy-like vector updates is performed per iteration, namely $t=6$ updates of the form $x \\leftarrow x + \\alpha y$, each with vectors in $\\mathbb{R}^{n}$.\n- A fixed number of vector scalings is performed per iteration, namely $u=2$ operations of the form $x \\leftarrow \\alpha x$.\n\nAdopt the standard operation cost model:\n- A sparse matrix-vector multiplication with a matrix having $m$ nonzero entries costs $2m$ floating-point operations (flops).\n- A length-$n$ inner product costs $2n$ flops.\n- A length-$n$ axpy costs $2n$ flops.\n- A length-$n$ scaling costs $n$ flops.\n\nFor storage, assume that every newly generated basis vector is stored explicitly and that, in addition to the vectors $v_{k+1}$ and $w_{k+1}$, exactly three scalar recurrence coefficients are stored per iteration.\n\nUnder these assumptions, compute:\n1. The exact per-iteration floating-point operation count $F(n,m)$ required to extend $V_{k}$ to $V_{k+1}$ and $W_{k}$ to $W_{k+1}$.\n2. The incremental storage $S(n)$, in number of scalars, required when these new basis vectors and scalar coefficients are added.\n\nExpress your final answer as the row matrix $\\begin{pmatrix} F(n,m) & S(n) \\end{pmatrix}$, with both entries given as closed-form expressions in terms of $n$ and $m$.",
            "solution": "The problem requires the computation of two quantities for a single iteration of the bi-Lanczos process within the Quasi-Minimal Residual (QMR) method: the total floating-point operation (flop) count, denoted by $F(n,m)$, and the incremental storage requirement, denoted by $S(n)$. The problem provides a precise model for the number of operations per iteration and their respective costs, as well as the components to be stored.\n\nFirst, we will calculate the per-iteration flop count, $F(n,m)$. This is the sum of the flops required for all specified operations within one iteration. The problem details the following operations and their costs for a sparse matrix $A \\in \\mathbb{R}^{n \\times n}$ with $m$ nonzero entries:\n\n1.  **Matrix-Vector Multiplications**: The problem states that there is exactly one sparse matrix-vector multiplication with $A$ and one with its transpose, $A^{\\mathsf{T}}$. The matrix $A^{\\mathsf{T}}$ has the same number of nonzero entries, $m$, as $A$. The cost for a single such operation is given as $2m$ flops.\n    The total cost from matrix-vector multiplications per iteration is:\n    $$ \\text{Cost}_{\\text{matvec}} = (\\text{cost for } A) + (\\text{cost for } A^{\\mathsf{T}}) = 2m + 2m = 4m \\text{ flops.} $$\n\n2.  **Inner Products**: The problem specifies that $s=4$ inner products are performed per iteration. Each inner product involves vectors of length $n$. The cost for one length-$n$ inner product is given as $2n$ flops.\n    The total cost from inner products per iteration is:\n    $$ \\text{Cost}_{\\text{inner}} = s \\times (2n) = 4 \\times 2n = 8n \\text{ flops.} $$\n\n3.  **AXPY-like Vector Updates**: The problem states that $t=6$ updates of the form $x \\leftarrow x + \\alpha y$ (axpy) are performed. These updates involve vectors in $\\mathbb{R}^{n}$. The cost for one length-$n$ axpy operation is given as $2n$ flops.\n    The total cost from axpy updates per iteration is:\n    $$ \\text{Cost}_{\\text{axpy}} = t \\times (2n) = 6 \\times 2n = 12n \\text{ flops.} $$\n\n4.  **Vector Scalings**: The problem specifies that $u=2$ vector scalings of the form $x \\leftarrow \\alpha x$ are performed. These involve vectors of length $n$. The cost for one length-$n$ scaling operation is given as $n$ flops.\n    The total cost from vector scalings per iteration is:\n    $$ \\text{Cost}_{\\text{scale}} = u \\times n = 2 \\times n = 2n \\text{ flops.} $$\n\nThe total per-iteration flop count, $F(n,m)$, is the sum of these individual costs:\n$$ F(n,m) = \\text{Cost}_{\\text{matvec}} + \\text{Cost}_{\\text{inner}} + \\text{Cost}_{\\text{axpy}} + \\text{Cost}_{\\text{scale}} $$\n$$ F(n,m) = 4m + 8n + 12n + 2n $$\n$$ F(n,m) = 4m + 22n $$\n\nNext, we will calculate the incremental storage per iteration, $S(n)$. This is the total number of new scalar values that must be stored. The problem specifies the following storage requirements:\n\n1.  **New Basis Vectors**: At each step, the process generates and stores two new basis vectors, $v_{k+1}$ and $w_{k+1}$. Both vectors are in $\\mathbb{R}^{n}$. Storing one vector of length $n$ requires storing $n$ scalar values.\n    The storage for the two new basis vectors is:\n    $$ \\text{Storage}_{\\text{vectors}} = (\\text{storage for } v_{k+1}) + (\\text{storage for } w_{k+1}) = n + n = 2n \\text{ scalars.} $$\n\n2.  **Scalar Recurrence Coefficients**: The problem states that exactly three scalar recurrence coefficients are stored per iteration.\n    The storage for these coefficients is:\n    $$ \\text{Storage}_{\\text{coeffs}} = 3 \\text{ scalars.} $$\n\nThe total incremental storage, $S(n)$, is the sum of these components:\n$$ S(n) = \\text{Storage}_{\\text{vectors}} + \\text{Storage}_{\\text{coeffs}} $$\n$$ S(n) = 2n + 3 $$\n\nThe problem asks for the final answer to be presented as the row matrix $\\begin{pmatrix} F(n,m) & S(n) \\end{pmatrix}$. Substituting the derived expressions for $F(n,m)$ and $S(n)$, we obtain the final result.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 4m + 22n & 2n + 3 \\end{pmatrix} } $$"
        },
        {
            "introduction": "While computational cost is important, robustness is paramount; an algorithm is useless if it fails to produce a solution. This practice explores a critical failure mode known as \"breakdown,\" where the underlying bi-Lanczos process can collapse, causing methods like the Biconjugate Gradient (BiCG) to terminate prematurely. By deriving the precise algebraic condition that triggers a breakdown in a specific scenario, you will gain a deeper appreciation for the numerical stability issues that motivated the design of more resilient solvers like QMR .",
            "id": "3594335",
            "problem": "Consider the biorthogonal Lanczos process that underlies Biconjugate Gradient (BiCG) and Quasi-Minimal Residual (QMR) for solving a nonsymmetric linear system in numerical linear algebra. Let $A \\in \\mathbb{R}^{3 \\times 3}$ be a nonsymmetric tridiagonal Toeplitz matrix with constant subdiagonal, diagonal, and superdiagonal entries given by $s$, $m$, and $t$, respectively:\n$$\nA \\;=\\;\n\\begin{pmatrix}\nm & t & 0 \\\\\ns & m & t \\\\\n0 & s & m\n\\end{pmatrix}.\n$$\nLet the initial guess be $x_0 = \\mathbf{0}$ and the right-hand side be $b = \\mathbf{e}_1$, so the initial residual is $r_0 = b - A x_0 = \\mathbf{e}_1$. Choose the shadow residual $r_0^\\sharp = \\mathbf{e}_1$. Define the first right and left Lanczos vectors by $v_1 = r_0$ and $w_1 = r_0^\\sharp$. For the first Lanczos step, define the scalar\n$$\n\\alpha_1 \\;=\\; \\frac{w_1^{T} A v_1}{w_1^{T} v_1}.\n$$\nThen form the second right and left Lanczos vectors by\n$$\nv_2 \\;=\\; A v_1 \\;-\\; \\alpha_1 v_1, \n\\qquad\nw_2 \\;=\\; A^{T} w_1 \\;-\\; \\alpha_1 w_1.\n$$\nBiCG experiences a true breakdown at iteration $j=2$ if $w_2^{T} v_2 = 0$, while QMR with look-ahead can continue by skipping the offending step. Using only these definitions and the given data, derive the closed-form expression of $w_2^{T} v_2$ in terms of the subdiagonal and superdiagonal parameters $s$ and $t$. Based on this expression, the parameter regimes on $s$ and $t$ that trigger ($w_2^{T} v_2 = 0$) and avoid ($w_2^{T} v_2 \\neq 0$) BiCG breakdown at $j=2$ follow immediately, and QMR with look-ahead is applicable in the former case.\n\nProvide your final answer as the exact algebraic expression for $w_2^{T} v_2$ in terms of $s$ and $t$.",
            "solution": "The problem statement has been validated as scientifically grounded, well-posed, and objective. It provides a self-contained and consistent setup for a standard problem in numerical linear algebra. All definitions and procedures are standard for the analysis of the biorthogonal Lanczos process, which underlies the Biconjugate Gradient (BiCG) and Quasi-Minimal Residual (QMR) methods. The problem is therefore deemed valid, and a solution is derived as follows.\n\nThe objective is to compute the scalar quantity $w_2^{T} v_2$, which determines if a breakdown occurs at the second step of the BiCG algorithm. The derivation proceeds by systematically calculating all intermediate quantities based on the provided givens.\n\nThe matrix $A \\in \\mathbb{R}^{3 \\times 3}$ is given by:\n$$\nA \\;=\\;\n\\begin{pmatrix}\nm & t & 0 \\\\\ns & m & t \\\\\n0 & s & m\n\\end{pmatrix}\n$$\nThe right-hand side vector is $b = \\mathbf{e}_1$, and the initial guess is $x_0 = \\mathbf{0}$. The initial residual is $r_0 = b - Ax_0 = \\mathbf{e}_1 - A\\mathbf{0} = \\mathbf{e}_1$.\nThe initial shadow residual is chosen as $r_0^\\sharp = \\mathbf{e}_1$.\n\nThe first right and left Lanczos vectors are defined from these residuals:\n$$\nv_1 = r_0 = \\mathbf{e}_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n$$\nw_1 = r_0^\\sharp = \\mathbf{e}_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThe first step is to compute the scalar $\\alpha_1$:\n$$\n\\alpha_1 \\;=\\; \\frac{w_1^{T} A v_1}{w_1^{T} v_1}\n$$\nWe first evaluate the denominator, $w_1^{T} v_1$:\n$$\nw_1^{T} v_1 = \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = 1\n$$\nSince $w_1^{T} v_1 \\neq 0$, the process can continue.\n\nNext, we evaluate the numerator, $w_1^{T} A v_1$. We first compute the matrix-vector product $A v_1$:\n$$\nA v_1 = \\begin{pmatrix} m & t & 0 \\\\ s & m & t \\\\ 0 & s & m \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} m \\\\ s \\\\ 0 \\end{pmatrix}\n$$\nNow, we can compute the numerator:\n$$\nw_1^{T} (A v_1) = \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} m \\\\ s \\\\ 0 \\end{pmatrix} = m\n$$\nUsing these results, we find $\\alpha_1$:\n$$\n\\alpha_1 = \\frac{m}{1} = m\n$$\nThe next step is to form the second right Lanczos vector, $v_2$:\n$$\nv_2 = A v_1 - \\alpha_1 v_1\n$$\nSubstituting the quantities we have already computed:\n$$\nv_2 = \\begin{pmatrix} m \\\\ s \\\\ 0 \\end{pmatrix} - m \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} m \\\\ s \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} m \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ s \\\\ 0 \\end{pmatrix}\n$$\nSimilarly, we form the second left Lanczos vector, $w_2$:\n$$\nw_2 = A^{T} w_1 - \\alpha_1 w_1\n$$\nFirst, we find the transpose of $A$, denoted $A^T$:\n$$\nA^{T} = \\begin{pmatrix} m & s & 0 \\\\ t & m & s \\\\ 0 & t & m \\end{pmatrix}\n$$\nNext, we compute the matrix-vector product $A^T w_1$:\n$$\nA^{T} w_1 = \\begin{pmatrix} m & s & 0 \\\\ t & m & s \\\\ 0 & t & m \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} m \\\\ t \\\\ 0 \\end{pmatrix}\n$$\nNow, we can compute $w_2$:\n$$\nw_2 = \\begin{pmatrix} m \\\\ t \\\\ 0 \\end{pmatrix} - m \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} m \\\\ t \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} m \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ t \\\\ 0 \\end{pmatrix}\n$$\nFinally, we compute the quantity $w_2^{T} v_2$, which is the inner product of the second left and right Lanczos vectors. A true breakdown in BiCG occurs if this quantity is zero.\n$$\nw_2^{T} v_2 = \\begin{pmatrix} 0 & t & 0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ s \\\\ 0 \\end{pmatrix} = (0)(0) + (t)(s) + (0)(0) = st\n$$\nThe expression for $w_2^{T} v_2$ is $st$. This result shows that a breakdown at the second step occurs if and only if $st = 0$, which means either the subdiagonal element $s$ or the superdiagonal element $t$ is zero. In such cases, the tridiagonal matrix $A$ would become triangular. The diagonal element $m$ does not influence this particular breakdown condition.",
            "answer": "$$\\boxed{st}$$"
        },
        {
            "introduction": "For many real-world problems, a \"raw\" iterative solver converges too slowly to be practical. Preconditioning is the most powerful technique for accelerating convergence, and this exercise introduces the three primary strategies: left, right, and split preconditioning. You will derive the transformed operators for each approach and compute their initial behavior, building a foundational understanding of how to tailor the QMR method for high-performance applications .",
            "id": "3594301",
            "problem": "Consider solving the nonsymmetric linear system $A x = b$ using the Quasi-Minimal Residual (QMR) method, where QMR stands for Quasi-Minimal Residual. Let $M$ be a nonsingular preconditioner. The QMR method is built atop the bi-Lanczos process applied to the system operator and its adjoint with respect to the Euclidean inner product.\n\nTask 1 (derivation): Starting from the definitions of left preconditioning, right preconditioning, and split preconditioning, derive the corresponding operators and the adjoint operators that enter the bi-Lanczos process:\n- Left preconditioning: the transformed system is $M^{-1} A x = M^{-1} b$.\n- Right preconditioning: the transformed system is $A M^{-1} y = b$ with $x = M^{-1} y$.\n- Split preconditioning: the transformed system is $M^{-1} A M^{-1} y = M^{-1} b$ with $x = M^{-1} y$.\n\nFor each case, denote the transformed operator by $T$ and derive its adjoint $T^{\\ast}$ with respect to the standard Euclidean inner product, expressed only in terms of $A$, $A^{\\ast}$, $M$, and $M^{\\ast}$. State clearly how the bi-Lanczos pairs $\\{v_k\\}$ and $\\{w_k\\}$ are advanced, i.e., that the forward sequence is driven by $T$ and the backward (shadow) sequence is driven by $T^{\\ast}$, and specify the biorthonormality condition on the starting vectors $(w_1, v_1) = 1$.\n\nTask 2 (initialization and computation): For each preconditioning, initialize the bi-Lanczos process from the corresponding residual as follows:\n- Left and split preconditioning: use $r_0^{(L)} = M^{-1} b$ and $r_0^{(S)} = M^{-1} b$ as the initial residuals in the transformed space. Set $v_1^{(L)} = r_0^{(L)} / \\|r_0^{(L)}\\|_2$ and $v_1^{(S)} = r_0^{(S)} / \\|r_0^{(S)}\\|_2$, and choose $w_1^{(L)} = v_1^{(L)}$ and $w_1^{(S)} = v_1^{(S)}$ so that $(w_1^{(\\cdot)}, v_1^{(\\cdot)}) = 1$.\n- Right preconditioning: use $r_0^{(R)} = b$ as the initial residual in the transformed space. Set $v_1^{(R)} = r_0^{(R)} / \\|r_0^{(R)}\\|_2$ and choose $w_1^{(R)} = v_1^{(R)}$ so that $(w_1^{(R)}, v_1^{(R)}) = 1$.\n\nIn each case, define the first bi-Lanczos diagonal coefficient $\\alpha_1$ by $\\alpha_1 = (w_1, T v_1)$, where $T$ is the transformed operator for that preconditioning.\n\nTask 3 (numerical evaluation): For the specific data\n$$\nA = \\begin{pmatrix} 4 & 1 \\\\ 0 & 2 \\end{pmatrix}, \\quad\nM = \\begin{pmatrix} 2 & 0 \\\\ 0 & 3 \\end{pmatrix}, \\quad\nb = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix},\n$$\ncarry out Task 2 concretely to compute the three values $\\alpha_1^{(L)}$, $\\alpha_1^{(R)}$, and $\\alpha_1^{(S)}$ corresponding to left, right, and split preconditioning respectively. Then form the scalar\n$$\nS \\;=\\; \\alpha_1^{(L)} \\;+\\; \\alpha_1^{(R)} \\;+\\; \\alpha_1^{(S)}.\n$$\n\nAnswer specification:\n- Your final answer must be the exact value of $S$ as a single reduced rational number.\n- No units are involved.",
            "solution": "The problem is first validated to ensure it is self-contained, scientifically grounded, and well-posed.\n\n### Step 1: Extract Givens\n- **Task**: Solve $A x = b$ using the Quasi-Minimal Residual (QMR) method.\n- **System**: $A$ is a nonsymmetric matrix, $M$ is a nonsingular preconditioner.\n- **Inner Product**: The adjoint is defined with respect to the standard Euclidean inner product, which for real vectors $u, v$ is $(u,v) = v^T u$.\n- **Preconditioning Schemes**:\n    - Left: $M^{-1} A x = M^{-1} b$.\n    - Right: $A M^{-1} y = b$, where $x = M^{-1} y$.\n    - Split: $M^{-1} A M^{-1} y = M^{-1} b$, where $x = M^{-1} y$.\n- **Operator Definitions**:\n    - $T$: The transformed operator for each scheme.\n    - $T^{\\ast}$: The adjoint of $T$.\n- **Bi-Lanczos Process**: The sequence $\\{v_k\\}$ is driven by $T$, and $\\{w_k\\}$ is driven by $T^{\\ast}$.\n- **Initial Conditions**:\n    - The starting vectors must satisfy $(w_1, v_1) = 1$.\n    - For left and split preconditioning: $r_0 = M^{-1} b$, $v_1 = r_0 / \\|r_0\\|_2$, $w_1 = v_1$.\n    - For right preconditioning: $r_0 = b$, $v_1 = r_0 / \\|r_0\\|_2$, $w_1 = v_1$.\n- **Coefficient $\\alpha_1$**: $\\alpha_1 = (w_1, T v_1)$.\n- **Numerical Data**:\n    - $A = \\begin{pmatrix} 4 & 1 \\\\ 0 & 2 \\end{pmatrix}$\n    - $M = \\begin{pmatrix} 2 & 0 \\\\ 0 & 3 \\end{pmatrix}$\n    - $b = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}$\n- **Final Quantity**: $S = \\alpha_1^{(L)} + \\alpha_1^{(R)} + \\alpha_1^{(S)}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-defined, mathematically sound, and provides all necessary information for a unique solution. It is a standard problem in the field of numerical linear algebra. The concepts of preconditioning, QMR, and the bi-Lanczos process are all standard. The data provided are consistent and allow for direct computation. The problem is valid.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution is provided below.\n\n---\n\nThe solution proceeds in three parts as specified by the problem tasks.\n\n### Task 1: Derivation of Operators\n\nThe adjoint of a matrix operator $T$ with respect to the Euclidean inner product is its conjugate transpose, denoted $T^{\\ast}$. For real matrices, this is the transpose, $T^T$. The problem uses the general notation $A^{\\ast}, M^{\\ast}$, which for the given real matrices correspond to $A^T, M^T$. The adjoint of a product of matrices is the product of their adjoints in reverse order, i.e., $(XY)^{\\ast} = Y^{\\ast}X^{\\ast}$. The adjoint of an inverse is the inverse of the adjoint, i.e., $(X^{-1})^{\\ast} = (X^{\\ast})^{-1}$.\n\n1.  **Left Preconditioning**: The system is $M^{-1} A x = M^{-1} b$.\n    The transformed operator is $T^{(L)} = M^{-1} A$.\n    Its adjoint is $T^{(L)\\ast} = (M^{-1} A)^{\\ast} = A^{\\ast} (M^{-1})^{\\ast} = A^{\\ast} (M^{\\ast})^{-1}$.\n\n2.  **Right Preconditioning**: The system is $A M^{-1} y = b$, with $x = M^{-1} y$.\n    The transformed operator is $T^{(R)} = A M^{-1}$.\n    Its adjoint is $T^{(R)\\ast} = (A M^{-1})^{\\ast} = (M^{-1})^{\\ast} A^{\\ast} = (M^{\\ast})^{-1} A^{\\ast}$.\n\n3.  **Split Preconditioning**: The system is $M^{-1} A M^{-1} y = M^{-1} b$, with $x = M^{-1} y$.\n    The transformed operator is $T^{(S)} = M^{-1} A M^{-1}$.\n    Its adjoint is $T^{(S)\\ast} = (M^{-1} A M^{-1})^{\\ast} = (M^{-1})^{\\ast} A^{\\ast} (M^{-1})^{\\ast} = (M^{\\ast})^{-1} A^{\\ast} (M^{\\ast})^{-1}$.\n\nIn the bi-Lanczos process, the sequence of vectors $\\{v_k\\}$ is generated by applying the operator $T$, and the sequence $\\{w_k\\}$ is generated by applying the adjoint operator $T^{\\ast}$. Specifically, the vectors are generated via three-term recurrences, where $v_{k+1}$ is in the Krylov subspace generated by $T$ on $v_k$, and $w_{k+1}$ is in the Krylov subspace generated by $T^{\\ast}$ on $w_k$. The initial vectors $v_1$ and $w_1$ must satisfy the biorthonormality condition $(w_1, v_1) = w_1^{\\ast}v_1 = 1$.\n\n### Task 2: Initialization and Computation of $\\alpha_1$\n\nThe first diagonal coefficient in the bi-Lanczos process is $\\alpha_1 = (w_1, T v_1)$. The problem specifies setting $w_1 = v_1$. Since $v_1$ is a unit vector, $\\|v_1\\|_2 = 1$, the condition $(w_1, v_1) = (v_1, v_1) = v_1^T v_1 = \\|v_1\\|_2^2 = 1$ is satisfied. With this choice, the formula for $\\alpha_1$ becomes $\\alpha_1 = (v_1, T v_1) = v_1^T T v_1$.\n\n1.  **Left Preconditioning**:\n    $r_0^{(L)} = M^{-1} b$.\n    $v_1^{(L)} = \\frac{r_0^{(L)}}{\\|r_0^{(L)}\\|_2}$.\n    $\\alpha_1^{(L)} = (v_1^{(L)})^T T^{(L)} v_1^{(L)} = \\left(\\frac{r_0^{(L)}}{\\|r_0^{(L)}\\|_2}\\right)^T (M^{-1}A) \\left(\\frac{r_0^{(L)}}{\\|r_0^{(L)}\\|_2}\\right) = \\frac{(r_0^{(L)})^T M^{-1} A r_0^{(L)}}{(r_0^{(L)})^T r_0^{(L)}}$.\n\n2.  **Right Preconditioning**:\n    $r_0^{(R)} = b$.\n    $v_1^{(R)} = \\frac{r_0^{(R)}}{\\|r_0^{(R)}\\|_2} = \\frac{b}{\\|b\\|_2}$.\n    $\\alpha_1^{(R)} = (v_1^{(R)})^T T^{(R)} v_1^{(R)} = \\left(\\frac{b}{\\|b\\|_2}\\right)^T (AM^{-1}) \\left(\\frac{b}{\\|b\\|_2}\\right) = \\frac{b^T A M^{-1} b}{b^T b}$.\n\n3.  **Split Preconditioning**:\n    $r_0^{(S)} = M^{-1} b$.\n    $v_1^{(S)} = \\frac{r_0^{(S)}}{\\|r_0^{(S)}\\|_2}$.\n    $\\alpha_1^{(S)} = (v_1^{(S)})^T T^{(S)} v_1^{(S)} = \\left(\\frac{r_0^{(S)}}{\\|r_0^{(S)}\\|_2}\\right)^T (M^{-1}AM^{-1}) \\left(\\frac{r_0^{(S)}}{\\|r_0^{(S)}\\|_2}\\right) = \\frac{(r_0^{(S)})^T M^{-1} A M^{-1} r_0^{(S)}}{(r_0^{(S)})^T r_0^{(S)}}$.\n\n### Task 3: Numerical Evaluation\n\nWe are given the data:\n$A = \\begin{pmatrix} 4 & 1 \\\\ 0 & 2 \\end{pmatrix}$, $M = \\begin{pmatrix} 2 & 0 \\\\ 0 & 3 \\end{pmatrix}$, $b = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}$.\nFirst, we compute $M^{-1}$:\n$M^{-1} = \\begin{pmatrix} 1/2 & 0 \\\\ 0 & 1/3 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{3} \\end{pmatrix}$.\n\n**Compute $\\alpha_1^{(L)}$**:\nThe initial vector for left preconditioning is $r_0^{(L)} = M^{-1} b = \\begin{pmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\nThe squared norm is $(r_0^{(L)})^T r_0^{(L)} = 1^2 + 1^2 = 2$.\nThe operator is $T^{(L)} = M^{-1}A = \\begin{pmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} 4 & 1 \\\\ 0 & 2 \\end{pmatrix} = \\begin{pmatrix} 2 & \\frac{1}{2} \\\\ 0 & \\frac{2}{3} \\end{pmatrix}$.\nThe numerator is $(r_0^{(L)})^T T^{(L)} r_0^{(L)} = \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\begin{pmatrix} 2 & \\frac{1}{2} \\\\ 0 & \\frac{2}{3} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\begin{pmatrix} 2 + \\frac{1}{2} \\\\ 0 + \\frac{2}{3} \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\begin{pmatrix} \\frac{5}{2} \\\\ \\frac{2}{3} \\end{pmatrix} = \\frac{5}{2} + \\frac{2}{3} = \\frac{15+4}{6} = \\frac{19}{6}$.\nSo, $\\alpha_1^{(L)} = \\frac{19/6}{2} = \\frac{19}{12}$.\n\n**Compute $\\alpha_1^{(R)}$**:\nThe initial vector is $r_0^{(R)} = b = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}$.\nThe squared norm is $b^T b = 2^2 + 3^2 = 4 + 9 = 13$.\nThe operator is $T^{(R)} = AM^{-1} = \\begin{pmatrix} 4 & 1 \\\\ 0 & 2 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{3} \\end{pmatrix} = \\begin{pmatrix} 2 & \\frac{1}{3} \\\\ 0 & \\frac{2}{3} \\end{pmatrix}$.\nThe numerator is $b^T T^{(R)} b = \\begin{pmatrix} 2 & 3 \\end{pmatrix} \\begin{pmatrix} 2 & \\frac{1}{3} \\\\ 0 & \\frac{2}{3} \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 2 & 3 \\end{pmatrix} \\begin{pmatrix} 4 + 1 \\\\ 0 + 2 \\end{pmatrix} = \\begin{pmatrix} 2 & 3 \\end{pmatrix} \\begin{pmatrix} 5 \\\\ 2 \\end{pmatrix} = 10 + 6 = 16$.\nSo, $\\alpha_1^{(R)} = \\frac{16}{13}$.\n\n**Compute $\\alpha_1^{(S)}$**:\nThe initial vector is $r_0^{(S)} = M^{-1} b = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$, which is the same as for left preconditioning. The squared norm is $(r_0^{(S)})^T r_0^{(S)} = 2$.\nThe operator is $T^{(S)} = M^{-1}AM^{-1} = \\begin{pmatrix} 2 & \\frac{1}{2} \\\\ 0 & \\frac{2}{3} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{2} & 0 \\\\ 0 & \\frac{1}{3} \\end{pmatrix} = \\begin{pmatrix} 1 & \\frac{1}{6} \\\\ 0 & \\frac{2}{9} \\end{pmatrix}$.\nThe numerator is $(r_0^{(S)})^T T^{(S)} r_0^{(S)} = \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & \\frac{1}{6} \\\\ 0 & \\frac{2}{9} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\begin{pmatrix} 1 + \\frac{1}{6} \\\\ 0 + \\frac{2}{9} \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\begin{pmatrix} \\frac{7}{6} \\\\ \\frac{2}{9} \\end{pmatrix} = \\frac{7}{6} + \\frac{2}{9} = \\frac{21+4}{18} = \\frac{25}{18}$.\nSo, $\\alpha_1^{(S)} = \\frac{25/18}{2} = \\frac{25}{36}$.\n\n**Compute S**:\nFinally, we compute the sum $S = \\alpha_1^{(L)} + \\alpha_1^{(R)} + \\alpha_1^{(S)}$.\n$S = \\frac{19}{12} + \\frac{16}{13} + \\frac{25}{36}$.\nFirst, combine the terms with denominators $12$ and $36$. The least common multiple is $36$.\n$\\frac{19}{12} = \\frac{19 \\times 3}{12 \\times 3} = \\frac{57}{36}$.\n$\\frac{19}{12} + \\frac{25}{36} = \\frac{57}{36} + \\frac{25}{36} = \\frac{82}{36} = \\frac{41}{18}$.\nNow, add the remaining term:\n$S = \\frac{41}{18} + \\frac{16}{13}$.\nThe least common multiple of $18$ and $13$ is $18 \\times 13 = 234$.\n$S = \\frac{41 \\times 13}{18 \\times 13} + \\frac{16 \\times 18}{13 \\times 18} = \\frac{533}{234} + \\frac{288}{234} = \\frac{533 + 288}{234} = \\frac{821}{234}$.\nTo confirm this is a reduced fraction, we check for common prime factors. The prime factors of the denominator $234 = 2 \\times 117 = 2 \\times 9 \\times 13 = 2 \\times 3^2 \\times 13$ are $2$, $3$, and $13$.\n- The numerator $821$ is not divisible by $2$ as it is odd.\n- The sum of digits of $821$ is $8+2+1=11$, which is not divisible by $3$, so $821$ is not divisible by $3$.\n- Dividing by $13$: $821 = 13 \\times 63 + 2$. So $821$ is not divisible by $13$.\nThe fraction is irreducible.",
            "answer": "$$\\boxed{\\frac{821}{234}}$$"
        }
    ]
}