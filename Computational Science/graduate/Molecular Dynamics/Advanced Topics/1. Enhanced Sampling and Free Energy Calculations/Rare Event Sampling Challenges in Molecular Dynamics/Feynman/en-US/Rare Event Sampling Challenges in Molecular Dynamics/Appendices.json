{
    "hands_on_practices": [
        {
            "introduction": "The cornerstone of chemical rate theory is understanding how a system crosses a potential energy barrier. This foundational exercise guides you through the derivation of the mean first passage time for a particle in a classic double-well potential, a canonical model for a rare event. By solving the backward Fokker-Planck equation in the high-barrier limit, you will derive Kramers' famous rate formula, gaining a deep, first-principles understanding of the Arrhenius factor and the prefactor's dependence on barrier and well curvature .",
            "id": "3440646",
            "problem": "Consider overdamped Langevin dynamics for a single particle in one spatial dimension evolving on the double-well potential $U(x) = a x^{4} - b x^{2}$ with $a>0$ and $b>0$. The equation of motion is\n$$\n\\gamma \\,\\dot{x}(t) \\;=\\; -\\,U'(x) \\;+\\; \\sqrt{2\\,\\gamma\\,k_{B}T}\\,\\eta(t),\n$$\nwhere $\\gamma$ is the friction coefficient, $k_{B}$ is Boltzmann’s constant, $T$ is the absolute temperature, and $\\eta(t)$ is unit-variance white noise with $\\langle \\eta(t)\\eta(t')\\rangle=\\delta(t-t')$. Define the mean first passage time (MFPT) as the expected time to reach the basin of the right well when starting at the left minimum $x_{L}=-\\sqrt{b/(2a)}$. Impose absorbing boundary at the right minimum $x_{R}=+\\sqrt{b/(2a)}$ and reflecting boundary at $x\\to -\\infty$ (which is effectively confining due to $U(x)\\to +\\infty$ as $x\\to -\\infty$). Work in the high-barrier limit where the activation energy $\\Delta U=U(0)-U(x_{L})$ satisfies $\\beta \\,\\Delta U \\gg 1$, with $\\beta = 1/(k_{B}T)$.\n\nStarting only from the Smoluchowski (overdamped Fokker–Planck) description and the backward equation for the MFPT, derive the leading-order asymptotic expression for the MFPT from the left to the right well, including both the Arrhenius factor and the full prefactor in terms of the local curvatures of $U(x)$ at the left minimum and at the barrier top. Then specialize your result to $U(x)=a x^{4}-b x^{2}$ and simplify it to a closed-form analytic expression in terms of $a$, $b$, $\\gamma$, $k_{B}$, and $T$.\n\nExpress your final answer as an analytic expression for the MFPT in seconds. Do not include any units in your boxed final answer. No numerical rounding is required.",
            "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and objective. It presents a standard problem in statistical physics concerning the calculation of a mean first passage time (MFPT) for a particle in a double-well potential, governed by overdamped Langevin dynamics. The derivation of Kramers' rate formula is a canonical exercise in this field.\n\nThe analysis begins with the backward Fokker-Planck equation for the MFPT, $\\tau(x)$, which is the expected time for a particle starting at position $x$ to first reach an absorbing boundary. The overdamped Langevin equation is given by\n$$ \\gamma \\dot{x}(t) = -U'(x) + \\sqrt{2\\gamma k_B T} \\eta(t) $$\nwhere $U'(x)$ is the derivative of the potential $U(x)$, $\\gamma$ is the friction coefficient, $k_B$ is the Boltzmann constant, $T$ is the temperature, and $\\eta(t)$ is Gaussian white noise. This corresponds to a stochastic differential equation with drift $\\mu(x) = -U'(x)/\\gamma$ and diffusion coefficient $D = k_B T / \\gamma$. The backward equation for the MFPT $\\tau(x)$ is a second-order ordinary differential equation given by:\n$$ \\mu(x) \\frac{d\\tau}{dx} + D \\frac{d^2\\tau}{dx^2} = -1 $$\nSubstituting the expressions for $\\mu(x)$ and $D$, we obtain:\n$$ -\\frac{U'(x)}{\\gamma} \\frac{d\\tau}{dx} + \\frac{k_B T}{\\gamma} \\frac{d^2\\tau}{dx^2} = -1 $$\nLet $\\beta = 1/(k_B T)$. The equation can be rewritten as:\n$$ D \\frac{d^2\\tau}{dx^2} - D \\beta U'(x) \\frac{d\\tau}{dx} = -1 $$\nThis problem defines the starting position at the left minimum $x_L = -\\sqrt{b/(2a)}$, an absorbing boundary at the right minimum $x_R = +\\sqrt{b/(2a)}$, and a reflecting boundary as $x \\to -\\infty$. The boundary conditions on $\\tau(x)$ are therefore:\n1. Absorbing boundary at $x_R$: $\\tau(x_R) = 0$.\n2. Reflecting boundary at $x \\to -\\infty$. This condition implies that the probability flux is zero, which for the backward equation translates to $\\lim_{x \\to -\\infty} \\frac{d\\tau}{dx} = 0$.\n\nLet $y(x) = d\\tau/dx$. The equation becomes a first-order linear ODE for $y(x)$:\n$$ \\frac{dy}{dx} - \\beta U'(x) y = -\\frac{1}{D} $$\nThe integrating factor is $\\exp\\left(-\\int \\beta U'(x) dx\\right) = \\exp(-\\beta U(x))$. Multiplying by the integrating factor yields:\n$$ \\frac{d}{dx} \\left( y(x) e^{-\\beta U(x)} \\right) = -\\frac{1}{D} e^{-\\beta U(x)} $$\nIntegrating from an arbitrary point $c$ to $x$:\n$$ y(x) e^{-\\beta U(x)} - y(c) e^{-\\beta U(c)} = -\\frac{1}{D} \\int_c^x e^{-\\beta U(s)} ds $$\nTo satisfy the reflecting boundary condition $\\lim_{x \\to -\\infty} y(x) = 0$, we take the limit $c \\to -\\infty$. Noting that $U(x) \\to \\infty$ as $x \\to -\\infty$, the term $y(c) e^{-\\beta U(c)}$ vanishes provided $y(c)$ does not grow faster than $e^{\\beta U(c)}$, which is physically required. Thus, we have:\n$$ y(x) e^{-\\beta U(x)} = -\\frac{1}{D} \\int_{-\\infty}^x e^{-\\beta U(s)} ds $$\n$$ y(x) = \\frac{d\\tau}{dx} = -\\frac{1}{D} e^{\\beta U(x)} \\int_{-\\infty}^x e^{-\\beta U(s)} ds $$\nTo find $\\tau(x)$, we integrate $y(x)$ from $x_R$ to $x$ and use the absorbing boundary condition $\\tau(x_R)=0$:\n$$ \\tau(x) = \\int_{x_R}^x y(s) ds = -\\frac{1}{D} \\int_{x_R}^x e^{\\beta U(s)} \\left( \\int_{-\\infty}^s e^{-\\beta U(q)} dq \\right) ds $$\nWe seek the MFPT starting from the left well minimum, $\\tau(x_L)$:\n$$ \\tau(x_L) = -\\frac{1}{D} \\int_{x_R}^{x_L} e^{\\beta U(s)} \\left( \\int_{-\\infty}^s e^{-\\beta U(q)} dq \\right) ds = \\frac{1}{D} \\int_{x_L}^{x_R} e^{\\beta U(s)} \\left( \\int_{-\\infty}^s e^{-\\beta U(q)} dq \\right) ds $$\nThis is the exact expression. We now evaluate it in the high-barrier limit, $\\beta \\Delta U \\gg 1$. This implies that the integrands are sharply peaked, allowing for the use of Laplace's method (saddle-point approximation).\n\nThe outer integral $\\int_{x_L}^{x_R} \\dots ds$ is dominated by the region where its integrand is maximal. The term $e^{\\beta U(s)}$ has a sharp maximum at the potential barrier top, $s=x_B=0$. The inner integral term is a slowly varying function in this region.\nThe inner integral, $I_{in}(s) = \\int_{-\\infty}^s e^{-\\beta U(q)} dq$, for $s$ near the barrier top $x_B$, is dominated by the region where $e^{-\\beta U(q)}$ is maximal. This occurs at the bottom of the left well, $q=x_L$. We approximate $U(q)$ near $x_L$ with a harmonic expansion: $U(q) \\approx U(x_L) + \\frac{1}{2}U''(x_L)(q-x_L)^2$.\nThen, the inner integral becomes:\n$$ I_{in}(s) \\approx \\int_{-\\infty}^{\\infty} e^{-\\beta \\left( U(x_L) + \\frac{1}{2}U''(x_L)(q-x_L)^2 \\right)} dq = e^{-\\beta U(x_L)} \\sqrt{\\frac{2\\pi}{\\beta U''(x_L)}} $$\nThe upper integration limit $s$ (near $0$) is far enough from $x_L$ to justify extending the limit to $\\infty$.\n\nNow, substitute this into the expression for $\\tau(x_L)$:\n$$ \\tau(x_L) \\approx \\frac{1}{D} \\left( e^{-\\beta U(x_L)} \\sqrt{\\frac{2\\pi}{\\beta U''(x_L)}} \\right) \\int_{x_L}^{x_R} e^{\\beta U(s)} ds $$\nThe remaining integral is evaluated by approximating $U(s)$ around the barrier top $s=x_B=0$: $U(s) \\approx U(x_B) + \\frac{1}{2}U''(x_B)s^2 = U(x_B) - \\frac{1}{2}|U''(x_B)|s^2$.\n$$ \\int_{x_L}^{x_R} e^{\\beta U(s)} ds \\approx \\int_{-\\infty}^{\\infty} e^{\\beta \\left( U(x_B) - \\frac{1}{2}|U''(x_B)|s^2 \\right)} ds = e^{\\beta U(x_B)} \\sqrt{\\frac{2\\pi}{\\beta |U''(x_B)|}} $$\nCombining all parts:\n$$ \\tau(x_L) \\approx \\frac{1}{D} \\left( e^{-\\beta U(x_L)} \\sqrt{\\frac{2\\pi}{\\beta U''(x_L)}} \\right) \\left( e^{\\beta U(x_B)} \\sqrt{\\frac{2\\pi}{\\beta |U''(x_B)|}} \\right) $$\n$$ \\tau(x_L) \\approx \\frac{2\\pi}{D\\beta\\sqrt{U''(x_L)|U''(x_B)|}} e^{\\beta (U(x_B)-U(x_L))} $$\nSubstituting $D = 1/(\\beta\\gamma)$ and defining the activation energy $\\Delta U = U(x_B) - U(x_L)$, we arrive at the general Kramers' formula for the MFPT in the overdamped limit:\n$$ \\tau_{Kramers} = \\frac{2\\pi\\gamma}{\\sqrt{U''(x_L)|U''(x_B)|}} e^{\\beta \\Delta U} $$\nNext, we specialize this result to the potential $U(x) = ax^4 - bx^2$ with $a>0, b>0$.\nFirst, we find the stationary points by setting $U'(x) = 4ax^3 - 2bx = 2x(2ax^2-b) = 0$. The solutions are $x=0$ and $x=\\pm\\sqrt{b/(2a)}$.\nThe second derivative is $U''(x) = 12ax^2 - 2b$.\nAt $x=0$, $U''(0) = -2b < 0$, so this is a local maximum (the barrier top, $x_B=0$).\nAt $x=\\pm\\sqrt{b/(2a)}$, $U''(\\pm\\sqrt{b/(2a)}) = 12a(b/(2a)) - 2b = 6b - 2b = 4b > 0$, so these are local minima. The left minimum is $x_L = -\\sqrt{b/(2a)}$.\n\nWe calculate the required quantities for the formula:\n- The curvature at the left minimum: $U''(x_L) = 4b$.\n- The magnitude of the curvature at the barrier top: $|U''(x_B)| = |-2b| = 2b$.\n- The potential values are $U(x_L) = a(-\\sqrt{b/(2a)})^4 - b(-\\sqrt{b/(2a)})^2 = a\\frac{b^2}{4a^2} - b\\frac{b}{2a} = \\frac{b^2}{4a} - \\frac{b^2}{2a} = -\\frac{b^2}{4a}$.\n- And $U(x_B) = U(0) = 0$.\n- The activation energy is $\\Delta U = U(x_B) - U(x_L) = 0 - (-\\frac{b^2}{4a}) = \\frac{b^2}{4a}$.\n\nFinally, we substitute these values into the Kramers' formula:\n$$ \\tau(x_L) \\approx \\frac{2\\pi\\gamma}{\\sqrt{(4b)(2b)}} \\exp\\left( \\beta \\frac{b^2}{4a} \\right) $$\n$$ \\tau(x_L) \\approx \\frac{2\\pi\\gamma}{\\sqrt{8b^2}} \\exp\\left( \\frac{b^2}{4a k_B T} \\right) $$\n$$ \\tau(x_L) \\approx \\frac{2\\pi\\gamma}{2\\sqrt{2}b} \\exp\\left( \\frac{b^2}{4a k_B T} \\right) $$\n$$ \\tau(x_L) \\approx \\frac{\\pi\\gamma}{\\sqrt{2}b} \\exp\\left( \\frac{b^2}{4a k_B T} \\right) $$\nThis expression is the leading-order asymptotic result for the mean first passage time from the left well to the right well for the given potential in the high-barrier limit.",
            "answer": "$$\n\\boxed{\\frac{\\pi \\gamma}{\\sqrt{2} b} \\exp\\left(\\frac{b^2}{4 a k_B T}\\right)}\n$$"
        },
        {
            "introduction": "While potential energy barriers are a useful starting point, barriers in complex molecular systems are governed by free energy, which includes entropic contributions. This practice explores the crucial concept of an 'entropic bottleneck,' where a transition is rare not because of a high energy cost, but because the transition pathway is narrow. By implementing a two-dimensional model and computing the Transition State Theory rate, you will develop a concrete intuition for how changes in conformational space can create significant free energy barriers .",
            "id": "3440663",
            "problem": "You are asked to construct a mathematically defined two-dimensional potential energy surface that exhibits an entropic bottleneck, in the sense that the potential energy barrier is low while the free energy barrier is high, and to compute how the rare-event transition rate depends on temperature. Your derivation and algorithm must start only from the following foundational base: Newton's Laws of motion, the canonical ensemble with the Boltzmann distribution, and the definition of rare-event rate as equilibrium flux across a dividing surface. The physical scenario is posed in purely mathematical terms to ensure universal applicability and unambiguous computation.\n\nDefine the two-dimensional potential energy as\n$$\nU(x,y) \\equiv V(x) + \\tfrac{1}{2}\\,k(x)\\,y^2,\n$$\nwith the one-dimensional double-well component\n$$\nV(x) \\equiv a\\,(x^2 - b^2)^2\n$$\nand the position-dependent transverse stiffness\n$$\nk(x) \\equiv k_0 + k_1 \\exp\\!\\big(-(x/\\sigma)^2\\big).\n$$\nChoose the reactant basin as the region $x<0$ and the product basin as the region $x>0$. The dividing surface is at $x=0$. The potential energy barrier height is $V(0)=a\\,b^4$, which can be made low by selecting small $a$. The entropic bottleneck is realized by making $k(x)$ large near $x=0$ while small in the basin, so that accessible transverse configurations shrink near the saddle, increasing the free energy barrier.\n\nWorking in reduced units, set the Boltzmann constant to $k_B=1$, the mass to $m=1$, and the unit length to $L_0=1$. Report all rates in inverse reduced time units. Angles do not appear, so no angle unit is needed. There are no percentages in this task.\n\nStarting only from the canonical ensemble and equilibrium flux definition across the dividing surface, derive the temperature-dependent transition rate $k(T)$ for this model using Transition State Theory (TST). Use the exact equilibrium expression for the flux across $x=0$ divided by the equilibrium probability of being in the reactant basin, and analytically integrate over the transverse coordinate $y$. Your final algorithm should compute $k(T)$ exactly for the model defined above as a one-dimensional quadrature over $x$.\n\nImplement a complete, runnable program that, for each specified test case, evaluates\n$$\nk(T) = \\left\\langle \\delta(x)\\,\\dot{x}\\,\\Theta(\\dot{x}) \\right\\rangle \\big/ \\Pr(x<0)\n$$\nby:\n- Carrying out the $y$-integral analytically under the canonical Boltzmann distribution,\n- Computing the remaining $x$-integral by numerical quadrature over $x\\in(-\\infty,0)$,\n- Using the Maxwell-Boltzmann distribution for velocities to obtain the positive normal velocity factor.\n\nThe program must use only the specified runtime environment and libraries. The final output must be a single line containing the results for all test cases as a comma-separated list enclosed in square brackets, for example, `[r_1,r_2,r_3]`, where each $r_i$ is a floating-point number representing the rate in inverse reduced time units.\n\nTest suite parameter sets, each a tuple $(a,b,k_0,k_1,\\sigma,m,T)$, are:\n- Case $1$ (happy path, low potential barrier, strong entropic bottleneck): $(0.02,\\,1.0,\\,1.0,\\,100.0,\\,0.3,\\,1.0,\\,0.5)$.\n- Case $2$ (low temperature, same bottleneck): $(0.02,\\,1.0,\\,1.0,\\,100.0,\\,0.3,\\,1.0,\\,0.1)$.\n- Case $3$ (higher temperature, same bottleneck): $(0.02,\\,1.0,\\,1.0,\\,100.0,\\,0.3,\\,1.0,\\,1.0)$.\n- Case $4$ (no entropic bottleneck, uniform transverse stiffness): $(0.02,\\,1.0,\\,1.0,\\,0.0,\\,0.3,\\,1.0,\\,0.5)$.\n- Case $5$ (extremely narrow bottleneck): $(0.02,\\,1.0,\\,1.0,\\,100.0,\\,0.1,\\,1.0,\\,0.5)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., `[r_1,r_2,r_3,r_4,r_5]`), where each $r_i$ is the computed rate for the corresponding case in inverse reduced time units.",
            "solution": "The problem statement is critically validated and deemed to be **valid**. It is scientifically grounded in statistical mechanics, well-posed with all necessary definitions and parameters, and expressed in objective mathematical language. The task is a standard, non-trivial problem in chemical rate theory that can be solved rigorously from the provided first principles.\n\nThe transition rate $k(T)$ from the reactant basin ($x<0$) to the product basin ($x>0$) is defined as the equilibrium flux of trajectories crossing the dividing surface at $x=0$ in the positive $x$-direction, normalized by the equilibrium probability of being in the reactant basin.\n$$\nk(T) = \\frac{\\left\\langle \\delta(x)\\,\\dot{x}\\,\\Theta(\\dot{x}) \\right\\rangle}{\\Pr(x<0)}\n$$\nwhere $\\langle \\cdot \\rangle$ denotes a canonical ensemble average, $\\dot{x}$ is the velocity along $x$, $\\delta(x)$ is the Dirac delta function selecting the dividing surface, and $\\Theta(\\dot{x})$ is the Heaviside step function ensuring flux is counted only in the forward (product) direction.\n\nThe canonical average of an observable $A(\\mathbf{q}, \\mathbf{p})$ in phase space $(\\mathbf{q}, \\mathbf{p})$ is given by $\\langle A \\rangle = Z^{-1} \\int A(\\mathbf{q}, \\mathbf{p}) e^{-\\beta H(\\mathbf{q}, \\mathbf{p})} d\\mathbf{q} d\\mathbf{p}$, where $H$ is the Hamiltonian, $\\beta = (k_B T)^{-1}$, and $Z$ is the total partition function. With $k_B=1$, $\\beta = 1/T$. The Hamiltonian for the two-dimensional system is\n$$\nH(x, y, p_x, p_y) = \\frac{p_x^2}{2m} + \\frac{p_y^2}{2m} + U(x, y)\n$$\nwith $U(x,y) = V(x) + \\frac{1}{2}k(x)y^2$. The particle mass is $m$.\n\nThe numerator is the flux $J = \\left\\langle \\delta(x)\\,\\dot{x}\\,\\Theta(\\dot{x}) \\right\\rangle$. Writing this as a phase space integral:\n$$\nJ = \\frac{1}{Z} \\int_{-\\infty}^{\\infty} dx \\int_{-\\infty}^{\\infty} dy \\int_{-\\infty}^{\\infty} dp_x \\int_{-\\infty}^{\\infty} dp_y \\, \\delta(x) \\frac{p_x}{m} \\Theta(p_x) e^{-\\beta H}\n$$\nThe integral over $x$ is eliminated by the delta function, which sets $x=0$ in the rest of the integrand. The expression separates into products of integrals over the remaining variables:\n$$\nJ = \\frac{1}{Z} \\left(\\int_0^{\\infty} \\frac{p_x}{m} e^{-\\beta p_x^2/(2m)} dp_x\\right) \\left(\\int_{-\\infty}^{\\infty} e^{-\\beta p_y^2/(2m)} dp_y\\right) \\left(\\int_{-\\infty}^{\\infty} e^{-\\beta U(0,y)} dy\\right)\n$$\nEvaluating the momentum integrals:\n1. $\\int_0^{\\infty} \\frac{p_x}{m} e^{-\\beta p_x^2/(2m)} dp_x = \\left[-\\frac{1}{\\beta} e^{-\\beta p_x^2/(2m)}\\right]_0^{\\infty} = \\frac{1}{\\beta} = T$.\n2. $\\int_{-\\infty}^{\\infty} e^{-\\beta p_y^2/(2m)} dp_y = \\sqrt{2\\pi m/\\beta} = \\sqrt{2\\pi m T}$.\n\nThe configuration integral at the transition state $x=0$ will be denoted $Z_q^\\ddagger$:\n$Z_q^\\ddagger = \\int_{-\\infty}^{\\infty} e^{-\\beta U(0,y)} dy$.\nThus, the flux is $J = \\frac{1}{Z} (T) (\\sqrt{2\\pi m T}) Z_q^\\ddagger$.\n\nThe denominator is the probability of being in the reactant basin, $\\Pr(x<0) = Z_R/Z$, where $Z_R$ is the reactant partition function:\n$$\nZ_R = \\int_{x<0} dx \\int_{-\\infty}^{\\infty} dy \\int_{-\\infty}^{\\infty} dp_x \\int_{-\\infty}^{\\infty} dp_y \\, e^{-\\beta H}\n$$\nThis also separates into momentum and configuration parts:\n$$\nZ_R = \\left(\\int_{-\\infty}^{\\infty} e^{-\\beta p_x^2/(2m)} dp_x\\right) \\left(\\int_{-\\infty}^{\\infty} e^{-\\beta p_y^2/(2m)} dp_y\\right) \\left(\\int_{x<0} dx \\int_{-\\infty}^{\\infty} dy \\, e^{-\\beta U(x,y)}\\right)\n$$\nThe momentum integrals evaluate to $(\\sqrt{2\\pi m T})^2 = 2\\pi m T$. The configurational part is the reactant partition function in configuration space, $Z_{R,q} = \\int_{x<0} dx \\int_{-\\infty}^{\\infty} dy \\, e^{-\\beta U(x,y)}$.\nSo, $Z_R = (2\\pi m T) Z_{R,q}$.\n\nCombining these results for the rate constant $k(T)$:\n$$\nk(T) = \\frac{J}{\\Pr(x<0)} = \\frac{J Z}{Z_R} = \\frac{ \\frac{1}{Z} (T \\sqrt{2\\pi m T}) Z_q^\\ddagger \\cdot Z}{(2\\pi m T) Z_{R,q}} = \\frac{T \\sqrt{2\\pi m T}}{2\\pi m T} \\frac{Z_q^\\ddagger}{Z_{R,q}} = \\sqrt{\\frac{T}{2\\pi m}} \\frac{Z_q^\\ddagger}{Z_{R,q}}\n$$\nThis is the standard formulation of Transition State Theory in configuration space.\n\nNow, we perform the analytical integration over the transverse coordinate $y$.\nFor an arbitrary $x$, the integral over $y$ is:\n$$\n\\int_{-\\infty}^{\\infty} e^{-\\beta U(x,y)} dy = \\int_{-\\infty}^{\\infty} e^{-\\beta(V(x) + \\frac{1}{2}k(x)y^2)} dy = e^{-\\beta V(x)} \\int_{-\\infty}^{\\infty} e^{-\\beta \\frac{k(x)}{2} y^2} dy\n$$\nThis is a standard Gaussian integral, which evaluates to $\\sqrt{2\\pi/(\\beta k(x))} = \\sqrt{2\\pi T/k(x)}$.\nSo, $\\int_{-\\infty}^{\\infty} e^{-\\beta U(x,y)} dy = e^{-V(x)/T} \\sqrt{2\\pi T/k(x)}$.\n\nApplying this result to $Z_q^\\ddagger$ (at $x=0$) and $Z_{R,q}$ (integrated over $x<0$):\n$$\nZ_q^\\ddagger = \\int_{-\\infty}^{\\infty} e^{-\\beta U(0,y)} dy = e^{-V(0)/T} \\sqrt{2\\pi T/k(0)}\n$$\n$$\nZ_{R,q} = \\int_{-\\infty}^{0} dx \\left( \\int_{-\\infty}^{\\infty} e^{-\\beta U(x,y)} dy \\right) = \\int_{-\\infty}^{0} dx \\, e^{-V(x)/T} \\sqrt{2\\pi T/k(x)}\n$$\nSubstituting these into the expression for $k(T)$:\n$$\nk(T) = \\sqrt{\\frac{T}{2\\pi m}} \\frac{e^{-V(0)/T} \\sqrt{2\\pi T/k(0)}}{\\int_{-\\infty}^{0} e^{-V(x)/T} \\sqrt{2\\pi T/k(x)} dx} = \\sqrt{\\frac{T}{2\\pi m}} \\frac{e^{-V(0)/T}/\\sqrt{k(0)}}{\\int_{-\\infty}^{0} e^{-V(x)/T}/\\sqrt{k(x)} dx}\n$$\nUsing the specific functional forms provided:\n$V(x) = a(x^2 - b^2)^2 \\implies V(0) = ab^4$.\n$k(x) = k_0 + k_1 \\exp(-(x/\\sigma)^2) \\implies k(0) = k_0+k_1$.\nThe final expression to be computed is:\n$$\nk(T) = \\sqrt{\\frac{T}{2\\pi m}} \\frac{\\exp(-ab^4/T) / \\sqrt{k_0+k_1}}{\\int_{-\\infty}^{0} \\frac{\\exp(-a(x^2-b^2)^2/T)}{\\sqrt{k_0 + k_1 \\exp(-(x/\\sigma)^2)}} dx}\n$$\nThe integral in the denominator cannot be solved analytically and must be computed by numerical quadrature. The provided algorithm will implement this formula for each test case.",
            "answer": "```python\nimport numpy as np\nfrom scipy import integrate\n\ndef solve():\n    \"\"\"\n    Computes the transition rate k(T) for a 2D potential energy surface \n    exhibiting an entropic bottleneck, based on Transition State Theory (TST).\n    \n    The rate is calculated using an analytical expression derived from first principles,\n    with the final step involving a 1D numerical quadrature.\n    \"\"\"\n    \n    # Test suite parameter sets, each a tuple (a, b, k0, k1, sigma, m, T)\n    test_cases = [\n        (0.02, 1.0, 1.0, 100.0, 0.3, 1.0, 0.5), # Case 1: Happy path\n        (0.02, 1.0, 1.0, 100.0, 0.3, 1.0, 0.1), # Case 2: Low temperature\n        (0.02, 1.0, 1.0, 100.0, 0.3, 1.0, 1.0), # Case 3: High temperature\n        (0.02, 1.0, 1.0, 0.0, 0.3, 1.0, 0.5),  # Case 4: No entropic bottleneck\n        (0.02, 1.0, 1.0, 100.0, 0.1, 1.0, 0.5), # Case 5: Narrow bottleneck\n    ]\n\n    results = []\n    for case in test_cases:\n        a, b, k0, k1, sigma, m, T = case\n\n        # Define the potential component V(x) and transverse stiffness k(x)\n        def V_func(x_val):\n            return a * (x_val**2 - b**2)**2\n\n        def k_func(x_val):\n            return k0 + k1 * np.exp(-(x_val / sigma)**2)\n\n        # Define the integrand for the denominator of the rate expression.\n        # This corresponds to exp(-V(x)/T) / sqrt(k(x)).\n        def integrand(x_val):\n            return np.exp(-V_func(x_val) / T) / np.sqrt(k_func(x_val))\n\n        # --- Calculate the components of the TST rate formula ---\n\n        # 1. Prefactor derived from kinetic terms\n        prefactor = np.sqrt(T / (2 * np.pi * m))\n\n        # 2. Numerator term, related to the transition state configuration\n        V_at_0 = a * b**4\n        k_at_0 = k0 + k1\n        \n        # This term is exp(-V(0)/T) / sqrt(k(0))\n        numerator_term = np.exp(-V_at_0 / T) / np.sqrt(k_at_0)\n\n        # 3. Denominator term, related to the reactant basin configuration\n        # This is the integral over x from -infinity to 0 of the integrand.\n        denominator_integral, _ = integrate.quad(integrand, -np.inf, 0, limit=100)\n        \n        # Combine all parts to get the final TST rate\n        rate = prefactor * numerator_term / denominator_integral\n        results.append(rate)\n\n    # Format the final output as a single comma-separated list in brackets,\n    # with each rate expressed in scientific notation for clarity.\n    print(f\"[{','.join(f'{r:.8e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "After running a simulation and observing a series of rare events, how can we be sure they correspond to a well-defined rate? This exercise addresses the critical task of data validation, focusing on whether event waiting times follow a homogeneous Poisson process, a key assumption for simple rate analysis. You will implement a powerful statistical test based on the time-rescaling theorem to analyze synthetic data, learning to identify both ideal Poisson statistics and common artifacts arising from biased simulations like metadynamics .",
            "id": "3440725",
            "problem": "You are tasked with designing and implementing a statistically principled detector for non-Poissonian waiting times in the context of rare event sampling in molecular dynamics, with an emphasis on metadynamics-corrected event times. Your algorithm must start from first principles, use only well-established definitions, and produce quantifiable outputs according to a fixed test suite.\n\nDefinitions and fundamental base:\n- A homogeneous Poisson process with constant event rate $k$ is a point process in continuous time such that the inter-event waiting times are independent and identically distributed random variables, each with the exponential distribution of rate $k$.\n- For an exponential distribution of rate $k$, the probability density function is $f(t) = k \\, e^{-k t}$ for $t \\ge 0$, the cumulative distribution function is $F(t) = 1 - e^{-k t}$, and the survival function is $S(t) = e^{-k t}$.\n- The time-rescaling theorem states that for a point process whose conditional intensity is correctly specified, there exists a monotone transformation of the inter-event times that yields identically distributed variables with a known, simple reference distribution. For a homogeneous Poisson process, derive the specific transformation that maps each waiting time to a variable with the standard uniform distribution on $[0,1]$. Your derivation must begin from the definitions above and must not assume any result beyond them.\n- For a sequence of independent exponential waiting times, derive the maximum likelihood estimator of the constant rate $k$.\n\nMetadynamics-corrected events:\n- In bias-accelerated simulations such as metadynamics, an event observed under a time-acceleration factor $a$ has a biased waiting time $t_{\\mathrm{b}}$ whose distribution differs from the unbiased waiting time. Under the simplifying model of piecewise-constant acceleration per event, the unbiased waiting time can be recovered exactly by the correction $t_{\\mathrm{corr}} = a \\, t_{\\mathrm{b}}$. In practice, $a$ may be estimated with noise, yielding a mis-corrected $t_{\\mathrm{corr}}^{\\mathrm{wrong}}$.\n- Your algorithm must treat each provided sequence of waiting times as the hypothesized unbiased times, estimate the constant rate parameter from the data, transform the waiting times via the transformation implied by the time-rescaling theorem for a homogeneous Poisson process, and then quantify the deviation from the uniform distribution on $[0,1]$ using the Kolmogorov–Smirnov (KS) statistic.\n\nAlgorithmic requirements:\n- Given a sequence of waiting times $\\{t_i\\}_{i=1}^n$, estimate the constant rate $\\hat{k}$ from the data using the maximum likelihood principle.\n- Using the homogeneous Poisson transform you derived, compute transformed variables $\\{u_i\\}_{i=1}^n$ and test their consistency with the standard uniform distribution on $[0,1]$ using the Kolmogorov–Smirnov statistic. Report both the KS statistic value and its corresponding $p$-value.\n- All outputs are dimensionless real numbers. No physical units are required.\n\nTest suite and data generation:\nImplement the following five independent test cases. In every case, use a fresh pseudorandom number generator stream initialized with the specified seed. All random variates must be independent within a case except where explicitly coupled by construction. Treat all time variables as unitless.\n\n- Case A (baseline homogeneous Poisson):\n  - Sample size $n = 500$.\n  - True rate $k = 0.5$.\n  - Seed $12345$.\n  - Generate $n$ independent exponential waiting times with rate $k$.\n\n- Case B (metadynamics-corrected, exact correction):\n  - Sample size $n = 500$.\n  - True rate $k = 0.2$.\n  - Seed $12346$.\n  - For each event $i$, draw an independent acceleration factor $a_i$ from a lognormal distribution with parameters $\\mu = \\ln(10)$ and $\\sigma = 0.5$ for the underlying normal.\n  - Conditional on $a_i$, draw a biased waiting time $t_{{\\mathrm{b}}, i}$ from an exponential distribution with rate $a_i \\, k$.\n  - Form the exactly corrected time $t_i = a_i \\, t_{{\\mathrm{b}}, i}$.\n  - Use $\\{t_i\\}$ as input to your detection algorithm.\n\n- Case C (metadynamics-corrected, mis-correction):\n  - Sample size $n = 500$.\n  - True rate $k = 0.2$.\n  - Seed $12347$.\n  - For each event $i$, draw $a_i$ as in Case B.\n  - Conditional on $a_i$, draw $t_{{\\mathrm{b}}, i}$ from an exponential distribution with rate $a_i \\, k$.\n  - Draw an independent estimation noise $\\epsilon_i$ from a normal distribution with mean $0$ and standard deviation $0.6$, and define $a_i^{\\mathrm{est}} = a_i \\, e^{\\epsilon_i}$.\n  - Form the mis-corrected time $t_i = a_i^{\\mathrm{est}} \\, t_{{\\mathrm{b}}, i}$.\n  - Use $\\{t_i\\}$ as input to your detection algorithm.\n\n- Case D (non-exponential renewal, gamma shape):\n  - Sample size $n = 500$.\n  - Baseline rate parameter $k_0 = 0.5$.\n  - Seed $12348$.\n  - Draw $n$ independent gamma-distributed waiting times with shape parameter $r = 2$ and rate parameter $\\lambda = r \\, k_0$ (equivalently, scale parameter $\\theta = 1/\\lambda$). This yields a renewal process with mean waiting time matching $1/k_0$ but non-exponential variability.\n  - Use these as input to your detection algorithm.\n\n- Case E (small-sample homogeneous Poisson edge case):\n  - Sample size $n = 10$.\n  - True rate $k = 0.5$.\n  - Seed $12349$.\n  - Generate $n$ independent exponential waiting times with rate $k$.\n\nRequired outputs:\n- For each case in the order A, B, C, D, E, compute and return two values: the Kolmogorov–Smirnov statistic $D$ and its $p$-value under the null hypothesis that the transformed variables are independent and identically distributed standard uniform random variables.\n- Your program should produce a single line of output containing the results as a comma-separated flat list of real numbers enclosed in square brackets, ordered as $[D_{\\mathrm{A}}, p_{\\mathrm{A}}, D_{\\mathrm{B}}, p_{\\mathrm{B}}, D_{\\mathrm{C}}, p_{\\mathrm{C}}, D_{\\mathrm{D}}, p_{\\mathrm{D}}, D_{\\mathrm{E}}, p_{\\mathrm{E}}]$.\n- Round each reported real number to $6$ decimal places before printing.\n\nConstraints:\n- Your derivations must start from the definitions and facts stated above. Do not assume or quote the target transformation or estimator without deriving them.\n- Your implementation must not assume prior knowledge of true parameters. All parameters needed by the test suite are for synthetic data generation only; your detection algorithm must estimate the rate from the provided waiting times in each case separately.",
            "solution": "The task is to design a principled statistical detector for non-Poissonian waiting times, a common challenge in analyzing rare events from molecular dynamics simulations. The foundation of the detector is the null hypothesis that the observed inter-event times $\\{t_i\\}_{i=1}^n$ are independent and identically distributed (i.i.d.) samples from an exponential distribution with a constant rate $k$, which is the defining characteristic of a homogeneous Poisson process (HPP). The a priori unknown rate $k$ must be estimated from the data. The core of the method involves transforming the observed times into a set of variables that, under the null hypothesis, should follow a standard uniform distribution. The deviation from uniformity is then quantified using the Kolmogorov-Smirnov (KS) test.\n\nThe solution proceeds in three stages: first, we derive the necessary theoretical components from first principles as required; second, we outline the complete algorithmic procedure; and third, we analyze the expected outcome for each of the specified test cases.\n\n### Theoretical Derivations\n\nTwo key results must be derived: the transformation mapping exponential variates to uniform variates, and the maximum likelihood estimator for the exponential rate parameter.\n\n**1. Time-Rescaling Transformation for a Homogeneous Poisson Process**\n\nThe problem requires the derivation of a transformation that maps an exponentially distributed waiting time $T$ to a random variable $U$ that is uniformly distributed on the interval $[0, 1]$. This is a specific application of the probability integral transform theorem.\n\nLet $T$ be a random variable representing an inter-event waiting time. Under the HPP hypothesis, $T$ follows an exponential distribution with rate parameter $k > 0$. The probability density function (PDF) and cumulative distribution function (CDF) are given as:\n$$\nf(t; k) = k e^{-kt} \\quad \\text{for } t \\ge 0\n$$\n$$\nF_T(t; k) = P(T \\le t) = \\int_0^t k e^{-k\\tau} d\\tau = \\left[ -e^{-k\\tau} \\right]_0^t = 1 - e^{-kt}\n$$\n\nThe probability integral transform theorem states that if $X$ is a continuous random variable with CDF $F_X(x)$, then the random variable $Y = F_X(X)$ is uniformly distributed on $[0, 1]$. Applying this theorem to our waiting time variable $T$:\nLet $U = F_T(T; k)$. The transformation is thus:\n$$\nU = 1 - e^{-kT}\n$$\n\nTo prove that $U \\sim U[0, 1]$, we find its CDF, denoted $F_U(u)$.\nThe support of $T$ is $[0, \\infty)$. This implies that $e^{-kT}$ is in $(0, 1]$, and therefore $U = 1 - e^{-kT}$ is in $[0, 1)$.\nFor any $u \\in [0, 1)$, the CDF of $U$ is:\n$$\nF_U(u) = P(U \\le u) = P(1 - e^{-kT} \\le u)\n$$\nRearranging the inequality to solve for $T$:\n$$\nP(-e^{-kT} \\le u - 1) \\implies P(e^{-kT} \\ge 1 - u)\n$$\nTaking the natural logarithm of both sides (which is a monotonic function):\n$$\nP(-kT \\ge \\ln(1 - u))\n$$\nSince $k > 0$, multiplying by $-1/k$ reverses the inequality:\n$$\nP\\left(T \\le -\\frac{1}{k}\\ln(1 - u)\\right)\n$$\nBy definition, $P(T \\le t) = F_T(t; k)$. Therefore:\n$$\nF_U(u) = F_T\\left(-\\frac{1}{k}\\ln(1 - u); k\\right) = 1 - \\exp\\left[-k \\left(-\\frac{1}{k}\\ln(1 - u)\\right)\\right]\n$$\n$$\nF_U(u) = 1 - \\exp[\\ln(1 - u)] = 1 - (1 - u) = u\n$$\nThe CDF of $U$ is $F_U(u) = u$ for $u \\in [0, 1)$, $F_U(u) = 0$ for $u < 0$, and $F_U(u) = 1$ for $u \\ge 1$. This is the CDF of the standard uniform distribution $U[0, 1]$.\nIn practice, the true rate $k$ is unknown and is replaced by its estimate $\\hat{k}$. The transformation applied to each observed time $t_i$ is therefore $u_i = 1 - e^{-\\hat{k}t_i}$.\n\n**2. Maximum Likelihood Estimator (MLE) for the Rate Parameter**\n\nGiven a set of $n$ i.i.d. waiting times $\\{t_i\\}_{i=1}^n$ drawn from an exponential distribution with unknown rate $k$, we derive the MLE for $k$.\n\nThe likelihood function, $\\mathcal{L}(k)$, is the joint probability density of the observed data, considered as a function of the parameter $k$:\n$$\n\\mathcal{L}(k; \\{t_i\\}_{i=1}^n) = \\prod_{i=1}^n f(t_i; k) = \\prod_{i=1}^n \\left(k e^{-kt_i}\\right) = k^n \\exp\\left(-k \\sum_{i=1}^n t_i\\right)\n$$\nTo simplify maximization, we work with the log-likelihood function, $\\ell(k) = \\ln \\mathcal{L}(k)$:\n$$\n\\ell(k) = \\ln\\left(k^n\\right) + \\ln\\left(\\exp\\left(-k \\sum_{i=1}^n t_i\\right)\\right) = n \\ln(k) - k \\sum_{i=1}^n t_i\n$$\nTo find the value of $k$ that maximizes $\\ell(k)$, we compute its derivative with respect to $k$ and set it to zero:\n$$\n\\frac{d\\ell(k)}{dk} = \\frac{n}{k} - \\sum_{i=1}^n t_i\n$$\nSetting the derivative to zero yields the MLE, $\\hat{k}$:\n$$\n\\frac{n}{\\hat{k}} - \\sum_{i=1}^n t_i = 0 \\implies \\frac{n}{\\hat{k}} = \\sum_{i=1}^n t_i\n$$\n$$\n\\hat{k} = \\frac{n}{\\sum_{i=1}^n t_i}\n$$\nThe estimator $\\hat{k}$ is the reciprocal of the sample mean of the waiting times, $\\bar{t} = \\frac{1}{n}\\sum_{i=1}^n t_i$.\nTo confirm this is a maximum, we check the second derivative:\n$$\n\\frac{d^2\\ell(k)}{dk^2} = -\\frac{n}{k^2}\n$$\nSince $n > 0$ and $k^2 > 0$ for any non-trivial case, the second derivative is always negative, confirming that $\\hat{k}$ corresponds to a maximum of the likelihood function.\n\n### Algorithmic Procedure\n\nFor each test case, the following algorithm is applied:\n1.  **Data Generation**: A sequence of $n$ waiting times, $\\{t_i\\}_{i=1}^n$, is generated according to the specific rules of the test case, using a pseudorandom number generator initialized with the specified seed to ensure reproducibility.\n2.  **Rate Estimation**: The maximum likelihood estimate of the rate, $\\hat{k}$, is computed from the generated data using the derived formula:\n    $$\n    \\hat{k} = \\frac{n}{\\sum_{i=1}^n t_i}\n    $$\n3.  **Time Rescaling**: Each waiting time $t_i$ in the sequence is transformed into a new variable $u_i$ using the derived time-rescaling transformation with the estimated rate $\\hat{k}$:\n    $$\n    u_i = 1 - e^{-\\hat{k}t_i}\n    $$\n    This produces a new sequence of rescaled times, $\\{u_i\\}_{i=1}^n$.\n4.  **Hypothesis Testing**: The Kolmogorov-Smirnov (KS) test is used to quantify the discrepancy between the empirical distribution of the $\\{u_i\\}$ and the theoretical standard uniform distribution, $U[0, 1]$. The KS statistic $D$ is the maximum absolute difference between the empirical CDF of $\\{u_i\\}$ and the CDF of $U[0, 1]$. The test also yields a $p$-value, which is the probability of observing a $D$ statistic at least as large as the one measured, under the null hypothesis that the $\\{u_i\\}$ are indeed i.i.d. from $U[0, 1]$. A small $p$-value (e.g., $< 0.05$) indicates a statistically significant deviation from the null HPP model.\n\n### Test Case Analysis\n\nThe test suite is designed to validate the algorithm under different well-defined scenarios:\n- **Case A (Baseline HPP)**: The data are generated from a true homogeneous Poisson process. We expect the algorithm to confirm the null hypothesis. The estimated rate $\\hat{k}$ should be close to the true rate $k=0.5$. The transformed variables $\\{u_i\\}$ should be nearly uniform, resulting in a small KS statistic $D$ and a large $p$-value.\n- **Case B (Exactly Corrected Metadynamics)**: The construction ensures that the corrected times $\\{t_i = a_i t_{\\mathrm{b},i}\\}$ are i.i.d. samples from an exponential distribution with rate $k=0.2$. This case is theoretically equivalent to Case A. We therefore expect a similar outcome: a small $D$ and a large $p$-value, demonstrating the algorithm's ability to correctly identify a valid HPP even when its statistics are recovered from a biased simulation.\n- **Case C (Mis-corrected Metadynamics)**: The noise in the acceleration factor estimation introduces a multiplicative error into the corrected times. The resulting $\\{t_i\\}$ will no longer be exponentially distributed. The algorithm is expected to detect this deviation. This should manifest as a large KS statistic $D$ and a correspondingly small $p$-value, leading to the rejection of the HPP hypothesis.\n- **Case D (Gamma Renewal Process)**: The waiting times are drawn from a Gamma distribution ($r=2$), which has a different shape from the exponential distribution (Gamma with $r=1$), although the mean waiting time is matched to a comparable HPP. The detector should be sensitive to this difference in the distribution's shape. We expect a large $D$ statistic and a very small $p$-value.\n- **Case E (Small-Sample HPP)**: This is an edge case to test the behavior with limited data ($n=10$). While the data generating process is a true HPP, the statistical power of the KS test is low for such a small sample size. Consequently, we expect to fail to reject the null hypothesis (i.e., obtain a large $p$-value), but the estimated $\\hat{k}$ and the KS statistic $D$ might show higher variance compared to the large-sample case (Case A).\n\nThe implementation will now proceed to execute this procedure for all five cases and report the results as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef solve():\n    \"\"\"\n    Solves the problem of detecting non-Poissonian waiting times\n    by implementing and applying a statistical test based on the\n    time-rescaling theorem and Kolmogorov-Smirnov statistic.\n    \"\"\"\n\n    test_cases = [\n        {'name': 'A', 'n': 500, 'k': 0.5, 'seed': 12345},\n        {'name': 'B', 'n': 500, 'k': 0.2, 'seed': 12346},\n        {'name': 'C', 'n': 500, 'k': 0.2, 'seed': 12347},\n        {'name': 'D', 'n': 500, 'k0': 0.5, 'seed': 12348},\n        {'name': 'E', 'n': 10, 'k': 0.5, 'seed': 12349},\n    ]\n\n    results = []\n    for case in test_cases:\n        rng = np.random.default_rng(case['seed'])\n        n = case['n']\n        \n        # --- Data Generation ---\n        if case['name'] == 'A':\n            # Case A: baseline homogeneous Poisson\n            k = case['k']\n            # numpy's exponential uses scale = 1/rate\n            times = rng.exponential(scale=1.0/k, size=n)\n        \n        elif case['name'] == 'B':\n            # Case B: metadynamics-corrected, exact correction\n            k = case['k']\n            # Lognormal parameters are for the underlying Normal distribution\n            log_a_mu = np.log(10)\n            log_a_sigma = 0.5\n            a_i = rng.lognormal(mean=log_a_mu, sigma=log_a_sigma, size=n)\n            \n            # Biased waiting time t_b has rate a_i * k\n            # Scale for exponential is 1 / (a_i * k)\n            t_b_i = rng.exponential(scale=1.0/(a_i * k))\n            \n            # Exactly corrected time\n            times = a_i * t_b_i\n            \n        elif case['name'] == 'C':\n            # Case C: metadynamics-corrected, mis-correction\n            k = case['k']\n            log_a_mu = np.log(10)\n            log_a_sigma = 0.5\n            a_i = rng.lognormal(mean=log_a_mu, sigma=log_a_sigma, size=n)\n            \n            t_b_i = rng.exponential(scale=1.0/(a_i * k))\n            \n            # Estimation noise for acceleration factor\n            epsilon_i = rng.normal(loc=0, scale=0.6, size=n)\n            a_est_i = a_i * np.exp(epsilon_i)\n            \n            # Mis-corrected time\n            times = a_est_i * t_b_i\n\n        elif case['name'] == 'D':\n            # Case D: non-exponential renewal, gamma shape\n            k0 = case['k0']\n            shape_r = 2.0\n            rate_lambda = shape_r * k0\n            # numpy's gamma uses scale = 1/rate\n            scale_theta = 1.0 / rate_lambda\n            times = rng.gamma(shape=shape_r, scale=scale_theta, size=n)\n\n        elif case['name'] == 'E':\n            # Case E: small-sample homogeneous Poisson\n            k = case['k']\n            times = rng.exponential(scale=1.0/k, size=n)\n        \n        # --- Algorithmic Analysis ---\n        \n        # 1. Estimate rate k using MLE\n        # handle case where sum of times is zero to avoid division by zero\n        sum_times = np.sum(times)\n        if sum_times <= 0:\n            # This is highly unlikely for exponential waiting times but is good practice\n            k_hat = np.inf\n        else:\n            k_hat = n / sum_times\n\n        # 2. Compute transformed variables (rescaled times)\n        # Using the transformation u = 1 - exp(-k*t)\n        u_values = 1.0 - np.exp(-k_hat * times)\n\n        # 3. Perform Kolmogorov-Smirnov test against standard uniform distribution\n        # kstest returns a result object with statistic and pvalue\n        ks_result = kstest(u_values, 'uniform')\n        D_statistic = ks_result.statistic\n        p_value = ks_result.pvalue\n        \n        # 4. Store rounded results\n        results.append(round(D_statistic, 6))\n        results.append(round(p_value, 6))\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}