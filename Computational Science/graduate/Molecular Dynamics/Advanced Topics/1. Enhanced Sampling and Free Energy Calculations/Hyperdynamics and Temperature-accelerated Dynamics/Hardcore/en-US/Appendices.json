{
    "hands_on_practices": [
        {
            "introduction": "This first exercise grounds the abstract theory of hyperdynamics in a concrete calculation. You will practice translating the 'hypertime' from an accelerated simulation back into the real physical time that would have elapsed without the bias potential. This time-remapping is the central mechanism of hyperdynamics, and by using the result to estimate a physical rate constant, you will connect the simulation output directly to experimentally relevant kinetics .",
            "id": "3417459",
            "problem": "A single reactive event is observed in a hyperdynamics simulation of a metastable basin. The original potential energy surface is $U(\\mathbf{r})$ and a nonnegative, state-dependent boost potential $\\Delta V(\\mathbf{r}) \\ge 0$ is applied to construct the biased potential $U_b(\\mathbf{r}) = U(\\mathbf{r}) + \\Delta V(\\mathbf{r})$. The system is coupled to a thermal bath at absolute temperature $T$ and evolves under the biased potential until it exits the basin at the biased exit time $\\tau_b$. You are given a discrete time series of the applied boost potential along the biased trajectory immediately preceding exit, sampled at uniform intervals $\\Delta t$:\n- Temperature $T = 300 \\ \\text{K}$, Boltzmann constant $k_B = 0.008314462618 \\ \\text{kJ} \\ \\text{mol}^{-1} \\ \\text{K}^{-1}$.\n- Sampling interval $\\Delta t = 0.2 \\ \\text{ps}$.\n- Number of samples $N = 10$, with $t_k = k \\Delta t$ and $\\tau_b = N \\Delta t = 2.0 \\ \\text{ps}$.\n- Boost potential samples in $\\text{kJ} \\ \\text{mol}^{-1}$:\n$$\n\\{\\Delta V(t_k)\\}_{k=1}^{10} = \\{24.0,\\ 25.0,\\ 23.5,\\ 24.5,\\ 26.0,\\ 25.5,\\ 24.0,\\ 23.0,\\ 22.5,\\ 24.0\\}.\n$$\n\nStarting from first principles of equilibrium statistical mechanics and barrier crossing in canonical ensembles, and without assuming any prefabricated “time rescaling” formulas, do the following:\n1) Derive an expression that relates the unbiased physical time $t_{\\text{phys}}$ accumulated during the biased trajectory up to $\\tau_b$ to the time-dependent boost potential $\\Delta V(t)$, under the standard hyperdynamics requirements that $\\Delta V(\\mathbf{r}) \\ge 0$ in the basin and $\\Delta V(\\mathbf{r}) = 0$ in the transition-state region.\n2) Using your derived expression and the discrete data, compute $t_{\\text{phys}}$ by an appropriate Riemann-sum approximation. Express your final $t_{\\text{phys}}$ in nanoseconds.\n3) Assuming a memoryless (Poisson) exit process from the basin at the unbiased conditions, give the maximum-likelihood estimate of the unbiased rate constant $k_0$ from this single observed exit, using your computed $t_{\\text{phys}}$. Express your final $k_0$ in $\\text{microsecond}^{-1}$.\n\nRound both requested numerical answers to three significant figures. When you report your final answer, list $t_{\\text{phys}}$ first (in nanoseconds) and $k_0$ second (in $\\text{microsecond}^{-1}$) as a row matrix.",
            "solution": "The problem is evaluated to be scientifically grounded, well-posed, objective, and internally consistent. It is a standard application of the principles of hyperdynamics, a valid and established method in computational statistical mechanics. All necessary data and conditions for a unique solution are provided. We may therefore proceed with the solution.\n\nThe problem requires a three-part solution: 1) derivation of the relationship between biased simulation time and physical time, 2) calculation of the total physical time, and 3) estimation of the unbiased rate constant.\n\n**1. Derivation of the Physical Time Expression**\n\nThe fundamental premise of hyperdynamics is to accelerate the escape from a potential energy basin without altering the relative probabilities of different escape pathways. This is achieved by adding a non-negative boost potential, $\\Delta V(\\mathbf{r})$, which is zero at the transition state boundaries of the basin.\n\nLet the system be in a canonical ensemble at temperature $T$. The probability density of finding the system at a point $\\mathbf{r}$ in configuration space is given by the Boltzmann distribution. For the original potential $U(\\mathbf{r})$, this is:\n$$ P_0(\\mathbf{r}) \\propto \\exp\\left(-\\frac{U(\\mathbf{r})}{k_B T}\\right) $$\nUnder the biased potential $U_b(\\mathbf{r}) = U(\\mathbf{r}) + \\Delta V(\\mathbf{r})$, the probability density becomes:\n$$ P_b(\\mathbf{r}) \\propto \\exp\\left(-\\frac{U_b(\\mathbf{r})}{k_B T}\\right) = \\exp\\left(-\\frac{U(\\mathbf{r}) + \\Delta V(\\mathbf{r})}{k_B T}\\right) = P_0(\\mathbf{r}) \\exp\\left(-\\frac{\\Delta V(\\mathbf{r})}{k_B T}\\right) $$\nThe time a trajectory spends in an infinitesimal region $d\\mathbf{r}$ is proportional to the probability density of being in that region. Let $dt_b$ be an infinitesimal increment of time in the biased simulation, during which the system is at position $\\mathbf{r}(t_b)$. The corresponding increment of physical time, $dt_{\\text{phys}}$, must be \"reweighted\" to correct for the artificial reduction in residence probability caused by $\\Delta V$. To restore the unbiased statistical weight, the time spent at $\\mathbf{r}$ must be multiplied by the factor by which its probability was decreased. This factor is the inverse of the probability ratio:\n$$ \\frac{P_0(\\mathbf{r})}{P_b(\\mathbf{r})} = \\frac{\\exp\\left(-U(\\mathbf{r})/(k_B T)\\right)}{\\exp\\left(-U_b(\\mathbf{r})/(k_B T)\\right)} = \\exp\\left(\\frac{U_b(\\mathbf{r}) - U(\\mathbf{r})}{k_B T}\\right) = \\exp\\left(\\frac{\\Delta V(\\mathbf{r})}{k_B T}\\right) $$\nThis is the so-called \"boost factor\". Therefore, the relation between the infinitesimal time increments is:\n$$ dt_{\\text{phys}} = \\exp\\left(\\frac{\\Delta V(\\mathbf{r}(t_b))}{k_B T}\\right) dt_b $$\nThe total accumulated physical time, $t_{\\text{phys}}$, over a biased trajectory of duration $\\tau_b$, is obtained by integrating this differential relation over the biased time $t_b$ from $0$ to $\\tau_b$. Letting $\\Delta V(t)$ represent the time-dependent boost potential along the trajectory, $\\Delta V(\\mathbf{r}(t))$, we have:\n$$ t_{\\text{phys}} = \\int_{0}^{\\tau_b} \\exp\\left(\\frac{\\Delta V(t)}{k_B T}\\right) dt $$\nThis is the required expression.\n\n**2. Calculation of Physical Time $t_{\\text{phys}}$**\n\nWe are given a discrete time series of $\\Delta V(t_k)$ at $N=10$ points, with a uniform time step $\\Delta t = 0.2 \\ \\text{ps}$. We can approximate the integral derived above using a Riemann sum. We will assume that the value $\\Delta V(t_k)$ is representative of the boost potential over the $k$-th time interval of duration $\\Delta t$.\n$$ t_{\\text{phys}} \\approx \\sum_{k=1}^{N} \\exp\\left(\\frac{\\Delta V(t_k)}{k_B T}\\right) \\Delta t $$\nFirst, we calculate the thermal energy $k_B T$ in the appropriate units:\n$$ k_B T = (0.008314462618 \\ \\text{kJ} \\ \\text{mol}^{-1} \\ \\text{K}^{-1}) \\times (300 \\ \\text{K}) \\approx 2.49434 \\ \\text{kJ} \\ \\text{mol}^{-1} $$\nThe given boost potential values $\\{\\Delta V_k\\}_{k=1}^{10}$ are $\\{24.0, 25.0, 23.5, 24.5, 26.0, 25.5, 24.0, 23.0, 22.5, 24.0\\}$ in $\\text{kJ} \\ \\text{mol}^{-1}$. The time step is $\\Delta t = 0.2 \\ \\text{ps}$.\n\nWe compute the arguments of the exponential function, $\\frac{\\Delta V_k}{k_B T}$:\n$$\n\\{9.6217, 10.0227, 9.4212, 9.8222, 10.4237, 10.2232, 9.6217, 9.2207, 9.0202, 9.6217\\}\n$$\nNext, we compute the boost factors, $\\exp(\\frac{\\Delta V_k}{k_B T})$:\n$$\n\\{15088.0, 22530.4, 12347.1, 18436.4, 33644.0, 27533.1, 15088.0, 10099.9, 8266.3, 15088.0\\}\n$$\nThe sum of these boost factors is:\n$$ \\sum_{k=1}^{10} \\exp\\left(\\frac{\\Delta V(t_k)}{k_B T}\\right) \\approx 178121.2 $$\nNow we multiply by the time step $\\Delta t$:\n$$ t_{\\text{phys}} \\approx (178121.2) \\times (0.2 \\ \\text{ps}) = 35624.24 \\ \\text{ps} $$\nThe problem asks for this result in nanoseconds ($\\text{ns}$). Since $1 \\ \\text{ns} = 1000 \\ \\text{ps}$, we have:\n$$ t_{\\text{phys}} \\approx 35.62424 \\ \\text{ns} $$\nRounding to three significant figures, we get $t_{\\text{phys}} = 35.6 \\ \\text{ns}$.\n\n**3. Maximum-Likelihood Estimate of the Unbiased Rate Constant $k_0$**\n\nWe are given that the unbiased exit from the basin is a memoryless process, which implies it follows a Poisson process. The waiting time for the first event in such a process is described by an exponential probability distribution. The probability density function for observing the first exit at time $t$ given an underlying rate constant $k_0$ is:\n$$ f(t | k_0) = k_0 \\exp(-k_0 t) $$\nWe have a single observation of an exit event, which occurred after a total accumulated physical time of $t_{\\text{phys}}$. The likelihood function $L(k_0)$ for this single observation is the probability density evaluated at $t = t_{\\text{phys}}$:\n$$ L(k_0) = k_0 \\exp(-k_0 t_{\\text{phys}}) $$\nTo find the maximum-likelihood estimate (MLE) of $k_0$, denoted $\\hat{k}_0$, we maximize $L(k_0)$. This is equivalent to maximizing the log-likelihood function, $\\ln L(k_0)$:\n$$ \\ln L(k_0) = \\ln(k_0) - k_0 t_{\\text{phys}} $$\nWe find the maximum by taking the derivative with respect to $k_0$ and setting it to zero:\n$$ \\frac{d}{dk_0} \\ln L(k_0) = \\frac{1}{k_0} - t_{\\text{phys}} $$\nSetting the derivative to zero gives the condition for the MLE $\\hat{k}_0$:\n$$ \\frac{1}{\\hat{k}_0} - t_{\\text{phys}} = 0 \\implies \\hat{k}_0 = \\frac{1}{t_{\\text{phys}}} $$\nUsing our calculated value for $t_{\\text{phys}} \\approx 35.62424 \\ \\text{ns}$:\n$$ \\hat{k}_0 = \\frac{1}{35.62424 \\ \\text{ns}} \\approx 0.0280708 \\ \\text{ns}^{-1} $$\nThe problem asks for the rate constant in units of inverse microseconds ($\\mu s^{-1}$). We use the conversion $1 \\ \\text{ns}^{-1} = 10^3 \\ \\mu s^{-1}$:\n$$ \\hat{k}_0 \\approx 0.0280708 \\times 10^3 \\ \\mu s^{-1} = 28.0708 \\ \\mu s^{-1} $$\nRounding to three significant figures, we get $k_0 = 28.1 \\ \\mu s^{-1}$.\n\nWe are asked to report $t_{\\text{phys}}$ in nanoseconds and $k_0$ in $\\mu s^{-1}$. The final rounded values are $35.6$ and $28.1$, respectively.",
            "answer": "$$\\boxed{\\begin{pmatrix} 35.6 & 28.1 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Advanced simulation methods rely on crucial assumptions, and a skilled practitioner must know how to verify them. This practice challenges you to act as a critical scientist by designing a statistical test for a cornerstone of hyperdynamics: the requirement that the bias potential is zero at the transition state. By analyzing simulation data for deviations from this ideal, you will gain experience in the essential art of method validation and diagnostics .",
            "id": "3417464",
            "problem": "In hyperdynamics, a bias potential $\\Delta V(\\mathbf{q})$ is added to raise the energy in long-lived basins while preserving exact transition-state kinetics by enforcing that the bias vanishes in a thin neighborhood of the dividing surface $\\Sigma$ separating metastable regions. Under canonical sampling at temperature $T$, and assuming transition-state theory (TST) is valid, the instantaneous reactive flux across $\\Sigma$ must be unaltered by the bias if and only if $\\Delta V(\\mathbf{q}) \\approx 0$ for $\\mathbf{q} \\in \\Sigma$. To assess whether a given hyperdynamics implementation respects this requirement in practice, consider the following diagnostic: collect the exit configurations $\\{\\mathbf{q}_{i}\\}_{i=1}^{n}$ at the first crossing of $\\Sigma$ for each observed basin escape and record the corresponding bias values $\\Delta V_{i} = \\Delta V(\\mathbf{q}_{i})$. In an ideal implementation, the distribution of $\\Delta V_{i}$ at exit should be centered at zero.\n\nYou are given a time-ordered sample $\\{\\Delta V_{i}\\}_{i=1}^{n}$ from a single long trajectory in which exits recur, measured at the instant of first crossing for each exit event. Assume:\n1) the trajectory is in a stationary canonical regime at temperature $T$,\n2) the exit configurations approximate samples from a steady flux across $\\Sigma$,\n3) the serial dependence of $\\{\\Delta V_{i}\\}$ can be modeled as a first-order autoregressive process with lag-$1$ autocorrelation coefficient $\\hat{\\rho}$.\n\nFormulate a two-sided hypothesis test for\n$$\nH_{0}: \\ \\mathbb{E}[\\Delta V_{\\mathrm{exit}}]=0\n\\quad \\text{versus} \\quad\nH_{1}: \\ \\mathbb{E}[\\Delta V_{\\mathrm{exit}}]\\neq 0,\n$$\nusing a large-sample normal approximation for the mean that accounts for autocorrelation through the integrated autocorrelation time under the autoregressive order-one model. Then, compute the two-sided $p$-value for the following dataset summary, where energies are reported as multiples of the thermal energy $k_B T$:\n- sample size $n=80$,\n- sample mean $\\bar{\\Delta V}=0.018$,\n- sample standard deviation $s=0.052$,\n- estimated lag-$1$ autocorrelation $\\hat{\\rho}=0.70$.\n\nState any intermediate expressions you use, and report the final two-sided $p$-value as a pure number (no units). Round your answer to four significant figures.",
            "solution": "The problem requires performing a two-sided hypothesis test to determine if the mean of the observed bias potentials at the dividing surface, $\\mathbb{E}[\\Delta V_{\\mathrm{exit}}]$, is statistically consistent with zero. The sample data $\\{\\Delta V_i\\}$ is a time-ordered series, and its serial dependence must be accounted for in the statistical test.\n\nFirst, we state the null and alternative hypotheses:\n$$\nH_0: \\mu = 0\n$$\n$$\nH_1: \\mu \\neq 0\n$$\nwhere $\\mu = \\mathbb{E}[\\Delta V_{\\mathrm{exit}}]$.\n\nThe standard procedure for testing the mean of a large sample is to use a $z$-test. The test statistic $z$ is given by:\n$$\nz = \\frac{\\bar{X} - \\mu_0}{\\sigma_{\\bar{X}}}\n$$\nwhere $\\bar{X}$ is the sample mean, $\\mu_0$ is the hypothesized population mean (in this case, $\\mu_0=0$), and $\\sigma_{\\bar{X}}$ is the standard error of the sample mean.\n\nFor a sample of size $n$ with independent and identically distributed (i.i.d.) observations, the variance of the sample mean is $\\sigma^2_{\\bar{X}} = \\frac{\\sigma^2}{n}$, where $\\sigma^2$ is the variance of the underlying distribution. However, the problem states that the data $\\{\\Delta V_i\\}$ are serially correlated, following a first-order autoregressive (AR(1)) process. In the presence of autocorrelation, the variance of the sample mean is larger than the i.i.d. case and is given by:\n$$\n\\sigma^2_{\\bar{X}} = \\frac{\\sigma^2}{n} g\n$$\nwhere $g$ is the statistical inefficiency, which quantifies the reduction in effective sample size due to correlation. The effective sample size is $n_{\\mathrm{eff}} = n/g$. The statistical inefficiency is defined for a stationary process as:\n$$\ng = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k\n$$\nwhere $\\rho_k$ is the autocorrelation of the time series at lag $k$.\n\nThe problem specifies an AR(1) model, for which the autocorrelation at lag $k$ is given by $\\rho_k = \\rho^k$, where $\\rho$ is the lag-$1$ autocorrelation coefficient. Substituting this into the expression for $g$:\n$$\ng = 1 + 2 \\sum_{k=1}^{\\infty} \\rho^k\n$$\nThe summation is a geometric series, which converges for $|\\rho|<1$ to $\\sum_{k=1}^{\\infty} \\rho^k = \\frac{\\rho}{1-\\rho}$. Therefore, the statistical inefficiency for an AR(1) process is:\n$$\ng = 1 + 2 \\left( \\frac{\\rho}{1-\\rho} \\right) = \\frac{1-\\rho+2\\rho}{1-\\rho} = \\frac{1+\\rho}{1-\\rho}\n$$\nThe population variance $\\sigma^2$ is unknown and is estimated by the sample variance $s^2$. The estimated standard error of the mean, $\\hat{\\sigma}_{\\bar{\\Delta V}}$, is then:\n$$\n\\hat{\\sigma}_{\\bar{\\Delta V}} = \\sqrt{\\frac{s^2}{n_{\\mathrm{eff}}}} = \\sqrt{\\frac{s^2 g}{n}} = \\frac{s}{\\sqrt{n}} \\sqrt{g}\n$$\nSubstituting the expression for $g$ and using the estimated lag-$1$ autocorrelation $\\hat{\\rho}$, our test statistic becomes:\n$$\nz = \\frac{\\bar{\\Delta V} - 0}{\\hat{\\sigma}_{\\bar{\\Delta V}}} = \\frac{\\bar{\\Delta V}}{\\frac{s}{\\sqrt{n}} \\sqrt{\\frac{1+\\hat{\\rho}}{1-\\hat{\\rho}}}}\n$$\nWe are given the following data from the simulation:\n- Sample size $n=80$\n- Sample mean $\\bar{\\Delta V}=0.018$\n- Sample standard deviation $s=0.052$\n- Estimated lag-$1$ autocorrelation $\\hat{\\rho}=0.70$\n\nFirst, we compute the estimated statistical inefficiency, $\\hat{g}$:\n$$\n\\hat{g} = \\frac{1+\\hat{\\rho}}{1-\\hat{\\rho}} = \\frac{1+0.70}{1-0.70} = \\frac{1.7}{0.3} = \\frac{17}{3} \\approx 5.6667\n$$\nThis value indicates that the effective number of independent samples is significantly smaller than the total sample size $n=80$, precisely $n_{\\mathrm{eff}} = n/\\hat{g} = 80 / (17/3) \\approx 14.1$.\n\nNext, we compute the estimated standard error of the mean:\n$$\n\\hat{\\sigma}_{\\bar{\\Delta V}} = \\frac{s}{\\sqrt{n}} \\sqrt{\\hat{g}} = \\frac{0.052}{\\sqrt{80}} \\sqrt{\\frac{17}{3}}\n$$\n$$\n\\hat{\\sigma}_{\\bar{\\Delta V}} \\approx \\frac{0.052}{8.94427} \\times 2.38048 \\approx 0.005814 \\times 2.38048 \\approx 0.013839\n$$\nNow, we can compute the $z$-statistic:\n$$\nz = \\frac{\\bar{\\Delta V}}{\\hat{\\sigma}_{\\bar{\\Delta V}}} = \\frac{0.018}{0.013839} \\approx 1.3006\n$$\nThe final step is to calculate the two-sided $p$-value. For a $z$-statistic of $1.3006$, the $p$-value is the probability of observing a value of the standard normal variable $Z$ that is at least as extreme, i.e., $P(|Z| \\ge |1.3006|)$. This is calculated as:\n$$\np = 2 \\times P(Z \\le -|z|) = 2 \\times \\Phi(-1.3006)\n$$\nwhere $\\Phi$ is the cumulative distribution function (CDF) of the standard normal distribution. Using standard tables or a computational tool for the normal CDF, we find:\n$$\n\\Phi(-1.3006) \\approx 0.0967\n$$\nTherefore, the two-sided $p$-value is:\n$$\np \\approx 2 \\times 0.0967 = 0.1934\n$$\nA $p$-value of $0.1934$ is typically greater than common significance levels (e.g., $\\alpha = 0.05$ or $\\alpha = 0.01$). Thus, based on this dataset, there is insufficient evidence to reject the null hypothesis that the mean bias potential at the dividing surface is zero. The hyperdynamics implementation appears to be performing correctly with respect to this diagnostic.\n\nRounding the final answer to four significant figures as requested, the $p$-value is $0.1934$.",
            "answer": "$$\n\\boxed{0.1934}\n$$"
        },
        {
            "introduction": "Shifting our focus to Temperature-Accelerated Dynamics (TAD), this problem addresses the method's predictive power and its sensitivity to model parameters. TAD extrapolates high-temperature dynamics to low-temperature timescales using the Arrhenius law, but the parameters of this law are never known with perfect certainty. This exercise will guide you through an uncertainty propagation analysis to quantify how small errors in barrier heights ($E$) and prefactors ($\\nu$) can impact the final predicted waiting times, a key skill for assessing the reliability of simulation results .",
            "id": "3417490",
            "problem": "Consider Temperature-Accelerated Dynamics (TAD) in molecular dynamics, where rare-event kinetics are assumed to follow Arrhenius behavior with rate $k(T) = \\nu \\exp\\!\\left(-\\frac{E}{k_{B} T}\\right)$ for temperature $T$, barrier height $E$, and attempt frequency (prefactor) $\\nu$. For a single dominant escape pathway at a low temperature $T_{L}$, the mean waiting time is $\\tau^{L} = \\frac{1}{k(T_{L})}$. In practice, the barrier height $E$ and the prefactor $\\nu$ are uncertain due to finite sampling and modeling approximations. Assume that these uncertainties are small, statistically independent, and characterized by standard deviations $\\sigma_{E}$ and $\\sigma_{\\nu}$, respectively. Using first-order (linearized) uncertainty propagation justified by differentiability and the smallness of perturbations, derive a closed-form analytic expression for the relative standard uncertainty $\\frac{\\sigma_{\\tau^{L}}}{\\tau^{L}}$ in terms of $\\sigma_{E}$, $\\sigma_{\\nu}$, $\\nu$, $k_{B}$, and $T_{L}$.\n\nState clearly any assumptions you make about smoothness and independence, and base your derivation on fundamental principles: Arrhenius kinetics for rare events and the definition of mean waiting time $\\tau^{L} = \\frac{1}{k(T_{L})}$. Express the final answer as a single closed-form analytic expression. No rounding is required. The final result is dimensionless; do not attach units to the final answer.",
            "solution": "The problem is scientifically grounded, well-posed, and self-contained. It presents a standard application of first-order uncertainty propagation to the Arrhenius rate equation, a fundamental concept in chemical kinetics and molecular dynamics. The necessary assumptions—small, statistically independent uncertainties—are explicitly provided, justifying the requested methodology. Therefore, the problem is valid and a solution can be derived.\n\nThe problem asks for the relative standard uncertainty $\\frac{\\sigma_{\\tau^{L}}}{\\tau^{L}}$ of the mean waiting time $\\tau^{L}$. The waiting time is given as the inverse of the rate constant $k(T_{L})$, which follows the Arrhenius law.\nThe rate constant at a low temperature $T_{L}$ is given by:\n$$k(T_{L}) = \\nu \\exp\\left(-\\frac{E}{k_{B} T_{L}}\\right)$$\nwhere $E$ is the energy barrier, $\\nu$ is the attempt frequency, and $k_{B}$ is the Boltzmann constant.\n\nThe mean waiting time $\\tau^{L}$ is therefore a function of the two uncertain parameters, $E$ and $\\nu$:\n$$\\tau^{L}(E, \\nu) = \\frac{1}{k(T_{L})} = \\frac{1}{\\nu \\exp\\left(-\\frac{E}{k_{B} T_{L}}\\right)} = \\frac{1}{\\nu} \\exp\\left(\\frac{E}{k_{B} T_{L}}\\right)$$\n\nWe are tasked with finding the uncertainty in $\\tau^{L}$ given the standard deviations $\\sigma_{E}$ and $\\sigma_{\\nu}$ for $E$ and $\\nu$, respectively. The problem specifies the use of first-order (linearized) uncertainty propagation. The general formula for the variance, $(\\sigma_{f})^2$, of a function $f(x_1, x_2, \\dots, x_n)$ of several statistically independent variables $x_i$ with variances $(\\sigma_{x_i})^2$ is:\n$$(\\sigma_{f})^2 \\approx \\sum_{i=1}^{n} \\left( \\frac{\\partial f}{\\partial x_i} \\right)^2 (\\sigma_{x_i})^2$$\n\nThis approximation is valid when the function $f$ is smooth (differentiable) and the uncertainties $\\sigma_{x_i}$ are small. The function $\\tau^L(E, \\nu)$ is differentiable with respect to both $E$ and $\\nu$ (for $\\nu > 0$, which is physically required). The problem states that uncertainties are small and that $E$ and $\\nu$ are statistically independent, thus the conditions for applying this formula are met.\n\nIn our case, $f = \\tau^{L}$, and the variables are $E$ and $\\nu$. The variance of $\\tau^{L}$ is given by:\n$$(\\sigma_{\\tau^{L}})^2 \\approx \\left( \\frac{\\partial \\tau^{L}}{\\partial E} \\right)^2 (\\sigma_{E})^2 + \\left( \\frac{\\partial \\tau^{L}}{\\partial \\nu} \\right)^2 (\\sigma_{\\nu})^2$$\n\nFirst, we compute the partial derivatives of $\\tau^{L}(E, \\nu)$:\n\n1.  Partial derivative with respect to the energy barrier $E$:\n    $$\\frac{\\partial \\tau^{L}}{\\partial E} = \\frac{\\partial}{\\partial E} \\left[ \\frac{1}{\\nu} \\exp\\left(\\frac{E}{k_{B} T_{L}}\\right) \\right]$$\n    Using the chain rule for differentiation, we get:\n    $$\\frac{\\partial \\tau^{L}}{\\partial E} = \\frac{1}{\\nu} \\exp\\left(\\frac{E}{k_{B} T_{L}}\\right) \\cdot \\frac{1}{k_{B} T_{L}}$$\n    Recognizing that $\\frac{1}{\\nu} \\exp\\left(\\frac{E}{k_{B} T_{L}}\\right)$ is just $\\tau^{L}$, we can write:\n    $$\\frac{\\partial \\tau^{L}}{\\partial E} = \\frac{\\tau^{L}}{k_{B} T_{L}}$$\n\n2.  Partial derivative with respect to the attempt frequency $\\nu$:\n    $$\\frac{\\partial \\tau^{L}}{\\partial \\nu} = \\frac{\\partial}{\\partial \\nu} \\left[ \\nu^{-1} \\exp\\left(\\frac{E}{k_{B} T_{L}}\\right) \\right]$$\n    Using the power rule for differentiation, we get:\n    $$\\frac{\\partial \\tau^{L}}{\\partial \\nu} = (-1)\\nu^{-2} \\exp\\left(\\frac{E}{k_{B} T_{L}}\\right) = -\\frac{1}{\\nu^2} \\exp\\left(\\frac{E}{k_{B} T_{L}}\\right)$$\n    We can rewrite this in terms of $\\tau^{L}$:\n    $$\\frac{\\partial \\tau^{L}}{\\partial \\nu} = -\\frac{1}{\\nu} \\left( \\frac{1}{\\nu} \\exp\\left(\\frac{E}{k_{B} T_{L}}\\right) \\right) = -\\frac{\\tau^{L}}{\\nu}$$\n\nNow, we substitute these partial derivatives back into the variance formula:\n$$(\\sigma_{\\tau^{L}})^2 \\approx \\left( \\frac{\\tau^{L}}{k_{B} T_{L}} \\right)^2 (\\sigma_{E})^2 + \\left( -\\frac{\\tau^{L}}{\\nu} \\right)^2 (\\sigma_{\\nu})^2$$\n$$(\\sigma_{\\tau^{L}})^2 \\approx (\\tau^{L})^2 \\left( \\frac{\\sigma_{E}}{k_{B} T_{L}} \\right)^2 + (\\tau^{L})^2 \\left( \\frac{\\sigma_{\\nu}}{\\nu} \\right)^2$$\n\nTo find the relative standard uncertainty, $\\frac{\\sigma_{\\tau^{L}}}{\\tau^{L}}$, we first find the relative variance by dividing the entire equation by $(\\tau^{L})^2$:\n$$\\frac{(\\sigma_{\\tau^{L}})^2}{(\\tau^{L})^2} \\approx \\left( \\frac{\\sigma_{E}}{k_{B} T_{L}} \\right)^2 + \\left( \\frac{\\sigma_{\\nu}}{\\nu} \\right)^2$$\nThis expression is the square of the relative standard uncertainty.\n\nFinally, taking the square root of both sides gives the desired expression for the relative standard uncertainty. Since standard uncertainty is a non-negative quantity, we take the positive root:\n$$\\frac{\\sigma_{\\tau^{L}}}{\\tau^{L}} \\approx \\sqrt{ \\left( \\frac{\\sigma_{E}}{k_{B} T_{L}} \\right)^2 + \\left( \\frac{\\sigma_{\\nu}}{\\nu} \\right)^2 }$$\n\nThis expression shows that the relative uncertainty in the waiting time is the quadratic sum of two terms: a term related to the uncertainty in the activation energy and the relative uncertainty in the prefactor. The contribution from the energy barrier's uncertainty is scaled by the thermal energy $k_B T_L$. This is the final closed-form analytic expression as requested.",
            "answer": "$$\\boxed{\\sqrt{ \\left( \\frac{\\sigma_{E}}{k_{B} T_{L}} \\right)^{2} + \\left( \\frac{\\sigma_{\\nu}}{\\nu} \\right)^{2} }}$$"
        }
    ]
}