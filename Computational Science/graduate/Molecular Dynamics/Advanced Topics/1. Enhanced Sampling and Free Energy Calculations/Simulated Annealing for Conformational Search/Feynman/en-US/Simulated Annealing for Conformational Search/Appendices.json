{
    "hands_on_practices": [
        {
            "introduction": "The effectiveness of simulated annealing hinges on setting the temperature high enough to overcome relevant energy barriers. This exercise provides direct, quantitative practice in using the Metropolis criterion, based on the Boltzmann distribution, to calculate the minimum temperature required to cross a given energy barrier $\\Delta E$ with a target probability. Mastering this calculation is a fundamental step in designing a rational and effective annealing schedule. ",
            "id": "3445992",
            "problem": "A model peptide has three side-chain dihedral angles whose transitions between rotameric states are dominated by torsional barriers. The barrier heights, defined as the energy increase required to reach the transition state relative to the current rotamer minimum, are measured as $\\Delta E_{\\chi_1} = 12 \\ \\mathrm{kJ/mol}$, $\\Delta E_{\\chi_2} = 18 \\ \\mathrm{kJ/mol}$, and $\\Delta E_{\\chi_3} = 25 \\ \\mathrm{kJ/mol}$. Consider a simulated annealing protocol for conformational search within molecular dynamics that employs the Metropolis acceptance rule with symmetric proposals for dihedral rotations. \n\nUse the following fundamental principles:\n- The Metropolis acceptance probability for a proposed move that increases the energy by $\\Delta U$ at temperature $T$ is $p_{\\mathrm{acc}} = \\exp(-\\Delta U/(k_B T))$, where $k_B$ is the Boltzmann constant.\n- When barrier heights are specified per mole, the relevant thermal factor is the molar gas constant $R$ defined by $R = N_A k_B$, so that the acceptance probability for crossing a molar barrier $\\Delta E$ is $p(T) = \\exp(-\\Delta E/(R T))$.\n- For $N$ statistically independent proposals at fixed temperature, each with success probability $p(T)$, the probability of at least one successful crossing in the block is $P_{\\mathrm{block}} = 1 - (1 - p(T))^{N}$.\n\nAssume that proposal independence across the barrier at fixed $T$ is a reasonable approximation within a block of $N = 100$ proposals. For each barrier $\\Delta E_{\\chi_i}$, compute the temperature $T_i$ at which the probability of crossing the barrier at least once in $N = 100$ proposals satisfies $P_{\\mathrm{block}} = 0.10$. Then, design a geometric cooling schedule $T_k = T_0 \\alpha^k$ with $0 < \\alpha < 1$ and integer $k \\geq 0$ that starts at a temperature $T_0$ sufficient to visit the highest barrier and then reduces in stages to facilitate visiting all rotamers associated with $\\chi_2$ and $\\chi_1$ before quenching.\n\nFinally, determine the minimal initial temperature $T_0$ (in Kelvin) that guarantees the highest barrier $\\Delta E_{\\chi_3}$ is crossed with $P_{\\mathrm{block}} = 0.10$ over $N = 100$ proposals. Express the final $T_0$ in Kelvin and round your answer to four significant figures.",
            "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\nThe verbatim givens extracted from the problem statement are as follows:\n-   Peptide side-chain torsional barrier heights: $\\Delta E_{\\chi_1} = 12 \\ \\mathrm{kJ/mol}$, $\\Delta E_{\\chi_2} = 18 \\ \\mathrm{kJ/mol}$, and $\\Delta E_{\\chi_3} = 25 \\ \\mathrm{kJ/mol}$.\n-   The protocol is simulated annealing using the Metropolis acceptance rule.\n-   Metropolis acceptance probability for an energy increase $\\Delta U$ at temperature $T$: $p_{\\mathrm{acc}} = \\exp(-\\Delta U/(k_B T))$.\n-   Boltzmann constant is denoted $k_B$.\n-   Acceptance probability for a molar barrier $\\Delta E$: $p(T) = \\exp(-\\Delta E/(R T))$, with the molar gas constant $R = N_A k_B$.\n-   Number of statistically independent proposals in a block: $N = 100$.\n-   Probability of at least one successful crossing in a block of $N$ proposals: $P_{\\mathrm{block}} = 1 - (1 - p(T))^{N}$.\n-   Target probability for at least one crossing: $P_{\\mathrm{block}} = 0.10$.\n-   Geometric cooling schedule form: $T_k = T_0 \\alpha^k$ for $0 < \\alpha < 1$ and integer $k \\geq 0$.\n-   Objective: Determine the minimal initial temperature $T_0$ (in Kelvin) for the highest barrier, $\\Delta E_{\\chi_3}$, to be crossed with $P_{\\mathrm{block}} = 0.10$, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity:\n-   **Scientifically Grounded**: The problem is firmly rooted in the principles of statistical mechanics and computational chemistry. The concepts of torsional energy barriers, simulated annealing, the Metropolis-Hastings algorithm, and the Boltzmann distribution are cornerstones of molecular dynamics and conformational analysis. All provided equations and principles are standard and correct.\n-   **Well-Posed**: The problem is well-posed. It provides a clear objective (calculate $T_0$) with all necessary mathematical relationships and numerical values to achieve a unique, meaningful solution. The context provided about the full cooling schedule serves to define the role of $T_0$ but does not introduce ambiguity, as the final task is explicitly isolated.\n-   **Objective**: The problem is stated in precise, quantitative, and unbiased language.\n-   **Consistency and Completeness**: The problem is self-contained and internally consistent. Although the value of the molar gas constant $R$ is not explicitly provided, it is a universal physical constant, and its use is standard practice in such problems. The problem does not contain contradictory constraints.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. It is a standard, well-defined problem in physical chemistry or biophysics. A complete solution will now be derived.\n\nThe main objective is to determine the initial temperature $T_0$ of a simulated annealing schedule. This temperature must be high enough to allow the system to overcome the highest energy barrier, $\\Delta E_{\\chi_3}$, with a specified probability. The condition is that the probability of at least one successful crossing in a block of $N=100$ proposals is $P_{\\mathrm{block}} = 0.10$.\n\nThe probability of at least one successful crossing, $P_{\\mathrm{block}}$, is related to the single-trial success probability, $p(T)$, by the given formula:\n$$P_{\\mathrm{block}} = 1 - (1 - p(T))^{N}$$\n\nWe are given $P_{\\mathrm{block}} = 0.10$ and $N = 100$. We can rearrange this equation to solve for the required single-trial probability, $p(T_0)$:\n$$1 - P_{\\mathrm{block}} = (1 - p(T_0))^{N}$$\n$$(1 - P_{\\mathrm{block}})^{1/N} = 1 - p(T_0)$$\n$$p(T_0) = 1 - (1 - P_{\\mathrm{block}})^{1/N}$$\n\nThe single-trial probability of accepting a move that increases the energy by the barrier height $\\Delta E$ is given by the Metropolis criterion, adapted for molar energies:\n$$p(T) = \\exp\\left(-\\frac{\\Delta E}{R T}\\right)$$\n\nEquating the two expressions for $p(T_0)$, we have:\n$$\\exp\\left(-\\frac{\\Delta E}{R T_0}\\right) = 1 - (1 - P_{\\mathrm{block}})^{1/N}$$\n\nTo solve for $T_0$, we take the natural logarithm of both sides:\n$$-\\frac{\\Delta E}{R T_0} = \\ln\\left(1 - (1 - P_{\\mathrm{block}})^{1/N}\\right)$$\n\nFinally, we isolate $T_0$:\n$$T_0 = -\\frac{\\Delta E}{R \\ln\\left(1 - (1 - P_{\\mathrm{block}})^{1/N}\\right)}$$\n\nThis is the general formula for the temperature required to cross a barrier $\\Delta E$. The problem specifies that $T_0$ is the initial temperature, designed to be high enough to traverse the highest energy barrier, which is $\\Delta E_{\\chi_3} = 25 \\ \\mathrm{kJ/mol}$.\n\nWe substitute the given values into this derived expression:\n-   $\\Delta E = \\Delta E_{\\chi_3} = 25 \\ \\mathrm{kJ/mol} = 2.5 \\times 10^4 \\ \\mathrm{J/mol}$\n-   $N = 100$\n-   $P_{\\mathrm{block}} = 0.10$\n-   The molar gas constant, $R$, is a fundamental constant. We will use its CODATA value, $R \\approx 8.314462618 \\ \\mathrm{J \\cdot mol^{-1} \\cdot K^{-1}}$.\n\nThe expression for $T_0$ becomes:\n$$T_0 = -\\frac{2.5 \\times 10^4}{R \\ln\\left(1 - (1 - 0.10)^{1/100}\\right)}$$\n$$T_0 = -\\frac{2.5 \\times 10^4}{R \\ln\\left(1 - (0.9)^{0.01}\\right)}$$\n\nNow, we perform the numerical calculation.\nFirst, the term in the logarithm:\n$$(0.9)^{0.01} \\approx 0.99894709$$\n$$1 - (0.9)^{0.01} \\approx 1 - 0.99894709 = 0.00105291$$\nThe natural logarithm of this value is:\n$$\\ln(0.00105291) \\approx -6.85549$$\nSubstituting this into the equation for $T_0$:\n$$T_0 = -\\frac{2.5 \\times 10^4 \\ \\mathrm{J/mol}}{8.31446 \\ \\mathrm{J \\cdot mol^{-1} \\cdot K^{-1}} \\times (-6.85549)}$$\n$$T_0 = \\frac{2.5 \\times 10^4}{8.31446 \\times 6.85549} \\ \\mathrm{K}$$\n$$T_0 = \\frac{2.5 \\times 10^4}{56.9935} \\ \\mathrm{K}$$\n$$T_0 \\approx 438.647 \\ \\mathrm{K}$$\n\nThe problem requires the answer to be rounded to four significant figures.\n$$T_0 \\approx 438.6 \\ \\mathrm{K}$$\nThis is the minimal initial temperature required for the simulated annealing protocol to ensure that the highest conformational barrier can be crossed with the specified probability.",
            "answer": "$$\\boxed{438.6}$$"
        },
        {
            "introduction": "A fixed computational budget presents a classic dilemma in conformational search: is it better to perform one long, in-depth simulation or many shorter, independent ones? This problem addresses this strategic question by modeling the trade-off between the annealing length $L$ of a single run and the number of restarts $R$. By maximizing the total probability of success, you will derive an optimal resource allocation strategy, a crucial skill for designing efficient computational experiments. ",
            "id": "3445986",
            "problem": "In a conformational search workflow within Molecular Dynamics (MD) using Simulated Annealing (SA), you have a fixed total computational budget of $B$ elementary integration steps to allocate between $R$ independent SA restarts and the annealing length $L$ of each restart. Each restart incurs a deterministic initialization overhead of $L_{0}$ steps (for thermostat reinitialization, velocity randomization, and local minimization), after which $L$ steps are used for the annealing schedule. Thus the resource constraint is $R(L + L_{0}) = B$. Assume that the restarts are statistically independent and that an empirical characterization of a single-restart success probability (discovering the true global minimum in a single restart of length $L$) is\n$$\np(L) = 1 - \\exp\\!\\big(-a\\, L^{\\beta}\\big),\n$$\nwith $a > 0$ and $0 < \\beta < 1$ constants describing the landscape-dependent kinetics. Using only the independence of restarts and the budget constraint, derive from first principles the allocation $(R,L)$ that maximizes the probability of at least one success within the budget $B$, and then evaluate the optimal number of restarts for the specific parameters $B = 2.5 \\times 10^{6}$, $L_{0} = 2.0 \\times 10^{3}$, $a = 7.5 \\times 10^{-4}$, and $\\beta = \\tfrac{1}{2}$. Express your final answer as an exact integer equal to the optimal number of restarts $R^{\\star}$ implied by the continuous optimum under these parameters (assume that $R^{\\star}$ happens to be an integer for the provided data). No units are required for the final answer. Do not round; report the exact integer.",
            "solution": "The user wants me to solve the following problem:\nIn a conformational search workflow within Molecular Dynamics (MD) using Simulated Annealing (SA), you have a fixed total computational budget of $B$ elementary integration steps to allocate between $R$ independent SA restarts and the annealing length $L$ of each restart. Each restart incurs a deterministic initialization overhead of $L_{0}$ steps (for thermostat reinitialization, velocity randomization, and local minimization), after which $L$ steps are used for the annealing schedule. Thus the resource constraint is $R(L + L_{0}) = B$. Assume that the restarts are statistically independent and that an empirical characterization of a single-restart success probability (discovering the true global minimum in a single restart of length $L$) is\n$$\np(L) = 1 - \\exp\\!\\big(-a\\, L^{\\beta}\\big),\n$$\nwith $a > 0$ and $0 < \\beta < 1$ constants describing the landscape-dependent kinetics. Using only the independence of restarts and the budget constraint, derive from first principles the allocation $(R,L)$ that maximizes the probability of at least one success within the budget $B$, and then evaluate the optimal number of restarts for the specific parameters $B = 2.5 \\times 10^{6}$, $L_{0} = 2.0 \\times 10^{3}$, $a = 7.5 \\times 10^{-4}$, and $\\beta = \\tfrac{1}{2}$. Express your final answer as an exact integer equal to the optimal number of restarts $R^{\\star}$ implied by the continuous optimum under these parameters (assume that $R^{\\star}$ happens to be an integer for the provided data). No units are required for the final answer. Do not round; report the exact integer.\n\n### Step 1: Extract Givens\n-   Total computational budget: $B$\n-   Number of independent SA restarts: $R$\n-   Annealing length per restart: $L$\n-   Initialization overhead per restart: $L_0$\n-   Budget constraint: $R(L + L_0) = B$\n-   Single-restart success probability: $p(L) = 1 - \\exp(-a L^{\\beta})$\n-   Constants: $a > 0$, $0 < \\beta < 1$\n-   Specific parameter values: $B = 2.5 \\times 10^{6}$, $L_0 = 2.0 \\times 10^{3}$, $a = 7.5 \\times 10^{-4}$, $\\beta = \\frac{1}{2}$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the fields of computational chemistry and optimization theory. Simulated annealing is a standard heuristic for finding global minima. The problem describes a realistic trade-off between the number of independent searches ($R$) and the length of each search ($L$) under a fixed computational budget. The functional form for the success probability $p(L)$ is a plausible empirical model. The problem is self-contained, with all necessary data and constraints provided. The language is precise and objective. There are no contradictions, ambiguities, or violations of scientific principles.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete, reasoned solution will be provided.\n\n### Solution Derivation\n\nThe objective is to maximize the probability of achieving at least one success across $R$ independent restarts. The probability of success for a single restart of length $L$ is given by $p(L) = 1 - \\exp(-a L^{\\beta})$. Consequently, the probability of failure for a single restart is $1 - p(L) = \\exp(-a L^{\\beta})$.\n\nSince the $R$ restarts are statistically independent, the probability that all $R$ restarts fail is the product of their individual failure probabilities:\n$$\nP_{\\text{all fail}} = (1 - p(L))^R = \\left( \\exp(-a L^{\\beta}) \\right)^R = \\exp(-R a L^{\\beta})\n$$\nThe probability of at least one success, $P_{\\text{success}}$, is the complement of all restarts failing:\n$$\nP_{\\text{success}}(R,L) = 1 - P_{\\text{all fail}} = 1 - \\exp(-R a L^{\\beta})\n$$\nTo maximize $P_{\\text{success}}$, we must maximize the argument of the exponential term, $R a L^{\\beta}$. Since $a$ is a positive constant, this is equivalent to maximizing the function $f(R,L) = R L^{\\beta}$ subject to the budget constraint $R(L + L_0) = B$.\n\nFor this optimization, we treat $R$ and $L$ as continuous positive variables. The constraint can be used to express one variable in terms of the other. Let us express $L$ as a function of $R$:\n$$\nL(R) = \\frac{B}{R} - L_0\n$$\nFor a physically meaningful annealing process, we must have $L > 0$, which implies $\\frac{B}{R} > L_0$, or $R < \\frac{B}{L_0}$.\n\nWe can now write the function to be maximized in terms of a single variable, $R$:\n$$\nf(R) = R \\left( \\frac{B}{R} - L_0 \\right)^{\\beta}\n$$\nTo find the optimal number of restarts, $R^{\\star}$, we differentiate $f(R)$ with respect to $R$ and set the derivative to zero. We use the product rule for differentiation, $\\frac{d}{dR}(uv) = u \\frac{dv}{dR} + v \\frac{du}{dR}$. Let $u(R) = R$ and $v(R) = (\\frac{B}{R} - L_0)^{\\beta}$.\n$$\n\\frac{du}{dR} = 1\n$$\n$$\n\\frac{dv}{dR} = \\beta \\left( \\frac{B}{R} - L_0 \\right)^{\\beta - 1} \\cdot \\left( -\\frac{B}{R^2} \\right)\n$$\nThe derivative of $f(R)$ is:\n$$\n\\frac{df}{dR} = (1) \\cdot \\left( \\frac{B}{R} - L_0 \\right)^{\\beta} + R \\cdot \\left[ \\beta \\left( \\frac{B}{R} - L_0 \\right)^{\\beta - 1} \\left( -\\frac{B}{R^2} \\right) \\right]\n$$\nSetting $\\frac{df}{dR} = 0$ to find the extremum:\n$$\n\\left( \\frac{B}{R} - L_0 \\right)^{\\beta} - \\frac{\\beta B}{R} \\left( \\frac{B}{R} - L_0 \\right)^{\\beta - 1} = 0\n$$\nSince $L = \\frac{B}{R} - L_0 > 0$, we can divide the equation by $(\\frac{B}{R} - L_0)^{\\beta - 1}$:\n$$\n\\left( \\frac{B}{R} - L_0 \\right) - \\frac{\\beta B}{R} = 0\n$$\nRearranging the terms to solve for $R$:\n$$\n\\frac{B}{R} - \\frac{\\beta B}{R} = L_0\n$$\n$$\n\\frac{B}{R} (1 - \\beta) = L_0\n$$\nThis gives the optimal number of restarts, $R^{\\star}$:\n$$\nR^{\\star} = \\frac{B(1 - \\beta)}{L_0}\n$$\nThis expression gives the optimal number of restarts $R^{\\star}$ as a function of the budget $B$, the overhead $L_0$, and the kinetic parameter $\\beta$. Notably, the optimum allocation is independent of the parameter $a$.\n\nNow, we substitute the given numerical values to find the specific value of $R^{\\star}$:\n-   $B = 2.5 \\times 10^6$\n-   $L_0 = 2.0 \\times 10^3$\n-   $\\beta = \\frac{1}{2}$\n\n$$\nR^{\\star} = \\frac{(2.5 \\times 10^6) \\left(1 - \\frac{1}{2}\\right)}{2.0 \\times 10^3}\n$$\n$$\nR^{\\star} = \\frac{(2.5 \\times 10^6) \\left(\\frac{1}{2}\\right)}{2.0 \\times 10^3}\n$$\n$$\nR^{\\star} = \\frac{1.25 \\times 10^6}{2.0 \\times 10^3}\n$$\n$$\nR^{\\star} = \\frac{1.25}{2.0} \\times 10^{6-3}\n$$\n$$\nR^{\\star} = 0.625 \\times 10^3\n$$\n$$\nR^{\\star} = 625\n$$\nThe problem states to assume $R^{\\star}$ is an integer, and our calculation yields exactly $625$. Therefore, the optimal number of restarts is $625$.",
            "answer": "$$\\boxed{625}$$"
        },
        {
            "introduction": "Simulated annealing can be driven by different underlying engines, most commonly Molecular Dynamics (MD) or Monte Carlo (MC). This advanced practice delves into the crucial question of how this choice affects the search process, particularly the nature of the transition pathways explored. You will implement both SA-MD and SA-MC, and then apply committor analysis—a rigorous method from statistical mechanics—to quantify and compare the dynamical biases of the paths generated by each algorithm. ",
            "id": "3446006",
            "problem": "You are asked to design and compare two simulated annealing strategies for exploring a two-dimensional conformational landscape, and to quantify a dynamical bias via committor analysis. The comparison must be performed on a toy two-dimensional potential energy surface that has multiple minima and saddle points. The final output must be produced by a single, complete, runnable program.\n\nConstruct a smooth two-dimensional potential energy function $V(x,y)$ and its gradient $\\nabla V(x,y)$ on $\\mathbb{R}^2$ starting from a standard parametric form that is known to generate multiple minima and saddle points. Use the following well-tested Müller–Brown construction with an overall energy scale factor $s$:\n$$\nV(x,y) \\equiv s \\sum_{i=1}^{4} A_i \\exp\\left(a_i (x-x_i)^2 + b_i (x-x_i)(y-y_i) + c_i (y-y_i)^2\\right),\n$$\nwith constants\n$$\nA = \\left[-200,-100,-170,15\\right],\\quad a=\\left[-1,-1,-6.5,0.7\\right],\\quad b=\\left[0,0,11,0.6\\right],\\quad c=\\left[-10,-10,-6.5,0.7\\right],\n$$\nand\n$$\nx_0=\\left[1,0,-0.5,-1\\right],\\quad y_0=\\left[0,0.5,1.5,1\\right].\n$$\nSet the energy scale to $s = 0.05$. Compute the gradient by analytic differentiation. All energies are in arbitrary units and Boltzmann's constant is $k_{\\mathrm{B}}=1$.\n\nDefine two basins $A$ and $B$ as disks in the plane, specified by centers and a radius. Use\n$$\n\\mathbf{r}_A=\\begin{bmatrix}-0.558\\\\1.442\\end{bmatrix},\\quad \\mathbf{r}_B=\\begin{bmatrix}0.623\\\\0.028\\end{bmatrix},\\quad r_{\\mathrm{basin}}=0.20,\n$$\nso that a point $\\mathbf{r}$ is in basin $A$ if $\\|\\mathbf{r}-\\mathbf{r}_A\\|_2<r_{\\mathrm{basin}}$ and in basin $B$ if $\\|\\mathbf{r}-\\mathbf{r}_B\\|_2<r_{\\mathrm{basin}}$. Initialize all runs at $\\mathbf{r}_A$ with an added independent Gaussian perturbation of standard deviation $\\sigma_{\\mathrm{init}}=0.02$ in each coordinate.\n\nImplement two simulated annealing strategies that generate paths $\\{\\mathbf{r}_k\\}_{k=0}^{N-1}$ while the scalar temperature $T_k$ follows a geometric cooling schedule. Let the number of annealing steps be $N$, the initial and final temperatures be $T_0$ and $T_f$, and define\n$$\nT_k = T_0 \\left(\\frac{T_f}{T_0}\\right)^{\\frac{k}{N-1}},\\quad k=0,1,\\ldots,N-1.\n$$\n\nStrategy $1$ (SA-MD, simulated annealing via molecular dynamics): Use underdamped Langevin dynamics with unit mass $m=1$ and friction coefficient $\\gamma$ integrated by a standard splitting scheme. At each annealing step $k$, with time step $\\Delta t$, apply the sequence\n- Half-kick: $\\mathbf{v}\\leftarrow \\mathbf{v} + \\frac{\\Delta t}{2m}\\mathbf{F}(\\mathbf{r})$ with $\\mathbf{F}=-\\nabla V$.\n- Ornstein–Uhlenbeck (thermostat): $\\mathbf{v} \\leftarrow c\\,\\mathbf{v} + \\sqrt{(1-c^2)T_k/m}\\,\\boldsymbol{\\eta}$ with $c=\\exp(-\\gamma \\Delta t)$ and $\\boldsymbol{\\eta}$ a standard normal vector in $\\mathbb{R}^2$.\n- Drift: $\\mathbf{r}\\leftarrow \\mathbf{r} + \\Delta t\\,\\mathbf{v}$.\n- Half-kick: $\\mathbf{v}\\leftarrow \\mathbf{v} + \\frac{\\Delta t}{2m}\\mathbf{F}(\\mathbf{r})$.\nStart velocities from the Maxwell–Boltzmann distribution at temperature $T_0$, that is, each component is sampled from $\\mathcal{N}(0,T_0/m)$.\n\nStrategy $2$ (SA-MC, simulated annealing via Monte Carlo): Use a Metropolis–Hastings random walk at temperature $T_k$. At step $k$, propose $\\mathbf{r}'=\\mathbf{r} + s_k \\boldsymbol{\\xi}$ where $\\boldsymbol{\\xi}$ is a standard normal vector in $\\mathbb{R}^2$ and $s_k = s_0 \\sqrt{T_k/T_0}$. Accept the proposal with probability $\\min\\{1,\\exp[-(V(\\mathbf{r}')-V(\\mathbf{r}))/T_k]\\}$, otherwise stay at $\\mathbf{r}$.\n\nFor each simulated annealing path, define a candidate transition-state point as follows. Identify the index $k^\\star$ of the maximum potential energy along the path,\n$$\nk^\\star = \\arg\\max_{0\\le k<N} V(\\mathbf{r}_k),\n$$\nand set $\\mathbf{r}_{\\mathrm{TS}}=\\mathbf{r}_{k^\\star}$. From this candidate point, estimate the committor to basin $B$ at a reference temperature $T_{\\mathrm{ref}}$ as the probability to hit $B$ before $A$ under overdamped Langevin dynamics with unit mobility $\\mu=1$,\n$$\nd\\mathbf{r}_t = -\\mu \\nabla V(\\mathbf{r}_t)\\,dt + \\sqrt{2\\mu T_{\\mathrm{ref}}}\\,d\\mathbf{W}_t,\n$$\ndiscretized by the Euler–Maruyama scheme with time step $\\delta t$ until first hitting either basin $A$ or $B$ or until a maximum number of steps is reached (in that last case, continue integrating until a basin is reached or the cap is hit; if the cap is hit, report the hit as whichever basin is closest at that time to ensure a definitive boolean outcome). For each $\\mathbf{r}_{\\mathrm{TS}}$, perform $M$ independent trials and define the empirical committor\n$$\n\\hat{p}_B(\\mathbf{r}_{\\mathrm{TS}}) = \\frac{1}{M}\\sum_{m=1}^M \\mathbf{1}\\{\\text{trial } m \\text{ reaches } B \\text{ before } A\\}.\n$$\nDefine the committor bias for that path as $b=|\\hat{p}_B(\\mathbf{r}_{\\mathrm{TS}})-\\tfrac{1}{2}|$.\n\nFor each test case described below, generate an ensemble of simulated annealing paths for each strategy, compute the committor bias $b$ for each path, and report the mean committor bias for each strategy. Finally, for each test case, output a single integer defined as follows: output $0$ if the SA-MD ensemble mean bias is strictly smaller than the SA-MC ensemble mean bias, output $1$ if the SA-MC ensemble mean bias is strictly smaller than the SA-MD ensemble mean bias, and output $-1$ otherwise. The final output line must be a single list whose entries are exactly these integers for the listed test cases.\n\nUse the following fixed numerical parameters, expressed in the stated units:\n- Simulated annealing common parameters: number of annealing steps $N=700$, initial temperature $T_0=0.40$, final temperature $T_f=0.020$, initialization noise standard deviation $\\sigma_{\\mathrm{init}}=0.020$.\n- SA-MD integrator parameters: time step $\\Delta t=0.010$, mass $m=1$, friction coefficient $\\gamma$ as specified in the test suite case.\n- SA-MC proposal scale: base scale $s_0=0.15$ so that $s_k=s_0 \\sqrt{T_k/T_0}$.\n- Committor estimation parameters: reference temperature $T_{\\mathrm{ref}}=0.060$, Euler–Maruyama time step $\\delta t=0.0040$, maximum number of committor integration steps per trial $N_{\\max}=4000$, number of trials per transition-state point $M=24$.\n- Basin geometry: basin radius $r_{\\mathrm{basin}}=0.20$.\n\nThe test suite contains three cases, each defined by a random seed for reproducibility and by a friction coefficient $\\gamma$ for SA-MD:\n- Case $1$: seed $7$, $\\gamma=1.0$.\n- Case $2$: seed $11$, $\\gamma=0.3$.\n- Case $3$: seed $23$, $\\gamma=3.0$.\n\nYour program must perform, for each test case, an ensemble of $5$ independent runs for SA-MD and $5$ independent runs for SA-MC, each starting from basin $A$ as specified. For random number generation, use the provided case seed and derive distinct seeds for different runs and strategies in a reproducible manner.\n\nFinal output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[0,1,-1]$, where the entries correspond, in order, to the three test cases stated above. No other text should be printed. No physical units conversion is required beyond the dimensionless specification given here. All angles, if any, should be treated as dimensionless since none are used here. All fractional answers must be printed as integers according to the above rule, so no percentages appear anywhere in the output.",
            "solution": "The problem requires a comparative analysis of two simulated annealing (SA) strategies—one based on molecular dynamics (SA-MD) and another on Monte Carlo (SA-MC)—for their effectiveness in identifying transition state (TS) regions on a complex potential energy surface (PES). The quality of the identified candidate TS points is quantified using the committor probability, a rigorous concept from statistical mechanics for characterizing reaction coordinates and transition states.\n\nFirst, we must formally define the environment for our computational experiment. The conformational landscape is described by a two-dimensional Müller-Brown potential energy surface, a standard benchmark for such studies. The function $V(x,y)$ is given by:\n$$\nV(x,y) = s \\sum_{i=1}^{4} A_i \\exp\\left(a_i (x-x_i)^2 + b_i (x-x_i)(y-y_i) + c_i (y-y_i)^2\\right)\n$$\nwhere the parameters $s, A_i, a_i, b_i, c_i, x_i, y_i$ are provided constants. The force on a particle at position $\\mathbf{r} = [x, y]^T$ is the negative gradient of the potential, $\\mathbf{F}(\\mathbf{r}) = -\\nabla V(\\mathbf{r})$, which we compute analytically for use in the dynamics simulations. Let the argument of the exponential for the $i$-th term be $E_i(x,y)$. The partial derivatives are:\n$$\n\\frac{\\partial V}{\\partial x} = s \\sum_{i=1}^{4} A_i e^{E_i(x,y)} \\left( 2a_i(x-x_i) + b_i(y-y_i) \\right)\n$$\n$$\n\\frac{\\partial V}{\\partial y} = s \\sum_{i=1}^{4} A_i e^{E_i(x,y)} \\left( b_i(x-x_i) + 2c_i(y-y_i) \\right)\n$$\nWe define two stable states, basin $A$ and basin $B$, as circular regions in the $(x,y)$ plane: a point $\\mathbf{r}$ is in basin $A$ if $\\|\\mathbf{r}-\\mathbf{r}_A\\| < r_{\\mathrm{basin}}$ and in basin $B$ if $\\|\\mathbf{r}-\\mathbf{r}_B\\| < r_{\\mathrm{basin}}$, where $\\mathbf{r}_A$, $\\mathbf{r}_B$, and $r_{\\mathrm{basin}}$ are given. All simulations are initiated from a random point in the immediate vicinity of the basin $A$ center, $\\mathbf{r}_A$.\n\nThe core of the method is simulated annealing, an optimization heuristic that mimics the process of annealing in metallurgy. A system is initialized at a high temperature $T_0$ and slowly cooled to a low final temperature $T_f$. The temperature $T_k$ at step $k$ of $N$ total steps follows a geometric cooling schedule:\n$$\nT_k = T_0 \\left(\\frac{T_f}{T_0}\\right)^{\\frac{k}{N-1}}, \\quad k=0, 1, \\ldots, N-1.\n$$\nAt high temperatures, the system has sufficient thermal energy to overcome potential barriers, allowing for broad exploration of the conformational space. As the temperature decreases, the system is more likely to settle into low-energy regions. The path traced during this process, $\\{\\mathbf{r}_k\\}_{k=0}^{N-1}$, may cross the primary energy barriers between stable states.\n\nWe compare two distinct algorithms for generating this path:\n\nStrategy 1: Simulated Annealing via Molecular Dynamics (SA-MD). This approach uses a physics-based model of motion. The particle's trajectory is governed by the underdamped Langevin equation, which models a particle of mass $m$ subject to a potential force, a frictional drag proportional to velocity, and a stochastic force from a heat bath. We integrate these dynamics using a robust splitting integrator known as g-BAOAB. For each time step $\\Delta t$ at temperature $T_k$, the position $\\mathbf{r}$ and velocity $\\mathbf{v}$ are updated via the sequence:\n1.  Velocity half-kick: $\\mathbf{v} \\leftarrow \\mathbf{v} + \\frac{\\Delta t}{2m}\\mathbf{F}(\\mathbf{r})$.\n2.  Thermostat: $\\mathbf{v} \\leftarrow c\\,\\mathbf{v} + \\sqrt{(1-c^2)T_k/m}\\,\\boldsymbol{\\eta}$, where $c=\\exp(-\\gamma \\Delta t)$, $\\gamma$ is the friction coefficient, and $\\boldsymbol{\\eta}$ is a vector of independent standard normal random variates. This step couples the system to the heat bath, adjusting the velocity to be consistent with the target temperature $T_k$.\n3.  Position drift: $\\mathbf{r} \\leftarrow \\mathbf{r} + \\Delta t\\,\\mathbf{v}$.\n4.  Velocity half-kick: $\\mathbf{v} \\leftarrow \\mathbf{v} + \\frac{\\Delta t}{2m}\\mathbf{F}(\\mathbf{r})$.\nSA-MD exploration is influenced by inertia; the system has \"memory\" of its direction of motion. The friction coefficient $\\gamma$ modulates this behavior, with low $\\gamma$ corresponding to more persistent, ballistic motion and high $\\gamma$ approaching diffusive motion.\n\nStrategy 2: Simulated Annealing via Monte Carlo (SA-MC). This approach operates directly on the configuration space without considering momentum. At each step $k$, a trial move is proposed from the current position $\\mathbf{r}$ to a new position $\\mathbf{r}' = \\mathbf{r} + s_k \\boldsymbol{\\xi}$, where $\\boldsymbol{\\xi}$ is a standard normal random vector and $s_k$ is a temperature-dependent step size, $s_k = s_0 \\sqrt{T_k/T_0}$. This trial move is accepted or rejected based on the Metropolis criterion: the move is accepted with probability $P_{\\text{acc}} = \\min\\{1, \\exp(-\\Delta V/T_k)\\}$, where $\\Delta V = V(\\mathbf{r}') - V(\\mathbf{r})$. If the move is rejected, the system remains at $\\mathbf{r}$. This algorithm ensures that the system's configurations will eventually sample the Boltzmann distribution at temperature $T_k$. Exploration is purely probabilistic and local.\n\nAfter generating a path via either SA-MD or SA-MC, we identify a candidate for the transition state. An ideal transition path between basins $A$ and $B$ will cross the dividing surface between them at a point of maximum potential energy. We thus select the point of highest potential energy along the SA trajectory, $\\mathbf{r}_{\\mathrm{TS}} = \\mathbf{r}_{k^\\star}$ where $k^\\star = \\arg\\max_{0\\le k<N} V(\\mathbf{r}_k)$, as our candidate TS point.\n\nThe quality of this candidate is assessed by computing its committor probability to basin $B$, denoted $p_B(\\mathbf{r}_{\\mathrm{TS}})$. The committor $p_B(\\mathbf{r})$ is the probability that a trajectory initiated at $\\mathbf{r}$ will reach basin $B$ before reaching basin $A$. A \"perfect\" transition state lies on the separatrix where this probability is exactly $1/2$. We empirically estimate $p_B(\\mathbf{r}_{\\mathrm{TS}})$ by launching $M$ independent simulation trials from $\\mathbf{r}_{\\mathrm{TS}}$. These trial trajectories follow overdamped Langevin dynamics at a fixed reference temperature $T_{\\text{ref}}$, governed by the stochastic differential equation $d\\mathbf{r}_t = -\\mu \\nabla V(\\mathbf{r}_t)\\,dt + \\sqrt{2\\mu T_{\\mathrm{ref}}}\\,d\\mathbf{W}_t$. Each trial is run until it enters either basin $A$ or $B$. The empirical committor $\\hat{p}_B(\\mathbf{r}_{\\mathrm{TS}})$ is the fraction of these $M$ trials that reach basin $B$ first. We quantify the deviation from an ideal TS by the committor bias, $b = |\\hat{p}_B(\\mathbf{r}_{\\mathrm{TS}}) - 1/2|$. A lower bias indicates a better TS candidate.\n\nThe final step is to perform this entire procedure for an ensemble of an equal number of SA-MD and SA-MC runs for each test case. By comparing the ensemble average of the committor bias, we can determine which strategy, on average, is more effective at locating the true transition state region under the specified conditions. A result of $0$ indicates SA-MD is superior (lower bias), $1$ indicates SA-MC is superior, and $-1$ indicates no significant difference. This provides a quantitative comparison of a dynamics-based versus a statistics-based search strategy.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    # Final print statement in the exact required format.\n    # Note: scipy is not needed as erf is not required for standard normal generation.\n    np.set_printoptions(precision=15)\n\n    # Define the Müller-Brown potential\n    class MullerBrown:\n        def __init__(self):\n            self.s = 0.05\n            self.A = np.array([-200, -100, -170, 15])\n            self.a = np.array([-1, -1, -6.5, 0.7])\n            self.b = np.array([0, 0, 11, 0.6])\n            self.c = np.array([-10, -10, -6.5, 0.7])\n            self.x0 = np.array([1, 0, -0.5, -1])\n            self.y0 = np.array([0, 0.5, 1.5, 1])\n\n        def potential(self, r):\n            x, y = r[0], r[1]\n            val = 0.0\n            for i in range(4):\n                dx = x - self.x0[i]\n                dy = y - self.y0[i]\n                exp_arg = self.a[i] * dx**2 + self.b[i] * dx * dy + self.c[i] * dy**2\n                val += self.A[i] * np.exp(exp_arg)\n            return self.s * val\n\n        def gradient(self, r):\n            x, y = r[0], r[1]\n            grad_x, grad_y = 0.0, 0.0\n            for i in range(4):\n                dx = x - self.x0[i]\n                dy = y - self.y0[i]\n                exp_arg = self.a[i] * dx**2 + self.b[i] * dx * dy + self.c[i] * dy**2\n                exp_val = np.exp(exp_arg)\n                \n                d_exp_arg_dx = 2 * self.a[i] * dx + self.b[i] * dy\n                d_exp_arg_dy = self.b[i] * dx + 2 * self.c[i] * dy\n\n                grad_x += self.A[i] * exp_val * d_exp_arg_dx\n                grad_y += self.A[i] * exp_val * d_exp_arg_dy\n            \n            return self.s * np.array([grad_x, grad_y])\n\n    # Shared parameters\n    PES = MullerBrown()\n    R_A = np.array([-0.558, 1.442])\n    R_B = np.array([0.623, 0.028])\n    R_BASIN = 0.20\n    R_BASIN_SQ = R_BASIN**2\n\n    N_SA = 700\n    T0 = 0.40\n    TF = 0.020\n    SIGMA_INIT = 0.020\n    ENSEMBLE_SIZE = 5\n\n    # Committor parameters\n    T_REF = 0.060\n    DT_COMMIT = 0.0040\n    N_MAX_COMMIT = 4000\n    M_COMMIT = 24\n    MU = 1.0\n\n    # SA-MD parameters\n    DT_MD = 0.010\n    M_MD = 1.0\n\n    # SA-MC parameters\n    S0_MC = 0.15\n\n    # Simulated annealing cooling schedule\n    temps = T0 * (TF/T0)**(np.arange(N_SA) / (N_SA - 1))\n\n    # --- Committor Estimation ---\n    def estimate_committor(r_ts, rng):\n        hits_B = 0\n        sqrt_term = np.sqrt(2 * MU * T_REF * DT_COMMIT)\n\n        for _ in range(M_COMMIT):\n            r = np.copy(r_ts)\n            hit = None\n            for _ in range(N_MAX_COMMIT):\n                grad = PES.gradient(r)\n                noise = rng.normal(0, 1, size=2)\n                r -= MU * grad * DT_COMMIT + sqrt_term * noise\n                \n                dist_sq_A = np.sum((r - R_A)**2)\n                if dist_sq_A < R_BASIN_SQ:\n                    hit = 'A'\n                    break\n                \n                dist_sq_B = np.sum((r - R_B)**2)\n                if dist_sq_B < R_BASIN_SQ:\n                    hit = 'B'\n                    break\n            \n            if hit == 'B':\n                hits_B += 1\n            elif hit is None: # Tie-breaker\n                dist_sq_A = np.sum((r - R_A)**2)\n                dist_sq_B = np.sum((r - R_B)**2)\n                if dist_sq_B < dist_sq_A:\n                    hits_B += 1\n        \n        return hits_B / M_COMMIT\n\n    # --- SA Strategies ---\n    def run_sa_md(gamma, rng):\n        r = R_A + rng.normal(0, SIGMA_INIT, size=2)\n        v = rng.normal(0, np.sqrt(T0 / M_MD), size=2)\n        \n        path = np.zeros((N_SA, 2))\n        path[0] = r\n        potentials = np.zeros(N_SA)\n        potentials[0] = PES.potential(r)\n\n        c = np.exp(-gamma * DT_MD)\n        c_factor_sqrt = np.sqrt((1 - c**2) / M_MD)\n        dt_over_2m = DT_MD / (2 * M_MD)\n\n        for k in range(N_SA - 1):\n            T_k = temps[k]\n            \n            # g-BAOAB integrator\n            force = -PES.gradient(r)\n            v += dt_over_2m * force\n            \n            v = c * v + np.sqrt(T_k) * c_factor_sqrt * rng.normal(0, 1, size=2)\n            \n            r += DT_MD * v\n            \n            force = -PES.gradient(r)\n            v += dt_over_2m * force\n            \n            path[k+1] = r\n            potentials[k+1] = PES.potential(r)\n        \n        k_star = np.argmax(potentials)\n        r_ts = path[k_star]\n        pB = estimate_committor(r_ts, rng)\n        return np.abs(pB - 0.5)\n\n    def run_sa_mc(rng):\n        r = R_A + rng.normal(0, SIGMA_INIT, size=2)\n        v_current = PES.potential(r)\n\n        path = np.zeros((N_SA, 2))\n        path[0] = r\n        potentials = np.zeros(N_SA)\n        potentials[0] = v_current\n\n        step_scales = S0_MC * np.sqrt(temps / T0)\n\n        for k in range(N_SA - 1):\n            T_k = temps[k]\n            s_k = step_scales[k]\n            \n            r_prime = r + rng.normal(0, s_k, size=2)\n            v_prime = PES.potential(r_prime)\n            \n            delta_v = v_prime - v_current\n            \n            if delta_v < 0 or rng.random() < np.exp(-delta_v / T_k):\n                r = r_prime\n                v_current = v_prime\n            \n            path[k+1] = r\n            potentials[k+1] = v_current\n            \n        k_star = np.argmax(potentials)\n        r_ts = path[k_star]\n        pB = estimate_committor(r_ts, rng)\n        return np.abs(pB - 0.5)\n\n    # --- Main Loop ---\n    test_cases = [\n        (7, 1.0),\n        (11, 0.3),\n        (23, 3.0),\n    ]\n\n    results = []\n    \n    for seed, gamma in test_cases:\n        master_rng = np.random.default_rng(seed)\n        md_seeds = master_rng.integers(0, 2**32, size=ENSEMBLE_SIZE)\n        mc_seeds = master_rng.integers(0, 2**32, size=ENSEMBLE_SIZE)\n\n        md_biases = []\n        for run_seed in md_seeds:\n            rng = np.random.default_rng(run_seed)\n            bias = run_sa_md(gamma, rng)\n            md_biases.append(bias)\n        \n        mc_biases = []\n        for run_seed in mc_seeds:\n            rng = np.random.default_rng(run_seed)\n            bias = run_sa_mc(rng)\n            mc_biases.append(bias)\n        \n        mean_md_bias = np.mean(md_biases)\n        mean_mc_bias = np.mean(mc_biases)\n\n        if mean_md_bias < mean_mc_bias:\n            results.append(0)\n        elif mean_mc_bias < mean_md_bias:\n            results.append(1)\n        else:\n            results.append(-1)\n            \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}