{
    "hands_on_practices": [
        {
            "introduction": "动态网络分析的第一步是将高维构象空间离散化为一组离散状态（微观状态），然后对它们之间的转换进行建模。本练习模拟了这一过程，从轨迹的低维表示开始，指导您完成聚类和转移矩阵估计。通过这个练习，您将掌握构建马尔可夫状态模型 (Markov State Model, MSM) 的核心工作流程，包括使用 k-means 算法对连续数据进行聚类，以及根据时间序列的状态标签估计转移概率矩阵 。",
            "id": "3408877",
            "problem": "给定一个低维嵌入中的时间有序构型，该嵌入模拟了经历稀有构象转变的分子动力学轨迹的扩散图坐标。您的任务是，从头开始实现一个处理流程，该流程通过在主导扩散坐标中进行聚类来构建微观态，然后根据观察到的这些微观态之间的跃迁建立一个有向动力学网络。您必须编写一个单一程序，该程序能够生成确定性的合成嵌入轨迹，在主导扩散坐标中使用 $k$-均值算法进行聚类，根据观察到的微观态之间的跃迁估计一个离散时间马尔可夫链，并报告每个测试用例指定的标量诊断值。\n\n基本出发点和定义：\n- 微观态分解是将构型空间划分为 $K$ 个不相交的簇。$k$-均值算法旨在寻找一个划分 $\\{C_1,\\dots,C_K\\}$ 和质心 $\\{\\mu_1,\\dots,\\mu_K\\}$，以最小化 $\\sum_{i=1}^{K} \\sum_{x \\in C_i} \\lVert x - \\mu_i \\rVert^2$，其中 $\\lVert \\cdot \\rVert$ 表示欧几里得范数。\n- 给定一个时间有序的微观态标签序列 $\\{s_t\\}_{t=0}^{T-1}$，经验转移计数矩阵 $N \\in \\mathbb{N}^{K \\times K}$ 定义为 $N_{ij} = \\#\\{t \\in \\{0,\\dots,T-2\\} : s_t = i, s_{t+1} = j\\}$。行随机转移概率矩阵 $P \\in \\mathbb{R}^{K \\times K}$ 通过 $P_{ij} = N_{ij} / \\sum_{j'} N_{ij'}$（如果 $\\sum_{j'} N_{ij'} > 0$）和 $P_{ij} = 0$（否则）来估计。\n- 对于任何行随机矩阵 $P$，其特征值满足 $\\lambda_1 = 1$。当至少存在两个特征值时，第二大特征值模 (SLEM) 定义为 $\\max\\{|\\lambda| : \\lambda \\text{ is an eigenvalue of } P, \\lambda \\neq 1\\}$；如果 $K=1$ 导致只存在一个特征值，则按惯例将 SLEM 取为 $0$。\n\n每个测试用例的数据生成：您将按如下方式合成一个确定性的、时间有序的嵌入轨迹 $X \\in \\mathbb{R}^{T \\times d}$，其中 $d=3$。定义一个慢切换信号 $s(t)$，该信号具有两个可能的势阱（值接近 $-1$ 和 $+1$）和最多两个斜坡：\n- 令 $t \\in \\{0, 1, \\dots, T-1\\}$。\n- 对所有 $t$ 初始化 $s(t) = -1$。\n- 定义一个从 $t_{\\text{up}}$ 开始、持续 $R$ 帧的上升斜坡：对于 $t_{\\text{up}} \\le t  \\min(t_{\\text{up}} + R, T)$，设置 $s(t) = -1 + 2\\,(t - t_{\\text{up}})/R$；对于 $t \\ge \\min(t_{\\text{up}} + R, T)$，设置 $s(t) = +1$（除非被下面的下降斜坡修改）。\n- 定义一个从 $t_{\\text{down}}$ 开始、持续 $R$ 帧的可选下降斜坡：对于 $t_{\\text{down}} \\le t  \\min(t_{\\text{down}} + R, T)$，设置 $s(t) = +1 - 2\\,(t - t_{\\text{down}})/R$；对于 $t \\ge \\min(t_{\\text{down}} + R, T)$，设置 $s(t) = -1$。如果 $t_{\\text{down}} \\ge T$，则不发生下降斜坡。\n- 定义角频率 $\\omega = 2\\pi/M$（单位为弧度/帧）。构建坐标\n$$\n\\begin{aligned}\nx_1(t) = s(t) + a \\sin(\\omega t),\\\\\nx_2(t) = \\tfrac{1}{2}\\,s(t) + a \\cos(\\omega t),\\\\\nx_3(t) = \\tfrac{1}{4}\\,\\sin(2 \\omega t).\n\\end{aligned}\n$$\n对于每个 $t$，设置 $X(t,:) = (x_1(t), x_2(t), x_3(t))$。\n\n聚类和网络构建：\n- 仅使用 $X$ 的前 $q$ 个坐标（“主导扩散坐标”）进行聚类。\n- 在聚类之前，沿每个坐标将这 $q$ 个坐标标准化为零均值和单位方差。如果某个坐标的方差为零，则将其标准差视为 $1$ 以避免除以零，从而保持该坐标不变。\n- 使用 Lloyd 算法和确定性的最远点初始化方法实现具有 $K$ 个簇的 $k$-均值算法：\n  1. 选择欧几里得范数最小的数据点作为第一个中心。\n  2. 对于每个后续的中心，选择与已选中心集中最近的中心距离最大的数据点。\n  3. 迭代分配（按最近的中心）和更新（质心作为算术平均值），直到标签不再改变或达到最大迭代次数 $M_{\\text{it}}$。如果出现空簇，则将其中心重新初始化为与其当前分配的中心距离最大的数据点，然后继续。\n- 根据时间顺序的簇标签，构建经验转移计数矩阵 $N$ 和行随机转移矩阵 $P$，包括自转移。\n\n每个测试用例的必需输出：\n- 令 $E$ 为具有严格正转移概率的有向边的数量，即 $P_{ij}  0$ 的条目计数。\n- 令 $\\theta$ 为如上定义的 $P$ 的第二大特征值模 (SLEM)。\n- 令 $f_{\\max}$ 为在占据最多的微观态中所花费的时间分数，计算方法为最大占据数除以 $T$。\n- 为每个测试用例报告列表 $[E, \\mathrm{round}(\\theta, 6), \\mathrm{round}(f_{\\max}, 6)]$，其中四舍五入到 $6$ 位小数。三角函数的角度必须以弧度计算。\n\n测试套件：\n- 案例 A：$(T, t_{\\text{up}}, t_{\\text{down}}, R, a, M, q, K) = (300, 80, 200, 20, 0.05, 15, 2, 2)$。\n- 案例 B (退化的聚类边界)：$(T, t_{\\text{up}}, t_{\\text{down}}, R, a, M, q, K) = (180, 60, 140, 10, 0.02, 12, 2, 1)$。\n- 案例 C (单向转移边缘情况)：$(T, t_{\\text{up}}, t_{\\text{down}}, R, a, M, q, K) = (250, 160, 1000, 20, 0.04, 20, 2, 2)$。\n为 $k$-均值算法设置最大迭代次数 $M_{\\text{it}} = 100$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素本身都是一个包含三个数字的方括号列表，代表一个测试用例，顺序与上面列出的相同。例如，输出格式必须与\n$[ [E_A,\\theta_A,f_{\\max,A}],[E_B,\\theta_B,f_{\\max,B}],[E_C,\\theta_C,f_{\\max,C}] ]$\n完全一样，除了所示的空格外，不需要额外的空格，也没有额外的文本。所有量均为无量纲，所有三角函数参数均为弧度。",
            "solution": "该问题要求实现一个确定性的计算流程来分析合成的分子动力学数据。该流程涉及合成轨迹，使用 $k$-均值聚类将其划分为微观态，构建马尔可夫动力学网络，并计算特定的网络诊断指标。本解答遵循所提供的定义和原则，逐步介绍解决方案。\n\n### 1. 轨迹合成\n对于每个测试用例，会生成一个时间有序的轨迹 $X \\in \\mathbb{R}^{T \\times d}$，其维度 $d=3$，长度为 $T$ 帧。时间索引为 $t \\in \\{0, 1, \\dots, T-1\\}$。\n\n首先，构建一个慢切换信号 $s(t)$，它模拟了两个亚稳态势阱（$s \\approx -1$ 和 $s \\approx +1$）之间的跃迁。该信号按如下方式生成：\n1.  初始化一个长度为 $T$ 的数组 $s$，其值为 $-1$。\n2.  引入一个从时间 $t_{\\text{up}}$ 开始，持续 $R$ 帧的上升斜坡。在时间步长 $t$ 处于区间 $[t_{\\text{up}}, \\min(t_{\\text{up}} + R, T))$ 内时，信号从 $-1$ 线性插值到 $+1$：\n    $$s(t) = -1 + 2 \\cdot \\frac{t - t_{\\text{up}}}{R}$$\n    对于所有后续时间 $t \\ge \\min(t_{\\text{up}} + R, T)$，信号被设置为 $s(t) = +1$。\n3.  一个可选的下降斜坡，与上升斜坡对称，从 $t_{\\text{down}}$ 开始。如果 $t_{\\text{down}}  T$，则对于 $t \\in [t_{\\text{down}}, \\min(t_{\\text{down}} + R, T))$，信号从 $+1$ 线性插值到 $-1$：\n    $$s(t) = +1 - 2 \\cdot \\frac{t - t_{\\text{down}}}{R}$$\n    对于所有后续时间 $t \\ge \\min(t_{\\text{down}} + R, T)$，信号被设置为 $s(t) = -1$。这个下降斜坡及其后续效果会覆盖由上升斜坡逻辑设置的任何值。\n\n定义了慢信号 $s(t)$ 后，构建三维坐标 $X(t,:) = (x_1(t), x_2(t), x_3(t))$。这些坐标将慢跃迁与由角频率 $\\omega = 2\\pi/M$ 控制的更快的周期性局部运动耦合起来：\n$$\n\\begin{aligned}\nx_1(t) = s(t) + a \\sin(\\omega t) \\\\\nx_2(t) = \\tfrac{1}{2}\\,s(t) + a \\cos(\\omega t) \\\\\nx_3(t) = \\tfrac{1}{4}\\,\\sin(2 \\omega t)\n\\end{aligned}\n$$\n参数 $a$ 控制快速波动的振幅。\n\n### 2. 微观态聚类\n使用 $k$-均值聚类将连续轨迹离散化为一系列微观态。\n\n首先，准备用于聚类的数据。按规定，仅使用轨迹 $X$ 的前 $q$ 个坐标。然后对该子矩阵 $X_{:,:q} \\in \\mathbb{R}^{T \\times q}$ 进行标准化处理。对于 $q$ 个坐标中的每一个，均值被移至零，方差被缩放到一。如果某个坐标的方差为零（即其标准差为 $0$），则将其标准差视为 $1$ 以防止除以零，由于其已经居中，该坐标保持不变。\n\n接下来，应用 $k$-均值聚类将 $T$ 个标准化数据点划分为 $K$ 个簇。实现中使用了 Lloyd 算法和确定性初始化方案，以确保结果可复现。\n-   **初始化（最远点法）**：\n    1.  选择欧几里得范数最小的数据点作为第一个质心。\n    2.  对于从 $2$ 到 $K$ 的每个后续质心 $i$，选择与所有先前选择的质心（$1, \\dots, i-1$）的最小平方欧氏距离最大的数据点。\n-   **迭代（Lloyd 算法）**：该算法通过两个步骤进行迭代，直到簇分配不再改变或达到最大迭代次数 $M_{\\text{it}} = 100$。\n    1.  **分配步骤**：根据欧氏距离，将每个数据点分配给最近质心对应的簇。这产生了一个时间有序的簇标签序列 $\\{z_t\\}_{t=0}^{T-1}$，其中 $z_t \\in \\{0, 1, \\dots, K-1\\}$。\n    2.  **更新步骤**：每个簇的质心被重新计算为分配给它的所有数据点的算术平均值。\n-   **空簇处理**：如果在一次迭代中某个簇变为空（即没有点分配给它），则其质心将被重新初始化。新的质心被选为与其自身当前分配的质心具有最大平方欧氏距离的数据点。此过程“窃取”一个拟合不佳的点来为该空簇提供种子，确保所有 $K$ 个簇都保持活动状态。这一操作在更新步骤内部、下一次迭代开始之前进行。\n\n### 3. 动力学网络分析\n微观态标签的时间序列 $\\{z_t\\}$ 用于构建一个由转移概率矩阵 $P$ 表示的离散时间马尔可夫链。\n\n-   **转移计数矩阵 ($N$)**：构建一个 $K \\times K$ 矩阵 $N$，其中条目 $N_{ij}$ 统计在时间延迟为一帧的情况下，从微观态 $i$ 到微观态 $j$ 的观测跃迁次数：\n    $$N_{ij} = \\#\\{t \\in \\{0, \\dots, T-2\\} : z_t = i, z_{t+1} = j\\}$$\n-   **转移概率矩阵 ($P$)**：计数矩阵 $N$ 被行归一化以得到行随机转移概率矩阵 $P \\in \\mathbb{R}^{K \\times K}$。从状态 $i$ 转移到状态 $j$ 的概率估计为：\n    $$P_{ij} = \\frac{N_{ij}}{\\sum_{k=0}^{K-1} N_{ik}}$$\n    如果一个状态 $i$ 没有观测到出向转移（即 $\\sum_{k} N_{ik} = 0$，这种情况只可能在状态 $i$ 仅在最后一个时间步 $t=T-1$ 被访问时发生），其对应的行 $P_{i,:}$ 将被设置为全零。\n\n最后，从该模型为每个测试用例计算三个标量诊断值：\n1.  **边数 ($E$)**：这是网络中具有正转移概率的有向边的数量，计算为矩阵 $P$ 中严格为正的条目数：$E = \\#\\{(i,j) : P_{ij}  0\\}$。\n2.  **第二大特征值模 ($\\theta$)**：这是矩阵 $P$ 的 SLEM，定义为 $\\theta = \\max\\{|\\lambda| : \\lambda \\text{ is an eigenvalue of } P, \\lambda \\neq 1\\}$。对于 $K=1$ 的情况，按惯例将 SLEM 取为 $0$。计算上，通过计算 $P$ 的所有特征值，取其绝对值，进行排序，然后选择第二大的值来找到它。由于 $P$ 被构建为行随机（或次随机）矩阵，其最大特征值模保证为 $1$（如果状态图是非平凡且连通的）。\n3.  **最大占据分数 ($f_{\\max}$)**：该指标衡量在占据最多的微观态中所花费的模拟时间比例。其计算方法是，找到具有最大分配帧数 $\\text{count}(k)$ 的微观态 $k$，然后除以总帧数 $T$：\n    $$f_{\\max} = \\frac{\\max_{k \\in \\{0, \\dots, K-1\\}} \\text{count}(k)}{T}$$\n\n计算出的 $\\theta$ 和 $f_{\\max}$ 值四舍五入到 $6$ 位小数。",
            "answer": "```python\nimport numpy as np\n\ndef generate_trajectory(T, t_up, t_down, R, a, M):\n    \"\"\"\n    Generates a deterministic synthetic trajectory based on the problem specification.\n\n    Args:\n        T (int): Total number of frames.\n        t_up (int): Start time of the upward ramp.\n        t_down (int): Start time of the downward ramp.\n        R (int): Duration of the ramps.\n        a (float): Amplitude of fast fluctuations.\n        M (int): Period of fast fluctuations.\n\n    Returns:\n        np.ndarray: The generated trajectory of shape (T, 3).\n    \"\"\"\n    t_vals = np.arange(T)\n    s = np.full(T, -1.0)\n\n    # Upward ramp and subsequent plateau\n    if t_up  T:\n        up_ramp_end = min(t_up + R, T)\n        ramp_indices = np.arange(t_up, up_ramp_end)\n        if len(ramp_indices)  0:\n            s[ramp_indices] = -1.0 + 2.0 * (ramp_indices - t_up) / R\n        if up_ramp_end  T:\n            s[up_ramp_end:T] = 1.0\n\n    # Downward ramp and subsequent plateau (overwrites previous values)\n    if t_down  T:\n        down_ramp_end = min(t_down + R, T)\n        ramp_indices = np.arange(t_down, down_ramp_end)\n        if len(ramp_indices)  0:\n            s[ramp_indices] = 1.0 - 2.0 * (ramp_indices - t_down) / R\n        if down_ramp_end  T:\n            s[down_ramp_end:T] = -1.0\n        \n    omega = 2 * np.pi / M\n    x1 = s + a * np.sin(omega * t_vals)\n    x2 = 0.5 * s + a * np.cos(omega * t_vals)\n    x3 = 0.25 * np.sin(2 * omega * t_vals)\n    \n    return np.stack([x1, x2, x3], axis=1)\n\ndef k_means(data, K, M_it):\n    \"\"\"\n    Performs k-means clustering with deterministic farthest-point initialization.\n\n    Args:\n        data (np.ndarray): The data to cluster, shape (n_samples, n_features).\n        K (int): The number of clusters.\n        M_it (int): The maximum number of iterations.\n\n    Returns:\n        np.ndarray: The final cluster labels for each data point.\n    \"\"\"\n    n_samples, n_features = data.shape\n    \n    if K == 1:\n        return np.zeros(n_samples, dtype=int)\n\n    # 1. Initialization: Farthest-point\n    centers = np.zeros((K, n_features))\n    norms_sq = np.sum(data**2, axis=1)\n    first_center_idx = np.argmin(norms_sq)\n    centers[0] = data[first_center_idx]\n    \n    min_dist_sq = np.full(n_samples, np.inf)\n    for i in range(1, K):\n        dist_sq_to_last_center = np.sum((data - centers[i-1])**2, axis=1)\n        min_dist_sq = np.minimum(min_dist_sq, dist_sq_to_last_center)\n        next_center_idx = np.argmax(min_dist_sq)\n        centers[i] = data[next_center_idx]\n\n    # 2. Lloyd's Algorithm\n    labels = -np.ones(n_samples, dtype=int)\n    for _ in range(M_it):\n        # Assignment step\n        dist_sq = np.sum((data[:, np.newaxis, :] - centers)**2, axis=2)\n        new_labels = np.argmin(dist_sq, axis=1)\n\n        # Convergence check\n        if np.array_equal(new_labels, labels):\n            break\n        labels = new_labels\n\n        # Update step\n        new_centers = np.zeros((K, n_features))\n        empty_clusters = []\n        for k in range(K):\n            points_in_cluster = data[labels == k]\n            if len(points_in_cluster) == 0:\n                empty_clusters.append(k)\n            else:\n                new_centers[k] = points_in_cluster.mean(axis=0)\n\n        # Empty cluster handling\n        if empty_clusters:\n            point_distances_sq = np.sum((data - centers[labels])**2, axis=1)\n            farthest_point_indices = np.argsort(point_distances_sq)[::-1]\n            \n            used_farthest_points = set()\n            farthest_idx_ptr = 0\n            for k in empty_clusters:\n                point_to_reseed_idx = farthest_point_indices[farthest_idx_ptr]\n                while point_to_reseed_idx in used_farthest_points:\n                    farthest_idx_ptr += 1\n                    point_to_reseed_idx = farthest_point_indices[farthest_idx_ptr]\n\n                new_centers[k] = data[point_to_reseed_idx]\n                used_farthest_points.add(point_to_reseed_idx)\n                \n        centers = new_centers\n        \n    return labels\n\ndef calculate_diagnostics(labels, K, T):\n    \"\"\"\n    Calculates network diagnostics E, theta, and f_max.\n\n    Args:\n        labels (np.ndarray): Time-ordered cluster labels.\n        K (int): Number of clusters.\n        T (int): Total number of frames.\n\n    Returns:\n        tuple: A tuple containing (E, theta, f_max).\n    \"\"\"\n    if K == 1:\n        return 1, 0.0, 1.0\n\n    N = np.zeros((K, K), dtype=int)\n    for i in range(T - 1):\n        N[labels[i], labels[i+1]] += 1\n\n    P = np.zeros((K, K))\n    row_sums = N.sum(axis=1)\n    non_zero_rows = row_sums  0\n    P[non_zero_rows] = N[non_zero_rows] / row_sums[non_zero_rows, np.newaxis]\n\n    E = np.count_nonzero(P)\n\n    eigenvalues = np.linalg.eigvals(P)\n    eigenvalue_moduli = np.abs(eigenvalues)\n    eigenvalue_moduli.sort() \n    theta = eigenvalue_moduli[-2] if len(eigenvalue_moduli) = 2 else 0.0\n\n    if T  0:\n        occupancies = np.bincount(labels, minlength=K)\n        f_max = np.max(occupancies) / T\n    else:\n        f_max = 0.0\n        \n    return E, theta, f_max\n\ndef solve():\n    \"\"\"\n    Main function to run the full pipeline for all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        (300, 80, 200, 20, 0.05, 15, 2, 2),  # Case A\n        (180, 60, 140, 10, 0.02, 12, 2, 1),  # Case B\n        (250, 160, 1000, 20, 0.04, 20, 2, 2), # Case C\n    ]\n    M_it = 100\n\n    all_results = []\n    for params in test_cases:\n        T, t_up, t_down, R, a, M, q, K = params\n        \n        X = generate_trajectory(T, t_up, t_down, R, a, M)\n        \n        data_for_clustering = X[:, :q]\n        \n        mean = data_for_clustering.mean(axis=0)\n        std = data_for_clustering.std(axis=0)\n        std[std == 0] = 1.0\n        standardized_data = (data_for_clustering - mean) / std\n        \n        labels = k_means(standardized_data, K, M_it)\n        \n        E, theta, f_max = calculate_diagnostics(labels, K, T)\n        \n        result = [E, round(theta, 6), round(f_max, 6)]\n        all_results.append(result)\n\n    result_str = ','.join([str(r).replace(' ', '') for r in all_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一旦构建了动态网络（由转移矩阵 $T(\\tau)$ 表示），其主要目的就是计算宏观的动力学可观测量。本练习演示了如何估计系统的生成元矩阵 (generator matrix)，并用它来计算平均首通时间 (Mean First-Passage Times, MFPTs)，这是一个衡量转变时间尺度的基本物理量 。这个实践将离散时间的转移矩阵 $T(\\tau)$ 与底层的连续时间马尔可夫过程生成元 $K$ 联系起来，阐释了如何通过建立并求解源于生成元的线性方程组来计算如 MFPTs 这样的关键动力学性质。",
            "id": "3408868",
            "problem": "一个定义在有限节点集上的连续时间马尔可夫链 (CTMC) 为动态网络建模，这些网络近似了分子动力学中亚稳态之间的构象转变。令 $T(\\tau)$ 为延迟时间 $\\tau0$ 时的行随机短延迟转移概率矩阵，令 $K$ 为无穷小生成元。Kolmogorov 前向方程表明 $\\frac{d}{dt}T(t)\\big|_{t=0}=K$，这导出了一阶近似 $T(\\tau)\\approx I+\\tau K$（对于较小的 $\\tau$）。给定一个节点吸收边界集 $B$ 及其补集 $\\bar{B}$，从节点 $i\\in \\bar{B}$ 开始到 $B$ 的平均首达时间 (MFPT) $m_i$ 求解线性系统 $K_{\\bar{B}\\bar{B}}\\,m=-\\mathbf{1}$，边界条件为对于 $j\\in B$，$m_j=0$，其中 $\\mathbf{1}$ 是维度为 $|\\bar{B}|$ 的全一向量。您的任务是为给定的矩阵 $T(\\tau)$、吸收集 $B$ 和起始节点 $s$ 的测试套件实现以下过程：\n1. 使用 $K\\approx (T(\\tau)-I)/\\tau$ 估计生成元。\n2. 通过限制到非吸收态索引 $\\bar{B}$ 来构成子矩阵 $K_{\\bar{B}\\bar{B}}$。\n3. 如果起始节点 $s\\in B$，则定义 MFPT 为 $0$。否则，求解 $K_{\\bar{B}\\bar{B}}\\,m=-\\mathbf{1}$ 并报告 $m_s$（对应于起始节点 $s$ 的分量）。\n所有索引都是从零开始的。不需要物理单位。返回的 MFPT 必须是四舍五入到六位小数的实数。\n\n测试套件：\n- 情况 1：\n  - $T^{(1)}=\\begin{bmatrix} 0.88  0.12  0 \\\\ 0.07  0.85  0.08 \\\\ 0  0.06  0.94 \\end{bmatrix}$，\n  - $\\tau^{(1)}=0.1$，\n  - $B^{(1)}=\\{2\\}$，\n  - $s^{(1)}=0$。\n- 情况 2：\n  - $T^{(2)}=\\begin{bmatrix} 0.935  0.045  0.02  0 \\\\ 0.025  0.935  0.03  0.01 \\\\ 0  0.015  0.935  0.05 \\\\ 0  0  0  1 \\end{bmatrix}$，\n  - $\\tau^{(2)}=0.05$，\n  - $B^{(2)}=\\{2,3\\}$，\n  - $s^{(2)}=0$。\n- 情况 3：\n  - $T^{(3)}=\\begin{bmatrix} 0.9975  0.0025 \\\\ 0.0015  0.9985 \\end{bmatrix}$，\n  - $\\tau^{(3)}=0.001$，\n  - $B^{(3)}=\\{1\\}$，\n  - $s^{(3)}=0$。\n- 情况 4：\n  - $T^{(4)}=\\begin{bmatrix} 0.9  0.04  0.06 \\\\ 0.02  0.9  0.08 \\\\ 0.04  0.04  0.92 \\end{bmatrix}$，\n  - $\\tau^{(4)}=0.2$，\n  - $B^{(4)}=\\{0\\}$，\n  - $s^{(4)}=0$。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[r_1,r_2,r_3,r_4]$），其中每个 $r_k$ 是情况 $k$ 的 MFPT，四舍五入到六位小数。",
            "solution": "问题陈述已经过严格验证，被认为是有效的。其科学基础是连续时间马尔可夫链理论，问题定义良好，具有清晰的算法步骤，并以客观、正式的语言表述。所有必要的数据均已提供且内部一致。\n\n任务是计算在几个给定场景下到达一组吸收态的平均首达时间 (MFPT)。通用方法直接源于吸收马尔可夫链理论。设状态空间被划分为一个瞬时态集 $\\bar{B}$ 和一个吸收态集 $B$。连续时间马尔可夫链的无穷小生成元用 $K$ 表示。与瞬时态对应的 $K$ 的子矩阵是 $K_{\\bar{B}\\bar{B}}$。MFPT 向量 $m$（其中每个分量 $m_i$ 是从瞬时态 $i \\in \\bar{B}$ 开始的 MFPT）通过求解以下线性系统找到：\n$$K_{\\bar{B}\\bar{B}}\\,m = -\\mathbf{1}$$\n其中 $\\mathbf{1}$ 是一个适当维度的全一列向量。根据定义，从一个已经在吸收集 $B$ 中的状态出发的 MFPT 为 $0$。\n\n生成元 $K$ 不是直接给出的，而是使用从矩阵指数关系 $T(\\tau) = e^{\\tau K} \\approx I + \\tau K$ 导出的一阶近似，从短延迟转移概率矩阵 $T(\\tau)$ 估计得出。这产生了近似式：\n$$K \\approx \\frac{T(\\tau) - I}{\\tau}$$\n其中 $I$ 是单位矩阵，$\\tau$ 是延迟时间。\n\n我们现在将此过程应用于每个测试案例。\n\n情况 1：\n给定：\n- 转移矩阵 $T^{(1)} = \\begin{bmatrix} 0.88  0.12  0 \\\\ 0.07  0.85  0.08 \\\\ 0  0.06  0.94 \\end{bmatrix}$\n- 延迟时间 $\\tau^{(1)} = 0.1$\n- 吸收集 $B^{(1)} = \\{2\\}$\n- 起始节点 $s^{(1)} = 0$\n\n起始节点 $s^{(1)}=0$ 不在吸收集 $B^{(1)}$ 中。非吸收（瞬时）态的集合是 $\\bar{B}^{(1)} = \\{0, 1\\}$。\n首先，我们估计生成元矩阵 $K^{(1)}$：\n$$K^{(1)} \\approx \\frac{1}{0.1} \\left( \\begin{bmatrix} 0.88  0.12  0 \\\\ 0.07  0.85  0.08 \\\\ 0  0.06  0.94 \\end{bmatrix} - \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{bmatrix} \\right) = \\begin{bmatrix} -1.2  1.2  0 \\\\ 0.7  -1.5  0.8 \\\\ 0  0.6  -0.6 \\end{bmatrix}$$\n接下来，我们通过选择对应于瞬时态 $\\{0, 1\\}$ 的行和列来构成子矩阵 $K^{(1)}_{\\bar{B}\\bar{B}}$：\n$$K^{(1)}_{\\bar{B}\\bar{B}} = \\begin{bmatrix} -1.2  1.2 \\\\ 0.7  -1.5 \\end{bmatrix}$$\n我们求解线性系统 $K^{(1)}_{\\bar{B}\\bar{B}} m = -\\mathbf{1}$，以求得 MFPT 向量 $m = \\begin{pmatrix} m_0 \\\\ m_1 \\end{pmatrix}$：\n$$\\begin{bmatrix} -1.2  1.2 \\\\ 0.7  -1.5 \\end{bmatrix} \\begin{pmatrix} m_0 \\\\ m_1 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix}$$\n求解该系统可得 $m_0 = 2.8125$ 和 $m_1 \\approx 1.979167$。所需的值是从起始节点 $s^{(1)}=0$ 出发的 MFPT，即 $m_0$。\n情况 1 的结果：$2.8125$。\n\n情况 2：\n给定：\n- 转移矩阵 $T^{(2)} = \\begin{bmatrix} 0.935  0.045  0.02  0 \\\\ 0.025  0.935  0.03  0.01 \\\\ 0  0.015  0.935  0.05 \\\\ 0  0  0  1 \\end{bmatrix}$\n- 延迟时间 $\\tau^{(2)} = 0.05$\n- 吸收集 $B^{(2)} = \\{2, 3\\}$\n- 起始节点 $s^{(2)} = 0$\n\n起始节点 $s^{(2)}=0$ 不在 $B^{(2)}$ 中。瞬时态的集合是 $\\bar{B}^{(2)} = \\{0, 1\\}$。\n生成元矩阵 $K^{(2)}$ 估计如下：\n$$K^{(2)} \\approx \\frac{1}{0.05} \\left( T^{(2)} - I \\right) = 20 \\begin{bmatrix} -0.065  0.045  0.02  0 \\\\ 0.025  -0.065  0.03  0.01 \\\\ 0  0.015  -0.065  0.05 \\\\ 0  0  0  0 \\end{bmatrix} = \\begin{bmatrix} -1.3  0.9  0.4  0 \\\\ 0.5  -1.3  0.6  0.2 \\\\ 0  0.3  -1.3  1.0 \\\\ 0  0  0  0 \\end{bmatrix}$$\n瞬时态 $\\{0, 1\\}$ 的子矩阵是：\n$$K^{(2)}_{\\bar{B}\\bar{B}} = \\begin{bmatrix} -1.3  0.9 \\\\ 0.5  -1.3 \\end{bmatrix}$$\n我们求解系统 $K^{(2)}_{\\bar{B}\\bar{B}} m = -\\mathbf{1}$：\n$$\\begin{bmatrix} -1.3  0.9 \\\\ 0.5  -1.3 \\end{bmatrix} \\begin{pmatrix} m_0 \\\\ m_1 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix}$$\n解为 $m_0 \\approx 1.774194$ 和 $m_1 \\approx 1.451613$。所需的 MFPT 是针对起始节点 $s^{(2)}=0$ 的，即 $m_0$。\n情况 2 的结果：$1.774194$。\n\n情况 3：\n给定：\n- 转移矩阵 $T^{(3)} = \\begin{bmatrix} 0.9975  0.0025 \\\\ 0.0015  0.9985 \\end{bmatrix}$\n- 延迟时间 $\\tau^{(3)} = 0.001$\n- 吸收集 $B^{(3)} = \\{1\\}$\n- 起始节点 $s^{(3)} = 0$\n\n起始节点 $s^{(3)}=0$ 不在 $B^{(3)}$ 中。瞬时态的集合是 $\\bar{B}^{(3)} = \\{0\\}$。\n生成元矩阵 $K^{(3)}$ 估计如下：\n$$K^{(3)} \\approx \\frac{1}{0.001} \\left( T^{(3)} - I \\right) = 1000 \\begin{bmatrix} -0.0025  0.0025 \\\\ 0.0015  -0.0015 \\end{bmatrix} = \\begin{bmatrix} -2.5  2.5 \\\\ 1.5  -1.5 \\end{bmatrix}$$\n瞬时态 $\\{0\\}$ 的子矩阵是一个 $1 \\times 1$ 矩阵：\n$$K^{(3)}_{\\bar{B}\\bar{B}} = \\begin{bmatrix} -2.5 \\end{bmatrix}$$\n该线性系统是一个简单的标量方程：\n$$[-2.5] [m_0] = [-1]$$\n求解 $m_0$ 得 $m_0 = \\frac{-1}{-2.5} = 0.4$。\n情况 3 的结果：$0.4$。\n\n情况 4：\n给定：\n- 转移矩阵 $T^{(4)} = \\begin{bmatrix} 0.9  0.04  0.06 \\\\ 0.02  0.9  0.08 \\\\ 0.04  0.04  0.92 \\end{bmatrix}$\n- 延迟时间 $\\tau^{(4)} = 0.2$\n- 吸收集 $B^{(4)} = \\{0\\}$\n- 起始节点 $s^{(4)} = 0$\n\n在这种情况下，起始节点 $s^{(4)}=0$ 是吸收集 $B^{(4)}$ 的一个元素。根据问题定义，从一个已经在集合中的节点到该集合的 MFPT 是 $0$。无需计算。\n情况 4 的结果：$0.0$。\n\n结果摘要，四舍五入至六位小数：\n- 情况 1: $2.812500$\n- 情况 2: $1.774194$\n- 情况 3: $0.400000$\n- 情况 4: $0.000000$\n这些将被格式化为所需的输出字符串。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the Mean First-Passage Time (MFPT) for a series of test cases\n    based on continuous-time Markov chain theory.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"T\": np.array([\n                [0.88, 0.12, 0.00],\n                [0.07, 0.85, 0.08],\n                [0.00, 0.06, 0.94]\n            ]),\n            \"tau\": 0.1,\n            \"B\": {2},\n            \"s\": 0\n        },\n        {\n            \"T\": np.array([\n                [0.935, 0.045, 0.020, 0.000],\n                [0.025, 0.935, 0.030, 0.010],\n                [0.000, 0.015, 0.935, 0.050],\n                [0.000, 0.000, 0.000, 1.000]\n            ]),\n            \"tau\": 0.05,\n            \"B\": {2, 3},\n            \"s\": 0\n        },\n        {\n            \"T\": np.array([\n                [0.9975, 0.0025],\n                [0.0015, 0.9985]\n            ]),\n            \"tau\": 0.001,\n            \"B\": {1},\n            \"s\": 0\n        },\n        {\n            \"T\": np.array([\n                [0.90, 0.04, 0.06],\n                [0.02, 0.90, 0.08],\n                [0.04, 0.04, 0.92]\n            ]),\n            \"tau\": 0.2,\n            \"B\": {0},\n            \"s\": 0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        T = case[\"T\"]\n        tau = case[\"tau\"]\n        B = case[\"B\"]\n        s = case[\"s\"]\n        \n        # If the starting node is in the absorbing set, MFPT is 0 by definition.\n        if s in B:\n            results.append(0.0)\n            continue\n            \n        num_states = T.shape[0]\n        \n        # Step 1: Estimate the generator matrix K\n        I = np.identity(num_states)\n        K = (T - I) / tau\n        \n        # Step 2: Form the submatrix K_BB_bar\n        # Identify non-absorbing (transient) states\n        transient_indices = [i for i in range(num_states) if i not in B]\n        \n        # Use np.ix_ to perform advanced indexing to get the submatrix\n        K_sub = K[np.ix_(transient_indices, transient_indices)]\n        \n        # Step 3: Solve the linear system K_sub * m = -1\n        # The right-hand side is a vector of -1s\n        rhs = np.full(len(transient_indices), -1.0)\n        \n        # Solve for the vector of MFPTs for transient states\n        m_vec = np.linalg.solve(K_sub, rhs)\n        \n        # Find the MFPT for the specific starting node s\n        # This requires finding the index of s within the list of transient states\n        try:\n            start_node_index_in_m = transient_indices.index(s)\n            mfpt = m_vec[start_node_index_in_m]\n            results.append(mfpt)\n        except ValueError:\n            # This case should not be reached if s is not in B\n            # as s must be in transient_indices.\n            # However, it is good practice to handle it.\n            # We can't determine MFPT if starting node is not in the system.\n            # We treat this as an anomaly, though the problem spec avoids this.\n            results.append(np.nan)\n\n\n    # Format the final output string with results rounded to six decimal places.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "从有限的模拟数据构建的模型会受到统计不确定性的影响。这个高级练习将展示如何超越单一的点估计模型，通过传播这种不确定性来得出更可靠的科学结论，例如识别变构通讯中的关键位点（热点）。本练习将介绍一个用于 MSM 分析的贝叶斯框架，您将使用狄利克雷先验 (Dirichlet priors) 从转移矩阵的后验分布中抽样，为每个样本计算网络中心性度量，并最终识别出那些在统计上稳健的中心节点，从而在分析中考虑了采样不确定性。",
            "id": "3408823",
            "problem": "给定一个由分子动力学模拟构象转变产生的离散状态马尔可夫状态模型（MSM）。该MSM是一个在有限节点集上的离散时间马尔可夫链，每个节点代表一个亚稳态构象状态（或与变构相关的粗粒化残基水平社群）。 empirical transition counts（经验转移计数）是可用的，并且每行的转移概率都用独立的狄利克雷先验进行建模。您的任务是将转移概率中的贝叶斯不确定性传播到与动力学网络分析相关的节点中心性的不确定性中，并根据下面定义的决策规则识别统计上稳健的变构热点。\n\n从第一性原理出发，使用以下基本依据：\n- 具有行随机转移矩阵 $P$ 且包含 $n$ 个状态的离散时间马尔可夫链的定义。\n- 在给定计数数据的情况下，对于 $P$ 的每一行，狄利克雷先验与多项式似然的共轭性。\n- 不可约、非周期马尔可夫链的平稳分布 $\\pi$ 的定义，其满足 $\\pi^{\\top} P = \\pi^{\\top}$ 和 $\\sum_{i=1}^{n} \\pi_i = 1$。\n- 平均首次通过时间（MFPTs）的定义及其与有限不可约马尔可夫链基本矩阵的关系。\n\n将节点 $j$ 的中心性定义为平稳平均的平均首次通过时间到 $j$ 的倒数，即当起始节点根据平稳分布进行分布时，节点 $j$ 的期望击中时间的倒数。概念上：采样 $X_0 \\sim \\pi$，然后定义 $T_j = \\min\\{ t \\ge 0 : X_t = j \\}$，并定义中心性 $C_j = 1 / \\mathbb{E}[T_j]$。您必须从上述基本依据出发，推导出 $C_j$ 关于 $P$ 和 $\\pi$ 的可实现表达式，而不使用任何黑箱中心性公式。\n\n不确定性传播要求：\n- 设 $C$ 是一个 $n \\times n$ 的非负整数矩阵，其中 $C_{ij}$ 是在长轨迹中从状态 $i$到状态 $j$ 的观测转移次数，并设 $\\alpha  0$ 是一个标量伪计数先验。对于每一行 $i$，设其在 $n$ 维概率单纯形上的先验为 $\\mathrm{Dirichlet}(\\alpha, \\alpha, \\dots, \\alpha)$，且各行之间独立。使用多项式-狄利克雷共轭性，得到每一行 $i$ 的后验分布为 $\\mathrm{Dirichlet}(\\alpha + C_{i1}, \\dots, \\alpha + C_{in})$。\n- 为了传播不确定性，通过从其狄利克雷后验分布中独立抽取每一行 $i$，生成 $S$ 个独立的全转移矩阵 $P$ 的样本。\n\n统计上稳健的变构热点的决策规则：\n- 对于每个抽样的转移矩阵，计算如上定义的节点中心性向量 $(C_1, \\dots, C_n)$。按中心性降序对节点进行排序；为了确定性地打破平局，使用字典序规则，即如果两个节点 $a$ 和 $b$ 的中心性在浮点数上相等，则优先选择索引较小的节点。从此排序中提取前 $k$ 个节点的集合。\n- 在 $S$ 个后验样本中，计算每个节点 $j$ 出现在前 $k$ 个集合中的经验频率 $f_j$。如果 $f_j \\ge \\tau$，则一个节点被宣布为统计上稳健的变构热点，其中 $\\tau \\in (0,1)$ 是一个置信度阈值。\n- 将每个测试用例的稳健热点索引集报告为一个按升序排序的0索引整数列表。\n\n实现一个程序，执行上述步骤并为以下测试套件生成所需的输出。您不得硬编码任何结果；必须通过实现所描述的过程来计算它们。所有随机抽样必须使用提供的种子以保证可复现性。\n\n测试套件：\n- 案例A（通用连接性，两个盆地）：\n  - 计数矩阵 $C^{(A)} \\in \\mathbb{N}_0^{5 \\times 5}$:\n    $$\n    C^{(A)} =\n    \\begin{bmatrix}\n    0  30  5  0  0 \\\\\n    20  0  10  0  0 \\\\\n    3  12  0  15  0 \\\\\n    0  0  8  0  22 \\\\\n    0  0  0  18  0\n    \\end{bmatrix}.\n    $$\n  - 先验伪计数 $\\alpha^{(A)} = 0.5$。\n  - 后验样本数 $S^{(A)} = 2000$。\n  - Top-$k^{(A)} = 2$。\n  - 置信度阈值 $\\tau^{(A)} = 0.95$。\n  - 伪随机种子 $s^{(A)} = 42$。\n\n- 案例B（稀疏且近乎确定性的转移）：\n  - 计数矩阵 $C^{(B)} \\in \\mathbb{N}_0^{4 \\times 4}$:\n    $$\n    C^{(B)} =\n    \\begin{bmatrix}\n    0  1  0  0 \\\\\n    0  0  50  0 \\\\\n    0  0  0  1 \\\\\n    25  0  0  0\n    \\end{bmatrix}.\n    $$\n  - 先验伪计数 $\\alpha^{(B)} = 0.1$。\n  - 后验样本数 $S^{(B)} = 3000$。\n  - Top-$k^{(B)} = 1$。\n  - 置信度阈值 $\\tau^{(B)} = 0.90$。\n  - 伪随机种子 $s^{(B)} = 123$。\n\n- 案例C（对称转移）：\n  - 计数矩阵 $C^{(C)} \\in \\mathbb{N}_0^{3 \\times 3}$:\n    $$\n    C^{(C)} =\n    \\begin{bmatrix}\n    0  10  10 \\\\\n    10  0  10 \\\\\n    10  10  0\n    \\end{bmatrix}.\n    $$\n  - 先验伪计数 $\\alpha^{(C)} = 1.0$。\n  - 后验样本数 $S^{(C)} = 1000$。\n  - Top-$k^{(C)} = 1$。\n  - 置信度阈值 $\\tau^{(C)} = 0.80$。\n  - 伪随机种子 $s^{(C)} = 7$。\n\n输出规范：\n- 您的程序应生成一行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个元素本身是一个0索引整数列表，对应一个测试用例的稳健热点索引，按案例A、案例B、案例C的顺序排列。例如，一个具有占位符值的语法有效输出的形式为 $[ [0,2], [1], [] ]$。您的程序必须严格按此格式打印一行。\n\n此问题不适用角度单位和物理单位。所有概率都是在 $[0,1]$ 区间内的无单位实数，所有计数都是非负整数。确保任何随机计算都由提供的种子控制以保证可复现性，并且数值计算对于小型矩阵是稳定的。",
            "solution": "该问题要求通过将贝叶斯不确定性从转移概率传播到特定定义的节点中心性度量，从而在离散状态马尔可夫状态模型（MSM）中识别统计上稳健的变构热点。解决方案包括三个主要部分：首先，从马尔可夫链理论的基本原理推导中心性度量；其次，概述贝叶斯不确定性传播过程；第三，根据给定的决策规则指定识别稳健热点的算法。\n\n### 1. 中心性度量的推导\n\n节点 $j$ 的中心性，记为 $C_j$，定义为到 $j$ 的平稳平均的平均首次通过时间的倒数。设离散时间马尔可夫链有 $n$ 个状态，一个行随机转移矩阵 $P$，以及一个唯一的平稳分布 $\\pi$ 满足 $\\pi^{\\top}P = \\pi^{\\top}$ 和 $\\sum_{i=0}^{n-1} \\pi_i = 1$。状态 $j$ 的击中时间为 $T_j = \\min\\{ t \\ge 0 : X_t = j \\}$。中心性为：\n\n$$ C_j = \\frac{1}{\\mathbb{E}_{\\pi}[T_j]} $$\n\n期望 $\\mathbb{E}_{\\pi}[T_j]$ 是针对从平稳分布 $\\pi$ 中抽取的初始状态 $X_0$ 计算的。它可以展开为：\n\n$$ \\mathbb{E}_{\\pi}[T_j] = \\sum_{i=0}^{n-1} \\pi_i \\mathbb{E}[T_j | X_0 = i] = \\sum_{i=0}^{n-1} \\pi_i m_{ij} $$\n\n其中 $m_{ij}$ 是从状态 $i$ 到状态 $j$ 的平均首次通过时间（MFPT）。根据问题对 $T_j$ 的定义，如果过程始于状态 $j$（即 $i=j$），击中时间为 $0$。因此，$m_{jj} = \\mathbb{E}[T_j | X_0 = j] = 0$。\n\n为了找到 $i \\neq j$ 时的MFPT $m_{ij}$，我们使用基本矩阵法。考虑一个修改后的马尔可夫链，其中状态 $j$ 被设置为吸收态。其他状态 $\\{0, 1, \\dots, n-1\\} \\setminus \\{j\\}$ 变为瞬时态。设 $P_j$ 是 $P$ 中对应于这些瞬时态的 $(n-1) \\times (n-1)$ 子矩阵。对于任何起始状态 $i \\neq j$，MFPT $m_{ij}$ 是被吸收到状态 $j$ 的期望时间。来自瞬时态的MFPT满足以下线性系统：\n\n$$ m_{ij} = 1 + \\sum_{k \\neq j} P_{ik} m_{kj} \\quad \\text{for } i \\neq j $$\n\n以向量形式，设 $\\vec{m}_j$ 是从所有状态 $i \\neq j$ 到状态 $j$ 的MFPT列向量，$\\mathbf{1}$ 是一个全为1的列向量。该系统为 $\\vec{m}_j = \\mathbf{1} + P_j \\vec{m}_j$。整理后得到 $(I - P_j)\\vec{m}_j = \\mathbf{1}$，其中 $I$ 是 $(n-1) \\times (n-1)$ 的单位矩阵。\n\n矩阵 $N_j = (I - P_j)^{-1}$ 被称为这个吸收链的基本矩阵。对于一个不可约的原始链，它的存在性是保证的，因为次随机矩阵 $P_j$ 的谱半径小于 $1$。因此，MFPT的解为：\n\n$$ \\vec{m}_j = (I - P_j)^{-1} \\mathbf{1} = N_j \\mathbf{1} $$\n\n这意味着对于 $i \\neq j$，$m_{ij}$ 是 $N_j$ 中对应于状态 $i$ 的行的元素之和。\n\n综合这些结果，到状态 $j$ 的平稳平均MFPT，我们记为 $H_j$，是：\n$$ H_j = \\mathbb{E}_{\\pi}[T_j] = \\sum_{i \\neq j} \\pi_i m_{ij} $$\n中心性则为 $C_j = 1/H_j$。对于不可约链，所有 $i$ 的 $\\pi_i  0$ 且 $i \\neq j$ 的 $m_{ij}  0$，确保 $H_j  0$。\n\n### 2. 贝叶斯不确定性传播\n\n转移概率是不确定的。给定一个经验转移计数矩阵 $C$ 和一个标量狄利克雷先验伪计数 $\\alpha  0$，转移矩阵 $P$ 的每一行 $i$ 的后验分布是独立的，并遵循狄利克雷分布：\n\n$$ P_{i,:} | C_{i,:} \\sim \\mathrm{Dirichlet}(\\alpha + C_{i,0}, \\alpha + C_{i,1}, \\dots, \\alpha + C_{i,n-1}) $$\n\n为了将这种不确定性传播到中心性度量上，我们采用蒙特卡洛抽样方法：\n1. 生成 $S$ 个独立的转移矩阵样本 $\\{P^{(1)}, P^{(2)}, \\dots, P^{(S)}\\}$。每个矩阵 $P^{(s)}$ 是通过从其各自的后验狄利克雷分布中独立抽取其行 $P^{(s)}_{i,:}$ 来构建的。\n2. 对于每个抽样矩阵 $P^{(s)}$，使用第1节中的推导计算完整的中心性向量 $(C_0^{(s)}, \\dots, C_{n-1}^{(s)})$。\n\n### 3. 算法流程与决策规则\n\n为识别给定测试用例的稳健变构热点的完整算法如下：\n\n1.  **初始化**：为可复现性设置随机数生成器种子。初始化一个大小为 $n$ 的计数器数组为零，它将存储每个节点出现在前 $k$ 个集合中的频率。\n2.  **后验抽样循环**：迭代 $S$ 次：\n    a. **抽样 $P$**：通过从其后验狄利克雷分布中抽取每一行来构建一个转移矩阵 $P$。\n    b. **计算平稳分布 $\\pi$**：数值求解 $P$ 的平稳分布。这通过找到 $P^{\\top}$ 对应于特征值 $1$ 的右特征向量来实现。然后将该特征向量归一化，使其和为 $1$。\n    c. **计算MFPT**：对于每个目标状态 $j \\in \\{0, \\dots, n-1\\}$，构建子矩阵 $P_j$，计算基本矩阵 $N_j=(I-P_j)^{-1}$，并计算所有 $i \\neq j$ 的MFPT $m_{ij}$。\n    d. **计算中心性**：计算平穩平均的MFPT $H_j = \\sum_{i \\neq j} \\pi_i m_{ij}$，然后计算中心性 $C_j = 1/H_j$。\n    e. **节点排序**：按中心性值的降序对节点进行排序。为打破平局，索引较小的节点优先。这通过基于元组 $(-C_j, j)$进行排序来实现。\n    f. **更新计数器**：从排序中识别出前 $k$ 个节点的集合，并增加相应的计数器。\n3.  **识别热点**：循环结束后，通过将其计数除以 $S$ 来计算每个节点 $j$ 的经验频率 $f_j$。如果节点 $j$ 的频率 $f_j$ 达到或超过给定的置信度阈值 $\\tau$，则该节点被宣布为稳健热点。\n4.  **最终输出**：收集所有稳健热点的0索引，并将其呈现在一个排序后的列表中。对提供的每个测试用例重复此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    It iterates through each case, performs the Bayesian analysis of node centrality,\n    and prints the final results in the specified format.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"C\": np.array([\n                [0, 30, 5, 0, 0],\n                [20, 0, 10, 0, 0],\n                [3, 12, 0, 15, 0],\n                [0, 0, 8, 0, 22],\n                [0, 0, 0, 18, 0]\n            ]),\n            \"alpha\": 0.5, \"S\": 2000, \"k\": 2, \"tau\": 0.95, \"seed\": 42\n        },\n        {\n            \"C\": np.array([\n                [0, 1, 0, 0],\n                [0, 0, 50, 0],\n                [0, 0, 0, 1],\n                [25, 0, 0, 0]\n            ]),\n            \"alpha\": 0.1, \"S\": 3000, \"k\": 1, \"tau\": 0.90, \"seed\": 123\n        },\n        {\n            \"C\": np.array([\n                [0, 10, 10],\n                [10, 0, 10],\n                [10, 10, 0]\n            ]),\n            \"alpha\": 1.0, \"S\": 1000, \"k\": 1, \"tau\": 0.80, \"seed\": 7\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        hotspots = analyze_case(\n            case[\"C\"], case[\"alpha\"], case[\"S\"], case[\"k\"], case[\"tau\"], case[\"seed\"]\n        )\n        results.append(hotspots)\n\n    # Format the final output string exactly as specified.\n    # str([0, 2]) -> '[0, 2]'. The join creates '[0, 2],[1],[]'.\n    # The f-string adds the outer brackets making '[[0, 2],[1],[]]'.\n    final_output_string = f\"[{','.join(map(str, results))}]\"\n    print(final_output_string)\n\ndef get_stationary_distribution(P):\n    \"\"\"\n    Computes the stationary distribution of a Markov chain given its transition matrix P.\n    It corresponds to the left eigenvector for the eigenvalue 1.\n    \"\"\"\n    # Solve for the right eigenvector of P.T for the eigenvalue 1.\n    eigvals, eigvecs = linalg.eig(P.T)\n    # Find the eigenvector corresponding to the eigenvalue closest to 1.0.\n    idx = np.argmin(np.abs(eigvals - 1.0))\n    pi_vec = np.real(eigvecs[:, idx])\n    # Normalize to obtain a probability distribution.\n    pi_vec /= np.sum(pi_vec)\n    return pi_vec\n\ndef get_centralities(P, pi):\n    \"\"\"\n    Computes the node centralities for a given transition matrix P and stationary distribution pi.\n    \"\"\"\n    n = P.shape[0]\n    mfpt_matrix = np.zeros((n, n))\n    all_indices = np.arange(n)\n\n    for j in range(n):\n        # Define transient states for the absorbing chain with absorbing state j.\n        transient_indices = np.delete(all_indices, j)\n        \n        # Extract the submatrix P_j for transient states.\n        P_j = P[np.ix_(transient_indices, transient_indices)]\n        \n        # Compute the fundamental matrix N_j = (I - P_j)^-1.\n        I_sub = np.identity(n - 1)\n        try:\n            N_j = linalg.inv(I_sub - P_j)\n        except linalg.LinAlgError:\n            # This should be rare given the problem setup but is good practice.\n            return np.full(n, -1.0) # Indicate failure\n\n        # MFPTs to state j are the row sums of the fundamental matrix.\n        mfpts_to_j = N_j.sum(axis=1)\n        \n        # Populate the MFPT matrix. m_{jj} is 0.\n        mfpt_matrix[transient_indices, j] = mfpts_to_j\n    \n    # Calculate stationary-averaged MFPT H_j = sum_i(pi_i * m_ij).\n    # This is equivalent to M.T @ pi for a column vector pi.\n    H = mfpt_matrix.T @ pi\n    \n    # Centrality C_j = 1 / H_j. Add a small epsilon to avoid division by zero.\n    centralities = 1.0 / (H + 1e-12)\n    return centralities\n\ndef analyze_case(C, alpha, S, k, tau, seed):\n    \"\"\"\n    Performs the full analysis for a single test case.\n    \"\"\"\n    n = C.shape[0]\n    rng = np.random.default_rng(seed)\n    \n    # Pre-compute posterior Dirichlet parameters.\n    posterior_params = C + alpha\n    \n    top_k_counts = np.zeros(n, dtype=int)\n    \n    for _ in range(S):\n        # 1. Sample a transition matrix P from the posterior.\n        P = np.array([rng.dirichlet(params) for params in posterior_params])\n        \n        # 2. Compute stationary distribution.\n        pi = get_stationary_distribution(P)\n        \n        # 3. Compute centralities.\n        centralities = get_centralities(P, pi)\n        if np.any(centralities  0): continue # Skip if computation failed.\n        \n        # 4. Rank nodes by (-centrality, index) and find top-k.\n        node_indices = np.arange(n)\n        sorted_indices = sorted(node_indices, key=lambda i: (-centralities[i], i))\n        top_k_nodes = sorted_indices[:k]\n        \n        # 5. Update counts for nodes in the top-k set.\n        top_k_counts[top_k_nodes] += 1\n        \n    # 6. Identify robust hotspots based on the frequency threshold tau.\n    frequencies = top_k_counts / S\n    robust_hotspots = np.where(frequencies >= tau)[0]\n    \n    return sorted(robust_hotspots.tolist())\n\n# The problem requires the script to be runnable \"as is\", so call solve().\nsolve()\n```"
        }
    ]
}