{
    "hands_on_practices": [
        {
            "introduction": "Milestoning is a powerful technique that avoids the brute-force simulation of long waiting times in metastable states. This is achieved by stitching together statistical information from short trajectories run between a series of interfaces, or \"milestones\". This exercise, , guides you through the core mathematical engine of the method, where you will use the law of total expectation to connect local dynamics to global kinetics and calculate the Mean First Passage Time (MFPT).",
            "id": "3434778",
            "problem": "Consider an overdamped molecular system at thermal equilibrium, modeled by a one-dimensional reaction coordinate with a milestoning discretization. Four milestones partition the coordinate into three cells, with labels $i \\in \\{0,1,2,3\\}$. The reactant set is milestone $A$ at $i=0$, and the product set is milestone $B$ at $i=3$. Under the standard milestoning assumptions (Markov renewal property at milestones and local equilibration on each milestone), define the mean first passage time (MFPT) $T_i$ as the expected time to reach $B$ when starting from milestone $i$. On each non-absorbing milestone $i \\in \\{0,1,2\\}$, infinitesimal trajectories initiated from the local stationary density restricted to milestone $i$ produce the following data:\n- The mean local exit time $\\tau_i$ (the expected time to hit any neighboring milestone starting from milestone $i$).\n- The conditional exit probabilities $p_{ij}$ for transitioning from milestone $i$ to a neighboring milestone $j$ at the next exit.\n\nAssume only nearest-neighbor exits occur and that $B$ is absorbing. The measured quantities are:\n- For milestone $i=0$: $\\tau_0 = 8 \\text{ ps}$ and $p_{01} = 1$.\n- For milestone $i=1$: $\\tau_1 = 12 \\text{ ps}$, $p_{10} = 0.35$, and $p_{12} = 0.65$.\n- For milestone $i=2$: $\\tau_2 = 15 \\text{ ps}$, $p_{21} = 0.25$, and $p_{23} = 0.75$.\n- For milestone $i=3$: $B$ is absorbing, so $T_3 = 0$ and there are no exits.\n\nStarting from the definitions above, and using only fundamental probabilistic reasoning (in particular, the law of total expectation) together with the Markov renewal assumption at milestones, derive from first principles the linear system satisfied by the MFPTs $T_i$ for $i \\in \\{0,1,2\\}$, and then solve this system to obtain $T_0$, the MFPT from $A$ to $B$.\n\nExpress the final MFPT $T_0$ in nanoseconds (ns). Round your answer to four significant figures.",
            "solution": "The problem is scientifically grounded, well-posed, objective, self-contained, and consistent. It describes a standard application of the milestoning method for calculating the mean first passage time (MFPT) of a process on a one-dimensional reaction coordinate. All necessary data are provided, and the probabilistic relationships are consistent. The task is to derive and solve the backward master equations for the MFPTs. The problem is valid.\n\nThe central principle for solving this problem is the application of the law of total expectation to the process of reaching the product state $B$ (milestone $i=3$) starting from an intermediate milestone $i$. The milestoning framework assumes that the process is a Markov renewal process at the milestones. This means that once a trajectory reaches a milestone, its future evolution is independent of how it arrived there.\n\nLet $T_i$ be the mean first passage time to reach the product state $B$ (milestone $3$) starting from a uniform stationary distribution on milestone $i$. A trajectory starting from milestone $i$ will first evolve within the cell associated with $i$ for a certain duration, until it hits a neighboring milestone $j$. The average duration of this first step is the mean local exit time, $\\tau_i$. The trajectory then arrives at milestone $j$ with a probability $p_{ij}$. Due to the Markov renewal property, the remaining expected time to reach $B$ from milestone $j$ is simply $T_j$.\n\nBy the law of total expectation, we can express $T_i$ as the sum of the mean time for the first exit and the expected time from the next milestone onward, averaged over all possible exits:\n$T_i = (\\text{mean time for first exit from cell } i) + (\\text{expected remaining time to reach } B)$\nMathematically, this is expressed as:\n$$T_i = \\tau_i + \\sum_{j} p_{ij} T_j$$\nwhere the sum is over all milestones $j$ that are neighbors of $i$. This set of equations is known as the backward master equation for the MFPTs.\n\nWe are given a system with four milestones, $i \\in \\{0, 1, 2, 3\\}$. Milestone $i=0$ is the reactant state $A$, and milestone $i=3$ is the absorbing product state $B$. The boundary condition for the absorbing state is $T_3 = 0$, as the time to reach $B$ starting from $B$ is zero. We need to find the MFPTs $T_0$, $T_1$, and $T_2$ for the non-absorbing milestones.\n\nThe given data are:\n- For milestone $i=0$: $\\tau_0 = 8 \\text{ ps}$, $p_{01} = 1$.\n- For milestone $i=1$: $\\tau_1 = 12 \\text{ ps}$, $p_{10} = 0.35$, $p_{12} = 0.65$.\n- For milestone $i=2$: $\\tau_2 = 15 \\text{ ps}$, $p_{21} = 0.25$, $p_{23} = 0.75$.\n\nWe can now write the specific equations for each non-absorbing milestone:\n\nFor milestone $i=2$: The neighbors are $j=1$ and $j=3$.\n$$T_2 = \\tau_2 + p_{21}T_1 + p_{23}T_3$$\nSubstituting the given values and $T_3=0$:\n$$T_2 = 15 + (0.25)T_1 + (0.75)(0)$$\n$$T_2 = 15 + 0.25 T_1 \\quad (1)$$\n\nFor milestone $i=1$: The neighbors are $j=0$ and $j=2$.\n$$T_1 = \\tau_1 + p_{10}T_0 + p_{12}T_2$$\nSubstituting the given values:\n$$T_1 = 12 + 0.35 T_0 + 0.65 T_2 \\quad (2)$$\n\nFor milestone $i=0$: The only neighbor is $j=1$.\n$$T_0 = \\tau_0 + p_{01}T_1$$\nSubstituting the given values:\n$$T_0 = 8 + (1)T_1$$\n$$T_0 = 8 + T_1 \\quad (3)$$\n\nWe now have a system of three linear equations with three unknowns ($T_0, T_1, T_2$). We can solve this system by substitution.\n\nFrom equation $(3)$, we can express $T_1$ in terms of $T_0$:\n$$T_1 = T_0 - 8$$\n\nSubstitute this expression for $T_1$ into equation $(1)$ to find $T_2$ in terms of $T_0$:\n$$T_2 = 15 + 0.25(T_0 - 8)$$\n$$T_2 = 15 + 0.25 T_0 - 2$$\n$$T_2 = 13 + 0.25 T_0$$\n\nNow, substitute the expressions for $T_1$ and $T_2$ in terms of $T_0$ into equation $(2)$:\n$$T_1 = 12 + 0.35 T_0 + 0.65 T_2$$\n$$T_0 - 8 = 12 + 0.35 T_0 + 0.65 (13 + 0.25 T_0)$$\n\nNow, we solve this equation for $T_0$. First, expand the right-hand side:\n$$T_0 - 8 = 12 + 0.35 T_0 + (0.65)(13) + (0.65)(0.25) T_0$$\n$$T_0 - 8 = 12 + 0.35 T_0 + 8.45 + 0.1625 T_0$$\n\nGroup the terms with $T_0$ and the constant terms:\n$$T_0 - 8 = (12 + 8.45) + (0.35 + 0.1625) T_0$$\n$$T_0 - 8 = 20.45 + 0.5125 T_0$$\n\nRearrange the equation to isolate $T_0$:\n$$T_0 - 0.5125 T_0 = 20.45 + 8$$\n$$(1 - 0.5125) T_0 = 28.45$$\n$$0.4875 T_0 = 28.45$$\n\nFinally, solve for $T_0$:\n$$T_0 = \\frac{28.45}{0.4875}$$\n$$T_0 \\approx 58.35897435... \\text{ ps}$$\n\nThe problem requires the final answer to be in nanoseconds (ns) and rounded to four significant figures.\nWe use the conversion $1 \\text{ ns} = 1000 \\text{ ps}$.\n$$T_0 (\\text{ns}) = \\frac{T_0 (\\text{ps})}{1000} = \\frac{58.35897435...}{1000} = 0.05835897435... \\text{ ns}$$\n\nRounding this value to four significant figures: The first four significant figures are $5$, $8$, $3$, $5$. The next digit is $8$, which is greater than or equal to $5$, so we round up the last significant digit.\n$$T_0 \\approx 0.05836 \\text{ ns}$$",
            "answer": "$$\\boxed{0.05836}$$"
        },
        {
            "introduction": "Transition Path Sampling (TPS) and Weighted Ensemble (WE) are two cornerstone algorithms for sampling rare reactive events, yet they operate on very different principles. This hands-on coding exercise, , challenges you to implement both methods for a simple, analytically solvable model system. By comparing the results from your simulations to the exact answer, you will gain a deep, practical understanding of how these distinct algorithms manage to sample the same underlying transition path ensemble.",
            "id": "3434777",
            "problem": "Consider a discrete-time, one-dimensional, nearest-neighbor Markov chain modeling overdamped diffusion across metastable sets with absorbing boundaries. The state space is $\\{0,1,2,\\dots,M\\}$, where state $0$ is the source set $\\mathcal{A}$ and state $M$ is the target set $\\mathcal{B}$. At each time step, a walker at interior state $i \\in \\{1,\\dots,M-1\\}$ moves to $i+1$ with probability $p$ and to $i-1$ with probability $q$, where $q = 1 - p$, and transitions from $0$ and $M$ are absorbing. Define a path observable $f(\\text{path})$ to be the total number of visits to a particular interior state $k \\in \\{1,\\dots,M-1\\}$ along a trajectory from its initial state until absorption. For a starting interior state $i \\in \\{1,\\dots,M-1\\}$, the transition-path ensemble is defined by conditioning the path distribution on eventual absorption in $\\mathcal{B}$ before absorption in $\\mathcal{A}$.\n\nYour objectives, based on fundamental principles of Markov chains and unbiased sampling, are as follows:\n\n- Starting from the definition of path probabilities in discrete-time Markov processes, the characterization of absorbing sets, and conditioning on events via the Doob $h$-transform, derive an exact expression for the conditional expectation $\\mathbb{E}[f(\\text{path}) \\mid \\text{absorb in } \\mathcal{B}]$ for the random walk described above. The derivation and the algorithm must start from first principles (transition probabilities and conditioning) without assuming any specialized formulas beyond standard Markov chain and linear algebra results. Express all mathematical entities using LaTeX.\n\n- Implement two estimators of $\\langle f(\\text{path}) \\rangle$ under matched boundary conditions:\n  1. A Transition Path Sampling (TPS)-like estimator that generates complete trajectories starting from $i$, discards those that absorb in $\\mathcal{A}$, and averages $f(\\text{path})$ over accepted trajectories that absorb in $\\mathcal{B}$.\n  2. A Weighted Ensemble (WE) estimator that maintains a fixed number of walkers per interior state bin by splitting and pruning with conserved statistical weights, propagates walkers according to the unbiased dynamics until absorption, and estimates the conditional expectation $\\mathbb{E}[f(\\text{path}) \\mid \\text{absorb in } \\mathcal{B}]$ as the ratio of the total weight times the path observable accumulated on trajectories that absorb in $\\mathcal{B}$ to the total weight absorbed into $\\mathcal{B}$.\n\n- Demonstrate equivalence (in the long-time limit) of the TPS and WE path ensembles by comparing $\\langle f(\\text{path}) \\rangle$ computed by both methods to the exact conditional expectation derived from first principles. Your numerical implementation must use scientifically sound parameters and must ensure that boundary conditions, starting distribution, and dynamics are matched across the two estimators.\n\nAll quantities are dimensionless.\n\nTest Suite:\nImplement the program to evaluate the following three parameter sets, each specified by $(M,p,i,k,T,K,N)$ where $T$ is the maximum number of propagation steps for the Weighted Ensemble estimator, $K$ is the target number of walkers per interior state bin in the Weighted Ensemble, and $N$ is the number of independent trajectories in the TPS-like estimator:\n\n- Case $1$: $(M,p,i,k,T,K,N) = (12,\\,0.55,\\,3,\\,6,\\,3000,\\,40,\\,30000)$.\n- Case $2$: $(M,p,i,k,T,K,N) = (12,\\,0.50,\\,4,\\,9,\\,4000,\\,60,\\,40000)$.\n- Case $3$: $(M,p,i,k,T,K,N) = (18,\\,0.52,\\,1,\\,9,\\,5000,\\,60,\\,50000)$.\n\nRequired Output:\nFor each case, compute three quantities: the TPS-like estimate, the WE estimate, and the exact conditional expectation. Return a boolean indicating equivalence if both the absolute difference between the TPS-like and WE estimates and the absolute differences between each estimator and the exact conditional expectation are strictly less than a tolerance $\\varepsilon = 0.03$. Your program should produce a single line of output containing the three booleans as a comma-separated list enclosed in square brackets (e.g., $\\texttt{[True,True,False]}$).\n\nFinal Output Format:\nYour program should produce exactly one line, formatted as a Python list of three booleans: $\\texttt{[b_1,b_2,b_3]}$, where each $b_j$ corresponds to Case $j$ as described above.",
            "solution": "The problem asks for the derivation of an exact formula for the conditional expectation of a path observable on a 1D lattice, and for its comparison with two numerical estimators: a Transition Path Sampling (TPS)-like method and a Weighted Ensemble (WE) method.\n\n### Part 1: Exact Analytical Derivation\n\nThe system is a one-dimensional discrete-time random walk on the states $\\{0, 1, \\dots, M\\}$. States $0$ and $M$ are absorbing, representing sets $\\mathcal{A}$ and $\\mathcal{B}$ respectively. For any interior state $j \\in \\{1, \\dots, M-1\\}$, the transition probabilities are $P(j \\to j+1) = p$ and $P(j \\to j-1) = q = 1-p$. The path observable $f(\\text{path})$ is the total number of visits to a specific interior state $k$. We seek the conditional expectation $\\mathbb{E}[f(\\text{path}) \\mid X_0=i, \\text{absorb in } \\mathcal{B}]$, where the walk starts at an interior state $i$.\n\n**1. Committor Probability**\n\nFirst, we define the committor probability, $h_j$, as the probability that a walk starting at state $j$ is absorbed at state $M$ before being absorbed at state $0$. The boundary conditions are $h_0 = 0$ and $h_M = 1$. For any interior state $j$, conditioning on the first step yields the recurrence relation:\n$$h_j = p \\cdot h_{j+1} + q \\cdot h_{j-1}$$\nThis is a second-order linear homogeneous difference equation, $p h_{j+1} - h_j + q h_{j-1} = 0$. The characteristic equation is $p\\lambda^2 - \\lambda + q = 0$, which has roots $\\lambda_1 = 1$ and $\\lambda_2 = q/p$.\n\nLet $\\rho = q/p$.\nIf $p \\neq 0.5$ (i.e., $\\rho \\neq 1$), the general solution is $h_j = C_1(1)^j + C_2(\\rho)^j$. Applying the boundary conditions $h_0 = C_1 + C_2 = 0$ and $h_M = C_1 + C_2\\rho^M = 1$, we solve for $C_1$ and $C_2$ to find:\n$$h_j = \\frac{\\rho^j - 1}{\\rho^M - 1}$$\nIf $p = 0.5$ (i.e., $\\rho = 1$), the characteristic equation has a double root at $\\lambda=1$. The general solution is $h_j = C_1(1)^j + C_2 j(1)^j = C_1 + C_2 j$. The boundary conditions $h_0 = C_1 = 0$ and $h_M = C_2 M = 1$ give:\n$$h_j = \\frac{j}{M}$$\nThe case for $p=0.5$ can also be obtained by taking the limit $\\rho \\to 1$ of the general formula using L'Hôpital's rule.\n\n**2. The Conditioned Process and Relation to the Green's Function**\n\nWe are interested in the ensemble of paths that start at $i$ and end at $M$. The properties of this conditioned process can be described by a new Markov chain, obtained via the Doob $h$-transform. The transition probabilities $P'_{jk}$ of this conditioned process are given by $P'_{jk} = P_{jk} h_k / h_j$.\n\nLet $E_i(k)$ be the expected number of visits to state $k$ starting from state $i$ in this conditioned process. We wish to compute $E_i(k)$. A more direct approach is to relate this conditional expectation to properties of the original, unconditioned process.\n\nThe conditional expectation can be written as:\n$$E_i(k) = \\mathbb{E}[f \\mid \\text{absorb at } M] = \\frac{\\mathbb{E}[f \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}}]}{P(\\text{absorb at } M)}$$\nThe denominator is simply the committor probability $h_i$. The numerator is the expectation of the observable multiplied by an indicator function for the event of absorption at $M$. Let $f = \\sum_{t=0}^{\\tau-1} \\delta_{X_t, k}$, where $\\tau$ is the absorption time.\n$$\n\\mathbb{E}[f \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i] = \\mathbb{E}\\left[\\left(\\sum_{t=0}^{\\tau-1} \\delta_{X_t, k}\\right) \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i\\right]\n$$\nBy linearity of expectation and the Markov property:\n$$\n\\sum_{t=0}^{\\tau-1} \\mathbb{E}[\\delta_{X_t, k} \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i] = \\sum_{t=0}^{\\tau-1} P(X_t=k \\text{ and absorb at } M \\mid X_0=i)\n$$\n$$\n= \\sum_{t=0}^{\\tau-1} P(X_t=k \\mid X_0=i) \\cdot P(\\text{absorb at } M \\mid X_t=k)\n$$\nThe second term in the product is simply $h_k$. Thus the expression becomes:\n$$\nh_k \\sum_{t=0}^{\\tau-1} P(X_t=k \\mid X_0=i) = h_k \\cdot \\mathbb{E}\\left[\\sum_{t=0}^{\\tau-1} \\delta_{X_t, k} \\mid X_0=i\\right]\n$$\nThe term in the expectation is the total number of visits to state $k$ in the original, unconditioned random walk starting from $i$ before absorption at either $0$ or $M$. Let's denote this quantity by $G_{ik}$, which is the discrete Green's function for the process on the finite domain with absorbing boundaries.\nSo, $\\mathbb{E}[f \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i] = G_{ik} h_k$.\nFinally, the conditional expectation is:\n$$E_i(k) = \\frac{G_{ik} h_k}{h_i}$$\n\n**3. The Green's Function $G_{ik}$**\n\nThe Green's function $G_{jk}$ is the solution to the difference equation for the expected number of visits:\n$$G_{jk} - (p G_{j+1, k} + q G_{j-1, k}) = \\delta_{jk}$$\nwith boundary conditions $G_{0k} = G_{Mk} = 0$. This is equivalent to solving $p G_{j+1, k} - G_{jk} + q G_{j-1, k} = -\\delta_{jk}$.\n\nThe solution can be constructed using homogeneous solutions, similar to the committor calculation.\nFor $p=0.5$:\n$$G_{ik} = \\begin{cases} \\frac{2i(M-k)}{M} & i \\le k \\\\ \\frac{2k(M-i)}{M} & i \\ge k \\end{cases}$$\nFor $p \\neq 0.5$ (with $\\rho=q/p$):\n$$G_{ik} = \\begin{cases} \\frac{(\\rho^k-\\rho^M)(\\rho^i-1)}{(q-p)\\rho^k(\\rho^M-1)} & i \\le k \\\\ \\frac{(\\rho^k-1)(\\rho^i-\\rho^M)}{(q-p)\\rho^k(\\rho^M-1)} & i \\ge k \\end{cases}$$\n\n**4. Final expression for $E_i(k)$**\n\nCombining the expressions for $G_{ik}$, $h_k$, and $h_i$ gives the final result.\n\nIf $p=0.5$:\n- For $i \\le k$: $E_i(k) = \\frac{2i(M-k)/M \\cdot k/M}{i/M} = \\frac{2k(M-k)}{M}$.\n- For $i > k$: $E_i(k) = \\frac{2k(M-i)/M \\cdot k/M}{i/M} = \\frac{2k^2(M-i)}{Mi}$.\n\nIf $p \\neq 0.5$:\n- For $i \\le k$: $E_i(k) = \\frac{G_{ik}h_k}{h_i} = \\frac{(\\rho^k-\\rho^M)(\\rho^i-1)}{(q-p)\\rho^k(\\rho^M-1)} \\frac{(\\rho^k-1)/(\\rho^M-1)}{(\\rho^i-1)/(\\rho^M-1)} = \\frac{(\\rho^k-\\rho^M)(\\rho^k-1)}{(q-p)\\rho^k(\\rho^M-1)}$.\n- For $i > k$: $E_i(k) = \\frac{G_{ik}h_k}{h_i} = \\frac{(\\rho^k-1)(\\rho^i-\\rho^M)}{(q-p)\\rho^k(\\rho^M-1)} \\frac{(\\rho^k-1)/(\\rho^M-1)}{(\\rho^i-1)/(\\rho^M-1)} = \\frac{(\\rho^k-1)^2(\\rho^i-\\rho^M)}{(q-p)\\rho^k(\\rho^M-1)(\\rho^i-1)}$.\n\nA key insight is that for $i \\le k$, the expected number of visits $E_i(k)$ is independent of the starting position $i$. This is because any path starting at $i \\le k$ and conditioned to reach $M$ must first reach state $k$. By the strong Markov property, the expected number of visits to $k$ from that point onward is independent of the history before reaching $k$. Therefore, $E_i(k) = E_k(k)$ for all $i \\le k$. Our derived formulas confirm this.\n\nThese expressions provide the exact analytical values against which the numerical estimators are compared.",
            "answer": "```python\nimport numpy as np\n\n# A helper class for Weighted Ensemble walkers\nclass Walker:\n    \"\"\"A simple class to hold walker data for the WE simulation.\"\"\"\n    def __init__(self, position, weight, visits_k):\n        self.position = position\n        self.weight = weight\n        self.visits_k = visits_k\n\ndef exact_solver(M, p, i, k):\n    \"\"\"\n    Computes the exact conditional expectation E[visits to k | start at i, absorb at M].\n    The derivation is based on relating the conditional expectation to the unconditioned\n    process's Green's function G_ik and committor probabilities h_i, h_k.\n    E_i(k) = (G_ik * h_k) / h_i.\n    \"\"\"\n    if not (1 <= i < M and 1 <= k < M):\n        raise ValueError(\"i and k must be interior states.\")\n\n    if p == 0.5:\n        if i <= k:\n            # For i <= k, E_i(k) = E_k(k) = G_kk\n            # G_kk for p=0.5 is 2k(M-k)/M\n            return (2.0 * k * (M - k)) / M\n        else:  # i > k\n            h_i = i / M\n            h_k = k / M\n            G_ik = (2.0 * k * (M - i)) / M\n            if h_i == 0: return np.nan\n            return (G_ik * h_k) / h_i\n    else:\n        rho = (1.0 - p) / p\n        q = 1.0 - p\n        \n        if np.isclose(rho, 1.0): # Fallback for floating point inaccuracy\n             if i <= k:\n                return (2.0 * k * (M - k)) / M\n             else:\n                h_i = i / M\n                h_k = k / M\n                G_ik = (2.0 * k * (M - i)) / M\n                if h_i == 0: return np.nan\n                return (G_ik * h_k) / h_i\n\n        rho_M = rho**M\n        rho_k = rho**k\n        \n        if i <= k:\n            # For i <= k, E_i(k) = E_k(k) = G_kk\n            num = (rho_k - rho_M) * (rho_k - 1.0)\n            den = (q - p) * rho_k * (rho_M - 1.0)\n            if den == 0: return np.nan\n            return num / den\n        else:  # i > k\n            rho_i = rho**i\n            \n            # Denominator of Green's function\n            g_den = (q - p) * rho_k * (rho_M - 1.0)\n            if g_den == 0: return np.nan\n            \n            # Green's function G_ik for i > k\n            g_num = (rho_k - 1.0) * (rho_i - rho_M)\n            G_ik = g_num / g_den\n            \n            # Committor probabilities h_i and h_k\n            h_den = rho_M - 1.0\n            if h_den == 0: return np.nan\n            h_i = (rho_i - 1.0) / h_den\n            h_k = (rho_k - 1.0) / h_den\n            \n            if h_i == 0: return np.nan\n            return (G_ik * h_k) / h_i\n\n\ndef tps_solver(M, p, i, k, N):\n    \"\"\"\n    Computes the conditional expectation using a brute-force TPS-like estimator.\n    It generates N independent trajectories and averages the observable over those that\n    reach the target state M before the source state 0.\n    \"\"\"\n    accepted_visits = []\n    \n    for _ in range(N):\n        pos = i\n        visits = 1 if pos == k else 0\n        # Set a max number of steps to prevent infinite loops in pathological cases\n        for _ in range(100*M*M): \n            if np.random.rand() < p:\n                pos += 1\n            else:\n                pos -= 1\n\n            if pos == 0:\n                # Absorbed at A, reject path\n                break\n            \n            if pos == M:\n                # Absorbed at B, accept path\n                if pos == k: # The absorption state could be k\n                    visits += 1\n                accepted_visits.append(visits)\n                break\n            \n            if pos == k:\n                visits += 1\n        else:\n            # Trajectory did not terminate, can be ignored or handled. We ignore.\n            pass\n\n\n    if not accepted_visits:\n        return 0.0\n    \n    return np.mean(accepted_visits)\n\ndef we_solver(M, p, i, k, T, K):\n    \"\"\"\n    Computes the conditional expectation using a Weighted Ensemble (WE) estimator.\n    Walkers are propagated with unbiased dynamics. After each step, walkers in each\n    bin are resampled to a fixed number K, conserving total weight.\n    \"\"\"\n    # Bins for interior states {1, ..., M-1}\n    bins = [[] for _ in range(M + 1)]\n\n    # Initial state: K walkers at state i, each with weight 1/K\n    initial_visits = 1 if i == k else 0\n    for _ in range(K):\n        bins[i].append(Walker(i, 1.0 / K, initial_visits))\n    \n    total_weight_in_bins = 1.0\n    \n    # Accumulators for the final calculation\n    total_f_weight_in_B = 0.0\n    total_weight_in_B = 0.0\n\n    for _ in range(T):\n        if total_weight_in_bins < 1e-9:\n            break\n\n        # List to hold walkers after one step of propagation\n        next_bins = [[] for _ in range(M + 1)]\n        \n        # --- Propagation Step ---\n        for j in range(1, M):\n            for walker in bins[j]:\n                new_pos = walker.position + 1 if np.random.rand() < p else walker.position - 1\n                new_visits = walker.visits_k + 1 if new_pos == k else walker.visits_k\n\n                if new_pos == 0:\n                    # Absorbed at A, weight flux is lost\n                    continue\n                elif new_pos == M:\n                    # Absorbed at B, accumulate weight and observable*weight\n                    total_weight_in_B += walker.weight\n                    total_f_weight_in_B += walker.weight * new_visits\n                else:\n                    # Moved to another interior bin\n                    new_walker = Walker(new_pos, walker.weight, new_visits)\n                    next_bins[new_pos].append(new_walker)\n        \n        bins = next_bins\n\n        # --- Resampling (Splitting/Merging) Step ---\n        total_weight_in_bins = 0.0\n        for j in range(1, M):\n            n_walkers = len(bins[j])\n            if n_walkers == 0:\n                continue\n\n            bin_total_weight = sum(w.weight for w in bins[j])\n            \n            if n_walkers != K:\n                walker_weights = [w.weight for w in bins[j]]\n                \n                if bin_total_weight > 0:\n                    probs = [w / bin_total_weight for w in walker_weights]\n                else:\n                    probs = None # Uniform sampling if total weight is zero\n\n                chosen_indices = np.random.choice(n_walkers, size=K, p=probs, replace=True)\n                \n                new_walkers_in_bin = []\n                # New walkers have their attributes copied from parents, but weight is redistributed\n                new_weight = bin_total_weight / K\n                for index in chosen_indices:\n                    parent = bins[j][index]\n                    child = Walker(parent.position, new_weight, parent.visits_k)\n                    new_walkers_in_bin.append(child)\n                bins[j] = new_walkers_in_bin\n\n            total_weight_in_bins += sum(w.weight for w in bins[j])\n\n    if total_weight_in_B == 0:\n        return 0.0\n        \n    return total_f_weight_in_B / total_weight_in_B\n\ndef solve():\n    test_cases = [\n        # (M, p, i, k, T, K, N)\n        (12, 0.55, 3, 6, 3000, 40, 30000),\n        (12, 0.50, 4, 9, 4000, 60, 40000),\n        (18, 0.52, 1, 9, 5000, 60, 50000),\n    ]\n\n    results = []\n    tolerance = 0.03\n\n    for case in test_cases:\n        M, p, i, k, T, K, N = case\n        \n        exact_val = exact_solver(M, p, i, k)\n        tps_val = tps_solver(M, p, i, k, N)\n        we_val = we_solver(M, p, i, k, T, K)\n\n        is_equivalent = (\n            abs(tps_val - we_val) < tolerance and\n            abs(tps_val - exact_val) < tolerance and\n            abs(we_val - exact_val) < tolerance\n        )\n        results.append(is_equivalent)\n\n    # Format output as a Python list of booleans\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Path reweighting is a profoundly important concept in statistical physics, allowing one to calculate observables in a target system by simulating a different, often more convenient, reference system. Formally grounded in Girsanov's theorem, this \"computational alchemy\" is central to free energy calculations and importance sampling schemes. In this practice, , you will derive the exact reweighting factor for paths generated by Langevin dynamics when the friction coefficient is altered, providing a rigorous look at how path probabilities change with physical parameters.",
            "id": "3434793",
            "problem": "Consider one-dimensional overdamped Langevin dynamics at constant temperature $T$ in a differentiable potential $U(x)$, where the fluctuation–dissipation relation holds. For friction coefficient $\\gamma$, the stochastic differential equation is\n$$\n\\mathrm{d}x_t \\;=\\; -\\frac{1}{\\gamma}\\,U'(x_t)\\,\\mathrm{d}t \\;+\\; \\sqrt{\\frac{2 k_B T}{\\gamma}}\\,\\mathrm{d}W_t,\n$$\nwith $k_B$ the Boltzmann constant and $W_t$ a standard Wiener process. Use the Euler–Maruyama discretization with time step $\\Delta t$ to generate paths $x_{0:N} \\equiv (x_0, x_1, \\dots, x_N)$, where $x_{i+1}$ is conditionally Gaussian given $x_i$. Suppose a Transition Path Sampling (TPS) simulation is run under the above dynamics with friction $\\gamma$ until step $m-1$, and then, mid-run at step $m$, the friction is switched to a new value $\\gamma'$, with the thermostat noise adjusted to preserve the fluctuation–dissipation relation at temperature $T$.\n\nStarting only from the definitions of the Langevin process, the fluctuation–dissipation relation, and the Gaussian transition density induced by Euler–Maruyama discretization, do the following:\n\n1) Derive the discrete-time path probability density $P_{\\gamma}(x_{0:N})$ for friction $\\gamma$ as a product of Gaussian transition probabilities, and analogously $P_{\\gamma'}(x_{0:N})$ for friction $\\gamma'$.\n\n2) Using the Radon–Nikodym derivative interpretation from Girsanov’s theorem for changes of path measure, derive a closed-form expression for the likelihood ratio (path reweighting factor)\n$$\nW[x_{0:N}] \\;=\\; \\frac{P_{\\text{switch}}(x_{0:N})}{P_{\\gamma}(x_{0:N})},\n$$\nwhere $P_{\\text{switch}}(x_{0:N})$ is the path probability under the protocol that uses friction $\\gamma$ for steps $0,1,\\dots,m-1$ and friction $\\gamma'$ for steps $m,m+1,\\dots,N-1$. Express $W[x_{0:N}]$ explicitly in terms of $\\gamma$, $\\gamma'$, $k_B T$, $\\Delta t$, the positions $x_i$, and the potential derivative $U'(x_i)$.\n\n3) Validate your reweighting by proving that $\\mathbb{E}_{\\gamma}[W[x_{0:N}]] = 1$, where the expectation is taken over paths generated entirely at friction $\\gamma$.\n\n4) Let $k_{AB}$ denote the rate constant from state $A$ to state $B$, estimated in TPS as a path-ensemble expectation $\\mathbb{E}_{\\gamma}\\!\\left[ \\mathcal{O}[x_{0:N}] \\right]$ of an appropriate path observable $\\mathcal{O}[x_{0:N}]$ that counts reactive trajectories per unit time. Use the path reweighting identity to write $k_{AB}(\\gamma')$ exactly as a single expectation with respect to the original $\\gamma$-dynamics. Do not assume time-reversal symmetry or provide any specialized rate formula; your derivation must rely only on path-space change of measure.\n\nYour final answer must be a single closed-form analytic expression. Provide the expression for $W[x_{0:N}]$ requested in item 2). No numerical evaluation is required.",
            "solution": "The problem asks for several derivations related to path reweighting for one-dimensional overdamped Langevin dynamics when the friction coefficient is changed mid-simulation. We will proceed by first validating the problem statement and then providing a step-by-step derivation for each required item.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   **Dynamics:** One-dimensional overdamped Langevin dynamics described by the stochastic differential equation (SDE):\n    $$\n    \\mathrm{d}x_t \\;=\\; -\\frac{1}{\\gamma}\\,U'(x_t)\\,\\mathrm{d}t \\;+\\; \\sqrt{\\frac{2 k_B T}{\\gamma}}\\,\\mathrm{d}W_t\n    $$\n    where $x_t$ is the position, $U(x)$ is a differentiable potential, $\\gamma$ is the friction coefficient, $T$ is the constant temperature, $k_B$ is the Boltzmann constant, and $W_t$ is a standard Wiener process. The fluctuation–dissipation relation is stated to hold.\n-   **Discretization:** The dynamics are discretized using the Euler–Maruyama scheme with a constant time step $\\Delta t$. Paths are denoted $x_{0:N} \\equiv (x_0, x_1, \\dots, x_N)$.\n-   **Protocols and Path Probabilities:**\n    -   $P_{\\gamma}(x_{0:N})$ is the path probability density for a path generated entirely with friction $\\gamma$.\n    -   $P_{\\text{switch}}(x_{0:N})$ is the path probability for a protocol where friction is $\\gamma$ for steps $i = 0, 1, \\dots, m-1$ (i.e., transitions up to $x_{m-1} \\to x_m$) and $\\gamma'$ for steps $i = m, m+1, \\dots, N-1$ (i.e., transitions from $x_m \\to x_{m+1}$ onwards).\n-   **Tasks:**\n    1.  Derive the discrete-time path probabilities $P_{\\gamma}(x_{0:N})$ and $P_{\\gamma'}(x_{0:N})$.\n    2.  Derive the likelihood ratio $W[x_{0:N}] = P_{\\text{switch}}(x_{0:N}) / P_{\\gamma}(x_{0:N})$.\n    3.  Prove that the expectation $\\mathbb{E}_{\\gamma}[W[x_{0:N}]] = 1$.\n    4.  Express the rate constant $k_{AB}(\\gamma')$ as an expectation over the $\\gamma$-dynamics.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is firmly rooted in the principles of statistical mechanics, stochastic processes (Langevin dynamics), and numerical methods (Euler–Maruyama). The concept of path reweighting is a standard and rigorous technique in computational physics, related to importance sampling and Girsanov's theorem.\n-   **Well-Posed:** The problem is well-defined. It provides a clear physical and mathematical setup and asks for specific, derivable quantities. The tasks are logically sequenced and lead to a clear objective.\n-   **Objective:** The language is formal, precise, and free of any subjective or non-scientific claims.\n-   **Completeness and Consistency:** The problem provides all necessary information: the SDE, the discretization scheme, the definition of the path ensembles, and the quantities to be derived. There are no apparent contradictions.\n-   **Realism and Feasibility:** The scenario described is a practical one in computational simulations, particularly in the context of free energy calculations and rare event sampling where system parameters might be changed to enhance sampling. The derivations are mathematically tractable.\n-   **Other Flaws:** The problem is neither trivial nor tautological, and it directly addresses the specified topic of path sampling methods in molecular dynamics.\n\n**Step 3: Verdict and Action**\nThe problem is valid. I will proceed with the full solution.\n\n### Derivations\n\nThe Euler–Maruyama discretization of the given SDE is:\n$$\nx_{i+1} - x_i = -\\frac{1}{\\gamma} U'(x_i) \\Delta t + \\sqrt{\\frac{2 k_B T}{\\gamma}} \\Delta W_i\n$$\nwhere $\\Delta W_i$ is an increment of the Wiener process, which is a Gaussian random variable with mean $0$ and variance $\\Delta t$. Let $Z_i = \\Delta W_i / \\sqrt{\\Delta t}$ be a standard normal random variable ($Z_i \\sim \\mathcal{N}(0,1)$). The discretization can be written as:\n$$\nx_{i+1} = x_i - \\frac{1}{\\gamma} U'(x_i) \\Delta t + \\sqrt{\\frac{2 k_B T \\Delta t}{\\gamma}} Z_i\n$$\nThis equation shows that given $x_i$, the next position $x_{i+1}$ is a Gaussian-distributed random variable. The conditional probability density $P_{\\gamma}(x_{i+1}|x_i)$ is that of a Gaussian distribution with mean $\\mu_i(\\gamma)$ and variance $\\sigma^2(\\gamma)$:\n$$\n\\mu_i(\\gamma) = x_i - \\frac{1}{\\gamma} U'(x_i) \\Delta t\n$$\n$$\n\\sigma^2(\\gamma) = \\frac{2 k_B T \\Delta t}{\\gamma}\n$$\nThe conditional probability density is therefore:\n$$\nP_{\\gamma}(x_{i+1}|x_i) = \\frac{1}{\\sqrt{2\\pi \\sigma^2(\\gamma)}} \\exp\\left( -\\frac{(x_{i+1} - \\mu_i(\\gamma))^2}{2\\sigma^2(\\gamma)} \\right)\n$$\n$$\nP_{\\gamma}(x_{i+1}|x_i) = \\left(\\frac{\\gamma}{4\\pi k_B T \\Delta t}\\right)^{1/2} \\exp\\left( -\\frac{\\gamma \\left(x_{i+1} - x_i + \\frac{1}{\\gamma}U'(x_i)\\Delta t\\right)^2}{4 k_B T \\Delta t} \\right)\n$$\n\n**1) Derivation of Path Probabilities**\n\nThe probability of an entire path $x_{0:N} = (x_0, x_1, \\dots, x_N)$, given a fixed starting point $x_0$, is the product of the conditional probabilities for each step, by the Markov property of the process:\n$$\nP_{\\gamma}(x_{0:N}) = \\prod_{i=0}^{N-1} P_{\\gamma}(x_{i+1}|x_i)\n$$\nSubstituting the Gaussian density, we get:\n$$\nP_{\\gamma}(x_{0:N}) = \\prod_{i=0}^{N-1} \\left(\\frac{\\gamma}{4\\pi k_B T \\Delta t}\\right)^{1/2} \\exp\\left( -\\frac{\\gamma \\left(x_{i+1} - x_i + \\frac{1}{\\gamma}U'(x_i)\\Delta t\\right)^2}{4 k_B T \\Delta t} \\right)\n$$\nAnalogously, for a path generated entirely with friction $\\gamma'$, we have:\n$$\nP_{\\gamma'}(x_{0:N}) = \\prod_{i=0}^{N-1} P_{\\gamma'}(x_{i+1}|x_i) = \\prod_{i=0}^{N-1} \\left(\\frac{\\gamma'}{4\\pi k_B T \\Delta t}\\right)^{1/2} \\exp\\left( -\\frac{\\gamma' \\left(x_{i+1} - x_i + \\frac{1}{\\gamma'}U'(x_i)\\Delta t\\right)^2}{4 k_B T \\Delta t} \\right)\n$$\n\n**2) Derivation of the Reweighting Factor $W[x_{0:N}]$**\n\nThe path probability for the switched protocol, $P_{\\text{switch}}(x_{0:N})$, uses $\\gamma$ for the first $m$ steps (from $i=0$ to $i=m-1$) and $\\gamma'$ for the remaining steps (from $i=m$ to $i=N-1$):\n$$\nP_{\\text{switch}}(x_{0:N}) = \\left( \\prod_{i=0}^{m-1} P_{\\gamma}(x_{i+1}|x_i) \\right) \\left( \\prod_{i=m}^{N-1} P_{\\gamma'}(x_{i+1}|x_i) \\right)\n$$\nThe reweighting factor is the ratio $W[x_{0:N}] = P_{\\text{switch}}(x_{0:N}) / P_{\\gamma}(x_{0:N})$. We substitute the expressions for the path probabilities:\n$$\nW[x_{0:N}] = \\frac{\\left( \\prod_{i=0}^{m-1} P_{\\gamma}(x_{i+1}|x_i) \\right) \\left( \\prod_{i=m}^{N-1} P_{\\gamma'}(x_{i+1}|x_i) \\right)}{\\prod_{i=0}^{N-1} P_{\\gamma}(x_{i+1}|x_i)}\n$$\nThe denominator can be split: $\\prod_{i=0}^{N-1} P_{\\gamma}(...) = (\\prod_{i=0}^{m-1} P_{\\gamma}(...))(\\prod_{i=m}^{N-1} P_{\\gamma}(...))$. The first part cancels out:\n$$\nW[x_{0:N}] = \\frac{\\prod_{i=m}^{N-1} P_{\\gamma'}(x_{i+1}|x_i)}{\\prod_{i=m}^{N-1} P_{\\gamma}(x_{i+1}|x_i)} = \\prod_{i=m}^{N-1} \\frac{P_{\\gamma'}(x_{i+1}|x_i)}{P_{\\gamma}(x_{i+1}|x_i)}\n$$\nLet's compute the ratio for a single step $i$:\n$$\n\\frac{P_{\\gamma'}(x_{i+1}|x_i)}{P_{\\gamma}(x_{i+1}|x_i)} = \\frac{\\left(\\frac{\\gamma'}{4\\pi k_B T \\Delta t}\\right)^{1/2}}{\\left(\\frac{\\gamma}{4\\pi k_B T \\Delta t}\\right)^{1/2}} \\exp\\left( -\\frac{(x_{i+1}-\\mu_i(\\gamma'))^2}{2\\sigma^2(\\gamma')} + \\frac{(x_{i+1}-\\mu_i(\\gamma))^2}{2\\sigma^2(\\gamma)} \\right)\n$$\nThe ratio of prefactors is $\\sqrt{\\gamma'/\\gamma}$. The argument of the exponential is:\n$$\n\\frac{(x_{i+1}-\\mu_i(\\gamma))^2}{2\\sigma^2(\\gamma)} - \\frac{(x_{i+1}-\\mu_i(\\gamma'))^2}{2\\sigma^2(\\gamma')} = \\frac{\\gamma \\left(x_{i+1} - x_i + \\frac{U'(x_i)}{\\gamma}\\Delta t\\right)^2}{4 k_B T \\Delta t} - \\frac{\\gamma' \\left(x_{i+1} - x_i + \\frac{U'(x_i)}{\\gamma'}\\Delta t\\right)^2}{4 k_B T \\Delta t}\n$$\nLet $\\delta x_i = x_{i+1} - x_i$ and $F_i = U'(x_i)$. The expression becomes:\n$$\n\\frac{1}{4 k_B T \\Delta t} \\left[ \\gamma(\\delta x_i + \\frac{F_i}{\\gamma}\\Delta t)^2 - \\gamma'(\\delta x_i + \\frac{F_i}{\\gamma'}\\Delta t)^2 \\right]\n$$\n$$\n= \\frac{1}{4 k_B T \\Delta t} \\left[ \\gamma\\left(\\delta x_i^2 + \\frac{2F_i}{\\gamma}\\Delta t \\delta x_i + \\frac{F_i^2}{\\gamma^2}\\Delta t^2\\right) - \\gamma'\\left(\\delta x_i^2 + \\frac{2F_i}{\\gamma'}\\Delta t \\delta x_i + \\frac{F_i^2}{(\\gamma')^2}\\Delta t^2\\right) \\right]\n$$\n$$\n= \\frac{1}{4 k_B T \\Delta t} \\left[ (\\gamma\\delta x_i^2 + 2F_i\\Delta t \\delta x_i + \\frac{F_i^2}{\\gamma}\\Delta t^2) - (\\gamma'\\delta x_i^2 + 2F_i\\Delta t \\delta x_i + \\frac{F_i^2}{\\gamma'}\\Delta t^2) \\right]\n$$\n$$\n= \\frac{1}{4 k_B T \\Delta t} \\left[ (\\gamma - \\gamma')\\delta x_i^2 + F_i^2\\Delta t^2\\left(\\frac{1}{\\gamma} - \\frac{1}{\\gamma'}\\right) \\right] = \\frac{1}{4 k_B T \\Delta t} \\left[ (\\gamma - \\gamma')\\delta x_i^2 + F_i^2\\Delta t^2\\left(\\frac{\\gamma'-\\gamma}{\\gamma\\gamma'}\\right) \\right]\n$$\n$$\n= \\frac{\\gamma - \\gamma'}{4 k_B T \\Delta t} \\left[ (\\delta x_i)^2 - \\frac{F_i^2 (\\Delta t)^2}{\\gamma\\gamma'} \\right] = \\frac{\\gamma - \\gamma'}{4 k_B T \\Delta t} \\left[ (x_{i+1}-x_i)^2 - \\frac{(U'(x_i))^2 (\\Delta t)^2}{\\gamma \\gamma'} \\right]\n$$\nTaking the product over $i$ from $m$ to $N-1$ (which has $N-m$ terms):\n$$\nW[x_{0:N}] = \\prod_{i=m}^{N-1} \\left(\\frac{\\gamma'}{\\gamma}\\right)^{1/2} \\exp\\left( \\frac{\\gamma - \\gamma'}{4 k_B T \\Delta t} \\left[ (x_{i+1}-x_i)^2 - \\frac{(U'(x_i))^2 (\\Delta t)^2}{\\gamma \\gamma'} \\right] \\right)\n$$\n$$\nW[x_{0:N}] = \\left(\\frac{\\gamma'}{\\gamma}\\right)^{(N-m)/2} \\exp\\left( \\frac{\\gamma - \\gamma'}{4 k_B T \\Delta t} \\sum_{i=m}^{N-1} \\left[ (x_{i+1}-x_i)^2 - \\frac{(U'(x_i))^2 (\\Delta t)^2}{\\gamma \\gamma'} \\right] \\right)\n$$\n\n**3) Validation of Reweighting**\n\nWe must prove that $\\mathbb{E}_{\\gamma}[W[x_{0:N}]] = 1$. The expectation with respect to the $\\gamma$-dynamics is defined as an integral over all possible paths (from a fixed $x_0$), weighted by the path probability $P_{\\gamma}(x_{0:N})$.\n$$\n\\mathbb{E}_{\\gamma}[W[x_{0:N}]] = \\int W[x_{0:N}] P_{\\gamma}(x_{0:N}) \\, \\mathrm{d}x_{1:N}\n$$\nwhere $\\mathrm{d}x_{1:N} = \\mathrm{d}x_1 \\mathrm{d}x_2 \\dots \\mathrm{d}x_N$. Substituting the definition $W[x_{0:N}] = P_{\\text{switch}}(x_{0:N}) / P_{\\gamma}(x_{0:N})$:\n$$\n\\mathbb{E}_{\\gamma}[W[x_{0:N}]] = \\int \\frac{P_{\\text{switch}}(x_{0:N})}{P_{\\gamma}(x_{0:N})} P_{\\gamma}(x_{0:N}) \\, \\mathrm{d}x_{1:N} = \\int P_{\\text{switch}}(x_{0:N}) \\, \\mathrm{d}x_{1:N}\n$$\nThe integral of $P_{\\text{switch}}(x_{0:N})$ over all possible paths must equal $1$ because $P_{\\text{switch}}(x_{0:N})$ is a valid, normalized probability density function for a path. We can show this explicitly by iterated integration:\n$$\n\\int P_{\\text{switch}}(x_{0:N}) \\, \\mathrm{d}x_{1:N} = \\int \\dots \\int \\left( \\prod_{i=0}^{m-1} P_{\\gamma}(x_{i+1}|x_i) \\right) \\left( \\prod_{j=m}^{N-1} P_{\\gamma'}(x_{j+1}|x_j) \\right) \\, \\mathrm{d}x_1 \\dots \\mathrm{d}x_N\n$$\nIntegrating over $x_N$ first: $\\int P_{\\gamma'}(x_N|x_{N-1}) \\, \\mathrm{d}x_N = 1$ since $P_{\\gamma'}$ is a normalized conditional PDF. This process is repeated backward for $x_{N-1}, \\dots, x_{m+1}$. Then, for $x_m, \\dots, x_1$, we use $\\int P_{\\gamma}(x_{i+1}|x_i) \\, \\mathrm{d}x_{i+1} = 1$. After all $N$ integrations, the result is $1$. Thus, $\\mathbb{E}_{\\gamma}[W[x_{0:N}]] = 1$.\n\n**4) Rate Constant Expression**\n\nThe rate constant $k_{AB}(\\gamma')$ is given as an expectation of an observable $\\mathcal{O}[x_{0:N}]$ over the path ensemble generated with friction $\\gamma'$:\n$$\nk_{AB}(\\gamma') = \\mathbb{E}_{\\gamma'}\\left[ \\mathcal{O}[x_{0:N}] \\right] = \\int \\mathcal{O}[x_{0:N}] P_{\\gamma'}(x_{0:N}) \\, \\mathrm{d}x_{1:N}\n$$\nTo express this as an expectation with respect to the $\\gamma$-dynamics, we use the identity $1 = P_{\\gamma}(x_{0:N})/P_{\\gamma}(x_{0:N})$:\n$$\nk_{AB}(\\gamma') = \\int \\mathcal{O}[x_{0:N}] \\frac{P_{\\gamma'}(x_{0:N})}{P_{\\gamma}(x_{0:N})} P_{\\gamma}(x_{0:N}) \\, \\mathrm{d}x_{1:N}\n$$\nLet $W'[x_{0:N}] = P_{\\gamma'}(x_{0:N}) / P_{\\gamma}(x_{0:N})$. This is the reweighting factor for switching the friction for the entire path duration (i.e., $m=0$ in our previous derivation). The integral is now recognizable as an expectation over the $\\gamma$-ensemble:\n$$\nk_{AB}(\\gamma') = \\int \\left( \\mathcal{O}[x_{0:N}] W'[x_{0:N}] \\right) P_{\\gamma}(x_{0:N}) \\, \\mathrm{d}x_{1:N} = \\mathbb{E}_{\\gamma}\\left[ \\mathcal{O}[x_{0:N}] W'[x_{0:N}] \\right]\n$$\nThis is the desired expression. $W'[x_{0:N}]$ is obtained from the result of part 2) by setting $m=0$.\n\nThe final answer requested is the expression for $W[x_{0:N}]$ from item 2).",
            "answer": "$$\n\\boxed{\\left(\\frac{\\gamma'}{\\gamma}\\right)^{\\frac{N-m}{2}} \\exp\\left( \\frac{\\gamma - \\gamma'}{4 k_B T \\Delta t} \\sum_{i=m}^{N-1} \\left[ (x_{i+1}-x_i)^2 - \\frac{(U'(x_i))^2 (\\Delta t)^2}{\\gamma \\gamma'} \\right] \\right)}\n$$"
        }
    ]
}