{
    "hands_on_practices": [
        {
            "introduction": "Before tackling complex numerical implementations, it is essential to grasp the core principle of force matching on a simple, analytically solvable system. This exercise explores a one-dimensional harmonic dimer to reveal a fundamental property of internal forces in coarse-graining. By calculating the mean force on the center of mass from first principles, you will solidify the connection between microscopic interactions and the resulting coarse-grained force, providing a crucial sanity check for more advanced models .",
            "id": "3399907",
            "problem": "Consider a one-dimensional Molecular Dynamics (MD) system consisting of two identical atoms connected by a harmonic spring and embedded in a thermal bath at temperature $T$. Let the atom positions be $x_1$ and $x_2$, and define the internal coordinate $r = x_1 - x_2$ and the Coarse-Grained (CG) mapping $R = (x_1 + x_2)/2$. The interaction potential between the two atoms is harmonic with equilibrium separation $a$ and spring constant $k$, given by the total potential energy\n$$\nU(x_1, x_2) = \\frac{k}{2}\\,(x_1 - x_2 - a)^{2}.\n$$\nAt equilibrium, the configurational distribution is canonical, with probability density proportional to $\\exp(-\\beta U)$, where $\\beta = 1/(k_B T)$ and $k_B$ is the Boltzmann constant. The microscopic forces on the atoms are defined by Newton’s second law and the conservative force relation $f_i = -\\partial U/\\partial x_i$ for $i \\in \\{1,2\\}$.\n\nIn bottom-up coarse-graining via force matching, the mean CG force associated with the mapping $R$ is obtained as the conditional ensemble average of the sum of the microscopic forces over all microscopic configurations consistent with the fixed CG coordinate $R$. Denote this conditional average over the internal coordinate $r$ at fixed $R$ by $\\langle \\cdot \\rangle_{r|R}$.\n\nStarting from the above definitions and equilibrium statistical mechanics, derive and compute the mean CG force\n$$\n\\left\\langle f_1 + f_2 \\right\\rangle_{r|R}\n$$\nfor the system defined, assuming no external field acts on $R$ and the only interaction is the harmonic internal potential $U(x_1, x_2)$ specified above. Express your final answer in Newtons. The answer must be a single real-valued number or a single closed-form analytic expression.",
            "solution": "The user wants to solve the problem:\n\"Consider a one-dimensional Molecular Dynamics (MD) system consisting of two identical atoms connected by a harmonic spring and embedded in a thermal bath at temperature $T$. Let the atom positions be $x_1$ and $x_2$, and define the internal coordinate $r = x_1 - x_2$ and the Coarse-Grained (CG) mapping $R = (x_1 + x_2)/2$. The interaction potential between the two atoms is harmonic with equilibrium separation $a$ and spring constant $k$, given by the total potential energy\n$$\nU(x_1, x_2) = \\frac{k}{2}\\,(x_1 - x_2 - a)^{2}.\n$$\nAt equilibrium, the configurational distribution is canonical, with probability density proportional to $\\exp(-\\beta U)$, where $\\beta = 1/(k_B T)$ and $k_B$ is the Boltzmann constant. The microscopic forces on the atoms are defined by Newton’s second law and the conservative force relation $f_i = -\\partial U/\\partial x_i$ for $i \\in \\{1,2\\}$.\n\nIn bottom-up coarse-graining via force matching, the mean CG force associated with the mapping $R$ is obtained as the conditional ensemble average of the sum of the microscopic forces over all microscopic configurations consistent with the fixed CG coordinate $R$. Denote this conditional average over the internal coordinate $r$ at fixed $R$ by $\\langle \\cdot \\rangle_{r|R}$.\n\nStarting from the above definitions and equilibrium statistical mechanics, derive and compute the mean CG force\n$$\n\\left\\langle f_1 + f_2 \\right\\rangle_{r|R}\n$$\nfor the system defined, assuming no external field acts on $R$ and the only interaction is the harmonic internal potential $U(x_1, x_2)$ specified above. Express your final answer in Newtons. The answer must be a single real-valued number or a single closed-form analytic expression.\"\n\nThe provided problem statement is being validated.\n\n### Step 1: Extract Givens\n-   System: 1D, two identical atoms.\n-   Atom positions: $x_1$, $x_2$.\n-   Internal coordinate: $r = x_1 - x_2$.\n-   Coarse-Grained (CG) coordinate: $R = (x_1 + x_2)/2$.\n-   Potential energy: $U(x_1, x_2) = \\frac{k}{2}\\,(x_1 - x_2 - a)^{2}$.\n-   Equilibrium distribution: Probability density is proportional to $\\exp(-\\beta U)$, with $\\beta = 1/(k_B T)$.\n-   Microscopic forces: $f_i = -\\partial U/\\partial x_i$ for $i \\in \\{1,2\\}$.\n-   Objective: Compute the mean CG force $\\left\\langle f_1 + f_2 \\right\\rangle_{r|R}$.\n-   Condition: No external field acts on $R$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded:** The problem is a standard exercise in statistical mechanics and coarse-graining theory, based on the harmonic oscillator model, the canonical ensemble, and the principles of force matching. All concepts are scientifically sound.\n-   **Well-Posed:** The problem provides all necessary definitions and constraints to compute the required quantity. The definitions of coordinates, potential, forces, and the averaging procedure are clear and unambiguous.\n-   **Objective:** The problem is stated in precise, objective mathematical and physical language.\n\nThe potential energy $U(x_1, x_2)$ depends only on the relative distance $x_1 - x_2$. This implies that the internal forces of the system are translationally invariant. The lack of an external potential on the center of mass coordinate $R$ leads to a non-normalizable partition function if integrated over all space, but this is a standard feature of such systems and does not invalidate the calculation of conditional averages, as the problematic degrees of freedom factor out. The problem is self-contained, consistent, and scientifically valid.\n\n### Step 3: Verdict and Action\nThe problem is valid. A detailed solution will be provided.\n\nThe objective is to compute the mean Coarse-Grained (CG) force, which is defined as the conditional ensemble average of the sum of the microscopic forces, $\\langle f_1 + f_2 \\rangle_{r|R}$. The microscopic forces $f_1$ and $f_2$ on atom $1$ and atom $2$, respectively, are derived from the potential energy $U(x_1, x_2)$.\n\nThe potential energy is given as:\n$$\nU(x_1, x_2) = \\frac{k}{2}(x_1 - x_2 - a)^{2}\n$$\nwhere $k$ is the spring constant and $a$ is the equilibrium separation.\n\nThe force on atom $1$ is the negative gradient of the potential with respect to its position $x_1$:\n$$\nf_1 = -\\frac{\\partial U}{\\partial x_1}\n$$\nSubstituting the expression for $U(x_1, x_2)$ and applying the chain rule:\n$$\nf_1 = -\\frac{\\partial}{\\partial x_1} \\left[ \\frac{k}{2}(x_1 - x_2 - a)^{2} \\right] = -\\frac{k}{2} \\cdot 2(x_1 - x_2 - a) \\cdot \\frac{\\partial}{\\partial x_1}(x_1 - x_2 - a)\n$$\n$$\nf_1 = -k(x_1 - x_2 - a) \\cdot (1) = -k(x_1 - x_2 - a)\n$$\n\nSimilarly, the force on atom $2$ is the negative gradient of the potential with respect to its position $x_2$:\n$$\nf_2 = -\\frac{\\partial U}{\\partial x_2}\n$$\nSubstituting the expression for $U(x_1, x_2)$ and applying the chain rule:\n$$\nf_2 = -\\frac{\\partial}{\\partial x_2} \\left[ \\frac{k}{2}(x_1 - x_2 - a)^{2} \\right] = -\\frac{k}{2} \\cdot 2(x_1 - x_2 - a) \\cdot \\frac{\\partial}{\\partial x_2}(x_1 - x_2 - a)\n$$\n$$\nf_2 = -k(x_1 - x_2 - a) \\cdot (-1) = k(x_1 - x_2 - a)\n$$\n\nThe sum of the microscopic forces is:\n$$\nf_1 + f_2 = \\left[-k(x_1 - x_2 - a)\\right] + \\left[k(x_1 - x_2 - a)\\right] = 0\n$$\nThe sum of the internal forces on the two atoms is identically zero. This is a direct consequence of the interaction potential $U$ depending only on the relative separation of the particles, $r = x_1 - x_2$. This property ensures that the internal forces satisfy Newton's third law ($f_1 = -f_2$) and reflects the translational invariance of the system's internal interactions. The total force due to internal interactions cannot cause an acceleration of the system's center of mass.\n\nThe quantity to be averaged, $\\langle f_1 + f_2 \\rangle_{r|R}$, is the conditional average of the sum of the forces. Since the sum $f_1 + f_2$ is equal to $0$ for any microscopic configuration $(x_1, x_2)$, its average over any ensemble, including the conditional ensemble at fixed $R$, must also be zero.\n$$\n\\left\\langle f_1 + f_2 \\right\\rangle_{r|R} = \\langle 0 \\rangle_{r|R} = 0\n$$\nThe details of the canonical distribution, the temperature $T$, and the Boltzmann constant $k_B$ are irrelevant to the final result, as the quantity being averaged is identically zero before any averaging is performed. The result holds for any potential of the form $U(x_1 - x_2)$.\n\nPhysically, the \"mean CG force\" as defined in the problem represents the average total force acting on the center of mass due to internal interactions. For an isolated system (no external fields), this force must be zero, as internal forces cannot change the state of motion of the center of mass. This is consistent with the calculation of the potential of mean force for the CG coordinate $R$. Since the potential $U$ does not depend on $R$, the marginal probability for $R$ is uniform, which corresponds to a constant potential of mean force, and thus a zero force on the CG coordinate $R$.\n\nTherefore, the mean CG force is exactly zero.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "Moving from analytical theory to practical application, we often approximate the unknown coarse-grained potential as a linear combination of pre-defined basis functions. This practice demonstrates how to translate the force matching principle into a standard linear least-squares problem, a cornerstone of modern scientific computing . You will learn to construct the design matrix and target vector from raw configuration and force data, providing a direct recipe for solving for the parameters of a coarse-grained model.",
            "id": "3399938",
            "problem": "You are given a bottom-up coarse-graining task framed as a linear force-matching problem in Molecular Dynamics (MD). The fundamental base is that for conservative coarse-grained forces, the force on coarse coordinates $R \\in \\mathbb{R}^D$ is the negative gradient of a potential $U_{\\theta}(R)$ that is modeled as a linear expansion in a set of basis functions $\\{B_k(R)\\}_{k=1}^K$, i.e., $U_{\\theta}(R) = \\sum_{k=1}^K \\theta_k B_k(R)$. The force is then $F_{\\theta}(R) = -\\nabla_R U_{\\theta}(R) = -\\sum_{k=1}^K \\theta_k \\nabla_R B_k(R)$. In force matching, we use the fine-grained forces $f(r_n) \\in \\mathbb{R}^{d_{\\mathrm{fg}}}$ at fine-grained coordinates $r_n$, and a linear mapping $\\Xi \\in \\mathbb{R}^{D \\times d_{\\mathrm{fg}}}$ to obtain coarse-grained force targets $b_n = \\Xi f(r_n) \\in \\mathbb{R}^D$. The least-squares problem is to find $\\theta \\in \\mathbb{R}^K$ minimizing $\\sum_{n=1}^N \\|F_{\\theta}(R_n) - b_n\\|_2^2$. This reduces to a linear system $A \\theta \\approx b$ with a design matrix $A \\in \\mathbb{R}^{(N D) \\times K}$ constructed by stacking the negative gradients of the basis functions evaluated at samples $\\{R_n\\}_{n=1}^N$.\n\nYour task is to implement a program that, for each provided test case, constructs the design matrix entries $A_{(n,d),k} = \\left(-\\nabla_R B_k(R_n)\\right)_d$ for each sample index $n \\in \\{1,\\dots,N\\}$ and component $d \\in \\{1,\\dots,D\\}$, constructs targets $b_{(n,d)} = \\left(\\Xi f(r_n)\\right)_d$, solves the linear least-squares problem for $\\theta$, and reports the coefficients. Angles must be interpreted in radians. All quantities are dimensionless. The program must use the following basis functions in two dimensions $D = 2$ with $R = (x,y)$:\n- $B_1(R) = \\tfrac{1}{2} \\left(x^2 + y^2\\right)$,\n- $B_2(R) = x y$,\n- $B_3(R) = \\sin(x)$,\n- $B_4(R) = \\cos(y)$.\nFor these, the negative gradients to be used for the design matrix are:\n- $-\\nabla_R B_1(R) = \\left(-x, -y\\right)$,\n- $-\\nabla_R B_2(R) = \\left(-y, -x\\right)$,\n- $-\\nabla_R B_3(R) = \\left(-\\cos(x), 0\\right)$,\n- $-\\nabla_R B_4(R) = \\left(0, \\sin(y)\\right)$.\nStack rows in $A$ and elements in $b$ by sample-major, component-minor order, i.e., for $n = 1, \\dots, N$ stack first the $x$-component row, then the $y$-component row.\n\nSolve for $\\theta$ using linear least squares in the Euclidean norm. If $A$ is rank-deficient, return the minimum-norm least-squares solution. For each test case, return the vector $\\theta \\in \\mathbb{R}^4$, rounded to six decimal places.\n\nTest suite:\n- Test case $1$ (happy path, identity mapping):\n  - $N = 3$, $D = 2$, $K = 4$, $d_{\\mathrm{fg}} = 2$.\n  - $R_1 = (0.0, 0.0)$, $R_2 = (1.0, 0.5)$, $R_3 = (-0.5, 1.0)$.\n  - $r_1 = (0.0, 0.0)$, $r_2 = (1.0, 0.5)$, $r_3 = (-0.5, 1.0)$.\n  - $\\Xi = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 1.0 \\end{bmatrix}$.\n  - $f(r_1) = (-0.5, 0.0)$; $f(r_2) = (-1.770151153, -0.119856385)$; $f(r_3) = (1.561208719, -2.710367746)$.\n- Test case $2$ (boundary case with near-singular design, identity mapping):\n  - $N = 2$, $D = 2$, $K = 4$, $d_{\\mathrm{fg}} = 2$.\n  - $R_1 = (1.0, 0.0)$, $R_2 = (2.0, 0.0)$.\n  - $r_1 = (1.0, 0.0)$, $r_2 = (2.0, 0.0)$.\n  - $\\Xi = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 1.0 \\end{bmatrix}$.\n  - $f(r_1) = (-0.729848847, -2.0)$; $f(r_2) = (-2.208073419, -4.0)$.\n- Test case $3$ (nontrivial mapping from fine-grained to coarse-grained forces):\n  - $N = 2$, $D = 2$, $K = 4$, $d_{\\mathrm{fg}} = 4$.\n  - $R_1 = (0.3, -0.7)$, $R_2 = (-1.2, 0.8)$.\n  - $r_1 = (0.3, 0.4, -0.7, -0.9)$, $r_2 = (-1.2, -1.1, 0.8, 0.6)$.\n  - $\\Xi = \\begin{bmatrix} 0.5 & 0.5 & 0.0 & 0.0 \\\\ 0.0 & 0.0 & 0.5 & 0.5 \\end{bmatrix}$.\n  - $f(r_1) = (2.0, 4.0, -1.0, 1.0)$; $f(r_2) = (-0.5, 1.5, 2.0, 2.0)$.\n- Test case $4$ (zero-force edge case):\n  - $N = 3$, $D = 2$, $K = 4$, $d_{\\mathrm{fg}} = 2$.\n  - $R_1 = (0.2, 0.2)$, $R_2 = (1.1, -1.1)$, $R_3 = (-2.0, 2.0)$.\n  - $r_1 = (0.2, 0.2)$, $r_2 = (1.1, -1.1)$, $r_3 = (-2.0, 2.0)$.\n  - $\\Xi = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 1.0 \\end{bmatrix}$.\n  - $f(r_1) = (0.0, 0.0)$; $f(r_2) = (0.0, 0.0)$; $f(r_3) = (0.0, 0.0)$.\n\nRequired algorithm, for each test case:\n1. Construct $A \\in \\mathbb{R}^{(N D) \\times K}$ with rows indexed by $(n,d)$ where $n \\in \\{1,\\dots,N\\}$, $d \\in \\{1,2\\}$, and $A_{(n,d),k} = \\left(-\\nabla_R B_k(R_n)\\right)_d$.\n2. Construct $b \\in \\mathbb{R}^{N D}$ by stacking $b_{(n,1)}$ then $b_{(n,2)}$ for each $n$, where $b_n = \\Xi f(r_n)$.\n3. Solve for $\\theta$ by minimizing $\\|A \\theta - b\\|_2^2$; if $A$ is rank-deficient, return the minimum-norm solution.\n4. Round each component of $\\theta$ to six decimal places.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case’s result is itself a bracketed, comma-separated list of the four rounded coefficients with no spaces. For example: \"[[a1,a2,a3,a4],[b1,b2,b3,b4],[c1,c2,c3,c4],[d1,d2,d3,d4]]\" where each placeholder is a float rounded to six decimals.",
            "solution": "The problem is assessed to be **valid**. It is scientifically grounded in the principles of molecular dynamics and statistical mechanics, specifically the method of force matching for coarse-graining. The problem is well-posed, providing all necessary data and definitions to construct a solvable linear least-squares problem. The instructions are objective, precise, and free of contradictions or ambiguities.\n\nThe task is to determine the optimal coefficients $\\theta \\in \\mathbb{R}^K$ for a coarse-grained potential model by minimizing the difference between model forces and target forces derived from a high-resolution simulation. This is a classic bottom-up coarse-graining procedure framed as a linear regression problem.\n\nThe coarse-grained potential energy $U_{\\theta}(R)$ is defined as a linear combination of $K$ basis functions $\\{B_k(R)\\}_{k=1}^K$:\n$$\nU_{\\theta}(R) = \\sum_{k=1}^{K} \\theta_k B_k(R)\n$$\nwhere $R \\in \\mathbb{R}^D$ are the coarse-grained coordinates and $\\theta = (\\theta_1, \\dots, \\theta_K)^T$ is the vector of coefficients to be determined. In this problem, the spatial dimension is $D=2$ and the number of basis functions is $K=4$.\n\nThe force on the coarse-grained system is the negative gradient of this potential with respect to the coordinates $R$:\n$$\nF_{\\theta}(R) = -\\nabla_R U_{\\theta}(R) = -\\nabla_R \\left(\\sum_{k=1}^{K} \\theta_k B_k(R)\\right) = \\sum_{k=1}^{K} \\theta_k (-\\nabla_R B_k(R))\n$$\nThis equation shows that the model force $F_{\\theta}(R)$ is linear in the coefficients $\\theta_k$. The terms $-\\nabla_R B_k(R)$ are vector-valued functions that act as the basis for the force field.\n\nThe goal of force matching is to find the parameter vector $\\theta$ that makes the model forces $F_{\\theta}(R_n)$ best match a set of target forces $b_n$ for a series of $N$ configurations (samples) indexed by $n=1, \\dots, N$. The target forces $b_n \\in \\mathbb{R}^D$ are obtained from fine-grained (e.g., all-atom) simulations via a linear mapping $\\Xi \\in \\mathbb{R}^{D \\times d_{\\mathrm{fg}}}$ applied to the fine-grained forces $f(r_n) \\in \\mathbb{R}^{d_{\\mathrm{fg}}}$:\n$$\nb_n = \\Xi f(r_n)\n$$\nThe optimization problem is to minimize the sum of squared differences (the least-squares residual) over all $N$ samples and all $D$ dimensions:\n$$\nL(\\theta) = \\sum_{n=1}^{N} \\|F_{\\theta}(R_n) - b_n\\|_2^2\n$$\nThis can be formulated as a standard linear least-squares problem, $A\\theta \\approx b$. The design matrix $A \\in \\mathbb{R}^{(ND) \\times K}$ and the target vector $b \\in \\mathbb{R}^{ND}$ are constructed by stacking the contributions from each sample. Following the problem's specified sample-major, component-minor ordering, the row of $A$ corresponding to the $d$-th component of the $n$-th sample is composed of the $d$-th components of the negative gradients of the basis functions:\n$$\nA_{(n,d), k} = \\left(-\\nabla_R B_k(R_n)\\right)_d\n$$\nSimilarly, the vector $b$ is formed by stacking the components of the target forces $b_n$:\n$$\nb_{(n,d)} = (b_n)_d\n$$\nFor this problem, with $D=2$ ($R=(x,y)$) and $K=4$, the basis functions and their specified negative gradients are:\n- $B_1(R) = \\tfrac{1}{2} (x^2 + y^2) \\implies -\\nabla_R B_1(R) = (-x, -y)$\n- $B_2(R) = xy \\implies -\\nabla_R B_2(R) = (-y, -x)$\n- $B_3(R) = \\sin(x) \\implies -\\nabla_R B_3(R) = (-\\cos(x), 0)$\n- $B_4(R) = \\cos(y) \\implies -\\nabla_R B_4(R) = (0, \\sin(y))$\n\nFor each sample $n=1, \\dots, N$ with coordinates $R_n=(x_n, y_n)$, we construct two rows in the design matrix $A$ (of size $(2N) \\times 4$). Using $0$-based indexing for implementation clarity, the rows are:\n- Row $2(n-1)$ (for $x$-component, $d=1$): $\\begin{bmatrix} -x_n & -y_n & -\\cos(x_n) & 0 \\end{bmatrix}$\n- Row $2(n-1)+1$ (for $y$-component, $d=2$): $\\begin{bmatrix} -y_n & -x_n & 0 & \\sin(y_n) \\end{bmatrix}$\n\nThe target vector $b$ (of size $2N$) is constructed by calculating $b_n = \\Xi f(r_n)$ for each sample and stacking the components: $b = [ (b_1)_1, (b_1)_2, (b_2)_1, (b_2)_2, \\dots, (b_N)_1, (b_N)_2 ]^T$.\n\nThe solution $\\theta$ that minimizes $\\|A\\theta - b\\|_2^2$ can be found using numerical linear algebra routines. The problem specifies that if the matrix $A$ is rank-deficient (i.e., its columns are not linearly independent), the unique minimum-norm solution for $\\theta$ should be returned. This is the solution $\\theta^*$ that minimizes $\\|A\\theta - b\\|_2$ and, among all vectors that achieve this minimum, also has the smallest Euclidean norm $\\|\\theta^*\\|_2$. The `numpy.linalg.lstsq` function in Python, with its default settings, provides precisely this minimum-norm least-squares solution. This is particularly relevant for Test Case $2$, which is constructed to have a rank-deficient design matrix, and Test Case $4$, where the homogeneous system $A\\theta \\approx 0$ is solved, for which the minimum-norm solution is $\\theta=0$.\n\nFor each test case, the procedure is as follows:\n1.  Initialize a matrix $A$ of zeros with shape $(2N, 4)$ and a vector $b$ of zeros with shape $(2N,)$.\n2.  Iterate through each sample $n$ from $1$ to $N$.\n3.  For each sample, extract the coarse-grained coordinates $R_n=(x_n, y_n)$ and the fine-grained force vector $f(r_n)$.\n4.  Compute the two rows of $A$ corresponding to sample $n$ using the gradient formulas.\n5.  Compute the target coarse-grained force $b_n = \\Xi f(r_n)$.\n6.  Place the values into the corresponding rows of $A$ and elements of $b$.\n7.  After populating $A$ and $b$, solve for $\\theta$ using `numpy.linalg.lstsq(A, b, rcond=None)`.\n8.  Round the resulting components of $\\theta$ to six decimal places.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of linear force-matching problems.\n    For each test case, it constructs the design matrix A and target vector b,\n    solves the least-squares problem A*theta = b for the coefficients theta,\n    and formats the results as specified.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"N\": 3, \"D\": 2, \"K\": 4, \"d_fg\": 2,\n            \"R\": np.array([[0.0, 0.0], [1.0, 0.5], [-0.5, 1.0]]),\n            \"f\": np.array([[-0.5, 0.0], [-1.770151153, -0.119856385], [1.561208719, -2.710367746]]),\n            \"Xi\": np.array([[1.0, 0.0], [0.0, 1.0]])\n        },\n        {\n            \"N\": 2, \"D\": 2, \"K\": 4, \"d_fg\": 2,\n            \"R\": np.array([[1.0, 0.0], [2.0, 0.0]]),\n            \"f\": np.array([[-0.729848847, -2.0], [-2.208073419, -4.0]]),\n            \"Xi\": np.array([[1.0, 0.0], [0.0, 1.0]])\n        },\n        {\n            \"N\": 2, \"D\": 2, \"K\": 4, \"d_fg\": 4,\n            \"R\": np.array([[0.3, -0.7], [-1.2, 0.8]]),\n            \"f\": np.array([[2.0, 4.0, -1.0, 1.0], [-0.5, 1.5, 2.0, 2.0]]),\n            \"Xi\": np.array([[0.5, 0.5, 0.0, 0.0], [0.0, 0.0, 0.5, 0.5]])\n        },\n        {\n            \"N\": 3, \"D\": 2, \"K\": 4, \"d_fg\": 2,\n            \"R\": np.array([[0.2, 0.2], [1.1, -1.1], [-2.0, 2.0]]),\n            \"f\": np.array([[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]),\n            \"Xi\": np.array([[1.0, 0.0], [0.0, 1.0]])\n        }\n    ]\n\n    results_str_list = []\n    \n    for case in test_cases:\n        N = case[\"N\"]\n        D = case[\"D\"]\n        K = case[\"K\"]\n        \n        R_samples = case[\"R\"]\n        f_samples = case[\"f\"]\n        Xi = case[\"Xi\"]\n        \n        # Initialize the design matrix A and target vector b\n        A = np.zeros((N * D, K))\n        b = np.zeros(N * D)\n        \n        # Populate the matrix A and vector b\n        for n in range(N):\n            Rn = R_samples[n]\n            xn, yn = Rn[0], Rn[1]\n            \n            # Row index for x-component: 2*n\n            # Row index for y-component: 2*n + 1\n            row_idx_x = 2 * n\n            row_idx_y = 2 * n + 1\n            \n            # Basis function gradients for A\n            # B1: 0.5*(x^2+y^2) => -grad B1 = (-x, -y)\n            A[row_idx_x, 0] = -xn\n            A[row_idx_y, 0] = -yn\n            \n            # B2: x*y => -grad B2 = (-y, -x)\n            A[row_idx_x, 1] = -yn\n            A[row_idx_y, 1] = -xn\n            \n            # B3: sin(x) => -grad B3 = (-cos(x), 0)\n            A[row_idx_x, 2] = -np.cos(xn)\n            A[row_idx_y, 2] = 0.0\n            \n            # B4: cos(y) => -grad B4 = (0, sin(y))\n            A[row_idx_x, 3] = 0.0\n            A[row_idx_y, 3] = np.sin(yn)\n            \n            # Target force vector b\n            fn = f_samples[n]\n            bn = Xi @ fn # Matrix-vector product\n            \n            b[row_idx_x] = bn[0]\n            b[row_idx_y] = bn[1]\n\n        # Solve for theta using linear least squares.\n        # np.linalg.lstsq returns the minimum-norm solution for rank-deficient matrices.\n        theta, residuals, rank, singular_values = np.linalg.lstsq(A, b, rcond=None)\n        \n        # Round the solution to six decimal places\n        theta_rounded = np.round(theta, 6)\n\n        # Format the result string for this case\n        case_result_str = f\"[{','.join([f'{c:.6f}' for c in theta_rounded])}]\"\n        results_str_list.append(case_result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_str_list)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "To create accurate and transferable coarse-grained models, we need potentials that are not only fitted to data but are also physically well-behaved. This advanced exercise introduces cubic splines as a powerful and flexible representation for the pair potential, allowing for arbitrary shapes. You will learn the critical skill of imposing physical realism—such as smoothness and a proper cutoff—by formulating them as linear constraints within the least-squares optimization framework, a technique essential for robust and stable coarse-grained simulations .",
            "id": "3399949",
            "problem": "Consider a bottom-up coarse-graining problem in Molecular Dynamics (MD), where the goal is to estimate a central pair potential $u(r)$ from fine-grained force data by force matching. Assume a purely radial, pairwise-additive interaction so that, for two particles separated by distance $r$, the radial force magnitude is $f(r) = -u'(r)$. You are tasked to represent $u(r)$ as a cubic spline defined on a set of strictly increasing knots $\\{r_a\\}_{a=0}^{A}$, where $A \\in \\mathbb{N}$ and $r_0 < r_1 < \\cdots < r_A$, with $A \\geq 1$. Between each consecutive pair of knots $[r_i, r_{i+1}]$ for $i \\in \\{0,\\dots,A-1\\}$, define a local coordinate $x = r - r_i$ and let\n$$\nu_i(x) = a_i + b_i x + c_i x^2 + d_i x^3,\n$$\nwith unknown coefficients $\\{a_i,b_i,c_i,d_i\\}$ per interval. Collect all unknowns into a single vector $\\mathbf{w} \\in \\mathbb{R}^{4A}$ ordered as $(a_0,b_0,c_0,d_0,a_1,b_1,c_1,d_1,\\dots,a_{A-1},b_{A-1},c_{A-1},d_{A-1})$.\n\nImpose the following linear equality constraints on $\\mathbf{w}$:\n\n- Continuity of $u(r)$ at each internal knot $r_i$ for $i \\in \\{1,\\dots,A-1\\}$:\n$$\nu_{i-1}(\\Delta_{i-1}) = u_{i}(0),\n$$\nwhere $\\Delta_{i-1} = r_i - r_{i-1}$.\n\n- Continuity of $u'(r)$ at each internal knot $r_i$ for $i \\in \\{1,\\dots,A-1\\}$:\n$$\nu_{i-1}'(\\Delta_{i-1}) = u_{i}'(0).\n$$\n\n- Smooth cutoff at the last knot $r_A$:\n$$\nu_{A-1}(\\Delta_{A-1}) = 0,\n$$\n$$\nu_{A-1}'(\\Delta_{A-1}) = 0,\n$$\nwhere $\\Delta_{A-1} = r_A - r_{A-1}$.\n\n- Gauge fixing at the first knot $r_0$:\n$$\nu_0(0) = 0.\n$$\n\nTasks:\n\n$1.$ Derive explicit linear equations for the constraints in terms of the coefficients $\\{a_i,b_i,c_i,d_i\\}$, and express them as a matrix equation $\\mathbf{C} \\mathbf{w} = \\mathbf{0}$, where $\\mathbf{C} \\in \\mathbb{R}^{M \\times 4A}$ for some $M \\in \\mathbb{N}$. Your derivation must start from the definitions above and use only the fundamentals of calculus and linear algebra.\n\n$2.$ For a given set of sample distances $\\{r_k\\}_{k=1}^{K}$ and corresponding force magnitudes $\\{f_k\\}_{k=1}^{K}$, construct a design matrix $\\mathbf{X} \\in \\mathbb{R}^{K \\times 4A}$ such that the force matching model is\n$$\n\\mathbf{f} \\approx \\mathbf{X} \\mathbf{w},\n$$\nwith the $k$-th row encoding $f(r_k) = -u'(r_k)$ as a linear function of the local interval’s coefficients. Provide the explicit formula for the nonzero entries of the $k$-th row in terms of the local coordinate $x_k = r_k - r_i$ for the interval $[r_i, r_{i+1}]$ containing $r_k$.\n\n$3.$ Explain, from first principles of linear algebra, how to solve the equality-constrained least squares problem\n$$\n\\min_{\\mathbf{w} \\in \\mathbb{R}^{4A}} \\|\\mathbf{X}\\mathbf{w} - \\mathbf{f}\\|_2^2 \\quad \\text{subject to} \\quad \\mathbf{C}\\mathbf{w} = \\mathbf{0},\n$$\nusing an orthogonal decomposition. Your explanation must identify how to compute a basis for the null space of $\\mathbf{C}$ and reduce the problem to an unconstrained least squares in the reduced coordinates.\n\n$4.$ Implement a program that constructs $\\mathbf{C}$ and $\\mathbf{X}$, solves for $\\mathbf{w}$, and returns a quantitative accuracy measure by comparing to known ground-truth coefficients used to generate synthetic data. All quantities are dimensionless.\n\nUse the following test suite of spline definitions, where the coefficients listed are the ground truth, and the synthetic data $\\{f_k\\}_{k=1}^{K}$ are generated without noise from these exact splines. In every case, use $K = 401$ sample points equispaced on $[r_0, r_A]$. For each case, output the maximum absolute coefficient error\n$$\n\\varepsilon_{\\max} = \\|\\widehat{\\mathbf{w}} - \\mathbf{w}^{\\star}\\|_{\\infty},\n$$\nwhere $\\widehat{\\mathbf{w}}$ is the estimated coefficient vector and $\\mathbf{w}^{\\star}$ is the ground truth. The three test cases are:\n\n- Case $1$: Knots $\\{r_a\\} = [0.0, 1.0, 2.0]$.\n  - Interval $[0.0, 1.0]$: $(a_0,b_0,c_0,d_0) = (0.0, 0.0, 1.0, 0.0)$.\n  - Interval $[1.0, 2.0]$: $(a_1,b_1,c_1,d_1) = (1.0, 2.0, -7.0, 4.0)$.\n\n- Case $2$: Knots $\\{r_a\\} = [0.0, 0.5, 1.0, 1.5]$.\n  - Interval $[0.0, 0.5]$: $(a_0,b_0,c_0,d_0) = (0.0, 0.0, 1.0, 0.0)$.\n  - Interval $[0.5, 1.0]$: $(a_1,b_1,c_1,d_1) = (0.25, 1.0, -1.0, 0.0)$.\n  - Interval $[1.0, 1.5]$: $(a_2,b_2,c_2,d_2) = (0.5, 0.0, -6.0, 8.0)$.\n\n- Case $3$: Knots $\\{r_a\\} = [0.0, 1.0]$.\n  - Interval $[0.0, 1.0]$: $(a_0,b_0,c_0,d_0) = (0.0, 1.0, -2.0, 1.0)$.\n\nYour program must:\n\n- Build $\\mathbf{C}$ from the constraints described above for each knot sequence.\n- Construct $\\mathbf{X}$ from the sample points and the model $f(r) = -u'(r)$.\n- Solve the constrained least squares problem using an orthogonal decomposition method based on a unitary matrix that exposes a basis for the null space of $\\mathbf{C}$.\n- Compute $\\varepsilon_{\\max}$ for each case.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[e1,e2,e3]\"), where each $e_i$ is the $\\varepsilon_{\\max}$ for the corresponding test case, represented as a floating-point number. All quantities are dimensionless and must be reported as raw decimal numbers (no percentages and no physical units).",
            "solution": "The problem requires the determination of coefficients for a cubic spline potential, $u(r)$, by fitting to force data. This is a common task in bottom-up coarse-graining for molecular dynamics. The problem is structured as an equality-constrained least squares optimization. The solution involves three main steps: defining the linear system representing the physical constraints, defining the linear model that relates the coefficients to the observed forces, and solving the resulting optimization problem.\n\nFirst, we formulate the linear equality constraints on the spline coefficients. The full coefficient vector, $\\mathbf{w} \\in \\mathbb{R}^{4A}$, concatenates the coefficients $\\{a_i, b_i, c_i, d_i\\}$ for each of the $A$ spline intervals. The individual coefficients $a_i, b_i, c_i, d_i$ are located at indices $4i, 4i+1, 4i+2, 4i+3$ of $\\mathbf{w}$, respectively. The constraints are expressed as a homogeneous linear system $\\mathbf{C}\\mathbf{w} = \\mathbf{0}$. Each constraint corresponds to one row in the matrix $\\mathbf{C}$.\n\nThe local potential in interval $i \\in \\{0, \\dots, A-1\\}$ for a local coordinate $x = r-r_i$ is $u_i(x) = a_i + b_i x + c_i x^2 + d_i x^3$. Its derivative is $u'_i(x) = b_i + 2c_i x + 3d_i x^2$. Let $\\Delta_j = r_{j+1} - r_j$ be the length of interval $j$.\n\n1.  **Continuity of $u(r)$**: For each internal knot $r_i$ where $i \\in \\{1,\\dots,A-1\\}$, the potential must be continuous. This implies $u_{i-1}(\\Delta_{i-1}) = u_i(0)$. Substituting the polynomial forms gives:\n    $$a_{i-1} + b_{i-1}\\Delta_{i-1} + c_{i-1}\\Delta_{i-1}^2 + d_{i-1}\\Delta_{i-1}^3 = a_i$$\n    This yields $A-1$ linear equations of the form:\n    $$a_{i-1} + b_{i-1}\\Delta_{i-1} + c_{i-1}\\Delta_{i-1}^2 + d_{i-1}\\Delta_{i-1}^3 - a_i = 0$$\n    Each such equation fills a row in $\\mathbf{C}$ with non-zero entries $1, \\Delta_{i-1}, \\Delta_{i-1}^2, \\Delta_{i-1}^3$ at columns corresponding to $(a_{i-1}, b_{i-1}, c_{i-1}, d_{i-1})$ and $-1$ at the column for $a_i$.\n\n2.  **Continuity of $u'(r)$**: The first derivative of the potential (related to force) must also be continuous at internal knots: $u'_{i-1}(\\Delta_{i-1}) = u'_{i}(0)$ for $i \\in \\{1,\\dots,A-1\\}$.\n    $$b_{i-1} + 2c_{i-1}\\Delta_{i-1} + 3d_{i-1}\\Delta_{i-1}^2 = b_i$$\n    This provides another $A-1$ equations:\n    $$b_{i-1} + 2c_{i-1}\\Delta_{i-1} + 3d_{i-1}\\Delta_{i-1}^2 - b_i = 0$$\n    The corresponding rows in $\\mathbf{C}$ have entries $1, 2\\Delta_{i-1}, 3\\Delta_{i-1}^2$ for $(b_{i-1}, c_{i-1}, d_{i-1})$ and $-1$ for $b_i$.\n\n3.  **Smooth Cutoff**: At the final knot $r_A$, the potential and its derivative must both be zero: $u(r_A) = 0$ and $u'(r_A) = 0$. This corresponds to $u_{A-1}(\\Delta_{A-1}) = 0$ and $u'_{A-1}(\\Delta_{A-1}) = 0$.\n    $$a_{A-1} + b_{A-1}\\Delta_{A-1} + c_{A-1}\\Delta_{A-1}^2 + d_{A-1}\\Delta_{A-1}^3 = 0$$\n    $$b_{A-1} + 2c_{A-1}\\Delta_{A-1} + 3d_{A-1}\\Delta_{A-1}^2 = 0$$\n    These two equations affect only the coefficients of the last interval, $\\{a_{A-1}, b_{A-1}, c_{A-1}, d_{A-1}\\}$.\n\n4.  **Gauge Fixing**: The potential is defined up to an additive constant. We fix this by setting the potential to zero at the origin: $u(r_0) = 0$, which is $u_0(0) = 0$.\n    $$a_0 = 0$$\n    This is a single equation, placing a $1$ in the first column of a row of $\\mathbf{C}$.\n\nIn total, for $A$ intervals, there are $(A-1) + (A-1) + 2 + 1 = 2A+1$ linear constraints. The matrix $\\mathbf{C}$ thus has dimensions $(2A+1) \\times 4A$.\n\nSecond, we construct the design matrix $\\mathbf{X}$ for the force-matching model $\\mathbf{f} \\approx \\mathbf{X}\\mathbf{w}$. The force magnitude is $f(r) = -u'(r)$. For a sample point $r_k$ located in interval $i$ (i.e., $r_k \\in [r_i, r_{i+1}]$), the local coordinate is $x_k = r_k - r_i$. The force is:\n$$f(r_k) = -u'_i(x_k) = -(b_i + 2c_i x_k + 3d_i x_k^2)$$\nThis equation is linear in the coefficients $b_i, c_i, d_i$. The $k$-th row of the equation $\\mathbf{f} = \\mathbf{X}\\mathbf{w}$ represents $f(r_k)$. Therefore, the $k$-th row of $\\mathbf{X}$ will have non-zero elements only in the columns corresponding to the coefficients of interval $i$. The specific entries are:\n-   At column $4i+1$ (for $b_i$): $-1$\n-   At column $4i+2$ (for $c_i$): $-2x_k = -2(r_k - r_i)$\n-   At column $4i+3$ (for $d_i$): $-3x_k^2 = -3(r_k - r_i)^2$\nAll other entries in the $k$-th row of $\\mathbf{X}$ are zero.\n\nThird, we solve the equality-constrained least squares problem:\n$$ \\min_{\\mathbf{w} \\in \\mathbb{R}^{4A}} \\|\\mathbf{X}\\mathbf{w} - \\mathbf{f}\\|_2^2 \\quad \\text{subject to} \\quad \\mathbf{C}\\mathbf{w} = \\mathbf{0} $$\nThe constraint $\\mathbf{C}\\mathbf{w} = \\mathbf{0}$ confines the solution vector $\\mathbf{w}$ to the null space of $\\mathbf{C}$, denoted $\\text{Null}(\\mathbf{C})$. A fundamental principle of linear algebra is that any vector in this subspace can be expressed as a linear combination of basis vectors for the subspace. Let $\\mathbf{Z}$ be a matrix whose columns form an orthonormal basis for $\\text{Null}(\\mathbf{C})$. Then any valid $\\mathbf{w}$ can be written as $\\mathbf{w} = \\mathbf{Z}\\boldsymbol{\\alpha}$ for some vector of reduced coordinates $\\boldsymbol{\\alpha}$.\n\nThe dimension of $\\text{Null}(\\mathbf{C})$ is $d = 4A - \\text{rank}(\\mathbf{C})$. Assuming the $2A+1$ constraints are linearly independent, the rank is $2A+1$, and the number of free parameters is $d = 4A - (2A+1) = 2A-1$.\nAn orthonormal basis $\\mathbf{Z}$ for $\\text{Null}(\\mathbf{C})$ can be computed robustly using numerical methods like the Singular Value Decomposition (SVD). If $\\mathbf{C} = \\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^T$, the columns of $\\mathbf{V}$ corresponding to zero singular values form an orthonormal basis for the null space.\n\nBy substituting $\\mathbf{w} = \\mathbf{Z}\\boldsymbol{\\alpha}$ into the objective function, we transform the constrained problem into an unconstrained one in terms of $\\boldsymbol{\\alpha}$:\n$$ \\min_{\\boldsymbol{\\alpha} \\in \\mathbb{R}^d} \\|\\mathbf{X}(\\mathbf{Z}\\boldsymbol{\\alpha}) - \\mathbf{f}\\|_2^2 = \\min_{\\boldsymbol{\\alpha} \\in \\mathbb{R}^d} \\|\\mathbf{X'}\\boldsymbol{\\alpha} - \\mathbf{f}\\|_2^2 $$\nwhere $\\mathbf{X'} = \\mathbf{X}\\mathbf{Z}$. This is a standard linear least squares problem, which can be solved for $\\hat{\\boldsymbol{\\alpha}}$ using, for instance, a QR decomposition of $\\mathbf{X'}$. Once $\\hat{\\boldsymbol{\\alpha}}$ is found, the final coefficient vector is reconstructed as $\\widehat{\\mathbf{w}} = \\mathbf{Z}\\hat{\\boldsymbol{\\alpha}}$. Since the provided test data is synthetic and noiseless, the computed $\\widehat{\\mathbf{w}}$ is expected to match the ground truth $\\mathbf{w}^{\\star}$ to within machine precision.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import null_space\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        (\n            [0.0, 1.0, 2.0],\n            [0.0, 0.0, 1.0, 0.0, 1.0, 2.0, -7.0, 4.0]\n        ),\n        # Case 2\n        (\n            [0.0, 0.5, 1.0, 1.5],\n            [0.0, 0.0, 1.0, 0.0, 0.25, 1.0, -1.0, 0.0, 0.5, 0.0, -6.0, 8.0]\n        ),\n        # Case 3\n        (\n            [0.0, 1.0],\n            [0.0, 1.0, -2.0, 1.0]\n        )\n    ]\n\n    results = []\n    for knots, w_star in test_cases:\n        error = solve_case(knots, w_star)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef solve_case(knots, w_star):\n    \"\"\"\n    Solves one test case of the spline fitting problem by building the constraint\n    and design matrices, and solving the constrained least squares problem.\n    \n    Args:\n        knots (list): A list of strictly increasing knot positions.\n        w_star (list): The ground-truth coefficient vector w*.\n\n    Returns:\n        float: The maximum absolute error ||w_hat - w*||_inf.\n    \"\"\"\n    knots = np.array(knots, dtype=np.float64)\n    w_star = np.array(w_star, dtype=np.float64)\n    \n    A = len(knots) - 1 # Number of intervals\n    num_coeffs = 4 * A # Total number of coefficients\n    \n    # 1. Construct the constraint matrix C\n    num_constraints = 2 * A + 1\n    C = np.zeros((num_constraints, num_coeffs), dtype=np.float64)\n    deltas = np.diff(knots)\n    \n    row_idx = 0\n    # Continuity constraints (A-1 for u, A-1 for u')\n    if A > 1:\n        for i in range(1, A):\n            delta_prev = deltas[i-1]\n            \n            # u_{i-1}(delta) = u_i(0)\n            C[row_idx, 4 * (i - 1) + 0] = 1.0\n            C[row_idx, 4 * (i - 1) + 1] = delta_prev\n            C[row_idx, 4 * (i - 1) + 2] = delta_prev**2\n            C[row_idx, 4 * (i - 1) + 3] = delta_prev**3\n            C[row_idx, 4 * i + 0] = -1.0\n            row_idx += 1\n            \n            # u'_{i-1}(delta) = u'_i(0)\n            C[row_idx, 4 * (i - 1) + 1] = 1.0\n            C[row_idx, 4 * (i - 1) + 2] = 2.0 * delta_prev\n            C[row_idx, 4 * (i - 1) + 3] = 3.0 * delta_prev**2\n            C[row_idx, 4 * i + 1] = -1.0\n            row_idx += 1\n\n    # Smooth cutoff constraints at r_A (2 constraints)\n    delta_last = deltas[A-1]\n    # u_{A-1}(delta_last) = 0\n    C[row_idx, 4 * (A - 1) + 0] = 1.0\n    C[row_idx, 4 * (A - 1) + 1] = delta_last\n    C[row_idx, 4 * (A - 1) + 2] = delta_last**2\n    C[row_idx, 4 * (A - 1) + 3] = delta_last**3\n    row_idx += 1\n    # u'_{A-1}(delta_last) = 0\n    C[row_idx, 4 * (A - 1) + 1] = 1.0\n    C[row_idx, 4 * (A - 1) + 2] = 2.0 * delta_last\n    C[row_idx, 4 * (A - 1) + 3] = 3.0 * delta_last**2\n    row_idx += 1\n    \n    # Gauge fixing constraint at r_0 (1 constraint)\n    # u_0(0) = 0 => a_0 = 0\n    C[row_idx, 0] = 1.0\n    \n    # 2. Find an orthonormal basis Z for the null space of C\n    Z = null_space(C)\n\n    # 3. Generate synthetic force data from w_star\n    K = 401\n    r_samples = np.linspace(knots[0], knots[-1], K, dtype=np.float64)\n    f_samples = np.zeros(K, dtype=np.float64)\n    \n    # Find interval indices for all sample points efficiently\n    indices = np.searchsorted(knots, r_samples, side='right') - 1\n    # Clip to handle the rightmost boundary point r_A\n    indices = np.clip(indices, 0, A - 1)\n\n    for k in range(K):\n        i = indices[k]\n        x_k = r_samples[k] - knots[i]\n        b_i, c_i, d_i = w_star[4*i+1], w_star[4*i+2], w_star[4*i+3]\n        f_samples[k] = -(b_i + 2.0*c_i*x_k + 3.0*d_i*x_k**2)\n\n    # 4. Construct the design matrix X\n    X = np.zeros((K, num_coeffs), dtype=np.float64)\n    for k in range(K):\n        i = indices[k]\n        x_k = r_samples[k] - knots[i]\n        # f(r_k) = - (b_i + 2*c_i*x_k + 3*d_i*x_k^2)\n        X[k, 4*i + 1] = -1.0\n        X[k, 4*i + 2] = -2.0 * x_k\n        X[k, 4*i + 3] = -3.0 * x_k**2\n        \n    # 5. Solve the constrained least squares problem\n    # Project into the null space of C\n    X_prime = X @ Z\n    \n    # Solve the unconstrained least squares problem for alpha\n    alpha_hat, _, _, _ = np.linalg.lstsq(X_prime, f_samples, rcond=None)\n    \n    # Reconstruct the full coefficient vector\n    w_hat = Z @ alpha_hat\n    \n    # 6. Compute the maximum absolute coefficient error\n    error = np.max(np.abs(w_hat - w_star))\n    \n    return error\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}