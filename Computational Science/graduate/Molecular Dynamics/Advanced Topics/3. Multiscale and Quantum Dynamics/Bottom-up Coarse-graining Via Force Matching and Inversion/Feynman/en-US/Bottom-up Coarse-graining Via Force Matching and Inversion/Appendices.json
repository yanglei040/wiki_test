{
    "hands_on_practices": [
        {
            "introduction": "Understanding coarse-graining from a statistical mechanics perspective begins with the Potential of Mean Force (PMF). The PMF represents the effective free energy landscape of a coarse-grained coordinate, which arises from averaging over all the microscopic degrees of freedom that have been integrated out. This exercise provides a first-principles derivation of the PMF for the simplest possible molecular system—a one-dimensional dimer—allowing you to see how an effective potential emerges from the underlying microscopic interactions .",
            "id": "3399951",
            "problem": "Consider a $1$-dimensional dimer consisting of two atoms with positions $x_1$ and $x_2$ on the real line. The intramolecular potential energy is harmonic, given by $U(x_1,x_2)=\\tfrac{k}{2}\\left(x_2-x_1-\\ell\\right)^2$, where $k>0$ is the spring constant and $\\ell>0$ is the equilibrium bond length. Define the coarse-grained coordinate as the arithmetic mean $R=\\left(x_1+x_2\\right)/2$. Assume a canonical ensemble at temperature $T$ with inverse temperature $\\beta=1/\\left(k_B T\\right)$, where $k_B$ is the Boltzmann constant, and assume there are no external fields or constraints other than the definition of $R$. Neglect momenta by working with the configurational distribution.\n\nStarting from first principles of the canonical ensemble and the definition of the potential of mean force (PMF), that is, using the configurational probability density proportional to $\\exp\\left(-\\beta U\\right)$ and the marginalization procedure required to obtain the distribution of $R$, integrate out the internal coordinate analytically to obtain the potential of mean force $U_{\\text{PMF}}(R)$ up to an additive constant. Express your final answer as an explicit function of $R$ and you may set the additive constant to zero. Your final answer must be a single analytic expression. Do not round. No units are required for the final expression.",
            "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n-   System: A $1$-dimensional dimer with two atoms at positions $x_1$ and $x_2$.\n-   Intramolecular potential energy: $U(x_1,x_2)=\\frac{k}{2}\\left(x_2-x_1-\\ell\\right)^2$.\n-   Constants: Spring constant $k>0$, equilibrium bond length $\\ell>0$.\n-   Coarse-grained coordinate: $R=\\frac{x_1+x_2}{2}$.\n-   Thermodynamic ensemble: Canonical ensemble at temperature $T$.\n-   Inverse temperature: $\\beta=\\frac{1}{k_B T}$, where $k_B$ is the Boltzmann constant.\n-   Assumptions: No external fields or constraints other than the definition of $R$. Momenta are neglected (configurational distribution).\n-   Task: Derive the potential of mean force, $U_{\\text{PMF}}(R)$, by analytically integrating out the internal coordinate. The final result should be expressed up to an additive constant, which may be set to zero.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is a standard exercise in statistical mechanics, dealing with fundamental concepts such as the canonical ensemble, Boltzmann distribution, coarse-graining, and the potential of mean force. The model of a harmonic dimer is a cornerstone of molecular physics. All principles involved are well-established.\n-   **Well-Posed**: The problem is clearly defined with all necessary components: the system, its potential energy, the coarse-grained variable, and the statistical ensemble. The request to find the potential of mean force via marginalization is a standard, solvable procedure. A unique solution (up to an additive constant) exists.\n-   **Objective**: The problem is stated using precise, unambiguous mathematical and physical terminology.\n\n### Step 3: Verdict and Action\n-   **Verdict**: The problem is valid. It is scientifically sound, well-posed, and objective.\n-   **Action**: Proceed with the solution.\n\nThe potential of mean force, $U_{\\text{PMF}}(R)$, for a coarse-grained coordinate $R$ is defined through the marginal probability density $P(R)$ of that coordinate:\n$$P(R) = C \\exp(-\\beta U_{\\text{PMF}}(R))$$\nwhere $C$ is a normalization constant and $\\beta = \\frac{1}{k_B T}$ is the inverse temperature.\n\nThe marginal probability density $P(R)$ is obtained by integrating the full configurational probability density, $P(x_1, x_2)$, over all microscopic degrees of freedom ($x_1$ and $x_2$) consistent with the given value of the coarse-grained coordinate $R$. The full probability density is proportional to the Boltzmann factor, $P(x_1, x_2) \\propto \\exp(-\\beta U(x_1, x_2))$.\n\nWe can write $P(R)$ as:\n$$P(R) \\propto \\int_{-\\infty}^{\\infty} dx_1 \\int_{-\\infty}^{\\infty} dx_2 \\, \\delta\\left(R - \\frac{x_1 + x_2}{2}\\right) \\exp\\left(-\\beta U(x_1, x_2)\\right)$$\nwhere $\\delta(\\cdot)$ is the Dirac delta function that enforces the constraint. The potential energy is given as $U(x_1,x_2)=\\frac{k}{2}\\left(x_2-x_1-\\ell\\right)^2$.\n\nTo evaluate the integral, it is convenient to perform a change of variables from the microscopic coordinates $(x_1, x_2)$ to a new set of coordinates that includes the coarse-grained variable $R$. A natural choice for the second coordinate is the internal separation, $r = x_2 - x_1$.\nThe transformation is:\n$$R = \\frac{x_1 + x_2}{2}$$\n$$r = x_2 - x_1$$\nThe inverse transformation expresses $x_1$ and $x_2$ in terms of $R$ and $r$:\n$$x_1 = R - \\frac{r}{2}$$\n$$x_2 = R + \\frac{r}{2}$$\nThe Jacobian determinant of this transformation is:\n$$J = \\det \\begin{pmatrix} \\frac{\\partial x_1}{\\partial R} & \\frac{\\partial x_1}{\\partial r} \\\\ \\frac{\\partial x_2}{\\partial R} & \\frac{\\partial x_2}{\\partial r} \\end{pmatrix} = \\det \\begin{pmatrix} 1 & -\\frac{1}{2} \\\\ 1 & \\frac{1}{2} \\end{pmatrix} = (1)\\left(\\frac{1}{2}\\right) - \\left(-\\frac{1}{2}\\right)(1) = \\frac{1}{2} + \\frac{1}{2} = 1$$\nThe differential volume element transforms as $dx_1 dx_2 = |J| dR dr = dR dr$.\n\nThe joint probability density in the new coordinates, $P(R, r)$, is proportional to the Boltzmann factor expressed in these coordinates. The potential energy becomes:\n$$U(x_1, x_2) = \\frac{k}{2}\\left((x_2-x_1) - \\ell\\right)^2 = \\frac{k}{2}(r - \\ell)^2$$\nCrucially, the potential energy $U$ depends only on the internal coordinate $r$ and is independent of the coarse-grained coordinate $R$. This is a direct consequence of the translational invariance of the potential.\n\nThe marginal probability density $P(R)$ is found by integrating the joint density $P(R, r)$ over the internal coordinate $r$. The coordinate $r = x_2 - x_1$ can range from $-\\infty$ to $\\infty$.\n$$P(R) = \\int_{-\\infty}^{\\infty} P(R, r) dr \\propto \\int_{-\\infty}^{\\infty} \\exp(-\\beta U(r)) dr$$\nSubstituting the expression for the potential:\n$$P(R) \\propto \\int_{-\\infty}^{\\infty} \\exp\\left(-\\beta \\frac{k}{2}(r - \\ell)^2\\right) dr$$\nThe integral on the right-hand side is a standard Gaussian integral. The variable of integration is $r$, and the integrand contains no dependence on $R$. The limits of integration are constant. Therefore, the value of this definite integral is a constant, independent of $R$.\n\nLet's evaluate the integral for completeness. Let $u = r - \\ell$, so $du = dr$. The integration limits for $u$ are also from $-\\infty$ to $\\infty$.\n$$\\int_{-\\infty}^{\\infty} \\exp\\left(-\\beta \\frac{k}{2}(r - \\ell)^2\\right) dr = \\int_{-\\infty}^{\\infty} \\exp\\left(-\\beta \\frac{k}{2} u^2\\right) du$$\nUsing the formula for a Gaussian integral, $\\int_{-\\infty}^{\\infty} \\exp(-ax^2) dx = \\sqrt{\\frac{\\pi}{a}}$, with $a = \\frac{\\beta k}{2}$:\n$$\\int_{-\\infty}^{\\infty} \\exp\\left(-\\beta \\frac{k}{2} u^2\\right) du = \\sqrt{\\frac{\\pi}{\\frac{\\beta k}{2}}} = \\sqrt{\\frac{2\\pi}{\\beta k}}$$\nAs shown, the integral evaluates to a constant. Thus, the marginal probability density $P(R)$ is constant:\n$$P(R) = \\text{Constant}$$\nThis signifies that the center of mass $R$ is equally likely to be found at any position, which is expected for a system with no external potential.\n\nNow, we relate this back to the potential of mean force:\n$$\\exp(-\\beta U_{\\text{PMF}}(R)) \\propto P(R) = \\text{Constant}$$\nTaking the natural logarithm of both sides:\n$$-\\beta U_{\\text{PMF}}(R) = \\ln(\\text{Constant}) = \\text{another Constant}$$\nTherefore, the potential of mean force is itself a constant:\n$$U_{\\text{PMF}}(R) = -\\frac{1}{\\beta} (\\text{another Constant}) = \\text{yet another Constant}$$\nThe problem states that we can define the PMF up to an arbitrary additive constant and that we may set this constant to zero.\nHence, we conclude:\n$$U_{\\text{PMF}}(R) = 0$$",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "While the PMF describes the effective potential, the force-matching method operates directly on the forces. This exercise examines the same harmonic dimer as the previous problem, but from the force-matching perspective by calculating the average microscopic force projected onto the coarse-grained coordinate. Completing this practice will help you build a crucial bridge between the structural (PMF) and force-based pictures of coarse-graining, illustrating the fundamental relationship $F_{\\text{CG}} = -\\nabla U_{\\text{PMF}}$ in a clear and analytical context .",
            "id": "3399907",
            "problem": "Consider a one-dimensional Molecular Dynamics (MD) system consisting of two identical atoms connected by a harmonic spring and embedded in a thermal bath at temperature $T$. Let the atom positions be $x_1$ and $x_2$, and define the internal coordinate $r = x_1 - x_2$ and the Coarse-Grained (CG) mapping $R = (x_1 + x_2)/2$. The interaction potential between the two atoms is harmonic with equilibrium separation $a$ and spring constant $k$, given by the total potential energy\n$$\nU(x_1, x_2) = \\frac{k}{2}\\,(x_1 - x_2 - a)^{2}.\n$$\nAt equilibrium, the configurational distribution is canonical, with probability density proportional to $\\exp(-\\beta U)$, where $\\beta = 1/(k_B T)$ and $k_B$ is the Boltzmann constant. The microscopic forces on the atoms are defined by Newton’s second law and the conservative force relation $f_i = -\\partial U/\\partial x_i$ for $i \\in \\{1,2\\}$.\n\nIn bottom-up coarse-graining via force matching, the mean CG force associated with the mapping $R$ is obtained as the conditional ensemble average of the sum of the microscopic forces over all microscopic configurations consistent with the fixed CG coordinate $R$. Denote this conditional average over the internal coordinate $r$ at fixed $R$ by $\\langle \\cdot \\rangle_{r|R}$.\n\nStarting from the above definitions and equilibrium statistical mechanics, derive and compute the mean CG force\n$$\n\\left\\langle f_1 + f_2 \\right\\rangle_{r|R}\n$$\nfor the system defined, assuming no external field acts on $R$ and the only interaction is the harmonic internal potential $U(x_1, x_2)$ specified above. Express your final answer in Newtons. The answer must be a single real-valued number or a single closed-form analytic expression.",
            "solution": "The user wants to solve the problem:\n\"Consider a one-dimensional Molecular Dynamics (MD) system consisting of two identical atoms connected by a harmonic spring and embedded in a thermal bath at temperature $T$. Let the atom positions be $x_1$ and $x_2$, and define the internal coordinate $r = x_1 - x_2$ and the Coarse-Grained (CG) mapping $R = (x_1 + x_2)/2$. The interaction potential between the two atoms is harmonic with equilibrium separation $a$ and spring constant $k$, given by the total potential energy\n$$\nU(x_1, x_2) = \\frac{k}{2}\\,(x_1 - x_2 - a)^{2}.\n$$\nAt equilibrium, the configurational distribution is canonical, with probability density proportional to $\\exp(-\\beta U)$, where $\\beta = 1/(k_B T)$ and $k_B$ is the Boltzmann constant. The microscopic forces on the atoms are defined by Newton’s second law and the conservative force relation $f_i = -\\partial U/\\partial x_i$ for $i \\in \\{1,2\\}$.\n\nIn bottom-up coarse-graining via force matching, the mean CG force associated with the mapping $R$ is obtained as the conditional ensemble average of the sum of the microscopic forces over all microscopic configurations consistent with the fixed CG coordinate $R$. Denote this conditional average over the internal coordinate $r$ at fixed $R$ by $\\langle \\cdot \\rangle_{r|R}$.\n\nStarting from the above definitions and equilibrium statistical mechanics, derive and compute the mean CG force\n$$\n\\left\\langle f_1 + f_2 \\right\\rangle_{r|R}\n$$\nfor the system defined, assuming no external field acts on $R$ and the only interaction is the harmonic internal potential $U(x_1, x_2)$ specified above. Express your final answer in Newtons. The answer must be a single real-valued number or a single closed-form analytic expression.\"\n\nThe provided problem statement is being validated.\n\n### Step 1: Extract Givens\n-   System: 1D, two identical atoms.\n-   Atom positions: $x_1$, $x_2$.\n-   Internal coordinate: $r = x_1 - x_2$.\n-   Coarse-Grained (CG) coordinate: $R = (x_1 + x_2)/2$.\n-   Potential energy: $U(x_1, x_2) = \\frac{k}{2}\\,(x_1 - x_2 - a)^{2}$.\n-   Equilibrium distribution: Probability density is proportional to $\\exp(-\\beta U)$, with $\\beta = 1/(k_B T)$.\n-   Microscopic forces: $f_i = -\\partial U/\\partial x_i$ for $i \\in \\{1,2\\}$.\n-   Objective: Compute the mean CG force $\\left\\langle f_1 + f_2 \\right\\rangle_{r|R}$.\n-   Condition: No external field acts on $R$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded:** The problem is a standard exercise in statistical mechanics and coarse-graining theory, based on the harmonic oscillator model, the canonical ensemble, and the principles of force matching. All concepts are scientifically sound.\n-   **Well-Posed:** The problem provides all necessary definitions and constraints to compute the required quantity. The definitions of coordinates, potential, forces, and the averaging procedure are clear and unambiguous.\n-   **Objective:** The problem is stated in precise, objective mathematical and physical language.\n\nThe potential energy $U(x_1, x_2)$ depends only on the relative distance $x_1 - x_2$. This implies that the internal forces of the system are translationally invariant. The lack of an external potential on the center of mass coordinate $R$ leads to a non-normalizable partition function if integrated over all space, but this is a standard feature of such systems and does not invalidate the calculation of conditional averages, as the problematic degrees of freedom factor out. The problem is self-contained, consistent, and scientifically valid.\n\n### Step 3: Verdict and Action\nThe problem is valid. A detailed solution will be provided.\n\nThe objective is to compute the mean Coarse-Grained (CG) force, which is defined as the conditional ensemble average of the sum of the microscopic forces, $\\langle f_1 + f_2 \\rangle_{r|R}$. The microscopic forces $f_1$ and $f_2$ on atom $1$ and atom $2$, respectively, are derived from the potential energy $U(x_1, x_2)$.\n\nThe potential energy is given as:\n$$\nU(x_1, x_2) = \\frac{k}{2}(x_1 - x_2 - a)^{2}\n$$\nwhere $k$ is the spring constant and $a$ is the equilibrium separation.\n\nThe force on atom $1$ is the negative gradient of the potential with respect to its position $x_1$:\n$$\nf_1 = -\\frac{\\partial U}{\\partial x_1}\n$$\nSubstituting the expression for $U(x_1, x_2)$ and applying the chain rule:\n$$\nf_1 = -\\frac{\\partial}{\\partial x_1} \\left[ \\frac{k}{2}(x_1 - x_2 - a)^{2} \\right] = -\\frac{k}{2} \\cdot 2(x_1 - x_2 - a) \\cdot \\frac{\\partial}{\\partial x_1}(x_1 - x_2 - a)\n$$\n$$\nf_1 = -k(x_1 - x_2 - a) \\cdot (1) = -k(x_1 - x_2 - a)\n$$\n\nSimilarly, the force on atom $2$ is the negative gradient of the potential with respect to its position $x_2$:\n$$\nf_2 = -\\frac{\\partial U}{\\partial x_2}\n$$\nSubstituting the expression for $U(x_1, x_2)$ and applying the chain rule:\n$$\nf_2 = -\\frac{\\partial}{\\partial x_2} \\left[ \\frac{k}{2}(x_1 - x_2 - a)^{2} \\right] = -\\frac{k}{2} \\cdot 2(x_1 - x_2 - a) \\cdot \\frac{\\partial}{\\partial x_2}(x_1 - x_2 - a)\n$$\n$$\nf_2 = -k(x_1 - x_2 - a) \\cdot (-1) = k(x_1 - x_2 - a)\n$$\n\nThe sum of the microscopic forces is:\n$$\nf_1 + f_2 = \\left[-k(x_1 - x_2 - a)\\right] + \\left[k(x_1 - x_2 - a)\\right] = 0\n$$\nThe sum of the internal forces on the two atoms is identically zero. This is a direct consequence of the interaction potential $U$ depending only on the relative separation of the particles, $r = x_1 - x_2$. This property ensures that the internal forces satisfy Newton's third law ($f_1 = -f_2$) and reflects the translational invariance of the system's internal interactions. The total force due to internal interactions cannot cause an acceleration of the system's center of mass.\n\nThe quantity to be averaged, $\\langle f_1 + f_2 \\rangle_{r|R}$, is the conditional average of the sum of the forces. Since the sum $f_1 + f_2$ is equal to $0$ for any microscopic configuration $(x_1, x_2)$, its average over any ensemble, including the conditional ensemble at fixed $R$, must also be zero.\n$$\n\\left\\langle f_1 + f_2 \\right\\rangle_{r|R} = \\langle 0 \\rangle_{r|R} = 0\n$$\nThe details of the canonical distribution, the temperature $T$, and the Boltzmann constant $k_B$ are irrelevant to the final result, as the quantity being averaged is identically zero before any averaging is performed. The result holds for any potential of the form $U(x_1 - x_2)$.\n\nPhysically, the \"mean CG force\" as defined in the problem represents the average total force on the center of mass due to internal interactions. For an isolated system (no external fields), this force must be zero, as internal forces cannot change the state of motion of the center of mass. This is consistent with the calculation of the potential of mean force for the CG coordinate $R$. Since the potential $U$ does not depend on $R$, the marginal probability for $R$ is uniform, which corresponds to a constant potential of mean force, and thus a zero force on the CG coordinate $R$.\n\nTherefore, the mean CG force is exactly zero.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "Moving from analytical theory to computational practice, real-world force matching requires fitting a potential model to data generated from a complex simulation. This hands-on coding exercise guides you through the core task of this process: translating the force-matching objective into a linear least-squares problem that a computer can solve. You will construct the design matrix from a chosen set of basis functions and the target force vector from fine-grained simulation snapshots, a foundational skill for implementing any linear force-matching method .",
            "id": "3399938",
            "problem": "You are given a bottom-up coarse-graining task framed as a linear force-matching problem in Molecular Dynamics (MD). The fundamental base is that for conservative coarse-grained forces, the force on coarse coordinates $R \\in \\mathbb{R}^D$ is the negative gradient of a potential $U_{\\theta}(R)$ that is modeled as a linear expansion in a set of basis functions $\\{B_k(R)\\}_{k=1}^K$, i.e., $U_{\\theta}(R) = \\sum_{k=1}^K \\theta_k B_k(R)$. The force is then $F_{\\theta}(R) = -\\nabla_R U_{\\theta}(R) = -\\sum_{k=1}^K \\theta_k \\nabla_R B_k(R)$. In force matching, we use the fine-grained forces $f(r_n) \\in \\mathbb{R}^{d_{\\mathrm{fg}}}$ at fine-grained coordinates $r_n$, and a linear mapping $\\Xi \\in \\mathbb{R}^{D \\times d_{\\mathrm{fg}}}$ to obtain coarse-grained force targets $b_n = \\Xi f(r_n) \\in \\mathbb{R}^D$. The least-squares problem is to find $\\theta \\in \\mathbb{R}^K$ minimizing $\\sum_{n=1}^N \\|F_{\\theta}(R_n) - b_n\\|_2^2$. This reduces to a linear system $A \\theta \\approx b$ with a design matrix $A \\in \\mathbb{R}^{(N D) \\times K}$ constructed by stacking the negative gradients of the basis functions evaluated at samples $\\{R_n\\}_{n=1}^N$.\n\nYour task is to implement a program that, for each provided test case, constructs the design matrix entries $A_{(n,d),k} = \\left(-\\nabla_R B_k(R_n)\\right)_d$ for each sample index $n \\in \\{1,\\dots,N\\}$ and component $d \\in \\{1,\\dots,D\\}$, constructs targets $b_{(n,d)} = \\left(\\Xi f(r_n)\\right)_d$, solves the linear least-squares problem for $\\theta$, and reports the coefficients. Angles must be interpreted in radians. All quantities are dimensionless. The program must use the following basis functions in two dimensions $D = 2$ with $R = (x,y)$:\n- $B_1(R) = \\tfrac{1}{2} \\left(x^2 + y^2\\right)$,\n- $B_2(R) = x y$,\n- $B_3(R) = \\sin(x)$,\n- $B_4(R) = \\cos(y)$.\nFor these, the negative gradients to be used for the design matrix are:\n- $-\\nabla_R B_1(R) = \\left(-x, -y\\right)$,\n- $-\\nabla_R B_2(R) = \\left(-y, -x\\right)$,\n- $-\\nabla_R B_3(R) = \\left(-\\cos(x), 0\\right)$,\n- $-\\nabla_R B_4(R) = \\left(0, \\sin(y)\\right)$.\nStack rows in $A$ and elements in $b$ by sample-major, component-minor order, i.e., for $n = 1, \\dots, N$ stack first the $x$-component row, then the $y$-component row.\n\nSolve for $\\theta$ using linear least squares in the Euclidean norm. If $A$ is rank-deficient, return the minimum-norm least-squares solution. For each test case, return the vector $\\theta \\in \\mathbb{R}^4$, rounded to six decimal places.\n\nTest suite:\n- Test case $1$ (happy path, identity mapping):\n  - $N = 3$, $D = 2$, $K = 4$, $d_{\\mathrm{fg}} = 2$.\n  - $R_1 = (0.0, 0.0)$, $R_2 = (1.0, 0.5)$, $R_3 = (-0.5, 1.0)$.\n  - $r_1 = (0.0, 0.0)$, $r_2 = (1.0, 0.5)$, $r_3 = (-0.5, 1.0)$.\n  - $\\Xi = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}$.\n  - $f(r_1) = (-0.5, 0.0)$; $f(r_2) = (-1.770151153, -0.119856385)$; $f(r_3) = (1.561208719, -2.710367746)$.\n- Test case $2$ (boundary case with near-singular design, identity mapping):\n  - $N = 2$, $D = 2$, $K = 4$, $d_{\\mathrm{fg}} = 2$.\n  - $R_1 = (1.0, 0.0)$, $R_2 = (2.0, 0.0)$.\n  - $r_1 = (1.0, 0.0)$, $r_2 = (2.0, 0.0)$.\n  - $\\Xi = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}$.\n  - $f(r_1) = (-0.729848847, -2.0)$; $f(r_2) = (-2.208073419, -4.0)$.\n- Test case $3$ (nontrivial mapping from fine-grained to coarse-grained forces):\n  - $N = 2$, $D = 2$, $K = 4$, $d_{\\mathrm{fg}} = 4$.\n  - $R_1 = (0.3, -0.7)$, $R_2 = (-1.2, 0.8)$.\n  - $r_1 = (0.3, 0.4, -0.7, -0.9)$, $r_2 = (-1.2, -1.1, 0.8, 0.6)$.\n  - $\\Xi = \\begin{bmatrix} 0.5  0.5  0.0  0.0 \\\\ 0.0  0.0  0.5  0.5 \\end{bmatrix}$.\n  - $f(r_1) = (2.0, 4.0, -1.0, 1.0)$; $f(r_2) = (-0.5, 1.5, 2.0, 2.0)$.\n- Test case $4$ (zero-force edge case):\n  - $N = 3$, $D = 2$, $K = 4$, $d_{\\mathrm{fg}} = 2$.\n  - $R_1 = (0.2, 0.2)$, $R_2 = (1.1, -1.1)$, $R_3 = (-2.0, 2.0)$.\n  - $r_1 = (0.2, 0.2)$, $r_2 = (1.1, -1.1)$, $r_3 = (-2.0, 2.0)$.\n  - $\\Xi = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}$.\n  - $f(r_1) = (0.0, 0.0)$; $f(r_2) = (0.0, 0.0)$; $f(r_3) = (0.0, 0.0)$.\n\nRequired algorithm, for each test case:\n1. Construct $A \\in \\mathbb{R}^{(N D) \\times K}$ with rows indexed by $(n,d)$ where $n \\in \\{1,\\dots,N\\}$, $d \\in \\{1,2\\}$, and $A_{(n,d),k} = \\left(-\\nabla_R B_k(R_n)\\right)_d$.\n2. Construct $b \\in \\mathbb{R}^{N D}$ by stacking $b_{(n,1)}$ then $b_{(n,2)}$ for each $n$, where $b_n = \\Xi f(r_n)$.\n3. Solve for $\\theta$ by minimizing $\\|A \\theta - b\\|_2^2$; if $A$ is rank-deficient, return the minimum-norm solution.\n4. Round each component of $\\theta$ to six decimal places.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case’s result is itself a bracketed, comma-separated list of the four rounded coefficients with no spaces. For example: \"[[a1,a2,a3,a4],[b1,b2,b3,b4],[c1,c2,c3,c4],[d1,d2,d3,d4]]\" where each placeholder is a float rounded to six decimals.",
            "solution": "The problem is assessed to be **valid**. It is scientifically grounded in the principles of molecular dynamics and statistical mechanics, specifically the method of force matching for coarse-graining. The problem is well-posed, providing all necessary data and definitions to construct a solvable linear least-squares problem. The instructions are objective, precise, and free of contradictions or ambiguities.\n\nThe task is to determine the optimal coefficients $\\theta \\in \\mathbb{R}^K$ for a coarse-grained potential model by minimizing the difference between model forces and target forces derived from a high-resolution simulation. This is a classic bottom-up coarse-graining procedure framed as a linear regression problem.\n\nThe coarse-grained potential energy $U_{\\theta}(R)$ is defined as a linear combination of $K$ basis functions $\\{B_k(R)\\}_{k=1}^K$:\n$$\nU_{\\theta}(R) = \\sum_{k=1}^{K} \\theta_k B_k(R)\n$$\nwhere $R \\in \\mathbb{R}^D$ are the coarse-grained coordinates and $\\theta = (\\theta_1, \\dots, \\theta_K)^T$ is the vector of coefficients to be determined. In this problem, the spatial dimension is $D=2$ and the number of basis functions is $K=4$.\n\nThe force on the coarse-grained system is the negative gradient of this potential with respect to the coordinates $R$:\n$$\nF_{\\theta}(R) = -\\nabla_R U_{\\theta}(R) = -\\nabla_R \\left(\\sum_{k=1}^{K} \\theta_k B_k(R)\\right) = \\sum_{k=1}^{K} \\theta_k (-\\nabla_R B_k(R))\n$$\nThis equation shows that the model force $F_{\\theta}(R)$ is linear in the coefficients $\\theta_k$. The terms $-\\nabla_R B_k(R)$ are vector-valued functions that act as the basis for the force field.\n\nThe goal of force matching is to find the parameter vector $\\theta$ that makes the model forces $F_{\\theta}(R_n)$ best match a set of target forces $b_n$ for a series of $N$ configurations (samples) indexed by $n=1, \\dots, N$. The target forces $b_n \\in \\mathbb{R}^D$ are obtained from fine-grained (e.g., all-atom) simulations via a linear mapping $\\Xi \\in \\mathbb{R}^{D \\times d_{\\mathrm{fg}}}$ applied to the fine-grained forces $f(r_n) \\in \\mathbb{R}^{d_{\\mathrm{fg}}}$:\n$$\nb_n = \\Xi f(r_n)\n$$\nThe optimization problem is to minimize the sum of squared differences (the least-squares residual) over all $N$ samples and all $D$ dimensions:\n$$\nL(\\theta) = \\sum_{n=1}^{N} \\|F_{\\theta}(R_n) - b_n\\|_2^2\n$$\nThis can be formulated as a standard linear least-squares problem, $A\\theta \\approx b$. The design matrix $A \\in \\mathbb{R}^{(ND) \\times K}$ and the target vector $b \\in \\mathbb{R}^{ND}$ are constructed by stacking the contributions from each sample. Following the problem's specified sample-major, component-minor ordering, the row of $A$ corresponding to the $d$-th component of the $n$-th sample is composed of the $d$-th components of the negative gradients of the basis functions:\n$$\nA_{(n,d), k} = \\left(-\\nabla_R B_k(R_n)\\right)_d\n$$\nSimilarly, the vector $b$ is formed by stacking the components of the target forces $b_n$:\n$$\nb_{(n,d)} = (b_n)_d\n$$\nFor this problem, with $D=2$ ($R=(x,y)$) and $K=4$, the basis functions and their specified negative gradients are:\n- $B_1(R) = \\tfrac{1}{2} (x^2 + y^2) \\implies -\\nabla_R B_1(R) = (-x, -y)$\n- $B_2(R) = xy \\implies -\\nabla_R B_2(R) = (-y, -x)$\n- $B_3(R) = \\sin(x) \\implies -\\nabla_R B_3(R) = (-\\cos(x), 0)$\n- $B_4(R) = \\cos(y) \\implies -\\nabla_R B_4(R) = (0, \\sin(y))$\n\nFor each sample $n=1, \\dots, N$ with coordinates $R_n=(x_n, y_n)$, we construct two rows in the design matrix $A$ (of size $(2N) \\times 4$). Using $0$-based indexing for implementation clarity, the rows are:\n- Row $2(n-1)$ (for $x$-component, $d=1$): $\\begin{bmatrix} -x_n  -y_n  -\\cos(x_n)  0 \\end{bmatrix}$\n- Row $2(n-1)+1$ (for $y$-component, $d=2$): $\\begin{bmatrix} -y_n  -x_n  0  \\sin(y_n) \\end{bmatrix}$\n\nThe target vector $b$ (of size $2N$) is constructed by calculating $b_n = \\Xi f(r_n)$ for each sample and stacking the components: $b = [ (b_1)_1, (b_1)_2, (b_2)_1, (b_2)_2, \\dots, (b_N)_1, (b_N)_2 ]^T$.\n\nThe solution $\\theta$ that minimizes $\\|A\\theta - b\\|_2^2$ can be found using numerical linear algebra routines. The problem specifies that if the matrix $A$ is rank-deficient (i.e., its columns are not linearly independent), the unique minimum-norm solution for $\\theta$ should be returned. This is the solution $\\theta^*$ that minimizes $\\|A\\theta - b\\|_2$ and, among all vectors that achieve this minimum, also has the smallest Euclidean norm $\\|\\theta^*\\|_2$. The `numpy.linalg.lstsq` function in Python, with its default settings, provides precisely this minimum-norm least-squares solution. This is particularly relevant for Test Case $2$, which is constructed to have a rank-deficient design matrix, and Test Case $4$, where the homogeneous system $A\\theta \\approx 0$ is solved, for which the minimum-norm solution is $\\theta=0$.\n\nFor each test case, the procedure is as follows:\n1.  Initialize a matrix $A$ of zeros with shape $(2N, 4)$ and a vector $b$ of zeros with shape $(2N,)$.\n2.  Iterate through each sample $n$ from $1$ to $N$.\n3.  For each sample, extract the coarse-grained coordinates $R_n=(x_n, y_n)$ and the fine-grained force vector $f(r_n)$.\n4.  Compute the two rows of $A$ corresponding to sample $n$ using the gradient formulas.\n5.  Compute the target coarse-grained force $b_n = \\Xi f(r_n)$.\n6.  Place the values into the corresponding rows of $A$ and elements of $b$.\n7.  After populating $A$ and $b$, solve for $\\theta$ using `numpy.linalg.lstsq(A, b, rcond=None)`.\n8.  Round the resulting components of $\\theta$ to six decimal places.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of linear force-matching problems.\n    For each test case, it constructs the design matrix A and target vector b,\n    solves the least-squares problem A*theta = b for the coefficients theta,\n    and formats the results as specified.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"N\": 3, \"D\": 2, \"K\": 4, \"d_fg\": 2,\n            \"R\": np.array([[0.0, 0.0], [1.0, 0.5], [-0.5, 1.0]]),\n            \"f\": np.array([[-0.5, 0.0], [-1.770151153, -0.119856385], [1.561208719, -2.710367746]]),\n            \"Xi\": np.array([[1.0, 0.0], [0.0, 1.0]])\n        },\n        {\n            \"N\": 2, \"D\": 2, \"K\": 4, \"d_fg\": 2,\n            \"R\": np.array([[1.0, 0.0], [2.0, 0.0]]),\n            \"f\": np.array([[-0.729848847, -2.0], [-2.208073419, -4.0]]),\n            \"Xi\": np.array([[1.0, 0.0], [0.0, 1.0]])\n        },\n        {\n            \"N\": 2, \"D\": 2, \"K\": 4, \"d_fg\": 4,\n            \"R\": np.array([[0.3, -0.7], [-1.2, 0.8]]),\n            \"f\": np.array([[2.0, 4.0, -1.0, 1.0], [-0.5, 1.5, 2.0, 2.0]]),\n            \"Xi\": np.array([[0.5, 0.5, 0.0, 0.0], [0.0, 0.0, 0.5, 0.5]])\n        },\n        {\n            \"N\": 3, \"D\": 2, \"K\": 4, \"d_fg\": 2,\n            \"R\": np.array([[0.2, 0.2], [1.1, -1.1], [-2.0, 2.0]]),\n            \"f\": np.array([[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]),\n            \"Xi\": np.array([[1.0, 0.0], [0.0, 1.0]])\n        }\n    ]\n\n    results_str_list = []\n    \n    for case in test_cases:\n        N = case[\"N\"]\n        D = case[\"D\"]\n        K = case[\"K\"]\n        \n        R_samples = case[\"R\"]\n        f_samples = case[\"f\"]\n        Xi = case[\"Xi\"]\n        \n        # Initialize the design matrix A and target vector b\n        A = np.zeros((N * D, K))\n        b = np.zeros(N * D)\n        \n        # Populate the matrix A and vector b\n        for n in range(N):\n            Rn = R_samples[n]\n            xn, yn = Rn[0], Rn[1]\n            \n            # Row index for x-component: 2*n\n            # Row index for y-component: 2*n + 1\n            row_idx_x = 2 * n\n            row_idx_y = 2 * n + 1\n            \n            # Basis function gradients for A\n            # B1: 0.5*(x^2+y^2) = -grad B1 = (-x, -y)\n            A[row_idx_x, 0] = -xn\n            A[row_idx_y, 0] = -yn\n            \n            # B2: x*y = -grad B2 = (-y, -x)\n            A[row_idx_x, 1] = -yn\n            A[row_idx_y, 1] = -xn\n            \n            # B3: sin(x) = -grad B3 = (-cos(x), 0)\n            A[row_idx_x, 2] = -np.cos(xn)\n            A[row_idx_y, 2] = 0.0\n            \n            # B4: cos(y) = -grad B4 = (0, sin(y))\n            A[row_idx_x, 3] = 0.0\n            A[row_idx_y, 3] = np.sin(yn)\n            \n            # Target force vector b\n            fn = f_samples[n]\n            bn = Xi @ fn # Matrix-vector product\n            \n            b[row_idx_x] = bn[0]\n            b[row_idx_y] = bn[1]\n\n        # Solve for theta using linear least squares.\n        # np.linalg.lstsq returns the minimum-norm solution for rank-deficient matrices.\n        theta, residuals, rank, singular_values = np.linalg.lstsq(A, b, rcond=None)\n        \n        # Round the solution to six decimal places\n        theta_rounded = np.round(theta, 6)\n\n        # Format the result string for this case\n        case_result_str = f\"[{','.join([f'{c:.6f}' for c in theta_rounded])}]\"\n        results_str_list.append(case_result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_str_list)}]\")\n\nsolve()\n```"
        }
    ]
}