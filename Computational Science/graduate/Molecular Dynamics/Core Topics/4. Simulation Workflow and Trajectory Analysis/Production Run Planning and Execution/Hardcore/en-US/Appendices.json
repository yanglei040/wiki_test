{
    "hands_on_practices": [
        {
            "introduction": "The efficiency and accuracy of a molecular dynamics simulation with long-range electrostatics are critically dependent on the parameters of the Particle-Mesh Ewald (PME) method. This exercise guides you through a systematic process of optimizing these parameters—the real-space cutoff $r_c$, the Ewald splitting parameter $\\alpha$, and the FFT grid size $n$. By minimizing a computational cost model subject to a fixed accuracy constraint, you will learn to navigate the fundamental trade-off between speed and physical fidelity in setting up your simulation engine .",
            "id": "3438102",
            "problem": "You are planning the production-phase electrostatics settings for a classical Molecular Dynamics simulation that will use Particle-Mesh Ewald (PME). You must construct a program that, for each system in a given test suite, selects PME parameters to minimize a cost model subject to a fixed accuracy constraint. Your selection variables are the Ewald splitting parameter $\\,\\alpha\\,$, the real-space cutoff $\\,r_c\\,$, and an isotropic three-dimensional grid size $\\,\\mathbf{n}_{\\mathrm{grid}} = (n,n,n)\\,$ constrained to be Fast Fourier Transform (FFT) friendly. The task is to produce a single-line output aggregating the optimal choices for all test cases.\n\nFundamental base and definitions:\n- The Ewald summation splits Coulomb interactions into real-space and reciprocal-space parts controlled by the Ewald splitting parameter $\\,\\alpha\\,$, such that complementary error functions weigh the short-range part and Gaussian screening weighs the long-range part.\n- The Root-Mean-Square (RMS) force error is modeled as the quadrature sum of a real-space truncation error and a reciprocal-space discretization error. We use a widely employed and conservative pair of error models that scale with density and characteristic spectral gaps:\n  1. Real-space RMS force error model:\n     $$\\mathcal{E}_{\\mathrm{real}}(\\alpha, r_c; \\rho, q_{\\mathrm{rms}}) \\;=\\; k_{\\mathrm{real}}\\; q_{\\mathrm{rms}}^2 \\, \\sqrt{\\rho}\\, \\exp\\!\\left(-(\\alpha r_c)^2\\right).$$\n  2. Reciprocal-space RMS force error model for smooth Particle-Mesh Ewald with cardinal B-spline assignment order $\\,p\\,$:\n     $$\\mathcal{E}_{\\mathrm{recip}}(\\alpha, n; L, \\rho, q_{\\mathrm{rms}}, p) \\;=\\; k_{\\mathrm{recip}}\\; q_{\\mathrm{rms}}^2 \\, \\sqrt{\\rho}\\; n^{-p}\\, \\exp\\!\\left(-\\left(\\frac{\\pi n}{\\alpha L}\\right)^2\\right).$$\n  The total RMS force error is:\n     $$\\mathcal{E}_{\\mathrm{tot}}(\\alpha, r_c, n) \\;=\\; \\sqrt{\\mathcal{E}_{\\mathrm{real}}(\\alpha, r_c)^2 + \\mathcal{E}_{\\mathrm{recip}}(\\alpha, n)^2}.$$\n- The grid size vector is constrained to $\\,\\mathbf{n}_{\\mathrm{grid}} = (n,n,n)\\,$ with $\\,n\\,$ restricted to be a $\\,5$-smooth integer (its prime factors are only $\\,2,3,5\\,$), chosen from a bounded interval $[n_{\\min}, n_{\\max}]$.\n- The simulation box is cubic of side length $\\,L\\,$, with $\\,N\\,$ particles and number density $\\,\\rho = N/L^3\\,$. All quantities are treated as dimensionless for this planning problem. The error tolerance $\\,\\varepsilon\\,$ is a dimensionless fraction of a characteristic force scale. The cost is in arbitrary time units per step.\n- The computational cost per time step is modeled as the sum of three components:\n  - Real-space pairwise computations with a Verlet list within cutoff $\\,r_c\\,$:\n    $$C_{\\mathrm{real}}(N, \\rho, r_c) \\;=\\; c_{\\mathrm{pair}}\\; N\\, \\rho\\, r_c^3.$$\n  - Charge spreading and force gathering on the mesh with B-spline of order $\\,p\\,$:\n    $$C_{\\mathrm{spread}}(n, p) \\;=\\; c_{\\mathrm{spread}}\\, p^3\\, n^3.$$\n  - Three-dimensional Fast Fourier Transform (FFT):\n    $$C_{\\mathrm{FFT}}(n) \\;=\\; c_{\\mathrm{FFT}}\\, n^3 \\log_2(n^3).$$\n  The total cost is:\n    $$C_{\\mathrm{tot}} \\;=\\; C_{\\mathrm{real}} + C_{\\mathrm{spread}} + C_{\\mathrm{FFT}}.$$\n\nOptimization problem:\n- Given $\\,N, L, q_{\\mathrm{rms}}, p, \\varepsilon\\,$, constants $\\,k_{\\mathrm{real}}, k_{\\mathrm{recip}}, c_{\\mathrm{pair}}, c_{\\mathrm{spread}}, c_{\\mathrm{FFT}}\\,$, and bounds on $\\,r_c, \\alpha, n\\,$, select $\\,(\\alpha, r_c, n)\\,$ to minimize $\\,C_{\\mathrm{tot}}\\,$ subject to:\n  $$\\mathcal{E}_{\\mathrm{tot}}(\\alpha, r_c, n) \\;\\le\\; \\varepsilon.$$\n- The search domains are constrained for practical production runs:\n  - Cutoff range: $\\,r_c \\in [r_{c,\\min}, r_{c,\\max}]$ with $\\,r_{c,\\min} = 0.5\\,$ and $\\,r_{c,\\max} = 0.49 L\\,$.\n  - Ewald splitting range tied to $\\,r_c\\,$: $\\,\\alpha \\in [\\alpha_{\\min}(r_c), \\alpha_{\\max}(r_c)]\\,$ with $\\,\\alpha_{\\min}(r_c) = 0.5/r_c\\,$ and $\\,\\alpha_{\\max}(r_c) = 3.5/r_c\\,$.\n  - Grid sizes: $\\,n \\in \\mathcal{N}\\,$, the set of $\\,5$-smooth integers in $[n_{\\min}, n_{\\max}]$ with $\\,n_{\\min} = 32\\,$ and $\\,n_{\\max} = 128\\,$.\n- If no feasible triple $\\,(\\alpha, r_c, n)\\,$ satisfies the error constraint, report an infeasible result.\n\nConstants to use:\n- Error model constants: $\\,k_{\\mathrm{real}} = 1.0\\,$ and $\\,k_{\\mathrm{recip}} = 1.0\\,$.\n- Cost model constants: $\\,c_{\\mathrm{pair}} = 10^{-6}\\,$, $\\,c_{\\mathrm{spread}} = 2\\times 10^{-7}\\,$, and $\\,c_{\\mathrm{FFT}} = 5\\times 10^{-6}\\,$.\n\nRequired outputs:\n- For each test case, your program must output the chosen parameters and metrics as a list:\n  $$[\\alpha^\\star, r_c^\\star, n^\\star, C_{\\mathrm{tot}}^\\star, \\mathcal{E}_{\\mathrm{tot}}^\\star, \\text{feasible}],$$\n  where $\\,\\text{feasible}\\,$ is a boolean that is true when a feasible solution exists and false otherwise. All floating-point outputs must be rounded to $\\,6\\,$ decimal places. If infeasible, return $\\,[-1,-1,-1,-1,-1,\\text{False}]\\,$ for that test case.\n- Your program should produce a single line of output containing the results as a comma-separated list of the per-test-case lists, enclosed in a single pair of square brackets. For example: $\\,\\texttt{[[...],[...],[...]]}\\,$.\n\nTest suite:\nUse the following four test cases, each described by the tuple $\\, (N, L, q_{\\mathrm{rms}}, p, \\varepsilon)\\,$:\n1. $\\, (100000,\\, 10.0,\\, 0.30,\\, 4,\\, 10^{-3})\\,$.\n2. $\\, (100000,\\, 10.0,\\, 0.30,\\, 4,\\, 3\\times 10^{-5})\\,$.\n3. $\\, (5000,\\, 6.0,\\, 0.50,\\, 6,\\, 5\\times 10^{-4})\\,$.\n4. $\\, (200000,\\, 8.0,\\, 0.25,\\, 6,\\, 10^{-5})\\,$.\n\nAlgorithmic requirements:\n- Your program must search the discrete set $\\,\\mathcal{N}\\,$ for $\\,n\\,$ and sample $\\,r_c\\,$ and $\\,\\alpha\\,$ on uniform grids within the specified ranges. Use at least $\\,40\\,$ linearly spaced samples for $\\,r_c\\,$ within $[r_{c,\\min}, r_{c,\\max}]$ and at least $\\,40\\,$ linearly spaced samples for $\\,\\alpha\\,$ within $[\\alpha_{\\min}(r_c), \\alpha_{\\max}(r_c)]$ for each $\\,r_c\\,$.\n- For each feasible combination, compute the total cost and select the one with minimal cost. Break ties by preferring smaller $\\,n\\,$, then smaller $\\,r_c\\,$, then smaller $\\,\\alpha\\,$.\n\nFinal output format:\n- Your program must produce a single line containing a single list with four sublists corresponding to the four test cases, each sublist having the format and rounding specified above, with no other text. For example:\n  $$\\texttt{[[a1,rc1,n1,c1,e1,True],[a2,rc2,n2,c2,e2,True],[...],[...]]}.$$",
            "solution": "The problem presented is a constrained optimization task central to the planning of molecular dynamics simulations employing the Particle-Mesh Ewald (PME) method for long-range electrostatics. The objective is to select a set of PME parameters—the Ewald splitting parameter $\\alpha$, the real-space cutoff distance $r_c$, and the FFT grid dimension $n$—that minimizes the computational cost per timestep, $C_{\\mathrm{tot}}$, while satisfying a user-defined tolerance $\\varepsilon$ on the root-mean-square (RMS) force error, $\\mathcal{E}_{\\mathrm{tot}}$.\n\nFirst, we restate the governing mathematical models provided. The total RMS force error, $\\mathcal{E}_{\\mathrm{tot}}$, is the quadrature sum of contributions from the real-space and reciprocal-space summations:\n$$\n\\mathcal{E}_{\\mathrm{tot}}(\\alpha, r_c, n) = \\sqrt{\\mathcal{E}_{\\mathrm{real}}(\\alpha, r_c)^2 + \\mathcal{E}_{\\mathrm{recip}}(\\alpha, n)^2}\n$$\nThe real-space error, $\\mathcal{E}_{\\mathrm{real}}$, arises from truncating the short-range interactions at the cutoff $r_c$:\n$$\n\\mathcal{E}_{\\mathrm{real}}(\\alpha, r_c; \\rho, q_{\\mathrm{rms}}) = k_{\\mathrm{real}} q_{\\mathrm{rms}}^2 \\sqrt{\\rho} \\exp(-(\\alpha r_c)^2)\n$$\nThe reciprocal-space error, $\\mathcal{E}_{\\mathrm{recip}}$, arises from the discretization of reciprocal space onto a grid of size $\\mathbf{n}_{\\mathrm{grid}} = (n,n,n)$:\n$$\n\\mathcal{E}_{\\mathrm{recip}}(\\alpha, n; L, \\rho, q_{\\mathrm{rms}}, p) = k_{\\mathrm{recip}} q_{\\mathrm{rms}}^2 \\sqrt{\\rho} n^{-p} \\exp\\left(-\\left(\\frac{\\pi n}{\\alpha L}\\right)^2\\right)\n$$\nHere, $\\rho = N/L^3$ is the particle number density, $q_{\\mathrm{rms}}$ is the root-mean-square particle charge, $L$ is the cubic box side length, and $p$ is the B-spline interpolation order. The constants $k_{\\mathrm{real}}$ and $k_{\\mathrm{recip}}$ are given as $1.0$.\n\nThe total computational cost, $C_{\\mathrm{tot}}$, is modeled as the sum of three primary components:\n$$\nC_{\\mathrm{tot}}(r_c, n; N, \\rho, p) = C_{\\mathrm{real}}(r_c) + C_{\\mathrm{spread}}(n) + C_{\\mathrm{FFT}}(n)\n$$\nwhere:\n- $C_{\\mathrm{real}}(N, \\rho, r_c) = c_{\\mathrm{pair}} N \\rho r_c^3$ is the cost of real-space pair computations.\n- $C_{\\mathrm{spread}}(n, p) = c_{\\mathrm{spread}} p^3 n^3$ is the cost of spreading charges to the mesh and gathering forces.\n- $C_{\\mathrm{FFT}}(n) = c_{\\mathrm{FFT}} n^3 \\log_2(n^3)$ is the cost of the $3$D Fast Fourier Transform.\nThe cost constants are specified as $c_{\\mathrm{pair}} = 10^{-6}$, $c_{\\mathrm{spread}} = 2\\times 10^{-7}$, and $c_{\\mathrm{FFT}} = 5\\times 10^{-6}$.\n\nThe optimization problem is to find $(\\alpha^\\star, r_c^\\star, n^\\star)$ that minimizes $C_{\\mathrm{tot}}$ subject to the constraint $\\mathcal{E}_{\\mathrm{tot}} \\le \\varepsilon$. The search space is defined by the parameters:\n- $n \\in \\mathcal{N}$, the set of $5$-smooth integers (prime factors $\\in \\{2,3,5\\}$) in the interval $[32, 128]$.\n- $r_c \\in [r_{c,\\min}, r_{c,\\max}] = [0.5, 0.49 L]$.\n- $\\alpha \\in [\\alpha_{\\min}(r_c), \\alpha_{\\max}(r_c)] = [0.5/r_c, 3.5/r_c]$.\n\nGiven the non-linear and coupled nature of the error and cost functions, an analytical solution is intractable. The prescribed solution method is a systematic grid search over the discretized parameter space. The discrete nature of $n$ forms the basis of the search. For each valid integer $n$, the continuous domains for $r_c$ and $\\alpha$ are sampled uniformly. Specifically, we use $40$ sample points for $r_c$ across its range and, for each $r_c$, $40$ sample points for $\\alpha$ across its corresponding range.\n\nThe algorithm proceeds as follows for each test case:\n1.  Generate the sorted list of $5$-smooth integers $\\mathcal{N}$ in $[32, 128]$.\n2.  Initialize a tracking tuple for the optimal parameters, $(C_{\\mathrm{best}}, n_{\\mathrm{best}}, r_{c, \\mathrm{best}}, \\alpha_{\\mathrm{best}})$, with $C_{\\mathrm{best}}$ set to infinity. This structure is chosen to facilitate lexicographical comparison, which naturally implements the specified tie-breaking rule: prefer lower cost, then smaller $n$, then smaller $r_c$, then smaller $\\alpha$.\n3.  Iterate through each $n \\in \\mathcal{N}$. For each $n$, iterate through the $40$ samples of $r_c$. For each $(n, r_c)$ pair, iterate through the $40$ samples of $\\alpha$.\n4.  At each point $(\\alpha, r_c, n)$ in the search grid, calculate the total error $\\mathcal{E}_{\\mathrm{tot}}$.\n5.  Check for feasibility by comparing the calculated error to the tolerance: $\\mathcal{E}_{\\mathrm{tot}} \\le \\varepsilon$.\n6.  If the parameter set is feasible, calculate the total cost $C_{\\mathrm{tot}}$.\n7.  Compare the current feasible solution's lexicographical tuple $(C_{\\mathrm{tot}}, n, r_c, \\alpha)$ with the best-so-far tuple. If the current one is smaller, it becomes the new optimum, and its parameters and error are stored.\n8.  After searching the entire grid, if a feasible solution was found, the optimal parameters $(\\alpha^\\star, r_c^\\star, n^\\star)$, the minimal cost $C_{\\mathrm{tot}}^\\star$, and the corresponding error $\\mathcal{E}_{\\mathrm{tot}}^\\star$ are recorded. Otherwise, the case is marked as infeasible.\n9.  The final results for each test case are formatted and aggregated into a single list structure as required. Floating-point values are formatted to $6$ decimal places.\n\nThis brute-force search guarantees finding the optimal parameters within the discretized space. The output is a collection of these optimal settings for the provided suite of test systems.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Finds optimal PME parameters by performing a grid search for a series of test cases.\n    \"\"\"\n\n    # Define constants from the problem statement.\n    K_REAL = 1.0\n    K_RECIP = 1.0\n    C_PAIR = 1.0e-6\n    C_SPREAD = 2.0e-7\n    C_FFT = 5.0e-6\n    N_MIN = 32\n    N_MAX = 128\n    RC_MIN_VAL = 0.5\n    NUM_SAMPLES = 40\n\n    test_cases = [\n        (100000, 10.0, 0.30, 4, 1e-3),\n        (100000, 10.0, 0.30, 4, 3e-5),\n        (5000, 6.0, 0.50, 6, 5e-4),\n        (200000, 8.0, 0.25, 6, 1e-5),\n    ]\n\n    def generate_smooth_numbers(n_min, n_max):\n        \"\"\"Generates 5-smooth integers within a given range.\"\"\"\n        nums = {1}\n        q = [1]\n        head = 0\n        # Generate all 5-smooth numbers up to n_max\n        while head < len(q):\n            curr = q[head]\n            head += 1\n            for factor in [2, 3, 5]:\n                next_val = curr * factor\n                if next_val <= n_max and next_val not in nums:\n                    nums.add(next_val)\n                    q.append(next_val)\n        # Filter by n_min and sort\n        return sorted([x for x in nums if x >= n_min])\n\n    n_smooth_list = generate_smooth_numbers(N_MIN, N_MAX)\n    \n    all_results = []\n    \n    for case in test_cases:\n        N, L, q_rms, p, epsilon = case\n        rho = N / (L**3)\n\n        best_params_tuple = (float('inf'), -1, -1.0, -1.0)  # (cost, n, rc, alpha)\n        best_error = -1.0\n        found_feasible = False\n\n        # Pre-calculate reciprocal space cost components which only depend on n and p\n        cost_recip_map = {}\n        for n_val in n_smooth_list:\n            c_spread = C_SPREAD * (p**3) * (n_val**3)\n            c_fft = C_FFT * (n_val**3) * np.log2(n_val**3)\n            cost_recip_map[n_val] = c_spread + c_fft\n\n        for n in n_smooth_list:\n            rc_max = 0.49 * L\n            rc_samples = np.linspace(RC_MIN_VAL, rc_max, NUM_SAMPLES)\n            \n            cost_recip = cost_recip_map[n]\n\n            for r_c in rc_samples:\n                alpha_min = 0.5 / r_c\n                alpha_max = 3.5 / r_c\n                alpha_samples = np.linspace(alpha_min, alpha_max, NUM_SAMPLES)\n\n                cost_real = C_PAIR * N * rho * r_c**3\n\n                common_err_factor = (q_rms**2) * np.sqrt(rho)\n                e_real_base = K_REAL * common_err_factor\n                e_recip_base = K_RECIP * common_err_factor * (n**(-p))\n                \n                for alpha in alpha_samples:\n                    # Error Calculation\n                    e_real_sq_arg = -((alpha * r_c)**2)\n                    e_real = e_real_base * np.exp(e_real_sq_arg)\n\n                    e_recip_sq_arg = -((np.pi * n) / (alpha * L))**2\n                    e_recip = e_recip_base * np.exp(e_recip_sq_arg)\n\n                    e_tot = np.sqrt(e_real**2 + e_recip**2)\n\n                    if e_tot <= epsilon:\n                        found_feasible = True\n                        \n                        # Cost Calculation\n                        cost_tot = cost_real + cost_recip\n                        \n                        current_params_tuple = (cost_tot, n, r_c, alpha)\n                        if current_params_tuple < best_params_tuple:\n                            best_params_tuple = current_params_tuple\n                            best_error = e_tot\n        \n        if found_feasible:\n            opt_cost, opt_n, opt_rc, opt_alpha = best_params_tuple\n            result = [opt_alpha, opt_rc, opt_n, opt_cost, best_error, True]\n        else:\n            result = [-1, -1, -1, -1, -1, False]\n        \n        all_results.append(result)\n\n    # Format the final output string exactly as specified.\n    output_parts = []\n    for res in all_results:\n        if res[-1] is False:\n            output_parts.append(\"[-1,-1,-1,-1,-1,False]\")\n        else:\n            alpha, rc, n, cost, error, _ = res\n            part = (f\"[{alpha:.6f},{rc:.6f},{n},\"\n                    f\"{cost:.6f},{error:.6f},True]\")\n            output_parts.append(part)\n    \n    final_output_string = f\"[{','.join(output_parts)}]\"\n    print(final_output_string)\n\nsolve()\n\n```"
        },
        {
            "introduction": "Selecting an appropriate integration timestep $\\Delta t$ is a balancing act between computational efficiency and numerical stability. While a larger timestep allows for sampling longer physical times, it can also lead to energy drift and compromise the validity of the simulation. This practice provides a quantitative protocol for choosing a production-safe timestep by modeling the long-term energy drift as a function of $\\Delta t$ and constraint tolerance, ensuring that your production run remains both stable and conservative .",
            "id": "3438059",
            "problem": "You are planning a production Molecular Dynamics (MD) run with holonomic constraints enforced by the SHAKE algorithm. Your goal is to select a production-safe maximum timestep $\\,\\Delta t\\,$ that satisfies stability and long-time energy conservation requirements. Assume the following principle-based model for the average long-time energy drift in constant energy simulations with constraints:\n1. The integrator is a second-order symplectic scheme, so its truncation error contributes a drift that scales with the squared timestep.\n2. The SHAKE constraint solver enforces constraints to a tolerance $\\,\\epsilon_{\\mathrm{SHAKE}}\\,$ and leaves a residual that injects error proportional to the square of this residual.\n\nUnder these assumptions, model the average long-time energy drift as\n$$\n\\left\\langle \\frac{dE}{dt} \\right\\rangle \\approx C_1 \\left(\\Delta t_{\\mathrm{ps}}\\right)^2 + C_2 \\,\\epsilon_{\\mathrm{SHAKE}}^2,\n$$\nwhere $\\,\\Delta t_{\\mathrm{ps}} = \\Delta t / 1000\\,$ is the timestep expressed in picoseconds, $\\,\\left\\langle dE/dt \\right\\rangle\\,$ is expressed in kilojoules per mole per picosecond, and $\\,C_1\\,$ and $\\,C_2\\,$ are nonnegative system-dependent coefficients to be determined from test runs.\n\nYour task is to:\n- Fit the coefficients $\\,C_1\\,$ and $\\,C_2\\,$ by least squares on provided test-run datasets.\n- For each dataset, compute the largest production-safe timestep $\\,\\Delta t_{\\mathrm{safe}}\\,$ (in femtoseconds) that satisfies:\n  - A target energy drift bound $\\,\\left\\langle dE/dt \\right\\rangle \\le D_{\\mathrm{target}}\\,$ at a specified constraint tolerance $\\,\\epsilon_{\\mathrm{target}}\\,$.\n  - A linear stability bound derived from the maximum vibrational frequency $\\,\\omega_{\\max}\\,$ (in radians per picosecond), namely\n    $$\n    \\Delta t_{\\mathrm{stab}} = \\frac{2}{\\omega_{\\max}},\n    $$\n    reduced by a conservative stability factor $\\,\\zeta = 0.85\\,$.\n  - A conservative production margin applied to the drift-based estimate via a factor $\\,\\gamma = 0.9\\,$.\n\nFormally, let\n$$\n\\Delta t_{\\mathrm{drift}} = \\sqrt{ \\max\\!\\left( 0, \\frac{D_{\\mathrm{target}} - C_2\\,\\epsilon_{\\mathrm{target}}^2}{C_1} \\right) },\n$$\ncomputed in picoseconds, and\n$$\n\\Delta t_{\\mathrm{stab,safe}} = \\zeta \\,\\Delta t_{\\mathrm{stab}} = \\zeta \\,\\frac{2}{\\omega_{\\max}},\n$$\nalso in picoseconds. Define the production-safe timestep as\n$$\n\\Delta t_{\\mathrm{safe}} = \\min\\!\\left( \\gamma \\,\\Delta t_{\\mathrm{drift}}, \\, \\Delta t_{\\mathrm{stab,safe}} \\right),\n$$\nand report it in femtoseconds. If $\\,D_{\\mathrm{target}} - C_2\\,\\epsilon_{\\mathrm{target}}^2 \\le 0\\,$, set $\\,\\Delta t_{\\mathrm{safe}} = 0\\,$.\n\nUse the following three datasets as a test suite. In each dataset, you are given a list of test-run observations as triples $\\,(\\Delta t_{\\mathrm{fs}}, \\epsilon_{\\mathrm{SHAKE}}, \\langle dE/dt\\rangle)\\,$ with timestep in femtoseconds, tolerance dimensionless, and drift in kilojoules per mole per picosecond. You are also given $\\,\\omega_{\\max}\\,$, $\\,\\epsilon_{\\mathrm{target}}\\,$, and $\\,D_{\\mathrm{target}}\\,$. All numbers are exact and should be used as-is.\n\nDataset A:\n- Observations:\n  - $(\\,0.5,\\, 1.0\\times 10^{-5},\\, 0.0051\\,)$\n  - $(\\,1.0,\\, 1.0\\times 10^{-5},\\, 0.0201\\,)$\n  - $(\\,2.0,\\, 1.0\\times 10^{-5},\\, 0.0801\\,)$\n  - $(\\,0.5,\\, 5.0\\times 10^{-5},\\, 0.0075\\,)$\n  - $(\\,1.0,\\, 5.0\\times 10^{-5},\\, 0.0225\\,)$\n  - $(\\,2.0,\\, 5.0\\times 10^{-5},\\, 0.0825\\,)$\n  - $(\\,0.5,\\, 1.0\\times 10^{-4},\\, 0.0150\\,)$\n  - $(\\,1.5,\\, 1.0\\times 10^{-4},\\, 0.0550\\,)$\n  - $(\\,2.5,\\, 1.0\\times 10^{-4},\\, 0.1350\\,)$\n- Other parameters:\n  - $\\,\\omega_{\\max} = 200\\,\\mathrm{rad/ps}\\,$\n  - $\\,\\epsilon_{\\mathrm{target}} = 1.0\\times 10^{-4}\\,$\n  - $\\,D_{\\mathrm{target}} = 0.0500\\,\\mathrm{kJ/mol/ps}\\,$\n\nDataset B:\n- Observations:\n  - $(\\,0.5,\\, 2.0\\times 10^{-5},\\, 0.00145\\,)$\n  - $(\\,1.5,\\, 2.0\\times 10^{-5},\\, 0.01145\\,)$\n  - $(\\,2.5,\\, 2.0\\times 10^{-5},\\, 0.03145\\,)$\n  - $(\\,3.0,\\, 2.0\\times 10^{-5},\\, 0.04520\\,)$\n  - $(\\,0.5,\\, 8.0\\times 10^{-5},\\, 0.00445\\,)$\n  - $(\\,1.5,\\, 8.0\\times 10^{-5},\\, 0.01445\\,)$\n  - $(\\,2.5,\\, 8.0\\times 10^{-5},\\, 0.03445\\,)$\n  - $(\\,3.0,\\, 8.0\\times 10^{-5},\\, 0.04820\\,)$\n- Other parameters:\n  - $\\,\\omega_{\\max} = 400\\,\\mathrm{rad/ps}\\,$\n  - $\\,\\epsilon_{\\mathrm{target}} = 2.0\\times 10^{-5}\\,$\n  - $\\,D_{\\mathrm{target}} = 0.0300\\,\\mathrm{kJ/mol/ps}\\,$\n\nDataset C:\n- Observations:\n  - $(\\,0.5,\\, 1.0\\times 10^{-4},\\, 0.0925\\,)$\n  - $(\\,1.0,\\, 1.0\\times 10^{-4},\\, 0.1000\\,)$\n  - $(\\,1.2,\\, 1.0\\times 10^{-4},\\, 0.1044\\,)$\n  - $(\\,0.5,\\, 3.0\\times 10^{-4},\\, 0.8125\\,)$\n  - $(\\,1.0,\\, 3.0\\times 10^{-4},\\, 0.8200\\,)$\n  - $(\\,1.2,\\, 3.0\\times 10^{-4},\\, 0.8244\\,)$\n- Other parameters:\n  - $\\,\\omega_{\\max} = 1200\\,\\mathrm{rad/ps}\\,$\n  - $\\,\\epsilon_{\\mathrm{target}} = 3.0\\times 10^{-4}\\,$\n  - $\\,D_{\\mathrm{target}} = 0.8000\\,\\mathrm{kJ/mol/ps}\\,$\n\nAdditional constants to use for all datasets:\n- Production drift margin factor $\\,\\gamma = 0.9\\,$.\n- Stability safety factor $\\,\\zeta = 0.85\\,$.\n\nComputational requirements:\n- For each dataset, perform a linear least-squares fit for $\\,C_1\\,$ and $\\,C_2\\,$ using the design variables $\\,(\\Delta t_{\\mathrm{ps}})^2\\,$ and $\\,\\epsilon^2\\,$.\n- Use the fitted $\\,C_1\\,$ and $\\,C_2\\,$ to compute $\\,\\Delta t_{\\mathrm{safe}}\\,$ as defined above, and report the result in femtoseconds, rounded to three decimal places.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the three datasets as a comma-separated list enclosed in square brackets, in the order A, B, C. For example, $\\,\\left[\\Delta t_{\\mathrm{safe}}^{(A)},\\Delta t_{\\mathrm{safe}}^{(B)},\\Delta t_{\\mathrm{safe}}^{(C)}\\right]\\,$ with each value in femtoseconds rounded to three decimal places, like $\\,\\left[1.250,2.000,0.500\\right]\\,$.",
            "solution": "The stated problem is to determine a production-safe timestep, $\\Delta t_{\\mathrm{safe}}$, for a Molecular Dynamics (MD) simulation. This is accomplished by first characterizing the system's energy drift behavior and then applying criteria for both long-term energy conservation and numerical stability. The process involves two main stages: a linear least-squares fit to determine model parameters from empirical data, followed by the application of specified formulas to calculate $\\Delta t_{\\mathrm{safe}}$.\n\nThe energy drift model is given as a linear combination of terms dependent on the integration timestep, $\\Delta t$, and the SHAKE constraint tolerance, $\\epsilon_{\\mathrm{SHAKE}}$:\n$$\n\\left\\langle \\frac{dE}{dt} \\right\\rangle \\approx C_1 \\left(\\Delta t_{\\mathrm{ps}}\\right)^2 + C_2 \\,\\epsilon_{\\mathrm{SHAKE}}^2\n$$\nHere, $\\Delta t_{\\mathrm{ps}}$ is the timestep in picoseconds ($\\Delta t_{\\mathrm{ps}} = \\Delta t_{\\mathrm{fs}} / 1000$), and $\\langle dE/dt \\rangle$ is the average energy drift in units of $\\mathrm{kJ/mol/ps}$. The coefficients $C_1$ and $C_2$ are system-specific constants that we must determine.\n\nTo find $C_1$ and $C_2$ for each dataset, we treat the model as a linear equation $y = C_1 x_1 + C_2 x_2$, where the independent variables are $x_1 = (\\Delta t_{\\mathrm{ps}})^2$ and $x_2 = \\epsilon_{\\mathrm{SHAKE}}^2$, and the dependent variable is $y = \\langle dE/dt \\rangle$. Given a set of $N$ observations $(\\Delta t_i, \\epsilon_i, y_i)$, we can construct a linear system $A\\mathbf{c} \\approx \\mathbf{b}$, where:\n- $\\mathbf{c} = [C_1, C_2]^T$ is the vector of coefficients to be determined.\n- $\\mathbf{b}$ is an $N \\times 1$ vector of the observed energy drifts $y_i$.\n- $A$ is the $N \\times 2$ design matrix, where the $i$-th row is $[(\\Delta t_{\\mathrm{ps}, i})^2, \\epsilon_i^2]$.\n\nThe coefficients $C_1$ and $C_2$ are found by solving this overdetermined system using the method of linear least squares, which minimizes the sum of the squares of the residuals. This solution is given by solving the normal equations:\n$$\nA^T A \\mathbf{c} = A^T \\mathbf{b}\n$$\n\nOnce $C_1$ and $C_2$ are determined, the production-safe timestep, $\\Delta t_{\\mathrm{safe}}$, is calculated as the minimum of two limiting timesteps, adjusted by safety factors.\n\n$1$. The drift-limited timestep, $\\Delta t_{\\mathrm{drift}}$, is derived from the requirement that the energy drift remains below a target threshold, $D_{\\mathrm{target}}$, for a given production tolerance, $\\epsilon_{\\mathrm{target}}$. Rearranging the model equation gives:\n$$\n\\Delta t_{\\mathrm{drift}} = \\sqrt{ \\max\\!\\left( 0, \\frac{D_{\\mathrm{target}} - C_2\\,\\epsilon_{\\mathrm{target}}^2}{C_1} \\right) }\n$$\nThis value is computed in picoseconds. A production margin factor, $\\gamma = 0.9$, is applied to this value.\n\n$2$. The stability-limited timestep, $\\Delta t_{\\mathrm{stab,safe}}$, is based on the highest vibrational frequency in the system, $\\omega_{\\max}$, to prevent numerical instability of the integrator. The Verlet stability criterion is $\\Delta t \\le 2/\\omega_{\\max}$. A conservative safety factor, $\\zeta = 0.85$, is applied:\n$$\n\\Delta t_{\\mathrm{stab,safe}} = \\zeta \\,\\frac{2}{\\omega_{\\max}}\n$$\nThis is also computed in picoseconds.\n\nThe final production-safe timestep, in picoseconds, is the more restrictive of these two:\n$$\n\\Delta t_{\\mathrm{safe}} = \\min\\!\\left( \\gamma \\,\\Delta t_{\\mathrm{drift}}, \\, \\Delta t_{\\mathrm{stab,safe}} \\right)\n$$\nAs per the problem specification, if $D_{\\mathrm{target}} - C_2\\,\\epsilon_{\\mathrm{target}}^2 \\le 0$, then $\\Delta t_{\\mathrm{drift}}$ is effectively $0$, which leads to $\\Delta t_{\\mathrm{safe}} = 0$. The final result is reported in femtoseconds ($\\mathrm{fs}$), where $1 \\mathrm{ps} = 1000 \\mathrm{fs}$.\n\nWe now apply this procedure to each dataset.\n\n**Dataset A**\n\n- Parameters: $\\omega_{\\max} = 200\\,\\mathrm{rad/ps}$, $\\epsilon_{\\mathrm{target}} = 1.0 \\times 10^{-4}$, $D_{\\mathrm{target}} = 0.0500\\,\\mathrm{kJ/mol/ps}$.\n- Constants: $\\gamma = 0.9$, $\\zeta = 0.85$.\n\nFirst, we perform the least-squares fit on the $9$ observations. The design matrix $A$ and observation vector $\\mathbf{b}$ are constructed. Solving $A^T A \\mathbf{c} = A^T \\mathbf{b}$ yields the coefficients:\n- $C_1 = 20000.0$\n- $C_2 = 1.0 \\times 10^6$\n\nNext, we calculate the two limiting timesteps:\n- Stability limit:\n$$\n\\Delta t_{\\mathrm{stab,safe}} = \\zeta \\frac{2}{\\omega_{\\max}} = 0.85 \\times \\frac{2}{200\\,\\mathrm{rad/ps}} = 0.0085\\,\\mathrm{ps}\n$$\n- Drift limit: We first evaluate the numerator term for $\\Delta t_{\\mathrm{drift}}$:\n$$\nD_{\\mathrm{target}} - C_2\\,\\epsilon_{\\mathrm{target}}^2 = 0.0500 - (1.0 \\times 10^6)(1.0 \\times 10^{-4})^2 = 0.0500 - 0.01 = 0.0400\n$$\nSince this is positive, we proceed:\n$$\n\\Delta t_{\\mathrm{drift}} = \\sqrt{\\frac{0.0400}{20000.0}} = \\sqrt{2 \\times 10^{-6}}\\,\\mathrm{ps} \\approx 0.0014142\\,\\mathrm{ps}\n$$\n\nFinally, we compute $\\Delta t_{\\mathrm{safe}}$:\n$$\n\\Delta t_{\\mathrm{safe}} = \\min(0.9 \\times 0.0014142\\,\\mathrm{ps}, 0.0085\\,\\mathrm{ps}) = \\min(0.0012728\\,\\mathrm{ps}, 0.0085\\,\\mathrm{ps}) = 0.0012728\\,\\mathrm{ps}\n$$\nConverting to femtoseconds and rounding to three decimal places gives $1.273\\,\\mathrm{fs}$.\n\n**Dataset B**\n\n- Parameters: $\\omega_{\\max} = 400\\,\\mathrm{rad/ps}$, $\\epsilon_{\\mathrm{target}} = 2.0 \\times 10^{-5}$, $D_{\\mathrm{target}} = 0.0300\\,\\mathrm{kJ/mol/ps}$.\n- Constants: $\\gamma = 0.9$, $\\zeta = 0.85$.\n\nThe least-squares fit on the $8$ observations for Dataset B yields:\n- $C_1 = 5000.0$\n- $C_2 = 5.0 \\times 10^5$\n\nNow, we calculate the limiting timesteps:\n- Stability limit:\n$$\n\\Delta t_{\\mathrm{stab,safe}} = \\zeta \\frac{2}{\\omega_{\\max}} = 0.85 \\times \\frac{2}{400\\,\\mathrm{rad/ps}} = 0.00425\\,\\mathrm{ps}\n$$\n- Drift limit:\n$$\nD_{\\mathrm{target}} - C_2\\,\\epsilon_{\\mathrm{target}}^2 = 0.0300 - (5.0 \\times 10^5)(2.0 \\times 10^{-5})^2 = 0.0300 - 0.0002 = 0.0298\n$$\nThis is positive, so:\n$$\n\\Delta t_{\\mathrm{drift}} = \\sqrt{\\frac{0.0298}{5000.0}} = \\sqrt{5.96 \\times 10^{-6}}\\,\\mathrm{ps} \\approx 0.0024413\\,\\mathrm{ps}\n$$\n\nThe safe timestep is:\n$$\n\\Delta t_{\\mathrm{safe}} = \\min(0.9 \\times 0.0024413\\,\\mathrm{ps}, 0.00425\\,\\mathrm{ps}) = \\min(0.0021972\\,\\mathrm{ps}, 0.00425\\,\\mathrm{ps}) = 0.0021972\\,\\mathrm{ps}\n$$\nConverting to femtoseconds and rounding gives $2.197\\,\\mathrm{fs}$.\n\n**Dataset C**\n\n- Parameters: $\\omega_{\\max} = 1200\\,\\mathrm{rad/ps}$, $\\epsilon_{\\mathrm{target}} = 3.0 \\times 10^{-4}$, $D_{\\mathrm{target}} = 0.8000\\,\\mathrm{kJ/mol/ps}$.\n- Constants: $\\gamma = 0.9$, $\\zeta = 0.85$.\n\nThe least-squares fit on the $6$ observations for Dataset C yields:\n- $C_1 = 10000.0$\n- $C_2 = 9.0 \\times 10^6$\n\nCalculating the limiting timesteps:\n- Stability limit:\n$$\n\\Delta t_{\\mathrm{stab,safe}} = \\zeta \\frac{2}{\\omega_{\\max}} = 0.85 \\times \\frac{2}{1200\\,\\mathrm{rad/ps}} \\approx 0.0014167\\,\\mathrm{ps}\n$$\n- Drift limit:\n$$\nD_{\\mathrm{target}} - C_2\\,\\epsilon_{\\mathrm{target}}^2 = 0.8000 - (9.0 \\times 10^6)(3.0 \\times 10^{-4})^2 = 0.8000 - 0.81 = -0.01\n$$\nSince this value is negative, the target drift $D_{\\mathrm{target}}$ cannot be achieved even with an infinitesimally small timestep, because the error from the constraint tolerance alone exceeds the budget. According to the problem statement, we must set $\\Delta t_{\\mathrm{safe}} = 0$. This is consistent with the formula $\\Delta t_{\\mathrm{drift}} = \\sqrt{\\max(0, \\ldots)} = 0$, leading to $\\Delta t_{\\mathrm{safe}} = \\min(0, \\Delta t_{\\mathrm{stab,safe}}) = 0$.\n\nConverting to femtoseconds and rounding gives $0.000\\,\\mathrm{fs}$.\n\nIn summary, the calculated safe timesteps are $1.273\\,\\mathrm{fs}$ for Dataset A, $2.197\\,\\mathrm{fs}$ for Dataset B, and $0.000\\,\\mathrm{fs}$ for Dataset C.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the production-safe MD timestep for three datasets.\n    \"\"\"\n\n    # Define the global constants\n    GAMMA = 0.9  # Production drift margin factor\n    ZETA = 0.85   # Stability safety factor\n\n    # Define the datasets\n    test_cases = [\n        {\n            \"name\": \"A\",\n            \"observations\": [\n                (0.5, 1.0e-5, 0.0051),\n                (1.0, 1.0e-5, 0.0201),\n                (2.0, 1.0e-5, 0.0801),\n                (0.5, 5.0e-5, 0.0075),\n                (1.0, 5.0e-5, 0.0225),\n                (2.0, 5.0e-5, 0.0825),\n                (0.5, 1.0e-4, 0.0150),\n                (1.5, 1.0e-4, 0.0550),\n                (2.5, 1.0e-4, 0.1350),\n            ],\n            \"omega_max\": 200.0,\n            \"epsilon_target\": 1.0e-4,\n            \"D_target\": 0.0500,\n        },\n        {\n            \"name\": \"B\",\n            \"observations\": [\n                (0.5, 2.0e-5, 0.00145),\n                (1.5, 2.0e-5, 0.01145),\n                (2.5, 2.0e-5, 0.03145),\n                (3.0, 2.0e-5, 0.04520),\n                (0.5, 8.0e-5, 0.00445),\n                (1.5, 8.0e-5, 0.01445),\n                (2.5, 8.0e-5, 0.03445),\n                (3.0, 8.0e-5, 0.04820),\n            ],\n            \"omega_max\": 400.0,\n            \"epsilon_target\": 2.0e-5,\n            \"D_target\": 0.0300,\n        },\n        {\n            \"name\": \"C\",\n            \"observations\": [\n                (0.5, 1.0e-4, 0.0925),\n                (1.0, 1.0e-4, 0.1000),\n                (1.2, 1.0e-4, 0.1044),\n                (0.5, 3.0e-4, 0.8125),\n                (1.0, 3.0e-4, 0.8200),\n                (1.2, 3.0e-4, 0.8244),\n            ],\n            \"omega_max\": 1200.0,\n            \"epsilon_target\": 3.0e-4,\n            \"D_target\": 0.8000,\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        obs = np.array(case[\"observations\"])\n        \n        # 1. Data Preparation for Least-Squares Fit\n        dt_fs = obs[:, 0]\n        epsilon_shake = obs[:, 1]\n        drift = obs[:, 2]\n\n        # Convert timestep from femtoseconds to picoseconds\n        dt_ps = dt_fs / 1000.0\n\n        # Construct the design matrix A and observation vector b\n        # Model: drift = C1 * (dt_ps^2) + C2 * (epsilon_shake^2)\n        x1 = dt_ps**2\n        x2 = epsilon_shake**2\n        A = np.vstack([x1, x2]).T\n        b = drift\n\n        # 2. Perform Linear Least-Squares Fit\n        coeffs, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n        C1, C2 = coeffs\n\n        # 3. Compute the production-safe timestep\n        \n        # Check explicit condition to set dt_safe = 0\n        drift_budget_term = case[\"D_target\"] - C2 * case[\"epsilon_target\"]**2\n        if drift_budget_term <= 0:\n            dt_safe_fs = 0.0\n        else:\n            # Calculate drift-limited timestep (in ps)\n            dt_drift_ps = np.sqrt(drift_budget_term / C1)\n\n            # Calculate stability-limited timestep (in ps)\n            dt_stab_safe_ps = ZETA * 2.0 / case[\"omega_max\"]\n\n            # Determine the final safe timestep (in ps)\n            dt_safe_ps = min(GAMMA * dt_drift_ps, dt_stab_safe_ps)\n            \n            # Convert to femtoseconds\n            dt_safe_fs = dt_safe_ps * 1000.0\n        \n        # Format result to 3 decimal places\n        results.append(f\"{dt_safe_fs:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A key question in planning any production simulation is determining the required run length to achieve statistically meaningful results. This practice illustrates how to answer this question quantitatively by connecting the desired precision of an observable to the simulation's statistical properties. You will derive and apply the relationship between the standard error of a time-averaged quantity, its intrinsic variance, its integrated autocorrelation time $\\tau_{\\mathrm{int}}$, and the total simulation time $T$, transforming the planning process from guesswork into a data-driven decision .",
            "id": "3438067",
            "problem": "A production Molecular Dynamics (MD) run is planned to estimate the time average of an observable $A(t)$ (for example, instantaneous potential energy per mole) with a prescribed precision. A short pilot simulation has been performed and, after discarding equilibration, the time series $A(t)$ appears stationary and ergodic. From the pilot data, the following estimates were obtained: the integrated autocorrelation time $\\tau_{\\mathrm{int}}$ and the variance $\\sigma_{A}^{2} \\equiv \\langle (A - \\langle A \\rangle)^{2} \\rangle$. The production trajectory will be run long enough that the total production time $T$ satisfies $T \\gg \\tau_{\\mathrm{int}}$, and the sampling is uniform in time.\n\nStarting from the definition of the time average $\\bar{A}_{T} \\equiv \\frac{1}{T} \\int_{0}^{T} A(t) \\, dt$ and the autocovariance function $C_{A}(t) \\equiv \\langle (A(0) - \\langle A \\rangle)(A(t) - \\langle A \\rangle) \\rangle$ for a stationary process, derive an expression for the asymptotic variance of $\\bar{A}_{T}$ in terms of $\\sigma_{A}^{2}$, $\\tau_{\\mathrm{int}}$, and $T$. Then use this expression to determine the required production time $T$ to achieve a target standard error $\\sigma_{\\bar{A}}$ on the estimator $\\bar{A}_{T}$.\n\nFor planning purposes, use the pilot estimates $\\tau_{\\mathrm{int}} = 25\\,\\mathrm{ps}$ and $\\sigma_{A}^{2} = 400\\,(\\mathrm{kJ}\\,\\mathrm{mol}^{-1})^{2}$, and require a target standard error $\\sigma_{\\bar{A}} = 1\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$. Express the final required production time $T$ in nanoseconds, and round your answer to three significant figures.",
            "solution": "The problem asks for a derivation of the variance of a time-averaged observable from a Molecular Dynamics (MD) simulation and subsequently a calculation of the required simulation length to achieve a target precision. The problem is scientifically grounded, well-posed, and contains all necessary information. We may proceed with the solution.\n\nFirst, we derive the expression for the variance of the time average, $\\bar{A}_{T}$. The time average of an observable $A(t)$ over a total time $T$ is defined as:\n$$\n\\bar{A}_{T} \\equiv \\frac{1}{T} \\int_{0}^{T} A(t) \\, dt\n$$\nThe variance of this estimator, denoted as $\\sigma_{\\bar{A}_{T}}^{2}$, is given by $\\sigma_{\\bar{A}_{T}}^{2} = \\langle (\\bar{A}_{T} - \\langle \\bar{A}_{T} \\rangle)^{2} \\rangle$, where $\\langle \\cdot \\rangle$ denotes an ensemble average. For a stationary process, the ensemble average $\\langle A(t) \\rangle$ is independent of time and equals the true mean, which we denote as $\\langle A \\rangle$. The ensemble average of the estimator $\\bar{A}_{T}$ is:\n$$\n\\langle \\bar{A}_{T} \\rangle = \\left\\langle \\frac{1}{T} \\int_{0}^{T} A(t) \\, dt \\right\\rangle = \\frac{1}{T} \\int_{0}^{T} \\langle A(t) \\rangle \\, dt = \\frac{1}{T} \\int_{0}^{T} \\langle A \\rangle \\, dt = \\frac{1}{T} \\langle A \\rangle [t]_{0}^{T} = \\langle A \\rangle\n$$\nThis shows that $\\bar{A}_{T}$ is an unbiased estimator of $\\langle A \\rangle$. The variance can therefore be written as:\n$$\n\\sigma_{\\bar{A}_{T}}^{2} = \\langle (\\bar{A}_{T} - \\langle A \\rangle)^{2} \\rangle\n$$\nSubstituting the definition of $\\bar{A}_{T}$ and introducing a fluctuation term $\\delta A(t) = A(t) - \\langle A \\rangle$:\n$$\n\\sigma_{\\bar{A}_{T}}^{2} = \\left\\langle \\left( \\frac{1}{T} \\int_{0}^{T} A(t) \\, dt - \\langle A \\rangle \\right)^{2} \\right\\rangle = \\left\\langle \\left( \\frac{1}{T} \\int_{0}^{T} (A(t) - \\langle A \\rangle) \\, dt \\right)^{2} \\right\\rangle = \\frac{1}{T^{2}} \\left\\langle \\left( \\int_{0}^{T} \\delta A(t) \\, dt \\right)^{2} \\right\\rangle\n$$\nWe can write the squared integral as a double integral:\n$$\n\\sigma_{\\bar{A}_{T}}^{2} = \\frac{1}{T^{2}} \\left\\langle \\int_{0}^{T} \\delta A(t) \\, dt \\int_{0}^{T} \\delta A(t') \\, dt' \\right\\rangle\n$$\nBy linearity of the expectation operator, we can move it inside the integrals:\n$$\n\\sigma_{\\bar{A}_{T}}^{2} = \\frac{1}{T^{2}} \\int_{0}^{T} dt \\int_{0}^{T} dt' \\, \\langle \\delta A(t) \\delta A(t') \\rangle\n$$\nFor a stationary process, the correlation $\\langle \\delta A(t) \\delta A(t') \\rangle$ depends only on the time difference, $|t' - t|$. This is precisely the definition of the autocovariance function, $C_{A}(\\tau) = \\langle \\delta A(0) \\delta A(\\tau) \\rangle$. Thus, $\\langle \\delta A(t) \\delta A(t') \\rangle = C_{A}(t' - t)$.\n$$\n\\sigma_{\\bar{A}_{T}}^{2} = \\frac{1}{T^{2}} \\int_{0}^{T} dt \\int_{0}^{T} dt' \\, C_{A}(t' - t)\n$$\nThis double integral over a square domain can be simplified. Using the identity $\\int_{0}^{L} \\int_{0}^{L} f(|x-y|) \\, dy \\, dx = 2 \\int_{0}^{L} (L-z) f(z) \\, dz$ and noting that the autocovariance function is even, $C_{A}(\\tau) = C_{A}(-\\tau)$, we have:\n$$\n\\sigma_{\\bar{A}_{T}}^{2} = \\frac{2}{T^{2}} \\int_{0}^{T} (T - \\tau) C_{A}(\\tau) \\, d\\tau = \\frac{2}{T} \\int_{0}^{T} \\left(1 - \\frac{\\tau}{T}\\right) C_{A}(\\tau) \\, d\\tau\n$$\nThe problem states that the total production time $T$ is much larger than the integrated autocorrelation time, $T \\gg \\tau_{\\mathrm{int}}$. The autocovariance $C_{A}(\\tau)$ decays to zero on a time scale characterized by $\\tau_{\\mathrm{int}}$. Therefore, for the significant part of the integration range where $C_{A}(\\tau)$ is non-zero, we have $\\tau \\ll T$. This allows two approximations:\n1.  The term $(1 - \\frac{\\tau}{T}) \\approx 1$.\n2.  The upper integration limit can be extended from $T$ to $\\infty$ with negligible error.\nApplying these approximations, we obtain the asymptotic variance:\n$$\n\\sigma_{\\bar{A}_{T}}^{2} \\approx \\frac{2}{T} \\int_{0}^{\\infty} C_{A}(\\tau) \\, d\\tau\n$$\nThe problem provides definitions for the variance $\\sigma_{A}^{2}$ and the integrated autocorrelation time $\\tau_{\\mathrm{int}}$. The variance of the observable $A$ is $\\sigma_{A}^{2} = C_{A}(0)$. The standard definition of the integrated autocorrelation time is the integral of the *normalized* autocorrelation function:\n$$\n\\tau_{\\mathrm{int}} = \\int_{0}^{\\infty} \\frac{C_{A}(\\tau)}{C_{A}(0)} \\, d\\tau = \\frac{1}{\\sigma_{A}^{2}} \\int_{0}^{\\infty} C_{A}(\\tau) \\, d\\tau\n$$\nFrom this, we find $\\int_{0}^{\\infty} C_{A}(\\tau) \\, d\\tau = \\sigma_{A}^{2} \\tau_{\\mathrm{int}}$. Substituting this into our expression for the variance of the mean gives the desired relationship:\n$$\n\\sigma_{\\bar{A}_{T}}^{2} \\approx \\frac{2 \\sigma_{A}^{2} \\tau_{\\mathrm{int}}}{T}\n$$\nNext, we use this expression to determine the required production time $T$. The target standard error on the estimator is $\\sigma_{\\bar{A}}$, which is the square root of the variance, $\\sigma_{\\bar{A}} = \\sqrt{\\sigma_{\\bar{A}_{T}}^{2}}$. Squaring both sides gives $\\sigma_{\\bar{A}}^{2} = \\sigma_{\\bar{A}_{T}}^{2}$. We can now solve for $T$:\n$$\nT \\approx \\frac{2 \\sigma_{A}^{2} \\tau_{\\mathrm{int}}}{\\sigma_{\\bar{A}}^{2}}\n$$\nWe are given the following pilot estimates and target precision:\n- $\\tau_{\\mathrm{int}} = 25\\,\\mathrm{ps}$\n- $\\sigma_{A}^{2} = 400\\,(\\mathrm{kJ}\\,\\mathrm{mol}^{-1})^{2}$\n- $\\sigma_{\\bar{A}} = 1\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$, which means $\\sigma_{\\bar{A}}^{2} = (1\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1})^{2} = 1\\,(\\mathrm{kJ}\\,\\mathrm{mol}^{-1})^{2}$.\n\nSubstituting these values into the expression for $T$:\n$$\nT \\approx \\frac{2 \\times 400\\,(\\mathrm{kJ}\\,\\mathrm{mol}^{-1})^{2} \\times 25\\,\\mathrm{ps}}{1\\,(\\mathrm{kJ}\\,\\mathrm{mol}^{-1})^{2}}\n$$\nThe units of $(\\mathrm{kJ}\\,\\mathrm{mol}^{-1})^{2}$ cancel, leaving the time in picoseconds:\n$$\nT \\approx (2 \\times 400 \\times 25)\\,\\mathrm{ps} = (800 \\times 25)\\,\\mathrm{ps} = 20000\\,\\mathrm{ps}\n$$\nThe problem requires the answer in nanoseconds (ns). Since $1\\,\\mathrm{ns} = 1000\\,\\mathrm{ps}$:\n$$\nT \\approx 20000\\,\\mathrm{ps} \\times \\frac{1\\,\\mathrm{ns}}{1000\\,\\mathrm{ps}} = 20\\,\\mathrm{ns}\n$$\nFinally, we must round the answer to three significant figures.\n$$\nT = 20.0\\,\\mathrm{ns}\n$$\nAs a consistency check, our result $T = 20000\\,\\mathrm{ps}$ is indeed much larger than $\\tau_{\\mathrm{int}} = 25\\,\\mathrm{ps}$ (by a factor of $800$), which validates the asymptotic approximation used in the derivation.",
            "answer": "$$\\boxed{20.0}$$"
        }
    ]
}