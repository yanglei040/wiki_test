{
    "hands_on_practices": [
        {
            "introduction": "任何能量最小化算法的第一步都是确定“下坡”方向。在分子系统中，这个方向由势能的负梯度给出，它直接对应于作用在每个原子上的力。这个基础练习  将指导你推导出一个常见的原子间相互作用——Lennard-Jones势的梯度，这是理解和实现分子动力学模拟中力计算的核心技能。",
            "id": "3449099",
            "problem": "在分子动力学 (MD) 的能量最小化算法中，例如最速下降法和共轭梯度法 (CG)，搜索方向和步长接受准则需要计算能量相对于原子笛卡尔坐标的梯度。考虑一对原子，其位置分别为 $x_i \\in \\mathbb{R}^3$ 和 $x_j \\in \\mathbb{R}^3$，它们通过 Lennard-Jones 势 $U(r) = 4\\epsilon\\left[\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6\\right]$ 相互作用，其中 $r = \\|x_i - x_j\\|$，$ \\epsilon  0$ 是深度参数，$\\sigma  0$ 是尺寸参数。从欧几里得范数的定义、向量微积分中的链式法则以及标量场与其梯度之间的基本关系出发，推导出笛卡尔梯度 $\\nabla_{x_i} U$ 和 $\\nabla_{x_j} U$ 的闭合形式，并将其完全简化为 $x_i$、$x_j$、$\\epsilon$、$\\sigma$ 和 $r$ 的函数。\n\n将最终结果表示为一个包含两个元素的单行矩阵，其中第一个元素是 $\\nabla_{x_i} U$ 的闭合形式表达式，第二个元素是 $\\nabla_{x_j} U$ 的闭合形式表达式。不需要进行数值计算，也不需要包含单位。不需要进行四舍五入。",
            "solution": "该问题要求推导 Lennard-Jones 势 $U$ 相对于原子位置 $x_i$ 和 $x_j$ 的笛卡尔梯度。势 $U$ 是关于两个原子间标量距离 $r = \\|x_i - x_j\\|$ 的函数。位置 $x_i$ 和 $x_j$ 是 $\\mathbb{R}^3$ 中的向量。\n\nLennard-Jones 势为：\n$$U(r) = 4\\epsilon\\left[\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6\\right]$$\n其中 $\\epsilon  0$ 和 $\\sigma  0$ 是常数。\n\n势 $U$ 是一个复合函数。它是一个定义在原子位置上的标量场 $U(x_i, x_j)$。它对 $x_i$ 和 $x_j$ 的依赖是通过标量距离 $r(x_i, x_j) = \\|x_i - x_j\\|$ 来实现的。为了求出 $U$ 相对于 $x_i$ 的梯度，记作 $\\nabla_{x_i} U$，我们应用向量微积分的链式法则：\n$$\\nabla_{x_i} U(r(x_i, x_j)) = \\frac{dU}{dr} \\nabla_{x_i} r$$\n这需要两个部分：$U$ 对 $r$ 的常导数 $\\frac{dU}{dr}$，以及标量距离 $r$ 对向量 $x_i$ 的梯度 $\\nabla_{x_i} r$。\n\n首先，我们计算 $\\frac{dU}{dr}$。为了清晰起见，我们将 $U(r)$ 重写为：\n$$U(r) = 4\\epsilon(\\sigma^{12}r^{-12} - \\sigma^6r^{-6})$$\n使用幂函数求导法则 $\\frac{d}{dr}(r^n) = nr^{n-1}$：\n$$\\frac{dU}{dr} = 4\\epsilon \\left[ \\sigma^{12}(-12r^{-13}) - \\sigma^6(-6r^{-7}) \\right]$$\n$$\\frac{dU}{dr} = 4\\epsilon \\left[ -12\\frac{\\sigma^{12}}{r^{13}} + 6\\frac{\\sigma^6}{r^7} \\right]$$\n提取公因式以简化表达式：\n$$\\frac{dU}{dr} = 24\\epsilon \\left[ \\frac{\\sigma^6}{r^7} - 2\\frac{\\sigma^{12}}{r^{13}} \\right]$$\n这也可以用无量纲比率表示：\n$$\\frac{dU}{dr} = \\frac{24\\epsilon}{r} \\left[ \\left(\\frac{\\sigma}{r}\\right)^6 - 2\\left(\\frac{\\sigma}{r}\\right)^{12} \\right]$$\n\n其次，我们计算 $\\nabla_{x_i} r$。距离 $r$ 是分离向量 $\\vec{r}_{ij} = x_i - x_j$ 的欧几里得范数：\n$$r = \\|x_i - x_j\\| = \\sqrt{(x_i - x_j) \\cdot (x_i - x_j)}$$\n通常先计算 $r^2$ 的梯度会更容易：\n$$r^2 = (x_i - x_j) \\cdot (x_i - x_j)$$\n梯度算子 $\\nabla_{x_i}$ 作用于 $x_i$ 的函数。使用点积的乘积法则 $\\nabla(A \\cdot B) = (\\nabla A)B + (\\nabla B)A$：\n$$\\nabla_{x_i} r^2 = \\nabla_{x_i} ((x_i - x_j) \\cdot (x_i - x_j)) = 2 (\\nabla_{x_i} (x_i - x_j)) \\cdot (x_i - x_j)$$\n$x_i$ 对自身的梯度是单位张量 $\\mathbf{I}$，而 $x_j$ 在对 $x_i$ 求导时是常数。因此，$\\nabla_{x_i} (x_i - x_j) = \\mathbf{I}$。\n$$\\nabla_{x_i} r^2 = 2 (x_i - x_j)$$\n或者，对左边使用链式法则，$\\nabla_{x_i} r^2 = 2r \\nabla_{x_i} r$。\n令 $\\nabla_{x_i} r^2$ 的两个表达式相等：\n$$2r \\nabla_{x_i} r = 2(x_i - x_j)$$\n$$\\nabla_{x_i} r = \\frac{x_i - x_j}{r}$$\n\n现在我们结合这两个部分来求 $\\nabla_{x_i} U$：\n$$\\nabla_{x_i} U = \\frac{dU}{dr} \\nabla_{x_i} r = \\left( \\frac{24\\epsilon}{r} \\left[ \\left(\\frac{\\sigma}{r}\\right)^6 - 2\\left(\\frac{\\sigma}{r}\\right)^{12} \\right] \\right) \\left( \\frac{x_i - x_j}{r} \\right)$$\n简化此表达式，我们得到：\n$$\\nabla_{x_i} U = \\frac{24\\epsilon}{r^2} \\left[ \\left(\\frac{\\sigma}{r}\\right)^6 - 2\\left(\\frac{\\sigma}{r}\\right)^{12} \\right] (x_i - x_j)$$\n\n接下来，我们推导相对于 $x_j$ 的梯度 $\\nabla_{x_j} U$。势 $U$ 仅取决于分离向量的大小，$r = \\|x_i - x_j\\| = \\|x_j - x_i\\|$。因此，该势对于粒子交换是对称的。对于这种仅取决于分离距离的对势，根据平移不变性（牛顿第三定律），作用在粒子对上的总力必须为零。作用在粒子 $k$ 上的力是 $F_k = -\\nabla_{x_k} U$。\n$$F_i + F_j = 0 \\implies -\\nabla_{x_i} U - \\nabla_{x_j} U = 0$$\n因此，\n$$\\nabla_{x_j} U = -\\nabla_{x_i} U$$\n代入 $\\nabla_{x_i} U$ 的表达式：\n$$\\nabla_{x_j} U = - \\left( \\frac{24\\epsilon}{r^2} \\left[ \\left(\\frac{\\sigma}{r}\\right)^6 - 2\\left(\\frac{\\sigma}{r}\\right)^{12} \\right] (x_i - x_j) \\right)$$\n通过将负号分配到向量部分 $(x_i - x_j)$ 中，我们得到：\n$$\\nabla_{x_j} U = \\frac{24\\epsilon}{r^2} \\left[ \\left(\\frac{\\sigma}{r}\\right)^6 - 2\\left(\\frac{\\sigma}{r}\\right)^{12} \\right] (x_j - x_i)$$\n\n所求的两个笛卡尔梯度是：\n$$\\nabla_{x_i} U = \\frac{24\\epsilon}{r^2} \\left[ \\left(\\frac{\\sigma}{r}\\right)^6 - 2\\left(\\frac{\\sigma}{r}\\right)^{12} \\right] (x_i - x_j)$$\n$$\\nabla_{x_j} U = \\frac{24\\epsilon}{r^2} \\left[ \\left(\\frac{\\sigma}{r}\\right)^6 - 2\\left(\\frac{\\sigma}{r}\\right)^{12} \\right] (x_j - x_i)$$\n这些表达式是所要求的闭合形式，已完全简化为 $x_i$、$x_j$、$\\epsilon$、$\\sigma$ 和 $r$ 的函数。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{24\\epsilon}{r^{2}} \\left[ \\left(\\frac{\\sigma}{r}\\right)^{6} - 2\\left(\\frac{\\sigma}{r}\\right)^{12} \\right] (x_i - x_j)  \\frac{24\\epsilon}{r^{2}} \\left[ \\left(\\frac{\\sigma}{r}\\right)^{6} - 2\\left(\\frac{\\sigma}{r}\\right)^{12} \\right] (x_j - x_i) \\end{pmatrix}}$$"
        },
        {
            "introduction": "虽然最速下降法在概念上很简单，但共轭梯度（CG）法通常是一种更高效、更强大的能量最小化工具。为了真正揭开其工作原理的神秘面纱，亲手在一个简单的二次模型系统上执行几步迭代是无价的。这个练习  让你能够深入了解CG算法的内部机制，包括如何计算步长 $\\alpha_k$、更新位置 $x_k$ 以及构建新的共轭搜索方向 $p_k$。",
            "id": "3449130",
            "problem": "在分子动力学 (MD) 中，对局部盆地周围势能的谐波近似进行能量最小化，可以由以下形式的二次函数建模：$$U(x) = \\frac{1}{2} x^{\\top} A x - b^{\\top} x,$$ 其中 $x \\in \\mathbb{R}^{n}$ 汇集了系统在平衡点附近的广义坐标，$A \\in \\mathbb{R}^{n \\times n}$ 是势能的对称正定 Hessian 矩阵，而 $b \\in \\mathbb{R}^{n}$ 代表由外力或梯度在参考构型周围线性化产生的线性项。最小化子 $x^{\\star}$ 满足平稳性条件 $$\\nabla U(x^{\\star}) = A x^{\\star} - b = 0,$$ 这是一个线性方程组。共轭梯度法 (CG) 在分子动力学中被广泛用于能量最小化，因为它利用对称正定系统的结构来快速收敛，而无需存储或分解矩阵。\n\n考虑能量函数 $$U(x) = \\frac{1}{2} x^{\\top} \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix} x - \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}^{\\top} x,$$ 其中 $x \\in \\mathbb{R}^{2}$。目标是使用共轭梯度 (CG) 方法求解等效的线性系统来最小化 $U(x)$：$$A x = b,$$ 其中 $$A = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}.$$ 使用标准的共轭梯度 (CG) 算法，初始猜测为 $$x_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix},$$ 残差定义为 $$r_{k} = b - A x_{k}.$$ 执行整整两次 CG 迭代以获得 $x_{2}$ 和 $r_{2}$。设第 $k$ 次迭代的误差为 $$e_{k} = x^{\\star} - x_{k},$$ 其中 $x^{\\star}$ 是 $A x = b$ 的精确解，并定义误差的 $A$-范数为 $$\\| e_{k} \\|_{A} = \\sqrt{ e_{k}^{\\top} A e_{k} }.$$ 将 $x_{2}$、$r_{2}$ 和 $\\| e_{2} \\|_{A}$ 这三个量报告为精确值（不要四舍五入）。将你的最终答案表示为一个包含这三项并按指定顺序排列的复合行矩阵。",
            "solution": "用户希望我遵循严谨的验证过程来解决问题，然后提供详细的解决方案。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n\n问题提供了以下数据和定义：\n- 势能函数：$U(x) = \\frac{1}{2} x^{\\top} A x - b^{\\top} x$，其中 $x \\in \\mathbb{R}^{2}$。\n- 矩阵 $A$：$A = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix}$。\n- 向量 $b$：$b = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$。\n- 解的初始猜测：$x_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。\n- 第 $k$ 次迭代的残差定义：$r_{k} = b - A x_{k}$。\n- 第 $k$ 次迭代的误差定义：$e_{k} = x^{\\star} - x_{k}$，其中 $x^{\\star}$ 是 $A x = b$ 的精确解。\n- 误差的 $A$-范数定义：$\\| e_{k} \\|_{A} = \\sqrt{ e_{k}^{\\top} A e_{k} }$。\n- 任务是执行整整两次共轭梯度 (CG) 方法迭代，以求出 $x_{2}$、$r_{2}$ 和 $\\| e_{2} \\|_{A}$。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n- **科学依据**：该问题是应用共轭梯度法来最小化一个二次函数，这等同于求解一个线性系统 $A x = b$。这是数值线性代数和优化中的一个标准且基本的问题，正如问题所述，在分子动力学等科学领域有直接应用。矩阵 $A$ 是对称的。要成为标准 CG 方法的有效问题，$A$ 还必须是正定的。$A$ 的主子式为 $\\det(4) = 4  0$ 和 $\\det(A) = 4 \\times 3 - 1 \\times 1 = 11  0$。由于所有主子式都为正，矩阵 $A$ 是正定的。因此，该问题在科学上和数学上都是合理的。\n- **适定性**：由于 $A$ 是对称正定矩阵，因此它是可逆的。所以，线性系统 $A x = b$ 有唯一解 $x^{\\star} = A^{-1} b$。$U(x)$ 的最小化问题也有唯一的全局最小值。该问题是适定的。\n- **客观性**：该问题使用精确的数学定义和语言陈述，没有任何主观性或模糊性。\n- **完整性**：执行两步 CG 算法所需的所有信息都已提供。\n- **其他缺陷**：该问题没有表现出验证标准中列出的任何其他缺陷。这是一个定义明确、标准的数值方法练习题。\n\n**步骤 3：结论和行动**\n\n问题有效。我将继续进行求解。\n\n### 解答\n\n共轭梯度算法是一种用于求解线性方程组 $A x = b$ 的迭代方法，其中 $A$ 是一个对称正定矩阵。该算法从初始猜测 $x_{0}$ 开始，按以下步骤进行：\n\n初始化：\n$k = 0$\n$r_{0} = b - A x_{0}$\n$p_{0} = r_{0}$\n\n对于 $k = 0, 1, 2, \\dots$：\n1. 计算步长：$\\alpha_{k} = \\frac{r_{k}^{\\top} r_{k}}{p_{k}^{\\top} A p_{k}}$\n2. 更新解：$x_{k+1} = x_{k} + \\alpha_{k} p_{k}$\n3. 更新残差：$r_{k+1} = r_{k} - \\alpha_{k} A p_{k}$\n4. 如果 $r_{k+1}$ 足够小，则停止。\n5. 计算搜索方向的改进因子：$\\beta_{k} = \\frac{r_{k+1}^{\\top} r_{k+1}}{r_{k}^{\\top} r_{k}}$\n6. 更新搜索方向：$p_{k+1} = r_{k+1} + \\beta_{k} p_{k}$\n\n我们被要求从 $x_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ 开始，执行整整两次迭代（$k=0$ 和 $k=1$）。\n\n**初始化 ($k=0$)**\n\n初始猜测为 $x_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。\n初始残差为：\n$$r_{0} = b - A x_{0} = b = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$$\n初始搜索方向与初始残差相同：\n$$p_{0} = r_{0} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$$\n\n**第一次迭代 ($k=0$)**\n\n1. 计算步长 $\\alpha_{0}$：\n分子是 $r_{0}^{\\top} r_{0} = \\begin{pmatrix} 1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = 1^{2} + 2^{2} = 5$。\n首先，我们计算 $A p_{0}$：\n$$A p_{0} = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 4(1) + 1(2) \\\\ 1(1) + 3(2) \\end{pmatrix} = \\begin{pmatrix} 6 \\\\ 7 \\end{pmatrix}$$\n分母是 $p_{0}^{\\top} A p_{0} = \\begin{pmatrix} 1  2 \\end{pmatrix} \\begin{pmatrix} 6 \\\\ 7 \\end{pmatrix} = 1(6) + 2(7) = 20$。\n所以，$\\alpha_{0} = \\frac{5}{20} = \\frac{1}{4}$。\n\n2. 更新解以得到 $x_{1}$：\n$$x_{1} = x_{0} + \\alpha_{0} p_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\frac{1}{4} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{4} \\\\ \\frac{2}{4} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{4} \\\\ \\frac{1}{2} \\end{pmatrix}$$\n\n3. 更新残差以得到 $r_{1}$：\n$$r_{1} = r_{0} - \\alpha_{0} A p_{0} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} - \\frac{1}{4} \\begin{pmatrix} 6 \\\\ 7 \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{6}{4} \\\\ 2 - \\frac{7}{4} \\end{pmatrix} = \\begin{pmatrix} \\frac{4-6}{4} \\\\ \\frac{8-7}{4} \\end{pmatrix} = \\begin{pmatrix} -\\frac{2}{4} \\\\ \\frac{1}{4} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix}$$\n\n5. 计算因子 $\\beta_{0}$：\n分子是 $r_{1}^{\\top} r_{1} = \\begin{pmatrix} -\\frac{1}{2}  \\frac{1}{4} \\end{pmatrix} \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix} = (-\\frac{1}{2})^{2} + (\\frac{1}{4})^{2} = \\frac{1}{4} + \\frac{1}{16} = \\frac{4+1}{16} = \\frac{5}{16}$。\n分母是 $r_{0}^{\\top} r_{0} = 5$。\n所以，$\\beta_{0} = \\frac{r_{1}^{\\top} r_{1}}{r_{0}^{\\top} r_{0}} = \\frac{5/16}{5} = \\frac{1}{16}$。\n\n6. 更新搜索方向以得到 $p_{1}$：\n$$p_{1} = r_{1} + \\beta_{0} p_{0} = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix} + \\frac{1}{16} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} -\\frac{8}{16} + \\frac{1}{16} \\\\ \\frac{4}{16} + \\frac{2}{16} \\end{pmatrix} = \\begin{pmatrix} -\\frac{7}{16} \\\\ \\frac{6}{16} \\end{pmatrix}$$\n\n**第二次迭代 ($k=1$)**\n\n1. 计算步长 $\\alpha_{1}$：\n分子是 $r_{1}^{\\top} r_{1} = \\frac{5}{16}$。\n首先，我们计算 $A p_{1}$：\n$$A p_{1} = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} -\\frac{7}{16} \\\\ \\frac{6}{16} \\end{pmatrix} = \\frac{1}{16} \\begin{pmatrix} 4(-7) + 1(6) \\\\ 1(-7) + 3(6) \\end{pmatrix} = \\frac{1}{16} \\begin{pmatrix} -22 \\\\ 11 \\end{pmatrix}$$\n分母是 $p_{1}^{\\top} A p_{1} = \\begin{pmatrix} -\\frac{7}{16}  \\frac{6}{16} \\end{pmatrix} \\left( \\frac{1}{16} \\begin{pmatrix} -22 \\\\ 11 \\end{pmatrix} \\right) = \\frac{1}{256} ((-7)(-22) + 6(11)) = \\frac{1}{256} (154 + 66) = \\frac{220}{256}$。\n所以，$\\alpha_{1} = \\frac{r_{1}^{\\top} r_{1}}{p_{1}^{\\top} A p_{1}} = \\frac{5/16}{220/256} = \\frac{5}{16} \\times \\frac{256}{220} = 5 \\times \\frac{16}{220} = \\frac{80}{220} = \\frac{8}{22} = \\frac{4}{11}$。\n\n2. 更新解以得到 $x_{2}$：\n$$x_{2} = x_{1} + \\alpha_{1} p_{1} = \\begin{pmatrix} \\frac{1}{4} \\\\ \\frac{1}{2} \\end{pmatrix} + \\frac{4}{11} \\begin{pmatrix} -\\frac{7}{16} \\\\ \\frac{6}{16} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{4} \\\\ \\frac{1}{2} \\end{pmatrix} + \\begin{pmatrix} -\\frac{7}{11 \\times 4} \\\\ \\frac{6}{11 \\times 4} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{4} - \\frac{7}{44} \\\\ \\frac{1}{2} + \\frac{6}{44} \\end{pmatrix}$$\n$$x_{2} = \\begin{pmatrix} \\frac{11-7}{44} \\\\ \\frac{22+6}{44} \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{44} \\\\ \\frac{28}{44} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{11} \\\\ \\frac{7}{11} \\end{pmatrix}$$\n这是第一个要求的量。\n\n3. 更新残差以得到 $r_{2}$：\n$$r_{2} = r_{1} - \\alpha_{1} A p_{1} = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix} - \\frac{4}{11} \\left( \\frac{1}{16} \\begin{pmatrix} -22 \\\\ 11 \\end{pmatrix} \\right) = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix} - \\frac{1}{44} \\begin{pmatrix} -22 \\\\ 11 \\end{pmatrix}$$\n$$r_{2} = \\begin{pmatrix} -\\frac{1}{2} + \\frac{22}{44} \\\\ \\frac{1}{4} - \\frac{11}{44} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{2} + \\frac{1}{2} \\\\ \\frac{1}{4} - \\frac{1}{4} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\n这是第二个要求的量。\n\n**误差计算**\n\n$A x = b$ 的精确解 $x^{\\star}$ 满足该方程。残差定义为 $r_{k} = b - A x_{k}$。如果 $r_{k} = 0$，那么 $b - A x_{k} = 0$，这意味着 $A x_{k} = b$。因此，$x_k$ 是精确解，$x_{k} = x^{\\star}$。\n在我们的例子中，$r_{2} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，所以 $x_{2}$ 是精确解：$x_{2} = x^{\\star}$。这是预期的结果，因为在精确算术下，对于一个 $n \\times n$ 的系统，CG 方法保证在至多 $n$ 次迭代内找到精确解。这里 $n=2$。\n\n第 $k=2$ 次迭代的误差是 $e_{2} = x^{\\star} - x_{2}$。由于 $x^{\\star} = x_{2}$，误差为：\n$$e_{2} = x_{2} - x_{2} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\n误差 $e_{2}$ 的 $A$-范数定义为 $\\| e_{2} \\|_{A} = \\sqrt{ e_{2}^{\\top} A e_{2} }$。\n$$\\| e_{2} \\|_{A} = \\sqrt{ \\begin{pmatrix} 0  0 \\end{pmatrix} \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} } = \\sqrt{0} = 0$$\n这是第三个要求的量。\n\n这三个量是：\n$x_{2} = \\begin{pmatrix} \\frac{1}{11} \\\\ \\frac{7}{11} \\end{pmatrix}$\n$r_{2} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$\n$\\| e_{2} \\|_{A} = 0$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\begin{pmatrix} \\frac{1}{11} \\\\ \\frac{7}{11} \\end{pmatrix}  \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}  0 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "真实的分子能量形貌很少是简单的各向同性碗状。它们常常包含狭窄、细长的“山谷”，即能量面在不同方向上的曲率（或“刚度”）差异巨大。这种各向异性使得像最速下降法这样的简单算法效率低下。这个编程练习  让你通过模拟来探索这种行为，亲眼观察算法在一个狭窄山谷中的低效“之”字形路径，从而深刻理解为何需要共轭梯度这类更先进的方法。",
            "id": "3449160",
            "problem": "考虑由 $U(x,y)=\\left(x^2-1\\right)^2+k\\,y^2$ 定义的二维势能函数 $U:\\mathbb{R}^2\\to\\mathbb{R}$，其中 $k0$ 是一个刚度参数，用于控制 $x$ 和 $y$ 方向之间的曲率各向异性。在分子动力学能量最小化的背景下，负梯度 $-\\nabla U$ 与力成正比，最速下降法更新沿着负梯度方向移动以降低势能。\n\n从给定的初始位置 $(x_0,y_0)$ 开始，使用 Armijo 回溯线搜索执行恰好 $2$ 次最速下降法迭代。在第 $n$ 次迭代中，最速下降法的更新形式为 $(x_{n+1},y_{n+1})=(x_n,y_n)-t_n\\,\\nabla U(x_n,y_n)$，其中步长 $t_n0$ 通过 Armijo 回溯法选择，以保证充分下降。Armijo 充分下降准则是指不等式 $U\\big((x_n,y_n)-t\\,\\nabla U(x_n,y_n)\\big)\\le U(x_n,y_n)-\\sigma\\,t\\,\\|\\nabla U(x_n,y_n)\\|_2^2$，其中 $t$ 从几何序列 $t=t_0\\,\\beta^m$（$m\\in\\{0,1,2,\\dots\\}$）中选择，$t_00$ 是初始步长，$\\beta\\in(0,1)$ 是回溯收缩因子，$\\sigma\\in\\left(0,\\tfrac{1}{2}\\right)$ 是 Armijo 参数。梯度根据第一性原理定义为 $\\nabla U(x,y)=\\left(\\tfrac{\\partial U}{\\partial x}(x,y),\\tfrac{\\partial U}{\\partial y}(x,y)\\right)$。\n\n定义两步的位移向量为 $\\Delta \\mathbf{r}_1=(x_1-x_0,\\,y_1-y_0)$ 和 $\\Delta \\mathbf{r}_2=(x_2-x_1,\\,y_2-y_1)$。为了量化曲率各向异性对路径的影响，计算无量纲的路径各向异性比 $R=\\dfrac{|\\Delta y_1|+|\\Delta y_2|}{|\\Delta x_1|+|\\Delta x_2|}$，其中 $\\Delta x_i$ 和 $\\Delta y_i$ 是 $\\Delta \\mathbf{r}_i$ 的分量。如果分母恰好为零，则定义 $R=+\\infty$。\n\n编写一个完整、可运行的程序，对下面的每个测试用例，执行恰好 $2$ 次带 Armijo 回溯的最速下降迭代，并输出相应的 $R$ 值（以浮点数形式）。不涉及物理单位；$R$ 是无量纲的。您的程序必须按照描述实现 Armijo 回溯，且仅使用所提供的参数。为保证数值稳健性，您可以在 Armijo 条件可满足时，通过设置一个足够大的整数来限制回溯缩减的最大次数，同时保持正确性。\n\n测试套件：\n- 用例 1：$k=10$, $(x_0,y_0)=(0.5,0.5)$, $t_0=1.0$, $\\beta=0.5$, $\\sigma=10^{-4}$。\n- 用例 2：$k=1$, $(x_0,y_0)=(0.5,0.5)$, $t_0=1.0$, $\\beta=0.5$, $\\sigma=10^{-4}$。\n- 用例 3：$k=1000$, $(x_0,y_0)=(0.5,0.5)$, $t_0=1.0$, $\\beta=0.5$, $\\sigma=10^{-4}$。\n- 用例 4：$k=10$, $(x_0,y_0)=(0.5,10^{-6})$, $t_0=1.0$, $\\beta=0.5$, $\\sigma=10^{-4}$。\n- 用例 5：$k=10$, $(x_0,y_0)=(0.0,0.5)$, $t_0=1.0$, $\\beta=0.5$, $\\sigma=10^{-4}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按测试用例的顺序排列，例如 $\\big[$result$1,$result$2,$result$3,$result$4,$result$5\\big]$。每个结果必须是该测试用例计算出的对应 $R$ 值，表示为浮点数，如果出现 $+\\infty$，则应打印为有效的浮点无穷大。",
            "solution": "用户提供了一个有效且适定的数值优化问题。任务是计算一个粒子在二维势能面上，使用带 Armijo 回溯线搜索的最速下降法精确迭代 $2$ 次后得到的路径各向异性比 $R$。\n\n解决方案的制定过程是：首先建立数学和算法框架，然后将该框架实现为代码，以解决所提供的测试用例。\n\n**1. 势能与梯度**\n势能函数 $U: \\mathbb{R}^2 \\to \\mathbb{R}$ 由下式给出：\n$$\nU(x,y) = \\left(x^2-1\\right)^2+k\\,y^2\n$$\n其中 $k0$ 是一个给定的刚度参数。在分子动力学和优化中，势能的负梯度 $-\\nabla U$ 对应于作用在粒子上的力。系统旨在最小化 $U$。\n\n梯度 $\\nabla U(x,y)$ 是 $U$ 对每个坐标的偏导数向量：\n$$\n\\nabla U(x,y) = \\left( \\frac{\\partial U}{\\partial x}, \\frac{\\partial U}{\\partial y} \\right)\n$$\n计算偏导数，我们得到：\n$$\n\\frac{\\partial U}{\\partial x} = 2(x^2-1) \\cdot (2x) = 4x(x^2-1) = 4x^3 - 4x\n$$\n$$\n\\frac{\\partial U}{\\partial y} = 2ky\n$$\n因此，梯度向量为：\n$$\n\\nabla U(x,y) = (4x^3 - 4x, 2ky)\n$$\n\n**2. 最速下降算法**\n最速下降法是一种迭代优化算法，它在每一步都将点沿着负梯度方向移动。设 $\\mathbf{r}_n = (x_n, y_n)$ 为第 $n$ 次迭代时的位置。下一个位置 $\\mathbf{r}_{n+1}$ 通过以下更新规则找到：\n$$\n\\mathbf{r}_{n+1} = \\mathbf{r}_n - t_n \\nabla U(\\mathbf{r}_n)\n$$\n此处 $t_n  0$ 是第 $n$ 次迭代的步长。步长方向 $\\mathbf{d}_n = -\\nabla U(\\mathbf{r}_n)$ 是势能面在 $\\mathbf{r}_n$ 处的最速下降方向。\n\n**3. Armijo 回溯线搜索**\n必须仔细选择步长 $t_n$ 以确保势能有充分的下降。Armijo 回溯线搜索是找到这样一个步长的过程。对于每次迭代 $n$，我们按如下方式寻找 $t_n$：\n\n- **参数**：搜索使用三个参数：初始试探步长 $t_{init}$（在问题描述中记为 $t_0$），收缩因子 $\\beta \\in (0,1)$，以及充分下降参数 $\\sigma \\in (0, 1/2)$。对于本问题，这些值为 $t_{init}=1.0$，$\\beta=0.5$ 和 $\\sigma=10^{-4}$。\n- **过程**：我们从试探步长 $t = t_{init}$ 开始。然后检查它是否满足 Armijo 条件：\n$$\nU(\\mathbf{r}_n - t\\,\\nabla U(\\mathbf{r}_n)) \\le U(\\mathbf{r}_n) - \\sigma\\,t\\,\\|\\nabla U(\\mathbf{r}_n)\\|_2^2\n$$\n- 如果条件满足，我们接受这个 $t$ 作为我们的步长 $t_n$。\n- 如果条件不满足，我们将步长按收缩因子缩小，$t \\leftarrow \\beta t$，然后重复检查。\n\n对于如下方有界的平滑函数，例如给定的势能 $U(x,y)$，此过程保证会终止。\n\n**4. 两步迭代与路径各向异性比的计算**\n问题要求从初始位置 $\\mathbf{r}_0 = (x_0, y_0)$ 开始，执行恰好 $2$ 次迭代。\n\n- **迭代 1**：\n  1.  设 $n=0$。从 $\\mathbf{r}_0 = (x_0, y_0)$ 开始。\n  2.  计算梯度 $\\mathbf{g}_0 = \\nabla U(\\mathbf{r}_0)$。\n  3.  使用 Armijo 回溯（如第 3 节所述）找到步长 $t_0$。\n  4.  更新位置：$\\mathbf{r}_1 = \\mathbf{r}_0 - t_0 \\mathbf{g}_0$。\n  5.  计算第一个位移向量：$\\Delta \\mathbf{r}_1 = \\mathbf{r}_1 - \\mathbf{r}_0 = (\\Delta x_1, \\Delta y_1)$。\n\n- **迭代 2**：\n  1.  设 $n=1$。从 $\\mathbf{r}_1$ 开始。\n  2.  计算梯度 $\\mathbf{g}_1 = \\nabla U(\\mathbf{r}_1)$。\n  3.  使用 Armijo 回溯找到步长 $t_1$。\n  4.  更新位置：$\\mathbf{r}_2 = \\mathbf{r}_1 - t_1 \\mathbf{g}_1$。\n  5.  计算第二个位移向量：$\\Delta \\mathbf{r}_2 = \\mathbf{r}_2 - \\mathbf{r}_1 = (\\Delta x_2, \\Delta y_2)$。\n\n最后，使用这些位移向量的分量计算无量纲路径各向异性比 $R$：\n$$\nR = \\frac{|\\Delta y_1| + |\\Delta y_2|}{|\\Delta x_1| + |\\Delta x_2|}\n$$\n如果分母 $|\\Delta x_1| + |\\Delta x_2|$ 恰好为零，则该比率定义为 $R=+\\infty$。例如，当梯度始终垂直于 $x$ 轴时，就会发生这种情况，导致所有运动都纯粹在 $y$ 方向上。\n\n所提供的 Python 代码为五个测试用例中的每一个实现了这个完整的过程，计算并报告 $R$ 的值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # Case 1: k=10, (x0,y0)=(0.5,0.5), t0=1.0, beta=0.5, sigma=10^{-4}.\n        {'k': 10, 'r0': (0.5, 0.5), 't_init': 1.0, 'beta': 0.5, 'sigma': 1e-4},\n        # Case 2: k=1, (x0,y0)=(0.5,0.5), t0=1.0, beta=0.5, sigma=10^{-4}.\n        {'k': 1, 'r0': (0.5, 0.5), 't_init': 1.0, 'beta': 0.5, 'sigma': 1e-4},\n        # Case 3: k=1000, (x0,y0)=(0.5,0.5), t0=1.0, beta=0.5, sigma=10^{-4}.\n        {'k': 1000, 'r0': (0.5, 0.5), 't_init': 1.0, 'beta': 0.5, 'sigma': 1e-4},\n        # Case 4: k=10, (x0,y0)=(0.5,10^{-6}), t0=1.0, beta=0.5, sigma=10^{-4}.\n        {'k': 10, 'r0': (0.5, 1e-6), 't_init': 1.0, 'beta': 0.5, 'sigma': 1e-4},\n        # Case 5: k=10, (x0,y0)=(0.0,0.5), t0=1.0, beta=0.5, sigma=10^{-4}.\n        {'k': 10, 'r0': (0.0, 0.5), 't_init': 1.0, 'beta': 0.5, 'sigma': 1e-4},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_steepest_descent_for_case(**case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_steepest_descent_for_case(k, r0, t_init, beta, sigma):\n    \"\"\"\n    Performs 2 iterations of steepest descent with Armijo backtracking\n    and computes the path-anisotropy ratio R.\n    \n    Args:\n        k (float): Stiffness parameter.\n        r0 (tuple): Initial position (x0, y0).\n        t_init (float): Initial step size for Armijo search.\n        beta (float): Backtracking shrinkage factor.\n        sigma (float): Armijo sufficient decrease parameter.\n        \n    Returns:\n        float: The computed path-anisotropy ratio R.\n    \"\"\"\n    r = np.array(r0, dtype=float)\n\n    def U(pos):\n        x, y = pos\n        return (x**2 - 1)**2 + k * y**2\n\n    def grad_U(pos):\n        x, y = pos\n        grad_x = 4 * x * (x**2 - 1)\n        grad_y = 2 * k * y\n        return np.array([grad_x, grad_y])\n\n    displacements = []\n    \n    # Perform exactly 2 iterations\n    for _ in range(2):\n        r_current = r\n        U_current = U(r_current)\n        g_current = grad_U(r_current)\n        g_norm_sq = np.dot(g_current, g_current)\n\n        # Armijo backtracking line search\n        t = t_init\n        \n        # Max backtracking iterations for numerical stability\n        max_backtrack_iters = 100 \n        for _ in range(max_backtrack_iters):\n            r_next_trial = r_current - t * g_current\n            U_next_trial = U(r_next_trial)\n            \n            # Armijo sufficient-decrease condition\n            armijo_rhs = U_current - sigma * t * g_norm_sq\n            if U_next_trial = armijo_rhs:\n                break\n            \n            t *= beta\n        # The 'else' on a for-loop executes if the loop completed without a 'break'.\n        # This case should not be reached for a well-posed problem.\n        # else:\n        #    # Handle failure to find a step size, e.g., by raising an error.\n        #    # For this problem, a step size is guaranteed to exist.\n        #    pass\n\n        # Update position using the found step size\n        r_next = r_current - t * g_current\n        \n        # Store displacement vector for this step\n        displacements.append(r_next - r_current)\n        \n        # Update current position for the next iteration\n        r = r_next\n\n    # Unpack displacements\n    delta_r1 = displacements[0]\n    delta_r2 = displacements[1]\n    \n    delta_x1, delta_y1 = delta_r1\n    delta_x2, delta_y2 = delta_r2\n\n    # Calculate the path-anisotropy ratio R\n    sum_delta_y = np.abs(delta_y1) + np.abs(delta_y2)\n    sum_delta_x = np.abs(delta_x1) + np.abs(delta_x2)\n\n    if sum_delta_x == 0.0:\n        R = float('inf')\n    else:\n        R = sum_delta_y / sum_delta_x\n        \n    return R\n\nsolve()\n```"
        }
    ]
}