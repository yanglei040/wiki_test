{
    "hands_on_practices": [
        {
            "introduction": "The formal connection between the microcanonical and canonical ensembles is established through a Laplace transform, which mathematically links the density of states $\\Omega(E)$ to the partition function $Z(\\beta)$. In the thermodynamic limit, the integrand in this transform becomes sharply peaked, causing the canonical average energy to converge to the most probable microcanonical energy—the very essence of ensemble equivalence. This computational exercise allows you to perform this transformation numerically, test the accuracy of the underlying saddle-point approximation, and appreciate the numerical stability challenges inherent in the process .",
            "id": "3410951",
            "problem": "You are given microcanonical density of states functions $\\Omega(E)$ defined on discrete energy grids, as would be obtained from Wang–Landau (WL) sampling. Your task is to reconstruct canonical thermodynamics via the Laplace transform and to assess both numerical stability of the computation and the accuracy of a saddle-point approximation that represents ensemble equivalence in the thermodynamic limit. All quantities are in dimensionless units with Boltzmann constant $k_{\\mathrm B}=1$, so energy $E$, inverse temperature $\\beta$, and entropy $S(E)=\\ln \\Omega(E)$ are dimensionless. No other physical units are used or required.\n\nFundamental definitions to use:\n- The canonical partition function is defined by the Laplace transform $Z(\\beta)=\\int_{0}^{\\infty}\\Omega(E)\\,\\mathrm{e}^{-\\beta E}\\,\\mathrm{d}E$.\n- The canonical mean energy is $U(\\beta)=\\int_{0}^{\\infty} E \\, \\pi_{\\beta}(E) \\,\\mathrm{d}E$, where $\\pi_{\\beta}(E)=\\Omega(E)\\,\\mathrm{e}^{-\\beta E}/Z(\\beta)$ is the normalized canonical energy distribution.\n- The microcanonical entropy is $S(E)=\\ln \\Omega(E)$, and the saddle-point approximation for the dominant energy solves the stationarity condition for the Legendre transform, which on a discrete grid you should compute as the maximizer of $F_{\\beta}(E)=S(E)-\\beta E$.\n\nDiscretization requirements:\n- Each input $\\Omega(E)$ is provided implicitly by a parametric form on a uniform grid $E_i=E_{\\min}+i\\,\\Delta E$ for $i=0,1,\\dots,N-1$ with constant spacing $\\Delta E=(E_{\\max}-E_{\\min})/(N-1)$.\n- You must approximate the Laplace integrals by the trapezoidal rule. To ensure numerical stability, you must implement a computation of $\\ln Z(\\beta)$ using a log-sum-exp transformation. Specifically, if $w_i$ are trapezoidal weights ($w_0=w_{N-1}=\\tfrac{1}{2}$ and $w_i=1$ otherwise), then define $f_i=\\ln \\Omega(E_i)-\\beta E_i+\\ln w_i+\\ln \\Delta E$, and compute $\\ln Z(\\beta)=\\ln \\sum_i \\exp(f_i)$ using a max-subtraction, i.e., $\\ln Z(\\beta)=m+\\ln \\sum_i \\exp(f_i-m)$ with $m=\\max_i f_i$.\n- The canonical mean energy must be computed from the same stabilized weights as $U(\\beta)=\\sum_i E_i \\, \\exp(f_i-\\ln Z(\\beta))$.\n- The saddle-point energy $E_{\\ast}(\\beta)$ must be obtained by maximizing $F_{\\beta}(E_i)=S(E_i)-\\beta E_i$ over the grid.\n\nNumerical stability assessment:\n- In addition to the stabilized computation, also compute a naive trapezoidal evaluation using direct exponentials $g_i=\\exp(\\ln \\Omega(E_i)-\\beta E_i)$ without max-subtraction. Declare the naive evaluation \"unstable\" if any $g_i$ is not finite, or if the naive partition sum is non-finite or non-positive. If it is finite and positive, compute the naive canonical mean energy $U_{\\mathrm{naive}}(\\beta)$ and compare to the stabilized $U(\\beta)$. If the relative difference exceeds a tolerance $\\tau=10^{-6}$, declare it unstable; otherwise declare it stable.\n- For each test case, report two results: (i) the relative absolute error of the saddle-point approximation for the mean energy, $\\varepsilon=\\lvert E_{\\ast}(\\beta)-U(\\beta)\\rvert/\\max(U(\\beta),\\epsilon)$ with $\\epsilon=10^{-300}$ to avoid division by zero, and (ii) a stability indicator $s$ that equals $1.0$ if the naive evaluation is unstable by the above criteria, and $0.0$ otherwise.\n\nTest suite:\nImplement the following three cases, each fully specified by a parametric $\\ln \\Omega(E)$ and by $(E_{\\min},E_{\\max},N,\\beta)$:\n\n- Case $1$ (unimodal, happy path):\n  - $\\ln \\Omega(E)=(a-1)\\ln E$ with $a=50$. This corresponds to an idealized many-degree-of-freedom kinetic density of states.\n  - Domain: $E_{\\min}=10^{-9}$, $E_{\\max}=500$, $N=20001$.\n  - Inverse temperature: $\\beta=0.5$.\n\n- Case $2$ (bimodal, ensemble nonequivalence regime):\n  - $\\ln \\Omega(E)=\\ln\\left(\\exp\\left(A_1+s_1 E-\\dfrac{(E-m_1)^2}{2 w_1^2}\\right)+\\exp\\left(A_2+s_2 E-\\dfrac{(E-m_2)^2}{2 w_2^2}\\right)\\right)$ with parameters $A_1=0$, $s_1=0.06$, $m_1=40$, $w_1=8$, $A_2=2.0$, $s_2=0.015$, $m_2=140$, $w_2=8$.\n  - Domain: $E_{\\min}=0$, $E_{\\max}=220$, $N=40001$.\n  - Inverse temperature: $\\beta=0.03$.\n\n- Case $3$ (extreme-scale, numerical stability stress test):\n  - $\\ln \\Omega(E)=(a-1)\\ln E$ with $a=200$.\n  - Domain: $E_{\\min}=10^{-9}$, $E_{\\max}=50000$, $N=80001$.\n  - Inverse temperature: $\\beta=0.01$.\n\nComputational and reporting requirements:\n- Use natural logarithms throughout.\n- Angles are not used; no angle units are required.\n- For each case, compute and return the pair $(\\varepsilon,s)$ as specified above, as floating-point numbers.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as $[\\varepsilon_1,s_1,\\varepsilon_2,s_2,\\varepsilon_3,s_3]$.",
            "solution": "The problem requires the computation of canonical thermodynamic properties from a given microcanonical density of states, $\\Omega(E)$, defined on a discrete energy grid. This involves evaluating Laplace transforms numerically. A key part of the task is to assess the numerical stability of this procedure and to quantify the accuracy of the saddle-point approximation, which is a manifestation of ensemble equivalence in the thermodynamic limit.\n\nThe fundamental relationship between the microcanonical entropy $S(E) = \\ln \\Omega(E)$ and the canonical partition function $Z(\\beta)$ at an inverse temperature $\\beta$ is given by the Laplace transform:\n$$\nZ(\\beta) = \\int_{0}^{\\infty} \\Omega(E) e^{-\\beta E} \\,\\mathrm{d}E = \\int_{0}^{\\infty} e^{S(E) - \\beta E} \\,\\mathrm{d}E\n$$\nThe canonical average energy $U(\\beta)$ is the first moment of the energy distribution $\\pi_{\\beta}(E) = e^{S(E)-\\beta E}/Z(\\beta)$:\n$$\nU(\\beta) = \\langle E \\rangle_{\\beta} = \\frac{\\int_{0}^{\\infty} E e^{S(E) - \\beta E} \\,\\mathrm{d}E}{\\int_{0}^{\\infty} e^{S(E) - \\beta E} \\,\\mathrm{d}E}\n$$\nIn the thermodynamic limit (for large systems), the integrand $e^{S(E)-\\beta E}$ becomes sharply peaked around its maximum. The energy $E_{\\ast}(\\beta)$ that maximizes the exponent, $S(E)-\\beta E$, is called the saddle-point energy. This condition is equivalent to finding the energy $E$ where the microcanonical temperature, defined as $T(E) = (\\partial S/\\partial E)^{-1}$, equals the canonical temperature $T = 1/\\beta$. For large systems, ensemble equivalence implies that the canonical average energy $U(\\beta)$ should converge to this saddle-point energy $E_{\\ast}(\\beta)$.\n\nThe defined task is to implement these calculations numerically for three specific test cases and report on (i) the relative error $\\varepsilon = \\lvert E_{\\ast}(\\beta)-U(\\beta)\\rvert/\\max(U(\\beta),\\epsilon)$ of the saddle-point approximation and (ii) a flag $s$ indicating the numerical stability of a naive computational approach compared to a stabilized one.\n\nThe algorithmic procedure is as follows:\n\n1.  **Grid Discretization**: For each case, a uniform energy grid $E_i = E_{\\min} + i \\Delta E$ is defined for $i=0, \\dots, N-1$, with spacing $\\Delta E = (E_{\\max}-E_{\\min})/(N-1)$. The microcanonical entropy $S(E_i) = \\ln \\Omega(E_i)$ is evaluated on this grid.\n\n2.  **Saddle-Point Energy Calculation**: The saddle-point energy $E_{\\ast}(\\beta)$ is found by identifying the grid point $E_i$ that maximizes the function $F_{\\beta}(E_i) = S(E_i) - \\beta E_i$.\n    $$\n    E_{\\ast}(\\beta) = \\underset{E_i}{\\mathrm{argmax}} \\left( S(E_i) - \\beta E_i \\right)\n    $$\n\n3.  **Stabilized Canonical Calculation**: The integrals for $Z(\\beta)$ and $U(\\beta)$ are approximated using the trapezoidal rule. To handle the large range of values in the exponential term, which can lead to numerical overflow or underflow, a log-sum-exp stabilization technique is mandated.\n    The partition function integral is approximated as $Z(\\beta) \\approx \\sum_{i=0}^{N-1} w_i \\Delta E \\, e^{S(E_i) - \\beta E_i}$, where $w_i$ are the trapezoidal weights ($w_0=w_{N-1}=\\frac{1}{2}$, and $w_i=1$ otherwise).\n    To compute its logarithm, we define terms $f_i = S(E_i) - \\beta E_i + \\ln(w_i) + \\ln(\\Delta E)$, such that $Z(\\beta) \\approx \\sum_i e^{f_i}$.\n    The stabilized computation of $\\ln Z(\\beta)$ is then:\n    $$\n    m = \\max_i(f_i) \\\\\n    \\ln Z(\\beta) = m + \\ln\\left(\\sum_{i=0}^{N-1} e^{f_i - m}\\right)\n    $$\n    The canonical mean energy $U(\\beta)$ is computed using weights derived from this stabilized calculation:\n    $$\n    U(\\beta) = \\frac{\\sum_i E_i w_i \\Delta E e^{S(E_i) - \\beta E_i}}{\\sum_i w_i \\Delta E e^{S(E_i) - \\beta E_i}} = \\frac{\\sum_i E_i e^{f_i}}{\\sum_i e^{f_i}} = \\sum_{i=0}^{N-1} E_i e^{f_i - \\ln Z(\\beta)}\n    $$\n\n4.  **Numerical Stability Assessment**: A naive computation is also performed. Let $g_i = e^{S(E_i) - \\beta E_i}$.\n    The naive partition function is $Z_{\\mathrm{naive}} = \\sum_i w_i g_i \\Delta E$.\n    The calculation is deemed unstable (and the stability flag $s$ is set to $1.0$) if any $g_i$ is not finite, if $Z_{\\mathrm{naive}}$ is not finite or not positive, or if the naive mean energy $U_{\\mathrm{naive}} = (\\sum_i E_i w_i g_i \\Delta E)/Z_{\\mathrm{naive}}$ has a relative difference from the stabilized $U(\\beta)$ exceeding $\\tau=10^{-6}$. Otherwise, the calculation is stable ($s=0.0$).\n\n5.  **Reporting**: For each test case, the pair $(\\varepsilon, s)$ is computed and reported. The three cases are designed to test different physical and numerical regimes: a standard unimodal system (Case 1), a bimodal system exhibiting ensemble non-equivalence (Case 2), and a large-scale system designed to cause numerical overflow in naive implementations (Case 3). For the bimodal case, the function $\\ln \\Omega(E)$ is itself a log-sum-of-exponentials, requiring a nested stable evaluation.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for microcanonical to canonical ensemble calculations.\n    \"\"\"\n\n    def log_omega_power_law(E, a):\n        \"\"\"Computes ln(Omega(E)) for a power-law density of states.\"\"\"\n        # This handles vector input E, taking care of log(0) if E_min=0, although here E_min  0.\n        return (a - 1) * np.log(E)\n\n    def log_omega_bimodal(E, **params):\n        \"\"\"Computes ln(Omega(E)) for a bimodal density of states using log-sum-exp.\"\"\"\n        p = params\n        term1 = p['A1'] + p['s1'] * E - ((E - p['m1'])**2) / (2 * p['w1']**2)\n        term2 = p['A2'] + p['s2'] * E - ((E - p['m2'])**2) / (2 * p['w2']**2)\n        \n        # Use log-sum-exp for numerical stability\n        max_term = np.maximum(term1, term2)\n        return max_term + np.log(np.exp(term1 - max_term) + np.exp(term2 - max_term))\n\n    def process_case(log_omega_func, E_min, E_max, N, beta, func_params):\n        \"\"\"\n        Processes a single test case to compute the saddle-point error and stability indicator.\n        \n        Returns:\n            A tuple (epsilon, s) containing the relative error and stability flag.\n        \"\"\"\n        # --- 1. Grid and Function Setup ---\n        E = np.linspace(E_min, E_max, N)\n        delta_E = (E_max - E_min) / (N - 1)\n        \n        # Handle E=0 in log for power law case (though not strictly necessary for problems as given)\n        if E_min == 0 and log_omega_func == log_omega_power_law:\n            log_omega_E = np.full_like(E, -np.inf)\n            log_omega_E[1:] = log_omega_func(E[1:], **func_params)\n        else:\n            log_omega_E = log_omega_func(E, **func_params)\n\n        # --- 2. Saddle-Point Energy Calculation ---\n        F_beta = log_omega_E - beta * E\n        E_star = E[np.argmax(F_beta)]\n\n        # --- 3. Stabilized Canonical Calculation ---\n        trapezoidal_weights = np.ones(N)\n        trapezoidal_weights[0] = 0.5\n        trapezoidal_weights[-1] = 0.5\n        \n        f = log_omega_E - beta * E + np.log(trapezoidal_weights) + np.log(delta_E)\n\n        # Log-sum-exp for ln(Z)\n        m = np.max(f[np.isfinite(f)]) # Avoid -inf from log(0) if any\n        log_Z = m + np.log(np.sum(np.exp(f - m)))\n        \n        # Stabilized mean energy U\n        U = np.sum(E * np.exp(f - log_Z))\n\n        # --- 4. Numerical Stability Assessment ---\n        s = 0.0\n        \n        # Naive calculation\n        with np.errstate(over='ignore'):\n            g = np.exp(log_omega_E - beta * E)\n        \n        if not np.all(np.isfinite(g)):\n            s = 1.0\n        else:\n            Z_naive = np.sum(trapezoidal_weights * g * delta_E)\n            if not np.isfinite(Z_naive) or Z_naive = 0:\n                s = 1.0\n            else:\n                U_naive = np.sum(trapezoidal_weights * E * g * delta_E) / Z_naive\n                \n                # Check relative difference\n                tau = 1e-6\n                if U == 0:\n                    if abs(U_naive) > tau: # If U is zero, U_naive should also be zero\n                        s = 1.0\n                elif np.abs(U_naive - U) / np.abs(U) > tau:\n                    s = 1.0\n\n        # --- 5. Error Calculation ---\n        epsilon_small = 1e-300\n        epsilon_rel_error = np.abs(E_star - U) / np.max([np.abs(U), epsilon_small])\n        \n        return epsilon_rel_error, s\n\n    # Define test cases\n    test_cases = [\n        {\n            \"log_omega_func\": log_omega_power_law,\n            \"E_min\": 1e-9, \"E_max\": 500, \"N\": 20001, \"beta\": 0.5,\n            \"func_params\": {\"a\": 50}\n        },\n        {\n            \"log_omega_func\": log_omega_bimodal,\n            \"E_min\": 0, \"E_max\": 220, \"N\": 40001, \"beta\": 0.03,\n            \"func_params\": {\n                'A1': 0, 's1': 0.06, 'm1': 40, 'w1': 8,\n                'A2': 2.0, 's2': 0.015, 'm2': 140, 'w2': 8\n            }\n        },\n        {\n            \"log_omega_func\": log_omega_power_law,\n            \"E_min\": 1e-9, \"E_max\": 50000, \"N\": 80001, \"beta\": 0.01,\n            \"func_params\": {\"a\": 200}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        eps, s = process_case(**case)\n        results.extend([eps, s])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{r:.7e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While ensemble equivalence is a robust principle for systems with short-range interactions, it can break down for systems exhibiting phase transitions, particularly those with long-range forces. This failure is deeply connected to the geometry of the microcanonical entropy function, specifically the loss of concavity in certain energy ranges. By working through the exactly solvable Curie-Weiss mean-field Ising model, this analytical exercise provides a concrete illustration of how a non-concave entropy function gives rise to ensemble inequivalence .",
            "id": "3410966",
            "problem": "Consider the Curie–Weiss mean-field Ising model with $N$ spins $\\sigma_{i}\\in\\{-1,+1\\}$, interaction strength $J0$, and external magnetic field $h\\in\\mathbb{R}$. The Hamiltonian is\n$$\nH_{N}(\\sigma) \\;=\\; -\\,\\frac{J}{2N}\\,\\Big(\\sum_{i=1}^{N}\\sigma_{i}\\Big)^{2}\\;-\\;h\\sum_{i=1}^{N}\\sigma_{i}.\n$$\nLet the magnetization per spin be $m=\\frac{1}{N}\\sum_{i=1}^{N}\\sigma_{i}$ and the energy per spin be $e=\\frac{1}{N}H_{N}(\\sigma)$. Work in the thermodynamic limit $N\\to\\infty$, and use standard combinatorial counting and large-deviation (Laplace) principles as needed.\n\n(a) Starting only from the definitions of the microcanonical entropy and the Hamiltonian, derive the microcanonical entropy density $s(e,m)$, defined as the leading-order exponential growth rate of the number of configurations with energy density $e$ and magnetization $m$. Clearly state the domain of $(e,m)$ on which $s(e,m)$ is finite and give its explicit expression on that domain.\n\n(b) Using the canonical ensemble at inverse temperature $\\beta0$, express the canonical free-energy density $f(\\beta,h)$ in the thermodynamic limit in terms of a variational problem over $m$. Your derivation must start from the canonical partition function and proceed by reducing the sum over microstates to a sum over magnetizations weighted by their degeneracies and Boltzmann factors. Give the final closed-form variational expression for $f(\\beta,h)$.\n\n(c) Specialize to zero field $h=0$. Analyze the curvature of the objective in the variational expression for $f(\\beta,0)$ with respect to $m$ at $m=0$ and determine when it ceases to be concave there, thereby indicating a loss of global concavity and the onset of $m$-constrained ensemble inequivalence driven by nonconcavity in the entropy contribution. As your final answer, provide the analytic expression for the critical inverse temperature $\\beta_{c}$ in terms of $J$ that separates the concave and nonconcave regimes. No rounding is required; report $\\beta_{c}$ as a single closed-form expression with no units.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard problem in statistical mechanics concerning the Curie-Weiss model, and all terms and requested derivations are conventional within the field. We proceed with the solution.\n\n(a) Derivation of the microcanonical entropy density $s(e,m)$.\n\nThe state of the system is defined by a configuration of $N$ spins $\\sigma = \\{\\sigma_1, \\dots, \\sigma_N\\}$ where $\\sigma_i \\in \\{-1, +1\\}$. The magnetization per spin is given by $m = \\frac{1}{N}\\sum_{i=1}^{N}\\sigma_{i}$. Let $N_+$ be the number of spins with value $+1$ and $N_-$ be the number of spins with value $-1$. We have the relations:\n$N = N_+ + N_-$\n$Nm = N_+ - N_-$\nSolving for $N_+$ and $N_-$ in terms of $N$ and $m$ yields:\n$$N_+ = N\\frac{1+m}{2} \\quad \\text{and} \\quad N_- = N\\frac{1-m}{2}$$\nFor $N_+$ and $N_-$ to be integers between $0$ and $N$, the allowed values of $m$ are discrete, ranging from $-1$ to $1$ in steps of $2/N$.\n\nThe Hamiltonian of the system is $H_{N}(\\sigma) = -\\frac{J}{2N}\\left(\\sum_{i=1}^{N}\\sigma_{i}\\right)^{2} - h\\sum_{i=1}^{N}\\sigma_{i}$. It depends only on the total magnetization $\\sum_{i=1}^{N}\\sigma_{i}=Nm$. Thus, for a given magnetization $m$, all microstates with that magnetization have the same energy:\n$$H_N(m) = -\\frac{J}{2N}(Nm)^2 - h(Nm) = -N\\left(\\frac{J}{2}m^2 + hm\\right)$$\nThe energy per spin, $e = H_N/N$, is therefore a deterministic function of the magnetization $m$:\n$$e(m) = -\\frac{J}{2}m^2 - hm$$\nThis relationship implies that the macroscopic variables $e$ and $m$ are not independent for this model. A configuration with magnetization $m$ necessarily has energy density $e(m)$.\n\nThe microcanonical entropy density $s(e,m)$ is defined as the leading-order exponential growth rate of the number of configurations, $\\Omega(N,e,m)$, with given energy density $e$ and magnetization $m$.\n$$s(e,m) = \\lim_{N\\to\\infty} \\frac{1}{N}\\ln \\Omega(N, e, m)$$\nDue to the constraint $e=e(m)$, the number of configurations is non-zero only on the curve defined by this relation. If $e \\neq -\\frac{J}{2}m^2 - hm$, then $\\Omega(N,e,m) = 0$, and consequently $s(e,m) = -\\infty$.\nIf $e = -\\frac{J}{2}m^2 - hm$, then the set of configurations is simply the set of all configurations with magnetization $m$. The number of such configurations is given by the binomial coefficient for arranging $N_+$ up-spins among $N$ sites:\n$$\\Omega(N, e(m), m) = \\binom{N}{N_+} = \\binom{N}{N\\frac{1+m}{2}}$$\nWe now compute the entropy density using Stirling's approximation for the logarithm of the binomial coefficient, $\\ln \\binom{N}{k} \\approx -N [p\\ln p + (1-p)\\ln(1-p)]$ for $p=k/N$ and large $N$. Setting $p = \\frac{1+m}{2}$, we get:\n$$s(m) = \\lim_{N\\to\\infty} \\frac{1}{N}\\ln\\binom{N}{N\\frac{1+m}{2}} = -\\left(\\frac{1+m}{2}\\right)\\ln\\left(\\frac{1+m}{2}\\right) - \\left(\\frac{1-m}{2}\\right)\\ln\\left(\\frac{1-m}{2}\\right)$$\nThe domain on which $s(e,m)$ is finite requires $m \\in [-1, 1]$ for the arguments of the logarithms to be non-negative and the spin counts to be valid. The entropy is zero at $m=\\pm 1$ and positive for $m\\in(-1,1)$.\nThus, the microcanonical entropy density $s(e,m)$ is given by:\n$$s(e,m) = \\begin{cases} -\\left(\\frac{1+m}{2}\\right)\\ln\\left(\\frac{1+m}{2}\\right) - \\left(\\frac{1-m}{2}\\right)\\ln\\left(\\frac{1-m}{2}\\right)  \\text{if } e = -\\frac{J}{2}m^2 - hm \\\\ -\\infty  \\text{otherwise} \\end{cases}$$\nThe domain where $s(e,m)$ is finite is the one-dimensional curve in the $(e,m)$-plane defined by $e = -\\frac{J}{2}m^2 - hm$ for $m \\in [-1, 1]$.\n\n(b) Variational expression for the canonical free-energy density $f(\\beta,h)$.\n\nThe canonical partition function at inverse temperature $\\beta$ is $Z_N(\\beta, h) = \\sum_{\\sigma} \\exp(-\\beta H_N(\\sigma))$. Since the Hamiltonian $H_N$ depends only on the magnetization $m$, we can rewrite the sum over all $2^N$ spin configurations as a sum over all possible values of magnetization, weighted by the number of configurations $\\Omega(N,m)$ for each $m$:\n$$Z_N(\\beta, h) = \\sum_{m} \\Omega(N,m) \\exp(-\\beta H_N(m))$$\nSubstituting the expressions for $\\Omega(N,m)$ (in the large $N$ limit) and $H_N(m)$:\n$$Z_N(\\beta, h) \\approx \\sum_{m} \\exp(N s(m)) \\exp\\left(-\\beta N\\left(-\\frac{J}{2}m^2 - hm\\right)\\right) = \\sum_{m} \\exp\\left(N\\left[s(m) + \\beta\\frac{J}{2}m^2 + \\beta hm\\right]\\right)$$\nIn the thermodynamic limit $N\\to\\infty$, the sum is dominated by the term with the maximum exponent. This is an application of Laplace's method. The sum can be approximated by its largest term (or an integral that is evaluated by the maximum of the integrand's exponent).\n$$\\lim_{N\\to\\infty} \\frac{1}{N}\\ln Z_N(\\beta, h) = \\max_{m \\in [-1,1]} \\left\\{ s(m) + \\beta\\frac{J}{2}m^2 + \\beta hm \\right\\}$$\nThe canonical free-energy density is defined as $f(\\beta, h) = \\lim_{N\\to\\infty} -\\frac{1}{N\\beta}\\ln Z_N(\\beta,h)$. Therefore:\n$$f(\\beta, h) = -\\frac{1}{\\beta} \\max_{m \\in [-1,1]} \\left\\{ s(m) + \\beta\\frac{J}{2}m^2 + \\beta hm \\right\\}$$\nThis can be rewritten as a minimization problem:\n$$f(\\beta, h) = \\min_{m \\in [-1,1]} \\left\\{ -\\frac{1}{\\beta}s(m) - \\frac{J}{2}m^2 - hm \\right\\}$$\nSubstituting the explicit formula for $s(m)$ from part (a), we obtain the final variational expression for the free-energy density:\n$$f(\\beta, h) = \\min_{m \\in [-1,1]} \\left\\{ \\frac{1}{\\beta}\\left[\\left(\\frac{1+m}{2}\\right)\\ln\\left(\\frac{1+m}{2}\\right) + \\left(\\frac{1-m}{2}\\right)\\ln\\left(\\frac{1-m}{2}\\right)\\right] - \\frac{J}{2}m^2 - hm \\right\\}$$\nThis expresses $f(\\beta,h)$ as the minimum value of a function of a single variational parameter $m$.\n\n(c) Analysis of curvature and determination of the critical inverse temperature $\\beta_c$.\n\nWe specialize to the case of zero external field, $h=0$. The objective function in the variational problem for $f(\\beta, 0)$ is the Ginzburg-Landau-like free energy functional:\n$$\\phi(m; \\beta) = \\frac{1}{\\beta}\\left[\\left(\\frac{1+m}{2}\\right)\\ln\\left(\\frac{1+m}{2}\\right) + \\left(\\frac{1-m}{2}\\right)\\ln\\left(\\frac{1-m}{2}\\right)\\right] - \\frac{J}{2}m^2$$\nThe problem asks for an analysis of the curvature of this objective function at $m=0$. The curvature is given by the second derivative, $\\frac{d^2\\phi}{dm^2}$. We first compute the derivatives of the entropic part. Let $g(m) = \\left(\\frac{1+m}{2}\\right)\\ln\\left(\\frac{1+m}{2}\\right) + \\left(\\frac{1-m}{2}\\right)\\ln\\left(\\frac{1-m}{2}\\right)$.\nThe first derivative with respect to $m$ is:\n$$\\frac{dg}{dm} = \\frac{1}{2}\\left[\\ln\\left(\\frac{1+m}{2}\\right)+1\\right] - \\frac{1}{2}\\left[\\ln\\left(\\frac{1-m}{2}\\right)+1\\right] = \\frac{1}{2}\\ln\\left(\\frac{1+m}{1-m}\\right) = \\text{arctanh}(m)$$\nThe second derivative is:\n$$\\frac{d^2g}{dm^2} = \\frac{d}{dm} \\text{arctanh}(m) = \\frac{1}{1-m^2}$$\nNow, we compute the second derivative of the full objective function $\\phi(m; \\beta)$:\n$$\\frac{d^2\\phi}{dm^2} = \\frac{1}{\\beta}\\frac{d^2g}{dm^2} - J = \\frac{1}{\\beta(1-m^2)} - J$$\nWe evaluate this curvature at the point $m=0$:\n$$\\frac{d^2\\phi}{dm^2}\\bigg|_{m=0} = \\frac{1}{\\beta} - J$$\nThe problem asks when the objective function $\\phi(m;\\beta)$ \"ceases to be concave\" at $m=0$. A function is locally concave at a point if its second derivative is less than or equal to zero. Thus, $\\phi(m;\\beta)$ is concave at $m=0$ if:\n$$\\frac{1}{\\beta} - J \\leq 0 \\quad \\implies \\quad 1 \\leq \\beta J \\quad \\implies \\quad \\beta \\geq \\frac{1}{J}$$\nThis corresponds to the low-temperature phase, where $m=0$ is an unstable point (a local maximum), and ferromagnetic order appears. The function \"ceases to be concave\" at $m=0$ when this condition is violated, i.e., when the curvature becomes positive. The transition occurs at the critical point where the curvature is exactly zero.\n$$\\frac{1}{\\beta_c} - J = 0$$\nSolving for the critical inverse temperature $\\beta_c$ gives:\n$$\\beta_c = \\frac{1}{J}$$\nFor $\\beta  \\beta_c$ (high temperatures), the curvature at $m=0$ is positive, making the objective function locally convex and yielding a stable paramagnetic state at $m=0$. For $\\beta  \\beta_c$ (low temperatures), the curvature is negative, the objective is locally concave, and the state at $m=0$ becomes unstable, leading to a phase transition to a ferromagnetic state with $m \\neq 0$.",
            "answer": "$$\\boxed{\\frac{1}{J}}$$"
        },
        {
            "introduction": "Ensemble inequivalence is not merely a theoretical concern for idealized models but can also manifest as a subtle artifact in practical molecular dynamics simulations. The specific algorithm used to control temperature—the thermostat—can generate a phase-space trajectory whose time-averaged properties do not exactly match the statistical averages of the target canonical ensemble, especially for finite-sized systems. This advanced derivation tasks you with analyzing the phase-space measure of Gaussian isokinetic dynamics, a deterministic thermostat, to reveal a small but systematic, size-dependent deviation from true canonical sampling .",
            "id": "3410998",
            "problem": "Consider a system of $N$ classical particles in three spatial dimensions evolving under deterministic Gaussian isokinetic dynamics, a form of Molecular Dynamics (MD) in which the instantaneous kinetic energy is constrained to remain constant. Let the positions be $\\mathbf{q} \\in \\mathbb{R}^{3N}$ and the momenta be $\\mathbf{p} \\in \\mathbb{R}^{3N}$, with masses $\\{m_i\\}_{i=1}^{3N}$ and potential energy $U(\\mathbf{q})$ giving forces $\\mathbf{F}(\\mathbf{q}) = -\\nabla_{\\mathbf{q}} U(\\mathbf{q})$. The kinetic energy is $K(\\mathbf{p}) = \\sum_{i=1}^{3N} \\frac{p_i^2}{2 m_i}$ and the constraint is enforced such that $K(\\mathbf{p}) = \\frac{3N}{2} k_B T$ for a target temperature $T$, where $k_B$ is the Boltzmann constant. The dynamics are defined by $\\dot{\\mathbf{q}} = \\mathbf{p}/\\mathbf{m}$ and $\\dot{\\mathbf{p}} = \\mathbf{F}(\\mathbf{q}) - \\alpha(\\mathbf{q},\\mathbf{p}) \\mathbf{p}$, where $\\alpha(\\mathbf{q},\\mathbf{p})$ is a scalar chosen to maintain the isokinetic constraint at all times.\n\nStarting from the phase-space continuity equation for deterministic flows, derive the invariant phase-space measure $\\rho(\\mathbf{q},\\mathbf{p})$ associated with these Gaussian isokinetic dynamics. Then, obtain the configurational marginal induced by this measure and determine the effective inverse temperature $\\beta_{\\mathrm{eff}}$ of the configurational distribution in terms of $N$, $T$, and $k_B$. Compare $\\beta_{\\mathrm{eff}}$ to the target inverse temperature $\\beta = 1/(k_B T)$ and conclude whether Gaussian isokinetic dynamics with $K(\\mathbf{p}) = \\frac{3N}{2} k_B T$ reproduces canonical configurational sampling at inverse temperature $\\beta$ for finite $N$.\n\nYour final answer must be the closed-form expression for the ratio $\\beta_{\\mathrm{eff}}/\\beta$. No numerical evaluation or rounding is required.",
            "solution": "The problem asks for the derivation of the invariant phase-space measure for a system evolving under Gaussian isokinetic dynamics and for the determination of the effective inverse temperature of the resulting configurational distribution.\n\nFirst, we validate the problem statement.\nStep 1: Extract Givens.\n- System of $N$ classical particles in three spatial dimensions.\n- Phase space coordinates: positions $\\mathbf{q} \\in \\mathbb{R}^{3N}$ and momenta $\\mathbf{p} \\in \\mathbb{R}^{3N}$.\n- Masses: $\\{m_i\\}_{i=1}^{3N}$.\n- Potential energy: $U(\\mathbf{q})$.\n- Forces: $\\mathbf{F}(\\mathbf{q}) = -\\nabla_{\\mathbf{q}} U(\\mathbf{q})$.\n- Kinetic energy: $K(\\mathbf{p}) = \\sum_{i=1}^{3N} \\frac{p_i^2}{2 m_i}$.\n- Isokinetic constraint: $K(\\mathbf{p}) = K_0 = \\frac{3N}{2} k_B T$, where $T$ is a target temperature and $k_B$ is the Boltzmann constant.\n- Equations of motion: $\\dot{\\mathbf{q}} = \\mathbf{p}/\\mathbf{m}$ (where $(\\mathbf{p}/\\mathbf{m})_i = p_i/m_i$) and $\\dot{\\mathbf{p}} = \\mathbf{F}(\\mathbf{q}) - \\alpha(\\mathbf{q},\\mathbf{p}) \\mathbf{p}$.\n- The scalar function $\\alpha(\\mathbf{q},\\mathbf{p})$ is a constraint multiplier ensuring $\\dot{K}(\\mathbf{p}) = 0$.\n\nStep 2: Validate Using Extracted Givens.\n- The problem is scientifically grounded. Gaussian isokinetics is a well-established simulation method in statistical mechanics.\n- The problem is well-posed, asking for a specific derivation with a unique outcome.\n- The problem is objective and uses precise mathematical language.\n- The problem is self-contained and provides all necessary definitions and equations. There are no contradictions.\n- The setup is a standard theoretical model in computational physics.\n- The structure is logical and leads to a meaningful solution.\n\nStep 3: Verdict and Action.\nThe problem is valid. We proceed with the solution.\n\nThe solution is constructed as follows:\n1. Determine the expression for the thermostat multiplier $\\alpha(\\mathbf{q},\\mathbf{p})$.\n2. Calculate the phase-space compressibility $\\Lambda$.\n3. Derive the invariant phase-space measure $\\rho(\\mathbf{q},\\mathbf{p})$.\n4. Obtain the marginal configurational distribution $P(\\mathbf{q})$.\n5. Identify the effective inverse temperature $\\beta_{\\mathrm{eff}}$ and compute the ratio $\\beta_{\\mathrm{eff}}/\\beta$.\n\nFirst, we find $\\alpha$ by enforcing the isokinetic constraint, $\\frac{dK}{dt} = 0$.\nThe time derivative of the kinetic energy is:\n$$ \\dot{K} = \\frac{d}{dt} \\left( \\sum_{i=1}^{3N} \\frac{p_i^2}{2 m_i} \\right) = \\sum_{i=1}^{3N} \\frac{p_i \\dot{p}_i}{m_i} $$\nUsing vector notation where component-wise division by mass is implied, this is $\\dot{K} = (\\mathbf{p}/\\mathbf{m}) \\cdot \\dot{\\mathbf{p}}$. Substituting the equation of motion for $\\dot{\\mathbf{p}}$:\n$$ \\dot{K} = (\\mathbf{p}/\\mathbf{m}) \\cdot (\\mathbf{F} - \\alpha \\mathbf{p}) = (\\mathbf{p}/\\mathbf{m}) \\cdot \\mathbf{F} - \\alpha (\\mathbf{p}/\\mathbf{m}) \\cdot \\mathbf{p} $$\nRecognizing that $(\\mathbf{p}/\\mathbf{m}) \\cdot \\mathbf{p} = \\sum_{i=1}^{3N} \\frac{p_i^2}{m_i} = 2 \\sum_{i=1}^{3N} \\frac{p_i^2}{2m_i} = 2K$, we have:\n$$ \\dot{K} = (\\mathbf{p}/\\mathbf{m}) \\cdot \\mathbf{F} - 2\\alpha K $$\nSetting $\\dot{K}=0$ and solving for $\\alpha$ gives:\n$$ \\alpha = \\frac{(\\mathbf{p}/\\mathbf{m}) \\cdot \\mathbf{F}}{2K} = \\frac{\\sum_{i=1}^{3N} p_i F_i / m_i}{2K} $$\n\nNext, we determine the phase-space compressibility, $\\Lambda = \\nabla_{\\mathbf{\\Gamma}} \\cdot \\dot{\\mathbf{\\Gamma}}$, where $\\mathbf{\\Gamma} = (\\mathbf{q}, \\mathbf{p})$ and $\\dot{\\mathbf{\\Gamma}}=(\\dot{\\mathbf{q}}, \\dot{\\mathbf{p}})$.\n$$ \\Lambda = \\nabla_{\\mathbf{q}} \\cdot \\dot{\\mathbf{q}} + \\nabla_{\\mathbf{p}} \\cdot \\dot{\\mathbf{p}} $$\nThe first term is $\\nabla_{\\mathbf{q}} \\cdot (\\mathbf{p}/\\mathbf{m}) = \\sum_{i=1}^{3N} \\frac{\\partial}{\\partial q_i} (\\frac{p_i}{m_i}) = 0$.\nThe second term is:\n$$ \\nabla_{\\mathbf{p}} \\cdot \\dot{\\mathbf{p}} = \\nabla_{\\mathbf{p}} \\cdot (\\mathbf{F} - \\alpha \\mathbf{p}) = \\nabla_{\\mathbf{p}} \\cdot \\mathbf{F} - \\nabla_{\\mathbf{p}} \\cdot (\\alpha \\mathbf{p}) $$\nSince $\\mathbf{F}$ depends only on $\\mathbf{q}$, $\\nabla_{\\mathbf{p}} \\cdot \\mathbf{F} = 0$. Thus, $\\Lambda = - \\nabla_{\\mathbf{p}} \\cdot (\\alpha \\mathbf{p})$.\nUsing the product rule for divergence: $\\nabla_{\\mathbf{p}} \\cdot (\\alpha \\mathbf{p}) = (\\nabla_{\\mathbf{p}} \\alpha) \\cdot \\mathbf{p} + \\alpha (\\nabla_{\\mathbf{p}} \\cdot \\mathbf{p})$.\nSince $\\mathbf{p} \\in \\mathbb{R}^{3N}$, $\\nabla_{\\mathbf{p}} \\cdot \\mathbf{p} = \\sum_{i=1}^{3N} \\frac{\\partial p_i}{\\partial p_i} = 3N$.\nWe need to calculate $(\\nabla_{\\mathbf{p}} \\alpha) \\cdot \\mathbf{p} = \\sum_{j=1}^{3N} p_j \\frac{\\partial \\alpha}{\\partial p_j}$.\n$$ \\frac{\\partial \\alpha}{\\partial p_j} = \\frac{\\partial}{\\partial p_j} \\left( \\frac{\\sum_k p_k F_k/m_k}{2K} \\right) = \\frac{F_j/m_j}{2K} - \\frac{\\sum_k p_k F_k/m_k}{(2K)^2} \\frac{\\partial(2K)}{\\partial p_j} $$\nSince $\\frac{\\partial(2K)}{\\partial p_j} = \\frac{\\partial}{\\partial p_j} \\sum_k \\frac{p_k^2}{m_k} = \\frac{2p_j}{m_j}$, we get:\n$$ \\frac{\\partial \\alpha}{\\partial p_j} = \\frac{F_j/m_j}{2K} - \\alpha \\frac{2p_j/m_j}{2K} = \\frac{F_j}{2Km_j} - \\frac{\\alpha p_j}{Km_j} $$\nThen, summing over $j$:\n$$ (\\nabla_{\\mathbf{p}} \\alpha) \\cdot \\mathbf{p} = \\sum_{j=1}^{3N} p_j \\left( \\frac{F_j}{2Km_j} - \\frac{\\alpha p_j}{Km_j} \\right) = \\frac{\\sum_j p_j F_j/m_j}{2K} - \\frac{\\alpha}{K} \\sum_j \\frac{p_j^2}{m_j} = \\alpha - \\frac{\\alpha}{K}(2K) = -\\alpha $$\nTherefore, $\\nabla_{\\mathbf{p}} \\cdot (\\alpha \\mathbf{p}) = -\\alpha + 3N\\alpha = (3N-1)\\alpha$.\nThe phase-space compressibility is $\\Lambda = -(3N-1)\\alpha$.\n\nThe phase-space continuity equation for a distribution $\\rho(\\mathbf{q}, \\mathbf{p}, t)$ is $\\frac{\\partial \\rho}{\\partial t} + \\nabla_{\\mathbf{\\Gamma}} \\cdot (\\rho \\dot{\\mathbf{\\Gamma}}) = 0$. For an invariant (stationary) measure, $\\frac{\\partial \\rho}{\\partial t} = 0$, so $\\nabla_{\\mathbf{\\Gamma}} \\cdot (\\rho \\dot{\\mathbf{\\Gamma}}) = 0$.\nExpanding this gives $\\dot{\\mathbf{\\Gamma}} \\cdot \\nabla_{\\mathbf{\\Gamma}} \\rho + \\rho (\\nabla_{\\mathbf{\\Gamma}} \\cdot \\dot{\\mathbf{\\Gamma}}) = 0$.\nThe first term is the total time derivative along a trajectory, so $\\frac{d\\rho}{dt} = -\\rho\\Lambda$.\nSubstituting for $\\Lambda$:\n$$ \\frac{1}{\\rho}\\frac{d\\rho}{dt} = \\frac{d}{dt} \\ln \\rho = -\\Lambda = (3N-1)\\alpha $$\nSubstitute the expression for $\\alpha$ and use $\\dot{\\mathbf{q}} = \\mathbf{p}/\\mathbf{m}$ and $\\mathbf{F} = -\\nabla_{\\mathbf{q}}U$:\n$$ \\frac{d}{dt} \\ln \\rho = (3N-1) \\frac{(\\mathbf{p}/\\mathbf{m})\\cdot \\mathbf{F}}{2K} = -(3N-1) \\frac{\\dot{\\mathbf{q}}\\cdot \\nabla_{\\mathbf{q}}U}{2K_0} $$\nwhere we have replaced the instantaneous kinetic energy $K$ with its constant value $K_0$.\nSince $\\frac{dU}{dt} = (\\nabla_{\\mathbf{q}} U) \\cdot \\dot{\\mathbf{q}}$, we have:\n$$ \\frac{d}{dt} \\ln \\rho = -\\frac{3N-1}{2K_0} \\frac{dU}{dt} $$\nIntegrating this differential equation along a trajectory yields the functional form of the invariant measure's dependence on $U(\\mathbf{q})$:\n$$ \\ln \\rho = -\\frac{3N-1}{2K_0} U(\\mathbf{q}) + C' $$\nThe full invariant phase-space measure must also incorporate the isokinetic constraint, which is done using a Dirac delta function:\n$$ \\rho(\\mathbf{q},\\mathbf{p}) = C \\delta(K(\\mathbf{p}) - K_0) \\exp\\left( -\\frac{3N-1}{2K_0} U(\\mathbf{q}) \\right) $$\nwhere $C$ is a normalization constant.\n\nTo find the configurational marginal distribution $P(\\mathbf{q})$, we integrate $\\rho(\\mathbf{q},\\mathbf{p})$ over all momenta $\\mathbf{p}$:\n$$ P(\\mathbf{q}) = \\int d^{3N}p \\, \\rho(\\mathbf{q},\\mathbf{p}) = C \\exp\\left( -\\frac{3N-1}{2K_0} U(\\mathbf{q}) \\right) \\int d^{3N}p \\, \\delta(K(\\mathbf{p}) - K_0) $$\nThe integral over the momenta is the surface area of the hypershell of constant kinetic energy $K_0$. This value is a constant, independent of the configuration $\\mathbf{q}$. Therefore, the configurational probability distribution is proportional to the exponential term:\n$$ P(\\mathbf{q}) \\propto \\exp\\left( -\\frac{3N-1}{2K_0} U(\\mathbf{q}) \\right) $$\nThe canonical configurational distribution at an inverse temperature $\\beta$ is given by $P_{\\mathrm{can}}(\\mathbf{q}) \\propto \\exp(-\\beta U(\\mathbf{q}))$. By comparing this with the distribution we derived, we can identify the effective inverse temperature $\\beta_{\\mathrm{eff}}$:\n$$ \\beta_{\\mathrm{eff}} = \\frac{3N-1}{2K_0} $$\nThe problem specifies the constraint value $K_0 = \\frac{3N}{2} k_B T$ and the target inverse temperature $\\beta = \\frac{1}{k_B T}$. Substituting for $K_0$:\n$$ \\beta_{\\mathrm{eff}} = \\frac{3N-1}{2 \\left( \\frac{3N}{2} k_B T \\right)} = \\frac{3N-1}{3N k_B T} $$\nFinally, we compute the ratio of the effective inverse temperature to the target inverse temperature:\n$$ \\frac{\\beta_{\\mathrm{eff}}}{\\beta} = \\frac{\\frac{3N-1}{3N k_B T}}{\\frac{1}{k_B T}} = \\frac{3N-1}{3N} = 1 - \\frac{1}{3N} $$\nFor any finite number of particles $N$, this ratio is less than $1$, meaning $\\beta_{\\mathrm{eff}} \\neq \\beta$. Consequently, Gaussian isokinetic dynamics with the specified kinetic energy constraint does *not* reproduce the canonical configurational distribution for a finite-sized system. Equivalence is only achieved in the thermodynamic limit, where $N \\rightarrow \\infty$ and $\\frac{\\beta_{\\mathrm{eff}}}{\\beta} \\rightarrow 1$.",
            "answer": "$$\n\\boxed{1 - \\frac{1}{3N}}\n$$"
        }
    ]
}