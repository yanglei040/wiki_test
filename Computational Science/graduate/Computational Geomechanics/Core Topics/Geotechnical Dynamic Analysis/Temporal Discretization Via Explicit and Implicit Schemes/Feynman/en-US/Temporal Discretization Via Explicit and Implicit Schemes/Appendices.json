{
    "hands_on_practices": [
        {
            "introduction": "A fundamental measure of a time integration scheme's performance is its order of accuracy, which quantifies how the error decreases as the time step is refined. This exercise lays the theoretical groundwork by guiding you through the derivation of the local truncation error for two canonical schemes: the explicit Central Difference method and the implicit Newmark average acceleration method . By applying Taylor series analysis to the simple linear oscillator, you will confirm that both schemes are second-order accurate, raising the crucial question of what other properties distinguish their practical behavior.",
            "id": "3566460",
            "problem": "Consider the undamped single-degree-of-freedom linear oscillator that models, for example, the fundamental mode of a lumped soil mass-spring idealization in computational geomechanics. The governing equation derived from Newton’s second law is\n$$\nm\\,\\ddot{u}(t) + k\\,u(t) = 0,\\quad m>0,\\ k>0,\n$$\nwhere $u(t)$ is the generalized displacement. Define the circular natural frequency by $\\omega^{2} = k/m$ and write the equation in the normalized form\n$$\n\\ddot{u}(t) + \\omega^{2}\\,u(t) = 0.\n$$\nLet $t_{n} = t_{0} + n\\,\\Delta t$ with constant time step $\\Delta t>0$, and set $u_{n} = u(t_{n})$, $v_{n} = \\dot{u}(t_{n})$, $a_{n} = \\ddot{u}(t_{n})$.\n\nTask A (Central Difference (CD) method, explicit). The CD method for the oscillator can be written as\n$$\n\\frac{u_{n+1} - 2\\,u_{n} + u_{n-1}}{\\Delta t^{2}} + \\omega^{2}\\,u_{n} = 0.\n$$\nDefine the local truncation error at $t_{n}$ as the defect\n$$\n\\tau^{\\mathrm{CD}}_{n} := \\frac{u(t_{n+1}) - 2\\,u(t_{n}) + u(t_{n-1})}{\\Delta t^{2}} + \\omega^{2}\\,u(t_{n}),\n$$\nobtained by inserting the exact solution $u(t)$ into the scheme. Using only fundamental Taylor expansions about $t_{n}$ and the governing differential equation, derive the leading nonzero term of $\\tau^{\\mathrm{CD}}_{n}$ in powers of $\\Delta t$.\n\nTask B (Newmark’s average acceleration (AA) scheme, implicit). Newmark’s AA scheme is defined by the pair of update formulas with average acceleration parameters $\\beta = 1/4$ and $\\gamma = 1/2$:\n$$\nu_{n+1} = u_{n} + \\Delta t\\,v_{n} + \\frac{\\Delta t^{2}}{4}\\,\\big(a_{n} + a_{n+1}\\big),\\qquad\nv_{n+1} = v_{n} + \\frac{\\Delta t}{2}\\,\\big(a_{n} + a_{n+1}\\big),\n$$\ntogether with the linear oscillator relation $a_{n} = -\\omega^{2}\\,u_{n}$ and $a_{n+1} = -\\omega^{2}\\,u_{n+1}$. Define the local truncation error at $t_{n}$ as the pair of defects obtained by inserting the exact solution values into these updates:\n$$\n\\tau^{\\mathrm{N}}_{u,n} := u(t_{n+1}) - u(t_{n}) - \\Delta t\\,v(t_{n}) - \\frac{\\Delta t^{2}}{4}\\,\\big(a(t_{n}) + a(t_{n+1})\\big),\n$$\n$$\n\\tau^{\\mathrm{N}}_{v,n} := v(t_{n+1}) - v(t_{n}) - \\frac{\\Delta t}{2}\\,\\big(a(t_{n}) + a(t_{n+1})\\big).\n$$\nUsing only fundamental Taylor expansions about $t_{n}$ and the governing differential equation, derive the leading nonzero terms of $\\tau^{\\mathrm{N}}_{u,n}$ and $\\tau^{\\mathrm{N}}_{v,n}$ in powers of $\\Delta t$.\n\nTask C (Global orders of accuracy). Using the consistency orders revealed by the local truncation errors and the known zero-stability of both schemes for the linear oscillator, conclude the global orders of accuracy in $u(t)$ for the CD method and for Newmark’s AA scheme. Express the final answer as a row matrix containing the two global orders of accuracy for displacement, in the order [CD, Newmark AA]. No units are required for the final answer. If you need to state any numerical constants during derivations, keep them in exact rational form. The final answer must be a single row matrix of two integers.",
            "solution": "The problem is subjected to validation prior to any attempt at a solution.\n\n### Step 1: Extract Givens\n-   **Governing Equation**: $m\\,\\ddot{u}(t) + k\\,u(t) = 0$, with mass $m>0$ and stiffness $k>0$.\n-   **Normalized Form**: $\\ddot{u}(t) + \\omega^{2}\\,u(t) = 0$, where the circular natural frequency is $\\omega = \\sqrt{k/m}$.\n-   **Time Discretization**: $t_{n} = t_{0} + n\\,\\Delta t$ with a constant time step $\\Delta t>0$.\n-   **Discrete Variables**: $u_{n} = u(t_{n})$, $v_{n} = \\dot{u}(t_{n})$, $a_{n} = \\ddot{u}(t_{n})$.\n-   **Task A: Central Difference (CD) Method**:\n    -   Scheme: $\\frac{u_{n+1} - 2\\,u_{n} + u_{n-1}}{\\Delta t^{2}} + \\omega^{2}\\,u_{n} = 0$.\n    -   Local Truncation Error (LTE): $\\tau^{\\mathrm{CD}}_{n} := \\frac{u(t_{n+1}) - 2\\,u(t_{n}) + u(t_{n-1})}{\\Delta t^{2}} + \\omega^{2}\\,u(t_{n})$.\n    -   Objective: Derive the leading nonzero term of $\\tau^{\\mathrm{CD}}_{n}$.\n-   **Task B: Newmark’s Average Acceleration (AA) Scheme**:\n    -   Parameters: $\\beta = 1/4$, $\\gamma = 1/2$.\n    -   Update formulas:\n        $u_{n+1} = u_{n} + \\Delta t\\,v_{n} + \\frac{\\Delta t^{2}}{4}\\,\\big(a_{n} + a_{n+1}\\big)$\n        $v_{n+1} = v_{n} + \\frac{\\Delta t}{2}\\,\\big(a_{n} + a_{n+1}\\big)$\n    -   Enforcement of governing equation: $a_{n} = -\\omega^{2}\\,u_{n}$ and $a_{n+1} = -\\omega^{2}\\,u_{n+1}$.\n    -   Local Truncation Errors (LTEs):\n        $\\tau^{\\mathrm{N}}_{u,n} := u(t_{n+1}) - u(t_{n}) - \\Delta t\\,v(t_{n}) - \\frac{\\Delta t^{2}}{4}\\,\\big(a(t_{n}) + a(t_{n+1})\\big)$\n        $\\tau^{\\mathrm{N}}_{v,n} := v(t_{n+1}) - v(t_{n}) - \\frac{\\Delta t}{2}\\,\\big(a(t_{n}) + a(t_{n+1})\\big)$\n    -   Objective: Derive the leading nonzero terms of $\\tau^{\\mathrm{N}}_{u,n}$ and $\\tau^{\\mathrm{N}}_{v,n}$.\n-   **Task C: Global Orders of Accuracy**:\n    -   Premise: Both schemes are known to be zero-stable.\n    -   Objective: Using the consistency orders from Tasks A and B, determine the global orders of accuracy for the displacement $u(t)$ for both the CD method and the Newmark AA scheme.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-defined and scientifically sound.\n-   **Scientifically Grounded**: The problem addresses the analysis of standard, widely used time integration schemes (Central Difference and Newmark) for the linear oscillator, a fundamental model in physics and engineering. The methods and concepts are cornerstones of computational dynamics.\n-   **Well-Posed**: The tasks are specific and mathematical, requiring derivations based on Taylor series expansions and interpretation of standard numerical analysis theory. The problem has a unique and meaningful solution.\n-   **Objective**: The problem is stated in precise mathematical language, free from ambiguity or subjective content.\n-   **Complete and Consistent**: All necessary equations, definitions, and conditions are provided. There are no internal contradictions.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution Derivations\n\nThe solution requires evaluating the local truncation errors (LTEs) by substituting the exact solution $u(t)$ of the governing differential equation, $\\ddot{u}(t) + \\omega^2 u(t) = 0$, into the numerical schemes. The derivatives of the exact solution are related by: $\\ddot{u}(t) = -\\omega^2 u(t)$, $\\dddot{u}(t) = -\\omega^2 \\dot{u}(t)$, $u^{(4)}(t) = -\\omega^2 \\ddot{u}(t) = \\omega^4 u(t)$, and so on.\n\n**Task A: Local Truncation Error of the Central Difference (CD) Method**\n\nThe LTE for the CD method is given by:\n$$\n\\tau^{\\mathrm{CD}}_{n} = \\frac{u(t_{n+1}) - 2\\,u(t_{n}) + u(t_{n-1})}{\\Delta t^{2}} + \\omega^{2}\\,u(t_{n})\n$$\nWe perform Taylor series expansions of $u(t_{n+1})$ and $u(t_{n-1})$ about the time $t_{n}$. For brevity, let $u_{n} = u(t_{n})$, $\\dot{u}_{n} = \\dot{u}(t_{n})$, etc.\n$$\nu(t_{n+1}) = u_{n} + \\Delta t\\,\\dot{u}_{n} + \\frac{\\Delta t^2}{2!}\\,\\ddot{u}_{n} + \\frac{\\Delta t^3}{3!}\\,\\dddot{u}_{n} + \\frac{\\Delta t^4}{4!}\\,u^{(4)}_{n} + O(\\Delta t^5)\n$$\n$$\nu(t_{n-1}) = u_{n} - \\Delta t\\,\\dot{u}_{n} + \\frac{\\Delta t^2}{2!}\\,\\ddot{u}_{n} - \\frac{\\Delta t^3}{3!}\\,\\dddot{u}_{n} + \\frac{\\Delta t^4}{4!}\\,u^{(4)}_{n} - O(\\Delta t^5)\n$$\nSubstituting these into the numerator of the first term of $\\tau^{\\mathrm{CD}}_{n}$:\n$$\nu(t_{n+1}) - 2\\,u_{n} + u(t_{n-1}) = \\left(2\\,\\frac{\\Delta t^2}{2!}\\,\\ddot{u}_{n}\\right) + \\left(2\\,\\frac{\\Delta t^4}{4!}\\,u^{(4)}_{n}\\right) + O(\\Delta t^6)\n$$\n$$\nu(t_{n+1}) - 2\\,u_{n} + u(t_{n-1}) = \\Delta t^2\\,\\ddot{u}_{n} + \\frac{\\Delta t^4}{12}\\,u^{(4)}_{n} + O(\\Delta t^6)\n$$\nNow, substitute this back into the expression for $\\tau^{\\mathrm{CD}}_{n}$:\n$$\n\\tau^{\\mathrm{CD}}_{n} = \\frac{\\Delta t^2\\,\\ddot{u}_{n} + \\frac{\\Delta t^4}{12}\\,u^{(4)}_{n} + O(\\Delta t^6)}{\\Delta t^2} + \\omega^{2}\\,u_{n}\n$$\n$$\n\\tau^{\\mathrm{CD}}_{n} = \\left(\\ddot{u}_{n} + \\frac{\\Delta t^2}{12}\\,u^{(4)}_{n} + O(\\Delta t^4)\\right) + \\omega^{2}\\,u_{n}\n$$\nRearranging the terms to group the governing equation:\n$$\n\\tau^{\\mathrm{CD}}_{n} = \\big(\\ddot{u}_{n} + \\omega^{2}\\,u_{n}\\big) + \\frac{\\Delta t^2}{12}\\,u^{(4)}_{n} + O(\\Delta t^4)\n$$\nSince $u(t)$ is the exact solution, $\\ddot{u}_{n} + \\omega^2 u_{n} = 0$. Thus, the expression simplifies to:\n$$\n\\tau^{\\mathrm{CD}}_{n} = \\frac{\\Delta t^2}{12}\\,u^{(4)}_{n} + O(\\Delta t^4)\n$$\nThe leading nonzero term of the local truncation error is $\\frac{\\Delta t^2}{12}\\,u^{(4)}(t_{n})$.\n\n**Task B: Local Truncation Errors of the Newmark AA Scheme**\n\nWe derive the LTEs for the displacement and velocity updates separately.\n\nFor the displacement update, the LTE is:\n$$\n\\tau^{\\mathrm{N}}_{u,n} = u(t_{n+1}) - u(t_{n}) - \\Delta t\\,v(t_{n}) - \\frac{\\Delta t^{2}}{4}\\,\\big(a(t_{n}) + a(t_{n+1})\\big)\n$$\nWe use Taylor expansions for $u(t_{n+1})$ and $a(t_{n+1})$ about $t_{n}$. We recall that $v_n=\\dot{u}_n$, $a_n=\\ddot{u}_n$, $\\dot{a}_n=\\dddot{u}_n$.\n$$\nu(t_{n+1}) = u_{n} + \\Delta t\\,\\dot{u}_{n} + \\frac{\\Delta t^2}{2}\\,\\ddot{u}_{n} + \\frac{\\Delta t^3}{6}\\,\\dddot{u}_{n} + O(\\Delta t^4)\n$$\n$$\na(t_{n+1}) = a_{n} + \\Delta t\\,\\dot{a}_{n} + O(\\Delta t^2)\n$$\nSubstituting these into the expression for $\\tau^{\\mathrm{N}}_{u,n}$:\n$$\n\\tau^{\\mathrm{N}}_{u,n} = \\left(u_{n} + \\Delta t\\,\\dot{u}_{n} + \\frac{\\Delta t^2}{2}\\,\\ddot{u}_{n} + \\frac{\\Delta t^3}{6}\\,\\dddot{u}_{n} + \\dots\\right) - u_{n} - \\Delta t\\,\\dot{u}_{n} - \\frac{\\Delta t^2}{4}\\,\\big(a_{n} + (a_{n} + \\Delta t\\,\\dot{a}_{n} + \\dots)\\big)\n$$\nRecognizing that $\\dot{u}_n=v_n$ and $\\ddot{u}_n=a_n$, we simplify:\n$$\n\\tau^{\\mathrm{N}}_{u,n} = \\left(\\frac{\\Delta t^2}{2}\\,a_{n} + \\frac{\\Delta t^3}{6}\\,\\dot{a}_{n} + \\dots\\right) - \\frac{\\Delta t^2}{4}\\,\\big(2\\,a_{n} + \\Delta t\\,\\dot{a}_{n} + \\dots\\big)\n$$\n$$\n\\tau^{\\mathrm{N}}_{u,n} = \\left(\\frac{\\Delta t^2}{2}\\,a_{n} + \\frac{\\Delta t^3}{6}\\,\\dot{a}_{n}\\right) - \\left(\\frac{\\Delta t^2}{2}\\,a_{n} + \\frac{\\Delta t^3}{4}\\,\\dot{a}_{n}\\right) + O(\\Delta t^4)\n$$\n$$\n\\tau^{\\mathrm{N}}_{u,n} = \\left(\\frac{1}{6} - \\frac{1}{4}\\right)\\Delta t^3\\,\\dot{a}_{n} + O(\\Delta t^4) = -\\frac{1}{12}\\,\\dot{a}_{n}\\,\\Delta t^3 + O(\\Delta t^4)\n$$\nThe leading term is $-\\frac{1}{12}\\,\\dddot{u}(t_{n})\\,\\Delta t^3$.\n\nFor the velocity update, the LTE is:\n$$\n\\tau^{\\mathrm{N}}_{v,n} = v(t_{n+1}) - v(t_{n}) - \\frac{\\Delta t}{2}\\,\\big(a(t_{n}) + a(t_{n+1})\\big)\n$$\nWe use Taylor expansions for $v(t_{n+1})$ and $a(t_{n+1})$ about $t_n$. We recall $\\dot{v}_n=a_n$, $\\ddot{v}_n=\\dot{a}_n$, $\\dddot{v}_n=\\ddot{a}_n$.\n$$\nv(t_{n+1}) = v_{n} + \\Delta t\\,\\dot{v}_{n} + \\frac{\\Delta t^2}{2}\\,\\ddot{v}_{n} + \\frac{\\Delta t^3}{6}\\,\\dddot{v}_{n} + O(\\Delta t^4)\n$$\n$$\na(t_{n+1}) = a_{n} + \\Delta t\\,\\dot{a}_{n} + \\frac{\\Delta t^2}{2}\\,\\ddot{a}_{n} + O(\\Delta t^3)\n$$\nSubstituting these into the expression for $\\tau^{\\mathrm{N}}_{v,n}$:\n$$\n\\tau^{\\mathrm{N}}_{v,n} = \\left(v_{n} + \\Delta t a_{n} + \\frac{\\Delta t^2}{2}\\,\\dot{a}_{n} + \\frac{\\Delta t^3}{6}\\,\\ddot{a}_{n} + \\dots\\right) - v_{n} - \\frac{\\Delta t}{2}\\,\\big(a_{n} + (a_{n} + \\Delta t\\,\\dot{a}_{n} + \\frac{\\Delta t^2}{2}\\,\\ddot{a}_{n} + \\dots)\\big)\n$$\n$$\n\\tau^{\\mathrm{N}}_{v,n} = \\left(\\Delta t a_{n} + \\frac{\\Delta t^2}{2}\\,\\dot{a}_{n} + \\frac{\\Delta t^3}{6}\\,\\ddot{a}_{n}\\right) - \\frac{\\Delta t}{2}\\,\\big(2\\,a_{n} + \\Delta t\\,\\dot{a}_{n} + \\frac{\\Delta t^2}{2}\\,\\ddot{a}_{n}\\big) + O(\\Delta t^4)\n$$\n$$\n\\tau^{\\mathrm{N}}_{v,n} = \\left(\\Delta t a_{n} + \\frac{\\Delta t^2}{2}\\,\\dot{a}_{n} + \\frac{\\Delta t^3}{6}\\,\\ddot{a}_{n}\\right) - \\left(\\Delta t a_{n} + \\frac{\\Delta t^2}{2}\\,\\dot{a}_{n} + \\frac{\\Delta t^3}{4}\\,\\ddot{a}_{n}\\right) + O(\\Delta t^4)\n$$\n$$\n\\tau^{\\mathrm{N}}_{v,n} = \\left(\\frac{1}{6} - \\frac{1}{4}\\right)\\Delta t^3\\,\\ddot{a}_{n} + O(\\Delta t^4) = -\\frac{1}{12}\\,\\ddot{a}_{n}\\,\\Delta t^3 + O(\\Delta t^4)\n$$\nThe leading term is $-\\frac{1}{12}\\,u^{(4)}(t_{n})\\,\\Delta t^3$.\n\n**Task C: Global Orders of Accuracy**\n\nThe global order of accuracy of a numerical method is its order of convergence. For a zero-stable method, the order of convergence is equal to its order of consistency. The problem states both schemes are zero-stable.\n\nFor the Central Difference method, the LTE is defined as the residual when the exact solution is substituted into the discretized differential equation: $\\tau^{\\mathrm{CD}}_n = O(\\Delta t^p)$ implies a consistency order of $p$. From Task A, we found $\\tau^{\\mathrm{CD}}_n = O(\\Delta t^2)$. Thus, the consistency order is $p=2$. The global order of accuracy for the CD method is therefore $2$.\n\nFor the Newmark AA method, a one-step scheme for the state vector $[u, v]^T$, the LTEs $\\tau^{\\mathrm{N}}_{u,n}$ and $\\tau^{\\mathrm{N}}_{v,n}$ represent the error accumulated in a single step (the one-step error). A one-step method is said to be consistent of order $p$ if its one-step error is of order $O(\\Delta t^{p+1})$. From Task B, the LTEs for both displacement and velocity are $O(\\Delta t^3)$. This means $p+1=3$, which implies a consistency order of $p=2$. The global order of accuracy for the Newmark AA scheme is therefore $2$.\n\nBoth methods exhibit a global order of accuracy of $2$ for the displacement $u(t)$. The final answer is a row matrix containing these two orders.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 & 2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Beyond the stability analysis for oscillatory systems, many geomechanical problems like consolidation are governed by diffusion equations, where physical plausibility is paramount. This exercise explores the discrete maximum principle (DMP), a crucial condition ensuring that solutions like pore pressure remain within physical bounds . You will analyze the versatile $\\theta$-scheme and discover how the popular, second-order accurate Crank-Nicolson method can produce non-physical oscillations, and how this can be remedied by introducing numerical dissipation through the choice of $\\theta$.",
            "id": "3566448",
            "problem": "Consider transient pore pressure diffusion in a saturated porous medium governed, under small-strain assumptions and negligible volumetric strain rate of the skeleton, by mass conservation and Darcy’s law. Denote the pore pressure by $p(\\mathbf{x},t)$, the specific storage (per unit volume) by $M>0$, and the hydraulic conductivity tensor by $\\mathbf{k}$ with fluid dynamic viscosity $\\mu$. In the absence of sources and with homogeneous Dirichlet boundary conditions, the strong form reduces to a parabolic diffusion equation of the form $M\\,\\partial p/\\partial t - \\nabla\\cdot\\left( \\mathbf{k}/\\mu \\,\\nabla p \\right)=0$. A standard Finite Element (FE) semi-discretization in space with mass lumping yields a system of ordinary differential equations\n$$\n\\mathbf{C}\\,\\dot{\\mathbf{p}}(t)+\\mathbf{K}\\,\\mathbf{p}(t)=\\mathbf{0},\n$$\nwhere $\\mathbf{p}(t)$ collects the nodal values of $p$, the capacity matrix $\\mathbf{C}$ is diagonal with positive entries $c_i\\propto M$, and the diffusion stiffness matrix $\\mathbf{K}$ is symmetric positive definite with strictly positive diagonal entries $k_{ii}>0$ and nonpositive off-diagonal entries $k_{ij}\\le 0$ for $i\\neq j$ (an $\\mathrm{M}$-matrix structure induced by standard diffusion discretizations on shape-regular meshes).\n\nTime discretize this system by the one-parameter $\\theta$-scheme (with $0\\le \\theta \\le 1$), which is implicit for $\\theta>0.5$ and explicit for $\\theta=0$. The discrete maximum principle (DMP) for pore pressure requires that, given nonnegative boundary data and a nonnegative state $\\mathbf{p}^n\\ge \\mathbf{0}$ at time level $t^n$, the update to $\\mathbf{p}^{n+1}$ at time $t^{n+1}=t^n+\\Delta t$ should not produce negative nodal values (no nonphysical undershoots) when the source term is zero.\n\nWhich of the following statements about the $\\theta$-scheme, the Crank–Nicolson scheme (Crank–Nicolson (CN) corresponds to $\\theta=0.5$), low storage $M$ (hence small $c_i$), and the occurrence of nonphysical undershoots are correct? Select all that apply.\n\nA. For $\\theta=0.5$, if there exists an index $i$ such that $\\Delta t > 2\\,c_i/k_{ii}$, the coefficient associated with the $i$-th diagonal of the right-hand side of the $\\theta$-scheme update becomes negative, which can break monotonicity and lead to nonphysical undershoots; choosing $\\theta\\in(0.5,1]$ increases numerical damping and enlarges the allowable $\\Delta t$, with $\\theta=1$ yielding unconditional monotonicity of the update.\n\nB. Because Crank–Nicolson is second-order accurate and $\\mathbf{K}$ is symmetric positive definite, CN always satisfies the discrete maximum principle for any $\\Delta t>0$ and any storage $M>0$.\n\nC. For low storage $M$ and large $\\Delta t$, selecting $\\theta<0.5$ is more robust than backward Euler ($\\theta=1$) and prevents undershoots due to its added numerical damping relative to CN.\n\nD. A sufficient condition to avoid undershoots with the $\\theta$-scheme in the zero-source case is that $c_i\\ge (1-\\theta)\\,\\Delta t\\,k_{ii}$ for all $i$, which may be violated by CN at small $M$ and large $\\Delta t$; increasing $\\theta$ above $0.5$ weakens this restriction, and for $\\theta=1$ the condition holds trivially.\n\nE. The appearance of undershoots with CN at low $M$ is entirely due to the spatial discretization and is unaffected by the choice of time discretization parameter $\\theta$.",
            "solution": "The user wants a critical validation of the problem statement, followed by a detailed solution and evaluation of the provided options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Governing Equation (strong form):** Transient pore pressure diffusion in a saturated porous medium is governed by $M\\,\\partial p/\\partial t - \\nabla\\cdot\\left( \\mathbf{k}/\\mu \\,\\nabla p \\right)=0$.\n- **Variables and Parameters:**\n    - Pore pressure: $p(\\mathbf{x},t)$.\n    - Specific storage: $M>0$.\n    - Hydraulic conductivity tensor: $\\mathbf{k}$.\n    - Fluid dynamic viscosity: $\\mu$.\n- **Boundary Conditions:** Homogeneous Dirichlet boundary conditions.\n- **Source Term:** Absent (zero).\n- **Semi-discretized System (FE):** $\\mathbf{C}\\,\\dot{\\mathbf{p}}(t)+\\mathbf{K}\\,\\mathbf{p}(t)=\\mathbf{0}$.\n- **Properties of Matrices:**\n    - $\\mathbf{p}(t)$: Vector of nodal values of $p$.\n    - $\\mathbf{C}$: Capacity matrix, diagonal with positive entries $c_i>0$ (proportional to $M$, $c_i \\propto M$).\n    - $\\mathbf{K}$: Diffusion stiffness matrix, symmetric positive definite (SPD), with strictly positive diagonal entries $k_{ii}>0$ and nonpositive off-diagonal entries $k_{ij}\\le 0$ for $i\\neq j$. This defines $\\mathbf{K}$ as an M-matrix.\n- **Time Discretization Scheme:** The one-parameter $\\theta$-scheme, with $0\\le \\theta \\le 1$.\n- **Discrete Maximum Principle (DMP):** Given nonnegative boundary data and a nonnegative state $\\mathbf{p}^n\\ge \\mathbf{0}$ at time $t^n$, the update $\\mathbf{p}^{n+1}$ should not produce negative nodal values, i.e., $\\mathbf{p}^{n+1} \\ge \\mathbf{0}$.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientifically Grounded:** The problem describes a standard consolidation/diffusion problem in geomechanics or porous media flow, governed by a parabolic partial differential equation. The semi-discretization into a system of ODEs and the subsequent time integration using the $\\theta$-scheme are standard, canonical procedures in computational mechanics and numerical analysis. The properties of the matrices $\\mathbf{C}$ (lumped mass) and $\\mathbf{K}$ (stiffness from a standard FE discretization of the Laplacian operator) are correct. The problem is fundamentally sound.\n2.  **Well-Posed:** The problem of analyzing the properties of a numerical scheme applied to a well-posed physical problem is itself a well-posed mathematical question.\n3.  **Objective:** The language is precise, quantitative, and free of subjective claims. The definitions (e.g., DMP) are clearly stated.\n4.  **Incomplete or Contradictory Setup:** The setup is self-contained and provides all necessary information to analyze the numerical scheme. There are no contradictions.\n5.  **Ill-Posed or Poorly Structured:** The question asks for an analysis of the conditions under which the $\\theta$-scheme satisfies the DMP, which has a definite mathematical answer based on the provided information.\n6.  **Trivial/Tautological:** The problem requires a non-trivial analysis of matrix properties and numerical stability, which is a core topic in numerical PDEs. It is not trivial.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is valid. It is scientifically sound, well-posed, objective, and self-contained. I will proceed with the solution.\n\n### Solution Derivation\n\nThe semi-discretized system of ordinary differential equations is given by:\n$$\n\\mathbf{C}\\,\\dot{\\mathbf{p}}(t)+\\mathbf{K}\\,\\mathbf{p}(t)=\\mathbf{0}\n$$\nApplying the $\\theta$-scheme for time discretization, we approximate the time derivative as $\\dot{\\mathbf{p}}(t) \\approx (\\mathbf{p}^{n+1} - \\mathbf{p}^n)/\\Delta t$ and evaluate the remaining term as a weighted average at time levels $t^n$ and $t^{n+1}$.\n$$\n\\mathbf{C}\\left(\\frac{\\mathbf{p}^{n+1} - \\mathbf{p}^n}{\\Delta t}\\right) + \\mathbf{K}\\left(\\theta\\,\\mathbf{p}^{n+1} + (1-\\theta)\\,\\mathbf{p}^n\\right) = \\mathbf{0}\n$$\nwhere $\\mathbf{p}^n$ is the nodal pressure vector at time $t^n$ and $\\mathbf{p}^{n+1}$ is the vector at $t^{n+1} = t^n + \\Delta t$. To find the update rule for $\\mathbf{p}^{n+1}$, we rearrange the equation to group terms with $\\mathbf{p}^{n+1}$ on the left-hand side and terms with $\\mathbf{p}^n$ on the right-hand side.\n$$\n\\left(\\frac{1}{\\Delta t}\\mathbf{C} + \\theta\\,\\mathbf{K}\\right)\\mathbf{p}^{n+1} = \\left(\\frac{1}{\\Delta t}\\mathbf{C} - (1-\\theta)\\,\\mathbf{K}\\right)\\mathbf{p}^n\n$$\nLet us define the matrices $\\mathbf{A} = \\frac{1}{\\Delta t}\\mathbf{C} + \\theta\\,\\mathbf{K}$ and $\\mathbf{B} = \\frac{1}{\\Delta t}\\mathbf{C} - (1-\\theta)\\,\\mathbf{K}$. The update scheme is then:\n$$\n\\mathbf{p}^{n+1} = \\mathbf{A}^{-1}\\mathbf{B}\\,\\mathbf{p}^n\n$$\nThe discrete maximum principle (DMP) requires that if $\\mathbf{p}^n \\ge \\mathbf{0}$ (meaning all components are non-negative), then $\\mathbf{p}^{n+1} \\ge \\mathbf{0}$. A sufficient condition for this to hold for any non-negative $\\mathbf{p}^n$ is that the update matrix $\\mathbf{G} = \\mathbf{A}^{-1}\\mathbf{B}$ is a non-negative matrix (i.e., all its entries $g_{ij}$ are non-negative).\n\nLet's analyze the properties of $\\mathbf{A}$ and $\\mathbf{B}$.\n1.  **Matrix $\\mathbf{A} = \\frac{1}{\\Delta t}\\mathbf{C} + \\theta\\,\\mathbf{K}$:**\n    - $\\mathbf{C}$ is a diagonal matrix with entries $c_i > 0$. So $\\frac{1}{\\Delta t}\\mathbf{C}$ is also a diagonal matrix with positive diagonal entries.\n    - $\\mathbf{K}$ is given as an M-matrix (SPD, $k_{ii}>0$, $k_{ij} \\le 0$ for $i \\ne j$).\n    - Since $\\theta \\ge 0$, $\\theta\\mathbf{K}$ has non-positive off-diagonal entries.\n    - The off-diagonal entries of $\\mathbf{A}$ are $a_{ij} = \\theta\\,k_{ij} \\le 0$ for $i \\neq j$.\n    - The diagonal entries of $\\mathbf{A}$ are $a_{ii} = \\frac{c_i}{\\Delta t} + \\theta\\,k_{ii} > 0$.\n    - Since $\\mathbf{K}$ is symmetric positive definite and $\\mathbf{C}$ is positive definite (as it's a diagonal matrix with positive entries), for $\\theta \\ge 0$, $\\mathbf{A}$ is a sum of a positive definite matrix and a positive semi-definite matrix, making $\\mathbf{A}$ positive definite. A positive definite matrix with non-positive off-diagonal entries is a non-singular M-matrix. A key property of non-singular M-matrices is that their inverse is non-negative, i.e., $\\mathbf{A}^{-1} \\ge \\mathbf{0}$.\n\n2.  **Matrix $\\mathbf{B} = \\frac{1}{\\Delta t}\\mathbf{C} - (1-\\theta)\\,\\mathbf{K}$:**\n    - Since $\\mathbf{A}^{-1}$ is a non-negative matrix, for the product $\\mathbf{G} = \\mathbf{A}^{-1}\\mathbf{B}$ to be non-negative, it is sufficient that $\\mathbf{B}$ is also a non-negative matrix.\n    - Let's check the entries of $\\mathbf{B}$.\n    - The off-diagonal entries are $b_{ij} = -(1-\\theta)k_{ij}$ for $i \\neq j$. Since $0 \\le \\theta \\le 1$, we have $1-\\theta \\ge 0$. As $k_{ij} \\le 0$, the product $b_{ij} = -(1-\\theta)k_{ij} \\ge 0$. So all off-diagonal entries are non-negative.\n    - The diagonal entries are $b_{ii} = \\frac{c_i}{\\Delta t} - (1-\\theta)k_{ii}$. For $\\mathbf{B}$ to be a non-negative matrix, we require $b_{ii} \\ge 0$ for all $i$.\n    $$\n    \\frac{c_i}{\\Delta t} - (1-\\theta)k_{ii} \\ge 0 \\quad \\implies \\quad c_i \\ge (1-\\theta)\\Delta t \\, k_{ii}\n    $$\nThis inequality is the sufficient condition for the $\\theta$-scheme to satisfy the DMP. Let's analyze this condition for specific values of $\\theta$.\n\n- **Crank–Nicolson (CN) scheme ($\\theta = 0.5$):** The condition becomes $c_i \\ge (1-0.5)\\Delta t\\,k_{ii}$, which simplifies to $c_i \\ge 0.5\\,\\Delta t\\,k_{ii}$ or $\\Delta t \\le \\frac{2\\,c_i}{k_{ii}}$. This is a conditional stability requirement. DMP is not guaranteed for any choice of $\\Delta t$.\n- **Backward Euler scheme ($\\theta = 1$):** The condition is $c_i \\ge (1-1)\\Delta t\\,k_{ii}$, which simplifies to $c_i \\ge 0$. Since we are given that $c_i > 0$, this condition is always satisfied for any $\\Delta t > 0$. The backward Euler scheme is therefore unconditionally monotonic (satisfies DMP).\n\n### Option-by-Option Analysis\n\n**A. For $\\theta=0.5$, if there exists an index $i$ such that $\\Delta t > 2\\,c_i/k_{ii}$, the coefficient associated with the $i$-th diagonal of the right-hand side of the $\\theta$-scheme update becomes negative, which can break monotonicity and lead to nonphysical undershoots; choosing $\\theta\\in(0.5,1]$ increases numerical damping and enlarges the allowable $\\Delta t$, with $\\theta=1$ yielding unconditional monotonicity of the update.**\n- The \"right-hand side of the $\\theta$-scheme update\" refers to the matrix $\\mathbf{B} = (\\frac{1}{\\Delta t}\\mathbf{C} - (1-\\theta)\\mathbf{K})$. For $\\theta=0.5$, its $i$-th diagonal entry is $b_{ii} = c_i/\\Delta t - 0.5\\,k_{ii}$. If $\\Delta t > 2\\,c_i/k_{ii}$, then $0.5\\,\\Delta t\\,k_{ii} > c_i$, which implies $c_i/\\Delta t - 0.5\\,k_{ii} < 0$. So, $b_{ii}$ becomes negative. A negative entry in $\\mathbf{B}$ can lead to a negative entry in $\\mathbf{p}^{n+1}$, violating the DMP. This part is correct.\n- The condition for monotonicity is $\\Delta t \\le \\frac{c_i}{(1-\\theta)k_{ii}}$. As $\\theta$ increases from $0.5$ to $1$, the denominator $(1-\\theta)$ decreases, so the upper bound on $\\Delta t$ increases, thus \"enlarging the allowable $\\Delta t$\". This is correct.\n- Schemes with $\\theta > 0.5$ are known to be more dissipative (possess more numerical damping) than the non-dissipative Crank-Nicolson scheme ($\\theta=0.5$). This is a standard result in numerical analysis.\n- For $\\theta=1$, as shown above, the condition is always met, so the scheme is unconditionally monotonic. This is correct.\n- **Verdict: Correct.**\n\n**B. Because Crank–Nicolson is second-order accurate and $\\mathbf{K}$ is symmetric positive definite, CN always satisfies the discrete maximum principle for any $\\Delta t>0$ and any storage $M>0$.**\n- Our analysis for $\\theta=0.5$ (CN) yielded the condition $\\Delta t \\le 2\\,c_i/k_{ii}$. This condition depends on $\\Delta t$, $c_i$ (which is proportional to storage $M$), and the mesh-dependent term $k_{ii}$. The claim that CN *always* satisfies the DMP for *any* $\\Delta t > 0$ and $M > 0$ is false. For a sufficiently large $\\Delta t$ or a sufficiently small storage $M$, the condition will be violated, and non-physical undershoots can occur. The second-order accuracy and SPD nature of $\\mathbf{K}$ are not sufficient to guarantee unconditional monotonicity.\n- **Verdict: Incorrect.**\n\n**C. For low storage $M$ and large $\\Delta t$, selecting $\\theta<0.5$ is more robust than backward Euler ($\\theta=1$) and prevents undershoots due to its added numerical damping relative to CN.**\n- The monotonicity condition is $c_i \\ge (1-\\theta)\\Delta t\\,k_{ii}$. If $\\theta < 0.5$, then $1-\\theta > 0.5$. This makes the right-hand side of the inequality larger, imposing a *stricter* condition on $\\Delta t$ compared to CN. Such schemes are less robust, not more.\n- Backward Euler ($\\theta=1$) is unconditionally monotonic and is the most robust scheme in this family with respect to the DMP. To claim a scheme with $\\theta < 0.5$ is more robust is false.\n- Schemes with $\\theta < 0.5$ are generally less stable and are not characterized by \"added numerical damping relative to CN\". In fact, they can be anti-dissipative.\n- **Verdict: Incorrect.**\n\n**D. A sufficient condition to avoid undershoots with the $\\theta$-scheme in the zero-source case is that $c_i\\ge (1-\\theta)\\,\\Delta t\\,k_{ii}$ for all $i$, which may be violated by CN at small $M$ and large $\\Delta t$; increasing $\\theta$ above $0.5$ weakens this restriction, and for $\\theta=1$ the condition holds trivially.**\n- The statement presents the exact sufficient condition derived above: $c_i \\ge (1-\\theta)\\Delta t\\,k_{ii}$. This is correct.\n- For CN ($\\theta=0.5$), the condition is $c_i \\ge 0.5\\,\\Delta t\\,k_{ii}$. Since $c_i \\propto M$, a small storage $M$ leads to a small $c_i$. If $\\Delta t$ is large, it is possible that $0.5\\,\\Delta t\\,k_{ii} > c_i$, violating the condition. This is correct.\n- As $\\theta$ increases from $0.5$ to $1$, the factor $(1-\\theta)$ decreases, making the right-hand side of the inequality smaller. This means the condition is easier to satisfy, so the restriction is weakened. This is correct.\n- For $\\theta=1$, the condition becomes $c_i \\ge 0$, which is true by definition ($c_i > 0$). It holds trivially for any $\\Delta t$. This is correct.\n- **Verdict: Correct.**\n\n**E. The appearance of undershoots with CN at low $M$ is entirely due to the spatial discretization and is unaffected by the choice of time discretization parameter $\\theta$.**\n- The analysis shows explicitly that the condition for avoiding undershoots, $c_i \\ge (1-\\theta)\\Delta t\\,k_{ii}$, depends directly on the time discretization parameter $\\theta$. By changing $\\theta$ (e.g., from $0.5$ to $1$), one can go from a conditionally monotonic scheme to an unconditionally monotonic one, for the very same spatial discretization (same $\\mathbf{C}$ and $\\mathbf{K}$). Therefore, the appearance of undershoots is strongly affected by the choice of $\\theta$. The statement that it is \"unaffected\" is false.\n- **Verdict: Incorrect.**",
            "answer": "$$\\boxed{AD}$$"
        },
        {
            "introduction": "The true challenge and power of implicit methods lie in their application to nonlinear systems, which are ubiquitous in realistic geomechanical modeling. This exercise demystifies the implementation of an implicit Newmark step for a system with nonlinear material stiffness, focusing on the iterative Newton-Raphson solution procedure . You will derive the consistent tangent Jacobian matrix required for quadratic convergence and implement a complete solver, gaining hands-on insight into the computational core of modern nonlinear structural dynamics codes.",
            "id": "3566474",
            "problem": "Consider a single-degree-of-freedom dynamic system representative of a lumped geomechanical discretization, governed by the strong form of linear momentum balance,\n$$\nm\\,\\ddot{u}(t) + c\\,\\dot{u}(t) + f_{\\mathrm{int}}(u(t)) = f_{\\mathrm{ext}}(t),\n$$\nwhere $m$ is the mass, $c$ is the viscous damping coefficient, $u(t)$ is the displacement, $f_{\\mathrm{int}}(u)$ is the nonlinear internal force due to the material response, and $f_{\\mathrm{ext}}(t)$ is the prescribed external force. Assume a nonlinear material response characterized by a scalar potential leading to an internal force\n$$\nf_{\\mathrm{int}}(u) = k\\,u + \\alpha\\,u^3,\n$$\nwith $k > 0$ and $\\alpha \\ge 0$.\n\nDiscretize time using the implicit Newmark family with time step $\\Delta t$, parameters $\\beta$ and $\\gamma$. The kinematic updates are\n$$\nu_{n+1} = u_n + \\Delta t\\,v_n + \\Delta t^2\\left(\\frac{1}{2} - \\beta\\right)a_n + \\beta\\,\\Delta t^2\\,a_{n+1},\n$$\n$$\nv_{n+1} = v_n + \\Delta t\\,(1 - \\gamma)\\,a_n + \\gamma\\,\\Delta t\\,a_{n+1},\n$$\nand the dynamic equilibrium at $t_{n+1}$ is\n$$\nm\\,a_{n+1} + c\\,v_{n+1} + f_{\\mathrm{int}}(u_{n+1}) = f_{\\mathrm{ext}}(t_{n+1}).\n$$\n\nTask 1 (derivation): Starting from linear momentum balance and the implicit Newmark updates, formulate the Newton–Raphson iteration for the unknown vector $\\left[u_{n+1},\\,v_{n+1},\\,a_{n+1}\\right]^\\top$ by writing the residuals\n$$\nR_m(u_{n+1}, v_{n+1}, a_{n+1}) = m\\,a_{n+1} + c\\,v_{n+1} + f_{\\mathrm{int}}(u_{n+1}) - f_{\\mathrm{ext}}(t_{n+1}),\n$$\n$$\nR_v(u_{n+1}, v_{n+1}, a_{n+1}) = v_{n+1} - v_n - \\Delta t\\,(1 - \\gamma)\\,a_n - \\gamma\\,\\Delta t\\,a_{n+1},\n$$\n$$\nR_u(u_{n+1}, v_{n+1}, a_{n+1}) = u_{n+1} - u_n - \\Delta t\\,v_n - \\Delta t^2\\left(\\frac{1}{2} - \\beta\\right)a_n - \\beta\\,\\Delta t^2\\,a_{n+1},\n$$\nand deriving the $3\\times 3$ Jacobian matrix of partial derivatives with respect to $\\left[u_{n+1},\\,v_{n+1},\\,a_{n+1}\\right]^\\top$. Explicitly identify each Jacobian block and show how a consistent linearization yields quadratic convergence.\n\nTask 2 (condensation): Show how to eliminate $v_{n+1}$ and $a_{n+1}$ via the Newmark constraints to obtain a scalar Newton update in $u_{n+1}$ with the effective tangent\n$$\nK_{\\mathrm{eff}}(u_{n+1}) = K_t(u_{n+1}) + a_0\\,m + a_1\\,c,\n$$\nwhere $K_t(u) = \\dfrac{df_{\\mathrm{int}}}{du}(u)$ and $a_0 = \\dfrac{1}{\\beta\\,\\Delta t^2}$, $a_1 = \\dfrac{\\gamma}{\\beta\\,\\Delta t}$. Derive this result directly from the $3\\times 3$ Jacobian via the appropriate Schur complement.\n\nTask 3 (implementation): Implement a Newton–Raphson solver for a single implicit Newmark step that uses the condensed scalar update for $u_{n+1}$, with\n$$\na_{n+1} = \\frac{1}{\\beta\\,\\Delta t^2}\\left(u_{n+1} - u_n - \\Delta t\\,v_n - \\Delta t^2\\left(\\frac{1}{2} - \\beta\\right)a_n\\right),\n$$\n$$\nv_{n+1} = v_n + \\Delta t\\,(1 - \\gamma)\\,a_n + \\gamma\\,\\Delta t\\,a_{n+1},\n$$\nand residual\n$$\nr(u_{n+1}) = m\\,a_{n+1} + c\\,v_{n+1} + f_{\\mathrm{int}}(u_{n+1}) - f_{\\mathrm{ext}}(t_{n+1}),\n$$\nwith update\n$$\n\\Delta u = -\\frac{r(u_{n+1})}{K_{\\mathrm{eff}}(u_{n+1})},\\quad u_{n+1}^{(k+1)} = u_{n+1}^{(k)} + \\Delta u.\n$$\nUse a stopping criterion $\\lvert r(u_{n+1})\\rvert \\le \\varepsilon$ with $\\varepsilon = 10^{-12}$.\n\nAdditionally, construct the full $3\\times 3$ Jacobian and verify numerically that its Schur complement with respect to $u_{n+1}$ matches $K_{\\mathrm{eff}}(u_{n+1})$ to within a specified tolerance. Report this verification as a boolean.\n\nInitialization: Compute $a_n$ from the equilibrium at $t_n$,\n$$\na_n = \\frac{f_{\\mathrm{ext}}(t_n) - c\\,v_n - f_{\\mathrm{int}}(u_n)}{m}.\n$$\n\nTest suite: For each case below, compute $u_{n+1}$ and the Jacobian consistency boolean. Express $u_{n+1}$ in meters as a float.\n\n- Case A (general nonlinear, damped): $m = 1.0\\,\\mathrm{kg}$, $c = 0.05\\,\\mathrm{N\\,s/m}$, $k = 100.0\\,\\mathrm{N/m}$, $\\alpha = 500.0\\,\\mathrm{N/m^3}$, $\\Delta t = 0.01\\,\\mathrm{s}$, $\\beta = 0.25$, $\\gamma = 0.5$, $u_n = 0.01\\,\\mathrm{m}$, $v_n = 0.0\\,\\mathrm{m/s}$, $f_{\\mathrm{ext}}(t_n) = 0.0\\,\\mathrm{N}$, $f_{\\mathrm{ext}}(t_{n+1}) = 1.0\\,\\mathrm{N}$.\n- Case B (undamped): $m = 2.0\\,\\mathrm{kg}$, $c = 0.0\\,\\mathrm{N\\,s/m}$, $k = 200.0\\,\\mathrm{N/m}$, $\\alpha = 1000.0\\,\\mathrm{N/m^3}$, $\\Delta t = 0.01\\,\\mathrm{s}$, $\\beta = 0.25$, $\\gamma = 0.5$, $u_n = 0.0\\,\\mathrm{m}$, $v_n = 0.0\\,\\mathrm{m/s}$, $f_{\\mathrm{ext}}(t_n) = 0.0\\,\\mathrm{N}$, $f_{\\mathrm{ext}}(t_{n+1}) = 0.5\\,\\mathrm{N}$.\n- Case C (small time step): $m = 1.0\\,\\mathrm{kg}$, $c = 0.05\\,\\mathrm{N\\,s/m}$, $k = 100.0\\,\\mathrm{N/m}$, $\\alpha = 500.0\\,\\mathrm{N/m^3}$, $\\Delta t = 0.001\\,\\mathrm{s}$, $\\beta = 0.25$, $\\gamma = 0.5$, $u_n = 0.01\\,\\mathrm{m}$, $v_n = 0.0\\,\\mathrm{m/s}$, $f_{\\mathrm{ext}}(t_n) = 0.0\\,\\mathrm{N}$, $f_{\\mathrm{ext}}(t_{n+1}) = 1.0\\,\\mathrm{N}$.\n- Case D (stiff nonlinear, moderate damping): $m = 0.5\\,\\mathrm{kg}$, $c = 0.2\\,\\mathrm{N\\,s/m}$, $k = 1000.0\\,\\mathrm{N/m}$, $\\alpha = 100000.0\\,\\mathrm{N/m^3}$, $\\Delta t = 0.01\\,\\mathrm{s}$, $\\beta = 0.25$, $\\gamma = 0.5$, $u_n = 0.002\\,\\mathrm{m}$, $v_n = 0.0\\,\\mathrm{m/s}$, $f_{\\mathrm{ext}}(t_n) = 0.0\\,\\mathrm{N}$, $f_{\\mathrm{ext}}(t_{n+1}) = 2.0\\,\\mathrm{N}$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output two entries: first the converged displacement $u_{n+1}$ in meters as a float, then a boolean indicating whether the condensed effective tangent $K_{\\mathrm{eff}}$ matches the Schur complement of the full Jacobian to within tolerance. For example, an output with four cases should look like\n`[ u_A, bool_A, u_B, bool_B, u_C, bool_C, u_D, bool_D ]`.",
            "solution": "The problem requires the formulation and implementation of a numerical solution for a single-degree-of-freedom (SDOF) nonlinear dynamic system. The system's behavior is described by the equation of motion, a second-order nonlinear ordinary differential equation:\n$$\nm\\,\\ddot{u}(t) + c\\,\\dot{u}(t) + f_{\\mathrm{int}}(u(t)) = f_{\\mathrm{ext}}(t)\n$$\nThe nonlinearity stems from the internal force, which is given by a cubic relationship: $f_{\\mathrm{int}}(u) = k\\,u + \\alpha\\,u^3$, characteristic of a Duffing oscillator. The parameters $m$, $c$, $k$, and $\\alpha$ are the mass, damping coefficient, linear stiffness, and nonlinear stiffness, respectively, with $k > 0$ and $\\alpha \\ge 0$.\n\nThe time domain is discretized using the implicit Newmark family of methods. The state of the system at time $t_{n+1} = t_n + \\Delta t$ is determined from the state at $t_n$ using the kinematic update rules for displacement $u_{n+1}$ and velocity $v_{n+1}$:\n$$\nu_{n+1} = u_n + \\Delta t\\,v_n + \\Delta t^2\\left(\\frac{1}{2} - \\beta\\right)a_n + \\beta\\,\\Delta t^2\\,a_{n+1}\n$$\n$$\nv_{n+1} = v_n + \\Delta t\\,(1 - \\gamma)\\,a_n + \\gamma\\,\\Delta t\\,a_{n+1}\n$$\nand the enforcement of dynamic equilibrium at time $t_{n+1}$:\n$$\nm\\,a_{n+1} + c\\,v_{n+1} + f_{\\mathrm{int}}(u_{n+1}) = f_{\\mathrm{ext}}(t_{n+1})\n$$\nSince these equations are implicit and nonlinear in the unknowns $u_{n+1}$, $v_{n+1}$, and $a_{n+1}$, an iterative numerical scheme such as the Newton-Raphson method is required to find the solution at each time step.\n\n### Task 1: Full System Newton-Raphson Formulation\n\nThe Newton-Raphson method solves a system of nonlinear equations $\\mathbf{R}(\\mathbf{x}) = \\mathbf{0}$ by iteratively finding corrections $\\Delta \\mathbf{x}$ to a guess $\\mathbf{x}^{(k)}$ from the linear system $\\mathbf{J}(\\mathbf{x}^{(k)}) \\Delta \\mathbf{x} = -\\mathbf{R}(\\mathbf{x}^{(k)})$, where $\\mathbf{J}$ is the Jacobian matrix of $\\mathbf{R}$.\n\nFor our problem, the vector of unknowns at time $t_{n+1}$ is $\\mathbf{x}_{n+1} = \\left[u_{n+1}, v_{n+1}, a_{n+1}\\right]^\\top$. The system of equations is formed by the three residual functions provided:\n$$\nR_m(u_{n+1}, v_{n+1}, a_{n+1}) = m\\,a_{n+1} + c\\,v_{n+1} + f_{\\mathrm{int}}(u_{n+1}) - f_{\\mathrm{ext}}(t_{n+1}) = 0\n$$\n$$\nR_v(u_{n+1}, v_{n+1}, a_{n+1}) = v_{n+1} - v_n - \\Delta t\\,(1 - \\gamma)\\,a_n - \\gamma\\,\\Delta t\\,a_{n+1} = 0\n$$\n$$\nR_u(u_{n+1}, v_{n+1}, a_{n+1}) = u_{n+1} - u_n - \\Delta t\\,v_n - \\Delta t^2\\left(\\frac{1}{2} - \\beta\\right)a_n - \\beta\\,\\Delta t^2\\,a_{n+1} = 0\n$$\nThe Jacobian matrix $\\mathbf{J}$ is the matrix of partial derivatives of the residual vector $\\mathbf{R} = [R_m, R_v, R_u]^\\top$ with respect to the unknown vector $\\mathbf{x}_{n+1}$. The components $J_{ij}$ are given by $J_{ij} = \\partial R_i / \\partial x_j$.\n\nThe required partial derivatives are:\n- For $R_m$:\n  - $\\frac{\\partial R_m}{\\partial u_{n+1}} = \\frac{d}{du_{n+1}}f_{\\mathrm{int}}(u_{n+1}) = K_t(u_{n+1}) = k + 3\\alpha u_{n+1}^2$\n  - $\\frac{\\partial R_m}{\\partial v_{n+1}} = c$\n  - $\\frac{\\partial R_m}{\\partial a_{n+1}} = m$\n- For $R_v$:\n  - $\\frac{\\partial R_v}{\\partial u_{n+1}} = 0$\n  - $\\frac{\\partial R_v}{\\partial v_{n+1}} = 1$\n  - $\\frac{\\partial R_v}{\\partial a_{n+1}} = -\\gamma\\,\\Delta t$\n- For $R_u$:\n  - $\\frac{\\partial R_u}{\\partial u_{n+1}} = 1$\n  - $\\frac{\\partial R_u}{\\partial v_{n+1}} = 0$\n  - $\\frac{\\partial R_u}{\\partial a_{n+1}} = -\\beta\\,\\Delta t^2$\n\nAssembling these components yields the $3 \\times 3$ Jacobian matrix:\n$$\n\\mathbf{J}(u_{n+1}) = \\frac{\\partial(R_m, R_v, R_u)}{\\partial(u_{n+1}, v_{n+1}, a_{n+1})} = \n\\begin{bmatrix}\nK_t(u_{n+1}) & c & m \\\\\n0 & 1 & -\\gamma\\,\\Delta t \\\\\n1 & 0 & -\\beta\\,\\Delta t^2\n\\end{bmatrix}\n$$\nThis Jacobian is the exact derivative of the residual vector, a property known as consistent linearization. Using this matrix in the Newton-Raphson update ensures that the method achieves its characteristic quadratic rate of convergence near the solution.\n\n### Task 2: Static Condensation and the Effective Tangent Stiffness\n\nThe $3 \\times 3$ system can be reduced to a single scalar equation for the primary unknown, $u_{n+1}$. This process, known as static condensation, results in a more efficient solver. The derivation relies on the Schur complement of the Jacobian matrix. We partition the linear system $\\mathbf{J} \\Delta \\mathbf{x} = -\\mathbf{R}$ corresponding to the primary unknown $\\Delta u$ and the secondary unknowns $\\left[\\Delta v, \\Delta a\\right]^\\top$:\n$$\n\\begin{bmatrix}\n\\mathbf{J}_{11} & \\mathbf{J}_{12} \\\\\n\\mathbf{J}_{21} & \\mathbf{J}_{22}\n\\end{bmatrix}\n\\begin{Bmatrix}\n\\Delta u \\\\\n\\Delta \\mathbf{x}_2\n\\end{Bmatrix}\n= -\n\\begin{Bmatrix}\nR_1 \\\\\n\\mathbf{R}_2\n\\end{Bmatrix}\n$$\nwhere $\\Delta \\mathbf{x}_2 = \\left[\\Delta v, \\Delta a\\right]^\\top$, and the partitions of $\\mathbf{J}$ are:\n$$\nJ_{11} = K_t(u_{n+1}), \\quad \\mathbf{J}_{12} = \\begin{bmatrix} c & m \\end{bmatrix}, \\quad \\mathbf{J}_{21} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad \\mathbf{J}_{22} = \\begin{bmatrix} 1 & -\\gamma\\,\\Delta t \\\\ 0 & -\\beta\\,\\Delta t^2 \\end{bmatrix}\n$$\nFrom the second row of the partitioned system, we solve for $\\Delta \\mathbf{x}_2$: $\\mathbf{J}_{21} \\Delta u + \\mathbf{J}_{22} \\Delta \\mathbf{x}_2 = -\\mathbf{R}_2 \\implies \\Delta \\mathbf{x}_2 = -\\mathbf{J}_{22}^{-1}(\\mathbf{R}_2 + \\mathbf{J}_{21} \\Delta u)$.\nSubstituting this into the first row gives:\n$$\n\\left(J_{11} - \\mathbf{J}_{12} \\mathbf{J}_{22}^{-1} \\mathbf{J}_{21}\\right) \\Delta u = -R_1 + \\mathbf{J}_{12}\\mathbf{J}_{22}^{-1}\\mathbf{R}_2\n$$\nThe term multiplying $\\Delta u$ is the Schur complement of $J_{11}$, which is the effective tangent stiffness $K_{\\mathrm{eff}}$. Let's compute it. First, we find the inverse of $\\mathbf{J}_{22}$:\n$$\n\\mathbf{J}_{22}^{-1} = \\frac{1}{\\det(\\mathbf{J}_{22})} \\begin{bmatrix} -\\beta\\,\\Delta t^2 & \\gamma\\,\\Delta t \\\\ 0 & 1 \\end{bmatrix} = \\frac{1}{-\\beta\\,\\Delta t^2} \\begin{bmatrix} -\\beta\\,\\Delta t^2 & \\gamma\\,\\Delta t \\\\ 0 & 1 \\end{bmatrix} = \\begin{bmatrix} 1 & -\\frac{\\gamma}{\\beta\\,\\Delta t} \\\\ 0 & -\\frac{1}{\\beta\\,\\Delta t^2} \\end{bmatrix}\n$$\nNow, we compute the triple product $\\mathbf{J}_{12} \\mathbf{J}_{22}^{-1} \\mathbf{J}_{21}$:\n$$\n\\mathbf{J}_{12} \\mathbf{J}_{22}^{-1} = \\begin{bmatrix} c & m \\end{bmatrix} \\begin{bmatrix} 1 & -\\frac{\\gamma}{\\beta\\,\\Delta t} \\\\ 0 & -\\frac{1}{\\beta\\,\\Delta t^2} \\end{bmatrix} = \\begin{bmatrix} c & -c\\frac{\\gamma}{\\beta\\,\\Delta t} - \\frac{m}{\\beta\\,\\Delta t^2} \\end{bmatrix}\n$$\n$$\n(\\mathbf{J}_{12} \\mathbf{J}_{22}^{-1}) \\mathbf{J}_{21} = \\begin{bmatrix} c & -c\\frac{\\gamma}{\\beta\\,\\Delta t} - \\frac{m}{\\beta\\,\\Delta t^2} \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = -c\\frac{\\gamma}{\\beta\\,\\Delta t} - \\frac{m}{\\beta\\,\\Delta t^2}\n$$\nFinally, the effective tangent stiffness is:\n$$\nK_{\\mathrm{eff}} = J_{11} - \\mathbf{J}_{12} \\mathbf{J}_{22}^{-1} \\mathbf{J}_{21} = K_t(u_{n+1}) - \\left( -c\\frac{\\gamma}{\\beta\\,\\Delta t} - \\frac{m}{\\beta\\,\\Delta t^2} \\right)\n$$\n$$\nK_{\\mathrm{eff}}(u_{n+1}) = K_t(u_{n+1}) + \\frac{1}{\\beta\\,\\Delta t^2} m + \\frac{\\gamma}{\\beta\\,\\Delta t} c\n$$\nThis matches the provided expression $K_{\\mathrm{eff}} = K_t + a_0 m + a_1 c$ with constants $a_0 = \\frac{1}{\\beta\\,\\Delta t^2}$ and $a_1 = \\frac{\\gamma}{\\beta\\,\\Delta t}$.\n\n### Task 3: Algorithmic Design and Implementation Principles\n\nThe condensed formulation allows us to solve for $u_{n+1}$ using a scalar Newton-Raphson iteration. The core of the algorithm is to solve the scalar residual equation $r(u_{n+1})=0$, where:\n$$\nr(u_{n+1}) = m\\,a_{n+1} + c\\,v_{n+1} + f_{\\mathrm{int}}(u_{n+1}) - f_{\\mathrm{ext}}(t_{n+1})\n$$\nIn this equation, $a_{n+1}$ and $v_{n+1}$ are not independent unknowns but are functions of $u_{n+1}$ through the Newmark kinematic relations:\n$$\na_{n+1}(u_{n+1}) = \\frac{1}{\\beta\\,\\Delta t^2}\\left(u_{n+1} - u_n - \\Delta t\\,v_n - \\Delta t^2\\left(\\frac{1}{2} - \\beta\\right)a_n\\right)\n$$\n$$\nv_{n+1}(u_{n+1}) = v_n + \\Delta t\\,(1 - \\gamma)\\,a_n + \\gamma\\,\\Delta t\\,a_{n+1}(u_{n+1})\n$$\nNote that before starting the time step, $a_n$ must be computed to satisfy equilibrium at time $t_n$: $a_n = (f_{\\mathrm{ext}}(t_n) - c v_n - f_{\\mathrm{int}}(u_n)) / m$.\n\nThe Newton-Raphson iteration for $u_{n+1}$ proceeds as follows:\n1.  Initialize iteration counter $k=0$ and the guess $u_{n+1}^{(0)} = u_n$.\n2.  Loop for $k=0, 1, 2, \\dots$ until convergence:\n    a. Let the current guess be $u_{\\text{curr}} = u_{n+1}^{(k)}$.\n    b. Calculate $a_{n+1}$ and $v_{n+1}$ using $u_{\\text{curr}}$ and the kinematic expressions above.\n    c. Evaluate the residual $r(u_{\\text{curr}})$.\n    d. Check for convergence: if $\\lvert r(u_{\\text{curr}}) \\rvert \\le \\varepsilon$ (with $\\varepsilon=10^{-12}$), the loop terminates.\n    e. Evaluate the effective tangent stiffness $K_{\\mathrm{eff}}(u_{\\text{curr}}) = \\frac{dr}{du_{n+1}}|_{u_{n+1}=u_{\\text{curr}}} = K_t(u_{\\text{curr}}) + a_0 m + a_1 c$.\n    f. Compute the update: $\\Delta u = -r(u_{\\text{curr}}) / K_{\\mathrm{eff}}(u_{\\text{curr}})$.\n    g. Update the guess: $u_{n+1}^{(k+1)} = u_{\\text{curr}} + \\Delta u$.\n3. The converged solution is the final value of $u_{n+1}$.\n\nFinally, the implementation requires a numerical verification that the analytical expression for $K_{\\mathrm{eff}}$ is equivalent to the Schur complement of the full $3 \\times 3$ Jacobian. This is achieved by:\n1.  Constructing the numerical Jacobian matrix $\\mathbf{J}$ at the converged solution $u_{n+1}$.\n2.  Partitioning $\\mathbf{J}$ into its $\\mathbf{J}_{11}$, $\\mathbf{J}_{12}$, $\\mathbf{J}_{21}$, and $\\mathbf{J}_{22}$ blocks.\n3.  Numerically computing the Schur complement $S = J_{11} - \\mathbf{J}_{12} (\\mathbf{J}_{22})^{-1} \\mathbf{J}_{21}$.\n4.  Comparing this numerical value $S$ to the value of $K_{\\mathrm{eff}}(u_{n+1})$ calculated from the analytical formula. The comparison is done within a small numerical tolerance, yielding a boolean result.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_newmark_step(params):\n    \"\"\"\n    Solves for the state at time t_{n+1} for a single time step using the\n    implicit Newmark method with a condensed Newton-Raphson scheme.\n\n    Args:\n        params (tuple): A tuple containing all problem parameters:\n                        (m, c, k, alpha, dt, beta, gamma, u_n, v_n, \n                         f_ext_n, f_ext_n1)\n\n    Returns:\n        tuple: A tuple containing the converged displacement u_{n+1} (float)\n               and a boolean indicating if the Jacobian verification passed.\n    \"\"\"\n    m, c, k, alpha, dt, beta, gamma, u_n, v_n, f_ext_n, f_ext_n1 = params\n\n    # --- Helper Functions ---\n    def f_int(u):\n        \"\"\"Internal force.\"\"\"\n        return k * u + alpha * u**3\n\n    def K_t(u):\n        \"\"\"Tangent stiffness from the internal force.\"\"\"\n        return k + 3 * alpha * u**2\n\n    # --- Initialization ---\n    # Compute acceleration at step n, assuming equilibrium.\n    a_n = (f_ext_n - c * v_n - f_int(u_n)) / m\n\n    # Newmark constants for the condensed system.\n    a0 = 1.0 / (beta * dt**2)\n    a1 = gamma / (beta * dt)\n\n    # --- Newton-Raphson Iteration for the Condensed System ---\n    u_n1 = u_n  # Initial guess for the displacement at t_{n+1}.\n    \n    epsilon = 1e-12\n    max_iter = 20\n\n    for _ in range(max_iter):\n        # Calculate kinematics (a_{n+1}, v_{n+1}) based on the current guess for u_{n+1}.\n        # The equation for a_{n+1} is derived from the Newmark displacement update:\n        # u_{n+1} = u_n + dt*v_n + dt^2*(1/2 - beta)*a_n + beta*dt^2*a_{n+1}\n        # Rearranging gives:\n        a_n1 = a0 * (u_n1 - u_n - dt * v_n) - (1/(2*beta) - 1) * a_n\n        \n        # The velocity v_{n+1} is updated using the computed a_{n+1}.\n        v_n1 = v_n + dt * (1 - gamma) * a_n + gamma * dt * a_n1\n\n        # Calculate the residual of the dynamic equilibrium equation at t_{n+1}.\n        residual = m * a_n1 + c * v_n1 + f_int(u_n1) - f_ext_n1\n\n        # Check for convergence.\n        if np.abs(residual) <= epsilon:\n            break\n\n        # Calculate the effective tangent stiffness K_eff.\n        K_eff = K_t(u_n1) + a0 * m + a1 * c\n\n        # Compute the update to the displacement.\n        delta_u = -residual / K_eff\n        u_n1 += delta_u\n    else:\n        # This block executes if the loop completes without converging.\n        # In a real application, an error should be raised.\n        # For this problem, convergence is expected.\n        pass\n    \n    final_u_n1 = u_n1\n\n    # --- Jacobian Verification ---\n    # 1. Calculate K_eff using the analytical condensed formula at the converged solution.\n    K_eff_condensed = K_t(final_u_n1) + a0 * m + a1 * c\n\n    # 2. Build the full 3x3 Jacobian matrix at the converged solution.\n    # The order of residuals is (R_m, R_v, R_u) and variables is (u, v, a).\n    J = np.array([\n        [K_t(final_u_n1), c, m],\n        [0.0, 1.0, -gamma * dt],\n        [1.0, 0.0, -beta * dt**2]\n    ])\n    \n    # 3. Partition the Jacobian matrix.\n    J11 = J[0, 0]\n    J12 = J[0, 1:].reshape(1, 2)\n    J21 = J[1:, 0].reshape(2, 1)\n    J22 = J[1:, 1:]\n\n    # 4. Calculate the Schur complement: S = J11 - J12 @ inv(J22) @ J21\n    try:\n        J22_inv = np.linalg.inv(J22)\n        schur_complement = (J11 - J12 @ J22_inv @ J21).item()\n    except np.linalg.LinAlgError:\n        schur_complement = np.nan # In case of singular J22\n\n    # 5. Compare the analytical K_eff with the numerical Schur complement.\n    is_consistent = np.isclose(schur_complement, K_eff_condensed)\n\n    return final_u_n1, is_consistent\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (general nonlinear, damped)\n        (1.0, 0.05, 100.0, 500.0, 0.01, 0.25, 0.5, 0.01, 0.0, 0.0, 1.0),\n        # Case B (undamped)\n        (2.0, 0.0, 200.0, 1000.0, 0.01, 0.25, 0.5, 0.0, 0.0, 0.0, 0.5),\n        # Case C (small time step)\n        (1.0, 0.05, 100.0, 500.0, 0.001, 0.25, 0.5, 0.01, 0.0, 0.0, 1.0),\n        # Case D (stiff nonlinear, moderate damping)\n        (0.5, 0.2, 1000.0, 100000.0, 0.01, 0.25, 0.5, 0.002, 0.0, 0.0, 2.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        u_final, is_consistent_bool = solve_newmark_step(case)\n        results.append(u_final)\n        results.append(str(is_consistent_bool))\n\n    # The problem asks for the boolean to be represented as a string like 'bool_A'.\n    # Python's str(True) is 'True', which fits this representation.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}