{
    "hands_on_practices": [
        {
            "introduction": "This first practice explores a core challenge in simulating physical systems: ensuring numerical solutions respect fundamental constraints, like non-negativity. Using a simplified model of granular compaction, you will directly compare the Forward and Backward Euler methods to see how explicit schemes can fail by producing unphysical results, while implicit schemes can inherently preserve these constraints . This exercise highlights the fundamental trade-off between the simplicity of explicit methods and the robustness of implicit ones.",
            "id": "3525390",
            "problem": "Consider a nondimensional lumped model for compaction during a rapid granular column collapse. Let the state variable be the void ratio $e(t)$, with the physically admissible constraint $e(t) \\ge 0$. Assume the compaction is dominated by a stiff frictional rheology that, at the lumped level, is represented by the first-order Ordinary Differential Equation (ODE)\n$$\n\\frac{de}{dt} = - \\sigma \\sqrt{e(t)}, \\quad t \\in [0,T], \\quad e(0) = e_0,\n$$\nwhere $\\sigma > 0$ is a nondimensional parameter capturing the intensity of frictional resistance in the granular skeleton. The ODE is well-defined and admits a nonnegative exact solution for any nonnegative initial condition $e_0 \\ge 0$. All quantities are nondimensional, and no physical units are required.\n\nYour task is to:\n- Derive from first principles the analytical solution $e(t)$ of the ODE on $[0,T]$ starting from the initial condition $e(0) = e_0$ and respecting the inequality constraint $e(t) \\ge 0$.\n- Implement two time-integration schemes over $[0,T]$:\n  - Forward Euler (FE), an explicit one-step method.\n  - Backward Euler (BE), an implicit one-step method that requires solving a scalar nonlinear equation at each time step.\n- Use a constant nominal step size $\\Delta t$ and partition $[0,T]$ into substeps such that each substep size $h$ satisfies $0 < h \\le \\Delta t$ and the final step lands exactly at $T$ (i.e., the last step size is $h = T - t$ if $T - t < \\Delta t$).\n- In the explicit FE update, do not impose any ad-hoc projection or clamping on the state variable: allow the discrete state $e_n$ to become negative if dictated by the explicit update. However, to avoid undefined evaluations, when computing the right-hand side at a step that originates from an $e_n < 0$, evaluate the square root as $\\sqrt{\\max(e_n,0)}$.\n- In the implicit BE update, solve exactly and uniquely for the next state $e_{n+1}$ at each step without any artificial projection. You may use any mathematically correct approach to solve this scalar nonlinear equation.\n- For each simulation, compute:\n  1. A boolean flag indicating whether the discrete FE trajectory ever violates the constraint, i.e., whether $e_n < 0$ for any step.\n  2. A boolean flag indicating whether the discrete BE trajectory ever violates the constraint, i.e., whether $e_n < 0$ for any step.\n  3. The absolute error at final time for FE, defined as $|e_{\\text{FE}}(T) - e_{\\text{exact}}(T)|$.\n  4. The absolute error at final time for BE, defined as $|e_{\\text{BE}}(T) - e_{\\text{exact}}(T)|$.\n\nTest Suite. Run the above for the following parameter sets $(e_0,\\sigma,T,\\Delta t)$:\n- Case A (happy path, fine time step): $(e_0,\\sigma,T,\\Delta t) = (\\,1.0,\\,10.0,\\,0.1,\\,0.01\\,)$.\n- Case B (coarse step inducing explicit instability and constraint violation): $(e_0,\\sigma,T,\\Delta t) = (\\,1.0,\\,10.0,\\,0.3,\\,0.15\\,)$.\n- Case C (boundary case where the exact solution reaches zero at $T$ and the explicit scheme lands exactly on the constraint): $(e_0,\\sigma,T,\\Delta t) = (\\,1.0,\\,10.0,\\,0.2,\\,0.1\\,)$.\n- Case D (very coarse single-step integration highlighting robustness versus accuracy): $(e_0,\\sigma,T,\\Delta t) = (\\,1.0,\\,10.0,\\,0.2,\\,0.2\\,)$.\n\nRequired final output format. Your program should produce a single line of output containing a comma-separated flat list with, for each case in the order A, B, C, D, the quadruple\n$[\\text{FE\\_violated},\\text{BE\\_violated},\\text{FE\\_abs\\_err},\\text{BE\\_abs\\_err}]$.\nThus the final output has $16$ entries, ordered as\n$$\n[\\text{A:FE\\_violated},\\text{A:BE\\_violated},\\text{A:FE\\_abs\\_err},\\text{A:BE\\_abs\\_err},\\ldots,\\text{D:FE\\_violated},\\text{D:BE\\_violated},\\text{D:FE\\_abs\\_err},\\text{D:BE\\_abs\\_err}].\n$$\nAll booleans must be printed as either $\\text{True}$ or $\\text{False}$, and all errors as decimal numbers. Your program must be self-contained and require no user input. The single line must be printed exactly as a Python list literal, for example $[\\text{True},\\text{False},0.123,0.045]$ for one case (but your program must aggregate all four cases as specified).",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded, well-posed, objective, and contains all necessary information to derive a unique and verifiable solution.\n\nThe task is to analyze the first-order Ordinary Differential Equation (ODE) governing a lumped model for granular compaction, given by:\n$$\n\\frac{de}{dt} = - \\sigma \\sqrt{e(t)}, \\quad t \\in [0,T]\n$$\nwith an initial condition $e(0) = e_0 \\ge 0$ and a physical constraint $e(t) \\ge 0$. The parameter $\\sigma > 0$ is a constant. We will first derive the analytical solution, then formulate the Forward and Backward Euler numerical schemes, and finally implement them to solve the problem for the specified test cases.\n\n### 1. Analytical Solution\n\nThe ODE is a separable nonlinear equation. For $e(t) > 0$, we can separate the variables $e$ and $t$:\n$$\n\\frac{de}{\\sqrt{e}} = -\\sigma \\, dt\n$$\nWe integrate both sides from the initial state $(0, e_0)$ to a generic state $(t, e(t))$:\n$$\n\\int_{e_0}^{e(t)} u^{-1/2} \\, du = \\int_0^t -\\sigma \\, ds\n$$\nEvaluating the integrals yields:\n$$\n[2\\sqrt{u}]_{e_0}^{e(t)} = [-\\sigma s]_0^t\n$$\n$$\n2\\sqrt{e(t)} - 2\\sqrt{e_0} = -\\sigma t\n$$\nSolving for $\\sqrt{e(t)}$, we get:\n$$\n\\sqrt{e(t)} = \\sqrt{e_0} - \\frac{\\sigma t}{2}\n$$\nSince the left-hand side, $\\sqrt{e(t)}$, must be non-negative, this expression is valid only as long as the right-hand side is also non-negative. This condition holds for $t \\le t^*$, where $t^*$ is the time at which the void ratio reaches zero:\n$$\n\\sqrt{e_0} - \\frac{\\sigma t^*}{2} = 0 \\implies t^* = \\frac{2\\sqrt{e_0}}{\\sigma}\n$$\nFor $t \\le t^*$, we can square both sides to find $e(t)$:\n$$\ne(t) = \\left(\\sqrt{e_0} - \\frac{\\sigma t}{2}\\right)^2\n$$\nFor $t > t^*$, the void ratio cannot become negative. Once $e$ reaches $0$, its derivative $\\frac{de}{dt} = -\\sigma \\sqrt{0}$ becomes $0$, so the void ratio remains at $0$. Therefore, the complete analytical solution is:\n$$\ne(t) = \\begin{cases} \\left(\\sqrt{e_0} - \\frac{\\sigma t}{2}\\right)^2 & \\text{if } t \\le \\frac{2\\sqrt{e_0}}{\\sigma} \\\\ 0 & \\text{if } t > \\frac{2\\sqrt{e_0}}{\\sigma} \\end{cases}\n$$\nThis can be expressed compactly as $e(t) = \\left( \\max\\left(0, \\sqrt{e_0} - \\frac{\\sigma t}{2}\\right) \\right)^2$.\n\n### 2. Numerical Schemes\n\nWe discretize the time interval $[0,T]$ into steps. Let $e_n$ be the numerical approximation of $e(t_n)$. The step size from $t_n$ to $t_{n+1}$ is $h = t_{n+1} - t_n$. The problem specifies a time-stepping strategy where $h = \\min(\\Delta t, T-t_n)$ for a nominal step size $\\Delta t$.\n\n#### Forward Euler (FE) Method\nThe Forward Euler method is an explicit one-step scheme. The update rule is derived from a first-order Taylor expansion around $t_n$:\n$$\ne_{n+1} = e_n + h \\frac{de}{dt}\\bigg|_{t_n} = e_n + h f(e_n)\n$$\nFor our specific ODE, $f(e_n)=-\\sigma\\sqrt{e_n}$. The problem specifies a modification to handle potential negative values of $e_n$ that the numerical scheme might produce:\n$$\ne_{n+1} = e_n - h \\sigma \\sqrt{\\max(0, e_n)}\n$$\nThis is an explicit update, as $e_{n+1}$ is computed directly from the known state $e_n$. The stability of this scheme is conditional. A linearized stability analysis suggests that the step size $h$ must satisfy $h \\le \\frac{4\\sqrt{e_n}}{\\sigma}$ to avoid oscillations and non-physical negative solutions. If this condition is violated, $e_{n+1}$ can become negative, violating the physical constraint $e(t) \\ge 0$. The simulation is required to track whether such a violation occurs.\n\n#### Backward Euler (BE) Method\nThe Backward Euler method is an implicit one-step scheme. The update rule is:\n$$\ne_{n+1} = e_n + h \\frac{de}{dt}\\bigg|_{t_{n+1}} = e_n + h f(e_{n+1})\n$$\nFor our ODE, this gives a nonlinear algebraic equation for $e_{n+1}$:\n$$\ne_{n+1} = e_n - h \\sigma \\sqrt{e_{n+1}}\n$$\nTo solve for $e_{n+1}$, let $x = \\sqrt{e_{n+1}}$. Since $e_{n+1} \\ge 0$ is sought, we must have $x \\ge 0$. The equation becomes a quadratic equation for $x$:\n$$\nx^2 + h\\sigma x - e_n = 0\n$$\nApplying the quadratic formula for $x$:\n$$\nx = \\frac{-h\\sigma \\pm \\sqrt{(h\\sigma)^2 - 4(1)(-e_n)}}{2} = \\frac{-h\\sigma \\pm \\sqrt{(h\\sigma)^2 + 4e_n}}{2}\n$$\nSince $x$ must be non-negative, and assuming the scheme preserves positivity ($e_n \\ge 0$), we must choose the positive root:\n$$\n\\sqrt{e_{n+1}} = x = \\frac{-h\\sigma + \\sqrt{(h\\sigma)^2 + 4e_n}}{2}\n$$\nThis solution for $x$ is always real and non-negative for any $h > 0$, $\\sigma > 0$, and $e_n \\ge 0$, because the discriminant $(h\\sigma)^2 + 4e_n$ is non-negative and $\\sqrt{(h\\sigma)^2 + 4e_n} \\ge \\sqrt{(h\\sigma)^2} = h\\sigma$.\nThus, starting from $e_0 \\ge 0$, the BE scheme guarantees $e_n \\ge 0$ for all $n \\ge 0$. This property is known as unconditional positivity preservation. The BE method will never violate the physical constraint for this problem. The update for $e_{n+1}$ is obtained by squaring $x$:\n$$\ne_{n+1} = \\left(\\frac{-h\\sigma + \\sqrt{(h\\sigma)^2 + 4e_n}}{2}\\right)^2\n$$\nThis provides an exact, unique, and physically admissible solution at each step without iteration.\n\nThe following Python implementation will execute these schemes for the four test cases and compute the required metrics: boolean flags for constraint violation and absolute errors at the final time $T$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print the results.\n    \"\"\"\n    # Test Suite: (e0, sigma, T, dt_nominal)\n    test_cases = [\n        # Case A (happy path, fine time step)\n        (1.0, 10.0, 0.1, 0.01),\n        # Case B (coarse step inducing explicit instability)\n        (1.0, 10.0, 0.3, 0.15),\n        # Case C (boundary case where exact solution reaches zero)\n        (1.0, 10.0, 0.2, 0.1),\n        # Case D (very coarse single-step integration)\n        (1.0, 10.0, 0.2, 0.2),\n    ]\n\n    results = []\n    for params in test_cases:\n        case_results = run_simulation(*params)\n        results.extend(case_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(e0, sigma, T, dt_nominal):\n    \"\"\"\n    Performs a single simulation for a given parameter set.\n\n    Args:\n        e0 (float): Initial void ratio.\n        sigma (float): Frictional resistance parameter.\n        T (float): Final time.\n        dt_nominal (float): Nominal time step size.\n\n    Returns:\n        tuple: A tuple containing (FE_violated, BE_violated, FE_abs_err, BE_abs_err).\n    \"\"\"\n\n    # --- Analytical Solution ---\n    def e_exact(t, e0_loc, sigma_loc):\n        val = np.sqrt(e0_loc) - sigma_loc * t / 2.0\n        return np.power(np.maximum(0.0, val), 2)\n\n    # --- Forward Euler (FE) Simulation ---\n    t_fe = 0.0\n    e_fe = e0\n    fe_violated = False\n    while t_fe  T:\n        h = min(dt_nominal, T - t_fe)\n        # Update rule with special handling for RHS\n        e_fe_next = e_fe - h * sigma * np.sqrt(np.maximum(0.0, e_fe))\n        e_fe = e_fe_next\n        t_fe += h\n        if e_fe  0.0:\n            fe_violated = True\n    \n    # --- Backward Euler (BE) Simulation ---\n    t_be = 0.0\n    e_be = e0\n    be_violated = False # Will remain False as BE is positivity-preserving\n    while t_be  T:\n        h = min(dt_nominal, T - t_be)\n        # Solve quadratic equation for sqrt(e_next)\n        # x^2 + h*sigma*x - e_be = 0\n        b_quad = h * sigma\n        c_quad = -e_be\n        sqrt_e_next = (-b_quad + np.sqrt(b_quad**2 - 4 * c_quad)) / 2.0\n        e_be_next = sqrt_e_next**2\n        \n        e_be = e_be_next\n        t_be += h\n        if e_be  0.0:\n            # This should never happen based on the derivation\n            be_violated = True\n\n    # --- Calculate Final Errors ---\n    e_final_exact = e_exact(T, e0, sigma)\n    fe_abs_err = abs(e_fe - e_final_exact)\n    be_abs_err = abs(e_be - e_final_exact)\n\n    return (fe_violated, be_violated, fe_abs_err, be_abs_err)\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        },
        {
            "introduction": "Moving from a simple ordinary differential equation (ODE) to a full partial differential equation (PDE), this practice tackles the classic problem of one-dimensional soil consolidation. You will implement the unconditionally stable Backward Euler method for a spatially discretized diffusion equation and compare your results against a precise analytical solution. This exercise shifts the focus from simple stability to a more nuanced aspect of accuracy: quantifying the numerical diffusion introduced by the time integration scheme, a common artifact in first-order methods .",
            "id": "3525360",
            "problem": "Consider the one-dimensional consolidation of a fully saturated, homogeneous soil layer of thickness $H$ under an initial uniform excess pore pressure $u_0$, with perfectly drained boundaries at $z=0$ and $z=H$. Under the assumptions of small deformations, constant coefficients, and Darcy flow, the combination of mass conservation and Darcy’s law yields a diffusion equation for the excess pore pressure $u(z,t)$ with the consolidation coefficient $c_v$ treated as known and constant. The mathematical model is the initial-boundary-value problem: find $u(z,t)$ on $z\\in[0,H]$, $t\\ge 0$, such that the governing equation, initial condition, and boundary conditions are satisfied.\n\nYour task is to study the time-integration accuracy and numerical diffusion of the backward (implicit) Euler method when applied, after spatial discretization by centered finite differences, to this model problem. In particular, you must:\n\n1) Starting from the diffusion equation form implied by mass conservation and Darcy’s law, and using a uniform spatial grid with $N$ equal segments and centered second-order finite differences for the spatial second derivative in $z$, derive the backward Euler fully discrete system advancing from time level $t^n$ to $t^{n+1}=t^n+\\Delta t$. You must clearly identify the linear system that determines the vector of interior nodal values of $u^{n+1}$ in terms of $u^n$.\n\n2) For the same model problem, derive the classical Fourier series analytical solution for $u(z,t)$ with drained ends and uniform initial condition $u(z,0)=u_0$. Use this closed-form series representation to evaluate $u(z,t)$ at arbitrary $t0$ with sufficient truncation to ensure accuracy.\n\n3) Implement a program that:\n- Assembles the centered finite-difference operator on a uniform grid with $N$ segments (so $N+1$ nodes), imposes homogeneous Dirichlet boundary conditions $u(0,t)=u(H,t)=0$, and advances in time by backward Euler with time step $\\Delta t$.\n- Compares the numerical solution at a fixed final time $t_{\\mathrm{final}}$ to the analytical solution by computing the relative $L^2$ error\n$$\nE(\\Delta t;N) \\equiv \\frac{\\left(\\int_0^H \\left[u_{\\mathrm{num}}(z,t_{\\mathrm{final}})-u_{\\mathrm{exact}}(z,t_{\\mathrm{final}})\\right]^2\\,\\mathrm{d}z\\right)^{1/2}}{\\left(\\int_0^H \\left[u_{\\mathrm{exact}}(z,t_{\\mathrm{final}})\\right]^2\\,\\mathrm{d}z\\right)^{1/2}},\n$$\napproximated by the trapezoidal rule on the chosen grid.\n- Quantifies the observed decay rate of the temporal error with respect to $\\Delta t$ by computing the least-squares slope\n$$\np \\equiv \\operatorname{slope}\\left(\\log E \\text{ vs. } \\log \\Delta t\\right),\n$$\nover a refinement ladder of time steps with fixed $N$ and fixed $t_{\\mathrm{final}}$. The expected value for backward Euler, before spatial error dominates, is approximately $p\\approx 1$.\n- Quantifies the numerical diffusion of backward Euler relative to the analytical solution by projecting the final solution onto the fundamental sine mode $\\sin\\!\\left(\\pi z/H\\right)$ and reporting the ratio\n$$\nR \\equiv \\frac{A_{1,\\mathrm{num}}(t_{\\mathrm{final}})}{A_{1,\\mathrm{exact}}(t_{\\mathrm{final}})},\n$$\nwhere\n$\nA_{1,\\mathrm{num}}(t) \\equiv \\frac{2}{H}\\int_0^H u_{\\mathrm{num}}(z,t)\\,\\sin\\!\\left(\\pi z/H\\right)\\,\\mathrm{d}z\n$\nis evaluated by the trapezoidal rule, and\n$\nA_{1,\\mathrm{exact}}(t) \\equiv \\frac{4u_0}{\\pi}\\exp\\!\\left(-\\pi^2 c_v t/H^2\\right).\n$\nValues $R1$ reflect over-diffusion introduced by backward Euler at finite $\\Delta t$.\n\nUse the following test suite. In all cases take $H=1.0\\,\\mathrm{m}$, $c_v=1.0\\times 10^{-6}\\,\\mathrm{m}^2/\\mathrm{s}$, and $u_0=1.0\\,\\mathrm{Pa}$. The final time is specified by the dimensionless time factor $T_v \\equiv c_v t_{\\mathrm{final}}/H^2$. For each test case, use the specified number of spatial segments $N$ and perform time step refinements by setting $\\Delta t = t_{\\mathrm{final}}/M$ for each $M$ in the provided list. For the numerical diffusion ratio $R$, report the value computed for the coarsest time step (i.e., the smallest $M$ in the list).\n\n- Test Case A (happy path):\n  - $T_v = 0.2$, $N=400$, $M\\in\\{100,200,400,800\\}$.\n- Test Case B (spatial-error influenced):\n  - $T_v = 0.2$, $N=40$, $M\\in\\{100,200,400,800\\}$.\n- Test Case C (longer final time):\n  - $T_v = 0.8$, $N=400$, $M\\in\\{400,800,1600,3200\\}$.\n\nImplementation requirements:\n- Angles appearing inside trigonometric functions are in radians.\n- All physical parameters ($H$, $c_v$, $t_{\\mathrm{final}}$, $\\Delta t$) must be handled in International System of Units (SI). The output quantities $p$ and $R$ are dimensionless. Your program must output only dimensionless numbers.\n- Use a sufficiently truncated Fourier series to represent the analytical solution such that the truncation error is negligible relative to the discretization errors for the given test suite. Clearly document any truncation strategy you use in your code comments.\n- Use the trapezoidal rule on the spatial grid to approximate all spatial integrals.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of three two-element lists, one per test case, in the order A, B, C. Each two-element list must contain $p$ and $R$ in this order. Print each floating-point number with exactly six digits after the decimal point. The exact required format is:\n$$\n\\texttt{[[p\\_A,R\\_A],[p\\_B,R\\_B],[p\\_C,R\\_C]]}\n$$\nwith no spaces anywhere in the line.\n\nYour program must be entirely self-contained and must not require any input. It must compute all required quantities internally for the specified test suite and print the final result in the exact format described above. The output $p$ and $R$ values must be real numbers (floats).",
            "solution": "The problem is valid as it is scientifically grounded in the theory of consolidation, mathematically well-posed, objective, and provides a complete and consistent set of data and instructions for its solution.\n\n### Part 1: Derivation of the Backward Euler Fully Discrete System\n\nThe governing partial differential equation (PDE) for one-dimensional consolidation is the diffusion equation for the excess pore pressure $u(z,t)$:\n$$\n\\frac{\\partial u}{\\partial t} = c_v \\frac{\\partial^2 u}{\\partial z^2}\n$$\nThis equation holds for $z \\in (0, H)$ and $t  0$. The initial condition is $u(z,0) = u_0$, and the boundary conditions are $u(0,t) = 0$ and $u(H,t) = 0$.\n\nTo formulate a numerical solution, we first discretize the spatial domain $[0, H]$ into $N$ equal segments of length $\\Delta z = H/N$. This defines a grid of $N+1$ points $z_j = j \\Delta z$ for $j=0, 1, \\dots, N$. Let $u_j(t)$ denote the numerical approximation of $u(z_j, t)$. The second spatial derivative at an interior node $z_j$ (where $j=1, \\dots, N-1$) is approximated using a second-order accurate centered finite difference:\n$$\n\\frac{\\partial^2 u}{\\partial z^2}\\bigg|_{z=z_j} \\approx \\frac{u_{j-1}(t) - 2u_j(t) - u_{j+1}(t)}{(\\Delta z)^2}\n$$\nSubstituting this approximation into the PDE transforms it into a system of $N-1$ coupled ordinary differential equations (ODEs), one for each interior node:\n$$\n\\frac{d u_j}{d t} = \\frac{c_v}{(\\Delta z)^2} \\left( u_{j-1}(t) - 2u_j(t) + u_{j+1}(t) \\right), \\quad j=1, \\dots, N-1\n$$\nThe boundary conditions imply $u_0(t)=0$ and $u_N(t)=0$ for all $t \\ge 0$.\n\nNext, we discretize the time domain. Let $t^n = n \\Delta t$ for $n=0, 1, 2, \\dots$, where $\\Delta t$ is the time step. Let $u_j^n$ be the approximation of $u(z_j, t^n)$. We use the backward (implicit) Euler method, which approximates the time derivative at the future time level $t^{n+1}$:\n$$\n\\frac{d u_j}{d t}\\bigg|_{t=t^{n+1}} \\approx \\frac{u_j^{n+1} - u_j^n}{\\Delta t}\n$$\nApplying this to the ODE system and evaluating the spatial derivative terms at time level $n+1$ yields the fully discrete scheme:\n$$\n\\frac{u_j^{n+1} - u_j^n}{\\Delta t} = \\frac{c_v}{(\\Delta z)^2} \\left( u_{j-1}^{n+1} - 2u_j^{n+1} + u_{j+1}^{n+1} \\right)\n$$\nTo determine the unknown values $u_j^{n+1}$ at the new time step, we rearrange the equation, placing all terms involving $u^{n+1}$ on the left-hand side and known terms from $u^n$ on the right-hand side.\n$$\nu_j^{n+1} - \\frac{c_v \\Delta t}{(\\Delta z)^2} \\left( u_{j-1}^{n+1} - 2u_j^{n+1} + u_{j+1}^{n+1} \\right) = u_j^n\n$$\nDefining the dimensionless Fourier number (or diffusion number) $\\alpha = \\frac{c_v \\Delta t}{(\\Delta z)^2}$, the equation for each interior node $j$ becomes:\n$$\n-\\alpha u_{j-1}^{n+1} + (1 + 2\\alpha) u_j^{n+1} - \\alpha u_{j+1}^{n+1} = u_j^n\n$$\nThis constitutes a system of $N-1$ linear algebraic equations. Letting $\\mathbf{u}^{n+1} = [u_1^{n+1}, u_2^{n+1}, \\dots, u_{N-1}^{n+1}]^T$ be the vector of unknown nodal values at time $t^{n+1}$, and $\\mathbf{u}^{n}$ be the vector of known values at $t^n$, the system is written in matrix form as:\n$$\n\\mathbf{B} \\, \\mathbf{u}^{n+1} = \\mathbf{u}^{n}\n$$\nHere, $\\mathbf{B}$ is the $(N-1) \\times (N-1)$ symmetric, tridiagonal matrix that must be inverted (or, a system solved) to advance the solution. Its entries are given by:\n$$\n\\mathbf{B}_{ij} =\n\\begin{cases}\n1 + 2\\alpha  \\text{if } i = j \\\\\n-\\alpha  \\text{if } |i - j| = 1 \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nAt each time step, this linear system is solved for $\\mathbf{u}^{n+1}$.\n\n### Part 2: Analytical Solution\n\nThe analytical solution for this initial-boundary-value problem can be derived using the method of separation of variables. We assume a solution of the form $u(z,t) = Z(z)T(t)$. Substituting this into the PDE and separating the variables yields two ODEs linked by a separation constant, which we denote as $-\\lambda^2$:\n$$\nZ''(z) + \\lambda^2 Z(z) = 0 \\quad \\text{and} \\quad T'(t) + c_v \\lambda^2 T(t) = 0\n$$\nThe spatial equation for $Z(z)$, together with the boundary conditions $Z(0)=0$ and $Z(H)=0$, forms a Sturm-Liouville problem. Its solutions are the eigenfunctions $Z_m(z) = \\sin(\\lambda_m z)$ with corresponding eigenvalues $\\lambda_m = \\frac{m\\pi}{H}$ for positive integers $m = 1, 2, 3, \\dots$. For each eigenvalue, the corresponding temporal solution is $T_m(t) = \\exp(-c_v \\lambda_m^2 t)$.\n\nThe general solution is a superposition of these fundamental solutions, forming a Fourier series:\n$$\nu(z,t) = \\sum_{m=1}^{\\infty} B_m \\sin\\left(\\frac{m\\pi z}{H}\\right) \\exp\\left(-\\frac{c_v m^2 \\pi^2 t}{H^2}\\right)\n$$\nThe Fourier coefficients $B_m$ are determined by the initial condition $u(z,0) = u_0$. Using the orthogonality of the sine functions on the interval $[0,H]$, we find:\n$$\nB_m = \\frac{2}{H} \\int_0^H u_0 \\sin\\left(\\frac{m\\pi z}{H}\\right) dz = \\frac{2u_0}{m\\pi}\\left(1 - \\cos(m\\pi)\\right)\n$$\nThis evaluates to $B_m = \\frac{4u_0}{m\\pi}$ if $m$ is odd, and $B_m = 0$ if $m$ is even. The final analytical solution is therefore:\n$$\nu_{\\mathrm{exact}}(z,t) = \\sum_{k=0}^{\\infty} \\frac{4u_0}{(2k+1)\\pi} \\sin\\left(\\frac{(2k+1)\\pi z}{H}\\right) \\exp\\left(-\\frac{c_v (2k+1)^2 \\pi^2 t}{H^2}\\right)\n$$\n\n### Part 3: Computational Strategy\n\nThe implementation proceeds by first defining a helper function to execute the simulation and analysis for a single test case. This function takes the parameters $T_v$, $N$, and the list of $M$ values as input.\n1.  **Initialization**: It calculates $t_{\\mathrm{final}}$, $\\Delta z$, and the spatial grid $z$. It also defines a function to compute the analytical solution by summing its truncated Fourier series. The truncation point is chosen to be large enough (e.g., $100$ terms) to ensure negligible series truncation error.\n2.  **Time-Step Refinement Loop**: The function iterates through the specified values of $M$. In each iteration:\n    *   It calculates $\\Delta t = t_{\\mathrm{final}}/M$.\n    *   The numerical solution is computed by initializing the interior nodal values to $u_0$ and then stepping forward $M$ times. In each step, the tridiagonal system $\\mathbf{B} \\mathbf{u}^{n+1} = \\mathbf{u}^{n}$ is solved efficiently using a banded matrix solver from the SciPy library.\n    *   The final numerical solution $u_{\\mathrm{num}}(z, t_{\\mathrm{final}})$ is compared to the analytical solution $u_{\\mathrm{exact}}(z, t_{\\mathrm{final}})$.\n    *   The relative $L^2$ error $E$ is computed using the trapezoidal rule for the integrals, and the logarithms of $E$ and $\\Delta t$ are stored.\n    *   For the first (coarsest) time step, the numerical diffusion ratio $R$ is calculated. This involves using the trapezoidal rule to compute the projection of the numerical solution onto the fundamental sine mode and dividing by the known analytical amplitude.\n3.  **Post-Processing**: After the loop, the temporal convergence rate $p$ is determined by a linear least-squares fit to the collected $\\log E$ versus $\\log \\Delta t$ data points. The function returns the computed values of $p$ and $R$.\n4.  **Main Execution**: The main part of the program defines the three test cases and calls the helper function for each. It then collects the results and formats them into the required single-line string output.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef run_case(Tv, N, M_list, H, cv, u0):\n    \"\"\"\n    Runs a single test case for the 1D consolidation problem.\n\n    Args:\n        Tv (float): Dimensionless time factor.\n        N (int): Number of spatial segments.\n        M_list (list of int): List of time step counts for refinement study.\n        H (float): Layer thickness.\n        cv (float): Consolidation coefficient.\n        u0 (float): Initial excess pore pressure.\n\n    Returns:\n        tuple: (p, R), where p is the temporal convergence rate and R is the \n               numerical diffusion ratio for the coarsest time step.\n    \"\"\"\n    t_final = Tv * H**2 / cv\n    dz = H / N\n    z_grid = np.linspace(0, H, N + 1)\n\n    log_E_list = []\n    log_dt_list = []\n    R_case = 0.0\n\n    def u_exact(z_vec, t):\n        \"\"\"\n        Computes the analytical solution using a truncated Fourier series.\n        The series converges rapidly for t > 0. Using 100 terms is\n        sufficiently accurate for the parameters in this problem.\n        \"\"\"\n        num_terms = 100 \n        sol = np.zeros_like(z_vec, dtype=float)\n        for k in range(num_terms):\n            m = 2 * k + 1\n            exp_term = np.exp(-cv * (m * np.pi / H)**2 * t)\n            term = (4 * u0 / (m * np.pi)) * np.sin(m * np.pi * z_vec / H) * exp_term\n            sol += term\n        return sol\n\n    for i, M in enumerate(M_list):\n        dt = t_final / M\n        \n        # --- Numerical Solution using Backward Euler ---\n        # Initial condition for interior nodes\n        u_n = u0 * np.ones(N - 1)\n        \n        alpha = cv * dt / dz**2\n        \n        # Setup the tridiagonal matrix B for the system B*u_n+1 = u_n\n        # using the format required by scipy.linalg.solve_banded\n        ab = np.zeros((3, N - 1))\n        ab[0, 1:] = -alpha      # Super-diagonal\n        ab[1, :] = 1 + 2 * alpha  # Main diagonal\n        ab[2, :-1] = -alpha     # Sub-diagonal\n        \n        # Time-stepping loop\n        for _ in range(M):\n            u_n = solve_banded((1, 1), ab, u_n, check_finite=False)\n            \n        # Reconstruct full solution vector including boundaries\n        u_num_final = np.concatenate(([0], u_n, [0]))\n        \n        # --- Analytical Solution ---\n        u_exact_final = u_exact(z_grid, t_final)\n        \n        # --- Error Calculation ---\n        integrand_num = (u_num_final - u_exact_final)**2\n        integrand_den = u_exact_final**2\n        \n        # Use trapezoidal rule for L2 norm approximation\n        L2_norm_diff = np.sqrt(np.trapz(integrand_num, z_grid))\n        L2_norm_exact = np.sqrt(np.trapz(integrand_den, z_grid))\n        \n        # Avoid division by zero if exact solution is zero (not the case here)\n        E = L2_norm_diff / L2_norm_exact if L2_norm_exact > 0 else 0.0\n\n        log_E_list.append(np.log(E))\n        log_dt_list.append(np.log(dt))\n        \n        # --- Numerical Diffusion Ratio R (for coarsest time step) ---\n        if i == 0:\n            # A_1_num: Projection of numerical solution onto the fundamental mode\n            integrand_A1_num = u_num_final * np.sin(np.pi * z_grid / H)\n            A1_num = (2.0 / H) * np.trapz(integrand_A1_num, z_grid)\n            \n            # A_1_exact: Analytical amplitude of the fundamental mode\n            A1_exact = (4.0 * u0 / np.pi) * np.exp(-np.pi**2 * Tv)\n            \n            R_case = A1_num / A1_exact\n\n    # --- Convergence Rate p ---\n    # Calculate slope of log(E) vs log(dt) using least squares (polyfit)\n    p = np.polyfit(log_dt_list, log_E_list, 1)[0]\n    \n    return p, R_case\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    # Global parameters\n    H = 1.0  # m\n    cv = 1.0e-6 # m^2/s\n    u0 = 1.0   # Pa\n\n    # Test suite definition\n    test_cases = [\n        # (Tv, N, M_list)\n        (0.2, 400, [100, 200, 400, 800]),      # Test Case A\n        (0.2, 40, [100, 200, 400, 800]),       # Test Case B\n        (0.8, 400, [400, 800, 1600, 3200]),    # Test Case C\n    ]\n\n    results = []\n    for Tv, N, M_list in test_cases:\n        p, R = run_case(Tv, N, M_list, H, cv, u0)\n        results.append(f\"[{p:.6f},{R:.6f}]\")\n\n    # Print the final output in the exact required format\n    print(f\"[[{','.join(results)}]]\")\n\n# Execute the solution\nsolve()\n\n```"
        },
        {
            "introduction": "The final practice addresses the complexities of realistic, nonlinear material behavior common in geomechanics. While the Backward Euler method is stable, the resulting nonlinear algebraic equations can be challenging to solve, especially in softening systems. Here, you will implement a Newton-Raphson solver, diagnose its failure for large time steps, and develop an adaptive time-stepping heuristic to ensure robust convergence, bridging the gap between basic numerical methods and the advanced algorithms used in modern simulation software .",
            "id": "3525394",
            "problem": "Consider a scalar rate-dependent softening model inspired by inelastic constitutive updates in computational geomechanics. Let $t \\in [0,T]$ denote time, and let $\\epsilon(t)$ be a prescribed total strain history. The internal variable $p(t)$ represents an accumulated inelastic measure (e.g., viscoplastic strain-like quantity) and evolves according to the nonlinear ordinary differential equation (ODE)\n$$\n\\frac{dp}{dt} = \\frac{1}{\\eta}\\,\\left[\\max\\!\\left(0,\\,f(p,\\epsilon(t))\\right)\\right]^m,\n$$\nwith viscosity parameter $\\eta0$, nonlinearity exponent $m \\ge 2$, and an overstress function exhibiting softening\n$$\nf(p,\\epsilon) = E\\,(\\epsilon - p) - \\sigma_{y0}\\,\\bigl(1 - c\\,p\\bigr).\n$$\nHere $E0$ is a stiffness scale, $\\sigma_{y0}0$ is an initial yield stress scale, and $c0$ controls softening of the strength. The prescribed strain is a linear ramp\n$$\n\\epsilon(t) = \\epsilon_{\\max}\\,\\frac{t}{T},\n$$\nwith $\\epsilon_{\\max}0$ and $T0$. The initial condition is $p(0)=0$. Assume all quantities are dimensionless.\n\nYou are asked to analyze and implement a time integrator for this initial value problem using both the fundamental discrete ideas of the forward Euler and backward Euler methods, and to connect time step size, fixed-point nonlinearity, and Newton-Raphson (NR) convergence behavior. Your derivations must start from the definitions of the forward and backward Euler time discretizations of the ODE and the definition of the Newton-Raphson method for solving nonlinear algebraic equations.\n\n1. Starting from the ODE and the definition of the backward Euler method, derive the nonlinear residual for a single time step $t_n \\to t_{n+1}$ for the unknown $p_{n+1}$, expressed in terms of $p_n$, $\\Delta t = t_{n+1}-t_n$, and $\\epsilon_{n+1} = \\epsilon(t_{n+1})$. Then derive the Newton-Raphson linearization by computing the derivative of the residual with respect to $p_{n+1}$.\n\n2. By analyzing the Newton-Raphson update you derived, obtain a sufficient local condition on $\\Delta t$ that promotes Newton convergence when the inelastic mechanism is active (i.e., when $f(p_{n+1},\\epsilon_{n+1})0$). Your condition should be expressed in terms of the local slope of the right-hand-side of the ODE with respect to $p$ and should clearly indicate how increasing $\\Delta t$ can destroy monotonicity or contractivity of the implicit fixed-point map, thereby impeding Newton convergence.\n\n3. Using the sufficient condition from item 2, derive a heuristic for adaptive time step reduction that can be applied when Newton residual reduction stalls. The heuristic must provide a formula to compute a reduced trial time step $\\Delta t_{\\text{new}}$ from a known pre-step state $(t_n,p_n)$ and the incoming $\\epsilon_{n+1}$, using only locally available information such as $p_n$, $\\epsilon_{n+1}$, and their induced estimate of the local derivative of the right-hand-side with respect to $p$. State your heuristic with a safety factor and explain briefly why it is reasonable.\n\n4. Implement a program that performs time stepping with backward Euler for the above model using Newton-Raphson at each step. Implement two drivers:\n   - A fixed step driver that attempts steps with a specified $\\Delta t$ and declares a step failure if Newton-Raphson does not converge to a tolerance within a maximum number of iterations or if the residual does not decrease meaningfully over several iterations (residual stall).\n   - An adaptive driver that, upon a fixed step failure, invokes your heuristic to reduce $\\Delta t$ and retries until success or until a minimum time step threshold is reached.\n\nFor numerical testing, use the following dimensionless parameters, which produce a highly nonlinear softening regime:\n- $E=1$, $\\sigma_{y0}=1$, $c=2$, $\\eta=1$, $m=3$, $T=1$, $\\epsilon_{\\max}=1.5$.\n- Initial condition $p(0)=0$.\n- Newton-Raphson absolute residual tolerance $10^{-10}$, and a maximum of $10$ iterations per step before declaring failure.\n- Residual stall detection: treat as a stall if the absolute residual does not decrease by at least a factor $0.5$ over any window of $3$ successive iterations while it remains above the tolerance.\n\nYour program must implement the following test suite and output the requested numerical results:\n\n- Test A (accuracy at small step): Fixed step backward Euler with $\\Delta t = 2\\times 10^{-3}$ over $[0,1]$. Compute the final value $p_{\\text{BE}}(T)$ and its absolute error with respect to a reference solution $p_{\\text{ref}}(T)$ computed by backward Euler with $\\Delta t_{\\text{ref}}=10^{-4}$. Return this error as a float.\n\n- Test B (Newton robustness at medium step): Fixed step backward Euler with $\\Delta t = 2\\times 10^{-2}$ over $[0,1]$. Report whether any step failed due to Newton nonconvergence or stall, encoded as an integer $1$ if any failure occurred and $0$ otherwise.\n\n- Test C (Newton robustness at large step): Fixed step backward Euler with $\\Delta t = 2\\times 10^{-1}$ over $[0,1]$. Report whether any step failed due to Newton nonconvergence or stall, encoded as an integer $1$ if any failure occurred and $0$ otherwise.\n\n- Test D (effectiveness of adaptive reduction): Adaptive backward Euler with initial trial $\\Delta t_{\\text{init}} = 2\\times 10^{-1}$ and the heuristic from item 3, over $[0,1]$. Report the total number of time step cuts (i.e., reductions of $\\Delta t$) performed as a nonnegative integer.\n\nAll outputs are dimensionless. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the following order: $[\\text{Test A result}, \\text{Test B result}, \\text{Test C result}, \\text{Test D result}]$.",
            "solution": "The problem requires the derivation and implementation of numerical methods for a scalar rate-dependent softening model, a common paradigm in computational geomechanics. The validation of the problem statement confirms its scientific soundness, self-consistency, and well-posed nature. We may therefore proceed with the solution.\n\nThe governing ordinary differential equation (ODE) for the internal variable $p(t)$ is:\n$$\n\\frac{dp}{dt} = \\frac{1}{\\eta}\\,\\left[\\max\\!\\left(0,\\,f(p,\\epsilon(t))\\right)\\right]^m\n$$\nwith the initial condition $p(0)=0$. The overstress function $f$ and strain history $\\epsilon(t)$ are given by:\n$$\nf(p,\\epsilon) = E\\,(\\epsilon - p) - \\sigma_{y0}\\,\\bigl(1 - c\\,p\\bigr)\n$$\n$$\n\\epsilon(t) = \\epsilon_{\\max}\\,\\frac{t}{T}\n$$\nFor the specific parameters $E=1$, $\\sigma_{y0}=1$, $c=2$, $\\eta=1$, $m=3$, $\\epsilon_{\\max}=1.5$, and $T=1$, the functions simplify to:\n$$\nf(p,\\epsilon) = 1(\\epsilon-p) - 1(1-2p) = \\epsilon + p - 1\n$$\n$$\n\\epsilon(t) = 1.5t\n$$\n$$\n\\frac{dp}{dt} = \\left[\\max\\!\\left(0,\\,\\epsilon(t) + p - 1\\right)\\right]^3\n$$\nThis simplified form will be used in the implementation for clarity and efficiency.\n\n### 1. Backward Euler Residual and Newton-Raphson Linearization\n\nThe backward Euler (BE) method discretizes the ODE over a time step $\\Delta t = t_{n+1} - t_n$ as:\n$$\n\\frac{p_{n+1} - p_n}{\\Delta t} = \\left.\\frac{dp}{dt}\\right|_{t=t_{n+1}}\n$$\nSubstituting the ODE's right-hand-side, evaluated at the unknown state $(p_{n+1}, t_{n+1})$, gives the implicit equation:\n$$\np_{n+1} = p_n + \\frac{\\Delta t}{\\eta} \\left[ \\max(0, f(p_{n+1}, \\epsilon_{n+1})) \\right]^m\n$$\nwhere $\\epsilon_{n+1} = \\epsilon(t_{n+1})$. To solve this for $p_{n+1}$ using the Newton-Raphson (NR) method, we define a residual function $R(p_{n+1})$ whose root is the solution:\n$$\nR(p_{n+1}) = p_{n+1} - p_n - \\frac{\\Delta t}{\\eta} \\left[ \\max(0, f(p_{n+1}, \\epsilon_{n+1})) \\right]^m = 0\n$$\nThe NR method requires the derivative of the residual with respect to the unknown, $p_{n+1}$, which is often called the tangent.\n$$\nR'(p_{n+1}) = \\frac{dR}{dp_{n+1}} = 1 - \\frac{\\Delta t}{\\eta} \\frac{d}{dp_{n+1}} \\left( \\left[ \\max(0, f(p_{n+1}, \\epsilon_{n+1})) \\right]^m \\right)\n$$\nThe derivative depends on whether the system is in an elastic state ($f \\le 0$) or a plastic/inelastic state ($f  0$).\nIf $f(p_{n+1}, \\epsilon_{n+1}) \\le 0$, the max term is zero, and its derivative is also zero. Thus, $R'(p_{n+1}) = 1$.\nIf $f(p_{n+1}, \\epsilon_{n+1})  0$, the inelastic mechanism is active. We apply the chain rule:\n$$\n\\frac{d}{dp_{n+1}} \\left[ f(p_{n+1}, \\epsilon_{n+1}) \\right]^m = m \\left[ f(p_{n+1}, \\epsilon_{n+1}) \\right]^{m-1} \\frac{\\partial f}{\\partial p_{n+1}}\n$$\nThe partial derivative of $f$ with respect to $p$ is:\n$$\n\\frac{\\partial f}{\\partial p} = \\frac{\\partial}{\\partial p} \\left( E(\\epsilon - p) - \\sigma_{y0}(1 - cp) \\right) = -E + \\sigma_{y0}c\n$$\nFor the given parameters, $\\frac{\\partial f}{\\partial p} = -1 + 1(2) = 1$.\nSo, for the active case, the tangent is:\n$$\nR'(p_{n+1}) = 1 - \\frac{\\Delta t}{\\eta} m \\left[ f(p_{n+1}, \\epsilon_{n+1}) \\right]^{m-1} (\\sigma_{y0}c - E)\n$$\nThe Newton-Raphson update at iteration $(k)$ for $p_{n+1}$ is then $p_{n+1}^{(k+1)} = p_{n+1}^{(k)} - R(p_{n+1}^{(k)}) / R'(p_{n+1}^{(k)})$.\n\n### 2. Sufficient Condition for Newton-Raphson Convergence\n\nThe BE equation can be written as a fixed-point problem $p_{n+1} = G(p_{n+1})$, with the map $G(p) = p_n + \\Delta t \\, \\mathcal{F}(p, \\epsilon_{n+1})$, where $\\mathcal{F}$ is the right-hand-side of the ODE. A sufficient condition for the convergence of a fixed-point iteration is that the map is a contraction, i.e., $|G'(p)|  1$. This is also a strong indicator of robust NR convergence.\nThe derivative of the map is $G'(p) = \\Delta t \\, \\frac{\\partial \\mathcal{F}}{\\partial p}(p, \\epsilon_{n+1})$. From Part 1, we know that $R'(p) = 1 - G'(p)$. The condition for monotonicity of the residual, $R'(p)0$, is equivalent to $G'(p)1$. Since $\\sigma_{y0}c - E  0$, we have $\\frac{\\partial \\mathcal{F}}{\\partial p}  0$, so $G'(p)0$. Thus, the condition becomes:\n$$\nG'(p) = \\Delta t \\, \\frac{\\partial \\mathcal{F}}{\\partial p}  1 \\implies \\Delta t  \\frac{1}{\\frac{\\partial \\mathcal{F}}{\\partial p}}\n$$\nSubstituting the expression for the derivative in the active case:\n$$\n\\frac{\\partial \\mathcal{F}}{\\partial p} = \\frac{m (\\sigma_{y0}c - E)}{\\eta} \\left[ f(p, \\epsilon_{n+1}) \\right]^{m-1}\n$$\nThe sufficient local condition on $\\Delta t$ is therefore:\n$$\n\\Delta t  \\frac{\\eta}{m (\\sigma_{y0}c - E) \\left[ f(p_{n+1}, \\epsilon_{n+1}) \\right]^{m-1}}\n$$\nPhysically, the term $\\frac{\\partial \\mathcal{F}}{\\partial p}$ represents the \"stiffness\" of the ODE evolution with respect to the state variable $p$. As softening progresses, $p$ increases, causing $f$ to grow, which in turn drastically increases $\\frac{\\partial \\mathcal{F}}{\\partial p}$ (due to the exponent $m-1 \\ge 1$). If $\\Delta t$ is too large, the term $\\Delta t \\frac{\\partial \\mathcal{F}}{\\partial p}$ can exceed $1$. This causes the fixed-point map $G$ to lose its contractivity and the NR residual $R$ to lose monotonicity ($R'  0$). An NR step based on a negative tangent can overshoot the solution, leading to oscillations or divergence.\n\n### 3. Adaptive Time Step Heuristic\n\nWhen an NR solution fails for a given time step $\\Delta t_{old}$, it often indicates a violation of the condition derived in Part 2. We can devise a heuristic to compute a smaller, safer time step $\\Delta t_{new}$ by estimating the critical term using locally available information. We do not know the solution $p_{n+1}$, so we use the state at the beginning of the step, $(p_n, t_n)$, and the strain at the end of the trial step, $\\epsilon_{n+1} = \\epsilon(t_n + \\Delta t_{old})$.\n\nThe heuristic is as follows:\n1. Estimate the local slope of the ODE's right-hand-side:\n$$\nk_{\\text{local}} = \\frac{\\partial \\mathcal{F}}{\\partial p}(p_n, \\epsilon_{n+1}) = \\frac{m (\\sigma_{y0}c - E)}{\\eta} \\left[\\max(0, f(p_n, \\epsilon_{n+1}))\\right]^{m-1}\n$$\n2. If $k_{\\text{local}}  0$, calculate a \"safe\" time step based on the stability condition, including a safety factor $\\alpha \\in (0,1)$, e.g., $\\alpha=0.8$:\n$$\n\\Delta t_{\\text{safe}} = \\frac{\\alpha}{k_{\\text{local}}}\n$$\n3. The new time step should be a reduction from the old one. A robust formula combines this estimate with a simple bisection:\n$$\n\\Delta t_{\\text{new}} = \\min(0.5 \\cdot \\Delta t_{\\text{old}}, \\Delta t_{\\text{safe}})\n$$\nIf $k_{\\text{local}} \\le 0$, the failure is likely not due to this specific instability mechanism, and a simple bisection $\\Delta t_{new} = 0.5 \\cdot \\Delta t_{old}$ is a reasonable fallback.\n\nThis heuristic is reasonable because it directly targets the source of the numerical instability by ensuring the new time step respects the local characteristic time scale of the system, $1/k_{\\text{local}}$.\n\n### 4. Implementation and Numerical Testing\n\nThe following section presents the Python implementation of the fixed-step and adaptive drivers for the specified backward Euler-Newton Raphson scheme, along with the execution of the four required tests.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# --- Model and Numerical Parameters ---\n# Model Parameters (dimensionless)\nE = 1.0\nSIGMA_Y0 = 1.0\nC = 2.0\nETA = 1.0\nM = 3.0\nT_FINAL = 1.0\nEPS_MAX = 1.5\n\n# Numerical Parameters for Solvers\nNR_TOL = 1e-10\nNR_MAX_ITER = 10\nNR_STALL_FACTOR = 0.5\nNR_STALL_WINDOW = 3\nADAPTIVE_SAFETY_FACTOR = 0.8\nMIN_DT = 1e-8\n\n\n# --- Constitutive and Model Functions ---\n\ndef epsilon(t: float) -> float:\n    \"\"\"Computes the prescribed total strain at a given time.\"\"\"\n    # Ensure time doesn't exceed the final time for epsilon calculation\n    t_clamped = min(t, T_FINAL)\n    return EPS_MAX * t_clamped / T_FINAL\n\ndef f_overstress(p: float, eps: float) -> float:\n    \"\"\"Computes the overstress function f(p, eps).\"\"\"\n    # Using simplified form from derivation: eps + p - 1\n    return eps + p - 1.0\n\ndef df_dp(p: float, eps: float) -> float:\n    \"\"\"Computes the partial derivative of f with respect to p.\"\"\"\n    # Using simplified form from derivation: 1.0\n    return 1.0\n\n\n# --- Core Numerical Solvers ---\n\ndef solve_step_be(p_n: float, t_n: float, dt: float) -> tuple[float, str]:\n    \"\"\"\n    Solves a single time step using Backward Euler and Newton-Raphson.\n\n    Args:\n        p_n: Value of p at the beginning of the step.\n        t_n: Time at the beginning of the step.\n        dt: Time step size.\n\n    Returns:\n        A tuple containing the new value of p and a status string \n        ('success', 'failure_stall', 'failure_singular', 'failure_max_iter').\n    \"\"\"\n    t_np1 = t_n + dt\n    eps_np1 = epsilon(t_np1)\n    \n    x_k = p_n  # Initial guess for p_{n+1}\n    res_hist = []\n\n    for k in range(NR_MAX_ITER):\n        f_val = f_overstress(x_k, eps_np1)\n        \n        if f_val = 0:  # Elastic case\n            residual = x_k - p_n\n            tangent = 1.0\n        else:  # Plastic case\n            f_pow_m = f_val**M\n            f_pow_m1 = f_val**(M - 1.0)\n            residual = x_k - p_n - (dt / ETA) * f_pow_m\n            tangent = 1.0 - (dt / ETA) * M * f_pow_m1 * df_dp(x_k, eps_np1)\n\n        abs_res = abs(residual)\n        res_hist.append(abs_res)\n        \n        if abs_res  NR_TOL:\n            return x_k, 'success'\n        \n        if k >= NR_STALL_WINDOW:\n            if res_hist[k] >= NR_STALL_FACTOR * res_hist[k - NR_STALL_WINDOW]:\n                return p_n, 'failure_stall'\n\n        if abs(tangent)  1e-12: # Avoid division by zero\n            return p_n, 'failure_singular'\n\n        x_k -= residual / tangent\n\n    return p_n, 'failure_max_iter'\n\n\ndef get_adaptive_dt(p_n: float, t_n: float, dt_old: float) -> float:\n    \"\"\"Computes a reduced time step using the derived heuristic.\"\"\"\n    eps_np1 = epsilon(t_n + dt_old)\n    f_est = f_overstress(p_n, eps_np1)\n    \n    if f_est = 0:\n        return 0.5 * dt_old\n\n    k_local = (M * df_dp(p_n, eps_np1) / ETA) * (f_est**(M - 1.0))\n    \n    if k_local = 1e-12: # If stiffness is negligible, just bisect\n        return 0.5 * dt_old\n    \n    dt_safe = ADAPTIVE_SAFETY_FACTOR / k_local\n    return min(0.5 * dt_old, dt_safe)\n\n\n# --- Driver Functions for Tests ---\n\ndef run_fixed_step_solver(dt: float) -> tuple[float, int]:\n    \"\"\"Runs the simulation with a fixed time step.\"\"\"\n    t = 0.0\n    p = 0.0\n    num_failures = 0\n    \n    while t  T_FINAL:\n        current_dt = min(dt, T_FINAL - t)\n        if current_dt  1e-12: break\n\n        p_new, status = solve_step_be(p, t, current_dt)\n        \n        if status != 'success':\n            num_failures += 1\n        \n        t += current_dt\n        p = p_new\n        \n    return p, num_failures\n\n\ndef run_adaptive_solver(dt_init: float) -> int:\n    \"\"\"Runs the simulation with adaptive time stepping.\"\"\"\n    t = 0.0\n    p = 0.0\n    dt = dt_init\n    num_cuts = 0\n\n    while t  T_FINAL:\n        current_dt_trial = min(dt, T_FINAL - t)\n\n        step_succeeded = False\n        while not step_succeeded:\n            if current_dt_trial  MIN_DT:\n                raise RuntimeError(\"Adaptive time step fell below minimum threshold.\")\n\n            p_new, status = solve_step_be(p, t, current_dt_trial)\n            \n            if status == 'success':\n                t += current_dt_trial\n                p = p_new\n                dt = current_dt_trial  # Use successful step for next trial\n                step_succeeded = True\n            else:\n                num_cuts += 1\n                dt_new = get_adaptive_dt(p, t, current_dt_trial)\n                current_dt_trial = dt_new\n                \n    return num_cuts\n\ndef solve():\n    \"\"\"\n    Main function to execute all tests and print the final results.\n    \"\"\"\n    # Test A: Accuracy check against a reference solution\n    p_ref, _ = run_fixed_step_solver(dt=1e-4)\n    p_test_a, _ = run_fixed_step_solver(dt=2e-3)\n    result_a = abs(p_test_a - p_ref)\n\n    # Test B: Robustness check with medium fixed step\n    _, failures_b = run_fixed_step_solver(dt=2e-2)\n    result_b = 1 if failures_b > 0 else 0\n\n    # Test C: Robustness check with large fixed step\n    _, failures_c = run_fixed_step_solver(dt=2e-1)\n    result_c = 1 if failures_c > 0 else 0\n    \n    # Test D: Effectiveness of adaptive stepping\n    result_d = run_adaptive_solver(dt_init=2e-1)\n\n    results = [result_a, result_b, result_c, result_d]\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the solution\nif __name__ == \"__main__\":\n    solve()\n\n```"
        }
    ]
}