{
    "hands_on_practices": [
        {
            "introduction": "高斯-高斯共轭模型因其具有解析上的易处理性，是贝叶斯分析的基石之一。本练习将引导你超越简单的后验推导，深入探讨一个至关重要的实践问题：我们的推断结论在多大程度上受到初始信念（即先验分布）的影响？通过亲手实现一个对先验超参数的敏感性分析 ，你将具体地理解先验知识与新观测数据之间的相互作用，这是贝叶斯建模艺术中的核心一环。",
            "id": "3502949",
            "problem": "对一个沉积岩试样进行了一系列单轴压缩试验，以估算其杨氏模量 $E$（单位：$\\mathrm{GPa}$），用于计算地质力学模拟。在线性弹性范围内的测量方案产生了 $n$ 个独立的比值 $y_i = \\sigma_i / \\varepsilon_i$，这些比值作为真实模量 $E$ 的带噪声的观测值，其中 $\\sigma_i$ 是轴向应力，$\\varepsilon_i$ 是轴向应变。仪器和校准报告指定了一个近似高斯的测量误差模型：给定真实模量 $E$ 时，每个观测值 $y_i$ 的条件分布为 $y_i \\mid E \\sim \\mathcal{N}(E,\\sigma^2)$，其中方差 $\\sigma^2$（单位：$\\mathrm{GPa}^2$）已知。$E$ 的先验分布被假定为高斯分布 $E \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2)$，其中 $(\\mu_0,\\sigma_0)$ 是编码关于 $E$ 的先验信念的超参数。\n\n从贝叶斯定理以及高斯似然和高斯先验的定义出发，推导一个算法以实现以下目标：\n- 在上述高斯-高斯模型下，根据观测值 $\\{y_i\\}_{i=1}^n$ 和超参数 $(\\mu_0,\\sigma_0)$ 计算 $E$ 的后验分布。\n- 计算 $E$ 的后验均值（单位：$\\mathrm{GPa}$）以及后验均值相对于先验超参数 $(\\mu_0,\\sigma_0)$ 的局部敏感度，该敏感度定义为偏导数 $\\partial \\mathbb{E}[E \\mid \\{y_i\\}] / \\partial \\mu_0$ 和 $\\partial \\mathbb{E}[E \\mid \\{y_i\\}] / \\partial \\sigma_0$。这些导数是无量纲的。\n\n似然函数使用以下数据集和测量方差：\n- 观测值（单位：$\\mathrm{GPa}$）：$y = [\\,24.8,\\,25.1,\\,25.5,\\,24.9,\\,25.0,\\,25.3,\\,24.7,\\,25.2\\,]$。\n- 已知测量标准差：$\\sigma = 0.5$（因此测量方差为 $\\sigma^2 = 0.25$，单位：$\\mathrm{GPa}^2$）。\n\n通过对以下先验超参数和样本大小的测试套件评估后验均值及其局部敏感度，进行敏感度分析：\n1. 基准，中等信息量的先验，全样本：$(\\mu_0,\\sigma_0) = (25.0\\,\\mathrm{GPa},\\,2.0\\,\\mathrm{GPa})$，$n = 8$。\n2. 高信息量且有偏的先验，全样本：$(\\mu_0,\\sigma_0) = (35.0\\,\\mathrm{GPa},\\,0.5\\,\\mathrm{GPa})$，$n = 8$。\n3. 非常模糊的先验，全样本：$(\\mu_0,\\sigma_0) = (20.0\\,\\mathrm{GPa},\\,10.0\\,\\mathrm{GPa})$，$n = 8$。\n4. 基准先验，小样本边缘情况（使用前 $n$ 个观测值）：$(\\mu_0,\\sigma_0) = (25.0\\,\\mathrm{GPa},\\,2.0\\,\\mathrm{GPa})$，$n = 2$。\n5. 接近正确、信息量极高的先验，全样本：$(\\mu_0,\\sigma_0) = (25.1\\,\\mathrm{GPa},\\,0.1\\,\\mathrm{GPa})$，$n = 8$。\n\n科学真实性要求：\n- 将 $E$ 视为一个连续的标量参数。\n- 将 $\\sigma^2$ 视为通过校准已知的固定值，不要对其进行估计。\n- 适用时，所有计算中模量的单位必须为 $\\mathrm{GPa}$，方差的单位必须为 $\\mathrm{GPa}^2$。\n- 局部敏感度是无量纲的。\n\n您的程序必须实现所推导的算法，并为每个测试用例生成单行输出，其中包含一个含有三个浮点数的列表：\n- $E$ 的后验均值，单位为 $\\mathrm{GPa}$，四舍五入到六位小数。\n- 后验均值相对于 $\\mu_0$ 的局部敏感度，四舍五入到六位小数。\n- 后验均值相对于 $\\sigma_0$ 的局部敏感度，四舍五入到六位小数。\n\n最终输出格式：\n- 单行输出，包含一个逗号分隔的列表，其中每个元素是对应测试用例的结果。每个结果本身是一个包含三个浮点数的列表，所有内容都用方括号括起来。例如：$[\\,[m_1,s_{\\mu,1},s_{\\sigma_0,1}],\\,[m_2,s_{\\mu,2},s_{\\sigma_0,2}],\\,\\dots\\,]$。\n- 后验均值必须以 $\\mathrm{GPa}$ 为单位表示，敏感度必须是无量纲的。",
            "solution": "该问题要求推导一个算法，用于对杨氏模量参数 $E$ 进行贝叶斯更新，并随后计算后验均值及其相对于先验超参数的敏感度。该模型假设测量数据服从高斯似然，参数 $E$ 服从高斯先验。这是一个经典的共轭先验模型示例。\n\n首先，我们基于贝叶斯定理建立数学框架。给定一组 $n$ 个独立观测值 $\\{y_i\\}_{i=1}^n$ 时，参数 $E$ 的后验概率分布正比于给定参数时数据的似然与参数先验分布的乘积：\n$$ p(E \\mid \\{y_i\\}_{i=1}^n) \\propto p(\\{y_i\\}_{i=1}^n \\mid E) \\cdot p(E) $$\n\n问题指定了以下分布：\n1.  **似然**：每个观测值 $y_i$ 均来自均值为 $E$、已知方差为 $\\sigma^2$ 的正态分布。由于观测值是独立的，联合似然是各个似然的乘积：\n    $$ p(\\{y_i\\} \\mid E) = \\prod_{i=1}^n \\mathcal{N}(y_i \\mid E, \\sigma^2) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - E)^2}{2\\sigma^2}\\right) $$\n    $$ p(\\{y_i\\} \\mid E) = (2\\pi\\sigma^2)^{-n/2} \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i - E)^2\\right) $$\n\n2.  **先验**：关于 $E$ 的先验信念被建模为具有超参数 $\\mu_0$（先验均值）和 $\\sigma_0^2$（先验方差）的正态分布：\n    $$ p(E) = \\mathcal{N}(E \\mid \\mu_0, \\sigma_0^2) = \\frac{1}{\\sqrt{2\\pi\\sigma_0^2}} \\exp\\left(-\\frac{(E - \\mu_0)^2}{2\\sigma_0^2}\\right) $$\n\n为了求得后验分布，我们将似然和先验结合起来。我们关注指数项，因为归一化常数与 $E$ 无关：\n$$ p(E \\mid \\{y_i\\}) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i - E)^2\\right) \\exp\\left(-\\frac{(E - \\mu_0)^2}{2\\sigma_0^2}\\right) $$\n$$ p(E \\mid \\{y_i\\}) \\propto \\exp\\left( -\\frac{1}{2} \\left[ \\frac{\\sum_{i=1}^n (y_i - E)^2}{\\sigma^2} + \\frac{(E - \\mu_0)^2}{\\sigma_0^2} \\right] \\right) $$\n\n指数中的表达式是 $E$ 的一个二次函数。这意味着后验分布也是一个正态分布，我们设为 $E \\mid \\{y_i\\} \\sim \\mathcal{N}(\\mu_n, \\sigma_n^2)$。为了找到其参数 $\\mu_n$ 和 $\\sigma_n^2$，我们可以对指数中的 $E$ 进行配方。\n设指数为 $-\\frac{1}{2} Q(E)$。展开 $Q(E)$ 中的各项：\n$$ Q(E) = \\frac{1}{\\sigma^2}\\sum_{i=1}^n (y_i^2 - 2y_iE + E^2) + \\frac{1}{\\sigma_0^2}(E^2 - 2E\\mu_0 + \\mu_0^2) $$\n按 $E$ 的幂次对各项进行分组：\n$$ Q(E) = E^2\\left(\\frac{n}{\\sigma^2} + \\frac{1}{\\sigma_0^2}\\right) - 2E\\left(\\frac{\\sum y_i}{\\sigma^2} + \\frac{\\mu_0}{\\sigma_0^2}\\right) + \\text{const} $$\n对于一个正态分布 $\\mathcal{N}(\\mu_n, \\sigma_n^2)$，其指数项为 $-\\frac{(E-\\mu_n)^2}{2\\sigma_n^2} = -\\frac{1}{2}\\left(\\frac{E^2}{\\sigma_n^2} - \\frac{2E\\mu_n}{\\sigma_n^2} + \\frac{\\mu_n^2}{\\sigma_n^2}\\right)$。通过匹配 $E^2$ 的系数，我们得到后验方差的倒数（即后验精度）：\n$$ \\frac{1}{\\sigma_n^2} = \\frac{n}{\\sigma^2} + \\frac{1}{\\sigma_0^2} $$\n因此，后验方差 $\\sigma_n^2$ 为：\n$$ \\sigma_n^2 = \\left(\\frac{n}{\\sigma^2} + \\frac{1}{\\sigma_0^2}\\right)^{-1} = \\frac{\\sigma^2\\sigma_0^2}{n\\sigma_0^2 + \\sigma^2} $$\n\n通过匹配 $E$ 的系数，我们求得后验均值 $\\mu_n$：\n$$ \\frac{\\mu_n}{\\sigma_n^2} = \\frac{\\sum y_i}{\\sigma^2} + \\frac{\\mu_0}{\\sigma_0^2} $$\n令 $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i$ 为观测值的样本均值。\n$$ \\mu_n = \\sigma_n^2 \\left(\\frac{n\\bar{y}}{\\sigma^2} + \\frac{\\mu_0}{\\sigma_0^2}\\right) $$\n代入 $\\sigma_n^2$ 的表达式：\n$$ \\mu_n = \\left(\\frac{\\sigma^2\\sigma_0^2}{n\\sigma_0^2 + \\sigma^2}\\right) \\left(\\frac{n\\bar{y}\\sigma_0^2 + \\mu_0\\sigma^2}{\\sigma^2\\sigma_0^2}\\right) = \\frac{n\\bar{y}\\sigma_0^2 + \\mu_0\\sigma^2}{n\\sigma_0^2 + \\sigma^2} $$\n\n后验均值，记作 $M(\\mu_0, \\sigma_0) = \\mathbb{E}[E \\mid \\{y_i\\}] = \\mu_n$，是我们需要计算局部敏感度的量。\n$$ M(\\mu_0, \\sigma_0) = \\frac{n\\bar{y}\\sigma_0^2 + \\mu_0\\sigma^2}{n\\sigma_0^2 + \\sigma^2} $$\n\n接下来，我们推导 $M$ 相对于先验超参数 $\\mu_0$ 和 $\\sigma_0$ 的偏导数。\n\n1.  **相对于 $\\mu_0$ 的敏感度**：我们将 $M$ 对 $\\mu_0$ 求导，将所有其他变量（$n, \\bar{y}, \\sigma^2, \\sigma_0$）视为常数。\n    $$ \\frac{\\partial M}{\\partial \\mu_0} = \\frac{\\partial}{\\partial \\mu_0} \\left( \\frac{n\\bar{y}\\sigma_0^2 + \\mu_0\\sigma^2}{n\\sigma_0^2 + \\sigma^2} \\right) = \\frac{1}{n\\sigma_0^2 + \\sigma^2} \\cdot \\frac{\\partial}{\\partial \\mu_0} (n\\bar{y}\\sigma_0^2 + \\mu_0\\sigma^2) $$\n    $$ \\frac{\\partial M}{\\partial \\mu_0} = \\frac{\\sigma^2}{n\\sigma_0^2 + \\sigma^2} $$\n\n2.  **相对于 $\\sigma_0$ 的敏感度**：我们将 $M$ 对 $\\sigma_0$ 求导。这需要使用商法则。令 $u(\\sigma_0) = n\\bar{y}\\sigma_0^2 + \\mu_0\\sigma^2$ 且 $v(\\sigma_0) = n\\sigma_0^2 + \\sigma^2$。它们对 $\\sigma_0$ 的导数分别为 $\\frac{\\partial u}{\\partial \\sigma_0} = 2n\\bar{y}\\sigma_0$ 和 $\\frac{\\partial v}{\\partial \\sigma_0} = 2n\\sigma_0$。\n    $$ \\frac{\\partial M}{\\partial \\sigma_0} = \\frac{v \\frac{\\partial u}{\\partial \\sigma_0} - u \\frac{\\partial v}{\\partial \\sigma_0}}{v^2} = \\frac{(n\\sigma_0^2 + \\sigma^2)(2n\\bar{y}\\sigma_0) - (n\\bar{y}\\sigma_0^2 + \\mu_0\\sigma^2)(2n\\sigma_0)}{(n\\sigma_0^2 + \\sigma^2)^2} $$\n    展开分子：\n    $$ (2n^2\\bar{y}\\sigma_0^3 + 2n\\bar{y}\\sigma_0\\sigma^2) - (2n^2\\bar{y}\\sigma_0^3 + 2n\\mu_0\\sigma_0\\sigma^2) $$\n    $$ = 2n\\bar{y}\\sigma_0\\sigma^2 - 2n\\mu_0\\sigma_0\\sigma^2 = 2n\\sigma_0\\sigma^2(\\bar{y} - \\mu_0) $$\n    相对于 $\\sigma_0$ 的敏感度的最终表达式是：\n    $$ \\frac{\\partial M}{\\partial \\sigma_0} = \\frac{2n\\sigma_0\\sigma^2(\\bar{y} - \\mu_0)}{(n\\sigma_0^2 + \\sigma^2)^2} $$\n\n需要实现的算法如下：\n对于每个具有给定先验超参数 $(\\mu_0, \\sigma_0)$ 和样本大小 $n$ 的测试用例：\n1.  从数据集中选择前 $n$ 个观测值，并计算样本均值 $\\bar{y}$。\n2.  使用给定的测量标准差 $\\sigma$ 来计算方差 $\\sigma^2$。\n3.  使用推导出的公式计算后验均值 $M$。\n4.  计算敏感度 $\\frac{\\partial M}{\\partial \\mu_0}$。\n5.  计算敏感度 $\\frac{\\partial M}{\\partial \\sigma_0}$。\n6.  存储得到的三个浮点数。\n所有单位必须保持一致（模量为 $\\mathrm{GPa}$，方差为 $\\mathrm{GPa}^2$）。从推导的公式中可以验证，敏感度是无量纲的。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian inference problem for Young's modulus,\n    calculating the posterior mean and its sensitivities for several test cases.\n    \"\"\"\n\n    # Full dataset of observations for Young's modulus E, in GPa.\n    y_full = np.array([24.8, 25.1, 25.5, 24.9, 25.0, 25.3, 24.7, 25.2])\n\n    # Known measurement standard deviation in GPa.\n    sigma = 0.5\n\n    # Test suite of prior hyperparameters (mu_0, sigma_0) and sample sizes (n).\n    test_cases = [\n        # (mu_0 [GPa], sigma_0 [GPa], n)\n        (25.0, 2.0, 8),  # 1. Baseline, moderately informative prior, full sample\n        (35.0, 0.5, 8),  # 2. Highly informative and biased prior, full sample\n        (20.0, 10.0, 8), # 3. Very vague prior, full sample\n        (25.0, 2.0, 2),  # 4. Baseline prior, small sample edge case\n        (25.1, 0.1, 8),  # 5. Near-correct, extremely informative prior, full sample\n    ]\n\n    all_results = []\n\n    for mu_0, sigma_0, n in test_cases:\n        # 1. Prepare data for the current case\n        # Use the first n observations from the full dataset.\n        y_obs = y_full[:n]\n        # Calculate the sample mean (y_bar).\n        y_bar = np.mean(y_obs)\n\n        # 2. Calculate intermediate quantities based on derived formulas\n        # Measurement variance (sigma^2).\n        sigma_sq = sigma**2\n        # Prior variance (sigma_0^2).\n        sigma0_sq = sigma_0**2\n        \n        # Common denominator in the expressions for posterior mean and sensitivities.\n        denominator = n * sigma0_sq + sigma_sq\n        \n        # 3. Compute posterior mean and sensitivities\n        # Posterior mean of E, denoted as M.\n        # M = (n * y_bar * sigma_0^2 + mu_0 * sigma^2) / (n * sigma_0^2 + sigma^2)\n        posterior_mean = (n * y_bar * sigma0_sq + mu_0 * sigma_sq) / denominator\n        \n        # Sensitivity of the posterior mean with respect to the prior mean (mu_0).\n        # S_mu0 = sigma^2 / (n * sigma_0^2 + sigma^2)\n        sensitivity_mu0 = sigma_sq / denominator\n        \n        # Sensitivity of the posterior mean with respect to the prior std. dev. (sigma_0).\n        # S_sigma0 = (2 * n * sigma_0 * sigma^2 * (y_bar - mu_0)) / (n * sigma_0^2 + sigma^2)^2\n        sensitivity_sigma0 = (2 * n * sigma_0 * sigma_sq * (y_bar - mu_0)) / (denominator**2)\n\n        # 4. Round results to six decimal places as required.\n        m_rounded = round(posterior_mean, 6)\n        s_mu0_rounded = round(sensitivity_mu0, 6)\n        s_sigma0_rounded = round(sensitivity_sigma0, 6)\n\n        # Append the list of results for the current test case.\n        all_results.append([m_rounded, s_mu0_rounded, s_sigma0_rounded])\n\n    # 5. Format and print the final output\n    # The required format is a string representation of a list of lists,\n    # with no whitespace. Example: [[a,b,c],[d,e,f]]\n    final_output_string = str(all_results).replace(' ', '')\n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "现实世界中的岩土力学模型，如经典的莫尔-库仑（Mohr-Coulomb）准则，通常是复杂的非线性模型，无法直接套用简单的共轭分布框架。在这种情况下，我们无法写出后验分布的简单解析表达式。本实践将介绍一种强大的替代技术：通过数值优化方法寻找后验概率最大（Maximum A Posteriori, MAP）的点估计值 。你将把这一技术应用于一个非常实际的工程场景——从三轴试验数据中推断岩土材料的强度参数。",
            "id": "3502946",
            "problem": "您必须实现一个完整的程序，通过对峰值强度的似然和由地质背景信息决定的先验进行建模，来对轴对称三轴压缩试验的莫尔–库仑参数执行贝叶斯更新，然后计算黏聚力和摩擦角的后验概率最大化（MAP）估计。未知参数是黏聚力 $c$（单位：千帕，kPa）和摩擦角 $\\phi$（单位：度）。该估计必须作为测试套件对多个数据集执行，每个数据集包含在指定围压下的峰值强度观测值。您的程序必须处理所有数据集，计算 $(c,\\phi)$ 的后验众数（使用物理上有意义的单位），并以指定格式生成单行输出。\n\n基本背景：\n- 莫尔–库仑破坏准则被用作三轴压缩破坏时峰值强度的本构基础。对于围压为 $\\sigma_3$（单位：kPa）和破坏时偏应力为 $q = \\sigma_1 - \\sigma_3$（单位：kPa）的轴对称三轴试验，由黏聚力 $c$ 和摩擦角 $\\phi$ 的莫尔–库仑准则预测的峰值偏应力为\n$$\nq(c,\\phi,\\sigma_3) = \\frac{2\\,c\\,\\cos\\phi_r}{1 - \\sin\\phi_r} + \\frac{2\\,\\sigma_3\\,\\sin\\phi_r}{1 - \\sin\\phi_r},\n$$\n其中 $\\phi_r$ 是以弧度表示的摩擦角，$\\phi$ 是以度表示的；因此，$\\phi_r = \\phi \\times \\pi/180$。\n- 贝叶斯推断使用贝叶斯法则进行，该法则指出给定数据的 $(c,\\phi)$ 的后验密度与似然乘以先验成正比。后验概率最大化（MAP）估计是后验概率的最大化者。\n\n似然和先验的建模假设：\n- 似然：对于由 $j$ 索引的每个数据集，其在围压 $\\{\\sigma_{3,j,i}\\}_{i=1}^{n_j}$ 下观测到的峰值偏应力为 $\\{q_{j,i}^{\\text{obs}}\\}_{i=1}^{n_j}$，假设独立的、已知标准差为 $s_j$（单位：kPa）的高斯测量误差，因此\n$$\nq_{j,i}^{\\text{obs}} = q(c,\\phi,\\sigma_{3,j,i}) + \\epsilon_{j,i}, \\quad \\epsilon_{j,i} \\sim \\mathcal{N}(0, s_j^2).\n$$\n- 关于 $c$ 的先验：假设一个由 $\\log c \\sim \\mathcal{N}(\\mu_{c,j}, \\sigma_{c,j}^2)$ 指定的对数正态先验，这强制 $c > 0$。\n- 关于 $\\phi$ 的先验：假设一个高斯先验 $\\phi \\sim \\mathcal{N}(\\mu_{\\phi,j}, \\sigma_{\\phi,j}^2)$，截断到物理上合理的区间 $[\\phi_{\\min,j}, \\phi_{\\max,j}]$（单位：度）。视 $(c,\\phi)$ 为先验独立的。\n\n您的任务：\n- 对于测试套件中的每个数据集，通过在 $c > 0$ 和 $\\phi \\in [\\phi_{\\min}, \\phi_{\\max}]$ 上数值最大化后验密度，计算 MAP 估计 $(c_{\\text{MAP}}, \\phi_{\\text{MAP}})$。如果您通过最小化负对数后验来实现，请确保适当地处理边界和数值稳定性。\n- $c_{\\text{MAP}}$ 的最终值以 kPa 表示，$\\phi_{\\text{MAP}}$ 的最终值以度表示。最终输出中的角度必须是度。输入无需单位转换，因为它们已经以 kPa 和度为单位提供。\n\n测试套件：\n- 数据集 $1$（类砂土，中等黏聚力）：\n    - 围压 $\\sigma_{3,1} = [$ $100$, $300$, $600$ $]$ kPa。\n    - 观测到的峰值偏应力 $q_{1}^{\\text{obs}} = [$ $304.0$, $704.0$, $1302.0$ $]$ kPa。\n    - 观测噪声标准差 $s_1 = $ $20.0$ kPa。\n    - 先验超参数：$\\mu_{c,1} = \\log($ $25.0$ $)$, $\\sigma_{c,1} = $ $0.4$; $\\mu_{\\phi,1} = $ $32.0$ 度, $\\sigma_{\\phi,1} = $ $5.0$ 度; 截断边界 $[\\phi_{\\min,1}, \\phi_{\\max,1}] = [$ $15.0$, $45.0$ $]$ 度。\n- 数据集 $2$（纯净砂，黏聚力接近零）：\n    - 围压 $\\sigma_{3,2} = [$ $50$, $150$, $300$ $]$ kPa。\n    - 观测到的峰值偏应力 $q_{2}^{\\text{obs}} = [$ $154.0$, $420.0$, $832.0$ $]$ kPa。\n    - 观测噪声标准差 $s_2 = $ $15.0$ kPa。\n    - 先验超参数：$\\mu_{c,2} = \\log($ $3.0$ $)$, $\\sigma_{c,2} = $ $0.5$; $\\mu_{\\phi,2} = $ $35.0$ 度, $\\sigma_{\\phi,2} = $ $3.0$ 度; 截断边界 $[\\phi_{\\min,2}, \\phi_{\\max,2}] = [$ $20.0$, $50.0$ $]$ 度。\n- 数据集 $3$（类黏土，较高黏聚力，较低摩擦角，数据较弱）：\n    - 围压 $\\sigma_{3,3} = [$ $50$, $150$, $300$ $]$ kPa。\n    - 观测到的峰值偏应力 $q_{3}^{\\text{obs}} = [$ $340.0$, $430.0$, $610.0$ $]$ kPa。\n    - 观测噪声标准差 $s_3 = $ $50.0$ kPa。\n    - 先验超参数：$\\mu_{c,3} = \\log($ $120.0$ $)$, $\\sigma_{c,3} = $ $0.3$; $\\mu_{\\phi,3} = $ $18.0$ 度, $\\sigma_{\\phi,3} = $ $4.0$ 度; 截断边界 $[\\phi_{\\min,3}, \\phi_{\\max,3}] = [$ $12.0$, $35.0$ $]$ 度。\n\n算法和数值要求：\n- 使用一个稳健的、能够处理 $c$ 和 $\\phi$ 边界的数值优化器。使用从先验超参数派生的多个初始猜测值，以减轻局部最优问题。\n- 实现对数似然、$c$ 的对数先验（对数正态）和 $\\phi$ 的对数先验（在给定区间上截断的高斯分布），以及最终的对数后验。您可以省略不依赖于 $(c,\\phi)$ 的加性常数，因为它们不影响 MAP。\n- 确保在三角函数中使用 $\\phi$ 时将其转换为弧度，并在输出时保持为度。\n- 强制 $c > 0$ 和 $\\phi_{\\min} \\le \\phi \\le \\phi_{\\max}$。\n\n最终输出规范：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个数据集的输出应为一个二元列表 $[c_{\\text{MAP}}, \\phi_{\\text{MAP}}]$，其中 $c_{\\text{MAP}}$ 以 kPa 为单位，$\\phi_{\\text{MAP}}$ 以度为单位，两者均四舍五入到三位小数。例如，输出必须看起来像\n[$[$ $c_1$ $,$ $\\phi_1$ $]$ $,$ $[$ $c_2$ $,$ $\\phi_2$ $]$ $,$ $[$ $c_3$ $,$ $\\phi_3$ $]$]\n并用实际数值替换。\n\n您的程序必须是完全自包含的，不需要用户输入，并严格遵守指定的执行环境。您的程序产生的最终答案必须是指定格式的浮点数或浮点数列表。",
            "solution": "该问题要求给定三轴试验的实验数据，找到莫尔–库仑参数——黏聚力 $c$ 和摩擦角 $\\phi$ 的后验概率最大化（MAP）估计。这是通过最大化后验概率密度函数 $p(c, \\phi | \\text{data})$ 来实现的，根据贝叶斯法则，该函数与似然和先验概率的乘积成正比：\n\n$$\np(c, \\phi | \\text{data}) \\propto p(\\text{data} | c, \\phi) \\cdot p(c, \\phi)\n$$\n\n参数 $c$ 和 $\\phi$ 被假定为先验独立的，所以 $p(c, \\phi) = p(c) \\cdot p(\\phi)$。最大化后验密度等同于最大化其对数（即对数后验），或最小化其负数（即负对数后验）。后者因其数值稳定性而常被优先选择。我们将用作目标函数 $F(c, \\phi)$ 来最小化的负对数后验是：\n\n$$\nF(c, \\phi) = -\\log[p(\\text{data} | c, \\phi)] - \\log[p(c)] - \\log[p(\\phi)]\n$$\n\n让我们为通用数据集 $j$ 定义每一项。待估计的参数是 $(c, \\phi)$，数据由 $n_j$ 对观测到的峰值偏应力 $\\{q_{j,i}^{\\text{obs}}\\}$ 和相应的围压 $\\{\\sigma_{3,j,i}\\}$ 组成。\n\n**1. 似然项**\n\n预测的峰值偏应力模型由莫尔–库仑破坏准则给出：\n$$\nq_{\\text{pred}}(c, \\phi, \\sigma_3) = \\frac{2c\\cos\\phi_r}{1 - \\sin\\phi_r} + \\frac{2\\sigma_3\\sin\\phi_r}{1 - \\sin\\phi_r}\n$$\n其中 $\\phi_r = \\phi \\cdot \\pi/180$ 是以弧度表示的摩擦角。\n\n观测值被假定为受到独立同分布的高斯噪声的干扰， $q_{j,i}^{\\text{obs}} = q_{\\text{pred}}(c, \\phi, \\sigma_{3,j,i}) + \\epsilon_{j,i}$，其中 $\\epsilon_{j,i} \\sim \\mathcal{N}(0, s_j^2)$。单个观测值 $q_{j,i}^{\\text{obs}}$ 的概率密度为：\n$$\np(q_{j,i}^{\\text{obs}} | c, \\phi) = \\frac{1}{\\sqrt{2\\pi s_j^2}} \\exp\\left(-\\frac{(q_{j,i}^{\\text{obs}} - q_{\\text{pred}}(c, \\phi, \\sigma_{3,j,i}))^2}{2s_j^2}\\right)\n$$\n由于观测值是独立的，总似然是各个密度的乘积。对数似然是各个对数密度的和：\n$$\n\\log[p(\\text{data}_j | c, \\phi)] = \\sum_{i=1}^{n_j} \\left( -\\frac{1}{2}\\log(2\\pi s_j^2) - \\frac{(q_{j,i}^{\\text{obs}} - q_{\\text{pred}}(c, \\phi, \\sigma_{3,j,i}))^2}{2s_j^2} \\right)\n$$\n为了优化，我们可以省略常数项 $-\\frac{n_j}{2}\\log(2\\pi s_j^2)$。要最小化的负对数似然项与误差平方和成正比：\n$$\n-\\log[p(\\text{data}_j | c, \\phi)] \\propto \\frac{1}{2s_j^2} \\sum_{i=1}^{n_j} (q_{j,i}^{\\text{obs}} - q_{\\text{pred}}(c, \\phi, \\sigma_{3,j,i}))^2\n$$\n\n**2. 黏聚力 $c$ 的先验项**\n\n黏聚力 $c$ 被赋予一个对数正态先验，由 $\\log c \\sim \\mathcal{N}(\\mu_{c,j}, \\sigma_{c,j}^2)$ 指定。$c$ 的概率密度函数是：\n$$\np(c) = \\frac{1}{c\\sigma_{c,j}\\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\log c - \\mu_{c,j})^2}{2\\sigma_{c,j}^2}\\right) \\quad \\text{for } c > 0\n$$\n对数先验是：\n$$\n\\log[p(c)] = -\\log c - \\frac{1}{2}\\log(2\\pi\\sigma_{c,j}^2) - \\frac{(\\log c - \\mu_{c,j})^2}{2\\sigma_{c,j}^2}\n$$\n省略常数项 $-\\frac{1}{2}\\log(2\\pi\\sigma_{c,j}^2)$，要最小化的 $c$ 的负对数先验项为：\n$$\n-\\log[p(c)] \\propto \\log c + \\frac{(\\log c - \\mu_{c,j})^2}{2\\sigma_{c,j}^2}\n$$\n\n**3. 摩擦角 $\\phi$ 的先验项**\n\n摩擦角 $\\phi$ 被赋予一个高斯先验，$\\phi \\sim \\mathcal{N}(\\mu_{\\phi,j}, \\sigma_{\\phi,j}^2)$，截断在区间 $[\\phi_{\\min,j}, \\phi_{\\max,j}]$ 内。其概率密度函数为：\n$$\np(\\phi) = \\begin{cases} \\frac{1}{Z} \\frac{1}{\\sigma_{\\phi,j}\\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\phi - \\mu_{\\phi,j})^2}{2\\sigma_{\\phi,j}^2}\\right)  \\text{if } \\phi \\in [\\phi_{\\min,j}, \\phi_{\\max,j}] \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n其中 $Z$ 是一个归一化常数，确保密度在区间上的积分为 $1$。由于 $Z$ 不依赖于 $\\phi$，它在对数后验中是一个加性常数，在优化过程中可以忽略。因此，要最小化的负对数先验项为：\n$$\n-\\log[p(\\phi)] \\propto \\frac{(\\phi - \\mu_{\\phi,j})^2}{2\\sigma_{\\phi,j}^2}\n$$\n截断约束 $\\phi \\in [\\phi_{\\min,j}, \\phi_{\\max,j}]$ 将在数值优化中作为边界来强制执行。\n\n**4. 完整的目标函数和优化策略**\n\n结合所有项，对于每个数据集 $j$ 要最小化的完整目标函数 $F(c, \\phi)$ 是：\n$$\nF(c, \\phi) = \\frac{1}{2s_j^2} \\sum_{i=1}^{n_j} (q_{j,i}^{\\text{obs}} - q_{\\text{pred}}(c, \\phi, \\sigma_{3,j,i}))^2 + \\log c + \\frac{(\\log c - \\mu_{c,j})^2}{2\\sigma_{c,j}^2} + \\frac{(\\phi - \\mu_{\\phi,j})^2}{2\\sigma_{\\phi,j}^2}\n$$\n此最小化过程受限于箱形约束 $c > 0$ 和 $\\phi_{\\min,j} \\le \\phi \\le \\phi_{\\max,j}$。对于数值实现，为了避免计算 $\\log(0)$， $c$ 的下界被设置为一个小的正值（例如，$10^{-9}$），而上界可以不加约束。\n\n我们将使用一个能够处理箱形约束的数值优化算法，具体是 `scipy.optimize.minimize` 中可用的 L-BFGS-B 算法。为增加找到全局最小值的可能性，我们将从多个初始点开始优化。这些点是根据先验分布系统地选择的：一个点在先验均值 $(\\exp(\\mu_{c,j}), \\mu_{\\phi,j})$，其他点在一个标准差之外，并确保它们在指定边界内。解 $(c_{\\text{MAP}}, \\phi_{\\text{MAP}})$ 是在所有尝试中产生目标函数 $F(c, \\phi)$ 最小值的那个。最终结果将四舍五入并以指定格式呈现。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Performs Bayesian MAP estimation of Mohr-Coulomb parameters for three datasets.\n    \"\"\"\n\n    # Define the three test cases as specified in the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Dataset 1\",\n            \"sigma3\": np.array([100.0, 300.0, 600.0]),\n            \"q_obs\": np.array([304.0, 704.0, 1302.0]),\n            \"s\": 20.0,\n            \"mu_c\": np.log(25.0),\n            \"sigma_c\": 0.4,\n            \"mu_phi\": 32.0,\n            \"sigma_phi\": 5.0,\n            \"phi_bounds\": (15.0, 45.0),\n        },\n        {\n            \"name\": \"Dataset 2\",\n            \"sigma3\": np.array([50.0, 150.0, 300.0]),\n            \"q_obs\": np.array([154.0, 420.0, 832.0]),\n            \"s\": 15.0,\n            \"mu_c\": np.log(3.0),\n            \"sigma_c\": 0.5,\n            \"mu_phi\": 35.0,\n            \"sigma_phi\": 3.0,\n            \"phi_bounds\": (20.0, 50.0),\n        },\n        {\n            \"name\": \"Dataset 3\",\n            \"sigma3\": np.array([50.0, 150.0, 300.0]),\n            \"q_obs\": np.array([340.0, 430.0, 610.0]),\n            \"s\": 50.0,\n            \"mu_c\": np.log(120.0),\n            \"sigma_c\": 0.3,\n            \"mu_phi\": 18.0,\n            \"sigma_phi\": 4.0,\n            \"phi_bounds\": (12.0, 35.0),\n        },\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Extract data for the current case for clarity\n        sigma3_data = case[\"sigma3\"]\n        q_obs_data = case[\"q_obs\"]\n        s = case[\"s\"]\n        mu_c = case[\"mu_c\"]\n        sigma_c = case[\"sigma_c\"]\n        mu_phi = case[\"mu_phi\"]\n        sigma_phi = case[\"sigma_phi\"]\n        phi_min, phi_max = case[\"phi_bounds\"]\n\n        def mohr_coulomb_model(c, phi_deg, sigma3):\n            \"\"\"\n            Calculates predicted deviatoric stress q based on Mohr-Coulomb.\n            c: cohesion (kPa)\n            phi_deg: friction angle (degrees)\n            sigma3: confining pressure (kPa)\n            \"\"\"\n            phi_rad = np.deg2rad(phi_deg)\n            sin_phi = np.sin(phi_rad)\n            cos_phi = np.cos(phi_rad)\n            \n            # Avoid division by zero if phi is 90 degrees\n            if np.isclose(sin_phi, 1.0):\n                return np.inf\n            \n            denominator = 1.0 - sin_phi\n            \n            q_pred = (2 * c * cos_phi + 2 * sigma3 * sin_phi) / denominator\n            return q_pred\n\n        def neg_log_posterior(params):\n            \"\"\"\n            Objective function: negative log-posterior probability.\n            params: a list or array [c, phi]\n            \"\"\"\n            c, phi = params\n\n            # Parameter bounds check (though handled by optimizer, this adds robustness)\n            if c = 0 or not (phi_min = phi = phi_max):\n                return np.inf\n\n            # 1. Negative Log-Likelihood\n            q_pred = mohr_coulomb_model(c, phi, sigma3_data)\n            sse = np.sum((q_obs_data - q_pred)**2)\n            neg_log_likelihood = sse / (2 * s**2)\n\n            # 2. Negative Log-Prior for c (Lognormal)\n            log_c = np.log(c)\n            neg_log_prior_c = log_c + ((log_c - mu_c)**2) / (2 * sigma_c**2)\n            \n            # 3. Negative Log-Prior for phi (Truncated Normal)\n            neg_log_prior_phi = ((phi - mu_phi)**2) / (2 * sigma_phi**2)\n\n            return neg_log_likelihood + neg_log_prior_c + neg_log_prior_phi\n\n        # Define bounds for the optimizer\n        # c > 0 (practically > a small epsilon)\n        # phi_min = phi = phi_max\n        bounds = [(1e-9, None), (phi_min, phi_max)]\n\n        # Set up multiple initial guesses to improve robustness against local minima\n        initial_guesses = []\n        # Guess 1: Prior mean\n        c0_mean = np.exp(mu_c)\n        phi0_mean = mu_phi\n        initial_guesses.append([c0_mean, phi0_mean])\n        \n        # Additional guesses based on prior standard deviation\n        c0_plus_std = np.exp(mu_c + sigma_c)\n        phi0_plus_std = np.clip(mu_phi + sigma_phi, phi_min, phi_max)\n        initial_guesses.append([c0_plus_std, phi0_plus_std])\n        \n        c0_minus_std = np.exp(mu_c - sigma_c)\n        phi0_minus_std = np.clip(mu_phi - sigma_phi, phi_min, phi_max)\n        initial_guesses.append([c0_minus_std, phi0_minus_std])\n\n        best_result = None\n        min_f_val = np.inf\n\n        for x0 in initial_guesses:\n            res = minimize(\n                neg_log_posterior,\n                x0=x0,\n                method='L-BFGS-B',\n                bounds=bounds\n            )\n            if res.success and res.fun  min_f_val:\n                min_f_val = res.fun\n                best_result = res.x\n\n        # Store the MAP estimate for c and phi, rounded to three decimal places\n        if best_result is not None:\n            c_map = round(best_result[0], 3)\n            phi_map = round(best_result[1], 3)\n            results.append([c_map, phi_map])\n        else:\n            # Fallback in case of optimization failure, though unlikely with this setup\n            results.append([np.nan, np.nan])\n\n    # Format the output as per the specification\n    # e.g., [[c1,phi1],[c2,phi2],[c3,phi3]]\n    output_str = \"[\" + \",\".join([f\"[{c},{p}]\" for c, p in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "虽然最大后验（MAP）估计为我们提供了一个有用的参数点估计，但完整的贝叶斯分析旨在刻画整个后验分布，以全面量化不确定性。本练习将介绍一种前沿的马尔可夫链蒙特卡洛（MCMC）方法——哈密顿蒙特卡洛（Hamiltonian Monte Carlo, HMC），它能高效地从高维复杂后验分布中进行采样 。此练习的核心挑战在于，将HMC应用于复杂物理模型时如何高效计算后验概率的梯度，特别是当模型（如此处的弹塑性本构关系）包含非光滑或分段定义的行为时。这个实践将为你打开一扇通往计算力学与贝叶斯推断交叉领域前沿研究课题的窗户。",
            "id": "3502899",
            "problem": "考虑一个通过具有线性各向同性硬化的小应变弹塑性模型建模的等截面杆的一维准静态拉伸试验。该杆具有均匀的横截面积 $A$ 和长度 $L$。在自由端施加轴向位移 $u$，固定端 $u=0$，从而在整个杆上产生均匀的工程应变 $\\varepsilon = u/L$。柯西应力用 $\\sigma$ 表示。本构响应为弹塑性，其参数（均为严格正值）为杨氏模量 $E$、初始屈服应力 $\\sigma_y$ 和硬化模量 $H$。假设为率无关塑性、相关联流动和线性各向同性硬化；使用标准返回映射算法来施加库恩-塔克（Kuhn–Tucker）条件。\n\n给定在几个施加的末端位移下的带噪声的反力测量值。在位移 $u$ 处的反力为 $F = A \\,\\sigma(E,\\sigma_y,H;\\varepsilon)$，其中 $\\sigma$ 由应变 $\\varepsilon = u/L$ 的弹塑性本构更新确定。测量噪声被建模为独立同分布的高斯噪声，其标准差已知为 $\\sigma_n$。\n\n在正参数的对数构成的参数空间中，使用哈密顿蒙特卡洛（HMC）进行贝叶斯推断。令 $x = [\\log E,\\log \\sigma_y,\\log H]^\\top$。给定观测数据 $\\mathcal{D}$， $x$ 的后验密度与似然和先验的乘积成正比。假设 $x$ 服从高斯先验，其均值为 $m$，对角协方差为 $\\operatorname{diag}(\\tau^2)$，其中 $\\tau$ 是标准差向量。似然是高斯的，具有指定的噪声标准差。\n\n为了评估HMC力（负对数后验的梯度），您必须对隐式的弹塑性本构更新（基于伴随的梯度）进行微分。弹塑性更新是分段可微的，并且在弹性和塑性状态之间的转换处（当试探应力首次达到屈服面时）表现出可微性中断。为分析此问题，请实现两种梯度变体：\n- 变体A（精确分段微分）：使用标准返回映射更新，并通过在每个活动区域内对返回映射方程进行微分来推导解析参数敏感度。在屈服阈值处，通过将状态视为弹性的方式来打破平局。\n- 变体B（平滑可微代理）：通过将正部算子替换为平滑近似，来构造一个可微代理，以替换不可微的塑性乘子更新。具体来说，对于标量 $z$，使用平滑近似 $\\operatorname{softplus}_\\beta(z) = \\frac{1}{\\beta}\\log\\!\\left(1+\\exp(\\beta z)\\right)$，其中锐度参数 $\\beta  0$ 是预先指定的。将此应用于塑性应变更新，使得最终的 $\\sigma(E,\\sigma_y,H;\\varepsilon)$ 在 $(E,\\sigma_y,H)$ 上处处可微。\n\n哈密顿蒙特卡洛（Hamiltonian Monte Carlo）详情：\n- 在无约束空间 $x = [\\log E,\\log \\sigma_y,\\log H]^\\top$ 上操作。\n- 将负对数后验（势能）$U(x)$ 定义为负对数似然和负对数先验的总和（包括所有依赖于 $x$ 的项）。\n- 对动能使用单位质量矩阵（单位质量）。\n- 使用具有指定步长和步数的蛙跳积分器。\n- 为了可复现性，使用固定的伪随机种子从 $\\mathbb{R}^3$ 中的标准正态分布中抽取动量。\n- 对每个数据集和每个梯度变体，从相同的初始点 $x_0$ 执行单个HMC提议，并报告相应的Metropolis接受概率。\n\n基本出发点：\n- 贝叶斯定理和高斯先验/似然定义。\n- 哈密顿量作为势能和动能之和的定义。\n- 具有线性各向同性硬化的率无关弹塑性的返回映射算法及其库恩-塔克（Kuhn–Tucker）条件，不提供最终敏感度的简化目标公式。\n- softplus函数作为正部函数的标准可微近似。\n\n使用以下固定的物理和概率设置（所有量均采用国际单位制）：\n- 几何：$A = 1.0\\times 10^{-2}\\ \\mathrm{m^2}$，$L = 1.0\\ \\mathrm{m}$。\n- 噪声：$\\sigma_n = 1.0\\times 10^{4}\\ \\mathrm{N}$。\n- $x$ 上的先验：$x \\sim \\mathcal{N}(m, \\operatorname{diag}(\\tau^2))$，其中\n  $m = [\\log(4.0\\times 10^{10}),\\ \\log(2.0\\times 10^{8}),\\ \\log(4.0\\times 10^{9})]^\\top$ 且 $\\tau = [0.5,\\ 0.5,\\ 0.5]^\\top$。\n- HMC积分器：步长 $\\epsilon_{\\mathrm{HMC}} = 2.0\\times 10^{-2}$（在 $x$ 空间中无量纲），蛙跳步数 $L_{\\mathrm{int}} = 25$。\n- 动量：从标准正态分布中抽取，种子为 $s = 12345$。\n- 初始点：$x_0 = [\\log(6.0\\times 10^{10}),\\ \\log(2.0\\times 10^{8}),\\ \\log(2.0\\times 10^{9})]^\\top$。\n- 平滑锐度：对于softplus代理，$\\beta = 2.0\\times 10^{3}$。\n\n数据生成真值（仅用于定义下面的测试测量值）：$E^\\star = 5.0\\times 10^{10}\\ \\mathrm{Pa}$，$\\sigma_y^\\star = 2.5\\times 10^{8}\\ \\mathrm{Pa}$， $H^\\star = 5.0\\times 10^{9}\\ \\mathrm{Pa}$。以下三个数据集用作测试套件。每个数据集列出了施加的位移 $u_i$（单位：$\\mathrm{m}$）和相应的测量反力 $F_i$（单位：$\\mathrm{N}$）。这些测量值是在真值参数下从弹塑性模型计算得出的，不包含额外噪声：\n\n- 数据集1（纯弹性）：$u = [5.0\\times 10^{-4},\\ 1.0\\times 10^{-3}]$，$F = [2.5\\times 10^{5},\\ 5.0\\times 10^{5}]$。\n- 数据集2（弹性到塑性）：$u = [4.0\\times 10^{-3},\\ 6.0\\times 10^{-3},\\ 8.0\\times 10^{-3}]$，$F = [2.0\\times 10^{6},\\ 2.5454545454545455\\times 10^{6},\\ 2.6363636363636365\\times 10^{6}]$。\n- 数据集3（接近屈服转换）：$u = [5.0\\times 10^{-3},\\ 5.1\\times 10^{-3},\\ 4.9\\times 10^{-3}]$，$F = [2.5\\times 10^{6},\\ 2.5045454545454546\\times 10^{6},\\ 2.45\\times 10^{6}]$。\n\n任务：\n1. 使用贝叶斯定理以及高斯先验和似然，构建负对数后验 $U(x)$。显式地说明从 $x$到 $(E,\\sigma_y,H)$ 的映射，并通过指数化确保 $(E,\\sigma_y,H)$ 的正性。陈述所有依赖于 $x$ 的项。\n2. 推导计算 $\\nabla_x U(x)$ 所需的参数敏感度（基于伴随的梯度），在以下条件下：\n   - 变体A：通过返回映射更新实现精确分段可微性，并采用将屈服阈值状态视为弹性的平局打破规则。\n   - 变体B：使用锐度为 $\\beta$ 的softplus平滑塑性更新，这会产生一个处处可微的代理。\n   您的推导应从返回映射的驻定性和一致性条件开始，通过隐式微分进行，展示如何应用链式法则来获得 $\\mathrm{d}F/\\mathrm{d}(E,\\sigma_y,H)$，然后获得 $\\nabla_x U(x)$。\n3. 对于每个数据集和每个梯度变体，从 $x_0$ 开始，使用给定的积分器参数和动量种子，实现单个HMC提议。计算每个提议的Metropolis接受概率，其定义为1与提议状态和原始状态之间负哈密顿量误差的指数函数值中的较小者。\n4. 按以下顺序将六个接受概率报告为浮点数：\n   - 数据集1使用变体A，\n   - 数据集1使用变体B，\n   - 数据集2使用变体A，\n   - 数据集2使用变体B，\n   - 数据集3使用变体A，\n   - 数据集3使用变体B。\n   这些接受概率是无量纲的；将它们报告为 $[0,1]$ 区间内的十进制数。\n   \n您的程序应生成单行输出，其中包含用方括号括起来的六个结果的逗号分隔列表（例如，“[r1,r2,r3,r4,r5,r6]”），不含任何额外文本。所有计算必须使用指定的国际单位制；根据定义，接受概率是无单位的。",
            "solution": "该任务要求计算单个哈密顿蒙特卡洛（HMC）提议的Metropolis接受概率。这需要评估哈密顿量，而哈密顿量又依赖于势能（负对数后验）及其相对于推断参数 $x = [\\log E, \\log \\sigma_y, \\log H]^\\top$ 的梯度。\n\n**1. 势能（负对数后验）**\n\n根据贝叶斯定理，$p(x|\\mathcal{D}) \\propto p(\\mathcal{D}|x) p(x)$。势能 $U(x)$ 是负对数后验（忽略常数项）：\n$$ U(x) = -\\log p(\\mathcal{D}|x) - \\log p(x) $$\n\n- **负对数先验**：$x$ 的先验为高斯分布 $x \\sim \\mathcal{N}(m, \\Sigma_p)$，其中 $\\Sigma_p = \\operatorname{diag}(\\tau^2)$。其负对数形式为：\n  $$ -\\log p(x) = \\frac{1}{2}(x-m)^\\top \\Sigma_p^{-1} (x-m) = \\frac{1}{2}\\sum_{j=1}^3 \\frac{(x_j - m_j)^2}{\\tau_j^2} $$\n\n- **负对数似然**：假设测量值 $F_i$ 独立且服从以模型预测 $F_{\\text{model}}(u_i; x)$ 为中心、方差为 $\\sigma_n^2$ 的高斯分布。负对数似然为：\n  $$ -\\log p(\\mathcal{D}|x) = \\sum_{i=1}^N \\frac{(F_i - F_{\\text{model}}(u_i; x))^2}{2\\sigma_n^2} $$\n  其中，模型预测力 $F_{\\text{model}}(u_i; x) = A \\cdot \\sigma(x; \\varepsilon_i)$，应变 $\\varepsilon_i = u_i/L$，物理参数 $(E, \\sigma_y, H)$ 通过对 $x$ 的分量取指数得到。\n\n结合以上两项，完整的势能函数为：\n$$ U(x) = \\frac{1}{2\\sigma_n^2} \\sum_{i=1}^N \\left(F_i - A \\cdot \\sigma(x; \\varepsilon_i)\\right)^2 + \\frac{1}{2} \\sum_{j=1}^3 \\frac{(x_j - m_j)^2}{\\tau_j^2} $$\n\n**2. 势能的梯度 $\\nabla_x U(x)$**\n\n梯度是两项梯度之和。\n- **先验梯度**：$\\nabla_x(-\\log p(x))_j = \\frac{x_j-m_j}{\\tau_j^2}$。\n- **似然梯度**：应用链式法则：\n  $$ \\nabla_x(-\\log p(\\mathcal{D}|x)) = \\sum_{i=1}^N \\frac{-(F_i - F_{\\text{model}}(u_i; x))}{\\sigma_n^2} \\nabla_x F_{\\text{model}}(u_i; x) $$\n  核心任务是求解 $\\nabla_x F_{\\text{model}} = A \\nabla_x \\sigma$。令 $\\theta = [E, \\sigma_y, H]^\\top$。根据链式法则，$\\nabla_x \\sigma = (\\frac{\\partial \\sigma}{\\partial \\theta})^\\top \\frac{\\partial \\theta}{\\partial x}$。由于 $\\theta = \\exp(x)$，$\\frac{\\partial \\theta}{\\partial x}$ 是一个对角矩阵，对角线元素为 $[E, \\sigma_y, H]$。因此，我们需要推导应力敏感度 $\\frac{\\partial \\sigma}{\\partial \\theta}$。\n\n**应力与敏感度推导（一维率无关塑性）**\n对于给定的总应变 $\\varepsilon$，返回映射算法包括弹性试探步和塑性修正步。\n1.  **试探状态**：$\\sigma_{\\text{trial}} = E\\varepsilon$。\n2.  **屈服函数**：$f(\\sigma, \\alpha) = \\sigma - (\\sigma_y + H\\alpha)$。试探屈服值为 $f_{\\text{trial}} = \\sigma_{\\text{trial}} - \\sigma_y$。\n\n**变体 A（精确分段导数）**：\n塑性乘子为 $\\Delta\\gamma = \\frac{\\max(0, f_{\\text{trial}})}{E+H}$。\n- 若 $f_{\\text{trial}} \\le 0$（弹性步）：最终应力为 $\\sigma = \\sigma_{\\text{trial}} = E\\varepsilon$。敏感度为：\n  $$ \\frac{\\partial \\sigma}{\\partial E} = \\varepsilon, \\quad \\frac{\\partial \\sigma}{\\partial \\sigma_y} = 0, \\quad \\frac{\\partial \\sigma}{\\partial H} = 0 $$\n- 若 $f_{\\text{trial}} > 0$（塑性步）：最终应力为 $\\sigma = \\sigma_{\\text{trial}} - E\\Delta\\gamma = \\frac{EH\\varepsilon + E\\sigma_y}{E+H}$。通过对该表达式求导得到敏感度：\n  $$ \\frac{\\partial \\sigma}{\\partial E} = \\frac{H^2\\varepsilon + H\\sigma_y}{(E+H)^2}, \\quad \\frac{\\partial \\sigma}{\\partial \\sigma_y} = \\frac{E}{E+H}, \\quad \\frac{\\partial \\sigma}{\\partial H} = \\frac{E(E\\varepsilon - \\sigma_y)}{(E+H)^2} $$\n\n**变体 B（平滑代理导数）**：\n塑性乘子使用softplus近似：$\\Delta\\gamma = \\frac{\\operatorname{softplus}_\\beta(f_{\\text{trial}})}{E+H}$。\n最终应力为 $\\sigma = E\\varepsilon - E\\Delta\\gamma = E\\varepsilon - \\frac{E}{E+H}\\operatorname{softplus}_\\beta(E\\varepsilon - \\sigma_y)$。该表达式对于 $\\theta=(E,\\sigma_y,H)$ 是平滑的。敏感度 $\\frac{\\partial \\sigma}{\\partial \\theta}$ 通过直接应用链式法则得到，其中 $\\operatorname{softplus}_\\beta(z)$ 的导数是sigmoid函数 $\\operatorname{sigm}_\\beta(z) = (1+e^{-\\beta z})^{-1}$。例如：\n$$ \\frac{\\partial \\sigma}{\\partial \\sigma_y} = -E \\frac{\\partial \\Delta\\gamma}{\\partial \\sigma_y} = -E \\left( \\frac{1}{E+H} \\cdot \\frac{\\partial}{\\partial \\sigma_y} \\operatorname{softplus}_\\beta(E\\varepsilon - \\sigma_y) \\right) = -E \\left( \\frac{1}{E+H} \\cdot \\operatorname{sigm}_\\beta(f_{\\text{trial}}) \\cdot (-1) \\right) = \\frac{E}{E+H}\\operatorname{sigm}_\\beta(f_{\\text{trial}}) $$\n对 $E$ 和 $H$ 的导数可类似求得。\n\n**3. HMC 提议与接受概率**\n\nHMC算法模拟哈密顿动力学。哈密顿量为 $H(x, p) = U(x) + K(p)$，其中动能为 $K(p) = \\frac{1}{2}p^\\top p$。\n1.  从 $(x_0, p_0)$ 开始，其中 $p_0 \\sim \\mathcal{N}(0, I)$。计算 $H_{\\text{init}} = H(x_0, p_0)$。\n2.  使用蛙跳积分器，以步长 $\\epsilon_{\\mathrm{HMC}}$ 演化 $L_{\\text{int}}$ 步，得到提议 $(x_{\\text{prop}}, p_{\\text{prop}})$。积分器使用上面推导的梯度 $\\nabla_x U(x)$。\n3.  计算 $H_{\\text{final}} = H(x_{\\text{prop}}, p_{\\text{prop}})$。\n4.  Metropolis接受概率为 $\\alpha = \\min(1, \\exp(H_{\\text{init}} - H_{\\text{final}}))$。\n\n该推导为实现解决方案提供了完整的框架。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian inference problem for an elastoplastic model using HMC.\n    \n    This function encapsulates the entire problem setup, including constants,\n    datasets, mathematical derivations, and the HMC algorithm, to compute\n    the Metropolis acceptance probabilities for six distinct test cases.\n    \"\"\"\n    \n    # Define constants and problem settings\n    A = 1.0e-2\n    L = 1.0\n    SIGMA_N = 1.0e4\n    PRIOR_MEAN = np.array([np.log(4.0e10), np.log(2.0e8), np.log(4.0e9)])\n    PRIOR_TAU = np.array([0.5, 0.5, 0.5])\n    PRIOR_VAR = PRIOR_TAU**2\n    HMC_EPS = 2.0e-2\n    HMC_L = 25\n    MOMENTUM_SEED = 12345\n    X0 = np.array([np.log(6.0e10), np.log(2.0e8), np.log(2.0e9)])\n    BETA_SMOOTH = 2.0e3\n\n    # Define datasets\n    test_cases = [\n        # Dataset 1\n        ({'u': np.array([5.0e-4, 1.0e-3]), 'F': np.array([2.5e5, 5.0e5])}, 'A'),\n        ({'u': np.array([5.0e-4, 1.0e-3]), 'F': np.array([2.5e5, 5.0e5])}, 'B'),\n        # Dataset 2\n        ({'u': np.array([4.0e-3, 6.0e-3, 8.0e-3]), 'F': np.array([2.0e6, 2.5454545454545455e6, 2.6363636363636365e6])}, 'A'),\n        ({'u': np.array([4.0e-3, 6.0e-3, 8.0e-3]), 'F': np.array([2.0e6, 2.5454545454545455e6, 2.6363636363636365e6])}, 'B'),\n        # Dataset 3\n        ({'u': np.array([5.0e-3, 5.1e-3, 4.9e-3]), 'F': np.array([2.5e6, 2.5045454545454546e6, 2.45e6])}, 'A'),\n        ({'u': np.array([5.0e-3, 5.1e-3, 4.9e-3]), 'F': np.array([2.5e6, 2.5045454545454546e6, 2.45e6])}, 'B'),\n    ]\n\n    # Helper functions for numerically stable math\n    def softplus(z, beta):\n        return np.logaddexp(0., beta * z) / beta\n\n    def sigmoid(z, beta):\n        arg = beta * z\n        if arg >= 0:\n            return 1. / (1. + np.exp(-arg))\n        else:\n            exp_arg = np.exp(arg)\n            return exp_arg / (1. + exp_arg)\n\n    # Core physics and gradient calculations\n    def get_stress_and_derivs(E, sigma_y, H, strain, variant, beta):\n        f_trial = E * strain - sigma_y\n        E_plus_H = E + H\n\n        if variant == 'A':\n            if f_trial = 0:  # Elastic\n                sigma = E * strain\n                dsigma_dE = strain\n                dsigma_dsy = 0.\n                dsigma_dH = 0.\n            else:  # Plastic\n                sigma = (E * H * strain + E * sigma_y) / E_plus_H\n                dsigma_dE = (H**2 * strain + H * sigma_y) / (E_plus_H**2)\n                dsigma_dsy = E / E_plus_H\n                dsigma_dH = E * f_trial / (E_plus_H**2)\n        else:  # 'B' - Smoothed\n            softplus_f = softplus(f_trial, beta)\n            sigmoid_f = sigmoid(f_trial, beta)\n            \n            delta_gamma = softplus_f / E_plus_H\n            sigma = E * strain - E * delta_gamma\n            \n            # Derivatives using the chain rule\n            d_delta_gamma_dE = (strain * sigmoid_f * E_plus_H - softplus_f) / (E_plus_H**2)\n            dsigma_dE = strain - delta_gamma - E * d_delta_gamma_dE\n            \n            d_delta_gamma_dsy = -sigmoid_f / E_plus_H\n            dsigma_dsy = -E * d_delta_gamma_dsy\n            \n            d_delta_gamma_dH = -softplus_f / (E_plus_H**2)\n            dsigma_dH = -E * d_delta_gamma_dH\n\n        dsigma_dtheta = np.array([dsigma_dE, dsigma_dsy, dsigma_dH])\n        return sigma, dsigma_dtheta\n\n    # Main functions for Bayesian inference\n    def potential_energy_and_grad(x, dataset, variant, beta):\n        E, sigma_y, H = np.exp(x)\n        u_data, F_obs = dataset['u'], dataset['F']\n        strains = u_data / L\n        \n        F_model = np.zeros_like(F_obs)\n        grad_F_x = np.zeros((len(strains), 3))\n\n        for i, strain in enumerate(strains):\n            sigma, dsigma_dtheta = get_stress_and_derivs(E, sigma_y, H, strain, variant, beta)\n            F_model[i] = A * sigma\n            grad_F_theta = A * dsigma_dtheta\n            grad_F_x[i, :] = grad_F_theta * np.array([E, sigma_y, H])\n            \n        residual = F_model - F_obs\n        neg_log_likelihood = 0.5 * np.sum(residual**2) / (SIGMA_N**2)\n        prior_residual = x - PRIOR_MEAN\n        neg_log_prior = 0.5 * np.sum(prior_residual**2 / PRIOR_VAR)\n        U = neg_log_likelihood + neg_log_prior\n        \n        grad_nll = np.sum((1. / SIGMA_N**2) * residual[:, np.newaxis] * grad_F_x, axis=0)\n        grad_nlp = (x - PRIOR_MEAN) / PRIOR_VAR\n        grad_U = grad_nll + grad_nlp\n        \n        return U, grad_U\n\n    def hmc_proposal(x0, dataset, variant):\n        rng = np.random.default_rng(MOMENTUM_SEED)\n        p0 = rng.normal(size=x0.shape)\n        \n        current_U, grad_U_current = potential_energy_and_grad(x0, dataset, variant, BETA_SMOOTH)\n        current_K = 0.5 * np.sum(p0**2)\n        \n        x = np.copy(x0)\n        p = np.copy(p0)\n        \n        # Leapfrog integration\n        p -= 0.5 * HMC_EPS * grad_U_current\n        \n        for i in range(HMC_L - 1):\n            x += HMC_EPS * p\n            _ , grad_U = potential_energy_and_grad(x, dataset, variant, BETA_SMOOTH)\n            p -= HMC_EPS * grad_U\n\n        x += HMC_EPS * p\n        proposed_U, grad_U_final = potential_energy_and_grad(x, dataset, variant, BETA_SMOOTH)\n        p -= 0.5 * HMC_EPS * grad_U_final\n        \n        proposed_K = 0.5 * np.sum(p**2)\n        \n        delta_H = (proposed_U + proposed_K) - (current_U + current_K)\n        \n        if np.isnan(delta_H):\n            acceptance_prob = 0.0\n        else:\n            acceptance_prob = min(1.0, np.exp(-delta_H))\n            \n        return acceptance_prob\n\n    # Main execution loop\n    results = []\n    for case in test_cases:\n        dataset, variant = case\n        prob = hmc_proposal(X0, dataset, variant)\n        results.append(prob)\n            \n    print(f\"[{','.join(f'{r:.16f}' for r in results)}]\")\n    \nsolve()\n```"
        }
    ]
}