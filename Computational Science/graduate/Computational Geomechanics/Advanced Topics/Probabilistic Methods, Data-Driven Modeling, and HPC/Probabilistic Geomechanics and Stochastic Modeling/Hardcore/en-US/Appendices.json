{
    "hands_on_practices": [
        {
            "introduction": "In geotechnical engineering, soil and rock properties exhibit significant spatial variability. Modeling these properties as random fields is a cornerstone of probabilistic geomechanics. This practice explores a fundamental consequence of this variability: the effect of spatial averaging. By deriving the variance of a spatially averaged property, you will gain a quantitative understanding of how the scale of observation or measurement ($L$) interacts with the intrinsic correlation structure of the material ($\\ell$) to reduce uncertainty, a concept critical for upscaling material properties and interpreting field data. ",
            "id": "3553043",
            "problem": "Consider a second-order stationary scalar random field $E(x)$ representing the spatial variability of a soil stiffness modulus along a one-dimensional profile. Let the mean be $\\mu_{E}$ and the covariance function be $C(h)=\\operatorname{Cov}\\!\\big(E(x),E(x+h)\\big)=\\sigma^{2}\\exp\\!\\big(-|h|/\\ell\\big)$, where $\\sigma^{2}$ is the variance and $\\ell$ is the correlation length. For a finite interval $[0,L]$ of length $L$, define the spatial average $\\bar{E}_{L}$ by\n$$\n\\bar{E}_{L}=\\frac{1}{L}\\int_{0}^{L}E(x)\\,\\mathrm{d}x.\n$$\nUsing only the definitions of variance and covariance for second-order stationary fields and basic properties of integrals, derive a closed-form expression for the variance $\\operatorname{Var}(\\bar{E}_{L})$ in terms of $\\sigma^{2}$, $L$, and $\\ell$ only. Then, based on the derived expression, explain qualitatively how the correlation length $\\ell$ governs the scaling of $\\operatorname{Var}(\\bar{E}_{L})$ with $L$ in the limiting regimes $L\\ll \\ell$ and $L\\gg \\ell$. Provide the final expression for $\\operatorname{Var}(\\bar{E}_{L})$ as your answer. Do not include any units in the final expression.",
            "solution": "The problem is scientifically grounded, well-posed, and objective. It presents a standard task in the stochastic modeling of spatially variable material properties, which is central to probabilistic geomechanics. All necessary definitions and parameters are provided, and no inconsistencies or ambiguities are present. Therefore, a complete solution is warranted.\n\nThe primary objective is to derive an expression for the variance of the spatial average of a second-order stationary random field $E(x)$ over an interval $[0,L]$. The spatial average $\\bar{E}_{L}$ is defined as:\n$$\n\\bar{E}_{L} = \\frac{1}{L}\\int_{0}^{L} E(x)\\,\\mathrm{d}x\n$$\nThe variance of $\\bar{E}_{L}$ is given by the general definition $\\operatorname{Var}(\\bar{E}_{L}) = E[\\bar{E}_{L}^2] - (E[\\bar{E}_{L}])^2$. First, we determine the expected value of $\\bar{E}_{L}$. By linearity of the expectation operator, we can interchange expectation and integration:\n$$\nE[\\bar{E}_{L}] = E\\left[\\frac{1}{L}\\int_{0}^{L} E(x)\\,\\mathrm{d}x\\right] = \\frac{1}{L}\\int_{0}^{L} E[E(x)]\\,\\mathrm{d}x\n$$\nSince the field $E(x)$ is second-order stationary, its mean $E[E(x)]$ is a constant, $\\mu_{E}$, for all $x$.\n$$\nE[\\bar{E}_{L}] = \\frac{1}{L}\\int_{0}^{L} \\mu_{E}\\,\\mathrm{d}x = \\frac{1}{L}(\\mu_{E}L) = \\mu_{E}\n$$\nNow, we express the variance of $\\bar{E}_{L}$ using its definition as a double integral.\n$$\n\\operatorname{Var}(\\bar{E}_{L}) = \\operatorname{Var}\\left(\\frac{1}{L}\\int_{0}^{L} E(x)\\,\\mathrm{d}x\\right) = \\frac{1}{L^2}\\operatorname{Var}\\left(\\int_{0}^{L} E(x)\\,\\mathrm{d}x\\right)\n$$\nThe variance of the integral can be written as:\n$$\n\\operatorname{Var}\\left(\\int_{0}^{L} E(x)\\,\\mathrm{d}x\\right) = E\\left[\\left(\\int_{0}^{L} E(x)\\,\\mathrm{d}x - E\\left[\\int_{0}^{L}E(y)\\,\\mathrm{d}y\\right]\\right)^2\\right]\n$$\nSince $E\\left[\\int_{0}^{L}E(y)\\,\\mathrm{d}y\\right] = L\\mu_{E}$, this becomes:\n$$\nE\\left[\\left(\\int_{0}^{L} (E(x) - \\mu_{E})\\,\\mathrm{d}x\\right)^2\\right] = E\\left[\\left(\\int_{0}^{L} (E(x) - \\mu_{E})\\,\\mathrm{d}x\\right)\\left(\\int_{0}^{L} (E(y) - \\mu_{E})\\,\\mathrm{d}y\\right)\\right]\n$$\n$$\n= E\\left[\\int_{0}^{L}\\int_{0}^{L} (E(x) - \\mu_{E})(E(y) - \\mu_{E})\\,\\mathrm{d}x\\,\\mathrm{d}y\\right]\n$$\nInterchanging expectation and integration gives:\n$$\n\\int_{0}^{L}\\int_{0}^{L} E[(E(x) - \\mu_{E})(E(y) - \\mu_{E})]\\,\\mathrm{d}x\\,\\mathrm{d}y = \\int_{0}^{L}\\int_{0}^{L} \\operatorname{Cov}(E(x), E(y))\\,\\mathrm{d}x\\,\\mathrm{d}y\n$$\nFor a second-order stationary field, the covariance is a function of the separation distance $h = x-y$, so $\\operatorname{Cov}(E(x), E(y)) = C(x-y)$. Therefore, the variance of the average is:\n$$\n\\operatorname{Var}(\\bar{E}_{L}) = \\frac{1}{L^2}\\int_{0}^{L}\\int_{0}^{L} C(x-y)\\,\\mathrm{d}x\\,\\mathrm{d}y\n$$\nThe problem provides the exponential covariance function $C(h) = \\sigma^2 \\exp(-|h|/\\ell)$. Substituting this into the equation:\n$$\n\\operatorname{Var}(\\bar{E}_{L}) = \\frac{\\sigma^2}{L^2}\\int_{0}^{L}\\int_{0}^{L} \\exp\\left(-\\frac{|x-y|}{\\ell}\\right)\\,\\mathrm{d}x\\,\\mathrm{d}y\n$$\nThe double integral can be evaluated efficiently by making a change of variables or by recognizing a general property of such integrals. The integral $\\int_{0}^{L}\\int_{0}^{L} f(|x-y|)\\,\\mathrm{d}x\\,\\mathrm{d}y$ is equivalent to $\\int_{-L}^{L} (L-|z|)f(|z|)\\,\\mathrm{d}z$. Since the integrand is an even function of $z$:\n$$\n\\int_{0}^{L}\\int_{0}^{L} \\exp\\left(-\\frac{|x-y|}{\\ell}\\right)\\,\\mathrm{d}x\\,\\mathrm{d}y = 2\\int_{0}^{L} (L-z)\\exp\\left(-\\frac{z}{\\ell}\\right)\\,\\mathrm{d}z\n$$\nWe evaluate this integral using integration by parts, $\\int u\\,\\mathrm{d}v = uv - \\int v\\,\\mathrm{d}u$. Let $u = L-z$ and $\\mathrm{d}v = \\exp(-z/\\ell)\\,\\mathrm{d}z$. Then $\\mathrm{d}u = -1\\,\\mathrm{d}z$ and $v = -\\ell\\exp(-z/\\ell)$.\n\\begin{align*} 2\\int_{0}^{L} (L-z)\\exp\\left(-\\frac{z}{\\ell}\\right)\\,\\mathrm{d}z = 2\\left(\\Big[(L-z)(-\\ell\\exp(-z/\\ell))\\Big]_{0}^{L} - \\int_{0}^{L} (-\\ell\\exp(-z/\\ell))(-1\\,\\mathrm{d}z)\\right) \\\\ = 2\\left(\\Big[0 - (L)(-\\ell)\\Big] - \\ell\\int_{0}^{L} \\exp(-z/\\ell)\\,\\mathrm{d}z\\right) \\\\ = 2\\left(L\\ell - \\ell\\Big[-\\ell\\exp(-z/\\ell)\\Big]_{0}^{L}\\right) \\\\ = 2\\left(L\\ell - \\ell(-\\ell\\exp(-L/\\ell) - (-\\ell))\\right) \\\\ = 2\\left(L\\ell - \\ell^2(1 - \\exp(-L/\\ell))\\right) \\\\ = 2L\\ell - 2\\ell^2(1 - \\exp(-L/\\ell))\\end{align*}\nSubstituting this result back into the expression for $\\operatorname{Var}(\\bar{E}_{L})$:\n$$\n\\operatorname{Var}(\\bar{E}_{L}) = \\frac{\\sigma^2}{L^2}\\left[2L\\ell - 2\\ell^2\\left(1 - \\exp\\left(-\\frac{L}{\\ell}\\right)\\right)\\right]\n$$\nThis expression can be rearranged into a more insightful form:\n$$\n\\operatorname{Var}(\\bar{E}_{L}) = \\frac{2\\sigma^2 \\ell^2}{L^2}\\left[\\frac{L}{\\ell} - 1 + \\exp\\left(-\\frac{L}{\\ell}\\right)\\right]\n$$\nThis is the required closed-form expression for the variance of the spatial average.\n\nNext, we analyze the scaling of $\\operatorname{Var}(\\bar{E}_{L})$ in two limiting regimes. Let $\\rho = L/\\ell$ be the dimensionless ratio of the averaging length to the correlation length.\n\nCase 1: $L \\ll \\ell$ (averaging length much smaller than correlation length).\nIn this regime, $\\rho \\to 0$. We use the Taylor series expansion for $\\exp(-\\rho)$ around $\\rho=0$:\n$\\exp(-\\rho) = 1 - \\rho + \\frac{\\rho^2}{2!} - \\frac{\\rho^3}{3!} + O(\\rho^4)$.\nSubstituting this into the term in the brackets:\n$$\n\\rho - 1 + \\exp(-\\rho) \\approx \\rho - 1 + \\left(1 - \\rho + \\frac{\\rho^2}{2}\\right) = \\frac{\\rho^2}{2}\n$$\nThe variance becomes:\n$$\n\\operatorname{Var}(\\bar{E}_{L}) \\approx \\frac{2\\sigma^2}{\\rho^2}\\left(\\frac{\\rho^2}{2}\\right) = \\sigma^2\n$$\nQualitatively, when $L$ is very small compared to $\\ell$, the random field $E(x)$ is highly correlated over the interval $[0,L]$. The values of $E(x)$ are nearly constant, so the spatial average $\\bar{E}_{L}$ is approximately equal to a single point value, e.g., $E(0)$. Consequently, the variance of the average approaches the point variance, $\\operatorname{Var}(\\bar{E}_{L}) \\approx \\operatorname{Var}(E(0)) = \\sigma^2$. The averaging provides negligible variance reduction.\n\nCase 2: $L \\gg \\ell$ (averaging length much larger than correlation length).\nIn this regime, $\\rho \\to \\infty$. As $\\rho$ becomes large, the term $\\exp(-\\rho)$ approaches $0$. The term in the brackets becomes approximately $(\\rho - 1)$. Since $\\rho \\gg 1$, this is further approximated by $\\rho$.\n$$\n\\operatorname{Var}(\\bar{E}_{L}) \\approx \\frac{2\\sigma^2 \\ell^2}{L^2}\\left(\\frac{L}{\\ell}\\right) = \\frac{2\\sigma^2\\ell}{L}\n$$\nThe variance scales inversely with the averaging length $L$.\nQualitatively, when $L$ is much larger than $\\ell$, the integral for $\\bar{E}_{L}$ averages over many nearly-independent segments of the random field, where the approximate length of each segment is related to the correlation length $\\ell$. Based on a Central Limit Theorem-type argument, averaging over approximately $N \\approx L/\\ell$ independent blocks would reduce the variance by a factor of $N$. This leads to the scaling $\\operatorname{Var}(\\bar{E}_{L}) \\propto 1/N \\propto \\ell/L$. The constant of proportionality, $2$ in this case, depends on the shape of the covariance function. This significant variance reduction is a key principle in geostatistical estimation and upscaling.",
            "answer": "$$\n\\boxed{\\frac{2\\sigma^2 \\ell^2}{L^2} \\left(\\frac{L}{\\ell} - 1 + \\exp\\left(-\\frac{L}{\\ell}\\right)\\right)}\n$$"
        },
        {
            "introduction": "Once uncertainty in material properties is characterized, the next step is to propagate it through a physical model to predict the system's response. This exercise introduces the intrusive Polynomial Chaos Expansion (PCE), a powerful spectral method that solves the stochastic governing equations directly. By applying the Galerkin projection in probability space to a simple elastic bar problem, you will derive the full deterministic system of equations that yields the stochastic solution, providing deep insight into the structure and sparsity of the computational system that arises in advanced uncertainty quantification. ",
            "id": "3553130",
            "problem": "Consider a one-dimensional elastic bar occupying the interval $[0,L]$ with constant cross-sectional area $A$, subject to small-strain linear elasticity. The displacement field $u(x,\\omega)$ satisfies the strong form equilibrium equation $-\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left(\\sigma(x,\\omega)\\right)=0$ with $\\sigma(x,\\omega)=E(\\omega)\\,\\varepsilon(x,\\omega)$ and $\\varepsilon(x,\\omega)=\\frac{\\mathrm{d}u}{\\mathrm{d}x}(x,\\omega)$. Assume deterministic boundary conditions: $u(0,\\omega)=0$ and a prescribed traction $t_L$ at $x=L$. The Young’s modulus is spatially uniform but random, modeled as $E(\\omega)=\\exp\\!\\big(Y(\\omega)\\big)$ where $Y(\\omega)$ is Gaussian with mean $\\mu_Y$ and standard deviation $\\sigma_Y$. \n\nUse the standard Galerkin weak form and a conforming Finite Element (FE) discretization with shape functions $N(x)$ and strain-displacement matrix $B(x)=\\frac{\\mathrm{d}N}{\\mathrm{d}x}(x)$. In this setting, the deterministic stiffness matrix associated with unit modulus is $K_0=\\int_0^L A\\,B(x)^{\\top}B(x)\\,\\mathrm{d}x$, so that the random stiffness is $K(E(\\omega))=E(\\omega)\\,K_0$. \n\nConstruct an intrusive Polynomial Chaos Expansion (PCE) for the stochastic solution by expanding the displacement coefficient vector $a(\\omega)$ (the FE nodal degrees of freedom) in terms of orthonormal Hermite polynomials $\\{\\psi_n(\\xi)\\}_{n=0}^{p}$ associated with the standard normal variable $\\xi\\sim\\mathcal{N}(0,1)$ underlying $Y(\\omega)=\\mu_Y+\\sigma_Y\\,\\xi(\\omega)$. Specifically, take $a(\\omega)=\\sum_{j=0}^{p} a_j\\,\\psi_j(\\xi(\\omega))$ with deterministic coefficient vectors $a_j\\in\\mathbb{R}^{n_u}$, where $n_u$ is the number of FE displacement degrees of freedom. Also expand $E(\\omega)$ in the same basis up to order $p$, $E(\\omega)=\\sum_{n=0}^{p} e_n\\,\\psi_n(\\xi(\\omega))$, and determine the coefficients $e_n$ from first principles using properties of Hermite polynomials and the lognormal map $E=\\exp(Y)$.\n\nApply the intrusive Galerkin projection in probability space with test functions $\\psi_i$, $i=0,\\dots,p$, to derive the coupled deterministic-stochastic algebraic system for the unknown vector of PCE coefficients $\\hat{a}=\\big[a_0^{\\top},a_1^{\\top},\\dots,a_p^{\\top}\\big]^{\\top}\\in\\mathbb{R}^{(p+1)n_u}$. Express the resulting left-hand-side global matrix in a Kronecker-product form involving $K_0$ and a $(p+1)\\times(p+1)$ stochastic coupling matrix assembled from triple products $\\langle\\psi_i\\psi_j\\psi_n\\rangle=\\mathbb{E}[\\psi_i(\\xi)\\psi_j(\\xi)\\psi_n(\\xi)]$. Clearly articulate any selection rules that control the sparsity of these triple products and hence the sparsity pattern of the global matrix blocks. \n\nIf you choose to use a first-order log-linearization for small $\\sigma_Y$, justify it rigorously and describe how it simplifies the block structure. Otherwise, proceed with the exact expansion of $\\exp(\\sigma_Y\\,\\xi)$ in the Hermite basis. In either case, derive a closed-form analytic expression for the intrusive global matrix using the coefficients $e_n$ and the triple-product matrices. \n\nYour final answer must be a single closed-form analytic expression for the intrusive global matrix in terms of $K_0$, $\\mu_Y$, $\\sigma_Y$, $p$, and the triple-product matrices. No numerical evaluation is required, and no rounding is needed. No units should be included in the final expression.",
            "solution": "The problem as stated is scientifically grounded, well-posed, objective, and internally consistent. It represents a standard application of the intrusive Polynomial Chaos-Finite Element Method to a one-dimensional linear elasticity problem with stochastic material properties. All necessary components for deriving the requested global matrix are provided. Therefore, the problem is valid, and a full solution is presented below.\n\nThe starting point is the Finite Element (FE) discretization of the strong form equilibrium equation. The standard Galerkin procedure in the spatial domain leads to a system of algebraic equations for the vector of nodal displacements, $a(\\omega) \\in \\mathbb{R}^{n_u}$:\n$$\nK(\\omega) a(\\omega) = F\n$$\nHere, $F$ is the deterministic external force vector resulting from the prescribed traction $t_L$, and $K(\\omega)$ is the random stiffness matrix. Given that the Young's modulus $E(\\omega)$ is spatially uniform, the stiffness matrix can be expressed as:\n$$\nK(\\omega) = E(\\omega) K_0\n$$\nwhere $K_0 = \\int_0^L A\\,B(x)^{\\top}B(x)\\,\\mathrm{d}x$ is the nominal stiffness matrix computed with a unit Young's modulus. The randomness in $E(\\omega)$ is modeled via a lognormal distribution, $E(\\omega) = \\exp(Y(\\omega))$, where $Y(\\omega)$ is a Gaussian random variable with mean $\\mu_Y$ and standard deviation $\\sigma_Y$. We can relate $Y(\\omega)$ to a standard normal variable $\\xi(\\omega) \\sim \\mathcal{N}(0,1)$ as $Y(\\omega) = \\mu_Y + \\sigma_Y \\xi(\\omega)$. Thus, the Young's modulus is a function of $\\xi$:\n$$\nE(\\xi) = \\exp(\\mu_Y + \\sigma_Y \\xi) = \\exp(\\mu_Y) \\exp(\\sigma_Y \\xi)\n$$\nThe stochastic FE system becomes:\n$$\n\\exp(\\mu_Y) \\exp(\\sigma_Y \\xi) K_0 a(\\xi) = F\n$$\nWe now employ the intrusive spectral method by expanding the unknown solution vector $a(\\xi)$ and the random modulus $E(\\xi)$ in a Polynomial Chaos Expansion (PCE) up to order $p$, using the basis of orthonormal Hermite polynomials $\\{\\psi_k(\\xi)\\}_{k=0}^p$:\n$$\na(\\xi) = \\sum_{j=0}^{p} a_j \\psi_j(\\xi)\n$$\n$$\nE(\\xi) = \\sum_{n=0}^{p} e_n \\psi_n(\\xi)\n$$\nThe coefficients $a_j \\in \\mathbb{R}^{n_u}$ are the deterministic unknowns we seek to find. The coefficients $e_n \\in \\mathbb{R}$ are determined by projecting $E(\\xi)$ onto the basis functions $\\psi_n(\\xi)$. Leveraging the orthonormality property $\\mathbb{E}[\\psi_k \\psi_m] = \\delta_{km}$, we have:\n$$\ne_n = \\mathbb{E}[E(\\xi) \\psi_n(\\xi)] = \\mathbb{E}[\\exp(\\mu_Y + \\sigma_Y \\xi) \\psi_n(\\xi)] = \\exp(\\mu_Y) \\mathbb{E}[\\exp(\\sigma_Y \\xi) \\psi_n(\\xi)]\n$$\nTo evaluate the expectation, we use the generating function for probabilist's Hermite polynomials $He_n(\\xi)$, which are related to the orthonormal polynomials by $\\psi_n(\\xi) = He_n(\\xi) / \\sqrt{n!}$. The generating function is $\\exp(t\\xi - t^2/2) = \\sum_{n=0}^{\\infty} \\frac{t^n}{n!} He_n(\\xi)$.\nConsider the expression $\\sum_{n=0}^{\\infty} \\frac{t^n}{n!} \\mathbb{E}[\\exp(\\sigma_Y \\xi) He_n(\\xi)]$:\n$$\n\\sum_{n=0}^{\\infty} \\frac{t^n}{n!} \\mathbb{E}[\\exp(\\sigma_Y \\xi) He_n(\\xi)] = \\mathbb{E}\\left[\\exp(\\sigma_Y \\xi) \\sum_{n=0}^{\\infty} \\frac{t^n}{n!} He_n(\\xi)\\right] = \\mathbb{E}[\\exp(\\sigma_Y \\xi) \\exp(t\\xi - t^2/2)]\n$$\n$$\n= \\mathbb{E}[\\exp((\\sigma_Y+t)\\xi - t^2/2)] = \\exp(-t^2/2) \\mathbb{E}[\\exp((\\sigma_Y+t)\\xi)]\n$$\nUsing the moment-generating function of a standard normal variable, $\\mathbb{E}[\\exp(s\\xi)] = \\exp(s^2/2)$, we get:\n$$\n= \\exp(-t^2/2) \\exp\\left(\\frac{(\\sigma_Y+t)^2}{2}\\right) = \\exp\\left(\\frac{-t^2 + \\sigma_Y^2 + 2\\sigma_Y t + t^2}{2}\\right) = \\exp\\left(\\frac{\\sigma_Y^2}{2} + \\sigma_Y t\\right)\n$$\nExpanding the result as a power series in $t$:\n$$\n\\exp\\left(\\frac{\\sigma_Y^2}{2}\\right) \\exp(\\sigma_Y t) = \\exp\\left(\\frac{\\sigma_Y^2}{2}\\right) \\sum_{n=0}^{\\infty} \\frac{(\\sigma_Y t)^n}{n!} = \\sum_{n=0}^{\\infty} \\left( \\exp\\left(\\frac{\\sigma_Y^2}{2}\\right) \\sigma_Y^n \\right) \\frac{t^n}{n!}\n$$\nBy comparing coefficients of $t^n/n!$, we find $\\mathbb{E}[\\exp(\\sigma_Y \\xi) He_n(\\xi)] = \\exp(\\sigma_Y^2/2) \\sigma_Y^n$. Substituting this back into the expression for $e_n$:\n$$\ne_n = \\frac{\\exp(\\mu_Y)}{\\sqrt{n!}} \\mathbb{E}[\\exp(\\sigma_Y \\xi) He_n(\\xi)] = \\exp\\left(\\mu_Y + \\frac{\\sigma_Y^2}{2}\\right) \\frac{\\sigma_Y^n}{\\sqrt{n!}}\n$$\nNext, we substitute the PCEs for $E(\\xi)$ and $a(\\xi)$ into the stochastic FE equation:\n$$\n\\left( \\sum_{n=0}^{p} e_n \\psi_n(\\xi) \\right) K_0 \\left( \\sum_{j=0}^{p} a_j \\psi_j(\\xi) \\right) = F\n$$\nThe intrusive Galerkin method requires projecting this residual equation onto each basis function $\\psi_i(\\xi)$ for $i=0, 1, \\dots, p$. This is achieved by taking the expectation of the equation multiplied by $\\psi_i(\\xi)$:\n$$\n\\mathbb{E}\\left[ \\psi_i(\\xi) \\left( \\sum_{n=0}^{p} e_n \\psi_n(\\xi) \\right) K_0 \\left( \\sum_{j=0}^{p} a_j \\psi_j(\\xi) \\right) \\right] = \\mathbb{E}[F \\psi_i(\\xi)]\n$$\nSince $K_0$, $a_j$, and $e_n$ are deterministic, we can move them outside the expectation:\n$$\n\\sum_{n=0}^{p} \\sum_{j=0}^{p} e_n K_0 a_j \\, \\mathbb{E}[\\psi_i(\\xi) \\psi_j(\\xi) \\psi_n(\\xi)] = \\mathbb{E}[F \\psi_i(\\xi)]\n$$\nLet us define the triple-product term $c_{ijn} = \\mathbb{E}[\\psi_i(\\xi) \\psi_j(\\xi) \\psi_n(\\xi)]$. The set of equations for $i = 0, \\dots, p$ becomes:\n$$\n\\sum_{j=0}^{p} \\left( \\sum_{n=0}^{p} c_{ijn} e_n \\right) K_0 a_j = \\mathbb{E}[F \\psi_i(\\xi)] \\quad \\text{for } i=0, \\dots, p\n$$\nThis is a system of $(p+1)$ coupled block equations. We can write this as a single large linear system $\\mathcal{K} \\hat{a} = \\hat{F}$, where $\\hat{a} = [a_0^\\top, a_1^\\top, \\dots, a_p^\\top]^\\top$ is the vector of all unknown coefficients. The global matrix $\\mathcal{K}$ is a $(p+1) \\times (p+1)$ block matrix, where the block at position $(i,j)$ (for $i,j \\in \\{0, \\dots, p\\}$) is the $n_u \\times n_u$ matrix multiplying $a_j$ in the $i$-th block equation:\n$$\n\\mathcal{K}_{ij} = \\left( \\sum_{n=0}^{p} c_{ijn} e_n \\right) K_0\n$$\nThis structure allows us to express the global matrix $\\mathcal{K}$ in Kronecker product form:\n$$\n\\mathcal{K} = S \\otimes K_0\n$$\nwhere $S$ is the $(p+1) \\times (p+1)$ stochastic coupling matrix with entries:\n$$\nS_{ij} = \\sum_{n=0}^{p} c_{ijn} e_n = \\sum_{n=0}^{p} \\mathbb{E}[\\psi_i(\\xi) \\psi_j(\\xi) \\psi_n(\\xi)] e_n\n$$\nThe sparsity of the matrix $S$, and therefore of the block structure of $\\mathcal{K}$, is governed by the selection rules for the triple product $c_{ijn}$. The term $c_{ijn}$ is non-zero only if:\n1. The sum of the indices is an even number: $i+j+n = 2k$ for some integer $k$.\n2. The indices satisfy the triangle inequality: $|i-j| \\le n \\le i+j$.\nThese rules significantly reduce the number of non-zero terms in the sum defining $S_{ij}$ and the number of non-zero blocks in the global system.\n\nCombining the expressions for $S_{ij}$ and $e_n$, we obtain the final form of the intrusive global matrix. Let $C_n$ be the $(p+1) \\times (p+1)$ matrix with entries $(C_n)_{ij} = c_{ijn}$. The stochastic coupling matrix is $S = \\sum_{n=0}^{p} e_n C_n$. Substituting the derived expression for $e_n$:\n$$\nS = \\sum_{n=0}^{p} \\left( \\exp\\left(\\mu_Y + \\frac{\\sigma_Y^2}{2}\\right) \\frac{\\sigma_Y^n}{\\sqrt{n!}} \\right) C_n = \\exp\\left(\\mu_Y + \\frac{\\sigma_Y^2}{2}\\right) \\sum_{n=0}^{p} \\frac{\\sigma_Y^n}{\\sqrt{n!}} C_n\n$$\nTherefore, the full intrusive global matrix is:\n$$\n\\mathcal{K} = \\left( \\exp\\left(\\mu_Y + \\frac{\\sigma_Y^2}{2}\\right) \\sum_{n=0}^{p} \\frac{\\sigma_Y^n}{\\sqrt{n!}} C_n \\right) \\otimes K_0\n$$\nThis expression represents the complete left-hand-side operator for the deterministic system of equations that solves for the PCE coefficients of the stochastic displacement field.",
            "answer": "$$\n\\boxed{\\exp\\left(\\mu_Y + \\frac{\\sigma_Y^2}{2}\\right) \\left( \\sum_{n=0}^{p} \\frac{\\sigma_Y^n}{\\sqrt{n!}} C_n \\right) \\otimes K_0}\n$$"
        },
        {
            "introduction": "A primary goal of uncertainty propagation is to assess system reliability, often by computing the probability of failure, $P_f$. When failure is a rare event (e.g., $P_f \\ll 1$), standard Monte Carlo methods become computationally prohibitive. This practice introduces Subset Simulation (SuS), an advanced simulation technique designed to efficiently estimate very small probabilities. Through this exercise, you will not only design the intermediate failure events that are key to the method's success but also analyze the estimator's variance, connecting the theoretical underpinnings of SuS to the practical choices that govern its efficiency. ",
            "id": "3553129",
            "problem": "Consider a probabilistic slope stability assessment in which the scalar performance variable $Y$ represents a dimensionless safety margin aggregated from random shear strength and pore pressure contributions. Assume $Y$ is modeled as a Gaussian random variable $Y \\sim \\mathcal{N}(\\mu,\\sigma^2)$, consistent with the Central Limit Theorem (CLT) when many independent contributing uncertainties are present. Failure is defined by the rare-event threshold exceedance $\\{Y \\ge b_L\\}$ with probability $P_f \\approx 10^{-6}$. To estimate $P_f$ using Subset Simulation (SuS), design a nested sequence of intermediate thresholds $\\{b_\\ell\\}_{\\ell=1}^L$ such that the level sets $\\{Y \\ge b_1\\} \\supset \\{Y \\ge b_2\\} \\supset \\dots \\supset \\{Y \\ge b_L\\}$ satisfy a constant conditional exceedance probability $p_0$ at each level, and the product $\\prod_{\\ell=1}^L p_0$ approximates $P_f$. For a given conditional sample size $m$ per level, the SuS estimator of $P_f$ is the product of $L$ sample proportions of exceedances at the designed thresholds.\n\nStarting from fundamental probabilistic definitions, model each within-level exceedance indicator as an independent Bernoulli random variable with success probability $p_0$, so the sample proportions are unbiased estimators of the conditional probabilities. Use this independence idealization as a design surrogate and derive the estimator variance as a function of the conditional sample size $m$, the level count $L$, and the constant conditional probability $p_0$. For the threshold design, use the Gaussian quantile relation to determine $b_\\ell$ such that the unconditional tail probability satisfies $\\mathbb{P}(Y \\ge b_\\ell) = p_0^\\ell$, ensuring that the nested rare-event sequence has the intended tail probabilities.\n\nYour program must:\n- Implement the threshold design for a standardized Gaussian $Y$ with $\\mu=0$ and $\\sigma=1$, computing $b_\\ell$ via the standard normal inverse cumulative distribution function for each level $\\ell=1,\\dots,L$ given $p_0$.\n- Implement the estimator variance computation for the SuS product estimator under the independence surrogate described above, expressed purely in terms of $m$, $L$, and $p_0$.\n- Use the following test suite of parameter sets $(p_0,m,L)$:\n    1. $(0.1,1000,6)$ as a typical rare-event design targeting $P_f \\approx 10^{-6}$.\n    2. $(0.1,200,6)$ to examine increased estimator variance with smaller conditional sample size.\n    3. $(0.1,10000,6)$ to examine reduced variance with larger conditional sample size.\n    4. $(0.2,800,9)$ to examine a different $p_0$ yielding approximately the same target rarity level.\n    5. $(0.05,500,5)$ to examine a more aggressive level probability with fewer levels.\n- Produce as final output a single line containing the estimator variances for the five test cases as a comma-separated list enclosed in square brackets, for example, \"[v1,v2,v3,v4,v5]\". Each entry must be a floating-point number. No other text should be printed.\n\nAll quantities are dimensionless, so no physical units are required. Angles are not involved. Express $p_0$ values as decimals in $(0,1)$.",
            "solution": "The Subset Simulation (SuS) framework estimates a rare-event probability $P_f$ by factorizing it into a product of more probable conditional events. The failure event is $\\{Y \\ge b_L\\}$ for a scalar performance variable $Y$, here modeled as $Y \\sim \\mathcal{N}(\\mu,\\sigma^2)$ due to aggregation of numerous uncertainties consistent with the Central Limit Theorem (CLT). In SuS, we select intermediate thresholds $\\{b_\\ell\\}_{\\ell=1}^L$ to form nested events $\\{Y \\ge b_1\\} \\supset \\dots \\supset \\{Y \\ge b_L\\}$, and design the conditional exceedance probability at each level to be a constant $p_0 \\in (0,1)$. This yields \n$$\nP_f \\approx \\prod_{\\ell=1}^L p_0 = p_0^L,\n$$\nwhich guides the choice of $L$ and $p_0$ such that $p_0^L \\approx 10^{-6}$ for the rare-event slope failure.\n\nThreshold design under the Gaussian model exploits the monotonicity of tail probabilities with thresholds. For a given $p_0$ and level index $\\ell$, the unconditional tail probability requirement $\\mathbb{P}(Y \\ge b_\\ell) = p_0^\\ell$ translates to a quantile equation via the standard normal cumulative distribution function (CDF) $\\Phi(\\cdot)$:\n$$\n\\mathbb{P}(Y \\ge b_\\ell) = 1 - \\Phi\\!\\left(\\frac{b_\\ell - \\mu}{\\sigma}\\right) = p_0^\\ell.\n$$\nSolving for $b_\\ell$ gives\n$$\nb_\\ell = \\mu + \\sigma \\,\\Phi^{-1}\\!\\left(1 - p_0^\\ell\\right),\n$$\nwhere $\\Phi^{-1}(\\cdot)$ denotes the inverse CDF (quantile function) of the standard normal distribution. For a standardized $Y$ with $\\mu=0$ and $\\sigma=1$, this simplifies to \n$$\nb_\\ell = \\Phi^{-1}\\!\\left(1 - p_0^\\ell\\right).\n$$\nThis sequence ensures $\\{Y \\ge b_\\ell\\}$ are nested with prescribed unconditional tail probabilities.\n\nWe now derive the estimator variance as a function of the conditional sample size $m$, the level count $L$, and the constant conditional probability $p_0$. At level $\\ell$, draw $m$ samples and form the indicator variables $I_{\\ell,i}$, where $I_{\\ell,i}=1$ if the $\\ell$th-level condition is satisfied and $0$ otherwise. Under the design surrogate that treats the $I_{\\ell,i}$ as independent and identically distributed Bernoulli random variables with success probability $p_0$, the sample proportion \n$$\n\\hat{p}_\\ell = \\frac{1}{m}\\sum_{i=1}^m I_{\\ell,i}\n$$\nis an unbiased estimator of $p_0$, i.e., $\\mathbb{E}[\\hat{p}_\\ell] = p_0$, with variance \n$$\n\\mathrm{Var}(\\hat{p}_\\ell) = \\frac{p_0(1-p_0)}{m}.\n$$\nThe SuS estimator for the failure probability is the product of the $L$ estimated conditional probabilities, \n$$\n\\hat{P}_f = \\prod_{\\ell=1}^L \\hat{p}_\\ell.\n$$\nAssuming independence across levels for the estimators (a standard design idealization providing a lower bound on variance when Markov Chain Monte Carlo correlations are negligible or effectively controlled), we can compute the variance of the product using the identity for independent random variables $X_1,\\dots,X_L$:\n$$\n\\mathrm{Var}\\!\\left(\\prod_{\\ell=1}^L X_\\ell\\right) = \\prod_{\\ell=1}^L \\mathbb{E}[X_\\ell^2] - \\prod_{\\ell=1}^L \\left(\\mathbb{E}[X_\\ell]\\right)^2.\n$$\nHere $X_\\ell=\\hat{p}_\\ell$, so we require $\\mathbb{E}[\\hat{p}_\\ell^2]$. For a sample proportion of $m$ independent Bernoulli trials with success probability $p_0$, we write\n$$\n\\mathbb{E}[\\hat{p}_\\ell^2] = \\mathrm{Var}(\\hat{p}_\\ell) + \\left(\\mathbb{E}[\\hat{p}_\\ell]\\right)^2 = \\frac{p_0(1-p_0)}{m} + p_0^2.\n$$\nSubstituting yields\n$$\n\\mathrm{Var}(\\hat{P}_f) = \\prod_{\\ell=1}^L \\left(p_0^2 + \\frac{p_0(1-p_0)}{m}\\right) - \\prod_{\\ell=1}^L p_0^2.\n$$\nBecause $p_0$ is constant across levels, this simplifies to\n$$\n\\mathrm{Var}(\\hat{P}_f) = \\left(p_0^2 + \\frac{p_0(1-p_0)}{m}\\right)^L - p_0^{2L}.\n$$\nIt is enlightening to factor $p_0^{2L}$:\n$$\n\\mathrm{Var}(\\hat{P}_f) = p_0^{2L}\\left[\\left(1 + \\frac{1-p_0}{m\\,p_0}\\right)^L - 1\\right],\n$$\nexplicitly showing how the variance scales with $m$ (decreasing as $m$ increases) and with $L$ (increasing with more levels for fixed $m$ and $p_0$). Note that the mean of the estimator is $\\mathbb{E}[\\hat{P}_f]=p_0^L$, consistent with an unbiased product estimator under independence.\n\nAlgorithmic design for the program:\n1. For each test case $(p_0,m,L)$, compute the level thresholds $b_\\ell$ using $b_\\ell=\\Phi^{-1}(1-p_0^\\ell)$ for $\\ell=1,\\dots,L$ with $\\mu=0$, $\\sigma=1$. This validates the threshold design step but does not affect the variance expression under the independence surrogate.\n2. Compute the estimator variance using \n$$\n\\mathrm{Var}(\\hat{P}_f) = \\left(p_0^2 + \\frac{p_0(1-p_0)}{m}\\right)^L - p_0^{2L}.\n$$\n3. Aggregate the variances for the five test cases into a single list and print it as a single line in the required format.\n\nThis approach is grounded in the foundational definitions of Bernoulli trials and properties of independent random variables, connecting the geomechanical rare-event estimation task to a tractable statistical design formula. The Gaussian threshold design aligns with the monotonic mapping from unconditional tail probabilities to quantiles, ensuring a scientifically realistic and self-consistent setup for Subset Simulation in the rare-event regime.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef subset_sim_variance(p0: float, m: int, L: int) - float:\n    \"\"\"\n    Compute the variance of the Subset Simulation estimator under\n    the independence surrogate:\n        Var(P_hat_f) = (p0^2 + p0*(1 - p0)/m)^L - p0^(2L)\n    \"\"\"\n    term = (p0 ** 2) + (p0 * (1.0 - p0) / m)\n    return (term ** L) - (p0 ** (2 * L))\n\ndef design_thresholds_gaussian(p0: float, L: int, mu: float = 0.0, sigma: float = 1.0):\n    \"\"\"\n    Design intermediate thresholds for Y ~ N(mu, sigma^2) such that\n    P(Y = b_l) = p0^l for l = 1..L.\n    Returns a list of thresholds [b_1, ..., b_L].\n    \"\"\"\n    thresholds = []\n    for l in range(1, L + 1):\n        tail_prob = p0 ** l\n        # b_l = mu + sigma * Phi^{-1}(1 - p0^l)\n        bl = mu + sigma * norm.ppf(1.0 - tail_prob)\n        thresholds.append(bl)\n    return thresholds\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case is a tuple: (p0, m, L)\n    test_cases = [\n        (0.1, 1000, 6),   # Typical rare-event design P_f ≈ 1e-6\n        (0.1, 200, 6),    # Smaller m increases variance\n        (0.1, 10000, 6),  # Larger m decreases variance\n        (0.2, 800, 9),    # Different p0, similar rarity\n        (0.05, 500, 5),   # More aggressive p0 with fewer levels\n    ]\n\n    results = []\n    for p0, m, L in test_cases:\n        # Threshold design (computed but not printed, validates the design step)\n        _thresholds = design_thresholds_gaussian(p0, L, mu=0.0, sigma=1.0)\n\n        # Compute variance of the SuS estimator under independence surrogate\n        var_est = subset_sim_variance(p0, m, L)\n        results.append(var_est)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}