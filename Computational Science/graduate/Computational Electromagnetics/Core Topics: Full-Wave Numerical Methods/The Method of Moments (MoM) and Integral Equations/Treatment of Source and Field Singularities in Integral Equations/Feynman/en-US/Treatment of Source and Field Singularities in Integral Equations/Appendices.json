{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of the Boundary Element Method is the analytical regularization of singular integrals that appear when the observation point lies on a source element. This exercise guides you through a classic and powerful technique based on the divergence theorem. You will see how a challenging two-dimensional integral of a double-layer potential kernel over a flat triangle can be exactly transformed into the sum of a purely geometric term—the solid angle—and a set of simple one-dimensional line integrals along the element's edges . Mastering this transformation is a fundamental step toward building accurate and robust computational electromagnetics codes.",
            "id": "3357681",
            "problem": "Consider the electrostatic limit of the three-dimensional free-space Green’s function for the Laplace equation, defined by $G(\\mathbf{r},\\mathbf{r}_0)=\\frac{1}{4\\pi |\\mathbf{r}-\\mathbf{r}_0|}$, where $\\mathbf{r}\\in\\mathbb{R}^{3}$ is the source point and $\\mathbf{r}_0\\in\\mathbb{R}^{3}$ is the field point. In a boundary integral formulation, the double-layer operator involves the kernel $\\nabla_{\\mathbf{r}_0}G(\\mathbf{r},\\mathbf{r}_0)$ integrated over a surface patch. Let $T$ be a planar triangle with vertices $\\mathbf{r}_1,\\mathbf{r}_2,\\mathbf{r}_3\\in\\mathbb{R}^{3}$, whose unit normal $\\mathbf{n}$ is chosen so that $\\mathbf{r}_1,\\mathbf{r}_2,\\mathbf{r}_3$ are ordered counterclockwise when viewed along $\\mathbf{n}$. Define the three directed edges by the ordered pairs $(\\mathbf{r}_1,\\mathbf{r}_2)$, $(\\mathbf{r}_2,\\mathbf{r}_3)$, and $(\\mathbf{r}_3,\\mathbf{r}_1)$. For each edge $e\\in\\{1,2,3\\}$, let $\\mathbf{t}_e$ be the unit tangent pointing from its first to its second vertex, and define the outward in-plane unit normal by $\\mathbf{m}_e=\\mathbf{n}\\times \\mathbf{t}_e$.\n\nLet $\\mathbf{a}\\in\\mathbb{R}^{3}$ be a constant vector. Denote by $R=|\\mathbf{r}-\\mathbf{r}_0|$, and write $\\mathbf{R}_i=\\mathbf{r}_i-\\mathbf{r}_0$ and $R_i=|\\mathbf{R}_i|$ for $i\\in\\{1,2,3\\}$. For each edge $e$ with endpoints $\\mathbf{r}_{e,1}$ and $\\mathbf{r}_{e,2}$, let $\\mathbf{p}_e$ be the closest point to $\\mathbf{r}_0$ on the infinite line containing the edge, define the signed along-edge coordinates $s_{e,i}=(\\mathbf{r}_{e,i}-\\mathbf{p}_e)\\cdot \\mathbf{t}_e$ for $i\\in\\{1,2\\}$, and set $\\rho_e=|\\mathbf{r}_0-\\mathbf{p}_e|$, the perpendicular distance from $\\mathbf{r}_0$ to that line.\n\nUsing only the fundamental laws and core definitions of potential theory and vector calculus, derive an analytic closed-form expression for the integral\n$$\nI(\\mathbf{a})=\\int_{T}\\frac{(\\mathbf{r}-\\mathbf{r}_0)\\cdot \\mathbf{a}}{R^{3}}\\,\\mathrm{d}S,\n$$\nexpressed in terms of the geometric data $\\{\\mathbf{r}_i\\}$, $\\mathbf{n}$, $\\{\\mathbf{t}_e\\}$, $\\{\\mathbf{m}_e\\}$, $\\{s_{e,i}\\}$, and $\\{\\rho_e\\}$.\n\nYour final expression must be a single closed-form analytic expression. No numerical evaluation is required. Additionally, explain the relevance of your result to the treatment of double-layer terms in boundary integral equations for electrostatics, including how the normal component recovers the solid angle and how the tangential component reduces to edge integrals that are free of singular field-point behavior. The final answer should be presented as an expression without units and does not require rounding.",
            "solution": "The problem asks for the derivation of a closed-form analytic expression for the integral\n$$\nI(\\mathbf{a})=\\int_{T}\\frac{(\\mathbf{r}-\\mathbf{r}_0)\\cdot \\mathbf{a}}{R^{3}}\\,\\mathrm{d}S,\n$$\nwhere $T$ is a planar triangle, $\\mathbf{r}_0$ is a field point, $\\mathbf{a}$ is a constant vector, and $R=|\\mathbf{r}-\\mathbf{r}_0|$. The integrand is related to the gradient of the free-space Green's function for the Laplace equation, $G(\\mathbf{r},\\mathbf{r}_0) = \\frac{1}{4\\pi R}$. Specifically, $\\nabla_{\\mathbf{r}}G = -\\frac{\\mathbf{r}-\\mathbf{r}_0}{4\\pi R^3}$. Thus, the integrand is proportional to $\\mathbf{a} \\cdot \\nabla_{\\mathbf{r}} (1/R)$.\n\nWe proceed by decomposing the constant vector $\\mathbf{a}$ into its components normal and tangential to the plane of the triangle $T$. Let $\\mathbf{n}$ be the unit normal to the plane of $T$. We can write\n$$\n\\mathbf{a} = (\\mathbf{a}\\cdot\\mathbf{n})\\mathbf{n} + (\\mathbf{a} - (\\mathbf{a}\\cdot\\mathbf{n})\\mathbf{n}) = \\mathbf{a}_n + \\mathbf{a}_t,\n$$\nwhere $\\mathbf{a}_n = (\\mathbf{a}\\cdot\\mathbf{n})\\mathbf{n}$ is the normal component and $\\mathbf{a}_t$ is the tangential component, which lies in the plane of $T$.\nSubstituting this decomposition into the integral yields two parts:\n$$\nI(\\mathbf{a}) = \\int_{T}\\frac{(\\mathbf{r}-\\mathbf{r}_0)\\cdot \\mathbf{a}_n}{R^{3}}\\,\\mathrm{d}S + \\int_{T}\\frac{(\\mathbf{r}-\\mathbf{r}_0)\\cdot \\mathbf{a}_t}{R^{3}}\\,\\mathrm{d}S = I_n + I_t.\n$$\n\nFirst, we evaluate the normal component integral, $I_n$:\n$$\nI_n = \\int_{T}\\frac{(\\mathbf{r}-\\mathbf{r}_0)\\cdot ((\\mathbf{a}\\cdot\\mathbf{n})\\mathbf{n})}{R^{3}}\\,\\mathrm{d}S = (\\mathbf{a}\\cdot\\mathbf{n}) \\int_{T}\\frac{(\\mathbf{r}-\\mathbf{r}_0)\\cdot \\mathbf{n}}{R^{3}}\\,\\mathrm{d}S.\n$$\nThe integral term is, by definition, the negative of the solid angle $\\Omega(T)$ subtended by the triangle $T$ at the field point $\\mathbf{r}_0$.\n$$\n\\Omega(T) \\equiv -\\int_{T}\\frac{(\\mathbf{r}-\\mathbf{r}_0)\\cdot \\mathbf{n}}{R^{3}}\\,\\mathrm{d}S.\n$$\nTherefore, the contribution from the normal component of $\\mathbf{a}$ is\n$$\nI_n = -(\\mathbf{a}\\cdot\\mathbf{n})\\Omega(T).\n$$\nThe solid angle $\\Omega(T)$ is a standard geometric quantity that depends on the vertices of the triangle $\\{\\mathbf{r}_1, \\mathbf{r}_2, \\mathbf{r}_3\\}$ and the field point $\\mathbf{r}_0$.\n\nNext, we evaluate the tangential component integral, $I_t$:\n$$\nI_t = \\int_{T}\\frac{(\\mathbf{r}-\\mathbf{r}_0)\\cdot \\mathbf{a}_t}{R^{3}}\\,\\mathrm{d}S.\n$$\nWe recognize that $\\frac{\\mathbf{r}-\\mathbf{r}_0}{R^3} = -\\nabla_{\\mathbf{r}}\\left(\\frac{1}{R}\\right)$. Since $\\mathbf{a}_t$ lies in the plane of the triangle, the dot product with the gradient can be expressed using the surface gradient operator, $\\nabla_S$:\n$$\n(\\mathbf{r}-\\mathbf{r}_0)\\cdot \\mathbf{a}_t / R^3 = -\\left(\\nabla_{\\mathbf{r}}\\frac{1}{R}\\right)\\cdot\\mathbf{a}_t = -\\left(\\nabla_S\\frac{1}{R}\\right)\\cdot\\mathbf{a}_t.\n$$\nWe use the vector identity for the surface divergence: $\\nabla_S \\cdot (\\phi \\mathbf{V}) = (\\nabla_S \\phi) \\cdot \\mathbf{V} + \\phi (\\nabla_S \\cdot \\mathbf{V})$. Let $\\phi = 1/R$ and $\\mathbf{V} = \\mathbf{a}_t$. Since $\\mathbf{a}_t$ is a constant vector, its surface divergence is zero, $\\nabla_S \\cdot \\mathbf{a}_t = 0$. Thus,\n$$\n\\nabla_S \\cdot \\left(\\frac{\\mathbf{a}_t}{R}\\right) = \\left(\\nabla_S \\frac{1}{R}\\right) \\cdot \\mathbf{a}_t.\n$$\nThe integrand of $I_t$ is therefore $-\\nabla_S \\cdot \\left(\\frac{\\mathbf{a}_t}{R}\\right)$. We can now apply the 2D divergence theorem (a variant of Green's theorem) to the planar surface $T$:\n$$\n\\int_T (\\nabla_S \\cdot \\mathbf{W}) \\,\\mathrm{d}S = \\oint_{\\partial T} \\mathbf{W} \\cdot \\mathbf{m} \\,\\mathrm{d}l,\n$$\nwhere $\\partial T$ is the boundary of the triangle (composed of its three edges) and $\\mathbf{m}$ is the outward-pointing in-plane unit normal to the boundary edge. The problem defines this vector as $\\mathbf{m}_e$ for each edge $e$.\nApplying this theorem to $I_t$:\n$$\nI_t = - \\int_T \\nabla_S \\cdot \\left(\\frac{\\mathbf{a}_t}{R}\\right) \\,\\mathrm{d}S = - \\oint_{\\partial T} \\frac{\\mathbf{a}_t}{R} \\cdot \\mathbf{m} \\,\\mathrm{d}l.\n$$\nThe boundary integral consists of a sum over the three edges of the triangle, which we label $e \\in \\{1,2,3\\}$:\n$$\nI_t = - \\sum_{e=1}^3 \\int_{e} \\frac{\\mathbf{a}_t \\cdot \\mathbf{m}_e}{R} \\,\\mathrm{d}l.\n$$\nFor a given edge $e$, the vectors $\\mathbf{a}_t$ and $\\mathbf{m}_e$ are constant. We can factor them out of the integral:\n$$\nI_t = - \\sum_{e=1}^3 (\\mathbf{a}_t \\cdot \\mathbf{m}_e) \\int_{e} \\frac{\\mathrm{d}l}{R}.\n$$\nThe term $\\mathbf{a}_t \\cdot \\mathbf{m}_e = (\\mathbf{a} - (\\mathbf{a}\\cdot\\mathbf{n})\\mathbf{n}) \\cdot \\mathbf{m}_e$. Since $\\mathbf{m}_e = \\mathbf{n} \\times \\mathbf{t}_e$, $\\mathbf{m}_e$ is orthogonal to $\\mathbf{n}$. Therefore, $\\mathbf{n} \\cdot \\mathbf{m}_e = 0$, and the expression simplifies to $\\mathbf{a}_t \\cdot \\mathbf{m}_e = \\mathbf{a} \\cdot \\mathbf{m}_e$.\n\nNow, we must evaluate the line integral $\\int_e \\frac{\\mathrm{d}l}{R}$ for each edge. For an edge $e$, let the line containing it be parameterized by a coordinate $s$, representing the signed distance along the unit tangent $\\mathbf{t}_e$ from the point $\\mathbf{p}_e$ (the closest point on the line to $\\mathbf{r}_0$). The distance $R$ from $\\mathbf{r}_0$ to a point $\\mathbf{r}$ on this line is $R = \\sqrt{s^2 + \\rho_e^2}$, where $\\rho_e = |\\mathbf{r}_0 - \\mathbf{p}_e|$ is the constant perpendicular distance from $\\mathbf{r}_0$ to the line. Let the edge start at a point corresponding to coordinate $s_{e,1}$ and end at $s_{e,2}$. The line integral becomes:\n$$\n\\int_e \\frac{\\mathrm{d}l}{R} = \\int_{s_{e,1}}^{s_{e,2}} \\frac{\\mathrm{d}s}{\\sqrt{s^2 + \\rho_e^2}}.\n$$\nThis is a standard integral whose antiderivative is $\\ln(s + \\sqrt{s^2 + \\rho_e^2})$. Evaluating at the limits gives:\n$$\n\\int_e \\frac{\\mathrm{d}l}{R} = \\left[ \\ln(s + \\sqrt{s^2 + \\rho_e^2}) \\right]_{s_{e,1}}^{s_{e,2}} = \\ln(s_{e,2} + \\sqrt{s_{e,2}^2 + \\rho_e^2}) - \\ln(s_{e,1} + \\sqrt{s_{e,1}^2 + \\rho_e^2}).\n$$\nThis can be written compactly as a single logarithm:\n$$\n\\int_e \\frac{\\mathrm{d}l}{R} = \\ln \\left( \\frac{s_{e,2} + \\sqrt{s_{e,2}^2+\\rho_e^2}}{s_{e,1} + \\sqrt{s_{e,1}^2+\\rho_e^2}} \\right).\n$$\nSubstituting this back into the expression for $I_t$:\n$$\nI_t = - \\sum_{e=1}^3 (\\mathbf{a} \\cdot \\mathbf{m}_e) \\ln \\left( \\frac{s_{e,2} + \\sqrt{s_{e,2}^2+\\rho_e^2}}{s_{e,1} + \\sqrt{s_{e,1}^2+\\rho_e^2}} \\right).\n$$\nCombining the normal and tangential parts, we arrive at the final expression for the integral $I(\\mathbf{a})$:\n$$\nI(\\mathbf{a}) = -(\\mathbf{a} \\cdot \\mathbf{n})\\Omega(T) - \\sum_{e=1}^3 (\\mathbf{a} \\cdot \\mathbf{m}_e) \\ln \\left( \\frac{s_{e,2} + \\sqrt{s_{e,2}^2+\\rho_e^2}}{s_{e,1} + \\sqrt{s_{e,1}^2+\\rho_e^2}} \\right).\n$$\n\nThis result is highly relevant to the numerical solution of boundary integral equations (BIEs) in electrostatics using the boundary element method (BEM).\n1.  **Double-Layer Term and Solid Angle:** The double-layer potential operator kernel is $\\frac{\\partial G}{\\partial n} = -\\frac{1}{4\\pi}\\frac{(\\mathbf{r}-\\mathbf{r}_0)\\cdot\\mathbf{n}}{R^3}$. When discretizing the BIE, one must compute integrals of this kernel over triangular panels. Our result for $\\mathbf{a}=\\mathbf{n}$ shows that $\\int_T \\frac{(\\mathbf{r}-\\mathbf{r}_0)\\cdot\\mathbf{n}}{R^3} \\mathrm{d}S = -(\\mathbf{n}\\cdot\\mathbf{n})\\Omega(T) - \\sum (\\mathbf{n}\\cdot\\mathbf{m}_e)\\ln(\\dots) = -\\Omega(T)$, since $\\mathbf{n}\\cdot\\mathbf{n}=1$ and $\\mathbf{n}\\cdot\\mathbf{m}_e = 0$. This analytically confirms that the integral of the double-layer kernel over a flat panel is precisely the negative of the solid angle subtended by the panel at the field point. This is crucial for evaluating the diagonal entries of the BEM matrix, where the singularity becomes most acute.\n\n2.  **Regularization of Singularities:** The original integral has an integrand of order $O(1/R^2)$. When the field point $\\mathbf{r}_0$ is very close to the triangle $T$, this integrand varies rapidly, making numerical quadrature difficult and inaccurate. Our derived formula transforms this challenging 2D integral into the sum of a solid angle term and three 1D edge contributions involving logarithms. This is a form of regularization. The \"singular behavior\" is analytically captured and isolated. The resulting expression is well-behaved and can be computed accurately and efficiently, even for field points close to the source triangle (as long as $\\mathbf{r}_0$ is not directly on an edge, where the logarithmic terms' arguments require careful handling). This analytical treatment is fundamental for the stability and accuracy of BEM implementations. The tangential part of the integral, which might appear in more complex physics problems (e.g., vector potential formulations), is reduced to a simple sum of edge terms, completely avoiding a 2D integration of a singular kernel.",
            "answer": "$$\n\\boxed{-(\\mathbf{a} \\cdot \\mathbf{n})\\Omega(T) - \\sum_{e=1}^3 (\\mathbf{a} \\cdot \\mathbf{m}_e) \\ln \\left( \\frac{s_{e,2} + \\sqrt{s_{e,2}^{2}+\\rho_e^{2}}}{s_{e,1} + \\sqrt{s_{e,1}^{2}+\\rho_e^{2}}} \\right)}\n$$"
        },
        {
            "introduction": "While many formulations involve weakly singular kernels, more advanced boundary integral equations, such as the Electric Field Integral Equation (EFIE), give rise to even stronger \"hypersingular\" kernels. These integrals diverge in the standard sense and require a more abstract regularization framework. This practice uses a one-dimensional model to introduce the powerful concept of the Hadamard finite-part (HFP) integral, which assigns a meaningful, finite value to such integrals by systematically canceling the divergent parts . This exercise will give you a concrete feel for a technique that is essential for working with some of the most important integral equations in electromagnetics.",
            "id": "3357670",
            "problem": "In computational electromagnetics, hypersingular boundary integral operators arise, for example, from taking normal derivatives of layer potentials, and are commonly regularized using the Hadamard finite-part (HFP) interpretation. Consider the one-dimensional scalar proxy of such a hypersingular form on the interval $[-1,1]$, given by\n$$\nI[\\phi] \\equiv \\text{f.p.} \\int_{-1}^{1} \\frac{\\phi(x)-\\phi(0)}{x^{2}} \\,\\mathrm{d}x,\n$$\nwhere the notation $\\text{f.p.}$ denotes the Hadamard finite-part integral, interpreted via the symmetric limit\n$$\n\\text{f.p.} \\int_{-1}^{1} \\frac{\\phi(x)-\\phi(0)}{x^{2}} \\,\\mathrm{d}x \\equiv \\lim_{\\varepsilon \\to 0^{+}} \\left( \\int_{-1}^{-\\varepsilon} \\frac{\\phi(x)-\\phi(0)}{x^{2}} \\,\\mathrm{d}x + \\int_{\\varepsilon}^{1} \\frac{\\phi(x)-\\phi(0)}{x^{2}} \\,\\mathrm{d}x \\right).\n$$\nTake the smooth density $\\phi(x)=\\exp(\\alpha x)$ with a real parameter $\\alpha \\in \\mathbb{R}$. Compute the analytic expression of $I[\\phi]$ as a closed-form function of $\\alpha$, expressing any special functions explicitly by name. Your final answer must be a single closed-form analytic expression in terms of $\\alpha$. No numerical approximation is required.\n\nIn your derivation, start from the definition of the Hadamard finite-part integral, use first principles of integration (such as integration by parts and the Cauchy principal value where appropriate), and clearly justify any limiting processes at $x=0$. Then, briefly explain how the structure of your result reflects the general pattern of hypersingular kernel regularization in boundary integral equations (BIEs) in computational electromagnetics, highlighting the emergence of a leading local term tied to smoothness of $\\phi$ near $x=0$ and the role of symmetric cancellation.",
            "solution": "The problem is to compute the Hadamard finite-part (HFP) integral\n$$\nI[\\phi] \\equiv \\text{f.p.} \\int_{-1}^{1} \\frac{\\phi(x)-\\phi(0)}{x^{2}} \\,\\mathrm{d}x\n$$\nfor the density function $\\phi(x) = \\exp(\\alpha x)$, where the HFP integral is defined by the symmetric limit\n$$\nI[\\phi] = \\lim_{\\varepsilon \\to 0^{+}} \\left( \\int_{-1}^{-\\varepsilon} \\frac{\\phi(x)-\\phi(0)}{x^{2}} \\,\\mathrm{d}x + \\int_{\\varepsilon}^{1} \\frac{\\phi(x)-\\phi(0)}{x^{2}} \\,\\mathrm{d}x \\right).\n$$\nTo compute the integral, we can simplify the expression by exploiting the symmetry of the integration domain. We split the integral over $[-1,1]$ into two parts, $[-1,0]$ and $[0,1]$. For the integral over $[-1, -\\varepsilon]$, we perform a change of variables $u = -x$, which gives $\\mathrm{d}u = -\\mathrm{d}x$. The limits of integration change from $x=-1$ to $u=1$ and from $x=-\\varepsilon$ to $u=\\varepsilon$.\n$$\n\\int_{-1}^{-\\varepsilon} \\frac{\\phi(x)-\\phi(0)}{x^{2}} \\,\\mathrm{d}x = \\int_{1}^{\\varepsilon} \\frac{\\phi(-u)-\\phi(0)}{(-u)^{2}} (-\\mathrm{d}u) = \\int_{\\varepsilon}^{1} \\frac{\\phi(-u)-\\phi(0)}{u^{2}} \\,\\mathrm{d}u.\n$$\nSubstituting this back into the HFP definition, and using $x$ as the dummy variable of integration, we get\n$$\nI[\\phi] = \\lim_{\\varepsilon \\to 0^{+}} \\left( \\int_{\\varepsilon}^{1} \\frac{\\phi(-x)-\\phi(0)}{x^{2}} \\,\\mathrm{d}x + \\int_{\\varepsilon}^{1} \\frac{\\phi(x)-\\phi(0)}{x^{2}} \\,\\mathrm{d}x \\right) = \\lim_{\\varepsilon \\to 0^{+}} \\int_{\\varepsilon}^{1} \\frac{\\phi(x) + \\phi(-x) - 2\\phi(0)}{x^{2}} \\,\\mathrm{d}x.\n$$\nNow, we analyze the behavior of the new integrand near $x=0$. The Taylor expansion of a sufficiently smooth function $\\phi(x)$ around $x=0$ is $\\phi(x) = \\phi(0) + \\phi'(0)x + \\frac{\\phi''(0)}{2!}x^2 + O(x^3)$. Then, $\\phi(-x) = \\phi(0) - \\phi'(0)x + \\frac{\\phi''(0)}{2!}x^2 - O(x^3)$.\nThe numerator is $\\phi(x) + \\phi(-x) - 2\\phi(0) = (\\phi(0) + \\phi'(0)x + \\dots) + (\\phi(0) - \\phi'(0)x + \\dots) - 2\\phi(0) = \\phi''(0)x^2 + O(x^4)$.\nThe integrand is therefore $\\frac{\\phi''(0)x^2 + O(x^4)}{x^2} = \\phi''(0) + O(x^2)$, which is regular at $x=0$. Thus, the limit can be brought inside the integral, and the HFP integral is equivalent to the standard Riemann integral:\n$$\nI[\\phi] = \\int_{0}^{1} \\frac{\\phi(x) + \\phi(-x) - 2\\phi(0)}{x^{2}} \\,\\mathrm{d}x.\n$$\nFor the given function $\\phi(x) = \\exp(\\alpha x)$, we have $\\phi(-x) = \\exp(-\\alpha x)$ and $\\phi(0) = \\exp(0) = 1$. The integral becomes\n$$\nI[\\phi] = \\int_{0}^{1} \\frac{\\exp(\\alpha x) + \\exp(-\\alpha x) - 2}{x^{2}} \\,\\mathrm{d}x.\n$$\nUsing the identity $\\cosh(z) = \\frac{\\exp(z) + \\exp(-z)}{2}$, the numerator is $2\\cosh(\\alpha x) - 2$.\n$$\nI[\\phi] = \\int_{0}^{1} \\frac{2\\cosh(\\alpha x) - 2}{x^{2}} \\,\\mathrm{d}x.\n$$\nWe compute this definite integral using integration by parts, $\\int u \\, \\mathrm{d}v = uv - \\int v \\, \\mathrm{d}u$.\nLet $u = 2\\cosh(\\alpha x) - 2$ and $\\mathrm{d}v = x^{-2} \\,\\mathrm{d}x$.\nThen $\\mathrm{d}u = 2\\alpha\\sinh(\\alpha x) \\,\\mathrm{d}x$ and $v = -x^{-1}$.\n$$\nI[\\phi] = \\left[ -\\frac{2\\cosh(\\alpha x) - 2}{x} \\right]_{0}^{1} - \\int_{0}^{1} \\left(-\\frac{1}{x}\\right) (2\\alpha\\sinh(\\alpha x)) \\,\\mathrm{d}x.\n$$\nThe boundary term is evaluated as:\n$$\n\\left[ -\\frac{2\\cosh(\\alpha x) - 2}{x} \\right]_{0}^{1} = \\left(-\\frac{2\\cosh(\\alpha) - 2}{1}\\right) - \\lim_{x \\to 0^{+}} \\left(-\\frac{2\\cosh(\\alpha x) - 2}{x}\\right).\n$$\nThe limit at $x=0$ can be evaluated using L'Hôpital's rule:\n$$\n\\lim_{x \\to 0^{+}} \\frac{-2\\cosh(\\alpha x) + 2}{x} = \\lim_{x \\to 0^{+}} \\frac{-2\\alpha\\sinh(\\alpha x)}{1} = 0.\n$$\nSo the boundary term evaluates to $-(2\\cosh(\\alpha) - 2) = 2 - 2\\cosh(\\alpha)$.\n\nThe remaining integral is:\n$$\n\\int_{0}^{1} \\frac{2\\alpha\\sinh(\\alpha x)}{x} \\,\\mathrm{d}x = 2\\alpha \\int_{0}^{1} \\frac{\\sinh(\\alpha x)}{x} \\,\\mathrm{d}x.\n$$\nWe make the substitution $t = \\alpha x$, so $\\mathrm{d}t = \\alpha\\,\\mathrm{d}x$ and $x=t/\\alpha$. The limits change from $x=0$ to $t=0$ and $x=1$ to $t=\\alpha$.\n$$\n2\\alpha \\int_{0}^{\\alpha} \\frac{\\sinh(t)}{t/\\alpha} \\frac{\\mathrm{d}t}{\\alpha} = 2\\alpha \\int_{0}^{\\alpha} \\frac{\\sinh(t)}{t} \\,\\mathrm{d}t.\n$$\nThe integral $\\int_0^z \\frac{\\sinh t}{t} \\mathrm{d}t$ defines the Hyperbolic Sine Integral, denoted $\\text{Shi}(z)$. Thus, this term is $2\\alpha \\text{Shi}(\\alpha)$.\n\nCombining the parts, we obtain the final expression for $I[\\phi]$:\n$$\nI[\\phi] = (2 - 2\\cosh(\\alpha)) + 2\\alpha \\text{Shi}(\\alpha).\n$$\n\nThis result reflects the general structure of hypersingular kernel regularization. The original operator is non-local and singular. The regularization process effectively splits the operator's action into a local part and a regular non-local part. The transformation to the regular integral $\\int_0^1 \\frac{\\phi(x)+\\phi(-x)-2\\phi(0)}{x^2} \\mathrm{d}x$ is key. It shows that the $1/x^2$ singularity is tamed by subtracting terms from the density's Taylor expansion ($\\phi(0)$ and cancelling the $\\phi'(0)x$ term by symmetrization) until the numerator vanishes to second order at the origin. The leading behavior for small $\\alpha$ is $I[\\phi] \\approx \\alpha^2 = \\phi''(0)$, demonstrating that the value of the hypersingular integral is tied to the second derivative of the density at the singularity, a general feature for $1/r^2$-type kernels. The IBP calculation reveals a different structure common in BIE analysis: the result is a sum of boundary terms ($2 - 2\\cosh(\\alpha)$) and a weakly singular integral, which here resolves to the special function $2\\alpha \\text{Shi}(\\alpha)$. The symmetric cancellation inherent in the HFP definition is the fundamental mechanism allowing this regularization.",
            "answer": "$$\n\\boxed{2\\alpha \\text{Shi}(\\alpha) - 2\\cosh(\\alpha) + 2}\n$$"
        },
        {
            "introduction": "The theoretical correctness of a singularity treatment scheme is ultimately tested by its impact on the final discretized linear system. This hands-on coding exercise provides a numerical laboratory to investigate how subtle errors in evaluating singular \"self-interaction\" terms can corrupt the physical and numerical properties of a Method of Moments matrix. By modeling a simple thin-wire antenna, you will implement diagnostics to measure the loss of physical reciprocity and the degradation of matrix conditioning, directly linking abstract mathematical errors to concrete numerical instability . This practice bridges the gap between analytical theory and the practical realities of building stable numerical solvers.",
            "id": "3357690",
            "problem": "You are asked to design and implement a numerical diagnostic to assess how inaccuracies in the evaluation of singular self-interactions alter the spectral properties and conditioning of matrices arising from the Electric Field Integral Equation (EFIE), and to propose symmetry- and reciprocity-based tests to detect such issues. Your implementation must be a complete, runnable program. The setting is a simplified, but scientifically consistent, one-dimensional discretization model of a thin, straight Perfect Electric Conductor (PEC) wire using the Method of Moments (MoM) with pulse (piecewise-constant) basis functions and collocation at segment midpoints.\n\nBegin from the following fundamental base:\n\n- Maxwell's equations in the frequency domain imply that the scattered field from surface currents can be represented by an integral involving the free-space Green's function. The Electric Field Integral Equation (EFIE), for a PEC, enforces the vanishing of the total tangential electric field on the scatterer surface, leading to an integral operator whose kernel is the free-space Green's function.\n- The free-space Green's function of the three-dimensional Helmholtz equation is $G(\\mathbf{r},\\mathbf{r}') = \\dfrac{e^{\\mathrm{i} k \\lVert \\mathbf{r} - \\mathbf{r}' \\rVert}}{4\\pi \\lVert \\mathbf{r} - \\mathbf{r}' \\rVert}$, where $k$ is the wavenumber measured in inverse meters ($\\mathrm{m}^{-1}$). The integral operator built from $G$ exhibits a source singularity at $\\mathbf{r} = \\mathbf{r}'$ and field singularities at near-coincident source-observation points; these must be treated carefully in discretizations to maintain physical reciprocity and desirable numerical conditioning.\n\nYour task is to:\n\n1. Mathematically formulate a discrete EFIE system for a straight thin wire of length $L$ aligned with the $x$-axis, subdivided into $N$ equal segments of length $\\Delta = L/N$. Let the segment midpoints be $x_i = \\left(i + \\tfrac{1}{2}\\right)\\Delta$ for $i \\in \\{0,1,\\dots,N-1\\}$. Use pulse basis/testing functions (collocation at midpoints). Define the matrix entries $A_{ij}$ by midpoint approximation of the double integral with the free-space Green's function:\n   - For $i \\neq j$, define $A_{ij} = \\Delta^2 \\, \\dfrac{e^{\\mathrm{i} k \\lvert x_i - x_j \\rvert}}{4\\pi \\lvert x_i - x_j \\rvert}$.\n   - For $i = j$, replace the singular term by a thin-wire regularization consistent with a finite wire radius $a$ (in meters), using a physically plausible effective self-term $A_{ii}^{\\text{true}} = \\Delta^2 \\, \\dfrac{1}{4\\pi a}$. Then introduce an inaccurate self-term model $A_{ii}^{\\text{inacc}} = A_{ii}^{\\text{true}} \\, (1 + \\varepsilon)$, where $\\varepsilon$ is a dimensionless relative error parameter. This models errors in treating the source singularity on the diagonal.\n   - To model inaccuracies in near-singular field interactions that can break reciprocity (while keeping the same testing and basis functions), allow optional asymmetric perturbations on immediate neighbor interactions: for $\\lvert i - j \\rvert = 1$ and $i < j$, add a skew term $\\delta_{ij} = \\eta \\, \\operatorname{Re}(A_{ij})$ to $A_{ij}$ only (do not add it to $A_{ji}$), where $\\eta$ is a dimensionless skew parameter. This simulates inconsistent handling of weak singularities or non-symmetric quadrature.\n\n2. Propose and implement diagnostics grounded in symmetry and reciprocity:\n   - Symmetry residual: $s = \\dfrac{\\lVert A - A^{\\mathsf{T}} \\rVert_{\\mathrm{F}}}{\\lVert A \\rVert_{\\mathrm{F}}}$, where $\\lVert \\cdot \\rVert_{\\mathrm{F}}$ denotes the Frobenius norm and $(\\cdot)^{\\mathsf{T}}$ denotes the transpose. In a reciprocal, Galerkin discretization with symmetric kernel, the matrix should be complex symmetric ($A = A^{\\mathsf{T}}$), so $s$ diagnoses reciprocity-breaking asymmetries.\n   - Reciprocity maximum relative discrepancy: $r = \\max_{i < j} \\dfrac{\\lvert A_{ij} - A_{ji} \\rvert}{\\max(\\lvert A_{ij} \\rvert, \\lvert A_{ji} \\rvert, \\tau)}$, where $\\tau$ is a small positive threshold to avoid division by zero. This sharpens the symmetry residual by focusing on the worst offending pair.\n   - Spectral properties and conditioning: compute the singular values $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_N \\ge 0$ of $A$ and define the condition number $\\kappa = \\dfrac{\\sigma_{\\max}}{\\sigma_{\\min}^{+}}$, where $\\sigma_{\\max} = \\sigma_1$ and $\\sigma_{\\min}^{+}$ is the smallest singular value exceeding a numerical threshold $\\tau_\\sigma$. Also compute the spectral radius $\\rho = \\max_j \\lvert \\lambda_j \\rvert$, where $\\lambda_j$ are the eigenvalues of $A$. These metrics quantify how inaccurate self-term evaluation affects the spectrum and conditioning.\n\n3. Implement the above in code as a self-contained program that builds $A$ for given parameters $(N, L, a, k, \\varepsilon, \\eta)$, computes $(s, r, \\kappa, \\rho)$, and outputs them. All outputs should be dimensionless numbers. Use the following test suite to cover different facets:\n   - Case $1$ (happy path, accurate, reciprocal): $N = 16$, $L = 1.0\\,\\mathrm{m}$, $a = 1.0 \\times 10^{-3}\\,\\mathrm{m}$, $k = 10.0\\,\\mathrm{m}^{-1}$, $\\varepsilon = 0.0$, $\\eta = 0.0$.\n   - Case $2$ (moderate diagonal error, still reciprocal): $N = 16$, $L = 1.0\\,\\mathrm{m}$, $a = 1.0 \\times 10^{-3}\\,\\mathrm{m}$, $k = 10.0\\,\\mathrm{m}^{-1}$, $\\varepsilon = 0.1$, $\\eta = 0.0$.\n   - Case $3$ (underestimated diagonal, reciprocity broken near-diagonal): $N = 16$, $L = 1.0\\,\\mathrm{m}$, $a = 1.0 \\times 10^{-3}\\,\\mathrm{m}$, $k = 10.0\\,\\mathrm{m}^{-1}$, $\\varepsilon = -0.1$, $\\eta = 0.05$.\n   - Case $4$ (low-frequency boundary, strong diagonal error): $N = 32$, $L = 1.0\\,\\mathrm{m}$, $a = 1.0 \\times 10^{-3}\\,\\mathrm{m}$, $k = 1.0 \\times 10^{-3}\\,\\mathrm{m}^{-1}$, $\\varepsilon = 0.5$, $\\eta = 0.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one sub-list per test case in the order given, where each sub-list is $[s, r, \\kappa, \\rho]$. For example, the output format must be exactly like $[[s_1,r_1,\\kappa_1,\\rho_1],[s_2,r_2,\\kappa_2,\\rho_3],[s_3,r_3,\\kappa_3,\\rho_3],[s_4,r_4,\\kappa_4,\\rho_4]]$. No other text should be printed.",
            "solution": "The task is to design and implement a numerical diagnostic to assess the impact of inaccuracies in a Method of Moments (MoM) discretization of the Electric Field Integral Equation (EFIE) for a thin wire. The diagnostics will focus on how errors in evaluating singular and near-singular interactions affect the symmetry, reciprocity, spectral properties, and conditioning of the resulting MoM matrix.\n\n### 1. Mathematical Formulation of the MoM Matrix\n\nWe consider a straight, thin Perfect Electric Conductor (PEC) wire of length $L$ and radius $a$, centered on the $x$-axis. The wire is discretized into $N$ equal segments of length $\\Delta = L/N$. The current on the wire is approximated using piecewise-constant (pulse) basis functions, one for each segment. The EFIE is enforced at the midpoint of each segment (collocation or point-matching). This procedure leads to a linear system of equations of the form $A \\mathbf{I} = \\mathbf{V}$, where $A$ is the $N \\times N$ MoM matrix (often called the impedance matrix), $\\mathbf{I}$ is the vector of unknown coefficients for the basis functions (current amplitudes), and $\\mathbf{V}$ is the excitation vector derived from the incident electric field.\n\nThe entry $A_{ij}$ of the matrix represents the tangential electric field at the center of segment $i$ (the observation point, $x_i$) produced by a unit-amplitude current basis function on segment $j$ (the source segment, with center $x_j$). The midpoints are located at $x_m = (m + 1/2)\\Delta$ for $m \\in \\{0, 1, \\dots, N-1\\}$.\n\nThe problem defines the matrix entries using a midpoint approximation for the interaction integrals, based on the free-space Green's function for the Helmholtz equation, $G(\\mathbf{r}, \\mathbf{r}') = \\frac{e^{\\mathrm{i}k \\lVert \\mathbf{r} - \\mathbf{r}' \\rVert}}{4\\pi \\lVert \\mathbf{r} - \\mathbf{r}' \\rVert}$, where $k$ is the wavenumber. The problem statement omits the physical constants (such as $\\mathrm{i}\\omega\\mu_0$) that would give $A$ units of impedance; as defined, the entries of $A$ have units of length. This is acceptable for a numerical diagnostic where properties like symmetry and condition number, and relative changes in spectral radius, are of primary interest.\n\n**Off-Diagonal Entries ($i \\neq j$):**\nFor distinct source and observation segments, the interaction is approximated by evaluating the Green's function between the segment midpoints and multiplying by the product of segment lengths, $\\Delta^2$. The distance between midpoints is $\\lvert x_i - x_j \\rvert = \\lvert i - j \\rvert \\Delta$.\n$$\nA_{ij} = \\Delta^2 \\, \\frac{e^{\\mathrm{i} k \\lvert x_i - x_j \\rvert}}{4\\pi \\lvert x_i - x_j \\rvert} = \\Delta \\, \\frac{e^{\\mathrm{i} k \\lvert i - j \\rvert \\Delta}}{4\\pi \\lvert i - j \\rvert} \\quad \\text{for } i \\neq j\n$$\n\n**Diagonal Entries ($i = j$):**\nThe Green's function is singular when the source and observation points coincide ($i=j$), requiring regularization. A standard thin-wire approximation replaces the singular kernel with a regularized value that depends on the wire radius $a$.\nThe problem specifies a \"true\" physically plausible self-term:\n$$\nA_{ii}^{\\text{true}} = \\Delta^2 \\, \\frac{1}{4\\pi a}\n$$\nTo model inaccuracies in the evaluation of this self-interaction, a relative error parameter $\\varepsilon$ is introduced:\n$$\nA_{ii} = A_{ii}^{\\text{inacc}} = A_{ii}^{\\text{true}} (1 + \\varepsilon) = \\frac{\\Delta^2}{4\\pi a} (1 + \\varepsilon)\n$$\n\n**Asymmetric Perturbations:**\nNumerical quadrature errors or inconsistent modeling of near-singular interactions can violate the reciprocity principle, which manifests as an asymmetric matrix ($A \\neq A^{\\mathsf{T}}$). This is modeled by adding a skew term to near-diagonal elements. For adjacent segments where $|i - j| = 1$ and $i < j$ (i.e., on the upper first off-diagonal), a perturbation is added:\n$$\nA_{ij} \\to A_{ij} + \\delta_{ij} \\quad \\text{for } j = i+1\n$$\nwhere $\\delta_{ij} = \\eta \\, \\operatorname{Re}(A_{ij})$, and $\\eta$ is a dimensionless skew parameter. The corresponding lower off-diagonal entry $A_{ji}$ is not modified, thus breaking the matrix symmetry.\n\n### 2. Diagnostic Metrics for Matrix Analysis\n\nTo quantify the effects of these inaccuracies, we employ four diagnostic metrics:\n\n**Symmetry Residual ($s$):**\nReciprocity in electromagnetics implies that the MoM matrix should be symmetric ($A_{ij} = A_{ji}$) if the same basis and testing functions are used (a Galerkin scheme) and the geometry and medium are reciprocal. In our collocation scheme, the matrix is still expected to be symmetric ($A=A^{\\mathsf{T}}$) due to the symmetry of the Green's function, $G(\\mathbf{r}, \\mathbf{r}') = G(\\mathbf{r}', \\mathbf{r})$. The symmetry residual measures the deviation from this property in the Frobenius norm:\n$$\ns = \\frac{\\lVert A - A^{\\mathsf{T}} \\rVert_{\\mathrm{F}}}{\\lVert A \\rVert_{\\mathrm{F}}}\n$$\nA value of $s$ close to zero indicates a numerically reciprocal system.\n\n**Reciprocity Maximum Relative Discrepancy ($r$):**\nThis metric provides a worst-case measure of asymmetry, pinpointing the element pair with the largest violation of reciprocity.\n$$\nr = \\max_{i < j} \\frac{\\lvert A_{ij} - A_{ji} \\rvert}{\\max(\\lvert A_{ij} \\rvert, \\lvert A_{ji} \\rvert, \\tau)}\n$$\nHere, $\\tau$ is a small threshold to prevent division by small numbers. This metric is more sensitive than $s$ to localized errors.\n\n**Condition Number ($\\kappa$):**\nThe condition number of a matrix measures the sensitivity of the solution of the linear system $A\\mathbf{I}=\\mathbf{V}$ to perturbations in $A$ or $\\mathbf{V}$. A large condition number signifies an ill-conditioned system, where small numerical errors can lead to large errors in the computed current $\\mathbf{I}$. It is defined using the singular values ($\\sigma_j$) of $A$:\n$$\n\\kappa = \\frac{\\sigma_{\\max}}{\\sigma_{\\min}^{+}}\n$$\nwhere $\\sigma_{\\max}$ is the largest singular value, and $\\sigma_{\\min}^{+}$ is the smallest singular value greater than a machine-precision threshold $\\tau_\\sigma$. Errors in the self-term ($\\varepsilon \\neq 0$) can significantly alter the singular value spectrum and thus the conditioning.\n\n**Spectral Radius ($\\rho$):**\nThe spectral radius is the maximum magnitude of the matrix's eigenvalues ($\\lambda_j$):\n$$\n\\rho = \\max_j \\lvert \\lambda_j \\rvert\n$$\nIt is a fundamental quantity that governs the convergence rate of iterative solvers like GMRES or BiCGSTAB, which are often used for large-scale MoM problems. Changes in $\\rho$ due to numerical errors can impact solver performance and stability.\n\n### 3. Implementation and Analysis\n\nThe implementation involves constructing the matrix $A$ according to the rules above for each set of parameters $(N, L, a, k, \\varepsilon, \\eta)$. Once $A$ is assembled, the four diagnostic metrics are computed using standard numerical linear algebra routines.\n\nThe algorithm proceeds as follows for each test case:\n1.  Calculate discretization length $\\Delta = L/N$.\n2.  Initialize an $N \\times N$ complex matrix $A$.\n3.  Populate off-diagonal entries $A_{ij}$ for $i \\neq j$ using the Green's function formula.\n4.  Populate diagonal entries $A_{ii}$ using the regularized, perturbed self-term formula.\n5.  If $\\eta \\neq 0$, add the asymmetric perturbation $\\delta_{i,i+1}$ to the elements $A_{i,i+1}$ for $i \\in \\{0, \\dots, N-2\\}$.\n6.  Compute the symmetry residual $s$ from $A$ and its transpose $A^{\\mathsf{T}}$.\n7.  Compute the maximum relative reciprocity error $r$ by iterating through the upper triangle of $A$.\n8.  Compute the singular values of $A$ to find the condition number $\\kappa$.\n9.  Compute the eigenvalues of $A$ to find the spectral radius $\\rho$.\n10. Store the resulting tuple $(s, r, \\kappa, \\rho)$.\n\nThis process allows for a systematic study of how specific, modeled numerical errors corrupt the ideal properties of the Method of Moments matrix.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_and_analyze(N, L, a, k, eps, eta):\n    \"\"\"\n    Builds the MoM matrix for a 1D wire and computes diagnostic metrics.\n\n    Args:\n        N (int): Number of segments.\n        L (float): Length of the wire in meters.\n        a (float): Radius of the wire in meters.\n        k (float): Wavenumber in 1/meters.\n        eps (float): Relative error on diagonal terms.\n        eta (float): Skew parameter for near-diagonal asymmetry.\n\n    Returns:\n        tuple: A tuple containing (s, r, kappa, rho).\n    \"\"\"\n    \n    # Define numerical thresholds\n    tau = 1e-16  # Threshold for reciprocity discrepancy denominator\n    tau_sigma = 1e-16 # Threshold for singular values\n\n    # 1. Discretization and Matrix Construction\n    delta = L / N\n    A = np.zeros((N, N), dtype=np.complex128)\n\n    # Generate indices for vectorized computation\n    i_coords = np.arange(N).reshape(N, 1)\n    j_coords = np.arange(N).reshape(1, N)\n    \n    # Off-diagonal entries\n    dist_ij = np.abs(i_coords - j_coords)\n    off_diag_mask = (dist_ij != 0)\n    \n    R = dist_ij[off_diag_mask] * delta\n    \n    # Pre-factor for off-diagonal terms\n    # A_ij = Delta^2 * G(xi, xj) where G is the Green's function\n    # A_ij = Delta^2 * exp(i*k*R) / (4*pi*R)\n    c_off_diag = delta**2 / (4.0 * np.pi)\n    A[off_diag_mask] = c_off_diag * np.exp(1j * k * R) / R\n\n    # Diagonal entries\n    # A_ii = Delta^2 / (4*pi*a) * (1 + eps)\n    A_ii_true = (delta**2) / (4.0 * np.pi * a)\n    A_ii_inacc = A_ii_true * (1.0 + eps)\n    np.fill_diagonal(A, A_ii_inacc)\n\n    # Asymmetric perturbations\n    if eta != 0.0:\n        for i in range(N - 1):\n            j = i + 1\n            # For i < j and |i-j|=1, add skew term\n            A[i, j] += eta * np.real(A[i, j])\n\n    # 2. Compute Diagnostic Metrics\n    \n    # Symmetry residual (s)\n    norm_A = np.linalg.norm(A, 'fro')\n    if norm_A == 0:\n        s = 0.0\n    else:\n        norm_A_minus_AT = np.linalg.norm(A - A.T, 'fro')\n        s = norm_A_minus_AT / norm_A\n\n    # Reciprocity maximum relative discrepancy (r)\n    max_rel_disc = 0.0\n    # Iterate through upper triangle\n    for i in range(N):\n        for j in range(i + 1, N):\n            num = np.abs(A[i, j] - A[j, i])\n            den = np.max([np.abs(A[i, j]), np.abs(A[j, i]), tau])\n            rel_disc = num / den\n            if rel_disc > max_rel_disc:\n                max_rel_disc = rel_disc\n    r = max_rel_disc\n    \n    # Condition number (kappa)\n    singular_values = np.linalg.svd(A, compute_uv=False)\n    sigma_max = singular_values[0] if len(singular_values) > 0 else 0.0\n    \n    positive_sv = singular_values[singular_values > tau_sigma]\n    if len(positive_sv) == 0:\n        kappa = np.inf\n    else:\n        sigma_min_plus = np.min(positive_sv)\n        if sigma_min_plus == 0:\n             kappa = np.inf\n        else:\n             kappa = sigma_max / sigma_min_plus\n\n    # Spectral radius (rho)\n    if N > 0:\n        eigenvalues = np.linalg.eigvals(A)\n        rho = np.max(np.abs(eigenvalues))\n    else:\n        rho = 0.0\n\n    return s, r, kappa, rho\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # (N, L, a, k, eps, eta)\n    test_cases = [\n        (16, 1.0, 1.0e-3, 10.0, 0.0, 0.0),      # Case 1\n        (16, 1.0, 1.0e-3, 10.0, 0.1, 0.0),      # Case 2\n        (16, 1.0, 1.0e-3, 10.0, -0.1, 0.05),    # Case 3\n        (32, 1.0, 1.0e-3, 1.0e-3, 0.5, 0.0),      # Case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        N, L, a, k, eps, eta = case\n        s, r, kappa, rho = build_and_analyze(N, L, a, k, eps, eta)\n        results.append([s, r, kappa, rho])\n    \n    # Format the final output string exactly as required\n    # e.g., [[s1,r1,k1,rho1],[s2,r2,k2,rho2],...]\n    output_str = \"[\" + \",\".join(\n        \"[\" + \",\".join(map(str, sublist)) + \"]\" for sublist in results\n    ) + \"]\"\n    \n    print(output_str)\n\nsolve()\n```"
        }
    ]
}