{
    "hands_on_practices": [
        {
            "introduction": "Effective singularity subtraction begins with a precise analytical understanding of the kernel itself. This first exercise guides you through the fundamental process of dissecting the two-dimensional Helmholtz Green's function, a cornerstone of modeling wave scattering and radiation. By deriving its behavior near the origin, you will learn to isolate the universal logarithmic singularity from the frequency-dependent, finite remainder, a critical skill for developing robust boundary element methods .",
            "id": "3348056",
            "problem": "Consider the time-harmonic scalar Helmholtz equation in two spatial dimensions with free-space boundary conditions,\n$$(\\nabla^{2} + k^{2})\\,G(\\mathbf{r}) = -\\delta(\\mathbf{r}),$$\nwhere $k>0$ is the wavenumber and $\\delta(\\cdot)$ is the Dirac delta distribution. The free-space Green’s function is given by\n$$G(\\mathbf{r}) = \\frac{i}{4} H_{0}^{(1)}(k r),$$\nwhere $r = \\|\\mathbf{r}\\|$ and $H_{0}^{(1)}$ is the order-zero Hankel function of the first kind. In computational electromagnetics, especially within boundary integral formulations and the Boundary Element Method (BEM), it is standard to perform singularity extraction by subtracting the static two-dimensional Green’s function kernel $-\\frac{1}{2\\pi}\\ln r$ to isolate a finite remainder at coincident points.\n\nStarting from fundamental definitions and well-tested series representations for the Bessel functions $J_{0}$ and $Y_{0}$ underlying $H_{0}^{(1)} = J_{0} + i Y_{0}$, derive the small-argument asymptotic of $G(\\mathbf{r})$ as $r \\to 0^{+}$, identify the leading logarithmic singularity, and determine the finite constant term that remains after subtracting $-\\frac{1}{2\\pi}\\ln r$. Your derivation must make clear how the logarithmic singularity arises and how the constant term depends on $k$.\n\nProvide, as your final answer, the explicit asymptotic expression for $G(\\mathbf{r})$ up to and including the constant term, i.e., an expression of the form\n$$-\\frac{1}{2\\pi}\\ln r + \\text{constant in } r$$\nwith the $k$-dependent constant fully specified. No numerical evaluation or rounding is required. The final answer must be a single closed-form analytic expression.",
            "solution": "The problem is first subjected to validation.\n\n### Step 1: Extract Givens\n- The governing equation is the two-dimensional, time-harmonic scalar Helmholtz equation: $(\\nabla^{2} + k^{2})\\,G(\\mathbf{r}) = -\\delta(\\mathbf{r})$.\n- The wavenumber $k$ is a positive real number, $k>0$.\n- The source term is the Dirac delta distribution, $\\delta(\\mathbf{r})$.\n- The free-space Green’s function is given as $G(\\mathbf{r}) = \\frac{i}{4} H_{0}^{(1)}(k r)$, where $r = \\|\\mathbf{r}\\|$.\n- $H_{0}^{(1)}$ is the order-zero Hankel function of the first kind.\n- The technique of singularity extraction involves subtracting the static Green's function, which is $-\\frac{1}{2\\pi}\\ln r$.\n- The Hankel function is related to the Bessel functions of the first kind ($J_0$) and second kind ($Y_0$) by $H_{0}^{(1)} = J_{0} + i Y_{0}$.\n- The task is to derive the small-argument asymptotic behavior of $G(\\mathbf{r})$ for $r \\to 0^{+}$ using the series representations for $J_0$ and $Y_0$, and to express the result in the form $-\\frac{1}{2\\pi}\\ln r + \\text{constant}$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem statement is entirely grounded in established mathematical physics and computational science. The Helmholtz equation, Green's functions, Bessel and Hankel functions, and the method of singularity extraction are all standard and well-documented concepts.\n- **Well-Posed:** The problem is well-posed. It asks for the derivation of a specific, known asymptotic limit of a defined function. The required steps are outlined, and a unique analytical solution exists.\n- **Objective:** The problem is stated in precise, objective, and formal mathematical language, free from any ambiguity or subjective elements.\n- **Conclusion:** The problem is scientifically sound, internally consistent, complete, and well-posed. It does not violate any of the specified criteria for invalidity.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full solution will be provided.\n\n### Derivation of the Asymptotic Expression\n\nThe objective is to determine the asymptotic behavior of the two-dimensional free-space Green's function for the Helmholtz equation as the radial distance $r = \\|\\mathbf{r}\\|$ approaches zero. The Green's function is given by:\n$$G(\\mathbf{r}) = \\frac{i}{4} H_{0}^{(1)}(k r)$$\nwhere $k > 0$ is the wavenumber and $H_{0}^{(1)}$ is the Hankel function of the first kind, of order zero.\n\nFirst, we express the Hankel function in terms of the Bessel function of the first kind, $J_0$, and the Bessel function of the second kind (or Neumann function), $Y_0$:\n$$H_{0}^{(1)}(z) = J_{0}(z) + i Y_{0}(z)$$\nSubstituting this definition into the expression for $G(\\mathbf{r})$ with the argument $z = kr$:\n$$G(\\mathbf{r}) = \\frac{i}{4} \\left( J_{0}(k r) + i Y_{0}(k r) \\right) = \\frac{i}{4} J_{0}(k r) - \\frac{1}{4} Y_{0}(k r)$$\nTo find the behavior as $r \\to 0^{+}$, we need the small-argument asymptotic expansions of $J_0(z)$ and $Y_0(z)$ for $z \\to 0^{+}$.\n\nThe series representation for the Bessel function $J_0(z)$ is:\n$$J_{0}(z) = \\sum_{m=0}^{\\infty} \\frac{(-1)^{m}}{(m!)^{2}} \\left(\\frac{z}{2}\\right)^{2m} = 1 - \\frac{z^2}{4} + \\frac{z^4}{64} - \\dots$$\nAs $z \\to 0$, the leading term is $1$. Thus, for small $r$:\n$$J_{0}(k r) = 1 + O((kr)^2)$$\n\nThe small-argument expansion for the Bessel function $Y_0(z)$ is more complex and is the source of the logarithmic singularity. The standard expansion is:\n$$Y_{0}(z) = \\frac{2}{\\pi} \\left[ \\left( \\ln\\left(\\frac{z}{2}\\right) + \\gamma \\right) J_0(z) - \\sum_{m=1}^{\\infty} \\frac{(-1)^m}{(m!)^2} \\left( \\sum_{j=1}^{m} \\frac{1}{j} \\right) \\left(\\frac{z}{2}\\right)^{2m} \\right]$$\nwhere $\\gamma \\approx 0.5772$ is the Euler-Mascheroni constant.\nFor $z \\to 0$, we know $J_0(z) \\to 1$. The summation term behaves as $O(z^2)$. Therefore, the leading-order behavior of $Y_0(z)$ is determined by the first term:\n$$Y_{0}(z) \\approx \\frac{2}{\\pi} \\left( \\ln\\left(\\frac{z}{2}\\right) + \\gamma \\right) \\cdot 1 = \\frac{2}{\\pi} \\left( \\ln(z) - \\ln(2) + \\gamma \\right)$$\nSubstituting $z=kr$, we get the small-argument behavior for $Y_0(kr)$:\n$$Y_{0}(k r) = \\frac{2}{\\pi} \\left( \\ln(kr) - \\ln(2) + \\gamma \\right) + O((kr)^2 \\ln(kr)) = \\frac{2}{\\pi} \\left( \\ln(k) + \\ln(r) - \\ln(2) + \\gamma \\right) + O((kr)^2 \\ln(kr))$$\n\nNow we substitute the asymptotic forms of $J_0(kr)$ and $Y_0(kr)$ back into the expression for $G(\\mathbf{r})$:\n$$G(\\mathbf{r}) \\approx \\frac{i}{4}(1) - \\frac{1}{4} \\left[ \\frac{2}{\\pi} \\left( \\ln(k) + \\ln(r) - \\ln(2) + \\gamma \\right) \\right]$$\nSimplifying this expression:\n$$G(\\mathbf{r}) \\approx \\frac{i}{4} - \\frac{1}{2\\pi} \\left( \\ln(k) + \\ln(r) - \\ln(2) + \\gamma \\right)$$\nTo match the requested form, we separate the term containing $\\ln(r)$:\n$$G(\\mathbf{r}) \\approx -\\frac{1}{2\\pi}\\ln(r) + \\left[ \\frac{i}{4} - \\frac{1}{2\\pi} \\left( \\ln(k) - \\ln(2) + \\gamma \\right) \\right]$$\nThe term $-\\frac{1}{2\\pi}\\ln(r)$ is the expected logarithmic singularity, which is identical to the Green's function for the 2D Laplacian operator, often called the static kernel. The remaining part is a constant with respect to $r$:\n$$\\text{Constant} = \\frac{i}{4} - \\frac{1}{2\\pi} \\left( \\ln(k) - \\ln(2) + \\gamma \\right) = \\frac{i}{4} - \\frac{1}{2\\pi} \\left( \\ln\\left(\\frac{k}{2}\\right) + \\gamma \\right)$$\nThis constant represents the finite part of the Helmholtz Green's function at the origin after the logarithmic singularity has been subtracted. Its dependence on the wavenumber $k$ arises directly from the argument of the logarithm in the $Y_0$ expansion.\n\nThe complete asymptotic expression for $G(\\mathbf{r})$ as $r \\to 0^{+}$ up to the constant term is therefore:\n$$G(\\mathbf{r}) \\approx -\\frac{1}{2\\pi}\\ln(r) + \\frac{i}{4} - \\frac{1}{2\\pi}\\left(\\ln\\left(\\frac{k}{2}\\right) + \\gamma\\right)$$\nThis result is fundamental for numerical methods like the Boundary Element Method, where subtracting this analytical form of the singularity allows for accurate numerical integration of the remaining well-behaved function.",
            "answer": "$$\n\\boxed{-\\frac{1}{2\\pi}\\ln(r) + \\frac{i}{4} - \\frac{1}{2\\pi}\\left(\\ln\\left(\\frac{k}{2}\\right) + \\gamma\\right)}\n$$"
        },
        {
            "introduction": "After analytically identifying the singular part of a kernel, the crucial next step is to apply this knowledge to improve numerical computations. This hands-on coding exercise demonstrates the profound impact of singularity subtraction on the accuracy of integral evaluation in a practical scenario. By implementing and comparing a naive quadrature with a subtraction-based approach for a nearly singular integral over a triangular mesh element, you will directly quantify the method's effectiveness and gain a tangible appreciation for its necessity in computational electromagnetics .",
            "id": "3348122",
            "problem": "Consider the static free-space Green’s kernel for the Laplace equation, defined by $G(\\mathbf{r},\\mathbf{r}') = \\dfrac{1}{4\\pi \\|\\mathbf{r} - \\mathbf{r}'\\|}$, where $\\mathbf{r}$ is the observation point and $\\mathbf{r}'$ is the source point on a planar surface. Let the reference triangle be the right triangle lying in the plane $z=0$ with vertices at $(0,0,0)$, $(1,0,0)$, and $(0,1,0)$. Its centroid is at $\\mathbf{r}_{c} = \\left(\\dfrac{1}{3}, \\dfrac{1}{3}, 0\\right)$. For an observation point a distance $\\delta$ above the centroid, $\\mathbf{r}_{\\text{obs}}(\\delta) = \\left(\\dfrac{1}{3}, \\dfrac{1}{3}, \\delta\\right)$ with $\\delta > 0$, define the kernel over the triangle by\n$$\nG(x,y;\\delta) = \\frac{1}{4\\pi\\sqrt{(x - \\tfrac{1}{3})^2 + (y - \\tfrac{1}{3})^2 + \\delta^2}},\n$$\nfor $(x,y)$ inside the triangle $\\{(x,y)\\,|\\, x \\ge 0,\\ y \\ge 0,\\ x + y \\le 1\\}$.\n\nLet the source weighting be the linear basis function equal to the barycentric coordinate associated with the vertex at $(1,0,0)$, namely $\\phi(x,y) = x$. The quantity of interest is the surface integral\n$$\nI(\\delta) = \\int_{T} \\phi(x,y)\\,G(x,y;\\delta)\\, \\mathrm{d}S = \\int_{0}^{1} \\int_{0}^{1-x} x\\, G(x,y;\\delta)\\,\\mathrm{d}y\\,\\mathrm{d}x,\n$$\nwhere $T$ denotes the reference triangle and $\\mathrm{d}S$ is the surface element in $\\mathrm{m}^2$. Although $I(\\delta)$ is finite for any $\\delta > 0$, numerical evaluation becomes challenging for small $\\delta$ due to the near-singular behavior of $G(x,y;\\delta)$ around $(x,y) = \\left(\\tfrac{1}{3}, \\tfrac{1}{3}\\right)$.\n\nA classical singularity extraction and subtraction technique rewrites the integral as\n$$\nI(\\delta) = \\underbrace{\\int_{T} \\big(\\phi(x,y) - \\phi(\\mathbf{r}_{c})\\big)\\, G(x,y;\\delta)\\, \\mathrm{d}S}_{I_{\\text{rem}}(\\delta)}\\;+\\; \\underbrace{\\phi(\\mathbf{r}_{c}) \\int_{T} G(x,y;\\delta)\\,\\mathrm{d}S}_{I_{\\text{sing}}(\\delta)},\n$$\nwhere $\\phi(\\mathbf{r}_{c}) = \\tfrac{1}{3}$ and $I_{\\text{rem}}(\\delta)$ has a milder local behavior because $\\phi(x,y) - \\phi(\\mathbf{r}_{c})$ vanishes at the centroid, reducing the peak severity of the integrand near the singularity.\n\nStarting from the fundamental definition of the Green’s function and the geometric parametrization of the triangle, implement and compare two numerical strategies for evaluating $I(\\delta)$:\n- A naive tensor-product Gauss–Legendre quadrature on the $(x,y)$ domain, with a fixed modest order $n$, directly approximating the double integral $\\int_{0}^{1} \\int_{0}^{1-x} x\\, G(x,y;\\delta)\\, \\mathrm{d}y\\,\\mathrm{d}x$.\n- A subtraction-based strategy that evaluates $I_{\\text{rem}}(\\delta)$ using the same modest quadrature order $n$ and evaluates $I_{\\text{sing}}(\\delta)$ with a significantly higher-order quadrature $n_{\\text{ref}}$ to emulate an analytically known singular contribution in practice.\n\nUse Gauss–Legendre quadrature in one dimension to approximate the integrals over $x \\in [0,1]$ and, for each $x$, over $y \\in [0,1-x]$, with the correct affine mapping and scaling of weights. Your program must:\n- Compute a high-accuracy reference $I_{\\text{ref}}(\\delta)$ by applying the high-order quadrature $n_{\\text{ref}}$ directly to $I(\\delta)$ (without subtraction).\n- Compute the absolute error of the naive method, $E_{\\text{naive}}(\\delta) = \\big| I_{\\text{naive}}(\\delta) - I_{\\text{ref}}(\\delta) \\big|$.\n- Compute the absolute error of the subtraction method, $E_{\\text{sub}}(\\delta) = \\big| I_{\\text{sub}}(\\delta) - I_{\\text{ref}}(\\delta) \\big|$.\n- Report the accuracy gain defined as\n$$\n\\Gamma(\\delta) = \\frac{E_{\\text{naive}}(\\delta)}{E_{\\text{sub}}(\\delta)}.\n$$\n\nPhysical units: treat $\\delta$ in meters and areas in square meters, but report the final accuracy gain $\\Gamma(\\delta)$ as a dimensionless float.\n\nAngle units do not arise in this problem.\n\nTest suite:\n- Use three values of $\\delta$ to exercise different regimes: $\\delta_1 = 10^{-1}\\,\\mathrm{m}$, $\\delta_2 = 10^{-3}\\,\\mathrm{m}$, and $\\delta_3 = 10^{-5}\\,\\mathrm{m}$.\n- Use a modest quadrature order $n = 24$ for the naive and the remainder integrals, and a high-order $n_{\\text{ref}} = 400$ for the reference and the singular part in the subtraction method.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite, for example $[\\Gamma(\\delta_1),\\Gamma(\\delta_2),\\Gamma(\\delta_3)]$. The outputs must be in the canonical Python float format.\n\nEnsure scientific realism by basing your approach on the above Green’s function definition and correct quadrature rules. Do not use any external data or shortcuts; implement the quadrature and subtraction exactly as specified.",
            "solution": "The problem requires a comparison of two numerical integration strategies for a near-singular integral arising in the context of the boundary element method for the Laplace equation. The quantity of interest is the integral $I(\\delta) = \\int_{T} \\phi(x,y) G(x,y;\\delta) \\mathrm{d}S$ over a reference triangle $T$, where $G$ is the static free-space Green's kernel and $\\phi$ is a linear source weighting. The near-singularity arises as the observation point, located at a distance $\\delta$ above the triangle's centroid, approaches the surface (i.e., as $\\delta \\to 0$). We will compare a direct, naive numerical quadrature with a more sophisticated singularity subtraction technique.\n\nThe core principle of singularity subtraction is to regularize the integrand. The integral $I(\\delta)$ is rewritten as:\n$$\nI(\\delta) = \\int_{T} \\big(\\phi(x,y) - \\phi(\\mathbf{r}_{c})\\big)\\, G(x,y;\\delta)\\, \\mathrm{d}S \\;+\\; \\phi(\\mathbf{r}_{c}) \\int_{T} G(x,y;\\delta)\\,\\mathrm{d}S\n$$\nThis splits the original integral into a \"remainder\" term $I_{\\text{rem}}(\\delta)$ and a \"singular\" term $I_{\\text{sing}}(\\delta)$. The crucial insight is that the source weighting function $\\phi(x,y)=x$ is smooth. By subtracting its value at the centroid, $\\phi(\\mathbf{r}_c) = \\phi(1/3, 1/3) = 1/3$, the new factor in the remainder integrand, $\\phi(x,y) - \\phi(\\mathbf{r}_c) = x - 1/3$, becomes zero at the $x$-coordinate of the near-singularity location. This cancellation significantly reduces the integrand's peak value, making $I_{\\text{rem}}(\\delta)$ much smoother and more amenable to accurate approximation with a low-order numerical quadrature. The singular behavior is isolated in $I_{\\text{sing}}(\\delta)$, which can then be handled with a high-accuracy method (here, a high-order quadrature) or, in practice, analytical formulas.\n\nTo perform the numerical integration over the reference triangle $T = \\{(x,y)\\,|\\, x \\ge 0,\\, y \\ge 0,\\, x + y \\le 1\\}$, we express the surface integral as an iterated integral:\n$$\n\\int_{T} f(x,y) \\mathrm{d}S = \\int_{0}^{1} \\left( \\int_{0}^{1-x} f(x,y) \\mathrm{d}y \\right) \\mathrm{d}x\n$$\nWe apply a tensor product of one-dimensional Gauss-Legendre quadrature rules. This requires mapping the standard quadrature interval $[-1, 1]$ to the integration limits $[0, 1]$ for the outer integral and $[0, 1-x]$ for the inner integral.\n\nFor the outer integral over $x$, the affine mapping from $\\xi \\in [-1, 1]$ to $x \\in [0, 1]$ is $x(\\xi) = \\frac{1}{2}(\\xi+1)$, with Jacobian $\\frac{\\mathrm{d}x}{\\mathrm{d}\\xi} = \\frac{1}{2}$.\nFor the inner integral over $y$, for a fixed $x$, the mapping from $\\eta \\in [-1, 1]$ to $y \\in [0, 1-x]$ is $y(\\eta) = \\frac{1-x}{2}(\\eta+1)$, with Jacobian $\\frac{\\mathrm{d}y}{\\mathrm{d}\\eta} = \\frac{1-x}{2}$.\n\nCombining these, the approximation for an $N$-point quadrature in each dimension becomes:\n$$\nI \\approx \\sum_{i=1}^{N} \\sum_{j=1}^{N} f(x_i, y_{ij}) \\, w_i w_j \\, \\left(\\frac{1-x_i}{4}\\right)\n$$\nwhere $(\\xi_k, w_k)$ for $k=1, \\dots, N$ are the $N$-point Gauss-Legendre nodes and weights, and the evaluation points are $x_i = \\frac{1}{2}(\\xi_i+1)$ and $y_{ij} = \\frac{1-x_i}{2}(\\eta_j+1)$ (using $\\eta_j = \\xi_j$).\n\nThe computational procedure is as follows:\n$1$. A high-accuracy reference value, $I_{\\text{ref}}(\\delta)$, is computed by integrating the original integrand, $\\phi(x,y)G(x,y;\\delta)$, using a high-order quadrature with $n_{\\text{ref}} = 400$.\n$2$. The naive approximation, $I_{\\text{naive}}(\\delta)$, is computed by integrating the same function but with a modest quadrature order of $n = 24$.\n$3$. The subtraction method approximation, $I_{\\text{sub}}(\\delta)$, is computed in two parts:\n    -   The regular part, $I_{\\text{rem}}(\\delta)$, is computed by integrating the regularized integrand, $(\\phi(x,y) - \\phi(\\mathbf{r}_c))G(x,y;\\delta)$, using the modest order $n = 24$.\n    -   The singular part, $I_{\\text{sing}}(\\delta)$, is computed by evaluating $\\phi(\\mathbf{r}_c) \\int_T G(x,y;\\delta)\\,\\mathrm{d}S$, where the integral of the Green's function $G$ is computed using the high order $n_{\\text{ref}} = 400$.\n    -   The final value is $I_{\\text{sub}}(\\delta) = I_{\\text{rem}}(\\delta) + I_{\\text{sing}}(\\delta)$.\n$4$. For each $\\delta$, the absolute errors $E_{\\text{naive}}(\\delta) = |I_{\\text{naive}}(\\delta) - I_{\\text{ref}}(\\delta)|$ and $E_{\\text{sub}}(\\delta) = |I_{\\text{sub}}(\\delta) - I_{\\text{ref}}(\\delta)|$ are calculated. The accuracy gain, $\\Gamma(\\delta) = E_{\\text{naive}}(\\delta) / E_{\\text{sub}}(\\delta)$, quantifies the effectiveness of the subtraction method. A larger value of $\\Gamma(\\delta)$ indicates a greater improvement in accuracy for the same computational cost (of the regular part).",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import roots_legendre\n\ndef solve():\n    \"\"\"\n    Computes the accuracy gain of a singularity subtraction technique for a near-singular\n    integral over a triangular domain.\n    \"\"\"\n\n    # Define the test cases and parameters from the problem statement.\n    test_deltas = [1e-1, 1e-3, 1e-5]\n    n_modest = 24\n    n_ref = 400\n    phi_centroid = 1.0 / 3.0\n    xc, yc = 1.0 / 3.0, 1.0 / 3.0\n\n    # Pre-compute Gauss-Legendre nodes and weights to avoid redundant calculations.\n    nodes_modest, weights_modest = roots_legendre(n_modest)\n    nodes_ref, weights_ref = roots_legendre(n_ref)\n\n    def G(x, y, delta):\n        \"\"\"\n        The static free-space Green's kernel for the Laplace equation.\n        G(r, r') = 1 / (4 * pi * ||r - r'||)\n        \"\"\"\n        inv_4pi = 1.0 / (4.0 * np.pi)\n        distance_sq = (x - xc)**2 + (y - yc)**2 + delta**2\n        return inv_4pi / np.sqrt(distance_sq)\n\n    def naive_integrand(x, y, delta):\n        \"\"\"\n        The original integrand: phi(x,y) * G(x,y;delta).\n        phi(x,y) = x\n        \"\"\"\n        return x * G(x, y, delta)\n\n    def rem_integrand(x, y, delta):\n        \"\"\"\n        The remainder integrand after subtraction: (phi(x,y) - phi_c) * G.\n        \"\"\"\n        return (x - phi_centroid) * G(x, y, delta)\n\n    def quad_2d_triangle(func, delta, nodes, weights):\n        \"\"\"\n        Performs 2D Gauss-Legendre quadrature over the reference triangle.\n        The integration is done on a [-1,1] x [-1,1] square and mapped to the triangle.\n        \"\"\"\n        # Create a 2D grid of nodes and weights using broadcasting\n        xi = nodes[:, np.newaxis]\n        eta = nodes[np.newaxis, :]\n        wi = weights[:, np.newaxis]\n        wj = weights[np.newaxis, :]\n\n        # Affine mapping from standard square to triangle\n        x = 0.5 * (xi + 1.0)\n        y = 0.5 * (1.0 - x) * (eta + 1.0)\n\n        # Jacobian of the transformation\n        jacobian = 0.5 * (1.0 - x) * 0.5\n\n        # Evaluate the integrand at all quadrature points\n        integrand_values = func(x, y, delta)\n\n        # Compute the integral by summing weighted values\n        integral = np.sum(wi * wj * integrand_values * jacobian)\n        \n        return integral\n\n\n    results = []\n    for delta in test_deltas:\n        # 1. Compute the high-accuracy reference value using n_ref points.\n        I_ref = quad_2d_triangle(naive_integrand, delta, nodes_ref, weights_ref)\n\n        # 2. Compute the naive approximation using n_modest points.\n        I_naive = quad_2d_triangle(naive_integrand, delta, nodes_modest, weights_modest)\n\n        # 3. Compute the subtraction-based approximation.\n        #    - The remainder term is integrated with the modest order.\n        I_rem = quad_2d_triangle(rem_integrand, delta, nodes_modest, weights_modest)\n        #    - The singular term's integral part is computed with high order.\n        I_G_ref = quad_2d_triangle(G, delta, nodes_ref, weights_ref)\n        I_sing = phi_centroid * I_G_ref\n        \n        I_sub = I_rem + I_sing\n\n        # 4. Compute absolute errors and the accuracy gain.\n        E_naive = np.abs(I_naive - I_ref)\n        E_sub = np.abs(I_sub - I_ref)\n        \n        # Handle the case where the subtraction method is extremely accurate,\n        # to avoid division by a number close to machine epsilon.\n        if E_sub == 0.0:\n            # If the subtraction method error is zero, the gain is effectively infinite.\n            # This can happen due to floating point limitations. We can report a large number\n            # or handle it as a special case. Here, if E_naive is also zero, gain is 1.\n            # Otherwise, gain is large. Since E_naive is not expected to be zero, it's safe to say gain is huge.\n            gamma = np.inf if E_naive > 0.0 else 1.0\n        else:\n            gamma = E_naive / E_sub\n            \n        results.append(gamma)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The previous practice demonstrated *that* singularity subtraction works; this final exercise explains *why* it works so well from a numerical analysis perspective. The core idea is that the remaining integrand is 'smooth,' allowing for rapid convergence with standard quadrature rules. This problem challenges you to formalize this concept by deriving the error bound for Gaussian quadrature when applied to such a smooth remainder function, connecting the function's derivatives to the convergence rate and solidifying the theoretical foundation of the entire technique .",
            "id": "3348057",
            "problem": "In computational electromagnetics, singularity extraction is used to separate the singular part of a boundary integral kernel from a smooth remainder so that high-order quadrature can be applied to the latter. Consider the scalar potential formulation associated with the three-dimensional Helmholtz equation, where the free-space Green’s function is decomposed into a singular kernel and a smooth remainder after extraction by $R(x)$, where $x$ is a one-dimensional coordinate along the element. Assume $R \\in C^{m}$ on the closed element with $m \\ge 2p$, and define the integral\n$$\nI_{h} \\equiv \\int_{x_{c}-h/2}^{x_{c}+h/2} R(x) \\, dx,\n$$\nwhere $x_{c}$ is the element center. Approximate $I_{h}$ using the $p$-point Gauss–Legendre rule mapped from the reference interval $[-1,1]$ to the element.\n\nStarting from the fundamental definitions of singularity extraction (decomposition of the integrand into singular and smooth parts) and the standard error representation for interpolatory Gaussian quadrature, derive a rigorous upper bound for the absolute quadrature error in terms of $p$, $h$, and a bound on the $2p$-th derivative of $R$. Specifically, let\n$$\nM_{2p} \\equiv \\max_{x \\in [x_{c}-h/2,\\, x_{c}+h/2]} \\left| \\frac{d^{2p} R(x)}{dx^{2p}} \\right|.\n$$\nExpress your final bound as a single closed-form expression that depends only on $p$, $h$, and $M_{2p}$.\n\nYour final answer must be a single analytic expression. Do not include units. Do not present an inequality or an equation as your final answer; present only the bounding expression itself as a function of $p$, $h$, and $M_{2p}$.",
            "solution": "The problem as stated is scientifically grounded, well-posed, objective, and internally consistent. It presents a standard exercise in numerical analysis, specifically the derivation of the error bound for Gaussian quadrature applied to an integral over an arbitrary interval. We may therefore proceed with the derivation.\n\nThe objective is to find an upper bound for the absolute error when approximating the integral\n$$\nI_{h} \\equiv \\int_{x_{c}-h/2}^{x_{c}+h/2} R(x) \\, dx\n$$\nusing a $p$-point Gauss-Legendre quadrature rule. The function $R(x)$ is assumed to be of class $C^{2p}$ on the integration interval.\n\nThe standard error formula for $p$-point Gauss-Legendre quadrature is defined on the reference interval $[-1, 1]$. Therefore, the first step is to transform the integral $I_{h}$ from the physical interval $[x_{c}-h/2, x_{c}+h/2]$ to the reference interval $[-1, 1]$. We use a linear affine mapping for the coordinate $x$:\n$$\nx(\\xi) = a\\xi + b\n$$\nWe require that $x(-1) = x_{c}-h/2$ and $x(1) = x_{c}+h/2$. Solving the system of two linear equations for $a$ and $b$ yields:\n$$\na = \\frac{h}{2}, \\quad b = x_{c}\n$$\nThus, the transformation is:\n$$\nx(\\xi) = \\frac{h}{2}\\xi + x_{c}\n$$\nThe differential element transforms as $dx = \\frac{h}{2} d\\xi$. Substituting this into the integral $I_h$ gives:\n$$\nI_{h} = \\int_{-1}^{1} R\\left(\\frac{h}{2}\\xi + x_{c}\\right) \\frac{h}{2} \\, d\\xi\n$$\nLet us define a new function $f(\\xi)$ corresponding to the integrand on the reference interval:\n$$\nf(\\xi) \\equiv \\frac{h}{2} R\\left(\\frac{h}{2}\\xi + x_{c}\\right)\n$$\nThe integral is now expressed as $I_h = \\int_{-1}^1 f(\\xi) d\\xi$. The quadrature error for $I_h$ is identical to the error of applying the $p$-point Gauss-Legendre rule to $f(\\xi)$ on $[-1, 1]$.\n\nThe standard formula for the error $E_p[f]$ of a $p$-point Gauss-Legendre quadrature for a function $f(\\xi)$ on $[-1, 1]$, assuming $f \\in C^{2p}([-1,1])$, is given by:\n$$\nE_p[f] = \\frac{2^{2p+1}(p!)^4}{(2p+1)\\left((2p)!\\right)^3} f^{(2p)}(\\eta)\n$$\nfor some $\\eta \\in (-1, 1)$. Here, $f^{(2p)}(\\eta)$ denotes the $2p$-th derivative of $f$ with respect to $\\xi$, evaluated at $\\eta$.\n\nTo apply this formula, we must compute the $2p$-th derivative of our specific function $f(\\xi)$. We use the chain rule for differentiation. Let $R^{(k)}(x)$ denote $\\frac{d^k R}{dx^k}$.\n$$\n\\frac{d}{d\\xi} = \\frac{dx}{d\\xi} \\frac{d}{dx} = \\frac{h}{2} \\frac{d}{dx}\n$$\nApplying this operator $2p$ times to $f(\\xi)$:\n$$\nf^{(2p)}(\\xi) = \\frac{d^{2p}}{d\\xi^{2p}} f(\\xi) = \\frac{d^{2p}}{d\\xi^{2p}} \\left[ \\frac{h}{2} R(x(\\xi)) \\right] = \\frac{h}{2} \\left(\\frac{h}{2}\\right)^{2p} R^{(2p)}(x(\\xi)) = \\left(\\frac{h}{2}\\right)^{2p+1} R^{(2p)}(x(\\xi))\n$$\nNow, we substitute this expression for $f^{(2p)}(\\xi)$ into the error formula:\n$$\nE_p[f] = \\frac{2^{2p+1}(p!)^4}{(2p+1)\\left((2p)!\\right)^3} \\left[ \\left(\\frac{h}{2}\\right)^{2p+1} R^{(2p)}(x(\\eta)) \\right]\n$$\nSimplifying the expression by combining the powers of $2$:\n$$\nE_p[f] = \\frac{2^{2p+1}(p!)^4}{(2p+1)\\left((2p)!\\right)^3} \\frac{h^{2p+1}}{2^{2p+1}} R^{(2p)}(x(\\eta)) = \\frac{h^{2p+1}(p!)^4}{(2p+1)\\left((2p)!\\right)^3} R^{(2p)}(x(\\eta))\n$$\nThe value $\\zeta = x(\\eta)$ is a point within the original integration interval $(x_{c}-h/2, x_{c}+h/2)$. The quadrature error for $I_h$, which we denote $E_h$, is therefore:\n$$\nE_h = \\frac{h^{2p+1}(p!)^4}{(2p+1)\\left((2p)!\\right)^3} R^{(2p)}(\\zeta)\n$$\nThe problem requires an upper bound for the absolute quadrature error, $|E_h|$. Taking the absolute value of both sides:\n$$\n|E_h| = \\left| \\frac{h^{2p+1}(p!)^4}{(2p+1)\\left((2p)!\\right)^3} R^{(2p)}(\\zeta) \\right| = \\frac{h^{2p+1}(p!)^4}{(2p+1)\\left((2p)!\\right)^3} \\left| R^{(2p)}(\\zeta) \\right|\n$$\nThe problem provides a bound on the magnitude of the $2p$-th derivative of $R$ over the element:\n$$\nM_{2p} \\equiv \\max_{x \\in [x_{c}-h/2,\\, x_{c}+h/2]} \\left| \\frac{d^{2p} R(x)}{dx^{2p}} \\right|\n$$\nSince $\\zeta$ lies within this interval, we have $| R^{(2p)}(\\zeta) | \\le M_{2p}$.\nSubstituting this into the expression for $|E_h|$ yields the desired upper bound:\n$$\n|E_h| \\le \\frac{h^{2p+1}(p!)^4}{(2p+1)\\left((2p)!\\right)^3} M_{2p}\n$$\nThe question asks for the bounding expression itself.",
            "answer": "$$\n\\boxed{\\frac{h^{2p+1} (p!)^4}{(2p+1)\\left((2p)!\\right)^3} M_{2p}}\n$$"
        }
    ]
}