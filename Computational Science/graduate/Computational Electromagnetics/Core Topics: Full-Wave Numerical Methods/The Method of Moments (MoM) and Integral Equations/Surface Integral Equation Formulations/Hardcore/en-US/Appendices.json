{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of implementing surface integral equations via the Method of Moments is the accurate computation of the matrix elements, which involves integrating the Green's function kernel. When the source and observation elements are the same or adjacent, this integration becomes challenging due to a singularity in the kernel. This exercise guides you through the essential analytical technique of using a coordinate transformation to regularize and exactly evaluate such a weakly singular integral, a fundamental skill for developing stable and accurate SIE solvers .",
            "id": "3352477",
            "problem": "In the method of moments discretization of the Electric Field Integral Equation (EFIE) for perfectly electrically conducting scatterers, the singular part of the free-space Green’s function kernel reduces, in the low-frequency limit, to the Laplace kernel proportional to $1/R$, where $R$ is the Euclidean distance between the observation and source points. For a coincident testing and source element, the associated geometric integral over a flat panel is weakly singular but finite, and must be treated analytically to preserve accuracy and stability in the surface integral equation formulation.\n\nConsider a flat reference triangular panel lying in the plane $z=0$ with vertices at $(0,0,0)$, $(1,0,0)$, and $(0,1,0)$. Place the observation point at the origin $(0,0,0)$, so that the kernel distance is $R=\\sqrt{x^{2}+y^{2}}$ for any source point $(x,y,0)$ on the triangle. Starting from first principles (the definition of the kernel and a valid change of variables), perform a coordinate transformation that removes the weak singularity and evaluate the integral\n$$\nI \\equiv \\iint_{T} \\frac{1}{\\sqrt{x^{2}+y^{2}}} \\, dx \\, dy,\n$$\nwhere $T=\\{(x,y)\\,:\\, x\\ge 0,\\; y\\ge 0,\\; x+y\\le 1\\}$ is the reference triangle. In your derivation, clearly identify the origin of any logarithmic contribution and the specific logarithmic term that must be handled carefully in numerical quadrature for surface integral equation formulations. Express your final result as a closed-form analytic expression. No numerical approximation is required for the final answer.",
            "solution": "The problem as stated is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. It represents a standard and fundamental calculation in the Method of Moments for surface integral equations in computational electromagnetics. We may therefore proceed with the derivation.\n\nThe problem requires the evaluation of the integral\n$$\nI \\equiv \\iint_{T} \\frac{1}{\\sqrt{x^{2}+y^{2}}} \\, dx \\, dy\n$$\nwhere the domain of integration $T$ is the triangle in the $z=0$ plane with vertices at $(0,0,0)$, $(1,0,0)$, and $(0,1,0)$. This domain is described by the inequalities $x \\ge 0$, $y \\ge 0$, and $x+y \\le 1$. The integrand has a weak singularity at the origin $(0,0,0)$, which is a vertex of the triangle.\n\nTo evaluate this integral, we perform a coordinate transformation from Cartesian coordinates $(x,y)$ to polar coordinates $(r,\\theta)$. This is the standard procedure for handling singularities of the form $1/R$, where $R=\\sqrt{x^2+y^2}$ is the radial distance from the singularity. The transformation is defined by:\n$$\nx = r \\cos\\theta\n$$\n$$\ny = r \\sin\\theta\n$$\nThe differential area element $dx \\, dy$ transforms according to the Jacobian of the transformation:\n$$\ndx \\, dy = |J| \\, dr \\, d\\theta = r \\, dr \\, d\\theta\n$$\nThe integrand, which is the kernel of the integral, becomes:\n$$\n\\frac{1}{\\sqrt{x^{2}+y^{2}}} = \\frac{1}{\\sqrt{(r\\cos\\theta)^{2} + (r\\sin\\theta)^{2}}} = \\frac{1}{\\sqrt{r^{2}(\\cos^{2}\\theta + \\sin^{2}\\theta)}} = \\frac{1}{r}\n$$\nSubstituting these into the integral, we observe a critical cancellation:\n$$\n\\frac{1}{\\sqrt{x^{2}+y^{2}}} dx \\, dy = \\frac{1}{r} (r \\, dr \\, d\\theta) = dr \\, d\\theta\n$$\nThis transformation effectively regularizes the integral by canceling the $1/r$ singularity with the factor of $r$ from the Jacobian. The problem is now reduced to integrating the constant function $1$ over the transformed domain.\n\nNext, we must determine the limits of integration for $r$ and $\\theta$ that correspond to the triangular domain $T$.\nThe conditions $x \\ge 0$ and $y \\ge 0$ restrict the angle $\\theta$ to the first quadrant, since $r \\ge 0$. Thus, the limits for $\\theta$ are:\n$$\n0 \\le \\theta \\le \\frac{\\pi}{2}\n$$\nThe third condition, $x+y \\le 1$, defines the upper bound for the radial coordinate $r$. Substituting the polar coordinate expressions:\n$$\nr \\cos\\theta + r \\sin\\theta \\le 1\n$$\n$$\nr(\\cos\\theta + \\sin\\theta) \\le 1\n$$\nSince $\\cos\\theta + \\sin\\theta > 0$ for $\\theta \\in [0, \\pi/2]$, we can write the upper limit for $r$ as:\n$$\nr \\le \\frac{1}{\\cos\\theta + \\sin\\theta}\n$$\nThe lower limit for $r$ is $0$. Therefore, the integral in polar coordinates is:\n$$\nI = \\int_{0}^{\\frac{\\pi}{2}} \\int_{0}^{\\frac{1}{\\cos\\theta + \\sin\\theta}} 1 \\, dr \\, d\\theta\n$$\nWe first evaluate the inner integral with respect to $r$:\n$$\n\\int_{0}^{\\frac{1}{\\cos\\theta + \\sin\\theta}} 1 \\, dr = [r]_{0}^{\\frac{1}{\\cos\\theta + \\sin\\theta}} = \\frac{1}{\\cos\\theta + \\sin\\theta}\n$$\nNow, we are left with the outer integral over $\\theta$:\n$$\nI = \\int_{0}^{\\frac{\\pi}{2}} \\frac{1}{\\cos\\theta + \\sin\\theta} \\, d\\theta\n$$\nTo evaluate this integral, we use the harmonic addition theorem, expressing the denominator in the form $A\\cos(\\theta-\\alpha)$. We set $\\cos\\theta + \\sin\\theta = A(\\cos\\theta\\cos\\alpha + \\sin\\theta\\sin\\alpha)$. By comparing coefficients of $\\cos\\theta$ and $\\sin\\theta$, we get $A\\cos\\alpha = 1$ and $A\\sin\\alpha = 1$. Squaring and adding these equations yields $A^2(\\cos^2\\alpha + \\sin^2\\alpha) = 1^2 + 1^2$, which gives $A^2 = 2$, so $A=\\sqrt{2}$. Dividing the two equations gives $\\tan\\alpha=1$, so $\\alpha = \\pi/4$.\nThus, the denominator is $\\cos\\theta + \\sin\\theta = \\sqrt{2}\\cos(\\theta - \\pi/4)$. The integral becomes:\n$$\nI = \\int_{0}^{\\frac{\\pi}{2}} \\frac{1}{\\sqrt{2}\\cos(\\theta - \\pi/4)} \\, d\\theta = \\frac{1}{\\sqrt{2}} \\int_{0}^{\\frac{\\pi}{2}} \\sec\\left(\\theta - \\frac{\\pi}{4}\\right) \\, d\\theta\n$$\nLet us perform a substitution $u = \\theta - \\pi/4$. Then $du = d\\theta$. The limits of integration for $u$ are:\nWhen $\\theta=0$, $u = -\\pi/4$.\nWhen $\\theta=\\pi/2$, $u = \\pi/2 - \\pi/4 = \\pi/4$.\nThe integral transforms to:\n$$\nI = \\frac{1}{\\sqrt{2}} \\int_{-\\pi/4}^{\\pi/4} \\sec(u) \\, du\n$$\nThe standard antiderivative of $\\sec(u)$ is $\\ln|\\sec(u) + \\tan(u)|$. Evaluating this at the limits:\n$$\nI = \\frac{1}{\\sqrt{2}} \\left[ \\ln|\\sec(u) + \\tan(u)| \\right]_{-\\pi/4}^{\\pi/4}\n$$\n$$\nI = \\frac{1}{\\sqrt{2}} \\left( \\ln\\left|\\sec\\left(\\frac{\\pi}{4}\\right) + \\tan\\left(\\frac{\\pi}{4}\\right)\\right| - \\ln\\left|\\sec\\left(-\\frac{\\pi}{4}\\right) + \\tan\\left(-\\frac{\\pi}{4}\\right)\\right| \\right)\n$$\nSubstituting the values $\\sec(\\pi/4) = \\sqrt{2}$, $\\tan(\\pi/4) = 1$, $\\sec(-\\pi/4) = \\sqrt{2}$, and $\\tan(-\\pi/4) = -1$:\n$$\nI = \\frac{1}{\\sqrt{2}} \\left( \\ln|\\sqrt{2} + 1| - \\ln|\\sqrt{2} - 1| \\right)\n$$\nSince $\\sqrt{2}+1 > 0$ and $\\sqrt{2}-1 > 0$, the absolute value signs can be removed. Using the property of logarithms $\\ln(a) - \\ln(b) = \\ln(a/b)$:\n$$\nI = \\frac{1}{\\sqrt{2}} \\ln\\left(\\frac{\\sqrt{2}+1}{\\sqrt{2}-1}\\right)\n$$\nTo simplify the argument of the logarithm, we multiply the numerator and denominator by the conjugate of the denominator:\n$$\n\\frac{\\sqrt{2}+1}{\\sqrt{2}-1} = \\frac{(\\sqrt{2}+1)(\\sqrt{2}+1)}{(\\sqrt{2}-1)(\\sqrt{2}+1)} = \\frac{(\\sqrt{2}+1)^{2}}{2-1} = (\\sqrt{2}+1)^{2}\n$$\nSubstituting this back into the expression for $I$:\n$$\nI = \\frac{1}{\\sqrt{2}} \\ln\\left( (\\sqrt{2}+1)^{2} \\right) = \\frac{2}{\\sqrt{2}} \\ln(\\sqrt{2}+1) = \\sqrt{2}\\ln(1+\\sqrt{2})\n$$\nThe problem also asks to identify the origin of the logarithmic contribution. The logarithm arises from the angular integration part of the problem, specifically from integrating the secant function $\\sec(u)$. This integral naturally evaluates to a logarithmic function. While the polar coordinate transformation removes the original algebraic singularity $1/r$, the geometry of the domain boundary, when expressed in polar coordinates, leads to an integrand $f(\\theta)$ whose antiderivative contains a logarithm.\n\nIn the context of numerical quadrature for surface integral equations, this analytical evaluation is performed precisely to avoid the difficulties of numerically integrating a singular function. However, if one were to use a more general numerical scheme based only on regularization (e.g., Duffy's transformation), the coordinate change would transform the integral into a form like $\\int_0^1 \\int_0^1 f(u,v) \\, du \\, dv$, where the new integrand $f(u,v)$ is no longer algebraically singular but may contain a term of the form $\\ln(u)$. This integrable logarithmic singularity, $\\ln(u)$, is the term that must be handled carefully, typically by employing specialized quadrature rules such as Gauss-log quadrature, to achieve accurate numerical results.",
            "answer": "$$\n\\boxed{\\sqrt{2}\\ln(1+\\sqrt{2})}\n$$"
        },
        {
            "introduction": "The theoretical elegance of SIEs meets a practical challenge when modeling objects with sharp geometric features like corners and edges, which induce singular behavior in the physical surface current density. A standard numerical discretization with uniform meshing struggles to capture these singularities, resulting in poor accuracy and slow convergence. This hands-on coding problem allows you to implement and analyze the impact of graded meshing, a critical technique where mesh elements are systematically refined near sharp features to efficiently resolve the solution and dramatically improve the solver's convergence rate .",
            "id": "3352485",
            "problem": "Consider an electrostatic scattering surrogate that captures the essential singular behavior of Surface Integral Equation (SIE) formulations near sharp geometric features. Starting from Maxwell’s equations, in the static limit with time dependence neglected, the electric field satisfies $\\nabla \\times \\mathbf{E} = \\mathbf{0}$ and $\\nabla \\cdot \\mathbf{E} = \\rho/\\varepsilon$. Introducing the electric potential $u$ via $\\mathbf{E} = -\\nabla u$, in source-free regions outside a perfectly conducting inclusion one obtains $\\Delta u = 0$ with Dirichlet boundary condition $u = u_0$ on the conductor boundary. In two dimensions, letting $S$ denote a thin perfectly conducting screen modeled as the line segment $[-1,1]$ on the $x$-axis, one can represent $u$ by a single-layer potential using the two-dimensional Laplace Green’s function $G(x,y) = -\\frac{1}{2\\pi}\\log|x - y|$. The boundary restriction of this representation yields a first-kind SIE for the unknown surface charge density $\\sigma$,\n$$\n\\int_{-1}^{1} G(x,y)\\,\\sigma(y)\\,\\mathrm{d}y = g(x), \\quad x \\in (-1,1),\n$$\nwhere $g(x)$ is the prescribed boundary data.\n\nNear sharp edges and tips, solutions to surface integral equations commonly exhibit singular behavior. For this screen segment, the exact surface charge density for certain constant boundary data behaves like $C/\\sqrt{1 - x^{2}}$ near the endpoints $x=\\pm1$, which mimics the canonical wedge-tip singularity. Your task is to implement and analyze a discretization strategy and mesh grading scheme that can capture this singularity, and to quantify the convergence rate of the numerical SIE solution with respect to the grading exponent compared to uniform refinement.\n\nYou must implement the following steps and design choices:\n\n1. Formulation and discretization:\n   - Use the single-layer operator with kernel $G(x,y) = -\\frac{1}{2\\pi}\\log|x - y|$ to formulate the SIE $\\int_{-1}^{1} G(x,y)\\,\\sigma(y)\\,\\mathrm{d}y = g(x)$ on the segment $[-1,1]$.\n   - Set the Dirichlet boundary data to the constant $g(x) = \\frac{\\log 2}{2}$, which induces the endpoint singularity in $\\sigma$ characteristic of wedge tips.\n   - Discretize the integral equation by a panel-based collocation method with piecewise constant basis functions. Partition $[-1,1]$ into $N$ panels with endpoints $\\{a_j,b_j\\}_{j=1}^{N}$ and use collocation points $x_i = \\frac{a_i + b_i}{2}$.\n   - Assemble the dense system matrix $A \\in \\mathbb{R}^{N \\times N}$ with entries\n     $$\n     A_{ij} = \\int_{a_j}^{b_j} G(x_i,y)\\,\\mathrm{d}y = -\\frac{1}{2\\pi}\\int_{a_j}^{b_j} \\log|x_i - y|\\,\\mathrm{d}y,\n     $$\n     evaluated exactly by calculus for the case of constant basis on each panel. Solve $A \\boldsymbol{\\sigma} = \\boldsymbol{g}$ for the panel-constant unknowns $\\{\\sigma_j\\}_{j=1}^{N}$, where $\\boldsymbol{g}$ is the constant vector with entries $g(x_i)$.\n\n2. Mesh design:\n   - Implement a uniform mesh ($p = 1$) with panel endpoints $x_k = -1 + 2s_k$ where $s_k = \\frac{k}{N}$ for $k = 0,1,\\dots,N$.\n   - Implement a symmetric graded mesh for a general grading exponent $p \\geq 1$ via the mapping\n     $$\n     \\beta_p(s) = \\frac{s^{p}}{s^{p} + (1 - s)^{p}}, \\quad x_k = -1 + 2\\,\\beta_p\\!\\left(\\frac{k}{N}\\right), \\quad k = 0,1,\\dots,N,\n     $$\n     which clusters panels near $x=\\pm1$ to better resolve the endpoint singularities. Use panel endpoints $\\{x_k\\}$ as $\\{a_j,b_j\\}$ with $a_j = x_{j-1}$ and $b_j = x_j$.\n\n3. Error metric and convergence rate:\n   - For each discretization, define the collocation points $x_i = \\frac{a_i + b_i}{2}$ and compare the numerical density $\\sigma_i$ against the exact singular profile $\\sigma^{\\star}(x) = \\frac{1}{\\sqrt{1 - x^{2}}}$ evaluated at $x_i$.\n   - Compute the discrete $L^{2}$ error\n     $$\n     E(N,p) = \\left(\\sum_{i=1}^{N} \\left(\\sigma_i - \\sigma^{\\star}(x_i)\\right)^{2} \\,(b_i - a_i)\\right)^{1/2}.\n     $$\n   - For two discretizations with panel counts $N_1$ and $N_2$ at the same grading exponent $p$, estimate the experimental order of convergence (EOC) with respect to $N$ as\n     $$\n     \\mathrm{EOC}(N_1,N_2,p) = \\frac{\\log\\left(\\frac{E(N_1,p)}{E(N_2,p)}\\right)}{\\log\\left(\\frac{N_2}{N_1}\\right)}.\n     $$\n\n4. Test suite:\n   - Implement the following test cases, each defined by $(N_1,N_2,p)$:\n     - $(N_1,N_2,p) = (32,64,1)$,\n     - $(N_1,N_2,p) = (32,64,2)$,\n     - $(N_1,N_2,p) = (32,64,4)$,\n     - $(N_1,N_2,p) = (16,32,8)$,\n     - $(N_1,N_2,p) = (8,16,1)$.\n   - These cases are chosen to cover a uniform baseline, moderate grading, stronger grading, and a lower-$N$ edge case.\n\n5. Final output format:\n   - Your program must output a single line containing the estimated convergence rates for the test cases, in the exact order listed above, formatted as a comma-separated Python-style list. Each number must be rounded to six decimal places. For example, an output line should look like\n     $$\n     [r_1,r_2,r_3,r_4,r_5]\n     $$\n     where $r_i$ are the rounded $\\mathrm{EOC}$ values corresponding to the five test cases.\n\nAll mathematical operations should be implemented numerically and the program must be self-contained, producing the single-line output without any external input. No physical units or angles are involved in this problem; all quantities are dimensionless. Your implementation must rely solely on the described integral equation, discretization, and mesh strategies to quantify the effect of grading near wedges and tips on the convergence rate of the SIE solution.",
            "solution": "The problem requires the implementation and analysis of a numerical method to solve a specific one-dimensional surface integral equation (SIE) arising in electrostatics. The goal is to quantify the effect of mesh grading on the convergence rate of the solution, particularly in capturing the singular behavior of the charge density near sharp edges.\n\nThe governing equation is a first-kind Fredholm integral equation for the unknown surface charge density $\\sigma(y)$ on the interval $[-1,1]$:\n$$\n\\int_{-1}^{1} G(x,y)\\,\\sigma(y)\\,\\mathrm{d}y = g(x), \\quad x \\in (-1,1)\n$$\nHere, $G(x,y) = -\\frac{1}{2\\pi}\\log|x - y|$ is the two-dimensional Green's function for the Laplacian, and the right-hand side is prescribed as the constant potential $g(x) = \\frac{\\log 2}{2}$. For this specific potential, the exact charge density is known to be $\\sigma^{\\star}(x) = \\frac{1}{\\sqrt{1 - x^{2}}}$, which exhibits singularities at the endpoints $x = \\pm 1$.\n\nOur approach is to solve this integral equation using a panel-based collocation method, also known as a Boundary Element Method (BEM) or Method of Moments (MoM).\n\n**1. Discretization and Matrix Formulation**\n\nWe partition the domain $[-1,1]$ into $N$ contiguous panels, or elements. Let the $j$-th panel be the interval $[a_j, b_j]$. We approximate the unknown charge density $\\sigma(y)$ as a piecewise constant function:\n$$\n\\sigma(y) \\approx \\sum_{j=1}^{N} \\sigma_j \\phi_j(y)\n$$\nwhere $\\sigma_j$ is the unknown constant value of the charge density on the $j$-th panel, and $\\phi_j(y)$ is a basis function that is $1$ for $y \\in [a_j, b_j]$ and $0$ otherwise.\n\nSubstituting this approximation into the integral equation yields:\n$$\n\\sum_{j=1}^{N} \\sigma_j \\int_{a_j}^{b_j} G(x,y)\\,\\mathrm{d}y = g(x)\n$$\nTo determine the $N$ unknown coefficients $\\{\\sigma_j\\}$, we enforce this equation at $N$ distinct collocation points. A standard choice for piecewise constant basis functions is to use the midpoint of each panel as a collocation point, $x_i = \\frac{a_i + b_i}{2}$ for $i=1, \\dots, N$. This leads to a system of linear equations $A\\boldsymbol{\\sigma} = \\boldsymbol{g}$, where $\\boldsymbol{\\sigma} = [\\sigma_1, \\dots, \\sigma_N]^T$ is the vector of unknown coefficients, $\\boldsymbol{g}$ is the vector of right-hand side values evaluated at the collocation points, $g_i = g(x_i) = \\frac{\\log 2}{2}$, and $A$ is the $N \\times N$ system matrix.\n\nThe entries of the matrix $A$ are given by the integral of the Green's function over each panel:\n$$\nA_{ij} = \\int_{a_j}^{b_j} G(x_i,y)\\,\\mathrm{d}y = -\\frac{1}{2\\pi}\\int_{a_j}^{b_j} \\log|x_i - y|\\,\\mathrm{d}y\n$$\nThis integral can be evaluated analytically. The indefinite integral of $\\log|c-y|$ with respect to $y$ is $(y-c)\\log|y-c| - y$. Evaluating this at the panel endpoints $a_j$ and $b_j$ gives:\n$$\n\\int_{a_j}^{b_j} \\log|x_i - y|\\,\\mathrm{d}y = \\left[ (y-x_i)\\log|y-x_i| - y \\right]_{y=a_j}^{y=b_j}\n$$\n$$\n= \\left( (b_j-x_i)\\log|b_j-x_i| - b_j \\right) - \\left( (a_j-x_i)\\log|a_j-x_i| - a_j \\right)\n$$\n$$\n= (b_j-x_i)\\log|b_j-x_i| - (a_j-x_i)\\log|a_j-x_i| - (b_j-a_j)\n$$\nThis formula is valid for both off-diagonal ($i \\neq j$) and diagonal ($i=j$) entries, as the logarithmic singularity is integrable. The final expression for the matrix entries is:\n$$\nA_{ij} = -\\frac{1}{2\\pi} \\left( (b_j-x_i)\\log|b_j-x_i| - (a_j-x_i)\\log|a_j-x_i| - (b_j-a_j) \\right)\n$$\n\n**2. Mesh Generation**\n\nThe accuracy of the numerical solution is highly dependent on the placement of the panels. To resolve the singularities at $x = \\pm 1$, the panels must become smaller near the endpoints. This is achieved using a graded mesh.\n\nWe generate a set of $N+1$ nodes $\\{x_k\\}_{k=0}^N$ that define the panel boundaries. The $j$-th panel is $[a_j, b_j] = [x_{j-1}, x_j]$. The nodes are defined via a mapping from a uniform grid $s_k = k/N$ for $k=0, \\dots, N$ in the interval $[0,1]$ to the physical domain $[-1,1]$. The grading is controlled by a parameter $p \\geq 1$.\nThe grading function is:\n$$\n\\beta_p(s) = \\frac{s^{p}}{s^{p} + (1 - s)^{p}}\n$$\nThe physical node locations are then:\n$$\nx_k = -1 + 2\\,\\beta_p\\!\\left(\\frac{k}{N}\\right)\n$$\nFor $p=1$, $\\beta_1(s) = s$, which results in a uniform mesh with equally spaced nodes. For $p > 1$, the function $\\beta_p(s)$ has steep slopes near $s=0$ and $s=1$, which clusters the nodes $x_k$ towards the endpoints $-1$ and $1$. A choice of $p=2$ is known to be particularly effective for the $\\frac{1}{\\sqrt{1-x^2}}$ singularity type.\n\n**3. Error Calculation and Convergence Analysis**\n\nAfter assembling the matrix $A$ and vector $\\boldsymbol{g}$, we solve the dense linear system $A\\boldsymbol{\\sigma} = \\boldsymbol{g}$ to obtain the numerical solution coefficients $\\sigma_i$. To quantify the accuracy, we compute the error by comparing this numerical solution to the known exact solution $\\sigma^{\\star}(x) = \\frac{1}{\\sqrt{1-x^2}}$ evaluated at the collocation points $x_i$.\n\nThe discrete $L^2$ error is defined as a weighted sum over the panels:\n$$\nE(N,p) = \\left(\\sum_{i=1}^{N} \\left(\\sigma_i - \\sigma^{\\star}(x_i)\\right)^{2} \\,(b_i - a_i)\\right)^{1/2}\n$$\nwhere $(b_i-a_i)$ is the length of the $i$-th panel.\n\nTo analyze the convergence behavior, we compute the Experimental Order of Convergence (EOC). The EOC measures the rate at which the error decreases as the number of panels $N$ increases. For two discretizations with panel counts $N_1$ and $N_2$ (typically $N_2 > N_1$), the EOC is estimated as:\n$$\n\\mathrm{EOC}(N_1,N_2,p) = \\frac{\\log\\left(\\frac{E(N_1,p)}{E(N_2,p)}\\right)}{\\log\\left(\\frac{N_2}{N_1}\\right)}\n$$\nA higher EOC indicates faster convergence. For a uniform mesh ($p=1$), the EOC is expected to be low (theoretically $0.5$) due to the unresolved singularities. An appropriately chosen grading ($p=2$) should significantly improve the EOC (theoretically to $1.5$). Over-grading ($p2$) can degrade performance as the error becomes dominated by the larger panels in the center of the domain.\n\nThe implementation will consist of functions to generate the mesh, assemble the matrix, solve the system, and compute the EOC for the specified test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve as sp_solve\n\ndef create_mesh(N, p):\n    \"\"\"\n    Generates a graded mesh on [-1, 1] with N panels and grading exponent p.\n\n    Args:\n        N (int): Number of panels.\n        p (float): Grading exponent. p=1 corresponds to a uniform mesh.\n\n    Returns:\n        tuple: A tuple containing:\n            - collocation_pts (np.ndarray): Midpoints of the panels.\n            - panel_endpoints_a (np.ndarray): Start points of the panels.\n            - panel_endpoints_b (np.ndarray): End points of the panels.\n            - panel_lengths (np.ndarray): Lengths of the panels.\n    \"\"\"\n    s = np.linspace(0, 1, N + 1)\n    \n    # Grading function beta_p(s)\n    if p == 1.0:\n        beta_s = s\n    else:\n        s_p = s**p\n        one_minus_s = 1 - s\n        # To avoid 0**p for negative p, but p>=1 here so it's fine.\n        one_minus_s_p = one_minus_s**p\n        # Add a small epsilon for numerical stability at s=0.5 if p is very large\n        denominator = s_p + one_minus_s_p\n        # Handle cases where denominator might be zero (s=0.5, p->inf)\n        # or s=0,1 gives 0/0 for p1, but p>=1 so safe.\n        beta_s = np.divide(s_p, denominator, out=np.full_like(s_p, 0.5), where=denominator!=0)\n        beta_s[0] = 0.0\n        beta_s[-1] = 1.0\n\n    endpoints = -1 + 2 * beta_s\n    \n    panel_endpoints_a = endpoints[:-1]\n    panel_endpoints_b = endpoints[1:]\n    \n    collocation_pts = (panel_endpoints_a + panel_endpoints_b) / 2\n    panel_lengths = panel_endpoints_b - panel_endpoints_a\n    \n    return collocation_pts, panel_endpoints_a, panel_endpoints_b, panel_lengths\n\ndef compute_error(N, p):\n    \"\"\"\n    Computes the discrete L2 error for a given discretization (N, p).\n    \"\"\"\n    collocation_pts, aj, bj, panel_lengths = create_mesh(N, p)\n    \n    # Assemble the matrix A using vectorized operations\n    xi = collocation_pts[:, np.newaxis] # Shape (N, 1)\n    aj_row = aj[np.newaxis, :]         # Shape (1, N)\n    bj_row = bj[np.newaxis, :]         # Shape (1, N)\n\n    def x_log_abs_x(x):\n        # np.log(0) is -inf, 0 * -inf is nan. We want it to be 0.\n        res = np.zeros_like(x, dtype=float)\n        mask = x != 0\n        res[mask] = x[mask] * np.log(np.abs(x[mask]))\n        return res\n        \n    term1 = x_log_abs_x(bj_row - xi)\n    term2 = x_log_abs_x(aj_row - xi)\n    \n    integral_val = term1 - term2 - (bj_row - aj_row)\n    A = -1 / (2 * np.pi) * integral_val\n\n    # Assemble the right-hand side vector g\n    g_val = np.log(2) / 2\n    g_vector = np.full(N, g_val)\n    \n    # Solve the linear system A * sigma = g\n    sigma = sp_solve(A, g_vector)\n    \n    # Compute the exact solution at collocation points\n    # 1 - x^2 can be calculated stably as (1-x)(1+x)\n    one_minus_x2 = 1 - collocation_pts**2\n    # Ensure no division by zero for points very close to +/- 1\n    one_minus_x2[one_minus_x2 = 0] = np.finfo(float).eps\n    exact_sigma = 1 / np.sqrt(one_minus_x2)\n    \n    # Compute the discrete L2 error\n    error_sq_sum = np.sum((sigma - exact_sigma)**2 * panel_lengths)\n    error = np.sqrt(error_sq_sum)\n    \n    return error\n\ndef calculate_eoc(N1, N2, p):\n    \"\"\"\n    Calculates the Experimental Order of Convergence (EOC).\n    \"\"\"\n    error1 = compute_error(N1, p)\n    error2 = compute_error(N2, p)\n    \n    eoc = np.log(error1 / error2) / np.log(N2 / N1)\n    \n    return eoc\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # test_cases are (N1, N2, p)\n    test_cases = [\n        (32, 64, 1),\n        (32, 64, 2),\n        (32, 64, 4),\n        (16, 32, 8),\n        (8, 16, 1),\n    ]\n\n    results = []\n    for case in test_cases:\n        N1, N2, p = case\n        eoc = calculate_eoc(N1, N2, p)\n        # Round to six decimal places as required.\n        results.append(round(eoc, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While the Electric and Magnetic Field Integral Equations (EFIE and MFIE) are foundational, they suffer from numerical issues like low-frequency breakdown and interior resonances. The Combined Field Integral Equation (CFIE) overcomes these by forming a linear combination of the two, but its effectiveness depends critically on the choice of the mixing parameter $\\alpha$. This advanced practice uses a computationally tractable spectral model to explore how to optimize $\\alpha$ across a range of frequencies, providing insight into designing robust, broadband SIE solvers with superior conditioning and faster iterative convergence .",
            "id": "3352519",
            "problem": "You are tasked with designing and evaluating a frequency-adaptive strategy for the Combined Field Integral Equation (CFIE) parameter in a simplified but scientifically faithful spectral surrogate of a surface integral equation formulation used in computational electromagnetics. The goal is to determine a parameter function $\\alpha(k)$, with $\\alpha(k) \\in [0,1]$, that minimizes the condition number of the discretized CFIE system matrix over a sweep of wavenumbers $k$ (in radians per meter). You will compare a uniform choice $\\alpha(k) \\equiv \\alpha$ against an adaptive strategy $\\alpha(k)$ chosen at each $k$.\n\nThe physical foundation is the time-harmonic Maxwell equations for scattering from a perfectly electrically conducting (PEC) closed surface. After a standard boundary integral equation formulation and discretization with Rao–Wilton–Glisson (RWG) basis functions, one obtains the Electric Field Integral Equation (EFIE) and Magnetic Field Integral Equation (MFIE) system matrices, denoted by $\\mathbf{A}_{\\mathrm{E}}(k)$ and $\\mathbf{A}_{\\mathrm{M}}(k)$, respectively. The CFIE matrix is constructed as\n$$\n\\mathbf{A}_{\\mathrm{C}}(\\alpha,k) \\triangleq \\alpha\\,\\mathbf{A}_{\\mathrm{E}}(k) + \\left(1-\\alpha\\right)\\,\\mathbf{A}_{\\mathrm{M}}(k),\n$$\nwhere $\\alpha \\in [0,1]$ is the CFIE mixing parameter. The condition number of a nonsingular matrix $\\mathbf{B}$ is defined as\n$$\n\\kappa(\\mathbf{B}) \\triangleq \\|\\mathbf{B}\\|_{2}\\,\\|\\mathbf{B}^{-1}\\|_{2},\n$$\nwhich for diagonalizable, symmetric positive-definite surrogates reduces to the ratio of largest to smallest eigenvalue.\n\nTo make the problem computationally tractable while preserving key spectral features (low-frequency breakdown of EFIE and interior resonance dips), you will use a surrogate spectral model in which $\\mathbf{A}_{\\mathrm{E}}(k)$ and $\\mathbf{A}_{\\mathrm{M}}(k)$ are diagonal in a fixed orthonormal basis with $N$ modes and $k$-dependent positive eigenvalues $\\{\\lambda_{\\mathrm{E},i}(k)\\}_{i=1}^N$ and $\\{\\lambda_{\\mathrm{M},i}(k)\\}_{i=1}^N$. The CFIE eigenvalues are then\n$$\n\\lambda_{\\mathrm{C},i}(\\alpha,k) = \\alpha\\,\\lambda_{\\mathrm{E},i}(k) + \\left(1-\\alpha\\right)\\,\\lambda_{\\mathrm{M},i}(k), \\quad i\\in\\{1,\\dots,N\\}.\n$$\nThe condition number of the CFIE surrogate is\n$$\n\\kappa(\\alpha,k) = \\frac{\\max_{i}\\lambda_{\\mathrm{C},i}(\\alpha,k)}{\\min_{i}\\lambda_{\\mathrm{C},i}(\\alpha,k)}.\n$$\n\nUse $N=6$ modes. Define the EFIE eigenvalues by a low-order polynomial baseline with narrow resonance dips:\n$$\n\\lambda_{\\mathrm{E},i}(k) = \\left(a_i + b_i\\,k + c_i\\,k^2\\right)\\,\\prod_{r \\in \\mathcal{R}_i}\\left(1 - h_{i,r}\\,\\exp\\left(-\\frac{(k-k_{i,r})^2}{2\\,\\sigma_{i,r}^2}\\right)\\right),\n$$\nwhere $k$ is in radians per meter. The MFIE eigenvalues are defined by a slowly varying baseline with mild smooth bumps:\n$$\n\\lambda_{\\mathrm{M},i}(k) = u_i + \\frac{v_i}{1+k} + \\sum_{m \\in \\mathcal{M}_i} g_{i,m}\\,\\exp\\left(-\\frac{(k-\\mu_{i,m})^2}{2\\,\\tau_{i,m}^2}\\right).\n$$\nAll eigenvalues must remain strictly positive for all $k$ in the sweeps below. Use the following constants (all scalars are real and strictly positive):\n\n- For EFIE coefficients $\\{a_i\\}_{i=1}^{6}$, $\\{b_i\\}_{i=1}^{6}$, $\\{c_i\\}_{i=1}^{6}$:\n  - $a_1 = 10^{-3}$, $a_2 = 0.3$, $a_3 = 0.4$, $a_4 = 10^{-3}$, $a_5 = 0.6$, $a_6 = 0.8$.\n  - $b_1 = 0.05$, $b_2 = 0.04$, $b_3 = 0.02$, $b_4 = 0.07$, $b_5 = 0.03$, $b_6 = 0.01$.\n  - $c_1 = 0.005$, $c_2 = 0.003$, $c_3 = 0.004$, $c_4 = 0.006$, $c_5 = 0.002$, $c_6 = 0.003$.\n- EFIE resonance sets $\\mathcal{R}_i$:\n  - $\\mathcal{R}_2 = \\{r\\}$ with $k_{2,r} = 3.0$, $\\sigma_{2,r} = 0.2$, $h_{2,r} = 0.9$.\n  - $\\mathcal{R}_5 = \\{r\\}$ with $k_{5,r} = 7.5$, $\\sigma_{5,r} = 0.25$, $h_{5,r} = 0.85$.\n  - $\\mathcal{R}_i = \\emptyset$ for $i \\in \\{1,3,4,6\\}$.\n- For MFIE coefficients $\\{u_i\\}_{i=1}^{6}$, $\\{v_i\\}_{i=1}^{6}$:\n  - $u_1 = 0.9$, $u_2 = 1.0$, $u_3 = 1.1$, $u_4 = 0.8$, $u_5 = 1.2$, $u_6 = 1.0$.\n  - $v_1 = 0.3$, $v_2 = 0.25$, $v_3 = 0.2$, $v_4 = 0.35$, $v_5 = 0.15$, $v_6 = 0.22$.\n- MFIE bump sets $\\mathcal{M}_i$:\n  - $\\mathcal{M}_3 = \\{m\\}$ with $\\mu_{3,m} = 6.0$, $\\tau_{3,m} = 0.4$, $g_{3,m} = 0.10$.\n  - $\\mathcal{M}_6 = \\{m\\}$ with $\\mu_{6,m} = 4.0$, $\\tau_{6,m} = 0.3$, $g_{6,m} = 0.08$.\n  - $\\mathcal{M}_i = \\emptyset$ for $i \\in \\{1,2,4,5\\}$.\n\nYour objective is to design, implement, and compare the following two CFIE parameter selection strategies:\n\n- Uniform strategy: choose a single $\\alpha^{\\star} \\in [0,1]$ that minimizes the average logarithmic condition number across a frequency sweep $\\{k_j\\}_{j=1}^{M}$:\n$$\nJ(\\alpha) \\triangleq \\frac{1}{M}\\sum_{j=1}^{M} \\log \\kappa(\\alpha,k_j).\n$$\n- Frequency-adaptive strategy: choose $\\alpha^{\\star}(k_j) \\in [0,1]$ for each $k_j$ to minimize $\\kappa(\\alpha,k_j)$.\n\nFor both strategies, report the geometric mean condition number over the sweep, defined as\n$$\n\\mathrm{GM} \\triangleq \\exp\\left(\\frac{1}{M}\\sum_{j=1}^{M} \\log \\kappa(\\cdot,k_j)\\right).\n$$\n\nNumerical procedure and constraints:\n\n- Restrict $\\alpha$ to a dense uniform grid on $[0,1]$ with step size $\\Delta \\alpha = 0.001$. This includes both endpoints $\\alpha=0$ and $\\alpha=1$.\n- The wavenumber $k$ is in radians per meter (rad/m). The condition number is dimensionless.\n- Implement the surrogate as described and ensure that for each $k$ in the sweeps, all eigenvalues remain strictly positive.\n\nTest Suite:\n\nUse the following three test cases, each with $M=61$ linearly spaced points:\n\n- Case A (broadband with multiple resonances): $k \\in [0.5,10.0]$ rad/m.\n- Case B (low-frequency emphasis): $k \\in [0.1,2.0]$ rad/m.\n- Case C (mid-to-high frequency): $k \\in [3.0,9.0]$ rad/m.\n\nFor each case, compute and output the following four quantities:\n\n- The optimal uniform $\\alpha^{\\star}$ that minimizes $J(\\alpha)$ over the sweep.\n- The geometric mean condition number for the uniform strategy, $\\mathrm{GM}_{\\mathrm{unif}}$.\n- The geometric mean condition number for the adaptive strategy, $\\mathrm{GM}_{\\mathrm{adapt}}$.\n- The improvement factor $R \\triangleq \\mathrm{GM}_{\\mathrm{unif}} / \\mathrm{GM}_{\\mathrm{adapt}}$.\n\nFinal Output Format:\n\nYour program should produce a single line of output containing a flattened, comma-separated list of $12$ floating-point values enclosed in square brackets, ordered case by case as\n$$\n[\\alpha^{\\star}_{\\mathrm{A}}, \\mathrm{GM}_{\\mathrm{unif,A}}, \\mathrm{GM}_{\\mathrm{adapt,A}}, R_{\\mathrm{A}}, \\alpha^{\\star}_{\\mathrm{B}}, \\mathrm{GM}_{\\mathrm{unif,B}}, \\mathrm{GM}_{\\mathrm{adapt,B}}, R_{\\mathrm{B}}, \\alpha^{\\star}_{\\mathrm{C}}, \\mathrm{GM}_{\\mathrm{unif,C}}, \\mathrm{GM}_{\\mathrm{adapt,C}}, R_{\\mathrm{C}}].\n$$\nAll outputs must be rounded to exactly $4$ decimal places. No other text should be printed. The wavenumber $k$ must be treated in radians per meter (rad/m) and all quantities to be reported are dimensionless. Angles are not used in this problem. Percentages must not appear; if any ratio is computed, it must be given as a decimal number. The program must be fully self-contained and require no input.",
            "solution": "The problem is valid as it is scientifically grounded in computational electromagnetics, well-posed, and provides a complete and consistent set of definitions and data. The task is to evaluate and compare two strategies for selecting the Combined Field Integral Equation (CFIE) mixing parameter, $\\alpha$, using a simplified but representative spectral surrogate model.\n\nThe foundation of the problem lies in the integral equation formulation for electromagnetic scattering from a perfectly electrically conducting (PEC) body. Discretization of the Electric Field Integral Equation (EFIE) and Magnetic Field Integral Equation (MFIE) yields linear systems with matrices $\\mathbf{A}_{\\mathrm{E}}(k)$ and $\\mathbf{A}_{\\mathrm{M}}(k)$, respectively, where $k$ is the wavenumber. The CFIE combines these to overcome numerical issues like interior resonances and low-frequency breakdown. The CFIE system matrix is a linear combination:\n$$\n\\mathbf{A}_{\\mathrm{C}}(\\alpha,k) = \\alpha\\,\\mathbf{A}_{\\mathrm{E}}(k) + \\left(1-\\alpha\\right)\\,\\mathbf{A}_{\\mathrm{M}}(k)\n$$\nwhere the mixing parameter $\\alpha$ is typically chosen in the range $[0, 1]$. The conditioning of this matrix, measured by its condition number $\\kappa(\\mathbf{A}_{\\mathrm{C}})$, is critical for the performance of iterative solvers.\n\nThis problem employs a surrogate model where the matrices are diagonal with $N=6$ modes. The eigenvalues of $\\mathbf{A}_{\\mathrm{E}}(k)$ and $\\mathbf{A}_{\\mathrm{M}}(k)$ are given by functions $\\lambda_{\\mathrm{E},i}(k)$ and $\\lambda_{\\mathrm{M},i}(k)$ for $i \\in \\{1, \\dots, 6\\}$. These functions are designed to mimic the known spectral behavior of their full-matrix counterparts. Specifically, the eigenvalues for the EFIE surrogate are given by:\n$$\n\\lambda_{\\mathrm{E},i}(k) = \\left(a_i + b_i\\,k + c_i\\,k^2\\right)\\,\\prod_{r \\in \\mathcal{R}_i}\\left(1 - h_{i,r}\\,\\exp\\left(-\\frac{(k-k_{i,r})^2}{2\\,\\sigma_{i,r}^2}\\right)\\right)\n$$\nThis form includes a polynomial baseline, which for some modes ($i=1, 4$) has a small constant term $a_i=10^{-3}$ to model the low-frequency ill-conditioning, and a product of Gaussian dips to represent sharp interior resonances. The eigenvalues for the MFIE surrogate are:\n$$\n\\lambda_{\\mathrm{M},i}(k) = u_i + \\frac{v_i}{1+k} + \\sum_{m \\in \\mathcal{M}_i} g_{i,m}\\,\\exp\\left(-\\frac{(k-\\mu_{i,m})^2}{2\\,\\tau_{i,m}^2}\\right)\n$$\nThis form is well-behaved at low frequencies ($k \\to 0$) and incorporates smooth spectral features. All provided parameters ensure that eigenvalues are strictly positive for the specified ranges of $k$.\n\nFor this diagonal surrogate model, the eigenvalues of the CFIE matrix are a simple linear combination of the EFIE and MFIE eigenvalues:\n$$\n\\lambda_{\\mathrm{C},i}(\\alpha,k) = \\alpha\\,\\lambda_{\\mathrm{E},i}(k) + \\left(1-\\alpha\\right)\\,\\lambda_{\\mathrm{M},i}(k)\n$$\nThe condition number, being the ratio of the largest to the smallest eigenvalue for a positive definite diagonal matrix, simplifies to:\n$$\n\\kappa(\\alpha,k) = \\frac{\\max_{i}\\lambda_{\\mathrm{C},i}(\\alpha,k)}{\\min_{i}\\lambda_{\\mathrm{C},i}(\\alpha,k)}\n$$\nThe objective is to find an optimal $\\alpha$ to minimize this condition number. Two strategies are compared.\n\n**1. Frequency-Adaptive Strategy**\n\nThis strategy seeks the best possible performance by choosing an optimal $\\alpha$ for each individual wavenumber $k_j$ in a given frequency sweep $\\{k_j\\}_{j=1}^M$. The optimization problem at each $k_j$ is:\n$$\n\\alpha^{\\star}(k_j) = \\underset{\\alpha \\in \\{0, \\Delta\\alpha, \\dots, 1\\}}{\\arg\\min} \\kappa(\\alpha, k_j)\n$$\nwhere the search for $\\alpha$ is performed over a discrete grid on $[0,1]$ with step size $\\Delta\\alpha = 0.001$. The overall performance of this strategy is measured by the geometric mean of the resulting minimized condition numbers:\n$$\n\\mathrm{GM}_{\\mathrm{adapt}} = \\exp\\left(\\frac{1}{M}\\sum_{j=1}^{M} \\log \\kappa(\\alpha^{\\star}(k_j),k_j)\\right)\n$$\nThis provides a benchmark for the best achievable conditioning with the CFIE approach.\n\n**2. Uniform Strategy**\n\nThis strategy seeks a single, fixed value of $\\alpha$ that performs well on average across the entire frequency sweep. The optimal uniform parameter, $\\alpha^{\\star}$, is found by minimizing the average logarithmic condition number:\n$$\nJ(\\alpha) = \\frac{1}{M}\\sum_{j=1}^{M} \\log \\kappa(\\alpha,k_j)\n$$\nThe optimization problem is thus:\n$$\n\\alpha^{\\star} = \\underset{\\alpha \\in \\{0, \\Delta\\alpha, \\dots, 1\\}}{\\arg\\min} J(\\alpha)\n$$\nThe performance of this strategy is the geometric mean condition number evaluated using this single optimal $\\alpha^{\\star}$ across all frequencies:\n$$\n\\mathrm{GM}_{\\mathrm{unif}} = \\exp\\left(\\frac{1}{M}\\sum_{j=1}^{M} \\log \\kappa(\\alpha^{\\star},k_j)\\right) = \\exp(J(\\alpha^{\\star}))\n$$\nThe comparison between the two strategies is quantified by the improvement factor $R = \\mathrm{GM}_{\\mathrm{unif}} / \\mathrm{GM}_{\\mathrm{adapt}}$.\n\nThe algorithmic procedure to solve the problem for each test case is as follows:\n1.  Define the discrete grid for $\\alpha$ on $[0,1]$ with $1001$ points and the wavenumber grid for $k$ with $M=61$ points for the specific case.\n2.  Vectorize the computation of eigenvalues. For the array of $k_j$ values, compute the $6 \\times M$ matrices of EFIE eigenvalues, $[\\lambda_{\\mathrm{E},i}(k_j)]$, and MFIE eigenvalues, $[\\lambda_{\\mathrm{M},i}(k_j)]$.\n3.  Construct a $1001 \\times 6 \\times M$ tensor of CFIE eigenvalues, $\\lambda_{\\mathrm{C},i}(\\alpha_p, k_j)$, using broadcasting operations over the $\\alpha$ grid.\n4.  Compute the $1001 \\times M$ matrix of condition numbers, $[\\kappa(\\alpha_p, k_j)]$, by taking the max-to-min ratio along the mode axis ($i$).\n5.  To evaluate the adaptive strategy, find the minimum condition number along the $\\alpha$ axis for each $k_j$. Compute the geometric mean of these minima to get $\\mathrm{GM}_{\\mathrm{adapt}}$.\n6.  To evaluate the uniform strategy, compute the cost function $J(\\alpha_p)$ by taking the mean of the logarithm of condition numbers along the $k$ axis for each $\\alpha_p$. Find the $\\alpha_p$ that minimizes $J(\\alpha_p)$ to get $\\alpha^{\\star}$. The minimum value of $J$ is $\\log(\\mathrm{GM}_{\\mathrm{unif}})$, so $\\mathrm{GM}_{\\mathrm{unif}} = \\exp(\\min J(\\alpha_p))$.\n7.  Calculate the improvement factor $R$ and collect the four required values for the given case.\n8.  Repeat for all three test cases and format the final output as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the CFIE parameter optimization problem for three test cases.\n    \"\"\"\n    \n    # Define model parameters\n    N = 6\n    # EFIE parameters\n    a = np.array([1e-3, 0.3, 0.4, 1e-3, 0.6, 0.8])\n    b = np.array([0.05, 0.04, 0.02, 0.07, 0.03, 0.01])\n    c = np.array([0.005, 0.003, 0.004, 0.006, 0.002, 0.003])\n    efie_res = {\n        1: {'k': 3.0, 'sigma': 0.2, 'h': 0.9},   # i=2\n        4: {'k': 7.5, 'sigma': 0.25, 'h': 0.85} # i=5\n    }\n    \n    # MFIE parameters\n    u = np.array([0.9, 1.0, 1.1, 0.8, 1.2, 1.0])\n    v = np.array([0.3, 0.25, 0.2, 0.35, 0.15, 0.22])\n    mfie_bumps = {\n        2: {'mu': 6.0, 'tau': 0.4, 'g': 0.10}, # i=3\n        5: {'mu': 4.0, 'tau': 0.3, 'g': 0.08}  # i=6\n    }\n    \n    def compute_lambda_E(k_vals):\n        \"\"\"Computes EFIE eigenvalues for all modes over a range of k.\"\"\"\n        lambda_E = np.zeros((N, len(k_vals)))\n        k_vals_sq = k_vals**2\n        for i in range(N):\n            poly_part = a[i] + b[i] * k_vals + c[i] * k_vals_sq\n            res_product = 1.0\n            if i in efie_res:\n                params = efie_res[i]\n                res_product *= (1 - params['h'] * np.exp(-(k_vals - params['k'])**2 / (2 * params['sigma']**2)))\n            lambda_E[i, :] = poly_part * res_product\n        return lambda_E\n\n    def compute_lambda_M(k_vals):\n        \"\"\"Computes MFIE eigenvalues for all modes over a range of k.\"\"\"\n        lambda_M = np.zeros((N, len(k_vals)))\n        for i in range(N):\n            base_part = u[i] + v[i] / (1 + k_vals)\n            bump_sum = 0.0\n            if i in mfie_bumps:\n                params = mfie_bumps[i]\n                bump_sum += params['g'] * np.exp(-(k_vals - params['mu'])**2 / (2 * params['tau']**2))\n            lambda_M[i, :] = base_part + bump_sum\n        return lambda_M\n        \n    test_cases = [\n        {'name': 'A', 'k_range': [0.5, 10.0]},\n        {'name': 'B', 'k_range': [0.1, 2.0]},\n        {'name': 'C', 'k_range': [3.0, 9.0]},\n    ]\n    M = 61\n    delta_alpha = 0.001\n    alpha_vals = np.linspace(0, 1, int(1/delta_alpha) + 1)\n    \n    final_results = []\n    \n    for case in test_cases:\n        k_vals = np.linspace(case['k_range'][0], case['k_range'][1], M)\n        \n        # Pre-compute eigenvalues\n        lambda_E_ik = compute_lambda_E(k_vals)\n        lambda_M_ik = compute_lambda_M(k_vals)\n        \n        # Vectorized calculation of CFIE eigenvalues and condition numbers\n        # Reshape for broadcasting:\n        # alpha_vals: (P, 1, 1) where P = number of alpha samples\n        # lambda_E/M_ik: (1, N, M) where N=modes, M=k samples\n        alpha_p11 = alpha_vals[:, np.newaxis, np.newaxis]\n        lambda_E_1NM = lambda_E_ik[np.newaxis, :, :]\n        lambda_M_1NM = lambda_M_ik[np.newaxis, :, :]\n        \n        # CFIE eigenvalues: (P, N, M)\n        lambda_C_piM = alpha_p11 * lambda_E_1NM + (1 - alpha_p11) * lambda_M_1NM\n        \n        # Condition numbers: (P, M)\n        kappa_pM = np.max(lambda_C_piM, axis=1) / np.min(lambda_C_piM, axis=1)\n        \n        # --- Frequency-adaptive strategy ---\n        min_kappa_adaptive_M = np.min(kappa_pM, axis=0)\n        log_kappa_adaptive_M = np.log(min_kappa_adaptive_M)\n        GM_adapt = np.exp(np.mean(log_kappa_adaptive_M))\n\n        # --- Uniform strategy ---\n        log_kappa_pM = np.log(kappa_pM)\n        J_p = np.mean(log_kappa_pM, axis=1)\n        \n        opt_alpha_idx = np.argmin(J_p)\n        alpha_star_uniform = alpha_vals[opt_alpha_idx]\n        \n        min_J = J_p[opt_alpha_idx]\n        GM_unif = np.exp(min_J)\n        \n        # --- Improvement Factor ---\n        R = GM_unif / GM_adapt\n        \n        final_results.extend([\n            round(alpha_star_uniform, 4),\n            round(GM_unif, 4),\n            round(GM_adapt, 4),\n            round(R, 4)\n        ])\n        \n    # Format and print the final output\n    print(f\"[{','.join(f'{v:.4f}' for v in final_results)}]\")\n\nsolve()\n```"
        }
    ]
}