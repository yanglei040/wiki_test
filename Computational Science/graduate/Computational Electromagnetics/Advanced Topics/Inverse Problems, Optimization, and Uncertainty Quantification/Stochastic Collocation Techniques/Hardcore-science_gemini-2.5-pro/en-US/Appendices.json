{
    "hands_on_practices": [
        {
            "introduction": "The foundation of stochastic collocation lies in approximating a complex, unknown function with a simpler polynomial surrogate. This exercise takes you back to first principles, asking you to derive the explicit formula for a multidimensional interpolant constructed on a tensor-product grid. Mastering this derivation solidifies your understanding of how sample data from deterministic solves are combined to form the surrogate model .",
            "id": "3350693",
            "problem": "In frequency-domain computational electromagnetics, consider a parameterized Maxwell boundary value problem whose scalar quantity of interest is denoted by $u(\\boldsymbol{\\xi})$, where $\\boldsymbol{\\xi} \\in \\Gamma \\subset \\mathbb{R}^{d}$ represents $d$ independent uncertain input parameters with product probability density $\\rho(\\boldsymbol{\\xi})=\\prod_{j=1}^{d}\\rho_{j}(\\xi_{j})$. In a stochastic collocation (SC) setting, you are given a tensor-product grid built from univariate node sets $\\{\\xi^{(j)}_{k_{j}}\\}_{k_{j}=1}^{n_{j}} \\subset \\Gamma_{j}$ for each dimension $j \\in \\{1,\\dots,d\\}$. For each dimension $j$, the corresponding univariate Lagrange basis polynomials $\\{\\ell_{j,k_{j}}(\\xi_{j})\\}_{k_{j}=1}^{n_{j}}$ are defined by the cardinality conditions $\\ell_{j,k_{j}}(\\xi^{(j)}_{m_{j}})=\\delta_{k_{j}m_{j}}$ for all $k_{j},m_{j}\\in\\{1,\\dots,n_{j}\\}$, where $\\delta_{k_{j}m_{j}}$ is the Kronecker delta. The full tensor-product node set is $\\{\\boldsymbol{\\xi}^{\\boldsymbol{k}}\\}_{\\boldsymbol{k}}$ with multi-index $\\boldsymbol{k}=(k_{1},\\dots,k_{d})$ and $\\boldsymbol{\\xi}^{\\boldsymbol{k}}=(\\xi^{(1)}_{k_{1}},\\dots,\\xi^{(d)}_{k_{d}})$. Assume that a deterministic Maxwell solver provides the values $u(\\boldsymbol{\\xi}^{\\boldsymbol{k}})$ at all tensor-product nodes.\n\nUsing only the fundamental definition of interpolation in a finite-dimensional function space and the cardinality property of the univariate Lagrange bases, derive the explicit expression for the tensor-product stochastic collocation interpolant $\\hat{u}(\\boldsymbol{\\xi})$ that exactly interpolates the available samples $\\{u(\\boldsymbol{\\xi}^{\\boldsymbol{k}})\\}$ at the tensor-product nodes. Your final answer must be a single closed-form analytic expression for $\\hat{u}(\\boldsymbol{\\xi})$. No numerical evaluation, units, or rounding are required.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It provides a complete and consistent set of definitions and conditions to derive the explicit expression for a tensor-product stochastic collocation interpolant. The problem is based on fundamental principles of multivariate polynomial interpolation and is a standard theoretical exercise in uncertainty quantification. All terms are formally defined, and the task is to perform a mathematical derivation based on the provided premises. Therefore, the problem is valid, and a solution will be furnished.\n\nThe objective is to derive the expression for the interpolant $\\hat{u}(\\boldsymbol{\\xi})$ which approximates the quantity of interest $u(\\boldsymbol{\\xi})$. The interpolant is constructed in a finite-dimensional function space and must satisfy the interpolation condition at a set of discrete points. The problem specifies a tensor-product structure, which guides the choice of the basis for the function space.\n\nLet the multivariate space of interpolating functions be spanned by the tensor products of the univariate Lagrange basis polynomials $\\{\\ell_{j,k_j}(\\xi_j)\\}$. A basis function in this multivariate space, associated with the tensor-product node $\\boldsymbol{\\xi}^{\\boldsymbol{k}}$, is given by the product of the corresponding univariate basis functions. Let us denote this multivariate basis function by $L_{\\boldsymbol{k}}(\\boldsymbol{\\xi})$, where $\\boldsymbol{k}=(k_1, \\dots, k_d)$ is a multi-index with each component $k_j$ ranging from $1$ to $n_j$. The definition is:\n$$L_{\\boldsymbol{k}}(\\boldsymbol{\\xi}) = \\prod_{j=1}^{d} \\ell_{j,k_j}(\\xi_j)$$\nThe stochastic collocation interpolant $\\hat{u}(\\boldsymbol{\\xi})$ can be expressed as a linear combination of these basis functions:\n$$\\hat{u}(\\boldsymbol{\\xi}) = \\sum_{\\boldsymbol{k}} c_{\\boldsymbol{k}} L_{\\boldsymbol{k}}(\\boldsymbol{\\xi})$$\nThe summation is performed over all valid multi-indices $\\boldsymbol{k}$, which corresponds to a sum over all nodes in the tensor-product grid. This can be written more explicitly as:\n$$\\hat{u}(\\boldsymbol{\\xi}) = \\sum_{k_1=1}^{n_1} \\cdots \\sum_{k_d=1}^{n_d} c_{(k_1, \\dots, k_d)} \\left( \\prod_{j=1}^{d} \\ell_{j,k_j}(\\xi_j) \\right)$$\nThe coefficients $c_{\\boldsymbol{k}}$ are unknown and must be determined. To find them, we enforce the interpolation condition, which states that the interpolant must be equal to the true function value at each node of the tensor-product grid. For any node $\\boldsymbol{\\xi}^{\\boldsymbol{m}}$ corresponding to a multi-index $\\boldsymbol{m}=(m_1, \\dots, m_d)$, this condition is:\n$$\\hat{u}(\\boldsymbol{\\xi}^{\\boldsymbol{m}}) = u(\\boldsymbol{\\xi}^{\\boldsymbol{m}})$$\nSubstituting the expression for $\\hat{u}(\\boldsymbol{\\xi})$ into the left side of this equation, we get:\n$$\\sum_{\\boldsymbol{k}} c_{\\boldsymbol{k}} L_{\\boldsymbol{k}}(\\boldsymbol{\\xi}^{\\boldsymbol{m}}) = u(\\boldsymbol{\\xi}^{\\boldsymbol{m}})$$\nNow, we must evaluate the basis function $L_{\\boldsymbol{k}}(\\boldsymbol{\\xi})$ at the node $\\boldsymbol{\\xi}^{\\boldsymbol{m}}$. By definition, $\\boldsymbol{\\xi}^{\\boldsymbol{m}} = (\\xi^{(1)}_{m_1}, \\dots, \\xi^{(d)}_{m_d})$. So we have:\n$$L_{\\boldsymbol{k}}(\\boldsymbol{\\xi}^{\\boldsymbol{m}}) = \\prod_{j=1}^{d} \\ell_{j,k_j}(\\xi^{(j)}_{m_j})$$\nThe problem states the cardinality property of the univariate Lagrange basis polynomials: $\\ell_{j,k_{j}}(\\xi^{(j)}_{m_{j}})=\\delta_{k_{j}m_{j}}$, where $\\delta_{k_{j}m_{j}}$ is the Kronecker delta. Substituting this property into the expression for $L_{\\boldsymbol{k}}(\\boldsymbol{\\xi}^{\\boldsymbol{m}})$ gives:\n$$L_{\\boldsymbol{k}}(\\boldsymbol{\\xi}^{\\boldsymbol{m}}) = \\prod_{j=1}^{d} \\delta_{k_j m_j}$$\nThe product of Kronecker deltas is $1$ if and only if $k_j = m_j$ for all $j \\in \\{1, \\dots, d\\}$, which means the multi-index $\\boldsymbol{k}$ must be identical to the multi-index $\\boldsymbol{m}$. If any component $k_j$ is not equal to $m_j$, the product is $0$. This product defines the multidimensional Kronecker delta, $\\delta_{\\boldsymbol{k}\\boldsymbol{m}}$. Thus, the multivariate basis functions also exhibit a cardinality property:\n$$L_{\\boldsymbol{k}}(\\boldsymbol{\\xi}^{\\boldsymbol{m}}) = \\delta_{\\boldsymbol{k}\\boldsymbol{m}}$$\nSubstituting this result back into the equation for the coefficients:\n$$\\sum_{\\boldsymbol{k}} c_{\\boldsymbol{k}} \\delta_{\\boldsymbol{k}\\boldsymbol{m}} = u(\\boldsymbol{\\xi}^{\\boldsymbol{m}})$$\nDue to the sifting property of the Kronecker delta, the summation on the left side collapses, leaving only the term for which $\\boldsymbol{k} = \\boldsymbol{m}$. This yields:\n$$c_{\\boldsymbol{m}} = u(\\boldsymbol{\\xi}^{\\boldsymbol{m}})$$\nSince this holds for any multi-index $\\boldsymbol{m}$, we have found that the coefficients $c_{\\boldsymbol{k}}$ are simply the known values of the function $u$ at the corresponding tensor-product nodes $\\boldsymbol{\\xi}^{\\boldsymbol{k}}$.\n\nFinally, we substitute these coefficients back into the general expression for the interpolant $\\hat{u}(\\boldsymbol{\\xi})$:\n$$\\hat{u}(\\boldsymbol{\\xi}) = \\sum_{\\boldsymbol{k}} u(\\boldsymbol{\\xi}^{\\boldsymbol{k}}) L_{\\boldsymbol{k}}(\\boldsymbol{\\xi})$$\nWriting this out fully using the definitions of $L_{\\boldsymbol{k}}(\\boldsymbol{\\xi})$ and the summation over the multi-index $\\boldsymbol{k}=(k_1, \\dots, k_d)$ provides the final explicit expression for the tensor-product stochastic collocation interpolant:\n$$\\hat{u}(\\boldsymbol{\\xi}) = \\sum_{k_1=1}^{n_1} \\cdots \\sum_{k_d=1}^{n_d} u(\\boldsymbol{\\xi}^{\\boldsymbol{k}}) \\prod_{j=1}^{d} \\ell_{j,k_j}(\\xi_j)$$\nThis expression satisfies the interpolation condition $\\hat{u}(\\boldsymbol{\\xi}^{\\boldsymbol{m}}) = u(\\boldsymbol{\\xi}^{\\boldsymbol{m}})$ for all nodes $\\boldsymbol{\\xi}^{\\boldsymbol{m}}$ by construction, and its derivation uses only the fundamental principles specified in the problem statement.",
            "answer": "$$\n\\boxed{\n\\hat{u}(\\boldsymbol{\\xi}) = \\sum_{k_1=1}^{n_1} \\cdots \\sum_{k_d=1}^{n_d} u(\\boldsymbol{\\xi}^{\\boldsymbol{k}}) \\prod_{j=1}^{d} \\ell_{j,k_j}(\\xi_j)\n}\n$$"
        },
        {
            "introduction": "Once a surrogate model is constructed, its primary purpose is to enable efficient uncertainty quantification, starting with the computation of statistical moments. This practice provides a concrete polynomial surrogate and asks you to calculate its mean and variance. This exercise bridges the gap between the abstract form of the interpolant and its practical use in extracting key statistical insights .",
            "id": "3350756",
            "problem": "Consider a two-parameter uncertainty model for a Transverse Electric (TE) plane-wave scattering problem in computational electromagnetics, in which the scalar quantity of interest $u$ (for example, a normalized backscatter amplitude extracted from the solution of Maxwell’s equations) depends on two standardized, independent random inputs $\\xi_{1}$ and $\\xi_{2}$, each uniformly distributed on $[-1,1]$. A non-intrusive stochastic collocation surrogate $\\hat{u}(\\xi_{1},\\xi_{2})$ is constructed by interpolating deterministic electromagnetic solves at tensor-product Gauss–Legendre nodes of order $3$ per dimension. The interpolation nodes and associated one-dimensional quadrature weights are\n$$\\xi^{(1)} = -\\sqrt{\\frac{3}{5}},\\quad \\xi^{(2)} = 0,\\quad \\xi^{(3)} = \\sqrt{\\frac{3}{5}},\\qquad w^{(1)} = \\frac{5}{9},\\quad w^{(2)} = \\frac{8}{9},\\quad w^{(3)} = \\frac{5}{9}.$$\nThe resulting surrogate has the form\n$$\\hat{u}(\\xi_{1},\\xi_{2}) = 1.2 + 0.4\\,\\xi_{1} - 0.3\\,\\xi_{2} + 0.25\\,\\xi_{1}\\xi_{2} + 0.1\\,\\xi_{1}^{2} + 0.05\\,\\xi_{2}^{2}.$$\nTreat $\\hat{u}$ as the collocation approximation to $u$. Using the quadrature induced by these interpolation nodes (i.e., the tensor-product Gauss–Legendre rule of order $3$ in each dimension), compute the mean $\\mathbb{E}[u]$ and the variance $\\mathrm{Var}[u]$ of $u$ under the independent uniform distributions on $[-1,1]^{2}$. Express your final answers as exact rational numbers with no rounding. Provide both $\\mathbb{E}[u]$ and $\\mathrm{Var}[u]$ together as a single row matrix in the final answer.",
            "solution": "The user wants me to solve the following problem:\n<quote>\nConsider a two-parameter uncertainty model for a Transverse Electric (TE) plane-wave scattering problem in computational electromagnetics, in which the scalar quantity of interest $u$ (for example, a normalized backscatter amplitude extracted from the solution of Maxwell’s equations) depends on two standardized, independent random inputs $\\xi_{1}$ and $\\xi_{2}$, each uniformly distributed on $[-1,1]$. A non-intrusive stochastic collocation surrogate $\\hat{u}(\\xi_{1},\\xi_{2})$ is constructed by interpolating deterministic electromagnetic solves at tensor-product Gauss–Legendre nodes of order $3$ per dimension. The interpolation nodes and associated one-dimensional quadrature weights are\n$$\\xi^{(1)} = -\\sqrt{\\frac{3}{5}},\\quad \\xi^{(2)} = 0,\\quad \\xi^{(3)} = \\sqrt{\\frac{3}{5}},\\qquad w^{(1)} = \\frac{5}{9},\\quad w^{(2)} = \\frac{8}{9},\\quad w^{(3)} = \\frac{5}{9}.$$\nThe resulting surrogate has the form\n$$\\hat{u}(\\xi_{1},\\xi_{2}) = 1.2 + 0.4\\,\\xi_{1} - 0.3\\,\\xi_{2} + 0.25\\,\\xi_{1}\\xi_{2} + 0.1\\,\\xi_{1}^{2} + 0.05\\,\\xi_{2}^{2}.$$\nTreat $\\hat{u}$ as the collocation approximation to $u$. Using the quadrature induced by these interpolation nodes (i.e., the tensor-product Gauss–Legendre rule of order $3$ in each dimension), compute the mean $\\mathbb{E}[u]$ and the variance $\\mathrm{Var}[u]$ of $u$ under the independent uniform distributions on $[-1,1]^{2}$. Express your final answers as exact rational numbers with no rounding. Provide both $\\mathbb{E}[u]$ and $\\mathrm{Var}[u]$ together as a single row matrix in the final answer.\n</quote>\n\n### Step 1: Extract Givens\n-   **Quantity of Interest**: A scalar $u$ approximated by a surrogate model $\\hat{u}(\\xi_1, \\xi_2)$.\n-   **Random Inputs**: $\\xi_1$ and $\\xi_2$ are independent random variables, each uniformly distributed on the interval $[-1, 1]$.\n-   **Surrogate Model**: $\\hat{u}(\\xi_1, \\xi_2) = 1.2 + 0.4\\,\\xi_1 - 0.3\\,\\xi_2 + 0.25\\,\\xi_1\\xi_2 + 0.1\\,\\xi_1^2 + 0.05\\,\\xi_2^2$.\n-   **Quadrature Rule**: A tensor-product Gauss-Legendre rule of order $3$ per dimension.\n-   **1D Nodes**: $\\xi^{(1)} = -\\sqrt{3/5}$, $\\xi^{(2)} = 0$, $\\xi^{(3)} = \\sqrt{3/5}$.\n-   **1D Weights**: $w^{(1)} = 5/9$, $w^{(2)} = 8/9$, $w^{(3)} = 5/9$.\n-   **Task**: Compute the mean $\\mathbb{E}[u]$ and variance $\\mathrm{Var}[u]$, approximated by applying the specified quadrature rule to the surrogate $\\hat{u}$. The results must be exact rational numbers.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It describes a standard application of stochastic collocation for uncertainty quantification in computational science. The provided polynomial surrogate is a common outcome of such a method. The nodes and weights correspond to the standard $3$-point Gauss-Legendre quadrature. The task to compute the mean and variance is well-defined. The problem is self-contained and free of contradictions or ambiguities. No invalidating flaws are identified.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution\nThe problem requires the computation of the mean $\\mathbb{E}[u]$ and variance $\\mathrm{Var}[u]$ using the surrogate model $\\hat{u}(\\xi_1, \\xi_2)$ and a specific numerical quadrature rule. We will compute the mean $\\mathbb{E}[\\hat{u}]$ and variance $\\mathrm{Var}[\\hat{u}]$ as the approximations for the true quantities. The random variables $\\xi_1$ and $\\xi_2$ are independent and uniformly distributed on $[-1, 1]$, so their joint probability density function (PDF) is $p(\\xi_1, \\xi_2) = p(\\xi_1)p(\\xi_2) = \\frac{1}{2} \\cdot \\frac{1}{2} = \\frac{1}{4}$ for $(\\xi_1, \\xi_2) \\in [-1, 1]^2$.\n\nThe expected value of a function $f(\\xi_1, \\xi_2)$ is given by the integral:\n$$ \\mathbb{E}[f] = \\int_{-1}^{1}\\int_{-1}^{1} f(\\xi_1, \\xi_2) p(\\xi_1, \\xi_2) \\,d\\xi_1 d\\xi_2 = \\frac{1}{4} \\int_{-1}^{1}\\int_{-1}^{1} f(\\xi_1, \\xi_2) \\,d\\xi_1 d\\xi_2 $$\nThe problem specifies that this integral should be evaluated using a tensor-product $3$-point Gauss-Legendre quadrature rule. The quadrature approximation of the integral is:\n$$ \\int_{-1}^{1}\\int_{-1}^{1} f(\\xi_1, \\xi_2) \\,d\\xi_1 d\\xi_2 \\approx \\sum_{i=1}^{3}\\sum_{j=1}^{3} w^{(i)}w^{(j)} f(\\xi^{(i)}, \\xi^{(j)}) $$\nA $1$-dimensional Gauss-Legendre quadrature rule with $n=3$ points is exact for polynomials of degree up to $2n-1 = 2(3)-1 = 5$. The tensor-product rule is exact for polynomials $\\xi_1^p \\xi_2^q$ where $p \\le 5$ and $q \\le 5$.\n\nThe surrogate model $\\hat{u}(\\xi_1, \\xi_2)$ is a polynomial with maximum degree $2$ in $\\xi_1$ and maximum degree $2$ in $\\xi_2$. Therefore, the $3$-point Gauss-Legendre quadrature rule will compute the integral $\\int_{-1}^{1}\\int_{-1}^{1} \\hat{u}(\\xi_1, \\xi_2) \\,d\\xi_1 d\\xi_2$ exactly.\nSimilarly, the variance calculation requires $\\mathbb{E}[\\hat{u}^2]$. The function $\\hat{u}^2$ is a polynomial with maximum degree $4$ in each variable ($\\xi_1^2 \\cdot \\xi_1^2 = \\xi_1^4$). Since $4 < 5$, the quadrature rule is also exact for $\\int_{-1}^{1}\\int_{-1}^{1} \\hat{u}(\\xi_1, \\xi_2)^2 \\,d\\xi_1 d\\xi_2$.\nConsequently, we can compute the exact mean and variance of $\\hat{u}$ by direct integration, which is equivalent to applying the specified quadrature.\n\nFirst, we convert the coefficients of $\\hat{u}$ to rational numbers:\n- $1.2 = \\frac{12}{10} = \\frac{6}{5}$\n- $0.4 = \\frac{4}{10} = \\frac{2}{5}$\n- $-0.3 = -\\frac{3}{10}$\n- $0.25 = \\frac{1}{4}$\n- $0.1 = \\frac{1}{10}$\n- $0.05 = \\frac{1}{20}$\nSo, $\\hat{u}(\\xi_1, \\xi_2) = \\frac{6}{5} + \\frac{2}{5}\\xi_1 - \\frac{3}{10}\\xi_2 + \\frac{1}{4}\\xi_1\\xi_2 + \\frac{1}{10}\\xi_1^2 + \\frac{1}{20}\\xi_2^2$.\n\n**1. Computation of the Mean $\\mathbb{E}[\\hat{u}]$**\nWe use the linearity of expectation and the fact that for an integer $k>0$, $\\mathbb{E}[\\xi_i^k] = \\frac{1}{2}\\int_{-1}^{1} x^k dx$. This integral is $0$ for odd $k$ and $\\frac{1}{k+1}$ for even $k$.\n$$ \\mathbb{E}[\\hat{u}] = \\mathbb{E}\\left[\\frac{6}{5} + \\frac{2}{5}\\xi_1 - \\frac{3}{10}\\xi_2 + \\frac{1}{4}\\xi_1\\xi_2 + \\frac{1}{10}\\xi_1^2 + \\frac{1}{20}\\xi_2^2\\right] $$\n$$ \\mathbb{E}[\\hat{u}] = \\frac{6}{5} + \\frac{2}{5}\\mathbb{E}[\\xi_1] - \\frac{3}{10}\\mathbb{E}[\\xi_2] + \\frac{1}{4}\\mathbb{E}[\\xi_1]\\mathbb{E}[\\xi_2] + \\frac{1}{10}\\mathbb{E}[\\xi_1^2] + \\frac{1}{20}\\mathbb{E}[\\xi_2^2] $$\nSince $\\mathbb{E}[\\xi_1] = \\mathbb{E}[\\xi_2] = 0$, the terms with odd powers vanish.\n$$ \\mathbb{E}[\\xi_1^2] = \\mathbb{E}[\\xi_2^2] = \\frac{1}{2}\\int_{-1}^{1} x^2 dx = \\frac{1}{2} \\left[\\frac{x^3}{3}\\right]_{-1}^{1} = \\frac{1}{2}\\left(\\frac{1}{3} - \\frac{-1}{3}\\right) = \\frac{1}{3} $$\n$$ \\mathbb{E}[\\hat{u}] = \\frac{6}{5} + \\frac{1}{10}\\left(\\frac{1}{3}\\right) + \\frac{1}{20}\\left(\\frac{1}{3}\\right) = \\frac{6}{5} + \\frac{1}{30} + \\frac{1}{60} = \\frac{72+2+1}{60} = \\frac{75}{60} = \\frac{5}{4} $$\n\n**2. Computation of the Variance $\\mathrm{Var}[\\hat{u}]$**\nThe variance is given by $\\mathrm{Var}[\\hat{u}] = \\mathbb{E}[\\hat{u}^2] - (\\mathbb{E}[\\hat{u}])^2$. We need to compute $\\mathbb{E}[\\hat{u}^2]$.\n$$ \\hat{u}^2 = \\left(\\frac{6}{5} + \\frac{2}{5}\\xi_1 - \\frac{3}{10}\\xi_2 + \\frac{1}{4}\\xi_1\\xi_2 + \\frac{1}{10}\\xi_1^2 + \\frac{1}{20}\\xi_2^2\\right)^2 $$\nWhen taking the expectation, only terms with even powers of both $\\xi_1$ and $\\xi_2$ will result in a non-zero value. Let's identify these terms from the expansion of $\\hat{u}^2$:\n$$ \\mathbb{E}[\\hat{u}^2] = \\mathbb{E} \\left[ \\left(\\frac{6}{5}\\right)^2 + \\left(\\frac{2}{5}\\xi_1\\right)^2 + \\left(-\\frac{3}{10}\\xi_2\\right)^2 + \\left(\\frac{1}{4}\\xi_1\\xi_2\\right)^2 + \\left(\\frac{1}{10}\\xi_1^2\\right)^2 + \\left(\\frac{1}{20}\\xi_2^2\\right)^2 \\right. $$\n$$ \\left. + 2\\left(\\frac{6}{5}\\right)\\left(\\frac{1}{10}\\xi_1^2\\right) + 2\\left(\\frac{6}{5}\\right)\\left(\\frac{1}{20}\\xi_2^2\\right) + 2\\left(\\frac{1}{10}\\xi_1^2\\right)\\left(\\frac{1}{20}\\xi_2^2\\right) \\right] $$\nWe use the following expectations:\n$\\mathbb{E}[\\xi_i^2] = 1/3$, $\\mathbb{E}[\\xi_i^4] = \\frac{1}{2}\\int_{-1}^{1} x^4 dx = \\frac{1}{5}$, $\\mathbb{E}[\\xi_1^2\\xi_2^2] = \\mathbb{E}[\\xi_1^2]\\mathbb{E}[\\xi_2^2] = (\\frac{1}{3})(\\frac{1}{3}) = \\frac{1}{9}$.\nSubstituting these values:\n$$ \\mathbb{E}[\\hat{u}^2] = \\left(\\frac{6}{5}\\right)^2 + \\left(\\frac{2}{5}\\right)^2\\mathbb{E}[\\xi_1^2] + \\left(\\frac{3}{10}\\right)^2\\mathbb{E}[\\xi_2^2] + \\left(\\frac{1}{4}\\right)^2\\mathbb{E}[\\xi_1^2\\xi_2^2] + \\left(\\frac{1}{10}\\right)^2\\mathbb{E}[\\xi_1^4] + \\left(\\frac{1}{20}\\right)^2\\mathbb{E}[\\xi_2^4] $$\n$$ + 2\\frac{6}{5}\\frac{1}{10}\\mathbb{E}[\\xi_1^2] + 2\\frac{6}{5}\\frac{1}{20}\\mathbb{E}[\\xi_2^2] + 2\\frac{1}{10}\\frac{1}{20}\\mathbb{E}[\\xi_1^2\\xi_2^2] $$\n$$ \\mathbb{E}[\\hat{u}^2] = \\frac{36}{25} + \\frac{4}{25}\\left(\\frac{1}{3}\\right) + \\frac{9}{100}\\left(\\frac{1}{3}\\right) + \\frac{1}{16}\\left(\\frac{1}{9}\\right) + \\frac{1}{100}\\left(\\frac{1}{5}\\right) + \\frac{1}{400}\\left(\\frac{1}{5}\\right) $$\n$$ + \\frac{12}{50}\\left(\\frac{1}{3}\\right) + \\frac{12}{100}\\left(\\frac{1}{3}\\right) + \\frac{2}{200}\\left(\\frac{1}{9}\\right) $$\n$$ \\mathbb{E}[\\hat{u}^2] = \\frac{36}{25} + \\frac{4}{75} + \\frac{3}{100} + \\frac{1}{144} + \\frac{1}{500} + \\frac{1}{2000} + \\frac{4}{50} + \\frac{4}{100} + \\frac{1}{900} $$\n$$ \\mathbb{E}[\\hat{u}^2] = \\frac{36}{25} + \\frac{4}{75} + \\frac{3}{100} + \\frac{1}{144} + \\frac{1}{500} + \\frac{1}{2000} + \\frac{2}{25} + \\frac{1}{25} + \\frac{1}{900} $$\nCombining terms with same denominators:\n$$ \\mathbb{E}[\\hat{u}^2] = \\left(\\frac{36+2+1}{25}\\right) + \\frac{4}{75} + \\frac{3}{100} + \\frac{1}{144} + \\left(\\frac{4}{2000}+\\frac{1}{2000}\\right) + \\frac{1}{900} $$\n$$ \\mathbb{E}[\\hat{u}^2] = \\frac{39}{25} + \\frac{4}{75} + \\frac{3}{100} + \\frac{1}{144} + \\frac{5}{2000} + \\frac{1}{900} = \\frac{39}{25} + \\frac{4}{75} + \\frac{3}{100} + \\frac{1}{144} + \\frac{1}{400} + \\frac{1}{900}$$\nThe least common multiple of the denominators $(25, 75, 100, 144, 400, 900)$ is $3600$.\n$$ \\mathbb{E}[\\hat{u}^2] = \\frac{39 \\cdot 144}{3600} + \\frac{4 \\cdot 48}{3600} + \\frac{3 \\cdot 36}{3600} + \\frac{1 \\cdot 25}{3600} + \\frac{1 \\cdot 9}{3600} + \\frac{1 \\cdot 4}{3600} $$\n$$ \\mathbb{E}[\\hat{u}^2] = \\frac{5616 + 192 + 108 + 25 + 9 + 4}{3600} = \\frac{5954}{3600} = \\frac{2977}{1800} $$\nNow we compute the variance:\n$$ \\mathrm{Var}[\\hat{u}] = \\mathbb{E}[\\hat{u}^2] - (\\mathbb{E}[\\hat{u}])^2 = \\frac{2977}{1800} - \\left(\\frac{5}{4}\\right)^2 = \\frac{2977}{1800} - \\frac{25}{16} $$\nThe least common multiple of $1800 = 2^3 \\cdot 3^2 \\cdot 5^2$ and $16 = 2^4$ is $2^4 \\cdot 3^2 \\cdot 5^2 = 3600$.\n$$ \\mathrm{Var}[\\hat{u}] = \\frac{2977 \\cdot 2}{3600} - \\frac{25 \\cdot 225}{3600} = \\frac{5954 - 5625}{3600} = \\frac{329}{3600} $$\n\nThe computed mean is $\\mathbb{E}[u] \\approx 5/4$ and the variance is $\\mathrm{Var}[u] \\approx 329/3600$.",
            "answer": "$$ \\boxed{\\begin{pmatrix} \\frac{5}{4} & \\frac{329}{3600} \\end{pmatrix}} $$"
        },
        {
            "introduction": "This comprehensive exercise guides you through a complete uncertainty quantification workflow, from physical modeling to numerical implementation and analysis. You will build an equivalent circuit model for an antenna and apply the stochastic collocation method to assess the impact of random physical parameters on its input impedance. This practice not only reinforces the core concepts but also exposes you to practical challenges, such as handling near-singular behavior in the parameter space .",
            "id": "3350734",
            "problem": "Consider a thin, center-fed planar antenna over a homogeneous substrate, excited at angular frequency $\\,\\omega\\,$. The input port is realized by a narrow feed gap of physical width $\\,g(\\xi_1)\\,$ between two conductors of effective overlapping area $\\,A\\,$, supported by a dielectric of relative permittivity $\\,\\varepsilon_r(\\xi_2)\\,$. The quantities $\\,\\xi_1\\,$ and $\\,\\xi_2\\,$ are independent standardized random variables with uniform distributions on the interval $\\,[-1,1]\\,$. The substrate’s absolute permittivity is $\\,\\varepsilon_0\\,\\varepsilon_r(\\xi_2)\\,$ where $\\,\\varepsilon_0\\,$ is the vacuum permittivity. The antenna radiates with a non-dispersive radiation resistance $\\,R_{\\mathrm{rad}}\\,$ and the local feed introduces a series inductance $\\,L_s\\,$. Work within the quasi-static lumped-element regime for the near-field at the feed, and assume a two-dimensional excitation in the $\\,x\\text{-}y\\,$ plane with negligible magnetic coupling beyond the feed inductance. Take the speed of light to be $\\,c\\,$, the electric field $\\,\\mathbf{E}\\,$, the magnetic field $\\,\\mathbf{H}\\,$, the electric flux density $\\,\\mathbf{D}\\,$, and the magnetic flux density $\\,\\mathbf{B}\\,$. Start from Maxwell’s equations $\\,\\nabla \\times \\mathbf{E} = -\\partial \\mathbf{B}/\\partial t\\,$ and $\\,\\nabla \\times \\mathbf{H} = \\mathbf{J} + \\partial \\mathbf{D}/\\partial t\\,$, the constitutive relation $\\,\\mathbf{D} = \\varepsilon \\mathbf{E}\\,$ with $\\,\\varepsilon = \\varepsilon_0 \\varepsilon_r\\,$, and the lumped-element limits implied by the telegrapher’s model to justify a reduced equivalent network that captures the port behavior. In this network, the radiation is represented by a resistance and the feed gap by a capacitor whose capacitance depends on $\\,\\varepsilon_r(\\xi_2)\\,$ and $\\,g(\\xi_1)\\,$ via an appropriate parallel-plate approximation. The port’s input impedance $\\,Z_{\\mathrm{in}}(\\boldsymbol{\\xi})\\,$ is the impedance seen looking into the port when the feed inductance is placed in series with the parallel combination of the radiation resistance and the gap capacitor. Because the gap capacitance grows unbounded as $\\,g(\\xi_1) \\to 0\\,$, the admittance of the parallel branch becomes large, which can produce non-smooth behavior in $\\,Z_{\\mathrm{in}}(\\boldsymbol{\\xi})\\,$ as a function of $\\,\\boldsymbol{\\xi} = (\\xi_1,\\xi_2)\\,$.\n\nYour task is to use stochastic collocation to quantify uncertainty in the magnitude of the input impedance $\\,|Z_{\\mathrm{in}}(\\boldsymbol{\\xi})|\\,$ induced by the random feed gap $\\,g(\\xi_1)\\,$ and substrate relative permittivity $\\,\\varepsilon_r(\\xi_2)\\,$, and to probe the effect of the near-singular capacitive behavior as $\\,g(\\xi_1) \\to 0\\,$. Model assumptions must remain within the quasi-static and linear regime. The computation must be performed using tensor-product Gauss–Legendre collocation points for the two independent uniform random variables. Expectations should be approximated by weighted sums over these points. Use an independent Quasi-Monte Carlo (QMC) baseline with a Sobol sequence to assess the collocation error for each test case.\n\nDefine the following deterministic parameters, all physically plausible and scientifically consistent:\n- Frequency $\\,f = 3\\times 10^9\\,$ in hertz (Hz), so $\\,\\omega = 2\\pi f\\,$ in radians per second.\n- Vacuum permittivity $\\,\\varepsilon_0 = 8.854187817\\times 10^{-12}\\,$ in farads per meter (F/m).\n- Effective overlapping area $\\,A = 1\\times 10^{-4}\\,$ in square meters (m$^2$).\n- Radiation resistance $\\,R_{\\mathrm{rad}} = 50\\,$ in ohms ($\\Omega$).\n- Series feed inductance $\\,L_s = 1\\times 10^{-9}\\,$ in henries (H).\n\nMapping from standardized random variables to physical parameters must be affine:\n- For any interval $\\,[a,b]\\,$ and standardized $\\,\\xi \\in [-1,1]\\,$, the physical value is $\\,x(\\xi) = \\frac{a+b}{2} + \\frac{b-a}{2}\\,\\xi\\,$.\n- Use this mapping to obtain $\\,g(\\xi_1)\\,$ and $\\,\\varepsilon_r(\\xi_2)\\,$ from their respective ranges.\n\nThe stochastic collocation must employ $\\,n\\,$ Gauss–Legendre points per dimension. If $\\,\\{(\\xi_{1,i},w_{1,i})\\}_{i=1}^n\\,$ and $\\,\\{(\\xi_{2,j},w_{2,j})\\}_{j=1}^n\\,$ are the one-dimensional nodes and weights on $\\,[-1,1]\\,$, then the two-dimensional tensor-product rule approximates the expectation of any square-integrable quantity $\\,u(\\xi_1,\\xi_2)\\,$ under the independent uniform distribution on the mapped rectangles by\n$$\n\\mathbb{E}[u] \\approx \\sum_{i=1}^n \\sum_{j=1}^n \\left(\\frac{w_{1,i}}{2}\\right)\\left(\\frac{w_{2,j}}{2}\\right) u\\!\\big(\\xi_{1,i},\\xi_{2,j}\\big),\n$$\nand similarly for $\\,\\mathbb{E}[u^2]\\,$ to obtain the variance $\\,\\mathrm{Var}[u] = \\mathbb{E}[u^2] - (\\mathbb{E}[u])^2\\,$. The quantity of interest is $\\,u(\\xi_1,\\xi_2) = |Z_{\\mathrm{in}}(\\xi_1,\\xi_2)|\\,$, expressed in ohms. The baseline QMC estimate must use a Sobol sequence in two dimensions over the physical parameter rectangles, transformed via the same affine mapping, with $\\,N\\,$ samples.\n\nConstruct the input impedance $\\,Z_{\\mathrm{in}}(\\boldsymbol{\\xi})\\,$ from first principles:\n- Use $\\,\\mathbf{D} = \\varepsilon \\mathbf{E}\\,$ and the parallel-plate approximation to argue that the gap capacitance satisfies a proportionality of the form $\\,C_{\\mathrm{gap}}(\\varepsilon_r,g) \\propto \\varepsilon_0\\,\\varepsilon_r\\,A/g\\,$.\n- Combine the radiation resistance and the gap capacitance in parallel and the feed inductance in series to obtain the port’s $\\,Z_{\\mathrm{in}}(\\boldsymbol{\\xi})\\,$.\n- Use $\\,u(\\xi_1,\\xi_2) = |Z_{\\mathrm{in}}(\\xi_1,\\xi_2)|\\,$ as the scalar observable.\n\nTest Suite. Evaluate four cases to examine both a typical situation and near-singular behavior:\n- Case $\\,1\\,$ (happy path): $\\,g \\in [10^{-4},5\\times 10^{-4}]\\,$ in meters, $\\,\\varepsilon_r \\in [2,4]\\,$ dimensionless, collocation order $\\,n=5\\,$, QMC samples $\\,N=32768\\,$.\n- Case $\\,2\\,$ (near-singular, small gap): $\\,g \\in [10^{-6},10^{-4}]\\,$ in meters, $\\,\\varepsilon_r \\in [2,4]\\,$ dimensionless, collocation order $\\,n=5\\,$, QMC samples $\\,N=32768\\,$.\n- Case $\\,3\\,$ (higher order near-singular): $\\,g \\in [10^{-6},10^{-4}]\\,$ in meters, $\\,\\varepsilon_r \\in [2,4]\\,$ dimensionless, collocation order $\\,n=9\\,$, QMC samples $\\,N=32768\\,$.\n- Case $\\,4\\,$ (narrow variability): $\\,g \\in [5\\times 10^{-5},6\\times 10^{-5}]\\,$ in meters, $\\,\\varepsilon_r \\in [2.4,2.6]\\,$ dimensionless, collocation order $\\,n=3\\,$, QMC samples $\\,N=32768\\,$.\n\nFor each case, compute using stochastic collocation:\n- The collocation estimate of $\\,\\mathbb{E}[|Z_{\\mathrm{in}}|]\\,$ in ohms.\n- The collocation estimate of $\\,\\mathrm{Var}(|Z_{\\mathrm{in}}|)\\,$ in ohms squared.\n\nAlso compute using QMC:\n- The baseline estimates of $\\,\\mathbb{E}[|Z_{\\mathrm{in}}|]\\,$ and $\\,\\mathrm{Var}(|Z_{\\mathrm{in}}|)\\,$, in the same units.\n\nQuantify the absolute errors:\n- $\\,e_{\\mu} = \\big|\\mathbb{E}_{\\mathrm{coll}}[|Z_{\\mathrm{in}}|] - \\mathbb{E}_{\\mathrm{QMC}}[|Z_{\\mathrm{in}}|]\\big|\\,$ in ohms.\n- $\\,e_{\\sigma^2} = \\big|\\mathrm{Var}_{\\mathrm{coll}}(|Z_{\\mathrm{in}}|) - \\mathrm{Var}_{\\mathrm{QMC}}(|Z_{\\mathrm{in}}|)\\big|\\,$ in ohms squared.\n\nYour program should produce a single line of output containing, for the four cases in order, the collocation mean, collocation variance, absolute mean error, and absolute variance error, as a comma-separated list enclosed in square brackets (for example, `[m_1,v_1,e_mu_1,e_sigma_sq_1,m_2,v_2,e_mu_2,e_sigma_sq_2,m_3,v_3,e_mu_3,e_sigma_sq_3,m_4,v_4,e_mu_4,e_sigma_sq_4]`). All values must be expressed in ohms or ohms squared as appropriate, rounded by the default floating-point representation of the programming language runtime.",
            "solution": "We begin with the macroscopic Maxwell equations $\\,\\nabla \\times \\mathbf{E} = -\\partial \\mathbf{B}/\\partial t\\,$, $\\,\\nabla \\times \\mathbf{H} = \\mathbf{J} + \\partial \\mathbf{D}/\\partial t\\,$, and the constitutive relations $\\,\\mathbf{D} = \\varepsilon \\mathbf{E}\\,$, $\\,\\mathbf{B} = \\mu \\mathbf{H}\\,$. In the quasi-static regime at the feed gap, the displacement current dominates over radiation within the small separation $\\,g\\,$, and the energy storage is primarily electric in the gap. With $\\,\\varepsilon = \\varepsilon_0 \\varepsilon_r\\,$ and gap area $\\,A\\,$, approximating the geometry by a parallel-plate capacitor yields a capacitance scaling\n$$\nC_{\\mathrm{gap}}(\\varepsilon_r,g) \\approx \\frac{\\varepsilon_0\\,\\varepsilon_r\\,A}{g},\n$$\nderived from $\\,Q = \\int_S \\mathbf{D}\\cdot\\mathrm{d}\\mathbf{S} = \\varepsilon \\int_S \\mathbf{E}\\cdot\\mathrm{d}\\mathbf{S}\\,$ and $\\,V = \\int \\mathbf{E}\\cdot \\mathrm{d}\\mathbf{\\ell}\\,$ across the gap, where the field is considered approximately uniform. This relation respects the limit $\\,C_{\\mathrm{gap}}\\to \\infty\\,$ as $\\,g\\to 0\\,$, reflecting the capacitive singularity in admittance $\\,Y_C = j\\omega C_{\\mathrm{gap}}\\,$.\n\nThe overall port can be represented by a lumped network whose series part is the feed inductance $\\,L_s\\,$ (accounting for magnetic energy storage near the feed line), and whose shunt part is the radiation resistance $\\,R_{\\mathrm{rad}}\\,$ in parallel with the gap capacitance $\\,C_{\\mathrm{gap}}(\\varepsilon_r,g)\\,$. This reduction follows from the telegrapher’s model applied locally to the feed region and the separation of radiative loss (resistive) from reactive storage (capacitive and inductive), consistent with linear time-harmonic behavior $\\,e^{j\\omega t}\\,$. The shunt branch admittance is\n$$\nY_{\\mathrm{shunt}}(\\varepsilon_r,g) = \\frac{1}{R_{\\mathrm{rad}}} + j\\omega C_{\\mathrm{gap}}(\\varepsilon_r,g),\n$$\nand its impedance is $\\,Z_{\\mathrm{shunt}} = 1/Y_{\\mathrm{shunt}}\\,$. The input impedance seen looking into the port is then the series sum\n$$\nZ_{\\mathrm{in}}(\\varepsilon_r,g) = Z_{\\mathrm{shunt}}(\\varepsilon_r,g) + j\\omega L_s.\n$$\nThe observable of interest is the magnitude\n$$\nu(\\varepsilon_r,g) = \\left|Z_{\\mathrm{in}}(\\varepsilon_r,g)\\right|.\n$$\n\nUncertainty stems from the random feed gap $\\,g(\\xi_1)\\,$ and dielectric $\\,\\varepsilon_r(\\xi_2)\\,$, with $\\,\\xi_1,\\xi_2 \\sim \\mathrm{Uniform}([-1,1])\\,$ and independent. The affine mapping $\\,x(\\xi) = \\frac{a+b}{2} + \\frac{b-a}{2}\\,\\xi\\,$ transforms standardized variables to physical parameters on $\\,[a,b]\\,$. For each test case, the ranges for $\\,g\\,$ and $\\,\\varepsilon_r\\,$ define rectangles in parameter space, and the joint density factorizes as the product of uniform densities.\n\nStochastic collocation for independent uniform variables employs tensor-product Gauss–Legendre points on $\\,[-1,1]\\,$. For a one-dimensional rule of order $\\,n\\,$ with nodes $\\,\\{\\xi_i\\}_{i=1}^n\\,$ and weights $\\,\\{w_i\\}_{i=1}^n\\,$, we approximate integrals by $\\,\\int_{-1}^1 f(\\xi)\\,\\mathrm{d}\\xi \\approx \\sum_i w_i f(\\xi_i)\\,$. The expectation with respect to the uniform distribution on $\\,[-1,1]\\,$ is $\\,\\mathbb{E}[f] = \\frac{1}{2}\\int_{-1}^1 f(\\xi)\\,\\mathrm{d}\\xi\\,$, yielding weights $\\,w_i/2\\,$. In two dimensions, the tensor-product expectation becomes\n$$\n\\mathbb{E}[u] \\approx \\sum_{i=1}^n \\sum_{j=1}^n \\left(\\frac{w_{1,i}}{2}\\right)\\left(\\frac{w_{2,j}}{2}\\right) u\\!\\big(\\xi_{1,i},\\xi_{2,j}\\big),\n$$\nwith $\\,u(\\xi_{1,i},\\xi_{2,j}) = |Z_{\\mathrm{in}}(\\varepsilon_r(\\xi_{2,j}),g(\\xi_{1,i}))|\\,$. For the variance, we use $\\,\\mathrm{Var}(u) = \\mathbb{E}[u^2] - (\\mathbb{E}[u])^2\\,$ and apply the same rule to $\\,u^2\\,$.\n\nTo probe non-smoothness, note that as $\\,g \\to 0\\,$, $\\,C_{\\mathrm{gap}} \\to \\infty\\,$ and $\\,Y_{\\mathrm{shunt}} \\to \\infty\\,$, so $\\,Z_{\\mathrm{shunt}} \\to 0\\,$. Consequently, $\\,Z_{\\mathrm{in}} \\to j\\omega L_s\\,$, a finite limit. However, the gradient $\\,\\partial Z_{\\mathrm{in}}/\\partial g\\,$ becomes large in magnitude because $\\,\\partial C_{\\mathrm{gap}}/\\partial g \\sim -\\varepsilon_0 \\varepsilon_r A/g^2\\,$, introducing steep variation and reduced smoothness as a function of $\\,g\\,$. Polynomial-based collocation (or equivalently, spectral interpolation) converges more slowly for such near-singular behavior, compared to the smoother regimes with larger $\\,g\\,$.\n\nWe implement a Quasi-Monte Carlo (QMC) baseline with a Sobol sequence over the physical rectangles for each case. Given $\\,N\\,$ two-dimensional points $\\,\\{\\mathbf{u}_k\\}_{k=1}^N\\,$ in $\\,[0,1]^2\\,$, we map them affinely to the rectangles for $\\,g\\,$ and $\\,\\varepsilon_r\\,$, evaluate $\\,u_k = |Z_{\\mathrm{in}}(\\varepsilon_r^{(k)},g^{(k)})|\\,$, and compute $\\,\\widehat{\\mathbb{E}}[u] = \\frac{1}{N}\\sum_k u_k\\,$ and $\\,\\widehat{\\mathrm{Var}}(u) = \\frac{1}{N}\\sum_k u_k^2 - \\left(\\frac{1}{N}\\sum_k u_k\\right)^2\\,$.\n\nFor the four test cases, we carry out:\n- Case $\\,1\\,$: Moderate $\\,g\\,$ away from $\\,0\\,$, expect collocation to agree well with QMC (small $\\,e_{\\mu}\\,$ and $\\,e_{\\sigma^2}\\,$) for $\\,n=5\\,$.\n- Case $\\,2\\,$: Near-singular $\\,g\\,$ range with $\\,n=5\\,$, expect larger errors due to reduced smoothness in the integrand with respect to $\\,\\xi_1\\,$.\n- Case $\\,3\\,$: Same near-singular range but higher order $\\,n=9\\,$, expect reduced errors compared to Case $\\,2\\,$, illustrating improved resolution of steep variation.\n- Case $\\,4\\,$: Narrow ranges for both $\\,g\\,$ and $\\,\\varepsilon_r\\,$, expect small variability and small absolute errors even with $\\,n=3\\,$.\n\nAlgorithmic steps:\n- Compute $\\,\\omega = 2\\pi f\\,$, and use $\\,\\varepsilon_0\\,$, $\\,A\\,$, $\\,R_{\\mathrm{rad}}\\,$, and $\\,L_s\\,$ as specified.\n- For each case, obtain $\\,n\\,$ Gauss–Legendre nodes and weights per dimension on $\\,[-1,1]\\,$, map to $\\,g\\,$ and $\\,\\varepsilon_r\\,$ via the affine transformation, and accumulate\n$$\n\\mu_{\\mathrm{coll}} \\approx \\sum_{i,j} \\frac{w_{1,i} w_{2,j}}{4}\\, u\\!\\big(\\xi_{1,i},\\xi_{2,j}\\big), \\quad\nm_{2,\\mathrm{coll}} \\approx \\sum_{i,j} \\frac{w_{1,i} w_{2,j}}{4}\\, u\\!\\big(\\xi_{1,i},\\xi_{2,j}\\big)^2,\n$$\nthen $\\,\\sigma^2_{\\mathrm{coll}} = m_{2,\\mathrm{coll}} - \\mu_{\\mathrm{coll}}^2\\,$.\n- Generate $\\,N\\,$ Sobol points $\\,\\mathbf{u}_k \\in [0,1]^2\\,$, map to the physical rectangles, evaluate $\\,u_k\\,$, and compute $\\,\\mu_{\\mathrm{QMC}}\\,$ and $\\,\\sigma^2_{\\mathrm{QMC}}\\,$.\n- Report $\\,\\mu_{\\mathrm{coll}}\\,$, $\\,\\sigma^2_{\\mathrm{coll}}\\,$, $\\,e_{\\mu} = |\\mu_{\\mathrm{coll}} - \\mu_{\\mathrm{QMC}}|\\,$, and $\\,e_{\\sigma^2} = |\\sigma^2_{\\mathrm{coll}} - \\sigma^2_{\\mathrm{QMC}}|\\,$ as floats.\n\nAll quantities $\\,\\mu_{\\mathrm{coll}}\\,$ and $\\,\\mu_{\\mathrm{QMC}}\\,$ are in ohms, and $\\,\\sigma^2_{\\mathrm{coll}}\\,$ and $\\,\\sigma^2_{\\mathrm{QMC}}\\,$ are in ohms squared. The final printed output is a single line with a comma-separated list enclosed in brackets, containing $\\,16\\,$ numbers in the order specified in the problem statement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom numpy.polynomial.legendre import leggauss\nfrom scipy.stats import qmc\n\n# Physical constants and model parameters\nf = 3.0e9  # Hz\nomega = 2.0 * np.pi * f  # rad/s\neps0 = 8.854187817e-12  # F/m\nA = 1.0e-4  # m^2\nR_rad = 50.0  # ohms\nL_s = 1.0e-9  # H\n\ndef map_affine(xi, a, b):\n    \"\"\"Affine map from standardized xi in [-1,1] to physical [a,b].\"\"\"\n    return 0.5 * (a + b) + 0.5 * (b - a) * xi\n\ndef gap_capacitance(eps_r, g):\n    \"\"\"Parallel-plate approximation for gap capacitance.\"\"\"\n    return eps0 * eps_r * A / g\n\ndef Z_in(eps_r, g):\n    \"\"\"Compute input impedance for given eps_r and g using the reduced network.\"\"\"\n    Cgap = gap_capacitance(eps_r, g)\n    Y_shunt = (1.0 / R_rad) + 1j * omega * Cgap\n    Z_shunt = 1.0 / Y_shunt\n    Z = Z_shunt + 1j * omega * L_s\n    return Z\n\ndef collocation_stats(g_range, eps_range, order):\n    \"\"\"Compute collocation-based mean and variance of |Z_in| using tensor-product Gauss-Legendre.\"\"\"\n    # 1D Gauss-Legendre nodes and weights on [-1,1]\n    xi1, w1 = leggauss(order)\n    xi2, w2 = leggauss(order)\n    # Tensor-product evaluation\n    mean = 0.0\n    m2 = 0.0\n    for i in range(order):\n        gi = map_affine(xi1[i], g_range[0], g_range[1])\n        for j in range(order):\n            epsj = map_affine(xi2[j], eps_range[0], eps_range[1])\n            val = np.abs(Z_in(epsj, gi))\n            weight = (w1[i] * w2[j]) / 4.0  # product of uniform expectation weights\n            mean += weight * val\n            m2 += weight * (val * val)\n    var = m2 - mean * mean\n    return mean, var\n\ndef qmc_stats(g_range, eps_range, n_samples):\n    \"\"\"Compute QMC Sobol-based mean and variance of |Z_in|.\"\"\"\n    sobol = qmc.Sobol(d=2, scramble=False)\n    # Generate points in [0,1)^2\n    pts = sobol.random(n=n_samples)\n    # Map to physical ranges\n    g = g_range[0] + (g_range[1] - g_range[0]) * pts[:, 0]\n    epsr = eps_range[0] + (eps_range[1] - eps_range[0]) * pts[:, 1]\n    vals = np.abs(Z_in(epsr, g))\n    mean = float(np.mean(vals))\n    var = float(np.var(vals, ddof=0))\n    return mean, var\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (g_min, g_max, eps_min, eps_max, collocation_order, qmc_samples)\n    test_cases = [\n        (1.0e-4, 5.0e-4, 2.0, 4.0, 5, 32768),          # Case 1: happy path\n        (1.0e-6, 1.0e-4, 2.0, 4.0, 5, 32768),          # Case 2: near-singular, small gap\n        (1.0e-6, 1.0e-4, 2.0, 4.0, 9, 32768),          # Case 3: higher order near-singular\n        (5.0e-5, 6.0e-5, 2.4, 2.6, 3, 32768),          # Case 4: narrow variability\n    ]\n\n    results = []\n    for case in test_cases:\n        gmin, gmax, epsmin, epsmax, order, n_qmc = case\n        g_range = (gmin, gmax)\n        eps_range = (epsmin, epsmax)\n        # Collocation estimates\n        m_coll, v_coll = collocation_stats(g_range, eps_range, order)\n        # QMC baseline\n        m_qmc, v_qmc = qmc_stats(g_range, eps_range, n_qmc)\n        # Errors\n        e_mean = abs(m_coll - m_qmc)\n        e_var = abs(v_coll - v_qmc)\n        # Append results in the required order\n        results.extend([m_coll, v_coll, e_mean, e_var])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}