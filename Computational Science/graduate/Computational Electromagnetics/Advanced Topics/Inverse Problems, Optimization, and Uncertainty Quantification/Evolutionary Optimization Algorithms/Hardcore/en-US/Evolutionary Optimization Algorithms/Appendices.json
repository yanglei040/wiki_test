{
    "hands_on_practices": [
        {
            "introduction": "The fitness function is the compass that guides an evolutionary search, and a faulty compass can lead the entire optimization astray. In computational electromagnetics, it is common for numerical artifacts, such as spurious reflections from simulation boundaries, to contaminate the field data and, consequently, the objective value. This exercise challenges you to design a robust fitness function by augmenting it with a penalty term that specifically targets and quantifies these artifacts, ensuring that the optimizer is guided by the true physical performance of the design rather than simulation inaccuracies .",
            "id": "3306079",
            "problem": "In a Finite-Difference Time-Domain (FDTD) simulation of a scattering structure embedded in a rectangular computational domain, the outer boundary is terminated by a Perfectly Matched Layer (PML). A parametric geometry is encoded by a vector of design variables $\\,\\boldsymbol{\\theta}\\,$ that modulates a spatially varying permittivity $\\,\\varepsilon(\\mathbf{x};\\boldsymbol{\\theta})\\,$ within a compact region strictly separated from the PML. A compactly supported current source $\\,\\mathbf{J}_{\\mathrm{s}}(\\mathbf{x},t)\\,$ drives the system from time $\\,t=0\\,$ to time $\\,t=\\tau_{\\mathrm{src}}\\,$, and the simulation runs until a fixed horizon $\\,t=T_{\\mathrm{end}}\\,$ using a common spatial grid and time step for all candidates $\\,\\boldsymbol{\\theta}\\,$. You wish to use an evolutionary algorithm to minimize a physical objective $\\,J_{\\mathrm{phys}}(\\boldsymbol{\\theta})\\,$, but you observe that late-time spurious reflections originating at the PML boundaries can contaminate the time-domain fields and thereby distort $\\,J_{\\mathrm{phys}}(\\boldsymbol{\\theta})\\,$ in a design-dependent manner. To robustify the fitness, you decide to augment $\\,J_{\\mathrm{phys}}(\\boldsymbol{\\theta})\\,$ with a penalty that measures late-time field energy near the PML. Let $\\,\\Omega_{\\mathrm{PML}}\\,$ denote a thin monitoring shell co-located with and entirely within the PML region, and let $\\,\\mathbf{E}_{\\mathrm{PML}}(t;\\mathbf{x})\\,$ denote the electric field restricted to $\\,\\Omega_{\\mathrm{PML}}\\,$. The window $[t_{1},t_{2}]$ is to be chosen to capture late-time artifacts while excluding direct-source transients. From first principles of electromagnetics and numerical stability considerations, select the most appropriate augmented fitness and the associated justification for how its construction yields consistent evaluation across different $\\,\\boldsymbol{\\theta}\\,$ under an evolutionary algorithm.\n\nWhich option is the most appropriate?\n\nA. Define\n$$\nJ_{\\mathrm{aug}}(\\boldsymbol{\\theta}) \\;=\\; J_{\\mathrm{phys}}(\\boldsymbol{\\theta}) \\;+\\; \\alpha \\,\\frac{\\displaystyle \\int_{t_{1}}^{t_{2}} \\int_{\\Omega_{\\mathrm{PML}}} \\|\\mathbf{E}_{\\mathrm{PML}}(t;\\mathbf{x})\\|^{2}\\,\\mathrm{d}\\mathbf{x}\\,\\mathrm{d}t}{\\displaystyle \\int_{0}^{T_{\\mathrm{end}}} \\int_{\\Omega_{\\mathrm{src}}} \\left|\\mathbf{J}_{\\mathrm{s}}(\\mathbf{x},t)\\cdot \\mathbf{E}(\\mathbf{x},t)\\right|\\,\\mathrm{d}\\mathbf{x}\\,\\mathrm{d}t},\n$$\nwith $\\,\\alpha>0\\,$ fixed, where $\\,\\Omega_{\\mathrm{src}}\\,$ is the compact source support. Choose $\\,t_{1}=\\tau_{\\mathrm{src}}+t_{\\mathrm{exit},\\max}+\\delta\\,$ and $\\,t_{2}=T_{\\mathrm{end}}\\,$, where $\\,t_{\\mathrm{exit},\\max}=D_{\\max}/v_{\\min}\\,$ is a conservative upper bound on the time for any wave packet to traverse from the source region to $\\,\\Omega_{\\mathrm{PML}}\\,$ given the known domain diameter $\\,D_{\\max}\\,$ and a lower bound $\\,v_{\\min}\\,$ on the phase velocity implied by material bounds across all feasible $\\,\\boldsymbol{\\theta}\\,$, and $\\,\\delta>0\\,$ is a small safety margin; these choices and the normalization are held fixed across all candidates $\\,\\boldsymbol{\\theta}\\,$.\n\nB. Define\n$$\nJ_{\\mathrm{aug}}(\\boldsymbol{\\theta}) \\;=\\; J_{\\mathrm{phys}}(\\boldsymbol{\\theta}) \\;+\\; \\alpha \\,\\int_{t_{1}(\\boldsymbol{\\theta})}^{t_{2}(\\boldsymbol{\\theta})} \\int_{\\Omega_{\\mathrm{PML}}} \\|\\mathbf{E}_{\\mathrm{PML}}(t;\\mathbf{x})\\|^{2}\\,\\mathrm{d}\\mathbf{x}\\,\\mathrm{d}t,\n$$\nwhere $\\,t_{1}(\\boldsymbol{\\theta})\\,$ is defined for each $\\,\\boldsymbol{\\theta}\\,$ as the earliest time at which the field magnitude at a single interior probe $\\,\\mathbf{x}_{0}\\,$ falls below a fixed threshold, and $\\,t_{2}(\\boldsymbol{\\theta})\\,$ is the first subsequent time the probe crosses the same threshold again. No normalization is applied.\n\nC. Define\n$$\nJ_{\\mathrm{aug}}(\\boldsymbol{\\theta}) \\;=\\; J_{\\mathrm{phys}}(\\boldsymbol{\\theta}) \\;+\\; \\alpha \\,\\int_{0}^{T_{\\mathrm{end}}} \\int_{\\Omega} \\|\\mathbf{E}(t;\\mathbf{x})\\|^{2}\\,\\mathrm{d}\\mathbf{x}\\,\\mathrm{d}t,\n$$\nwhere $\\,\\Omega\\,$ is the entire computational domain (including but not restricted to the PML). The window is the full simulation $[0,T_{\\mathrm{end}}]$ to capture all energy, since spurious reflections are part of the total.\n\nD. Define\n$$\nJ_{\\mathrm{aug}}(\\boldsymbol{\\theta}) \\;=\\; J_{\\mathrm{phys}}(\\boldsymbol{\\theta}) \\;+\\; \\alpha \\,\\sup_{t\\in[t_{1},t_{2}]} \\|\\mathbf{E}_{\\mathrm{PML}}(t;\\mathbf{x}_{\\mathrm{b}})\\|^{2},\n$$\nwith a fixed probe point $\\,\\mathbf{x}_{\\mathrm{b}}\\,$ on the PML interface and a fixed late-time window $[t_{1},t_{2}]$ common to all $\\,\\boldsymbol{\\theta}\\,$. No normalization is applied because the supremum is scale-invariant up to a constant factor.",
            "solution": "The problem asks for the most appropriate formulation of an augmented fitness function $J_{\\mathrm{aug}}(\\boldsymbol{\\theta})$ for an evolutionary algorithm. The goal is to minimize a primary physical objective $J_{\\mathrm{phys}}(\\boldsymbol{\\theta})$, while simultaneously penalizing spurious late-time reflections from the Perfectly Matched Layer (PML) boundary of a Finite-Difference Time-Domain (FDTD) simulation. The key challenge is that the magnitude of these reflections can be design-dependent, and the penalty must provide a consistent and fair basis for comparing different designs $\\boldsymbol{\\theta}$.\n\nA valid penalty function must satisfy several criteria based on first principles of physics and numerical optimization:\n1.  **Specificity:** The penalty must selectively target the artifact of interest, namely the spurious, late-time reflections from the PML. It should not be sensitive to the legitimate, desired physical behavior, such as the initial wave propagation or scattering.\n2.  **Robustness:** The measurement should be insensitive to arbitrary choices like single probe locations or noisy instantaneous field values. It should capture the overall magnitude of the artifact, for instance, by integrating over the relevant spatial region and time interval.\n3.  **Consistency and Fairness:** This is the most critical requirement for an evolutionary algorithm. The algorithm compares fitness values of different candidate designs. If the penalty term is not properly normalized, it may unfairly punish designs that are, for example, stronger scatterers, even if the PML is performing equally well in a relative sense. The penalty should reflect the *performance* of the PML for a given design, not the absolute magnitude of the fields.\n\nLet's evaluate the proposed options against these criteria. The artifact to be measured is the energy of the spuriously reflected fields. The energy density of the electric field is proportional to $\\|\\mathbf{E}\\|^2$. Therefore, a sound penalty term will be based on the integral of $\\|\\mathbf{E}\\|^2$.\n\n**Option A Analysis**\nThe proposed augmented fitness is:\n$$\nJ_{\\mathrm{aug}}(\\boldsymbol{\\theta}) \\;=\\; J_{\\mathrm{phys}}(\\boldsymbol{\\theta}) \\;+\\; \\alpha \\,\\frac{\\displaystyle \\int_{t_{1}}^{t_{2}} \\int_{\\Omega_{\\mathrm{PML}}} \\|\\mathbf{E}_{\\mathrm{PML}}(t;\\mathbf{x})\\|^{2}\\,\\mathrm{d}\\mathbf{x}\\,\\mathrm{d}t}{\\displaystyle \\int_{0}^{T_{\\mathrm{end}}} \\int_{\\Omega_{\\mathrm{src}}} \\left|\\mathbf{J}_{\\mathrm{s}}(\\mathbf{x},t)\\cdot \\mathbf{E}(\\mathbf{x},t)\\right|\\,\\mathrm{d}\\mathbf{x}\\,\\mathrm{d}t}\n$$\n- **Specificity and Robustness:** The penalty term (the fraction) is constructed by integrating the electric field energy density ($\\|\\mathbf{E}\\|^2$) over a monitoring shell $\\Omega_{\\mathrm{PML}}$ within the PML. This spatial integration makes the measure robust against local field variations, unlike a single-point probe. The time integration is performed over a late-time window $[t_1, t_2]$. The start time $t_1 = \\tau_{\\mathrm{src}} + t_{\\mathrm{exit},\\max} + \\delta$ is rigorously defined to begin after any legitimate wave (from the source or scatterer) could have traversed the domain and exited through the PML. This timing isolates the late-time artifacts. Using $t_2 = T_{\\mathrm{end}}$ ensures all late-time effects within the simulation horizon are captured. The use of a fixed time window for all $\\boldsymbol{\\theta}$ is crucial for consistent comparison.\n- **Consistency and Fairness:** The numerator measures the total spurious reflected energy in the late-time window. Crucially, this quantity is normalized by the denominator, which is the integral of $|\\mathbf{J}_{\\mathrm{s}}\\cdot\\mathbf{E}|$. From Poynting's theorem, $\\mathbf{J}_{\\mathrm{s}}\\cdot\\mathbf{E}$ represents the power density delivered by the source to the electromagnetic field. The integral of its magnitude over the source volume and the relevant time represents the total energy coupled into the simulation for a particular design $\\boldsymbol{\\theta}$. By normalizing the reflected energy (numerator) by the total injected energy (denominator), the penalty becomes a dimensionless quantity analogous to a power reflection coefficient. This ratio measures the *relative* inefficiency of the PML for each specific design. It ensures that a design that strongly interacts with the source (large denominator) is not unfairly penalized for having a proportionally larger, but not relatively worse, reflection. This normalization is essential for a fair comparison across the design space.\n\nThis formulation meets all the required criteria.\n\n**Verdict:** **Correct**.\n\n**Option B Analysis**\nThe proposed augmented fitness is:\n$$\nJ_{\\mathrm{aug}}(\\boldsymbol{\\theta}) \\;=\\; J_{\\mathrm{phys}}(\\boldsymbol{\\theta}) \\;+\\; \\alpha \\,\\int_{t_{1}(\\boldsymbol{\\theta})}^{t_{2}(\\boldsymbol{\\theta})} \\int_{\\Omega_{\\mathrm{PML}}} \\|\\mathbf{E}_{\\mathrm{PML}}(t;\\mathbf{x})\\|^{2}\\,\\mathrm{d}\\mathbf{x}\\,\\mathrm{d}t\n$$\nThis option has three major deficiencies:\n1.  **No Normalization:** The penalty is an absolute measure of energy. A design $\\boldsymbol{\\theta}_A$ that scatters twice as much energy towards the PML as a design $\\boldsymbol{\\theta}_B$ would have a much larger penalty, even if the PML's relative reflection performance is identical for both. This biases the optimizer against strongly interacting designs.\n2.  **Inconsistent Time Window:** The time window $[t_1(\\boldsymbol{\\theta}), t_2(\\boldsymbol{\\theta})]$ is design-dependent. This means the fitness function is evaluating integrals over different domains for different candidates, which violates the principle of consistent comparison. The EA's selection process would be compromised.\n3.  **Fragile Window Definition:** Defining the time window based on a threshold crossing at a single probe point $\\mathbf{x}_0$ is not robust. The field behavior at a single point may not be representative of the global field decay, as it can be affected by local nulls or interferences. The choice of $\\mathbf{x}_0$ and the threshold are arbitrary and can lead to erratic behavior.\n\n**Verdict:** **Incorrect**.\n\n**Option C Analysis**\nThe proposed augmented fitness is:\n$$\nJ_{\\mathrm{aug}}(\\boldsymbol{\\theta}) \\;=\\; J_{\\mathrm{phys}}(\\boldsymbol{\\theta}) \\;+\\; \\alpha \\,\\int_{0}^{T_{\\mathrm{end}}} \\int_{\\Omega} \\|\\mathbf{E}(t;\\mathbf{x})\\|^{2}\\,\\mathrm{d}\\mathbf{x}\\,\\mathrm{d}t\n$$\nThe penalty term here is the total electric field energy in the entire domain $\\Omega$ over the entire simulation time.\n- **Lack of Specificity:** This measure is not specific to the PML reflection artifact. It is dominated by the energy of the source pulse and the primary scattered fields. The spurious reflected energy is typically a very small fraction of this total energy. Minimizing this term would not effectively target the reduction of PML reflections; instead, it would likely penalize any design that stores or radiates energy efficiently, which is contrary to the likely goal of the primary objective $J_{\\mathrm{phys}}$. The argument that \"spurious reflections are part of the total\" is true but misleading, as their contribution is masked.\n\n**Verdict:** **Incorrect**.\n\n**Option D Analysis**\nThe proposed augmented fitness is:\n$$\nJ_{\\mathrm{aug}}(\\boldsymbol{\\theta}) \\;=\\; J_{\\mathrm{phys}}(\\boldsymbol{\\theta}) \\;+\\; \\alpha \\,\\sup_{t\\in[t_{1},t_{2}]} \\|\\mathbf{E}_{\\mathrm{PML}}(t;\\mathbf{x}_{\\mathrm{b}})\\|^{2}\n$$\nThis option has several flaws:\n1.  **Lack of Spatial Robustness:** The penalty is based on the field at a single, fixed point $\\mathbf{x}_{\\mathrm{b}}$. The spatial distribution of reflected fields can be complex. An optimizer could find a trivial solution that creates a field null at $\\mathbf{x}_{\\mathrm{b}}$ while reflections are large elsewhere. A spatially integrated measure is far more robust.\n2.  **Lack of Temporal Robustness:** Using the supremum (maximum value) is less robust than integrating over time. The penalty can be dominated by a single transient spike, while ignoring a persistent, lower-amplitude reflection that contains more total energy. Time integration provides a more stable measure of the total reflected energy.\n3.  **No Normalization:** The claim that the supremum is scale-invariant is incorrect in this physical context. If a design doubles the incident field amplitude at the boundary, the reflected field amplitude will also double (for a linear system), and the penalty term $\\|\\mathbf{E}\\|^2$ will quadruple. This term is not scale-invariant and, like in option B, will unfairly penalize designs that produce stronger fields, irrespective of the PML's relative performance.\n\n**Verdict:** **Incorrect**.\n\nBased on this detailed analysis, Option A provides the only scientifically sound, robust, and consistent formulation for the augmented fitness function, making it the most appropriate choice for the stated problem.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Electromagnetic systems are governed by fundamental physical laws, which must be respected by any valid design. The Lorentz reciprocity theorem, for instance, imposes a strict symmetry condition on the scattering matrix of any linear, isotropic device. This practice explores how to integrate such a physical law directly into the evolutionary algorithm as a feasibility constraint . You will develop a \"repair operator\" that enforces this symmetry, demonstrating a powerful technique for handling constraints by projecting an infeasible candidate solution back into the space of physically valid designs with minimal perturbation.",
            "id": "3306120",
            "problem": "Consider a linear, time-invariant, isotropic, source-free electromagnetic medium governed by Maxwell's equations. For a multiport structure excited by time-harmonic sources with angular frequency $\\omega$ expressed in radians per second, define the incident wave amplitudes vector $\\mathbf{a}(\\omega)$ and the scattered (outgoing) wave amplitudes vector $\\mathbf{b}(\\omega)$. The scattering matrix $\\mathbf{S}(\\omega; x)$ is the linear operator relating these quantities via $\\mathbf{b}(\\omega) = \\mathbf{S}(\\omega; x)\\,\\mathbf{a}(\\omega)$, where $x$ denotes the design parameters of the structure (e.g., geometric features or material property distributions).\n\nA foundational result derived from the Lorentz reciprocity theorem, applied to Maxwell's equations for linear time-invariant isotropic media with symmetric permittivity and permeability tensors, implies that for reciprocal systems the scattering matrix must be symmetric, i.e., $\\mathbf{S}(\\omega; x) = \\mathbf{S}^{\\top}(\\omega; x)$ for all $\\omega$.\n\nYou are tasked with formulating a feasibility rule suitable for use within an evolutionary optimization algorithm to enforce reciprocity. The feasibility rule must evaluate a candidate design $x$ at a finite set of sampled angular frequencies and declare the design feasible only if the simulated scattering matrices obey the reciprocity constraint within a specified numerical tolerance. Additionally, you must implement a repair operator that minimally modifies a given (possibly infeasible) $\\mathbf{S}(\\omega; x)$ to produce a symmetric matrix, thereby restoring feasibility without altering the underlying design excessively.\n\nYour solution must satisfy the following:\n\n- Starting from Maxwell's equations and the Lorentz reciprocity theorem, logically justify why reciprocity requires $\\mathbf{S}(\\omega; x) = \\mathbf{S}^{\\top}(\\omega; x)$.\n- Define a reciprocity violation metric using the Frobenius norm and construct a feasibility rule and a repair operator grounded in first principles. The feasibility rule must use a tolerance parameter $\\tau$.\n- The repair operator must be the symmetric projection $\\mathbf{R}(\\mathbf{S}) = \\tfrac{1}{2}\\left(\\mathbf{S} + \\mathbf{S}^{\\top}\\right)$ and you must justify, from a mathematical optimization perspective, that it minimally perturbs $\\mathbf{S}$ in the Frobenius norm among all symmetric matrices.\n- Implement a program that, for each test case below, computes the following four quantities:\n  1. The maximum reciprocity violation before repair, defined as $v_{\\text{before}} = \\max_{\\omega \\in \\Omega} \\left\\|\\mathbf{S}(\\omega; x) - \\mathbf{S}^{\\top}(\\omega; x)\\right\\|_{F}$.\n  2. The maximum reciprocity violation after repair, defined as $v_{\\text{after}} = \\max_{\\omega \\in \\Omega} \\left\\|\\mathbf{R}(\\mathbf{S}(\\omega; x)) - \\mathbf{R}(\\mathbf{S}(\\omega; x))^{\\top}\\right\\|_{F}$.\n  3. The feasibility after repair, defined as the boolean $b_{\\text{feasible}} = \\left[v_{\\text{after}} \\le \\tau\\right]$.\n  4. The maximum perturbation introduced by the repair, defined as $d_{\\text{max}} = \\max_{\\omega \\in \\Omega} \\left\\|\\mathbf{R}(\\mathbf{S}(\\omega; x)) - \\mathbf{S}(\\omega; x)\\right\\|_{F}$.\n- Use the numerical tolerance $\\tau = 10^{-8}$.\n- Express angular frequencies in radians per second; outputs are dimensionless real numbers and booleans. No percentage units are to be used.\n- Your program should produce a single line of output containing a comma-separated list of the five test case results, each represented as a list in the form $[v_{\\text{before}}, v_{\\text{after}}, b_{\\text{feasible}}, d_{\\text{max}}]$.\n\nTest Suite:\nFor each test case, $\\Omega$ contains two angular frequencies, and $\\mathbf{S}(\\omega; x)$ is a $3\\times 3$ complex matrix specified below.\n\n- Test Case A (already reciprocal across sampled frequencies):\n  Frequencies: $\\Omega = \\{2\\pi \\cdot 10^{9},\\, 2\\pi \\cdot 2 \\cdot 10^{9}\\}$.\n  Matrices:\n  $$\n  \\mathbf{S}(2\\pi \\cdot 10^{9}; x) =\n  \\begin{bmatrix}\n  0.10 & 0.02 & 0.03\\\\\n  0.02 & 0.20 & 0.01\\\\\n  0.03 & 0.01 & 0.15\n  \\end{bmatrix}\n  $$\n  $$\n  \\mathbf{S}(2\\pi \\cdot 2 \\cdot 10^{9}; x) =\n  \\begin{bmatrix}\n  0.08 + 0.02\\,\\mathrm{i} & 0.01 - 0.005\\,\\mathrm{i} & 0.00 + 0.01\\,\\mathrm{i}\\\\\n  0.01 - 0.005\\,\\mathrm{i} & 0.12 + 0.00\\,\\mathrm{i} & 0.02 + 0.003\\,\\mathrm{i}\\\\\n  0.00 + 0.01\\,\\mathrm{i} & 0.02 + 0.003\\,\\mathrm{i} & 0.09 - 0.01\\,\\mathrm{i}\n  \\end{bmatrix}\n  $$\n\n- Test Case B (slightly asymmetric due to small noise):\n  Frequencies: $\\Omega = \\{2\\pi \\cdot 1.2 \\cdot 10^{9},\\, 2\\pi \\cdot 1.8 \\cdot 10^{9}\\}$.\n  Matrices:\n  $$\n  \\mathbf{S}(2\\pi \\cdot 1.2 \\cdot 10^{9}; x) =\n  \\begin{bmatrix}\n  0.20 & 0.05 + 0.001 & 0.00 - 0.002\\\\\n  0.05 - 0.001 & 0.15 & 0.01 + 0.0005\\\\\n  0.00 + 0.002 & 0.01 - 0.0005 & 0.10\n  \\end{bmatrix}\n  $$\n  $$\n  \\mathbf{S}(2\\pi \\cdot 1.8 \\cdot 10^{9}; x) =\n  \\begin{bmatrix}\n  0.18 + 0.01\\,\\mathrm{i} & 0.02 + 0.00\\,\\mathrm{i} + 0.001 + 0.0005\\,\\mathrm{i} & 0.03 - 0.01\\,\\mathrm{i} - 0.001 - 0.0003\\,\\mathrm{i}\\\\\n  0.02 + 0.00\\,\\mathrm{i} - 0.001 - 0.0005\\,\\mathrm{i} & 0.16 - 0.005\\,\\mathrm{i} & 0.04 + 0.002\\,\\mathrm{i} + 0.0004 - 0.0002\\,\\mathrm{i}\\\\\n  0.03 - 0.01\\,\\mathrm{i} + 0.001 + 0.0003\\,\\mathrm{i} & 0.04 + 0.002\\,\\mathrm{i} - 0.0004 + 0.0002\\,\\mathrm{i} & 0.11 + 0.00\\,\\mathrm{i}\n  \\end{bmatrix}\n  $$\n\n- Test Case C (strongly asymmetric):\n  Frequencies: $\\Omega = \\{2\\pi \\cdot 0.8 \\cdot 10^{9},\\, 2\\pi \\cdot 1.6 \\cdot 10^{9}\\}$.\n  Matrices:\n  $$\n  \\mathbf{S}(2\\pi \\cdot 0.8 \\cdot 10^{9}; x) =\n  \\begin{bmatrix}\n  0.30 + 0.00\\,\\mathrm{i} & 0.10 + 0.05\\,\\mathrm{i} & -0.20 + 0.10\\,\\mathrm{i}\\\\\n  0.05 - 0.10\\,\\mathrm{i} & -0.10 + 0.00\\,\\mathrm{i} & 0.25 + 0.00\\,\\mathrm{i}\\\\\n  0.15 - 0.05\\,\\mathrm{i} & 0.40 + 0.20\\,\\mathrm{i} & 0.05 + 0.30\\,\\mathrm{i}\n  \\end{bmatrix}\n  $$\n  $$\n  \\mathbf{S}(2\\pi \\cdot 1.6 \\cdot 10^{9}; x) =\n  \\begin{bmatrix}\n  0.25 - 0.05\\,\\mathrm{i} & -0.35 + 0.10\\,\\mathrm{i} & 0.20 + 0.00\\,\\mathrm{i}\\\\\n  0.20 - 0.15\\,\\mathrm{i} & 0.30 + 0.05\\,\\mathrm{i} & -0.10 + 0.25\\,\\mathrm{i}\\\\\n  0.05 + 0.20\\,\\mathrm{i} & 0.12 - 0.30\\,\\mathrm{i} & -0.20 + 0.10\\,\\mathrm{i}\n  \\end{bmatrix}\n  $$\n\n- Test Case D (boundary case: zero scattering):\n  Frequencies: $\\Omega = \\{2\\pi \\cdot 10^{9},\\, 2\\pi \\cdot 1.5 \\cdot 10^{9}\\}$.\n  Matrices:\n  $$\n  \\mathbf{S}(2\\pi \\cdot 10^{9}; x) =\n  \\begin{bmatrix}\n  0 & 0 & 0\\\\\n  0 & 0 & 0\\\\\n  0 & 0 & 0\n  \\end{bmatrix}\n  \\quad,\\quad\n  \\mathbf{S}(2\\pi \\cdot 1.5 \\cdot 10^{9}; x) =\n  \\begin{bmatrix}\n  0 & 0 & 0\\\\\n  0 & 0 & 0\\\\\n  0 & 0 & 0\n  \\end{bmatrix}\n  $$\n\n- Test Case E (frequency-dependent with moderate asymmetry):\n  Frequencies: $\\Omega = \\{2\\pi \\cdot 1.1 \\cdot 10^{9},\\, 2\\pi \\cdot 1.7 \\cdot 10^{9}\\}$.\n  Matrices:\n  $$\n  \\mathbf{S}(2\\pi \\cdot 1.1 \\cdot 10^{9}; x) =\n  \\begin{bmatrix}\n  0.12 & 0.03 + 0.005 & 0.025 - 0.004\\\\\n  0.03 - 0.005 & 0.18 & 0.02 + 0.003\\\\\n  0.025 + 0.004 & 0.02 - 0.003 & 0.14\n  \\end{bmatrix}\n  $$\n  $$\n  \\mathbf{S}(2\\pi \\cdot 1.7 \\cdot 10^{9}; x) =\n  \\begin{bmatrix}\n  0.10 + 0.02\\,\\mathrm{i} & 0.04 - 0.01\\,\\mathrm{i} - 0.01 + 0.005\\,\\mathrm{i} & 0.00 + 0.03\\,\\mathrm{i} + 0.006 - 0.004\\,\\mathrm{i}\\\\\n  0.04 - 0.01\\,\\mathrm{i} + 0.01 - 0.005\\,\\mathrm{i} & 0.20 + 0.00\\,\\mathrm{i} & 0.01 + 0.02\\,\\mathrm{i} - 0.005 + 0.002\\,\\mathrm{i}\\\\\n  0.00 + 0.03\\,\\mathrm{i} - 0.006 + 0.004\\,\\mathrm{i} & 0.01 + 0.02\\,\\mathrm{i} + 0.005 - 0.002\\,\\mathrm{i} & 0.13 - 0.01\\,\\mathrm{i}\n  \\end{bmatrix}\n  $$\n\nImplementation details and output specification:\n- Use $\\tau = 10^{-8}$.\n- Compute $v_{\\text{before}}$, $v_{\\text{after}}$, $b_{\\text{feasible}}$, and $d_{\\text{max}}$ for each test case exactly as defined above.\n- Your program should produce a single line of output containing a comma-separated list of the five test case results, each represented as a list $[v_{\\text{before}}, v_{\\text{after}}, b_{\\text{feasible}}, d_{\\text{max}}]$, enclosed in square brackets, for example:\n  `[[v_before^(A), v_after^(A), b_feasible^(A), d_max^(A)],...,[v_before^(E), v_after^(E), b_feasible^(E), d_max^(E)]]]`\nNo input from the user is required; all data must be embedded in the program.",
            "solution": "The problem requires the formulation and implementation of a reciprocity constraint for use in evolutionary optimization algorithms applied to computational electromagnetics. This involves deriving the theoretical basis for the constraint, defining a quantitative measure of its violation, and constructing a repair operator that enforces the constraint while minimally perturbing the original system.\n\n### 1. Theoretical Justification for S-Matrix Symmetry from Lorentz Reciprocity\n\nThe symmetry of the scattering matrix, $\\mathbf{S} = \\mathbf{S}^{\\top}$, for a reciprocal multiport network is a direct consequence of the Lorentz reciprocity theorem. The derivation begins with Maxwell's equations for time-harmonic electromagnetic fields with an angular frequency $\\omega$, denoted by phasors $(\\vec{E}, \\vec{H})$.\n\nIn a source-free volume $V$ occupied by a linear, time-invariant, and isotropic medium, Maxwell's curl equations are:\n$$ \\nabla \\times \\vec{E} = -j\\omega\\mu\\vec{H} $$\n$$ \\nabla \\times \\vec{H} = j\\omega\\epsilon\\vec{E} $$\nThe material properties are described by the permittivity $\\epsilon$ and permeability $\\mu$. For an isotropic medium, these are scalars. More generally, for a reciprocal medium, they are symmetric tensors, i.e., $\\epsilon = \\epsilon^{\\top}$ and $\\mu = \\mu^{\\top}$.\n\nConsider two independent sets of sources producing two distinct sets of fields, $(\\vec{E}_1, \\vec{H}_1)$ and $(\\vec{E}_2, \\vec{H}_2)$, at the same frequency $\\omega$. By vector identity, we have:\n$$ \\nabla \\cdot (\\vec{E}_1 \\times \\vec{H}_2) = \\vec{H}_2 \\cdot (\\nabla \\times \\vec{E}_1) - \\vec{E}_1 \\cdot (\\nabla \\times \\vec{H}_2) = -j\\omega\\mu (\\vec{H}_1 \\cdot \\vec{H}_2) - j\\omega\\epsilon (\\vec{E}_1 \\cdot \\vec{E}_2) $$\n$$ \\nabla \\cdot (\\vec{E}_2 \\times \\vec{H}_1) = \\vec{H}_1 \\cdot (\\nabla \\times \\vec{E}_2) - \\vec{E}_2 \\cdot (\\nabla \\times \\vec{H}_1) = -j\\omega\\mu (\\vec{H}_2 \\cdot \\vec{H}_1) - j\\omega\\epsilon (\\vec{E}_2 \\cdot \\vec{E}_1) $$\nSubtracting these two equations yields $\\nabla \\cdot (\\vec{E}_1 \\times \\vec{H}_2 - \\vec{E}_2 \\times \\vec{H}_1) = 0$. Applying the divergence theorem over the volume $V$ leads to the integral form of the Lorentz reciprocity theorem:\n$$ \\oint_{\\partial V} (\\vec{E}_1 \\times \\vec{H}_2 - \\vec{E}_2 \\times \\vec{H}_1) \\cdot d\\vec{A} = 0 $$\nwhere $\\partial V$ is the boundary surface of $V$.\n\nFor a multiport device, this surface $\\partial V$ consists of the port apertures and the enclosing metallic or radiation boundaries. Assuming perfect conductors or a surface at infinity where fields vanish, the integral is non-zero only over the ports. The fields at each port $k$ can be decomposed into a superposition of guided modes. For a single-mode port, the field is a combination of an incident wave with amplitude $a_k$ and a scattered wave with amplitude $b_k$. The total tangential fields at port $k$ are related to these amplitudes and the port's normalized modal fields $(\\vec{e}_k, \\vec{h}_k)$. The surface integral reduces to a sum over all $N$ ports:\n$$ \\sum_{k=1}^{N} \\int_{A_k} (\\vec{E}_{1,t} \\times \\vec{H}_{2,t} - \\vec{E}_{2,t} \\times \\vec{H}_{1,t}) \\cdot d\\vec{A}_k = 0 $$\nWith proper normalization of the modal fields, this algebraic sum becomes a relationship between the incident and scattered wave amplitudes for the two states:\n$$ \\sum_{k=1}^{N} (a_{1k} b_{2k} - a_{2k} b_{1k}) = 0 $$\nIn vector form, this is $\\mathbf{a}_1^{\\top} \\mathbf{b}_2 - \\mathbf{a}_2^{\\top} \\mathbf{b}_1 = 0$. Using the definition of the scattering matrix, $\\mathbf{b} = \\mathbf{S}\\mathbf{a}$, we can substitute $\\mathbf{b}_1 = \\mathbf{S}\\mathbf{a}_1$ and $\\mathbf{b}_2 = \\mathbf{S}\\mathbf{a}_2$:\n$$ \\mathbf{a}_1^{\\top} (\\mathbf{S}\\mathbf{a}_2) - \\mathbf{a}_2^{\\top} (\\mathbf{S}\\mathbf{a}_1) = 0 $$\nSince $(\\mathbf{X}\\mathbf{Y})^\\top = \\mathbf{Y}^\\top\\mathbf{X}^\\top$ and a scalar is its own transpose, we can write $\\mathbf{a}_2^{\\top}\\mathbf{S}\\mathbf{a}_1 = (\\mathbf{a}_1^\\top \\mathbf{S}^\\top \\mathbf{a}_2)$. The equation becomes:\n$$ \\mathbf{a}_1^{\\top} \\mathbf{S} \\mathbf{a}_2 - \\mathbf{a}_1^{\\top} \\mathbf{S}^{\\top} \\mathbf{a}_2 = \\mathbf{a}_1^{\\top} (\\mathbf{S} - \\mathbf{S}^{\\top}) \\mathbf{a}_2 = 0 $$\nThis relationship must hold for any arbitrary choice of excitation vectors $\\mathbf{a}_1$ and $\\mathbf{a}_2$. This is only possible if the matrix in the middle is the zero matrix, i.e., $\\mathbf{S} - \\mathbf{S}^{\\top} = \\mathbf{0}$, which implies $\\mathbf{S} = \\mathbf{S}^{\\top}$. This proves that reciprocity requires the scattering matrix to be symmetric.\n\n### 2. Feasibility Rule and Reciprocity Violation Metric\n\nIn computational electromagnetics, numerical errors in simulation can lead to a scattering matrix $\\mathbf{S}$ that is not perfectly symmetric, even if the modeled physical system is reciprocal. For an optimization algorithm, we need a rule to decide if a candidate design is \"feasible\" with respect to the reciprocity constraint.\n\nA natural way to quantify the violation is to measure the \"size\" of the skew-symmetric component of the matrix, $\\mathbf{S} - \\mathbf{S}^{\\top}$. We use the Frobenius norm for this purpose. The Frobenius norm of a complex matrix $\\mathbf{A} \\in \\mathbb{C}^{m \\times n}$ is defined as:\n$$ \\|\\mathbf{A}\\|_F = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n} |A_{ij}|^2} $$\nThe reciprocity violation metric for a given scattering matrix $\\mathbf{S}(\\omega; x)$ is defined as:\n$$ v(\\mathbf{S}) = \\|\\mathbf{S}(\\omega; x) - \\mathbf{S}^{\\top}(\\omega; x)\\|_F $$\nFor an optimization problem evaluated over a set of frequencies $\\Omega$, the feasibility rule is constructed using a numerical tolerance $\\tau > 0$. A design $x$ is declared feasible if the maximum violation over all sampled frequencies is within this tolerance:\n$$ \\text{Design } x \\text{ is feasible if } \\max_{\\omega \\in \\Omega} v(\\mathbf{S}(\\omega; x)) \\le \\tau $$\n\n### 3. Repair Operator and its Optimality\n\nWhen a candidate design is found to be infeasible (i.e., its $\\mathbf{S}$ matrix is not sufficiently symmetric), a repair operator can be used to project it back into the feasible set. The proposed operator is the symmetric projection:\n$$ \\mathbf{R}(\\mathbf{S}) = \\frac{1}{2}(\\mathbf{S} + \\mathbf{S}^{\\top}) $$\nThis operator generates a symmetric matrix, as $(\\mathbf{R}(\\mathbf{S}))^{\\top} = \\frac{1}{2}(\\mathbf{S}^{\\top} + (\\mathbf{S}^{\\top})^{\\top}) = \\frac{1}{2}(\\mathbf{S}^{\\top} + \\mathbf{S}) = \\mathbf{R}(\\mathbf{S})$.\n\nWe must justify that this operator minimally perturbs $\\mathbf{S}$, which mathematically means that $\\mathbf{R}(\\mathbf{S})$ is the solution to the following optimization problem:\n$$ \\min_{\\mathbf{X}} \\|\\mathbf{S} - \\mathbf{X}\\|_F \\quad \\text{subject to} \\quad \\mathbf{X} = \\mathbf{X}^{\\top} $$\nWe seek the symmetric matrix $\\mathbf{X}$ that is closest to $\\mathbf{S}$ in the sense of the Frobenius norm. Let's minimize the squared norm, $f(\\mathbf{X}) = \\|\\mathbf{S} - \\mathbf{X}\\|_F^2$:\n$$ f(\\mathbf{X}) = \\sum_{i,j} |S_{ij} - X_{ij}|^2 $$\nWe can minimize this function by taking derivatives with respect to the independent elements of $\\mathbf{X}$ and setting them to zero. Since $\\mathbf{X}$ is symmetric ($X_{ij} = X_{ji}$), the independent variables are $X_{ii}$ for all $i$, and $X_{ij}$ for $i < j$.\n\nThe objective function can be written as:\n$$ f(\\mathbf{X}) = \\sum_{i} |S_{ii} - X_{ii}|^2 + \\sum_{i < j} (|S_{ij} - X_{ij}|^2 + |S_{ji} - X_{ji}|^2) $$\nSince $X_{ij} = X_{ji}$, this simplifies to:\n$$ f(\\mathbf{X}) = \\sum_{i} |S_{ii} - X_{ii}|^2 + \\sum_{i < j} (|S_{ij} - X_{ij}|^2 + |S_{ji} - X_{ij}|^2) $$\nMinimizing each term separately:\nFor the diagonal elements ($i=j$): The term $|S_{ii} - X_{ii}|^2$ is minimized when $X_{ii} = S_{ii}$.\nFor the off-diagonal elements ($i \\neq j$): Consider the pair of terms for $(i, j)$ and $(j, i)$ with $i < j$. Let $g(X_{ij}) = |S_{ij} - X_{ij}|^2 + |S_{ji} - X_{ij}|^2$. Let $X_{ij} = u + iv$, $S_{ij} = a+ib$, and $S_{ji} = c+id$.\n$$ g(u, v) = (a-u)^2 + (b-v)^2 + (c-u)^2 + (d-v)^2 $$\nTaking partial derivatives and setting to zero:\n$$ \\frac{\\partial g}{\\partial u} = -2(a-u) - 2(c-u) = 0 \\implies 4u = 2(a+c) \\implies u = \\frac{a+c}{2} $$\n$$ \\frac{\\partial g}{\\partial v} = -2(b-v) - 2(d-v) = 0 \\implies 4v = 2(b+d) \\implies v = \\frac{b+d}{2} $$\nThe optimal $X_{ij}$ is therefore $u+iv = \\frac{a+c}{2} + i\\frac{b+d}{2} = \\frac{1}{2}((a+ib) + (c+id)) = \\frac{1}{2}(S_{ij} + S_{ji})$.\nCombining the results for diagonal and off-diagonal elements, the optimal symmetric matrix $\\mathbf{X}$ has elements $X_{ij} = \\frac{1}{2}(S_{ij} + S_{ji})$. This is precisely the matrix $\\mathbf{R}(\\mathbf{S}) = \\frac{1}{2}(\\mathbf{S} + \\mathbf{S}^{\\top})$.\nThus, $\\mathbf{R}(\\mathbf{S})$ is the unique closest symmetric matrix to $\\mathbf{S}$ in the Frobenius norm, justifying its use as a minimal perturbation repair operator.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the reciprocity validation and repair problem for a series of test cases.\n    \"\"\"\n    \n    # Define the numerical tolerance for the feasibility check.\n    tau = 1e-8\n\n    # Define the test cases from the problem statement.\n    # Each test case is a list of S-matrices given as numpy arrays.\n    test_cases = [\n        # Test Case A (already reciprocal)\n        [\n            np.array([\n                [0.10, 0.02, 0.03],\n                [0.02, 0.20, 0.01],\n                [0.03, 0.01, 0.15]\n            ], dtype=complex),\n            np.array([\n                [0.08 + 0.02j, 0.01 - 0.005j, 0.00 + 0.01j],\n                [0.01 - 0.005j, 0.12 + 0.00j,  0.02 + 0.003j],\n                [0.00 + 0.01j,  0.02 + 0.003j, 0.09 - 0.01j]\n            ], dtype=complex)\n        ],\n        \n        # Test Case B (slightly asymmetric)\n        [\n            np.array([\n                [0.20, 0.05 + 0.001, 0.00 - 0.002],\n                [0.05 - 0.001, 0.15, 0.01 + 0.0005],\n                [0.00 + 0.002, 0.01 - 0.0005, 0.10]\n            ], dtype=complex),\n            np.array([\n                [0.18 + 0.01j, 0.02 + 0.00j + 0.001 + 0.0005j, 0.03 - 0.01j - 0.001 - 0.0003j],\n                [0.02 + 0.00j - 0.001 - 0.0005j, 0.16 - 0.005j, 0.04 + 0.002j + 0.0004 - 0.0002j],\n                [0.03 - 0.01j + 0.001 + 0.0003j, 0.04 + 0.002j - 0.0004 + 0.0002j, 0.11 + 0.00j]\n            ], dtype=complex)\n        ],\n        \n        # Test Case C (strongly asymmetric)\n        [\n            np.array([\n                [0.30 + 0.00j, 0.10 + 0.05j, -0.20 + 0.10j],\n                [0.05 - 0.10j, -0.10 + 0.00j, 0.25 + 0.00j],\n                [0.15 - 0.05j, 0.40 + 0.20j, 0.05 + 0.30j]\n            ], dtype=complex),\n            np.array([\n                [0.25 - 0.05j, -0.35 + 0.10j, 0.20 + 0.00j],\n                [0.20 - 0.15j, 0.30 + 0.05j, -0.10 + 0.25j],\n                [0.05 + 0.20j, 0.12 - 0.30j, -0.20 + 0.10j]\n            ], dtype=complex)\n        ],\n\n        # Test Case D (boundary case: zero scattering)\n        [\n            np.array([\n                [0, 0, 0],\n                [0, 0, 0],\n                [0, 0, 0]\n            ], dtype=complex),\n            np.array([\n                [0, 0, 0],\n                [0, 0, 0],\n                [0, 0, 0]\n            ], dtype=complex)\n        ],\n\n        # Test Case E (frequency-dependent with moderate asymmetry)\n        [\n            np.array([\n                [0.12, 0.03 + 0.005, 0.025 - 0.004],\n                [0.03 - 0.005, 0.18, 0.02 + 0.003],\n                [0.025 + 0.004, 0.02 - 0.003, 0.14]\n            ], dtype=complex),\n            np.array([\n                [0.10 + 0.02j, 0.04 - 0.01j - 0.01 + 0.005j, 0.00 + 0.03j + 0.006 - 0.004j],\n                [0.04 - 0.01j + 0.01 - 0.005j, 0.20 + 0.00j, 0.01 + 0.02j - 0.005 + 0.002j],\n                [0.00 + 0.03j - 0.006 + 0.004j, 0.01 + 0.02j + 0.005 - 0.002j, 0.13 - 0.01j]\n            ], dtype=complex)\n        ]\n    ]\n\n    all_results = []\n    \n    for case_matrices in test_cases:\n        violations_before = []\n        violations_after = []\n        perturbations = []\n\n        for S in case_matrices:\n            # Calculate violation before repair\n            diff_before = S - S.T\n            v_before_single = np.linalg.norm(diff_before, 'fro')\n            violations_before.append(v_before_single)\n\n            # Apply the repair operator\n            S_repaired = 0.5 * (S + S.T)\n\n            # Calculate violation after repair\n            # This should be zero or very close to it due to floating-point arithmetic\n            diff_after = S_repaired - S_repaired.T\n            v_after_single = np.linalg.norm(diff_after, 'fro')\n            violations_after.append(v_after_single)\n\n            # Calculate the perturbation introduced by the repair\n            perturbation_matrix = S_repaired - S\n            d_single = np.linalg.norm(perturbation_matrix, 'fro')\n            perturbations.append(d_single)\n\n        # Compute the maximums over the frequencies for the current test case\n        v_before = max(violations_before)\n        v_after = max(violations_after)\n        d_max = max(perturbations)\n        \n        # Determine feasibility after repair\n        b_feasible = v_after = tau\n        \n        all_results.append([v_before, v_after, b_feasible, d_max])\n\n    # Format the final output string to be a list of lists with no spaces\n    # Example: [[v1,v2,True,v3],[v4,v5,False,v6]]\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "The primary bottleneck in applying evolutionary algorithms to computational electromagnetics is the staggering computational cost of each fitness evaluation, which often involves a full-wave simulation. However, genetic operators like crossover can frequently regenerate individuals that have already been evaluated in previous generations. This practice demonstrates a crucial optimization technique: implementing a caching mechanism to store and retrieve past results, thereby avoiding redundant simulations . By deriving the expected time savings from first principles, you will gain a quantitative understanding of how this strategy can dramatically accelerate the optimization process.",
            "id": "3306062",
            "problem": "An optimization of a metasurface scatterer in computational electromagnetics is performed using a Genetic Algorithm (GA), where each candidate design (genotype) is evaluated by a Finite-Difference Time-Domain (FDTD) solver. The electromagnetic response is deterministic for a fixed simulation setting, so repeating an evaluation for an identical pair consisting of a genotype and its simulation settings yields the same fitness. To avoid redundant FDTD solves, a caching mechanism is proposed: build a key as a cryptographic hash of the tuple consisting of the genotype and the simulation settings. Let the hash key be defined as $H(g,s)$, where $g$ is the genotype and $s$ is the vector of simulation settings (e.g., frequencies, mesh resolution, boundary conditions). Assume the hash collision probability is negligible, lookup time is $\\mathcal{O}(1)$, and simulation settings $s$ remain constant throughout the generation under consideration. The cache initially contains the $N$ unique individuals from the previous generation, each stored under its key.\n\nIn one generation, the GA produces $N$ offspring, with a fraction $f_{c}$ generated by crossover and the remaining fraction $1 - f_{c}$ generated by mutation. Due to representation redundancies (e.g., symmetries and neutral encodings), crossover frequently reproduces genotypes that have already been seen in previous generations under the same settings. Model this by the following probabilities: among crossover offspring, the probability that an offspring has a genotype equal to one already in the cache under the same settings is $p_{c}$; among mutation offspring, the corresponding probability is $p_{m}$.\n\nEach FDTD evaluation of a unique key incurs an evaluation time $t_{e}$, and the caching mechanism adds overhead: computing the hash costs $t_{h}$, a cache lookup costs $t_{\\ell}$, and retrieving a cached fitness costs $t_{r}$. For unique keys, storing the new result into the cache costs $t_{s}$. The baseline without caching performs $N$ FDTD evaluations per generation.\n\nUsing only the above modeling assumptions, derive from first principles the expected net time saved per generation by the caching mechanism compared to the uncached baseline. Then compute this expected net time savings numerically for the following parameter values:\n- Number of offspring per generation $N = 250$.\n- Crossover fraction $f_{c} = 0.85$.\n- Duplicate probability among crossover offspring $p_{c} = 0.42$.\n- Duplicate probability among mutation offspring $p_{m} = 0.07$.\n- FDTD evaluation time $t_{e} = 18.5$ s.\n- Hash computation time $t_{h} = 8.0 \\times 10^{-4}$ s.\n- Lookup time $t_{\\ell} = 5.0 \\times 10^{-4}$ s.\n- Retrieval time $t_{r} = 3.0 \\times 10^{-4}$ s.\n- Store time $t_{s} = 6.0 \\times 10^{-4}$ s.\n\nExpress the final expected net time savings per generation in seconds and round your answer to $4$ significant figures.",
            "solution": "The user wants to find the expected net time saved per generation by implementing a caching mechanism in a Genetic Algorithm. The solution will be derived from first principles and then computed numerically.\n\n### Step 1: Problem Validation\n\n**1.1. Extract Givens**\n-   Number of offspring per generation: $N = 250$\n-   Crossover fraction: $f_{c} = 0.85$\n-   Remaining fraction (mutation): $1 - f_{c}$\n-   Duplicate probability among crossover offspring: $p_{c} = 0.42$\n-   Duplicate probability among mutation offspring: $p_{m} = 0.07$\n-   FDTD evaluation time: $t_{e} = 18.5$ s\n-   Hash computation time: $t_{h} = 8.0 \\times 10^{-4}$ s $= 0.0008$ s\n-   Cache lookup time: $t_{\\ell} = 5.0 \\times 10^{-4}$ s $= 0.0005$ s\n-   Cached fitness retrieval time: $t_{r} = 3.0 \\times 10^{-4}$ s $= 0.0003$ s\n-   New result storage time: $t_{s} = 6.0 \\times 10^{-4}$ s $= 0.0006$ s\n-   Baseline: $N$ FDTD evaluations per generation, with time $t_{e}$ each.\n-   Assumptions: Negligible hash collision probability, $\\mathcal{O}(1)$ lookup time, constant simulation settings $s$.\n\n**1.2. Validate Using Extracted Givens**\n-   **Scientifically Grounded**: The problem is set in the context of computational engineering (computational electromagnetics) and computer science (evolutionary algorithms, performance analysis). The use of caching to avoid redundant computations is a standard and valid technique. The model is a probabilistic performance analysis, which is a well-established mathematical method. All aspects are scientifically sound.\n-   **Well-Posed**: The problem provides all necessary parameters and a clear objective: derive a formula and compute a numerical value. The setup allows for a unique, stable, and meaningful solution.\n-   **Objective**: The language is precise, quantitative, and free of subjectivity. The terms are clearly defined within the context of the model.\n-   **Completeness and Consistency**: The problem is self-contained. All variables needed for the derivation are defined and have consistent units (seconds). There are no contradictions.\n-   **Realism**: The provided time values are realistic. FDTD simulations are computationally expensive (seconds to minutes or hours), while hashing and memory operations are very fast (microseconds to milliseconds). The probabilities are also within a reasonable range.\n\n**1.3. Verdict and Action**\nThe problem is valid. It is scientifically sound, well-posed, objective, complete, and consistent. I will proceed with providing a complete solution.\n\n### Step 2: Derivation of the Solution\n\nThe objective is to find the expected net time saved per generation, $\\Delta T$. This is the difference between the total time without caching, $T_{uncached}$, and the expected total time with caching, $E[T_{cached}]$.\n$$\n\\Delta T = T_{uncached} - E[T_{cached}]\n$$\nThe baseline process without caching performs $N$ evaluations, so the total time is:\n$$\nT_{uncached} = N t_{e}\n$$\nTo find the expected time with caching, we can determine the expected time cost for a single offspring and multiply by $N$, as the process is identical for all offspring. Let $E[\\Delta T_{indiv}]$ be the expected time saved for a single offspring. The total expected time saved is then $\\Delta T = N \\cdot E[\\Delta T_{indiv}]$.\n\nThe expected time saved for one offspring is the sum of the savings in each possible scenario, weighted by their probabilities. There are two scenarios for an offspring: its genotype is already in the cache (a \"hit\"), or it is not (a \"miss\").\n\nFirst, let's determine the overall probability of a cache hit, $P_{hit}$. An offspring is generated either by crossover (with probability $f_c$) or by mutation (with probability $1-f_c$).\nThe probability of a hit is given by the law of total probability:\n$$\nP_{hit} = P(\\text{hit}|\\text{crossover})P(\\text{crossover}) + P(\\text{hit}|\\text{mutation})P(\\text{mutation})\n$$\nUsing the problem's definitions, $P(\\text{hit}|\\text{crossover}) = p_{c}$ and $P(\\text{hit}|\\text{mutation}) = p_{m}$.\nThus, the overall probability of a cache hit for any given offspring is:\n$$\nP_{hit} = p_{c} f_{c} + p_{m} (1 - f_{c})\n$$\nThe probability of a cache miss is $P_{miss} = 1 - P_{hit}$.\n\nNow, we analyze the time saved in each scenario:\n1.  **Cache Hit**: This occurs with probability $P_{hit}$.\n    -   Without caching, the time cost would be $t_{e}$.\n    -   With caching, the process is: compute hash ($t_{h}$), look up key ($t_{\\ell}$), and retrieve the stored result ($t_{r}$). The total cost is $t_{h} + t_{\\ell} + t_{r}$.\n    -   The time saved in this case is $\\Delta T_{hit} = t_{e} - (t_{h} + t_{\\ell} + t_{r})$.\n\n2.  **Cache Miss**: This occurs with probability $P_{miss} = 1 - P_{hit}$.\n    -   Without caching, the time cost would be $t_{e}$.\n    -   With caching, the process is: compute hash ($t_{h}$), look up key ($t_{\\ell}$), perform the FDTD evaluation ($t_{e}$), and store the new result ($t_{s}$). The total cost is $t_{h} + t_{\\ell} + t_{e} + t_{s}$.\n    -   The time saved in this case is $\\Delta T_{miss} = t_{e} - (t_{h} + t_{\\ell} + t_{e} + t_{s}) = -(t_{h} + t_{\\ell} + t_{s})$. This represents a net cost (negative savings) due to the caching overhead.\n\nThe expected time saved per offspring, $E[\\Delta T_{indiv}]$, is the weighted average of the savings in these two cases:\n$$\nE[\\Delta T_{indiv}] = P_{hit} \\cdot \\Delta T_{hit} + (1 - P_{hit}) \\cdot \\Delta T_{miss}\n$$\n$$\nE[\\Delta T_{indiv}] = P_{hit}(t_{e} - t_{h} - t_{\\ell} - t_{r}) + (1 - P_{hit})(-t_{h} - t_{\\ell} - t_{s})\n$$\nExpanding the expression:\n$$\nE[\\Delta T_{indiv}] = P_{hit} t_{e} - P_{hit}(t_{h} + t_{\\ell} + t_{r}) - (t_{h} + t_{\\ell} + t_{s}) + P_{hit}(t_{h} + t_{\\ell} + t_{s})\n$$\n$$\nE[\\Delta T_{indiv}] = P_{hit} t_{e} - P_{hit} t_{h} - P_{hit} t_{\\ell} - P_{hit} t_{r} - t_{h} - t_{\\ell} - t_{s} + P_{hit} t_{h} + P_{hit} t_{\\ell} + P_{hit} t_{s}\n$$\nCanceling and rearranging terms:\n$$\nE[\\Delta T_{indiv}] = P_{hit} t_{e} - (t_{h} + t_{\\ell} + t_{s}) + P_{hit} t_{s} - P_{hit} t_{r}\n$$\n$$\nE[\\Delta T_{indiv}] = P_{hit}(t_{e} + t_{s} - t_{r}) - (t_{h} + t_{\\ell} + t_{s})\n$$\nThe total expected net time saved per generation is $N$ times this value:\n$$\n\\Delta T = N \\left[ P_{hit}(t_{e} + t_{s} - t_{r}) - (t_{h} + t_{\\ell} + t_{s}) \\right]\n$$\nSubstituting the expression for $P_{hit}$:\n$$\n\\Delta T = N \\left[ (p_{c} f_{c} + p_{m} (1 - f_{c}))(t_{e} + t_{s} - t_{r}) - (t_{h} + t_{\\ell} + t_{s}) \\right]\n$$\n\n### Step 3: Numerical Calculation\n\nNow we substitute the given numerical values into the derived formula.\n-   $N = 250$\n-   $f_{c} = 0.85$\n-   $p_{c} = 0.42$\n-   $p_{m} = 0.07$\n-   $t_{e} = 18.5$ s\n-   $t_{h} = 8.0 \\times 10^{-4}$ s $= 0.0008$ s\n-   $t_{\\ell} = 5.0 \\times 10^{-4}$ s $= 0.0005$ s\n-   $t_{r} = 3.0 \\times 10^{-4}$ s $= 0.0003$ s\n-   $t_{s} = 6.0 \\times 10^{-4}$ s $= 0.0006$ s\n\nFirst, calculate the overall hit probability $P_{hit}$:\n$$\nP_{hit} = (0.85)(0.42) + (1 - 0.85)(0.07) = 0.357 + (0.15)(0.07) = 0.357 + 0.0105 = 0.3675\n$$\nNext, calculate the two main terms inside the brackets of the $\\Delta T$ formula.\nThe savings-related term:\n$$\nt_{e} + t_{s} - t_{r} = 18.5 + 0.0006 - 0.0003 = 18.5003 \\text{ s}\n$$\nThe overhead-related term:\n$$\nt_{h} + t_{\\ell} + t_{s} = 0.0008 + 0.0005 + 0.0006 = 0.0019 \\text{ s}\n$$\nNow, substitute these into the expression for $\\Delta T$:\n$$\n\\Delta T = 250 \\left[ (0.3675)(18.5003) - 0.0019 \\right]\n$$\n$$\n\\Delta T = 250 \\left[ 6.79886025 - 0.0019 \\right]\n$$\n$$\n\\Delta T = 250 \\left[ 6.79696025 \\right]\n$$\n$$\n\\Delta T = 1699.2400625 \\text{ s}\n$$\nThe problem requires the answer to be rounded to $4$ significant figures. The number is $1699.2400625$. The first four significant figures are $1$, $6$, $9$, and $9$. The fifth digit is $2$, which is less than $5$, so we round down (truncate).\n$$\n\\Delta T \\approx 1699 \\text{ s}\n$$",
            "answer": "$$\n\\boxed{1699}\n$$"
        }
    ]
}