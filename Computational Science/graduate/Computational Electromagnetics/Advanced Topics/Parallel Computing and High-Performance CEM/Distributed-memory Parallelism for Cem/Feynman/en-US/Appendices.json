{
    "hands_on_practices": [
        {
            "introduction": "Effective parallelization begins with understanding its costs. In domain-decomposed methods like the Finite-Difference Time-Domain (FDTD) algorithm, communication for halo exchanges is a primary performance bottleneck. This first exercise provides practice in analyzing this overhead by identifying the required data transfers on a Yee grid and using the fundamental latency-bandwidth ($\\alpha-\\beta$) model to estimate the total communication time .",
            "id": "3301712",
            "problem": "Consider a three-dimensional Finite-Difference Time-Domain (FDTD) discretization of Maxwell’s equations on a Yee staggered grid, where electric field components $E_x$, $E_y$, $E_z$ and magnetic field components $H_x$, $H_y$, $H_z$ are updated via local curl operations. The computational domain has total dimensions $N_x \\times N_y \\times N_z$ cells and is distributed over a process grid of $P_x \\times P_y \\times P_z$ ranks using a Cartesian partition with periodic boundary conditions, so that each rank communicates with $6$ face-adjacent neighbors. Assume double-precision storage (each field value occupies $8$ bytes). Communication uses halo exchanges with a $1$-cell thickness for the minimum set of neighbor field components required by the Yee update stencils.\n\nThe latency–bandwidth ($\\alpha$–$\\beta$) model describes the point-to-point communication time as $T_{\\text{msg}} = \\alpha + \\beta m$, where $\\alpha$ is the per-message latency, $\\beta$ is the inverse bandwidth expressed in $\\mathrm{s}$/byte, and $m$ is the message size in bytes. Assume that halo exchanges are performed in two sweeps per time step: one for electric fields and one for magnetic fields; in each sweep, one message is sent to each of the $6$ neighbors, aggregating the necessary halo data per face for that field family.\n\nGiven:\n- $N_x = 1024$, $N_y = 512$, $N_z = 256$.\n- $P_x = 8$, $P_y = 4$, $P_z = 2$.\n- Per-message latency $\\alpha = 2 \\times 10^{-6}\\ \\mathrm{s}$.\n- Inverse bandwidth $\\beta = 1 \\times 10^{-10}\\ \\mathrm{s}$/byte.\n\nUse the Yee update structure to determine the minimal $1$-cell halo payload per rank required for the electric field exchange and for the magnetic field exchange (i.e., component-wise on each face, only those components whose update stencils require neighbor data in the direction normal to that face). Then, under the stated aggregation policy (one message per neighbor per sweep), estimate the total per-rank communication time per time step using the $\\alpha$–$\\beta$ model.\n\nRound your final communication time to four significant figures and express your answer in seconds.",
            "solution": "The problem requires an estimation of the total per-rank communication time per time step for a three-dimensional Finite-Difference Time-Domain (FDTD) simulation. The estimation will be based on the provided parameters for the computational domain, process grid, and a latency-bandwidth communication model.\n\nFirst, we determine the dimensions of the computational subdomain allocated to each of the $P = P_x \\times P_y \\times P_z$ processing ranks. The total domain of $N_x \\times N_y \\times N_z$ cells is partitioned in a Cartesian manner. The dimensions of the local subdomain on each rank, denoted by $n_x, n_y, n_z$, are:\n$$n_x = \\frac{N_x}{P_x} = \\frac{1024}{8} = 128 \\text{ cells}$$\n$$n_y = \\frac{N_y}{P_y} = \\frac{512}{4} = 128 \\text{ cells}$$\n$$n_z = \\frac{N_z}{P_z} = \\frac{256}{2} = 128 \\text{ cells}$$\nEach rank manages a cubic subdomain of $128 \\times 128 \\times 128$ cells.\n\nNext, we must determine the data payload for the halo exchanges. The problem specifies a $1$-cell thick halo and requires us to use the \"minimum set\" of field components dictated by the Yee FDTD update stencils. In the Yee scheme, the electric field ($E$) components are updated using the curl of the magnetic field ($H$), and vice-versa. For instance, the update for the $E_y$ component involves a finite difference of $H_z$ in the $x$-direction:\n$$\\frac{\\partial E_y}{\\partial t} \\propto \\frac{\\partial H_x}{\\partial z} - \\frac{\\partial H_z}{\\partial x}$$\nTo compute $E_y$ on the boundary of a subdomain (e.g., on a plane at constant $x$), the finite difference in $x$ requires the value of $H_z$ from the adjacent cell in the neighboring subdomain. A similar analysis shows that updating $E_z$ on a constant-$x$ boundary requires $H_y$ from the neighbor. The update for $E_x$ does not require any data from neighbors in the $x$-direction. Therefore, to update the $E$-field components on a face perpendicular to the $x$-axis, a process must receive a $1$-cell thick layer of the $H_y$ and $H_z$ components from its neighbor in the $x$-direction. These components, $H_y$ and $H_z$, are tangential to the face.\n\nBy symmetry, the components required for exchange across each of the three Cartesian directions are the two field components tangential to the respective faces.\n\\begin{itemize}\n    \\item Across faces perpendicular to the $x$-axis: $E_y, E_z$ are exchanged for the $H$-field update, and $H_y, H_z$ are exchanged for the $E$-field update.\n    \\item Across faces perpendicular to the $y$-axis: $E_x, E_z$ are exchanged for the $H$-field update, and $H_x, H_z$ are exchanged for the $E$-field update.\n    \\item Across faces perpendicular to the $z$-axis: $E_x, E_y$ are exchanged for the $H$-field update, and $H_x, H_y$ are exchanged for the $E$-field update.\n\\end{itemize}\nIn all cases, $2$ field components must be exchanged across each face. The problem states that data is stored in double precision, which corresponds to $8$ bytes per value.\n\nThe communication for one time step consists of two sweeps: one for electric fields and one for magnetic fields. In each sweep, a rank sends one aggregated message to each of its $6$ neighbors. Let's calculate the size of these messages.\n\nFor the electric field sweep (exchanging $E$-fields):\n- Message size to neighbors in $\\pm x$ directions ($m_{E,x}$): The face area is $n_y \\times n_z$. Two components ($E_y, E_z$) are exchanged.\n$$m_{E,x} = n_y \\times n_z \\times 2 \\text{ components} \\times 8 \\frac{\\text{bytes}}{\\text{component}} = 128 \\times 128 \\times 2 \\times 8 = 262144 \\text{ bytes}$$\n- Message size to neighbors in $\\pm y$ directions ($m_{E,y}$): The face area is $n_x \\times n_z$. Two components ($E_x, E_z$) are exchanged.\n$$m_{E,y} = n_x \\times n_z \\times 2 \\times 8 = 128 \\times 128 \\times 2 \\times 8 = 262144 \\text{ bytes}$$\n- Message size to neighbors in $\\pm z$ directions ($m_{E,z}$): The face area is $n_x \\times n_y$. Two components ($E_x, E_y$) are exchanged.\n$$m_{E,z} = n_x \\times n_y \\times 2 \\times 8 = 128 \\times 128 \\times 2 \\times 8 = 262144 \\text{ bytes}$$\nThe message sizes for the magnetic field sweep ($m_{H,x}, m_{H,y}, m_{H,z}$) are identical because the number of components and face dimensions are the same. Let's denote the common message size by $m = 262144$ bytes.\n\nThe total communication time per rank per time step, $T_{\\text{total}}$, is the sum of the times for both sweeps. The time for a single message is given by the $\\alpha$-$\\beta$ model: $T_{\\text{msg}} = \\alpha + \\beta m$.\n\nTime for the $E$-field sweep ($T_E$): This sweep involves sending $6$ messages (one to each neighbor).\n$$T_E = 2 \\times (\\alpha + \\beta m_{E,x}) + 2 \\times (\\alpha + \\beta m_{E,y}) + 2 \\times (\\alpha + \\beta m_{E,z})$$\nSince $m_{E,x} = m_{E,y} = m_{E,z} = m$:\n$$T_E = 2(\\alpha + \\beta m) + 2(\\alpha + \\beta m) + 2(\\alpha + \\beta m) = 6(\\alpha + \\beta m)$$\n\nTime for the $H$-field sweep ($T_H$): Similarly,\n$$T_H = 6(\\alpha + \\beta m)$$\n\nThe total time is the sum of the times for the two sweeps:\n$$T_{\\text{total}} = T_E + T_H = 6(\\alpha + \\beta m) + 6(\\alpha + \\beta m) = 12(\\alpha + \\beta m)$$\n\nNow, we substitute the given values:\n$\\alpha = 2 \\times 10^{-6}\\ \\mathrm{s}$\n$\\beta = 1 \\times 10^{-10}\\ \\mathrm{s}/\\text{byte}$\n$m = 262144\\ \\text{bytes}$\n\n$$T_{\\text{total}} = 12 \\left( (2 \\times 10^{-6}) + (1 \\times 10^{-10}) \\times 262144 \\right)$$\n$$T_{\\text{total}} = 12 \\left( 2 \\times 10^{-6} + 2.62144 \\times 10^{-5} \\right)$$\n$$T_{\\text{total}} = 12 \\left( 0.2 \\times 10^{-5} + 2.62144 \\times 10^{-5} \\right)$$\n$$T_{\\text{total}} = 12 \\left( 2.82144 \\times 10^{-5} \\right)$$\n$$T_{\\text{total}} = 33.85728 \\times 10^{-5} \\ \\mathrm{s}$$\n$$T_{\\text{total}} = 0.0003385728 \\ \\mathrm{s}$$\n\nThe problem requires rounding the final answer to four significant figures.\n$$T_{\\text{total}} \\approx 0.0003386 \\ \\mathrm{s}$$\n\nThis can be expressed in scientific notation as $3.386 \\times 10^{-4}\\ \\mathrm{s}$.",
            "answer": "$$\\boxed{3.386 \\times 10^{-4}}$$"
        },
        {
            "introduction": "Having modeled the cost of communication, the next step is to implement it efficiently. This practice addresses the common challenge of packing noncontiguous halo data, which arises from complex memory layouts like Array-of-Structures (AoS) or from selecting specific slices of a grid. You will learn to construct and validate Message Passing Interface (MPI) derived datatypes, a powerful mechanism for describing these memory patterns directly and avoiding costly manual data marshalling .",
            "id": "3301714",
            "problem": "You are given a three-dimensional Yee-grid discretization used in Computational Electromagnetics (CEM) and a distributed-memory subdomain whose halo exchanges must move noncontiguous edge or face data between neighboring processes. Consider two common memory layouts for field components: Array-of-Structures (AoS) and Structure-of-Arrays (SoA). Let the primitive scalar type be IEEE-754 double precision with size $s_T = 8$ bytes. In the AoS layout, each grid cell stores $C$ components in the fixed order $\\{E_x, E_y, E_z, H_x, H_y, H_z\\}$, so $C = 6$, using row-major storage with the linearized element index\n$$\n\\mathrm{idx}_{\\mathrm{AoS}}(i,j,k,c) \\;=\\; \\bigl( ((i \\cdot n_y) + j) \\cdot n_z + k \\bigr)\\cdot C + c,\n$$\nfor $0 \\le i < n_x$, $0 \\le j < n_y$, $0 \\le k < n_z$, and $0 \\le c < C$. In the SoA layout for a single component array (e.g., $E_x$), the linear index is\n$$\n\\mathrm{idx}_{\\mathrm{SoA}}(i,j,k) \\;=\\; i\\cdot (n_y n_z) + j \\cdot n_z + k.\n$$\nA face halo on the plane $i=i_0$ requires packing a $y\\!-\\!z$ slab, and an edge halo along a coordinate axis requires packing a one-dimensional line of cells at fixed transverse indices. A typical Message Passing Interface (MPI) derived datatype used for noncontiguous data is the vector type, characterized by a triplet $(R,b,s)$ where $R$ is the repetition count, $b$ is the contiguous blocklength (in units of the primitive $T$), and $s$ is the stride (in units of $T$) between starts of consecutive blocks. The byte displacement of the start of block $r$ is $d_r = (d_0 + r\\cdot s)\\cdot s_T$, and the extent (distance from the lowest addressed byte in the type to the highest addressed byte plus one) is\n$$\n\\mathrm{extent} \\;=\\; \\bigl((R-1)\\cdot s + b\\bigr)\\cdot s_T.\n$$\n\nYour task is to construct, for specific halo selections, an equivalent MPI vector derived datatype $(R,b,s)$ that would pack the required noncontiguous entries, and to prove the correctness of its extent and byte-alignment relative to the underlying memory layout. Your program must verify, for each test case, that:\n\n- The computed extent from $(R,b,s)$ matches the extent computed directly from the underlying linear indices of the selected elements.\n- Every block start displacement is a multiple of $s_T$ bytes (alignment).\n- A linear pack using the $(R,b,s)$ specification produces exactly the same ordered sequence of values as a direct element-wise gather from the underlying array using the index definitions above.\n\nYou must start from first principles: use the row-major address mapping given above, the fact that the Yee-grid face $y\\!-\\!z$ slab at fixed $i=i_0$ has $n_y n_z$ cells, and that in the AoS layout selecting a subset $S$ of component indices from each cell produces contiguous mini-blocks of length $|S|$ per cell with stride $C$ between consecutive cells when scanning $(j,k)$ in row-major order. Do not use any specialized MPI library; instead, compute the indices and the $(R,b,s)$ parameters explicitly and validate them algorithmically.\n\nTest suite and required outputs:\n\n- Test case A (AoS, face, tangential electric components):\n  - Parameters: $n_x=4$, $n_y=3$, $n_z=2$, $C=6$, $i_0 = n_x - 1$, tangential electric components to the $x$-normal face are $E_y$ and $E_z$, i.e., $S = \\{1,2\\}$.\n  - Required vector parameters: $R = n_y n_z$, $b = |S|$, $s = C$.\n  - The program must check that the packed sequence matches the direct gather of $\\mathrm{idx}_{\\mathrm{AoS}}(i_0,j,k,c)$ for $(j,k)$ in row-major order and $c \\in S$ in ascending order.\n\n- Test case B (SoA, face, contiguous component slab):\n  - Parameters: $n_x=4$, $n_y=3$, $n_z=2$, component $E_x$ only, face $i_0 = 1$.\n  - Required vector parameters: $R = 1$, $b = n_y n_z$, $s$ arbitrary (it is irrelevant when $R=1$).\n  - The program must check that the pack equals the direct gather of $\\mathrm{idx}_{\\mathrm{SoA}}(i_0,j,k)$ for all $(j,k)$ in row-major order.\n\n- Test case C (AoS, edge along $x$ with single magnetic component):\n  - Parameters: $n_x=5$, $n_y=1$, $n_z=4$, $C=6$, edge along $x$ at $(j_0,k_0)=(0,3)$, magnetic component $H_y$ with component index $c_0=4$.\n  - Required vector parameters: $R = n_x$, $b = 1$, $s = n_y n_z C$.\n  - The program must check that the pack equals the direct gather of $\\mathrm{idx}_{\\mathrm{AoS}}(i,j_0,k_0,c_0)$ for $i$ in ascending order.\n\nFor each test case, the program must return a boolean that is true if and only if all three validations pass (extent equality, alignment of every block start, and exact element-wise pack equivalence). Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[resultA,resultB,resultC]\").\n\nAll answers are in pure booleans; no physical units are required. Angles do not apply.\n\nYour final program must be a complete, self-contained script that constructs the index sets and vector parameters, performs the verifications described above for the specified test suite, and prints a single-line result list as specified.",
            "solution": "The problem requires the validation of Message Passing Interface (MPI) derived vector datatypes for packing noncontiguous halo data in a distributed-memory computational electromagnetics simulation using a three-dimensional Yee-grid. The validation must be performed algorithmically for three specific test cases, covering both Array-of-Structures (AoS) and Structure-of-Arrays (SoA) memory layouts. The core of the task is to confirm that the provided vector datatype parameters $(R, b, s)$ correctly describe the memory layout of the required halo elements.\n\nFirst, we establish the fundamental principles of memory indexing and data packing. The position of a data element in memory is determined by a linearized index, which maps a multi-dimensional grid coordinate to a one-dimensional array index. For a grid of dimensions $n_x \\times n_y \\times n_z$, the memory layouts are defined as follows:\n\nIn the Array-of-Structures (AoS) layout, all $C$ field components for a single grid cell are stored contiguously. The lineal memory index for the component $c$ at grid-point $(i,j,k)$ is given by the row-major formula:\n$$\n\\mathrm{idx}_{\\mathrm{AoS}}(i,j,k,c) \\;=\\; \\bigl( (i \\cdot n_y + j) \\cdot n_z + k \\bigr) \\cdot C + c\n$$\nwhere the term $(i \\cdot n_y + j) \\cdot n_z + k$ is the linear index of the cell, and $c$ is the offset for the specific component within that cell's structure. The indices are in the ranges $0 \\le i < n_x$, $0 \\le j < n_y$, $0 \\le k < n_z$, and $0 \\le c < C$.\n\nIn the Structure-of-Arrays (SoA) layout, each field component is stored in a separate, contiguous array. For a single component array, the index for the element at grid-point $(i,j,k)$ is:\n$$\n\\mathrm{idx}_{\\mathrm{SoA}}(i,j,k) \\;=\\; i \\cdot (n_y n_z) + j \\cdot n_z + k\n$$\n\nAn MPI vector datatype is a powerful tool for describing a pattern of noncontiguous data that consists of equally spaced blocks. It is defined by a triplet $(R,b,s)$:\n- $R$: The repetition count, i.e., the number of blocks.\n- $b$: The blocklength, i.e., the number of contiguous primitive elements in each block.\n- $s$: The stride, i.e., the distance in units of the primitive element size from the start of one block to the start of the next.\n\nThe set of element indices described by such a vector, relative to a starting index $\\mathrm{idx}_{\\mathrm{start}}$, can be generated by the formula:\n$$\n\\mathrm{idx}(r, \\beta) = \\mathrm{idx}_{\\mathrm{start}} + r \\cdot s + \\beta\n$$\nfor $r \\in [0, R-1]$ and $\\beta \\in [0, b-1]$.\n\nThe validation process involves three checks for each test case:\n1.  **Pack Equivalence**: We generate a list of indices by directly iterating through the specified halo elements in the prescribed order (the \"direct gather\"). We then generate a second list of indices using the MPI-style vector formula with the given $(R, b, s)$ parameters, starting from the index of the very first element of the direct gather. The test passes if and only if these two lists are identical.\n2.  **Extent Matching**: The extent of a datatype is the total memory span from its lowest addressed byte to its highest addressed byte plus one. For the MPI vector, this is given by $\\mathrm{extent}_{\\mathrm{MPI}} = \\bigl((R-1) \\cdot s + b\\bigr) \\cdot s_T$, where $s_T$ is the size of the primitive data type in bytes. For the direct gather, the extent is calculated from the minimum and maximum indices found in the gathered set: $\\mathrm{extent}_{\\mathrm{direct}} = (\\mathrm{idx}_{\\mathrm{max}} - \\mathrm{idx}_{\\mathrm{min}} + 1) \\cdot s_T$. The test passes if $\\mathrm{extent}_{\\mathrm{MPI}} = \\mathrm{extent}_{\\mathrm{direct}}$.\n3.  **Alignment**: This check verifies that the starting address of each of the $R$ blocks is a multiple of the primitive type size $s_T$. The byte address of the start of block $r$ is $(\\mathrm{idx}_{\\mathrm{start}} + r \\cdot s) \\cdot s_T$. Since all terms are integers, this byte address is inherently a multiple of $s_T$. The check is thus formally satisfied by construction.\n\nWe now apply this methodology to each test case.\n\n**Test Case A (AoS, face halo)**\n- Parameters: $n_x=4$, $n_y=3$, $n_z=2$, $C=6$, $s_T=8$. Halo at $i_0 = 3$ with components $S=\\{1,2\\}$.\n- Vector spec: $R = n_y n_z = 6$, $b = |S| = 2$, $s = C = 6$.\nThe halo consists of a $y-z$ slab of cells. In row-major order, iterating over $(j,k)$ explores consecutive cells in memory. For each cell, the tangential components $E_y$ (index $c=1$) and $E_z$ (index $c=2$) are contiguous. This forms a block of length $b=2$. The distance between the start of one cell's data and the start of the next (e.g., at $(i_0, j, k)$ and $(i_0, j, k+1)$) is exactly $C$ elements. Thus, the stride $s=C$ is correct. The number of cells in the slab is $n_y n_z$, so the repetition count is $R=n_y n_z$. The provided parameters are consistent with the memory layout. Our algorithmic validation will confirm this.\n\n**Test Case B (SoA, face halo)**\n- Parameters: $n_x=4$, $n_y=3$, $n_z=2$, $s_T=8$. Halo at $i_0 = 1$ for a single component array.\n- Vector spec: $R = 1$, $b = n_y n_z = 6$. The stride $s$ is irrelevant.\nIn the SoA layout, a $y-z$ slab at a fixed $i_0$ is a contiguous block of memory. The indices $\\mathrm{idx}_{\\mathrm{SoA}}(i_0, j, k) = i_0(n_y n_z) + j n_z + k$ are consecutive as $(j,k)$ are varied in row-major order. Therefore, the entire halo can be described as a single block ($R=1$) of length $b=n_y n_z$. The parameters are correct.\n\n**Test Case C (AoS, edge halo)**\n- Parameters: $n_x=5$, $n_y=1$, $n_z=4$, $C=6$, $s_T=8$. Edge at $(j_0,k_0)=(0,3)$ with component $c_0=4$.\n- Vector spec: $R = n_x = 5$, $b = 1$, $s = n_y n_z C = 24$.\nThe halo consists of a single component from each cell along a line in the $x$-direction. We pack one element per cell, so the blocklength is $b=1$. The repetitions are over the $x$-dimension, so $R=n_x$. The stride is the distance between the same component in adjacent cells along the $x$-axis, i.e., between $(i, j_0, k_0)$ and $(i+1, j_0, k_0)$. The difference in their linear cell indices is $((i+1)n_y + j_0)n_z+k_0 - ((i \\cdot n_y + j_0)n_z+k_0) = n_y n_z$. Since each cell structure has size $C$, the stride in elements is $s = n_y n_z C$. The parameters are consistent.\n\nThe provided Python code implements the `verify_case` function, which performs the three validation checks for a generic case, and then applies it to the specific parameters of Test Cases A, B, and C, reporting a boolean for each.",
            "answer": "```python\nimport numpy as np\n\ndef verify_case(layout, params, halo_selection, vector_spec):\n    \"\"\"\n    Verifies the correctness of an MPI vector datatype for a given halo selection.\n    \n    Args:\n        layout (str): Memory layout, 'AoS' or 'SoA'.\n        params (dict): Grid and data type parameters (nx, ny, nz, C, sT).\n        halo_selection (dict): Description of the halo elements to pack.\n        vector_spec (dict): The MPI vector parameters (R, b, s) to validate.\n\n    Returns:\n        bool: True if all three validations (pack equivalence, extent, alignment) pass.\n    \"\"\"\n    # Unpack parameters\n    nx, ny, nz = params.get('nx'), params.get('ny'), params.get('nz')\n    sT = params.get('sT')\n    R, b, s = vector_spec['R'], vector_spec['b'], vector_spec['s']\n\n    # --- Step 1: Generate direct gather indices in the specified order ---\n    direct_indices = []\n    if layout == 'AoS':\n        C = params['C']\n        def idx_aos(i, j, k, c):\n            return (((i * ny) + j) * nz + k) * C + c\n        \n        selection_type = halo_selection['type']\n        if selection_type == 'face':\n            i0 = halo_selection['i0']\n            S = halo_selection['S']\n            for j in range(ny):\n                for k in range(nz):\n                    for c in sorted(S):\n                        direct_indices.append(idx_aos(i0, j, k, c))\n        elif selection_type == 'edge':\n            j0, k0 = halo_selection['j0'], halo_selection['k0']\n            c0 = halo_selection['c0']\n            for i in range(nx):\n                direct_indices.append(idx_aos(i, j0, k0, c0))\n    elif layout == 'SoA':\n        def idx_soa(i, j, k):\n            return i * (ny * nz) + j * nz + k\n\n        selection_type = halo_selection['type']\n        if selection_type == 'face':\n            i0 = halo_selection['i0']\n            for j in range(ny):\n                for k in range(nz):\n                    direct_indices.append(idx_soa(i0, j, k))\n    \n    if not direct_indices:\n        return False\n\n    # --- Step 2: Generate MPI-style pack indices ---\n    start_index = direct_indices[0]\n    pack_indices = []\n    for r in range(R):\n        block_start_index = start_index + r * s\n        for i in range(b):\n            pack_indices.append(block_start_index + i)\n            \n    # --- Step 3: Perform Verifications ---\n    \n    # Verification 1: Pack Equivalence\n    # Checks if the sequence of elements gathered matches the sequence from the vector type.\n    pack_equivalence_ok = (direct_indices == pack_indices)\n\n    # Verification 2: Extent Equality\n    # The MPI extent formula defines the span of the datatype in memory.\n    extent_mpi = ((R - 1) * s + b) * sT\n    \n    # The direct extent is the span from the first byte of the first selected element\n    # to the last byte of the last selected element.\n    idx_min = direct_indices[0]\n    idx_max = direct_indices[-1]\n    extent_direct = (idx_max - idx_min + 1) * sT\n    \n    extent_equality_ok = (extent_mpi == extent_direct)\n\n    # Verification 3: Alignment\n    # Checks if the start of each block is aligned to the primitive type size.\n    # This is formally true by construction but is checked explicitly.\n    alignment_ok = True\n    for r in range(R):\n        block_start_index = start_index + r * s\n        block_start_displacement_bytes = block_start_index * sT\n        if block_start_displacement_bytes % sT != 0:\n            alignment_ok = False\n            break\n\n    return pack_equivalence_ok and extent_equality_ok and alignment_ok\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define common parameters\n    sT = 8 # bytes for double precision\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        {\n            'name': 'A',\n            'layout': 'AoS',\n            'params': {'nx': 4, 'ny': 3, 'nz': 2, 'C': 6, 'sT': sT},\n            'halo_selection': {'type': 'face', 'i0': 4 - 1, 'S': {1, 2}},\n            'vector_spec': {'R': 3 * 2, 'b': 2, 's': 6}\n        },\n        {\n            'name': 'B',\n            'layout': 'SoA',\n            'params': {'nx': 4, 'ny': 3, 'nz': 2, 'sT': sT},\n            'halo_selection': {'type': 'face', 'i0': 1},\n            'vector_spec': {'R': 1, 'b': 3 * 2, 's': 3 * 2} # s is arbitrary when R=1\n        },\n        {\n            'name': 'C',\n            'layout': 'AoS',\n            'params': {'nx': 5, 'ny': 1, 'nz': 4, 'C': 6, 'sT': sT},\n            'halo_selection': {'type': 'edge', 'j0': 0, 'k0': 3, 'c0': 4},\n            'vector_spec': {'R': 5, 'b': 1, 's': 1 * 4 * 6}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = verify_case(\n            case['layout'],\n            case['params'],\n            case['halo_selection'],\n            case['vector_spec']\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Beyond performance, the correctness and reproducibility of results are paramount in scientific computing. This final practice explores a subtle but critical issue: the non-associativity of floating-point addition, which can cause parallel reductions to yield different results depending on the execution environment. By analyzing a carefully constructed scenario, you will quantify this effect and design a reduction scheme that guarantees bitwise-reproducible results, a key principle for ensuring numerical integrity in large-scale simulations .",
            "id": "3301755",
            "problem": "A three-dimensional Finite-Difference Time-Domain (FDTD) simulation in computational electromagnetics is executed on a distributed-memory cluster using the Message Passing Interface (MPI). At a single time step, a global diagnostic is formed as a domain sum of a signed conservation residual (normalized and dimensionless), which accumulates local process contributions. Due to numerical cancellation and differences in summation order, the global sum can vary across different MPI reduction trees because floating-point addition is not associative.\n\nConsider three MPI ranks with local contributions stored in IEEE 754 binary64 (double precision) floating-point format:\n$$\nr_0 = 2^{54}, \\quad r_1 = 3, \\quad r_2 = -2^{54}.\n$$\nTwo distinct MPI reduction trees are used for the global sum over $\\{r_0, r_1, r_2\\}$, both performing pairwise floating-point additions with round-to-nearest, ties-to-even:\n\n1. Tree A (left-deep): compute $$((r_0 + r_1) + r_2).$$\n2. Tree B (balanced): compute $$((r_0 + r_2) + r_1).$$\n\nStarting from the standard floating-point model and the definition of unit roundoff and representable spacing at a given magnitude, derive the two global sums produced by Tree A and Tree B, and the absolute difference between them. Then, design a reduction scheme that guarantees bitwise reproducibility of the global diagnostic across arbitrary MPI reduction trees by enforcing a mathematically well-defined summation result independent of process count and order. Using that scheme, determine the bitwise reproducible global diagnostic for the given dataset $\\{r_0, r_1, r_2\\}$.\n\nExpress the final diagnostic value as a dimensionless number. Round your final answer to four significant figures.",
            "solution": "The problem analyzes the summation of three numbers, $r_0 = 2^{54}$, $r_1 = 3$, and $r_2 = -2^{54}$, using IEEE 754 `binary64` (double precision) arithmetic with the round-to-nearest, ties-to-even rounding mode.\n\nIn the `binary64` format, a number is represented with a significand precision of $p = 53$ bits (one implicit leading bit and $52$ explicit fraction bits). The unit roundoff, or machine epsilon, is $\\varepsilon_{\\text{mach}} = 2^{1-p} = 2^{-52}$. The spacing between representable floating-point numbers, known as the Unit in the Last Place (ULP), depends on the magnitude of the number. For a number $x$ whose value is close to $2^E$, the ULP is given by $\\text{ulp}(x) = 2^{E - (p-1)} = \\varepsilon_{\\text{mach}} \\cdot 2^E$.\n\nFor the given value $r_0 = 2^{54}$, the exponent is $E=54$. The ULP in this range is:\n$$\n\\text{ulp}(2^{54}) = 2^{54 - (53-1)} = 2^{54-52} = 2^2 = 4\n$$\nThis means that any real number in the interval $[2^{54}, 2^{54}+4)$ can only be represented as either $2^{54}$ or $2^{54}+4$.\n\n**Tree A: Left-deep reduction `((r_0 + r_1) + r_2)`**\n\nFirst, we compute the intermediate sum $S_{A1} = fl(r_0 + r_1)$, where $fl(\\cdot)$ denotes the floating-point evaluation.\n$$\nS_{A1} = fl(2^{54} + 3)\n$$\nThe exact result is $2^{54} + 3$. This value is not exactly representable in `binary64` format, as the representable numbers near $2^{54}$ are integer multiples of $\\text{ulp}(2^{54}) = 4$. The two machine-representable numbers bracketing the exact sum are $N_1 = 2^{54}$ and $N_2 = 2^{54} + 4$.\n\nTo apply the round-to-nearest rule, we find the distances to these numbers:\n- Distance to $N_1$: $|(2^{54} + 3) - 2^{54}| = 3$\n- Distance to $N_2$: $|(2^{54} + 3) - (2^{54} + 4)| = |-1| = 1$\n\nSince the exact result is closer to $N_2$, the sum is rounded up. This phenomenon, where a small number is lost when added to a large number, is known as swamping.\n$$\nS_{A1} = 2^{54} + 4\n$$\nNext, we compute the final sum for Tree A, $S_A = fl(S_{A1} + r_2)$:\n$$\nS_A = fl((2^{54} + 4) + (-2^{54}))\n$$\nThe argument to $fl(\\cdot)$ is exactly $4$. Since $4$ ($=1.0 \\times 2^2$) is exactly representable in `binary64` format, no rounding is necessary.\n$$\nS_A = 4\n$$\n\n**Tree B: Balanced reduction `((r_0 + r_2) + r_1)`**\n\nFirst, we compute the intermediate sum $S_{B1} = fl(r_0 + r_2)$:\n$$\nS_{B1} = fl(2^{54} + (-2^{54})) = fl(0)\n$$\nBoth $2^{54}$ and $-2^{54}$ are exactly representable, and their sum is exactly $0$, which is also exactly representable. This operation results in catastrophic cancellation, but in this specific instance, the result is exact.\n$$\nS_{B1} = 0\n$$\nNext, we compute the final sum for Tree B, $S_B = fl(S_{B1} + r_1)$:\n$$\nS_B = fl(0 + 3)\n$$\nThe number $3$ is also exactly representable in `binary64` format ($3 = 1.5 \\times 2^1$). Thus, the sum is exact.\n$$\nS_B = 3\n$$\n\n**Difference between Tree A and Tree B**\n\nThe absolute difference between the two computed global sums is:\n$$\n|S_A - S_B| = |4 - 3| = 1\n$$\nThis discrepancy is a direct consequence of the non-associativity of floating-point addition.\n\n**Design of a Reproducible Reduction Scheme**\n\nTo guarantee bitwise reproducibility, the reduction scheme must produce a result that is independent of the summation order and process count. This requires enforcing a mathematically well-defined result. The ideal result is the exact mathematical sum of the contributions.\n\nThe designed scheme is an **exact summation algorithm**. Such algorithms avoid intermediate rounding errors by using a \"superaccumulator,\" which is a data structure capable of representing the sum of floating-point numbers exactly. A common implementation of this concept involves representing the sum as an unevaluated series of non-overlapping floating-point numbers (a floating-point expansion). When a new number is added, it is incorporated into this expansion without any loss of precision. The final floating-point result is obtained by rounding the exact sum stored in the superaccumulator only once at the very end.\n\nThis approach ensures that the fundamental arithmetic is effectively associative and commutative, thereby making the final sum independent of the reduction tree structure (i.e., the order of operations). Algorithms developed by D. E. Knuth, M. J. D. Powell, T. J. Dekker, and more recently Jonathan Shewchuk, provide practical implementations of this principle. Python's `math.fsum` function is a well-known example of such an algorithm.\n\n**Application of the Reproducible Scheme**\n\nApplying this scheme to the given dataset $\\{r_0, r_1, r_2\\}$ involves computing the true mathematical sum. The exact summation algorithm, by its nature, will yield this result.\n$$\nS_{\\text{reproducible}} = r_0 + r_1 + r_2 = 2^{54} + 3 + (-2^{54}) = 3\n$$\nThis result is independent of the order in which $r_0$, $r_1$, and $r_2$ are accumulated. The bitwise reproducible global diagnostic is therefore $3$. Expressed with four significant figures, this value is $3.000$.",
            "answer": "$$\n\\boxed{3.000}\n$$"
        }
    ]
}