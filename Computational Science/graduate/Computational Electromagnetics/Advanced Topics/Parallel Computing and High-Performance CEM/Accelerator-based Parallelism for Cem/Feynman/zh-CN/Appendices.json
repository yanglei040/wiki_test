{
    "hands_on_practices": [
        {
            "introduction": "在计算电磁学中，稀疏矩阵向量乘法 (SpMV) 是许多迭代求解器的核心。在受内存带宽限制的 GPU 架构上，其性能主要取决于数据移动而非浮点计算能力。本练习将引导你通过第一性原理，为两种常见的稀疏矩阵存储格式（CSR 和 ELL）推导内存流量模型，从而量化预测其性能上限，这是进行性能优化的第一步。",
            "id": "3287509",
            "problem": "考虑在计算电磁学（CEM）中，由麦克斯韦方程组的旋度-旋度算子离散化产生的稀疏矩阵向量乘积 $y \\leftarrow A x$。矩阵 $A$ 是一个 $n \\times n$ 的方阵，其平均行长度为 $r$，非零元素总数为 $\\text{nnz}$，因此 $n = \\text{nnz}/r$。该计算在图形处理器（GPU）上执行，并受限于设备的全局内存带宽。\n\n假设如下：\n- 每个矩阵和向量值以 $b_{v}$ 字节存储，每个列索引或行指针以 $b_{i}$ 字节存储。\n- 稀疏矩阵以压缩稀疏行（CSR）格式或Ellpack-Itpack（ELL）格式存储。对于ELL格式，假设模板是均匀的，因此每行的存储宽度恰好等于 $r$（除了 $r$ 之外没有填充开销）。\n- 对于CSR格式，每行访问一次行指针数组以获取范围边界（每行两个指针）。\n- 向量 $y$ 每行使用流式存储写入一次（忽略写分配惩罚）。\n- 定义一个向量重用因子 $\\theta \\in [1,r]$，使得平均而言，$x$ 中一个元素的单次全局内存加载可服务于 $\\theta$ 个非零元素的贡献，然后才需要再次对该元素进行全局内存加载。换句话说，$x$ 的全局加载次数为 $\\text{nnz}/\\theta$。\n- GPU 具有持续的全局内存带宽 $W$，单位为字节/秒。\n\n从数据移动的第一性原理出发，并基于矩阵 $A$ 中每个非零元贡献一次乘法和一次加法（每个非零元总计 $2$ 次浮点运算）这一事实，推导每种存储格式（CSR 和 ELL）下，单次稀疏矩阵向量乘积的总全局内存流量，并将其表示为 $r$、$\\text{nnz}$、$b_{v}$、$b_{i}$ 和 $\\theta$ 的函数。利用这些流量结果，预测在带宽为 $W$ 的 GPU 上，每种格式的带宽限制性能（以每秒浮点运算次数为单位），并以闭式解析表达式的形式提供您的最终答案。\n\n以每秒浮点运算次数（FLOP/s）表示最终性能值。按 CSR、ELL 的顺序列出两个结果。",
            "solution": "所述问题具有科学依据，提法恰当，并包含足够的信息来推导所要求的性能模型。因此，该问题被认为是有效的。本解答将通过推导每种指定稀疏矩阵格式的总内存流量和由此产生的性能来进行。\n\n对于带宽限制的计算，其基本原理是性能（以每秒浮点运算次数，即 $\\text{FLOP/s}$ 衡量）等于浮点运算总数与计算总耗时之比。总时间 $t$ 由传入和传出全局内存的数据总量（称为总流量 $T$）和持续内存带宽 $W$ 决定。\n\n对于稀疏矩阵向量乘积，浮点运算总数（$\\text{FLOPs}$）为矩阵的每个非零元素进行 $2$ 次运算（一次乘法，一次加法）。对于 $\\text{nnz}$ 个非零元素，我们有：\n$$\n\\text{Total FLOPs} = 2 \\times \\text{nnz}\n$$\n执行时间 $t$ 是总流量除以带宽：\n$$\nt = \\frac{T}{W}\n$$\n因此，性能 $P$ 可以表示为：\n$$\nP = \\frac{\\text{Total FLOPs}}{t} = \\frac{2 \\times \\text{nnz}}{T/W} = \\frac{2 \\times \\text{nnz} \\times W}{T}\n$$\n问题的核心是确定每种存储格式的总流量 $T$。总流量是读取矩阵 $A$ 的字节数、读取输入向量 $x$ 的字节数以及写入输出向量 $y$ 的字节数之和。\n\n首先，我们定义两种存储格式共有的流量组成部分。\n读取输入向量 $x$ 的流量（记为 $T_x$）取决于重用因子 $\\theta$。问题指出，$x$ 的全局加载次数为 $\\frac{\\text{nnz}}{\\theta}$，每个元素的大小为 $b_v$ 字节。\n$$\nT_x = \\frac{\\text{nnz}}{\\theta} \\times b_v\n$$\n写入输出向量 $y$ 的流量（记为 $T_y$）涉及为矩阵的 $n$ 行中的每一行写入一个大小为 $b_v$ 的元素。\n$$\nT_y = n \\times b_v\n$$\n使用给定的关系式 $n = \\frac{\\text{nnz}}{r}$，这变为：\n$$\nT_y = \\frac{\\text{nnz}}{r} \\times b_v\n$$\n\n接下来，我们推导每种特定格式的表达式。\n\n**1. 压缩稀疏行（CSR）格式**\n\nCSR 格式的总内存流量 $T_{\\text{CSR}}$ 是矩阵数据结构和向量的流量之和。\nCSR 格式的矩阵 $A$ 需要读取三个数组：\n- 非零值数组：$\\text{nnz}$ 个元素，每个元素大小为 $b_v$ 字节。流量为 $\\text{nnz} \\times b_v$。\n- 列索引数组：$\\text{nnz}$ 个元素，每个元素大小为 $b_i$ 字节。流量为 $\\text{nnz} \\times b_i$。\n- 行指针数组：问题指明为 $n$ 行中的每一行读取两个指针。每个指针为 $b_i$ 字节。流量为 $2 \\times n \\times b_i = 2 \\times \\frac{\\text{nnz}}{r} \\times b_i$。\n\n读取 CSR 格式矩阵 $A$ 的流量 $T_{A, \\text{CSR}}$ 是这些部分的总和：\n$$\nT_{A, \\text{CSR}} = (\\text{nnz} \\times b_v) + (\\text{nnz} \\times b_i) + \\left(2 \\times \\frac{\\text{nnz}}{r} \\times b_i\\right)\n$$\n总流量 $T_{\\text{CSR}}$ 是矩阵流量、输入向量流量和输出向量流量的总和：\n$$\nT_{\\text{CSR}} = T_{A, \\text{CSR}} + T_x + T_y = \\left(\\text{nnz} \\cdot b_v + \\text{nnz} \\cdot b_i + \\frac{2 \\cdot \\text{nnz} \\cdot b_i}{r}\\right) + \\left(\\frac{\\text{nnz} \\cdot b_v}{\\theta}\\right) + \\left(\\frac{\\text{nnz} \\cdot b_v}{r}\\right)\n$$\n提取公因式 $\\text{nnz}$：\n$$\nT_{\\text{CSR}} = \\text{nnz} \\left( b_v + b_i + \\frac{2 b_i}{r} + \\frac{b_v}{\\theta} + \\frac{b_v}{r} \\right)\n$$\n按 $b_v$ 和 $b_i$ 合并同类项：\n$$\nT_{\\text{CSR}} = \\text{nnz} \\left[ b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\left(1 + \\frac{2}{r}\\right) \\right]\n$$\n那么 CSR 的性能 $P_{\\text{CSR}}$ 为：\n$$\nP_{\\text{CSR}} = \\frac{2 \\times \\text{nnz} \\times W}{T_{\\text{CSR}}} = \\frac{2 \\times \\text{nnz} \\times W}{\\text{nnz} \\left[ b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\left(1 + \\frac{2}{r}\\right) \\right]}\n$$\n$\\text{nnz}$ 项被约去，得到最终的性能表达式：\n$$\nP_{\\text{CSR}} = \\frac{2 W}{b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\left(1 + \\frac{2}{r}\\right)}\n$$\n\n**2. Ellpack-Itpack (ELL) 格式**\n\n对于 ELL 格式，在行长度 $r$ 均匀且无填充的情况下，矩阵数据存储在两个大小为 $n \\times r$ 的数组中。每个数组中存储的元素总数为 $n \\times r = (\\frac{\\text{nnz}}{r}) \\times r = \\text{nnz}$。\n读取 ELL 格式矩阵 $A$ 的流量 $T_{A, \\text{ELL}}$ 为：\n- 非零值数组：$\\text{nnz}$ 个元素，每个元素大小为 $b_v$ 字节。流量为 $\\text{nnz} \\times b_v$。\n- 列索引数组：$\\text{nnz}$ 个元素，每个元素大小为 $b_i$ 字节。流量为 $\\text{nnz} \\times b_i$。\n没有行指针数组。\n$$\nT_{A, \\text{ELL}} = (\\text{nnz} \\times b_v) + (\\text{nnz} \\times b_i)\n$$\nELL 格式的总流量 $T_{\\text{ELL}}$ 为：\n$$\nT_{\\text{ELL}} = T_{A, \\text{ELL}} + T_x + T_y = (\\text{nnz} \\cdot b_v + \\text{nnz} \\cdot b_i) + \\left(\\frac{\\text{nnz} \\cdot b_v}{\\theta}\\right) + \\left(\\frac{\\text{nnz} \\cdot b_v}{r}\\right)\n$$\n提取公因式 $\\text{nnz}$ 并合并同类项：\n$$\nT_{\\text{ELL}} = \\text{nnz} \\left[ b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\right]\n$$\n那么 ELL 的性能 $P_{\\text{ELL}}$ 为：\n$$\nP_{\\text{ELL}} = \\frac{2 \\times \\text{nnz} \\times W}{T_{\\text{ELL}}} = \\frac{2 \\times \\text{nnz} \\times W}{\\text{nnz} \\left[ b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\right]}\n$$\n$\\text{nnz}$ 项被约去，得到最终的性能表达式：\n$$\nP_{\\text{ELL}} = \\frac{2 W}{b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i}\n$$\n这两个推导出的表达式代表了在给定假设下 CSR 和 ELL 格式的带宽限制性能。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{2 W}{b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\left(1 + \\frac{2}{r}\\right)}  \\frac{2 W}{b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "理论模型是理解性能瓶颈的有力工具，其中 Roofline 模型尤为重要。它通过计算核心的算术强度 (Arithmetic Intensity) 及其与硬件内存带宽和峰值计算性能的关系，来判断计算任务是受内存限制还是计算限制。本练习将带你实际计算一个典型 SpMV 核心的算术强度，应用 Roofline 模型预测其性能边界，并与给定的实测性能进行比较，以推断如非合并内存访问等次级性能瓶颈的存在。",
            "id": "3287482",
            "problem": "一个三维频域计算电磁学 (CEM) 求解器在一个图形处理器 (GPU) 加速器上使用压缩稀疏行 (CSR) 格式的稀疏矩阵向量乘法 (SpMV) 核函数来应用离散化的旋度-旋度算子。计算采用双精度。每个非零元对输出累加贡献一次乘法和一次加法，并且在累加结束时，每行存储一次输出向量的元素。CSR 数据结构的布局方式使得矩阵值和列索引从设备内存（动态随机存取存储器, DRAM）中读取，而输入向量元素由于重用而具有部分局部性，仅在缓存未命中时才由设备内存提供服务。\n\n假设以下科学上一致的参数：\n- 每行平均非零元数 $r = 40$。\n- 输入向量在二级缓存的命中率 $h = 0.6$（因此有 $1 - h$ 比例的输入向量读取请求会访问 DRAM）。\n- 矩阵值大小：每个非零元 $8\\,\\mathrm{B}$（双精度）。\n- 列索引大小：每个非零元 $4\\,\\mathrm{B}$（32位整数）。\n- 输出向量存储大小：每行 $8\\,\\mathrm{B}$（双精度），摊销到该行的 $r$ 个非零元上。\n- 加速器的峰值双精度浮点吞吐量 $F = 10 \\times 10^{12}\\,\\mathrm{FLOP/s}$。\n- 可持续的设备内存带宽 $W = 1.6 \\times 10^{12}\\,\\mathrm{B/s}$。\n- 该算子在加速器上测得的 SpMV 性能 $P_{\\mathrm{meas}} = 0.14 \\times 10^{12}\\,\\mathrm{FLOP/s}$。\n\n从关于吞吐量约束、算术强度以及数据移动与计算关系的第一性原理出发，完成以下任务：\n1. 在给定假设下，通过计算浮点运算和每个非零元摊销的设备内存流量，推导出此 SpMV 的算术强度 $I$（单位为 $\\mathrm{FLOP/B}$）。\n2. 用 $F$、$W$ 和 $I$ 表示此加速器上 SpMV 浮点速率可达到的最紧密上界，并计算其数值。\n3. 将最终上界表示为以 $\\mathrm{TFLOP/s}$ 为单位的单个数字，并四舍五入到三位有效数字。\n4. 在你的推理中，将此上界与 $P_{\\mathrm{meas}}$ 进行比较，以推断主导的瓶颈区域，并讨论非合并访问或缓存颠簸等现象是否是可能的贡献因素。\n\n只有第3项要求的数值上界将作为最终答案评分。将你的答案四舍五入到三位有效数字。以 $\\mathrm{TFLOP/s}$ 为单位表示最终上界。",
            "solution": "本问题要求使用 Roofline 性能模型的原理来分析图形处理器 (GPU) 上的稀疏矩阵向量乘法 (SpMV) 核函数的性能。我们必须首先验证问题陈述。\n\n### 步骤1：提取已知条件\n- 计算：每个非零元1次乘法和1次加法，即每个非零元2次浮点运算 (FLOP)。\n- 数据格式：双精度，压缩稀疏行 (CSR)。\n- 每行平均非零元数：$r = 40$。\n- 输入向量二级缓存命中率：$h = 0.6$。\n- 矩阵值大小：每个非零元 $8\\,\\mathrm{B}$。\n- 列索引大小：每个非零元 $4\\,\\mathrm{B}$。\n- 输出向量存储大小：每行 $8\\,\\mathrm{B}$。\n- 峰值双精度浮点吞吐量：$F = 10 \\times 10^{12}\\,\\mathrm{FLOP/s}$。\n- 可持续设备内存带宽：$W = 1.6 \\times 10^{12}\\,\\mathrm{B/s}$。\n- 测得的 SpMV 性能：$P_{\\mathrm{meas}} = 0.14 \\times 10^{12}\\,\\mathrm{FLOP/s}$。\n\n### 步骤2：使用提取的已知条件进行验证\n问题陈述提供了一组用于建模 SpMV 核函数性能的参数。这些参数，如内存带宽、峰值 FLOP 速率、数据结构大小和缓存行为，是高性能计算中性能分析的典型参数。该场景在科学上基于计算科学和计算机体系结构的原理，特别是将处理器性能与内存带宽和算术强度相关联的 Roofline 模型。该问题是自洽的，为推导提供了所有必要的数据。各个量在物理上是一致的（例如，大小以字节为单位，速率以操作/秒或字节/秒为单位）。该问题是适定的、客观的，并且没有违反任何科学原理。\n\n### 步骤3：结论与行动\n问题有效。我们将继续进行解答。\n\n解决方案包括四个部分：(1) 推导算术强度 $I$，(2) 推导理论性能上界，(3) 用数值表示该上界，以及 (4) 在上下文中讨论结果。\n\n**1. 算术强度 ($I$) 的推导**\n\n算术强度 $I$ 定义为执行的浮点运算次数与主设备内存 (DRAM) 之间传输的总数据字节数之比。\n\n首先，我们计算每个非零元的 FLOP 次数。问题陈述指出，每个非零元贡献一次乘法和一次加法。\n$$\n\\text{每个非零元的 FLOP 数} = 1 \\, (\\text{乘法}) + 1 \\, (\\text{加法}) = 2 \\, \\mathrm{FLOP}\n$$\n\n接下来，我们计算从/向 DRAM 传输的总字节数，并将其摊销到每个非零元上。这种流量包括读取矩阵数据（值和索引）、读取输入向量元素以及写入输出向量元素。\n\n- **矩阵数据流量：** 对于每个非零元，我们必须从 DRAM 中读取其值和列索引。\n  - 矩阵值（双精度）：$8\\,\\mathrm{B}$\n  - 列索引（32位整数）：$4\\,\\mathrm{B}$\n  - 矩阵数据每非零元的流量 = $8\\,\\mathrm{B} + 4\\,\\mathrm{B} = 12\\,\\mathrm{B}$。\n\n- **输入向量流量：** 对于每个非零元，必须读取输入向量的一个元素。元素大小为双精度，即 $8\\,\\mathrm{B}$。此读取操作受缓存影响。缓存命中率为 $h = 0.6$，则未命中率为 $1 - h = 0.4$。只有缓存未命中才会导致从 DRAM 产生流量。\n  - 输入向量每非零元的流量 = $(1 - h) \\times (\\text{双精度大小}) = (1 - 0.6) \\times 8\\,\\mathrm{B} = 0.4 \\times 8\\,\\mathrm{B} = 3.2\\,\\mathrm{B}$。\n\n- **输出向量流量：** 每行写入输出向量的一个元素。对于每 $r$ 个非零元（其中 $r=40$），这是一次 $8\\,\\mathrm{B}$ 的写入操作。该流量成本摊销到该行的非零元上。\n  - 输出向量每非零元的流量 = $\\frac{8\\,\\mathrm{B}}{r} = \\frac{8\\,\\mathrm{B}}{40} = 0.2\\,\\mathrm{B}$。\n\n每个非零元的总内存流量是这些分量的总和：\n$$\n\\text{每个非零元的字节数} = 12\\,\\mathrm{B} + 3.2\\,\\mathrm{B} + 0.2\\,\\mathrm{B} = 15.4\\,\\mathrm{B}\n$$\n\n现在，我们可以计算算术强度 $I$：\n$$\nI = \\frac{\\text{每个非零元的 FLOP 数}}{\\text{每个非零元的字节数}} = \\frac{2\\,\\mathrm{FLOP}}{15.4\\,\\mathrm{B}} = \\frac{10}{77}\\,\\mathrm{FLOP/B}\n$$\n数值上，$I \\approx 0.12987\\,\\mathrm{FLOP/B}$。\n\n**2. 性能上界的推导**\n\nRoofline 模型假定，可达到的性能 $P$ 受限于峰值计算吞吐量 ($F$) 和由内存带宽 ($W$) 与算术强度 ($I$) 决定的性能的最小值。\n可达到的最紧密上界 $P_{\\mathrm{bound}}$ 由下式给出：\n$$\nP_{\\mathrm{bound}} = \\min(F, I \\times W)\n$$\n给定 $F = 10 \\times 10^{12}\\,\\mathrm{FLOP/s}$ 和 $W = 1.6 \\times 10^{12}\\,\\mathrm{B/s}$。我们来计算内存限制的性能 $I \\times W$：\n$$\nI \\times W = \\left(\\frac{10}{77}\\,\\mathrm{FLOP/B}\\right) \\times \\left(1.6 \\times 10^{12}\\,\\mathrm{B/s}\\right) = \\frac{16}{77} \\times 10^{12}\\,\\mathrm{FLOP/s}\n$$\n计算其数值：\n$$\n\\frac{16}{77} \\approx 0.207792...\n$$\n因此，内存限制的性能约为 $0.2078 \\times 10^{12}\\,\\mathrm{FLOP/s}$。\n\n现在我们将其与峰值计算性能 $F$ 进行比较：\n$$\nP_{\\mathrm{bound}} = \\min(10 \\times 10^{12}\\,\\mathrm{FLOP/s}, \\, 0.2078 \\times 10^{12}\\,\\mathrm{FLOP/s})\n$$\n最小值显然是内存限制的值。\n$$\nP_{\\mathrm{bound}} \\approx 0.2078 \\times 10^{12}\\,\\mathrm{FLOP/s}\n$$\n\n**3. 以 TFLOP/s 为单位的最终上界**\n\n最终答案必须以 TFLOP/s 为单位，并四舍五入到三位有效数字。\n$1\\,\\mathrm{TFLOP/s} = 10^{12}\\,\\mathrm{FLOP/s}$。\n$$\nP_{\\mathrm{bound}} \\approx 0.2078\\,\\mathrm{TFLOP/s}\n$$\n四舍五入到三位有效数字得到 $0.208\\,\\mathrm{TFLOP/s}$。\n\n**4. 瓶颈讨论**\n\n- **主要瓶颈：** 计算表明 $I \\times W \\approx 0.208\\,\\mathrm{TFLOP/s}$，而 $F = 10\\,\\mathrm{TFLOP/s}$。由于 $I \\times W \\ll F$，该 SpMV 核函数是强 **内存限制** 的。其性能由从设备内存读取和存储数据的速率决定，而不是由 GPU 浮点单元的原始计算能力决定。\n\n- **与实测性能的比较：** 推导出的理论上界为 $P_{\\mathrm{bound}} \\approx 0.208\\,\\mathrm{TFLOP/s}$。给出的实测性能为 $P_{\\mathrm{meas}} = 0.14\\,\\mathrm{TFLOP/s}$。实测性能达到了理论上界的约 $\\frac{P_{\\mathrm{meas}}}{P_{\\mathrm{bound}}} = \\frac{0.14}{0.208} \\approx 67.3\\%$。这表明虽然内存带宽是主要限制因素，但其他因素阻止了应用程序完全饱和可持续带宽 $W$。\n\n- **性能差距的可能原因：** Roofline 模型假设工作负载可以完全利用给定的可持续带宽 $W$。$P_{\\mathrm{bound}}$ 和 $P_{\\mathrm{meas}}$ 之间的差距表明这个假设没有完全满足。对于基于 CSR 的 SpMV，一个主要元凶是 **非合并内存访问**。虽然矩阵值和列索引是连续存储的，可以被高效地（合并地）读取，但输入向量的元素是通过列索引间接访问的。这些索引通常不是顺序的，导致对输入向量的内存读取是分散的。这种访问模式在 GPU 上效率低下，会将有效内存带宽降低到可持续峰值 $W$ 以下。缓存颠簸是另一个可能的因素，即输入向量元素局部性差，导致过多的缓存驱逐，尽管模型试图通过平均命中率 $h$ 来解释这一点。由于不规则的访问模式，真实的缓存性能可能比这个平均值差。因此，非合并访问是观察到的性能低于简单 Roofline 模型预测上界的一个极有可能的原因。",
            "answer": "$$\\boxed{0.208}$$"
        },
        {
            "introduction": "除了核心计算本身的效率，总执行时间还受到如核心启动延迟等系统开销的显著影响，这在包含大量短时核心的时域求解器中尤为突出。现代 GPU 提供了如 CUDA Graphs 等技术来摊销这种开销。本练习要求你建立一个成本模型，精确推导出一个临界点——即需要执行多少个时间步，使用 CUDA Graphs 的优势才能抵消其初始设置成本，这对于优化长时间运行的模拟至关重要。",
            "id": "3287454",
            "problem": "一个在计算电磁学 (CEM) 中使用 Yee 格式的三维交错网格麦克斯韦时域求解器在图形处理器 (GPU) 上运行。在每个时间步中，求解器执行一个由 $n_k$ 个 GPU 核函数组成的固定序列，这些核函数实现了例如电场和磁场更新以及完美匹配层 (PML) 项。求解器推进 $S$ 个时间步。考虑两种启动策略：\n\n- 基准策略：每个时间步使用统一计算设备架构 (CUDA) 单独启动每个核函数，每个核函数产生 $\\ell$ 的启动延迟。假设由于严格的步内依赖关系，此启动开销无法与核函数执行重叠。\n- CUDA Graphs 策略：将每个时间步的整个核函数序列作为 CUDA Graph 捕获并实例化一次，产生一次性实例化成本 $g$。随后的每个时间步都以每步 $\\ell_g$ 的图启动延迟来启动这个预实例化的图。此外，每个时间步更新图节点的标量参数或指针的成本为每步 $u$。假设两种策略中的核函数执行时间相同，唯一的区别在于如上定义的与启动相关的开销。\n\n从求解时间构成的基本原理出发，推导最小整数时间步数 $S_\\star$ 的精确闭式表达式，使得使用 CUDA Graphs 的累积启动相关开销严格小于基准的逐核函数启动策略。将 $S_\\star$ 表示为 $n_k$、$\\ell$、$\\ell_g$、$u$ 和 $g$ 的函数。假设 $n_k \\ell  \\ell_g + u$，以确保可以获得收益。以单一解析表达式的形式提供最终的 $S_\\star$。不需要进行数值计算，最终答案也不需要单位。",
            "solution": "问题要求推导最小整数时间步数 $S_\\star$，在该时间步数下，基于 CUDA Graphs 的求解器的总启动相关开销严格小于基准的逐核函数启动策略。我们首先将每种策略的累积开销表示为时间步数 $S$ 的函数。\n\n令 $O_{base}(S)$ 表示基准策略在 $S$ 个时间步后的累积启动相关开销。在此策略中，每个时间步单独启动 $n_k$ 个核函数。每次核函数启动产生 $\\ell$ 的延迟。单个时间步的开销是核函数数量与每个核函数延迟的乘积，即 $n_k \\ell$。假设每个时间步的此开销是恒定的，则 $S$ 步后的总累积开销由下式给出：\n$$O_{base}(S) = S \\cdot n_k \\ell$$\n\n接下来，令 $O_{graph}(S)$ 表示 CUDA Graphs 策略在 $S$ 个时间步后的累积启动相关开销。此策略有一个用于捕获和实例化图的一次性前期成本 $g$。此成本在执行任何时间步之前产生一次。随后，对于 $S$ 个时间步中的每一个，都存在一个经常性开销。这个经常性开销包括图启动延迟 $\\ell_g$ 和更新图参数的成本 $u$。因此，每个时间步的总经常性开销为 $\\ell_g + u$。$S$ 个时间步后的累积开销是初始一次性成本与 $S$ 步内总经常性成本之和：\n$$O_{graph}(S) = g + S (\\ell_g + u)$$\n\n问题要求最小整数时间步数 $S_\\star$，使得 CUDA Graphs 策略的开销严格小于基准策略。此条件由以下不等式表示：\n$$O_{graph}(S)  O_{base}(S)$$\n将 $O_{graph}(S)$ 和 $O_{base}(S)$ 的表达式代入不等式，我们得到：\n$$g + S (\\ell_g + u)  S n_k \\ell$$\n\n为了找到关于 $S$ 的条件，我们必须解这个不等式。我们首先将包含 $S$ 的项分离到不等式的一侧：\n$$g  S n_k \\ell - S (\\ell_g + u)$$\n在右侧提出公因子 $S$ 得到：\n$$g  S (n_k \\ell - (\\ell_g + u))$$\n$$g  S (n_k \\ell - \\ell_g - u)$$\n问题给出了约束条件 $n_k \\ell  \\ell_g + u$，这意味着项 $(n_k \\ell - \\ell_g - u)$ 是一个正量。这个条件在物理上是必要的；如果基准方法的每步开销不大于图方法的每步开销，那么图方法将永远无法克服其初始设置成本 $g$，也就不可能获得任何收益。由于 $(n_k \\ell - \\ell_g - u)  0$，我们可以将不等式两边同时除以该项，而无需改变不等号的方向：\n$$S  \\frac{g}{n_k \\ell - \\ell_g - u}$$\n\n这个不等式给出了时间步数 $S$ 必须满足的条件，以使 CUDA Graphs 方法性能更优。我们的任务是找到满足此条件的最小*整数*值 $S$，我们将其表示为 $S_\\star$。\n令右侧的表达式为一个实数 $V$：\n$$V = \\frac{g}{n_k \\ell - \\ell_g - u}$$\n条件是 $S  V$。由于 $S$ 必须是整数，严格大于 $V$ 的最小整数值由 $\\lfloor V \\rfloor + 1$ 给出，其中 $\\lfloor \\cdot \\rfloor$ 表示向下取整函数（小于或等于其参数的最大整数）。对于任何实数 $V$，整数 $\\lfloor V \\rfloor + 1$ 是严格大于 $V$ 的第一个整数。\n\n因此，最小整数时间步数 $S_\\star$ 是：\n$$S_\\star = \\left\\lfloor \\frac{g}{n_k \\ell - \\ell_g - u} \\right\\rfloor + 1$$\n这就是 CUDA Graphs 的累积启动相关开销变得严格有利所需的时间步数的闭式表达式。",
            "answer": "$$\n\\boxed{\\left\\lfloor \\frac{g}{n_k \\ell - \\ell_g - u} \\right\\rfloor + 1}\n$$"
        }
    ]
}