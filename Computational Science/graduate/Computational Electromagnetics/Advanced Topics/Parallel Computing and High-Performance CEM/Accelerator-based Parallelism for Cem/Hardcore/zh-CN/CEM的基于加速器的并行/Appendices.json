{
    "hands_on_practices": [
        {
            "introduction": "在高性能计算中，尤其是在计算电磁学（CEM）领域，许多算法的性能瓶颈在于内存带宽而非计算能力。本练习将引导你通过第一性原理，为稀疏矩阵向量乘法（SpMV）这一核心操作建立一个基于内存带宽的性能模型。通过分析压缩稀疏行（CSR）和ELLPACK（ELL）这两种常用格式的数据移动，你将学会如何量化内存流量并预测带宽限制下的理论性能峰值，这是进行任何进一步性能优化的基础。",
            "id": "3287509",
            "problem": "考虑稀疏矩阵向量乘积 $y \\leftarrow A x$，该运算源于计算电磁学 (CEM) 中对麦克斯韦方程组的 curl-curl 算子离散化。矩阵 $A$ 是一个 $n \\times n$ 的方阵，其平均行长为 $r$，非零元素总数为 $\\text{nnz}$，因此有 $n = \\text{nnz}/r$。该计算在图形处理器 (GPU) 上执行，并受限于设备的全局内存带宽。\n\n假设如下：\n- 每个矩阵和向量元素以 $b_{v}$ 字节存储，每个列索引或行指针以 $b_{i}$ 字节存储。\n- 稀疏矩阵以压缩稀疏行 (CSR) 格式或 Ellpack-Itpack (ELL) 格式存储。对于 ELL 格式，假设模板是均匀的，因此每行的存储宽度恰好等于 $r$ (除了 $r$ 之外没有填充开销)。\n- 对于 CSR 格式，每行访问一次行指针数组以获取 $r$ 范围的边界 (每行两个指针)。\n- 向量 $y$ 每行使用流式存储 (streaming stores) 写入一次 (忽略写分配惩罚)。\n- 定义一个向量重用因子 $\\theta \\in [1,r]$，使得平均而言，$x$ 的一个元素的单次全局内存加载可以服务于 $\\theta$ 个非零项的贡献，然后才需要对该元素进行另一次全局内存加载。换句话说，$x$ 的全局加载次数为 $\\text{nnz}/\\theta$。\n- GPU 的持续全局内存带宽为 $W$，单位为字节/秒。\n\n从数据移动的第一性原理出发，并基于 $A$ 中每个非零元贡献一次乘法和一次加法 (每个非零元总计 $2$ 次浮点运算) 这一事实，推导对于每种存储格式 (CSR 和 ELL)，单次稀疏矩阵向量乘积的总全局内存流量，并将其表示为 $r$、$\\text{nnz}$、$b_{v}$、$b_{i}$ 和 $\\theta$ 的函数。利用这些流量结果，预测在带宽为 $W$ 的 GPU 上，每种格式的带宽限制性能 (以浮点运算/秒为单位)，并以闭式解析表达式的形式给出你的最终答案。\n\n以浮点运算/秒 (FLOP/s) 表示最终的性能值。按 CSR、ELL 的顺序提供两个结果。",
            "solution": "所述问题具有科学依据，提法明确，并包含足够的信息来推导所要求的性能模型。因此，该问题被视为有效。解答过程将为每种指定的稀疏矩阵格式推导总内存流量和由此产生的性能。\n\n对于带宽限制的计算，其基本原理是性能 (以浮点运算/秒，即 $\\text{FLOP/s}$ 为单位) 是浮点运算总数与计算总耗时之比。总时间 $t$ 由传入和传出全局内存的数据总量 (称为总流量 $T$) 和持续内存带宽 $W$ 决定。\n\n稀疏矩阵向量乘积的浮点运算总数 ($\\text{FLOPs}$) 为矩阵的每个非零元素进行 $2$ 次运算 (一次乘法，一次加法)。对于 $\\text{nnz}$ 个非零元素，我们有：\n$$\n\\text{Total FLOPs} = 2 \\times \\text{nnz}\n$$\n执行时间 $t$ 是总流量除以带宽：\n$$\nt = \\frac{T}{W}\n$$\n因此，性能 $P$ 可以表示为：\n$$\nP = \\frac{\\text{Total FLOPs}}{t} = \\frac{2 \\times \\text{nnz}}{T/W} = \\frac{2 \\times \\text{nnz} \\times W}{T}\n$$\n问题的核心是确定每种存储格式的总流量 $T$。总流量是读取矩阵 $A$ 的字节数、读取输入向量 $x$ 的字节数以及写入输出向量 $y$ 的字节数之和。\n\n首先，我们定义两种存储格式共有的流量分量。\n读取输入向量 $x$ 的流量，记为 $T_x$，取决于重用因子 $\\theta$。问题陈述，$x$ 的全局加载次数为 $\\frac{\\text{nnz}}{\\theta}$，每个元素大小为 $b_v$ 字节。\n$$\nT_x = \\frac{\\text{nnz}}{\\theta} \\times b_v\n$$\n写入输出向量 $y$ 的流量，记为 $T_y$，涉及为矩阵的 $n$ 行中的每一行写入一个大小为 $b_v$ 的元素。\n$$\nT_y = n \\times b_v\n$$\n使用给定关系 $n = \\frac{\\text{nnz}}{r}$，上式变为：\n$$\nT_y = \\frac{\\text{nnz}}{r} \\times b_v\n$$\n\n接下来，我们推导每种特定格式的表达式。\n\n**1. 压缩稀疏行 (CSR) 格式**\n\nCSR 格式的总内存流量 $T_{\\text{CSR}}$ 是矩阵数据结构和向量的流量之和。\nCSR 格式的矩阵 $A$ 需要读取三个数组：\n- 非零值数组：$\\text{nnz}$ 个元素，每个元素大小为 $b_v$ 字节。流量为 $\\text{nnz} \\times b_v$。\n- 列索引数组：$\\text{nnz}$ 个元素，每个元素大小为 $b_i$ 字节。流量为 $\\text{nnz} \\times b_i$。\n- 行指针数组：问题指明为 $n$ 行中的每一行读取两个指针。每个指针为 $b_i$ 字节。流量为 $2 \\times n \\times b_i = 2 \\times \\frac{\\text{nnz}}{r} \\times b_i$。\n\n读取 CSR 格式矩阵 $A$ 的流量 $T_{A, \\text{CSR}}$ 是这些分量的总和：\n$$\nT_{A, \\text{CSR}} = (\\text{nnz} \\times b_v) + (\\text{nnz} \\times b_i) + \\left(2 \\times \\frac{\\text{nnz}}{r} \\times b_i\\right)\n$$\n总流量 $T_{\\text{CSR}}$ 是矩阵流量、输入向量流量和输出向量流量的总和：\n$$\nT_{\\text{CSR}} = T_{A, \\text{CSR}} + T_x + T_y = \\left(\\text{nnz} \\cdot b_v + \\text{nnz} \\cdot b_i + \\frac{2 \\cdot \\text{nnz} \\cdot b_i}{r}\\right) + \\left(\\frac{\\text{nnz} \\cdot b_v}{\\theta}\\right) + \\left(\\frac{\\text{nnz} \\cdot b_v}{r}\\right)\n$$\n提出公因子 $\\text{nnz}$：\n$$\nT_{\\text{CSR}} = \\text{nnz} \\left( b_v + b_i + \\frac{2 b_i}{r} + \\frac{b_v}{\\theta} + \\frac{b_v}{r} \\right)\n$$\n按 $b_v$ 和 $b_i$ 分组各项：\n$$\nT_{\\text{CSR}} = \\text{nnz} \\left[ b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\left(1 + \\frac{2}{r}\\right) \\right]\n$$\n那么，CSR 的性能 $P_{\\text{CSR}}$ 为：\n$$\nP_{\\text{CSR}} = \\frac{2 \\times \\text{nnz} \\times W}{T_{\\text{CSR}}} = \\frac{2 \\times \\text{nnz} \\times W}{\\text{nnz} \\left[ b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\left(1 + \\frac{2}{r}\\right) \\right]}\n$$\n$\\text{nnz}$ 项被消去，得到最终的性能表达式：\n$$\nP_{\\text{CSR}} = \\frac{2 W}{b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\left(1 + \\frac{2}{r}\\right)}\n$$\n\n**2. Ellpack-Itpack (ELL) 格式**\n\n对于 ELL 格式，在行长 $r$ 均匀且无填充的情况下，矩阵数据存储在两个大小为 $n \\times r$ 的数组中。每个数组中存储的元素总数为 $n \\times r = (\\frac{\\text{nnz}}{r}) \\times r = \\text{nnz}$。\n读取 ELL 格式矩阵 $A$ 的流量 $T_{A, \\text{ELL}}$ 是：\n- 非零值数组：$\\text{nnz}$ 个元素，每个元素大小为 $b_v$ 字节。流量为 $\\text{nnz} \\times b_v$。\n- 列索引数组：$\\text{nnz}$ 个元素，每个元素大小为 $b_i$ 字节。流量为 $\\text{nnz} \\times b_i$。\n没有行指针数组。\n$$\nT_{A, \\text{ELL}} = (\\text{nnz} \\times b_v) + (\\text{nnz} \\times b_i)\n$$\nELL 格式的总流量 $T_{\\text{ELL}}$ 是：\n$$\nT_{\\text{ELL}} = T_{A, \\text{ELL}} + T_x + T_y = (\\text{nnz} \\cdot b_v + \\text{nnz} \\cdot b_i) + \\left(\\frac{\\text{nnz} \\cdot b_v}{\\theta}\\right) + \\left(\\frac{\\text{nnz} \\cdot b_v}{r}\\right)\n$$\n提出公因子 $\\text{nnz}$ 并分组各项：\n$$\nT_{\\text{ELL}} = \\text{nnz} \\left[ b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\right]\n$$\n那么，ELL 的性能 $P_{\\text{ELL}}$ 为：\n$$\nP_{\\text{ELL}} = \\frac{2 \\times \\text{nnz} \\times W}{T_{\\text{ELL}}} = \\frac{2 \\times \\text{nnz} \\times W}{\\text{nnz} \\left[ b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\right]}\n$$\n$\\text{nnz}$ 项被消去，得到最终的性能表达式：\n$$\nP_{\\text{ELL}} = \\frac{2 W}{b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i}\n$$\n在给定假设下，这两个推导出的表达式代表了 CSR 和 ELL 格式的带宽限制性能。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{2 W}{b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i \\left(1 + \\frac{2}{r}\\right)} & \\frac{2 W}{b_v \\left(1 + \\frac{1}{\\theta} + \\frac{1}{r}\\right) + b_i} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "建立了基本的性能模型后，下一步是使用更全面的工具来诊断性能瓶颈。本练习将介绍算术强度（Arithmetic Intensity）和Roofline模型，这是一个强大的框架，用于确定一个计算核心是受计算能力限制还是内存带宽限制。通过计算一个实际的SpMV核的算术强度并将其与测量的性能进行比较，你将能够推断出诸如非合并内存访问等潜在的低效率来源，从而更精确地指导优化工作。",
            "id": "3287482",
            "problem": "一个三维频域计算电磁学 (CEM) 求解器在图形处理单元 (GPU) 加速器上使用压缩稀疏行 (CSR) 格式的稀疏矩阵向量乘法 (SpMV) 核函数来应用离散化的旋度-旋度算子。该计算采用双精度。每个非零元对输出的累加贡献一次乘法和一次加法，并且在累加结束时，每行存储一次输出向量元素。CSR 数据结构的布局方式是，矩阵值和列索引从设备内存（动态随机存取存储器，DRAM）中获取，而输入向量元素由于重用而具有部分局部性，仅在缓存未命中时才由设备内存提供。\n\n假设以下科学上一致的参数：\n- 每行平均非零元数 $r = 40$。\n- 二级缓存的输入向量缓存命中率 $h = 0.6$（因此比例为 $1 - h$ 的输入向量获取操作会访问 DRAM）。\n- 每个非零元的矩阵值大小为 $8\\,\\mathrm{B}$（双精度）。\n- 每个非零元的列索引大小为 $4\\,\\mathrm{B}$（32位整数）。\n- 每行输出向量的存储大小为 $8\\,\\mathrm{B}$（双精度），分摊到该行的 $r$ 个非零元上。\n- 加速器的双精度浮点峰值吞吐量 $F = 10 \\times 10^{12}\\,\\mathrm{FLOP/s}$。\n- 可持续的设备内存带宽 $W = 1.6 \\times 10^{12}\\,\\mathrm{B/s}$。\n- 在该加速器上针对此算子测得的 SpMV 性能 $P_{\\mathrm{meas}} = 0.14 \\times 10^{12}\\,\\mathrm{FLOP/s}$。\n\n从关于吞吐量约束、算术强度以及数据移动与计算的基本原理出发，完成以下任务：\n1. 在给定假设下，通过计算浮点操作和每个非零元分摊的设备内存流量，推导出此 SpMV 的算术强度 $I$（单位为 $\\mathrm{FLOP/B}$）。\n2. 用 $F$、$W$ 和 $I$ 表示，推导出此加速器上 SpMV 浮点速率可达到的最紧密界限，并计算其数值。\n3. 将最终界限表示为以 $\\mathrm{TFLOP/s}$ 为单位的单个数字，并四舍五入到三位有效数字。\n4. 在你的推理中，将该界限与 $P_{\\mathrm{meas}}$ 进行比较，以推断主导的瓶颈区域，并讨论非合并访问或缓存颠簸等现象是否是可能的促成因素。\n\n只有第3项要求的数值界限将作为最终答案进行评分。请将您的答案四舍五入到三位有效数字。以 $\\mathrm{TFLOP/s}$ 为单位表示最终界限。",
            "solution": "该问题要求使用 Roofline 性能模型的原理，分析在图形处理单元 (GPU) 上的稀疏矩阵向量乘法 (SpMV) 核函数的性能。我们必须首先验证问题陈述的有效性。\n\n### 步骤1：提取已知条件\n- 计算：每个非零元需要 1 次乘法和 1 次加法，即每个非零元 2 次浮点运算 (FLOPs)。\n- 数据格式：双精度，压缩稀疏行 (CSR)。\n- 每行平均非零元数：$r = 40$。\n- 输入向量二级缓存命中率：$h = 0.6$。\n- 每个非零元的矩阵值大小：$8\\,\\mathrm{B}$。\n- 每个非零元的列索引大小：$4\\,\\mathrm{B}$。\n- 每行输出向量存储大小：$8\\,\\mathrm{B}$。\n- 双精度浮点峰值吞吐量：$F = 10 \\times 10^{12}\\,\\mathrm{FLOP/s}$。\n- 可持续设备内存带宽：$W = 1.6 \\times 10^{12}\\,\\mathrm{B/s}$。\n- 测量的 SpMV 性能：$P_{\\mathrm{meas}} = 0.14 \\times 10^{12}\\,\\mathrm{FLOP/s}$。\n\n### 步骤2：使用提取的已知条件进行验证\n问题陈述提供了一组用于建模 SpMV 核函数性能的参数。这些参数，如内存带宽、峰值 FLOP 速率、数据结构大小和缓存行为，是高性能计算中性能分析的典型参数。该场景在计算科学和计算机体系结构的原理上具有科学依据，特别是 Roofline 模型，该模型将处理器性能与内存带宽和算术强度联系起来。问题是自洽的，为推导提供了所有必要的数据。各量在物理上是一致的（例如，以字节为单位的大小，以操作/秒或字节/秒为单位的速率）。问题是适定的、客观的，并且没有违反任何科学原理。\n\n### 步骤3：结论与行动\n问题有效。我们将继续进行求解。\n\n解决方案包括四个部分：(1) 推导算术强度 $I$，(2) 推导理论性能界限，(3) 用数值表示该界限，以及 (4) 在上下文中讨论结果。\n\n**1. 算术强度 ($I$) 的推导**\n\n算术强度 $I$ 定义为执行的浮点操作数与主设备内存 (DRAM) 之间传输的总数据字节数之比。\n\n首先，我们计算每个非零元素的 FLOP 数。问题陈述中指出，每个非零元贡献一次乘法和一次加法。\n$$\n\\text{每个非零元的 FLOP 数} = 1 \\, (\\text{乘法}) + 1 \\, (\\text{加法}) = 2 \\, \\mathrm{FLOP}\n$$\n\n接下来，我们计算从/向 DRAM 传输的总字节数，并分摊到每个非零元上。该流量包括读取矩阵数据（值和索引）、读取输入向量元素以及写入输出向量元素。\n\n- **矩阵数据流量：** 对于每个非零元，我们必须从 DRAM 中读取其值和列索引。\n  - 矩阵值（双精度）：$8\\,\\mathrm{B}$\n  - 列索引（32位整数）：$4\\,\\mathrm{B}$\n  - 每个非零元的矩阵数据流量 = $8\\,\\mathrm{B} + 4\\,\\mathrm{B} = 12\\,\\mathrm{B}$。\n\n- **输入向量流量：** 对于每个非零元，必须读取输入向量的一个元素。元素大小为双精度，即 $8\\,\\mathrm{B}$。此读取操作受缓存影响。缓存命中率为 $h = 0.6$，则未命中率为 $1 - h = 0.4$。只有缓存未命中才会导致来自 DRAM 的流量。\n  - 每个非零元的输入向量流量 = $(1 - h) \\times (\\text{双精度大小}) = (1 - 0.6) \\times 8\\,\\mathrm{B} = 0.4 \\times 8\\,\\mathrm{B} = 3.2\\,\\mathrm{B}$。\n\n- **输出向量流量：** 每行写入一个输出向量元素。对于每 $r$ 个非零元（其中 $r=40$），这是一次 $8\\,\\mathrm{B}$ 的写入操作。该流量成本分摊到该行的非零元上。\n  - 每个非零元的输出向量流量 = $\\frac{8\\,\\mathrm{B}}{r} = \\frac{8\\,\\mathrm{B}}{40} = 0.2\\,\\mathrm{B}$。\n\n每个非零元的总内存流量是这些分量的总和：\n$$\n\\text{每个非零元的字节数} = 12\\,\\mathrm{B} + 3.2\\,\\mathrm{B} + 0.2\\,\\mathrm{B} = 15.4\\,\\mathrm{B}\n$$\n\n现在，我们可以计算算术强度 $I$：\n$$\nI = \\frac{\\text{每个非零元的 FLOP 数}}{\\text{每个非零元的字节数}} = \\frac{2\\,\\mathrm{FLOP}}{15.4\\,\\mathrm{B}} = \\frac{10}{77}\\,\\mathrm{FLOP/B}\n$$\n数值上，$I \\approx 0.12987\\,\\mathrm{FLOP/B}$。\n\n**2. 性能界限的推导**\n\nRoofline 模型假设，可达到的性能 $P$ 受限于峰值计算吞吐量 ($F$) 和由内存带宽 ($W$) 与算术强度 ($I$) 所决定的性能两者中的最小值。\n可达到的最紧密界限 $P_{\\mathrm{bound}}$ 由下式给出：\n$$\nP_{\\mathrm{bound}} = \\min(F, I \\times W)\n$$\n我们已知 $F = 10 \\times 10^{12}\\,\\mathrm{FLOP/s}$ 和 $W = 1.6 \\times 10^{12}\\,\\mathrm{B/s}$。我们来计算受内存限制的性能 $I \\times W$：\n$$\nI \\times W = \\left(\\frac{10}{77}\\,\\mathrm{FLOP/B}\\right) \\times \\left(1.6 \\times 10^{12}\\,\\mathrm{B/s}\\right) = \\frac{16}{77} \\times 10^{12}\\,\\mathrm{FLOP/s}\n$$\n计算其数值：\n$$\n\\frac{16}{77} \\approx 0.207792...\n$$\n所以，受内存限制的性能约为 $0.2078 \\times 10^{12}\\,\\mathrm{FLOP/s}$。\n\n现在我们将其与峰值计算性能 $F$ 进行比较：\n$$\nP_{\\mathrm{bound}} = \\min(10 \\times 10^{12}\\,\\mathrm{FLOP/s}, \\, 0.2078 \\times 10^{12}\\,\\mathrm{FLOP/s})\n$$\n最小值显然是受内存限制的值。\n$$\nP_{\\mathrm{bound}} \\approx 0.2078 \\times 10^{12}\\,\\mathrm{FLOP/s}\n$$\n\n**3. 以 TFLOP/s 为单位的最终界限**\n\n最终答案必须以 TFLOP/s 为单位，并四舍五入到三位有效数字。\n$1\\,\\mathrm{TFLOP/s} = 10^{12}\\,\\mathrm{FLOP/s}$。\n$$\nP_{\\mathrm{bound}} \\approx 0.2078\\,\\mathrm{TFLOP/s}\n$$\n四舍五入到三位有效数字得到 $0.208\\,\\mathrm{TFLOP/s}$。\n\n**4. 瓶颈讨论**\n\n- **主导瓶颈：** 计算表明 $I \\times W \\approx 0.208\\,\\mathrm{TFLOP/s}$，而 $F = 10\\,\\mathrm{TFLOP/s}$。由于 $I \\times W \\ll F$，该 SpMV 核函数是强**内存受限**的。其性能取决于从设备内存中获取数据和向其存储数据的速率，而不是由 GPU 浮点单元的原始计算能力决定。\n\n- **与实测性能的比较：** 推导出的理论界限为 $P_{\\mathrm{bound}} \\approx 0.208\\,\\mathrm{TFLOP/s}$。给出的实测性能为 $P_{\\mathrm{meas}} = 0.14\\,\\mathrm{TFLOP/s}$。实测性能达到了理论界限的约 $\\frac{P_{\\mathrm{meas}}}{P_{\\mathrm{bound}}} = \\frac{0.14}{0.208} \\approx 67.3\\%$。这表明，虽然内存带宽是主要限制因素，但其他因素阻止了应用程序完全饱和可持续带宽 $W$。\n\n- **性能差距的可能原因：** Roofline 模型假设工作负载可以完全利用给定的可持续带宽 $W$。$P_{\\mathrm{bound}}$ 和 $P_{\\mathrm{meas}}$ 之间的差距表明这一假设并未完全满足。对于基于 CSR 的 SpMV，一个主要元凶是**非合并内存访问**。虽然矩阵值和列索引是连续存储的，可以高效地（合并）获取，但输入向量元素是通过列索引间接访问的。这些索引通常不是顺序的，导致对输入向量进行分散的内存读取。这种访问模式在 GPU 上效率低下，会将有效内存带宽降低到峰值可持续值 $W$ 以下。缓存颠簸是另一个可能的因素，即输入向量元素的局部性差，导致过多的缓存驱逐，尽管模型试图通过平均命中率 $h$ 来解释这一点。由于不规则的访问模式，真实的缓存性能可能比这个平均值更差。因此，非合并访问是观察到的性能低于简单 Roofline 模型预测界限的一个极有可能的原因。",
            "answer": "$$\\boxed{0.208}$$"
        },
        {
            "introduction": "对单个计算核心进行优化后，性能提升的瓶颈往往会转移到更高层面的算法结构上，例如在时域求解器中反复提交计算任务的开销。本练习探讨了如何通过CUDA Graphs技术来摊销内核启动延迟，这对于包含一系列固定内核序列的迭代算法尤为重要。通过推导使用CUDA Graphs的性能增益收支平衡点，你将理解在何种条件下这种高级优化技术能够带来显著的性能提升，并掌握评估其适用性的分析方法。",
            "id": "3287454",
            "problem": "一个在计算电磁学（CEM）中采用 Yee 格式的三维交错网格麦克斯韦时域求解器，运行在图形处理器（GPU）上。在每个时间步中，该求解器执行一个由 $n_k$ 个 GPU 核函数组成的固定序列，这些核函数用于实现例如电场和磁场更新以及完美匹配层（PML）项的计算。求解器总共推进 $S$ 个时间步。考虑两种启动策略：\n\n- 基准策略：在每个时间步中，使用 Compute Unified Device Architecture (CUDA) 单独启动每个核函数，每个核函数的启动会产生 $\\ell$ 的延迟。假设由于严格的步内依赖关系，这种启动开销不能与核函数的执行重叠。\n- CUDA Graphs：每个时间步的完整核函数序列被捕获并作为 CUDA Graph 实例化一次，产生一次性实例化成本 $g$。后续的每个时间步启动这个预先实例化的图，每个时间步的图启动延迟为 $\\ell_g$。此外，每个时间步更新图节点的标量参数或指针的成本为 $u$。假设两种策略中的核函数执行时间相同，唯一的区别在于如上定义的与启动相关的开销。\n\n从求解时间构成的第一性原理出发，推导使 CUDA Graphs 累积的与启动相关的开销严格小于基准的逐核函数启动策略的开销所需的最小整数时间步数 $S_\\star$ 的精确闭式表达式。将 $S_\\star$ 表示为 $n_k$、$\\ell$、$\\ell_g$、$u$ 和 $g$ 的函数。假设 $n_k \\ell > \\ell_g + u$，以确保可以获得收益。将最终的 $S_\\star$ 以单一解析表达式的形式给出。无需进行数值计算，最终答案也无需单位。",
            "solution": "问题要求推导最小整数时间步数 $S_\\star$，在该时间步数下，基于 CUDA Graphs 的求解器的总启动相关开销严格小于基准的逐核函数启动策略。我们首先将每种策略的累积开销表示为时间步数 $S$ 的函数。\n\n令 $O_{base}(S)$ 表示基准策略在 $S$ 个时间步后的累积启动相关开销。在这种策略中，每个时间步会单独启动 $n_k$ 个核函数。每次核函数启动会产生 $\\ell$ 的延迟。单个时间步的开销是核函数数量与每个核函数延迟的乘积，即 $n_k \\ell$。假设每个时间步的此开销是恒定的，则 $S$ 步后的总累积开销由下式给出：\n$$O_{base}(S) = S \\cdot n_k \\ell$$\n\n接下来，令 $O_{graph}(S)$ 表示 CUDA Graphs 策略在 $S$ 个时间步后的累积启动相关开销。该策略有一个用于捕获和实例化图的一次性前期成本 $g$。此成本在执行任何时间步之前只产生一次。随后，对于 $S$ 个时间步中的每一步，都有一个经常性开销。这个经常性开销包括图启动延迟 $\\ell_g$ 和更新图参数的成本 $u$。因此，每个时间步的总经常性开销为 $\\ell_g + u$。$S$ 个时间步后的累积开销是初始一次性成本与 $S$ 步总经常性成本之和：\n$$O_{graph}(S) = g + S (\\ell_g + u)$$\n\n问题要求的是最小整数时间步数 $S_\\star$，使得 CUDA Graphs 策略的开销严格小于基准策略的开销。这个条件可由以下不等式表示：\n$$O_{graph}(S)  O_{base}(S)$$\n将 $O_{graph}(S)$ 和 $O_{base}(S)$ 的表达式代入不等式，我们得到：\n$$g + S (\\ell_g + u)  S n_k \\ell$$\n\n为了找到关于 $S$ 的条件，我们必须解这个不等式。我们首先将包含 $S$ 的项分离到不等式的一侧：\n$$g  S n_k \\ell - S (\\ell_g + u)$$\n在右侧提取公因子 $S$ 得到：\n$$g  S (n_k \\ell - (\\ell_g + u))$$\n$$g  S (n_k \\ell - \\ell_g - u)$$\n问题给出了约束条件 $n_k \\ell  \\ell_g + u$，这意味着项 $(n_k \\ell - \\ell_g - u)$ 是一个正数。这个条件在物理上是必要的；如果基准方法的每步开销不大于图方法的每步开销，那么图方法就永远无法弥补其初始设置成本 $g$，也就无法获得任何收益。由于 $(n_k \\ell - \\ell_g - u)  0$，我们可以用这个项除以不等式两边，而无需改变不等号的方向：\n$$S  \\frac{g}{n_k \\ell - \\ell_g - u}$$\n\n这个不等式给出了为使 CUDA Graphs 方法性能更优，时间步数 $S$ 必须满足的条件。我们的任务是找到满足此条件的 $S$ 的最小*整数*值，我们将其表示为 $S_\\star$。\n令右侧的表达式为一个实数 $V$：\n$$V = \\frac{g}{n_k \\ell - \\ell_g - u}$$\n条件是 $S  V$。由于 $S$ 必须是整数，严格大于 $V$ 的最小整数值由 $\\lfloor V \\rfloor + 1$ 给出，其中 $\\lfloor \\cdot \\rfloor$ 表示向下取整函数（即不大于其参数的最大整数）。对于任何实数 $V$，整数 $\\lfloor V \\rfloor + 1$ 是第一个严格大于 $V$ 的整数。\n\n因此，最小整数时间步数 $S_\\star$ 是：\n$$S_\\star = \\left\\lfloor \\frac{g}{n_k \\ell - \\ell_g - u} \\right\\rfloor + 1$$\n这就是 CUDA Graphs 的累积启动相关开销开始变得严格占优所需的时间步数的闭式表达式。",
            "answer": "$$\n\\boxed{\\left\\lfloor \\frac{g}{n_k \\ell - \\ell_g - u} \\right\\rfloor + 1}\n$$"
        }
    ]
}