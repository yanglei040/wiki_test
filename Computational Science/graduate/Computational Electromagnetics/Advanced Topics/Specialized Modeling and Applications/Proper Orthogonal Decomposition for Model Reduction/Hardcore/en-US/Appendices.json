{
    "hands_on_practices": [
        {
            "introduction": "To build a strong foundation, we begin with a verification exercise using a manufactured solution to a simple diffusion problem, where the system's dynamics are intentionally confined to a known low-dimensional subspace. By implementing a POD-Galerkin model for this ideal scenario , you will confirm a core principle: when the solution manifold is a linear subspace, Proper Orthogonal Decomposition (POD) can identify it exactly, leading to a reduced-order model with virtually zero error.",
            "id": "3435994",
            "problem": "Consider the one-dimensional diffusion partial differential equation (PDE) on the open interval $\\left(0,1\\right)$ with homogeneous Dirichlet boundary conditions and constant diffusivity, and let a standard second-order centered finite-difference semi-discretization be used on $n$ interior grid points. Denote the resulting semi-discrete state vector by $u\\left(t\\right) \\in \\mathbb{R}^{n}$. The semi-discrete model is the linear time-invariant system\n$$\n\\frac{d}{dt} u\\left(t\\right) \\;=\\; A\\,u\\left(t\\right), \\quad A \\;=\\; \\nu\\,L_{h},\n$$\nwhere $\\nu \\in \\mathbb{R}_{+}$ is the diffusivity and $L_{h} \\in \\mathbb{R}^{n \\times n}$ is the tridiagonal discrete Laplacian with entries\n$$\n\\left(L_{h}\\right)_{i,i} \\;=\\; -\\frac{2}{h^{2}}, \\quad \\left(L_{h}\\right)_{i,i+1} \\;=\\; \\left(L_{h}\\right)_{i+1,i} \\;=\\; \\frac{1}{h^{2}}, \\quad h \\;=\\; \\frac{1}{n+1}, \\quad i \\;=\\; 1,\\dots,n-1.\n$$\nThe matrix $A$ is real symmetric negative-definite, hence admits an eigendecomposition $A \\;=\\; V \\Lambda V^{\\top}$ with orthonormal $V \\in \\mathbb{R}^{n \\times n}$ and diagonal $\\Lambda \\in \\mathbb{R}^{n \\times n}$ having strictly negative diagonal entries. The exact solution for any initial condition $u\\left(0\\right)$ is then\n$$\nu\\left(t\\right) \\;=\\; V\\,e^{\\Lambda t}\\,V^{\\top} u\\left(0\\right).\n$$\n\nYou are to design a manufactured-solution experiment in which the full model solution lies exactly in the span of a few chosen eigenmodes, and then verify by computation that Proper Orthogonal Decomposition (POD) combined with a Galerkin projection onto the POD subspace recovers the same span and yields zero projection error when the POD rank is at least as large as the number of active modes. Use the following principle-based steps.\n\n1) Subspace invariance and manufactured solution. Choose a small set of mode indices $\\mathcal{K} \\subset \\left\\{1,\\dots,n\\right\\}$ of size $r_{\\mathrm{true}}$ (the number of active modes). Let $V_{\\mathcal{K}} \\in \\mathbb{R}^{n \\times r_{\\mathrm{true}}}$ denote the matrix whose columns are the corresponding eigenvectors of $A$, ordered by increasing absolute value of the associated eigenvalues. Choose a nonzero coefficient vector $a \\in \\mathbb{R}^{r_{\\mathrm{true}}}$ and set\n$$\nu\\left(0\\right) \\;=\\; V_{\\mathcal{K}}\\,a, \\qquad u\\left(t\\right) \\;=\\; V_{\\mathcal{K}}\\,\\exp\\!\\left(\\Lambda_{\\mathcal{K}} t\\right) a,\n$$\nwhere $\\Lambda_{\\mathcal{K}} \\in \\mathbb{R}^{r_{\\mathrm{true}} \\times r_{\\mathrm{true}}}$ is the diagonal eigenvalue submatrix. By construction, for every $t \\ge 0$, $u\\left(t\\right)$ lies in $\\mathrm{span}\\!\\left(V_{\\mathcal{K}}\\right)$, an $A$-invariant subspace.\n\n2) Snapshot collection and POD. Form the snapshot matrix $X \\in \\mathbb{R}^{n \\times m}$ with columns $u\\left(t_{j}\\right)$ at $m$ distinct times $0 = t_{1} < t_{2} < \\dots < t_{m} = T$. Compute the Singular Value Decomposition (SVD) $X \\;=\\; U \\Sigma W^{\\top}$ with orthonormal $U \\in \\mathbb{R}^{n \\times n}$, diagonal nonnegative $\\Sigma \\in \\mathbb{R}^{n \\times m}$, and orthonormal $W \\in \\mathbb{R}^{m \\times m}$. For a prescribed POD rank $r_{\\mathrm{pod}}$, define the POD basis as the first $r_{\\mathrm{pod}}$ columns of $U$, denoted $\\Phi \\in \\mathbb{R}^{n \\times r_{\\mathrm{pod}}}$.\n\n3) POD projection error. The orthogonal projector onto the POD subspace is $P \\;=\\; \\Phi \\Phi^{\\top}$. The normalized projection error of the snapshots is\n$$\n\\mathcal{E}_{\\mathrm{proj}} \\;=\\; \\frac{\\left\\| X \\;-\\; P X \\right\\|_{F}}{\\left\\| X \\right\\|_{F}},\n$$\nwhere $\\left\\|\\cdot\\right\\|_{F}$ denotes the Frobenius norm. If $r_{\\mathrm{pod}} \\ge r_{\\mathrm{true}}$ and $\\mathrm{rank}\\left(X\\right) = r_{\\mathrm{true}}$, then $\\mathcal{E}_{\\mathrm{proj}}$ must be zero in exact arithmetic.\n\n4) POD–Galerkin reduced model. Form the Galerkin-projected reduced operator\n$$\nA_{r} \\;=\\; \\Phi^{\\top} A \\Phi \\;\\in\\; \\mathbb{R}^{r_{\\mathrm{pod}} \\times r_{\\mathrm{pod}}},\n$$\nand the reduced initial state $c\\left(0\\right) \\;=\\; \\Phi^{\\top} u\\left(0\\right)$. Evolve the reduced model\n$$\n\\frac{d}{dt} c\\left(t\\right) \\;=\\; A_{r}\\,c\\left(t\\right), \\qquad c\\left(t\\right) \\;=\\; e^{A_{r} t} c\\left(0\\right),\n$$\nand reconstruct the reduced state $u_{r}\\left(t\\right) \\;=\\; \\Phi\\,c\\left(t\\right)$. Compute the final-time relative error\n$$\n\\mathcal{E}_{\\mathrm{final}} \\;=\\; \\frac{\\left\\| u\\left(T\\right) - u_{r}\\left(T\\right) \\right\\|_{2}}{\\left\\| u\\left(T\\right) \\right\\|_{2}}.\n$$\nIf $r_{\\mathrm{pod}} \\ge r_{\\mathrm{true}}$, then invariance implies $u_{r}\\left(t\\right) \\equiv u\\left(t\\right)$ in exact arithmetic, hence $\\mathcal{E}_{\\mathrm{final}} = 0$.\n\nImplement a program that constructs $A$ from $\\nu$ and $n$, computes its eigendecomposition, manufactures $u\\left(t\\right)$ from a chosen set of modes and coefficients, builds the POD basis, computes $\\mathcal{E}_{\\mathrm{proj}}$ and $\\mathcal{E}_{\\mathrm{final}}$, and outputs these two errors for each of the following test cases. In all cases, the POD inner product is the Euclidean inner product on $\\mathbb{R}^{n}$, all time values are in the same arbitrary unit, and no physical units are required.\n\nTest suite (each case is a tuple $\\left(n, \\nu, T, \\mathcal{K}, a, m, r_{\\mathrm{pod}}\\right)$):\n- Case $1$: $\\left(n=80, \\nu=0.5, T=0.7, \\mathcal{K}=\\left[1,3\\right], a=\\left[1.0,-0.4\\right], m=6, r_{\\mathrm{pod}}=2\\right)$.\n- Case $2$: $\\left(n=60, \\nu=0.2, T=1.3, \\mathcal{K}=\\left[2,5,7\\right], a=\\left[0.7,-1.0,0.5\\right], m=9, r_{\\mathrm{pod}}=3\\right)$.\n- Case $3$: $\\left(n=64, \\nu=1.0, T=0.3, \\mathcal{K}=\\left[4\\right], a=\\left[1.0\\right], m=4, r_{\\mathrm{pod}}=5\\right)$.\n- Case $4$: $\\left(n=60, \\nu=0.2, T=0.8, \\mathcal{K}=\\left[1,4,6\\right], a=\\left[1.0,-0.5,0.3\\right], m=8, r_{\\mathrm{pod}}=2\\right)$.\n\nImportant implementation details:\n- When constructing $A$, use the tridiagonal $L_{h}$ defined above and multiply by the diffusivity $\\nu$.\n- Compute the eigendecomposition of $A$ as $A \\;=\\; V \\Lambda V^{\\top}$ and order eigenpairs by increasing $\\left|\\lambda\\right|$ so that mode index $k$ denotes the eigenpair with the $k$-th smallest $\\left|\\lambda\\right|$.\n- Manufacture snapshots using only the selected eigenpairs in $\\mathcal{K}$ and the formula $u\\left(t\\right) \\;=\\; \\sum_{j} a_{j}\\,e^{\\lambda_{k_{j}} t}\\,v_{k_{j}}$ to ensure exact subspace invariance.\n- For each test case, output the pair $\\left(\\mathcal{E}_{\\mathrm{proj}}, \\mathcal{E}_{\\mathrm{final}}\\right)$ as two floating-point numbers appended to a single flat output list.\n\nFinal output format:\nYour program should produce a single line of output containing a single list with $2$ floating-point numbers per test case in the order of the cases above, namely\n$$\n\\left[\\mathcal{E}_{\\mathrm{proj}}^{(1)}, \\mathcal{E}_{\\mathrm{final}}^{(1)}, \\mathcal{E}_{\\mathrm{proj}}^{(2)}, \\mathcal{E}_{\\mathrm{final}}^{(2)}, \\mathcal{E}_{\\mathrm{proj}}^{(3)}, \\mathcal{E}_{\\mathrm{final}}^{(3)}, \\mathcal{E}_{\\mathrm{proj}}^{(4)}, \\mathcal{E}_{\\mathrm{final}}^{(4)}\\right],\n$$\nprinted exactly as a comma-separated list enclosed in square brackets. No other text should be printed. All angle measures, percentages, and physical units are not applicable; all numerical outputs must be real numbers.",
            "solution": "The problem statement constitutes a valid and well-posed numerical verification experiment. It is grounded in the established principles of the numerical solution of partial differential equations, linear algebra, and model order reduction via Proper Orthogonal Decomposition (POD) and Galerkin projection. All required parameters and procedures are specified without ambiguity or contradiction, allowing for a unique and meaningful computational result. We will proceed with the solution.\n\nThe core of the problem is to verify a fundamental property of POD-Galerkin reduced-order models (ROMs): if the solution of a full-order model (FOM) evolves within a low-dimensional subspace, a POD-Galerkin ROM of sufficient rank can exactly represent the solution and its dynamics, resulting in zero error.\n\nThe solution is implemented by following the four principle-based steps outlined in the problem description.\n\n**1. System and Manufactured Solution Construction**\n\nFirst, we construct the semi-discrete linear time-invariant system $\\frac{d}{dt} u(t) = A u(t)$ that approximates the one-dimensional diffusion equation. For a spatial domain of length $L=1$ discretized with $n$ interior points, the grid spacing is $h = \\frac{1}{n+1}$. The system matrix is $A = \\nu L_h$, where $\\nu \\in \\mathbb{R}_{+}$ is the diffusivity and $L_h \\in \\mathbb{R}^{n \\times n}$ is the second-order finite-difference approximation of the Laplacian operator with homogeneous Dirichlet boundary conditions. $L_h$ is a real, symmetric, tridiagonal matrix defined by:\n$$\n(L_h)_{ij} = \\frac{1}{h^2} \\begin{cases} -2 & i=j \\\\ 1 & |i-j|=1 \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nThe matrix $A$ is symmetric and negative definite. Its eigendecomposition, $A = V \\Lambda V^{\\top}$, provides a basis of orthonormal eigenvectors $V \\in \\mathbb{R}^{n \\times n}$ and a diagonal matrix $\\Lambda \\in \\mathbb{R}^{n \\times n}$ of corresponding real, negative eigenvalues. The problem requires the eigenpairs $(\\lambda_k, v_k)$ to be ordered by increasing absolute value of the eigenvalues, i.e., $|\\lambda_1| \\le |\\lambda_2| \\le \\dots \\le |\\lambda_n|$.\n\nA manufactured solution is then constructed to lie exactly within a predetermined invariant subspace of $A$. We choose a set of $r_{\\mathrm{true}}$ mode indices $\\mathcal{K} \\subset \\{1, \\dots, n\\}$. Let $V_{\\mathcal{K}} \\in \\mathbb{R}^{n \\times r_{\\mathrm{true}}}$ be the matrix whose columns are the selected eigenvectors, and $\\Lambda_{\\mathcal{K}} \\in \\mathbb{R}^{r_{\\mathrm{true}} \\times r_{\\mathrm{true}}}$ be the diagonal matrix of corresponding eigenvalues. For a given coefficient vector $a \\in \\mathbb{R}^{r_{\\mathrm{true}}}$, the initial condition is set to $u(0) = V_{\\mathcal{K}} a$. The exact time-evolved solution is then given by:\n$$\nu(t) = V e^{\\Lambda t} V^{\\top} u(0) = V e^{\\Lambda t} V^{\\top} V_{\\mathcal{K}} a\n$$\nSince the columns of $V$ are orthonormal, $V^{\\top} V_{\\mathcal{K}}$ is zero except for the rows corresponding to the indices in $\\mathcal{K}$. This simplifies the solution to:\n$$\nu(t) = V_{\\mathcal{K}} e^{\\Lambda_{\\mathcal{K}} t} a\n$$\nBy construction, the state vector $u(t)$ remains in the subspace $\\mathrm{span}(V_{\\mathcal{K}})$ for all $t \\ge 0$.\n\n**2. Snapshot Collection and POD Basis**\n\nWe collect $m$ \"snapshots\" of the system state $u(t_j)$ at distinct time instances $t_j$ over the interval $[0, T]$, where $0 = t_1 < t_2 < \\dots < t_m = T$. These snapshots form the columns of the snapshot matrix $X = [u(t_1), u(t_2), \\dots, u(t_m)] \\in \\mathbb{R}^{n \\times m}$.\n\nThe POD basis is a set of orthonormal vectors that optimally capture the energy of the snapshots. It is obtained from the Singular Value Decomposition (SVD) of the snapshot matrix, $X = U \\Sigma W^{\\top}$. Here, $U \\in \\mathbb{R}^{n \\times n}$ contains the left singular vectors (the POD modes), $\\Sigma \\in \\mathbb{R}^{n \\times m}$ is a diagonal matrix of singular values $\\sigma_i \\ge 0$, and $W \\in \\mathbb{R}^{m \\times m}$ contains the right singular vectors. The POD basis of rank $r_{\\mathrm{pod}}$ is the matrix $\\Phi \\in \\mathbb{R}^{n \\times r_{\\mathrm{pod}}}$ formed by the first $r_{\\mathrm{pod}}$ columns of $U$.\n\n**3. POD Projection Error**\n\nThe orthogonal projector onto the POD subspace $\\mathrm{span}(\\Phi)$ is $P = \\Phi \\Phi^{\\top}$. The error incurred by projecting the snapshots onto this subspace is quantified by the normalized Frobenius norm of the residual:\n$$\n\\mathcal{E}_{\\mathrm{proj}} = \\frac{\\| X - P X \\|_{F}}{\\| X \\|_{F}}\n$$\nUsing the properties of the SVD, this error can be computed from the singular values without explicitly forming the matrices:\n$$\n\\mathcal{E}_{\\mathrm{proj}} = \\sqrt{\\frac{\\sum_{i=r_{\\mathrm{pod}}+1}^{k} \\sigma_i^2}{\\sum_{i=1}^{k} \\sigma_i^2}}\n$$\nwhere $k = \\mathrm{rank}(X)$. If the data lies in an $r_{\\mathrm{true}}$-dimensional subspace, then $\\mathrm{rank}(X) = r_{\\mathrm{true}}$ (assuming sufficient snapshots). If $r_{\\mathrm{pod}} \\ge r_{\\mathrm{true}}$, all non-zero singular values are captured, the numerator becomes zero, and thus $\\mathcal{E}_{\\mathrm{proj}}$ must be zero in exact arithmetic.\n\n**4. POD-Galerkin Reduced Model and Final-Time Error**\n\nThe POD-Galerkin method projects the governing equation onto the POD basis $\\Phi$. An approximate solution is sought in the form $u_r(t) = \\Phi c(t)$, where $c(t) \\in \\mathbb{R}^{r_{\\mathrm{pod}}}$ are the reduced coordinates. Substituting this into the FOM and pre-multiplying by $\\Phi^{\\top}$ yields the reduced-order model:\n$$\n\\frac{d}{dt} c(t) = A_r c(t), \\quad \\text{with} \\quad A_r = \\Phi^{\\top} A \\Phi \\in \\mathbb{R}^{r_{\\mathrm{pod}} \\times r_{\\mathrm{pod}}}\n$$\nThe initial condition is also projected: $c(0) = \\Phi^{\\top} u(0)$. The reduced system is evolved in time using the matrix exponential: $c(t) = e^{A_r t} c(0)$. The FOM solution is then reconstructed as $u_r(t) = \\Phi c(t)$.\n\nThe accuracy of the ROM is assessed by comparing its solution to the manufactured FOM solution at the final time $t=T$:\n$$\n\\mathcal{E}_{\\mathrm{final}} = \\frac{\\| u(T) - u_r(T) \\|_{2}}{\\| u(T) \\|_{2}}\n$$\nWhen $r_{\\mathrm{pod}} \\ge r_{\\mathrm{true}}$, the POD subspace $\\mathrm{span}(\\Phi)$ contains the invariant subspace $\\mathrm{span}(V_{\\mathcal{K}})$. Consequently, the projection is exact, $u_r(t)$ will be identical to $u(t)$, and $\\mathcal{E}_{\\mathrm{final}}$ will be zero in exact arithmetic. For cases where $r_{\\mathrm{pod}} < r_{\\mathrm{true}}$, both $\\mathcal{E}_{\\mathrm{proj}}$ and $\\mathcal{E}_{\\mathrm{final}}$ are expected to be non-zero. The following program computes these two error metrics for the specified test cases.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef solve():\n    \"\"\"\n    Implements the POD-Galerkin model reduction experiment for the 1D diffusion equation.\n    \"\"\"\n    test_cases = [\n        # (n, nu, T, K, a, m, r_pod)\n        (80, 0.5, 0.7, [1, 3], [1.0, -0.4], 6, 2),\n        (60, 0.2, 1.3, [2, 5, 7], [0.7, -1.0, 0.5], 9, 3),\n        (64, 1.0, 0.3, [4], [1.0], 4, 5),\n        (60, 0.2, 0.8, [1, 4, 6], [1.0, -0.5, 0.3], 8, 2),\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        n, nu, T, K, a, m, r_pod = case\n        a_vec = np.array(a)\n\n        # 1. System construction and manufactured solution\n        # Construct the system matrix A\n        h = 1.0 / (n + 1.0)\n        diag_val = -2.0 / (h**2)\n        offdiag_val = 1.0 / (h**2)\n        main_diag = np.full(n, diag_val)\n        off_diag = np.full(n - 1, offdiag_val)\n        L_h = np.diag(main_diag) + np.diag(off_diag, k=1) + np.diag(off_diag, k=-1)\n        A = nu * L_h\n\n        # Compute eigendecomposition and sort by increasing absolute eigenvalue\n        lambdas, V = np.linalg.eigh(A)\n        sort_indices = np.argsort(np.abs(lambdas))\n        lambdas_sorted = lambdas[sort_indices]\n        V_sorted = V[:, sort_indices]\n\n        # Select modes for manufactured solution (convert 1-based K to 0-based indices)\n        mode_indices = [k - 1 for k in K]\n        V_K = V_sorted[:, mode_indices]\n        lambdas_K = lambdas_sorted[mode_indices]\n        \n        # Define initial condition\n        u0 = V_K @ a_vec\n\n        # 2. Snapshot collection and POD basis\n        # Generate snapshots\n        t_space = np.linspace(0.0, T, m)\n        X = np.zeros((n, m))\n        for j, t_j in enumerate(t_space):\n            # u(t) = V_K @ diag(exp(lambda_k * t)) @ a\n            X[:, j] = V_K @ (np.exp(lambdas_K * t_j) * a_vec)\n        \n        # Compute POD basis via SVD. U must be n x n as per problem description.\n        U, s, _ = np.linalg.svd(X, full_matrices=True)\n        Phi = U[:, :r_pod]\n\n        # 3. POD projection error\n        norm_X_sq = np.sum(s**2)\n        if norm_X_sq < 1e-15:\n            # Handle trivial case of zero snapshots\n            E_proj = 0.0\n        else:\n            # Sum of squares of truncated singular values\n            norm_err_sq = np.sum(s[r_pod:]**2)\n            E_proj = np.sqrt(norm_err_sq / norm_X_sq)\n\n        # 4. POD-Galerkin reduced model and final-time error\n        # Full (manufactured) solution at the final time T\n        u_T = V_K @ (np.exp(lambdas_K * T) * a_vec)\n        \n        # If r_pod is 0, reduced solution is identically zero\n        if r_pod == 0:\n            u_r_T = np.zeros(n)\n        else:\n            # Construct and evolve the reduced-order model\n            A_r = Phi.T @ A @ Phi\n            c0 = Phi.T @ u0\n            c_T = expm(A_r * T) @ c0\n            \n            # Reconstruct the FOM-space solution from the ROM\n            u_r_T = Phi @ c_T\n\n        # Compute final-time relative error\n        norm_u_T = np.linalg.norm(u_T)\n        if norm_u_T < 1e-15:\n            E_final = 0.0\n        else:\n            E_final = np.linalg.norm(u_T - u_r_T) / norm_u_T\n            \n        all_results.extend([E_proj, E_final])\n\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Real-world systems are often described by parameters that can change, such as material properties or operating conditions. This practice explores the challenge of parametric dependence by building a POD basis for an advection-diffusion system at a specific 'training' parameter value. You will then test the resulting Reduced-Order Model (ROM) at different parameter values , revealing the inherent limitations of a standard POD basis and motivating the need for more advanced parametric model reduction techniques.",
            "id": "3265932",
            "problem": "Consider the one-dimensional linear advection-diffusion initial-boundary value problem on the spatial interval $x \\in (0,1)$ with homogeneous Dirichlet boundary conditions, governed by the partial differential equation\n$$\n\\frac{\\partial u}{\\partial t}(x,t;\\mu) \\;=\\; \\mu \\,\\frac{\\partial^2 u}{\\partial x^2}(x,t;\\mu) \\;-\\; a \\,\\frac{\\partial u}{\\partial x}(x,t;\\mu), \\quad u(0,t;\\mu) = 0,\\quad u(1,t;\\mu) = 0,\\quad u(x,0;\\mu) = u_0(x),\n$$\nwhere $\\mu > 0$ is the diffusion parameter and $a \\ge 0$ is the advection speed. The Reduced-Order Model (ROM) will be constructed using a Galerkin projection onto a basis obtained via Proper Orthogonal Decomposition (POD) of snapshots generated at a training parameter $\\mu_{\\text{train}}$, and then applied to test parameters $\\mu_{\\text{test}}$ of the same partial differential equation.\n\nStarting from fundamental definitions:\n- Use the method-of-lines to semi-discretize the spatial derivatives on $N$ interior grid points with uniform spacing $h$, where $h = \\frac{1}{N+1}$ and the interior nodes are $x_i = i h$ for $i = 1,2,\\dots,N$. Approximate $\\frac{\\partial^2 u}{\\partial x^2}$ using the standard second-order centered finite difference, and approximate $\\frac{\\partial u}{\\partial x}$ using the first-order upwind finite difference consistent with $a \\ge 0$. This yields a semi-discrete ordinary differential equation\n$$\n\\frac{d \\mathbf{u}}{dt}(t;\\mu) \\;=\\; A(\\mu)\\,\\mathbf{u}(t;\\mu),\n$$\nwhere $\\mathbf{u}(t;\\mu) \\in \\mathbb{R}^N$ and $A(\\mu) \\in \\mathbb{R}^{N \\times N}$ is the parameter-dependent spatial operator formed from the discretizations.\n- Advance the semi-discrete system in time using the implicit Euler method. With time step $\\Delta t$ and $t_k = k\\,\\Delta t$, the update satisfies\n$$\n\\left(I - \\Delta t\\,A(\\mu)\\right)\\,\\mathbf{u}^{k+1} \\;=\\; \\mathbf{u}^{k},\n$$\nwhere $\\mathbf{u}^k \\approx \\mathbf{u}(t_k;\\mu)$.\n- Generate a snapshot matrix $X \\in \\mathbb{R}^{N \\times (K+1)}$ at the training parameter $\\mu_{\\text{train}}$ by concatenating the state vectors $\\mathbf{u}^k$ over $k = 0,1,\\dots,K$ for final time $T = K\\,\\Delta t$. Compute the Proper Orthogonal Decomposition (POD) basis of rank $r$ using the Singular Value Decomposition (SVD), $X = U\\,\\Sigma\\,V^\\top$, and take the first $r$ columns of $U$ as the orthonormal basis $V \\in \\mathbb{R}^{N \\times r}$. Proper Orthogonal Decomposition (POD) is defined here as the computation of an orthonormal basis that maximizes captured energy (in the Euclidean inner product) from the snapshot ensemble via the Singular Value Decomposition (SVD).\n- Form the Galerkin-projected Reduced-Order Model (ROM) for a test parameter $\\mu_{\\text{test}}$ by projecting the full operator onto the POD basis, yielding\n$$\nA_r(\\mu_{\\text{test}}) \\;=\\; V^\\top A(\\mu_{\\text{test}}) V \\in \\mathbb{R}^{r \\times r},\n$$\nand evolve the reduced system with implicit Euler:\n$$\n\\left(I_r - \\Delta t\\,A_r(\\mu_{\\text{test}})\\right)\\,\\mathbf{y}^{k+1} \\;=\\; \\mathbf{y}^{k}, \\quad \\text{with} \\quad \\mathbf{y}^0 \\;=\\; V^\\top \\mathbf{u}^0, \\quad \\mathbf{u}_{\\text{ROM}}^{k} \\;=\\; V\\,\\mathbf{y}^{k}.\n$$\n\nYour program must implement the above using the following scientifically consistent and self-contained test suite and parameters:\n- Spatial discretization:\n  - $N = 64$ interior points.\n  - Domain length $L = 1$, grid spacing $h = \\frac{L}{N+1}$, interior nodes $x_i = i\\,h$ for $i=1,\\dots,N$.\n  - Homogeneous Dirichlet boundaries are enforced by the stencil construction on the interior unknowns.\n- Time discretization:\n  - Implicit Euler with $\\Delta t = 10^{-3}$.\n  - Final time $T = 0.2$, so $K = \\frac{T}{\\Delta t} = 200$ time steps.\n- PDE parameters:\n  - Advection speed $a = 1.0$.\n  - Training diffusion parameter $\\mu_{\\text{train}} = 0.01$.\n- Initial condition:\n  - $u_0(x) = \\sin(\\pi x) + \\tfrac{1}{2}\\,\\sin(2\\pi x)$, discretized on the interior nodes to form $\\mathbf{u}^0 \\in \\mathbb{R}^N$.\n- POD basis:\n  - Rank $r = 6$ constructed from snapshots at $\\mu_{\\text{train}}$ using the Singular Value Decomposition (SVD) of the snapshot matrix as described above.\n\nEvaluate the ROM at the following four test parameters to analyze the impact of generating the basis from a different parameter regime:\n- Case $1$: $\\mu_{\\text{test}} = \\mu_{\\text{train}}$.\n- Case $2$: $\\mu_{\\text{test}} = 1.2\\,\\mu_{\\text{train}}$.\n- Case $3$: $\\mu_{\\text{test}} = 5\\,\\mu_{\\text{train}}$.\n- Case $4$: $\\mu_{\\text{test}} = 10^{-4}$.\n\nFor each case, compute the final-time relative error between the full-order model (FOM) and ROM solutions,\n$$\ne_{\\text{final}} \\;=\\; \\frac{\\left\\|\\mathbf{u}^{K} - \\mathbf{u}_{\\text{ROM}}^{K}\\right\\|_2}{\\left\\|\\mathbf{u}^{K}\\right\\|_2},\n$$\nwhere $\\|\\cdot\\|_2$ is the Euclidean norm.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the four cases $[\\text{Case 1}, \\text{Case 2}, \\text{Case 3}, \\text{Case 4}]$, with each value printed as a decimal with eight digits after the decimal point (e.g., $[0.00123456,0.00234567,0.01234567,0.12345678]$). No physical units are involved, and all angles, if any, are implicitly in radians, though none are used here. The answers are pure real numbers in decimal form.",
            "solution": "The user-provided problem is a well-defined and scientifically sound exercise in numerical methods for partial differential equations, specifically focusing on reduced-order modeling using Proper Orthogonal Decomposition (POD). The problem is validated as follows:\n\n- **Scientific Grounding**: The problem is based on the one-dimensional linear advection-diffusion equation, a canonical model in fluid dynamics and transport phenomena. The numerical methods specified—Method of Lines, finite differences (central for diffusion, upwind for advection), implicit Euler time integration, and POD via Singular Value Decomposition (SVD)—are all standard and rigorously established techniques in scientific computing. The problem is free of any scientific or factual unsoundness.\n- **Well-Posedness and Completeness**: The problem statement provides all necessary information to construct and solve the problem. This includes the PDE, domain, boundary and initial conditions, all numerical parameters ($N, L, a, \\Delta t, T, r$), the precise definitions of the discretization stencils, the time integration scheme, the procedure for POD basis generation, and the specific test cases. The implicit Euler method ensures numerical stability. The upwind scheme is appropriate for the advective term. The overall problem is well-posed and self-contained.\n- **Objectivity and Clarity**: The problem is stated in precise, unambiguous mathematical language. There is no subjective or opinion-based content. A minor notational ambiguity exists where the POD basis is called $V$ but is defined using the columns of $U$ from the SVD $X=U\\Sigma V^\\top$. However, this is clarified by the explicit instruction \"take the first $r$ columns of $U$ as the orthonormal basis,\" which aligns with the standard convention for POD of state trajectories. This does not impede a unique and correct implementation.\n\nGiven that the problem is valid, a step-by-step solution is developed.\n\n### 1. Full-Order Model (FOM) Discretization\n\nThe partial differential equation is:\n$$\n\\frac{\\partial u}{\\partial t} \\;=\\; \\mu \\,\\frac{\\partial^2 u}{\\partial x^2} \\;-\\; a \\,\\frac{\\partial u}{\\partial x}\n$$\nWe discretize the spatial domain $x \\in (0,1)$ into $N=64$ interior points $x_i = i h$ for $i=1,\\dots,N$, with grid spacing $h = 1/(N+1)$. The state of the system is represented by the vector $\\mathbf{u}(t) \\in \\mathbb{R}^N$, where $(\\mathbf{u})_i = u(x_i, t)$.\n\nThe spatial derivatives are approximated using finite differences as specified:\n- **Diffusion Term (2nd-order centered)**:\n$$\n\\frac{\\partial^2 u}{\\partial x^2}\\bigg|_{x_i} \\approx \\frac{u(x_{i+1},t) - 2u(x_i,t) + u(x_{i-1},t)}{h^2} = \\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2}\n$$\n- **Advection Term (1st-order upwind for $a \\ge 0$)**:\n$$\n\\frac{\\partial u}{\\partial x}\\bigg|_{x_i} \\approx \\frac{u(x_i,t) - u(x_{i-1},t)}{h} = \\frac{u_i - u_{i-1}}{h}\n$$\n\nSubstituting these approximations into the PDE for each interior node $x_i$ yields a system of ordinary differential equations (ODEs), $\\frac{d\\mathbf{u}}{dt} = A(\\mu)\\mathbf{u}$. The $i$-th equation is:\n$$\n\\frac{du_i}{dt} = \\mu \\left( \\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2} \\right) - a \\left( \\frac{u_i - u_{i-1}}{h} \\right)\n$$\nHomogeneous Dirichlet boundary conditions $u(0,t)=u_0=0$ and $u(1,t)=u_{N+1}=0$ are incorporated into the stencils at the boundaries ($i=1$ and $i=N$). Rearranging the terms for $u_{i-1}$, $u_i$, and $u_{i+1}$ reveals the structure of the system matrix $A(\\mu)$:\n$$\n\\frac{du_i}{dt} = \\left(\\frac{\\mu}{h^2} + \\frac{a}{h}\\right) u_{i-1} + \\left(-\\frac{2\\mu}{h^2} - \\frac{a}{h}\\right) u_i + \\left(\\frac{\\mu}{h^2}\\right) u_{i+1}\n$$\nThis defines a tridiagonal matrix $A(\\mu) \\in \\mathbb{R}^{N \\times N}$ with the following diagonals:\n- **Main diagonal**: $-\\frac{2\\mu}{h^2} - \\frac{a}{h}$\n- **Sub-diagonal (lower)**: $\\frac{\\mu}{h^2} + \\frac{a}{h}$\n- **Super-diagonal (upper)**: $\\frac{\\mu}{h^2}$\n\n### 2. Time Integration and Snapshot Generation\n\nThe semi-discrete system is advanced in time using the implicit Euler method with timestep $\\Delta t = 10^{-3}$:\n$$\n\\frac{\\mathbf{u}^{k+1} - \\mathbf{u}^{k}}{\\Delta t} = A(\\mu) \\mathbf{u}^{k+1} \\implies \\left(I - \\Delta t\\,A(\\mu)\\right)\\,\\mathbf{u}^{k+1} = \\mathbf{u}^{k}\n$$\nTo obtain the solution at step $k+1$, we solve a linear system at each time step.\n\nSnapshots are generated by solving the FOM for the training parameter $\\mu_{\\text{train}} = 0.01$. The initial condition is $\\mathbf{u}^0$, obtained by evaluating $u_0(x) = \\sin(\\pi x) + \\frac{1}{2}\\sin(2\\pi x)$ at the grid points $x_i$. The simulation runs up to time $T=0.2$, which corresponds to $K = T/\\Delta t = 200$ steps. The snapshot matrix $X \\in \\mathbb{R}^{N \\times (K+1)}$ is formed by collecting the state vectors:\n$$\nX = \\begin{bmatrix} | & | & & | \\\\ \\mathbf{u}^0 & \\mathbf{u}^1 & \\dots & \\mathbf{u}^K \\\\ | & | & & | \\end{bmatrix}\n$$\n\n### 3. POD Basis Construction\n\nThe POD basis is computed from the Singular Value Decomposition (SVD) of the snapshot matrix $X$:\n$$\nX = U \\Sigma V^\\top\n$$\nThe columns of the matrix $U \\in \\mathbb{R}^{N \\times (K+1)}$ are the left singular vectors, which are orthonormal and represent the spatial modes of the system's dynamics. The optimal rank-$r$ basis, in the sense of capturing the most energy, is formed by the first $r$ columns of $U$. We construct the basis matrix $V_{\\text{basis}} \\in \\mathbb{R}^{N \\times r}$ using $r=6$:\n$$\nV_{\\text{basis}} = U[:, 0:r]\n$$\n\n### 4. Reduced-Order Model (ROM) Formulation and Simulation\n\nThe ROM is constructed by projecting the governing FOM equations onto the low-dimensional subspace spanned by $V_{\\text{basis}}$. An approximate solution is sought in the form $\\mathbf{u}_{\\text{ROM}}(t) = V_{\\text{basis}}\\mathbf{y}(t)$, where $\\mathbf{y}(t) \\in \\mathbb{R}^r$ are the reduced coordinates.\nSubstituting this into the semi-discrete system and applying Galerkin projection (pre-multiplying by $V_{\\text{basis}}^\\top$) yields the ROM for a given test parameter $\\mu_{\\text{test}}$:\n$$\nV_{\\text{basis}}^\\top V_{\\text{basis}} \\frac{d\\mathbf{y}}{dt} = V_{\\text{basis}}^\\top A(\\mu_{\\text{test}}) V_{\\text{basis}} \\mathbf{y}\n$$\nSince $V_{\\text{basis}}$ is orthonormal ($V_{\\text{basis}}^\\top V_{\\text{basis}} = I_r$), this simplifies to:\n$$\n\\frac{d\\mathbf{y}}{dt} = A_r(\\mu_{\\text{test}}) \\mathbf{y}, \\quad \\text{where} \\quad A_r(\\mu_{\\text{test}}) = V_{\\text{basis}}^\\top A(\\mu_{\\text{test}}) V_{\\text{basis}}\n$$\nThe reduced operator $A_r \\in \\mathbb{R}^{r \\times r}$. The initial condition for the ROM is the projection of the full-order initial condition: $\\mathbf{y}^0 = V_{\\text{basis}}^\\top \\mathbf{u}^0$.\nThe ROM is time-stepped with implicit Euler, analogous to the FOM:\n$$\n\\left(I_r - \\Delta t\\,A_r(\\mu_{\\text{test}})\\right)\\,\\mathbf{y}^{k+1} = \\mathbf{y}^{k}\n$$\nAfter simulating to the final time $T$ to find $\\mathbf{y}^K$, the solution is reconstructed back to the full state space: $\\mathbf{u}_{\\text{ROM}}^K = V_{\\text{basis}}\\mathbf{y}^K$.\n\n### 5. Error Evaluation\n\nFor each test case $\\mu_{\\text{test}}$, we compute both the FOM solution $\\mathbf{u}^K$ and the ROM solution $\\mathbf{u}_{\\text{ROM}}^K$ at the final time $T=0.2$. The relative error is calculated as:\n$$\ne_{\\text{final}} = \\frac{\\|\\mathbf{u}^K - \\mathbf{u}_{\\text{ROM}}^K\\|_2}{\\|\\mathbf{u}^K\\|_2}\n$$\nThis procedure is repeated for all four specified values of $\\mu_{\\text{test}}$, and the resulting errors are reported.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a POD-Galerkin Reduced-Order Model for a 1D advection-diffusion\n    equation and evaluates its accuracy for several test parameters.\n    \"\"\"\n    # --------------------------------------------------------------------------\n    # 1. Define problem parameters and grid\n    # --------------------------------------------------------------------------\n    N = 64                  # Number of interior spatial points\n    L = 1.0                 # Domain length\n    a = 1.0                 # Advection speed\n    dt = 1.0e-3             # Time step\n    T = 0.2                 # Final time\n    r = 6                   # Rank of POD basis\n    mu_train = 0.01         # Training diffusion parameter\n\n    test_cases_mu = [\n        mu_train,\n        1.2 * mu_train,\n        5.0 * mu_train,\n        1.0e-4\n    ]\n\n    h = L / (N + 1)         # Grid spacing\n    K = int(T / dt)         # Number of time steps\n    x_grid = np.arange(1, N + 1) * h\n\n    # Initial condition\n    u0 = np.sin(np.pi * x_grid) + 0.5 * np.sin(2 * np.pi * x_grid)\n\n    # Memoization caches for efficiency\n    memo_A = {}\n    memo_fom_final_state = {}\n\n    # --------------------------------------------------------------------------\n    # 2. Helper functions for FOM and ROM\n    # --------------------------------------------------------------------------\n    def build_A(mu):\n        \"\"\"Constructs the FOM spatial discretization matrix A(mu).\"\"\"\n        if mu in memo_A:\n            return memo_A[mu]\n\n        h2 = h * h\n        diag_main = -2.0 * mu / h2 - a / h\n        diag_upper = mu / h2\n        diag_lower = mu / h2 + a / h\n        \n        A = np.zeros((N, N))\n        np.fill_diagonal(A, diag_main)\n        np.fill_diagonal(A[1:, :-1], diag_lower)\n        np.fill_diagonal(A[:-1, 1:], diag_upper)\n        \n        memo_A[mu] = A\n        return A\n\n    def run_fom(mu, collect_snapshots=False):\n        \"\"\"Simulates the Full-Order Model (FOM).\"\"\"\n        if not collect_snapshots and mu in memo_fom_final_state:\n            return memo_fom_final_state[mu], None\n\n        A = build_A(mu)\n        # Implicit Euler matrix: M * u^{k+1} = u^k\n        M = np.eye(N) - dt * A\n        u = u0.copy()\n\n        if collect_snapshots:\n            snapshots = np.zeros((N, K + 1))\n            snapshots[:, 0] = u\n            for k in range(K):\n                u = np.linalg.solve(M, u)\n                snapshots[:, k + 1] = u\n            return u, snapshots\n        else:\n            for k in range(K):\n                u = np.linalg.solve(M, u)\n            memo_fom_final_state[mu] = u\n            return u, None\n    \n    # --------------------------------------------------------------------------\n    # 3. Generate POD basis from training data\n    # --------------------------------------------------------------------------\n    _, X_train = run_fom(mu_train, collect_snapshots=True)\n    \n    # Compute SVD: X = U * S * Vh. The POD basis are the left singular vectors (columns of U).\n    # The problem description calls the basis 'V', but it's constructed from 'U'.\n    U, _, _ = np.linalg.svd(X_train, full_matrices=False)\n    V_basis = U[:, :r]\n\n    # --------------------------------------------------------------------------\n    # 4. Evaluate ROM for each test case\n    # --------------------------------------------------------------------------\n    results = []\n    \n    # Project initial condition onto the POD basis\n    y0 = V_basis.T @ u0\n    \n    for mu_test in test_cases_mu:\n        # Get the true FOM solution at the final time for comparison\n        u_fom_final, _ = run_fom(mu_test, collect_snapshots=False)\n\n        # Build and run the ROM\n        A_test = build_A(mu_test)\n        \n        # Project the FOM operator to get the ROM operator\n        A_r = V_basis.T @ A_test @ V_basis\n        \n        # Implicit Euler matrix for the ROM\n        M_r = np.eye(r) - dt * A_r\n        \n        y = y0.copy()\n        for _ in range(K):\n            y = np.linalg.solve(M_r, y)\n        \n        # Reconstruct the full-order solution from the ROM state\n        u_rom_final = V_basis @ y\n        \n        # Calculate final-time relative error\n        error_norm = np.linalg.norm(u_fom_final - u_rom_final)\n        fom_norm = np.linalg.norm(u_fom_final)\n        \n        if fom_norm == 0:\n            # Avoid division by zero, though unlikely for this problem\n            relative_error = error_norm\n        else:\n            relative_error = error_norm / fom_norm\n            \n        results.append(relative_error)\n        \n    # --------------------------------------------------------------------------\n    # 5. Format and print the final output\n    # --------------------------------------------------------------------------\n    formatted_results = [f\"{res:.8f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Finally, we tackle a problem directly from computational electromagnetics, involving vector fields discretized with curl-conforming Whitney edge elements. This advanced practice addresses the critical choice of the inner product when constructing the POD basis—comparing a simple coefficient-based approach with a physically-grounded one using the finite element mass matrix. By analyzing the impact on projection error, curl preservation, and tangential continuity , you will gain insight into how to build reduced-order models that respect the fundamental structure of Maxwell's equations in the space $H(\\mathrm{curl})$.",
            "id": "3343556",
            "problem": "Consider time-harmonic computational electromagnetics in two spatial dimensions, where the electric field is modeled in the curl-conforming Sobolev space of square-integrable vector fields with square-integrable curl, denoted by $H(\\mathrm{curl})$. The lowest-order $H(\\mathrm{curl})$-conforming finite element space on a simplicial mesh is spanned by Whitney $1$-forms (Whitney edge elements), which are tangentially continuous across interior edges and form the $1$-form space of the discrete de Rham complex. The Proper Orthogonal Decomposition (POD) may be performed in the coefficient space with the Euclidean inner product or in the physical space with the $L^2$ inner product, the latter induced by the mass matrix associated with the Whitney $1$-forms. The goal is to compare these two POD constructions in terms of preservation of curl-conformity and tangential continuity, using discrete metrics derived from first principles.\n\nYou are to implement a program that constructs the following from first principles:\n- A triangular mesh (with explicitly specified vertices and connectivity),\n- The global edge set with a consistent orientation, the face-edge oriented incidence matrix $C$, the Whitney $1$-form mass matrix $M_1$ representing the $L^2$ inner product $\\int_{\\Omega} \\boldsymbol{u} \\cdot \\boldsymbol{v}\\, \\mathrm{d}x$, and the face (Whitney $2$-form) mass matrix $M_2$ representing the $L^2$ inner product of scalar $2$-forms $\\int_{\\Omega} \\phi\\, \\psi\\, \\mathrm{d}x$,\n- Snapshot vectors $\\boldsymbol{s}_\\ell \\in \\mathbb{R}^{N_e}$ of edge-based degrees of freedom obtained by integrating prescribed analytic vector fields along oriented edges (the degree of freedom associated with a global oriented edge is the line integral of the field’s tangential component along that oriented edge),\n- Two reduced bases of rank $r$: one via coefficient-space POD (Euclidean inner product on coefficients) and one via physical $L^2$ POD (mass-weighted using $M_1$).\n\nUse the following fundamental principles as the base of your derivations and implementation:\n- Maxwell–Faraday law in integral form implies Stokes’ theorem for the curl: for any sufficiently smooth $\\boldsymbol{E}$ and any triangle (face) $T$, $\\int_T (\\nabla \\times \\boldsymbol{E}) \\cdot \\boldsymbol{\\hat{z}}\\,\\mathrm{d}x = \\oint_{\\partial T} \\boldsymbol{E} \\cdot \\boldsymbol{t}\\,\\mathrm{d}s$. In the Whitney complex, the discrete curl mapping from edge degrees of freedom to face degrees of freedom is the oriented face-edge incidence matrix $C$.\n- Whitney $1$-forms on a triangle with barycentric coordinates $(\\lambda_0,\\lambda_1,\\lambda_2)$ and gradients $(\\nabla \\lambda_0,\\nabla \\lambda_1,\\nabla \\lambda_2)$ are, for an oriented local edge $(i \\to j)$, given by $\\boldsymbol{W}_{ij}(\\boldsymbol{x}) = \\lambda_i(\\boldsymbol{x}) \\nabla \\lambda_j - \\lambda_j(\\boldsymbol{x}) \\nabla \\lambda_i$. These span an $H(\\mathrm{curl})$-conforming space and are tangentially continuous across interior edges. The mass matrix entries are $[M_1]_{ef} = \\int_{\\Omega} \\boldsymbol{W}_e \\cdot \\boldsymbol{W}_f\\,\\mathrm{d}x$, assembled by summing element contributions. Use triangle quadrature that is exact for polynomials up to degree $2$.\n- The physical $L^2$-POD with respect to $M_1$ is obtained by forming the mass-weighted snapshot matrix $L^\\top S$ where $M_1 = L L^\\top$ is a Cholesky factorization with $L$ lower triangular, taking a singular value decomposition, and mapping back to coefficient space by $L^{-\\top}$. The coefficient-space POD uses the standard Euclidean inner product on columns of $S$.\n\nDefine the analytic test fields by parameters $(a,b)$ as\n$$\n\\boldsymbol{E}_{a,b}(x,y) = \\begin{bmatrix} \\sin(a x)\\cos(b y) \\\\ \\cos(a x)\\sin(b y) \\end{bmatrix},\n$$\nwhere $a$ and $b$ are given real numbers. For each oriented global edge with endpoints $(x_0,y_0)$ and $(x_1,y_1)$, the snapshot degree of freedom is\n$$\n\\int_{0}^{1} \\boldsymbol{E}_{a,b}\\!\\left(x_0 + s(x_1-x_0),\\, y_0 + s(y_1-y_0)\\right) \\cdot \\boldsymbol{t}\\, \\lVert \\boldsymbol{e} \\rVert \\,\\mathrm{d}s,\n$$\nwhere $\\boldsymbol{e} = (x_1-x_0, y_1-y_0)$, $\\lVert \\boldsymbol{e} \\rVert$ is its Euclidean length, and $\\boldsymbol{t} = \\boldsymbol{e}/\\lVert \\boldsymbol{e} \\rVert$ is the unit tangent consistent with the edge orientation.\n\nFor each test case below, construct:\n- A training snapshot matrix $S \\in \\mathbb{R}^{N_e \\times N_{\\mathrm{train}}}$ by evaluating line integrals for specified $(a,b)$ pairs,\n- A test set $\\{\\boldsymbol{s}^{(\\mathrm{test})}_j\\}_{j=1}^{N_{\\mathrm{test}}}$ with specified $(a,b)$ pairs,\n- Two reduced bases of rank $r$: $V_{\\mathrm{coef}} \\in \\mathbb{R}^{N_e \\times r}$ obtained by coefficient-space POD and $V_{\\mathrm{phys}} \\in \\mathbb{R}^{N_e \\times r}$ obtained by physical $L^2$-POD.\n\nCompute the following metrics:\n1) Physical $L^2$ projection error for each test vector $\\boldsymbol{s}$ onto the span of $V$:\n$$\n\\varepsilon_{E}(V,\\boldsymbol{s}) = \\frac{\\lVert \\boldsymbol{s} - V (V^\\top M_1 V)^{-1} V^\\top M_1 \\boldsymbol{s} \\rVert_{M_1}}{\\lVert \\boldsymbol{s} \\rVert_{M_1}},\n\\quad \\lVert \\boldsymbol{w} \\rVert_{M_1} := \\sqrt{\\boldsymbol{w}^\\top M_1 \\boldsymbol{w}}.\n$$\nUse the average of $\\varepsilon_E$ over all test vectors for comparison.\n\n2) Curl-approximation error (face $L^2$) for each test vector $\\boldsymbol{s}$:\n$$\n\\varepsilon_{\\mathrm{curl}}(V,\\boldsymbol{s}) =\n\\frac{\\min_{\\boldsymbol{\\alpha} \\in \\mathbb{R}^r} \\lVert C V \\boldsymbol{\\alpha} - C \\boldsymbol{s} \\rVert_{M_2}}{\\lVert C \\boldsymbol{s} \\rVert_{M_2}}\n=\n\\frac{\\lVert C V \\boldsymbol{\\alpha}^\\star - C \\boldsymbol{s} \\rVert_{M_2}}{\\lVert C \\boldsymbol{s} \\rVert_{M_2}},\n$$\nwhere\n$$\n\\boldsymbol{\\alpha}^\\star = \\left(V^\\top C^\\top M_2 C V\\right)^{-1} V^\\top C^\\top M_2 C \\boldsymbol{s},\n\\quad \\lVert \\boldsymbol{q} \\rVert_{M_2} := \\sqrt{\\boldsymbol{q}^\\top M_2 \\boldsymbol{q}}.\n$$\nUse the average of $\\varepsilon_{\\mathrm{curl}}$ over all test vectors for comparison.\n\n3) Tangential continuity check on interior edges for each reduced basis column (mode) $\\boldsymbol{v}$:\n- For every interior edge shared by two triangles, evaluate the reconstructed vector field from each adjacent triangle at the edge midpoint using the Whitney $1$-form expansion with coefficients given by $\\boldsymbol{v}$, then take the difference of the tangential components along the edge. Let $\\Delta_{\\mathrm{tan}}(\\boldsymbol{v})$ be the maximum absolute jump magnitude over all interior edges for this mode. Report the maximum over all modes, $\\max_{k=1,\\dots,r} \\Delta_{\\mathrm{tan}}(\\boldsymbol{v}_k)$.\n\nFor numerical stability when inverting reduced Gram matrices, it is acceptable to use a small Tikhonov regularization $\\delta I$ with $\\delta = 10^{-12}$ added to the Gram matrices prior to inversion, i.e., replace $A^{-1}$ by $(A + \\delta I)^{-1}$.\n\nTest Suite:\n- Case $1$ (uniform mesh, moderate rank):\n  - Vertices: $(0,0)$, $(1,0)$, $(1,1)$, $(0,1)$.\n  - Triangles (counterclockwise): $[0,1,2]$, $[0,2,3]$.\n  - Training parameters $(a,b)$: $(\\pi,\\pi)$, $(2\\pi,\\pi)$, $(\\pi,2\\pi)$.\n  - Test parameters $(a,b)$: $(\\tfrac{3}{2}\\pi, \\tfrac{1}{2}\\pi)$, $(\\tfrac{5}{2}\\pi, \\tfrac{3}{2}\\pi)$.\n  - Reduced rank: $r=2$.\n\n- Case $2$ (skewed mesh, moderate rank):\n  - Vertices: $(0,0)$, $(1.2,0)$, $(1.7,1.0)$, $(-0.2,1.0)$.\n  - Triangles (counterclockwise): $[0,1,2]$, $[0,2,3]$.\n  - Training parameters $(a,b)$: $(\\pi,\\pi)$, $(2\\pi,\\pi)$, $(\\pi,2\\pi)$.\n  - Test parameters $(a,b)$: $(\\tfrac{5}{2}\\pi, \\tfrac{3}{2}\\pi)$, $(2\\pi,2\\pi)$.\n  - Reduced rank: $r=2$.\n\n- Case $3$ (uniform mesh, saturation rank):\n  - Vertices: $(0,0)$, $(1,0)$, $(1,1)$, $(0,1)$.\n  - Triangles (counterclockwise): $[0,1,2]$, $[0,2,3]$.\n  - Training parameters $(a,b)$: $(\\pi,\\pi)$, $(2\\pi,\\pi)$, $(\\pi,2\\pi)$.\n  - Test parameters $(a,b)$: identical to the training set.\n  - Reduced rank: $r=3$.\n\nAngle values $a$ and $b$ are in radians. There are no physical units required for the output.\n\nRequired final outputs per case:\n- Let $\\overline{\\varepsilon}_E^{\\mathrm{coef}}$ and $\\overline{\\varepsilon}_E^{\\mathrm{phys}}$ be the averages of $\\varepsilon_E$ over the test set for the coefficient-space POD and the physical $L^2$-POD, respectively. Define $b_1$ to be $1$ if $\\overline{\\varepsilon}_E^{\\mathrm{phys}} < \\overline{\\varepsilon}_E^{\\mathrm{coef}}$, and $0$ otherwise.\n- Let $\\overline{\\varepsilon}_{\\mathrm{curl}}^{\\mathrm{coef}}$ and $\\overline{\\varepsilon}_{\\mathrm{curl}}^{\\mathrm{phys}}$ be the averages of $\\varepsilon_{\\mathrm{curl}}$ over the test set for the two methods. Define $b_2$ to be $1$ if $\\overline{\\varepsilon}_{\\mathrm{curl}}^{\\mathrm{phys}} < \\overline{\\varepsilon}_{\\mathrm{curl}}^{\\mathrm{coef}}$, and $0$ otherwise.\n- Let $\\Delta^{\\mathrm{coef}}_{\\max}$ and $\\Delta^{\\mathrm{phys}}_{\\max}$ be the maximum tangential jumps for the two reduced bases. Using the threshold $\\tau = 10^{-10}$, define $b_3$ to be $1$ if $\\Delta^{\\mathrm{coef}}_{\\max} \\le \\tau$ and $\\Delta^{\\mathrm{phys}}_{\\max} \\le \\tau$, and $0$ otherwise.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each case contributes a three-entry list $[b_1,b_2,b_3]$. For the three cases above, the final output must have the form\n$$\n\\big[ [b_1^{(1)}, b_2^{(1)}, b_3^{(1)}], [b_1^{(2)}, b_2^{(2)}, b_3^{(2)}], [b_1^{(3)}, b_2^{(3)}, b_3^{(3)}] \\big].\n$$\nAll entries must be integers, either $0$ or $1$.",
            "solution": "The problem is a valid, well-posed computational task grounded in the principles of finite element methods for computational electromagnetics. It requires the implementation of a lowest-order $H(\\mathrm{curl})$-conforming finite element space (Whitney $1$-forms) and a comparison of two Proper Orthogonal Decomposition (POD) schemes. All required data, formulae, and evaluation metrics are explicitly provided and are consistent with established scientific literature.\n\nThe solution will be constructed following these steps:\n1.  **Discretization Setup**: For each test case, the computational domain is first discretized. From the given vertices and triangles, a global set of oriented edges is constructed. This defines the degrees of freedom for the Whitney $1$-form space. We then construct the key discrete operators: the oriented face-edge incidence matrix $C$ (discrete curl), the edge mass matrix $M_1$ (representing the $L^2$ inner product for vector fields), and the face mass matrix $M_2$ (representing the $L^2$ inner product for scalar fields).\n2.  **Finite Element Matrices from First Principles**:\n    *   The matrix $C \\in \\mathbb{R}^{N_f \\times N_e}$ maps edge coefficients to face values. An entry $C_{fe}$ is $+1$ or $-1$ if edge $e$ belongs to the boundary of face $f$, with the sign indicating matching or opposing orientation relative to the face's counter-clockwise boundary traversal. Otherwise, it is $0$.\n    *   The face mass matrix $M_2 \\in \\mathbb{R}^{N_f \\times N_f}$ is diagonal, with entries $[M_2]_{ff}$ being the area of face $f$, as Whitney $2$-forms are piecewise constant.\n    *   The edge mass matrix $M_1 \\in \\mathbb{R}^{N_e \\times N_e}$ has entries $[M_1]_{ef} = \\int_{\\Omega} \\boldsymbol{W}_e \\cdot \\boldsymbol{W}_f \\, \\mathrm{d}x$, where $\\boldsymbol{W}_e$ is the Whitney $1$-form basis function for edge $e$. This matrix is assembled by summing contributions from local element mass matrices. For a triangle $T$ with area $A_T$ and vertices $\\boldsymbol{v}_i, \\boldsymbol{v}_j, \\boldsymbol{v}_k$, the basis function for edge $(\\boldsymbol{v}_i, \\boldsymbol{v}_j)$ is $\\boldsymbol{W}_{ij} = \\lambda_i \\nabla\\lambda_j - \\lambda_j \\nabla\\lambda_i$, where $\\lambda_i$ are barycentric coordinates. The integrand $\\boldsymbol{W}_e \\cdot \\boldsymbol{W}_f$ is a quadratic polynomial in position. We use a $3$-point quadrature rule (evaluating at the midpoints of the triangle's edges), which is exact for quadratic polynomials, to compute the local matrix entries.\n3.  **Snapshot Generation**: Snapshot vectors are generated by projecting the continuous analytic field $\\boldsymbol{E}_{a,b}(x,y)$ onto the finite element space. The degree of freedom for each edge is the line integral of the field's tangential component along that edge. This integral is computed numerically using high-precision quadrature. A set of snapshots for different parameters $(a,b)$ forms the snapshot matrix $S$.\n4.  **Proper Orthogonal Decomposition (POD)**: Two POD bases of rank $r$ are constructed from the training snapshot matrix $S$.\n    *   **Coefficient-space POD**: This corresponds to the standard POD formulation in Euclidean space. The basis $V_{\\mathrm{coef}}$ is obtained from the left singular vectors of the snapshot matrix $S$. These basis vectors are orthonormal in the Euclidean sense, i.e., $V_{\\mathrm{coef}}^\\top V_{\\mathrm{coef}} = I$.\n    *   **Physical $L^2$-space POD**: This method respects the physical inner product of the underlying function space, which is represented by the mass matrix $M_1$. We compute the Cholesky factorization $M_1 = L L^\\top$ and perform SVD on the mass-weighted snapshot matrix $L^\\top S$. The resulting POD modes are then mapped back to the original coefficient space via $L^{-\\top}$. The resulting basis $V_{\\mathrm{phys}}$ is orthonormal with respect to the $M_1$ inner product, i.e., $V_{\\mathrm{phys}}^\\top M_1 V_{\\mathrm{phys}} = I$.\n5.  **Evaluation Metrics**: The two reduced bases, $V_{\\mathrm{coef}}$ and $V_{\\mathrm{phys}}$, are evaluated against a set of test snapshots using three metrics:\n    *   **Physical $L^2$ Projection Error ($\\varepsilon_E$)**: This measures how well the reduced basis can represent the test snapshots in the natural energy norm of the space, induced by $M_1$. By construction, $L^2$-POD is optimal for this metric, so we expect $\\overline{\\varepsilon}_E^{\\mathrm{phys}} \\le \\overline{\\varepsilon}_E^{\\mathrm{coef}}$. The boolean flag $b_1$ tests this.\n    *   **Curl-Approximation Error ($\\varepsilon_{\\mathrm{curl}}$)**: This evaluates the ability of the reduced basis to approximate the curl of the test snapshots. The error is measured in the $L^2$ norm for faces, induced by $M_2$. This metric is crucial as it probes whether a basis optimized for field energy also preserves the differential structure, which is not guaranteed. The flag $b_2$ compares the performance of the two methods.\n    *   **Tangential Continuity ($\\Delta_{\\mathrm{tan}}$)**: The Whitney $1$-form basis functions are designed to be in the $H(\\mathrm{curl})$ space, which implies that any field expanded in this basis is tangentially continuous across interior element edges. This metric serves as a verification of the correctness of our finite element implementation. For any valid coefficient vector (including the columns of our reduced bases), the jump in the tangential component of the reconstructed field across interior edges should be zero up to machine precision. The flag $b_3$ checks if both bases satisfy this fundamental property below a small tolerance $\\tau = 10^{-10}$.\n\nThe implementation will proceed by systematically constructing these components for each test case and computing the specified boolean indicators $b_1, b_2, b_3$.",
            "answer": "```python\nimport numpy as np\nfrom scipy.integrate import quad\nfrom scipy.linalg import cholesky, solve_triangular, inv\n\ndef solve():\n    \"\"\"\n    Main solver function that iterates through test cases and prints the final result.\n    \"\"\"\n    test_cases = [\n        # Case 1: uniform mesh, moderate rank\n        {\n            \"vertices\": np.array([[0.0, 0.0], [1.0, 0.0], [1.0, 1.0], [0.0, 1.0]]),\n            \"triangles\": np.array([[0, 1, 2], [0, 2, 3]]),\n            \"train_params\": [(np.pi, np.pi), (2 * np.pi, np.pi), (np.pi, 2 * np.pi)],\n            \"test_params\": [(1.5 * np.pi, 0.5 * np.pi), (2.5 * np.pi, 1.5 * np.pi)],\n            \"r\": 2,\n        },\n        # Case 2: skewed mesh, moderate rank\n        {\n            \"vertices\": np.array([[0.0, 0.0], [1.2, 0.0], [1.7, 1.0], [-0.2, 1.0]]),\n            \"triangles\": np.array([[0, 1, 2], [0, 2, 3]]),\n            \"train_params\": [(np.pi, np.pi), (2 * np.pi, np.pi), (np.pi, 2 * np.pi)],\n            \"test_params\": [(2.5 * np.pi, 1.5 * np.pi), (2 * np.pi, 2 * np.pi)],\n            \"r\": 2,\n        },\n        # Case 3: uniform mesh, saturation rank\n        {\n            \"vertices\": np.array([[0.0, 0.0], [1.0, 0.0], [1.0, 1.0], [0.0, 1.0]]),\n            \"triangles\": np.array([[0, 1, 2], [0, 2, 3]]),\n            \"train_params\": [(np.pi, np.pi), (2 * np.pi, np.pi), (np.pi, 2 * np.pi)],\n            \"test_params\": [(np.pi, np.pi), (2 * np.pi, np.pi), (np.pi, 2 * np.pi)],\n            \"r\": 3,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result_tuple = _run_case(\n            case[\"vertices\"],\n            case[\"triangles\"],\n            case[\"train_params\"],\n            case[\"test_params\"],\n            case[\"r\"],\n        )\n        results.append(list(result_tuple))\n\n    # Format the final output string to remove spaces.\n    final_output_str = \"[\" + \",\".join(str(r).replace(\" \", \"\") for r in results) + \"]\"\n    print(final_output_str)\n\ndef _run_case(vertices, triangles, train_params, test_params, r):\n    \"\"\"\n    Processes a single test case.\n    \"\"\"\n    delta = 1e-12\n    tau = 1e-10\n\n    # 1. Mesh and Operators\n    mesh_data = _build_mesh_topology(vertices, triangles)\n    C = mesh_data[\"C\"]\n    M1, M2 = _build_mass_matrices(vertices, triangles, mesh_data)\n\n    # 2. Snapshot Generation\n    S_train = _generate_snapshots(vertices, mesh_data[\"global_edges\"], train_params)\n    test_vectors = [\n        _generate_snapshots(vertices, mesh_data[\"global_edges\"], [params]).flatten()\n        for params in test_params\n    ]\n\n    # 3. POD\n    V_coef = _pod_coefficient(S_train, r)\n    V_phys = _pod_physical(S_train, r, M1)\n\n    # 4. Metrics\n    # Metric 1: Projection Error\n    err_E_coef = np.mean([_calc_projection_error(V_coef, s, M1, delta) for s in test_vectors])\n    err_E_phys = np.mean([_calc_projection_error(V_phys, s, M1, delta) for s in test_vectors])\n\n    # Metric 2: Curl Error\n    err_curl_coef = np.mean([_calc_curl_error(V_coef, s, C, M2, delta) for s in test_vectors])\n    err_curl_phys = np.mean([_calc_curl_error(V_phys, s, C, M2, delta) for s in test_vectors])\n    \n    # Metric 3: Tangential Continuity\n    max_jump_coef = _calc_max_tangential_jump(V_coef, mesh_data)\n    max_jump_phys = _calc_max_tangential_jump(V_phys, mesh_data)\n\n    # 5. Boolean Indicators\n    b1 = 1 if err_E_phys  err_E_coef else 0\n    b2 = 1 if err_curl_phys  err_curl_coef else 0\n    b3 = 1 if max_jump_coef = tau and max_jump_phys = tau else 0\n\n    return b1, b2, b3\n\ndef _build_mesh_topology(vertices, triangles):\n    edge_map = {}\n    global_edges = []\n    \n    # Create global edge list with consistent orientation (low_idx -> high_idx)\n    sorted_tri_vtx = [tuple(sorted(tri)) for tri in triangles]\n    for tri_vtx in sorted_tri_vtx:\n        for i in range(3):\n            v1_idx, v2_idx = tri_vtx[i], tri_vtx[(i + 1) % 3]\n            edge = tuple(sorted((v1_idx, v2_idx)))\n            if edge not in edge_map:\n                edge_map[edge] = len(global_edges)\n                global_edges.append((edge[0], edge[1]))\n\n    num_faces = len(triangles)\n    num_edges = len(global_edges)\n    C = np.zeros((num_faces, num_edges))\n\n    for i, tri in enumerate(triangles):\n        face_edges = [(tri[0], tri[1]), (tri[1], tri[2]), (tri[2], tri[0])]\n        for v1, v2 in face_edges:\n            edge_key = tuple(sorted((v1, v2)))\n            edge_idx = edge_map[edge_key]\n            orientation = 1 if v1  v2 else -1\n            C[i, edge_idx] += orientation\n    \n    # Identify interior edges\n    edge_counts = {}\n    for tri in triangles:\n        for i in range(3):\n            edge = tuple(sorted((tri[i], tri[(i+1)%3])))\n            edge_counts[edge] = edge_counts.get(edge, 0) + 1\n    \n    interior_edges = [edge for edge, count in edge_counts.items() if count > 1]\n    \n    # For each interior edge, find adjacent triangles\n    adj_tris = {}\n    for edge in interior_edges:\n        adj_tris[edge] = []\n        for i, tri in enumerate(triangles):\n            tri_edges = {tuple(sorted((tri[j], tri[(j+1)%3]))) for j in range(3)}\n            if edge in tri_edges:\n                adj_tris[edge].append(i)\n\n    return {\n        \"vertices\": vertices,\n        \"triangles\": triangles,\n        \"edge_map\": edge_map,\n        \"global_edges\": global_edges,\n        \"C\": C,\n        \"interior_edges\": interior_edges,\n        \"adj_tris\": adj_tris,\n    }\n\n\ndef _build_mass_matrices(vertices, triangles, mesh_data):\n    num_edges = len(mesh_data[\"global_edges\"])\n    num_faces = len(triangles)\n    edge_map = mesh_data[\"edge_map\"]\n\n    M1 = np.zeros((num_edges, num_edges))\n    M2 = np.zeros((num_faces, num_faces))\n\n    for i, tri in enumerate(triangles):\n        v = vertices[tri]\n        v0, v1, v2 = v[0], v[1], v[2]\n        \n        # Area and gradients of barycentric coordinates\n        area = 0.5 * np.linalg.det(np.array([[v1[0]-v0[0], v2[0]-v0[0]], [v1[1]-v0[1], v2[1]-v0[1]]]))\n        if area = 0:\n            raise ValueError(\"Triangle has non-positive area, check orientation.\")\n        M2[i, i] = area\n\n        mat = np.array([[v0[0],v0[1],1],[v1[0],v1[1],1],[v2[0],v2[1],1]]).T\n        inv_mat = np.linalg.inv(mat)\n\n        def get_grads(iv):\n            return inv_mat[iv,:2]\n\n        grads_lambda = np.array([get_grads(0), get_grads(1), get_grads(2)])\n        \n        # Local edges in CCW order\n        local_edges_vtx_indices = [(0, 1), (1, 2), (2, 0)]\n        local_whitney_funcs = [\n            lambda l: l[0] * grads_lambda[1] - l[1] * grads_lambda[0],\n            lambda l: l[1] * grads_lambda[2] - l[2] * grads_lambda[1],\n            lambda l: l[2] * grads_lambda[0] - l[0] * grads_lambda[2],\n        ]\n\n        # Quadrature points (midpoints of edges)\n        quad_points = [(v0+v1)/2, (v1+v2)/2, (v2+v0)/2]\n        \n        # Barycentric coordinates of quadrature points\n        bary_coords = [np.array([0.5, 0.5, 0]), np.array([0, 0.5, 0.5]), np.array([0.5, 0, 0.5])]\n        \n        # Evaluate basis functions at quadrature points\n        W_vals = np.zeros((3, 3, 2))  # (basis_func_idx, quad_pt_idx, xy_comp)\n        for i_basis in range(3):\n            for i_quad in range(3):\n                W_vals[i_basis, i_quad, :] = local_whitney_funcs[i_basis](bary_coords[i_quad])\n        \n        # Compute local mass matrix\n        M_local = np.zeros((3, 3))\n        for i in range(3):\n            for j in range(3):\n                integral = np.sum([np.dot(W_vals[i, k], W_vals[j, k]) for k in range(3)])\n                M_local[i, j] = (area / 3.0) * integral\n        \n        # Assemble into global M1\n        global_indices = []\n        orientations = []\n        for v1_idx, v2_idx in local_edges_vtx_indices:\n            v1_abs, v2_abs = tri[v1_idx], tri[v2_idx]\n            edge_key = tuple(sorted((v1_abs, v2_abs)))\n            global_indices.append(edge_map[edge_key])\n            orientations.append(1 if v1_abs  v2_abs else -1)\n        \n        for i in range(3):\n            for j in range(3):\n                gi, gj = global_indices[i], global_indices[j]\n                si, sj = orientations[i], orientations[j]\n                M1[gi, gj] += si * sj * M_local[i, j]\n\n    return M1, M2\n\ndef _generate_snapshots(vertices, global_edges, params_list):\n    def analytic_E(x, y, a, b):\n        return np.array([np.sin(a * x) * np.cos(b * y), np.cos(a * x) * np.sin(b * y)])\n\n    num_edges = len(global_edges)\n    num_snapshots = len(params_list)\n    S = np.zeros((num_edges, num_snapshots))\n\n    for j, (a, b) in enumerate(params_list):\n        for i, edge in enumerate(global_edges):\n            v0 = vertices[edge[0]]\n            v1 = vertices[edge[1]]\n            dv = v1 - v0\n            \n            def integrand(s):\n                pt = v0 + s * dv\n                return np.dot(analytic_E(pt[0], pt[1], a, b), dv)\n            \n            # Use quad for accurate integration\n            integral_val, _ = quad(integrand, 0, 1, epsabs=1e-12, epsrel=1e-12)\n            S[i, j] = integral_val\n    return S\n\ndef _pod_coefficient(S, r):\n    U, _, _ = np.linalg.svd(S, full_matrices=False)\n    return U[:, :r]\n\ndef _pod_physical(S, r, M1):\n    L = cholesky(M1, lower=True)\n    S_w = L.T @ S\n    U_w, _, _ = np.linalg.svd(S_w, full_matrices=False)\n    U_w_r = U_w[:, :r]\n    V_phys = solve_triangular(L.T, U_w_r, lower=False)\n    return V_phys\n\ndef _calc_projection_error(V, s, M1, delta):\n    s_norm_M1 = np.sqrt(s.T @ M1 @ s)\n    if s_norm_M1  1e-14:\n        return 0.0\n    \n    gram_V = V.T @ M1 @ V\n    proj_s_coeffs = np.linalg.solve(gram_V + delta * np.eye(gram_V.shape[0]), V.T @ M1 @ s)\n    proj_s = V @ proj_s_coeffs\n    \n    residual = s - proj_s\n    residual_norm_M1 = np.sqrt(residual.T @ M1 @ residual)\n    \n    return residual_norm_M1 / s_norm_M1\n\ndef _calc_curl_error(V, s, C, M2, delta):\n    Cs = C @ s\n    norm_Cs_M2 = np.sqrt(Cs.T @ M2 @ Cs)\n    if norm_Cs_M2  1e-14:\n        return 0.0\n\n    CV = C @ V\n    gram_CV = CV.T @ M2 @ CV\n    alpha_star = np.linalg.solve(gram_CV + delta * np.eye(gram_CV.shape[0]), CV.T @ M2 @ Cs)\n    \n    residual = CV @ alpha_star - Cs\n    residual_norm_M2 = np.sqrt(residual.T @ M2 @ residual)\n    \n    return residual_norm_M2 / norm_Cs_M2\n\ndef _evaluate_field(v_coeffs, tri_idx, point, mesh_data):\n    vertices = mesh_data[\"vertices\"]\n    triangles = mesh_data[\"triangles\"]\n    edge_map = mesh_data[\"edge_map\"]\n    \n    tri_vtx_indices = triangles[tri_idx]\n    v = vertices[tri_vtx_indices]\n    v0, v1, v2 = v[0], v[1], v[2]\n    \n    mat = np.array([[v0[0],v1[0],v2[0]], [v0[1],v1[1],v2[1]], [1,1,1]])\n    lambda_coords = np.linalg.solve(mat, np.array([point[0], point[1], 1]))\n\n    grad_mat = np.array([[v0[0], v0[1], 1],[v1[0], v1[1], 1],[v2[0], v2[1], 1]]).T\n    inv_grad_mat = np.linalg.inv(grad_mat)\n    \n    grads_lambda = np.array([inv_grad_mat[0,:2], inv_grad_mat[1,:2], inv_grad_mat[2,:2]])\n    \n    local_edges_vtx_indices = [(0, 1), (1, 2), (2, 0)]\n    local_whitney_funcs = [\n        lambda l: l[0] * grads_lambda[1] - l[1] * grads_lambda[0],\n        lambda l: l[1] * grads_lambda[2] - l[2] * grads_lambda[1],\n        lambda l: l[2] * grads_lambda[0] - l[0] * grads_lambda[2],\n    ]\n    \n    field_vec = np.zeros(2)\n    for i, (loc_v1, loc_v2) in enumerate(local_edges_vtx_indices):\n        abs_v1, abs_v2 = tri_vtx_indices[loc_v1], tri_vtx_indices[loc_v2]\n        edge_key = tuple(sorted((abs_v1, abs_v2)))\n        global_idx = edge_map[edge_key]\n        orientation = 1 if abs_v1  abs_v2 else -1\n        coeff = v_coeffs[global_idx]\n        \n        field_vec += orientation * coeff * local_whitney_funcs[i](lambda_coords)\n        \n    return field_vec\n\ndef _calc_max_tangential_jump(V, mesh_data):\n    vertices = mesh_data[\"vertices\"]\n    interior_edges = mesh_data[\"interior_edges\"]\n    adj_tris = mesh_data[\"adj_tris\"]\n\n    max_jump = 0.0\n    for v_k in V.T:  # Iterate through columns (modes)\n        for edge_key in interior_edges:\n            v_start_idx, v_end_idx = edge_key\n            v_start, v_end = vertices[v_start_idx], vertices[v_end_idx]\n            midpoint = (v_start + v_end) / 2.0\n            tangent = (v_end - v_start) / np.linalg.norm(v_end - v_start)\n            \n            tri1_idx, tri2_idx = adj_tris[edge_key]\n            \n            field1 = _evaluate_field(v_k, tri1_idx, midpoint, mesh_data)\n            field2 = _evaluate_field(v_k, tri2_idx, midpoint, mesh_data)\n            \n            jump = np.abs(np.dot(field1 - field2, tangent))\n            if jump > max_jump:\n                max_jump = jump\n\n    return max_jump\n\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}