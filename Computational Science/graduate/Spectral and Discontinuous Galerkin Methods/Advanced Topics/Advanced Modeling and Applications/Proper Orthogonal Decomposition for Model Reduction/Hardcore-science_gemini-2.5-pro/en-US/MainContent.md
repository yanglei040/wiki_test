## Introduction
In modern computational science and engineering, high-fidelity simulations provide unparalleled insight but often come at an immense computational cost, limiting their use in time-critical applications like control, optimization, and uncertainty quantification. Proper Orthogonal Decomposition (POD) offers a powerful mathematical framework to address this challenge. It provides a systematic way to analyze complex datasets, extract the most dominant patterns, and construct highly efficient, low-dimensional [reduced-order models](@entry_id:754172) (ROMs) that retain the essential dynamics of the original system.

This article bridges the gap between the abstract theory of POD and its practical implementation, particularly within the context of advanced numerical schemes like spectral and Discontinuous Galerkin (DG) methods. It addresses the critical, yet often overlooked, nuances of applying POD correctly, such as selecting a physically consistent inner product and ensuring the stability and computational efficiency of the resulting ROM.

Across three comprehensive chapters, you will gain a deep understanding of POD-based [model reduction](@entry_id:171175). The first chapter, **Principles and Mechanisms**, demystifies the mathematical foundations, guiding you through the derivation of POD modes via the [method of snapshots](@entry_id:168045) and explaining their optimality. The second chapter, **Applications and Interdisciplinary Connections**, showcases the versatility of POD across various scientific fields and tackles crucial practical challenges such as handling nonlinearities, ensuring stability, and estimating error. Finally, **Hands-On Practices** will provide you with computational exercises to solidify your understanding of key techniques for building and applying POD-based ROMs.

## Principles and Mechanisms

Proper Orthogonal Decomposition (POD) provides a systematic and powerful methodology for extracting dominant, energy-ordered [coherent structures](@entry_id:182915) from a large dataset. In the context of [model order reduction](@entry_id:167302) for systems governed by [partial differential equations](@entry_id:143134) (PDEs), POD is used to construct a low-dimensional basis that optimally captures the dynamics observed in a series of high-fidelity solutions, or **snapshots**. This chapter delves into the fundamental principles and mechanisms of POD, with a particular focus on its application to solutions generated by spectral and discontinuous Galerkin (DG) methods. We will explore the formulation of the POD problem, its theoretical underpinnings, practical considerations for constructing physically meaningful models, and the stability properties of the resulting [reduced-order models](@entry_id:754172) (ROMs).

### The POD Framework in a Galerkin Setting

At its core, POD seeks to find an [optimal basis](@entry_id:752971) for representing a given set of data. The definition of "optimality" is central and is intrinsically tied to the choice of an inner product, which defines the geometry of the data space and the notion of energy.

#### The Role of the Inner Product

Consider a set of $m$ solution snapshots, $\{ \mathbf{u}^{(k)} \}_{k=1}^m$, where each $\mathbf{u}^{(k)} \in \mathbb{R}^{N}$ is a vector of degrees of freedom representing the state of a system at a particular time or for a specific parameter value. These vectors are assembled into a **snapshot matrix** $X = [\mathbf{u}^{(1)}, \mathbf{u}^{(2)}, \dots, \mathbf{u}^{(m)}] \in \mathbb{R}^{N \times m}$. The fundamental goal of POD is to find an $r$-dimensional orthonormal basis $\{ \boldsymbol{\phi}_i \}_{i=1}^r$ (with $r \ll N$) that minimizes the average squared projection error of the snapshots:
$$
\min_{\{\boldsymbol{\phi}_i\}_{i=1}^r} \sum_{k=1}^m \left\| \mathbf{u}^{(k)} - \sum_{i=1}^r \langle \mathbf{u}^{(k)}, \boldsymbol{\phi}_i \rangle_W \boldsymbol{\phi}_i \right\|_W^2
$$
where the inner product $\langle \cdot, \cdot \rangle_W$ and its [induced norm](@entry_id:148919) $\| \cdot \|_W$ are defined by a [symmetric positive definite](@entry_id:139466) (SPD) weight matrix $W$, such that $\langle \mathbf{a}, \mathbf{b} \rangle_W = \mathbf{a}^\top W \mathbf{b}$.

The choice of $W$ is not arbitrary; it must be physically meaningful. An unweighted Euclidean inner product ($W=I$) treats each degree of freedom equally, which is often inappropriate for discretized PDEs where degrees of freedom may correspond to basis coefficients on non-uniform meshes or represent different physical quantities.

#### The Mass Matrix as the Natural Metric

For spatial discretizations such as the finite element, spectral, or discontinuous Galerkin methods, the solution at any time is represented as a function in a finite-dimensional approximation space, typically through an expansion in a set of basis functions $\{ \psi_j(\mathbf{x}) \}_{j=1}^N$. A solution state is thus represented by its vector of coefficients, $\mathbf{u}^{(k)}$, such that $u_h(\mathbf{x}, t_k) = \sum_{j=1}^N u_j^{(k)} \psi_j(\mathbf{x})$.

The natural inner product for such functions is the $L^2(\Omega)$ inner product, $\langle f, g \rangle_{L^2} = \int_\Omega f(\mathbf{x})g(\mathbf{x}) \, d\mathbf{x}$. When applied to two functions $u_h = \sum_i a_i \psi_i$ and $v_h = \sum_j b_j \psi_j$ from the approximation space, this inner product becomes a [weighted inner product](@entry_id:163877) on their coefficient vectors:
$$
\langle u_h, v_h \rangle_{L^2} = \int_\Omega \left( \sum_i a_i \psi_i \right) \left( \sum_j b_j \psi_j \right) \, d\mathbf{x} = \sum_{i,j} a_i b_j \int_\Omega \psi_i \psi_j \, d\mathbf{x} = \mathbf{a}^\top M \mathbf{b}
$$
The matrix $M$ with entries $M_{ij} = \int_\Omega \psi_i(\mathbf{x}) \psi_j(\mathbf{x}) \, d\mathbf{x}$ is the **mass matrix**. It is symmetric and, for a valid basis, [positive definite](@entry_id:149459). Therefore, the mass matrix provides the natural and physically consistent weighting matrix for POD when working with coefficients from a Galerkin [discretization](@entry_id:145012). The resulting inner product is often called the **[energy inner product](@entry_id:167297)**, and the POD modes are found to be optimal with respect to the discrete $L^2$ norm.

In DG methods, where basis functions have local support on individual elements, the global [mass matrix](@entry_id:177093) is block-diagonal, with each block corresponding to an element's local mass matrix. This structure reflects the disjoint support of basis functions from different elements .

### The Optimization Problem and the Method of Snapshots

The POD optimization problem, which seeks to maximize the projected energy, can be efficiently solved using the **[method of snapshots](@entry_id:168045)**, introduced by Sirovich. This technique is particularly effective when the number of degrees of freedom $N$ is much larger than the number of snapshots $m$.

#### Formulating POD as an Energy Maximization Problem

The problem of minimizing the projection error is equivalent to maximizing the average projected energy. For the first POD mode $\boldsymbol{\phi}_1$, the optimization problem is:
$$
\max_{\boldsymbol{\phi}} \sum_{k=1}^m |\langle \mathbf{u}^{(k)}, \boldsymbol{\phi} \rangle_M|^2 \quad \text{subject to} \quad \|\boldsymbol{\phi}\|_M^2 = 1
$$
This can be written in matrix form as:
$$
\max_{\boldsymbol{\phi}} \sum_{k=1}^m (\boldsymbol{\phi}^\top M \mathbf{u}^{(k)})(\mathbf{u}^{(k)\top} M \boldsymbol{\phi}) = \max_{\boldsymbol{\phi}} \boldsymbol{\phi}^\top M \left( \sum_{k=1}^m \mathbf{u}^{(k)}\mathbf{u}^{(k)\top} \right) M \boldsymbol{\phi}
$$
Recognizing that the sum is the snapshot matrix product $X X^\top$, the problem is to maximize $\boldsymbol{\phi}^\top M X X^\top M \boldsymbol{\phi}$ subject to the constraint $\boldsymbol{\phi}^\top M \boldsymbol{\phi} = 1$. The solution to this [constrained optimization](@entry_id:145264) problem is given by the leading eigenvector of the $N \times N$ [matrix pencil](@entry_id:751760) $(MXX^\top M, M)$, or equivalently, the [standard eigenvalue problem](@entry_id:755346) for the **correlation matrix** $C = M^{1/2} X X^\top M^{1/2}$.

#### The Snapshot Gram Matrix and the Eigenvalue Problem

Solving an [eigenvalue problem](@entry_id:143898) for an $N \times N$ matrix can be computationally prohibitive. The [method of snapshots](@entry_id:168045) reformulates the problem by observing that any optimal POD mode must lie in the span of the snapshots themselves, i.e., $\boldsymbol{\phi} = \sum_j a_j \mathbf{u}^{(j)} = X \mathbf{a}$ for some coefficient vector $\mathbf{a} \in \mathbb{R}^m$. Substituting this ansatz into the optimization problem transforms it into a problem for the small coefficient vector $\mathbf{a}$ .

The objective function becomes a maximization over $\mathbf{a}$:
$$
\max_{\mathbf{a}} (X\mathbf{a})^\top M X X^\top M (X\mathbf{a}) = \max_{\mathbf{a}} \mathbf{a}^\top (X^\top M X) (X^\top M X) \mathbf{a}
$$
The constraint becomes:
$$
(X\mathbf{a})^\top M (X\mathbf{a}) = \mathbf{a}^\top (X^\top M X) \mathbf{a} = 1
$$
Defining the $m \times m$ **snapshot Gram matrix** (or correlation matrix) $K = X^\top M X$, the problem simplifies to:
$$
\max_{\mathbf{a}} \mathbf{a}^\top K^2 \mathbf{a} \quad \text{subject to} \quad \mathbf{a}^\top K \mathbf{a} = 1
$$
Using the method of Lagrange multipliers, this leads to the [standard eigenvalue problem](@entry_id:755346) for the small $m \times m$ Gram matrix:
$$
K \mathbf{v}_i = \sigma_i \mathbf{v}_i
$$
The eigenvalues $\sigma_i$ are directly related to the squared singular values of the weighted snapshot matrix $M^{1/2}X$ and represent the "energy" captured by each mode. The eigenvectors $\mathbf{v}_i$ provide the coefficients for constructing the $M$-orthonormal POD modes $\boldsymbol{\phi}_i$ from the snapshots:
$$
\boldsymbol{\phi}_i = \frac{1}{\sqrt{\sigma_i}} X \mathbf{v}_i
$$
The fraction of the total snapshot energy captured by the first $r$ modes is given by the ratio of the sum of the corresponding eigenvalues to the total sum: $\left(\sum_{i=1}^r \sigma_i\right) / \left(\sum_{j=1}^m \sigma_j\right)$.

#### A Concrete Example: Non-Orthogonal Bases

The necessity of the mass matrix $M$ is most apparent when the underlying basis functions are not orthogonal, which is common in DG or [spectral methods](@entry_id:141737), especially on curved or non-affinely mapped elements. Using an inexact or identity [mass matrix](@entry_id:177093) would mean optimizing with respect to a physically incorrect energy measure, leading to a suboptimal basis. For instance, consider a DG implementation on a curved element where exact quadrature is used to assemble the [mass matrix](@entry_id:177093). This ensures that the matrix $M$ precisely represents the $L^2$ inner product on the discrete function space. Any POD modes constructed using this $M$ will then be truly optimal in capturing the physical $L^2$ energy of the solution .

### Theoretical Guarantees: POD and the Kolmogorov n-Width

While POD is derived from a discrete set of snapshots, its efficacy stems from its profound connection to the theoretical concept of optimal approximation, quantified by the **Kolmogorov n-width**.

#### Measuring Optimal Approximability

The Kolmogorov n-width, denoted $d_n(\mathcal{M})$, measures how well a given set $\mathcal{M}$ in a [normed space](@entry_id:157907) can be approximated by a linear subspace of dimension $n$. For the Hilbert space induced by the inner product $\langle \cdot, \cdot \rangle_M$, it is defined as the best possible [worst-case error](@entry_id:169595):
$$
d_n(\mathcal{M})_M = \inf_{\dim(V)=n} \sup_{\mathbf{u} \in \mathcal{M}} \inf_{\mathbf{v} \in V} \| \mathbf{u} - \mathbf{v} \|_M
$$
where the outer [infimum](@entry_id:140118) is taken over all $n$-dimensional subspaces $V$. The n-width represents the error of the best possible approximation of the set $\mathcal{M}$ by a subspace of dimension $n$. A rapidly decaying $d_n(\mathcal{M})_M$ with increasing $n$ indicates that the set $\mathcal{M}$ is highly compressible and can be accurately represented by a low-dimensional model.

#### The n-Width and Singular Value Decay

A cornerstone result in [approximation theory](@entry_id:138536) states that for a compact set $\mathcal{M}$ that is the image of the [unit ball](@entry_id:142558) of a Hilbert space under a [compact linear operator](@entry_id:267666) $A$ (i.e., $\mathcal{M} = A(B_H)$), the Kolmogorov n-width is given exactly by the singular values of that operator:
$$
d_n(\mathcal{M})_M = \sigma_{n+1}(A)
$$
where $\sigma_{n+1}(A)$ is the $(n+1)$-th singular value of $A$, and the optimal $n$-dimensional subspace is spanned by the first $n$ [singular vectors](@entry_id:143538) .

In the context of POD, we work with a finite set of snapshots. Let this set be the columns of the matrix $X$. Consider the [compact set](@entry_id:136957) $K = \{ X\mathbf{c} : \|\mathbf{c}\|_2 \le 1 \}$. The POD basis of dimension $n$ is the optimal subspace for approximating this set. The n-width of $K$ in the $M$-norm is given by the $(n+1)$-th [singular value](@entry_id:171660) of the weighted snapshot operator $M^{1/2}X$ . This singular value, often denoted $\lambda_{n+1}^{1/2}$ in contexts where the eigenvalues of the Gram matrix are used, represents the worst-case projection error onto the $n$-dimensional POD basis. For example, if the weighted snapshot [correlation matrix](@entry_id:262631) $C = X^\top M X$ has eigenvalues $\{12, 3, 3/4\}$, the 2-width of the corresponding set $K$ would be $d_2(K) = \sqrt{3/4} = \sqrt{3}/2$ .

This result provides the theoretical justification for POD: by selecting modes corresponding to the largest singular values (or eigenvalues of the Gram matrix), we are constructing a basis that is provably optimal for the given snapshot data and closely related to the [optimal basis](@entry_id:752971) for the underlying continuous solution manifold.

### Constructing Physically Meaningful Inner Products

For complex systems involving multiple physical fields or disparate [energy scales](@entry_id:196201), the choice of the inner product $\langle \mathbf{u}, \mathbf{v} \rangle_W = \mathbf{u}^\top W \mathbf{v}$ (where we now use $W$ to denote the full weighting matrix) is critical for obtaining a balanced and meaningful ROM.

#### The Challenge of Multi-Physics Systems

When the [state vector](@entry_id:154607) $\mathbf{u}$ concatenates variables with different physical units (e.g., density $\rho$, momentum $\rho\mathbf{u}$, and total energy density $E$ in [compressible flow](@entry_id:156141)), a simple $L^2$ inner product (i.e., using only the mass matrix $M$) is dimensionally inconsistent. It is equivalent to adding kilograms to joules, a physically nonsensical operation. The resulting POD modes would be arbitrarily biased towards variables whose numerical values are largest, not necessarily those that are most important dynamically.

A second challenge arises when different fields have vastly different energy levels. For instance, in a fluid flow problem, the kinetic energy associated with the velocity field might be orders of magnitude larger than a scalar "energy" associated with a pressure or temperature field. A standard [energy inner product](@entry_id:167297) would cause the POD to focus almost exclusively on the high-energy velocity field, potentially neglecting the crucial dynamics of the lower-energy pressure field .

Several strategies can be employed to construct a physically meaningful inner product that addresses these challenges.

#### Strategy 1: Nondimensionalization via Characteristic Scales

The fundamental way to resolve dimensional inconsistency is to nondimensionalize all variables using appropriate [characteristic scales](@entry_id:144643). For a [compressible flow](@entry_id:156141) system, one might choose a reference density $\rho_0$ and velocity $U_0$. The state variables are then scaled as $\tilde{\rho} = \rho/\rho_0$, $\tilde{m} = (\rho u)/(\rho_0 U_0)$, and $\tilde{E} = E/(\rho_0 U_0^2)$. The inner product is then defined on these dimensionless quantities.

In the discrete setting, this is achieved by defining a block-diagonal [scaling matrix](@entry_id:188350) $S$ (denoted $W$ in ), e.g., $S = \text{diag}(1/\rho_0, 1/(\rho_0 U_0), \dots)$. The dimensionless coefficient vector is $\tilde{\mathbf{u}} = S\mathbf{u}$. The physically consistent inner product then takes the form of the standard $L^2$ inner product on the nondimensionalized vectors:
$$
\langle \mathbf{u}, \mathbf{v} \rangle = \langle \tilde{\mathbf{u}}, \tilde{\mathbf{v}} \rangle_M = (S\mathbf{u})^\top M (S\mathbf{v}) = \mathbf{u}^\top S^\top M S \mathbf{v}
$$
This form defines an SPD metric that correctly represents the $L^2$ inner product of the nondimensionalized fields and ensures that the POD optimization is physically consistent .

#### Strategy 2: Data-Driven Balancing of Energy Contributions

Even after [nondimensionalization](@entry_id:136704), different fields may contribute unequally to the total energy. To ensure that each field's dynamics are adequately represented in the POD basis, a data-driven scaling can be applied. The goal is to choose scaling factors such that each field contributes approximately equally to the total [energy budget](@entry_id:201027) that POD optimizes.

A common approach is to scale each field variable such that its time-averaged energy is normalized to unity. For two fields $u$ and $p$ with mass matrices $M_u$ and $M_p$, we define scaling factors $s_u$ and $s_p$:
$$
s_u = \left( \frac{1}{K} \sum_{k=1}^K \|\mathbf{u}^{(k)}\|_{M_u}^2 \right)^{-1/2}, \quad s_p = \left( \frac{1}{K} \sum_{k=1}^K \|\mathbf{p}^{(k)}\|_{M_p}^2 \right)^{-1/2}
$$
where $K$ is the number of snapshots. The POD is then performed using an inner product that incorporates these scaling factors. This ensures that the resulting POD basis is not dominated by a single high-energy field and provides a more balanced representation of the overall system dynamics .

#### Strategy 3: Choosing Alternative Energy Norms

The $L^2$ norm is not the only valid choice for defining energy. For certain physical systems, other norms may be more relevant. For [compressible flows](@entry_id:747589), one might be more interested in capturing kinetic [energy fluctuations](@entry_id:148029) rather than total $L^2$ energy of the conservative variables.

This can be achieved by designing a custom weighting matrix for the inner product. A naive choice like $\mathbf{W} = \text{diag}(0, \rho_{ref}, \rho_{ref}, \dots, 0)$ to isolate velocity components is flawed because it results in a positive *semi-definite* matrix, which defines a [seminorm](@entry_id:264573), not a norm, and can cause issues in POD algorithms. A mathematically sound approach is to regularize this matrix by adding small positive values on the diagonal for the non-velocity components. This defines an SPD matrix that emphasizes kinetic energy while still constituting a valid norm. The transformation from primitive to conservative variables via the system Jacobian can be used to construct the corresponding SPD weighting matrix in the space of conservative variables .

A more advanced method involves using the Hessian of a convex entropy function, known as a **symmetrizer**, as the weighting matrix. This defines an inner product that corresponds to the thermodynamic energy of the system and is crucial for developing entropy-[stable numerical schemes](@entry_id:755322) and ROMs .

### ROM Construction, Truncation, and Stability

Once a set of $r$ POD basis vectors $\{ \boldsymbol{\phi}_i \}_{i=1}^r$ is computed, they are assembled into a matrix $V = [\boldsymbol{\phi}_1, \dots, \boldsymbol{\phi}_r]$. This basis is then used to construct a ROM.

#### Galerkin Projection

The standard method for deriving the ROM is **Galerkin projection**. The high-dimensional state $\mathbf{u}(t) \in \mathbb{R}^N$ is approximated by a linear combination of the POD modes: $\mathbf{u}(t) \approx V \mathbf{a}(t)$, where $\mathbf{a}(t) \in \mathbb{R}^r$ is the vector of reduced coordinates. Substituting this approximation into the [full-order model](@entry_id:171001), say $M\dot{\mathbf{u}} = A\mathbf{u}$, and projecting the resulting residual onto the [test space](@entry_id:755876) spanned by the POD basis itself (i.e., left-multiplying by $V^\top$) yields the ROM:
$$
V^\top M V \dot{\mathbf{a}}(t) = V^\top A V \mathbf{a}(t)
$$
If the POD basis $V$ is constructed to be $M$-orthonormal ($V^\top M V = I_r$), the reduced system simplifies to $\dot{\mathbf{a}}(t) = \widehat{A} \mathbf{a}(t)$, where $\widehat{A} = V^\top A V$ is the reduced operator.

#### Truncation Criteria for the POD Basis

A critical decision is the choice of the reduced dimension $r$. This is typically guided by the decay of the singular values (or eigenvalues $\sigma_i$ of the Gram matrix), which represent the energy content of the modes. Common truncation strategies include :

1.  **Fixed Error Tolerance**: Choose the smallest $r$ such that the energy of the truncated modes falls below a prescribed absolute tolerance $\epsilon^2$: $\sum_{i=r+1}^m \sigma_i \le \epsilon^2$. This provides an a posteriori bound on the mean squared projection error of the snapshots.
2.  **Relative Energy Capture**: Choose the smallest $r$ such that the captured energy exceeds a certain fraction $\eta$ (e.g., $0.9999$) of the total energy: $\left(\sum_{i=1}^r \sigma_i\right) / \left(\sum_{j=1}^m \sigma_j\right) \ge \eta$. For a given snapshot set, these two criteria are equivalent, with $\eta = 1 - \epsilon^2 / (\sum_j \sigma_j)$ [@problem_id:3410838, option C].
3.  **Gap Heuristic**: Choose $r$ just before a large drop or "gap" in the [singular value](@entry_id:171660) spectrum, identified, for example, by a large ratio $\sqrt{\sigma_r}/\sqrt{\sigma_{r+1}}$. This suggests a natural separation between dominant and sub-dominant modes.

#### Preservation of System Structure and Stability

A key advantage of Galerkin projection is its tendency to preserve the mathematical structure of the original problem. This has profound implications for the stability of the ROM.

If the [full-order model](@entry_id:171001) is dissipative (i.e., its energy is non-increasing), a standard Galerkin projection onto an $M$-[orthonormal basis](@entry_id:147779) will produce a ROM that is also dissipative. This is because any state of the ROM, when mapped back to the full-dimensional space, is a valid state for which the [dissipativity](@entry_id:162959) property holds. This stability preservation is a structural property of the projection and is independent of the dimension $r$ or the specific truncation criterion used to choose it .

Similarly, if the [full-order model](@entry_id:171001) is conservative (e.g., governed by a skew-[symmetric operator](@entry_id:275833) arising from a split-form DG [discretization](@entry_id:145012)), a Galerkin projection will produce a ROM that is also perfectly energy-neutral. The algebraic cancellations that ensure [energy conservation](@entry_id:146975) in the full model are inherited by the reduced model through the projection . This structural preservation is a major strength of POD-Galerkin methods, but it can be broken by further approximations, such as collocation-based [hyper-reduction](@entry_id:163369), which may introduce aliasing errors that lead to spurious energy growth or decay .

### Advanced Considerations: Snapshot Selection for Stiff Systems

The choice of what data to collect in the snapshot matrix can significantly impact the ROM's accuracy, particularly for problems with stiff dynamics, such as fast-decaying transients.

#### The Limits of State-Based Snapshots

When a system contains stiff modes (corresponding to eigenvalues $\lambda_i$ with large magnitude and negative real part), these modes decay very quickly. If POD is performed on snapshots of the state $\mathbf{u}(t)$, these fast modes may contribute very little to the total time-averaged energy of the system. Consequently, a POD basis optimized to capture state energy may truncate these modes, leading to a ROM that is inaccurate for representing the initial fast transient behavior .

#### Emphasizing Dynamics with Derivative and Residual Snapshots

To build a ROM that better captures stiff dynamics, one can perform POD on snapshots of the **time derivative** $\dot{\mathbf{u}}(t)$ or the **spatial residual** $\mathbf{r}(t) = A\mathbf{u}(t) = M\dot{\mathbf{u}}(t)$. The time derivative of a mode $e^{\lambda_i t}\mathbf{v}_i$ is $\lambda_i e^{\lambda_i t}\mathbf{v}_i$. The energy contribution of this mode to the time-derivative snapshot set is therefore scaled by a factor of $|\lambda_i|^2$ relative to its contribution to the state snapshot set. This amplification forces the POD optimization to prioritize retaining the fast modes (large $|\lambda_i|$), resulting in a ROM with significantly improved accuracy for stiff dynamics [@problem_id:3410874, option D].

Performing POD on residual snapshots $\mathbf{r}(t)$ can achieve the same goal if the correct inner product is used. The appropriate inner product for residuals is the [dual norm](@entry_id:263611) induced by $M^{-1}$, i.e., $\langle \mathbf{r}_1, \mathbf{r}_2 \rangle = \mathbf{r}_1^\top M^{-1} \mathbf{r}_2$. This is because:
$$
\mathbf{r}^\top M^{-1} \mathbf{r} = (M\dot{\mathbf{u}})^\top M^{-1} (M\dot{\mathbf{u}}) = \dot{\mathbf{u}}^\top M^\top M^{-1} M \dot{\mathbf{u}} = \dot{\mathbf{u}}^\top M \dot{\mathbf{u}} = \|\dot{\mathbf{u}}\|_M^2
$$
Thus, performing POD on residuals with the $M^{-1}$ inner product is mathematically equivalent to performing POD on time derivatives with the $M$ inner product. Using such physically-motivated weighted norms is crucial for avoiding the mesh-dependent artifacts that can arise from using a simple Euclidean norm on coefficient vectors, ensuring robust capture of operator-driven stiffness and sharp physical features in high-order DG discretizations [@problem_id:3410874, option E].