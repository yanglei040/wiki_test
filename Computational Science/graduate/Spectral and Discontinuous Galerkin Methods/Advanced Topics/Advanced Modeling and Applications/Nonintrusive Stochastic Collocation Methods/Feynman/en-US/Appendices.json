{
    "hands_on_practices": [
        {
            "introduction": "Nonintrusive stochastic collocation relies on numerical quadrature to approximate statistical moments of a quantity of interest. The choice of quadrature points and weights is not arbitrary; it is deeply connected to the probability distribution of the random inputs. This exercise  takes you through the fundamental process of deriving a Gauss-Hermite quadrature rule, the standard choice for problems involving Gaussian random variables, from the underlying theory of orthogonal polynomials.",
            "id": "3403692",
            "problem": "Consider nonintrusive stochastic collocation for uncertainty quantification in spectral and Discontinuous Galerkin (DG) discretizations, where expectations with respect to a Gaussian measure are approximated by Gaussian quadrature rules. Let the weight be the unnormalized Gaussian weight $w(x)=\\exp(-x^{2})$ on $(-\\infty,\\infty)$, and consider a level $n=3$ Gauss–Hermite rule. Starting from the foundational facts of orthogonal polynomials and weighted inner products, namely that the Hermite polynomials (physicists’ convention) $\\{H_{k}(x)\\}_{k\\geq 0}$ are orthogonal on $(-\\infty,\\infty)$ with respect to $w(x)$ and that exactness up to degree $2n-1$ is enforced by choosing $n$ abscissae at the zeros of the degree-$n$ orthogonal polynomial and solving for the $n$ weights by moment matching, derive the $n=3$ Gauss–Hermite quadrature abscissae and weights by requiring exactness for all polynomials of degree up to $2n-1=5$.\n\nSpecifically:\n- Use the definition of Hermite polynomials with respect to $w(x)=\\exp(-x^{2})$ and their recurrence to identify the degree-$3$ orthogonal polynomial and its zeros, which are the abscissae.\n- Use the moment constraints $\\int_{-\\infty}^{\\infty} x^{k} \\exp(-x^{2})\\,dx$ for $k=0,1,2,3,4,5$ to determine and verify the weights associated with those abscissae, ensuring exactness up to total polynomial degree $5$.\n- Report the abscissae in ascending order followed by the corresponding weights as a single row matrix, with no rounding.\n\nYour final answer must be a single analytic expression. No units are needed.",
            "solution": "The user wants to derive the abscissae and weights for a level $n=3$ Gauss-Hermite quadrature rule.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- **Topic:** Nonintrusive stochastic collocation for spectral and Discontinuous Galerkin (DG) methods.\n- **Approximation method:** Gaussian quadrature rules to approximate expectations with respect to a Gaussian measure.\n- **Weight function:** Unnormalized Gaussian weight $w(x) = \\exp(-x^2)$.\n- **Domain:** $(-\\infty, \\infty)$.\n- **Quadrature rule level:** $n=3$ Gauss-Hermite rule.\n- **Orthogonal polynomials:** Hermite polynomials (physicists’ convention), $\\{H_k(x)\\}_{k\\ge 0}$, are orthogonal on $(-\\infty, \\infty)$ with respect to $w(x)$.\n- **Quadrature rule construction principle:** For a level-$n$ rule, the $n$ abscissae are the zeros of the degree-$n$ orthogonal polynomial. The $n$ weights are found by enforcing exactness for a set of basis functions.\n- **Required exactness:** The quadrature rule must be exact for all polynomials of degree up to $2n-1 = 2(3)-1 = 5$.\n- **Specific tasks:**\n    1. Identify the degree-3 Hermite polynomial, $H_3(x)$, and find its zeros (the abscissae).\n    2. Use moment constraints $\\int_{-\\infty}^{\\infty} x^k \\exp(-x^2) dx$ for $k=0,1,2,3,4,5$ to determine the weights.\n    3. Report the abscissae (in ascending order) and their corresponding weights.\n- **Final answer format:** A single row matrix with abscissae first, then weights. No rounding.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It is a standard problem in numerical analysis and is directly relevant to the stated field of uncertainty quantification. All necessary information is provided, the premises are factually correct, and the required derivation is a non-trivial but feasible mathematical exercise. There are no contradictions, ambiguities, or unsound elements.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A detailed solution will be provided.\n\n### Derivation of Abscissae and Weights\n\nThe problem requires constructing a Gauss-Hermite quadrature rule of the form\n$$\n\\int_{-\\infty}^{\\infty} f(x) \\exp(-x^2) \\,dx \\approx \\sum_{i=1}^{3} w_i f(x_i)\n$$\nwhere $\\{x_i\\}_{i=1}^3$ are the abscissae and $\\{w_i\\}_{i=1}^3$ are the weights. The rule must be exact for all polynomials $f(x)$ up to degree $2n-1 = 2(3)-1 = 5$.\n\n**1. Determine the Abscissae**\n\nAccording to the theory of Gaussian quadrature, for the weight function $w(x) = \\exp(-x^2)$, the abscissae are the roots of the degree-$n$ orthogonal polynomial. In this case, $n=3$, and the relevant orthogonal polynomials are the Hermite polynomials (physicists' convention), denoted $H_k(x)$.\n\nThe first few Hermite polynomials are generated by the recurrence relation $H_{k+1}(x) = 2x H_k(x) - 2k H_{k-1}(x)$, with starting polynomials $H_0(x) = 1$ and $H_1(x) = 2x$.\n- $k=0$: $H_0(x) = 1$\n- $k=1$: $H_1(x) = 2x$\n- $k=2$: $H_2(x) = 2x H_1(x) - 2(1) H_0(x) = 2x(2x) - 2(1) = 4x^2 - 2$\n- $k=3$: $H_3(x) = 2x H_2(x) - 2(2) H_1(x) = 2x(4x^2 - 2) - 4(2x) = 8x^3 - 4x - 8x = 8x^3 - 12x$\n\nThe abscissae $\\{x_i\\}$ are the roots of $H_3(x) = 0$:\n$$\n8x^3 - 12x = 0\n$$\nFactoring out $4x$:\n$$\n4x(2x^2 - 3) = 0\n$$\nThe roots are $x=0$ and $2x^2-3=0$, which gives $x^2 = \\frac{3}{2}$, so $x = \\pm \\sqrt{\\frac{3}{2}}$.\nArranging the abscissae in ascending order:\n$$\nx_1 = -\\sqrt{\\frac{3}{2}}, \\quad x_2 = 0, \\quad x_3 = \\sqrt{\\frac{3}{2}}\n$$\n\n**2. Determine the Weights**\n\nThe weights $\\{w_i\\}$ are determined by requiring the quadrature rule to be exact for polynomials up to degree $2n-1=5$. We enforce this by matching the moments, i.e., ensuring the formula is exact for $f(x) = x^k$ for $k=0, 1, 2, \\dots, 5$.\nThe governing system of equations is:\n$$\n\\sum_{i=1}^{3} w_i x_i^k = \\int_{-\\infty}^{\\infty} x^k \\exp(-x^2) \\,dx = M_k\n$$\nFirst, we compute the moments $M_k$. The integrand $x^k \\exp(-x^2)$ is an odd function for odd $k$, so its integral over the symmetric domain $(-\\infty, \\infty)$ is zero.\n$$\nM_k = 0 \\quad \\text{for } k=1, 3, 5\n$$\nFor even $k=2m$, the moment is related to the Gamma function $\\Gamma(z) = \\int_0^{\\infty} t^{z-1} e^{-t} dt$.\n$$\nM_{2m} = \\int_{-\\infty}^{\\infty} x^{2m} \\exp(-x^2) \\,dx = 2 \\int_0^{\\infty} x^{2m} \\exp(-x^2) \\,dx\n$$\nUsing the substitution $u=x^2$ (so $x=u^{1/2}$ and $dx = \\frac{1}{2}u^{-1/2}du$):\n$$\nM_{2m} = 2 \\int_0^{\\infty} u^m \\exp(-u) \\frac{1}{2} u^{-1/2} \\,du = \\int_0^{\\infty} u^{m-1/2} \\exp(-u) \\,du = \\Gamma\\left(m + \\frac{1}{2}\\right)\n$$\nUsing $\\Gamma(1/2) = \\sqrt{\\pi}$ and $\\Gamma(z+1) = z\\Gamma(z)$, we find the required even moments:\n- $k=0$ ($m=0$): $M_0 = \\Gamma(1/2) = \\sqrt{\\pi}$\n- $k=2$ ($m=1$): $M_2 = \\Gamma(3/2) = \\frac{1}{2}\\Gamma(1/2) = \\frac{\\sqrt{\\pi}}{2}$\n- $k=4$ ($m=2$): $M_4 = \\Gamma(5/2) = \\frac{3}{2}\\Gamma(3/2) = \\frac{3}{2} \\frac{\\sqrt{\\pi}}{2} = \\frac{3\\sqrt{\\pi}}{4}$\n\nNow we set up the equations for the weights $w_1$, $w_2$, and $w_3$:\n- For $k=0$: $w_1 + w_2 + w_3 = M_0 = \\sqrt{\\pi}$\n- For $k=1$: $w_1 x_1 + w_2 x_2 + w_3 x_3 = M_1 = 0$\n  $w_1 \\left(-\\sqrt{\\frac{3}{2}}\\right) + w_2(0) + w_3 \\left(\\sqrt{\\frac{3}{2}}\\right) = 0 \\implies w_1=w_3$\n- For $k=2$: $w_1 x_1^2 + w_2 x_2^2 + w_3 x_3^2 = M_2 = \\frac{\\sqrt{\\pi}}{2}$\n  $w_1 \\left(\\frac{3}{2}\\right) + w_2(0) + w_3 \\left(\\frac{3}{2}\\right) = \\frac{\\sqrt{\\pi}}{2}$\n\nSince $w_1=w_3$, the equation for $k=2$ becomes:\n$$\n2 w_1 \\left(\\frac{3}{2}\\right) = \\frac{\\sqrt{\\pi}}{2} \\implies 3w_1 = \\frac{\\sqrt{\\pi}}{2} \\implies w_1 = \\frac{\\sqrt{\\pi}}{6}\n$$\nThus, $w_3 = w_1 = \\frac{\\sqrt{\\pi}}{6}$.\n\nSubstituting $w_1$ and $w_3$ into the equation for $k=0$:\n$$\n\\frac{\\sqrt{\\pi}}{6} + w_2 + \\frac{\\sqrt{\\pi}}{6} = \\sqrt{\\pi}\n$$\n$$\n\\frac{\\sqrt{\\pi}}{3} + w_2 = \\sqrt{\\pi} \\implies w_2 = \\sqrt{\\pi} - \\frac{\\sqrt{\\pi}}{3} = \\frac{2\\sqrt{\\pi}}{3}\n$$\nSo the weights are:\n$$\nw_1 = \\frac{\\sqrt{\\pi}}{6}, \\quad w_2 = \\frac{2\\sqrt{\\pi}}{3}, \\quad w_3 = \\frac{\\sqrt{\\pi}}{6}\n$$\n\n**3. Verification**\n\nThe problem requires verification up to degree $5$. We used moments for $k=0,1,2$. We must check if our rule is exact for $k=3, 4, 5$.\n- For $k=3$: The quadrature sum is $\\sum_{i=1}^3 w_i x_i^3 = w_1 x_1^3 + w_2 x_2^3 + w_3 x_3^3$.\n$$\n\\frac{\\sqrt{\\pi}}{6}\\left(-\\sqrt{\\frac{3}{2}}\\right)^3 + \\frac{2\\sqrt{\\pi}}{3}(0)^3 + \\frac{\\sqrt{\\pi}}{6}\\left(\\sqrt{\\frac{3}{2}}\\right)^3 = \\frac{\\sqrt{\\pi}}{6} \\left[ -\\left(\\frac{3}{2}\\right)^{3/2} + \\left(\\frac{3}{2}\\right)^{3/2} \\right] = 0\n$$\nThis matches $M_3=0$. The rule is exact for $x^3$.\n\n- For $k=4$: The quadrature sum is $\\sum_{i=1}^3 w_i x_i^4 = w_1 x_1^4 + w_2 x_2^4 + w_3 x_3^4$.\n$$\n\\frac{\\sqrt{\\pi}}{6}\\left(-\\sqrt{\\frac{3}{2}}\\right)^4 + \\frac{2\\sqrt{\\pi}}{3}(0)^4 + \\frac{\\sqrt{\\pi}}{6}\\left(\\sqrt{\\frac{3}{2}}\\right)^4 = 2 \\left( \\frac{\\sqrt{\\pi}}{6} \\right) \\left( \\frac{3}{2} \\right)^2 = \\frac{\\sqrt{\\pi}}{3} \\frac{9}{4} = \\frac{3\\sqrt{\\pi}}{4}\n$$\nThis matches $M_4 = \\frac{3\\sqrt{\\pi}}{4}$. The rule is exact for $x^4$.\n\n- For $k=5$: The quadrature sum is $\\sum_{i=1}^3 w_i x_i^5 = w_1 x_1^5 + w_2 x_2^5 + w_3 x_3^5$.\n$$\n\\frac{\\sqrt{\\pi}}{6}\\left(-\\sqrt{\\frac{3}{2}}\\right)^5 + \\frac{2\\sqrt{\\pi}}{3}(0)^5 + \\frac{\\sqrt{\\pi}}{6}\\left(\\sqrt{\\frac{3}{2}}\\right)^5 = \\frac{\\sqrt{\\pi}}{6} \\left[ -\\left(\\frac{3}{2}\\right)^{5/2} + \\left(\\frac{3}{2}\\right)^{5/2} \\right] = 0\n$$\nThis matches $M_5=0$. The rule is exact for $x^5$.\n\nThe derivation is complete and verified. The abscissae in ascending order are $-\\sqrt{3/2}$, $0$, $\\sqrt{3/2}$, and the corresponding weights are $\\sqrt{\\pi}/6$, $2\\sqrt{\\pi}/3$, $\\sqrt{\\pi}/6$.\n\n**Final Result**\nThe abscissae and corresponding weights are collected into a single row matrix as required.\nAbscissae: $x_1 = -\\sqrt{\\frac{3}{2}}$, $x_2 = 0$, $x_3 = \\sqrt{\\frac{3}{2}}$.\nWeights: $w_1 = \\frac{\\sqrt{\\pi}}{6}$, $w_2 = \\frac{2\\sqrt{\\pi}}{3}$, $w_3 = \\frac{\\sqrt{\\pi}}{6}$.\nThe final matrix is $(x_1, x_2, x_3, w_1, w_2, w_3)$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -\\sqrt{\\frac{3}{2}} & 0 & \\sqrt{\\frac{3}{2}} & \\frac{\\sqrt{\\pi}}{6} & \\frac{2\\sqrt{\\pi}}{3} & \\frac{\\sqrt{\\pi}}{6} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "While tensor-product grids are simple to construct, they suffer from the \"curse of dimensionality,\" becoming computationally intractable as the number of random variables increases. Sparse grids, built using the Smolyak construction, offer a powerful remedy by intelligently selecting a subset of tensor-product points to maintain accuracy at a fraction of the cost. This practice  provides hands-on experience with the combinatorial logic of the Smolyak algorithm, requiring you to identify the contributing multi-indices and calculate the size of a three-dimensional sparse grid.",
            "id": "3403649",
            "problem": "Consider a nonintrusive stochastic collocation method (SCM) for a $3$-dimensional parametric input vector $\\boldsymbol{\\xi} = (\\xi_1,\\xi_2,\\xi_3)$ whose components are independent and uniformly distributed on the interval $[-1,1]$. You will construct a sparse grid node set for interpolation based on the Smolyak operator $\\mathcal{A}(q,d)$ with $q=3$ and $d=3$, using nested one-dimensional Clenshaw–Curtis collocation rules.\n\nUse the following foundational definitions:\n\n- The one-dimensional level-$\\ell$ collocation rule has a nested node set $\\mathcal{X}_\\ell$ with cardinality $N_\\ell$, where $N_1 = 1$, $N_2 = 3$, $N_3 = 5$, and, for $\\ell \\geq 2$, $N_\\ell = 2^{\\ell-1} + 1$. Define the hierarchical increment sets by $\\Delta \\mathcal{X}_1 := \\mathcal{X}_1$, and, for $\\ell \\geq 2$, $\\Delta \\mathcal{X}_\\ell := \\mathcal{X}_\\ell \\setminus \\mathcal{X}_{\\ell-1}$, with incremental cardinalities $M_\\ell := |\\Delta \\mathcal{X}_\\ell|$. By definition, $M_1 = 1$, $M_2 = 2$, and, for $\\ell \\geq 3$, $M_\\ell = N_\\ell - N_{\\ell-1} = 2^{\\ell-2}$.\n\n- The Smolyak interpolation operator with nested rules is formed from tensor-product hierarchical increments. Its multi-index set is\n$$\n\\mathcal{I}(q,d) := \\left\\{ \\boldsymbol{i} = (i_1,i_2,i_3) \\in \\mathbb{N}^3 \\;:\\; \\sum_{k=1}^3 i_k \\leq q + d - 1,\\;\\; i_k \\geq 1 \\right\\}.\n$$\nThe associated sparse grid node set is the disjoint union of tensor-product increment sets,\n$$\n\\mathcal{S}(q,d) := \\bigcup_{\\boldsymbol{i} \\in \\mathcal{I}(q,d)} \\left( \\Delta \\mathcal{X}_{i_1} \\times \\Delta \\mathcal{X}_{i_2} \\times \\Delta \\mathcal{X}_{i_3} \\right),\n$$\nand its total number of distinct nodes is\n$$\n|\\mathcal{S}(q,d)| = \\sum_{\\boldsymbol{i} \\in \\mathcal{I}(q,d)} \\prod_{k=1}^3 M_{i_k}.\n$$\n\nTasks:\n1. List all multi-index combinations $\\boldsymbol{i} \\in \\mathcal{I}(q=3,d=3)$ that contribute to the Smolyak operator.\n2. Using the above definitions, compute the total number of distinct collocation nodes in the sparse grid $\\mathcal{S}(3,3)$.\n\nYour final answer must be the single integer equal to $|\\mathcal{S}(3,3)|$.",
            "solution": "The problem statement has been validated and is deemed sound. It is a well-posed mathematical problem based on standard definitions in the field of numerical analysis, specifically for sparse grid methods. All necessary data and definitions are provided, internally consistent, and free of ambiguity.\n\nThe objective is to compute the total number of distinct collocation nodes, denoted by $|\\mathcal{S}(q,d)|$, in a sparse grid constructed using the Smolyak operator. The parameters are given as the level-to-accuracy parameter $q=3$ and the input dimension $d=3$.\n\nThe total number of nodes is given by the formula:\n$$\n|\\mathcal{S}(q,d)| = \\sum_{\\boldsymbol{i} \\in \\mathcal{I}(q,d)} \\prod_{k=1}^d M_{i_k}\n$$\nFor this problem, $d=3$, so the formula is:\n$$\n|\\mathcal{S}(3,3)| = \\sum_{\\boldsymbol{i} \\in \\mathcal{I}(3,3)} M_{i_1} M_{i_2} M_{i_3}\n$$\n\nThe first step is to identify the set of multi-indices $\\mathcal{I}(q,d)$. The definition provided is:\n$$\n\\mathcal{I}(q,d) := \\left\\{ \\boldsymbol{i} = (i_1, \\dots, i_d) \\in \\mathbb{N}^d \\;:\\; \\sum_{k=1}^d i_k \\leq q + d - 1,\\;\\; i_k \\geq 1 \\right\\}\n$$\nWith $q=3$ and $d=3$, the condition on the sum of indices becomes:\n$$\n\\sum_{k=1}^3 i_k \\leq 3 + 3 - 1 = 5\n$$\nSo, we must find all triples of positive integers $\\boldsymbol{i} = (i_1, i_2, i_3)$ whose sum is less than or equal to $5$. We can enumerate these multi-indices by grouping them according to their sum, $|\\boldsymbol{i}|_1 = i_1+i_2+i_3$.\n\nTask 1: List all multi-index combinations $\\boldsymbol{i} \\in \\mathcal{I}(3,3)$.\n\n-   Case $|\\boldsymbol{i}|_1 = 3$:\n    The only combination of three positive integers that sum to $3$ is $(1,1,1)$.\n    Multi-indices: $(1,1,1)$.\n\n-   Case $|\\boldsymbol{i}|_1 = 4$:\n    We need combinations of three positive integers that sum to $4$. The only partition of $4$ into three parts is $2+1+1$. The permutations of $(2,1,1)$ are:\n    Multi-indices: $(2,1,1)$, $(1,2,1)$, $(1,1,2)$.\n\n-   Case $|\\boldsymbol{i}|_1 = 5$:\n    We need combinations of three positive integers that sum to $5$. The partitions of $5$ into three parts are $3+1+1$ and $2+2+1$.\n    Permutations of $(3,1,1)$: $(3,1,1)$, $(1,3,1)$, $(1,1,3)$.\n    Permutations of $(2,2,1)$: $(2,2,1)$, $(2,1,2)$, $(1,2,2)$.\n\nIn total, the set $\\mathcal{I}(3,3)$ contains $1+3+3+3 = 10$ multi-indices:\n$$\n\\mathcal{I}(3,3) = \\{ (1,1,1), (2,1,1), (1,2,1), (1,1,2), (3,1,1), (1,3,1), (1,1,3), (2,2,1), (2,1,2), (1,2,2) \\}\n$$\n\nTask 2: Compute the total number of distinct collocation nodes $|\\mathcal{S}(3,3)|$.\n\nNext, we need the values of the incremental cardinalities, $M_\\ell = |\\Delta\\mathcal{X}_\\ell|$, for the indices that appear in $\\mathcal{I}(3,3)$, which are $\\ell \\in \\{1,2,3\\}$.\nFrom the problem statement:\n-   $M_1 = 1$\n-   $M_2 = 2$\n-   For $\\ell \\geq 3$, $M_\\ell = 2^{\\ell-2}$. For $\\ell=3$, this gives $M_3 = 2^{3-2} = 2^1 = 2$.\n\nNow we can compute the sum $\\sum_{\\boldsymbol{i} \\in \\mathcal{I}(3,3)} M_{i_1} M_{i_2} M_{i_3}$. We can group the terms by the structure of the multi-index $\\boldsymbol{i}$:\n\n-   For $\\boldsymbol{i} = (1,1,1)$:\n    There is one such index. The contribution is $M_1 M_1 M_1 = 1 \\cdot 1 \\cdot 1 = 1$.\n\n-   For permutations of $(2,1,1)$:\n    There are $3$ such indices: $(2,1,1)$, $(1,2,1)$, and $(1,1,2)$. For each, the product of cardinalities is $M_2 M_1 M_1 = 2 \\cdot 1 \\cdot 1 = 2$.\n    The total contribution from this group is $3 \\times 2 = 6$.\n\n-   For permutations of $(3,1,1)$:\n    There are $3$ such indices: $(3,1,1)$, $(1,3,1)$, and $(1,1,3)$. For each, the product of cardinalities is $M_3 M_1 M_1 = 2 \\cdot 1 \\cdot 1 = 2$.\n    The total contribution from this group is $3 \\times 2 = 6$.\n\n-   For permutations of $(2,2,1)$:\n    There are $3$ such indices: $(2,2,1)$, $(2,1,2)$, and $(1,2,2)$. For each, the product of cardinalities is $M_2 M_2 M_1 = 2 \\cdot 2 \\cdot 1 = 4$.\n    The total contribution from this group is $3 \\times 4 = 12$.\n\nFinally, the total number of nodes is the sum of these contributions:\n$$\n|\\mathcal{S}(3,3)| = 1 + 6 + 6 + 12 = 25\n$$\nThus, the total number of distinct collocation nodes in the sparse grid $\\mathcal{S}(3,3)$ is $25$.",
            "answer": "$$\\boxed{25}$$"
        },
        {
            "introduction": "The accuracy of standard stochastic collocation methods hinges on the assumption that the solution depends smoothly on the random parameters. However, in many nonlinear systems, such as fluid dynamics problems involving shock waves, this assumption fails, leading to poor convergence. This advanced practice  explores a powerful solution: a multi-element approach that partitions the parameter space to isolate non-smooth behavior, thereby restoring the accuracy of local collocation. By implementing a solver for the Burgers' equation, you will directly compare this adaptive strategy against a global approach and witness its superior performance.",
            "id": "3403658",
            "problem": "Consider the inviscid scalar conservation law known as the Burgers equation on the periodic spatial domain $[0,1]$ with time $t \\ge 0$,\n$$\n\\partial_t u(x,t;\\xi) + \\partial_x \\left( \\tfrac{1}{2} u(x,t;\\xi)^2 \\right) = 0,\n$$\nwith initial condition\n$$\nu(x,0;\\xi) = \\xi \\sin(2\\pi x),\n$$\nwhere $\\xi$ is a scalar parameter modeled as a random variable uniformly distributed on $[0,1]$. For a fixed spatial location $x^\\star \\in [0,1]$ and a fixed time $t>0$, the quantity of interest is the parameter-to-solution map $\\xi \\mapsto u(x^\\star,t;\\xi)$ and the expectation\n$$\n\\mathbb{E}[u(x^\\star,t)] = \\int_0^1 u(x^\\star,t;\\xi) \\, d\\xi.\n$$\n\nFundamental theory for the inviscid Burgers equation implies that shocks form at the first time $t_s(\\xi)$ given by\n$$\nt_s(\\xi) = -\\frac{1}{\\min_{x \\in [0,1]} \\partial_x u(x,0;\\xi)} = \\frac{1}{2\\pi \\xi},\n$$\nobtained from the method of characteristics where the solution gradient evolves according to $\\partial_x u(x(t),t) = \\frac{\\partial_x u(x_0,0)}{1 + t \\, \\partial_x u(x_0,0)}$ and blows up when $1 + t \\, \\partial_x u(x_0,0) = 0$. For any fixed $t>0$, define the critical threshold\n$$\n\\xi_c(t) = \\min\\left\\{1, \\frac{1}{2\\pi t}\\right\\}.\n$$\nThen for $\\xi \\in [0,\\xi_c(t)]$ the solution is smooth at time $t$, while for $\\xi \\in (\\xi_c(t),1]$ the solution has formed a shock before time $t$. The map $\\xi \\mapsto u(x^\\star,t;\\xi)$ consequently exhibits reduced regularity at $\\xi=\\xi_c(t)$.\n\nNonintrusive stochastic collocation approximates $\\mathbb{E}[u(x^\\star,t)]$ by evaluating the deterministic solution $u(x^\\star,t;\\xi)$ at quadrature points in the parameter space and summing with corresponding weights. A global polynomial collocation on $[0,1]$ suffers from reduced accuracy when the parametric map is nonsmooth. A remedy is to partition the parameter space into two elements,\n$$\n\\mathcal{E}_1 = [0,\\xi_c(t)], \\quad \\mathcal{E}_2 = (\\xi_c(t),1],\n$$\nand perform local collocation on each element separately, summing the contributions to obtain the expectation.\n\nYour task is to implement and compare the following two nonintrusive stochastic collocation estimators for $\\mathbb{E}[u(x^\\star,t)]$:\n\n1. A global Gauss–Legendre collocation on $[0,1]$ with $N_g$ points:\n$$\n\\mathbb{E}_{\\mathrm{global}}[u(x^\\star,t)] \\approx \\sum_{j=1}^{N_g} w_j^{(g)} \\, u(x^\\star,t;\\xi_j^{(g)}),\n$$\nwhere $\\{(\\xi_j^{(g)}, w_j^{(g)})\\}_{j=1}^{N_g}$ are Gauss–Legendre nodes and weights mapped from $[-1,1]$ to $[0,1]$.\n\n2. A two-element partitioned Gauss–Legendre collocation with $N_1$ points on $\\mathcal{E}_1$ and $N_2$ points on $\\mathcal{E}_2$:\n$$\n\\mathbb{E}_{\\mathrm{local}}[u(x^\\star,t)] \\approx \\sum_{j=1}^{N_1} w_j^{(1)} \\, u(x^\\star,t;\\xi_j^{(1)}) + \\sum_{k=1}^{N_2} w_k^{(2)} \\, u(x^\\star,t;\\xi_k^{(2)}),\n$$\nwhere $\\{(\\xi_j^{(1)}, w_j^{(1)})\\}_{j=1}^{N_1}$ and $\\{(\\xi_k^{(2)}, w_k^{(2)})\\}_{k=1}^{N_2}$ are Gauss–Legendre nodes and weights mapped to the subintervals $\\mathcal{E}_1$ and $\\mathcal{E}_2$, respectively. In the degenerate cases $\\xi_c(t) \\le 0$ or $\\xi_c(t) \\ge 1$, interpret the partition in the obvious way (one element has measure zero).\n\nFor each required evaluation $u(x^\\star,t;\\xi)$ at a collocation point $\\xi$, you must solve the deterministic Burgers equation to time $t$ using a conservative finite-volume method with periodic boundary conditions, Rusanov numerical flux\n$$\n\\widehat{f}(u_L,u_R) = \\frac{1}{2}\\left(\\tfrac{1}{2}u_L^2 + \\tfrac{1}{2}u_R^2\\right) - \\frac{1}{2} a_{\\max} (u_R - u_L), \\quad a_{\\max} = \\max\\{|u_L|,|u_R|\\},\n$$\nand the total variation diminishing Runge–Kutta method of order $2$ for time integration. Use a Courant–Friedrichs–Lewy number $C \\in (0,1)$ to set the time step adaptively as\n$$\n\\Delta t = C \\frac{\\Delta x}{\\max_i |u_i|},\n$$\nwith a suitable cap to avoid excessively large steps when $\\max_i |u_i|$ is small. Initialize with the cell-average values of $u(x,0;\\xi)$ at uniform cell centers and evolve until time $t$. The final value $u(x^\\star,t;\\xi)$ should be obtained by nearest-cell evaluation at the grid point closest to $x^\\star$. All quantities are nondimensional; no physical units are required.\n\nDefine the reference value $\\mathbb{E}_{\\mathrm{ref}}[u(x^\\star,t)]$ by a high-order Gauss–Legendre quadrature with $N_{\\mathrm{ref}}$ points on $[0,1]$, using the same deterministic solver.\n\nTest suite. Use the following four test cases, each specified as a tuple $(t, N_x, N_g, N_1, N_2)$:\n- Case $1$: $(0.4, 256, 8, 4, 4)$\n- Case $2$: $(0.4, 256, 12, 6, 6)$\n- Case $3$: $(0.1, 256, 8, 4, 4)$\n- Case $4$: $(1.5, 256, 8, 4, 4)$\n\nIn all cases, set $x^\\star = 0.25$, $C = 0.4$, and $N_{\\mathrm{ref}} = 64$. For each case, compute the absolute errors\n$$\ne_{\\mathrm{global}} = \\left| \\mathbb{E}_{\\mathrm{global}}[u(x^\\star,t)] - \\mathbb{E}_{\\mathrm{ref}}[u(x^\\star,t)] \\right|, \\quad\ne_{\\mathrm{local}}  = \\left| \\mathbb{E}_{\\mathrm{local}}[u(x^\\star,t)] - \\mathbb{E}_{\\mathrm{ref}}[u(x^\\star,t)] \\right|.\n$$\nFor each case, output the integer $1$ if $e_{\\mathrm{local}} < e_{\\mathrm{global}}$, and $0$ otherwise. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[1,0,1,1]\").",
            "solution": "The problem statement is assessed to be valid. It is a well-posed, scientifically grounded, and objective numerical experiment. The problem asks for a comparison of two nonintrusive stochastic collocation schemes for computing the expected value of a quantity of interest related to the inviscid Burgers' equation with a random initial condition. The underlying mathematical model (Burgers' equation), the phenomenon of shock formation, the principles of uncertainty quantification via stochastic collocation, and the specified numerical methods (finite volume, Rusanov flux, TVD-RK2) are all standard and well-established in the fields of computational fluid dynamics and scientific-computing. The parameters and test cases are clearly defined, and the task is computationally feasible. There are no contradictions, ambiguities, or factual unsoundness.\n\nThe core of this problem lies in computing the expectation of a functional of the solution to a parameter-dependent partial differential equation (PDE):\n$$\n\\mathbb{E}[u(x^\\star,t)] = \\int_0^1 u(x^\\star,t;\\xi) \\rho(\\xi) \\, d\\xi,\n$$\nwhere $\\xi$ is a random variable with probability density function $\\rho(\\xi)$. For this problem, $\\xi$ is uniformly distributed on $[0,1]$, so $\\rho(\\xi) = 1$. The integral becomes a standard definite integral of the parameter-to-solution map $g(\\xi) = u(x^\\star,t;\\xi)$.\n\nA nonintrusive stochastic collocation method approximates this integral using a numerical quadrature rule:\n$$\n\\mathbb{E}[g(\\xi)] \\approx \\sum_{j=1}^{N} w_j g(\\xi_j),\n$$\nwhere $\\{\\xi_j\\}_{j=1}^N$ are the collocation points (or quadrature nodes) and $\\{w_j\\}_{j=1}^N$ are the corresponding quadrature weights. The term \"nonintrusive\" signifies that this method treats the deterministic PDE solver as a black box, requiring only its evaluation at the specified points $\\xi_j$.\n\nThe accuracy of such an approximation depends critically on the smoothness of the integrand $g(\\xi)$. For polynomial-based quadrature schemes, such as the Gauss-Legendre quadrature specified, rapid (spectral) convergence is achieved if $g(\\xi)$ is analytic or at least $C^\\infty$. However, the problem statement correctly points out that the integrand $g(\\xi) = u(x^\\star,t;\\xi)$ is not globally smooth. The solution to the inviscid Burgers' equation develops a shock at a time $t_s(\\xi)$ that depends on the parameter $\\xi$. Specifically, $t_s(\\xi) = (2\\pi\\xi)^{-1}$. For a fixed time $t$, the solution's qualitative behavior changes at a critical parameter value $\\xi_c(t) = (2\\pi t)^{-1}$. For $\\xi < \\xi_c(t)$, the solution is smooth at time $t$, whereas for $\\xi > \\xi_c(t)$, a shock has already formed. This transition introduces a \"kink\" (a C1 discontinuity, or worse) in the map $\\xi \\mapsto u(x^\\star,t;\\xi)$ at $\\xi = \\xi_c(t)$.\n\nA global polynomial approximation, as used in the `global` estimator, struggles to accurately represent a function with such a kink. This leads to slow convergence of the quadrature error, a phenomenon analogous to the Gibbs phenomenon in Fourier series. The `local` or \"multi-element\" collocation method is designed to overcome this. By partitioning the parameter domain $[0,1]$ at the point of non-smoothness $\\xi_c(t)$ into two subdomains, $\\mathcal{E}_1 = [0, \\xi_c(t)]$ and $\\mathcal{E}_2 = (\\xi_c(t), 1]$, the integral is split:\n$$\n\\int_0^1 g(\\xi) \\, d\\xi = \\int_0^{\\xi_c(t)} g(\\xi) \\, d\\xi + \\int_{\\xi_c(t)}^1 g(\\xi) \\, d\\xi.\n$$\nThe integrand $g(\\xi)$ is smooth within each subdomain. Applying a separate Gauss-Legendre quadrature to each integral and summing the results circumvents the issue of the global non-smoothness, restoring the high-order accuracy of the quadrature. This problem is designed to demonstrate the superior accuracy of this partitioned approach when the total number of function evaluations is kept constant or similar.\n\nTo evaluate $g(\\xi_j) = u(x^\\star, t; \\xi_j)$, a numerical solver for the deterministic Burgers' equation is required. The problem specifies a conservative finite volume method, which is an appropriate choice for hyperbolic conservation laws that admit discontinuous (shock) solutions. The method operates on cell-average values of the solution. The spatial operator is discretized using the Rusanov numerical flux, a simple and robust flux that provides the necessary numerical dissipation to capture shocks without spurious oscillations. Time integration is performed using a second-order Total Variation Diminishing (TVD) Runge-Kutta scheme, which is a Strong-Stability-Preserving (SSP) method designed to maintain stability and non-oscillatory properties when discretizing hyperbolic PDEs. The time step $\\Delta t$ is chosen adaptively based on the Courant-Friedrichs-Lewy (CFL) condition to ensure numerical stability.\n\nThe overall algorithm is as follows:\n1.  Implement a function to generate Gauss-Legendre nodes and weights mapped to an arbitrary interval $[a,b]$.\n2.  Implement the deterministic finite volume solver for the Burgers' equation, which takes $\\xi$ and $t$ as inputs and returns the solution at $x^\\star$.\n3.  For each test case, calculate the critical parameter $\\xi_c(t)$.\n4.  Compute a high-accuracy reference solution $\\mathbb{E}_{\\mathrm{ref}}$ using a large number of quadrature points on $[0,1]$.\n5.  Compute the global estimate $\\mathbb{E}_{\\mathrm{global}}$ using $N_g$ points on $[0,1]$.\n6.  Compute the local estimate $\\mathbb{E}_{\\mathrm{local}}$ by applying quadrature with $N_1$ points on $[0, \\xi_c(t)]$ and $N_2$ points on $[\\xi_c(t), 1]$, and summing the results. The degenerate cases where $\\xi_c(t) \\ge 1$ (no shocks for any $\\xi \\in [0,1]$) are handled by performing a single quadrature over $[0,1]$.\n7.  Calculate the absolute errors $e_{\\mathrm{global}}$ and $e_{\\mathrm{local}}$ with respect to $\\mathbb{E}_{\\mathrm{ref}}$ and determine if $e_{\\mathrm{local}} < e_{\\mathrm{global}}$.\n\nThis numerical experiment will demonstrate the effectiveness of adaptively partitioning the parameter space in stochastic collocation methods when the underlying model response is non-smooth.",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef get_gauss_quadrature(N, interval):\n    \"\"\"\n    Computes Gauss-Legendre nodes and weights on a given interval.\n    \n    Args:\n        N (int): Number of quadrature points.\n        interval (list or tuple): The interval [a, b].\n    \n    Returns:\n        tuple: A tuple containing:\n            - np.ndarray: The quadrature nodes.\n            - np.ndarray: The quadrature weights.\n    \"\"\"\n    if N == 0:\n        return np.array([]), np.array([])\n    a, b = interval\n    # Get standard nodes and weights on [-1, 1]\n    z, w_hat = np.polynomial.legendre.leggauss(N)\n    # Map nodes to [a, b]\n    nodes = 0.5 * (b - a) * z + 0.5 * (a + b)\n    # Map weights to [a, b]\n    weights = 0.5 * (b - a) * w_hat\n    return nodes, weights\n\ndef compute_rhs(u, dx):\n    \"\"\"\n    Computes the right-hand side of the semi-discretized Burgers' equation,\n    L(u) = - (f_{i+1/2} - f_{i-1/2}) / dx, using Rusanov flux.\n    \"\"\"\n    # Periodic boundary conditions by rolling the array\n    u_L = u\n    u_R = np.roll(u, -1)\n\n    # Physical flux F(u) = 0.5 * u^2\n    flux_phys_L = 0.5 * u_L**2\n    flux_phys_R = 0.5 * u_R**2\n\n    # Rusanov flux: F_hat(u_L, u_R)\n    a_max = np.maximum(np.abs(u_L), np.abs(u_R))\n    flux_num_iph = 0.5 * (flux_phys_L + flux_phys_R) - 0.5 * a_max * (u_R - u_L)\n\n    # Flux at i-1/2 by rolling the i+1/2 flux array\n    flux_num_imh = np.roll(flux_num_iph, 1)\n\n    # RHS_i = -(flux_{i+1/2} - flux_{i-1/2}) / dx\n    rhs = -(flux_num_iph - flux_num_imh) / dx\n    return rhs\n\ndef solve_burgers_fv(xi, t_final, Nx, C, x_star):\n    \"\"\"\n    Solves the deterministic 1D Burgers' equation using a finite volume method.\n    \"\"\"\n    dx = 1.0 / Nx\n    x_centers = dx * (np.arange(Nx) + 0.5)\n\n    # Initial condition: u(x,0) = xi * sin(2*pi*x) at cell centers\n    u = xi * np.sin(2.0 * math.pi * x_centers)\n    t_curr = 0.0\n\n    # TVD-RK2 time integration\n    while t_curr < t_final:\n        max_abs_u = np.max(np.abs(u))\n        # Prevent division by zero and excessively large dt\n        dt_cfl = C * dx / max(max_abs_u, 1e-9)\n        dt = min(dt_cfl, t_final - t_curr)\n\n        # Stage 1\n        rhs1 = compute_rhs(u, dx)\n        u1 = u + dt * rhs1\n\n        # Stage 2\n        rhs2 = compute_rhs(u1, dx)\n        u = 0.5 * u + 0.5 * u1 + 0.5 * dt * rhs2\n\n        t_curr += dt\n\n    # Find the value at the cell closest to x_star\n    idx_star = int(round(x_star / dx - 0.5))\n    return u[idx_star]\n\ndef compute_expectation(nodes, weights, t_final, Nx, C, x_star):\n    \"\"\"\n    Computes the expectation by summing up solutions at given collocation points.\n    \"\"\"\n    expectation = 0.0\n    for xi_j, w_j in zip(nodes, weights):\n        u_val = solve_burgers_fv(xi_j, t_final, Nx, C, x_star)\n        expectation += w_j * u_val\n    return expectation\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and compare collocation methods.\n    \"\"\"\n    test_cases = [\n        # (t, Nx, Ng, N1, N2)\n        (0.4, 256, 8, 4, 4),\n        (0.4, 256, 12, 6, 6),\n        (0.1, 256, 8, 4, 4),\n        (1.5, 256, 8, 4, 4),\n    ]\n\n    x_star = 0.25\n    C = 0.4\n    N_ref = 64\n\n    results = []\n\n    for case in test_cases:\n        t, Nx, Ng, N1, N2 = case\n\n        # --- Reference expectation ---\n        ref_nodes, ref_weights = get_gauss_quadrature(N_ref, [0.0, 1.0])\n        E_ref = compute_expectation(ref_nodes, ref_weights, t, Nx, C, x_star)\n\n        # --- Global collocation ---\n        global_nodes, global_weights = get_gauss_quadrature(Ng, [0.0, 1.0])\n        E_global = compute_expectation(global_nodes, global_weights, t, Nx, C, x_star)\n\n        # --- Local (partitioned) collocation ---\n        xi_c = min(1.0, 1.0 / (2.0 * math.pi * t))\n        \n        E_local = 0.0\n        # If xi_c >= 1, the function is smooth on [0,1]. E2 is empty.\n        if xi_c >= 1.0:\n            nodes1, weights1 = get_gauss_quadrature(N1, [0.0, 1.0])\n            E_local = compute_expectation(nodes1, weights1, t, Nx, C, x_star)\n        # If xi_c < 1 an t > 0, the kink is inside (0,1).\n        else:\n            # Element 1: [0, xi_c]\n            nodes1, weights1 = get_gauss_quadrature(N1, [0.0, xi_c])\n            E1 = compute_expectation(nodes1, weights1, t, Nx, C, x_star)\n            \n            # Element 2: [xi_c, 1]\n            nodes2, weights2 = get_gauss_quadrature(N2, [xi_c, 1.0])\n            E2 = compute_expectation(nodes2, weights2, t, Nx, C, x_star)\n\n            E_local = E1 + E2\n\n        # --- Compare errors ---\n        e_global = abs(E_global - E_ref)\n        e_local = abs(E_local - E_ref)\n\n        results.append(1 if e_local < e_global else 0)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}