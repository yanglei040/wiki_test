{
    "hands_on_practices": [
        {
            "introduction": "本练习将引导你具体实践如何构建经验插值方法（EIM）代理模型。我们将聚焦于高分辨率有限体积格式中的一个关键部分：非线性通量限制器。通过为参数化的 minmod 限制器创建一个代理模型 ，你将亲手实现 EIM 的核心机制，并研究代理模型的一个关键问题——它对原始数值格式稳定性（如 $L^1$ 收缩性）的潜在影响。",
            "id": "3383561",
            "problem": "考虑在周期性定义域 $[0,1]$ 上的一个一维标量守恒律，由 $u_t + f(u)_x = 0$ 给出。对于线性平流情况，设 $f(u) = a u$，其中平流速度 $a > 0$ 为常数。将定义域离散化为 $N$ 个中心为 $x_i$、间距为 $\\Delta x = 1/N$ 的均匀单元，并使用单个显式前向欧拉步的有限体积守恒律单调上游中心格式 (MUSCL) 重构，该重构在左侧界面处进行，并使用一个由 $\\theta \\in [1,2]$ 参数化的 minmod 族斜率限制器。广义的基于 minmod 的通量限制器 $\\phi_\\theta(r)$ 作用于斜率比 $r$，并按元素定义为\n$$\n\\phi_\\theta(r) = \\max\\left(0,\\min(\\theta r,1),\\min(r,\\theta)\\right).\n$$\n假设 $a=1$ 并为时间步长 $\\Delta t$ 选择一个 Courant–Friedrichs–Lewy 数 $\\nu = a \\Delta t / \\Delta x \\in (0,1)$。\n\n对于具有周期性边界条件的单元平均向量 $u \\in \\mathbb{R}^N$，定义一阶、二阶和三阶离散差分算子如下：\n$$\n\\delta^- u_i = u_i - u_{i-1}, \\quad \\delta^+ u_i = u_{i+1} - u_i,\n$$\n$$\n\\Delta^{(2,-)} u_i = u_i - 2u_{i-1} + u_{i-2}, \\quad \\Delta^{(2,+)} u_i = u_{i+2} - 2u_{i+1} + u_i,\n$$\n$$\n\\Delta^{(3,-)} u_i = u_i - 3u_{i-1} + 3u_{i-2} - u_{i-3}, \\quad \\Delta^{(3,+)} u_i = u_{i+3} - 3u_{i+2} + 3u_{i+1} - u_i,\n$$\n其中下标对 $N$ 取模。对应的斜率比为\n$$\nr^{(1)}_i = \\frac{\\delta^- u_i}{\\delta^+ u_i + \\varepsilon}, \\quad r^{(2)}_i = \\frac{\\Delta^{(2,-)} u_i}{\\Delta^{(2,+)} u_i + \\varepsilon}, \\quad r^{(3)}_i = \\frac{\\Delta^{(3,-)} u_i}{\\Delta^{(3,+)} u_i + \\varepsilon},\n$$\n其中 $\\varepsilon > 0$ 是一个为了数值稳健性而设的小量。考虑一个次数为 $p \\in \\{1,2,3\\}$ 的分层重构，通过将界面 $x_{i+\\frac{1}{2}}$ 处的左状态定义为\n$$\nu^-_{i+\\frac{1}{2}} = u_i + \\frac{1}{2}\\,\\phi_\\theta\\!\\left(r^{(1)}_i\\right)\\,\\delta^- u_i + \\mathbf{1}_{\\{p\\ge 2\\}}\\,\\frac{1}{8}\\,\\phi_{\\alpha_2\\theta}\\!\\left(r^{(2)}_i\\right)\\,\\Delta^{(2,-)} u_i + \\mathbf{1}_{\\{p\\ge 3\\}}\\,\\frac{1}{48}\\,\\phi_{\\alpha_3\\theta}\\!\\left(r^{(3)}_i\\right)\\,\\Delta^{(3,-)} u_i,\n$$\n其中 $\\alpha_2 = \\tfrac{1}{2}$ 且 $\\alpha_3 = \\tfrac{1}{4}$，而 $\\mathbf{1}_{\\{\\cdot\\}}$ 是指示函数。在 $x_{i+\\frac{1}{2}}$ 处的迎风数值通量为 $F_{i+\\frac{1}{2}} = a\\,u^-_{i+\\frac{1}{2}}$，单元更新公式为\n$$\nu_i^{(1)} = u_i^{(0)} - \\nu \\left(F_{i+\\frac{1}{2}} - F_{i-\\frac{1}{2}}\\right),\n$$\n其中索引是周期性的。\n\n你将为作用于标量变量 $r$ 的非线性算子 $g(r;\\theta) = \\phi_\\theta(r)$ 实现一个经验插值法 (EIM) 代理模型。EIM 的构建必须从第一性原理出发：\n- 在 $r \\in [-R,R]$ 中选择一个包含 $n_r$ 个点的均匀训练网格，并选择一个参数训练集 $\\theta_j \\in [\\theta_{\\min},\\theta_{\\max}]$。\n- 构建快照矩阵 $S \\in \\mathbb{R}^{n_r \\times m}$，其列 $S(:,j) = g(r_{\\ell};\\theta_j)$ 是在 $r$-网格上计算得到的。\n- 计算奇异值分解并选择一个秩为 $k$ 的基 $U_k \\in \\mathbb{R}^{n_r \\times k}$。\n- 通过经典贪心残差最大化算法选择 $k$ 个经验插值节点 $\\{r_{p_j}\\}_{j=1}^k$，形成插值矩阵 $P^T U_k = U_k[p_1,\\dots,p_k,:] \\in \\mathbb{R}^{k \\times k}$。\n- 对于给定的 $\\theta$，构建在线近似\n$$\ng_{\\mathrm{EIM}}(\\cdot;\\theta) \\approx U_k \\left(P^T U_k\\right)^{-1} P^T g(\\cdot;\\theta),\n$$\n其中 $P^T g(\\cdot;\\theta)$ 是 $g(r_{p_j};\\theta)$ 在所选节点处的精确值。\n\n使用此代理模型来近似 MUSCL 重构中的限制器 $\\phi_\\theta(r)$，方法是在一个密集的 $r$-网格上计算 $g_{\\mathrm{EIM}}(\\cdot;\\theta)$，然后线性插值到所需的 $r$ 值。当 $p \\ge 2$ 时，对缩放后的参数 $\\alpha_2 \\theta$ 和 $\\alpha_3 \\theta$ 重用相同的代理模型。\n\n定义三对初始数据 $(u^{(0)}, v^{(0)})$ 来探究 $L^1$ 收缩性质：\n1. 一对具有微小位移的不连续阶跃函数：$u^{(0)}(x) = \\mathbf{1}_{[0,0.5)}(x)$ 和 $v^{(0)}(x) = \\mathbf{1}_{[0,0.52)}(x)$。\n2. 一对具有小相位移的光滑正弦波：$u^{(0)}(x) = 0.5 + 0.45 \\sin(2\\pi x)$ 和 $v^{(0)}(x) = 0.5 + 0.45 \\sin(2\\pi (x+\\delta))$，其中 $\\delta = 0.02$。\n3. 一对平滑随机场：从独立标准正态分布中抽取 $w \\in \\mathbb{R}^N$，通过在宽度为9个单元的窗口上进行局部平均来平滑以获得 $u^{(0)}$，并设置 $v^{(0)}(x) = u^{(0)}(x) + 0.01\\sin(4\\pi x)$，将两者都裁剪到 $[0,1]$ 区间内。\n\n对于每一对，计算离散 $L^1$ 距离 $\\|u^{(0)} - v^{(0)}\\|_1 = \\Delta x \\sum_i |u_i^{(0)} - v_i^{(0)}|$，并在一个更新步后使用以下方法计算 $\\|u^{(1)} - v^{(1)}\\|_1$：\n- 精确限制器 $\\phi_\\theta$ (基线)，以及\n- 使用 EIM 代理模型 $g_{\\mathrm{EIM}}$ 代替 $\\phi_\\theta$ (代理模型)。\n\n如果对于给定的 $(p,\\theta)$，三对初始数据中至少有一对满足\n$$\n\\|u^{(1)}_{\\mathrm{sur}} - v^{(1)}_{\\mathrm{sur}}\\|_1 > \\|u^{(0)} - v^{(0)}\\|_1 + \\varepsilon \\quad \\text{and} \\quad \\|u^{(1)}_{\\mathrm{exact}} - v^{(1)}_{\\mathrm{exact}}\\|_1 \\le \\|u^{(0)} - v^{(0)}\\|_1 + \\varepsilon,\n$$\n的条件，则声明该代理模型降低了 $L^1$ 收缩性，其中容差 $\\varepsilon = 10^{-12}$。\n\n使用 $a = 1$, $N = 200$, $\\nu = 0.5$, $\\varepsilon = 10^{-12}$, $R = 6$, $n_r = 401$ 实现以上过程，EIM 训练参数为 $\\theta_{\\min} = 1.2$, $\\theta_{\\max} = 1.8$，共 $m = 5$ 个均匀间隔的训练参数，秩为 $k = 4$。\n\n测试套件：\n使用以下八个参数集 $(p,\\theta)$：\n- $(1, 1.0)$,\n- $(1, 1.8)$,\n- $(1, 2.0)$,\n- $(2, 1.0)$,\n- $(2, 1.8)$,\n- $(2, 2.0)$,\n- $(3, 1.3)$,\n- $(3, 2.0)$.\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含八个测试用例的布尔退化结果，按给定顺序排列，格式为方括号括起来的逗号分隔列表（例如，`[True,False,False,True,False,False,True,False]`）。不应打印任何其他文本。不使用角度；输出中没有物理单位。所有计算必须如上所述以纯数学术语执行。",
            "solution": "该问题要求实现一个高阶 MUSCL 型有限体积格式，以求解周期性定义域上的一维线性平流方程 $u_t + a u_x = 0$。问题的核心是为非线性广义 minmod 通量限制器函数 $\\phi_\\theta(r)$ 构建一个经验插值法 (EIM) 代理模型，并评估该代理模型是否降低了数值格式的 $L^1$ 收缩性质。\n\n该方法论涉及几个不同的步骤：\n$1$. 定义并实现最高达到 $p \\in \\{1,2,3\\}$ 阶的分层 MUSCL 有限体积格式。\n$2$. 离线构建限制器函数 $\\phi_\\theta(r)$ 的 EIM 代理模型。\n$3$. 使用精确限制器和 EIM 代理模型在线评估该格式。\n$4$. 针对一组测试用例，基于离散 $L^1$ 范数进行定量比较，以检查收缩性质是否退化。\n\n首先，我们详细说明数值格式。定义域 $[0,1]$ 被离散化为 $N$ 个宽度为 $\\Delta x = 1/N$ 的单元。在时间步 $n$ 的单元平均量记为 $u_i^{(n)}$。单个前向欧拉时间步通过以下方式更新解：\n$$\nu_i^{(n+1)} = u_i^{(n)} - \\frac{\\Delta t}{\\Delta x} \\left(F_{i+\\frac{1}{2}} - F_{i-\\frac{1}{2}}\\right)\n$$\n其中 $\\nu = a \\Delta t / \\Delta x$ 是 Courant 数。数值通量 $F_{i+\\frac{1}{2}}$ 是一个迎风通量，$F_{i+\\frac{1}{2}} = a u^-_{i+\\frac{1}{2}}$，因为平流速度 $a=1$ 是正的。值 $u^-_{i+\\frac{1}{2}}$ 是解在界面 $x_{i+\\frac{1}{2}}$ 左侧的高阶重构。次数为 $p$ 的分层重构由下式给出：\n$$\nu^-_{i+\\frac{1}{2}} = u_i + \\frac{1}{2}\\phi_\\theta(r^{(1)}_i)\\delta^- u_i + \\mathbf{1}_{\\{p\\ge 2\\}}\\frac{1}{8}\\phi_{\\alpha_2\\theta}(r^{(2)}_i)\\Delta^{(2,-)} u_i + \\mathbf{1}_{\\{p\\ge 3\\}}\\frac{1}{48}\\phi_{\\alpha_3\\theta}(r^{(3)}_i)\\Delta^{(3,-)} u_i\n$$\n项 $\\delta^- u_i$, $\\Delta^{(2,-)} u_i$ 和 $\\Delta^{(3,-)} u_i$ 分别是一阶、二阶和三阶的后向有限差分算子。对应的斜率比 $r^{(k)}_i$ 是通过将后向差分除以相应的前向差分形成的，例如，$r^{(1)}_i = (\\delta^- u_i) / (\\delta^+ u_i + \\varepsilon)$。函数 $\\phi_\\theta(r)$ 是广义 minmod 限制器：\n$$\n\\phi_\\theta(r) = \\max\\left(0, \\min(\\theta r, 1), \\min(r, \\theta)\\right)\n$$\n此限制器应用于重构的每一阶，使用缩放参数 $\\alpha_k \\theta$ 来控制伪振荡。常数给定为 $\\alpha_2 = 1/2$ 和 $\\alpha_3 = 1/4$。所有下标都以对 $N$ 取模的方式进行周期性处理。\n\n其次，我们为参数化函数 $g(r; \\theta) = \\phi_\\theta(r)$ 构建 EIM 代理模型。这是一种模型降阶技术，并从一个离线训练阶段开始。\n$1$. 在区间 $[\\theta_{\\min}, \\theta_{\\max}] = [1.2, 1.8]$ 中均匀选择一组 $m=5$ 个训练参数 $\\{\\theta_j\\}_{j=1}^5$。\n$2$. 为变量 $r$ 在 $[-R, R] = [-6, 6]$ 内均匀创建一个包含 $n_r = 401$ 个点的训练网格。\n$3$. 组装一个快照矩阵 $S \\in \\mathbb{R}^{n_r \\times m}$，其中每一列 $S_{:,j}$ 是函数 $g(r; \\theta_j)$ 在 $r$-网格上的求值。\n$4$. 快照矩阵的奇异值分解 (SVD) $S = U \\Sigma V^\\top$ 为快照张成的空间提供了一个标准正交基 $U$。我们将此基截断为前 $k=4$ 个主导模态，得到降阶基 $U_k \\in \\mathbb{R}^{n_r \\times k}$。\n$5$. 使用贪心算法从 $r$-网格中选择一组 $k=4$ 个经验插值节点 $\\{r_{p_j}\\}_{j=1}^k$。该算法迭代地选择一个点，该点在使用先前选择的点和基向量构建的插值来逼近下一个基向量时，能够最大化残差。此过程确保了插值矩阵是良态的。\n令 $I = \\{p_1, \\dots, p_k\\}$ 为插值节点的索引集。我们定义一个矩阵 $M = U_k[I, :]$，它表示在插值节点处求值的基向量。该矩阵的逆矩阵 $M^{-1}$ 被预先计算。离线阶段通过存储 $U_k$、$M^{-1}$、插值节点索引 $I$ 和 $r$-网格来结束。\n\n第三，在在线阶段，对于任何新参数 $\\theta$，都会评估 EIM 代理模型 $g_{\\mathrm{EIM}}(r;\\theta)$。这通过首先仅在 $k$ 个插值节点上评估精确函数 $g(r;\\theta)$ 来完成，$g_{\\text{nodes}} = g(r_I; \\theta)$。然后在降阶基中的近似系数计算为 $c = M^{-1} g_{\\text{nodes}}$。EIM 近似则由 $g_{\\mathrm{EIM}}(\\cdot ; \\theta) = U_k c$ 给出。问题指定此 EIM 评估应在训练阶段的密集 $r$-网格上执行。当 MUSCL 格式需要根据解数据计算出的特定斜率比 $r_i$ 对应的 $\\phi_\\theta(r_i)$ 值时，该值通过对密集 $r$-网格上的预计算向量 $g_{\\mathrm{EIM}}(\\cdot ; \\theta)$ 进行线性插值来获得。\n\n最后，我们测试代理模型的性能。$L^1$ 收缩性质指出，对于一个有效的格式，两个不同解之间的 $L^1$ 距离不应随时间增加，即 $\\|u^{(n+1)} - v^{(n+1)}\\|_1 \\le \\|u^{(n)} - v^{(n)}\\|_1$。我们使用三对初始条件 $(u^{(0)}, v^{(0)})$ 对此性质进行一个时间步的测试。对于每个测试用例 $(p, \\theta)$，我们比较使用精确限制器和 EIM 代理模型时 $L^1$ 距离的演化。如果对于三对初始条件中的任何一对，代理模型导致 $L^1$ 距离显著增加，而精确格式却没有，则声明代理模型导致“退化”。形式上，如果满足以下条件，则发生退化：\n$$\n\\|u^{(1)}_{\\mathrm{sur}} - v^{(1)}_{\\mathrm{sur}}\\|_1 > \\|u^{(0)} - v^{(0)}\\|_1 + \\varepsilon \\quad \\text{and} \\quad \\|u^{(1)}_{\\mathrm{exact}} - v^{(1)}_{\\mathrm{exact}}\\|_1 \\le \\|u^{(0)} - v^{(0)}\\|_1 + \\varepsilon\n$$\n容差为 $\\varepsilon = 10^{-12}$。该实现将对所有指定的 $(p, \\theta)$ 对系统地执行此过程，并报告一个布尔值，指示是否观察到退化。\n\n所有数值参数都在问题中指定：$a=1$, $N=200$, $\\nu=0.5$, $\\varepsilon=10^{-12}$, $R=6$, $n_r=401$, $\\theta_{\\min}=1.2$, $\\theta_{\\max}=1.8$, $m=5$, $k=4$。对于涉及随机场的第三个初始条件，使用固定种子以保证可复现性。\n\n最终的 Python 代码实现了这些步骤。为限制器 $\\phi_\\theta$、EIM 构建、EIM 评估、MUSCL 更新步骤以及初始条件的生成定义了辅助函数。主函数协调所有用例的测试过程，并打印最终的布尔值列表。该实现使用 `numpy` 进行数组操作，使用 `numpy.linalg.svd` 进行奇异值分解。使用 `numpy.roll` 来高效地实现具有周期性边界条件的有限差分。线性插值使用 `numpy.interp` 执行。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not used as per the allowed library list.\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and produce the final output.\n    \"\"\"\n    # Global parameters as specified in the problem\n    a = 1.0\n    N = 200\n    nu = 0.5\n    eps = 1e-12\n    R = 6.0\n    n_r = 401\n    theta_min = 1.2\n    theta_max = 1.8\n    m = 5\n    k = 4\n    dx = 1.0 / N\n    \n    # EIM surrogate parameters\n    eim_params = {\n        'R': R,\n        'n_r': n_r,\n        'theta_min': theta_min,\n        'theta_max': theta_max,\n        'm': m,\n        'k': k\n    }\n\n    # Test suite from the problem statement\n    test_suite = [\n        (1, 1.0),\n        (1, 1.8),\n        (1, 2.0),\n        (2, 1.0),\n        (2, 1.8),\n        (2, 2.0),\n        (3, 1.3),\n        (3, 2.0)\n    ]\n\n    # Build the EIM surrogate (offline stage)\n    eim_data = build_eim_surrogate(eim_params)\n\n    # Get initial conditions\n    ic_pairs = get_initial_conditions(N, dx)\n\n    results = []\n    for p, theta in test_suite:\n        degradation_found = False\n        for u0, v0 in ic_pairs:\n            l1_dist_0 = dx * np.sum(np.abs(u0 - v0))\n\n            # Run with exact limiter\n            u1_exact = get_update(u0, p, theta, a, nu, dx, N, eps, use_eim=False, eim_data=None)\n            v1_exact = get_update(v0, p, theta, a, nu, dx, N, eps, use_eim=False, eim_data=None)\n            l1_dist_1_exact = dx * np.sum(np.abs(u1_exact - v1_exact))\n\n            # Run with EIM surrogate\n            u1_sur = get_update(u0, p, theta, a, nu, dx, N, eps, use_eim=True, eim_data=eim_data)\n            v1_sur = get_update(v0, p, theta, a, nu, dx, N, eps, use_eim=True, eim_data=eim_data)\n            l1_dist_1_sur = dx * np.sum(np.abs(u1_sur - v1_sur))\n\n            # Check degradation condition\n            if l1_dist_1_sur > l1_dist_0 + eps and l1_dist_1_exact <= l1_dist_0 + eps:\n                degradation_found = True\n                break  # One instance of degradation is sufficient for this test case\n        \n        results.append(degradation_found)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef phi_theta(r, theta):\n    \"\"\"\n    Computes the generalized minmod flux limiter.\n    phi_theta(r) = max(0, min(theta*r, 1), min(r, theta))\n    \"\"\"\n    zero = np.zeros_like(r)\n    term1 = np.minimum(theta * r, 1.0)\n    term2 = np.minimum(r, theta)\n    return np.maximum.reduce([zero, term1, term2])\n\ndef build_eim_surrogate(params):\n    \"\"\"\n    Builds the EIM surrogate (offline phase).\n    \"\"\"\n    k = params['k']\n    r_grid = np.linspace(-params['R'], params['R'], params['n_r'])\n    theta_train = np.linspace(params['theta_min'], params['theta_max'], params['m'])\n\n    # 1. Snapshot matrix\n    S = np.zeros((params['n_r'], params['m']))\n    for j, th in enumerate(theta_train):\n        S[:, j] = phi_theta(r_grid, th)\n\n    # 2. SVD and basis\n    U, s, Vh = np.linalg.svd(S, full_matrices=False)\n    U_k = U[:, :k]\n\n    # 3. Greedy selection of interpolation points\n    indices = []\n    # First point\n    p1_idx = np.argmax(np.abs(U_k[:, 0]))\n    indices.append(p1_idx)\n    \n    for j in range(1, k):\n        U_sub = U_k[:, :j]\n        target_vec = U_k[:, j]\n        \n        P_U_sub = U_k[indices, :j]\n        P_target_vec = U_k[indices, j]\n        \n        coeffs = np.linalg.solve(P_U_sub, P_target_vec)\n        \n        residual = target_vec - U_sub @ coeffs\n        p_new_idx = np.argmax(np.abs(residual))\n        indices.append(p_new_idx)\n\n    # 4. Pre-compute inverse of interpolation matrix\n    M = U_k[indices, :]\n    M_inv = np.linalg.inv(M)\n\n    return {'U_k': U_k, 'M_inv': M_inv, 'indices': indices, 'r_grid': r_grid}\n\ndef evaluate_eim_surrogate(eim_data, theta):\n    \"\"\"\n    Evaluates the EIM surrogate for a given theta (online phase).\n    \"\"\"\n    U_k = eim_data['U_k']\n    M_inv = eim_data['M_inv']\n    indices = eim_data['indices']\n    r_grid = eim_data['r_grid']\n\n    r_nodes = r_grid[indices]\n    g_at_nodes = phi_theta(r_nodes, theta)\n    \n    coeffs = M_inv @ g_at_nodes\n    g_eim = U_k @ coeffs\n\n    return g_eim\n\ndef get_update(u, p, theta, a, nu, dx, N, eps, use_eim, eim_data):\n    \"\"\"\n    Computes one time step of the MUSCL scheme.\n    \"\"\"\n    # Difference operators\n    dm1_u = u - np.roll(u, 1)\n    dp1_u = np.roll(u, -1) - u\n    \n    # Ratios\n    r1 = dm1_u / (dp1_u + eps)\n\n    # Limiter application\n    if use_eim:\n        # Evaluate EIM on dense grid\n        g_eim_1 = evaluate_eim_surrogate(eim_data, theta)\n        # Interpolate to find values at required ratios\n        phi1 = np.interp(r1, eim_data['r_grid'], g_eim_1)\n    else:\n        phi1 = phi_theta(r1, theta)\n\n    # Hierarchical Reconstruction\n    u_left = u + 0.5 * phi1 * dm1_u\n\n    alpha2 = 0.5\n    if p >= 2:\n        dm2_u = u - 2 * np.roll(u, 1) + np.roll(u, 2)\n        dp2_u = np.roll(u, -2) - 2 * np.roll(u, -1) + u\n        r2 = dm2_u / (dp2_u + eps)\n        \n        if use_eim:\n            g_eim_2 = evaluate_eim_surrogate(eim_data, alpha2 * theta)\n            phi2 = np.interp(r2, eim_data['r_grid'], g_eim_2)\n        else:\n            phi2 = phi_theta(r2, alpha2 * theta)\n            \n        u_left += (1.0 / 8.0) * phi2 * dm2_u\n\n    alpha3 = 0.25\n    if p >= 3:\n        dm3_u = u - 3 * np.roll(u, 1) + 3 * np.roll(u, 2) - np.roll(u, 3)\n        dp3_u = np.roll(u, -3) - 3 * np.roll(u, -2) + 3 * np.roll(u, -1) - u\n        r3 = dm3_u / (dp3_u + eps)\n\n        if use_eim:\n            g_eim_3 = evaluate_eim_surrogate(eim_data, alpha3 * theta)\n            phi3 = np.interp(r3, eim_data['r_grid'], g_eim_3)\n        else:\n            phi3 = phi_theta(r3, alpha3 * theta)\n            \n        u_left += (1.0 / 48.0) * phi3 * dm3_u\n\n    # Numerical Flux\n    F = a * u_left\n    F_imhalf = np.roll(F, 1)\n\n    # Update\n    u_new = u - nu * (F - F_imhalf)\n    return u_new\n\ndef get_initial_conditions(N, dx):\n    \"\"\"\n    Generates the three pairs of initial condition data.\n    \"\"\"\n    x = (np.arange(N) + 0.5) * dx\n    ic_pairs = []\n\n    # 1. Discontinuous step functions\n    u0_1 = (x < 0.5).astype(float)\n    v0_1 = (x < 0.52).astype(float)\n    ic_pairs.append((u0_1, v0_1))\n\n    # 2. Smooth sinusoidal waves\n    delta = 0.02\n    u0_2 = 0.5 + 0.45 * np.sin(2 * np.pi * x)\n    v0_2 = 0.5 + 0.45 * np.sin(2 * np.pi * (x + delta))\n    ic_pairs.append((u0_2, v0_2))\n\n    # 3. Smoothed random fields\n    np.random.seed(42) # For reproducibility\n    w = np.random.randn(N)\n    window_width = 9\n    pad_width = window_width // 2\n    w_padded = np.concatenate((w[-pad_width:], w, w[:pad_width]))\n    kernel = np.ones(window_width) / window_width\n    u0_3_raw = np.convolve(w_padded, kernel, mode='valid')\n    \n    v0_3_raw = u0_3_raw + 0.01 * np.sin(4 * np.pi * x)\n    \n    u0_3 = np.clip(u0_3_raw, 0, 1)\n    v0_3 = np.clip(v0_3_raw, 0, 1)\n    ic_pairs.append((u0_3, v0_3))\n\n    return ic_pairs\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "在构建了基本的 EIM 模型后，下一个关键问题是如何选择最优的插值点。本练习  旨在比较两种强大的选择策略：一种是基于主元 QR 分解的全局代数方法，另一种是专为间断 Galerkin (DG) 方法设计的、考虑物理特性的“局部化”贪心算法。通过实现和比较这两种方法，你将更深入地理解选点算法如何影响模型精度，以及如何根据底层数值方法的结构来定制这些算法。",
            "id": "3383616",
            "problem": "考虑一维域 $[0,1]$，它被划分为 $E$ 个无重叠单元 $\\{K\\}_{K=1}^{E}$，每个单元配备 $n_p$ 个局部配置节点。全局节点集由 $i=1,\\dots,M$ 索引，其中 $M=E \\cdot n_p$，并且每个索引 $i$ 都映射到一个唯一的单元 $K(i) \\in \\{1,\\dots,E\\}$。设 $x_i \\in [0,1]$ 表示与全局索引 $i$ 对应的坐标。\n\n设参数化状态由确定性函数 $u(x;\\mu)$ 给出，其中 $\\mu \\in [0,1]$ 是一个标量参数，并定义一个非线性算子 $\\mathcal{N}(u)$。您的任务是为 $\\mathcal{N}(u)$ 构建一个适用于间断 Galerkin (DG) 离散化的经验插值法 (EIM)，并比较两种选点策略：\n- 一种由单元 DG 残差范数驱动的局部贪心策略。\n- 一种全局主元 QR 策略。\n\n请使用以下精确的数学规范。\n\n- 空间离散化和参数化状态：\n  - 使用 $E=10$ 个单元，每个单元 $n_p=6$ 个节点。对于每个单元 $K$，将 $n_p$ 个节点均匀放置在单元内部，以使所有全局节点在不同单元间是不同的。\n  - 定义\n    $$u(x;\\mu) = \\sin\\!\\big(2\\pi(x+0.3\\mu)\\big) + \\tfrac{1}{2}\\cos\\!\\big(5\\pi(x-0.2\\mu)\\big) + 0.2\\exp\\!\\big(-50(x-0.3-0.4\\mu)^2\\big)。$$\n  - 定义非线性算子\n    $$\\mathcal{N}(u) = u^2 + \\exp(u)。$$\n\n- 快照矩阵和降阶基：\n  - 设训练参数集为 $\\{\\mu_k\\}_{k=1}^{N_\\mathrm{train}}$，其中包含 $[0,1]$ 上的 $N_\\mathrm{train}=24$ 个等距值。\n  - 构建快照矩阵 $S \\in \\mathbb{R}^{M \\times N_\\mathrm{train}}$，其元素为\n    $$S_{i,k} = \\mathcal{N}(u(x_i;\\mu_k))。$$\n  - 计算薄奇异值分解 $S = U \\Sigma V^\\top$，并将 $U$ 的前 $r_{\\max}$ 列定义为降阶空间基，记为 $\\Phi = [\\phi_1,\\dots,\\phi_{r_{\\max}}] \\in \\mathbb{R}^{M \\times r_{\\max}}$，其中 $r_{\\max}=12$。\n\n- 离散经验插值法 (EIM) 近似算子：\n  - 对于一个基数为 $r$ 的插值索引集 $\\mathcal{I}_r = \\{i_1,\\dots,i_r\\} \\subset \\{1,\\dots,M\\}$，设 $P_{\\mathcal{I}_r} \\in \\mathbb{R}^{M \\times r}$ 是在索引 $\\mathcal{I}_r$ 处提取元素的采样矩阵。\n  - 任何向量 $f \\in \\mathbb{R}^M$ 的秩为 $r$ 的 EIM 近似由下式给出\n    $$\\mathcal{P}_r(f) = \\Phi_r \\left(P_{\\mathcal{I}_r}^\\top \\Phi_r\\right)^{-1} P_{\\mathcal{I}_r}^\\top f,$$\n    其中 $\\Phi_r = [\\phi_1,\\dots,\\phi_r]$。\n\n- 需要实现的选点策略：\n  1. 由单元 DG 残差范数驱动的局部贪心策略：\n     - 初始化一个空索引集。对于 $k=1,\\dots,r_{\\max}$：\n       - 使用已选索引 $\\mathcal{I}_{k-1}$ 将 $\\phi_k$ 的当前近似定义为\n         $$\\widehat{\\phi}_k = \\begin{cases}\n         0,  & k=1,\\\\\n         \\Phi_{k-1} \\left(P_{\\mathcal{I}_{k-1}}^\\top \\Phi_{k-1}\\right)^{-1} P_{\\mathcal{I}_{k-1}}^\\top \\phi_k,  & k \\ge 2,\n         \\end{cases}$$\n         以及残差 $r_k = \\phi_k - \\widehat{\\phi}_k \\in \\mathbb{R}^M$。\n       - 对每个单元 $K$，计算单元 DG 残差范数\n         $$\\|r_k\\|_{K} = \\left(\\sum_{i:K(i)=K} r_k(i)^2\\right)^{1/2}。$$\n       - 设 $K^\\star$ 是使 $\\|r_k\\|_K$ 最大化的单元。选择新的插值索引 $i_k$ 为单元 $K^\\star$ 内使 $|r_k(i)|$ 最大化的索引。设置 $\\mathcal{I}_k = \\mathcal{I}_{k-1} \\cup \\{i_k\\}$。\n  2. 全局主元 QR：\n     - 计算 $\\Phi^\\top$ 的列主元 QR 分解，并将主元顺序定义为 $\\{1,\\dots,M\\}$ 的一个排列。对于秩 $r$，取前 $r$ 个主元索引作为 $\\mathcal{I}_r$。\n\n- 评估协议：\n  - 定义测试参数集 $\\{\\mu^\\mathrm{test}_j\\}_{j=1}^{N_\\mathrm{test}}$，其中 $N_\\mathrm{test}=4$ 个值为 $\\{0.07, 0.31, 0.58, 0.83\\}$。\n  - 对于每个秩 $r \\in \\{1,4,8,12\\}$ 和每个测试参数 $\\mu^\\mathrm{test}_j$：\n    - 构建 $f = \\mathcal{N}(u(\\cdot;\\mu^\\mathrm{test}_j)) \\in \\mathbb{R}^M$。\n    - 使用局部贪心索引 $\\mathcal{I}^{\\mathrm{loc}}_r$ 计算 EIM 近似 $\\widehat{f}_\\mathrm{loc}$，并使用主元 QR 索引 $\\mathcal{I}^{\\mathrm{qr}}_r$ 计算 $\\widehat{f}_\\mathrm{qr}$。\n    - 计算相对误差\n      $$e_\\mathrm{loc}(r,\\mu^\\mathrm{test}_j) = \\frac{\\|f - \\widehat{f}_\\mathrm{loc}\\|_2}{\\|f\\|_2}, \\quad e_\\mathrm{qr}(r,\\mu^\\mathrm{test}_j) = \\frac{\\|f - \\widehat{f}_\\mathrm{qr}\\|_2}{\\|f\\|_2}。$$\n  - 对每个秩 $r$，计算两种方法在测试集上的平均相对误差：\n    $$\\overline{e}_\\mathrm{loc}(r) = \\frac{1}{N_\\mathrm{test}} \\sum_{j=1}^{N_\\mathrm{test}} e_\\mathrm{loc}(r,\\mu^\\mathrm{test}_j), \\quad \\overline{e}_\\mathrm{qr}(r) = \\frac{1}{N_\\mathrm{test}} \\sum_{j=1}^{N_\\mathrm{test}} e_\\mathrm{qr}(r,\\mu^\\mathrm{test}_j)。$$\n\n您的任务：\n- 完全并确定性地实现上述流程。\n- 仅使用为指定矩阵和向量良定义的线性代数运算。如果在任何步骤中线性求解是病态或奇异的，请使用最小二乘解而不是失败。\n- 您必须构建您的程序，以完全按照以下顺序为秩 $r \\in \\{1,4,8,12\\}$ 生成以下最终输出：\n  $$\\left[\\overline{e}_\\mathrm{loc}(1), \\overline{e}_\\mathrm{qr}(1), \\overline{e}_\\mathrm{loc}(4), \\overline{e}_\\mathrm{qr}(4), \\overline{e}_\\mathrm{loc}(8), \\overline{e}_\\mathrm{qr}(8), \\overline{e}_\\mathrm{loc}(12), \\overline{e}_\\mathrm{qr}(12)\\right].$$\n\n测试套件和答案规范：\n- 您必须使用上文指定的精确参数值、空间离散化和秩。\n- 每个测试用例的输出必须是浮点数。最终输出格式必须是单行，包含一个按所述确切顺序排列的八个浮点数的 Python 风格列表，不带单位，也无附加文本。程序必须在没有任何用户输入的情况下运行，并且不得依赖任何外部文件或网络资源。",
            "solution": "用户提供的问题是数值分析领域一个定义明确的任务，具体涉及模型降阶和经验插值法 (EIM)。该问题在科学上是合理的，内容是自洽的，并且算法上是明确的。此问题被认定为有效。\n\n解决方案是按照指定的流程逐步构建的。\n\n### 1. 离散化和问题设置\n\n首先，我们建立计算域和离散化。空间域为 $[0,1]$。它被划分为 $E=10$ 个单元，记为 $K_e = [(e-1)/E, e/E]$，其中 $e=1, \\dots, 10$。在每个单元内部，我们均匀放置 $n_p=6$ 个配置节点。单元 $K_e$ 中第 $j$ 个节点（$j=1, \\dots, n_p$）的坐标由 $x_{e,j} = \\frac{e-1}{E} + j \\frac{1/E}{n_p+1}$ 给出。这产生了一个包含 $M = E \\cdot n_p = 60$ 个不同全局节点的集合，其坐标记为 $x_i$，其中 $i=1, \\dots, M$。一个映射 $K(i)$ 将每个全局节点索引 $i$ 与其对应的单元索引关联起来。\n\n参数化状态函数 $u(x;\\mu)$ 和非线性算子 $\\mathcal{N}(u)$ 定义如下：\n$$u(x;\\mu) = \\sin\\!\\big(2\\pi(x+0.3\\mu)\\big) + \\tfrac{1}{2}\\cos\\!\\big(5\\pi(x-0.2\\mu)\\big) + 0.2\\exp\\!\\big(-50(x-0.3-0.4\\mu)^2\\big)$$\n$$\\mathcal{N}(u) = u^2 + \\exp(u)$$\n其中 $\\mu \\in [0,1]$ 是一个标量参数。\n\n### 2. 降阶基生成\n\n使用快照法为非线性输出生成一个降阶基。\n参数 $\\mu$ 的训练集是 $[0,1]$ 上的一个包含 $N_{\\mathrm{train}}=24$ 个点的等距网格，记为 $\\{\\mu_k\\}_{k=1}^{24}$。\n对于每个 $\\mu_k$，我们在所有全局节点 $x_i$ 上计算非线性算子，以形成一个快照向量 $f_k \\in \\mathbb{R}^M$，其中 $(f_k)_i = \\mathcal{N}(u(x_i; \\mu_k))$。\n这些快照被收集为快照矩阵 $S = [f_1 | f_2 | \\dots | f_{N_{\\mathrm{train}}}] \\in \\mathbb{R}^{M \\times N_{\\mathrm{train}}}$ 的列。\n\n然后我们计算快照矩阵的薄奇异值分解 (SVD)：$S = U \\Sigma V^\\top$。左奇异向量，即 $U \\in \\mathbb{R}^{M \\times N_{\\mathrm{train}}}$ 的列，构成了快照所张成空间的最优标准正交基。通过取 $U$ 的前 $r_{\\max}=12$ 列来构造降阶基 $\\Phi \\in \\mathbb{R}^{M \\times r_{\\max}}$，即 $\\Phi = [\\phi_1, \\dots, \\phi_{r_{\\max}}]$。一个秩为 $r$ 的基记为 $\\Phi_r = [\\phi_1, \\dots, \\phi_r]$。\n\n### 3. 选点策略\n\n任务的核心是从 $M$ 个可用节点中选择一组包含 $r$ 个插值点（或全局节点索引）的集合 $\\mathcal{I}_r = \\{i_1, \\dots, i_r\\}$。我们实现并比较两种策略。\n\n#### 3.1. 局部贪心策略\n\n这是一个迭代过程。对于 $k=1, \\dots, r_{\\max}$，我们选择第 $k$ 个索引 $i_k$。该选择基于残差向量 $r_k = \\phi_k - \\widehat{\\phi}_k$，其中 $\\widehat{\\phi}_k$ 是使用先前选择的 $k-1$ 个索引对第 $k$ 个基向量 $\\phi_k$ 进行的 EIM 近似。\n对于 $k=1$，没有选择任何索引，所以残差就是 $r_1 = \\phi_1$。\n对于 $k>1$，给定索引集 $\\mathcal{I}_{k-1}=\\{i_1, \\dots, i_{k-1}\\}$，近似为：\n$$\\widehat{\\phi}_k = \\Phi_{k-1} \\left(P_{\\mathcal{I}_{k-1}}^\\top \\Phi_{k-1}\\right)^{-1} P_{\\mathcal{I}_{k-1}}^\\top \\phi_k$$\n其中 $P_{\\mathcal{I}_{k-1}}$ 是在索引集 $\\mathcal{I}_{k-1}$ 处对向量进行采样的算子。为了数值稳定性，使用最小二乘法（`numpy.linalg.lstsq`）求解系数的线性系统。\n\n一旦计算出残差 $r_k$，我们为每个单元 $K$ 计算其逐单元 $L_2$ 范数：$\\|r_k\\|_K = (\\sum_{i: K(i)=K} r_k(i)^2)^{1/2}$。我们确定使该范数最大化的单元 $K^\\star$。然后，新的索引 $i_k$ 被选为 $K^\\star$ 内使残差绝对值 $|r_k(i)|$ 最大化的节点。索引集更新为：$\\mathcal{I}_k = \\mathcal{I}_{k-1} \\cup \\{i_k\\}$。对 $k=1, \\dots, r_{\\max}$ 重复此过程，以生成索引的有序列表 $\\mathcal{I}^{\\mathrm{loc}}_{r_{\\max}}$。\n\n#### 3.2. 全局主元 QR 策略\n\n该策略利用了列主元 QR 分解的性质。这是一种非迭代的直接方法。我们计算基矩阵转置 $\\Phi^\\top$ 的列主元 QR 分解。分解形式为 $\\Phi^\\top P = QR$，其中 $P$ 是一个置换矩阵，它对 $\\Phi^\\top$ 的列进行重排，以确保得到一个良态的上三角矩阵 $R$。$\\Phi^\\top$ 的列对应于全局节点 $\\{1, \\dots, M\\}$。因此，置换 $P$ 定义了对 $\\Phi$ 中最线性无关的行的贪心选择。从置换中获得的主元索引被用作插值点。对于秩为 $r$ 的近似，我们使用前 $r$ 个主元索引。此过程生成索引的有序列表 $\\mathcal{I}^{\\mathrm{qr}}_{r_{\\max}}$。\n\n### 4. EIM 近似的评估\n\n我们评估使用两组选定点集的 EIM 的准确性。向量 $f \\in \\mathbb{R}^M$ 的秩为 $r$ 的 EIM 近似由下式给出：\n$$\\mathcal{P}_r(f) = \\Phi_r \\left(P_{\\mathcal{I}_r}^\\top \\Phi_r\\right)^{-1} P_{\\mathcal{I}_r}^\\top f$$\n同样，逆的计算是通过对系数 $c$ 的方程组 $(P_{\\mathcal{I}_r}^\\top \\Phi_r)c = P_{\\mathcal{I}_r}^\\top f$ 进行稳健的最小二乘求解，然后进行重构 $\\mathcal{P}_r(f) = \\Phi_r c$。\n\n评估使用一组测试参数 $\\mu^\\mathrm{test} = \\{0.07, 0.31, 0.58, 0.83\\}$。对于每个秩 $r \\in \\{1, 4, 8, 12\\}$ 和每个 $\\mu^\\mathrm{test}_j$，我们执行以下操作：\n1.  在所有全局节点上计算“真实”输出向量 $f = \\mathcal{N}(u(\\cdot; \\mu^\\mathrm{test}_j))$。\n2.  使用局部贪心索引 $\\mathcal{I}^{\\mathrm{loc}}_r$ 计算 EIM 近似 $\\widehat{f}_{\\mathrm{loc}}$。\n3.  使用主元 QR 索引 $\\mathcal{I}^{\\mathrm{qr}}_r$ 计算 EIM 近似 $\\widehat{f}_{\\mathrm{qr}}$。\n4.  计算两种方法的相对误差：\n    $$e_{\\mathrm{loc}}(r,\\mu^\\mathrm{test}_j) = \\frac{\\|f - \\widehat{f}_{\\mathrm{loc}}\\|_2}{\\|f\\|_2}, \\quad e_{\\mathrm{qr}}(r,\\mu^\\mathrm{test}_j) = \\frac{\\|f - \\widehat{f}_{\\mathrm{qr}}\\|_2}{\\|f\\|_2}$$\n\n最后，对于每个秩 $r$，我们计算每种方法在测试集上的平均相对误差 $\\overline{e}_\\mathrm{loc}(r)$ 和 $\\overline{e}_\\mathrm{qr}(r)$。最终输出是这八个值的有序列表。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import qr\n\ndef solve():\n    \"\"\"\n    Implements and compares two EIM point-selection strategies:\n    1. Localized greedy based on elementwise DG residual norms.\n    2. Global pivoted QR decomposition.\n    \"\"\"\n    # 1. Define constants and parameters\n    E = 10\n    n_p = 6\n    M = E * n_p\n    N_train = 24\n    r_max = 12\n    \n    mu_train = np.linspace(0, 1, N_train)\n    mu_test = np.array([0.07, 0.31, 0.58, 0.83])\n    ranks_eval = [1, 4, 8, 12]\n\n    # 2. Generate global node coordinates\n    x_nodes = np.zeros(M)\n    h = 1.0 / E\n    for e in range(E):\n        x_min = e * h\n        for j in range(n_p):\n            x_nodes[e * n_p + j] = x_min + (j + 1) * h / (n_p + 1)\n\n    # 3. Define the state function and nonlinear operator\n    def u_func(x, mu):\n        term1 = np.sin(2 * np.pi * (x + 0.3 * mu))\n        term2 = 0.5 * np.cos(5 * np.pi * (x - 0.2 * mu))\n        term3 = 0.2 * np.exp(-50 * (x - 0.3 - 0.4 * mu)**2)\n        return term1 + term2 + term3\n\n    def N_op(u_val):\n        return u_val**2 + np.exp(u_val)\n\n    # 4. Construct the snapshot matrix\n    S = np.zeros((M, N_train))\n    for k, mu in enumerate(mu_train):\n        u_vals = u_func(x_nodes, mu)\n        S[:, k] = N_op(u_vals)\n\n    # 5. Compute SVD and extract the reduced basis Phi\n    U, _, _ = np.linalg.svd(S, full_matrices=False)\n    Phi = U[:, :r_max]\n\n    # 6. Point Selection Strategy 1: Localized Greedy\n    indices_loc = []\n    for k_idx in range(r_max):\n        phi_k = Phi[:, k_idx]\n        \n        if k_idx == 0:\n            residual = phi_k\n        else:\n            Phi_prev = Phi[:, :k_idx]\n            # Solve (P^T Phi_prev) c = P^T phi_k for coefficients c\n            A = Phi_prev[indices_loc, :]\n            b = phi_k[indices_loc]\n            # Use least-squares for robustness as per problem spec\n            coeffs, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n            phi_hat = Phi_prev @ coeffs\n            residual = phi_k - phi_hat\n        \n        # Compute element-wise residual L2 norms\n        # Reshape residual into (E, n_p) to calculate norm per element\n        res_reshaped = residual.reshape((E, n_p))\n        element_norms = np.linalg.norm(res_reshaped, axis=1)\n        \n        # Find element with the maximum residual norm\n        best_element_idx = np.argmax(element_norms)\n        \n        # Find index within that element that maximizes |residual|\n        start_idx = best_element_idx * n_p\n        end_idx = start_idx + n_p\n        local_max_idx = np.argmax(np.abs(residual[start_idx:end_idx]))\n        new_index = start_idx + local_max_idx\n        \n        indices_loc.append(new_index)\n\n    # 7. Point Selection Strategy 2: Global Pivoted QR\n    # Column-pivoted QR of Phi^T gives a row pivot selection for Phi\n    _, _, p = qr(Phi.T, pivoting=True)\n    indices_qr = p[:r_max]\n\n    # 8. Evaluation Protocol\n    final_results = []\n    for r in ranks_eval:\n        errors_loc = []\n        errors_qr = []\n\n        # Get the basis and index sets for the current rank r\n        Phi_r = Phi[:, :r]\n        I_loc_r = indices_loc[:r]\n        I_qr_r = indices_qr[:r]\n\n        for mu_j in mu_test:\n            # Generate the full-order model output for the test parameter\n            f = N_op(u_func(x_nodes, mu_j))\n            f_norm = np.linalg.norm(f)\n\n            # --- Localized Greedy Method Evaluation ---\n            A_loc = Phi_r[I_loc_r, :]\n            b_loc = f[I_loc_r]\n            coeffs_loc, _, _, _ = np.linalg.lstsq(A_loc, b_loc, rcond=None)\n            f_hat_loc = Phi_r @ coeffs_loc\n            err_loc = np.linalg.norm(f - f_hat_loc) / f_norm\n            errors_loc.append(err_loc)\n\n            # --- Pivoted QR Method Evaluation ---\n            A_qr = Phi_r[I_qr_r, :]\n            b_qr = f[I_qr_r]\n            coeffs_qr, _, _, _ = np.linalg.lstsq(A_qr, b_qr, rcond=None)\n            f_hat_qr = Phi_r @ coeffs_qr\n            err_qr = np.linalg.norm(f - f_hat_qr) / f_norm\n            errors_qr.append(err_qr)\n        \n        # Compute mean errors for rank r and append to results\n        avg_err_loc = np.mean(errors_loc)\n        avg_err_qr = np.mean(errors_qr)\n        final_results.extend([avg_err_loc, avg_err_qr])\n\n    # 9. Print the final results in the specified format\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "任何数据驱动模型（包括 EIM）的性能都从根本上受限于其训练数据的质量。本练习  将我们的重点从插值算法本身转移到快照收集策略上，探讨在训练数据中包含瞬态动力学信息将如何影响模型的泛化能力。通过为两个典型的可压缩流问题构建并测试 EIM 代理模型，你将定量地证明，为何一个丰富多样的快照集对于创建能够在新的、未见过的条件下表现出色的、鲁棒的降阶模型至关重要。",
            "id": "3383626",
            "problem": "考虑用于逼近谱方法和间断伽辽金 (DG) 方法中出现的非线性算子的离散经验插值法 (EIM)。其目标是利用一组训练快照，为一个将离散场映射到离散残差的非线性算子构建一个基于插值的代理模型。您将使用两种典型的流场代理模型来研究包含瞬态快照对未训练马赫数泛化误差的影响，这两种模型分别标记以反映经典的可压缩欧拉方程测试问题：一个熵稳定激波管代理模型和一个等熵涡代理模型。\n\n基本背景包括以下广泛接受的定义和事实：\n- 间断伽辽金 (DG) 方法是一种使用不连续多项式空间的有限元法，对于非线性守恒律，该方法通常采用分裂形式离散化和熵稳定数值通量来控制混叠并确保稳定性。在一维情况下，对于标量场 $u(x)$ 和光滑的测试函数，非线性通量导数在谱网格上表示为将一个离散微分矩阵应用于 $u$ 的非线性函数。\n- 谱方法使用全局基函数并在特殊节点上进行配置。对于整数 $N \\geq 1$，切比雪夫-高斯-洛巴托节点定义为 $x_j = \\cos(\\pi j / N)$，其中 $j = 0, 1, \\dots, N$，这些节点位于 $[-1,1]$ 区间内。与这些节点相关的谱微分矩阵 $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ 的元素为\n$$\nD_{ij} = \\begin{cases}\n\\frac{c_i}{c_j} \\frac{(-1)^{i+j}}{x_i - x_j}, & i \\neq j,\\\\\n-\\frac{x_i}{2(1-x_i^2)}, & 1 \\leq i = j \\leq N-1,\\\\\n\\frac{2N^2+1}{6}, & i=j=0,\\\\\n-\\frac{2N^2+1}{6}, & i=j=N,\n\\end{cases}\n$$\n其中 $c_0 = c_N = 2$，$c_j = 1$ 对于 $1 \\leq j \\leq N-1$。\n- 经验插值法 (EIM) 通过投影到由经验基向量张成的子空间，并强制在选定索引处进行插值来确定系数，从而逼近非线性算子 $\\mathcal{N} : \\mathbb{R}^Q \\rightarrow \\mathbb{R}^Q$。标准的实用程序使用本征正交分解 (POD) 从快照中提取主导模态，并使用离散经验插值法 (DEIM) 贪婪地选择插值索引。给定快照矩阵 $F \\in \\mathbb{R}^{Q \\times S}$ 及其奇异值分解 $F = U \\Sigma V^\\top$，前 $r$ 个左奇异向量 $U_r \\in \\mathbb{R}^{Q \\times r}$ 作为基。DEIM 通过一种贪心算法选择索引 $\\{p_1, \\dots, p_r\\}$，该算法基于将 $U_r$ 的连续投影到先前选择的插值约束上所产生的残差绝对值的最大化。新向量 $f \\in \\mathbb{R}^Q$ 的 EIM 逼近为 $\\hat{f} = U_r c$，其中系数向量 $c \\in \\mathbb{R}^r$ 通过求解方型线性系统 $U_r[P,:] c = f[P]$ 得到，其中 $P = [p_1,\\dots,p_r]$，$U_r[P,:]$ 是这些行对应的子矩阵。\n\n在此问题中，请在切比雪夫-高斯-洛巴托网格上定义两个代理非线性算子：\n\n1.  一维熵稳定激波管代理模型：\n    -   域：$x \\in [-1,1]$，其中 $N_x = 64$，给出 65 个节点。\n    -   马赫数参数：$M \\in \\mathbb{R}_{>0}$。\n    -   时间参数：$t \\in \\mathbb{R}_{\\geq 0}$。\n    -   代理场：\n        $$\n        \\phi_{\\mathrm{shock}}(x; M, t) = \\frac{M}{2} \\left[1 + \\tanh\\!\\left(k(M)\\,(x - s(M)\\,t)\\right)\\right] + 0.05\\,M\\,\\sin(8\\pi x)\\,e^{-t},\n        $$\n        其中 $k(M) = 6M$，$s(M) = \\frac{M}{2}$。增加的衰减高频项用于模拟瞬态内容。\n    -   非线性算子：\n        $$\n        \\mathcal{N}_{\\mathrm{shock}}(M,t) = D \\left(\\frac{\\phi_{\\mathrm{shock}}(\\cdot;M,t)^2}{2}\\right),\n        $$\n        其中 $D$ 是切比雪夫-高斯-洛巴托微分矩阵。\n\n2.  二维等熵涡代理模型：\n    -   域：$(x,y) \\in [-1,1] \\times [-1,1]$，其中 $N_y = 32$，每个坐标有 33 个节点，构成张量积配置网格。\n    -   马赫数参数：$M \\in \\mathbb{R}_{>0}$。\n    -   时间参数：$t \\in \\mathbb{R}_{\\geq 0}$。\n    -   代理场：\n        $$\n        \\phi_{\\mathrm{vortex}}(x,y; M,t) = M\\,\\exp\\!\\left(-\\alpha(M)\\left[(x - v_x(M)\\,t)^2 + (y - v_y(M)\\,t)^2\\right]\\right)\\,\\sin(\\pi x)\\,\\cos(\\pi y) + 0.05\\,M\\,\\sin(6\\pi(x+y))\\,e^{-t},\n        $$\n        其中 $\\alpha(M) = 1 + M$，$v_x(M) = v_y(M) = \\frac{M}{2}$。高斯包络和三角因子模拟了一个带有瞬态高频内容的移动漩涡结构。\n    -   非线性算子：\n        $$\n        \\mathcal{N}_{\\mathrm{vortex}}(M,t) = \\partial_x\\!\\left(\\phi_{\\mathrm{vortex}}^2\\right) + \\partial_y\\!\\left(\\phi_{\\mathrm{vortex}}^2\\right),\n        $$\n        通过在每个坐标上应用一维微分矩阵 $D$ 来计算：如果 $G = \\phi_{\\mathrm{vortex}}^2$ 在张量网格上排列为一个矩阵，则 $\\partial_x(G) = D\\,G$ 和 $\\partial_y(G) = G\\,D^\\top$，然后扁平化为一个向量。\n\n训练策略：\n- 策略 $\\mathrm{S0}$ (稳态主导)：使用训练时间 $t \\in \\{0.3,\\,0.4,\\,0.5\\}$。\n- 策略 $\\mathrm{S1}$ (包含瞬态)：使用训练时间 $t \\in \\{0.05,\\,0.2,\\,0.5\\}$。\n\n对于每种代理模型场景，使用以下训练马赫数：\n- 激波管训练马赫数：$M \\in \\{1.2,\\,2.0\\}$。\n- 涡流训练马赫数：$M \\in \\{0.4,\\,0.8\\}$。\n\n通过连接所有指定 $(M,t)$ 对的列向量 $\\mathcal{N}(M,t)$ 来为每种策略构建快照矩阵。从此矩阵中，构建一个秩为 $r=6$ 的 POD 基（如果奇异值少于6个，则取 $r$ 等于可用的奇异值数量），然后构建 DEIM 插值索引。使用这些为每个场景定义两个 EIM 模型：一个用于 $\\mathrm{S0}$，一个用于 $\\mathrm{S1}$。\n\n为未经训练的马赫数 $M^\\star$ 和时间 $t^\\star$ 定义泛化误差为相对欧几里得范数误差\n$$\n\\epsilon(M^\\star, t^\\star) = \\frac{\\left\\| \\mathcal{N}(M^\\star,t^\\star) - \\widehat{\\mathcal{N}}(M^\\star,t^\\star)\\right\\|_2}{\\left\\|\\mathcal{N}(M^\\star,t^\\star)\\right\\|_2},\n$$\n其中 $\\widehat{\\mathcal{N}}$ 是使用所选策略的 EIM 重构。\n\n测试套件：\n- 激波管测试 (一维):\n  1. 未经训练的马赫数 $M^\\star = 1.6$ 在 $t^\\star = 0.15$。\n  2. 未经训练的马赫数 $M^\\star = 3.0$ 在 $t^\\star = 0.15$ (较高马赫数的边缘情况)。\n- 等熵涡测试 (二维):\n  3. 未经训练的马赫数 $M^\\star = 0.6$ 在 $t^\\star = 0.15$。\n  4. 未经训练的马赫数 $M^\\star = 0.2$ 在 $t^\\star = 0.15$ (较低马赫数的边缘情况)。\n\n对于每个测试案例，计算改进量\n$$\n\\Delta = \\epsilon_{\\mathrm{S0}}(M^\\star, t^\\star) - \\epsilon_{\\mathrm{S1}}(M^\\star, t^\\star),\n$$\n这是一个实数。按指定顺序报告所有四个改进量。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果（例如，\"[result1,result2,result3,result4]\"）。由于所有量都是无量纲的，因此不涉及角度，也不需要物理单位。\n\n请严格按以下设置实现：\n- 使用指定的切比雪夫-高斯-洛巴托节点和微分矩阵。\n- 在一维中使用 $N_x = 64$，在二维中每个坐标使用 $N_y = 32$。\n- 使用所述的训练时间和马赫数。\n- 对两种策略均使用 POD 秩 $r=6$，如果可用快照少于6个，则截断为快照数量。\n\n最终输出必须是四个浮点数改进量 $\\Delta$ 的列表，顺序遵循测试套件：激波管在 $M^\\star=1.6$、激波管在 $M^\\star=3.0$、涡流在 $M^\\star=0.6$、涡流在 $M^\\star=0.2$。",
            "solution": "用户提供了一个问题，要求实现和比较应用于流体动力学模拟中产生的非线性算子的两种经验插值法 (EIM) 训练策略。该问题定义明确，科学上合理，且数值上易于处理。所有必要的定义、参数和步骤都已指定。因此，该问题被认为是有效的。\n\n解决方案首先实现必要的数学构造，然后构建指定的 EIM 模型，最后在给定的测试案例上评估其性能，以计算所要求的改进度量。\n\n### 步骤1：数学和算法预备\n\n所需的核心组件是切比雪夫-高斯-洛巴托 (CGL) 节点及相关的谱微分矩阵、代理非线性算子以及本征正交分解-离散经验插值法 (POD-DEIM) 算法。\n\n**切比雪夫-高斯-洛巴托网格和微分矩阵**\n\n对于多项式次数 $N$，在区间 $[-1, 1]$ 上的 $N+1$ 个 CGL 节点由以下公式给出：\n$$\nx_j = \\cos\\left(\\frac{\\pi j}{N}\\right), \\quad j = 0, 1, \\dots, N\n$$\n在这些节点上能精确微分最高 $N$ 次多项式的谱微分矩阵 $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ 由其元素 $D_{ij}$ 定义。对于 $i \\neq j$：\n$$\nD_{ij} = \\frac{c_i}{c_j} \\frac{(-1)^{i+j}}{x_i - x_j}\n$$\n其中 $c_0 = c_N = 2$，$c_j = 1$ 对于 $1 \\leq j \\leq N-1$。对角线元素为：\n$$\nD_{jj} = \\begin{cases}\n\\frac{2N^2+1}{6},  & j=0, \\\\\n-\\frac{x_j}{2(1-x_j^2)},  & 1 \\leq j \\leq N-1, \\\\\n-\\frac{2N^2+1}{6},  & j=N.\n\\end{cases}\n$$\n对于一维激波管问题，将为 $N=N_x=64$ 构建此矩阵；对于二维涡流问题，将为 $N=N_y=32$ 构建此矩阵。\n\n### 步骤2：代理非线性算子\n\n在这些谱网格上定义了两个典型的非线性算子。\n\n**1. 一维激波管代理模型 ($\\mathcal{N}_{\\mathrm{shock}}$)**\n代理场 $\\phi_{\\mathrm{shock}}$ 在具有 $N_x=64$ 的一维 CGL 网格上进行评估，得到一个长度为 $Q = N_x+1 = 65$ 的向量。该场由下式给出：\n$$\n\\phi_{\\mathrm{shock}}(x; M, t) = \\frac{M}{2} \\left[1 + \\tanh\\left(k(M)(x - s(M)t)\\right)\\right] + 0.05 M \\sin(8\\pi x) e^{-t}\n$$\n其中 $k(M) = 6M$，$s(M) = M/2$。非线性算子将微分矩阵应用于表示通量 $f(\\phi) = \\phi^2/2$ 的向量：\n$$\n\\mathcal{N}_{\\mathrm{shock}}(M,t) = D \\left(\\frac{\\phi_{\\mathrm{shock}}(\\cdot; M,t)^2}{2}\\right)\n$$\n这里的平方和除法是在场值向量上逐元素执行的。\n\n**2. 二维等熵涡代理模型 ($\\mathcal{N}_{\\mathrm{vortex}}$)**\n代理场 $\\phi_{\\mathrm{vortex}}$ 在每个维度具有 $N_y=32$ 的二维张量积 CGL 网格上进行评估，得到一个 $(N_y+1) \\times (N_y+1) = 33 \\times 33$ 的点网格。总自由度数为 $Q = 33^2 = 1089$。该场为：\n$$\n\\phi_{\\mathrm{vortex}}(x,y; M,t) = M e^{-\\alpha(M)((x - v_x(M)t)^2 + (y - v_y(M)t)^2)}\\sin(\\pi x)\\cos(\\pi y) + 0.05 M \\sin(6\\pi(x+y))e^{-t}\n$$\n其中 $\\alpha(M) = 1+M$，$v_x(M) = v_y(M) = M/2$。非线性算子是二次通量的离散散度：\n$$\n\\mathcal{N}_{\\mathrm{vortex}}(M,t) = \\partial_x(\\phi_{\\mathrm{vortex}}^2) + \\partial_y(\\phi_{\\mathrm{vortex}}^2)\n$$\n令 $G$ 为网格上 $\\phi_{\\mathrm{vortex}}^2$ 值的矩阵，偏导数通过与一维微分矩阵 $D$（大小为 $33 \\times 33$）的矩阵乘法来计算。根据问题的明确指示，我们计算 $\\partial_x G = D G$ 和 $\\partial_y G = G D^\\top$。结果相加并扁平化为一个长度为 $Q=1089$ 的向量。\n\n### 步骤3：POD-DEIM 模型构建\n\n对于给定的场景（激波或涡流）和训练策略（S0 或 S1），EIM 模型的构建如下：\n\n1.  **快照收集**：对策略指定的每对训练马赫数 $M$ 和时间 $t$ 评估非线性算子 $\\mathcal{N}(M, t)$。结果向量作为快照矩阵 $F \\in \\mathbb{R}^{Q \\times S}$ 的列进行收集，其中 $S$ 是快照数量（在此问题中 $S=6$）。\n2.  **POD 基生成**：计算快照矩阵的奇异值分解 (SVD)：$F = U \\Sigma V^\\top$。选择左奇异向量矩阵 $U$ 的前 $r=6$ 列作为 POD 基，记作 $U_r \\in \\mathbb{R}^{Q \\times r}$。\n3.  **DEIM 索引选择**：使用离散经验插值法 (DEIM) 选择 $r$ 个插值索引 $P = \\{p_1, \\dots, p_r\\}$。这是一个贪心算法：\n    *   第一个索引 $p_1$ 被选为第一个基向量 $u_1$ 绝对值最大值的位置。\n    *   对于 $k=2, \\dots, r$，第 $k$ 个基向量 $u_k$ 通过其在前 $k-1$ 个基向量张成的空间上的投影来逼近，系数由在先前选择的索引 $\\{p_1, \\dots, p_{k-1}\\}$ 处的插值确定。计算此逼近的残差，并选择新的索引 $p_k$ 作为该残差绝对值最大值的位置。\n    此过程产生一组 $r$ 个索引 $P$。\n\nEIM 模型由对 $(U_r, P)$ 定义。\n\n### 步骤4：EIM 逼近与误差评估\n\n对于未经训练的参数集，给定一个新的状态向量 $f_{\\mathrm{new}} = \\mathcal{N}(M^\\star, t^\\star)$，计算 EIM 逼近 $\\hat{f}_{\\mathrm{new}}$。\n\n1.  **逼近**：逼近为 $\\hat{f}_{\\mathrm{new}} = U_r c$，其中系数向量 $c \\in \\mathbb{R}^r$ 通过求解强制在 DEIM 索引处插值的小型方型线性系统得到：\n    $$\n    (U_r)_{P,:} c = (f_{\\mathrm{new}})_P\n    $$\n    这里，$(U_r)_{P,:}$ 是通过选择 $U_r$ 中与 $P$ 中索引对应的行形成的 $r \\times r$ 矩阵，而 $(f_{\\mathrm{new}})_P$ 是通过选择 $f_{\\mathrm{new}}$ 的相应条目形成的向量。\n2.  **误差计算**：给定策略的泛化误差是真实算子输出与 EIM 逼近之差的相对欧几里得范数：\n    $$\n    \\epsilon(M^\\star, t^\\star) = \\frac{\\| \\mathcal{N}(M^\\star, t^\\star) - \\widehat{\\mathcal{N}}(M^\\star, t^\\star) \\|_2}{\\| \\mathcal{N}(M^\\star, t^\\star) \\|_2}\n    $$\n3.  **改进度量**：最终感兴趣的量是包含瞬态的策略 (S1) 相对于稳态主导的策略 (S0) 的改进，通过它们误差的差异来衡量：\n    $$\n    \\Delta = \\epsilon_{\\mathrm{S0}}(M^\\star, t^\\star) - \\epsilon_{\\mathrm{S1}}(M^\\star, t^\\star)\n    $$\n\n对问题陈述中指定的四个测试案例中的每一个都执行此过程。预期的结果是 $\\Delta > 0$，这表明策略 S1（在训练期间接触了瞬态动力学）为瞬态测试案例提供了更好的逼近。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\n# This solution was executed with numpy==1.23.5 and scipy==1.11.4\n\ndef get_chebyshev_diff_matrix(N: int) -> np.ndarray:\n    \"\"\"\n    Computes the Chebyshev spectral differentiation matrix for N+1\n    Chebyshev-Gauss-Lobatto nodes.\n    \"\"\"\n    if N == 0:\n        return np.zeros((1, 1))\n    \n    x = np.cos(np.pi * np.arange(N + 1) / N)\n    D = np.zeros((N + 1, N + 1))\n    \n    c = np.ones(N + 1)\n    c[0] = 2.0\n    c[N] = 2.0\n\n    for i in range(N + 1):\n        for j in range(N + 1):\n            if i == j:\n                if i == 0:\n                    D[i, j] = (2 * N**2 + 1) / 6.0\n                elif i == N:\n                    D[i, j] = -(2 * N**2 + 1) / 6.0\n                else:\n                    D[i, j] = -x[j] / (2 * (1 - x[j]**2))\n            else:\n                D[i, j] = (c[i] / c[j]) * ((-1)**(i + j)) / (x[i] - x[j])\n    return D\n\ndef deim(U: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Performs the Discrete Empirical Interpolation Method (DEIM) to select\n    interpolation indices given a basis U.\n    \"\"\"\n    Q, r = U.shape\n    P = np.zeros(r, dtype=int)\n    \n    # First point\n    p1_idx = np.argmax(np.abs(U[:, 0]))\n    P[0] = p1_idx\n    \n    for k in range(1, r):\n        u_k = U[:, k]\n        \n        # Solve for coefficients\n        U_P_k_minus_1 = U[P[:k], :k]\n        u_k_P = u_k[P[:k]]\n        \n        try:\n            coeffs = linalg.solve(U_P_k_minus_1, u_k_P)\n        except linalg.LinAlgError:\n            # Fallback to pseudo-inverse if matrix is singular.\n            # This can happen if basis vectors are nearly linearly dependent at selected points.\n            coeffs = linalg.lstsq(U_P_k_minus_1, u_k_P)[0]\n\n        # Compute residual\n        residual = u_k - U[:, :k] @ coeffs\n        \n        # Select next point\n        p_k_idx = np.argmax(np.abs(residual))\n        P[k] = p_k_idx\n        \n    return P\n\ndef shock_phi(x: np.ndarray, M: float, t: float) -> np.ndarray:\n    k = 6.0 * M\n    s = M / 2.0\n    phi = M / 2.0 * (1.0 + np.tanh(k * (x - s * t))) + 0.05 * M * np.sin(8.0 * np.pi * x) * np.exp(-t)\n    return phi\n\ndef shock_op(M: float, t: float, D: np.ndarray, x: np.ndarray) -> np.ndarray:\n    phi = shock_phi(x, M, t)\n    flux = 0.5 * phi**2\n    return D @ flux\n\ndef vortex_phi(X: np.ndarray, Y: np.ndarray, M: float, t: float) -> np.ndarray:\n    alpha = 1.0 + M\n    v_x = v_y = M / 2.0\n    term1 = M * np.exp(-alpha * ((X - v_x * t)**2 + (Y - v_y * t)**2)) * np.sin(np.pi * X) * np.cos(np.pi * Y)\n    term2 = 0.05 * M * np.sin(6.0 * np.pi * (X + Y)) * np.exp(-t)\n    return term1 + term2\n\ndef vortex_op(M: float, t: float, D: np.ndarray, X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n    phi_grid = vortex_phi(X, Y, M, t)\n    G = phi_grid**2\n    # Per problem statement: d_x(G) = D G, d_y(G) = G D^T\n    dG_dx = D @ G\n    dG_dy = G @ D.T\n    op_grid = dG_dx + dG_dy\n    return op_grid.ravel()\n\ndef build_eim_model(scenario: str, strategy: str, params: dict):\n    \"\"\"\n    Builds the POD-DEIM model for a given scenario and strategy.\n    \"\"\"\n    r = params['r']\n    train_times = params['train_times'][strategy]\n    train_machs = params['train_machs'][scenario]\n\n    snapshots = []\n    if scenario == 'shock':\n        N = params['N_shock']\n        D = params['D_shock']\n        x = params['x_shock']\n        for M_train in train_machs:\n            for t_train in train_times:\n                snapshot = shock_op(M_train, t_train, D, x)\n                snapshots.append(snapshot)\n    elif scenario == 'vortex':\n        N = params['N_vortex']\n        D = params['D_vortex']\n        X, Y = params['grid_vortex']\n        for M_train in train_machs:\n            for t_train in train_times:\n                snapshot = vortex_op(M_train, t_train, D, X, Y)\n                snapshots.append(snapshot)\n    \n    F = np.array(snapshots).T\n    \n    # POD basis\n    U, s, Vt = linalg.svd(F, full_matrices=False)\n    num_snaps = F.shape[1]\n    rank = min(r, num_snaps, len(s)) # Use at most r basis vectors\n    U_r = U[:, :rank]\n    \n    # DEIM indices\n    P = deim(U_r)\n    \n    return U_r, P\n\ndef apply_eim_model(f: np.ndarray, U_r: np.ndarray, P: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Applies the EIM model to approximate a vector f.\n    \"\"\"\n    U_r_P = U_r[P, :]\n    f_P = f[P]\n    \n    try:\n        c = linalg.solve(U_r_P, f_P)\n    except linalg.LinAlgError:\n        c = linalg.lstsq(U_r_P, f_P)[0]\n    \n    f_hat = U_r @ c\n    return f_hat\n\ndef calculate_error(f, f_hat):\n    \"\"\"Computes the relative L2 error.\"\"\"\n    norm_f = linalg.norm(f)\n    if norm_f == 0:\n        return 0.0 if linalg.norm(f_hat) == 0 else 1.0\n    return linalg.norm(f - f_hat) / norm_f\n\ndef solve():\n    params = {\n        'N_shock': 64,\n        'N_vortex': 32,\n        'r': 6,\n        'train_times': {\n            'S0': [0.3, 0.4, 0.5],\n            'S1': [0.05, 0.2, 0.5]\n        },\n        'train_machs': {\n            'shock': [1.2, 2.0],\n            'vortex': [0.4, 0.8]\n        },\n        'test_cases': [\n            {'scenario': 'shock', 'M_star': 1.6, 't_star': 0.15},\n            {'scenario': 'shock', 'M_star': 3.0, 't_star': 0.15},\n            {'scenario': 'vortex', 'M_star': 0.6, 't_star': 0.15},\n            {'scenario': 'vortex', 'M_star': 0.2, 't_star': 0.15},\n        ]\n    }\n\n    # Pre-compute shared data\n    N_shock = params['N_shock']\n    params['D_shock'] = get_chebyshev_diff_matrix(N_shock)\n    params['x_shock'] = np.cos(np.pi * np.arange(N_shock + 1) / N_shock)\n    \n    N_vortex = params['N_vortex']\n    params['D_vortex'] = get_chebyshev_diff_matrix(N_vortex)\n    vortex_nodes = np.cos(np.pi * np.arange(N_vortex + 1) / N_vortex)\n    params['grid_vortex'] = np.meshgrid(vortex_nodes, vortex_nodes)\n\n    results = []\n    \n    # Group tests by scenario to avoid re-building models\n    all_scenarios = ['shock', 'vortex']\n    \n    # The order of tests in the problem statement is:\n    # 1. shock, M=1.6\n    # 2. shock, M=3.0\n    # 3. vortex, M=0.6\n    # 4. vortex, M=0.2\n    \n    test_case_order = [\n        ('shock', 1.6), ('shock', 3.0),\n        ('vortex', 0.6), ('vortex', 0.2)\n    ]\n\n    for scenario, M_star in test_case_order:\n        # Get the t_star for this test\n        t_star = 0.15\n\n        # Build models for the scenario\n        U_r_s0, P_s0 = build_eim_model(scenario, 'S0', params)\n        U_r_s1, P_s1 = build_eim_model(scenario, 'S1', params)\n\n        # Generate true solution\n        if scenario == 'shock':\n            f_true = shock_op(M_star, t_star, params['D_shock'], params['x_shock'])\n        else: # vortex\n            f_true = vortex_op(M_star, t_star, params['D_vortex'], *params['grid_vortex'])\n\n        # Apply S0 model and get error\n        f_hat_s0 = apply_eim_model(f_true, U_r_s0, P_s0)\n        eps_s0 = calculate_error(f_true, f_hat_s0)\n        \n        # Apply S1 model and get error\n        f_hat_s1 = apply_eim_model(f_true, U_r_s1, P_s1)\n        eps_s1 = calculate_error(f_true, f_hat_s1)\n        \n        # Calculate improvement\n        delta = eps_s0 - eps_s1\n        results.append(delta)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}