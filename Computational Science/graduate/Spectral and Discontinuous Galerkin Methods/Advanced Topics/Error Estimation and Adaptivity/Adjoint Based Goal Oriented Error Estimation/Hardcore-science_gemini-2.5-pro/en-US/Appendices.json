{
    "hands_on_practices": [
        {
            "introduction": "This first practice builds the foundation for understanding adjoint-based error analysis by examining a simple, stationary diffusion problem. By deriving the error representation from first principles, you will see how the choice of Discontinuous Galerkin (DG) formulation directly impacts the structure of the error estimate . This exercise highlights the concept of dual consistency and reveals how a symmetric scheme can simplify the error representation, a key insight for developing more accurate estimators.",
            "id": "3362379",
            "problem": "Consider the one-dimensional linear diffusion equation on the periodic interval $\\Omega = (0,1)$,\n$$\n- u'' = f \\quad \\text{in } \\Omega, \\qquad u \\text{ is $1$-periodic,}\n$$\nwith a real-valued, sufficiently smooth source $f$. Let the goal functional be\n$$\nJ(u) = \\int_{0}^{1} u(x)\\,\\psi(x)\\,dx,\n$$\nwith $\\psi \\in C^{\\infty}(\\Omega)$ of zero mean so that the periodic adjoint $z$ exists and is unique up to an additive constant fixed by the zero-mean condition. The continuous adjoint problem is\n$$\n- z'' = \\psi \\quad \\text{in } \\Omega, \\qquad z \\text{ is $1$-periodic and has zero mean.}\n$$\nDiscretize the primal problem using the interior penalty discontinuous Galerkin (DG) method on a uniform mesh $\\mathcal{T}_h$ with elements of size $h$, with a discontinuous polynomial space of degree $p \\ge 1$. On each interior face $e \\in \\mathcal{E}_h$, denote by $[v] = v^{+} - v^{-}$ the jump and by $\\{v\\} = \\tfrac{1}{2}(v^{+} + v^{-})$ the average, where $v^{\\pm}$ are traces from the right/left elements. Consider the family of interior penalty bilinear forms parameterized by a symmetry parameter $\\theta \\in \\mathbb{R}$ and a penalty magnitude $\\gamma > 0$,\n$$\na_h(w,v) = \\sum_{K \\in \\mathcal{T}_h} \\int_{K} w'(x)\\,v'(x)\\,dx \\;-\\; \\sum_{e \\in \\mathcal{E}_h} \\left( \\{w'\\}[v] + \\theta\\,\\{v'\\}[w] \\right) \\;+\\; \\sum_{e \\in \\mathcal{E}_h} \\frac{\\gamma}{h}\\,[w]\\,[v].\n$$\nThe symmetric interior penalty Galerkin (SIPG), non-symmetric interior penalty Galerkin (NIPG), and incomplete interior penalty Galerkin (IIPG) methods correspond, respectively, to $\\theta = 1$, $\\theta = -1$, and $\\theta = 0$, with the same penalty magnitude $\\gamma > 0$. The discrete primal solution $u_h \\in V_h$ satisfies $a_h(u_h,v_h) = \\int_{0}^{1} f\\,v_h\\,dx$ for all $v_h \\in V_h$.\n\nStarting only from the definitions above, use the periodic adjoint $z$ (a smooth function, so that $[z] = 0$ and $[z'] = 0$ on interior faces) to derive a representation for the goal error $J(u) - J(u_h)$ that isolates the adjoint-weighted face-jump contribution proportional to $\\sum_{e \\in \\mathcal{E}_h} \\{z'\\}\\,[u_h]$. Show that the coefficient multiplying this contribution has the form $c(\\theta)$, independent of $\\gamma$, and determine the value of $\\theta$ that minimizes the magnitude of this adjoint-weighted jump contribution over all $\\theta \\in \\mathbb{R}$ (in particular, over the common variants $\\theta \\in \\{ -1, 0, 1 \\}$). Express your final answer as the single value of $\\theta$ that minimizes this coefficient. No rounding is required, and no physical units are involved. Report only the minimizing $\\theta$ value.",
            "solution": "We begin with the definition of the goal error, where $\\varepsilon(x) = u(x) - u_h(x)$ is the solution error:\n$$\nJ(u) - J(u_h) = \\int_0^1 \\varepsilon(x) \\psi(x) dx\n$$\nUsing the adjoint equation, $-z'' = \\psi$, and integrating by parts twice over each element $K \\in \\mathcal{T}_h$, we obtain an error representation involving the discontinuous error function $\\varepsilon$ and the smooth adjoint solution $z$:\n$$\nJ(u) - J(u_h) = \\sum_{K \\in \\mathcal{T}_h} \\int_K \\varepsilon' z' dx - \\sum_{e \\in \\mathcal{E}_h} \\{\\varepsilon'\\} [z] - \\sum_{e \\in \\mathcal{E}_h} [\\varepsilon] \\{z'\\}\n$$\nSince the adjoint solution $z$ is smooth, its jump across any face is zero, $[z] = 0$. The error representation simplifies to:\n$$\nJ(u) - J(u_h) = \\sum_{K \\in \\mathcal{T}_h} \\int_K \\varepsilon' z' dx - \\sum_{e \\in \\mathcal{E}_h} [\\varepsilon] \\{z'\\}\n$$\nNext, we use the definition of the DG bilinear form $a_h(w,v)$. We evaluate $a_h(\\varepsilon, z)$. Since $z$ is smooth, $[z]=0$, and the form simplifies to:\n$$\na_h(\\varepsilon, z) = \\sum_{K \\in \\mathcal{T}_h} \\int_K \\varepsilon' z' dx - \\theta \\sum_{e \\in \\mathcal{E}_h} \\{z'\\} [\\varepsilon]\n$$\nRearranging this gives an expression for the integral term in our error representation:\n$$\n\\sum_{K \\in \\mathcal{T}_h} \\int_K \\varepsilon' z' dx = a_h(\\varepsilon, z) + \\theta \\sum_{e \\in \\mathcal{E}_h} \\{z'\\} [\\varepsilon]\n$$\nSubstituting this back into the error representation yields:\n$$\nJ(u) - J(u_h) = \\left( a_h(\\varepsilon, z) + \\theta \\sum_{e \\in \\mathcal{E}_h} \\{z'\\} [\\varepsilon] \\right) - \\sum_{e \\in \\mathcal{E}_h} [\\varepsilon] \\{z'\\} = a_h(\\varepsilon, z) + (\\theta-1) \\sum_{e \\in \\mathcal{E}_h} \\{z'\\} [\\varepsilon]\n$$\nSince the exact solution $u$ is smooth, its jump is zero, so $[\\varepsilon] = [u - u_h] = -[u_h]$. The error representation becomes:\n$$\nJ(u) - J(u_h) = a_h(u-u_h, z) + (1-\\theta) \\sum_{e \\in \\mathcal{E}_h} \\{z'\\} [u_h]\n$$\nThe problem asks to find the value of $\\theta$ that minimizes the magnitude of the contribution from the term $\\sum_{e \\in \\mathcal{E}_h} \\{z'\\}\\,[u_h]$. The coefficient of this term is $c(\\theta) = 1-\\theta$. To minimize its magnitude, $|1-\\theta|$, we must choose $\\theta$ such that $1-\\theta=0$.\nTherefore, the minimizing value is $\\theta=1$. This corresponds to the Symmetric Interior Penalty Galerkin (SIPG) method, for which this particular term in the error expansion vanishes, a property known as dual consistency for this term.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "We now transition from stationary problems to time-dependent phenomena, a common scenario in physics and engineering. This exercise uses a linear advection equation where the adjoint solution is constant, allowing us to isolate the effect of practical numerical components like slope limiters . Through a blend of theoretical analysis and coding, you will quantify how standard stabilization techniques can interfere with the goal-oriented error estimator and learn to design a simple, \"adjoint-aware\" modification to preserve its accuracy.",
            "id": "3362322",
            "problem": "Consider the scalar conservation law $u_t + \\left(f(u)\\right)_x = 0$ on the one-dimensional domain $\\Omega = [0,1]$, with constant advection speed $a > 0$ and flux $f(u) = a\\,u$, equipped with inflow boundary condition $u(0,t) = u_{\\mathrm{in}}(t)$ and outflow at $x = 1$. Let the goal functional be $J\\left(u(T)\\right) = \\int_{0}^{1} u(x,T)\\,dx$. Work with a one-step explicit update from time $t^n$ to $t^{n+1} = t^n + \\Delta t$, using a piecewise-linear Discontinuous Galerkin (DG) method of polynomial degree one on a uniform mesh of $N$ cells of size $\\Delta x = 1/N$, and an upwind numerical flux at all faces consistent with $a > 0$.\n\nYou must:\n\n1. Derive, starting from the conservation law, the DG weak form with upwind flux for the semi-discrete scheme, and then the adjoint equation associated with the goal functional $J\\left(u(T)\\right)$. Demonstrate that the adjoint field $\\phi(x,t)$ entering the dual-weighted residual is constant in space and time for $f(u) = a\\,u$ and the specified $J\\left(u(T)\\right)$.\n\n2. Using the dual-weighted residual framework for a goal-oriented a posteriori error estimate over the single update from $t^n$ to $t^{n+1}$, show how the interior contributions telescope and that the leading-order estimator depends only on the inflow and outflow face contributions for the constant adjoint weight. Express the estimator in terms of the left trace at the outflow boundary and the inflow boundary value.\n\n3. Analyze the effect of slope limiters that act only on the intra-cell slope while preserving the cell average. Explain qualitatively and quantitatively how such limiters perturb the adjoint-based estimator through their modification of the outflow face trace. Then propose a slope limiter design that preserves the dual residual to leading order for $J\\left(u\\right) = \\int_{\\Omega} u\\,dx$. Your design must:\n   - Preserve cell averages exactly.\n   - Modify intra-cell slopes in a way that keeps the outflow face trace unchanged to leading order relative to the unlimited reconstruction.\n\n4. Implement a program that constructs the piecewise-linear representation $u_h(x)$ per cell with:\n   - Cell average $\\bar u_i$ computed by numerical quadrature of a given continuous initial field $u(x)$ over each cell.\n   - An unlimited slope $s_i$ computed from the neighboring cell averages via centered or one-sided differences.\n   - A classical minmod limiter applied to the slopes to obtain $s_i^{\\mathrm{mm}}$.\n   - Your proposed adjoint-preserving limiter producing slopes $s_i^{\\mathrm{adj}}$ that maintain the outflow face trace at $x=1$ to leading order while keeping $\\bar u_i$ unchanged.\n\nUse the upwind numerical flux $F_{i+1/2} = a\\,u^-_{i+1/2}$ at interior faces with $a>0$, where $u^-_{i+1/2}$ is the left trace reconstructed from cell $i$. At the inflow boundary $x=0$, set $F_{1-1/2} = a\\,u_{\\mathrm{in}}^n$, with $u_{\\mathrm{in}}^n$ taken from the continuous initial field at $x=0$. At the outflow boundary $x=1$, use $F_{N+1/2} = a\\,u^-_{N+1/2}$ reconstructed from the last cell. Define one update with time step $\\Delta t = \\mathrm{CFL} \\cdot \\Delta x/a$, where $\\mathrm{CFL} = 0.3$.\n\nCompute the adjoint-based goal-oriented error estimate over this single update for three slope choices: unlimited slopes $s_i$, minmod-limited slopes $s_i^{\\mathrm{mm}}$, and adjoint-preserving slopes $s_i^{\\mathrm{adj}}$. The estimator must be derived from the dual-weighted residual using the constant adjoint weight and must be expressed in terms of the boundary flux difference over the time step.\n\nYour program must evaluate the estimator for the following test suite of initial fields and parameters:\n- Test Case A (smooth, happy path): $a = 1.0$, $N = 50$, $u(x) = \\sin\\left(2\\pi x\\right)$, $u_{\\mathrm{in}}^n = u(0)$.\n- Test Case B (discontinuity, limiter activation): $a = 1.0$, $N = 80$, $u(x) = \\begin{cases} 1, & x < 0.7 \\\\ 0, & x \\ge 0.7 \\end{cases}$, $u_{\\mathrm{in}}^n = u(0)$.\n- Test Case C (sharp localized feature): $a = 2.0$, $N = 60$, $u(x) = \\exp\\left(-100\\,(x - 0.5)^2\\right)$, $u_{\\mathrm{in}}^n = u(0)$.\n\nAdopt dimensionless units throughout, since the quantities involved are pure numbers in this setting.\n\nFinal Output Specification:\n- Your program should produce a single line of output containing the nine results as a comma-separated list enclosed in square brackets, in the order:\n  $[\\text{A}_{\\mathrm{unlim}}, \\text{A}_{\\mathrm{mm}}, \\text{A}_{\\mathrm{adj}}, \\text{B}_{\\mathrm{unlim}}, \\text{B}_{\\mathrm{mm}}, \\text{B}_{\\mathrm{adj}}, \\text{C}_{\\mathrm{unlim}}, \\text{C}_{\\mathrm{mm}}, \\text{C}_{\\mathrm{adj}}]$,\n  where each entry is the adjoint-based estimator for the respective case and slope choice, expressed as a float.",
            "solution": "1.  **DG Weak Form and Adjoint Equation**:\n    Starting from $u_t + (au)_x = 0$, multiplying by a test function $v_h \\in V_h$, integrating over an element $K_i$, and applying integration by parts gives the semi-discrete DG form:\n    $$ \\frac{d}{dt}\\int_{K_i} u_h v_h \\,dx - \\int_{K_i} a u_h v_h' \\,dx + [a u_h v_h]_{x_{i-1/2}}^{x_{i+1/2}} = 0 $$\n    Replacing the flux at faces with an upwind numerical flux $F(u^-, u^+) = a u^-$ (for $a>0$) and summing over all elements yields the global semi-discrete system.\n    The continuous adjoint equation for the goal $J(u(T)) = \\int_0^1 u(x,T)dx$ is found by requiring $\\int_0^T\\int_0^1 (u_t+au_x)\\phi \\,dx\\,dt=0$. Integration by parts leads to the adjoint PDE $\\phi_t + a\\phi_x = 0$ with terminal condition $\\phi(x,T) = 1$ and inflow boundary condition $\\phi(1,t)=1$. The unique solution to this problem is $\\phi(x,t) = 1$ for all $(x,t)$.\n\n2.  **Error Estimator**:\n    The dual-weighted residual error over one time step $[t^n, t^{n+1}]$ is $\\eta = \\int_{t^n}^{t^{n+1}} \\mathcal{R}(u_h^n; \\phi) dt$. With $\\phi=1$ and an explicit Euler time step, the residual is integrated over the space-time slab. The DG scheme is locally conservative, meaning $\\frac{1}{\\Delta t}\\int_{K_i}(u_h^{n+1}-u_h^n)dx = -(F^n_{i+1/2}-F^n_{i-1/2})$. Summing over all elements, the change in the total integral is governed by the boundary fluxes:\n    $$ \\frac{J(u_h^{n+1}) - J(u_h^n)}{\\Delta t} = -(F^n_{N+1/2} - F^n_{1/2}) $$\n    The exact solution satisfies $\\frac{dJ(u)}{dt} = -(a u(1,t) - a u(0,t))$. The error estimator for one time step is the difference between the numerical and exact flux balances, which simplifies to the net flux error at the boundaries, weighted by $\\Delta t$:\n    $$ \\eta \\approx \\Delta t ( (a u_{in}^n) - (a u_h^-(1,t^n)) ) = a \\Delta t (u_{in}^n - u_h^-(1,t^n)) $$\n    where $u_h^-(1,t^n)$ is the reconstructed value at the outflow boundary from the last cell.\n\n3.  **Slope Limiter Analysis and Design**:\n    The reconstructed outflow value is $u_h^-(1,t^n) = \\bar{u}_N^n + s_N^n \\frac{\\Delta x}{2}$. A slope limiter replaces the unlimited slope $s_N^n$ with a limited slope $s_N^{\\lim,n}$. This directly changes the value of the error estimator $\\eta$. To preserve the estimator to leading order, we must ensure the limited slope in the final cell, $s_N^{\\lim,n}$, remains equal to the unlimited slope, $s_N^n$.\n    Our proposed **adjoint-preserving limiter** design is:\n    - Apply a standard limiter (e.g., minmod) to all interior cells $i = 1, \\dots, N-1$.\n    - For the final cell, $i=N$, do not apply the limiter; use the original, unlimited slope. This ensures that the outflow trace, and thus the estimator $\\eta$, is unchanged by the limiting procedure.\n\n4.  **Implementation**: The provided Python code implements the logic described. It computes cell averages, three sets of slopes (unlimited, minmod, and our adjoint-preserving design), and then evaluates the estimator $\\eta$ for each combination of test case and slope set.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to compute adjoint-based goal-oriented error estimates for three different\n    slope limiting strategies across three test cases for a 1D linear advection equation.\n    \"\"\"\n    CFL = 0.3\n\n    test_cases = [\n        # Test Case A (smooth)\n        {'a': 1.0, 'N': 50, 'u_func': lambda x: np.sin(2 * np.pi * x)},\n        # Test Case B (discontinuity)\n        {'a': 1.0, 'N': 80, 'u_func': lambda x: np.where(x < 0.7, 1.0, 0.0)},\n        # Test Case C (sharp feature)\n        {'a': 2.0, 'N': 60, 'u_func': lambda x: np.exp(-100 * (x - 0.5)**2)},\n    ]\n\n    results = []\n\n    def minmod(a, b):\n        \"\"\"Standard minmod limiter function.\"\"\"\n        return 0.5 * (np.sign(a) + np.sign(b)) * np.minimum(np.abs(a), np.abs(b))\n\n    for case in test_cases:\n        a = case['a']\n        N = case['N']\n        u_initial = case['u_func']\n\n        # Setup mesh\n        dx = 1.0 / N\n        x_faces = np.linspace(0, 1, N + 1)\n        x_centers = x_faces[:-1] + dx / 2.0\n\n        # Compute cell averages by high-resolution numerical quadrature (100 points per cell)\n        u_bar = np.zeros(N)\n        for i in range(N):\n            quad_points = np.linspace(x_faces[i], x_faces[i+1], 100)\n            u_bar[i] = np.mean(u_initial(quad_points))\n\n        # 1. Compute unlimited slopes\n        s_unlim = np.zeros(N)\n        # One-sided differences at boundaries\n        s_unlim[0] = (u_bar[1] - u_bar[0]) / dx\n        s_unlim[-1] = (u_bar[-1] - u_bar[-2]) / dx\n        # Centered differences for interior\n        for i in range(1, N - 1):\n            s_unlim[i] = (u_bar[i+1] - u_bar[i-1]) / (2 * dx)\n\n        # 2. Compute minmod-limited slopes\n        s_mm = np.zeros(N)\n        # Use unlimited slopes at boundaries as limiters are mainly for interior\n        s_mm[0] = s_unlim[0]\n        s_mm[-1] = s_unlim[-1]\n        # Apply minmod limiter to interior slopes\n        for i in range(1, N - 1):\n            delta_plus = (u_bar[i+1] - u_bar[i]) / dx\n            delta_minus = (u_bar[i] - u_bar[i-1]) / dx\n            # Here we limit the original centered slope against the one-sided slopes\n            # for a more robust version, but classic form is common.\n            # A simpler, common TVD choice is to directly use the minmod of the one-sided differences.\n            s_mm[i] = minmod(delta_plus, delta_minus)\n        \n        # 3. Compute adjoint-preserving slopes\n        s_adj = np.copy(s_mm)\n        # Restore the unlimited slope in the last cell\n        s_adj[-1] = s_unlim[-1]\n        \n        # Calculate time step and estimator for each slope set\n        dt = CFL * dx / a\n        u_in = u_initial(0.0)\n\n        slope_sets = [s_unlim, s_mm, s_adj]\n        \n        for slopes in slope_sets:\n            # Reconstructed value at outflow boundary x=1 from cell N\n            u_outflow_trace = u_bar[-1] + slopes[-1] * (dx / 2.0)\n            \n            # Adjoint-based error estimator\n            estimator = a * dt * (u_in - u_outflow_trace)\n            results.append(estimator)\n\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\n\nsolve()\n```"
        },
        {
            "introduction": "This final practice advances to systems of partial differential equations, which model complex phenomena like fluid dynamics. You will investigate the crucial concept of \"adjoint consistency,\" a property ensuring that the discrete adjoint problem correctly approximates its continuous counterpart . By analyzing numerical fluxes for the linearized Euler equations, you will learn to identify and quantify the \"adjoint-consistency defect\" and understand its practical consequences for accurately estimating important engineering quantities like aerodynamic drag.",
            "id": "3362346",
            "problem": "Consider the two-dimensional linearized Euler equations written in primitive variables for small perturbations about a uniform base state. Let the perturbation vector be $q = [\\rho, u, v, p]^{\\top}$, where $\\rho$ is density, $u$ is the velocity component in the $x$ direction, $v$ is the velocity component in the $y$ direction, and $p$ is pressure. The base state is $(\\rho_0, u_0, v_0, p_0)$, with constant ratio of specific heats $\\gamma$. The linearized system, valid for small perturbations and uniform base state, can be written as\n$$\n\\partial_t q + A_x \\,\\partial_x q + A_y \\,\\partial_y q = 0,\n$$\nwhere\n$$\nA_x = \\begin{bmatrix}\nu_0 & \\rho_0 & 0 & 0 \\\\\n0 & u_0 & 0 & \\dfrac{1}{\\rho_0} \\\\\n0 & 0 & u_0 & 0 \\\\\n0 & \\gamma p_0 & 0 & u_0\n\\end{bmatrix}, \\quad\nA_y = \\begin{bmatrix}\nv_0 & 0 & \\rho_0 & 0 \\\\\n0 & v_0 & 0 & 0 \\\\\n0 & 0 & v_0 & \\dfrac{1}{\\rho_0} \\\\\n0 & 0 & \\gamma p_0 & v_0\n\\end{bmatrix}.\n$$\nFor a face with unit normal $n = (n_x,n_y)$, define\n$$\nA_n = n_x A_x + n_y A_y.\n$$\nYou will consider the discontinuous Galerkin (DG) method for this linear system. The DG interface term requires a numerical flux $\\widehat{F}(q^{-},q^{+},n)$ that is consistent and conservative, where $q^{-}$ and $q^{+}$ are the interior and exterior traces on the face. For a linear system, the numerical flux induces a bilinear form that depends on the Jacobian matrices of $\\widehat{F}$ with respect to its arguments. Denote the Jacobian of the flux with respect to the interior state by\n$$\nM = \\frac{\\partial \\widehat{F}}{\\partial q^{-}}(q^{-},q^{+},n).\n$$\n\nIn adjoint-based goal-oriented error estimation, one considers the adjoint equation associated with a chosen functional. Here, focus on the drag functional\n$$\nJ(q) = \\int_{\\Gamma} \\left(p\\,n_x - \\rho\\,u\\,v\\,n_y\\right)\\,ds,\n$$\ndefined on a boundary portion $\\Gamma$, with $n$ the outward unit normal. Linearizing $J$ around the uniform base state $(\\rho_0,u_0,v_0,p_0)$ yields the first variation\n$$\n\\delta J = \\int_{\\Gamma} g(n)^{\\top} \\,\\delta q \\, ds,\n$$\nwhere the boundary sensitivity vector $g(n) \\in \\mathbb{R}^4$ is\n$$\ng(n) = \\begin{bmatrix}\n-\\,u_0\\,v_0\\,n_y \\\\\n-\\,\\rho_0\\,v_0\\,n_y \\\\\n-\\,\\rho_0\\,u_0\\,n_y \\\\\nn_x\n\\end{bmatrix}.\n$$\nThe adjoint equation for the linearized system is $\\partial_t \\varphi + A_x^{\\top} \\partial_x \\varphi + A_y^{\\top} \\partial_y \\varphi = 0$, with adjoint boundary data consistent with $g(n)$ on $\\Gamma$. For adjoint consistency of the DG discretization, the numerical flux used for the primal problem must induce an adjoint numerical flux whose Jacobian with respect to the interior adjoint state $\\varphi^{-}$ satisfies\n$$\nM = \\left( M_{\\text{adj}} \\right)^{\\top}, \\quad \\text{where} \\quad M_{\\text{adj}} = \\frac{\\partial \\widehat{F}_{\\text{adj}}}{\\partial \\varphi^{-}}(\\varphi^{-},\\varphi^{+},n),\n$$\nand $\\widehat{F}_{\\text{adj}}$ is the numerical flux applied to the adjoint operator with matrices $A_x^{\\top}$ and $A_y^{\\top}$.\n\nTwo common choices of linear numerical flux are:\n\n1. Exact matrix upwind flux based on spectral decomposition:\n$$\n\\widehat{F}(q^{-},q^{+},n) = A_n^{+} q^{-} + A_n^{-} q^{+}, \\quad A_n^{\\pm} = S \\Lambda^{\\pm} S^{-1}, \\quad \\Lambda^{\\pm} = \\operatorname{diag}\\big(\\max(\\lambda_i,0),\\min(\\lambda_i,0)\\big),\n$$\nwhere $A_n = S \\Lambda S^{-1}$ is a diagonalization with eigenvalues $\\lambda_i$ and eigenvectors $S$.\n\n2. Local Lax–Friedrichs (Rusanov) flux:\n$$\n\\widehat{F}(q^{-},q^{+},n) = \\frac{1}{2}\\left(A_n (q^{-}+q^{+}) - \\alpha (q^{+}-q^{-})\\right),\n$$\nwhere $\\alpha \\ge \\rho(A_n)$ is any bound on the spectral radius of $A_n$.\n\nFor the adjoint operator, one may define the adjoint numerical flux similarly by substituting $A_n^{\\top}$ and possibly an adjoint parameter $\\alpha_{\\text{adj}}$. The scheme is adjoint-consistent if $M = (M_{\\text{adj}})^{\\top}$, which holds for the exact matrix upwind flux provided the splitting is done using the true eigendecomposition, and for the local Lax–Friedrichs flux provided $\\alpha_{\\text{adj}} = \\alpha$.\n\nTask:\n\n1. Derive from first principles the matrices $A_x$ and $A_y$ above based on the linearization of the Euler equations about a uniform base state, and the boundary sensitivity vector $g(n)$ for the functional $J$.\n\n2. Derive the adjoint consistency condition $M = (M_{\\text{adj}})^{\\top}$ and verify that:\n   - For the exact matrix upwind flux, $M = A_n^{+}$ and $M_{\\text{adj}} = (A_n^{\\top})^{+}$, and adjoint consistency holds.\n   - For the local Lax–Friedrichs flux, $M = \\dfrac{1}{2}\\left(A_n + \\alpha I\\right)$ and $M_{\\text{adj}} = \\dfrac{1}{2}\\left(A_n^{\\top} + \\alpha_{\\text{adj}} I\\right)$, so adjoint consistency requires $\\alpha_{\\text{adj}} = \\alpha$.\n\n3. Implement a program that, for specified base state parameters, constructs $A_x$, $A_y$, and evaluates the adjoint-consistency defect\n$$\n\\Delta(n,\\text{flux},\\alpha,\\alpha_{\\text{adj}}) = \\left\\| M - (M_{\\text{adj}})^{\\top} \\right\\|_F,\n$$\nwhere $\\|\\cdot\\|_F$ denotes the Frobenius norm. Also compute a functional-weighted sensitivity magnitude\n$$\nS(n,\\text{flux},\\alpha,\\alpha_{\\text{adj}}) = \\left\\| \\left( M - (M_{\\text{adj}})^{\\top} \\right)^{\\top} g(n) \\right\\|_2,\n$$\nwhich measures how the inconsistency affects the drag functional linearization; here $\\|\\cdot\\|_2$ is the Euclidean norm.\n\nUse the following physically reasonable base state constants in the International System of Units (SI units):\n$$\n\\gamma = 1.4, \\quad \\rho_0 = 1.0 \\ \\text{kg/m}^3, \\quad p_0 = 10^5 \\ \\text{Pa}, \\quad u_0 = 300 \\ \\text{m/s}, \\quad v_0 = 50 \\ \\text{m/s}.\n$$\nDefine the speed of sound $a = \\sqrt{\\gamma p_0 / \\rho_0}$ only if needed for interpretation; the numerical tasks below use $A_x$ and $A_y$ directly.\n\nTest Suite:\n\nEvaluate $(\\Delta,S)$ for the following four test cases, which probe different normals and flux choices:\n\n- Case 1 (happy path): $n = \\left(\\dfrac{1}{\\sqrt{2}}, \\dfrac{1}{\\sqrt{2}}\\right)$, exact matrix upwind flux; this should give adjoint-consistency defect near zero.\n- Case 2 (baseline consistency): $n = (1,0)$, local Lax–Friedrichs flux with $\\alpha$ equal to the spectral radius of $A_n$ and $\\alpha_{\\text{adj}} = \\alpha$; this should give defect near zero.\n- Case 3 (inconsistency, mild): $n = (0,1)$, local Lax–Friedrichs flux with $\\alpha$ equal to the spectral radius of $A_n$ and $\\alpha_{\\text{adj}} = 0.5\\,\\alpha$; this should exhibit a nonzero defect.\n- Case 4 (inconsistency, strong): $n = \\left(\\dfrac{1}{\\sqrt{2}}, \\dfrac{1}{\\sqrt{2}}\\right)$, local Lax–Friedrichs flux with $\\alpha$ equal to spectral radius and $\\alpha_{\\text{adj}} = 2\\,\\alpha$; this should exhibit a larger defect.\n\nFinal Output Format:\n\nYour program should produce a single line of output containing the eight floating-point results aggregated for all four test cases in order, with each case contributing two numbers $(\\Delta,S)$, flattened into one list. The required format is a single comma-separated list enclosed in square brackets, for example\n$$\n[\\Delta_1,S_1,\\Delta_2,S_2,\\Delta_3,S_3,\\Delta_4,S_4].\n$$\nNo angles are used in the output; the reported values are dimensionless norms. The program must be fully self-contained and require no user input.",
            "solution": "1.  **Derivations**:\n    The system matrices $A_x$ and $A_y$ are derived by linearizing the compressible Euler equations in primitive variables $(\\rho, u, v, p)$ around a uniform base state $(\\rho_0, u_0, v_0, p_0)$, and keeping only first-order terms. For example, the linearized continuity equation $\\partial_t \\rho + u_0 \\partial_x \\rho + v_0 \\partial_y \\rho + \\rho_0(\\partial_x u + \\partial_y v) = 0$ gives the first row of the matrices.\n    The drag functional $J(q) = \\int_{\\Gamma} (p\\,n_x - \\rho\\,u\\,v\\,n_y)\\,ds$ is linearized by substituting $p \\to p_0+p'$, etc., and collecting first-order perturbation terms. The term $-\\rho u v n_y$ linearizes to $-(\\rho_0 u_0 v_0 + \\rho' u_0 v_0 + \\rho_0 u' v_0 + \\rho_0 u_0 v')n_y$. Collecting all such terms gives the variation $\\delta J = \\int_{\\Gamma} g(n)^{\\top} q' \\, ds$, from which the vector $g(n)$ can be identified as given in the problem.\n\n2.  **Adjoint Consistency Condition**:\n    The condition $M = (M_{\\text{adj}})^{\\top}$ ensures that the discrete adjoint operator is a consistent discretization of the continuous adjoint operator.\n    - **Exact Matrix Upwind Flux**: Here, $M = A_n^{+}$ and $M_{\\text{adj}} = (A_n^{\\top})^{+}$. The condition becomes $A_n^{+} = ((A_n^{\\top})^{+})^{\\top}$. Using the spectral decomposition $A_n = S \\Lambda S^{-1}$ and the property that the eigenvalues of $A_n$ and $A_n^\\top$ are the same, this identity can be shown to hold exactly, proving the flux is adjoint-consistent.\n    - **Local Lax–Friedrichs Flux**: Here, $M = \\frac{1}{2}(A_n + \\alpha I)$ and $M_{\\text{adj}} = \\frac{1}{2}(A_n^{\\top} + \\alpha_{\\text{adj}} I)$. The condition $M = (M_{\\text{adj}})^{\\top}$ becomes $\\frac{1}{2}(A_n + \\alpha I) = (\\frac{1}{2}(A_n^{\\top} + \\alpha_{\\text{adj}} I))^{\\top} = \\frac{1}{2}(A_n + \\alpha_{\\text{adj}} I)$. This equality holds if and only if $\\alpha = \\alpha_{\\text{adj}}$.\n\n3.  **Numerical Implementation**: The provided Python code numerically evaluates the adjoint-consistency defect for the specified cases.\n    - It first constructs the matrices $A_x$, $A_y$ and the vector $g(n)$ from the base state parameters.\n    - For each test case, it computes the matrix $A_n$ for the given normal $n$.\n    - For the upwind flux, it computes $M$ and $M_{\\text{adj}}$ using spectral decomposition (`numpy.linalg.eig`) and finds their difference.\n    - For the LLF flux, it computes $M$ and $(M_{\\text{adj}})^{\\top}$ using the algebraic formulas derived above with the specified $\\alpha$ and $\\alpha_{\\text{adj}}$. The spectral radius $\\alpha$ is calculated from the known eigenvalues of the linearized Euler system.\n    - Finally, it computes the Frobenius norm of the defect matrix $\\Delta = \\| M - (M_{\\text{adj}})^{\\top} \\|_F$ and the functional-weighted sensitivity $S = \\| (M - (M_{\\text{adj}})^{\\top})^{\\top} g(n) \\|_2$ and prints the results.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating adjoint-consistency defects for the\n    linearized Euler equations under different numerical flux choices.\n    \"\"\"\n    # Base state parameters (SI units)\n    gamma = 1.4\n    rho_0 = 1.0\n    p_0 = 1e5\n    u_0 = 300.0\n    v_0 = 50.0\n\n    # Construct system matrices Ax and Ay\n    A_x = np.array([\n        [u_0, rho_0, 0, 0],\n        [0, u_0, 0, 1.0/rho_0],\n        [0, 0, u_0, 0],\n        [0, gamma*p_0, 0, u_0]\n    ])\n    A_y = np.array([\n        [v_0, 0, rho_0, 0],\n        [0, v_0, 0, 0],\n        [0, 0, v_0, 1.0/rho_0],\n        [0, 0, gamma*p_0, v_0]\n    ])\n\n    test_cases = [\n        # Case 1: Exact upwind, n=(1/sqrt(2), 1/sqrt(2))\n        (np.array([1.0/np.sqrt(2), 1.0/np.sqrt(2)]), 'upwind', None),\n        # Case 2: LLF, n=(1,0), alpha_adj = alpha\n        (np.array([1.0, 0.0]), 'llf', 1.0),\n        # Case 3: LLF, n=(0,1), alpha_adj = 0.5*alpha\n        (np.array([0.0, 1.0]), 'llf', 0.5),\n        # Case 4: LLF, n=(1/sqrt(2), 1/sqrt(2)), alpha_adj = 2.0*alpha\n        (np.array([1.0/np.sqrt(2), 1.0/np.sqrt(2)]), 'llf', 2.0),\n    ]\n\n    results = []\n\n    for n, flux_type, alpha_adj_factor in test_cases:\n        n_x, n_y = n\n        \n        # Form the flux Jacobian An\n        A_n = n_x * A_x + n_y * A_y\n        \n        # Form the boundary sensitivity vector g(n)\n        g_n = np.array([\n            -u_0 * v_0 * n_y,\n            -rho_0 * v_0 * n_y,\n            -rho_0 * u_0 * n_y,\n            n_x\n        ])\n\n        if flux_type == 'upwind':\n            \n            def get_positive_part(A):\n                \"\"\"Computes the positive part of a matrix via spectral decomposition.\"\"\"\n                eigvals, S = np.linalg.eig(A)\n                S_inv = np.linalg.inv(S)\n                # For hyperbolic systems, eigenvalues are real. Use .real to handle potential small imaginary parts from numerics.\n                Lambda_plus = np.diag(np.maximum(eigvals.real, 0))\n                return S @ Lambda_plus @ S_inv\n\n            # Primal flux Jacobian M\n            M = get_positive_part(A_n)\n            \n            # Adjoint flux Jacobian Madj\n            M_adj = get_positive_part(A_n.T)\n            \n            # Defect matrix D\n            D = M - M_adj.T\n            \n        elif flux_type == 'llf':\n            # Speed of sound squared\n            a0_sq = gamma * p_0 / rho_0\n            a0 = np.sqrt(a0_sq)\n            \n            # Convective velocity in normal direction\n            V_n = u_0 * n_x + v_0 * n_y\n            \n            # Eigenvalues of An are V_n, V_n, V_n-a0, V_n+a0\n            eigvals_An = np.array([V_n, V_n, V_n - a0, V_n + a0])\n            \n            # Primal stabilization parameter alpha\n            alpha = np.max(np.abs(eigvals_An))\n            \n            # Adjoint stabilization parameter alpha_adj\n            alpha_adj = alpha * alpha_adj_factor\n            \n            I = np.identity(4)\n            \n            # Primal flux Jacobian M\n            M = 0.5 * (A_n + alpha * I)\n            \n            # Transpose of adjoint flux Jacobian (M_adj)^T\n            M_adj_T = 0.5 * (A_n + alpha_adj * I)\n            \n            # Defect matrix D\n            D = M - M_adj_T\n        \n        # Calculate consistency defect Delta (Frobenius norm)\n        delta = np.linalg.norm(D, 'fro')\n        \n        # Calculate functional-weighted sensitivity S (Euclidean norm)\n        s_val = np.linalg.norm(D.T @ g_n)\n        \n        results.extend([delta, s_val])\n\n    # Format and print the final output\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}