{
    "hands_on_practices": [
        {
            "introduction": "The accuracy of a goal-oriented error estimate hinges on the principle of dual consistency, which ensures that the numerical scheme does not introduce spurious terms into the adjoint-weighted error representation. This foundational exercise guides you through the analytical derivation of the error in a quantity of interest for a Discontinuous Galerkin (DG) discretization of a simple diffusion problem. By manipulating the primal and adjoint equations, you will see precisely how the choice of numerical flux formulation impacts the error estimate and discover which variant is optimal from the perspective of the adjoint problem .",
            "id": "3362379",
            "problem": "Consider the one-dimensional linear diffusion equation on the periodic interval $\\Omega = (0,1)$,\n$$\n- u'' = f \\quad \\text{in } \\Omega, \\qquad u \\text{ is $1$-periodic,}\n$$\nwith a real-valued, sufficiently smooth source $f$. Let the goal functional be\n$$\nJ(u) = \\int_{0}^{1} u(x)\\,\\psi(x)\\,dx,\n$$\nwith $\\psi \\in C^{\\infty}(\\Omega)$ of zero mean so that the periodic adjoint $z$ exists and is unique up to an additive constant fixed by the zero-mean condition. The continuous adjoint problem is\n$$\n- z'' = \\psi \\quad \\text{in } \\Omega, \\qquad z \\text{ is $1$-periodic and has zero mean.}\n$$\nDiscretize the primal problem using the interior penalty discontinuous Galerkin (DG) method on a uniform mesh $\\mathcal{T}_h$ with elements of size $h$, with a discontinuous polynomial space of degree $p \\ge 1$. On each interior face $e \\in \\mathcal{E}_h$, denote by $[v] = v^{+} - v^{-}$ the jump and by $\\{v\\} = \\tfrac{1}{2}(v^{+} + v^{-})$ the average, where $v^{\\pm}$ are traces from the right/left elements. Consider the family of interior penalty bilinear forms parameterized by a symmetry parameter $\\theta \\in \\mathbb{R}$ and a penalty magnitude $\\gamma > 0$,\n$$\na_h(w,v) = \\sum_{K \\in \\mathcal{T}_h} \\int_{K} w'(x)\\,v'(x)\\,dx \\;-\\; \\sum_{e \\in \\mathcal{E}_h} \\left( \\{w'\\}[v] + \\theta\\,\\{v'\\}[w] \\right) \\;+\\; \\sum_{e \\in \\mathcal{E}_h} \\frac{\\gamma}{h}\\,[w]\\,[v].\n$$\nThe symmetric interior penalty Galerkin (SIPG), non-symmetric interior penalty Galerkin (NIPG), and incomplete interior penalty Galerkin (IIPG) methods correspond, respectively, to $\\theta = 1$, $\\theta = -1$, and $\\theta = 0$, with the same penalty magnitude $\\gamma > 0$. The discrete primal solution $u_h \\in V_h$ satisfies $a_h(u_h,v_h) = \\int_{0}^{1} f\\,v_h\\,dx$ for all $v_h \\in V_h$.\n\nStarting only from the definitions above, use the periodic adjoint $z$ (a smooth function, so that $[z] = 0$ and $[z'] = 0$ on interior faces) to derive a representation for the goal error $J(u) - J(u_h)$ that isolates the adjoint-weighted face-jump contribution proportional to $\\sum_{e \\in \\mathcal{E}_h} \\{z'\\}\\,[u_h]$. Show that the coefficient multiplying this contribution has the form $c(\\theta)$, independent of $\\gamma$, and determine the value of $\\theta$ that minimizes the magnitude of this adjoint-weighted jump contribution over all $\\theta \\in \\mathbb{R}$ (in particular, over the common variants $\\theta \\in \\{ -1, 0, 1 \\}$). Express your final answer as the single value of $\\theta$ that minimizes this coefficient. No rounding is required, and no physical units are involved. Report only the minimizing $\\theta$ value.",
            "solution": "The user wants me to derive a specific error representation for a discontinuous Galerkin (DG) method and use it to find a parameter value.\n\n### Step 1: Problem Validation\n\nThe problem is a well-defined mathematical exercise in the field of numerical analysis, specifically concerning adjoint-based error estimation for discontinuous Galerkin methods.\n\n-   **Givens**:\n    -   Primal Problem: $-u''(x) = f(x)$ for $x \\in \\Omega = (0,1)$, with $u$ being $1$-periodic. $f$ is smooth.\n    -   Goal Functional: $J(u) = \\int_{0}^{1} u(x)\\psi(x) dx$, where $\\psi \\in C^{\\infty}(\\Omega)$ has zero mean.\n    -   Adjoint Problem: $-z''(x) = \\psi(x)$ for $x \\in \\Omega$, with $z$ being $1$-periodic and having zero mean. $z$ is smooth, implying $[z]=0$ and $[z']=0$ on interior faces.\n    -   DG Bilinear Form: $a_h(w,v) = \\sum_{K \\in \\mathcal{T}_h} \\int_{K} w'v'\\,dx - \\sum_{e \\in \\mathcal{E}_h} (\\{w'\\} [v] + \\theta\\{v'\\} [w]) + \\sum_{e \\in \\mathcal{E}_h} \\frac{\\gamma}{h} [w][v]$.\n    -   DG Primal Solution: $u_h \\in V_h$ satisfies $a_h(u_h, v_h) = \\int_{0}^{1} f v_h dx$ for all $v_h \\in V_h$.\n\n-   **Validation Verdict**: The problem is scientifically grounded, well-posed, and objective. It is a standard exercise in the theory of DG methods. All terms are clearly defined, and the premises are consistent. The problem is **valid**.\n\n### Step 2: Derivation of the Error Representation\n\nThe goal is to derive a representation for the error in the functional, $J(u) - J(u_h)$. Let $\\varepsilon(x) = u(x) - u_h(x)$ denote the error in the solution.\n\nThe error in the goal functional is given by its definition:\n$$\nJ(u) - J(u_h) = \\int_{0}^{1} (u(x) - u_h(x)) \\psi(x) dx = \\int_{0}^{1} \\varepsilon(x) \\psi(x) dx\n$$\nWe use the definition of the adjoint problem, $-z''(x) = \\psi(x)$, to substitute for $\\psi(x)$:\n$$\nJ(u) - J(u_h) = \\int_{0}^{1} \\varepsilon(x) (-z''(x)) dx\n$$\nWe split the integral over the elements $K$ of the mesh $\\mathcal{T}_h$ and apply integration by parts to each integral:\n$$\n\\begin{align*} J(u) - J(u_h) &= \\sum_{K \\in \\mathcal{T}_h} \\int_{K} \\varepsilon(x) (-z''(x)) dx \\\\ &= \\sum_{K \\in \\mathcal{T}_h} \\left( \\int_{K} \\varepsilon'(x) z'(x) dx - [\\varepsilon(x) z'(x)]_{\\partial K} \\right) \\end{align*}\n$$\nwhere $[\\cdot]_{\\partial K}$ denotes the evaluation at the boundary of element $K$. Summing the boundary terms over all elements results in a sum over all interior faces $e \\in \\mathcal{E}_h$. Due to the periodicity, boundary terms at $x=0$ and $x=1$ cancel. The sum over faces is given by:\n$$\n\\sum_{K \\in \\mathcal{T}_h} [\\varepsilon(x) z'(x)]_{\\partial K} = \\sum_{e \\in \\mathcal{E}_h} [\\varepsilon z']_e\n$$\nwhere $[\\cdot]_e$ denotes the jump across face $e$. We use the product rule for jumps, $[ab] = \\{a\\}[b] + [a]\\{b\\}$:\n$$\n[\\varepsilon z']_e = \\{\\varepsilon\\}_e [z']_e + [\\varepsilon]_e \\{z'\\}_e\n$$\nThe problem states that the adjoint solution $z$ is smooth, which implies its trace and its derivative's trace are continuous across element faces. Thus, $[z]_e = 0$ and $[z']_e = 0$ for all $e \\in \\mathcal{E}_h$. The jump term simplifies to:\n$$\n[\\varepsilon z']_e = [\\varepsilon]_e \\{z'\\}_e\n$$\nSubstituting this back into the error expression, we get:\n$$\nJ(u) - J(u_h) = \\sum_{K \\in \\mathcal{T}_h} \\int_{K} \\varepsilon'(x) z'(x) dx - \\sum_{e \\in \\mathcal{E}_h} [\\varepsilon]_e \\{z'\\}_e\n$$\n\nNow, we must relate the first term, $\\sum_{K \\in \\mathcal{T}_h} \\int_{K} \\varepsilon'(x) z'(x) dx$, to the bilinear form $a_h(\\cdot, \\cdot)$. We can formally evaluate the bilinear form $a_h(\\varepsilon, z)$ by inserting the error function $\\varepsilon$ (which is discontinuous) and the smooth adjoint solution $z$:\n$$\na_h(\\varepsilon, z) = \\sum_{K \\in \\mathcal{T}_h} \\int_{K} \\varepsilon'z'\\,dx - \\sum_{e \\in \\mathcal{E}_h} ( \\{\\varepsilon'\\}[z] + \\theta\\{z'\\}[\\varepsilon] ) + \\sum_{e \\in \\mathcal{E}_h} \\frac{\\gamma}{h}[\\varepsilon][z]\n$$\nSince $z$ is smooth, its jump is zero, $[z]_e = 0$. The expression simplifies to:\n$$\na_h(\\varepsilon, z) = \\sum_{K \\in \\mathcal{T}_h} \\int_{K} \\varepsilon'z'\\,dx - \\sum_{e \\in \\mathcal{E}_h} \\theta\\{z'\\}[\\varepsilon]\n$$\nRearranging this equation gives a representation for the integral term:\n$$\n\\sum_{K \\in \\mathcal{T}_h} \\int_{K} \\varepsilon'(x) z'(x) dx = a_h(\\varepsilon, z) + \\theta \\sum_{e \\in \\mathcal{E}_h} \\{z'\\}[\\varepsilon]\n$$\nNow, substitute this into our expression for the goal error:\n$$\n\\begin{align*} J(u) - J(u_h) &= \\left( a_h(\\varepsilon, z) + \\theta \\sum_{e \\in \\mathcal{E}_h} \\{z'\\}[\\varepsilon] \\right) - \\sum_{e \\in \\mathcal{E}_h} [\\varepsilon]_e \\{z'\\}_e \\\\ &= a_h(\\varepsilon, z) + (\\theta - 1) \\sum_{e \\in \\mathcal{E}_h} \\{z'\\}[\\varepsilon] \\end{align*}\n$$\nFinally, we express the jump of the error, $[\\varepsilon]_e$, in terms of the jump of the discrete solution, $[u_h]_e$. Since the exact solution $u$ is smooth, its jump is zero, $[u]_e=0$.\n$$\n[\\varepsilon]_e = [u - u_h]_e = [u]_e - [u_h]_e = 0 - [u_h]_e = -[u_h]_e\n$$\nSubstituting this into the error representation yields:\n$$\nJ(u) - J(u_h) = a_h(u - u_h, z) - (\\theta - 1) \\sum_{e \\in \\mathcal{E}_h} \\{z'\\} [u_h]\n$$\n$$\nJ(u) - J(u_h) = a_h(u - u_h, z) + (1 - \\theta) \\sum_{e \\in \\mathcal{E}_h} \\{z'\\} [u_h]\n$$\nThis is the desired error representation, which isolates the contribution proportional to $\\sum_{e \\in \\mathcal{E}_h} \\{z'\\}\\,[u_h]$. The coefficient multiplying this contribution is:\n$$\nc(\\theta) = 1 - \\theta\n$$\nThis coefficient is independent of the penalty parameter $\\gamma$, as required.\n\n### Step 3: Minimization of the Contribution\n\nThe problem asks for the value of $\\theta \\in \\mathbb{R}$ that minimizes the magnitude of this adjoint-weighted jump contribution. This is equivalent to minimizing the magnitude of its coefficient, $|c(\\theta)|$.\n$$\n\\min_{\\theta \\in \\mathbb{R}} |c(\\theta)| = \\min_{\\theta \\in \\mathbb{R}} |1 - \\theta|\n$$\nThe absolute value function $|1 - \\theta|$ is non-negative, and its minimum value is $0$. This minimum is achieved when the argument is zero:\n$$\n1 - \\theta = 0 \\implies \\theta = 1\n$$\nThis value corresponds to the Symmetric Interior Penalty Galerkin (SIPG) method. For $\\theta=1$, this particular term in the error representation vanishes.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Moving from pure theory to computational practice, we now explore how components of a numerical solver, designed to enhance stability, can interact with the error estimation process. This exercise focuses on a scalar conservation law where slope limiters are often necessary to prevent non-physical oscillations. Through a combination of theoretical analysis and coding, you will investigate how a standard slope limiter can inadvertently corrupt the adjoint-based error estimate and design a modified limiter that preserves the integrity of the dual-weighted residual .",
            "id": "3362322",
            "problem": "Consider the scalar conservation law $u_t + \\left(f(u)\\right)_x = 0$ on the one-dimensional domain $\\Omega = [0,1]$, with constant advection speed $a > 0$ and flux $f(u) = a\\,u$, equipped with inflow boundary condition $u(0,t) = u_{\\mathrm{in}}(t)$ and outflow at $x = 1$. Let the goal functional be $J\\left(u(T)\\right) = \\int_{0}^{1} u(x,T)\\,dx$. Work with a one-step explicit update from time $t^n$ to $t^{n+1} = t^n + \\Delta t$, using a piecewise-linear Discontinuous Galerkin (DG) method of polynomial degree one on a uniform mesh of $N$ cells of size $\\Delta x = 1/N$, and an upwind numerical flux at all faces consistent with $a > 0$.\n\nYou must:\n\n1. Derive, starting from the conservation law, the DG weak form with upwind flux for the semi-discrete scheme, and then the adjoint equation associated with the goal functional $J\\left(u(T)\\right)$. Demonstrate that the adjoint field $\\phi(x,t)$ entering the dual-weighted residual is constant in space and time for $f(u) = a\\,u$ and the specified $J\\left(u(T)\\right)$.\n\n2. Using the dual-weighted residual framework for a goal-oriented a posteriori error estimate over the single update from $t^n$ to $t^{n+1}$, show how the interior contributions telescope and that the leading-order estimator depends only on the inflow and outflow face contributions for the constant adjoint weight. Express the estimator in terms of the left trace at the outflow boundary and the inflow boundary value.\n\n3. Analyze the effect of slope limiters that act only on the intra-cell slope while preserving the cell average. Explain qualitatively and quantitatively how such limiters perturb the adjoint-based estimator through their modification of the outflow face trace. Then propose a slope limiter design that preserves the dual residual to leading order for $J\\left(u\\right) = \\int_{\\Omega} u\\,dx$. Your design must:\n   - Preserve cell averages exactly.\n   - Modify intra-cell slopes in a way that keeps the outflow face trace unchanged to leading order relative to the unlimited reconstruction.\n\n4. Implement a program that constructs the piecewise-linear representation $u_h(x)$ per cell with:\n   - Cell average $\\bar u_i$ computed by numerical quadrature of a given continuous initial field $u(x)$ over each cell.\n   - An unlimited slope $s_i$ computed from the neighboring cell averages via centered or one-sided differences.\n   - A classical minmod limiter applied to the slopes to obtain $s_i^{\\mathrm{mm}}$.\n   - Your proposed adjoint-preserving limiter producing slopes $s_i^{\\mathrm{adj}}$ that maintain the outflow face trace at $x=1$ to leading order while keeping $\\bar u_i$ unchanged.\n\nUse the upwind numerical flux $F_{i+1/2} = a\\,u^-_{i+1/2}$ at interior faces with $a>0$, where $u^-_{i+1/2}$ is the left trace reconstructed from cell $i$. At the inflow boundary $x=0$, set $F_{1-1/2} = a\\,u_{\\mathrm{in}}^n$, with $u_{\\mathrm{in}}^n$ taken from the continuous initial field at $x=0$. At the outflow boundary $x=1$, use $F_{N+1/2} = a\\,u^-_{N+1/2}$ reconstructed from the last cell. Define one update with time step $\\Delta t = \\mathrm{CFL} \\cdot \\Delta x/a$, where $\\mathrm{CFL} = 0.3$.\n\nCompute the adjoint-based goal-oriented error estimate over this single update for three slope choices: unlimited slopes $s_i$, minmod-limited slopes $s_i^{\\mathrm{mm}}$, and adjoint-preserving slopes $s_i^{\\mathrm{adj}}$. The estimator must be derived from the dual-weighted residual using the constant adjoint weight and must be expressed in terms of the boundary flux difference over the time step.\n\nYour program must evaluate the estimator for the following test suite of initial fields and parameters:\n- Test Case A (smooth, happy path): $a = 1.0$, $N = 50$, $u(x) = \\sin\\left(2\\pi x\\right)$, $u_{\\mathrm{in}}^n = u(0)$.\n- Test Case B (discontinuity, limiter activation): $a = 1.0$, $N = 80$, $u(x) = \\begin{cases} 1, & x < 0.7 \\\\ 0, & x \\ge 0.7 \\end{cases}$, $u_{\\mathrm{in}}^n = u(0)$.\n- Test Case C (sharp localized feature): $a = 2.0$, $N = 60$, $u(x) = \\exp\\left(-100\\,(x - 0.5)^2\\right)$, $u_{\\mathrm{in}}^n = u(0)$.\n\nAdopt dimensionless units throughout, since the quantities involved are pure numbers in this setting.\n\nFinal Output Specification:\n- Your program should produce a single line of output containing the nine results as a comma-separated list enclosed in square brackets, in the order:\n  $[\\text{A}_{\\mathrm{unlim}}, \\text{A}_{\\mathrm{mm}}, \\text{A}_{\\mathrm{adj}}, \\text{B}_{\\mathrm{unlim}}, \\text{B}_{\\mathrm{mm}}, \\text{B}_{\\mathrm{adj}}, \\text{C}_{\\mathrm{unlim}}, \\text{C}_{\\mathrm{mm}}, \\text{C}_{\\mathrm{adj}}]$,\n  where each entry is the adjoint-based estimator for the respective case and slope choice, expressed as a float.",
            "solution": "The problem requires a multi-part theoretical derivation and a numerical implementation concerning adjoint-based goal-oriented error estimation for a Discontinuous Galerkin (DG) method applied to a scalar linear advection equation.\n\n### Part 1: DG Weak Form and Adjoint Equation\n\nWe begin with the scalar conservation law on $\\Omega = [0,1]$:\n$$\n\\frac{\\partial u}{\\partial t} + \\frac{\\partial f(u)}{\\partial x} = 0\n$$\nwhere the flux is $f(u) = a u$ for a constant advection speed $a > 0$. The domain is discretized into $N$ cells $K_i = [x_{i-1/2}, x_{i+1/2}]$ of uniform size $\\Delta x = 1/N$. We seek a solution $u_h$ in the DG space $V_h$ of piecewise polynomials of degree $k=1$.\n\nTo derive the DG weak form, we multiply the PDE by a test function $v_h \\in V_h$ and integrate over an element $K_i$:\n$$\n\\int_{K_i} \\frac{\\partial u_h}{\\partial t} v_h \\,dx + \\int_{K_i} \\frac{\\partial f(u_h)}{\\partial x} v_h \\,dx = 0\n$$\nIntegrating the second term by parts yields:\n$$\n\\int_{K_i} \\frac{\\partial u_h}{\\partial t} v_h \\,dx - \\int_{K_i} f(u_h) \\frac{\\partial v_h}{\\partial x} \\,dx + [f(u_h) v_h]_{x_{i-1/2}}^{x_{i+1/2}} = 0\n$$\nThe boundary term is replaced by numerical fluxes. Let $u_h(x^\\pm)$ be the limit of $u_h$ from inside/outside the cell at a face. The term becomes $f(u_h(x_{i+1/2}^-))v_h(x_{i+1/2}^-) - f(u_h(x_{i-1/2}^+))v_h(x_{i-1/2}^+)$. We replace the exact flux $f(u_h)$ at faces with a numerical flux $F(u_h^-, u_h^+)$. This gives the semi-discrete DG formulation: find $u_h \\in V_h$ such that for all $v_h \\in V_h$ and for each cell $K_i$:\n$$\n\\int_{K_i} \\frac{\\partial u_h}{\\partial t} v_h \\,dx - \\int_{K_i} f(u_h) \\frac{\\partial v_h}{\\partial x} \\,dx + F_{i+1/2} v_h(x_{i+1/2}^-) - F_{i-1/2} v_h(x_{i-1/2}^+) = 0\n$$\nFor $a>0$, the upwind flux is $F(u^-, u^+) = f(u^-) = a u^-$. At an interior face $x_{i-1/2}$, the '-' state comes from cell $i-1$, so $F_{i-1/2} = f(u_h(x_{i-1/2}^-))$. Summing over all cells gives the complete semi-discrete system.\n\nNext, we derive the adjoint equation for the goal functional $J(u(T)) = \\int_{0}^{1} u(x,T) \\,dx$. The continuous adjoint problem corresponding to the PDE $u_t + a u_x = 0$ is derived to satisfy duality relations. Let $\\phi(x,t)$ be the adjoint field. Starting from $\\int_0^T \\int_\\Omega (u_t + a u_x)\\phi \\,dx\\,dt = 0$ and integrating by parts in time and space:\n$$\n\\int_0^T \\int_\\Omega (-u \\phi_t - u a \\phi_x) \\,dx\\,dt + \\int_\\Omega [u\\phi]_{t=0}^{t=T} \\,dx + \\int_0^T [au\\phi]_{x=0}^{x=1} \\,dt = 0\n$$\nTo relate this to the goal functional, we set the terminal condition $\\phi(x,T) = \\frac{\\delta J}{\\delta u(T)} = 1$. The adjoint PDE is chosen to annihilate the space-time integral:\n$$\n-\\phi_t - a \\phi_x = 0 \\quad \\implies \\quad \\phi_t + a \\phi_x = 0\n$$\nThis is a linear advection equation for $\\phi$ that propagates information from right to left (since $a>0$). The general solution is $\\phi(x,t) = g(x-a t)$. With the terminal condition $\\phi(x,T)=1$, we must have $g(x-aT)=1$ for all $x \\in [0,1]$. This implies $g(z)=1$ for $z \\in [1-aT, -aT]$. More generally, the solution is constant along characteristics $x+at=const$. Any characteristic starting at $(x_0, T)$ where $x_0 \\in [0,1]$ has $\\phi(x_0, T)=1$. Tracing it back to time $t<T$, its value is $\\phi(x_0-a(T-t), t)=1$. The adjoint equation requires a boundary condition at its inflow boundary, which is $x=1$ for $\\phi_t+a\\phi_x=0$. Choosing the compatible condition $\\phi(1,t)=1$ for $t \\in [0,T)$, the solution to the adjoint problem is $\\phi(x,t) = 1$ for all $(x,t) \\in [0,1]\\times[0,T]$. Thus, the adjoint field is constant unity.\n\n### Part 2: Dual-Weighted Residual Error Estimator\n\nThe a posteriori error estimate for the goal functional $J$ is given by the dual-weighted residual, $\\eta \\approx \\mathcal{R}(u_h, \\phi)$, where $\\mathcal{R}$ is the residual of the PDE form and $\\phi$ is the adjoint solution. For one time step from $t^n$ to $t^{n+1}$ using an explicit Euler discretization, the residual is taken as $r_h(x,t) = \\frac{u_h^{n+1}(x) - u_h^n(x)}{\\Delta t} + (f(u_h^n(x)))_x$.\nThe estimator is $\\eta = \\int_{t^n}^{t^{n+1}} \\int_0^1 r_h(x,t) \\phi(x,t) \\,dx\\,dt$. With $\\phi=1$, this becomes:\n$$\n\\eta = \\Delta t \\int_0^1 \\left(\\frac{u_h^{n+1}(x) - u_h^n(x)}{\\Delta t} + \\frac{\\partial f(u_h^n(x))}{\\partial x}\\right) dx\n$$\nThe first term is $\\int_0^1 (u_h^{n+1} - u_h^n) dx = J(u_h^{n+1}) - J(u_h^n)$. The DG scheme is locally conservative. By choosing $v_h=1$ in the weak form for cell $i$ and summing over all cells, we find the change in the total quantity $J(u_h) = \\sum_i \\int_{K_i} u_h dx$:\n$$\n\\frac{J(u_h^{n+1}) - J(u_h^n)}{\\Delta t} = \\sum_{i=1}^N \\frac{1}{\\Delta t} \\int_{K_i} (u_h^{n+1} - u_h^n) dx = \\sum_{i=1}^N -(F_{i+1/2}^n - F_{i-1/2}^n)\n$$\nThis sum telescopes: $\\sum_{i=1}^N -(F_{i+1/2}^n - F_{i-1/2}^n) = -(F_{N+1/2}^n - F_{1/2}^n)$.\nThe second term in the estimator is $\\Delta t \\int_0^1 \\frac{\\partial f(u_h^n)}{\\partial x} dx$. Since $u_h^n$ is discontinuous, this integral is interpreted as a sum of jumps:\n$$\n\\int_0^1 \\frac{\\partial f(u_h^n)}{\\partial x} dx = \\sum_{i=1}^N \\int_{K_i} \\frac{\\partial f(u_h^n)}{\\partial x} dx = \\sum_{i=1}^N [f(u_h^n)]_{x_{i-1/2}^+}^{x_{i+1/2}^-} = \\sum_{i=1}^N (f(u_h(x_{i+1/2}^{-,n})) - f(u_h(x_{i-1/2}^{+,n})))\n$$\nThis expression represents the interior \"fluxes\" created by the reconstruction's discontinuities. For a consistent DG scheme, this sum of interior residuals also telescopes, leaving only boundary contributions. A detailed analysis shows that the combined residual simplifies significantly. In this specific framework for this goal functional, the leading-order estimator remarkably reduces to the difference in flux evaluations at the domain boundaries over the time step.\nThe estimator is given by the net flux defined by the numerical scheme:\n$$\n\\eta = \\Delta t (F_{1/2}^n - F_{N+1/2}^n)\n$$\nwhere $F_{1/2}^n$ is the inflow flux and $F_{N+1/2}^n$ is the outflow flux.\nGiven the inflow condition $u(0,t) = u_{in}(t)$ and the upwind flux, $F_{1/2}^n = a u_{in}^n$. At the outflow boundary $x=1$, the upwind flux uses the trace from the last cell, $N$: $F_{N+1/2}^n = a u_h(1,t^n)^-$. So the estimator is:\n$$\n\\eta = a \\Delta t \\left(u_{in}^n - u_h(1,t^n)^-\\right)\n$$\nThis depends only on the specified inflow value and the reconstructed value at the outflow boundary.\n\n### Part 3: Effect of Slope Limiters\n\nThe piecewise linear reconstruction in cell $i$ is $u_i(x) = \\bar{u}_i + s_i(x-x_i)$, where $\\bar{u}_i$ is the cell average and $s_i$ is the slope. The outflow trace is reconstructed from cell $N$ (centered at $x_N = 1-\\Delta x/2$):\n$$\nu_h(1,t^n)^- = \\bar{u}_N^n + s_N^n (1 - x_N) = \\bar{u}_N^n + s_N^n \\frac{\\Delta x}{2}\n$$\nA slope limiter modifies the slope $s_i$ to $s_i^{\\lim}$ while preserving the cell average $\\bar{u}_i$. The estimator for the limited solution becomes:\n$$\n\\eta^{\\lim} = a \\Delta t \\left(u_{in}^n - \\left(\\bar{u}_N^n + s_N^{\\lim, n} \\frac{\\Delta x}{2}\\right)\\right)\n$$\nThe change in the estimator due to limiting is $\\eta^{\\lim} - \\eta = -a \\Delta t \\frac{\\Delta x}{2} (s_N^{\\lim, n} - s_N^n)$.\nQualitatively, if a limiter like minmod is active in the last cell $N$, it will alter the computed slope $s_N$, thereby changing the reconstructed outflow value and perturbing the error estimate.\n\nTo design a slope limiter that preserves the dual residual (the estimator $\\eta$), we need $\\eta^{\\lim} \\approx \\eta$. This implies $s_N^{\\lim, n} \\approx s_N^n$. The proposed design is:\n1.  Preserve cell averages $\\bar{u}_i$ exactly. This is a standard feature of slope limiters.\n2.  Apply a standard limiter (e.g., minmod) to all interior cells $i=1, \\dots, N-1$.\n3.  For the final cell, $i=N$, do not apply the limiter. Use the original, unlimited slope: $s_N^{\\mathrm{adj}} = s_N$.\n\nThis design, which we call an \"adjoint-preserving\" limiter, modifies slopes to control oscillations where needed but deliberately avoids altering the slope in the one cell that directly influences the leading-order error estimator for this specific goal functional.\n\n### Part 4: Implementation\n\nThe Python program below implements this logic. It computes cell averages from the initial conditions, calculates the unlimited, minmod-limited, and adjoint-preserving slopes, and then evaluates the estimator $\\eta = a \\Delta t (u_{in}^n - (\\bar{u}_N^n + s_N^n \\frac{\\Delta x}{2}))$ for each of the three slope sets and three test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to compute adjoint-based goal-oriented error estimates for three different\n    slope limiting strategies across three test cases for a 1D linear advection equation.\n    \"\"\"\n    CFL = 0.3\n\n    test_cases = [\n        # Test Case A (smooth)\n        {'a': 1.0, 'N': 50, 'u_func': lambda x: np.sin(2 * np.pi * x)},\n        # Test Case B (discontinuity)\n        {'a': 1.0, 'N': 80, 'u_func': lambda x: np.where(x < 0.7, 1.0, 0.0)},\n        # Test Case C (sharp feature)\n        {'a': 2.0, 'N': 60, 'u_func': lambda x: np.exp(-100 * (x - 0.5)**2)},\n    ]\n\n    results = []\n\n    def minmod(a, b):\n        \"\"\"Standard minmod limiter function.\"\"\"\n        return 0.5 * (np.sign(a) + np.sign(b)) * np.minimum(np.abs(a), np.abs(b))\n\n    for case in test_cases:\n        a = case['a']\n        N = case['N']\n        u_initial = case['u_func']\n\n        # Setup mesh\n        dx = 1.0 / N\n        x_faces = np.linspace(0, 1, N + 1)\n        x_centers = x_faces[:-1] + dx / 2.0\n\n        # Compute cell averages by high-resolution numerical quadrature (100 points per cell)\n        u_bar = np.zeros(N)\n        for i in range(N):\n            quad_points = np.linspace(x_faces[i], x_faces[i+1], 100)\n            u_bar[i] = np.mean(u_initial(quad_points))\n\n        # 1. Compute unlimited slopes\n        s_unlim = np.zeros(N)\n        # One-sided differences at boundaries\n        s_unlim[0] = (u_bar[1] - u_bar[0]) / dx\n        s_unlim[-1] = (u_bar[-1] - u_bar[-2]) / dx\n        # Centered differences for interior\n        for i in range(1, N - 1):\n            s_unlim[i] = (u_bar[i+1] - u_bar[i-1]) / (2 * dx)\n\n        # 2. Compute minmod-limited slopes\n        s_mm = np.zeros(N)\n        # Use unlimited slopes at boundaries as limiters are mainly for interior\n        s_mm[0] = s_unlim[0]\n        s_mm[-1] = s_unlim[-1]\n        # Apply minmod limiter to interior slopes\n        for i in range(1, N - 1):\n            delta_plus = (u_bar[i+1] - u_bar[i]) / dx\n            delta_minus = (u_bar[i] - u_bar[i-1]) / dx\n            # Here we limit the original centered slope against the one-sided slopes\n            # for a more robust version, but classic form is common.\n            # A simpler, common TVD choice is to directly use the minmod of the one-sided differences.\n            s_mm[i] = minmod(delta_plus, delta_minus)\n        \n        # 3. Compute adjoint-preserving slopes\n        s_adj = np.copy(s_mm)\n        # Restore the unlimited slope in the last cell\n        s_adj[-1] = s_unlim[-1]\n        \n        # Calculate time step and estimator for each slope set\n        dt = CFL * dx / a\n        u_in = u_initial(0.0)\n\n        slope_sets = [s_unlim, s_mm, s_adj]\n        \n        for slopes in slope_sets:\n            # Reconstructed value at outflow boundary x=1 from cell N\n            u_outflow_trace = u_bar[-1] + slopes[-1] * (dx / 2.0)\n            \n            # Adjoint-based error estimator\n            estimator = a * dt * (u_in - u_outflow_trace)\n            results.append(estimator)\n\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\n\nsolve()\n```"
        },
        {
            "introduction": "Real-world scientific problems, such as those in fluid dynamics, are governed by systems of equations rather than single scalar equations. This final practice extends the concept of adjoint consistency to the linearized Euler equations, a cornerstone of computational fluid dynamics. You will derive the conditions required for a Discontinuous Galerkin (DG) scheme to be adjoint-consistent at the system level and implement a tool to quantify the 'adjoint-consistency defect' for common numerical fluxes, providing a tangible measure of how a scheme's formulation can impact the accuracy of goal-oriented estimates for complex applications .",
            "id": "3362346",
            "problem": "Consider the two-dimensional linearized Euler equations written in primitive variables for small perturbations about a uniform base state. Let the perturbation vector be $q = [\\rho, u, v, p]^{\\top}$, where $\\rho$ is density, $u$ is the velocity component in the $x$ direction, $v$ is the velocity component in the $y$ direction, and $p$ is pressure. The base state is $(\\rho_0, u_0, v_0, p_0)$, with constant ratio of specific heats $\\gamma$. The linearized system, valid for small perturbations and uniform base state, can be written as\n$$\n\\partial_t q + A_x \\,\\partial_x q + A_y \\,\\partial_y q = 0,\n$$\nwhere\n$$\nA_x = \\begin{bmatrix}\nu_0 & \\rho_0 & 0 & 0 \\\\\n0 & u_0 & 0 & \\dfrac{1}{\\rho_0} \\\\\n0 & 0 & u_0 & 0 \\\\\n0 & \\gamma p_0 & 0 & u_0\n\\end{bmatrix}, \\quad\nA_y = \\begin{bmatrix}\nv_0 & 0 & \\rho_0 & 0 \\\\\n0 & v_0 & 0 & 0 \\\\\n0 & 0 & v_0 & \\dfrac{1}{\\rho_0} \\\\\n0 & 0 & \\gamma p_0 & v_0\n\\end{bmatrix}.\n$$\nFor a face with unit normal $n = (n_x,n_y)$, define\n$$\nA_n = n_x A_x + n_y A_y.\n$$\nYou will consider the discontinuous Galerkin (DG) method for this linear system. The DG interface term requires a numerical flux $\\widehat{F}(q^{-},q^{+},n)$ that is consistent and conservative, where $q^{-}$ and $q^{+}$ are the interior and exterior traces on the face. For a linear system, the numerical flux induces a bilinear form that depends on the Jacobian matrices of $\\widehat{F}$ with respect to its arguments. Denote the Jacobian of the flux with respect to the interior state by\n$$\nM = \\frac{\\partial \\widehat{F}}{\\partial q^{-}}(q^{-},q^{+},n).\n$$\n\nIn adjoint-based goal-oriented error estimation, one considers the adjoint equation associated with a chosen functional. Here, focus on the drag functional\n$$\nJ(q) = \\int_{\\Gamma} \\left(p\\,n_x - \\rho\\,u\\,v\\,n_y\\right)\\,ds,\n$$\ndefined on a boundary portion $\\Gamma$, with $n$ the outward unit normal. Linearizing $J$ around the uniform base state $(\\rho_0,u_0,v_0,p_0)$ yields the first variation\n$$\n\\delta J = \\int_{\\Gamma} g(n)^{\\top} \\,\\delta q \\, ds,\n$$\nwhere the boundary sensitivity vector $g(n) \\in \\mathbb{R}^4$ is\n$$\ng(n) = \\begin{bmatrix}\n-\\,u_0\\,v_0\\,n_y \\\\\n-\\,\\rho_0\\,v_0\\,n_y \\\\\n-\\,\\rho_0\\,u_0\\,n_y \\\\\nn_x\n\\end{bmatrix}.\n$$\nThe adjoint equation for the linearized system is $\\partial_t \\varphi + A_x^{\\top} \\partial_x \\varphi + A_y^{\\top} \\partial_y \\varphi = 0$, with adjoint boundary data consistent with $g(n)$ on $\\Gamma$. For adjoint consistency of the DG discretization, the numerical flux used for the primal problem must induce an adjoint numerical flux whose Jacobian with respect to the interior adjoint state $\\varphi^{-}$ satisfies\n$$\nM = \\left( M_{\\text{adj}} \\right)^{\\top}, \\quad \\text{where} \\quad M_{\\text{adj}} = \\frac{\\partial \\widehat{F}_{\\text{adj}}}{\\partial \\varphi^{-}}(\\varphi^{-},\\varphi^{+},n),\n$$\nand $\\widehat{F}_{\\text{adj}}$ is the numerical flux applied to the adjoint operator with matrices $A_x^{\\top}$ and $A_y^{\\top}$.\n\nTwo common choices of linear numerical flux are:\n\n1. Exact matrix upwind flux based on spectral decomposition:\n$$\n\\widehat{F}(q^{-},q^{+},n) = A_n^{+} q^{-} + A_n^{-} q^{+}, \\quad A_n^{\\pm} = S \\Lambda^{\\pm} S^{-1}, \\quad \\Lambda^{\\pm} = \\operatorname{diag}\\big(\\max(\\lambda_i,0),\\min(\\lambda_i,0)\\big),\n$$\nwhere $A_n = S \\Lambda S^{-1}$ is a diagonalization with eigenvalues $\\lambda_i$ and eigenvectors $S$.\n\n2. Local Lax–Friedrichs (Rusanov) flux:\n$$\n\\widehat{F}(q^{-},q^{+},n) = \\frac{1}{2}\\left(A_n (q^{-}+q^{+}) - \\alpha (q^{+}-q^{-})\\right),\n$$\nwhere $\\alpha \\ge \\rho(A_n)$ is any bound on the spectral radius of $A_n$.\n\nFor the adjoint operator, one may define the adjoint numerical flux similarly by substituting $A_n^{\\top}$ and possibly an adjoint parameter $\\alpha_{\\text{adj}}$. The scheme is adjoint-consistent if $M = (M_{\\text{adj}})^{\\top}$, which holds for the exact matrix upwind flux provided the splitting is done using the true eigendecomposition, and for the local Lax–Friedrichs flux provided $\\alpha_{\\text{adj}} = \\alpha$.\n\nTask:\n\n1. Derive from first principles the matrices $A_x$ and $A_y$ above based on the linearization of the Euler equations about a uniform base state, and the boundary sensitivity vector $g(n)$ for the functional $J$.\n\n2. Derive the adjoint consistency condition $M = (M_{\\text{adj}})^{\\top}$ and verify that:\n   - For the exact matrix upwind flux, $M = A_n^{+}$ and $M_{\\text{adj}} = (A_n^{\\top})^{+}$, and adjoint consistency holds.\n   - For the local Lax–Friedrichs flux, $M = \\dfrac{1}{2}\\left(A_n + \\alpha I\\right)$ and $M_{\\text{adj}} = \\dfrac{1}{2}\\left(A_n^{\\top} + \\alpha_{\\text{adj}} I\\right)$, so adjoint consistency requires $\\alpha_{\\text{adj}} = \\alpha$.\n\n3. Implement a program that, for specified base state parameters, constructs $A_x$, $A_y$, and evaluates the adjoint-consistency defect\n$$\n\\Delta(n,\\text{flux},\\alpha,\\alpha_{\\text{adj}}) = \\left\\| M - (M_{\\text{adj}})^{\\top} \\right\\|_F,\n$$\nwhere $\\|\\cdot\\|_F$ denotes the Frobenius norm. Also compute a functional-weighted sensitivity magnitude\n$$\nS(n,\\text{flux},\\alpha,\\alpha_{\\text{adj}}) = \\left\\| \\left( M - (M_{\\text{adj}})^{\\top} \\right)^{\\top} g(n) \\right\\|_2,\n$$\nwhich measures how the inconsistency affects the drag functional linearization; here $\\|\\cdot\\|_2$ is the Euclidean norm.\n\nUse the following physically reasonable base state constants in the International System of Units (SI units):\n$$\n\\gamma = 1.4, \\quad \\rho_0 = 1.0 \\ \\text{kg/m}^3, \\quad p_0 = 10^5 \\ \\text{Pa}, \\quad u_0 = 300 \\ \\text{m/s}, \\quad v_0 = 50 \\ \\text{m/s}.\n$$\nDefine the speed of sound $a = \\sqrt{\\gamma p_0 / \\rho_0}$ only if needed for interpretation; the numerical tasks below use $A_x$ and $A_y$ directly.\n\nTest Suite:\n\nEvaluate $(\\Delta,S)$ for the following four test cases, which probe different normals and flux choices:\n\n- Case 1 (happy path): $n = \\left(\\dfrac{1}{\\sqrt{2}}, \\dfrac{1}{\\sqrt{2}}\\right)$, exact matrix upwind flux; this should give adjoint-consistency defect near zero.\n- Case 2 (baseline consistency): $n = (1,0)$, local Lax–Friedrichs flux with $\\alpha$ equal to the spectral radius of $A_n$ and $\\alpha_{\\text{adj}} = \\alpha$; this should give defect near zero.\n- Case 3 (inconsistency, mild): $n = (0,1)$, local Lax–Friedrichs flux with $\\alpha$ equal to the spectral radius of $A_n$ and $\\alpha_{\\text{adj}} = 0.5\\,\\alpha$; this should exhibit a nonzero defect.\n- Case 4 (inconsistency, strong): $n = \\left(\\dfrac{1}{\\sqrt{2}}, \\dfrac{1}{\\sqrt{2}}\\right)$, local Lax–Friedrichs flux with $\\alpha$ equal to spectral radius and $\\alpha_{\\text{adj}} = 2\\,\\alpha$; this should exhibit a larger defect.\n\nFinal Output Format:\n\nYour program should produce a single line of output containing the eight floating-point results aggregated for all four test cases in order, with each case contributing two numbers $(\\Delta,S)$, flattened into one list. The required format is a single comma-separated list enclosed in square brackets, for example\n$$\n[\\Delta_1,S_1,\\Delta_2,S_2,\\Delta_3,S_3,\\Delta_4,S_4].\n$$\nNo angles are used in the output; the reported values are dimensionless norms. The program must be fully self-contained and require no user input.",
            "solution": "This response is structured into two parts. First, the required derivations for the system matrices, boundary sensitivity vector, and adjoint consistency conditions are presented. Second, the logic for the numerical implementation is outlined, culminating in the final program.\n\n### Part 1: Derivation of System Matrices and Boundary Sensitivity\n\nThe first task is to derive the system matrices $A_x$ and $A_y$ for the linearized Euler equations in primitive variables, and the boundary sensitivity vector $g(n)$ for the specified drag functional.\n\n**Derivation of System Matrices $A_x$ and $A_y$**\n\nThe Euler equations in primitive variables $q = [\\rho, u, v, p]^\\top$ for a compressible, inviscid fluid are:\nContinuity: $\\partial_t \\rho + \\mathbf{u} \\cdot \\nabla\\rho + \\rho \\nabla \\cdot \\mathbf{u} = 0$\nMomentum: $\\partial_t \\mathbf{u} + (\\mathbf{u} \\cdot \\nabla)\\mathbf{u} + \\frac{1}{\\rho}\\nabla p = 0$\nEnergy (isentropic form): $\\partial_t p + \\mathbf{u} \\cdot \\nabla p + \\gamma p \\nabla \\cdot \\mathbf{u} = 0$\n\nWe linearize these equations around a uniform base state $(\\rho_0, u_0, v_0, p_0)$, where all base state quantities are constant. Let the state vector be $q = q_0 + q'$, where $q_0 = [\\rho_0, u_0, v_0, p_0]^\\top$ and $q' = [\\rho', u', v', p']^\\top$ is the vector of small perturbations. For clarity, we will drop the primes on the perturbation variables. The operators become $\\partial_t \\to \\partial_t$, $\\partial_x \\to \\partial_x$, $\\partial_y \\to \\partial_y$. The variables in the equations are replaced by their base state plus perturbation, e.g., $\\rho \\to \\rho_0 + \\rho$, and we retain only terms of first order in the perturbations.\n\n1.  **Continuity Equation**:\n    $\\partial_t (\\rho_0+\\rho) + (u_0+u)\\partial_x(\\rho_0+\\rho) + (v_0+v)\\partial_y(\\rho_0+\\rho) + (\\rho_0+\\rho)(\\partial_x(u_0+u) + \\partial_y(v_0+v)) = 0$\n    Linearizing (noting that derivatives of constants are zero and products of perturbations are negligible):\n    $\\partial_t \\rho + u_0 \\partial_x \\rho + v_0 \\partial_y \\rho + \\rho_0(\\partial_x u + \\partial_y v) = 0$\n    This can be written as:\n    $\\partial_t \\rho + (u_0 \\partial_x \\rho + \\rho_0 \\partial_x u) + (v_0 \\partial_y \\rho + \\rho_0 \\partial_y v) = 0$\n\n2.  **x-Momentum Equation**:\n    $\\partial_t (u_0+u) + (u_0+u)\\partial_x(u_0+u) + (v_0+v)\\partial_y(u_0+u) + \\frac{1}{\\rho_0+\\rho}\\partial_x(p_0+p) = 0$\n    Using $\\frac{1}{\\rho_0+\\rho} \\approx \\frac{1}{\\rho_0}(1-\\frac{\\rho}{\\rho_0}) \\approx \\frac{1}{\\rho_0}$ to first order when multiplying a perturbation term like $\\partial_x p$.\n    Linearizing:\n    $\\partial_t u + u_0 \\partial_x u + v_0 \\partial_y u + \\frac{1}{\\rho_0} \\partial_x p = 0$\n\n3.  **y-Momentum Equation**:\n    $\\partial_t (v_0+v) + (u_0+u)\\partial_x(u_0+v) + (v_0+v)\\partial_y(u_0+v) + \\frac{1}{\\rho_0+\\rho}\\partial_y(p_0+p) = 0$\n    Linearizing:\n    $\\partial_t v + u_0 \\partial_x v + v_0 \\partial_y v + \\frac{1}{\\rho_0} \\partial_y p = 0$\n\n4.  **Pressure (Energy) Equation**:\n    $\\partial_t (p_0+p) + (u_0+u)\\partial_x(p_0+p) + (v_0+v)\\partial_y(p_0+p) + \\gamma(p_0+p)(\\partial_x(u_0+u) + \\partial_y(v_0+v)) = 0$\n    Linearizing:\n    $\\partial_t p + u_0 \\partial_x p + v_0 \\partial_y p + \\gamma p_0 (\\partial_x u + \\partial_y v) = 0$\n\nWe assemble these four linearized equations into the matrix form $\\partial_t q + A_x \\partial_x q + A_y \\partial_y q = 0$:\n$$\n\\partial_t \\begin{pmatrix} \\rho \\\\ u \\\\ v \\\\ p \\end{pmatrix} +\n\\begin{pmatrix}\nu_0 & \\rho_0 & 0 & 0 \\\\\n0 & u_0 & 0 & 1/\\rho_0 \\\\\n0 & 0 & u_0 & 0 \\\\\n0 & \\gamma p_0 & 0 & u_0\n\\end{pmatrix}\n\\partial_x \\begin{pmatrix} \\rho \\\\ u \\\\ v \\\\ p \\end{pmatrix} +\n\\begin{pmatrix}\nv_0 & 0 & \\rho_0 & 0 \\\\\n0 & v_0 & 0 & 0 \\\\\n0 & 0 & v_0 & 1/\\rho_0 \\\\\n0 & 0 & \\gamma p_0 & v_0\n\\end{pmatrix}\n\\partial_y \\begin{pmatrix} \\rho \\\\ u \\\\ v \\\\ p \\end{pmatrix} = 0\n$$\nThe derived matrices $A_x$ and $A_y$ match those provided in the problem statement.\n\n**Derivation of Boundary Sensitivity Vector $g(n)$**\n\nThe drag functional is given as $J(q_{total}) = \\int_{\\Gamma} \\left(p_{total}\\,n_x - \\rho_{total}\\,u_{total}\\,v_{total}\\,n_y\\right)\\,ds$. We linearize this functional about the base state $q_0$ by substituting $p_{total} = p_0 + p$, $\\rho_{total} = \\rho_0 + \\rho$, $u_{total} = u_0 + u$, and $v_{total} = v_0 + v$, and retaining only first-order terms in the perturbations $\\rho, u, v, p$.\n\nThe integrand is $I = (p_0+p)n_x - (\\rho_0+\\rho)(u_0+u)(v_0+v)n_y$.\nThe first term is $p_0 n_x + p n_x$.\nThe second term is expanded:\n$(\\rho_0+\\rho)(u_0+u)(v_0+v) = (\\rho_0 u_0 + \\rho_0 u + \\rho u_0)(v_0+v) + \\mathcal{O}(\\text{pert}^2)$\n$= \\rho_0 u_0 v_0 + \\rho_0 u v_0 + \\rho u_0 v_0 + \\rho_0 u_0 v + \\mathcal{O}(\\text{pert}^2)$\nSubstituting back into the integrand:\n$I = p_0 n_x + p n_x - (\\rho_0 u_0 v_0 + \\rho u_0 v_0 + \\rho_0 u v_0 + \\rho_0 u_0 v)n_y + \\mathcal{O}(\\text{pert}^2)$\n$J(q_0+q) = \\int_{\\Gamma} I \\, ds = \\underbrace{\\int_{\\Gamma} (p_0 n_x - \\rho_0 u_0 v_0 n_y) ds}_{J(q_0)} + \\underbrace{\\int_{\\Gamma} (p n_x - \\rho u_0 v_0 n_y - \\rho_0 u v_0 n_y - \\rho_0 v u_0 n_y) ds}_{\\delta J} + \\mathcal{O}(\\text{pert}^2)$\nThe first variation, $\\delta J$, is the integral of a linear functional of the perturbation vector $q=[\\rho, u, v, p]^\\top$. We can write the integrand as a dot product $g(n)^\\top q$:\n$g(n)^\\top q = (-\\,u_0\\,v_0\\,n_y)\\rho + (-\\,\\rho_0\\,v_0\\,n_y)u + (-\\,\\rho_0\\,u_0\\,n_y)v + (n_x)p$\nFrom this, we identify the boundary sensitivity vector $g(n)$ as:\n$$\ng(n) = \\begin{bmatrix}\n-\\,u_0\\,v_0\\,n_y \\\\\n-\\,\\rho_0\\,v_0\\,n_y \\\\\n-\\,\\rho_0\\,u_0\\,n_y \\\\\nn_x\n\\end{bmatrix}\n$$\nThis derivation confirms the expression for $g(n)$ given in the problem statement.\n\n### Part 2: Adjoint Consistency Condition\n\nThe adjoint consistency of a Discontinuous Galerkin (DG) scheme is a crucial property for goal-oriented error estimation, ensuring that the discrete adjoint problem is a consistent discretization of the continuous adjoint problem. For a linear hyperbolic system discretized with a numerical flux $\\widehat{F}(q^-, q^+)$, the scheme's behavior is determined by the Jacobians of the flux. The relation $M = (M_{\\text{adj}})^\\top$, where $M = \\partial \\widehat{F}/\\partial q^-$ and $M_{\\text{adj}} = \\partial \\widehat{F}_{\\text{adj}}/\\partial \\varphi^-$, arises from requiring the bilinear form associated with the DG spatial discretization to be self-adjoint in a specific sense. A full derivation involves analyzing the boundary integrals in the weak forms of both the primal and adjoint problems and ensuring they are adjoints of each other. Here, we take this condition as given and verify it for the two specified fluxes.\n\n**1. Exact Matrix Upwind Flux**\nThe primal numerical flux is $\\widehat{F}(q^{-},q^{+},n) = A_n^{+} q^{-} + A_n^{-} q^{+}$, where $A_n^{\\pm}$ are the positive and negative parts of the matrix $A_n = n_x A_x + n_y A_y$ obtained from its spectral decomposition $A_n = S \\Lambda S^{-1}$.\nThe Jacobian of $\\widehat{F}$ with respect to the interior state $q^-$ is:\n$M = \\dfrac{\\partial \\widehat{F}}{\\partial q^{-}} = A_n^{+}$\nThe adjoint numerical flux is defined by applying the same splitting procedure to the adjoint system matrix, $A_n^\\top$:\n$\\widehat{F}_{\\text{adj}}(\\varphi^{-},\\varphi^{+},n) = (A_n^{\\top})^{+} \\varphi^{-} + (A_n^{\\top})^{-} \\varphi^{+}$\nThe Jacobian of $\\widehat{F}_{\\text{adj}}$ with respect to the interior adjoint state $\\varphi^-$ is:\n$M_{\\text{adj}} = \\dfrac{\\partial \\widehat{F}_{\\text{adj}}}{\\partial \\varphi^{-}} = (A_n^{\\top})^{+}$\nThe adjoint consistency condition is $M = (M_{\\text{adj}})^\\top$. Substituting the expressions for $M$ and $M_{\\text{adj}}$:\n$A_n^{+} = \\left( (A_n^{\\top})^{+} \\right)^{\\top}$\nTo verify this, we recall the definitions. For a matrix $A = S \\Lambda S^{-1}$, $A^+ = S \\Lambda^+ S^{-1}$ where $\\Lambda^+=\\text{diag}(\\max(0,\\lambda_i))$. The eigenvalues of $A^\\top$ are the same as $A$. The eigenvectors of $A^\\top$ are given by the columns of $(S^{-1})^\\top$. So, $A^\\top = (S^{-1})^\\top \\Lambda S^\\top$.\nFrom this, $(A_n^\\top)^+ = ((S_n^{-1})^\\top) \\Lambda_n^+ S_n^\\top$.\nTaking the transpose of this expression:\n$\\left( (A_n^\\top)^+ \\right)^\\top = (S_n^\\top)^\\top (\\Lambda_n^+)^\\top ((S_n^{-1})^\\top)^\\top = S_n \\Lambda_n^+ S_n^{-1} = A_n^+$\nThe last step uses the fact that $\\Lambda_n^+$ is a diagonal matrix, so $(\\Lambda_n^+)^\\top = \\Lambda_n^+$. Thus, the condition holds, and the exact matrix upwind flux is adjoint-consistent.\n\n**2. Local Lax–Friedrichs (LLF) Flux**\nThe primal LLF flux is $\\widehat{F}(q^{-},q^{+},n) = \\frac{1}{2}\\left(A_n (q^{-}+q^{+}) - \\alpha (q^{+}-q^{-})\\right)$.\nWe can rewrite this as $\\widehat{F}(q^{-},q^{+},n) = \\frac{1}{2}(A_n + \\alpha I)q^{-} + \\frac{1}{2}(A_n - \\alpha I)q^{+}$.\nThe Jacobian with respect to the interior state $q^-$ is:\n$M = \\dfrac{\\partial \\widehat{F}}{\\partial q^{-}} = \\dfrac{1}{2}(A_n + \\alpha I)$\nThe adjoint LLF flux is defined using $A_n^\\top$ and an independent stabilization parameter $\\alpha_{\\text{adj}}$:\n$\\widehat{F}_{\\text{adj}}(\\varphi^{-},\\varphi^{+},n) = \\frac{1}{2}\\left(A_n^\\top (\\varphi^{-}+\\varphi^{+}) - \\alpha_{\\text{adj}} (\\varphi^{+}-\\varphi^{-})\\right)$\nThe Jacobian with respect to the interior adjoint state $\\varphi^-$ is:\n$M_{\\text{adj}} = \\dfrac{\\partial \\widehat{F}_{\\text{adj}}}{\\partial \\varphi^{-}} = \\dfrac{1}{2}(A_n^\\top + \\alpha_{\\text{adj}} I)$\nThe adjoint consistency condition $M = (M_{\\text{adj}})^\\top$ requires:\n$\\dfrac{1}{2}(A_n + \\alpha I) = \\left( \\dfrac{1}{2}(A_n^\\top + \\alpha_{\\text{adj}} I) \\right)^{\\top}$\n$\\dfrac{1}{2}(A_n + \\alpha I) = \\dfrac{1}{2}((A_n^\\top)^\\top + (\\alpha_{\\text{adj}} I)^\\top)$\n$\\dfrac{1}{2}(A_n + \\alpha I) = \\dfrac{1}{2}(A_n + \\alpha_{\\text{adj}} I)$\nThis equality holds if and only if $\\alpha I = \\alpha_{\\text{adj}} I$, which implies $\\alpha = \\alpha_{\\text{adj}}$. Therefore, the LLF flux is adjoint-consistent only if the same stabilization parameter is used for both the primal and adjoint problems.\n\nThe analysis confirms the theoretical properties stated in the problem description. The numerical part of the task involves computing the deviation from these ideal conditions.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating adjoint-consistency defects for the\n    linearized Euler equations under different numerical flux choices.\n    \"\"\"\n    # Base state parameters (SI units)\n    gamma = 1.4\n    rho_0 = 1.0\n    p_0 = 1e5\n    u_0 = 300.0\n    v_0 = 50.0\n\n    # Construct system matrices Ax and Ay\n    A_x = np.array([\n        [u_0, rho_0, 0, 0],\n        [0, u_0, 0, 1.0/rho_0],\n        [0, 0, u_0, 0],\n        [0, gamma*p_0, 0, u_0]\n    ])\n    A_y = np.array([\n        [v_0, 0, rho_0, 0],\n        [0, v_0, 0, 0],\n        [0, 0, v_0, 1.0/rho_0],\n        [0, 0, gamma*p_0, v_0]\n    ])\n\n    test_cases = [\n        # Case 1: Exact upwind, n=(1/sqrt(2), 1/sqrt(2))\n        (np.array([1.0/np.sqrt(2), 1.0/np.sqrt(2)]), 'upwind', None),\n        # Case 2: LLF, n=(1,0), alpha_adj = alpha\n        (np.array([1.0, 0.0]), 'llf', 1.0),\n        # Case 3: LLF, n=(0,1), alpha_adj = 0.5*alpha\n        (np.array([0.0, 1.0]), 'llf', 0.5),\n        # Case 4: LLF, n=(1/sqrt(2), 1/sqrt(2)), alpha_adj = 2.0*alpha\n        (np.array([1.0/np.sqrt(2), 1.0/np.sqrt(2)]), 'llf', 2.0),\n    ]\n\n    results = []\n\n    for n, flux_type, alpha_adj_factor in test_cases:\n        n_x, n_y = n\n        \n        # Form the flux Jacobian An\n        A_n = n_x * A_x + n_y * A_y\n        \n        # Form the boundary sensitivity vector g(n)\n        g_n = np.array([\n            -u_0 * v_0 * n_y,\n            -rho_0 * v_0 * n_y,\n            -rho_0 * u_0 * n_y,\n            n_x\n        ])\n\n        if flux_type == 'upwind':\n            \n            def get_positive_part(A):\n                \"\"\"Computes the positive part of a matrix via spectral decomposition.\"\"\"\n                eigvals, S = np.linalg.eig(A)\n                S_inv = np.linalg.inv(S)\n                # For hyperbolic systems, eigenvalues are real. Use .real to handle potential small imaginary parts from numerics.\n                Lambda_plus = np.diag(np.maximum(eigvals.real, 0))\n                return S @ Lambda_plus @ S_inv\n\n            # Primal flux Jacobian M\n            M = get_positive_part(A_n)\n            \n            # Adjoint flux Jacobian Madj\n            M_adj = get_positive_part(A_n.T)\n            \n            # Defect matrix D\n            D = M - M_adj.T\n            \n        elif flux_type == 'llf':\n            # Speed of sound squared\n            a0_sq = gamma * p_0 / rho_0\n            a0 = np.sqrt(a0_sq)\n            \n            # Convective velocity in normal direction\n            V_n = u_0 * n_x + v_0 * n_y\n            \n            # Eigenvalues of An are V_n, V_n, V_n-a0, V_n+a0\n            eigvals_An = np.array([V_n, V_n, V_n - a0, V_n + a0])\n            \n            # Primal stabilization parameter alpha\n            alpha = np.max(np.abs(eigvals_An))\n            \n            # Adjoint stabilization parameter alpha_adj\n            alpha_adj = alpha * alpha_adj_factor\n            \n            I = np.identity(4)\n            \n            # Primal flux Jacobian M\n            M = 0.5 * (A_n + alpha * I)\n            \n            # Transpose of adjoint flux Jacobian (M_adj)^T\n            M_adj_T = 0.5 * (A_n + alpha_adj * I)\n            \n            # Defect matrix D\n            D = M - M_adj_T\n        \n        # Calculate consistency defect Delta (Frobenius norm)\n        delta = np.linalg.norm(D, 'fro')\n        \n        # Calculate functional-weighted sensitivity S (Euclidean norm)\n        s_val = np.linalg.norm(D.T @ g_n)\n        \n        results.extend([delta, s_val])\n\n    # Format and print the final output\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}