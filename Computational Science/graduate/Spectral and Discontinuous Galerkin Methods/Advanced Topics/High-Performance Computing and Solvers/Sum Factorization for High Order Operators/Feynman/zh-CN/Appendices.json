{
    "hands_on_practices": [
        {
            "introduction": "理解求和因子分解法的最佳起点是亲手构建它。本练习将引导你从一维分量出发，利用张量积的性质，推导出多维微分算子的求和因子分解形式。通过这个过程，你将揭示该方法高效计算的核心机制，并深化对谱方法和间断Galerkin方法中算子作用方式的理解。",
            "id": "3422305",
            "problem": "考虑一个一维多项式逼近空间，由次数至多为 $p$ 的拉格朗日基函数 $\\ell_{j}(x)$ 张成，该基函数基于一个仿射坐标为 $x$ 的区间上的 $N=p+1$ 个不同节点 $\\{x_{j}\\}_{j=0}^{p}$ 构建。令 $\\{\\xi_{q}\\}_{q=1}^{Q}$ 为一个求积网格，包含 $Q \\geq N$ 个点，且不同于节点网格（一种非配置格式）。将从节点系数到求积点值的插值算子定义为线性映射 $I \\in \\mathbb{R}^{Q \\times N}$，它将一个系数向量 $u \\in \\mathbb{R}^{N}$ 映射到值向量 $(Iu) \\in \\mathbb{R}^{Q}$，其中 $(Iu)_{q} = \\sum_{j=0}^{p} u_{j} \\, \\ell_{j}(\\xi_{q})$。此外，将一维求积网格微分算子 $\\mathcal{D} \\in \\mathbb{R}^{Q \\times Q}$ 定义为作用于求积点值 $f \\in \\mathbb{R}^{Q}$ 的线性映射，满足对于所有 $u \\in \\mathbb{R}^{N}$，$\\mathcal{D}(Iu) = \\left(\\frac{d}{dx}\\sum_{j=0}^{p} u_{j}\\,\\ell_{j}\\right)\\big|_{\\{\\xi_{q}\\}}$，即它返回在节点基中表示的任意多项式在求积点处的精确导数值。\n\n现在考虑一个 $d$ 维参考单元，其具有可分离的张量积拉格朗日基 $\\{\\ell_{j_{1}}(x_{1}) \\cdots \\ell_{j_{d}}(x_{d})\\}$，该基由每个坐标方向上相同的的一维节点集 $\\{x_{j}\\}_{j=0}^{p}$ 构建，以及一个由每个坐标方向上相同的一维求积网格 $\\{\\xi_{q}\\}_{q=1}^{Q}$ 构建的可分离求积网格 $\\{\\xi_{q_{1}},\\dots,\\xi_{q_{d}}\\}$。令 $u \\in \\mathbb{R}^{N^{d}}$ 表示按字典序重塑为向量的节点系数张量。在谱方法和间断伽辽金（DG）方法中，高阶算子的一个基本构建块是沿每个坐标方向应用的序列 $u \\mapsto Iu \\mapsto \\mathcal{D}(Iu)$。仅使用上述核心定义和张量积的线性性质，推导一维插值矩阵 $I$ 的显式逐项公式，然后从第一性原理出发，表达将 $u$ 映射到所有求积点上方向导数之和的 $d$ 维复合算子，该算子纯粹用一维算子和克罗内克积表示。您的最终答案必须是这个 $d$ 维求和因子分解算子的单一闭式解析表达式，用 $I$、$\\mathcal{D}$ 和克罗内克积表示。不需要进行数值计算，也无需舍入。最终算子仅需以符号表达式表示。",
            "solution": "对问题陈述的有效性进行了严谨的分析。\n\n### 步骤1：提取已知条件\n- 一个次数至多为 $p$ 的一维多项式逼近空间。\n- 该空间由拉格朗日基函数 $\\ell_{j}(x)$ 张成。\n- 该基函数基于一个仿射坐标为 $x$ 的区间上的 $N=p+1$ 个不同节点 $\\{x_{j}\\}_{j=0}^{p}$ 构建。\n- 一个包含 $Q$ 个不同点 $\\{\\xi_{q}\\}_{q=1}^{Q}$ 的求积网格，其中 $Q \\geq N$。\n- 该求积网格与节点网格非配置。\n- 一维插值算子是一个线性映射 $I \\in \\mathbb{R}^{Q \\times N}$。\n- $I$ 对节点系数向量 $u \\in \\mathbb{R}^{N}$ 的作用定义为 $(Iu)_{q} = \\sum_{j=0}^{p} u_{j} \\, \\ell_{j}(\\xi_{q})$。\n- 一维求积网格微分算子是一个线性映射 $\\mathcal{D} \\in \\mathbb{R}^{Q \\times Q}$。\n- $\\mathcal{D}$ 的作用被定义为，对于任何 $u \\in \\mathbb{R}^{N}$，$\\mathcal{D}(Iu)$ 产生多项式 $\\sum_{j=0}^{p} u_{j}\\,\\ell_{j}(x)$ 在求积点 $\\{\\xi_{q}\\}$ 处的精确导数值向量，即 $\\mathcal{D}(Iu) = \\left(\\frac{d}{dx}\\sum_{j=0}^{p} u_{j}\\,\\ell_{j}\\right)\\big|_{\\{\\xi_{q}\\}}$。\n- 一个 $d$ 维参考单元，其具有由每个坐标方向上相同的一维节点构成的可分离张量积拉格朗日基 $\\{\\ell_{j_{1}}(x_{1}) \\cdots \\ell_{j_{d}}(x_{d})\\}$。\n- 一个由一维网格 $\\{\\xi_{q}\\}$ 的张量积构成的可分离 $d$ 维求积网格。\n- 节点系数张量 $u \\in \\mathbb{R}^{N^{d}}$，按字典序重塑为一个向量。\n\n### 步骤2：使用提取的已知条件进行验证\n根据验证标准对问题进行评估。\n- **科学性**：该问题设定在数值分析中一个完善的数学框架内，具体涉及谱方法和间断伽辽金（DG）方法。拉格朗日多项式、求积、张量积和克罗内克积等概念都是标准且数学上合理的。\n- **适定性**：该问题是适定的。它为所有算子和空间提供了清晰而精确的定义，并要求基于这些定义推导一个特定的复合算子。目标明确，提供的信息足以推导出唯一的解析表达式。\n- **客观性**：该问题以正式、客观的数学语言陈述，没有任何主观性、模糊性或非科学性主张。\n\n该问题不存在任何使其无效的缺陷。它在数学上是合理的，自洽的，并且与高阶算子和因子分解这一特定主题直接相关。\n\n### 步骤3：结论与行动\n该问题是**有效的**。将提供一个完整、合理的解答。\n\n### 解答推导\n目标是推导出一个线性算子的表达式，该算子将 $d$ 维节点系数向量映射到在 $d$ 维求积网格上计算的所有一阶偏导数之和。\n\n首先，我们确定一维插值矩阵 $I \\in \\mathbb{R}^{Q \\times N}$ 的显式逐项公式。根据定义，对于一个节点系数向量 $u = (u_0, u_1, \\dots, u_p)^T \\in \\mathbb{R}^N$，得到的求积点值向量 $v = Iu$ 的第 $q$ 个分量由下式给出：\n$$v_q = (Iu)_q = \\sum_{j=0}^{p} u_{j} \\, \\ell_{j}(\\xi_{q})$$\n矩阵向量乘积的标准定义是 $(Iu)_q = \\sum_{j=0}^{p} I_{q,j+1} u_j$（矩阵条目使用基于1的索引，向量分量 $u_j$ 使用基于0的索引）。假设使用字典序映射，其中列索引对应于基函数索引，我们有 $(Iu)_q = \\sum_{j=0}^{p} I_{qj} u_j$。通过直接比较，矩阵 $I$ 的条目必须是：\n$$I_{qj} = \\ell_{j}(\\xi_{q})$$\n对于 $q \\in \\{1, \\dots, Q\\}$ 和 $j \\in \\{0, \\dots, p\\}$。因此，$I$ 是一个在求积点上计算基函数值的矩阵。\n\n接下来，我们构建 $d$ 维算子。令 $U(\\mathbf{x}) = U(x_1, \\dots, x_d)$ 是由节点系数 $u \\in \\mathbb{R}^{N^d}$ 表示的多项式函数。由于张量积基，该函数为：\n$$U(x_1, \\dots, x_d) = \\sum_{j_1=0}^{p} \\cdots \\sum_{j_d=0}^{p} u_{j_1, \\dots, j_d} \\left( \\ell_{j_1}(x_1) \\cdots \\ell_{j_d}(x_d) \\right)$$\n其中 $u_{j_1, \\dots, j_d}$ 是系数张量的条目。\n\n让我们考虑将节点系数 $u$ 映射到单一偏导数 $\\frac{\\partial U}{\\partial x_k}$ 在求积点上的值的算子。\n$$\\frac{\\partial U}{\\partial x_k} = \\sum_{j_1=0}^{p} \\cdots \\sum_{j_d=0}^{p} u_{j_1, \\dots, j_d} \\left( \\ell_{j_1}(x_1) \\cdots \\frac{d\\ell_{j_k}(x_k)}{dx_k} \\cdots \\ell_{j_d}(x_d) \\right)$$\n在 $d$ 维求积点 $(\\xi_{q_1}, \\dots, \\xi_{q_d})$ 上计算此式可得：\n$$\\left. \\frac{\\partial U}{\\partial x_k} \\right|_{(\\xi_{q_1}, \\dots, \\xi_{q_d})} = \\sum_{j_1=0}^{p} \\cdots \\sum_{j_d=0}^{p} u_{j_1, \\dots, j_d} \\left( \\ell_{j_1}(\\xi_{q_1}) \\cdots \\left(\\frac{d\\ell_{j_k}}{dx_k}\\right)(\\xi_{q_k}) \\cdots \\ell_{j_d}(\\xi_{q_d}) \\right)$$\n这个操作将整个系数张量 $u_{j_1, \\dots, j_d}$ 映射到求积点上的导数值张量，可以表示为一个作用于向量化系数 $u$ 的线性算子。\n\n沿每个维度 $i$ 的操作要么是插值（如果 $i \\neq k$），要么是微分后求值（如果 $i=k$）。\n1.  对于任何维度 $i \\neq k$，操作是插值，它将 $N$ 个节点系数映射到 $Q$ 个求积点值。这由矩阵 $I \\in \\mathbb{R}^{Q \\times N}$ 表示。\n2.  对于维度 $k$，操作将 $N$ 个节点系数映射到求积点上的 $Q$ 个导数值。根据问题定义，该算子是复合算子 $\\mathcal{D}I \\in \\mathbb{R}^{Q \\times N}$。\n\n对于张量积结构，多维线性算子是一维算子的克罗内克积。因此，计算所有求积点上关于 $x_k$ 的偏导数的算子 $\\mathbf{L}_k$ 是：\n$$\\mathbf{L}_k = I \\otimes \\cdots \\otimes I \\otimes \\underbrace{(\\mathcal{D}I)}_{k\\text{-th position}} \\otimes I \\otimes \\cdots \\otimes I$$\n这个算子 $\\mathbf{L}_k$ 是一个大小为 $Q^d \\times N^d$ 的矩阵。\n\n问题要求的是产生所有一阶方向导数之和的复合算子。根据微分和克罗内克积的线性性质，我们记为 $\\mathbf{L}$ 的这个全局算子是各个方向导数算子的和：\n$$\\mathbf{L} = \\sum_{k=1}^{d} \\mathbf{L}_k$$\n代入 $\\mathbf{L}_k$ 的表达式，我们得到：\n$$\\mathbf{L} = \\sum_{k=1}^{d} \\left( I \\otimes \\cdots \\otimes I \\otimes (\\mathcal{D}I) \\otimes I \\otimes \\cdots \\otimes I \\right)$$\n其中项 $(\\mathcal{D}I)$ 出现在克罗内克积的第 $k$ 个位置，对应于求和中的第 $k$ 项。此表达式纯粹用一维算子 $I$ 和 $\\mathcal{D}$ 以及克罗内克积表示，符合要求。它代表了梯度算子的“求和因子分解”形式，这种形式常用于谱元法和DG方法中以进行高效计算。",
            "answer": "$$\\boxed{\\sum_{k=1}^{d} \\left( I \\otimes \\cdots \\otimes I \\otimes (\\mathcal{D}I) \\otimes I \\otimes \\cdots \\otimes I \\right) \\quad \\text{其中 } (\\mathcal{D}I) \\text{ 是乘积中的第 } k\\text{ 项}}$$"
        },
        {
            "introduction": "构建算子之后，下一步是在Galerkin框架内应用它，这通常需要进行数值积分。本练习将探讨被积函数中的多项式结构如何决定了精确积分所需的最少正交点数。对于任何希望在保证精度的同时实现高效计算的实践者来说，这是至关重要的一步。",
            "id": "3422359",
            "problem": "考虑参考超立方体 $\\hat{K} = [-1,1]^d$（其中 $d \\ge 2$）上的张量积多项式空间 $Q_p$，该空间定义为在每个坐标方向上次数最高为 $p$ 的多项式空间。设 $\\{\\phi_i\\}$ 是 $Q_p$ 的一组基，并考虑一个从 $\\hat{K}$ 到物理单元 $K$ 的仿射映射，该映射的雅可比矩阵和度量项在 $K$ 上为常数。对于标量泊松问题，使用标准的 Galerkin 公式，单元质量和刚度算子定义为\n$$\nM_{ij} = \\int_{K} \\phi_i \\, \\phi_j \\, \\mathrm{d}x, \n\\qquad\nA_{ij} = \\int_{K} \\nabla \\phi_i \\cdot \\nabla \\phi_j \\, \\mathrm{d}x.\n$$\n假设 $M_{ij}$ 和 $A_{ij}$ 都通过在每个坐标方向上使用相同数量（$q$ 个）求积点的张量积高斯求积法进行计算。在一维情况下，使用 $q$ 个点的高斯求积法则可以精确地积分最高达到某个次数的多项式。在多维情况下，张量积求积法可以精确地积分单变量多项式的张量积，其在每个坐标方向上的次数需满足相应的要求。\n\n仅从上述定义和一维高斯求积的标准精确性性质出发，并利用作为求和因子分解基础的张量积可分性，推导在维度 $d \\ge 2$ 的仿射单元上使用 $Q_p$ 基函数时，保证对所有 $i,j$ 的 $M_{ij}$ 和 $A_{ij}$ 进行精确计算的关于 $q$ 的最小精确性条件。清楚地说明 $M_{ij}$ 和 $A_{ij}$ 的被积函数中出现的最高多项式次数如何决定每个方向上的求积要求，并用此确定每个算子所需的最小整数 $q$。\n\n将你的最终答案表示为一个行矩阵 $\\big(q_{\\text{mass}} \\;\\; q_{\\text{stiff}}\\big)$，其中 $q_{\\text{mass}}$ 和 $q_{\\text{stiff}}$ 分别是为确保质量和刚度算子精确性所需的每个坐标方向上的最小高斯点数。最终答案无需四舍五入，也不应包含单位。",
            "solution": "该问题要求确定在仿射超立方体单元上，对标量泊松问题使用 $Q_p$ 多项式基时，为精确计算单元质量矩阵 $M_{ij}$ 和刚度矩阵 $A_{ij}$ 所需的每个坐标方向上的最小高斯求积点数 $q$。分析过程如下：首先将定义积分变换到参考单元上，然后确定被积函数在任意单个坐标方向上的最高多项式次数。\n\n设从参考超立方体 $\\hat{K} = [-1,1]^d$ 到物理单元 $K$ 的仿射映射为 $\\mathbf{x} = F(\\hat{\\mathbf{x}})$。由于该映射是仿射的，变换的雅可比矩阵 $J$ 是一个常数矩阵。因此，其行列式 $|\\det(J)|$ 也是一个常数。物理单元 $K$ 上的基函数 $\\phi_i$ 与参考单元 $\\hat{K}$ 上的基函数 $\\hat{\\phi}_i$ 通过复合关系相关联，即 $\\phi_i = \\hat{\\phi}_i \\circ F^{-1}$。基函数 $\\{\\hat{\\phi}_i\\}$ 是 $Q_p$ 空间中的多项式，这意味着对于 $k \\in \\{1, 2, \\dots, d\\}$，它们在每个坐标 $\\hat{x}_k$ 上的次数最高为 $p$。\n\n一个具有 $q$ 个点的一维高斯求积法则对于次数最高为 $2q-1$ 的多项式是精确的。对于张量积域上的多维积分，一个在 $d$ 个方向上各有 $q$ 个点的张量积高斯求积法是精确的，当且仅当被积函数在每个坐标变量上分别是一个次数最高为 $2q-1$ 的多项式。因此，为求得所需的最小 $q$ 值，我们必须找出被积函数在任意单个坐标方向上的最高多项式次数 $D$。精确性的条件是 $2q - 1 \\ge D$，这意味着最小整数 $q$ 由 $q = \\lceil \\frac{D+1}{2} \\rceil$ 给出。\n\n首先，我们分析质量矩阵 $M_{ij}$。\n质量矩阵元素的积分为：\n$$\nM_{ij} = \\int_{K} \\phi_i(\\mathbf{x}) \\, \\phi_j(\\mathbf{x}) \\, \\mathrm{d}\\mathbf{x}\n$$\n将此积分变换到参考单元 $\\hat{K}$ 上，得到：\n$$\nM_{ij} = \\int_{\\hat{K}} \\hat{\\phi}_i(\\hat{\\mathbf{x}}) \\, \\hat{\\phi}_j(\\hat{\\mathbf{x}}) \\, |\\det(J)| \\, \\mathrm{d}\\hat{\\mathbf{x}}\n$$\n由于 $|\\det(J)|$ 是一个常数，被积函数的多项式部分是乘积 $\\hat{\\phi}_i(\\hat{\\mathbf{x}}) \\, \\hat{\\phi}_j(\\hat{\\mathbf{x}})$。$\\hat{\\phi}_i$ 和 $\\hat{\\phi}_j$ 都属于 $Q_p$ 空间，这意味着它们在每个坐标 $\\hat{x}_k$ 上的次数最高为 $p$。两个这样的多项式相乘，在每个坐标方向上的次数最高为 $p+p=2p$。因此，质量矩阵被积函数在任意坐标方向上的最高次数为 $D_{\\text{mass}} = 2p$。\n\n为确保精确积分，每个方向上的求积点数 $q_{\\text{mass}}$ 必须满足：\n$$\n2q_{\\text{mass}} - 1 \\ge D_{\\text{mass}} = 2p\n$$\n$$\n2q_{\\text{mass}} \\ge 2p + 1\n$$\n$$\nq_{\\text{mass}} \\ge p + \\frac{1}{2}\n$$\n由于 $q_{\\text{mass}}$ 必须是整数，所需的最小点数为 $q_{\\text{mass}} = p+1$。\n\n接下来，我们分析刚度矩阵 $A_{ij}$。\n刚度矩阵元素的积分为：\n$$\nA_{ij} = \\int_{K} \\nabla_{\\mathbf{x}} \\phi_i(\\mathbf{x}) \\cdot \\nabla_{\\mathbf{x}} \\phi_j(\\mathbf{x}) \\, \\mathrm{d}\\mathbf{x}\n$$\n根据链式法则，梯度算子的变换关系为 $\\nabla_{\\mathbf{x}} = (J^{-1})^T \\nabla_{\\hat{\\mathbf{x}}}$。参考单元上的积分变为：\n$$\nA_{ij} = \\int_{\\hat{K}} \\left((J^{-1})^T \\nabla_{\\hat{\\mathbf{x}}} \\hat{\\phi}_i(\\hat{\\mathbf{x}})\\right) \\cdot \\left((J^{-1})^T \\nabla_{\\hat{\\mathbf{x}}} \\hat{\\phi}_j(\\hat{\\mathbf{x}})\\right) \\, |\\det(J)| \\, \\mathrm{d}\\hat{\\mathbf{x}}\n$$\n这可以写成：\n$$\nA_{ij} = \\int_{\\hat{K}} (\\nabla_{\\hat{\\mathbf{x}}} \\hat{\\phi}_i)^T G (\\nabla_{\\hat{\\mathbf{x}}} \\hat{\\phi}_j) \\, |\\det(J)| \\, \\mathrm{d}\\hat{\\mathbf{x}}\n$$\n其中 $G = J^{-1} (J^{-1})^T$ 是一个常数矩阵，因为对于仿射映射，$J$ 是常数。被积函数为 $I_{\\text{stiff}} = |\\det(J)| \\sum_{k=1}^d \\sum_{l=1}^d G_{kl} \\frac{\\partial \\hat{\\phi}_i}{\\partial \\hat{x}_k} \\frac{\\partial \\hat{\\phi}_j}{\\partial \\hat{x}_l}$。\n我们必须确定 $I_{\\text{stiff}}$ 在任意单个坐标方向（比如 $\\hat{x}_m$）上的最高多项式次数。和的次数是其各项次数的最大值。让我们分析单项 $\\frac{\\partial \\hat{\\phi}_i}{\\partial \\hat{x}_k} \\frac{\\partial \\hat{\\phi}_j}{\\partial \\hat{x}_l}$ 在 $\\hat{x}_m$ 上的次数。\n函数 $\\hat{\\phi}_i \\in Q_p$ 在 $\\hat{x}_m$ 上的次数最高为 $p$。其偏导数 $\\frac{\\partial \\hat{\\phi}_i}{\\partial \\hat{x}_k}$ 在 $\\hat{x}_m$ 上的次数，当 $k=m$ 时最高为 $p-1$，当 $k \\ne m$ 时最高为 $p$。\n乘积项在 $\\hat{x}_m$ 上的次数是其因子次数之和。我们考虑 $k$ 和 $l$ 相对于 $m$ 的所有可能情况：\n1.  如果 $k=m$ 且 $l=m$：在 $\\hat{x}_m$ 上的次数最高为 $(p-1) + (p-1) = 2p-2$。\n2.  如果 $k=m$ 且 $l \\ne m$（或反之）：在 $\\hat{x}_m$ 上的次数最高为 $(p-1) + p = 2p-1$。\n3.  如果 $k \\ne m$ 且 $l \\ne m$：在 $\\hat{x}_m$ 上的次数最高为 $p + p = 2p$。\n\n这第三种情况产生了最高次数，它之所以可能，是因为维度 $d \\ge 2$，允许对 $\\hat{x}_m$ 以外的坐标进行求导。例如，当 $d=2$ 时，项 $\\frac{\\partial \\hat{\\phi}_i}{\\partial \\hat{x}_2} \\frac{\\partial \\hat{\\phi}_j}{\\partial \\hat{x}_2}$ 是被积函数的一部分。基函数 $\\hat{\\phi}_i$ 和 $\\hat{\\phi}_j$ 在 $\\hat{x}_1$ 上的次数可以高达 $p$。对 $\\hat{x}_2$ 求导不会改变它们对 $\\hat{x}_1$ 的依赖关系。因此，该乘积在 $\\hat{x}_1$ 上的次数可以高达 $2p$。这代表了被积函数和式中任意项在任意坐标方向上的最高可能次数。对于任意仿射单元（即对于任意常数矩阵 $G$），不能保证最高次项会抵消，因此整个被积函数 $I_{\\text{stiff}}$ 在任意坐标方向上的最高次数是 $D_{\\text{stiff}} = 2p$。\n\n为确保精确积分，每个方向上的求积点数 $q_{\\text{stiff}}$ 必须满足：\n$$\n2q_{\\text{stiff}} - 1 \\ge D_{\\text{stiff}} = 2p\n$$\n$$\n2q_{\\text{stiff}} \\ge 2p + 1\n$$\n$$\nq_{\\text{stiff}} \\ge p + \\frac{1}{2}\n$$\n由于 $q_{\\text{stiff}}$ 必须是整数，所需的最小点数为 $q_{\\text{stiff}} = p+1$。\n\n总而言之，对于维度 $d \\ge 2$ 和仿射单元映射，质量矩阵被积函数的每坐标最高多项式次数为 $2p$，刚度矩阵被积函数的也是 $2p$。两者为实现精确计算，在每个方向上需要相同数量的最小高斯求积点数。\n质量算子所需的最小点数为 $q_{\\text{mass}} = p+1$。\n刚度算子所需的最小点数为 $q_{\\text{stiff}} = p+1$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\np+1 & p+1\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "求和因子分解法的主要优势在于其卓越的计算性能。本练习提供了一个动手建模与比较传统显式矩阵组装和无矩阵求和因子分解法性能的机会。通过在CPU和GPU架构上应用roofline模型，你将能够量化求和因子分解法显示其优越性的交叉点，从而深刻体会其在高性能计算中的实际影响力。",
            "id": "3422374",
            "problem": "考虑在张量积六面体单元上，使用位于 Gauss-Lobatto-Legendre 点的配置拉格朗日基进行的三维间断 Galerkin (DG) 离散化。设多项式阶数为 $p$，定义 $m = p + 1$ 为每个轴上的一维点数，$n = m^3$ 为每个单元的自由度数。重点是在参考单元上逐单元应用对称泊松算子。将比较两种策略：(1) 显式组装单元刚度矩阵，然后进行稠密矩阵向量乘法；以及 (2) 使用一维变换序列的求和分解 (Sum Factorization, SF) 无矩阵应用。\n\n基本原理如下：\n- 张量积结构：基是可分离的，因此三维微分算子的应用可以分解为一维运算序列。\n- 求和分解：在 $d = 3$ 维中，通过在每个轴上应用 $D^\\top W D$ 的拉普拉斯算子分解应用，利用沿各轴线的一维运算，将应用算子的算术运算量从 $O(n^2)$ 减少到 $O(d\\,m^{d+1})$。\n- Roofline 性能模型：执行时间由 $T = \\max\\left(\\frac{F}{P}, \\frac{B}{\\beta}\\right)$ 建模，其中 $F$ 是浮点运算次数， $P$ 是峰值浮点吞吐量（单位：每秒浮点运算次数，flops/s），$B$ 是主存与处理器之间移动的字节数，$\\beta$ 是持续内存带宽（单位：每秒字节数，B/s）。对于此问题，所有算术运算均为双精度，因此每次标量读取或写入占用 8 字节。\n\n你需要使用 Roofline 模型对每个单元的以下内容进行建模：\n- 显式组装：\n  - 组装浮点运算次数 $F_\\mathrm{asm} = 3 m^6$ 和组装字节数 $B_\\mathrm{asm} = n^2 \\cdot 8 = m^6 \\cdot 8$。\n  - 稠密矩阵向量乘法浮点运算次数 $F_\\mathrm{spmv} = 2 n^2 = 2 m^6$ 和字节数 $B_\\mathrm{spmv} = n^2 \\cdot 8 + n \\cdot 8 + n \\cdot 8 = m^6 \\cdot 8 + 2 m^3 \\cdot 8$。\n  - 每个单元的显式路径时间 $T_\\mathrm{explicit}(m) = T_\\mathrm{asm}(m) + T_\\mathrm{spmv}(m)$，其中 $T_\\mathrm{asm}(m) = \\max\\left(\\frac{F_\\mathrm{asm}}{P}, \\frac{B_\\mathrm{asm}}{\\beta}\\right)$ 且 $T_\\mathrm{spmv}(m) = \\max\\left(\\frac{F_\\mathrm{spmv}}{P}, \\frac{B_\\mathrm{spmv}}{\\beta}\\right)$。\n- 求和分解无矩阵应用：\n  - 浮点运算次数 $F_\\mathrm{mf} = 12 m^4$，基于每个轴（共 3 个轴）上两次一维矩阵向量乘积（前向导数和带权重的伴随）。\n  - 字节数 $B_\\mathrm{mf} = 2 n \\cdot 8 = 16 m^3$，用于读取输入向量和写入输出向量。\n  - 每个单元的无矩阵时间 $T_\\mathrm{mf}(m) = \\max\\left(\\frac{F_\\mathrm{mf}}{P}, \\frac{B_\\mathrm{mf}}{\\beta}\\right)$。\n- 每次运行中与架构相关的一次性开销：\n  - 中央处理器 (CPU)：除每个单元的时间外，无额外开销。\n  - 图形处理器 (GPU)：算子常数 $D$ 和 $W$ 的一次性主机到设备传输，字节数为 $B_\\mathrm{transfer}(m) = \\left(3 m^2 + m\\right) \\cdot 8$，时间为 $T_\\mathrm{transfer}(m) = \\frac{B_\\mathrm{transfer}(m)}{\\beta}$。\n\n令 $E$ 表示问题中的单元数。对于每种架构，总运行时间模型如下：\n- CPU 总计：$T_\\mathrm{explicit,total}(m, E) = E \\cdot T_\\mathrm{explicit}(m)$ 和 $T_\\mathrm{mf,total}(m, E) = E \\cdot T_\\mathrm{mf}(m)$。\n- GPU 总计：$T_\\mathrm{explicit,total}(m, E) = E \\cdot T_\\mathrm{explicit}(m)$ 和 $T_\\mathrm{mf,total}(m, E) = T_\\mathrm{transfer}(m) + E \\cdot T_\\mathrm{mf}(m)$。\n\n定义架构参数如下：\n- CPU：峰值吞吐量 $P_\\mathrm{CPU} = 100 \\times 10^{9}$ flops/s 和带宽 $\\beta_\\mathrm{CPU} = 50 \\times 10^{9}$ bytes/s。\n- GPU：峰值吞吐量 $P_\\mathrm{GPU} = 10 \\times 10^{12}$ flops/s 和带宽 $\\beta_\\mathrm{GPU} = 900 \\times 10^{9}$ bytes/s。\n\n任务：\n- 分别针对每种架构，从测试集中确定最小多项式阶数 $p_c \\in \\{1, 2, 3, 4, 5, 6\\}$ 和最小单元数 $E_c$，使得 $T_\\mathrm{mf,total}(m, E) \\le T_\\mathrm{explicit,total}(m, E)$ 成立。如果该不等式对多个配对 $(p, E)$ 成立，则选择最小的 $p$，并针对该 $p$ 选择最小的 $E$。如果在指定的测试集上该不等式永不成立，则对 $p$ 和 $E$ 均返回 -1。\n\n使用以下测试集范围：\n- 多项式阶数 $p \\in \\{1, 2, 3, 4, 5, 6\\}$，其中 $m = p + 1$。\n- 单元数 $E \\in \\{1, 8, 64, 512\\}$。\n\n最终输出格式：\n- 你的程序应产生单行输出，其中包含四个整数 $[p_\\mathrm{CPU}, E_\\mathrm{CPU}, p_\\mathrm{GPU}, E_\\mathrm{GPU}]$，其中 $p_\\mathrm{CPU}$ 和 $E_\\mathrm{CPU}$ 是中央处理器的交叉阶数和单元数，$p_\\mathrm{GPU}$ 和 $E_\\mathrm{GPU}$ 是图形处理器的交叉阶数和单元数。如果某个架构未找到交叉点，则该架构的两个条目均输出 -1。",
            "solution": "该问题已经过验证，被确定为是良构的、有科学依据且内部一致的。它提出了一个标准的性能建模练习，在间断 Galerkin 方法的背景下，比较了应用高阶微分算子的两种常见算法策略——显式矩阵组装与无矩阵求和分解。所有必要的公式、参数和评估标准均已提供。\n\n任务是确定对于中央处理器 (CPU) 和图形处理器 (GPU)，在何种最小多项式阶数 $p_c$ 和最小单元数 $E_c$ 下，求和分解（无矩阵）方法的计算速度开始快于显式组装方法。分析将在指定的多项式阶数 $p \\in \\{1, 2, 3, 4, 5, 6\\}$ 和单元数 $E \\in \\{1, 8, 64, 512\\}$ 的测试集上进行。每个维度的点数为 $m = p + 1$。\n\n每个操作的性能由 Roofline 模型决定，其中执行时间 $T$ 是浮点运算所需时间（计算密集型）和数据移动所需时间（内存密集型）的最大值：\n$$T = \\max\\left(\\frac{F}{P}, \\frac{B}{\\beta}\\right)$$\n此处，$F$ 是浮点运算的次数，$P$ 是峰值浮点吞吐量，$B$ 是传输的字节数，$\\beta$ 是内存带宽。所有标量均为双精度，占用 8 字节。\n\n两种架构的参数如下：\n- CPU：$P_\\mathrm{CPU} = 100 \\times 10^{9}$ flops/s, $\\beta_\\mathrm{CPU} = 50 \\times 10^{9}$ bytes/s。\n- GPU：$P_\\mathrm{GPU} = 10 \\times 10^{12}$ flops/s, $\\beta_\\mathrm{GPU} = 900 \\times 10^{9}$ bytes/s。\n\n显式方法的每个单元的时间 $T_\\mathrm{explicit}(m)$ 是组装时间 $T_\\mathrm{asm}(m)$ 和矩阵向量乘积时间 $T_\\mathrm{spmv}(m)$ 的总和。\n- 组装：$F_\\mathrm{asm} = 3 m^6$ 次浮点运算和 $B_\\mathrm{asm} = 8 m^6$ 字节。\n  $$T_\\mathrm{asm}(m) = \\max\\left(\\frac{3 m^6}{P}, \\frac{8 m^6}{\\beta}\\right)$$\n- 矩阵向量乘积：$F_\\mathrm{spmv} = 2 m^6$ 次浮点运算和 $B_\\mathrm{spmv} = 8 m^6 + 16 m^3$ 字节。\n  $$T_\\mathrm{spmv}(m) = \\max\\left(\\frac{2 m^6}{P}, \\frac{8 m^6 + 16 m^3}{\\beta}\\right)$$\n- 每个单元的总显式时间：\n  $$T_\\mathrm{explicit}(m) = T_\\mathrm{asm}(m) + T_\\mathrm{spmv}(m)$$\n\n无矩阵方法的每个单元的时间 $T_\\mathrm{mf}(m)$ 由下式给出：\n- 无矩阵应用：$F_\\mathrm{mf} = 12 m^4$ 次浮点运算和 $B_\\mathrm{mf} = 16 m^3$ 字节。\n  $$T_\\mathrm{mf}(m) = \\max\\left(\\frac{12 m^4}{P}, \\frac{16 m^3}{\\beta}\\right)$$\n\n对于 GPU，无矩阵方法的算子存在一次性数据传输成本。\n- 传输：$B_\\mathrm{transfer}(m) = (3 m^2 + m) \\cdot 8$ 字节。\n  $$T_\\mathrm{transfer}(m) = \\frac{B_\\mathrm{transfer}(m)}{\\beta_\\mathrm{GPU}}$$\n\n一个包含 $E$ 个单元的问题的总运行时间为：\n- CPU:\n  $T_\\mathrm{explicit,total}(m, E) = E \\cdot T_\\mathrm{explicit}(m)$\n  $T_\\mathrm{mf,total}(m, E) = E \\cdot T_\\mathrm{mf}(m)$\n- GPU:\n  $T_\\mathrm{explicit,total}(m, E) = E \\cdot T_\\mathrm{explicit}(m)$\n  $T_\\mathrm{mf,total}(m, E) = T_\\mathrm{transfer}(m) + E \\cdot T_\\mathrm{mf}(m)$\n\n我们从测试集中寻找最小的配对 $(p_c, E_c)$，使得 $T_\\mathrm{mf,total}(m, E) \\le T_\\mathrm{explicit,total}(m, E)$。\n\n**CPU 分析**\n\n对于 CPU，无矩阵方法具有优势的条件是：\n$$E \\cdot T_\\mathrm{mf}(m) \\le E \\cdot T_\\mathrm{explicit}(m)$$\n这可以简化为：\n$$T_\\mathrm{mf}(m) \\le T_\\mathrm{explicit}(m)$$\n该条件与单元数 $E$ 无关。我们必须找到满足此不等式的最小 $p \\in \\{1, ..., 6\\}$。然后，问题要求从测试集中找出最小的 $E$，即 $E_c = 1$。\n\n我们测试 $p=1$ 的情况，此时 $m=2$。\n使用 $P = P_\\mathrm{CPU}$ 和 $\\beta = \\beta_\\mathrm{CPU}$：\n$T_\\mathrm{asm}(2) = \\max\\left(\\frac{3 \\cdot 2^6}{100 \\cdot 10^9}, \\frac{8 \\cdot 2^6}{50 \\cdot 10^9}\\right) = \\max(1.92 \\cdot 10^{-9}, 10.24 \\cdot 10^{-9}) = 10.24 \\cdot 10^{-9}$ 秒。\n$T_\\mathrm{spmv}(2) = \\max\\left(\\frac{2 \\cdot 2^6}{100 \\cdot 10^9}, \\frac{8 \\cdot 2^6 + 16 \\cdot 2^3}{50 \\cdot 10^9}\\right) = \\max(1.28 \\cdot 10^{-9}, 12.8 \\cdot 10^{-9}) = 12.8 \\cdot 10^{-9}$ 秒。\n$T_\\mathrm{explicit}(2) = 10.24 \\cdot 10^{-9} + 12.8 \\cdot 10^{-9} = 23.04 \\cdot 10^{-9}$ 秒。\n\n$T_\\mathrm{mf}(2) = \\max\\left(\\frac{12 \\cdot 2^4}{100 \\cdot 10^9}, \\frac{16 \\cdot 2^3}{50 \\cdot 10^9}\\right) = \\max(1.92 \\cdot 10^{-9}, 2.56 \\cdot 10^{-9}) = 2.56 \\cdot 10^{-9}$ 秒。\n\n不等式 $2.56 \\cdot 10^{-9} \\le 23.04 \\cdot 10^{-9}$ 成立。\n由于在最小多项式阶数 $p=1$ 时条件即得到满足，因此 CPU 的最小交叉配对为 $(p_\\mathrm{CPU}, E_\\mathrm{CPU}) = (1, 1)$。\n\n**GPU 分析**\n\n对于 GPU，条件是：\n$$T_\\mathrm{transfer}(m) + E \\cdot T_\\mathrm{mf}(m) \\le E \\cdot T_\\mathrm{explicit}(m)$$\n这可以重排以求解 $E$：\n$$T_\\mathrm{transfer}(m) \\le E \\cdot (T_\\mathrm{explicit}(m) - T_\\mathrm{mf}(m))$$\n仅当 $T_\\mathrm{explicit}(m) > T_\\mathrm{mf}(m)$ 时存在解。如果此条件成立，则对于任何满足以下条件的 E，都会出现交叉：\n$$E \\ge \\frac{T_\\mathrm{transfer}(m)}{T_\\mathrm{explicit}(m) - T_\\mathrm{mf}(m)}$$\n我们寻找使 $T_\\mathrm{explicit}(m) > T_\\mathrm{mf}(m)$ 成立的最小 $p$，然后从其测试集中找到满足条件的最小 $E$。\n\n我们测试 $p=1$ 的情况，此时 $m=2$。\n使用 $P = P_\\mathrm{GPU}$ 和 $\\beta = \\beta_\\mathrm{GPU}$：\n$T_\\mathrm{asm}(2) = \\max\\left(\\frac{3 \\cdot 2^6}{10 \\cdot 10^{12}}, \\frac{8 \\cdot 2^6}{900 \\cdot 10^9}\\right) = \\max(1.92 \\cdot 10^{-14}, 0.569 \\cdot 10^{-9}) \\approx 0.569 \\cdot 10^{-9}$ 秒。\n$T_\\mathrm{spmv}(2) = \\max\\left(\\frac{2 \\cdot 2^6}{10 \\cdot 10^{12}}, \\frac{8 \\cdot 2^6 + 16 \\cdot 2^3}{900 \\cdot 10^9}\\right) = \\max(1.28 \\cdot 10^{-14}, 0.711 \\cdot 10^{-9}) \\approx 0.711 \\cdot 10^{-9}$ 秒。\n$T_\\mathrm{explicit}(2) \\approx 0.569 \\cdot 10^{-9} + 0.711 \\cdot 10^{-9} \\approx 1.280 \\cdot 10^{-9}$ 秒。\n\n$T_\\mathrm{mf}(2) = \\max\\left(\\frac{12 \\cdot 2^4}{10 \\cdot 10^{12}}, \\frac{16 \\cdot 2^3}{900 \\cdot 10^9}\\right) = \\max(1.92 \\cdot 10^{-14}, 0.142 \\cdot 10^{-9}) \\approx 0.142 \\cdot 10^{-9}$ 秒。\n\n条件 $T_\\mathrm{explicit}(2) > T_\\mathrm{mf}(2)$ 成立 ($1.280 \\cdot 10^{-9} > 0.142 \\cdot 10^{-9}$)。现在我们求 $E$ 的阈值。\n$T_\\mathrm{transfer}(2) = \\frac{(3 \\cdot 2^2 + 2) \\cdot 8}{900 \\cdot 10^9} = \\frac{112}{900 \\cdot 10^9} \\approx 0.124 \\cdot 10^{-9}$ 秒。\n$E \\ge \\frac{0.124 \\cdot 10^{-9}}{1.280 \\cdot 10^{-9} - 0.142 \\cdot 10^{-9}} = \\frac{0.124}{1.138} \\approx 0.109$。\n\n在测试集 $\\{1, 8, 64, 512\\}$ 中，大于或等于 $0.109$ 的最小整数值 $E$ 是 $E=1$。\n由于在最小多项式阶数 $p=1$ 时就找到了交叉点，因此 GPU 的最小交叉配对为 $(p_\\mathrm{GPU}, E_\\mathrm{GPU}) = (1, 1)$。\n\n**结论**\n分析表明，对于 CPU 和 GPU 架构，从测试集中的最低阶多项式 ($p=1$) 和最小网格尺寸 ($E=1$) 开始，求和分解方法就优于显式组装方法。\n- 对于 CPU：$p_c=1, E_c=1$。\n- 对于 GPU：$p_c=1, E_c=1$。\n因此，最终结果是 $[1, 1, 1, 1]$。",
            "answer": "$$\\boxed{[1, 1, 1, 1]}$$"
        }
    ]
}