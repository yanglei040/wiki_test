{
    "hands_on_practices": [
        {
            "introduction": "The first step in mastering matrix-free methods is to build and verify a basic operator, ensuring it performs the exact same computation as its matrix-based counterpart. This practice demystifies the concept by tasking you with implementing both the traditional assembled sparse matrix and the matrix-free operator for a linear advection problem . By comparing their outputs, you will gain concrete proof of their mathematical equivalence and appreciate how the matrix-free approach achieves this through purely local, element-level computations, avoiding the need for large, global data structures.",
            "id": "3398909",
            "problem": "Consider the one-dimensional linear advection equation with constant velocity on a periodic domain. Let the physical domain be the interval $[0,1]$, partitioned into $E$ affine elements of equal length $h = 1/E$. Each element $e$ is mapped from the reference interval $[-1,1]$ by an affine map with Jacobian $J_e = h/2$. On each element, approximate the solution by a polynomial of degree $N$ using a nodal representation at the Legendre–Gauss–Lobatto (LGL) nodes $\\{\\xi_j\\}_{j=0}^N$ with associated LGL quadrature weights $\\{w_j\\}_{j=0}^N$. Denote the Lagrange interpolating basis functions by $\\{\\phi_j(\\xi)\\}_{j=0}^N$ such that $\\phi_j(\\xi_k) = \\delta_{jk}$, and define the derivative matrix $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ on the reference interval via the identity $d u/d \\xi \\big|_{\\xi = \\xi_j} = \\sum_{k=0}^N D_{jk} u(\\xi_k)$ for any polynomial of degree at most $N$.\n\nFor a constant advection speed $a > 0$, the semi-discrete discontinuous Galerkin weak form with the upwind numerical flux on element $e$ states that, for each test function index $j \\in \\{0,\\dots,N\\}$,\n$$\n\\int_{x_{e-1/2}}^{x_{e+1/2}} \\phi_j(x) \\frac{\\partial u}{\\partial t}(x,t) \\, dx\n= -a \\int_{x_{e-1/2}}^{x_{e+1/2}} \\phi_j'(x) u(x,t) \\, dx\n+ a \\, \\phi_j(x_{e+1/2}) \\, \\hat{u}_{e+1/2} - a \\, \\phi_j(x_{e-1/2}) \\, \\hat{u}_{e-1/2},\n$$\nwhere $x_{e\\pm 1/2}$ are the physical element boundaries, the prime denotes derivative with respect to $x$, and $\\hat{u}_{e\\pm 1/2}$ is the upwind numerical trace for $u$ at the right/left element interface. On the periodic mesh and for $a>0$, the upwind numerical trace takes the left state at each interface, i.e., $\\hat{u}_{e+1/2} = u_{N}^e$ and $\\hat{u}_{e-1/2} = u_{N}^{e-1}$, where $u_j^e$ denotes the value at node index $j$ on element $e$ and $e-1$ is the left neighbor of $e$ with periodic wrapping.\n\nUse the following well-tested foundational facts:\n- The LGL nodes are the endpoints $\\xi_0 = -1$, $\\xi_N = 1$ together with the $N-1$ roots in $(-1,1)$ of the derivative of the degree-$N$ Legendre polynomial $P_N(\\xi)$.\n- The LGL quadrature weights satisfy $w_j = \\dfrac{2}{N(N+1)} \\dfrac{1}{[P_N(\\xi_j)]^2}$ for $j = 0,\\dots,N$.\n- The mass matrix on element $e$ in the nodal LGL basis is diagonal with entries $M_{jj}^e = J_e w_j$, due to collocation with LGL quadrature.\n- The derivative matrix entries for the Lagrange basis at distinct nodes $\\xi_j \\neq \\xi_k$ are given by the barycentric differentiation identity $D_{jk} = \\dfrac{\\omega_k}{\\omega_j}\\dfrac{1}{\\xi_j - \\xi_k}$, with diagonal entries $D_{jj} = -\\sum_{k\\ne j} D_{jk}$, where $\\omega_j$ are the barycentric weights $\\omega_j = \\left(\\prod_{k\\ne j}(\\xi_j - \\xi_k)\\right)^{-1}$.\n\nTask: Starting from these fundamental definitions and facts, design and implement a procedure to compare, for specified $(E,N,a)$, the actions of a matrix-free discontinuous Galerkin operator with those of a globally assembled sparse matrix operator, both representing the same semi-discrete mapping from nodal degrees of freedom to the right-hand side vector induced by the weak form. Your comparison should be performed by computing norms of differences across random test vectors.\n\nYour program must:\n1. Construct the LGL nodes and weights for a given polynomial degree $N$.\n2. Construct the derivative matrix $D$ using barycentric weights on the LGL nodes.\n3. Define a matrix-free operator application that, without assembling a global matrix, computes the semi-discrete right-hand side at each nodal degree of freedom using only element-local operations, the mass matrix diagonal, the derivative matrix, and upwind numerical fluxes with periodic boundary conditions.\n4. Assemble the global sparse matrix that represents the same semi-discrete operator mapping on the entire periodic mesh with $E$ elements, ordered by concatenating the $(N+1)$ nodes of each element.\n5. For a prescribed number of random test vectors with a fixed seed for reproducibility, compute for each vector the relative $2$-norm of the difference between the matrix-free result and the assembled sparse matrix-vector product result. For each test case, return the maximum of these relative norms.\n\nUse the following test suite (each tuple lists $(E,N,a,\\text{seed},R)$, where $R$ is the number of random vectors tested):\n- $(1,1,1.0,42,3)$: a single element, lowest order case, three random vectors.\n- $(4,3,1.0,7,5)$: a moderate number of elements and degree, five random vectors.\n- $(8,7,0.5,123,4)$: higher polynomial degree, four random vectors.\n- $(10,2,0.0,9,2)$: zero advection speed edge case, two random vectors.\n- $(3,5,2.0,100,4)$: fewer elements with higher speed, four random vectors.\n\nAngle units are not applicable since no angles are used. No physical units need be reported since the output is purely mathematical. For each test case, compute a single floating-point number equal to the maximum relative $2$-norm of the differences across its $R$ random vectors.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4,result5]\"), with each result corresponding to the test cases listed in the same order above.",
            "solution": "The problem requires the design, implementation, and verification of two computational approaches for applying the spatial operator of a discontinuous Galerkin (DG) discretization of the one-dimensional linear advection equation. The two approaches are a matrix-free method and a method based on an assembled global sparse matrix. The verification consists of comparing their outputs on random vectors and computing the maximum relative difference.\n\n### Mathematical Formulation\nThe problem considers the linear advection equation $\\frac{\\partial u}{\\partial t} + a \\frac{\\partial u}{\\partial x} = 0$ on a periodic domain $[0,1]$ with advection speed $a > 0$. The domain is partitioned into $E$ elements, and on each element, the solution is approximated by a polynomial of degree $N$. The semi-discrete weak form on an element $e$ for a test function $\\phi_j$ is given by:\n$$\n\\int_{x_e} \\phi_j \\frac{\\partial u}{\\partial t} \\, dx = -a \\int_{x_e} \\phi_j' u \\, dx + a \\, \\phi_j(x_{e+1/2}) \\, \\hat{u}_{e+1/2} - a \\, \\phi_j(x_{e-1/2}) \\, \\hat{u}_{e-1/2}\n$$\nThe left side corresponds to the mass matrix acting on the time derivative of the solution coefficients. The task is to compute the right-hand side (RHS) vector for the entire set of degrees of freedom (DOFs). Let $u^e = [u_0^e, \\dots, u_N^e]^T$ be the vector of nodal DOFs on element $e$. The global vector of DOFs $U$ is the concatenation of all $u^e$. The operator to be implemented maps $U$ to the global RHS vector $F(U)$. Let's analyze the contributions to the RHS on a single element $e$.\n\n#### Volume Integral Term\nThe first term is the volume integral, which we denote as $F_{\\text{vol}, j}^e$:\n$$\nF_{\\text{vol}, j}^e = -a \\int_{x_e} \\phi_j'(x) u(x) \\, dx\n$$\nOn element $e$, the solution is $u(x) = \\sum_{k=0}^N u_k^e \\phi_k(x)$. Substituting this into the integral gives:\n$$\nF_{\\text{vol}, j}^e = -a \\sum_{k=0}^N u_k^e \\int_{x_e} \\phi_j'(x) \\phi_k(x) \\, dx\n$$\nThe integral $\\int_{x_e} \\phi_j'(x) \\phi_k(x) \\, dx$ defines the entries of the element stiffness matrix. Transforming to the reference element $[-1,1]$ using the affine map $x(\\xi)$ with Jacobian $J_e = h/2$, where $h=1/E$: $\\phi_j'(x) = \\frac{d\\phi_j}{d\\xi}\\frac{d\\xi}{dx} = \\frac{1}{J_e}\\frac{d\\phi_j}{d\\xi}$ and $dx = J_e d\\xi$. The integral becomes:\n$$\nS^{\\text{ref}}_{jk} = \\int_{-1}^1 \\left(\\frac{1}{J_e}\\frac{d\\phi_j}{d\\xi}\\right) \\phi_k(\\xi) J_e d\\xi = \\int_{-1}^1 \\frac{d\\phi_j}{d\\xi}(\\xi) \\phi_k(\\xi) d\\xi\n$$\nThis reference stiffness matrix is independent of the element. We approximate this integral using the $N+1$-point LGL quadrature rule, which is exact for polynomials of degree up to $2N-1$. The integrand's degree is at most $2N-1$, so the quadrature is not exact in general, but it is the standard DG approach.\nUsing the property that $\\frac{d\\phi_j}{d\\xi}(\\xi) = \\sum_{l=0}^N \\frac{d\\phi_j}{d\\xi}(\\xi_l) \\phi_l(\\xi) = \\sum_{l=0}^N D_{lj} \\phi_l(\\xi)$:\n$$\nS^{\\text{ref}}_{jk} \\approx \\sum_{m=0}^N w_m \\left(\\sum_{l=0}^N D_{lj} \\phi_l(\\xi_m)\\right) \\phi_k(\\xi_m) = \\sum_{m=0}^N w_m \\left(\\sum_{l=0}^N D_{lj} \\delta_{lm}\\right) \\delta_{mk} = w_k D_{kj}\n$$\nIn matrix notation, $S^{\\text{ref}} = D^T \\text{diag}(w)$. The volume contribution to the RHS vector on element $e$ is $F_{\\text{vol}}^e = -a S^{\\text{ref}} u^e$.\n\n#### Surface (Flux) Integral Term\nThe second part of the RHS involves the numerical flux at the element boundaries, $x_{e \\pm 1/2}$:\n$$\nF_{\\text{flux}, j}^e = a \\, \\phi_j(x_{e+1/2}) \\, \\hat{u}_{e+1/2} - a \\, \\phi_j(x_{e-1/2}) \\, \\hat{u}_{e-1/2}\n$$\nThe Lagrange basis functions $\\phi_j$ are defined on the LGL nodes $\\{\\xi_k\\}_{k=0}^N$, where $\\xi_0=-1$ and $\\xi_N=1$. These map to the element boundaries $x_{e-1/2}$ and $x_{e+1/2}$ respectively. Due to the property $\\phi_j(\\xi_k)=\\delta_{jk}$, we have $\\phi_j(x_{e-1/2})=\\delta_{j0}$ and $\\phi_j(x_{e+1/2})=\\delta_{jN}$. This means the flux term is non-zero only for the first and last nodes of the element ($j=0$ and $j=N$).\nFor $a>0$, the upwind flux takes the value from the \"left\" state at an interface.\n- At the right boundary $x_{e+1/2}$: $\\hat{u}_{e+1/2} = u(x_{e+1/2}^-)$, which is the value at node $N$ on the current element $e$, so $\\hat{u}_{e+1/2} = u_N^e$.\n- At the left boundary $x_{e-1/2}$: $\\hat{u}_{e-1/2} = u(x_{e-1/2}^-)$, which is the value at node $N$ on the neighboring element to the left, $e-1$. Due to periodicity, if $e=0$, $e-1$ corresponds to element $E-1$. Thus, $\\hat{u}_{e-1/2} = u_N^{e-1}$.\nThe flux contributions are:\n- For node $j=0$: $-a \\cdot 1 \\cdot \\hat{u}_{e-1/2} = -a u_N^{e-1}$.\n- For node $j=N$: $a \\cdot 1 \\cdot \\hat{u}_{e+1/2} = a u_N^e$.\n\n### Algorithmic Implementation Strategy\n\n#### Foundational Components\nThe implementation starts by constructing the necessary building blocks for a given polynomial degree $N$:\n1.  **LGL Nodes and Weights**: The nodes $\\{\\xi_j\\}$ are found as the union of $\\{-1, 1\\}$ and the roots of the derivative of the Legendre polynomial $P_N(\\xi)$, which are equivalent to the roots of the Jacobi polynomial $P_{N-1}^{(1,1)}(\\xi)$. The weights $\\{w_j\\}$ are computed via the provided formula.\n2.  **Derivative Matrix**: The reference derivative matrix $D$ is constructed using the given barycentric formula, $D_{jk} = \\frac{\\omega_k}{\\omega_j}\\frac{1}{\\xi_j - \\xi_k}$, and $D_{jj} = -\\sum_{k\\ne j} D_{jk}$. The barycentric weights $\\omega_j = (\\prod_{k\\ne j}(\\xi_j - \\xi_k))^{-1}$ are computed carefully using logarithms to maintain numerical stability.\n\n#### Matrix-Free Operator\nThis operator computes the action $F(U)$ directly without forming a global matrix. It iterates through each of the $E$ elements:\n1.  For each element $e$, extract the local DOF vector $u^e$ from the global vector $U$.\n2.  Compute the volume term: $F_{\\text{vol}}^e = -a (D^T \\text{diag}(w)) u^e$.\n3.  Identify the upwind neighbor's DOF, $u_N^{e-1}$.\n4.  Add the flux contributions: subtract $a u_N^{e-1}$ from the first component of $F_{\\text{vol}}^e$, and add $a u_N^e$ to the last component.\n5.  The resulting vector is the RHS contribution from element $e$, which is stored in the corresponding segment of the global RHS vector $F(U)$.\n\n#### Assembled Matrix Operator\nThis approach explicitly constructs the global $E(N+1) \\times E(N+1)$ sparse matrix $L$ such that $F(U) = L U$.\n1.  Initialize a sparse matrix (e.g., in LIL format for efficient construction).\n2.  Iterate through each element $e$:\n    a.  **Volume part**: The local operator $-a S^{\\text{ref}} = -a D^T \\text{diag}(w)$ is a dense $(N+1) \\times (N+1)$ block. This block is added to the diagonal block of $L$ corresponding to element $e$.\n    b.  **Flux part**: The flux terms create couplings between adjacent elements. For each element $e$:\n        i.  The term $a u_N^e$ adds to the entry in $L$ at the row and column corresponding to the global index of node $N$ on element $e$.\n        ii. The term $-a u_N^{e-1}$ adds to the entry in $L$ at the row for node $0$ on element $e$ and the column for node $N$ on element $e-1$.\n3.  Convert the matrix to an efficient format for matrix-vector products (e.g., CSR).\n\n#### Verification\nFor each test case, $R$ random vectors $U_i$ are generated. The operator action is computed using both methods, yielding $y_{\\text{free},i}$ and $y_{\\text{mat},i} = L U_i$. The relative 2-norm of the difference, $\\frac{\\|y_{\\text{free},i} - y_{\\text{mat},i}\\|_2}{\\|y_{\\text{mat},i}\\|_2}$, is computed. The maximum of these norms over the $R$ vectors is reported. For the special case $a=0$, both methods yield a zero vector, so the difference is zero, and the relative error is taken to be $0$.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_jacobi, eval_legendre\nfrom scipy.sparse import lil_matrix\n\ndef get_lgl_nodes_weights(N):\n    \"\"\"\n    Computes the Legendre-Gauss-Lobatto (LGL) nodes and weights for a given\n    polynomial degree N.\n    \"\"\"\n    if N == 0:\n        return np.array([-1.0]), np.array([2.0])\n    if N == 1:\n        nodes = np.array([-1.0, 1.0])\n        weights = np.array([1.0, 1.0])\n        return nodes, weights\n\n    # Interior nodes are roots of P_N'(x), which are roots of Jacobi P_{N-1}^{(1,1)}(x)\n    interior_nodes, _ = roots_jacobi(N - 1, 1, 1)\n    nodes = np.concatenate(([-1.0], interior_nodes, [1.0]))\n\n    # Weights from the formula w_j = 2 / (N(N+1) [P_N(xi_j)]^2)\n    poly_vals = eval_legendre(N, nodes)\n    weights = 2.0 / (N * (N + 1) * poly_vals**2)\n    \n    return nodes, weights\n\ndef get_derivative_matrix(N, nodes):\n    \"\"\"\n    Computes the nodal derivative matrix D on the reference element using\n    the provided barycentric weight formula.\n    \"\"\"\n    if N == 0:\n        return np.array([[0.0]])\n    \n    D = np.zeros((N + 1, N + 1))\n    omega = np.zeros(N + 1)\n\n    # Compute barycentric weights omega_j = (product_{k!=j} (xi_j - xi_k))^{-1}\n    # This is done using logarithms to avoid numerical overflow/underflow.\n    for j in range(N + 1):\n        log_abs_prod = np.sum(np.log(np.abs(nodes[j] - np.delete(nodes, j))))\n        # The sign of the product is (-1)^(N-j) for ordered nodes.\n        # The sign of omega_j is the same.\n        sign = (-1.0)**(N - j)\n        omega[j] = sign / np.exp(log_abs_prod)\n\n    # Off-diagonal entries: D_jk = (omega_k/omega_j) / (xi_j - xi_k)\n    for j in range(N + 1):\n        for k in range(N + 1):\n            if j != k:\n                D[j, k] = (omega[k] / omega[j]) / (nodes[j] - nodes[k])\n\n    # Diagonal entries: D_jj = -sum_{k!=j} D_jk\n    for j in range(N + 1):\n        D[j, j] = -np.sum(D[j, :])\n        \n    return D\n\ndef matrix_free_operator(U, E, N, a, D, w):\n    \"\"\"\n    Computes the action of the DG operator in a matrix-free fashion.\n    \"\"\"\n    dofs = E * (N + 1)\n    rhs = np.zeros(dofs)\n    \n    if np.isclose(a, 0.0):\n        return rhs\n\n    U_mat = U.reshape((E, N + 1))\n    \n    # Reference stiffness matrix S_ref = D^T @ diag(w)\n    # This is efficiently computed by scaling columns of D^T by w.\n    S_ref = D.T * w\n\n    for e in range(E):\n        u_e = U_mat[e, :]\n        \n        # Volume term contribution\n        vol_term = -a * (S_ref @ u_e)\n        \n        # Flux term contribution (upwind for a > 0)\n        e_prev = (e - 1 + E) % E\n        u_left_neighbor_val = U_mat[e_prev, N]  # u_N from element e-1\n        u_self_right_val = u_e[N]               # u_N from element e\n        \n        flux_term_at_0 = -a * u_left_neighbor_val\n        flux_term_at_N = a * u_self_right_val\n        \n        # Combine local contributions\n        rhs_e = vol_term\n        rhs_e[0] += flux_term_at_0\n        rhs_e[N] += flux_term_at_N\n        \n        # Place into global RHS vector\n        rhs[e * (N + 1):(e + 1) * (N + 1)] = rhs_e\n        \n    return rhs\n\ndef assemble_global_matrix(E, N, a, D, w):\n    \"\"\"\n    Assembles the global sparse matrix for the DG operator.\n    \"\"\"\n    dofs = E * (N + 1)\n    L_global = lil_matrix((dofs, dofs))\n\n    if np.isclose(a, 0.0):\n        return L_global.tocsr()\n\n    S_ref = D.T * w\n    local_op_block = -a * S_ref\n\n    for e in range(E):\n        start_idx = e * (N + 1)\n        end_idx = (e + 1) * (N + 1)\n        \n        # Add volume term (block diagonal part)\n        L_global[start_idx:end_idx, start_idx:end_idx] = local_op_block\n        \n        # Add flux terms (off-diagonal and diagonal-modifying part)\n        e_prev = (e - 1 + E) % E\n        \n        # Contribution from left neighbor to node j=0\n        row_idx_0 = start_idx\n        col_idx_neighbor = e_prev * (N + 1) + N\n        L_global[row_idx_0, col_idx_neighbor] += -a\n        \n        # Contribution from self to node j=N\n        row_idx_N = start_idx + N\n        col_idx_self = start_idx + N\n        L_global[row_idx_N, col_idx_self] += a\n        \n    return L_global.tocsr()\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and compare operator implementations.\n    \"\"\"\n    test_cases = [\n        (1, 1, 1.0, 42, 3),\n        (4, 3, 1.0, 7, 5),\n        (8, 7, 0.5, 123, 4),\n        (10, 2, 0.0, 9, 2),\n        (3, 5, 2.0, 100, 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        E, N, a, seed, R = case\n        \n        rel_diffs = []\n        \n        # Pre-compute DG basis components for the given degree N\n        nodes, weights = get_lgl_nodes_weights(N)\n        D = get_derivative_matrix(N, nodes)\n        \n        # Assemble the global sparse matrix for this test case\n        L_global = assemble_global_matrix(E, N, a, D, weights)\n        \n        # Use a reproducible random number generator for this case\n        rng = np.random.default_rng(seed)\n        \n        for _ in range(R):\n            U_rand = rng.random(E * (N + 1))\n            \n            y_free = matrix_free_operator(U_rand, E, N, a, D, weights)\n            y_mat = L_global @ U_rand\n            \n            diff_norm = np.linalg.norm(y_free - y_mat)\n            y_mat_norm = np.linalg.norm(y_mat)\n            \n            if y_mat_norm > 1e-15:\n                rel_diff = diff_norm / y_mat_norm\n            else:\n                # If true result is zero vector, relative error is 0 if difference is also zero.\n                rel_diff = 0.0 if diff_norm < 1e-15 else np.inf\n\n            rel_diffs.append(rel_diff)\n\n        results.append(max(rel_diffs))\n        \n    print(f\"[{','.join(f'{r:.12e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Real-world fluid dynamics and wave propagation problems are inherently nonlinear, introducing challenges not seen in linear models. This practice moves beyond simple advection to the nonlinear conservation law $u_t + \\partial_x(u^3) = 0$, where the interaction of high-order polynomials and nonlinear fluxes can lead to aliasing-driven instabilities . You will implement and compare a standard but potentially unstable operator against advanced, stabilized techniques—split-form operators and modal filtering—to understand how to design robust matrix-free methods for practical applications.",
            "id": "3399016",
            "problem": "Consider the one-dimensional scalar conservation law $u_t + \\partial_x f(u) = 0$ with $f(u) = u^3$ on the periodic domain $x \\in [0, 2\\pi]$. Use a Discontinuous Galerkin Spectral Element Method (DGSEM) with Legendre–Gauss–Lobatto (LGL) collocation, polynomial degree $p$, and $N = p+1$ nodal points per element. Let the mesh consist of $E$ uniform elements, with a mapping from the reference interval $\\xi \\in [-1,1]$ to each physical element $x \\in [x_L, x_R]$ given by $x(\\xi) = \\tfrac{1}{2} (x_R + x_L) + \\tfrac{1}{2} (x_R - x_L) \\, \\xi$. The Jacobian is constant per element: $J = \\tfrac{x_R - x_L}{2}$. Assume periodic boundary conditions.\n\nWork in a matrix-free fashion using the Summation-By-Parts (SBP) structure at the discrete LGL collocation points:\n- Let $\\{ \\xi_i, w_i \\}_{i=0}^{N-1}$ denote the LGL nodes and quadrature weights on $[-1,1]$, with quadrature exactness for polynomials up to degree $2p-1$.\n- Let $D \\in \\mathbb{R}^{N \\times N}$ be the nodal differentiation matrix of the Lagrange interpolants at the LGL nodes, and define the SBP matrix $Q = W D$, where $W = \\mathrm{diag}(w_0,\\ldots,w_{N-1})$ is the diagonal quadrature weight matrix. Let $B = \\mathrm{diag}(-1, 0, \\ldots, 0, +1)$.\n- The standard strong-form DGSEM semidiscrete operator for $u_t + \\partial_x f(u) = 0$ (per element) is\n$$\n\\frac{d \\boldsymbol{u}}{dt} \\;=\\; - \\frac{2}{J} \\, W^{-1} \\left( Q \\, \\boldsymbol{f} \\;-\\; B \\, \\boldsymbol{f}^{\\ast} \\right),\n$$\nwhere $\\boldsymbol{u} = (u(\\xi_0),\\ldots,u(\\xi_{N-1}))^\\top$, $\\boldsymbol{f} = (f(u(\\xi_0)), \\ldots, f(u(\\xi_{N-1})))^\\top$, and the numerical flux $\\boldsymbol{f}^{\\ast}$ has nonzero entries only at the end points and is built from interface fluxes between neighboring elements. For periodicity, the left face of the first element interfaces with the right face of the last element.\n\nDefine the following three matrix-free high-order operator variants under under-integrated quadrature (i.e., using only the LGL rule):\n1. Consistent collocation DGSEM: Use the strong-form operator above with the Rusanov (local Lax–Friedrichs) numerical flux at interfaces,\n$$\nf^{\\mathrm{num}}(u^-, u^+) = \\tfrac{1}{2} \\big( f(u^-) + f(u^+) \\big) \\;-\\; \\tfrac{1}{2} \\, \\alpha \\, (u^+ - u^-), \\quad \\alpha = \\max\\left( |f'(u^-)|, |f'(u^+)| \\right),\n$$\nwhere $f'(u) = 3 u^2$.\n2. Split-form (entropy-conservative flux differencing) DGSEM: Replace the volume term by a flux-differencing form using a symmetric two-point entropy-conservative flux $F^{\\mathrm{ec}}(u,v)$ for $f(u)=u^3$. Use\n$$\nF^{\\mathrm{ec}}(u,v) = \\frac{\\Psi(v) - \\Psi(u)}{v-u}, \\quad \\Psi'(u) = f(u), \\quad \\Psi(u) = \\frac{u^4}{4},\n$$\nwhich evaluates to\n$$\nF^{\\mathrm{ec}}(u,v) \\;=\\; \\frac{u^3 + u^2 v + u v^2 + v^3}{4}.\n$$\nThe semidiscrete operator per element is\n$$\n\\frac{d \\boldsymbol{u}}{dt} \\;=\\; - \\frac{2}{J} \\, W^{-1} \\left( \\boldsymbol{s} \\;-\\; B \\, \\boldsymbol{f}^{\\ast} \\right), \\quad s_i = \\sum_{j=0}^{N-1} Q_{ij} \\, \\big( 2 \\, F^{\\mathrm{ec}}(u_i, u_j) \\big),\n$$\nwith the same Rusanov interface flux as in the consistent form.\n3. Filtered consistent form: Compute the consistent collocation DGSEM right-hand side $\\tfrac{d\\boldsymbol{u}}{dt}$ as in item $1$, then filter it per element in a Legendre modal basis using an exponential filter of order $s$ and strength $\\alpha_f$. Let $V \\in \\mathbb{R}^{N \\times N}$ be the matrix with $V_{ik} = P_k(\\xi_i)$ where $P_k$ is the Legendre polynomial of degree $k$. Define the quadrature-weighted modal coefficients $\\boldsymbol{a}$ by solving\n$$\nG \\, \\boldsymbol{a} = V^\\top W \\, \\boldsymbol{r}, \\quad G = V^\\top W V,\n$$\nfor $\\boldsymbol{r} = \\tfrac{d\\boldsymbol{u}}{dt}$, then apply the diagonal filter $\\Sigma_{kk} = \\exp\\!\\left( - \\alpha_f \\left( \\tfrac{k}{p} \\right)^s \\right)$ for $k = 0,\\ldots,p$, and reconstruct $\\widetilde{\\boldsymbol{r}} = V \\, \\Sigma \\, \\boldsymbol{a}$. Use $\\widetilde{\\boldsymbol{r}}$ as the filtered right-hand side.\n\nUnder-integrated quadrature arises because the LGL rule of degree $2p-1$ is used to approximate volume terms whose exact polynomial degree would be higher for nonlinear fluxes, e.g., $f(u) = u^3$ combined with derivatives of basis functions, which can give degrees up to $4p-1$. This can introduce aliasing errors and spurious energy production in the consistent collocation form. The split-form flux differencing and filtering approaches aim to mitigate such issues.\n\nLet the initial condition be the smooth periodic function\n$$\nu(x,0) \\;=\\; 0.5 + 0.25 \\sin(x) + 0.1 \\sin(2x).\n$$\nDefine the discrete quadrature-based energy as\n$$\nE(\\boldsymbol{u}) \\;=\\; \\frac{1}{2} \\sum_{e=1}^{E} \\left( J \\, \\boldsymbol{u}_e^\\top \\, W \\, \\boldsymbol{u}_e \\right),\n$$\nand define the instantaneous energy production rate of a semidiscrete operator $\\mathcal{R}(\\boldsymbol{u})$ by\n$$\n\\dot{E}(\\boldsymbol{u}) \\;=\\; \\sum_{e=1}^{E} \\left( \\frac{J}{2} \\, \\boldsymbol{u}_e^\\top \\, W \\, \\mathcal{R}(\\boldsymbol{u}_e) \\right).\n$$\nFor each operator variant above, compute $\\dot{E}(\\boldsymbol{u}(x,0))$ at $t=0$ using only the LGL quadrature for all volume terms (i.e., under-integration), and periodic Rusanov interface fluxes.\n\nImplement the entire calculation in a single program, strictly matrix-free at the element level (i.e., apply $Q$, $W$, and fluxes by local algebra without assembling global matrices). Use the following parameters for the test suite:\n- Domain: $[0, 2\\pi]$.\n- Number of elements: $E = 6$.\n- Polynomial degrees: $p \\in \\{2, 4, 8\\}$, hence $N = p+1 \\in \\{3, 5, 9\\}$.\n- Filter parameters for the filtered consistent form: $\\alpha_f = 18$ and $s = 8$.\n\nTest suite and required outputs:\n- For each $p \\in \\{2,4,8\\}$, compute the instantaneous energy production rate $\\dot{E}$ at $t=0$ for the three methods in the order: consistent collocation DGSEM, split-form flux-differencing DGSEM, filtered consistent DGSEM.\n- The program should produce a single line of output containing these $9$ results as a comma-separated list enclosed in square brackets, in scientific notation with exactly six digits after the decimal point, ordered by increasing $p$ and, within each $p$, by the method order specified above. For example, the output format must be\n$[\\mathrm{v}_1,\\mathrm{v}_2,\\ldots,\\mathrm{v}_9]$\nwith each $\\mathrm{v}_k$ a float printed as, e.g., $-1.234567\\mathrm{e}{-03}$.\n\nNotes and constraints:\n- All angles are in radians.\n- There are no physical units in this problem; all quantities are nondimensional.\n- Your implementation must calculate LGL nodes and weights, the nodal differentiation matrix by barycentric weights, the SBP matrix $Q = W D$, and must remain matrix-free at the global level.\n- Under-integration is mandatory: do not use over-integration for volume terms.\n- The program must not require any input and must print only the single line with the results in the specified format.",
            "solution": "The user wants to solve a numerical analysis problem.\n\n### Step 1: Extract Givens\nThe problem asks to compute the instantaneous energy production rate for three variants of a Discontinuous Galerkin Spectral Element Method (DGSEM) for the scalar conservation law $\\partial_t u + \\partial_x f(u) = 0$.\n\n- **PDE and Domain:**\n  - Equation: $u_t + \\partial_x f(u) = 0$\n  - Flux function: $f(u) = u^3$\n  - Domain: $x \\in [0, 2\\pi]$, periodic.\n\n- **Discretization:**\n  - Method: DGSEM with Legendre-Gauss-Lobatto (LGL) collocation.\n  - Polynomial degree: $p \\in \\{2, 4, 8\\}$.\n  - Nodal points per element: $N = p+1$.\n  - Mesh: $E=6$ uniform elements.\n  - Mapping: Reference $\\xi \\in [-1,1]$ to physical $[x_L, x_R]$ by $x(\\xi) = \\tfrac{1}{2} (x_R + x_L) + \\tfrac{1}{2} (x_R - x_L) \\, \\xi$.\n  - Jacobian: $J = \\tfrac{x_R - x_L}{2}$.\n  - LGL nodes and weights on $[-1,1]$: $\\{ \\xi_i, w_i \\}_{i=0}^{N-1}$. Quadrature is exact for polynomials up to degree $2p-1$.\n  - Nodal differentiation matrix: $D \\in \\mathbb{R}^{N \\times N}$.\n  - SBP matrix: $Q = W D$, where $W = \\mathrm{diag}(w_0,\\ldots,w_{N-1})$.\n  - Boundary matrix: $B = \\mathrm{diag}(-1, 0, \\ldots, 0, +1)$.\n\n- **Initial Condition:**\n  - $u(x,0) = 0.5 + 0.25 \\sin(x) + 0.1 \\sin(2x)$.\n\n- **Operator Definitions:**\n  - **1. Consistent Collocation DGSEM:**\n    - Semidiscrete form (per element): $\\frac{d \\boldsymbol{u}}{dt} = - \\frac{2}{J} \\, W^{-1} \\left( Q \\, \\boldsymbol{f} - B \\, \\boldsymbol{f}^{\\ast} \\right)$.\n    - Interface flux: Rusanov (local Lax-Friedrichs) flux, $f^{\\mathrm{num}}(u^-, u^+) = \\tfrac{1}{2} ( f(u^-) + f(u^+) ) - \\tfrac{1}{2} \\, \\alpha \\, (u^+ - u^-)$, with $\\alpha = \\max\\left( |f'(u^-)|, |f'(u^+)| \\right)$ and $f'(u) = 3 u^2$.\n  - **2. Split-form (Entropy-Conservative) DGSEM:**\n    - Volume term replacement: $s_i = \\sum_{j=0}^{N-1} Q_{ij} \\, \\big( 2 \\, F^{\\mathrm{ec}}(u_i, u_j) \\big)$, with $F^{\\mathrm{ec}}(u,v) = \\frac{u^3 + u^2 v + u v^2 + v^3}{4}$.\n    - Semidiscrete form: $\\frac{d \\boldsymbol{u}}{dt} = - \\frac{2}{J} \\, W^{-1} \\left( \\boldsymbol{s} - B \\, \\boldsymbol{f}^{\\ast} \\right)$, with the same Rusanov interface flux.\n  - **3. Filtered Consistent Form:**\n    - Compute the consistent DGSEM RHS, $\\boldsymbol{r} = \\tfrac{d\\boldsymbol{u}}{dt}$.\n    - Filter $\\boldsymbol{r}$ per element:\n      - Solve $G \\, \\boldsymbol{a} = V^\\top W \\, \\boldsymbol{r}$ for modal coefficients $\\boldsymbol{a}$, where $G = V^\\top W V$ and $V_{ik} = P_k(\\xi_i)$ ($P_k$ is the Legendre polynomial of degree $k$).\n      - Apply diagonal filter: $\\widetilde{\\boldsymbol{a}} = \\Sigma \\boldsymbol{a}$ with $\\Sigma_{kk} = \\exp\\!\\left( - \\alpha_f \\left( \\tfrac{k}{p} \\right)^s \\right)$.\n      - Reconstruct: $\\widetilde{\\boldsymbol{r}} = V \\, \\widetilde{\\boldsymbol{a}}$.\n    - Filter parameters: $\\alpha_f = 18$, $s = 8$.\n\n- **Analysis Quantity:**\n  - Discrete energy: $E(\\boldsymbol{u}) = \\frac{1}{2} \\sum_{e=1}^{E} \\left( J \\, \\boldsymbol{u}_e^\\top \\, W \\, \\boldsymbol{u}_e \\right)$.\n  - Instantaneous energy production rate: $\\dot{E}(\\boldsymbol{u}) = \\sum_{e=1}^{E} \\left( \\frac{J}{2} \\, \\boldsymbol{u}_e^\\top \\, W \\, \\mathcal{R}(\\boldsymbol{u}_e) \\right)$, where $\\mathcal{R}(\\boldsymbol{u}_e)$ is the semidiscrete operator RHS for an element.\n\n- **Task Summary:**\n  - For each $p \\in \\{2, 4, 8\\}$, compute $\\dot{E}(\\boldsymbol{u}(x,0))$ for the three methods.\n  - The implementation must be matrix-free at the global level.\n  - All volume quadratures must be under-integrated using the LGL rule.\n  - Output a single line with 9 comma-separated values in scientific notation with 6 decimal places.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded:** The problem describes standard and advanced numerical methods (DGSEM, split-form operators, filtering) for solving hyperbolic conservation laws. These are well-established techniques in computational science and engineering. The equations for the operators, numerical fluxes, and analysis are consistent with the literature on the subject, even if some constant factors (e.g., $2/J$, $J/2$) might appear non-standard in some textbook derivations, they are explicitly given and define the mathematical problem unambiguously. The problem is grounded in the principles of numerical analysis and fluid dynamics.\n2.  **Well-Posed:** The problem is well-posed. It provides a specific initial condition, a well-defined PDE, and a complete description of three numerical schemes. All parameters ($p, E, \\alpha_f, s$) are specified. The task is to compute a specific quantity, the energy production rate at $t=0$, which is a direct calculation without time-stepping. This setup ensures a unique and meaningful solution exists.\n3.  **Objective:** The language is precise, mathematical, and free of ambiguity or subjective claims. All terms are defined via equations.\n4.  **Completeness and Consistency:** All necessary information is provided. The definitions for the operators, fluxes, energy, and energy rate are self-contained. There are no contradictions in the setup.\n5.  **Feasibility:** The required computations are complex but standard for numerical methods development and are computationally feasible within a single script. No physical impossibilities are involved.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a well-defined, self-contained, and scientifically sound exercise in numerical methods. I will proceed with the solution.\n\n### Principle-Based Design\nThe solution will be implemented by breaking down the problem into logical, reusable components based on the mathematical structure of the DGSEM.\n\n1.  **Preliminaries and Discretization Setup:**\n    The core of a DGSEM is the choice of nodal points and the resulting operators on the reference element $[-1,1]$.\n    -   **LGL Nodes and Weights:** For a given polynomial degree $p$ (with $N=p+1$ points), the Legendre-Gauss-Lobatto (LGL) nodes are the roots of $(1-\\xi^2)P'_p(\\xi)$, where $P_p$ is the Legendre polynomial of degree $p$. The corresponding quadrature weights $w_i$ can be calculated from a known formula. These will be generated by a dedicated function.\n    -   **Differentiation Matrix ($D$):** This matrix represents the differentiation of Lagrange basis polynomials defined on the LGL nodes. Its entries $D_{ij}$ have a well-known analytical form for LGL nodes, which we will implement.\n    -   **SBP Operator ($Q$):** The Summation-By-Parts operator $Q = WD$ is constructed. The property $Q+Q^T=B$ is key to the stability properties of DGSEM, linking the volume operator to the boundary terms.\n    -   **Mesh and Initial Condition:** The physical domain $[0, 2\\pi]$ is divided into $E=6$ elements. The physical coordinates of the LGL nodes in each element are found using the provided mapping. The initial condition $u(x,0)$ is then evaluated at these physical nodes to populate the global solution vector.\n\n2.  **Right-Hand Side (RHS) Evaluation ($\\mathcal{R}(\\boldsymbol{u})$):**\n    For each of the three specified methods, a function will compute the semidiscrete RHS, $\\frac{d\\boldsymbol{u}}{dt}$. This process is \"matrix-free\" at the global level, meaning we iterate over each element, perform local computations, and assemble the global RHS vector element by element without forming large global matrices.\n    -   **Element Loop:** The core of the computation is a loop over the $E$ elements.\n    -   **Interface Flux:** For each element, we need the solution values at its own boundaries and at the boundaries of its neighbors to compute the numerical flux. Due to periodicity, the left neighbor of the first element is the last element, and the right neighbor of the last element is the first. We will use the Rusanov flux as specified. The surface term contribution is then calculated as $-B \\boldsymbol{f}^{\\ast}$.\n    -   **Volume Term (Method Dependent):**\n        -   **Consistent Form:** The volume term is computed as $Q \\boldsymbol{f}$, where $\\boldsymbol{f}$ is the flux function $f(u)=u^3$ evaluated at the element's nodes.\n        -   **Split Form:** The volume term is replaced by a specialized symmetric term $\\boldsymbol{s}$, calculated using the provided two-point entropy-conservative flux $F^{\\mathrm{ec}}(u_i, u_j)$. This involves a dense $N \\times N$ calculation per element but leads to better stability properties by preventing aliasing-driven energy growth.\n    -   **Filtering (Method 3):** For the filtered method, the RHS from the consistent form is first computed. Then, it is transformed into a Legendre modal basis, a damping factor is applied to the high-mode coefficients, and the result is transformed back to the nodal basis. This requires the Legendre-Vandermonde matrix $V$ and solving a small linear system involving the mass matrix $G=V^T W V$.\n\n3.  **Energy Production Rate ($\\dot{E}$):**\n    Once the global RHS vector $\\mathcal{R}(\\boldsymbol{u})$ is computed for a given method, the instantaneous energy production rate $\\dot{E}$ is calculated using the formula provided in the problem statement. This involves another loop over the elements, where for each element, we compute the inner product $\\frac{J}{2} \\boldsymbol{u}_e^\\top W \\mathcal{R}(\\boldsymbol{u}_e)$ and sum the results. A positive $\\dot{E}$ indicates that the numerical scheme is generating energy (a source of instability), while a zero or negative rate is desirable for stability. The split-form is designed to yield a non-positive energy rate from the volume term.\n\nThe entire process is repeated for each polynomial degree $p \\in \\{2, 4, 8\\}$, and the nine resulting values for $\\dot{E}$ are collected and formatted for the final output.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import eval_legendre\nfrom numpy.polynomial.legendre import Legendre\n\ndef solve():\n    \"\"\"\n    Main solver function to compute and print the results as per the problem statement.\n    \"\"\"\n\n    # --- Helper Functions ---\n\n    def lgl_nodes_weights(p):\n        \"\"\"\n        Computes LGL nodes and weights for polynomial degree p (N=p+1 points).\n        \"\"\"\n        if p == 0:\n            return np.array([0.0]), np.array([2.0])\n        \n        # Nodes are roots of (1-x^2) * P_p'(x)\n        # Interior nodes are roots of P_p'(x)\n        leg_poly = Legendre.basis(p)\n        interior_nodes = leg_poly.deriv(1).roots()\n        \n        nodes = np.sort(np.concatenate(([-1.0], interior_nodes, [1.0])))\n\n        # Weights formula: w_j = 2 / (p(p+1) * [P_p(xi_j)]^2)\n        P_p_at_nodes = leg_poly(nodes)\n        weights = 2.0 / (p * (p + 1) * P_p_at_nodes**2)\n        \n        return nodes, weights\n\n    def diff_matrix(p, nodes):\n        \"\"\"\n        Computes the nodal differentiation matrix D for degree p at LGL nodes.\n        \"\"\"\n        N = p + 1\n        D = np.zeros((N, N))\n        \n        # Off-diagonal entries using barycentric formula for LGL\n        leg_poly = Legendre.basis(p)\n        leg_poly_nodes = leg_poly(nodes)\n        for i in range(N):\n            for j in range(N):\n                if i != j:\n                    D[i, j] = leg_poly_nodes[i] / (leg_poly_nodes[j] * (nodes[i] - nodes[j]))\n        \n        # Diagonal entries using exact formula for LGL\n        D[0, 0] = -p * (p + 1) / 4.0\n        D[N - 1, N - 1] = p * (p + 1) / 4.0\n        # Interior diagonal entries are 0 for LGL nodes\n        for i in range(1, N - 1):\n            D[i, i] = 0.0\n\n        return D\n\n    def vandermonde_matrix(p, nodes):\n        \"\"\"\n        Computes the Vandermonde matrix V_ik = P_k(xi_i) for Legendre polynomials.\n        \"\"\"\n        N = p + 1\n        V = np.zeros((N, N))\n        for k in range(N):\n            V[:, k] = eval_legendre(k, nodes)\n        return V\n\n    def rusanov_flux(u_m, u_p):\n        \"\"\"\n        Calculates the Rusanov numerical flux for f(u)=u^3.\n        \"\"\"\n        f_m, f_p = u_m**3, u_p**3\n        dfdu_m, dfdu_p = 3 * u_m**2, 3 * u_p**2\n        alpha = max(abs(dfdu_m), abs(dfdu_p))\n        return 0.5 * (f_m + f_p) - 0.5 * alpha * (u_p - u_m)\n\n    def calculate_rhs(u_global, p, E, Q, W_diag, J, method, **kwargs):\n        \"\"\"\n        Calculates the global RHS vector for a given method.\n        \"\"\"\n        N = p + 1\n        rhs_global = np.zeros_like(u_global)\n        W_inv_diag = 1.0 / W_diag\n\n        for e in range(E):\n            idx_e = slice(e * N, (e + 1) * N)\n            u_e = u_global[idx_e]\n            \n            # Neighbor data for boundary fluxes\n            e_L = (e - 1 + E) % E\n            e_R = (e + 1) % E\n            u_L_minus = u_global[e_L * N + (N-1)]\n            u_R_plus = u_global[e_R * N]\n            \n            # Interface fluxes\n            f_star_L = rusanov_flux(u_L_minus, u_e[0])\n            f_star_R = rusanov_flux(u_e[-1], u_R_plus)\n            \n            # Surface term B*f_star (here B is diag(-1, ..., 1))\n            B_f_star = np.zeros(N)\n            B_f_star[0] = -f_star_L\n            B_f_star[-1] = f_star_R\n            \n            # Volume term\n            if method in ['consistent', 'filtered']:\n                f_e = u_e**3\n                vol_term = Q @ f_e\n            elif method == 'split':\n                # F_ec(u,v) = (u^3+u^2v+uv^2+v^3)/4\n                # We need s_i = sum_j Q_ij * (2 * F_ec_ij)\n                # 2*F_ec = 0.5 * (u^3+u^2v+uv^2+v^3)\n                F_ec_mat_2 = 0.5 * (u_e[:, None]**3 + u_e[:, None]**2 * u_e[None, :] + \\\n                                   u_e[:, None] * u_e[None, :]**2 + u_e[None, :]**3)\n                vol_term = np.sum(Q * F_ec_mat_2, axis=1)\n            else:\n                raise ValueError(\"Unknown method\")\n\n            # Combine terms for elemental RHS (pre-filtering)\n            # RHS = - (2/J) * W_inv * (vol - B*f_star)\n            rhs_e = -(2.0 / J) * (W_inv_diag * (vol_term - B_f_star))\n            \n            # Apply filter if specified\n            if method == 'filtered':\n                V = kwargs['V']\n                G_inv = kwargs['G_inv']\n                alpha_f = kwargs['alpha_f']\n                s_filter = kwargs['s_filter']\n                \n                # Project to modal space: a = G_inv @ V.T @ W @ r\n                b_modal = V.T @ (W_diag * rhs_e)\n                a = G_inv @ b_modal\n                \n                # Filter coefficients\n                modes = np.arange(N)\n                sigma_diag = np.exp(-alpha_f * (modes / p)**s_filter)\n                a_filtered = sigma_diag * a\n                \n                # Reconstruct to nodal space\n                rhs_e = V @ a_filtered\n\n            rhs_global[idx_e] = rhs_e\n            \n        return rhs_global\n\n    def calculate_dot_E(u_global, rhs_global, p, E, W_diag, J):\n        \"\"\"\n        Calculates the total instantaneous energy production rate.\n        \"\"\"\n        N = p + 1\n        total_dot_E = 0.0\n        W = np.diag(W_diag)\n        for e in range(E):\n            idx_e = slice(e * N, (e + 1) * N)\n            u_e = u_global[idx_e]\n            r_e = rhs_global[idx_e]\n            \n            # From problem: dot_E = sum_e (J/2) * u_e^T * W * r_e\n            dot_E_e = (J / 2.0) * (u_e.T @ W @ r_e)\n            total_dot_E += dot_E_e\n        return total_dot_E\n\n    # --- Main Calculation ---\n\n    test_cases_p = [2, 4, 8]\n    E = 6\n    domain = [0, 2 * np.pi]\n    alpha_f = 18.0\n    s_filter = 8.0\n    \n    results = []\n\n    for p in test_cases_p:\n        N = p + 1\n        \n        # Pre-compute operators on reference element\n        xi, w = lgl_nodes_weights(p)\n        D = diff_matrix(p, xi)\n        W_diag = w\n        Q = np.diag(W_diag) @ D\n        J = (domain[1] - domain[0]) / (2.0 * E) # Jacobian J = (x_R-x_L)/2\n\n        # Pre-compute filter matrices\n        V = vandermonde_matrix(p, xi)\n        G = V.T @ np.diag(W_diag) @ V\n        G_inv = np.linalg.inv(G)\n        \n        # Set up global initial condition\n        x_boundaries = np.linspace(domain[0], domain[1], E + 1)\n        u_global = np.zeros(E * N)\n        for e in range(E):\n            x_L, x_R = x_boundaries[e], x_boundaries[e+1]\n            x_nodes_e = 0.5 * (x_L + x_R) + 0.5 * (x_R - x_L) * xi\n            u_e = 0.5 + 0.25 * np.sin(x_nodes_e) + 0.1 * np.sin(2 * x_nodes_e)\n            u_global[e*N:(e+1)*N] = u_e\n\n        # Method 1: Consistent Collocation\n        rhs_consistent = calculate_rhs(u_global, p, E, Q, W_diag, J, 'consistent')\n        dot_E_consistent = calculate_dot_E(u_global, rhs_consistent, p, E, W_diag, J)\n        results.append(dot_E_consistent)\n        \n        # Method 2: Split-form\n        rhs_split = calculate_rhs(u_global, p, E, Q, W_diag, J, 'split')\n        dot_E_split = calculate_dot_E(u_global, rhs_split, p, E, W_diag, J)\n        results.append(dot_E_split)\n\n        # Method 3: Filtered Consistent\n        # The unfiltered RHS is computed inside calculate_rhs with method='filtered'\n        rhs_filtered = calculate_rhs(u_global, p, E, Q, W_diag, J, 'filtered', \n                                     V=V, G_inv=G_inv, alpha_f=alpha_f, s_filter=s_filter)\n        dot_E_filtered = calculate_dot_E(u_global, rhs_filtered, p, E, W_diag, J)\n        results.append(dot_E_filtered)\n\n    # Format and print the final output\n    formatted_results = [f\"{res:.6e}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "After learning how to build and stabilize matrix-free operators, we confront the ultimate motivation for their use: performance. This practice shifts the focus from numerical accuracy to computational efficiency, exploring why these methods are a cornerstone of modern high-performance computing . You will develop and analyze a computational performance model to quantify key metrics like arithmetic intensity and throughput, revealing how the scalability of matrix-free operators with polynomial degree $p$ allows them to effectively utilize the capabilities of modern hardware.",
            "id": "3399013",
            "problem": "Design and implement a complete, runnable program that simulates and analyzes the scalability of matrix-free, high-order operators for the scalar Poisson problem in three dimensions using a tensor-product Discontinuous Galerkin (DG) operator with symmetric interior penalty terms. Your analysis must be purely algorithmic and mathematical, based on first principles and well-tested formulas, and must not rely on external measurements. The program must generate synthetic measurements of iteration counts, arithmetic intensity, and throughput across element size refinements in $h$ (mesh size) and increasing polynomial degree $p$, and then fit a simple performance model to these measurements.\n\nUse the following fundamental base and definitions:\n\n- Consider a unit cube domain with a structured Cartesian mesh of $M \\times M \\times M$ elements, where $M = 2^L$ for refinement level $L \\in \\mathbb{N}_0$. The element size is $h = 1/M = 2^{-L}$.\n- Use a nodal tensor-product basis of order $p$ per coordinate direction with $n = p + 1$ nodes per direction and $n^3$ nodes per element.\n- Adopt a standard sum-factorized matrix-free implementation for the DG operator. Model the floating-point operation count per element by\n$$\nF_{\\text{elem}}(p) = 90\\,n^4 + 60\\,n^3 \\quad \\text{flops}, \\quad n = p+1,\n$$\nwhich accounts for volume and face terms in a symmetric interior penalty discretization with tensor contractions along each coordinate. This captures the well-known $\\mathcal{O}(n^{d+1})$ cost for volume terms and $\\mathcal{O}(n^d)$ cost for face terms in $d=3$.\n- Model the main memory traffic per element by\n$$\nB_{\\text{elem}}(p) = 72\\,n^3 \\quad \\text{bytes},\n$$\nwhich accounts for reading the input vector once ($8\\,n^3$ bytes), writing the output vector once ($8\\,n^3$ bytes), and reading geometry factors at quadrature points (modeled as $56\\,n^3$ bytes), all in double precision. Assume basis and quadrature metadata are effectively cached and do not dominate memory traffic.\n- The arithmetic intensity per element is\n$$\nI(p) = \\frac{F_{\\text{elem}}(p)}{B_{\\text{elem}}(p)} \\quad \\text{flops/byte}.\n$$\n- Use a simple roofline execution time model per element:\n$$\nt_{\\text{elem}}(p; P, \\mathrm{BW}) = \\max\\!\\left(\\frac{F_{\\text{elem}}(p)}{P}, \\frac{B_{\\text{elem}}(p)}{\\mathrm{BW}} \\right),\n$$\nwhere $P$ is the peak floating-point rate in flops per second and $\\mathrm{BW}$ is the sustained memory bandwidth in bytes per second. The achieved throughput (floating-point rate) per combination of $p$ and $h$ is\n$$\n\\Theta(p; P, \\mathrm{BW}) = \\frac{F_{\\text{elem}}(p)}{t_{\\text{elem}}(p; P, \\mathrm{BW})} = \\min\\!\\left(P,\\, I(p)\\,\\mathrm{BW}\\right),\n$$\nwhich is independent of $h$.\n- Model the iteration count of the Conjugate Gradient (CG) method with diagonal (Jacobi) preconditioning through the standard bound\n$$\nk(h,p;\\varepsilon) \\approx \\left\\lceil \\tfrac{1}{2}\\sqrt{\\kappa(h,p)} \\,\\ln\\!\\left(\\tfrac{2}{\\varepsilon}\\right)\\right\\rceil,\n$$\nwhere the condition number scales as\n$$\n\\kappa(h,p) = C\\,\\frac{p^4}{h^2},\n$$\na widely accepted scaling for high-order finite element and spectral element discretizations of elliptic operators, and set $C = 1$ and the relative residual tolerance to $\\varepsilon = 10^{-8}$.\n\nFor each test case below, your program must:\n1. Generate all pairs $(L, p)$ from the supplied lists of refinement levels and polynomial degrees.\n2. For each $p$, compute $F_{\\text{elem}}(p)$, $B_{\\text{elem}}(p)$, $I(p)$, $t_{\\text{elem}}(p; P, \\mathrm{BW})$, and $\\Theta(p; P, \\mathrm{BW})$ using the formulas above.\n3. For each pair $(L,p)$, compute $h = 2^{-L}$ and the iteration count $k(h,p;\\varepsilon)$ using the formula above.\n4. Aggregate the following metrics per test case:\n   - The average arithmetic intensity across all considered $p$ values,\n     $$\n     \\overline{I} = \\frac{1}{N_p}\\sum_{p} I(p),\n     $$\n     where $N_p$ is the number of distinct $p$ values in the test case.\n   - The average achieved throughput across all $(L,p)$ pairs,\n     $$\n     \\overline{\\Theta} = \\frac{1}{N_L N_p}\\sum_{L}\\sum_{p} \\Theta(p; P, \\mathrm{BW}),\n     $$\n     where $N_L$ is the number of refinement levels in the test case.\n   - The average CG iteration count across all $(L,p)$ pairs,\n     $$\n     \\overline{k} = \\frac{1}{N_L N_p}\\sum_{L}\\sum_{p} k(h,p;\\varepsilon).\n     $$\n5. Fit a roofline performance model from the synthetic per-element times $t_{\\text{elem}}(p; P, \\mathrm{BW})$ by computing the tightest feasible peak parameters $(\\widehat{P}, \\widehat{\\mathrm{BW}})$ that satisfy the roofline inequalities for all observed $p$:\n   $$\n   \\widehat{P} = \\max_{p} \\frac{F_{\\text{elem}}(p)}{t_{\\text{elem}}(p; P, \\mathrm{BW})}, \\qquad\n   \\widehat{\\mathrm{BW}} = \\max_{p} \\frac{B_{\\text{elem}}(p)}{t_{\\text{elem}}(p; P, \\mathrm{BW})}.\n   $$\n   This is the minimal pair $(\\widehat{P}, \\widehat{\\mathrm{BW}})$ such that $t_{\\text{elem}}(p; \\widehat{P}, \\widehat{\\mathrm{BW}}) \\le t_{\\text{elem}}(p; P, \\mathrm{BW})$ for all $p$, and equals the true $(P,\\mathrm{BW})$ when both bandwidth- and compute-limited regimes appear in the dataset. When only one regime appears, $\\widehat{P}$ or $\\widehat{\\mathrm{BW}}$ becomes a lower bound of the true peak value.\n\nTest Suite:\n- Test Case A (balanced to bandwidth-limited crossover):\n  - Peak floating-point rate: $P = 400 \\times 10^9$ flops/s.\n  - Memory bandwidth: $\\mathrm{BW} = 100 \\times 10^9$ bytes/s.\n  - Refinement levels: $L \\in \\{0,1,2,3\\}$.\n  - Polynomial degrees: $p \\in \\{1,3,7,15\\}$.\n- Test Case B (bandwidth-limited across the entire set):\n  - Peak floating-point rate: $P = 1500 \\times 10^9$ flops/s.\n  - Memory bandwidth: $\\mathrm{BW} = 40 \\times 10^9$ bytes/s.\n  - Refinement levels: $L \\in \\{0,1,2,3\\}$.\n  - Polynomial degrees: $p \\in \\{1,2,3,4,7\\}$.\n- Test Case C (balanced to compute-limited crossover):\n  - Peak floating-point rate: $P = 800 \\times 10^9$ flops/s.\n  - Memory bandwidth: $\\mathrm{BW} = 200 \\times 10^9$ bytes/s.\n  - Refinement levels: $L \\in \\{1,2,3\\}$.\n  - Polynomial degrees: $p \\in \\{1,5,9,13\\}$.\n\nUnits and output requirements:\n- Express throughput as gigaflops per second (GF/s), i.e., divide flops per second by $10^9$.\n- Express memory bandwidth as gigabytes per second (GB/s), i.e., divide bytes per second by $10^9$.\n- The final output must be a single line containing a list of three results (one per test case), where each result is a list of five numbers:\n  $$\n  [\\,\\overline{k},\\,\\overline{I},\\,\\overline{\\Theta}\\,(\\text{GF/s}),\\,\\widehat{\\mathrm{BW}}\\,(\\text{GB/s}),\\,\\widehat{P}\\,(\\text{GF/s})\\,].\n  $$\n- Round all floating-point outputs to $6$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[[...],[...],[...]]\"). No other text should be printed.\n\nYour implementation must follow these steps deterministically and must not use any randomness. The program must run as-is without any user input, external files, or network access. Ensure that all computations are reproducible solely from the definitions provided here.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of numerical analysis and high-performance computing, well-posed with a complete set of definitions and constraints, and objective in its formulation. All provided models and formulas are standard in the field of computational science for analyzing the performance of numerical methods. I will now proceed with a detailed solution.\n\nThe solution is designed by systematically implementing the mathematical models provided for performance analysis of a matrix-free Discontinuous Galerkin (DG) operator. The analysis is broken down into three main components: the computational kernel's performance, the iterative solver's convergence, and the fitting of a performance model to synthetic data.\n\n**1. Per-Element Performance Model (Computational Kernel)**\n\nThe core of the simulation is the performance model for the application of the DG operator on a single mesh element. The operator application is the most time-consuming part of an iterative solver like Conjugate Gradients (CG).\n\nThe floating-point operation (flop) count per element, $F_{\\text{elem}}(p)$, is given by:\n$$\nF_{\\text{elem}}(p) = 90\\,n^4 + 60\\,n^3 \\quad \\text{flops}, \\quad \\text{where } n = p+1\n$$\nHere, $p$ is the polynomial degree of the basis functions. This formula models the cost of a sum-factorization implementation in three dimensions ($d=3$). The dominant term, $90\\,n^4$, reflects the $\\mathcal{O}(n^{d+1})$ complexity associated with tensor contractions for volume integrals. The $60\\,n^3$ term reflects the $\\mathcal{O}(n^d)$ complexity for face integrals inherent to the DG method.\n\nThe main memory traffic (bytes moved) per element, $B_{\\text{elem}}(p)$, is:\n$$\nB_{\\text{elem}}(p) = 72\\,n^3 \\quad \\text{bytes}, \\quad \\text{where } n = p+1\n$$\nThis model assumes double-precision floating-point numbers ($8$ bytes). It accounts for reading the input vector ($8n^3$ bytes), writing the resulting output vector ($8n^3$ bytes), and reading pre-computed geometric factors for the element ($56n^3$ bytes), which are necessary for transforming from a reference element to the physical element.\n\nThe ratio of these two quantities defines the arithmetic intensity, $I(p)$:\n$$\nI(p) = \\frac{F_{\\text{elem}}(p)}{B_{\\text{elem}}(p)} = \\frac{90n^4 + 60n^3}{72n^3} = \\frac{90(p+1) + 60}{72} \\quad \\text{flops/byte}\n$$\nArithmetic intensity is a crucial, hardware-independent metric that characterizes the algorithm's data locality. A higher intensity implies more computation is performed per byte of data moved from main memory.\n\nThe execution time per element, $t_{\\text{elem}}$, is determined using the roofline model, which posits that performance is limited by either the machine's peak floating-point rate, $P$, or its memory bandwidth, $\\mathrm{BW}$:\n$$\nt_{\\text{elem}}(p; P, \\mathrm{BW}) = \\max\\left(\\frac{F_{\\text{elem}}(p)}{P}, \\frac{B_{\\text{elem}}(p)}{\\mathrm{BW}} \\right)\n$$\nThe achieved floating-point throughput, $\\Theta(p; P, \\mathrm{BW})$, is the number of flops performed divided by this time, which can be expressed as:\n$$\n\\Theta(p; P, \\mathrm{BW}) = \\frac{F_{\\text{elem}}(p)}{t_{\\text{elem}}(p; P, \\mathrm{BW})} = \\min(P, I(p) \\cdot \\mathrm{BW})\n$$\nThis concise form shows that throughput is limited by the peak compute rate $P$ if the kernel is compute-bound ($I(p) > P/\\mathrm{BW}$), and by the rate at which the memory system can deliver data ($I(p) \\cdot \\mathrm{BW}$) if the kernel is memory-bound ($I(p)  P/\\mathrm{BW}$).\n\n**2. Iterative Solver Performance Model (Convergence)**\n\nThe total time to solve the linear system depends on both the time per iteration (dominated by the operator applications) and the number of iterations required for convergence. The number of iterations, $k$, for the Conjugate Gradient method is modeled based on its standard convergence theory. For a relative residual tolerance $\\varepsilon$, the number of iterations is approximately:\n$$\nk(h,p;\\varepsilon) \\approx \\left\\lceil \\tfrac{1}{2}\\sqrt{\\kappa(h,p)} \\,\\ln\\left(\\tfrac{2}{\\varepsilon}\\right)\\right\\rceil\n$$\nwhere $\\kappa(h,p)$ is the condition number of the preconditioned system matrix. For a Symmetric Interior Penalty (SIP) DG discretization of the Poisson problem with Jacobi preconditioning, the condition number scales with the mesh size $h$ and polynomial degree $p$ as:\n$$\n\\kappa(h,p) = C\\,\\frac{p^4}{h^2}\n$$\nThis scaling is a well-established result in the analysis of high-order methods, arising from trace and inverse inequalities. With the given constants $C=1$ and $\\varepsilon=10^{-8}$, and the mesh size relation $h=2^{-L}$ for refinement level $L$, the iteration count formula becomes:\n$$\nk(L,p) = \\left\\lceil \\tfrac{1}{2}\\sqrt{\\frac{p^4}{(2^{-L})^2}} \\,\\ln\\left(\\frac{2}{10^{-8}}\\right)\\right\\rceil = \\left\\lceil p^2 \\cdot 2^{L-1} \\ln(2\\cdot 10^8)\\right\\rceil\n$$\n\n**3. Aggregation and Performance Model Fitting**\n\nFor each test case, the program computes the above quantities for all specified pairs of $(L, p)$. It then calculates three average metrics:\n- Average arithmetic intensity, $\\overline{I}$: The mean of $I(p)$ over all $p$.\n- Average achieved throughput, $\\overline{\\Theta}$: The mean of $\\Theta(p)$ over all pairs $(L,p)$. Since $\\Theta$ is independent of $L$, this is equivalent to the mean over $p$.\n- Average CG iterations, $\\overline{k}$: The mean of $k(L,p)$ over all pairs $(L,p)$.\n\nFinally, the program reverse-engineers a roofline model from the synthetic timing data. It computes the tightest feasible peak parameters $(\\widehat{P}, \\widehat{\\mathrm{BW}})$ that are consistent with the observed per-element times $t_{\\text{elem}}(p; P, \\mathrm{BW})$. These are calculated as:\n$$\n\\widehat{P} = \\max_{p} \\frac{F_{\\text{elem}}(p)}{t_{\\text{elem}}(p; P, \\mathrm{BW})} = \\max_p \\Theta(p; P, \\mathrm{BW})\n$$\n$$\n\\widehat{\\mathrm{BW}} = \\max_{p} \\frac{B_{\\text{elem}}(p)}{t_{\\text{elem}}(p; P, \\mathrm{BW})} = \\max_p \\min(P/I(p), \\mathrm{BW})\n$$\nThese fitted parameters will match the true hardware parameters $(P, \\mathrm{BW})$ if the chosen set of polynomial degrees $p$ includes values that fall in both the memory-bound and compute-bound regimes. If all points are in one regime, the fitted value for the unconstrained resource ($\\widehat{P}$ in a memory-bound case, or $\\widehat{\\mathrm{BW}}$ in a compute-bound case) represents a lower bound on its true peak value.\n\nThe implementation automates these calculations for each provided test case, formats the results into the specified units (GF/s and GB/s), rounds them, and prints them in the required list-of-lists format.",
            "answer": "```python\nimport numpy as np\n\ndef process_case(P, BW, L_values, p_values):\n    \"\"\"\n    Processes a single test case to compute performance metrics.\n\n    Args:\n        P (float): Peak floating-point rate in flops/s.\n        BW (float): Memory bandwidth in bytes/s.\n        L_values (list): List of refinement levels L.\n        p_values (list): List of polynomial degrees p.\n\n    Returns:\n        list: A list of 5 floating-point numbers representing the results for the case:\n              [avg_k, avg_I, avg_Theta_gfs, fit_BW_gbs, fit_P_gfs].\n    \"\"\"\n    \n    C = 1.0\n    epsilon = 1e-8\n    k_log_term = np.log(2.0 / epsilon)\n    \n    intensities = []\n    throughputs = []\n    iter_counts = []\n    \n    # For roofline fitting\n    p_fit_P_values = []\n    p_fit_BW_values = []\n\n    # Loop over polynomial degrees p\n    for p in p_values:\n        n = float(p + 1)\n        \n        # Flops and Bytes per element\n        f_elem = 90.0 * n**4 + 60.0 * n**3\n        b_elem = 72.0 * n**3\n        \n        # Arithmetic intensity\n        intensity = f_elem / b_elem\n        intensities.append(intensity)\n        \n        # Roofline time and throughput\n        t_compute = f_elem / P\n        t_memory = b_elem / BW\n        t_elem = max(t_compute, t_memory)\n        \n        throughput = f_elem / t_elem\n        throughputs.append(throughput)\n        \n        # Values for fitting\n        p_fit_P_values.append(f_elem / t_elem)\n        p_fit_BW_values.append(b_elem / t_elem)\n\n        # Loop over refinement levels L\n        for L in L_values:\n            h = 2.0**(-L)\n            \n            # Condition number\n            kappa = C * (p**4) / (h**2)\n            \n            # Iteration count\n            k = np.ceil(0.5 * np.sqrt(kappa) * k_log_term)\n            iter_counts.append(k)\n            \n    # Calculate aggregate metrics\n    avg_I = np.mean(intensities)\n    \n    # Throughput is independent of L, averaging over L and p is same as over p\n    avg_Theta = np.mean(throughputs)\n    \n    avg_k = np.mean(iter_counts)\n    \n    # Fit the roofline model\n    fit_P = max(p_fit_P_values)\n    fit_BW = max(p_fit_BW_values)\n\n    # Convert to required units\n    avg_Theta_gfs = avg_Theta / 1e9\n    fit_P_gfs = fit_P / 1e9\n    fit_BW_gbs = fit_BW / 1e9\n    \n    # Return rounded results\n    return [\n        avg_k,\n        avg_I,\n        avg_Theta_gfs,\n        fit_BW_gbs,\n        fit_P_gfs\n    ]\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Test Case A\n        (400e9, 100e9, [0, 1, 2, 3], [1, 3, 7, 15]),\n        # Test Case B\n        (1500e9, 40e9, [0, 1, 2, 3], [1, 2, 3, 4, 7]),\n        # Test Case C\n        (800e9, 200e9, [1, 2, 3], [1, 5, 9, 13])\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = process_case(*case)\n        all_results.append(result)\n\n    # Format the final output string as a list of lists of numbers\n    formatted_inner_lists = []\n    for res_list in all_results:\n        # Format each number to 6 decimal places\n        formatted_nums = [f'{val:.6f}' for val in res_list]\n        formatted_inner_lists.append(f\"[{','.join(formatted_nums)}]\")\n    \n    final_output = f\"[{','.join(formatted_inner_lists)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}