{
    "hands_on_practices": [
        {
            "introduction": "本节的实践练习将引导您从头开始构建通量重构（FR）方法的核心。通过为一个简单的一维线性平流方程编写代码，您将亲手实现该方法的关键组成部分，并探索不同节点配置对数值稳定性的影响。这项练习旨在巩固您对FR格式离散化和基于能量的稳定性分析的理解 。",
            "id": "3386483",
            "problem": "考虑周期性域上的一维线性平流守恒律，\n$$\nu_t + a\\,u_x = 0,\\quad x\\in[0,L],\\ t\\ge 0,\n$$\n其中平流速度 $a>0$ 为常数，且具有周期性边界条件。将域离散为 $N$ 个大小为 $h=L/N$ 的均匀单元，并在每个单元内用参考坐标 $\\xi\\in[-1,1]$ 中次数为 $p$ 的多项式来近似解。在每个单元内，使用包含 $n=p+1$ 个不同节点 $\\{\\xi_i\\}_{i=1}^n$ 的节点表示法，以及由求积权重定义的相应离散质量矩阵。\n\n通量重构 (Flux Reconstruction, FR) 方法，也称为重构校正程序 (Correction Procedure via Reconstruction, CPR)，通过一个由界面通量差和选定的校正函数构建的校正项来增强插值通量的节点导数。在具有周期性耦合的强形式单元格式下，对于 $a>0$（左侧界面为入流），半离散格式可以写为\n$$\n\\frac{d\\mathbf{u}_e}{dt} \\;=\\; -\\frac{2a}{h}\\left( \\mathbf{D}\\,\\mathbf{u}_e \\;+\\; c\\,\\mathbf{g}'_L\\left( u^{\\text{num}}_{e-1,R} - u^{\\text{poly}}_{e,L} \\right)\\right),\n$$\n其中 $\\mathbf{u}_e\\in\\mathbb{R}^n$ 是单元 $e$ 中节点解值的向量，$\\mathbf{D}\\in\\mathbb{R}^{n\\times n}$ 是所选节点的节点微分矩阵，$u^{\\text{poly}}_{e,L}$ 是通过插值获得的左边界值，$u^{\\text{num}}_{e-1,R}$ 是通过数值通量从左相邻单元传入的右边界值，而 $c$ 是一个标量校正振幅。边界值是通过在 $\\xi=-1$ 和 $\\xi=+1$ 处评估节点 Lagrange 基函数得到的。将相应的评估行向量分别表示为 $\\mathbf{v}_L^T$ 和 $\\mathbf{v}_R^T$，因此对于 $a>0$ 的迎风格式，有 $u^{\\text{poly}}_{e,L}=\\mathbf{v}_L^T\\mathbf{u}_e$ 和 $u^{\\text{num}}_{e-1,R}=\\mathbf{v}_R^T\\mathbf{u}_{e-1}$。离散质量矩阵 $\\mathbf{M}\\in\\mathbb{R}^{n\\times n}$ 定义为与所选节点分布相关联的求积权重的对角矩阵，它提供了离散内积 $\\langle \\mathbf{u},\\mathbf{v}\\rangle_{\\mathbf{M}}=\\mathbf{u}^T\\mathbf{M}\\mathbf{v}$。\n\n您将比较三种节点分布：\n- Legendre–Gauss 节点及其精确的 Gauss 求积权重。\n- Legendre–Gauss–Lobatto 节点及 Lobatto 求积权重。\n- $[-1,1]$ 上的等距节点，其闭合 Newton–Cotes 求积权重由对最高 $n-1$ 次多项式的精确性确定。\n\n对于左侧界面的校正函数，选择由下式定义的次数为 $p+1$ 的唯一多项式\n$$\ng_L(\\xi) = s_p\\;\\frac{1-\\xi}{2}\\;P_p(\\xi),\\quad s_p := \\frac{1}{P_p(-1)} = (-1)^p,\n$$\n其中 $P_p(\\xi)$ 是次数为 $p$ 的 Legendre 多项式。此选择强制 $g_L(-1)=1$，$g_L(+1)=0$，并产生一个非恒定的导数\n$$\ng_L'(\\xi) = s_p\\left[ -\\frac{1}{2}P_p(\\xi) + \\frac{1-\\xi}{2}P_p'(\\xi)\\right],\n$$\n其节点采样产生用于 FR 校正的向量 $\\mathbf{g}'_L\\in\\mathbb{R}^n$。\n\n定义全局半离散算子 $\\mathbf{A}\\in\\mathbb{R}^{(Nn)\\times(Nn)}$，该算子用于推进由所有单元节点状态 $\\{\\mathbf{u}_e\\}_{e=0}^{N-1}$ 堆叠而成的级联状态 $\\mathbf{U}\\in\\mathbb{R}^{Nn}$。在周期性耦合下，该算子具有块结构，其中包含涉及 $\\mathbf{D}$ 的单元内项和通过 $\\mathbf{g}'_L\\mathbf{v}_R^T$ 实现的单元间入流耦合。令全局块对角质量矩阵为 $\\mathbf{M}_{\\text{glob}}=\\operatorname{diag}(\\mathbf{M},\\dots,\\mathbf{M})\\in\\mathbb{R}^{(Nn)\\times(Nn)}$。\n\n作为基于 $\\mathbf{M}_{\\text{glob}}$ 内积能量的稳定性度量，考虑对称算子\n$$\n\\mathbf{S}_{\\mathbf{M}} = \\frac{1}{2}\\left(\\mathbf{M}_{\\text{glob}}\\mathbf{A} + \\mathbf{A}^T\\mathbf{M}_{\\text{glob}}\\right).\n$$\n它关于 $\\mathbf{M}_{\\text{glob}}$ 的广义特征值表征了瞬时能量增长率：最大特征值的非正性意味着离散能量不增加。为比较节点分布，您必须：\n1. 对于每个节点分布和给定的 $(p,N)$，在长度为 $L=1$ 的周期性域上使用 $a>0$ 的迎风数值通量来构造 $\\mathbf{A}$。\n2. 计算 $\\mathbf{S}_{\\mathbf{M}}$ 相对于 $\\mathbf{M}_{\\text{glob}}$ 的最大广义特征值，这等价于对称矩阵 $\\mathbf{C}=\\mathbf{M}_{\\text{glob}}^{-1/2}\\mathbf{S}_{\\mathbf{M}}\\mathbf{M}_{\\text{glob}}^{-1/2}$ 的最大特征值，并将其作为一个实数标量稳定性指标。\n3. 为每种节点分布推导一个校正缩放律 $c_{\\text{norm}}$，通过要求导数校正向量的 $\\mathbf{M}$ 加权范数在不同节点集之间相等，来归一化离散质量矩阵在 $n$ 个点上的影响。具体来说，为每个节点集 $S$ 选择，\n$$\nc_{\\text{norm}}^{(S)} \\ \\text{such that}\\ \\ \\left\\|\\mathbf{g}'_L\\right\\|_{\\mathbf{M}^{(S)}} \\, c_{\\text{norm}}^{(S)} \\ = \\ \\left\\|\\mathbf{g}'_L\\right\\|_{\\mathbf{M}^{(\\text{ref})}},\n$$\n其中 $\\|\\mathbf{w}\\|_{\\mathbf{M}} := \\sqrt{\\mathbf{w}^T\\mathbf{M}\\mathbf{w}}$ 且 $(\\text{ref})$ 表示一个固定的参考节点集。在此任务中，使用 Legendre–Gauss–Lobatto 作为参考。通过将校正振幅 $c$ 与 $c_{\\text{norm}}^{(S)}$ 相乘，在 FR 算子中实现此归一化。\n4. 量化应用归一化前后节点分布对稳定性度量的影响。\n\n您的程序必须实现上述内容，并为以下测试套件生成数值结果，其中 $a=1$ 且 $L=1$：\n- 测试用例 1：$p=2, N=10$。\n- 测试用例 2：$p=3, N=8$。\n- 测试用例 3：$p=5, N=6$。\n\n对于每个测试用例，并按 Legendre–Gauss、Legendre–Gauss–Lobatto、Equidistant 的顺序为每种节点分布计算两个实数：\n- 当 $c=1$ 时（无归一化）$\\mathbf{C}$ 的最大特征值。\n- 当使用上面推导的归一化校正振幅 $c=c_{\\text{norm}}^{(S)}$ 时 $\\mathbf{C}$ 的最大特征值。\n\n最终输出格式必须是单行，包含一个由三个列表组成的列表，每个内部列表对应一个测试用例。每个内部列表必须按以下顺序包含六个浮点数\n$$\n\\big[\\lambda_{\\max}^{\\text{Gauss}},\\ \\lambda_{\\max}^{\\text{Lobatto}},\\ \\lambda_{\\max}^{\\text{Equid}},\\ \\lambda_{\\max,\\text{norm}}^{\\text{Gauss}},\\ \\lambda_{\\max,\\text{norm}}^{\\text{Lobatto}},\\ \\lambda_{\\max,\\text{norm}}^{\\text{Equid}}\\big],\n$$\n其中每个 $\\lambda_{\\max}$ 是指定配置下 $\\mathbf{C}$ 的最大特征值。该行必须精确地打印为 Python 的列表的列表形式，例如：\n$$\n\\texttt{[[x_{11},x_{12},x_{13},x_{14},x_{15},x_{16}],[x_{21},\\dots,x_{26}],[x_{31},\\dots,x_{36}]]}\n$$\n本问题不涉及单位。不使用角度。不使用百分比。",
            "solution": "用户希望分析用于求解一维线性平流方程的通量重构 (Flux Reconstruction, FR) / 重构校正程序 (Correction Procedure via Reconstruction, CPR) 方法的稳定性。该分析涉及比较每个单元内的三种不同节点集：Legendre-Gauss (LG)、Legendre-Gauss-Lobatto (LGL) 和等距节点。稳定性将通过计算从半离散系统导出的特定对称化算子的最大特征值来量化。该问题还要求推导并应用一个归一化因子到校正项，以确保不同节点分布之间的公平比较。\n\n### **问题验证**\n\n**步骤 1：提取给定信息**\n\n- **守恒律**：$u_t + a\\,u_x = 0$，对于 $x\\in[0,L], t\\ge 0$。\n- **平流速度**：常数 $a>0$。\n- **边界条件**：在 $[0,L]$ 上周期。\n- **离散化**：$N$ 个均匀单元，大小 $h=L/N$。\n- **近似**：在参考单元 $\\xi\\in[-1,1]$ 上，使用 $n=p+1$ 个节点 $\\{\\xi_i\\}_{i=1}^n$ 的次数为 $p$ 的多项式。\n- **节点集**：\n  1. Legendre-Gauss (LG) 节点和权重。\n  2. Legendre-Gauss-Lobatto (LGL) 节点和权重。\n  3. 等距节点及闭合 Newton-Cotes 权重（对于次数最高为 $n-1$ 的多项式是精确的）。\n- **半离散 FR/CPR 格式**：$\\frac{d\\mathbf{u}_e}{dt} = -\\frac{2a}{h}\\left( \\mathbf{D}\\,\\mathbf{u}_e + c\\,\\mathbf{g}'_L\\left( u^{\\text{num}}_{e-1,R} - u^{\\text{poly}}_{e,L} \\right)\\right)$。\n- **FR 格式中的项**：\n  - $\\mathbf{u}_e$：单元 $e$ 中节点解值的向量。\n  - $\\mathbf{D}$：节点微分矩阵。\n  - $u^{\\text{poly}}_{e,L} = \\mathbf{v}_L^T\\mathbf{u}_e$：在左边界（$\\xi=-1$）处的插值解。\n  - $u^{\\text{num}}_{e-1,R} = \\mathbf{v}_R^T\\mathbf{u}_{e-1}$：来自左相邻单元右边界的数值通量（对于 $a>0$ 为迎风格式）。\n  - $c$：标量校正振幅。\n  - $\\mathbf{g}'_L$：校正函数 $g_L(\\xi)$ 导数的节点值向量。\n- **校正函数**：$g_L(\\xi) = s_p\\;\\frac{1-\\xi}{2}\\;P_p(\\xi)$，其中 $s_p = (-1)^p$，$P_p(\\xi)$ 是次数为 $p$ 的 Legendre 多项式。\n- **质量矩阵**：$\\mathbf{M}$ 是求积权重的对角矩阵。全局质量矩阵是 $\\mathbf{M}_{\\text{glob}}=\\operatorname{diag}(\\mathbf{M},\\dots,\\mathbf{M})$。\n- **稳定性度量**：对称矩阵 $\\mathbf{C}=\\mathbf{M}_{\\text{glob}}^{-1/2}\\mathbf{S}_{\\mathbf{M}}\\mathbf{M}_{\\text{glob}}^{-1/2}$ 的最大特征值，其中 $\\mathbf{S}_{\\mathbf{M}} = \\frac{1}{2}\\left(\\mathbf{M}_{\\text{glob}}\\mathbf{A} + \\mathbf{A}^T\\mathbf{M}_{\\text{glob}}\\right)$，而 $\\mathbf{A}$ 是全局半离散算子 ($\\frac{d\\mathbf{U}}{dt} = \\mathbf{A}\\mathbf{U}$)。\n- **校正归一化**：为每个节点集 $S$ 确定 $c_{\\text{norm}}^{(S)}$，使得 $\\left\\|\\mathbf{g}'_L\\right\\|_{\\mathbf{M}^{(S)}} \\, c_{\\text{norm}}^{(S)} = \\left\\|\\mathbf{g}'_L\\right\\|_{\\mathbf{M}^{(\\text{ref})}}$，其中参考集是 LGL。范数为 $\\|\\mathbf{w}\\|_{\\mathbf{M}} = \\sqrt{\\mathbf{w}^T\\mathbf{M}\\mathbf{w}}$。\n- **常数**：$a=1$, $L=1$。\n- **测试用例**：$(p=2, N=10)$；$(p=3, N=8)$；$(p=5, N=6)$。\n- **要求输出**：对于每个测试用例，一个包含六个特征值的列表：$[\\lambda_{\\max}^{\\text{LG}}, \\lambda_{\\max}^{\\text{LGL}}, \\lambda_{\\max}^{\\text{Equid}}]$（$c=1$），后跟 $[\\lambda_{\\max,\\text{norm}}^{\\text{LG}}, \\lambda_{\\max,\\text{norm}}^{\\text{LGL}}, \\lambda_{\\max,\\text{norm}}^{\\text{Equid}}]$（$c=c_{\\text{norm}}$）。\n\n**步骤 2：使用提取的给定信息进行验证**\n\n根据验证标准检查问题陈述。\n\n- **科学基础**：该问题是偏微分方程高阶数值方法领域的标准练习，特别关注 FR/CPR 公式的谱特性。所有概念（节点基、微分矩阵、FR 校正、能量稳定性分析）在科学文献中都是公认的。\n- **适定性**：该问题在数学和算法上都是明确定义的。构建算子和后续特征值分析所需的所有组件都已指定。这些任务会导向一组唯一的数值结果。\n- **客观性**：问题陈述使用精确、客观的数学语言，没有歧义或主观论断。\n- **缺陷清单**：\n  1.  **科学/事实不健全**：无。公式是正确的。\n  2.  **非形式化/不相关**：无。该问题是一个形式化的数值分析任务，与其陈述的主题直接相关。\n  3.  **不完整/矛盾的设置**：无。节点、权重、矩阵和算子的所有必需定义都已提供，或可以从标准原理中唯一推导。\n  4.  **不切实际/不可行**：无。该问题是一个具有可行参数的标准数值实验。\n  5.  **不适定/结构不良**：无。该问题结构良好，可导出一个唯一的、有意义的数值解（特征值集合）。\n  6.  **伪深刻/琐碎**：无。该问题需要对数值分析和线性代数中的几个概念进行非平凡的实现，代表了一项合理的计算任务。\n  7.  **超出科学可验证性**：无。结果是数值上可计算的，并且可以独立验证。\n\n**步骤 3：结论与行动**\n\n问题是**有效的**。将提供完整解答。\n\n### **求解方法**\n\n求解过程需要为多项式次数 $p$、单元数量 $N$ 和节点分布的各种配置，构建全局半离散算子 $\\mathbf{A}$ 和全局质量矩阵 $\\mathbf{M}_{\\text{glob}}$。每个配置的核心步骤如下：\n\n1.  **生成节点数据**：对于每个包含 $n=p+1$ 个点的节点集 (LG, LGL, Equidistant)：\n    -   计算节点位置 $\\{\\xi_i\\}_{i=1}^n \\in [-1, 1]$。\n    -   计算相应的求积权重 $\\{w_i\\}_{i=1}^n$。这些权重构成单元质量矩阵 $\\mathbf{M}$ 的对角线。\n\n2.  **构建单元矩阵**：\n    -   **微分矩阵 ($\\mathbf{D}$)**：计算 $n \\times n$ 矩阵，其中 $D_{ij} = \\ell_j'(\\xi_i)$，$\\ell_j$ 是第 $j$ 个 Lagrange 多项式。将采用一种使用重心权重的稳定方法。\n    -   **边界评估向量 ($\\mathbf{v}_L^T, \\mathbf{v}_R^T$)**：这些是分别包含 Lagrange 基函数在 $\\xi=-1$ 和 $\\xi=1$ 处值的行向量。对于包含端点的 LGL 节点，这些向量是平凡的（例如，$\\mathbf{v}_L^T = [1, 0, \\dots, 0]$）。对于其他节点，必须进行计算。\n    -   **校正函数向量 ($\\mathbf{g}'_L$)**：在每个节点 $\\xi_i$ 处评估指定校正函数的导数 $g_L'(\\xi) = (-1)^p\\left[ -\\frac{1}{2}P_p(\\xi) + \\frac{1-\\xi}{2}P_p'(\\xi)\\right]$，以形成向量 $\\mathbf{g}'_L$。\n\n3.  **归一化因子计算**：\n    -   对于每个节点集 $S \\in \\{\\text{LG, LGL, Equidistant}\\}$，计算归一化因子 $c_{\\text{norm}}^{(S)} = \\frac{\\|\\mathbf{g}'_L\\|_{\\mathbf{M}^{(\\text{LGL})}}}{\\|\\mathbf{g}'_L\\|_{\\mathbf{M}^{(S)}}}}$。参考范数使用给定次数 $p$ 的 LGL 节点和权重计算。$\\mathbf{M}$-范数为 $\\|\\mathbf{w}\\|_{\\mathbf{M}} = \\sqrt{\\mathbf{w}^T \\mathbf{M} \\mathbf{w}}$。根据定义，$c_{\\text{norm}}^{(\\text{LGL})} = 1$。\n\n4.  **组装全局算子 ($\\mathbf{A}$)**：\n    -   全局算子 $\\mathbf{A}$ 是一个 $(Nn) \\times (Nn)$ 的块循环矩阵。其定义源于将数值通量代入 FR 格式：\n      $$ \\frac{d\\mathbf{u}_e}{dt} = -\\frac{2a}{h}\\left( (\\mathbf{D} - c\\mathbf{g}'_L\\mathbf{v}_L^T)\\mathbf{u}_e + (c\\mathbf{g}'_L\\mathbf{v}_R^T)\\mathbf{u}_{e-1} \\right) $$\n    -   对角块为 $\\mathbf{A}_{ee} = -\\frac{2a}{h}(\\mathbf{D} - c\\mathbf{g}'_L\\mathbf{v}_L^T)$。\n    -   次对角块（以及由于周期性而出现的右上角块）为 $\\mathbf{A}_{e,e-1} = -\\frac{2a}{h}(c\\mathbf{g}'_L\\mathbf{v}_R^T)$。\n    -   这将对 $c=1$ 和 $c=c_{\\text{norm}}^{(S)}$ 两种情况执行。\n\n5.  **计算稳定性度量**：\n    -   将全局质量矩阵 $\\mathbf{M}_{\\text{glob}}$ 构建为单元质量矩阵 $\\mathbf{M}$ 的块对角矩阵。\n    -   形成质量缩放算子的对称部分：$\\mathbf{S}_{\\mathbf{M}} = \\frac{1}{2}(\\mathbf{M}_{\\text{glob}}\\mathbf{A} + \\mathbf{A}^T\\mathbf{M}_{\\text{glob}})$。\n    -   为了找到 $(\\mathbf{S_M}, \\mathbf{M}_{\\text{glob}})$ 的广义特征值，我们求解对称矩阵 $\\mathbf{C} = \\mathbf{M}_{\\text{glob}}^{-1/2} \\mathbf{S_M} \\mathbf{M}_{\\text{glob}}^{-1/2}$ 的等价标准特征值问题。\n    -   计算 $\\mathbf{C}$ 的最大特征值。由于 $\\mathbf{C}$ 是对称的，其特征值为实数，可以使用高效算法。非正值意味着能量不增加（稳定）。\n\n整个过程将对每个测试用例 $(p, N)$ 和三种节点分布中的每一种重复进行。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import legendre, roots_legendre, roots_jacobi\nfrom scipy.linalg import eigh\n\ndef get_nodes_and_weights(n, node_type):\n    \"\"\"\n    Computes nodal points and quadrature weights for a given type.\n    n: number of points (p+1)\n    node_type: 'gauss', 'lobatto', or 'equidistant'\n    \"\"\"\n    if node_type == 'gauss':\n        nodes, weights = roots_legendre(n)\n        return np.array(nodes), np.array(weights)\n    elif node_type == 'lobatto':\n        p = n - 1\n        if n == 1:\n            return np.array([0.0]), np.array([2.0])\n        if n == 2:\n            return np.array([-1.0, 1.0]), np.array([1.0, 1.0])\n        \n        interior_nodes, _ = roots_jacobi(n - 2, 1, 1)\n        nodes = np.concatenate(([-1.0], np.sort(interior_nodes), [1.0]))\n        \n        P_p = legendre(p)\n        weights = 2.0 / (n * p * P_p(nodes)**2)\n        return nodes, weights\n    elif node_type == 'equidistant':\n        nodes = np.linspace(-1.0, 1.0, n)\n        # Newton-Cotes weights by solving Vandermonde system\n        V = np.vander(nodes, n, increasing=True)\n        rhs = np.zeros(n)\n        for i in range(n):\n            rhs[i] = (1.0 - (-1.0)**(i + 1)) / (i + 1)\n        weights = np.linalg.solve(V.T, rhs)\n        return nodes, weights\n    else:\n        raise ValueError(f\"Unknown node type: {node_type}\")\n\ndef lagrange_diff_matrix(nodes):\n    \"\"\"\n    Computes the differentiation matrix using the barycentric formula.\n    \"\"\"\n    n = len(nodes)\n    D = np.zeros((n, n))\n    \n    # Barycentric weights\n    w = np.ones(n)\n    for j in range(n):\n        for k in range(n):\n            if k != j:\n                w[j] *= (nodes[j] - nodes[k])\n    w = 1.0 / w\n    \n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                D[i, j] = (w[j] / w[i]) / (nodes[i] - nodes[j])\n                \n    for i in range(n):\n        D[i, i] = -np.sum(D[i, :])\n    return D\n\ndef get_boundary_vectors(nodes):\n    \"\"\"\n    Computes Lagrange basis evaluation vectors at xi = -1 and xi = 1.\n    \"\"\"\n    n = len(nodes)\n    # Check if nodes are Lobatto type (endpoints included)\n    if np.isclose(nodes[0], -1.0) and np.isclose(nodes[-1], 1.0):\n        vL = np.zeros(n)\n        vL[0] = 1.0\n        vR = np.zeros(n)\n        vR[-1] = 1.0\n        return vL, vR\n    \n    # Otherwise, compute via explicit Lagrange polynomial evaluation.\n    def lagrange_eval(x, j, eval_nodes):\n        num, den = 1.0, 1.0\n        for m, xm in enumerate(eval_nodes):\n            if m != j:\n                num *= (x - xm)\n                den *= (eval_nodes[j] - xm)\n        return num / den\n\n    vL = np.array([lagrange_eval(-1.0, j, nodes) for j in range(n)])\n    vR = np.array([lagrange_eval(1.0, j, nodes) for j in range(n)])\n    return vL, vR\n\ndef get_correction_vector(p, nodes):\n    \"\"\"\n    Computes the nodal vector for the derivative of the g_L correction function.\n    \"\"\"\n    sp = (-1.0)**p\n    Pp = legendre(p)\n    Pp_prime = Pp.deriv(1)\n    \n    g_prime_vals = sp * (-0.5 * Pp(nodes) + 0.5 * (1.0 - nodes) * Pp_prime(nodes))\n    return g_prime_vals\n\ndef compute_max_eigenvalue(A, M_glob):\n    \"\"\"\n    Computes the largest generalized eigenvalue of (S_M, M_glob).\n    \"\"\"\n    S_M = 0.5 * (M_glob @ A + A.T @ M_glob)\n    # Using scipy.linalg.eigh for generalized symmetric eigenproblem\n    # It is generally more stable than forming C explicitly.\n    # It returns eigenvalues in ascending order.\n    eigvals = eigh(S_M, M_glob, eigvals_only=True)\n    return eigvals[-1]\n\ndef solve_one_case(p, N, a, L):\n    \"\"\"\n    Solves the problem for one (p, N) test case.\n    \"\"\"\n    n = p + 1\n    h = L / N\n    \n    node_types = ['gauss', 'lobatto', 'equidistant']\n    \n    # Calculate normalization constants\n    ref_nodes, ref_weights = get_nodes_and_weights(n, 'lobatto')\n    ref_g_prime = get_correction_vector(p, ref_nodes)\n    ref_M_elem = np.diag(ref_weights)\n    norm_ref = np.sqrt(ref_g_prime.T @ ref_M_elem @ ref_g_prime)\n    \n    c_norms = {}\n    for nt in node_types:\n        nodes_s, weights_s = get_nodes_and_weights(n, nt)\n        g_prime_s = get_correction_vector(p, nodes_s)\n        M_elem_s = np.diag(weights_s)\n        norm_s = np.sqrt(g_prime_s.T @ M_elem_s @ g_prime_s)\n        c_norms[nt] = norm_ref / norm_s if norm_s > 1e-15 else 1.0\n\n    unnormalized_eigs = []\n    normalized_eigs = []\n\n    for node_type in node_types:\n        nodes, weights = get_nodes_and_weights(n, node_type)\n        D = lagrange_diff_matrix(nodes)\n        M_elem = np.diag(weights)\n        vL_T, vR_T = get_boundary_vectors(nodes)\n        g_prime_vec = get_correction_vector(p, nodes)\n        \n        # Calculate for both c=1 and c=c_norm\n        for c_val, eig_list in zip([1.0, c_norms[node_type]], [unnormalized_eigs, normalized_eigs]):\n            dof = N * n\n            \n            # semi-discrete operator blocks\n            prefactor = -2.0 * a / h\n            A_diag_block = prefactor * (D - c_val * np.outer(g_prime_vec, vL_T))\n            A_offdiag_block = prefactor * (c_val * np.outer(g_prime_vec, vR_T))\n            \n            # Assemble global operator A\n            A = np.zeros((dof, dof))\n            for e in range(N):\n                e_slice = slice(e * n, (e + 1) * n)\n                em1 = (e - 1 + N) % N\n                em1_slice = slice(em1 * n, (em1 + 1) * n)\n                \n                A[e_slice, e_slice] = A_diag_block\n                A[e_slice, em1_slice] = A_offdiag_block\n                \n            M_glob = np.kron(np.eye(N), M_elem)\n            \n            max_eig = compute_max_eigenvalue(A, M_glob)\n            eig_list.append(max_eig)\n\n    return unnormalized_eigs + normalized_eigs\n\ndef solve():\n    \"\"\"\n    Main driver function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        (2, 10),  # p, N\n        (3, 8),\n        (5, 6),\n    ]\n    a = 1.0\n    L = 1.0\n    \n    final_results = []\n    for p, N in test_cases:\n        case_results = solve_one_case(p, N, a, L)\n        final_results.append(case_results)\n        \n    # The output format must be a Python list of lists.\n    # str(list) provides the canonical representation.\n    # The example in the prompt `[[x11,x12,...]]` has no spaces.\n    # We will remove them to match the example's formatting precisely.\n    print(str(final_results).replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了线性问题的基本原理之后，我们将注意力转向非线性守恒律所带来的一个关键挑战：混叠误差。这项练习要求您从理论上分析当非线性通量（如 $f(u) = u^p$）与标准积分方法结合时，如何导致精度降阶。通过推导一个充分的过积分条件，您将学会如何通过精确计算体积项来恢复设计精度，这是处理非线性问题时至关重要的一步 。",
            "id": "3386485",
            "problem": "考虑周期性区域上的一维守恒律 $u_{t} + \\partial_{x} f(u) = 0$，该守恒律通过通量重构（Flux Reconstruction, FR）方法（也称为通过重构的修正程序，Correction Procedure via Reconstruction, CPR）在由局部坐标为 $\\xi \\in [-1,1]$ 的仿射映射单元组成的均匀网格上进行离散。在每个单元上，近似解 $u^{h}(\\xi)$ 由一个关于 $\\xi$ 的 $N$ 次多项式表示，该多项式由高斯-洛巴托-勒让德（Gauss–Lobatto–Legendre, GLL）点上的节点值构造。体积项的弱形式采用标准的FR/DG分部积分形式，并使用体积求积进行计算。\n\n假设一个非线性通量 $f(u) = u^{p}$，其中 $p \\geq 2$ 为整数。对于光滑解，在没有求积混叠并且假设修正函数足够正则的情况下，设计的精度阶为 $N+1$。当所选的求积方法不能精确地积分体积项的多项式被积函数时，体积项中就会出现积分不足（混叠），从而将形式精度阶降低到 $N+1$ 以下。\n\n仅使用关于复合和乘法下多项式次数的经过充分检验的事实，以及具有 $Q$ 个点的高斯-洛巴托-勒让德求积（对次数最高为 $2Q-3$ 的多项式精确）和具有 $M$ 个点的高斯-勒让德求积（对次数最高为 $2M-1$ 的多项式精确）的经典精确性性质，完成以下任务：\n\n1. 对于次数至多为 $N$ 的测试函数，确定在每个单元上为了满足弱形式而必须被精确积分的体积被积函数的最大多项式次数。\n2. 解释当 $Q=N+1$ 时，对于 $p \\geq 2$ 的情况，这如何导致混叠，从而将形式精度阶从设计的 $N+1$ 阶降低。\n3. 通过选择一个具有 $M$ 个点的高斯-勒让德体积求积方法，提出一个充分的过积分条件，以使体积项得到精确积分，并恢复设计的 $N+1$ 精度阶。\n\n你的最终答案必须是一个单一的闭式解析表达式，给出保证体积项精确积分的最小 $M$（用 $N$ 和 $p$ 表示）。不需要进行数值近似或四舍五入。",
            "solution": "该问题陈述在科学上是合理的、适定的、客观且自洽的。它提出了一个偏微分方程高阶数值方法领域的标准分析问题。所有提供的信息在事实上都是正确的，并且与任务相关。因此，有必要提供完整的解答。\n\n一般的一维守恒律由下式给出：\n$$\nu_{t} + \\partial_{x} f(u) = 0\n$$\n其中 $u$ 是守恒变量，$f(u)$ 是通量函数。对于本问题，通量被指定为非线性函数 $f(u) = u^{p}$，其中 $p \\geq 2$ 为某个整数。\n\n区域被离散化为单元。在一个参考单元上，局部坐标为 $\\xi \\in [-1, 1]$，解 $u^{h}(\\xi)$ 由一个次数至多为 $N$ 的多项式近似。弱形式的测试函数 $v^{h}(\\xi)$ 来自相同的多项式空间，因此 $\\deg(v^{h}) \\leq N$。\n\n控制方程的弱形式，在给定单元 $K$ 上进行分部积分并变换到参考单元后，包含一个形如下式的体积积分项：\n$$\n\\int_{-1}^{1} f(u^{h}(\\xi)) \\frac{d v^{h}}{d \\xi} \\, d\\xi\n$$\n采用数值求积格式来近似该积分。整个数值方法的精度取决于该求积对特定被积多项式的精确性。被积函数是乘积 $I(\\xi) = f(u^{h}(\\xi)) \\frac{d v^{h}}{d \\xi}$。\n\n**1. 体积被积函数的最大多项式次数**\n\n为了确定求积法则所需的精确性，我们必须首先确定被积函数 $I(\\xi)$ 可能的最大多项式次数。此分析依赖于多项式乘法和复合的基本性质。\n\n- 解的近似 $u^{h}(\\xi)$ 是一个次数至多为 $N$ 的多项式。我们记作 $\\deg(u^{h}) \\leq N$。\n- 通量函数为 $f(u) = u^{p}$。当应用于多项式近似解时，我们得到 $f(u^{h}(\\xi)) = (u^{h}(\\xi))^{p}$。复合函数的次数是次数的乘积，所以 $\\deg(f(u^{h})) = p \\cdot \\deg(u^{h})$。因此，最大次数为 $pN$。\n- 测试函数 $v^{h}(\\xi)$ 也是一个次数至多为 $N$ 的多项式，所以 $\\deg(v^{h}) \\leq N$。\n- 它关于局部坐标 $\\xi$ 的导数 $\\frac{d v^{h}}{d \\xi}$ 是一个次数至多为 $N-1$ 的多项式。所以，$\\deg(\\frac{d v^{h}}{d \\xi}) \\leq N-1$。\n- 被积函数 $I(\\xi)$ 是 $f(u^{h}(\\xi))$ 和 $\\frac{d v^{h}}{d \\xi}$ 的乘积。多项式乘积的次数是它们各自次数的和。\n- 因此，被积函数的最大次数为：\n$$\n\\deg(I) = \\deg(f(u^{h})) + \\deg\\left(\\frac{d v^{h}}{d \\xi}\\right) = pN + (N-1) = (p+1)N - 1\n$$\n为了在不引入求积误差的情况下满足弱形式，体积积分必须被精确计算。这要求一个对所有次数直到 $(p+1)N - 1$ 的多项式都精确的求积法则。\n\n**2. 标准 GLL 求积的混叠**\n\n问题陈述指出，一种常见的方法是使用 $Q$ 个高斯-洛巴托-勒让德（GLL）点（其中 $Q = N+1$）进行体积求积。数值求积的经典理论表明，一个具有 $Q$ 个点的 GLL 法则能精确积分次数最高为 $2Q-3$ 的多项式。\n\n- 将 $Q = N+1$ 代入 GLL 精确性公式，我们发现该求积法则对次数最高为以下值的多项式是精确的：\n$$\n2(N+1) - 3 = 2N + 2 - 3 = 2N - 1\n$$\n- 当被积函数的次数超过求积法则能够精确积分的次数时，就会发生混叠，这会导致形式精度阶的降低。这个条件是：\n$$\n\\deg(I) > 2N - 1\n$$\n- 代入第1部分中 $\\deg(I)$ 的表达式：\n$$\n(p+1)N - 1 > 2N - 1\n$$\n- 这个不等式简化为：\n$$\n(p+1)N > 2N\n$$\n- 假设一个非平凡的多项式近似空间（即 $N \\geq 1$），我们可以两边除以 $N$：\n$$\np+1 > 2 \\implies p > 1\n$$\n- 问题指定 $p$ 是一个整数且 $p \\geq 2$。对于任何这样的 $p$，条件 $p > 1$ 都满足。因此，对于任何形式为 $u^p$（其中 $p \\geq 2$）的非线性通量，体积被积函数的次数 $(p+1)N-1$ 严格大于标准 $Q=N+1$ GLL 求积所提供的精确次数 $2N-1$。这种不精确积分会引入混叠误差，从而破坏数值解，并阻止该方法达到其 $N+1$ 的设计精度阶。\n\n**3. 充分的过积分条件**\n\n为了恢复设计精度阶，体积积分必须被精确计算。这可以通过采用具有足够高精确度的求积法则来实现，这种技术被称为过积分。我们的任务是为高斯-勒让德（GL）体积求积找到一个充分的点数 $M$。\n\n- 一个具有 $M$ 个点的 GL 求积法则已知对次数最高为 $2M-1$ 的多项式是精确的。\n- 为确保体积项的精确积分，GL 法则的精确次数必须大于或等于被积多项式的最大次数 $\\deg(I)$。\n- 这给出了条件：\n$$\n2M - 1 \\geq \\deg(I)\n$$\n- 代入推导出的被积函数次数：\n$$\n2M - 1 \\geq (p+1)N - 1\n$$\n- 简化不等式：\n$$\n2M \\geq (p+1)N\n$$\n- 求解 $M$：\n$$\nM \\geq \\frac{(p+1)N}{2}\n$$\n- 由于 $M$ 必须是表示求积点数的整数，满足此条件的最小整数 $M$ 值是不小于 $\\frac{(p+1)N}{2}$ 的最小整数。这由向上取整函数（ceiling function）给出。\n- 保证体积项精确积分所需的最少高斯-勒让德点数为：\n$$\nM_{min} = \\left\\lceil \\frac{(p+1)N}{2} \\right\\rceil\n$$\n$M$ 的这种选择确保了体积项积分不会引入混叠误差，这是 FR/CPR 格式对光滑解达到其 $N+1$ 的形式设计精度阶的一个必要条件。",
            "answer": "$$\\boxed{\\left\\lceil \\frac{(p+1)N}{2} \\right\\rceil}$$"
        },
        {
            "introduction": "数值方法的理论优雅性必须通过高效的计算实现来体现。最后的这项实践将FR方法带入高性能计算（HPC）领域，特别是图形处理器（GPU）上的实现。您将通过一个性能模型来分析不同的内存布局和计算顺序如何影响关键的FR校正步骤的效率，重点关注内存合并和占用率等概念 。这个练习旨在培养您在理论算法和现代硬件架构之间建立联系的能力。",
            "id": "3386482",
            "problem": "考虑通量重构（Flux Reconstruction, FR）方法中的修正步骤，该方法也称为通过重构的修正程序（Correction Procedure via Reconstruction, CPR）。在一维空间中，每个单元的多项式次数记为 $p$，设每个单元的解点数为 $n_p = p + 1$。对于单元索引 $e \\in \\{0,1,\\dots,E-1\\}$ 和节点索引 $i \\in \\{0,1,\\dots,n_p-1\\}$，半离散残差 $R[e,i]$ 的标准FR修正可写为以下形式\n$$\nR[e,i] \\leftarrow R[e,i] + G_L[i]\\cdot J_L[e] + G_R[i]\\cdot J_R[e],\n$$\n其中 $G_L[i]$ 和 $G_R[i]$ 是修正函数的节点值，$J_L[e]$ 和 $J_R[e]$ 是每个单元的面跳跃贡献。此更新应用于所有 $E \\cdot n_p$ 个自由度，是一个 $O(N)$ 的内核，其中 $N = E \\cdot n_p$。\n\n要求您为FR修正步骤建立两种图形处理单元（GPU）内核排序的模型，并分析重排计算如何影响内存合并和占用率，进而影响预测的运行时间。定义两种排序：\n- 排序A（单元主序遍历）：每个块更新一个单元；线程遍历节点索引 $i$。\n- 排序B（节点主序遍历）：每个块更新跨多个单元的同一个节点索引 $i$；线程遍历单元索引 $e$。\n\n假设残差数组 $R$ 具有以下内存布局：\n- 单元主序布局（EM）：展平索引 $k = e \\cdot n_p + i$。\n- 节点主序布局（NM）：展平索引 $k = i \\cdot E + e$。\n\n对于两种排序，假设每个线程在修正步骤中执行以下操作：\n- 算术：$c_{op} = 4$ 次浮点运算（两次乘法和两次加法）。\n- 内存：\n  - 读取两个双精度浮点数为 $G_L[i], G_R[i]$，总字节数为 $b_G = 16$（假设完全可缓存，因此完全合并）。\n  - 读取两个双精度浮点数为 $J_L[e], J_R[e]$，总字节数为 $b_J = 16$（假设在块内广播，因此完全合并）。\n  - 读-改-写一个双精度浮点数为 $R[e,i]$，总字节数为 $b_R = 16$（这是唯一其内存合并依赖于排序和布局的内存访问）。\n\n假设使用以下性能模型：\n- 线程束大小 $W = 32$。\n- 对于 $R$ 的访问，将步幅 $s$ 定义为一个线程束中连续线程之间地址的差异（以双精度浮点数为单位）。$R$ 访问的合并效率建模为\n$$\n\\epsilon(s) = \\begin{cases}\n1/s, & 1 \\le s \\le W,\\\\\n1/W, & s \\ge W,\n\\end{cases}\n$$\n并且仅应用于 $b_R$ 的贡献。所有其他字节都被认为是完全合并的，效率为 $1$。\n- 排序、布局和 $R$-步幅之间的映射关系：\n  - 对于单元主序布局（EM）：排序A的步幅为 $s_A = 1$，排序B的步幅为 $s_B = n_p$。\n  - 对于节点主序布局（NM）：排序A的步幅为 $s_A = E$，排序B的步幅为 $s_B = 1$。\n- 流式多处理器（SM）资源限制：\n  - 每个SM的最大线程数 $T_{SM}$，\n  - 每个SM的最大线程束数 $W_{SM}$，\n  - 每个SM的最大驻留块数 $B_{SM}$，\n  - 每个SM的寄存器文件大小 $R_{SM}$（以寄存器为单位），\n  - 每个SM的共享内存大小 $S_{SM}$（以字节为单位）。\n- 内核资源使用情况：\n  - 每块的线程数 $T_b$，\n  - 每个线程的寄存器数 $R_t$，\n  - 每块的共享内存大小 $S_b$。\n- 每个SM的占用率推导：\n  - 每块的线程束数 $w_b = \\lceil T_b / W \\rceil$，\n  - 受线程数限制的块数 $B_T = \\left\\lfloor \\dfrac{T_{SM}}{T_b} \\right\\rfloor$，\n  - 受线程束数限制的块数 $B_W = \\left\\lfloor \\dfrac{W_{SM}}{w_b} \\right\\rfloor$，\n  - 受寄存器数限制的块数 $B_R = \\left\\lfloor \\dfrac{R_{SM}}{R_t \\cdot T_b} \\right\\rfloor$，\n  - 受共享内存限制的块数 $B_S = \\left\\lfloor \\dfrac{S_{SM}}{S_b} \\right\\rfloor$（如果 $S_b > 0$），否则为 $+\\infty$，\n  - 驻留块数 $B_{res} = \\min\\{B_{SM}, B_T, B_W, B_R, B_S\\}$，\n  - 活动线程束数 $W_{act} = B_{res} \\cdot w_b$，\n  - 占用率 $\\mathrm{occ} = \\min\\left(1, \\dfrac{W_{act}}{W_{SM}}\\right)$。\n- 设备峰值计算吞吐量 $P_{peak}$（单位：浮点运算/秒）。\n- 设备峰值内存带宽 $B_{peak}$（单位：字节/秒）。\n- 对于总未知量 $N = E \\cdot n_p$，计算时间建模为\n$$\nt_{comp} = \\frac{N \\cdot c_{op}}{P_{peak} \\cdot \\mathrm{occ}},\n$$\n内存时间建模为\n$$\nt_{mem} = N \\cdot \\left(\\frac{b_R}{B_{peak} \\cdot \\epsilon(s)} + \\frac{b_G + b_J}{B_{peak}}\\right).\n$$\n- 内核时间是计算时间和内存时间的最大值：\n$$\nt = \\max\\{t_{comp}, t_{mem}\\}.\n$$\n\n您的任务是编写一个程序，该程序根据一个小型测试套件，为每种情况计算通过重排FR修正内核以最大化内存合并而获得的预测加速比，即较慢排序的预测运行时间与较快排序的预测运行时间的比率。对于每个测试，考虑在指定的布局和硬件约束下，排序A和排序B，并返回较优排序相对于较差排序的加速比。\n\n对所有测试使用以下固定的硬件参数：\n- 线程束大小 $W = 32$，\n- 每个SM的最大线程数 $T_{SM} = 2048$，\n- 每个SM的最大线程束数 $W_{SM} = 64$，\n- 每个SM的最大驻留块数 $B_{SM} = 32$，\n- 每个SM的寄存器文件大小 $R_{SM} = 65536$，\n- 每个SM的共享内存大小 $S_{SM} = 65536$ 字节，\n- 设备峰值计算吞吐量 $P_{peak} = 10^{13}$ 浮点运算/秒，\n- 设备峰值内存带宽 $B_{peak} = 6 \\times 10^{11}$ 字节/秒。\n\n对所有测试使用以下固定的内核级参数：\n- 每个线程的操作数 $c_{op} = 4$ 次浮点运算，\n- 每个线程的字节数 $b_G = 16$, $b_J = 16$, $b_R = 16$。\n\n测试套件：\n- 测试 $1$（理想情况，单元主序布局有利于单元主序遍历）：\n  - $E = 4096$, $p = 7$ (因此 $n_p = 8$), 布局 $\\text{EM}$,\n  - 排序A：$T_b = 32$, $R_t = 48$, $S_b = 0$,\n  - 排序B：$T_b = 256$, $R_t = 64$, $S_b = 0$。\n- 测试 $2$（布局翻转，节点主序布局有利于节点主序遍历）：\n  - $E = 4096$, $p = 7$ (因此 $n_p = 8$), 布局 $\\text{NM}$,\n  - 排序A：$T_b = 32$, $R_t = 48$, $S_b = 0$,\n  - 排序B：$T_b = 256$, $R_t = 64$, $S_b = 0$。\n- 测试 $3$（寄存器压力边界，大 $p$）：\n  - $E = 8192$, $p = 31$ (因此 $n_p = 32$), 布局 $\\text{EM}$,\n  - 排序A：$T_b = 32$, $R_t = 128$, $S_b = 0$,\n  - 排序B：$T_b = 256$, $R_t = 64$, $S_b = 0$。\n- 测试 $4$（小问题规模边界情况）：\n  - $E = 16$, $p = 1$ (因此 $n_p = 2$), 布局 $\\text{NM}$,\n  - 排序A：$T_b = 32$, $R_t = 24$, $S_b = 0$,\n  - 排序B：$T_b = 64$, $R_t = 24$, $S_b = 0$。\n- 测试 $5$（排序A的共享内存占用率限制）：\n  - $E = 2048$, $p = 15$ (因此 $n_p = 16$), 布局 $\\text{EM}$,\n  - 排序A：$T_b = 32$, $R_t = 48$, $S_b = 32768$,\n  - 排序B：$T_b = 256$, $R_t = 32$, $S_b = 0$。\n\n对于每个测试，使用上述模型计算预测运行时间 $t_A$ 和 $t_B$，然后计算加速比为\n$$\nS = \\frac{\\max\\{t_A, t_B\\}}{\\min\\{t_A, t_B\\}}.\n$$\n\n您的程序应生成单行输出，其中包含测试 $1$ 到 $5$ 的五个加速比，格式为逗号分隔的列表并用方括号括起来，每个加速比四舍五入到六位小数（例如 $[1.234567,2.000000, \\dots]$）。不涉及角度，因此不需要角度单位。输出中无需报告物理单位；数值为无量纲的比率。",
            "solution": "该问题要求分析通量重构（FR）方法中修正步骤的GPU内核性能。具体来说，我们需要为残差数组 $R$ 的两种不同内存布局——单元主序（EM）和节点主序（NM）——对两种不同的计算排序（称为排序A（单元主序）和排序B（节点主序））的运行时间进行建模。目标是预测在给定布局和一组内核参数的情况下，通过选择性能更优的排序所能实现的加速比。\n\n解决方案涉及逐步应用所提供的性能模型。对于每个测试用例，我们必须计算排序A和排序B的预测运行时间 $t$。运行时间定义为计算受限时间 $t_{comp}$ 和内存受限时间 $t_{mem}$ 的最大值。加速比 $S$ 则是较大运行时间与较小运行时间的比值。\n\n对每种排序的计算过程如下：\n\n首先，我们确定占用率 $\\mathrm{occ}$，它表示在给定的内核启动配置下，流式多处理器（SM）的计算资源被主动利用的比例。占用率受到最受限资源的限制，无论是线程、线程束、寄存器还是共享内存。问题陈述中定义了以下量：\n- 线程束大小: $W$\n- 每个SM的最大线程数: $T_{SM}$\n- 每个SM的最大线程束数: $W_{SM}$\n- 每个SM的最大驻留块数: $B_{SM}$\n- 每个SM的寄存器文件大小: $R_{SM}$\n- 每个SM的共享内存大小: $S_{SM}$\n- 内核的每块线程数: $T_b$\n- 每个线程的寄存器数: $R_t$\n- 每块的共享内存大小: $S_b$\n\n由此，我们推导出每个SM上并发块数的资源限制：\n1.  每块的线程束数: $w_b = \\lceil T_b / W \\rceil$。\n2.  受线程数限制的块数: $B_T = \\left\\lfloor \\dfrac{T_{SM}}{T_b} \\right\\rfloor$。\n3.  受线程束数限制的块数: $B_W = \\left\\lfloor \\dfrac{W_{SM}}{w_b} \\right\\rfloor$。\n4.  受寄存器数限制的块数: $B_R = \\left\\lfloor \\dfrac{R_{SM}}{R_t \\cdot T_b} \\right\\rfloor$。\n5.  受共享内存限制的块数: $B_S = \\left\\lfloor \\dfrac{S_{SM}}{S_b} \\right\\rfloor$（如果 $S_b > 0$），否则 $B_S$ 实际上是无限的。\n\n每个SM的驻留块数 $B_{res}$ 是这些限制与架构最大值的最小值：\n$$\nB_{res} = \\min\\{B_{SM}, B_T, B_W, B_R, B_S\\}\n$$\n每个SM的活动线程束数则为 $W_{act} = B_{res} \\cdot w_b$。最后，占用率为：\n$$\n\\mathrm{occ} = \\min\\left(1, \\dfrac{W_{act}}{W_{SM}}\\right)\n$$\n\n第二，我们计算计算受限时间 $t_{comp}$。该时间与有效峰值计算吞吐量成反比，有效峰值计算吞吐量是设备的峰值吞吐量 $P_{peak}$ 乘以占用率。对于一个总自由度为 $N = E \\cdot n_p$（其中 $n_p = p+1$）、每个自由度需要 $c_{op}$ 次浮点运算的问题，计算时间为：\n$$\nt_{comp} = \\frac{N \\cdot c_{op}}{P_{peak} \\cdot \\mathrm{occ}}\n$$\n\n第三，我们计算内存受限时间 $t_{mem}$。该时间取决于传输的数据量和有效内存带宽。区分不同排序的关键因素是访问残差数组 $R$ 进行读-改-写操作时的内存合并。该模型定义了一个合并效率 $\\epsilon(s)$，它是一个线程束中连续线程访问的内存地址之间的步幅 $s$ 的函数。步幅本身由内存布局（EM或NM）和内核遍历排序（A或B）的组合决定。\n给定的映射关系是：\n- 对于单元主序布局（EM）：排序A的步幅为 $s_A = 1$；排序B的步幅为 $s_B = n_p$。\n- 对于节点主序布局（NM）：排序A的步幅为 $s_A = E$；排序B的步幅为 $s_B = 1$。\n\n$R$ 访问的合并效率由以下公式给出：\n$$\n\\epsilon(s) = \\begin{cases}\n1/s, & 1 \\le s \\le W,\\\\\n1/W, & s \\ge W,\n\\end{cases}\n$$\n所有 $N$ 个自由度的总内存时间是与合并无关的访问（$G_L, G_R, J_L, J_R$，总字节数为 $b_G + b_J$）和与合并相关的访问（$R$，字节数为 $b_R$）的贡献之和：\n$$\nt_{mem} = N \\cdot \\left(\\frac{b_R}{B_{peak} \\cdot \\epsilon(s)} + \\frac{b_G + b_J}{B_{peak}}\\right)\n$$\n步幅 $s=1$ 产生完美的合并效率 $\\epsilon(1)=1$，从而最小化内存时间。较大的步幅会降低 $R$ 数组访问的有效带宽，从而降低性能。\n\n第四，预测的内核运行时间 $t$ 是计算时间和内存时间的最大值，因为一个内核可能是计算受限的，也可能是内存受限的：\n$$\nt = \\max\\{t_{comp}, t_{mem}\\}\n$$\n\n最后，对于每个测试用例，我们计算排序A的运行时间 $t_A$ 和排序B的运行时间 $t_B$。加速比 $S$ 是较慢时间与较快时间的比率，表示选择最优排序所带来的性能增益：\n$$\nS = \\frac{\\max\\{t_A, t_B\\}}{\\min\\{t_A, t_B\\}}\n$$\n将此过程系统地应用于所有提供的测试用例，以得出最终结果。",
            "answer": "```python\nimport numpy as np\nimport math\n\n# Define fixed hardware and kernel parameters\nW = 32\nT_SM = 2048\nW_SM = 64\nB_SM = 32\nR_SM = 65536\nS_SM = 65536\nP_peak = 1e13\nB_peak = 6e11\nc_op = 4\nb_G = 16\nb_J = 16\nb_R = 16\n\ndef calculate_time(E, p, layout, T_b, R_t, S_b, ordering):\n    \"\"\"\n    Calculates the predicted runtime for a given configuration based on the provided performance model.\n    \"\"\"\n    # 1. Calculate derived problem-specific values\n    n_p = p + 1\n    N = E * n_p\n\n    # 2. Calculate Occupancy (occ)\n    w_b = math.ceil(T_b / W)\n    \n    B_T = math.floor(T_SM / T_b)\n    B_W = math.floor(W_SM / w_b)\n\n    # Prevent division by zero if T_b or R_t is zero, though not expected from problem statement.\n    if R_t * T_b > 0:\n        B_R = math.floor(R_SM / (R_t * T_b))\n    else:\n        B_R = float('inf')\n\n    if S_b > 0:\n        B_S = math.floor(S_SM / S_b)\n    else:\n        B_S = float('inf')\n\n    B_res = min(B_SM, B_T, B_W, B_R, B_S)\n    W_act = B_res * w_b\n    occ = min(1.0, W_act / W_SM) if W_SM > 0 else 0.0\n\n    # 3. Calculate Compute Time (t_comp)\n    # Prevent division by zero if P_peak or occ is zero\n    if P_peak > 0 and occ > 0:\n        t_comp = (N * c_op) / (P_peak * occ)\n    else:\n        t_comp = float('inf')\n\n    # 4. Calculate Memory Time (t_mem)\n    # Determine stride s\n    if layout == 'EM':\n        s = 1 if ordering == 'A' else n_p\n    elif layout == 'NM':\n        s = E if ordering == 'A' else 1\n    else:\n        raise ValueError(\"Invalid memory layout specified.\")\n\n    # Calculate coalescing efficiency epsilon(s)\n    if 1 <= s <= W:\n        epsilon_s = 1.0 / s\n    else: # s > W\n        epsilon_s = 1.0 / W\n    \n    # Calculate t_mem\n    # Prevent division by zero if B_peak or epsilon_s is zero\n    if B_peak > 0 and epsilon_s > 0:\n        term_R = b_R / (B_peak * epsilon_s)\n        term_GJ = (b_G + b_J) / B_peak\n        t_mem = N * (term_R + term_GJ)\n    else:\n        t_mem = float('inf')\n\n    # 5. Calculate Kernel Time (t)\n    t = max(t_comp, t_mem)\n\n    return t\n\ndef solve():\n    \"\"\"\n    Processes the test suite to calculate speedups for each case.\n    \"\"\"\n    test_cases = [\n        # Test 1: E, p, layout, (T_b_A, R_t_A, S_b_A), (T_b_B, R_t_B, S_b_B)\n        (4096, 7, 'EM', (32, 48, 0), (256, 64, 0)),\n        # Test 2\n        (4096, 7, 'NM', (32, 48, 0), (256, 64, 0)),\n        # Test 3\n        (8192, 31, 'EM', (32, 128, 0), (256, 64, 0)),\n        # Test 4\n        (16, 1, 'NM', (32, 24, 0), (64, 24, 0)),\n        # Test 5\n        (2048, 15, 'EM', (32, 48, 32768), (256, 32, 0)),\n    ]\n\n    results = []\n    for case in test_cases:\n        E, p, layout, params_A, params_B = case\n        T_b_A, R_t_A, S_b_A = params_A\n        T_b_B, R_t_B, S_b_B = params_B\n\n        t_A = calculate_time(E, p, layout, T_b_A, R_t_A, S_b_A, 'A')\n        t_B = calculate_time(E, p, layout, T_b_B, R_t_B, S_b_B, 'B')\n        \n        if min(t_A, t_B) > 0:\n            speedup = max(t_A, t_B) / min(t_A, t_B)\n        else:\n            speedup = 1.0 # Should not happen with valid inputs\n\n        results.append(f\"{speedup:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}