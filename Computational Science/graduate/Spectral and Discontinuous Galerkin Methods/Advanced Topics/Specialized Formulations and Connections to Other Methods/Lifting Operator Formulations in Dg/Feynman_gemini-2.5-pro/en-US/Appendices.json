{
    "hands_on_practices": [
        {
            "introduction": "The lifting operator is a core component in many Discontinuous Galerkin (DG) formulations, translating information from element faces into the element interior. To truly understand this operator, it is essential to move beyond its abstract definition and perform a concrete calculation. This first exercise guides you through computing the explicit polynomial representation of a lifting operator in a simple one-dimensional setting, grounding the theory in a direct, hands-on application of the Riesz representation theorem. ",
            "id": "3395997",
            "problem": "Consider the one-dimensional reference element $K=[-1,1]$ and the scalar finite-dimensional approximation space $V_h=\\mathbb{P}_1(K)$ of polynomials of degree at most $1$ on $K$. In the Discontinuous Galerkin (DG) method, the face lifting operator $L_F$ maps a face function $g$ supported on a single face $F\\subset \\partial K$ into a volumetric function $L_F(g)\\in V_h$, defined by the Riesz representation of the boundary functional with respect to the $L^2(K)$ inner product:\n$$\n\\int_{K} L_F(g)\\, v \\, dx \\;=\\; \\int_{F} g\\, v \\, ds \\quad \\text{for all } v\\in V_h.\n$$\nAssume the endpoint face $F=\\{1\\}$, and let $g=1$ on $F$. Use the standard $L^2(K)$ inner product as the Riesz map and represent $L_F(g)$ in the basis $\\{\\phi_0(x),\\phi_1(x)\\}=\\{1,x\\}$ of $V_h$ by solving the associated mass-matrix system. Compute the explicit closed-form expression for $L_F(g)$ as a function of $x$.\n\nYour final answer must be a single closed-form analytic expression. Do not provide intermediate equations in the final answer.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, objective, and complete.\n\n### Step 1: Extract Givens\n- Domain: One-dimensional reference element $K = [-1, 1]$.\n- Approximation space: $V_h = \\mathbb{P}_1(K)$, the space of polynomials of degree at most $1$.\n- Basis for $V_h$: $\\{\\phi_0(x), \\phi_1(x)\\} = \\{1, x\\}$.\n- Definition of face lifting operator $L_F(g) \\in V_h$:\n$$ \\int_{K} L_F(g)\\, v \\, dx = \\int_{F} g\\, v \\, ds \\quad \\text{for all } v \\in V_h. $$\n- Specific face: $F = \\{1\\}$.\n- Specific face function: $g = 1$ on $F$.\n- Inner product for Riesz map: Standard $L^2(K)$ inner product, $\\langle u, v \\rangle = \\int_K uv \\, dx$.\n- Task: Compute the explicit closed-form expression for $L_F(g)$ as a function of $x$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded within the field of numerical analysis, specifically the Discontinuous Galerkin (DG) method. The definition of the lifting operator via the Riesz representation theorem is a standard and core concept in the theory of DG methods. The problem is well-posed; for a finite-dimensional space $V_h$ with a given inner product, the Riesz representation theorem guarantees the existence and uniqueness of the solution $L_F(g)$. The problem statement is objective, using precise mathematical terminology without ambiguity. All necessary data and definitions are provided, and there are no contradictions. The problem is a standard, solvable exercise in applying the definition of the DG lifting operator.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be derived.\n\n### Solution Derivation\nThe objective is to find the function $L_F(g) \\in V_h = \\mathbb{P}_1(K)$. Since $L_F(g)$ is a polynomial of degree at most $1$, it can be expressed as a linear combination of the basis functions $\\{\\phi_0(x), \\phi_1(x)\\} = \\{1, x\\}$. Let this representation be:\n$$\nL_F(g)(x) = c_0 \\phi_0(x) + c_1 \\phi_1(x) = c_0 \\cdot 1 + c_1 \\cdot x\n$$\nwhere $c_0$ and $c_1$ are the unknown coefficients to be determined.\n\nThe defining equation for the lifting operator is:\n$$\n\\int_{K} L_F(g)\\, v \\, dx = \\int_{F} g\\, v \\, ds\n$$\nThis equation must hold for all test functions $v \\in V_h$. It is sufficient to enforce this condition for the basis functions $v = \\phi_0(x)$ and $v = \\phi_1(x)$. This yields a system of two linear equations for the two unknowns $c_0$ and $c_1$.\n\nSubstituting the expression for $L_F(g)(x)$ into the defining equation, we get:\n$$\n\\int_{-1}^{1} (c_0 + c_1 x) \\, v(x) \\, dx = \\int_{\\{1\\}} g(1) \\, v(1) \\, ds\n$$\nThe integral over the face $F=\\{1\\}$ is interpreted as a point evaluation, so $\\int_{\\{1\\}} f(x) ds = f(1)$. Given $g=1$ on $F$, the right-hand side becomes $g(1)v(1) = 1 \\cdot v(1) = v(1)$.\n\nWe now test for each basis function:\n\nCase 1: $v(x) = \\phi_0(x) = 1$.\nThe equation becomes:\n$$\n\\int_{-1}^{1} (c_0 + c_1 x) \\cdot 1 \\, dx = \\phi_0(1) = 1\n$$\n$$\nc_0 \\int_{-1}^{1} 1 \\, dx + c_1 \\int_{-1}^{1} x \\, dx = 1\n$$\nEvaluating the integrals:\n$$\n\\int_{-1}^{1} 1 \\, dx = [x]_{-1}^{1} = 1 - (-1) = 2\n$$\n$$\n\\int_{-1}^{1} x \\, dx = \\left[\\frac{x^2}{2}\\right]_{-1}^{1} = \\frac{1}{2} - \\frac{1}{2} = 0\n$$\nSo, the first equation is:\n$$\n2c_0 + 0 \\cdot c_1 = 1\n$$\n\nCase 2: $v(x) = \\phi_1(x) = x$.\nThe equation becomes:\n$$\n\\int_{-1}^{1} (c_0 + c_1 x) \\cdot x \\, dx = \\phi_1(1) = 1\n$$\n$$\nc_0 \\int_{-1}^{1} x \\, dx + c_1 \\int_{-1}^{1} x^2 \\, dx = 1\n$$\nEvaluating the integrals:\n$$\n\\int_{-1}^{1} x \\, dx = 0\n$$\n$$\n\\int_{-1}^{1} x^2 \\, dx = \\left[\\frac{x^3}{3}\\right]_{-1}^{1} = \\frac{1}{3} - \\left(-\\frac{1}{3}\\right) = \\frac{2}{3}\n$$\nSo, the second equation is:\n$$\n0 \\cdot c_0 + \\frac{2}{3} c_1 = 1\n$$\n\nWe have the following system of linear equations for $(c_0, c_1)$:\n$$\n\\begin{pmatrix}\n\\int_K \\phi_0 \\phi_0 dx & \\int_K \\phi_0 \\phi_1 dx \\\\\n\\int_K \\phi_1 \\phi_0 dx & \\int_K \\phi_1 \\phi_1 dx\n\\end{pmatrix}\n\\begin{pmatrix}\nc_0 \\\\\nc_1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\phi_0(1) \\\\\n\\phi_1(1)\n\\end{pmatrix}\n$$\nSubstituting the calculated values:\n$$\n\\begin{pmatrix}\n2 & 0 \\\\\n0 & \\frac{2}{3}\n\\end{pmatrix}\n\\begin{pmatrix}\nc_0 \\\\\nc_1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 \\\\\n1\n\\end{pmatrix}\n$$\nThis is the mass-matrix system mentioned in the problem. Since the mass matrix is diagonal (due to the $L^2$-orthogonality of the basis functions $\\{1, x\\}$ on the symmetric interval $[-1, 1]$), the solution is found directly:\nFrom the first row:\n$$\n2c_0 = 1 \\implies c_0 = \\frac{1}{2}\n$$\nFrom the second row:\n$$\n\\frac{2}{3}c_1 = 1 \\implies c_1 = \\frac{3}{2}\n$$\nHaving found the coefficients, we can construct the explicit expression for the lifting operator's action on $g=1$ at face $F=\\{1\\}$:\n$$\nL_F(g)(x) = c_0 + c_1 x = \\frac{1}{2} + \\frac{3}{2}x\n$$\nThis is the required closed-form expression.",
            "answer": "$$\n\\boxed{\\frac{1}{2} + \\frac{3}{2}x}\n$$"
        },
        {
            "introduction": "While the exact lifting operator is defined via continuous integrals, practical DG codes rely on numerical quadrature to approximate them. This transition from the continuous to the discrete world is subtle and has profound implications for the accuracy and stability of the numerical scheme. This practice problem challenges you to analyze how different implementation choices—specifically the selection of basis functions and quadrature rules—affect the fidelity of the computed lifting operator, highlighting the critical link between numerical integration theory and practical code development. ",
            "id": "3396023",
            "problem": "Consider a single reference element $K$ (for example, a tensor-product interval or square) and the polynomial space $[\\mathbb{P}_p(K)]^d$, where $\\mathbb{P}_p(K)$ denotes polynomials of total degree at most $p$ on $K$ and $d \\in \\{1,2,3\\}$. In interior penalty discontinuous Galerkin (DG) formulations for second-order problems, a canonical lifting operator $R_h$ maps face data $\\lambda$ defined on $\\partial K$ into a vector field $R_h(\\lambda) \\in [\\mathbb{P}_p(K)]^d$ by the Riesz representation associated with the $L^2(K)$ inner product: for all $v \\in [\\mathbb{P}_p(K)]^d$,\n$$(R_h(\\lambda), v)_{L^2(K)} \\;=\\; \\langle \\lambda, v \\cdot n \\rangle_{L^2(\\partial K)}.$$\nHere $n$ is the outward unit normal on $\\partial K$. In practical implementations, the inner products on $K$ and on $\\partial K$ are computed either exactly or by quadrature, and the discrete Riesz map depends on these choices.\n\nTwo common implementations are:\n- Modal implementation: use a Legendre polynomial basis that is $L^2(K)$-orthonormal (with exact integration), so that the mass matrix on $K$ is diagonal under exact integration.\n- Nodal implementation: use the nodal basis associated with Legendre-Gauss-Lobatto (LGL) nodes and compute all volume and face integrals by the collocated LGL quadrature with $p+1$ points in each coordinate direction.\n\nWell-tested quadrature facts to use:\n- $N$-point Gauss-Legendre (GL) quadrature on an interval is exact for polynomials of degree up to $2N-1$.\n- $(N+1)$-point Legendre-Gauss-Lobatto (LGL) quadrature on an interval is exact for polynomials of degree up to $2N-1$.\n- Tensor-product rules have degrees of exactness given by the tensor product of the one-dimensional degrees.\n\nAnswer the following multiple-choice question. Select all statements that are correct and justify your choices from first principles, explicitly invoking the definition of the Riesz map and the degrees of exactness.\n\nWhich of the following statements about lifting implementations and quadrature exactness are correct?\n\nA. With a modal Legendre basis and exact integration in the volume and on the faces, the computed lifting coincides with the exact $L^2(K)$ Riesz representative of the face functional for all $\\lambda \\in \\mathbb{P}_p(\\partial K)$.\n\nB. With a modal Legendre basis but with both volume and face integrals approximated by $(p+1)$-point LGL quadrature, the resulting lifting differs from the exact lifting only in the coefficient multiplying the highest-order Legendre mode in each element; all lower modal coefficients match the exact lifting for any polynomial face data $\\lambda$.\n\nC. With a nodal LGL basis and collocated $(p+1)$-point LGL quadrature in the volume and on the faces, the computed lifting is the exact Riesz representative with respect to the quadrature-induced inner product $(\\cdot,\\cdot)_Q$, not the exact $L^2(K)$ inner product, and its discrepancy relative to the exact $L^2(K)$ lifting is confined to contributions of polynomial degree $2p$ in the volume and on the faces.\n\nD. To guarantee that the discrete lifting coincides with the exact $L^2(K)$ Riesz map for all polynomial face data $\\lambda$ of degree at most $p$, it suffices to use $(p+1)$-point LGL quadrature for the volume integrals, while any face quadrature with at least $(p+1)$ points per direction is adequate.\n\nE. If one uses $(p+1)$-point Gauss-Legendre quadrature in the volume and on each face, then both the modal and nodal implementations produce lifting coefficients identical to the exact $L^2(K)$ Riesz representative for all $\\lambda \\in \\mathbb{P}_p(\\partial K)$.",
            "solution": "The user has requested a rigorous validation and solution of a problem concerning lifting operators in discontinuous Galerkin methods.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **Domain**: A single reference element $K$ (e.g., tensor-product interval or square).\n*   **Polynomial Space**: $[\\mathbb{P}_p(K)]^d$, the space of vector-valued polynomials where each component is a polynomial of total degree at most $p$. The dimension $d \\in \\{1,2,3\\}$.\n*   **Lifting Operator**: $R_h$ maps face data $\\lambda$ from $\\partial K$ to a vector field $R_h(\\lambda) \\in [\\mathbb{P}_p(K)]^d$.\n*   **Defining Equation (Riesz Map)**: For all test functions $v \\in [\\mathbb{P}_p(K)]^d$, the lifting operator $R_h(\\lambda)$ satisfies:\n    $$(R_h(\\lambda), v)_{L^2(K)} = \\langle \\lambda, v \\cdot n \\rangle_{L^2(\\partial K)}$$\n    where $n$ is the outward unit normal on $\\partial K$.\n*   **Implementations**:\n    1.  **Modal**: Uses an $L^2(K)$-orthonormal Legendre polynomial basis.\n    2.  **Nodal**: Uses a nodal basis associated with Legendre-Gauss-Lobatto (LGL) nodes and computes integrals using collocated LGL quadrature with $p+1$ points per dimension.\n*   **Quadrature Rules**:\n    1.  $N$-point Gauss-Legendre (GL) quadrature on an interval is exact for polynomials of degree up to $2N-1$.\n    2.  $(N+1)$-point Legendre-Gauss-Lobatto (LGL) quadrature on an interval is exact for polynomials of degree up to $2N-1$.\n*   **Face Data**: The options specify $\\lambda \\in \\mathbb{P}_p(\\partial K)$.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientific Grounding**: The problem is firmly rooted in the theory of spectral and discontinuous Galerkin (DG) methods, a standard and well-established area of numerical analysis. The definition of the lifting operator as a Riesz map is canonical.\n*   **Well-Posedness**: The problem asks for an evaluation of several statements based on the provided definitions and facts. This is a well-defined task with a determinable set of correct answers.\n*   **Objectivity**: The problem is stated in precise, objective, mathematical language, free from subjective or ambiguous terminology.\n*   **Completeness and Consistency**: The problem provides all necessary definitions (lifting operator, polynomial spaces, inner products) and facts (quadrature rules) to analyze the statements. There are no internal contradictions.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is scientifically sound, well-posed, objective, and self-contained. It is valid. I will now proceed with the solution.\n\n### Derivation\n\nThe core of the problem lies in understanding when a numerically computed lifting operator, $R_{h,Q}(\\lambda)$, equals the exact one, $R_h(\\lambda)$. The exact lifting operator is the unique element in $[\\mathbb{P}_p(K)]^d$ that satisfies the defining equation.\n\nLet $\\{\\phi_i\\}_{i=1}^M$ be a basis for $[\\mathbb{P}_p(K)]^d$. We can express the lifting operator as $R_h(\\lambda) = \\sum_{j=1}^M r_j \\phi_j$. Substituting this into the defining equation and testing against each basis function $\\phi_i$ yields a linear system for the coefficients $r = (r_j)$:\n$$ \\sum_{j=1}^M \\underbrace{(\\phi_j, \\phi_i)_{L^2(K)}}_{M_{ij}} r_j = \\underbrace{\\langle \\lambda, \\phi_i \\cdot n \\rangle_{L^2(\\partial K)}}_{F_i} \\implies Mr = F $$\nwhere $M$ is the mass matrix and $F$ is the load vector. The exact solution is $r = M^{-1}F$.\n\nA numerical implementation replaces the exact integrals with quadrature rules, leading to a computed mass matrix $M_Q$ and a computed load vector $F_Q$. The computed coefficients are $r_Q = M_Q^{-1} F_Q$. The computed lifting $R_{h,Q}(\\lambda)$ equals the exact lifting $R_h(\\lambda)$ if and only if the coefficients are identical, $r_Q = r$. This occurs if and only if the quadrature is exact for all integrals involved, i.e., $M_Q = M$ and $F_Q = F$.\n\nLet's determine the required degree of exactness for the quadrature rules.\n1.  **Mass Matrix Integrand**: The entries of $M$ are integrals of $\\phi_j \\cdot \\phi_i$ over $K$. Since $\\phi_i, \\phi_j \\in [\\mathbb{P}_p(K)]^d$, their dot product is a sum of products of polynomials of total degree up to $p$. The resulting integrand has a total degree of at most $p+p=2p$.\n2.  **Load Vector Integrand**: The entries of $F$ are integrals of $\\lambda (v \\cdot n)$ over $\\partial K$. The problem considers $\\lambda \\in \\mathbb{P}_p(\\partial K)$. The test function components are traces of polynomials in $\\mathbb{P}_p(K)$, so they are in $\\mathbb{P}_p(\\partial K)$. The integrand on each face therefore has a degree of at most $p+p=2p$.\n\nTherefore, to guarantee $R_{h,Q}(\\lambda) = R_h(\\lambda)$ for all $\\lambda \\in \\mathbb{P}_p(\\partial K)$, the volume quadrature for the mass matrix and the face quadrature for the load vector must both be exact for polynomials of degree up to $2p$.\n\nLet's analyze the provided quadrature rules:\n*   **$(p+1)$-point GL quadrature**: Setting $N=p+1$ in the rule \"exact for degree $2N-1$\" gives a degree of exactness of $2(p+1)-1 = 2p+1$. This is sufficient to integrate polynomials of degree $2p$ exactly.\n*   **$(p+1)$-point LGL quadrature**: Setting $N+1=p+1 \\implies N=p$ in the rule \"exact for degree $2N-1$\" gives a degree of exactness of $2p-1$. This is **not** sufficient to integrate polynomials of degree $2p$ exactly.\n\n### Option-by-Option Analysis\n\n**A. With a modal Legendre basis and exact integration in the volume and on the faces, the computed lifting coincides with the exact $L^2(K)$ Riesz representative of the face functional for all $\\lambda \\in \\mathbb{P}_p(\\partial K)$.**\n\nThis statement posits the use of \"exact integration\". This means the computed mass matrix $M_Q$ is identical to the exact mass matrix $M$, and the computed load vector $F_Q$ is identical to the exact load vector $F$. By definition, the solution of the system $Mr=F$ gives the coefficients for the exact $L^2(K)$ Riesz representative. Since the computation uses the exact matrices and vectors, the result must be the exact Riesz representative. The choice of basis (modal Legendre) is incidental to this conclusion; it would be true for any basis.\n\n**Verdict: Correct.**\n\n**B. With a modal Legendre basis but with both volume and face integrals approximated by $(p+1)$-point LGL quadrature, the resulting lifting differs from the exact lifting only in the coefficient multiplying the highest-order Legendre mode in each element; all lower modal coefficients match the exact lifting for any polynomial face data $\\lambda$.**\n\nLet the basis $\\{\\phi_i\\}$ be ordered by polynomial degree. We use $(p+1)$-point LGL quadrature, which is exact for degree $2p-1$.\nThe mass matrix is $M_{ij} = (\\phi_j, \\phi_i)_{L^2(K)}$. For a modal Legendre basis, $M$ is the identity matrix ($I$). The computed mass matrix $(M_Q)_{ij}$ is found using quadrature. The integrand $\\phi_j \\cdot \\phi_i$ has degree $\\deg(\\phi_j) + \\deg(\\phi_i)$. The integral is exact if $\\deg(\\phi_j) + \\deg(\\phi_i) \\le 2p-1$. If we partition the basis into functions of degree $<p$ (low) and degree $=p$ (high), the computed mass matrix $M_Q$ is block-diagonal, specifically $\\begin{pmatrix} I & 0 \\\\ 0 & M_{hh,Q} \\end{pmatrix}$, where $M_{hh,Q}$ is the submatrix for high-degree modes and is not equal to the identity.\nThe load vector is $F_i = \\langle \\lambda, \\phi_i \\cdot n \\rangle_{L^2(\\partial K)}$. The integrand has degree up to $\\deg(\\lambda) + \\deg(\\phi_i)$. Assuming $\\lambda \\in \\mathbb{P}_p(\\partial K)$, the degree is up to $p + \\deg(\\phi_i)$. The integral is exact if $p + \\deg(\\phi_i) \\le 2p-1$, which simplifies to $\\deg(\\phi_i) \\le p-1$. Thus, the load vector components for low-degree modes are computed exactly ($F_{l,Q} = F_l$), but not for high-degree modes ($F_{h,Q} \\neq F_h$).\nThe computed coefficients $r_Q$ solve $M_Q r_Q = F_Q$. This decouples to $I r_{l,Q} = F_{l,Q}$ and $M_{hh,Q} r_{h,Q} = F_{h,Q}$. From the first equation, $r_{l,Q} = F_{l,Q} = F_l$, which are the exact coefficients for the low-degree modes. The high-degree coefficients, $r_{h,Q}$, are different from the exact ones.\nThe analysis confirms that the error is confined to the coefficients of the basis functions of degree $p$. However, the statement claims the error is \"only in the coefficient multiplying **the** highest-order Legendre mode\". This phrasing implies a unique highest-order mode. This is true only in one dimension ($d=1$). For $d>1$ (e.g., on a square), the space $\\mathbb{P}_p(K)$ contains multiple basis functions of the maximal degree $p$ (e.g., for $p=2$, $x^2$, $xy$, $y^2$). Therefore, the statement is not formally correct for the general case described in the problem setup. A meticulous evaluation must reject it based on this imprecision.\n\n**Verdict: Incorrect.**\n\n**C. With a nodal LGL basis and collocated $(p+1)$-point LGL quadrature in the volume and on the faces, the computed lifting is the exact Riesz representative with respect to the quadrature-induced inner product $(\\cdot,\\cdot)_Q$, not the exact $L^2(K)$ inner product, and its discrepancy relative to the exact $L^2(K)$ lifting is confined to contributions of polynomial degree $2p$ in the volume and on the faces.**\n\nThe computed lifting $R_{h,Q}(\\lambda)$ is found by solving $(R_{h,Q}, v)_Q = \\langle \\lambda, v \\cdot n \\rangle_Q$ for all $v \\in [\\mathbb{P}_p(K)]^d$. This is precisely the definition of the Riesz representative in the space $[\\mathbb{P}_p(K)]^d$ endowed with the discrete inner product $(\\cdot,\\cdot)_Q$. So the first part of the statement is correct by definition.\nThe discrepancy arises because $(\\cdot,\\cdot)_Q \\neq (\\cdot,\\cdot)_{L^2(K)}$ and $\\langle\\cdot,\\cdot\\rangle_Q \\neq \\langle\\cdot,\\cdot\\rangle_{L^2(\\partial K)}$. The $(p+1)$-point LGL quadrature is exact for polynomials up to degree $2p-1$. The integrands for the mass matrix and load vector can have degree up to $2p$. The quadrature error functional is zero for any polynomial integrand of degree $\\le 2p-1$. The first degree for which the quadrature is inexact is $2p$. Therefore, the source of any discrepancy between the computed and exact solutions stems from the failure of the quadrature rule to exactly integrate polynomials of degree $2p$. The statement that the discrepancy is \"confined to contributions of polynomial degree $2p$\" correctly identifies this source.\n\n**Verdict: Correct.**\n\n**D. To guarantee that the discrete lifting coincides with the exact $L^2(K)$ Riesz map for all polynomial face data $\\lambda$ of degree at most $p$, it suffices to use $(p+1)$-point LGL quadrature for the volume integrals, while any face quadrature with at least $(p+1)$ points per direction is adequate.**\n\nTo guarantee the computed lifting is identical to the exact one, both the volume and face quadratures must be exact for polynomials of degree up to $2p$. The statement proposes using $(p+1)$-point LGL quadrature for the volume integrals. As established, this rule is only exact for polynomials of degree up to $2p-1$. It is therefore insufficient to compute the mass matrix exactly, as some entries involve integrals of polynomials of degree $2p$. The statement is false on this basis alone.\n\n**Verdict: Incorrect.**\n\n**E. If one uses $(p+1)$-point Gauss-Legendre quadrature in the volume and on each face, then both the modal and nodal implementations produce lifting coefficients identical to the exact $L^2(K)$ Riesz representative for all $\\lambda \\in \\mathbb{P}_p(\\partial K)$.**\n\nAs derived earlier, ensuring the computed lifting is identical to the exact one requires quadrature rules that are exact for polynomials of degree up to $2p$. The $(p+1)$-point Gauss-Legendre (GL) quadrature rule is exact for polynomials of degree up to $2(p+1)-1 = 2p+1$. Since $2p+1 \\ge 2p$, this rule is sufficient to compute both the mass matrix and the load vector entries exactly. This means $M_Q = M$ and $F_Q = F$. The computed coefficients $r_Q = M_Q^{-1}F_Q$ will therefore be identical to the exact coefficients $r=M^{-1}F$. This conclusion is independent of the choice of basis (modal or nodal), as the underlying function $R_h(\\lambda)$ represented by these coefficients is unique.\n\n**Verdict: Correct.**",
            "answer": "$$\\boxed{ACE}$$"
        },
        {
            "introduction": "Beyond single-element accuracy, the efficiency of a DG method on large-scale problems depends critically on high-level algorithmic decisions. When dealing with lifting operators, a key choice is whether to precompute and store the operator matrices or to apply them \"on-the-fly\" by solving small linear systems as needed. This exercise provides a framework for quantitatively comparing these two strategies, offering valuable insight into the trade-offs between memory usage and computational cost that are central to designing high-performance scientific software. ",
            "id": "3396038",
            "problem": "Consider the Discontinuous Galerkin (DG) method on a three-dimensional, structured grid of hexahedral elements with tensor-product polynomial basis of degree $p=4$. For each element $K$, define the face lifting operator $r_{F}$ by the discrete Riesz representation: for any face $F \\subset \\partial K$ and any face function $v$ in the trace space, $r_{F} v \\in \\mathcal{P}_{p}(K)$ satisfies\n$$\n(r_{F} v, w)_{K} = \\langle v, w|_{F} \\rangle_{F} \\quad \\text{for all } w \\in \\mathcal{P}_{p}(K),\n$$\nwhere $(\\cdot,\\cdot)_{K}$ denotes the element $L^{2}$ inner product and $\\langle \\cdot,\\cdot \\rangle_{F}$ denotes the face $L^{2}$ inner product. In a finite-dimensional representation, this leads to the linear algebraic relation\n$$\n\\mathbf{M}_{K} \\, \\mathbf{R}_{F} = \\mathbf{B}_{F}^{\\top},\n$$\nwhere $\\mathbf{M}_{K} \\in \\mathbb{R}^{N_{p} \\times N_{p}}$ is the element mass matrix, $\\mathbf{R}_{F} \\in \\mathbb{R}^{N_{p} \\times N_{f}}$ is the matrix representation of $r_{F}$, and $\\mathbf{B}_{F}^{\\top} \\in \\mathbb{R}^{N_{p} \\times N_{f}}$ couples face degrees of freedom to volume test functions. For tensor-product bases on hexahedra, the number of element degrees of freedom is $N_{p} = (p+1)^{3}$ and the number of face degrees of freedom is $N_{f} = (p+1)^{2}$. Each hexahedral element has $6$ faces.\n\nAdopt the following dense linear algebra cost model (counting floating-point additions and multiplications equally as one flop):\n- Cholesky factorization of a symmetric positive definite matrix $\\mathbf{M}_{K} \\in \\mathbb{R}^{N_{p} \\times N_{p}}$ costs $\\frac{1}{3} N_{p}^{3}$ flops.\n- Solving $\\mathbf{M}_{K} \\mathbf{x} = \\mathbf{b}$ using the Cholesky factors with forward and backward substitutions costs $2 N_{p}^{2}$ flops per right-hand side.\n- A matrix-vector product with a matrix in $\\mathbb{R}^{m \\times n}$ costs $2 m n$ flops.\n\nAssume a structured grid of $N_{x} \\times N_{y} \\times N_{z}$ elements, and that the element mass matrix factorization (Cholesky) is performed once per element and reused thereafter. Consider two strategies:\n1. Precompute all per-face lifting matrices $\\mathbf{R}_{F}$ for every element and face by solving $\\mathbf{M}_{K} \\mathbf{R}_{F} = \\mathbf{B}_{F}^{\\top}$ for all faces $F$.\n2. Apply the lifting operator on-the-fly: for any given face data vector $\\mathbf{w} \\in \\mathbb{R}^{N_{f}}$, compute $\\mathbf{y} = \\mathbf{R}_{F}\\mathbf{w}$ by first forming $\\mathbf{b} = \\mathbf{B}_{F}^{\\top} \\mathbf{w}$ and then solving $\\mathbf{M}_{K} \\mathbf{y} = \\mathbf{b}$ using the stored Cholesky factors.\n\nCompute, for $p=4$, the ratio of the total flop count of strategy 1 (constructing all $\\mathbf{R}_{F}$ operators for every face of every element) to the total flop count of a single on-the-fly application of strategy 2 over all faces of all elements. Express your final answer as a single exact rational number. No rounding is required.",
            "solution": "We begin by enumerating the degrees of freedom for polynomial degree $p=4$ on a hexahedral element with tensor-product basis. The number of volume degrees of freedom is\n$$\nN_{p} = (p+1)^{3} = (4+1)^{3} = 125,\n$$\nand the number of face degrees of freedom is\n$$\nN_{f} = (p+1)^{2} = (4+1)^{2} = 25.\n$$\nEach element has $6$ faces.\n\nWe adopt the stated flop model:\n- Cholesky factorization of $\\mathbf{M}_{K} \\in \\mathbb{R}^{N_{p} \\times N_{p}}$ costs $\\frac{1}{3} N_{p}^{3}$ flops.\n- Solving with one right-hand side (RHS) using the Cholesky factors costs $2 N_{p}^{2}$ flops.\n- A matrix-vector product $\\mathbb{R}^{m \\times n} \\to \\mathbb{R}^{m}$ costs $2 m n$ flops.\n\nWe proceed to compute the costs per element and then multiply by the number of elements $N_{e} = N_{x} N_{y} N_{z}$. Since we will ultimately form a ratio of two costs that both scale linearly in $N_{e}$, $N_{e}$ will cancel.\n\nCost of strategy 1 (precompute all per-face lifting matrices $\\mathbf{R}_{F}$):\n- Perform one Cholesky factorization of $\\mathbf{M}_{K}$ per element: cost $\\frac{1}{3} N_{p}^{3}$ flops.\n- For each face, solve $\\mathbf{M}_{K} \\mathbf{R}_{F} = \\mathbf{B}_{F}^{\\top}$ for $\\mathbf{R}_{F} \\in \\mathbb{R}^{N_{p} \\times N_{f}}$. This is equivalent to solving $\\mathbf{M}_{K} \\mathbf{x} = \\mathbf{b}$ for $N_{f}$ columns per face, each costing $2 N_{p}^{2}$ flops. Thus, the per-face cost is $2 N_{p}^{2} N_{f}$ flops.\n- There are $6$ faces per element, so the total solve cost per element is $6 \\cdot 2 N_{p}^{2} N_{f} = 12 N_{p}^{2} N_{f}$ flops.\n\nTherefore, the total precompute cost per element is\n$$\nC_{\\text{pre}}^{(K)} = \\frac{1}{3} N_{p}^{3} + 12 N_{p}^{2} N_{f}.\n$$\nAcross all elements, the total precompute cost is\n$$\nC_{\\text{pre}} = N_{e} \\left( \\frac{1}{3} N_{p}^{3} + 12 N_{p}^{2} N_{f} \\right).\n$$\n\nCost of strategy 2 for a single global application (apply lifting on-the-fly over all faces of all elements):\n- Assume the Cholesky factorization of $\\mathbf{M}_{K}$ has already been performed and stored, so we do not include that cost here (it is amortized and common to both strategies in use).\n- For each element face application, we first form $\\mathbf{b} = \\mathbf{B}_{F}^{\\top} \\mathbf{w}$ with cost $2 N_{p} N_{f}$ flops, then solve $\\mathbf{M}_{K} \\mathbf{y} = \\mathbf{b}$ with cost $2 N_{p}^{2}$ flops. Hence, per face the on-the-fly application cost is\n$$\nC_{\\text{otf}}^{(F)} = 2 N_{p} N_{f} + 2 N_{p}^{2}.\n$$\n- With $6$ faces per element, the per-element cost for one global application is\n$$\nC_{\\text{otf}}^{(K)} = 6 \\left( 2 N_{p} N_{f} + 2 N_{p}^{2} \\right) = 12 N_{p} N_{f} + 12 N_{p}^{2}.\n$$\nAcross all elements, the total cost for one global application is\n$$\nC_{\\text{otf}} = N_{e} \\left( 12 N_{p} N_{f} + 12 N_{p}^{2} \\right).\n$$\n\nWe are asked to compute the ratio of the total flop count of strategy 1 (constructing all $\\mathbf{R}_{F}$ operators) to the total flop count of a single on-the-fly application of strategy 2 (over all faces of all elements), for $p=4$. This ratio is\n$$\n\\mathcal{R} = \\frac{C_{\\text{pre}}}{C_{\\text{otf}}} = \\frac{N_{e} \\left( \\frac{1}{3} N_{p}^{3} + 12 N_{p}^{2} N_{f} \\right)}{N_{e} \\left( 12 N_{p} N_{f} + 12 N_{p}^{2} \\right)}.\n$$\nThe factor $N_{e}$ cancels, leaving\n$$\n\\mathcal{R} = \\frac{\\frac{1}{3} N_{p}^{3} + 12 N_{p}^{2} N_{f}}{12 N_{p} N_{f} + 12 N_{p}^{2}}.\n$$\nDivide numerator and denominator by $12 N_{p}^{2}$:\n$$\n\\mathcal{R} = \\frac{\\frac{1}{36} N_{p} + N_{f}}{1 + \\frac{N_{f}}{N_{p}}}.\n$$\nFor $p=4$, we substitute $N_{p} = 125$ and $N_{f} = 25$:\n$$\n\\mathcal{R} = \\frac{\\frac{1}{36} \\cdot 125 + 25}{1 + \\frac{25}{125}} = \\frac{\\frac{125}{36} + 25}{1 + \\frac{1}{5}} = \\frac{\\frac{125 + 900}{36}}{\\frac{6}{5}} = \\frac{\\frac{1025}{36}}{\\frac{6}{5}} = \\frac{1025}{36} \\cdot \\frac{5}{6} = \\frac{5125}{216}.\n$$\nThis is already in lowest terms, since $5125 = 125 \\cdot 41$ and $216 = 2^{3} \\cdot 3^{3}$ share no common prime factors. Thus, the exact ratio is\n$$\n\\mathcal{R} = \\frac{5125}{216}.\n$$\nInterpreting this, constructing all per-face lifting operators costs $\\frac{5125}{216}$ times the cost of performing a single global on-the-fly lifting application across all faces, for $p=4$ on a structured hexahedral grid under the stated cost model.",
            "answer": "$$\\boxed{\\frac{5125}{216}}$$"
        }
    ]
}