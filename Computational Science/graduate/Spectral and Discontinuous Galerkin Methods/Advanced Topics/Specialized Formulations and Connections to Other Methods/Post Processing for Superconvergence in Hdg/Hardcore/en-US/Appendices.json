{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides a direct, hands-on derivation of the post-processed solution in its simplest setting. By working through a single-element case with a known polynomial solution, you will verify the remarkable exactness property of the Hybridizable Discontinuous Galerkin (HDG) post-processing operator. This foundational practice  is crucial for building a concrete intuition for why and how superconvergence is achieved.",
            "id": "3410138",
            "problem": "Consider the steady diffusion model problem on a single convex polygonal element $K = [0,1] \\times [0,1]$ with constant diffusivity, governed by the partial differential equation $-\\Delta u = f$ and Dirichlet boundary condition $u|_{\\partial K} = g$. Let the exact (manufactured) solution be $u(x,y) = x^2 + y^2$ on $K$. Then $f(x,y) = -\\Delta u(x,y)$ and $g(x,y) = u(x,y)$ on $\\partial K$.\n\nLet $\\mathcal{P}_{k}(K)$ denote the space of polynomials of total degree at most $k$ on $K$, and let the Hybridizable Discontinuous Galerkin (HDG) method be posed with local spaces $\\boldsymbol{q}_{h} \\in [\\mathcal{P}_{k}(K)]^{2}$, $u_{h} \\in \\mathcal{P}_{k}(K)$, and numerical trace $\\widehat{u}_{h}$ on $\\partial K$ (single element setting). Assume $k=1$ and that the computed HDG flux $\\boldsymbol{q}_{h}$ equals the $L^{2}(K)$-projection of the exact flux $\\nabla u$ into $[\\mathcal{P}_{1}(K)]^{2}$. Since $\\nabla u(x,y) = (2x, 2y)$ already belongs to $[\\mathcal{P}_{1}(K)]^{2}$, this assumption implies $\\mathbf{q}_{h} = \\nabla u$ on $K$.\n\nDefine the standard HDG post-processing $u_{h}^{\\star} \\in \\mathcal{P}_{k+1}(K)$ as the unique polynomial satisfying, for all $w \\in \\mathcal{P}_{k+1}(K)$,\n$$(\\nabla u_{h}^{\\star}, \\nabla w)_{K} = (\\boldsymbol{q}_{h}, \\nabla w)_{K},$$\ntogether with the mean-value constraint \n$$\\int_{K} u_{h}^{\\star} \\,\\mathrm{d}\\boldsymbol{x} = \\int_{K} u \\,\\mathrm{d}\\boldsymbol{x}.$$\nHere, $(\\cdot,\\cdot)_{K}$ denotes the $L^{2}(K)$ inner product, and $\\mathrm{d}\\boldsymbol{x}$ is the area measure on $K$.\n\nStarting from the above definitions and the manufactured data, derive $u_{h}^{\\star}(x,y)$ explicitly and verify the achieved degree and exactness properties implied by the post-processing on this single-element problem. Your final answer must be a single closed-form analytical expression in terms of $x$ and $y$ for $u_{h}^{\\star}(x,y)$. No numerical rounding is required.",
            "solution": "The problem is valid as it is mathematically well-posed, scientifically grounded within the field of numerical analysis, and provides a complete and consistent set of definitions and data.\n\nThe task is to derive the explicit form of the post-processed Hybridizable Discontinuous Galerkin (HDG) solution, denoted by $u_h^\\star(x,y)$, on a single square element $K = [0,1] \\times [0,1]$. The polynomial degree for the local HDG spaces is $k=1$.\n\nThe defining properties of the post-processed solution $u_h^\\star \\in \\mathcal{P}_{k+1}(K) = \\mathcal{P}_{2}(K)$ are given by two conditions:\n1.  A variational equation:\n    $$(\\nabla u_{h}^{\\star}, \\nabla w)_{K} = (\\boldsymbol{q}_{h}, \\nabla w)_{K}, \\quad \\forall w \\in \\mathcal{P}_{2}(K)$$\n2.  A mean-value constraint:\n    $$\\int_{K} u_{h}^{\\star} \\,\\mathrm{d}\\boldsymbol{x} = \\int_{K} u \\,\\mathrm{d}\\boldsymbol{x}$$\nHere, $(\\cdot, \\cdot)_{K}$ denotes the standard $L^2$ inner product on the domain $K$.\n\nFirst, we must determine the HDG flux approximation $\\boldsymbol{q}_h$. The problem states that $\\boldsymbol{q}_h$ is the $L^2(K)$-projection of the exact flux $\\nabla u$ onto the polynomial space $[\\mathcal{P}_{k}(K)]^2$, which with $k=1$ is $[\\mathcal{P}_{1}(K)]^2$.\n\nThe exact solution is given as $u(x,y) = x^2 + y^2$.\nThe exact flux is the gradient of $u$:\n$$\\nabla u(x,y) = \\left( \\frac{\\partial u}{\\partial x}, \\frac{\\partial u}{\\partial y} \\right) = (2x, 2y)$$\nEach component of the vector field $\\nabla u$ is a polynomial of degree $1$. Therefore, the exact flux $\\nabla u$ is already an element of the target space for the projection, $[\\mathcal{P}_{1}(K)]^2$.\nThe $L^2$-projection of an element onto a space that already contains that element is simply the element itself.\nThus, we have $\\boldsymbol{q}_h = \\nabla u = (2x, 2y)$.\n\nNow, we substitute this result for $\\boldsymbol{q}_h$ into the variational equation defining $u_h^\\star$:\n$$(\\nabla u_{h}^{\\star}, \\nabla w)_{K} = (\\nabla u, \\nabla w)_{K}, \\quad \\forall w \\in \\mathcal{P}_{2}(K)$$\nBy the linearity of the inner product, this equation can be rewritten as:\n$$(\\nabla u_{h}^{\\star} - \\nabla u, \\nabla w)_{K} = 0$$\nwhich simplifies to:\n$$(\\nabla (u_{h}^{\\star} - u), \\nabla w)_{K} = 0, \\quad \\forall w \\in \\mathcal{P}_{2}(K)$$\nLet us define the error of the post-processed solution as $e_u^\\star = u_h^\\star - u$. The equation becomes:\n$$(\\nabla e_u^\\star, \\nabla w)_{K} = 0, \\quad \\forall w \\in \\mathcal{P}_{2}(K)$$\nWe know that the exact solution $u(x,y) = x^2+y^2$ is a polynomial of degree $2$, so $u \\in \\mathcal{P}_{2}(K)$. The post-processed solution $u_h^\\star$ is also sought in the space $\\mathcal{P}_{2}(K)$. Consequently, their difference, the error $e_u^\\star$, must also be a polynomial in $\\mathcal{P}_{2}(K)$.\n\nSince $e_u^\\star \\in \\mathcal{P}_{2}(K)$, we are free to choose the test function $w$ to be $e_u^\\star$ itself. Making this substitution, we obtain:\n$$(\\nabla e_u^\\star, \\nabla e_u^\\star)_{K} = 0$$\nThis inner product is the definition of the squared $L^2$-norm of the gradient of $e_u^\\star$:\n$$\\int_{K} |\\nabla e_u^\\star|^2 \\,\\mathrm{d}\\boldsymbol{x} = 0$$\nThe integrand, $|\\nabla e_u^\\star|^2$, is a non-negative continuous function. For its integral over the domain $K$, which has a positive measure (Area$(K)=1$), to be zero, the integrand must be identically zero throughout $K$.\n$$|\\nabla e_u^\\star(\\boldsymbol{x})|^2 = 0 \\quad \\forall \\boldsymbol{x} \\in K$$\nThis implies that the gradient itself must be the zero vector everywhere in $K$:\n$$\\nabla e_u^\\star(\\boldsymbol{x}) = \\boldsymbol{0} \\quad \\forall \\boldsymbol{x} \\in K$$\nA function whose gradient is zero throughout a connected domain must be constant on that domain. Therefore, $e_u^\\star(\\boldsymbol{x}) = C$ for some real constant $C$.\nRecalling the definition of $e_u^\\star$, we have $u_h^\\star(\\boldsymbol{x}) - u(\\boldsymbol{x}) = C$, or $u_h^\\star(\\boldsymbol{x}) = u(\\boldsymbol{x}) + C$.\n\nTo determine the value of the constant $C$, we now apply the second condition, the mean-value constraint:\n$$\\int_{K} u_{h}^{\\star} \\,\\mathrm{d}\\boldsymbol{x} = \\int_{K} u \\,\\mathrm{d}\\boldsymbol{x}$$\nSubstituting $u_h^\\star = u+C$ into this equation yields:\n$$\\int_{K} (u(\\boldsymbol{x}) + C) \\,\\mathrm{d}\\boldsymbol{x} = \\int_{K} u(\\boldsymbol{x}) \\,\\mathrm{d}\\boldsymbol{x}$$\nThe integral on the left side can be split:\n$$\\int_{K} u(\\boldsymbol{x}) \\,\\mathrm{d}\\boldsymbol{x} + \\int_{K} C \\,\\mathrm{d}\\boldsymbol{x} = \\int_{K} u(\\boldsymbol{x}) \\,\\mathrm{d}\\boldsymbol{x}$$\nSubtracting $\\int_K u(\\boldsymbol{x}) d\\boldsymbol{x}$ from both sides leaves:\n$$\\int_{K} C \\,\\mathrm{d}\\boldsymbol{x} = 0$$\n$$C \\int_{K} \\,\\mathrm{d}\\boldsymbol{x} = 0$$\nThe integral $\\int_K d\\boldsymbol{x}$ represents the area of the domain $K = [0,1] \\times [0,1]$, which is $1$.\n$$C \\cdot 1 = 0 \\implies C=0$$\nSince the constant $C$ is zero, the error $e_u^\\star$ is identically zero. Therefore, the post-processed solution is identical to the exact solution:\n$$u_h^\\star(\\boldsymbol{x}) = u(\\boldsymbol{x})$$\nSubstituting the given expression for $u(x,y)$:\n$$u_h^\\star(x,y) = x^2 + y^2$$\n\nFinally, we verify the properties of this result. The derived solution $u_h^\\star(x,y) = x^2 + y^2$ is a polynomial of total degree $2$, which is consistent with the requirement that $u_h^\\star \\in \\mathcal{P}_{k+1}(K) = \\mathcal{P}_{2}(K)$. The result $u_h^\\star=u$ demonstrates the exactness property of the HDG post-processing for this specific case. This is a known theoretical result: for a single element, if the exact solution $u$ is a polynomial of degree at most $k+1$ (here, $u \\in \\mathcal{P}_2$ and $k=1$), the post-processed solution $u_h^\\star$ is exact. Our derivation confirms this superconvergence property.",
            "answer": "$$\n\\boxed{x^{2} + y^{2}}\n$$"
        },
        {
            "introduction": "Moving beyond the standard isotropic case, this practice explores the adaptability of the post-processing framework. You will derive a modified operator using a weighted inner product designed to handle anisotropic phenomena, common in advection-dominated problems. This exercise  highlights how post-processing can be tailored to specific physical features, enhancing its power and versatility.",
            "id": "3410083",
            "problem": "Consider the scalar advection-diffusion model problem on a single element $K \\subset \\mathbb{R}^{2}$ with constant advection field $\\boldsymbol{\\beta} \\in \\mathbb{R}^{2}$ and diffusion coefficient $\\epsilon > 0$. Let the Hybridizable Discontinuous Galerkin (HDG) method produce an element-local approximation of the gradient, denoted $\\boldsymbol{q}_{h}$, of polynomial degree $k$ on $K$. Classical superconvergent post-processing lifts the solution to degree $k+1$ by defining $u^{\\star} \\in \\mathcal{P}_{k+1}(K)$ as the unique mean-zero polynomial satisfying a gradient-matching variational condition against all mean-zero test functions in $\\mathcal{P}_{k+1}(K)$.\n\nIn anisotropic advection-diffusion, consider a modified post-processing operator defined by a weighted projection aligned with $\\boldsymbol{\\beta}$. Introduce the symmetric positive-definite weight matrix\n$$\n\\mathbf{M} \\;=\\; \\mathbf{I} \\;+\\; \\gamma \\,\\frac{\\boldsymbol{\\beta}\\,\\boldsymbol{\\beta}^{\\top}}{|\\boldsymbol{\\beta}|^{2}},\n$$\nwith $\\gamma \\geq 0$, and define $u^{\\star} \\in \\mathcal{P}_{k+1}(K)$ with zero mean to satisfy, for every $v \\in \\mathcal{P}_{k+1}(K)$ with zero mean,\n$$\n\\int_{K} \\big( \\mathbf{M}\\,\\nabla u^{\\star} \\big)\\cdot \\nabla v \\, \\mathrm{d}\\boldsymbol{x} \\;=\\; \\int_{K} \\big( \\mathbf{M}\\,\\boldsymbol{q}_{h} \\big)\\cdot \\nabla v \\, \\mathrm{d}\\boldsymbol{x}.\n$$\nStarting from the definitions of $\\mathcal{P}_{k+1}(K)$, orthogonality, and weighted $L^{2}$ projections, derive the operator above and specialize it on the reference element $K = [0,1]^{2}$ with constant $\\boldsymbol{\\beta} = (1,0)^{\\top}$ so that\n$$\n\\mathbf{M} \\;=\\; \\begin{pmatrix} 1+\\gamma & 0 \\\\ 0 & 1 \\end{pmatrix}.\n$$\nLet $k=1$ so that $u^{\\star} \\in \\mathcal{P}_{2}(K)$ and assume the HDG gradient approximation is the linear field\n$$\n\\boldsymbol{q}_{h}(x,y) \\;=\\; \\begin{pmatrix} \\mu\\,x + \\nu\\,y \\\\ \\rho\\,x + \\sigma\\,y \\end{pmatrix},\n$$\nfor given real coefficients $\\mu, \\nu, \\rho, \\sigma$. Parameterize $u^{\\star}$ by\n$$\nu^{\\star}(x,y) \\;=\\; \\tfrac{1}{2}\\,a\\,x^{2} \\;+\\; b\\,x\\,y \\;+\\; \\tfrac{1}{2}\\,c\\,y^{2} \\;+\\; d\\,x \\;+\\; e\\,y \\;+\\; g,\n$$\nand impose the mean-zero constraint $\\int_{K} u^{\\star}\\,\\mathrm{d}\\boldsymbol{x} = 0$ to fix $g$. Using only fundamental properties of polynomial spaces, weighted projections, and symmetry of mixed partial derivatives, derive the normal equations for the coefficients $a,b,c,d,e$ by minimizing the weighted residual functional\n$$\nJ(a,b,c,d,e) \\;=\\; \\int_{K} \\Big( \\nabla u^{\\star}(x,y) \\;-\\; \\boldsymbol{q}_{h}(x,y) \\Big)^{\\top} \\mathbf{M} \\Big( \\nabla u^{\\star}(x,y) \\;-\\; \\boldsymbol{q}_{h}(x,y) \\Big)\\,\\mathrm{d}\\boldsymbol{x}.\n$$\nSolve these equations explicitly and provide the closed-form analytic expression for the cross-term coefficient $b$ in terms of $\\gamma$, $\\nu$, and $\\rho$. Conclude by hypothesizing, based on your derivation, how increasing $\\gamma$ affects the anisotropy of the post-processing error along and across the direction of $\\boldsymbol{\\beta}$. Your final answer must be the requested expression for $b$ as a function of $\\gamma$, $\\nu$, and $\\rho$.",
            "solution": "The user has provided a problem in the field of numerical analysis, specifically concerning post-processing techniques for the Hybridizable Discontinuous Galerkin (HDG) method. I will first validate the problem statement and then proceed to a full derivation.\n\n### Step 1: Extract Givens\n- **Model Problem**: Scalar advection-diffusion on an element $K \\subset \\mathbb{R}^{2}$.\n- **Parameters**: Constant advection field $\\boldsymbol{\\beta} \\in \\mathbb{R}^{2}$, diffusion coefficient $\\epsilon > 0$.\n- **HDG Approximation**: Element-local gradient approximation $\\boldsymbol{q}_{h}$ of polynomial degree $k$.\n- **Post-processed Solution**: $u^{\\star} \\in \\mathcal{P}_{k+1}(K)$ with zero mean, $\\int_K u^{\\star} \\, \\mathrm{d}\\boldsymbol{x} = 0$.\n- **Weight Matrix**: $\\mathbf{M} = \\mathbf{I} + \\gamma \\frac{\\boldsymbol{\\beta}\\,\\boldsymbol{\\beta}^{\\top}}{|\\boldsymbol{\\beta}|^{2}}$ with $\\gamma \\geq 0$.\n- **Variational Formulation**: For every $v \\in \\mathcal{P}_{k+1}(K)$ with zero mean,\n$$ \\int_{K} \\big( \\mathbf{M}\\,\\nabla u^{\\star} \\big)\\cdot \\nabla v \\, \\mathrm{d}\\boldsymbol{x} = \\int_{K} \\big( \\mathbf{M}\\,\\boldsymbol{q}_{h} \\big)\\cdot \\nabla v \\, \\mathrm{d}\\boldsymbol{x}. $$\n- **Minimization Functional**: $J(a,b,c,d,e) = \\int_{K} \\Big( \\nabla u^{\\star}(x,y) - \\boldsymbol{q}_{h}(x,y) \\Big)^{\\top} \\mathbf{M} \\Big( \\nabla u^{\\star}(x,y) - \\boldsymbol{q}_{h}(x,y) \\Big)\\,\\mathrm{d}\\boldsymbol{x}$.\n- **Specialization**:\n    - Reference element: $K = [0,1]^{2}$.\n    - Advection field: $\\boldsymbol{\\beta} = (1,0)^{\\top}$.\n    - Resulting weight matrix: $\\mathbf{M} = \\begin{pmatrix} 1+\\gamma & 0 \\\\ 0 & 1 \\end{pmatrix}$.\n    - Polynomial degree: $k=1$, so $u^{\\star} \\in \\mathcal{P}_{2}(K)$.\n- **Parameterizations**:\n    - HDG gradient: $\\boldsymbol{q}_{h}(x,y) = \\begin{pmatrix} \\mu\\,x + \\nu\\,y \\\\ \\rho\\,x + \\sigma\\,y \\end{pmatrix}$.\n    - Post-processed solution: $u^{\\star}(x,y) = \\frac{1}{2}\\,a\\,x^{2} + b\\,x\\,y + \\frac{1}{2}\\,c\\,y^{2} + d\\,x + e\\,y + g$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, situated within the well-established mathematical framework of finite element methods and approximation theory. The concepts of HDG methods, polynomial spaces, weighted projections, and variational principles are standard in computational mathematics. The problem is well-posed; it asks for the derivation of coefficients by minimizing a quadratic functional, a process which leads to a well-defined system of linear equations. The language is objective, formal, and precise. There are no contradictions, missing information, or pseudoscientific claims. The problem is a valid and non-trivial exercise in applied mathematics.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the derivation.\n\n### Derivation\nThe problem asks for the derivation of the normal equations for the coefficients of the post-processed solution $u^{\\star}$ by minimizing the functional $J$, and then to solve for the coefficient $b$. The variational formulation provided is the Euler-Lagrange equation associated with the minimization of the quadratic functional $J$. Minimizing $J$ with respect to its parameters $(a,b,c,d,e)$ is equivalent to finding the stationary point where the partial derivatives of $J$ with respect to each parameter are zero.\n\nFirst, we express the gradient of $u^{\\star}$:\n$$ \\nabla u^{\\star}(x,y) = \\begin{pmatrix} \\partial_x u^{\\star} \\\\ \\partial_y u^{\\star} \\end{pmatrix} = \\begin{pmatrix} a\\,x + b\\,y + d \\\\ b\\,x + c\\,y + e \\end{pmatrix} $$\nThe error vector, $\\boldsymbol{\\delta} = \\nabla u^{\\star} - \\boldsymbol{q}_h$, is:\n$$ \\boldsymbol{\\delta}(x,y) = \\begin{pmatrix} (a-\\mu)x + (b-\\nu)y + d \\\\ (b-\\rho)x + (c-\\sigma)y + e \\end{pmatrix} $$\nThe functional $J$ to be minimized is the integral of the weighted squared norm of this error over the domain $K = [0,1]^2$:\n$$ J = \\int_0^1 \\int_0^1 \\boldsymbol{\\delta}^{\\top} \\mathbf{M} \\boldsymbol{\\delta} \\,\\mathrm{d}x\\,\\mathrm{d}y $$\nSubstituting the expressions for $\\boldsymbol{\\delta}$ and $\\mathbf{M}$:\n$$ J = \\int_K \\left[ (1+\\gamma)\\big((a-\\mu)x + (b-\\nu)y + d\\big)^2 + \\big((b-\\rho)x + (c-\\sigma)y + e\\big)^2 \\right] \\mathrm{d}\\boldsymbol{x} $$\nThe normal equations are obtained by setting the partial derivatives of $J$ with respect to each of the five coefficients $a, b, c, d, e$ to zero. We utilize the identity $\\int_0^1 \\int_0^1 x^i y^j \\,\\mathrm{d}x\\,\\mathrm{d}y = \\frac{1}{(i+1)(j+1)}$.\n\n1.  $\\frac{\\partial J}{\\partial a} = 0$:\n    $$ \\int_K 2(1+\\gamma)\\big((a-\\mu)x + (b-\\nu)y + d\\big)x \\, \\mathrm{d}\\boldsymbol{x} = 0 $$\n    $$ \\int_K \\big(ax^2 + bxy + dx\\big) \\, \\mathrm{d}\\boldsymbol{x} = \\int_K \\big(\\mu x^2 + \\nu xy\\big) \\, \\mathrm{d}\\boldsymbol{x} $$\n    $$ a\\frac{1}{3} + b\\frac{1}{4} + d\\frac{1}{2} = \\mu\\frac{1}{3} + \\nu\\frac{1}{4} \\quad (1) $$\n\n2.  $\\frac{\\partial J}{\\partial c} = 0$:\n    $$ \\int_K 2\\big((b-\\rho)x + (c-\\sigma)y + e\\big)y \\, \\mathrm{d}\\boldsymbol{x} = 0 $$\n    $$ \\int_K \\big(bxy + cy^2 + ey\\big) \\, \\mathrm{d}\\boldsymbol{x} = \\int_K \\big(\\rho xy + \\sigma y^2\\big) \\, \\mathrm{d}\\boldsymbol{x} $$\n    $$ b\\frac{1}{4} + c\\frac{1}{3} + e\\frac{1}{2} = \\rho\\frac{1}{4} + \\sigma\\frac{1}{3} \\quad (2) $$\n\n3.  $\\frac{\\partial J}{\\partial d} = 0$:\n    $$ \\int_K 2(1+\\gamma)\\big((a-\\mu)x + (b-\\nu)y + d\\big) \\, \\mathrm{d}\\boldsymbol{x} = 0 $$\n    $$ \\int_K \\big(ax + by + d\\big) \\, \\mathrm{d}\\boldsymbol{x} = \\int_K \\big(\\mu x + \\nu y\\big) \\, \\mathrm{d}\\boldsymbol{x} $$\n    $$ a\\frac{1}{2} + b\\frac{1}{2} + d = \\mu\\frac{1}{2} + \\nu\\frac{1}{2} \\quad (3) $$\n\n4.  $\\frac{\\partial J}{\\partial e} = 0$:\n    $$ \\int_K 2\\big((b-\\rho)x + (c-\\sigma)y + e\\big) \\, \\mathrm{d}\\boldsymbol{x} = 0 $$\n    $$ \\int_K \\big(bx + cy + e\\big) \\, \\mathrm{d}\\boldsymbol{x} = \\int_K \\big(\\rho x + \\sigma y\\big) \\, \\mathrm{d}\\boldsymbol{x} $$\n    $$ b\\frac{1}{2} + c\\frac{1}{2} + e = \\rho\\frac{1}{2} + \\sigma\\frac{1}{2} \\quad (4) $$\nWe can simplify this system. From $(3)$, we solve for $d$: $d = \\frac{1}{2}(\\mu+\\nu-a-b)$. Substituting this into $(1)$:\n$$ \\frac{a}{3} + \\frac{b}{4} + \\frac{1}{4}(\\mu+\\nu-a-b) = \\frac{\\mu}{3} + \\frac{\\nu}{4} $$\n$$ \\left(\\frac{1}{3}-\\frac{1}{4}\\right)a + \\left(\\frac{1}{4}-\\frac{1}{4}\\right)b = \\left(\\frac{1}{3}-\\frac{1}{4}\\right)\\mu + \\left(\\frac{1}{4}-\\frac{1}{4}\\right)\\nu $$\n$$ \\frac{a}{12} = \\frac{\\mu}{12} \\implies a = \\mu $$\nSimilarly, from $(4)$, we solve for $e$: $e = \\frac{1}{2}(\\rho+\\sigma-b-c)$. Substituting this into $(2)$:\n$$ \\frac{b}{4} + \\frac{c}{3} + \\frac{1}{4}(\\rho+\\sigma-b-c) = \\frac{\\rho}{4} + \\frac{\\sigma}{3} $$\n$$ \\left(\\frac{1}{4}-\\frac{1}{4}\\right)b + \\left(\\frac{1}{3}-\\frac{1}{4}\\right)c = \\left(\\frac{1}{4}-\\frac{1}{4}\\right)\\rho + \\left(\\frac{1}{3}-\\frac{1}{4}\\right)\\sigma $$\n$$ \\frac{c}{12} = \\frac{\\sigma}{12} \\implies c = \\sigma $$\nThe results $a=\\mu$ and $c=\\sigma$ are remarkably simple. They indicate that the post-processing exactly recovers the coefficients of the second-order pure derivative terms from the corresponding terms in the HDG gradient approximation.\n\nNow we derive the equation for $b$ by computing $\\frac{\\partial J}{\\partial b} = 0$:\n$$ \\frac{\\partial J}{\\partial b} = \\int_K \\left[ 2(1+\\gamma)\\big((a-\\mu)x + (b-\\nu)y + d\\big)y + 2\\big((b-\\rho)x + (c-\\sigma)y + e\\big)x \\right] \\mathrm{d}\\boldsymbol{x} = 0 $$\nSubstituting $a=\\mu$ and $c=\\sigma$, the equation simplifies:\n$$ \\int_K \\left[ (1+\\gamma)\\big((b-\\nu)y + d\\big)y + \\big((b-\\rho)x + e\\big)x \\right] \\mathrm{d}\\boldsymbol{x} = 0 $$\n$$ (1+\\gamma)\\int_K \\big((b-\\nu)y^2 + dy\\big)\\mathrm{d}\\boldsymbol{x} + \\int_K \\big((b-\\rho)x^2 + ex\\big)\\mathrm{d}\\boldsymbol{x} = 0 $$\n$$ (1+\\gamma)\\left( (b-\\nu)\\frac{1}{3} + d\\frac{1}{2} \\right) + \\left( (b-\\rho)\\frac{1}{3} + e\\frac{1}{2} \\right) = 0 \\quad (5) $$\nWe have explicit forms for $d$ and $e$ in terms of $b$. With $a=\\mu$, equation $(3)$ gives $d = \\frac{1}{2}(\\nu-b)$. With $c=\\sigma$, equation $(4)$ gives $e = \\frac{1}{2}(\\rho-b)$. Substituting these into $(5)$:\n$$ (1+\\gamma)\\left( (b-\\nu)\\frac{1}{3} + \\frac{1}{2}\\frac{\\nu-b}{2} \\right) + \\left( (b-\\rho)\\frac{1}{3} + \\frac{1}{2}\\frac{\\rho-b}{2} \\right) = 0 $$\n$$ (1+\\gamma)\\left( \\frac{b}{3} - \\frac{\\nu}{3} + \\frac{\\nu}{4} - \\frac{b}{4} \\right) + \\left( \\frac{b}{3} - \\frac{\\rho}{3} + \\frac{\\rho}{4} - \\frac{b}{4} \\right) = 0 $$\nCombine terms inside the parentheses:\n$$ (1+\\gamma)\\left( \\frac{b}{12} - \\frac{\\nu}{12} \\right) + \\left( \\frac{b}{12} - \\frac{\\rho}{12} \\right) = 0 $$\nMultiply by $12$:\n$$ (1+\\gamma)(b-\\nu) + (b-\\rho) = 0 $$\n$$ b + \\gamma b - \\nu - \\gamma\\nu + b - \\rho = 0 $$\n$$ b(2+\\gamma) = \\nu(1+\\gamma) + \\rho $$\nSolving for $b$:\n$$ b = \\frac{(1+\\gamma)\\nu + \\rho}{2+\\gamma} $$\n\nFinally, we conclude with the requested hypothesis. The coefficient $b$ represents the mixed partial derivative $\\partial_{xy}^2 u^{\\star}$. The terms $\\nu = \\partial_y q_x$ and $\\rho = \\partial_x q_y$ are the corresponding (and generally unequal) mixed derivatives from the HDG gradient $\\boldsymbol{q}_h$. The expression for $b$ can be written as a weighted average:\n$$ b = \\left(\\frac{1+\\gamma}{2+\\gamma}\\right)\\nu + \\left(\\frac{1}{2+\\gamma}\\right)\\rho $$\nWhen $\\gamma=0$, $\\mathbf{M}=\\mathbf{I}$ (isotropic weighting), and $b = \\frac{\\nu+\\rho}{2}$, which is the arithmetic mean. As $\\gamma \\to \\infty$, the weight on $\\nu$ approaches $1$ while the weight on $\\rho$ approaches $0$, so $b \\to \\nu$.\nThe parameter $\\gamma$ controls the anisotropy of the projection. The term $(1+\\gamma)$ weights the error in the component of the gradient parallel to $\\boldsymbol{\\beta}=(1,0)^\\top$, which is $\\partial_x u^\\star - q_x$. Increasing $\\gamma$ heavily penalizes this error component, forcing $\\nabla u^\\star$ to trust the $x$-component of the HDG gradient, $q_x$, more than the $y$-component, $q_y$. Consequently, the properties of $\\partial_x u^{\\star}$ (such as its derivative with respect to $y$, which is $b$) are driven to match the properties of $q_x$ (whose derivative with respect to $y$ is $\\nu$).\nHypothesis: Increasing $\\gamma$ introduces anisotropy into the post-processing by prioritizing the reduction of the error component along the advection direction $\\boldsymbol{\\beta}$ over the error component in the transverse direction. This forces the post-processed solution's gradient to more closely match the component of the HDG gradient aligned with $\\boldsymbol{\\beta}$, potentially at the cost of a larger discrepancy with the transverse component of the HDG gradient. This makes the post-processing error itself anisotropic, with its magnitude likely being smaller along $\\boldsymbol{\\beta}$ and larger in the direction perpendicular to it.",
            "answer": "$$\\boxed{\\frac{(1+\\gamma)\\nu + \\rho}{2+\\gamma}}$$"
        },
        {
            "introduction": "This final practice transitions from analytical derivation to computational implementation, tackling the physically significant Helmholtz equation. You will build a complete HDG solver and apply post-processing to analyze its impact on dispersion error, a critical metric for wave propagation problems. This comprehensive exercise  demonstrates the practical application of superconvergence concepts in reducing phase errors and improving simulation fidelity for time-harmonic waves.",
            "id": "3410122",
            "problem": "You are asked to design and implement a Hybridizable Discontinuous Galerkin (HDG) method with postprocessing for the one-dimensional time-harmonic Helmholtz equation, and to study whether the recovered postprocessed solution exhibits superconvergent dispersion error relative to the standard HDG solution. The Helmholtz model problem is\n$$\n- \\frac{d^2 u}{dx^2} - \\kappa^2 u = f \\quad \\text{on } [0,L],\n$$\nwith Dirichlet boundary conditions consistent with a right-going plane wave,\n$$\nu(0) = 1, \\quad u(L) = e^{i \\kappa L}.\n$$\nAssume $f(x) = 0$ so the exact solution is the plane wave $u(x) = e^{i \\kappa x}$.\n\nThe task focuses on the one-dimensional HDG method with polynomial degree $p=1$ for both the primal variable $u$ and the mixed flux variable $q = du/dx$, on a uniform mesh of $N$ elements covering $[0,L]$. Let the element size be $h = L/N$. Use a constant stabilization parameter $\\tau = \\alpha / h$ where $\\alpha > 0$. The HDG formulation in mixed form on each element $K = [x_L, x_R]$ is defined by seeking $(q_h, u_h)$ with $q_h \\in \\mathcal{P}_1(K)$ and $u_h \\in \\mathcal{P}_1(K)$ such that, for all test functions $r \\in \\mathcal{P}_1(K)$ and $v \\in \\mathcal{P}_1(K)$,\n$$\n\\int_K q_h r \\, dx + \\int_K u_h \\frac{dr}{dx} \\, dx - \\widehat{u} \\, r \\, n \\Big|_{\\partial K} = 0,\n$$\n$$\n- \\int_K q_h \\frac{dv}{dx} \\, dx + \\widehat{q} \\, n \\, v \\Big|_{\\partial K} - \\kappa^2 \\int_K u_h v \\, dx = \\int_K f v \\, dx.\n$$\nHere $n$ denotes the outward unit normal at the element boundary point, the numerical trace $\\widehat{u}$ is the single-valued hybrid unknown defined on mesh nodes, and the numerical flux is taken as\n$$\n\\widehat{q} \\cdot n = q_h \\, n + \\tau \\left( u_h - \\widehat{u} \\right) \\quad \\text{on } \\partial K.\n$$\nOn each element, use the reference coordinate $\\xi \\in [0,1]$ with the affine mapping $x(\\xi) = x_L + h \\xi$. Use the local linear basis $\\{\\varphi_0(\\xi), \\varphi_1(\\xi)\\} = \\{1-\\xi, \\xi\\}$ for both $u_h$ and $q_h$. All element integrals must be exactly computed using the reference basis on $[0,1]$; denote the element mass matrix by\n$$\nM = h \\begin{bmatrix} \\int_0^1 \\varphi_0^2 \\, d\\xi & \\int_0^1 \\varphi_0 \\varphi_1 \\, d\\xi \\\\\n\\int_0^1 \\varphi_1 \\varphi_0 \\, d\\xi & \\int_0^1 \\varphi_1^2 \\, d\\xi \\end{bmatrix}\n= h \\begin{bmatrix} \\frac{1}{3} & \\frac{1}{6} \\\\ \\frac{1}{6} & \\frac{1}{3} \\end{bmatrix},\n$$\nand the derivative coupling matrix (arising from $\\int_K w \\, r' \\, dx$ and $\\int_K q \\, v' \\, dx$) by\n$$\nE = \\begin{bmatrix} \\int_K \\varphi_0 \\, \\frac{d\\varphi_0}{dx} \\, dx & \\int_K \\varphi_0 \\, \\frac{d\\varphi_1}{dx} \\, dx \\\\ \\int_K \\varphi_1 \\, \\frac{d\\varphi_0}{dx} \\, dx & \\int_K \\varphi_1 \\, \\frac{d\\varphi_1}{dx} \\, dx \\end{bmatrix}\n= \\begin{bmatrix} -\\frac{1}{2} & \\frac{1}{2} \\\\ -\\frac{1}{2} & \\frac{1}{2} \\end{bmatrix}.\n$$\n\nPerform static condensation on each element: write the local system for the element coefficients $(q_0, q_1, u_0, u_1)$ in terms of the two endpoint hybrid variables $(\\widehat{u}_L, \\widehat{u}_R)$, and solve to obtain a $4 \\times 2$ local mapping\n$$\n\\begin{bmatrix} q_0 \\\\ q_1 \\\\ u_0 \\\\ u_1 \\end{bmatrix}\n= S \\begin{bmatrix} \\widehat{u}_L \\\\ \\widehat{u}_R \\end{bmatrix}\n$$\nfor $f=0$. Then form the outgoing numerical fluxes at the element endpoints,\n$$\nF_L^{\\text{out}} = \\widehat{q}_L n_L = n_L \\, q_0 + \\tau \\left( u_0 - \\widehat{u}_L \\right), \\quad n_L = -1,\n$$\n$$\nF_R^{\\text{out}} = \\widehat{q}_R n_R = n_R \\, q_1 + \\tau \\left( u_1 - \\widehat{u}_R \\right), \\quad n_R = +1.\n$$\nConstruct for each element a $2 \\times 2$ matrix mapping $(\\widehat{u}_L, \\widehat{u}_R)$ to $(F_L^{\\text{out}}, F_R^{\\text{out}})$, and assemble the global skeleton system by enforcing continuity of numerical fluxes: at each interior node shared by two adjacent elements, require that the sum of outgoing numerical fluxes from the left and right elements equals zero. Impose Dirichlet boundary conditions at $x=0$ and $x=L$ so that $\\widehat{u}(0) = e^{i \\kappa \\cdot 0} = 1$ and $\\widehat{u}(L) = e^{i \\kappa L}$. Solve the resulting linear system to obtain the hybrid unknowns at all interior nodes, then recover $(q_h, u_h)$ elementwise using the local mapping.\n\nDefine a classical HDG postprocessing that recovers an enriched $u^\\star$ on each element $K$ as follows: seek $u^\\star \\in \\mathcal{P}_2(K)$ with basis $\\{\\beta_0(\\xi), \\beta_1(\\xi), \\beta_2(\\xi)\\} = \\{1, \\xi, \\xi(1-\\xi)\\}$ such that\n$$\n\\int_K \\frac{d u^\\star}{dx} \\, \\varphi_j \\, dx = \\int_K q_h \\, \\varphi_j \\, dx \\quad \\text{for } j=0,1,\n$$\n$$\n\\int_K u^\\star \\, dx = \\int_K u_h \\, dx.\n$$\nThis is a local $3 \\times 3$ system that uniquely determines the coefficients of $u^\\star$.\n\nTo measure dispersion error, approximate the phase of the numerical solution as follows. Evaluate $u_h$ and $u^\\star$ at a set of interior sample points in each element, collect all points across the domain to form a strictly increasing sequence $\\{x_m\\}$ with corresponding complex values $\\{u_m\\}$. Compute the principal value phase $\\phi_m = \\arg(u_m)$ and perform phase unwrapping to obtain a continuous phase function $\\Phi(x)$. Estimate the effective numerical wavenumber $\\kappa_h$ of the discrete solution by least-squares fitting of $\\Phi(x)$ versus $x$ to the affine model $\\Phi(x) \\approx a x + b$, taking $\\kappa_h = a$. Define the dispersion error as $|\\kappa_h - \\kappa|$.\n\nYour program must:\n- Implement the one-dimensional HDG method described above with polynomial degree $p=1$ and stabilization parameter $\\tau = \\alpha/h$.\n- Implement the local postprocessing to obtain $u^\\star \\in \\mathcal{P}_2(K)$ by matching the $L^2$ projections of $\\frac{du^\\star}{dx}$ to $q_h$ and preserving the element mean of $u$.\n- For each mesh size $h$, compute the dispersion errors for both $u_h$ and $u^\\star$.\n- For each test case, compute the empirical convergence order of the dispersion error for $u_h$ and for $u^\\star$ by performing a linear regression of $\\log(\\text{error})$ against $\\log(h)$ across the provided mesh sizes. Decide that $u^\\star$ exhibits superconvergent dispersion error relative to $u_h$ if the observed order for $u^\\star$ exceeds that of $u_h$ by at least $0.5$.\n\nUse the following test suite of parameter sets:\n- Case A (happy path): $L = 1$, $\\kappa = 8\\pi$, $\\alpha = 1$, mesh sizes given by $N \\in \\{40, 80, 160\\}$.\n- Case B (boundary-lean case): $L = 1$, $\\kappa = 4\\pi$, $\\alpha = 1$, mesh sizes given by $N \\in \\{20, 40, 80\\}$.\n- Case C (higher-frequency case): $L = 1$, $\\kappa = 12\\pi$, $\\alpha = 1$, mesh sizes given by $N \\in \\{60, 120, 240\\}$.\n\nAngle computations must be done in radians. There are no physical unit conversions since all quantities are nondimensionalized. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one boolean per test case indicating whether superconvergence is detected for that case (e.g., $[X_A, X_B, X_C]$ where each $X_\\cdot$ is either $True$ or $False$).",
            "solution": "The problem statement describes a complete numerical experiment to investigate superconvergence in the dispersion error of a postprocessed Hybridizable Discontinuous Galerkin (HDG) method for the one-dimensional Helmholtz equation. The problem is well-posed, scientifically sound, and provides all necessary information for its implementation. We therefore proceed with a full solution.\n\nThe core of the task is to implement the specified HDG method, perform a local postprocessing step to enhance the solution, and then analyze the numerical dispersion properties of both the standard and the postprocessed solutions to determine if the latter exhibits a higher order of convergence.\n\n### 1. HDG Formulation and Discretization\n\nThe problem is the one-dimensional Helmholtz equation on the domain $[0, L]$:\n$$\n-u'' - \\kappa^2 u = 0\n$$\nwith a known plane wave solution $u(x) = e^{i \\kappa x}$ enforced by Dirichlet boundary conditions. We first reformulate this second-order equation as a first-order system by introducing the flux variable $q = u'$:\n$$\n\\begin{cases}\nq - u' = 0 \\\\\n-q' - \\kappa^2 u = 0\n\\end{cases}\n$$\nThe HDG method is formulated on a mesh of $N$ elements $K$. Within each element, the solution $(q_h, u_h)$ is sought in the space of linear polynomials $\\mathcal{P}_1(K)$. The weak formulation, for test functions $(r, v) \\in \\mathcal{P}_1(K) \\times \\mathcal{P}_1(K)$, is given by:\n$$\n\\int_K q_h r \\, dx + \\int_K u_h r' \\, dx - \\int_{\\partial K} \\widehat{u} r n \\, ds = 0\n$$\n$$\n- \\int_K q_h v' \\, dx - \\kappa^2 \\int_K u_h v \\, dx + \\int_{\\partial K} \\widehat{q} n v \\, ds = 0\n$$\nHere, $\\widehat{u}$ is the globally single-valued hybrid variable defined on the mesh nodes, which replaces the multi-valued trace of $u_h$. The numerical flux $\\widehat{q}$ is defined to ensure stability and consistency:\n$$\n\\widehat{q} \\cdot n = q_h n + \\tau (u_h - \\widehat{u})\n$$\nwhere $\\tau = \\alpha/h$ is the stabilization parameter.\n\n### 2. Derivation of the Local System (Static Condensation)\n\nOn a reference element $[0, 1]$ mapped to a physical element $K$ of size $h$, we expand the local unknowns $u_h$ and $q_h$ in the basis $\\{\\varphi_0(\\xi), \\varphi_1(\\xi)\\} = \\{1-\\xi, \\xi\\}$:\n$$\nu_h(\\xi) = u_0 \\varphi_0(\\xi) + u_1 \\varphi_1(\\xi), \\quad q_h(\\xi) = q_0 \\varphi_0(\\xi) + q_1 \\varphi_1(\\xi)\n$$\nLet $\\mathbf{u} = [u_0, u_1]^T$ and $\\mathbf{q} = [q_0, q_1]^T$. Substituting these into the weak form and testing with $\\varphi_j$ for $j=0,1$ leads to a $4 \\times 4$ local system. Using the provided element matrices $M$ (mass) and $E$ (derivative coupling), this system can be expressed as:\n$$\n\\begin{bmatrix}\nM & E^T \\\\\nC-E & \\tau I - \\kappa^2 M\n\\end{bmatrix}\n\\begin{bmatrix} \\mathbf{q} \\\\ \\mathbf{u} \\end{bmatrix}\n=\n\\begin{bmatrix}\n-1 & 0 \\\\\n0 & 1 \\\\\n\\tau & 0 \\\\\n0 & \\tau\n\\end{bmatrix}\n\\begin{bmatrix} \\widehat{u}_L \\\\ \\widehat{u}_R \\end{bmatrix}\n$$\nwhere $M$ is the physical mass matrix ($M=h \\times M_{ref}$), $I$ is the $2 \\times 2$ identity matrix, $C = \\text{diag}(-1, 1)$, and $(\\widehat{u}_L, \\widehat{u}_R)$ are the values of the hybrid variable at the element's left and right nodes. This equation is of the form $L_{\\text{loc}} [\\mathbf{q}^T, \\mathbf{u}^T]^T = R_{\\text{loc}} [\\widehat{u}_L, \\widehat{u}_R]^T$.\n\nStatic condensation consists of formally solving for the local degrees of freedom in terms of the hybrid variables:\n$$\n\\begin{bmatrix} \\mathbf{q} \\\\ \\mathbf{u} \\end{bmatrix} = L_{\\text{loc}}^{-1} R_{\\text{loc}} \\begin{bmatrix} \\widehat{u}_L \\\\ \\widehat{u}_R \\end{bmatrix} = S \\begin{bmatrix} \\widehat{u}_L \\\\ \\widehat{u}_R \\end{bmatrix}\n$$\nThe $4 \\times 2$ matrix $S$ maps the nodal hybrid values to the element-local polynomial coefficients.\n\n### 3. Global System Assembly\n\nThe global system is built by enforcing continuity of the numerical flux at each interior node. The outgoing fluxes from an element are:\n$$\nF_L^{\\text{out}} = -q_0 + \\tau(u_0 - \\widehat{u}_L), \\quad F_R^{\\text{out}} = q_1 + \\tau(u_1 - \\widehat{u}_R)\n$$\nUsing the mapping $S$, these fluxes can be expressed solely in terms of $(\\widehat{u}_L, \\widehat{u}_R)$ via a $2 \\times 2$ local stiffness matrix $K_{\\text{loc}}$:\n$$\n\\begin{bmatrix} F_L^{\\text{out}} \\\\ F_R^{\\text{out}} \\end{bmatrix} = K_{\\text{loc}} \\begin{bmatrix} \\widehat{u}_L \\\\ \\widehat{u}_R \\end{bmatrix} = \\left( \\begin{bmatrix} -1 & 0 & \\tau & 0 \\\\ 0 & 1 & 0 & \\tau \\end{bmatrix} S - \\begin{bmatrix} \\tau & 0 \\\\ 0 & \\tau \\end{bmatrix} \\right) \\begin{bmatrix} \\widehat{u}_L \\\\ \\widehat{u}_R \\end{bmatrix}\n$$\nAt each interior node $x_j$, flux continuity requires $F_{R, \\text{elem } j-1}^{\\text{out}} + F_{L, \\text{elem } j}^{\\text{out}} = 0$. This condition connects $\\widehat{u}_{j-1}$, $\\widehat{u}_j$, and $\\widehat{u}_{j+1}$, leading to a global tridiagonal system for the unknown interior $\\widehat{u}_j$ values. After imposing the Dirichlet boundary conditions for $\\widehat{u}_0$ and $\\widehat{u}_N$, this system is solved.\n\n### 4. Local Solution Postprocessing\n\nOnce the hybrid variables $\\widehat{u}_j$ are known, we can recover the local solutions $(q_h, u_h)$ on each element using the matrix $S$. The standard HDG solution $u_h$ is of degree $p=1$. To obtain a more accurate representation, we perform a local postprocessing to find a quadratic solution $u^\\star \\in \\mathcal{P}_2(K)$. We seek $u^\\star$ on each element satisfying two conditions: its derivative weakly matches the computed flux $q_h$, and its mean matches the mean of $u_h$. For basis functions $\\varphi_j \\in \\mathcal{P}_1(K)$, this is:\n$$\n\\int_K \\frac{d u^\\star}{dx} \\varphi_j \\, dx = \\int_K q_h \\varphi_j \\, dx, \\quad j=0,1\n$$\n$$\n\\int_K u^\\star \\, dx = \\int_K u_h \\, dx\n$$\nExpanding $u^\\star(\\xi) = c_0 + c_1\\xi + c_2\\xi(1-\\xi)$ on the reference element, these three conditions yield a unique, explicit solution for the coefficients $(c_0, c_1, c_2)$ in terms of the known coefficients $(q_0, q_1, u_0, u_1)$:\n$$\nc_1 = \\frac{h}{2}(q_0+q_1), \\quad c_2 = \\frac{h}{2}(q_0-q_1), \\quad c_0 = \\frac{u_0+u_1}{2} - \\frac{c_1}{2} - \\frac{c_2}{6}\n$$\n\n### 5. Dispersion Error Analysis and Convergence\n\nNumerical dispersion error manifests as a phase error, causing the numerical solution's wavelength to differ from the exact one. We quantify this by estimating the numerical wavenumber $\\kappa_h$. We evaluate the numerical solutions $u_h$ and $u^\\star$ at several interior points $\\{x_m\\}$ across all elements. The phase of these complex values, $\\phi_m = \\arg(u_m)$, is unwrapped to obtain a continuous phase function $\\Phi(x)$. We then perform a linear least-squares fit of $\\Phi(x_m)$ against $x_m$. The resulting slope is the estimated numerical wavenumber $\\kappa_h$. The dispersion error is defined as $|\\kappa_h - \\kappa|$.\n\nThis process is repeated for a sequence of decreasing mesh sizes $h$. The convergence order $P$ is estimated by a linear regression of $\\log(\\text{error})$ vs. $\\log(h)$. For the HDG method with $p=1$, the dispersion error for $u_h$ is theoretically expected to converge with order $P_{u_h} \\approx 2$. The postprocessed solution $u^\\star$ is expected to exhibit superconvergence, with an order $P_{u^\\star} \\approx 4$. The problem defines superconvergence as being observed if $P_{u^\\star} \\ge P_{u_h} + 0.5$. Our theoretical expectation is a difference of $2.0$, so we anticipate this condition will be met.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_orders(h_values, errors):\n    \"\"\"\n    Calculate the order of convergence from a list of mesh sizes and errors.\n    Fits log(error) = p * log(h) + C.\n    \"\"\"\n    log_h = np.log(h_values)\n    log_e = np.log(errors)\n    A = np.vstack([log_h, np.ones(len(log_h))]).T\n    p, _ = np.linalg.lstsq(A, log_e, rcond=None)[0]\n    return p\n\ndef run_case(L, kappa, alpha, N_values):\n    \"\"\"\n    Runs a single test case for the HDG method, computes dispersion errors\n    for u_h and u_star, determines convergence orders, and checks for\n    superconvergence.\n    \"\"\"\n    errors_uh = []\n    errors_ustar = []\n    h_values = []\n\n    for N in N_values:\n        h = L / N\n        tau = alpha / h\n        \n        # --- 1. Local System (Static Condensation) ---\n        # M_h is the physical mass matrix M = h * M_ref\n        M_h = h * np.array([[1/3, 1/6], [1/6, 1/3]], dtype=np.complex128)\n        E = np.array([[-1/2, 1/2], [-1/2, 1/2]], dtype=np.complex128)\n        C_mat = np.diag([-1, 1]).astype(np.complex128)\n        \n        L_loc = np.zeros((4, 4), dtype=np.complex128)\n        L_loc[0:2, 0:2] = M_h \n        L_loc[0:2, 2:4] = E.T\n        L_loc[2:4, 0:2] = C_mat - E\n        # CORRECTED: removed the erroneous h**2 factor.\n        L_loc[2:4, 2:4] = tau * np.eye(2) - (kappa**2) * M_h\n        \n        R_loc = np.array([[-1, 0], [0, 1], [tau, 0], [0, tau]], dtype=np.complex128)\n        \n        # S maps hybrid vars to local coeffs: [q0,q1,u0,u1] = S @ [uL_hat, uR_hat]\n        S = np.linalg.solve(L_loc, R_loc)\n\n        # --- 2. Local-to-Global Mapping ---\n        # K_loc maps hybrid vars to outgoing fluxes: [F_L, F_R] = K_loc @ [uL_hat, uR_hat]\n        Flux_op = np.array([[-1, 0, tau, 0], [0, 1, 0, tau]], dtype=np.complex128)\n        Tau_mat = np.diag([tau, tau]).astype(np.complex128)\n        K_loc = Flux_op @ S - Tau_mat\n        \n        # --- 3. Global System Assembly and Solve ---\n        dim = N - 1\n        A_global = np.zeros((dim, dim), dtype=np.complex128)\n        b_global = np.zeros(dim, dtype=np.complex128)\n\n        diag_val = K_loc[1, 1] + K_loc[0, 0]\n        off_diag_upper = K_loc[0, 1]\n        off_diag_lower = K_loc[1, 0]\n\n        np.fill_diagonal(A_global, diag_val)\n        if dim > 1:\n            np.fill_diagonal(A_global[0:, 1:], off_diag_upper)\n            np.fill_diagonal(A_global[1:, 0:], off_diag_lower)\n\n        u0_hat = 1.0 + 0.0j\n        uL_hat = np.exp(1j * kappa * L)\n\n        if dim > 0:\n            b_global[0] = -K_loc[1, 0] * u0_hat\n            b_global[-1] -= K_loc[0, 1] * uL_hat\n        \n        u_hat_interior = np.linalg.solve(A_global, b_global) if dim > 0 else np.array([])\n        u_hat_full = np.concatenate(([u0_hat], u_hat_interior, [uL_hat]))\n\n        # --- 4 & 5. Solution Recovery and Postprocessing ---\n        sample_points_xi = np.array([0.25, 0.5, 0.75])\n        num_samples_per_elem = len(sample_points_xi)\n        \n        x_samples = np.zeros(N * num_samples_per_elem)\n        uh_samples = np.zeros(N * num_samples_per_elem, dtype=np.complex128)\n        ustar_samples = np.zeros(N * num_samples_per_elem, dtype=np.complex128)\n\n        for i in range(N):\n            xl = i * h\n            u_hat_local = np.array([u_hat_full[i], u_hat_full[i+1]])\n            coeffs_local = S @ u_hat_local\n            q0, q1 = coeffs_local[0:2]\n            u0, u1 = coeffs_local[2:4]\n            \n            c1 = (h / 2) * (q0 + q1)\n            c2 = (h / 2) * (q0 - q1)\n            c0 = (u0 + u1) / 2 - c1 / 2 - c2 / 6\n            \n            for j, xi in enumerate(sample_points_xi):\n                idx = i * num_samples_per_elem + j\n                x_samples[idx] = xl + h * xi\n                uh_samples[idx] = u0 * (1 - xi) + u1 * xi\n                ustar_samples[idx] = c0 * 1 + c1 * xi + c2 * xi * (1 - xi)\n\n        # --- 6. Dispersion Analysis ---\n        sort_idx = np.argsort(x_samples)\n        x_samples_sorted = x_samples[sort_idx]\n        uh_samples_sorted = uh_samples[sort_idx]\n        ustar_samples_sorted = ustar_samples[sort_idx]\n\n        A_fit = np.vstack([x_samples_sorted, np.ones(len(x_samples_sorted))]).T\n\n        phase_uh = np.unwrap(np.angle(uh_samples_sorted))\n        kappa_h_uh, _ = np.linalg.lstsq(A_fit, phase_uh, rcond=None)[0]\n        errors_uh.append(abs(kappa_h_uh - kappa))\n\n        phase_ustar = np.unwrap(np.angle(ustar_samples_sorted))\n        kappa_h_ustar, _ = np.linalg.lstsq(A_fit, phase_ustar, rcond=None)[0]\n        errors_ustar.append(abs(kappa_h_ustar - kappa))\n\n        h_values.append(h)\n\n    # --- 7. Convergence Order Calculation ---\n    h_values = np.array(h_values)\n    errors_uh, errors_ustar = np.array(errors_uh), np.array(errors_ustar)\n    \n    order_uh = calculate_orders(h_values, errors_uh)\n    order_ustar = calculate_orders(h_values, errors_ustar)\n\n    return order_ustar >= order_uh + 0.5\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # (L, kappa, alpha, N_values)\n        (1.0, 8 * np.pi, 1.0, [40, 80, 160]),\n        (1.0, 4 * np.pi, 1.0, [20, 40, 80]),\n        (1.0, 12 * np.pi, 1.0, [60, 120, 240]),\n    ]\n\n    results = []\n    for case in test_cases:\n        L, kappa, alpha, N_values = case\n        is_superconvergent = run_case(L, kappa, alpha, N_values)\n        results.append(is_superconvergent)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}