## Introduction
Compact Discontinuous Galerkin (CDG) methods represent a powerful and efficient class of numerical techniques within the broader family of discontinuous Galerkin (DG) methods. Renowned for their ability to combine [high-order accuracy](@entry_id:163460), geometric flexibility, and suitability for parallel computing, DG methods have become a cornerstone of modern computational science. However, a key challenge lies in designing schemes that are both stable and computationally lean. Many formulations introduce dependencies that extend beyond immediate neighboring elements, creating a wider computational "stencil" that increases cost and communication overhead.

This article addresses the principles and practices of CDG methods, which are specifically designed to overcome this challenge by maintaining a minimal, compact stencil. We explore how these methods achieve stability and accuracy while restricting inter-element coupling to only face-adjacent neighbors. Over the following chapters, you will gain a deep understanding of this sophisticated numerical framework. The "Principles and Mechanisms" chapter will deconstruct the core theory, from the defining compact stencil to the role of lifting operators and the foundations of stability. Next, "Applications and Interdisciplinary Connections" will showcase the versatility of CDG methods in solving complex problems in solid mechanics, fluid dynamics, and electromagnetics. Finally, the "Hands-On Practices" section will provide targeted exercises to reinforce these concepts and their practical implications.

## Principles and Mechanisms

This chapter delves into the core principles and underlying mechanisms of Compact Discontinuous Galerkin (CDG) methods. Building upon the general framework of discontinuous Galerkin (DG) techniques, we will explore the defining features that render these methods "compact" and analyze the theoretical and computational advantages that arise from this structure. We will investigate the mathematical machinery, such as lifting operators, that enables these formulations, examine their stability and convergence properties, and discuss practical considerations for robust and efficient implementation.

### The Defining "Compact" Stencil

The central characteristic of a wide class of discontinuous Galerkin methods, including the Symmetric Interior Penalty Galerkin (SIPG) method and the compact variants we focus on, is the structure of their inter-element coupling. When a partial differential equation is discretized using these methods, the resulting algebraic system exhibits a specific, highly localized pattern of connectivity.

Formally, we can represent the mesh connectivity as a graph where each element is a node. An edge exists between two nodes if the corresponding elements share a common face (a $(d-1)$-dimensional boundary for a problem in $\mathbb{R}^d$). A discontinuous Galerkin method is said to have a **compact stencil** if the resulting linear system of equations respects this graph structure exclusively. That is, the degrees of freedom associated with a given element $K_i$ are directly coupled only to the degrees of freedom within $K_i$ itself and to those within its immediate face-neighbors . Couplings between elements that share only a lower-dimensional boundary (like a vertex or an edge in three dimensions) or are not direct neighbors are explicitly zero.

This property is fundamental. It ensures that the assembled global stiffness matrix is exceptionally sparse, a feature that is paramount for [computational efficiency](@entry_id:270255), especially in large-scale simulations. For an element-block representation of the matrix, a compact stencil implies that the $(i,j)$-th block is non-zero only if element $i$ is the same as element $j$, or if elements $i$ and $j$ are face-adjacent. This principle holds even for more complex DG formulations that introduce auxiliary variables (e.g., for the flux), provided these variables can be eliminated locally on each element through a procedure known as **[static condensation](@entry_id:176722)**. The final Schur [complement system](@entry_id:142643) for the primary element-wise unknowns must retain this face-neighbor coupling pattern to be considered compact .

It is instructive to contrast this with other DG variants. The stencil of a standard SIPG method for a diffusion problem is naturally compact, coupling only face-neighbors. The methods we term CDG are specifically designed to achieve this same minimal, 1-ring stencil . This is distinct from so-called "hybridized" methods like the Hybridizable Discontinuous Galerkin (HDG) method. While HDG also relies on local computations, its final global system is formulated in terms of unknowns living only on the element faces (the mesh skeleton). In this skeletal system, the unknowns on the faces of a given element become coupled not only to each other but also to the unknowns on the faces of all immediate neighbors, leading to a different, though still sparse, coupling structure .

### Mechanisms for Compactness: Local Lifting Operators

A primary mechanism for constructing CDG methods is the **[lifting operator](@entry_id:751273)**. A [lifting operator](@entry_id:751273) is a mathematical tool that provides a way to represent an integral over an element's boundary (a face integral) as an integral over the element's interior (a [volume integral](@entry_id:265381)). This is achieved by "lifting" a function defined on a face into a function defined over the volume of the adjacent element(s).

Let us consider a function $\phi$ defined on a face $F$. A local [lifting operator](@entry_id:751273) $\mathcal{R}_F^K$ maps $\phi$ to a vector-valued polynomial $\mathcal{R}_F^K(\phi)$ within the adjacent element $K$. This mapping is typically defined via a Riesz representation:
$$
\int_K \mathcal{R}_F^K(\phi) \cdot \boldsymbol{\tau}_h \, \mathrm{d}\boldsymbol{x} \;=\; \int_F \phi \, (\boldsymbol{\tau}_h|_K \cdot \boldsymbol{n}_K) \, \mathrm{d}s \quad \forall \, \boldsymbol{\tau}_h \in [\mathbb{P}_p(K)]^d
$$
where $\boldsymbol{\tau}_h$ is a vector-valued polynomial [test function](@entry_id:178872) on $K$, and $\boldsymbol{n}_K$ is the outward normal from $K$ on face $F$. The crucial property of this **local lifting** is that the resulting polynomial $\mathcal{R}_F^K(\phi)$ depends only on data on the face $F$ and the geometry of the element $K$ .

In CDG methods for diffusion problems, the flux across an element face is approximated using a reconstructed gradient. This gradient is formed by correcting the broken (element-wise) gradient $\nabla_h u_h$ with a lifting of the jumps in the solution, $\llbracket u_h \rrbracket$, across the element's boundary. If this correction is constructed using only local liftings, the reconstructed gradient on an element $K$ will depend only on the solution values in $K$ and its immediate face-neighbors. Consequently, the resulting global [bilinear form](@entry_id:140194), which involves inner products of these reconstructed gradients, will only couple face-adjacent elements. This procedure guarantees a compact stencil .

This is in stark contrast to methods that employ a **global lifting**. A global [lifting operator](@entry_id:751273) defines the correction on element $K$ using jumps from faces all over the mesh. A more common scenario leading to a non-compact stencil arises from the choice of numerical flux, as in the original Bassi-Rebay (BR1) scheme. There, the numerical flux on a face is the average of reconstructed gradients from the two adjacent elements. The reconstructed gradient on a neighbor $K'$ depends on jumps on all of *its* faces, which brings in information from the neighbors of $K'$. This chain of dependencies means the calculation on element $K$ requires information from its "neighbors' neighbors," creating a wider, non-compact two-ring stencil . The development of CDG methods was motivated precisely by the desire to create formulations that achieve stability through liftings while strictly preserving the minimal, compact stencil.

### Stability and Convergence Properties

#### Coercivity via Implicit Stabilization

A key question for any numerical method is stability, which is mathematically established through the [coercivity](@entry_id:159399) of its [bilinear form](@entry_id:140194). Methods like SIPG achieve [coercivity](@entry_id:159399) by adding an explicit penalty term that penalizes the jump in the solution across element faces. CDG methods, in their final form, often appear to be "penalty-free." However, stability is not achieved by magic; it is provided implicitly by the structure of the lifting operators.

The CDG [bilinear form](@entry_id:140194) for a diffusion problem can be expressed in a symmetric, compact form involving an augmented gradient, $\boldsymbol{G}_h(u_h) = \nabla_h u_h + \mathbf{R}_h(\llbracket u_h \rrbracket)$, where $\mathbf{R}_h$ is the global lifting constructed from local ones:
$$
a_h(u_h, v_h) = \int_{\Omega} \boldsymbol{G}_h(u_h) \cdot \boldsymbol{G}_h(v_h) \, \mathrm{d}x
$$
The associated [energy norm](@entry_id:274966) is simply $\|v_h\|_{\mathrm{CDG}}^2 = a_h(v_h, v_h)$. The stability of the method hinges on proving that this norm effectively controls the jumps in the solution, just as an explicit penalty term would. This is where the properties of the [lifting operator](@entry_id:751273) become critical. Through the use of trace and inverse inequalities, one can establish a fundamental [norm equivalence](@entry_id:137561) :
$$
\sum_{K \in \mathcal{T}_h} \|\mathbf{R}_h(\llbracket v_h \rrbracket)\|_{0,K}^2 \simeq \sum_{F \in \mathcal{F}_h} h_F^{-1} \|\llbracket v_h \rrbracket\|_{0,F}^2
$$
This equivalence demonstrates that the volumetric norm of the lifted jumps (the second term in the CDG energy norm) is equivalent to the standard jump-penalty term found in SIPG methods. It confirms that the [lifting operator](@entry_id:751273) provides the necessary stabilization, ensuring that the CDG bilinear form is coercive with respect to a standard DG norm. The stabilization is not absent; it is simply reformulated into [volume integrals](@entry_id:183482) via the lifting mechanism .

#### Adjoint Consistency and Optimal Convergence

Beyond stability, a crucial property for ensuring the highest possible accuracy is **[adjoint consistency](@entry_id:746293)**. For self-adjoint problems such as Poisson's equation, the [continuous operator](@entry_id:143297) is self-adjoint. To achieve the optimal [order of convergence](@entry_id:146394) for the error in the $L^2$ norm (typically of order $h^{p+1}$ for polynomials of degree $p$), the discrete operator must mimic this property; that is, the discrete [bilinear form](@entry_id:140194) must be symmetric, $a_h(u_h, v_h) = a_h(v_h, u_h)$.

This requirement is fulfilled by constructing the numerical fluxes in a symmetric way. A non-symmetric formulation can still be stable and convergent, but it generally fails the Aubin-Nitsche duality argument, which is the standard technique for proving optimal $L^2$ error estimates. A non-symmetric scheme is not adjoint consistent, and this lack of consistency introduces lower-order error terms that prevent the gain of an extra [order of convergence](@entry_id:146394) in $h$, leading to a suboptimal $L^2$ error rate (typically $h^p$) . Therefore, the symmetric construction of CDG methods is not merely an aesthetic choice but a crucial ingredient for achieving the best possible accuracy.

### Hybridization and Computational Advantages

Many modern CDG methods are formulated as **hybridized** DG methods. In this approach, the set of unknowns is expanded to include not only the solution inside each element, $u_h|_K$, but also a new variable representing the trace of the solution on all element faces, $\widehat{u}_h$.

The discretization then yields two sets of equations:
1.  A set of local problems, where the PDE is enforced on each element $K$, coupling the interior unknowns $\boldsymbol{u}_K$ to the trace unknowns $\boldsymbol{\lambda}_{\partial K}$ on its boundary.
2.  A set of transmission conditions, typically enforcing flux continuity, that couple the solutions across adjacent elements via the shared trace variable $\widehat{u}_h$.

The great advantage of this formulation is that the interior unknowns $\boldsymbol{u}_K$ can be eliminated from the system *locally* on each element. This process, known as **[static condensation](@entry_id:176722)**, involves inverting the local element matrix to express $\boldsymbol{u}_K$ purely in terms of the trace unknowns $\boldsymbol{\lambda}_{\partial K}$ on the element's boundary .

After substituting these local relations into the transmission conditions, all interior unknowns vanish from the global problem. The result is a much smaller global linear system involving only the trace unknowns $\widehat{u}_h$ on the mesh skeleton. This is the final **Schur [complement system](@entry_id:142643)**. The sparsity pattern of this system is determined by the fact that the local [static condensation](@entry_id:176722) on an element $K$ couples all of its own boundary faces together. Therefore, two face unknowns in the global system are coupled if and only if their corresponding faces belong to the same element .

This structure is exceptionally well-suited for parallel computing using **[domain decomposition methods](@entry_id:165176)**. One can partition the mesh into large subdomains, and the hybridization procedure can be applied at the subdomain level. Independent solves are performed within each subdomain (analogous to the local element solves), followed by the solution of a global interface problem for the trace variables on the boundaries between subdomains. This hierarchy dramatically reduces the communication required between processors, enabling scalable performance on massively parallel architectures.

### Practical Considerations and Robustness

#### Basis Functions and Implementation

The choice of polynomial basis within each element has significant practical consequences. Two common choices are nodal bases and modal bases.
*   A **nodal basis**, such as a Lagrange basis, consists of polynomials that are equal to 1 at one specific node within the element and 0 at all others.
*   A **[modal basis](@entry_id:752055)** consists of a set of polynomials, typically chosen to be orthogonal with respect to the $L^2$ inner product on the element.

While the choice of basis is a purely local transformation and does not alter the global element-to-element coupling pattern , it profoundly affects the properties of the local matrices. With an orthonormal [modal basis](@entry_id:752055), the element mass matrix becomes the identity matrix by definition, which is perfectly conditioned. In contrast, a nodal basis generally yields a full, non-[diagonal mass matrix](@entry_id:173002). While this matrix can be made diagonal through a "[mass lumping](@entry_id:175432)" approximation, its conditioning is a serious concern. For nodal bases constructed on [equispaced points](@entry_id:637779), the condition number of the mass matrix grows exponentially with the polynomial degree $p$, a reflection of the ill-conditioning of the underlying Vandermonde matrix. This poor conditioning can lead to a severe loss of [numerical precision](@entry_id:173145), making orthonormal modal bases or nodal bases on well-chosen points (like Gauss-Lobatto points) far more robust, especially for [high-order methods](@entry_id:165413) or on distorted meshes .

Furthermore, when implementing these methods on general meshes, particularly those with [curved elements](@entry_id:748117) defined by isoparametric mappings, meticulous care must be taken to ensure geometric consistency on shared faces. To preserve conservation and symmetry, a single, consistent set of physical quadrature points, weights, and normal vectors must be used by both elements sharing a face. A common robust strategy is to designate one element as the "master" for defining the face geometry and then use the mapping bijections to find the corresponding reference points for the "slave" element, ensuring traces and fluxes are evaluated at the exact same physical locations with normals that are exactly opposite, i.e., $\boldsymbol{n}^+ = -\boldsymbol{n}^-$ .

#### Robustness for Heterogeneous Problems

In many physical applications, material properties, such as the diffusion coefficient $\kappa$, can vary by orders of magnitude across the domain. A numerical method is considered **robust** if its stability and accuracy do not degrade as the contrast ratio of these coefficients ($\kappa_{\max} / \kappa_{\min}$) becomes large.

Achieving robustness in DG methods requires careful design of the numerical flux. It is a well-established result that using a simple arithmetic average of $\kappa$ from the two sides of a face leads to stability and error constants that depend on the contrast ratio, making the method non-robust . The key to robustness is to use a **harmonic average** of the coefficient in the numerical flux:
$$
\overline{\kappa}_F = \frac{2\kappa^+ \kappa^-}{\kappa^+ + \kappa^-}
$$
When this average is used, the terms in the stability analysis that could potentially grow with the contrast ratio remain bounded. In conjunction, the [stabilization parameter](@entry_id:755311) $\sigma_F$ (whether explicit in SIPG or implicit in CDG) must be scaled appropriately with the local value of $\kappa$ (e.g., the harmonic average) to ensure [coercivity](@entry_id:159399) without being overly diffusive. The combination of [harmonic averaging](@entry_id:750175) in the flux and proper scaling of the stabilization yields a method whose performance is independent of the jumps in the diffusion coefficient, a critical feature for reliable simulation of [heterogeneous media](@entry_id:750241)  .