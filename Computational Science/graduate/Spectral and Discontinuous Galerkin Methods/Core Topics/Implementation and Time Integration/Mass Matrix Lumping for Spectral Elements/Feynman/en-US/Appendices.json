{
    "hands_on_practices": [
        {
            "introduction": "Mastering a numerical technique begins with a solid grasp of its fundamental components. This first exercise provides a foundational, step-by-step derivation of the lumped mass matrix for a one-dimensional spectral element. By starting from the definition of Legendre polynomials to find the Gauss-Lobatto-Legendre nodes and their corresponding quadrature weights , you will see precisely how and why the lumped mass matrix simplifies to a diagonal form, directly connecting theory to a practical computational shortcut.",
            "id": "3398294",
            "problem": "Consider the reference one-dimensional spectral element on the interval $[-1,1]$ with Lagrange interpolation basis functions built on the Gauss–Lobatto–Legendre (GLL) nodes associated with polynomial degree $N=4$. Let $\\{\\phi_i(x)\\}_{i=0}^{N}$ denote the nodal Lagrange basis functions associated with the $N+1$ GLL nodes $\\{\\xi_i\\}_{i=0}^{N}$, where the endpoints $x=-1$ and $x=1$ are included and the interior nodes are the roots of the derivative of the Legendre polynomial of degree $N$. The continuous spectral element mass matrix on the reference element is defined by\n$$\nM_{ij} \\;=\\; \\int_{-1}^{1} \\phi_i(x)\\,\\phi_j(x)\\,\\mathrm{d}x.\n$$\nIn mass-lumped spectral elements and in the Discontinuous Galerkin (DG) method, a common diagonal approximation to $M_{ij}$ is obtained by applying GLL quadrature on the same GLL nodes, yielding diagonal entries that depend on the quadrature weights.\n\nStarting from the defining properties of Legendre polynomials and the GLL construction (endpoints included and interior nodes given by the roots of the derivative of the Legendre polynomial of degree $N$), and using only these fundamental relationships and exact integration requirements for polynomials, do the following for $N=4$ on the reference element $[-1,1]$:\n- determine the $N+1$ GLL nodes $\\{\\xi_i\\}_{i=0}^{N}$,\n- compute the corresponding GLL quadrature weights $\\{w_i\\}_{i=0}^{N}$, and\n- assemble the diagonal entries of the lumped mass matrix, defined by applying the GLL quadrature to $M_{ii}$ on the reference element.\n\nExpress your final answer as a single ordered row vector listing the five diagonal lumped mass entries from the leftmost node ($x=-1$) to the rightmost node ($x=1$). Provide exact rational values; no rounding is required. The final answer must be given as a single analytic expression.",
            "solution": "The problem requires the determination of the diagonal entries of the lumped mass matrix for a one-dimensional spectral element on the reference interval $[-1, 1]$ using a polynomial basis of degree $N=4$. This task involves three main steps: first, finding the Gauss-Lobatto-Legendre (GLL) nodes; second, computing the corresponding GLL quadrature weights; and third, assembling the lumped mass matrix entries, which, as will be shown, are identical to the quadrature weights.\n\nThe GLL nodes $\\{\\xi_i\\}_{i=0}^N$ for a polynomial of degree $N$ are defined on the interval $[-1, 1]$. The set of nodes includes the endpoints $\\xi_0 = -1$ and $\\xi_N = 1$. The $N-1$ interior nodes are the roots of the first derivative of the Legendre polynomial of degree $N$, denoted as $P'_N(x)$. For this problem, $N=4$.\n\nFirst, we must determine the Legendre polynomial $P_4(x)$. The Legendre polynomials $P_n(x)$ can be generated using the Bonnet recurrence relation:\n$$ (n+1)P_{n+1}(x) = (2n+1)xP_n(x) - nP_{n-1}(x) $$\nwith the starting polynomials $P_0(x) = 1$ and $P_1(x) = x$.\nFor $n=1$:\n$2P_2(x) = 3xP_1(x) - 1P_0(x) = 3x(x) - 1 = 3x^2 - 1 \\implies P_2(x) = \\frac{1}{2}(3x^2 - 1)$.\nFor $n=2$:\n$3P_3(x) = 5xP_2(x) - 2P_1(x) = 5x\\left(\\frac{1}{2}(3x^2 - 1)\\right) - 2x = \\frac{15}{2}x^3 - \\frac{5}{2}x - 2x = \\frac{1}{2}(15x^3 - 9x) \\implies P_3(x) = \\frac{1}{2}(5x^3 - 3x)$.\nFor $n=3$:\n$4P_4(x) = 7xP_3(x) - 3P_2(x) = 7x\\left(\\frac{1}{2}(5x^3 - 3x)\\right) - 3\\left(\\frac{1}{2}(3x^2 - 1)\\right) = \\frac{1}{2}(35x^4 - 21x^2 - 9x^2 + 3) = \\frac{1}{2}(35x^4 - 30x^2 + 3)$.\nThus, the Legendre polynomial of degree $4$ is:\n$$ P_4(x) = \\frac{1}{8}(35x^4 - 30x^2 + 3) $$\nNext, we find its derivative, $P'_4(x)$:\n$$ P'_4(x) = \\frac{d}{dx}\\left[\\frac{1}{8}(35x^4 - 30x^2 + 3)\\right] = \\frac{1}{8}(140x^3 - 60x) = \\frac{20}{8}x(7x^2 - 3) = \\frac{5}{2}x(7x^2 - 3) $$\nThe interior GLL nodes are the roots of $P'_4(x) = 0$. Setting the derivative to zero gives $x=0$ and $7x^2 - 3 = 0$, which yields $x^2 = \\frac{3}{7}$, or $x = \\pm\\sqrt{\\frac{3}{7}}$.\nThe set of $N+1=5$ GLL nodes, ordered from smallest to largest, is:\n$$ \\xi_0 = -1, \\quad \\xi_1 = -\\sqrt{\\frac{3}{7}}, \\quad \\xi_2 = 0, \\quad \\xi_3 = \\sqrt{\\frac{3}{7}}, \\quad \\xi_4 = 1 $$\n\nThe second step is to compute the GLL quadrature weights $\\{w_i\\}_{i=0}^N$. The formula for the weights is given by:\n$$ w_i = \\frac{2}{N(N+1)[P_N(\\xi_i)]^2} $$\nFor $N=4$, this becomes $w_i = \\frac{2}{4(5)[P_4(\\xi_i)]^2} = \\frac{1}{10[P_4(\\xi_i)]^2}$.\nWe evaluate $P_4(x)$ at each of the GLL nodes:\nFor the endpoints $\\xi_0 = -1$ and $\\xi_4 = 1$:\n$P_4(1) = \\frac{1}{8}(35(1)^4 - 30(1)^2 + 3) = \\frac{1}{8}(35 - 30 + 3) = \\frac{8}{8} = 1$.\n$P_4(-1) = \\frac{1}{8}(35(-1)^4 - 30(-1)^2 + 3) = \\frac{1}{8}(35 - 30 + 3) = \\frac{8}{8} = 1$.\nThe weights for the endpoints are:\n$w_0 = w_4 = \\frac{1}{10[1]^2} = \\frac{1}{10}$.\nFor the interior node $\\xi_2 = 0$:\n$P_4(0) = \\frac{1}{8}(3) = \\frac{3}{8}$.\nThe weight for the central node is:\n$w_2 = \\frac{1}{10[3/8]^2} = \\frac{1}{10(9/64)} = \\frac{64}{90} = \\frac{32}{45}$.\nFor the interior nodes $\\xi_1 = -\\sqrt{3/7}$ and $\\xi_3 = \\sqrt{3/7}$, we use $\\xi_{1,3}^2 = 3/7$:\n$P_4(\\pm\\sqrt{3/7}) = \\frac{1}{8}\\left(35\\left(\\frac{3}{7}\\right)^2 - 30\\left(\\frac{3}{7}\\right) + 3\\right) = \\frac{1}{8}\\left(35\\frac{9}{49} - \\frac{90}{7} + 3\\right) = \\frac{1}{8}\\left(\\frac{5 \\cdot 9}{7} - \\frac{90}{7} + \\frac{21}{7}\\right) = \\frac{1}{8}\\left(\\frac{45 - 90 + 21}{7}\\right) = \\frac{1}{8}\\left(\\frac{-24}{7}\\right) = -\\frac{3}{7}$.\nThe weights for these nodes are:\n$w_1 = w_3 = \\frac{1}{10[-3/7]^2} = \\frac{1}{10(9/49)} = \\frac{49}{90}$.\nThe GLL quadrature weights are:\n$w_0 = \\frac{1}{10}$, $w_1 = \\frac{49}{90}$, $w_2 = \\frac{32}{45}$, $w_3 = \\frac{49}{90}$, $w_4 = \\frac{1}{10}$.\nAs a verification, the sum of the weights must equal $\\int_{-1}^1 1 \\, dx = 2$:\n$\\sum_{i=0}^4 w_i = \\frac{1}{10} + \\frac{49}{90} + \\frac{32}{45} + \\frac{49}{90} + \\frac{1}{10} = \\frac{9}{90} + \\frac{49}{90} + \\frac{64}{90} + \\frac{49}{90} + \\frac{9}{90} = \\frac{9+49+64+49+9}{90} = \\frac{180}{90} = 2$. The weights are correct.\n\nThe third and final step is to determine the diagonal entries of the lumped mass matrix. The consistent mass matrix is $M_{ij} = \\int_{-1}^1 \\phi_i(x)\\phi_j(x) dx$, where $\\phi_i(x)$ are the Lagrange basis functions defined on the GLL nodes $\\{\\xi_k\\}$, such that $\\phi_i(\\xi_k) = \\delta_{ik}$. The problem states that the lumped mass matrix is obtained by applying the GLL quadrature rule to the integral for the mass matrix entries. The GLL quadrature approximation of an integral is $\\int_{-1}^1 f(x) dx \\approx \\sum_{k=0}^N w_k f(\\xi_k)$.\nApplying this to the diagonal entries $M_{ii}$ of the mass matrix:\n$$ M_{ii}^{\\text{lumped}} = \\sum_{k=0}^{N} w_k \\phi_i(\\xi_k)\\phi_i(\\xi_k) = \\sum_{k=0}^{N} w_k (\\phi_i(\\xi_k))^2 $$\nUsing the property of Lagrange basis functions, $\\phi_i(\\xi_k) = \\delta_{ik}$ (the Kronecker delta):\n$$ M_{ii}^{\\text{lumped}} = \\sum_{k=0}^{N} w_k (\\delta_{ik})^2 $$\nSince $\\delta_{ik}$ is either $0$ or $1$, $(\\delta_{ik})^2 = \\delta_{ik}$. The sum is non-zero only at the term where $k=i$:\n$$ M_{ii}^{\\text{lumped}} = w_i (\\delta_{ii})^2 = w_i(1) = w_i $$\nThis shows that the diagonal entries of the lumped mass matrix are simply the GLL quadrature weights. Therefore, the ordered list of the five diagonal lumped mass entries, corresponding to the nodes from $\\xi_0=-1$ to $\\xi_4=1$, is the ordered list of the weights $\\{w_i\\}_{i=0}^4$.\n\nThe final answer is the row vector of these weights.\nThe vector is $(w_0, w_1, w_2, w_3, w_4) = (\\frac{1}{10}, \\frac{49}{90}, \\frac{32}{45}, \\frac{49}{90}, \\frac{1}{10})$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{10} & \\frac{49}{90} & \\frac{32}{45} & \\frac{49}{90} & \\frac{1}{10}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Every approximation in numerical methods involves a trade-off between computational cost and accuracy. While mass lumping yields a diagonal matrix that dramatically simplifies explicit time-stepping, it is essential to quantify its impact on the physical fidelity of the simulation. This practice  uses the one-dimensional wave equation to demonstrate this trade-off, guiding you to derive a closed-form expression for the error in the wave's propagation speed. This makes the abstract concept of numerical dispersion tangible and highlights the primary accuracy compromise associated with mass lumping.",
            "id": "3398334",
            "problem": "Consider the one-dimensional scalar wave equation in conservative form on the reference domain $[-1,1]$ with periodic boundary conditions,\n$$\nu_{tt}(x,t) \\;=\\; c^{2}\\,u_{xx}(x,t),\n$$\nwhere $c>0$ is a constant propagation speed. In a single-element spectral element method (SEM), approximate $u(x,t)$ by a polynomial of degree $2$ expressed in the Lagrange nodal basis associated with the Legendre–Gauss–Lobatto (LGL) nodes $x_{1}=-1$, $x_{2}=0$, and $x_{3}=1$. Let $\\{\\ell_{i}(x)\\}_{i=1}^{3}$ denote the corresponding Lagrange basis polynomials satisfying $\\ell_{i}(x_{j})=\\delta_{ij}$. Define the consistent mass matrix $M\\in\\mathbb{R}^{3\\times3}$ and the stiffness matrix $K\\in\\mathbb{R}^{3\\times3}$ by the exact bilinear forms\n$$\nM_{ij} \\;=\\; \\int_{-1}^{1} \\ell_{i}(x)\\,\\ell_{j}(x)\\,dx,\n\\qquad\nK_{ij} \\;=\\; \\int_{-1}^{1} \\ell'_{i}(x)\\,\\ell'_{j}(x)\\,dx.\n$$\nDefine the lumped mass matrix $\\tilde{M}\\in\\mathbb{R}^{3\\times3}$ as the diagonal matrix of LGL quadrature weights on $[-1,1]$, i.e., $\\tilde{M} = \\mathrm{diag}(w_{1},w_{2},w_{3})$ with $w_{1}=\\frac{1}{3}$, $w_{2}=\\frac{4}{3}$, and $w_{3}=\\frac{1}{3}$. The semi-discrete dynamics are governed by\n$$\nM\\,\\ddot{\\mathbf{u}}(t) + c^{2} K\\,\\mathbf{u}(t) = \\mathbf{0}\n\\quad\\text{or}\\quad\n\\tilde{M}\\,\\ddot{\\mathbf{u}}(t) + c^{2} K\\,\\mathbf{u}(t) = \\mathbf{0},\n$$\ndepending on whether $M$ or $\\tilde{M}$ is used. For a given wavenumber $k\\in\\mathbb{R}$, consider the complex-valued nodal vector that samples a plane wave at the LGL nodes,\n$$\n\\mathbf{v}_{k} = \\begin{pmatrix} \\exp(\\mathrm{i}k x_{1}) \\\\ \\exp(\\mathrm{i}k x_{2}) \\\\ \\exp(\\mathrm{i}k x_{3}) \\end{pmatrix}\n= \\begin{pmatrix} \\exp(-\\mathrm{i}k) \\\\ 1 \\\\ \\exp(\\mathrm{i}k) \\end{pmatrix}.\n$$\nThe squared angular frequency associated with $\\mathbf{v}_{k}$ in the consistent and lumped cases can be estimated by the Rayleigh quotients,\n$$\n\\omega_{M}^{2}(k) = c^{2}\\,\\frac{\\mathbf{v}_{k}^{\\ast} K\\,\\mathbf{v}_{k}}{\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k}},\n\\qquad\n\\omega_{\\tilde{M}}^{2}(k) = c^{2}\\,\\frac{\\mathbf{v}_{k}^{\\ast} K\\,\\mathbf{v}_{k}}{\\mathbf{v}_{k}^{\\ast} \\tilde{M}\\,\\mathbf{v}_{k}},\n$$\nwhere the superscript $\\ast$ denotes complex conjugate transpose. Define the phase speed $c_{p}(k) = \\omega(k)/k$. Using only the definitions above and first principles of the Galerkin discretization, construct a counterexample showing that $M$ and $\\tilde{M}$ yield different eigenfrequency estimates for the same $\\mathbf{v}_{k}$, and derive a closed-form expression for the relative phase speed error\n$$\n\\delta(k) \\;=\\; \\frac{c_{p,\\tilde{M}}(k) - c_{p,M}(k)}{c_{p,M}(k)}.\n$$\nYour final answer must be a single closed-form analytic expression for $\\delta(k)$ in terms of $k$. No numerical evaluation or rounding is required.",
            "solution": "The problem is well-posed and scientifically sound, grounded in the principles of numerical analysis for partial differential equations, specifically the spectral element method. All definitions and conditions are provided, and no contradictions or ambiguities are present. We may proceed with the solution.\n\nThe objective is to find the relative phase speed error, $\\delta(k)$, defined as\n$$\n\\delta(k) = \\frac{c_{p,\\tilde{M}}(k) - c_{p,M}(k)}{c_{p,M}(k)} = \\frac{c_{p,\\tilde{M}}(k)}{c_{p,M}(k)} - 1.\n$$\nThe phase speed is given by $c_p(k) = \\omega(k)/k$. Therefore, the ratio of phase speeds is equal to the ratio of angular frequencies:\n$$\n\\frac{c_{p,\\tilde{M}}(k)}{c_{p,M}(k)} = \\frac{\\omega_{\\tilde{M}}(k)/k}{\\omega_{M}(k)/k} = \\frac{\\omega_{\\tilde{M}}(k)}{\\omega_{M}(k)}.\n$$\nSince $\\omega(k) > 0$ for non-trivial modes, we can write this as the square root of the ratio of squared frequencies:\n$$\n\\frac{\\omega_{\\tilde{M}}(k)}{\\omega_{M}(k)} = \\sqrt{\\frac{\\omega_{\\tilde{M}}^{2}(k)}{\\omega_{M}^{2}(k)}}.\n$$\nUsing the provided definitions of the squared angular frequencies as Rayleigh quotients:\n$$\n\\frac{\\omega_{\\tilde{M}}^{2}(k)}{\\omega_{M}^{2}(k)} = \\frac{c^{2}\\,\\frac{\\mathbf{v}_{k}^{\\ast} K\\,\\mathbf{v}_{k}}{\\mathbf{v}_{k}^{\\ast} \\tilde{M}\\,\\mathbf{v}_{k}}}{c^{2}\\,\\frac{\\mathbf{v}_{k}^{\\ast} K\\,\\mathbf{v}_{k}}{\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k}}}.\n$$\nAssuming the mode is not trivial, $\\mathbf{v}_{k}^{\\ast} K\\,\\mathbf{v}_{k} \\neq 0$, and we can cancel this term, which simplifies the expression significantly:\n$$\n\\frac{\\omega_{\\tilde{M}}^{2}(k)}{\\omega_{M}^{2}(k)} = \\frac{\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k}}{\\mathbf{v}_{k}^{\\ast} \\tilde{M}\\,\\mathbf{v}_{k}}.\n$$\nThus, the relative error $\\delta(k)$ depends only on the ratio of the denominator terms from the Rayleigh quotients:\n$$\n\\delta(k) = \\sqrt{\\frac{\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k}}{\\mathbf{v}_{k}^{\\ast} \\tilde{M}\\,\\mathbf{v}_{k}}} - 1.\n$$\nOur task reduces to computing the two quadratic forms in the denominator.\n\nFirst, we compute the term for the lumped mass matrix, $\\mathbf{v}_{k}^{\\ast} \\tilde{M}\\,\\mathbf{v}_{k}$. The lumped mass matrix $\\tilde{M}$ is diagonal with entries given by the Legendre-Gauss-Lobatto (LGL) quadrature weights for $3$ points: $\\tilde{M} = \\mathrm{diag}(w_{1}, w_{2}, w_{3}) = \\mathrm{diag}(\\frac{1}{3}, \\frac{4}{3}, \\frac{1}{3})$. The test vector is $\\mathbf{v}_{k} = (\\exp(-\\mathrm{i}k), 1, \\exp(\\mathrm{i}k))^T$.\n$$\n\\mathbf{v}_{k}^{\\ast} \\tilde{M}\\,\\mathbf{v}_{k} = \\begin{pmatrix} \\exp(\\mathrm{i}k) & 1 & \\exp(-\\mathrm{i}k) \\end{pmatrix} \\begin{pmatrix} \\frac{1}{3} & 0 & 0 \\\\ 0 & \\frac{4}{3} & 0 \\\\ 0 & 0 & \\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} \\exp(-\\mathrm{i}k) \\\\ 1 \\\\ \\exp(\\mathrm{i}k) \\end{pmatrix}\n$$\n$$\n\\mathbf{v}_{k}^{\\ast} \\tilde{M}\\,\\mathbf{v}_{k} = \\frac{1}{3} \\exp(\\mathrm{i}k)\\exp(-\\mathrm{i}k) + \\frac{4}{3}(1)(1) + \\frac{1}{3}\\exp(-\\mathrm{i}k)\\exp(\\mathrm{i}k) = \\frac{1}{3} + \\frac{4}{3} + \\frac{1}{3} = \\frac{6}{3} = 2.\n$$\nThis term is constant and equal to the sum of the quadrature weights, because all components of $\\mathbf{v}_k$ have unit modulus.\n\nNext, we compute the term for the consistent mass matrix, $\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k}$. By definition, $M_{ij} = \\int_{-1}^{1} \\ell_{i}(x)\\,\\ell_{j}(x)\\,dx$. Let us define the degree-$2$ polynomial interpolant of the plane wave $\\exp(\\mathrm{i}kx)$ at the LGL nodes, $f_k(x) = \\sum_{j=1}^{3} \\exp(\\mathrm{i}k x_j) \\ell_j(x) = \\sum_{j=1}^{3} (\\mathbf{v}_k)_j \\ell_j(x)$. The quadratic form can be written as:\n$$\n\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k} = \\sum_{i=1}^{3}\\sum_{j=1}^{3} \\overline{(\\mathbf{v}_k)_i} M_{ij} (\\mathbf{v}_k)_j = \\sum_{i=1}^{3}\\sum_{j=1}^{3} \\overline{(\\mathbf{v}_k)_i} \\left(\\int_{-1}^{1} \\ell_{i}(x)\\,\\ell_{j}(x)\\,dx \\right) (\\mathbf{v}_k)_j\n= \\int_{-1}^{1} \\left(\\sum_{i=1}^{3} \\overline{(\\mathbf{v}_k)_i} \\ell_i(x)\\right) \\left(\\sum_{j=1}^{3} (\\mathbf{v}_k)_j \\ell_j(x)\\right) dx = \\int_{-1}^{1} \\overline{f_k(x)}f_k(x)\\,dx = \\int_{-1}^{1} |f_k(x)|^2 dx.\n$$\nTo find $f_k(x)$, we construct the Lagrange basis polynomials $\\{\\ell_j(x)\\}_{j=1}^3$ for the nodes $x_1=-1$, $x_2=0$, $x_3=1$:\n$$\n\\ell_1(x) = \\frac{x(x-1)}{(-1)(-2)} = \\frac{1}{2}(x^2-x)\n$$\n$$\n\\ell_2(x) = \\frac{(x+1)(x-1)}{(1)(-1)} = 1-x^2\n$$\n$$\n\\ell_3(x) = \\frac{(x+1)x}{(2)(1)} = \\frac{1}{2}(x^2+x)\n$$\nNow, we construct $f_k(x) = (\\mathbf{v}_k)_1 \\ell_1(x) + (\\mathbf{v}_k)_2 \\ell_2(x) + (\\mathbf{v}_k)_3 \\ell_3(x)$:\n$$\nf_k(x) = \\exp(-\\mathrm{i}k)\\frac{1}{2}(x^2-x) + (1)(1-x^2) + \\exp(\\mathrm{i}k)\\frac{1}{2}(x^2+x)\n$$\n$$\nf_k(x) = \\left(\\frac{\\exp(-\\mathrm{i}k)+\\exp(\\mathrm{i}k)}{2} - 1\\right)x^2 + \\left(\\frac{\\exp(\\mathrm{i}k)-\\exp(-\\mathrm{i}k)}{2}\\right)x + 1\n$$\nUsing Euler's formulas, $\\cos(k) = \\frac{\\exp(\\mathrm{i}k)+\\exp(-\\mathrm{i}k)}{2}$ and $\\sin(k) = \\frac{\\exp(\\mathrm{i}k)-\\exp(-\\mathrm{i}k)}{2\\mathrm{i}}$:\n$$\nf_k(x) = (\\cos k - 1)x^2 + \\mathrm{i}\\sin(k)x + 1\n$$\nNext, we find $|f_k(x)|^2 = f_k(x)\\overline{f_k(x)}$:\n$$\n|f_k(x)|^2 = \\left( (\\cos k - 1)x^2 + 1 \\right)^2 + (\\sin(k)x)^2\n$$\n$$\n|f_k(x)|^2 = (\\cos k - 1)^2 x^4 + 2(\\cos k - 1)x^2 + 1 + \\sin^2(k)x^2\n$$\n$$\n|f_k(x)|^2 = (\\cos k - 1)^2 x^4 + (2\\cos k - 2 + \\sin^2 k)x^2 + 1\n$$\nUsing $\\sin^2(k) = 1-\\cos^2(k)$:\n$$\n|f_k(x)|^2 = (\\cos k - 1)^2 x^4 + (2\\cos k - 2 + 1 - \\cos^2 k)x^2 + 1\n$$\n$$\n|f_k(x)|^2 = (\\cos k - 1)^2 x^4 - (\\cos^2 k - 2\\cos k + 1)x^2 + 1 = (\\cos k - 1)^2 x^4 - (\\cos k - 1)^2 x^2 + 1\n$$\nNow we integrate $|f_k(x)|^2$ over the domain $[-1, 1]$:\n$$\n\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k} = \\int_{-1}^{1} \\left( (\\cos k - 1)^2(x^4 - x^2) + 1 \\right) dx = (\\cos k - 1)^2 \\left[\\frac{x^5}{5} - \\frac{x^3}{3}\\right]_{-1}^{1} + [x]_{-1}^{1}\n$$\n$$\n\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k} = (\\cos k - 1)^2 \\left( 2\\left(\\frac{1}{5} - \\frac{1}{3}\\right) \\right) + 2 = (\\cos k - 1)^2 \\left( 2\\left(\\frac{3-5}{15}\\right) \\right) + 2\n$$\n$$\n\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k} = -\\frac{4}{15}(\\cos k - 1)^2 + 2 = 2 - \\frac{4}{15}(\\cos^2 k - 2\\cos k + 1)\n$$\n$$\n\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k} = \\frac{30 - 4\\cos^2 k + 8\\cos k - 4}{15} = \\frac{26 + 8\\cos k - 4\\cos^2 k}{15} = \\frac{2}{15}(13 + 4\\cos k - 2\\cos^2 k).\n$$\nThe fact that $\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k}$ depends on $k$ while $\\mathbf{v}_{k}^{\\ast} \\tilde{M}\\,\\mathbf{v}_{k}$ does not, provides a counterexample. Specifically, $\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k} = \\mathbf{v}_{k}^{\\ast} \\tilde{M}\\,\\mathbf{v}_{k}$ only if $\\frac{2}{15}(13 + 4\\cos k - 2\\cos^2 k) = 2$, which simplifies to $2(\\cos k - 1)^2 = 0$, implying $\\cos k = 1$. For any $k$ not an integer multiple of $2\\pi$, the denominators of the Rayleigh quotients differ, and thus $\\omega_M^2(k) \\ne \\omega_{\\tilde{M}}^2(k)$, demonstrating that the eigenfrequency estimates are different.\n\nNow we can compute the ratio needed for $\\delta(k)$:\n$$\n\\frac{\\mathbf{v}_{k}^{\\ast} M\\,\\mathbf{v}_{k}}{\\mathbf{v}_{k}^{\\ast} \\tilde{M}\\,\\mathbf{v}_{k}} = \\frac{\\frac{2}{15}(13 + 4\\cos k - 2\\cos^2 k)}{2} = \\frac{1}{15}(13 + 4\\cos k - 2\\cos^2 k).\n$$\nFinally, we substitute this into the expression for $\\delta(k)$:\n$$\n\\delta(k) = \\sqrt{\\frac{1}{15}(13 + 4\\cos k - 2\\cos^2 k)} - 1.\n$$\nThis is the closed-form analytic expression for the relative phase speed error.",
            "answer": "$$ \\boxed{\\sqrt{\\frac{1}{15}(13 + 4\\cos(k) - 2\\cos^{2}(k))} - 1} $$"
        },
        {
            "introduction": "Beyond integration accuracy, the numerical properties of system matrices are critical for the robustness and efficiency of a method, particularly as the polynomial order increases. This hands-on coding exercise  challenges you to investigate the conditioning of the consistent and lumped mass matrices. By computing and comparing their condition numbers, $\\kappa_2(\\mathbf{A})$, for increasing spectral order $p$, you will uncover a fundamental difference in their numerical behavior that has profound implications for algorithm design and performance.",
            "id": "3398308",
            "problem": "Consider the one-dimensional reference interval $\\left[-1,1\\right]$ and the spectral element method using nodal Lagrange polynomials of degree $p$ at Gauss–Lobatto–Legendre (GLL) nodes. Let $\\left\\{\\ell_i(x)\\right\\}_{i=0}^{p}$ denote the Lagrange basis functions associated with the $p+1$ GLL nodes. The consistent element mass matrix $\\mathbf{M}^{\\text{cons}} \\in \\mathbb{R}^{(p+1)\\times(p+1)}$ is defined by the fundamental inner product of the $L^2$ space,\n$$\nM^{\\text{cons}}_{ij} \\;=\\; \\int_{-1}^{1} \\ell_i(x)\\,\\ell_j(x)\\,\\mathrm{d}x,\n$$\nwhich must be computed exactly for polynomials of degree up to $2p$ to preserve the induced norm. The lumped mass matrix $\\mathbf{M}^{\\text{lump}} \\in \\mathbb{R}^{(p+1)\\times(p+1)}$ is the diagonal matrix constructed by applying GLL quadrature directly to the same $L^2$ inner product with the nodal basis, resulting in diagonal entries equal to the GLL quadrature weights at the GLL nodes.\n\nFor any symmetric positive definite matrix $\\mathbf{A}$, define the two-norm condition number by\n$$\n\\kappa_2(\\mathbf{A}) \\;=\\; \\frac{\\lambda_{\\max}(\\mathbf{A})}{\\lambda_{\\min}(\\mathbf{A})},\n$$\nwhere $\\lambda_{\\max}$ and $\\lambda_{\\min}$ are the largest and smallest eigenvalues, respectively.\n\nStarting from the fundamental definition of the $L^2$ inner product and its exact evaluation via Gaussian quadrature for polynomials, implement a program that:\n- Constructs the GLL nodes and GLL quadrature weights of order $p$ using mathematically justified root-finding for Jacobi polynomials of suitable parameters, ensuring that interior nodes coincide with the roots of the derivative of the Legendre polynomial of degree $p$ and that endpoints $\\pm 1$ are included.\n- Assembles $\\mathbf{M}^{\\text{cons}}$ by evaluating the integral using Gauss–Legendre quadrature with a number of points sufficient to integrate any polynomial of degree $2p$ exactly.\n- Assembles $\\mathbf{M}^{\\text{lump}}$ as a diagonal matrix using the GLL quadrature weights, reflecting the mass-lumped approach in spectral elements.\n- Computes $\\kappa_2(\\mathbf{M}^{\\text{cons}})$ and $\\kappa_2(\\mathbf{M}^{\\text{lump}})$ for the test suite degrees $p \\in \\{4,8,12\\}$, and additionally reports growth factors relative to the baseline $p=4$, defined for each family of matrices by\n$$\ng^{\\text{cons}}(p) \\;=\\; \\frac{\\kappa_2(\\mathbf{M}^{\\text{cons}}(p))}{\\kappa_2(\\mathbf{M}^{\\text{cons}}(4))}, \n$$\n$$\ng^{\\text{lump}}(p) \\;=\\; \\frac{\\kappa_2(\\mathbf{M}^{\\text{lump}}(p))}{\\kappa_2(\\mathbf{M}^{\\text{lump}}(4))}.\n$$\n\nUse the following test suite parameter values to ensure coverage of moderate and higher orders: $p=4$ (baseline), $p=8$ (higher), and $p=12$ (even higher). For each $p$:\n- Return the condition numbers $\\kappa_2(\\mathbf{M}^{\\text{cons}})$ and $\\kappa_2(\\mathbf{M}^{\\text{lump}})$ as real numbers (floats).\n- Return the growth factors $g^{\\text{cons}}(p)$ and $g^{\\text{lump}}(p)$ as real numbers (floats).\n\nYour program should produce a single line of output containing four lists enclosed in square brackets:\n1. The list of $\\kappa_2(\\mathbf{M}^{\\text{cons}})$ values for $p\\in\\{4,8,12\\}$.\n2. The list of $\\kappa_2(\\mathbf{M}^{\\text{lump}})$ values for $p\\in\\{4,8,12\\}$.\n3. The list of $g^{\\text{cons}}(p)$ values for $p\\in\\{4,8,12\\}$.\n4. The list of $g^{\\text{lump}}(p)$ values for $p\\in\\{4,8,12\\}$.\n\nThus, the exact required output format is a single line like:\n```\n[[kappa_2(M^cons(4)),kappa_2(M^cons(8)),kappa_2(M^cons(12))],[kappa_2(M^lump(4)),kappa_2(M^lump(8)),kappa_2(M^lump(12))],[g^cons(4),g^cons(8),g^cons(12)],[g^lump(4),g^lump(8),g^lump(12)]]\n```\nNo physical units are involved in this computation; all outputs should be real numbers without any units.",
            "solution": "The problem as stated is subjected to validation and is deemed correct, well-posed, and scientifically sound. It represents a standard and insightful exercise in the numerical analysis of spectral element methods. All definitions, including those for Gauss–Lobatto–Legendre (GLL) nodes, consistent and lumped mass matrices, and condition numbers, are consistent with established literature in computational science. The problem is self-contained and provides all necessary information for a unique, verifiable solution. We may therefore proceed with a principled derivation and implementation.\n\n### Step 1: Gauss–Lobatto–Legendre Nodes and Quadrature Weights\n\nThe foundation of a nodal spectral element is the set of basis functions, which are defined with respect to a specific set of nodes on the reference interval $x \\in [-1, 1]$. The problem specifies Gauss–Lobatto–Legendre (GLL) nodes.\n\nFor a polynomial degree $p$, there are $N+1 = p+1$ GLL nodes, which we denote as $\\{x_j\\}_{j=0}^{p}$. These nodes are defined as the roots of the polynomial $(1-x^2)P'_p(x)$, where $P_p(x)$ is the Legendre polynomial of degree $p$. This definition ensures that the endpoints $x_0 = -1$ and $x_p = 1$ are included in the nodal set. The $p-1$ interior nodes are the roots of $P'_p(x)$.\n\nA numerically stable method to find these interior nodes leverages the relationship between the derivative of a Legendre polynomial and a Jacobi polynomial:\n$$\n\\frac{\\mathrm{d}P_p(x)}{\\mathrm{d}x} \\propto P_{p-1}^{(1,1)}(x)\n$$\nwhere $P_{n}^{(\\alpha,\\beta)}(x)$ is the Jacobi polynomial of degree $n$ with parameters $\\alpha$ and $\\beta$. Thus, the $p-1$ interior GLL nodes are precisely the roots of $P_{p-1}^{(1,1)}(x)$. These can be computed reliably using established numerical routines.\n\nAssociated with the GLL nodes is a GLL quadrature rule, which approximates an integral as a weighted sum of function values at the nodes:\n$$\n\\int_{-1}^{1} f(x)\\,\\mathrm{d}x \\approx \\sum_{j=0}^{p} w_j f(x_j)\n$$\nThis quadrature rule, using $p+1$ points, is exact for all polynomials of degree up to $2p-1$. The quadrature weights $\\{w_j\\}_{j=0}^{p}$ are given by the formula:\n$$\nw_j = \\frac{2}{p(p+1) [P_p(x_j)]^2}, \\quad j=0, 1, \\dots, p\n$$\nFor the endpoints $x_j = \\pm 1$, since $|P_p(\\pm 1)| = 1$, the weights simplify to $w_{0} = w_{p} = \\frac{2}{p(p+1)}$.\n\n### Step 2: Lumped Mass Matrix and its Condition Number\n\nThe lumped mass matrix, $\\mathbf{M}^{\\text{lump}}$, is derived by applying the GLL quadrature rule to the integral defining the consistent mass matrix. The basis functions are the Lagrange polynomials $\\{\\ell_i(x)\\}_{i=0}^{p}$ associated with the GLL nodes $\\{x_j\\}_{j=0}^{p}$. These basis functions possess the cardinal property $\\ell_i(x_j) = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta.\n\nApplying GLL quadrature to the mass matrix integral yields:\n$$\nM_{ij}^{\\text{cons}} = \\int_{-1}^{1} \\ell_i(x) \\ell_j(x)\\,\\mathrm{d}x \\approx \\sum_{k=0}^{p} w_k \\ell_i(x_k) \\ell_j(x_k)\n$$\nSubstituting the cardinal property $\\ell_i(x_k) = \\delta_{ik}$ and $\\ell_j(x_k) = \\delta_{jk}$:\n$$\nM_{ij}^{\\text{lump}} = \\sum_{k=0}^{p} w_k \\delta_{ik} \\delta_{jk}\n$$\nThis sum is non-zero only when $i=j=k$, resulting in $M_{ii}^{\\text{lump}} = w_i$ and $M_{ij}^{\\text{lump}} = 0$ for $i \\neq j$. Thus, the lumped mass matrix is a diagonal matrix with the GLL quadrature weights on its diagonal:\n$$\n\\mathbf{M}^{\\text{lump}} = \\text{diag}(w_0, w_1, \\dots, w_p)\n$$\nThe eigenvalues of a diagonal matrix are simply its diagonal entries. As $\\mathbf{M}^{\\text{lump}}$ is symmetric and its entries (the weights $w_j$) are positive, it is positive definite. Its eigenvalues are $\\{\\lambda_j\\}_{j=0}^p = \\{w_j\\}_{j=0}^p$. The condition number is therefore a direct ratio of the maximum and minimum GLL weights:\n$$\n\\kappa_2(\\mathbf{M}^{\\text{lump}}) = \\frac{\\lambda_{\\max}(\\mathbf{M}^{\\text{lump}})}{\\lambda_{\\min}(\\mathbf{M}^{\\text{lump}})} = \\frac{\\max_{j} \\{w_j\\}}{\\min_{j} \\{w_j\\}}\n$$\nThe minimum weight occurs at the endpoints, $\\min\\{w_j\\} = \\frac{2}{p(p+1)}$, which scales as $O(p^{-2})$. The maximum weight occurs near the center of the interval and can be shown to scale as $O(p^{-1})$. Consequently, $\\kappa_2(\\mathbf{M}^{\\text{lump}})$ is expected to grow as $O(p)$.\n\n### Step 3: Consistent Mass Matrix and its Condition Number\n\nThe consistent mass matrix, $\\mathbf{M}^{\\text{cons}}$, is defined by the exact evaluation of the integral:\n$$\nM_{ij}^{\\text{cons}} = \\int_{-1}^{1} \\ell_i(x) \\ell_j(x)\\,\\mathrm{d}x\n$$\nThe integrand, $\\ell_i(x)\\ell_j(x)$, is a product of two polynomials of degree $p$, resulting in a polynomial of degree up to $2p$. To compute this integral exactly, we must use a quadrature rule that is exact for polynomials of at least this degree. The Gauss-Legendre quadrature rule with $N_q$ points is exact for polynomials of degree up to $2N_q - 1$. We require $2N_q - 1 \\ge 2p$, which implies $N_q \\ge p + 1/2$. We choose $N_q = p+1$, which satisfies this condition.\n\nLet $\\{x^q_k, w^q_k\\}_{k=0}^{N_q-1}$ be the $N_q$-point Gauss-Legendre quadrature nodes and weights. The entries of the consistent mass matrix are computed as:\n$$\nM_{ij}^{\\text{cons}} = \\sum_{k=0}^{N_q-1} w^q_k \\ell_i(x^q_k) \\ell_j(x^q_k)\n$$\nThis computation involves first evaluating all Lagrange basis functions $\\ell_i(x)$ at all Gauss-Legendre quadrature nodes $x^q_k$. The Lagrange polynomial $\\ell_i(x)$ is given by its standard definition based on the GLL nodes $\\{x_j\\}$:\n$$\n\\ell_i(x) = \\prod_{j=0, j \\neq i}^{p} \\frac{x - x_j}{x_i - x_j}\n$$\nOnce the matrix $\\mathbf{M}^{\\text{cons}}$ is assembled, its eigenvalues are computed numerically. Since the matrix is real and symmetric (by construction), its eigenvalues are real. As it is also positive definite, its eigenvalues are positive. The condition number is then computed as the ratio of the maximum to the minimum eigenvalue:\n$$\n\\kappa_2(\\mathbf{M}^{\\text{cons}}) = \\frac{\\lambda_{\\max}(\\mathbf{M}^{\\text{cons}})}{\\lambda_{\\min}(\\mathbf{M}^{\\text{cons}})}\n$$\nTheoretical analysis shows that for the GLL nodal basis, the condition number of the consistent mass matrix is bounded by a constant independent of the polynomial degree $p$. Our numerical results are expected to corroborate this property.\n\n### Step 4: Growth Factors\n\nFinally, to quantify the growth of the condition numbers with respect to the polynomial degree $p$, we compute growth factors relative to the baseline case of $p=4$. For each family of matrices (consistent and lumped), the growth factor for a given $p$ is defined as:\n$$\ng(p) = \\frac{\\kappa_2(\\mathbf{M}(p))}{\\kappa_2(\\mathbf{M}(4))}\n$$\nFor the baseline case $p=4$, the growth factors $g^{\\text{cons}}(4)$ and $g^{\\text{lump}}(4)$ are by definition equal to $1.0$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import roots_jacobi, legendre, roots_legendre\n\ndef solve():\n    \"\"\"\n    Computes and compares the condition numbers of consistent and lumped mass matrices\n    for 1D spectral elements using GLL nodes for various polynomial degrees.\n    \"\"\"\n    p_values = [4, 8, 12]\n    \n    kappa_cons_list = []\n    kappa_lump_list = []\n\n    for p in p_values:\n        # Step 1: Compute GLL nodes and weights for degree p\n        \n        # Interior GLL nodes are roots of the derivative of P_p(x), which are the\n        # roots of the Jacobi polynomial P_{p-1}^{(1,1)}(x).\n        if p > 1:\n            interior_nodes = roots_jacobi(p - 1, 1, 1)[0]\n        else:\n            interior_nodes = np.array([])\n            \n        # Combine with endpoints to get the full set of p+1 GLL nodes\n        gll_nodes = np.concatenate(([-1.0], interior_nodes, [1.0]))\n        gll_nodes.sort()\n\n        # Compute GLL quadrature weights using the formula:\n        # w_j = 2 / (p * (p+1) * [P_p(x_j)]^2)\n        P_p = legendre(p)\n        gll_weights = 2.0 / (p * (p + 1) * (P_p(gll_nodes)**2))\n\n        # Step 2: Assemble lumped mass matrix and compute its condition number\n        \n        # The lumped mass matrix is diagonal with the GLL weights.\n        # Its eigenvalues are the weights themselves.\n        kappa_lump = np.max(gll_weights) / np.min(gll_weights)\n        kappa_lump_list.append(kappa_lump)\n\n        # Step 3: Assemble consistent mass matrix and compute its condition number\n        \n        # The integrand for M_cons is a polynomial of degree 2p. We need a\n        # quadrature rule exact for this degree. Gauss-Legendre with N_q points\n        # is exact for polynomials of degree 2*N_q - 1.\n        # We need 2*N_q - 1 >= 2p, so N_q >= p + 1/2. We choose N_q = p + 1.\n        n_quad = p + 1\n        gl_nodes, gl_weights = roots_legendre(n_quad)\n\n        # Evaluate all Lagrange basis functions (defined on GLL nodes) at all\n        # Gauss-Legendre quadrature nodes.\n        # L_ki = l_i(x_k^q)\n        L_matrix = np.zeros((n_quad, p + 1))\n        for i in range(p + 1):\n            # Numerator term for l_i(x): product of (x - x_j) for j != i\n            # Vectorized computation for all gl_nodes at once.\n            nodes_without_i = np.delete(gll_nodes, i)\n            # Use np.subtract.outer to create a matrix of differences (gl_nodes_k - nodes_without_i_j)\n            # then take the product along axis 1.\n            num_prods = np.prod(np.subtract.outer(gl_nodes, nodes_without_i), axis=1)\n\n            # Denominator term for l_i(x): product of (x_i - x_j) for j != i\n            denom = np.prod(gll_nodes[i] - nodes_without_i)\n            \n            L_matrix[:, i] = num_prods / denom\n        \n        # Assemble the consistent mass matrix using the rule:\n        # M_cons = L^T * diag(w^q) * L\n        M_cons = L_matrix.T @ np.diag(gl_weights) @ L_matrix\n        \n        # Compute eigenvalues. Use eigvalsh as the matrix is symmetric.\n        eigenvalues_cons = np.linalg.eigvalsh(M_cons)\n        \n        kappa_cons = np.max(eigenvalues_cons) / np.min(eigenvalues_cons)\n        kappa_cons_list.append(kappa_cons)\n\n    # Step 4: Calculate growth factors relative to p=4\n    baseline_kappa_cons = kappa_cons_list[0]\n    baseline_kappa_lump = kappa_lump_list[0]\n    \n    g_cons_list = [k / baseline_kappa_cons for k in kappa_cons_list]\n    g_lump_list = [k / baseline_kappa_lump for k in kappa_lump_list]\n\n    # Combine all results into a list of lists for printing\n    final_results = [\n        kappa_cons_list,\n        kappa_lump_list,\n        g_cons_list,\n        g_lump_list\n    ]\n\n    # Format the output string exactly as required, without spaces.\n    output_str = \"[\" + \",\".join([f\"[{','.join(map(str, sublist))}]\" for sublist in final_results]) + \"]\"\n    \n    print(output_str)\n\nsolve()\n```"
        }
    ]
}