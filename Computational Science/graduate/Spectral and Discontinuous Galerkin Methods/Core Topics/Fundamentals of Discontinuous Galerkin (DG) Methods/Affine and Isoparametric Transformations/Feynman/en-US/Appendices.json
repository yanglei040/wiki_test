{
    "hands_on_practices": [
        {
            "introduction": "The cornerstone of applying high-order methods to complex geometries is the transformation from a simple reference element to a physical element in the mesh. This first practice explores the most fundamental of these transformations: the affine map. By working through the concrete example of mapping a reference tetrahedron to a physical one, you will directly construct the mapping matrix and vector, and verify the map's validity by computing its Jacobian determinant .",
            "id": "3362693",
            "problem": "In the spectral element method and the discontinuous Galerkin method, mappings between a reference element and a physical element are constructed using isoparametric transformations. For a linear simplex (triangle in two dimensions or tetrahedron in three dimensions), the isoparametric mapping is affine, and its Jacobian determines both invertibility and orientation. Consider the canonical reference tetrahedron $\\hat{K}$ with vertices at the origin and the standard basis points in $\\mathbb{R}^{3}$, namely $\\hat{v}_{1}=(0,0,0)$, $\\hat{v}_{2}=(1,0,0)$, $\\hat{v}_{3}=(0,1,0)$, and $\\hat{v}_{4}=(0,0,1)$. Let $K$ be a physical tetrahedron in $\\mathbb{R}^{3}$ with vertices $v_{1}=(2,-1,0)$, $v_{2}=(3,2,1)$, $v_{3}=(1,3,-2)$, and $v_{4}=(0,0,4)$.\n\nStarting from the fundamental definition of the linear isoparametric mapping on a tetrahedron expressed in terms of the linear Lagrange shape functions on $\\hat{K}$, derive the affine form $F(\\hat{\\boldsymbol{x}})=A\\,\\hat{\\boldsymbol{x}}+b$, identify how $A$ and $b$ depend on the vertex coordinates, and construct $A$ and $b$ explicitly for the given $K$. Then compute the inverse mapping $F^{-1}$ and the condition under which $F$ is invertible with positive orientation, describing the domain of validity of $F^{-1}$ in terms of the image tetrahedron $K$.\n\nYour final reported result must be the three component functions of $F^{-1}(x,y,z)$ together with the scalar $\\det(A)$, collected into a single row matrix. No rounding is required. Do not include any units. Express the final answer as a single row matrix in LaTeX as specified.",
            "solution": "The problem requires the derivation of the affine mapping between a canonical reference tetrahedron $\\hat{K}$ and a physical tetrahedron $K$, the calculation of its inverse, and the evaluation of the Jacobian determinant.\n\nThe canonical reference tetrahedron $\\hat{K}$ is defined by the vertices $\\hat{v}_{1}=(0,0,0)$, $\\hat{v}_{2}=(1,0,0)$, $\\hat{v}_{3}=(0,1,0)$, and $\\hat{v}_{4}=(0,0,1)$. The physical tetrahedron $K$ has vertices $v_{1}=(2,-1,0)$, $v_{2}=(3,2,1)$, $v_{3}=(1,3,-2)$, and $v_{4}=(0,0,4)$. We denote a point in the reference element as $\\hat{\\boldsymbol{x}} = (\\hat{x}, \\hat{y}, \\hat{z})^T$ and a point in the physical element as $\\boldsymbol{x} = (x, y, z)^T$.\n\nThe linear isoparametric mapping $F: \\hat{K} \\to K$ is constructed using the linear Lagrange shape functions $\\hat{L}_i(\\hat{\\boldsymbol{x}})$ associated with the vertices $\\hat{v}_i$ of $\\hat{K}$. These shape functions are defined by the property $\\hat{L}_i(\\hat{v}_j) = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta. For the given canonical tetrahedron, these functions are the barycentric coordinates and are found to be:\n$$ \\hat{L}_{1}(\\hat{\\boldsymbol{x}}) = 1 - \\hat{x} - \\hat{y} - \\hat{z} $$\n$$ \\hat{L}_{2}(\\hat{\\boldsymbol{x}}) = \\hat{x} $$\n$$ \\hat{L}_{3}(\\hat{\\boldsymbol{x}}) = \\hat{y} $$\n$$ \\hat{L}_{4}(\\hat{\\boldsymbol{x}}) = \\hat{z} $$\n\nThe mapping $F$ is defined by interpolating the physical vertex coordinates using these shape functions:\n$$ \\boldsymbol{x} = F(\\hat{\\boldsymbol{x}}) = \\sum_{i=1}^{4} v_i \\hat{L}_i(\\hat{\\boldsymbol{x}}) $$\nSubstituting the expressions for $\\hat{L}_i(\\hat{\\boldsymbol{x}})$:\n$$ \\boldsymbol{x} = v_1(1 - \\hat{x} - \\hat{y} - \\hat{z}) + v_2\\hat{x} + v_3\\hat{y} + v_4\\hat{z} $$\nTo express this in the affine form $F(\\hat{\\boldsymbol{x}}) = A\\hat{\\boldsymbol{x}} + b$, we rearrange the equation by grouping terms with $\\hat{x}$, $\\hat{y}$, and $\\hat{z}$:\n$$ \\boldsymbol{x} = v_1 + (v_2 - v_1)\\hat{x} + (v_3 - v_1)\\hat{y} + (v_4 - v_1)\\hat{z} $$\nThis equation can be written in matrix form as:\n$$ \\boldsymbol{x} = \\begin{pmatrix} v_{2x}-v_{1x} & v_{3x}-v_{1x} & v_{4x}-v_{1x} \\\\ v_{2y}-v_{1y} & v_{3y}-v_{1y} & v_{4y}-v_{1y} \\\\ v_{2z}-v_{1z} & v_{3z}-v_{1z} & v_{4z}-v_{1z} \\end{pmatrix} \\begin{pmatrix} \\hat{x} \\\\ \\hat{y} \\\\ \\hat{z} \\end{pmatrix} + \\begin{pmatrix} v_{1x} \\\\ v_{1y} \\\\ v_{1z} \\end{pmatrix} $$\nComparing this to $\\boldsymbol{x} = A\\hat{\\boldsymbol{x}} + b$, we identify the matrix $A$ (the Jacobian of the transformation) and the vector $b$:\n$$ A = \\begin{pmatrix} v_2-v_1 & v_3-v_1 & v_4-v_1 \\end{pmatrix} \\quad , \\quad b = v_1 $$\nThe columns of $A$ are the vectors forming the edges of the physical tetrahedron originating from vertex $v_1$.\n\nNow, we construct $A$ and $b$ using the given vertex coordinates:\n$v_1 = (2, -1, 0)^T$, $v_2 = (3, 2, 1)^T$, $v_3 = (1, 3, -2)^T$, $v_4 = (0, 0, 4)^T$.\nThe vector $b$ is:\n$$ b = v_1 = \\begin{pmatrix} 2 \\\\ -1 \\\\ 0 \\end{pmatrix} $$\nThe columns of $A$ are:\n$v_2 - v_1 = (3-2, 2-(-1), 1-0)^T = (1, 3, 1)^T$\n$v_3 - v_1 = (1-2, 3-(-1), -2-0)^T = (-1, 4, -2)^T$\n$v_4 - v_1 = (0-2, 0-(-1), 4-0)^T = (-2, 1, 4)^T$\nSo, the matrix $A$ is:\n$$ A = \\begin{pmatrix} 1 & -1 & -2 \\\\ 3 & 4 & 1 \\\\ 1 & -2 & 4 \\end{pmatrix} $$\n\nThe mapping $F$ is invertible if and only if $A$ is an invertible matrix, which is true if $\\det(A) \\neq 0$. The mapping preserves orientation if $\\det(A) > 0$. Let us compute the determinant of $A$:\n$$ \\det(A) = 1(4 \\cdot 4 - 1 \\cdot (-2)) - (-1)(3 \\cdot 4 - 1 \\cdot 1) + (-2)(3 \\cdot (-2) - 4 \\cdot 1) $$\n$$ \\det(A) = 1(16 + 2) + 1(12 - 1) - 2(-6 - 4) = 18 + 11 - 2(-10) = 18 + 11 + 20 = 49 $$\nSince $\\det(A)=49 > 0$, the mapping is invertible and orientation-preserving. The physical vertices form a non-degenerate tetrahedron.\n\nThe inverse mapping $F^{-1}: K \\to \\hat{K}$ is found by solving $\\boldsymbol{x} = A\\hat{\\boldsymbol{x}} + b$ for $\\hat{\\boldsymbol{x}}$:\n$$ A\\hat{\\boldsymbol{x}} = \\boldsymbol{x} - b \\implies \\hat{\\boldsymbol{x}} = A^{-1}(\\boldsymbol{x} - b) $$\nThe domain of validity for $F^{-1}$ is the physical tetrahedron $K$.\nTo find $A^{-1}$, we use the adjugate matrix formula $A^{-1} = \\frac{1}{\\det(A)}\\text{adj}(A)$. The adjugate matrix, $\\text{adj}(A)$, is the transpose of the cofactor matrix $C$.\nThe cofactors $C_{ij}$ of $A$ are:\n$C_{11} = +(16 - (-2)) = 18$\n$C_{12} = -(12 - 1) = -11$\n$C_{13} = +(-6 - 4) = -10$\n$C_{21} = -(-4 - 4) = 8$\n$C_{22} = +(4 - (-2)) = 6$\n$C_{23} = -(-2 - (-1)) = 1$\n$C_{31} = +(-1 - (-8)) = 7$\n$C_{32} = -(1 - (-6)) = -7$\n$C_{33} = +(4 - (-3)) = 7$\nThe cofactor matrix is $C = \\begin{pmatrix} 18 & -11 & -10 \\\\ 8 & 6 & 1 \\\\ 7 & -7 & 7 \\end{pmatrix}$.\nThe adjugate matrix is $\\text{adj}(A) = C^T = \\begin{pmatrix} 18 & 8 & 7 \\\\ -11 & 6 & -7 \\\\ -10 & 1 & 7 \\end{pmatrix}$.\nThus, the inverse matrix is:\n$$ A^{-1} = \\frac{1}{49} \\begin{pmatrix} 18 & 8 & 7 \\\\ -11 & 6 & -7 \\\\ -10 & 1 & 7 \\end{pmatrix} $$\nNow we can write the explicit form of the inverse mapping $F^{-1}(\\boldsymbol{x}) = \\hat{\\boldsymbol{x}}$:\n$$ \\begin{pmatrix} \\hat{x} \\\\ \\hat{y} \\\\ \\hat{z} \\end{pmatrix} = \\frac{1}{49} \\begin{pmatrix} 18 & 8 & 7 \\\\ -11 & 6 & -7 \\\\ -10 & 1 & 7 \\end{pmatrix} \\begin{pmatrix} x - 2 \\\\ y - (-1) \\\\ z - 0 \\end{pmatrix} = \\frac{1}{49} \\begin{pmatrix} 18 & 8 & 7 \\\\ -11 & 6 & -7 \\\\ -10 & 1 & 7 \\end{pmatrix} \\begin{pmatrix} x - 2 \\\\ y + 1 \\\\ z \\end{pmatrix} $$\nThe three component functions of $F^{-1}(x,y,z)$ are obtained by matrix-vector multiplication:\n$$ \\hat{x}(x,y,z) = \\frac{1}{49} [18(x-2) + 8(y+1) + 7z] = \\frac{1}{49} (18x - 36 + 8y + 8 + 7z) = \\frac{1}{49} (18x + 8y + 7z - 28) $$\n$$ \\hat{y}(x,y,z) = \\frac{1}{49} [-11(x-2) + 6(y+1) - 7z] = \\frac{1}{49} (-11x + 22 + 6y + 6 - 7z) = \\frac{1}{49} (-11x + 6y - 7z + 28) $$\n$$ \\hat{z}(x,y,z) = \\frac{1}{49} [-10(x-2) + 1(y+1) + 7z] = \\frac{1}{49} (-10x + 20 + y + 1 + 7z) = \\frac{1}{49} (-10x + y + 7z + 21) $$\nThe problem asks for these three functions and the value of $\\det(A)$ to be reported.\n$\\det(A) = 49$.\nThe component functions of $F^{-1}$ are $\\hat{x}(x,y,z)$, $\\hat{y}(x,y,z)$, and $\\hat{z}(x,y,z)$ as derived above.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{49} (18x + 8y + 7z - 28) & \\frac{1}{49} (-11x + 6y - 7z + 28) & \\frac{1}{49} (-10x + y + 7z + 21) & 49\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While affine maps are perfect for straight-sided elements, accurately capturing curved boundaries requires higher-order, non-linear transformations. This exercise transitions to the core idea of isoparametric mapping, where polynomial basis functions describe not just the solution but also the geometry itself. You will construct a quadratic map for a curved quadrilateral and compute its Jacobian, gaining hands-on experience with the essential mechanics of representing curved elements in spectral and DG methods .",
            "id": "3362702",
            "problem": "Consider the reference square $\\hat{\\Omega} = [-1,1] \\times [-1,1]$ with reference coordinates $(\\xi,\\eta)$. Construct a quadratic isoparametric mapping $\\boldsymbol{F} : \\hat{\\Omega} \\to \\Omega \\subset \\mathbb{R}^2$ for a curved quadrilateral used in the spectral element and discontinuous Galerkin methods as follows.\n\nThe physical element $\\Omega$ has:\n- Bottom edge: the straight line segment from $(-1,-1)$ to $(1,-1)$.\n- Left and right edges: the straight line segments from $(-1,-1)$ to $(-1,1)$ and from $(1,-1)$ to $(1,1)$, respectively.\n- Top edge: the circular arc of the circle $x^2 + y^2 = 2$ joining $(-1,1)$ to $(1,1)$.\n\nImpose a quadratic isoparametric geometry using the tensor-product quadratic Lagrange interpolation with nodes at the $3 \\times 3$ grid $(\\xi,\\eta) \\in \\{-1,0,1\\} \\times \\{-1,0,1\\}$, where the eight boundary nodes map to the corresponding physical points:\n- Corners: $(-1,-1) \\mapsto (-1,-1)$, $(1,-1) \\mapsto (1,-1)$, $(1,1) \\mapsto (1,1)$, $(-1,1) \\mapsto (-1,1)$,\n- Midpoints on edges: $(0,-1) \\mapsto (0,-1)$, $(1,0) \\mapsto (1,0)$, $(-1,0) \\mapsto (-1,0)$, and $(0,1) \\mapsto (0,\\sqrt{2})$ (top midpoint on the circular arc).\nSet the interior node $(0,0) \\mapsto (0,0)$.\n\n1. Using the definition of isoparametric mapping with tensor-product quadratic Lagrange basis polynomials on $\\{-1,0,1\\}$ in each coordinate, derive explicit formulas for $x(\\xi,\\eta)$ and $y(\\xi,\\eta)$.\n2. From first principles, compute the Jacobian matrix $\\boldsymbol{J}(\\xi,\\eta) = \\partial(x,y)/\\partial(\\xi,\\eta)$ and its determinant $\\det \\boldsymbol{J}(\\xi,\\eta)$.\n3. Evaluate $\\det \\boldsymbol{J}$ at the two-dimensional Legendre–Gauss–Lobatto (LGL) points of polynomial degree $N=2$, namely at the tensor-product set $(\\xi,\\eta) \\in \\{-1,0,1\\} \\times \\{-1,0,1\\}$.\n4. Report the arithmetic mean of these nine values of $\\det \\boldsymbol{J}$ as a single exact closed-form expression. Do not round your answer.",
            "solution": "The solution proceeds in four stages:\n1.  Derivation of the isoparametric coordinate transformation $\\boldsymbol{F}(\\xi,\\eta) = (x(\\xi,\\eta), y(\\xi,\\eta))$.\n2.  Computation of the Jacobian matrix $\\boldsymbol{J}(\\xi,\\eta)$ and its determinant $\\det\\boldsymbol{J}(\\xi,\\eta)$.\n3.  Evaluation of $\\det\\boldsymbol{J}$ at the nine specified Legendre-Gauss-Lobatto (LGL) points.\n4.  Calculation of the arithmetic mean of these determinant values.\n\n### 1. Isoparametric Mapping\nThe mapping is constructed using tensor-product quadratic Lagrange basis polynomials. The 1D Lagrange basis polynomials on the interval $[-1,1]$ with nodes at $\\{-1, 0, 1\\}$ are:\n$$L_{-1}(\\zeta) = \\frac{(\\zeta-0)(\\zeta-1)}{(-1-0)(-1-1)} = \\frac{1}{2}\\zeta(\\zeta-1)$$\n$$L_0(\\zeta) = \\frac{(\\zeta-(-1))(\\zeta-1)}{(0-(-1))(0-1)} = -(\\zeta+1)(\\zeta-1) = 1-\\zeta^2$$\n$$L_1(\\zeta) = \\frac{(\\zeta-(-1))(\\zeta-0)}{(1-(-1))(1-0)} = \\frac{1}{2}\\zeta(\\zeta+1)$$\nA useful property is that their sum is unity: $\\sum_{i=-1,0,1} L_i(\\zeta) = 1$.\n\nThe isoparametric mapping from the reference coordinates $(\\xi,\\eta)$ to the physical coordinates $(x,y)$ is given by:\n$$x(\\xi,\\eta) = \\sum_{i \\in \\{-1,0,1\\}} \\sum_{j \\in \\{-1,0,1\\}} x_{ij} L_i(\\xi)L_j(\\eta)$$\n$$y(\\xi,\\eta) = \\sum_{i \\in \\{-1,0,1\\}} \\sum_{j \\in \\{-1,0,1\\}} y_{ij} L_i(\\xi)L_j(\\eta)$$\nwhere $(x_{ij}, y_{ij})$ are the physical coordinates of the node corresponding to the reference node $(\\xi_i, \\eta_j)$.\n\n**Derivation of $x(\\xi,\\eta)$:**\nThe physical $x$-coordinates of the nodes are given by $x_{ij} = \\xi_i \\in \\{-1, 0, 1\\}$.\n$$x(\\xi,\\eta) = \\sum_{j} \\left( x_{-1,j}L_{-1}(\\xi)L_j(\\eta) + x_{0,j}L_0(\\xi)L_j(\\eta) + x_{1,j}L_1(\\xi)L_j(\\eta) \\right)$$\n$$x(\\xi,\\eta) = \\sum_{j} \\left( (-1)L_{-1}(\\xi)L_j(\\eta) + (0)L_0(\\xi)L_j(\\eta) + (1)L_1(\\xi)L_j(\\eta) \\right)$$\n$$x(\\xi,\\eta) = \\left( L_1(\\xi)-L_{-1}(\\xi) \\right) \\sum_j L_j(\\eta)$$\nUsing $\\sum_j L_j(\\eta) = 1$:\n$$x(\\xi,\\eta) = L_1(\\xi)-L_{-1}(\\xi) = \\frac{1}{2}\\xi(\\xi+1) - \\frac{1}{2}\\xi(\\xi-1) = \\frac{1}{2}(\\xi^2+\\xi - \\xi^2+\\xi) = \\xi$$\n\n**Derivation of $y(\\xi,\\eta)$:**\nThe physical $y$-coordinates $(y_{ij})$ are provided. A direct summation is possible, but a more insightful approach is to consider the transformation as a baseline affine map plus a non-linear correction. The affine map $y=\\eta$ correctly maps $8$ of the $9$ nodes, with the only deviation being at $(\\xi, \\eta) = (0,1)$, where the physical coordinate is $y_{0,1}=\\sqrt{2}$ instead of $y=1$. The required correction at this node is $\\sqrt{2}-1$. This correction must be zero at all other nodes. This is perfectly described by the basis function corresponding to the node $(0,1)$, which is $L_0(\\xi)L_1(\\eta)$.\nThus, the mapping for $y$ can be expressed as:\n$$y(\\xi,\\eta) = \\eta + (y_{0,1}-1) \\cdot L_0(\\xi)L_1(\\eta)$$\nSubstituting the given values and basis functions:\n$$y(\\xi,\\eta) = \\eta + (\\sqrt{2}-1) (1-\\xi^2) \\left(\\frac{1}{2}\\eta(\\eta+1)\\right)$$\nSo, the explicit formulas for the mapping are:\n$$x(\\xi,\\eta) = \\xi$$\n$$y(\\xi,\\eta) = \\eta + \\frac{\\sqrt{2}-1}{2}(1-\\xi^2)(\\eta^2+\\eta)$$\n\n### 2. Jacobian Matrix and Determinant\nThe Jacobian matrix of the transformation is $\\boldsymbol{J} = \\frac{\\partial(x,y)}{\\partial(\\xi,\\eta)} = \\begin{pmatrix} \\partial x/\\partial \\xi & \\partial x/\\partial \\eta \\\\ \\partial y/\\partial \\xi & \\partial y/\\partial \\eta \\end{pmatrix}$.\n\nFirst, we compute the partial derivatives:\n$$\\frac{\\partial x}{\\partial \\xi} = 1$$\n$$\\frac{\\partial x}{\\partial \\eta} = 0$$\n$$\\frac{\\partial y}{\\partial \\xi} = \\frac{\\partial}{\\partial \\xi} \\left[ \\eta + \\frac{\\sqrt{2}-1}{2}(1-\\xi^2)(\\eta^2+\\eta) \\right] = \\frac{\\sqrt{2}-1}{2}(-2\\xi)(\\eta^2+\\eta) = -(\\sqrt{2}-1)\\xi(\\eta^2+\\eta)$$\n$$\\frac{\\partial y}{\\partial \\eta} = \\frac{\\partial}{\\partial \\eta} \\left[ \\eta + \\frac{\\sqrt{2}-1}{2}(1-\\xi^2)(\\eta^2+\\eta) \\right] = 1 + \\frac{\\sqrt{2}-1}{2}(1-\\xi^2)(2\\eta+1)$$\n\nThe Jacobian matrix is:\n$$\\boldsymbol{J}(\\xi,\\eta) = \\begin{pmatrix} 1 & 0 \\\\ -(\\sqrt{2}-1)\\xi(\\eta^2+\\eta) & 1 + \\frac{\\sqrt{2}-1}{2}(1-\\xi^2)(2\\eta+1) \\end{pmatrix}$$\n\nThe determinant of the Jacobian is:\n$$\\det\\boldsymbol{J}(\\xi,\\eta) = (1) \\left( 1 + \\frac{\\sqrt{2}-1}{2}(1-\\xi^2)(2\\eta+1) \\right) - (0) \\left( -(\\sqrt{2}-1)\\xi(\\eta^2+\\eta) \\right)$$\n$$\\det\\boldsymbol{J}(\\xi,\\eta) = 1 + \\frac{\\sqrt{2}-1}{2}(1-\\xi^2)(2\\eta+1)$$\n\n### 3. Evaluation of the Determinant at LGL points\nWe evaluate $\\det\\boldsymbol{J}$ at the $9$ points $(\\xi,\\eta) \\in \\{-1,0,1\\} \\times \\{-1,0,1\\}$.\n\nCase 1: $\\xi = -1$ or $\\xi = 1$.\nFor these values, the term $(1-\\xi^2) = 1 - (\\pm 1)^2 = 0$.\nTherefore, $\\det\\boldsymbol{J} = 1 + 0 = 1$. This applies to $6$ points:\n$\\det\\boldsymbol{J}(-1,-1) = 1$\n$\\det\\boldsymbol{J}(-1,0) = 1$\n$\\det\\boldsymbol{J}(-1,1) = 1$\n$\\det\\boldsymbol{J}(1,-1) = 1$\n$\\det\\boldsymbol{J}(1,0) = 1$\n$\\det\\boldsymbol{J}(1,1) = 1$\n\nCase 2: $\\xi = 0$.\nFor this value, $(1-\\xi^2) = 1 - 0^2 = 1$. The determinant simplifies to $\\det\\boldsymbol{J}(0,\\eta) = 1 + \\frac{\\sqrt{2}-1}{2}(2\\eta+1)$.\nWe evaluate this for $\\eta \\in \\{-1,0,1\\}$:\n- For $(\\xi,\\eta) = (0,-1)$:\n  $$\\det\\boldsymbol{J}(0,-1) = 1 + \\frac{\\sqrt{2}-1}{2}(2(-1)+1) = 1 - \\frac{\\sqrt{2}-1}{2} = \\frac{2 - (\\sqrt{2}-1)}{2} = \\frac{3-\\sqrt{2}}{2}$$\n- For $(\\xi,\\eta) = (0,0)$:\n  $$\\det\\boldsymbol{J}(0,0) = 1 + \\frac{\\sqrt{2}-1}{2}(2(0)+1) = 1 + \\frac{\\sqrt{2}-1}{2} = \\frac{2 + \\sqrt{2}-1}{2} = \\frac{1+\\sqrt{2}}{2}$$\n- For $(\\xi,\\eta) = (0,1)$:\n  $$\\det\\boldsymbol{J}(0,1) = 1 + \\frac{3(\\sqrt{2}-1)}{2} = \\frac{2 + 3\\sqrt{2}-3}{2} = \\frac{3\\sqrt{2}-1}{2}$$\n\nThe nine values of the determinant are: $1, 1, 1, \\frac{3-\\sqrt{2}}{2}, \\frac{1+\\sqrt{2}}{2}, \\frac{3\\sqrt{2}-1}{2}, 1, 1, 1$.\n\n### 4. Arithmetic Mean\nThe arithmetic mean is the sum of the nine values divided by $9$.\n$$\\text{Sum} = (1+1+1) + \\left(\\frac{3-\\sqrt{2}}{2} + \\frac{1+\\sqrt{2}}{2} + \\frac{3\\sqrt{2}-1}{2}\\right) + (1+1+1)$$\n$$\\text{Sum} = 6 + \\frac{(3-\\sqrt{2}) + (1+\\sqrt{2}) + (3\\sqrt{2}-1)}{2}$$\n$$\\text{Sum} = 6 + \\frac{3 - \\sqrt{2} + 1 + \\sqrt{2} + 3\\sqrt{2} - 1}{2}$$\n$$\\text{Sum} = 6 + \\frac{(3+1-1) + (-\\sqrt{2}+\\sqrt{2}+3\\sqrt{2})}{2} = 6 + \\frac{3 + 3\\sqrt{2}}{2}$$\n$$\\text{Sum} = \\frac{12}{2} + \\frac{3 + 3\\sqrt{2}}{2} = \\frac{15 + 3\\sqrt{2}}{2}$$\n\nThe arithmetic mean is $\\frac{1}{9} \\times \\text{Sum}$:\n$$\\text{Mean} = \\frac{1}{9} \\left(\\frac{15 + 3\\sqrt{2}}{2}\\right) = \\frac{15 + 3\\sqrt{2}}{18}$$\nFactoring out a $3$ from the numerator:\n$$\\text{Mean} = \\frac{3(5 + \\sqrt{2})}{18} = \\frac{5 + \\sqrt{2}}{6}$$",
            "answer": "$$\\boxed{\\frac{5 + \\sqrt{2}}{6}}$$"
        },
        {
            "introduction": "The geometric properties of an element mapping have profound consequences for the stability and efficiency of the numerical simulation. This final practice moves from calculation to analysis, investigating how geometric anisotropy affects the conditioning of the discrete system. By analyzing a simple stretching transformation, you will derive the scaling laws for the eigenvalues of the mass and stiffness matrices, providing a clear theoretical understanding of why high-aspect-ratio elements can degrade solver performance .",
            "id": "3362662",
            "problem": "Consider a single two-dimensional spectral element used in a Spectral Element Method or Discontinuous Galerkin Method (collectively, high-order methods), where the physical element $\\Omega$ is obtained from the reference square $\\hat{\\Omega} = [-1,1] \\times [-1,1]$ via the smooth mapping $F : \\hat{\\Omega} \\to \\Omega$ defined by $F(\\xi,\\eta) = (\\alpha\\,\\xi,\\eta)$ with $\\alpha > 0$. This mapping represents an affine stretch by a factor $\\alpha$ in the $\\xi$-direction and identity in the $\\eta$-direction, and is a special case of an isoparametric transformation with constant Jacobian. Let $\\{\\hat{\\psi}_{i}\\}_{i=1}^{N}$ be an $L^{2}(\\hat{\\Omega})$-orthonormal polynomial basis on the reference element (for example, tensor-product Legendre polynomials normalized in $L^{2}$), and define the corresponding physical basis by pullback $\\phi_{i} = \\hat{\\psi}_{i} \\circ F^{-1}$ so that the trial and test spaces on $\\Omega$ are the pushforward of the reference space under $F$.\n\nDefine the element mass matrix $M_{\\Omega} \\in \\mathbb{R}^{N \\times N}$ and stiffness matrix $K_{\\Omega} \\in \\mathbb{R}^{N \\times N}$ by the bilinear forms\n$$\n(M_{\\Omega})_{ij} = \\int_{\\Omega} \\phi_{i}(\\boldsymbol{x})\\,\\phi_{j}(\\boldsymbol{x})\\,\\mathrm{d}\\boldsymbol{x},\n\\qquad\n(K_{\\Omega})_{ij} = \\int_{\\Omega} \\nabla \\phi_{i}(\\boldsymbol{x}) \\cdot \\nabla \\phi_{j}(\\boldsymbol{x})\\,\\mathrm{d}\\boldsymbol{x},\n$$\nwhere $\\nabla$ denotes the gradient with respect to the physical coordinates. Use only foundational principles of change-of-variables for integrals under smooth mappings and the chain rule for gradients under differentiable coordinate transformations, together with standard facts about symmetric positive definite matrices and their Rayleigh quotients, to determine how the eigenvalues of $M_{\\Omega}$ and $K_{\\Omega}$ scale as functions of the stretch factor $\\alpha$.\n\nSpecifically:\n- Derive the dependence of the eigenvalues of $M_{\\Omega}$ on $\\alpha$.\n- Derive the dependence on $\\alpha$ of the smallest and largest eigenvalues of $K_{\\Omega}$.\n- From these, determine the scaling with $\\alpha$ of the spectral condition number of $K_{\\Omega}$.\n\nInterpret your findings for the regime $\\alpha \\gg 1$ in terms of anisotropy and conditioning of the discretization.\n\nReport your final answer as a single row of four symbolic expressions in the following order:\n$$\n\\text{(i) mass eigenvalue scaling factor},\\quad\n\\text{(ii) smallest stiffness eigenvalue scaling factor},\\quad\n\\text{(iii) largest stiffness eigenvalue scaling factor},\\quad\n\\text{(iv) stiffness condition number scaling factor}.\n$$\nNo numerical approximation is required; provide exact expressions in terms of $\\alpha$ only. No units are involved.",
            "solution": "The problem requires an analysis of the scaling of eigenvalues of the element mass and stiffness matrices under an anisotropic affine transformation. The physical element $\\Omega$ is mapped from the reference square $\\hat{\\Omega} = [-1,1] \\times [-1,1]$ by $F(\\xi,\\eta) = (x,y) = (\\alpha\\xi, \\eta)$, where $\\alpha > 0$. We will use change-of-variables and the chain rule to relate the physical matrices to their reference counterparts.\n\nThe Jacobian matrix of the transformation $F$ is\n$$\nJ = \\frac{\\partial(x,y)}{\\partial(\\xi,\\eta)} = \\begin{pmatrix} \\frac{\\partial x}{\\partial \\xi} & \\frac{\\partial x}{\\partial \\eta} \\\\ \\frac{\\partial y}{\\partial \\xi} & \\frac{\\partial y}{\\partial \\eta} \\end{pmatrix} = \\begin{pmatrix} \\alpha & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\nThe determinant of the Jacobian is $\\det(J) = \\alpha$. The differential area element transforms as $\\mathrm{d}\\boldsymbol{x} = |\\det(J)|\\,\\mathrm{d}\\hat{\\boldsymbol{x}} = \\alpha\\,\\mathrm{d}\\hat{\\boldsymbol{x}}$, since $\\alpha > 0$.\n\n### (i) Mass Matrix Eigenvalue Scaling\n\nThe element mass matrix is defined by $(M_{\\Omega})_{ij} = \\int_{\\Omega} \\phi_{i}(\\boldsymbol{x})\\,\\phi_{j}(\\boldsymbol{x})\\,\\mathrm{d}\\boldsymbol{x}$. The physical basis functions $\\phi_i$ are related to the reference basis functions $\\hat{\\psi}_i$ by $\\phi_i = \\hat{\\psi}_i \\circ F^{-1}$, which implies $\\phi_i(F(\\hat{\\boldsymbol{x}})) = \\hat{\\psi}_i(\\hat{\\boldsymbol{x}})$.\n\nWe perform a change of variables in the integral from the physical domain $\\Omega$ to the reference domain $\\hat{\\Omega}$:\n$$\n(M_{\\Omega})_{ij} = \\int_{\\hat{\\Omega}} \\phi_{i}(F(\\hat{\\boldsymbol{x}}))\\,\\phi_{j}(F(\\hat{\\boldsymbol{x}}))\\,|\\det(J)|\\,\\mathrm{d}\\hat{\\boldsymbol{x}} = \\int_{\\hat{\\Omega}} \\hat{\\psi}_{i}(\\hat{\\boldsymbol{x}})\\,\\hat{\\psi}_{j}(\\hat{\\boldsymbol{x}})\\,\\alpha\\,\\mathrm{d}\\hat{\\boldsymbol{x}}\n$$\n$$\n(M_{\\Omega})_{ij} = \\alpha \\int_{\\hat{\\Omega}} \\hat{\\psi}_{i}(\\hat{\\boldsymbol{x}})\\,\\hat{\\psi}_{j}(\\hat{\\boldsymbol{x}})\\,\\mathrm{d}\\hat{\\boldsymbol{x}}\n$$\nThe problem states that $\\{\\hat{\\psi}_{i}\\}$ is an $L^{2}(\\hat{\\Omega})$-orthonormal basis. By definition, this means $\\int_{\\hat{\\Omega}} \\hat{\\psi}_{i}(\\hat{\\boldsymbol{x}})\\,\\hat{\\psi}_{j}(\\hat{\\boldsymbol{x}})\\,\\mathrm{d}\\hat{\\boldsymbol{x}} = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta.\nTherefore, the mass matrix is\n$$\nM_{\\Omega} = \\alpha I_{N}\n$$\nwhere $I_N$ is the $N \\times N$ identity matrix. The eigenvalues of a scalar multiple of the identity matrix are all equal to that scalar. Thus, every eigenvalue of $M_{\\Omega}$ is $\\alpha$. The scaling factor for the eigenvalues of the mass matrix is $\\alpha$.\n\n### (ii, iii) Stiffness Matrix Eigenvalue Scaling\n\nThe element stiffness matrix is defined by $(K_{\\Omega})_{ij} = \\int_{\\Omega} \\nabla \\phi_{i}(\\boldsymbol{x}) \\cdot \\nabla \\phi_{j}(\\boldsymbol{x})\\,\\mathrm{d}\\boldsymbol{x}$. We must transform the gradient operator $\\nabla \\equiv \\nabla_{\\boldsymbol{x}} = (\\partial/\\partial x, \\partial/\\partial y)^T$ to the reference coordinates $\\hat{\\boldsymbol{x}} = (\\xi, \\eta)$.\n\nFrom the chain rule, the gradient of a function $\\phi_i$ on the physical domain is related to the gradient of the corresponding function $\\hat{\\psi}_i$ on the reference domain by $\\hat{\\nabla}\\hat{\\psi}_i = J^T \\nabla_{\\boldsymbol{x}}\\phi_i$. Therefore,\n$$\n\\nabla_{\\boldsymbol{x}}\\phi_i = (J^T)^{-1} \\hat{\\nabla}\\hat{\\psi}_i\n$$\nFor our specific transformation, $J$ is symmetric, so $J^T = J$. The inverse is $J^{-1} = \\begin{pmatrix} 1/\\alpha & 0 \\\\ 0 & 1 \\end{pmatrix}$. The physical gradient is\n$$\n\\nabla_{\\boldsymbol{x}}\\phi_i = \\begin{pmatrix} 1/\\alpha & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} \\partial\\hat{\\psi}_i/\\partial\\xi \\\\ \\partial\\hat{\\psi}_i/\\partial\\eta \\end{pmatrix} = \\begin{pmatrix} (1/\\alpha)\\partial\\hat{\\psi}_i/\\partial\\xi \\\\ \\partial\\hat{\\psi}_i/\\partial\\eta \\end{pmatrix}\n$$\nThe dot product in the integrand becomes:\n$$\n\\nabla \\phi_{i} \\cdot \\nabla \\phi_{j} = \\left(\\frac{1}{\\alpha}\\frac{\\partial\\hat{\\psi}_i}{\\partial\\xi}\\right)\\left(\\frac{1}{\\alpha}\\frac{\\partial\\hat{\\psi}_j}{\\partial\\xi}\\right) + \\left(\\frac{\\partial\\hat{\\psi}_i}{\\partial\\eta}\\right)\\left(\\frac{\\partial\\hat{\\psi}_j}{\\partial\\eta}\\right) = \\frac{1}{\\alpha^2}\\frac{\\partial\\hat{\\psi}_i}{\\partial\\xi}\\frac{\\partial\\hat{\\psi}_j}{\\partial\\xi} + \\frac{\\partial\\hat{\\psi}_i}{\\partial\\eta}\\frac{\\partial\\hat{\\psi}_j}{\\partial\\eta}\n$$\nSubstituting this and $\\mathrm{d}\\boldsymbol{x} = \\alpha\\,\\mathrm{d}\\hat{\\boldsymbol{x}}$ into the stiffness matrix definition:\n$$\n(K_{\\Omega})_{ij} = \\int_{\\hat{\\Omega}} \\left(\\frac{1}{\\alpha^2}\\frac{\\partial\\hat{\\psi}_i}{\\partial\\xi}\\frac{\\partial\\hat{\\psi}_j}{\\partial\\xi} + \\frac{\\partial\\hat{\\psi}_i}{\\partial\\eta}\\frac{\\partial\\hat{\\psi}_j}{\\partial\\eta}\\right) \\alpha\\,\\mathrm{d}\\hat{\\boldsymbol{x}}\n$$\n$$\n(K_{\\Omega})_{ij} = \\frac{1}{\\alpha}\\int_{\\hat{\\Omega}}\\frac{\\partial\\hat{\\psi}_i}{\\partial\\xi}\\frac{\\partial\\hat{\\psi}_j}{\\partial\\xi}\\,\\mathrm{d}\\hat{\\boldsymbol{x}} + \\alpha\\int_{\\hat{\\Omega}}\\frac{\\partial\\hat{\\psi}_i}{\\partial\\eta}\\frac{\\partial\\hat{\\psi}_j}{\\partial\\eta}\\,\\mathrm{d}\\hat{\\boldsymbol{x}}\n$$\nLet us define the reference stiffness matrices associated with each coordinate direction:\n$(\\hat{K}_{\\xi})_{ij} = \\int_{\\hat{\\Omega}}\\frac{\\partial\\hat{\\psi}_i}{\\partial\\xi}\\frac{\\partial\\hat{\\psi}_j}{\\partial\\xi}\\,\\mathrm{d}\\hat{\\boldsymbol{x}}$ and $(\\hat{K}_{\\eta})_{ij} = \\int_{\\hat{\\Omega}}\\frac{\\partial\\hat{\\psi}_i}{\\partial\\eta}\\frac{\\partial\\hat{\\psi}_j}{\\partial\\eta}\\,\\mathrm{d}\\hat{\\boldsymbol{x}}$.\nThen, the physical stiffness matrix is a linear combination of these reference matrices:\n$$\nK_{\\Omega} = \\frac{1}{\\alpha}\\hat{K}_{\\xi} + \\alpha\\hat{K}_{\\eta}\n$$\nThe matrices $\\hat{K}_{\\xi}$ and $\\hat{K}_{\\eta}$ are constant, symmetric, and positive semi-definite. Their eigenvalues are non-negative constants independent of $\\alpha$. To determine the scaling of the eigenvalues of $K_{\\Omega}$, we analyze its Rayleigh quotient for a vector $v \\in \\mathbb{R}^N, v \\neq 0$:\n$$\n\\frac{v^T K_{\\Omega} v}{v^T v} = \\frac{1}{\\alpha}\\frac{v^T \\hat{K}_{\\xi} v}{v^T v} + \\alpha\\frac{v^T \\hat{K}_{\\eta} v}{v^T v}\n$$\nThe eigenvalues of $K_{\\Omega}$ are the extrema of this quotient. The stiffness matrix for problems without pure Dirichlet conditions has a zero eigenvalue corresponding to constant functions. We analyze the scaling of the smallest non-zero eigenvalue, $\\lambda_{\\min}^*(K_{\\Omega})$, and the largest eigenvalue, $\\lambda_{\\max}(K_{\\Omega})$.\n\nSmallest non-zero eigenvalue: To minimize the Rayleigh quotient for large $\\alpha$, we must select a vector $v$ that makes the dominant term $\\alpha (v^T \\hat{K}_{\\eta} v)$ small. The polynomial space contains functions that depend only on $\\xi$ (e.g., $\\hat{u}(\\xi, \\eta) = f(\\xi)$). For the coefficient vector $v$ of such a function, $\\partial\\hat{u}/\\partial\\eta = 0$, which implies $v^T \\hat{K}_{\\eta} v = 0$. For such a vector, the Rayleigh quotient simplifies to $\\frac{1}{\\alpha}\\frac{v^T \\hat{K}_{\\xi} v}{v^T v}$. The minimum non-zero value of this expression is $\\frac{1}{\\alpha} \\lambda_{\\min}^*(\\hat{K}_{\\xi}|_{\\ker(\\hat{K}_\\eta)})$, which is a positive constant divided by $\\alpha$. Thus, the smallest non-zero eigenvalue scales as $1/\\alpha$.\n\nLargest eigenvalue: To maximize the Rayleigh quotient for large $\\alpha$, we must select a vector $v$ that makes the dominant term $\\alpha (v^T \\hat{K}_{\\eta} v)$ large. The maximum value of the quotient will be dominated by modes that vary in the $\\eta$-direction. The maximum is bounded by $\\lambda_{\\max}(K_\\Omega) \\le \\frac{1}{\\alpha}\\lambda_{\\max}(\\hat{K}_{\\xi}) + \\alpha\\lambda_{\\max}(\\hat{K}_{\\eta})$. For large $\\alpha$, the second term dominates. Choosing $v$ to be the eigenvector corresponding to $\\lambda_{\\max}(\\hat{K}_{\\eta})$ provides a lower bound that also scales with $\\alpha$. Therefore, the largest eigenvalue scales as $\\alpha$.\n\n### (iv) Stiffness Condition Number Scaling\n\nThe spectral condition number of $K_{\\Omega}$ is the ratio of its largest eigenvalue to its smallest non-zero eigenvalue:\n$$\n\\kappa(K_{\\Omega}) = \\frac{\\lambda_{\\max}(K_{\\Omega})}{\\lambda_{\\min}^*(K_{\\Omega})}\n$$\nUsing the scaling factors derived above:\n$$\n\\text{Scaling of } \\kappa(K_{\\Omega}) = \\frac{\\text{Scaling of } \\lambda_{\\max}(K_{\\Omega})}{\\text{Scaling of } \\lambda_{\\min}^*(K_{\\Omega})} = \\frac{O(\\alpha)}{O(1/\\alpha)} = O(\\alpha^2)\n$$\nThe condition number scaling factor is $\\alpha^2$.\n\n### Interpretation for $\\alpha \\gg 1$\n\nFor $\\alpha \\gg 1$, the element becomes a long, thin rectangle with aspect ratio $\\alpha$. The scaling results have important implications:\n- **Mass matrix:** The eigenvalues scale with $\\alpha$, reflecting the fact that the total \"mass\" (area) of the element grows linearly with the stretch factor $\\alpha$.\n- **Stiffness matrix:** The eigenvalue spectrum becomes widely spread. The small eigenvalues, scaling as $1/\\alpha$, correspond to smooth, large-scale modes that vary slowly along the element's long direction. The large eigenvalues, scaling as $\\alpha$, correspond to highly oscillatory, small-scale modes that vary rapidly across the element's short direction.\n- **Condition number:** The condition number of the stiffness matrix deteriorates as $\\alpha^2$. This severe ill-conditioning reflects the geometric anisotropy and is a well-known issue in numerical methods. It significantly slows down the convergence of iterative solvers used for the resulting linear systems, making computations on meshes with high-aspect-ratio elements challenging.\n\nThe requested scaling factors are:\n(i) Mass eigenvalue: $\\alpha$\n(ii) Smallest stiffness eigenvalue: $1/\\alpha$\n(iii) Largest stiffness eigenvalue: $\\alpha$\n(iv) Stiffness condition number: $\\alpha^2$",
            "answer": "$$\\boxed{\\begin{pmatrix} \\alpha & \\frac{1}{\\alpha} & \\alpha & \\alpha^2 \\end{pmatrix}}$$"
        }
    ]
}