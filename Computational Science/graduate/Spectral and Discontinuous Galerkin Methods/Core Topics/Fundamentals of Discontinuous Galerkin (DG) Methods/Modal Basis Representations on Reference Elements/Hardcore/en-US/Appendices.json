{
    "hands_on_practices": [
        {
            "introduction": "The foundation of any modal method lies in its choice of basis functions, which are typically required to be orthonormal to simplify calculations and ensure stability. This first practice explores the fundamental process of constructing an orthonormal basis on the one-dimensional reference element . By starting with the standard but unnormalized Legendre polynomials, you will derive the scaling factors needed for orthonormality, a task that directly relates to computing the diagonal entries of the mass matrix.",
            "id": "3400583",
            "problem": "Consider the standard one-dimensional reference element $I = [-1,1]$ used in Spectral and Discontinuous Galerkin (DG) methods. Let $\\{P_{n}\\}_{n=0}^{\\infty}$ denote the unnormalized Legendre polynomials on $I$, characterized by $P_{n}(1)=1$, which form a modal basis on $I$. Define the $L^{2}(I)$ inner product with unit weight by $\\langle f,g\\rangle = \\int_{-1}^{1} f(x)\\,g(x)\\,dx$, and let the mass matrix entries be given by $M_{mn} = \\int_{-1}^{1} P_{m}(x)\\,P_{n}(x)\\,dx$. Starting from the definitions of the inner product and mass matrix and using only fundamental properties of Legendre polynomials on $[-1,1]$, derive a closed-form expression for the diagonal entries $M_{nn}$ and determine a scaling factor $\\alpha_{n}$ such that $\\phi_{n}(x) = \\alpha_{n}\\,P_{n}(x)$ yields an $L^{2}(I)$-orthonormal basis, that is, $\\int_{-1}^{1} \\phi_{m}(x)\\,\\phi_{n}(x)\\,dx = \\delta_{mn}$ for all $m,n \\ge 0$. Provide your final answer as a single row matrix containing the expressions for $M_{nn}$ and $\\alpha_{n}$ in terms of $n$. No numerical approximation is required, and no units are involved.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**Step 1: Extract Givens**\n- **Reference element:** $I = [-1,1]$.\n- **Basis functions:** $\\{P_{n}\\}_{n=0}^{\\infty}$, the unnormalized Legendre polynomials on $I$.\n- **Normalization condition:** $P_{n}(1)=1$ for all $n \\ge 0$.\n- **Inner product:** $\\langle f,g\\rangle = \\int_{-1}^{1} f(x)\\,g(x)\\,dx$.\n- **Mass matrix:** $M_{mn} = \\int_{-1}^{1} P_{m}(x)\\,P_{n}(x)\\,dx$.\n- **Objective 1:** Find a closed-form expression for the diagonal mass matrix entries, $M_{nn}$.\n- **Objective 2:** Find a scaling factor $\\alpha_{n}$ such that $\\{\\phi_{n}(x) = \\alpha_{n}\\,P_{n}(x)\\}$ is an $L^{2}(I)$-orthonormal basis, i.e., $\\int_{-1}^{1} \\phi_{m}(x)\\,\\phi_{n}(x)\\,dx = \\delta_{mn}$.\n- **Constraint:** The derivation must use only fundamental properties of Legendre polynomials on $[-1,1]$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, rooted in the standard theory of orthogonal polynomials and their application in numerical methods for partial differential equations (specifically, spectral and discontinuous Galerkin methods). The concepts of Legendre polynomials, $L^2$ inner products, and orthonormality are well-defined mathematical constructs. The problem is well-posed, stating clear objectives and providing all necessary definitions and constraints. It is objective and free of any ambiguity or subjective claims. The problem does not violate any of the invalidity criteria listed in the prompt.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A full solution will be provided.\n\n**Derivation of the Diagonal Mass Matrix Entries, $M_{nn}$**\n\nThe diagonal entries of the mass matrix are given by $M_{nn} = \\langle P_{n},P_{n}\\rangle = \\int_{-1}^{1} (P_{n}(x))^{2}\\,dx$. We will derive a closed-form expression for $M_{nn}$ by leveraging the three-term recurrence relation for Legendre polynomials, which is a fundamental property. The Legendre polynomials with the normalization $P_{n}(1)=1$ satisfy the following recurrence relation for $n \\ge 1$:\n$$ (n+1)P_{n+1}(x) = (2n+1)xP_{n}(x) - nP_{n-1}(x) $$\nRearranging this for the term $xP_{n}(x)$, we get:\n$$ (2n+1)xP_{n}(x) = (n+1)P_{n+1}(x) + nP_{n-1}(x) $$\nLet's multiply this equation by $P_{n-1}(x)$ and integrate over the interval $I=[-1,1]$:\n$$ (2n+1)\\int_{-1}^{1} xP_{n}(x)P_{n-1}(x)\\,dx = (n+1)\\int_{-1}^{1} P_{n+1}(x)P_{n-1}(x)\\,dx + n\\int_{-1}^{1} (P_{n-1}(x))^{2}\\,dx $$\nA fundamental property of Legendre polynomials is their orthogonality on $[-1,1]$ with respect to the $L^2$ inner product, i.e., $\\int_{-1}^{1} P_{m}(x)P_{n}(x)\\,dx = 0$ for $m \\ne n$. Applying this property, the first integral on the right-hand side is zero. The second integral is, by definition, $M_{n-1,n-1}$. Thus, for $n \\ge 1$:\n$$ (2n+1)\\int_{-1}^{1} xP_{n}(x)P_{n-1}(x)\\,dx = n M_{n-1,n-1} $$\nThis gives a first expression for the integral involving $x$:\n$$ \\int_{-1}^{1} xP_{n}(x)P_{n-1}(x)\\,dx = \\frac{n}{2n+1} M_{n-1,n-1} $$\nNext, we can shift the index in the recurrence relation from $n$ to $n-1$ (for $n \\ge 2$, or more generally by defining $P_{-1}=0$):\n$$ nP_{n}(x) = (2(n-1)+1)xP_{n-1}(x) - (n-1)P_{n-2}(x) $$\nRearranging for $xP_{n-1}(x)$:\n$$ (2n-1)xP_{n-1}(x) = nP_{n}(x) + (n-1)P_{n-2}(x) $$\nNow, multiply this equation by $P_{n}(x)$ and integrate over $I$:\n$$ (2n-1)\\int_{-1}^{1} xP_{n-1}(x)P_{n}(x)\\,dx = n\\int_{-1}^{1} (P_{n}(x))^{2}\\,dx + (n-1)\\int_{-1}^{1} P_{n-2}(x)P_{n}(x)\\,dx $$\nBy orthogonality, the second integral on the right-hand side is zero. The first integral on the right is $M_{nn}$. Therefore, for $n \\ge 1$:\n$$ (2n-1)\\int_{-1}^{1} xP_{n}(x)P_{n-1}(x)\\,dx = n M_{nn} $$\nThis yields a second expression for the same integral:\n$$ \\int_{-1}^{1} xP_{n}(x)P_{n-1}(x)\\,dx = \\frac{n}{2n-1} M_{nn} $$\nEquating the two expressions for the integral $\\int_{-1}^{1} xP_{n}(x)P_{n-1}(x)\\,dx$, we obtain a recurrence relation for $M_{nn}$:\n$$ \\frac{n}{2n-1} M_{nn} = \\frac{n}{2n+1} M_{n-1,n-1} $$\nFor $n \\ge 1$, we can divide by $n$ to get:\n$$ M_{nn} = \\frac{2n-1}{2n+1} M_{n-1,n-1} $$\nTo find a closed-form expression, we need a base case. For $n=0$, $P_0(x)$ is a constant. The condition $P_0(1)=1$ implies $P_0(x)=1$. Thus,\n$$ M_{00} = \\int_{-1}^{1} (P_0(x))^2\\,dx = \\int_{-1}^{1} 1^2\\,dx = [x]_{-1}^{1} = 1 - (-1) = 2 $$\nBy repeatedly applying the recurrence relation, we get a telescoping product:\n$$ M_{nn} = \\left(\\frac{2n-1}{2n+1}\\right)M_{n-1,n-1} = \\left(\\frac{2n-1}{2n+1}\\right)\\left(\\frac{2n-3}{2n-1}\\right)M_{n-2,n-2} = \\dots = \\left(\\frac{2n-1}{2n+1}\\right)\\left(\\frac{2n-3}{2n-1}\\right)\\dots\\left(\\frac{1}{3}\\right)M_{00} $$\nThe intermediate terms cancel out, leaving:\n$$ M_{nn} = \\frac{1}{2n+1} M_{00} = \\frac{2}{2n+1} $$\nThis formula holds for all $n \\ge 0$.\n\n**Derivation of the Orthonormal Scaling Factor, $\\alpha_{n}$**\n\nThe basis $\\{\\phi_{n}(x) = \\alpha_{n}P_{n}(x)\\}$ is required to be orthonormal, which means $\\int_{-1}^{1} \\phi_{m}(x)\\phi_{n}(x)\\,dx = \\delta_{mn}$.\nSubstituting the definition of $\\phi_n(x)$:\n$$ \\int_{-1}^{1} (\\alpha_{m}P_{m}(x))(\\alpha_{n}P_{n}(x))\\,dx = \\alpha_{m}\\alpha_{n}\\int_{-1}^{1} P_{m}(x)P_{n}(x)\\,dx = \\alpha_{m}\\alpha_{n}M_{mn} = \\delta_{mn} $$\nThe orthogonality of the Legendre polynomials $\\{P_n\\}$ ensures that $M_{mn} = 0$ for $m \\ne n$, so the condition is already satisfied for off-diagonal terms. For the diagonal terms ($m=n$), we require:\n$$ \\alpha_{n}^2 M_{nn} = 1 $$\nSolving for $\\alpha_n^2$:\n$$ \\alpha_{n}^2 = \\frac{1}{M_{nn}} $$\nUsing the previously derived expression for $M_{nn}$:\n$$ \\alpha_{n}^2 = \\frac{1}{\\frac{2}{2n+1}} = \\frac{2n+1}{2} $$\nBy convention, the scaling factor $\\alpha_n$ is taken to be positive. Therefore, taking the positive square root gives:\n$$ \\alpha_{n} = \\sqrt{\\frac{2n+1}{2}} $$\n\nThe derived closed-form expressions for the diagonal mass matrix entries and the orthonormal scaling factor are $M_{nn} = \\frac{2}{2n+1}$ and $\\alpha_{n} = \\sqrt{\\frac{2n+1}{2}}$, respectively.",
            "answer": "$$ \\boxed{\\begin{pmatrix} \\frac{2}{2n+1} & \\sqrt{\\frac{2n+1}{2}} \\end{pmatrix}} $$"
        },
        {
            "introduction": "When extending modal methods from one to two dimensions, a key decision is the choice of element geometry, typically triangles or quadrilaterals. This choice fundamentally impacts the structure and size of the polynomial space used for approximation. This exercise guides you through a comparison of the total-degree polynomial space on a reference triangle and the tensor-product space on a reference square . By calculating and comparing the dimensions of these spaces, you will gain a clear understanding of the trade-offs in computational cost associated with each element type.",
            "id": "3400513",
            "problem": "Consider the reference triangle $\\hat{T}^2 := \\{(r,s)\\in \\mathbb{R}^2 : r \\ge 0, s \\ge 0, r+s \\le 1\\}$ and the reference quadrilateral $\\hat{Q}^2 := [-1,1]^2$. Let $P^p(\\hat{T}^2)$ denote the space of polynomials in two variables with total degree at most $p$ restricted to $\\hat{T}^2$, and let $Q^p(\\hat{Q}^2)$ denote the tensor-product polynomial space on $\\hat{Q}^2$ formed by polynomials of degree at most $p$ in each coordinate. In the context of spectral and Discontinuous Galerkin (DG) methods, modal bases on $\\hat{T}^2$ and $\\hat{Q}^2$ are typically constructed to span $P^p(\\hat{T}^2)$ and $Q^p(\\hat{Q}^2)$, respectively. Starting from the core definition of these polynomial spaces and basic combinatorial counting of monomials, derive general expressions for $\\dim P^p(\\hat{T}^2)$ and $\\dim Q^p(\\hat{Q}^2)$ in terms of $p$. Then, compute these dimensions explicitly for $p=0,1,2,3$. Finally, interpret the asymptotic growth rates with respect to $p$ and explain, in words, how the difference in growth arises from the total-degree versus tensor-product structure, and how this impacts the number of modal degrees of freedom on $\\hat{T}^2$ compared with $\\hat{Q}^2$ for the same $p$.\n\nFor your final boxed answer, list the eight requested dimensions in a single row matrix, ordered as $\\dim P^0(\\hat{T}^2)$, $\\dim P^1(\\hat{T}^2)$, $\\dim P^2(\\hat{T}^2)$, $\\dim P^3(\\hat{T}^2)$, $\\dim Q^0(\\hat{Q}^2)$, $\\dim Q^1(\\hat{Q}^2)$, $\\dim Q^2(\\hat{Q}^2)$, $\\dim Q^3(\\hat{Q}^2)$. No rounding is required and no physical units are involved.",
            "solution": "The problem is valid as it is scientifically grounded in the theory of polynomial approximation spaces used in numerical analysis, is well-posed with clear and standard definitions, and is expressed in objective, formal language. We may proceed with the solution.\n\nThe core of the problem is to determine the dimensions of two standard polynomial spaces used in spectral and discontinuous Galerkin methods, $P^p(\\hat{T}^2)$ and $Q^p(\\hat{Q}^2)$. The dimension of a vector space is equal to the number of elements in any of its bases. We will determine these dimensions by counting the number of monomials that form a basis for each space.\n\nFirst, let us find the dimension of $P^p(\\hat{T}^2)$, the space of polynomials in two variables (let's use $r$ and $s$) with a total degree of at most $p$. A basis for this space is given by the set of all monomials of the form $r^i s^j$, where $i$ and $j$ are non-negative integers satisfying the condition $i+j \\le p$.\nTo count the number of such pairs $(i, j)$, we can use a combinatorial argument. The problem is equivalent to finding the number of non-negative integer solutions to the inequality $i+j \\le p$. We can introduce a non-negative integer slack variable $k$ such that $k = p - (i+j)$. The inequality then transforms into the equation $i+j+k = p$, where $i \\ge 0$, $j \\ge 0$, and $k \\ge 0$.\nThis is a classic stars-and-bars problem in combinatorics. We are distributing $p$ identical items (stars) into $3$ distinct bins (representing variables $i$, $j$, and $k$). The number of ways to do this is given by the multiset coefficient formula:\n$$ \\dim P^p(\\hat{T}^2) = \\binom{p+3-1}{3-1} = \\binom{p+2}{2} $$\nExpanding the binomial coefficient, we obtain the general expression for the dimension:\n$$ \\dim P^p(\\hat{T}^2) = \\frac{(p+2)!}{2!(p+2-2)!} = \\frac{(p+2)(p+1)}{2} $$\n\nNext, we find the dimension of $Q^p(\\hat{Q}^2)$, the tensor-product polynomial space on $\\hat{Q}^2 = [-1,1]^2$. This space is formed by polynomials of degree at most $p$ in each coordinate variable (let's use $\\xi$ and $\\eta$). A basis for $Q^p(\\hat{Q}^2)$ is the set of monomials $\\xi^i \\eta^j$ where the exponents $i$ and $j$ independently satisfy $0 \\le i \\le p$ and $0 \\le j \\le p$.\nThe number of possible integer values for the exponent $i$ (from $0$ to $p$) is $p+1$.\nSimilarly, the number of possible integer values for the exponent $j$ (from $0$ to $p$) is $p+1$.\nSince the choices for $i$ and $j$ are independent, the total number of basis monomials is the product of the number of choices for each exponent. Therefore, the dimension is:\n$$ \\dim Q^p(\\hat{Q}^2) = (p+1)(p+1) = (p+1)^2 $$\n\nNow, we compute these dimensions for the specific polynomial degrees $p=0, 1, 2, 3$.\n\nFor the triangular element space $P^p(\\hat{T}^2)$:\n- For $p=0$: $\\dim P^0(\\hat{T}^2) = \\frac{(0+2)(0+1)}{2} = \\frac{2 \\cdot 1}{2} = 1$.\n- For $p=1$: $\\dim P^1(\\hat{T}^2) = \\frac{(1+2)(1+1)}{2} = \\frac{3 \\cdot 2}{2} = 3$.\n- For $p=2$: $\\dim P^2(\\hat{T}^2) = \\frac{(2+2)(2+1)}{2} = \\frac{4 \\cdot 3}{2} = 6$.\n- For $p=3$: $\\dim P^3(\\hat{T}^2) = \\frac{(3+2)(3+1)}{2} = \\frac{5 \\cdot 4}{2} = 10$.\n\nFor the quadrilateral element space $Q^p(\\hat{Q}^2)$:\n- For $p=0$: $\\dim Q^0(\\hat{Q}^2) = (0+1)^2 = 1^2 = 1$.\n- For $p=1$: $\\dim Q^1(\\hat{Q}^2) = (1+1)^2 = 2^2 = 4$.\n- For $p=2$: $\\dim Q^2(\\hat{Q}^2) = (2+1)^2 = 3^2 = 9$.\n- For $p=3$: $\\dim Q^3(\\hat{Q}^2) = (3+1)^2 = 4^2 = 16$.\n\nFinally, we interpret the asymptotic growth and the structural differences.\nThe asymptotic growth rate for large $p$ for each dimension is determined by the highest power of $p$ in its formula:\n- $\\dim P^p(\\hat{T}^2) = \\frac{1}{2}p^2 + \\frac{3}{2}p + 1$. The growth is quadratic, with $\\dim P^p(\\hat{T}^2) \\sim \\frac{1}{2}p^2$ as $p \\to \\infty$.\n- $\\dim Q^p(\\hat{Q}^2) = p^2 + 2p + 1$. The growth is also quadratic, with $\\dim Q^p(\\hat{Q}^2) \\sim p^2$ as $p \\to \\infty$.\n\nThe difference in growth arises directly from the differing constraints on the monomial exponents. For $P^p(\\hat{T}^2)$, the exponents $(i,j)$ must satisfy $i \\ge 0, j \\ge 0, i+j \\le p$. If we were to plot these integer pairs in a plane, they would completely fill a discrete triangle with vertices at $(0,0)$, $(p,0)$, and $(0,p)$. For $Q^p(\\hat{Q}^2)$, the exponents must satisfy $0 \\le i \\le p$ and $0 \\le j \\le p$. These integer pairs fill a discrete square with vertices at $(0,0)$, $(p,0)$, $(p,p)$, and $(0,p)$.\n\nFor any $p \\ge 1$, the square region of exponents for $Q^p$ strictly contains the triangular region for $P^p$. The \"extra\" monomials in $Q^p$ are those for which $i+j > p$. These include higher-order interaction terms such as $\\xi^p\\eta^p$, which has a total degree of $2p$. The maximum total degree in $Q^p(\\hat{Q}^2)$ is $2p$, whereas for $P^p(\\hat{T}^2)$ it is $p$ by definition. This structural difference means that for the same polynomial order parameter $p$, the quadrilateral space $Q^p(\\hat{Q}^2)$ contains significantly more basis functions, or degrees of freedom, than the triangular space $P^p(\\hat{T}^2)$. Asymptotically, for large $p$, a quadrilateral element has approximately twice the number of degrees of freedom as a triangular element ($\\lim_{p \\to \\infty} \\frac{\\dim Q^p}{\\dim P^p} = \\frac{p^2}{p^2/2} = 2$). This has direct implications for computational cost in methods like DG, where triangular meshes can be more economical than quadrilateral meshes when using the same polynomial order $p$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 & 3 & 6 & 10 & 1 & 4 & 9 & 16\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Constructing an orthogonal modal basis on a triangular element is significantly more involved than the tensor-product approach used for quadrilaterals, requiring specialized constructions like the Dubiner basis. This practice delves into the inner workings of such a basis, which elegantly maps the triangle to a square where orthogonality can be established using products of Jacobi polynomials . By explicitly evaluating an inner product between two different basis functions and verifying that it is zero, you will see firsthand how the theoretical property of orthogonality is built into the very definition of the basis.",
            "id": "3400515",
            "problem": "Consider the reference triangle $\\hat{T}^2$ with vertices at $(-1,-1)$, $(1,-1)$, and $(-1,1)$. Let $(a,b)\\in[-1,1]^2$ denote the collapsed coordinates related to $(r,s)\\in\\hat{T}^2$ by the mapping $r=\\frac{1}{2}(1+a)(1-b)-1$, $s=b$, whose Jacobian determinant is $J(a,b)=\\frac{1-b}{2}$. Let $\\hat{P}_n^{(\\alpha,\\beta)}$ denote the $L^2([-1,1],(1-x)^{\\alpha}(1+x)^{\\beta})$-orthonormal Jacobi polynomials. The Dubiner modal basis on $\\hat{T}^2$ is defined by\n$$\n\\phi_{p,q}(r,s)\\;=\\;\\sqrt{2}\\,\\hat{P}_p^{(0,0)}\\!\\big(a(r,s)\\big)\\,\\hat{P}_q^{(2p+1,0)}\\!\\big(b(r,s)\\big)\\,\\left(\\frac{1-b(r,s)}{2}\\right)^{p},\n$$\nfor integers $p\\ge 0$, $q\\ge 0$. The $L^2$ inner product on $\\hat{T}^2$ is\n$$\n(f,g)_{\\hat{T}^2}\\;=\\;\\int_{\\hat{T}^2} f(r,s)\\,g(r,s)\\,dr\\,ds.\n$$\nUsing only the above definitions, evaluate explicitly the integral $(\\phi_{2,0},\\phi_{1,1})_{\\hat{T}^2}$ by transforming the integral to $(a,b)$-coordinates and employing an appropriate tensor-product Gauss-type quadrature that is exact for the separated factors you obtain. Then verify that the value vanishes by orthogonality arguments inherent to the construction of the basis. Your final answer must be a single real number. No rounding is required.",
            "solution": "The task is to evaluate the integral $I = (\\phi_{2,0},\\phi_{1,1})_{\\hat{T}^2}$ and then verify the result using orthogonality arguments. The inner product is defined as:\n$$\nI = (\\phi_{2,0},\\phi_{1,1})_{\\hat{T}^2} = \\int_{\\hat{T}^2} \\phi_{2,0}(r,s)\\,\\phi_{1,1}(r,s)\\,dr\\,ds\n$$\nThe first step is to transform the integral from the reference triangle $\\hat{T}^2$ in $(r,s)$ coordinates to the reference square $[-1,1]^2$ in $(a,b)$ coordinates. The differential area element transforms as $dr\\,ds = J(a,b)\\,da\\,db$, where the Jacobian determinant is given as $J(a,b)=\\frac{1-b}{2}$. The integral becomes:\n$$\nI = \\int_{-1}^{1} \\int_{-1}^{1} \\phi_{2,0}(a,b)\\,\\phi_{1,1}(a,b)\\,J(a,b)\\,da\\,db\n$$\nThe basis functions are given by the general formula:\n$$\n\\phi_{p,q}(r,s) = \\sqrt{2}\\,\\hat{P}_p^{(0,0)}\\!\\big(a(r,s)\\big)\\,\\hat{P}_q^{(2p+1,0)}\\!\\big(b(r,s)\\big)\\,\\left(\\frac{1-b(r,s)}{2}\\right)^{p}\n$$\nFor $(\\phi_{2,0},\\phi_{1,1})_{\\hat{T}^2}$, we have two sets of indices: $(p,q) = (2,0)$ and $(p',q') = (1,1)$. Let's write the specific basis functions:\nFor $p=2, q=0$:\n$$\n\\phi_{2,0}(a,b) = \\sqrt{2}\\,\\hat{P}_2^{(0,0)}(a)\\,\\hat{P}_0^{(2(2)+1,0)}(b)\\,\\left(\\frac{1-b}{2}\\right)^{2} = \\sqrt{2}\\,\\hat{P}_2^{(0,0)}(a)\\,\\hat{P}_0^{(5,0)}(b)\\,\\left(\\frac{1-b}{2}\\right)^{2}\n$$\nFor $p'=1, q'=1$:\n$$\n\\phi_{1,1}(a,b) = \\sqrt{2}\\,\\hat{P}_1^{(0,0)}(a)\\,\\hat{P}_1^{(2(1)+1,0)}(b)\\,\\left(\\frac{1-b}{2}\\right)^{1} = \\sqrt{2}\\,\\hat{P}_1^{(0,0)}(a)\\,\\hat{P}_1^{(3,0)}(b)\\,\\left(\\frac{1-b}{2}\\right)\n$$\nNow, substitute these into the integral expression:\n$$\nI = \\int_{-1}^{1} \\int_{-1}^{1} \\left[ \\sqrt{2}\\,\\hat{P}_2^{(0,0)}(a)\\,\\hat{P}_0^{(5,0)}(b)\\,\\left(\\frac{1-b}{2}\\right)^{2} \\right] \\left[ \\sqrt{2}\\,\\hat{P}_1^{(0,0)}(a)\\,\\hat{P}_1^{(3,0)}(b)\\,\\left(\\frac{1-b}{2}\\right) \\right] \\left(\\frac{1-b}{2}\\right) \\,da\\,db\n$$\nCombining terms, we get:\n$$\nI = \\int_{-1}^{1} \\int_{-1}^{1} 2 \\left( \\hat{P}_2^{(0,0)}(a)\\,\\hat{P}_1^{(0,0)}(a) \\right) \\left( \\hat{P}_0^{(5,0)}(b)\\,\\hat{P}_1^{(3,0)}(b) \\right) \\left( \\frac{1-b}{2} \\right)^{2+1+1} \\,da\\,db\n$$\n$$\nI = \\int_{-1}^{1} \\int_{-1}^{1} 2 \\left( \\hat{P}_2^{(0,0)}(a)\\,\\hat{P}_1^{(0,0)}(a) \\right) \\left( \\hat{P}_0^{(5,0)}(b)\\,\\hat{P}_1^{(3,0)}(b) \\left( \\frac{1-b}{2} \\right)^{4} \\right) \\,da\\,db\n$$\nThe integral is separable into a product of two one-dimensional integrals:\n$$\nI = 2 \\left[ \\int_{-1}^{1} \\hat{P}_2^{(0,0)}(a)\\,\\hat{P}_1^{(0,0)}(a) \\,da \\right] \\left[ \\int_{-1}^{1} \\hat{P}_0^{(5,0)}(b)\\,\\hat{P}_1^{(3,0)}(b) \\left( \\frac{1-b}{2} \\right)^{4} \\,db \\right]\n$$\nLet's denote the integral in $a$ as $I_a$ and the integral in $b$ as $I_b$. The problem requires evaluation using a Gauss-type quadrature that is exact. We first analyze $I_a$:\n$$\nI_a = \\int_{-1}^{1} \\hat{P}_2^{(0,0)}(a)\\,\\hat{P}_1^{(0,0)}(a) \\,da\n$$\nThe polynomials $\\hat{P}_n^{(0,0)}$ are the orthonormal Legendre polynomials. We have:\n$\\hat{P}_1^{(0,0)}(a) = \\sqrt{\\frac{3}{2}}a$\n$\\hat{P}_2^{(0,0)}(a) = \\sqrt{\\frac{5}{2}}\\frac{1}{2}(3a^2-1)$\nThe integrand of $I_a$ is $f(a) = \\hat{P}_2^{(0,0)}(a)\\,\\hat{P}_1^{(0,0)}(a) = \\sqrt{\\frac{15}{4}}\\frac{1}{2}(3a^3-a) = \\frac{\\sqrt{15}}{4}(3a^3-a)$. This is a polynomial of degree $3$. A Gauss-Legendre quadrature with $N$ points is exact for polynomials of degree up to $2N-1$. For our integrand of degree $3$, we need $2N-1 \\ge 3$, which means $N \\ge 2$. We choose a $2$-point Gauss-Legendre quadrature, which is exact.\nThe $2$-point rule for an integral $\\int_{-1}^1 g(x)dx$ is given by $w_1 g(x_1) + w_2 g(x_2)$, with nodes $x_1 = -1/\\sqrt{3}$, $x_2 = 1/\\sqrt{3}$ and weights $w_1 = w_2 = 1$.\nApplying this to $I_a$:\n$$\nI_a = f(-1/\\sqrt{3}) + f(1/\\sqrt{3})\n$$\nWe evaluate $f(a)$ at the nodes:\n$f(1/\\sqrt{3}) = \\frac{\\sqrt{15}}{4}\\left(3\\left(\\frac{1}{\\sqrt{3}}\\right)^3 - \\frac{1}{\\sqrt{3}}\\right) = \\frac{\\sqrt{15}}{4}\\left(3\\frac{1}{3\\sqrt{3}} - \\frac{1}{\\sqrt{3}}\\right) = \\frac{\\sqrt{15}}{4}\\left(\\frac{1}{\\sqrt{3}} - \\frac{1}{\\sqrt{3}}\\right) = 0$.\n$f(-1/\\sqrt{3}) = \\frac{\\sqrt{15}}{4}\\left(3\\left(\\frac{-1}{\\sqrt{3}}\\right)^3 - \\left(\\frac{-1}{\\sqrt{3}}\\right)\\right) = \\frac{\\sqrt{15}}{4}\\left(3\\frac{-1}{3\\sqrt{3}} + \\frac{1}{\\sqrt{3}}\\right) = \\frac{\\sqrt{15}}{4}\\left(-\\frac{1}{\\sqrt{3}} + \\frac{1}{\\sqrt{3}}\\right) = 0$.\nThus, the quadrature yields $I_a = 0 + 0 = 0$.\nSince the integral $I_a$ is a factor of the total integral $I$, we have:\n$$\nI = 2 \\cdot I_a \\cdot I_b = 2 \\cdot 0 \\cdot I_b = 0\n$$\nThe value of the integral is $0$. This result is exact because the quadrature rule is exact for the polynomial integrand. For completeness, a tensor-product quadrature would be constructed. The integrand in $b$ is a polynomial of degree $5$, which requires a $3$-point Gauss-Legendre rule for exact integration. The full, exact quadrature would be a $2 \\times 3$ tensor-product Gauss-Legendre rule. However, since the $a$-integral is $0$, the total value is $0$ regardless of the $b$-integral's value.\n\nNext, we verify this result using the orthogonality properties of the basis construction. The inner product $(\\phi_{p,q}, \\phi_{p',q'})_{\\hat{T}^2}$ is:\n$$\n(\\phi_{p,q}, \\phi_{p',q'})_{\\hat{T}^2} = \\int_{-1}^{1} \\int_{-1}^{1} \\phi_{p,q}(a,b)\\,\\phi_{p',q'}(a,b) \\frac{1-b}{2} \\,da\\,db\n$$\nSubstituting the general expressions and separating the variables:\n$$\n= \\int_{-1}^{1} \\int_{-1}^{1} 2 \\hat{P}_p^{(0,0)}(a)\\hat{P}_{p'}^{(0,0)}(a) \\hat{P}_q^{(2p+1,0)}(b)\\hat{P}_{q'}^{(2p'+1,0)}(b) \\left(\\frac{1-b}{2}\\right)^{p+p'} \\frac{1-b}{2} \\,da\\,db\n$$\n$$\n= \\left( \\int_{-1}^{1} \\hat{P}_p^{(0,0)}(a)\\hat{P}_{p'}^{(0,0)}(a) \\,da \\right) \\left( \\int_{-1}^{1} 2 \\hat{P}_q^{(2p+1,0)}(b)\\hat{P}_{q'}^{(2p'+1,0)}(b) \\left(\\frac{1-b}{2}\\right)^{p+p'+1} \\,db \\right)\n$$\nThe polynomials $\\hat{P}_n^{(0,0)}(a)$ are, by definition, orthonormal with respect to the weight function $w(a)=(1-a)^0(1+a)^0=1$ on the interval $[-1,1]$. Therefore, the integral in $a$ is, by definition of orthonormality:\n$$\n\\int_{-1}^{1} \\hat{P}_p^{(0,0)}(a)\\hat{P}_{p'}^{(0,0)}(a) \\,da = \\delta_{pp'}\n$$\nwhere $\\delta_{pp'}$ is the Kronecker delta.\nIn our specific case, we are computing $(\\phi_{2,0}, \\phi_{1,1})_{\\hat{T}^2}$, so we have $p=2$ and $p'=1$. Since $p \\neq p'$, the Kronecker delta $\\delta_{2,1} = 0$.\nThe entire inner product is a product of the $a$-integral and the $b$-integral. Since the $a$-integral is $0$, the entire expression is $0$.\n$$\n(\\phi_{2,0}, \\phi_{1,1})_{\\hat{T}^2} = \\delta_{2,1} \\cdot (\\text{integral in } b) = 0 \\cdot (\\text{integral in } b) = 0\n$$\nThis confirms, through the inherent orthogonality of the construction, that the integral $(\\phi_{2,0}, \\phi_{1,1})_{\\hat{T}^2}$ must be zero. This is a general feature of this basis: $(\\phi_{p,q}, \\phi_{p',q'})_{\\hat{T}^2}=0$ if $p \\neq p'$. The calculation via quadrature explicitly showed this to be true.",
            "answer": "$$\n\\boxed{0}\n$$"
        }
    ]
}