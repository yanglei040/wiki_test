{
    "hands_on_practices": [
        {
            "introduction": "The transformation from a simple reference element, like a square, to a complex physical element is the cornerstone of high-order methods. This transformation is quantified by the Jacobian matrix and its determinant, $J$. This first exercise  provides practice in computing the Jacobian for a given curvilinear mapping and interpreting its determinant as a local area scaling factor, a fundamental concept for understanding how integrals are transformed and how element geometry is locally distorted.",
            "id": "3393863",
            "problem": "In high-order Spectral Element Method (SEM) and Discontinuous Galerkin (DG) formulations, integrals over a physical element are evaluated by pulling back to a reference element via a smooth mapping. Consider the two-dimensional reference square $[-1,1]^2$ with coordinates $(\\xi,\\eta)$ and the curvilinear isoparametric mapping $\\boldsymbol{x}(\\xi,\\eta) = \\big(x(\\xi,\\eta),y(\\xi,\\eta)\\big)$ into the physical plane defined by\n$$\nx(\\xi,\\eta) = \\xi + 0.1\\,\\xi\\,\\eta,\\qquad y(\\xi,\\eta) = \\eta + 0.2\\,\\eta^{2}.\n$$\nStarting from first principles, namely the change-of-variables theorem for surface integrals and the definition of the Jacobian matrix as the matrix of partial derivatives of the mapping, derive the determinant of the Jacobian matrix $J(\\xi,\\eta)$ for this mapping. Using your derived expression, evaluate $J(\\xi,\\eta)$ and its absolute value $|J(\\xi,\\eta)|$ at the point $(\\xi,\\eta)=(0.5,-0.5)$. Briefly interpret the value of the determinant as a local area scaling factor that relates an infinitesimal area element in the reference space to its image in the physical space. Express your final answer as the exact value of $|J(0.5,-0.5)|$ (no rounding).",
            "solution": "The problem requires the derivation of the Jacobian determinant for a given mapping from a reference element to a physical element, its evaluation at a specific point, and an interpretation of its geometric meaning.\n\nThe mapping from the reference coordinates $(\\xi, \\eta)$ in the square $[-1,1]^2$ to the physical coordinates $(x,y)$ is given by $\\boldsymbol{x}(\\xi,\\eta) = \\big(x(\\xi,\\eta), y(\\xi,\\eta)\\big)$, with components:\n$$\nx(\\xi,\\eta) = \\xi + 0.1\\,\\xi\\,\\eta\n$$\n$$\ny(\\xi,\\eta) = \\eta + 0.2\\,\\eta^{2}\n$$\nFrom first principles, the Jacobian matrix of this transformation, denoted $\\mathbf{J}(\\xi, \\eta)$, is the matrix of all first-order partial derivatives of the mapping functions:\n$$\n\\mathbf{J}(\\xi, \\eta) = \\frac{\\partial(x,y)}{\\partial(\\xi,\\eta)} = \\begin{pmatrix} \\frac{\\partial x}{\\partial \\xi}  \\frac{\\partial x}{\\partial \\eta} \\\\ \\frac{\\partial y}{\\partial \\xi}  \\frac{\\partial y}{\\partial \\eta} \\end{pmatrix}\n$$\nWe compute each partial derivative:\n1.  $\\frac{\\partial x}{\\partial \\xi} = \\frac{\\partial}{\\partial \\xi} (\\xi + 0.1\\,\\xi\\,\\eta) = 1 + 0.1\\,\\eta$\n2.  $\\frac{\\partial x}{\\partial \\eta} = \\frac{\\partial}{\\partial \\eta} (\\xi + 0.1\\,\\xi\\,\\eta) = 0.1\\,\\xi$\n3.  $\\frac{\\partial y}{\\partial \\xi} = \\frac{\\partial}{\\partial \\xi} (\\eta + 0.2\\,\\eta^{2}) = 0$\n4.  $\\frac{\\partial y}{\\partial \\eta} = \\frac{\\partial}{\\partial \\eta} (\\eta + 0.2\\,\\eta^{2}) = 1 + 0.4\\,\\eta$\n\nSubstituting these into the matrix gives the Jacobian matrix for the mapping:\n$$\n\\mathbf{J}(\\xi, \\eta) = \\begin{pmatrix} 1 + 0.1\\,\\eta  0.1\\,\\xi \\\\ 0  1 + 0.4\\,\\eta \\end{pmatrix}\n$$\nThe determinant of the Jacobian matrix, denoted by $J(\\xi,\\eta)$, is calculated as:\n$$\nJ(\\xi,\\eta) = \\det(\\mathbf{J}(\\xi, \\eta)) = (1 + 0.1\\,\\eta)(1 + 0.4\\,\\eta) - (0.1\\,\\xi)(0)\n$$\nThus, the expression for the Jacobian determinant is:\n$$\nJ(\\xi,\\eta) = (1 + 0.1\\,\\eta)(1 + 0.4\\,\\eta)\n$$\nNext, we evaluate this determinant at the specified point $(\\xi, \\eta) = (0.5, -0.5)$.\nSubstituting $\\xi = 0.5$ and $\\eta = -0.5$:\n$$\nJ(0.5, -0.5) = \\big(1 + 0.1 \\times (-0.5)\\big) \\big(1 + 0.4 \\times (-0.5)\\big)\n$$\n$$\nJ(0.5, -0.5) = (1 - 0.05)(1 - 0.20)\n$$\n$$\nJ(0.5, -0.5) = (0.95)(0.80)\n$$\nTo find the exact value, we can use fractions: $0.95 = \\frac{95}{100} = \\frac{19}{20}$ and $0.80 = \\frac{80}{100} = \\frac{4}{5}$.\n$$\nJ(0.5, -0.5) = \\left(\\frac{19}{20}\\right) \\left(\\frac{4}{5}\\right) = \\frac{19 \\times 4}{20 \\times 5} = \\frac{19}{5 \\times 5} = \\frac{19}{25}\n$$\nThis exact value can also be expressed as the decimal $0.76$.\nThe value of the Jacobian determinant at the point is $J(0.5,-0.5) = 0.76$.\nThe absolute value is $|J(0.5, -0.5)| = |0.76| = 0.76$.\n\nThe interpretation of the Jacobian determinant comes from the change of variables theorem for multiple integrals. An infinitesimal area element $dA_{ref} = d\\xi\\,d\\eta$ in the reference space is mapped to an infinitesimal area element $dA_{phys} = dx\\,dy$ in the physical space, and their areas are related by:\n$$\ndA_{phys} = |J(\\xi,\\eta)| \\, dA_{ref}\n$$\nThe value $|J(\\xi,\\eta)|$ is therefore the local area scaling factor. At the point $(\\xi, \\eta) = (0.5, -0.5)$, the value is $|J| = 0.76$. This means that an infinitesimal area in the reference space around this point is transformed into an area in the physical space that is $0.76$ times as large. Since $|J|  1$, the mapping is a local compression of area. The sign of $J = 0.76$ is positive, which indicates that the mapping is orientation-preserving at this point.",
            "answer": "$$\n\\boxed{\\frac{19}{25}}\n$$"
        },
        {
            "introduction": "While the Jacobian determinant provides a scalar measure of area change, a full description of the mapping's geometry requires a tensorial framework. This practice  introduces the essential tools of differential geometry used in modern numerical methods: the covariant and contravariant basis vectors and the metric tensor. By calculating these quantities and relating them to the geometric anisotropy of the element, you will develop a deeper understanding of how element shape distortion is quantified and how it impacts the performance of numerical schemes.",
            "id": "3393851",
            "problem": "In high-order spectral element and discontinuous Galerkin (DG) methods, physical elements are mapped from a reference element with coordinates $(\\xi,\\eta)$ to physical space coordinates $\\boldsymbol{x}=(x,y)$ via a smooth mapping. Consider the two-dimensional mapping defined by\n$$\n\\boldsymbol{x}(\\xi,\\eta) = \\big(x(\\xi,\\eta),y(\\xi,\\eta)\\big) = \\big(\\,\\xi + \\alpha \\eta^{2},\\ \\eta\\,\\big),\n$$\nwhere $\\alpha \\in \\mathbb{R}$ is a given constant. Using only foundational definitions from differential geometry of mappings as employed in high-order methods, perform the following at the point $(\\xi,\\eta)=(0,1)$:\n\n1. Compute the covariant basis vectors $\\boldsymbol{a}_{1}$ and $\\boldsymbol{a}_{2}$, defined by $\\boldsymbol{a}_{i} = \\partial \\boldsymbol{x} / \\partial \\xi^{i}$ with $(\\xi^{1},\\xi^{2})=(\\xi,\\eta)$.\n2. Compute the metric tensor components $g_{ij}$, defined by $g_{ij} = \\boldsymbol{a}_{i} \\cdot \\boldsymbol{a}_{j}$.\n3. Compute the contravariant basis vectors $\\boldsymbol{a}^{1}$ and $\\boldsymbol{a}^{2}$, defined by the duality relations $\\boldsymbol{a}^{i} \\cdot \\boldsymbol{a}_{j} = \\delta^{i}_{\\ j}$.\n4. Using the definition that the anisotropy factor of the mapping at a point is the ratio of the largest to the smallest singular value of the Jacobian of the mapping at that point (equivalently, the square root of the spectral condition number of the metric tensor), derive an exact expression for the anisotropy factor as a function of $\\alpha$.\n\nBriefly interpret how the parameter $\\alpha$ influences the geometric anisotropy at the specified point, based on your computed quantities.\n\nReport as your final answer the exact closed-form expression you obtain for the anisotropy factor as a function of $\\alpha$. Do not round. Do not include units.",
            "solution": "The problem statement is parsed and validated as scientifically grounded, well-posed, and objective. It is based on standard definitions from differential geometry as applied to numerical methods for partial differential equations. All necessary information is provided, and the problem is mathematically solvable. We proceed with the solution.\n\nThe mapping from the reference coordinates $(\\xi, \\eta)$ to the physical coordinates $\\boldsymbol{x}=(x,y)$ is given by\n$$\n\\boldsymbol{x}(\\xi,\\eta) = \\big(x(\\xi,\\eta), y(\\xi,\\eta)\\big) = \\big(\\xi + \\alpha \\eta^{2}, \\eta\\big)\n$$\nwhere $\\alpha \\in \\mathbb{R}$ is a constant. We are asked to perform calculations at the point $(\\xi,\\eta)=(0,1)$.\n\n**1. Covariant Basis Vectors**\n\nThe covariant basis vectors, $\\boldsymbol{a}_{1}$ and $\\boldsymbol{a}_{2}$, are defined as the partial derivatives of the position vector $\\boldsymbol{x}$ with respect to the reference coordinates $\\xi^1 = \\xi$ and $\\xi^2 = \\eta$.\n\nThe vector $\\boldsymbol{a}_{1}$ is:\n$$\n\\boldsymbol{a}_{1} = \\frac{\\partial \\boldsymbol{x}}{\\partial \\xi} = \\left(\\frac{\\partial x}{\\partial \\xi}, \\frac{\\partial y}{\\partial \\xi}\\right) = \\left(\\frac{\\partial}{\\partial \\xi}(\\xi + \\alpha \\eta^2), \\frac{\\partial}{\\partial \\xi}(\\eta)\\right) = (1, 0)\n$$\nThis vector is constant throughout the domain.\n\nThe vector $\\boldsymbol{a}_{2}$ is:\n$$\n\\boldsymbol{a}_{2} = \\frac{\\partial \\boldsymbol{x}}{\\partial \\eta} = \\left(\\frac{\\partial x}{\\partial \\eta}, \\frac{\\partial y}{\\partial \\eta}\\right) = \\left(\\frac{\\partial}{\\partial \\eta}(\\xi + \\alpha \\eta^2), \\frac{\\partial}{\\partial \\eta}(\\eta)\\right) = (2\\alpha\\eta, 1)\n$$\nEvaluating these vectors at the specified point $(\\xi, \\eta) = (0, 1)$:\n$$\n\\boldsymbol{a}_{1}|_{(0,1)} = (1, 0)\n$$\n$$\n\\boldsymbol{a}_{2}|_{(0,1)} = (2\\alpha(1), 1) = (2\\alpha, 1)\n$$\n\n**2. Metric Tensor Components**\n\nThe components of the covariant metric tensor, $g_{ij}$, are defined by the dot products of the covariant basis vectors: $g_{ij} = \\boldsymbol{a}_{i} \\cdot \\boldsymbol{a}_{j}$. At the point $(0,1)$:\n\n$$\ng_{11} = \\boldsymbol{a}_{1} \\cdot \\boldsymbol{a}_{1} = (1, 0) \\cdot (1, 0) = 1^2 + 0^2 = 1\n$$\n$$\ng_{12} = \\boldsymbol{a}_{1} \\cdot \\boldsymbol{a}_{2} = (1, 0) \\cdot (2\\alpha, 1) = (1)(2\\alpha) + (0)(1) = 2\\alpha\n$$\n$$\ng_{21} = \\boldsymbol{a}_{2} \\cdot \\boldsymbol{a}_{1} = (2\\alpha, 1) \\cdot (1, 0) = (2\\alpha)(1) + (1)(0) = 2\\alpha\n$$\n$$\ng_{22} = \\boldsymbol{a}_{2} \\cdot \\boldsymbol{a}_{2} = (2\\alpha, 1) \\cdot (2\\alpha, 1) = (2\\alpha)^2 + 1^2 = 4\\alpha^2 + 1\n$$\nThe metric tensor $G$ at $(\\xi, \\eta) = (0,1)$ is the matrix with components $g_{ij}$:\n$$\nG = \\begin{pmatrix} g_{11}  g_{12} \\\\ g_{21}  g_{22} \\end{pmatrix} = \\begin{pmatrix} 1  2\\alpha \\\\ 2\\alpha  4\\alpha^2 + 1 \\end{pmatrix}\n$$\n\n**3. Contravariant Basis Vectors**\n\nThe contravariant basis vectors, $\\boldsymbol{a}^{1}$ and $\\boldsymbol{a}^{2}$, are defined by the duality relations $\\boldsymbol{a}^{i} \\cdot \\boldsymbol{a}_{j} = \\delta^{i}_{\\ j}$, where $\\delta^{i}_{\\ j}$ is the Kronecker delta. They can be computed using the components of the contravariant metric tensor $g^{ij}$, which are the entries of the inverse of the matrix $G$.\nFirst, we compute the determinant of $G$:\n$$\n\\det(G) = g_{11}g_{22} - g_{12}g_{21} = (1)(4\\alpha^2 + 1) - (2\\alpha)(2\\alpha) = 4\\alpha^2 + 1 - 4\\alpha^2 = 1\n$$\nThe inverse matrix $G^{-1} = [g^{ij}]$ is:\n$$\nG^{-1} = \\frac{1}{\\det(G)} \\begin{pmatrix} g_{22}  -g_{12} \\\\ -g_{21}  g_{11} \\end{pmatrix} = \\frac{1}{1} \\begin{pmatrix} 4\\alpha^2 + 1  -2\\alpha \\\\ -2\\alpha  1 \\end{pmatrix} = \\begin{pmatrix} 4\\alpha^2 + 1  -2\\alpha \\\\ -2\\alpha  1 \\end{pmatrix}\n$$\nThe contravariant basis vectors are related to the covariant ones by $\\boldsymbol{a}^i = \\sum_{j=1}^2 g^{ij}\\boldsymbol{a}_j$:\n$$\n\\boldsymbol{a}^{1} = g^{11}\\boldsymbol{a}_{1} + g^{12}\\boldsymbol{a}_{2} = (4\\alpha^2+1)(1,0) + (-2\\alpha)(2\\alpha,1) = (4\\alpha^2+1-4\\alpha^2, -2\\alpha) = (1, -2\\alpha)\n$$\n$$\n\\boldsymbol{a}^{2} = g^{21}\\boldsymbol{a}_{1} + g^{22}\\boldsymbol{a}_{2} = (-2\\alpha)(1,0) + (1)(2\\alpha,1) = (-2\\alpha+2\\alpha, 1) = (0, 1)\n$$\n\n**4. Anisotropy Factor**\n\nThe anisotropy factor is defined as the ratio of the largest to the smallest singular value of the Jacobian of the mapping, $\\sigma_{\\max}/\\sigma_{\\min}$. This is equivalent to the square root of the spectral condition number of the metric tensor $G=J^T J$, where $J$ is the Jacobian matrix. The spectral condition number is $\\kappa_2(G) = \\lambda_{\\max}/\\lambda_{\\min}$, where $\\lambda_{\\max}$ and $\\lambda_{\\min}$ are the largest and smallest eigenvalues of $G$. Thus, the anisotropy factor is $\\sqrt{\\lambda_{\\max}/\\lambda_{\\min}}$.\n\nThe eigenvalues $\\lambda$ of $G$ are the roots of the characteristic equation $\\det(G - \\lambda I) = 0$:\n$$\n\\det \\begin{pmatrix} 1-\\lambda  2\\alpha \\\\ 2\\alpha  4\\alpha^2 + 1 - \\lambda \\end{pmatrix} = (1-\\lambda)(4\\alpha^2 + 1 - \\lambda) - (2\\alpha)^2 = 0\n$$\n$$\n\\lambda^2 - (4\\alpha^2 + 2)\\lambda + (4\\alpha^2 + 1) - 4\\alpha^2 = 0\n$$\n$$\n\\lambda^2 - (4\\alpha^2 + 2)\\lambda + 1 = 0\n$$\nUsing the quadratic formula for $\\lambda$:\n$$\n\\lambda = \\frac{(4\\alpha^2 + 2) \\pm \\sqrt{(4\\alpha^2 + 2)^2 - 4(1)(1)}}{2}\n$$\n$$\n\\lambda = \\frac{4\\alpha^2 + 2 \\pm \\sqrt{16\\alpha^4 + 16\\alpha^2 + 4 - 4}}{2} = \\frac{4\\alpha^2 + 2 \\pm \\sqrt{16\\alpha^4 + 16\\alpha^2}}{2}\n$$\n$$\n\\lambda = \\frac{4\\alpha^2 + 2 \\pm \\sqrt{16\\alpha^2(\\alpha^2 + 1)}}{2} = \\frac{4\\alpha^2 + 2 \\pm 4|\\alpha|\\sqrt{\\alpha^2+1}}{2}\n$$\nThe two eigenvalues are:\n$$\n\\lambda_{\\max} = 2\\alpha^2 + 1 + 2|\\alpha|\\sqrt{\\alpha^2+1}\n$$\n$$\n\\lambda_{\\min} = 2\\alpha^2 + 1 - 2|\\alpha|\\sqrt{\\alpha^2+1}\n$$\nWe notice that the product of the eigenvalues is $\\lambda_{\\max}\\lambda_{\\min} = \\frac{c}{a} = 1$. This is consistent with our earlier finding that $\\det(G)=1$, as the determinant is the product of eigenvalues.\n\nThe anisotropy factor is $\\sqrt{\\lambda_{\\max}/\\lambda_{\\min}}$. Since $\\lambda_{\\min} = 1/\\lambda_{\\max}$, we can simplify this expression:\n$$\n\\text{Anisotropy Factor} = \\sqrt{\\frac{\\lambda_{\\max}}{1/\\lambda_{\\max}}} = \\sqrt{\\lambda_{\\max}^2} = \\lambda_{\\max}\n$$\n(We take the positive root as eigenvalues of the positive-definite matrix $G$ are positive, and thus $\\lambda_{\\max} > 0$).\nTherefore, the exact expression for the anisotropy factor as a function of $\\alpha$ is:\n$$\n\\text{Anisotropy Factor} = 2\\alpha^2 + 1 + 2|\\alpha|\\sqrt{\\alpha^2+1}\n$$\n\n**Interpretation:**\nThe parameter $\\alpha$ controls the shear in the mapping. When $\\alpha=0$, the mapping is the identity, the covariant basis vectors $\\boldsymbol{a}_1=(1,0)$ and $\\boldsymbol{a}_2=(0,1)$ are orthogonal and of unit length, the metric tensor is the identity, and the anisotropy factor is $2(0)^2+1+0 = 1$. A factor of $1$ signifies an isotropic mapping with no distortion. As $|\\alpha|$ increases, the angle between the basis vectors $\\boldsymbol{a}_1$ and $\\boldsymbol{a}_2=(2\\alpha,1)$ deviates from $90^\\circ$, and the length of $\\boldsymbol{a}_2$ increases. This geometric distortion is quantified by the anisotropy factor, which increases monotonically with $|\\alpha|$. A large anisotropy factor indicates a highly distorted element, which can degrade the accuracy and stability of numerical simulations.",
            "answer": "$$\n\\boxed{2\\alpha^2 + 1 + 2|\\alpha|\\sqrt{\\alpha^2+1}}\n$$"
        },
        {
            "introduction": "A crucial property for any robust numerical scheme on curvilinear grids is \"free-stream preservation\"—the ability to maintain a constant flow without generating artificial sources or sinks. This property hinges on satisfying a discrete version of a continuous metric identity, known as the Geometric Conservation Law (GCL). This exercise  provides a powerful demonstration of this principle by asking you to analyze a scheme where the GCL is intentionally violated, allowing you to analytically compute the spurious residual that arises and thereby appreciate the necessity of conservative metric approximations.",
            "id": "3393877",
            "problem": "Consider a two-dimensional nodal spectral element discretization on the reference square $\\hat{\\Omega} = [-1,1] \\times [-1,1]$ with a tensor-product Gauss–Lobatto–Legendre (GLL) grid of polynomial degree $N=2$. The nodes in each coordinate are $s \\in \\{-1,0,1\\}$ and $r \\in \\{-1,0,1\\}$, and the associated one-dimensional GLL differentiation matrix is\n$$\nD \\;=\\;\n\\begin{pmatrix}\n-\\tfrac{3}{2}  2  -\\tfrac{1}{2} \\\\[4pt]\n-\\tfrac{1}{2}  0  \\tfrac{1}{2} \\\\[4pt]\n\\tfrac{1}{2}  -2  \\tfrac{3}{2}\n\\end{pmatrix}.\n$$\nLet the curvilinear mapping from reference coordinates $(r,s)$ to physical coordinates $(x,y)$ be\n$$\nx(r,s) \\;=\\; r \\;+\\; r\\,s^{2}, \n\\qquad\ny(r,s) \\;=\\; s.\n$$\nAdopt the standard covariant base vectors $\\mathbf{a}_{r} = \\partial \\mathbf{x}/\\partial r$ and $\\mathbf{a}_{s} = \\partial \\mathbf{x}/\\partial s$, the Jacobian determinant $J = \\det[\\mathbf{a}_{r}\\ \\mathbf{a}_{s}]$, and the contravariant metric vectors $J\\,\\mathbf{a}^{r}$ and $J\\,\\mathbf{a}^{s}$ defined by the planar $90^{\\circ}$ rotation of the covariant base vectors:\n$$\nJ\\,\\mathbf{a}^{r} \\;=\\; \\big(a_{s,y},\\,-a_{s,x}\\big),\n\\qquad\nJ\\,\\mathbf{a}^{s} \\;=\\; \\big(-a_{r,y},\\,a_{r,x}\\big),\n$$\nwhere $\\mathbf{a}_{r}=(a_{r,x},a_{r,y})$ and $\\mathbf{a}_{s}=(a_{s,x},a_{s,y})$. For this mapping, the exact $y$-components of the contravariant metric vectors are\n$$\nG^{r}_{y}(r,s) \\;=\\; -\\,2\\,r\\,s,\n\\qquad\nG^{s}_{y}(r,s) \\;=\\; 1 \\;+\\; s^{2}.\n$$\nThese satisfy the continuous metric identity $\\partial_{r} G^{r}_{y} + \\partial_{s} G^{s}_{y} = 0$.\n\nNow construct a discrete metric approximation that violates the metric identity by defining the $y$-component of $J\\,\\mathbf{a}^{s}$ via a degree-one interpolation in the $s$-direction using only the endpoint nodes $s=\\pm 1$:\n$$\n\\tilde{G}^{s}_{y}(r,s) \\;:=\\; I_{1}\\big[\\,1+s^{2}\\,\\big](s)\n\\;=\\; \\tfrac{1+s}{2}\\big(1+1^{2}\\big) \\;+\\; \\tfrac{1-s}{2}\\big(1+(-1)^{2}\\big)\n\\;=\\; 2,\n$$\nso that $\\tilde{G}^{s}_{y}$ is constant in $s$. Keep $G^{r}_{y}$ exact at the nodes.\n\nConsider mapped linear advection of a constant solution $u(r,s)\\equiv u_{0}$ with a constant physical advection velocity $\\mathbf{a}=(0,1)$. In strong form, the semi-discrete volume residual at a node $(r_{i},s_{j})$ is computed by applying the tensor-product differentiation operators to the mapped contravariant flux components\n$$\n\\phi^{r}(r_{i},s_{j}) \\;=\\; u_{0}\\,G^{r}_{y}(r_{i},s_{j}), \n\\qquad\n\\phi^{s}(r_{i},s_{j}) \\;=\\; u_{0}\\,\\tilde{G}^{s}_{y}(r_{i},s_{j}),\n$$\nnamely\n$$\n\\mathcal{R}_{ij} \\;=\\; \\sum_{k=1}^{3} D_{ik}\\,\\phi^{r}(r_{k},s_{j}) \\;+\\; \\sum_{\\ell=1}^{3} D_{j\\ell}\\,\\phi^{s}(r_{i},s_{\\ell}).\n$$\n\nUsing $u_{0}=1$, evaluate the semi-discrete volume residual $\\mathcal{R}_{ij}$ at the nodal point $(r_{i},s_{j})=(0,1)$. Provide the final answer as a single real number. No rounding is required.",
            "solution": "The problem is valid. The setup is self-contained, scientifically sound within the domain of numerical analysis for partial differential equations, and well-posed. All necessary data and definitions for the calculation are provided.\n\nThe objective is to compute the semi-discrete volume residual $\\mathcal{R}_{ij}$ at the nodal point $(r_{i},s_{j})=(0,1)$. The nodal grid points for polynomial degree $N=2$ are $r, s \\in \\{-1, 0, 1\\}$. We can index these as $r_1=-1$, $r_2=0$, $r_3=1$ and $s_1=-1$, $s_2=0$, $s_3=1$. The target node $(r,s)=(0,1)$ thus corresponds to the indices $(i,j)=(2,3)$.\n\nThe formula for the semi-discrete volume residual at node $(r_i, s_j)$ is given by:\n$$\n\\mathcal{R}_{ij} \\;=\\; \\sum_{k=1}^{3} D_{ik}\\,\\phi^{r}(r_{k},s_{j}) \\;+\\; \\sum_{\\ell=1}^{3} D_{j\\ell}\\,\\phi^{s}(r_{i},s_{\\ell})\n$$\nWe need to evaluate this for $(i,j)=(2,3)$:\n$$\n\\mathcal{R}_{23} \\;=\\; \\sum_{k=1}^{3} D_{2k}\\,\\phi^{r}(r_{k},s_{3}) \\;+\\; \\sum_{\\ell=1}^{3} D_{3\\ell}\\,\\phi^{s}(r_{2},s_{\\ell})\n$$\nThe calculation is split into two parts.\n\nPart 1: The derivative in the $r$-direction.\nThis term is the first summation: $\\sum_{k=1}^{3} D_{2k}\\,\\phi^{r}(r_{k},s_{3})$. This corresponds to applying the second row of the differentiation matrix $D$ to the vector of flux values $\\phi^r$ evaluated along the line where $s=s_3=1$.\nThe second row of the differentiation matrix $D$ is given as $(D_{21}, D_{22}, D_{23}) = (-\\frac{1}{2}, 0, \\frac{1}{2})$.\nThe contravariant flux component $\\phi^r$ is defined as $\\phi^{r}(r,s) = u_{0}\\,G^{r}_{y}(r,s)$. With $u_0=1$ and the exact metric component $G^{r}_{y}(r,s) = -2rs$, the flux becomes $\\phi^{r}(r,s) = -2rs$.\nWe evaluate this flux at $s_j=s_3=1$ for each of the $r$-nodes $r_k \\in \\{-1, 0, 1\\}$:\n\\begin{itemize}\n    \\item For $k=1$, $r_1=-1$: $\\phi^{r}(r_{1},s_{3}) = \\phi^{r}(-1,1) = -2(-1)(1) = 2$.\n    \\item For $k=2$, $r_2=0$: $\\phi^{r}(r_{2},s_{3}) = \\phi^{r}(0,1) = -2(0)(1) = 0$.\n    \\item For $k=3$, $r_3=1$: $\\phi^{r}(r_{3},s_{3}) = \\phi^{r}(1,1) = -2(1)(1) = -2$.\n\\end{itemize}\nThe first term of the residual is the dot product of the second row of $D$ and the vector of flux values $(\\phi^{r}(-1,1), \\phi^{r}(0,1), \\phi^{r}(1,1))$:\n$$\n\\sum_{k=1}^{3} D_{2k}\\,\\phi^{r}(r_{k},s_{3}) = D_{21}\\phi^{r}(r_1,s_3) + D_{22}\\phi^{r}(r_2,s_3) + D_{23}\\phi^{r}(r_3,s_3)\n= \\left(-\\frac{1}{2}\\right)(2) \\;+\\; (0)(0) \\;+\\; \\left(\\frac{1}{2}\\right)(-2) = -1 - 1 = -2.\n$$\n\nPart 2: The derivative in the $s$-direction.\nThis term is the second summation: $\\sum_{\\ell=1}^{3} D_{3\\ell}\\,\\phi^{s}(r_{2},s_{\\ell})$. This corresponds to applying the third row of the differentiation matrix $D$ to the vector of flux values $\\phi^s$ evaluated along the line where $r=r_2=0$.\nThe third row of the differentiation matrix $D$ is given as $(D_{31}, D_{32}, D_{33}) = (\\frac{1}{2}, -2, \\frac{3}{2})$.\nThe contravariant flux component $\\phi^s$ is defined using the approximated metric, $\\phi^{s}(r,s) = u_{0}\\,\\tilde{G}^{s}_{y}(r,s)$. With $u_0=1$ and the given approximation $\\tilde{G}^{s}_{y}(r,s) = 2$, the flux becomes $\\phi^{s}(r,s) = 2$.\nThis flux is constant. We evaluate it at $r_i=r_2=0$ for each of the $s$-nodes $s_\\ell \\in \\{-1, 0, 1\\}$:\n\\begin{itemize}\n    \\item For $\\ell=1$, $s_1=-1$: $\\phi^{s}(r_{2},s_{1}) = \\phi^{s}(0,-1) = 2$.\n    \\item For $\\ell=2$, $s_2=0$: $\\phi^{s}(r_{2},s_{2}) = \\phi^{s}(0,0) = 2$.\n    \\item For $\\ell=3$, $s_3=1$: $\\phi^{s}(r_{2},s_{3}) = \\phi^{s}(0,1) = 2$.\n\\end{itemize}\nThe second term of the residual is the dot product of the third row of $D$ and the vector of flux values $(\\phi^{s}(0,-1), \\phi^{s}(0,0), \\phi^{s}(0,1))$:\n$$\n\\sum_{\\ell=1}^{3} D_{3\\ell}\\,\\phi^{s}(r_{2},s_{\\ell}) = D_{31}\\phi^{s}(r_2,s_1) + D_{32}\\phi^{s}(r_2,s_2) + D_{33}\\phi^{s}(r_2,s_3)\n= \\left(\\frac{1}{2}\\right)(2) \\;+\\; (-2)(2) \\;+\\; \\left(\\frac{3}{2}\\right)(2) = 1 - 4 + 3 = 0.\n$$\nThis result is expected, as differentiation of a constant function by a consistent discrete operator yields zero. The sum of the elements in any row of the GLL differentiation matrix is zero, which ensures this property.\n\nFinally, we sum the two parts to get the total residual $\\mathcal{R}_{23}$:\n$$\n\\mathcal{R}_{23} = (-2) + (0) = -2.\n$$\nThe non-zero residual indicates that the chosen discrete approximation of the metric factors violates the discrete Geometric Conservation Law (GCL), leading to spurious source terms even for a constant solution.",
            "answer": "$$\\boxed{-2}$$"
        }
    ]
}