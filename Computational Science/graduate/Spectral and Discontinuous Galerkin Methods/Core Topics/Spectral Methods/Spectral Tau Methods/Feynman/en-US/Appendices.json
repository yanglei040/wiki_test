{
    "hands_on_practices": [
        {
            "introduction": "The elegance of the spectral Tau method lies in its unique approach to enforcing boundary conditions. Instead of modifying the basis functions, it adjusts the highest-order spectral coefficients of the solution to satisfy the constraints exactly. This analytical exercise invites you to dissect this core mechanism by deriving from first principles how the boundary data \"contaminates\" the spectrum of the numerical solution . By working through this problem, you will gain a fundamental, quantitative understanding of how the Tau method operates at the level of spectral coefficients.",
            "id": "3419545",
            "problem": "Consider the Spectral Tau method (also known as the Tau method in spectral approximations) for a scalar boundary-value problem posed on the interval $[-1,1]$ using the Legendre polynomial basis $\\{P_{n}(x)\\}_{n=0}^{\\infty}$. Let the target function be the analytic function\n$$\nu(x) \\;=\\; \\frac{1}{\\sqrt{\\,1 \\;-\\; 2 t x \\;+\\; t^{2}\\,}},\n$$\nwith a real parameter $t$ satisfying $|t|<1$. The identity operator $L u = u$ is used so that the interior residual equation is $u_{N}(x) \\approx u(x)$ in the Legendre-weighted sense, while nonhomogeneous Dirichlet boundary conditions $u(-1)=A$ and $u(1)=B$ are enforced exactly via two Tau rows. The Spectral Tau approximation is sought in the form\n$$\nu_{N}(x) \\;=\\; \\sum_{n=0}^{N} a_{n}^{(N)}\\,P_{n}(x).\n$$\nThe Tau discretization proceeds by enforcing the weighted residual conditions\n$$\n\\int_{-1}^{1} P_{n}(x)\\,\\big(u_{N}(x) - u(x)\\big)\\,dx \\;=\\; 0,\\quad n=0,1,\\dots,N-2,\n$$\nand replacing the last two equations by the nonhomogeneous boundary conditions\n$$\nu_{N}(-1) \\;=\\; u(-1),\\qquad u_{N}(1) \\;=\\; u(1).\n$$\nThis construction makes the top two coefficients $a_{N-1}^{(N)}$ and $a_{N}^{(N)}$ deviate from the true Legendre coefficients of $u$ in order to enforce the boundary values; this is the boundary-data contamination induced by the Tau rows. Using only first principles about orthogonality of Legendre polynomials and the endpoint values $P_{n}(\\pm 1)$, determine closed-form expressions for the contaminated coefficients $a_{N-1}^{(N)}$ and $a_{N}^{(N)}$ as functions of $t$ and $N$. Your final answers must be analytic expressions, and no rounding is required. In addition, from these expressions, infer whether the contaminated modes decay or grow with increasing $N$, but ensure your submitted final answer contains only the expressions for $a_{N-1}^{(N)}$ and $a_{N}^{(N)}$.",
            "solution": "The problem asks for the determination of the two highest-degree coefficients, $a_{N-1}^{(N)}$ and $a_N^{(N)}$, in a Spectral Tau approximation of a given function $u(x)$. The approximation $u_N(x)$ is constructed to satisfy a set of weighted residual equations and two boundary conditions exactly.\n\nThe target function is given by\n$$u(x) = \\frac{1}{\\sqrt{1 - 2tx + t^2}}, \\quad |t|<1.$$\nThis function is the generating function for the Legendre polynomials, $P_n(x)$. Its expansion in the Legendre basis is known to be\n$$u(x) = \\sum_{n=0}^{\\infty} t^n P_n(x).$$\nThe true Legendre coefficients of $u(x)$, which we may denote as $c_n$, are therefore given by $c_n = t^n$.\n\nThe Spectral Tau approximation is sought in the form\n$$u_N(x) = \\sum_{n=0}^{N} a_n^{(N)} P_n(x).$$\nThe coefficients $a_n^{(N)}$ are determined by a system of $N+1$ linear equations. For $n=0, 1, \\dots, N-2$, the equations are given by the weighted residual conditions:\n$$\\int_{-1}^{1} P_n(x) \\big(u_N(x) - u(x)\\big) dx = 0.$$\nLet's substitute the series expansions for $u_N(x)$ and $u(x)$ into this integral expression:\n$$\\int_{-1}^{1} P_n(x) \\left( \\sum_{k=0}^{N} a_k^{(N)} P_k(x) - \\sum_{k=0}^{\\infty} t^k P_k(x) \\right) dx = 0.$$\nDue to the orthogonality property of Legendre polynomials, $\\int_{-1}^{1} P_n(x) P_k(x) dx = \\frac{2}{2n+1}\\delta_{nk}$, where $\\delta_{nk}$ is the Kronecker delta, the integral simplifies significantly. For a given $n \\in \\{0, 1, \\dots, N-2\\}$, the integral picks out only the terms where $k=n$:\n$$a_n^{(N)} \\int_{-1}^{1} P_n(x)^2 dx - t^n \\int_{-1}^{1} P_n(x)^2 dx = 0.$$\nThis simplifies to $(a_n^{(N)} - t^n) \\frac{2}{2n+1} = 0$, which implies\n$$a_n^{(N)} = t^n \\quad \\text{for } n = 0, 1, \\dots, N-2.$$\nThus, the lower-order coefficients of the Tau approximation are identical to the true Legendre coefficients of the function $u(x)$. The \"contamination\" from enforcing the boundary conditions affects only the coefficients not constrained by orthogonality, namely $a_{N-1}^{(N)}$ and $a_N^{(N)}$.\n\nTo find these two remaining coefficients, we use the two boundary conditions, which are enforced exactly:\n$$u_N(-1) = u(-1) \\quad \\text{and} \\quad u_N(1) = u(1).$$\nWe first evaluate the true function $u(x)$ at the boundaries $x=\\pm 1$:\n$$u(1) = \\frac{1}{\\sqrt{1 - 2t + t^2}} = \\frac{1}{\\sqrt{(1-t)^2}} = \\frac{1}{|1-t|} = \\frac{1}{1-t}, \\quad \\text{since } |t|<1.$$\n$$u(-1) = \\frac{1}{\\sqrt{1 + 2t + t^2}} = \\frac{1}{\\sqrt{(1+t)^2}} = \\frac{1}{|1+t|} = \\frac{1}{1+t}, \\quad \\text{since } |t|<1.$$\nNext, we evaluate the approximation $u_N(x)$ at the boundaries, using the known properties $P_n(1)=1$ and $P_n(-1)=(-1)^n$:\n$$u_N(1) = \\sum_{n=0}^{N} a_n^{(N)} P_n(1) = \\sum_{n=0}^{N} a_n^{(N)}.$$\n$$u_N(-1) = \\sum_{n=0}^{N} a_n^{(N)} P_n(-1) = \\sum_{n=0}^{N} a_n^{(N)} (-1)^n.$$\nEquating the approximation to the true function at the boundaries gives the system:\n1.  $\\sum_{n=0}^{N} a_n^{(N)} = u(1) = \\frac{1}{1-t} = \\sum_{n=0}^{\\infty} t^n$.\n2.  $\\sum_{n=0}^{N} a_n^{(N)} (-1)^n = u(-1) = \\frac{1}{1+t} = \\sum_{n=0}^{\\infty} (-t)^n$.\n\nLet's expand the sums for the Tau approximation, substituting $a_n^{(N)} = t^n$ for $n \\le N-2$:\n1.  $\\sum_{n=0}^{N-2} t^n + a_{N-1}^{(N)} + a_N^{(N)} = \\sum_{n=0}^{\\infty} t^n = \\sum_{n=0}^{N-2} t^n + \\sum_{n=N-1}^{\\infty} t^n$.\n    Subtracting the common partial sum from both sides yields:\n    $$a_{N-1}^{(N)} + a_N^{(N)} = \\sum_{n=N-1}^{\\infty} t^n = t^{N-1} + t^N + t^{N+1} + \\dots$$\n    This is a geometric series with first term $t^{N-1}$ and ratio $t$. Its sum is $\\frac{t^{N-1}}{1-t}$.\n    So, our first equation is: $a_{N-1}^{(N)} + a_N^{(N)} = \\frac{t^{N-1}}{1-t}$.\n\n2.  $\\sum_{n=0}^{N-2} t^n (-1)^n + a_{N-1}^{(N)} (-1)^{N-1} + a_N^{(N)} (-1)^N = \\sum_{n=0}^{\\infty} (-t)^n = \\sum_{n=0}^{N-2} (-t)^n + \\sum_{n=N-1}^{\\infty} (-t)^n$.\n    Subtracting the common partial sum from both sides yields:\n    $$a_{N-1}^{(N)} (-1)^{N-1} + a_N^{(N)} (-1)^N = \\sum_{n=N-1}^{\\infty} (-t)^n = \\frac{(-t)^{N-1}}{1-(-t)} = \\frac{(-1)^{N-1} t^{N-1}}{1+t}.$$\n    Dividing the entire equation by $(-1)^{N-1}$ gives:\n    $$a_{N-1}^{(N)} - a_N^{(N)} = \\frac{t^{N-1}}{1+t}.$$\n\nWe now have a $2 \\times 2$ linear system for $a_{N-1}^{(N)}$ and $a_N^{(N)}$:\n$$\n\\begin{cases}\n    a_{N-1}^{(N)} + a_N^{(N)} = \\frac{t^{N-1}}{1-t} \\\\\n    a_{N-1}^{(N)} - a_N^{(N)} = \\frac{t^{N-1}}{1+t}\n\\end{cases}\n$$\nTo solve for $a_{N-1}^{(N)}$, we add the two equations:\n$$2 a_{N-1}^{(N)} = \\frac{t^{N-1}}{1-t} + \\frac{t^{N-1}}{1+t} = t^{N-1} \\left( \\frac{(1+t) + (1-t)}{(1-t)(1+t)} \\right) = t^{N-1} \\left( \\frac{2}{1-t^2} \\right).$$\n$$a_{N-1}^{(N)} = \\frac{t^{N-1}}{1-t^2}.$$\nTo solve for $a_N^{(N)}$, we subtract the second equation from the first:\n$$2 a_N^{(N)} = \\frac{t^{N-1}}{1-t} - \\frac{t^{N-1}}{1+t} = t^{N-1} \\left( \\frac{(1+t) - (1-t)}{(1-t)(1+t)} \\right) = t^{N-1} \\left( \\frac{2t}{1-t^2} \\right).$$\n$$a_N^{(N)} = \\frac{t^N}{1-t^2}.$$\nThese are the closed-form expressions for the contaminated coefficients. The true coefficients are $c_{N-1} = t^{N-1}$ and $c_N = t^N$. The contamination manifests as a multiplicative factor of $\\frac{1}{1-t^2}$, which is constant with respect to $N$.\n\nRegarding the behavior for large $N$: since $|t|<1$, the terms $|t|^{N-1}$ and $|t|^N$ both decay to zero as $N \\to \\infty$. Therefore, the contaminated coefficients $a_{N-1}^{(N)}$ and $a_N^{(N)}$ decay to zero, ensuring convergence of the spectral approximation's coefficients.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{t^{N-1}}{1-t^2} & \\frac{t^N}{1-t^2}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Moving from analytical insight to practical implementation, we now tackle the discretization of a boundary value problem. This practice guides you through the construction of the full linear system that arises from a Legendre-Tau method for the Poisson equation . You will discover that the resulting system matrix is typically dense and ill-conditioned, posing a significant challenge for iterative solvers. By implementing and comparing different preconditioning strategies, you will develop essential skills for building efficient and robust spectral solvers.",
            "id": "3419514",
            "problem": "Consider the spectral Tau method for the linear boundary value problem on the interval $[-1,1]$:\n$$\n- u''(x) = f(x), \\quad x \\in (-1,1), \\qquad u(-1) = 0, \\quad u(1) = 0,\n$$\nwhere $u(x)$ is approximated by a truncated Legendre series $u_N(x) = \\sum_{k=0}^{N} a_k P_k(x)$, with $P_k(x)$ denoting the Legendre polynomial of degree $k$. Let $\\{P_k(x)\\}_{k=0}^\\infty$ be the classical orthogonal polynomial family on $[-1,1]$ with unit weight, satisfying\n$$\n\\int_{-1}^{1} P_i(x) P_j(x)\\, dx = \\frac{2}{2i+1} \\delta_{ij}.\n$$\nThe spectral Tau method enforces the differential equation in a weak sense for the first $N-1$ Legendre test functions and imposes the two boundary conditions by replacing the last two equations. Specifically, define the $(N+1)\\times(N+1)$ Tau matrix $A$ as follows:\n- For interior indices $i = 0,1,\\dots,N-2$, the row corresponds to the weak form of $-u''(x)$ projected onto $P_i(x)$:\n$$\n\\int_{-1}^{1} P_i(x)\\big(-u''(x)\\big)\\, dx = \\int_{-1}^{1} P_i(x) f(x)\\, dx.\n$$\n- The last two rows enforce the Dirichlet boundary conditions:\n$$\n\\sum_{k=0}^{N} a_k P_k(-1) = 0 \\quad \\text{and} \\quad \\sum_{k=0}^{N} a_k P_k(1) = 0.\n$$\nFor a Legendre-series representation $v(x) = \\sum_{k=0}^{N} c_k P_k(x)$, its second derivative $v''(x)$ has a Legendre-series representation with coefficients obtained by applying the Legendre-series differentiation operator twice. If $v''(x) = \\sum_{i=0}^{N-2} d_i P_i(x)$, then the weak projection onto $P_i(x)$ is\n$$\n\\int_{-1}^{1} P_i(x) v''(x)\\, dx = \\frac{2}{2i+1} d_i.\n$$\nUsing these facts, the interior rows of the Tau matrix are linear in the modal coefficients $a_k$ through the Legendre-series second derivative operator.\n\nPreconditioning is often required to improve the conditioning of the Tau matrix and the robustness of iterative solvers. In this task, you will construct $A$ and evaluate two left preconditioning strategies:\n1. Row $2$-norm scaling preconditioner, which scales each row $A_{i,:}$ by the reciprocal of its Euclidean norm, i.e., $M_{\\text{row}}^{-1} = \\operatorname{diag}\\left( \\frac{1}{\\|A_{i,:}\\|_2} \\right)$.\n2. Legendre weight normalization preconditioner, which scales the interior rows by the Legendre inner-product weight and leaves the boundary rows unchanged, i.e.,\n$M_{\\text{w}}^{-1} = \\operatorname{diag}\\left( \\frac{2i+1}{2} \\text{ for } i=0,\\dots,N-2; \\; 1, \\; 1 \\right)$.\n\nStarting from the orthogonality of Legendre polynomials and the definition of the spectral Tau method, derive the construction of the Tau matrix $A$ and the right-hand side vector $b$ for a given Legendre-series forcing $f(x) = \\sum_{k=0}^{N-2} \\hat{f}_k P_k(x)$, where\n$b_i = \\int_{-1}^{1} P_i(x) f(x)\\, dx = \\frac{2}{2i+1} \\hat{f}_i, \\quad i=0,\\dots,N-2, \\qquad b_{N-1} = 0, \\quad b_N = 0$.\nImplement a complete, runnable program that:\n- Constructs the Legendre-series second derivative operator applied to modal coefficients, by using Legendre-series differentiation twice.\n- Assembles the Tau matrix $A$ for given $N$.\n- Assembles the right-hand side $b$ for given Legendre forcing coefficients $\\hat{f}_k$.\n- Forms the preconditioned matrices $A_{\\text{row}} = M_{\\text{row}}^{-1} A$ and $A_{\\text{w}} = M_{\\text{w}}^{-1} A$ and the preconditioned right-hand sides $b_{\\text{row}} = M_{\\text{row}}^{-1} b$ and $b_{\\text{w}} = M_{\\text{w}}^{-1} b$.\n- Computes the $2$-norm condition numbers $\\kappa_2(A)$, $\\kappa_2(A_{\\text{row}})$, and $\\kappa_2(A_{\\text{w}})$.\n- Computes the relative residual norms after one Richardson iteration step from the zero initial guess for each system $A x = b$, $A_{\\text{row}} x = b_{\\text{row}}$, and $A_{\\text{w}} x = b_{\\text{w}}$, taking $x^{(1)} = b$, $x^{(1)}_{\\text{row}} = b_{\\text{row}}$, and $x^{(1)}_{\\text{w}} = b_{\\text{w}}$, and reporting\n$$\n\\rho_{\\text{none}} = \\frac{\\| b - A x^{(1)} \\|_2}{\\| b \\|_2}, \\quad \\rho_{\\text{row}} = \\frac{\\| b - A x^{(1)}_{\\text{row}} \\|_2}{\\| b \\|_2}, \\quad \\rho_{\\text{w}} = \\frac{\\| b - A x^{(1)}_{\\text{w}} \\|_2}{\\| b \\|_2}.\n$$\n\nUse the following test suite of parameter values to exercise different behaviors of the method:\n- Test case 1 (boundary-dominated, minimal size): $N = 2$ and $f(x) = P_0(x)$, that is $\\hat{f}_0 = 1$ and $\\hat{f}_k = 0$ for $k \\ge 1$.\n- Test case 2 (moderate size, sparse forcing): $N = 16$ and $f(x) = P_2(x) + 0.5\\, P_5(x) + 0.1\\, P_{12}(x)$, that is $\\hat{f}_2 = 1$, $\\hat{f}_5 = 0.5$, $\\hat{f}_{12} = 0.1$, all other $\\hat{f}_k = 0$.\n- Test case 3 (large size, alternating decaying forcing): $N = 48$ and $\\hat{f}_k = \\frac{(-1)^k}{k+1}$ for $k = 0,1,\\dots,N-2$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sublist with the six floating-point numbers\n$$\n[\\kappa_2(A), \\; \\kappa_2(A_{\\text{row}}), \\; \\kappa_2(A_{\\text{w}}), \\; \\rho_{\\text{none}}, \\; \\rho_{\\text{row}}, \\; \\rho_{\\text{w}}].\n$$\nFor example, the output must look like\n$$\n\\big[ [\\text{t1\\_kA},\\text{t1\\_kRow},\\text{t1\\_kW},\\text{t1\\_rhoNone},\\text{t1\\_rhoRow},\\text{t1\\_rhoW}], [\\text{t2\\_kA},\\dots], [\\text{t3\\_kA},\\dots] \\big],\n$$\nwith no additional text. Angles are not involved, and there are no physical units; all numerical answers must be reported as plain floating-point numbers in the specified format.",
            "solution": "The problem is to solve $-u''(x) = f(x)$ on the interval $[-1, 1]$ with homogeneous Dirichlet boundary conditions $u(-1) = 0$ and $u(1) = 0$. The solution $u(x)$ is approximated by a degree-$N$ polynomial $u_N(x) = \\sum_{k=0}^{N} a_k P_k(x)$, where $P_k(x)$ are the Legendre polynomials. The goal is to determine the coefficients $a_k$.\n\nThe spectral Tau method generates a system of linear equations, $A\\vec{a} = \\vec{b}$, for the coefficient vector $\\vec{a} = [a_0, a_1, \\dots, a_N]^T$. We will construct the $(N+1) \\times (N+1)$ matrix $A$ and the right-hand side vector $\\vec{b}$ of size $N+1$.\n\n**1. Legendre Series Differentiation**\n\nA critical component is the operator that maps the Legendre coefficients of a function $v(x)$ to the coefficients of its derivative $v'(x)$. Let $v(x) = \\sum_{k=0}^{N} c_k P_k(x)$ and its derivative be $v'(x) = \\sum_{j=0}^{N-1} c'_j P_j(x)$. The coefficients are related by the well-known recurrence:\n$$\nc'_j = (2j+1) \\sum_{\\substack{k=j+1 \\\\ k+j \\text{ is odd}}}^{N} c_k\n$$\nThis relation defines a linear operator, which can be represented by an $(N+1) \\times (N+1)$ matrix $D^{(1)}$ that maps the coefficient vector $\\vec{c}=[c_0, \\dots, c_N]^T$ to $\\vec{c'} = [c'_0, \\dots, c'_{N-1}, 0, \\dots, 0]^T$. The matrix entries are:\n$$\nD^{(1)}_{jk} = \\begin{cases} 2j+1 & \\text{if } k > j \\text{ and } k+j \\text{ is odd} \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nThe second derivative operator, $D^{(2)}$, which maps the coefficients of $v(x)$ to those of $v''(x)$, is obtained by applying the first derivative operator twice: $D^{(2)} = D^{(1)} \\times D^{(1)}$.\n\n**2. Assembling the Tau Matrix $A$**\n\nThe $(N+1)$ equations that form the system $A\\vec{a}=\\vec{b}$ come from two sources: the differential equation and the boundary conditions.\n\n*   **Interior Rows ($i=0, 1, \\dots, N-2$):**\n    These rows enforce the differential equation in a weighted-residual sense. The equation for the $i$-th test function $P_i(x)$ is:\n    $$\n    \\int_{-1}^{1} P_i(x) \\left(-u_N''(x)\\right) dx = \\int_{-1}^{1} P_i(x) f(x) dx\n    $$\n    Let the Legendre expansion of the second derivative be $u_N''(x) = \\sum_{j=0}^{N-2} d_j P_j(x)$, where the coefficient vector $\\vec{d} = D^{(2)}\\vec{a}$. The left-hand side (LHS) becomes:\n    $$\n    \\text{LHS}_i = -\\int_{-1}^{1} P_i(x) \\left( \\sum_{j=0}^{N-2} d_j P_j(x) \\right) dx\n    $$\n    Using the orthogonality property of Legendre polynomials, $\\int_{-1}^{1} P_i(x) P_j(x) dx = \\frac{2}{2i+1} \\delta_{ij}$, the LHS simplifies to:\n    $$\n    \\text{LHS}_i = -d_i \\frac{2}{2i+1} = -\\frac{2}{2i+1} (D^{(2)}\\vec{a})_i = -\\frac{2}{2i+1} \\sum_{j=0}^{N} D^{(2)}_{ij} a_j\n    $$\n    The problem defines the $i$-th row of the linear system as $(A\\vec{a})_i = b_i$. By matching terms, the $i$-th row of the matrix $A$ for $i=0, \\dots, N-2$ is given by:\n    $$\n    A_{ij} = -\\frac{2}{2i+1} D^{(2)}_{ij} \\quad \\text{for } j=0, \\dots, N\n    $$\n\n*   **Boundary Rows ($i=N-1, N$):**\n    The last two rows of the system impose the Dirichlet boundary conditions $u_N(-1)=0$ and $u_N(1)=0$.\n    $$\n    u_N(1) = \\sum_{k=0}^{N} a_k P_k(1) = 0 \\quad \\text{and} \\quad u_N(-1) = \\sum_{k=0}^{N} a_k P_k(-1) = 0\n    $$\n    Using the known properties $P_k(1)=1$ and $P_k(-1)=(-1)^k$, these equations become:\n    $$\n    \\sum_{k=0}^{N} a_k = 0 \\quad \\text{and} \\quad \\sum_{k=0}^{N} a_k (-1)^k = 0\n    $$\n    We assign the condition at $x=-1$ to row $N-1$ and the condition at $x=1$ to row $N$. This defines the last two rows of $A$:\n    $$\n    A_{N-1, k} = (-1)^k \\quad \\text{for } k=0, \\dots, N\n    $$\n    $$\n    A_{N, k} = 1 \\quad \\text{for } k=0, \\dots, N\n    $$\n\n**3. Assembling the Right-Hand-Side Vector $\\vec{b}$**\n\n*   For the interior equations ($i=0, \\dots, N-2$), the right-hand side is $b_i = \\int_{-1}^{1} P_i(x) f(x) dx$. Given the expansion $f(x) = \\sum_{k=0}^{N-2} \\hat{f}_k P_k(x)$, orthogonality gives:\n    $$\n    b_i = \\hat{f}_i \\int_{-1}^{1} P_i(x)^2 dx = \\frac{2}{2i+1} \\hat{f}_i\n    $$\n*   For the boundary equations ($i=N-1, N$), the conditions are homogeneous, so $b_{N-1}=0$ and $b_{N}=0$.\n\n**4. Preconditioning**\n\nTwo left preconditioners are considered. A preconditioner $M^{-1}$ transforms the system $A\\vec{a}=\\vec{b}$ into $M^{-1}A\\vec{a} = M^{-1}\\vec{b}$.\n1.  **Row 2-norm scaling:** $M_{\\text{row}}^{-1}$ is a diagonal matrix where the $i$-th diagonal element is the reciprocal of the Euclidean norm of the $i$-th row of $A$: $(M_{\\text{row}}^{-1})_{ii} = 1/\\|A_{i,:}\\|_2$.\n2.  **Legendre weight normalization:** $M_{\\text{w}}^{-1}$ is a diagonal matrix intended to reverse the scaling applied to the interior rows of $A$. Its diagonal entries are $(M_{\\text{w}}^{-1})_{ii} = (2i+1)/2$ for $i=0, \\dots, N-2$, and $(M_{\\text{w}}^{-1})_{ii} = 1$ for $i=N-1, N$.\n\nThe preconditioned matrices are $A_{\\text{row}} = M_{\\text{row}}^{-1} A$ and $A_{\\text{w}} = M_{\\text{w}}^{-1} A$. The preconditioned right-hand sides are $\\vec{b}_{\\text{row}} = M_{\\text{row}}^{-1} \\vec{b}$ and $\\vec{b}_{\\text{w}} = M_{\\text{w}}^{-1} \\vec{b}$.\n\n**5. Condition Number and Residual Norm Calculation**\n\nThe $2$-norm condition numbers $\\kappa_2(\\cdot)$ of the original and preconditioned matrices are computed. The improvement in convergence behavior is assessed using one step of a Richardson iteration, starting from a zero initial guess. For a generic preconditioned system $M^{-1}A\\vec{a}=M^{-1}\\vec{b}$, the first Richardson iterate (with step size $1$) is $\\vec{a}^{(1)} = M^{-1}\\vec{b}$. The problem specifies using this iterate to evaluate the residual of the original system, $\\| \\vec{b} - A \\vec{a}^{(1)} \\|_2 / \\| \\vec{b} \\|_2$.\n*   No preconditioning ($M=I$): $\\vec{a}^{(1)} = \\vec{b}$. The residual norm is $\\rho_{\\text{none}} = \\| \\vec{b} - A\\vec{b} \\|_2 / \\| \\vec{b} \\|_2$.\n*   Row-norm preconditioning ($M=M_{\\text{row}}$): $\\vec{a}^{(1)}_{\\text{row}} = M_{\\text{row}}^{-1}\\vec{b} = \\vec{b}_{\\text{row}}$. Residual norm is $\\rho_{\\text{row}} = \\| \\vec{b} - A\\vec{b}_{\\text{row}} \\|_2 / \\| \\vec{b} \\|_2$.\n*   Weight preconditioning ($M=M_{\\text{w}}$): $\\vec{a}^{(1)}_{\\text{w}} = M_{\\text{w}}^{-1}\\vec{b} = \\vec{b}_{\\text{w}}$. Residual norm is $\\rho_{\\text{w}} = \\| \\vec{b} - A\\vec{b}_{\\text{w}} \\|_2 / \\| \\vec{b} \\|_2$.\n\nThe implementation will follow these derived steps.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main driver function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Test case 1: N=2, f(x) = P_0(x)\n        (2, {0: 1.0}),\n        # Test case 2: N=16, f(x) = P_2(x) + 0.5 P_5(x) + 0.1 P_12(x)\n        (16, {2: 1.0, 5: 0.5, 12: 0.1}),\n        # Test case 3: N=48, f_k = (-1)^k / (k+1)\n        (48, 'alternating')\n    ]\n\n    results = []\n    for N, f_hat_coeffs in test_cases:\n        res = compute_metrics(N, f_hat_coeffs)\n        results.append(res)\n    \n    # Format the output string as required: [[...],[...],[...]]\n    case_strings = []\n    for res_list in results:\n      case_strings.append(f\"[{','.join(map(str, res_list))}]\")\n    final_string = f\"[{','.join(case_strings)}]\"\n    print(final_string)\n\ndef compute_metrics(N, f_hat_coeffs):\n    \"\"\"\n    Constructs matrices and computes metrics for a single test case.\n\n    Args:\n        N (int): The degree of the Legendre polynomial approximation.\n        f_hat_coeffs (dict or str): Specification for the forcing term coefficients.\n\n    Returns:\n        list: A list of six floating-point numbers containing the computed metrics.\n    \"\"\"\n    # 1. Construct f_hat vector from the provided coefficients\n    f_hat = np.zeros(N - 1)\n    if isinstance(f_hat_coeffs, dict):\n        for k, v in f_hat_coeffs.items():\n            if k < len(f_hat):\n                f_hat[k] = v\n    elif f_hat_coeffs == 'alternating':\n        k_vals = np.arange(N - 1)\n        f_hat = ((-1.0)**k_vals) / (k_vals + 1.0)\n\n    # 2. Construct Legendre differentiation matrix D1 and second derivative D2\n    D1 = np.zeros((N + 1, N + 1))\n    for n in range(N):\n        for k in range(n + 1, N + 1):\n            if (k + n) % 2 == 1:\n                D1[n, k] = 2 * n + 1\n    D2 = D1 @ D1\n    \n    # 3. Assemble the Tau matrix A\n    A = np.zeros((N + 1, N + 1))\n    # Interior rows (i = 0 to N-2)\n    i_vals_int = np.arange(N - 1)\n    scaling_int = -2.0 / (2.0 * i_vals_int + 1.0)\n    A[:N-1, :] = scaling_int[:, np.newaxis] * D2[:N-1, :]\n    # Boundary rows (i = N-1, N)\n    k_vals = np.arange(N + 1)\n    A[N - 1, :] = (-1.0)**k_vals\n    A[N, :] = 1.0\n\n    # 4. Assemble the right-hand side vector b\n    b = np.zeros(N + 1)\n    b[:N-1] = (2.0 / (2.0 * i_vals_int + 1.0)) * f_hat\n    \n    # 5. Compute condition number of the original matrix A\n    kappa_A = np.linalg.cond(A)\n\n    # 6. Row 2-norm preconditioning\n    M_row_inv_diag = np.zeros(N + 1)\n    row_norms = np.linalg.norm(A, axis=1)\n    non_zero_indices = row_norms > 1e-15\n    M_row_inv_diag[non_zero_indices] = 1.0 / row_norms[non_zero_indices]\n    \n    A_row = A * M_row_inv_diag[:, np.newaxis]\n    b_row = b * M_row_inv_diag\n    kappa_A_row = np.linalg.cond(A_row)\n\n    # 7. Legendre weight normalization preconditioning\n    M_w_inv_diag = np.ones(N + 1)\n    M_w_inv_diag[:N-1] = (2.0 * i_vals_int + 1.0) / 2.0\n    \n    A_w = A * M_w_inv_diag[:, np.newaxis]\n    b_w = b * M_w_inv_diag\n    kappa_A_w = np.linalg.cond(A_w)\n\n    # 8. Compute relative residual norms\n    norm_b = np.linalg.norm(b)\n    \n    if norm_b < 1e-15:\n        rho_none = 0.0\n        rho_row = 0.0\n        rho_w = 0.0\n    else:\n        # Preconditioned Richardson step 1: x_k+1 = x_k + M^-1 (b - A x_k)\n        # With x_0 = 0, we get x_1 = M^-1 b.\n        # Residual norm is ||b - A x_1||_2 / ||b||_2\n\n        # No preconditioning (M = I): x_1 = b\n        x1_none = b\n        rho_none = np.linalg.norm(b - A @ x1_none) / norm_b\n        \n        # Row-norm preconditioning: x_1 = M_row^-1 b = b_row\n        x1_row = b_row\n        rho_row = np.linalg.norm(b - A @ x1_row) / norm_b\n        \n        # Weight preconditioning: x_1 = M_w^-1 b = b_w\n        x1_w = b_w\n        rho_w = np.linalg.norm(b - A @ x1_w) / norm_b\n\n    return [kappa_A, kappa_A_row, kappa_A_w, rho_none, rho_row, rho_w]\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "Spectral methods truly shine when applied to complex, time-dependent problems, but this transition introduces new challenges, particularly in handling nonlinearities. This exercise explores the application of the Chebyshev-Tau method to a nonlinear wave equation, focusing on the critical issue of aliasing control . You will implement a time-reversible integrator and compare de-aliasing strategies, gaining practical experience in managing the numerical artifacts that can compromise the long-term stability and physical accuracy of a simulation.",
            "id": "3419510",
            "problem": "Consider the one-dimensional nonlinear Klein–Gordon/wave equation with cubic nonlinearity on the interval $\\left[-1,1\\right]$,\n$$\nu_{tt}(x,t) \\;=\\; u_{xx}(x,t) \\;-\\; u(x,t)^3,\\quad x\\in[-1,1],\\; t\\ge 0,\n$$\nsubject to homogeneous Dirichlet boundary conditions and smooth initial data,\n$$\nu(-1,t) \\;=\\; 0,\\quad u(1,t) \\;=\\; 0,\\quad u(x,0) \\;=\\; u_0(x),\\quad u_t(x,0) \\;=\\; 0.\n$$\nThis equation has a continuous-time energy invariant\n$$\nE(t) \\;=\\; \\int_{-1}^{1} \\left(\\tfrac{1}{2} u_t(x,t)^2 \\;+\\; \\tfrac{1}{2} u_x(x,t)^2 \\;+\\; \\tfrac{1}{4} u(x,t)^4\\right)\\,dx,\n$$\nwhich is conserved exactly, i.e., $dE/dt = 0$, under sufficiently smooth solutions and exact spatial and temporal discretization.\n\nYour task is to implement a spatial Spectral Tau method using Chebyshev polynomials that enforces the Dirichlet boundary conditions, and to compare two de-aliasing strategies for the nonlinear term when evaluating it in physical space:\n\n- Strategy A (standard 2/3-rule): after computing the nodal nonlinear term $g(x) = u(x)^3$, project $g$ to Chebyshev coefficients via a Discrete Cosine Transform (DCT) of type I, and zero the highest one-third of modal coefficients before transforming back; that is, retain only the lowest $\\left\\lfloor \\tfrac{2}{3}(N+1)\\right\\rfloor$ Chebyshev modes and set the rest to zero, where $N$ is the spectral truncation degree (so there are $N+1$ Chebyshev–Lobatto nodes).\n- Strategy B (selective filtering of Tau rows only): after computing $g(x) = u(x)^3$ nodally and projecting to Chebyshev coefficients via a DCT of type I, zero only the highest $K$ modal coefficients associated with the Tau enforcement (take $K=2$ to match the two Dirichlet boundary conditions), and leave all other coefficients unchanged, then transform back.\n\nUse a Chebyshev–Lobatto grid with $N+1$ points $x_k = \\cos\\left(\\pi k/N\\right)$ for $k=0,1,\\dots,N$, and a classical Spectral Tau enforcement by replacing the boundary equations by the Dirichlet constraints $u(-1,t)=u(1,t)=0$ at every time step. In nodal form, the semi-discrete system reads\n$$\nu_t \\;=\\; p,\\qquad\np_t \\;=\\; \\mathcal{L} u \\;-\\; \\mathcal{N}(u),\n$$\nwhere $p$ approximates $u_t$, $\\mathcal{L}$ is the discrete Chebyshev second-derivative operator implementing $u_{xx}$ at the interior nodes, and $\\mathcal{N}(u)$ is the filtered nonlinear term according to either Strategy A or Strategy B. Enforce the Dirichlet conditions by setting $u(x_0,t)=u(x_N,t)=0$ and $p(x_0,t)=p(x_N,t)=0$ for all times. Advance in time with a time-reversible second-order Störmer–Verlet update (also known as leapfrog–Verlet):\n$$\n\\begin{aligned}\np^{n+\\tfrac{1}{2}} &= p^n + \\tfrac{\\Delta t}{2}\\, \\left(\\mathcal{L} u^n - \\mathcal{N}(u^n)\\right),\\\\\nu^{n+1} &= u^n + \\Delta t\\, p^{n+\\tfrac{1}{2}},\\\\\np^{n+1} &= p^{n+\\tfrac{1}{2}} + \\tfrac{\\Delta t}{2}\\, \\left(\\mathcal{L} u^{n+1} - \\mathcal{N}(u^{n+1})\\right),\n\\end{aligned}\n$$\nwith boundary values enforced after each substep. Approximate the spatial integral in the energy with Clenshaw–Curtis quadrature weights on the Chebyshev–Lobatto grid, so that for nodal vectors $u$ and $p$ and the Chebyshev differentiation matrix $D$,\n$$\nE_h(t) \\;=\\; \\sum_{k=0}^{N} w_k \\left(\\tfrac{1}{2} p_k^2 \\;+\\; \\tfrac{1}{2} (Du)_k^2 \\;+\\; \\tfrac{1}{4} u_k^4\\right),\n$$\nwhere $w_k$ are the quadrature weights and $(Du)_k$ approximates $u_x$ at node $k$.\n\nDefine the initial condition as\n$$\nu_0(x) \\;=\\; A \\,\\sin\\!\\left(\\tfrac{\\pi}{2}(x+1)\\right),\n$$\nwhich satisfies the Dirichlet boundary conditions, with $A$ a given amplitude.\n\nImplement both de-aliasing strategies and measure the relative energy drift at final time $T$ for each strategy,\n$$\n\\delta_{\\mathrm{A}} \\;=\\; \\frac{\\left|E_h^{\\mathrm{A}}(T) - E_h^{\\mathrm{A}}(0)\\right|}{E_h^{\\mathrm{A}}(0)},\\qquad\n\\delta_{\\mathrm{B}} \\;=\\; \\frac{\\left|E_h^{\\mathrm{B}}(T) - E_h^{\\mathrm{B}}(0)\\right|}{E_h^{\\mathrm{B}}(0)}.\n$$\nFor each test case below, output the ratio\n$$\n\\rho \\;=\\; \\frac{\\delta_{\\mathrm{B}}}{\\delta_{\\mathrm{A}}}.\n$$\nA ratio $\\rho > 1$ indicates that Strategy B (selective filtering of Tau rows only) degrades long-time energy preservation relative to the standard $2/3$-rule; a ratio $\\rho  1$ indicates that Strategy B improves it.\n\nUse the Discrete Cosine Transform (DCT) of type I with orthonormal normalization to map between nodal values and Chebyshev modal coefficients. Angles are in radians. No physical units are required.\n\nTest suite:\n- Case 1 (happy path): $N=48$, $\\Delta t = 5\\times 10^{-4}$, $T=1.0$, $A=1.0$.\n- Case 2 (long-time): $N=48$, $\\Delta t = 5\\times 10^{-4}$, $T=2.0$, $A=1.0$.\n- Case 3 (coarser and stronger nonlinearity): $N=32$, $\\Delta t = 10^{-3}$, $T=2.0$, $A=1.5$.\n- Case 4 (small amplitude edge case): $N=24$, $\\Delta t = 10^{-3}$, $T=1.0$, $A=0.1$.\n\nProgram requirements:\n- Implement the Chebyshev differentiation matrix and Clenshaw–Curtis weights on the Chebyshev–Lobatto grid.\n- Implement both de-aliasing strategies as defined above using DCT type I with orthonormal normalization.\n- For each test case, compute $\\rho$ as above.\n\nFinal output format:\nYour program should produce a single line of output containing the results for the four test cases as a comma-separated list of floats enclosed in square brackets (e.g., \"[r1,r2,r3,r4]\"). The entries must be in the same order as the test suite above. No additional text should be printed.",
            "solution": "This problem requires the simulation of a nonlinear wave equation using a spectral method for the spatial discretization and a time-reversible integrator. The core task is to compare two de-aliasing strategies for the cubic nonlinearity and assess their impact on the long-term conservation of a discrete energy functional.\n\nThe spatial domain is discretized using Chebyshev-Lobatto points, and spatial derivatives are computed using Chebyshev differentiation matrices. Boundary conditions are enforced directly by setting the values at the grid's endpoints to zero at every step. The time integration is performed with the Störmer-Verlet method, which is well-suited for conservative mechanical systems due to its time-reversibility and symplectic nature.\n\nThe key challenge lies in handling the nonlinear term $u^3$. Its evaluation in physical space and subsequent truncation in spectral space can lead to aliasing errors, which pollute the spectrum and can cause numerical instability. Two strategies are compared:\n1.  **Strategy A (2/3-rule):** This is a standard method for de-aliasing cubic nonlinearities. It involves transforming the nodal values of $u^3$ to the spectral domain (Chebyshev coefficients), zeroing out the highest one-third of the coefficients, and transforming back. This correctly computes the nonlinear term as long as the solution is well-resolved by the lowest third of the available modes.\n2.  **Strategy B (Selective Filtering):** This is a heuristic approach proposed by the problem. It posits that since two degrees of freedom are used for boundary conditions, the projection of the nonlinear forcing onto these modes is spurious. It is implemented by zeroing out only the highest two Chebyshev coefficients of the nodal $u^3$ vector.\n\nThe quality of each strategy is measured by computing the relative energy drift over the simulation time. The ratio of these drifts, $\\rho = \\delta_B / \\delta_A$, provides a quantitative comparison of their performance in preserving the system's energy.",
            "answer": "```python\nimport numpy as np\nfrom scipy.fft import dct, idct\n\ndef cheb_diff_matrices(N):\n    \"\"\"\n    Computes Chebyshev collocation points and differentiation matrices D1 and D2\n    on N+1 Chebyshev-Lobatto points.\n    \"\"\"\n    if N == 0:\n        return np.array([0.0]), np.array([[0.0]]), np.array([[0.0]])\n    \n    x = np.cos(np.pi * np.arange(N + 1) / N)\n    \n    # First derivative matrix D1\n    c = np.ones(N + 1)\n    c[0] = c[N] = 2.0\n    c = c * (-1)**np.arange(N + 1)\n    \n    X = np.tile(x, (N + 1, 1))\n    dX = X - X.T\n    \n    D = (c[:, np.newaxis] / c[np.newaxis, :]) / (dX + np.eye(N + 1))\n    D = D - np.diag(np.sum(D.T, axis=0))\n    \n    # Second derivative matrix D2\n    D2 = D @ D\n    \n    return x, D, D2\n\ndef clenshaw_curtis_weights(N):\n    \"\"\"\n    Computes Clenshaw-Curtis quadrature weights on N+1 Chebyshev-Lobatto points.\n    \"\"\"\n    if N == 0:\n        return np.array([2.0])\n    if N == 1:\n        return np.array([1.0, 1.0])\n    \n    theta = np.pi * np.arange(N + 1) / N\n    w = np.zeros(N + 1)\n    ii = np.arange(1, N)\n    v = np.ones(N - 1)\n    \n    if N % 2 == 0:\n        w[0] = w[N] = 1.0 / (N**2 - 1)\n        for k in range(1, N // 2):\n            v -= 2 * np.cos(2 * k * theta[ii]) / (4 * k**2 - 1)\n        v -= np.cos(N * theta[ii]) / (N**2 - 1)\n    else:  # N is odd\n        w[0] = w[N] = 1.0 / N**2\n        for k in range(1, (N + 1) // 2):\n            v -= 2 * np.cos(2 * k * theta[ii]) / (4 * k**2 - 1)\n    \n    w[ii] = 2 * v / N\n    return w\n\ndef dealiasing_A(v, N):\n    \"\"\"Strategy A: 2/3-rule de-aliasing.\"\"\"\n    c = dct(v, type=1, norm='ortho')\n    N_trunc = int(np.floor(2.0 / 3.0 * (N + 1)))\n    c[N_trunc:] = 0.0\n    return idct(c, type=1, norm='ortho')\n\ndef dealiasing_B(v, N):\n    \"\"\"Strategy B: Selective filtering of K=2 highest modes.\"\"\"\n    K = 2\n    c = dct(v, type=1, norm='ortho')\n    if N + 1  K:\n        c[N + 1 - K:] = 0.0\n    return idct(c, type=1, norm='ortho')\n\ndef calculate_energy(u, p, D, w):\n    \"\"\"Computes the discrete energy of the system.\"\"\"\n    u_x = D @ u\n    integrand = 0.5 * p**2 + 0.5 * u_x**2 + 0.25 * u**4\n    return np.sum(w * integrand)\n\ndef run_simulation(N, dt, T, A, dealiasing_func):\n    \"\"\"\n    Runs the simulation for a given set of parameters and de-aliasing strategy.\n    \"\"\"\n    x, D, D2 = cheb_diff_matrices(N)\n    w = clenshaw_curtis_weights(N)\n\n    # Initial conditions\n    u = A * np.sin(np.pi / 2.0 * (x + 1.0))\n    p = np.zeros(N + 1)\n    \n    # Enforce boundary conditions on initial state\n    u[0] = u[N] = 0.0\n    p[0] = p[N] = 0.0\n\n    E0 = calculate_energy(u, p, D, w)\n    if np.abs(E0)  np.finfo(float).eps:\n        return 0.0\n\n    num_steps = int(round(T / dt))\n\n    # Time integration using Störmer-Verlet\n    for _ in range(num_steps):\n        # First half-step for momentum\n        nonlinear_term_n = u**3\n        dealiased_n = dealiasing_func(nonlinear_term_n, N)\n        acceleration_n = D2 @ u - dealiased_n\n        acceleration_n[0] = acceleration_n[N] = 0.0  # Evolve interior nodes only\n        \n        p_half = p + (dt / 2.0) * acceleration_n\n        \n        # Position update\n        u_new = u + dt * p_half\n        u_new[0] = u_new[N] = 0.0  # Enforce BC on u\n        u = u_new\n\n        # Second half-step for momentum\n        nonlinear_term_n1 = u**3\n        dealiased_n1 = dealiasing_func(nonlinear_term_n1, N)\n        acceleration_n1 = D2 @ u - dealiased_n1\n        acceleration_n1[0] = acceleration_n1[N] = 0.0 # Evolve interior nodes only\n        \n        p_new = p_half + (dt / 2.0) * acceleration_n1\n        p_new[0] = p_new[N] = 0.0 # Enforce BC on p\n        p = p_new\n    \n    ET = calculate_energy(u, p, D, w)\n    \n    relative_drift = np.abs(ET - E0) / np.abs(E0)\n    return relative_drift\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and compute the ratio of energy drifts.\n    \"\"\"\n    test_cases = [\n        # (N, dt, T, A)\n        (48, 5e-4, 1.0, 1.0),\n        (48, 5e-4, 2.0, 1.0),\n        (32, 1e-3, 2.0, 1.5),\n        (24, 1e-3, 1.0, 0.1),\n    ]\n\n    results = []\n    for N, dt, T, A in test_cases:\n        drift_A = run_simulation(N, dt, T, A, dealiasing_A)\n        drift_B = run_simulation(N, dt, T, A, dealiasing_B)\n        \n        if np.abs(drift_A)  np.finfo(float).eps:\n            # If drift A is zero, rho is inf if drift B is non-zero, or 1 if both are zero.\n            rho = np.inf if np.abs(drift_B)  np.finfo(float).eps else 1.0\n        else:\n            rho = drift_B / drift_A\n\n        results.append(rho)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}