{
    "hands_on_practices": [
        {
            "introduction": "In the Fourier-Galerkin method, the choice of basis is fundamental. Using an orthonormal basis is highly advantageous as it simplifies the resulting discrete system, typically leading to a diagonal mass matrix. This exercise provides foundational practice in constructing such a basis by deriving the normalization constants for the real trigonometric functions from first principles, using the standard $L^2$ inner product on a periodic domain .",
            "id": "3387170",
            "problem": "Consider the space of square-integrable, real-valued, $2\\pi$-periodic functions on the interval $[0,2\\pi]$ equipped with the inner product\n$$\\langle f,g\\rangle=\\frac{1}{2\\pi}\\int_{0}^{2\\pi} f(x)\\,g(x)\\,dx.$$\nThis inner product arises naturally in spectral expansions for periodic problems and leads to diagonal mass matrices in Discontinuous Galerkin (DG) methods when an orthonormal basis is used. Starting from the definition of orthonormality for a set $\\{\\varphi_{i}\\}$, namely $\\langle \\varphi_{i},\\varphi_{j}\\rangle=\\delta_{ij}$, determine multiplicative normalization constants for the real trigonometric family consisting of the constant function and the single-frequency pair at a fixed positive integer $k$. Specifically, find constants $A$, $B$, and $C$ such that the set\n$$\\{A\\cdot 1,\\;B\\cdot \\cos(kx),\\;C\\cdot \\sin(kx)\\}$$\nis orthonormal with respect to $\\frac{1}{2\\pi}\\int_0^{2\\pi}\\cdot\\,dx$. Your derivation must start from the inner product definition and fundamental trigonometric identities, without invoking pre-tabulated Fourier orthogonality results. Express your final answer as a row matrix containing the three constants in the order corresponding to $\\{1,\\cos(kx),\\sin(kx)\\}$. No rounding is required.",
            "solution": "The problem is valid. It is a well-posed mathematical problem grounded in the fundamental principles of functional analysis and Fourier theory, with direct relevance to numerical methods for partial differential equations. All definitions are clear and self-contained.\n\nThe task is to find the positive normalization constants $A$, $B$, and $C$ such that the set of real-valued functions $\\{\\varphi_1(x), \\varphi_2(x), \\varphi_3(x)\\}$ given by\n$$ \\varphi_1(x) = A \\cdot 1 = A $$\n$$ \\varphi_2(x) = B \\cdot \\cos(kx) $$\n$$ \\varphi_3(x) = C \\cdot \\sin(kx) $$\nis an orthonormal set for a fixed positive integer $k$. The space of functions is equipped with the inner product\n$$ \\langle f,g\\rangle=\\frac{1}{2\\pi}\\int_{0}^{2\\pi} f(x)\\,g(x)\\,dx. $$\nThe condition for orthonormality is $\\langle \\varphi_{i},\\varphi_{j}\\rangle=\\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta, which is $1$ if $i=j$ and $0$ if $i \\neq j$.\n\nWe will determine the constants by enforcing the normalization condition $\\langle \\varphi_i, \\varphi_i \\rangle = 1$ for $i=1, 2, 3$. Then, we will verify that the orthogonality conditions $\\langle \\varphi_i, \\varphi_j \\rangle = 0$ for $i \\neq j$ are satisfied.\n\n1.  **Normalization of the constant function $\\varphi_1(x) = A$**\n\nThe normalization condition is $\\langle \\varphi_1, \\varphi_1 \\rangle = 1$.\n$$ \\langle A, A \\rangle = \\frac{1}{2\\pi}\\int_{0}^{2\\pi} A \\cdot A \\,dx = \\frac{A^2}{2\\pi}\\int_{0}^{2\\pi} 1 \\,dx $$\nThe integral is $\\int_{0}^{2\\pi} 1 \\,dx = [x]_0^{2\\pi} = 2\\pi$.\nSubstituting this result into the inner product expression:\n$$ \\langle A, A \\rangle = \\frac{A^2}{2\\pi} (2\\pi) = A^2 $$\nFor normalization, we must have $A^2 = 1$. Choosing the positive constant, we find $A=1$.\n\n2.  **Normalization of the cosine function $\\varphi_2(x) = B \\cos(kx)$**\n\nThe normalization condition is $\\langle \\varphi_2, \\varphi_2 \\rangle = 1$.\n$$ \\langle B\\cos(kx), B\\cos(kx) \\rangle = \\frac{1}{2\\pi}\\int_{0}^{2\\pi} (B\\cos(kx))^2 \\,dx = \\frac{B^2}{2\\pi}\\int_{0}^{2\\pi} \\cos^2(kx) \\,dx $$\nTo evaluate the integral, we use the power-reduction identity $\\cos^2(\\theta) = \\frac{1+\\cos(2\\theta)}{2}$.\n$$ \\int_{0}^{2\\pi} \\cos^2(kx) \\,dx = \\int_{0}^{2\\pi} \\frac{1+\\cos(2kx)}{2} \\,dx = \\frac{1}{2} \\left[ \\int_{0}^{2\\pi} 1 \\,dx + \\int_{0}^{2\\pi} \\cos(2kx) \\,dx \\right] $$\nThe first integral is $\\int_{0}^{2\\pi} 1 \\,dx = 2\\pi$. The second integral is:\n$$ \\int_{0}^{2\\pi} \\cos(2kx) \\,dx = \\left[ \\frac{\\sin(2kx)}{2k} \\right]_0^{2\\pi} $$\nSince $k$ is a positive integer, $2k$ is also an integer. Thus, $\\sin(2k \\cdot 2\\pi) = \\sin(4\\pi k) = 0$ and $\\sin(0)=0$. The integral evaluates to $0$.\nTherefore, $\\int_{0}^{2\\pi} \\cos^2(kx) \\,dx = \\frac{1}{2} [2\\pi + 0] = \\pi$.\nSubstituting this into the inner product expression:\n$$ \\langle B\\cos(kx), B\\cos(kx) \\rangle = \\frac{B^2}{2\\pi} (\\pi) = \\frac{B^2}{2} $$\nFor normalization, we set $\\frac{B^2}{2} = 1$, which gives $B^2=2$. Choosing the positive constant, we have $B=\\sqrt{2}$.\n\n3.  **Normalization of the sine function $\\varphi_3(x) = C \\sin(kx)$**\n\nThe normalization condition is $\\langle \\varphi_3, \\varphi_3 \\rangle = 1$.\n$$ \\langle C\\sin(kx), C\\sin(kx) \\rangle = \\frac{1}{2\\pi}\\int_{0}^{2\\pi} (C\\sin(kx))^2 \\,dx = \\frac{C^2}{2\\pi}\\int_{0}^{2\\pi} \\sin^2(kx) \\,dx $$\nUsing the power-reduction identity $\\sin^2(\\theta) = \\frac{1-\\cos(2\\theta)}{2}$:\n$$ \\int_{0}^{2\\pi} \\sin^2(kx) \\,dx = \\int_{0}^{2\\pi} \\frac{1-\\cos(2kx)}{2} \\,dx = \\frac{1}{2} \\left[ \\int_{0}^{2\\pi} 1 \\,dx - \\int_{0}^{2\\pi} \\cos(2kx) \\, dx \\right] $$\nAs calculated previously, $\\int_{0}^{2\\pi} 1 \\,dx = 2\\pi$ and $\\int_{0}^{2\\pi} \\cos(2kx) \\,dx = 0$.\nSo, $\\int_{0}^{2\\pi} \\sin^2(kx) \\,dx = \\frac{1}{2} [2\\pi - 0] = \\pi$.\nSubstituting this into the inner product expression:\n$$ \\langle C\\sin(kx), C\\sin(kx) \\rangle = \\frac{C^2}{2\\pi} (\\pi) = \\frac{C^2}{2} $$\nFor normalization, $\\frac{C^2}{2} = 1$, giving $C^2=2$. Choosing the positive constant, $C=\\sqrt{2}$.\n\n4.  **Verification of Orthogonality**\n\nWe must verify that $\\langle \\varphi_i, \\varphi_j \\rangle = 0$ for $i \\neq j$.\n\n-   $\\langle \\varphi_1, \\varphi_2 \\rangle = \\langle A, B\\cos(kx) \\rangle = \\frac{AB}{2\\pi}\\int_{0}^{2\\pi} \\cos(kx) \\,dx$. Since $k$ is a positive integer,\n    $$ \\int_{0}^{2\\pi} \\cos(kx) \\,dx = \\left[\\frac{\\sin(kx)}{k}\\right]_0^{2\\pi} = \\frac{\\sin(2\\pi k) - \\sin(0)}{k} = \\frac{0-0}{k} = 0 $$\n    Thus, $\\langle \\varphi_1, \\varphi_2 \\rangle = 0$.\n\n-   $\\langle \\varphi_1, \\varphi_3 \\rangle = \\langle A, C\\sin(kx) \\rangle = \\frac{AC}{2\\pi}\\int_{0}^{2\\pi} \\sin(kx) \\,dx$. Since $k$ is a positive integer,\n    $$ \\int_{0}^{2\\pi} \\sin(kx) \\,dx = \\left[-\\frac{\\cos(kx)}{k}\\right]_0^{2\\pi} = -\\frac{\\cos(2\\pi k) - \\cos(0)}{k} = -\\frac{1-1}{k} = 0 $$\n    Thus, $\\langle \\varphi_1, \\varphi_3 \\rangle = 0$.\n\n-   $\\langle \\varphi_2, \\varphi_3 \\rangle = \\langle B\\cos(kx), C\\sin(kx) \\rangle = \\frac{BC}{2\\pi}\\int_{0}^{2\\pi} \\cos(kx)\\sin(kx) \\,dx$. Using the identity $\\sin(2\\theta) = 2\\sin(\\theta)\\cos(\\theta)$, we have $\\cos(kx)\\sin(kx) = \\frac{1}{2}\\sin(2kx)$.\n    $$ \\int_{0}^{2\\pi} \\cos(kx)\\sin(kx) \\,dx = \\frac{1}{2}\\int_{0}^{2\\pi} \\sin(2kx) \\,dx = \\frac{1}{2}\\left[-\\frac{\\cos(2kx)}{2k}\\right]_0^{2\\pi} $$\n    Since $k$ is a positive integer, $2k$ is an integer, so $\\cos(2k \\cdot 2\\pi) = \\cos(4\\pi k) = 1$ and $\\cos(0)=1$.\n    $$ \\frac{1}{2} \\left(-\\frac{1-1}{2k}\\right) = 0 $$\n    Thus, $\\langle \\varphi_2, \\varphi_3 \\rangle = 0$.\n\nThe orthogonality conditions are satisfied. The normalization constants are $A=1$, $B=\\sqrt{2}$, and $C=\\sqrt{2}$. The final answer is the row matrix of these constants.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 1 & \\sqrt{2} & \\sqrt{2} \\end{pmatrix} } $$"
        },
        {
            "introduction": "A significant challenge in implementing spectral methods for nonlinear partial differential equations is the treatment of nonlinear terms, such as $u^p$. When a truncated Fourier series for $u$ is raised to a power, the resulting trigonometric polynomial contains higher-frequency modes that can be misrepresented on a discrete grid, an error known as aliasing. This exercise explores how to determine the minimum number of quadrature points required to compute the Galerkin projection of such a nonlinear term exactly, introducing the crucial concept of oversampling for de-aliasing .",
            "id": "3387173",
            "problem": "Consider the complex exponential Fourier basis on the interval $[0,2\\pi)$, $\\{\\phi_{k}(x)\\}_{k\\in\\mathbb{Z}}$ with $\\phi_{k}(x)=\\exp(i k x)$. Let $K\\in\\mathbb{N}$ and define the truncated Fourier-Galerkin space $V_{K}=\\mathrm{span}\\{\\phi_{k}:|k|\\le K\\}$ of dimension $N=2K+1$. Let $u_{N}(x)=\\sum_{|k|\\le K}\\hat{u}_{k}\\,\\exp(i k x)\\in V_{K}$ be a $2\\pi$-periodic function. For a fixed integer $p\\ge 2$, the $k$th Galerkin coefficient of the polynomial nonlinearity of degree $p$ is the exact inner product\n$$\n\\mathcal{I}_{k}=\\int_{0}^{2\\pi} \\big(u_{N}(x)\\big)^{p}\\,\\overline{\\phi_{k}(x)}\\,dx=\\int_{0}^{2\\pi} \\big(u_{N}(x)\\big)^{p}\\,\\exp(-i k x)\\,dx,\\quad |k|\\le K.\n$$\nSuppose $\\mathcal{I}_{k}$ is computed using the composite trapezoidal rule with $M$ equispaced nodes $x_{j}=\\tfrac{2\\pi j}{M}$ for $j=0,1,\\dots,M-1$, i.e.,\n$$\n\\mathcal{Q}_{M}\\big[(u_{N})^{p}\\,\\overline{\\phi_{k}}\\big]=\\frac{2\\pi}{M}\\sum_{j=0}^{M-1} \\big(u_{N}(x_{j})\\big)^{p}\\,\\exp(-i k x_{j}).\n$$\nUsing only fundamental properties of Fourier series and of the composite trapezoidal rule on $[0,2\\pi)$, determine the minimal integer $M$ (as a function of $p$ and $K$) such that, for all choices of $\\{\\hat{u}_{k}\\}_{|k|\\le K}$ and for all $|k|\\le K$, the quadrature $\\mathcal{Q}_{M}$ returns the exact integrals $\\mathcal{I}_{k}$. Define the oversampling factor $\\rho=\\tfrac{M}{N}=\\tfrac{M}{2K+1}$ and give the minimal oversampling factor $\\rho_{\\min}$ as a closed-form symbolic expression in terms of $p$ and $K$. Your final answer must be this expression for $\\rho_{\\min}$.",
            "solution": "The problem asks for the minimal number of quadrature points $M$ for the composite trapezoidal rule on $[0, 2\\pi)$ to exactly compute the Galerkin coefficients $\\mathcal{I}_k$ of a polynomial nonlinearity $(u_N(x))^p$ for all modes $|k| \\le K$ and for all choices of Fourier coefficients of $u_N$. From this, we are to determine the minimal oversampling factor $\\rho_{\\min}$.\n\nLet $f(x)$ be a $2\\pi$-periodic function with a convergent Fourier series $f(x) = \\sum_{m \\in \\mathbb{Z}} \\hat{f}_m \\exp(imx)$. The exact integral of $f(x)$ over its period is given by\n$$\n\\int_{0}^{2\\pi} f(x) \\,dx = \\int_{0}^{2\\pi} \\left( \\sum_{m \\in \\mathbb{Z}} \\hat{f}_m \\exp(imx) \\right) dx = \\sum_{m \\in \\mathbb{Z}} \\hat{f}_m \\int_{0}^{2\\pi} \\exp(imx) \\,dx = 2\\pi \\hat{f}_0.\n$$\nThe composite trapezoidal rule with $M$ equispaced nodes $x_j = \\frac{2\\pi j}{M}$ for $j=0, \\dots, M-1$ approximates this integral as\n$$\n\\mathcal{Q}_M[f] = \\frac{2\\pi}{M} \\sum_{j=0}^{M-1} f(x_j) = \\frac{2\\pi}{M} \\sum_{j=0}^{M-1} \\sum_{m \\in \\mathbb{Z}} \\hat{f}_m \\exp(imx_j) = \\frac{2\\pi}{M} \\sum_{m \\in \\mathbb{Z}} \\hat{f}_m \\left( \\sum_{j=0}^{M-1} \\exp\\left(im \\frac{2\\pi j}{M}\\right) \\right).\n$$\nThe inner sum is a geometric series which equals $M$ if $m$ is a multiple of $M$ (i.e., $m=lM$ for some $l \\in \\mathbb{Z}$), and $0$ otherwise. Thus, the quadrature evaluates to\n$$\n\\mathcal{Q}_M[f] = 2\\pi \\sum_{l \\in \\mathbb{Z}} \\hat{f}_{lM}.\n$$\nThis is the aliasing formula. The quadrature $\\mathcal{Q}_M[f]$ is exact if and only if all aliasing terms for $l \\neq 0$ vanish, i.e., $\\sum_{l \\in \\mathbb{Z}, l \\neq 0} \\hat{f}_{lM} = 0$. If $f(x)$ is a trigonometric polynomial of degree $L$, meaning its Fourier coefficients $\\hat{f}_m$ are zero for all $|m| > L$, this condition for exactness is satisfied if $|lM| > L$ for all non-zero integers $l$. The most restrictive case is for $l = \\pm 1$, which requires $M > L$. The minimal integer $M$ for which the quadrature is exact is therefore $M = L+1$.\n\nIn our problem, the integral to be computed is $\\mathcal{I}_k = \\int_{0}^{2\\pi} (u_N(x))^p \\exp(-ikx) dx$. The integrand is $f_k(x) = (u_N(x))^p \\exp(-ikx)$. We need to find the maximum degree of $f_k(x)$ over all valid choices, i.e., for all $|k| \\le K$ and for any set of coefficients $\\{\\hat{u}_k\\}_{|k|\\le K}$.\n\nThe function $u_N(x) = \\sum_{|k'|\\le K} \\hat{u}_{k'} \\exp(ik'x)$ is a trigonometric polynomial of degree at most $K$. Under the condition \"for all choices of $\\{\\hat{u}_k\\}$\", we must assume a worst-case scenario where the coefficients corresponding to the highest and lowest frequencies, $\\hat{u}_K$ and $\\hat{u}_{-K}$, are non-zero. Thus, the degree of $u_N(x)$ is exactly $K$.\n\nThe term $(u_N(x))^p$ is the product of $p$ such polynomials. By the convolution theorem, the set of Fourier modes of a product is the Minkowski sum of the sets of modes of the factors. The frequencies in $u_N(x)$ are in the set $\\{-K, -K+1, \\dots, K\\}$. The frequencies in $(u_N(x))^p$ are sums of $p$ such frequencies, and therefore lie in the range $[-pK, pK]$. Since we must consider all choices of coefficients, we can construct a $u_N(x)$ (e.g., $u_N(x) = \\exp(iKx)$) for which $(u_N(x))^p = \\exp(ipKx)$, so the maximum frequency is indeed $pK$. Thus, $(u_N(x))^p$ is a trigonometric polynomial of degree $pK$.\n\nThe integrand is $f_k(x) = (u_N(x))^p \\exp(-ikx)$. The frequencies of this function are the frequencies of $(u_N(x))^p$ shifted by $-k$. Since the frequencies of $(u_N(x))^p$ are in $[-pK, pK]$, the frequencies of $f_k(x)$ are in the range $[-pK-k, pK-k]$.\n\nThe degree of $f_k(x)$ for a fixed $k$ is the maximum absolute value of the frequencies present.\n$$\nL_k = \\max(|-pK-k|, |pK-k|).\n$$\nSince $p \\ge 2$ and $K \\ge 1$, $pK$ is positive. The expression simplifies to\n$$\nL_k = \\max(pK+k, pK-k) \\quad \\text{if } k \\ge 0, \\quad \\text{or} \\quad \\max(pK-k, pK+k) \\quad \\text{if } k < 0.\n$$\nIn general, this is $pK+|k|$.\n\nThe quadrature rule must be exact for all $|k| \\le K$. This requires that the number of points $M$ is sufficient for the integrand with the highest degree. We must find the maximum possible degree $L_{\\max}$ over all integrands $f_k(x)$ for $|k| \\le K$.\n$$\nL_{\\max} = \\max_{|k| \\le K} L_k = \\max_{|k| \\le K} (pK+|k|).\n$$\nThe function $pK+|k|$ is maximized when $|k|$ is maximized. Since $|k| \\le K$, the maximum value is attained at $|k|=K$.\n$$\nL_{\\max} = pK+K = (p+1)K.\n$$\nFor the composite trapezoidal rule to be exact for all these integrands, the number of quadrature points $M$ must be strictly greater than the maximum possible degree of any of the integrands.\n$$\nM > L_{\\max} \\implies M > (p+1)K.\n$$\nThe minimal integer $M$ that satisfies this condition is\n$$\nM_{\\min} = (p+1)K + 1.\n$$\nThe problem defines the dimension of the space $V_K$ as $N = 2K+1$ and the oversampling factor as $\\rho = \\frac{M}{N}$. We are asked for the minimal oversampling factor $\\rho_{\\min}$, which corresponds to $M_{\\min}$.\n$$\n\\rho_{\\min} = \\frac{M_{\\min}}{N} = \\frac{(p+1)K+1}{2K+1}.\n$$\nThis expression gives the minimal oversampling factor required to prevent aliasing errors when computing the Galerkin projection of the $p$-th degree polynomial nonlinearity. For the common case of quadratic nonlinearity ($p=2$), this factor is $\\rho_{\\min} = \\frac{3K+1}{2K+1}$, which approaches $\\frac{3}{2}$ for large $K$, corresponding to the well-known \"3/2-rule\" for de-aliasing.",
            "answer": "$$\n\\boxed{\\frac{(p+1)K+1}{2K+1}}\n$$"
        },
        {
            "introduction": "For time-dependent or parameter-dependent problems, the smoothness of the solution may vary, making a fixed spectral resolution inefficient. A powerful strategy is to adapt the number of Fourier modes, $N$, to maintain a desired error tolerance. This practice leverages Parseval's theorem to link the $L^2$ truncation error directly to the energy in the truncated \"tail\" of the Fourier spectrum, guiding you to design and implement a practical adaptive truncation algorithm with hysteresis to ensure stability .",
            "id": "3387179",
            "problem": "Consider a periodic problem on the spatial domain $[0,2\\pi)$ with a Fourier basis $\\{e^{\\mathrm{i}kx}\\}_{k\\in\\mathbb{Z}}$. Let a real-valued function $u(x,t)$ be sampled at $M$ equispaced points $x_j=\\frac{2\\pi j}{M}$ for $j=0,1,\\dots,M-1$. Denote the discrete Fourier coefficients by $\\hat{u}_k(t)$ at wavenumber $k\\in\\mathbb{Z}$, computed via a discrete Fourier transform. Define the per-mode energy by $\\mathcal{E}_k(t)=|\\hat{u}_k(t)|^2$ and the total energy by $\\mathcal{E}_{\\mathrm{tot}}(t)=\\sum_{k\\in\\mathbb{Z}}\\mathcal{E}_k(t)$. For a truncation wavenumber $N(t)\\in\\mathbb{N}$, the truncated spectral approximation $u_N(x,t)$ keeps modes with $|k|\\le N(t)$.\n\nYour task is to design and implement an adaptive truncation criterion that grows or shrinks $N(t)$ to maintain a target relative error tolerance $\\varepsilon$ in the $L^2$ norm, for solutions with time-varying smoothness. Begin from the following base:\n\n- The Fourier series for periodic functions on $[0,2\\pi)$.\n- Parseval's identity for square-integrable periodic functions, implying that the squared $L^2$ norm equals the sum of squared magnitudes of Fourier coefficients.\n\nUsing these, derive a rule to choose the minimal truncation index $N_{\\min}(t)$ such that the energy in the neglected tail is sufficiently small relative to the total energy. Let the tail energy be $\\mathcal{T}(N,t)=\\sum_{|k|>N}\\mathcal{E}_k(t)$ and define the relative tail fraction $f(N,t)=\\frac{\\mathcal{T}(N,t)}{\\mathcal{E}_{\\mathrm{tot}}(t)}$ when $\\mathcal{E}_{\\mathrm{tot}}(t)>0$. In the degenerate case $\\mathcal{E}_{\\mathrm{tot}}(t)=0$, define $N_{\\min}(t)=0$ and a neutral action.\n\nTo avoid chattering in $N(t)$, incorporate hysteresis with two thresholds $0<\\alpha<\\beta<1$ as follows:\n- If $f(N(t),t)>\\beta\\,\\varepsilon^2$, choose to grow to $N_{\\min}(t)$.\n- If $f(N(t),t)<\\alpha\\,\\varepsilon^2$, choose to shrink to $N_{\\min}(t)$.\n- Otherwise, keep $N(t)$ unchanged.\n\nImplement this criterion in a program that, for a set of prescribed snapshots $u(x)$, computes $N_{\\min}$ and the action indicator $a\\in\\{-1,0,1\\}$ for shrink, keep, grow, respectively, given the current $N$ and tolerance $\\varepsilon$. Use equispaced samples with $M$ points, and group energies by the absolute wavenumber $|k|$ so that the radial energy at each integer wavenumber is the sum of energies over $k$ and $-k$. The discrete scaling of the Fourier transform may differ from the continuous normalization, but the relative tail fraction $f(N)$ must be computed consistently so that common scaling factors cancel.\n\nAngle units must be radians.\n\nTest Suite:\nUse $M=256$, thresholds $\\alpha=0.25$ and $\\beta=0.75$, and the following $5$ test cases. In each case, the program must construct $u(x)$ at $M$ points, compute the discrete Fourier transform and energies, then determine $N_{\\min}$ and the action using the rule above.\n\n- Case $1$: $u_1(x)=\\sin(x)+0.2\\,\\sin(5x)$ with $\\varepsilon=10^{-6}$ and current $N=8$.\n- Case $2$: $u_2(x)=\\sin(x)+0.2\\,\\sin(5x)+0.2\\,\\sin(30x)$ with $\\varepsilon=10^{-3}$ and current $N=8$.\n- Case $3$: $u_3(x)=\\sin(x)$ with $\\varepsilon=10^{-4}$ and current $N=64$.\n- Case $4$: $u_4(x)=0$ with $\\varepsilon=10^{-2}$ and current $N=10$.\n- Case $5$: $u_5(x)=a\\,\\sin(x)+b\\,\\sin(16x)$ with $a=1$ and $b=\\sqrt{\\frac{\\beta\\,\\varepsilon^2}{1-\\beta\\,\\varepsilon^2}}$, using $\\varepsilon=10^{-1}$ and current $N=8$.\n\nRequired Final Output Format:\nYour program should produce a single line of output containing a list of results, one per test case, where each result is the list $[N_{\\min},a]$ with $N_{\\min}\\in\\mathbb{N}$ and $a\\in\\{-1,0,1\\}$. The output must be a single comma-separated list enclosed in square brackets, for example, $[[N_{\\min,1},a_1],[N_{\\min,2},a_2],\\dots,[N_{\\min,5},a_5]]$.",
            "solution": "The problem requires the design and implementation of an adaptive truncation criterion for Fourier spectral methods on a periodic domain. The criterion adjusts the truncation wavenumber, $N(t)$, to maintain a specified relative error tolerance, $\\varepsilon$, in the $L^2$ norm. The adaptation includes a hysteresis mechanism to prevent rapid oscillations in $N(t)$.\n\n### Theoretical Foundation and Derivation\n\nA real-valued, square-integrable function $u(x)$ on the periodic domain $[0, 2\\pi)$ can be represented by its Fourier series:\n$$u(x) = \\sum_{k=-\\infty}^{\\infty} c_k e^{\\mathrm{i}kx}$$\nwhere $c_k = \\frac{1}{2\\pi} \\int_0^{2\\pi} u(x) e^{-\\mathrm{i}kx} dx$ are the Fourier coefficients. For a real function $u(x)$, these coefficients satisfy the symmetry property $c_{-k} = \\overline{c_k}$.\n\nParseval's theorem relates the integral of the squared magnitude of the function (its energy) to the sum of the squared magnitudes of its Fourier coefficients:\n$$\\frac{1}{2\\pi} \\int_0^{2\\pi} |u(x)|^2 dx = \\|u\\|_{L^2}^2 = \\sum_{k=-\\infty}^{\\infty} |c_k|^2$$\n\nA spectral approximation $u_N(x)$ is formed by truncating the series, keeping only modes with absolute wavenumbers $|k| \\le N$:\n$$u_N(x) = \\sum_{k=-N}^{N} c_k e^{\\mathrm{i}kx}$$\nThe truncation error is $e_N(x) = u(x) - u_N(x) = \\sum_{|k|>N} c_k e^{\\mathrm{i}kx}$. The squared $L^2$ norm of this error is given by Parseval's theorem as:\n$$\\|e_N\\|_{L^2}^2 = \\sum_{|k|>N} |c_k|^2$$\n\nThe relative error in the $L^2$ norm is $\\frac{\\|e_N\\|_{L^2}}{\\|u\\|_{L^2}}$. The square of this quantity is the ratio of the energy in the truncated tail of the spectrum to the total energy of the signal:\n$$\\left(\\frac{\\|e_N\\|_{L^2}}{\\|u\\|_{L^2}}\\right)^2 = \\frac{\\sum_{|k|>N} |c_k|^2}{\\sum_{k=-\\infty}^{\\infty} |c_k|^2}$$\n\nIn a numerical setting, the function $u(x)$ is sampled at $M$ discrete, equispaced points $x_j = \\frac{2\\pi j}{M}$. The Discrete Fourier Transform (DFT) is used to compute a set of discrete Fourier coefficients, $\\hat{u}_k$, for wavenumbers $k$ in a finite range (typically $|k| \\le M/2$). While the scaling of DFT coefficients may differ from the continuous coefficients $c_k$, the ratio of energies is independent of this scaling.\n\nWe define the discrete per-mode energy as $\\mathcal{E}_k = |\\hat{u}_k|^2$, the total energy as $\\mathcal{E}_{\\mathrm{tot}} = \\sum_k \\mathcal{E}_k$, and the tail energy for a truncation $N$ as $\\mathcal{T}(N) = \\sum_{|k|>N} \\mathcal{E}_k$. The discrete analogue of the squared relative error is the relative tail fraction:\n$$f(N) = \\frac{\\mathcal{T}(N)}{\\mathcal{E}_{\\mathrm{tot}}}$$\nThe objective is to maintain a relative error tolerance $\\varepsilon$, which translates to keeping $f(N) \\le \\varepsilon^2$.\n\n### Algorithmic Design\n\nThe task is twofold: first, to determine the minimal truncation index $N_{\\min}$ that satisfies the tolerance; second, to decide on an action (grow, shrink, or keep) for the current truncation index $N$ based on a hysteresis rule.\n\n**1. Computing the Minimal Truncation Index $N_{\\min}$**\n\n$N_{\\min}$ is defined as the smallest non-negative integer $N$ such that $f(N) \\le \\varepsilon^2$.\n$$f(N) = \\frac{\\sum_{|k|>N} \\mathcal{E}_k}{\\mathcal{E}_{\\mathrm{tot}}} \\le \\varepsilon^2$$\nThis inequality can be rewritten in terms of the energy contained within the modes $|k| \\le N$:\n$$\\mathcal{E}_{\\mathrm{tot}} - \\sum_{|k|\\le N} \\mathcal{E}_k \\le \\varepsilon^2 \\mathcal{E}_{\\mathrm{tot}}$$\n$$\\sum_{|k|\\le N} \\mathcal{E}_k \\ge (1-\\varepsilon^2) \\mathcal{E}_{\\mathrm{tot}}$$\nThis gives a direct algorithm to find $N_{\\min}$:\n1.  Compute the discrete Fourier coefficients $\\hat{u}_k$ of the sampled function using the FFT.\n2.  Calculate the per-mode energies $\\mathcal{E}_k = |\\hat{u}_k|^2$ and the total energy $\\mathcal{E}_{\\mathrm{tot}} = \\sum_k \\mathcal{E}_k$.\n3.  For a real signal, $\\mathcal{E}_k = \\mathcal{E}_{-k}$. Group energies by absolute wavenumber $|k|$, defining the radial energy $E_K = \\sum_{|k|=K} \\mathcal{E}_k$ for $K \\ge 0$.\n4.  Calculate the target cumulative energy $E_{\\mathrm{target}} = (1-\\varepsilon^2) \\mathcal{E}_{\\mathrm{tot}}$.\n5.  Iterate through absolute wavenumbers $K = 0, 1, 2, \\dots$ in increasing order, calculating the cumulative energy $C_K = \\sum_{i=0}^K E_i$.\n6.  $N_{\\min}$ is the first value $K$ for which $C_K \\ge E_{\\mathrm{target}}$.\n7.  If $u(x)=0$, then $\\mathcal{E}_{\\mathrm{tot}}=0$. The problem prescribes $N_{\\min}=0$.\n\n**2. Hysteresis-based Action Indicator**\n\nGiven the current truncation index $N$, we compute the relative tail fraction $f(N)$. The action $a \\in \\{-1, 0, 1\\}$ (for shrink, keep, grow) is determined by comparing $f(N)$ to two thresholds based on $\\varepsilon^2$ and parameters $0 < \\alpha < \\beta < 1$.\n1.  Calculate $f(N) = \\mathcal{T}(N) / \\mathcal{E}_{\\mathrm{tot}}$. This is most easily computed as $1 - (\\sum_{|k|\\le N} \\mathcal{E}_k) / \\mathcal{E}_{\\mathrm{tot}}$.\n2.  Apply the rules:\n    -   If $f(N) > \\beta \\varepsilon^2$, the error is too large. Set $a=1$ (grow).\n    -   If $f(N) < \\alpha \\varepsilon^2$, the resolution is excessive and can be reduced. Set $a=-1$ (shrink).\n    -   Otherwise, if $\\alpha \\varepsilon^2 \\le f(N) \\le \\beta \\varepsilon^2$, the error is in an acceptable range. Set $a=0$ (keep).\n3.  In the case $u(x)=0$, $\\mathcal{E}_{\\mathrm{tot}}=0$ and $f(N)$ is undefined. The \"otherwise\" case applies, leading to a neutral action $a=0$.\n\nThis procedure provides the required pair $[N_{\\min}, a]$ for each given snapshot of the function $u(x)$.",
            "answer": "[[5, -1],[30, 1],[1, -1],[0, 0],[1, 0]]"
        }
    ]
}