{
    "hands_on_practices": [
        {
            "introduction": "Our first practice explores the fundamental relationship between the differential operator, the basis functions, and the choice of test space. By using Legendre polynomials, which are the eigenfunctions of the Sturm-Liouville operator in the problem, we can see how a Galerlin projection simplifies dramatically. This exercise  will clarify the distinction between Galerkin and Petrov-Galerkin methods and reveal the elegant structure that emerges when the trial space is well-suited to the problem.",
            "id": "3425419",
            "problem": "Consider the one-dimensional spectral discretization on the interval $[-1,1]$ using the Legendre polynomials $\\{L_n(x)\\}_{n \\ge 0}$, where $L_0(x)=1$, $L_1(x)=x$, and higher order $L_n(x)$ are defined as the unique degree-$n$ polynomials that are orthogonal on $[-1,1]$ with respect to the unit weight. Let the trial space be\n$$\nV_N \\;=\\; \\operatorname{span}\\{L_0, L_1, \\dots, L_N\\}.\n$$\nWe study the weak form of the Legendre Sturm–Liouville operator with a zeroth-order reaction term: find $u_N \\in V_N$ such that\n$$\na(u_N, w) \\;=\\; \\ell(w) \\quad \\text{for all } w \\in W_N,\n$$\nwith bilinear form\n$$\na(u,w) \\;=\\; \\int_{-1}^{1} (1-x^2)\\, u'(x)\\, w'(x)\\, dx \\;+\\; \\mu \\int_{-1}^{1} u(x)\\, w(x)\\, dx,\n$$\nwhere $\\mu$ is a given real parameter, and with linear functional $\\ell(\\cdot)$ left unspecified. You are asked to:\n- Identify the standard Galerkin choice for the test space $W_N$ in terms of $V_N$.\n- Identify one Petrov–Galerkin (PG) choice for $W_N$ that is naturally induced by mapping $V_N$ through a single differentiation and multiplication by $(1-x^2)$, thereby pairing the trial space with test functions of the form $(1-x^2)\\,\\phi'(x)$ for $\\phi \\in V_N$.\n- For the standard Galerkin choice of $W_N$, consider the Rayleigh quotient\n$$\nR_p(\\mu) \\;=\\; \\frac{a(L_p, L_p)}{\\displaystyle \\int_{-1}^{1} L_p(x)^2\\, dx},\n$$\nfor a fixed integer $p$ with $0 \\le p \\le N$. Using only foundational properties of the Legendre polynomials and the given bilinear form, derive a closed-form expression for $R_p(\\mu)$ as a function of $p$ and $\\mu$.\n\nYour final answer must be the single closed-form expression for $R_p(\\mu)$. No numerical approximation is required and no units are involved.",
            "solution": "The problem statement is evaluated as valid. It is a well-posed and scientifically grounded problem in the field of numerical analysis, specifically pertaining to spectral Galerkin methods. It is self-contained, and its terms are defined with sufficient rigor to permit a unique solution.\n\nThe problem asks for three distinct items: the identification of a standard Galerkin test space, the identification of a specific Petrov-Galerkin test space, and the derivation of a closed-form expression for a Rayleigh quotient. We will address these sequentially.\n\nFirst, we identify the standard Galerkin choice for the test space $W_N$. The Galerkin method is defined by the condition that the test space is identical to the trial space. Given the trial space $V_N = \\operatorname{span}\\{L_0, L_1, \\dots, L_N\\}$, the standard Galerkin choice for the test space is:\n$$\nW_N = V_N = \\operatorname{span}\\{L_0, L_1, \\dots, L_N\\}\n$$\n\nSecond, we identify the Petrov-Galerkin (PG) test space described in the problem. The problem states that this space is \"naturally induced by mapping $V_N$ through a single differentiation and multiplication by $(1-x^2)$\". This means that for any trial function $\\phi \\in V_N$, the corresponding test function is of the form $(1-x^2)\\phi'(x)$. Therefore, the test space $W_N$ is the set of all such functions:\n$$\nW_N = \\left\\{ (1-x^2)\\phi'(x) \\mid \\phi \\in V_N \\right\\}\n$$\nSince $V_N$ is a linear space, this set is also a linear space. Specifically, as $\\phi$ ranges over the basis $\\{L_0, L_1, \\dots, L_N\\}$ of $V_N$, the space $W_N$ is spanned by the functions $\\{(1-x^2)L_n'(x)\\}_{n=0}^N$. Note that $L_0(x)=1$, so $L_0'(x)=0$, and the first basis function is zero.\n$$\nW_N = \\operatorname{span}\\{(1-x^2)L_1'(x), \\dots, (1-x^2)L_N'(x)\\}\n$$\n\nThird, we derive the closed-form expression for the Rayleigh quotient $R_p(\\mu)$ for a fixed integer $p$ such that $0 \\le p \\le N$. The Rayleigh quotient is defined as:\n$$\nR_p(\\mu) = \\frac{a(L_p, L_p)}{\\displaystyle \\int_{-1}^{1} L_p(x)^2\\, dx}\n$$\nThe bilinear form $a(u,w)$ is given by:\n$$\na(u,w) = \\int_{-1}^{1} (1-x^2)\\, u'(x)\\, w'(x)\\, dx + \\mu \\int_{-1}^{1} u(x)\\, w(x)\\, dx\n$$\nSubstituting $u = w = L_p$ into the bilinear form, we obtain the numerator of the Rayleigh quotient:\n$$\na(L_p, L_p) = \\int_{-1}^{1} (1-x^2)\\, (L_p'(x))^2\\, dx + \\mu \\int_{-1}^{1} (L_p(x))^2\\, dx\n$$\nWe need to evaluate the two integrals in this expression.\n\nThe second integral is a direct application of the orthogonality property of Legendre polynomials, which states that for any integers $m, n \\ge 0$:\n$$\n\\int_{-1}^{1} L_m(x) L_n(x)\\, dx = \\frac{2}{2n+1} \\delta_{mn}\n$$\nwhere $\\delta_{mn}$ is the Kronecker delta. For $m=n=p$, this gives:\n$$\n\\int_{-1}^{1} (L_p(x))^2\\, dx = \\frac{2}{2p+1}\n$$\nThis is also the denominator of the Rayleigh quotient.\n\nNow we evaluate the first integral, $\\int_{-1}^{1} (1-x^2)\\, (L_p'(x))^2\\, dx$. We use the defining differential equation for Legendre polynomials, known as Legendre's equation:\n$$\n\\frac{d}{dx}\\left[ (1-x^2) \\frac{dy}{dx} \\right] + \\lambda y = 0\n$$\nThe Legendre polynomial $L_p(x)$ is the solution to this equation with the eigenvalue $\\lambda = p(p+1)$. Thus, $L_p(x)$ satisfies:\n$$\n\\frac{d}{dx}\\left[ (1-x^2) L_p'(x) \\right] + p(p+1)L_p(x) = 0\n$$\nTo evaluate the integral, we use integration by parts. The following identity can be derived by integrating the term $\\int_{-1}^{1} L_p(x) \\frac{d}{dx}\\left[ (1-x^2) L_p'(x) \\right] dx$ by parts:\n$$\n\\int_{-1}^{1} L_p(x) \\frac{d}{dx}\\left( (1-x^2) L_p'(x) \\right) dx = \\left[ L_p(x) (1-x^2) L_p'(x) \\right]_{-1}^{1} - \\int_{-1}^{1} (1-x^2) (L_p'(x))^2\\, dx\n$$\nThe boundary term evaluates to zero because the factor $(1-x^2)$ is zero at both $x=1$ and $x=-1$. The functions $L_p(x)$ and $L_p'(x)$ are finite at these points. Thus, the identity simplifies to:\n$$\n\\int_{-1}^{1} L_p(x) \\frac{d}{dx}\\left( (1-x^2) L_p'(x) \\right) dx = - \\int_{-1}^{1} (1-x^2) (L_p'(x))^2\\, dx\n$$\nFrom the Legendre differential equation, we substitute $\\frac{d}{dx}\\left( (1-x^2) L_p'(x) \\right) = -p(p+1)L_p(x)$ into the left side of this identity:\n$$\n\\int_{-1}^{1} L_p(x) \\left( -p(p+1)L_p(x) \\right) dx = - \\int_{-1}^{1} (1-x^2) (L_p'(x))^2\\, dx\n$$\n$$\n-p(p+1) \\int_{-1}^{1} (L_p(x))^2\\, dx = - \\int_{-1}^{1} (1-x^2) (L_p'(x))^2\\, dx\n$$\nThis directly gives the required identity:\n$$\n\\int_{-1}^{1} (1-x^2) (L_p'(x))^2\\, dx = p(p+1) \\int_{-1}^{1} (L_p(x))^2\\, dx\n$$\nUsing the orthogonality result, we find:\n$$\n\\int_{-1}^{1} (1-x^2) (L_p'(x))^2\\, dx = p(p+1) \\left( \\frac{2}{2p+1} \\right)\n$$\nNow we can write the full expression for the numerator $a(L_p, L_p)$:\n$$\na(L_p, L_p) = p(p+1) \\left( \\frac{2}{2p+1} \\right) + \\mu \\left( \\frac{2}{2p+1} \\right) = \\left( p(p+1) + \\mu \\right) \\left( \\frac{2}{2p+1} \\right)\n$$\nFinally, we compute the Rayleigh quotient by dividing $a(L_p, L_p)$ by the denominator $\\int_{-1}^{1} (L_p(x))^2\\, dx = \\frac{2}{2p+1}$:\n$$\nR_p(\\mu) = \\frac{\\left( p(p+1) + \\mu \\right) \\left( \\frac{2}{2p+1} \\right)}{\\left( \\frac{2}{2p+1} \\right)}\n$$\nThe term $\\frac{2}{2p+1}$ cancels, yielding the final closed-form expression:\n$$\nR_p(\\mu) = p(p+1) + \\mu\n$$\nThis result is valid for any integer $p \\ge 0$. For $p=0$, $L_0(x)=1$ and $L_0'(x)=0$, so $a(L_0,L_0) = \\int_{-1}^1 0 dx + \\mu \\int_{-1}^1 1^2 dx = 2\\mu$. The denominator is $\\int_{-1}^1 1^2 dx = 2$. $R_0(\\mu) = 2\\mu/2 = \\mu$. Our formula gives $0(0+1)+\\mu = \\mu$, which is consistent.\nThis expression represents the eigenvalue of the differential operator $-\\frac{d}{dx}((1-x^2)\\frac{d}{dx}) + \\mu$ when applied to its eigenfunction $L_p(x)$.",
            "answer": "$$\n\\boxed{p(p+1) + \\mu}\n$$"
        },
        {
            "introduction": "Numerical methods are ultimately implemented on computers, which requires us to replace continuous integrals with discrete sums through numerical quadrature. This practice  investigates the profound effect of this transition, showing how a specific choice of nodal basis and quadrature points can diagonalize the mass matrix—a technique known as mass lumping. You will quantify the error introduced by this approximation, gaining insight into the trade-offs between computational efficiency and accuracy.",
            "id": "3425399",
            "problem": "Let $P_n(x)$ denote the Legendre polynomial of degree $n$ on the interval $[-1,1]$, orthogonal with respect to the continuous inner product $\\langle u,v\\rangle := \\int_{-1}^{1} u(x)\\,v(x)\\,dx$. Let $\\{x_i\\}_{i=0}^{N}$ be the Gauss–Lobatto–Legendre (GLL) nodes on $[-1,1]$ for degree $N$, which are the $N+1$ points consisting of the endpoints $x_0=-1$, $x_N=1$ and the $N-1$ interior roots of $(1-x^2)P_N'(x)$. Let $\\{w_i\\}_{i=0}^{N}$ be the corresponding GLL weights such that the Gauss–Lobatto–Legendre quadrature is exact for integrands of degree at most $2N-1$, and let $\\ell_j(x)$ be the nodal Lagrange basis of degree $N$ defined by $\\ell_j(x_i)=\\delta_{ij}$ for $0\\le i,j\\le N$.\n\nConsider the polynomial trial space $V_N=\\{p:\\deg p\\le N\\}$ and take the test space to be $V_N$ as well. Define the discrete inner product induced by the Gauss–Lobatto–Legendre quadrature by $\\langle u,v\\rangle_Q := \\sum_{i=0}^{N} w_i\\,u(x_i)\\,v(x_i)$.\n\nUsing only foundational facts about Legendre polynomials and Gauss–Lobatto–Legendre quadrature (orthogonality of $\\{P_n\\}$ and quadrature exactness up to degree $2N-1$), do the following:\n\n1) Construct the nodal Lagrange basis $\\{\\ell_j\\}_{j=0}^{N}$ at the Gauss–Lobatto–Legendre nodes by giving a closed-form expression for $\\ell_j(x)$ in terms of $\\{x_i\\}_{i=0}^{N}$.\n\n2) Explain why, with the discrete inner product $\\langle\\cdot,\\cdot\\rangle_Q$, the trial and test spaces are identified by a diagonal mass matrix in the nodal basis. Then, quantify precisely how replacing the continuous inner product $\\langle\\cdot,\\cdot\\rangle$ by the discrete inner product $\\langle\\cdot,\\cdot\\rangle_Q$ alters the relation between the trial and test spaces by characterizing the difference between the continuous and discrete mass matrices in the nodal basis. In particular, show that this difference is supported only along the degree-$N$ Legendre mode and thereby reduces to a rank-one correction determined by a single scalar coefficient that depends only on $N$.\n\nLet $\\boldsymbol{p}\\in\\mathbb{R}^{N+1}$ denote the vector of samples of the degree-$N$ Legendre polynomial at the Gauss–Lobatto–Legendre nodes, $\\boldsymbol{p}_i := P_N(x_i)$, and let $\\boldsymbol{W}=\\operatorname{diag}(w_0,\\dots,w_N)$. Let $\\boldsymbol{M}$ be the exact mass matrix with entries $\\boldsymbol{M}_{ij} = \\int_{-1}^{1} \\ell_i(x)\\,\\ell_j(x)\\,dx$. Define $\\alpha_N$ to be the unique scalar such that the difference $\\boldsymbol{M}-\\boldsymbol{W}$ equals $\\alpha_N\\,(\\boldsymbol{W}\\boldsymbol{p})(\\boldsymbol{W}\\boldsymbol{p})^{\\top}$.\n\nDetermine $\\alpha_N$ in closed form as a function of $N$. Your final answer must be a single closed-form analytic expression for $\\alpha_N$.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It is based on standard, verifiable principles of numerical analysis and polynomial approximation theory. The required data and definitions are provided, and no contradictions are apparent. Therefore, the problem is deemed valid and a full solution can be constructed.\n\nThe problem asks for several related tasks. We will address them in order.\n\n1) Construct the nodal Lagrange basis $\\{\\ell_j\\}_{j=0}^{N}$.\n2) Explain the structure of the discrete mass matrix and characterize its difference from the continuous mass matrix.\n3) Determine the scalar coefficient $\\alpha_N$.\n\nHere, $V_N = \\text{span}\\{\\ell_j(x)\\}_{j=0}^N = \\text{span}\\{P_k(x)\\}_{k=0}^N$ is the space of polynomials of degree at most $N$.\n\n**1. Nodal Lagrange Basis**\n\nThe nodal Lagrange basis polynomial $\\ell_j(x) \\in V_N$ is defined by the property $\\ell_j(x_i) = \\delta_{ij}$, where $\\{x_i\\}_{i=0}^N$ are the Gauss-Lobatto-Legendre (GLL) nodes and $\\delta_{ij}$ is the Kronecker delta. The unique polynomial of degree at most $N$ satisfying these $N+1$ conditions is given by the standard formula for Lagrange interpolating polynomials:\n$$\n\\ell_j(x) = \\prod_{\\substack{k=0 \\\\ k \\neq j}}^{N} \\frac{x-x_k}{x_j-x_k}\n$$\nThis is the closed-form expression for $\\ell_j(x)$ in terms of the GLL nodes.\n\n**2. Discrete Mass Matrix and its Relation to the Continuous Mass Matrix**\n\nThe problem asks to explain why the discrete inner product $\\langle\\cdot,\\cdot\\rangle_Q$ identifies the trial and test spaces by a diagonal mass matrix in the nodal basis $\\{\\ell_j\\}_{j=0}^N$. The matrix associated with an inner product is called a mass matrix. The discrete mass matrix, let us call it $\\boldsymbol{M}_Q$, has entries given by the discrete inner product of the basis functions:\n$$\n(\\boldsymbol{M}_Q)_{ij} = \\langle \\ell_i, \\ell_j \\rangle_Q := \\sum_{k=0}^{N} w_k \\ell_i(x_k) \\ell_j(x_k)\n$$\nBy the definition of the Lagrange basis, $\\ell_i(x_k) = \\delta_{ik}$ and $\\ell_j(x_k) = \\delta_{jk}$. Substituting these into the sum:\n$$\n(\\boldsymbol{M}_Q)_{ij} = \\sum_{k=0}^{N} w_k \\delta_{ik} \\delta_{jk}\n$$\nThe term $\\delta_{ik}\\delta_{jk}$ is non-zero only if $k=i$ and $k=j$ simultaneously, which means it is non-zero only if $i=j$ and $k=i$. The sum therefore collapses to a single term when $i=j$, and is zero if $i \\neq j$.\n$$\n(\\boldsymbol{M}_Q)_{ij} = w_i \\delta_{ij}\n$$\nThis shows that $\\boldsymbol{M}_Q$ is a diagonal matrix whose diagonal entries are the quadrature weights, $(\\boldsymbol{M}_Q)_{ii} = w_i$. This matrix is precisely the matrix $\\boldsymbol{W} = \\operatorname{diag}(w_0, \\dots, w_N)$ defined in the problem. The orthogonality of the nodal basis under the discrete inner product, $\\langle \\ell_i, \\ell_j \\rangle_Q = w_i\\delta_{ij}$, results in a diagonal (or \"lumped\") mass matrix.\n\nNext, we characterize the difference $\\boldsymbol{M}-\\boldsymbol{W}$. The entries of this difference matrix are given by:\n$$\n(\\boldsymbol{M}-\\boldsymbol{W})_{ij} = \\boldsymbol{M}_{ij} - w_i\\delta_{ij} = \\int_{-1}^{1} \\ell_i(x)\\ell_j(x)\\,dx - \\sum_{k=0}^{N} w_k \\ell_i(x_k)\\ell_j(x_k)\n$$\nThis difference is the error of the GLL quadrature rule when applied to the function $\\ell_i(x)\\ell_j(x)$. The degree of this polynomial is at most $N+N=2N$. The GLL quadrature with $N+1$ nodes is exact for polynomials of degree at most $2N-1$. Therefore, a non-zero error can only occur for polynomials of degree $2N$.\n\nLet's test the action of the error matrix $\\boldsymbol{E} = \\boldsymbol{M}-\\boldsymbol{W}$ on a vector $\\boldsymbol{v} \\in \\mathbb{R}^{N+1}$ that represents the nodal values of a polynomial $v(x) \\in \\mathbb{P}_{N-1}$ (the space of polynomials of degree at most $N-1$). The corresponding polynomial is $v(x) = \\sum_{j=0}^N v_j \\ell_j(x)$, where $v_j = v(x_j)$. The $i$-th component of the matrix-vector product $\\boldsymbol{E}\\boldsymbol{v}$ is:\n$$\n(\\boldsymbol{E}\\boldsymbol{v})_i = \\sum_{j=0}^{N} E_{ij}v_j = \\sum_{j=0}^{N} \\left(\\langle \\ell_i, \\ell_j \\rangle - w_i\\delta_{ij}\\right) v_j = \\langle \\ell_i, \\sum_{j=0}^{N} v_j\\ell_j \\rangle - \\sum_{j=0}^{N}w_i\\delta_{ij}v_j = \\langle \\ell_i, v \\rangle - w_iv_i\n$$\nThe second term can be written as $\\langle \\ell_i, v \\rangle_Q$. Thus, $(\\boldsymbol{E}\\boldsymbol{v})_i = \\langle \\ell_i, v \\rangle - \\langle \\ell_i, v \\rangle_Q$. This is the quadrature error for the polynomial $\\ell_i(x)v(x)$. The degree of this polynomial is at most $\\deg(\\ell_i) + \\deg(v) \\le N + (N-1) = 2N-1$. Since the GLL quadrature is exact for polynomials of this degree, the error is zero.\n$$\n(\\boldsymbol{E}\\boldsymbol{v})_i = 0\n$$\nThis holds for all $i=0,\\dots,N$. Thus, $\\boldsymbol{E}\\boldsymbol{v}=\\boldsymbol{0}$ for any vector $\\boldsymbol{v}$ representing a polynomial in $\\mathbb{P}_{N-1}$. The space of such vectors has dimension $N$. Since $\\boldsymbol{E}$ is an $(N+1)\\times(N+1)$ matrix, its null space has dimension at least $N$, which implies that its rank is at most $1$. Since the quadrature is not exact for degree $2N$, the error is not identically zero, so $\\mathrm{rank}(\\boldsymbol{E})=1$. A rank-one matrix represents an operator whose range is a one-dimensional subspace, which in this case corresponds to the component of the polynomials that is in $\\mathbb{P}_N$ but not in $\\mathbb{P}_{N-1}$. This component is spanned by the Legendre polynomial $P_N(x)$. This confirms that the difference between the mass matrices is a rank-one correction supported along the degree-$N$ Legendre mode.\n\n**3. Determination of $\\alpha_N$**\n\nWe start from the given identity:\n$$\n\\boldsymbol{M} - \\boldsymbol{W} = \\alpha_N (\\boldsymbol{W}\\boldsymbol{p})(\\boldsymbol{W}\\boldsymbol{p})^{\\top}\n$$\nwhere $\\boldsymbol{p}$ is the vector of nodal values of $P_N(x)$, i.e., $p_i = P_N(x_i)$. To find $\\alpha_N$, we can project this matrix equation onto the vector $\\boldsymbol{p}$:\n$$\n(\\boldsymbol{M} - \\boldsymbol{W})\\boldsymbol{p} = \\alpha_N (\\boldsymbol{W}\\boldsymbol{p})(\\boldsymbol{W}\\boldsymbol{p})^{\\top}\\boldsymbol{p}\n$$\nLet's analyze the right-hand side (RHS) first. The term $(\\boldsymbol{W}\\boldsymbol{p})^{\\top}\\boldsymbol{p}$ is a scalar:\n$$\n(\\boldsymbol{W}\\boldsymbol{p})^{\\top}\\boldsymbol{p} = \\sum_{i=0}^N (w_i p_i) p_i = \\sum_{i=0}^N w_i P_N(x_i)^2 = \\langle P_N, P_N \\rangle_Q\n$$\nSo, the RHS is the vector $\\alpha_N \\langle P_N, P_N \\rangle_Q (\\boldsymbol{W}\\boldsymbol{p})$.\n\nNow, let's analyze the left-hand side (LHS), $(\\boldsymbol{M} - \\boldsymbol{W})\\boldsymbol{p} = \\boldsymbol{M}\\boldsymbol{p} - \\boldsymbol{W}\\boldsymbol{p}$. The $i$-th component of $\\boldsymbol{M}\\boldsymbol{p}$ is:\n$$\n(\\boldsymbol{M}\\boldsymbol{p})_i = \\sum_{j=0}^{N} \\boldsymbol{M}_{ij}p_j = \\sum_{j=0}^{N} \\left(\\int_{-1}^{1} \\ell_i(x)\\ell_j(x)\\,dx\\right) P_N(x_j) = \\int_{-1}^{1} \\ell_i(x) \\left(\\sum_{j=0}^{N} P_N(x_j)\\ell_j(x)\\right)\\,dx\n$$\nThe sum $\\sum_{j=0}^{N} P_N(x_j)\\ell_j(x)$ is the unique polynomial in $V_N$ that interpolates $P_N(x)$ at the $N+1$ GLL nodes. Since $P_N(x)$ is itself in $V_N$, this interpolant is exactly $P_N(x)$. Therefore:\n$$\n(\\boldsymbol{M}\\boldsymbol{p})_i = \\int_{-1}^{1} \\ell_i(x)P_N(x)\\,dx = \\langle \\ell_i, P_N \\rangle\n$$\nThe $i$-th component of the LHS vector is thus $\\langle \\ell_i, P_N \\rangle - (\\boldsymbol{W}\\boldsymbol{p})_i = \\langle \\ell_i, P_N \\rangle - w_i p_i$.\n\nEquating the $i$-th components of the LHS and RHS:\n$$\n\\langle \\ell_i, P_N \\rangle - w_i p_i = \\alpha_N \\langle P_N, P_N \\rangle_Q (w_i p_i)\n$$\nTo eliminate the basis function $\\ell_i$, we multiply by $p_i = P_N(x_i)$ and sum over $i$:\n$$\n\\sum_{i=0}^N p_i (\\langle \\ell_i, P_N \\rangle - w_i p_i) = \\sum_{i=0}^N p_i \\left( \\alpha_N \\langle P_N, P_N \\rangle_Q (w_i p_i) \\right)\n$$\nThe LHS becomes:\n$$\n\\sum_{i=0}^N P_N(x_i) \\langle \\ell_i, P_N \\rangle - \\sum_{i=0}^N w_i P_N(x_i)^2 = \\int_{-1}^{1} \\left(\\sum_{i=0}^N P_N(x_i)\\ell_i(x)\\right)P_N(x)\\,dx - \\langle P_N, P_N \\rangle_Q\n$$\nUsing $\\sum_{i=0}^N P_N(x_i)\\ell_i(x) = P_N(x)$, the LHS simplifies to $\\langle P_N, P_N \\rangle - \\langle P_N, P_N \\rangle_Q$.\n\nThe RHS becomes:\n$$\n\\alpha_N \\langle P_N, P_N \\rangle_Q \\sum_{i=0}^N w_i P_N(x_i)^2 = \\alpha_N \\langle P_N, P_N \\rangle_Q \\langle P_N, P_N \\rangle_Q = \\alpha_N \\left( \\langle P_N, P_N \\rangle_Q \\right)^2\n$$\nEquating the simplified LHS and RHS:\n$$\n\\langle P_N, P_N \\rangle - \\langle P_N, P_N \\rangle_Q = \\alpha_N \\left( \\langle P_N, P_N \\rangle_Q \\right)^2\n$$\nSolving for $\\alpha_N$:\n$$\n\\alpha_N = \\frac{\\langle P_N, P_N \\rangle - \\langle P_N, P_N \\rangle_Q}{\\left( \\langle P_N, P_N \\rangle_Q \\right)^2}\n$$\nTo evaluate this expression, we use two foundational facts:\n1. The orthogonality property of Legendre polynomials gives the continuous inner product:\n$$\n\\langle P_N, P_N \\rangle = \\int_{-1}^{1} [P_N(x)]^2\\,dx = \\frac{2}{2N+1}\n$$\n2. A property of the GLL quadrature weights is $w_i = \\frac{2}{N(N+1)[P_N(x_i)]^2}$ for all nodes $i=0, \\dots, N$. This allows us to compute the discrete inner product:\n$$\n\\langle P_N, P_N \\rangle_Q = \\sum_{i=0}^{N} w_i [P_N(x_i)]^2 = \\sum_{i=0}^{N} \\frac{2}{N(N+1)[P_N(x_i)]^2} [P_N(x_i)]^2 = \\sum_{i=0}^{N} \\frac{2}{N(N+1)}\n$$\nSince there are $N+1$ terms in the sum:\n$$\n\\langle P_N, P_N \\rangle_Q = (N+1) \\frac{2}{N(N+1)} = \\frac{2}{N}\n$$\nSubstituting these results into the expression for $\\alpha_N$:\n$$\n\\alpha_N = \\frac{\\frac{2}{2N+1} - \\frac{2}{N}}{\\left(\\frac{2}{N}\\right)^2} = \\frac{2\\left(\\frac{N - (2N+1)}{N(2N+1)}\\right)}{\\frac{4}{N^2}} = \\frac{2\\left(\\frac{-N-1}{N(2N+1)}\\right)}{\\frac{4}{N^2}}\n$$\n$$\n\\alpha_N = -\\frac{2(N+1)}{N(2N+1)} \\cdot \\frac{N^2}{4} = -\\frac{N(N+1)}{2(2N+1)}\n$$\nThis is the closed-form expression for $\\alpha_N$.",
            "answer": "$$\\boxed{-\\frac{N(N+1)}{2(2N+1)}}$$"
        },
        {
            "introduction": "In many advanced applications, strongly enforcing boundary conditions on the trial space is either inconvenient or impossible. This is where the flexibility of the weak formulation shines, as demonstrated by Nitsche’s method. This exercise  guides you through the process of modifying a bilinear form to weakly impose Dirichlet conditions, introducing a penalty term whose scaling is critical for the stability of the entire scheme.",
            "id": "3425415",
            "problem": "Consider the second-order elliptic boundary value problem on a bounded Lipschitz domain $\\Omega \\subset \\mathbb{R}^{d}$ with boundary $\\Gamma := \\partial \\Omega$:\n$$\n-\\nabla \\cdot (\\kappa \\nabla u) = f \\quad \\text{in } \\Omega, \n\\qquad\nu = g \\quad \\text{on } \\Gamma,\n$$\nwhere $\\kappa > 0$ is a constant diffusion coefficient, $f \\in L^{2}(\\Omega)$, and $g \\in H^{1/2}(\\Gamma)$. Let $\\mathcal{T}_{h}$ be a shape-regular, quasi-uniform mesh of $\\Omega$ with characteristic mesh size $h$, and let $V_{h} \\subset H^{1}(\\Omega)$ be a conforming space of continuous, piecewise polynomials of degree $p \\ge 1$ on $\\mathcal{T}_{h}$ (typical of high-order spectral element discretizations). The test space is taken equal to the trial space, i.e., the Galerkin method is based on $V_{h} \\times V_{h}$.\n\nFormulate Nitsche’s method that imposes the Dirichlet boundary condition weakly using a symmetric, consistent bilinear form and a boundary penalty term with parameter $\\gamma = \\gamma(h,p,\\kappa) > 0$. Then, starting from first principles (integration by parts, Cauchy–Schwarz inequality, Young’s inequality, and standard polynomial inverse/trace estimates on shape-regular meshes), derive a sufficient lower bound scaling for $\\gamma$ in terms of $h$ and $p$ that guarantees coercivity of the discrete bilinear form on $V_{h}$ with respect to the energy norm. Interpret “without over-penalization” as identifying the asymptotically minimal scaling in $h$ and $p$ (up to multiplicative constants independent of $h$ and $p$) that ensures coercivity.\n\nProvide, as your final answer, the asymptotically minimal penalty scaling $\\gamma(h,p,\\kappa)$ in closed form, ignoring any universal multiplicative constants that are independent of $h$ and $p$. No numerical rounding is required and no units should be included in the final expression. The final answer must be a single analytic expression.",
            "solution": "The user wants me to solve a problem on Nitsche's method for a second-order elliptic PDE.\n\n**1. Problem Validation**\n\nThe user wants me to solve a problem on Nitsche's method for a second-order elliptic PDE. The problem statement is:\nConsider the second-order elliptic boundary value problem on a bounded Lipschitz domain $\\Omega \\subset \\mathbb{R}^{d}$ with boundary $\\Gamma := \\partial \\Omega$:\n$$\n-\\nabla \\cdot (\\kappa \\nabla u) = f \\quad \\text{in } \\Omega, \n\\qquad\nu = g \\quad \\text{on } \\Gamma,\n$$\nwhere $\\kappa > 0$ is a constant diffusion coefficient, $f \\in L^{2}(\\Omega)$, and $g \\in H^{1/2}(\\Gamma)$. Let $\\mathcal{T}_{h}$ be a shape-regular, quasi-uniform mesh of $\\Omega$ with characteristic mesh size $h$, and let $V_{h} \\subset H^{1}(\\Omega)$ be a conforming space of continuous, piecewise polynomials of degree $p \\ge 1$ on a shape-regular, quasi-uniform mesh $\\mathcal{T}_{h}$ with mesh size $h$.\nThe test space is taken equal to the trial space, i.e., the Galerkin method is based on $V_{h} \\times V_{h}$.\n\nFormulate Nitsche’s method that imposes the Dirichlet boundary condition weakly using a symmetric, consistent bilinear form and a boundary penalty term with parameter $\\gamma > 0$. Then, starting from first principles (integration by parts, Cauchy–Schwarz inequality, Young’s inequality, and standard polynomial inverse/trace estimates on shape-regular meshes), derive a sufficient lower bound scaling for $\\gamma(h, p, \\kappa)$ that guarantees coercivity of the discrete bilinear form on $V_{h}$ with respect to the energy norm. Interpret “without over-penalization” as identifying the asymptotically minimal scaling in $h$ and $p$ (up to multiplicative constants independent of $h$ and $p$) that ensures coercivity.\n\n- **Step 1: Extract Givens**\n    - PDE: $-\\nabla \\cdot (\\kappa \\nabla u) = f$ in $\\Omega$.\n    - Boundary Condition: $u = g$ on $\\Gamma$.\n    - Domain: $\\Omega \\subset \\mathbb{R}^{d}$ is a bounded Lipschitz domain.\n    - Coefficient: $\\kappa > 0$ is a constant.\n    - Source term: $f \\in L^{2}(\\Omega)$.\n    - Boundary data: $g \\in H^{1/2}(\\Gamma)$.\n    - Discretization: $V_{h} \\subset H^{1}(\\Omega)$ is a space of continuous, piecewise polynomials of degree $p \\ge 1$ on a shape-regular, quasi-uniform mesh $\\mathcal{T}_{h}$ with mesh size $h$.\n    - Method: Symmetric Nitsche's method with penalty parameter $\\gamma > 0$.\n    - Task: Derive the asymptotically minimal scaling for $\\gamma(h, p, \\kappa)$ that ensures coercivity of the discrete bilinear form.\n\n- **Step 2: Validate Using Extracted Givens**\n    - The problem is **scientifically grounded**. It is a standard, fundamental problem in the numerical analysis of finite element methods for PDEs.\n    - The problem is **well-posed**. It asks for a specific derivation that leads to a unique analytical scaling law.\n    - The problem is stated with **objective**, standard mathematical language.\n    - The setup is **complete and consistent**. All necessary components for the derivation (PDE, function spaces, method type) are specified. The reference to \"standard polynomial inverse/trace estimates\" is appropriate, as these are staple tools in the field.\n\n- **Step 3: Verdict and Action**\n    - The problem is deemed **valid**. A full solution will be provided.\n\n**2. Formulation of Symmetric Nitsche's Method**\n\nWe begin with the strong form of the problem: $-\\nabla \\cdot (\\kappa \\nabla u) = f$. To derive a weak formulation, we multiply by a test function $v \\in V_h$ and integrate over the domain $\\Omega$.\n$$\n- \\int_{\\Omega} v (\\nabla \\cdot (\\kappa \\nabla u)) \\, d\\Omega = \\int_{\\Omega} v f \\, d\\Omega\n$$\nApplying integration by parts (Green's first identity), we obtain:\n$$\n\\int_{\\Omega} \\kappa \\nabla u \\cdot \\nabla v \\, d\\Omega - \\int_{\\Gamma} v (\\kappa \\nabla u \\cdot \\mathbf{n}) \\, d\\Gamma = \\int_{\\Omega} f v \\, d\\Omega\n$$\nwhere $\\mathbf{n}$ is the outward-pointing unit normal vector on $\\Gamma$. We denote the normal derivative $\\nabla u \\cdot \\mathbf{n}$ as $\\frac{\\partial u}{\\partial \\mathbf{n}}$.\n\nThe standard Galerkin method would require the trial space to satisfy the Dirichlet boundary conditions. Nitsche's method imposes this condition weakly. The symmetric variant is constructed to be consistent and symmetric. We seek a discrete solution $u_h \\in V_h$ such that for all test functions $v_h \\in V_h$, the following equation holds:\n$$\nB(u_h, v_h) = F(v_h)\n$$\nThe bilinear form $B(u, v)$ and linear functional $F(v)$ are constructed as follows. We start with the left-hand side from integration by parts, $\\int_{\\Omega} \\kappa \\nabla u_h \\cdot \\nabla v_h \\, d\\Omega$, and subtract terms to enforce the boundary condition. We subtract a term involving the normal flux of $u_h$ and add a symmetric counterpart involving the normal flux of $v_h$. We also add a penalty term to ensure stability.\nThe resulting symmetric Nitsche formulation is: find $u_h \\in V_h$ such that for all $v_h \\in V_h$:\n$$\n\\int_{\\Omega} \\kappa \\nabla u_h \\cdot \\nabla v_h \\, d\\Omega - \\int_{\\Gamma} \\kappa v_h \\frac{\\partial u_h}{\\partial \\mathbf{n}} \\, d\\Gamma - \\int_{\\Gamma} \\kappa (u_h - g) \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\, d\\Gamma + \\int_{\\Gamma} \\gamma (u_h - g) v_h \\, d\\Gamma = \\int_{\\Omega} f v_h \\, d\\Omega\n$$\nThis method is consistent because if the exact solution $u$ is inserted, the terms involving $(u-g)$ vanish on $\\Gamma$, and the equation reduces to the original weak form.\n\nBy rearranging the terms, we can identify the bilinear form $B(u_h, v_h)$ and the linear form $F(v_h)$:\n$$\nB(u_h, v_h) = \\int_{\\Omega} \\kappa \\nabla u_h \\cdot \\nabla v_h \\, d\\Omega - \\int_{\\Gamma} \\kappa v_h \\frac{\\partial u_h}{\\partial \\mathbf{n}} \\, d\\Gamma - \\int_{\\Gamma} \\kappa u_h \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\, d\\Gamma + \\int_{\\Gamma} \\gamma u_h v_h \\, d\\Gamma\n$$\n$$\nF(v_h) = \\int_{\\Omega} f v_h \\, d\\Omega - \\int_{\\Gamma} \\kappa g \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\, d\\Gamma + \\int_{\\Gamma} \\gamma g v_h \\, d\\Gamma\n$$\nBy inspection, the bilinear form $B(u_h, v_h)$ is symmetric.\n\n**3. Derivation of the Coercivity Condition**\n\nTo ensure the existence and uniqueness of the solution to the discrete system, the bilinear form $B(v_h, v_h)$ must be coercive on the space $V_h$. We analyze $B(v_h, v_h)$ for an arbitrary function $v_h \\in V_h$:\n$$\nB(v_h, v_h) = \\int_{\\Omega} \\kappa |\\nabla v_h|^2 \\, d\\Omega - 2\\int_{\\Gamma} \\kappa v_h \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\, d\\Gamma + \\int_{\\Gamma} \\gamma v_h^2 \\, d\\Gamma\n$$\nLet $\\| \\cdot \\|_{0,\\Omega}$ denote the $L^2(\\Omega)$-norm and $\\| \\cdot \\|_{0,\\Gamma}$ denote the $L^2(\\Gamma)$-norm. Then:\n$$\nB(v_h, v_h) = \\kappa \\|\\nabla v_h\\|_{0,\\Omega}^2 - 2\\kappa \\int_{\\Gamma} v_h \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\, d\\Gamma + \\gamma \\|v_h\\|_{0,\\Gamma}^2\n$$\nThe second term must be controlled. We apply the Cauchy-Schwarz inequality to the integral:\n$$\n\\left| -2\\kappa \\int_{\\Gamma} v_h \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\, d\\Gamma \\right| \\le 2\\kappa \\|v_h\\|_{0,\\Gamma} \\left\\| \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\right\\|_{0,\\Gamma}\n$$\nNext, we apply Young's inequality, $2ab \\le \\frac{1}{\\epsilon} a^2 + \\epsilon b^2$, for an arbitrary $\\epsilon > 0$:\n$$\n2\\kappa \\|v_h\\|_{0,\\Gamma} \\left\\| \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\right\\|_{0,\\Gamma} \\le \\frac{1}{\\epsilon} \\|v_h\\|_{0,\\Gamma}^2 + \\epsilon \\kappa^2 \\left\\| \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\right\\|_{0,\\Gamma}^2\n$$\nSubstituting this bound into the expression for $B(v_h, v_h)$:\n$$\nB(v_h, v_h) \\ge \\kappa \\|\\nabla v_h\\|_{0,\\Omega}^2 + \\gamma \\|v_h\\|_{0,\\Gamma}^2 - \\frac{1}{\\epsilon} \\|v_h\\|_{0,\\Gamma}^2 - \\epsilon \\kappa^2 \\left\\| \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\right\\|_{0,\\Gamma}^2\n$$\nGrouping the terms:\n$$\nB(v_h, v_h) \\ge \\kappa \\|\\nabla v_h\\|_{0,\\Omega}^2 - \\epsilon \\kappa^2 \\left\\| \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\right\\|_{0,\\Gamma}^2 + \\left(\\gamma - \\frac{1}{\\epsilon}\\right) \\|v_h\\|_{0,\\Gamma}^2\n$$\nTo proceed, we need to bound the norm of the normal derivative on the boundary, $\\left\\| \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\right\\|_{0,\\Gamma}$. Since $|\\frac{\\partial v_h}{\\partial \\mathbf{n}}| = |\\nabla v_h \\cdot \\mathbf{n}| \\le |\\nabla v_h|$, we have $\\left\\| \\frac{\\partial v_h}{\\partial \\mathbf{n}} \\right\\|_{0,\\Gamma} \\le \\|\\nabla v_h\\|_{0,\\Gamma}$. We now invoke a standard polynomial trace inverse inequality, which relates the norm of a function's gradient on the boundary of an element to its norm in the interior. For a function $v_h \\in V_h$, on a shape-regular mesh of size $h$, this inequality is:\n$$\n\\|\\nabla v_h\\|_{0,\\Gamma}^2 = \\sum_{F \\in \\mathcal{F}_h^{\\Gamma}} \\|\\nabla v_h\\|_{0,F}^2 \\le C_{inv} \\frac{p^2}{h} \\sum_{K \\in \\mathcal{T}_h} \\|\\nabla v_h\\|_{0,K}^2 = C_{inv} \\frac{p^2}{h} \\|\\nabla v_h\\|_{0,\\Omega}^2\n$$\nwhere $\\mathcal{F}_h^\\Gamma$ is the set of faces on the boundary $\\Gamma$, and $C_{inv}$ is a constant independent of $h$, $p$, and $\\kappa$. The scaling factor $\\frac{p^2}{h}$ is characteristic of high-order and spectral element methods.\n\nSubstituting this inequality into our bound for $B(v_h, v_h)$:\n$$\nB(v_h, v_h) \\ge \\kappa \\|\\nabla v_h\\|_{0,\\Omega}^2 - \\epsilon \\kappa^2 \\left( C_{inv} \\frac{p^2}{h} \\|\\nabla v_h\\|_{0,\\Omega}^2 \\right) + \\left(\\gamma - \\frac{1}{\\epsilon}\\right) \\|v_h\\|_{0,\\Gamma}^2\n$$\nWe collect the coefficients of the norm terms:\n$$\nB(v_h, v_h) \\ge \\kappa \\left( 1 - \\epsilon \\kappa C_{inv} \\frac{p^2}{h} \\right) \\|\\nabla v_h\\|_{0,\\Omega}^2 + \\left(\\gamma - \\frac{1}{\\epsilon}\\right) \\|v_h\\|_{0,\\Gamma}^2\n$$\nFor coercivity, we require the coefficients of both terms to be positive. This gives us two conditions:\n1. $1 - \\epsilon \\kappa C_{inv} \\frac{p^2}{h} > 0 \\implies \\epsilon < \\frac{h}{\\kappa C_{inv} p^2}$\n2. $\\gamma - \\frac{1}{\\epsilon} > 0 \\implies \\gamma > \\frac{1}{\\epsilon}$\n\nCombining these two conditions, we must be able to choose $\\epsilon$ and $\\gamma$ such that:\n$$\n\\gamma > \\frac{1}{\\epsilon} > \\kappa C_{inv} \\frac{p^2}{h}\n$$\nThis shows that for the method to be coercive, the penalty parameter $\\gamma$ must be chosen to be greater than $\\kappa C_{inv} \\frac{p^2}{h}$. A sufficient condition is to choose $\\gamma = \\gamma_0 \\kappa \\frac{p^2}{h}$ for some constant $\\gamma_0 > C_{inv}$. If this is done, we can always find an $\\epsilon$ satisfying the required inequalities (for example, any $\\epsilon$ in the interval $(\\frac{h}{\\gamma_0 \\kappa p^2}, \\frac{h}{C_{inv} \\kappa p^2})$).\n\n**4. Asymptotically Minimal Scaling**\n\nThe derivation shows that to guarantee coercivity, the penalty parameter $\\gamma$ must scale at least as fast as $\\kappa \\frac{p^2}{h}$. Choosing a scaling that grows slower than this would not allow for satisfying the necessary conditions for any choice of constant pre-factors. Thus, the asymptotically minimal scaling (without over-penalization) for the penalty parameter $\\gamma$ that ensures coercivity is proportional to $\\kappa \\frac{p^2}{h}$. The problem asks to provide this scaling in closed form, ignoring any multiplicative constants independent of $h$ and $p$.\n\nThe final expression for the scaling is therefore:\n$$\n\\gamma(h, p, \\kappa) \\sim \\kappa \\frac{p^2}{h}\n$$",
            "answer": "$$\n\\boxed{\\kappa \\frac{p^2}{h}}\n$$"
        }
    ]
}