{
    "hands_on_practices": [
        {
            "introduction": "Spectral methods are built on the idea of representing solutions as series of well-chosen basis functions. This first exercise explores how the combination of a differential operator and its boundary conditions naturally defines such a basis. By solving the 1D Laplacian eigenvalue problem with homogeneous Dirichlet conditions, you will derive the classic Fourier sine basis and reinforce your understanding of the crucial properties of orthogonality and completeness that make these functions so powerful for numerical solutions .",
            "id": "3379345",
            "problem": "Consider the one-dimensional Laplacian eigenvalue problem on the interval $(0,1)$ given by the ordinary differential equation $-u''(x) = \\lambda u(x)$, subject to homogeneous Dirichlet boundary conditions $u(0) = 0$ and $u(1) = 0$. In the framework of spectral methods and discontinuous Galerkin methods, this is a prototypical Sturm–Liouville problem whose eigenstructure underpins orthogonal expansions, stability, and convergence of numerical schemes. Starting from the foundational facts that the Dirichlet Laplacian is a self-adjoint operator on $L^{2}(0,1)$ with domain $H^{2}(0,1) \\cap H_{0}^{1}(0,1)$, and that self-adjoint Sturm–Liouville operators have real eigenvalues with orthogonal eigenfunctions forming a complete set in $L^{2}(0,1)$, carry out the following steps:\n\n1. Solve the boundary value problem $-u''(x) = \\lambda u(x)$ with $u(0) = 0$ and $u(1) = 0$ to determine all eigenpairs $(\\lambda_{n}, u_{n})$. Justify that the eigenvalues are real and the eigenfunctions corresponding to distinct eigenvalues are orthogonal in $L^{2}(0,1)$, and explain why the eigenfunctions form a complete set in $L^{2}(0,1)$.\n2. For the function $f(x) = x$ on $(0,1)$, form its Fourier sine expansion in the eigenfunction basis $\\{u_{n}\\}_{n \\ge 1}$, using the $L^{2}(0,1)$ inner product $\\langle v, w \\rangle = \\int_{0}^{1} v(x) w(x) \\,\\mathrm{d}x$. Define the expansion coefficients $b_{n}$ by the projection formula $b_{n} = \\langle f, u_{n} \\rangle / \\langle u_{n}, u_{n} \\rangle$, and determine $b_{n}$ explicitly for all $n \\ge 1$.\n3. Using orthogonality and completeness, apply Parseval’s identity for this expansion to compute the exact value of the infinite sum\n$$\nS \\;=\\; \\sum_{n=1}^{\\infty} \\frac{1}{2}\\,b_{n}^{2}.\n$$\nProvide the final result for $S$ as a single exact number. No rounding is required. The final answer must be a single real number without any units.",
            "solution": "### Part 1: Determination of Eigenpairs and Justification of Properties\n\nThe eigenvalue problem is given by the ordinary differential equation\n$$\n-u''(x) = \\lambda u(x), \\quad x \\in (0,1)\n$$\nwith homogeneous Dirichlet boundary conditions $u(0) = 0$ and $u(1) = 0$. The equation can be rewritten as $u''(x) + \\lambda u(x) = 0$. We analyze the nature of the eigenvalues $\\lambda$.\n\nCase 1: $\\lambda < 0$. Let $\\lambda = -\\mu^2$ for some $\\mu > 0$. The equation becomes $u''(x) - \\mu^2 u(x) = 0$, with the general solution $u(x) = A \\cosh(\\mu x) + B \\sinh(\\mu x)$. Applying the boundary conditions:\n$u(0) = A \\cosh(0) + B \\sinh(0) = A = 0$.\nThe solution reduces to $u(x) = B \\sinh(\\mu x)$. The second boundary condition gives $u(1) = B \\sinh(\\mu) = 0$. Since $\\mu > 0$, $\\sinh(\\mu) \\neq 0$, which implies $B=0$. This yields only the trivial solution $u(x) = 0$, so there are no negative eigenvalues.\n\nCase 2: $\\lambda = 0$. The equation is $u''(x) = 0$, with the general solution $u(x) = Ax + B$. Applying the boundary conditions:\n$u(0) = B = 0$.\n$u(1) = A \\cdot 1 = A = 0$.\nThis again yields only the trivial solution, so $\\lambda=0$ is not an eigenvalue.\n\nCase 3: $\\lambda > 0$. Let $\\lambda = k^2$ for some $k > 0$. The equation becomes $u''(x) + k^2 u(x) = 0$, with the general solution $u(x) = A \\cos(k x) + B \\sin(k x)$. Applying the boundary conditions:\n$u(0) = A \\cos(0) + B \\sin(0) = A = 0$.\nThe solution is now $u(x) = B \\sin(k x)$. The second boundary condition gives $u(1) = B \\sin(k) = 0$. To obtain a non-trivial solution, we must have $B \\neq 0$, which requires $\\sin(k) = 0$. The solutions for $k>0$ are $k = n\\pi$ for $n = 1, 2, 3, \\ldots$.\nThe eigenvalues are therefore $\\lambda_n = k_n^2 = (n\\pi)^2$ for $n \\in \\{1, 2, 3, \\ldots\\}$.\nThe corresponding eigenfunctions are $u_n(x) = B_n \\sin(n\\pi x)$. We may choose the constant $B_n=1$ for simplicity, yielding the eigenpairs:\n$$\n(\\lambda_n, u_n(x)) = ((n\\pi)^2, \\sin(n\\pi x)) \\quad \\text{for } n=1, 2, 3, \\dots\n$$\n\nJustification of properties:\nThe problem is a regular Sturm-Liouville problem for the operator $L[u] = -u''$ on the interval $[0,1]$ with the specified boundary conditions. The properties of such systems are well-established.\n1.  Real Eigenvalues: The operator $L$ with the given boundary conditions is self-adjoint on $L^2(0,1)$. Let $(\\lambda, u)$ be an eigenpair. Then $\\langle Lu, u \\rangle = \\langle \\lambda u, u \\rangle = \\lambda \\langle u, u \\rangle$. Using integration by parts and the boundary conditions $u(0)=u(1)=0$:\n    $$\n    \\langle Lu, u \\rangle = \\int_{0}^{1} -u''(x) \\overline{u(x)} \\, \\mathrm{d}x = \\left[-u'(x)\\overline{u(x)}\\right]_{0}^{1} + \\int_{0}^{1} u'(x) \\overline{u'(x)} \\, \\mathrm{d}x = \\int_{0}^{1} |u'(x)|^2 \\, \\mathrm{d}x\n    $$\n    This is a real, non-negative quantity. Since $\\langle u, u \\rangle = \\int_{0}^{1} |u(x)|^2 \\, \\mathrm{d}x > 0$ for a non-trivial eigenfunction $u$, it follows that $\\lambda = \\frac{\\int_{0}^{1} |u'(x)|^2 \\, \\mathrm{d}x}{\\int_{0}^{1} |u(x)|^2 \\, \\mathrm{d}x}$ must be real and non-negative. Our direct calculation confirms this.\n2.  Orthogonality of Eigenfunctions: Let $(\\lambda_n, u_n)$ and $(\\lambda_m, u_m)$ be two eigenpairs with $\\lambda_n \\neq \\lambda_m$. We have $Lu_n = \\lambda_n u_n$ and $Lu_m = \\lambda_m u_m$. Due to the self-adjointness of $L$:\n    $$\n    \\langle Lu_n, u_m \\rangle = \\langle u_n, Lu_m \\rangle\n    $$\n    Substituting the eigenvalue relations and using the fact that eigenvalues are real:\n    $$\n    \\langle \\lambda_n u_n, u_m \\rangle = \\langle u_n, \\lambda_m u_m \\rangle \\implies \\lambda_n \\langle u_n, u_m \\rangle = \\lambda_m \\langle u_n, u_m \\rangle\n    $$\n    This gives $(\\lambda_n - \\lambda_m) \\langle u_n, u_m \\rangle = 0$. Since $\\lambda_n \\neq \\lambda_m$, we must have $\\langle u_n, u_m \\rangle = 0$. The eigenfunctions are thus orthogonal in $L^2(0,1)$.\n3.  Completeness: A central theorem of Sturm-Liouville theory states that the set of eigenfunctions of a regular Sturm-Liouville problem forms a complete orthogonal basis for the Hilbert space $L^2$ on the interval. Since our problem is a regular Sturm-Liouville problem, the set of eigenfunctions $\\{u_n(x) = \\sin(n\\pi x)\\}_{n \\ge 1}$ is a complete basis for $L^2(0,1)$.\n\n### Part 2: Fourier Sine Expansion Coefficients\n\nWe wish to find the coefficients $b_n$ for the expansion of $f(x) = x$ in the eigenfunction basis $\\{u_n\\}_{n \\ge 1}$. The formula provided is $b_n = \\frac{\\langle f, u_n \\rangle}{\\langle u_n, u_n \\rangle}$.\n\nFirst, we compute the denominator, which is the squared $L^2$-norm of the eigenfunction $u_n(x) = \\sin(n\\pi x)$:\n$$\n\\langle u_n, u_n \\rangle = \\int_{0}^{1} \\sin^2(n\\pi x) \\, \\mathrm{d}x = \\int_{0}^{1} \\frac{1 - \\cos(2n\\pi x)}{2} \\, \\mathrm{d}x = \\frac{1}{2} \\left[ x - \\frac{\\sin(2n\\pi x)}{2n\\pi} \\right]_{0}^{1} = \\frac{1}{2} (1 - 0) = \\frac{1}{2}\n$$\n\nNext, we compute the numerator, which is the projection of $f(x)=x$ onto $u_n(x)$:\n$$\n\\langle f, u_n \\rangle = \\int_{0}^{1} x \\sin(n\\pi x) \\, \\mathrm{d}x\n$$\nUsing integration by parts with $u=x$ and $dv = \\sin(n\\pi x)dx$:\n$$\n\\int_{0}^{1} x \\sin(n\\pi x) \\, \\mathrm{d}x = \\left[ x \\left(-\\frac{\\cos(n\\pi x)}{n\\pi}\\right) \\right]_{0}^{1} - \\int_{0}^{1} \\left(-\\frac{\\cos(n\\pi x)}{n\\pi}\\right) \\, \\mathrm{d}x\n$$\n$$\n= \\left( -\\frac{1 \\cdot \\cos(n\\pi)}{n\\pi} - 0 \\right) + \\frac{1}{n\\pi} \\int_{0}^{1} \\cos(n\\pi x) \\, \\mathrm{d}x\n$$\n$$\n= -\\frac{(-1)^n}{n\\pi} + \\frac{1}{n\\pi} \\left[ \\frac{\\sin(n\\pi x)}{n\\pi} \\right]_{0}^{1} = \\frac{(-1)^{n+1}}{n\\pi} + \\frac{1}{(n\\pi)^2}(\\sin(n\\pi) - \\sin(0)) = \\frac{(-1)^{n+1}}{n\\pi}\n$$\n\nNow we combine the numerator and denominator to find $b_n$:\n$$\nb_n = \\frac{\\frac{(-1)^{n+1}}{n\\pi}}{\\frac{1}{2}} = \\frac{2(-1)^{n+1}}{n\\pi}\n$$\n\n### Part 3: Computation of the Sum using Parseval's Identity\n\nThe problem asks for the value of the sum $S = \\sum_{n=1}^{\\infty} \\frac{1}{2}\\,b_{n}^{2}$. We are to use Parseval's identity. For a function $f$ expanded in a complete orthogonal basis $\\{u_n\\}$ as $f(x) = \\sum_{n=1}^{\\infty} c_n u_n(x)$ with $c_n = \\frac{\\langle f, u_n \\rangle}{\\langle u_n, u_n \\rangle}$, Parseval's identity states:\n$$\n\\langle f, f \\rangle = \\sum_{n=1}^{\\infty} |c_n|^2 \\langle u_n, u_n \\rangle\n$$\nIn our case, $f(x)=x$, the coefficients are $b_n=c_n$, and the eigenfunctions are real. The identity becomes:\n$$\n\\int_{0}^{1} (f(x))^2 \\, \\mathrm{d}x = \\sum_{n=1}^{\\infty} b_n^2 \\langle u_n, u_n \\rangle\n$$\nSubstituting the known values $f(x)=x$ and $\\langle u_n, u_n \\rangle = 1/2$:\n$$\n\\int_{0}^{1} x^2 \\, \\mathrm{d}x = \\sum_{n=1}^{\\infty} b_n^2 \\left(\\frac{1}{2}\\right)\n$$\nThe right-hand side is precisely the sum $S$ that we need to compute. Therefore, the value of $S$ is given by the integral on the left-hand side.\n$$\nS = \\int_{0}^{1} x^2 \\, \\mathrm{d}x = \\left[ \\frac{x^3}{3} \\right]_{0}^{1} = \\frac{1^3}{3} - \\frac{0^3}{3} = \\frac{1}{3}\n$$\nThe exact value of the infinite sum is $1/3$.",
            "answer": "$$\n\\boxed{\\frac{1}{3}}\n$$"
        },
        {
            "introduction": "While the previous practice focused on the strong form of an eigenvalue problem, Galerkin methods are founded on the weak, or variational, formulation. This exercise shifts our focus to this essential framework, demonstrating how Neumann and Robin conditions are elegantly incorporated as \"natural\" boundary conditions through integration by parts. This analytical practice will deepen your understanding of the theoretical underpinnings of solvability and uniqueness, which are governed by compatibility conditions and the coercivity of the resulting bilinear form .",
            "id": "3379401",
            "problem": "Consider the one-dimensional Poisson boundary value problem on the interval $\\Omega = (-1,1)$,\n$$\n-\\frac{\\mathrm{d}^2 u}{\\mathrm{d}x^2} = f(x),\n$$\nwith mixed Neumann–Robin boundary conditions\n$$\n\\frac{\\mathrm{d}u}{\\mathrm{d}x}(-1) = g_{N}, \\qquad \\frac{\\mathrm{d}u}{\\mathrm{d}x}(1) + \\beta\\, u(1) = g_{R},\n$$\nwhere $\\beta>0$ is a given constant, and $f$, $g_{N}$, $g_{R}$ are given data. Develop the weak formulation suitable for a Legendre spectral Galerkin method and for a Discontinuous Galerkin (DG) method by starting from the fundamental definition of the weak solution based on integration by parts. Then:\n\n1. By testing with constant functions, rigorously derive the compatibility condition that ensures solvability when the Robin boundary condition is turned off (that is, when $\\beta=0$ so that the right boundary condition is Neumann), and justify uniqueness in the mixed Neumann–Robin case ($\\beta>0$) by establishing coercivity of the bilinear form with a trace term.\n\n2. For the specific data $f(x) = p\\,x + q$ with constants $p,q \\in \\mathbb{R}$, compute the exact solution and determine the mean value $\\overline{u} = \\frac{1}{2}\\int_{-1}^{1} u(x)\\,\\mathrm{d}x$ as a closed-form expression in terms of $p$, $q$, $g_{N}$, $g_{R}$, and $\\beta$. Express your final answer for $\\overline{u}$ as a single analytic expression. No rounding is required.",
            "solution": "### Derivation of the Weak Formulation\n\nTo derive the weak formulation, we start with the strong form of the problem. We seek a solution $u$ in a suitable function space, which for this problem is the Sobolev space $H^1(\\Omega)$. We multiply the PDE by an arbitrary test function $v \\in H^1(\\Omega)$ and integrate over the domain $\\Omega = (-1, 1)$:\n$$\n-\\int_{-1}^{1} \\frac{\\mathrm{d}^2 u}{\\mathrm{d}x^2} v(x) \\,\\mathrm{d}x = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x\n$$\nWe apply integration by parts to the left-hand side:\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x - \\left[ \\frac{\\mathrm{d}u}{\\mathrm{d}x}(x) v(x) \\right]_{-1}^{1} = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x\n$$\nExpanding the boundary terms, we get:\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x - \\frac{\\mathrm{d}u}{\\mathrm{d}x}(1)v(1) + \\frac{\\mathrm{d}u}{\\mathrm{d}x}(-1)v(-1) = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x\n$$\nNow, we incorporate the boundary conditions. The Neumann condition $\\frac{\\mathrm{d}u}{\\mathrm{d}x}(-1) = g_N$ is a natural boundary condition and can be substituted directly. The Robin condition gives $\\frac{\\mathrm{d}u}{\\mathrm{d}x}(1) = g_R - \\beta u(1)$, which is also substituted.\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x - (g_R - \\beta u(1))v(1) + g_N v(-1) = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x\n$$\nRearranging the terms to group those involving the unknown solution $u$ on the left and known data on the right gives:\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x + \\beta u(1) v(1) = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x + g_R v(1) - g_N v(-1)\n$$\nThis is the weak formulation of the problem. We define a bilinear form $a(u,v)$ and a linear functional $L(v)$ as:\n-   Bilinear form: $a(u,v) = \\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x + \\beta u(1) v(1)$\n-   Linear functional: $L(v) = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x + g_R v(1) - g_N v(-1)$\n\nThe weak problem is to find $u \\in H^1(\\Omega)$ such that $a(u,v) = L(v)$ for all $v \\in H^1(\\Omega)$. This formulation is suitable for approximation by spectral Galerkin or continuous Galerkin finite element methods. A Discontinuous Galerkin (DG) method would require a slight modification involving numerical fluxes at the element boundary (which in this case is the domain boundary), but this formulation is the fundamental starting point.\n\n### Part 1: Compatibility and Uniqueness Analysis\n\n**Compatibility Condition for $\\beta = 0$ (Pure Neumann BCs)**\n\nWhen $\\beta=0$, the Robin condition becomes a Neumann condition: $\\frac{\\mathrm{d}u}{\\mathrm{d}x}(1) = g_R$. The weak formulation simplifies to: Find $u \\in H^1(\\Omega)$ such that for all $v \\in H^1(\\Omega)$,\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} \\frac{\\mathrm{d}v}{\\mathrm{d}x} \\,\\mathrm{d}x = \\int_{-1}^{1} f(x) v(x) \\,\\mathrm{d}x + g_R v(1) - g_N v(-1)\n$$\nThe problem states to test with constant functions. Let's choose the test function $v(x) = 1$. For this choice, $\\frac{\\mathrm{d}v}{\\mathrmd{x}} = 0$, $v(1)=1$, and $v(-1)=1$. Substituting this into the weak formulation gives:\n$$\n\\int_{-1}^{1} \\frac{\\mathrm{d}u}{\\mathrm{d}x} (0) \\,\\mathrm{d}x = \\int_{-1}^{1} f(x) (1) \\,\\mathrm{d}x + g_R (1) - g_N (1)\n$$\n$$\n0 = \\int_{-1}^{1} f(x) \\,\\mathrm{d}x + g_R - g_N\n$$\nThis yields the compatibility condition for solvability:\n$$\n\\int_{-1}^{1} f(x) \\,\\mathrm{d}x = g_N - g_R\n$$\nThis condition is necessary for a solution to exist. If it holds, a solution exists but is only unique up to an additive constant, since if $u(x)$ is a solution, so is $u(x)+C$ for any constant $C$. This is because the kernel of the bilinear form $a(u,v)=\\int u'v' dx$ consists of all constant functions.\n\n**Uniqueness for $\\beta>0$ (Mixed Neumann-Robin BCs)**\n\nFor $\\beta>0$, we can establish existence and uniqueness of the solution via the Lax-Milgram theorem. This requires the bilinear form $a(u,v)$ to be continuous and coercive on $H^1(\\Omega)$. Continuity is straightforward. We focus on proving coercivity, i.e., there exists a constant $C > 0$ such that $a(u,u) \\ge C \\|u\\|_{H^1}^2$ for all $u \\in H^1(\\Omega)$. The $H^1$ norm is defined as $\\|u\\|_{H^1}^2 = \\|u\\|_{L^2}^2 + \\|u'\\|_{L^2}^2 = \\int_{-1}^1 u^2 dx + \\int_{-1}^1 (u')^2 dx$.\n\nThe bilinear form evaluated for $v=u$ is:\n$$\na(u,u) = \\int_{-1}^{1} \\left(\\frac{\\mathrm{d}u}{\\mathrm{d}x}\\right)^2 \\,\\mathrm{d}x + \\beta (u(1))^2 = \\|u'\\|_{L^2}^2 + \\beta (u(1))^2\n$$\nSince $\\beta>0$, both terms are non-negative. We will use a proof by contradiction to show coercivity. Assume $a(u,u)$ is not coercive. Then there exists a sequence $\\{u_n\\}_{n=1}^{\\infty} \\subset H^1(\\Omega)$ such that $\\|u_n\\|_{H^1} = 1$ for all $n$, and $a(u_n, u_n) \\to 0$ as $n \\to \\infty$.\n\nThe condition $a(u_n, u_n) \\to 0$ implies that $\\|u_n'\\|_{L^2}^2 \\to 0$ and $\\beta (u_n(1))^2 \\to 0$. Since $\\beta>0$, this means $\\|u_n'\\|_{L^2} \\to 0$ and $u_n(1) \\to 0$.\nThe condition $\\|u_n\\|_{H^1} = 1$ means $\\|u_n\\|_{L^2}^2 + \\|u_n'\\|_{L^2}^2 = 1$. Since $\\|u_n'\\|_{L^2} \\to 0$, we must have $\\|u_n\\|_{L^2} \\to 1$.\n\nNow, for any $u_n \\in H^1(\\Omega)$, we can use the Fundamental Theorem of Calculus:\n$$\nu_n(x) = u_n(1) - \\int_x^1 u_n'(t) \\,\\mathrm{d}t\n$$\nTaking the absolute value and applying the Cauchy-Schwarz inequality to the integral:\n$$\n|u_n(x)| \\le |u_n(1)| + \\left|\\int_x^1 u_n'(t) \\,\\mathrm{d}t\\right| \\le |u_n(1)| + \\left(\\int_x^1 1^2 \\,\\mathrm{d}t\\right)^{1/2} \\left(\\int_x^1 (u_n'(t))^2 \\,\\mathrm{d}t\\right)^{1/2}\n$$\n$$\n|u_n(x)| \\le |u_n(1)| + \\sqrt{1-x} \\left(\\int_x^1 (u_n')^2 \\,\\mathrm{d}t\\right)^{1/2} \\le |u_n(1)| + \\sqrt{2} \\|u_n'\\|_{L^2}\n$$\nAs $n \\to \\infty$, we know $u_n(1) \\to 0$ and $\\|u_n'\\|_{L^2} \\to 0$. Thus, for any $x \\in [-1,1]$, $|u_n(x)| \\to 0$. The convergence is uniform in $x$.\nUniform convergence implies $L^2$ convergence. Therefore, $\\|u_n\\|_{L^2} \\to 0$.\nThis result, $\\|u_n\\|_{L^2} \\to 0$, directly contradicts our earlier finding that $\\|u_n\\|_{L^2} \\to 1$.\n\nThe contradiction arose from the assumption that $a(u,u)$ is not coercive. Therefore, $a(u,u)$ is coercive on $H^1(\\Omega)$. By the Lax-Milgram theorem, the weak problem has a unique solution for any given $f, g_N, g_R$.\n\n### Part 2: Exact Solution and Mean Value\n\nGiven $f(x) = px+q$, the PDE is $-\\frac{\\mathrm{d}^2 u}{\\mathrm{d}x^2} = px+q$. We find the general solution by integrating twice with respect to $x$:\n$$\n\\frac{\\mathrm{d}u}{\\mathrm{d}x} = -\\int (px+q) \\,\\mathrm{d}x = -\\frac{p}{2}x^2 - qx + C_1\n$$\n$$\nu(x) = \\int \\left(-\\frac{p}{2}x^2 - qx + C_1\\right) \\,\\mathrm{d}x = -\\frac{p}{6}x^3 - \\frac{q}{2}x^2 + C_1x + C_2\n$$\nThe constants of integration $C_1$ and $C_2$ are determined by the boundary conditions.\n\n1.  From the Neumann condition at $x=-1$: $\\frac{\\mathrm{d}u}{\\mathrm{d}x}(-1) = g_N$.\n    $$\n    -\\frac{p}{2}(-1)^2 - q(-1) + C_1 = g_N \\implies -\\frac{p}{2} + q + C_1 = g_N\n    $$\n    $$\n    C_1 = g_N + \\frac{p}{2} - q\n    $$\n\n2.  From the Robin condition at $x=1$: $\\frac{\\mathrm{d}u}{\\mathrm{d}x}(1) + \\beta u(1) = g_R$.\n    $$\n    \\frac{\\mathrm{d}u}{\\mathrm{d}x}(1) = -\\frac{p}{2}(1)^2 - q(1) + C_1 = -\\frac{p}{2} - q + C_1\n    $$\n    $$\n    u(1) = -\\frac{p}{6}(1)^3 - \\frac{q}{2}(1)^2 + C_1(1) + C_2 = -\\frac{p}{6} - \\frac{q}{2} + C_1 + C_2\n    $$\n    Substituting these into the Robin condition:\n    $$\n    \\left(-\\frac{p}{2} - q + C_1\\right) + \\beta\\left(-\\frac{p}{6} - \\frac{q}{2} + C_1 + C_2\\right) = g_R\n    $$\n    Substitute the expression for $C_1$:\n    $$\n    \\left(-\\frac{p}{2} - q + g_N + \\frac{p}{2} - q\\right) + \\beta\\left(-\\frac{p}{6} - \\frac{q}{2} + g_N + \\frac{p}{2} - q + C_2\\right) = g_R\n    $$\n    $$\n    (g_N - 2q) + \\beta\\left(\\frac{p}{3} - \\frac{3q}{2} + g_N + C_2\\right) = g_R\n    $$\n    Now, solve for $C_2$:\n    $$\n    \\beta(C_2) = g_R - (g_N - 2q) - \\beta\\left(\\frac{p}{3} - \\frac{3q}{2} + g_N\\right)\n    $$\n    $$\n    C_2 = \\frac{g_R - g_N + 2q}{\\beta} - \\left(\\frac{p}{3} - \\frac{3q}{2} + g_N\\right) = \\frac{g_R - g_N + 2q}{\\beta} - \\frac{p}{3} + \\frac{3q}{2} - g_N\n    $$\n\nFinally, we compute the mean value $\\overline{u}$:\n$$\n\\overline{u} = \\frac{1}{2}\\int_{-1}^{1} u(x)\\,\\mathrm{d}x = \\frac{1}{2}\\int_{-1}^{1} \\left(-\\frac{p}{6}x^3 - \\frac{q}{2}x^2 + C_1x + C_2\\right) \\,\\mathrm{d}x\n$$\nThe integrals of odd powers ($x^3$, $x$) over the symmetric interval $(-1,1)$ are zero.\n$$\n\\overline{u} = \\frac{1}{2} \\left[ -\\frac{q}{2} \\int_{-1}^{1} x^2 \\,\\mathrm{d}x + C_2 \\int_{-1}^{1} 1 \\,\\mathrm{d}x \\right] = \\frac{1}{2} \\left[ -\\frac{q}{2} \\left(\\frac{x^3}{3}\\right)\\bigg|_{-1}^{1} + C_2 (x)\\bigg|_{-1}^{1} \\right]\n$$\n$$\n\\overline{u} = \\frac{1}{2} \\left[ -\\frac{q}{2} \\left(\\frac{1}{3} - \\frac{-1}{3}\\right) + C_2 (1 - (-1)) \\right] = \\frac{1}{2} \\left[ -\\frac{q}{2}\\left(\\frac{2}{3}\\right) + 2C_2 \\right] = -\\frac{q}{6} + C_2\n$$\nSubstituting the expression for $C_2$:\n$$\n\\overline{u} = -\\frac{q}{6} + \\left( \\frac{g_R - g_N + 2q}{\\beta} - \\frac{p}{3} + \\frac{3q}{2} - g_N \\right)\n$$\nGroup terms by $p$, $q$, $g_N$, and $g_R$:\n$$\n\\overline{u} = -\\frac{p}{3} + q\\left(-\\frac{1}{6} + \\frac{2}{\\beta} + \\frac{3}{2}\\right) + g_N\\left(-1 - \\frac{1}{\\beta}\\right) + g_R\\left(\\frac{1}{\\beta}\\right)\n$$\nSimplify the coefficients:\n$$\n-\\frac{1}{6} + \\frac{3}{2} = \\frac{-1+9}{6} = \\frac{8}{6} = \\frac{4}{3}\n$$\n$$\n-1 - \\frac{1}{\\beta} = -\\frac{\\beta+1}{\\beta}\n$$\nSo, the mean value is:\n$$\n\\overline{u} = -\\frac{p}{3} + q\\left(\\frac{4}{3} + \\frac{2}{\\beta}\\right) - g_N\\left(\\frac{\\beta+1}{\\beta}\\right) + \\frac{g_R}{\\beta}\n$$\nThis expression can be combined over a common denominator $3\\beta$:\n$$\n\\overline{u} = \\frac{-p\\beta + q(4\\beta+6) - 3g_N(\\beta+1) + 3g_R}{3\\beta}\n$$\n$$\n\\overline{u} = \\frac{3g_R - (3\\beta+3)g_N - \\beta p + (4\\beta+6)q}{3\\beta}\n$$",
            "answer": "$$\n\\boxed{\\frac{3g_R - (3\\beta+3)g_N - \\beta p + (4\\beta+6)q}{3\\beta}}\n$$"
        },
        {
            "introduction": "Handling inhomogeneous Dirichlet (or \"essential\") boundary conditions presents a unique challenge, as they must be explicitly enforced on the solution space. A common and powerful strategy is to use a \"lifting function\" to transform the problem into an equivalent one with homogeneous boundary conditions, which is often simpler to solve. This final practice guides you through the construction of such a lifting function in a 2D setting with mixed boundary types, illustrating how this practical technique modifies the problem's source term and makes it amenable to a standard Galerkin formulation .",
            "id": "3379353",
            "problem": "Consider the second-order elliptic model problem with constant conductivity on a square reference spectral element, inspired by the polynomial frameworks used in Spectral Element Methods (SEM) and Discontinuous Galerkin (DG) methods. Let the domain be $\\Omega = [-1,1] \\times [-1,1]$, and consider the equation $-\\nabla \\cdot (\\kappa \\nabla u) = f$ in $\\Omega$ with boundary decomposition $\\partial \\Omega = \\Gamma_{D} \\cup \\Gamma_{N} \\cup \\Gamma_{R}$, where $\\Gamma_{D} = \\{(x,y) \\in \\partial \\Omega : y = 1\\}$, $\\Gamma_{N} = \\{(x,y) \\in \\partial \\Omega : y = -1\\}$, and $\\Gamma_{R} = \\{(x,y) \\in \\partial \\Omega : x = \\pm 1\\}$. The boundary conditions are inhomogeneous Dirichlet on $\\Gamma_{D}$, homogeneous Neumann on $\\Gamma_{N}$, and homogeneous Robin on $\\Gamma_{R}$, namely: $u = g$ on $\\Gamma_{D}$, $\\kappa \\nabla u \\cdot n = 0$ on $\\Gamma_{N}$, and $\\kappa \\nabla u \\cdot n + \\beta u = 0$ on $\\Gamma_{R}$, with $\\beta > 0$ constant and $n$ the outward unit normal. Assume $\\kappa > 0$ is a uniform scalar.\n\nA standard device in Spectral Element Methods and Symmetric Interior Penalty Discontinuous Galerkin (SIPDG) methods is the construction of a lifting function that enforces inhomogeneous Dirichlet data while preserving other boundary segments (Neumann and Robin) in homogeneous form for the transformed unknown. Starting from the strong form and the fundamental integration-by-parts identity that underlies the weak formulation, consider the decomposition $u = v + w$, where $w$ is a lifting that exactly enforces the Dirichlet condition on $\\Gamma_{D}$ and is chosen so that substituting $u = v + w$ preserves the homogeneous Neumann and Robin conditions for $v$ on $\\Gamma_{N}$ and $\\Gamma_{R}$, respectively. The function $v$ then satisfies an equation of the same type in the interior with a modified right-hand side.\n\nLet the inhomogeneous Dirichlet data be the spectral polynomial $g(x) = (1 - x^{2})^{2}$ on $\\Gamma_{D}$, and construct a lifting of tensor-product form $w(x,y) = g(x) \\, b(y)$ with minimal-degree polynomial $b(y)$ such that $w(x,1) = g(x)$, $\\nabla w \\cdot n = 0$ on $\\Gamma_{N}$, and both $w = 0$ and $\\nabla w \\cdot n = 0$ on $\\Gamma_{R}$ (so that homogeneous Robin is preserved for $v$ irrespective of $\\beta$). Work from first principles (the strong equation and boundary conditions), derive the transformed interior equation satisfied by $v$, and compute the explicit modification induced on the volumetric right-hand side, namely the function $\\delta f(x,y)$ such that $-\\nabla \\cdot (\\kappa \\nabla v) = f + \\delta f$ in $\\Omega$.\n\nProvide the exact, closed-form analytic expression for $\\delta f(x,y)$ in terms of $x$, $y$, and $\\kappa$. Your final answer must be a single closed-form expression. No numerical rounding is required. Express angles, if any appear, in radians.",
            "solution": "The problem is to find an explicit expression for the modification to the right-hand side, $\\delta f(x,y)$, when transforming a second-order elliptic problem with inhomogeneous Dirichlet data into one with homogeneous data. This is achieved by introducing a lifting function $w(x,y)$.\n\nThe original problem is defined on the domain $\\Omega = [-1,1] \\times [-1,1]$:\n$$-\\nabla \\cdot (\\kappa \\nabla u) = f$$\nwith constant conductivity $\\kappa > 0$. The boundary conditions are:\n$u = g$ on $\\Gamma_{D} = \\{(x,y) \\in \\partial \\Omega : y = 1\\}$.\n$\\kappa \\nabla u \\cdot n = 0$ on $\\Gamma_{N} = \\{(x,y) \\in \\partial \\Omega : y = -1\\}$.\n$\\kappa \\nabla u \\cdot n + \\beta u = 0$ on $\\Gamma_{R} = \\{(x,y) \\in \\partial \\Omega : x = \\pm 1\\}$.\n\nWe use the decomposition $u = v + w$, where $w$ is the lifting function. The goal is to find $v$ which satisfies an equation of the form $-\\nabla \\cdot (\\kappa \\nabla v) = f + \\delta f$ with homogeneous boundary conditions.\n\nFirst, we must determine the lifting function $w(x,y)$. The problem states it has the form $w(x,y) = g(x) b(y)$, where $g(x) = (1 - x^{2})^{2}$ and $b(y)$ is a minimal-degree polynomial. The conditions on $w$ are:\n1.  $w(x,1) = g(x)$ to enforce the Dirichlet condition.\n2.  $\\nabla w \\cdot n = 0$ on $\\Gamma_{N}$ to preserve the homogeneous Neumann condition for $v$.\n3.  $w = 0$ and $\\nabla w \\cdot n = 0$ on $\\Gamma_R$ to preserve the homogeneous Robin condition for $v$.\n\nLet's translate these conditions on $w$ into conditions on the polynomial $b(y)$.\n\nCondition 1: On $\\Gamma_D$ ($y=1$), $w(x,1) = g(x)b(1)$. For this to equal $g(x)$, we must have:\n$$b(1) = 1$$\n\nCondition 2: On $\\Gamma_N$ ($y=-1$), the outward unit normal is $n = (0, -1)$. The condition is $\\nabla w \\cdot n = 0$.\n$$\\nabla w = \\left( \\frac{\\partial w}{\\partial x}, \\frac{\\partial w}{\\partial y} \\right) = \\left( \\frac{dg}{dx} b(y), g(x) \\frac{db}{dy} \\right)$$\n$$\\nabla w \\cdot n = - \\frac{\\partial w}{\\partial y} = -g(x) \\frac{db}{dy}$$\nEvaluated at $y=-1$, we need $-g(x) \\frac{db}{dy}(-1) = 0$ for all $x \\in [-1,1]$. Since $g(x)$ is not identically zero, this requires:\n$$\\frac{db}{dy}(-1) = 0 \\quad \\text{or} \\quad b'(-1) = 0$$\n\nCondition 3: On $\\Gamma_R$ ($x=\\pm 1$), the outward normals are $n = (1, 0)$ for $x=1$ and $n = (-1, 0)$ for $x=-1$.\nThe condition $w=0$ on $\\Gamma_R$ means $w(\\pm 1, y) = g(\\pm 1) b(y) = (1 - (\\pm 1)^2)^2 b(y) = 0 \\cdot b(y) = 0$. This condition is automatically satisfied for any $b(y)$ due to the choice of $g(x)$.\nThe condition $\\nabla w \\cdot n = 0$ on $\\Gamma_R$:\nat $x=1$, $\\nabla w \\cdot n = \\frac{\\partial w}{\\partial x}(1,y) = \\frac{dg}{dx}(1) b(y)$.\nat $x=-1$, $\\nabla w \\cdot n = -\\frac{\\partial w}{\\partial x}(-1,y) = -\\frac{dg}{dx}(-1) b(y)$.\nSince $g(x)=(1-x^2)^2$, its derivative is $g'(x) = 2(1-x^2)(-2x) = -4x(1-x^2)$. Thus, $g'(\\pm 1)=0$. This condition is also automatically satisfied for any $b(y)$.\n\nIn this context, a minimal lifting function should be non-zero only on the boundary segment with inhomogeneous data and vanish on other segments to avoid introducing spurious boundary values. This implies an additional condition: $w(x,-1)=0$ on $\\Gamma_N$. This translates to $g(x)b(-1)=0$, which implies $b(-1)=0$.\n\nSo, we seek the minimal-degree polynomial $b(y)$ satisfying the three conditions:\n(i) $b(1)=1$\n(ii) $b(-1)=0$\n(iii) $b'(-1)=0$\n\nConditions (ii) and (iii) imply that $b(y)$ has a double root at $y=-1$. Therefore, $b(y)$ must have a factor of $(y+1)^2$. The minimal degree form is $b(y) = C(y+1)^2$ for some constant $C$.\nUsing condition (i) to find $C$:\n$b(1) = C(1+1)^2 = 4C = 1 \\implies C = \\frac{1}{4}$.\nThe minimal-degree polynomial that satisfies these standard lifting conditions is the quadratic:\n$$b(y) = \\frac{1}{4}(y+1)^2$$\nThus, the lifting function is:\n$$w(x,y) = g(x) b(y) = (1-x^2)^2 \\frac{1}{4}(y+1)^2$$\n\nNext, we derive the equation for $v$. We substitute $u = v+w$ into the original PDE:\n$$-\\nabla \\cdot (\\kappa \\nabla (v+w)) = f$$\n$$-\\nabla \\cdot (\\kappa \\nabla v) - \\nabla \\cdot (\\kappa \\nabla w) = f$$\nRearranging for the equation in $v$:\n$$-\\nabla \\cdot (\\kappa \\nabla v) = f + \\nabla \\cdot (\\kappa \\nabla w)$$\nBy comparing with the form $-\\nabla \\cdot (\\kappa \\nabla v) = f + \\delta f$, we identify the modification term as:\n$$\\delta f(x,y) = \\nabla \\cdot (\\kappa \\nabla w)$$\nSince $\\kappa$ is a constant scalar, this simplifies to:\n$$\\delta f(x,y) = \\kappa \\nabla^2 w = \\kappa \\left( \\frac{\\partial^2 w}{\\partial x^2} + \\frac{\\partial^2 w}{\\partial y^2} \\right)$$\nWe now compute the second partial derivatives of $w(x,y)$.\nLet $g(x) = (1-x^2)^2$ and $h(y) = \\frac{1}{4}(y+1)^2$. Then $w(x,y) = g(x)h(y)$.\nThe Laplacian is $\\nabla^2 w = \\frac{d^2 g}{dx^2} h(y) + g(x) \\frac{d^2 h}{dy^2}$.\n\nFirst, the derivatives with respect to $x$:\n$g(x) = (1-x^2)^2 = 1 - 2x^2 + x^4$\n$\\frac{dg}{dx} = -4x + 4x^3$\n$\\frac{d^2g}{dx^2} = -4 + 12x^2$\n\nSecond, the derivatives with respect to $y$:\n$h(y) = \\frac{1}{4}(y+1)^2 = \\frac{1}{4}(y^2+2y+1)$\n$\\frac{dh}{dy} = \\frac{1}{4}(2y+2) = \\frac{1}{2}(y+1)$\n$\\frac{d^2h}{dy^2} = \\frac{1}{2}$\n\nNow, we assemble the Laplacian of $w$:\n$$\\nabla^2 w = \\left( 12x^2 - 4 \\right) h(y) + g(x) \\left( \\frac{1}{2} \\right)$$\n$$\\nabla^2 w = \\left( 12x^2 - 4 \\right) \\frac{1}{4}(y+1)^2 + (1-x^2)^2 \\frac{1}{2}$$\n$$\\nabla^2 w = (3x^2 - 1)(y+1)^2 + \\frac{1}{2}(1-x^2)^2$$\n\nFinally, we write the expression for $\\delta f(x,y)$:\n$$\\delta f(x,y) = \\kappa \\nabla^2 w = \\kappa \\left[ (3x^2-1)(y+1)^2 + \\frac{1}{2}(1-x^2)^2 \\right]$$\nThis is the final, closed-form analytic expression for the modification to the right-hand side.",
            "answer": "$$\n\\boxed{\\kappa \\left[ (3x^2-1)(y+1)^2 + \\frac{1}{2}(1-x^2)^2 \\right]}\n$$"
        }
    ]
}