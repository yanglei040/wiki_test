{
    "hands_on_practices": [
        {
            "introduction": "This first practice explores a fundamental weakness of high-order Newton-Cotes rules: the numerical instability inherent in calculating their weights. By constructing the weights from their defining moment-matching conditions, you will discover how the ill-conditioned Vandermonde matrix for equispaced points leads to significant errors in standard floating-point arithmetic as the order increases . This exercise provides a direct, quantitative measure of why these rules are impractical for high-degree polynomial approximation.",
            "id": "3401957",
            "problem": "Consider the closed Newton–Cotes quadrature on the unit interval, in which one approximates the integral of a sufficiently smooth function $f(x)$ over $[0,1]$ by\n$$\n\\int_{0}^{1} f(x)\\,dx \\approx \\sum_{i=0}^{n} w_i f(x_i),\n$$\nwhere $x_i = \\frac{i}{n}$ for $i = 0,1,\\dots,n$ are $n+1$ equispaced nodes on $[0,1]$, and $w_i$ are the quadrature weights. In the context of spectral and discontinuous Galerkin methods (Spectral/DG), this family of formulas is a canonical example of quadrature on equispaced grids, known to suffer from numerical instabilities for large $n$ due to the ill-conditioning associated with high-degree polynomial interpolation on equispaced points.\n\nBy the exactness requirement for polynomials, the quadrature must integrate every monomial $p_j(x)=x^j$ for $j=0,\\dots,n$ exactly. This yields a linear system for the weights,\n$$\n\\sum_{i=0}^{n} w_i x_i^j \\;=\\; \\int_{0}^{1} x^j\\,dx \\;=\\; \\frac{1}{j+1}, \\quad j=0,1,\\dots,n,\n$$\nwhich can be written in matrix form as $A\\,\\mathbf{w}=\\mathbf{m}$, where $A_{j,i}=x_i^j$ and $\\mathbf{m}_j=\\frac{1}{j+1}$. For large $n$, solving this system in standard double precision can be numerically sensitive.\n\nTask. Write a complete, runnable program that:\n1) Constructs the closed Newton–Cotes weight vector $\\mathbf{w}\\in\\mathbb{R}^{n+1}$ for each prescribed $n$ by solving $A\\,\\mathbf{w}=\\mathbf{m}$ in two ways:\n- In standard double precision using dense linear algebra.\n- In exact rational arithmetic (representing all entries as rational numbers) to obtain a high-quality reference solution.\n2) Converts the exact rational reference solution to high-precision real values, and reports quantitative measures of numerical sensitivity for the double-precision solution:\n- The relative $\\ell_\\infty$-norm error\n$$\n\\mathrm{rinf} \\;=\\; \\frac{\\max_{0\\le i\\le n} \\left| w_i^{(\\mathrm{double})} - w_i^{(\\mathrm{ref})}\\right|}{\\max_{0\\le i\\le n} \\left| w_i^{(\\mathrm{ref})}\\right|}.\n$$\n- The absolute deviation from unity of the sum of the double-precision weights,\n$$\n\\mathrm{sdev} \\;=\\; \\left| \\sum_{i=0}^{n} w_i^{(\\mathrm{double})} - 1 \\right|.\n$$\n- Two boolean flags indicating whether any reference weight is strictly negative and whether any double-precision weight is strictly negative.\n3) Uses the above to empirically assess round-off and cancellation effects as $n$ grows.\n\nUse the following test suite of degrees (number of subintervals) to exercise different regimes of numerical sensitivity:\n- $n=1$ (boundary case: two nodes).\n- $n=2$ (classical Simpson-type regime).\n- $n=8$ (moderately high order).\n- $n=12$ (high order where sensitivity increases).\n- $n=16$ (very high order for equispaced Newton–Cotes, typically unstable).\n\nYour program must:\n- For each $n$ in the test suite, output a list containing five entries in the order\n$$\n\\left[n,\\; \\mathrm{rinf},\\; \\mathrm{sdev},\\; \\mathrm{neg\\_ref},\\; \\mathrm{neg\\_double}\\right],\n$$\nwhere $n$ is an integer, $\\mathrm{rinf}$ and $\\mathrm{sdev}$ are floating-point numbers, and $\\mathrm{neg\\_ref}$ and $\\mathrm{neg\\_double}$ are booleans.\n- Aggregate all per-$n$ lists into a single list, and print exactly one line containing this aggregate list in standard Python list syntax, for example,\n$$\n\\big[ [\\cdots], [\\cdots], \\dots \\big].\n$$\n\nScientific and algorithmic bases to be used:\n- Fundamental definition of closed Newton–Cotes weights as those for which the quadrature is exact for all polynomials up to degree $n$ on $[0,1]$.\n- Construction of the linear system $A\\,\\mathbf{w}=\\mathbf{m}$ from monomial exactness.\n- Exact reference computation via rational arithmetic for $x_i=\\frac{i}{n}$ and $\\int_0^1 x^j dx=\\frac{1}{j+1}$.\n- Relative error and absolute sum deviation as numerical sensitivity measures.\n\nAngle units, physical units, and percentages do not apply. All outputs are unitless real numbers or booleans.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[[n,rinf,sdev,neg_ref,neg_double], ...]\").",
            "solution": "The user provided a valid problem.\n\n### Step 1: Extract Givens\n- **Quadrature Rule**: The integral of a function $f(x)$ on $[0,1]$ is approximated by a closed Newton–Cotes formula:\n$$ \\int_{0}^{1} f(x)\\,dx \\approx \\sum_{i=0}^{n} w_i f(x_i) $$\n- **Nodes**: $n+1$ equispaced nodes on $[0,1]$, given by $x_i = \\frac{i}{n}$ for $i = 0,1,\\dots,n$.\n- **Weight Calculation**: The weights $w_i$ are determined by requiring the quadrature to be exact for all monomials $p_j(x)=x^j$ for $j=0,\\dots,n$. This leads to the linear system:\n$$ \\sum_{i=0}^{n} w_i x_i^j = \\frac{1}{j+1}, \\quad j=0,1,\\dots,n $$\n- **Matrix Form**: The linear system is $A\\,\\mathbf{w}=\\mathbf{m}$, where $A_{j,i}=x_i^j$ (a Vandermonde matrix), $\\mathbf{w}$ is the vector of weights, and $\\mathbf{m}_j=\\frac{1}{j+1}$.\n- **Computational Methods**:\n    1.  **Double Precision**: Solve the system using standard floating-point arithmetic. Let the solution be $\\mathbf{w}^{(\\mathrm{double})}$.\n    2.  **Exact Reference**: Solve the system using exact rational arithmetic. Convert the result to high-precision floating point for comparison, denoted $\\mathbf{w}^{(\\mathrm{ref})}$.\n- **Numerical Sensitivity Metrics**:\n    1.  **Relative $\\ell_\\infty$-norm error**: $\\mathrm{rinf} = \\frac{\\max_{i} \\left| w_i^{(\\mathrm{double})} - w_i^{(\\mathrm{ref})}\\right|}{\\max_{i} \\left| w_i^{(\\mathrm{ref})}\\right|}$.\n    2.  **Sum Deviation**: $\\mathrm{sdev} = \\left| \\sum_{i=0}^{n} w_i^{(\\mathrm{double})} - 1 \\right|$.\n    3.  **Negative Weight Flags**: $\\mathrm{neg\\_ref}$ (boolean, for reference weights) and $\\mathrm{neg\\_double}$ (boolean, for double-precision weights).\n- **Test Suite**: The analysis is to be performed for $n \\in \\{1, 2, 8, 12, 16\\}$.\n- **Output Format**: A single list of lists, where each inner list has the format $[n, \\mathrm{rinf}, \\mathrm{sdev}, \\mathrm{neg\\_ref}, \\mathrm{neg\\_double}]$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is a classic investigation in numerical analysis. The construction of Newton-Cotes weights via a Vandermonde system and the well-known ill-conditioning of this system for equispaced points are fundamental concepts. The proposed experiment is scientifically sound and directly demonstrates these principles.\n- **Well-Posed**: For any given $n \\ge 1$, the nodes $x_i$ are distinct. The corresponding Vandermonde matrix $A$ is therefore non-singular, guaranteeing a unique solution $\\mathbf{w}$ for the weights. The problem is well-defined and has a unique, meaningful solution.\n- **Objective**: All terms, formulas, and metrics are defined with mathematical precision. The problem is free from any subjective or ambiguous language.\n- **Other Flaws**: The problem is self-contained, consistent, feasible, and non-trivial. It does not violate any of the other invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. A reasoned solution will be developed.\n\n### Principle-Based Design\nThe solution proceeds by implementing the numerical experiment as specified. For each value of $n$ in the test suite, we will perform the following steps:\n\n1.  **System Construction (Double Precision)**: We define the size of the system as $N = n+1$. The nodes $x_i = i/n$ are created as a `numpy` array of double-precision floats. The Vandermonde matrix $A$ is constructed using `numpy.vander`, and the right-hand side vector $\\mathbf{m}$ is also formed with floats. The system $A \\mathbf{w} = \\mathbf{m}$ is then solved for $\\mathbf{w}^{(\\mathrm{double})}$ using `numpy.linalg.solve`. This function implements a standard, robust algorithm (typically based on LU decomposition) for solving dense linear systems.\n\n2.  **System Construction (Exact Rational Arithmetic)**: To obtain a high-quality reference solution, we avoid floating-point representation errors. We use Python's `fractions.Fraction` class, which performs arithmetic on rational numbers exactly. The nodes $x_i = i/n$ and the monomial integrals $1/(j+1)$ are represented as `Fraction` objects. The matrix $A$ and vector $\\mathbf{m}$ are constructed with these exact rational entries.\n\n3.  **Exact System Solution**: Since `numpy` and `scipy` do not have built-in linear algebra solvers for rational number types, a custom solver must be implemented. We will use the Gauss-Jordan elimination algorithm. This algorithm transforms the augmented matrix $[A|\\mathbf{m}]$ into $[I|\\mathbf{w}]$, where $I$ is the identity matrix and $\\mathbf{w}$ is the solution vector. All arithmetic operations (addition, subtraction, multiplication, division) within the algorithm are performed using `Fraction`'s methods, ensuring the result $\\mathbf{w}^{(\\mathrm{ref\\_rational})}$ is exact.\n\n4.  **Metric Computation**:\n    - The exact rational weights $\\mathbf{w}^{(\\mathrm{ref\\_rational})}$ are converted to standard double-precision floats to yield $\\mathbf{w}^{(\\mathrm{ref})}$.\n    - The relative $\\ell_\\infty$ error, `rinf`, is computed by finding the maximum absolute difference between `w_double` and `w_ref` and normalizing by the maximum absolute value of `w_ref`. This quantifies the worst-case relative error in the computed weights.\n    - The sum deviation, `sdev`, is the absolute difference between the sum of the double-precision weights and $1$. Since the condition $\\sum w_i = 1$ (for $j=0$) is one of the equations in the linear system, this metric measures how well the numerical solution satisfies this fundamental constraint.\n    - The boolean flags `neg_ref` and `neg_double` are determined by checking if any weight in the respective vectors is strictly negative. The check for the reference solution is performed on the exact rational values before conversion to float to avoid any ambiguity from floating-point inaccuracies.\n\nThis process is repeated for each $n$, and the results are aggregated into the specified list-of-lists format for the final output. The experiment is designed to reveal the degradation of numerical accuracy as $n$ increases, a direct consequence of the exponentially growing condition number of the Vandermonde matrix for equispaced points.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom fractions import Fraction\nimport sys\n\n# Increase recursion limit for potentially deep calls in Fraction arithmetic for large n.\n# Although not strictly necessary for n<=16, it is good practice for larger systems.\nsys.setrecursionlimit(2000)\n\ndef solve_rational_system(A_rational, m_rational):\n    \"\"\"\n    Solves a linear system Ax=b where A and b contain Fraction objects.\n    Uses Gauss-Jordan elimination.\n\n    Args:\n        A_rational (list of lists of Fraction): The N x N coefficient matrix.\n        m_rational (list of Fraction): The N-element right-hand side vector.\n\n    Returns:\n        list of Fraction: The solution vector x.\n    \"\"\"\n    N = len(m_rational)\n    # Create the augmented matrix [A|m]\n    Ab = [A_rational[i] + [m_rational[i]] for i in range(N)]\n\n    for i in range(N):\n        # Find a non-zero pivot in column i, at or below the current row\n        pivot_row = i\n        while pivot_row < N and Ab[pivot_row][i] == 0:\n            pivot_row += 1\n\n        if pivot_row == N:\n            # This should not happen for the non-singular matrices in this problem\n            raise ValueError(\"Matrix is singular or near-singular.\")\n\n        # Swap the current row with the pivot row\n        Ab[i], Ab[pivot_row] = Ab[pivot_row], Ab[i]\n\n        # Get the pivot element\n        pivot_val = Ab[i][i]\n\n        # Normalize the pivot row by dividing all its elements by the pivot value\n        for j in range(i, N + 1):\n            Ab[i][j] /= pivot_val\n\n        # Eliminate the entry in the current pivot column for all other rows\n        for k in range(N):\n            if k != i:\n                factor = Ab[k][i]\n                # Subtract factor * (pivot row) from row k\n                for j in range(i, N + 1):\n                    Ab[k][j] -= factor * Ab[i][j]\n\n    # After Gauss-Jordan, the last column of the augmented matrix is the solution\n    w_rational = [Ab[row][N] for row in range(N)]\n    return w_rational\n\n\ndef compute_metrics_for_n(n):\n    \"\"\"\n    Constructs and solves the Newton-Cotes system for a given degree n,\n    and computes the specified numerical sensitivity metrics.\n    \"\"\"\n    N = n + 1  # Number of nodes and dimension of the system\n\n    # --- 1. Double precision solution ---\n    nodes_double = np.linspace(0.0, 1.0, N, dtype=np.float64)\n    # The matrix A has entries A_ji = x_i^j.\n    # np.vander(x, N, increasing=True) produces columns [x^0, x^1, ...].\n    # Transposing gives rows [x_0^j, x_1^j, ...], which is what we need.\n    A_double = np.vander(nodes_double, N, increasing=True).T\n    m_double = 1.0 / (np.arange(N, dtype=np.float64) + 1.0)\n    \n    w_double = np.linalg.solve(A_double, m_double)\n\n    # --- 2. Exact rational reference solution ---\n    # Handle the case n=0 if it were to be used, although test cases start at n=1\n    if n == 0:\n        nodes_rational = [Fraction(0, 1)] # A single node at 0\n    else:\n        nodes_rational = [Fraction(i, n) for i in range(N)]\n\n    A_rational = [[node ** j for node in nodes_rational] for j in range(N)]\n    m_rational = [Fraction(1, j + 1) for j in range(N)]\n\n    w_ref_rational = solve_rational_system(A_rational, m_rational)\n    \n    # Convert rational reference solution to float for comparison\n    w_ref = np.array([float(f) for f in w_ref_rational], dtype=np.float64)\n\n    # --- 3. Compute metrics ---\n    # Relative infinity-norm error\n    abs_error = np.abs(w_double - w_ref)\n    max_abs_error = np.max(abs_error)\n    max_abs_ref = np.max(np.abs(w_ref))\n    \n    if max_abs_ref == 0.0:\n        rinf = np.inf if max_abs_error > 0.0 else 0.0\n    else:\n        rinf = max_abs_error / max_abs_ref\n\n    # Absolute deviation of sum from unity\n    sdev = np.abs(np.sum(w_double) - 1.0)\n\n    # Check for negative weights\n    neg_ref = any(w < Fraction(0) for w in w_ref_rational)\n    neg_double = bool(np.any(w_double < 0))\n\n    return [n, rinf, sdev, neg_ref, neg_double]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [1, 2, 8, 12, 16]\n\n    results = []\n    for n in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        result = compute_metrics_for_n(n)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The format \"[[...],[...]]\" is standard Python list representation.\n    # The template 'f\"[{\",\".join(map(str, results))}]\"' correctly produces this.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "In spectral methods, accuracy hinges on the precise computation of inner products, which are used to project functions onto a polynomial basis. This practice demonstrates the phenomenon of aliasing, a critical source of error that occurs when the numerical quadrature is not strong enough to resolve the integrand exactly . By simulating the projection of a high-degree polynomial onto a low-degree space with an insufficient Newton-Cotes rule, you will quantify how unresolved modes can spuriously corrupt the computed solution.",
            "id": "3401943",
            "problem": "Consider the reference interval $[-1,1]$ and the standard Legendre polynomial basis $\\{P_k(x)\\}_{k \\ge 0}$, where $P_k(x)$ denotes the degree-$k$ Legendre polynomial satisfying $P_k(1)=1$. In spectral and discontinuous Galerkin methods, modal projection of a function $f(x)$ onto the polynomial space of degree at most $p$ uses the $L^2([-1,1])$ inner product with unit weight:\n$$\n\\langle f, g \\rangle = \\int_{-1}^{1} f(x)\\,g(x)\\,dx,\n$$\nand the coefficients of the projection are given by\n$$\nc_k = \\frac{\\int_{-1}^{1} f(x)\\,P_k(x)\\,dx}{\\int_{-1}^{1} P_k(x)^2\\,dx}, \\quad k=0,1,\\dots,p.\n$$\nA foundational fact is the orthogonality of Legendre polynomials:\n$$\n\\int_{-1}^{1} P_m(x)\\,P_k(x)\\,dx = \n\\begin{cases}\n0, & m \\ne k, \\\\[4pt]\n\\dfrac{2}{2k+1}, & m=k,\n\\end{cases}\n$$\nwhich implies that if $f(x)$ contains only unresolved polynomial modes (degrees strictly greater than $p$), then its exact modal projection onto degrees $\\le p$ is identically zero.\n\nIn practice, projections are often computed by numerical quadrature. A closed Newton–Cotes quadrature rule on $[-1,1]$ with $N+1$ equispaced nodes $x_j \\in [-1,1]$, $j=0,\\dots,N$, can be specified by weights $\\{w_j\\}_{j=0}^N$ that satisfy the moment-matching conditions for monomials:\n$$\n\\sum_{j=0}^{N} w_j\\,x_j^m = \\int_{-1}^{1} x^m \\, dx, \\quad m=0,1,\\dots,N.\n$$\nSuch an interpolatory rule integrates all polynomials of total degree up to $N$ exactly. When applied to the inner product $\\int_{-1}^{1} f(x)\\,P_k(x)\\,dx$ where the integrand has degree exceeding $N$, underintegration occurs and aliasing can arise: unresolved higher-degree modes of $f(x)$ can spuriously contribute to low-order modal coefficients $\\{c_k\\}$, manifesting as oscillations in the reconstructed solution.\n\nConstruct the following example to expose aliasing and quantify its impact in terms of unresolved polynomial modes:\n\n1. Define the unresolved function\n$$\nf(x) = \\sum_{m=p+1}^{p+M} a_m\\,P_m(x), \\quad a_m = \\frac{(-1)^m}{m+1},\n$$\nwhich contains only Legendre modes of degree strictly greater than $p$.\n\n2. For a given polynomial degree $p$ and a closed Newton–Cotes rule with $N+1$ equispaced nodes on $[-1,1]$, compute the underintegrated modal coefficients\n$$\n\\widetilde{c}_k = \\frac{Q_N\\big(f P_k\\big)}{\\int_{-1}^{1} P_k(x)^2\\,dx}, \\quad k=0,1,\\dots,p,\n$$\nwhere $Q_N(g) = \\sum_{j=0}^N w_j\\,g(x_j)$ denotes the Newton–Cotes quadrature of $g(x)$ and the denominator is the exact Legendre norm $\\int_{-1}^{1} P_k^2\\,dx = \\frac{2}{2k+1}$.\n\n3. Form the aliased projection\n$$\ng_{\\text{alias}}(x) = \\sum_{k=0}^{p} \\widetilde{c}_k\\,P_k(x).\n$$\n\n4. Quantify the aliasing error via the ratio of the $L^2([-1,1])$ norm of the aliased projection to the $L^2([-1,1])$ norm of the unresolved function, both computed exactly using Legendre orthogonality:\n$$\nE_{\\text{alias}} = \\left\\| g_{\\text{alias}} \\right\\|_{L^2([-1,1])} = \\sqrt{ \\sum_{k=0}^{p} \\left(\\widetilde{c}_k\\right)^2\\,\\frac{2}{2k+1} },\n$$\n$$\nE_{\\text{unresolved}} = \\left\\| f \\right\\|_{L^2([-1,1])} = \\sqrt{ \\sum_{m=p+1}^{p+M} a_m^2\\,\\frac{2}{2m+1} },\n$$\nand report the dimensionless ratio\n$$\nR = \\frac{E_{\\text{alias}}}{E_{\\text{unresolved}}}.\n$$\n\nYour program must:\n- Construct the closed Newton–Cotes weights by solving the moment-matching linear system for monomials $x^m$ up to degree $N$ using $N+1$ equispaced nodes on $[-1,1]$.\n- Use the above definitions to compute $R$ for each test case.\n\nUse the following test suite:\n- Case A (happy path, exactness at the boundary): $p=3$, $N=8$, $M=2$.\n- Case B (moderate underintegration): $p=6$, $N=6$, $M=4$.\n- Case C (severe underintegration): $p=10$, $N=4$, $M=10$.\n- Case D (happy path, exactness at the boundary): $p=4$, $N=9$, $M=1$.\n\nYour program should produce a single line of output containing the results $[R_A,R_B,R_C,R_D]$ as a comma-separated list of decimal numbers, each rounded to eight digits after the decimal point, enclosed in square brackets (e.g., \"[0.00000000,0.12345678,0.98765432,0.00000001]\"). No physical units apply, and angles are not used. The only required outputs are these four floats in the specified format.",
            "solution": "The problem requires a quantitative analysis of aliasing error that arises from the under-integration of modal projections in spectral methods. The core task is to compute the ratio $R$ of the $L^2$ norm of a spurious, aliased projection to the $L^2$ norm of an original, unresolved function for several parameter sets $(p, N, M)$. The entire process is grounded in the properties of Legendre polynomials and Newton–Cotes quadrature.\n\nFirst, we must construct the specified closed Newton–Cotes quadrature rule for a given degree $N$. The rule uses $N+1$ equispaced nodes on the interval $[-1, 1]$, given by $x_j = -1 + \\frac{2j}{N}$ for $j=0, 1, \\dots, N$. The corresponding weights $\\{w_j\\}_{j=0}^N$ are found by enforcing the condition that the quadrature rule is exact for all monomials $x^m$ up to degree $N$. This yields a system of $N+1$ linear equations:\n$$\n\\sum_{j=0}^{N} w_j\\,x_j^m = \\int_{-1}^{1} x^m \\, dx, \\quad m=0,1,\\dots,N.\n$$\nThe right-hand side is the moment integral, which evaluates to $\\frac{2}{m+1}$ if $m$ is even and $0$ if $m$ is odd. This linear system can be written in matrix form as $V\\mathbf{w} = \\mathbf{b}$, where $V$ is a Vandermonde matrix with entries $V_{mj} = x_j^m$, $\\mathbf{w}$ is the vector of unknown weights, and $\\mathbf{b}$ is the vector of moments. This system is solved to find the weights $w_j$.\n\nNext, we compute the under-integrated modal coefficients, $\\widetilde{c}_k$, for $k=0, 1, \\dots, p$. The formula is:\n$$\n\\widetilde{c}_k = \\frac{Q_N\\big(f P_k\\big)}{\\int_{-1}^{1} P_k(x)^2\\,dx}.\n$$\nThe denominator is known from Legendre polynomial orthogonality to be $\\frac{2}{2k+1}$. The numerator is the numerical quadrature of the product of the unresolved function $f(x)$ and the Legendre basis polynomial $P_k(x)$:\n$$\nQ_N(f P_k) = \\sum_{j=0}^{N} w_j f(x_j) P_k(x_j).\n$$\nThe unresolved function $f(x)$ is defined as a sum of higher-order Legendre modes:\n$$\nf(x) = \\sum_{m=p+1}^{p+M} a_m\\,P_m(x), \\quad \\text{with} \\quad a_m = \\frac{(-1)^m}{m+1}.\n$$\nTo calculate $Q_N(f P_k)$, we first evaluate $f(x_j)$ at each quadrature node $x_j$ by summing the contributions from the relevant Legendre polynomials $P_m(x_j)$ for $m=p+1, \\dots, p+M$. Then, we evaluate $P_k(x_j)$ at the nodes, compute the product $f(x_j)P_k(x_j)$, multiply by the weights $w_j$, and sum the results.\n\nWith the aliased coefficients $\\widetilde{c}_k$ computed, we can quantify the total aliasing error by calculating the $L^2$ norm of the aliased projection $g_{\\text{alias}}(x) = \\sum_{k=0}^{p} \\widetilde{c}_k P_k(x)$. Using the orthogonality of Legendre polynomials, this norm is given by:\n$$\nE_{\\text{alias}} = \\left\\| g_{\\text{alias}} \\right\\|_{L^2([-1,1])} = \\sqrt{ \\sum_{k=0}^{p} \\left(\\widetilde{c}_k\\right)^2\\,\\frac{2}{2k+1} }.\n$$\nSimilarly, the $L^2$ norm of the original unresolved function $f(x)$ is calculated as:\n$$\nE_{\\text{unresolved}} = \\left\\| f \\right\\|_{L^2([-1,1])} = \\sqrt{ \\sum_{m=p+1}^{p+M} a_m^2\\,\\frac{2}{2m+1} }.\n$$\nThe final step is to compute the dimensionless ratio $R = \\frac{E_{\\text{alias}}}{E_{\\text{unresolved}}}$. A value of $R=0$ implies no aliasing, while $R>0$ indicates that energy from unresolved modes has spuriously appeared in the lower-degree projection.\n\nIt is noteworthy that for a closed Newton–Cotes rule with $N+1$ points derived from an interpolating polynomial of degree $N$, the rule is exact for all polynomials of degree up to $N$. The integrand for the modal coefficient is $f(x)P_k(x)$, which is a polynomial of degree up to $(p+M)+p$. If this degree is less than or equal to $N$, the quadrature $Q_N(fP_k)$ will be exact. Since the exact integral $\\int_{-1}^1 f(x)P_k(x)dx$ is zero by orthogonality (as $f(x)$ only contains modes with degree $>p$ and $P_k(x)$ has degree $\\le p$), the computed coefficients $\\widetilde{c}_k$ will be zero. Consequently, $E_{\\text{alias}}$ and the ratio $R$ will be zero. This applies to test cases A ($p=3, M=2, N=8$; max integrand degree is $3+2+3=8$) and D ($p=4, M=1, N=9$; max integrand degree is $4+1+4=9$). For cases B and C, the integrand degree exceeds $N$, leading to under-integration and non-zero aliasing error.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import eval_legendre\n\ndef solve():\n    \"\"\"\n    Main function to solve the aliasing problem for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (p, N, M)\n        (3, 8, 2),   # Case A\n        (6, 6, 4),   # Case B\n        (10, 4, 10), # Case C\n        (4, 9, 1),   # Case D\n    ]\n\n    results = []\n    for p, N, M in test_cases:\n        # This function encapsulates the logic for a single test case.\n        result = compute_aliasing_ratio(p, N, M)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\ndef compute_aliasing_ratio(p, N, M):\n    \"\"\"\n    Computes the aliasing error ratio R for a given (p, N, M) set.\n    \"\"\"\n    # Step 1: Construct the closed Newton–Cotes weights.\n    # The N+1 equispaced nodes on [-1, 1].\n    nodes = np.linspace(-1.0, 1.0, N + 1)\n\n    # Set up the linear system V*w = b for the weights.\n    # V is the Vandermonde matrix, V_mj = x_j^m.\n    V = np.vander(nodes, N + 1, increasing=True).T\n    \n    # b is the vector of moments of monomials, integral(x^m, -1, 1).\n    b = np.zeros(N + 1)\n    for m in range(N + 1):\n        if m % 2 == 0:\n            b[m] = 2.0 / (m + 1.0)\n        # else b[m] is 0.0\n    \n    # Solve for the weights.\n    weights = np.linalg.solve(V, b)\n\n    # Step 2: Compute the L^2 norm of the unresolved function, E_unresolved.\n    unresolved_sum_sq = 0.0\n    m_range = range(p + 1, p + M + 1)\n    for m in m_range:\n        a_m = ((-1.0)**m) / (m + 1.0)\n        # The squared L^2 norm of P_m is 2 / (2m + 1).\n        norm_sq_Pm = 2.0 / (2.0 * m + 1.0)\n        unresolved_sum_sq += a_m**2 * norm_sq_Pm\n    \n    e_unresolved = np.sqrt(unresolved_sum_sq)\n    \n    # If there are no unresolved modes, the ratio is ill-defined or 0.\n    # Given the problem constraints (M>=1), e_unresolved will be non-zero.\n    if e_unresolved == 0.0:\n        return 0.0\n\n    # Step 3: Compute the underintegrated modal coefficients, tilde_c_k.\n    # First, evaluate the unresolved function f(x) at the quadrature nodes.\n    f_at_nodes = np.zeros(N + 1)\n    for m in m_range:\n        a_m = ((-1.0)**m) / (m + 1.0)\n        f_at_nodes += a_m * eval_legendre(m, nodes)\n    \n    tilde_c = np.zeros(p + 1)\n    k_range = range(p + 1)\n    for k in k_range:\n        # Numerator: Apply quadrature Q_N(f * P_k).\n        Pk_at_nodes = eval_legendre(k, nodes)\n        integrand_at_nodes = f_at_nodes * Pk_at_nodes\n        q_n_fPk = np.dot(weights, integrand_at_nodes)\n        \n        # Denominator is the exact squared norm of P_k.\n        norm_sq_Pk = 2.0 / (2.0 * k + 1.0)\n        \n        tilde_c[k] = q_n_fPk / norm_sq_Pk\n        \n    # Step 4: Compute the L^2 norm of the aliased projection, E_alias.\n    alias_sum_sq = 0.0\n    for k in k_range:\n        norm_sq_Pk = 2.0 / (2.0 * k + 1.0)\n        alias_sum_sq += tilde_c[k]**2 * norm_sq_Pk\n        \n    e_alias = np.sqrt(alias_sum_sq)\n    \n    # Step 5: Quantify the aliasing error via the ratio R.\n    R = e_alias / e_unresolved\n    \n    return R\n\nsolve()\n```"
        },
        {
            "introduction": "The stability of many numerical methods for PDEs relies on the discrete operator inheriting properties of the continuous operator, such as positivity. This final practice bridges the gap between abstract quadrature theory and practical numerical stability by investigating the impact of negative Newton-Cotes weights on a Discontinuous Galerkin (DG) discretization of the diffusion operator . You will assemble the elemental stiffness matrix and discover firsthand how negative weights can destroy its symmetric positive definiteness, a property crucial for a stable and physically meaningful simulation.",
            "id": "3401958",
            "problem": "Consider the one-dimensional diffusion operator in Discontinuous Galerkin (DG) form, restricted to a single element mapped to the reference interval $\\left[-1,1\\right]$. The elemental volume contribution to the bilinear form for diffusion is defined by\n$$\na(u,v) \\;=\\; \\int_{-1}^{1} \\partial_x u(x)\\,\\partial_x v(x)\\,\\mathrm{d}x,\n$$\nwhere $u$ and $v$ belong to a polynomial space on the reference element. In spectral DG practice, a common choice is to represent functions using Legendre polynomials $\\{P_n(x)\\}_{n\\ge 0}$ on $\\left[-1,1\\right]$. To avoid the null mode in the diffusion energy, we consider the subspace spanned by $\\{P_n(x)\\}_{n=1}^{p}$, i.e., we exclude the constant mode $P_0$.\n\nNumerical integration is performed by a Newton–Cotes quadrature formula. Let a closed Newton–Cotes rule be defined over $\\left[-1,1\\right]$ by $N$ equispaced nodes including the endpoints:\n$$\nx_k \\;=\\; -1 + \\frac{2k}{N-1}, \\quad k=0,1,\\dots,N-1,\n$$\nwith associated weights $\\{w_k\\}_{k=0}^{N-1}$. The quadrature approximates integrals of the form $\\int_{-1}^{1} g(x)\\,\\mathrm{d}x$ by the weighted sum $\\sum_{k=0}^{N-1} w_k\\,g(x_k)$. The closed Newton–Cotes weights are defined by exactness on algebraic monomials up to degree $N-1$:\n$$\n\\sum_{k=0}^{N-1} w_k\\,x_k^m \\;=\\; \\int_{-1}^{1} x^m\\,\\mathrm{d}x, \\quad m=0,1,\\dots,N-1.\n$$\nIt is well known that for sufficiently large $N$, some closed Newton–Cotes weights become negative. Underintegration refers to using a quadrature whose exactness degree is lower than the degree required to integrate the bilinear form exactly on the chosen polynomial space.\n\nThe discrete elemental operator (Gram matrix of the bilinear form) is constructed as follows. Let $D(x)$ denote the column vector of derivatives of the Legendre basis functions,\n$$\nD(x) \\;=\\; \\begin{bmatrix} P_1'(x) \\\\ P_2'(x) \\\\ \\vdots \\\\ P_p'(x) \\end{bmatrix},\n$$\nand define the discrete Gram matrix $G\\in\\mathbb{R}^{p\\times p}$ by\n$$\nG \\;=\\; \\sum_{k=0}^{N-1} w_k\\, D(x_k)\\,D(x_k)^\\top.\n$$\nThis construction corresponds to applying the closed Newton–Cotes quadrature to the integrand $\\partial_x P_i(x)\\,\\partial_x P_j(x)$ for all basis indices $i,j$. The symmetric positive definiteness of the bilinear form is lost if the smallest eigenvalue of $G$ is non-positive, which may result either from rank deficiency (e.g., underintegration leading to zero eigenvalues) or from indefiniteness (e.g., negative weights causing negative eigenvalues).\n\nYour task is to implement a program that, for a prescribed set of polynomial degrees $p$ and numbers of quadrature points $N$, constructs $G$ via the procedure above, computes its spectrum, and determines whether symmetric positive definiteness is lost. Use the following test suite:\n- Case $1$: $p=3$, $N=5$.\n- Case $2$: $p=5$, $N=4$ (underintegration with fewer quadrature points than basis dimension).\n- Case $3$: $p=9$, $N=11$ (high-order closed Newton–Cotes with known negative weights).\n- Case $4$: $p=1$, $N=2$ (baseline trapezoidal rule).\n- Case $5$: $p=8$, $N=9$ (closed Newton–Cotes with negative weights).\n\nFor each case:\n1. Construct the closed Newton–Cotes weights $\\{w_k\\}_{k=0}^{N-1}$ by enforcing polynomial exactness up to degree $N-1$ on the equispaced nodes on $\\left[-1,1\\right]$.\n2. Evaluate $P_n'(x_k)$ for $n=1,\\dots,p$ at all quadrature nodes $x_k$.\n3. Assemble $G$ as above and symmetrize it by taking $\\frac{1}{2}\\left(G+G^\\top\\right)$.\n4. Compute the sorted eigenvalues of $G$ in ascending order.\n5. Determine whether symmetric positive definiteness is lost by checking if the smallest eigenvalue is less than or equal to a tolerance $\\varepsilon=10^{-10}$.\n\nYour program must output a single line containing a list of length equal to the number of test cases. Each entry in this list must itself be a list consisting of the sorted eigenvalues (floats) followed by a boolean indicating loss of symmetric positive definiteness (use $True$ if the smallest eigenvalue is $\\le \\varepsilon$, and $False$ otherwise). For example, the output format must look like\n$$\n\\big[ \\,[\\lambda_1,\\lambda_2,\\dots,\\lambda_p,\\text{flag}],\\; \\dots \\,\\big],\n$$\nwith no spaces in the printed string.\n\nNo physical units or angle units are involved. All numerical values must be expressed as floating-point numbers, and all logical decisions must be expressed as booleans. The final line produced by your program should be exactly the list described above, printed as a single line with comma-separated entries enclosed in square brackets.",
            "solution": "The problem requires an analysis of the symmetric positive definiteness of a discrete one-dimensional diffusion operator constructed using a spectral basis of Legendre polynomials within the Discontinuous Galerkin (DG) framework. The integration is performed numerically using closed Newton-Cotes quadrature rules. For specified polynomial degrees $p$ and numbers of quadrature points $N$, we are to construct the discrete Gram matrix $G$, compute its eigenvalues, and determine if positive definiteness is lost. Loss of positive definiteness is defined as the smallest eigenvalue being less than or equal to a tolerance $\\varepsilon = 10^{-10}$.\n\nThe procedure involves several distinct mathematical and computational steps, which are detailed below.\n\nFirst, we define the computational environment. The analysis is performed on the reference element, the interval $\\left[-1, 1\\right]$. The polynomial basis for the DG space is chosen to be $\\{P_n(x)\\}_{n=1}^p$, where $P_n(x)$ is the Legendre polynomial of degree $n$. The constant mode $P_0(x)$ is excluded to eliminate the trivial null mode of the diffusion operator.\n\nThe core of the problem lies in the construction and analysis of the discrete Gram matrix $G$, whose entries are given by the numerical quadrature of the bilinear form $a(u,v) = \\int_{-1}^{1} (\\partial_x u)(\\partial_x v) \\mathrm{d}x$ with $u=P_i(x)$ and $v=P_j(x)$. The discrete matrix $G \\in \\mathbb{R}^{p\\times p}$ is defined as:\n$$\nG_{ij} = \\sum_{k=0}^{N-1} w_k P_i'(x_k) P_j'(x_k).\n$$\n\nThe overall algorithm proceeds as follows for each test case $(p, N)$:\n\n1.  **Construct the Closed Newton-Cotes Quadrature Rule**\n\n    A closed Newton-Cotes quadrature rule on the interval $\\left[-1, 1\\right]$ with $N$ points is defined by a set of $N$ equispaced nodes $\\{x_k\\}_{k=0}^{N-1}$ and corresponding weights $\\{w_k\\}_{k=0}^{N-1}$.\n\n    The nodes are given by the formula:\n    $$\n    x_k = -1 + \\frac{2k}{N-1}, \\quad \\text{for } k=0, 1, \\dots, N-1.\n    $$\n    The weights are determined by enforcing that the quadrature rule exactly integrates polynomials up to degree $N-1$. This leads to a system of $N$ linear equations for the $N$ weights:\n    $$\n    \\sum_{k=0}^{N-1} w_k x_k^m = \\int_{-1}^{1} x^m \\mathrm{d}x, \\quad \\text{for } m=0, 1, \\dots, N-1.\n    $$\n    The integral on the right-hand side evaluates to:\n    $$\n    \\int_{-1}^{1} x^m \\mathrm{d}x = \\frac{1 - (-1)^{m+1}}{m+1} = \\begin{cases} \\frac{2}{m+1} & \\text{if } m \\text{ is even} \\\\ 0 & \\text{if } m \\text{ is odd} \\end{cases}.\n    $$\n    This linear system can be written in matrix form as $V \\mathbf{w} = \\mathbf{b}$, where $V$ is a Vandermonde matrix with entries $V_{mk} = x_k^m$, $\\mathbf{w}$ is the column vector of weights $[w_0, \\dots, w_{N-1}]^\\top$, and $\\mathbf{b}$ is the column vector of the monomial integrals. Solving this system yields the required weights. For $N \\ge 9$ (and some other values like $N=8$), some of these weights become negative, which can compromise the positive definiteness of the resulting discrete operator.\n\n2.  **Evaluate Derivatives of Legendre Polynomials**\n\n    The basis functions are the Legendre polynomials $\\{P_n(x)\\}_{n=1}^p$. We require their first derivatives, $\\{P_n'(x)\\}_{n=1}^p$. These derivatives are themselves polynomials. For each basis function $P_n'(x)$, we must evaluate it at all the quadrature nodes $\\{x_k\\}$. This yields a set of values $P_n'(x_k)$ for $n \\in \\{1, \\dots, p\\}$ and $k \\in \\{0, \\dots, N-1\\}$. These evaluations can be organized into a matrix $D_{\\text{eval}} \\in \\mathbb{R}^{p \\times N}$ where $(D_{\\text{eval}})_{nk} = P_{n+1}'(x_k)$ (using $0$-based indexing for rows).\n\n3.  **Assemble the Discrete Gram Matrix $G$**\n\n    The Gram matrix $G$ is defined by the sum:\n    $$\n    G = \\sum_{k=0}^{N-1} w_k D(x_k) D(x_k)^\\top,\n    $$\n    where $D(x_k)$ is the column vector of basis function derivatives evaluated at node $x_k$:\n    $$\n    D(x_k) = \\begin{bmatrix} P_1'(x_k) \\\\ P_2'(x_k) \\\\ \\vdots \\\\ P_p'(x_k) \\end{bmatrix}.\n    $$\n    Using the matrix of evaluations $D_{\\text{eval}}$ from the previous step and a diagonal matrix $W = \\text{diag}(w_0, \\dots, w_{N-1})$, the matrix $G$ can be computed efficiently as:\n    $$\n    G = D_{\\text{eval}} W D_{\\text{eval}}^\\top.\n    $$\n    From this construction, we can infer potential sources of rank deficiency. The rank of $G$ is at most the rank of $W$ (which is $N$ if all weights are non-zero) and at most the rank of $D_{\\text{eval}}$ (which is at most $\\min(p, N)$). If $N < p$, the rank of $G$ is at most $N$, meaning $G$ will be a $p \\times p$ matrix with rank less than $p$. It will therefore have at least $p-N$ zero eigenvalues, leading to a loss of positive definiteness. This situation is referred to as underintegration.\n\n4.  **Analyze Symmetric Positive Definiteness**\n\n    Theoretically, the matrix $G$ as constructed is symmetric. However, due to floating-point arithmetic, small asymmetries may arise. To ensure a valid eigenvalue decomposition for a symmetric matrix, we first explicitly symmetrize $G$:\n    $$\n    G_{\\text{sym}} = \\frac{1}{2} (G + G^\\top).\n    $$\n    Next, we compute the eigenvalues of $G_{\\text{sym}}$. Since $G_{\\text{sym}}$ is a real symmetric matrix, all its eigenvalues are real. We sort these eigenvalues in ascending order: $\\lambda_1 \\le \\lambda_2 \\le \\dots \\le \\lambda_p$.\n\n    A matrix is symmetric positive definite if and only if all its eigenvalues are strictly positive. The problem defines loss of symmetric positive definiteness as the condition where the smallest eigenvalue, $\\lambda_1$, is non-positive. We check this condition using the given tolerance $\\varepsilon = 10^{-10}$:\n    $$\n    \\text{Loss of SPD} \\iff \\lambda_1 \\le \\varepsilon.\n    $$\n    A boolean flag is set based on this outcome ($True$ for loss, $False$ for preservation). The final result for each case comprises the sorted list of eigenvalues and this boolean flag.\n\nThis procedure is applied to each of the specified test cases, and the results are aggregated into the final output format. The chosen test cases are designed to highlight different numerical phenomena: stable integration ($p=3, N=5$), rank deficiency from underintegration ($p=5, N=4$), and indefiniteness from negative quadrature weights ($p=9, N=11$ and $p=8, N=9$). The case $p=1, N=2$ serves as a simple, stable baseline corresponding to the trapezoidal rule.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import legendre\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases, analyzing the symmetric positive\n    definiteness of a DG diffusion operator matrix.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (3, 5),   # Case 1\n        (5, 4),   # Case 2\n        (9, 11),  # Case 3\n        (1, 2),   # Case 4\n        (8, 9),   # Case 5\n    ]\n    \n    epsilon = 1e-10\n    all_results = []\n\n    for p, N in test_cases:\n        # Step 1: Construct the Closed Newton-Cotes Quadrature Rule\n        # Generate N equispaced nodes on [-1, 1]\n        nodes = np.linspace(-1.0, 1.0, N)\n\n        # Determine weights by solving the linear system for polynomial exactness\n        # The system is V.T @ w = b, where V is a Vandermonde matrix\n        V = np.vander(nodes, N, increasing=True).T\n        \n        # Right-hand side: integrals of x^m from -1 to 1\n        b = np.zeros(N)\n        for m in range(N):\n            if (m + 1) % 2 != 0:\n                b[m] = 2.0 / (m + 1)\n        \n        weights = np.linalg.solve(V, b)\n\n        # Step 2: Evaluate Derivatives of Legendre Polynomials\n        # D_eval is a p x N matrix where D_eval[i, j] = P_{i+1}'(nodes[j])\n        D_eval = np.zeros((p, N))\n        for n_poly in range(1, p + 1):\n            P_n = legendre(n_poly)\n            P_n_prime = P_n.deriv()\n            D_eval[n_poly - 1, :] = P_n_prime(nodes)\n\n        # Step 3: Assemble the Discrete Gram Matrix G\n        # G = D_eval @ diag(weights) @ D_eval.T\n        G = D_eval @ np.diag(weights) @ D_eval.T\n        \n        # Step 4: Analyze Symmetric Positive Definiteness\n        # Symmetrize the matrix to correct for potential floating point inaccuracies\n        G_sym = 0.5 * (G + G.T)\n        \n        # Compute eigenvalues. eigvalsh returns them sorted in ascending order.\n        eigenvalues = np.linalg.eigvalsh(G_sym)\n        \n        # Check if the smallest eigenvalue is non-positive within the tolerance\n        is_lost = eigenvalues[0] <= epsilon\n        \n        # Format the result for this test case\n        result_case = eigenvalues.tolist() + [is_lost]\n        all_results.append(result_case)\n\n    # Final print statement in the exact required format.\n    results_str_list = []\n    for res in all_results:\n        # The last element is a boolean, the rest are floats.\n        # str() on a boolean gives 'True' or 'False' with a capital letter, as required.\n        str_vals = [f\"{v}\" for v in res]\n        results_str_list.append(f\"[{','.join(str_vals)}]\")\n    \n    print(f\"[{','.join(results_str_list)}]\")\n\nsolve()\n```"
        }
    ]
}