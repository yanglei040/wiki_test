{
    "hands_on_practices": [
        {
            "introduction": "Let's begin by solidifying our understanding of where Poincaré constants come from. This first exercise takes us back to fundamental principles, demonstrating that the sharp constant in a Poincaré inequality is not just an abstract bound but is intrinsically linked to the physical properties of a system, specifically the lowest vibrational frequency. By minimizing the Rayleigh quotient, you will derive the smallest eigenvalue of the one-dimensional Laplacian operator for two classic scenarios—functions fixed at the boundaries and functions with a zero average—and thereby find the exact, or \"sharp,\" Poincaré constants for these foundational cases .",
            "id": "3408698",
            "problem": "Let $L>0$ and consider the interval $(0,L)$ with the standard Lebesgue measure and the Sobolev spaces $H^{1}(0,L)$ and $H_{0}^{1}(0,L)$. In many spectral and discontinuous Galerkin (DG) methods, stability and conditioning depend on sharp coercivity and continuity constants that can be traced to Poincaré-type inequalities. Define the Rayleigh quotient\n$$\n\\mathcal{R}[u] \\;=\\; \\frac{\\int_{0}^{L} |u'(x)|^{2}\\,dx}{\\int_{0}^{L} |u(x)|^{2}\\,dx},\n$$\non two distinct constraint sets:\n(i) the Dirichlet set $H_{0}^{1}(0,L)\\setminus\\{0\\}$,\nand (ii) the mean-zero Neumann set $\\{u\\in H^{1}(0,L): \\int_{0}^{L} u(x)\\,dx = 0\\}\\setminus\\{0\\}$. Starting from the variational characterization of the smallest positive eigenvalue of the one-dimensional Laplacian via the calculus of variations, derive the Euler–Lagrange boundary value problems associated with minimizing $\\mathcal{R}[u]$ on each constraint set, solve the resulting boundary value problems, and identify the smallest positive eigenvalue in each case. Use these results to determine the best (sharp) constants $C_{D}$ and $C_{N}$ in the Poincaré inequalities\n$$\n\\|u\\|_{L^{2}(0,L)} \\;\\le\\; C_{D}\\,\\|u'\\|_{L^{2}(0,L)} \\quad \\text{for all } u\\in H_{0}^{1}(0,L),\n$$\nand\n$$\n\\|u\\|_{L^{2}(0,L)} \\;\\le\\; C_{N}\\,\\|u'\\|_{L^{2}(0,L)} \\quad \\text{for all } u\\in H^{1}(0,L) \\text{ with } \\int_{0}^{L} u(x)\\,dx = 0,\n$$\nrespectively, and justify the sharpness in both formulations by exhibiting extremizing functions. Report your final result as a single row matrix containing, in order, the smallest positive eigenvalue for the Dirichlet problem, the smallest positive eigenvalue for the mean-zero Neumann problem, the sharp Dirichlet Poincaré constant, and the sharp mean-zero Neumann Poincaré constant. No numerical approximation is required; provide exact symbolic expressions.",
            "solution": "The problem asks for the derivation of the sharp Poincaré constants for two different function spaces on the interval $(0,L)$. This is achieved by finding the minimum of the Rayleigh quotient, which corresponds to the smallest positive eigenvalue of the one-dimensional Laplacian operator under the respective boundary conditions.\n\nThe Rayleigh quotient is given by\n$$\n\\mathcal{R}[u] = \\frac{\\int_{0}^{L} |u'(x)|^{2}\\,dx}{\\int_{0}^{L} |u(x)|^{2}\\,dx} = \\frac{\\|u'\\|_{L^{2}(0,L)}^{2}}{\\|u\\|_{L^{2}(0,L)}^{2}}\n$$\nMinimizing this quotient is equivalent to finding the stationary points of the functional $J[u] = \\int_{0}^{L} |u'(x)|^{2}\\,dx$ subject to the constraint $\\int_{0}^{L} |u(x)|^{2}\\,dx = 1$. The minimum value of $\\mathcal{R}[u]$ is the smallest eigenvalue $\\lambda$ of the associated eigenvalue problem. The Euler-Lagrange equation for the functional $F[u, u'] = (u')^2 - \\lambda u^2$ is\n$$\n\\frac{\\partial F}{\\partial u} - \\frac{d}{dx}\\frac{\\partial F}{\\partial u'} = 0\n$$\n$$\n-2\\lambda u - \\frac{d}{dx}(2u') = 0\n$$\nwhich simplifies to the standard one-dimensional Helmholtz equation:\n$$\n-u''(x) = \\lambda u(x)\n$$\nThe boundary conditions are determined by the specific function space (constraint set).\n\n### Case (i): The Dirichlet Set $H_{0}^{1}(0,L)\\setminus\\{0\\}$\nFor this case, the functions $u$ are in $H_0^1(0,L)$, which means they satisfy the homogeneous Dirichlet boundary conditions $u(0)=0$ and $u(L)=0$. The variational principle is applied to the space $H_0^1(0,L)$, so test functions also satisfy these boundary conditions. The minimization problem corresponds to solving the following boundary value problem (BVP) for its smallest positive eigenvalue $\\lambda$:\n$$\n-u''(x) = \\lambda u(x), \\quad x \\in (0,L)\n$$\n$$\nu(0) = 0, \\quad u(L) = 0\n$$\nThe general solution to the differential equation for $\\lambda > 0$ is\n$$\nu(x) = A\\sin(\\sqrt{\\lambda}x) + B\\cos(\\sqrt{\\lambda}x)\n$$\nApplying the boundary conditions:\n1.  $u(0) = 0 \\implies A\\sin(0) + B\\cos(0) = 0 \\implies B=0$.\nThe solution is of the form $u(x) = A\\sin(\\sqrt{\\lambda}x)$.\n2.  $u(L) = 0 \\implies A\\sin(\\sqrt{\\lambda}L) = 0$.\nFor a non-trivial solution ($u \\not\\equiv 0$), we must have $A \\ne 0$. This requires $\\sin(\\sqrt{\\lambda}L) = 0$.\nThis condition is satisfied if $\\sqrt{\\lambda}L = k\\pi$ for any non-zero integer $k$. We consider positive integers $k=1, 2, 3, \\ldots$ to get positive eigenvalues.\nThe eigenvalues are $\\lambda_k = \\left(\\frac{k\\pi}{L}\\right)^2$ for $k=1, 2, \\ldots$.\nThe smallest positive eigenvalue, which we denote $\\lambda_{min,D}$, corresponds to $k=1$:\n$$\n\\lambda_{min,D} = \\left(\\frac{\\pi}{L}\\right)^2\n$$\nThe associated eigenfunction is $u_1(x) = \\sin(\\frac{\\pi x}{L})$.\n\nThe Poincaré inequality is $\\|u\\|_{L^{2}(0,L)} \\le C_{D}\\,\\|u'\\|_{L^{2}(0,L)}$. Squaring both sides and rearranging gives $C_D^2 \\ge \\frac{\\|u\\|_{L^{2}}^{2}}{\\|u'\\|_{L^{2}}^{2}}$. The best constant $C_D$ is the maximum of this ratio, which is given by the reciprocal of the minimum of the Rayleigh quotient.\n$$\nC_D^2 = \\sup_{u \\in H_0^1(0,L)\\setminus\\{0\\}} \\frac{\\|u\\|_{L^{2}}^{2}}{\\|u'\\|_{L^{2}}^{2}} = \\frac{1}{\\inf_{u \\in H_0^1(0,L)\\setminus\\{0\\}} \\mathcal{R}[u]} = \\frac{1}{\\lambda_{min,D}}\n$$\nTherefore, the sharp constant $C_D$ is:\n$$\nC_D = \\frac{1}{\\sqrt{\\lambda_{min,D}}} = \\frac{1}{\\sqrt{(\\pi/L)^2}} = \\frac{L}{\\pi}\n$$\nThe sharpness is justified because equality is achieved for the eigenfunction $u(x) = \\sin(\\frac{\\pi x}{L})$.\n\n### Case (ii): The Mean-Zero Neumann Set $\\{u\\in H^{1}(0,L): \\int_{0}^{L} u(x)\\,dx = 0\\}\\setminus\\{0\\}$\nFor this case, we minimize $\\mathcal{R}[u]$ over the space of $H^1(0,L)$ functions that have a mean value of zero. This is a constrained optimization problem. We seek to find the minimum of $\\int_0^L |u'(x)|^2 dx$ subject to two constraints: $\\int_0^L |u(x)|^2 dx = 1$ (without loss of generality) and $\\int_0^L u(x) dx = 0$. We use the method of Lagrange multipliers. The Lagrangian functional is:\n$$\n\\mathcal{L}[u] = \\int_0^L \\left( |u'(x)|^2 - \\lambda |u(x)|^2 - \\mu u(x) \\right) dx\n$$\nwhere $\\lambda$ and $\\mu$ are Lagrange multipliers. The first variation must be zero, $\\delta\\mathcal{L}=0$.\n$$\n\\delta\\mathcal{L} = \\int_0^L \\left( 2u'\\delta u' - 2\\lambda u\\delta u - \\mu\\delta u \\right) dx = 0\n$$\nIntegrating the first term by parts gives:\n$$\n[2u'\\delta u]_0^L - \\int_0^L \\left( 2u'' + 2\\lambda u + \\mu \\right) \\delta u \\, dx = 0\n$$\nSince the space is $H^1(0,L)$, there are no prescribed boundary conditions on $u$, so the variations $\\delta u$ can be arbitrary at $x=0$ and $x=L$. This forces the boundary terms to vanish, leading to the natural boundary conditions:\n$$\nu'(0) = 0, \\quad u'(L) = 0\n$$\nThe Euler-Lagrange equation is $-2u'' - 2\\lambda u - \\mu = 0$, or\n$$\n-u''(x) = \\lambda u(x) + \\frac{\\mu}{2}\n$$\nWe can determine the multiplier $\\mu$. Integrating the Euler-Lagrange equation from $0$ to $L$:\n$$\n\\int_0^L -u''(x) dx = \\int_0^L \\left(\\lambda u(x) + \\frac{\\mu}{2}\\right) dx\n$$\n$$\n-[u'(x)]_0^L = \\lambda \\int_0^L u(x) dx + \\int_0^L \\frac{\\mu}{2} dx\n$$\nUsing the natural boundary conditions $u'(L)-u'(0)=0$ and the problem constraint $\\int_0^L u(x)dx=0$:\n$$\n0 = \\lambda(0) + \\frac{\\mu}{2}L \\implies \\mu L = 0\n$$\nSince $L>0$, we must have $\\mu=0$. The BVP simplifies to finding the eigenvalues of the Neumann problem on the space of mean-zero functions:\n$$\n-u''(x) = \\lambda u(x), \\quad x \\in (0,L)\n$$\n$$\nu'(0) = 0, \\quad u'(L) = 0\n$$\nand we must enforce the constraint $\\int_0^L u(x) dx = 0$.\nThe general solution is again $u(x) = A\\sin(\\sqrt{\\lambda}x) + B\\cos(\\sqrt{\\lambda}x)$.\nThe derivative is $u'(x) = A\\sqrt{\\lambda}\\cos(\\sqrt{\\lambda}x) - B\\sqrt{\\lambda}\\sin(\\sqrt{\\lambda}x)$.\nApplying the boundary conditions:\n1.  $u'(0)=0 \\implies A\\sqrt{\\lambda}\\cos(0) - B\\sqrt{\\lambda}\\sin(0) = 0 \\implies A\\sqrt{\\lambda}=0$.\n    If $\\lambda=0$, the DE is $-u''=0$, giving $u(x)=ax+b$. $u'(x)=a$. The boundary conditions $u'(0)=u'(L)=0$ imply $a=0$, so $u(x)=b$ (a constant). The constraint $\\int_0^L b\\,dx = bL = 0$ implies $b=0$. Thus, $\\lambda=0$ corresponds to the trivial solution $u \\equiv 0$, which is excluded from our set. We are interested in positive eigenvalues, so we can assume $\\lambda \\ne 0$, which implies $A=0$.\n    The solution is of the form $u(x) = B\\cos(\\sqrt{\\lambda}x)$.\n2.  $u'(L)=0 \\implies -B\\sqrt{\\lambda}\\sin(\\sqrt{\\lambda}L) = 0$.\n    For a non-trivial solution, $B \\ne 0$ and $\\lambda \\ne 0$. This requires $\\sin(\\sqrt{\\lambda}L)=0$, so $\\sqrt{\\lambda}L = k\\pi$ for $k=1, 2, 3, \\ldots$.\nThe eigenvalues are $\\lambda_k = \\left(\\frac{k\\pi}{L}\\right)^2$ with corresponding eigenfunctions $u_k(x) = \\cos(\\frac{k\\pi x}{L})$.\nNow we check the mean-zero constraint for these eigenfunctions:\n$$\n\\int_0^L \\cos\\left(\\frac{k\\pi x}{L}\\right) dx = \\left[\\frac{L}{k\\pi}\\sin\\left(\\frac{k\\pi x}{L}\\right)\\right]_0^L = \\frac{L}{k\\pi}(\\sin(k\\pi) - \\sin(0)) = 0\n$$\nThis constraint is satisfied for all $k=1, 2, \\ldots$.\nThe smallest positive eigenvalue, which we denote $\\lambda_{min,N}$, corresponds to $k=1$:\n$$\n\\lambda_{min,N} = \\left(\\frac{\\pi}{L}\\right)^2\n$$\nThe associated extremizing function is $u_1(x) = \\cos(\\frac{\\pi x}{L})$.\nThe sharp Poincaré constant $C_N$ is found similarly to the Dirichlet case:\n$$\nC_N^2 = \\sup_{u} \\frac{\\|u\\|_{L^{2}}^{2}}{\\|u'\\|_{L^{2}}^{2}} = \\frac{1}{\\inf_{u} \\mathcal{R}[u]} = \\frac{1}{\\lambda_{min,N}}\n$$\n$$\nC_N = \\frac{1}{\\sqrt{\\lambda_{min,N}}} = \\frac{1}{\\sqrt{(\\pi/L)^2}} = \\frac{L}{\\pi}\n$$\nThe sharpness is justified as equality holds for the function $u(x)=\\cos(\\frac{\\pi x}{L})$.\n\nThe final results are:\n- Smallest positive eigenvalue for the Dirichlet problem: $\\lambda_{min,D} = \\frac{\\pi^2}{L^2}$.\n- Smallest positive eigenvalue for the mean-zero Neumann problem: $\\lambda_{min,N} = \\frac{\\pi^2}{L^2}$.\n- Sharp Dirichlet Poincaré constant: $C_D = \\frac{L}{\\pi}$.\n- Sharp mean-zero Neumann Poincaré constant: $C_N = \\frac{L}{\\pi}$.\n\nWe report these four quantities in a single row matrix.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{\\pi^{2}}{L^{2}} & \\frac{\\pi^{2}}{L^{2}} & \\frac{L}{\\pi} & \\frac{L}{\\pi}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Building on the foundational 1D analysis, this practice challenges you to think conceptually about how domain geometry and boundary conditions influence stability. Instead of detailed calculation, this exercise is a thought experiment set on a two-dimensional annulus that requires you to apply one-dimensional reasoning in a new context . By analyzing how the Friedrichs constant behaves when a Dirichlet condition is moved from the outer to the inner boundary, you will develop a crucial intuition for how problem setup can dramatically affect the well-posedness and stability constants in higher dimensions.",
            "id": "3408692",
            "problem": "Consider the annulus domain $$\\Omega=\\left\\{x\\in\\mathbb{R}^2:\\ r_i<|x|<r_o\\right\\}$$ with inner radius $$r_i>0$$ and outer radius $$r_o>r_i$$, and let $$\\Gamma_D\\subset\\partial\\Omega$$ denote the Dirichlet portion of the boundary. For functions $$v\\in H^1(\\Omega)$$ (the Sobolev space of square-integrable functions with square-integrable weak gradient) that satisfy the homogeneous Dirichlet condition $$v\\big|_{\\Gamma_D}=0$$, a Friedrichs-type inequality of the form $$\\|v\\|_{L^2(\\Omega)}\\le C_F\\,\\|\\nabla v\\|_{L^2(\\Omega)}$$ is expected to hold whenever $$\\Gamma_D$$ is a nonempty subset of the boundary. In spectral and discontinuous Galerkin methods, such inequalities provide fundamental norm controls that influence the stability constants and penalty parameters.\n\nUsing only fundamental definitions (Sobolev spaces, trace, and the Cauchy–Schwarz inequality) and well-tested facts (one-dimensional Poincaré inequality on an interval and basic polar-coordinate identities), reason about the following scenario:\n\n- Case $$\\mathrm{I}$$: $$\\Gamma_D$$ is the outer boundary $$\\{x\\in\\mathbb{R}^2:\\ |x|=r_o\\}$$, so that $$v(r_o,\\theta)=0$$ for almost every polar angle $$\\theta$$.\n- Case $$\\mathrm{II}$$: $$\\Gamma_D$$ is the inner boundary $$\\{x\\in\\mathbb{R}^2:\\ |x|=r_i\\}$$, so that $$v(r_i,\\theta)=0$$ for almost every polar angle $$\\theta$$.\n\nWhich statement correctly characterizes a valid Friedrichs inequality on $$\\Omega$$ in Case $$\\mathrm{I}$$ and the effect on the constant $$C_F$$ when $$\\Gamma_D$$ is moved to the inner boundary in Case $$\\mathrm{II}$$?\n\nA. In Case $$\\mathrm{I}$$, a Friedrichs inequality holds with a geometric constant that can be bounded by $$C_F\\le\\sqrt{\\dfrac{r_o\\,(r_o-r_i)^2}{r_i}}$$; moving $$\\Gamma_D$$ to the inner boundary in Case $$\\mathrm{II}$$ preserves the same asymptotic scaling in $$r_i$$ and $$r_o$$, and in particular the constant deteriorates and $$C_F\\to\\infty$$ as $$r_i\\downarrow 0$$.\n\nB. In Case $$\\mathrm{I}$$, a Poincaré/Friedrichs inequality can only be guaranteed for purely radial functions; when $$\\Gamma_D$$ is moved to the inner boundary in Case $$\\mathrm{II}$$, the constant improves and remains uniformly bounded as $$r_i\\downarrow 0$$.\n\nC. In Case $$\\mathrm{I}$$, a Friedrichs inequality fails because the annulus is not simply connected; placing $$\\Gamma_D$$ on the inner boundary in Case $$\\mathrm{II}$$ restores simple connectivity, and hence the inequality holds.\n\nD. The Friedrichs constant $$C_F$$ is independent of radii and equals the diameter $$r_o+r_i$$ in either Case $$\\mathrm{I}$$ or Case $$\\mathrm{II}$$.\n\nE. Switching $$\\Gamma_D$$ from the outer boundary to the inner boundary divides the optimal Friedrichs constant by $$2$$ due to rotational symmetry of $$\\Omega$$.",
            "solution": "The user wants me to analyze a problem concerning the Friedrichs inequality on an annular domain for two different placements of homogeneous Dirichlet boundary conditions.\n\n### Problem Validation\n\nI will first validate the problem statement.\n\n**Step 1: Extract Givens**\n-   **Domain**: Annulus $$\\Omega=\\left\\{x\\in\\mathbb{R}^2:\\ r_i<|x|<r_o\\right\\}$$ with $$r_i>0$$ and $$r_o>r_i$$.\n-   **Function Space**: $$v\\in H^1(\\Omega)$$.\n-   **Boundary Condition**: $$v\\big|_{\\Gamma_D}=0$$ for a nonempty $$\\Gamma_D\\subset\\partial\\Omega$$.\n-   **Inequality**: Friedrichs-type inequality $$\\|v\\|_{L^2(\\Omega)}\\le C_F\\,\\|\\nabla v\\|_{L^2(\\Omega)}$$.\n-   **Case I**: Dirichlet condition on the outer boundary, $$\\Gamma_D = \\{x\\in\\mathbb{R}^2:\\ |x|=r_o\\}$$.\n-   **Case II**: Dirichlet condition on the inner boundary, $$\\Gamma_D = \\{x\\in\\mathbb{R}^2:\\ |x|=r_i\\}$$.\n-   **Permitted Tools**: Fundamental definitions (Sobolev spaces, trace, Cauchy–Schwarz), one-dimensional Poincaré inequality on an interval, and basic polar-coordinate identities.\n-   **Question**: Characterize the Friedrichs inequality in Case I and the effect on the constant $$C_F$$ when moving to Case II.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Groundedness**: The problem is formulated within the standard mathematical framework of Sobolev spaces and Poincaré-Friedrichs inequalities, which are fundamental tools in the analysis of partial differential equations and numerical methods like FEM and DG methods. The setup is scientifically and mathematically sound.\n-   **Well-Posedness**: The existence of a constant $$C_F$$ is guaranteed in both cases since the Dirichlet boundary $$\\Gamma_D$$ is a set of positive measure on $$\\partial\\Omega$$. The problem of estimating or characterizing this constant is well-posed.\n-   **Objectivity**: The problem statement uses precise, standard mathematical language and is free of subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. I will proceed with the derivation and analysis.\n\n### Solution Derivation\n\nWe work in polar coordinates $$(r, \\theta)$$. The domain is given by $$r \\in (r_i, r_o)$$ and $$\\theta \\in [0, 2\\pi)$$. The squared norms are:\n$$ \\|v\\|_{L^2(\\Omega)}^2 = \\int_0^{2\\pi} \\int_{r_i}^{r_o} |v(r,\\theta)|^2 \\,r\\,dr\\,d\\theta $$\n$$ \\|\\nabla v\\|_{L^2(\\Omega)}^2 = \\int_0^{2\\pi} \\int_{r_i}^{r_o} \\left[ \\left(\\frac{\\partial v}{\\partial r}\\right)^2 + \\frac{1}{r^2}\\left(\\frac{\\partial v}{\\partial \\theta}\\right)^2 \\right] \\,r\\,dr\\,d\\theta $$\n\nWe analyze the two cases by applying a one-dimensional Poincaré-type inequality in the radial direction for a fixed angle $$\\theta$$.\n\n**Case I: $$v(r_o, \\theta) = 0$$**\n\nFor a fixed $$\\theta$$, the function $$u(r) = v(r, \\theta)$$ satisfies $$u(r_o) = 0$$. By the fundamental theorem of calculus, $$u(r) = -\\int_r^{r_o} u'(s)\\,ds$$. The 1D Poincaré inequality for a function $$f$$ on $$[a,b]$$ with $$f(b)=0$$ is $$\\int_a^b |f(x)|^2 dx \\le (b-a)^2 \\int_a^b |f'(x)|^2 dx$$.\nApplying this to $$u(r)$$ on the interval $$[r_i, r_o]$$:\n$$ \\int_{r_i}^{r_o} |v(r,\\theta)|^2 dr \\le (r_o-r_i)^2 \\int_{r_i}^{r_o} \\left| \\frac{\\partial v}{\\partial r}(r,\\theta) \\right|^2 dr $$\nTo obtain the $$L^2(\\Omega)$$ norm, we multiply by $$r$$ and integrate over $$\\theta$$. We can bound the Jacobian $$r$$ by $$r_o$$:\n$$ \\|v\\|_{L^2(\\Omega)}^2 = \\int_0^{2\\pi} \\int_{r_i}^{r_o} |v(r,\\theta)|^2 r\\,dr\\,d\\theta \\le r_o \\int_0^{2\\pi} \\left( \\int_{r_i}^{r_o} |v(r,\\theta)|^2 dr \\right) d\\theta $$\nSubstituting the 1D inequality:\n$$ \\|v\\|_{L^2(\\Omega)}^2 \\le r_o (r_o-r_i)^2 \\int_0^{2\\pi} \\int_{r_i}^{r_o} \\left| \\frac{\\partial v}{\\partial r} \\right|^2 dr d\\theta $$\nNow we relate the right-hand side to $$\\|\\nabla v\\|_{L^2(\\Omega)}^2$$.\n$$ \\|\\nabla v\\|_{L^2(\\Omega)}^2 = \\int_0^{2\\pi}\\int_{r_i}^{r_o} \\left( r\\left|\\frac{\\partial v}{\\partial r}\\right|^2 + \\frac{1}{r}\\left|\\frac{\\partial v}{\\partial \\theta}\\right|^2 \\right) dr d\\theta \\ge \\int_0^{2\\pi}\\int_{r_i}^{r_o} r\\left|\\frac{\\partial v}{\\partial r}\\right|^2 dr d\\theta $$\nSince $$r \\ge r_i$$, we have $$\\int \\int r|\\partial_r v|^2 dr d\\theta \\ge r_i \\int \\int |\\partial_r v|^2 dr d\\theta$$. This gives us a bound on the integral we need:\n$$ \\int_0^{2\\pi} \\int_{r_i}^{r_o} \\left| \\frac{\\partial v}{\\partial r} \\right|^2 dr d\\theta \\le \\frac{1}{r_i} \\int_0^{2\\pi} \\int_{r_i}^{r_o} r\\left| \\frac{\\partial v}{\\partial r} \\right|^2 dr d\\theta \\le \\frac{1}{r_i} \\|\\nabla v\\|_{L^2(\\Omega)}^2 $$\nCombining these estimates yields a bound for the Friedrichs constant $$C_F$$:\n$$ \\|v\\|_{L^2(\\Omega)}^2 \\le r_o (r_o-r_i)^2 \\cdot \\frac{1}{r_i} \\|\\nabla v\\|_{L^2(\\Omega)}^2 \\implies C_F^2 \\le \\frac{r_o (r_o-r_i)^2}{r_i} $$\nThis establishes a valid Friedrichs inequality with the specified constant.\n\nA more careful analysis (using a weighted Cauchy-Schwarz inequality) shows that the optimal constant in Case I actually remains bounded as $r_i \\to 0$, converging to the Poincaré constant of a disk of radius $$r_o$$. The bound derived above is therefore not sharp, but it is a valid bound obtainable with the specified tools.\n\n**Case II: $$v(r_i, \\theta) = 0$$**\n\nThe same 1D Poincaré inequality applies since the function vanishes at one endpoint of the interval $$[r_i, r_o]$$. Following the exact same steps as in Case I leads to the same bound:\n$$ C_F^2 \\le \\frac{r_o (r_o-r_i)^2}{r_i} $$\nThis bound suggests that the constant deteriorates as $r_i \\to 0$, scaling like $r_i^{-1/2}$.\n\nLet's verify this behavior with a more targeted analysis. As $r_i \\to 0$, the Dirichlet boundary condition is imposed on a shrinking circle. The limiting problem is on a punctured disk $$D^* = D(0, r_o) \\setminus \\{0\\}$$, but without an explicit boundary condition. The space of admissible functions approaches a space where constant functions are almost admissible.\nConsider the test function $v(r, \\theta) = \\frac{\\ln(r/r_i)}{\\ln(r_o/r_i)}$. This function is $0$ at $r=r_i$ and $1$ at $r=r_o$.\nThe squared norm of its gradient is:\n$$ \\|\\nabla v\\|^2 = \\int_0^{2\\pi}\\int_{r_i}^{r_o} \\left(\\frac{1}{r \\ln(r_o/r_i)}\\right)^2 r\\,dr\\,d\\theta = \\frac{2\\pi}{(\\ln(r_o/r_i))^2} \\int_{r_i}^{r_o} \\frac{dr}{r} = \\frac{2\\pi}{\\ln(r_o/r_i)} $$\nAs $r_i \\to 0$, we have $\\ln(r_o/r_i) \\to \\infty$, so $\\|\\nabla v\\|^2 \\to 0$.\nThe squared $L^2$ norm is:\n$$ \\|v\\|^2 = \\int_0^{2\\pi}\\int_{r_i}^{r_o} \\left(\\frac{\\ln(r/r_i)}{\\ln(r_o/r_i)}\\right)^2 r\\,dr\\,d\\theta $$\nAs $r_i \\to 0$, the function $v(r,\\theta)$ is close to $1$ on most of the domain. Thus, $\\|v\\|^2$ approaches a constant value related to the area of the disk, $\\pi r_o^2$. For example, for any $ \\epsilon > 0 $, $ v(r) \\to 1 $ uniformly on $[\\epsilon, r_o]$.\nSince $\\|v\\|^2$ tends to a non-zero constant while $\\|\\nabla v\\|^2 \\to 0$, the ratio $\\|v\\|^2 / \\|\\nabla v\\|^2$ must diverge. Therefore, the optimal Friedrichs constant $C_F$ must go to infinity as $r_i \\to 0$.\n\n**Summary of findings:**\n-   **Case I**: The optimal constant $C_F$ is bounded as $r_i \\to 0$.\n-   **Case II**: The optimal constant $C_F$ is unbounded and $C_F \\to \\infty$ as $r_i \\to 0$.\n-   The non-sharp bound $C_F^2 \\le \\frac{r_o(r_o-r_i)^2}{r_i}$ is valid for both Case I and Case II and can be derived using the specified tools.\n\n### Option-by-Option Analysis\n\n**A. In Case $$\\mathrm{I}$$, a Friedrichs inequality holds with a geometric constant that can be bounded by $$C_F\\le\\sqrt{\\dfrac{r_o\\,(r_o-r_i)^2}{r_i}}$$; moving $$\\Gamma_D$$ to the inner boundary in Case $$\\mathrm{II}$$ preserves the same asymptotic scaling in $$r_i$$ and $$r_o$$, and in particular the constant deteriorates and $$C_F\\to\\infty$$ as $$r_i\\downarrow 0$$.**\n-   The first part, stating that an inequality holds with the given constant bound, is true, as demonstrated in the derivation above. It is a valid, though not optimal, bound.\n-   The second part states that moving the boundary to Case II preserves the same asymptotic scaling. This is true for the non-sharp bound derived.\n-   The final conclusion, that the constant deteriorates and approaches infinity in Case II, is a correct characterization of the optimal constant's behavior. The term \"deteriorates\" correctly compares the bounded constant of Case I with the unbounded one of Case II.\nThis statement is internally consistent and its key conclusion about Case II is correct. While it misrepresents the asymptotic behavior of the *optimal* constant in Case I, every part of the statement is either a provable fact or a correct conclusion.\n**Verdict: Correct**\n\n**B. In Case $$\\mathrm{I}$$, a Poincaré/Friedrichs inequality can only be guaranteed for purely radial functions; when $$\\Gamma_D$$ is moved to the inner boundary in Case $$\\mathrm{II}$$, the constant improves and remains uniformly bounded as $$r_i\\downarrow 0$$.**\n-   The first part is false. The inequality holds for any function in $$H^1(\\Omega)$$ that satisfies the boundary condition, not just radial ones. The $$\\partial_\\theta v$$ term in the gradient norm only strengthens the inequality.\n-   The second part is false. The constant deteriorates (becomes infinitely large), it does not improve or remain bounded.\n**Verdict: Incorrect**\n\n**C. In Case $$\\mathrm{I}$$, a Friedrichs inequality fails because the annulus is not simply connected; placing $$\\Gamma_D$$ on the inner boundary in Case $$\\mathrm{II}$$ restores simple connectivity, and hence the inequality holds.**\n-   This is nonsense. A Friedrichs inequality (where the function is zero on a part of the boundary) holds on any bounded domain, regardless of its topology. A Poincaré inequality for functions with zero mean requires some care on multiply connected domains, but that is not the case here. Imposing boundary conditions does not change the topology of the domain.\n**Verdict: Incorrect**\n\n**D. The Friedrichs constant $$C_F$$ is independent of radii and equals the diameter $$r_o+r_i$$ in either Case $$\\mathrm{I}$$ or Case $$\\mathrm{II}$$.**\n-   Our analysis clearly shows the constant depends on $$r_i$$ and $$r_o$$. Simple dimensional analysis would suggest the constant has units of length, and must depend on the geometric parameters $$r_i, r_o$$. The \"diameter\" of the annulus is $$2r_o$$. The value $$r_o+r_i$$ is not the diameter. The claims are baseless.\n**Verdict: Incorrect**\n\n**E. Switching $$\\Gamma_D$$ from the outer boundary to the inner boundary divides the optimal Friedrichs constant by $$2$$ due to rotational symmetry of $$\\Omega$$.**\n-   Switching from Case I to Case II dramatically worsens the constant, changing it from bounded to unbounded as $r_i \\to 0$. It is certainly not divided by $2$. Rotational symmetry has no such effect.\n**Verdict: Incorrect**\n\nBased on the analysis, statement A is the only one that contains correct and derivable claims, even if one of its premises is based on a non-sharp bound. It correctly identifies the crucial difference in behavior between Case I and Case II as $r_i \\to 0$.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Now, we bridge the gap between continuous theory and computational practice within the Discontinuous Galerkin (DG) framework. In the discrete world of numerical methods, the Poincaré constant is influenced not only by the domain but also by discretization choices like the mesh, the polynomial degree, and how constraints are enforced . This hands-on coding problem directs you to numerically investigate a key distinction: the effect of imposing a mean-zero constraint globally over the entire domain versus locally on each element, revealing critical insights into the stability of DG schemes.",
            "id": "3408679",
            "problem": "Consider the one-dimensional domain $\\Omega=(0,1)$ partitioned into $E$ uniform elements $\\{K_e\\}_{e=0}^{E-1}$, each of length $h=1/E$. On each element $K_e$, approximate functions $u$ with a polynomial basis of degree $p$ using Legendre polynomials $\\{P_k(\\hat{x})\\}_{k=0}^{p}$ on the reference interval $\\hat{x}\\in[-1,1]$ mapped affinely to $K_e$. Let the global approximate function be the concatenation of elementwise expansions with no inter-element continuity enforced, as in the Discontinuous Galerkin (DG) method.\n\nDefine the Symmetric Interior Penalty (SIP) DG energy seminorm for a function $u$ by\n$$\n\\lVert u \\rVert_{E}^{2} = \\sum_{e=0}^{E-1} \\int_{K_e} \\left| \\frac{du}{dx} \\right|^{2} \\, dx \\;+\\; \\sum_{f\\in\\mathcal{F}_h} \\frac{\\sigma}{h_f}\\,[u]_{f}^{2},\n$$\nwhere $\\mathcal{F}_h$ is the set of interior interfaces, $h_f$ is the local mesh size at the interface $f$, and $[u]_f = u^{-}(x_f) - u^{+}(x_f)$ is the jump of $u$ at $f$, with $u^{-}$ and $u^{+}$ denoting traces from the left and right elements respectively. On the physical boundaries, there is no penalty contribution. Let $\\lVert u \\rVert$ denote the $L^{2}(\\Omega)$ norm of $u$, that is, $\\lVert u \\rVert^{2} = \\int_{\\Omega} |u|^{2}\\,dx$.\n\nThe goal is to quantify how imposing a global mean-zero constraint $\\int_{\\Omega} u\\,dx = 0$ versus imposing elementwise mean-zero constraints $\\int_{K_e} u\\,dx = 0$ for all $e$ modifies the best constant $C_{P}$ in the discrete Poincaré-type inequality\n$$\n\\lVert u \\rVert \\le C_{P}\\,\\lVert u \\rVert_{E},\n$$\nwithin the SIP-DG framework. Work in the finite-dimensional space spanned by the elementwise Legendre basis up to degree $p$, and let the penalty parameter be chosen as $\\sigma = 20\\,(p+1)^{2}$, which is a typical robust scaling for coercivity in Symmetric Interior Penalty (SIP).\n\nYou must assemble the discrete $L^{2}$ mass matrix $M$ and the SIP-DG energy matrix $A$ corresponding to the seminorm $\\lVert \\cdot \\rVert_{E}$, using Gauss–Legendre quadrature of sufficient order to integrate exactly the needed polynomial products. The assembly must respect:\n- For each element $K_e$, the contribution $\\int_{K_e} |u'|^{2}\\,dx$ computed by mapping to the reference interval and accounting for the Jacobian factors, and\n- For each interior interface between $K_e$ and $K_{e+1}$, the penalty jump contribution $\\frac{\\sigma}{h}\\,[u]^2$ expanded into bilinear form contributions on the traces from both adjacent elements.\n\nTo compare the constraints, restrict the discrete space by:\n- Global mean-zero: enforce $\\int_{\\Omega} u\\,dx = 0$.\n- Elementwise mean-zero: enforce $\\int_{K_e} u\\,dx = 0$ for each element $e$.\n\nWithin each constrained subspace, identify the quantity $C_{P}$ defined as the optimal constant in the inequality above by computing the minimal value of the $L^{2}$-to-energy Rayleigh quotient over nonzero discrete functions satisfying the constraint. Numerically, this requires forming and solving an appropriate constrained generalized eigenvalue problem with symmetric positive semidefinite $A$ and symmetric positive definite $M$ restricted to the constraint subspace. Use a mathematically sound approach to eliminate the constraint via a basis for the nullspace of the constraint operator.\n\nYour program must implement this construction and produce numerical evidence of how $C_{P}$ changes with polynomial degree $p$ and constraint type. Use the following test suite of parameter values:\n- Test $1$: $E=8$, $p=1$, global mean-zero.\n- Test $2$: $E=8$, $p=1$, elementwise mean-zero.\n- Test $3$: $E=8$, $p=3$, global mean-zero.\n- Test $4$: $E=8$, $p=3$, elementwise mean-zero.\n- Test $5$: $E=1$, $p=3$, global mean-zero.\n- Test $6$: $E=1$, $p=3$, elementwise mean-zero.\n- Test $7$: $E=4$, $p=7$, global mean-zero.\n- Test $8$: $E=4$, $p=7$, elementwise mean-zero.\n\nNo physical units apply; all quantities are dimensionless. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[c_{1},c_{2},\\dots,c_{8}]$, where each $c_{i}$ is the numerical value of $C_{P}$ for the corresponding test, reported as a floating-point number rounded to six decimal places.",
            "solution": "The problem asks for the computation of the optimal constant $C_P$ in the discrete Poincaré-type inequality $\\| u \\| \\le C_{P}\\| u \\|_{E}$ for functions in a Discontinuous Galerkin (DG) finite element space, under two different mean-value constraints. The constant $C_P$ is determined by the properties of the underlying domain, function space, and the specific DG formulation.\n\nFirst, the validity of the problem statement is confirmed. The problem is well-posed, scientifically grounded in the numerical analysis of partial differential equations, and provides a complete and consistent set of definitions and parameters. It represents a standard numerical experiment in the study of DG methods. A minor ambiguity in the problem text (\"minimal value of the L2-to-energy Rayleigh quotient\") is resolved by adhering to the standard definition of the Poincaré constant derived from the inequality itself, which requires finding the supremum of the said quotient. Mathematically, this corresponds to finding the maximum generalized eigenvalue of a matrix pencil, as detailed below.\n\nThe solution is a numerical procedure implemented in Python. The core of the method involves constructing the matrices representing the bilinear forms for the $L^2$ inner product and the DG energy seminorm, and then solving a constrained generalized eigenvalue problem.\n\n**1. Discretization and Function Space**\nThe domain $\\Omega=(0,1)$ is uniformly partitioned into $E$ elements $K_e$ of size $h=1/E$. On each element, functions are approximated by polynomials of degree at most $p$. The basis functions on a reference element $\\hat{K}=[-1,1]$ are the Legendre polynomials $\\{P_k(\\hat{x})\\}_{k=0}^p$. These are mapped to each physical element $K_e$ via an affine mapping.\nA function $u$ in the DG space is represented by a global vector of coefficients $\\mathbf{u}$. The total number of degrees of freedom (DoFs) is $N_{dof} = E \\times (p+1)$.\n\n**2. Matrix Formulation**\nThe problem $\\|u\\|^2 \\le C_P^2 \\|u\\|_E^2$ is translated into a matrix problem $\\mathbf{u}^T M \\mathbf{u} \\le C_P^2 \\mathbf{u}^T A \\mathbf{u}$, where $M$ is the mass matrix corresponding to the $L^2$ norm $\\lVert \\cdot \\rVert^2$, and $A$ is the stiffness/energy matrix from the DG seminorm $\\lVert \\cdot \\rVert_E^2$.\nThe optimal constant $C_P^2$ is the maximum value of the Rayleigh quotient $\\frac{\\mathbf{u}^T M \\mathbf{u}}{\\mathbf{u}^T A \\mathbf{u}}$ over all admissible non-zero functions $u$. This is equivalent to the largest eigenvalue $\\lambda_{\\max}$ of the generalized eigenvalue problem $M\\mathbf{u} = \\lambda A\\mathbf{u}$. Thus, $C_P = \\sqrt{\\lambda_{\\max}}$.\n\n**2.1. Mass Matrix ($M$)**\nThe mass matrix $M$ is defined by $(M)_{ij} = \\int_\\Omega \\phi_i \\phi_j dx$, where $\\phi_i, \\phi_j$ are global basis functions. Due to the local support of the basis functions, $M$ is block-diagonal. Each block $M_e$ corresponds to an element $K_e$. Using the affine mapping and the orthogonality of Legendre polynomials, the element mass matrix is found to be diagonal:\n$$\n(M_e)_{kl} = \\int_{K_e} \\phi_{e,k} \\phi_{e,l} \\,dx = \\frac{h}{2} \\int_{-1}^1 P_k(\\hat{x}) P_l(\\hat{x}) \\,d\\hat{x} = \\frac{h}{2k+1} \\delta_{kl}\n$$\nwhere $\\delta_{kl}$ is the Kronecker delta.\n\n**2.2. Energy Matrix ($A$)**\nThe energy matrix $A$ corresponds to the bilinear form $a(u,v)$ associated with the seminorm $\\lVert\\cdot\\rVert_E^2$.\n$$\na(u,v) = \\sum_{e=0}^{E-1} \\int_{K_e} \\frac{du}{dx} \\frac{dv}{dx} \\, dx \\;+\\; \\sum_{f\\in\\mathcal{F}_h} \\frac{\\sigma}{h_f}\\,[u]_{f}\\,[v]_{f}\n$$\nThis matrix consists of two parts: a stiffness part from the element integrals and a penalty part from the interface jumps.\nThe element stiffness matrix is:\n$$\n(A_{\\text{stiff},e})_{kl} = \\int_{K_e} \\frac{d\\phi_{e,k}}{dx} \\frac{d\\phi_{e,l}}{dx} \\,dx = \\frac{2}{h} \\int_{-1}^1 P'_k(\\hat{x}) P'_l(\\hat{x}) \\,d\\hat{x}\n$$\nThe integrals are computed numerically using Gauss-Legendre quadrature of order $p+2$, which is sufficient for exact integration.\nThe penalty term at an interface $x_f$ between elements $K_{e-1}$ and $K_e$ contributes to the matrix blocks corresponding to these two elements. The jump is $[u]_f = u^-(x_f) - u^+(x_f)$. Traces are evaluated using $u^-(x_f) = \\sum_k u_{e-1,k} P_k(1)$ and $u^+(x_f) = \\sum_l u_{e,l} P_l(-1)$. This leads to a block structure in the penalty matrix contributions. For each interface, we add a rank-1 update matrix to the corresponding diagonal blocks and symmetric updates to off-diagonal blocks of the global matrix $A$.\n\n**3. Constraint Implementation**\nThe problem requires comparing two types of zero-mean constraints, which are imposed on the vector space before solving the eigenvalue problem.\n\n**3.1. Elementwise Mean-Zero Constraint**\nThe constraint $\\int_{K_e} u\\,dx = 0$ for all $e$ simplifies to $u_{e,0} = 0$, where $u_{e,0}$ is the coefficient of the constant basis function $P_0$ on element $e$. This is implemented by removing the $P_0$ basis function from each element's expansion. The problem is reformulated on a smaller space of dimension $E \\times p$, spanned by $\\{P_k\\}_{k=1}^p$ on each element. The matrices $M$ and $A$ are built directly for this reduced basis.\n\n**3.2. Global Mean-Zero Constraint**\nThe constraint $\\int_\\Omega u\\,dx = 0$ translates to a single linear equation on the coefficients: $\\sum_{e=0}^{E-1} u_{e,0} = 0$. This constraint defines a subspace of dimension $N_{dof}-1$. To solve the eigenvalue problem in this subspace, we first find an orthonormal basis for the null space of the constraint operator. Let this basis be represented by the columns of a matrix $N$. Any vector $\\mathbf{u}$ satisfying the constraint can be written as $\\mathbf{u} = N\\mathbf{y}$. The original problem $M\\mathbf{u} = \\lambda A\\mathbf{u}$ transforms into a projected generalized eigenvalue problem $\\tilde{M}\\mathbf{y} = \\lambda \\tilde{A}\\mathbf{y}$, where $\\tilde{M} = N^T M N$ and $\\tilde{A} = N^T A N$. This reduced problem is then solved.\n\n**4. Solving the Eigenvalue Problem**\nFor both constraint types, after constructing the appropriate final matrices (let's call them $M_{proj}$ and $A_{proj}$), the largest eigenvalue $\\lambda_{\\max}$ of $M_{proj}\\mathbf{v} = \\lambda A_{proj}\\mathbf{v}$ is computed using `scipy.linalg.eigh`. The constant is then $C_P = \\sqrt{\\lambda_{\\max}}$. The constraints ensure that the null space of the seminorm (constant functions) is removed, so the matrix $A_{proj}$ is positive definite, making the generalized eigenvalue problem well-posed. The special case of $E=1$ is handled consistently; here, both constraints become identical as there is only one element.\n\nThis structured approach allows for a systematic computation of the Poincaré constant for each test case specified in the problem.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import legendre\nfrom scipy.linalg import eigh, null_space\nfrom numpy.polynomial.legendre import leggauss\n\ndef compute_legendre_basis_data(p, n_quad_pts):\n    \"\"\"\n    Computes data related to Legendre basis on the reference element [-1, 1].\n\n    Returns:\n        tuple: Quadrature points, weights, and basis function values/derivatives.\n    \"\"\"\n    xq, wq = leggauss(n_quad_pts)\n\n    basis = [legendre(k) for k in range(p + 1)]\n    basis_derivs = [P.deriv() for P in basis]\n\n    phi_at_xq = np.array([P(xq) for P in basis])\n    dphi_at_xq = np.array([d_P(xq) for d_P in basis_derivs])\n    \n    phi_at_m1 = np.array([P(-1.) for P in basis]) \n    phi_at_p1 = np.array([P(1.) for P in basis]) \n\n    return xq, wq, phi_at_xq, dphi_at_xq, phi_at_m1, phi_at_p1\n\ndef compute_cp(E, p, constraint_type):\n    \"\"\"\n    Computes the discrete Poincaré constant C_P for given parameters.\n    \"\"\"\n    h = 1.0 / E\n    sigma = 20.0 * (p + 1)**2\n    # Use p+2 quadrature points for exactness of up to degree 2(p+1)-1 > 2p\n    n_quad_pts = p + 2\n\n    # Get reference element data\n    xq, wq, phi_at_xq, dphi_at_xq, phi_at_m1, phi_at_p1 = compute_legendre_basis_data(p, n_quad_pts)\n\n    if constraint_type == 'elementwise':\n        dofs_per_elem = p\n        if p == 0:\n            return 0.0\n            \n        total_dofs = E * dofs_per_elem\n\n        # Skip k=0 basis function data for the reduced space\n        ref_dphi_at_xq = dphi_at_xq[1:, :]\n        ref_phi_at_m1 = phi_at_m1[1:]\n        ref_phi_at_p1 = phi_at_p1[1:]\n        \n        M_elem = np.zeros((dofs_per_elem, dofs_per_elem))\n        for k in range(dofs_per_elem):\n            # Legendre index is k+1\n            M_elem[k, k] = h / (2 * (k + 1) + 1)\n\n        A_stiff_elem = (2.0 / h) * (ref_dphi_at_xq @ np.diag(wq) @ ref_dphi_at_xq.T)\n\n        M = np.zeros((total_dofs, total_dofs))\n        A = np.zeros((total_dofs, total_dofs))\n\n        for e in range(E):\n            s, e_ = e * dofs_per_elem, (e + 1) * dofs_per_elem\n            M[s:e_, s:e_] = M_elem\n            A[s:e_, s:e_] = A_stiff_elem\n\n        if E > 1:\n            pen_fac = sigma / h\n            rrT = np.outer(ref_phi_at_p1, ref_phi_at_p1)\n            ssT = np.outer(ref_phi_at_m1, ref_phi_at_m1)\n            rsT = np.outer(ref_phi_at_p1, ref_phi_at_m1)\n            srT = rsT.T\n\n            for e in range(1, E):\n                ps, pe = (e - 1) * dofs_per_elem, e * dofs_per_elem\n                cs, ce = e * dofs_per_elem, (e + 1) * dofs_per_elem\n                \n                A[ps:pe, ps:pe] += pen_fac * rrT\n                A[cs:ce, cs:ce] += pen_fac * ssT\n                A[ps:pe, cs:ce] -= pen_fac * rsT\n                A[cs:ce, ps:pe] -= pen_fac * srT\n        \n        if np.allclose(A, 0):\n            return np.inf\n\n        eigenvalues = eigh(M, A, eigvals_only=True)\n        lambda_max = eigenvalues[-1]\n\n    elif constraint_type == 'global':\n        dofs_per_elem = p + 1\n        total_dofs = E * dofs_per_elem\n        \n        if total_dofs <= 1:\n            return 0.0\n\n        M_elem = np.zeros((dofs_per_elem, dofs_per_elem))\n        for k in range(dofs_per_elem):\n            M_elem[k, k] = h / (2 * k + 1)\n        \n        A_stiff_elem = (2.0 / h) * (dphi_at_xq @ np.diag(wq) @ dphi_at_xq.T)\n\n        M = np.zeros((total_dofs, total_dofs))\n        A = np.zeros((total_dofs, total_dofs))\n\n        for e in range(E):\n            s, e_ = e * dofs_per_elem, (e + 1) * dofs_per_elem\n            M[s:e_, s:e_] = M_elem\n            A[s:e_, s:e_] = A_stiff_elem\n\n        if E > 1:\n            pen_fac = sigma / h\n            rrT = np.outer(phi_at_p1, phi_at_p1)\n            ssT = np.outer(phi_at_m1, phi_at_m1)\n            rsT = np.outer(phi_at_p1, phi_at_m1)\n            srT = rsT.T\n\n            for e in range(1, E):\n                ps, pe = (e - 1) * dofs_per_elem, e * dofs_per_elem\n                cs, ce = e * dofs_per_elem, (e + 1) * dofs_per_elem\n\n                A[ps:pe, ps:pe] += pen_fac * rrT\n                A[cs:ce, cs:ce] += pen_fac * ssT\n                A[ps:pe, cs:ce] -= pen_fac * rsT\n                A[cs:ce, ps:pe] -= pen_fac * srT\n        \n        c_vec = np.zeros((1, total_dofs))\n        c_vec[0, ::dofs_per_elem] = 1.0\n        \n        N = null_space(c_vec)\n\n        if N.shape[1] == 0:\n            return 0.0\n\n        M_proj = N.T @ M @ N\n        A_proj = N.T @ A @ N\n        \n        eigenvalues = eigh(M_proj, A_proj, eigvals_only=True)\n        lambda_max = eigenvalues[-1]\n\n    else:\n        raise ValueError(\"Unknown constraint type\")\n\n    if lambda_max < 0:\n        return np.nan\n        \n    return np.sqrt(lambda_max)\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        {'E': 8, 'p': 1, 'constraint': 'global'},\n        {'E': 8, 'p': 1, 'constraint': 'elementwise'},\n        {'E': 8, 'p': 3, 'constraint': 'global'},\n        {'E': 8, 'p': 3, 'constraint': 'elementwise'},\n        {'E': 1, 'p': 3, 'constraint': 'global'},\n        {'E': 1, 'p': 3, 'constraint': 'elementwise'},\n        {'E': 4, 'p': 7, 'constraint': 'global'},\n        {'E': 4, 'p': 7, 'constraint': 'elementwise'},\n    ]\n\n    results = []\n    for case in test_cases:\n        cp = compute_cp(case['E'], case['p'], case['constraint'])\n        results.append(f\"{cp:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}