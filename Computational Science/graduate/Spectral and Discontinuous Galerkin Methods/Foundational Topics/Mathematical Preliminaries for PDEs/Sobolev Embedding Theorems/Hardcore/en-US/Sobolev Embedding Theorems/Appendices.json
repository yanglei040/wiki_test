{
    "hands_on_practices": [
        {
            "introduction": "Understanding Sobolev embeddings begins with the simplest cases. This foundational exercise guides you through deriving the sharp constant for the classic embedding of $H^1$ into a space of Hölder continuous functions in one dimension. By applying the Fundamental Theorem of Calculus and the Cauchy-Schwarz inequality, you will gain first-hand experience with the core analytical techniques used in the proof of many embedding theorems .",
            "id": "3414907",
            "problem": "Let $\\Omega = (0,1)$ and consider the Sobolev space $H^{1}(\\Omega)$ and the Hölder space $C^{0,\\alpha}(\\Omega)$ with exponent $\\alpha \\in (0,1)$. For a function $f \\in C^{0,\\alpha}(\\Omega)$, define the Hölder seminorm\n$$\n[f]_{C^{0,\\alpha}(\\Omega)} := \\sup_{\\substack{x,y \\in \\Omega\\\\ x \\neq y}} \\frac{|f(x) - f(y)|}{|x-y|^{\\alpha}}.\n$$\nIn the context of spectral methods and Discontinuous Galerkin (DG) methods, sharp embedding constants control pointwise oscillation in terms of square-integrable gradients and directly influence a priori error estimates. Assume only the fundamental properties of functions in $H^{1}(\\Omega)$, the Fundamental Theorem of Calculus, and classical inequalities. Using integral representations valid for $H^{1}(\\Omega)$ functions and first principles reasoning, determine the smallest constant $C_{\\ast}$ such that the inequality\n$$\n[f]_{C^{0,1/2}(\\Omega)} \\leq C_{\\ast} \\,\\|f'\\|_{L^{2}(\\Omega)}\n$$\nholds for all $f \\in H^{1}(\\Omega)$. Then, briefly compare your explicit one-dimensional constant with the scaling predicted by the general $n$-dimensional Morrey-type estimate for $W^{1,p}(\\Omega)$ with $pn$, specialized to $n=1$, $p=2$, on a unit interval, but report only the value of $C_{\\ast}$ as your final answer. No rounding is required, and no physical units are involved. Provide the exact value of $C_{\\ast}$.",
            "solution": "The problem requires finding the smallest constant $C_{\\ast}$, known as the sharp constant, for the embedding of the Sobolev space $H^{1}(\\Omega)$ into the Hölder space $C^{0,1/2}(\\Omega)$ on the domain $\\Omega = (0,1)$. The inequality in question is:\n$$\n[f]_{C^{0,1/2}(\\Omega)} \\leq C_{\\ast} \\,\\|f'\\|_{L^{2}(\\Omega)}\n$$\nfor all functions $f \\in H^{1}(\\Omega)$, where $f'$ denotes the weak derivative of $f$. The Hölder seminorm is defined as:\n$$\n[f]_{C^{0,1/2}(\\Omega)} := \\sup_{\\substack{x,y \\in \\Omega\\\\ x \\neq y}} \\frac{|f(x) - f(y)|}{|x-y|^{1/2}}\n$$\nand the norm in $L^{2}(\\Omega)$ is $\\|f'\\|_{L^{2}(\\Omega)} = \\left(\\int_{0}^{1} |f'(t)|^2 \\, dt\\right)^{1/2}$.\n\nThe sharp constant $C_{\\ast}$ is the supremum of the ratio of the left-hand side to the right-hand side over all admissible functions:\n$$\nC_{\\ast} = \\sup_{f \\in H^{1}(\\Omega), f' \\not\\equiv 0} \\frac{[f]_{C^{0,1/2}(\\Omega)}}{\\|f'\\|_{L^{2}(\\Omega)}}\n$$\nWe will determine $C_{\\ast}$ in two steps: first, by finding an upper bound for the constant, and second, by showing this bound is attained or can be approached arbitrarily closely.\n\nStep 1: Deriving an upper bound for $C_{\\ast}$.\n\nLet $f \\in H^{1}(\\Omega)$. Functions in $H^{1}$ on a one-dimensional interval are absolutely continuous. Therefore, for any two points $x, y \\in \\Omega$, we can use the Fundamental Theorem of Calculus to write:\n$$\nf(x) - f(y) = \\int_{y}^{x} f'(t) \\, dt\n$$\nWithout loss of generality, let $x  y$. Taking the absolute value, we have:\n$$\n|f(x) - f(y)| = \\left| \\int_{y}^{x} f'(t) \\, dt \\right| = \\left| \\int_{y}^{x} 1 \\cdot f'(t) \\, dt \\right|\n$$\nWe apply the Cauchy-Schwarz inequality for integrals to the expression on the right-hand side:\n$$\n\\left| \\int_{y}^{x} 1 \\cdot f'(t) \\, dt \\right| \\leq \\left( \\int_{y}^{x} 1^2 \\, dt \\right)^{1/2} \\left( \\int_{y}^{x} |f'(t)|^2 \\, dt \\right)^{1/2}\n$$\nThis simplifies to:\n$$\n|f(x) - f(y)| \\leq (x-y)^{1/2} \\left( \\int_{y}^{x} |f'(t)|^2 \\, dt \\right)^{1/2}\n$$\nDividing by $|x-y|^{1/2} = (x-y)^{1/2}$ (since $x \\neq y$), we obtain:\n$$\n\\frac{|f(x) - f(y)|}{|x-y|^{1/2}} \\leq \\left( \\int_{y}^{x} |f'(t)|^2 \\, dt \\right)^{1/2}\n$$\nThe integral over the subinterval $[y, x]$ is bounded by the integral over the entire domain $\\Omega = (0,1)$:\n$$\n\\left( \\int_{y}^{x} |f'(t)|^2 \\, dt \\right)^{1/2} \\leq \\left( \\int_{0}^{1} |f'(t)|^2 \\, dt \\right)^{1/2} = \\|f'\\|_{L^{2}(\\Omega)}\n$$\nCombining these inequalities, we have for any pair $x, y \\in \\Omega$ with $x \\neq y$:\n$$\n\\frac{|f(x) - f(y)|}{|x-y|^{1/2}} \\leq \\|f'\\|_{L^{2}(\\Omega)}\n$$\nSince this holds for all such pairs, we can take the supremum over all $x, y \\in \\Omega$ with $x \\neq y$:\n$$\n\\sup_{\\substack{x,y \\in \\Omega\\\\ x \\neq y}} \\frac{|f(x) - f(y)|}{|x-y|^{1/2}} \\leq \\|f'\\|_{L^{2}(\\Omega)}\n$$\nThis is equivalent to $[f]_{C^{0,1/2}(\\Omega)} \\leq 1 \\cdot \\|f'\\|_{L^{2}(\\Omega)}$. This inequality demonstrates that the constant $C_{\\ast}$ must be less than or equal to $1$, i.e., $C_{\\ast} \\leq 1$.\n\nStep 2: Showing the bound is sharp.\n\nTo prove that $C_{\\ast} = 1$, we must show that $C_{\\ast} \\ge 1$. We can do this by constructing a sequence of functions $f_k \\in H^1(\\Omega)$ for which the ratio $\\frac{[f_k]_{C^{0,1/2}(\\Omega)}}{\\|f_k'\\|_{L^2(\\Omega)}}$ approaches $1$, or by finding a single function for which the ratio is exactly $1$.\n\nLet's choose an arbitrary subinterval $(a,b) \\subset \\Omega = (0,1)$, with $0  a  b  1$. Consider a function $f \\in H^{1}(\\Omega)$ whose weak derivative $f'(t)$ is the characteristic function of this interval:\n$$\nf'(t) = \\chi_{(a,b)}(t) = \\begin{cases} 1  \\text{if } t \\in (a,b) \\\\ 0  \\text{otherwise} \\end{cases}\n$$\nThe function $f'$ is in $L^{2}(\\Omega)$. An antiderivative is $f(x) = \\int_0^x f'(t)\\,dt$, which is a continuous, piecewise linear function, and thus is in $H^1(\\Omega)$.\n\nLet's compute the $L^{2}$-norm of $f'$:\n$$\n\\|f'\\|_{L^{2}(\\Omega)}^2 = \\int_{0}^{1} |f'(t)|^2 \\, dt = \\int_{a}^{b} 1^2 \\, dt = b-a\n$$\nTherefore, $\\|f'\\|_{L^{2}(\\Omega)} = \\sqrt{b-a}$.\n\nNow, let's compute the Hölder seminorm $[f]_{C^{0,1/2}(\\Omega)}$. For any $x, y \\in \\Omega$ with $xy$:\n$$\n\\frac{|f(x)-f(y)|}{|x-y|^{1/2}} = \\frac{|\\int_y^x f'(t)\\,dt|}{|x-y|^{1/2}} = \\frac{\\int_y^x \\chi_{(a,b)}(t)\\,dt}{\\sqrt{x-y}} = \\frac{\\text{length}((y,x) \\cap (a,b))}{\\sqrt{x-y}}\n$$\nFrom Step 1, we know this quantity is bounded by $(\\int_y^x |f'(t)|^2 dt)^{1/2} = \\sqrt{\\text{length}((y,x) \\cap (a,b))}$. Let $L_{int} = \\text{length}((y,x))$ and $L_{cap} = \\text{length}((y,x) \\cap (a,b))$. The quantity is $L_{cap}/\\sqrt{L_{int}}$.\n\nLet's evaluate this for the specific choice of $x=b$ and $y=a$. We have:\n$$\n\\frac{|f(b)-f(a)|}{|b-a|^{1/2}} = \\frac{\\int_a^b 1 \\, dt}{\\sqrt{b-a}} = \\frac{b-a}{\\sqrt{b-a}} = \\sqrt{b-a}\n$$\nTo find the seminorm, we need the supremum over all pairs. Let's analyze the function $g(x,y) = \\frac{\\text{length}((y,x) \\cap (a,b))}{\\sqrt{x-y}}$.\nIf we choose the interval $(y,x)$ to be exactly $(a,b)$, we've shown the value is $\\sqrt{b-a}$.\nIf we choose an interval $(y,x)$ that is a subset of $(a,b)$, then $\\text{length}((y,x) \\cap (a,b)) = x-y$. The value is $\\frac{x-y}{\\sqrt{x-y}} = \\sqrt{x-y}$, which is maximized when $x-y$ is as large as possible, i.e., $x-y \\to b-a$.\nIf we choose an interval $(y,x)$ that contains $(a,b)$, then $\\text{length}((y,x) \\cap (a,b)) = b-a$. The value is $\\frac{b-a}{\\sqrt{x-y}}$. This is maximized when $x-y$ is minimized, i.e., when $(y,x)$ is just $(a,b)$, making the value $\\frac{b-a}{\\sqrt{b-a}} = \\sqrt{b-a}$.\nA more formal argument confirms that the supremum is indeed $\\sqrt{b-a}$.\nSo, for this function $f$, we have $[f]_{C^{0,1/2}(\\Omega)} = \\sqrt{b-a}$.\n\nNow we can compute the ratio for this specific function:\n$$\n\\frac{[f]_{C^{0,1/2}(\\Omega)}}{\\|f'\\|_{L^{2}(\\Omega)}} = \\frac{\\sqrt{b-a}}{\\sqrt{b-a}} = 1\n$$\nSince we have found a non-trivial function $f \\in H^{1}(\\Omega)$ for which the ratio is exactly $1$, the supremum over all such functions must be at least $1$. Thus, $C_{\\ast} \\ge 1$.\n\nCombining our two findings, $C_{\\ast} \\leq 1$ and $C_{\\ast} \\ge 1$, we conclude that the sharp constant is exactly $1$.\n\nThe problem also asks for a brief comparison with the general $n$-dimensional Morrey-type estimate for $W^{1,p}(\\Omega)$, specialized to our case. For $W^{1,p}(\\Omega)$ with $pn$, the embedding is into $C^{0,\\alpha}(\\overline{\\Omega})$ with $\\alpha = 1 - n/p$. For our problem, the space is $H^1(\\Omega) = W^{1,2}(\\Omega)$ and the domain is one-dimensional, so $n=1$ and $p=2$. The condition $pn$ is satisfied as $2  1$. The predicted Hölder exponent is $\\alpha = 1 - 1/2 = 1/2$, which matches the problem statement. The direct derivation using the Fundamental Theorem of Calculus and the Cauchy-Schwarz inequality, as performed in Step 1, is the standard method for proving the one-dimensional case of Morrey's inequality. This method directly yields the constant $C=1$. Our finding in Step 2 that this constant is sharp demonstrates that, for this specific case ($n=1, p=2, \\Omega=(0,1)$), the simplest proof technique for the general theorem happens to yield the optimal constant.\n\nThe final answer required is the value of $C_\\ast$.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "In the analysis of Discontinuous Galerkin and spectral methods, we often work with finite-dimensional spaces of polynomials. This exercise explores the concept of an inverse inequality, a discrete analogue of Sobolev embeddings that relates different norms for functions within these spaces. You will analytically investigate how the constant in this inequality depends critically on the polynomial degree $p$, revealing a scaling behavior that is fundamental to the analysis of high-order methods .",
            "id": "3414895",
            "problem": "Consider a single fixed hyperrectangular element $K = [0,h]^n$ in $n$ spatial dimensions used in a Discontinuous Galerkin (DG) method, and let $p$ denote the polynomial degree. Define the reference element $\\hat{K} = [-1,1]^n$ and the affine mapping $\\Phi : \\hat{K} \\to K$ given componentwise by $x_i = \\frac{h}{2}(\\xi_i + 1)$ for $i = 1,\\dots,n$. Let $P_p(\\xi)$ denote the degree-$p$ Legendre polynomial on $[-1,1]$ and define the $p$-refined tensor-product polynomial on the physical element by\n$$\nu_{p,h,n}(x) = \\prod_{i=1}^n P_p\\big(\\xi_i(x)\\big),\n$$\nwhere $\\xi(x) = \\Phi^{-1}(x)$ denotes the inverse affine mapping from $K$ to $\\hat{K}$. The Lebesgue space norms are defined by\n$$\n\\|v\\|_{L^\\infty(K)} = \\operatorname*{ess\\,sup}_{x\\in K} |v(x)|,\n\\quad\n\\|v\\|_{L^2(K)} = \\left( \\int_K |v(x)|^2 \\, dx \\right)^{1/2}.\n$$\nWithin the Discontinuous Galerkin framework, the deterioration of the $L^\\infty$ bound relative to the $L^2$ norm for $p$-refined polynomials is predicted to be consistent with the Nikolskii rate $(p/h)^{n/2}$.\n\nYour task is to construct this sequence $u_{p,h,n}$, compute a discrete approximation of the $L^\\infty$ norm by sampling $u_{p,h,n}$ at an equispaced grid of $m$ points per coordinate on $K$ (including endpoints), compute the exact $L^2$ norm using only fundamental orthogonality facts of Legendre polynomials, and then compute:\n- the ratio\n$$\nR(n,h,p) = \\frac{\\|u_{p,h,n}\\|_{L^\\infty(K)}}{\\|u_{p,h,n}\\|_{L^2(K)}},\n$$\n- and the Nikolskii-normalized ratio\n$$\n\\mathrm{NR}(n,h,p) = \\frac{R(n,h,p)}{(p/h)^{n/2}}.\n$$\nYou must implement a complete, runnable program that uses these definitions as the fundamental base. The program must compute both $R(n,h,p)$ and $\\mathrm{NR}(n,h,p)$ for each test case below and output all results in a single line as a comma-separated list enclosed in square brackets, in the order $[R_1,\\mathrm{NR}_1,R_2,\\mathrm{NR}_2,\\dots]$ (all values as decimal floats). No physical units are involved. Angles are not involved. Percentages must not be used.\n\nUse the following test suite that covers a happy path, boundary conditions, and edge cases across dimensions, degrees, and element sizes:\n- Test case $1$: $n=1$, $h=1.0$, $p=1$, with $m=33$ samples per dimension.\n- Test case $2$: $n=1$, $h=1.0$, $p=16$, with $m=65$ samples per dimension.\n- Test case $3$: $n=2$, $h=0.5$, $p=6$, with $m=33$ samples per dimension.\n- Test case $4$: $n=2$, $h=0.1$, $p=16$, with $m=33$ samples per dimension.\n- Test case $5$: $n=3$, $h=0.25$, $p=4$, with $m=33$ samples per dimension.\n- Test case $6$: $n=3$, $h=0.1$, $p=10$, with $m=33$ samples per dimension.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets and ordered as $[R_1,\\mathrm{NR}_1,R_2,\\mathrm{NR}_2,\\dots]$ for the six test cases specified above.",
            "solution": "The problem has been validated and is deemed a well-posed, scientifically grounded problem in numerical analysis. We proceed to derive the necessary quantities to compute the ratios $R(n,h,p)$ and $\\mathrm{NR}(n,h,p)$.\n\nThe core of the problem is the calculation of the $L^\\infty(K)$ and $L^2(K)$ norms of the function $u_{p,h,n}(x) = \\prod_{i=1}^n P_p(\\xi_i(x))$, where $\\xi_i(x) = \\frac{2x_i}{h} - 1$ is the inverse affine map from the physical element $K=[0,h]^n$ to the reference element $\\hat{K}=[-1,1]^n$.\n\n**1. Calculation of the $L^\\infty$ Norm**\n\nThe $L^\\infty$ norm is defined as $\\|v\\|_{L^\\infty(K)} = \\operatorname*{ess\\,sup}_{x\\in K} |v(x)|$. For our function $u_{p,h,n}(x)$, this is:\n$$\n\\|u_{p,h,n}\\|_{L^\\infty(K)} = \\operatorname*{ess\\,sup}_{x\\in K} \\left| \\prod_{i=1}^n P_p\\big(\\xi_i(x)\\big) \\right|\n$$\nSince the mapping $\\xi(x)$ is a bijection from $K$ to $\\hat{K}$, we can evaluate the supremum over the reference element $\\hat{K}$:\n$$\n\\|u_{p,h,n}\\|_{L^\\infty(K)} = \\operatorname*{ess\\,sup}_{\\xi\\in \\hat{K}} \\left| \\prod_{i=1}^n P_p(\\xi_i) \\right| = \\operatorname*{ess\\,sup}_{\\xi\\in [-1,1]^n} \\prod_{i=1}^n \\left| P_p(\\xi_i) \\right|\n$$\nThe supremum of a product of non-negative functions is the product of their suprema. Therefore, we can separate the expression by coordinate:\n$$\n\\|u_{p,h,n}\\|_{L^\\infty(K)} = \\prod_{i=1}^n \\left( \\operatorname*{ess\\,sup}_{\\xi_i\\in [-1,1]} |P_p(\\xi_i)| \\right)\n$$\nA fundamental property of Legendre polynomials $P_p(\\xi)$ is that for $\\xi \\in [-1,1]$, their absolute value is bounded by $1$, i.e., $|P_p(\\xi)| \\le 1$. The maximum absolute value of $1$ is achieved at the endpoints of the interval, as $|P_p(\\pm 1)| = 1$. Thus, for each dimension $i$, we have:\n$$\n\\operatorname*{ess\\,sup}_{\\xi_i\\in [-1,1]} |P_p(\\xi_i)| = 1\n$$\nSubstituting this back, we find the exact $L^\\infty$ norm:\n$$\n\\|u_{p,h,n}\\|_{L^\\infty(K)} = \\prod_{i=1}^n 1 = 1\n$$\nThe problem specifies approximating this norm by sampling on an equispaced grid of $m$ points per dimension on $K$, including endpoints. The endpoints $x_i = 0$ and $x_i=h$ of the physical element $K$ correspond to the endpoints $\\xi_i=-1$ and $\\xi_i=1$ of the reference interval $[-1,1]$. Since the grid includes the vertices of $K$, it will sample the function at points where its absolute value is maximal ($1$). Therefore, the discrete approximation yields the exact analytical value, $\\|u_{p,h,n}\\|_{L^\\infty(K)}=1$.\n\n**2. Calculation of the $L^2$ Norm**\n\nThe $L^2$ norm is defined as $\\|v\\|_{L^2(K)} = \\left( \\int_K |v(x)|^2 \\, dx \\right)^{1/2}$. We evaluate the squared norm first:\n$$\n\\|u_{p,h,n}\\|_{L^2(K)}^2 = \\int_K \\left| \\prod_{i=1}^n P_p\\big(\\xi_i(x)\\big) \\right|^2 \\, dx\n$$\nWe perform a change of variables from $x \\in K$ to $\\xi \\in \\hat{K}$ using the mapping $x_i = \\frac{h}{2}(\\xi_i+1)$. The Jacobian matrix of this transformation is diagonal, with entries $J_{ij} = \\frac{\\partial x_i}{\\partial \\xi_j} = \\delta_{ij} \\frac{h}{2}$. Its determinant is $\\det(J) = (\\frac{h}{2})^n$. The integral becomes:\n$$\n\\|u_{p,h,n}\\|_{L^2(K)}^2 = \\int_{\\hat{K}} \\left( \\prod_{i=1}^n P_p(\\xi_i) \\right)^2 \\det(J) \\, d\\xi = \\left(\\frac{h}{2}\\right)^n \\int_{[-1,1]^n} \\prod_{i=1}^n \\left(P_p(\\xi_i)\\right)^2 \\, d\\xi_1 \\dots d\\xi_n\n$$\nBy Fubini's theorem, this multidimensional integral can be separated into a product of one-dimensional integrals:\n$$\n\\|u_{p,h,n}\\|_{L^2(K)}^2 = \\left(\\frac{h}{2}\\right)^n \\prod_{i=1}^n \\int_{-1}^1 \\left(P_p(\\xi_i)\\right)^2 \\, d\\xi_i\n$$\nThe problem directs us to use the fundamental orthogonality facts of Legendre polynomials. The key property is:\n$$\n\\int_{-1}^1 P_j(\\xi) P_k(\\xi) \\, d\\xi = \\frac{2}{2j+1} \\delta_{jk}\n$$\nFor our case, where $j=k=p$, this simplifies to:\n$$\n\\int_{-1}^1 (P_p(\\xi))^2 \\, d\\xi = \\frac{2}{2p+1}\n$$\nSubstituting this result for each of the $n$ integrals:\n$$\n\\|u_{p,h,n}\\|_{L^2(K)}^2 = \\left(\\frac{h}{2}\\right)^n \\left( \\frac{2}{2p+1} \\right)^n = \\frac{h^n}{2^n} \\frac{2^n}{(2p+1)^n} = \\left(\\frac{h}{2p+1}\\right)^n\n$$\nTaking the square root gives the exact $L^2$ norm:\n$$\n\\|u_{p,h,n}\\|_{L^2(K)} = \\left( \\left(\\frac{h}{2p+1}\\right)^n \\right)^{1/2} = \\left(\\frac{h}{2p+1}\\right)^{n/2}\n$$\n\n**3. Computation of Ratios**\n\nWith the exact analytical expressions for both norms, we can now compute the required ratios.\nThe ratio $R(n,h,p)$ is:\n$$\nR(n,h,p) = \\frac{\\|u_{p,h,n}\\|_{L^\\infty(K)}}{\\|u_{p,h,n}\\|_{L^2(K)}} = \\frac{1}{\\left(\\frac{h}{2p+1}\\right)^{n/2}} = \\left(\\frac{2p+1}{h}\\right)^{n/2}\n$$\nThe Nikolskii-normalized ratio $\\mathrm{NR}(n,h,p)$ is:\n$$\n\\mathrm{NR}(n,h,p) = \\frac{R(n,h,p)}{(p/h)^{n/2}} = \\frac{\\left(\\frac{2p+1}{h}\\right)^{n/2}}{\\left(\\frac{p}{h}\\right)^{n/2}} = \\left( \\frac{(2p+1)/h}{p/h} \\right)^{n/2} = \\left(\\frac{2p+1}{p}\\right)^{n/2} = \\left(2 + \\frac{1}{p}\\right)^{n/2}\n$$\nThese final analytical formulas are used to compute the results for each test case. As $p \\to \\infty$, the term $(2 + 1/p)^{n/2}$ approaches $2^{n/2}$, showing that the Nikolskii scaling captures the dominant behavior. The parameter $m$ is irrelevant for the final calculation because the exact norms are determined analytically.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the norm ratio R and the Nikolskii-normalized ratio NR\n    for a series of test cases in a Discontinuous Galerkin context.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (n, h, p, m), where n is dimension, h is element size,\n    # p is polynomial degree, and m is samples per dimension.\n    test_cases = [\n        (1, 1.0, 1, 33),\n        (1, 1.0, 16, 65),\n        (2, 0.5, 6, 33),\n        (2, 0.1, 16, 33),\n        (3, 0.25, 4, 33),\n        (3, 0.1, 10, 33),\n    ]\n\n    results = []\n    for n, h, p, m in test_cases:\n        # Based on the analytical derivation:\n        # The L-infinity norm is exactly 1.\n        # The L2 norm is ((h / (2*p + 1))**n)**0.5 = (h / (2*p + 1))**(n/2).\n\n        # R = L_inf / L_2 = 1 / (h / (2*p + 1))**(n/2)\n        # R = ((2*p + 1) / h)**(n / 2.0)\n        ratio_R = ((2 * p + 1) / h)**(n / 2.0)\n\n        # NR = R / (p/h)**(n/2)\n        # NR = (((2*p + 1)/h) / (p/h))**(n/2)\n        # NR = ((2*p + 1)/p)**(n/2) = (2 + 1/p)**(n/2)\n        # The parameter m is not needed for the analytical computation.\n        nikolskii_ratio_NR = (2.0 + 1.0 / p)**(n / 2.0)\n\n        results.append(ratio_R)\n        results.append(nikolskii_ratio_NR)\n\n    # Final print statement in the exact required format.\n    # The format is a single line, comma-separated list enclosed in brackets.\n    # Example: [R_1,NR_1,R_2,NR_2,...]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The constants in Sobolev-type inequalities are not always universal; they can depend on the geometry of the domain. This practice focuses on trace inequalities, which are essential for controlling jump terms in DG methods, and demonstrates their failure on meshes with high aspect ratios. By analyzing a sequence of anisotropic elements, you will see why standard isotropic estimates are insufficient and why a more nuanced, geometry-aware analysis is essential for robust numerical schemes .",
            "id": "3414934",
            "problem": "Consider a family of discontinuous Galerkin meshes comprised of axis-aligned rectangles. Let a single element be the rectangle $K = [0,h_x] \\times [0,h_y]$, where $h_x  0$ and $h_y  0$ are the side lengths in the $x$ and $y$ directions. Let the trace operator map a function $v \\in H^1(K)$ (Sobolev space of square-integrable functions with square-integrable weak gradient) to its boundary values on $\\partial K$, and consider the standard isotropic trace control that would be used on shape-regular families: for an element size parameter $h := \\max\\{h_x, h_y\\}$, a canonical isotropic bound aims to control the boundary norm by a bulk norm via\n$$\n\\| v \\|_{L^2(\\partial K)}^2 \\leq C \\left( h^{-1} \\| v \\|_{L^2(K)}^2 + h \\| \\nabla v \\|_{L^2(K)}^2 \\right),\n$$\nwith a constant $C$ that is uniform over the mesh sequence. In discontinuous Galerkin interior penalty formulations, the jump term across an interior face $F$ of length $\\ell_F$ for a piecewise function $u$ is penalized by a term of the form\n$$\n\\int_F \\frac{\\sigma}{h_F} [u]^2 \\, ds,\n$$\nwhere $[u]$ is the trace jump, $\\sigma  0$ is a fixed penalty parameter, and $h_F$ is an isotropic face size chosen consistently with $h$ on the adjacent elements, often taken as $h_F = h$. These isotropic controls are known to be stable when the mesh is shape-regular (uniformly bounded aspect ratio), but may fail as anisotropy grows.\n\nYour task is to construct and analyze a mesh sequence with growing anisotropy and demonstrate numerically that isotropic trace-type controls cannot uniformly bound the boundary or jump terms. Proceed from the following fundamental base: the definition of $L^2$ norms on domains and boundaries, the definition of weak gradient norms, and the structure of discontinuous Galerkin interior penalty jump terms. Do not use pre-packaged anisotropic inequalities; derive all expressions from first principles using the exact integrals of simple representative functions.\n\nDefine, for any rectangle $K = [0,h_x] \\times [0,h_y]$ and $h = \\max\\{h_x,h_y\\}$, the ratio\n$$\nR(v; K) := \\frac{\\| v \\|_{L^2(\\partial K)}^2}{h^{-1} \\| v \\|_{L^2(K)}^2 + h \\| \\nabla v \\|_{L^2(K)}^2},\n$$\nfor the three test functions\n- $v(x,y) = 1$,\n- $v(x,y) = x$,\n- $v(x,y) = y$.\nThese functions probe different directional behaviors relative to anisotropy.\n\nAlso define a two-element discontinuous Galerkin configuration comprised of two adjacent rectangles $K^-$ and $K^+$ that share a single vertical interior face $F$ of length $h_y$, with both rectangles equal to $[0,h_x] \\times [0,h_y]$ and $[h_x,2h_x] \\times [0,h_y]$. Consider the piecewise constant function $u$ such that $u|_{K^-} = -1$ and $u|_{K^+} = 1$, the penalty parameter $\\sigma = 1$, and an isotropic face size $h_F = h := \\max\\{h_x,h_y\\}$. Define the isotropic jump-to-bulk control ratio\n$$\nQ(h_x, h_y) := \\frac{\\int_F \\frac{\\sigma}{h_F} [u]^2 \\, ds}{h^{-1} \\left( \\| u \\|_{L^2(K^-)}^2 + \\| u \\|_{L^2(K^+)}^2 \\right) + h \\left( \\| \\nabla u \\|_{L^2(K^-)}^2 + \\| \\nabla u \\|_{L^2(K^+)}^2 \\right)}.\n$$\nThis ratio quantifies the extent to which the isotropic bulk control fails to uniformly bound the jump term as anisotropy grows.\n\nUsing only the definitions of $L^2$ and boundary integrals and the fact that the weak gradients of the given test functions are classical gradients, write a program that computes the ratios $R(v;K)$ and $Q(h_x,h_y)$ exactly for specified element sizes. Your program must evaluate the following test suite that exercises different behaviors:\n\n- Anisotropic sequence with growing aspect ratio, defined by $h_x(n) = 2^{-n}$ and $h_y(n) = 2^{-2n}$, for $n \\in \\{1,3,5\\}$. For each $n$, compute the maximum\n$$\nM(n) := \\max\\left\\{ R(1;K_n), R(x;K_n), R(y;K_n) \\right\\},\n$$\nwhere $K_n = [0,h_x(n)] \\times [0,h_y(n)]$, and also compute\n$$\nQ(n) := Q\\left(h_x(n), h_y(n)\\right).\n$$\n\n- A shape-regular (isotropic) comparison case with $h_x = h_y = 2^{-3}$. Compute\n$$\nM_{\\mathrm{iso}} := \\max\\left\\{ R(1;K_{\\mathrm{iso}}), R(x;K_{\\mathrm{iso}}), R(y;K_{\\mathrm{iso}}) \\right\\},\n$$\nwhere $K_{\\mathrm{iso}} = [0,2^{-3}] \\times [0,2^{-3}]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets: specifically,\n$$\n\\left[ M(1), M(3), M(5), M_{\\mathrm{iso}}, Q(1), Q(3), Q(5) \\right].\n$$\nAll outputs must be real numbers (floats). No physical units are involved. Angles are not present. Express all quantities as dimensionless floats. Ensure your program is self-contained, requires no input, and uses only the libraries specified in the execution environment.",
            "solution": "The problem is valid. It is a well-posed and scientifically grounded exercise in the analysis of numerical methods, specifically demonstrating the failure of isotropic trace inequalities on anisotropic meshes from first principles.\n\nThe task is to compute two ratios, $R(v;K)$ and $Q(h_x, h_y)$, for a series of rectangular elements with growing anisotropy, and for a shape-regular comparison case. We will derive the analytical expressions for these ratios by computing the required integrals from their definitions.\n\nLet the rectangular element be $K = [0, h_x] \\times [0, h_y]$, with $h_x  0$ and $h_y  0$. The isotropic size parameter is $h := \\max\\{h_x, h_y\\}$. The ratio $R(v;K)$ is defined as:\n$$\nR(v; K) := \\frac{\\| v \\|_{L^2(\\partial K)}^2}{h^{-1} \\| v \\|_{L^2(K)}^2 + h \\| \\nabla v \\|_{L^2(K)}^2}\n$$\nThe norms are defined as:\n- $\\| v \\|_{L^2(K)}^2 = \\int_K v^2 \\, dA = \\int_0^{h_y} \\int_0^{h_x} v(x,y)^2 \\, dx \\, dy$\n- $\\| \\nabla v \\|_{L^2(K)}^2 = \\int_K |\\nabla v|^2 \\, dA = \\int_0^{h_y} \\int_0^{h_x} \\left( (\\partial_x v)^2 + (\\partial_y v)^2 \\right) \\, dx \\, dy$\n- $\\| v \\|_{L^2(\\partial K)}^2 = \\int_{\\partial K} v^2 \\, ds$, which is the sum of integrals over the four sides of the rectangle.\n\nWe evaluate these terms for the three specified test functions.\n\n**Case 1: $v(x,y) = 1$**\n\nThe gradient is $\\nabla v = (0, 0)$.\nThe squared $L^2(K)$ norm is:\n$$\n\\| v \\|_{L^2(K)}^2 = \\int_0^{h_y} \\int_0^{h_x} 1^2 \\, dx \\, dy = h_x h_y\n$$\nThe squared $L^2(K)$ norm of the gradient is:\n$$\n\\| \\nabla v \\|_{L^2(K)}^2 = \\int_0^{h_y} \\int_0^{h_x} (0^2 + 0^2) \\, dx \\, dy = 0\n$$\nThe squared $L^2(\\partial K)$ norm is the integral of $1^2$ over the boundary, which is the perimeter of the rectangle:\n$$\n\\| v \\|_{L^2(\\partial K)}^2 = \\int_{\\partial K} 1^2 \\, ds = 2(h_x + h_y)\n$$\nSubstituting these into the definition of $R$:\n$$\nR(1; K) = \\frac{2(h_x + h_y)}{h^{-1} (h_x h_y) + h (0)} = \\frac{2h(h_x + h_y)}{h_x h_y} = 2h \\left( \\frac{1}{h_y} + \\frac{1}{h_x} \\right)\n$$\n\n**Case 2: $v(x,y) = x$**\n\nThe gradient is $\\nabla v = (1, 0)$.\nThe squared $L^2(K)$ norm is:\n$$\n\\| v \\|_{L^2(K)}^2 = \\int_0^{h_y} \\int_0^{h_x} x^2 \\, dx \\, dy = h_y \\left[ \\frac{x^3}{3} \\right]_0^{h_x} = \\frac{h_x^3 h_y}{3}\n$$\nThe squared $L^2(K)$ norm of the gradient is:\n$$\n\\| \\nabla v \\|_{L^2(K)}^2 = \\int_0^{h_y} \\int_0^{h_x} (1^2 + 0^2) \\, dx \\, dy = h_x h_y\n$$\nThe squared $L^2(\\partial K)$ norm is the sum of integrals over the four sides:\n- Bottom edge ($y=0$, $x \\in [0, h_x]$): $\\int_0^{h_x} x^2 \\, dx = \\frac{h_x^3}{3}$\n- Top edge ($y=h_y$, $x \\in [0, h_x]$): $\\int_0^{h_x} x^2 \\, dx = \\frac{h_x^3}{3}$\n- Left edge ($x=0$, $y \\in [0, h_y]$): $\\int_0^{h_y} 0^2 \\, dy = 0$\n- Right edge ($x=h_x$, $y \\in [0, h_y]$): $\\int_0^{h_y} h_x^2 \\, dy = h_x^2 h_y$\nThe sum is $\\| v \\|_{L^2(\\partial K)}^2 = \\frac{2h_x^3}{3} + h_x^2 h_y$.\nSubstituting these into the definition of $R$:\n$$\nR(x; K) = \\frac{\\frac{2h_x^3}{3} + h_x^2 h_y}{h^{-1} \\left(\\frac{h_x^3 h_y}{3}\\right) + h (h_x h_y)} = \\frac{h_x^2(\\frac{2h_x}{3} + h_y)}{h_x h_y (\\frac{h^{-1} h_x^2}{3} + h)} = \\frac{h_x (\\frac{2h_x}{3} + h_y)}{h_y (\\frac{h^{-1} h_x^2}{3} + h)}\n$$\n\n**Case 3: $v(x,y) = y$**\n\nBy symmetry with the case $v(x,y)=x$, we can swap $h_x$ and $h_y$. The gradient is $\\nabla v = (0, 1)$.\n- $\\| v \\|_{L^2(K)}^2 = \\frac{h_x h_y^3}{3}$\n- $\\| \\nabla v \\|_{L^2(K)}^2 = h_x h_y$\n- $\\| v \\|_{L^2(\\partial K)}^2 = h_x h_y^2 + \\frac{2h_y^3}{3}$\nSubstituting these into the definition of $R$:\n$$\nR(y; K) = \\frac{h_x h_y^2 + \\frac{2h_y^3}{3}}{h^{-1} \\left(\\frac{h_x h_y^3}{3}\\right) + h (h_x h_y)} = \\frac{h_y^2(h_x + \\frac{2h_y}{3})}{h_x h_y (\\frac{h^{-1} h_y^2}{3} + h)} = \\frac{h_y (h_x + \\frac{2h_y}{3})}{h_x (\\frac{h^{-1} h_y^2}{3} + h)}\n$$\n\n**Derivation of the ratio $Q(h_x, h_y)$**\n\nThe configuration consists of two elements, $K^- = [0,h_x] \\times [0,h_y]$ and $K^+ = [h_x,2h_x] \\times [0,h_y]$, sharing a vertical interior face $F = \\{h_x\\} \\times [0,h_y]$ of length $\\ell_F=h_y$. The piecewise function is $u|_{K^-} = -1$ and $u|_{K^+} = 1$. The jump across the face is $[u] = u|_{K^+} - u|_{K^-} = 1 - (-1) = 2$. The penalty parameter is $\\sigma=1$ and the isotropic face size is $h_F = h = \\max\\{h_x,h_y\\}$.\nThe ratio $Q$ is defined as:\n$$\nQ(h_x, h_y) := \\frac{\\int_F \\frac{\\sigma}{h_F} [u]^2 \\, ds}{h^{-1} \\left( \\| u \\|_{L^2(K^-)}^2 + \\| u \\|_{L^2(K^+)}^2 \\right) + h \\left( \\| \\nabla u \\|_{L^2(K^-)}^2 + \\| \\nabla u \\|_{L^2(K^+)}^2 \\right)}\n$$\nThe numerator is:\n$$\n\\int_F \\frac{\\sigma}{h_F} [u]^2 \\, ds = \\frac{1}{h} \\cdot 2^2 \\int_0^{h_y} \\, ds = \\frac{4}{h} h_y\n$$\nFor the denominator, we compute the norms. Since $u$ is piecewise constant, its weak gradient is zero within each element, so $\\| \\nabla u \\|_{L^2(K^-)}^2 = 0$ and $\\| \\nabla u \\|_{L^2(K^+)}^2 = 0$.\nThe $L^2$ norms are:\n$$\n\\| u \\|_{L^2(K^-)}^2 = \\int_{K^-} (-1)^2 \\, dA = \\text{Area}(K^-) = h_x h_y\n$$\n$$\n\\| u \\|_{L^2(K^+)}^2 = \\int_{K^+} (1)^2 \\, dA = \\text{Area}(K^+) = h_x h_y\n$$\nThe denominator is therefore:\n$$\nh^{-1} (h_x h_y + h_x h_y) + h(0+0) = \\frac{2h_x h_y}{h}\n$$\nThe ratio $Q$ is:\n$$\nQ(h_x, h_y) = \\frac{\\frac{4h_y}{h}}{\\frac{2h_x h_y}{h}} = \\frac{4h_y}{2h_x h_y} = \\frac{2}{h_x}\n$$\nThis result demonstrates that the ratio $Q$ is independent of $h_y$ and blows up as $h_x \\to 0$.\n\n**Numerical Evaluation**\n\nWe now apply these formulas to the specified test cases.\n\n_Anisotropic sequence_: $h_x(n) = 2^{-n}$ and $h_y(n) = 2^{-2n}$ for $n \\in \\{1, 3, 5\\}$.\nFor $n \\ge 1$, we have $2n  n$, so $2^{-2n}  2^{-n}$, which means $h_y  h_x$. Thus, $h = \\max\\{h_x, h_y\\} = h_x$. The aspect ratio is $h_x/h_y = 2^n$, which grows with $n$.\nWe use $h=h_x$ in the formulas for $R$:\n- $R(1; K_n) = \\frac{2h_x(h_x + h_y)}{h_x h_y} = \\frac{2(h_x+h_y)}{h_y} = 2(\\frac{h_x}{h_y}+1) = 2(2^n+1)$.\n- $R(x; K_n) = \\frac{h_x (\\frac{2h_x}{3} + h_y)}{h_y (\\frac{h_x^{-1} h_x^2}{3} + h_x)} = \\frac{h_x (\\frac{2h_x}{3} + h_y)}{h_y (\\frac{h_x}{3} + h_x)} = \\frac{h_x(\\frac{2h_x}{3} + h_y)}{h_y(\\frac{4h_x}{3})} = \\frac{2h_x+3h_y}{4h_y} = \\frac{1}{2}\\frac{h_x}{h_y} + \\frac{3}{4} = \\frac{1}{2}2^n + \\frac{3}{4}$.\n- $R(y; K_n) = \\frac{h_y (h_x + \\frac{2h_y}{3})}{h_x (\\frac{h_x^{-1} h_y^2}{3} + h_x)} = \\frac{h_y(h_x + \\frac{2}{3}h_y)}{h_x^2 + h_y^2/3}$.\n$R(1; K_n) = 2^{n+1}+2$ and $R(x; K_n) = 2^{n-1}+0.75$. For $n \\ge 1$, $R(1; K_n)$ is larger. $R(y; K_n)$ approaches $0$ as $n \\to \\infty$. Thus, $M(n) = \\max\\{R(1;K_n), R(x;K_n), R(y;K_n)\\} = 2(2^n+1)$.\n- For $n=1$: $M(1) = 2(2^1+1) = 6$.\n- For $n=3$: $M(3) = 2(2^3+1) = 18$.\n- For $n=5$: $M(5) = 2(2^5+1) = 66$.\n\nFor $Q(n)$, we have $Q(n) = 2/h_x(n) = 2/2^{-n} = 2^{n+1}$.\n- For $n=1$: $Q(1) = 2^{1+1} = 4$.\n- For $n=3$: $Q(3) = 2^{3+1} = 16$.\n- For $n=5$: $Q(5) = 2^{5+1} = 64$.\n\n_Isotropic case_: $h_x = h_y = 2^{-3}$. Here $h=h_x=h_y$. Let's call this size $H$.\n- $R(1; K_{\\mathrm{iso}}) = \\frac{2H(H+H)}{H \\cdot H} = \\frac{4H^2}{H^2} = 4$.\n- $R(x; K_{\\mathrm{iso}}) = \\frac{H(\\frac{2H}{3} + H)}{H(\\frac{H^{-1}H^2}{3} + H)} = \\frac{H(5H/3)}{H(4H/3)} = \\frac{5}{4} = 1.25$.\n- $R(y; K_{\\mathrm{iso}}) = R(x; K_{\\mathrm{iso}}) = 1.25$ by symmetry.\nTherefore, $M_{\\mathrm{iso}} = \\max\\{4, 1.25, 1.25\\} = 4$.\n\nThe final list of results is $[M(1), M(3), M(5), M_{\\mathrm{iso}}, Q(1), Q(3), Q(5)]$.\n- $M(1) = 6.0$\n- $M(3) = 18.0$\n- $M(5) = 66.0$\n- $M_{\\mathrm{iso}} = 4.0$\n- $Q(1) = 4.0$\n- $Q(3) = 16.0$\n- $Q(5) = 64.0$\nThese values clearly demonstrate that the ratios $R$ and $Q$ are not uniformly bounded for the anisotropic mesh sequence, confirming the failure of the isotropic control.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_R(v_type, hx, hy):\n    \"\"\"\n    Computes the ratio R(v; K) for a given test function type and element dimensions.\n\n    R(v; K) = ||v||^2_L2(dK) / (h^-1 ||v||^2_L2(K) + h ||grad v||^2_L2(K))\n    \"\"\"\n    if not (hx  0 and hy  0):\n        # This case should not be reached with the problem's inputs\n        raise ValueError(\"Element dimensions hx and hy must be positive.\")\n        \n    h = max(hx, hy)\n\n    if v_type == '1':\n        # v(x,y) = 1\n        # Numerator: ||v||^2_L2(dK) = Perimeter = 2*(hx+hy)\n        num = 2.0 * (hx + hy)\n        # Denominator:\n        # ||v||^2_L2(K) = hx*hy\n        # ||grad v||^2_L2(K) = 0\n        den = (1.0 / h) * (hx * hy)\n        if den == 0.0: return np.inf\n        return num / den\n\n    elif v_type == 'x':\n        # v(x,y) = x\n        # Numerator: ||v||^2_L2(dK) = integral of x^2 over boundary\n        num = (2.0/3.0) * hx**3 + hx**2 * hy\n        # Denominator:\n        # ||v||^2_L2(K) = integral of x^2 over K = hx^3 * hy / 3\n        v_norm_sq = (hx**3 * hy) / 3.0\n        # ||grad v||^2_L2(K) = integral of 1^2 over K = hx*hy\n        grad_v_norm_sq = hx * hy\n        den = (1.0 / h) * v_norm_sq + h * grad_v_norm_sq\n        if den == 0.0: return np.inf\n        return num / den\n\n    elif v_type == 'y':\n        # v(x,y) = y\n        # Numerator: ||v||^2_L2(dK) = integral of y^2 over boundary\n        num = hx * hy**2 + (2.0/3.0) * hy**3\n        # Denominator:\n        # ||v||^2_L2(K) = integral of y^2 over K = hx * hy^3 / 3\n        v_norm_sq = (hx * hy**3) / 3.0\n        # ||grad v||^2_L2(K) = integral of 1^2 over K = hx*hy\n        grad_v_norm_sq = hx * hy\n        den = (1.0 / h) * v_norm_sq + h * grad_v_norm_sq\n        if den == 0.0: return np.inf\n        return num / den\n\n    else:\n        raise ValueError(\"Invalid v_type specified. Must be '1', 'x', or 'y'.\")\n\ndef calculate_Q(hx, hy):\n    \"\"\"\n    Computes the ratio Q(hx, hy) for given element dimensions.\n    Based on the analytical derivation, Q(hx, hy) = 2/hx.\n    \"\"\"\n    if hx == 0.0: return np.inf\n    return 2.0 / hx\n\ndef solve():\n    \"\"\"\n    Main function to compute and print the results for the problem.\n    \"\"\"\n    \n    # Define test cases from the problem statement.\n    test_n = [1, 3, 5]\n    \n    m_anisotropic_results = []\n    q_anisotropic_results = []\n\n    # Anisotropic sequence calculation\n    for n in test_n:\n        hx = 2.0**(-n)\n        hy = 2.0**(-2*n)\n\n        # Calculate M(n)\n        r_1 = calculate_R('1', hx, hy)\n        r_x = calculate_R('x', hx, hy)\n        r_y = calculate_R('y', hx, hy)\n        m_n = max(r_1, r_x, r_y)\n        m_anisotropic_results.append(m_n)\n\n        # Calculate Q(n)\n        q_n = calculate_Q(hx, hy)\n        q_anisotropic_results.append(q_n)\n\n    # Isotropic comparison case calculation\n    hx_iso = 2.0**(-3)\n    hy_iso = 2.0**(-3)\n    \n    r_1_iso = calculate_R('1', hx_iso, hy_iso)\n    r_x_iso = calculate_R('x', hx_iso, hy_iso)\n    r_y_iso = calculate_R('y', hx_iso, hy_iso)\n    m_iso = max(r_1_iso, r_x_iso, r_y_iso)\n\n    # Assemble the final list in the required order\n    # [ M(1), M(3), M(5), M_iso, Q(1), Q(3), Q(5) ]\n    final_results = [\n        m_anisotropic_results[0],\n        m_anisotropic_results[1],\n        m_anisotropic_results[2],\n        m_iso,\n        q_anisotropic_results[0],\n        q_anisotropic_results[1],\n        q_anisotropic_results[2],\n    ]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        }
    ]
}