{
    "hands_on_practices": [
        {
            "introduction": "用于稀疏近似的贪婪算法建立在一个简单而强大的思想之上：在每一步选择单个最佳的字典元素。第一个练习将带您回到这个核心原则。通过从一个正交字典中计算信号的最佳1项近似，您将对原子选择和系数计算如何构成匹配追踪等方法的基础有一个基于第一性原理的理解 。",
            "id": "3449256",
            "problem": "设 $A=[a_1,a_2,a_3]\\in\\mathbb{R}^{3\\times 3}$ 是一个具有标准正交列的字典，其中\n$$\na_1=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\\\ \\frac{1}{\\sqrt{2}}\\\\ 0\\end{pmatrix},\\quad\na_2=\\begin{pmatrix}\\frac{1}{\\sqrt{6}}\\\\ -\\frac{1}{\\sqrt{6}}\\\\ \\frac{2}{\\sqrt{6}}\\end{pmatrix},\\quad\na_3=\\begin{pmatrix}\\frac{1}{\\sqrt{3}}\\\\ -\\frac{1}{\\sqrt{3}}\\\\ -\\frac{1}{\\sqrt{3}}\\end{pmatrix}.\n$$\n考虑一个合成模型，其中信号 $y\\in\\mathbb{R}^{3}$ 由一个线性组合 $Ax$ 近似，其系数向量 $x\\in\\mathbb{R}^{3}$ 是 $1$-稀疏的（即，最多有 $1$ 个非零项）。设\n$$\ny=\\begin{pmatrix}3\\\\ -1\\\\ 4\\end{pmatrix}.\n$$\n从 $1$-稀疏合成近似、标准正交性和欧几里得范数的定义出发，确定在 $A$ 的单个列和标量系数的所有选择中，能使残差范数 $\\|y-\\hat{y}\\|_2$ 最小化的 $1$-项近似 $\\hat{y}$，然后计算相关的残差范数 $\\|y-\\hat{y}\\|_2$。仅基于这些定义，给出清晰的推导过程，以证明所选原子和系数的合理性。\n\n将您的最终答案表示为四元组 $(\\hat{y}_1,\\hat{y}_2,\\hat{y}_3,\\|y-\\hat{y}\\|_2)$，并使用精确值。不要四舍五入。",
            "solution": "该问题要求从一个字典 $A$ 中为给定信号 $y$ 找到最优的 $1$-项合成近似 $\\hat{y}$。字典 $A = [a_1, a_2, a_3]$ 由 $\\mathbb{R}^3$ 中的三个标准正交列组成，信号为 $y \\in \\mathbb{R}^3$。\n\n一个 $1$-项近似是形如 $\\hat{y} = x_j a_j$ 的向量，其中 $a_j$ 是从字典中选择的某个原子（其中 $j \\in \\{1, 2, 3\\}$），$x_j \\in \\mathbb{R}$ 是一个标量系数。目标是找到特定的原子 $a_j$ 和系数 $x_j$，以最小化残差的欧几里得范数 $\\|y - \\hat{y}\\|_2$。\n\n该优化问题可以表述为：\n$$\n\\min_{j \\in \\{1, 2, 3\\}, x_j \\in \\mathbb{R}} \\|y - x_j a_j\\|_2\n$$\n这个问题可以分两步解决。首先，对于每个固定的原子 $a_j$，我们找到最优的系数 $x_j$。其次，我们比较每个 $j$ 选择所产生的最小残差，以找到全局最优的近似。\n\n我们固定一个索引 $j \\in \\{1, 2, 3\\}$。我们试图找到使函数 $f(x_j) = \\|y - x_j a_j\\|_2$ 最小化的标量 $x_j$。最小化范数等价于最小化其平方 $f(x_j)^2 = \\|y - x_j a_j\\|_2^2$。根据欧几里得范数的定义，即向量与其自身的点积，我们有：\n$$\n\\|y - x_j a_j\\|_2^2 = (y - x_j a_j)^T (y - x_j a_j)\n$$\n展开乘积可得：\n$$\n\\|y - x_j a_j\\|_2^2 = y^T y - x_j y^T a_j - x_j a_j^T y + x_j^2 a_j^T a_j\n$$\n因为 $y^T a_j$ 是一个标量，所以它的转置 $a_j^T y$ 与它相等。此外，问题中说明 $A$ 的列是标准正交的，这意味着它们是单位向量，所以 $a_j^T a_j = \\|a_j\\|_2^2 = 1$。该表达式简化为关于 $x_j$ 的二次函数：\n$$\n\\|y - x_j a_j\\|_2^2 = \\|y\\|_2^2 - 2x_j (y^T a_j) + x_j^2\n$$\n为了找到使这个二次函数最小化的 $x_j$ 的值，我们可以对其关于 $x_j$ 求导并令其为零：\n$$\n\\frac{d}{dx_j} \\left( \\|y\\|_2^2 - 2x_j (y^T a_j) + x_j^2 \\right) = -2(y^T a_j) + 2x_j = 0\n$$\n解出 $x_j$ 即可得到给定原子 $a_j$ 的最优系数：\n$$\nx_j = y^T a_j\n$$\n这个结果表明，用于近似 $y$ 的 $a_j$ 的最佳标量倍数，是通过将 $y$ 正交投影到由 $a_j$ 张成的直线上得到的。\n\n现在我们必须确定哪个原子 $a_j$ 能提供最好的近似。我们将最优系数 $x_j = y^T a_j$ 代回残差范数平方的表达式中：\n$$\n\\min_{x_j} \\|y - x_j a_j\\|_2^2 = \\|y\\|_2^2 - 2(y^T a_j)(y^T a_j) + (y^T a_j)^2 = \\|y\\|_2^2 - (y^T a_j)^2\n$$\n为了在所有可能的 $j$ 选择中找到全局最小残差，我们必须选择使 $\\|y\\|_2^2 - (y^T a_j)^2$ 最小化的索引 $j$。由于 $\\|y\\|_2^2$ 是一个常数项，这等价于最大化 $(y^T a_j)^2$ 项，或者等价地，最大化其绝对值 $|y^T a_j|$。\n\n给定信号 $y = \\begin{pmatrix} 3 \\\\ -1 \\\\ 4 \\end{pmatrix}$ 和原子：\n$$\na_1=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\\\ \\frac{1}{\\sqrt{2}}\\\\ 0\\end{pmatrix},\\quad\na_2=\\begin{pmatrix}\\frac{1}{\\sqrt{6}}\\\\ -\\frac{1}{\\sqrt{6}}\\\\ \\frac{2}{\\sqrt{6}}\\end{pmatrix},\\quad\na_3=\\begin{pmatrix}\\frac{1}{\\sqrt{3}}\\\\ -\\frac{1}{\\sqrt{3}}\\\\ -\\frac{1}{\\sqrt{3}}\\end{pmatrix}\n$$\n我们现在计算 $j=1, 2, 3$ 时的内积 $y^T a_j$：\n$$\ny^T a_1 = (3)\\left(\\frac{1}{\\sqrt{2}}\\right) + (-1)\\left(\\frac{1}{\\sqrt{2}}\\right) + (4)(0) = \\frac{3}{\\sqrt{2}} - \\frac{1}{\\sqrt{2}} = \\frac{2}{\\sqrt{2}} = \\sqrt{2}\n$$\n$$\ny^T a_2 = (3)\\left(\\frac{1}{\\sqrt{6}}\\right) + (-1)\\left(-\\frac{1}{\\sqrt{6}}\\right) + (4)\\left(\\frac{2}{\\sqrt{6}}\\right) = \\frac{3}{\\sqrt{6}} + \\frac{1}{\\sqrt{6}} + \\frac{8}{\\sqrt{6}} = \\frac{12}{\\sqrt{6}} = \\frac{12\\sqrt{6}}{6} = 2\\sqrt{6}\n$$\n$$\ny^T a_3 = (3)\\left(\\frac{1}{\\sqrt{3}}\\right) + (-1)\\left(-\\frac{1}{\\sqrt{3}}\\right) + (4)\\left(-\\frac{1}{\\sqrt{3}}\\right) = \\frac{3}{\\sqrt{3}} + \\frac{1}{\\sqrt{3}} - \\frac{4}{\\sqrt{3}} = 0\n$$\n现在我们比较这些内积的绝对值：\n$$\n|y^T a_1| = \\sqrt{2} \\approx 1.414\n$$\n$$\n|y^T a_2| = 2\\sqrt{6} = \\sqrt{24} \\approx 4.899\n$$\n$$\n|y^T a_3| = 0\n$$\n最大的绝对值是 $|y^T a_2| = 2\\sqrt{6}$。因此，近似 $y$ 的最佳原子是 $a_2$。最优系数是 $x_2 = y^T a_2 = 2\\sqrt{6}$。\n\n因此，最佳的 $1$-项近似 $\\hat{y}$ 是：\n$$\n\\hat{y} = x_2 a_2 = (2\\sqrt{6}) \\begin{pmatrix}\\frac{1}{\\sqrt{6}}\\\\ -\\frac{1}{\\sqrt{6}}\\\\ \\frac{2}{\\sqrt{6}}\\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -2 \\\\ 4 \\end{pmatrix}\n$$\n近似的分量是 $\\hat{y}_1=2$，$\\hat{y}_2=-2$ 和 $\\hat{y}_3=4$。\n\n最后，我们计算残差的范数 $\\|y - \\hat{y}\\|_2$。残差向量是：\n$$\nr = y - \\hat{y} = \\begin{pmatrix} 3 \\\\ -1 \\\\ 4 \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ -2 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\n残差的范数是：\n$$\n\\|y - \\hat{y}\\|_2 = \\|r\\|_2 = \\sqrt{1^2 + 1^2 + 0^2} = \\sqrt{2}\n$$\n或者，使用前面推导的公式：\n$$\n\\|y - \\hat{y}\\|_2 = \\sqrt{\\|y\\|_2^2 - (y^T a_2)^2}\n$$\n首先，$\\|y\\|_2^2 = 3^2 + (-1)^2 + 4^2 = 9 + 1 + 16 = 26$。\n然后，$(y^T a_2)^2 = (2\\sqrt{6})^2 = 4 \\times 6 = 24$。\n$$\n\\|y - \\hat{y}\\|_2 = \\sqrt{26 - 24} = \\sqrt{2}\n$$\n两种方法得到相同的结果。\n\n最终答案是四元组 $(\\hat{y}_1, \\hat{y}_2, \\hat{y}_3, \\|y-\\hat{y}\\|_2)$，即 $(2, -2, 4, \\sqrt{2})$。",
            "answer": "$$\n\\boxed{(2, -2, 4, \\sqrt{2})}\n$$"
        },
        {
            "introduction": "在单步选择的基础上，我们现在探讨如何将这一思想扩展到迭代算法中。本练习直接比较了两种基础的贪婪方法：匹配追踪（MP）和正交匹配追踪（OMP）。通过在同一个问题上追踪两种算法的两轮迭代，您将发现最小二乘“去偏”步骤的关键作用，正是这一步骤赋予了OMP性能优势，并构成了更高级技术的基础 。",
            "id": "3449235",
            "problem": "考虑一个实值线性模型，其数据向量为 $y \\in \\mathbb{R}^{2}$，字典矩阵为 $A \\in \\mathbb{R}^{2 \\times 3}$，其列（原子）是单位范数，具体如下\n$$\nA = \\begin{pmatrix}\n1  \\frac{1}{\\sqrt{2}}  0 \\\\\n0  \\frac{1}{\\sqrt{2}}  1\n\\end{pmatrix}, \\quad y = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}.\n$$\n设原子表示为 $a_{1}, a_{2}, a_{3} \\in \\mathbb{R}^{2}$，即 $A = [a_{1} \\ a_{2} \\ a_{3}]$。将要应用的贪婪方法是匹配追踪（Matching Pursuit, MP）和正交匹配追踪（Orthogonal Matching Pursuit, OMP），其定义如下。\n\n匹配追踪（MP）算法初始化残差 $r^{(0)} = y$，并在每次迭代 $t \\geq 1$ 时，选择使内积绝对值 $|\\langle r^{(t-1)}, a_{j} \\rangle|$ 在 $j \\in \\{1,2,3\\}$ 上最大化的索引 $j_{t} \\in \\{1,2,3\\}$。然后，它通过从残差中减去 $r^{(t-1)}$ 在所选原子上的标量投影来更新残差，即 $r^{(t)} = r^{(t-1)} - \\langle r^{(t-1)}, a_{j_{t}} \\rangle a_{j_{t}}$，而不修改先前选择的系数。\n\n正交匹配追踪（OMP）算法也初始化 $r^{(0)} = y$，并在每次迭代 $t \\geq 1$ 时，选择使 $|\\langle r^{(t-1)}, a_{j} \\rangle|$ 最大化的索引 $j_{t}$，但随后通过将 $y$ 正交投影到由所有已选索引 $S^{(t)} = \\{j_{1}, \\dots, j_{t}\\}$ 构成的原子张成的子空间 $\\operatorname{span}\\{a_{j}: j \\in S^{(t)}\\}$ 上，重新计算支撑集为 $S^{(t)}$ 的系数向量。也就是说，找到最小化 $\\|y - A_{S^{(t)}} x\\|_{2}$ 的 $x^{(t)}$，其中 $A_{S^{(t)}}$ 是由 $A$ 中索引为 $S^{(t)}$ 的列组成的子矩阵。然后残差为 $r^{(t)} = y - A_{S^{(t)}} x^{(t)}$。\n\n从 $r^{(0)} = y$ 开始，对给定的 $y$ 和 $A$ 运行匹配追踪（MP）和正交匹配追踪（OMP）算法，各运行恰好两次迭代（$t=1$ 和 $t=2$）。在每次迭代中，确定所选原子的索引，计算更新后的残差，并计算其欧几里得范数。请使用有限维欧几里得空间中内积、标量投影和正交投影的基本定义。在完成两种方法的两次迭代后，比较所选原子索引的有序对和残差范数。最后，计算两次迭代后残差范数的差值，\n$$\n\\|r^{(2)}_{\\mathrm{MP}}\\|_{2} - \\|r^{(2)}_{\\mathrm{OMP}}\\|_{2},\n$$\n并将此值作为一个精确的实数提供。不需要四舍五入。",
            "solution": "问题要求运行匹配追踪（MP）和正交匹配追踪（OMP）算法两次迭代，以找到向量 $y \\in \\mathbb{R}^{2}$ 在字典 $A \\in \\mathbb{R}^{2 \\times 3}$ 下的稀疏近似。然后我们必须计算这两种方法最终残差范数之间的差值。\n\n给定的数据如下：\n数据向量 $y = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$。\n字典矩阵 $A = \\begin{pmatrix} 1  \\frac{1}{\\sqrt{2}}  0 \\\\ 0  \\frac{1}{\\sqrt{2}}  1 \\end{pmatrix}$。\n$A$ 的列，称为原子，分别是 $a_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$，$a_{2} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix}$ 和 $a_{3} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。所有原子都是单位范数，即对于 $j \\in \\{1,2,3\\}$，$\\|a_j\\|_2 = 1$。\n两种算法的初始残差均为 $r^{(0)} = y = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$。\n\n**匹配追踪 (Matching Pursuit, MP)**\n\n**迭代 1 (t=1):**\n第一步是选择与当前残差 $r^{(0)}$ 最相关的原子 $a_j$。我们计算 $j \\in \\{1,2,3\\}$ 的内积绝对值 $|\\langle r^{(0)}, a_j \\rangle|$：\n$|\\langle r^{(0)}, a_1 \\rangle| = \\left| \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\right| = |1 \\cdot 1 + 2 \\cdot 0| = |1| = 1$。\n$|\\langle r^{(0)}, a_2 \\rangle| = \\left| \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\cdot \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\right| = \\left| 1 \\cdot \\frac{1}{\\sqrt{2}} + 2 \\cdot \\frac{1}{\\sqrt{2}} \\right| = \\left| \\frac{3}{\\sqrt{2}} \\right| = \\frac{3}{\\sqrt{2}}$。\n$|\\langle r^{(0)}, a_3 \\rangle| = \\left| \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\cdot \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\right| = |1 \\cdot 0 + 2 \\cdot 1| = |2| = 2$。\n\n比较这些值，我们有 $1$、$\\frac{3}{\\sqrt{2}} \\approx 2.121$ 和 $2$。最大值是 $\\frac{3}{\\sqrt{2}}$。\n因此，所选索引为 $j_1=2$。\n\nMP 算法通过减去 $r^{(0)}$ 在 $a_2$ 上的投影来更新残差：\n$r^{(1)}_{\\mathrm{MP}} = r^{(0)} - \\langle r^{(0)}, a_{j_1} \\rangle a_{j_1} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} - \\frac{3}{\\sqrt{2}} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} - \\begin{pmatrix} \\frac{3}{2} \\\\ \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix}$。\n该残差的欧几里得范数是：\n$\\|r^{(1)}_{\\mathrm{MP}}\\|_{2} = \\sqrt{\\left(-\\frac{1}{2}\\right)^2 + \\left(\\frac{1}{2}\\right)^2} = \\sqrt{\\frac{1}{4} + \\frac{1}{4}} = \\sqrt{\\frac{1}{2}} = \\frac{1}{\\sqrt{2}}$。\n\n**迭代 2 (t=2):**\n现在我们选择与新残差 $r^{(1)}_{\\mathrm{MP}}$ 最相关的原子：\n$|\\langle r^{(1)}_{\\mathrm{MP}}, a_1 \\rangle| = \\left| \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\right| = |-\\frac{1}{2}| = \\frac{1}{2}$。\n$|\\langle r^{(1)}_{\\mathrm{MP}}, a_2 \\rangle| = \\left| \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} \\cdot \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\right| = \\left|-\\frac{1}{2\\sqrt{2}} + \\frac{1}{2\\sqrt{2}}\\right| = |0| = 0$。\n$|\\langle r^{(1)}_{\\mathrm{MP}}, a_3 \\rangle| = \\left| \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} \\cdot \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\right| = |\\frac{1}{2}| = \\frac{1}{2}$。\n\n索引 $j=1$ 和 $j=3$ 之间出现平局。一种常见的打破平局规则是选择索引最小的原子。我们选择 $j_2=1$。\n残差更新如下：\n$r^{(2)}_{\\mathrm{MP}} = r^{(1)}_{\\mathrm{MP}} - \\langle r^{(1)}_{\\mathrm{MP}}, a_{j_2} \\rangle a_{j_2} = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} - \\left(-\\frac{1}{2}\\right) \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} + \\begin{pmatrix} \\frac{1}{2} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\frac{1}{2} \\end{pmatrix}$。\n最终 MP 残差的欧几里得范数是：\n$\\|r^{(2)}_{\\mathrm{MP}}\\|_{2} = \\sqrt{0^2 + \\left(\\frac{1}{2}\\right)^2} = \\sqrt{\\frac{1}{4}} = \\frac{1}{2}$。\nMP 算法所选索引的有序对是 $(2, 1)$。\n\n**正交匹配追踪 (Orthogonal Matching Pursuit, OMP)**\n\n**迭代 1 (t=1):**\n选择步骤与 MP 相同。计算相同的内积，选择相同的原子。\n所选索引 $j_1=2$。所选索引的集合是 $S^{(1)} = \\{2\\}$。\nOMP 通过将 $y$ 正交投影到所选原子的张成空间上来计算系数。在这里，我们将 $y$ 投影到 $\\operatorname{span}\\{a_2\\}$ 上。系数 $x^{(1)}$ 是通过求解最小二乘问题 $\\min_{x} \\|y - a_2 x\\|_2$ 找到的。由于 $a_2$ 是单位范数，解为 $x^{(1)} = \\langle y, a_2 \\rangle = \\frac{3}{\\sqrt{2}}$。\n近似为 $y_{\\text{approx}}^{(1)} = x^{(1)} a_2 = \\frac{3}{\\sqrt{2}} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{2} \\\\ \\frac{3}{2} \\end{pmatrix}$。\n残差是 $r^{(1)}_{\\mathrm{OMP}} = y - y_{\\text{approx}}^{(1)} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} - \\begin{pmatrix} \\frac{3}{2} \\\\ \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix}$。\n这与 MP 中的第一个残差相同，正如第一次迭代所预期的。\n$\\|r^{(1)}_{\\mathrm{OMP}}\\|_{2} = \\frac{1}{\\sqrt{2}}$。\n\n**迭代 2 (t=2):**\n选择基于与当前残差 $r^{(1)}_{\\mathrm{OMP}}$ 的内积，该残差与 $r^{(1)}_{\\mathrm{MP}}$ 相同。选择过程与 MP 的第二次迭代相同。\n所选索引 $j_2=1$。所选索引的集合是 $S^{(2)} = \\{2, 1\\}$。\nOMP 通过将 $y$ 投影到子空间 $\\operatorname{span}\\{a_1, a_2\\}$ 上来重新计算系数。我们找到最小化 $\\|y - A_{S^{(2)}} x\\|_2$ 的系数向量 $x^{(2)}$，其中 $A_{S^{(2)}} = [a_1 \\ a_2] = \\begin{pmatrix} 1  \\frac{1}{\\sqrt{2}} \\\\ 0  \\frac{1}{\\sqrt{2}} \\end{pmatrix}$。\n列 $a_1$ 和 $a_2$ 是线性无关的，因此构成了 $\\mathbb{R}^2$ 的一个基。因此，$\\operatorname{span}\\{a_1, a_2\\} = \\mathbb{R}^2$。\n任何向量 $y \\in \\mathbb{R}^2$ 在整个空间 $\\mathbb{R}^2$ 上的正交投影就是向量 $y$ 本身。\n所以，OMP 的近似是 $y_{\\text{approx}}^{(2)} = y$。\n因此残差是 $r^{(2)}_{\\mathrm{OMP}} = y - y_{\\text{approx}}^{(2)} = y - y = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。\n最终 OMP 残差的欧几里得范数是：\n$\\|r^{(2)}_{\\mathrm{OMP}}\\|_{2} = 0$。\nOMP 算法所选索引的有序对是 $(2, 1)$。\n\n**比较与最终计算**\n- 两种方法所选索引的有序对是相同的：$(j_1, j_2) = (2, 1)$。\n- MP 的最终残差范数是 $\\|r^{(2)}_{\\mathrm{MP}}\\|_{2} = \\frac{1}{2}$。\n- OMP 的最终残差范数是 $\\|r^{(2)}_{\\mathrm{OMP}}\\|_{2} = 0$。\n\n问题要求计算两次迭代后残差范数的差值：\n$\\|r^{(2)}_{\\mathrm{MP}}\\|_{2} - \\|r^{(2)}_{\\mathrm{OMP}}\\|_{2} = \\frac{1}{2} - 0 = \\frac{1}{2}$。",
            "answer": "$$\n\\boxed{\\frac{1}{2}}\n$$"
        },
        {
            "introduction": "贪婪算法虽然功能强大，但并不能保证在所有情况下都成功。这个高级练习挑战您从应用算法转向分析其理论极限。您将构建一个OMP失败的特定场景，从而具体阐释著名的互相关性条件，并对字典结构与恢复保证之间的相互作用产生更深刻的理解 。",
            "id": "3449211",
            "problem": "设 $A \\in \\mathbb{R}^{k \\times (k+1)}$ 是一个字典，其列 $\\{a_{1},\\dots,a_{k+1}\\}$ 是单位范数的。$A$ 的互相关性定义为 $\\mu(A) \\triangleq \\max_{i \\neq j} |\\langle a_{i}, a_{j} \\rangle|$。正交匹配追踪 (OMP) 在给定一个测量值 $y \\in \\mathbb{R}^{k}$ 时，在其第一次迭代中选择使 $|\\langle a_{j}, y \\rangle|$ 最大化的索引 $j$。\n\n仅使用上述定义、标准的内积性质和格拉姆矩阵事实，显式地构造一个字典 $A$ 和一个 $k$-稀疏向量 $x^{\\star} \\in \\mathbb{R}^{k+1}$，其支撑集为 $S = \\{1,\\dots,k\\}$ 且在 $S$ 上具有相等的正系数，使得：\n- $\\mu(A) = \\frac{1}{k}$，\n- 对于无噪声数据 $y = A x^{\\star}$，正交匹配追踪 (OMP) 可以在第一次迭代时就选择错误的原子 $a_{k+1}$，\n- 经典的互相关性条件 $k \\ge \\frac{1}{2}\\left(1 + \\mu(A)^{-1}\\right)$ 成立。\n\n你的构造必须基于 $\\mathbb{R}^{k-1}$ 中的一组 $k$ 个单位向量，这些向量构成一个正单形的顶点。然后，将它们嵌入到 $\\mathbb{R}^{k}$ 中，并增加一个与该单形子空间正交的额外单位向量，以构成 $A$。\n\n最后，对于你的构造，以闭合形式计算比率\n$$\nr \\triangleq \\frac{\\max_{j \\notin S} |\\langle a_{j}, y \\rangle|}{\\max_{i \\in S} |\\langle a_{i}, y \\rangle|},\n$$\n并表示为 $k$ 的函数。你的最终答案必须是一个单一的精确表达式，不带单位且不进行四舍五入。",
            "solution": "我们按照指定的方式构造字典 $A$，然后定义稀疏向量 $x^{\\star}$，最后分析 OMP 算法的第一步。\n\n**1. 字典 $A$ 的构造**\n\n我们遵循提供的提示。构造始于在 $\\mathbb{R}^{k-1}$ 空间中的一组 $k$ 个单位向量 $\\{v_1, \\dots, v_k\\}$，它们构成一个以原点为中心的正单形的顶点。这样一组向量的一个关键性质是它们的成对内积为常数且为负。具体来说，对于 $\\{1, \\dots, k\\}$ 中任何 $i \\neq j$，我们有 $\\langle v_i, v_j \\rangle = -\\frac{1}{k-1}$。这样一组向量的存在性是几何学中的一个标准结果。\n\n接下来，我们将这些向量嵌入到 $\\mathbb{R}^k$ 中，以构成我们字典的前 $k$ 列 $\\{a_1, \\dots, a_k\\}$。我们定义这些列为 $a_j = \\begin{pmatrix} \\alpha v_j \\\\ \\beta \\end{pmatrix}$，对于 $j \\in \\{1, \\dots, k\\}$，其中前 $k-1$ 个分量是向量 $\\alpha v_j$，第 $k$ 个分量是标量 $\\beta$。标量 $\\alpha$ 和 $\\beta$ 是待确定的实常数。为了使 $a_j$ 成为单位向量，我们必须有 $\\|a_j\\|_2^2 = 1$。\n$$ \\|a_j\\|_2^2 = \\alpha^2 \\|v_j\\|_2^2 + \\beta^2 = \\alpha^2(1) + \\beta^2 = 1 $$\n所以，我们需要 $\\alpha^2 + \\beta^2 = 1$。我们选择 $\\alpha > 0$。\n\n最后一列 $a_{k+1}$ 是 $\\mathbb{R}^k$ 中的一个单位向量，它“与单形子空间正交”。我们将其解释为 $a_{k+1}$ 与 $\\{v_j\\}$ 被映射到的子空间正交，即由形如 $[v^T, 0]^T$（其中 $v \\in \\mathbb{R}^{k-1}$）的向量所张成的子空间。与该子空间正交的单位向量是 $e_k = [0, \\dots, 0, 1]^T \\in \\mathbb{R}^k$。所以，我们设 $a_{k+1} = e_k$。\n\n现在，我们通过强制执行互相关性条件 $\\mu(A) = \\frac{1}{k}$ 来确定 $\\alpha$ 和 $\\beta$。我们计算 $A$ 的不同列之间的内积。\n对于 $1 \\le i \\neq j \\le k$：\n$$ \\langle a_i, a_j \\rangle = \\left\\langle \\begin{pmatrix} \\alpha v_i \\\\ \\beta \\end{pmatrix}, \\begin{pmatrix} \\alpha v_j \\\\ \\beta \\end{pmatrix} \\right\\rangle = \\alpha^2 \\langle v_i, v_j \\rangle + \\beta^2 = \\alpha^2 \\left(-\\frac{1}{k-1}\\right) + \\beta^2 $$\n对于 $j \\in \\{1, \\dots, k\\}$：\n$$ \\langle a_j, a_{k+1} \\rangle = \\left\\langle \\begin{pmatrix} \\alpha v_j \\\\ \\beta \\end{pmatrix}, e_k \\right\\rangle = \\beta $$\n互相关性为 $\\mu(A) = \\max \\left( \\left| -\\frac{\\alpha^2}{k-1} + \\beta^2 \\right|, |\\beta| \\right)$。为了满足 $\\mu(A) = \\frac{1}{k}$，我们可以将两项的绝对值都设为 $\\frac{1}{k}$。令 $|\\beta| = \\frac{1}{k}$。不失一般性，我们选择 $\\beta = \\frac{1}{k}$。\n根据单位范数约束，$\\alpha^2 = 1 - \\beta^2 = 1 - \\frac{1}{k^2} = \\frac{k^2-1}{k^2}$。\n现在我们检查另一个内积项：\n$$ \\left| -\\frac{\\alpha^2}{k-1} + \\beta^2 \\right| = \\left| -\\frac{(k^2-1)/k^2}{k-1} + \\frac{1}{k^2} \\right| = \\left| -\\frac{(k-1)(k+1)}{k^2(k-1)} + \\frac{1}{k^2} \\right| = \\left| -\\frac{k+1}{k^2} + \\frac{1}{k^2} \\right| = \\left| -\\frac{k}{k^2} \\right| = \\frac{1}{k} $$\n两个内积的绝对值都是 $\\frac{1}{k}$，因此构造成功，且 $\\mu(A) = \\frac{1}{k}$。\n\n**2. OMP 第一次迭代分析**\n\n稀疏向量 $x^{\\star}$ 的支撑集在 $S = \\{1, \\dots, k\\}$ 上，且具有相等的正系数。为简单起见，我们令非零系数为 $1$。因此，$x^{\\star} = [1, \\dots, 1, 0]^T \\in \\mathbb{R}^{k+1}$。\n测量向量为 $y = A x^{\\star} = \\sum_{j=1}^{k} a_j$。\n\nOMP 的第一步是找到与 $y$ 相关性最高的 $A$ 的列。我们计算所有 $j \\in \\{1, \\dots, k+1\\}$ 的内积 $\\langle a_j, y \\rangle$。\n\n对于索引 $j \\in S = \\{1, \\dots, k\\}$（一个“正确的”原子）：\n$$ \\langle a_j, y \\rangle = \\left\\langle a_j, \\sum_{i=1}^k a_i \\right\\rangle = \\langle a_j, a_j \\rangle + \\sum_{i=1, i \\neq j}^k \\langle a_j, a_i \\rangle $$\n我们有 $\\|a_j\\|_2^2=1$。对于 $i \\neq j$，我们发现 $\\langle a_i, a_j \\rangle = -\\frac{\\alpha^2}{k-1} + \\beta^2 = -\\frac{1}{k}$。\n$$ \\langle a_j, y \\rangle = 1 + (k-1) \\left(-\\frac{1}{k}\\right) = 1 - \\frac{k-1}{k} = \\frac{k - (k-1)}{k} = \\frac{1}{k} $$\n所以，对于所有 $j \\in S$，都有 $|\\langle a_j, y \\rangle| = \\frac{1}{k}$。这意味着 $\\max_{j \\in S} |\\langle a_j, y \\rangle| = \\frac{1}{k}$。\n\n对于索引 $j=k+1 \\notin S$（“错误的”原子）：\n$$ \\langle a_{k+1}, y \\rangle = \\left\\langle a_{k+1}, \\sum_{i=1}^k a_i \\right\\rangle = \\sum_{i=1}^k \\langle a_{k+1}, a_i \\rangle $$\n我们有 $\\langle a_{k+1}, a_i \\rangle = \\beta = \\frac{1}{k}$，对于所有 $i \\in \\{1, \\dots, k\\}$。\n$$ \\langle a_{k+1}, y \\rangle = \\sum_{i=1}^k \\frac{1}{k} = k \\cdot \\frac{1}{k} = 1 $$\n所以，$|\\langle a_{k+1}, y \\rangle| = 1$。\n\n比较相关性，我们有 $|\\langle a_{k+1}, y \\rangle| = 1$ 和 $\\max_{j \\in S} |\\langle a_j, y \\rangle| = \\frac{1}{k}$。对于任何整数 $k > 1$，我们有 $1 > \\frac{1}{k}$。因此，OMP 将在第一次迭代时选择错误的原子 $a_{k+1}$，因为它与测量值 $y$ 的相关性比任何正确的原子都强。\n\n**3. 比率 $r$ 的计算**\n\n问题要求计算比率：\n$$ r \\triangleq \\frac{\\max_{j \\notin S} |\\langle a_{j}, y \\rangle|}{\\max_{i \\in S} |\\langle a_{i}, y \\rangle|} $$\n不在 $S=\\{1, \\dots, k\\}$ 中的索引集就是 $\\{k+1\\}$。所以，分子是 $|\\langle a_{k+1}, y \\rangle|$。\n使用我们计算出的值：\n$$ r = \\frac{|\\langle a_{k+1}, y \\rangle|}{\\max_{i \\in \\{1, \\dots, k\\}} |\\langle a_i, y \\rangle|} = \\frac{1}{1/k} = k $$\n该比率是 $k$ 的一个简单函数。",
            "answer": "$$\n\\boxed{k}\n$$"
        }
    ]
}