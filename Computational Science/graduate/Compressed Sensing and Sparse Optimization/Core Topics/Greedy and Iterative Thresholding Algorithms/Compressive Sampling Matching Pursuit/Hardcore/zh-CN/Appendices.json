{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握像 CoSaMP 这样的迭代算法，最有效的方法之一就是亲手执行其计算步骤。本练习将引导你完成 CoSaMP 算法一个完整的迭代周期，从计算代理向量、识别和合并支撑集，到求解最小二乘问题和剪枝，让你对算法的内部工作机制有具体而深入的理解。通过这个具体的数值示例 ，你将能够巩固对每个阶段目标的认识。",
            "id": "3434637",
            "problem": "考虑一个压缩感知中的线性测量模型，其中信号 $x \\in \\mathbb{R}^{5}$ 在规范基下是 $k$-稀疏的（即，基变换矩阵是单位矩阵），测量值由 $y = A x$ 给出，其中 $A \\in \\mathbb{R}^{3 \\times 5}$。令\n$$A = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix}$$\n$\\Phi = I_{5}$，以及\n$$x = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 0 \\end{bmatrix}$$\n因此 $y = A x$。从基本定义出发：线性测量 $y = A x$，$x$ 在单位基下的稀疏性，支撑集为非零项的索引集合，最小二乘拟合为最小化残差的欧几里得范数。执行一轮完整的压缩采样匹配追踪（Compressive Sampling Matching Pursuit, CoSaMP）算法，目标稀疏度为 $k = 2$，从零初始估计 $x^{(0)} = 0$ 和残差 $r^{(0)} = y$ 开始。遵循以下基本步骤：\n\n- 计算代理 $u = A^{\\top} r^{(0)}$。\n- 识别与 $|u|$ 中幅值最大的 $2k$ 个元素对应的索引集 $\\Omega$。\n- 与当前支撑集合并，形成 $\\mathcal{T} = \\Omega \\cup \\operatorname{supp}(x^{(0)})$。\n- 求解最小二乘问题 $b = \\arg\\min_{z \\in \\mathbb{R}^{5},\\, \\operatorname{supp}(z) \\subseteq \\mathcal{T}} \\| y - A z \\|_{2}$；如果存在多个最小化解，选择欧几里得范数最小的那个。\n- 将 $b$ 剪枝，保留其幅值最大的 $k$ 个元素，以获得 $x^{(1)}$。\n- 形成更新后的残差 $r^{(1)} = y - A x^{(1)}$。\n\n更新后的残差的欧几里得范数 $\\| r^{(1)} \\|_{2}$ 是多少？请以闭式解析表达式给出最终答案。不要进行近似或四舍五入。",
            "solution": "该问题要求执行一轮完整的压缩采样匹配追踪（CoSaMP）算法，以求得更新后残差的欧几里得范数 $\\| r^{(1)} \\|_{2}$。我们已知线性测量模型 $y = Ax$，其中信号 $x \\in \\mathbb{R}^{5}$ 在规范基下是稀疏的。\n\n给定的数据如下：\n- 测量矩阵: $A = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 5}$\n- 真实信号: $x = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 0 \\end{bmatrix} \\in \\mathbb{R}^{5}$\n- 算法的目标稀疏度: $k = 2$\n- 初始信号估计: $x^{(0)} = 0 \\in \\mathbb{R}^{5}$\n- 基变换矩阵是单位矩阵 $\\Phi = I_{5}$。\n\n迭代过程遵循一系列预定步骤。首先，我们计算测量向量 $y$。\n$$y = Ax = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1(1) + 1(2) \\\\ 1(2) \\\\ 1(1) \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix}$$\n初始残差为 $r^{(0)} = y = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix}$。\n\n现在，我们进行CoSaMP迭代的步骤。\n\n1.  **计算代理**：代理 $u$ 由 $u = A^{\\top} r^{(0)}$ 给出。\n    $$A^{\\top} = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\\\ 0  0  1 \\end{bmatrix}$$\n    $$u = A^{\\top} r^{(0)} = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\\\ 0  0  1 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1(3) + 1(1) \\\\ 1(2) \\\\ 1(3) + 1(2) \\\\ 1(2) + 1(1) \\\\ 1(1) \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ 2 \\\\ 5 \\\\ 3 \\\\ 1 \\end{bmatrix}$$\n\n2.  **识别支撑集**：我们识别与 $|u|$ 中幅值最大的 $2k$ 个元素对应的索引集 $\\Omega$。这里，$k=2$，所以 $2k=4$。向量 $u$ 的所有元素都是正的，所以 $|u|=u$。$u$ 的元素按幅值降序排列为 $5, 4, 3, 2$，对应的索引是 $3, 1, 4, 2$。\n    $$\\Omega = \\{1, 2, 3, 4\\}$$\n\n3.  **合并支撑集**：新的候选支撑集 $\\mathcal{T}$ 是 $\\Omega$ 与前一个估计 $x^{(0)}$ 的支撑集的并集。\n    $$\\operatorname{supp}(x^{(0)}) = \\operatorname{supp}(0) = \\emptyset$$\n    $$\\mathcal{T} = \\Omega \\cup \\operatorname{supp}(x^{(0)}) = \\{1, 2, 3, 4\\}$$\n\n4.  **求解最小二乘问题**：我们必须找到支撑集包含在 $\\mathcal{T}$ 中的向量 $b$，使得 $\\|y - Az\\|_2$ 最小化。这等价于在最小二乘意义下从系统 $A_{\\mathcal{T}} b_{\\mathcal{T}} \\approx y$ 求解 $b_{\\mathcal{T}}$，其中 $A_{\\mathcal{T}}$ 是由 $A$ 中索引为 $\\mathcal{T}$ 的列组成的子矩阵。\n    $$A_{\\mathcal{T}} = \\begin{bmatrix} 1  0  1  0 \\\\ 0  1  1  1 \\\\ 1  0  0  1 \\end{bmatrix}$$\n    问题指定，如果存在多个最小化解，我们选择欧几里得范数最小的那个。这对应于解 $b_{\\mathcal{T}} = A_{\\mathcal{T}}^{\\dagger} y$，其中 $A_{\\mathcal{T}}^{\\dagger}$ 是 $A_{\\mathcal{T}}$ 的摩尔-彭若斯伪逆。由于 $A_{\\mathcal{T}}$ 是一个秩为 $3$ 的 $3 \\times 4$ 矩阵（它具有满行秩），其伪逆由 $A_{\\mathcal{T}}^{\\dagger} = A_{\\mathcal{T}}^{\\top}(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top})^{-1}$ 给出。\n    首先，我们计算 $A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top}$：\n    $$A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top} = \\begin{bmatrix} 1  0  1  0 \\\\ 0  1  1  1 \\\\ 1  0  0  1 \\end{bmatrix} \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} = \\begin{bmatrix} 2  1  1 \\\\ 1  3  1 \\\\ 1  1  2 \\end{bmatrix}$$\n    接下来，我们求这个 $3 \\times 3$ 矩阵的逆。其行列式为 $\\det(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top}) = 2(6-1) - 1(2-1) + 1(1-3) = 10 - 1 - 2 = 7$。\n    逆矩阵是：\n    $$(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top})^{-1} = \\frac{1}{7} \\begin{bmatrix} 5  -1  -2 \\\\ -1  3  -1 \\\\ -2  -1  5 \\end{bmatrix}$$\n    现在我们可以计算 $b_{\\mathcal{T}}$：\n    $$b_{\\mathcal{T}} = A_{\\mathcal{T}}^{\\top}(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top})^{-1} y = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} \\left( \\frac{1}{7} \\begin{bmatrix} 5  -1  -2 \\\\ -1  3  -1 \\\\ -2  -1  5 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix} \\right)$$\n    $$b_{\\mathcal{T}} = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} \\left( \\frac{1}{7} \\begin{bmatrix} 15-2-2 \\\\ -3+6-1 \\\\ -6-2+5 \\end{bmatrix} \\right) = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} \\left( \\frac{1}{7} \\begin{bmatrix} 11 \\\\ 2 \\\\ -3 \\end{bmatrix} \\right) = \\frac{1}{7} \\begin{bmatrix} 11-3 \\\\ 2 \\\\ 11+2 \\\\ 2-3 \\end{bmatrix} = \\frac{1}{7} \\begin{bmatrix} 8 \\\\ 2 \\\\ 13 \\\\ -1 \\end{bmatrix}$$\n    完整的向量 $b \\in \\mathbb{R}^5$ 是通过将这些值放在 $\\mathcal{T}$ 中的索引位置并在其他位置补零来构造的：\n    $$b = \\begin{bmatrix} 8/7 \\\\ 2/7 \\\\ 13/7 \\\\ -1/7 \\\\ 0 \\end{bmatrix}$$\n\n5.  **剪枝估计**: 我们通过保留 $b$ 中幅值最大的 $k=2$ 个分量来获得新的信号估计 $x^{(1)}$。$b$ 的非零分量的幅值是 $|8/7|$、 $|2/7|$、 $|13/7|$ 和 $|-1/7|$，即 $8/7$、 $2/7$、 $13/7$ 和 $1/7$。最大的两个是 $13/7$（在索引 $3$ 处）和 $8/7$（在索引 $1$ 处）。\n    因此，我们将所有其他分量设置为零：\n    $$x^{(1)} = \\begin{bmatrix} 8/7 \\\\ 0 \\\\ 13/7 \\\\ 0 \\\\ 0 \\end{bmatrix}$$\n\n6.  **更新残差**：新的残差 $r^{(1)}$ 是 $r^{(1)} = y - Ax^{(1)}$。\n    $$Ax^{(1)} = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix} \\begin{bmatrix} 8/7 \\\\ 0 \\\\ 13/7 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 8/7 + 13/7 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix} = \\begin{bmatrix} 21/7 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix}$$\n    $$r^{(1)} = y - Ax^{(1)} = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix} - \\begin{bmatrix} 3 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 14/7 - 13/7 \\\\ 7/7 - 8/7 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1/7 \\\\ -1/7 \\end{bmatrix}$$\n\n最后，我们计算更新后残差 $r^{(1)}$ 的欧几里得范数。\n$$\\|r^{(1)}\\|_{2} = \\sqrt{0^2 + (1/7)^2 + (-1/7)^2} = \\sqrt{\\frac{1}{49} + \\frac{1}{49}} = \\sqrt{\\frac{2}{49}} = \\frac{\\sqrt{2}}{7}$$\n一次迭代后残差的欧几里得范数为 $\\frac{\\sqrt{2}}{7}$。",
            "answer": "$$\\boxed{\\frac{\\sqrt{2}}{7}}$$"
        },
        {
            "introduction": "CoSaMP 算法的成功恢复能力在理论上由传感矩阵 $A$ 是否满足约束等距性质 (Restricted Isometry Property, RIP) 来保证。当 RIP 条件被破坏时，算法可能会失败。本练习  构建了一个精巧的反例，其中传感矩阵的列之间存在高度相关性，从而违反了 RIP。通过分析这个案例，你将亲眼见证算法如何选择错误的支撑集，并从理论上计算其约束等距常数，从而深刻理解 RIP 在确保贪婪算法稳定性中的核心作用。",
            "id": "3436625",
            "problem": "考虑无噪声线性测量模型 $y = A x^{\\star}$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 且 $x^{\\star} \\in \\mathbb{R}^{n}$，$x^{\\star}$ 是 $k$-稀疏的。压缩采样匹配追踪（Compressive Sampling Matching Pursuit，以下简称 CoSaMP）算法通过与当前残差的相关性来迭代地识别候选支撑集，在合并的支撑集上求解最小二乘问题，然后在更新残差之前剪枝到 $k$ 个条目。CoSaMP 的恢复保证通常在限制等距性质（Restricted Isometry Property, RIP）下给出：如果对于所有 $s$-稀疏向量 $v$，都满足 $(1 - \\delta_{s}) \\|v\\|_{2}^{2} \\le \\|A v\\|_{2}^{2} \\le (1 + \\delta_{s}) \\|v\\|_{2}^{2}$，则矩阵 $A$ 具有阶数为 $s$ 的 RIP，其限制等距常数（restricted isometry constant, RIC）为 $\\delta_{s}$。\n\n构建一个感知矩阵 $A \\in \\mathbb{R}^{2 \\times 8}$，其列向量为\n$$\na_{1} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix},\\quad\na_{2} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix},\\quad\na_{3} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix},\\quad\na_{4} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix},\\quad\na_{5} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix},\\quad\na_{6} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix},\\quad\na_{7} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix},\\quad\na_{8} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}.\n$$\n令 $k = 2$，真实信号为 $x^{\\star} \\in \\mathbb{R}^{8}$，其分量为 $x^{\\star}_{1} = 1$，$x^{\\star}_{2} = 1$，且对于 $j \\in \\{3,4,5,6,7,8\\}$，$x^{\\star}_{j} = 0$。因此 $y = A x^{\\star} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$。\n\n从限制等距性质和 CoSaMP 迭代（残差更新、基于相关性识别 $2k$ 个索引、在合并支撑集上进行最小二乘、按系数大小剪枝到 $k$、以及残差重新计算）的定义出发，完成以下任务：\n\n- 仅使用上述定义和标准线性代数，确定 CoSaMP 算法在应用于 $(A, y)$ 时，在第一次迭代中识别出的 $2k$ 个索引的集合，并证明在最小二乘和剪枝步骤之后，CoSaMP 可以选择一个不包含真实索引 $\\{1, 2\\}$ 的支撑集，同时实现零残差。\n- 通过分析所有 $4k$-稀疏向量 $v$ 的 $\\|A v\\|_{2}^{2}$ 相对于 $\\|v\\|_{2}^{2}$ 的极值偏差，计算所构造矩阵 $A$ 的限制等距常数 $\\delta_{4k}$。\n\n将最终答案表示为 $A$ 的 $\\delta_{4k}$ 的精确值。无需四舍五入。不涉及物理单位。",
            "solution": "用户在压缩感知领域提供了一个适定问题。该问题要求对一个特定构造的感知矩阵和信号，分析压缩采样匹配追踪（CoSaMP）算法的第一次迭代，并计算相应的限制等距常数（RIC）。该问题是有效的，因为它是科学有据、自洽且客观的。\n\n问题分为两部分。首先，我们将分析 CoSaMP 算法的行为。其次，我们将计算限制等距常数 $\\delta_{4k}$。\n\n**第一部分：CoSaMP 算法第一次迭代的分析**\n\nCoSaMP 算法以估计值 $x^0 = 0$ 和相应的支撑集 $T^0 = \\emptyset$ 进行初始化。初始残差为 $r^0 = y - Ax^0 = y$。\n给定的参数是：\n- 稀疏度：$k=2$。\n- 真实信号：$x^{\\star} \\in \\mathbb{R}^{8}$，其中 $x^{\\star}_{1} = 1$, $x^{\\star}_{2} = 1$，对于 $j  2$，$x^{\\star}_{j} = 0$。真实支撑集为 $\\{1, 2\\}$。\n- 感知矩阵 $A \\in \\mathbb{R}^{2 \\times 8}$，其列向量由\n$a_{1} = a_5 = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$，$a_{2} = a_6 = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$，以及 $a_{3} = a_{4} = a_{7} = a_{8} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$ 给出。\n- 测量向量：$y = A x^{\\star} = a_1 x^{\\star}_1 + a_2 x^{\\star}_2 = 1 \\cdot \\begin{pmatrix}1 \\\\ 0\\end{pmatrix} + 1 \\cdot \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$。\n\nCoSaMP 的第一次迭代（$\\ell=1$）过程如下：\n\n1.  **使用相关性识别支撑集：**\n    我们计算“代理”向量 $p = A^T r^0 = A^T y$。\n    $$\n    A^T y =\n    \\begin{pmatrix}\n    a_1^T \\\\ a_2^T \\\\ a_3^T \\\\ a_4^T \\\\ a_5^T \\\\ a_6^T \\\\ a_7^T \\\\ a_8^T\n    \\end{pmatrix}\n    \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} =\n    \\begin{pmatrix}\n    a_1^T y \\\\ a_2^T y \\\\ a_3^T y \\\\ a_4^T y \\\\ a_5^T y \\\\ a_6^T y \\\\ a_7^T y \\\\ a_8^T y\n    \\end{pmatrix}\n    $$\n    相关性计算如下：\n    - $a_1^T y = a_5^T y = \\begin{pmatrix}1  0\\end{pmatrix} \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = 1$。\n    - $a_2^T y = a_6^T y = \\begin{pmatrix}0  1\\end{pmatrix} \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = 1$。\n    - $a_3^T y = a_4^T y = a_7^T y = a_8^T y = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1  1\\end{pmatrix} \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\frac{2}{\\sqrt{2}} = \\sqrt{2}$。\n\n    代理向量为 $p = (1, 1, \\sqrt{2}, \\sqrt{2}, 1, 1, \\sqrt{2}, \\sqrt{2})^T$。\n    CoSaMP 识别出对应于 $p$ 中 $2k = 4$ 个最大幅值分量的索引集合 $\\Omega$。四个最大幅值均为 $\\sqrt{2}$，对应的索引为 $\\{3, 4, 7, 8\\}$。因此，$\\Omega = \\{3, 4, 7, 8\\}$。注意，真实支撑集索引 $\\{1, 2\\}$ 没有被选中，因为它们的相关值较小。\n\n2.  **合并支撑集：**\n    通过将前一个支撑集与新识别的索引合并，形成候选支撑集：$S^1 = T^0 \\cup \\Omega = \\emptyset \\cup \\{3, 4, 7, 8\\} = \\{3, 4, 7, 8\\}$。\n\n3.  **最小二乘估计：**\n    我们寻找一个在 $S^1$ 上支撑的信号估计 $b$，以最好地解释测量值 $y$。这通过求解最小二乘问题来完成：\n    $$\n    b_{S^1} = \\arg\\min_z \\| y - A_{S^1} z \\|_2^2\n    $$\n    其中 $A_{S^1}$ 是由 $A$ 中索引为 $S^1$ 的列组成的子矩阵。这些列是 $a_3, a_4, a_7, a_8$，它们都相同：对于 $i \\in S^1$，$a_i = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$。\n    $A_{S^1}$ 的列空间是一维的，由向量 $v_0 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$ 张成。向量 $y = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\sqrt{2} v_0$ 完全位于此列空间中。因此，最小二乘问题的残差为零，任何满足 $A_{S^1} z = y$ 的向量 $z \\in \\mathbb{R}^4$ 都是一个有效解。\n    设 $z = (z_1, z_2, z_3, z_4)^T$。方程 $A_{S^1} z = y$ 为：\n    $$\n    z_1 a_3 + z_2 a_4 + z_3 a_7 + z_4 a_8 = y\n    $$\n    $$\n    (z_1 + z_2 + z_3 + z_4) \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}\n    $$\n    这简化为单个线性方程 $z_1 + z_2 + z_3 + z_4 = \\sqrt{2}$。\n    这个方程有无穷多个解。问题陈述 CoSaMP“可以选择”一个支撑集，这意味着我们可以从这个解集中选择一个特定的解。让我们选择一个 $2$-稀疏的解。例如，令 $z_1 = \\frac{\\sqrt{2}}{2}$，$z_2 = \\frac{\\sqrt{2}}{2}$，且 $z_3=z_4=0$。\n    这对应于一个中间信号估计 $b$，其非零项为 $b_3 = \\frac{\\sqrt{2}}{2}$ 和 $b_4 = \\frac{\\sqrt{2}}{2}$。\n\n4.  **剪枝：**\n    算法对中间信号 $b$ 进行剪枝以获得新的估计 $x^1$。新的支撑集 $T^1$ 由 $b$ 中 $k=2$ 个最大幅值项的索引组成。在我们的例子中，非零项是 $b_3$ 和 $b_4$，它们的幅值都是 $\\frac{\\sqrt{2}}{2}$。因此，新的支撑集是 $T^1 = \\{3, 4\\}$。\n    新的信号估计 $x^1$ 是 $b$ 限制在该支撑集上的结果：$x^1_3 = \\frac{\\sqrt{2}}{2}$，$x^1_4 = \\frac{\\sqrt{2}}{2}$，所有其他项均为零。\n    这个新的支撑集 $T^1=\\{3, 4\\}$ 不包含真实支撑集索引 $\\{1, 2\\}$。\n\n5.  **残差更新：**\n    迭代的最后一步是计算新的残差 $r^1 = y - Ax^1$。\n    $$\n    A x^1 = a_3 x^1_3 + a_4 x^1_4 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix} \\left(\\frac{\\sqrt{2}}{2}\\right) + \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix} \\left(\\frac{\\sqrt{2}}{2}\\right) = \\begin{pmatrix}1/2 \\\\ 1/2\\end{pmatrix} + \\begin{pmatrix}1/2 \\\\ 1/2\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}\n    $$\n    由于 $A x^1 = y$，残差为 $r^1 = y - y = 0$。\n    由于残差为零，算法终止，在支撑集 $\\{3, 4\\}$ 上恢复了一个不正确的稀疏信号 $x^1$。这表明了由于感知矩阵 $A$ 的结构，CoSaMP 算法出现了一个失败案例。\n\n**第二部分：RIC $\\delta_{4k}$ 的计算**\n\n矩阵 $A$ 的限制等距常数（RIC）$\\delta_s$ 是使得对于所有 $s$-稀疏向量 $v$，以下不等式成立的最小非负数：\n$$ (1 - \\delta_s) \\|v\\|_2^2 \\le \\|Av\\|_2^2 \\le (1 + \\delta_s) \\|v\\|_2^2 $$\n$\\delta_s$ 的一个等价描述是：\n$$ \\delta_s = \\max \\left( \\max_{S:|S|=s} \\lambda_{\\max}(A_S^T A_S) - 1, 1 - \\min_{S:|S|=s} \\lambda_{\\min}(A_S^T A_S) \\right) $$\n其中 $A_S$ 是由 $A$ 中索引为集合 $S$ 的列组成的子矩阵，$\\lambda_{\\max}$ 和 $\\lambda_{\\min}$ 分别表示最大和最小特征值。\n\n我们需要计算 $k=2$ 时的 $\\delta_{4k}$，即 $\\delta_8$。矩阵 $A$ 有 $n=8$ 列。$\\mathbb{R}^8$ 中的一个 $8$-稀疏向量可以是 $\\mathbb{R}^8$ 中的任意向量。因此，我们只需要考虑整个矩阵 $A$ 本身。大小为 $8$ 的子矩阵集合只包含一个元素，即 $A$。\n$\\delta_8$ 的公式简化为：\n$$ \\delta_8 = \\max \\left( \\lambda_{\\max}(A^T A) - 1, 1 - \\lambda_{\\min}(A^T A) \\right) $$\n为了找到 $8 \\times 8$ 矩阵 $A^T A$ 的特征值，计算 $2 \\times 2$ 矩阵 $A A^T$ 的特征值在计算上更简单。$A^T A$ 的非零特征值与 $A A^T$ 的特征值相同。\n\n设 $c=1/\\sqrt{2}$。矩阵 $A$ 是：\n$$\nA = \\begin{pmatrix}\n1  0  c  c  1  0  c  c \\\\\n0  1  c  c  0  1  c  c\n\\end{pmatrix}\n$$\n我们计算 $A A^T$：\n$$\nA A^T = \\begin{pmatrix}\n1  0  c  c  1  0  c  c \\\\\n0  1  c  c  0  1  c  c\n\\end{pmatrix}\n\\begin{pmatrix}\n1  0 \\\\ 0  1 \\\\ c  c \\\\ c  c \\\\ 1  0 \\\\ 0  1 \\\\ c  c \\\\ c  c\n\\end{pmatrix}\n$$\n项 $(A A^T)_{11}$ 是 $A$ 第一行元素平方的和：\n$(A A^T)_{11} = 1^2 + 0^2 + c^2 + c^2 + 1^2 + 0^2 + c^2 + c^2 = 2 + 4c^2 = 2 + 4(1/2) = 4$。\n项 $(A A^T)_{22}$ 是 $A$ 第二行元素平方的和：\n$(A A^T)_{22} = 0^2 + 1^2 + c^2 + c^2 + 0^2 + 1^2 + c^2 + c^2 = 2 + 4c^2 = 2 + 4(1/2) = 4$。\n非对角项 $(A A^T)_{12} = (A A^T)_{21}$ 是 $A$ 的两行之间的点积：\n$(A A^T)_{12} = 1(0) + 0(1) + c(c) + c(c) + 1(0) + 0(1) + c(c) + c(c) = 4c^2 = 4(1/2) = 2$。\n所以，该矩阵是：\n$$\nA A^T = \\begin{pmatrix} 4  2 \\\\ 2  4 \\end{pmatrix}\n$$\n通过求解特征方程 $\\det(A A^T - \\lambda I) = 0$ 来找到特征值 $\\lambda$：\n$$\n\\det \\begin{pmatrix} 4-\\lambda  2 \\\\ 2  4-\\lambda \\end{pmatrix} = (4-\\lambda)^2 - 4 = 0\n$$\n$$\n(4-\\lambda)^2 = 4 \\implies 4-\\lambda = \\pm 2\n$$\n特征值为 $\\lambda_1 = 4-2=2$ 和 $\\lambda_2 = 4+2=6$。\n\n矩阵 $A$ 的秩为 $2$。因此，$8 \\times 8$ 矩阵 $A^T A$ 的秩也为 $2$，并拥有两个非零特征值，即 $2$ 和 $6$。其余的 $8-2=6$ 个特征值为 $0$。\n$A^T A$ 的特征值为 $\\{6, 2, 0, 0, 0, 0, 0, 0\\}$。\n因此，$\\lambda_{\\max}(A^T A) = 6$ 且 $\\lambda_{\\min}(A^T A) = 0$。\n\n将这些值代入 $\\delta_8$ 的公式：\n$$\n\\delta_8 = \\max(6 - 1, 1 - 0) = \\max(5, 1) = 5\n$$\n所构造矩阵 $A$ 的限制等距常数 $\\delta_{4k}$ 为 $5$。",
            "answer": "$$\n\\boxed{5}\n$$"
        },
        {
            "introduction": "在 CoSaMP 迭代中，即使初步的支撑集识别看起来合理，后续的最小二乘估计步骤也可能成为误差的来源。本项高级练习  深入探讨了一个更为微妙的失败模式：传感矩阵中列向量之间的近似共线性。你将分析这种结构如何导致最小二乘子问题变得病态，进而放大噪声的影响，并最终引诱剪枝步骤做出错误的决策。",
            "id": "3436690",
            "problem": "考虑压缩采样匹配追踪（CoSaMP）算法，该算法在每次迭代中，通过选择与当前残差高度相关的传感矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的列来形成一个工作支撑集，然后在该支撑集上求解一个最小二乘子问题，并通过保留 $k$ 个最大幅值的系数进行剪枝。回顾在此类分析中使用的基本原理：在支撑集 $T$ 上的最小二乘步骤求解 $\\min_{z \\in \\mathbb{R}^{|T|}} \\|A_T z - y\\|_2^2$，这等价于正规方程 $A_T^\\top A_T z = A_T^\\top y$，并且格拉姆矩阵 $A_T^\\top A_T$ 的条件数控制了解对扰动的敏感性。同时回顾，$s$ 阶的有限等距性质（RIP）要求对于任何 $s$-稀疏向量 $x$，都有 $(1 - \\delta_s)\\|x\\|_2^2 \\le \\|A x\\|_2^2 \\le (1 + \\delta_s)\\|x\\|_2^2$，这尤其限制了任何 $s$ 列子矩阵的条件数。\n\n设 $m = 3$ 且 $n \\ge 4$。定义列向量 $a_1, a_2 \\in \\mathbb{R}^3$ 为 $a_1 = (1, 0, 0)^\\top$ 和 $a_2 = (1, \\delta, 0)^\\top$，其中 $\\delta  0$ 是一个小参数，并假设其余的列 $\\{a_j\\}_{j \\ge 3}$ 的选择使得它们在所考虑的迭代中与 $y$ 的相关性可以忽略不计。设真实的稀疏系数向量为 $x^\\star \\in \\mathbb{R}^n$，其支撑集为 $\\{1\\}$ 且值为 $x^\\star_1 = 1$。测量值为 $y = A x^\\star + n$，其中扰动为 $n = (0, \\eta, 0)^\\top$，$\\eta \\ge 0$ 为某个小值。在第一次 CoSaMP 迭代中，代理 $A^\\top y$ 选择了工作支撑集 $T = \\{1, 2\\}$，因为 $a_1$ 和 $a_2$ 都与 $y$ 强相关。在 $T$ 上的最小二乘步骤构建格拉姆矩阵 $G = A_T^\\top A_T$ 和右侧项 $b = A_T^\\top y$，求解 $G x_T = b$，然后通过保留 $x_T$ 中最大幅值的元素来剪枝至 $k = 1$。\n\n仅使用上述定义以及线性最小二乘和条件数的基本原理，分析 $a_1$ 和 $a_2$ 的近似共线性对最小二乘步骤的稳定性和剪枝决策的影响。以下哪个陈述是正确的？\n\nA. 对于 $n = (0, \\eta, 0)^\\top$，在 $T$ 上的最小二乘解是 $x_T = (x_1, x_2)$，其中 $x_1 = 1 - \\eta / \\delta$ 和 $x_2 = \\eta / \\delta$。特别地，如果 $\\eta = 2 \\delta$，则 $x_T = (-1, 2)$，并且剪枝至 $k = 1$ 会选择索引 2，这相对于真实支撑集是错误的。\n\nB. 将正规方程求解替换为对 $A_T$ 进行瘦 $QR$ 分解，可以保证对于所有的 $\\delta$ 和 $\\eta$，都有 $|x_i| \\le 1$（对于 $i \\in T$），从而消除不稳定性。\n\nC. 添加参数为 $\\lambda = \\delta^2$ 的 Tikhonov（岭）正则化，得到修正后的系统 $(A_T^\\top A_T + \\lambda I) x_T^\\lambda = A_T^\\top y$。对于 $\\eta = 2 \\delta$，这种选择仍然可能因为偏好近似共线的列而导致剪枝错误，因此剪枝决策的不稳定性可能仍然存在。\n\nD. 如果 $A$ 满足 2 阶的有限等距性质且 $\\delta_2  0.1$，那么像上面 $\\{a_1, a_2\\}$ 这样近似共线的列对就不可能出现；因此，在任何双元素支撑集上的最小二乘子问题都是良态的，从而在通常用于分析 CoSaMP 的 RIP 假设下，防止了这种失败模式的发生。\n\nE. 在此场景下，将 $A$ 的每一列缩放到单位 $\\ell_2$ 范数可以消除近似共线性问题，并稳定最小二乘步骤和剪枝。",
            "solution": "用户希望我验证问题陈述然后解决它。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n- 算法：压缩采样匹配追踪（CoSaMP）。\n- 迭代过程：形成工作支撑集，求解最小二乘，剪枝。\n- 最小二乘子问题：在支撑集 $T$ 上，求解 $\\min_{z \\in \\mathbb{R}^{|T|}} \\|A_T z - y\\|_2^2$，这等价于正规方程 $A_T^\\top A_T z = A_T^\\top y$。\n- 条件数与格拉姆矩阵 $A_T^\\top A_T$ 相关。\n- 有限等距性质（RIP）：$s$ 阶，对于任何 $s$-稀疏向量 $x$，有 $(1 - \\delta_s)\\|x\\|_2^2 \\le \\|A x\\|_2^2 \\le (1 + \\delta_s)\\|x\\|_2^2$。\n- 传感矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其中 $m=3$ 且 $n \\ge 4$。\n- 列向量 $a_1 = (1, 0, 0)^\\top$ 和 $a_2 = (1, \\delta, 0)^\\top$，其中 $\\delta  0$ 是一个小参数。\n- 其余的列 $\\{a_j\\}_{j \\ge 3}$ 与 $y$ 的相关性可以忽略不计。\n- 真实的稀疏系数向量 $x^\\star \\in \\mathbb{R}^n$ 的支撑集为 $\\{1\\}$ 且值为 $x^\\star_1 = 1$。\n- 测量值由 $y = A x^\\star + n$ 给出。\n- 扰动为 $n = (0, \\eta, 0)^\\top$，其中 $\\eta \\ge 0$ 为某个小值。\n- 在第一次 CoSaMP 迭代中，代理 $A^\\top y$ 选择了工作支撑集 $T = \\{1, 2\\}$。\n- 剪枝步骤通过保留最大幅值的元素将支撑集大小减至 $k=1$。\n\n**步骤2：使用提取的已知条件进行验证**\n\n问题陈述在科学上是合理的、适定的和客观的。\n1.  科学依据：该问题是在压缩感知和稀疏恢复的标准理论框架内提出的。CoSaMP、RIP、最小二乘和 Tikhonov 正则化都是公认的概念。所描述的场景，即列相关性导致不稳定性，是用于说明稀疏恢复中的挑战以及需要像 RIP 这样的条件的典型例子。\n2.  适定性：该问题是自洽的，并提供了进行所需分析的全部必要信息。变量、常数和条件都有明确定义。问题是精确的，并允许通过数学推导得出一个唯一的、可确定的答案。\n3.  客观性：该问题以精确、客观的数学语言陈述，没有任何主观或基于意见的主张。\n4.  无缺陷：该问题没有违反任何基本原则，不基于错误的前提，也不包含内部矛盾。这个设置虽然是一个理想化的“玩具问题”，但是是分析算法性质的一种有效且常用的方法。它不是欠定的、过约束的或病态的。\n\n**步骤3：结论和行动**\n\n问题是有效的。分析将继续进行。\n\n### 求解推导\n\n首先，我们建立在支撑集 $T = \\{1, 2\\}$ 上的最小二乘问题的核心组件。\n子矩阵 $A_T$ 由 $A$ 的前两列组成：\n$$A_T = \\begin{pmatrix} a_1  a_2 \\end{pmatrix} = \\begin{pmatrix} 1  1 \\\\ 0  \\delta \\\\ 0  0 \\end{pmatrix}$$\n测量向量 $y$ 是：\n$$y = A x^\\star + n = a_1 x^\\star_1 + n = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\cdot 1 + \\begin{pmatrix} 0 \\\\ \\eta \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\eta \\\\ 0 \\end{pmatrix}$$\n最小二乘问题 $\\min_{x_T} \\|A_T x_T - y\\|_2^2$ 通过正规方程 $G x_T = b$ 求解，其中 $x_T = (x_1, x_2)^\\top$。\n格拉姆矩阵 $G$ 是：\n$$G = A_T^\\top A_T = \\begin{pmatrix} 1  0  0 \\\\ 1  \\delta  0 \\end{pmatrix} \\begin{pmatrix} 1  1 \\\\ 0  \\delta \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  1 \\\\ 1  1+\\delta^2 \\end{pmatrix}$$\n右侧向量 $b$ 是：\n$$b = A_T^\\top y = \\begin{pmatrix} 1  0  0 \\\\ 1  \\delta  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ \\eta \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1+\\eta\\delta \\end{pmatrix}$$\n该方程组是：\n$$ \\begin{pmatrix} 1  1 \\\\ 1  1+\\delta^2 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1+\\eta\\delta \\end{pmatrix} $$\n这给了我们两个线性方程：\n1.  $x_1 + x_2 = 1$\n2.  $x_1 + (1+\\delta^2)x_2 = 1+\\eta\\delta$\n\n从第二个方程中减去第一个方程，得到：\n$$(1+\\delta^2)x_2 - x_2 = (1+\\eta\\delta) - 1$$\n$$\\delta^2 x_2 = \\eta\\delta$$\n因为 $\\delta  0$，我们可以除以 $\\delta$ 得到：\n$$x_2 = \\frac{\\eta}{\\delta}$$\n将此结果代回第一个方程：\n$$x_1 = 1 - x_2 = 1 - \\frac{\\eta}{\\delta}$$\n因此，在支撑集 $T$ 上的最小二乘解是 $x_T = (1 - \\eta/\\delta, \\eta/\\delta)^\\top$。对于小的 $\\delta$，即使是小的扰动 $\\eta$ 也可能导致大的系数。这种放大效应是病态系统的一个标志。$G$ 的行列式是 $\\det(G) = 1(1+\\delta^2) - 1(1) = \\delta^2$，对于小的 $\\delta$ 来说，这个值接近于零，证实了其病态性。\n\n### 逐项分析\n\n**A. 对于 $n = (0, \\eta, 0)^\\top$，在 $T$ 上的最小二乘解是 $x_T = (x_1, x_2)$，其中 $x_1 = 1 - \\eta / \\delta$ 和 $x_2 = \\eta / \\delta$。特别地，如果 $\\eta = 2 \\delta$，则 $x_T = (-1, 2)$，并且剪枝至 $k = 1$ 会选择索引 2，这相对于真实支撑集是错误的。**\n\n上述推导证实了最小二乘解是 $x_T = (1 - \\eta/\\delta, \\eta/\\delta)^\\top$。\n如果我们设置 $\\eta = 2\\delta$，解就变为：\n$$x_1 = 1 - \\frac{2\\delta}{\\delta} = 1 - 2 = -1$$\n$$x_2 = \\frac{2\\delta}{\\delta} = 2$$\n所以，$x_T = (-1, 2)^\\top$。剪枝步骤保留最大幅值的系数。我们比较 $|x_1| = |-1| = 1$ 和 $|x_2| = |2| = 2$。由于 $|x_2|  |x_1|$，算法将支撑集剪枝为 $\\{2\\}$。$x^\\star$ 的真实支撑集是 $\\{1\\}$。因此，剪枝决策是错误的。该陈述与我们的推导完全一致。\n\n结论：**正确**。\n\n**B. 将正规方程求解替换为对 $A_T$ 进行瘦 $QR$ 分解，可以保证对于所有的 $\\delta$ 和 $\\eta$，都有 $|x_i| \\le 1$（对于 $i \\in T$），从而消除不稳定性。**\n\n最小二乘解 $x_T = (A_T^\\top A_T)^{-1} A_T^\\top y$ 在数学上是唯一的，无论使用何种算法来计算它。对 $A_T$ 进行 $QR$ 分解是一种数值上更稳定的计算该解的方法，可以缓解诸如显式构造 $A_T^\\top A_T$ 时的精度损失等问题。然而，它得出的是完全相同的理论解。不稳定性是问题本身的病态性质（$A_T$ 中近似共线的列）所固有的，而不是数值求解器的问题。解仍然是 $x_T = (1 - \\eta/\\delta, \\eta/\\delta)^\\top$。声称 $|x_i| \\le 1$ 是错误的。例如，在选项 A 中 $\\eta = 2\\delta$ 的情况下，我们有 $x_2 = 2$，因此 $|x_2|  1$。\n\n结论：**不正确**。\n\n**C. 添加参数为 $\\lambda = \\delta^2$ 的 Tikhonov（岭）正则化，得到修正后的系统 $(A_T^\\top A_T + \\lambda I) x_T^\\lambda = A_T^\\top y$。对于 $\\eta = 2 \\delta$，这种选择仍然可能因为偏好近似共线的列而导致剪枝错误，因此剪枝决策的不稳定性可能仍然存在。**\n\n正则化后的系统是 $(G + \\lambda I) x_T^\\lambda = b$。当 $\\lambda = \\delta^2$ 时，矩阵变为：\n$$G + \\lambda I = \\begin{pmatrix} 1  1 \\\\ 1  1+\\delta^2 \\end{pmatrix} + \\begin{pmatrix} \\delta^2  0 \\\\ 0  \\delta^2 \\end{pmatrix} = \\begin{pmatrix} 1+\\delta^2  1 \\\\ 1  1+2\\delta^2 \\end{pmatrix}$$\n我们考虑 $\\eta = 2\\delta$ 的情况。右侧项是 $b = (1, 1+(2\\delta)\\delta)^\\top = (1, 1+2\\delta^2)^\\top$。该系统为：\n$$ \\begin{pmatrix} 1+\\delta^2  1 \\\\ 1  1+2\\delta^2 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1+2\\delta^2 \\end{pmatrix} $$\n让我们测试解 $x_T^\\lambda = (0, 1)^\\top$。\n第一个方程：$(1+\\delta^2)(0) + 1(1) = 1$。满足。\n第二个方程：$1(0) + (1+2\\delta^2)(1) = 1+2\\delta^2$。也满足。\n所以，正则化解恰好是 $x_T^\\lambda = (0, 1)^\\top$。\n当剪枝至 $k=1$ 时，我们比较 $|x_1| = 0$ 和 $|x_2| = 1$。算法选择了支撑集 $\\{2\\}$。这仍然是一个错误，因为真实的支撑集是 $\\{1\\}$。正则化稳定了系数（它们不再随着 $\\delta \\to 0$ 而发散），但对于这个参数选择，剪枝决策仍然是错误的。因此，*决策*的不稳定性持续存在。\n\n结论：**正确**。\n\n**D. 如果 $A$ 满足 2 阶的有限等距性质且 $\\delta_2  0.1$，那么像上面 $\\{a_1, a_2\\}$ 这样近似共线的列对就不可能出现；因此，在任何双元素支撑集上的最小二乘子问题都是良态的，从而在通常用于分析 CoSaMP 的 RIP 假设下，防止了这种失败模式的发生。**\n\n$s$ 阶的 RIP 和常数 $\\delta_s$ 意味着，对于任何具有 $|S|=s$ 列的子矩阵 $A_S$，其格拉姆矩阵 $A_S^\\top A_S$ 的特征值必须位于区间 $[1-\\delta_s, 1+\\delta_s]$ 内。\n在我们的例子中，$S=T=\\{1,2\\}$。我们需要检查 $G = A_T^\\top A_T = \\begin{pmatrix} 1  1 \\\\ 1  1+\\delta^2 \\end{pmatrix}$ 的特征值。特征方程是 $(1-\\mu)(1+\\delta^2-\\mu)-1 = 0$，可以简化为 $\\mu^2 - (2+\\delta^2)\\mu + \\delta^2 = 0$。特征值为 $\\mu = \\frac{(2+\\delta^2) \\pm \\sqrt{(2+\\delta^2)^2 - 4\\delta^2}}{2} = \\frac{(2+\\delta^2) \\pm \\sqrt{4+\\delta^4}}{2}$。\n对于小的 $\\delta$，较大的特征值是 $\\mu_1 \\approx \\frac{2+\\delta^2+2}{2} = 2 + \\frac{\\delta^2}{2}$。较小的特征值是 $\\mu_2 \\approx \\frac{2+\\delta^2-2}{2} = \\frac{\\delta^2}{2}$。\n如果 RIP 成立且 $\\delta_2  0.1$，则特征值必须在 $[0.9, 1.1]$ 区间内。我们的特征值 $\\mu_1 \\approx 2$ 和 $\\mu_2 \\approx \\delta^2/2$ 显然在这个区间之外。因此，包含列 $a_1$ 和 $a_2$ 的矩阵违反了 2 阶 RIP。\n这个推论是正确的：如果 $A$ 满足 RIP，那么这样近似共线的列就不可能存在。\n此外，如果 RIP 成立，任何 $2 \\times 2$ 格拉姆矩阵的条件数都有界 $\\kappa(A_S^\\top A_S) \\le \\frac{1+\\delta_2}{1-\\delta_2}  \\frac{1.1}{0.9} \\approx 1.22$。这保证了所有含 2 项的最小二乘子问题都是良态的。这种良态性正是防止问题中所展示的失败模式（误差放大和错误剪枝）的原因。该陈述正确地将抽象的 RIP 条件与防止这种具体的实际失败联系起来。\n\n结论：**正确**。\n\n**E. 在此场景下，将 $A$ 的每一列缩放到单位 $\\ell_2$ 范数可以消除近似共线性问题，并稳定最小二乘步骤和剪枝。**\n\n近似共线性是由向量之间的夹角决定的几何属性。对向量进行归一化不会改变它们之间的夹角。\n原始列向量是 $a_1 = (1, 0, 0)^\\top$ 和 $a_2 = (1, \\delta, 0)^\\top$。\n它们的范数是 $\\|a_1\\|_2 = 1$ 和 $\\|a_2\\|_2 = \\sqrt{1+\\delta^2}$。\n它们之间夹角 $\\theta$ 的余弦是 $\\cos(\\theta) = \\frac{a_1^\\top a_2}{\\|a_1\\|_2 \\|a_2\\|_2} = \\frac{1}{1 \\cdot \\sqrt{1+\\delta^2}} = \\frac{1}{\\sqrt{1+\\delta^2}}$。\n对于小的 $\\delta$，这个值非常接近 1，表明向量几乎是平行的（共线的）。\n设归一化后的列为 $a_1' = a_1/\\|a_1\\|_2 = a_1$ 和 $a_2' = a_2/\\|a_2\\|_2$。内积为 $a_1'^\\top a_2' = \\cos(\\theta) = 1/\\sqrt{1+\\delta^2}$，这个值仍然接近 1。\n归一化列的格拉姆矩阵将是 $G' = \\begin{pmatrix} 1  \\cos(\\theta) \\\\ \\cos(\\theta)  1 \\end{pmatrix}$。它的行列式是 $1 - \\cos^2(\\theta) = 1 - \\frac{1}{1+\\delta^2} = \\frac{\\delta^2}{1+\\delta^2}$。对于小的 $\\delta$，这仍然是一个非常小的数，因此格拉姆矩阵仍然是病态的。列归一化不能解决由近似共线性引起的病态问题。\n\n结论：**不正确**。",
            "answer": "$$\\boxed{ACD}$$"
        }
    ]
}