{
    "hands_on_practices": [
        {
            "introduction": "硬阈值追踪算法中的“追踪”本质上是一种基于梯度的搜索。本练习通过计算梯度的利普希茨常数，深入探讨了这种搜索的稳定性 。理解这个常数是选择“安全”步长、确保算法稳步收敛而不发散的关键。",
            "id": "3450360",
            "problem": "考虑压缩感知中的最小二乘目标函数 $f(x) = \\frac{1}{2}\\|A x - y\\|_{2}^{2}$，其中 $A \\in \\mathbb{R}^{3 \\times 2}$ 且 $y \\in \\mathbb{R}^{3}$。令传感矩阵为\n$$\nA = \\begin{pmatrix}\n1  1 \\\\\n0  1 \\\\\n1  0\n\\end{pmatrix}.\n$$\n从梯度利普希茨常数的定义出发，计算使梯度 $\\nabla f(x)$ 对所有 $x, z \\in \\mathbb{R}^{2}$ 满足不等式 $\\|\\nabla f(x) - \\nabla f(z)\\|_{2} \\leq L \\|x - z\\|_{2}$ 的最小常数 $L$。然后，解释该常数在硬阈值追踪（Hard Thresholding Pursuit, HTP）算法中选择安全梯度步长的作用。其中 HTP 表示硬阈值追踪。给出 $L$ 的精确值作为最终答案。无需四舍五入，也无需单位。",
            "solution": "我们从梯度利普希茨常数的定义开始。如果一个连续可微函数 $f$ 的梯度是 $L$-利普希茨连续的，那么\n$$\n\\|\\nabla f(x) - \\nabla f(z)\\|_{2} \\leq L \\|x - z\\|_{2} \\quad \\text{对所有 } x, z.\n$$\n对于二次函数 $f(x) = \\frac{1}{2}\\|A x - y\\|_{2}^{2}$，其梯度为\n$$\n\\nabla f(x) = A^{\\top}(A x - y).\n$$\n因此，对于任意 $x, z \\in \\mathbb{R}^{2}$，\n$$\n\\nabla f(x) - \\nabla f(z) = A^{\\top}A(x - z).\n$$\n由此可知，最小的允许值 $L$ 是 $A^{\\top}A$ 在欧几里得范数下的算子范数，即\n$$\nL = \\|A^{\\top}A\\|_{2}.\n$$\n由于 $A^{\\top}A$ 是对称半正定矩阵，其算子范数等于其最大特征值。此外，根据奇异值分解，有 $\\|A^{\\top}A\\|_{2} = \\|A\\|_{2}^{2}$。\n\n我们现在显式地计算 $A^{\\top}A$。给定\n$$\nA = \\begin{pmatrix}\n1  1 \\\\\n0  1 \\\\\n1  0\n\\end{pmatrix},\n$$\n我们得到\n$$\nA^{\\top}A = \n\\begin{pmatrix}\n1  0  1 \\\\\n1  1  0\n\\end{pmatrix}\n\\begin{pmatrix}\n1  1 \\\\\n0  1 \\\\\n1  0\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2  1 \\\\\n1  2\n\\end{pmatrix}.\n$$\n$2 \\times 2$ 矩阵 $\\begin{pmatrix}2  1 \\\\ 1  2\\end{pmatrix}$ 的特征值可以通过求解\n$$\n\\det\\!\\left(\\begin{pmatrix}2  1 \\\\ 1  2\\end{pmatrix} - \\lambda I\\right) = 0,\n$$\n得到，即\n$$\n\\det\\!\\begin{pmatrix}2 - \\lambda  1 \\\\ 1  2 - \\lambda\\end{pmatrix}\n= (2 - \\lambda)^{2} - 1 = \\lambda^{2} - 4\\lambda + 3 = 0.\n$$\n方程的根为 $\\lambda = 1$ 和 $\\lambda = 3$。因此，\n$$\n\\|A^{\\top}A\\|_{2} = \\lambda_{\\max}(A^{\\top}A) = 3,\n$$\n所以\n$$\nL = \\|A^{\\top}A\\|_{2} = \\|A\\|_{2}^{2} = 3.\n$$\n\n现在我们解释 $L$ 在硬阈值追踪（HTP）中选择安全梯度步长的作用。在 HTP 中，我们首先执行一个中间梯度步\n$$\nx^{t + \\frac{1}{2}} = x^{t} - \\mu \\nabla f(x^{t}) = x^{t} - \\mu A^{\\top}(A x^{t} - y),\n$$\n然后进行硬阈值操作以强制实现 $k$-稀疏性，并在所选的支撑集上进行受限最小二乘优化。常数 $L$ 控制了 $f$ 的平滑度，根据具有 $L$-利普希茨梯度的函数的下降引理，\n$$\nf\\!\\left(x - \\mu \\nabla f(x)\\right) \\leq f(x) - \\left(\\mu - \\frac{L \\mu^{2}}{2}\\right)\\|\\nabla f(x)\\|_{2}^{2},\n$$\n只要 $0  \\mu \\leq \\frac{2}{L}$，该不等式就能保证 $f$ 的单调递减。在 HTP 和迭代硬阈值（Iterative Hard Thresholding）算法中，一个普遍采用的保守选择是\n$$\n\\mu \\leq \\frac{1}{L} = \\frac{1}{\\|A\\|_{2}^{2}},\n$$\n这确保了二次代理函数在 $x$ 处是 $f$ 的一个上界，并在阈值处理和支撑集优化之前产生一个安全的步长。对于给定的矩阵，安全的一般性选择是 $\\mu \\leq \\frac{1}{3}$，其中规范选择是 $\\mu = \\frac{1}{3}$。",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "“硬阈值”步骤看似直观：只保留最大的 $k$ 个系数。然而，实际操作中会遇到一些微妙之处，特别是当多个系数的绝对值相同时 。本练习探讨了硬阈值算子的非唯一性，以及建立确定性“平局打破”规则对获得可复现结果的重要性。",
            "id": "3450389",
            "problem": "在压缩感知和稀疏优化中，$k$阶硬阈值算子（记为 $H_{k}$）将一个向量 $v \\in \\mathbb{R}^{n}$ 映射到一个向量，其支撑集是对应于 $v$ 中 $k$ 个最大幅值分量的任意索引子集，而所有其他分量均被置为零。当在选择边界上出现幅值相等的情况时，若无明确的平局打破规则，$H_{k}$ 可能是集值的。请从以下形式化定义出发：$H_{k}(v)$ 保留 $v$ 在一个大小为 $|S|=k$ 的索引集 $S \\subset \\{1,\\dots,n\\}$ 上的分量，该索引集满足对于所有 $i \\in S$ 和 $j \\notin S$，都有 $|v_{i}| \\geq |v_{j}|$，并对所有 $j \\notin S$，将 $v_{j}$ 置为零。\n\n考虑给定向量 $v \\in \\mathbb{R}^{8}$\n$$\nv = (5,\\,-5,\\,5,\\,3,\\,-3,\\,3,\\,-3,\\,1),\n$$\n并取 $k=4$。请从第一性原理出发，仅使用上述定义和绝对值的排序，完成以下任务：\n- 通过确定幅值和选择边界的位置，解释为何在没有平局打破规则的情况下 $H_{4}(v)$ 是集值的。\n- 通过枚举或计算与定义一致的容许支撑集，推导在所有可能的平局打破方式下，$H_{4}(v)$ 的不同输出的数量 $N$。\n- 提出一个有原则的、确定性的、仅基于索引排序的平局打破规则（例如，在幅值相等的候选项中按字典序选择最小索引），并在此规则下指明唯一的 $H_{4}(v)$ 结果，以验证其与定义的一致性。\n\n作为你的最终答案，请提供 $N$ 的精确整数值。无需四舍五入，也无需单位。",
            "solution": "该问题要求对特定向量 $v \\in \\mathbb{R}^{n}$（其中 $n=8$）和稀疏度 $k=4$ 的硬阈值算子 $H_{k}$ 进行分析。算子 $H_{k}(v)$ 通过保留 $v$ 中绝对值最大的 $k$ 个分量，并将其余所有分量置为零，来生成一个向量。形式上，$H_{k}(v)$ 的支撑集是一个大小为 $|S|=k$ 的索引集 $S \\subset \\{1,\\dots,n\\}$，使得对于任意 $i \\in S$ 和 $j \\notin S$，条件 $|v_{i}| \\geq |v_{j}|$ 均成立。\n\n给定向量为\n$$\nv = (5,\\,-5,\\,5,\\,3,\\,-3,\\,3,\\,-3,\\,1) \\in \\mathbb{R}^{8}\n$$\n稀疏度为 $k=4$。\n\n首先，我们计算 $v$ 的各分量的幅值：\n$$\n|v| = (|5|, |-5|, |5|, |3|, |-3|, |3|, |-3|, |1|) = (5, 5, 5, 3, 3, 3, 3, 1)\n$$\n为了确定 $k=4$ 个最大的幅值，我们可以将这些值按降序排列：\n$$\n5, 5, 5, 3, 3, 3, 3, 1\n$$\n对于 $k=4$，第 $k$ 大的幅值是此排序列表中的第四个值，即 $3$。我们称此阈值幅值为 $\\mu_4 = 3$。\n\n$H_{k}(v)$ 的定义要求我们选择一个大小为 $|S|=4$ 的支撑集 $S$。任何包含在 $S$ 中的索引 $i$ 都必须满足对所有不在 $S$ 中的索引 $j$，有 $|v_i| \\geq |v_j|$。这等价于说，所选集合中元素的最小幅值必须大于或等于所选集合外元素的最大幅值。\n\n我们根据对应分量的幅值将 $v$ 的索引分组：\n-   幅值为 $5$ 的索引：$I_5 = \\{1, 2, 3\\}$。共有 $3$ 个这样的索引。\n-   幅值为 $3$ 的索引：$I_3 = \\{4, 5, 6, 7\\}$。共有 $4$ 个这样的索引。\n-   幅值为 $1$ 的索引：$I_1 = \\{8\\}$。只有 $1$ 个这样的索引。\n\n为构建大小为 $k=4$ 的支撑集 $S$，我们必须遵循一个基于阈值 $\\mu_4=3$ 的清晰程序：\n1.  所有对应于幅值严格大于 $\\mu_4=3$ 的索引都必须包含在 $S$ 中。在本例中，这适用于 $I_5$ 中的索引，其分量的幅值为 $5$。因此，$\\{1, 2, 3\\} \\subset S$。我们现在已经为我们的支撑集选择了 $3$ 个索引。\n2.  我们需要再选择 $k-3 = 4-3=1$ 个索引来完成支撑集 $S$。\n3.  这个最后位置的候选项必须从其分量幅值等于阈值 $\\mu_4=3$ 的索引集合中选择。这个集合是 $I_3 = \\{4, 5, 6, 7\\}$。\n\n选择边界位于幅值 $3$ 处。因为有三个幅值为 $5$ 的分量（必须保留）和四个幅值为 $3$ 的分量，我们必须从这四个幅值为 $3$ 的分量中选择一个，以补全 $k=4$ 个最大幅值分量的集合。这个选择并非由只陈述了幅值条件的定义所唯一确定。这正是 $H_{4}(v)$ 是集值的原因。我们可以选择将 $I_3$ 中的四个索引中的哪一个包含在支撑集 $S$ 中。\n\n为了找到不同输出的数量 $N$，我们需要计算可以形成的有效支撑集的数量。如前所述，$S$ 的前三个元素必须是 $\\{1, 2, 3\\}$。我们需要从幅值相等的候选项集合 $I_3 = \\{4, 5, 6, 7\\}$ 中选择 $1$ 个元素。从一个包含 $4$ 个索引的集合中选择 $1$ 个索引的方法数由二项式系数给出：\n$$\nN_{S} = \\binom{4}{1} = \\frac{4!}{1!(4-1)!} = 4\n$$\n这给出了 $4$ 个可能的支撑集：\n-   $S_1 = \\{1, 2, 3, 4\\}$\n-   $S_2 = \\{1, 2, 3, 5\\}$\n-   $S_3 = \\{1, 2, 3, 6\\}$\n-   $S_4 = \\{1, 2, 3, 7\\}$\n\n每个支撑集都会产生一个不同的输出向量，因为在从 $I_3$ 中选择的索引处，$v$ 的值并不完全相同，并且它们的位置也不同。我们列出结果向量：\n-   对于 $S_1 = \\{1, 2, 3, 4\\}$，输出是 $(5, -5, 5, 3, 0, 0, 0, 0)$。\n-   对于 $S_2 = \\{1, 2, 3, 5\\}$，输出是 $(5, -5, 5, 0, -3, 0, 0, 0)$。\n-   对于 $S_3 = \\{1, 2, 3, 6\\}$，输出是 $(5, -5, 5, 0, 0, 3, 0, 0)$。\n-   对于 $S_4 = \\{1, 2, 3, 7\\}$，输出是 $(5, -5, 5, 0, 0, 0, -3, 0)$。\n这四个向量是不同的。因此，$H_{4}(v)$ 的不同输出数量为 $N=4$。\n\n最后，我们提出一个有原则的、确定性的平局打破规则，并确定唯一的输出。一个标准的规则是字典序（最小索引）选择：当在选择边界上出现幅值相等时，优先选择索引最小的候选项。\n-   幅值相等的候选项是 $I_3 = \\{4, 5, 6, 7\\}$ 中的索引。\n-   根据最小索引规则，我们必须选择值最小的索引，即 $4$。\n-   这个规则使得最后一个支撑集成员的选择是唯一的。得到的支撑集是 $S = \\{1, 2, 3, 4\\}$。\n-   在此平局打破规则下，$H_{4}(v)$ 的唯一输出是通过保留 $v$ 在索引 $1, 2, 3, 4$ 上的分量，并将其余分量置为零来获得的：\n$$\nH_4(v) = (v_1, v_2, v_3, v_4, 0, 0, 0, 0) = (5, -5, 5, 3, 0, 0, 0, 0)\n$$\n这个结果与 $H_k$ 的定义一致。支撑集是 $S=\\{1,2,3,4\\}$，其大小为 $|S|=4$。对于任何 $i \\in S$，最小幅值是 $|v_4|=3$。对于任何 $j \\notin S = \\{5,6,7,8\\}$，最大幅值是 $|v_5|=|v_6|=|v_7|=3$。条件 $|v_i| \\geq |v_j|$ 对所有 $i \\in S, j \\notin S$ 都成立，因为 $3 \\geq 3$。\n\n不同输出的数量 $N$ 是从四个幅值相等的候选项中选择一个索引的方法数。因此，$N=4$。",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "一个算法的实用性在很大程度上取决于其计算效率。最后的练习将我们的关注点从单个步骤的机制转移到整个HTP迭代的总体成本上 。通过分析稠密和结构化传感矩阵下的计算复杂度，您将深入了解HTP在何种情况下是计算可行的，以及快速变换如何显著加速该算法。",
            "id": "3450349",
            "problem": "考虑线性测量模型 $y = A x^{\\star} + w$，其中 $A \\in \\mathbb{R}^{m \\times n}$，$x^{\\star} \\in \\mathbb{R}^{n}$ 是 $k$-稀疏的，且 $w \\in \\mathbb{R}^{m}$。硬阈值追踪（HTP）算法在第 $t$ 次迭代时通过以下步骤寻求一个 $k$-稀疏估计 $x^{t}$：计算残差 $r^{t} = y - A x^{t}$，形成梯度 $g^{t} = A^{\\top} r^{t}$，构造一个代理 $p^{t} = x^{t} + g^{t}$，选择支撑集 $S^{t+1}$，其由 $|p^{t}|$ 中 $k$ 个最大分量的索引给出，并通过求解 $\\min_{z \\in \\mathbb{R}^{k}} \\| y - A_{S^{t+1}} z \\|_{2}^{2}$ 来执行约束最小二乘更新，其中 $A_{S^{t+1}} \\in \\mathbb{R}^{m \\times k}$ 收集了 $A$ 中由 $S^{t+1}$ 索引的列，并设置 $(x^{t+1})_{S^{t+1}} = z$，$(x^{t+1})_{(S^{t+1})^{c}} = 0$。假设 $x^{t}$ 在每次迭代中都是 $k$-稀疏的，并且算术成本遵循标准的稠密线性代数模型：一个 $m \\times n$ 的稠密矩阵乘以一个稠密向量的成本为 $\\Theta(m n)$ 次运算，将 $A$ 乘以一个 $k$-稀疏向量的成本为 $\\Theta(m k)$ 次运算，使用部分选择法从一个 $n$-维向量中选出前 $k$ 个条目的成本为 $\\Theta(n)$ 次运算，以及通过数值稳定方法（例如 $QR$）对一个 $m \\times k$ 矩阵进行因式分解以求解最小二乘问题的成本为 $\\Theta(m k^{2})$ 次运算，随后进行三角求解还需额外的 $\\Theta(k^{2})$ 次运算。\n\n基于这些基础和 HTP 的迭代结构，推导在以下两种情况下，作为 $m$、$n$ 和 $k$ 的函数，其逐次迭代的渐近计算复杂度（用大$\\mathcal{O}$表示法）：\n1. $A$ 是一个没有可利用结构的稠密矩阵。\n2. $A$ 表示一个支持快速乘法的欠采样酉变换（例如，部分傅里叶或哈达玛变换），因此对于任何 $v \\in \\mathbb{R}^{n}$，$A v$ 和 $A^{\\top} v$ 都可以在 $\\mathcal{O}(n \\log_{2}(n))$ 时间内计算，而对 $A_{S}$ 的受限最小二乘则使用标准的稠密方法执行。\n\n在每种情况下，汇总一次完整 HTP 迭代中的主要成本，通过舍弃不影响主导复杂度的低阶项进行简化，并将两种情况的最终逐次迭代复杂度表示为大$\\mathcal{O}$表达式。你的最终答案必须由这两个大$\\mathcal{O}$表达式组成，并使用 LaTeX 的 $\\mathrm{pmatrix}$ 环境排列成一个单行矩阵。不需要四舍五入，也不涉及物理单位。",
            "solution": "任务是推导在两种不同测量矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的假设下，硬阈值追踪（HTP）算法的逐次迭代计算复杂度。分析将通过将单次 HTP 迭代分解为其构成步骤，并将其渐近成本（以维度 $m$、$n$ 和稀疏度 $k$ 的函数形式，用大$\\mathcal{O}$表示法表示）相加来进行。\n\nHTP 迭代通过以下主要计算步骤从估计 $x^t$ 进行到 $x^{t+1}$：\n1.  计算残差：$r^{t} = y - A x^{t}$\n2.  形成梯度等效项：$g^{t} = A^{\\top} r^{t}$\n3.  构造代理信号：$p^{t} = x^{t} + g^{t}$\n4.  识别新支撑集：$S^{t+1}$ = $p^{t}$ 中 $k$ 个最大幅值分量的索引\n5.  求解约束最小二乘问题以进行更新：$(x^{t+1})_{S^{t+1}} = \\arg\\min_{z \\in \\mathbb{R}^{k}} \\| y - A_{S^{t+1}} z \\|_{2}^{2}$\n\n我们针对两种指定情况分析每个步骤的计算成本。\n\n**情况1：$A$ 是一个稠密矩阵**\n\n在这种情况下，$A$ 是一个没有特殊结构的通用 $m \\times n$ 稠密矩阵。我们使用提供的标准计算成本。\n\n步骤1：计算残差 $r^{t} = y - A x^{t}$。\n向量 $x^{t}$ 是 $k$-稀疏的。一个稠密的 $m \\times n$ 矩阵 $A$ 与一个 $k$-稀疏向量 $x^{t}$ 的乘积可以通过对 $A$ 中与 $x^{t}$ 非零项对应的 $k$ 个列进行加权求和来计算，权重为这些非零项。此操作的成本为 $\\mathcal{O}(m k)$。随后的向量减法 $y - (A x^{t})$ 的成本为 $\\mathcal{O}(m)$。因此，此步骤的总成本为 $\\mathcal{O}(m k + m) = \\mathcal{O}(m k)$，因为 $k \\ge 1$。\n\n步骤2：形成梯度 $g^{t} = A^{\\top} r^{t}$。\n矩阵 $A^{\\top}$ 是一个稠密的 $n \\times m$ 矩阵，残差 $r^{t}$ 是一个稠密的 $m \\times 1$ 向量。这是一个标准的稠密矩阵-向量乘法，成本为 $\\mathcal{O}(n m)$。\n\n步骤3：构造代理 $p^{t} = x^{t} + g^{t}$。\n这涉及将一个 $k$-稀疏向量 $x^{t}$ 与一个稠密向量 $g^{t}$ 相加，两者的大小均为 $n$。此操作需要遍历稠密向量，成本为 $\\mathcal{O}(n)$。\n\n步骤4：识别新支撑集 $S^{t+1}$。\n这需要找到 $n$ 维向量 $p^{t}$ 中绝对值最大的 $k$ 个分量的索引。使用部分选择算法（例如，introselect），可以在线性时间内完成。成本为 $\\mathcal{O}(n)$。\n\n步骤5：执行约束最小二乘更新。\n此步骤涉及求解最小二乘问题 $\\min_{z} \\| y - A_{S^{t+1}} z \\|_{2}^{2}$。首先，必须通过提取 $A$ 中由 $S^{t+1}$ 索引的 $k$ 个列来形成 $m \\times k$ 子矩阵 $A_{S^{t+1}}$。此操作的成本为 $\\mathcal{O}(m k)$。然后，使用 QR 分解求解这个 $m \\times k$ 系统的最小二乘问题，其成本为 $\\mathcal{O}(m k^{2})$。因此，此步骤的总成本为 $\\mathcal{O}(m k + m k^{2}) = \\mathcal{O}(m k^{2})$，因为 $k \\ge 1$。\n\n情况1的总复杂度：\n逐次迭代的总复杂度是这些步骤成本的总和：\n$$ \\mathcal{O}(m k) + \\mathcal{O}(n m) + \\mathcal{O}(n) + \\mathcal{O}(n) + \\mathcal{O}(m k^{2}) = \\mathcal{O}(n m + m k^{2} + m k + n) $$\n在典型的高维设置中，即 $k \\ll m, n$，$\\mathcal{O}(mk)$ 和 $\\mathcal{O}(n)$ 项分别被 $\\mathcal{O}(mk^2)$ (因为 $k \\geq 1$) 和 $\\mathcal{O}(nm)$ (因为 $m \\geq 1$) 所主导。主导项是 $\\mathcal{O}(nm)$ 和 $\\mathcal{O}(mk^2)$。由于没有指定 $n$ 和 $k^2$ 之间的渐近关系，因此必须保留这两项。最终的复杂度为 $\\mathcal{O}(m n + m k^{2})$。\n\n**情况2：$A$ 是一个具有快速乘法运算的欠采样酉变换**\n\n在这种情况下，应用 $A$ 或 $A^{\\top}$ 的成本为 $\\mathcal{O}(n \\log_{2}(n))$。最小二乘子问题仍然使用稠密方法求解。\n\n步骤1：计算残差 $r^{t} = y - A x^{t}$。\n将算子 $A$ 应用于任何向量的成本给定为 $\\mathcal{O}(n \\log_{2}(n))$。尽管 $x^{t}$ 是 $k$-稀疏的，但像 FFT 这样的快速变换通常不会为任意稀疏输入提供计算上的简化。因此，计算 $A x^{t}$ 的成本是 $\\mathcal{O}(n \\log_{2}(n))$。向量减法的成本为 $\\mathcal{O}(m)$，是次要项。总成本为 $\\mathcal{O}(n \\log_{2}(n))$。\n\n步骤2：形成梯度 $g^{t} = A^{\\top} r^{t}$。\n向量 $r^{t} \\in \\mathbb{R}^{m}$ 是稠密的。应用伴随算子 $A^{\\top}$ 的成本也给定为 $\\mathcal{O}(n \\log_{2}(n))$。\n\n步骤3：构造代理 $p^{t} = x^{t} + g^{t}$。\n与情况1相同，这是一个向量加法，成本为 $\\mathcal{O}(n)$。\n\n步骤4：识别新支撑集 $S^{t+1}$。\n与情况1相同，此操作的成本为 $\\mathcal{O}(n)$。\n\n步骤5：执行约束最小二乘更新。\n问题陈述该步骤使用“标准稠密方法”执行。这需要显式地构造 $m \\times k$ 矩阵 $A_{S^{t+1}}$。对于像欠采样傅里叶或哈达玛矩阵这样的结构化矩阵，任何元素 $A_{ij}$ 都可以在 $\\mathcal{O}(1)$ 时间内计算。因此，整个 $m \\times k$ 矩阵 $A_{S^{t+1}}$ 可以在 $\\mathcal{O}(m k)$ 时间内构造。随后，通过 QR 分解求解最小二乘问题的成本为 $\\mathcal{O}(m k^{2})$。此步骤的总成本为 $\\mathcal{O}(m k + m k^{2}) = \\mathcal{O}(m k^{2})$。\n\n情况2的总复杂度：\n逐次迭代的总复杂度是成本的总和：\n$$ \\mathcal{O}(n \\log_{2}(n)) + \\mathcal{O}(n \\log_{2}(n)) + \\mathcal{O}(n) + \\mathcal{O}(n) + \\mathcal{O}(m k^{2}) = \\mathcal{O}(n \\log_{2}(n) + m k^{2}) $$\n在这里，$\\mathcal{O}(n)$ 项被 $\\mathcal{O}(n \\log_{2}(n))$ 所主导。主导项来自快速变换和最小二乘求解。\n\n两种情况的最终逐次迭代复杂度为：\n1.  稠密 $A$：$\\mathcal{O}(m n + m k^{2})$\n2.  快速变换 $A$：$\\mathcal{O}(n \\log_{2}(n) + m k^{2})$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\mathcal{O}(m n + m k^{2})  \\mathcal{O}(n \\log_{2}(n) + m k^{2})\n\\end{pmatrix}\n}\n$$"
        }
    ]
}