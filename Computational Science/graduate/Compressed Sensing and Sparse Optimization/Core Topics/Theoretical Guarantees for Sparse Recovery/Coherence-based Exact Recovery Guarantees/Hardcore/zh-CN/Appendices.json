{
    "hands_on_practices": [
        {
            "introduction": "互相关性 $\\mu$ 是一个简单而强大的度量，用于预测稀疏恢复的成功率。这个练习  将指导您从精确恢复条件（ERC）出发，推导出最著名的基于互相关性的保证条件。通过分析其极限行为，您将更深入地理解稀疏度和字典几何性质之间的基本权衡。",
            "id": "3435250",
            "problem": "给定一个列向量单位范数化的实数矩阵，请分析基于经典互相关性的稀疏恢复精确恢复阈值，及其在互相关性趋于零时的极限行为。所有运算都在有限维实数线性代数的框架下进行。所有角度均以弧度为单位，不涉及物理单位。\n\n基础知识：\n- 列向量单位范数化的矩阵的互相关性定义为 $\\,\\mu(A) \\triangleq \\max_{i\\neq j}\\,|\\langle a_i,a_j\\rangle|\\,$，其中 $\\,a_i\\,$ 表示第 $\\,i\\,$ 列，$\\,\\langle\\cdot,\\cdot\\rangle\\,$ 是标准内积。\n- 列子矩阵 $\\,A_S\\,$ 的 Gram 矩阵为 $\\,G_S \\triangleq A_S^\\top A_S\\,$。\n- 来自稀疏优化的精确恢复条件 (ERC) 指出，通过 $\\ell_1$-最小化或正交匹配追踪算法唯一恢复任何 $\\,s\\,$稀疏向量的一个充分条件是\n$$\n\\max_{j\\notin S}\\,\\|A_S^+ a_j\\|_1  1,\n$$\n对于每个支撑集 $\\,S\\subset\\{1,\\dots,n\\}\\,$，其中 $\\,|S|=s\\,$，且 $\\,A_S^+ \\triangleq (A_S^\\top A_S)^{-1}A_S^\\top\\,$ 表示满列秩矩阵 $\\,A_S\\,$ 的 Moore–Penrose 伪逆。\n- 你可以使用经典的矩阵范数不等式（矩阵范数的次可乘性，向量范数与矩阵范数之间的关系）、用于求逆的 Neumann 级数界 $\\,\\|(I - E)^{-1}\\|\\leq 1/(1-\\|E\\|)\\,$ (当 $\\,\\|E\\|1\\,$) 以及 Gershgorin 圆盘定理来论证 $\\,G_S\\,$ 的可逆性。\n\n任务 A (推导)：仅从上述基础知识出发，推导出一个仅用 $\\,\\mu(A)\\,$ 表示的、保证对于所有大小为 $\\,s\\,$ 的支撑集都满足 ERC 的、仅依赖于相关性的充分阈值。然后分析极限 $\\,\\mu(A)\\to 0\\,$，证明该阈值可近似表示为\n$$\ns \\;\\approx\\; \\tfrac{1}{2}\\!\\left(1+\\tfrac{1}{\\mu(A)}\\right),\n$$\n其精确含义是，满足你的界所隐含的严格不等式的最大整数 $\\,s\\,$ 满足\n$$\n\\lim_{\\mu\\to 0^+}\\; \\mu \\cdot s(\\mu) \\;=\\; \\tfrac{1}{2},\\qquad\n\\lim_{\\mu\\to 0^+}\\; \\frac{s(\\mu)}{\\tfrac{1}{2}(1+\\tfrac{1}{\\mu})} \\;=\\; 1.\n$$\n你的推导必须从定义和已列出的经过充分检验的事实出发；不要引用任何以目标阈值为输入的结果。\n\n任务 B (数值示例)：考虑一个由 $\\,\\varepsilon\\,$ 参数化的显式字典族 $\\,A(\\varepsilon)\\in\\mathbb{R}^{n\\times n}\\,$，其中 $\\,n\\geq 2\\,$，定义如下。设 $\\,\\{e_1,\\dots,e_n\\}\\,$ 为 $\\,\\mathbb{R}^n\\,$ 的标准基。定义\n- $\\,a_1(\\varepsilon) \\triangleq e_1\\,$，\n- 对于每个 $\\,j\\in\\{2,\\dots,n\\}\\,$，$\\,a_j(\\varepsilon) \\triangleq \\varepsilon\\,e_1 + \\sqrt{1-\\varepsilon^2}\\,e_j\\,$，\n并将列向量 $\\,a_j(\\varepsilon)\\,$ 组合成矩阵 $\\,A(\\varepsilon)\\,$。证明对于每个 $\\,\\varepsilon\\in(0,1]\\,$，矩阵 $\\,A(\\varepsilon)\\,$ 的列向量都具有单位范数，并且\n$$\n\\mu\\big(A(\\varepsilon)\\big) \\;=\\; \\max\\{\\varepsilon,\\,\\varepsilon^2\\} \\;=\\; \\varepsilon.\n$$\n\n任务 C (程序规范)：实现一个程序，对每个测试用例 $\\,(\\varepsilon, n)\\,$（其中 $\\,n\\in\\mathbb{N}\\,$ 且 $\\,\\varepsilon\\in(0,1]\\,$）执行以下操作：\n- 按上文所述构造 $\\,A(\\varepsilon)\\in\\mathbb{R}^{n\\times n}\\,$ 并计算 $\\,\\mu\\big(A(\\varepsilon)\\big)\\,$。\n- 计算实数值的相关性阈值\n$$\ns_{\\mathrm{cont}}(\\mu) \\;\\triangleq\\; \\tfrac{1}{2}\\!\\left(1+\\tfrac{1}{\\mu}\\right),\n$$\n以及满足你的推导所隐含的严格不等式的最大整数，记为\n$$\ns_{\\mathrm{int}}(\\mu) \\;\\triangleq\\; \\left\\lceil s_{\\mathrm{cont}}(\\mu)\\right\\rceil - 1.\n$$\n- 报告缩放积 $\\,\\mu\\cdot s_{\\mathrm{int}}(\\mu)\\,$ 和相对偏差\n$$\n\\mathrm{rel\\_dev} \\;\\triangleq\\; \\frac{\\big|s_{\\mathrm{cont}}(\\mu)-s_{\\mathrm{int}}(\\mu)\\big|}{s_{\\mathrm{cont}}(\\mu)}.\n$$\n- (可选)通过穷举支撑集搜索，在 $\\,s_{\\mathrm{int}}(\\mu)\\,$ 处数值验证精确恢复条件：定义\n$$\nT_{A,s} \\;\\triangleq\\; \\max_{S\\subset\\{1,\\dots,n\\},\\,|S|=s}\\;\\max_{j\\notin S}\\; \\big\\|A_S^+\\,a_j\\big\\|_1.\n$$\n如果 $\\,s_{\\mathrm{int}}(\\mu)\\leq n-1\\,$，通过枚举精确计算 $\\,T_{A,s_{\\mathrm{int}}}\\,$ 并设置一个指示符\n$$\n\\mathrm{erc\\_ok} \\;=\\; \\begin{cases}\n1  \\text{若 } T_{A,s_{\\mathrm{int}}}  1,\\\\\n0  \\text{否则。}\n\\end{cases}\n$$\n如果 $\\,s_{\\mathrm{int}}(\\mu)  n-1\\,$，跳过验证并输出 $\\,\\mathrm{erc\\_ok}=-1\\,$。\n- 将所有浮点输出四舍五入到 $\\,6\\,$ 位小数。\n\n测试套件：\n- 所有用例均使用 $\\,n=8\\,$ 和以下 $\\,\\varepsilon\\,$ 值：\n  - $\\,\\varepsilon = 0.5\\,$，\n  - $\\,\\varepsilon = \\tfrac{1}{3}\\,$，\n  - $\\,\\varepsilon = 0.2\\,$，\n  - $\\,\\varepsilon = 0.15\\,$，\n  - $\\,\\varepsilon = 0.1\\,$，\n  - $\\,\\varepsilon = 0.05\\,$。\n对于每个用例，程序必须输出一个列表\n$$\n\\big[\\mu,\\, s_{\\mathrm{int}},\\, \\mu\\cdot s_{\\mathrm{int}},\\, \\mathrm{rel\\_dev},\\, \\mathrm{erc\\_ok}\\big],\n$$\n其中实数按要求四舍五入到 $\\,6\\,$ 位小数。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个由各用例列表组成的、用逗号分隔的列表，并用方括号括起来，例如\n$$\n\\big[\\,[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],\\;[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],\\;\\dots\\big].\n$$\n不应打印任何其他文本。",
            "solution": "该问题经核实具有科学依据，定义明确且客观。它是压缩感知和稀疏优化领域的标准练习，所有必要组件都已定义，任务集也清晰明了。\n\n### 任务 A：基于相关性的恢复阈值推导\n\n主要目标是根据互相关性 $\\mu(A)$ 推导出一个关于稀疏度 $s$ 的充分条件，以保证精确恢复条件 (ERC) 成立。ERC 由下式给出\n$$\n\\max_{S:|S|=s} \\max_{j\\notin S} \\|A_S^+ a_j\\|_1  1\n$$\n其中 $A$ 是一个列向量单位范数化的矩阵，$S$ 是一个大小为 $s$ 的支撑集，$a_j$ 是 $A$ 的第 $j$ 列，$A_S^+$ 是由索引在 $S$ 中的列构成的子矩阵 $A_S$ 的 Moore-Penrose 伪逆。我们已知 $A_S^+ = (A_S^\\top A_S)^{-1}A_S^\\top$。\n\n我们固定一个大小为 $|S|=s$ 的支撑集 $S$ 和一个索引 $j \\notin S$。我们需要对 $\\|A_S^+ a_j\\|_1$ 进行界定。\n令 $v_j = A_S^+ a_j = (A_S^\\top A_S)^{-1} (A_S^\\top a_j)$。\n令 $G_S = A_S^\\top A_S$ 为 $A_S$ 的 Gram 矩阵。这是一个 $s \\times s$ 矩阵。令 $c_j = A_S^\\top a_j$ 为一个 $s$ 维向量。则 $v_j = G_S^{-1} c_j$。\n\n使用标准的矩阵和向量范数不等式，我们有：\n$$\n\\|v_j\\|_1 = \\|G_S^{-1} c_j\\|_1 \\le \\|G_S^{-1}\\|_1 \\|c_j\\|_1\n$$\n我们需要对右侧的两项进行界定。\n\n1.  **界定 $\\|c_j\\|_1$**：向量 $c_j$ 的分量为 $(c_j)_i = \\langle a_i, a_j \\rangle$（对于每个 $i \\in S$）。互相关性 $\\mu(A)$ 定义为 $\\mu(A) \\triangleq \\max_{i\\neq k}\\,|\\langle a_i, a_k\\rangle|$。由于 $j \\notin S$，对于每个 $i \\in S$，都有 $i \\ne j$。因此，$|\\langle a_i, a_j \\rangle| \\le \\mu(A)$。\n    $c_j$ 的 $\\ell_1$-范数是其 $s$ 个分量绝对值之和：\n    $$\n    \\|c_j\\|_1 = \\sum_{i \\in S} |\\langle a_i, a_j \\rangle| \\le \\sum_{i \\in S} \\mu(A) = s \\mu(A)\n    $$\n\n2.  **界定 $\\|G_S^{-1}\\|_1$**：Gram 矩阵 $G_S$ 可以写成 $G_S = I + E$，其中 $I$ 是 $s \\times s$ 单位矩阵，$E$ 是一个包含非对角线内积的矩阵。$G_S$ 的对角线元素为 $(G_S)_{ii} = \\langle a_i, a_i \\rangle = 1$，因为所有列向量都是单位范数的。非对角线元素为 $(G_S)_{ik} = \\langle a_i, a_k \\rangle$（对于 $i, k \\in S, i \\ne k$）。\n    因此，$E$ 的对角线元素为零，其非对角线元素为 $(E)_{ik} = \\langle a_i, a_k \\rangle$，所以对于 $i \\ne k$，有 $|(E)_{ik}| \\le \\mu(A)$。\n\n    为了确保 $G_S$ 可逆并界定其逆矩阵，我们可以使用 Gershgorin 圆盘定理或 Neumann 级数。我们使用后者，这需要对 $E$ 的一个范数进行界定。矩阵 $\\ell_\\infty$-范数由最大绝对行和给出：\n    $$\n    \\|E\\|_\\infty = \\max_{i \\in S} \\sum_{k \\in S} |E_{ik}| = \\max_{i \\in S} \\sum_{k \\in S, k \\ne i} |\\langle a_i, a_k \\rangle| \\le \\max_{i \\in S} \\sum_{k \\in S, k \\ne i} \\mu(A) = (s-1)\\mu(A)\n    $$\n    如果 $\\|E\\|_\\infty  1$，即 $(s-1)\\mu(A)  1$，则矩阵 $G_S = I+E$ 是可逆的，并且我们可以界定其逆矩阵的范数：\n    $$\n    \\|G_S^{-1}\\|_\\infty \\le \\frac{1}{1 - \\|E\\|_\\infty} \\le \\frac{1}{1 - (s-1)\\mu(A)}\n    $$\n    由于 $G_S$ 是一个 Gram 矩阵，它是对称的。其逆矩阵 $G_S^{-1}$ 也是对称的。对于任何对称矩阵 $M$，有 $\\|M\\|_1 = \\|M\\|_\\infty$。因此，\n    $$\n    \\|G_S^{-1}\\|_1 = \\|G_S^{-1}\\|_\\infty \\le \\frac{1}{1 - (s-1)\\mu(A)}\n    $$\n\n综合这些界，我们得到：\n$$\n\\|A_S^+ a_j\\|_1 \\le \\|G_S^{-1}\\|_1 \\|c_j\\|_1 \\le \\frac{s \\mu(A)}{1 - (s-1)\\mu(A)}\n$$\n为了使 ERC 成立，我们要求这个上界严格小于 1：\n$$\n\\frac{s \\mu(A)}{1 - (s-1)\\mu(A)}  1\n$$\n这个不等式取决于分母为正，即我们已经施加的条件 $(s-1)\\mu(A)  1$。假设此条件成立，我们可以用分母乘以两边：\n$$\ns \\mu(A)  1 - (s-1)\\mu(A) \\implies s \\mu(A)  1 - s\\mu(A) + \\mu(A)\n$$\n整理各项得到：\n$$\n2s\\mu(A) - \\mu(A)  1 \\implies (2s-1)\\mu(A)  1\n$$\n假设 $\\mu(A)  0$，我们可以相除得到关于 $s$ 的条件：\n$$\n2s-1  \\frac{1}{\\mu(A)} \\implies 2s  1 + \\frac{1}{\\mu(A)} \\implies s  \\frac{1}{2}\\left(1 + \\frac{1}{\\mu(A)}\\right)\n$$\n这就是著名的基于相关性的稀疏精确恢复的充分条件。\n\n现在，我们分析当 $\\mu \\to 0^+$ 时的极限行为。令 $s(\\mu)$ 为满足严格不等式 $s  \\frac{1}{2}(1 + 1/\\mu)$ 的最大整数。这由 $s(\\mu) = \\lceil \\frac{1}{2}(1 + 1/\\mu) \\rceil - 1$ 给出。\n令 $f(\\mu) = \\frac{1}{2}(1 + 1/\\mu)$。根据向上取整函数的定义，我们有 $f(\\mu) \\le \\lceil f(\\mu) \\rceil  f(\\mu)+1$。减 1 得到 $f(\\mu)-1 \\le s(\\mu)  f(\\mu)$。\n$\\frac{1}{2}(1 + 1/\\mu) - 1 \\le s(\\mu)  \\frac{1}{2}(1 + 1/\\mu)$。\n$\\frac{1}{2\\mu} - \\frac{1}{2} \\le s(\\mu)  \\frac{1}{2\\mu} + \\frac{1}{2}$。\n\n1.  **$\\mu \\cdot s(\\mu)$ 的极限**：将不等式乘以 $\\mu  0$：\n    $$\n    \\mu\\left(\\frac{1}{2\\mu} - \\frac{1}{2}\\right) \\le \\mu \\cdot s(\\mu)  \\mu\\left(\\frac{1}{2\\mu} + \\frac{1}{2}\\right) \\implies \\frac{1}{2} - \\frac{\\mu}{2} \\le \\mu \\cdot s(\\mu)  \\frac{1}{2} + \\frac{\\mu}{2}\n    $$\n    当 $\\mu \\to 0^+$ 时，上界和下界都收敛于 $1/2$。根据夹逼定理，$\\lim_{\\mu\\to 0^+} \\mu \\cdot s(\\mu) = \\frac{1}{2}$。\n\n2.  **比例的极限**：将不等式 $f(\\mu)-1 \\le s(\\mu)  f(\\mu)$ 除以 $f(\\mu)$：\n    $$\n    \\frac{f(\\mu)-1}{f(\\mu)} \\le \\frac{s(\\mu)}{f(\\mu)}  \\frac{f(\\mu)}{f(\\mu)} \\implies 1 - \\frac{1}{f(\\mu)} \\le \\frac{s(\\mu)}{f(\\mu)}  1\n    $$\n    当 $\\mu \\to 0^+$ 时，$f(\\mu) = \\frac{1}{2}(1+1/\\mu) \\to \\infty$，所以 $1/f(\\mu) \\to 0$。下界收敛于 1。根据夹逼定理，$\\lim_{\\mu\\to 0^+} \\frac{s(\\mu)}{f(\\mu)} = 1$。\n\n### 任务 B：矩阵族 $A(\\varepsilon)$ 的分析\n\n给定 $A(\\varepsilon) \\in \\mathbb{R}^{n \\times n}$，其中 $n \\ge 2, \\varepsilon \\in (0,1]$，其列向量为 $a_1(\\varepsilon) = e_1$ 和 $a_j(\\varepsilon) = \\varepsilon e_1 + \\sqrt{1-\\varepsilon^2} e_j$（对于 $j \\ge 2$）。\n\n1.  **单位列范数**：\n    - 对于第 1 列：$\\|a_1\\|^2 = \\|e_1\\|^2 = 1^2 = 1$。\n    - 对于第 $j \\in \\{2, \\dots, n\\}$ 列：向量 $e_1$ 和 $e_j$ 是正交的。根据勾股定理：\n      $\\|a_j\\|^2 = \\|\\varepsilon e_1 + \\sqrt{1-\\varepsilon^2} e_j\\|^2 = (\\varepsilon)^2 + (\\sqrt{1-\\varepsilon^2})^2 = \\varepsilon^2 + 1 - \\varepsilon^2 = 1$。\n    所有列向量都具有单位 $\\ell_2$-范数。\n\n2.  **互相关性**：我们计算不同列之间的内积。\n    - 对于 $j \\in \\{2, \\dots, n\\}$：\n      $\\langle a_1, a_j \\rangle = \\langle e_1, \\varepsilon e_1 + \\sqrt{1-\\varepsilon^2} e_j \\rangle = \\varepsilon \\langle e_1, e_1 \\rangle + \\sqrt{1-\\varepsilon^2} \\langle e_1, e_j \\rangle = \\varepsilon \\cdot 1 + 0 = \\varepsilon$。\n    - 对于 $i,j \\in \\{2, \\dots, n\\}$ 且 $i \\ne j$：\n      $\\langle a_i, a_j \\rangle = \\langle \\varepsilon e_1 + \\sqrt{1-\\varepsilon^2} e_i, \\varepsilon e_1 + \\sqrt{1-\\varepsilon^2} e_j \\rangle$。\n      利用 $\\{e_k\\}$ 的正交性展开此式：\n      $\\langle a_i, a_j \\rangle = \\varepsilon^2 \\langle e_1, e_1 \\rangle + (1-\\varepsilon^2) \\langle e_i, e_j \\rangle = \\varepsilon^2 \\cdot 1 + (1-\\varepsilon^2) \\cdot 0 = \\varepsilon^2$。\n    非对角线内积的绝对值集合为 $\\{\\varepsilon, \\varepsilon^2\\}$。互相关性是这些值的最大值：\n    $\\mu(A(\\varepsilon)) = \\max \\{|\\varepsilon|, |\\varepsilon^2|\\}$。由于 $\\varepsilon \\in (0,1]$，我们有 $\\varepsilon  0$ 和 $\\varepsilon^2 \\le \\varepsilon$。因此，$\\mu(A(\\varepsilon)) = \\varepsilon$。\n\n### 任务 C：程序规范逻辑\n\n程序将为 $n=8$ 且 $\\varepsilon$ 取 $(0,1]$ 中几个值的测试套件实现指定的计算。对于每个测试用例 $(\\varepsilon, n)$：\n1.  根据任务 B 的推导，互相关性计算为 $\\mu = \\varepsilon$。\n2.  计算连续和整数稀疏度阈值：\n    $s_{\\mathrm{cont}}(\\mu) = \\frac{1}{2}(1+1/\\mu)$ 和 $s_{\\mathrm{int}}(\\mu) = \\lceil s_{\\mathrm{cont}}(\\mu)\\rceil - 1$。\n3.  计算缩放积 $\\mu \\cdot s_{\\mathrm{int}}(\\mu)$ 和相对偏差 $\\mathrm{rel\\_dev} = |s_{\\mathrm{cont}}(\\mu)-s_{\\mathrm{int}}(\\mu)|/s_{\\mathrm{cont}}(\\mu)$。\n4.  对稀疏度 $s = s_{\\mathrm{int}}(\\mu)$ 进行 ERC 的数值验证。\n    - 如果 $s_{\\mathrm{int}}(\\mu)  n-1$，则无法进行验证，$\\mathrm{erc\\_ok}$ 设置为 $-1$。\n    - 否则，构造大小为 $n \\times n$ 的矩阵 $A(\\varepsilon)$。然后程序使用 `itertools.combinations` 穷举遍历所有大小为 $s_{\\mathrm{int}}(\\mu)$ 的支撑集 $S \\subset \\{1, \\dots, n\\}$。\n    - 对于每个支撑集 $S$，程序计算所有 $j \\notin S$ 的 $\\|A_S^+ a_j\\|_1$ 的最大值。伪逆 $A_S^+$ 使用 `numpy.linalg.pinv` 计算。\n    - 确定所有支撑集 $S$ 的最大值，记为 $T_{A,s_{\\mathrm{int}}}$。\n    - 如果 $T_{A,s_{\\mathrm{int}}}  1$，指示符 $\\mathrm{erc\\_ok}$ 设置为 $1$，否则为 $0$。\n5.  最后，为该测试用例生成一个包含 $[\\mu, s_{\\mathrm{int}}, \\mu \\cdot s_{\\mathrm{int}}, \\mathrm{rel\\_dev}, \\mathrm{erc\\_ok}]$ 的列表，其中所有浮点值都四舍五入到 6 位小数。所有测试用例的结果汇总成一个列表的列表，作为最终输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy  # Per library specification, though not strictly used.\nimport math\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Solves the problem by analyzing a parametrized matrix family A(eps)\n    and verifying the derived coherence-based exact recovery threshold.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (epsilon, n)\n        (0.5, 8),\n        (1/3, 8),\n        (0.2, 8),\n        (0.15, 8),\n        (0.1, 8),\n        (0.05, 8),\n    ]\n\n    all_results = []\n    for eps, n in test_cases:\n        # Per Task B, mu(A(eps)) = eps for eps in (0, 1].\n        mu = eps\n\n        # Compute coherence-based thresholds\n        s_cont = 0.5 * (1.0 + 1.0 / mu)\n        s_int = math.ceil(s_cont) - 1\n\n        # Compute derived quantities\n        mu_s_int = mu * s_int\n        if s_cont > 0:\n            rel_dev = abs(s_cont - s_int) / s_cont\n        else:\n            rel_dev = 0.0\n\n        # Numerically verify the Exact Recovery Condition (ERC)\n        erc_ok = -1\n        if s_int > n - 1:\n            erc_ok = -1\n        else:\n            # Construct the matrix A(eps)\n            A = np.zeros((n, n), dtype=float)\n            e1 = np.zeros(n, dtype=float)\n            e1[0] = 1.0\n            A[:, 0] = e1\n            for j in range(1, n):\n                ej = np.zeros(n, dtype=float)\n                ej[j] = 1.0\n                A[:, j] = eps * e1 + math.sqrt(1 - eps**2) * ej\n\n            # Exhaustively check all supports of size s_int\n            max_erc_val = 0.0\n            all_indices = set(range(n))\n            \n            # The number of combinations can be large, but for n=8 and s=7 it's feasible.\n            s = int(s_int)\n            # s=0 is trivial, ERC holds if defined. Let's assume s >= 1.\n            if s >= 1:\n                for s_indices in combinations(range(n), s):\n                    S = list(s_indices)\n                    J = list(all_indices - set(S))\n                    \n                    A_S = A[:, S]\n                    \n                    # Compute the Moore-Penrose pseudoinverse\n                    A_S_plus = np.linalg.pinv(A_S)\n                    \n                    for j in J:\n                        a_j = A[:, j]\n                        \n                        # Calculate the l1-norm of the projection\n                        norm_val = np.linalg.norm(A_S_plus @ a_j, ord=1)\n                        \n                        if norm_val > max_erc_val:\n                            max_erc_val = norm_val\n            \n            # The ERC is T_{A,s}  1\n            erc_ok = 1 if max_erc_val  1.0 else 0\n\n        # Assemble the list of results for this case, with rounding\n        case_result = [\n            round(mu, 6),\n            s_int,\n            round(mu_s_int, 6),\n            round(rel_dev, 6),\n            erc_ok\n        ]\n        all_results.append(case_result)\n\n    # Format the final output string as a list of lists\n    # e.g., [[val1, val2], [val3, val4]]\n    # Using str() on a list of lists produces the desired format with spaces.\n    # The problem asks for comma-separated list of lists, without specifying space behavior.\n    # Using a join of stringified lists is safer.\n    final_output_str = f\"[{','.join([str(res) for res in all_results])}]\"\n\n    # Final print statement in the exact required format.\n    print(final_output_str.replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "在建立了互相关性的重要性之后，下一个练习  旨在揭示其局限性。您将构建两个具有完全相同互相关性的字典，但会观察到它们在正交匹配追踪（OMP）算法下表现出不同的恢复性能。这个动手实践突显了更精细的几何属性，例如子矩阵的谱特性，对于全面理解和预测恢复行为至关重要。",
            "id": "3435245",
            "problem": "构建两个显式的实数字典 $A \\in \\mathbb{R}^{m \\times n}$ 和 $B \\in \\mathbb{R}^{m \\times n}$，它们具有相同的互相关性，但精心选择的子格拉姆矩阵 (sub-Gram matrices) 的谱特性不同。然后，针对几个稀疏信号，通过经验比较正交匹配追踪 (OMP) 的精确恢复能力。完全在实数上使用精确算术进行运算，不涉及物理单位。无需引入角度。任务是从第一性原理出发，推导并实现以下流程：\n\n1. 定义和要使用的核心对象。\n   - 对于列为单位范数的字典 $D$，其互相关性 $\\mu(D)$ 定义为 $\\mu(D) \\triangleq \\max_{i \\neq j} \\left| \\langle d_i, d_j \\rangle \\right|$，其中 $d_i$ 表示 $D$ 的第 $i$ 列。对于非单位范数的列，格拉姆矩阵中的内积必须在按列归一化后计算。\n   - 由有限集 $T \\subset \\{1,\\dots,n\\}$ 索引的列子集的子格拉姆矩阵 (sub-Gram matrix) 为 $G_T(D) \\triangleq D_T^\\top D_T$，其中 $D_T$ 是由索引在 $T$ 中的列构成的子矩阵。\n   - 正交匹配追踪 (OMP) 是一种用于稀疏恢复的贪心算法。给定一个字典 $D$、一个测量向量 $y$ 和一个目标稀疏度 $k$，OMP 迭代执行以下步骤：\n     - 选择与当前残差的绝对相关性最大的索引。\n     - 扩充活动集。\n     - 在活动集上重新计算最小二乘拟合，并更新残差。\n     - 重复正好 $k$ 次迭代，并返回所选的支持集。\n   - 对于一个给定的实例，精确恢复意味着返回的支持集等于真实支持集。\n\n2. 具体的字典。使用 $m = 4$ 和 $n = 5$。定义 $A$ 和 $B$ 的列如下，其中 $\\mathbf{e}_1,\\mathbf{e}_2,\\mathbf{e}_3,\\mathbf{e}_4$ 是 $\\mathbb{R}^4$ 中的标准基向量：\n   - 对于 $A$：\n     - $a_1 = \\mathbf{e}_1 = [1,0,0,0]^\\top$，\n     - $a_2 = \\mathbf{e}_2 = [0,1,0,0]^\\top$，\n     - $a_3 = \\mathbf{e}_3 = [0,0,1,0]^\\top$，\n     - $a_4 = \\left[\\frac{1}{2}, -\\frac{1}{2}, 0, \\frac{1}{\\sqrt{2}}\\right]^\\top$，\n     - $a_5 = \\left[\\frac{1}{2}, -\\frac{1}{2}, 0, -\\frac{1}{\\sqrt{2}}\\right]^\\top$。\n   - 对于 $B$：\n     - $b_1 = \\mathbf{e}_1 = [1,0,0,0]^\\top$，\n     - $b_2 = \\mathbf{e}_2 = [0,1,0,0]^\\top$，\n     - $b_3 = \\mathbf{e}_3 = [0,0,1,0]^\\top$，\n     - $b_4 = \\left[\\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2}\\right]^\\top$，\n     - $b_5 = -\\mathbf{e}_4 = [0,0,0,-1]^\\top$。\n   所有列都是单位范数。$A$ 和 $B$ 的互相关性均为 $\\mu = \\frac{1}{2}$，因为在各自按列归一化的格拉姆矩阵中，最大的绝对非对角线元素等于 $\\frac{1}{2}$。\n\n3. 用于谱比较的子格拉姆矩阵。设目标支持集为 $S = \\{1,2,3\\}$，并定义 $T = S \\cup \\{4\\} = \\{1,2,3,4\\}$。您必须计算 $G_T(A)$ 和 $G_T(B)$ 的最小特征值。这些值反映了列集合 $A_T$ 和 $B_T$ 的条件数差异，尽管 $A$ 和 $B$ 具有相同的互相关性。\n\n4. 稀疏信号测试套件。对于每个测试，创建一个系数向量 $x \\in \\mathbb{R}^n$，并使用指定的 $D \\in \\{A,B\\}$ 计算 $y = D x$。对于所有测试，真实支持集为 $S = \\{1,2,3\\}$。\n   - 情况1（顺利路径与失败模式）：$k=3$，$x = [1, 1, 1, 0, 0]^\\top$。\n   - 情况2（基于相关性的保证的边界情况）：$k=1$，$x = [1, 0, 0, 0, 0]^\\top$。\n   - 情况3（小的相等系数，聚合相关性挑战）：$k=3$，$x = [0.2, 0.2, 0.2, 0, 0]^\\top$。\n   对于每种情况，使用 $D=A$ 和 $D=B$ 运行 OMP 恰好 $k$ 次迭代，并报告恢复的支持集是否等于 $S$。\n\n5. 要求的计算和输出。\n   - 计算 $\\mu(A)$ 和 $\\mu(B)$，并在数值公差 $\\tau = 10^{-12}$ 内验证它们是否相同，每个测试用例报告一个布尔值。\n   - 计算最小特征值 $\\lambda_{\\min}\\!\\left(G_T(A)\\right)$ 和 $\\lambda_{\\min}\\!\\left(G_T(B)\\right)$。\n   - 对于每种情况，按规定运行 OMP，并报告两个布尔值，分别表示使用 $A$ 和使用 $B$ 是否精确恢复了支持集。\n   - 对于每种情况，将结果汇总到一个列表中：\n     - $\\left[\\text{mu\\_equal}, \\lambda_{\\min}\\!\\left(G_T(A)\\right), \\lambda_{\\min}\\!\\left(G_T(B)\\right), \\text{omp\\_success\\_A}, \\text{omp\\_success\\_B}\\right]$,\n     其中 `mu_equal`、`omp_success_A` 和 `omp_success_B` 是布尔值，特征值是四舍五入到 $6$ 位小数的浮点数。\n   - 最终输出格式：您的程序应生成单行输出，其中包含三个按情况划分的结果列表的列表，即，一行看起来像 $[\\text{case1\\_result},\\text{case2\\_result},\\text{case3\\_result}]$，没有多余的空格或文本。例如：$[[\\text{...}],[\\text{...}],[\\text{...}]]$.\n\n确保您的实现不读取输入，并使用确定性的线性代数和固定的数值比较公差。完全按照上述描述实现正交匹配追踪 (OMP)，在每种情况下恰好迭代 $k$ 次后停止。在评估互相关性时，所有内积和格拉姆矩阵必须在列归一化后计算。按规定将浮点特征值四舍五入到 $6$ 位小数。",
            "solution": "该问题要求构建和分析两个字典 $A$ 和 $B$，以展示子格拉姆矩阵的谱特性（而不仅仅是互相关性）如何影响像正交匹配追踪 (OMP) 这类稀疏恢复算法的成功。我们将首先定义数学对象，然后计算所需的度量，最后通过模拟 OMP 来验证理论预测。\n\n字典 $A, B \\in \\mathbb{R}^{m \\times n}$ 在 $m=4$ 和 $n=5$ 的情况下给出。设 $\\mathbf{e}_i$ 为 $\\mathbb{R}^4$ 中的第 $i$ 个标准基向量。\n\n字典 $A$ 的列为：\n- $a_1 = [1, 0, 0, 0]^\\top$\n- $a_2 = [0, 1, 0, 0]^\\top$\n- $a_3 = [0, 0, 1, 0]^\\top$\n- $a_4 = \\left[\\frac{1}{2}, -\\frac{1}{2}, 0, \\frac{1}{\\sqrt{2}}\\right]^\\top$\n- $a_5 = \\left[\\frac{1}{2}, -\\frac{1}{2}, 0, -\\frac{1}{\\sqrt{2}}\\right]^\\top$\n\n字典 $B$ 的列为：\n- $b_1 = [1, 0, 0, 0]^\\top$\n- $b_2 = [0, 1, 0, 0]^\\top$\n- $b_3 = [0, 0, 1, 0]^\\top$\n- $b_4 = \\left[\\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2}\\right]^\\top$\n- $b_5 = [0, 0, 0, -1]^\\top$\n\n经核实，两个字典的所有列的欧几里得范数均为 $1$。\n\n对于列为单位范数的字典 $D$，其互相关性 $\\mu(D)$ 为 $\\mu(D) = \\max_{i \\neq j} |\\langle d_i, d_j \\rangle|$。这是格拉姆矩阵 $G(D) = D^\\top D$ 的最大绝对非对角元素。\n\n对于字典 A，其格拉姆矩阵 $G(A) = A^\\top A$ 为：\n$$ G(A) = \\begin{pmatrix}\n1  0  0  1/2  1/2 \\\\\n0  1  0  -1/2  -1/2 \\\\\n0  0  1  0  0 \\\\\n1/2  -1/2  0  1  0 \\\\\n1/2  -1/2  0  0  1\n\\end{pmatrix} $$\n最大的绝对非对角元素值为 $|\\pm 1/2| = 1/2$。因此，$\\mu(A) = 1/2$。\n\n对于字典 B，其格拉姆矩阵 $G(B) = B^\\top B$ 为：\n$$ G(B) = \\begin{pmatrix}\n1  0  0  1/2  0 \\\\\n0  1  0  1/2  0 \\\\\n0  0  1  1/2  0 \\\\\n1/2  1/2  1/2  1  0 \\\\\n0  0  0  0  1\n\\end{pmatrix} $$\n最大的绝对非对角元素值为 $1/2$。因此，$\\mu(B) = 1/2$。\n互相关性相同：$\\mu(A) = \\mu(B) = 1/2$。\n\n接下来，我们分析子格拉姆矩阵的谱特性。指定的索引集为 $T = \\{1, 2, 3, 4\\}$，它包含真实支持集 $S = \\{1, 2, 3\\}$ 和一个干扰原子。子格拉姆矩阵为 $G_T(A) = A_T^\\top A_T$ 和 $G_T(B) = B_T^\\top B_T$。\n\n子矩阵 $A_T$ 由列 $a_1, a_2, a_3, a_4$ 组成。其格拉姆矩阵为：\n$$ G_T(A) = \\begin{pmatrix}\n1  0  0  1/2 \\\\\n0  1  0  -1/2 \\\\\n0  0  1  0 \\\\\n1/2  -1/2  0  1\n\\end{pmatrix} $$\n特征多项式为 $\\det(G_T(A) - \\lambda I) = (1-\\lambda)^2 ((1-\\lambda)^2 - 1/2)$。特征值为 $\\lambda \\in \\{1, 1, 1 - 1/\\sqrt{2}, 1 + 1/\\sqrt{2}\\}$。最小特征值为 $\\lambda_{\\min}(G_T(A)) = 1 - 1/\\sqrt{2} \\approx 0.292893$。\n\n子矩阵 $B_T$ 由列 $b_1, b_2, b_3, b_4$ 组成。其格拉姆矩阵为：\n$$ G_T(B) = \\begin{pmatrix}\n1  0  0  1/2 \\\\\n0  1  0  1/2 \\\\\n0  0  1  1/2 \\\\\n1/2  1/2  1/2  1\n\\end{pmatrix} $$\n特征多项式为 $\\det(G_T(B) - \\lambda I) = (1-\\lambda)^2 ((1-\\lambda)^2 - 3/4)$。特征值为 $\\lambda \\in \\{1, 1, 1 - \\sqrt{3}/2, 1 + \\sqrt{3}/2\\}$。最小特征值为 $\\lambda_{\\min}(G_T(B)) = 1 - \\sqrt{3}/2 \\approx 0.133975$。\n\n格拉姆矩阵的最小特征值量化了其列的线性无关性。值越小，表示这些列“越接近”线性相关。此处，$\\lambda_{\\min}(G_T(B))  \\lambda_{\\min}(G_T(A))$，表明原子集 $\\{b_1, b_2, b_3, b_4\\}$ 的条件比 $\\{a_1, a_2, a_3, a_4\\}$ 更差。这是解释 OMP 性能差异的关键。\n\n正交匹配追踪 (OMP) 是一种迭代贪心算法。对于给定的稀疏度 $k$、字典 $D$ 和测量值 $y = Dx$，它对 $i=1, \\dots, k$ 执行如下操作：\n1. 初始化：残差 $r_0 = y$，支持集 $\\Lambda_0 = \\emptyset$。\n2. 原子选择：找到索引 $j_i = \\arg\\max_{j} |\\langle d_j, r_{i-1} \\rangle|$。\n3. 支持集更新：$\\Lambda_i = \\Lambda_{i-1} \\cup \\{j_i\\}$。\n4. 信号更新与残差计算：求解最小二乘问题 $x_i = \\arg\\min_{z} \\|y - D_{\\Lambda_i} z\\|_2^2$。新的残差为 $r_i = y - D_{\\Lambda_i} x_i$。这等效于将 $y$ 投影到由 $D_{\\Lambda_i}$ 张成的子空间的正交补上，即 $r_i = (I - P_{\\Lambda_i})y$，其中 $P_{\\Lambda_i}$ 是投影矩阵。\n最终恢复的支持集为 $\\Lambda_k$。\n\n我们使用此过程分析测试用例。请注意，在实现中索引是从 0 开始的，所以 $S=\\{0,1,2\\}$。\n\n情况 1：$k=3$，$x=[1, 1, 1, 0, 0]^\\top$。真实支持集是 $S=\\{0,1,2\\}$。\n- 对于字典 $A$：$y_A = A x = a_1 + a_2 + a_3 = [1, 1, 1, 0]^\\top$。OMP 从残差 $r_0 = y_A$ 开始。相关性为 $|\\langle a_1, r_0 \\rangle|=1$、 $|\\langle a_2, r_0 \\rangle|=1$、 $|\\langle a_3, r_0 \\rangle|=1$，其他为 $0$。假设在相关性相等时选择最小的索引，OMP 将依次选择原子 $0, 1, 2$。恢复的支持集为 $\\{0, 1, 2\\}$，等于 $S$。因此，恢复成功。\n- 对于字典 $B$：$y_B = B x = b_1 + b_2 + b_3 = [1, 1, 1, 0]^\\top$。初始残差为 $r_0=y_B$。相关性为 $|\\langle b_1, r_0 \\rangle|=1$、 $|\\langle b_2, r_0 \\rangle|=1$、 $|\\langle b_3, r_0 \\rangle|=1$，但 $|\\langle b_4, r_0 \\rangle| = |\\langle b_4, b_1+b_2+b_3 \\rangle| = |\\frac{1}{2}+\\frac{1}{2}+\\frac{1}{2}|=1.5$。OMP 在第一步错误地选择了原子 $3$（对应于 $b_4$），因为它具有最高的相关性。最终的支持集不可能是 $S$。恢复失败。这次失败是 $B_T$ 条件差的直接后果，其较小的 $\\lambda_{\\min}$ 已表明了这一点。原子 $b_4$ 与真实原子 $b_1+b_2+b_3$ 的线性组合高度相关。\n\n情况 2：$k=1$，$x=[1, 0, 0, 0, 0]^\\top$。真实支持集是 $\\{0\\}$。\n问题规定，恢复的支持集应与 $S=\\{0,1,2\\}$ 进行比较。\n- 对于字典 $A$：$y_A = a_1 = [1, 0, 0, 0]^\\top$。对于 $k=1$，OMP 选择与 $y_A$ 相关性最高的原子。这显然是 $a_1$（索引 $0$），相关性为 $1$。恢复的支持集是 $\\{0\\}$。由于 $\\{0\\} \\neq \\{0, 1, 2\\}$，该测试被视为失败。\n- 对于字典 $B$：$y_B = b_1 = [1, 0, 0, 0]^\\top$。类似地，OMP 选择原子 $b_1$（索引 $0$）。恢复的支持集是 $\\{0\\}$，不等于 $S=\\{0, 1, 2\\}$。测试失败。\n在这两种子情况下，OMP 都正确地识别了真实的 1-稀疏支持集，但由于问题指定要与一个 3 元素集合进行比较，因此测试失败。\n\n情况 3：$k=3$，$x=[0.2, 0.2, 0.2, 0, 0]^\\top$。真实支持集是 $S=\\{0,1,2\\}$。\n这种情况是情况1的一个缩放版本。测量向量 $y$ 只是情况1中向量的 $0.2$ 倍。OMP 的选择标准 $\\arg\\max_{j} |\\langle d_j, r_{i-1} \\rangle|$ 对测量向量（以及所有后续残差）的正向缩放是不变的。因此，对于两个字典，所选原子的序列将与情况1相同。\n- 对于字典 $A$：恢复成功，得到支持集 $\\{0, 1, 2\\}$。\n- 对于字典 $B$：恢复失败，因为首先选择了原子 $3$。\n\n结果证实，即使互相关性相同，由子格拉姆矩阵的谱特性所反映的原子子集间的相关性分布，对于稀疏恢复而言是一个更具决定性的因素。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the compressed sensing problem by defining two dictionaries,\n    calculating their properties, and running Orthogonal Matching Pursuit (OMP).\n    \"\"\"\n\n    # 1. Define Dictionaries A and B\n    sqrt2 = np.sqrt(2.0)\n    A = np.array([\n        [1.0, 0.0, 0.0, 0.5, 0.5],\n        [0.0, 1.0, 0.0, -0.5, -0.5],\n        [0.0, 0.0, 1.0, 0.0, 0.0],\n        [0.0, 0.0, 0.0, 1.0 / sqrt2, -1.0 / sqrt2]\n    ])\n\n    B = np.array([\n        [1.0, 0.0, 0.0, 0.5, 0.0],\n        [0.0, 1.0, 0.0, 0.5, 0.0],\n        [0.0, 0.0, 1.0, 0.5, 0.0],\n        [0.0, 0.0, 0.0, 0.5, -1.0]\n    ])\n\n    def get_mutual_coherence(D):\n        \"\"\"Computes the mutual coherence of a dictionary.\"\"\"\n        # Normalize columns to be safe, as per problem description\n        D_norm = D / np.linalg.norm(D, axis=0)\n        gram_matrix = D_norm.T @ D_norm\n        np.fill_diagonal(gram_matrix, 0)\n        return np.max(np.abs(gram_matrix))\n\n    def get_min_eigenvalue_subgram(D, T_indices):\n        \"\"\"Computes the minimum eigenvalue of a sub-Gram matrix.\"\"\"\n        D_T = D[:, T_indices]\n        G_T = D_T.T @ D_T\n        # use eigvalsh for Hermitian matrices\n        eigenvalues = np.linalg.eigvalsh(G_T)\n        return np.min(eigenvalues)\n\n    def omp(D, y, k):\n        \"\"\"\n        Orthogonal Matching Pursuit algorithm.\n        Stops after exactly k iterations.\n        \"\"\"\n        num_atoms = D.shape[1]\n        residual = np.copy(y)\n        support = []\n        \n        for _ in range(k):\n            correlations = np.abs(D.T @ residual)\n            # Mask already selected atoms\n            if support:\n                correlations[support] = -1\n            \n            # Find the best atom (smallest index in case of a tie)\n            best_atom_idx = np.argmax(correlations)\n            support.append(best_atom_idx)\n\n            # Update residual using projection\n            D_support = D[:, support]\n            \n            # Solve least squares: x = (D_S^T D_S)^-1 D_S^T y\n            # Using pseudoinverse for stability, although solve would also work\n            # as submatrices are full rank here.\n            x_support = np.linalg.pinv(D_support) @ y\n            \n            # Update residual\n            residual = y - D_support @ x_support\n            \n        return set(support)\n\n    # 2. Define Test Cases and Fixed Parameters\n    T_indices = [0, 1, 2, 3] # Indices for sub-Gram matrix, 1-based {1,2,3,4}\n    S_target = {0, 1, 2}     # Target support set, 1-based {1,2,3}\n    \n    test_cases = [\n        # k, x_coeffs\n        (3, np.array([1.0, 1.0, 1.0, 0.0, 0.0])),\n        (1, np.array([1.0, 0.0, 0.0, 0.0, 0.0])),\n        (3, np.array([0.2, 0.2, 0.2, 0.0, 0.0])),\n    ]\n\n    # Pre-compute dictionary properties as they are the same for all cases\n    mu_A = get_mutual_coherence(A)\n    mu_B = get_mutual_coherence(B)\n    mu_equal = abs(mu_A - mu_B)  1e-12\n\n    lambda_min_A = get_min_eigenvalue_subgram(A, T_indices)\n    lambda_min_B = get_min_eigenvalue_subgram(B, T_indices)\n\n    results = []\n    for k, x in test_cases:\n        # Generate measurement vectors\n        y_A = A @ x\n        y_B = B @ x\n\n        # Run OMP\n        recovered_support_A = omp(A, y_A, k)\n        recovered_support_B = omp(B, y_B, k)\n\n        # Check for exact recovery against the specified target set S\n        omp_success_A = (recovered_support_A == S_target)\n        omp_success_B = (recovered_support_B == S_target)\n\n        # Aggregate results for the case\n        case_result = [\n            mu_equal,\n            round(lambda_min_A, 6),\n            round(lambda_min_B, 6),\n            omp_success_A,\n            omp_success_B\n        ]\n        results.append(case_result)\n        \n    # Final print statement in the exact required format.\n    # The string representation of list of lists is \"[...], [...]\"\n    # We join these with commas and wrap in an outer \"[]\"\n    print(f\"[{','.join(map(str, results))}]\".replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "不同的恢复算法拥有不同的性能保证。本练习  旨在比较凸优化方法（基追踪）和简单贪心算法的恢复条件。通过推导和比较它们各自的保证，您将发现这些条件不仅与算法本身有关，还可能依赖于稀疏信号自身的属性，例如其非零系数的动态范围。",
            "id": "3435239",
            "problem": "考虑一个列向量为单位范数的实数矩阵。设 $\\Phi \\in \\mathbb{R}^{m \\times n}$ 的列向量为 $\\{\\phi_j\\}_{j=1}^n$，且对所有 $j$ 满足 $\\|\\phi_j\\|_2 = 1$。$\\Phi$ 的相互相干性 (mutual coherence) 定义为\n$$\n\\mu(\\Phi) \\triangleq \\max_{1 \\le i \\ne j \\le n} \\left| \\langle \\phi_i, \\phi_j \\rangle \\right|.\n$$\n给定一个 $k$-稀疏向量 $x \\in \\mathbb{R}^n$（即 $|\\mathrm{supp}(x)| = k$）和无噪声测量值 $y = \\Phi x$，我们寻求使用贪婪算法或凸优化程序从 $y$ 中精确恢复 $x$。定义振幅比 (amplitude ratio)\n$$\n\\rho(x) \\triangleq \\frac{\\min_{i \\in \\mathrm{supp}(x)} |x_i|}{\\max_{i \\in \\mathrm{supp}(x)} |x_i|} \\in (0,1].\n$$\n\n我们关注的凸优化程序是基追踪 (Basis Pursuit, BP)，它求解 $\\min_{z \\in \\mathbb{R}^n} \\|z\\|_1$，约束条件为 $\\Phi z = y$。我们关注的贪婪方法是简单贪婪阈值法 (Simple Greedy Thresholding, SGT)，它选择 $|\\langle \\phi_j, y \\rangle|$ 值最大的 $k$ 个索引。\n\n您的任务是实现一个程序，对每个测试用例，计算相互相干性 $\\mu(\\Phi)$、每种方法基于相干性的精确恢复保证所能支持的最大稀疏度 $k$，以及指定的目标稀疏度 $k_{\\mathrm{target}}$ 是否被每种保证所认证。所有推导必须从基本不等式（如柯西-施瓦茨不等式和三角不等式）以及上述定义出发，不得依赖于问题陈述中给出的目标公式。\n\n具体来说，您的程序必须：\n\n- 通过构建格拉姆矩阵 (Gram matrix) $G = \\Phi^\\top \\Phi$，将其对角线元素置零，并取非对角线元素绝对值的最大值来计算 $\\mu(\\Phi)$。\n- 对于凸优化方法基追踪 (Basis Pursuit, BP)，使用基于相互相干性的充分条件，得到最大整数 $k_{\\mathrm{BP}}^{\\max}(\\mu)$，使得当 $k \\le k_{\\mathrm{BP}}^{\\max}(\\mu)$ 时，对所有 $k$-稀疏的 $x$ 都能精确恢复。在需要时使用严格不等式，并为了数值上的现实性，将 $k_{\\mathrm{BP}}^{\\max}(\\mu)$ 的上限设为 $n$。\n- 对于贪婪方法简单贪婪阈值法 (Simple Greedy Thresholding, SGT)，推导一个依赖于 $\\rho(x)$ 的基于相互相干性的充分条件，并得到最大整数 $k_{\\mathrm{SGT}}^{\\max}(\\mu,\\rho)$，使得当 $k \\le k_{\\mathrm{SGT}}^{\\max}(\\mu,\\rho)$ 时能够精确恢复。在需要时使用严格不等式，并为了数值上的现实性，将 $k_{\\mathrm{SGT}}^{\\max}(\\mu,\\rho)$ 的上限设为 $n$。\n- 对于指定的目标稀疏度 $k_{\\mathrm{target}}$，报告布尔值，指示 BP 和 SGT 的保证是否能认证在 $k = k_{\\mathrm{target}}$ 时的精确恢复。\n\n使用以下测试套件，其中每个案例指定 $(m,n)$、一个确定性矩阵构造规则、一个振幅比 $\\rho$ 和一个目标稀疏度 $k_{\\mathrm{target}}$：\n\n- 案例 1：$m = 32$，$n = 64$。通过使用固定的种子 $7$ 抽取独立的标准正态分布项来构造 $\\Phi$，并将列向量归一化为单位范数。使用 $\\rho = 0.3$ 和 $k_{\\mathrm{target}} = 3$。\n- 案例 2：$m = 50$，$n = 100$。通过使用固定的种子 $1234$ 抽取独立的标准正态分布项来构造 $\\Phi$，并将列向量归一化为单位范数。使用 $\\rho = 0.95$ 和 $k_{\\mathrm{target}} = 4$。\n- 案例 3：$m = 10$，$n = 12$。通过使用固定的种子 $202$ 抽取独立的标准正态分布项来构造 $\\Phi$，将列向量归一化为单位范数，然后在归一化后使第 1 列和第 2 列相同（即将第二列设置为等于第一列）。使用 $\\rho = 0.5$ 和 $k_{\\mathrm{target}} = 1$。\n- 案例 4：$m = 3$，$n = 3$。确定性地构造具有单位范数列向量的 $\\Phi$，列向量为 $\\phi_1 = (1,0,0)^\\top$、$\\phi_2 = (c,\\sqrt{1-c^2},0)^\\top$ 和 $\\phi_3 = (c,0,\\sqrt{1-c^2})^\\top$，其中 $c = \\frac{1}{3}$。使用 $\\rho = 1.0$ 和 $k_{\\mathrm{target}} = 2$。\n\n最终输出格式：\n\n- 对每个测试用例，输出列表 $[\\mu, k_{\\mathrm{BP}}^{\\max}(\\mu), k_{\\mathrm{SGT}}^{\\max}(\\mu,\\rho), s_{\\mathrm{BP}}, s_{\\mathrm{SGT}}]$，其中 $\\mu$ 四舍五入到 $6$ 位小数，$k_{\\mathrm{BP}}^{\\max}(\\mu)$ 和 $k_{\\mathrm{SGT}}^{\\max}(\\mu,\\rho)$ 是整数，$s_{\\mathrm{BP}}$ 和 $s_{\\mathrm{SGT}}$ 是布尔值，指示 $k_{\\mathrm{target}}$ 是否被各自的保证所认证。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，例如 $[[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],\\ldots]$，不含任何额外文本。\n\n程序必须是自包含的，且不要求任何输入。",
            "solution": "该问题要求推导基于相干性的充分条件，用于从无噪声测量值 $y = \\Phi x \\in \\mathbb{R}^m$ 中精确恢复稀疏向量 $x \\in \\mathbb{R}^n$，并在程序中实现这些条件。矩阵 $\\Phi \\in \\mathbb{R}^{m \\times n}$ 的列向量 $\\phi_j$ 被归一化为单位 $\\ell_2$ 范数，即 $\\|\\phi_j\\|_2 = 1$。分析的关键在于相互相干性 $\\mu(\\Phi) = \\max_{i \\ne j} |\\langle \\phi_i, \\phi_j \\rangle|$。我们将为两种恢复方法推导条件：基追踪 (Basis Pursuit, BP) 和我们称之为简单贪婪阈值法 (Simple Greedy Thresholding, SGT) 的贪婪方法。\n\n设 $x$ 是一个 $k$-稀疏向量。我们将其支撑集（非零项的索引集合）表示为 $S_0 = \\mathrm{supp}(x)$，其中 $|S_0| = k$。设 $S_0^c$ 为 $S_0$ 的补集。对于任何索引集 $S \\subseteq \\{1, \\dots, n\\}$，$\\Phi_S$ 表示由 $S$ 索引的列组成的 $\\Phi$ 的子矩阵。\n\n### 1. 基追踪 (Basis Pursuit, BP) 的恢复保证\n基追踪通过求解以下凸优化问题来恢复 $x$：\n$$ \\min_{z \\in \\mathbb{R}^n} \\|z\\|_1 \\quad \\text{subject to} \\quad \\Phi z = y $$\n如果存在一个“对偶凭证” (dual certificate) $\\lambda \\in \\mathbb{R}^m$，使得向量 $v = \\Phi^\\top \\lambda$ 满足以下条件，那么真实的稀疏向量 $x$ 是该问题的唯一解：\n1. 对于所有 $i \\in S_0$，$v_i = \\mathrm{sgn}(x_i)$。\n2. 对于所有 $j \\in S_0^c$，$|v_j|  1$。\n\n我们仅使用关于支撑集 $S_0$ 的信息（而非 $x$ 本身的值）来构造一个候选对偶向量 $\\lambda$。一个标准的选择是 $\\lambda = \\Phi_{S_0}(\\Phi_{S_0}^\\top \\Phi_{S_0})^{-1} \\mathrm{sgn}(x_{S_0})$。这个构造要求格拉姆矩阵 $G_{S_0} = \\Phi_{S_0}^\\top \\Phi_{S_0}$ 是可逆的。根据 Gershgorin 圆盘定理，如果 $(k-1)\\mu  1$，则 $G_{S_0}$ 可逆。\n\n让我们用这个 $\\lambda$ 的选择来验证这两个条件：\n1. 对于 $i \\in S_0$，$v$ 的相应部分是 $v_{S_0} = \\Phi_{S_0}^\\top \\lambda = \\Phi_{S_0}^\\top \\Phi_{S_0} (\\Phi_{S_0}^\\top \\Phi_{S_0})^{-1} \\mathrm{sgn}(x_{S_0}) = \\mathrm{sgn}(x_{S_0})$。此条件得到满足。\n\n2. 对于 $j \\in S_0^c$，我们必须对 $|v_j| = |\\phi_j^\\top \\lambda|$ 进行界定。\n$$ |v_j| = |\\phi_j^\\top \\Phi_{S_0} (\\Phi_{S_0}^\\top \\Phi_{S_0})^{-1} \\mathrm{sgn}(x_{S_0})| $$\n使用 Holder 不等式，我们得到：\n$$ |v_j| \\le \\|\\phi_j^\\top \\Phi_{S_0}\\|_1 \\|(\\Phi_{S_0}^\\top \\Phi_{S_0})^{-1}\\|_\\infty \\|\\mathrm{sgn}(x_{S_0})\\|_\\infty $$\n第一项受相互相干性限制：$\\|\\phi_j^\\top \\Phi_{S_0}\\|_1 = \\sum_{i \\in S_0} |\\langle \\phi_j, \\phi_i \\rangle| \\le k\\mu$。\n对于第二项，我们界定矩阵的无穷范数。设 $G_{S_0} = I + B$。如果 $\\|B\\|_\\infty = \\max_{i \\in S_0} \\sum_{l \\in S_0, l \\ne i} |\\langle \\phi_i, \\phi_l \\rangle| \\le (k-1)\\mu  1$，则 $\\|G_{S_0}^{-1}\\|_\\infty \\le \\frac{1}{1-\\|B\\|_\\infty} \\le \\frac{1}{1-(k-1)\\mu}$。\n第三项 $\\|\\mathrm{sgn}(x_{S_0})\\|_\\infty = 1$。\n\n结合这些界限，我们得到：\n$$ |v_j| \\le k\\mu \\cdot \\frac{1}{1-(k-1)\\mu} \\cdot 1 = \\frac{k\\mu}{1-(k-1)\\mu} $$\n为了精确恢复，我们需要 $|v_j|  1$，这导出了充分条件：\n$$ \\frac{k\\mu}{1-(k-1)\\mu}  1 \\implies k\\mu  1 - (k-1)\\mu \\implies 2k\\mu - \\mu  1 $$\n$$ k  \\frac{1+\\mu}{2\\mu} = \\frac{1}{2} + \\frac{1}{2\\mu} $$\n这个条件保证了对任何 $k$-稀疏信号的恢复。满足这个严格不等式的最大整数 $k$ 是 $k_{\\mathrm{BP}}^{\\max}(\\mu) = \\lceil \\frac{1}{2} + \\frac{1}{2\\mu} \\rceil - 1$。\n\n### 2. 简单贪婪阈值法 (Simple Greedy Thresholding, SGT) 的恢复保证\nSGT 方法通过选择与 $|c_j| = |\\langle \\phi_j, y \\rangle|$ 的最大值相对应的 $k$ 个索引来识别 $x$ 的支撑集。如果所选索引的集合恰好是 $S_0$，则该方法成功。这在 $\\min_{j \\in S_0} |c_j|  \\max_{l \\in S_0^c} |c_l|$ 时发生。\n\n让我们计算相关性 $c_j$。由于 $y = \\sum_{i \\in S_0} x_i \\phi_i$：\n$$ c_j = \\langle \\phi_j, \\sum_{i \\in S_0} x_i \\phi_i \\rangle = \\sum_{i \\in S_0} x_i \\langle \\phi_j, \\phi_i \\rangle $$\n对于一个“正确”的索引 $j \\in S_0$：\n$$ c_j = x_j \\langle \\phi_j, \\phi_j \\rangle + \\sum_{i \\in S_0, i \\ne j} x_i \\langle \\phi_j, \\phi_i \\rangle = x_j + \\sum_{i \\in S_0, i \\ne j} x_i \\langle \\phi_j, \\phi_i \\rangle $$\n使用三角不等式，我们可以对其幅值给出一个下界：\n$$ |c_j| \\ge |x_j| - \\sum_{i \\in S_0, i \\ne j} |x_i| |\\langle \\phi_j, \\phi_i \\rangle| \\ge |x_j| - \\mu \\sum_{i \\in S_0, i \\ne j} |x_i| $$\n设 $x_{\\min} = \\min_{i \\in S_0} |x_i|$ 和 $x_{\\max} = \\max_{i \\in S_0} |x_i|$。这个和有 $k-1$ 项，每项最多为 $x_{\\max}$。因此，最小正确相关性的一个下界是：\n$$ \\min_{j \\in S_0} |c_j| \\ge x_{\\min} - \\mu (k-1) x_{\\max} $$\n对于一个“不正确”的索引 $l \\in S_0^c$：\n$$ c_l = \\sum_{i \\in S_0} x_i \\langle \\phi_l, \\phi_i \\rangle $$\n使用三角不等式，我们可以对其幅值给出一个上界：\n$$ |c_l| \\le \\sum_{i \\in S_0} |x_i| |\\langle \\phi_l, \\phi_i \\rangle| \\le \\mu \\sum_{i \\in S_0} |x_i| $$\n这个和有 $k$ 项。因此，最大不正确相关性的一个上界是：\n$$ \\max_{l \\in S_0^c} |c_l| \\le \\mu k x_{\\max} $$\nSGT 成功的充分条件是 $\\min_{j \\in S_0} |c_j|  \\max_{l \\in S_0^c} |c_l|$，如果以下条件成立，则该条件得到保证：\n$$ x_{\\min} - \\mu (k-1) x_{\\max}  \\mu k x_{\\max} $$\n$$ x_{\\min}  (k-1)\\mu x_{\\max} + k\\mu x_{\\max} = (2k-1)\\mu x_{\\max} $$\n除以 $x_{\\max}$ 并使用振幅比的定义 $\\rho(x) = x_{\\min}/x_{\\max}$：\n$$ \\rho(x)  (2k-1)\\mu $$\n给定振幅比的值 $\\rho$，我们可以找到使此条件成立的最大稀疏度 $k$。我们重排不等式以求解 $k$：\n$$ 2k-1  \\frac{\\rho}{\\mu} \\implies 2k  1 + \\frac{\\rho}{\\mu} \\implies k  \\frac{1}{2} + \\frac{\\rho}{2\\mu} $$\n满足这个严格不等式的最大整数 $k$ 是 $k_{\\mathrm{SGT}}^{\\max}(\\mu,\\rho) = \\lceil \\frac{1}{2} + \\frac{\\rho}{2\\mu} \\rceil - 1$。\n\n### 3. 实现\n程序将为每个测试用例实现以下步骤：\n1. 根据指定的规则（高斯、退化或确定性）构造矩阵 $\\Phi \\in \\mathbb{R}^{m \\times n}$，并确保其列向量被归一化。\n2. 通过计算格拉姆矩阵 $G = \\Phi^\\top \\Phi$，将其对角线元素置零，并找到剩余非对角线元素的最大绝对值来计算相互相干性 $\\mu(\\Phi)$。\n3. 应用推导出的公式计算最大认证稀疏度 $k_{\\mathrm{BP}}^{\\max}(\\mu)$ 和 $k_{\\mathrm{SGT}}^{\\max}(\\mu,\\rho)$。在 $\\mu \\approx 0$ 的情况下，保证延伸到理论极限，我们将其上限定为 $n$。\n4. 对于给定的目标稀疏度 $k_{\\mathrm{target}}$，确定它是否被每个保证所认证，即检查是否 $k_{\\mathrm{target}} \\le k_{\\mathrm{BP}}^{\\max}(\\mu)$ 和 $k_{\\mathrm{target}} \\le k_{\\mathrm{SGT}}^{\\max}(\\mu,\\rho)$。\n5. 将结果格式化为列表 $[\\mu, k_{\\mathrm{BP}}^{\\max}, k_{\\mathrm{SGT}}^{\\max}, s_{\\mathrm{BP}}, s_{\\mathrm{SGT}}]$，并收集它们用于最终输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes coherence-based recovery guarantees for compressed sensing.\n    \"\"\"\n    test_cases = [\n        # (m, n, construction_rule, seed, rho, k_target)\n        (32, 64, 'gaussian', 7, 0.3, 3),\n        (50, 100, 'gaussian', 1234, 0.95, 4),\n        (10, 12, 'degenerate_gaussian', 202, 0.5, 1),\n        (3, 3, 'deterministic', None, 1.0, 2)\n    ]\n\n    results = []\n    for m, n, rule, seed, rho, k_target in test_cases:\n        # 1. Construct the matrix Phi\n        if rule == 'gaussian':\n            rng = np.random.default_rng(seed)\n            Phi = rng.standard_normal((m, n))\n            # Normalize columns to unit norm\n            col_norms = np.linalg.norm(Phi, axis=0)\n            # Avoid division by zero, though unlikely.\n            col_norms[col_norms == 0] = 1.0\n            Phi = Phi / col_norms\n        elif rule == 'degenerate_gaussian':\n            rng = np.random.default_rng(seed)\n            Phi = rng.standard_normal((m, n))\n            # Normalize columns to unit norm\n            col_norms = np.linalg.norm(Phi, axis=0)\n            col_norms[col_norms == 0] = 1.0\n            Phi = Phi / col_norms\n            # Make columns 1 and 2 identical (indices 0 and 1)\n            Phi[:, 1] = Phi[:, 0]\n        elif rule == 'deterministic':\n            c = 1/3.0\n            Phi = np.array([\n                [1.0, c, c],\n                [0.0, np.sqrt(1.0 - c**2), 0.0],\n                [0.0, 0.0, np.sqrt(1.0 - c**2)]\n            ])\n            # Columns are unit norm by construction.\n        \n        # 2. Compute mutual coherence mu\n        # Gram matrix\n        G = Phi.T @ Phi\n        # Zero out the diagonal to isolate off-diagonal elements\n        np.fill_diagonal(G, 0)\n        mu = np.max(np.abs(G))\n        \n        # Handle the case of orthogonal columns (mu=0) to avoid division by zero.\n        if np.isclose(mu, 0):\n            # For orthogonal columns, recovery is guaranteed for any k up to n\n            k_bp_max = n\n            k_sgt_max = n\n        else:\n            # 3. Calculate k_bp_max for Basis Pursuit\n            # Condition: k  0.5 * (1/mu + 1)\n            val_bp = 0.5 * (1.0/mu + 1.0)\n            # k_bp_max is the largest integer k satisfying the strict inequality\n            k_bp_max = int(np.ceil(val_bp) - 1)\n            \n            # 4. Calculate k_sgt_max for Simple Greedy Thresholding\n            # Condition: k  0.5 * (rho/mu + 1)\n            val_sgt = 0.5 * (rho/mu + 1.0)\n            # k_sgt_max is the largest integer k satisfying the strict inequality\n            k_sgt_max = int(np.ceil(val_sgt) - 1)\n            \n        # Cap k_max values by n as per problem description\n        k_bp_max = min(k_bp_max, n)\n        k_sgt_max = min(k_sgt_max, n)\n\n        # 5. Determine if k_target is certified by each guarantee\n        s_bp = (k_target = k_bp_max)\n        s_sgt = (k_target = k_sgt_max)\n\n        # Store results for this case\n        results.append([mu, k_bp_max, k_sgt_max, s_bp, s_sgt])\n\n    # Format the final output string as a list of lists.\n    # e.g., [[val1,val2,...],[val1,val2,...]]\n    formatted_results = []\n    for res in results:\n        mu_val, k_bp, k_sgt, s_bp_val, s_sgt_val = res\n        # Format mu to 6 decimal places, and booleans to string representation.\n        formatted_str = f\"[{mu_val:.6f},{k_bp},{k_sgt},{s_bp_val},{s_sgt_val}]\"\n        # Since standard Python str(bool) gives 'True'/'False', we use these.\n        formatted_results.append(formatted_str)\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}