{
    "hands_on_practices": [
        {
            "introduction": "由于精确计算限定等距常数（Restricted Isometry Constant, RIC）是一个NP难问题，通过计算方法进行经验性估计便成为一种至关重要的实用工具。本练习  将指导您构建一个蒙特卡洛（Monte Carlo）估计器，以近似计算给定矩阵的RIC。通过这个实践，您将对随机矩阵的RIC行为，以及它如何依赖于测量数 $m$ 和稀疏度 $s$ 等关键参数，建立起直观的理解。",
            "id": "3489923",
            "problem": "您的任务是在压缩感知和稀疏优化的背景下，经验性地近似与限制等距性质 (RIP) 相关的限制等距常数 (RIC)。\n对于一个矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其 $s$ 阶限制等距性质 (RIP) 定义为：存在一个最小的数 $\\delta_s(A) \\in [0,\\infty)$，使得对于每个 $s$-稀疏向量 $x \\in \\mathbb{R}^n$（即一个最多有 $s$ 个非零项的向量），都满足\n$$(1 - \\delta_s(A)) \\, \\lVert x \\rVert_2^2 \\le \\lVert A x \\rVert_2^2 \\le (1 + \\delta_s(A)) \\, \\lVert x \\rVert_2^2.$$\n在这里，$\\delta_s(A)$ 被称为限制等距常数 (RIC)。一种在计算上探究 $\\delta_s(A)$ 的标准方法依赖于由大小为 $s$ 的支撑集索引的 $A$ 的子矩阵的谱行为。\n\n您的任务是设计并实现一个计算实验，该实验通过在大小为 $s$ 的支撑集上进行随机搜索来近似 $\\delta_s(A)$，并用它来经验性地研究对于随机高斯感知矩阵，$\\delta_s(A)$ 如何随采样率 $m/n$ 和稀疏度 $s$ 变化。您必须遵守以下规范。\n\n- 使用以下基础依据：\n  - 限制等距性质 (RIP) 和限制等距常数 (RIC) 的定义。\n  - 谱特征：对于每个满足 $\\lvert S \\rvert = s$ 的支撑集 $S \\subset \\{1,\\dots,n\\}$，如果 $A_S \\in \\mathbb{R}^{m \\times s}$ 表示由 $S$ 索引的 $A$ 的列构成的子矩阵，那么 $A_S^\\top A_S$ 的特征值控制了在该支撑集上 RIP 定义中的不等式。\n  - 关于随机高斯矩阵的经过充分检验的事实，包括：如果 $A$ 的元素是独立同分布的，方差为 $1/m$，并且其列被归一化为单位 $\\ell_2$ 范数，那么当 $s \\ll m$ 时，$A_S^\\top A_S$ 的特征值会集中在 1 附近。\n\n- 实现以下随机估计器：\n  - 对于给定的 $A \\in \\mathbb{R}^{m \\times n}$ 和稀疏度 $s$，执行 $T$ 次独立试验。在每次试验中，从 $\\{1,\\dots,n\\}$ 中无放回地均匀随机抽取一个大小为 $s$ 的支撑集 $S$。构建子矩阵 $A_S \\in \\mathbb{R}^{m \\times s}$ 并计算格拉姆矩阵 (Gram matrix) $G_S = A_S^\\top A_S \\in \\mathbb{R}^{s \\times s}$。令 $\\lambda_{\\min}(G_S)$ 和 $\\lambda_{\\max}(G_S)$ 分别表示其最小和最大特征值。定义试验偏差为 $d(S) = \\max\\{ \\lvert \\lambda_{\\min}(G_S) - 1 \\rvert, \\lvert \\lambda_{\\max}(G_S) - 1 \\rvert \\}$。估计器为 $\\widehat{\\delta}_s(A) = \\max_{t = 1,\\dots,T} d(S_t)$，这是对 $\\delta_s(A)$ 的一个蒙特卡洛 (Monte Carlo) 下界。\n  - 在运行估计器之前，将 $A$ 的列归一化为单位 $\\ell_2$ 范数。这确保了当 $s = 1$ 时，估计器应返回一个接近 $0$ 的值。\n\n- 实验设计：\n  - 对于每个测试用例，构建一个 $m \\times n$ 的矩阵 $A$，其元素独立分布于 $\\mathcal{N}(0, 1/m)$，然后将各列归一化为单位 $\\ell_2$ 范数。\n  - 为了在所有试验和测试用例中保证可复现性，使用一个固定的伪随机种子，其值为 $2025$。\n  - 在所有测试用例中使用相同数量的试验次数 $T$。\n\n- 测试套件：\n  - 您必须在以下六个参数设置 $(m,n,s)$ 上评估该估计器：\n    1. $(m,n,s) = (80, 200, 1)$。\n    2. $(m,n,s) = (80, 200, 10)$。\n    3. $(m,n,s) = (40, 200, 10)$。\n    4. $(m,n,s) = (120, 200, 20)$。\n    5. $(m,n,s) = (60, 200, 50)$。\n    6. $(m,n,s) = (40, 200, 50)$。\n  - 每个用例使用 $T = 250$ 次试验。\n\n- 输出规格：\n  - 您的程序必须输出单行内容，该行包含一个长度为 $6$ 的 Python 风格的浮点数列表，其中第 $i$ 个条目是您对第 $i$ 个测试用例的近似值 $\\widehat{\\delta}_s(A)$。\n  - 每个浮点数必须精确到小数点后 $6$ 位。\n  - 该行不得包含任何额外文本，并且格式必须与示例完全一致，例如 `[0.000000,0.123456,0.234567,0.345678,0.456789,0.567890]`。\n\n- 额外的解释性任务（在您的内部算法设计中处理，并在解题报告中解释，而不是在代码输出中）：基于随机高斯矩阵经过充分检验的行为以及 RIC 相对于 $s$ 的单调性，解释当 $m/n$ 增加和 $s$ 增加时，经验值应如何变化，并将您的观察结果与 $A_S^\\top A_S$ 谱的集中所建议的启发式缩放规律联系起来。\n\n此问题不涉及物理单位、角度单位或百分比符号。您的最终答案必须是一个完整的程序，该程序无需用户输入即可运行，并精确打印出指定的单行结果列表。",
            "solution": "任务是实现一个随机算法，用于对给定的矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和稀疏度 $s$，经验性地估计其限制等距常数 (RIC)，记为 $\\delta_s(A)$。然后，我们将应用此算法研究随机高斯矩阵在不同参数设置下 RIC 的行为。\n\n限制等距性质 (RIP) 是压缩感知中的一个核心概念。如果存在一个小的常数 $\\delta_s(A) \\in [0, 1)$，使得对于所有 $s$-稀疏向量 $x \\in \\mathbb{R}^n$（即最多有 $s$ 个非零项的向量），以下不等式成立，则矩阵 $A$ 满足 $s$ 阶 RIP：\n$$ (1 - \\delta_s(A)) \\lVert x \\rVert_2^2 \\le \\lVert Ax \\rVert_2^2 \\le (1 + \\delta_s(A)) \\lVert x \\rVert_2^2 $$\n常数 $\\delta_s(A)$ 是 $A$ 的第 $s$ 个限制等距常数。此性质确保 $A$ 在所有 $s$-稀疏向量的集合上充当一个近似等距映射，保持它们的长度。\n\n计算 $\\delta_s(A)$ 的一个关键洞见是它与子矩阵特征值的联系。设 $S \\subset \\{1, \\dots, n\\}$ 是一个基数为 $|S| \\le s$ 的索引支撑集。设 $A_S \\in \\mathbb{R}^{m \\times |S|}$ 是 $A$ 中仅包含由 $S$ 索引的列的子矩阵。对于任何支撑集为 $S$ 的向量 $x$，我们有 $Ax = A_S x_S$，其中 $x_S$ 包含 $x$ 的非零项。其范数的平方为 $\\lVert Ax \\rVert_2^2 = x_S^\\top A_S^\\top A_S x_S$。根据瑞利-里兹定理 (Rayleigh-Ritz theorem)，比率 $\\lVert Ax \\rVert_2^2 / \\lVert x \\rVert_2^2$ 受格拉姆矩阵 $G_S = A_S^\\top A_S$ 的最小和最大特征值的界定。因此，RIP 不等式可以用这些特征值来改写。RIC $\\delta_s(A)$ 的正式定义为：\n$$ \\delta_s(A) = \\max_{|S|=s} \\lVert A_S^\\top A_S - I \\rVert_{2 \\to 2} $$\n其中 $\\lVert \\cdot \\rVert_{2 \\to 2}$ 是谱范数。这等价于找到所有可能的 $s \\times s$ 格拉姆矩阵 $A_S^\\top A_S$ 的特征值与 $1$ 的最大偏差：\n$$ \\delta_s(A) = \\max_{|S|=s} \\left\\{ \\max(|\\lambda_{\\max}(A_S^\\top A_S) - 1|, |\\lambda_{\\min}(A_S^\\top A_S) - 1|) \\right\\} $$\n精确计算 $\\delta_s(A)$ 在计算上是难解的 (NP-hard)，因为它需要搜索所有 $\\binom{n}{s}$ 个可能的支撑集。\n\n为了解决这个问题，我们采用蒙特卡洛 (Monte Carlo) 近似。我们不是穷尽地检查所有支撑集，而是无放回地均匀随机抽取大量的支撑集 $S_1, S_2, \\dots, S_T$（共 $T$ 个）。对于每个抽样的支撑集 $S_t$，我们计算试验偏差 $d(S_t) = \\max\\{|\\lambda_{\\max}(A_{S_t}^\\top A_{S_t}) - 1|, |\\lambda_{\\min}(A_{S_t}^\\top A_{S_t}) - 1|\\}$。RIC 的估计器 $\\widehat{\\delta}_s(A)$ 则是所有试验中发现的最大偏差：\n$$ \\widehat{\\delta}_s(A) = \\max_{t \\in \\{1,\\dots,T\\}} d(S_t) $$\n这个估计器提供了真实 $\\delta_s(A)$ 的一个下界。\n\n实验设计规定了感知矩阵 $A$ 的构造方法。其元素独立地从高斯分布 $\\mathcal{N}(0, 1/m)$ 中抽取。随后，它的 $n$ 个列都被归一化为单位 $\\ell_2$ 范数。这种归一化是一个标准惯例，并确保了当 $s=1$ 时，子矩阵 $A_S$ 是一个满足 $\\lVert a_j \\rVert_2 = 1$ 的单列 $a_j$。相应的格拉姆矩阵是一个 $1 \\times 1$ 的矩阵 $A_S^\\top A_S = [a_j^\\top a_j] = [1]$，其唯一的特征值为 $1$。因此，偏差为 $0$，这可作为对我们实现的一个有价值的合理性检查。\n\n每个测试用例 $(m, n, s)$ 的算法流程如下：\n1. 用固定的种子 $2025$ 初始化一个伪随机数生成器，以确保可复现性。\n2. 生成一个 $m \\times n$ 的矩阵 $A$，其元素从 $\\mathcal{N}(0, 1/m)$ 中抽取。\n3. 将 $A$ 的每一列归一化为单位 $\\ell_2$ 范数。\n4. 初始化一个变量 `max_deviation` 为 $0.0$。\n5. 执行 $T=250$ 次试验。在每次试验中：\n    a. 从 $\\{1, \\dots, n\\}$ 中无放回地随机选择一个大小为 $s$ 的支撑集 $S$。\n    b. 提取相应的子矩阵 $A_S$。\n    c. 计算格拉姆矩阵 $G_S = A_S^\\top A_S$。\n    d. 计算 $G_S$ 的特征值。由于 $G_S$ 是对称半正定的，因此使用针对厄米特矩阵的专门算法来保证准确性和效率。\n    e. 确定最小特征值 $\\lambda_{\\min}$ 和最大特征值 $\\lambda_{\\max}$。\n    f. 计算本次试验的偏差，$d(S) = \\max\\{1 - \\lambda_{\\min}, \\lambda_{\\max} - 1\\}$。注意，对于一个半正定矩阵，$\\lambda_{\\min} \\ge 0$，且理论预测它应接近 $1$，所以 $|1-\\lambda_{\\min}| \\approx 1-\\lambda_{\\min}$。\n    g. 如果当前试验的偏差更大，则用它更新 `max_deviation`。\n6. `max_deviation` 的最终值即为给定参数下的估计 RIC，$\\widehat{\\delta}_s(A)$。\n\n根据压缩感知理论，我们预期结果中会呈现以下趋势：\n- **对稀疏度 ($s$) 的依赖性**：RIC $\\delta_s(A)$ 随 $s$ 单调非递减。随着 $s$ 的增加，$s$-稀疏向量的集合扩大，组合最大化是在一个更大的子矩阵族上进行的，这使得找到一个其格拉姆矩阵 (Gramian) 的特征值远离 1 的“坏”子矩阵的可能性更大。我们的估计值 $\\widehat{\\delta}_s(A)$ 应该表现出类似的增长趋势。\n- **对测量数 ($m$) 的依赖性**：对于固定的 $n$ 和 $s$，增加测量数 $m$（从而增加采样率 $m/n$）能提供更多信息，并使线性系统更超定。这通常会改善 RIP，使得 $A_S^\\top A_S$ 的特征值更紧密地集中在 $1$ 附近。因此，我们预期随着 $m$ 的增加，$\\delta_s(A)$ 和我们的估计值 $\\widehat{\\delta}_s(A)$ 会减小。\n测试套件旨在探究这些行为，例如，通过比较具有相同 $(n,s)$ 但不同 $m$ 的情况，或具有相同 $(m,n)$ 但不同 $s$ 的情况。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the RIC estimation experiments and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (m, n, s)\n        (80, 200, 1),\n        (80, 200, 10),\n        (40, 200, 10),\n        (120, 200, 20),\n        (60, 200, 50),\n        (40, 200, 50),\n    ]\n    \n    # Number of Monte Carlo trials\n    T = 250\n    # Seed for reproducibility\n    seed = 2025\n\n    # A single random number generator for all experiments to ensure reproducibility\n    rng = np.random.default_rng(seed)\n\n    def estimate_ric(m, n, s, T, rng):\n        \"\"\"\n        Estimates the Restricted Isometry Constant (RIC) for a random Gaussian matrix.\n\n        Args:\n            m (int): Number of rows (measurements).\n            n (int): Number of columns (ambient dimension).\n            s (int): Sparsity level.\n            T (int): Number of Monte Carlo trials.\n            rng (np.random.Generator): Random number generator instance.\n\n        Returns:\n            float: The estimated RIC, delta_s.\n        \"\"\"\n        # Step 1: Construct the random matrix A with N(0, 1/m) entries.\n        A = rng.normal(loc=0.0, scale=np.sqrt(1.0 / m), size=(m, n))\n\n        # Step 2: Normalize the columns of A to have unit l2 norm.\n        col_norms = np.linalg.norm(A, axis=0)\n        # Avoid division by zero, though highly improbable with a continuous distribution.\n        col_norms[col_norms == 0] = 1.0\n        A = A / col_norms\n\n        max_deviation = 0.0\n\n        if s == 0:\n            return 0.0\n\n        # Step 3: Perform T independent trials.\n        for _ in range(T):\n            # a. Draw a random support set S of size s without replacement.\n            support_S = rng.choice(n, size=s, replace=False)\n\n            # b. Form the submatrix A_S.\n            A_S = A[:, support_S]\n\n            # c. Compute the Gram matrix G_S = A_S^T * A_S.\n            G_S = A_S.T @ A_S\n\n            # d. Compute the eigenvalues of G_S.\n            # G_S is a real symmetric matrix, so use eigvalsh for efficiency\n            # and numerical stability. It returns sorted eigenvalues.\n            eigenvalues = np.linalg.eigvalsh(G_S)\n\n            lambda_min = eigenvalues[0]\n            lambda_max = eigenvalues[-1]\n\n            # e. Compute the trial deviation.\n            deviation = max(abs(lambda_min - 1.0), abs(lambda_max - 1.0))\n\n            # f. Update the overall maximum deviation.\n            if deviation > max_deviation:\n                max_deviation = deviation\n        \n        return max_deviation\n\n    results = []\n    for m, n, s in test_cases:\n        result = estimate_ric(m, n, s, T, rng)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Each floating-point number is rounded to exactly 6 decimal places.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "从随机矩阵转向结构化矩阵，我们可以更深入地探究RIC的本质。虽然随机矩阵通常具有良好的平均RIP特性，但现实世界中的矩阵可能包含特定的结构，从而产生“最坏情况”的子矩阵。本练习旨在挑战您为具有已知相关块的矩阵找到精确的RIC ，揭示矩阵结构如何直接影响该常数，并加深您对RIC作为一种最坏情况保证的理解。",
            "id": "3489942",
            "problem": "考虑一个实传感矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其列 $\\{a_{j}\\}_{j=1}^{n}$ 均为单位范数列，并回顾限制等距性质 (RIP)：$s$阶限制等距常数 (RIC) $\\delta_{s}$ 是满足以下条件的最小数 $\\delta \\geq 0$，即对于所有 $s$-稀疏向量 $x \\in \\mathbb{R}^{n}$，\n$$(1-\\delta)\\|x\\|_{2}^{2} \\leq \\|Ax\\|_{2}^{2} \\leq (1+\\delta)\\|x\\|_{2}^{2}。$$\n等价地，对于每个大小为 $|S|=s$ 的支撑集 $S \\subset [n]$，$s \\times s$ 的格拉姆矩阵 $G_{S} := A_{S}^{\\top} A_{S}$ 满足 $\\|G_{S}-I\\|_{2} \\leq \\delta$，其中 $I$ 是 $s \\times s$ 的单位矩阵。\n\n现在假设 $A$ 具有以下结构。存在一个索引集 $C \\subset [n]$，其大小为 $|C|=r$，以及一个固定的相关参数 $\\mu$，$0  \\mu  1$，使得：\n- 对所有不同的 $i,j \\in C$，有 $a_{i}^{\\top} a_{j}=\\mu$，且对所有 $i \\in C$，有 $a_{i}^{\\top} a_{i}=1$。\n- 对所有 $k \\notin C$，列 $\\{a_{k}\\}_{k \\notin C}$ 是相互标准正交的，并且每个 $a_{k}$（其中 $k \\notin C$）都与每个 $a_{i}$（其中 $i \\in C$）正交。\n\n固定一个整数 $s$，满足 $2 \\leq s \\leq r$。考虑对抗性支撑选择：在所有大小为 $|S|=s$ 的支撑集 $S \\subset [n]$ 中，寻找那些使谱范数偏差 $\\|A_{S}^{\\top} A_{S}-I\\|_{2}$ 最大化的 $S$，即在RIP意义下条件最差的 $s$-列子矩阵。\n\n从上述核心定义出发，仅使用标准线性代数，完成以下任务：\n- 确定使 $\\|A_{S}^{\\top} A_{S}-I\\|_{2}$ 最大化的支撑集 $S$ 的结构。\n- 计算 $\\max_{|S|=s}\\|A_{S}^{\\top} A_{S}-I\\|_{2}$ 的精确值，用 $\\mu$ 和 $s$ 表示。\n- 对于 $2 \\leq s \\leq r$，推导出 $A$ 的限制等距常数 $\\delta_{s}$ 的精确解析表达式。\n\n你的最终答案必须是关于 $\\mu$ 和 $s$ 的单个闭式表达式。不需要四舍五入，也没有单位。",
            "solution": "### 第1步：提取已知条件\n-   传感矩阵：$A \\in \\mathbb{R}^{m \\times n}$\n-   $A$的列：$\\{a_j\\}_{j=1}^{n}$ 是单位范数列，即对所有 $j \\in [n]$ 都有 $a_j^{\\top} a_j = 1$。\n-   限制等距常数 (RIC) $\\delta_s$：对于所有 $s$-稀疏向量 $x \\in \\mathbb{R}^{n}$，满足 $(1-\\delta)\\|x\\|_{2}^{2} \\leq \\|Ax\\|_{2}^{2} \\leq (1+\\delta)\\|x\\|_{2}^{2}$ 的最小数 $\\delta \\geq 0$。\n-   RIC的等价定义：$\\delta_s = \\max_{S \\subset [n], |S|=s} \\|A_{S}^{\\top} A_{S} - I\\|_{2}$，其中 $A_S$ 是由 $A$ 中索引为 $S$ 的列组成的子矩阵，$I$ 是 $s \\times s$ 单位矩阵。\n-   索引集 $C \\subset [n]$，其大小为 $|C|=r$。\n-   相关参数 $\\mu$，满足 $0  \\mu  1$。\n-   $A$的结构：\n    1.  对所有不同的 $i, j \\in C$，$a_i^{\\top} a_j = \\mu$。\n    2.  对所有 $k \\notin C$，列 $\\{a_k\\}_{k \\notin C}$ 是相互标准正交的，即 $a_k^{\\top} a_l = \\delta_{kl}$ (克罗内克δ)。\n    3.  对所有 $i \\in C$ 和 $k \\notin C$，$a_i^{\\top} a_k = 0$。\n-   稀疏度 $s$ 是一个整数，满足 $2 \\leq s \\leq r$。\n\n### 第2步：使用提取的已知条件进行验证\n问题陈述具有科学依据，是适定且客观的。\n1.  **科学或事实不健全**：该问题植根于压缩感知和线性代数的既定数学框架。限制等距性质是一个标准概念。没有违反任何科学原理。\n2.  **无法形式化或不相关**：该问题是一个形式化的数学练习，直接关系到限制等距性质这一主题。\n3.  **不完整或矛盾的设置**：问题提供了所有必要的定义、常数和条件。关于矩阵 $A$ 的条件是具体且一致的。约束 $s \\leq r$ 确保可以从相关集 $C$ 中选择 $s$ 列。\n4.  **不切实际或不可行**：构造这样一个矩阵 $A$ 在数学上是可行的（例如，通过块对角格拉姆矩阵和随后的Cholesky分解或Gram-Schmidt过程）。\n5.  **不适定或结构不良**：目标是明确的：在一个有限的可能性集合上找到一个明确定义量的最大值。预期会有一个唯一的解。所有术语都是该领域的标准术语。\n6.  **伪深刻、琐碎或同义反复**：该问题要求对支撑集 $S$ 的选择如何影响 $A_S^{\\top} A_S - I$ 的谱范数进行结构化分析，这涉及理解结构化矩阵的特征值。这并非易事。\n7.  **超出科学可验证性**：这些主张完全在数学证明的范畴内。\n\n### 第3步：结论与行动\n问题是有效的。我将继续提供完整解答。\n\n### 解答\n主要目标是计算给定矩阵 $A$ 的 $s$ 阶限制等距常数 (RIC) $\\delta_s$。根据定义，它由下式给出：\n$$ \\delta_s = \\max_{S \\subset [n], |S|=s} \\|A_S^{\\top} A_S - I_s\\|_2 $$\n其中 $S$ 是大小为 $s$ 的支撑集，$A_S$ 是包含由 $S$ 索引的列的 $A$ 的子矩阵，$I_s$ 是 $s \\times s$ 单位矩阵。矩阵 $G_S = A_S^{\\top} A_S$ 是 $A_S$ 中各列的格拉姆矩阵。\n\n让我们根据支撑集 $S$ 的构成来分析 $G_S$ 的结构。任何大小为 $s$ 的支撑集 $S$ 都可以划分为两个不相交的子集：$S_C = S \\cap C$ 和 $S_{C^c} = S \\cap ([n] \\setminus C)$。设 $k = |S_C|$，则 $0 \\leq k \\leq s$。因此，有 $|S_{C^c}| = s-k$。\n\n由 $S_C$ 索引的列都来自相关集 $C$。由 $S_{C^c}$ 索引的列来自 $C$ 之外的标准正交集。根据问题陈述，$C$ 中的任何列都与不在 $C$ 中的任何列正交。因此，对于 $i \\in S_C$ 和 $j \\in S_{C^c}$，我们有 $a_i^{\\top} a_j = 0$。\n\n这种正交性意味着，在经过适当的行和列置换（这不会改变谱范数）后，格拉姆矩阵 $G_S$ 是块对角的：\n$$ G_S = A_S^{\\top} A_S = \\begin{pmatrix} A_{S_C}^{\\top} A_{S_C}  A_{S_C}^{\\top} A_{S_{C^c}} \\\\ A_{S_{C^c}}^{\\top} A_{S_C}  A_{S_{C^c}}^{\\top} A_{S_{C^c}} \\end{pmatrix} = \\begin{pmatrix} G_{S_C}  \\mathbf{0} \\\\ \\mathbf{0}  G_{S_{C^c}} \\end{pmatrix} $$\n其中 $G_{S_C}$ 是 $S_C$ 中列的 $k \\times k$ 格拉姆矩阵，$G_{S_{C^c}}$ 是 $S_{C^c}$ 中列的 $(s-k) \\times (s-k)$ 格拉姆矩阵。\n\n让我们分析这两个块：\n1.  由 $S_{C^c}$ 索引的列是相互标准正交的。因此，它们的格拉姆矩阵是单位矩阵：$G_{S_{C^c}} = I_{s-k}$。\n2.  由 $S_C$ 索引的列都具有单位范数，并且它们的成对内积为 $\\mu$。因此，$G_{S_C}$ 是一个 $k \\times k$ 矩阵，其对角线上为1，所有非对角线元素为 $\\mu$。我们将此矩阵表示为 $M_k$。\n$$ M_k = \\begin{pmatrix} 1  \\mu  \\dots  \\mu \\\\ \\mu  1  \\dots  \\mu \\\\ \\vdots  \\vdots  \\ddots  \\vdots \\\\ \\mu  \\mu  \\dots  1 \\end{pmatrix}_{k \\times k} $$\n\n那么矩阵 $G_S - I_s$ 是：\n$$ G_S - I_s = \\begin{pmatrix} M_k  \\mathbf{0} \\\\ \\mathbf{0}  I_{s-k} \\end{pmatrix} - \\begin{pmatrix} I_k  \\mathbf{0} \\\\ \\mathbf{0}  I_{s-k} \\end{pmatrix} = \\begin{pmatrix} M_k - I_k  \\mathbf{0} \\\\ \\mathbf{0}  \\mathbf{0} \\end{pmatrix} $$\n块对角矩阵的谱范数（最大奇异值）是其各块谱范数的最大值。因此：\n$$ \\|G_S - I_s\\|_2 = \\|M_k - I_k\\|_2 $$\n我们现在的任务是找到 $\\max_{0 \\leq k \\leq s} \\|M_k - I_k\\|_2$。\n\n让我们分析 $\\|M_k - I_k\\|_2$。矩阵 $M_k$ 可以写成 $M_k = (1-\\mu)I_k + \\mu J_k$，其中 $J_k$ 是 $k \\times k$ 的全1矩阵。那么矩阵 $M_k - I_k$ 是：\n$$ M_k - I_k = (1-\\mu)I_k + \\mu J_k - I_k = \\mu J_k - \\mu I_k = \\mu(J_k - I_k) $$\n这是一个对角线上为0，其他所有位置为 $\\mu$ 的矩阵。由于它是一个对称矩阵，其谱范数是其特征值的最大绝对值。让我们求 $J_k - I_k$ 的特征值。矩阵 $J_k$ 的特征值为 $k$（重数为1，特征向量为全1向量 $\\mathbf{1}$）和 $0$（重数为 $k-1$）。因此，$J_k - I_k$ 的特征值为 $k-1$ 和 $-1$（重数为 $k-1$）。\n\n$M_k - I_k = \\mu(J_k - I_k)$ 的特征值为 $\\mu(k-1)$（重数为1）和 $-\\mu$（重数为 $k-1$）。这个推导对于 $k \\geq 2$ 是有效的。\n\n让我们考虑 $k \\in \\{0, 1, \\dots, s\\}$ 的可能值：\n-   如果 $k=0$，支撑集 $S$ 完全在 $C^c$ 中。$S_C$ 为空，所以 $M_0$ 是一个空矩阵，且 $\\|M_0-I_0\\|_2=0$。\n-   如果 $k=1$，$S$ 包含一个来自 $C$ 的列和 $s-1$ 个来自 $C^c$ 的列。这 $s$ 列是相互正交的，所以 $G_S=I_s$ 且 $\\|G_S-I_s\\|_2 = 0$。另外，$M_1$ 是 $1 \\times 1$ 矩阵 $[1]$，所以 $M_1 - I_1 = [0]$，其范数为0。\n-   如果 $k \\geq 2$，$M_k - I_k$ 的特征值为 $\\mu(k-1)$ 和 $-\\mu$。谱范数是它们绝对值的最大值：\n    $$ \\|M_k - I_k\\|_2 = \\max (|\\mu(k-1)|, |-\\mu|) $$\n    由于 $0  \\mu  1$ 且 $k \\geq 2$，我们有 $\\mu(k-1) > 0$。所以，\n    $$ \\|M_k - I_k\\|_2 = \\max (\\mu(k-1), \\mu) $$\n    由于 $k \\geq 2$，有 $k-1 \\geq 1$。因此，$\\mu(k-1) \\geq \\mu$。这将范数简化为：\n    $$ \\|M_k - I_k\\|_2 = \\mu(k-1) \\quad \\text{for } k \\geq 2 $$\n\n为了找到 $\\delta_s$，我们必须在 $k$ 的所有可能值上最大化这个范数：\n$$ \\delta_s = \\max_{k \\in \\{0, 1, \\dots, s\\}} \\|M_k - I_k\\|_2 $$\n设 $f(k) = \\|M_k - I_k\\|_2$。我们有：\n$$ f(k) = \\begin{cases} 0  \\text{if } k=0, 1 \\\\ \\mu(k-1)  \\text{if } 2 \\leq k \\leq s \\end{cases} $$\n函数 $f(k)$ 在 $k \\in \\{0, 1, \\dots, s\\}$ 上是非递减的。最大值在 $k$ 的最大可能值处取得，即 $k=s$。问题陈述 $s \\geq 2$，所以这种情况是相关的。条件 $s \\leq r$ 确保可以从集合 $C$ 中选择 $s$ 列，即可以有 $k=s$。\n\n最大值为 $f(s)=\\mu(s-1)$。\n\n因此，我们可以得出结论：\n1.  **对抗性支撑的结构**：使 $\\|A_{S}^{\\top} A_{S}-I\\|_{2}$ 最大化的尺寸为 $s$ 的支撑集 $S$ 是那些完全从相关集 $C$ 中选择的集合。即，任何满足 $|S|=s$ 的 $S \\subset C$。\n2.  **最大范数值**：最大值为 $\\max_{|S|=s}\\|A_{S}^{\\top} A_{S}-I\\|_{2} = \\mu(s-1)$。\n3.  **限制等距常数 $\\delta_s$**：根据定义，$\\delta_s$ 就是这个最大值。\n    $$ \\delta_s = \\mu(s-1) $$\n\n这个表达式在给定范围 $2 \\leq s \\leq r$ 内有效。",
            "answer": "$$\\boxed{\\mu(s-1)}$$"
        },
        {
            "introduction": "最后，我们来探讨限定等距性质（RIP）的实际意义及其局限性。一个良好的RIP常数固然重要，但它是否是解决所有问题的万能钥匙？本练习  提供了一个发人深省的反例：即使对于 $s$-稀疏信号具有完美的RIP（即 $\\delta_s=0$），对于仅仅是*可压缩*（compressible）而非严格稀疏的信号，其恢复效果也可能并非理想。这个例子突显了精确稀疏性和可压缩性之间的重要区别，有助于您更准确地理解RIP在恢复保证中的作用。",
            "id": "3489943",
            "problem": "设 $A \\in \\mathbb{R}^{1 \\times 3}$ 是一个感知矩阵，其列向量为 $a_{1} = 1$，$a_{2} = 1$ 和 $a_{3} = 1$。考虑从无噪声测量值 $y = A x$ 中恢复信号 $x \\in \\mathbb{R}^{3}$ 的任务，该任务通过凸优化在满足测量约束的条件下最小化 $\\ell_{1}$ 范数。限制等距性质 (RIP) 及其限制等距常数 (RIC) $\\delta_{s}$ 定义为对于所有 $s$-稀疏的 $z \\in \\mathbb{R}^{3}$，满足\n$$\n(1 - \\delta) \\|z\\|_{2}^{2} \\leq \\|A z\\|_{2}^{2} \\leq (1 + \\delta) \\|z\\|_{2}^{2}\n$$\n的最小 $\\delta \\geq 0$。\n您的目标是证明，当真实信号是可压缩但非严格 $s$-稀疏时，一个小的 $\\delta_{s}$ 并不能保证对模型失配的鲁棒性，并量化恢复误差的恶化程度。\n\n具体来说：\n\n1. 仅使用限制等距常数的定义，计算给定矩阵 $A$ 的 $\\delta_{1}$。\n\n2. 设真实信号为 $x^{\\star} = (1, \\epsilon, 0)^{\\top}$，其中 $0  \\epsilon  1$，该信号是可压缩的但非严格 1-稀疏的。记 $y = A x^{\\star}$。构造一个可行点 $z^{\\flat}$，它在约束 $A z = y$ 下最小化 $\\|z\\|_{1}$ 并且是 1-稀疏的。\n\n3. 计算欧几里得误差 $\\|z^{\\flat} - x^{\\star}\\|_{2}$。设 $x_{1}$ 表示 $x^{\\star}$ 的最佳 1-稀疏近似（其获得方式为保留 $x^{\\star}$ 中最大幅值的元素，并将其余元素置零），并计算模型失配误差 $\\|x^{\\star} - x_{1}\\|_{2}$。\n\n4. 定义恶化因子\n$$\nR(\\epsilon) := \\frac{\\|z^{\\flat} - x^{\\star}\\|_{2}}{\\|x^{\\star} - x_{1}\\|_{2}}。\n$$\n精确计算 $R(\\epsilon)$ 并将其表示为单一的封闭形式值。无需四舍五入，也无物理单位。您的最终答案必须是一个实数值或一个解析表达式。",
            "solution": "该问题经评估在科学上是合理的、良定的和客观的。它在压缩感知的标准数学框架内提出了一组明确的任务。解决问题所需的所有数据和定义都已提供，且无内部矛盾。我们可以开始求解。\n\n该问题要求进行一个分为四部分的分析，内容关于使用给定感知矩阵通过 $\\ell_{1}$-最小化来恢复信号。该矩阵是 $A \\in \\mathbb{R}^{1 \\times 3}$，定义为 $A = \\begin{pmatrix} 1  1  1 \\end{pmatrix}$。\n\n**第一部分：计算限制等距常数 $\\delta_{1}$。**\n\n限制等距常数 $\\delta_{s}$ 是对于所有 $s$-稀疏向量 $z$ 满足不等式\n$$\n(1 - \\delta) \\|z\\|_{2}^{2} \\leq \\|A z\\|_{2}^{2} \\leq (1 + \\delta) \\|z\\|_{2}^{2}\n$$\n的最小非负数 $\\delta$。我们被要求计算 $\\delta_{1}$。\n\n一个 1-稀疏向量 $z \\in \\mathbb{R}^{3}$ 是一个最多只有一个非零元素的向量。设 $z$ 是一个一般的 1-稀疏向量。它可以写成以下三种形式之一：\n$z = \\begin{pmatrix} c \\\\ 0 \\\\ 0 \\end{pmatrix}$，$z = \\begin{pmatrix} 0 \\\\ c \\\\ 0 \\end{pmatrix}$，或 $z = \\begin{pmatrix} 0 \\\\ 0 \\\\ c \\end{pmatrix}$，对于某个标量 $c \\in \\mathbb{R}$。\n\n在这三种情况下，$z$ 的欧几里得范数的平方均为 $\\|z\\|_{2}^{2} = c^{2}$。\n\n现在我们为每种情况计算 $\\|A z\\|_{2}^{2}$：\n1.  对于 $z = \\begin{pmatrix} c \\\\ 0 \\\\ 0 \\end{pmatrix}$，$Az = \\begin{pmatrix} 1  1  1 \\end{pmatrix} \\begin{pmatrix} c \\\\ 0 \\\\ 0 \\end{pmatrix} = c$。因此，$\\|Az\\|_{2}^{2} = c^{2}$。\n2.  对于 $z = \\begin{pmatrix} 0 \\\\ c \\\\ 0 \\end{pmatrix}$，$Az = \\begin{pmatrix} 1  1  1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ c \\\\ 0 \\end{pmatrix} = c$。因此，$\\|Az\\|_{2}^{2} = c^{2}$。\n3.  对于 $z = \\begin{pmatrix} 0 \\\\ 0 \\\\ c \\end{pmatrix}$，$Az = \\begin{pmatrix} 1  1  1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ c \\end{pmatrix} = c$。因此，$\\|Az\\|_{2}^{2} = c^{2}$。\n\n对于任何 1-稀疏向量 $z$ 的每种情况，我们都已证明 $\\|A z\\|_{2}^{2} = \\|z\\|_{2}^{2}$。\n\n将此代入 $s=1$ 的 RIP 定义中：\n$$\n(1 - \\delta_{1}) \\|z\\|_{2}^{2} \\leq \\|z\\|_{2}^{2} \\leq (1 + \\delta_{1}) \\|z\\|_{2}^{2}\n$$\n假设 $z$ 不是零向量（对于零向量，不等式是平凡的），我们可以除以 $\\|z\\|_{2}^{2}$：\n$$\n1 - \\delta_{1} \\leq 1 \\quad \\text{和} \\quad 1 \\leq 1 + \\delta_{1}\n$$\n第一个不等式意味着 $\\delta_{1} \\geq 0$。第二个不等式也意味着 $\\delta_{1} \\geq 0$。满足这些条件的 $\\delta_{1}$ 的最小非负值为 $\\delta_{1} = 0$。\n\n**第二部分：构造恢复信号 $z^{\\flat}$。**\n\n真实信号为 $x^{\\star} = \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ 0 \\end{pmatrix}$，其中 $0  \\epsilon  1$。\n无噪声测量值为 $y = A x^{\\star} = \\begin{pmatrix} 1  1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ 0 \\end{pmatrix} = 1 + \\epsilon$。\n\n任务是找到一个向量 $z^{\\flat}$，它在约束 $A z = y$ 下最小化 $\\ell_{1}$-范数 $\\|z\\|_{1}$，并且具有 $z^{\\flat}$ 必须是 1-稀疏的附加属性。\n\n约束为 $z_{1} + z_{2} + z_{3} = 1+\\epsilon$。目标是最小化 $\\|z\\|_{1} = |z_{1}| + |z_{2}| + |z_{3}|$。\n根据三角不等式，对于任何可行的 $z$：\n$$\n\\|z\\|_{1} = |z_{1}| + |z_{2}| + |z_{3}| \\geq |z_{1} + z_{2} + z_{3}| = |1+\\epsilon|\n$$\n因为 $0  \\epsilon  1$，我们有 $1+\\epsilon > 0$，所以 $|1+\\epsilon| = 1+\\epsilon$。因此，$\\|z\\|_{1}$ 的最小可能值为 $1+\\epsilon$。\n\n我们必须找到一个 1-稀疏向量 $z^{\\flat}$，它满足 $A z^{\\flat} = 1+\\epsilon$ 并达到这个最小范数 $\\|z^{\\flat}\\|_{1} = 1+\\epsilon$。让我们检验一下可能的 1-稀疏向量：\n1.  $z = \\begin{pmatrix} c \\\\ 0 \\\\ 0 \\end{pmatrix}$：$A z = c$。所以，$c=1+\\epsilon$。这得到 $z^{(1)} = \\begin{pmatrix} 1+\\epsilon \\\\ 0 \\\\ 0 \\end{pmatrix}$。其 $\\ell_{1}$-范数为 $\\|z^{(1)}\\|_{1} = |1+\\epsilon| = 1+\\epsilon$。\n2.  $z = \\begin{pmatrix} 0 \\\\ c \\\\ 0 \\end{pmatrix}$：$A z = c$。所以，$c=1+\\epsilon$。这得到 $z^{(2)} = \\begin{pmatrix} 0 \\\\ 1+\\epsilon \\\\ 0 \\end{pmatrix}$。其 $\\ell_{1}$-范数为 $\\|z^{(2)}\\|_{1} = |1+\\epsilon| = 1+\\epsilon$。\n3.  $z = \\begin{pmatrix} 0 \\\\ 0 \\\\ c \\end{pmatrix}$：$A z = c$。所以，$c=1+\\epsilon$。这得到 $z^{(3)} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1+\\epsilon \\end{pmatrix}$。其 $\\ell_{1}$-范数为 $\\|z^{(3)}\\|_{1} = |1+\\epsilon| = 1+\\epsilon$。\n\n这三个向量都是 1-稀疏的，满足测量约束，并达到最小 $\\ell_{1}$-范数。$\\ell_1$-最小化问题的解集实际上是这三个点的凸包。问题要求我们构造一个 1-稀疏的单点 $z^{\\flat}$。这意味着我们必须从 $z^{(1)}$、$z^{(2)}$ 或 $z^{(3)}$ 中选择一个。\n\n$z^{\\flat}$ 的选择会影响最终的误差计算。然而，问题要求恶化因子 $R(\\epsilon)$ 是一个单一的封闭形式值。正如我们将看到的，这些选择中只有一个能导出一个不依赖于 $\\epsilon$ 的常数 $R(\\epsilon)$ 结果。这表明题目意图一个特定的选择。最符合原则的选择是其稀疏模式与真实信号 $x^{\\star}$ 的最佳 1-稀疏近似相匹配的选择。$x^{\\star}$ 的最大分量是其第一个分量，所以其最佳 1-稀疏近似的非零项在第一个位置。因此，我们选择其非零项也在第一个位置的解 $z^{\\flat}$。\n\n因此，我们构造 $z^{\\flat} = z^{(1)} = \\begin{pmatrix} 1+\\epsilon \\\\ 0 \\\\ 0 \\end{pmatrix}$。\n\n**第三部分：计算欧几里得误差和模型失配误差。**\n\n恢复信号 $z^{\\flat}$ 与真实信号 $x^{\\star}$ 之间的欧几里得误差为：\n$$\n\\|z^{\\flat} - x^{\\star}\\|_{2} = \\left\\| \\begin{pmatrix} 1+\\epsilon \\\\ 0 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ 0 \\end{pmatrix} \\right\\|_{2} = \\left\\| \\begin{pmatrix} \\epsilon \\\\ -\\epsilon \\\\ 0 \\end{pmatrix} \\right\\|_{2} = \\sqrt{\\epsilon^{2} + (-\\epsilon)^{2} + 0^{2}} = \\sqrt{2\\epsilon^{2}} = \\epsilon\\sqrt{2}\n$$\n因为 $\\epsilon > 0$。\n\n接下来，我们求 $x_{1}$，即 $x^{\\star}$ 的最佳 1-稀疏近似。它的构成方法是保留 $x^{\\star}$ 中绝对值最大的元素，并将其他元素置零。\n给定 $x^{\\star} = \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ 0 \\end{pmatrix}$ 且 $0  \\epsilon  1$，最大幅值的元素是第一个元素，即 1。\n所以，$x_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$。\n\n模型失配误差是 $x^{\\star}$ 和 $x_{1}$ 之间的欧几里得距离：\n$$\n\\|x^{\\star} - x_{1}\\|_{2} = \\left\\| \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\right\\|_{2} = \\left\\| \\begin{pmatrix} 0 \\\\ \\epsilon \\\\ 0 \\end{pmatrix} \\right\\|_{2} = \\sqrt{0^{2} + \\epsilon^{2} + 0^{2}} = \\epsilon\n$$\n\n**第四部分：计算恶化因子 $R(\\epsilon)$。**\n\n恶化因子定义为上面计算的两个误差之比：\n$$\nR(\\epsilon) := \\frac{\\|z^{\\flat} - x^{\\star}\\|_{2}}{\\|x^{\\star} - x_{1}\\|_{2}}\n$$\n代入计算出的值：\n$$\nR(\\epsilon) = \\frac{\\epsilon\\sqrt{2}}{\\epsilon} = \\sqrt{2}\n$$\n这个结果是一个与 $\\epsilon$ 无关的常数，这与问题中答案必须是单一封闭形式值的隐含约束是一致的。这证实了我们对 $z^{\\flat}$ 的选择是题目所期望的。最终结果表明，即使对于 1-稀疏信号有完美的等距性（$\\delta_{1}=0$），对于可压缩信号的 $\\ell_{1}$-范数恢复误差也比最佳情况下的近似误差大 $\\sqrt{2}$ 倍。",
            "answer": "$$\\boxed{\\sqrt{2}}$$"
        }
    ]
}