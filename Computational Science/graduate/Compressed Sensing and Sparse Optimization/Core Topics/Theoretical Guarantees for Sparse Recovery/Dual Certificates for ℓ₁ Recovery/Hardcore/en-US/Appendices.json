{
    "hands_on_practices": [
        {
            "introduction": "The ability to guarantee that $\\ell_1$-minimization has found the correct sparse solution is central to compressed sensing theory. This practice provides a foundational exercise in constructing a \"dual certificate,\" a key piece of evidence for such a guarantee. You will build the canonical dual certificate for a Basis Pursuit problem and verify that it satisfies the necessary conditions for exact recovery, solidifying your understanding of the Karush-Kuhn-Tucker (KKT) conditions in action. ",
            "id": "3444698",
            "problem": "Consider the convex optimization problem of basis pursuit, which minimizes the $\\ell_{1}$-norm of a vector subject to linear equality constraints: minimize $\\|x\\|_{1}$ subject to $A x = y$, where $A \\in \\mathbb{R}^{m \\times n}$ has unit-norm columns and mutual coherence $\\mu$ defined by $\\mu = \\max_{i \\neq j} |a_{i}^{\\top} a_{j}|$, with $a_{j}$ denoting the $j$-th column of $A$. A dual certificate for exact $\\ell_{1}$ recovery is a vector $z \\in \\mathbb{R}^{m}$ satisfying $A_{S}^{\\top} z = \\mathrm{sgn}(x_{S})$ and $\\|A_{S^{c}}^{\\top} z\\|_{\\infty}  1$, where $S$ is the support of the sparse solution $x$, $S^{c}$ is its complement, and $\\mathrm{sgn}(x_{S})$ is the sign pattern of $x$ restricted to $S$. Starting from the definitions of mutual coherence and the characterization of dual certificates via the Karush–Kuhn–Tucker (KKT) optimality conditions, construct and verify a dual certificate.\n\nLet $A \\in \\mathbb{R}^{3 \\times 3}$ have columns\n$$\na_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad\na_{2} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad\na_{3} = \\begin{pmatrix} \\tfrac{1}{4} \\\\ \\tfrac{1}{4} \\\\ \\sqrt{\\tfrac{7}{8}} \\end{pmatrix},\n$$\nso that all columns have unit Euclidean norm and mutual coherence $\\mu = \\tfrac{1}{4}$. Let the support be $S = \\{1, 2\\}$ and let the sign vector be $\\mathrm{sgn}(x_{S}) = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. Using the coherence definition and the KKT conditions for dual feasibility, explicitly compute\n$$\nz^{\\star} = A_{S} \\big(A_{S}^{\\top} A_{S}\\big)^{-1} \\mathrm{sgn}(x_{S})\n$$\nand verify $\\|A_{S^{c}}^{\\top} z^{\\star}\\|_{\\infty}  1$.\n\nProvide the final answer as the explicit closed-form vector $z^{\\star}$ in exact form. No rounding is required.",
            "solution": "The problem requires the construction and verification of a dual certificate for $\\ell_{1}$ recovery in the context of compressed sensing. We are given a specific matrix $A$, a support set $S$, and a sign pattern on that support. We must compute a candidate dual certificate $z^{\\star}$ using a provided formula and then verify that it satisfies the necessary optimality condition.\n\nFirst, let us formalize the given information. The dictionary matrix $A \\in \\mathbb{R}^{3 \\times 3}$ has columns:\n$$\na_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad\na_{2} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad\na_{3} = \\begin{pmatrix} \\frac{1}{4} \\\\ \\frac{1}{4} \\\\ \\sqrt{\\frac{7}{8}} \\end{pmatrix}\n$$\nThe support of the sparse solution is given as $S = \\{1, 2\\}$, and the sign vector on this support is $\\mathrm{sgn}(x_{S}) = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. The complement of the support set is $S^{c} = \\{3\\}$.\n\nThe candidate dual certificate, which is the minimum $\\ell_{2}$-norm vector $z$ satisfying the Karush-Kuhn-Tucker (KKT) condition on the support set, is given by the formula:\n$$\nz^{\\star} = A_{S} \\left(A_{S}^{\\top} A_{S}\\right)^{-1} \\mathrm{sgn}(x_{S})\n$$\nOur first step is to construct the matrix $A_{S}$, which is formed by the columns of $A$ indexed by the set $S$.\n$$\nA_{S} = \\begin{pmatrix} a_{1}  a_{2} \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 0  0 \\end{pmatrix}\n$$\nNext, we compute the Gram matrix $A_{S}^{\\top} A_{S}$.\n$$\nA_{S}^{\\top} A_{S} = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} (1)(1)+(0)(0)+(0)(0)  (1)(0)+(0)(1)+(0)(0) \\\\ (0)(1)+(1)(0)+(0)(0)  (0)(0)+(1)(1)+(0)(0) \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}\n$$\nThe Gram matrix is the $2 \\times 2$ identity matrix, $I_{2}$. The inverse is simply the identity matrix itself.\n$$\n\\left(A_{S}^{\\top} A_{S}\\right)^{-1} = I_{2}^{-1} = I_{2} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}\n$$\nNow we can compute $z^{\\star}$ by substituting the components into the formula.\n$$\nz^{\\star} = A_{S} \\left(A_{S}^{\\top} A_{S}\\right)^{-1} \\mathrm{sgn}(x_{S}) = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n$$\nz^{\\star} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} (1)(1) + (0)(1) \\\\ (0)(1) + (1)(1) \\\\ (0)(1) + (0)(1) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\nHaving computed the candidate dual certificate $z^{\\star}$, we must verify that it satisfies the strict inequality condition for dual feasibility on the off-support set $S^{c}$. The condition is $\\|A_{S^{c}}^{\\top} z^{\\star}\\|_{\\infty}  1$.\n\nThe matrix $A_{S^{c}}$ is composed of the columns of $A$ indexed by $S^{c} = \\{3\\}$.\n$$\nA_{S^{c}} = a_{3} = \\begin{pmatrix} \\frac{1}{4} \\\\ \\frac{1}{4} \\\\ \\sqrt{\\frac{7}{8}} \\end{pmatrix}\n$$\nWe compute the product $A_{S^{c}}^{\\top} z^{\\star}$:\n$$\nA_{S^{c}}^{\\top} z^{\\star} = a_{3}^{\\top} z^{\\star} = \\begin{pmatrix} \\frac{1}{4}  \\frac{1}{4}  \\sqrt{\\frac{7}{8}} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\nA_{S^{c}}^{\\top} z^{\\star} = \\left(\\frac{1}{4}\\right)(1) + \\left(\\frac{1}{4}\\right)(1) + \\left(\\sqrt{\\frac{7}{8}}\\right)(0) = \\frac{1}{4} + \\frac{1}{4} + 0 = \\frac{2}{4} = \\frac{1}{2}\n$$\nSince $S^{c}$ contains only one index, the result is a scalar. The infinity norm of a scalar is its absolute value.\n$$\n\\|A_{S^{c}}^{\\top} z^{\\star}\\|_{\\infty} = \\left|\\frac{1}{2}\\right| = \\frac{1}{2}\n$$\nThe verification step is to check if this value is less than $1$.\n$$\n\\frac{1}{2}  1\n$$\nThis inequality is true. Therefore, the vector $z^{\\star}$ is a valid dual certificate. The problem asks for the explicit vector $z^{\\star}$ as the final answer.\n$$\nz^{\\star} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\nThis completes the required computation and verification.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "While Basis Pursuit is a fundamental model, many practical applications use the LASSO formulation to balance data fidelity with sparsity. This exercise extends the concept of dual certificates to the LASSO setting, where the regularization parameter $\\lambda$ plays a crucial role. By working through this problem, you will see how the dual certificate conditions are adapted for LASSO and how to verify them in a concrete numerical example. ",
            "id": "3444688",
            "problem": "Consider the least absolute shrinkage and selection operator (LASSO) problem in compressed sensing and sparse optimization, defined by minimizing the objective function $$f(x) = \\frac{1}{2}\\|y - A x\\|_{2}^{2} + \\lambda \\|x\\|_{1},$$ where $A \\in \\mathbb{R}^{m \\times n}$ is a sensing matrix, $y \\in \\mathbb{R}^{m}$ is the measurement vector, and $\\lambda  0$ is a regularization parameter. The set $S \\subset \\{1,\\dots,n\\}$ denotes a candidate support, and $\\mathrm{sgn}(x_{S})$ denotes the vector of signs of the entries of $x$ restricted to the set $S$.\n\nStarting from the definitions of the subdifferential of the $\\ell_{1}$ norm and the Karush-Kuhn-Tucker (KKT) optimality conditions for convex optimization, derive the dual certificate conditions that a residual vector $z = y - A x$ must satisfy at an optimal solution $x^{\\star}$ with support $S$. Then, for the specific data\n$$\nA = \\begin{pmatrix}\n2  1  \\frac{1}{4}  1 \\\\\n1  3  \\frac{1}{2}  0\n\\end{pmatrix}, \\quad\ny = \\begin{pmatrix}\n\\frac{7}{10} \\\\\n-\\frac{9}{10}\n\\end{pmatrix}, \\quad\nS = \\{1,2\\}, \\quad\n\\mathrm{sgn}(x_{S}) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix},\n$$\ncompute a vector $z \\in \\mathbb{R}^{2}$ that satisfies the on-support dual certificate relation $$A_{S}^{\\top} z = \\lambda\\,\\mathrm{sgn}(x_{S}),$$ where $A_{S}$ denotes the submatrix of $A$ formed by the columns indexed by $S$, and verify the off-support bound $$\\|A_{S^{c}}^{\\top} z\\|_{\\infty}  \\lambda,$$ where $A_{S^{c}}$ is the submatrix formed by the columns indexed by the complement $S^{c}$. Finally, define the certification ratio\n$$\n\\rho \\triangleq \\frac{\\|A_{S^{c}}^{\\top} z\\|_{\\infty}}{\\lambda},\n$$\nand compute its exact value for the given data. Express your final numerical answer for $\\rho$ as an exact fraction with no rounding.",
            "solution": "The user has provided a problem from the field of sparse optimization, asking for a derivation of dual certificate conditions for a LASSO solution and a subsequent calculation based on specific data.\n\n### Step 1: Derivation of the Dual Certificate Conditions\n\nThe LASSO objective function is given by:\n$$f(x) = \\frac{1}{2}\\|y - A x\\|_{2}^{2} + \\lambda \\|x\\|_{1}$$\nwhere $x \\in \\mathbb{R}^n$, $y \\in \\mathbb{R}^m$, $A \\in \\mathbb{R}^{m \\times n}$, and $\\lambda  0$. This function is convex, being the sum of a differentiable convex function $g(x) = \\frac{1}{2}\\|y - A x\\|_{2}^{2}$ and a non-differentiable convex function $h(x) = \\lambda \\|x\\|_{1}$.\n\nThe first-order optimality condition for a minimizer $x^{\\star}$ is given by the Karush-Kuhn-Tucker (KKT) conditions, which for this problem structure state that the zero vector must be in the sum of the gradient of the differentiable part and the subdifferential of the non-differentiable part:\n$$0 \\in \\nabla g(x^{\\star}) + \\partial h(x^{\\star})$$\n\nFirst, we compute the gradient of $g(x)$:\n$$\\nabla g(x) = \\nabla_{x} \\left( \\frac{1}{2}(y - Ax)^{\\top}(y - Ax) \\right) = A^{\\top}(Ax - y) = -A^{\\top}(y - Ax)$$\nAt the optimal solution $x^{\\star}$, we define the residual vector as $z = y - A x^{\\star}$. The gradient is then $\\nabla g(x^{\\star}) = -A^{\\top}z$.\n\nNext, we find the subdifferential of $h(x) = \\lambda \\|x\\|_{1} = \\lambda \\sum_{i=1}^{n} |x_i|$. The subdifferential $\\partial h(x)$ is the set of all subgradient vectors $v \\in \\mathbb{R}^n$ whose components $v_i$ satisfy:\n$$v_i \\in \\lambda \\cdot \\partial |x_i| = \\begin{cases} \\{\\lambda \\, \\mathrm{sgn}(x_i)\\}  \\text{if } x_i \\neq 0 \\\\ [-\\lambda, \\lambda]  \\text{if } x_i = 0 \\end{cases}$$\n\nSubstituting these into the optimality condition, we get:\n$$0 \\in -A^{\\top}z + \\partial h(x^{\\star}) \\iff A^{\\top}z \\in \\partial h(x^{\\star})$$\nLet $S = \\mathrm{supp}(x^{\\star}) = \\{i \\mid x_i^{\\star} \\neq 0\\}$ be the support of the optimal solution and $S^c$ be its complement. The condition $A^{\\top}z \\in \\partial h(x^{\\star})$ can be separated into conditions on the support $S$ and off the support $S^c$:\n1.  For indices $i \\in S$, we have $x_i^{\\star} \\neq 0$, so $(A^{\\top}z)_i = \\lambda \\, \\mathrm{sgn}(x_i^{\\star})$.\n2.  For indices $i \\in S^c$, we have $x_i^{\\star} = 0$, so $|(A^{\\top}z)_i| \\leq \\lambda$.\n\nFor $x^{\\star}$ to be the unique minimizer, the off-support condition is typically required to be strict. Using the submatrix notation where $A_S$ consists of columns of $A$ indexed by $S$, the dual certificate conditions are:\n- (On-support) $A_{S}^{\\top} z = \\lambda\\,\\mathrm{sgn}(x_{S}^{\\star})$\n- (Off-support) $\\|A_{S^{c}}^{\\top} z\\|_{\\infty}  \\lambda$\n\n### Step 2: Computation for the Given Data\n\nWe are given the following data:\n$$\nA = \\begin{pmatrix}\n2  1  \\frac{1}{4}  1 \\\\\n1  3  \\frac{1}{2}  0\n\\end{pmatrix}, \\quad\ny = \\begin{pmatrix}\n\\frac{7}{10} \\\\\n-\\frac{9}{10}\n\\end{pmatrix}, \\quad\nS = \\{1,2\\}, \\quad\n\\mathrm{sgn}(x_{S}) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\n$$\nThe support is $S=\\{1,2\\}$, so the complement is $S^c=\\{3,4\\}$. The corresponding submatrices of $A$ are:\n$$\nA_S = \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix}, \\quad\nA_{S^c} = \\begin{pmatrix} \\frac{1}{4}  1 \\\\ \\frac{1}{2}  0 \\end{pmatrix}\n$$\n\nFirst, we compute the vector $z \\in \\mathbb{R}^2$ that satisfies the on-support relation $A_S^\\top z = \\lambda \\cdot \\mathrm{sgn}(x_S)$. Since $A_S$ is symmetric, $A_S^\\top=A_S$.\n$$\n\\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix}\n\\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix} = \\lambda\n\\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\n$$\nTo solve for $z$, we find the inverse of $A_S$. The determinant is $\\det(A_S) = (2)(3) - (1)(1) = 5$.\n$$(A_S)^{-1} = \\frac{1}{5} \\begin{pmatrix} 3  -1 \\\\ -1  2 \\end{pmatrix}$$\nNow, we can solve for $z$:\n$$\nz = \\lambda (A_S)^{-1} \\mathrm{sgn}(x_S) = \\lambda \\frac{1}{5} \\begin{pmatrix} 3  -1 \\\\ -1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = \\frac{\\lambda}{5} \\begin{pmatrix} 3(1) - 1(-1) \\\\ -1(1) + 2(-1) \\end{pmatrix} = \\frac{\\lambda}{5} \\begin{pmatrix} 4 \\\\ -3 \\end{pmatrix}\n$$\nSo, the vector $z$ is $z = \\lambda \\begin{pmatrix} \\frac{4}{5} \\\\ -\\frac{3}{5} \\end{pmatrix}$.\n\nNext, we verify the off-support condition $\\|A_{S^{c}}^{\\top} z\\|_{\\infty}  \\lambda$. We compute $A_{S^c}^\\top z$:\n$$\nA_{S^c}^\\top z = \\begin{pmatrix} \\frac{1}{4}  \\frac{1}{2} \\\\ 1  0 \\end{pmatrix} \\left( \\lambda \\begin{pmatrix} \\frac{4}{5} \\\\ -\\frac{3}{5} \\end{pmatrix} \\right) = \\lambda \\begin{pmatrix} \\frac{1}{4}(\\frac{4}{5}) + \\frac{1}{2}(-\\frac{3}{5}) \\\\ 1(\\frac{4}{5}) + 0(-\\frac{3}{5}) \\end{pmatrix} = \\lambda \\begin{pmatrix} \\frac{1}{5} - \\frac{3}{10} \\\\ \\frac{4}{5} \\end{pmatrix} = \\lambda \\begin{pmatrix} -\\frac{1}{10} \\\\ \\frac{8}{10} \\end{pmatrix}\n$$\nThe infinity norm is:\n$$\n\\|A_{S^{c}}^{\\top} z\\|_{\\infty} = \\left\\| \\lambda \\begin{pmatrix} -\\frac{1}{10} \\\\ \\frac{8}{10} \\end{pmatrix} \\right\\|_{\\infty} = \\lambda \\max\\left(\\left|-\\frac{1}{10}\\right|, \\left|\\frac{8}{10}\\right|\\right) = \\frac{8}{10}\\lambda = \\frac{4}{5}\\lambda\n$$\nThe off-support condition is $\\frac{4}{5}\\lambda  \\lambda$, which is true for any $\\lambda  0$.\n\nThe problem states that $z$ is the residual $y-Ax^\\star$. This relationship, along with the given $y$, allows for determining the valid range of $\\lambda$. The primal solution's non-zero components $x_S^\\star$ are related to $y$ and $z$ via $z = y - A_S x_S^\\star$, which implies $x_S^\\star = (A_S)^{-1}(y-z)$.\n$$\nx_S^\\star = \\frac{1}{5} \\begin{pmatrix} 3  -1 \\\\ -1  2 \\end{pmatrix} \\left( \\begin{pmatrix} \\frac{7}{10} \\\\ -\\frac{9}{10} \\end{pmatrix} - \\frac{\\lambda}{5} \\begin{pmatrix} 4 \\\\ -3 \\end{pmatrix} \\right) = \\frac{1}{5} \\begin{pmatrix} 3  -1 \\\\ -1  2 \\end{pmatrix} \\begin{pmatrix} \\frac{7}{10} - \\frac{4\\lambda}{5} \\\\ -\\frac{9}{10} + \\frac{3\\lambda}{5} \\end{pmatrix}\n$$\n$$\nx_S^\\star = \\frac{1}{5} \\begin{pmatrix} 3(\\frac{7}{10}-\\frac{4\\lambda}{5}) - (-\\frac{9}{10}+\\frac{3\\lambda}{5}) \\\\ -(\\frac{7}{10}-\\frac{4\\lambda}{5}) + 2(-\\frac{9}{10}+\\frac{3\\lambda}{5}) \\end{pmatrix} = \\frac{1}{5} \\begin{pmatrix} \\frac{21}{10} + \\frac{9}{10} - \\frac{12\\lambda}{5} - \\frac{3\\lambda}{5} \\\\ -\\frac{7}{10} - \\frac{18}{10} + \\frac{4\\lambda}{5} + \\frac{6\\lambda}{5} \\end{pmatrix}\n$$\n$$\nx_S^\\star = \\frac{1}{5} \\begin{pmatrix} 3 - 3\\lambda \\\\ -\\frac{5}{2} + 2\\lambda \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{5}(1-\\lambda) \\\\ -\\frac{1}{2} + \\frac{2}{5}\\lambda \\end{pmatrix}\n$$\nThe given signs $\\mathrm{sgn}(x_S) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$ require $x_{S,1}^\\star  0$ and $x_{S,2}^\\star  0$.\n1.  $x_{S,1}^\\star  0 \\implies \\frac{3}{5}(1-\\lambda)  0 \\implies 1-\\lambda  0 \\implies \\lambda  1$.\n2.  $x_{S,2}^\\star  0 \\implies -\\frac{1}{2} + \\frac{2}{5}\\lambda  0 \\implies \\frac{2}{5}\\lambda  \\frac{1}{2} \\implies \\lambda  \\frac{5}{4}$.\nCombining these with $\\lambda0$, the solution $x^\\star$ has the given support and signs for any $\\lambda \\in (0,1)$. The vector $z$ is thus part of a family of vectors parameterized by $\\lambda \\in (0,1)$.\n\nFinally, we compute the certification ratio $\\rho$:\n$$\n\\rho \\triangleq \\frac{\\|A_{S^{c}}^{\\top} z\\|_{\\infty}}{\\lambda}\n$$\nSubstituting the expression we found for the infinity norm:\n$$\n\\rho = \\frac{\\frac{4}{5}\\lambda}{\\lambda} = \\frac{4}{5}\n$$\nThe value of $\\rho$ is constant and does not depend on the specific choice of $\\lambda$ from its valid range.",
            "answer": "$$\\boxed{\\frac{4}{5}}$$"
        },
        {
            "introduction": "Why are dual certificates so important when simpler metrics like mutual coherence exist? This final practice answers that question by demonstrating the superior precision of support-specific analysis. You will encounter a scenario where the standard coherence-based guarantee fails to predict recovery, yet a direct analysis using the dual certificate proves that exact recovery is, in fact, guaranteed. This exercise highlights the power of dual certificates to provide sharp, non-conservative recovery conditions. ",
            "id": "3444677",
            "problem": "Consider the linear system with sensing matrix $A \\in \\mathbb{R}^{3 \\times 3}$ whose unit-norm columns are\n$$\na_{1} \\;=\\; \\begin{pmatrix}1 \\\\ 0 \\\\ 0\\end{pmatrix}, \n\\quad\na_{2} \\;=\\; \\begin{pmatrix}\\frac{3}{5} \\\\ \\frac{4}{5} \\\\ 0\\end{pmatrix},\n\\quad\na_{3} \\;=\\; \\begin{pmatrix}0 \\\\ 0 \\\\ 1\\end{pmatrix}.\n$$\nLet the true signal $x^{\\star} \\in \\mathbb{R}^{3}$ be $2$-sparse with support $S=\\{1,2\\}$ and arbitrary nonzero coefficients on $S$ (with arbitrary signs). Let the observed data be $y = A x^{\\star}$, and consider Basis Pursuit (also called $\\ell_{1}$-minimization): minimize the $\\ell_{1}$ norm of $z \\in \\mathbb{R}^{3}$ subject to $A z = y$.\n\nUsing only first principles from convex duality and the dual certificate characterization of $\\ell_{1}$ recovery, do the following:\n\n1. Compute the mutual coherence $\\mu(A)$ of $A$ and verify whether the standard coherence-based sufficient condition for exact recovery of all $k$-sparse signals with $k=2$ would certify recovery in this instance.\n\n2. Focusing on the specific support $S=\\{1,2\\}$, use the exact recovery condition based on dual certificates for this particular support to determine the exact recovery constant for $S$ (i.e., the smallest value that upper-bounds the magnitude of correlations induced on the complement of $S$ by the canonical dual certificate constructed from $S$). Your answer must be the exact numerical value of this constant.\n\nProvide as your final answer only the exact numerical value obtained in part 2. No rounding is required.",
            "solution": "We proceed from standard bases in convex analysis and sparse recovery. The Basis Pursuit problem is the convex program that minimizes the $\\ell_{1}$ norm subject to linear equality constraints. Its dual program and Karush–Kuhn–Tucker (KKT) conditions are well known: exact recovery of a $k$-sparse vector $x^{\\star}$ with support $S$ is certified by the existence of a dual vector $y \\in \\mathbb{R}^{3}$ satisfying the dual certificate conditions\n$$\nA_{S}^{\\top} y \\;=\\; \\operatorname{sgn}(x^{\\star}_{S})\n\\quad \\text{and} \\quad\n\\|A_{S^{c}}^{\\top} y\\|_{\\infty} \\;\\; 1,\n$$\nwhere $A_{S}$ is the submatrix of $A$ with columns indexed by $S$ and $\\operatorname{sgn}(\\cdot)$ is the elementwise sign. A canonical construction sets\n$$\ny \\;=\\; A_{S} \\bigl(A_{S}^{\\top} A_{S}\\bigr)^{-1} \\operatorname{sgn}(x^{\\star}_{S}),\n$$\nwhich automatically enforces $A_{S}^{\\top} y = \\operatorname{sgn}(x^{\\star}_{S})$. Inserting this $y$ into the off-support correlations yields the support-specific exact recovery constant\n$$\n\\max_{j \\in S^{c}} \\left\\| \\bigl(A_{S}^{\\top} A_{S}\\bigr)^{-1} A_{S}^{\\top} a_{j} \\right\\|_{1},\n$$\nand if this maximum is strictly less than $1$, then a dual certificate exists for every sign pattern on $S$, and Basis Pursuit exactly recovers any $x^{\\star}$ supported on $S$.\n\nStep 1: Mutual coherence and the coherence-based bound. The mutual coherence $\\mu(A)$ is defined as\n$$\n\\mu(A) \\;=\\; \\max_{i \\neq j} \\bigl|a_{i}^{\\top} a_{j}\\bigr|.\n$$\nFor the given $A$, compute the pairwise inner products:\n$$\na_{1}^{\\top} a_{2} \\;=\\; \\frac{3}{5}, \n\\quad\na_{1}^{\\top} a_{3} \\;=\\; 0,\n\\quad\na_{2}^{\\top} a_{3} \\;=\\; 0.\n$$\nHence\n$$\n\\mu(A) \\;=\\; \\frac{3}{5}.\n$$\nThe standard coherence-based sufficient condition for exact recovery of all $k$-sparse signals (via Basis Pursuit) requires\n$$\n\\mu(A) \\;\\; \\frac{1}{2k-1}.\n$$\nFor $k=2$, this bound is $\\mu(A)  \\frac{1}{3}$. Since $\\frac{3}{5}  \\frac{1}{3}$, this criterion does not certify recovery in this instance. Thus the coherence bound is too conservative here.\n\nStep 2: Exact recovery constant for the specific support $S=\\{1,2\\}$. We compute\n$$\nA_{S} \\;=\\; \\begin{pmatrix}\n1  \\frac{3}{5} \\\\\n0  \\frac{4}{5} \\\\\n0  0\n\\end{pmatrix},\n\\quad\nA_{S}^{\\top} A_{S} \\;=\\; \n\\begin{pmatrix}\n1  \\frac{3}{5} \\\\\n\\frac{3}{5}  1\n\\end{pmatrix}.\n$$\nThe inverse is\n$$\n\\bigl(A_{S}^{\\top} A_{S}\\bigr)^{-1}\n\\;=\\;\n\\frac{1}{1 - \\left(\\frac{3}{5}\\right)^{2}}\n\\begin{pmatrix}\n1  -\\frac{3}{5} \\\\\n-\\frac{3}{5}  1\n\\end{pmatrix}\n\\;=\\;\n\\frac{1}{\\frac{16}{25}}\n\\begin{pmatrix}\n1  -\\frac{3}{5} \\\\\n-\\frac{3}{5}  1\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n\\frac{25}{16}  -\\frac{15}{16} \\\\\n-\\frac{15}{16}  \\frac{25}{16}\n\\end{pmatrix}.\n$$\nFor the sole column outside $S$, namely $a_{3}$, we have\n$$\nA_{S}^{\\top} a_{3} \\;=\\;\n\\begin{pmatrix}\na_{1}^{\\top} a_{3} \\\\\na_{2}^{\\top} a_{3}\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n0 \\\\ 0\n\\end{pmatrix}.\n$$\nTherefore,\n$$\n\\bigl(A_{S}^{\\top} A_{S}\\bigr)^{-1} A_{S}^{\\top} a_{3}\n\\;=\\;\n\\begin{pmatrix}\n\\frac{25}{16}  -\\frac{15}{16} \\\\\n-\\frac{15}{16}  \\frac{25}{16}\n\\end{pmatrix}\n\\begin{pmatrix}\n0 \\\\ 0\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n0 \\\\ 0\n\\end{pmatrix},\n$$\nand its $\\ell_{1}$ norm is $0$. Taking the maximum over $j \\in S^{c}$ yields the exact recovery constant\n$$\n\\max_{j \\in S^{c}} \\left\\| \\bigl(A_{S}^{\\top} A_{S}\\bigr)^{-1} A_{S}^{\\top} a_{j} \\right\\|_{1}\n\\;=\\;\n0.\n$$\nBecause $0  1$, the exact recovery condition holds for the specific support $S$, so a dual certificate exists for any sign pattern on $S$, and Basis Pursuit exactly recovers $x^{\\star}$. This explicitly demonstrates that, although the coherence bound does not guarantee recovery for $k=2$ when $\\mu(A)=\\frac{3}{5}$, the support-specific dual certificate condition is easily satisfied, illustrating the conservativeness of coherence-based criteria.",
            "answer": "$$\\boxed{0}$$"
        }
    ]
}