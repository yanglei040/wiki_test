{
    "hands_on_practices": [
        {
            "introduction": "理论的最佳理解方式是通过实践。第一个练习将引导您一步步地构建一个原始-对偶见证。通过在一个小而明确定义的问题上手动处理KKT（Karush-Kuhn-Tucker）条件，您将对原始解、符号一致性和对偶可行性约束如何相互作用以验证特定支撑集获得切实的直观理解。这个计算练习将揭示原始-对偶证明的核心机制。",
            "id": "3191241",
            "problem": "考虑使用平方误差损失的线性回归的最小绝对收缩和选择算子 (LASSO)，其定义为优化问题 $$\\min_{\\beta \\in \\mathbb{R}^{p}} \\left\\{ \\frac{1}{2n} \\|y - X\\beta\\|_{2}^{2} + \\lambda \\|\\beta\\|_{1} \\right\\},$$ 其中 $X \\in \\mathbb{R}^{n \\times p}$ 是一个固定的设计矩阵，$y \\in \\mathbb{R}^{n}$ 是观测响应，$n$ 是样本数量，$p$ 是预测变量的数量，$\\lambda  0$ 是正则化参数，$\\|\\cdot\\|_{1}$ 表示 $\\ell_{1}$ 范数。Karush-Kuhn-Tucker (KKT) 最优性条件表明，对于任何 LASSO 解 $\\hat{\\beta}$，存在一个对偶向量 $\\hat{z} \\in \\mathbb{R}^{p}$ 使得 $$\\frac{1}{n} X^{\\top}(y - X\\hat{\\beta}) = \\lambda \\hat{z},$$ 且分量上满足条件：如果 $\\hat{\\beta}_{j} \\neq 0$，则 $\\hat{z}_{j} = \\operatorname{sign}(\\hat{\\beta}_{j})$；如果 $\\hat{\\beta}_{j} = 0$，则 $\\hat{z}_{j} \\in [-1,1]$。\n\n你将使用原始-对偶见证构造 (primal-dual witness construction) 来为一个小型实例验证精确的支撑集恢复。设 $n = 4$ 且 $p = 3$，$X$ 的列向量 $x_{1}, x_{2}, x_{3} \\in \\mathbb{R}^{4}$ 和响应 $y \\in \\mathbb{R}^{4}$ 由下式给出\n$$x_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad x_{2} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad x_{3} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad y = \\begin{pmatrix} 1.2 \\\\ 0.9 \\\\ 2.1 \\\\ -0.2 \\end{pmatrix}.$$\n假设候选的真实支撑集是 $S = \\{1,2\\}$，符号向量为 $s_{S} = (1,1)$，我们希望使用原始-对偶见证来验证 LASSO 精确地选择了支撑集 $S$。\n\n请遵循以下步骤：\n1. 仅使用 KKT 最优性条件和原始-对偶见证框架，写出在 $S$ 上的受限 KKT 系统，该系统确定了一个具有符号 $s_{S}$ 的候选原始解 $\\hat{\\beta}_{S}$，并将 $\\hat{\\beta}_{S}$ 表示为 $\\lambda$ 的显式仿射函数。\n2. 陈述保证 $S$ 上符号一致性的关于 $\\hat{\\beta}_{S}$ 的不等式约束，并将它们简化为关于 $\\lambda$ 的数值不等式。\n3. 通过 KKT 条件计算相应的对偶坐标 $\\hat{z}_{3}$，在 $S^{c} = \\{3\\}$ 上构建对偶凭证 (dual certificate)，并将要求 $|\\hat{z}_{3}|  1$ 简化为关于 $\\lambda$ 的数值条件。\n4. 确定使所有这些条件同时成立的 $\\lambda  0$ 的最大值，从而通过原始-对偶见证验证具有符号 $s_{S}$ 的精确支撑集恢复。\n\n请以精确数值（不要四舍五入）给出你的最终答案。不涉及物理单位。",
            "solution": "该问题要求我们使用原始-对偶见证构造来找到最大的正则化参数 $\\lambda$，使得 LASSO 解具有特定的支撑集 $S = \\{1,2\\}$ 和特定的符号模式 $s_S = (1,1)$。该过程涉及在支撑集为 $S$ 且符号为 $s_S$ 的假设下，建立并求解 Karush-Kuhn-Tucker (KKT) 最优性条件。这将产生一个依赖于 $\\lambda$ 的候选解 $\\hat{\\beta}$。然后，我们必须验证该候选解确实是真实 LASSO 解的条件。这些条件是：\n1.  活跃集 $S$ 中的系数必须具有假定的符号（符号一致性）。\n2.  对应于非活跃集 $S^c$ 的对偶变量的绝对值必须严格小于 1（对偶可行性）。\n\n我们给定的数据如下：\n$n = 4$, $p = 3$。\n$X = [x_1, x_2, x_3]$ 其中 $x_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$, $x_2 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$, $x_3 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$。\n响应向量为 $y = \\begin{pmatrix} 1.2 \\\\ 0.9 \\\\ 2.1 \\\\ -0.2 \\end{pmatrix}$。\n候选支撑集为 $S = \\{1,2\\}$，符号向量为 $s_S = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。这意味着候选解的形式为 $\\hat{\\beta} = (\\hat{\\beta}_1, \\hat{\\beta}_2, 0)^\\top$，其中 $\\hat{\\beta}_1  0$ 且 $\\hat{\\beta}_2  0$。\n\n令 $X_S = [x_1, x_2]$ 为 $X$ 中对应于活跃集 $S$ 的子矩阵。\n$$X_S = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\\\ 0  0 \\end{pmatrix}$$\n令 $\\hat{\\beta}_S = \\begin{pmatrix} \\hat{\\beta}_1 \\\\ \\hat{\\beta}_2 \\end{pmatrix}$ 为非零系数向量。\n\n**步骤 1：确定候选原始解 $\\hat{\\beta}_{S}$**\n\n限制在活跃集 $S$ 上的 KKT 条件由下式给出：\n$$\\frac{1}{n} X_S^\\top (y - X_S \\hat{\\beta}_S) = \\lambda s_S$$\n重新整理此方程可得到关于 $\\hat{\\beta}_S$ 的线性系统：\n$$X_S^\\top X_S \\hat{\\beta}_S = X_S^\\top y - n \\lambda s_S$$\n$$\\hat{\\beta}_S = (X_S^\\top X_S)^{-1} (X_S^\\top y - n \\lambda s_S)$$\n我们计算所需的矩阵和向量：\n$$X_S^\\top X_S = \\begin{pmatrix} 1  0  1  0 \\\\ 0  1  1  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix}$$\n其逆矩阵为：\n$$(X_S^\\top X_S)^{-1} = \\frac{1}{2 \\cdot 2 - 1 \\cdot 1} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix}$$\n接下来，我们计算 $X_S^\\top y$：\n$$X_S^\\top y = \\begin{pmatrix} 1  0  1  0 \\\\ 0  1  1  0 \\end{pmatrix} \\begin{pmatrix} 1.2 \\\\ 0.9 \\\\ 2.1 \\\\ -0.2 \\end{pmatrix} = \\begin{pmatrix} 1.2 + 2.1 \\\\ 0.9 + 2.1 \\end{pmatrix} = \\begin{pmatrix} 3.3 \\\\ 3.0 \\end{pmatrix}$$\n现在我们将这些代入 $\\hat{\\beta}_S$ 的表达式中。其中 $n=4$ 且 $s_S = (1,1)^\\top$：\n$$\\hat{\\beta}_S = \\frac{1}{3} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} \\left( \\begin{pmatrix} 3.3 \\\\ 3.0 \\end{pmatrix} - 4\\lambda \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right)$$\n$$\\hat{\\beta}_S = \\frac{1}{3} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} \\begin{pmatrix} 3.3 - 4\\lambda \\\\ 3.0 - 4\\lambda \\end{pmatrix}$$\n$$\\hat{\\beta}_S = \\frac{1}{3} \\begin{pmatrix} 2(3.3 - 4\\lambda) - (3.0 - 4\\lambda) \\\\ -(3.3 - 4\\lambda) + 2(3.0 - 4\\lambda) \\end{pmatrix}$$\n$$\\hat{\\beta}_S = \\frac{1}{3} \\begin{pmatrix} 6.6 - 8\\lambda - 3.0 + 4\\lambda \\\\ -3.3 + 4\\lambda + 6.0 - 8\\lambda \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 3.6 - 4\\lambda \\\\ 2.7 - 4\\lambda \\end{pmatrix}$$\n因此，$\\hat{\\beta}_S$ 的分量为：\n$$\\hat{\\beta}_1(\\lambda) = \\frac{3.6 - 4\\lambda}{3} = 1.2 - \\frac{4}{3}\\lambda$$\n$$\\hat{\\beta}_2(\\lambda) = \\frac{2.7 - 4\\lambda}{3} = 0.9 - \\frac{4}{3}\\lambda$$\n\n**步骤 2：检查 $S$ 上的符号一致性**\n\n为使假定的符号 $s_S=(1,1)$ 正确，我们要求 $\\hat{\\beta}_1  0$ 且 $\\hat{\\beta}_2  0$。\n条件 $\\hat{\\beta}_1  0$ 意味着：\n$$1.2 - \\frac{4}{3}\\lambda  0 \\implies 1.2  \\frac{4}{3}\\lambda \\implies \\frac{6}{5}  \\frac{4}{3}\\lambda \\implies \\lambda  \\frac{6}{5} \\cdot \\frac{3}{4} = \\frac{18}{20} = \\frac{9}{10} = 0.9$$\n条件 $\\hat{\\beta}_2  0$ 意味着：\n$$0.9 - \\frac{4}{3}\\lambda  0 \\implies 0.9  \\frac{4}{3}\\lambda \\implies \\frac{9}{10}  \\frac{4}{3}\\lambda \\implies \\lambda  \\frac{9}{10} \\cdot \\frac{3}{4} = \\frac{27}{40} = 0.675$$\n两个不等式都必须成立，因此我们取更严格的那个：\n$$\\lambda  0.675 \\quad \\text{或} \\quad \\lambda  \\frac{27}{40}$$\n\n**步骤 3：在 $S^c$ 上构建对偶凭证**\n\n对于非活跃集 $S^c = \\{3\\}$，我们必须检查对偶可行性条件 $|\\hat{z}_3|  1$。对偶变量 $\\hat{z}_3$ 由 $j=3$ 的 KKT 条件确定：\n$$\\frac{1}{n} x_3^\\top (y - X\\hat{\\beta}) = \\lambda \\hat{z}_3$$\n因为 $\\hat{\\beta}_3 = 0$，我们有 $X\\hat{\\beta} = X_S\\hat{\\beta}_S$。因此：\n$$\\hat{z}_3 = \\frac{1}{n\\lambda} x_3^\\top (y - X_S \\hat{\\beta}_S)$$\n我们计算各项：\n$$x_3^\\top y = \\begin{pmatrix} 1  1  0  0 \\end{pmatrix} \\begin{pmatrix} 1.2 \\\\ 0.9 \\\\ 2.1 \\\\ -0.2 \\end{pmatrix} = 1.2 + 0.9 = 2.1$$\n$$x_3^\\top X_S = \\begin{pmatrix} 1  1  0  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  1 \\end{pmatrix}$$\n所以，\n$$\\hat{z}_3 = \\frac{1}{4\\lambda} \\left( 2.1 - \\begin{pmatrix} 1  1 \\end{pmatrix} \\hat{\\beta}_S \\right) = \\frac{1}{4\\lambda} (2.1 - (\\hat{\\beta}_1 + \\hat{\\beta}_2))$$\n代入 $\\hat{\\beta}_1(\\lambda)$ 和 $\\hat{\\beta}_2(\\lambda)$ 的表达式：\n$$\\hat{\\beta}_1 + \\hat{\\beta}_2 = \\left(1.2 - \\frac{4}{3}\\lambda\\right) + \\left(0.9 - \\frac{4}{3}\\lambda\\right) = 2.1 - \\frac{8}{3}\\lambda$$\n现在，将此代入 $\\hat{z}_3$ 的表达式中：\n$$\\hat{z}_3 = \\frac{1}{4\\lambda} \\left( 2.1 - \\left(2.1 - \\frac{8}{3}\\lambda\\right) \\right) = \\frac{1}{4\\lambda} \\left(\\frac{8}{3}\\lambda\\right) = \\frac{8}{12} = \\frac{2}{3}$$\n对偶变量 $\\hat{z}_3$ 是一个常数。对偶可行性条件为 $|\\hat{z}_3|  1$，即 $|\\frac{2}{3}|  1$。这对任何 $\\lambda  0$ 都成立。\n\n**步骤 4：确定 $\\lambda$ 的最大值**\n\n原始-对偶见证构造为所有同时满足所有条件的 $\\lambda  0$ 的值，验证了支撑集 $S=\\{1,2\\}$ 和符号 $s_S=(1,1)$。这些条件是：\n1. $\\lambda  0$ (根据问题陈述)\n2. $\\lambda  0.675$ (根据 $\\hat{\\beta}_S$ 的符号一致性)\n3. $|\\hat{z}_3|  1$ (该条件恒成立，不施加额外限制)\n\n综合这些条件，能够正确识别支撑集为 $S=\\{1,2\\}$ 的 $\\lambda$ 的集合由开区间 $\\lambda \\in (0, 0.675)$ 给出。问题要求的是使这些条件成立的 $\\lambda$ 的最大值。这对应于该区间的上确界。在这个边界值上，其中一个不等式变为等式，活跃集即将发生改变。\n$$\\lambda_{\\max} = \\sup(0, 0.675) = 0.675$$\n用精确分数形式表示，该值为 $\\frac{27}{40}$。\n对于任何 $\\lambda \\in (0, \\frac{27}{40})$，LASSO 解的支撑集为 $\\{1,2\\}$。在 $\\lambda = \\frac{27}{40}$ 时，$\\hat{\\beta}_2$ 变为 $0$，因此支撑集缩小为 $\\{1\\}$。因此，使得原始-对偶见证的严格条件对支撑集 $\\{1,2\\}$ 成立的最大值是该区间的上确界。",
            "answer": "$$\\boxed{\\frac{27}{40}}$$"
        },
        {
            "introduction": "原始-对偶见证不仅是针对固定正则化参数 $\\lambda$ 的静态证书，它还为理解整个Lasso解路径提供了一个强有力的视角。这个练习要求您分析当 $\\lambda$ 变化时对偶变量是如何演变的。您将精确计算出对偶可行性约束首次变为紧绷的时刻，这对应于像LARS（最小角回归）这样的同伦算法中的一个“事件”，即一个新变量进入模型。",
            "id": "3467715",
            "problem": "考虑最小绝对收缩和选择算子 (Lasso) 问题\n$$\\min_{\\beta \\in \\mathbb{R}^{p}} \\ \\frac{1}{2}\\|y - X\\beta\\|_{2}^{2} + \\lambda \\|\\beta\\|_{1},$$\n其中 $X \\in \\mathbb{R}^{n \\times p}$ 的列经过标准化，使得 $X^{\\top}X$ 的对角线元素为1。令 $G = X^{\\top}X$ 表示格拉姆矩阵，并令 $c = X^{\\top}y$。最优性的 Karush-Kuhn-Tucker (KKT) 条件表明，存在一个次梯度 $z \\in \\partial \\|\\beta\\|_{1}$ 使得\n$$X^{\\top}(y - X\\beta) = \\lambda z,$$\n其中当 $\\beta_{j} \\neq 0$ 时，$z_{j} = \\operatorname{sign}(\\beta_{j})$；当 $\\beta_{j} = 0$ 时，$|z_{j}| \\leq 1$。在原始-对偶验证构造中，对于一个假设的活动集 $S$ 及其符号向量 $s \\in \\{-1, +1\\}^{|S|}$，受限的原始问题满足\n$$G_{SS}\\beta_{S} = c_{S} - \\lambda s,$$\n并且 $S^{c}$ 上的对偶凭证为\n$$z_{S^{c}} = \\frac{1}{\\lambda}\\left(c_{S^{c}} - G_{S^{c}S}\\beta_{S}\\right),$$\n要求对于所有 $j \\in S^{c}$ 都有 $|z_{j}|  1$，以满足严格对偶可行性。\n\n假设 $p=3$，格拉姆矩阵和相关性向量由下式给出\n$$G = \\begin{pmatrix}\n1  \\frac{1}{4}  0 \\\\\n\\frac{1}{4}  1  0 \\\\\n0  0  1\n\\end{pmatrix}, \\qquad c = \\begin{pmatrix} 2 \\\\ \\frac{3}{2} \\\\ \\frac{1}{5} \\end{pmatrix}。$$\n沿着同伦（最小角回归）路径，当 $\\lambda \\downarrow 0$ 时，在 $\\lambda = \\max_{j}|c_{j}|$ 处第一个进入的变量是符号为 $+1$ 的坐标1。考虑一个活动集为 $S = \\{1\\}$ 且符号为 $s = +1$ 的原始-对偶验证，它在一个使该验证保持有效的 $\\lambda$ 范围内维持。\n\n根据 KKT 条件和原始-对偶验证构造，推导出使得坐标2的对偶可行性约束首次变为紧约束（即 $|z_{2}| = 1$）的最小 $\\lambda  0$ 的精确值，这标志着坐标2加入活动集的同伦算法事件的发生。将最终答案表示为一个单一的精确数。无需四舍五入。",
            "solution": "我们的目标是找到沿 Lasso 同伦路径发生特定事件时的正则化参数 $\\lambda$ 的值。\n\n### 步骤 1：建立受限原始解\n我们从受限原始方程开始，以求解活动集 $S=\\{1\\}$ 上的原始变量 $\\beta_1$。此时，符号为 $s_1 = +1$。\n受限原始方程为 $G_{SS}\\beta_{S} = c_{S} - \\lambda s$。\n根据给定的数据，$G_{SS} = G_{11} = 1$ 且 $c_S = c_1 = 2$。\n代入这些值：\n$$1 \\cdot \\beta_{1} = 2 - \\lambda \\cdot (+1)$$\n$$\\beta_{1} = 2 - \\lambda$$\n为保证此解的有效性（即符号一致性），$\\beta_1$ 的符号必须与假定的符号 $s_1=+1$ 匹配，因此我们要求 $\\beta_1 > 0$。这意味着 $2 - \\lambda > 0$，即 $\\lambda  2$。这与同伦路径的起始点 $\\lambda_{\\max} = \\max_j |c_j| = 2$ 是一致的。\n\n### 步骤 2：推导对偶凭证\n接下来，我们推导非活动集 $S^c = \\{2, 3\\}$ 上对偶凭证 $z_{S^c}$ 的表达式。\n对偶凭证方程为 $z_{S^{c}} = \\frac{1}{\\lambda}\\left(c_{S^{c}} - G_{S^{c}S}\\beta_{S}\\right)$。\n相关的子矩阵和子向量为：\n$c_{S^{c}} = \\begin{pmatrix} c_{2} \\\\ c_{3} \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{2} \\\\ \\frac{1}{5} \\end{pmatrix}$\n$G_{S^{c}S} = \\begin{pmatrix} G_{21} \\\\ G_{31} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{4} \\\\ 0 \\end{pmatrix}$\n\n将这些代入方程，并将 $\\beta_1 = 2 - \\lambda$ 代入：\n$$\\begin{pmatrix} z_{2} \\\\ z_{3} \\end{pmatrix} = \\frac{1}{\\lambda} \\left( \\begin{pmatrix} \\frac{3}{2} \\\\ \\frac{1}{5} \\end{pmatrix} - \\begin{pmatrix} \\frac{1}{4} \\\\ 0 \\end{pmatrix} (2 - \\lambda) \\right)$$\n\n### 步骤 3：求解事件发生的 $\\lambda$ 值\n我们关注坐标2的对偶凭证 $z_2$：\n$$z_{2} = \\frac{1}{\\lambda} \\left( \\frac{3}{2} - \\frac{1}{4}(2 - \\lambda) \\right)$$\n$$z_{2} = \\frac{1}{\\lambda} \\left( \\frac{3}{2} - \\frac{2}{4} + \\frac{\\lambda}{4} \\right)$$\n$$z_{2} = \\frac{1}{\\lambda} \\left( \\frac{3}{2} - \\frac{1}{2} + \\frac{\\lambda}{4} \\right)$$\n$$z_{2} = \\frac{1}{\\lambda} \\left( 1 + \\frac{\\lambda}{4} \\right) = \\frac{1}{\\lambda} + \\frac{1}{4}$$\n问题要求找到坐标2的对偶可行性约束首次变为紧约束时的 $\\lambda$ 值，即 $|z_{2}| = 1$。\n由于我们考虑 $\\lambda > 0$ 的同伦路径，$\\frac{1}{\\lambda} + \\frac{1}{4}$ 总是正的。因此，我们可以去掉绝对值符号：\n$$ \\frac{1}{\\lambda} + \\frac{1}{4} = 1 $$\n求解 $\\lambda$：\n$$ \\frac{1}{\\lambda} = 1 - \\frac{1}{4} = \\frac{3}{4} $$\n$$ \\lambda = \\frac{4}{3} $$\n这就是坐标2准备进入活动集时的 $\\lambda$ 值。\n\n### 步骤 4：验证事件顺序（可选）\n为了确认这是路径上的下一个事件，我们检查在 $\\lambda = 4/3$ 时坐标3的状态。\n$$z_{3} = \\frac{1}{\\lambda} \\left( \\frac{1}{5} - 0 \\cdot (2 - \\lambda) \\right) = \\frac{1}{5\\lambda}$$\n在 $\\lambda = 4/3$ 时：\n$$z_{3} = \\frac{1}{5 \\cdot \\frac{4}{3}} = \\frac{1}{\\frac{20}{3}} = \\frac{3}{20}$$\n此时 $|z_3| = \\frac{3}{20}  1$，因此坐标3的对偶可行性约束没有被违反。坐标2的事件（在 $\\lambda = 4/3$）确实发生在坐标3的事件（当 $|z_3|=1$ 时，即 $\\lambda = 1/5$）之前。\n因此，所求的 $\\lambda$ 值为 $\\frac{4}{3}$。",
            "answer": "$$\\boxed{\\frac{4}{3}}$$"
        },
        {
            "introduction": "为什么原始-对偶见证构造有时无法验证真实的支撑集？最后的这个练习将从计算转向理论与代码的结合，以探究支撑集恢复的根本限制。您将首先推导著名的不可分条件（irrepresentable condition），然后通过一个编程练习亲眼见证特征之间的高度相关性如何违反此条件，从而导致Lasso选择错误的变量。",
            "id": "3186678",
            "problem": "考虑小样本大维度情景下的线性模型 $y = X \\beta + \\varepsilon$，其中 $p \\gg n$，且 $X \\in \\mathbb{R}^{n \\times p}$，$\\beta \\in \\mathbb{R}^{p}$，$\\varepsilon \\in \\mathbb{R}^{n}$。最小绝对值收缩与选择算子 (LASSO) 估计量定义为以下凸目标函数的最小化子：\n$$\n\\widehat{\\beta}_{\\lambda} \\in \\arg\\min_{\\beta \\in \\mathbb{R}^{p}} \\left\\{\\frac{1}{2n}\\|y - X\\beta\\|_2^2 + \\lambda \\|\\beta\\|_1\\right\\},\n$$\n其中 $\\lambda  0$ 是一个正则化参数，$\\|\\cdot\\|_1$ 表示 $\\ell_1$-范数。精确支撑集恢复问题旨在探究是否满足 $\\operatorname{supp}(\\widehat{\\beta}_{\\lambda}) = \\operatorname{supp}(\\beta)$。\n\n请仅从凸优化的 Karush-Kuhn-Tucker (KKT) 最优性条件、$\\ell_1$-范数的次梯度以及样本格拉姆矩阵 $G = X^{\\top} X / n$ 的定义出发，为 LASSO 实现精确支撑集恢复推导出一个必须成立的必要不等式，该不等式被称为不可表示条件。你的推导必须从线性模型和 KKT 条件开始，并且必须阐明由 $G$ 的分块量化的特征间相关性如何控制恢复真实支撑集的能力。请精确解释在 $p \\gg n$ 的情景下，特征相关性如何会违反此条件，从而阻碍精确的支撑集恢复。\n\n然后，实现一个程序，针对提供的一个包含三个合成场景的测试套件执行以下步骤，每个场景都旨在探究不可表示条件的不同方面：\n\n- 对于每个场景，生成一个具有 $n$ 行和 $p$ 列的设计矩阵 $X$，一个具有已知支撑集 $S \\subset \\{1,\\dots,p\\}$ 的真实系数向量 $\\beta$，以及一个响应向量 $y = X\\beta + \\varepsilon$，其中 $\\varepsilon$ 从零均值高斯分布中抽取。$X$ 的所有列必须被标准化，使其均值为 $0$ 且欧几里得范数为 $\\sqrt{n}$，$y$ 必须被中心化，使其均值为 $0$（无截距项）。支撑集 $S$ 固定为前 $k$ 个索引 $\\{0,1,\\dots,k-1\\}$，其系数大小相等且严格为正。每个场景使用固定的随机种子以确保可复现性。\n\n- 仅使用样本格拉姆矩阵 $G = X^{\\top} X / n$，计算不可表示指数\n$$\n\\mu = \\left\\|G_{S^c,S} \\, G_{S,S}^{-1} \\, \\operatorname{sgn}(\\beta_S)\\right\\|_{\\infty},\n$$\n其中 $S^c$ 是 $S$ 的补集，$G_{S,S}$ 是由 $S$ 索引的 $G$ 的主子矩阵，$G_{S^c,S}$ 是行索引在 $S^c$ 中、列索引在 $S$ 中的 $G$ 的子矩阵，$\\operatorname{sgn}(\\cdot)$ 是按元素取符号函数。如果 $G_{S,S}$ 不可逆，请使用数值稳定的替代方法（例如 Moore-Penrose 伪逆）来评估该表达式。当且仅当 $\\mu  1$ 时，声明不可表示条件成立。\n\n- 使用坐标下降法拟合 LASSO 以获得 $\\widehat{\\beta}_{\\lambda}$，对每个场景使用上述目标函数和给定的 $\\lambda$。通过检查 $\\widehat{\\beta}_{\\lambda}$ 的非零项索引集是否等于 $S$ 来判断是否实现了精确支撑集恢复，其中当估计系数的绝对值严格大于 $10^{-6}$ 时，该索引被视为非零。\n\n测试套件和参数：\n1. 理想路径（弱相关性）：\n   - $n = 30$, $p = 80$, $k = 5$, 系数大小 $b = 1.0$, 噪声标准差 $\\sigma = 0.01$, 正则化参数 $\\lambda = 0.2$, 随机种子 $0$。\n   - 构造方法：$X$ 具有独立的标准正态分布条目；除了随机抽样外，不强制施加特殊的相关结构。\n2. 近边界相关性（单个强相关体）：\n   - $n = 30$, $p = 80$, $k = 5$, $b = 1.0$, $\\sigma = 0.05$, $\\lambda = 0.05$, 随机种子 $1$。\n   - 构造方法：从独立的标准正态分布 $X$ 开始，然后对于索引为 $50、51、52$ 的三个非支撑集列，设置 $X_{\\cdot, j} \\leftarrow 0.95 \\cdot X_{\\cdot, 0} + \\sqrt{1 - 0.95^2} \\cdot u_j$，其中 $u_j$ 是一个独立的标准正态向量。这为真实支撑集特征创建了一个高度相关的代理。\n3. 反例（多个强相关体）：\n   - $n = 30$, $p = 80$, $k = 5$, $b = 1.0$, $\\sigma = 0.01$, $\\lambda = 0.2$, 随机种子 $2$。\n   - 构造方法：从独立的标准正态分布 $X$ 开始，然后对于索引为 $60, 61, 62, 63, 64$ 的五个非支撑集列，设置：\n     - $X_{\\cdot, 60} \\leftarrow 0.8 \\cdot X_{\\cdot, 0} + 0.8 \\cdot X_{\\cdot, 1} + 0.1 \\cdot u_{60}$,\n     - $X_{\\cdot, 61} \\leftarrow 0.8 \\cdot X_{\\cdot, 1} + 0.8 \\cdot X_{\\cdot, 2} + 0.1 \\cdot u_{61}$,\n     - $X_{\\cdot, 62} \\leftarrow 0.8 \\cdot X_{\\cdot, 2} + 0.8 \\cdot X_{\\cdot, 3} + 0.1 \\cdot u_{62}$,\n     - $X_{\\cdot, 63} \\leftarrow 0.8 \\cdot X_{\\cdot, 3} + 0.8 \\cdot X_{\\cdot, 4} + 0.1 \\cdot u_{63}$,\n     - $X_{\\cdot, 64} \\leftarrow 0.8 \\cdot X_{\\cdot, 0} + 0.8 \\cdot X_{\\cdot, 4} + 0.1 \\cdot u_{64}$,\n     其中每个 $u_j$ 都是一个独立的标准正态向量。这产生了多个强相关体，其综合效应挑战了不可表示条件。\n\n对于每个场景，在按上述方式构造 $X$ 后，将每列标准化为均值为 $0$、欧几里得范数为 $\\sqrt{n}$，将 $y$ 中心化为均值为 $0$，并设置真实支撑集 $S = \\{0,1,2,3,4\\}$，其中对于 $j \\in S$，$\\beta_j = b$，否则 $\\beta_j = 0$。使用给定的 $\\sigma$ 来抽取 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_n)$。\n\n你的程序应该生成一行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个场景贡献一个形式为 $[\\mu, c, r]$ 的列表，包含以下组件：\n- $\\mu$: 不可表示指数，为浮点数，四舍五入到六位小数，\n- $c$: 一个布尔值，表示不可表示条件是否成立（如果 $\\mu  1$ 则为 true，否则为 false），\n- $r$: 一个布尔值，表示 LASSO 是否恢复了精确支撑集（如果 $\\operatorname{supp}(\\widehat{\\beta}_{\\lambda}) = S$ 则为 true，否则为 false）。\n\n例如，最终输出应类似于 $[[\\mu_1,c_1,r_1],[\\mu_2,c_2,r_2],[\\mu_3,c_3,r_3]]$，其中符号被数值替换。本问题不涉及物理单位或角度单位。所有随机抽样必须在指定的随机种子下执行，以确保可复现性。",
            "solution": "该问题要求推导 LASSO 估计量实现精确支撑集恢复的不可表示条件，并实现一个程序来测试此条件。\n\n### 不可表示条件的推导\n\n我们从线性模型 $y = X \\beta + \\varepsilon$ 开始，其中 $X \\in \\mathbb{R}^{n \\times p}$，$\\beta \\in \\mathbb{R}^{p}$，$y \\in \\mathbb{R}^{n}$，$\\varepsilon \\in \\mathbb{R}^{n}$ 是一个噪声向量。LASSO 估计量 $\\widehat{\\beta}_{\\lambda}$ 最小化目标函数：\n$$L(\\beta) = \\frac{1}{2n}\\|y - X\\beta\\|_2^2 + \\lambda \\|\\beta\\|_1$$\n这是一个凸优化问题。一个向量 $\\widehat{\\beta}$ 是解当且仅当零向量是 $L(\\beta)$ 在 $\\widehat{\\beta}$ 处的次微分的元素。$L(\\beta)$ 的次微分由 $\\partial L(\\beta) = \\nabla \\left(\\frac{1}{2n}\\|y - X\\beta\\|_2^2\\right) + \\lambda \\partial \\|\\beta\\|_1$ 给出。\n\n最小二乘项的梯度是 $\\frac{1}{n}X^{\\top}(X\\beta - y)$。$\\ell_1$-范数 $\\|\\beta\\|_1 = \\sum_{j=1}^p |\\beta_j|$ 的次微分是向量集合 $z \\in \\mathbb{R}^p$，使得对于每个分量 $j$：\n$$\nz_j = \\begin{cases}\n\\operatorname{sgn}(\\beta_j)  \\text{若 } \\beta_j \\neq 0 \\\\\nv_j \\in [-1, 1]  \\text{若 } \\beta_j = 0\n\\end{cases}\n$$\n其中 $\\operatorname{sgn}(\\cdot)$ 是符号函数。\n\n因此，$\\widehat{\\beta}_{\\lambda}$ 的 Karush-Kuhn-Tucker (KKT) 最优性条件是，存在一个次梯度向量 $z$，当 $\\widehat{\\beta}_{\\lambda,j} \\neq 0$ 时 $z_j = \\operatorname{sgn}(\\widehat{\\beta}_{\\lambda,j})$，当 $\\widehat{\\beta}_{\\lambda,j} = 0$ 时 $|z_j| \\le 1$，使得：\n$$ \\frac{1}{n}X^{\\top}(X\\widehat{\\beta}_{\\lambda} - y) + \\lambda z = 0 \\implies \\frac{1}{n}X^{\\top}(y - X\\widehat{\\beta}_{\\lambda}) = \\lambda z $$\n\n现在，我们假设 LASSO 实现了精确支撑集恢复。令 $S = \\operatorname{supp}(\\beta)$ 为真实支撑集，即 $\\beta_j \\neq 0$ 的索引集合。精确支撑集恢复的假设意味着 $\\operatorname{supp}(\\widehat{\\beta}_{\\lambda}) = S$。这表示对于 $j \\in S$，$\\widehat{\\beta}_{\\lambda,j} \\neq 0$，而对于 $j \\in S^c$（$S$ 的补集），$\\widehat{\\beta}_{\\lambda,j} = 0$。\n\n我们将设计矩阵 $X$ 划分为 $X_S$ 和 $X_{S^c}$，分别对应于 $S$ 和 $S^c$ 中的列。类似地，我们将像 $\\beta$ 这样的向量划分为 $\\beta_S$ 和 $\\beta_{S^c}$。在支撑集恢复的假设下，由于 $\\widehat{\\beta}_{\\lambda,S^c} = 0$，我们有 $X\\widehat{\\beta}_{\\lambda} = X_S \\widehat{\\beta}_{\\lambda,S}$。\n\n现在 KKT 条件可以根据划分 $(S, S^c)$ 分为两部分：\n1.  对于索引 $j \\in S$（激活集）：\n    $$ \\frac{1}{n}X_S^{\\top}(y - X_S\\widehat{\\beta}_{\\lambda,S}) = \\lambda \\operatorname{sgn}(\\widehat{\\beta}_{\\lambda,S}) $$\n2.  对于索引 $j \\in S^c$（非激活集）：\n    $$ \\left|\\frac{1}{n}X_{S^c}^{\\top}(y - X_S\\widehat{\\beta}_{\\lambda,S})\\right| \\le \\lambda \\quad (\\text{逐元素不等式}) $$\n\n为了使精确恢复有意义，特别是在 $\\lambda \\to 0$ 的渐近意义上，我们要求符号一致性：$\\operatorname{sgn}(\\widehat{\\beta}_{\\lambda,S}) = \\operatorname{sgn}(\\beta_S)$。我们假设这一点成立。第一个 KKT 条件变为：\n$$ \\frac{1}{n}X_S^{\\top}(y - X_S\\widehat{\\beta}_{\\lambda,S}) = \\lambda \\operatorname{sgn}(\\beta_S) $$\n代入线性模型 $y = X_S\\beta_S + \\varepsilon$（因为 $\\beta_{S^c} = 0$）：\n$$ \\frac{1}{n}X_S^{\\top}(X_S\\beta_S + \\varepsilon - X_S\\widehat{\\beta}_{\\lambda,S}) = \\lambda \\operatorname{sgn}(\\beta_S) $$\n使用样本格拉姆矩阵的定义 $G = X^{\\top}X/n$，其子矩阵为 $G_{S,S} = X_S^{\\top}X_S/n$。该方程简化为：\n$$ G_{S,S}(\\beta_S - \\widehat{\\beta}_{\\lambda,S}) + \\frac{1}{n}X_S^{\\top}\\varepsilon = \\lambda \\operatorname{sgn}(\\beta_S) $$\n假设 $G_{S,S}$ 可逆，我们可以表示出差值 $(\\beta_S - \\widehat{\\beta}_{\\lambda,S})$：\n$$ \\beta_S - \\widehat{\\beta}_{\\lambda,S} = G_{S,S}^{-1} \\left( \\lambda \\operatorname{sgn}(\\beta_S) - \\frac{1}{n}X_S^{\\top}\\varepsilon \\right) $$\n\n现在我们分析非激活集 $S^c$ 的第二个 KKT 条件。我们代入残差 $y - X_S\\widehat{\\beta}_{\\lambda,S}$ 的表达式：\n$$ y - X_S\\widehat{\\beta}_{\\lambda,S} = (X_S\\beta_S + \\varepsilon) - X_S\\widehat{\\beta}_{\\lambda,S} = X_S(\\beta_S - \\widehat{\\beta}_{\\lambda,S}) + \\varepsilon $$\n再代入 $(\\beta_S - \\widehat{\\beta}_{\\lambda,S})$ 的表达式：\n$$ y - X_S\\widehat{\\beta}_{\\lambda,S} = X_S G_{S,S}^{-1} \\left( \\lambda \\operatorname{sgn}(\\beta_S) - \\frac{1}{n}X_S^{\\top}\\varepsilon \\right) + \\varepsilon $$\n现在，我们将其代入非激活集的 KKT 条件中：\n$$ \\left| \\frac{1}{n}X_{S^c}^{\\top} \\left( X_S G_{S,S}^{-1} \\lambda \\operatorname{sgn}(\\beta_S) - X_S G_{S,S}^{-1} \\frac{1}{n}X_S^{\\top}\\varepsilon + \\varepsilon \\right) \\right| \\le \\lambda $$\n使用 $G_{S^c,S} = X_{S^c}^{\\top}X_S/n$ 并整理各项：\n$$ \\left| \\lambda G_{S^c,S} G_{S,S}^{-1} \\operatorname{sgn}(\\beta_S) + \\frac{1}{n}(X_{S^c}^{\\top} - X_{S^c}^{\\top}X_S G_{S,S}^{-1} \\frac{1}{n}X_S^{\\top})\\varepsilon \\right| \\le \\lambda $$\n两边同除以 $\\lambda  0$：\n$$ \\left| G_{S^c,S} G_{S,S}^{-1} \\operatorname{sgn}(\\beta_S) + \\frac{1}{\\lambda} \\cdot (\\text{噪声项}) \\right| \\le 1 $$\n为了使这个不等式成立，特别是对于一系列小的 $\\lambda$ 值（此时噪声项可能不可忽略），表达式的确定性部分必须严格有界且小于 1。如果向量 $G_{S^c,S} G_{S,S}^{-1} \\operatorname{sgn}(\\beta_S)$ 的任何元素的绝对值等于或大于 1，那么即使很小的噪声 $\\varepsilon$ 也容易导致该不等式被违反。因此，稳健的支撑集恢复的一个必要条件是**不可表示条件**：\n$$ \\left\\| G_{S^c,S} G_{S,S}^{-1} \\operatorname{sgn}(\\beta_S) \\right\\|_{\\infty}  1 $$\n量 $\\mu = \\left\\| G_{S^c,S} G_{S,S}^{-1} \\operatorname{sgn}(\\beta_S) \\right\\|_{\\infty}$ 就是不可表示指数。\n\n### 特征相关性和 $p \\gg n$ 情景的作用\n\n不可表示条件突显了特征相关性的关键作用。\n- $G_{S,S} = X_S^{\\top}X_S/n$ 表示真实预测变量*之间*的相关性。如果这些预测变量高度相关（多重共线性），$G_{S,S}$ 将是病态的，其逆矩阵 $G_{S,S}^{-1}$ 将会有较大的元素值。\n- $G_{S^c,S} = X_{S^c}^{\\top}X_S/n$ 表示真实预测变量（在 $S$ 中）与不相关的“噪声”预测变量（在 $S^c$ 中）*之间*的相关性。\n\n乘积 $G_{S^c,S} G_{S,S}^{-1}$ 可以解释为将每个噪声预测变量 $X_j$ ($j \\in S^c$) 对真实预测变量集 $X_S$ 进行回归时的回归系数矩阵。如果一个噪声预测变量 $X_j$ 可以被真实预测变量的线性组合很好地近似，那么 $G_{S^c,S} G_{S,S}^{-1}$ 中对应的行将具有较大的元素值。当这个线性组合与真实系数 $\\beta_S$ 的符号一致时，不可表示指数 $\\mu$ 就可能超过 1。\n\n在这种情况下，LASSO 无法区分真实的稀疏模型与一个包含了高度相关的噪声预测变量的模型。术语“不可表示”在这里有些反直觉，它指的是*噪声预测变量*不能被*真实预测变量*“表示”（represent），而条件失败则意味着噪声预测变量可以被真实预测变量过度地表示。\n\n在小样本、大维度 ($p \\gg n$) 的情景下，有几个因素会加剧这个问题：\n1.  高维度性：当存在大量噪声预测变量（$p-k \\gg n$）时，在 $S^c$ 中找到一个或多个与 $S$ 中变量伪高度相关的预测变量的概率会急剧增加。\n2.  病态性：当真实预测变量的数量 $k$ 接近样本量 $n$ 时，矩阵 $G_{S,S}$ 会变得病态或奇异，导致 $\\|G_{S,S}^{-1}\\|$ 急剧增大。这会放大激活集和非激活集之间任何已有的相关性。\n3.  伪相关：当 $n$ 较小时，样本格拉姆矩阵 $G$ 是总体协方差的一个有噪声的估计。随机性可能会产生在底层数据生成过程中并不存在的强样本相关性，从而导致违反该条件。\n\n这些因素的结合使得在 $p \\gg n$ 情景下使用 LASSO 进行精确支撑集恢复变得极具挑战性。不可表示条件为这一挑战提供了精确的数学表述，表明成功与否关键取决于设计矩阵的相关性结构。",
            "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef _generate_data(n, p, k, b, sigma, seed, construction):\n    \"\"\"Generates synthetic data for a single LASSO scenario.\"\"\"\n    rng = np.random.default_rng(seed)\n    # Start with an independent standard normal design matrix\n    X = rng.standard_normal((n, p))\n    \n    # Apply specific correlation structures based on the scenario\n    if construction == 'single_correlate':\n        # Create non-support features highly correlated with a single support feature\n        for j in [50, 51, 52]:\n            u_j = rng.standard_normal(n)\n            X[:, j] = 0.95 * X[:, 0] + np.sqrt(1.0 - 0.95**2) * u_j\n    elif construction == 'multiple_correlates':\n        # Create non-support features that are linear combinations of multiple support features\n        correlates_def = {\n            60: [0, 1], 61: [1, 2], 62: [2, 3], 63: [3, 4], 64: [0, 4]\n        }\n        for j, support_indices in correlates_def.items():\n            u_j = rng.standard_normal(n)\n            # Coefficients are chosen to likely violate the irrepresentable condition\n            linear_combo = 0.8 * X[:, support_indices[0]] + 0.8 * X[:, support_indices[1]]\n            X[:, j] = linear_combo + 0.1 * u_j\n            \n    # Standardize columns of X: mean 0, Euclidean norm sqrt(n)\n    X -= X.mean(axis=0)\n    col_norms = np.linalg.norm(X, axis=0)\n    # Avoid division by zero for columns that might be all zero by adding a small epsilon.\n    X = X / (col_norms + 1e-9) * np.sqrt(n)\n    \n    # Define true coefficient vector beta and support S\n    beta_true = np.zeros(p)\n    beta_true[:k] = b\n    S = set(range(k))\n    \n    # Generate response vector y\n    epsilon = rng.standard_normal(n) * sigma\n    y = X @ beta_true + epsilon\n    \n    # Center y\n    y -= y.mean()\n    \n    return X, y, beta_true, S\n\ndef _calculate_mu(X, S, beta_true, n, p):\n    \"\"\"Calculates the irrepresentable index mu.\"\"\"\n    # Compute the sample Gram matrix\n    G = (X.T @ X) / n\n    \n    # Partition the Gram matrix according to the support S and its complement Sc\n    S_list = sorted(list(S))\n    Sc_list = sorted(list(set(range(p)) - S))\n    \n    G_Sc_S = G[np.ix_(Sc_list, S_list)]\n    G_S_S = G[np.ix_(S_list, S_list)]\n    \n    # Compute the inverse of G_S_S using the Moore-Penrose pseudoinverse for stability\n    # The check_finite=False argument is needed for some edge cases with older scipy versions.\n    G_S_S_inv = linalg.pinv(G_S_S, check_finite=False)\n\n    # Get the sign vector of the true coefficients on the support\n    sgn_beta_S = np.sign(beta_true[S_list])\n    \n    # Compute the vector whose max absolute value is the irrepresentable index\n    v = G_Sc_S @ G_S_S_inv @ sgn_beta_S\n    \n    # The irrepresentable index mu is the infinity norm of this vector\n    mu = np.max(np.abs(v))\n    \n    return mu\n\ndef _lasso_cd(X, y, lambda_, max_iter=1000, tol=1e-7):\n    \"\"\"Fits the LASSO estimator using coordinate descent.\"\"\"\n    n, p = X.shape\n    beta = np.zeros(p)\n    \n    # Coordinate descent with efficient residual updates.\n    # Because X columns are normalized to have squared L2-norm of n,\n    # the updates simplify nicely.\n    residual = y.copy()\n\n    for _ in range(max_iter):\n        max_change = 0.0\n        for j in range(p):\n            beta_j_old = beta[j]\n            \n            # The argument for the soft-thresholding operator is a_j.\n            # a_j = (Xj.T @ (y - X@beta_except_j)) / n\n            # This can be efficiently computed as:\n            # a_j = (Xj.T @ current_residual)/n + (Xj.T @ Xj / n) * beta_j_old\n            # Since Xj.T @ Xj / n = 1 in our setup\n            a_j = (X[:, j] @ residual) / n + beta_j_old\n            \n            # Apply the soft-thresholding operator S_lambda(a_j)\n            beta[j] = np.sign(a_j) * max(abs(a_j) - lambda_, 0.0)\n            \n            delta_beta_j = beta[j] - beta_j_old\n            if delta_beta_j != 0.0:\n                residual -= X[:, j] * delta_beta_j\n            \n            if abs(delta_beta_j)  max_change:\n                max_change = abs(delta_beta_j)\n        \n        if max_change  tol:\n            break\n            \n    return beta\n\ndef _check_recovery(beta_hat, S, tol=1e-6):\n    \"\"\"Checks if the estimated support equals the true support.\"\"\"\n    S_hat = {i for i, b in enumerate(beta_hat) if abs(b)  tol}\n    return S_hat == S\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Scenario 1: Weak correlations, recovery expected.\n        {'n': 30, 'p': 80, 'k': 5, 'b': 1.0, 'sigma': 0.01, 'lambda_': 0.2, 'seed': 0, 'construction': 'independent'},\n        # Scenario 2: Strong correlation, recovery challenging.\n        {'n': 30, 'p': 80, 'k': 5, 'b': 1.0, 'sigma': 0.05, 'lambda_': 0.05, 'seed': 1, 'construction': 'single_correlate'},\n        # Scenario 3: Multiple strong correlates, recovery expected to fail.\n        {'n': 30, 'p': 80, 'k': 5, 'b': 1.0, 'sigma': 0.01, 'lambda_': 0.2, 'seed': 2, 'construction': 'multiple_correlates'},\n    ]\n\n    results = []\n    for params in test_cases:\n        # Unpack parameters\n        n, p, k, b = params['n'], params['p'], params['k'], params['b']\n        sigma, lambda_ = params['sigma'], params['lambda_']\n        seed, construction = params['seed'], params['construction']\n        \n        # 1. Generate data\n        X, y, beta_true, S = _generate_data(n, p, k, b, sigma, seed, construction)\n        \n        # 2. Compute irrepresentable index and condition\n        mu = _calculate_mu(X, S, beta_true, n, p)\n        irrep_cond_holds = mu  1.0\n        \n        # 3. Fit LASSO model using coordinate descent\n        beta_hat = _lasso_cd(X, y, lambda_)\n\n        # 4. Check for exact support recovery\n        recovery_succeeded = _check_recovery(beta_hat, S)\n        \n        results.append([mu, irrep_cond_holds, recovery_succeeded])\n\n    # Format the final output string as specified\n    formatted_results = [f\"[{res[0]:.6f},{str(res[1]).lower()},{str(res[2]).lower()}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}