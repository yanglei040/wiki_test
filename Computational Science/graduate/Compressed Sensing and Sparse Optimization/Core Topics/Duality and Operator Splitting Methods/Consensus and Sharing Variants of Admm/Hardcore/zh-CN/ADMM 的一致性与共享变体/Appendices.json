{
    "hands_on_practices": [
        {
            "introduction": "理论联系实际是掌握任何算法的关键。在本节中，我们将通过一系列实践操作来深化对交替方向乘子法（ADMM）共识变体的理解。这些练习旨在将理论知识转化为解决实际问题的能力，涵盖从性能分析到算法调优和优化的核心技能。\n\n在部署分布式算法之前，对其计算成本进行量化分析是至关重要的第一步。这个练习将指导你精确计算共识ADMM单次迭代的浮点运算（flop）次数，从而具体理解问题维度 $n$ 和智能体数量 $N$ 如何影响算法性能。通过这种分析，你可以识别潜在的计算瓶颈，并为算法优化提供依据 。",
            "id": "3438216",
            "problem": "考虑在压缩感知和稀疏优化中的二次损失共识表述，其中 $N$ 个代理持有局部数据矩阵 $A_i \\in \\mathbb{R}^{m_i \\times n}$ 和向量 $b_i \\in \\mathbb{R}^{m_i}$，并寻求就一个全局变量 $v \\in \\mathbb{R}^{n}$ 达成一致。交替方向乘子法 (ADMM) 通过求解如下对称正定线性系统来更新局部变量 $x_i \\in \\mathbb{R}^{n}$\n$$\n\\left(A_i^{\\top}A_i + \\rho I\\right)x_i = A_i^{\\top} b_i + \\rho \\left(v - u_i\\right),\n$$\n其中 $u_i \\in \\mathbb{R}^{n}$ 是缩放对偶变量，并通过平均法更新共识变量\n$$\nv \\leftarrow \\frac{1}{N}\\sum_{i=1}^{N}\\left(x_i + u_i\\right).\n$$\n假设存在以下单次迭代场景和计数模型：\n- $A_i^{\\top}A_i$ 和 $A_i^{\\top}b_i$ 已离线预计算并存储，但惩罚参数 $\\rho$ 在每次迭代时自适应更新，因此 $\\left(A_i^{\\top}A_i + \\rho I\\right)$ 的Cholesky分解必须在每次迭代中重新计算。\n- 矩阵 $A_i^{\\top}A_i + \\rho I$ 是维度为 $n \\times n$ 的稠密对称正定矩阵；每个系统的求解通过进行Cholesky分解，然后进行两次三角求解来完成。\n- 在标准稠密代价模型下计算浮点运算次数 (flops)：每次标量加法或乘法消耗 $1$ flop；将 $\\rho$ 加到对角线上消耗 $n$ flops；一个稠密的 $n \\times n$ 对称正定矩阵的Cholesky分解消耗 $\\frac{n^{3}}{3}$ flops；使用一个稠密的 $n \\times n$ 三角矩阵和一个稠密的 $n$ 维向量进行一次三角求解消耗 $n^{2}$ flops；构建右端项 $A_i^{\\top}b_i + \\rho(v - u_i)$ 消耗 $3n$ flops；全局平均步骤 $v \\leftarrow \\frac{1}{N}\\sum_{i=1}^{N}(x_i + u_i)$ 通过单遍将 $(x_i + u_i)$ 累加到 $v$ 中，然后用 $\\frac{1}{N}$ 缩放 $v$ 来计算，消耗 $2Nn + n$ flops。\n\n在这些假设下，计算每次迭代的总浮点运算次数的精确值，结果应为一个关于 $N$ 和 $n$ 的闭式表达式，并计及以下所有操作：\n- 所有 $N$ 个局部 $x_i$ 更新，包括每个代理的对角线调整、Cholesky分解、右端项构建和两次三角求解，\n- 加上对 $v$ 的全局平均步骤。\n\n将你的最终答案表示为单个解析表达式。无需四舍五入。不涉及物理单位。答案必须是单个表达式，而不是不等式或等式。",
            "solution": "我们从共识表述开始，其中每个代理 $i \\in \\{1, \\dots, N\\}$ 通过求解对称正定系统来执行 $x_i$ 的局部更新\n$$\n\\left(A_i^{\\top}A_i + \\rho I\\right)x_i = A_i^{\\top} b_i + \\rho \\left(v - u_i\\right).\n$$\n鉴于 $A_i^{\\top}A_i$ 和 $A_i^{\\top}b_i$ 已经离线预计算，每个代理单次迭代的操作包括：\n- 对角线调整：将 $\\rho$ 加到 $A_i^{\\top}A_i$ 的 $n$ 个对角线元素上，消耗 $n$ flops；\n- $\\left(A_i^{\\top}A_i + \\rho I\\right)$ 的Cholesky分解，消耗 $\\frac{n^{3}}{3}$ flops；\n- 构建右端项 $r_i = A_i^{\\top}b_i + \\rho(v - u_i)$，消耗 $3n$ flops（一次用于 $v - u_i$ 的减法，一次与 $\\rho$ 的标量乘法，一次与 $A_i^{\\top}b_i$ 的加法）；\n- 使用Cholesky因子通过两次三角求解来解该系统：\n  - 使用下三角因子进行前向求解：$n^{2}$ flops，\n  - 使用转置（上三角）进行后向求解：$n^{2}$ flops，\n  总计 $2n^{2}$ flops。\n\n将单个代理的这些消耗加总，得到\n$$\n\\text{每个代理的局部代价} = n + \\frac{n^{3}}{3} + 3n + 2n^{2} = \\frac{n^{3}}{3} + 2n^{2} + 4n.\n$$\n对于所有 $N$ 个代理，总的局部更新代价是\n$$\nN\\left(\\frac{n^{3}}{3} + 2n^{2} + 4n\\right).\n$$\n\n接下来，考虑全局平均步骤\n$$\nv \\leftarrow \\frac{1}{N}\\sum_{i=1}^{N}\\left(x_i + u_i\\right).\n$$\n单遍累加策略通过遍历 $i$ 将 $x_i + u_i$ 加到一个运行总和中，然后用 $\\frac{1}{N}$ 进行缩放来计算 $v$。此步骤的单次迭代flop计数为：\n- 对每个 $i$ 计算 $x_i + u_i$：$Nn$ 次加法，\n- 对每个 $i$ 累加到 $v$ 中：另外 $Nn$ 次加法，\n- 用 $\\frac{1}{N}$ 缩放 $v$：$n$ 次乘法，\n总计\n$$\n2Nn + n\n$$\nflops。\n\n因此，结合所有局部更新和全局平均步骤，单次迭代的总flop计数为\n$$\nN\\left(\\frac{n^{3}}{3} + 2n^{2} + 4n\\right) + \\left(2Nn + n\\right) = \\frac{N}{3}n^{3} + 2Nn^{2} + 6Nn + n.\n$$\n这就是所要求的，一个关于 $N$ 和 $n$ 的闭式解析表达式。",
            "answer": "$$\\boxed{\\frac{N}{3}n^{3} + 2Nn^{2} + 6Nn + n}$$"
        },
        {
            "introduction": "成功运行像ADMM这样的迭代算法，不仅仅是启动程序那么简单，更需要持续监控其收敛进程并进行动态调整。这个问题模拟了一个典型的实际场景：你将面对一份真实的迭代日志，需要根据原始残差和对偶残差的变化来判断算法是否收敛，并决定如何调整关键的惩罚参数 $\\rho$ 以平衡原始可行性和对偶可行性，从而加速收敛。掌握这项技能是高效应用ADMM的核心 。",
            "id": "3438215",
            "problem": "考虑将交替方向乘子法（ADMM）的分布式一致性形式应用于一个包含 $M$ 个智能体的压缩感知模型，其中需要求解 $\\min_{x_1,\\ldots,x_M,z}\\sum_{i=1}^M f_i(x_i)+g(z)$，约束条件为对所有 $i\\in\\{1,\\ldots,M\\}$ 都有 $x_i=z$。假设使用缩放形式的ADMM，其缩放对偶变量为 $u_i$。设原始残差为堆叠的一致性违反量 $r^k=\\big(x_1^k-z^k,\\ldots,x_M^k-z^k\\big)$，对偶残差为 $s^k=\\rho\\big(z^k-z^{k-1}\\big)$（广播到每个块，因此报告的范数是堆叠向量的范数）。给定以下在使用固定惩罚参数 $\\rho$ 时得到的这些残差的欧几里得范数的迭代日志，其中 $k\\in\\{1,\\ldots,11\\}$：\n- 迭代索引：$k=\\{1,2,3,4,5,6,7,8,9,10,11\\}$。\n- 原始残差范数：$\\{\\lVert r^1\\rVert_2,\\ldots,\\lVert r^{11}\\rVert_2\\}=\\{1.0\\times 10^{0},\\,5.0\\times 10^{-1},\\,2.5\\times 10^{-1},\\,1.2\\times 10^{-1},\\,6.0\\times 10^{-2},\\,3.0\\times 10^{-2},\\,1.5\\times 10^{-2},\\,7.0\\times 10^{-3},\\,3.5\\times 10^{-3},\\,1.7\\times 10^{-3},\\,8.0\\times 10^{-4}\\}$。\n- 对偶残差范数：$\\{\\lVert s^1\\rVert_2,\\ldots,\\lVert s^{11}\\rVert_2\\}=\\{1.0\\times 10^{-4},\\,2.0\\times 10^{-4},\\,4.0\\times 10^{-4},\\,8.0\\times 10^{-4},\\,1.6\\times 10^{-3},\\,8.0\\times 10^{-4},\\,4.0\\times 10^{-4},\\,2.0\\times 10^{-4},\\,1.0\\times 10^{-4},\\,5.0\\times 10^{-5},\\,2.5\\times 10^{-5}\\}$。\n\n假设在每次迭代中，绝对和相对停止容限评估为固定的阈值，即 $\\varepsilon_{\\mathrm{pri}}=1.0\\times 10^{-3}$ 和 $\\varepsilon_{\\mathrm{dual}}=1.0\\times 10^{-3}$。你需要仅根据上述日志和标准的一致性ADMM实践，来决定何时停止算法，以及是否以及如何调整惩罚参数 $\\rho$ 以在保持稳定性的同时提高收敛速度。特别地，你的答案应遵循以下原则：\n- 停止条件应反映与 Karush–Kuhn–Tucker 条件相关的原始和对偶可行性的近似满足。\n- 调整 $\\rho$ 的决策应由增广拉格朗日动力学中原始和对偶进展之间的相互作用来证明其合理性。\n\n选择下面唯一的最佳策略。\n\nA. 在迭代 $k=11$ 之前不要停止，因为你需要同时满足 $\\lVert r^k\\rVert_2\\le \\varepsilon_{\\mathrm{pri}}$ 和 $\\lVert s^k\\rVert_2\\le \\varepsilon_{\\mathrm{dual}}$，这在 $k=11$ 时首次发生。为了加速 $\\lVert r^k\\rVert_2\\gg \\lVert s^k\\rVert_2$ 的早期迭代（例如，对于 $k\\in\\{1,2,3,4,5,6,7,8,9,10\\}$），每当 $\\lVert r^k\\rVert_2>10\\,\\lVert s^k\\rVert_2$ 时，以乘法方式增加 $\\rho$（例如，乘以因子2），并通过乘以逆因子来重新缩放缩放的对偶变量以保持等价性。这会增加对一致性的权重，更积极地缩小 $\\lVert r^k\\rVert_2$，并平衡残差，通常在不牺牲稳定性的前提下提高收敛速度。\n\nB. 在迭代 $k=5$ 时停止，因为在那之后 $\\lVert r^k\\rVert_2$ 继续下降到 $\\varepsilon_{\\mathrm{pri}}$ 以下，并且 $\\lVert s^k\\rVert_2$ 达到峰值；为避免在 $k=5$ 时的对偶残差峰值，每当 $\\lVert r^k\\rVert_2>10\\,\\lVert s^k\\rVert_2$ 时减小 $\\rho$，这可以防止对偶残差增长并提高稳定性。\n\nC. 在迭代 $k=11$ 时停止，但为了提高 $\\lVert r^k\\rVert_2\\gg \\lVert s^k\\rVert_2$ 的早期阶段的稳定性，对 $k\\in\\{1,2,3,4\\}$ 减小 $\\rho$（例如，除以因子2），使得增广拉格朗日惩罚更温和；这降低了 $z$-更新的刚度，从而加速了原始可行性的达成。\n\nD. 全程保持 $\\rho$ 固定以避免不稳定性，并在迭代 $k=8$ 时停止，因为即使 $\\lVert s^8\\rVert_2>\\varepsilon_{\\mathrm{dual}}$，也有 $\\lVert r^8\\rVert_2\\varepsilon_{\\mathrm{pri}}$；在一致性ADMM中，原始残差满足其容限就足够了，因为对偶残差最终会衰减。",
            "solution": "用户希望我扮演一位严格的理工科教授，来分析一个关于交替方向乘子法（ADMM）的问题。\n\n### 第1步：提取已知信息\n\n-   **问题：** 用于 $\\min_{x_1,\\ldots,x_M,z}\\sum_{i=1}^M f_i(x_i)+g(z)$，约束为对所有 $i\\in\\{1,\\ldots,M\\}$ 都有 $x_i=z$ 的分布式一致性ADMM。\n-   **算法：** 缩放形式的ADMM，惩罚参数为 $\\rho$，缩放对偶变量为 $u_i$。\n-   **原始残差：** $r^k=\\big(x_1^k-z^k,\\ldots,x_M^k-z^k\\big)$。\n-   **对偶残差：** $s^k=\\rho\\big(z^k-z^{k-1}\\big)$。\n-   **迭代日志 ($k=1, \\dots, 11$):**\n    -   原始残差范数, $\\lVert r^k\\rVert_2$: $\\{1.0\\times 10^{0},\\,5.0\\times 10^{-1},\\,2.5\\times 10^{-1},\\,1.2\\times 10^{-1},\\,6.0\\times 10^{-2},\\,3.0\\times 10^{-2},\\,1.5\\times 10^{-2},\\,7.0\\times 10^{-3},\\,3.5\\times 10^{-3},\\,1.7\\times 10^{-3},\\,8.0\\times 10^{-4}\\}$。\n    -   对偶残差范数, $\\lVert s^k\\rVert_2$: $\\{1.0\\times 10^{-4},\\,2.0\\times 10^{-4},\\,4.0\\times 10^{-4},\\,8.0\\times 10^{-4},\\,1.6\\times 10^{-3},\\,8.0\\times 10^{-4},\\,4.0\\times 10^{-4},\\,2.0\\times 10^{-4},\\,1.0\\times 10^{-4},\\,5.0\\times 10^{-5},\\,2.5\\times 10^{-5}\\}$。\n-   **停止容限：** $\\varepsilon_{\\mathrm{pri}}=1.0\\times 10^{-3}$ 和 $\\varepsilon_{\\mathrm{dual}}=1.0\\times 10^{-3}$。\n-   **目标：** 确定正确的停止迭代次数和调整 $\\rho$ 的适当策略。\n\n### 第2步：使用提取的已知信息进行验证\n\n-   **科学上 обоснованный：** 问题背景是一致性ADMM，这是分布式优化和信号处理中一个标准且广泛使用的算法。问题公式、原始和对偶残差的定义，以及惩罚参数自适应的概念都是ADMM理论和实践中的标准元素。所提供的数值数据，显示初始原始残差大而对偶残差小，是一种常见情况。\n-   **问题适定性：** 问题是适定的。它提供了具体的数据集，并要求根据已建立的算法实践进行解释。在存在一种标准的、被广泛接受的针对所述情况的启发式方法的意义上，存在一个唯一的“最佳策略”。\n-   **客观性：** 问题陈述客观，使用精确的数学定义并提供数值数据。它要求根据标准实践做出决策，这是一个可验证的标准。\n\n问题陈述没有违反任何无效性标准。它在科学上是合理的、适定的、客观的，并且对于手头的任务是完整的。\n\n### 第3步：结论和行动\n\n问题是**有效的**。我将继续进行求解。\n\n### 推导与分析\n\n问题需要两个主要决策：何时停止算法，以及如何调整惩罚参数 $\\rho$ 以获得更好的性能。\n\n**1. 停止准则**\n\nADMM的标准停止条件基于原始和对偶残差，它们衡量了Karush-Kuhn-Tucker（KKT）条件的满足程度。算法在迭代 $k$ 终止，如果以下两个条件都满足：\n$$ \\lVert r^k \\rVert_2 \\le \\varepsilon_{\\mathrm{pri}} $$\n$$ \\lVert s^k \\rVert_2 \\le \\varepsilon_{\\mathrm{dual}} $$\n给定 $\\varepsilon_{\\mathrm{pri}} = 1.0 \\times 10^{-3}$ 和 $\\varepsilon_{\\mathrm{dual}} = 1.0 \\times 10^{-3}$。我们检查提供的迭代日志，以找到第一个同时满足这两个条件的迭代 $k$。\n\n-   **原始残差条件：** $\\lVert r^k \\rVert_2 \\le 1.0 \\times 10^{-3}$\n    -   对于 $k=1, \\dots, 10$，范数分别为 $1.0, 0.5, 0.25, 0.12, 0.06, 0.03, 0.015, 7.0 \\times 10^{-3}, 3.5 \\times 10^{-3}, 1.7 \\times 10^{-3}$。所有这些都大于 $1.0 \\times 10^{-3}$。\n    -   对于 $k=11$，我们有 $\\lVert r^{11} \\rVert_2 = 8.0 \\times 10^{-4}$。因为 $8.0 \\times 10^{-4}  1.0 \\times 10^{-3}$，所以在 $k=11$ 时满足原始条件。\n\n-   **对偶残差条件：** $\\lVert s^k \\rVert_2 \\le 1.0 \\times 10^{-3}$\n    -   对于 $k=1,2,3,4$：范数为 $\\{1.0, 2.0, 4.0, 8.0\\} \\times 10^{-4}$，都 $\\le 1.0 \\times 10^{-3}$。条件满足。\n    -   对于 $k=5$：范数为 $\\lVert s^5 \\rVert_2 = 1.6 \\times 10^{-3}$，大于 $1.0 \\times 10^{-3}$。条件不满足。\n    -   对于 $k=6, \\dots, 11$：范数为 $\\{8.0, 4.0, 2.0, 1.0\\} \\times 10^{-4}$，$5.0 \\times 10^{-5}$ 和 $2.5 \\times 10^{-5}$。所有这些都 $\\le 1.0 \\times 10^{-3}$。条件满足。\n\n算法必须在**两个**条件首次同时满足时停止。\n-   在 $k=1, \\dots, 4$：原始条件失败，对偶条件通过。不停止。\n-   在 $k=5$：原始条件失败，对偶条件失败。不停止。\n-   在 $k=6, \\dots, 10$：原始条件失败，对偶条件通过。不停止。\n-   在 $k=11$：原始条件通过（$\\lVert r^{11} \\rVert_2 = 8.0 \\times 10^{-4} \\le 1.0 \\times 10^{-3}$）且对偶条件通过（$\\lVert s^{11} \\rVert_2 = 2.5 \\times 10^{-5} \\le 1.0 \\times 10^{-3}$）。两个条件都满足。\n\n因此，正确的停止迭代是 $k=11$。\n\n**2. 惩罚参数自适应**\n\n原始和对偶残差的相对大小为调整 $\\rho$ 的策略提供了信息。目标是平衡残差，因为这通常会导致更快的收敛。标准启发式方法如下：\n-   如果原始残差远大于对偶残差，即对于某个 $\\mu > 1$（例如 $\\mu=10$），有 $\\lVert r^k \\rVert_2 > \\mu \\lVert s^k \\rVert_2$，这表明原始可行性（本例中为一致性）是瓶颈。为了解决这个问题，应该**增加**惩罚参数 $\\rho$（例如，$\\rho \\to \\tau\\rho$，其中 $\\tau>1$，例如 $\\tau=2$）。这会对违反约束 $x_i = z$ 施加更高的惩罚，从而促使原始残差更快地减小。\n-   如果对偶残差远大于原始残差，即 $\\lVert s^k \\rVert_2 > \\mu \\lVert r^k \\rVert_2$，则应**减小** $\\rho$（$\\rho \\to \\rho/\\tau$）。\n\n让我们从日志中检查比率 $\\lVert r^k \\rVert_2 / \\lVert s^k \\rVert_2$，使用 $\\mu=10$ 作为典型阈值。\n-   $k=1$: $1.0 / (1.0 \\times 10^{-4}) = 10000 \\gg 10$\n-   $k=2$: $0.5 / (2.0 \\times 10^{-4}) = 2500 \\gg 10$\n-   $k=3$: $0.25 / (4.0 \\times 10^{-4}) = 625 \\gg 10$\n-   $k=4$: $0.12 / (8.0 \\times 10^{-4}) = 150 \\gg 10$\n-   $k=5$: $(6.0 \\times 10^{-2}) / (1.6 \\times 10^{-3}) = 37.5 \\gg 10$\n-   ...\n-   $k=11$: $(8.0 \\times 10^{-4}) / (2.5 \\times 10^{-5}) = 32 \\gg 10$\n\n在日志中的每一次迭代中，原始残差范数都显著大于对偶残差范数。条件 $\\lVert r^k\\rVert_2>10\\,\\lVert s^k\\rVert_2$ 总是满足的。这表明 $\\rho$ 的初始选择太小，导致在满足一致性约束方面进展缓慢。正确的自适应策略是**增加 $\\rho$**。\n\n在缩放形式的ADMM中调整 $\\rho$ 时，至关重要的是也要重新缩放对偶变量 $u_i$ 以维持等价关系 $y_i = \\rho u_i$，其中 $y_i$ 是未缩放的对偶变量。如果 $\\rho$ 更新为 $\\rho_{\\text{new}} = \\tau \\rho_{\\text{old}}$，那么缩放对偶变量必须更新为 $u_{i, \\text{new}} = u_{i, \\text{old}} / \\tau$。这对应于用逆因子重新缩放。\n\n### 逐项分析\n\n**A. 在迭代 $k=11$ 之前不要停止，因为你需要同时满足 $\\lVert r^k\\rVert_2\\le \\varepsilon_{\\mathrm{pri}}$ 和 $\\lVert s^k\\rVert_2\\le \\varepsilon_{\\mathrm{dual}}$，这在 $k=11$ 时首次发生。为了加速 $\\lVert r^k\\rVert_2\\gg \\lVert s^k\\rVert_2$ 的早期迭代（例如，对于 $k\\in\\{1,2,3,4,5,6,7,8,9,10\\}$），每当 $\\lVert r^k\\rVert_2>10\\,\\lVert s^k\\rVert_2$ 时，以乘法方式增加 $\\rho$（例如，乘以因子2），并通过乘以逆因子来重新缩放缩放的对偶变量以保持等价性。这会增加对一致性的权重，更积极地缩小 $\\lVert r^k\\rVert_2$，并平衡残差，通常在不牺牲稳定性的前提下提高收敛速度。**\n-   **停止：** 正确地将 $k=11$ 识别为停止迭代。\n-   **自适应：** 正确地识别出 $\\lVert r^k\\rVert_2 \\gg \\lVert s^k\\rVert_2$ 并提出了标准、正确的增加 $\\rho$ 的启发式方法。\n-   **重新缩放：** 正确地提到了对缩放对偶变量进行必要的重新缩放。\n-   **理由：** 提供的推理完全合理，并与ADMM理论一致。\n此选项是**正确的**。\n\n**B. 在迭代 $k=5$ 时停止，因为在那之后 $\\lVert r^k\\rVert_2$ 继续下降到 $\\varepsilon_{\\mathrm{pri}}$ 以下，并且 $\\lVert s^k\\rVert_2$ 达到峰值；为避免在 $k=5$ 时的对偶残差峰值，每当 $\\lVert r^k\\rVert_2>10\\,\\lVert s^k\\rVert_2$ 时减小 $\\rho$，这可以防止对偶残差增长并提高稳定性。**\n-   **停止：** 停止迭代 $k=5$ 是不正确的。在 $k=5$ 时，$\\lVert r^5 \\rVert_2 = 6.0 \\times 10^{-2} \\gg \\varepsilon_{\\mathrm{pri}}$ 并且 $\\lVert s^5 \\rVert_2 = 1.6 \\times 10^{-3} > \\varepsilon_{\\mathrm{dual}}$。\n-   **自适应：** 提议减小 $\\rho$ 与观察到的残差不平衡的正确策略相反。\n此选项是**不正确的**。\n\n**C. 在迭代 $k=11$ 时停止，但为了提高 $\\lVert r^k\\rVert_2\\gg \\lVert s^k\\rVert_2$ 的早期阶段的稳定性，对 $k\\in\\{1,2,3,4\\}$ 减小 $\\rho$（例如，除以因子2），使得增广拉格朗日惩罚更温和；这降低了 $z$-更新的刚度，从而加速了原始可行性的达成。**\n-   **停止：** 停止迭代 $k=11$ 是正确的。\n-   **自适应：** 提议减小 $\\rho$ 是不正确的。它会加剧原始/对偶残差的不平衡，并减慢而不是加速原始可行性的满足。其理由是有缺陷的。\n此选项是**不正确的**。\n\n**D. 全程保持 $\\rho$ 固定以避免不稳定性，并在迭代 $k=8$ 时停止，因为即使 $\\lVert s^8\\rVert_2>\\varepsilon_{\\mathrm{dual}}$，也有 $\\lVert r^8\\rVert_2\\varepsilon_{\\mathrm{pri}}$；在一致性ADMM中，原始残差满足其容限就足够了，因为对偶残差最终会衰减。**\n-   **停止：** 停止迭代 $k=8$ 是不正确的。声称 $\\lVert r^8\\rVert_2  \\varepsilon_{\\mathrm{pri}}$ 是事实错误的，因为 $\\lVert r^8\\rVert_2 = 7.0 \\times 10^{-3} > 1.0 \\times 10^{-3}$。\n-   **原则：** 断言仅满足原始容限就足够是根本错误的。收敛需要原始和对偶可行性。\n-   **自适应：** 虽然保持 $\\rho$ 固定是一种有效（尽管次优）的策略，但自适应 $\\rho$ 方案是标准做法，并且如果做得正确，通常可以提高性能而不会导致不稳定性。\n此选项是**不正确的**。\n\n基于此全面分析，选项A是唯一一个提出完全正确且理由充分的、与标准ADMM实践相符的策略。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在许多大规模问题中，ADMM迭代中最耗时的部分是求解其局部子问题。当这些子问题通过迭代方法（如预条件共轭梯度法，PCG）求解时，预处理（preconditioning）成为一种强大的加速工具。本练习将深入探讨如何设计一个简单而有效的对角预条件子，将数值线性代数中的理论（如Gershgorin圆盘定理）与ADMM的实际性能提升联系起来，展示了高级优化技巧在实践中的应用 。",
            "id": "3438192",
            "problem": "考虑一个用于稀疏回归任务的分布式一致性交替方向乘子法 (ADMM) 公式，其中工作节点 $i$ 持有数据矩阵 $A_i \\in \\mathbb{R}^{m_i \\times n}$ 和观测值 $b_i \\in \\mathbb{R}^{m_i}$。全局问题是在一致性分裂下最小化 $\\sum_{i=1}^N \\tfrac{1}{2}\\lVert A_i x - b_i \\rVert_2^2 + \\lambda \\lVert x \\rVert_1$，其中每个工作节点维护一个局部副本 $x_i$，并约束其等于一个全局变量 $z$。在缩放形式的 ADMM 中，第 $k$ 次迭代的 $x_i$ 更新需要求解对称正定线性系统\n$$(A_i^\\top A_i + \\rho I) x_i^{k+1} = A_i^\\top b_i + \\rho (z^k - u_i^k),$$\n其中 $\\rho > 0$ 是增广拉格朗日惩罚参数，$u_i^k$ 是缩放对偶变量。假设该系统通过预条件共轭梯度法 (PCG) 内迭代以固定的相对容差进行非精确求解。\n\n从以下经过充分检验的事实出发：\n- 对于任何对称正定矩阵 $H$，条件数为 $\\kappa(H) := \\lambda_{\\max}(H)/\\lambda_{\\min}(H)$，其中 $\\lambda_{\\max}(H)$ 和 $\\lambda_{\\min}(H)$ 分别是最大和最小特征值。\n- 对于应用于 $H x = b$ 的 PCG，若使用对称正定预条件子 $M$，其收敛速率由 $\\kappa(M^{-1/2} H M^{-1/2})$ 控制；具体来说，将误差的 $H$-范数减小一个因子 $\\epsilon \\in (0,1)$ 所需的迭代次数 $t(\\epsilon)$ 满足 $t(\\epsilon) = \\mathcal{O}\\!\\left(\\sqrt{\\kappa(M^{-1/2} H M^{-1/2})} \\log(1/\\epsilon)\\right)$。\n- Gershgorin 圆盘定理：一个方阵的每个特征值都位于至少一个圆盘内，该圆盘以某个对角线元素为圆心，其半径等于该行非对角线元素绝对值之和。\n\n您的目标是为内部 PCG 求解选择一个对角预条件子，以改善 $A_i^\\top A_i + \\rho I$ 的条件数，同时保持 ADMM 的不动点。哪个选项最好地提出了这样一个预条件子，并正确地阐述了其对内迭代次数和整体 ADMM 效率的影响？\n\nA. 使用 Jacobi 预条件子 $M_i := \\operatorname{diag}(A_i^\\top A_i) + \\rho I$，并应用对称预处理以获得 PCG 系统 $M_i^{-1/2} (A_i^\\top A_i + \\rho I) M_i^{-1/2}$。预处理后矩阵的特征值位于以 $1$ 为圆心、半径为 $r_i := \\sum_{j \\ne i} \\frac{|(A_i^\\top A_i)_{ij}|}{(A_i^\\top A_i)_{ii} + \\rho}$ 的 Gershgorin 圆盘的并集中，因此如果 $\\max_i r_i = r  1$，则 $\\kappa \\le \\frac{1+r}{1-r}$，该值随着 $\\rho$ 的增加而减小。因此，对于固定的容差，PCG 迭代次数按 $\\mathcal{O}(\\sqrt{\\kappa})$ 下降，并且因为待解的精确线性系统没有改变，所以 ADMM 的不动点得以保持；当对角预处理的开销可以忽略不计时，每次 ADMM 迭代的总墙上时钟时间减少，从而提高了端到端效率。\n\nB. 使用标量预条件子 $M_i := \\rho I$；这使得预处理后矩阵的条件数等于 $1$ 且与 $A_i$ 无关，因此对于任何容差，PCG 都在 1 次迭代内收敛，从而极大地加速了 ADMM。\n\nC. 使用完整预条件子 $M_i := A_i^\\top A_i + \\rho I$，使得预处理后系统的条件数恰好为 $1$；在 PCG 中应用 $M_i^{-1}$ 的成本相对于与 $A_i$ 和 $A_i^\\top$ 进行矩阵-向量乘法的成本可以忽略不计，因此内求解实际上需要 1 次迭代，而不会对整体效率产生不利影响。\n\nD. 使用对角预条件子 $M_i := \\operatorname{diag}(A_i^\\top A_i)$（不含 $\\rho I$ 项）。虽然 PCG 迭代次数可能会减少，但对角缩放会改变局部子问题，从而改变 ADMM 的不动点；外部 ADMM 的收敛可能会加速，但会收敛到与未使用预处理方法不同的解。\n\n选择所有适用项。",
            "solution": "我们使用核心原则来分析所提出的预条件子：对称正定系统的条件数、基于 Gershgorin 定理的对角缩放矩阵的界，以及预条件共轭梯度法收敛性对预处理算子谱的依赖关系。我们还援引了 ADMM 不动点在内部线性求解器预处理下的不变性，前提是同一个线性系统被求解到固定的容差。\n\n设 $H_i := A_i^\\top A_i + \\rho I$，对于任何 $\\rho > 0$，该矩阵都是对称正定的。使用对称正定预条件子 $M_i$ 的 PCG 可以有效地求解 $M_i^{-1/2} H_i M_i^{-1/2} \\tilde{x} = M_i^{-1/2} b$，其条件数得到改善，由 $\\kappa(M_i^{-1/2} H_i M_i^{-1/2})$ 衡量。\n\n我们对预处理后的矩阵应用 Gershgorin 定理。对于一个对角预条件子 $M_i = \\operatorname{diag}(H_i)$（即 Jacobi 选择），预处理后的矩阵 $M_i^{-1} H_i$ 的对角线元素等于 $1$，非对角线元素为 $\\frac{(H_i)_{ij}}{(H_i)_{ii}}$（对于 $i \\ne j$）。由于 $M_i$ 是对角的，使用 $M_i^{-1/2}$ 进行对称预处理会保持 $M_i^{-1} H_i$ 的特征值。然后，Gershgorin 定理将 $M_i^{-1/2} H_i M_i^{-1/2}$ 的每个特征值 $\\lambda$ 置于某个圆盘 $D(1, r_i)$ 内部，其中\n$$r_i := \\sum_{j \\ne i} \\left| \\frac{(H_i)_{ij}}{(H_i)_{ii}} \\right| = \\sum_{j \\ne i} \\frac{|(A_i^\\top A_i)_{ij}|}{(A_i^\\top A_i)_{ii} + \\rho}。$$\n如果 $r := \\max_i r_i  1$（严格对角占优），则所有特征值都位于 $[1-r, 1+r]$ 区间内，且条件数服从\n$$\\kappa\\!\\left(M_i^{-1/2} H_i M_i^{-1/2}\\right) \\le \\frac{1 + r}{1 - r}。$$\n因为当 $\\rho$ 增加时，$r$ 单调递减（分母 $(A_i^\\top A_i)_{ii} + \\rho$ 增长而非对角项固定），所以这个界会变紧，谱会更紧密地聚集在 $1$ 附近。达到固定相对容差 $\\epsilon$ 所需的 PCG 迭代次数大致与 $\\sqrt{\\kappa}$ 成比例减少：\n$$t(\\epsilon) = \\mathcal{O}\\!\\left( \\sqrt{ \\kappa\\!\\left(M_i^{-1/2} H_i M_i^{-1/2}\\right)} \\log(1/\\epsilon) \\right)。$$\n预处理不会改变正在求解的线性系统；它只改变了构建 Krylov 搜索方向时所用的度量。因此，假设使用相同的停止准则，带预处理的 PCG 所产生的 $x_i$ 更新是对同一局部子问题精确最小化子的一个近似，故 ADMM 的不动点保持不变。如果应用 $M_i^{-1}$（一个对角缩放）的成本相对于与 $A_i$ 和 $A_i^\\top$ 相乘的主要成本可以忽略不计（通常情况下确实如此），那么每次迭代的墙上时钟时间会得到改善。这证实了预处理对内迭代次数和整体 ADMM 效率的预期效果。\n\n现在我们评估每个选项：\n\nA. Jacobi 预条件子 $M_i := \\operatorname{diag}(A_i^\\top A_i) + \\rho I$ 正是 $H_i$ 的对角部分。对称预处理 $M_i^{-1/2} H_i M_i^{-1/2}$ 产生一个对角线为单位元的矩阵，Gershgorin 定理可以直接应用于此，其半径为 $r_i = \\sum_{j \\ne i} \\frac{|(A_i^\\top A_i)_{ij}|}{(A_i^\\top A_i)_{ii} + \\rho}$。如果 $r  1$，则界 $\\kappa \\le \\frac{1+r}{1-r}$ 成立，并随着 $\\rho$ 的增长而改善。对于固定容差，PCG 迭代次数按 $\\mathcal{O}(\\sqrt{\\kappa})$ 减少。因为求解的是同一个线性系统（在规定的容差范围内），所以 ADMM 不动点不受影响。对角预条件子的应用成本低廉，因此每次 ADMM 迭代的总运行时间减少，从而提高了端到端效率。结论：正确。\n\nB. 标量预条件子 $M_i := \\rho I$ 只是在预处理矩阵 $M_i^{-1/2} H_i M_i^{-1/2} = \\rho^{-1} H_i$ 中将 $H_i$ 按一个常数进行缩放，这不会改变条件数：$\\kappa(\\rho^{-1} H_i) = \\kappa(H_i)$。声称条件数变为 1 且 PCG 在 1 次迭代内收敛是错误的，除非 $H_i$ 与单位矩阵成比例，而通常情况并非如此。结论：不正确。\n\nC. 完整预条件子 $M_i := H_i$ 确实会产生一个条件数为 1 的预处理矩阵，意味着在精确算术中 1 次迭代即可收敛。然而，这不符合题目要求的对角预条件子，并且在 PCG 中应用 $M_i^{-1}$ 需要对 $H_i$ 进行求解（例如，进行因式分解或内部迭代求解），这个成本不可忽略，并且违背了使用 PCG 来避免昂贵因式分解的初衷。在预设的场景中，关于开销可忽略的说法是不合理的。结论：不正确。\n\nD. 对角预条件子 $M_i := \\operatorname{diag}(A_i^\\top A_i)$ 省略了 $\\rho I$ 项，因此是对 $A_i^\\top A_i$ 而非 $H_i$ 进行预处理。虽然可以用这个 $M_i$ 来分析 $M_i^{-1/2} H_i M_i^{-1/2}$，但该陈述声称对角缩放会改变 ADMM 不动点。这是错误的：预处理仅加速了对相同最优性条件的迭代求解，并不会改变局部二次子问题的最小化子，因此它不会改变 ADMM 的不动点。此外，从 $M_i$ 中省略 $\\rho I$ 通常会比使用 $\\operatorname{diag}(H_i)$ 产生更弱的对角占优性，因此在改善条件数方面效果较差。结论：不正确。\n\n因此，只有选项 A 既提出了一个合适的对角预条件子，又正确评估了其对内部求解器迭代次数和整体 ADMM 效率的影响。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}