{
    "hands_on_practices": [
        {
            "introduction": "要真正理解一个由优化问题定义的估计量，我们必须首先掌握其约束条件的几何形态。本练习提供了一个具体的实践机会，让您能够直观地理解丹齐格选择器 (Dantzig selector)。通过一个简单的二维示例，您将推导出由核心约束 $\\|A^{\\top}(y - A x)\\|_{\\infty} \\le \\delta$ 定义的可行域，并发现它构成一个多面体，最终通过找到具有最小 $\\ell_1$ 范数的顶点来确定解 。",
            "id": "3487278",
            "problem": "考虑一个线性模型，其设计矩阵为 $A \\in \\mathbb{R}^{2 \\times 2}$，观测向量为 $y \\in \\mathbb{R}^{2}$。Dantzig选择器对系数向量 $x \\in \\mathbb{R}^{2}$ 施加约束 $\\|A^{\\top}(y - A x)\\|_{\\infty} \\le \\delta$，其中 $\\delta > 0$ 是给定的容差。设\n$$\nA = \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix}, \\quad y = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}, \\quad \\delta = 1.\n$$\n从Dantzig选择器约束 $\\|A^{\\top}(y - A x)\\|_{\\infty} \\le \\delta$ 的定义和基本的线性代数恒等式出发，完成以下任务：\n- 推导出一个关于 $x$ 各分量的显式线性不等式组，该不等式组刻画了 $\\mathbb{R}^{2}$ 中的可行域。\n- 通过求解相应的边界等式，计算该可行多面体区域的所有极点（顶点）。\n- 确定在可行域上最小化目标 $\\|x\\|_{1}$ 的极点，并通过分析在各顶点（以及必要时，在边上）达到的 $\\|x\\|_{1}$ 的值来证明你的选择。\n\n将最小化极点的坐标以单行向量的形式作为最终答案报告。无需四舍五入，不涉及单位。",
            "solution": "该问题要求解Dantzig选择器优化问题，其目标是在设计矩阵的列与残差之间的相关性约束下，最小化系数向量 $x$ 的 $\\ell_1$-范数。\n\n首先，我们验证问题陈述的有效性。\n\n### 步骤1：提取已知条件\n- 设计矩阵：$A = \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix} \\in \\mathbb{R}^{2 \\times 2}$\n- 观测向量：$y = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix} \\in \\mathbb{R}^{2}$\n- 系数向量：$x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} \\in \\mathbb{R}^{2}$\n- 容差：$\\delta = 1$\n- 约束条件：$\\|A^{\\top}(y - A x)\\|_{\\infty} \\le \\delta$\n- 目标：在由约束定义的可行域上最小化 $\\|x\\|_{1}$。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题在科学上植根于稀疏优化和压缩感知领域。Dantzig选择器是一种成熟的方法。问题是适定的（well-posed），所有必需的矩阵、向量和参数都已提供。数据在数值上和维度上都是一致的。语言客观而精确。任务定义清晰，涉及标准的数学程序（线性代数，凸优化）。未发现任何缺陷。\n\n### 步骤3：结论与行动\n问题是有效的。我们继续进行求解。\n\n问题的核心是刻画由Dantzig选择器约束 $\\|A^{\\top}(y - A x)\\|_{\\infty} \\le \\delta$ 定义的可行域，然后找到该区域内具有最小 $\\ell_1$-范数的点。\n\n我们首先计算范数内的表达式。$A$ 的转置是：\n$$\nA^{\\top} = \\begin{pmatrix} 1  0 \\\\ 1  1 \\end{pmatrix}\n$$\n项 $Ax$ 为：\n$$\nAx = \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} x_1 + x_2 \\\\ x_2 \\end{pmatrix}\n$$\n残差向量 $r = y - Ax$ 为：\n$$\nr = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} x_1 + x_2 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 3 - x_1 - x_2 \\\\ 1 - x_2 \\end{pmatrix}\n$$\n现在，我们计算乘积 $A^{\\top}r$：\n$$\nA^{\\top}r = \\begin{pmatrix} 1  0 \\\\ 1  1 \\end{pmatrix} \\begin{pmatrix} 3 - x_1 - x_2 \\\\ 1 - x_2 \\end{pmatrix} = \\begin{pmatrix} 1(3 - x_1 - x_2) + 0(1 - x_2) \\\\ 1(3 - x_1 - x_2) + 1(1 - x_2) \\end{pmatrix} = \\begin{pmatrix} 3 - x_1 - x_2 \\\\ 4 - x_1 - 2x_2 \\end{pmatrix}\n$$\nDantzig选择器约束为 $\\|A^{\\top}(y - A x)\\|_{\\infty} \\le \\delta$。当 $\\delta = 1$ 时，它变为：\n$$\n\\left\\| \\begin{pmatrix} 3 - x_1 - x_2 \\\\ 4 - x_1 - 2x_2 \\end{pmatrix} \\right\\|_{\\infty} \\le 1\n$$\n向量的无穷范数 $\\|\\cdot\\|_{\\infty}$ 是其分量绝对值的最大值。因此，该约束等价于以下两个不等式：\n$$\n|3 - x_1 - x_2| \\le 1 \\quad \\text{和} \\quad |4 - x_1 - 2x_2| \\le 1\n$$\n我们可以将每个绝对值不等式展开为一对线性不等式。\n对于第一个不等式 $|3 - x_1 - x_2| \\le 1$：\n$$\n-1 \\le 3 - x_1 - x_2 \\le 1\n$$\n这得到：\n1.  $3 - x_1 - x_2 \\le 1 \\implies 2 \\le x_1 + x_2$\n2.  $3 - x_1 - x_2 \\ge -1 \\implies 4 \\ge x_1 + x_2$\n\n对于第二个不等式 $|4 - x_1 - 2x_2| \\le 1$：\n$$\n-1 \\le 4 - x_1 - 2x_2 \\le 1\n$$\n这得到：\n3.  $4 - x_1 - 2x_2 \\le 1 \\implies 3 \\le x_1 + 2x_2$\n4.  $4 - x_1 - 2x_2 \\ge -1 \\implies 5 \\ge x_1 + 2x_2$\n\n因此，可行域是 $\\mathbb{R}^2$ 中的一个多面体，由四个半空间的交集定义：\n$$\n\\begin{cases}\nx_1 + x_2 \\ge 2 \\\\\nx_1 + x_2 \\le 4 \\\\\nx_1 + 2x_2 \\ge 3 \\\\\nx_1 + 2x_2 \\le 5\n\\end{cases}\n$$\n该区域是一个闭合有界的凸集（一个平行四边形）。该区域的极点（顶点）可以通过求解边界线的交点来找到。边界线为：\n$L_1: x_1 + x_2 = 2$\n$L_2: x_1 + x_2 = 4$\n$L_3: x_1 + 2x_2 = 3$\n$L_4: x_1 + 2x_2 = 5$\n\n直线 $L_1$ 和 $L_2$ 是平行的。直线 $L_3$ 和 $L_4$ 是平行的。顶点是从 $\\{L_1, L_2\\}$ 中选一条直线和从 $\\{L_3, L_4\\}$ 中选一条直线的四个交点。\n\n顶点1（$L_1$ 和 $L_3$ 的交点）：\n$$\n\\begin{cases} x_1 + x_2 = 2 \\\\ x_1 + 2x_2 = 3 \\end{cases} \\implies (x_1 + 2x_2) - (x_1 + x_2) = 3 - 2 \\implies x_2 = 1.\n$$\n将 $x_2 = 1$ 代入 $x_1 + x_2 = 2$ 得到 $x_1 = 1$。该顶点是 $V_1 = (1, 1)$。\n\n顶点2（$L_1$ 和 $L_4$ 的交点）：\n$$\n\\begin{cases} x_1 + x_2 = 2 \\\\ x_1 + 2x_2 = 5 \\end{cases} \\implies (x_1 + 2x_2) - (x_1 + x_2) = 5 - 2 \\implies x_2 = 3.\n$$\n将 $x_2 = 3$ 代入 $x_1 + x_2 = 2$ 得到 $x_1 = -1$。该顶点是 $V_2 = (-1, 3)$。\n\n顶点3（$L_2$ 和 $L_4$ 的交点）：\n$$\n\\begin{cases} x_1 + x_2 = 4 \\\\ x_1 + 2x_2 = 5 \\end{cases} \\implies (x_1 + 2x_2) - (x_1 + x_2) = 5 - 4 \\implies x_2 = 1.\n$$\n将 $x_2 = 1$ 代入 $x_1 + x_2 = 4$ 得到 $x_1 = 3$。该顶点是 $V_3 = (3, 1)$。\n\n顶点4（$L_2$ 和 $L_3$ 的交点）：\n$$\n\\begin{cases} x_1 + x_2 = 4 \\\\ x_1 + 2x_2 = 3 \\end{cases} \\implies (x_1 + 2x_2) - (x_1 + x_2) = 3 - 4 \\implies x_2 = -1.\n$$\n将 $x_2 = -1$ 代入 $x_1 + x_2 = 4$ 得到 $x_1 = 5$。该顶点是 $V_4 = (5, -1)$。\n\n可行域的四个极点是 $V_1=(1, 1)$、$V_2=(-1, 3)$、$V_3=(3, 1)$ 和 $V_4=(5, -1)$。\n\n目标是在此可行域上最小化 $\\ell_1$-范数 $\\|x\\|_{1} = |x_1| + |x_2|$。由于目标函数 $\\|x\\|_1$ 是一个凸函数，且可行域是一个紧凸集，最小值必定在其一个或多个极点（顶点）处取得。我们计算每个顶点处的目标函数值：\n- 对于 $V_1 = (1, 1)$：$\\|V_1\\|_1 = |1| + |1| = 2$。\n- 对于 $V_2 = (-1, 3)$：$\\|V_2\\|_1 = |-1| + |3| = 1 + 3 = 4$。\n- 对于 $V_3 = (3, 1)$：$\\|V_3\\|_1 = |3| + |1| = 3 + 1 = 4$。\n- 对于 $V_4 = (5, -1)$：$\\|V_4\\|_1 = |5| + |-1| = 5 + 1 = 6$。\n\n比较这些值，$\\|x\\|_1$ 的最小值是 $2$，在顶点 $V_1 = (1, 1)$ 处取得。问题要求找出最小化目标的极点。根据我们对极点的分析，这个点是唯一确定的。\n\n因此，在可行域上最小化 $\\ell_1$-范数的极点是 $(1, 1)$。",
            "answer": "$$\\boxed{\\begin{pmatrix} 1  1 \\end{pmatrix}}$$"
        },
        {
            "introduction": "在理想化条件下分析统计方法，往往能揭示其内在的核心机制。在本练习中，我们将在正交设计矩阵 ($X^\\top X = I$) 的情境下探索丹齐格选择器，这种情况能极大地简化其背后的数学原理。您将会发现，在此条件下，丹齐格选择器简化为著名的软阈值算子 (soft-thresholding operator)，从而在该方法与稀疏估计中的其他基础技术之间建立了关键的联系 。",
            "id": "3487307",
            "problem": "令 $X \\in \\mathbb{R}^{n \\times p}$ 是一个设计矩阵，满足 $X^\\top X = I$，令 $y \\in \\mathbb{R}^{n}$ 是一个观测响应向量。定义 $b = X^\\top y \\in \\mathbb{R}^{p}$。Dantzig选择子是由以下凸规划定义的估计量 $\\hat{\\beta}(\\lambda) \\in \\mathbb{R}^{p}$：\n$$\n\\hat{\\beta}(\\lambda) \\in \\arg\\min_{\\beta \\in \\mathbb{R}^{p}} \\|\\beta\\|_{1} \\quad \\text{subject to} \\quad \\|X^\\top(y - X\\beta)\\|_{\\infty} \\le \\lambda,\n$$\n其中 $\\lambda > 0$ 是一个调节参数。仅从上述定义和标准正交条件 $X^\\top X = I$ 出发，通过将问题简化为可分离的坐标级子问题，推导最小化子 $\\hat{\\beta}(\\lambda)$ 关于 $b$ 和 $\\lambda$ 的闭式表达式。然后，定义偏差向量 $\\Delta(\\lambda) = \\hat{\\beta}(\\lambda) - b$，并计算 $\\ell_{2}$ 和 $\\ell_{\\infty}$ 偏差，即 $\\|\\Delta(\\lambda)\\|_{2}$ 和 $\\|\\Delta(\\lambda)\\|_{\\infty}$，将它们表示为 $\\lambda$ 和 $b$ 的函数的解析表达式。将你的最终答案表示为一个单行矩阵，其中包含用 $b$ 和 $\\lambda$ 表示的两个闭式表达式。不需要进行数值近似或四舍五入。",
            "solution": "根据指定标准，该问题陈述被评估为有效。它在统计优化领域具有科学依据，是适定的、客观的，并包含了得出唯一解所需的所有必要信息。\n\n问题要求在设计矩阵为标准正交的条件下，求解Dantzig选择子优化问题的闭式解，并随后计算偏差向量的 $\\ell_{2}$ 和 $\\ell_{\\infty}$ 范数。\n\nDantzig选择子被定义为凸规划问题的解 $\\hat{\\beta}(\\lambda)$：\n$$\n\\min_{\\beta \\in \\mathbb{R}^{p}} \\|\\beta\\|_{1} \\quad \\text{subject to} \\quad \\|X^\\top(y - X\\beta)\\|_{\\infty} \\le \\lambda\n$$\n给定设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 满足 $X^\\top X = I$，其中 $I$ 是 $p \\times p$ 的单位矩阵。我们还给定了定义 $b = X^\\top y \\in \\mathbb{R}^{p}$。\n\n首先，我们利用给定信息简化优化问题的约束条件：\n$$\nX^\\top(y - X\\beta) = X^\\top y - (X^\\top X)\\beta\n$$\n代入 $b = X^\\top y$ 和 $X^\\top X = I$，我们得到：\n$$\nX^\\top(y - X\\beta) = b - \\beta\n$$\n因此，约束条件 $\\|X^\\top(y - X\\beta)\\|_{\\infty} \\le \\lambda$ 简化为：\n$$\n\\|b - \\beta\\|_{\\infty} \\le \\lambda\n$$\n向量 $v \\in \\mathbb{R}^{p}$ 的 $\\ell_{\\infty}$-范数定义为 $\\|v\\|_{\\infty} = \\max_{j=1,\\dots,p} |v_j|$。因此，该约束等价于一组 $p$ 个分量不等式：\n$$\n|b_j - \\beta_j| \\le \\lambda \\quad \\text{for each } j = 1, \\dots, p\n$$\n\n目标函数是 $\\ell_1$-范数，它在 $\\beta$ 的各个分量上是可加分离的：\n$$\n\\|\\beta\\|_{1} = \\sum_{j=1}^{p} |\\beta_j|\n$$\n由于目标函数和约束条件都是可分离的，我们可以将这个 $p$ 维优化问题分解为 $p$ 个独立的一维优化问题。对每个分量 $j \\in \\{1, \\dots, p\\}$，我们求解：\n$$\n\\hat{\\beta}_j(\\lambda) = \\arg\\min_{\\beta_j \\in \\mathbb{R}} |\\beta_j| \\quad \\text{subject to} \\quad |b_j - \\beta_j| \\le \\lambda\n$$\n约束条件 $|b_j - \\beta_j| \\le \\lambda$ 等价于 $-\\lambda \\le b_j - \\beta_j \\le \\lambda$，这为 $\\beta_j$ 定义了闭区间 $[b_j - \\lambda, b_j + \\lambda]$。因此我们寻找的是该区间内绝对值最小的元素。这等价于在区间 $[b_j - \\lambda, b_j + \\lambda]$ 中找到离原点 $0$ 最近的点。\n\n我们通过考虑该区间相对于 $0$ 的位置来分析解：\n1.  如果区间包含 $0$，即 $b_j - \\lambda \\le 0 \\le b_j + \\lambda$，这等价于 $|b_j| \\le \\lambda$，则绝对值最小的点是 $\\hat{\\beta}_j(\\lambda) = 0$。\n2.  如果区间完全在 $0$ 的右侧，即 $b_j - \\lambda > 0$，这等价于 $b_j > \\lambda$，则绝对值最小的点是区间的左端点，即 $\\hat{\\beta}_j(\\lambda) = b_j - \\lambda$。\n3.  如果区间完全在 $0$ 的左侧，即 $b_j + \\lambda  0$，这等价于 $b_j  -\\lambda$，则绝对值最小的点是区间的右端点，即 $\\hat{\\beta}_j(\\lambda) = b_j + \\lambda$。\n\n这三种情况可以使用软阈值算子 $S_{\\lambda}(\\cdot)$ 紧凑地表示：\n$$\n\\hat{\\beta}_j(\\lambda) = S_{\\lambda}(b_j) = \\text{sgn}(b_j) \\max(0, |b_j| - \\lambda)\n$$\n向量解是通过将此算子逐元素地应用于向量 $b$ 得到的：$\\hat{\\beta}(\\lambda) = S_{\\lambda}(b)$。\n\n接下来，我们计算偏差向量 $\\Delta(\\lambda) = \\hat{\\beta}(\\lambda) - b$。第 $j$ 个分量是 $\\Delta_j(\\lambda) = \\hat{\\beta}_j(\\lambda) - b_j$。我们使用相同的案例分析：\n1.  如果 $|b_j| \\le \\lambda$，那么 $\\hat{\\beta}_j(\\lambda) = 0$，所以 $\\Delta_j(\\lambda) = 0 - b_j = -b_j$。\n2.  如果 $b_j  \\lambda$，那么 $\\hat{\\beta}_j(\\lambda) = b_j - \\lambda$，所以 $\\Delta_j(\\lambda) = (b_j - \\lambda) - b_j = -\\lambda$。\n3.  如果 $b_j  -\\lambda$，那么 $\\hat{\\beta}_j(\\lambda) = b_j + \\lambda$，所以 $\\Delta_j(\\lambda) = (b_j + \\lambda) - b_j = \\lambda$。\n\n这些可以总结为：\n$$\n\\Delta_j(\\lambda) =\n\\begin{cases}\n-b_j  \\text{if } |b_j| \\le \\lambda \\\\\n-\\lambda \\cdot \\text{sgn}(b_j)  \\text{if } |b_j|  \\lambda\n\\end{cases}\n$$\n\n现在我们计算偏差向量 $\\Delta(\\lambda)$ 所需的范数。\n\n首先是 $\\ell_2$-范数 $\\|\\Delta(\\lambda)\\|_2$。我们计算它的平方：\n$$\n\\|\\Delta(\\lambda)\\|_2^2 = \\sum_{j=1}^{p} \\Delta_j(\\lambda)^2\n$$\n我们将和式根据 $|b_j|$ 的条件分为两部分：\n$$\n\\|\\Delta(\\lambda)\\|_2^2 = \\sum_{j: |b_j| \\le \\lambda} \\Delta_j(\\lambda)^2 + \\sum_{j: |b_j|  \\lambda} \\Delta_j(\\lambda)^2\n$$\n对于索引 $j$ 满足 $|b_j| \\le \\lambda$ 的情况，我们有 $\\Delta_j(\\lambda)^2 = (-b_j)^2 = b_j^2$。\n对于索引 $j$ 满足 $|b_j|  \\lambda$ 的情况，我们有 $\\Delta_j(\\lambda)^2 = (-\\lambda \\cdot \\text{sgn}(b_j))^2 = \\lambda^2$。\n所以，范数的平方是：\n$$\n\\|\\Delta(\\lambda)\\|_2^2 = \\sum_{j: |b_j| \\le \\lambda} b_j^2 + \\sum_{j: |b_j|  \\lambda} \\lambda^2\n$$\n第二个和式是对所有满足 $|b_j|  \\lambda$ 的索引求和。如果我们用 $|\\{j : |b_j|  \\lambda\\}|$ 表示这类索引的数量，那么这个和式等于 $\\lambda^2 |\\{j : |b_j|  \\lambda\\}|$。\n取平方根得到 $\\ell_2$-范数：\n$$\n\\|\\Delta(\\lambda)\\|_2 = \\sqrt{\\sum_{j: |b_j| \\le \\lambda} b_j^2 + \\lambda^2 |\\{j : |b_j|  \\lambda\\}|}\n$$\n这可以用指示函数 $\\mathbb{I}(\\cdot)$ 写成：\n$$\n\\|\\Delta(\\lambda)\\|_2 = \\sqrt{\\sum_{j=1}^{p} b_j^2 \\mathbb{I}(|b_j| \\le \\lambda) + \\lambda^{2} \\sum_{j=1}^{p} \\mathbb{I}(|b_j|  \\lambda)}\n$$\n\n其次是 $\\ell_\\infty$-范数 $\\|\\Delta(\\lambda)\\|_\\infty = \\max_{j=1,\\dots,p} |\\Delta_j(\\lambda)|$。我们分析 $|\\Delta_j(\\lambda)|$ 的大小：\n1.  如果 $|b_j| \\le \\lambda$，那么 $|\\Delta_j(\\lambda)| = |-b_j| = |b_j|$。在这种情况下，有 $|\\Delta_j(\\lambda)| \\le \\lambda$。\n2.  如果 $|b_j|  \\lambda$，那么 $|\\Delta_j(\\lambda)| = |-\\lambda \\cdot \\text{sgn}(b_j)| = \\lambda$。\n\n我们需要在所有 $|\\Delta_j(\\lambda)|$ 中找到最大值。这些值的集合是 $\\{|b_j| \\text{ for } j \\text{ s.t. } |b_j| \\le \\lambda\\} \\cup \\{\\lambda \\text{ for } j \\text{ s.t. } |b_j|  \\lambda\\}$。\n让我们根据 $\\lambda$ 和 $\\|b\\|_\\infty = \\max_j |b_j|$ 之间的关系考虑两种情况：\n1.  如果 $\\|b\\|_\\infty \\le \\lambda$，那么对于所有的 $j=1, \\dots, p$ 都有 $|b_j| \\le \\lambda$。在这种情况下，对所有 $j$ 都有 $\\Delta_j(\\lambda) = -b_j$。那么 $\\|\\Delta(\\lambda)\\|_\\infty = \\max_j |-b_j| = \\max_j |b_j| = \\|b\\|_\\infty$。\n2.  如果 $\\|b\\|_\\infty  \\lambda$，那么至少存在一个索引 $k$ 使得 $|b_k|  \\lambda$。对于任何这样的 $k$，都有 $|\\Delta_k(\\lambda)| = \\lambda$。对于任何满足 $|b_j| \\le \\lambda$ 的索引 $j$，我们有 $|\\Delta_j(\\lambda)| = |b_j| \\le \\lambda$。因此，所有分量的最大值恰好是 $\\lambda$。\n\n结合这两种情况，我们发现：\n$$\n\\|\\Delta(\\lambda)\\|_\\infty =\n\\begin{cases}\n\\|b\\|_\\infty  \\text{if } \\|b\\|_\\infty \\le \\lambda \\\\\n\\lambda  \\text{if } \\|b\\|_\\infty  \\lambda\n\\end{cases}\n$$\n这恰好是 $\\min(\\lambda, \\|b\\|_\\infty)$ 的定义。\n\n所要求的两个表达式是 $\\|\\Delta(\\lambda)\\|_2$ 和 $\\|\\Delta(\\lambda)\\|_{\\infty}$。我们将按要求将它们呈现在一个行矩阵中。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\sqrt{\\sum_{j=1}^{p} b_j^2 \\mathbb{I}(|b_j| \\le \\lambda) + \\lambda^{2} \\sum_{j=1}^{p} \\mathbb{I}(|b_j|  \\lambda)}  \\min(\\lambda, \\|b\\|_{\\infty}) \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "一项统计分析的结论不应受到任意选择的影响，例如预测变量的度量单位。本练习探讨了丹齐格选择器的一个重要性质：尺度不变性 (scale invariance)。您将研究缩放设计矩阵的单个列如何影响问题，并推导出为确保解保持一致性所需的精确权重，这一概念对于该方法在实践中的稳健应用至关重要 。",
            "id": "3487301",
            "problem": "考虑一个线性观测模型 $y = A \\beta^{\\star} + \\varepsilon$，其设计矩阵为 $A \\in \\mathbb{R}^{n \\times p}$，参数向量为 $\\beta^{\\star} \\in \\mathbb{R}^{p}$，噪声为 $\\varepsilon \\in \\mathbb{R}^{n}$。Dantzig选择器定义为以下问题的解：\n$$\n\\min_{\\beta \\in \\mathbb{R}^{p}} \\|\\beta\\|_{1} \\quad \\text{subject to} \\quad \\|A^{\\top}(y - A \\beta)\\|_{\\infty} \\le \\tau,\n$$\n其中 $\\tau  0$ 是给定的容差。现在，通过一个非零标量 $c \\in \\mathbb{R} \\setminus \\{0\\}$ 对设计矩阵的某一列 $A_{j} \\in \\mathbb{R}^{n}$ 进行缩放，得到 $A^{(c)}$，其第 $j$ 列为 $A_{j}^{(c)} = c A_{j}$，所有其他列保持不变。定义对角缩放矩阵 $S(c) \\in \\mathbb{R}^{p \\times p}$ 为 $S(c)_{jj} = c$ 且当 $k \\ne j$ 时 $S(c)_{kk} = 1$。考虑以下基于缩放后设计的加权Dantzig选择器：\n$$\n\\min_{\\beta \\in \\mathbb{R}^{p}} \\sum_{k=1}^{p} w_{k}(c)\\,|\\beta_{k}| \\quad \\text{subject to} \\quad \\left\\|U(c)^{-1}\\,(A^{(c)})^{\\top}\\bigl(y - A^{(c)} \\beta\\bigr)\\right\\|_{\\infty} \\le \\tau,\n$$\n其中 $w_{k}(c)  0$ 是给定的目标权重，而 $U(c) \\in \\mathbb{R}^{p \\times p}$ 是一个对角矩阵，其对角线元素为 $u_{k}(c)  0$。您的任务是确定被缩放坐标上的权重对 $w_{j}(c)$ 和 $u_{j}(c)$ 的显式表达式，使得带 $(A^{(c)}, w(c), U(c))$ 的加权问题在以下意义上对列缩放具有解不变性：\n1) 对于任何 $y \\in \\mathbb{R}^{n}$ 和任何 $\\tau  0$，如果 $\\widehat{\\beta}$ 是上述使用 $A$ 的无权问题的解，那么 $\\widehat{\\beta}^{(c)} := S(c)^{-1}\\widehat{\\beta}$ 是使用 $A^{(c)}$、$w(c)$ 和 $U(c)$ 的加权问题的解。\n2) 该不变性必须在不改变 $\\tau$ 以及除了 $A_{j} \\leftarrow c A_{j}$ 和指定权重之外不修改任何其他数据的情况下成立。\n\n假设所有未缩放坐标 $k \\ne j$ 上的权重固定为 $w_{k}(c) = 1$ 和 $u_{k}(c) = 1$。请以单个 $1 \\times 2$ 行矩阵的形式，给出缩放坐标权重对 $\\bigl(w_{j}(c), u_{j}(c)\\bigr)$ 的解析表达式作为您的最终答案。无需也禁止使用任何数值近似，且不涉及任何单位。",
            "solution": "用户想要找到权重 $w_j(c)$ 和 $u_j(c)$，使得Dantzig选择器优化问题对于设计矩阵 $A$ 的单列缩放具有不变性。\n\n设原始Dantzig选择器问题表示为 $\\text{P}_1$：\n$$\n\\text{P}_1: \\quad \\min_{\\beta \\in \\mathbb{R}^{p}} \\|\\beta\\|_{1} \\quad \\text{subject to} \\quad \\|A^{\\top}(y - A \\beta)\\|_{\\infty} \\le \\tau\n$$\n设 $\\widehat{\\beta}$ 是 $\\text{P}_1$ 的一个解。\n\n修改后的设计矩阵 $A^{(c)}$ 是通过将 $A$ 的第 $j$ 列乘以一个非零标量 $c$ 形成的。也就是，$A_{j}^{(c)} = c A_{j}$，且对于所有 $k \\ne j$，$A_{k}^{(c)} = A_{k}$。设 $S(c)$ 是对角矩阵，其满足 $S(c)_{jj} = c$ 且当 $k \\ne j$ 时 $S(c)_{kk} = 1$。那么修改后的设计矩阵可以紧凑地表示为 $A^{(c)} = A S(c)$。\n\n使用缩放后设计矩阵的加权Dantzig选择器问题，我们记为 $\\text{P}_2$，给出如下：\n$$\n\\text{P}_2: \\quad \\min_{\\tilde{\\beta} \\in \\mathbb{R}^{p}} \\sum_{k=1}^{p} w_{k}(c)\\,|\\tilde{\\beta}_{k}| \\quad \\text{subject to} \\quad \\left\\|U(c)^{-1}\\,(A^{(c)})^{\\top}\\bigl(y - A^{(c)} \\tilde{\\beta}\\bigr)\\right\\|_{\\infty} \\le \\tau\n$$\n这里我们使用 $\\tilde{\\beta}$ 来区分 $\\text{P}_2$ 和 $\\text{P}_1$ 的优化变量。给定对于 $k \\ne j$，权重固定为 $w_{k}(c) = 1$ 和 $u_{k}(c) = 1$。对角矩阵 $U(c)$ 的元素为 $U(c)_{kk} = u_k(c)$。\n\n问题要求，如果 $\\widehat{\\beta}$ 是 $\\text{P}_1$ 的一个解，那么 $\\widehat{\\beta}^{(c)} = S(c)^{-1}\\widehat{\\beta}$ 必须是 $\\text{P}_2$ 的一个解。这意味着在变量替换 $\\beta = S(c)\\tilde{\\beta}$（等价于 $\\tilde{\\beta} = S(c)^{-1}\\beta$）下，这两个优化问题必须是等价的。\n\n我们将用代换 $\\beta = S(c)\\tilde{\\beta}$ 来变换问题 $\\text{P}_1$，并要求得到的关于变量 $\\tilde{\\beta}$ 的问题与 $\\text{P}_2$ 完全相同。\n\n**1. 变换目标函数：**\n$\\text{P}_1$ 的目标函数是 $\\|\\beta\\|_{1}$。代入 $\\beta = S(c)\\tilde{\\beta}$，我们得到：\n$$\n\\|\\beta\\|_{1} = \\|S(c)\\tilde{\\beta}\\|_{1} = \\sum_{k=1}^{p} |(S(c)\\tilde{\\beta})_{k}| = \\sum_{k=1}^{p} |S(c)_{kk} \\tilde{\\beta}_{k}|\n$$\n由于当 $k \\ne j$ 时 $S(c)_{jj} = c$ 且 $S(c)_{kk} = 1$，目标函数变为：\n$$\n|S(c)_{jj} \\tilde{\\beta}_{j}| + \\sum_{k \\ne j} |S(c)_{kk} \\tilde{\\beta}_{k}| = |c||\\tilde{\\beta}_{j}| + \\sum_{k \\ne j} |\\tilde{\\beta}_{k}|\n$$\n现在，我们将其与 $\\text{P}_2$ 的目标函数进行比较：\n$$\n\\sum_{k=1}^{p} w_{k}(c)\\,|\\tilde{\\beta}_{k}| = w_{j}(c)|\\tilde{\\beta}_{j}| + \\sum_{k \\ne j} w_{k}(c)|\\tilde{\\beta}_{k}|\n$$\n给定当 $k \\ne j$ 时 $w_{k}(c) = 1$，此为 $w_{j}(c)|\\tilde{\\beta}_{j}| + \\sum_{k \\ne j} |\\tilde{\\beta}_{k}|$。\n为使两个目标函数对于 $\\tilde{\\beta}$ 的任何选择都相同，它们的系数必须匹配。这就得出了权重 $w_j(c)$ 的条件：\n$$\nw_{j}(c) = |c|\n$$\n由于 $c \\in \\mathbb{R} \\setminus \\{0\\}$，我们有 $|c|0$，这与要求 $w_k(c)  0$ 一致。\n\n**2. 变换约束条件：**\n$\\text{P}_1$ 的约束条件是 $\\|A^{\\top}(y - A \\beta)\\|_{\\infty} \\le \\tau$。我们代入 $\\beta = S(c)\\tilde{\\beta}$：\n$$\n\\|A^{\\top}(y - A S(c)\\tilde{\\beta})\\|_{\\infty} \\le \\tau\n$$\n使用关系 $A^{(c)} = A S(c)$，括号内的项变为 $y - A^{(c)}\\tilde{\\beta}$。所以变换后的约束条件是：\n$$\n\\|A^{\\top}(y - A^{(c)}\\tilde{\\beta})\\|_{\\infty} \\le \\tau\n$$\n现在，让我们将其与 $\\text{P}_2$ 的约束条件进行比较：\n$$\n\\left\\|U(c)^{-1}\\,(A^{(c)})^{\\top}\\bigl(y - A^{(c)} \\tilde{\\beta}\\bigr)\\right\\|_{\\infty} \\le \\tau\n$$\n为了关联这两个约束条件，我们考察 $A^{\\top}$ 和 $(A^{(c)})^{\\top}$ 之间的关系。\n$$\n(A^{(c)})^{\\top} = (A S(c))^{\\top} = S(c)^{\\top}A^{\\top}\n$$\n由于 $S(c)$ 是对角矩阵，它是对称的，所以 $S(c)^{\\top} = S(c)$。因此：\n$$\n(A^{(c)})^{\\top} = S(c)A^{\\top} \\implies A^{\\top} = S(c)^{-1}(A^{(c)})^{\\top}\n$$\n其中 $S(c)^{-1}$ 是一个对角矩阵，其满足 $(S(c)^{-1})_{jj} = 1/c$ 且当 $k \\ne j$ 时 $(S(c)^{-1})_{kk} = 1$。\n\n将 $A^{\\top} = S(c)^{-1}(A^{(c)})^{\\top}$ 代入从 $\\text{P}_1$ 变换得到的约束条件中：\n$$\n\\|S(c)^{-1}(A^{(c)})^{\\top}(y - A^{(c)}\\tilde{\\beta})\\|_{\\infty} \\le \\tau\n$$\n为了使这个约束条件对于任何 $\\tilde{\\beta}$ 都等价于 $\\text{P}_2$ 的约束条件 $\\|U(c)^{-1}(A^{(c)})^{\\top}(y - A^{(c)}\\tilde{\\beta})\\|_{\\infty} \\le \\tau$，范数内的向量 $v = (A^{(c)})^{\\top}(y - A^{(c)}\\tilde{\\beta})$ 上的线性算子必须以保持 $\\ell_\\infty$-范数球的方式等价。\n具体来说，由两个约束条件定义的可行集必须是相同的。这意味着对于任何向量 $v \\in \\mathbb{R}^p$，我们必须有 $\\|S(c)^{-1} v\\|_{\\infty} = \\|U(c)^{-1} v\\|_{\\infty}$。\n$$\n\\max_{k} |(S(c)^{-1}v)_k| = \\max_{k} |(U(c)^{-1}v)_k|\n$$\n$$\n\\max_{k} \\frac{1}{|s_k(c)|}|v_k| = \\max_{k} \\frac{1}{u_k(c)}|v_k|\n$$\n其中 $s_k(c)$ 是 $S(c)$ 的对角线元素，并且我们已经使用了 $u_k(c)0$。这个等式必须对任何向量 $v$ 都成立，这意味着对于每个分量 $k$，系数必须相等：\n$$\n\\frac{1}{|s_k(c)|} = \\frac{1}{u_k(c)} \\implies u_k(c) = |s_k(c)|\n$$\n我们对所有 $k$ 检查这个条件：\n- 对于 $k \\ne j$，$s_k(c) = 1$，所以我们要求 $u_k(c) = |1| = 1$。这与给定的未缩放坐标的条件 $u_k(c)=1$ 相匹配。\n- 对于 $k = j$，$s_j(c) = c$，所以我们要求 $u_j(c) = |c|$。\n\n这给出了权重 $u_j(c)$ 的表达式。由于 $c \\ne 0$，我们有 $|c|0$，与要求 $u_k(c)0$ 一致。\n\n总之，为了使加权Dantzig选择器在指定意义上对列缩放具有解不变性，缩放坐标 $j$ 上的权重必须是：\n$$w_j(c) = |c|$$\n$$u_j(c) = |c|$$\n\n因此，权重对 $(w_j(c), u_j(c))$ 是 $(|c|, |c|)$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n|c|  |c|\n\\end{pmatrix}\n}\n$$"
        }
    ]
}