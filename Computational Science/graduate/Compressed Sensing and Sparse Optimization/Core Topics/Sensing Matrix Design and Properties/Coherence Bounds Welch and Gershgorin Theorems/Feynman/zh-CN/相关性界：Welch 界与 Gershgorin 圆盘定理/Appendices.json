{
    "hands_on_practices": [
        {
            "introduction": "理论为我们分析传感矩阵提供了强大的工具，但要真正掌握这些概念，动手实践至关重要。本练习将引导你通过编程，从零开始检验互相关性 (mutual coherence, $\\mu$)、Welch 界以及基于 Gershgorin 圆盘定理的受限等距常数 ($\\delta_s$) 界之间的关系。通过将理论界与数值计算的精确值进行比较，你将深化对这些核心概念在实际（尽管是模拟的）场景中相互作用的理解 。",
            "id": "3434936",
            "problem": "您的任务是通过编程研究互相关性、Welch 下界以及基于 Gershgorin 的限制等距常数界之间的相互作用，研究对象是其列受到乘性归一化误差扰动的随机部分正交矩阵。\n\n仅从以下基本概念出发：\n- 互相关性的定义：对于一个带列的矩阵，互相关性是不同列对之间归一化内积的绝对值的最大值。\n- Welch 界：对于固定维度空间中任意一组固定数量的单位向量，互相关性服从一个仅由维度和向量数量决定的通用下界。\n- Gershgorin 圆盘定理：实对称矩阵的每个特征值都至少位于一个 Gershgorin 圆盘内，该圆盘由对应行的对角线元素以及非对角线元素绝对值之和确定。\n- 矩阵的 s 阶限制等距常数：最小的非负数，使得该矩阵与任何 s-稀疏向量的乘积的平方范数被夹在向量平方范数的线性扰动之间。\n\n您的程序必须为每个测试用例实现以下流程：\n1. 在 $\\mathbb{R}^{n \\times n}$ 中构建一个随机标准正交基，选择 $m$ 个不同的行以形成一个随机的 $m \\times n$ 部分正交矩阵，然后应用形式为 $1 + \\varepsilon \\cdot \\theta_j$ 的独立乘性列缩放，其中每个 $\\theta_j$ 位于 $\\left[-1,1\\right]$ 内，以引入列归一化误差。所有随机性必须由提供的整数种子控制，以确保可复现性。\n2. 通过将每对内积除以相应列范数的乘积，并取所有不同列对的最大绝对值，来计算经验互相关性 $\\mu$。\n3. 计算作为 $m$ 和 $n$ 函数的 Welch 下界，并与 $\\mu$ 一同报告。同时报告 $\\mu$ 是否在标准数值容差范围内大于或等于 Welch 界。\n4. 通过详尽枚举所有大小为 $s$ 的列子集，形成它们的格拉姆矩阵 (Gram matrix)，并取所有子集中特征值与 $1$ 的最大绝对偏差，来计算精确的限制等距常数 $\\delta_s$。这等同于在所有支撑于大小为 $s$ 的子集上的单位向量上优化二次型，但必须通过子集枚举和特征值计算来执行，以确保精确性。\n5. 仅使用可直接计算的矩阵量，计算 $\\delta_s$ 的两个基于 Gershgorin 的上界：\n   - 一个基于相干性的界，该界通过将 Gershgorin 定理应用于单位范数列的格拉姆矩阵推导得出，从而得到一个用互相关性表示的、与 $s$ 相关的界。\n   - 一个从未归一化的格拉姆矩阵推导出的界，该界既包含了由列归一化误差引起的对角线元素与 1 的偏差，也包含了对非对角线元素大小的统一界。\n6. 将精确的 $\\delta_s$ 与每个界进行比较，并报告每个界是否在数值容差范围内是精确值的上界。\n\n您的程序必须使用以下测试套件。对于每个元组，条目为 $(\\text{seed}, n, m, s, \\varepsilon)$:\n- $(123, 16, 8, 3, 0.05)$: 一个均衡的中等规模案例，用于测试典型行为。\n- $(456, 18, 15, 4, 0.10)$: 一个 $m$ 接近 $n$ 的案例，用于测试较小的 Welch 界以及中等归一化误差的影响。\n- $(789, 14, 7, 1, 0.20)$: 一个 $s=1$ 的边界案例，用于隔离对角线元素与 1 的偏差。\n\n最终输出要求：\n- 对于每个测试用例，按以下顺序输出一个包含八个条目的列表：\n  1. 经验互相关性 $\\mu$，浮点数。\n  2. Welch 下界，浮点数。\n  3. 一个布尔值，指示 $\\mu$ 是否在一个小容差内大于或等于 Welch 界。\n  4. 精确的 $\\delta_s$，浮点数。\n  5. 基于相干性的 $\\delta_s$ 的 Gershgorin 上界，浮点数。\n  6. 未归一化的 $\\delta_s$ 的 Gershgorin 上界，浮点数。\n  7. 一个布尔值，指示精确的 $\\delta_s$ 是否在一个小容差内小于或等于基于相干性的界。\n  8. 一个布尔值，指示精确的 $\\delta_s$ 是否在一个小容差内小于或等于未归一化的 Gershgorin 界。\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，形式为列表的列表，格式完全如下：\n  [[case1_entry1,case1_entry2,...,case1_entry8],[case2_entry1,...,case2_entry8],[case3_entry1,...,case3_entry8]]\n\n不涉及物理单位或角度单位。所有计算都必须是实数值的。通过在计算精确的限制等距常数时使用精确的子集枚举，并根据上面列出的基本概念推导所有报告的界，而不是使用捷径或黑箱公式，来确保科学真实性。",
            "solution": "我们从基本定义和经典定理出发，推导出要计算的量以及算法步骤。\n\n设 $A \\in \\mathbb{R}^{m \\times n}$ 表示传感矩阵。设 $a_j \\in \\mathbb{R}^m$ 表示 $A$ 的第 $j$ 列。互相关性定义为\n$$\n\\mu \\triangleq \\max_{i \\neq j} \\frac{\\left| \\langle a_i, a_j \\rangle \\right|}{\\|a_i\\|_2 \\, \\|a_j\\|_2},\n$$\n即不同列之间归一化内积的绝对值的最大值。这个量对各列的正向缩放是不变的。\n\nWelch 界是通过考虑 $\\mathbb{R}^m$ 中的 $n$ 个单位向量，它们的格拉姆矩阵 $G \\in \\mathbb{R}^{n \\times n}$（对角线元素为 1），以及与维度 $m$ 相关的 Frobenius 范数约束而产生的。具体来说，设 $G = X^\\top X$，其中 $X \\in \\mathbb{R}^{m \\times n}$ 的列 $x_j$ 具有单位范数。$G$ 的特征值为非负，总和为 $n$，且最多有 $m$ 个非零特征值，因为 $\\operatorname{rank}(G) \\le m$。在所有这样的 $G$ 中，非对角线元素的平方和，\n$$\n\\sum_{i \\ne j} G_{ij}^2 = \\|G\\|_F^2 - \\operatorname{trace}(G^2) \\quad \\text{(with diagonal subtracted)},\n$$\n根据凸性和对称性，当非零特征值相等时达到最小值。这产生了经典的 Welch 下界，用于限制非对角线元素的最大幅值。具体到当前情况，对于 $\\mathbb{R}^m$ 中的 $n$ 个单位向量，互相关性服从\n$$\n\\mu \\ge \\sqrt{\\frac{n - m}{m (n - 1)}}.\n$$\n在我们的计算中，$A$ 的列在行选择和缩放后通常不是单位范数，但如上定义的互相关性正确地归一化了内积，所以我们将经验 $\\mu$ 与这个通用下界进行比较。\n\n阶为 $s$ 的限制等距常数 (RIC)，记作 $\\delta_s$，通过以下不等式定义\n$$\n(1 - \\delta_s) \\, \\|x\\|_2^2 \\le \\|A x\\|_2^2 \\le (1 + \\delta_s) \\, \\|x\\|_2^2\n\\quad \\text{for all $s$-sparse vectors $x \\in \\mathbb{R}^n$}.\n$$\n等价地，对于每个子集 $S \\subset \\{1,\\dots,n\\}$ 且 $|S| = s$，令 $A_S$ 表示由 $S$ 索引的列组成的 $m \\times s$ 子矩阵，其格拉姆矩阵为 $G_S = A_S^\\top A_S$，我们有\n$$\n\\lambda_{\\min}(G_S) \\ge 1 - \\delta_s, \\quad \\lambda_{\\max}(G_S) \\le 1 + \\delta_s,\n$$\n因此\n$$\n\\delta_s = \\max_{|S|=s} \\max \\left\\{ 1 - \\lambda_{\\min}(G_S), \\, \\lambda_{\\max}(G_S) - 1 \\right\\}.\n$$\n因此，精确的 $\\delta_s$ 可以通过枚举所有大小为 $s$ 的子集 $S$，计算 $G_S$ 的极端特征值，并汇总它们与 $1$ 的最坏情况偏差来计算。\n\n为了从第一性原理获得 $\\delta_s$ 的易于处理的上界，我们使用 Gershgorin 圆盘定理。对于任何实对称矩阵 $M$，每个特征值都位于至少一个形如 $[M_{ii} - R_i, M_{ii} + R_i]$ 的区间内，其中 $R_i = \\sum_{j \\ne i} |M_{ij}|$ 是绝对行和半径。将其应用于 $G_S$ 可得，对于每个 $i \\in S$，\n$$\n\\lambda \\in \\left[ (G_S)_{ii} - \\sum_{j \\in S, j \\ne i} |(G_S)_{ij}|, \\, (G_S)_{ii} + \\sum_{j \\in S, j \\ne i} |(G_S)_{ij}| \\right].\n$$\n令 $d_j = \\|a_j\\|_2^2 = G_{jj}$ 且 $\\nu = \\max_{i \\ne j} |G_{ij}|$。那么，对所有 $|S| = s$ 的 $S$ 和所有 $i \\in S$ 统一地，我们得到\n$$\n\\lambda \\in \\left[ d_i - (s - 1) \\nu, \\, d_i + (s - 1) \\nu \\right].\n$$\n由此可知，任何此类特征值与 $1$ 的偏差由以下公式界定\n$$\n| \\lambda - 1 | \\le | d_i - 1 | + (s - 1) \\nu.\n$$\n对 $i$ 和 $S$ 取最大值得出未归一化的 Gershgorin 界\n$$\n\\delta_s \\le \\alpha + (s - 1) \\nu, \\quad \\text{where } \\alpha \\triangleq \\max_j | d_j - 1 |, \\;\\; \\nu \\triangleq \\max_{i \\ne j} | G_{ij} |.\n$$\n\n此外，如果所有列都被归一化为单位范数，使得对所有 $j$ 都有 $d_j = 1$，则 $G_{ij}$ 等于归一化内积。在这种情况下，通过使用互相关性来界定行和，\n$$\n\\sum_{j \\in S, j \\ne i} | G_{ij} | \\le (s - 1) \\mu,\n$$\n因此 $G_S$ 的特征值位于 $[1 - (s - 1) \\mu, \\, 1 + (s - 1) \\mu]$ 内，这意味着基于相关性的 Gershgorin 界为\n$$\n\\delta_s \\le (s - 1) \\mu.\n$$\n在我们的设定中，实际矩阵 $A$ 具有列归一化误差；因此，未归一化的 Gershgorin 界直接适用于 $A$，而基于相关性的界对应于其列被单独归一化为单位范数的矩阵。因此，基于相关性的界可能会低估未归一化矩阵 $A$ 的真实 RIC，而未归一化的 Gershgorin 界则保证是真实 RIC 的上界。\n\n算法设计：\n1. 随机部分正交矩阵的构造：通过对高斯随机矩阵进行 QR 分解并校正列符号以使分布均匀，生成一个 Haar 分布的正交矩阵 $Q \\in \\mathbb{R}^{n \\times n}$。选择 $m$ 个不同的行以形成 $A_0 \\in \\mathbb{R}^{m \\times n}$。\n2. 列归一化误差：抽取独立的缩放因子 $s_j \\in [1 - \\varepsilon, 1 + \\varepsilon]$ 并设置 $A = A_0 \\, \\mathrm{diag}(s)$。\n3. 互相关性：计算格拉姆矩阵 $G = A^\\top A$ 和列范数 $d_j = G_{jj}$；然后计算归一化两两相关性 $G_{ij}/\\sqrt{d_i d_j}$ 并取最大绝对非对角线值。\n4. Welch 界：根据 $m$ 和 $n$ 计算下界。\n5. 精确 RIC：枚举所有 $\\binom{n}{s}$ 个大小为 $s$ 的支撑集 $S$，计算 $G_S$ 及其极端特征值，并累积与 $1$ 的最大偏差。\n6. Gershgorin 界：计算 $\\alpha = \\max_j |d_j - 1|$, $\\nu = \\max_{i \\ne j} |G_{ij}|$, 并形成 $\\alpha + (s - 1)\\nu$；同时计算 $(s - 1)\\mu$。\n7. 容差检查：用一个小的非负容差来测试 $\\mu$ 与 Welch 界以及 $\\delta_s$ 与每个 Gershgorin 界的关系，以考虑浮点运算。\n\n该测试套件涵盖：\n- 一个具有中等维度和微小缩放误差的典型情景。\n- 一个 $m$ 接近 $n$ 的案例，其中 Welch 下界很小，且缩放误差适中。\n- 边界情况 $s = 1$，此时 RIC 简化为最大对角线偏差，从而隔离了列归一化误差的影响。\n\n程序打印单行：一个列表，其中包含每个测试用例的、按指定顺序排列的八个条目的列表。所有报告的量都是直接根据定义和上面推导的 Gershgorin 定理计算的，精确的 RIC 是通过详尽的子集枚举和特征值计算获得的。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import combinations\n\ndef haar_orthogonal(n: int, rng: np.random.Generator) -> np.ndarray:\n    \"\"\"\n    Generate a Haar-distributed orthogonal matrix Q in R^{n x n}\n    using QR decomposition of a Gaussian random matrix with sign correction.\n    \"\"\"\n    X = rng.standard_normal((n, n))\n    Q, R = np.linalg.qr(X)\n    d = np.sign(np.diag(R))\n    d[d == 0] = 1.0\n    Q = Q @ np.diag(d)\n    return Q\n\ndef solve_case(seed: int, n: int, m: int, s: int, eps: float):\n    rng = np.random.default_rng(seed)\n    \n    # 1. Construct matrix\n    Q = haar_orthogonal(n, rng)\n    row_indices = rng.choice(n, m, replace=False)\n    A0 = Q[row_indices, :]\n    thetas = rng.uniform(-1.0, 1.0, size=n)\n    scaling_factors = 1.0 + eps * thetas\n    A = A0 * scaling_factors\n\n    # 2. Compute empirical mutual coherence mu\n    G = A.T @ A\n    col_norms_sq = np.diag(G)\n    col_norms = np.sqrt(col_norms_sq)\n    # Prevent division by zero\n    col_norms[col_norms  1e-12] = 1.0\n    \n    mu_matrix = np.abs(G / np.outer(col_norms, col_norms))\n    np.fill_diagonal(mu_matrix, 0)\n    mu = np.max(mu_matrix)\n\n    # 3. Compute Welch bound\n    welch_bound = 0.0\n    if n > m:\n        welch_bound = np.sqrt((n - m) / (m * (n - 1)))\n    mu_geq_welch = mu >= welch_bound - 1e-9\n\n    # 4. Compute exact delta_s\n    max_dev = 0.0\n    indices = range(n)\n    for s_indices in combinations(indices, s):\n        G_s = G[np.ix_(s_indices, s_indices)]\n        eigvals = np.linalg.eigvalsh(G_s)\n        dev = np.max(np.abs(eigvals - 1.0))\n        if dev > max_dev:\n            max_dev = dev\n    delta_s_exact = max_dev\n\n    # 5. Compute Gershgorin bounds\n    # Coherence-based bound (idealized for unit-norm columns)\n    delta_s_coherence_bound = (s - 1) * mu\n\n    # Un-normalized Gershgorin bound (for the actual matrix)\n    alpha = np.max(np.abs(col_norms_sq - 1.0))\n    G_off_diag = G.copy()\n    np.fill_diagonal(G_off_diag, 0)\n    nu = np.max(np.abs(G_off_diag))\n    delta_s_unnormalized_bound = alpha + (s - 1) * nu\n    \n    # 6. Compare bounds\n    exact_le_coherence = delta_s_exact = delta_s_coherence_bound + 1e-9\n    exact_le_unnormalized = delta_s_exact = delta_s_unnormalized_bound + 1e-9\n\n    return [\n        mu, welch_bound, bool(mu_geq_welch),\n        delta_s_exact, delta_s_coherence_bound, delta_s_unnormalized_bound,\n        bool(exact_le_coherence), bool(exact_le_unnormalized)\n    ]\n\ndef solve():\n    test_suite = [\n        (123, 16, 8, 3, 0.05),\n        (456, 18, 15, 4, 0.10),\n        (789, 14, 7, 1, 0.20),\n    ]\n    \n    all_results = [solve_case(*params) for params in test_suite]\n    \n    # Format the final output string as a list of lists, with no spaces.\n    results_as_strings = [str(r).replace(\" \", \"\") for r in all_results]\n    print(f\"[{','.join(results_as_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "理解一个矩阵的特性是第一步，而改进它则是下一步。这个练习将带你探索一个实用的字典设计策略：剪枝，即从一个给定的传感矩阵中剔除“最差”的列，以期改善其整体性能。通过实现一个贪婪剪枝算法并量化其对互相关性和 Orthogonal Matching Pursuit (OMP) 算法恢复保证的影响，你将明白相关性不仅是分析工具，更是可以主动优化的设计目标 。",
            "id": "3434906",
            "problem": "您的任务是定量评估从一个近等角紧框架（near-ETF）类型的传感矩阵中移除固定数量的列，如何影响压缩感知和稀疏优化中基于相干性的关键恢复保证。\n\n请严格在纯数学环境下进行操作，使用实数矩阵，不涉及物理单位。所有角度与此问题无关。\n\n从以下基本概念开始：\n- 互相关性、格拉姆矩阵、有限等距常数和支撑集限制子矩阵的定义。\n- 单位范数框架的相干性韦尔奇界。\n- 格什戈林圆盘定理。\n- 基于互相关性的经典充分条件，用于通过正交匹配追踪（OMP）实现精确恢复，其中正交匹配追踪（OMP）是一种用于稀疏恢复的贪婪算法。\n\n您的程序必须为每个测试用例实现以下步骤：\n1. 按如下方式构造一个维度为 $m \\times n$ 的实数传感矩阵。生成一个具有独立标准正态分布条目的矩阵，并将每列归一化为单位 $\\ell_2$ 范数。这样就构造了一个随机的近等角紧框架，其互相关性对于给定的 $(m,n)$ 接近最小值，但不一定等于韦尔奇界。\n2. 计算互相关性 $\\mu$，其值为列归一化传感矩阵的格拉姆矩阵的非对角元素绝对值的最大值。\n3. 仅使用基本结果，推导并计算：\n   - 由韦尔奇定理预测的给定 $(m,n)$ 下 $\\mu$ 的下界。\n   - 基于应用于格拉姆矩阵的 $s \\times s$ 主子矩阵的格什戈林圆盘，得到的有限等距常数 $\\delta_s$ 的上界。\n   - 仅用 $\\mu$ 表示的、基于互相关性的OMP成功保证成立的最大稀疏度 $s_{\\text{OMP}}$。\n4. 通过消除 $k$ 个对相干性最有害（因此对基于格什戈林的界最差）的列来执行列剪枝，使用以下贪婪规则：在每个剪枝步骤中，对每列 $j$ 计算其与所有其他列的内积绝对值之和（对所有 $i \\neq j$ 求和），并移除具有最大和的列。移除一列后，在缩减后的矩阵上重新计算这些和，并重复此过程，直到移除 $k$ 列。用 $n' = n - k$ 表示剪枝后的列数。\n5. 对剪枝后的矩阵重新计算步骤2和步骤3中的所有量。\n6. 对于给定的固定稀疏度 $s$，通过将 $s$ 与剪枝前后的 $s_{\\text{OMP}}$ 进行比较，判断OMP成功保证是否在剪枝前后得到满足。\n\n限制和约定：\n- 所有列都被归一化为单位 $\\ell_2$ 范数。\n- 格拉姆矩阵必须根据构造的传感矩阵精确计算。\n- 如果 $n \\le m$，$\\mu$ 的韦尔奇下界应取为 $0$。\n- 在所有测试用例中，保证稀疏度 $s$ 在剪枝后满足 $s \\le n'$。\n- 对于每个测试用例，给定种子随机数生成器后，所有计算都是确定性的。\n- 对于所有浮点输出，使用标准四舍五入精确到小数点后六位。\n\n测试套件：\n对于以下每个参数元组 $(m,n,k,s,\\text{seed})$，执行上述过程：\n- 测试用例 A: $(m,n,k,s,\\text{seed}) = (30,60,10,4,1)$。\n- 测试用例 B: $(m,n,k,s,\\text{seed}) = (40,80,0,6,2)$。\n- 测试用例 C: $(m,n,k,s,\\text{seed}) = (20,100,40,8,3)$。\n- 测试用例 D: $(m,n,k,s,\\text{seed}) = (50,55,4,3,4)$。\n- 测试用例 E: $(m,n,k,s,\\text{seed}) = (30,90,20,10,5)$。\n\n对于每个测试用例，您的程序必须按以下顺序输出一个列表：\n- 剪枝前的互相关性 $\\mu$，作为浮点数，四舍五入到六位小数。\n- 剪枝后的互相关性 $\\mu'$，作为浮点数，四舍五入到六位小数。\n- 剪枝前基于格什戈林圆盘的 $\\delta_s$ 上界，作为浮点数，四舍五入到六位小数。\n- 剪枝后基于格什戈林圆盘的 $\\delta_s$ 上界，作为浮点数，四舍五入到六位小数。\n- 剪枝前OMP保证的最大稀疏度 $s_{\\text{OMP}}$，作为整数。\n- 剪枝后OMP保证的最大稀疏度 $s_{\\text{OMP}}'$，作为整数。\n- 表示对于固定的 $s$，OMP保证在剪枝前是否成立的布尔值。\n- 表示对于固定的 $s$，OMP保证在剪枝后是否成立的布尔值。\n- 剪枝前 $\\mu$ 的韦尔奇下界，作为浮点数，四舍五入到六位小数。\n- 剪枝后 $\\mu$ 的韦尔奇下界，作为浮点数，四舍五入到六位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由方括号括起来的、按测试用例划分的逗号分隔列表。例如，一个有效的输出格式为 “[[case1_values...],[case2_values...],...]”，不含空格。每个内部列表必须严格遵循上述指定的顺序。不得打印任何其他文本。",
            "solution": "问题陈述已经过验证，被认为是有效的。它在科学上基于压缩感知和稀疏优化的原理，问题设定良好，具有清晰的算法流程，并且其表述是客观的。所有必要的数据和定义都已提供，没有内部矛盾或含糊不清之处。\n\n任务是分析一种特定的贪婪列剪枝策略对传感矩阵基于相干性的恢复保证的影响。对于由参数 $(m, n, k, s, \\text{seed})$ 指定的每个测试用例，我们将在对矩阵进行剪枝前后执行一系列计算。\n\n**1. 传感矩阵的构造**\n\n首先，构造一个传感矩阵 $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$。其条目独立地从标准正态分布 $\\mathcal{N}(0,1)$ 中抽取。随后，其 $n$ 个列（对于 $i \\in \\{1, \\dots, n\\}$ 表示为 $\\mathbf{a}_i$）中的每一列都被归一化为单位欧几里得范数（$\\ell_2$-范数）：\n$$\n\\|\\mathbf{a}_i\\|_2 = 1 \\quad \\forall i \\in \\{1, \\dots, n\\}\n$$\n这个过程产生一个随机矩阵，其列构成一个单位范数框架。然后计算格拉姆矩阵 $\\mathbf{G} \\in \\mathbb{R}^{n \\times n}$ 为 $\\mathbf{G} = \\mathbf{A}^T\\mathbf{A}$。格拉姆矩阵的条目是矩阵 $\\mathbf{A}$ 各列之间的内积：$G_{ij} = \\langle \\mathbf{a}_i, \\mathbf{a}_j \\rangle$。由于列归一化，$\\mathbf{G}$ 的对角线元素均为1，$G_{ii} = \\|\\mathbf{a}_i\\|_2^2 = 1$。非对角线元素量化了不同列之间的相关性。\n\n**2. 剪枝前基于相干性的保证分析**\n\n在移除任何列之前，我们基于初始矩阵 $\\mathbf{A}$ 计算几个关键指标。\n\n*   **互相关性 ($\\mu$)：** 矩阵 $\\mathbf{A}$ 的互相关性是其格拉姆矩阵非对角线元素绝对值的最大值。它衡量任意两个不同列之间的最坏情况相关性。\n    $$\n    \\mu = \\mu(\\mathbf{A}) = \\max_{i \\neq j} |\\langle \\mathbf{a}_i, \\mathbf{a}_j \\rangle| = \\max_{i \\neq j} |G_{ij}|\n    $$\n*   **韦尔奇界 ($\\mu_W$)：** 该定理为 $\\mathbb{R}^m$ 中任意具有 $n$ 个单位范数向量的框架的互相关性提供了一个基本下界。对于 $n  m$，该界由以下公式给出：\n    $$\n    \\mu_W = \\sqrt{\\frac{n-m}{m(n-1)}}\n    $$\n    对于 $n \\le m$ 的情况，问题指定使用 $\\mu_W = 0$。达到此界的矩阵被称为等角紧框架（ETF）。所构造的随机矩阵预计是一个近ETF，意味着其相干性 $\\mu$ 将接近 $\\mu_W$。\n*   **基于格什戈林圆盘的有限等距常数（$\\delta_s$）上界：** 有限等距性质（RIP）是恢复保证的核心概念。如果对于任意 $s$-稀疏向量 $\\mathbf{x}$，都有 $(1-\\delta_s)\\|\\mathbf{x}\\|_2^2 \\le \\|\\mathbf{A}\\mathbf{x}\\|_2^2 \\le (1+\\delta_s)\\|\\mathbf{x}\\|_2^2$ 成立，则称矩阵 $\\mathbf{A}$ 具有阶数为 $s$、常数为 $\\delta_s$ 的RIP。这等价于要求格拉姆矩阵 $\\mathbf{G}$ 的任意 $s \\times s$ 主子矩阵 $\\mathbf{G}_S$ 的所有特征值都位于区间 $[1-\\delta_s, 1+\\delta_s]$ 内。格什戈林圆盘定理指出，$\\mathbf{G}_S$ 的每个特征值都位于以其对角线元素为中心的圆盘并集内。由于 $(\\mathbf{G}_S)_{ii}=1$，特征值 $\\lambda$ 必须满足 $|\\lambda - 1| \\le \\max_{i \\in S} \\sum_{j \\in S, j \\neq i} |G_{ij}|$。该和的上界为 $(s-1)\\mu$。这给出了 $\\delta_s$ 的一个简单上界：\n    $$\n    \\delta_s \\le (s-1)\\mu\n    $$\n    我们为给定的稀疏度 $s$ 计算这个值，$\\delta_{s, \\text{Gersh}} = (s-1)\\mu$。\n*   **OMP恢复保证 ($s_{\\text{OMP}}$)：** 正交匹配追踪（OMP）是一种贪婪算法，保证能够从测量值 $\\mathbf{y} = \\mathbf{A}\\mathbf{x}$ 中完美恢复任何 $s$-稀疏信号 $\\mathbf{x}$，前提是稀疏度 $s$ 满足以下条件：\n    $$\n    s  \\frac{1}{2}\\left(1 + \\frac{1}{\\mu}\\right)\n    $$\n    我们计算此保证成立的最大整数稀疏度 $s_{\\text{OMP}}$。这是严格小于该界的最大整数：\n    $$\n    s_{\\text{OMP}} = \\left\\lceil \\frac{1}{2}\\left(1 + \\frac{1}{\\mu}\\right) \\right\\rceil - 1\n    $$\n\n**3. 贪婪列剪枝**\n\n该过程涉及使用贪婪策略从 $\\mathbf{A}$ 中移除 $k$ 列。目标是移除“对相干性最有害”的列。这被解释为移除与所有其他列具有最高总绝对相关性的列。在 $k$ 个剪枝步骤的每一步中，我们执行以下操作：\n1.  对于当前具有列 $\\{\\mathbf{a}_j\\}$ 的矩阵，计算每列 $j$ 的“相干性贡献”：$c_j = \\sum_{i \\neq j} |\\langle \\mathbf{a}_i, \\mathbf{a}_j \\rangle|$。\n2.  识别使该和最大化的列索引 $j^*$：$j^* = \\arg\\max_j c_j$。\n3.  从矩阵中移除列 $\\mathbf{a}_{j^*}$。\n\n此过程重复 $k$ 次，将列数从 $n$ 减少到 $n' = n-k$。将得到的剪枝后矩阵表示为 $\\mathbf{A}'$。\n\n**4. 剪枝后分析**\n\n剪枝后，我们得到矩阵 $\\mathbf{A}' \\in \\mathbb{R}^{m \\times n'}$。对这个新矩阵重新评估在步骤2中计算的所有量：\n*   剪枝后互相关性，$\\mu' = \\mu(\\mathbf{A}')$。\n*   剪枝后韦尔奇界，$\\mu'_W$，使用维度 $n'$ 计算。\n*   剪枝后基于格什戈林圆盘的 $\\delta_s$ 上界，即 $\\delta'_{s, \\text{Gersh}} = (s-1)\\mu'$。\n*   剪枝后OMP保证的最大稀疏度，$s'_{\\text{OMP}}$，使用 $\\mu'$ 计算。\n\n**5. OMP保证判定**\n\n最后，对于给定的固定稀疏度 $s$，我们判断OMP成功保证在剪枝前后是否均得到满足。这涉及两个布尔检查：\n1.  **剪枝前：** $s  \\frac{1}{2}\\left(1 + \\frac{1}{\\mu}\\right)$ 是否成立？\n2.  **剪枝后：** $s  \\frac{1}{2}\\left(1 + \\frac{1}{\\mu'}\\right)$ 是否成立？\n\n对于每个测试用例，这些步骤生成所需的十个输出值：$\\mu$, $\\mu'$, $\\delta_{s, \\text{Gersh}}$, $\\delta'_{s, \\text{Gersh}}$, $s_{\\text{OMP}}$, $s'_{\\text{OMP}}$，两个布尔值，$\\mu_W$ 和 $\\mu'_W$。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to execute the analysis for all test cases.\n    \"\"\"\n    test_cases = [\n        # (m, n, k, s, seed)\n        (30, 60, 10, 4, 1),\n        (40, 80, 0, 6, 2),\n        (20, 100, 40, 8, 3),\n        (50, 55, 4, 3, 4),\n        (30, 90, 20, 10, 5),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        m, n, k, s, seed = case\n        result = process_case(m, n, k, s, seed)\n        all_results.append(result)\n\n    # Format the final output string as a list of lists, with no spaces.\n    results_as_strings = [str(r).replace(\" \", \"\") for r in all_results]\n    print(f\"[{','.join(results_as_strings)}]\")\n\ndef process_case(m, n, k, s, seed):\n    \"\"\"\n    Processes a single test case according to the problem specification.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Construct the sensing matrix\n    A = rng.standard_normal((m, n))\n    A /= np.linalg.norm(A, axis=0, keepdims=True)\n\n    # 2. Pre-pruning analysis\n    mu_pre, delta_s_bound_pre, s_omp_pre, omp_guarantee_pre, welch_pre = analyze_matrix(A, s)\n\n    # 4. Perform column pruning\n    A_pruned = A.copy()\n    for _ in range(k):\n        # Ensure there are columns to prune\n        if A_pruned.shape[1] = 1:\n            break\n        \n        # Compute Gram matrix for the current matrix\n        G_prune = A_pruned.T @ A_pruned\n        np.fill_diagonal(G_prune, 0)\n        \n        # Find the column that maximizes the sum of absolute inner products\n        # with other columns.\n        coherence_sums = np.sum(np.abs(G_prune), axis=1)\n        idx_to_remove = np.argmax(coherence_sums)\n        \n        # Remove the identified column\n        A_pruned = np.delete(A_pruned, idx_to_remove, axis=1)\n    \n    # 5. Post-pruning analysis\n    if k == 0:\n        # If no pruning was done, post-pruning metrics are identical to pre-pruning.\n        mu_post = mu_pre\n        delta_s_bound_post = delta_s_bound_pre\n        s_omp_post = s_omp_pre\n        omp_guarantee_post = omp_guarantee_pre\n        welch_post = welch_pre\n    else:\n        mu_post, delta_s_bound_post, s_omp_post, omp_guarantee_post, welch_post = analyze_matrix(A_pruned, s)\n\n    # 6. Format and return results\n    return [\n        round(mu_pre, 6),\n        round(mu_post, 6),\n        round(delta_s_bound_pre, 6),\n        round(delta_s_bound_post, 6),\n        int(s_omp_pre),\n        int(s_omp_post),\n        omp_guarantee_pre,\n        omp_guarantee_post,\n        round(welch_pre, 6),\n        round(welch_post, 6)\n    ]\n\ndef analyze_matrix(A, s):\n    \"\"\"\n    Computes all required metrics for a given sensing matrix A and sparsity s.\n    \"\"\"\n    m, n = A.shape\n\n    if n = 1:\n        # Trivial case with 0 or 1 columns: coherence is 0.\n        mu = 0.0\n        delta_s_bound = 0.0\n        # OMP bound is infinite, so s_omp is effectively infinite. Use a large integer.\n        s_omp = 2**31 - 1\n        omp_guarantee = True\n        welch = 0.0\n        return mu, delta_s_bound, s_omp, omp_guarantee, welch\n\n    # Compute Gram matrix and mutual coherence\n    G = A.T @ A\n    np.fill_diagonal(G, 0)\n    mu = np.max(np.abs(G))\n\n    # Welch bound\n    if n > m:\n        welch = np.sqrt((n - m) / (m * (n - 1)))\n    else:\n        welch = 0.0\n\n    # Gershgorin-based upper bound on RIC\n    delta_s_bound = (s - 1) * mu\n\n    # OMP success guarantee\n    if mu == 0:\n        s_omp = 2**31 - 1\n        omp_guarantee = True\n    else:\n        omp_bound = 0.5 * (1 + 1 / mu)\n        # s_OMP is the largest integer s' such that s'  omp_bound.\n        s_omp = np.ceil(omp_bound) - 1\n        # Check if the specific sparsity s meets the guarantee.\n        omp_guarantee = (s  omp_bound)\n    \n    return mu, delta_s_bound, s_omp, omp_guarantee, welch\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "最后的这个练习将我们带入更高级的矩阵设计领域，我们将使用连续优化方法来微调矩阵，而不是离散的剪枝操作。本练习旨在介绍通过预缩放（pre-scaling）来改善矩阵受限等距性质 (Restricted Isometry Property, RIP) 的思想，你将构建并求解一个凸优化问题，以找到最佳的列权重来最小化 Gershgorin 半径。这个练习不仅展示了一种精妙的设计技术，也揭示了在改进理论界限和维持数值稳定性之间的权衡 。",
            "id": "3434940",
            "problem": "考虑一个实数矩阵 $A \\in \\mathbb{R}^{m \\times n}$，它代表压缩感知中的一个传感字典。令 $A = [a_1,\\dots,a_n]$ 表示其列，并定义格拉姆矩阵 $G = A^\\top A \\in \\mathbb{R}^{n \\times n}$。对于一个具有严格正项的对角缩放矩阵 $D = \\mathrm{diag}(d_1,\\dots,d_n)$，重缩放后的矩阵为 $A D$，其格拉姆矩阵为 $G(D) = (A D)^\\top (A D) = D A^\\top A D = D G D$，其元素为 $g_{ij}(D) = d_i d_j \\langle a_i, a_j \\rangle$。\n\n格什戈林圆盘定理指出，一个实对称矩阵的每个特征值都位于至少一个圆盘内，该圆盘以对角线元素 $g_{ii}(D)$ 为中心，半径为 $r_i(D) = \\sum_{j \\neq i} |g_{ij}(D)|$。在有限等距性质（RIP）的背景下，目标是使 $G(D)$ 的主子矩阵的特征值接近于 $1$，这可以通过减小最大格什戈林半径并将对角线元素保持在 $1$ 附近来保守地促进。对于单位范数列，互相关性定义为 $\\mu = \\max_{i \\neq j} \\left|\\frac{\\langle a_i, a_j \\rangle}{\\|a_i\\|_2 \\|a_j\\|_2}\\right|$，而当 $n  m$ 时，Welch界给出了 $\\mu$ 的一个下界，即 $\\mu \\ge \\sqrt{\\frac{n - m}{m (n - 1)}}$。\n\n您的任务是：\n- 制定并实现一个优化问题，选择正的缩放因子 $d_i$ 来减小 $G(D)$ 的最大格什戈林半径 $\\max_i r_i(D)$，同时通过箱式约束 $\\alpha_{\\min} \\le \\|d_i a_i\\|_2 \\le \\alpha_{\\max}$（其中 $\\alpha_{\\min}, \\alpha_{\\max}$ 为固定标量）来强制重缩放后列范数 $\\|d_i a_i\\|_2$ 的稳定性。该优化必须基于一个基本基础：使用格什戈林圆盘定理和凸分析。您必须使用变量 $x_i = \\log d_i$ 进行工作，并使用 log-sum-exp 构造设计一个基于 $\\max_i r_i(D)$ 的平滑近似的凸目标。不假设或要求 $A$ 中的列是单位范数。\n- 量化在 $A$ 中存在噪声的情况下，改进的RIP界与列范数稳定性之间的权衡。使用基于格什戈林的 $k$-有限等距常数 $\\delta_k$ 的上界，定义为\n$$\n\\delta_k \\le \\max_{i \\in \\{1,\\dots,n\\}} \\left( \\left| g_{ii}(D) - 1 \\right| + \\sum_{\\text{top }(k-1)\\text{ off-diagonals in row } i} \\left| g_{ij}(D) \\right| \\right),\n$$\n该上界通过将格什戈林定理应用于所有 $k \\times k$ 主子矩阵，并将每个圆盘半径上界设为相应行中 $(k-1)$ 个最大非对角线元素绝对值之和得到。通过重缩放后列范数与 $1$ 的最大偏差来衡量稳定性，即 $\\max_i \\left| \\|d_i a_i\\|_2 - 1 \\right|$。\n- 计算并报告归一化列 $\\tilde{a}_i = a_i / \\|a_i\\|_2$ 的互相关性 $\\mu = \\max_{i \\neq j} |\\langle \\tilde{a}_i, \\tilde{a}_j \\rangle|$，以及Welch界 $\\sqrt{\\max\\left\\{0, \\frac{n - m}{m (n - 1)}\\right\\}}$。\n\n实现细节：\n- 通过定义 $x_i = \\log d_i$ 来构建凸目标，使用权重 $w_{ij} = |\\langle a_i, a_j \\rangle|$（当 $i \\neq j$ 时）和 $w_{ii} = 0$，并使用 log-sum-exp 代理最小化 $\\max_i \\sum_{j \\neq i} w_{ij} \\exp(x_i + x_j)$ 的平滑近似。强制执行约束 $\\log(\\alpha_{\\min}/\\|a_i\\|_2) \\le x_i \\le \\log(\\alpha_{\\max}/\\|a_i\\|_2)$。\n- 使用基于原则的投影梯度法和在平滑凸目标上的回溯线搜索来解决优化问题。解析地推导并实现梯度，并投影到箱式约束上。\n- 优化后，构建 $D = \\mathrm{diag}(e^{x_1},\\dots,e^{x_n})$，计算 $G(D)$、最大格什戈林半径 $\\max_i r_i(D)$，以及使用每行 $(k-1)$ 个最大非对角线元素之和给出的 $\\delta_k$ 界，还有最大范数偏差。\n\n测试套件：\n- 使用四个测试用例，参数为 $(m,n,k,\\text{seed},\\text{noise},\\alpha_{\\min},\\alpha_{\\max})$：\n    1. $(20,30,4,1,0.05,0.90,1.10)$\n    2. $(20,30,4,2,0.05,0.99,1.01)$\n    3. $(40,60,6,3,0.15,0.70,1.30)$\n    4. $(8,12,3,4,0.00,0.85,1.15)$\n- 对于每个测试用例，使用给定的种子生成具有零均值和单位方差的独立同分布高斯项的矩阵 $A$，并添加一个噪声矩阵，其缩放使其弗罗贝尼乌斯范数等于基础矩阵 $A$ 的弗罗贝尼乌斯范数的指定分数。具体来说，如果 $Z$ 具有独立同分布的 $\\mathcal{N}(0,1)$ 项，则将噪声设置为 $\\eta \\, Z$，其中 $\\eta = \\text{noise} \\cdot \\|A\\|_F / \\|Z\\|_F$，并使用 $A \\leftarrow A + \\eta Z$。\n\n您的程序必须为每个测试用例计算以下七个量：\n- 缩放前 $G$ 的最大格什戈林半径，$\\max_i \\sum_{j \\neq i} |g_{ij}|$。\n- 优化后 $G(D)$ 的最大格什戈林半径，$\\max_i \\sum_{j \\neq i} |g_{ij}(D)|$。\n- 缩放前基于格什戈林的 $\\delta_k$ 上界。\n- 缩放后基于格什戈林的 $\\delta_k$ 上界。\n- 重缩放后列范数与 $1$ 的最大偏差，$\\max_i \\left| \\|d_i a_i\\|_2 - 1 \\right|$。\n- $A$ 的归一化列的互相关性 $\\mu$。\n- Welch下界 $\\sqrt{\\max\\left\\{0, \\frac{n - m}{m (n - 1)}\\right\\}}$。\n\n最终输出格式：\n- 您的程序应生成一行输出，包含用方括号括起来的逗号分隔列表形式的结果，其中每个测试用例的指标表示为一个包含六位小数浮点数的列表。例如，输出应如下所示：\n`[ [x_{1,1}, x_{1,2}, \\dots, x_{1,7}], [x_{2,1}, \\dots, x_{2,7}], [x_{3,1}, \\dots, x_{3,7}], [x_{4,1}, \\dots, x_{4,7}] ]`。",
            "solution": "用户提供了一个在压缩感知和稀疏优化领域内的问题，该问题涉及对传感矩阵 $A$ 进行预缩放以改善其属性，特别是与有限等距性质（RIP）相关的属性。该问题将使用格什戈林圆盘定理和凸优化来解决。\n\n### 步骤1：问题验证\n\n**1.1. 已知条件提取**\n\n- **传感字典**：一个实数矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其列为 $a_1, \\dots, a_n$。\n- **格拉姆矩阵**：$G = A^\\top A \\in \\mathbb{R}^{n \\times n}$。\n- **缩放**：一个对角矩阵 $D = \\mathrm{diag}(d_1, \\dots, d_n)$，其中 $d_i  0$。\n- **缩放后的格拉姆矩阵**：$G(D) = (AD)^\\top(AD) = D G D$，其元素为 $g_{ij}(D) = d_i d_j \\langle a_i, a_j \\rangle$。\n- **格什戈林半径**：对于 $G(D)$，第 $i$ 行的半径是 $r_i(D) = \\sum_{j \\neq i} |g_{ij}(D)|$。\n- **优化目标**：最小化 $\\max_i r_i(D)$。\n- **约束**：对缩放后列范数的箱式约束：$\\alpha_{\\min} \\le \\|d_i a_i\\|_2 \\le \\alpha_{\\max}$。\n- **优化变量**：$x_i = \\log d_i$。\n- **目标函数**：一个基于 $\\max_i r_i(D)$ 的 log-sum-exp 平滑近似的凸目标。定义明确为最小化 $\\max_i \\sum_{j \\neq i} w_{ij} \\exp(x_i + x_j)$ 的代理，其中 $w_{ij} = |\\langle a_i, a_j \\rangle|$。\n- **优化算法**：带回溯线搜索的投影梯度法。\n- **RIP界 ($\\delta_k$)**：基于格什戈林的上界由 $\\delta_k \\le \\max_{i} \\left( \\left| g_{ii}(D) - 1 \\right| + \\sum_{\\text{top }(k-1)} \\left| g_{ij}(D) \\right| \\right)$ 给出。\n- **稳定性度量**：缩放后列范数与1的最大偏差：$\\max_i | \\|d_i a_i\\|_2 - 1 |$。\n- **互相关性**：$\\mu = \\max_{i \\neq j} |\\langle a_i/\\|a_i\\|_2, a_j/\\|a_j\\|_2 \\rangle|$。\n- **Welch界**：$\\sqrt{\\max\\left\\{0, \\frac{n - m}{m (n - 1)}\\right\\}}$。\n- **测试套件**：四组特定的参数 $(m, n, k, \\text{seed}, \\text{noise}, \\alpha_{\\min}, \\alpha_{\\max})$。\n- **矩阵生成**：从 $\\mathcal{N}(0,1)$ 分布的项生成 $A$，并添加缩放后的噪声。\n- **要求输出**：每个测试用例的七个特定数值。\n\n**1.2. 根据标准进行验证**\n根据验证标准对问题进行评估：\n- **科学基础**：该问题牢固地植根于线性代数、压缩感知和凸优化中的既定概念。格拉姆矩阵、格什戈林圆盘定理、有限等距性质（RIP）、互相关性、Welch界、log-sum-exp平滑和投影梯度下降等概念都是标准的、数学上严谨的。\n- **良态的**：问题是良态的。它指定了输入、优化问题（一个在凸集上的凸最小化问题，有唯一解）、要使用的算法以及确切的所需输出。整个设置是自包含的，足以产生唯一的结果。\n- **客观性**：语言精确、数学化，没有任何主观性或歧义。\n\n该问题没有表现出任何无效性缺陷。它在科学上不是不合理的，也不是不可形式化的、不完整的、不切实际的、病态的、琐碎的或不可验证的。\n\n**1.3. 结论**\n问题是**有效的**。\n\n### 步骤2：解法推导与设计\n\n问题的核心是解决一个带约束的优化问题。我们将首先形式化目标函数及其梯度，然后详细说明投影梯度算法，最后指定所需指标的计算。\n\n**2.1. 凸优化公式**\n令 $A \\in \\mathbb{R}^{m \\times n}$ 为传感矩阵。目标是找到缩放因子 $d_i  0$ 来最小化缩放后格拉姆矩阵 $G(D) = D A^\\top A D$ 的最大格什戈林半径。\n第 $i$ 个格什戈林圆盘的半径为 $r_i(D) = \\sum_{j \\neq i} |g_{ij}(D)| = \\sum_{j \\neq i} d_i d_j |\\langle a_i, a_j \\rangle|$。\n使用变量替换 $x_i = \\log d_i$，从而 $d_i = e^{x_i}$，半径成为 $\\mathbf{x} = [x_1, \\dots, x_n]^\\top$ 的函数：\n$$ r_i(\\mathbf{x}) = \\sum_{j \\neq i} |\\langle a_i, a_j \\rangle| e^{x_i + x_j} $$\n我们的目标是最小化 $\\max_{i} r_i(\\mathbf{x})$。按照规定，我们使用 log-sum-exp 函数作为 max 函数的平滑代理。要最小化的目标函数是：\n$$ f(\\mathbf{x}) = \\log\\left(\\sum_{i=1}^n \\exp(r_i(\\mathbf{x}))\\right) $$\n该函数是凸函数，因为每个 $r_i(\\mathbf{x})$ 是指数函数之和（一个凸函数），而凸函数向量的 log-sum-exp 也是凸函数。\n\n**2.2. 梯度推导**\n要实现基于梯度的算法，我们需要梯度 $\\nabla f(\\mathbf{x})$。梯度的第 $k$ 个分量由链式法则给出：\n$$ \\frac{\\partial f}{\\partial x_k} = \\frac{1}{\\sum_{l=1}^n e^{r_l(\\mathbf{x})}} \\sum_{i=1}^n e^{r_i(\\mathbf{x})} \\frac{\\partial r_i(\\mathbf{x})}{\\partial x_k} $$\n令 $p_i(\\mathbf{x}) = \\frac{e^{r_i(\\mathbf{x})}}{\\sum_l e^{r_l(\\mathbf{x})}}$。则 $\\frac{\\partial f}{\\partial x_k} = \\sum_{i=1}^n p_i(\\mathbf{x}) \\frac{\\partial r_i(\\mathbf{x})}{\\partial x_k}$。\n$r_i(\\mathbf{x})$ 的偏导数为：\n-   若 $i=k$：$\\frac{\\partial r_k}{\\partial x_k} = \\sum_{j \\neq k} |\\langle a_k, a_j \\rangle| e^{x_k+x_j} = r_k(\\mathbf{x})$。\n-   若 $i \\neq k$：$\\frac{\\partial r_i}{\\partial x_k} = |\\langle a_i, a_k \\rangle| e^{x_i+x_k}$。\n\n结合这些，梯度的第 $k$ 个分量是：\n$$ (\\nabla f)_k = p_k(\\mathbf{x}) r_k(\\mathbf{x}) + \\sum_{i \\neq k} p_i(\\mathbf{x}) |\\langle a_i, a_k \\rangle| e^{x_i+x_k} $$\n为了高效计算，这可以被向量化。令 $W$ 为一个矩阵，其元素为 $W_{ij} = |\\langle a_i, a_j \\rangle|$（当 $i \\neq j$ 时）且 $W_{ii} = 0$。令 $\\mathbf{e^x} = [e^{x_1}, \\dots, e^{x_n}]^\\top$。\n-   半径向量为 $\\mathbf{r}(\\mathbf{x}) = \\text{diag}(\\mathbf{e^x}) (W \\mathbf{e^x})$。更简单地， $r_i(\\mathbf{x}) = \\sum_j W_{ij} e^{x_i}e^{x_j}$，这可以从 `W * outer(exp(x), exp(x))` 计算得出。\n-   梯度可以表示为：\n    $$ \\nabla f = \\mathbf{p} \\odot \\mathbf{r} + \\mathbf{e^x} \\odot (W (\\mathbf{p} \\odot \\mathbf{e^x})) $$\n    其中 $\\odot$ 表示逐元素乘法，$\\mathbf{p}$ 是概率 $p_i(\\mathbf{x})$ 的向量。\n\n**2.3. 约束与投影**\n约束条件是 $\\alpha_{\\min} \\le \\|d_i a_i\\|_2 \\le \\alpha_{\\max}$，这可以转化为 $\\alpha_{\\min} \\le e^{x_i} \\|a_i\\|_2 \\le \\alpha_{\\max}$。取对数得到关于 $\\mathbf{x}$ 的箱式约束：\n$$ \\log\\left(\\frac{\\alpha_{\\min}}{\\|a_i\\|_2}\\right) \\le x_i \\le \\log\\left(\\frac{\\alpha_{\\max}}{\\|a_i\\|_2}\\right) $$\n设这些界限为 $L_i$ 和 $U_i$。可行集 $C$ 是一个超矩形。到该集合上的投影算子 $P_C(\\mathbf{y})$ 只是逐元素的裁剪：$P_C(\\mathbf{y})_i = \\max(L_i, \\min(U_i, y_i))$。\n\n**2.4. 带回溯线搜索的投影梯度法**\n优化过程如下：\n1.  初始化 $\\mathbf{x}^{(0)}$（例如，在可行箱的中心）。\n2.  对于 $t = 0, 1, 2, \\dots$ 直到收敛：\n    a.  计算梯度 $\\mathbf{g}^{(t)} = \\nabla f(\\mathbf{x}^{(t)})$。\n    b.  使用回溯线搜索找到一个步长 $\\eta_t  0$。从 $\\eta = 1$ 开始。当 Armijo 条件 $f(\\mathbf{x}_{proj})  f(\\mathbf{x}^{(t)}) + c \\cdot (\\mathbf{g}^{(t)})^\\top (\\mathbf{x}_{proj} - \\mathbf{x}^{(t)})$ 不满足时，减小 $\\eta \\leftarrow \\beta \\eta$，其中 $\\mathbf{x}_{proj} = P_C(\\mathbf{x}^{(t)} - \\eta \\mathbf{g}^{(t)})$。典型值为 $c=10^{-4}$ 和 $\\beta=0.5$。\n    c.  更新：$\\mathbf{x}^{(t+1)} = P_C(\\mathbf{x}^{(t)} - \\eta_t \\mathbf{g}^{(t)})$。\n3.  最终的 $\\mathbf{x}^*$ 给出最优的缩放因子 $d_i^* = e^{x_i^*}$。\n\n**2.5. 指标计算**\n找到最优缩放 $D = \\mathrm{diag}(e^{\\mathbf{x}^*})$ 后，我们为原始矩阵 $A$ 和缩放后矩阵 $AD$ 计算七个所需的指标。\n-   **格什戈林半径**：由 $G=A^\\top A$ 和 $G(D)=DGD$ 计算。\n-   **$\\delta_k$ 界**：对于相应格拉姆矩阵（$G$ 或 $G(D)$）的每一行 $i$，我们计算 $|g_{ii} - 1| + S_i$，其中 $S_i$ 是该行中 $k-1$ 个最大非对角线绝对值之和。最终的界是所有行的最大值。\n-   **范数偏差**：计算为 $\\max_i |d_i^* \\|a_i\\|_2 - 1|$。\n-   **互相关性  Welch界**：从原始矩阵 $A$ 计算，首先对其列进行归一化。\n\n实现将遵循这一原则性设计。为保证数值稳定性，log-sum-exp 的计算将使用标准的减去最大值的技巧来防止溢出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It orchestrates matrix generation, optimization, and metric calculation.\n    \"\"\"\n\n    def solve_single_case(m, n, k, seed, noise_frac, alpha_min, alpha_max):\n        \"\"\"\n        Solves the problem for a single set of parameters.\n        \"\"\"\n        \n        # 1. Generate matrix A with specified noise level\n        rng = np.random.default_rng(seed)\n        A_base = rng.standard_normal((m, n))\n        if noise_frac > 0:\n            Z = rng.standard_normal((m, n))\n            norm_A_base = np.linalg.norm(A_base, 'fro')\n            norm_Z = np.linalg.norm(Z, 'fro')\n            if norm_Z > 1e-12:\n                eta = noise_frac * norm_A_base / norm_Z\n                A = A_base + eta * Z\n            else:\n                A = A_base\n        else:\n            A = A_base\n\n        G = A.T @ A\n        col_norms = np.linalg.norm(A, axis=0)\n        # Prevent division by zero for potential zero-norm columns\n        col_norms[col_norms  1e-12] = 1e-12\n\n        # 2. Calculate metrics that are independent of scaling\n        # Metric 6: Mutual Coherence\n        A_normalized = A / col_norms\n        G_normalized = A_normalized.T @ A_normalized\n        np.fill_diagonal(G_normalized, 0)\n        mu = np.max(np.abs(G_normalized))\n        \n        # Metric 7: Welch Bound\n        if n > m:\n            welch_bound = np.sqrt((n - m) / (m * (n - 1)))\n        else:\n            welch_bound = 0.0\n\n        # 3. Calculate metrics for the original matrix A (before scaling)\n        def get_delta_k_bound(gram_matrix, k_val):\n            abs_G = np.abs(gram_matrix)\n            g_ii = np.diag(gram_matrix)\n            np.fill_diagonal(abs_G, 0)\n            \n            delta_k_terms = np.zeros(gram_matrix.shape[0])\n            for i in range(gram_matrix.shape[0]):\n                row = abs_G[i, :]\n                if k_val == 1:\n                    sum_k1_largest = 0.0\n                else:\n                    partition_idx = len(row) - (k_val - 1)\n                    sum_k1_largest = np.sum(np.partition(row, partition_idx)[partition_idx:])\n                delta_k_terms[i] = np.abs(g_ii[i] - 1) + sum_k1_largest\n            return np.max(delta_k_terms)\n\n        abs_G_unscaled = np.abs(G)\n        np.fill_diagonal(abs_G_unscaled, 0)\n        # Metric 1: Max Gershgorin radius before scaling\n        max_gersh_radius_before = np.max(np.sum(abs_G_unscaled, axis=1))\n        # Metric 3: Gershgorin-based delta_k bound before scaling\n        delta_k_before = get_delta_k_bound(G, k)\n        \n        # 4. Run the optimization\n        W = np.abs(G)\n        np.fill_diagonal(W, 0)\n\n        lower_bounds = np.log(alpha_min / col_norms)\n        upper_bounds = np.log(alpha_max / col_norms)\n        \n        # Initialize x at the center of the feasible box\n        x = (lower_bounds + upper_bounds) / 2.0\n        \n        # Hyperparameters for projected gradient descent\n        max_iter = 500\n        tolerance = 1e-7\n        beta = 0.5  # for backtracking line search\n        c_armijo = 1e-4\n\n        for _ in range(max_iter):\n            x_old = x.copy()\n            \n            # Compute objective value and gradient\n            exp_x = np.exp(x)\n            exp_x_outer = np.outer(exp_x, exp_x)\n            radii_vec = np.sum(W * exp_x_outer, axis=1)\n            \n            # Objective (stable log-sum-exp)\n            max_r = np.max(radii_vec)\n            exp_radii_shifted = np.exp(radii_vec - max_r)\n            sum_exp_radii = np.sum(exp_radii_shifted)\n            obj_val = max_r + np.log(sum_exp_radii)\n            \n            # Gradient (stable and vectorized)\n            p = exp_radii_shifted / sum_exp_radii\n            term1 = p * radii_vec\n            u = p * exp_x\n            v = W @ u\n            term2 = exp_x * v\n            grad = term1 + term2\n            \n            # Backtracking line search with Armijo condition\n            eta = 1.0\n            while True:\n                x_proj = np.clip(x - eta * grad, lower_bounds, upper_bounds)\n                \n                exp_x_proj = np.exp(x_proj)\n                exp_x_proj_outer = np.outer(exp_x_proj, exp_x_proj)\n                radii_vec_proj = np.sum(W * exp_x_proj_outer, axis=1)\n                max_r_proj = np.max(radii_vec_proj)\n                obj_val_proj = max_r_proj + np.log(np.sum(np.exp(radii_vec_proj - max_r_proj)))\n                \n                armijo_rhs = obj_val + c_armijo * np.dot(grad, x_proj - x)\n                \n                if obj_val_proj = armijo_rhs:\n                    break\n                \n                eta *= beta\n                if eta  1e-12:\n                    x_proj = np.clip(x - eta * grad, lower_bounds, upper_bounds)\n                    break\n            \n            x = x_proj\n            \n            if np.linalg.norm(x - x_old)  tolerance:\n                break\n                \n        # 5. Calculate metrics for the scaled matrix A*D (after scaling)\n        d_opt = np.exp(x)\n        D_opt = np.diag(d_opt)\n        G_scaled = D_opt @ G @ D_opt\n        \n        abs_G_scaled = np.abs(G_scaled)\n        np.fill_diagonal(abs_G_scaled, 0)\n        # Metric 2: Max Gershgorin radius after scaling\n        max_gersh_radius_after = np.max(np.sum(abs_G_scaled, axis=1))\n        # Metric 4: Gershgorin-based delta_k bound after scaling\n        delta_k_after = get_delta_k_bound(G_scaled, k)\n        \n        # Metric 5: Max deviation of rescaled column norms from 1\n        scaled_norms = d_opt * col_norms\n        max_norm_dev = np.max(np.abs(scaled_norms - 1))\n        \n        return [round(val, 6) for val in [\n            max_gersh_radius_before, max_gersh_radius_after,\n            delta_k_before, delta_k_after,\n            max_norm_dev, mu, welch_bound\n        ]]\n\n    # Define test cases from the problem statement\n    test_cases = [\n        (20, 30, 4, 1, 0.05, 0.90, 1.10),\n        (20, 30, 4, 2, 0.05, 0.99, 1.01),\n        (40, 60, 6, 3, 0.15, 0.70, 1.30),\n        (8, 12, 3, 4, 0.00, 0.85, 1.15),\n    ]\n\n    all_results = []\n    for params in test_cases:\n        result = solve_single_case(*params)\n        all_results.append(result)\n\n    # Format the final output string to match the required format\n    inner_strs = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_output_str = f\"[{','.join(inner_strs)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}