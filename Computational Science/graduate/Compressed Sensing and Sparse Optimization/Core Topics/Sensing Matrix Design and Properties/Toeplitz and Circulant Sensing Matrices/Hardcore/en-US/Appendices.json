{
    "hands_on_practices": [
        {
            "introduction": "The efficiency of iterative optimization algorithms in compressed sensing relies heavily on the speed of matrix-vector multiplications. This practice focuses on the cornerstone of working with structured sensing matrices: implementing the forward operator $A x$ and its adjoint $A^* y$ without forming the matrices explicitly. By leveraging the convolution theorem, you will see how the computationally expensive operation of circular convolution is transformed into a highly efficient element-wise product in the Fourier domain, a skill essential for any large-scale application .",
            "id": "3490937",
            "problem": "You are given an $n \\times n$ circulant sensing matrix $C(g)$ generated by a vector $g \\in \\mathbb{C}^n$, and a sampling operator $P \\in \\{0,1\\}^{m \\times n}$ that selects $m$ distinct rows of an input matrix according to an index set $S \\subset \\{0,1,\\dots,n-1\\}$. Define $A = P C(g)$. The operator $C(g)$ acts on a vector $x \\in \\mathbb{C}^n$ by circular convolution with $g$, and the operator $P$ acts by selecting the entries of a vector with indices in $S$, in order. Let $A^*$ denote the conjugate transpose of $A$.\n\nYour tasks are:\n- Design routines that compute $A x$ and $A^* y$ using the Fast Fourier Transform (FFT) without explicitly forming $A$.\n- Provide a clear complexity analysis, in terms of $n$ and $m$, for your FFT-based routines and for the na√Øve dense-matrix approach that explicitly forms and multiplies by $A$.\n\nStart from the following fundamental base:\n- The action of a circulant matrix $C(g)$ on a vector is equal to circular convolution by $g$.\n- Circular convolution in the time domain corresponds to pointwise multiplication in the frequency domain under the Discrete Fourier Transform (DFT).\n- The sampling operator $P$ selects $m$ entries indexed by $S$ in order, and its adjoint $P^*$ embeds a length-$m$ vector into $\\mathbb{C}^n$ by placing its entries at indices $S$ and zeros elsewhere.\n\nThe program you produce must:\n- Implement routines that compute $A x$ and $A^* y$ using FFTs without forming $A$.\n- For verification, compute reference results using explicit dense matrices (forming the circulant matrix and, when needed, the sampling operator or its adjoint) and compare to the FFT-based outputs.\n- For each test case, return a single float equal to the maximum of two relative errors: one for $A x$ and one for $A^* y$, where relative error is defined as $\\lVert u_{\\mathrm{FFT}} - u_{\\mathrm{dense}} \\rVert_2 / \\lVert u_{\\mathrm{dense}} \\rVert_2$ with the convention that if the denominator is $0$, the relative error is the numerator.\n\nTest suite:\nUse the following five test cases with the specified random seeds to ensure reproducibility. In each case, $S$ is the index set for $P$ and vectors are drawn from standard normal distributions as specified.\n\n- Case $1$: $n = 64$, $m = 32$, $S$ is a uniformly random subset of size $32$ from $\\{0,1,\\dots,63\\}$ sorted in ascending order (seed $0$). $g \\in \\mathbb{C}^{64}$ and $x \\in \\mathbb{C}^{64}$ are complex with independent real and imaginary parts drawn from $\\mathcal{N}(0,1)$; $y \\in \\mathbb{C}^{32}$ is complex with independent real and imaginary parts drawn from $\\mathcal{N}(0,1)$.\n- Case $2$: $n = 64$, $m = 64$, $S = \\{0,1,\\dots,63\\}$ (seed $1$). $g \\in \\mathbb{R}^{64}$ and $x \\in \\mathbb{R}^{64}$ are real with entries drawn from $\\mathcal{N}(0,1)$; $y \\in \\mathbb{R}^{64}$ is real with entries drawn from $\\mathcal{N}(0,1)$.\n- Case $3$: $n = 17$, $m = 1$, $S = \\{5\\}$ (seed $2$). $g \\in \\mathbb{C}^{17}$ and $x \\in \\mathbb{C}^{17}$ are complex with independent real and imaginary parts drawn from $\\mathcal{N}(0,1)$; $y \\in \\mathbb{C}$ is complex with independent real and imaginary parts drawn from $\\mathcal{N}(0,1)$.\n- Case $4$: $n = 50$, $m = 25$, $S = \\{0,1,\\dots,24\\}$ (seed $3$). $g \\in \\mathbb{R}^{50}$ and $x \\in \\mathbb{R}^{50}$ are real with entries drawn from $\\mathcal{N}(0,1)$; $y \\in \\mathbb{R}^{25}$ is real with entries drawn from $\\mathcal{N}(0,1)$.\n- Case $5$: $n = 128$, $m = 60$, $S$ is a uniformly random subset of size $60$ from $\\{0,1,\\dots,127\\}$ sorted in ascending order (seed $4$). $g \\in \\mathbb{R}^{128}$ is real with entries drawn from $\\mathcal{N}(0,1)$; $x \\in \\mathbb{R}^{128}$ is $k$-sparse with $k = 5$ nonzero entries selected uniformly at random (seed $4$) with values drawn from $\\mathcal{N}(0,1)$; $y \\in \\mathbb{R}^{60}$ is real with entries drawn from $\\mathcal{N}(0,1)$.\n\nComplexity analysis requirements:\n- Derive the asymptotic complexity of computing $A x$ and $A^* y$ with FFTs, assuming precomputation of the DFT of $g$.\n- Contrast this with the complexity of explicitly forming $A$ and performing dense matrix-vector multiplications.\n- Clearly state the dependence on $n$ and $m$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where the $i$-th entry is the float for test case $i$ (for $i = 1,2,3,4,5$), for example, $[r_1,r_2,r_3,r_4,r_5]$.",
            "solution": "The problem requires the design and analysis of efficient algorithms for computing the matrix-vector products $A x$ and $A^* y$, where $A$ is a structured sensing matrix defined as $A = P C(g)$. The matrix $C(g)$ is an $n \\times n$ circulant matrix generated by a vector $g \\in \\mathbb{C}^n$, and $P$ is an $m \\times n$ sampling operator that selects $m$ rows according to a given index set $S$. The key is to leverage the Fast Fourier Transform (FFT) to avoid the explicit formation and storage of the potentially large matrices involved.\n\n### Fast Computation of $A x$\n\nThe operation $A x$ is defined as $A x = P (C(g) x)$. We can compute this in two stages:\n1.  Compute the intermediate vector $z = C(g) x$.\n2.  Apply the sampling operator $P$ to $z$ to get the final result.\n\nThe action of a circulant matrix $C(g)$ on a vector $x$ is equivalent to the circular convolution of its generating vector $g$ and the vector $x$. This is denoted as $z = g * x$. The Convolution Theorem states that circular convolution in the time domain corresponds to element-wise multiplication in the frequency domain. Let $\\mathcal{F}$ denote the Discrete Fourier Transform (DFT) and $\\mathcal{F}^{-1}$ denote its inverse. The theorem is expressed as:\n$$\n\\mathcal{F}(g * x) = \\mathcal{F}(g) \\odot \\mathcal{F}(x)\n$$\nwhere $\\odot$ represents the Hadamard (element-wise) product.\n\nTherefore, the vector $z$ can be computed efficiently as:\n$$\nz = \\mathcal{F}^{-1}(\\mathcal{F}(g) \\odot \\mathcal{F}(x))\n$$\n\nThe second step is to apply the sampling operator $P$. The operator $P$ selects the entries of $z$ corresponding to the indices in the set $S \\subset \\{0, 1, \\dots, n-1\\}$. If $z = [z_0, z_1, \\dots, z_{n-1}]^T$, then $Pz$ is a vector of length $m$ containing the elements $\\{z_i\\}_{i \\in S}$.\n\nThe complete FFT-based algorithm for computing $A x$ is as follows:\n1.  Compute the DFT of the generating vector, $\\hat{g} = \\mathcal{F}(g)$. This can be pre-computed and stored if $A$ is applied multiple times.\n2.  Compute the DFT of the input vector, $\\hat{x} = \\mathcal{F}(x)$.\n3.  Perform the element-wise product in the frequency domain: $\\hat{z} = \\hat{g} \\odot \\hat{x}$.\n4.  Compute the inverse DFT to return to the time domain: $z = \\mathcal{F}^{-1}(\\hat{z})$.\n5.  Extract the $m$ elements of $z$ at the indices specified by $S$.\n\n### Fast Computation of $A^* y$\n\nThe adjoint operator $A^*$ is given by $A^* = (P C(g))^* = C(g)^* P^*$. The action on a vector $y \\in \\mathbb{C}^m$ is thus $A^* y = C(g)^* (P^* y)$. This can also be computed in stages.\n\n1.  Compute the intermediate vector $v = P^* y$. The operator $P^*$ is the adjoint of the sampling operator $P$. It performs an embedding operation: it takes a vector $y$ of length $m$ and creates a vector $v$ of length $n$ by placing the elements of $y$ at the indices specified by $S$ and filling the remaining entries with zeros. That is, for $i \\in \\{0, 1, \\dots, n-1\\}$, $v_i = y_k$ if $i$ is the $k$-th element of the sorted index set $S$, and $v_i = 0$ if $i \\notin S$.\n\n2.  Compute the product $w = C(g)^* v$. We must first characterize the matrix $C(g)^*$. The conjugate transpose of a circulant matrix is also a circulant matrix. If $C(g)$ is generated by the vector $g$, then $C(g)^*$ is generated by a vector $g'$ where $g'_k = \\overline{g_{(-k) \\pmod{n}}}$ for $k \\in \\{0, 1, \\dots, n-1\\}$. This vector $g'$ is the conjugated and time-reversed version of $g$.\n\nThe action $C(g)^* v$ is therefore equivalent to the circular convolution $g' * v$. We can again apply the Convolution Theorem:\n$$\nw = g' * v = \\mathcal{F}^{-1}(\\mathcal{F}(g') \\odot \\mathcal{F}(v))\n$$\nA crucial property connects the DFT of $g'$ to the DFT of $g$. The DFT of $g'$ is the element-wise complex conjugate of the DFT of $g$:\n$$\n\\mathcal{F}(g')_k = \\sum_{j=0}^{n-1} g'_j e^{-2\\pi i jk / n} = \\sum_{j=0}^{n-1} \\overline{g_{(-j) \\pmod n}} e^{-2\\pi i jk / n}\n$$\nLetting $l = (-j) \\pmod n$, we have $j = (-l) \\pmod n$. The sum becomes:\n$$\n\\sum_{l=0}^{n-1} \\overline{g_l} e^{-2\\pi i (-l)k / n} = \\sum_{l=0}^{n-1} \\overline{g_l} e^{2\\pi i lk / n} = \\overline{\\sum_{l=0}^{n-1} g_l e^{-2\\pi i lk / n}} = \\overline{\\mathcal{F}(g)_k}\n$$\nThus, $\\mathcal{F}(g') = \\overline{\\mathcal{F}(g)}$. Substituting this into the expression for $w$ gives:\n$$\nw = \\mathcal{F}^{-1}(\\overline{\\mathcal{F}(g)} \\odot \\mathcal{F}(v))\n$$\n\nThe complete FFT-based algorithm for computing $A^* y$ is as follows:\n1.  Compute the DFT of the generating vector, $\\hat{g} = \\mathcal{F}(g)$. This is the same pre-computation as for $A x$.\n2.  Construct the sparse vector $v \\in \\mathbb{C}^n$ by embedding $y \\in \\mathbb{C}^m$ at indices $S$.\n3.  Compute the DFT of the embedded vector, $\\hat{v} = \\mathcal{F}(v)$.\n4.  Compute the element-wise product in the frequency domain: $\\hat{w} = \\overline{\\hat{g}} \\odot \\hat{v}$.\n5.  Compute the inverse DFT to obtain the final result: $w = \\mathcal{F}^{-1}(\\hat{w})$.\n\n### Complexity Analysis\n\nWe analyze the computational complexity of both the FFT-based methods and the naive dense matrix approaches. The complexity of an $N$-point FFT or IFFT is $O(N \\log N)$.\n\n**FFT-based Approach:**\n-   **Pre-computation:** Computing $\\hat{g} = \\mathcal{F}(g)$ requires $O(n \\log n)$ operations. This is a one-time cost.\n-   **Computation of $A x$:**\n    1.  $\\mathcal{F}(x)$: $O(n \\log n)$.\n    2.  $\\hat{g} \\odot \\hat{x}$: $O(n)$.\n    3.  $\\mathcal{F}^{-1}(\\hat{z})$: $O(n \\log n)$.\n    4.  Sampling $Pz$: $O(m)$.\n    The total complexity, assuming $\\hat{g}$ is pre-computed, is dominated by the FFTs, resulting in **$O(n \\log n)$**.\n-   **Computation of $A^* y$:**\n    1.  Embedding $P^*y$: $O(n)$ to initialize a zero vector and $O(m)$ to place the elements. Total $O(n)$.\n    2.  $\\mathcal{F}(v)$: $O(n \\log n)$.\n    3.  $\\overline{\\hat{g}} \\odot \\hat{v}$: $O(n)$.\n    4.  $\\mathcal{F}^{-1}(\\hat{w})$: $O(n \\log n)$.\n    The total complexity, assuming $\\hat{g}$ is pre-computed, is again dominated by the FFTs, resulting in **$O(n \\log n)$**.\n\n**Dense Matrix Approach:**\n-   **Forming the matrix $A$:** The full circulant matrix $C(g)$ has $n^2$ entries. Constructing it takes $O(n^2)$ time. The matrix $A = P C(g)$ is an $m \\times n$ matrix formed by selecting $m$ rows from $C(g)$. This sub-sampling can be done in $O(mn)$ time.\n-   **Computation of $A x$:** This is a multiplication of an $m \\times n$ matrix with an $n \\times 1$ vector. This requires $m$ inner products of length $n$, giving a complexity of **$O(mn)$**.\n-   **Computation of $A^* y$:** The matrix $A^*$ is $n \\times m$. Multiplying it by an $m \\times 1$ vector requires $n$ inner products of length $m$, also leading to a complexity of **$O(mn)$**.\n\n**Comparison:**\nThe FFT-based approach has a complexity of $O(n \\log n)$ for both forward ($A x$) and adjoint ($A^* y$) operations. The dense matrix approach has a complexity of $O(mn)$. The FFT-based method is computationally superior whenever $n \\log n < mn$, which simplifies to $m > \\log n$. In typical compressed sensing scenarios, $m$ is proportional to the sparsity of the signal and the log factors, i.e., $m \\approx k \\log(n/k)$, which is almost always greater than $\\log n$. For large-scale problems where $m$ is not trivially small, the FFT-based routines provide a significant performance advantage, turning a quadratic-time problem (if $m=O(n)$) into a near-linear-time one.",
            "answer": "```python\nimport numpy as np\nfrom scipy.fft import fft, ifft\nfrom scipy.linalg import circulant\n\ndef compute_Ax_fft(g, x, S):\n    \"\"\"Computes A @ x using FFT, where A = P @ C(g).\"\"\"\n    n = g.shape[0]\n    # Step 1: Compute z = C(g) @ x via FFT\n    # This corresponds to circular convolution g * x\n    g_hat = fft(g)\n    x_hat = fft(x)\n    z_hat = g_hat * x_hat\n    z = ifft(z_hat)\n    \n    # Step 2: Apply sampling operator P\n    # Select entries of z at indices S\n    return z[S]\n\ndef compute_A_star_y_fft(g, y, S, n):\n    \"\"\"Computes A.conj().T @ y using FFT, where A = P @ C(g).\"\"\"\n    # Adjoint is A* = C(g)* @ P*\n    \n    # Step 1: Apply P*, which embeds y into a sparse vector of size n\n    v = np.zeros(n, dtype=y.dtype)\n    v[S] = y\n    \n    # Step 2: Apply C(g)*, which is convolution with conj(g_timereversed)\n    # In frequency domain, this is multiplication with conj(fft(g))\n    g_hat = fft(g)\n    v_hat = fft(v)\n    w_hat = np.conj(g_hat) * v_hat\n    w = ifft(w_hat)\n    \n    return w\n\ndef relative_error(u_test, u_ref):\n    \"\"\"\n    Calculates the relative error ||u_test - u_ref|| / ||u_ref||.\n    If ||u_ref|| is 0, returns ||u_test - u_ref||.\n    \"\"\"\n    diff_norm = np.linalg.norm(u_test - u_ref)\n    ref_norm = np.linalg.norm(u_ref)\n    \n    if ref_norm == 0:\n        return diff_norm\n    return diff_norm / ref_norm\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and compute errors.\n    \"\"\"\n    test_cases = [\n        {'n': 64, 'm': 32, 's_type': 'random', 'seed': 0, 'cplx': True, 'sparse_x': False},\n        {'n': 64, 'm': 64, 's_type': 'full', 'seed': 1, 'cplx': False, 'sparse_x': False},\n        {'n': 17, 'm': 1, 's_type': 'single', 'seed': 2, 'cplx': True, 'sparse_x': False},\n        {'n': 50, 'm': 25, 's_type': 'first_m', 'seed': 3, 'cplx': False, 'sparse_x': False},\n        {'n': 128, 'm': 60, 's_type': 'random', 'seed': 4, 'cplx': False, 'sparse_x': True, 'k': 5},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        n, m, seed = case['n'], case['m'], case['seed']\n        rng = np.random.default_rng(seed)\n\n        # Generate index set S\n        if case['s_type'] == 'random':\n            S = rng.choice(n, m, replace=False)\n            S.sort()\n        elif case['s_type'] == 'full':\n            S = np.arange(n)\n        elif case['s_type'] == 'single':\n            S = np.array([5])\n        elif case['s_type'] == 'first_m':\n            S = np.arange(m)\n        \n        # Determine data type\n        dtype = np.complex128 if case['cplx'] else np.float64\n\n        # Generate vectors g, x, y\n        if case['cplx']:\n            g = rng.standard_normal(n) + 1j * rng.standard_normal(n)\n            y = rng.standard_normal(m) + 1j * rng.standard_normal(m)\n            if case.get('sparse_x', False):\n                 k = case['k']\n                 x = np.zeros(n, dtype=dtype)\n                 nonzero_indices = rng.choice(n, k, replace=False)\n                 nonzero_values = rng.standard_normal(k) + 1j * rng.standard_normal(k)\n                 x[nonzero_indices] = nonzero_values\n            else:\n                 x = rng.standard_normal(n) + 1j * rng.standard_normal(n)\n        else:\n            g = rng.standard_normal(n)\n            y = rng.standard_normal(m)\n            if case.get('sparse_x', False):\n                 k = case['k']\n                 x = np.zeros(n, dtype=dtype)\n                 # Use a different seed for x's sparsity pattern for reproducibility as per problem \n                 # (even if seed is the same, this is good practice).\n                 rng_sparse = np.random.default_rng(seed)\n                 nonzero_indices = rng_sparse.choice(n, k, replace=False)\n                 nonzero_values = rng_sparse.standard_normal(k)\n                 x[nonzero_indices] = nonzero_values\n            else:\n                 x = rng.standard_normal(n)\n        \n        # --- FFT-based computation ---\n        ax_fft = compute_Ax_fft(g, x, S)\n        a_star_y_fft = compute_A_star_y_fft(g, y, S, n)\n\n        # --- Dense matrix computation for verification ---\n        C_dense = circulant(g)\n        A_dense = C_dense[S, :]\n        \n        ax_dense = A_dense @ x\n        \n        # Using A_dense.conj().T for A*\n        a_star_y_dense = A_dense.conj().T @ y\n\n        # --- Compare results and compute error ---\n        err_ax = relative_error(ax_fft, ax_dense)\n        err_a_star_y = relative_error(a_star_y_fft, a_star_y_dense)\n        \n        results.append(max(err_ax, err_a_star_y))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Building upon fast operator implementations, this exercise demonstrates their power within a modern optimization framework. You will implement the Alternating Direction Method of Multipliers (ADMM) to solve the constrained Basis Pursuit problem, a cornerstone of sparse recovery theory. The key insight you will explore is how the computationally intensive projection step of ADMM becomes an efficient element-wise operation in the Fourier domain, making the solution of large-scale inverse problems feasible .",
            "id": "3490941",
            "problem": "Consider the constrained Basis Pursuit problem in compressed sensing: minimize the entrywise one-norm of a signal subject to exact linear measurements,\n$$\n\\min_{x \\in \\mathbb{R}^n} \\ \\|x\\|_1 \\quad \\text{subject to} \\quad A x = y,\n$$\nwhere $A \\in \\mathbb{R}^{n \\times n}$ is a real-valued circulant sensing matrix generated by a real kernel $a \\in \\mathbb{R}^n$ via circular convolution. The circulant matrix $A$ represents the linear operator $x \\mapsto a \\star x$ (circular convolution), and is diagonalizable by the Discrete Fourier Transform (DFT). Let $F \\in \\mathbb{C}^{n \\times n}$ denote the unitary DFT matrix with entries\n$$\nF_{k\\ell} = \\frac{1}{\\sqrt{n}} \\exp\\left(-\\mathrm{i} \\frac{2\\pi k \\ell}{n}\\right), \\quad 0 \\le k,\\ell \\le n-1,\n$$\nso that $A$ admits the Fourier diagonalization\n$$\nA = F^{\\ast} \\ \\mathrm{diag}(\\widehat{a}) \\ F,\n$$\nwhere $\\widehat{a} = F a$ is the DFT of $a$ and $F^{\\ast}$ is the conjugate transpose of $F$. This implies $A x = F^{\\ast} \\left( \\widehat{a} \\odot (F x) \\right)$ and $A^{\\top} r = F^{\\ast} \\left( \\overline{\\widehat{a}} \\odot (F r) \\right)$, where $\\odot$ denotes elementwise multiplication and $\\overline{\\widehat{a}}$ is the complex conjugate. Furthermore, $A A^{\\top} = F^{\\ast} \\ \\mathrm{diag}(|\\widehat{a}|^2) \\ F$, so $(A A^{\\top})^{-1}$ is diagonal in the Fourier domain when $|\\widehat{a}|$ has strictly positive entries.\n\nYou are asked to implement the Alternating Direction Method of Multipliers (ADMM) to solve the constrained Basis Pursuit, exploiting the circulant structure to compute updates efficiently using Fast Fourier Transforms (FFTs). Use the splitting\n$$\n\\min_{x,z \\in \\mathbb{R}^n} \\ \\underbrace{I_{\\{u \\in \\mathbb{R}^n : A u = y\\}}(x)}_{f(x)} + \\underbrace{\\|z\\|_1}_{g(z)} \\quad \\text{subject to} \\quad x = z,\n$$\nwhere $I_{\\mathcal{C}}$ is the indicator function of the set $\\mathcal{C}$, and apply ADMM in scaled form with parameter $\\rho > 0$. The fundamental bases to use are:\n- The proximal operator of the one-norm is entrywise soft-thresholding: for $\\lambda > 0$,\n$$\n\\mathrm{prox}_{\\lambda \\|\\cdot\\|_1}(v)_i = \\mathrm{sign}(v_i) \\cdot \\max\\{|v_i| - \\lambda, 0\\}.\n$$\n- The projection onto the affine subspace $\\{x \\in \\mathbb{R}^n : A x = y\\}$ in Euclidean norm is given by\n$$\n\\Pi_{\\{A x = y\\}}(w) = w + A^{\\top} (A A^{\\top})^{-1} (y - A w).\n$$\n- Circulant matrices are diagonalized by the DFT, so products by $A$, $A^{\\top}$, and $(A A^{\\top})^{-1}$ can be computed via FFTs.\n\nDerive from first principles the ADMM updates for $x$, $z$, and the scaled dual variable $u$, showing how each step is computed and why FFTs yield efficient implementations for circulant $A$. In particular, express the $x$-update as the projection onto the affine set using the diagonalization of $A A^{\\top}$ in the Fourier domain, and the $z$-update as soft-thresholding. Clarify the role of the scaled dual variable and the stopping criteria in terms of primal and dual residuals.\n\nThen implement a complete, runnable program that:\n- Constructs circulant matrices implicitly via kernels $a$ and uses FFTs to compute all required linear operations.\n- Solves the constrained Basis Pursuit using ADMM with the described splitting.\n- Uses a small ridge parameter $\\gamma \\ge 0$ in the inversion of $A A^{\\top}$ to handle potential near-singular cases by replacing $(A A^{\\top})^{-1}$ with $(A A^{\\top} + \\gamma I)^{-1}$, which remains diagonal in the Fourier domain.\n- Validates the solution on the following test suite of three cases, each specified by $(n, a, x^{\\star})$ with $y = A x^{\\star}$:\n  1. A general \"happy path\" case: $n = 64$. Choose $a \\in \\mathbb{R}^n$ with independent standard normal entries. Choose $x^{\\star}$ to be $3$-sparse with nonzero entries drawn from a standard normal distribution at random positions. Set $\\gamma = 10^{-12}$ and $\\rho = 1$.\n  2. A boundary case (identity operator): $n = 32$. Let $a = e_1 \\in \\mathbb{R}^n$ (first standard basis vector), which yields $A = I_n$. Choose any $5$-sparse $x^{\\star}$ with nonzero entries drawn from a standard normal distribution at random positions. Set $\\gamma = 0$ and $\\rho = 1$.\n  3. An edge case (near singular spectrum): $n = 64$. Choose $a$ such that $a_0 = 10^{-3}$, $a_1 = 1$, and $a_k = 0$ for $k \\ge 2$. Choose $x^{\\star}$ to be $4$-sparse with nonzero entries drawn from a standard normal distribution at random positions. Set $\\gamma = 10^{-8}$ and $\\rho = 1$.\n\nFor each test case, run ADMM until convergence or a fixed iteration cap. Declare success if and only if both conditions hold:\n- The relative recovery error satisfies\n$$\n\\frac{\\|x^{(K)} - x^{\\star}\\|_2}{\\max\\{\\|x^{\\star}\\|_2, 10^{-12}\\}} \\le 10^{-3},\n$$\nwhere $x^{(K)}$ is the final ADMM estimate.\n- The measurement residual satisfies\n$$\n\\|A x^{(K)} - y\\|_2 \\le 10^{-8}.\n$$\n\nYour program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets (e.g., \"[true_case1,true_case2,true_case3]\"), where each entry is a boolean indicating success for that case. Angles and physical units are not applicable; all quantities are purely mathematical. Do not print anything else besides this single line.",
            "solution": "The problem asks for the derivation and implementation of the Alternating Direction Method of Multipliers (ADMM) to solve the constrained Basis Pursuit problem, leveraging the circulant structure of the sensing matrix $A$ for computational efficiency using the Fast Fourier Transform (FFT).\n\nThe optimization problem is:\n$$\n\\min_{x \\in \\mathbb{R}^n} \\|x\\|_1 \\quad \\text{subject to} \\quad A x = y\n$$\nHere, $A \\in \\mathbb{R}^{n \\times n}$ is a circulant matrix generated by a kernel $a \\in \\mathbb{R}^n$, such that the operation $Ax$ corresponds to the circular convolution $a \\star x$.\n\nTo apply ADMM, we introduce a splitting variable $z \\in \\mathbb{R}^n$ and an auxiliary constraint $x=z$. The problem is reformulated as:\n$$\n\\min_{x,z \\in \\mathbb{R}^n} f(x) + g(z) \\quad \\text{subject to} \\quad x - z = 0\n$$\nwhere $f(x) = I_{\\{u \\in \\mathbb{R}^n : A u = y\\}}(x)$ is the indicator function for the affine set of measurement consistency, and $g(z) = \\|z\\|_1$ is the sparsity-promoting one-norm. The indicator function $I_{\\mathcal{C}}(x)$ is $0$ if $x \\in \\mathcal{C}$ and $+\\infty$ otherwise.\n\nThe scaled-form augmented Lagrangian for this problem, with penalty parameter $\\rho > 0$ and scaled dual variable $u$, is:\n$$\n\\mathcal{L}_{\\rho}(x, z, u) = f(x) + g(z) + \\frac{\\rho}{2} \\|x - z + u\\|_2^2 - \\frac{\\rho}{2} \\|u\\|_2^2\n$$\nADMM proceeds by iteratively minimizing $\\mathcal{L}_{\\rho}$ with respect to $x$ and $z$, followed by an update of the dual variable $u$. The sequence of updates at iteration $k+1$ is:\n1.  $x^{(k+1)} := \\arg\\min_x \\mathcal{L}_{\\rho}(x, z^{(k)}, u^{(k)})$\n2.  $z^{(k+1)} := \\arg\\min_z \\mathcal{L}_{\\rho}(x^{(k+1)}, z, u^{(k)})$\n3.  $u^{(k+1)} := u^{(k)} + x^{(k+1)} - z^{(k+1)}$\n\nWe now derive each update step in detail.\n\n**1. The $x$-update**\n\nThe minimization for $x$ is:\n$$\nx^{(k+1)} = \\arg\\min_x \\left( I_{\\{x : Ax=y\\}}(x) + \\frac{\\rho}{2} \\|x - z^{(k)} + u^{(k)}\\|_2^2 \\right)\n$$\nThis update is equivalent to finding a point $x$ that satisfies the constraint $Ax=y$ while being closest in the Euclidean sense to the vector $w^{(k)} = z^{(k)} - u^{(k)}$. This is precisely the orthogonal projection of $w^{(k)}$ onto the affine subspace $\\mathcal{C} = \\{x \\in \\mathbb{R}^n : A x = y\\}$.\n$$\nx^{(k+1)} = \\Pi_{\\mathcal{C}}(w^{(k)})\n$$\nThe formula for this projection is given as $\\Pi_{\\mathcal{C}}(w) = w + A^{\\top} (A A^{\\top})^{-1} (y - A w)$. To handle potentially singular or ill-conditioned $A A^{\\top}$, a small ridge parameter $\\gamma \\ge 0$ is added, leading to the regularized projection:\n$$\nx^{(k+1)} = w^{(k)} + A^{\\top}(A A^{\\top} + \\gamma I)^{-1}(y - A w^{(k)})\n$$\nThe efficiency of this step comes from the circulant structure of $A$. A circulant matrix is diagonalized by the Discrete Fourier Transform. Let $\\text{fft}(\\cdot)$ and $\\text{ifft}(\\cdot)$ denote the Fast Fourier Transform and its inverse. The circular convolution property states that $a \\star x = \\text{ifft}(\\text{fft}(a) \\odot \\text{fft}(x))$, where $\\odot$ is elementwise multiplication. Let $\\hat{v} = \\text{fft}(v)$.\n-   The action of $A$ is $Ax = \\text{ifft}(\\hat{a} \\odot \\hat{x})$.\n-   The action of the transpose $A^{\\top}$ (which is circulant with a flipped kernel) corresponds to $A^{\\top}r = \\text{ifft}(\\overline{\\hat{a}} \\odot \\hat{r})$, where $\\overline{\\hat{a}}$ is the complex conjugate of $\\hat{a}$.\n-   The operator $AA^{\\top}$ corresponds to multiplication in the Fourier domain by $\\hat{a} \\odot \\overline{\\hat{a}} = |\\hat{a}|^2$.\n-   The operator $(AA^{\\top} + \\gamma I)$ corresponds to multiplication in the Fourier domain by $|\\hat{a}|^2 + \\gamma$.\n-   Consequently, the inverse operator $(AA^{\\top} + \\gamma I)^{-1}$ corresponds to elementwise division in the Fourier domain by $|\\hat{a}|^2 + \\gamma$.\n\nLet $r^{(k)} = y - A w^{(k)}$. The correction term $c^{(k)} = A^{\\top}(A A^{\\top} + \\gamma I)^{-1} r^{(k)}$ can be computed efficiently.\nFirst, apply the inverse operator to $r^{(k)}$: $v^{(k)} = (A A^{\\top} + \\gamma I)^{-1} r^{(k)}$. In the Fourier domain, this is $\\hat{v}^{(k)} = \\hat{r}^{(k)} \\oslash (|\\hat{a}|^2 + \\gamma)$, where $\\oslash$ denotes elementwise division.\nThen, apply $A^\\top$ to $v^{(k)}$: $c^{(k)} = A^\\top v^{(k)}$. In the Fourier domain, this is $\\hat{c}^{(k)} = \\overline{\\hat{a}} \\odot \\hat{v}^{(k)}$.\nCombining these, the Fourier transform of the correction term is:\n$$\n\\hat{c}^{(k)} = \\overline{\\hat{a}} \\odot \\left( \\frac{\\text{fft}(y - A w^{(k)})}{|\\hat{a}|^2 + \\gamma} \\right)\n$$\nThe full $x$-update consists of computing $w^{(k)} = z^{(k)} - u^{(k)}$, then computing $c^{(k)} = \\text{ifft}(\\hat{c}^{(k)})$, and finally setting $x^{(k+1)} = w^{(k)} + c^{(k)}$. Since all input vectors are real, the updated $x^{(k+1)}$ must also be real; any imaginary part is due to numerical noise and should be discarded.\n\n**2. The $z$-update**\n\nThe minimization for $z$ is:\n$$\nz^{(k+1)} = \\arg\\min_z \\left( \\|z\\|_1 + \\frac{\\rho}{2} \\|x^{(k+1)} - z + u^{(k)}\\|_2^2 \\right)\n$$\nRearranging the quadratic term gives:\n$$\nz^{(k+1)} = \\arg\\min_z \\left( \\|z\\|_1 + \\frac{\\rho}{2} \\|z - (x^{(k+1)} + u^{(k)})\\|_2^2 \\right)\n$$\nThis is the definition of the proximal operator of the $\\ell_1$-norm. Specifically, it is $\\mathrm{prox}_{\\frac{1}{\\rho}\\|\\cdot\\|_1}(x^{(k+1)} + u^{(k)})$. The proximal operator of $\\lambda \\|\\cdot\\|_1$ is the elementwise soft-thresholding operator $S_{\\lambda}(v)_i = \\mathrm{sign}(v_i) \\max(|v_i| - \\lambda, 0)$. For our problem, the function is $1 \\cdot \\|\\cdot\\|_1$ and the penalty parameter is $\\rho/2$, which corresponds to a prox-parameter of $1/\\rho$.\nThus, the update is given by entrywise soft-thresholding:\n$$\nz^{(k+1)} = S_{1/\\rho}(x^{(k+1)} + u^{(k)})\n$$\n\n**3. The $u$-update**\n\nThe update for the scaled dual variable $u$ is straightforward:\n$$\nu^{(k+1)} = u^{(k)} + x^{(k+1)} - z^{(k+1)}\n$$\nThis step enforces the constraint $x=z$. The term $x^{(k+1)} - z^{(k+1)}$ is the primal residual at the current iteration.\n\n**Stopping Criteria**\n\nThe convergence of ADMM can be monitored using primal and dual residuals. The primal residual is $r_{\\text{primal}}^{(k+1)} = x^{(k+1)} - z^{(k+1)}$, measuring the violation of the constraint $x-z=0$. The dual residual, $r_{\\text{dual}}^{(k+1)} = \\rho A^\\top A (z^{(k+1)} - z^{(k)})$, measures the change in the dual objective. In practice, a simpler form $r_{\\text{dual}}^{(k+1)} = \\rho(z^{(k+1)} - z^{(k)})$ is often used. The algorithm is considered to have converged when the norms of both residuals fall below certain tolerances. For the present problem, we run the algorithm for a fixed number of iterations and then check the final solution against specified quality criteria.\nThe dual variable $u$ can be interpreted as a running sum of the primal errors, providing an integral-like correction that drives the primal residual to zero.\n\n**Algorithm Summary**\nInitialize $x^{(0)}$, $z^{(0)}$, $u^{(0)}$ (e.g., to zero vectors), and choose $\\rho > 0$, $\\gamma > 0$. For $k=0, 1, 2, \\ldots$\n1.  $w^{(k)} = z^{(k)} - u^{(k)}$\n2.  $r^{(k)} = y - \\text{ifft}(\\hat{a} \\odot \\text{fft}(w^{(k)}))$\n3.  $\\hat{c}^{(k)} = \\overline{\\hat{a}} \\odot \\text{fft}(r^{(k)}) \\oslash (|\\hat{a}|^2 + \\gamma)$\n4.  $c^{(k)} = \\text{ifft}(\\hat{c}^{(k)})$\n5.  $x^{(k+1)} = \\text{real}(w^{(k)} + c^{(k)})$\n6.  $v^{(k)} = x^{(k+1)} + u^{(k)}$\n7.  $z^{(k+1)} = \\text{sign}(v^{(k)}) \\odot \\max(\\text{abs}(v^{(k)}) - 1/\\rho, 0)$\n8.  $u^{(k+1)} = u^{(k)} + x^{(k+1)} - z^{(k+1)}$\nThis iterative process is implemented to solve the given problem.",
            "answer": "```python\nimport numpy as np\nfrom numpy.fft import fft, ifft\n\ndef admm_basis_pursuit(a, y, rho, gamma, max_iter=1000):\n    \"\"\"\n    Solves the constrained Basis Pursuit problem using ADMM.\n\n    min ||x||_1 subject to Ax=y, where A is a circulant matrix.\n\n    Args:\n        a (np.ndarray): The real kernel generating the circulant matrix A.\n        y (np.ndarray): The measurement vector.\n        rho (float): The ADMM penalty parameter.\n        gamma (float): The ridge regularization parameter for matrix inversion.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        np.ndarray: The estimated sparse signal x.\n    \"\"\"\n    n = len(a)\n    \n    # Pre-compute Fourier transform of the kernel and related quantities\n    a_hat = fft(a)\n    a_hat_conj = np.conj(a_hat)\n    a_hat_mag_sq = np.abs(a_hat)**2\n\n    # Denominator for the x-update, pre-computed for efficiency\n    x_update_denom = a_hat_mag_sq + gamma\n\n    # Initialize variables\n    x = np.zeros(n)\n    z = np.zeros(n)\n    u = np.zeros(n)\n\n    # Soft-thresholding lambda\n    lambda_st = 1.0 / rho\n\n    for _ in range(max_iter):\n        # x-update (projection onto {x | Ax=y})\n        w = z - u\n        \n        # Aw = ifft(fft(a) * fft(w))\n        Aw = np.real(ifft(a_hat * fft(w)))\n        \n        # residual r = y - Aw\n        r = y - Aw\n        \n        # FFT of residual\n        r_hat = fft(r)\n        \n        # Correction term in Fourier domain\n        # c_hat = conj(a_hat) * r_hat / (|a_hat|^2 + gamma)\n        c_hat = a_hat_conj * r_hat / x_update_denom\n        \n        # Correction term in signal domain\n        c = np.real(ifft(c_hat))\n        \n        x = w + c\n\n        # z-update (soft-thresholding)\n        v = x + u\n        z = np.sign(v) * np.maximum(np.abs(v) - lambda_st, 0)\n        \n        # u-update (dual variable update)\n        u = u + x - z\n        \n    return x\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    rng = np.random.default_rng(42)  # Seed for reproducibility\n    results = []\n\n    # --- Test Case 1: General \"happy path\" case ---\n    n1 = 64\n    k1 = 3\n    a1 = rng.standard_normal(n1)\n    x_star1 = np.zeros(n1)\n    indices1 = rng.choice(n1, k1, replace=False)\n    x_star1[indices1] = rng.standard_normal(k1)\n    y1 = np.real(ifft(fft(a1) * fft(x_star1)))\n    gamma1 = 1e-12\n    rho1 = 1.0\n\n    x_final1 = admm_basis_pursuit(a1, y1, rho1, gamma1)\n    \n    err_norm1 = np.linalg.norm(x_final1 - x_star1)\n    x_star_norm1 = np.linalg.norm(x_star1)\n    rel_err1 = err_norm1 / max(x_star_norm1, 1e-12)\n    \n    y_final1 = np.real(ifft(fft(a1) * fft(x_final1)))\n    res_norm1 = np.linalg.norm(y_final1 - y1)\n    \n    success1 = rel_err1 <= 1e-3 and res_norm1 <= 1e-8\n    results.append(success1)\n    \n    # --- Test Case 2: Boundary case (identity operator) ---\n    n2 = 32\n    k2 = 5\n    a2 = np.zeros(n2)\n    a2[0] = 1.0  # a = e_1 => A = I\n    x_star2 = np.zeros(n2)\n    indices2 = rng.choice(n2, k2, replace=False)\n    x_star2[indices2] = rng.standard_normal(k2)\n    y2 = np.real(ifft(fft(a2) * fft(x_star2))) # y2 = x_star2\n    gamma2 = 0.0\n    rho2 = 1.0\n    \n    # For A=I, problem is min ||x||_1 s.t. x=y. Solution is x=y.\n    # ADMM should converge very quickly.\n    x_final2 = admm_basis_pursuit(a2, y2, rho2, gamma2, max_iter=20)\n    \n    err_norm2 = np.linalg.norm(x_final2 - x_star2)\n    x_star_norm2 = np.linalg.norm(x_star2)\n    rel_err2 = err_norm2 / max(x_star_norm2, 1e-12)\n    \n    y_final2 = np.real(ifft(fft(a2) * fft(x_final2)))\n    res_norm2 = np.linalg.norm(y_final2 - y2)\n    \n    success2 = rel_err2 <= 1e-3 and res_norm2 <= 1e-8\n    results.append(success2)\n\n    # --- Test Case 3: Edge case (near singular spectrum) ---\n    n3 = 64\n    k3 = 4\n    a3 = np.zeros(n3)\n    a3[0] = 1e-3\n    a3[1] = 1.0\n    x_star3 = np.zeros(n3)\n    indices3 = rng.choice(n3, k3, replace=False)\n    x_star3[indices3] = rng.standard_normal(k3)\n    y3 = np.real(ifft(fft(a3) * fft(x_star3)))\n    gamma3 = 1e-8\n    rho3 = 1.0\n    \n    x_final3 = admm_basis_pursuit(a3, y3, rho3, gamma3, max_iter=2000)\n    \n    err_norm3 = np.linalg.norm(x_final3 - x_star3)\n    x_star_norm3 = np.linalg.norm(x_star3)\n    rel_err3 = err_norm3 / max(x_star_norm3, 1e-12)\n    \n    y_final3 = np.real(ifft(fft(a3) * fft(x_final3)))\n    res_norm3 = np.linalg.norm(y_final3 - y3)\n    \n    success3 = rel_err3 <= 1e-3 and res_norm3 <= 1e-8\n    results.append(success3)\n    \n    # Print results in the specified format\n    print(f\"[{','.join(map(str, results))}]\".lower())\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond exploiting the structure of the sensing matrix, profound efficiencies can be gained by leveraging prior knowledge about the signal itself. This practice investigates the case of periodic signals, whose Fourier transforms are concentrated on a sparse grid of spectral lines. You will discover how this periodicity allows an $n$-dimensional convolution problem to be collapsed into a much smaller $p$-dimensional equivalent through aliasing, enabling exact signal recovery from a drastically reduced number of measurements .",
            "id": "3490928",
            "problem": "Consider a real, length-$n$ discrete signal $x \\in \\mathbb{R}^n$ and a real generating vector $h \\in \\mathbb{R}^n$. Let $C(h) \\in \\mathbb{R}^{n \\times n}$ denote the circulant matrix generated by $h$, so that the measurement vector $y \\in \\mathbb{R}^n$ is given by $y = C(h)\\,x$, which is the circular convolution of $h$ and $x$. Assume that $p$ divides $n$, that $x$ is $p$-periodic (that is, $x[t+p] = x[t]$ for all $t$ modulo $n$), and that $x$ is $s$-sparse within one period (that is, among the $p$ entries $\\{x[0],\\dots,x[p-1]\\}$, at most $s$ entries are nonzero, and the pattern repeats every period). The task is to exploit the structure of Toeplitz and circulant sensing matrices and the spectral implications of periodicity to reduce the number of measurements $m$ while preserving exact support recovery.\n\nThe fundamental base you should use is:\n\n- The definition of circulant matrices and the discrete Fourier transform (DFT): For the $n$-point DFT, let $\\widehat{v}[k] = \\sum_{t=0}^{n-1} v[t] e^{-2\\pi i k t / n}$ and $v[t] = \\frac{1}{n} \\sum_{k=0}^{n-1} \\widehat{v}[k] e^{2\\pi i k t / n}$ for any $v \\in \\mathbb{C}^n$.\n- Circulant diagonalization: $C(h) = F_n^* \\,\\mathrm{diag}(\\widehat{h})\\, F_n$, where $F_n$ is the unitary $n$-point DFT matrix up to normalization conventions.\n- Periodicity-spectral line relation: If $x$ is $p$-periodic with $p$ dividing $n$, then $\\widehat{x}[k]$ is supported only on spectral indices $k$ that are integer multiples of $L = n/p$.\n- Aliasing by period folding: When one restricts a circular convolution with a $p$-periodic input to one period, the effective convolution kernel is the $p$-length alias-fold of $h$ defined by $h_p[r] = \\sum_{q=0}^{L-1} h[r + q p]$ for $r \\in \\{0,\\dots,p-1\\}$.\n\nFrom these bases, you must derive and implement a detection-and-recovery method that:\n\n- Uses only $m = p$ time-domain measurements of $y$, specifically the first $p$ entries $y[0],\\dots,y[p-1]$ (one full period of $y$), exploiting that if $x$ is $p$-periodic then $y$ is also $p$-periodic.\n- Constructs $h_p \\in \\mathbb{R}^p$ by alias-folding $h$ over cosets modulo $p$ via $h_p[r] = \\sum_{q=0}^{L-1} h[r + q p]$ with $L = n/p$.\n- Recovers the period pattern $x_{\\mathrm{per}} \\in \\mathbb{R}^p$ from the length-$p$ circular convolution relation between $h_p$ and the first-period measurements of $y$, using only the core principles above and without assuming any formula beyond them.\n- Identifies the exact support of $x$ over $\\{0,\\dots,n-1\\}$ by recovering the support in one period and replicating it across all periods.\n\nYou must show why this works from first principles: explain why $y[0],\\dots,y[p-1]$ equal the $p$-point circular convolution of $h_p$ with the period pattern $x_{\\mathrm{per}}$, and why deconvolution in the $p$-point DFT domain yields exact support whenever the $p$-point DFT of $h_p$ is nonzero on all indices corresponding to the spectral lines at multiples of $L = n/p$ (which, for real-valued $x_{\\mathrm{per}}$, reduces to entrywise nonzero $\\widehat{h_p}$ to ensure invertibility). You must also justify how this reduces the number of required measurements from a naive $m = n$ to $m = p$ with no loss in support accuracy under the stated noiseless conditions.\n\nImplementation requirements:\n\n- For each test case, synthesize $x$ and $h$ as follows:\n  - Draw the period support uniformly at random among all $s$-subsets of $\\{0,\\dots,p-1\\}$.\n  - Draw nonzero amplitudes independently from a continuous distribution supported away from zero (for example, a uniform distribution on an interval not containing zero, with random signs). Replicate the $p$-length period to length $n$.\n  - Draw $h$ with independent entries from a continuous distribution (for example, standard normal). If the $p$-point DFT of $h_p$ has any entry whose magnitude is closer to zero than a small tolerance, you may redraw $h$ to avoid numerical degeneracy.\n- Compute $y = C(h) x$ by circular convolution of length $n$ and then keep only the first $p$ entries.\n- Recover the period pattern $x_{\\mathrm{per}}$ using only these $p$ measurements and $h_p$. Identify the support over one period by thresholding very small numerical residuals, and replicate the support across all $n$ indices.\n- Return a boolean indicating whether the recovered full support exactly matches the ground-truth support.\n\nYour program must implement the above pipeline for the following test suite of parameter quadruples $(n,p,s,\\mathrm{seed})$:\n\n- Test A: $(n,p,s,\\mathrm{seed}) = (256,8,3,12345)$.\n- Test B: $(n,p,s,\\mathrm{seed}) = (180,9,4,54321)$.\n- Test C (boundary $p$): $(n,p,s,\\mathrm{seed}) = (128,1,1,111)$.\n- Test D (full-period support): $(n,p,s,\\mathrm{seed}) = (96,6,6,2222)$.\n- Test E: $(n,p,s,\\mathrm{seed}) = (210,7,2,3333)$.\n\nAll signals are real-valued and noiseless. Angles, if any appear in internal DFT computations, are in radians, but the outputs are booleans and therefore unitless.\n\nFinal output format requirement:\n\n- Your program should produce a single line of output containing the results for Tests A through E as a comma-separated list enclosed in square brackets, in order, where each entry is a boolean indicating exact support match for that test (for example, $[\\text{True},\\text{False},\\text{True},\\text{True},\\text{True}]$). No other text should be printed.",
            "solution": "The core of the problem is to recover a real, length-$n$ signal $x \\in \\mathbb{R}^n$ from a single period of its circular convolution with a known kernel $h \\in \\mathbb{R}^n$, i.e., $y = C(h)x$, by exploiting the fact that $x$ is $p$-periodic, where $p$ is a divisor of $n$. The signal $x$ is also known to be $s$-sparse within each period. We are given the measurements $y[0], \\dots, y[p-1]$.\n\nFirst, we establish that the measurement vector $y$ is also $p$-periodic. The circular convolution is defined as $y[t] = \\sum_{k=0}^{n-1} h[k] x[(t-k) \\pmod n]$. To check for periodicity, we evaluate $y[t+p]$:\n$$ y[t+p] = \\sum_{k=0}^{n-1} h[k] x[((t+p)-k) \\pmod n] $$\nSince $x$ is $p$-periodic, $x[j+p] = x[j]$ for any index $j$ (modulo $n$). Thus, $x[((t-k)+p) \\pmod n] = x[(t-k) \\pmod n]$. Substituting this back, we get:\n$$ y[t+p] = \\sum_{k=0}^{n-1} h[k] x[(t-k) \\pmod n] = y[t] $$\nThis confirms that $y$ is $p$-periodic. Consequently, all unique information about $y$ is contained in its first period, $\\{y[0], y[1], \\dots, y[p-1]\\}$. This justifies the reduction in the number of required measurements from $m=n$ to $m=p$, as the remaining $n-p$ measurements are redundant. Let us denote this single period of measurements as $y_{\\mathrm{per}} \\in \\mathbb{R}^p$, where $y_{\\mathrm{per}}[r] = y[r]$ for $r \\in \\{0, \\dots, p-1\\}$. Similarly, let $x_{\\mathrm{per}} \\in \\mathbb{R}^p$ be the repeating pattern of $x$, such that $x[t] = x_{\\mathrm{per}}[t \\pmod p]$.\n\nOur next step is to derive the relationship between $y_{\\mathrm{per}}$, $x_{\\mathrm{per}}$, and $h$. For any $r \\in \\{0, \\dots, p-1\\}$, the measurement $y[r]$ is:\n$$ y[r] = \\sum_{k=0}^{n-1} h[k] x[(r-k) \\pmod n] $$\nUsing the periodicity of $x$, we have $x[(r-k) \\pmod n] = x_{\\mathrm{per}}[(r-k) \\pmod p]$. The expression becomes:\n$$ y[r] = \\sum_{k=0}^{n-1} h[k] x_{\\mathrm{per}}[(r-k) \\pmod p] $$\nWe can group the summation over the index $k$ by its value modulo $p$. Let $L=n/p$. We can express any $k \\in \\{0, \\dots, n-1\\}$ uniquely as $k = j + qp$ where $j \\in \\{0, \\dots, p-1\\}$ and $q \\in \\{0, \\dots, L-1\\}$. Substituting this into the summation gives:\n$$ y[r] = \\sum_{j=0}^{p-1} \\sum_{q=0}^{L-1} h[j+qp] x_{\\mathrm{per}}[(r-(j+qp)) \\pmod p] $$\nThe index for $x_{\\mathrm{per}}$ simplifies, as $(r - j - qp) \\pmod p = (r - j) \\pmod p$. The term no longer depends on the inner summation index $q$:\n$$ y[r] = \\sum_{j=0}^{p-1} \\sum_{q=0}^{L-1} h[j+qp] x_{\\mathrm{per}}[(r-j) \\pmod p] $$\nSwapping the order of summation is now possible:\n$$ y[r] = \\sum_{j=0}^{p-1} \\left( \\sum_{q=0}^{L-1} h[j+qp] \\right) x_{\\mathrm{per}}[(r-j) \\pmod p] $$\nWe recognize the term in parentheses as the alias-folded kernel, as defined in the problem statement. Let $h_p \\in \\mathbb{R}^p$ be this folded kernel, where its $j$-th element is $h_p[j] = \\sum_{q=0}^{L-1} h[j+qp]$. The equation simplifies to:\n$$ y[r] = \\sum_{j=0}^{p-1} h_p[j] x_{\\mathrm{per}}[(r-j) \\pmod p] $$\nThis is precisely the definition of the $p$-point circular convolution of $h_p$ and $x_{\\mathrm{per}}$. In vector notation, this is $y_{\\mathrm{per}} = C_p(h_p) x_{\\mathrm{per}}$, where $C_p$ denotes a $p \\times p$ circulant matrix.\n\nTo recover $x_{\\mathrm{per}}$, we leverage the convolution theorem of the Discrete Fourier Transform (DFT). Let $\\widehat{v}$ denote the $p$-point DFT of a vector $v \\in \\mathbb{R}^p$. Applying the DFT to the convolution equation yields:\n$$ \\widehat{y_{\\mathrm{per}}}[k] = \\widehat{h_p}[k] \\cdot \\widehat{x_{\\mathrm{per}}}[k] $$\nfor each frequency index $k \\in \\{0, \\dots, p-1\\}$. We can solve for the DFT of the unknown signal pattern, $\\widehat{x_{\\mathrm{per}}}$:\n$$ \\widehat{x_{\\mathrm{per}}}[k] = \\frac{\\widehat{y_{\\mathrm{per}}}[k]}{\\widehat{h_p}[k]} $$\nThis deconvolution step is well-defined provided that $\\widehat{h_p}[k] \\neq 0$ for all $k$. Since the entries of the original kernel $h$ are drawn from a continuous distribution, the probability of any $\\widehat{h_p}[k]$ being exactly zero is negligible. The problem allows for redrawing $h$ if any of these values are numerically too close to zero, ensuring the invertibility of the operation.\n\nOnce $\\widehat{x_{\\mathrm{per}}}$ is calculated, we can recover the time-domain signal pattern $x_{\\mathrm{per}}$ by applying the inverse $p$-point DFT:\n$$ x_{\\mathrm{per}} = \\mathrm{IDFT}_p(\\widehat{x_{\\mathrm{per}}}) $$\nThis recovers the repeating pattern $x_{\\mathrm{per}}$ exactly, under the stated noiseless conditions. The sparsity of $x_{\\mathrm{per}}$ is not required for this deconvolution method to work, but it is the structural property that often motivates such problems in compressed sensing.\n\nFinally, we recover the support of the full signal $x$. The support of the period, $S_{\\mathrm{per}}$, is the set of indices $j \\in \\{0, \\dots, p-1\\}$ where $|x_{\\mathrm{per}}[j]|$ is greater than a small numerical tolerance. The full support of $x$ over $\\{0, \\dots, n-1\\}$ is then constructed by replicating this period support across all $L=n/p$ blocks:\n$$ S_x = \\{ j + qp \\mid j \\in S_{\\mathrm{per}}, q \\in \\{0, \\dots, L-1\\} \\} $$\nThis procedure guarantees exact support recovery with only $p$ measurements, demonstrating a significant reduction in sampling complexity by exploiting the signal's periodic structure.\n\nThe algorithm to be implemented is as follows:\n1.  Synthesize the ground truth signal $x \\in \\mathbb{R}^n$ and kernel $h \\in \\mathbb{R}^n$ according to the problem specification. This includes ensuring $h$ leads to a well-conditioned deconvolution.\n2.  Compute the full measurement vector $y = C(h)x$ using $n$-point circular convolution and retain only the first $p$ entries, $y_{\\mathrm{per}}$.\n3.  Compute the alias-folded kernel $h_p$ from $h$.\n4.  Perform deconvolution in the $p$-point DFT domain to find the recovered pattern $x_{\\mathrm{per,rec}}$.\n5.  Determine the support of the recovered pattern by thresholding small values.\n6.  Construct the full recovered support by periodic extension.\n7.  Compare the recovered support with the ground truth support and return a boolean indicating an exact match.",
            "answer": "```python\nimport numpy as np\n\ndef run_test_case(n: int, p: int, s: int, seed: int) -> bool:\n    \"\"\"\n    Runs a single test case for the periodic signal recovery problem.\n\n    Args:\n        n: The total signal length.\n        p: The period length.\n        s: The number of non-zero elements per period (sparsity).\n        seed: The random seed for reproducibility.\n\n    Returns:\n        A boolean indicating whether the recovered support exactly matches the true support.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    L = n // p\n    TOLERANCE = 1e-9\n\n    # 1. Generate the ground truth signal x\n    # The support is 's' random indices within one period.\n    period_support = rng.choice(p, size=s, replace=False)\n    \n    # Amplitudes are drawn from a standard normal distribution.\n    x_per = np.zeros(p)\n    if s > 0:\n        x_per[period_support] = rng.standard_normal(s)\n    \n    # Replicate the period 'L' times to create the full signal x.\n    x = np.tile(x_per, L)\n    \n    # Determine the true support set for comparison later.\n    if s > 0:\n        true_support_set = set((period_support[:, None] + np.arange(L) * p).flatten())\n    else:\n        true_support_set = set()\n\n    # 2. Generate the sensing kernel h and the folded kernel h_p\n    # We must ensure that the DFT of h_p has no zero entries for deconvolution.\n    h_p_dft = None\n    while True:\n        # h has i.i.d. standard normal entries.\n        h = rng.standard_normal(n)\n        \n        # Compute the alias-folded kernel h_p.\n        # h.reshape((L, p)) groups h into L rows of p elements.\n        # Summing along axis 0 gives h_p[j] = sum_q h[j + q*p].\n        h_p = np.sum(h.reshape((L, p)), axis=0)\n        \n        # Compute the p-point DFT of h_p.\n        h_p_dft = np.fft.fft(h_p)\n        \n        # Check if any DFT coefficient is too close to zero. If not, break.\n        if np.all(np.abs(h_p_dft) > TOLERANCE):\n            break\n        # Otherwise, redraw h and try again.\n\n    # 3. Simulate the measurement process\n    # y is the n-point circular convolution of h and x.\n    y_full = np.real(np.fft.ifft(np.fft.fft(h) * np.fft.fft(x)))\n    \n    # We only use the first p measurements.\n    y_per = y_full[:p]\n\n    # 4. Recover the period pattern x_per\n    # Compute the p-point DFT of the measurements.\n    y_per_dft = np.fft.fft(y_per)\n    \n    # Perform deconvolution in the frequency domain.\n    x_per_rec_dft = y_per_dft / h_p_dft\n    \n    # Invert the DFT to get the recovered time-domain pattern.\n    x_per_rec = np.real(np.fft.ifft(x_per_rec_dft))\n    \n    # 5. Identify the support and compare\n    # Find the support of the recovered pattern by thresholding.\n    rec_period_support = np.where(np.abs(x_per_rec) > TOLERANCE)[0]\n    \n    # Replicate the period support to get the full recovered support.\n    if rec_period_support.size > 0:\n        rec_full_support_set = set((rec_period_support[:, None] + np.arange(L) * p).flatten())\n    else:\n        rec_full_support_set = set()\n\n    # Return True if the recovered support exactly matches the true support.\n    return rec_full_support_set == true_support_set\n\n\ndef solve():\n    \"\"\"\n    Main function to execute the test suite and print results.\n    \"\"\"\n    # Test cases: (n, p, s, seed)\n    test_cases = [\n        (256, 8, 3, 12345),   # Test A\n        (180, 9, 4, 54321),   # Test B\n        (128, 1, 1, 111),     # Test C (boundary p=1)\n        (96, 6, 6, 2222),     # Test D (full-period support s=p)\n        (210, 7, 2, 3333),     # Test E\n    ]\n\n    results = []\n    for case in test_cases:\n        n, p, s, seed = case\n        is_match = run_test_case(n, p, s, seed)\n        results.append(is_match)\n\n    # Print results in the required format: [True,True,False,...]\n    print(f\"[{','.join(map(str, results))}]\".lower())\n\nsolve()\n```"
        }
    ]
}