{
    "hands_on_practices": [
        {
            "introduction": "FISTA 理论上的 $O(1/k^2)$ 收敛速度为其性能提供了强有力的保证。第一个练习将这个抽象的界限具体化，要求你为一个给定的 LASSO 问题计算达到期望精度所需的具体迭代次数。通过计算 Lipschitz 常数 $L$ 和到最优解的距离，你将亲身体验如何在实际场景中应用收敛速度公式 。",
            "id": "3439140",
            "problem": "考虑压缩感知中的复合凸优化问题\n$$\nF(x) \\equiv f(x) + g(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2} + \\lambda \\|x\\|_{1},\n$$\n其中 $A \\in \\mathbb{R}^{3 \\times 3}$，$b \\in \\mathbb{R}^{3}$，$\\lambda  0$，$f$ 是一个梯度利普希茨连续的凸函数，$g$ 是一个具有可计算近端算子的正常、闭、凸函数。假设使用快速迭代收缩阈值算法（FISTA）来解决此问题，采用标准常数步长 $1/L$ 和精确的近端算子求值，其中 $L$ 是 $\\nabla f$ 的利普希茨常数。\n\n使用以下数据：\n- $A = \\operatorname{diag}(5, 3, 1)$，\n- $b = (0, 0, 0)^{\\top}$，\n- $\\lambda = 1$，\n- 初始点 $x_{0} = (3, 4, 0)^{\\top}$。\n\n假设在 $f$ 的 $L$-平滑性和 $g$ 的凸性条件下，复合凸最小化问题的标准FISTA收敛速率成立，推导出一个显式迭代预算，以保证目标间隙满足 $F(x_{k}) - F(x^{\\star}) \\le \\epsilon$（对于给定的容差 $\\epsilon$），然后计算当容差 $\\epsilon = 2 \\times 10^{-2}$ 时的最小整数 $k$。\n\n将您的最终答案以单个整数形式提供。除了取满足保证的最小整数外，不需要进行四舍五入。",
            "solution": "首先验证该问题，以确保其科学基础扎实、适定且客观。\n\n### 步骤 1：提取已知条件\n- **优化问题**：最小化 $F(x) = f(x) + g(x)$，其中 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 且 $g(x) = \\lambda \\|x\\|_{1}$。\n- **定义域**：$A \\in \\mathbb{R}^{3 \\times 3}$，$b \\in \\mathbb{R}^{3}$。\n- **算法**：快速迭代收缩阈值算法（FISTA），步长为 $1/L$。\n- **数据**：\n    - $A = \\operatorname{diag}(5, 3, 1)$\n    - $b = (0, 0, 0)^{\\top}$\n    - $\\lambda = 1$\n    - 初始点：$x_{0} = (3, 4, 0)^{\\top}$\n- **性质**：$f(x)$ 是一个梯度为 $L$-利普希茨连续的凸函数。$g(x)$ 是一个正常、闭、凸函数。\n- **任务**：\n    1.  推导一个显式迭代预算 $k$，以保证 $F(x_{k}) - F(x^{\\star}) \\le \\epsilon$。\n    2.  计算当容差为 $\\epsilon = 2 \\times 10^{-2}$ 时所需的最小整数 $k$。\n\n### 步骤 2：使用提取的已知条件进行验证\n- **科学基础**：该问题描述了 LASSO 目标函数，它是压缩感知和稀疏回归的基石。FISTA 是解决此类问题的标准、可证明收敛的算法。FISTA 的收敛速率是凸优化理论中的一个经典结果。该问题在科学和数学上是合理的。\n- **适定性**：该问题提供了确定 FISTA 收敛速率公式中所有量的必要信息。利普希茨常数 $L$ 可以从 $A$ 推导得出。最优解 $x^\\star$ 可以从给定数据中唯一确定。任务是应用一个已知的理论界，这是一个定义明确的数学练习。\n- **客观性**：问题以精确的数学术语陈述，没有歧义或主观论断。\n\n### 步骤 3：结论与行动\n该问题是有效的，因为它是优化领域一个成熟理论结果的标准应用。我们继续进行求解。\n\n### 详细解答\n\n问题是求 FISTA 保证目标函数值差距至多为 $\\epsilon$ 所需的最小迭代次数 $k$。目标函数为 $F(x) = f(x) + g(x)$，其中 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 且 $g(x) = \\lambda \\|x\\|_{1}$。\n\n应用于此复合问题的 FISTA 的标准收敛速率表明，迭代序列 $\\{x_k\\}$ 满足：\n$$\nF(x_{k}) - F(x^{\\star}) \\le \\frac{2L \\|x_0 - x^{\\star}\\|_2^2}{(k+1)^2}\n$$\n其中 $x^{\\star}$ 是 $F(x)$ 的一个最小化子，$x_0$ 是初始点，$L$ 是光滑部分梯度 $\\nabla f(x)$ 的利普希茨常数。\n\n为了找到迭代预算，我们需要计算 $L$，$x^{\\star}$ 和 $\\|x_0 - x^{\\star}\\|_2^2$。\n\n**1. 计算利普希茨常数 $L$**\n$f(x)$ 的梯度是 $\\nabla f(x) = A^{\\top}(Ax - b)$。海森矩阵是 $\\nabla^2 f(x) = A^{\\top}A$。$\\nabla f(x)$ 的利普希茨常数 $L$ 是海森矩阵的最大特征值，即 $L = \\lambda_{\\max}(A^{\\top}A)$。\n给定 $A = \\operatorname{diag}(5, 3, 1)$，$A$ 是一个对称矩阵，因此 $A^{\\top} = A$。\n$$\nA^{\\top}A = A^2 = (\\operatorname{diag}(5, 3, 1))^2 = \\operatorname{diag}(5^2, 3^2, 1^2) = \\operatorname{diag}(25, 9, 1)\n$$\n对角矩阵的特征值是其对角线上的元素。因此，最大特征值为 $\\lambda_{\\max}(A^{\\top}A) = 25$。\n因此，利普希茨常数是 $L = 25$。\n\n**2. 找到最优解 $x^{\\star}$**\n目标函数是 $F(x) = \\frac{1}{2}\\|Ax - b\\|_{2}^{2} + \\lambda \\|x\\|_{1}$。\n根据给定数据，$b = (0, 0, 0)^{\\top}$ 且 $\\lambda=1$，函数变为：\n$$\nF(x) = \\frac{1}{2}\\|Ax\\|_{2}^{2} + \\|x\\|_{1}\n$$\n项 $f(x) = \\frac{1}{2}\\|Ax\\|_{2}^{2}$ 是非负的。由于 $A = \\operatorname{diag}(5, 3, 1)$ 是可逆的，所以 $Ax=0$ 当且仅当 $x=0$。因此，$f(x) \\ge 0$，且仅在 $x=0$ 时取等号。\n项 $g(x) = \\|x\\|_{1}$ 也是非负的，且 $g(x)=0$ 当且仅当 $x=0$。\n因此，和 $F(x) = f(x) + g(x)$ 是非负的，并且它等于 $0$ 当且仅当两项都为零，这唯一地发生在 $x=0$ 时。\n所以，最小化子是 $x^{\\star} = (0, 0, 0)^{\\top}$，最小目标值为 $F(x^{\\star}) = 0$。\n\n**3. 计算初始距离 $\\|x_0 - x^{\\star}\\|_2^2$**\n初始点给定为 $x_0 = (3, 4, 0)^{\\top}$，并且我们已经求得 $x^{\\star} = (0, 0, 0)^{\\top}$。\n欧几里得距离的平方是：\n$$\n\\|x_0 - x^{\\star}\\|_2^2 = \\|(3, 4, 0)^{\\top} - (0, 0, 0)^{\\top}\\|_2^2 = \\|(3, 4, 0)^{\\top}\\|_2^2 = 3^2 + 4^2 + 0^2 = 9 + 16 = 25\n$$\n\n**4. 推导显式迭代预算并计算 $k$**\n我们需要迭代次数 $k$ 满足 $F(x_k) - F(x^\\star) \\le \\epsilon$。使用 FISTA 的收敛保证，我们需要满足：\n$$\n\\frac{2L \\|x_0 - x^{\\star}\\|_2^2}{(k+1)^2} \\le \\epsilon\n$$\n重新整理这个不等式以求解 $k$ 得到显式迭代预算：\n$$\n(k+1)^2 \\ge \\frac{2L \\|x_0 - x^{\\star}\\|_2^2}{\\epsilon}\n$$\n$$\nk+1 \\ge \\sqrt{\\frac{2L \\|x_0 - x^{\\star}\\|_2^2}{\\epsilon}}\n$$\n$$\nk \\ge \\sqrt{\\frac{2L \\|x_0 - x^{\\star}\\|_2^2}{\\epsilon}} - 1\n$$\n这是一般迭代预算的表达式。现在我们代入问题的具体数值：$L=25$，$\\|x_0 - x^{\\star}\\|_2^2=25$，以及 $\\epsilon = 2 \\times 10^{-2}$。\n$$\nk \\ge \\sqrt{\\frac{2 \\times 25 \\times 25}{2 \\times 10^{-2}}} - 1\n$$\n$$\nk \\ge \\sqrt{\\frac{25^2}{10^{-2}}} - 1\n$$\n$$\nk \\ge \\sqrt{625 \\times 100} - 1\n$$\n$$\nk \\ge \\sqrt{62500} - 1\n$$\n$$\nk \\ge 250 - 1\n$$\n$$\nk \\ge 249\n$$\n问题要求满足此条件的最小整数 $k$。大于或等于 $249$ 的最小整数是 $249$。\n因此，需要最少 $k=249$ 次迭代来保证目标间隙小于或等于 $2 \\times 10^{-2}$。",
            "answer": "$$\\boxed{249}$$"
        },
        {
            "introduction": "为什么 FISTA 被认为是一种“加速”方法？本练习通过将 FISTA 与其非加速的对应算法 ISTA 进行比较，深入探讨了这个问题。你将推导控制两种算法收敛速度的显式常数，从而精确地揭示 Nesterov 动量如何转化为更快的 $O(1/k^2)$ 收敛速度，而 ISTA 的收敛速度则较慢，为 $O(1/k)$ 。这个练习将巩固你对 FISTA 效率来源的理解。",
            "id": "3439144",
            "problem": "考虑写成复合凸函数形式的最小绝对收缩和选择算子 (Lasso) 目标函数 $F(x) = g(x) + h(x)$，其中 $g(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$，$h(x) = \\lambda \\|x\\|_{1}$ 且 $\\lambda  0$。设梯度 $\\nabla g$ 是 $L$-利普希茨连续的，其中 $L = \\|A\\|_{2}^{2}$，$\\|A\\|_{2}$ 表示 $A$ 的谱范数（最大奇异值）。迭代收缩阈值算法 (ISTA) 使用步长为 $1/L$ 的近端梯度更新，而快速迭代收缩阈值算法 (FISTA) 使用 Nesterov 型外推法和规范的惯性参数序列来加速 ISTA。\n\n请仅从凸性、梯度利普希茨连续性的基本定义以及近端算子的性质出发，为以下界限推导显式常数：\n$$F(x_{k}) - F(x^{\\star}) \\leq \\frac{C_{\\mathrm{ISTA}}}{k} \\quad \\text{以及} \\quad F(x_{k}) - F(x^{\\star}) \\leq \\frac{C_{\\mathrm{FISTA}}}{(k+1)^{2}}，$$\n这两个界限分别对应于在同一 Lasso 实例上使用步长 $1/L$ 的 ISTA 和 FISTA。您的推导必须明确地用 $L$ 和 $\\|x_{0} - x^{\\star}\\|_{2}^{2}$ 表示常数 $C_{\\mathrm{ISTA}}$ 和 $C_{\\mathrm{FISTA}}$，其中 $x_{0}$ 是初始迭代点，$x^{\\star}$ 是 $F$ 的任意一个极小点。\n\n然后，在以下具体实例上计算这些常数的值：\n$$A = \\begin{pmatrix} 3  0  0 \\\\ 0  1  0 \\\\ 0  0  2 \\end{pmatrix}, \\quad b = 0, \\quad \\lambda  0, \\quad x_{0} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\end{pmatrix}.$$\n计算此实例的 $L = \\|A\\|_{2}^{2}$ 和比率 $C_{\\mathrm{FISTA}} / C_{\\mathrm{ISTA}}$。将该比率作为最终答案。如果您需要近似任何中间量，请不要这样做；在整个过程中使用精确算术。最终答案必须是一个实数。",
            "solution": "所述问题是有效的。它在科学上基于成熟的凸优化理论，特别是一阶复合函数方法。该问题是适定的、客观的，并包含了推导常数和计算其比率所需的所有必要信息。\n\n总体目标函数为 $F(x) = g(x) + h(x)$，其中 $g(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 是凸函数且其梯度 $\\nabla g(x) = A^T(Ax-b)$ 是 $L$-利普希茨连续的，而 $h(x) = \\lambda \\|x\\|_{1}$ 是凸函数但不可微。梯度的利普希茨常数为 $L = \\|A^T A\\|_2 = \\|A\\|_2^2$。$F$ 的极小点记为 $x^\\star$。\n\n**第一部分：ISTA 收敛速率常数的推导**\n\n迭代收缩阈值算法 (ISTA) 是一种近端梯度法。对于步长 $\\alpha$，其更新规则为：\n$$x_{k+1} = \\mathrm{prox}_{\\alpha h}(x_k - \\alpha \\nabla g(x_k))$$\n问题指定步长为 $\\alpha = 1/L$。\n收敛速率的推导依赖于一个我们首先要建立的关键不等式。\n根据定义，具有 $L$-利普希茨梯度的函数 $g$ 满足下降引理：对于任意 $x, y$，\n$$g(y) \\leq g(x) + \\langle \\nabla g(x), y-x \\rangle + \\frac{L}{2} \\|y-x\\|_{2}^{2}$$\n设 $x_k$ 为当前迭代点，$x_{k+1}$ 为 ISTA 以 $\\alpha = 1/L$ 生成的下一个迭代点。\n在下降引理中令 $x=x_k$ 和 $y=x_{k+1}$，我们有：\n$$g(x_{k+1}) \\leq g(x_k) + \\langle \\nabla g(x_k), x_{k+1}-x_k \\rangle + \\frac{L}{2} \\|x_{k+1}-x_k\\|_{2}^{2}$$\n近端算子更新 $x_{k+1} = \\mathrm{prox}_{h/L}(x_k - \\frac{1}{L} \\nabla g(x_k))$ 是函数 $u \\mapsto \\frac{L}{2} \\|u - (x_k - \\frac{1}{L} \\nabla g(x_k))\\|_2^2 + h(u)$ 的唯一极小点。\n$x_{k+1}$ 的最优性条件是 $0 \\in \\partial h(x_{k+1}) + L(x_{k+1} - (x_k - \\frac{1}{L} \\nabla g(x_k)))$，化简后得到\n$$L(x_k - x_{k+1}) - \\nabla g(x_k) \\in \\partial h(x_{k+1})$$\n令 $\\xi_{k+1} = L(x_k - x_{k+1}) - \\nabla g(x_k)$ 为 $\\partial h(x_{k+1})$ 中的这个次梯度。根据凸函数 $h$ 的次梯度定义，对于任意点 $y$：\n$$h(y) \\geq h(x_{k+1}) + \\langle \\xi_{k+1}, y-x_{k+1} \\rangle = h(x_{k+1}) + \\langle L(x_k - x_{k+1}) - \\nabla g(x_k), y-x_{k+1} \\rangle$$\n整理可得：\n$$h(x_{k+1}) \\leq h(y) - \\langle L(x_k - x_{k+1}) - \\nabla g(x_k), y-x_{k+1} \\rangle$$\n现在，考虑总函数值 $F(x_{k+1}) = g(x_{k+1}) + h(x_{k+1})$。\n$$F(x_{k+1}) \\leq \\left( g(x_k) + \\langle \\nabla g(x_k), x_{k+1}-x_k \\rangle + \\frac{L}{2} \\|x_{k+1}-x_k\\|_{2}^{2} \\right) + \\left( h(y) - \\langle L(x_k - x_{k+1}) - \\nabla g(x_k), y-x_{k+1} \\rangle \\right)$$\n$$F(x_{k+1}) \\leq g(x_k) + h(y) + \\langle \\nabla g(x_k), y-x_k \\rangle + \\frac{L}{2} \\|x_{k+1}-x_k\\|_{2}^{2} - L\\langle x_k - x_{k+1}, y-x_{k+1} \\rangle$$\n项 $\\langle x_k - x_{k+1}, y-x_{k+1} \\rangle$ 可以使用恒等式 $2\\langle a,b \\rangle = \\|a\\|^2+\\|b\\|^2-\\|a-b\\|^2$ 展开，其中 $a=x_k-x_{k+1}$，$b=y-x_{k+1}$。我们得到 $2\\langle x_k - x_{k+1}, y-x_{k+1} \\rangle = \\|x_k-x_{k+1}\\|^2 + \\|y-x_{k+1}\\|^2 - \\|x_k-y\\|^2$。\n代入此式：\n$$F(x_{k+1}) \\leq g(x_k) + h(y) + \\langle \\nabla g(x_k), y-x_k \\rangle + \\frac{L}{2} \\|x_{k+1}-x_k\\|_{2}^{2} - \\frac{L}{2} \\left( \\|x_k-x_{k+1}\\|^2 + \\|y-x_{k+1}\\|^2 - \\|x_k-y\\|^2 \\right)$$\n$$F(x_{k+1}) \\leq g(x_k) + \\langle \\nabla g(x_k), y-x_k \\rangle + h(y) + \\frac{L}{2} \\left( \\|x_k-y\\|^2 - \\|x_{k+1}-y\\|^2 \\right)$$\n根据 $g$ 的凸性，我们有 $g(y) \\geq g(x_k) + \\langle \\nabla g(x_k), y-x_k \\rangle$。因此，$g(x_k) + \\langle \\nabla g(x_k), y-x_k \\rangle \\leq g(y)$。\n$$F(x_{k+1}) \\leq g(y) + h(y) + \\frac{L}{2} \\left( \\|x_k-y\\|^2 - \\|x_{k+1}-y\\|^2 \\right)$$\n这个不等式对任意 $y$ 都成立。我们选择 $y=x^\\star$，即 $F$ 的一个极小点。\n$$F(x_{k+1}) - F(x^\\star) \\leq \\frac{L}{2} \\left( \\|x_k-x^\\star\\|_2^2 - \\|x_{k+1}-x^\\star\\|_2^2 \\right)$$\n令 $\\delta_k = F(x_k) - F(x^\\star)$。上述不等式为 $\\delta_{k+1} \\le \\frac{L}{2} (\\|x_k-x^\\star\\|_2^2 - \\|x_{k+1}-x^\\star\\|_2^2)$。\n将此式从 $k=0$ 到 $K-1$ 求和：\n$$\\sum_{k=1}^{K} \\delta_k \\leq \\frac{L}{2} \\sum_{k=0}^{K-1} \\left( \\|x_k-x^\\star\\|_2^2 - \\|x_{k+1}-x^\\star\\|_2^2 \\right) = \\frac{L}{2} \\left( \\|x_0-x^\\star\\|_2^2 - \\|x_K-x^\\star\\|_2^2 \\right)$$\n由于 $\\|x_K-x^\\star\\|_2^2 \\geq 0$，我们有 $\\sum_{k=1}^{K} \\delta_k \\leq \\frac{L}{2} \\|x_0-x^\\star\\|_2^2$。\n当 $\\alpha \\le 1/L$ 时，对于 ISTA，函数值序列 $\\{F(x_k)\\}$ 是非增的。因此，$\\{\\delta_k\\}$ 是一个非负的非增序列。\n这意味着对于所有 $k \\leq K$，有 $\\delta_K \\leq \\delta_k$。\n因此，$K \\delta_K \\leq \\sum_{k=1}^{K} \\delta_k$。\n结合这些结果：\n$$K \\delta_K \\leq \\frac{L}{2} \\|x_0-x^\\star\\|_2^2 \\implies \\delta_K \\leq \\frac{L \\|x_0-x^\\star\\|_2^2}{2K}$$\n用 $k$ 替换 $K$，我们得到第 $k$ 次迭代的界限：\n$$F(x_k) - F(x^\\star) \\leq \\frac{L \\|x_0-x^\\star\\|_2^2}{2k}$$\n与指定形式 $F(x_k) - F(x^\\star) \\leq \\frac{C_{\\mathrm{ISTA}}}{k}$ 比较，我们确定常数为：\n$$C_{\\mathrm{ISTA}} = \\frac{L}{2} \\|x_0-x^\\star\\|_2^2$$\n\n**第二部分：FISTA 收敛速率常数的推导**\n\n快速迭代收缩阈值算法 (FISTA) 使用 Nesterov 型加速方案。其 $O(1/k^2)$ 速率的推导要复杂得多。它依赖于一个精心构造的势函数或李雅普诺夫函数以及一个特定的动量参数序列。我们概述其主要思想。\n\nFISTA 的更新步骤是：\n1. $x_k = \\mathrm{prox}_{h/L}(y_k - \\frac{1}{L}\\nabla g(y_k))$\n2. $t_{k+1} = \\frac{1+\\sqrt{1+4t_k^2}}{2}$\n3. $y_{k+1} = x_k + \\frac{t_k-1}{t_{k+1}}(x_k-x_{k-1})$\n初始化为 $t_1=1$，$y_1=x_0$，$x_{-1}=x_0$。\n\n证明策略涉及操作与 ISTA 中使用的相同的基本不等式，但应用于迭代点 $x_k$ 和外推点 $y_k$ 的混合。这样可以建立一个递归关系。证明中的关键不等式（例如，Beck  Teboulle, 2009 的定理 4.4 或 Nocedal  Wright, 2006 \"Numerical Optimization\" 的定理 10.35）具有以下形式：\n$$t_k^2(F(x_k)-F(x^\\star)) - t_{k-1}^2(F(x_{k-1})-F(x^\\star)) \\le \\frac{L}{2}(\\|u_{k-1}\\|^2 - \\|u_k\\|^2)$$\n其中 $u_k$ 是一个与迭代点相关的辅助向量序列。将此不等式从 $k=1$ 到 $K$ 求和，在右侧产生一个伸缩和。这导出了一个形式如下的不等式：\n$$t_K^2(F(x_K)-F(x^\\star)) \\le \\frac{L}{2}\\|x_0-x^\\star\\|_2^2$$\n参数序列满足 $t_K \\ge \\frac{K+1}{2}$。代入此式可得：\n$$(\\frac{K+1}{2})^2 (F(x_K)-F(x^\\star)) \\le \\frac{L}{2}\\|x_0-x^\\star\\|_2^2$$\n$$F(x_K)-F(x^\\star) \\le \\frac{2L\\|x_0-x^\\star\\|_2^2}{(K+1)^2}$$\n一些证明会得出略有不同的常数或对 $k^2$ 与 $(k+1)^2$ 的依赖关系。问题中指定的形式 $\\frac{C_{\\mathrm{FISTA}}}{(k+1)^2}$ 是一个标准结果。与我们推导的界限比较，我们确定常数为：\n$$C_{\\mathrm{FISTA}} = 2L \\|x_0-x^\\star\\|_2^2$$\n\n**第三部分：针对特定实例的求值**\n\n我们被给予以下具体实例：\n$$A = \\begin{pmatrix} 3  0  0 \\\\ 0  1  0 \\\\ 0  0  2 \\end{pmatrix}, \\quad b = 0, \\quad \\lambda  0, \\quad x_{0} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\end{pmatrix}$$\n首先，我们计算必要的量。\n1.  **利普希茨常数 $L$**：\n    $L = \\|A\\|_2^2$。谱范数 $\\|A\\|_2$ 是 $A$ 的最大奇异值。由于 $A$ 是一个对角矩阵，其奇异值是对角元素的绝对值：$\\{|3|, |1|, |2|\\}$。最大奇异值为 $3$。\n    因此，$L = 3^2 = 9$。\n\n2.  **最优解 $x^\\star$**：\n    我们必须找到 $F(x) = \\frac{1}{2}\\|Ax\\|_2^2 + \\lambda\\|x\\|_1$ 的极小点。\n    目标函数为 $F(x) = \\frac{1}{2}( (3x_1)^2 + (1x_2)^2 + (2x_3)^2 ) + \\lambda(|x_1|+|x_2|+|x_3|)$。\n    $F(x) = \\frac{1}{2}(9x_1^2 + x_2^2 + 4x_3^2) + \\lambda(|x_1|+|x_2|+|x_3|)$。\n    对于任意 $x$，两项都是非负的。第一项当且仅当 $x=0$ 时为零。第二项当且仅当 $x=0$ 时为零（因为 $\\lambda  0$）。\n    因此，$F(x)$ 仅在 $x=0$ 处达到其最小值 $0$。唯一的极小点是 $x^\\star = 0$。\n\n3.  **初始点到最优点的距离 $\\|x_0 - x^\\star\\|_2^2$**：\n    由于 $x^\\star = 0$，我们有 $x_0 - x^\\star = x_0 = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\end{pmatrix}$。\n    $\\|x_0 - x^\\star\\|_2^2 = 1^2 + 2^2 + 2^2 = 1 + 4 + 4 = 9$。\n\n现在我们可以表示此实例的常数：\n$$C_{\\mathrm{ISTA}} = \\frac{L}{2} \\|x_0 - x^\\star\\|_2^2 = \\frac{9}{2} \\times 9 = \\frac{81}{2}$$\n$$C_{\\mathrm{FISTA}} = 2L \\|x_0 - x^\\star\\|_2^2 = 2 \\times 9 \\times 9 = 162$$\n\n**第四部分：计算比率**\n\n最后一步是计算比率 $C_{\\mathrm{FISTA}} / C_{\\mathrm{ISTA}}$。\n$$\\frac{C_{\\mathrm{FISTA}}}{C_{\\mathrm{ISTA}}} = \\frac{2L \\|x_0 - x^\\star\\|_2^2}{\\frac{L}{2} \\|x_0 - x^\\star\\|_2^2} = \\frac{2}{1/2} = 4$$\n只要 $L$ 和 $\\|x_0-x^\\star\\|_2^2$ 不为零，该比率就与它们的具体值无关。它反映了两种算法推导出的上界之间的根本性差异。",
            "answer": "$$\n\\boxed{4}\n$$"
        },
        {
            "introduction": "理论上，FISTA 需要知道精确的 Lipschitz 常数 $L$ 来设置最优步长。然而在实践中，计算精确的 $L$ 可能很困难或计算成本高昂，导致实践者使用一个估计值 $L' \\ge L$。这最后一个练习探讨了这种选择的实际后果 。通过分析将 $L$ 高估一个因子 $c$ 会如何影响收敛保证和所需的迭代次数，你将对算法的鲁棒性及其在实际应用中的固有权衡获得关键的见解。",
            "id": "3439173",
            "problem": "考虑压缩感知中的复合凸优化问题，其目标是最小化目标函数 $$F(x) = f(x) + g(x),$$ 其中 $$f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2} \\quad \\text{和} \\quad g(x) = \\lambda \\|x\\|_{1},$$ 此处 $A \\in \\mathbb{R}^{m \\times n}$ 是一个传感矩阵，$b \\in \\mathbb{R}^{m}$ 是一个给定的测量向量，而 $\\lambda  0$ 是一个正则化参数。梯度 $\\nabla f$ 是 Lipschitz 连续的，其最小的有效 Lipschitz 常数为 $L = \\sigma_{\\max}(A)^{2}$，其中 $\\sigma_{\\max}(A)$ 表示 $A$ 的最大奇异值。假设应用快速迭代收缩阈值算法 (FISTA, Fast Iterative Shrinkage-Thresholding Algorithm)，其步长为常数 $t = 1/L'$，并采用标准的 Nesterov 型加速参数，其中 $L' = c L$，因子 $c  1$（即，Lipschitz 常数被一个乘法因子 $c$ 高估了）。\n\n仅使用 $f$ 的基本平滑性上界和 $g$ 的凸性，从不等式\n$$f(y) \\leq f(x) + \\langle \\nabla f(x), y - x \\rangle + \\frac{L}{2}\\|y - x\\|_{2}^{2},$$\n以及用任何 $L' \\geq L$ 构建的替代函数是 $f$ 的有效上模型的性质出发。基于这些原理，推导 FISTA 的函数值精度界如何随 $L'$ 变化（不要预先假设或引用任何显式的收敛速率公式；相反，应从二次上模型的齐次性和加速势能函数的构造进行推理）。然后：\n\n1. 在固定的迭代索引 $k$ 处，确定当 $L'$ 被 $c L$ 替换时，函数值误差界中的确切乘法减速因子。\n2. 对于固定的目标精度水平 $\\varepsilon  0$，确定当 $L'$ 再次被 $c L$ 替换时，迭代复杂度（保证 $F(x_{k}) - F(x^{\\star}) \\leq \\varepsilon$ 所需的迭代次数）中的确切乘法减速因子。\n\n最后，通过表达当使用 Frobenius 范数界 $L' = \\|A\\|_{F}^{2}$ 代替谱范数界 $L = \\sigma_{\\max}(A)^{2}$ 时产生的过高估计因子 $c$，在病态传感矩阵的背景下说明这些减速情况，并解释奇异值分布如何影响减速。您的最终答案必须是第 1 部分和第 2 部分的减速因子对，以 $c$ 的行矩阵形式表示。无需四舍五入，也无物理单位。",
            "solution": "该问题要求分析当目标函数光滑部分的梯度 Lipschitz 常数被高估时，快速迭代收缩阈值算法 (FISTA) 的收敛速率。我们需要确定误差界和迭代复杂度方面的减速情况。\n\n优化问题是最小化 $F(x) = f(x) + g(x)$，其中 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 且 $g(x) = \\lambda \\|x\\|_{1}$。函数 $f(x)$ 是凸且连续可微的，其梯度 $\\nabla f(x) = A^T(Ax-b)$ 是 Lipschitz 连续的，常数为 $L = \\sigma_{\\max}(A)^2$。函数 $g(x)$ 是凸的但非光滑。\n\nFISTA 是一种加速的近端梯度方法。其分析的一个关键要素是 $f(x)$ 的二次上界，该上界由其梯度的 Lipschitz 连续性保证。对于任何 $L' \\geq L$，我们有主化不等式：\n$$\nf(y) \\leq f(x) + \\langle \\nabla f(x), y - x \\rangle + \\frac{L'}{2}\\|y - x\\|_{2}^{2}, \\quad \\forall x, y \\in \\mathbb{R}^n.\n$$\n这个不等式是我们推导的起点。\n\nFISTA 算法在第 $k$ 次迭代时，通过执行一个近端梯度步骤，从一个搜索点 $y_k$ 生成一个新的迭代点 $x_{k+1}$。这个步骤可以看作是最小化一个围绕 $y_k$ 的 $F(x)$ 的替代函数：\n$$\nx_{k+1} = \\underset{x \\in \\mathbb{R}^n}{\\arg\\min} \\left\\{ f(y_k) + \\langle \\nabla f(y_k), x - y_k \\rangle + \\frac{L'}{2}\\|x - y_k\\|_{2}^{2} + g(x) \\right\\}.\n$$\n使用的步长是 $t = 1/L'$。设被最小化的替代函数为 $Q_{L'}(x, y_k)$。因为 $L' \\geq L$，这是 $F(x)$ 的一个上界：对于所有 $x$，$F(x) \\le Q_{L'}(x, y_k)$。因此，$F(x_{k+1}) \\le Q_{L'}(x_{k+1}, y_k)$。由于 $x_{k+1}$ 是 $Q_{L'}(x, y_k)$ 的最小化子，我们有对任意 $x \\in \\mathbb{R}^n$，$Q_{L'}(x_{k+1}, y_k) \\le Q_{L'}(x, y_k)$。\n\n将这些事实与 $f$ 和 $g$ 的凸性相结合，可以推导出一个控制单次迭代进展的基本不等式。对于任何 $x \\in \\mathbb{R}^n$：\n\\begin{align*}\nF(x_{k+1}) - F(x)  \\le Q_{L'}(x_{k+1}, y_k) - F(x) \\\\\n \\le Q_{L'}(x, y_k) - F(x) \\\\\n = \\left( f(y_k) + \\langle \\nabla f(y_k), x - y_k \\rangle + \\frac{L'}{2}\\|x - y_k\\|_{2}^{2} + g(x) \\right) - (f(x) + g(x)) \\\\\n = (f(y_k) - f(x) + \\langle \\nabla f(y_k), x - y_k \\rangle) + \\frac{L'}{2}\\|x - y_k\\|_{2}^{2}.\n\\end{align*}\n根据 $f$ 的凸性，我们有 $f(y_k) - f(x) + \\langle \\nabla f(y_k), x - y_k \\rangle \\le 0$。这导致 $F(x_{k+1}) - F(x) \\le \\frac{L'}{2}\\|x-y_k\\|_2^2$。虽然这是正确的，但并非最紧的界。按照提示的要求，一个更仔细的推导需要使用近端步骤的最优性条件以及 $f$ 和 $g$ 的凸性定义。这导出了众所周知的不等式：\n$$\nF(x_{k+1}) - F(x) \\le \\frac{L'}{2} \\left[ \\|x - y_k\\|_{2}^{2} - \\|x - x_{k+1}\\|_{2}^{2} \\right].\n$$\n这个不等式是 FISTA 收敛性分析的核心。“加速势能函数构造”指的是将这个不等式（在 $x = x_k$ 和 $x = x^{\\star}$ 处求值，其中 $x^{\\star}$ 是 $F$ 的一个最小化子）与 $y_k$ 的特定 Nesterov 动量规则相结合。这个过程构造了一个 Lyapunov 函数，证明了收敛速率。标准分析表明，对于动量参数的适当选择，函数值误差 $F(x_k) - F(x^{\\star})$ 的界为：\n$$\nF(x_k) - F(x^{\\star}) \\leq \\frac{\\alpha L' \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2},\n$$\n其中 $\\alpha$ 是一个常数（对于具有 $t_k \\ge k/2$ 的常见 FISTA 变体，通常 $\\alpha=2$）。关键点在于，该界与算法步长中使用的 Lipschitz 常数 $L'$ 成正比。“二次上模型的齐次性”意味着二次项的系数 $\\frac{L'}{2}$ 随 $L'$ 线性缩放，并且这种线性缩放直接传播到最终的收敛速率界。\n\n我们用 $B(k, L') = \\frac{\\alpha L' \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2}$ 表示误差界。我们感兴趣的是，当我们将最优常数 $L = \\sigma_{\\max}(A)^2$ 替换为某个 $c  1$ 的高估常数 $L' = cL$ 时会发生什么。\n\n**1. 函数值误差界中的乘法减速因子**\n\n在固定的迭代次数 $k$ 时，我们比较使用 $L$ 获得的误差界和使用 $L' = cL$ 获得的误差界。\n使用最优常数的界是 $B(k, L) = \\frac{\\alpha L \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2}$。\n使用高估常数的界是 $B(k, cL) = \\frac{\\alpha (cL) \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2}$。\n\n误差界中的乘法因子增长是其比率：\n$$\n\\frac{B(k, cL)}{B(k, L)} = \\frac{\\frac{\\alpha c L \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2}}{\\frac{\\alpha L \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2}} = c.\n$$\n因此，将 Lipschitz 常数高估一个因子 $c$ 会导致在任何给定的迭代 $k$ 处，理论误差界增大 $c$ 倍。\n\n**2. 迭代复杂度中的乘法减速因子**\n\n迭代复杂度指的是达到所需精度 $\\varepsilon  0$ 所需的迭代次数。设 $K(L', \\varepsilon)$ 是保证 $F(x_k) - F(x^{\\star}) \\leq \\varepsilon$ 所需的最小迭代次数 $k$。\n\n使用常数 $L$，我们需要找到 $k_1 = K(L, \\varepsilon)$ 使得：\n$$\n\\frac{\\alpha L \\|x_0 - x^{\\star}\\|_{2}^{2}}{k_1^2} \\leq \\varepsilon \\implies k_1^2 \\geq \\frac{\\alpha L \\|x_0 - x^{\\star}\\|_{2}^{2}}{\\varepsilon} \\implies k_1 \\geq \\sqrt{\\frac{\\alpha L}{\\varepsilon}} \\|x_0 - x^{\\star}\\|_{2}.\n$$\n使用常数 $L' = cL$，我们需要找到 $k_2 = K(cL, \\varepsilon)$ 使得：\n$$\n\\frac{\\alpha (cL) \\|x_0 - x^{\\star}\\|_{2}^{2}}{k_2^2} \\leq \\varepsilon \\implies k_2^2 \\geq \\frac{\\alpha cL \\|x_0 - x^{\\star}\\|_{2}^{2}}{\\varepsilon} \\implies k_2 \\geq \\sqrt{\\frac{\\alpha cL}{\\varepsilon}} \\|x_0 - x^{\\star}\\|_{2}.\n$$\n迭代复杂度中的乘法减速因子是所需迭代次数的比率：\n$$\n\\frac{k_2}{k_1} \\approx \\frac{\\sqrt{\\frac{\\alpha cL}{\\varepsilon}} \\|x_0 - x^{\\star}\\|_{2}}{\\sqrt{\\frac{\\alpha L}{\\varepsilon}} \\|x_0 - x^{\\star}\\|_{2}} = \\sqrt{c}.\n$$\n因此，将 Lipschitz 常数高估一个因子 $c$ 会使达到给定精度所需的迭代次数增加一个因子 $\\sqrt{c}$。\n\n**使用 Frobenius 范数的说明**\n\n该问题建议用一个例子来说明，其中紧的 Lipschitz 常数 $L = \\sigma_{\\max}(A)^2$ 被更易于计算的上界 $L' = \\|A\\|_F^2$ 所取代。矩阵 $A$ 的 Frobenius 范数与其奇异值 $\\sigma_i(A)$ 的关系为 $\\|A\\|_F^2 = \\sum_{i=1}^{\\text{rank}(A)} \\sigma_i(A)^2$。最大奇异值为 $\\sigma_{\\max}(A) = \\sigma_1(A)$（假设奇异值已排序 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots$）。\n高估因子 $c$ 为：\n$$\nc = \\frac{L'}{L} = \\frac{\\|A\\|_{F}^{2}}{\\sigma_{\\max}(A)^2} = \\frac{\\sum_{i=1}^{\\text{rank}(A)} \\sigma_i(A)^2}{\\sigma_1(A)^2} = 1 + \\frac{\\sum_{i=2}^{\\text{rank}(A)} \\sigma_i(A)^2}{\\sigma_1(A)^2}.\n$$\n由于 $\\sigma_i(A)^2 \\geq 0$，我们有 $c \\geq 1$。$c$ 的大小取决于奇异值的分布。\n- 如果矩阵是数值上秩为1的，或者其奇异值衰减非常快（对于 $i  1$，有 $\\sigma_1 \\gg \\sigma_i$），那么和 $\\sum_{i=2}^{\\text{rank}(A)} \\sigma_i(A)^2$ 相对于 $\\sigma_1(A)^2$ 会很小，$c$ 将接近于 $1$。在这种情况下，减速是微不足道的。\n- 如果奇异值相对平坦（许多 $\\sigma_i$ 的量级与 $\\sigma_1$ 相似），那么 $c$ 可能会很大。在所有非零奇异值都相等的极端情况下，$c = \\text{rank}(A)$。\n- 一个“病态”矩阵（大的 $\\sigma_1/\\sigma_{\\text{rank}(A)}$）不一定意味着大的 $c$。如上所示，大的 $c$ 是由奇异值谱的平坦性引起的，而不一定是最大和最小奇异值之间的大比率。一个所有 $\\sigma_i$ 都相等的良态矩阵，对于给定的秩，会产生可能的最大 $c$ 值。\n\n因此，当传感矩阵 $A$ 的“能量”（奇异值平方和）分布在许多奇异值上，而不是集中在少数几个主导奇异值上时，使用 Frobenius 范数界是最不利的，会导致因子为 $c$ 和 $\\sqrt{c}$ 的显著减速。\n\n两个减速因子分别是误差界的 $c$ 和迭代复杂度的 $\\sqrt{c}$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nc  \\sqrt{c}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}