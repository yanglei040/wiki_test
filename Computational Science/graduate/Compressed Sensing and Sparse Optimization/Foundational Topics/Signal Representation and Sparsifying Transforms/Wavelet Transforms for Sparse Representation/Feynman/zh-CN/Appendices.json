{
    "hands_on_practices": [
        {
            "introduction": "深入理解任何高级工具都始于对其基本原理的掌握。这项练习提供了一个具体的、分步的计算任务，要求你使用Haar滤波器对一个简单的分段常数信号进行离散小波变换（DWT）。通过亲手执行滤波和下采样的操作，你将揭开该算法的神秘面纱，并为DWT如何将信号分解为近似和细节分量建立起坚实的直觉。",
            "id": "3493857",
            "problem": "考虑一个定义在 $n \\in \\{0,1,\\dots,15\\}$ 上的实值、长度为16的离散时间信号 $x[n]$，其序列为\n$$\nx = \\left[5,\\,5,\\,5,\\,5,\\,2,\\,2,\\,2,\\,2,\\,0,\\,0,\\,8,\\,8,\\,8,\\,8,\\,8,\\,8\\right].\n$$\n设正交双通道滤波器组的分析滤波器指定为 Haar 滤波器\n$$\nh = \\left[\\frac{1}{\\sqrt{2}},\\,\\frac{1}{\\sqrt{2}}\\right], \\qquad g = \\left[\\frac{1}{\\sqrt{2}},\\, -\\frac{1}{\\sqrt{2}}\\right],\n$$\n并在需要时使用对称边界延拓。执行两级离散小波变换 (DWT)，定义如下：第一级近似系数和细节系数为\n$$\na_{1}[n] = h_{0}\\,x[2n] + h_{1}\\,x[2n+1], \\qquad d_{1}[n] = g_{0}\\,x[2n] + g_{1}\\,x[2n+1],\n$$\n其中 $n = 0,1,\\dots,7$。第二级系数通过将相同的 $h$ 和 $g$ 应用于第一级近似 $a_{1}$ 获得：\n$$\na_{2}[n] = h_{0}\\,a_{1}[2n] + h_{1}\\,a_{1}[2n+1], \\qquad d_{2}[n] = g_{0}\\,a_{1}[2n] + g_{1}\\,a_{1}[2n+1],\n$$\n其中 $n = 0,1,2,3$。\n\n请进行这些计算，并报告三个子带系数向量 $a_{2}$、$d_{2}$ 和 $d_{1}$。最后，计算第二级细节子带的总能量，\n$$\nE_{d_{2}} = \\sum_{n=0}^{3} \\left(d_{2}[n]\\right)^{2},\n$$\n并将此值作为最终答案。最终答案应表示为一个不进行四舍五入的实数。",
            "solution": "问题要求计算给定离散时间信号 $x[n]$ 的两级离散小波变换 (DWT)，并随后计算第二级细节系数的能量。信号长度为 $N=16$，由以下序列给出：\n$$x = \\left[5,\\,5,\\,5,\\,5,\\,2,\\,2,\\,2,\\,2,\\,0,\\,0,\\,8,\\,8,\\,8,\\,8,\\,8,\\,8\\right]$$\n正交 Haar 小波变换的分析滤波器是低通滤波器 $h$ 和高通滤波器 $g$：\n$$h = \\left[\\frac{1}{\\sqrt{2}},\\,\\frac{1}{\\sqrt{2}}\\right] \\quad \\implies \\quad h_0 = \\frac{1}{\\sqrt{2}}, h_1 = \\frac{1}{\\sqrt{2}}$$\n$$g = \\left[\\frac{1}{\\sqrt{2}},\\, -\\frac{1}{\\sqrt{2}}\\right] \\quad \\implies \\quad g_0 = \\frac{1}{\\sqrt{2}}, g_1 = -\\frac{1}{\\sqrt{2}}$$\n问题指明边界效应通过对称延拓处理，但考虑到滤波器长度为 $2$ 且信号长度是2的幂，此次特定计算不需要延拓。\n\n首先，我们计算第一级近似系数 $a_1[n]$ 和细节系数 $d_1[n]$（其中 $n \\in \\{0, 1, \\dots, 7\\}$）。控制方程为：\n$$a_{1}[n] = h_{0}\\,x[2n] + h_{1}\\,x[2n+1] = \\frac{1}{\\sqrt{2}}(x[2n] + x[2n+1])$$\n$$d_{1}[n] = g_{0}\\,x[2n] + g_{1}\\,x[2n+1] = \\frac{1}{\\sqrt{2}}(x[2n] - x[2n+1])$$\n我们按如下方式计算每个系数：\n$a_1[0] = \\frac{1}{\\sqrt{2}}(x[0]+x[1]) = \\frac{1}{\\sqrt{2}}(5+5) = \\frac{10}{\\sqrt{2}} = 5\\sqrt{2}$\n$d_1[0] = \\frac{1}{\\sqrt{2}}(x[0]-x[1]) = \\frac{1}{\\sqrt{2}}(5-5) = 0$\n$a_1[1] = \\frac{1}{\\sqrt{2}}(x[2]+x[3]) = \\frac{1}{\\sqrt{2}}(5+5) = \\frac{10}{\\sqrt{2}} = 5\\sqrt{2}$\n$d_1[1] = \\frac{1}{\\sqrt{2}}(x[2]-x[3]) = \\frac{1}{\\sqrt{2}}(5-5) = 0$\n$a_1[2] = \\frac{1}{\\sqrt{2}}(x[4]+x[5]) = \\frac{1}{\\sqrt{2}}(2+2) = \\frac{4}{\\sqrt{2}} = 2\\sqrt{2}$\n$d_1[2] = \\frac{1}{\\sqrt{2}}(x[4]-x[5]) = \\frac{1}{\\sqrt{2}}(2-2) = 0$\n$a_1[3] = \\frac{1}{\\sqrt{2}}(x[6]+x[7]) = \\frac{1}{\\sqrt{2}}(2+2) = \\frac{4}{\\sqrt{2}} = 2\\sqrt{2}$\n$d_1[3] = \\frac{1}{\\sqrt{2}}(x[6]-x[7]) = \\frac{1}{\\sqrt{2}}(2-2) = 0$\n$a_1[4] = \\frac{1}{\\sqrt{2}}(x[8]+x[9]) = \\frac{1}{\\sqrt{2}}(0+0) = 0$\n$d_1[4] = \\frac{1}{\\sqrt{2}}(x[8]-x[9]) = \\frac{1}{\\sqrt{2}}(0-0) = 0$\n$a_1[5] = \\frac{1}{\\sqrt{2}}(x[10]+x[11]) = \\frac{1}{\\sqrt{2}}(8+8) = \\frac{16}{\\sqrt{2}} = 8\\sqrt{2}$\n$d_1[5] = \\frac{1}{\\sqrt{2}}(x[10]-x[11]) = \\frac{1}{\\sqrt{2}}(8-8) = 0$\n$a_1[6] = \\frac{1}{\\sqrt{2}}(x[12]+x[13]) = \\frac{1}{\\sqrt{2}}(8+8) = \\frac{16}{\\sqrt{2}} = 8\\sqrt{2}$\n$d_1[6] = \\frac{1}{\\sqrt{2}}(x[12]-x[13]) = \\frac{1}{\\sqrt{2}}(8-8) = 0$\n$a_1[7] = \\frac{1}{\\sqrt{2}}(x[14]+x[15]) = \\frac{1}{\\sqrt{2}}(8+8) = \\frac{16}{\\sqrt{2}} = 8\\sqrt{2}$\n$d_1[7] = \\frac{1}{\\sqrt{2}}(x[14]-x[15]) = \\frac{1}{\\sqrt{2}}(8-8) = 0$\n\n得到的第一级系数向量为：\n$$a_1 = \\left[5\\sqrt{2},\\, 5\\sqrt{2},\\, 2\\sqrt{2},\\, 2\\sqrt{2},\\, 0,\\, 8\\sqrt{2},\\, 8\\sqrt{2},\\, 8\\sqrt{2}\\right]$$\n$$d_1 = \\left[0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0\\right]$$\n\n接下来，我们通过将相同的滤波器应用于第一级近似向量 $a_1$ 来计算第二级系数。第二级近似系数 $a_2[n]$ 和细节系数 $d_2[n]$ 的计算范围为 $n \\in \\{0, 1, 2, 3\\}$：\n$$a_{2}[n] = h_{0}\\,a_{1}[2n] + h_{1}\\,a_{1}[2n+1] = \\frac{1}{\\sqrt{2}}(a_{1}[2n] + a_{1}[2n+1])$$\n$$d_{2}[n] = g_{0}\\,a_{1}[2n] + g_{1}\\,a_{1}[2n+1] = \\frac{1}{\\sqrt{2}}(a_{1}[2n] - a_{1}[2n+1])$$\n我们计算每个系数：\n$a_2[0] = \\frac{1}{\\sqrt{2}}(a_1[0]+a_1[1]) = \\frac{1}{\\sqrt{2}}(5\\sqrt{2}+5\\sqrt{2}) = \\frac{1}{\\sqrt{2}}(10\\sqrt{2}) = 10$\n$d_2[0] = \\frac{1}{\\sqrt{2}}(a_1[0]-a_1[1]) = \\frac{1}{\\sqrt{2}}(5\\sqrt{2}-5\\sqrt{2}) = 0$\n$a_2[1] = \\frac{1}{\\sqrt{2}}(a_1[2]+a_1[3]) = \\frac{1}{\\sqrt{2}}(2\\sqrt{2}+2\\sqrt{2}) = \\frac{1}{\\sqrt{2}}(4\\sqrt{2}) = 4$\n$d_2[1] = \\frac{1}{\\sqrt{2}}(a_1[2]-a_1[3]) = \\frac{1}{\\sqrt{2}}(2\\sqrt{2}-2\\sqrt{2}) = 0$\n$a_2[2] = \\frac{1}{\\sqrt{2}}(a_1[4]+a_1[5]) = \\frac{1}{\\sqrt{2}}(0+8\\sqrt{2}) = \\frac{1}{\\sqrt{2}}(8\\sqrt{2}) = 8$\n$d_2[2] = \\frac{1}{\\sqrt{2}}(a_1[4]-a_1[5]) = \\frac{1}{\\sqrt{2}}(0-8\\sqrt{2}) = -8$\n$a_2[3] = \\frac{1}{\\sqrt{2}}(a_1[6]+a_1[7]) = \\frac{1}{\\sqrt{2}}(8\\sqrt{2}+8\\sqrt{2}) = \\frac{1}{\\sqrt{2}}(16\\sqrt{2}) = 16$\n$d_2[3] = \\frac{1}{\\sqrt{2}}(a_1[6]-a_1[7]) = \\frac{1}{\\sqrt{2}}(8\\sqrt{2}-8\\sqrt{2}) = 0$\n\n按要求计算出的子带系数向量为：\n$$a_2 = \\left[10,\\, 4,\\, 8,\\, 16\\right]$$\n$$d_2 = \\left[0,\\, 0,\\, -8,\\, 0\\right]$$\n$$d_1 = \\left[0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0\\right]$$\n\n最后，我们计算第二级细节子带的总能量 $E_{d_{2}}$：\n$$E_{d_{2}} = \\sum_{n=0}^{3} \\left(d_{2}[n]\\right)^{2}$$\n代入向量 $d_2$ 的值：\n$$E_{d_{2}} = (0)^{2} + (0)^{2} + (-8)^{2} + (0)^{2} = 0 + 0 + 64 + 0 = 64$$\n第二级细节子带的能量是 $64$。",
            "answer": "$$\\boxed{64}$$"
        },
        {
            "introduction": "在掌握了基本计算流程后，我们可以转向更为抽象的线性代数视角。这项练习要求你以编程方式构建两个基本变换的完整矩阵表示：离散傅里叶变换（DFT）和Haar离散小波变换（DWT）。通过计算这些基之间的互相关性（mutual coherence）$\\mu$，你将定量地探索信号处理中的一种“不确定性原理”——一个域中的局部化（如小波的时间域）意味着在另一个域中的离域化（如傅里叶的频率域），这是支撑压缩感知等应用的关键性质。",
            "id": "3493805",
            "problem": "给定一个整数 $n$，满足 $n = 2^J$，其中 $J \\geq 1$ 是某个整数。令 $F \\in \\mathbb{C}^{n \\times n}$ 表示酉离散傅里叶变换 (DFT) 矩阵，令 $W \\in \\mathbb{R}^{n \\times n}$ 表示标准正交 Haar 离散小波变换 (DWT) 矩阵。您的任务是从第一性原理出发，数值地构造 $F$ 和 $W$，计算这两个标准正交基之间的经验互相关性，并描述相关性值在 Haar 小波尺度上的分布情况。\n\n用作起点的基本定义：\n- 酉离散傅里叶变换 (DFT) 矩阵 $F$ 的元素为\n$$\nF_{t,k} = \\frac{1}{\\sqrt{n}} \\exp\\left(2\\pi i \\frac{t k}{n}\\right),\n\\quad t \\in \\{0,1,\\dots,n-1\\},\\ k \\in \\{0,1,\\dots,n-1\\}.\n$$\n- 标准正交 Haar 离散小波变换 (DWT) 矩阵 $W$ 由 $n$ 个标准正交的列向量组成。其中一列是尺度向量 $\\phi \\in \\mathbb{R}^n$，其元素对所有 $t$ 均为 $\\phi[t] = \\frac{1}{\\sqrt{n}}$。对于每个尺度 $s \\in \\{1,2,\\dots,J\\}$，其支撑长度为 $L_s = 2^s$，存在 $n / L_s$ 个小波原子 $\\{\\psi_{s,k}\\}_{k=0}^{n/L_s - 1}$，其中每个 $\\psi_{s,k} \\in \\mathbb{R}^n$ 定义为\n$$\n\\psi_{s,k}[t] =\n\\begin{cases}\n+\\frac{1}{\\sqrt{L_s}},  t \\in \\{k L_s, k L_s + 1, \\dots, k L_s + \\frac{L_s}{2} - 1\\}, \\\\\n-\\frac{1}{\\sqrt{L_s}},  t \\in \\{k L_s + \\frac{L_s}{2}, k L_s + \\frac{L_s}{2}+1, \\dots, (k+1)L_s - 1\\}, \\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\n在标准欧几里得内积下，这些向量是标准正交的，并且与 $\\phi$ 一起构成了 $\\mathbb{R}^n$ 的一个完备标准正交基。\n\n待计算量的定义：\n- 两个标准正交基 $U, V \\in \\mathbb{C}^{n \\times n}$（其列向量分别为 $\\{u_i\\}$ 和 $\\{v_j\\}$）之间的互相关性为\n$$\n\\mu(U,V) = \\max_{1 \\leq i,j \\leq n} \\left| \\langle u_i, v_j \\rangle \\right|.\n$$\n- 令 $C = F^* W \\in \\mathbb{C}^{n \\times n}$，其中 $F^*$ 表示 $F$ 的共轭转置。矩阵 $C$ 包含了所有成对的内积 $\\langle f_i, w_j \\rangle$。那么，经验互相关性为\n$$\n\\hat{\\mu} = \\max_{i,j} |C_{i,j}|.\n$$\n- 对于一个 Haar 小波尺度 $s \\in \\{1,2,\\dots,J\\}$，定义 $\\mathcal{J}_s$ 为 $W$ 中对应于尺度 $s$ 的小波原子的列索引集合。同时，定义 $\\mathcal{J}_0$ 为包含尺度向量 $\\phi$ 索引的单元素集。对于每个列索引 $j \\in \\mathcal{J}_s$，定义其与 DFT 基的经验相关性为\n$$\n\\gamma_j = \\max_{1 \\leq i \\leq n} |C_{i,j}|.\n$$\n这样就得到了一个按尺度划分的集合 $\\{\\gamma_j : j \\in \\mathcal{J}_s\\}$，其在尺度 $s$ 上的分布可以通过其均值和最大值来概括。\n\n程序任务：\n1. 根据上述定义，为给定的 $n$ 数值地构造 $F$ 和 $W$。\n2. 通过检查 $F^* F \\approx I_n$ 和 $W^\\top W \\approx I_n$ 来数值地验证 $F$ 和 $W$ 分别是酉矩阵/标准正交矩阵，其中 $I_n$ 是 $n \\times n$ 的单位矩阵。\n3. 计算 $C = F^* W$ 和经验互相关性 $\\hat{\\mu} = \\max_{i,j} |C_{i,j}|$。\n4. 对于每个尺度 $s \\in \\{0,1,2,\\dots,J\\}$，计算集合 $\\{\\gamma_j : j \\in \\mathcal{J}_s\\}$，并通过其均值和最大值进行总结。\n5. 数值稳定性和归一化：确保 $F$ 精确地是酉矩阵，并且 Haar 原子按照规定精确归一化。所有内积都采用标准的复欧几里得内积。\n6. 测试套件和覆盖范围：\n   - 使用测试套件 $n \\in \\{2, 8, 32\\}$，以覆盖一个基可能重合的极端小案例、一个小规模的多尺度案例和一个中等规模的多尺度案例。\n7. 输出规范：\n   - 对于测试套件中的每个 $n$，生成一个包含四个项目的列表：整数 $n$、浮点数 $\\hat{\\mu}$、按尺度排列的均值列表 $[\\text{mean}_s]_{s=0}^J$ 和按尺度排列的最大值列表 $[\\text{max}_s]_{s=0}^J$。其中，尺度 $s=0$ 表示尺度向量，尺度 $s=1,\\dots,J$ 表示从小到大（从最精细到最粗糙）排列的小波尺度。\n   - 在输出前，将所有浮点数值四舍五入到 $12$ 位小数。\n   - 您的程序应生成单行输出，其中包含三个测试用例的结果，形式为用方括号括起来的逗号分隔列表。具体来说，最终输出必须是一个长度为 $3$ 的列表，其中每个元素是上述针对每个 $n$ 的列表，例如 $[\\text{case}_1, \\text{case}_2, \\text{case}_3]$。\n   - 不涉及物理单位或角度；所有输出都是无量纲的实数。",
            "solution": "用户提供的问题被评估为**有效**。它在科学上基于傅里叶分析和小波分析的原理，提法得当，定义清晰一致，且其表述是客观的。任务是数值实现并分析信号处理中两个基本标准正交基之间的关系。\n\n问题的核心是量化离散傅里叶变换 (DFT) 基与 Haar 小波基之间的“非相干性”。DFT 基的元素在频率上是完全局域化的，而 Haar 小波基的元素在时间和尺度上具有不同程度的局域化。互相关性可作为衡量一个基中的元素与另一个基中的元素之间最大可能相似性的指标。在压缩感知等领域，低互相关性是一个理想的属性，因为它保证了在一个基中稀疏的信号在另一个基中会表现为密集的、展开的信号，从而能够从少量测量中进行稳健的恢复。\n\n解决方案按以下几个步骤进行：\n1.  构造 DFT 矩阵 $F$ 和 Haar DWT 矩阵 $W$。\n2.  计算基变换矩阵 $C = F^*W$。\n3.  计算整体经验互相关性 $\\hat{\\mu}$。\n4.  对相关性值进行逐尺度分析。\n\n**1. 标准正交基的构造**\n\n给定一个整数 $n=2^J$（其中 $J \\geq 1$），我们构造两个 $n \\times n$ 矩阵，其列向量构成 $\\mathbb{C}^n$ 的标准正交基。\n\n**离散傅里叶变换 (DFT) 矩阵, $F$**\nDFT 矩阵 $F \\in \\mathbb{C}^{n \\times n}$ 由其元素定义，这些元素对应于不同频率的复正弦波。第 $t$ 行和第 $k$ 列的元素由下式给出：\n$$\nF_{t,k} = \\frac{1}{\\sqrt{n}} \\exp\\left(2\\pi i \\frac{t k}{n}\\right), \\quad t, k \\in \\{0, 1, \\dots, n-1\\}\n$$\n$F$ 的列，表示为 $\\{f_k\\}_{k=0}^{n-1}$，构成了 $\\mathbb{C}^n$ 的一个标准正交基。该矩阵是酉矩阵，满足 $F^* F = F F^* = I_n$，其中 $F^*$ 是 $F$ 的共轭转置，$I_n$ 是 $n \\times n$ 的单位矩阵。\n\n**Haar 离散小波变换 (DWT) 矩阵, $W$**\nHaar DWT 矩阵 $W \\in \\mathbb{R}^{n \\times n}$ 由实值的、分段常数的基向量组成。其列构成了 $\\mathbb{R}^n$（因此也构成了 $\\mathbb{C}^n$）的一个标准正交基。该基由一个尺度向量和 $n-1$ 个按尺度组织的小波向量组成。\n\n- **尺度向量 ($\\phi$):** 该向量表示最粗糙的可能信息（信号的平均值）。它是我方矩阵 $W$ 的第一列，并对应于我们指定为 $s=0$ 的“尺度”：\n$$\n\\phi[t] = \\frac{1}{\\sqrt{n}} \\quad \\text{for } t \\in \\{0, 1, \\dots, n-1\\}\n$$\n\n- **小波向量 ($\\psi_{s,k}$):** 这些向量捕捉不同尺度和位置的细节。对于每个尺度 $s \\in \\{1, 2, \\dots, J\\}$，小波的支撑长度为 $L_s = 2^s$。在每个尺度 $s$ 上，有 $n/L_s$ 个小波，由平移参数 $k \\in \\{0, 1, \\dots, n/L_s - 1\\}$ 索引。小波 $\\psi_{s,k}$ 定义为：\n$$\n\\psi_{s,k}[t] =\n\\begin{cases}\n+\\frac{1}{\\sqrt{L_s}},  \\text{for } t \\in \\{k L_s, \\dots, k L_s + \\frac{L_s}{2} - 1\\} \\\\\n-\\frac{1}{\\sqrt{L_s}},  \\text{for } t \\in \\{k L_s + \\frac{L_s}{2}, \\dots, (k+1)L_s - 1\\} \\\\\n0,  \\text{otherwise}\n\\end{cases}\n$$\n矩阵 $W$ 是通过将这些向量作为其列来构建的。我们采用的排序方式是，第一列是尺度向量 $\\phi$。随后是尺度 $s=1$（最精细的细节，最短的支撑长度 $L_1=2$）的所有小波向量，然后是尺度 $s=2$ 的所有小波向量，以此类推，直到尺度 $s=J$（最粗糙的细节，最长的支撑长度 $L_J=n$）的单个小波。这个包含 $1 + \\sum_{s=1}^{J} (n/L_s) = 1 + (n-1) = n$ 个向量的集合是标准正交的，因此 $W^\\top W = I_n$。\n\n**2. 互相关性计算**\n\n这两个基之间的关系由矩阵 $C = F^*W$ 捕捉。该矩阵的每个元素 $C_{i,j}$ 是第 $i$ 个 DFT 基向量和第 $j$ 个 Haar 基向量之间的内积：\n$$\nC_{i,j} = \\langle f_i, w_j \\rangle\n$$\n其中 $\\{f_i\\}$ 是 $F$ 的列，$\\{w_j\\}$ 是 $W$ 的列。\n\n**经验互相关性** $\\hat{\\mu}$ 是两个基的向量之间任意内积的最大绝对值。它衡量了一个基的向量在另一个基的向量上的最大可能投影。\n$$\n\\hat{\\mu} = \\mu(F, W) = \\max_{0 \\leq i,j  n} |\\langle f_i, w_j \\rangle| = \\max_{i,j} |C_{i,j}|\n$$\n\n**3. 逐尺度相关性分析**\n\n为了理解相关性在不同 Haar 尺度上的分布情况，我们分析 $C$ 中对应于每个尺度的列。\n设 $\\mathcal{J}_s$ 为 $W$ 中（因此也是 $C$ 中）对应于尺度 $s$ 的基向量的列索引集合。对于尺度向量 $\\phi$，$\\mathcal{J}_0 = \\{0\\}$；对于 $s \\in \\{1, \\dots, J\\}$，$\\mathcal{J}_s$ 包含所有 $\\{\\psi_{s,k}\\}$ 的索引。\n\n对于每个 Haar 基向量 $w_j$，其与整个 DFT 基的个体相关性定义为：\n$$\n\\gamma_j = \\max_{0 \\leq i  n} |C_{i,j}|\n$$\n该值表示特定 Haar 向量 $w_j$ 与任何傅里叶基向量的最大相似度。\n\n然后，我们通过计算相关性值集合 $\\{\\gamma_j : j \\in \\mathcal{J}_s\\}$ 的两个统计量来总结在每个尺度 $s \\in \\{0, 1, \\dots, J\\}$ 上的行为：\n- 尺度 $s$ 的平均相关性： $\\text{mean}_s = \\frac{1}{|\\mathcal{J}_s|} \\sum_{j \\in \\mathcal{J}_s} \\gamma_j$\n- 尺度 $s$ 的最大相关性： $\\text{max}_s = \\max_{j \\in \\mathcal{J}_s} \\gamma_j$\n\n最终的算法为指定的 $n$ 值实现了这些构造和计算，并根据输出要求将浮点结果四舍五入到 12 位小数。对于 $n=2$ 的情况，DFT 基和 Haar 基重合，导致相关性为 $1$。对于更大的 $n$，这两个基是不同的，相关性小于 $1$，并在各个尺度上呈现出结构化的分布。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs DFT and Haar DWT matrices and computes their mutual coherence.\n    \"\"\"\n    test_cases = [2, 8, 32]\n    all_results = []\n\n    for n in test_cases:\n        # J is determined from n = 2^J\n        J = int(np.log2(n))\n\n        # 1. Construct the unitary DFT matrix F\n        t = np.arange(n).reshape(-1, 1)\n        k = np.arange(n).reshape(1, -1)\n        F = (1 / np.sqrt(n)) * np.exp(2j * np.pi * t * k / n)\n\n        # 2. Construct the orthonormal Haar DWT matrix W\n        W = np.zeros((n, n))\n        scale_indices = {}\n        \n        # Scale s=0: Scaling vector phi\n        W[:, 0] = 1 / np.sqrt(n)\n        scale_indices[0] = [0]\n        col_idx = 1\n        \n        # Scales s=1 to J: Wavelet vectors\n        # Ordered from finest (s=1) to coarsest (s=J)\n        for s in range(1, J + 1):\n            L_s = 2**s\n            num_wavelets = n // L_s\n            current_scale_cols = []\n            for k_trans in range(num_wavelets):\n                psi = np.zeros(n)\n                start = k_trans * L_s\n                mid = start + L_s // 2\n                end = (k_trans + 1) * L_s\n                \n                psi[start:mid] = 1 / np.sqrt(L_s)\n                psi[mid:end] = -1 / np.sqrt(L_s)\n                \n                W[:, col_idx] = psi\n                current_scale_cols.append(col_idx)\n                col_idx += 1\n            scale_indices[s] = current_scale_cols\n\n        # Verification step (for correctness, not part of output)\n        # assert np.allclose(F.conj().T @ F, np.identity(n))\n        # assert np.allclose(W.T @ W, np.identity(n))\n\n        # 3. Compute C = F* W and the empirical mutual coherence\n        C = F.conj().T @ W\n        C_abs = np.abs(C)\n        hat_mu = np.max(C_abs)\n\n        # 4. Per-scale analysis\n        scale_means = []\n        scale_maxs = []\n        \n        # Analysis is over scales s = 0, 1, ..., J\n        for s in range(J + 1):\n            cols = scale_indices[s]\n            # Get the sub-matrix of |C| for the current scale\n            C_sub = C_abs[:, cols]\n            \n            # gamma_j is the max of each column\n            gammas = np.max(C_sub, axis=0)\n            \n            scale_means.append(np.mean(gammas))\n            scale_maxs.append(np.max(gammas))\n            \n        # 5. Format results\n        hat_mu_rounded = round(hat_mu, 12)\n        means_rounded = [round(m, 12) for m in scale_means]\n        maxs_rounded = [round(m, 12) for m in maxs_rounded]\n\n        result_for_n = [n, hat_mu_rounded, means_rounded, maxs_rounded]\n        all_results.append(result_for_n)\n\n    # Final print statement must match the specified format.\n    # The standard string representation of a list is used.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "最后，我们将从固定的变换方法迈向自适应信号分析。本练习介绍了小波包变换（Wavelet Packet Transform），它提供了一个比标准DWT丰富得多的正交基库。你将实现Coifman-Wickerhauser算法来搜索这个基库，并根据指定的成本函数找到能够最稀疏地表示给定信号的“最佳基”，这为信号压缩和分析提供了强大的工具。",
            "id": "3493807",
            "problem": "考虑一个实值离散时间信号 $x \\in \\mathbb{R}^N$，其中 $N$ 是 $2$ 的幂。目标是使用 Haar 小波通过小波包变换（WPT）构建一个标准正交字典，并执行自适应最佳基选择，以最小化一个稀疏熵代价泛函。该问题必须从基本原理出发解决，这些原理基于标准正交变换、能量守恒、不相交系数集上的代价可分性，以及在完全二叉分解树上的动态规划。\n\n从以下基本定义和事实开始：\n\n1. Haar 低通和高通滤波器定义为 $h = \\left[\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}\\right]$ 和 $g = \\left[\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}}\\right]$。对于任意长度为偶数的向量 $v$，其元素为 $v[0],v[1],\\dots,v[m-1]$，双通道 Haar 分析产生两个长度为 $\\frac{m}{2}$ 的输出：\n   $$a[k] = \\frac{v[2k] + v[2k+1]}{\\sqrt{2}}, \\quad d[k] = \\frac{v[2k] - v[2k+1]}{\\sqrt{2}}, \\quad k = 0,1,\\dots,\\frac{m}{2}-1.$$\n   此变换是标准正交的，因此能量守恒，即 $\\|v\\|_2^2 = \\|a\\|_2^2 + \\|d\\|_2^2$。\n\n2. 小波包变换（WPT）构建一个系数向量的完全二叉树。第 $0$ 层的根节点是 $x$ 本身。第 $\\ell$ 层的每个节点包含一个长度为 $N / 2^\\ell$ 的系数向量。其在第 $\\ell+1$ 层的两个子节点是通过对该节点的向量应用上述方程得到的，产生两个长度均为 $N / 2^{\\ell+1}$ 的子向量。该分解过程持续到第 $J = \\log_2 N$ 层，此时所有叶节点的向量长度为 $1$。\n\n3. 对于一个非零向量 $v \\in \\mathbb{R}^m$，定义稀疏熵代价泛函为\n   $$C_\\alpha(v) = \\alpha \\|v\\|_1 + (1-\\alpha) H(v),$$\n   其中 $\\alpha \\in [0,1]$，$H(v)$ 是 $v$ 的归一化能量分布的香农熵（Shannon entropy），即，设 $E = \\sum_{i=1}^m v_i^2$ 和 $p_i = \\frac{v_i^2}{E}$，定义\n   $$H(v) = -\\sum_{i=1}^m p_i \\log(p_i + \\varepsilon),$$\n   其中 $\\varepsilon = 10^{-12}$。如果 $E=0$，则定义 $C_\\alpha(v)=0$。对数为自然对数。\n\n4. 在完整 WPT 树上的最佳基选择定义为：在每个节点处选择保留该节点不分裂（产生其自身系数向量的代价），或分裂成其两个子节点（产生子节点最优代价之和），以使总代价最小化。因为代价在不相交的系数集上是可加的，并且变换是标准正交的，所以在树上使用动态规划，通过比较不分裂节点的代价与子节点最优代价之和，可以得到全局最优基。在代价相等的情况下，选择不分裂节点，以偏好更粗糙的表示。\n\n实现以下编程任务：\n\n1. 对于任何长度为 $N$（$N$ 是 $2$ 的幂）的输入信号 $x$，使用上面给出的 Haar 对偶公式构建完整的小波包变换树。不使用边界扩展；精确应用对偶公式，使得第 $\\ell$ 层上长度为 $N/2^\\ell$ 的每个节点都产生两个长度为 $N/2^{\\ell+1}$ 的子节点。\n\n2. 如上定义节点代价 $C_\\alpha(v)$。执行自底向上的动态规划，在每个节点处决定是保留不分裂还是分裂成其子节点，选择使代价最小化的选项。在两种选项代价相等的情况下，选择保留不分裂。返回总的最优代价和所选最佳基中选定节点的数量（即，保持不分裂的节点计数）。\n\n3. 使用以下信号和参数的测试套件。在所有情况下，设置 $\\varepsilon = 10^{-12}$ 并分解到最大深度 $J = \\log_2 N$。\n\n   - 测试用例 1（理想路径，平滑与稀疏混合）：\n     - $N = 64$.\n     - 对于 $n = 0,1,\\dots,63$，定义\n       $$x[n] = \\sin\\left(\\frac{2\\pi \\cdot 3 \\cdot n}{64}\\right) + 0.5\\left(\\delta[n - 10] + \\delta[n - 45]\\right),$$\n       其中 $\\delta[\\cdot]$ 是克罗内克 delta 函数。\n     - $\\alpha = 0.5$.\n\n   - 测试用例 2（边界情况，平凡结构）：\n     - $N = 64$.\n     - 对所有 $n$，$x[n] = 1$。\n     - $\\alpha = 0.7$.\n\n   - 测试用例 3（边缘情况，随机内容）：\n     - $N = 64$.\n     - $x[n]$ 是来自高斯分布 $\\mathcal{N}(0,1)$ 的独立同分布样本，使用固定的随机种子 $s = 0$ 生成。\n     - $\\alpha = 0$.\n\n   - 测试用例 4（短长度边界，高度局部化）：\n     - $N = 8$.\n     - 如果 $n = 4$，则 $x[n] = 1$；否则 $x[n] = 0$。\n     - $\\alpha = 0.5$.\n\n4. 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。对于每个测试用例，首先输出最佳基中选定节点的整数数量，然后是总的最优代价（浮点数，四舍五入到六位小数）。因此，对于四个测试用例，输出必须是\n   $$[n_1, c_1, n_2, c_2, n_3, c_3, n_4, c_4],$$\n   其中 $n_i$ 是整数，$c_i$ 是测试用例 $i$ 的浮点数（四舍五入到六位小数）。\n\n所有量都是无量纲的；不涉及物理单位。三角函数中的角度以弧度为单位。请确保使用指定的 $\\varepsilon$ 实现 $\\log$ 的数值稳定性，并如前所述，将零能量向量的熵定义为 $0$。",
            "solution": "该问题要求使用 Haar 小波通过小波包变换（WPT）为信号实现一个自适应最佳基选择算法。选择准则是最小化一个指定的稀疏熵代价泛函。解决方案是通过在完整 WPT 分解树上使用动态规划方法找到的。该过程可分为三个主要概念阶段：构建基库、定义代价度量和执行优化。\n\n### 1. 作为标准正交基库的小波包变换\n\n小波包变换（WPT）生成一个标准正交基的字典。对于信号 $x \\in \\mathbb{R}^N$（其中 $N$ 是 $2$ 的幂），我们可以构建一个系数向量的完全二叉树。\n\n-   **树的生成**：树的根节点位于 $\\ell=0$ 层，是信号 $x$ 本身。位于任意 $\\ell$ 层的节点，包含一个长度为 $m = N/2^\\ell$ 的向量 $v$，该节点可分解为位于 $\\ell+1$ 层的两个子节点。该分解是通过应用一个双通道标准正交滤波器组实现的。对于 Haar 小波，低通滤波器为 $h = \\left[\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}\\right]$，高通滤波器为 $g = \\left[\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}}\\right]$。分解公式如下：\n    -   近似（低通）系数：$$a[k] = \\frac{v[2k] + v[2k+1]}{\\sqrt{2}}$$\n    -   细节（高通）系数：$$d[k] = \\frac{v[2k] - v[2k+1]}{\\sqrt{2}}$$\n    对于 $k = 0, 1, \\dots, \\frac{m}{2}-1$。得到的向量 $a$ 和 $d$ 的长度均为 $m/2$，并构成两个子节点。此过程重复进行，直到达到最大深度 $J = \\log_2 N$，此时叶节点包含长度为 $1$ 的向量。\n\n-   **标准正交基**：该完全二叉树包含了一个丰富的 $\\mathbb{R}^N$ 标准正交基库。任何其对应时频瓦片能够划分整个时频平面的节点集合，都可以形成一个有效的基。在树结构中，这对应于任何一组终端节点，这些节点是被剪枝分支的兄弟节点，并且它们自身在所选基中没有后代。根节点本身构成一个基（$x$ 的标准基表示）。第 $J$ 层的所有叶节点构成另一个基（完全小波包分解）。该算法的目标就是从这个库中选择最优基。\n\n### 2. 稀疏熵代价泛函\n\n要选择一个“最佳”基，我们需要一个定量的可取性度量。问题为树中的任何系数向量 $v \\in \\mathbb{R}^m$ 定义了一个代价泛函 $C_\\alpha(v)$。该泛函旨在偏好那些信号能量集中在少数几个大数值系数上的表示（即稀疏表示）。\n\n对于一个非零向量 $v$，其代价为：\n$$C_\\alpha(v) = \\alpha \\|v\\|_1 + (1-\\alpha) H(v)$$\n其中 $\\alpha \\in [0,1]$。\n\n-   **$L_1$ 范数 ($ \\|v\\|_1 = \\sum_{i=1}^m |v_i|$)**：该分量是稀疏性的一个著名凸代理。最小化 $L_1$ 范数会鼓励产生许多系数接近于零的解。\n\n-   **香农熵 ($H(v)$)**：该分量衡量信号能量分布的“平坦度”或“离散度”。其定义为：\n    $$H(v) = -\\sum_{i=1}^m p_i \\log(p_i + \\varepsilon)$$\n    其中 $p_i = v_i^2 / E$ 是第 $i$ 个系数的归一化能量，$E = \\|v\\|_2^2 = \\sum_{i=1}^m v_i^2$ 是向量的总能量。能量集中在单个系数上的信号具有非常低的熵，而能量均匀分布在所有系数上的信号具有高熵。小常数 $\\varepsilon = 10^{-12}$ 通过防止计算 $\\log(0)$ 来确保数值稳定性。\n\n如果能量 $E=0$，则代价定义为 $C_\\alpha(v)=0$。参数 $\\alpha$ 平衡了两种稀疏度量之间的权衡。\n\n### 3. 通过动态规划进行最佳基选择\n\n高效找到全局最优基的关键在于代价泛函在不相交系数集上的可加性，这是由变换的标准正交性所保证的。这使得我们可以使用一种动态规划算法，通常称为 Coifman-Wickerhauser 算法。\n\n该算法在 WPT 树上自底向上进行：\n\n1.  **初始化（叶节点）**：对于最大深度 $J = \\log_2 N$ 的每个叶节点，不存在进一步分裂的可能性。其最优代价就是其自身系数向量的代价，即 $C_\\alpha(v)$。\n\n2.  **递归步骤（自底向上遍历）**：我们从 $\\ell = J-1$ 层向上移动到 $\\ell = 0$ 层的根节点。对于 $\\ell$ 层的每个节点 $P$ 及其在 $\\ell+1$ 层的子节点 $C_1$ 和 $C_2$：\n    -   我们获取其子节点为根的子树已经计算出的最优代价，记为 $C_{\\text{opt}}(C_1)$ 和 $C_{\\text{opt}}(C_2)$。节点 $P$ 的“分裂”代价是这些代价之和：$C_{\\text{split}} = C_{\\text{opt}}(C_1) + C_{\\text{opt}}(C_2)$。\n    -   我们计算节点 $P$ 的“不分裂”代价，即用 $P$ 自身的系数向量表示信号子空间的代价：$C_{\\text{unsplit}} = C_\\alpha(v_P)$。\n    -   **决策**：我们比较这两个代价。根据问题的平局处理规则：\n        -   如果 $C_{\\text{unsplit}} \\le C_{\\text{split}}$，我们决定在此节点处剪枝。以 $P$ 为根的子树的最优代价是 $C_{\\text{opt}}(P) = C_{\\text{unsplit}}$，我们将 $P$ 标记为终端节点（不分裂）。\n        -   否则，如果 $C_{\\text{unsplit}} > C_{\\text{split}}$，我们保留分裂。最优代价是 $C_{\\text{opt}}(P) = C_{\\text{split}}$，我们将 $P$ 标记为非终端节点（分裂）。\n\n3.  **最终结果**：此过程持续进行，直到到达根节点（$\\ell=0, \\text{index}=0$）。值 $C_{\\text{opt}}(\\text{root})$ 是 WPT 库中任何基的最小可能代价。\n\n为了找出所选最佳基中的节点数量，我们对树进行一次最终的自顶向下遍历，遵循动态规划阶段做出的决策。从根节点开始，如果一个节点被标记为“不分裂”，我们对其计数并停止遍历该分支。如果它被标记为“分裂”，我们递归地下降到其两个子节点并对它们的节点数求和。这次遍历恰好计算了最优基树的终端节点数。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the entire process.\n    It defines test cases, runs the best-basis selection algorithm\n    for each, and formats the final output.\n    \"\"\"\n    \n    # Global constants defined in the problem\n    EPSILON = 1e-12\n    SQRT2 = np.sqrt(2.0)\n\n    # --- Helper Functions ---\n\n    def generate_signal(case_id, N):\n        \"\"\"Generates the input signal x for a given test case.\"\"\"\n        n_indices = np.arange(N)\n        if case_id == 1:\n            # x[n] = sin(2*pi*3*n/64) + 0.5 * (delta[n-10] + delta[n-45])\n            x = np.sin(2 * np.pi * 3 * n_indices / N)\n            x[10] += 0.5\n            x[45] += 0.5\n            return x\n        elif case_id == 2:\n            # x[n] = 1 for all n\n            return np.ones(N)\n        elif case_id == 3:\n            # N(0,1) with seed 0\n            np.random.seed(0)\n            return np.random.randn(N)\n        elif case_id == 4:\n            # x[n] = delta[n-4]\n            x = np.zeros(N)\n            x[4] = 1.0\n            return x\n        return None\n\n    def cost_functional(v, alpha):\n        \"\"\"\n        Computes the sparsity-entropy cost C_alpha(v) for a vector v.\n        \"\"\"\n        v = np.asarray(v)\n        energy = np.sum(v**2)\n\n        if energy  EPSILON:  # Treat as zero energy\n            return 0.0\n\n        l1_norm = np.sum(np.abs(v))\n        \n        p = (v**2) / energy\n        # Filter p_i that are effectively zero to avoid adding log(epsilon)\n        p_nonzero = p[p  0] \n        entropy = -np.sum(p_nonzero * np.log(p_nonzero + EPSILON))\n\n        return alpha * l1_norm + (1 - alpha) * entropy\n\n    def haar_analysis(v):\n        \"\"\"\n        Performs one level of Haar wavelet decomposition using vectorized operations.\n        \"\"\"\n        a = (v[0::2] + v[1::2]) / SQRT2\n        d = (v[0::2] - v[1::2]) / SQRT2\n        return a, d\n\n    def find_best_basis_and_cost(x, N, alpha):\n        \"\"\"\n        Implements the main WPT and best-basis selection algorithm.\n        \"\"\"\n        J = int(np.log2(N))\n\n        # 1. Construct the full Wavelet Packet Transform tree\n        # The tree is stored in a dictionary mapping (level, index) to the coefficient vector.\n        tree = {}\n        tree[(0, 0)] = x\n        for level in range(J):\n            num_nodes_in_level = 1  level\n            for index in range(num_nodes_in_level):\n                parent_vector = tree.get((level, index))\n                if parent_vector is not None:\n                    a, d = haar_analysis(parent_vector)\n                    tree[(level + 1, 2 * index)] = a\n                    tree[(level + 1, 2 * index + 1)] = d\n\n        # 2. Perform bottom-up dynamic programming\n        optimal_costs = {}\n        is_split_decision = {}  # Stores bool: True if node is split, False if not.\n\n        # Initialization at the deepest level (leaves)\n        for index in range(1  J):\n            leaf_vector = tree[(J, index)]\n            optimal_costs[(J, index)] = cost_functional(leaf_vector, alpha)\n            \n        # Iterate upwards from level J-1 to 0\n        for level in range(J - 1, -1, -1):\n            num_nodes_in_level = 1  level\n            for index in range(num_nodes_in_level):\n                # Cost if we do not split this node\n                node_vector = tree[(level, index)]\n                cost_unsplit = cost_functional(node_vector, alpha)\n\n                # Cost if we split (sum of optimal costs of children)\n                child1_key = (level + 1, 2 * index)\n                child2_key = (level + 1, 2 * index + 1)\n                cost_split = optimal_costs[child1_key] + optimal_costs[child2_key]\n                \n                # Decision logic with tie-breaking rule\n                if cost_unsplit = cost_split:\n                    optimal_costs[(level, index)] = cost_unsplit\n                    is_split_decision[(level, index)] = False\n                else:\n                    optimal_costs[(level, index)] = cost_split\n                    is_split_decision[(level, index)] = True\n        \n        total_optimal_cost = optimal_costs[(0, 0)]\n\n        # 3. Count nodes in the chosen best basis by traversing the decision tree\n        def count_basis_nodes(level, index):\n            # If a node is not marked as split, it's a terminal node in the best basis.\n            # Leaves (level J) are terminal by definition and won't be in is_split_decision.\n            if not is_split_decision.get((level, index), False):\n                return 1\n            \n            # If it is split, recurse on its children and sum their counts.\n            count = count_basis_nodes(level + 1, 2 * index) + \\\n                    count_basis_nodes(level + 1, 2 * index + 1)\n            return count\n\n        num_selected_nodes = count_basis_nodes(0, 0)\n        \n        return num_selected_nodes, total_optimal_cost\n\n    # --- Main Execution Loop ---\n\n    test_cases = [\n        {'id': 1, 'N': 64, 'alpha': 0.5},\n        {'id': 2, 'N': 64, 'alpha': 0.7},\n        {'id': 3, 'N': 64, 'alpha': 0.0},\n        {'id': 4, 'N': 8,  'alpha': 0.5},\n    ]\n\n    results = []\n    for case in test_cases:\n        signal = generate_signal(case['id'], case['N'])\n        n_nodes, cost = find_best_basis_and_cost(signal, case['N'], case['alpha'])\n        \n        results.append(str(n_nodes))\n        results.append(f\"{cost:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}