{
    "hands_on_practices": [
        {
            "introduction": "Understanding how a wavelet transform induces sparsity begins with mastering its fundamental mechanics. This exercise provides a concrete, step-by-step calculation of a multi-level Discrete Wavelet Transform (DWT) for a simple piecewise-constant signal. By manually applying the Haar filters, you will directly observe how the transform compacts the signal's energy into a few approximation coefficients, rendering the detail subbands sparse and revealing the core principle of wavelet-based compression .",
            "id": "3493857",
            "problem": "Consider a real-valued length-$16$ discrete-time signal $x[n]$ defined for $n \\in \\{0,1,\\dots,15\\}$ by the sequence\n$$\nx = \\left[5,\\,5,\\,5,\\,5,\\,2,\\,2,\\,2,\\,2,\\,0,\\,0,\\,8,\\,8,\\,8,\\,8,\\,8,\\,8\\right].\n$$\nLet the analysis filters for the orthonormal two-channel filter bank be specified as the Haar filters\n$$\nh = \\left[\\frac{1}{\\sqrt{2}},\\,\\frac{1}{\\sqrt{2}}\\right], \\qquad g = \\left[\\frac{1}{\\sqrt{2}},\\, -\\frac{1}{\\sqrt{2}}\\right],\n$$\nand use symmetric boundary extension where needed. Perform two levels of the Discrete Wavelet Transform (DWT), defined as follows: the level-$1$ approximation and detail coefficients are\n$$\na_{1}[n] = h_{0}\\,x[2n] + h_{1}\\,x[2n+1], \\qquad d_{1}[n] = g_{0}\\,x[2n] + g_{1}\\,x[2n+1],\n$$\nfor $n = 0,1,\\dots,7$. The level-$2$ coefficients are obtained by applying the same $h$ and $g$ to the level-$1$ approximation $a_{1}$:\n$$\na_{2}[n] = h_{0}\\,a_{1}[2n] + h_{1}\\,a_{1}[2n+1], \\qquad d_{2}[n] = g_{0}\\,a_{1}[2n] + g_{1}\\,a_{1}[2n+1],\n$$\nfor $n = 0,1,2,3$.\n\nCarry out these computations and report the three subband coefficient vectors $a_{2}$, $d_{2}$, and $d_{1}$. Finally, compute the total energy of the level-$2$ detail subband,\n$$\nE_{d_{2}} = \\sum_{n=0}^{3} \\left(d_{2}[n]\\right)^{2},\n$$\nand provide this value as the final answer. Express the final answer as a real number with no rounding.",
            "solution": "The problem requires the computation of a two-level Discrete Wavelet Transform (DWT) of a given discrete-time signal $x[n]$ and subsequently the energy of the level-$2$ detail coefficients. The signal is of length $N=16$ and given by the sequence:\n$$x = \\left[5,\\,5,\\,5,\\,5,\\,2,\\,2,\\,2,\\,2,\\,0,\\,0,\\,8,\\,8,\\,8,\\,8,\\,8,\\,8\\right]$$\nThe analysis filters for the orthonormal Haar wavelet transform are the low-pass filter $h$ and the high-pass filter $g$:\n$$h = \\left[\\frac{1}{\\sqrt{2}},\\,\\frac{1}{\\sqrt{2}}\\right] \\quad \\implies \\quad h_0 = \\frac{1}{\\sqrt{2}}, h_1 = \\frac{1}{\\sqrt{2}}$$\n$$g = \\left[\\frac{1}{\\sqrt{2}},\\, -\\frac{1}{\\sqrt{2}}\\right] \\quad \\implies \\quad g_0 = \\frac{1}{\\sqrt{2}}, g_1 = -\\frac{1}{\\sqrt{2}}$$\nThe problem specifies that boundary effects are handled by symmetric extension, but given the filter length of $2$ and the signal length being a power of two, no extension is required for this specific calculation.\n\nFirst, we compute the level-$1$ approximation coefficients $a_1[n]$ and detail coefficients $d_1[n]$ for $n \\in \\{0, 1, \\dots, 7\\}$. The governing equations are:\n$$a_{1}[n] = h_{0}\\,x[2n] + h_{1}\\,x[2n+1] = \\frac{1}{\\sqrt{2}}(x[2n] + x[2n+1])$$\n$$d_{1}[n] = g_{0}\\,x[2n] + g_{1}\\,x[2n+1] = \\frac{1}{\\sqrt{2}}(x[2n] - x[2n+1])$$\nWe compute each coefficient as follows:\n$a_1[0] = \\frac{1}{\\sqrt{2}}(x[0]+x[1]) = \\frac{1}{\\sqrt{2}}(5+5) = \\frac{10}{\\sqrt{2}} = 5\\sqrt{2}$\n$d_1[0] = \\frac{1}{\\sqrt{2}}(x[0]-x[1]) = \\frac{1}{\\sqrt{2}}(5-5) = 0$\n$a_1[1] = \\frac{1}{\\sqrt{2}}(x[2]+x[3]) = \\frac{1}{\\sqrt{2}}(5+5) = \\frac{10}{\\sqrt{2}} = 5\\sqrt{2}$\n$d_1[1] = \\frac{1}{\\sqrt{2}}(x[2]-x[3]) = \\frac{1}{\\sqrt{2}}(5-5) = 0$\n$a_1[2] = \\frac{1}{\\sqrt{2}}(x[4]+x[5]) = \\frac{1}{\\sqrt{2}}(2+2) = \\frac{4}{\\sqrt{2}} = 2\\sqrt{2}$\n$d_1[2] = \\frac{1}{\\sqrt{2}}(x[4]-x[5]) = \\frac{1}{\\sqrt{2}}(2-2) = 0$\n$a_1[3] = \\frac{1}{\\sqrt{2}}(x[6]+x[7]) = \\frac{1}{\\sqrt{2}}(2+2) = \\frac{4}{\\sqrt{2}} = 2\\sqrt{2}$\n$d_1[3] = \\frac{1}{\\sqrt{2}}(x[6]-x[7]) = \\frac{1}{\\sqrt{2}}(2-2) = 0$\n$a_1[4] = \\frac{1}{\\sqrt{2}}(x[8]+x[9]) = \\frac{1}{\\sqrt{2}}(0+0) = 0$\n$d_1[4] = \\frac{1}{\\sqrt{2}}(x[8]-x[9]) = \\frac{1}{\\sqrt{2}}(0-0) = 0$\n$a_1[5] = \\frac{1}{\\sqrt{2}}(x[10]+x[11]) = \\frac{1}{\\sqrt{2}}(8+8) = \\frac{16}{\\sqrt{2}} = 8\\sqrt{2}$\n$d_1[5] = \\frac{1}{\\sqrt{2}}(x[10]-x[11]) = \\frac{1}{\\sqrt{2}}(8-8) = 0$\n$a_1[6] = \\frac{1}{\\sqrt{2}}(x[12]+x[13]) = \\frac{1}{\\sqrt{2}}(8+8) = \\frac{16}{\\sqrt{2}} = 8\\sqrt{2}$\n$d_1[6] = \\frac{1}{\\sqrt{2}}(x[12]-x[13]) = \\frac{1}{\\sqrt{2}}(8-8) = 0$\n$a_1[7] = \\frac{1}{\\sqrt{2}}(x[14]+x[15]) = \\frac{1}{\\sqrt{2}}(8+8) = \\frac{16}{\\sqrt{2}} = 8\\sqrt{2}$\n$d_1[7] = \\frac{1}{\\sqrt{2}}(x[14]-x[15]) = \\frac{1}{\\sqrt{2}}(8-8) = 0$\n\nThe resulting level-$1$ coefficient vectors are:\n$$a_1 = \\left[5\\sqrt{2},\\, 5\\sqrt{2},\\, 2\\sqrt{2},\\, 2\\sqrt{2},\\, 0,\\, 8\\sqrt{2},\\, 8\\sqrt{2},\\, 8\\sqrt{2}\\right]$$\n$$d_1 = \\left[0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0\\right]$$\n\nNext, we compute the level-$2$ coefficients by applying the same filters to the level-$1$ approximation vector $a_1$. The level-$2$ approximation coefficients $a_2[n]$ and detail coefficients $d_2[n]$ are computed for $n \\in \\{0, 1, 2, 3\\}$:\n$$a_{2}[n] = h_{0}\\,a_{1}[2n] + h_{1}\\,a_{1}[2n+1] = \\frac{1}{\\sqrt{2}}(a_{1}[2n] + a_{1}[2n+1])$$\n$$d_{2}[n] = g_{0}\\,a_{1}[2n] + g_{1}\\,a_{1}[2n+1] = \\frac{1}{\\sqrt{2}}(a_{1}[2n] - a_{1}[2n+1])$$\nWe compute each coefficient:\n$a_2[0] = \\frac{1}{\\sqrt{2}}(a_1[0]+a_1[1]) = \\frac{1}{\\sqrt{2}}(5\\sqrt{2}+5\\sqrt{2}) = \\frac{1}{\\sqrt{2}}(10\\sqrt{2}) = 10$\n$d_2[0] = \\frac{1}{\\sqrt{2}}(a_1[0]-a_1[1]) = \\frac{1}{\\sqrt{2}}(5\\sqrt{2}-5\\sqrt{2}) = 0$\n$a_2[1] = \\frac{1}{\\sqrt{2}}(a_1[2]+a_1[3]) = \\frac{1}{\\sqrt{2}}(2\\sqrt{2}+2\\sqrt{2}) = \\frac{1}{\\sqrt{2}}(4\\sqrt{2}) = 4$\n$d_2[1] = \\frac{1}{\\sqrt{2}}(a_1[2]-a_1[3]) = \\frac{1}{\\sqrt{2}}(2\\sqrt{2}-2\\sqrt{2}) = 0$\n$a_2[2] = \\frac{1}{\\sqrt{2}}(a_1[4]+a_1[5]) = \\frac{1}{\\sqrt{2}}(0+8\\sqrt{2}) = \\frac{1}{\\sqrt{2}}(8\\sqrt{2}) = 8$\n$d_2[2] = \\frac{1}{\\sqrt{2}}(a_1[4]-a_1[5]) = \\frac{1}{\\sqrt{2}}(0-8\\sqrt{2}) = -8$\n$a_2[3] = \\frac{1}{\\sqrt{2}}(a_1[6]+a_1[7]) = \\frac{1}{\\sqrt{2}}(8\\sqrt{2}+8\\sqrt{2}) = \\frac{1}{\\sqrt{2}}(16\\sqrt{2}) = 16$\n$d_2[3] = \\frac{1}{\\sqrt{2}}(a_1[6]-a_1[7]) = \\frac{1}{\\sqrt{2}}(8\\sqrt{2}-8\\sqrt{2}) = 0$\n\nThe computed subband coefficient vectors as requested are:\n$$a_2 = \\left[10,\\, 4,\\, 8,\\, 16\\right]$$\n$$d_2 = \\left[0,\\, 0,\\, -8,\\, 0\\right]$$\n$$d_1 = \\left[0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0,\\, 0\\right]$$\n\nFinally, we compute the total energy of the level-$2$ detail subband, $E_{d_{2}}$:\n$$E_{d_{2}} = \\sum_{n=0}^{3} \\left(d_{2}[n]\\right)^{2}$$\nSubstituting the values from the $d_2$ vector:\n$$E_{d_{2}} = (0)^{2} + (0)^{2} + (-8)^{2} + (0)^{2} = 0 + 0 + 64 + 0 = 64$$\nThe energy of the level-$2$ detail subband is $64$.",
            "answer": "$$\\boxed{64}$$"
        },
        {
            "introduction": "Moving from one-dimensional signals to two-dimensional data like images is a critical step in applying wavelet theory. This practice extends the DWT to 2D by applying the transform separably, a technique fundamental to image processing. By analyzing a simple image patch with a distinct edge, you will explore how the 2D DWT decomposes the image into subbands that isolate features based on their orientation, providing a sparse representation of directional structures .",
            "id": "3493867",
            "problem": "Consider a two-dimensional discrete wavelet transform (DWT) using the Haar wavelet on a small image patch. The Haar scaling filter and wavelet filter are defined as $h = \\left[\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}\\right]$ and $g = \\left[\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}}\\right]$, respectively. The two-dimensional transform is applied separably: first convolve each row with $h$ and $g$ and downsample by $2$ along the horizontal dimension to obtain row low-pass and high-pass halves; next, convolve each column of these halves with $h$ and $g$ and downsample by $2$ along the vertical dimension to obtain the four level-$1$ subbands. Use the convention that $LL$ denotes low-pass along rows then low-pass along columns, $LH$ denotes low-pass along rows then high-pass along columns, $HL$ denotes high-pass along rows then low-pass along columns, and $HH$ denotes high-pass along rows then high-pass along columns. The level-$2$ transform is formed by applying the same separable operation to the $LL_{1}$ subband only.\n\nLet the image patch be\n$$\nX = \\begin{pmatrix}\n4 & 4 & 4 & 4 \\\\\n4 & 4 & 4 & 4 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0\n\\end{pmatrix}.\n$$\nCompute the first two scales (levels) of the Haar DWT coefficients: the level-$1$ subbands $LL_{1}$, $LH_{1}$, $HL_{1}$, $HH_{1}$ (each of size $2 \\times 2$) and the level-$2$ subbands $LL_{2}$, $LH_{2}$, $HL_{2}$, $HH_{2}$ (each a scalar). For each subband, define its energy as the sum of squares of its coefficients. Let the dominant detail subband be the subband with the largest energy among $\\{LH_{1}, HL_{1}, HH_{1}, LH_{2}, HL_{2}, HH_{2}\\}$. Let $E_{\\text{total}}$ be the sum of squares of all $16$ entries of $X$. Define\n$$\nS \\triangleq \\frac{E_{\\text{dominant detail}}}{E_{\\text{total}}}.\n$$\nProvide the value of $S$ as your final answer. Express the final answer as a decimal rounded to four significant figures.",
            "solution": "The solution involves computing a two-level 2D Discrete Wavelet Transform (DWT) of the image patch $X$, finding the energies of all detail subbands, and then calculating the ratio of the maximum detail energy to the total image energy.\n\n**Step 1: Calculate Total Energy $E_{\\text{total}}$**\nThe total energy is the sum of squared pixel values. The image patch $X$ has 8 pixels with value 4 and 8 pixels with value 0.\n$$\nX = \\begin{pmatrix}\n4 & 4 & 4 & 4 \\\\\n4 & 4 & 4 & 4 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0\n\\end{pmatrix}\n$$\n$$\nE_{\\text{total}} = \\sum_{i,j} X_{ij}^2 = 8 \\times 4^2 + 8 \\times 0^2 = 8 \\times 16 = 128.\n$$\n\n**Step 2: Level-1 2D DWT Calculation**\nThe 2D transform is applied separably. The 1D Haar transform of a pair $(u, v)$ yields a low-pass coefficient $(u+v)/\\sqrt{2}$ and a high-pass coefficient $(u-v)/\\sqrt{2}$.\n\n*   **Row-wise transform:** We apply the 1D transform to each row of $X$.\n    - Rows 1 and 2, $[4, 4, 4, 4]$, are transformed into a low-pass part $\\left[\\frac{4+4}{\\sqrt{2}}, \\frac{4+4}{\\sqrt{2}}\\right] = [4\\sqrt{2}, 4\\sqrt{2}]$ and a high-pass part $\\left[\\frac{4-4}{\\sqrt{2}}, \\frac{4-4}{\\sqrt{2}}\\right] = [0, 0]$.\n    - Rows 3 and 4, $[0, 0, 0, 0]$, are transformed into a low-pass part $[0, 0]$ and a high-pass part $[0, 0]$.\n    This yields intermediate matrices for the low-pass and high-pass row outputs:\n    $$\n    X_L = \\begin{pmatrix} 4\\sqrt{2} & 4\\sqrt{2} \\\\ 4\\sqrt{2} & 4\\sqrt{2} \\\\ 0 & 0 \\\\ 0 & 0 \\end{pmatrix}, \\quad X_H = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\\\ 0 & 0 \\\\ 0 & 0 \\end{pmatrix}.\n    $$\n\n*   **Column-wise transform:** We now transform the columns of $X_L$ and $X_H$.\n    - Transforming the columns of $X_L$: Each column is $[4\\sqrt{2}, 4\\sqrt{2}, 0, 0]^T$. The transform gives a low-pass part $\\left[\\frac{4\\sqrt{2}+4\\sqrt{2}}{\\sqrt{2}}, \\frac{0+0}{\\sqrt{2}}\\right] = [8, 0]$ and a high-pass part $\\left[\\frac{4\\sqrt{2}-4\\sqrt{2}}{\\sqrt{2}}, \\frac{0-0}{\\sqrt{2}}\\right] = [0, 0]$. This produces the $LL_1$ and $LH_1$ subbands:\n    $$\n    LL_1 = \\begin{pmatrix} 8 & 8 \\\\ 0 & 0 \\end{pmatrix}, \\quad LH_1 = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}.\n    $$\n    - Transforming the columns of $X_H$: Since $X_H$ is a zero matrix, the transform results in zero matrices for the $HL_1$ and $HH_1$ subbands:\n    $$\n    HL_1 = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}, \\quad HH_1 = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}.\n    $$\n\n**Step 3: Level-2 2D DWT Calculation**\nThe level-2 transform is applied to the $2 \\times 2$ subband $LL_1$.\n\n*   **Row-wise transform on $LL_1$:**\n    - Row 1, $[8, 8]$, transforms to low-pass $[\\frac{8+8}{\\sqrt{2}}] = [8\\sqrt{2}]$ and high-pass $[\\frac{8-8}{\\sqrt{2}}] = [0]$.\n    - Row 2, $[0, 0]$, transforms to low-pass $[0]$ and high-pass $[0]$.\n    The intermediate matrices are $LL_{1,L} = \\begin{pmatrix} 8\\sqrt{2} \\\\ 0 \\end{pmatrix}$ and $LL_{1,H} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n\n*   **Column-wise transform:**\n    - Transforming the column of $LL_{1,L}$: The vector $[8\\sqrt{2}, 0]^T$ transforms to a low-pass scalar $LL_2 = \\frac{8\\sqrt{2}+0}{\\sqrt{2}} = 8$ and a high-pass scalar $LH_2 = \\frac{8\\sqrt{2}-0}{\\sqrt{2}} = 8$.\n    - Transforming the column of $LL_{1,H}$: The vector $[0, 0]^T$ transforms to $HL_2 = 0$ and $HH_2 = 0$.\n\nThe level-2 subbands are: $LL_2=8$, $LH_2=8$, $HL_2=0$, $HH_2=0$.\n\n**Step 4: Determine the Dominant Detail Subband Energy**\nThe energy of a subband is the sum of squares of its coefficients. We examine the six detail subbands:\n- $E(LH_1) = 0^2+0^2+0^2+0^2 = 0$\n- $E(HL_1) = 0^2+0^2+0^2+0^2 = 0$\n- $E(HH_1) = 0^2+0^2+0^2+0^2 = 0$\n- $E(LH_2) = 8^2 = 64$\n- $E(HL_2) = 0^2 = 0$\n- $E(HH_2) = 0^2 = 0$\n\nThe maximum energy among the detail subbands is $E_{\\text{dominant detail}} = 64$.\n\n**Step 5: Compute the Final Value $S$**\nThe ratio $S$ is computed as:\n$$\nS = \\frac{E_{\\text{dominant detail}}}{E_{\\text{total}}} = \\frac{64}{128} = 0.5\n$$\nExpressed as a decimal with four significant figures, the answer is $0.5000$.",
            "answer": "$$\\boxed{0.5000}$$"
        },
        {
            "introduction": "While the standard DWT offers a powerful fixed representation, true optimization often requires adapting the transform to the unique structure of a signal. This advanced practice dives into the Wavelet Packet Transform (WPT), which generates a vast library of possible orthonormal bases, and tasks you with implementing an algorithm to select the \"best basis\". By minimizing a sparsity-promoting cost functional, you will create a signal-adaptive representation that is maximally sparse, a cornerstone of modern compression and analysis techniques .",
            "id": "3493807",
            "problem": "Consider a real-valued discrete-time signal $x \\in \\mathbb{R}^N$ with $N$ equal to a power of $2$. The goal is to construct an orthonormal dictionary via the Wavelet Packet Transform (WPT) using the Haar wavelet, and to perform adaptive best-basis selection that minimizes a sparsity-entropy cost functional. The problem must be solved from first principles grounded in orthonormal transforms, energy preservation, separability of cost across disjoint coefficient sets, and dynamic programming over a full binary decomposition tree.\n\nStart from the following fundamental definitions and facts:\n\n1. The Haar low-pass and high-pass filters are defined by $h = \\left[\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}\\right]$ and $g = \\left[\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}}\\right]$. For any even-length vector $v$ with entries $v[0],v[1],\\dots,v[m-1]$, the two-channel Haar analysis yields two length-$\\frac{m}{2}$ outputs:\n   $$a[k] = \\frac{v[2k] + v[2k+1]}{\\sqrt{2}}, \\quad d[k] = \\frac{v[2k] - v[2k+1]}{\\sqrt{2}}, \\quad k = 0,1,\\dots,\\frac{m}{2}-1.$$\n   This transform is orthonormal, and thus preserves energy, i.e., $\\|v\\|_2^2 = \\|a\\|_2^2 + \\|d\\|_2^2$.\n\n2. The Wavelet Packet Transform (WPT) constructs a full binary tree of coefficient vectors. The root at level $0$ is $x$ itself. Each node at level $\\ell$ holds a coefficient vector of length $N / 2^\\ell$. Its two children at level $\\ell+1$ are obtained by applying the above equations to that node’s vector, producing two children vectors each of length $N / 2^{\\ell+1}$. This decomposition continues until level $J = \\log_2 N$, where all leaves have length $1$.\n\n3. Define the sparsity-entropy cost functional for a nonzero vector $v \\in \\mathbb{R}^m$ as\n   $$C_\\alpha(v) = \\alpha \\|v\\|_1 + (1-\\alpha) H(v),$$\n   where $\\alpha \\in [0,1]$ and $H(v)$ is the Shannon entropy of the normalized energy distribution of $v$, namely, with $E = \\sum_{i=1}^m v_i^2$ and $p_i = \\frac{v_i^2}{E}$, define\n   $$H(v) = -\\sum_{i=1}^m p_i \\log(p_i + \\varepsilon),$$\n   with $\\varepsilon = 10^{-12}$. If $E=0$, define $C_\\alpha(v)=0$. The logarithm is the natural logarithm.\n\n4. The best-basis selection over the full WPT tree is defined by choosing, at each node, either to keep the node unsplit (incurring the cost of its own coefficient vector) or to split into its two children (incurring the sum of the children’s optimal costs), so as to minimize the total cost. Because the cost is additive over disjoint sets of coefficients and the transform is orthonormal, a dynamic programming on the tree that compares the unsplit-node cost to the sum of optimal children costs yields the globally optimal basis. In the case of equality, choose the unsplit node to favor coarser representations.\n\nImplement the following programmatic tasks:\n\n1. Construct the full Wavelet Packet Transform tree using the Haar pairwise formulas given above, for any input signal $x$ of length $N$ with $N$ a power of $2$. Use no boundary extension; apply the pairwise formulas exactly so that every node at level $\\ell$ of length $N/2^\\ell$ produces two children of length $N/2^{\\ell+1}$.\n\n2. Define the node cost $C_\\alpha(v)$ as above. Perform bottom-up dynamic programming to decide, at each node, whether to keep it unsplit or to split into its children, choosing the option that minimizes the cost. In the case of equality of the two options, choose to keep the node unsplit. Return the total optimal cost and the number of selected nodes in the chosen best basis (i.e., the count of nodes that are kept unsplit).\n\n3. Use the following test suite of signals and parameters. In all cases, set $\\varepsilon = 10^{-12}$ and decompose to maximum depth $J = \\log_2 N$.\n\n   - Test Case $1$ (happy path, mixed smooth and sparse):\n     - $N = 64$.\n     - For $n = 0,1,\\dots,63$, define\n       $$x[n] = \\sin\\left(\\frac{2\\pi \\cdot 3 \\cdot n}{64}\\right) + 0.5\\left(\\delta[n - 10] + \\delta[n - 45]\\right),$$\n       where $\\delta[\\cdot]$ is the Kronecker delta.\n     - $\\alpha = 0.5$.\n\n   - Test Case $2$ (boundary with trivial structure):\n     - $N = 64$.\n     - $x[n] = 1$ for all $n$.\n     - $\\alpha = 0.7$.\n\n   - Test Case $3$ (edge case with stochastic content):\n     - $N = 64$.\n     - $x[n]$ are independent and identically distributed samples from a Gaussian distribution $\\mathcal{N}(0,1)$, generated with a fixed random seed $s = 0$.\n     - $\\alpha = 0$.\n\n   - Test Case $4$ (short-length boundary, highly localized):\n     - $N = 8$.\n     - $x[n] = 1$ if $n = 4$ and $x[n] = 0$ otherwise.\n     - $\\alpha = 0.5$.\n\n4. Final Output Format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output first the integer number of selected nodes in the best basis, followed by the total optimal cost as a float rounded to six decimal places. Therefore, with four test cases, the output must be\n   $$[n_1, c_1, n_2, c_2, n_3, c_3, n_4, c_4],$$\n   where $n_i$ is an integer and $c_i$ is a float rounded to six decimal places for test case $i$.\n\nAll quantities are dimensionless; no physical units are involved. Angles in trigonometric functions are in radians. Ensure numerical stability for $\\log$ with the specified $\\varepsilon$ and define the entropy for zero-energy vectors to be $0$ as stated.",
            "solution": "The problem requires the implementation of an adaptive best-basis selection algorithm for a signal using the Wavelet Packet Transform (WPT) with Haar wavelets. The selection criterion is the minimization of a specified sparsity-entropy cost functional. The solution is found using a dynamic programming approach on the full WPT decomposition tree. The process can be broken down into three main conceptual stages: constructing the library of bases, defining the cost metric, and performing the optimization.\n\n### 1. The Wavelet Packet Transform as a Library of Orthonormal Bases\n\nThe Wavelet Packet Transform (WPT) generates a dictionary of orthonormal bases. For a signal $x \\in \\mathbb{R}^N$ where $N$ is a power of $2$, we can construct a full binary tree of coefficient vectors.\n\n-   **Tree Generation**: The root of the tree, at level $\\ell=0$, is the signal $x$ itself. A node at any level $\\ell$ containing a vector $v$ of length $m = N/2^\\ell$ is decomposed into two children nodes at level $\\ell+1$. This decomposition is achieved by applying a two-channel orthonormal filter bank. For the Haar wavelet, the low-pass filter is $h = \\left[\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}\\right]$ and the high-pass filter is $g = \\left[\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}}\\right]$. The decomposition formulas are:\n    -   Approximation (low-pass) coefficients: $$a[k] = \\frac{v[2k] + v[2k+1]}{\\sqrt{2}}$$\n    -   Detail (high-pass) coefficients: $$d[k] = \\frac{v[2k] - v[2k+1]}{\\sqrt{2}}$$\n    for $k = 0, 1, \\dots, \\frac{m}{2}-1$. The resulting vectors $a$ and $d$ each have length $m/2$ and form the two children nodes. This process is repeated until the maximum depth $J = \\log_2 N$ is reached, where the leaf nodes contain vectors of length $1$.\n\n-   **Orthonormal Bases**: The full binary tree contains a rich library of orthonormal bases for $\\mathbb{R}^N$. A valid basis is formed by any collection of nodes whose corresponding time-frequency tiles partition the entire time-frequency plane. In terms of the tree structure, this corresponds to any set of terminal nodes that are siblings of pruned branches and which themselves have no descendants in the chosen basis. The root node itself forms one basis (the standard basis representation of $x$). The set of all leaf nodes at level $J$ forms another basis (the full wavelet packet decomposition). The goal of the algorithm is to select the optimal basis from this library.\n\n### 2. The Sparsity-Entropy Cost Functional\n\nTo select a \"best\" basis, we need a quantitative measure of desirability. The problem defines a cost functional $C_\\alpha(v)$ for any coefficient vector $v \\in \\mathbb{R}^m$ in the tree. This functional is designed to favor representations where the signal's energy is concentrated in a few large-magnitude coefficients (i.e., a sparse representation).\n\nFor a nonzero vector $v$, the cost is:\n$$C_\\alpha(v) = \\alpha \\|v\\|_1 + (1-\\alpha) H(v)$$\nwhere $\\alpha \\in [0,1]$.\n\n-   **$L_1$ Norm ($ \\|v\\|_1 = \\sum_{i=1}^m |v_i|$)**: This component is a well-known convex proxy for sparsity. Minimizing the $L_1$ norm encourages solutions with many coefficients close to zero.\n\n-   **Shannon Entropy ($H(v)$)**: This component measures the \"flatness\" or \"spread\" of the signal's energy distribution. It is defined as:\n    $$H(v) = -\\sum_{i=1}^m p_i \\log(p_i + \\varepsilon)$$\n    where $p_i = v_i^2 / E$ is the normalized energy of the $i$-th coefficient, and $E = \\|v\\|_2^2 = \\sum_{i=1}^m v_i^2$ is the total energy of the vector. A signal whose energy is concentrated in a single coefficient has very low entropy, while a signal with energy spread evenly across all coefficients has high entropy. The small constant $\\varepsilon = 10^{-12}$ ensures numerical stability by preventing the evaluation of $\\log(0)$.\n\nIf the energy $E=0$, the cost is defined as $C_\\alpha(v)=0$. The parameter $\\alpha$ balances the trade-off between the two sparsity measures.\n\n### 3. Best-Basis Selection via Dynamic Programming\n\nThe key to finding the globally optimal basis efficiently is the additive nature of the cost functional across disjoint sets of coefficients, enabled by the orthonormality of the transform. This allows the use of a dynamic programming algorithm, commonly known as the Coifman-Wickerhauser algorithm.\n\nThe algorithm proceeds bottom-up on the WPT tree:\n\n1.  **Initialization (Leaves)**: For each leaf node at the maximum depth $J = \\log_2 N$, there is no possibility of splitting further. Its optimal cost is simply the cost of its own coefficient vector, $C_\\alpha(v)$.\n\n2.  **Recursive Step (Bottom-up Traversal)**: We move upwards from level $\\ell = J-1$ to the root at $\\ell = 0$. For each node $P$ at level $\\ell$ with children $C_1$ and $C_2$ at level $\\ell+1$:\n    -   We retrieve the already computed optimal costs for the subtrees rooted at its children, let's call them $C_{\\text{opt}}(C_1)$ and $C_{\\text{opt}}(C_2)$. The \"split\" cost for node $P$ is the sum of these costs: $C_{\\text{split}} = C_{\\text{opt}}(C_1) + C_{\\text{opt}}(C_2)$.\n    -   We compute the \"unsplit\" cost for node $P$, which is the cost of representing the signal subspace with $P$'s own coefficient vector: $C_{\\text{unsplit}} = C_\\alpha(v_P)$.\n    -   **Decision**: We compare the two costs. According to the problem's tie-breaking rule:\n        -   If $C_{\\text{unsplit}} \\le C_{\\text{split}}$, we decide to prune the tree at this node. The optimal cost for the subtree rooted at $P$ is $C_{\\text{opt}}(P) = C_{\\text{unsplit}}$, and we mark $P$ as a terminal node (unsplit).\n        -   Otherwise, if $C_{\\text{unsplit}} > C_{\\text{split}}$, we keep the split. The optimal cost is $C_{\\text{opt}}(P) = C_{\\text{split}}$, and we mark $P$ as a non-terminal (split) node.\n\n3.  **Final Result**: This process continues until we reach the root node $(\\ell=0, \\text{index}=0)$. The value $C_{\\text{opt}}(\\text{root})$ is the minimum possible cost for any basis in the WPT library.\n\nTo find the number of nodes in the selected best basis, we perform a final top-down traversal of the tree, following the decisions made during the dynamic programming phase. Starting from the root, if a node was marked \"unsplit\", we count it and stop traversing that branch. If it was marked \"split\", we recursively descend to its two children and sum their node counts. This traversal counts exactly the terminal nodes of the optimal basis tree.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the entire process.\n    It defines test cases, runs the best-basis selection algorithm\n    for each, and formats the final output.\n    \"\"\"\n    \n    # Global constants defined in the problem\n    EPSILON = 1e-12\n    SQRT2 = np.sqrt(2.0)\n\n    # --- Helper Functions ---\n\n    def generate_signal(case_id, N):\n        \"\"\"Generates the input signal x for a given test case.\"\"\"\n        n_indices = np.arange(N)\n        if case_id == 1:\n            # x[n] = sin(2*pi*3*n/64) + 0.5 * (delta[n-10] + delta[n-45])\n            x = np.sin(2 * np.pi * 3 * n_indices / N)\n            x[10] += 0.5\n            x[45] += 0.5\n            return x\n        elif case_id == 2:\n            # x[n] = 1 for all n\n            return np.ones(N)\n        elif case_id == 3:\n            # N(0,1) with seed 0\n            np.random.seed(0)\n            return np.random.randn(N)\n        elif case_id == 4:\n            # x[n] = delta[n-4]\n            x = np.zeros(N)\n            x[4] = 1.0\n            return x\n        return None\n\n    def cost_functional(v, alpha):\n        \"\"\"\n        Computes the sparsity-entropy cost C_alpha(v) for a vector v.\n        \"\"\"\n        v = np.asarray(v)\n        energy = np.sum(v**2)\n\n        if energy < EPSILON:  # Treat as zero energy\n            return 0.0\n\n        l1_norm = np.sum(np.abs(v))\n        \n        p = (v**2) / energy\n        # Filter p_i that are effectively zero to avoid adding log(epsilon)\n        p_nonzero = p[p > 0] \n        entropy = -np.sum(p_nonzero * np.log(p_nonzero + EPSILON))\n\n        return alpha * l1_norm + (1 - alpha) * entropy\n\n    def haar_analysis(v):\n        \"\"\"\n        Performs one level of Haar wavelet decomposition using vectorized operations.\n        \"\"\"\n        a = (v[0::2] + v[1::2]) / SQRT2\n        d = (v[0::2] - v[1::2]) / SQRT2\n        return a, d\n\n    def find_best_basis_and_cost(x, N, alpha):\n        \"\"\"\n        Implements the main WPT and best-basis selection algorithm.\n        \"\"\"\n        J = int(np.log2(N))\n\n        # 1. Construct the full Wavelet Packet Transform tree\n        # The tree is stored in a dictionary mapping (level, index) to the coefficient vector.\n        tree = {}\n        tree[(0, 0)] = x\n        for level in range(J):\n            num_nodes_in_level = 1 << level\n            for index in range(num_nodes_in_level):\n                parent_vector = tree.get((level, index))\n                if parent_vector is not None:\n                    a, d = haar_analysis(parent_vector)\n                    tree[(level + 1, 2 * index)] = a\n                    tree[(level + 1, 2 * index + 1)] = d\n\n        # 2. Perform bottom-up dynamic programming\n        optimal_costs = {}\n        is_split_decision = {}  # Stores bool: True if node is split, False if not.\n\n        # Initialization at the deepest level (leaves)\n        for index in range(1 << J):\n            leaf_vector = tree[(J, index)]\n            optimal_costs[(J, index)] = cost_functional(leaf_vector, alpha)\n            \n        # Iterate upwards from level J-1 to 0\n        for level in range(J - 1, -1, -1):\n            num_nodes_in_level = 1 << level\n            for index in range(num_nodes_in_level):\n                # Cost if we do not split this node\n                node_vector = tree[(level, index)]\n                cost_unsplit = cost_functional(node_vector, alpha)\n\n                # Cost if we split (sum of optimal costs of children)\n                child1_key = (level + 1, 2 * index)\n                child2_key = (level + 1, 2 * index + 1)\n                cost_split = optimal_costs[child1_key] + optimal_costs[child2_key]\n                \n                # Decision logic with tie-breaking rule\n                if cost_unsplit <= cost_split:\n                    optimal_costs[(level, index)] = cost_unsplit\n                    is_split_decision[(level, index)] = False\n                else:\n                    optimal_costs[(level, index)] = cost_split\n                    is_split_decision[(level, index)] = True\n        \n        total_optimal_cost = optimal_costs[(0, 0)]\n\n        # 3. Count nodes in the chosen best basis by traversing the decision tree\n        def count_basis_nodes(level, index):\n            # If a node is not marked as split, it's a terminal node in the best basis.\n            # Leaves (level J) are terminal by definition and won't be in is_split_decision.\n            if not is_split_decision.get((level, index), False):\n                return 1\n            \n            # If it is split, recurse on its children and sum their counts.\n            count = count_basis_nodes(level + 1, 2 * index) + \\\n                    count_basis_nodes(level + 1, 2 * index + 1)\n            return count\n\n        num_selected_nodes = count_basis_nodes(0, 0)\n        \n        return num_selected_nodes, total_optimal_cost\n\n    # --- Main Execution Loop ---\n\n    test_cases = [\n        {'id': 1, 'N': 64, 'alpha': 0.5},\n        {'id': 2, 'N': 64, 'alpha': 0.7},\n        {'id': 3, 'N': 64, 'alpha': 0.0},\n        {'id': 4, 'N': 8,  'alpha': 0.5},\n    ]\n\n    results = []\n    for case in test_cases:\n        signal = generate_signal(case['id'], case['N'])\n        n_nodes, cost = find_best_basis_and_cost(signal, case['N'], case['alpha'])\n        \n        results.append(str(n_nodes))\n        results.append(f\"{cost:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}