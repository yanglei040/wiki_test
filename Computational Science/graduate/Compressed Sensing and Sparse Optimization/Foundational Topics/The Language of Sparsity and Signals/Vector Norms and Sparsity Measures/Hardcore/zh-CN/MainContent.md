## 引言
在现代数据科学、信号处理和机器学习领域，我们常常面临一个根本性挑战：如何从看似不完整的信息中提取出简洁而有意义的结构。这一挑战的核心在于“[稀疏性](@entry_id:136793)”——即大部分信号或模型参数为零或接近于零的假设。寻找欠定[线性方程组](@entry_id:148943)的最[稀疏解](@entry_id:187463)是这类问题的典型代表，但直接度量[稀疏性](@entry_id:136793)的$\ell_0$范数会导致计算上不可行的[NP难问题](@entry_id:146946)，这构成了理论与实践之间的巨大鸿沟。

本文旨在系统性地填补这一知识鸿沟，为读者揭示[向量范数](@entry_id:140649)与稀疏性度量之间的深刻联系。我们将深入探讨为何$\ell_1$范数能够成为$\ell_0$范数强大而实用的凸代理，从而将棘手的组合优化问题转化为可高效求解的凸问题。通过本文的学习，您将掌握[稀疏恢复](@entry_id:199430)背后的核心数学原理及其在多学科[交叉](@entry_id:147634)领域的广泛应用。

文章将分为三个章节逐步展开：首先，在“原理与机制”中，我们将建立起范数的数学框架，从几何和概率角度剖析$\ell_1$范数诱导[稀疏性](@entry_id:136793)的内在机制，并讨论其理论保证条件。接着，在“应用与交叉学科联系”中，我们将展示这些原理如何应用于高级信号模型、机器学习中的特征选择与模型安全，以及[强化学习](@entry_id:141144)等前沿领域。最后，通过“动手实践”部分，您将有机会通过解决具体问题来巩固所学理论，将抽象概念转化为解决实际问题的能力。

## 原理与机制

在上一章引言中，我们介绍了在信号处理和统计学中寻找欠定线性方程组稀疏解的核心问题。本章将深入探讨支撑[稀疏恢复](@entry_id:199430)的数学原理与核心机制。我们将首先建立用于度量向量大小和[稀疏性](@entry_id:136793)的数学工具——范数（norms），然后系统地阐释为何 $\ell_1$ 范数能够作为稀疏性的有效凸代理。我们将从几何、概率和算法等多个角度进行剖析，并探讨其局限性与扩展。

### 衡量向量：范数及其几何意义

在[向量空间](@entry_id:151108)中，为了量化向量的“大小”或“长度”，我们引入了**范数**的概念。一个函数 $\| \cdot \|: \mathbb{R}^n \to \mathbb{R}$ 被称为范数，如果它对任意向量 $x, y \in \mathbb{R}^n$ 和标量 $\alpha \in \mathbb{R}$ 满足以下三条性质：
1.  **非负性（Non-negativity）**: $\|x\| \ge 0$，且 $\|x\| = 0$ 当且仅当 $x$ 是零向量。
2.  **[绝对齐次性](@entry_id:274917)（Absolute homogeneity）**: $\|\alpha x\| = |\alpha| \|x\|$。
3.  **三角不等式（Triangle inequality）**: $\|x+y\| \le \|x\| + \|y\|$。

在[稀疏优化](@entry_id:166698)领域，最常用的是 $\ell_p$ 范数家族，其定义为：
$$
\|x\|_p = \left( \sum_{i=1}^n |x_i|^p \right)^{1/p}
$$
其中 $p \ge 1$。三个最重要的特例是：

-   **$\ell_1$ 范数（[曼哈顿范数](@entry_id:143036)）**: 当 $p=1$ 时，定义为向量各元素[绝对值](@entry_id:147688)之和。
    $$
    \|x\|_1 = \sum_{i=1}^n |x_i|
    $$

-   **$\ell_2$ 范数（欧几里得范数）**: 当 $p=2$ 时，对应于我们所熟知的向量欧几里得长度。
    $$
    \|x\|_2 = \left( \sum_{i=1}^n x_i^2 \right)^{1/2}
    $$

-   **$\ell_\infty$ 范数（[最大范数](@entry_id:268962)或[切比雪夫范数](@entry_id:184858)）**: 当 $p \to \infty$ 时，其极限为向量中[绝对值](@entry_id:147688)最大的元素。
    $$
    \|x\|_\infty = \max_{1 \le i \le n} |x_i|
    $$

#### [范数的几何学](@entry_id:267495)：单位球

理解不同范数之间差异的关键在于观察它们的**单位球**，即所有范数不大于1的向量构成的集合 $\mathcal{B}_p = \{x \in \mathbb{R}^n : \|x\|_p \le 1\}$。
-   $\ell_2$ 单位球是我们熟悉的超球面，表面光滑且处处可微（除了原点）。
-   $\ell_1$ 单位球是一个**[交叉多胞体](@entry_id:748072)**（cross-polytope）。在二维空间中是一个菱形（旋转了45度的正方形），在三维空间中是一个正八面体。它的显著特征是具有“尖角”或**顶点**（vertices），这些顶点正好落在坐标轴上。
-   $\ell_\infty$ 单位球是一个**[超立方体](@entry_id:273913)**（hypercube）。在二维空间中是一个正方形，在三维空间中是一个立方体。它的“尖角”则[分布](@entry_id:182848)在各个卦限的对角线方向。

这些几何形状上的差异，尤其是“尖角”的存在与否，是理解范数在[优化问题](@entry_id:266749)中不同行为的根本原因，我们将在后文详细阐述。

#### 有限维空间中范数的等价性

在[有限维向量空间](@entry_id:265491)（如 $\mathbb{R}^n$）中，一个重要的性质是**[范数等价](@entry_id:137561)性**。这意味着对于任意两种范数 $\|\cdot\|_a$ 和 $\|\cdot\|_b$，都存在正常数 $c_1$ 和 $c_2$，使得对于所有非零向量 $x \in \mathbb{R}^n$ 都成立：
$$
c_1 \|x\|_a \le \|x\|_b \le c_2 \|x\|_a
$$
这保证了在拓扑意义上，所有范数都诱导出相同的收敛性和连续性概念。然而，在[优化问题](@entry_id:266749)中，这些常数 $c_1$ 和 $c_2$ 的具体数值至关重要，因为它们决定了不同范数度量下的“大小”关系。

例如，我们可以推导 $\ell_1, \ell_2, \ell_\infty$ 范数之间的紧致界 。对于任意 $x \in \mathbb{R}^n$，以下不等式成立：
$$
\|x\|_2 \le \|x\|_1 \le \sqrt{n} \|x\|_2
$$
$$
\|x\|_\infty \le \|x\|_2 \le \sqrt{n} \|x\|_\infty
$$
这里的系数被称为**紧致常数**（sharp constants），因为它们是能使不等式对所有 $x$ 成立的最优值。

-   当向量 $x$ 是**稀疏**的，例如只有一个非零元素（如[标准基向量](@entry_id:152417) $e_k = (0, \dots, 1, \dots, 0)$），我们有 $\|e_k\|_1 = 1$ 和 $\|e_k\|_2 = 1$。此时，$\|x\|_1 / \|x\|_2$ 的比值达到下界 $1$。同样，$\|e_k\|_2 = 1$ 和 $\|e_k\|_\infty = 1$，$\|x\|_2 / \|x\|_\infty$ 的比值也达到下界 $1$。
-   当向量 $x$ 是**稠密**的，且所有元素的[绝对值](@entry_id:147688)都相等（如 $x = (1, 1, \dots, 1)$），我们有 $\|x\|_1 = n$ 和 $\|x\|_2 = \sqrt{n}$。此时，$\|x\|_1 / \|x\|_2$ 的比值达到[上界](@entry_id:274738) $\sqrt{n}$。同样，$\|x\|_2 = \sqrt{n}$ 和 $\|x\|_\infty = 1$，$\|x\|_2 / \|x\|_\infty$ 的比值也达到上界 $\sqrt{n}$。

这些关系揭示了一个深刻的联系：$\ell_1$ 范数相对 $\ell_2$ 范数更能“放大”稠密向量的“大小”，而对稀疏向量的度量则与 $\ell_2$ 范数更为接近。这一特性是 $\ell_1$ 范数促进稀疏性的数学基础之一。

### 衡量稀疏度：从组合到连续

#### “黄金标准”：$\ell_0$ 伪范数

衡量向量稀疏度的最自然方式是计算其非零元素的个数。这个计数由 **$\ell_0$ “范数”**（或称为伪范数，因为它不满足[绝对齐次性](@entry_id:274917)）给出：
$$
\|x\|_0 = \sum_{i=1}^n \mathbb{I}(x_i \neq 0)
$$
其中 $\mathbb{I}(\cdot)$ 是指示函数。在压缩感知的框架下，我们的终极目标通常是求解以下 $\ell_0$ 最小化问题：
$$
\min_{x \in \mathbb{R}^n} \|x\|_0 \quad \text{subject to} \quad Ax=y
$$
然而，由于 $\|x\|_0$ 是一个离散的、非凸的函数，上述[优化问题](@entry_id:266749)是一个NP-hard的组合优化问题。对所有可能的非零元素[子集](@entry_id:261956)进行搜索的计算成本是指数级的，这在实际应用中是不可行的。因此，我们需要寻找一个计算上易于处理的替代方案。

#### 作为稀疏性凸代理的$\ell_1$范数

$\ell_1$ 范数是实践中最成功的 $\ell_0$ 范数的**凸代理**（convex surrogate）。这意味着我们转而求解一个凸[优化问题](@entry_id:266749)：
$$
\min_{x \in \mathbb{R}^n} \|x\|_1 \quad \text{subject to} \quad Ax=y
$$
这个问题被称为**[基追踪](@entry_id:200728)**（Basis Pursuit）。它是一个[线性规划](@entry_id:138188)问题，可以被高效地求解。令人惊讶的是，在特定条件下，这个凸问题的解与原始的组合问题的解是完全相同的。以下我们将从几个角度阐释其内在原因。

##### 几何直觉

$\ell_1$ 范数促进稀疏性的能力可以通过几何直观地理解。求解 $\min \|x\|$ s.t. $Ax=y$ 的过程，等价于寻找一个以原点为中心、不断“膨胀”的范数球，直到它首次接触到由约束 $Ax=y$ 定义的仿射[子空间](@entry_id:150286) $\mathcal{S}$。这个首次接触的点就是[最小范数解](@entry_id:751996)。

-   对于**$\ell_2$ 范数**，其单位球是光滑的超球面。当它膨胀接触到仿射[子空间](@entry_id:150286) $\mathcal{S}$ 时，接触点通常是原点到 $\mathcal{S}$ 的[正交投影](@entry_id:144168)。由于球面的[旋转对称](@entry_id:137077)性，它对坐标轴没有偏好，因此解向量的元素通常都是非零的，即解是**稠密**的。

-   对于**$\ell_1$ 范数**，其[单位球](@entry_id:142558)是带有“尖角”的[交叉多胞体](@entry_id:748072)。当它膨胀时，极有可能在某个尖锐的顶点或边上首先接触到仿射[子空间](@entry_id:150286) $\mathcal{S}$。$\ell_1$ 球的顶点（如 $(\pm c, 0, \dots, 0)$）和边都位于某些坐标为零的[子空间](@entry_id:150286)上。因此，接触点很可能是一个**稀疏**向量 。

一个具体的例子可以很好地说明这一点 。考虑一个测量矩阵 $A \in \mathbb{R}^{2 \times 3}$，其列向量为[单位向量](@entry_id:165907) $a_1, a_2, a_3$。假设真实信号是 $x^\star = e_1 = (1, 0, 0)^\top$，测量结果为 $y=Ae_1=a_1$。$\ell_1$ 最小化能够精确地恢复 $x^\star$。然而，如果我们求解最小 $\ell_2$ 范数解，我们会得到一个稠密的解 $x_{ls} = (\frac{2}{3}, \frac{1}{3}, \frac{1}{3})^\top$，其能量[分布](@entry_id:182848)在所有三个分量上。这清晰地展示了 $\ell_1$ 范数与生俱来的稀疏选择能力。

##### 一个简单的平局打破者

在某些情况下，可能存在多个具有相同最小稀疏度（即相同 $\ell_0$ 范数）的解。此时，$\ell_0$ 最小化本身无法区分它们。然而，$\ell_1$ 最小化可以充当一个有效的**平局打破者**。

考虑一个简单的情景 ：$A = \begin{pmatrix} 1  \alpha \end{pmatrix}$ 和 $y=b \neq 0$。[约束方程](@entry_id:138140)为 $x_1 + \alpha x_2 = b$。存在两个1-[稀疏解](@entry_id:187463)：$x^{(1)} = (b, 0)^\top$ 和 $x^{(2)} = (0, b/\alpha)^\top$。这两个解的 $\ell_0$ 范数都是1，因此从 $\ell_0$ 最小化的角度看，它们是等价的。

然而，它们的 $\ell_1$ 范数分别为 $\|x^{(1)}\|_1 = |b|$ 和 $\|x^{(2)}\|_1 = |b|/|\alpha|$。$\ell_1$ 最小化会选择范数值更小的那个解。
-   如果 $|\alpha| > 1$，则 $|b|/|\alpha|  |b|$，$\ell_1$ 最小化选择 $x^{(2)}$。
-   如果 $|\alpha|  1$，则 $|b|/|\alpha| > |b|$，$\ell_1$ 最小化选择 $x^{(1)}$。
-   当 $|\alpha| = 1$ 时，两者范数相等，$\ell_1$ 最小化也无法唯一区分。

这个例子表明，$\ell_1$ 范数偏好将非零元素放在测量矩阵 $A$ 中对应列“较大”的位置上（这里“较大”指的是列的范数，尽管在这个例子中未明确，但其影响体现在系数 $\alpha$ 上）。

##### 恢复的充分条件

$\ell_1$ 最小化能够成功恢复稀疏信号并非总是成立，它依赖于测量矩阵 $A$ 的性质。有几个关键的性质可以为恢复提供保证。

-   **[零空间性质](@entry_id:752758) (Null Space Property, NSP)**：这是保证对于所有 $k$-稀疏信号都能通过 $\ell_1$ 最小化精确恢复的**充要条件**。NSP要求对于矩阵 $A$ 的[零空间](@entry_id:171336) $\ker(A)$ 中的任何非[零向量](@entry_id:156189) $v$，其在任意大小为 $k$ 的索引[子集](@entry_id:261956) $S$ 上的能量（以 $\ell_1$ 范数衡量）必须严格小于其在补集 $S^c$ 上的能量，即 $\|v_S\|_1  \|v_{S^c}\|_1$。

-   **有限等距性质 (Restricted Isometry Property, RIP)**：这是一个更强但仅为**充分**的条件。RIP要求矩阵 $A$ 对所有 $k$-稀疏向量近似地保持其 $\ell_2$ 长度。具体来说，存在一个常数 $\delta_k \in [0, 1)$，使得对所有 $k$-稀疏向量 $x$，$(1-\delta_k)\|x\|_2^2 \le \|Ax\|_2^2 \le (1+\delta_k)\|x\|_2^2$ 成立。如果 $\delta_{2k}$ 足够小（例如 $\delta_{2k}  \sqrt{2}-1$），则可以保证 $\ell_1$ 最小化的稳定恢复。

-   **[互相关性](@entry_id:188177) (Mutual Coherence)**：这是一个更简单但更保守的条件，定义为矩阵 $A$ 归一化列之间[内积](@entry_id:158127)[绝对值](@entry_id:147688)的最大值 $\mu(A)$。如果 $k  \frac{1}{2}(1 + 1/\mu(A))$，则可以保证恢复。

有趣的是，一个矩阵可能不满足较强的RIP条件，但仍然满足NSP，从而保证恢复 。同样，一个矩阵的[互相关性](@entry_id:188177)可能过大以至于无法提供[恢复保证](@entry_id:754159)，但其RIP常数可能足够小，从而仍然可以保证恢复 。这表明这些条件之间存在一种层次关系，NSP是最根本的。

#### 超越$\ell_0$和$\ell_1$：其他稀疏性度量

除了 $\ell_0$ 和 $\ell_1$ 之外，还存在其他衡量[稀疏性](@entry_id:136793)的函数。一个值得注意的例子是 **Hoyer 比率** ：
$$
S(x) = \frac{\|x\|_1}{\|x\|_2}
$$
这个度量具有一些理想的性质。首先，它是**尺度不变**的，即 $S(cx) = S(x)$ 对于任何非零标量 $c$ 都成立。这意味着它只关心向量中元素的相对大小[分布](@entry_id:182848)，而不关心向量的整体能量。其次，它与 $\ell_0$ 范数有明确的界限关系：对于任意非零向量 $x$，我们有 $1 \le S(x) \le \sqrt{\|x\|_0}$。
-   下界 $S(x)=1$ 当且仅当 $x$ 是1-稀疏的。
-   [上界](@entry_id:274738) $S(x)=\sqrt{\|x\|_0}$ 当且仅当 $x$ 的所有非零元素具有相同的[绝对值](@entry_id:147688)。

这表明，最小化 $S(x)$ 确实能促进稀疏性。然而，与 $\ell_0$ 范数一样，$S(x)$ 是一个**非凸函数** ，这使得相关的[优化问题](@entry_id:266749)难以全局求解。

### [稀疏性](@entry_id:136793)诱导正则项的概率解释

除了几何和优化的角度，我们还可以从概率和统计的角度来理解稀疏性正则化，特别是通过**最大后验（Maximum A Posteriori, MAP）**估计框架。[MAP估计](@entry_id:751667)的目标是在给定观测数据 $y$ 的情况下，找到最可能产生这些数据的信号 $x$。根据贝叶斯定理，[后验概率](@entry_id:153467) $p(x|y)$ 正比于[似然](@entry_id:167119) $p(y|x)$ 和先验 $p(x)$ 的乘积：
$$
p(x|y) \propto p(y|x) p(x)
$$
[MAP估计](@entry_id:751667)等价于最小化负对数后验，即 $-\ln p(y|x) - \ln p(x)$。

#### 拉普拉斯先验与$\ell_1$范数（[LASSO](@entry_id:751223)）

假设信号 $x$ 的每个分量 $x_i$ 独立地服从均值为零、[尺度参数](@entry_id:268705)为 $b$ 的**[拉普拉斯分布](@entry_id:266437)**（Laplace distribution），其[概率密度函数](@entry_id:140610)为 $p(x_i) \propto \exp(-|x_i|/b)$。同时，假设测量噪声 $w = y - Ax$ 是独立同分布的高斯噪声 $w \sim \mathcal{N}(0, \sigma^2 I)$。

在这种设定下 ：
-   [负对数似然](@entry_id:637801) $-\ln p(y|x)$ 正比于 $\ell_2$ 数据保真项 $\|y-Ax\|_2^2$。
-   负对数先验 $-\ln p(x)$ 正比于 $\ell_1$ 范数 $\|x\|_1$。

因此，[MAP估计](@entry_id:751667)问题变为：
$$
\min_{x \in \mathbb{R}^n} \left( \frac{1}{2\sigma^2} \|y - Ax\|_2^2 + \frac{1}{b} \|x\|_1 \right)
$$
这等价于求解著名的 **LASSO (Least Absolute Shrinkage and Selection Operator)** 问题：
$$
\min_{x \in \mathbb{R}^n} \frac{1}{2} \|y - Ax\|_2^2 + \lambda \|x\|_1
$$
其中正则化参数 $\lambda = \sigma^2 / b$。这个推导为 $\ell_1$ 正则化提供了坚实的统计基础：它相当于假设信号本身具有[稀疏性](@entry_id:136793)（由拉普拉斯先验建模）。参数 $\lambda$ 在噪声[方差](@entry_id:200758) $\sigma^2$ 较大或先验尺度 $b$ 较小时取值较大，这意味着当数据不可信或我们先验地相信信号更稀疏时，我们会施加更强的 $\ell_1$ 惩罚。

#### 尖峰-厚板先验与$\ell_0$范数

与拉普拉斯先验不同，**尖峰-厚板先验（Spike-and-Slab prior）** 是一种更直接地对[稀疏性](@entry_id:136793)建模的贝叶斯方法 。它引入二元[潜变量](@entry_id:143771) $z_i \in \{0, 1\}$，其中 $z_i=1$ 表示第 $i$ 个系数是“活跃的”，$z_i=0$ 表示它是“不活跃的”。
-   如果 $z_i=0$（“尖峰”部分），则 $x_i=0$。
-   如果 $z_i=1$（“厚板”部分），则 $x_i$ 从某个连续分布（如[高斯分布](@entry_id:154414) $\mathcal{N}(0, \tau^2)$）中抽取。

在这种模型下，对 $(x, z)$ 进行联合[MAP估计](@entry_id:751667)，最终得到的目标函数等价于：
$$
\min_x \frac{1}{2\sigma^2} \|y - Ax\|_2^2 + \frac{1}{2\tau^2} \|x\|_2^2 + \lambda' \|x\|_0
$$
这里的 $\lambda'$ 是一个依赖于先验参数的常数。这个[目标函数](@entry_id:267263)包含一个 $\ell_0$ 惩罚项，这再次印证了 $\ell_0$ 是[稀疏性](@entry_id:136793)的直接度量。然而，正如我们前面所讨论的，这个问题的[组合性](@entry_id:637804)质使其难以求解。对每个可能的支撑集（由 $z$ 决定，共 $2^n$ 个）求解一个子问题（一个简单的[岭回归](@entry_id:140984)问题），然后比较它们，在计算上是不可行的 。这进一步凸显了像 [LASSO](@entry_id:751223) 这样的[凸松弛](@entry_id:636024)方法的价值和重要性。

### $\ell_1$最小化的局限与扩展

尽管 $\ell_1$ 范数非常强大，但它并非万能药。理解其局限性并探索更先进的方法是[稀疏优化](@entry_id:166698)研究的前沿。

#### 当$\ell_1$失效时：积分差距与非凸替代方案

$\ell_1$ 松弛的有效性并非没有代价。**积分差距（integrality gap）**这个概念量化了[凸松弛](@entry_id:636024)问题（如 $\ell_1$ 最小化）的最优值与原始组合问题（$\ell_0$ 最小化）最优值之间的最坏情况比率。在一个背包问题的变种中，可以证明 $\ell_0$ 和 $\ell_1$ 最小化之间的积分差距为 $2$ 。这意味着在最坏的情况下，$\ell_1$ 范数的最优值可能仅为 $\ell_0$ 范数最优值的一半，这暗示了松弛可能带来的性能损失。

为了弥合 $\ell_1$ 和 $\ell_0$ 之间的差距，研究者们提出了使用 $\ell_p$ [准范数](@entry_id:753960) ($0  p  1$) 进行优化的非凸方法。当 $p$ 趋近于 $0$ 时，$\ell_p$ [准范数](@entry_id:753960)能更好地逼近 $\ell_0$ 范数。存在一些情况，$\ell_1$ 最小化会失败并返回一个稠密的解，而 $\ell_p$ 最小化（如 $p=0.5$）却能成功恢复出更稀疏的真实解 。

当然，优化非凸的 $\ell_p$ [目标函数](@entry_id:267263)极具挑战性。一个流行的算法是**迭代重加权$\ell_1$（Iteratively Reweighted $\ell_1$, IRL1）**。该算法通过一系列带权的 $\ell_1$ 最小化问题来逼近 $\ell_p$ 最小化问题。在每一步，它会根据当前解的幅度来更新权重：幅度较小的元素在下一步中获得较大的权重，从而被更强烈地惩罚，鼓励其变为零 。

#### [结构化稀疏性](@entry_id:636211)：混合范数

在许多应用中，稀疏性不仅体现在单个元素上，还体现在预定义的元素**组（group）**上。例如，在基因分析中，我们可能希望选择整个基因通路而不是单个基因。这种**[结构化稀疏性](@entry_id:636211)**可以通过**混合范数（mixed norms）**来促进。

考虑一个向量 $x$ 被划分为若干组 $G_1, G_2, \dots$。两种常见的混合范数是 $\ell_{1,2}$ 和 $\ell_{1,\infty}$ 范数 ：
$$
\|x\|_{1,2} = \sum_g \|x_{G_g}\|_2 \quad (\text{Group LASSO})
$$
$$
\|x\|_{1,\infty} = \sum_g \|x_{G_g}\|_\infty
$$
这两种范数都会促进**[组稀疏性](@entry_id:750076)**，即倾向于使整个组的系数同时为零。然而，它们对组内元素的行为有不同的影响，这可以通过分析其单位球的几何形状来理解。

-   **$\ell_{1,2}$ 范数**的单位球极点对应于仅在单个组内有非零元素，且该组内元素的 $\ell_2$ 范数为1的向量。由于 $\ell_2$ 球是光滑的，该范数对组内的稀疏性没有偏好。它只负责选择“活跃”的组，而不关心组内能量如何[分布](@entry_id:182848)。

-   **$\ell_{1,\infty}$ 范数**的单位球极点则更为特殊。它们同样是组稀疏的，但在活跃的组内，所有元素的[绝对值](@entry_id:147688)都必须达到最大值（即1）。这意味着 $\ell_{1,\infty}$ 范数不仅选择活跃组，还倾向于使组内所有元素的幅度相等并变得稠密。

这些不同的性质使得混合范数成为在信号或模型具有已知结构时进行变量选择的强大工具。通过精心设计范数，我们可以将复杂的先验知识编码到[凸优化](@entry_id:137441)框架中。