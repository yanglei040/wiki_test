{
    "hands_on_practices": [
        {
            "introduction": "为了恢复在梯度域中稀疏的信号（例如分段常数信号），总变差（TV）最小化是一种基础且强大的工具。本练习将通过一个简单的低维示例，带你亲手解构该过程，不仅要求你找到原始解，还要求你构建对偶证书来严格证明其最优性。通过这个练习，你将对稀疏恢复背后的凸优化原理，特别是对偶性和最优性条件，建立坚实的直观理解。",
            "id": "3478998",
            "problem": "考虑一个长度为 $n=4$ 的一维离散信号，由向量 $x \\in \\mathbb{R}^{4}$ 表示。给定两个通过对长度为 $2$ 的不相交连续块进行平均而获得的低分辨率样本。具体来说，传感算子 $A \\in \\mathbb{R}^{2 \\times 4}$ 为\n$$\nA \\;=\\; \\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{2}  0  0 \\\\\n0  0  \\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix},\n$$\n观测向量为 $y \\in \\mathbb{R}^{2}$，且 $y = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。假设未知信号是分段常数，在索引 $2$ 和 $3$ 之间有单个跳变，这与许多自然信号和图像在其梯度上是稀疏的一致。\n\n定义前向差分算子 $D \\in \\mathbb{R}^{3 \\times 4}$ 为\n$$\nD \\;=\\; \\begin{pmatrix}\n-1  1  0  0 \\\\\n0  -1  1  0 \\\\\n0  0  -1  1\n\\end{pmatrix},\n$$\n并定义 $x$ 的离散全变分 (TV) 为 $\\|Dx\\|_{1}$。考虑全变分 (TV) 正则化可行性规划\n$$\n\\min_{x \\in \\mathbb{R}^{4}} \\;\\|Dx\\|_{1} \\quad \\text{subject to} \\quad Ax = y.\n$$\n\n仅从作为支撑函数的 $\\ell_{1}$范数的核心定义和凸对偶性出发，完成以下任务：\n\n1. 利用信号在索引 $\\{1,2\\}$ 和 $\\{3,4\\}$ 上是分段常数以及低分辨率约束是唯一测量值这一信息，恢复唯一的极小化子 $x^{\\star}$。\n2. 使用恒等式 $\\|w\\|_{1} = \\max_{\\|z\\|_{\\infty} \\leq 1} z^{\\top} w$ 和针对线性约束的适当拉格朗日乘子，推导拉格朗日对偶问题。确定最优对偶变量必须满足的对偶可行性条件和互补松弛条件。\n3. 计算一个显式的对偶证书 $(v^{\\star}, z^{\\star})$，以证明您恢复的 $x^{\\star}$ 的最优性，其中 $v^{\\star} \\in \\mathbb{R}^{2}$ 是与等式约束 $Ax=y$ 相关联的对偶变量，而 $z^{\\star} \\in \\mathbb{R}^{3}$ 是 $\\|Dx\\|_{1}$ 的次梯度变量。您的构造必须满足连接 $A^{\\top} v^{\\star}$ 和 $D^{\\top} z^{\\star}$ 的平稳性条件和可行性条件。\n4. 计算最优对偶目标值 $y^{\\top} v^{\\star}$。\n\n您的最终答案必须是等于最优对偶目标值 $y^{\\top} v^{\\star}$ 的单个实数。不需要四舍五入，也不涉及单位。请精确表示最终答案。",
            "solution": "该问题是一个适定的凸优化规划。我们按顺序解决四个要求的任务。\n\n原始问题由下式给出：\n$$\n\\min_{x \\in \\mathbb{R}^{4}} \\;\\|Dx\\|_{1} \\quad \\text{subject to} \\quad Ax = y\n$$\n其中 $x = (x_1, x_2, x_3, x_4)^{\\top}$，矩阵 $A$、$D$ 和向量 $y$ 为：\n$$\nA = \\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{2}  0  0 \\\\\n0  0  \\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}, \\quad D = \\begin{pmatrix}\n-1  1  0  0 \\\\\n0  -1  1  0 \\\\\n0  0  -1  1\n\\end{pmatrix}, \\quad y = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\n目标函数是离散全变分 (TV) 半范数，$\\|Dx\\|_{1} = |x_2 - x_1| + |x_3 - x_2| + |x_4 - x_3|$。\n\n1. 恢复原始极小化子 $x^{\\star}$。\n问题提供了结构信息，即信号 $x$ 在索引集 $\\{1, 2\\}$ 和 $\\{3, 4\\}$ 上是分段常数。这意味着 $x_1 = x_2$ 且 $x_3 = x_4$。我们可以利用此信息以及线性约束 $Ax=y$ 来确定唯一的极小化子 $x^{\\star}$。\n约束条件为：\n$$\n\\frac{1}{2}x_1 + \\frac{1}{2}x_2 = 0 \\quad \\implies \\quad x_1 + x_2 = 0\n$$\n$$\n\\frac{1}{2}x_3 + \\frac{1}{2}x_4 = 1 \\quad \\implies \\quad x_3 + x_4 = 2\n$$\n将分段常数条件代入这些方程：\n对于第一个约束，当 $x_1 = x_2$ 时：\n$$\nx_1 + x_1 = 2x_1 = 0 \\implies x_1 = 0\n$$\n因此，$x_1 = x_2 = 0$。\n对于第二个约束，当 $x_3 = x_4$ 时：\n$$\nx_3 + x_3 = 2x_3 = 2 \\implies x_3 = 1\n$$\n因此，$x_3 = x_4 = 1$。\n这为最优解提供了一个唯一的候选者：\n$$\nx^{\\star} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\n根据构造，该向量 $x^{\\star}$ 是可行的。其对应的目标值为：\n$$\nDx^{\\star} = \\begin{pmatrix} x_2 - x_1 \\\\ x_3 - x_2 \\\\ x_4 - x_3 \\end{pmatrix}_{\\vert x=x^{\\star}} = \\begin{pmatrix} 0 - 0 \\\\ 1 - 0 \\\\ 1 - 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\|Dx^{\\star}\\|_{1} = |0| + |1| + |0| = 1\n$$\n该解在其梯度上是稀疏的，在 $Dx^{\\star}$ 中只有一个非零分量。这与 TV 最小化的目标一致。\n\n2. 拉格朗日对偶问题和最优性条件。\n我们从原始问题出发，并利用 $\\ell_1$范数作为 $\\ell_{\\infty}$范数球的支撑函数的定义来推导对偶问题。\n原始问题是 $\\min_{x} \\|Dx\\|_{1}$，约束条件为 $Ax = y$。\n使用恒等式 $\\|w\\|_{1} = \\max_{\\|z\\|_{\\infty} \\leq 1} z^{\\top}w$，我们可以将原始问题重写为极小极大问题：\n$$\n\\min_{x \\in \\mathbb{R}^{4} \\text{ s.t. } Ax=y} \\max_{z \\in \\mathbb{R}^{3} \\text{ s.t. } \\|z\\|_{\\infty} \\leq 1} z^{\\top}(Dx)\n$$\n由于目标函数是凸的且约束是线性的，强对偶性成立。我们可以交换 min 和 max 算子：\n$$\n\\max_{z \\in \\mathbb{R}^{3} \\text{ s.t. } \\|z\\|_{\\infty} \\leq 1} \\min_{x \\in \\mathbb{R}^{4} \\text{ s.t. } Ax=y} z^{\\top}(Dx)\n$$\n内部的最小化问题是 $\\min_{x} (D^{\\top}z)^{\\top}x$，约束条件为 $Ax = y$。我们为其等式约束引入对偶变量 $v \\in \\mathbb{R}^{2}$ 来构造其拉格朗日函数：\n$$\n\\mathcal{L}(x, v) = (D^{\\top}z)^{\\top}x + v^{\\top}(y - Ax) = (D^{\\top}z - A^{\\top}v)^{\\top}x + y^{\\top}v\n$$\n为使 $\\mathcal{L}(x, v)$ 关于 $x$ 的最小值有界（即不为 $-\\infty$），$x$ 的系数必须为零。这给出了条件 $D^{\\top}z - A^{\\top}v = 0$，或 $A^{\\top}v = D^{\\top}z$。\n如果此条件成立，则内部问题的最小值为 $y^{\\top}v$。\n将此代回外部的最大化问题，我们得到拉格朗日对偶问题：\n$$\n\\max_{v \\in \\mathbb{R}^{2}, z \\in \\mathbb{R}^{3}} y^{\\top}v \\quad \\text{subject to} \\quad A^{\\top}v = D^{\\top}z \\quad \\text{and} \\quad \\|z\\|_{\\infty} \\leq 1\n$$\n对偶对 $(x^{\\star}, (v^{\\star}, z^{\\star}))$ 的最优性条件是：\n(a) 原始可行性：$Ax^{\\star} = y$。\n(b) 对偶可行性：$A^{\\top}v^{\\star} = D^{\\top}z^{\\star}$ 且 $\\|z^{\\star}\\|_{\\infty} \\leq 1$。\n(c) 互补松弛性：此条件关联了原始变量和对偶变量。对于 $\\ell_1$范数，其形式为 $z^{\\star} \\in \\partial(\\|Dx^{\\star}\\|_{1})$。这意味着对于每个分量 $i \\in \\{1, 2, 3\\}$，如果 $(Dx^{\\star})_i \\neq 0$，我们有 $z_i^{\\star} = \\text{sign}((Dx^{\\star})_i)$；如果 $(Dx^{\\star})_i = 0$，则有 $|z_i^{\\star}| \\leq 1$。这可以概括为对所有 $i$ 都有 $z_i^{\\star} (Dx^{\\star})_i = |(Dx^{\\star})_i|$。\n\n3. 计算对偶证书 $(v^{\\star}, z^{\\star})$。\n我们寻找一对 $(v^{\\star}, z^{\\star})$，它满足我们的原始解 $x^{\\star} = (0, 0, 1, 1)^{\\top}$ 的对偶可行性和互补松弛性条件。\n从步骤 1，我们有 $Dx^{\\star} = (0, 1, 0)^{\\top}$。\n互补松弛性条件意味着：\n- $(Dx^{\\star})_1 = 0 \\implies |z^{\\star}_1| \\leq 1$。\n- $(Dx^{\\star})_2 = 1 \\implies z^{\\star}_2 = \\text{sign}(1) = 1$。\n- $(Dx^{\\star})_3 = 0 \\implies |z^{\\star}_3| \\leq 1$。\n现在，我们使用对偶可行性条件 $A^{\\top}v^{\\star} = D^{\\top}z^{\\star}$，其中 $v^{\\star} = (v^{\\star}_1, v^{\\star}_2)^{\\top}$ 且 $z^{\\star} = (z^{\\star}_1, 1, z^{\\star}_3)^{\\top}$。\n矩阵为 $A^{\\top} = \\begin{pmatrix} 1/2  0 \\\\ 1/2  0 \\\\ 0  1/2 \\\\ 0  1/2 \\end{pmatrix}$ 和 $D^{\\top} = \\begin{pmatrix} -1  0  0 \\\\ 1  -1  0 \\\\ 0  1  -1 \\\\ 0  0  1 \\end{pmatrix}$。\n线性方程组为：\n$$\n\\begin{pmatrix}\n1/2  0 \\\\ 1/2  0 \\\\ 0  1/2 \\\\ 0  1/2\n\\end{pmatrix}\n\\begin{pmatrix} v^{\\star}_1 \\\\ v^{\\star}_2 \\end{pmatrix}\n=\n\\begin{pmatrix}\n-1  0  0 \\\\ 1  -1  0 \\\\ 0  1  -1 \\\\ 0  0  1\n\\end{pmatrix}\n\\begin{pmatrix} z^{\\star}_1 \\\\ 1 \\\\ z^{\\star}_3 \\end{pmatrix}\n$$\n这产生了四个方程：\n1. $\\frac{1}{2}v^{\\star}_1 = -z^{\\star}_1$\n2. $\\frac{1}{2}v^{\\star}_1 = z^{\\star}_1 - 1$\n3. $\\frac{1}{2}v^{\\star}_2 = 1 - z^{\\star}_3$\n4. $\\frac{1}{2}v^{\\star}_2 = z^{\\star}_3$\n由方程 (1) 和 (2) 得：\n$-z^{\\star}_1 = z^{\\star}_1 - 1 \\implies 2z^{\\star}_1 = 1 \\implies z^{\\star}_1 = \\frac{1}{2}$。\n代回 (1) 中：$\\frac{1}{2}v^{\\star}_1 = -\\frac{1}{2} \\implies v^{\\star}_1 = -1$。\n由方程 (3) 和 (4) 得：\n$1 - z^{\\star}_3 = z^{\\star}_3 \\implies 2z^{\\star}_3 = 1 \\implies z^{\\star}_3 = \\frac{1}{2}$。\n代回 (4) 中：$\\frac{1}{2}v^{\\star}_2 = \\frac{1}{2} \\implies v^{\\star}_2 = 1$。\n因此，对偶证书是：\n$$\nv^{\\star} = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}, \\quad z^{\\star} = \\begin{pmatrix} \\frac{1}{2} \\\\ 1 \\\\ \\frac{1}{2} \\end{pmatrix}\n$$\n我们验证剩下的条件 $\\|z^{\\star}\\|_{\\infty} \\leq 1$：\n$\\|z^{\\star}\\|_{\\infty} = \\max(|\\frac{1}{2}|, |1|, |\\frac{1}{2}|) = 1$，该条件得到满足。\n所有最优性条件均已满足，证明了 $x^{\\star}$ 确实是一个极小化子。\n\n4. 计算最优对偶目标值。\n对偶问题的最优值由 $y^{\\top}v^{\\star}$ 给出。\n$$\ny^{\\top}v^{\\star} = \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix} = (0)(-1) + (1)(1) = 1\n$$\n根据强对偶性，该值必须等于原始最优值 $\\|Dx^{\\star}\\|_{1}$，即 $1$。结果是一致的。",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "一个变换是否能有效地稀疏表示一类信号，是其在图像压缩和处理中应用价值的关键。本练习将引导你通过编码实践，定量地比较两种经典的变换——离散余弦变换（DCT）和哈尔小波变换（Haar Wavelet）——在处理不同类型图像结构（如边缘、纹理和平滑区域）时的能量集中能力。通过这个动手实验，你将深入理解为何没有一种变换是万能的，以及如何根据信号特性选择合适的稀疏表示基。",
            "id": "3479024",
            "problem": "令 $x \\in \\mathbb{R}^{n \\times n}$ 表示一个在均匀网格上采样的边长为 $n$ 的方形图像块。考虑 $\\mathbb{R}^{n \\times n}$ 上的两种正交变换：带有正交缩放的二维II型离散余弦变换 (DCT)，以及带有二进多分辨率分解的二维正交哈尔小波变换。对于任意正交变换 $\\mathcal{T}:\\mathbb{R}^{n \\times n} \\to \\mathbb{R}^{n \\times n}$，定义变换系数为 $c = \\mathcal{T}(x)$，并定义由 $k$ 个最大幅值系数所捕获的能量分数为\n$$\nF_{\\mathcal{T}}(k; x) = \\frac{\\sum_{i \\in S_k} c_i^2}{\\sum_{i=1}^{n^2} c_i^2},\n$$\n其中 $S_k$ 索引了 $|c_i|$ 中最大的 $k$ 个条目，$c_i$ 以任意固定的线性化顺序枚举了 $c$ 的条目。由于 $\\mathcal{T}$ 是正交的，根据帕塞瓦尔恒等式，我们有 $\\sum_{i=1}^{n^2} c_i^2 = \\sum_{u,v=1}^{n} x_{uv}^2$。\n\n从正交变换、能量和帕塞瓦尔恒等式的定义出发，分析自然图像块在二维DCT与二维哈尔小波变换下的能量集中和稀疏性。使用能量分数度量 $F_{\\mathcal{T}}(k;x)$ 并研究其对 $k$ 的依赖性。\n\n使用 $n=32$ 构建一个确定性的图像块测试集，旨在反映自然图像中的常见结构（分段平滑边缘、纹理和平滑斑点）。每个图像块必须进行均值中心化并缩放至单位 $\\ell_2$ 范数，以使能量分数无量纲且具有可比性。三个类别明确定义如下：\n\n1. 边缘块（卡通状阶跃边缘）：对于角度 $\\theta \\in \\{0, \\pi/6, \\pi/3, \\pi/2\\}$，定义\n$$\nx_{\\text{edge}}(u,v;\\theta) = \\begin{cases}\n1,  \\cos(\\theta)\\left(\\frac{u}{n} - \\frac{1}{2}\\right) + \\sin(\\theta)\\left(\\frac{v}{n} - \\frac{1}{2}\\right) \\ge 0, \\\\\n0,  \\text{otherwise},\n\\end{cases}\n$$\n对于 $u,v \\in \\{0,1,\\dots,n-1\\}$，然后减去均值并缩放至单位 $\\ell_2$ 范数。\n\n2. 纹理块（余弦光栅之和）：对于四个预定义的空间频率和相位列表，\n- 频率 $\\{(1,2),(2,1),(3,0),(0,3)\\}$，相位 $\\{0, \\pi/4, \\pi/2, 3\\pi/4\\}$\n- 频率 $\\{(1,1),(2,0),(0,2),(3,3)\\}$，相位 $\\{\\pi/6, \\pi/3, \\pi/2, 2\\pi/3\\}$\n- 频率 $\\{(4,1),(1,4),(2,2),(0,1)\\}$，相位 $\\{\\pi/5, 2\\pi/5, 3\\pi/5, 4\\pi/5\\}$\n- 频率 $\\{(3,2),(2,3),(1,0),(0,1)\\}$，相位 $\\{0.1, 0.7, 1.2, 2.0\\}$\n定义\n$$\nx_{\\text{tex}}(u,v) = \\sum_{j=1}^{4} \\frac{1}{1 + \\sqrt{f_{x,j}^2 + f_{y,j}^2}} \\cos\\!\\left(2\\pi\\left(f_{x,j}\\frac{u}{n} + f_{y,j}\\frac{v}{n}\\right) + \\phi_j\\right),\n$$\n然后减去均值并缩放至单位 $\\ell_2$ 范数。\n\n3. 平滑斑点块（高斯函数之和）：对于四组中心、标准差和振幅的集合，定义\n$$\nx_{\\text{blob}}(u,v) = \\sum_{j=1}^{3} a_j \\exp\\!\\left(-\\frac{\\left(\\frac{u}{n} - c_{x,j}\\right)^2 + \\left(\\frac{v}{n} - c_{y,j}\\right)^2}{2\\sigma_j^2}\\right),\n$$\n参数为以下确定性值：\n- 中心 $\\{(0.3,0.3),(0.7,0.5),(0.5,0.8)\\}$，$\\sigma \\in \\{0.08,0.12,0.10\\}$，$a \\in \\{1.0,0.6,0.8\\}$；\n- 中心 $\\{(0.2,0.7),(0.6,0.2),(0.8,0.8)\\}$，$\\sigma \\in \\{0.10,0.09,0.11\\}$，$a \\in \\{0.9,0.7,0.5\\}$；\n- 中心 $\\{(0.4,0.4),(0.5,0.6),(0.7,0.3)\\}$，$\\sigma \\in \\{0.07,0.13,0.09\\}$，$a \\in \\{1.1,0.5,0.6\\}$；\n- 中心 $\\{(0.25,0.25),(0.75,0.75),(0.5,0.5)\\}$，$\\sigma \\in \\{0.12,0.12,0.08\\}$，$a \\in \\{0.8,0.8,1.0\\}$；\n然后减去均值并缩放至单位 $\\ell_2$ 范数。\n\n对于DCT，使用沿行和列可分离应用的、带有正交缩放的二维II型DCT。对于小波，使用二维正交哈尔变换，其二进分解通过在当前的低-低子带上沿行和列重复应用一维正交哈尔变换来实现，直到子带大小为 $1 \\times 1$。\n\n令 $k$ 值的集合为 $K = \\{0,1,4,16,64,256,n^2\\}$，其中 $n=32$，因此 $n^2=1024$。对于每个 $k \\in K$，计算在两种变换下整个测试集的平均能量分数，记为 $\\overline{F}_{\\text{DCT}}(k)$ 和 $\\overline{F}_{\\text{Haar}}(k)$。将每个 $k$ 的比较度量定义为差值\n$$\nD(k) = \\overline{F}_{\\text{DCT}}(k) - \\overline{F}_{\\text{Haar}}(k),\n$$\n这是一个实数。对于每种变换，答案是以小数表示的在 $[0,1]$ 区间内的无量纲分数；对于 $D(k)$，答案是实数。\n\n您的程序必须：\n- 按照规定构建 $12$ 个图像块（$4$ 个边缘，$4$ 个纹理，$4$ 个斑点），并对每个图像块进行均值中心化和单位范数归一化。\n- 实现二维正交DCT和二维正交哈尔变换。\n- 对于每个 $k \\in K$，计算这 $12$ 个图像块上的 $\\overline{F}_{\\text{DCT}}(k)$、$\\overline{F}_{\\text{Haar}}(k)$，然后计算 $D(k)$。\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的结果按 $K$ 中 $k$ 的顺序排列，即 $[D(0),D(1),D(4),D(16),D(64),D(256),D(1024)]$。\n\n测试集涵盖了边界条件（$k=0$ 和 $k=n^2$）和不同的稀疏尺度。最终输出是无物理单位的实数（浮点数）。",
            "solution": "用户提供了一个问题，要求对信号处理中两种著名的正交变换——二维离散余弦变换 (DCT) 和二维哈尔小波变换——进行对比分析，重点在于它们稀疏表示不同类型图像结构的能力。该对比将在一个明确定义的、由合成图像块组成的测试集上进行。\n\n分析基于**能量集中**的概念。在信号处理中，如果大部分信号能量可以被少数变换系数捕获，则称该变换为一类信号提供了稀疏表示。用于衡量这一点的度量是能量分数 $F_{\\mathcal{T}}(k; x)$，定义为：\n$$\nF_{\\mathcal{T}}(k; x) = \\frac{\\sum_{i \\in S_k} c_i^2}{\\sum_{i=1}^{n^2} c_i^2}\n$$\n此处，$c = \\mathcal{T}(x)$ 是图像块 $x \\in \\mathbb{R}^{n \\times n}$ 在正交变换 $\\mathcal{T}$ 下的系数。集合 $S_k$ 包含了具有最大幅值 $|c_i|$ 的 $k$ 个系数的索引。由于变换 $\\mathcal{T}$ 是正交的，帕塞瓦尔恒等式表明总能量在信号域和变换域之间是守恒的：$\\sum_{i=1}^{n^2} c_i^2 = \\sum_{u,v=1}^{n} x_{uv}^2 = \\|x\\|_F^2$，其中 $\\|x\\|_F$ 是弗罗贝尼乌斯范数。问题规定每个图像块 $x$ 都被归一化为单位 $\\ell_2$ 范数（对于向量化的矩阵，这等同于弗罗贝尼乌斯范数），这意味着 $\\|x\\|_F^2 = 1$。因此，能量分数公式中的分母始终为 1，从而将度量简化为前 $k$ 个系数的平方幅值之和：\n$$\nF_{\\mathcal{T}}(k; x) = \\sum_{i \\in S_k} c_i^2\n$$\n\n所考虑的两种变换具有性质截然不同的基函数，这导致它们在信号表示方面具有不同的优势。\n\n1.  **二维正交离散余弦变换 (DCT-II)**：DCT的基函数是不同频率的余弦函数。这些函数是平滑且非局域的（其支撑集覆盖整个图像块）。因此，DCT非常擅长表示平滑且高度相关的信号，这是自然图像中平滑变化区域的共同特征。二维DCT是可分离的，通过对图像块的行和列分别应用一维DCT来计算。对于正交变换，会应用特定的缩放因子：零频率系数为 $\\sqrt{1/n}$，所有其他频率系数为 $\\sqrt{2/n}$。\n\n2.  **二维正交哈尔小波变换**：哈尔小波系统由一个分段常数尺度函数（盒函数）和一个分段常数小波函数（方波）构建而成。其基函数在空间和频率上都是局域化的（尽管频率局域性较差）。这种空间局域性使得哈尔小波变换在表示具有尖锐不连续点（如边缘）的信号时非常有效，这些不连续点可以由相应位置和尺度上的少数小波系数紧凑地表示。指定的小波变换是一个二进多分辨率分解，其中可分离地应用一维哈尔变换，产生四个子带（LL, LH, HL, HH），然后将此过程递归地应用于低-低（LL）子带，直到留下一个 $1 \\times 1$ 的LL子带。\n\n该问题要求创建一个由 $12$ 个大小为 $n=32$ 的图像块组成的确定性测试集，旨在模拟三种基本的图像结构类型：\n*   **边缘块**：这些是卡通状图像，在不同方向上具有单个尖锐的阶跃边缘。由于其尖锐的、局域化的不连续性，预计哈尔变换将比DCT提供更紧凑的表示。\n*   **纹理块**：这些是通过对余弦光栅求和生成的。由于它们由正弦分量组成，其基函数也是正弦波的DCT预计将提供极其紧凑的表示。\n*   **平滑斑点块**：这些是通过对平滑高斯函数求和生成的。这些图像块的平滑性和高空间相关性使其成为通过DCT进行稀疏表示的理想候选项。\n\n对于生成的 $12$ 个图像块中的每一个，我们将执行以下步骤：\n1.  通过减去其均值来对图像块 $x$ 进行均值中心化，$x' = x - \\bar{x}$。\n2.  将图像块归一化至单位 $\\ell_2$ 范数，$x_{\\text{norm}} = x' / \\|x'\\|_2$。\n3.  计算变换系数 $c_{\\text{DCT}} = \\mathcal{T}_{\\text{DCT}}(x_{\\text{norm}})$ 和 $c_{\\text{Haar}} = \\mathcal{T}_{\\text{Haar}}(x_{\\text{norm}})$。\n4.  对于集合 $K = \\{0, 1, 4, 16, 64, 256, 1024\\}$ 中的每个 $k$ 值，计算能量分数 $F_{\\text{DCT}}(k; x_{\\text{norm}})$ 和 $F_{\\text{Haar}}(k; x_{\\text{norm}})$。这包括将系数的绝对值按降序排序，并对前 $k$ 个值的平方求和。\n5.  处理完所有 $12$ 个图像块后，为每个 $k \\in K$ 计算平均能量分数 $\\overline{F}_{\\text{DCT}}(k)$ 和 $\\overline{F}_{\\text{Haar}}(k)$。\n6.  最后，计算差值度量 $D(k) = \\overline{F}_{\\text{DCT}}(k) - \\overline{F}_{\\text{Haar}}(k)$。\n\n$D(k)$ 的正值表示，平均而言，DCT对前 $k$ 个系数实现了更好的能量集中；而负值则表示哈尔变换表现更优。$k=0$ 和 $k=n^2=1024$ 的值用作边界检查。当 $k=0$ 时，没有捕获任何能量，所以 $F(0)=0$ 且 $D(0)=0$。当 $k=n^2$ 时，所有能量都被捕获，所以 $F(n^2)=1$（根据帕塞瓦尔恒等式和单位范数），因此 $D(n^2)=0$。$D(k)$ 的中间值将揭示两种变换在不同稀疏级别下的相对性能。根据变换的性质和测试图像块的特点，我们预计对于大多数 $k$，$D(k)$ 将为正值，因为 $12$ 个图像块中有 $8$ 个（纹理和斑点）本质上是平滑或正弦的，这有利于DCT。边缘块将对总和产生负贡献，但其影响可能会被抵消。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.fft import dct\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the patch generation, transformation, and analysis.\n    \"\"\"\n    n = 32\n    K = [0, 1, 4, 16, 64, 256, 1024]\n    \n    patches = generate_patches(n)\n    \n    num_patches = len(patches)\n    num_k = len(K)\n    \n    F_dct_all = np.zeros((num_patches, num_k))\n    F_haar_all = np.zeros((num_patches, num_k))\n    \n    for i, patch in enumerate(patches):\n        # Apply transforms\n        c_dct = ortho_dct2(patch)\n        c_haar = ortho_haar2(patch)\n        \n        # Calculate energy fractions for each k\n        for j, k in enumerate(K):\n            F_dct_all[i, j] = calculate_energy_fraction(c_dct, k)\n            F_haar_all[i, j] = calculate_energy_fraction(c_haar, k)\n            \n    # Average over all patches\n    F_dct_avg = np.mean(F_dct_all, axis=0)\n    F_haar_avg = np.mean(F_haar_all, axis=0)\n    \n    # Compute the difference metric\n    D = F_dct_avg - F_haar_avg\n    \n    # Format and print the final output\n    print(f\"[{','.join(f'{d:.12f}' for d in D)}]\")\n\ndef _normalize_patch(patch):\n    \"\"\"Mean-centers and scales a patch to unit l2 norm.\"\"\"\n    p = patch - np.mean(patch)\n    norm = np.linalg.norm(p)\n    if norm > 1e-9:\n        return p / norm\n    return p\n\ndef generate_patches(n):\n    \"\"\"\n    Generates the test suite of 12 image patches.\n    \"\"\"\n    patches = []\n    \n    # Coordinate grids\n    u = np.arange(n)\n    v = np.arange(n)\n    uu, vv = np.meshgrid(u, v, indexing='ij')\n    \n    # 1. Edge Patches\n    x_coords_centered = uu / n - 0.5\n    y_coords_centered = vv / n - 0.5\n    thetas = [0, np.pi/6, np.pi/3, np.pi/2]\n    for theta in thetas:\n        patch = (np.cos(theta) * x_coords_centered + np.sin(theta) * y_coords_centered >= 0).astype(float)\n        patches.append(_normalize_patch(patch))\n\n    u_norm = uu / n\n    v_norm = vv / n\n\n    # 2. Texture Patches\n    tex_params = [\n        ({'freqs': [(1,2),(2,1),(3,0),(0,3)], 'phases': [0, np.pi/4, np.pi/2, 3*np.pi/4]}),\n        ({'freqs': [(1,1),(2,0),(0,2),(3,3)], 'phases': [np.pi/6, np.pi/3, np.pi/2, 2*np.pi/3]}),\n        ({'freqs': [(4,1),(1,4),(2,2),(0,1)], 'phases': [np.pi/5, 2*np.pi/5, 3*np.pi/5, 4*np.pi/5]}),\n        ({'freqs': [(3,2),(2,3),(1,0),(0,1)], 'phases': [0.1, 0.7, 1.2, 2.0]}),\n    ]\n    for params in tex_params:\n        patch = np.zeros((n, n))\n        for j in range(4):\n            fx, fy = params['freqs'][j]\n            phi = params['phases'][j]\n            weight = 1.0 / (1.0 + np.sqrt(fx**2 + fy**2))\n            patch += weight * np.cos(2 * np.pi * (fx * u_norm + fy * v_norm) + phi)\n        patches.append(_normalize_patch(patch))\n\n    # 3. Smooth Blob Patches\n    blob_params = [\n        ({'centers': [(0.3,0.3),(0.7,0.5),(0.5,0.8)], 'sigmas': [0.08,0.12,0.10], 'amps': [1.0,0.6,0.8]}),\n        ({'centers': [(0.2,0.7),(0.6,0.2),(0.8,0.8)], 'sigmas': [0.10,0.09,0.11], 'amps': [0.9,0.7,0.5]}),\n        ({'centers': [(0.4,0.4),(0.5,0.6),(0.7,0.3)], 'sigmas': [0.07,0.13,0.09], 'amps': [1.1,0.5,0.6]}),\n        ({'centers': [(0.25,0.25),(0.75,0.75),(0.5,0.5)], 'sigmas': [0.12,0.12,0.08], 'amps': [0.8,0.8,1.0]}),\n    ]\n    for params in blob_params:\n        patch = np.zeros((n, n))\n        for j in range(3):\n            cx, cy = params['centers'][j]\n            sigma = params['sigmas'][j]\n            a = params['amps'][j]\n            patch += a * np.exp(-((u_norm - cx)**2 + (v_norm - cy)**2) / (2 * sigma**2))\n        patches.append(_normalize_patch(patch))\n        \n    return patches\n\n\ndef ortho_dct2(x):\n    \"\"\"\n    Computes the 2D orthonormal DCT-II.\n    \"\"\"\n    return dct(dct(x, type=2, norm='ortho', axis=1), type=2, norm='ortho', axis=0)\n\ndef ortho_haar2(x):\n    \"\"\"\n    Computes the 2D orthonormal Haar wavelet transform with dyadic decomposition.\n    \"\"\"\n    n = x.shape[0]\n    h = x.copy()\n    L = n\n    sqrt2 = np.sqrt(2.0)\n    \n    while L > 1:\n        L_half = L // 2\n        # Operate on the current LL subband\n        subband = h[:L, :L]\n        \n        # 1D Haar on rows\n        rows_avg = (subband[:, 0::2] + subband[:, 1::2]) / sqrt2\n        rows_diff = (subband[:, 0::2] - subband[:, 1::2]) / sqrt2\n        transformed_rows = np.hstack((rows_avg, rows_diff))\n        \n        # 1D Haar on columns of the row-transformed matrix\n        cols_avg = (transformed_rows[0::2, :] + transformed_rows[1::2, :]) / sqrt2\n        cols_diff = (transformed_rows[0::2, :] - transformed_rows[1::2, :]) / sqrt2\n        transformed_cols = np.vstack((cols_avg, cols_diff))\n        \n        # Place the transformed result back into the main matrix\n        h[:L, :L] = transformed_cols\n        \n        L = L_half\n        \n    return h\n\n\ndef calculate_energy_fraction(c, k):\n    \"\"\"\n    Calculates the fraction of energy in the top-k magnitude coefficients.\n    Assumes total energy (denominator) is 1.\n    \"\"\"\n    if k == 0:\n        return 0.0\n    \n    c_flat = c.flatten()\n    # The problem implies that total energy is 1, so the fraction is simply\n    # the sum of squares of the k largest-magnitude coefficients.\n    \n    # Sort absolute values in descending order\n    sorted_abs_coeffs_sq = np.sort(np.abs(c_flat)**2)[::-1]\n    \n    # Sum the k largest squared coefficients\n    energy = np.sum(sorted_abs_coeffs_sq[:k])\n    \n    return energy\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "尽管总变差（TV）模型在图像去噪和重建中取得了巨大成功，但它也存在固有缺陷，比如会产生“阶梯效应”并系统性地压缩斜坡信号的斜率。本练习旨在通过实现一个更先进的二阶总广义变差（TGV）模型，让你直面并解决这些问题。在这个实践中，你将应用原始-对偶算法来比较TV和TGV在处理斜坡信号时的偏差，从而体会从基础模型向更精细化模型演进的必要性。",
            "id": "3478968",
            "problem": "要求您实现一个原始-对偶算法，使用二阶广义全变分 (TGV) 正则化对一维小信号进行去噪，并将其斜坡偏差与一阶全变分 (TV) 去噪进行比较。此任务必须基于以下基本概念完成：一个数据保真项与一个稀疏性诱导正则化器之和的凸优化、一维信号上的离散导数算子的定义，以及平方误差数据保真项的邻近算子。您不能假设任何非从这些基础直接推导出的结果，并且应从凸分析、对偶性和邻近分裂的第一性原理推导出您的算法更新步骤。\n\n考虑一个包含 $n$ 个样本的信号，表示为向量 $u \\in \\mathbb{R}^n$。令 $f \\in \\mathbb{R}^n$ 表示观测到的含噪数据。离散前向差分算子 $D : \\mathbb{R}^n \\to \\mathbb{R}^n$ 使用带有齐次诺伊曼边界条件的单边差分定义。数据保真项是平方误差 $F(u) = \\frac{1}{2}\\lVert u - f \\rVert_2^2$。一阶全变分 (TV) 正则化器是 $D u$ 的各向异性 $\\ell_1$ 范数。二阶广义全变分 (TGV$^2$) 引入一个辅助场 $w \\in \\mathbb{R}^n$，并以正常数作为权重，惩罚 $D u - w$ 和 $D w$ 的各向异性 $\\ell_1$ 范数。您的实现必须基于这些定义推导并使用一个原始-对偶方案，以计算 TV 和 TGV$^2$ 正则化的去噪解。\n\n将斜坡偏差定义为重建信号的估计斜率与潜在无噪声斜坡信号的真实斜率之间的差异。对于每次重建，通过对重建信号的所有样本进行最小二乘线性回归来估计斜率。分别计算 TV 和 TGV$^2$ 重建的绝对斜坡偏差，并报告这些绝对偏差之间的差值，定义为 $\\Delta = \\lvert b_{\\mathrm{TV}} \\rvert - \\lvert b_{\\mathrm{TGV}} \\rvert$，其中 $b_{\\mathrm{TV}}$ 和 $b_{\\mathrm{TGV}}$ 是相对于真实斜率的带符号斜率误差。$\\Delta$ 的正值表示 TGV$^2$ 表现出比 TV 更低的绝对偏差。\n\n在一个单一的自包含程序中实现这些算法，为以下测试套件生成结果。在所有情况下，算法均使用固定参数：样本数 $n = 32$，原始步长 $\\tau = 0.1$，对偶步长 $\\sigma = 0.1$，超松弛参数 $\\theta = 1$，迭代次数 $N_{\\mathrm{iter}} = 1000$，TV 正则化权重 $\\lambda_{\\mathrm{TV}} = 0.12$，以及 TGV$^2$ 权重 $\\alpha_1 = 0.8$ 和 $\\alpha_2 = 1.6$。为保证噪声的可复现性，使用固定的随机种子 42。所有量均为无量纲量。不涉及角度。没有物理单位。\n\n测试套件：\n- 案例 $1$ (理想情况)：一个线性斜坡信号 $u^\\star[i] = i/(n-1)$，$i \\in \\{0, \\dots, n-1\\}$，观测时带有均值为零、标准差为 $\\sigma_{\\mathrm{noise}} = 0.05$ 的加性独立同分布高斯噪声。按规定计算 $\\Delta$。\n- 案例 $2$ (边界条件覆盖)：一个常数信号 $u^\\star[i] = 0.5$，观测时带有均值为零、标准差为 $\\sigma_{\\mathrm{noise}} = 0.05$ 的加性独立同分布高斯噪声。按规定计算 $\\Delta$。\n- 案例 $3$ (边缘情况)：一个无噪声的线性斜坡信号 $u^\\star[i] = i/(n-1)$，其中 $\\sigma_{\\mathrm{noise}} = 0$。按规定计算 $\\Delta$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的浮点数列表，顺序为 $[\\Delta_{\\text{案例 }1}, \\Delta_{\\text{案例 }2}, \\Delta_{\\text{案例 }3}]$，每个数字四舍五入到六位小数（例如，$[0.123456,0.000001,-0.045000]$）。",
            "solution": "该问题要求实现并比较用于一维信号去噪的一阶全变分 (TV) 和二阶广义全变分 (TGV) 正则化。比较基于斜坡偏差，该偏差量化了每种方法保持线性斜率的能力。解决方案是使用原始-对偶算法，从凸优化的第一性原理推导得出。\n\n去噪问题的一般形式是找到一个信号 $u \\in \\mathbb{R}^n$，使其最小化一个复合目标函数：\n$$ u^* = \\arg\\min_{u \\in \\mathbb{R}^n} \\left( F(u) + R(u) \\right) $$\n其中 $F(u)$ 是数据保真项，$R(u)$ 是正则化器。问题指定数据保真项为与观测到的含噪信号 $f \\in \\mathbb{R}^n$ 之间的平方 $\\ell_2$ 范数距离，由 $F(u) = \\frac{1}{2}\\lVert u - f \\rVert_2^2$ 给出。\n\n该问题使用原始-对偶混合梯度 (PDHG) 方法求解，该方法也称为 Chambolle-Pock 算法，非常适合求解以下形式的问题：\n$$ \\min_{x} \\mathcal{F}(x) + \\mathcal{G}(Kx) $$\n其中 $\\mathcal{F}$ 和 $\\mathcal{G}$ 是正常、凸、下半连续函数，$K$ 是一个连续线性算子。该问题的迭代格式定义为：\n$$\n\\begin{cases}\ny^{k+1} = \\mathrm{prox}_{\\sigma \\mathcal{G}^*}(y^k + \\sigma K \\bar{x}^k) \\\\\nx^{k+1} = \\mathrm{prox}_{\\tau \\mathcal{F}}(x^k - \\tau K^* y^{k+1}) \\\\\n\\bar{x}^{k+1} = x^{k+1} + \\theta(x^{k+1} - x^k)\n\\end{cases}\n$$\n在这里，$x$ 是原始变量，$y$ 是对偶变量，$K^*$ 是 $K$ 的伴随算子，$\\mathcal{G}^*$ 是 $\\mathcal{G}$ 的凸共轭，而 $\\mathrm{prox}_{\\gamma H}(z) = \\arg\\min_v ( H(v) + \\frac{1}{2\\gamma} \\lVert v-z \\rVert_2^2 )$ 是邻近算子。算法参数包括原始步长 $\\tau > 0$、对偶步长 $\\sigma > 0$ 和超松弛参数 $\\theta \\in [0, 1]$。步长必须满足 $\\tau \\sigma \\lVert K \\rVert^2  1$。问题指定 $\\tau=0.1$，$\\sigma=0.1$ 和 $\\theta=1$。\n\n具有齐次诺伊曼边界条件的离散前向差分算子 $D: \\mathbb{R}^n \\to \\mathbb{R}^n$ 定义为对 $i \\in \\{0, \\dots, n-2\\}$ 有 $(Du)_i = u_{i+1} - u_i$，且 $(Du)_{n-1} = 0$。其伴随算子 $D^*: \\mathbb{R}^n \\to \\mathbb{R}^n$ 必须对所有 $u, p \\in \\mathbb{R}^n$ 满足 $\\langle Du, p \\rangle = \\langle u, D^*p \\rangle$。由此可得 $(D^*p)_0 = -p_0$，对 $i \\in \\{1, \\dots, n-2\\}$ 有 $(D^*p)_i = p_{i-1} - p_i$，以及 $(D^*p)_{n-1} = p_{n-2}$。\n\n对于 TV 和 TGV 模型，数据保真项分量 $\\mathcal{F}$ 及其邻近算子是共同的。令 $\\mathcal{F}(u) = \\frac{1}{2}\\lVert u - f \\rVert_2^2$。其邻近算子为：\n$$ \\mathrm{prox}_{\\tau \\mathcal{F}}(v) = \\arg\\min_u \\left( \\frac{1}{2}\\lVert u - f \\rVert_2^2 + \\frac{1}{2\\tau}\\lVert u - v \\rVert_2^2 \\right) = \\frac{v + \\tau f}{1 + \\tau} $$\n\n**一阶全变分 (TV) 去噪**\nTV 正则化问题为：\n$$ \\min_{u \\in \\mathbb{R}^n} \\frac{1}{2}\\lVert u - f \\rVert_2^2 + \\lambda_{\\mathrm{TV}} \\lVert Du \\rVert_1 $$\n这符合 PDHG 框架，并作如下设定：\n- 原始变量 $x = u \\in \\mathbb{R}^n$。\n- $\\mathcal{F}(u) = \\frac{1}{2}\\lVert u - f \\rVert_2^2$。\n- $\\mathcal{G}(y) = \\lambda_{\\mathrm{TV}} \\lVert y \\rVert_1$，其中 $y \\in \\mathbb{R}^n$ 是一个通用变量。\n- 线性算子 $K = D$。\n\n$\\mathcal{G}$ 的凸共轭是 $\\mathcal{G}^*(p) = I_{\\lVert \\cdot \\rVert_\\infty \\le \\lambda_{\\mathrm{TV}}}(p)$，即半径为 $\\lambda_{\\mathrm{TV}}$ 的 $\\ell_\\infty$ 球的指示函数。$\\mathcal{G}^*$ 的邻近算子是到这个球上的投影：\n$$ \\mathrm{prox}_{\\sigma \\mathcal{G}^*}(v) = \\mathrm{proj}_{\\lVert \\cdot \\rVert_\\infty \\le \\lambda_{\\mathrm{TV}}}(v) $$\n这个投影是按元素计算的，即 $(v_i)_{\\text{proj}} = v_i / \\max(1, |v_i|/\\lambda_{\\mathrm{TV}})$。\n完整的 TV 去噪算法如下：\n1. 初始化 $u^0$，$\\bar{u}^0 = u^0$，以及对偶变量 $y^0$。\n2. 对 $k=0, 1, \\dots, N_{\\mathrm{iter}}-1$：\n   $y^{k+1} = \\mathrm{proj}_{\\lVert \\cdot \\rVert_\\infty \\le \\lambda_{\\mathrm{TV}}}(y^k + \\sigma D \\bar{u}^k)$\n   $u^{k+1} = \\frac{(u^k - \\tau D^* y^{k+1}) + \\tau f}{1 + \\tau}$\n   $\\bar{u}^{k+1} = u^{k+1} + \\theta(u^{k+1} - u^k)$\n\n**二阶广义全变分 (TGV$^2$) 去噪**\nTGV$^2$ 正则化问题是关于信号 $u$ 和辅助场 $w \\in \\mathbb{R}^n$ 的联合最小化问题：\n$$ \\min_{u, w} \\frac{1}{2}\\lVert u - f \\rVert_2^2 + \\alpha_1 \\lVert Du - w \\rVert_1 + \\alpha_2 \\lVert Dw \\rVert_1 $$\n为了将其纳入 PDHG 框架，我们定义一个复合原始变量 $x = (u, w) \\in \\mathbb{R}^{2n}$。\n- $\\mathcal{F}(u, w) = \\frac{1}{2}\\lVert u - f \\rVert_2^2 + 0 \\cdot \\lVert w \\rVert_2^2$。\n- $\\mathcal{G}(z_1, z_2) = \\alpha_1 \\lVert z_1 \\rVert_1 + \\alpha_2 \\lVert z_2 \\rVert_1$，对于 $(z_1, z_2) \\in \\mathbb{R}^{2n}$。\n- 线性算子 $K(u,w) = \\begin{pmatrix} Du - w \\\\ Dw \\end{pmatrix} = \\begin{pmatrix} D  -I \\\\ 0  D \\end{pmatrix} \\begin{pmatrix} u \\\\ w \\end{pmatrix}$。\n\n伴随算子是 $K^* = \\begin{pmatrix} D^*  0 \\\\ -I  D^* \\end{pmatrix}$。对偶变量是 $y=(p,q) \\in \\mathbb{R}^{2n}$。\n$\\mathcal{F}$ 的邻近算子对 $u$ 和 $w$ 是可分的：\n$$ \\mathrm{prox}_{\\tau\\mathcal{F}}((v_u, v_w)) = \\left(\\frac{v_u + \\tau f}{1+\\tau}, v_w\\right) $$\n共轭函数 $\\mathcal{G}^*$ 是集合 $\\{ (p,q) \\mid \\lVert p \\rVert_\\infty \\le \\alpha_1, \\lVert q \\rVert_\\infty \\le \\alpha_2 \\}$ 的指示函数。其邻近算子是到该集合上的投影，该投影对 $p$ 和 $q$ 是可分的。\nTGV$^2$ 去噪算法如下：\n1. 初始化 $u^0, w^0$，$\\bar{u}^0=u^0, \\bar{w}^0=w^0$，以及对偶变量 $p^0, q^0$。\n2. 对 $k=0, 1, \\dots, N_{\\mathrm{iter}}-1$：\n   $p^{k+1} = \\mathrm{proj}_{\\lVert \\cdot \\rVert_\\infty \\le \\alpha_1}(p^k + \\sigma(D\\bar{u}^k - \\bar{w}^k))$\n   $q^{k+1} = \\mathrm{proj}_{\\lVert \\cdot \\rVert_\\infty \\le \\alpha_2}(q^k + \\sigma D\\bar{w}^k)$\n   $u_{v} = u^k - \\tau D^*p^{k+1}$\n   $w_{v} = w^k - \\tau(-p^{k+1} + D^*q^{k+1})$\n   $u^{k+1} = \\frac{u_v + \\tau f}{1+\\tau}$\n   $w^{k+1} = w_v$\n   $\\bar{u}^{k+1} = u^{k+1} + \\theta(u^{k+1} - u^k)$\n   $\\bar{w}^{k+1} = w^{k+1} + \\theta(w^{k+1} - w^k)$\n\n**斜坡偏差计算**\n对于每个重建信号 $u_{\\text{recon}}$，通过最小二乘回归找到最小化 $\\sum_{i=0}^{n-1} ( (m \\cdot i + c) - u_{\\text{recon}}[i] )^2$ 的系数 $m$ 来估计其斜率。带符号的斜率误差（即偏差）为 $b = m - m^\\star$，其中 $m^\\star$ 是真实潜在信号的斜率。对于线性斜坡信号 $u^\\star[i] = i/(n-1)$，$m^\\star = 1/(n-1)$。对于常数信号，$m^\\star = 0$。最终的度量指标是绝对偏差之差：$\\Delta = |b_{\\mathrm{TV}}| - |b_{\\mathrm{TGV}}|$。正的 $\\Delta$ 值表示 TGV$^2$ 的绝对斜坡偏差更小，因此能更好地保留线性结构，这是 TGV$^2$ 相较于 TV 的一个已知理论优势。实现部分将为指定的测试套件执行这些推导出的算法。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the denoising experiments and compute the ramp bias difference.\n    Implements primal-dual algorithms for TV and TGV denoising from first principles.\n    \"\"\"\n    # --- Global Problem Parameters ---\n    N = 32\n    TAU = 0.1\n    SIGMA = 0.1\n    THETA = 1.0\n    N_ITER = 1000\n    LAMBDA_TV = 0.12\n    ALPHA1 = 0.8\n    ALPHA2 = 1.6\n    SEED = 42\n\n    # --- Operator Definitions ---\n    def D_op(u):\n        \"\"\"Discrete forward difference operator with homogeneous Neumann boundary.\"\"\"\n        n = len(u)\n        res = np.zeros(n, dtype=np.float64)\n        res[:-1] = u[1:] - u[:-1]\n        # res[-1] is 0 by initialization\n        return res\n\n    def D_adj_op(p):\n        \"\"\"Adjoint of the discrete forward difference operator.\"\"\"\n        n = len(p)\n        res = np.zeros(n, dtype=np.float64)\n        res[0] = -p[0]\n        if n > 2:\n            res[1:-1] = p[:-2] - p[1:-1]\n        if n > 1:\n            res[-1] = p[-2]\n        return res\n\n    # --- Denoising Algorithms ---\n    def denoise_tv(f):\n        \"\"\"\n        TV denoising using a primal-dual algorithm.\n        min_u 0.5 * ||u - f||^2 + LAMBDA_TV * ||Du||_1\n        \"\"\"\n        u = np.copy(f)\n        u_bar = np.copy(u)\n        y = np.zeros_like(f)\n\n        for _ in range(N_ITER):\n            u_old = np.copy(u)\n            \n            # Dual update using prox of the conjugate\n            y_update_arg = y + SIGMA * D_op(u_bar)\n            denom = np.maximum(1.0, np.abs(y_update_arg) / LAMBDA_TV)\n            y = y_update_arg / denom\n\n            # Primal update using prox of the data fidelity term\n            prox_arg = u_old - TAU * D_adj_op(y)\n            u = (prox_arg + TAU * f) / (1.0 + TAU)\n            \n            # Over-relaxation step\n            u_bar = u + THETA * (u - u_old)\n        \n        return u\n\n    def denoise_tgv(f):\n        \"\"\"\n        TGV denoising using a primal-dual algorithm.\n        min_{u,w} 0.5*||u-f||^2 + ALPHA1*||Du-w||_1 + ALPHA2*||Dw||_1\n        \"\"\"\n        u = np.copy(f)\n        u_bar = np.copy(u)\n        w = np.zeros_like(f)\n        w_bar = np.zeros_like(f)\n        p = np.zeros_like(f)\n        q = np.zeros_like(f)\n        \n        for _ in range(N_ITER):\n            u_old = np.copy(u)\n            w_old = np.copy(w)\n            \n            # Dual update for (p, q)\n            v_p = p + SIGMA * (D_op(u_bar) - w_bar)\n            v_q = q + SIGMA * D_op(w_bar)\n            \n            p = v_p / np.maximum(1.0, np.abs(v_p) / ALPHA1)\n            q = v_q / np.maximum(1.0, np.abs(q) / ALPHA2)\n            \n            # Primal update for (u, w)\n            v_u = u_old - TAU * D_adj_op(p)\n            v_w = w_old - TAU * (-p + D_adj_op(q))\n            \n            u = (v_u + TAU * f) / (1.0 + TAU)\n            w = v_w\n            \n            # Over-relaxation step\n            u_bar = u + THETA * (u - u_old)\n            w_bar = w + THETA * (w - w_old)\n            \n        return u\n\n    # --- Bias Calculation ---\n    def get_slope(u):\n        \"\"\"Estimate the slope of a signal using linear least squares.\"\"\"\n        n = len(u)\n        x = np.arange(n, dtype=np.float64)\n        A = np.vstack([x, np.ones(n)]).T\n        m, _ = np.linalg.lstsq(A, u, rcond=None)[0]\n        return m\n\n    # --- Test Suite Execution ---\n    rng = np.random.default_rng(SEED)\n    test_specs = [\n        {'type': 'ramp', 'noise_std': 0.05},\n        {'type': 'const', 'noise_std': 0.05},\n        {'type': 'ramp', 'noise_std': 0.0},\n    ]\n    \n    results = []\n    for spec in test_specs:\n        if spec['type'] == 'ramp':\n            u_star = np.arange(N, dtype=np.float64) / (N - 1)\n            true_slope = 1.0 / (N - 1)\n        else: # 'const'\n            u_star = np.full(N, 0.5, dtype=np.float64)\n            true_slope = 0.0\n\n        if spec['noise_std'] > 0:\n            noise = rng.normal(0, spec['noise_std'], N)\n            f = u_star + noise\n        else:\n            f = u_star\n            \n        # Perform denoising\n        u_tv = denoise_tv(f)\n        u_tgv = denoise_tgv(f)\n        \n        # Calculate slope errors (bias)\n        slope_tv = get_slope(u_tv)\n        slope_tgv = get_slope(u_tgv)\n        \n        bias_tv = slope_tv - true_slope\n        bias_tgv = slope_tgv - true_slope\n        \n        # Calculate delta of absolute biases\n        delta = np.abs(bias_tv) - np.abs(bias_tgv)\n        results.append(delta)\n\n    # --- Format and Print Output according to problem specification ---\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}