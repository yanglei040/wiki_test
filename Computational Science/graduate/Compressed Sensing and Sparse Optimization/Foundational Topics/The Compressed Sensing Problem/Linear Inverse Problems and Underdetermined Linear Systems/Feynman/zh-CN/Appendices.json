{
    "hands_on_practices": [
        {
            "introduction": "LASSO是求解欠定线性问题的基石，它通过引入$\\ell_1$范数惩罚项来促进解的稀疏性。要真正理解LASSO的工作原理，关键在于认识到其解是关于正则化参数$\\lambda$的分段线性函数。通过手动追踪一个小规模问题的完整解路径，你将深入理解$\\lambda$如何调控数据保真度与稀疏性之间的权衡，并清晰地观察到变量是如何随着$\\lambda$的变化进入或离开模型（即活性集）的。",
            "id": "3457315",
            "problem": "考虑最小绝对收缩和选择算子 (LASSO) 问题，其中测量矩阵为 $A \\in \\mathbb{R}^{2 \\times 4}$，未知系数向量为 $x \\in \\mathbb{R}^{4}$，观测值为 $y \\in \\mathbb{R}^{2}$：\n$$\n\\min_{x \\in \\mathbb{R}^{4}} \\ \\frac{1}{2} \\| y - A x \\|_{2}^{2} + \\lambda \\| x \\|_{1},\n$$\n其中 $A$ 的列是由下式定义的单位范数原子\n$$\na_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad a_{2} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad a_{3} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\quad a_{4} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix},\n$$\n且观测值为\n$$\ny = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}.\n$$\n令 $x(\\lambda)$ 表示对于每个 $\\lambda \\geq 0$ 的唯一 LASSO 解。从 LASSO 最优性的基本 Karush-Kuhn-Tucker (KKT) 条件出发，确定所有使得 $x(\\lambda)$ 的活性集和/或符号模式发生变化的断点 $\\lambda$，并推导出当 $\\lambda$ 从最大断点递减至 $0$ 时，在每个分段上 $x(\\lambda)$ 的精确分段线性表达式。对于每个开区间和每个断点，显式地验证活性和非活性坐标的 KKT 条件。\n\n以精确的闭式形式表示所有量。作为最终答案，请以降序将断点向量报告为行矩阵。不要对最终答案进行四舍五入。最终答案必须以无单位的单个表达式给出。",
            "solution": "用户想要找到一个特定 LASSO 问题的解路径。\n\nLASSO 问题由下式给出：\n$$ \\min_{x \\in \\mathbb{R}^{4}} \\ \\frac{1}{2} \\| y - A x \\|_{2}^{2} + \\lambda \\| x \\|_{1} $$\n最优性的 Karush-Kuhn-Tucker (KKT) 条件表明，零向量必须位于目标函数的次微分中。这意味着存在一个向量 $s \\in \\partial \\|x\\|_1$ 使得：\n$$ A^T(y - Ax) = \\lambda s $$\n其中 $s$ 是 $\\ell_1$-范数的次梯度，其分量 $s_i$ 满足：\n$$\ns_i = \\begin{cases}\n\\text{sign}(x_i)   \\text{若 } x_i \\neq 0 \\\\\n\\in [-1, 1]   \\text{若 } x_i = 0\n\\end{cases}\n$$\n令 $\\mathcal{I} = \\{i \\mid x_i \\neq 0\\}$ 为活性集。KKT 条件可以分为两部分：\n1.  对于活性指标 $i \\in \\mathcal{I}$：$a_i^T(y - Ax) = \\lambda \\cdot \\text{sign}(x_i)$。\n2.  对于非活性指标 $j \\notin \\mathcal{I}$：$|a_j^T(y - Ax)| \\leq \\lambda$。\n\n我们追踪当 $\\lambda$ 从一个较大的值递减时解的路径 $x(\\lambda)$。\n\n**第一段：寻找第一个断点 $\\lambda_1$**\n\n对于足够大的 $\\lambda$，$\\ell_1$ 惩罚项占主导地位，迫使解为 $x(\\lambda) = 0$。在这种情况下，活性集为空集，$\\mathcal{I} = \\emptyset$。KKT 条件简化为对所有 $i=1, 2, 3, 4$ 都有 $|a_i^T(y-A\\cdot 0)| \\leq \\lambda$。这等价于 $\\lambda \\geq \\max_i |a_i^T y|$。\n我们来计算相关性 $c = A^T y$：\n$A = \\begin{pmatrix} 1  0  \\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{2}} \\\\ 0  1  \\frac{1}{\\sqrt{2}}  -\\frac{1}{\\sqrt{2}} \\end{pmatrix}$, $y = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$。\n$c_1 = a_1^T y = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 2$。\n$c_2 = a_2^T y = \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 1$。\n$c_3 = a_3^T y = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\frac{3}{\\sqrt{2}}$。\n$c_4 = a_4^T y = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1  -1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sqrt{2}}$。\n\n第一个（最大的）断点 $\\lambda_1$ 是使其中一个不等式变为等式的 $\\lambda$ 值：\n$$ \\lambda_1 = \\max_{i} |c_i| = \\max \\left\\{ 2, 1, \\frac{3}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}} \\right\\} = \\frac{3}{\\sqrt{2}} $$\n对于所有 $\\lambda \\geq \\lambda_1$，解为 $x(\\lambda) = 0$。在 $\\lambda_1 = 3/\\sqrt{2}$ 处，原子 $a_3$ 变为活性的。$x_3$ 的符号将是 $\\text{sign}(c_3) = +1$。\n\n**第二段：$\\lambda \\in (\\lambda_2, \\lambda_1)$ 的路径**\n\n对于 $\\lambda  \\lambda_1$，活性集为 $\\mathcal{I} = \\{3\\}$，且 $x_3$ 的符号为 $s_3=1$。解向量的形式为 $x(\\lambda) = (0, 0, x_3(\\lambda), 0)^T$，其中 $x_3(\\lambda) > 0$。\n活性集的 KKT 条件是 $a_3^T(y - a_3 x_3) = \\lambda s_3 = \\lambda$。\n由于原子是单位范数的（$a_3^T a_3 = 1$），这变为 $a_3^T y - x_3 = \\lambda$，从而得到：\n$$ x_3(\\lambda) = a_3^T y - \\lambda = \\frac{3}{\\sqrt{2}} - \\lambda $$\n只要 $x_3(\\lambda)>0$（即 $\\lambda  \\lambda_1$）且非活性原子 $i \\in \\{1, 2, 4\\}$ 的 KKT 条件 $|a_i^T(y - a_3 x_3(\\lambda))| \\leq \\lambda$ 得到满足，该路径就有效。\n令 $r(\\lambda) = y - a_3 x_3(\\lambda)$。相关性为 $a_i^T r(\\lambda) = a_i^T y - (a_i^T a_3) x_3(\\lambda)$。\n我们需要内积：$a_1^T a_3 = 1/\\sqrt{2}$，$a_2^T a_3 = 1/\\sqrt{2}$，$a_4^T a_3 = 0$。\n\n对于 $i=1$：$a_1^T r(\\lambda) = c_1 - (a_1^T a_3)x_3(\\lambda) = 2 - \\frac{1}{\\sqrt{2}}(\\frac{3}{\\sqrt{2}} - \\lambda) = 2 - \\frac{3}{2} + \\frac{\\lambda}{\\sqrt{2}} = \\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}}$。\n条件 $|a_1^T r(\\lambda)| \\leq \\lambda$ 变为 $\\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}} \\leq \\lambda$（因为当 $\\lambda>0$ 时该项为正）。\n这得到 $\\frac{1}{2} \\leq \\lambda(1 - \\frac{1}{\\sqrt{2}})$，所以 $\\lambda \\geq \\frac{1/2}{1-1/\\sqrt{2}} = \\frac{\\sqrt{2}}{2(\\sqrt{2}-1)} = \\frac{\\sqrt{2}(\\sqrt{2}+1)}{2} = \\frac{2+\\sqrt{2}}{2}$。\n\n对于 $i=2$：$a_2^T r(\\lambda) = c_2 - (a_2^T a_3)x_3(\\lambda) = 1 - \\frac{1}{\\sqrt{2}}(\\frac{3}{\\sqrt{2}} - \\lambda) = 1 - \\frac{3}{2} + \\frac{\\lambda}{\\sqrt{2}} = -\\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}}$。\n条件是 $|-\\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}}| \\leq \\lambda$。这给出两个不等式：\n(a) $-\\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}} \\leq \\lambda \\implies -\\frac{1}{2} \\leq \\lambda(1-\\frac{1}{\\sqrt{2}})$，这对 $\\lambda>0$ 成立。\n(b) $-\\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}} \\geq -\\lambda \\implies \\frac{1}{2} \\leq \\lambda(1+\\frac{1}{\\sqrt{2}})$，所以 $\\lambda \\geq \\frac{1/2}{1+1/\\sqrt{2}} = \\frac{\\sqrt{2}}{2(\\sqrt{2}+1)} = \\frac{2-\\sqrt{2}}{2}$。\n\n对于 $i=4$：$a_4^T r(\\lambda) = c_4 - (a_4^T a_3)x_3(\\lambda) = \\frac{1}{\\sqrt{2}} - 0 = \\frac{1}{\\sqrt{2}}$。\n条件是 $|\\frac{1}{\\sqrt{2}}| \\leq \\lambda$，所以 $\\lambda \\geq \\frac{1}{\\sqrt{2}}$。\n\n下一个断点 $\\lambda_2$ 是其中一个不等式变为等式的点。这发生在边界值中最大的 $\\lambda  \\lambda_1$ 处：\n$$ \\lambda_2 = \\max\\left\\{ \\frac{2+\\sqrt{2}}{2}, \\frac{2-\\sqrt{2}}{2}, \\frac{1}{\\sqrt{2}} \\right\\} $$\n数值近似为 $1.707$、$0.293$、$0.707$。最大值是 $\\frac{2+\\sqrt{2}}{2}$。\n该值小于 $\\lambda_1 = 3/\\sqrt{2} \\approx 2.121$。\n所以，第二个断点是 $\\lambda_2 = \\frac{2+\\sqrt{2}}{2} = 1 + \\frac{\\sqrt{2}}{2}$。\n在 $\\lambda_2$ 处，我们有 $a_1^T r(\\lambda_2) = \\lambda_2$，原子 $a_1$ 进入活性集。其符号为 $\\text{sign}(a_1^T r(\\lambda_2)) = +1$。\n\n**第三段：$\\lambda \\in (0, \\lambda_2)$ 的路径**\n\n对于 $\\lambda  \\lambda_2$，活性集为 $\\mathcal{I}=\\{1, 3\\}$，符号为 $s_1=1, s_3=1$。解的形式为 $x(\\lambda)=(x_1(\\lambda), 0, x_3(\\lambda), 0)^T$。\n活性集的 KKT 条件是 $A_{\\mathcal{I}}^T(y - A_{\\mathcal{I}}x_{\\mathcal{I}}) = \\lambda s_{\\mathcal{I}}$，其中 $A_{\\mathcal{I}}=[a_1, a_3]$ 且 $x_{\\mathcal{I}} = [x_1, x_3]^T$。\n这得到 $A_{\\mathcal{I}}^T A_{\\mathcal{I}} x_{\\mathcal{I}} = A_{\\mathcal{I}}^T y - \\lambda s_{\\mathcal{I}}$。\n$A_{\\mathcal{I}}^T A_{\\mathcal{I}} = \\begin{pmatrix} a_1^T a_1  a_1^T a_3 \\\\ a_3^T a_1  a_3^T a_3 \\end{pmatrix} = \\begin{pmatrix} 1  1/\\sqrt{2} \\\\ 1/\\sqrt{2}  1 \\end{pmatrix}$。\n其逆矩阵为 $(A_{\\mathcal{I}}^T A_{\\mathcal{I}})^{-1} = \\frac{1}{1-1/2}\\begin{pmatrix} 1  -1/\\sqrt{2} \\\\ -1/\\sqrt{2}  1 \\end{pmatrix} = \\begin{pmatrix} 2  -\\sqrt{2} \\\\ -\\sqrt{2}  2 \\end{pmatrix}$。\n$A_{\\mathcal{I}}^T y = \\begin{pmatrix} c_1 \\\\ c_3 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 3/\\sqrt{2} \\end{pmatrix}$ 且 $s_{\\mathcal{I}} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n所以，$x_{\\mathcal{I}}(\\lambda) = (A_{\\mathcal{I}}^T A_{\\mathcal{I}})^{-1} (A_{\\mathcal{I}}^T y - \\lambda s_{\\mathcal{I}}) = \\begin{pmatrix} 2  -\\sqrt{2} \\\\ -\\sqrt{2}  2 \\end{pmatrix} \\begin{pmatrix} 2-\\lambda \\\\ 3/\\sqrt{2}-\\lambda \\end{pmatrix}$。\n$x_1(\\lambda) = 2(2-\\lambda) - \\sqrt{2}(3/\\sqrt{2}-\\lambda) = 4 - 2\\lambda - 3 + \\sqrt{2}\\lambda = 1 + (\\sqrt{2}-2)\\lambda$。\n$x_3(\\lambda) = -\\sqrt{2}(2-\\lambda) + 2(3/\\sqrt{2}-\\lambda) = -2\\sqrt{2} + \\sqrt{2}\\lambda + 3\\sqrt{2} - 2\\lambda = \\sqrt{2} + (\\sqrt{2}-2)\\lambda$。\n\n我们检查下一个断点。当一个活性系数变为零，或一个非活性原子的相关性达到 $\\pm \\lambda$ 时，就会出现断点。\n- `活性系数`：\n  $x_1(\\lambda) = 1+(\\sqrt{2}-2)\\lambda  0 \\implies 1  (2-\\sqrt{2})\\lambda \\implies \\lambda  \\frac{1}{2-\\sqrt{2}} = \\frac{2+\\sqrt{2}}{2} = \\lambda_2$。所以对于 $\\lambda  \\lambda_2$，$x_1(\\lambda)>0$。\n  $x_3(\\lambda) = \\sqrt{2}+(\\sqrt{2}-2)\\lambda  0 \\implies \\sqrt{2}  (2-\\sqrt{2})\\lambda \\implies \\lambda  \\frac{\\sqrt{2}}{2-\\sqrt{2}} = \\frac{\\sqrt{2}(2+\\sqrt{2})}{2} = 1+\\sqrt{2}$。由于 $1+\\sqrt{2}  \\lambda_2$，$x_3(\\lambda)$ 在 $\\lambda \\in (0, \\lambda_2)$ 区间内保持为正。\n  在 $\\lambda \\in (0, \\lambda_2)$ 区间内，符号保持一致，没有活性系数变为零。\n\n- `非活性系数` $i \\in \\{2, 4\\}$：\n  残差为 $r(\\lambda) = y - a_1x_1(\\lambda) - a_3x_3(\\lambda)$。\n  对于 $i=2$：$a_2^T r(\\lambda) = c_2 - (a_2^T a_1)x_1(\\lambda) - (a_2^T a_3)x_3(\\lambda) = 1 - 0 - \\frac{1}{\\sqrt{2}}x_3(\\lambda)$。\n  $a_2^T r(\\lambda) = 1 - \\frac{1}{\\sqrt{2}}(\\sqrt{2}+(\\sqrt{2}-2)\\lambda) = 1 - (1+\\frac{\\sqrt{2}-2}{\\sqrt{2}}\\lambda) = - (1-\\sqrt{2})\\lambda = (\\sqrt{2}-1)\\lambda$。\n  条件是 $|a_2^T r(\\lambda)| \\leq \\lambda \\implies |(\\sqrt{2}-1)\\lambda| \\leq \\lambda \\implies (\\sqrt{2}-1)\\lambda \\leq \\lambda$，这简化为 $\\sqrt{2}-1 \\leq 1$ 或 $\\sqrt{2} \\leq 2$。对于 $\\lambda>0$，此不等式是严格的，因此原子 2 永远不会变为活性的。\n  对于 $i=4$：$a_4^T r(\\lambda) = c_4 - (a_4^T a_1)x_1(\\lambda) - (a_4^T a_3)x_3(\\lambda) = \\frac{1}{\\sqrt{2}} - \\frac{1}{\\sqrt{2}}x_1(\\lambda) - 0$。\n  $a_4^T r(\\lambda) = \\frac{1}{\\sqrt{2}}(1-x_1(\\lambda)) = \\frac{1}{\\sqrt{2}}(1 - (1+(\\sqrt{2}-2)\\lambda)) = \\frac{1}{\\sqrt{2}}(-(\\sqrt{2}-2)\\lambda) = \\frac{2-\\sqrt{2}}{\\sqrt{2}}\\lambda = (\\sqrt{2}-1)\\lambda$。\n  这与原子 2 的相关性相同，对于 $\\lambda > 0$，它也严格小于 $\\lambda$。\n\n对于 $\\lambda \\in (0, \\lambda_2)$，没有新事件发生。活性集和符号模式在 $\\lambda$ 降至 $0$ 的过程中保持不变。\n因此，对于 $\\lambda>0$，只有两个断点。\n\n断点按降序排列为：\n$\\lambda_1 = \\frac{3}{\\sqrt{2}} = \\frac{3\\sqrt{2}}{2}$\n$\\lambda_2 = 1 + \\frac{\\sqrt{2}}{2} = \\frac{2+\\sqrt{2}}{2}$\n\n解路径 $x(\\lambda)$ 的总结：\n1.  对于 $\\lambda \\geq \\frac{3\\sqrt{2}}{2}$：$x(\\lambda) = (0, 0, 0, 0)^T$。\n2.  对于 $\\lambda \\in [\\frac{2+\\sqrt{2}}{2}, \\frac{3\\sqrt{2}}{2})$：$x(\\lambda) = (0, 0, \\frac{3}{\\sqrt{2}}-\\lambda, 0)^T$。\n3.  对于 $\\lambda \\in [0, \\frac{2+\\sqrt{2}}{2})$：$x(\\lambda) = (1+(\\sqrt{2}-2)\\lambda, 0, \\sqrt{2}+(\\sqrt{2}-2)\\lambda, 0)^T$。\n\n问题要求的是断点向量。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{3\\sqrt{2}}{2}  \\frac{2+\\sqrt{2}}{2} \\end{pmatrix} } $$"
        },
        {
            "introduction": "标准LASSO促进的是单个系数的稀疏性，但在许多实际应用中，我们需要同时选择或剔除一组相关的变量，例如代表某个分类特征的所有虚拟变量。组LASSO（Group LASSO）通过使用混合的$\\ell_{2,1}$范数将稀疏性推广到变量组的层面。这项练习要求你推导组LASSO的优化条件（KKT条件）及其对应的块软阈值算子，这将巩固你对结构化稀疏性及其算法基础的理解。",
            "id": "3457329",
            "problem": "考虑一个欠定线性反问题，其数据矩阵为 $A \\in \\mathbb{R}^{m \\times n}$，观测向量为 $b \\in \\mathbb{R}^{m}$，其中 $m  n$。令 $\\mathcal{G}$ 为 $\\{1,2,\\ldots,n\\}$ 的一个划分为不相交的组，对于任意 $x \\in \\mathbb{R}^{n}$，根据此划分记为 $x = [x_{g}]_{g \\in \\mathcal{G}}$。定义组套索范数为 $\\|x\\|_{2,1} = \\sum_{g \\in \\mathcal{G}} \\|x_{g}\\|_{2}$。考虑以下凸优化问题\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\; \\frac{1}{2}\\|A x - b\\|_{2}^{2} + \\lambda \\|x\\|_{2,1},\n$$\n其中正则化参数 $\\lambda  0$。\n\n任务：\n1) 仅使用凸函数的一阶最优性条件和范数的次微分定义，推导上述问题最小化子 $x^{\\star}$ 的 Karush-Kuhn-Tucker (KKT) 条件。对每个组 $g \\in \\mathcal{G}$ 分组表达该条件。\n\n2) 从次微分的刻画出发，推导表征函数 $x \\mapsto \\lambda \\|x\\|_{2,1}$ 的邻近算子的块软阈值规则，然后给出最小化目标函数的邻近梯度迭代法。你的推导必须从邻近子问题的一阶充要最优性条件开始，并通过对每个块进行最小化来继续。\n\n3) 现在，具体到以下实例：$m = 3$，$n = 4$，以及两个组 $\\mathcal{G} = \\{g_{1}, g_{2}\\}$，其中 $g_{1} = \\{1,4\\}$ 且 $g_{2} = \\{2,3\\}$。令 $A$ 的列为\n$$\na_{1} = \\begin{pmatrix}1 \\\\ 0 \\\\ 0\\end{pmatrix}, \\quad\na_{2} = \\begin{pmatrix}0 \\\\ 1 \\\\ 0\\end{pmatrix}, \\quad\na_{3} = \\begin{pmatrix}0 \\\\ 0 \\\\ 1\\end{pmatrix}, \\quad\na_{4} = \\begin{pmatrix}1 \\\\ 1 \\\\ 0\\end{pmatrix},\n$$\n因此 $A = [a_{1} \\; a_{2} \\; a_{3} \\; a_{4}] \\in \\mathbb{R}^{3 \\times 4}$，并令 $b = \\begin{pmatrix}1 \\\\ 2 \\\\ 3\\end{pmatrix} \\in \\mathbb{R}^{3}$。使用你推导的 KKT 条件，确定使得 $x^{\\star} = 0$ 满足该问题最优性条件的最小 $\\lambda_{0}$ 值。将你的最终答案表示为单个精确的解析表达式。不要四舍五入。",
            "solution": "该问题要求推导组套索优化问题的 Karush-Kuhn-Tucker (KKT) 条件、其相关邻近算子的推导，以及一个特定实例的解。目标函数为 $F(x) = f(x) + h(x)$，其中 $f(x) = \\frac{1}{2}\\|Ax - b\\|_{2}^{2}$ 是一个可微凸函数，$h(x) = \\lambda \\|x\\|_{2,1}$ 是一个不可微凸函数。这里 $\\|x\\|_{2,1} = \\sum_{g \\in \\mathcal{G}} \\|x_{g}\\|_{2}$。\n\n**1) KKT 条件的推导**\n\n一个向量 $x^{\\star} \\in \\mathbb{R}^{n}$ 是凸函数 $F(x)$ 的最小化子，当且仅当它满足一阶最优性条件：\n$$\n0 \\in \\partial F(x^{\\star})\n$$\n由于 $f(x)$ 是可微的，和函数 $F(x) = f(x) + h(x)$ 的次微分由 $f(x)$ 的梯度和 $h(x)$ 的次微分之和给出：\n$$\n\\partial F(x^{\\star}) = \\nabla f(x^{\\star}) + \\partial h(x^{\\star})\n$$\n$f(x)$ 的梯度为 $\\nabla f(x) = A^T(Ax - b)$。最优性条件变为：\n$$\n0 \\in A^T(Ax^{\\star} - b) + \\partial h(x^{\\star})\n$$\n这等价于：\n$$\n-A^T(Ax^{\\star} - b) \\in \\partial h(x^{\\star})\n$$\n函数 $h(x) = \\lambda \\|x\\|_{2,1} = \\lambda \\sum_{g \\in \\mathcal{G}} \\|x_g\\|_2$ 关于组 $\\mathcal{G}$ 是可分的。其次微分是每一项次微分的笛卡尔积：\n$$\n\\partial h(x) = \\partial \\left(\\lambda \\sum_{g \\in \\mathcal{G}} \\|x_g\\|_2\\right) = \\lambda \\prod_{g \\in \\mathcal{G}} \\partial \\|x_g\\|_2\n$$\n对于一个向量 $z$，欧几里得范数 $\\|z\\|_2$ 的次微分是：\n$$\n\\partial \\|z\\|_2 = \\begin{cases} \\{z / \\|z\\|_2\\}   \\text{若 } z \\neq 0 \\\\ \\{u \\mid \\|u\\|_2 \\le 1\\}   \\text{若 } z = 0 \\end{cases}\n$$\n其中 $\\{u \\mid \\|u\\|_2 \\le 1\\}$ 是相应维度中的闭单位球。\n\n令 $r^{\\star} = A^T(b - Ax^{\\star})$ 为与残差相关的向量。最优性条件 $-A^T(Ax^{\\star} - b) \\in \\partial h(x^{\\star})$ 可以写成 $r^{\\star} \\in \\lambda \\partial \\|x^{\\star}\\|_{2,1}$。\n让我们根据组 $\\mathcal{G}$ 对 $r^{\\star}$ 进行划分，$r^{\\star} = [r^{\\star}_g]_{g \\in \\mathcal{G}}$。$A$ 中对应于组 $g$ 中索引的子矩阵记为 $A_g$。则 $r^{\\star}_g = A_g^T (b - Ax^{\\star})$。最优性条件可以对每个组 $g \\in \\mathcal{G}$ 表示为：\n$$\nA_g^T (b - Ax^{\\star}) \\in \\lambda \\partial \\|x_g^{\\star}\\|_2\n$$\n我们对每个组 $g$ 分两种情况分析此条件：\n\n情况 1：$x_g^{\\star} \\ne 0$。\n在这种情况下，$\\partial \\|x_g^{\\star}\\|_2 = \\{x_g^{\\star} / \\|x_g^{\\star}\\|_2\\}$。条件变为：\n$$\nA_g^T (b - Ax^{\\star}) = \\lambda \\frac{x_g^{\\star}}{\\|x_g^{\\star}\\|_2}\n$$\n对两边取欧几里得范数得到 $\\|A_g^T (b - Ax^{\\star})\\|_2 = \\lambda$。\n\n情况 2：$x_g^{\\star} = 0$。\n在这种情况下，$\\partial \\|x_g^{\\star}\\|_2 = \\{u_g \\mid \\|u_g\\|_2 \\le 1\\}$。条件变为：\n$$\nA_g^T (b - Ax^{\\star}) \\in \\lambda \\{u_g \\mid \\|u_g\\|_2 \\le 1\\}\n$$\n这等价于说明左边向量的范数必须小于或等于 $\\lambda$：\n$$\n\\|A_g^T (b - Ax^{\\star})\\|_2 \\le \\lambda\n$$\n这些就是最小化子 $x^{\\star}$ 的分组 KKT 条件。\n\n**2) 邻近算子和邻近梯度迭代**\n\n函数 $\\psi(x)$ 的邻近算子定义为 $\\text{prox}_{\\psi}(v) = \\arg\\min_{x} \\left(\\psi(x) + \\frac{1}{2}\\|x - v\\|_2^2\\right)$。\n我们感兴趣的是 $h(x) = \\lambda \\|x\\|_{2,1}$ 的邻近算子。令 $\\alpha  0$ 为步长。我们需要计算 $\\text{prox}_{\\alpha h}(v)$。\n$$\n\\text{prox}_{\\alpha h}(v) = \\arg\\min_{x} \\left(\\alpha\\lambda \\|x\\|_{2,1} + \\frac{1}{2}\\|x - v\\|_2^2\\right)\n$$\n目标函数在各个组 $g \\in \\mathcal{G}$ 上是可分的：\n$$\n\\alpha\\lambda \\sum_{g \\in \\mathcal{G}} \\|x_g\\|_2 + \\frac{1}{2} \\sum_{g \\in \\mathcal{G}} \\|x_g - v_g\\|_2^2\n$$\n我们可以独立地对每个块 $x_g$ 进行最小化：\n$$\n\\hat{x}_g = \\arg\\min_{x_g} \\left(\\alpha\\lambda \\|x_g\\|_2 + \\frac{1}{2}\\|x_g - v_g\\|_2^2\\right)\n$$\n令 $\\mu = \\alpha\\lambda$。这个子问题的一阶最优性条件是：\n$$\n0 \\in \\mu \\partial \\|\\hat{x}_g\\|_2 + (\\hat{x}_g - v_g) \\quad \\iff \\quad v_g - \\hat{x}_g \\in \\mu \\partial \\|\\hat{x}_g\\|_2\n$$\n情况 A：$\\hat{x}_g \\ne 0$。条件是 $v_g - \\hat{x}_g = \\mu \\frac{\\hat{x}_g}{\\|\\hat{x}_g\\|_2}$。\n这意味着 $v_g = \\hat{x}_g \\left(1 + \\frac{\\mu}{\\|\\hat{x}_g\\|_2}\\right)$。由此可见，$\\hat{x}_g$ 必须是 $v_g$ 的正标量倍数。对两边取范数：\n$\\|v_g\\|_2 = \\|\\hat{x}_g\\|_2 \\left(1 + \\frac{\\mu}{\\|\\hat{x}_g\\|_2}\\right) = \\|\\hat{x}_g\\|_2 + \\mu$。\n因此，$\\|\\hat{x}_g\\|_2 = \\|v_g\\|_2 - \\mu$。由于 $\\|\\hat{x}_g\\|_2  0$，这种情况只有在 $\\|v_g\\|_2  \\mu$ 时才可能发生。\n将此代回，我们得到 $v_g = \\hat{x}_g \\frac{\\|v_g\\|_2}{\\|v_g\\|_2 - \\mu}$，这给出 $\\hat{x}_g = \\frac{\\|v_g\\|_2 - \\mu}{\\|v_g\\|_2} v_g = \\left(1 - \\frac{\\mu}{\\|v_g\\|_2}\\right) v_g$。\n\n情况 B：$\\hat{x}_g = 0$。条件是 $v_g \\in \\mu \\partial \\|0\\|_2$，这意味着 $\\|v_g\\|_2 \\le \\mu$。\n\n结合这两种情况，每个块的解是：\n$$\n\\hat{x}_g = \\begin{cases} \\left(1 - \\frac{\\alpha\\lambda}{\\|v_g\\|_2}\\right) v_g   \\text{若 } \\|v_g\\|_2  \\alpha\\lambda \\\\ 0   \\text{若 } \\|v_g\\|_2 \\le \\alpha\\lambda \\end{cases}\n$$\n这可以使用正部函数 $(\\cdot)_+ = \\max(0, \\cdot)$ 紧凑地写为：\n$$\n\\hat{x}_g = \\left(1 - \\frac{\\alpha\\lambda}{\\|v_g\\|_2}\\right)_+ v_g\n$$\n这就是块软阈值规则。\n\n最小化 $f(x) + h(x)$ 的邻近梯度法是一个迭代算法，由下式给出：\n$$\nx^{(k+1)} = \\text{prox}_{\\alpha h}\\left(x^{(k)} - \\alpha \\nabla f(x^{(k)})\\right)\n$$\n其中 $\\alpha  0$ 是步长。对于我们的问题，这变为：\n$$\nx^{(k+1)} = \\text{prox}_{\\alpha\\lambda \\|\\cdot\\|_{2,1}}\\left(x^{(k)} - \\alpha A^T(Ax^{(k)} - b)\\right)\n$$\n应用我们推导出的块软阈值算子，令 $v^{(k)} = x^{(k)} - \\alpha A^T(Ax^{(k)} - b)$。每个组 $g \\in \\mathcal{G}$ 的更新为：\n$$\nx_g^{(k+1)} = \\left(1 - \\frac{\\alpha\\lambda}{\\|v_g^{(k)}\\|_2}\\right)_+ v_g^{(k)}\n$$\n\n**3) 零解的最小 $\\lambda$**\n\n我们寻求最小的 $\\lambda_0  0$ 使得 $x^{\\star} = 0$ 是一个最小化子。使用第1部分的 KKT 条件，我们必须满足非活动组（即 $x_g^{\\star}=0$）的条件。由于对于 $x^{\\star}=0$ 所有组都是非活动的，我们必须对所有 $g \\in \\mathcal{G}$ 满足：\n$$\n\\|A_g^T (b - A \\cdot 0)\\|_2 \\le \\lambda\n$$\n这对所有 $g \\in \\mathcal{G}$ 简化为 $\\|A_g^T b\\|_2 \\le \\lambda$。\n为了对所有组都满足此条件，$\\lambda$ 必须大于或等于这些范数的最大值。因此，最小的此种 $\\lambda$ 是：\n$$\n\\lambda_0 = \\max_{g \\in \\mathcal{G}} \\|A_g^T b\\|_2\n$$\n现在，我们使用具体的实例数据：$m=3$，$n=4$。\n$A = \\begin{pmatrix} 1  0  0  1 \\\\ 0  1  0  1 \\\\ 0  0  1  0 \\end{pmatrix}$，$b = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}$。\n组为 $g_1 = \\{1,4\\}$ 和 $g_2 = \\{2,3\\}$。\n\n列子矩阵是：\n$A_{g_1}$（A 的第 1 列和第 4 列）：$A_{g_1} = \\begin{pmatrix} 1  1 \\\\ 0  1 \\\\ 0  0 \\end{pmatrix}$。\n$A_{g_2}$（A 的第 2 列和第 3 列）：$A_{g_2} = \\begin{pmatrix} 0  0 \\\\ 1  0 \\\\ 0  1 \\end{pmatrix}$。\n\n接下来，我们为每个组计算 $A_g^T b$。\n对于组 $g_1$：\n$$\nA_{g_1}^T b = \\begin{pmatrix} 1  0  0 \\\\ 1  1  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} (1)(1)+(0)(2)+(0)(3) \\\\ (1)(1)+(1)(2)+(0)(3) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}\n$$\n欧几里得范数是 $\\|A_{g_1}^T b\\|_2 = \\sqrt{1^2 + 3^2} = \\sqrt{1+9} = \\sqrt{10}$。\n\n对于组 $g_2$：\n$$\nA_{g_2}^T b = \\begin{pmatrix} 0  1  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} (0)(1)+(1)(2)+(0)(3) \\\\ (0)(1)+(0)(2)+(1)(3) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}\n$$\n欧几里得范数是 $\\|A_{g_2}^T b\\|_2 = \\sqrt{2^2 + 3^2} = \\sqrt{4+9} = \\sqrt{13}$。\n\n最小的 $\\lambda_0$ 是这些值的最大值：\n$$\n\\lambda_0 = \\max \\left( \\|A_{g_1}^T b\\|_2, \\|A_{g_2}^T b\\|_2 \\right) = \\max(\\sqrt{10}, \\sqrt{13}) = \\sqrt{13}\n$$",
            "answer": "$$\n\\boxed{\\sqrt{13}}\n$$"
        },
        {
            "introduction": "LASSO的效果在很大程度上取决于正则化参数$\\lambda$的选择，但在实际问题中，我们通常不知道真实的信号或噪声水平，因此难以先验地确定最优$\\lambda$。斯坦无偏风险估计（Stein's Unbiased Risk Estimate, SURE）提供了一个强大的统计工具，它可以在不知道真实信号的情况下估计均方误差，从而实现数据驱动的参数选择。在这个问题中，你将为一个去噪问题推导SURE公式并用它来选择最优的$\\lambda$，从而架起优化理论与实际统计模型选择之间的桥梁。",
            "id": "3457312",
            "problem": "考虑一个带有单位传感矩阵的线性逆问题，其中观测值被建模为 $y = x_{0} + w \\in \\mathbb{R}^{n}$，且 $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$。令估计量 $\\widehat{x}_{\\lambda}(y)$ 为最小绝对收缩和选择算子 (LASSO) 的解，即 $\\frac{1}{2} \\|y - x\\|_{2}^{2} + \\lambda \\|x\\|_{1}$ 的最小化子，它在分量上与水平为 $\\lambda$ 的软阈值算子 $S_{\\lambda}(y)$ 一致，因此 $\\widehat{x}_{\\lambda}(y) = S_{\\lambda}(y)$，其中 $(S_{\\lambda}(y))_{i} = \\operatorname{sign}(y_{i}) \\max\\{|y_{i}| - \\lambda, 0\\}$。使用 Stein 无偏风险估计 (SURE)，从第一性原理推导一个关于无噪声响应的均方预测误差的无偏估计量，也就是说，推导 $\\mathbb{E}\\big[\\|S_{\\lambda}(y) - x_{0}\\|_{2}^{2}\\big]$ 的一个无偏估计量，该估计量纯粹用 $y$、$\\sigma^{2}$ 和 $S_{\\lambda}(\\cdot)$ 的散度来表示。证明这个 SURE 可以使用软阈值算子的散度来显式地写出。\n\n然后，使用您推导出的表达式，确定对于以下数据最小化 SURE 的 $\\lambda$ 值：\n- 维度 $n = 6$，\n- 噪声方差 $\\sigma^{2} = 0.25$，\n- 观测向量 $y \\in \\mathbb{R}^{6}$ 由 $y = (3.10,\\,-2.40,\\,0.95,\\,-1.80,\\,0.12,\\,-0.42)^{\\top}$ 给出。\n\n只报告最小化子 $\\lambda^{\\star}$ 的数值。不要对最终答案进行四舍五入。",
            "solution": "我们从高斯序列模型 $y = x_{0} + w \\in \\mathbb{R}^{n}$ 开始，其中 $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$。在单位设计矩阵下，LASSO 估计量是软阈值算子 $S_{\\lambda}(y)$，其分量定义为\n$$\n(S_{\\lambda}(y))_{i} = \\operatorname{sign}(y_{i}) \\max\\{|y_{i}| - \\lambda, 0\\}。\n$$\n我们感兴趣的量是相对于无噪声响应 $x_{0}$ 的均方预测误差，\n$$\nR(\\lambda) \\equiv \\mathbb{E}\\big[\\|S_{\\lambda}(y) - x_{0}\\|_{2}^{2}\\big]。\n$$\nStein 无偏风险估计 (SURE) 在 $S_{\\lambda}$ 几乎处处满足的温和正则性条件（弱可微性和可积性）下，提供了 $R(\\lambda)$ 的一个无偏估计量：\n$$\n\\operatorname{SURE}(\\lambda; y) \\equiv \\|S_{\\lambda}(y) - y\\|_{2}^{2} + 2 \\sigma^{2} \\,\\operatorname{div}_{y} S_{\\lambda}(y) - n \\sigma^{2}，\n$$\n它满足 $\\mathbb{E}[\\operatorname{SURE}(\\lambda; y)] = R(\\lambda)$。\n\n我们现在计算软阈值算子的散度。对于每个分量 $i \\in \\{1,\\dots,n\\}$，当 $|y_{i}| \\neq \\lambda$ 时，映射 $y_{i} \\mapsto (S_{\\lambda}(y))_{i}$ 是可微的，其导数为\n$$\n\\frac{\\partial (S_{\\lambda}(y))_{i}}{\\partial y_{i}} =\n\\begin{cases}\n1,   \\text{如果 } |y_{i}| > \\lambda,\\\\\n0,   \\text{如果 } |y_{i}|  \\lambda.\n\\end{cases}\n$$\n在不可微的扭结处 $|y_{i}| = \\lambda$（在高斯定律下这是一个勒贝格测度为零的集合），Stein 公式仍然有效。因此，散度是\n$$\n\\operatorname{div}_{y} S_{\\lambda}(y) = \\sum_{i=1}^{n} \\frac{\\partial (S_{\\lambda}(y))_{i}}{\\partial y_{i}} = \\#\\{i: |y_{i}| > \\lambda\\} \\equiv k(\\lambda)，\n$$\n即活跃（非零）软阈值分量的数量。\n\n接下来，我们简化残差项 $\\|S_{\\lambda}(y) - y\\|_{2}^{2}$。对于任意坐标 $i$：\n- 如果 $|y_{i}|  \\lambda$（活跃），则 $(S_{\\lambda}(y))_{i} = y_{i} - \\operatorname{sign}(y_{i}) \\lambda$，因此 $(S_{\\lambda}(y))_{i} - y_{i} = -\\operatorname{sign}(y_{i}) \\lambda$，并且 $((S_{\\lambda}(y))_{i} - y_{i})^{2} = \\lambda^{2}$。\n- 如果 $|y_{i}| \\leq \\lambda$（不活跃），则 $(S_{\\lambda}(y))_{i} = 0$，因此 $(S_{\\lambda}(y))_{i} - y_{i} = -y_{i}$，并且 $((S_{\\lambda}(y))_{i} - y_{i})^{2} = y_{i}^{2}$。\n\n因此，\n$$\n\\|S_{\\lambda}(y) - y\\|_{2}^{2} = \\sum_{i: |y_{i}|  \\lambda} \\lambda^{2} + \\sum_{i: |y_{i}| \\leq \\lambda} y_{i}^{2} = \\sum_{i=1}^{n} \\min\\{y_{i}^{2}, \\lambda^{2}\\}。\n$$\n结合散度，我们得到显式的 SURE：\n$$\n\\operatorname{SURE}(\\lambda; y) = \\sum_{i=1}^{n} \\min\\{y_{i}^{2}, \\lambda^{2}\\} + 2 \\sigma^{2} k(\\lambda) - n \\sigma^{2}。\n$$\n\n我们将 $\\operatorname{SURE}(\\lambda; y)$ 作为 $\\lambda$ 的函数来分析其结构。令 $s_{(1)} \\geq s_{(2)} \\geq \\cdots \\geq s_{(n)}$ 为 $\\{|y_{i}|\\}_{i=1}^{n}$ 的顺序统计量。对于 $\\lambda \\in (s_{(t+1)}, s_{(t)}]$，并约定 $s_{(n+1)} \\equiv 0$，活跃系数的数量为 $k(\\lambda) = t$，且\n$$\n\\operatorname{SURE}(\\lambda; y) = t \\lambda^{2} + \\sum_{i=t+1}^{n} s_{(i)}^{2} + (2t - n) \\sigma^{2}。\n$$\n在每个开区间 $(s_{(t+1)}, s_{(t)})$ 内，导数为 $\\frac{d}{d\\lambda} \\operatorname{SURE}(\\lambda; y) = 2 t \\lambda \\geq 0$，因此 $\\operatorname{SURE}(\\lambda; y)$ 在每个这样的区间上关于 $\\lambda$ 是非递减的。因此，任何最小化子都必须出现在某个区间的左端点，即在 $\\lambda \\in \\{0, s_{(n)}, s_{(n-1)}, \\dots, s_{(1)}\\}$ 处。\n\n我们现在将此应用于给定数据。此处 $n = 6$，$\\sigma^{2} = 0.25$，且\n$$\ny = (3.10,\\,-2.40,\\,0.95,\\,-1.80,\\,0.12,\\,-0.42)^{\\top}，\n$$\n因此排序后的绝对值为\n$$\ns_{(1)} = 3.10,\\quad s_{(2)} = 2.40,\\quad s_{(3)} = 1.80,\\quad s_{(4)} = 0.95,\\quad s_{(5)} = 0.42,\\quad s_{(6)} = 0.12。\n$$\n我们在候选点 $\\lambda \\in \\{0,\\,0.12,\\,0.42,\\,0.95,\\,1.80,\\,2.40,\\,3.10\\}$ 处计算 $\\operatorname{SURE}(\\lambda; y)$ 的值。\n\n首先，在 $\\lambda = 0$ 处，所有分量都是活跃的，因此 $k(0) = 6$ 且\n$$\n\\operatorname{SURE}(0; y) = \\sum_{i=1}^{n} \\min\\{y_{i}^{2}, 0\\} + (2 \\cdot 6 - 6)\\sigma^{2} = 0 + 6 \\cdot 0.25 = 1.5。\n$$\n\n对于 $\\lambda = s_{(t)}$ 且 $t \\in \\{1,\\dots,6\\}$，在阈值点右侧，活跃集的大小为 $t-1$，我们有\n$$\n\\operatorname{SURE}(s_{(t)}; y) = (t-1) s_{(t)}^{2} + \\sum_{i=t}^{n} s_{(i)}^{2} + \\big(2(t-1) - n\\big) \\sigma^{2}。\n$$\n我们预先计算平方和尾部和：\n$$\ns_{(1)}^{2} = 9.61,\\quad s_{(2)}^{2} = 5.76,\\quad s_{(3)}^{2} = 3.24,\\quad s_{(4)}^{2} = 0.9025,\\quad s_{(5)}^{2} = 0.1764,\\quad s_{(6)}^{2} = 0.0144,\n$$\n以及尾部和\n$$\n\\sum_{i=1}^{6} s_{(i)}^{2} = 19.7033,\\quad \\sum_{i=2}^{6} s_{(i)}^{2} = 10.0933,\\quad \\sum_{i=3}^{6} s_{(i)}^{2} = 4.3333,\\quad \\sum_{i=4}^{6} s_{(i)}^{2} = 1.0933,\\quad \\sum_{i=5}^{6} s_{(i)}^{2} = 0.1908,\\quad \\sum_{i=6}^{6} s_{(i)}^{2} = 0.0144。\n$$\n我们还注意到 $(2(t-1) - n) \\sigma^{2} = (2t - 8) \\cdot 0.25$。\n\n现在计算每个候选值：\n- 对于 $t = 6$ (即 $\\lambda = 0.12$)：$(t-1) s_{(t)}^{2} + \\sum_{i=t}^{n} s_{(i)}^{2} = 5 \\cdot 0.0144 + 0.0144 = 0.0864$，且 $(2t - 8) \\cdot 0.25 = (12 - 8) \\cdot 0.25 = 1.0$，因此 $\\operatorname{SURE}(0.12; y) = 0.0864 + 1.0 = 1.0864$。\n- 对于 $t = 5$ (即 $\\lambda = 0.42$)：$4 \\cdot 0.1764 + 0.1908 = 0.8964$，且 $(10 - 8) \\cdot 0.25 = 0.5$，因此 $\\operatorname{SURE}(0.42; y) = 0.8964 + 0.5 = 1.3964$。\n- 对于 $t = 4$ (即 $\\lambda = 0.95$)：$3 \\cdot 0.9025 + 1.0933 = 3.8008$，且 $(8 - 8) \\cdot 0.25 = 0$，因此 $\\operatorname{SURE}(0.95; y) = 3.8008$。\n- 对于 $t = 3$ (即 $\\lambda = 1.80$)：$2 \\cdot 3.24 + 4.3333 = 10.8133$，且 $(6 - 8) \\cdot 0.25 = -0.5$，因此 $\\operatorname{SURE}(1.80; y) = 10.3133$。\n- 对于 $t = 2$ (即 $\\lambda = 2.40$)：$1 \\cdot 5.76 + 10.0933 = 15.8533$，且 $(4 - 8) \\cdot 0.25 = -1.0$，因此 $\\operatorname{SURE}(2.40; y) = 14.8533$。\n- 对于 $t = 1$ (即 $\\lambda = 3.10$)：$0 + 19.7033$，且 $(2 - 8) \\cdot 0.25 = -1.5$，因此 $\\operatorname{SURE}(3.10; y) = 18.2033$。\n\n比较所有候选值，我们发现\n$$\n\\operatorname{SURE}(0; y) = 1.5,\\quad \\operatorname{SURE}(0.12; y) = 1.0864,\\quad \\operatorname{SURE}(0.42; y) = 1.3964,\n$$\n并且其余候选值产生更大的值。由于 $\\operatorname{SURE}(\\lambda; y)$ 在断点之间是非递减的，全局最小化子在 $\\lambda^{\\star} = 0.12$ 处取得。\n\n因此，对于给定数据，最小化 SURE 的 $\\lambda$ 值是 $\\lambda^{\\star} = 0.12$。",
            "answer": "$$\\boxed{0.12}$$"
        }
    ]
}