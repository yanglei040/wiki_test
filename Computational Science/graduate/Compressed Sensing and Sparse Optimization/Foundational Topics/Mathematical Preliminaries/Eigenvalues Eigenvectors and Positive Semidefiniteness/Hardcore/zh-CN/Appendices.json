{
    "hands_on_practices": [
        {
            "introduction": "在稀疏恢复中，一个常见的理想化模型是假设传感矩阵的列具有相等的成对相关性。这个练习  要求你推导由此产生的Gram矩阵的条件数，从而将一个简单的结构参数——相干性($\\mu$)——与一个关键的数值稳定性度量直接联系起来。这项实践旨在培养计算结构化矩阵特征值的基本技能。",
            "id": "3445779",
            "problem": "在稀疏恢复流程中，人们通常在初始支撑集选择（例如，通过最小绝对收缩和选择算子 (LASSO)）之后，执行支撑集限制去偏。考虑一个具有单位范数列的传感矩阵，并设 $S$ 是一个大小为 $s=4$ 的选定支撑集。假设由 $S$ 索引的列是等相关的：每个非对角内积都等于一个公共相干水平 $\\mu \\in [0,1)$。因此，格拉姆矩阵为\n$$\nG \\equiv A_{S}^{\\top}A_{S} = (1-\\mu) I_{4} + \\mu \\mathbf{1}\\mathbf{1}^{\\top},\n$$\n其中 $I_{4}$ 是 $4 \\times 4$ 的单位矩阵，$\\mathbf{1}$ 表示 4 维全一向量。仅使用线性代数的核心定义和半正定矩阵的性质，计算谱条件数 $\\kappa_{2}(G)$，其定义为 $G$ 的最大特征值与最小特征值之比，并以 $\\mu$ 的函数形式给出闭式解。然后，从第一性原理出发，论证所计算出的 $\\kappa_{2}(G)$ 对于在加性高斯白噪声 (AWGN) 条件下，与标准正交情况相比，支撑集 $S$ 上的支撑集限制最小二乘去偏的数值精度和噪声敏感度意味着什么。最终答案必须是您用 $\\mu$ 表示的 $\\kappa_{2}(G)$ 的闭式表达式。",
            "solution": "该问题要求计算一个特定格拉姆矩阵的谱条件数，并在稀疏恢复的背景下解释其含义。我将首先验证问题的陈述。该问题提供了一个定义明确的数学对象，即矩阵 $G = (1-\\mu) I_{4} + \\mu \\mathbf{1}\\mathbf{1}^{\\top}$（其中 $\\mu \\in [0,1)$），并要求计算一个标准的、定义明确的量，即谱条件数 $\\kappa_{2}(G)$。稀疏恢复和最小二乘去偏的背景在该领域是科学上合理且标准的。所有术语都定义清晰，没有矛盾或信息缺失。因此，该问题是有效的。\n\n为了计算谱条件数 $\\kappa_{2}(G)$，我们必须找到 $G$ 的最大特征值与最小特征值之比。我们直接从核心定义 $G\\mathbf{v} = \\lambda\\mathbf{v}$ 出发寻找 $G$ 的特征值，其中 $\\lambda$ 是一个特征值，$\\mathbf{v}$ 是其对应的非零特征向量。\n\n给定的矩阵是 $G = (1-\\mu) I_{4} + \\mu \\mathbf{1}\\mathbf{1}^{\\top}$，其中 $I_{4}$ 是 $4 \\times 4$ 的单位矩阵，$\\mathbf{1}$ 是 $4 \\times 1$ 的全一向量。特征值方程为：\n$$\n\\left( (1-\\mu) I_{4} + \\mu \\mathbf{1}\\mathbf{1}^{\\top} \\right) \\mathbf{v} = \\lambda \\mathbf{v}\n$$\n将各项作用于向量 $\\mathbf{v}$：\n$$\n(1-\\mu)\\mathbf{v} + \\mu (\\mathbf{1}^{\\top}\\mathbf{v})\\mathbf{1} = \\lambda\\mathbf{v}\n$$\n重新整理各项，我们得到：\n$$\n\\mu (\\mathbf{1}^{\\top}\\mathbf{v})\\mathbf{1} = (\\lambda - (1-\\mu))\\mathbf{v}\n$$\n$$\n\\mu (\\mathbf{1}^{\\top}\\mathbf{v})\\mathbf{1} = (\\lambda - 1 + \\mu)\\mathbf{v}\n$$\n我们针对特征向量 $\\mathbf{v}$ 的两种不同情况来分析这个方程。\n\n情况 1：特征向量 $\\mathbf{v}$ 与全一向量 $\\mathbf{1}$ 正交。\n在这种情况下，内积 $\\mathbf{1}^{\\top}\\mathbf{v} = 0$。方程的左边变成零向量：\n$$\n\\mathbf{0} = (\\lambda - 1 + \\mu)\\mathbf{v}\n$$\n由于 $\\mathbf{v}$ 是一个特征向量，它必须是非零的（$\\mathbf{v} \\neq \\mathbf{0}$）。因此，标量乘数必须为零：\n$$\n\\lambda - 1 + \\mu = 0 \\implies \\lambda = 1 - \\mu\n$$\n在 $\\mathbb{R}^4$ 中与 $\\mathbf{1}$ 正交的向量空间是一个维度为 $4-1=3$ 的子空间。因此，有 3 个线性无关的特征向量与特征值 $\\lambda = 1 - \\mu$ 相关联。该特征值的重数为 3。\n\n情况 2：特征向量 $\\mathbf{v}$ 与 $\\mathbf{1}$ 不正交。\n从方程 $\\mu (\\mathbf{1}^{\\top}\\mathbf{v})\\mathbf{1} = (\\lambda - 1 + \\mu)\\mathbf{v}$ 中，我们可以看到，如果两边的量都非零，那么 $\\mathbf{v}$ 必须是 $\\mathbf{1}$ 的标量倍。让我们测试向量 $\\mathbf{v} = \\mathbf{1}$ 本身。\n内积为 $\\mathbf{1}^{\\top}\\mathbf{v} = \\mathbf{1}^{\\top}\\mathbf{1} = 1^2 + 1^2 + 1^2 + 1^2 = 4$。\n将 $\\mathbf{v}=\\mathbf{1}$ 代入特征值方程：\n$$\nG\\mathbf{1} = \\left( (1-\\mu) I_{4} + \\mu \\mathbf{1}\\mathbf{1}^{\\top} \\right) \\mathbf{1} = (1-\\mu)\\mathbf{1} + \\mu\\mathbf{1}(\\mathbf{1}^{\\top}\\mathbf{1}) = (1-\\mu)\\mathbf{1} + \\mu\\mathbf{1}(4)\n$$\n$$\nG\\mathbf{1} = (1-\\mu+4\\mu)\\mathbf{1} = (1+3\\mu)\\mathbf{1}\n$$\n这表明 $\\mathbf{1}$ 是一个特征向量，其对应的特征值为 $\\lambda = 1+3\\mu$。\n\n矩阵 $G$ 是一个 $4 \\times 4$ 矩阵，所以它有 4 个特征值。我们已经找到了所有这些特征值：\n$$\n\\lambda_{1} = 1+3\\mu \\quad (\\text{重数为 } 1)\n$$\n$$\n\\lambda_{2,3,4} = 1-\\mu \\quad (\\text{重数为 } 3)\n$$\n问题指定 $\\mu \\in [0, 1)$。对于此区间内的任何 $\\mu$，$1+3\\mu \\geq 1$ 且 $1-\\mu > 0$。因此，所有特征值都是严格为正的，这证实了 $G$ 是一个正定矩阵。\n\n为了求出谱条件数 $\\kappa_2(G)$，我们需要确定最大和最小特征值，即 $\\lambda_{\\max}(G)$ 和 $\\lambda_{\\min}(G)$。我们比较两个不同的特征值表达式：$1+3\\mu$ 和 $1-\\mu$。\n对于 $\\mu \\in [0,1)$，我们有 $3\\mu \\geq 0$ 和 $-\\mu \\leq 0$。因此，$1+3\\mu \\geq 1$ 且 $1-\\mu \\leq 1$。\n更直接地，对于 $\\mu \\geq 0$，有 $3\\mu \\geq -\\mu$，这意味着 $1+3\\mu \\geq 1-\\mu$。等号仅在 $\\mu=0$ 时成立。\n所以，对于 $\\mu \\in [0, 1)$:\n$$\n\\lambda_{\\max}(G) = 1+3\\mu\n$$\n$$\n\\lambda_{\\min}(G) = 1-\\mu\n$$\n谱条件数定义为它们的比值：\n$$\n\\kappa_{2}(G) = \\frac{\\lambda_{\\max}(G)}{\\lambda_{\\min}(G)} = \\frac{1+3\\mu}{1-\\mu}\n$$\n\n现在，我们必须论证计算出的 $\\kappa_{2}(G)$ 对支撑集限制的最小二乘去偏问题意味着什么。去偏步骤涉及求解限制在支撑集 $S$ 上的标准最小二乘问题：\n$$\n\\min_{\\mathbf{x}_S} \\|\\mathbf{y} - A_S \\mathbf{x}_S\\|_2^2\n$$\n其中 $A_S$ 是由 $S$ 索引的 $A$ 的列组成的矩阵。解由正规方程组给出：\n$$\n(A_S^{\\top}A_S)\\mathbf{x}_S = A_S^{\\top}\\mathbf{y} \\implies G\\mathbf{x}_S = A_S^{\\top}\\mathbf{y}\n$$\n这个线性系统的性质由条件数 $\\kappa_{2}(G)$ 决定。\n\n标准正交情况对应于 $A_S$ 的列是标准正交的，即 $G = A_S^{\\top}A_S = I_4$。这等同于在我们的模型中设置 $\\mu=0$。在这种情况下，$\\lambda_{\\max}(G) = 1$ 且 $\\lambda_{\\min}(G)=1$，所以 $\\kappa_{2}(G) = \\frac{1+0}{1-0} = 1$。条件数为 1 是最优的、可能的最小值，表示一个完全良态的问题。\n\n随着相干性 $\\mu$ 从 0 增加到 1，条件数 $\\kappa_{2}(G) = \\frac{1+3\\mu}{1-\\mu}$ 单调增加。当 $\\mu \\to 1$ 时，$\\kappa_{2}(G) \\to \\infty$。大的条件数表明矩阵 $G$ 是病态的，意味着它接近奇异。与标准正交情况相比，这有两个关键影响：\n\n1.  **数值精度：** 当使用有限精度算法（例如，在计算机上）求解系统 $G\\mathbf{x}_S = A_S^{\\top}\\mathbf{y}$ 时，计算解的相对误差受 $\\kappa_2(G)$ 的限制。较大的 $\\kappa_{2}(G)$ 意味着微小的浮点表示误差会被放大，导致数值计算出的解可能与真实的数学解有显著差异。随着 $\\mu$ 的增加，去偏步骤在数值上变得不稳定，结果的可靠性降低。\n\n2.  **噪声敏感度：** 在带有加性高斯白噪声 (AWGN) 的模型中，$\\mathbf{y} = A_S\\mathbf{x}_{S,\\text{true}} + \\mathbf{n}$，最小二乘估计为 $\\mathbf{x}_S = \\mathbf{x}_{S,\\text{true}} + G^{-1}A_S^{\\top}\\mathbf{n}$。误差项 $\\mathbf{e} = G^{-1}A_S^{\\top}\\mathbf{n}$ 是测量噪声 $\\mathbf{n}$ 通过系统传播的结果。这种噪声的放大程度由矩阵 $G^{-1}$ 决定。$G^{-1}$ 的特征值是 $G$ 特征值的倒数，具体为 $1/\\lambda_{\\min}(G) = 1/(1-\\mu)$ 和 $1/\\lambda_{\\max}(G) = 1/(1+3\\mu)$。大的 $\\kappa_2(G)$ 意味着 $\\lambda_{\\min}(G)$ 非常小。因此，$G^{-1}$ 的最大特征值非常大。这意味着与 $\\lambda_{\\min}(G)$ 对应的特征向量对齐的噪声分量会被急剧放大。因此，高的相干性 $\\mu$ 会导致高的条件数，这反过来又导致对测量噪声的极度敏感，使得去偏估计 $\\mathbf{x}_S$ 与在标准正交（$\\mu=0$）情况下获得的鲁棒、抗噪声的估计相比，变得高度不准确和不稳定。\n\n总之，$\\kappa_{2}(G)$ 的值可以作为一种精确的度量，衡量当传感矩阵在所选支撑集上的列变得更加相关时，最小二乘去偏过程在数值稳定性和统计效率（噪声放大）方面的退化程度。",
            "answer": "$$\n\\boxed{\\frac{1+3\\mu}{1-\\mu}}\n$$"
        },
        {
            "introduction": "虽然互相关性是一个有用的启发式指标，但它有时可能会产生误导。这个练习  通过一个思想实验，比较了两个具有相同互相关性但非对角线元素符号模式不同的Gram矩阵。通过计算并比较它们的最小特征值，我们将揭示相关性的具体排列方式（而不仅仅是其最大幅值）如何深刻影响恢复保证和稳定性。",
            "id": "3445795",
            "problem": "考虑一个感知矩阵 $A \\in \\mathbb{R}^{3 \\times 3}$，其列向量为单位范数向量。相互干性定义为 $\\mu(A) = \\max_{i \\neq j} |\\langle a_i, a_j \\rangle|$，其中 $\\langle \\cdot, \\cdot \\rangle$ 表示标准欧几里得内积，$a_i$ 是 $A$ 的第 $i$ 列。对于一个支撑集 $S \\subseteq \\{1,2,3\\}$，受限感知矩阵的格拉姆矩阵 (Gram matrix) 为 $G = A_S^{\\top} A_S$，根据其构造，该矩阵是对称半正定的。从这些定义出发，分析 $G$ 中非对角线元素的符号模式如何影响 $G$ 的最小特征值。\n\n构建两个感知矩阵 $A^{(1)}$ 和 $A^{(2)}$，它们都在 $\\mathbb{R}^{3 \\times 3}$ 中，具有相同的相互干性 $\\mu \\in (0, \\tfrac{1}{2})$、单位范数列向量和支撑集 $S = \\{1,2,3\\}$，使得：\n- 对于 $A^{(1)}$，其格拉姆矩阵 $G^{(1)} = A^{(1)}_S{}^{\\top} A^{(1)}_S$ 的元素为 $G^{(1)}_{ii} = 1$ 和 $G^{(1)}_{ij} = \\mu$ (当 $i \\neq j$ 时)。\n- 对于 $A^{(2)}$，其格拉姆矩阵 $G^{(2)} = A^{(2)}_S{}^{\\top} A^{(2)}_S$ 的元素为 $G^{(2)}_{ii} = 1$，$G^{(2)}_{12} = G^{(2)}_{21} = \\mu$，$G^{(2)}_{13} = G^{(2)}_{31} = \\mu$ 以及 $G^{(2)}_{23} = G^{(2)}_{32} = -\\mu$。\n\n你可以使用一个基本事实：任何对称半正定矩阵都是欧几里得空间中某组向量的格拉姆矩阵。要求 $A^{(1)}$ 和 $A^{(2)}$ 具有相同的相互干性 $\\mu$，并且 $G^{(1)}$ 和 $G^{(2)}$ 都必须是半正定矩阵。\n\n计算比值\n$$\nr(\\mu) = \\frac{\\lambda_{\\min}\\!\\left(A^{(1)}_S{}^{\\top} A^{(1)}_S\\right)}{\\lambda_{\\min}\\!\\left(A^{(2)}_S{}^{\\top} A^{(2)}_S\\right)}.\n$$\n的精确闭式表达式，该表达式是关于 $\\mu$ 的函数。\n请以关于 $\\mu$ 的单个简化解析表达式的形式给出最终答案。无需四舍五入。答案不得包含任何单位。",
            "solution": "问题要求计算两个指定的格拉姆矩阵 $G^{(1)}$ 和 $G^{(2)}$ 的最小特征值之比。这两个矩阵是从具有特定属性的感知矩阵 $A^{(1)}$ 和 $A^{(2)}$ 导出的。给定的支撑集为 $S = \\{1,2,3\\}$，对于一个 $3 \\times 3$ 矩阵，这意味着受限矩阵 $A_S$ 就是完整的矩阵 $A$。因此，格拉姆矩阵为 $G = A^{\\top}A$。\n\n根据问题描述，这两个格拉姆矩阵定义如下：\n$$\nG^{(1)} = \\begin{pmatrix} 1  \\mu  \\mu \\\\ \\mu  1  \\mu \\\\ \\mu  \\mu  1 \\end{pmatrix}\n$$\n和\n$$\nG^{(2)} = \\begin{pmatrix} 1  \\mu  \\mu \\\\ \\mu  1  -\\mu \\\\ \\mu  -\\mu  1 \\end{pmatrix}\n$$\n其中相互干性 $\\mu$ 的范围是 $\\mu \\in (0, \\frac{1}{2})$。我们的目标是计算 $r(\\mu) = \\frac{\\lambda_{\\min}(G^{(1)})}{\\lambda_{\\min}(G^{(2)})}$。我们通过求解每个矩阵的特征值来继续。\n\n首先，我们分析 $G^{(1)}$。该矩阵具有特殊结构，可以写成单位矩阵 $I$ 和全一矩阵 $J$ 的线性组合：\n$$\nG^{(1)} = (1-\\mu)I + \\mu J\n$$\n其中 $I$ 是 $3 \\times 3$ 单位矩阵，$J$ 是所有元素都为 $1$ 的 $3 \\times 3$ 矩阵。一个形如 $aI + bJ$ 的 $n \\times n$ 矩阵的特征值为 $a+nb$（重数为 $1$）和 $a$（重数为 $n-1$）。在我们的例子中，$n=3$，$a=1-\\mu$，$b=\\mu$。\n因此，$G^{(1)}$ 的特征值为：\n$\\lambda_1 = (1-\\mu) + 3\\mu = 1+2\\mu$（重数为 $1$）\n$\\lambda_2, \\lambda_3 = 1-\\mu$（重数为 $2$）\n\n为了找到最小特征值 $\\lambda_{\\min}(G^{(1)})$，我们比较 $1+2\\mu$ 和 $1-\\mu$。已知 $\\mu \\in (0, \\frac{1}{2})$，$\\mu$ 是正数。两者之差为 $(1+2\\mu) - (1-\\mu) = 3\\mu$。由于 $\\mu > 0$，这个差是正的，这意味着 $1+2\\mu > 1-\\mu$。因此，$G^{(1)}$ 的最小特征值为：\n$$\n\\lambda_{\\min}(G^{(1)}) = 1-\\mu\n$$\n问题陈述断言 $G^{(1)}$ 必须是半正定的，这要求所有特征值都为非负。由于 $\\mu  \\frac{1}{2}$，我们有 $1-\\mu > \\frac{1}{2} > 0$ 且 $1+2\\mu > 1 > 0$，因此该条件得到满足。\n\n接下来，我们分析 $G^{(2)}$。为了求其特征值，我们求解特征方程 $\\det(G^{(2)} - \\lambda I) = 0$：\n$$\n\\det \\begin{pmatrix} 1-\\lambda  \\mu  \\mu \\\\ \\mu  1-\\lambda  -\\mu \\\\ \\mu  -\\mu  1-\\lambda \\end{pmatrix} = 0\n$$\n展开行列式，我们得到：\n$$\n(1-\\lambda)((1-\\lambda)^2 - (-\\mu)^2) - \\mu(\\mu(1-\\lambda) - \\mu(-\\mu)) + \\mu(\\mu(-\\mu) - \\mu(1-\\lambda)) = 0\n$$\n$$\n(1-\\lambda)((1-\\lambda)^2 - \\mu^2) - \\mu(\\mu(1-\\lambda) + \\mu^2) + \\mu(-\\mu^2 - \\mu(1-\\lambda)) = 0\n$$\n$$\n(1-\\lambda)^3 - \\mu^2(1-\\lambda) - \\mu^2(1-\\lambda) - \\mu^3 - \\mu^3 - \\mu^2(1-\\lambda) = 0\n$$\n$$\n(1-\\lambda)^3 - 3\\mu^2(1-\\lambda) - 2\\mu^3 = 0\n$$\n我们进行替换，$x = 1-\\lambda$。方程变为一个关于 $x$ 的降次三次方程：\n$$\nx^3 - 3\\mu^2 x - 2\\mu^3 = 0\n$$\n我们可以通过因式分解来找到这个多项式的根。我们测试与 $\\mu$ 相关的简单根。\n对于 $x=2\\mu$：$(2\\mu)^3 - 3\\mu^2(2\\mu) - 2\\mu^3 = 8\\mu^3 - 6\\mu^3 - 2\\mu^3 = 0$。所以，$x=2\\mu$ 是一个根。\n对于 $x=-\\mu$：$(-\\mu)^3 - 3\\mu^2(-\\mu) - 2\\mu^3 = -\\mu^3 + 3\\mu^3 - 2\\mu^3 = 0$。所以，$x=-\\mu$ 是一个根。\n由于 $x^3+px^2+qx+r=0$ 的根之和为 $-p$，而我们方程中 $x^2$ 的系数为 $0$，所以三个根的和必须为 $0$。如果我们已经有两个根 $2\\mu$ 和 $-\\mu$，那么第三个根必须是 $-(2\\mu - \\mu) = -\\mu$。\n所以，$x$ 的根是 $2\\mu$、$-\\mu$ 和 $-\\mu$。\n特征值 $\\lambda$ 通过 $\\lambda = 1-x$ 求得。因此，$G^{(2)}$ 的特征值为：\n$\\lambda_1 = 1 - 2\\mu$（重数为 $1$）\n$\\lambda_2, \\lambda_3 = 1 - (-\\mu) = 1+\\mu$（重数为 $2$）\n\n为了找到最小特征值 $\\lambda_{\\min}(G^{(2)})$，我们比较 $1-2\\mu$ 和 $1+\\mu$。两者之差为 $(1+\\mu) - (1-2\\mu) = 3\\mu$。由于 $\\mu > 0$，这个差是正的，这意味着 $1+\\mu > 1-2\\mu$。因此，$G^{(2)}$ 的最小特征值为：\n$$\n\\lambda_{\\min}(G^{(2)}) = 1-2\\mu\n$$\n$G^{(2)}$ 也必须是半正定的。对于 $\\mu \\in (0, \\frac{1}{2})$，我们有 $1-2\\mu > 0$ 且 $1+\\mu > 1 > 0$，所以特征值确实为正，这确认了该矩阵是正定的。\n\n最后，我们计算所要求的比值 $r(\\mu)$：\n$$\nr(\\mu) = \\frac{\\lambda_{\\min}(G^{(1)})}{\\lambda_{\\min}(G^{(2)})} = \\frac{1-\\mu}{1-2\\mu}\n$$\n此表达式已简化，即为最终答案。",
            "answer": "$$\\boxed{\\frac{1-\\mu}{1-2\\mu}}$$"
        },
        {
            "introduction": "理论分析常常依赖于Gram子矩阵的最小特征值，但对于一个通用的、无结构的矩阵，我们该如何计算这个值呢？这个编码练习  将指导你实现瑞利商迭代算法，这是一种解决此问题的强大数值方法。这项实践展示了如何近似计算关键的理论量，并将其与唯一性和噪声稳定性等实际恢复条件联系起来。",
            "id": "3445866",
            "problem": "给定一个传感矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和一个选择列子集的支撑集 $S \\subseteq \\{0,1,\\dots,n-1\\}$。对于由 $A$ 中索引为 $S$ 的列构成的子矩阵 $A_S \\in \\mathbb{R}^{m \\times |S|}$，考虑其格拉姆矩阵 $G_S = A_S^{\\top} A_S$，该矩阵是对称正半定的。最小特征值 $\\lambda_{\\min}(G_S)$ 等于 $A_S$ 的最小奇异值的平方。在压缩感知和稀疏优化中，当支撑集已知或被假设时，$\\lambda_{\\min}(G_S)$ 的性质对于恢复的唯一性和稳定性至关重要。\n\n从基本原理开始：\n- 对于任意非零向量 $x \\in \\mathbb{R}^{|S|}$，瑞利商定义为 $R(x) = \\dfrac{x^{\\top} G_S x}{x^{\\top} x}$。\n- 对于对称矩阵 $G_S$，在 $x \\neq 0$ 的范围内，$R(x)$ 的最小值恰好是 $\\lambda_{\\min}(G_S)$，在与 $\\lambda_{\\min}(G_S)$ 相关联的 $G_S$ 的特征向量处取得。\n- 对称正半定矩阵的所有特征值均为非负，而 $G_S = A_S^{\\top} A_S$ 根据其构造是正半定的。\n\n任务：使用基于瑞利商的迭代方法，实现 $\\lambda_{\\min}(G_S)$ 的数值近似。使用带瑞利商更新的反迭代法来近似最小特征值和特征向量，并为可能奇异或接近奇异的正半定矩阵设置适当的保障措施。然后将该近似值与恢复条件联系起来，并计算以下量：\n1. 通过您的瑞利商迭代获得的 $\\lambda_{\\min}(G_S)$ 的数值近似值。\n2. 通过直接对称特征分解计算出的精确 $\\lambda_{\\min}(G_S)$，作为基准真相。\n3. 一个布尔值，指示在无噪声情况下，支撑集 $S$ 上的恢复是否唯一，定义为 $A_S$ 具有满列秩。使用判据 $\\lambda_{\\min}(G_S) > \\tau$，容差 $\\tau = 10^{-8}$。\n4. 一个稳定性因子 $c_S$，定义为 $c_S = 1 / \\sigma_{\\min}(A_S) = 1 / \\sqrt{\\lambda_{\\min}(G_S)}$，其中较大的 $c_S$ 表示在约束于 $S$ 的最小二乘恢复中噪声放大更严重。\n5. 当 $A$ 的所有列都被归一化为单位 $\\ell_2$ 范数时，子集限制等距偏差 $\\delta_S$ 定义为 $\\delta_S = \\max_{i} \\left| \\lambda_i(G_S) - 1 \\right|$。这量化了 $A_S$ 在其列所张成的子空间上偏离等距映射的程度。\n6. 一个布尔值，指示经典的类限制等距检查是否在子集上通过，定义为 $\\delta_S  \\sqrt{2} - 1$。\n\n构建并评估以下测试套件。在所有情况下，在形成 $A_S$ 和 $G_S$ 之前，将 $A$ 的每一列归一化为单位 $\\ell_2$ 范数。\n\n- 测试用例 1（通用、随机、良态）：\n  - 维度：$m = 8$， $n = 10$。\n  - 随机种子：$0$。\n  - 构造：抽取具有独立标准正态分布元素的 $A$，然后将每列归一化为单位 $\\ell_2$ 范数。\n  - 支撑集：$S = [0, 3, 7]$。\n\n- 测试用例 2（接近共线性导致接近奇异）：\n  - 维度：$m = 6$， $n = 8$。\n  - 随机种子：$1$。\n  - 构造：\n    - 生成一个具有独立标准正态分布元素的随机基矩阵。\n    - 通过归一化一个随机列来形成单位向量 $u \\in \\mathbb{R}^{m}$。\n    - 生成一个随机向量 $v \\in \\mathbb{R}^{m}$，通过 $v \\leftarrow v - (u^{\\top} v) u$ 将其与 $u$ 正交化，然后归一化 $v$。\n    - 将 $A$ 的第 0 列设置为 $u$，将 $A$ 的第 1 列设置为 $u + \\varepsilon v$ 的归一化结果，其中 $\\varepsilon = 10^{-3}$，将 $A$ 的第 2 列设置为一个随机向量的归一化结果，其他列保持为随机。最后将 $A$ 的所有列归一化为单位 $\\ell_2$ 范数。\n  - 支撑集：$S = [0, 1, 2]$。\n\n- 测试用例 3（单列子集）：\n  - 维度：$m = 5$， $n = 7$。\n  - 随机种子：$123$。\n  - 构造：抽取具有独立标准正态分布元素的 $A$，然后将每列归一化为单位 $\\ell_2$ 范数。\n  - 支撑集：$S = [5]$。\n\n- 测试用例 4（病态但满秩）：\n  - 维度：$m = 6$， $n = 8$。\n  - 随机种子：$42$。\n  - 构造：\n    - 生成一个具有独立标准正态分布元素的随机基矩阵。\n    - 归一化 $A$ 的所有列。\n    - 将第 7 列修改为 $A[:, 1] + \\eta r$ 的归一化结果，其中 $r$ 是一个新的随机向量，$\\eta = 10^{-2}$，然后重新归一化所有列。\n  - 支撑集：$S = [1, 4, 6, 7]$。\n\n您的程序应为每个测试用例输出一个列表，其中包含：\n- 近似的 $\\lambda_{\\min}(G_S)$（浮点数），\n- 精确的 $\\lambda_{\\min}(G_S)$（浮点数），\n- 唯一性布尔值，\n- 稳定性因子 $c_S$（浮点数），\n- 偏差 $\\delta_S$（浮点数），\n- 限制等距检查布尔值。\n\n您的程序应生成单行输出，包含所有测试用例的结果列表，该列表为用方括号括起来的逗号分隔列表，例如，$$[ [r_1], [r_2], [r_3], [r_4] ]$$ 其中每个 $[r_i]$ 本身是包含上述六个项目的列表。",
            "solution": "该解决方案围绕数值线性代数及其在压缩感知中应用的原则构建。问题的核心是分析与子矩阵 $A_S$ 相关的格拉姆矩阵 $G_S = A_S^\\top A_S$。最小特征值 $\\lambda_{\\min}(G_S)$ 至关重要，因为它决定了在已知支撑集 $S$ 上的稀疏恢复问题的条件数。\n\n**$\\lambda_{\\min}(G_S)$ 的近似：**\n问题要求使用“带瑞利商更新的反迭代法”，这是一种更常被称为瑞利商迭代（RQI）的强大算法。对于一个对称矩阵 $G_S$ 和一个近似特征向量 $x_k$，RQI 包含两个步骤：\n$1$. 计算瑞利商：$\\mu_k = \\frac{x_k^\\top G_S x_k}{x_k^\\top x_k}$。这是对于给定 $x_k$ 的最佳特征值估计。\n$2$. 通过求解 $(G_S - \\mu_k I) y_{k+1} = x_k$ 并归一化来更新特征向量估计：$x_{k+1} = y_{k+1} / \\|y_{k+1}\\|_2$。此步骤是反迭代法的一种形式，其中位移 $\\mu_k$ 是动态更新的。\n\nRQI 表现出三次方收敛速度，但其能否找到特定特征值（本例中为最小特征值）取决于初始向量 $x_0$。一个简单的随机起点可能会收敛到任意一个特征值。为了可靠地定位 $\\lambda_{\\min}(G_S)$，需要一个更鲁棒的初始化方法。我们采用一个预处理步骤，在一个轻微位移的矩阵 $(G_S + \\epsilon I)$ 上使用简单的反幂法迭代，其中 $\\epsilon$ 是一个小的正数。应用几次求解 $(G_S + \\epsilon I)y = x$ 的迭代会将向量 $x$ 引导至与 $G_S$ 最接近 $-\\epsilon$ 的特征值（即 $\\lambda_{\\min}(G_S)$）所对应的特征向量。这个经过优化的向量随后作为 RQI 的高质量起始点，确保收敛到所需的特征值。\n\nRQI 的一个关键方面是处理线性系统的求解。当 $\\mu_k$ 接近一个真实特征值时，矩阵 $(G_S - \\mu_k I)$ 会变得病态或奇异。这是该算法的一个特性，而非缺陷；解向量 $y_{k+1}$ 的巨大模长正是加速收敛的原因。我们的实现将捕获由此奇异性引起的 `numpy.linalg.LinAlgError`，并将其正确地解释为收敛的迹象，从而终止迭代。\n\n**相关度量的计算：**\n一旦确定了 $\\lambda_{\\min}(G_S)$，我们计算几个与压缩感知理论相关的核心量：\n\n$1$. **基准真相特征值：** 我们使用一个标准的、高度优化的对称特征求解器（`numpy.linalg.eigh`）来计算 $G_S$ 的所有特征值，以获得 $\\lambda_{\\min}(G_S)$ 的精确参考值，并用于计算 $\\delta_S$。\n$2$. **恢复的唯一性：** 对于无噪声测量 $y=Ax$，如果真实稀疏向量 $x$ 的支撑集为 $S$，那么（在已知 $S$ 的情况下）$x$ 的唯一可恢复性等价于能够唯一求解 $y = A_S x_S$。这要求 $A_S$ 具有满列秩，这当且仅当 $G_S=A_S^\\top A_S$ 可逆时成立，即 $\\lambda_{\\min}(G_S) > 0$。我们用数值容差 $\\tau = 10^{-8}$ 来检验这个条件。\n$3$. **稳定性因子 ($c_S$)：** 在有噪声的情况下，最小二乘解的稳定性取决于 $A_S$ 的条件数。一个关键度量是 $c_S = 1/\\sigma_{\\min}(A_S)$，其中 $\\sigma_{\\min}(A_S)$ 是 $A_S$ 的最小奇异值。利用恒等式 $\\lambda_{\\min}(G_S) = \\sigma_{\\min}(A_S)^2$，我们有 $c_S = 1/\\sqrt{\\lambda_{\\min}(G_S)}$。一个大的 $c_S$ 表明对噪声高度敏感。如果 $\\lambda_{\\min}(G_S)=0$，该因子为无穷大。\n$4$. **子集限制等距偏差 ($\\delta_S$)：** 限制等距性（RIP）是压缩感知理论的基石。虽然计算真实的 RIP 常数是 NP-难的，但我们可以针对特定子集 $S$ 检验一个相关属性。如果 $A$ 的所有列都经过单位归一化，当 $A_S$ 是一个等距映射时，算子 $A_S^\\top A_S$ 在其定义域上表现为单位算子。偏差 $\\delta_S = \\max_i |\\lambda_i(G_S) - 1|$ 量化了 $G_S$ 与单位矩阵 $I$ 的差异程度。\n$5$. **经典类 RIP 检查：** 许多恢复保证的一个充分（但非必要）条件是，对于 $2k$-稀疏信号，$\\delta_{2k}  \\sqrt{2}-1$。我们将此检查应用于我们的特定子集 $S$，评估是否 $\\delta_S  \\sqrt{2}-1$。\n\n整个过程对一套测试用例进行自动化处理，每个用例都旨在探测问题的不同方面，从良态的随机矩阵到特意构造的病态情况。使用固定的随机种子确保了所有构造和结果的可复现性。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import lu_factor, lu_solve\n\ndef approximate_lambda_min(G, rng, num_init_iter=10, num_rqi_iter=15):\n    \"\"\"\n    Approximates the smallest eigenvalue of a symmetric positive semidefinite matrix G\n    using inverse iteration followed by Rayleigh Quotient Iteration (RQI).\n    \n    Args:\n        G (np.ndarray): The symmetric positive semidefinite matrix.\n        rng (np.random.Generator): A random number generator.\n        num_init_iter (int): Number of iterations for the initial inverse power method.\n        num_rqi_iter (int): Number of iterations for RQI.\n\n    Returns:\n        float: The approximated smallest eigenvalue.\n    \"\"\"\n    k = G.shape[0]\n    if k == 0:\n        return np.nan\n    if k == 1:\n        return G[0, 0]\n\n    # Initialize a random vector\n    x = rng.standard_normal(size=k)\n    x /= np.linalg.norm(x)\n\n    # 1. Initial phase: Shifted inverse iteration to find a good starting vector.\n    # This guides the vector towards the eigenvector of the smallest eigenvalue.\n    # The shift makes the system well-conditioned.\n    shift = 1e-12\n    G_shifted = G + shift * np.identity(k)\n    try:\n        # Pre-compute LU factorization for efficiency in the loop\n        lu, piv = lu_factor(G_shifted)\n        for _ in range(num_init_iter):\n            y = lu_solve((lu, piv), x)\n            norm_y = np.linalg.norm(y)\n            if norm_y  1e-20:\n                # Vector collapsed; restart with new random vector\n                x = rng.standard_normal(size=k)\n                x /= np.linalg.norm(x)\n                lu, piv = lu_factor(G + shift * np.identity(k)) # Recalculate LU\n                continue\n            x = y / norm_y\n    except np.linalg.LinAlgError:\n        # Fallback to pseudo-inverse if LU fails (extremely unlikely with the shift)\n        G_pinv = np.linalg.pinv(G_shifted)\n        for _ in range(num_init_iter):\n            y = G_pinv @ x\n            norm_y = np.linalg.norm(y)\n            if norm_y  1e-20:\n                x = rng.standard_normal(size=k)\n                x /= np.linalg.norm(x)\n                continue\n            x = y / norm_y\n\n    # 2. Refinement phase: Rayleigh Quotient Iteration\n    lambda_approx = np.dot(x, G @ x)\n\n    for _ in range(num_rqi_iter):\n        M = G - lambda_approx * np.identity(k)\n        try:\n            y = np.linalg.solve(M, x)\n        except np.linalg.LinAlgError:\n            # Expected condition: M is singular, so lambda_approx is close to an eigenvalue.\n            return lambda_approx\n        \n        norm_y = np.linalg.norm(y)\n        if norm_y  1e-20:\n            return lambda_approx\n        x = y / norm_y\n        lambda_approx = np.dot(x, G @ x)\n        \n    return lambda_approx\n\ndef run_test_case(m, n, seed, S, A_construction_func):\n    \"\"\"\n    Sets up and runs a single test case, computing all required metrics.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    A = A_construction_func(m, n, rng)\n\n    A_S = A[:, S]\n    G_S = A_S.T @ A_S\n\n    # 1. Approximate lambda_min using RQI\n    approx_lambda_min = approximate_lambda_min(G_S, rng)\n\n    # 2. Exact eigenvalues for ground truth and other metrics\n    if G_S.shape[0] == 0:\n        all_eigenvalues = np.array([])\n        exact_lambda_min = np.nan\n    else:\n\n        all_eigenvalues = np.linalg.eigh(G_S)[0]\n        exact_lambda_min = all_eigenvalues[0] if len(all_eigenvalues) > 0 else np.nan\n\n\n    # 3. Uniqueness boolean\n    tau = 1e-8\n    is_unique = exact_lambda_min > tau if not np.isnan(exact_lambda_min) else False\n\n    # 4. Stability factor\n    if not np.isnan(exact_lambda_min) and exact_lambda_min > 1e-15:\n        stability_factor_c_S = 1.0 / np.sqrt(exact_lambda_min)\n    else:\n        stability_factor_c_S = np.inf\n        \n    # 5. Restricted Isometry Deviation\n    if G_S.shape[0] > 0:\n        rip_deviation_delta_S = np.max(np.abs(all_eigenvalues - 1.0))\n    else:\n        rip_deviation_delta_S = 0.0\n\n    # 6. Restricted Isometry Check\n    rip_check = rip_deviation_delta_S  (np.sqrt(2.0) - 1.0)\n\n    return [\n        approx_lambda_min,\n        exact_lambda_min,\n        is_unique,\n        stability_factor_c_S,\n        rip_deviation_delta_S,\n        rip_check,\n    ]\n\ndef solve():\n    \"\"\"\n    Main function to define, run, and print results for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"m\": 8, \"n\": 10, \"seed\": 0, \"S\": [0, 3, 7],\n            \"construct\": lambda m, n, rng: (\n                lambda A: A / np.linalg.norm(A, axis=0)\n            )(rng.standard_normal(size=(m, n)))\n        },\n        {\n            \"m\": 6, \"n\": 8, \"seed\": 1, \"S\": [0, 1, 2],\n            \"construct\": lambda m, n, rng: (\n                lambda A: (\n                    A.__setitem__((slice(None), 0), (lambda u_rand: u_rand / np.linalg.norm(u_rand))(rng.standard_normal(size=m))),\n                    A.__setitem__((slice(None), 1), (lambda u, v, eps: (u + eps * v) / np.linalg.norm(u + eps * v))(\n                        A[:, 0], \n                        (lambda u, v_rand: (v_rand - np.dot(u, v_rand) * u) / np.linalg.norm(v_rand - np.dot(u, v_rand) * u))(A[:, 0], rng.standard_normal(size=m)),\n                        1e-3\n                    )),\n                    A.__setitem__((slice(None), 2), (lambda r: r / np.linalg.norm(r))(rng.standard_normal(size=m))),\n                    A / np.linalg.norm(A, axis=0)\n                )[-1]\n            )(rng.standard_normal(size=(m, n)))\n        },\n        {\n            \"m\": 5, \"n\": 7, \"seed\": 123, \"S\": [5],\n            \"construct\": lambda m, n, rng: (\n                lambda A: A / np.linalg.norm(A, axis=0)\n            )(rng.standard_normal(size=(m, n)))\n        },\n        {\n            \"m\": 6, \"n\": 8, \"seed\": 42, \"S\": [1, 4, 6, 7],\n            \"construct\": lambda m, n, rng: (\n                lambda A: (\n                    A.__setitem__((slice(None), 7), (lambda col: col / np.linalg.norm(col))(A[:, 1] + 1e-2 * rng.standard_normal(size=m))),\n                    A / np.linalg.norm(A, axis=0)\n                )[-1]\n            )((lambda B: B / np.linalg.norm(B, axis=0))(rng.standard_normal(size=(m, n))))\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(case[\"m\"], case[\"n\"], case[\"seed\"], case[\"S\"], case[\"construct\"])\n        results.append(result)\n\n    # Format output as a string representing a list of lists.\n    # The template `f\"[{','.join(map(str, results))}]\"` handles this structure correctly.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}