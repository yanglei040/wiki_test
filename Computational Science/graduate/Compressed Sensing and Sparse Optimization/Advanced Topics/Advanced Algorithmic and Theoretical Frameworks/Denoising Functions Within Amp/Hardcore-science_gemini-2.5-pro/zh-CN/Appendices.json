{
    "hands_on_practices": [
        {
            "introduction": "在信号处理中，一个核心挑战是如何在不知道原始真实信号的情况下，为去噪器选择最优参数。斯坦无偏风险估计（Stein's Unbiased Risk Estimate, SURE）为此提供了一个强大的解决方案，它允许我们仅根据带噪观测数据来估计均方误差（MSE）。这个练习将引导您从第一性原理推导SURE，并将其应用于经典的软阈值去噪器，通过实践来掌握这种数据驱动的参数优化方法。",
            "id": "3443731",
            "problem": "给定一系列在加性高斯噪声模型下的近似消息传递 (AMP) 去噪场景，你需要推导并实现一个 Stein 无偏风险估计 (SURE) 来调整软阈值去噪函数。目标是从第一性原理出发推导该估计量，然后使用它来选择一个软阈值，以在给定有效观测向量和已知有效噪声方差的情况下，最小化 SURE。\n\n从适用于近似消息传递中压缩感知和稀疏优化的基础出发：一个高斯噪声模型和均方误差风险的定义。具体来说，考虑观测模型，其中未知信号 $x_0 \\in \\mathbb{R}^n$ 通过以下方式被观测\n$$\ny = x_0 + w,\n$$\n其中 $w \\sim \\mathcal{N}(0, \\tau^2 I_n)$ 是一个独立的高斯噪声向量，其方差 $\\tau^2$ 对算法是已知的。在 AMP 的一次迭代中，去噪函数逐分量地应用于有效观测值 $y$，以产生 $x_0$ 的一个估计 $\\eta(y)$。对于由标量阈值 $t$ 参数化的去噪器，其均方误差风险为\n$$\nR(t) = \\mathbb{E}\\left[\\frac{1}{n}\\left\\|\\eta(y; t) - x_0\\right\\|_2^2\\right],\n$$\n该风险依赖于未知的真实信号 $x_0$。你必须使用关于高斯分布和弱可微函数散度的成熟理论，来推导一个仅依赖于 $y$、$\\tau^2$ 和去噪器，而无需 $x_0$ 知识的无偏估计量。不要假设估计量有任何预先指定的形式；应从高斯噪声模型、风险的定义以及关于高斯随机变量期望的恒等式出发进行推导。\n\n具体到逐分量应用的软阈值去噪器：\n$$\n\\eta_i(y_i; t) = \\mathrm{sign}(y_i)\\max\\{|y_i| - t, 0\\},\n$$\n对于所有 $i \\in \\{1,\\dots,n\\}$，且 $t \\ge 0$。构建 $\\eta(\\cdot; t)$ 相对于 $y$ 的散度，并将其整合到你推导的无偏风险估计量中。然后设计一个算法，在区间 $[0, \\max_i |y_i|]$ 上对 $t$ 进行包含 $512$ 个网格点的均匀网格搜索，以找到最小化你所推导的无偏风险估计量的阈值 $t^\\star$。使用确定性的平局打破规则，即在所有最小化者中选择最小的 $t$。\n\n对于下面的测试套件中的每一种场景，通过使用指定的随机种子抽取 $w$ 并计算 $y = x_0 + w$ 来生成有效观测向量。对于每个测试用例，你的程序必须计算并返回：\n- 最小化阈值 $t^\\star$。\n- 在 $t^\\star$ 处取值的最小化无偏风险估计量。\n- 经验均方误差 $\\frac{1}{n}\\|\\eta(y; t^\\star) - x_0\\|_2^2$，用于在合成数据上进行验证（注意，对于任何单次实现，不要求其与估计量相等）。\n- 每坐标散度，定义为 $\\frac{1}{n}\\sum_{i=1}^n \\frac{\\partial \\eta_i(y_i; t^\\star)}{\\partial y_i}$，这是近似消息传递中 Onsager 修正项所使用的量。\n\n所有量都应被视为无单位的实数。不涉及角度，也不需要任何物理单位。你的程序必须是确定性的和自包含的。\n\n测试套件：\n1. 情况 A (理想情况): $n = 10$，\n$$\nx_0 = [3.0, 0.0, 0.0, -2.0, 0.0, 0.0, 1.5, 0.0, 0.0, 0.0],\n$$\n$\\tau = 0.8$，随机种子 $0$。\n2. 情况 B (边界情况 $\\tau = 0$): $n = 8$，\n$$\nx_0 = [0.0, 0.0, 4.0, -3.5, 0.0, 2.0, 0.0, -1.0],\n$$\n$\\tau = 0.0$，随机种子 $1$ (当 $\\tau = 0$ 时，种子无关紧要)。\n3. 情况 C (高噪声): $n = 12$，\n$$\nx_0 = [0.5, -0.5, 0.2, 0.0, 0.0, 0.0, 1.0, 0.0, -1.2, 0.3, 0.0, 0.0],\n$$\n$\\tau = 2.0$，随机种子 $1$。\n4. 情况 D (全零信号): $n = 9$,\n$$\nx_0 = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n$$\n$\\tau = 0.5$，随机种子 $42$。\n\n最终输出格式：\n你的程序应该产生单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是一个形如 $[t^\\star, \\mathrm{Estimator}(t^\\star), \\mathrm{MSE}(t^\\star), \\mathrm{DivPerDim}(t^\\star)]$ 的列表，并且外层列表聚合了这四个用例，例如\n$$\n[[t^\\star_A, \\mathrm{Estimator}_A, \\mathrm{MSE}_A, \\mathrm{DivPerDim}_A],[t^\\star_B, \\mathrm{Estimator}_B, \\mathrm{MSE}_B, \\mathrm{DivPerDim}_B],[t^\\star_C, \\mathrm{Estimator}_C, \\mathrm{MSE}_C, \\mathrm{DivPerDim}_C],[t^\\star_D, \\mathrm{Estimator}_D, \\mathrm{MSE}_D, \\mathrm{DivPerDim}_D]].\n$$\n不应打印任何额外的文本。",
            "solution": "用户提供的问题陈述已经过分析，并被认为是有效的。它具有科学依据、问题定义清晰、客观，并包含唯一可验证解所需的所有必要信息。我们现在开始推导和实现。\n\n### 1. Stein 无偏风险估计 (SURE) 的推导\n\n我们的目标是为去噪函数 $\\eta(y; t)$ 的均方误差 (MSE) 风险找到一个无偏估计量。该风险定义为：\n$$\nR(t) = \\mathbb{E}\\left[\\frac{1}{n}\\left\\|\\eta(y; t) - x_0\\right\\|_2^2\\right]\n$$\n观测模型为 $y = x_0 + w$，其中 $w \\sim \\mathcal{N}(0, \\tau^2 I_n)$ 是一个高斯噪声向量。真实信号 $x_0$ 是未知的。$R(t)$ 的估计量，记为 $\\hat{R}(y;t)$，必须仅依赖于观测值 $y$、噪声方差 $\\tau^2$ 和去噪器 $\\eta$。\n\n让我们考虑未归一化的风险，$\\mathbb{E}[\\|\\eta(y) - x_0\\|_2^2]$。我们可以通过加上和减去 $y$ 来展开平方范数：\n$$\n\\|\\eta(y) - x_0\\|_2^2 = \\|\\eta(y) - y + y - x_0\\|_2^2 = \\|(\\eta(y) - y) + w\\|_2^2\n$$\n展开内积可得：\n$$\n\\|\\eta(y) - x_0\\|_2^2 = \\|\\eta(y) - y\\|_2^2 + \\|w\\|_2^2 + 2(\\eta(y) - y)^T w\n$$\n对噪声分布取期望，我们得到：\n$$\n\\mathbb{E}[\\|\\eta(y) - x_0\\|_2^2] = \\mathbb{E}[\\|\\eta(y) - y\\|_2^2] + \\mathbb{E}[\\|w\\|_2^2] + 2\\mathbb{E}[(\\eta(y) - y)^T w]\n$$\n我们来分析每一项：\n1.  $\\mathbb{E}[\\|\\eta(y) - y\\|_2^2]$: 这一项依赖于可观测的量 $y$，所以它的样本值 $\\|\\eta(y) - y\\|_2^2$ 可以用在我们的估计量中。\n2.  $\\mathbb{E}[\\|w\\|_2^2] = \\mathbb{E}[\\sum_{i=1}^n w_i^2] = \\sum_{i=1}^n \\mathbb{E}[w_i^2] = n\\tau^2$。由于 $\\tau^2$ 是已知的，这一项也是已知的。\n3.  $2\\mathbb{E}[(\\eta(y) - y)^T w]$: 这个交叉项涉及到未知的 $w$。我们可以使用 Stein 引理来简化它。\n\n对于一个高斯随机向量 $Y \\sim \\mathcal{N}(\\mu, \\sigma^2 I)$ 和一个弱可微函数 $g: \\mathbb{R}^n \\to \\mathbb{R}^n$，Stein 引理指出：\n$$\n\\mathbb{E}[(Y - \\mu)^T g(Y)] = \\sigma^2 \\mathbb{E}[\\nabla \\cdot g(Y)]\n$$\n在我们的情况下，$Y=y$，$\\mu=x_0$，且 $\\sigma^2=\\tau^2$。向量 $w$ 是 $y - x_0$。因此，我们有：\n$$\n\\mathbb{E}[w^T \\eta(y)] = \\tau^2 \\mathbb{E}[\\nabla \\cdot \\eta(y)]\n$$\n其中 $\\nabla \\cdot \\eta(y) = \\sum_{i=1}^n \\frac{\\partial \\eta_i}{\\partial y_i}$ 是函数 $\\eta$ 的散度。\n\n交叉项可以展开为：\n$$\n\\mathbb{E}[(\\eta(y) - y)^T w] = \\mathbb{E}[\\eta(y)^T w] - \\mathbb{E}[y^T w]\n$$\n对第一部分应用 Stein 引理得到 $\\mathbb{E}[\\eta(y)^T w] = \\tau^2 \\mathbb{E}[\\nabla \\cdot \\eta(y)]$。\n对于第二部分，我们代入 $y = x_0 + w$：\n$$\n\\mathbb{E}[y^T w] = \\mathbb{E}[(x_0 + w)^T w] = \\mathbb{E}[x_0^T w] + \\mathbb{E}[w^T w] = x_0^T \\mathbb{E}[w] + \\mathbb{E}[\\|w\\|_2^2] = 0 + n\\tau^2 = n\\tau^2\n$$\n综合这些，交叉项的期望为：\n$$\n\\mathbb{E}[(\\eta(y) - y)^T w] = \\tau^2 \\mathbb{E}[\\nabla \\cdot \\eta(y)] - n\\tau^2\n$$\n将所有项代回风险的展开式中：\n$$\n\\mathbb{E}[\\|\\eta(y) - x_0\\|_2^2] = \\mathbb{E}[\\|\\eta(y) - y\\|_2^2] + n\\tau^2 + 2(\\tau^2 \\mathbb{E}[\\nabla \\cdot \\eta(y)] - n\\tau^2)\n$$\n$$\n\\mathbb{E}[\\|\\eta(y) - x_0\\|_2^2] = \\mathbb{E}[\\|\\eta(y) - y\\|_2^2 - n\\tau^2 + 2\\tau^2 \\nabla \\cdot \\eta(y)]\n$$\n根据期望的线性性质，$\\|\\eta(y) - x_0\\|_2^2$ 的一个无偏估计量是右侧期望内的随机变量。通过除以 $n$ 进行归一化以匹配风险 $R(t)$ 的定义，我们得到 Stein 无偏风险估计：\n$$\n\\hat{R}(y; t) = \\frac{1}{n} \\left( \\|\\eta(y;t) - y\\|_2^2 - n\\tau^2 + 2\\tau^2 \\nabla \\cdot \\eta(y;t) \\right)\n$$\n此表达式仅依赖于 $y$、$\\tau^2$ 和 $\\eta$，并且是真实风险的无偏估计量，即 $\\mathbb{E}[\\hat{R}(y; t)] = R(t)$。\n\n### 2. 针对软阈值去噪器的特化\n\n问题指定了逐分量的软阈值函数：\n$$\n\\eta_i(y_i; t) = \\mathrm{sign}(y_i)\\max\\{|y_i| - t, 0\\} = \\begin{cases} y_i - t   \\text{if } y_i > t \\\\ 0   \\text{if } |y_i| \\le t \\\\ y_i + t   \\text{if } y_i  -t \\end{cases}\n$$\n为了使用 SURE 公式，我们需要它的散度，$\\nabla \\cdot \\eta(y;t) = \\sum_{i=1}^n \\frac{\\partial \\eta_i(y_i; t)}{\\partial y_i}$。\n函数 $\\eta_i$ 是弱可微的。它关于 $y_i$ 的弱导数为：\n$$\n\\frac{\\partial \\eta_i(y_i; t)}{\\partial y_i} = \\begin{cases} 1   \\text{if } |y_i| > t \\\\ 0   \\text{if } |y_i|  t \\end{cases}\n$$\n这可以用指示函数紧凑地写成：$\\mathbb{I}(|y_i| > t)$。\n因此，散度是 $y$ 中绝对值超过阈值 $t$ 的元素数量：\n$$\n\\nabla \\cdot \\eta(y;t) = \\sum_{i=1}^n \\mathbb{I}(|y_i| > t)\n$$\n我们还需要 $\\|\\eta(y;t) - y\\|_2^2 = \\sum_{i=1}^n (\\eta_i(y_i; t) - y_i)^2$ 这一项。\n- 如果 $|y_i| > t$，则 $\\eta_i(y_i; t) - y_i = -t \\cdot \\mathrm{sign}(y_i)$，所以 $(\\eta_i - y_i)^2 = t^2$。\n- 如果 $|y_i| \\le t$，则 $\\eta_i(y_i; t) - y_i = -y_i$，所以 $(\\eta_i - y_i)^2 = y_i^2$。\n\n这使我们可以将平方和写为：\n$$\n\\|\\eta(y;t) - y\\|_2^2 = \\sum_{i: |y_i| \\le t} y_i^2 + \\sum_{i: |y_i| > t} t^2\n$$\n将这些特化的形式代入通用的 SURE 公式，得到需要最小化的最终表达式：\n$$\n\\hat{R}(y; t) = \\frac{1}{n} \\left( \\left(\\sum_{i: |y_i| \\le t} y_i^2 + \\sum_{i: |y_i| > t} t^2\\right) - n\\tau^2 + 2\\tau^2 \\sum_{i=1}^n \\mathbb{I}(|y_i| > t) \\right)\n$$\n\n### 3. 算法实现\n\n该算法将通过在区间 $[0, \\max_i|y_i|]$ 上执行均匀网格搜索来找到最优阈值 $t^\\star$。对于每个测试用例，执行以下步骤：\n1.  使用指定的参数（$x_0, \\tau$）和给定的随机种子生成的伪随机噪声向量 $w \\sim \\mathcal{N}(0, \\tau^2 I_n)$，生成观测向量 $y = x_0 + w$。\n2.  定义一个包含 $512$ 个候选阈值 $t$ 的网格，范围从 $0$ 到 $\\max_i|y_i|$。\n3.  对于每个候选阈值 $t$，使用推导出的公式计算 SURE 值 $\\hat{R}(y; t)$。\n4.  确定最小化 $\\hat{R}(y; t)$ 的阈值 $t^\\star$。如果出现平局，则选择其中最小的 $t$。\n5.  使用最优阈值 $t^\\star$，计算所需的四个度量指标：\n    - 最优阈值 $t^\\star$。\n    - 最小化的 SURE 值，$\\hat{R}(y; t^\\star)$。\n    - 经验 MSE，$\\frac{1}{n}\\|\\eta(y; t^\\star) - x_0\\|_2^2$。\n    - 每坐标散度，$\\frac{1}{n} \\sum_{i=1}^n \\mathbb{I}(|y_i| > t^\\star)$。\n然后将所有测试用例的结果格式化为指定的单行输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and applies SURE for soft-thresholding to find the optimal threshold\n    for several denoising scenarios.\n    \"\"\"\n    test_cases = [\n        # Case A: Happy path\n        {'n': 10, 'x0': np.array([3.0, 0.0, 0.0, -2.0, 0.0, 0.0, 1.5, 0.0, 0.0, 0.0]), 'tau': 0.8, 'seed': 0},\n        # Case B: Boundary case tau = 0\n        {'n': 8, 'x0': np.array([0.0, 0.0, 4.0, -3.5, 0.0, 2.0, 0.0, -1.0]), 'tau': 0.0, 'seed': 1},\n        # Case C: High noise\n        {'n': 12, 'x0': np.array([0.5, -0.5, 0.2, 0.0, 0.0, 0.0, 1.0, 0.0, -1.2, 0.3, 0.0, 0.0]), 'tau': 2.0, 'seed': 1},\n        # Case D: All zeros signal\n        {'n': 9, 'x0': np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), 'tau': 0.5, 'seed': 42},\n    ]\n\n    all_results = []\n    num_grid_points = 512\n\n    for case in test_cases:\n        n, x0, tau, seed = case['n'], case['x0'], case['tau'], case['seed']\n        \n        # Generate observation y = x0 + w\n        rng = np.random.default_rng(seed)\n        noise = rng.normal(loc=0.0, scale=tau, size=n)\n        y = x0 + noise\n        \n        # Define the grid for the threshold t\n        t_max = np.max(np.abs(y)) if y.size > 0 else 0.0\n        t_grid = np.linspace(0.0, t_max, num_grid_points, endpoint=True)\n\n        sure_values = np.zeros(num_grid_points)\n        abs_y = np.abs(y)\n        y_squared = y**2\n        tau_squared = tau**2\n\n        # Grid search for the optimal threshold t\n        for i, t in enumerate(t_grid):\n            # Mask for elements whose magnitude is greater than t\n            survived_mask = abs_y > t\n            # Mask for elements whose magnitude is less than or equal to t\n            shrunk_mask = ~survived_mask\n\n            # Count of surviving elements (for divergence term and t^2 term)\n            k_t = np.sum(survived_mask)\n\n            # Sum of squares of elements that are shrunk to zero\n            sum_sq_le = np.sum(y_squared[shrunk_mask])\n            \n            # The SURE formula: (1/n) * (||eta(y;t) - y||^2 - n*tau^2 + 2*tau^2*div(eta))\n            # ||eta(y;t) - y||^2 = sum_{|y_i|=t} y_i^2 + sum_{|y_i|>t} t^2\n            # div(eta) = k_t\n            sure_val = (sum_sq_le + k_t * t**2 - n * tau_squared + 2 * tau_squared * k_t) / n\n            sure_values[i] = sure_val\n\n        # Find the threshold t that minimizes SURE. np.argmin handles ties by taking the first occurrence.\n        min_idx = np.argmin(sure_values)\n        t_star = t_grid[min_idx]\n        min_sure = sure_values[min_idx]\n\n        # Calculate final quantities with the optimal threshold t_star\n        # Soft-thresholding function\n        eta_y_star = np.sign(y) * np.maximum(abs_y - t_star, 0)\n        \n        # Empirical Mean-Squared Error\n        mse_star = np.mean((eta_y_star - x0)**2)\n        \n        # Divergence per coordinate\n        div_star = np.sum(abs_y > t_star)\n        div_per_dim_star = div_star / n\n        \n        all_results.append([t_star, min_sure, mse_star, div_per_dim_star])\n\n    # Format the final output string exactly as specified\n    formatted_results = []\n    for res in all_results:\n        # Join numbers with commas, enclosed in brackets\n        formatted_results.append(f\"[{','.join(f'{v:.15g}' for v in res)}]\")\n    \n    # Join each case's result with a comma, enclosed in brackets\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "近似消息传递（AMP）算法的“即插即用”（Plug-and-Play, PnP）框架允许我们集成各种先进的去噪器。然而，一个关键问题是确保这些外部去噪器的行为与AMP的状态演化（State Evolution）理论相符。这个练习将带您实践一个关键的校准步骤：通过调整一个简单的归一化因子，使通用去噪器的均方误差（MSE）与理想的贝叶斯最优去噪器的性能相匹配，从而保证整个算法的收敛性和性能。",
            "id": "3443767",
            "problem": "考虑用于压缩感知的近似消息传递 (AMP) 框架，其中去噪函数作用于形式为 $y = x + \\tau Z$ 的伪观测。这里，$x \\in \\mathbb{R}^n$ 是从指定的先验分布中抽取的独立同分布 (i.i.d.) 样本，$Z \\in \\mathbb{R}^n$ 是从标准正态分布 $Z \\sim \\mathcal{N}(0,1)$ 中抽取的独立同分布样本。在 AMP 中，校准一个即插即用去噪器对于保持状态演化缩放至关重要，这要求去噪器在当前有效噪声水平下产生的均方误差 (MSE) 与状态演化预测的目标 MSE 相匹配。我们专注于通过调整应用于去噪器的单个标量归一化因子来强制执行归一化条件\n$$\n\\mathbb{E}\\big\\|\\eta(x + \\tau Z) - x\\big\\|_2^2 \\approx \\text{MSE}_{\\text{target}},\n$$\n\n请使用以下基本原理：\n- 最小化均方误差的贝叶斯估计器是在假设的先验和噪声模型下的条件期望 $\\eta_{\\mathrm{Bayes}}(y) = \\mathbb{E}[x \\mid y]$。\n- 对于任意固定的可测去噪函数 $D(y)$，以及应用于去噪器输出的标量归一化 $\\alpha \\in \\mathbb{R}$，MSE 可以展开为\n$$\n\\mathrm{MSE}(\\alpha) = \\mathbb{E}\\big[(\\alpha D(y) - x)^2\\big] = \\alpha^2 \\mathbb{E}[D(y)^2] - 2 \\alpha \\mathbb{E}[x D(y)] + \\mathbb{E}[x^2],\n$$\n这是一个关于 $\\alpha$ 的二次函数。\n- 对于由稀疏度水平 $0 \\leq \\rho \\leq 1$ 和活跃分量方差 $\\sigma_x^2  0$ 定义的伯努利-高斯先验， $x$ 的分布为\n$$\nx_i \\stackrel{\\text{i.i.d.}}{\\sim} (1-\\rho)\\,\\delta_0 + \\rho\\,\\mathcal{N}(0,\\sigma_x^2),\n$$\n观测模型为 $y_i = x_i + \\tau Z_i$，其中 $Z_i \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1)$，对于 $i = 1,\\dots,n$。\n\n任务：\n1. 从第一性原理推导伯努利-高斯先验的贝叶斯最优去噪器 $\\eta_{\\mathrm{Bayes}}(y) = \\mathbb{E}[x \\mid y]$。使用此去噪器定义目标 MSE\n$$\n\\mathrm{MSE}_{\\text{target}} = \\mathbb{E}\\big[(\\eta_{\\mathrm{Bayes}}(x+\\tau Z) - x)^2\\big].\n$$\n您的程序应使用指定的参数，通过蒙特卡洛抽样对该期望进行经验估计。\n\n2. 定义一个带有输入缩放 $s$ 和输出归一化 $\\alpha$ 的即插即用去噪器族 $D(y)$：\n   - 线性收缩器：$D_{\\mathrm{lin}}(y; s, \\sigma_x, \\tau) = a_{\\mathrm{lin}}\\, (s y)$，其中 $a_{\\mathrm{lin}} = \\frac{\\sigma_x^2}{\\sigma_x^2 + (s\\tau)^2}$。\n   - 软阈值：$D_{\\mathrm{soft}}(y; s, \\tau) = \\mathrm{soft}(s y; \\lambda)$，其中 $\\mathrm{soft}(u;\\lambda) = \\mathrm{sign}(u)\\max(|u| - \\lambda, 0)$ 且 $\\lambda = 2 (s \\tau)$。\n   - 非齐次饱和：$D_{\\mathrm{nh}}(y; s, \\tau) = (s y)\\,\\exp\\!\\big(-\\gamma\\,|s y|/(s\\tau)\\big)$，其中 $\\gamma = 0.5$ 为固定值。\n   - 退化零去噪器：$D_{\\mathrm{zero}}(y) \\equiv 0$。\n\n   归一化的即插即用去噪器为 $\\eta_{\\alpha}(y) = \\alpha\\, D(y)$，其中 $y = x + \\tau Z$。\n\n3. 校准目标：对于每个测试案例，使用贝叶斯最优去噪器计算 $\\mathrm{MSE}_{\\text{target}}$，然后为指定的 $D(\\cdot)$ 和 $s$ 校准 $\\alpha$ 以强制执行\n$$\n\\mathbb{E}\\big[(\\alpha D(x+\\tau Z) - x)^2\\big] \\approx \\mathrm{MSE}_{\\text{target}},\n$$\n在绝对容差 $\\varepsilon$ 内。在可能的情况下，使用上面的二次展开式推导出 $\\alpha$ 的直接解。明确处理校准不可能的情况，例如当 $\\mathbb{E}[D(y)^2] = 0$ 或当目标 MSE 严格低于所选去噪器族可实现的最小 MSE 时（此时归一化失败）。\n\n4. 经验估计：所有期望都必须使用给定的参数通过蒙特卡洛方法进行经验估计。不涉及物理单位。\n\n5. 测试套件：\n   - 案例 1 (理想情况，贝叶斯线性一致性)：$n = 100000$, $\\rho = 1.0$, $\\sigma_x = 1.0$, $\\tau = 0.5$，去噪器类型 = 线性收缩器，输入缩放 $s = 0.7$，容差 $\\varepsilon = 10^{-4}$。\n   - 案例 2 (稀疏区域，启发式软阈值，中度失配)：$n = 100000$, $\\rho = 0.05$, $\\sigma_x = 2.0$, $\\tau = 0.3$，去噪器类型 = 软阈值，输入缩放 $s = 0.8$，容差 $\\varepsilon = 2 \\times 10^{-2}$。\n   - 案例 3 (失效模式，退化去噪器)：$n = 100000$, $\\rho = 0.2$, $\\sigma_x = 1.0$, $\\tau = 1.0$，去噪器类型 = 退化零，输入缩放 $s = 1.0$，容差 $\\varepsilon = 10^{-4}$。\n   - 案例 4 (非齐次饱和去噪器)：$n = 100000$, $\\rho = 0.2$, $\\sigma_x = 1.5$, $\\tau = 0.4$，去噪器类型 = 非齐次饱和，输入缩放 $s = 1.2$，容差 $\\varepsilon = 3 \\times 10^{-2}$。\n\n6. 输出规范：对于每个案例，您的程序应返回一个布尔值，指示校准是否成功，成功的定义是达到的 MSE 与目标 MSE 之间的绝对差值小于或等于容差 $\\varepsilon$。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，“[true_case1,true_case2,true_case3,true_case4]”），布尔值使用 Python 的标准大写形式（“True”或“False”）。\n\n您的程序必须是自包含的，使用固定的随机种子确定性地执行所有计算，并遵守指定的运行时环境。",
            "solution": "用户提供的问题是一个有效的、适定的计算信号处理练习，特别是在用于稀疏恢复的近似消息传递 (AMP) 领域。它基于贝叶斯估计和二次优化的既定原则。所有参数和函数都已明确定义，目标清晰且可形式化。\n\n### 步骤 1：提取给定信息\n- **观测模型**：$y = x + \\tau Z$，其中 $y, x, Z \\in \\mathbb{R}^n$。$Z_i \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1)$。\n- **信号先验**：伯努利-高斯，$x_i \\stackrel{\\text{i.i.d.}}{\\sim} (1-\\rho)\\,\\delta_0 + \\rho\\,\\mathcal{N}(0,\\sigma_x^2)$，稀疏度为 $0 \\leq \\rho \\leq 1$，活跃分量方差为 $\\sigma_x^2  0$。\n- **通用去噪函数**：$\\eta(y)$ 作用于伪观测 $y$。\n- **校准目标**：对于一个即插即用去噪器族 $D(y)$，找到一个标量归一化 $\\alpha$ 用于 $\\eta_\\alpha(y) = \\alpha D(y)$，使得 $\\mathbb{E}\\big\\|\\eta_{\\alpha}(x + \\tau Z) - x\\big\\|_2^2 \\approx \\mathrm{MSE}_{\\text{target}}$。\n- **目标 MSE**：$\\mathrm{MSE}_{\\text{target}} = \\mathbb{E}\\big\\|\\eta_{\\mathrm{Bayes}}(x+\\tau Z) - x\\big\\|_2^2$，其中 $\\eta_{\\mathrm{Bayes}}(y) = \\mathbb{E}[x \\mid y]$。\n- **MSE 展开**：对于 $\\eta_\\alpha(y) = \\alpha D(y)$，MSE 是关于 $\\alpha$ 的二次函数：$\\mathrm{MSE}(\\alpha) = \\alpha^2 \\mathbb{E}[D(y)^2] - 2 \\alpha \\mathbb{E}[x D(y)] + \\mathbb{E}[x^2]$。\n- **即插即用去噪器**：\n    1.  $D_{\\mathrm{lin}}(y; s, \\sigma_x, \\tau) = a_{\\mathrm{lin}}\\, (s y)$，其中 $a_{\\mathrm{lin}} = \\frac{\\sigma_x^2}{\\sigma_x^2 + (s\\tau)^2}$。\n    2.  $D_{\\mathrm{soft}}(y; s, \\tau) = \\mathrm{soft}(s y; \\lambda) = \\mathrm{sign}(s y)\\max(|s y| - \\lambda, 0)$，其中 $\\lambda = 2 (s \\tau)$。\n    3.  $D_{\\mathrm{nh}}(y; s, \\tau) = (s y)\\,\\exp\\!\\big(-\\gamma\\,|s y|/(s\\tau)\\big)$，其中 $\\gamma = 0.5$。\n    4.  $D_{\\mathrm{zero}}(y) \\equiv 0$。\n- **经验估计**：所有期望都通过蒙特卡洛模拟进行估计，样本大小为 $n$。\n- **测试案例**：四个案例，指定了所有参数：$(n, \\rho, \\sigma_x, \\tau, \\text{去噪器类型}, s, \\varepsilon)$。\n- **成功标准**：如果校准后去噪器达到的 MSE 在目标 MSE 的容差 $\\varepsilon$ 范围内，则校准成功。\n- **输出**：一个布尔值列表，指示每个测试案例的成功情况。\n\n### 步骤 2：使用提取的给定信息进行验证\n该问题在科学和数学上是合理的。\n- **科学基础**：该问题设置在 AMP 的背景下，这是压缩感知领域的一种最先进算法。伯努利-高斯先验、贝叶斯最优估计器和常见的启发式去噪器（收缩、阈值）的使用都是该领域的标准实践。校准目标是使即插即用 AMP 变得严谨的关键组成部分。\n- **适定性**：问题陈述清晰。目标（找到 $\\alpha$ 以匹配目标 MSE）具有明确定义的数学结构（一个二次方程）。解的存在条件可以从该结构中自然推导出来。为每个案例提供了所有必要的参数。\n- **客观性**：问题使用精确的数学语言和定义，没有歧义，也不包含主观陈述。\n\n该问题没有任何无效性缺陷。它是一个形式化的、自包含的、可验证的计算问题。\n\n### 步骤 3：结论与行动\n该问题是**有效**的。将提供完整的解决方案。\n\n---\n\n### 基于原理的解决方案\n解决方案主要分三个阶段进行：首先，推导定义了目标性能的贝叶斯最优去噪器；其次，将校准过程表述为一个二次优化问题；第三，使用蒙特卡洛模拟对所有量进行经验估计。\n\n#### 1. 贝叶斯最优去噪器的推导\n由于数据是独立同分布的，目标是计算单个分量的条件期望 $\\eta_{\\mathrm{Bayes}}(y_i) = \\mathbb{E}[x_i \\mid y_i]$。$x_i$ 的先验是狄拉克δ函数在零点和高斯分布的混合：$p(x_i) = (1-\\rho)\\delta_0(x_i) + \\rho \\mathcal{N}(x_i; 0, \\sigma_x^2)$。似然函数为 $p(y_i \\mid x_i) = \\mathcal{N}(y_i; x_i, \\tau^2)$。\n\n条件期望由全期望定律给出：\n$$\n\\mathbb{E}[x_i \\mid y_i] = \\mathbb{E}[x_i \\mid y_i, x_i=0]P(x_i=0 \\mid y_i) + \\mathbb{E}[x_i \\mid y_i, x_i\\neq 0]P(x_i\\neq 0 \\mid y_i)\n$$\n第一项为零。设 $\\pi(y_i) = P(x_i \\neq 0 \\mid y_i)$ 为分量非零的后验概率。表达式简化为：\n$$\n\\eta_{\\mathrm{Bayes}}(y_i) = \\pi(y_i) \\mathbb{E}[x_i \\mid y_i, x_i\\neq 0]\n$$\n\n我们首先使用贝叶斯法则计算 $\\pi(y_i)$：\n$$\n\\pi(y_i) = \\frac{p(y_i \\mid x_i \\neq 0) P(x_i \\neq 0)}{p(y_i \\mid x_i \\neq 0) P(x_i \\neq 0) + p(y_i \\mid x_i = 0) P(x_i=0)}\n$$\n边缘似然为：\n-   如果 $x_i=0$，则 $y_i = \\tau Z_i$，所以 $p(y_i \\mid x_i=0) = \\mathcal{N}(y_i; 0, \\tau^2)$。\n-   如果 $x_i \\neq 0$，$x_i \\sim \\mathcal{N}(0, \\sigma_x^2)$。观测值 $y_i = x_i + \\tau Z_i$ 是两个独立高斯变量的和，因此 $y_i \\sim \\mathcal{N}(0, \\sigma_x^2 + \\tau^2)$。所以，$p(y_i \\mid x_i \\neq 0) = \\mathcal{N}(y_i; 0, \\sigma_x^2+\\tau^2)$。\n\n将这些代入 $\\pi(y_i)$ 的表达式中得到：\n$$\n\\pi(y_i) = \\frac{\\rho \\mathcal{N}(y_i; 0, \\sigma_x^2+\\tau^2)}{(1-\\rho)\\mathcal{N}(y_i; 0, \\tau^2) + \\rho \\mathcal{N}(y_i; 0, \\sigma_x^2+\\tau^2)} = \\left( 1 + \\frac{1-\\rho}{\\rho} \\frac{\\mathcal{N}(y_i; 0, \\tau^2)}{\\mathcal{N}(y_i; 0, \\sigma_x^2+\\tau^2)} \\right)^{-1}\n$$\n高斯概率密度函数（PDF）之比计算为：\n$$\n\\frac{\\mathcal{N}(y_i; 0, \\tau^2)}{\\mathcal{N}(y_i; 0, \\sigma_x^2+\\tau^2)} = \\sqrt{\\frac{\\sigma_x^2+\\tau^2}{\\tau^2}} \\exp\\left(-\\frac{y_i^2}{2}\\left(\\frac{1}{\\tau^2} - \\frac{1}{\\sigma_x^2+\\tau^2}\\right)\\right) = \\sqrt{1+\\frac{\\sigma_x^2}{\\tau^2}} \\exp\\left(\\frac{-y_i^2 \\sigma_x^2}{2\\tau^2(\\sigma_x^2+\\tau^2)}\\right)\n$$\n\n接下来，我们计算条件均值 $\\mathbb{E}[x_i \\mid y_i, x_i\\neq 0]$。这是一个标准的高斯推断问题。后验分布 $p(x_i \\mid y_i, x_i\\neq 0)$ 正比于似然函数与活跃先验的乘积：$p(x_i \\mid y_i, x_i\\neq 0) \\propto \\mathcal{N}(y_i; x_i, \\tau^2)\\mathcal{N}(x_i; 0, \\sigma_x^2)$。这是一个高斯分布，其均值是著名的维纳滤波器估计：\n$$\n\\mathbb{E}[x_i \\mid y_i, x_i\\neq 0] = \\frac{\\sigma_x^2}{\\sigma_x^2+\\tau^2} y_i\n$$\n结合这些结果，得到贝叶斯最优去噪器的最终形式：\n$$\n\\eta_{\\mathrm{Bayes}}(y_i) = \\pi(y_i) \\left( \\frac{\\sigma_x^2}{\\sigma_x^2+\\tau^2} y_i \\right)\n$$\n然后通过生成 $x$ 和 $Z$ 的样本，构成 $y$，计算 $\\eta_{\\mathrm{Bayes}}(y)$，并对平方误差求平均，来经验估计目标 MSE $\\mathrm{MSE}_{\\text{target}}$：$\\mathrm{MSE}_{\\text{target}} \\approx \\frac{1}{n}\\sum_{i=1}^n (\\eta_{\\mathrm{Bayes}}(y_i) - x_i)^2$。\n\n#### 2. 归一化因子 $\\alpha$ 的校准\n给定一个即插即用去噪器 $D(y)$，我们的目标是找到一个标量 $\\alpha$，使得 $\\eta_\\alpha(y) = \\alpha D(y)$ 的 MSE 与目标 MSE 相匹配。$\\eta_\\alpha(y)$ 的 MSE 是：\n$$\n\\mathrm{MSE}(\\alpha) = \\mathbb{E}\\left[(\\alpha D(y) - x)^2\\right] = \\alpha^2 \\mathbb{E}[D(y)^2] - 2\\alpha \\mathbb{E}[x D(y)] + \\mathbb{E}[x^2]\n$$\n让我们基于蒙特卡洛样本定义期望的经验估计：\n-   $A = \\frac{1}{n} \\sum_{i=1}^n D(y_i)^2$\n-   $B = \\frac{1}{n} \\sum_{i=1}^n x_i D(y_i)$\n-   $C = \\frac{1}{n} \\sum_{i=1}^n x_i^2$\n\n校准目标变成了求解关于 $\\alpha$ 的二次方程：\n$$\nA \\alpha^2 - 2B \\alpha + C = \\mathrm{MSE}_{\\text{target}} \\quad \\implies \\quad A \\alpha^2 - 2B \\alpha + (C - \\mathrm{MSE}_{\\text{target}}) = 0\n$$\n这是一个关于 $\\alpha$ 的标准二次方程。当且仅当判别式非负时，存在实数解：\n$$\n\\Delta = (-2B)^2 - 4A(C - \\mathrm{MSE}_{\\text{target}}) = 4(B^2 - AC + A \\cdot \\mathrm{MSE}_{\\text{target}}) \\ge 0\n$$\n这个条件等价于 $\\mathrm{MSE}_{\\text{target}} \\ge C - B^2/A$。项 $C - B^2/A$ 是去噪器族 $\\alpha D(y)$ 可实现的最小 MSE，在 $\\alpha = B/A$ 时取得。因此，当且仅当目标 MSE 不低于所选去噪器可实现的最小 MSE 时，校准才可能。\n\n如果 $\\Delta \\ge 0$，$\\alpha$ 的两个解是：\n$$\n\\alpha = \\frac{2B \\pm \\sqrt{\\Delta}}{2A} = \\frac{B \\pm \\sqrt{B^2 - A(C - \\mathrm{MSE}_{\\text{target}})}}{A}\n$$\n在没有进一步约束的情况下，一个合理的启发式方法是选择绝对值较小的 $\\alpha$ 解，代表最小的校正。\n\n一旦找到 $\\alpha$，达到的 MSE 计算为 $\\mathrm{MSE}_{\\text{achieved}} = A\\alpha^2 - 2B\\alpha + C$。如果 $|\\mathrm{MSE}_{\\text{achieved}} - \\mathrm{MSE}_{\\text{target}}| \\le \\varepsilon$，则认为校准成功。根据构造，如果通过解二次方程找到了实数 $\\alpha$，这个条件将在浮点精度内成立。主要的失效模式是负判别式。\n\n一个特殊情况是退化零去噪器，$D(y) \\equiv 0$。这里，$A = \\mathbb{E}[D(y)^2] = 0$ 且 $B = \\mathbb{E}[x D(y)] = 0$。MSE 变得与 $\\alpha$ 无关：$\\mathrm{MSE}(\\alpha) = \\mathbb{E}[x^2] = C$。只有当这个固定的 MSE 值恰好接近目标值时，即 $|C - \\mathrm{MSE}_{\\text{target}}| \\le \\varepsilon$，校准才可能。\n\n#### 3. 算法实现\n程序将为每个测试案例实现此逻辑。固定的随机种子确保确定性。所有计算都使用 `numpy` 以提高效率。最终输出是一个布尔值列表，指示每个案例的校准成功情况。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the denoiser calibration problem for the given test cases.\n    \"\"\"\n    np.random.seed(0)\n\n    test_cases = [\n        {'n': 100000, 'rho': 1.0, 'sigma_x': 1.0, 'tau': 0.5, 'denoiser': 'linear', 's': 0.7, 'eps': 1e-4, 'gamma': 0.5},\n        {'n': 100000, 'rho': 0.05, 'sigma_x': 2.0, 'tau': 0.3, 'denoiser': 'soft', 's': 0.8, 'eps': 2e-2, 'gamma': 0.5},\n        {'n': 100000, 'rho': 0.2, 'sigma_x': 1.0, 'tau': 1.0, 'denoiser': 'zero', 's': 1.0, 'eps': 1e-4, 'gamma': 0.5},\n        {'n': 100000, 'rho': 0.2, 'sigma_x': 1.5, 'tau': 0.4, 'denoiser': 'nh_saturating', 's': 1.2, 'eps': 3e-2, 'gamma': 0.5},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # Unpack parameters\n        n = case['n']\n        rho = case['rho']\n        sigma_x = case['sigma_x']\n        tau = case['tau']\n        denoiser_type = case['denoiser']\n        s = case['s']\n        eps = case['eps']\n        gamma = case['gamma']\n\n        # 1. Generate data from the Bernoulli-Gaussian model\n        support = np.random.binomial(1, rho, n).astype(float)\n        active_components = np.random.normal(0, sigma_x, n)\n        x = support * active_components\n        Z = np.random.normal(0, 1, n)\n        y = x + tau * Z\n\n        # 2. Compute the Bayes-optimal denoiser and target MSE\n        if rho == 0:\n            x_hat_bayes = np.zeros_like(y)\n        elif rho == 1:\n            # Pure Gaussian case (Wiener filter)\n            x_hat_bayes = (sigma_x**2 / (sigma_x**2 + tau**2)) * y\n        else:\n            # Full Bernoulli-Gaussian case\n            var_sum = sigma_x**2 + tau**2\n            ratio_std = np.sqrt(var_sum / tau**2)\n            exp_term_arg = -y**2 * sigma_x**2 / (2 * tau**2 * var_sum)\n             # Add a small constant to prevent division by zero for rho\n            pi = 1.0 / (1.0 + ((1.0 - rho) / rho) * ratio_std * np.exp(exp_term_arg))\n            post_mean_active = (sigma_x**2 / var_sum) * y\n            x_hat_bayes = pi * post_mean_active\n        \n        mse_target = np.mean((x_hat_bayes - x)**2)\n\n        # 3. Define and apply the plug-and-play denoiser\n        d_y = None\n        if denoiser_type == 'linear':\n            a_lin = sigma_x**2 / (sigma_x**2 + (s * tau)**2)\n            d_y = a_lin * (s * y)\n        elif denoiser_type == 'soft':\n            sy = s * y\n            threshold = 2 * s * tau\n            d_y = np.sign(sy) * np.maximum(np.abs(sy) - threshold, 0)\n        elif denoiser_type == 'nh_saturating':\n            sy = s * y\n            d_y = sy * np.exp(-gamma * np.abs(sy) / (s * tau))\n        elif denoiser_type == 'zero':\n            d_y = np.zeros(n)\n        \n        # 4. Calibrate alpha and check for success\n        success = False\n        if denoiser_type == 'zero':\n            mse_achieved = np.mean(x**2)\n            if np.abs(mse_achieved - mse_target) = eps:\n                success = True\n        else:\n            A_hat = np.mean(d_y**2)\n            B_hat = np.mean(x * d_y)\n            C_hat = np.mean(x**2)\n\n            if A_hat == 0:\n                # Should not happen for non-zero denoisers with this setup, but is a failure\n                success = False\n            else:\n                # Solve A*alpha^2 - 2*B*alpha + (C - MSE_target) = 0\n                C_prime = C_hat - mse_target\n                discriminant = (2 * B_hat)**2 - 4 * A_hat * C_prime\n\n                if discriminant >= 0:\n                    # A solution exists, so calibration is possible\n                    sqrt_discriminant = np.sqrt(discriminant)\n                    alpha1 = (2 * B_hat + sqrt_discriminant) / (2 * A_hat)\n                    alpha2 = (2 * B_hat - sqrt_discriminant) / (2 * A_hat)\n\n                    # Choose the solution with the smaller absolute value\n                    alpha_sol = alpha1 if np.abs(alpha1)  np.abs(alpha2) else alpha2\n                    \n                    # Calculate achieved MSE and check against tolerance\n                    mse_achieved = A_hat * alpha_sol**2 - 2 * B_hat * alpha_sol + C_hat\n                    if np.abs(mse_achieved - mse_target) = eps:\n                        success = True\n                else:\n                    # No real solution for alpha, calibration fails\n                    success = False\n        \n        results.append(success)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "除了预测算法的性能，状态演化（State Evolution, SE）理论还是分析AMP算法稳定性的强大数学工具。在实际应用中，噪声可能不完全是高斯分布，而是具有更重的“尾部”（heavy tails）。这个练习将引导您深入理论层面，通过线性化SE方程，分析一个稳健的M估计去噪器在不同噪声模型（高斯噪声与拉普拉斯噪声）下的稳定性边界，从而揭示去噪器设计与噪声统计特性如何共同决定算法的基本工作极限。",
            "id": "3443729",
            "problem": "考虑近似消息传递（AMP）算法在压缩感知中的一次迭代，其中可分离的坐标级去噪器 $\\,\\eta(\\cdot)\\,$ 应用于等效标量信道 $\\,R = X_0 + \\tau Z\\,$，其中 $\\,X_0\\,$ 是真实信号分量，$\\,\\tau \\ge 0\\,$ 是由状态演化（SE）预测的等效噪声标准差，而 $\\,Z\\,$ 是一个零均值、对称的噪声变量。假设欠采样率 $\\,\\delta \\in (0,1)\\,$ 且测量噪声方差为零。等效噪声方差的 SE 递推公式为\n$$\n\\tau_{t+1}^2 \\;=\\; \\frac{1}{\\delta}\\,\\mathbb{E}\\!\\left[\\bigl(\\eta\\!\\left(X_0+\\tau_t Z\\right) - X_0\\bigr)^2\\right],\n$$\n其中期望是关于 $\\,X_0\\,$ 和 $\\,Z\\,$ 的联合分布计算的。为了分离出去噪器的噪声整形行为，考虑零信号情况 $\\,X_0 \\equiv 0\\,$，此时 SE 递推简化为\n$$\n\\tau_{t+1}^2 \\;=\\; \\frac{1}{\\delta}\\,\\mathbb{E}\\!\\left[\\eta\\!\\left(\\tau_t Z\\right)^2\\right].\n$$\n通过 Huber 收缩构造一个稳健的 M 估计去噪器，其影响函数为 $\\,\\psi(u) = \\min(u,\\kappa)\\,$（对于 $\\,u \\ge 0\\,$）且参数 $\\,\\kappa0\\,$，并定义\n$$\n\\eta(x) \\;=\\; \\mathrm{sign}(x)\\,\\max\\!\\bigl(|x| - \\lambda\\,\\psi(|x|),\\,0\\bigr), \\quad \\lambda0.\n$$\n当 $\\,\\lambda \\in (0,1)\\,$ 时，关注不动点 $\\,\\tau=0\\,$ 在 SE 映射下的局部稳定性。对于小的 $\\,\\tau\\,$，通过对 $\\,\\tau^2\\,$ 进行线性化来分析 SE 映射，并将临界欠采样率 $\\,\\delta_c\\,$ 定义为 $\\,\\tau=0\\,$ 从稳定过渡到不稳定的那个值（即线性化的斜率为 1）。\n\n设 $\\,Z_L\\,$ 是一个拉普拉斯（双指数）随机变量，其密度为 $\\,f_{Z_L}(z) = \\tfrac{1}{2b}\\exp(-|z|/b)\\,$，尺度为 $\\,b0\\,$；设 $\\,Z_G\\,$ 为标准高斯变量。分别用 $\\,\\delta_c^{L}\\,$ 和 $\\,\\delta_c^{G}\\,$ 表示对于 $\\,Z_L\\,$ 和 $\\,Z_G\\,$，使用上述去噪器从 $\\,\\tau=0\\,$ 处的 SE 线性化得到的相应临界欠采样率。\n\n计算比率\n$$\nR(b) \\;=\\; \\frac{\\delta_c^{L}}{\\delta_c^{G}}\n$$\n结果表示为关于 $\\,b\\,$ 的闭式解析表达式。你的最终答案必须是 $\\,R(b)\\,$ 的简化解析表达式。不需要进行数值取整。",
            "solution": "该问题要求计算比率 $R(b) = \\frac{\\delta_c^{L}}{\\delta_c^{G}}$，其中 $\\delta_c^{L}$ 和 $\\delta_c^{G}$ 分别是在拉普拉斯和高斯噪声统计下，状态演化（SE）映射的不动点 $\\tau=0$ 保持稳定时的临界欠采样率。\n\n在零信号情况（$X_0 \\equiv 0$）下，等效噪声方差 $\\tau^2$ 的 SE 递推公式由下式给出：\n$$\n\\tau_{t+1}^2 = \\frac{1}{\\delta}\\,\\mathbb{E}\\!\\left[\\eta\\!\\left(\\tau_t Z\\right)^2\\right]\n$$\n该方程定义了等效噪声标准差平方的迭代映射，我们可以将其写为 $\\tau_{t+1}^2 = F(\\tau_t^2)$，其中函数 $F$ 定义为 $F(v) = \\frac{1}{\\delta}\\mathbb{E}\\!\\left[\\eta\\!\\left(\\sqrt{v} Z\\right)^2\\right]$（对于 $v \\ge 0$）。\n\n不动点在 $\\tau=0$（或 $v=0$）处的稳定性由函数 $F(v)$ 在 $v=0$ 处的斜率决定。临界欠采样率 $\\delta_c$ 是使该斜率恰好为 1 的 $\\delta$ 值。斜率 $S$ 由 $F(v)$ 在 $v=0$ 处的导数给出：\n$$\nS = \\frac{dF}{dv}\\bigg|_{v=0} = \\lim_{v \\to 0^+} \\frac{F(v) - F(0)}{v - 0}\n$$\n由于 $\\eta(0)=0$，我们有 $F(0)=0$。此外，令 $v=\\tau^2$，当 $v \\to 0^+$ 时，我们有 $\\tau \\to 0^+$。因此，斜率为：\n$$\nS = \\lim_{\\tau \\to 0^+} \\frac{\\frac{1}{\\delta}\\mathbb{E}\\!\\left[\\eta\\!\\left(\\tau Z\\right)^2\\right]}{\\tau^2} = \\frac{1}{\\delta} \\lim_{\\tau \\to 0^+} \\mathbb{E}\\!\\left[\\left(\\frac{\\eta(\\tau Z)}{\\tau}\\right)^2\\right]\n$$\n为了计算这个极限，我们首先分析去噪器 $\\eta(x)$ 在自变量 $x$ 很小的时候的行为。去噪器定义为：\n$$\n\\eta(x) = \\mathrm{sign}(x)\\,\\max\\!\\bigl(|x| - \\lambda\\,\\psi(|x|),\\,0\\bigr)\n$$\n其中影响函数为 $\\psi(u) = \\min(u, \\kappa)$（对于 $u \\ge 0$），且参数满足 $\\lambda \\in (0,1)$ 和 $\\kappa0$。\n对于小的 $x$ 使得 $|x|  \\kappa$，影响函数为 $\\psi(|x|) = |x|$。将此代入 $\\eta(x)$ 的表达式中：\n$$\n\\eta(x) = \\mathrm{sign}(x)\\,\\max\\!\\bigl(|x| - \\lambda|x|,\\,0\\bigr) = \\mathrm{sign}(x)\\,\\max\\!\\bigl((1-\\lambda)|x|,\\,0\\bigr)\n$$\n因为给定 $\\lambda \\in (0,1)$，所以项 $1-\\lambda$ 是正的。因此，对于任何满足 $|x|\\kappa$ 的非零 $x$，我们有 $(1-\\lambda)|x|0$。这可将表达式简化为：\n$$\n\\eta(x) = \\mathrm{sign}(x)(1-\\lambda)|x| = (1-\\lambda)x, \\quad \\text{for } |x|\\kappa\n$$\n这表明在 $x=0$ 的一个邻域内，去噪器 $\\eta(x)$ 是一个斜率为 $(1-\\lambda)$ 的线性函数。因此，在原点的导数为 $\\eta'(0) = 1-\\lambda$。\n\n现在我们回到斜率 $S$ 的极限。对于随机变量 $Z=z$ 的任何固定值，当 $\\tau \\to 0$ 时，自变量 $\\tau z$ 最终将落入 $|\\tau z|   \\kappa$ 的区域。因此，我们可以在期望内部计算极限：\n$$\n\\lim_{\\tau \\to 0^+} \\frac{\\eta(\\tau z)}{\\tau} = z \\cdot \\lim_{\\tau \\to 0^+} \\frac{\\eta(\\tau z)}{\\tau z} = z \\cdot \\eta'(0) = z(1-\\lambda)\n$$\n我们可以根据控制收敛定理交换极限和期望。这需要一个控制函数。我们可以证明对于所有 $x$，都有 $|\\eta(x)| \\le |x|$。当 $|x|  \\kappa$ 时，由于 $\\lambda \\in (0,1)$，有 $|\\eta(x)| = |(1-\\lambda)x| \\le |x|$。当 $|x| \\ge \\kappa$ 时，有 $|\\eta(x)| = \\max(|x|-\\lambda\\kappa, 0) \\le |x|$。因此， $|\\eta(\\tau z)| \\le |\\tau z|$，这意味着 $\\left(\\frac{\\eta(\\tau z)}{\\tau}\\right)^2 \\le z^2$。由于高斯分布和拉普拉斯分布的 $\\mathbb{E}[Z^2]$ 都是有限的，函数 $g(Z)=Z^2$ 可以作为随机变量 $\\left(\\frac{\\eta(\\tau Z)}{\\tau}\\right)^2$ 的一个合适的控制函数。\n\n因此，斜率 $S$ 为：\n$$\nS = \\frac{1}{\\delta} \\mathbb{E}\\!\\left[\\left( Z(1-\\lambda) \\right)^2\\right] = \\frac{(1-\\lambda)^2}{\\delta} \\mathbb{E}[Z^2]\n$$\n临界欠采样率 $\\delta_c$ 可通过将斜率 $S$ 设为 1 来求得：\n$$\n1 = \\frac{(1-\\lambda)^2}{\\delta_c} \\mathbb{E}[Z^2] \\implies \\delta_c = (1-\\lambda)^2 \\mathbb{E}[Z^2]\n$$\n这个 $\\delta_c$ 的表达式取决于噪声分布 $Z$ 的二阶矩。我们现在为指定的两种情况计算这个值。\n\n情况 1：标准高斯噪声（$Z_G$）\n对于一个标准高斯随机变量 $Z_G \\sim N(0,1)$，其均值为 $\\mathbb{E}[Z_G] = 0$，方差为 $\\mathrm{Var}(Z_G) = 1$。其二阶矩为：\n$$\n\\mathbb{E}[Z_G^2] = \\mathrm{Var}(Z_G) + (\\mathbb{E}[Z_G])^2 = 1 + 0^2 = 1\n$$\n对应的临界欠采样率为：\n$$\n\\delta_c^{G} = (1-\\lambda)^2 \\cdot 1 = (1-\\lambda)^2\n$$\n\n情况 2：拉普拉斯噪声（$Z_L$）\n拉普拉斯随机变量 $Z_L$ 的概率密度函数为 $f_{Z_L}(z) = \\frac{1}{2b}\\exp(-|z|/b)$（对于 $z \\in \\mathbb{R}$），尺度参数 $b0$。由于其密度函数关于 $z=0$ 对称，所以均值为 $\\mathbb{E}[Z_L] = 0$。其二阶矩即为方差：\n$$\n\\mathbb{E}[Z_L^2] = \\int_{-\\infty}^{\\infty} z^2 f_{Z_L}(z) dz = \\int_{-\\infty}^{\\infty} z^2 \\frac{1}{2b}\\exp\\left(-\\frac{|z|}{b}\\right) dz\n$$\n被积函数是一个偶函数，因此我们可以简化积分为：\n$$\n\\mathbb{E}[Z_L^2] = 2 \\int_{0}^{\\infty} z^2 \\frac{1}{2b}\\exp\\left(-\\frac{z}{b}\\right) dz = \\frac{1}{b} \\int_{0}^{\\infty} z^2 \\exp\\left(-\\frac{z}{b}\\right) dz\n$$\n我们使用换元法，令 $t = z/b$，这意味着 $z=bt$ 且 $dz=b\\,dt$。\n$$\n\\mathbb{E}[Z_L^2] = \\frac{1}{b} \\int_{0}^{\\infty} (bt)^2 \\exp(-t) (b\\,dt) = \\frac{b^3}{b} \\int_{0}^{\\infty} t^2 \\exp(-t) dt = b^2 \\int_{0}^{\\infty} t^{3-1} \\exp(-t) dt\n$$\n该积分是伽马函数的定义 $\\Gamma(s) = \\int_0^\\infty t^{s-1} e^{-t} dt$，其中 $s=3$。我们有 $\\Gamma(3) = (3-1)! = 2! = 2$。\n因此，拉普拉斯分布的二阶矩为：\n$$\n\\mathbb{E}[Z_L^2] = b^2 \\cdot \\Gamma(3) = 2b^2\n$$\n对应的临界欠采样率为：\n$$\n\\delta_c^{L} = (1-\\lambda)^2 \\cdot \\mathbb{E}[Z_L^2] = (1-\\lambda)^2 (2b^2)\n$$\n\n最后，我们计算所要求的比率 $R(b)$：\n$$\nR(b) = \\frac{\\delta_c^{L}}{\\delta_c^{G}} = \\frac{(1-\\lambda)^2 (2b^2)}{(1-\\lambda)^2}\n$$\n由于 $\\lambda \\in (0,1)$，项 $(1-\\lambda)^2$ 非零，可以从分子和分母中约去。\n$$\nR(b) = 2b^2\n$$\n结果与去噪器参数 $\\lambda$ 和 $\\kappa$ 无关，因为它们对原点处导数 $\\eta'(0)$ 的影响是一个对 $\\delta_c^L$ 和 $\\delta_c^G$ 而言公共的乘法因子。",
            "answer": "$$\n\\boxed{2b^2}\n$$"
        }
    ]
}