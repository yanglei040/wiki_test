{
    "hands_on_practices": [
        {
            "introduction": "近似消息传递（AMP）算法是在密集图上对环路信念传播（loopy Belief Propagation, BP）进行高斯近似的结果，但它的实际吸引力很大程度上源于其计算效率。本练习旨在量化AMP相对于朴素BP实现在计算成本上的巨大优势。通过这个计算，您将深刻理解为什么AMP能够成为解决大规模问题的实用且强大的工具。",
            "id": "3438006",
            "problem": "考虑压缩感知中的标准线性观测模型，由 $y = A x + w$ 给出，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个稠密感知矩阵，$x \\in \\mathbb{R}^{n}$ 是一个具有可分先验的未知信号，$w \\in \\mathbb{R}^{m}$ 是加性高斯白噪声。其对应的因子图是二分图，包含 $m$ 个测量因子节点（索引为 $a \\in \\{1,\\ldots,m\\}$）和 $n$ 个变量节点（索引为 $i \\in \\{1,\\ldots,n\\}$），其中每个因子节点都连接到每个变量节点（即，该图是具有 $mn$ 条边的完全二分图）。\n\n在该图上，朴素的有环置信度传播（BP）（和积算法）在每次迭代中沿每条边发送两条有向消息：一条变量到因子消息和一条因子到变量消息。假设每条消息都在自然域中参数化，因此合并来自邻居的消息等同于对自然参数进行简单的标量加法。将一个单位的计算成本定义为一次标量邻居聚合（即，将一条传入的标量消息加到一个累加器中）。您可以忽略所有不随节点度变化的常数因子。\n\n1) 仅使用 BP 的基本规则，即每条边上的发出消息不包括来自该边的相应传入消息，而是聚合所有其他邻居的消息，计算朴素有环 BP 在此稠密图上每次迭代执行的标量邻居聚合的确切次数，作为 $m$ 和 $n$ 的函数。\n\n2) 近似消息传递（AMP）执行的每次迭代更新，可以通过与 $A$ 和 $A^{\\top}$ 进行恰好 $2$ 次稠密矩阵向量乘法来实现。在相同的单位成本模型下（沿一条边的一次标量乘加贡献算作一次聚合），AMP 的每次迭代成本恰好是 $2mn$ 次聚合。计算朴素有环 BP 和 AMP 每次迭代聚合次数之间的确切比率 $R(m,n)$。\n\n请以 $R(m,n)$ 的闭式表达式形式提供您的最终答案。无需四舍五入，也不涉及物理单位。请将您的最终答案表示为单个解析表达式。",
            "solution": "用户希望针对一个特定的压缩感知问题，找出朴素有环置信度传播（BP）与近似消息传递（AMP）每次迭代的计算成本之比。\n\n### 步骤 1：问题验证\n\n首先，我将提取给定信息并验证问题陈述。\n\n**提取的已知条件：**\n-   **模型：** 线性观测模型 $y = A x + w$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个稠密感知矩阵，$x \\in \\mathbb{R}^{n}$ 是具有可分先验的信号，$w \\in \\mathbb{R}^{m}$ 是加性高斯白噪声。\n-   **因子图：** 一个包含 $m$ 个因子节点和 $n$ 个变量节点的完全二分图。这意味着每个因子节点都连接到每个变量节点。\n-   **算法 1 (BP)：** 朴素的有环置信度传播（和积算法）。一次迭代包括沿 $mn$ 条边中的每一条计算两条消息（变量到因子和因子到变量）。\n-   **BP 更新规则：** 一条边上的发出消息是通过聚合来自所有其他邻居节点的消息计算得出的，不包括通过目标边连接的那个节点。\n-   **算法 2 (AMP)：** 近似消息传递。其更新可以通过与 $A$ 和 $A^{\\top}$ 进行恰好 $2$ 次稠密矩阵向量乘法来实现。\n-   **成本模型：**\n    -   计算成本的单位被定义为一次“标量邻居聚合”，即“将一条传入的标量消息加到一个累加器中”。\n    -   对于 BP，消息被参数化，使得组合等同于参数的标量加法。\n    -   对于 AMP，成本模型被指定为“沿一条边的一次标量乘加贡献算作一次聚合”。\n    -   AMP 的每次迭代总成本明确给出为 $2mn$ 次聚合。\n-   **目标：** 计算比率 $R(m,n) = \\frac{\\text{Cost}_{\\text{BP}}}{\\text{Cost}_{\\text{AMP}}}$。\n\n**验证：**\n1.  **科学依据：** 该问题设置在压缩感知和图形模型这一成熟领域。稠密图上的有环 BP 与 AMP 算法之间的关系是现代统计信号处理中的一个基本课题。模型和算法都是标准的。\n2.  **适定性：** 该问题提供了明确的目标和一套定义（图结构、算法、成本度量），足以推导出唯一的解析解。\n3.  **客观性：** 语言正式、精确，不含主观内容。\n\n问题陈述指出，信号模型涉及 $x \\in \\mathbb{R}^n$ 和高斯噪声，这通常意味着 BP 消息将是高斯分布，每个分布由两个标量（例如均值和方差）参数化。然而，成本单位被定义为“一条传入的**标量消息**的加法”。虽然这看起来可能有些矛盾，但一个有效的解释是，为了进行这种理想化的计算成本分析，该问题有意将消息结构简化为单个标量。这是理论练习中为了关注标度律而采取的常见做法。问题陈述中用于计算的具体规则优先于背景知识。在这种解释下，该问题是自洽且可解的。\n\n**结论：** 问题有效。我将继续进行求解。\n\n### 步骤 2：求解推导\n\n求解过程需要根据提供的成本模型计算朴素有环 BP 的每次迭代成本，然后将其除以给定的 AMP 成本。\n\n**第 1 部分：朴素有环 BP 的计算成本 ($C_{\\text{BP}}$)**\n\n在此图上，一次有环 BP 的迭代包括更新所有变量到因子消息和所有因子到变量消息。该图是一个具有 $mn$ 条边的完全二分图。\n\n**A. 变量到因子（V-to-F）消息的成本：**\n-   考虑单个变量节点 $x_i$，其中 $i \\in \\{1, \\ldots, n\\}$。在完全二分图中，它连接到所有 $m$ 个因子节点。\n-   为了计算从变量节点 $x_i$ 到特定因子节点 $f_a$ 的发出消息，BP 规则要求聚合来自所有其他因子节点（即 $\\{f_b\\}_{b \\neq a}$）的传入消息。\n-   需要聚合的此类邻居数量为 $m-1$。\n-   成本单位是每次传入消息进行一次标量聚合。因此，计算一条 V-to-F 消息的成本是 $m-1$ 个单位。\n-   共有 $n$ 个变量节点，每个节点向所有 $m$ 个因子节点发送消息。V-to-F 消息的总数为 $nm$。\n-   在一次迭代中，所有 V-to-F 消息的总成本是消息数量与每条消息成本的乘积：\n$$ C_{\\text{V-to-F}} = (\\text{消息数量}) \\times (\\text{每条消息的成本}) = (nm) \\times (m-1) $$\n\n**B. 因子到变量（F-to-V）消息的成本：**\n-   考虑单个因子节点 $f_a$，其中 $a \\in \\{1, \\ldots, m\\}$。在完全二分图中，它连接到所有 $n$ 个变量节点。\n-   为了计算从因子节点 $f_a$ 到特定变量节点 $x_i$ 的发出消息，BP 规则要求聚合来自所有其他变量节点（即 $\\{x_j\\}_{j \\neq i}$）的传入消息。\n-   需要聚合的此类邻居数量为 $n-1$。\n-   根据相同的成本模型，计算一条 F-to-V 消息的成本是 $n-1$ 个单位。\n-   共有 $m$ 个因子节点，每个节点向所有 $n$ 个变量节点发送消息。F-to-V 消息的总数为 $mn$。\n-   在一次迭代中，所有 F-to-V 消息的总成本是：\n$$ C_{\\text{F-to-V}} = (\\text{消息数量}) \\times (\\text{每条消息的成本}) = (mn) \\times (n-1) $$\n\n**C. BP 总成本：**\n-   朴素有环 BP 每次迭代的总成本是 V-to-F 和 F-to-V 消息更新成本的总和。\n$$ C_{\\text{BP}} = C_{\\text{V-to-F}} + C_{\\text{F-to-V}} = nm(m-1) + mn(n-1) $$\n-   提取公因式 $mn$：\n$$ C_{\\text{BP}} = mn \\left( (m-1) + (n-1) \\right) = mn(m+n-2) $$\n\n**第 2 部分：BP 成本与 AMP 成本之比, $R(m,n)$**\n\n问题陈述，在相同的单位成本模型下，AMP 的每次迭代成本为：\n$$ C_{\\text{AMP}} = 2mn $$\n\n比率 $R(m,n)$ 定义为朴素 BP 的成本除以 AMP 的成本。\n$$ R(m,n) = \\frac{C_{\\text{BP}}}{C_{\\text{AMP}}} = \\frac{mn(m+n-2)}{2mn} $$\n\n假设 $m \\ge 1$ 且 $n \\ge 1$，则 $mn$ 项非零，可以从分子和分母中约去。\n$$ R(m,n) = \\frac{m+n-2}{2} $$\n\n这个结果量化了 AMP 相对于稠密图上的朴素有环 BP 的显著计算优势。BP 的复杂度与 $m^2n + mn^2$ 成比例，而 AMP 实现了 $O(mn)$ 的复杂度。比率 $R(m,n)$ 随问题维度 $m$ 和 $n$ 线性增长。",
            "answer": "$$ \\boxed{\\frac{m+n-2}{2}} $$"
        },
        {
            "introduction": "AMP算法的理论基石是状态演化（State Evolution, SE），它精确地刻画了算法在大系统极限下的性能。本练习将引导您动手推导SE递归式及其不动点方程，展示如何利用这一强大工具来预测算法的渐近均方误差。通过处理一个先验不匹配的场景，您还将探索AMP的“普适性”及其在非理想条件下的稳健性。",
            "id": "3437997",
            "problem": "考虑一个压缩感知中的线性观测模型：测量向量 $y \\in \\mathbb{R}^{m}$ 由一个未知信号 $x_0 \\in \\mathbb{R}^{n}$ 通过 $y = A x_0 + w$ 生成，其中 $A \\in \\mathbb{R}^{m \\times n}$ 的元素 $A_{ij} \\sim \\mathcal{N}(0, 1/m)$ 是独立同分布的，噪声向量 $w \\in \\mathbb{R}^{m}$ 的元素 $w_i \\sim \\mathcal{N}(0, \\sigma_w^2)$ 是独立的，未知信号的分量是独立的，满足 $x_{0,i} \\sim \\mathcal{N}(0, \\sigma_x^2)$。设欠采样率为 $\\delta = m/n \\in (0, \\infty)$，其中 $m, n \\to \\infty$ 且 $\\delta$ 固定。\n\n近似消息传递 (Approximate Message Passing, AMP) 算法可以从该线性模型的稠密因子图上的置信传播 (Belief Propagation, BP) 推导得出，其中应用了中心极限定理 (Central Limit Theorem, CLT) 和对高维消息的高斯近似。具体来说，AMP 迭代的形式是在每次迭代中对一个等效标量信道 $u = x + \\tau z$ 进行可分离去噪，其中 $x \\sim \\mathcal{N}(0, \\sigma_x^2)$，$z \\sim \\mathcal{N}(0,1)$，并且 $\\tau^2$ 表示一个由称为状态演化的一维递归所预测的等效噪声方差。假设 AMP 算法使用一个失配的高斯先验 $\\mathcal{N}(0, \\sigma_q^2)$（而不是真实的 $\\mathcal{N}(0, \\sigma_x^2)$）来运行，因此，在等效噪声方差 $\\tau^2$ 下的标量去噪器被取为在先验 $\\mathcal{N}(0, \\sigma_q^2)$ 和观测模型 $u = x + \\tau z$ 下的后验均值。\n\n任务：\n1. 从稠密线性高斯模型上的 BP 公式出发，并仅使用 CLT 来证明对聚合消息的高斯近似的合理性，推导跟踪等效方差 $\\tau_t^2$ 的一维状态演化递归，该递归适用于由失配高斯先验导出的可分离标量去噪器 $\\eta(\\cdot; \\tau^2)$ 的 AMP 算法。你的推导应精确说明为什么在大系统极限下，AMP 在迭代 $t$ 时的误差分布如同一个标量高斯信道 $U = X + \\tau_t Z$，其中 $X \\sim \\mathcal{N}(0, \\sigma_x^2)$，$Z \\sim \\mathcal{N}(0,1)$ 相互独立；以及为什么下一次迭代的等效方差 $\\tau_{t+1}^2$ 是通过将此标量去噪器的均方误差与测量率 $\\delta$ 和测量噪声方差 $\\sigma_w^2$ 组合得到的。\n2. 对失配高斯先验 $\\mathcal{N}(0, \\sigma_q^2)$ 和标量观测模型 $u = x + \\tau z$ 使用贝叶斯法则，以 $u$、$\\sigma_q^2$ 和 $\\tau^2$ 的函数形式，推导后验均值去噪器 $\\eta(u; \\tau^2)$ 的闭式解。\n3. 结合第 1 部分和第 2 部分的结果，以闭式形式获得在无噪声情况 $\\sigma_w^2 = 0$ 下等效方差 $\\tau_{\\star}^2$ 的不动点方程，用 $\\delta$、$\\sigma_x^2$ 和 $\\sigma_q^2$ 表示。然后，具体到参数设置 $\\delta = 1$、$\\sigma_x^2 = 3$、$\\sigma_q^2 = 1$，计算 $\\tau_{\\star}^2$ 的严格为正的不动点值。\n\n你的最终答案必须是等于此不动点值的单个实数。不涉及单位。最终答案不要提供任何额外的评论。",
            "solution": "该问题要求推导失配近似消息传递 (AMP) 算法的状态演化，失配去噪器的具体形式，以及在特定参数集下计算所得递归的一个不动点。我们按要求分三部分进行。\n\n### 第 1 部分：状态演化递归的推导\n\n近似消息传递 (AMP) 算法为信号 `x_0` 提供了一个迭代估计 `x^t`。其在大系统极限（$m, n \\to \\infty$ 且 $m/n \\to \\delta$）下的行为被一个称为状态演化 (SE) 的标量递归精确刻画。该推导依赖于将许多弱相关随机变量的和近似为高斯分布，其合理性由中心极限定理 (CLT) 保证。\n\n状态演化的核心假设是，在每次迭代 $t$ 中，进入去噪函数的向量 `u^t` 的分量，在统计上等价于来自一个标量高斯信道的样本。具体来说，对于每个分量 $i \\in \\{1, \\dots, n\\}$，等效观测 $u_i^t$ 的分布如同 $u_i^t = x_{0,i} + \\tau_t z_i$，其中 $x_{0,i}$ 是真实的信号分量，$z_i \\sim \\mathcal{N}(0, 1)$ 是一个独立于 $x_{0,i}$ 的标准高斯随机变量，而 $\\tau_t^2$ 是在迭代 $t$ 时的等效噪声方差。信号分量 $x_{0,i}$ 是从 $\\mathcal{N}(0, \\sigma_x^2)$ 中抽取的独立同分布样本。\n\n估计 $x^{t+1}$ 的 AMP 更新通过将标量去噪函数 $\\eta(\\cdot; \\tau_t^2)$ 逐分量地应用于此等效观测得到：\n$$\nx_i^{t+1} = \\eta(u_i^t; \\tau_t^2) = \\eta(x_{0,i} + \\tau_t z_i; \\tau_t^2)\n$$\n状态演化递归描述了等效方差 $\\tau_t^2$ 如何从一次迭代演化到下一次。迭代 $t+1$ 中的噪声由迭代 $t+1$ 的残差构成。标准 AMP 算法包含一个“Onsager”修正项，它确保在每个阶段增加的等效噪声是渐近高斯且独立于信号的。可以严格证明，阶段 $t+1$ 的等效噪声与向量 $A^T z^{t+1}$ 相关，其中 $z^{t+1}$ 是一个类似残差的项。为我们的目的，我们将分析此项的统计特性。\n\n让我们将迭代 $t+1$ 的估计误差定义为 $d_i^{t+1} = x_i^{t+1} - x_{0,i} = \\eta(x_{0,i} + \\tau_t z_i; \\tau_t^2) - x_{0,i}$。则均方误差 (MSE) 由下式给出：\n$$\n\\text{MSE}(\\tau_t^2) = \\mathbb{E}[(d_i^{t+1})^2] = \\mathbb{E}_{X,Z}[(\\eta(X + \\tau_t Z; \\tau_t^2) - X)^2]\n$$\n其中期望是关于 $X \\sim \\mathcal{N}(0, \\sigma_x^2)$ 和 $Z \\sim \\mathcal{N}(0, 1)$ 计算的。\n\n下一个等效噪声方差 $\\tau_{t+1}^2$ 是向量 $A^T(y - Ax^{t+1})$ 的分量的方差。我们来分析向量 $v^{t+1} = y - Ax^{t+1}$。代入 $y = Ax_0 + w$：\n$$\nv^{t+1} = A x_0 + w - A x^{t+1} = A(x_0 - x^{t+1}) + w = -A d^{t+1} + w\n$$\n该向量的一个分量 $v_j^{t+1}$ 由下式给出：\n$$\nv_j^{t+1} = -\\sum_{k=1}^n A_{jk} d_k^{t+1} + w_j\n$$\n在大系统极限下，项 $d_k^{t+1}$ 是独立同分布的随机变量（根据 SE 假设），其均值为 $\\mathbb{E}[d_k^{t+1}]$，方差为 $\\text{MSE}(\\tau_t^2)$。元素 $A_{jk}$ 是独立同分布的 $\\mathcal{N}(0, 1/m)$。项 $\\sum_{k=1}^n A_{jk} d_k^{t+1}$ 是 $n$ 个独立同分布随机变量的和。根据 CLT，这个和收敛到一个高斯随机变量。其方差为：\n$$\n\\text{Var}\\left(\\sum_{k=1}^n A_{jk} d_k^{t+1}\\right) = n \\cdot \\mathbb{E}[A_{jk}^2] \\cdot \\mathbb{E}[(d_k^{t+1})^2] = n \\cdot \\frac{1}{m} \\cdot \\text{MSE}(\\tau_t^2) = \\frac{1}{\\delta} \\text{MSE}(\\tau_t^2)\n$$\n（这里我们使用了 $\\mathbb{E}[d_k^{t+1}]$ 可以不失一般性地假设为零，这对于后验均值估计器是成立的）。由于 $w_j$ 独立于 $A$ 和 $d^{t+1}$，$v_j^{t+1}$ 的方差为：\n$$\n\\text{Var}(v_j^{t+1}) = \\text{Var}\\left(-\\sum_k A_{jk} d_k^{t+1}\\right) + \\text{Var}(w_j) = \\frac{1}{\\delta} \\text{MSE}(\\tau_t^2) + \\sigma_w^2\n$$\n下一次迭代的等效噪声，它决定了 $\\tau_{t+1}^2$，由向量 $h^{t+1} = A^T v^{t+1}$ 的分量给出。一个分量 $h_i^{t+1}$ 是：\n$$\nh_i^{t+1} = \\sum_{j=1}^m A_{ji} v_j^{t+1}\n$$\n再次，根据 CLT，由于 $v_j^{t+1}$ 是独立同分布的高斯变量，$h_i^{t+1}$ 也是高斯分布的。其方差是 $\\tau_{t+1}^2$：\n$$\n\\tau_{t+1}^2 = \\text{Var}(h_i^{t+1}) = \\sum_{j=1}^m \\mathbb{E}[A_{ji}^2] \\mathbb{E}[(v_j^{t+1})^2] = m \\cdot \\frac{1}{m} \\cdot \\text{Var}(v_j^{t+1}) = \\text{Var}(v_j^{t+1})\n$$\n因此，等效方差的状态演化递归是：\n$$\n\\tau_{t+1}^2 = \\sigma_w^2 + \\frac{1}{\\delta} \\mathbb{E}_{X,Z}[(\\eta(X + \\tau_t Z; \\tau_t^2) - X)^2]\n$$\n其中 $X \\sim \\mathcal{N}(0, \\sigma_x^2)$ 且 $Z \\sim \\mathcal{N}(0, 1)$。这解释了为什么下一次迭代的方差是测量噪声 $\\sigma_w^2$、测量率 $\\delta$ 和标量去噪器均方误差的函数。\n\n### 第 2 部分：失配高斯去噪器的推导\n\n去噪器 $\\eta(u; \\tau^2)$ 是在 $x$ 的先验为 $\\mathcal{N}(0, \\sigma_q^2)$ 的假设下，对于标量观测模型 $u = x + \\tau z$（其中 $z \\sim \\mathcal{N}(0,1)$）的后验均值 $\\mathbb{E}[x|u]$。\n似然是 $p(u|x) = \\mathcal{N}(u|x, \\tau^2)$，先验是 $p(x) = \\mathcal{N}(x|0, \\sigma_q^2)$。\n使用贝叶斯法则，后验分布 $p(x|u)$ 正比于似然和先验的乘积：\n$$\np(x|u) \\propto p(u|x) p(x) \\propto \\exp\\left(-\\frac{(u-x)^2}{2\\tau^2}\\right) \\exp\\left(-\\frac{x^2}{2\\sigma_q^2}\\right)\n$$\n我们分析指数部分，忽略不依赖于 $x$ 的项：\n$$\n-\\frac{1}{2}\\left(\\frac{u^2 - 2ux + x^2}{\\tau^2} + \\frac{x^2}{\\sigma_q^2}\\right) = -\\frac{1}{2}\\left(x^2\\left(\\frac{1}{\\tau^2} + \\frac{1}{\\sigma_q^2}\\right) - 2x\\frac{u}{\\tau^2}\\right) + \\text{const}\n$$\n这是一个关于 $x$ 的二次型，表明后验是高斯的，$p(x|u) = \\mathcal{N}(x|\\mu_{post}, \\sigma_{post}^2)$。后验方差 $\\sigma_{post}^2$ 从 $x^2$ 的系数中找到：\n$$\n\\frac{1}{\\sigma_{post}^2} = \\frac{1}{\\tau^2} + \\frac{1}{\\sigma_q^2} = \\frac{\\sigma_q^2+\\tau^2}{\\tau^2\\sigma_q^2} \\implies \\sigma_{post}^2 = \\frac{\\tau^2\\sigma_q^2}{\\sigma_q^2+\\tau^2}\n$$\n后验均值 $\\mu_{post}$ 通过匹配 $x$ 的线性项的系数找到：\n$$\n\\frac{\\mu_{post}}{\\sigma_{post}^2} = \\frac{u}{\\tau^2} \\implies \\mu_{post} = u \\frac{\\sigma_{post}^2}{\\tau^2} = u \\left(\\frac{\\tau^2\\sigma_q^2}{\\sigma_q^2+\\tau^2}\\right) \\frac{1}{\\tau^2} = \\frac{\\sigma_q^2}{\\sigma_q^2+\\tau^2} u\n$$\n因此，标量去噪器是线性收缩函数：\n$$\n\\eta(u; \\tau^2) = \\frac{\\sigma_q^2}{\\sigma_q^2 + \\tau^2} u\n$$\n\n### 第 3 部分：不动点方程与求解\n\n我们结合前两部分的结果来找到等效方差 $\\tau_\\star^2$ 的不动点方程。一个不动点满足 $\\tau_\\star^2 = \\tau_{t+1}^2 = \\tau_t^2$。\n当 $\\sigma_w^2 = 0$ 时，SE 递归为 $\\tau^2 = \\frac{1}{\\delta} \\text{MSE}(\\tau^2)$。我们来计算 MSE：\n$$\n\\text{MSE}(\\tau^2) = \\mathbb{E}[(\\eta(X + \\tau Z; \\tau^2) - X)^2]\n$$\n代入去噪器： $\\eta(X + \\tau Z; \\tau^2) = \\frac{\\sigma_q^2}{\\sigma_q^2 + \\tau^2}(X + \\tau Z)$。\n误差是：\n$$\n\\eta(X + \\tau Z; \\tau^2) - X = \\left(\\frac{\\sigma_q^2}{\\sigma_q^2 + \\tau^2} - 1\\right)X + \\frac{\\sigma_q^2 \\tau}{\\sigma_q^2 + \\tau^2} Z = -\\frac{\\tau^2}{\\sigma_q^2 + \\tau^2} X + \\frac{\\sigma_q^2 \\tau}{\\sigma_q^2 + \\tau^2} Z\n$$\n由于 $X \\sim \\mathcal{N}(0, \\sigma_x^2)$ 和 $Z \\sim \\mathcal{N}(0, 1)$ 是独立的，$\\mathbb{E}[XZ] = 0$。MSE 是这两项方差的和：\n$$\n\\text{MSE}(\\tau^2) = \\mathbb{E}\\left[\\left(-\\frac{\\tau^2}{\\sigma_q^2 + \\tau^2} X\\right)^2\\right] + \\mathbb{E}\\left[\\left(\\frac{\\sigma_q^2 \\tau}{\\sigma_q^2 + \\tau^2} Z\\right)^2\\right]\n$$\n$$\n\\text{MSE}(\\tau^2) = \\left(\\frac{\\tau^2}{\\sigma_q^2 + \\tau^2}\\right)^2 \\mathbb{E}[X^2] + \\left(\\frac{\\sigma_q^2 \\tau}{\\sigma_q^2 + \\tau^2}\\right)^2 \\mathbb{E}[Z^2]\n$$\n使用 $\\mathbb{E}[X^2]=\\sigma_x^2$ 和 $\\mathbb{E}[Z^2]=1$：\n$$\n\\text{MSE}(\\tau^2) = \\frac{(\\tau^2)^2 \\sigma_x^2 + (\\sigma_q^2)^2 \\tau^2}{(\\sigma_q^2 + \\tau^2)^2}\n$$\n不动点方程 $\\tau_\\star^2 = \\frac{1}{\\delta} \\text{MSE}(\\tau_\\star^2)$ 变为：\n$$\n\\tau_\\star^2 = \\frac{1}{\\delta} \\frac{(\\tau_\\star^2)^2 \\sigma_x^2 + (\\sigma_q^2)^2 \\tau_\\star^2}{(\\sigma_q^2 + \\tau_\\star^2)^2}\n$$\n对于一个严格为正的不动点 $\\tau_\\star^2 > 0$，我们可以除以 $\\tau_\\star^2$：\n$$\n1 = \\frac{1}{\\delta} \\frac{\\tau_\\star^2 \\sigma_x^2 + (\\sigma_q^2)^2}{(\\sigma_q^2 + \\tau_\\star^2)^2}\n$$\n$$\n\\delta (\\sigma_q^2 + \\tau_\\star^2)^2 = \\tau_\\star^2 \\sigma_x^2 + (\\sigma_q^2)^2\n$$\n现在我们代入给定的参数值：$\\delta = 1$，$\\sigma_x^2 = 3$ 和 $\\sigma_q^2 = 1$。令 $T = \\tau_\\star^2$：\n$$\n1 \\cdot (1 + T)^2 = T \\cdot 3 + 1^2\n$$\n$$\n1 + 2T + T^2 = 3T + 1\n$$\n$$\nT^2 - T = 0\n$$\n$$\nT(T-1) = 0\n$$\n$T = \\tau_\\star^2$ 的可能解是 $0$ 和 $1$。问题要求的是严格为正的不动点值。\n因此，严格为正的不动点是 $\\tau_\\star^2 = 1$。",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "尽管功能强大，AMP有时会表现出不稳定的行为，这与它所源于的环路信念传播算法的特性一脉相承。本练习通过对状态演化映射进行线性化，深入探讨了AMP的稳定性分析。您将看到该分析如何预测振荡行为，以及如何通过精确调整阻尼（damping）这一常见的实用技巧来保证算法的收敛。",
            "id": "3437999",
            "problem": "考虑一个带有稠密随机感知矩阵的标准压缩感知模型：测量值由 $y = A x_0 + w$ 生成，其中感知矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的元素 $A_{ij} \\sim \\mathcal{N}(0, 1/n)$ 是独立同分布的，信号 $x_0 \\in \\mathbb{R}^{n}$ 的分量是独立同分布的，其先验为 $P_{X}$，噪声 $w \\in \\mathbb{R}^{m}$ 的元素 $w_i \\sim \\mathcal{N}(0, \\sigma_w^2)$ 是独立同分布的。设测量率为 $\\delta = m/n \\in (0, \\infty)$。\n\n近似消息传递 (AMP) 可以被理解为在由 $A$ 导出的稠密因子图上，含环置信度传播 (BP) 的一种高维极限，其中对腔消息进行了高斯近似并加入了 Onsager 修正。这个极限在大系统极限下会引起精确的标量解耦，该过程由状态演化 (SE) 描述。对于一个 Lipschitz 连续的去噪器 $\\eta: \\mathbb{R} \\to \\mathbb{R}$（在工作点邻域内的 Lipschitz 常数为 $L$），其渐近均方误差的 SE 递归可以写为对非负序列 $\\{v_t\\}_{t \\geq 0}$ 的迭代：\n$$\nv_{t+1} = F(v_{t}) \\equiv \\sigma_{w}^{2} + \\frac{1}{\\delta} \\,\\mathbb{E}\\!\\left[\\big(\\eta\\!\\left(X + \\sqrt{v_{t}}\\,Z\\right) - X\\big)^{2}\\right],\n$$\n其中 $X \\sim P_{X}$，$Z \\sim \\mathcal{N}(0,1)$，期望是关于 $(X,Z)$ 的联合分布计算的。假设无阻尼 SE 存在一个不动点 $v^{\\ast} \\ge 0$，即 $v^{\\ast} = F(v^{\\ast})$，并且 $F$ 在 $v^{\\ast}$ 处可微，其导数为 $a \\equiv F'(v^{\\ast}) \\in \\mathbb{R}$。在标准的 SE 控制收敛论证下，$\\eta$ 的 Lipschitz 属性保证了 $F$ 在 $v^{\\ast}$ 的一个邻域内是局部 Lipschitz 连续且几乎处处可微的。\n\n在实践中，AMP 及其前身含环置信度传播通常通过阻尼来稳定，即对消息或状态更新进行欠松弛。考虑由下式定义的阻尼 SE：\n$$\nv_{t+1} = (1-\\lambda)\\,v_{t} + \\lambda\\,F(v_{t}),\n$$\n其中阻尼参数 $\\lambda \\in (0,1]$。\n\n任务：\n1) 从上述 SE 定义出发，仅利用 $F$ 在 $v^{\\ast}$ 处的可微性，推导无阻尼和阻尼 SE 在 $v^{\\ast}$ 附近的线性化迭代映射，并用 $a$ 和 $\\lambda$ 表示阻尼 SE 的有效线性化因子。\n\n2) 将 AMP 视为含环置信度传播的高维高斯近似极限，简要解释消息层面的阻尼如何对应于 SE 中的阻尼，以及为什么局部线性化因子决定了 $v^{\\ast}$ 附近振荡动力学的稳定性。\n\n3) 假设对于一个特定的 Lipschitz 去噪器和信号先验，无阻尼 SE 在不动点处的线性化斜率为 $a = -\\tfrac{3}{2}$。确定能够保证阻尼 SE 局部线性收敛到 $v^{\\ast}$ 的最大阻尼参数 $\\lambda \\in (0,1]$，即确保阻尼线性化因子的绝对值严格小于 1。请将你的最终答案表示为一个精确分数。如果你选择近似计算，请将结果四舍五入到四位有效数字。",
            "solution": "该问题要求分析近似消息传递 (AMP) 算法的状态演化 (SE) 动力学，重点关注线性化、阻尼的作用以及保证稳定性的阻尼参数的计算。\n\n**任务 1：状态演化动力学的线性化**\n\n系统的动力学由关于均方误差 $v_t$ 的迭代映射描述。给定一个不动点 $v^{\\ast}$ 使得 $v^{\\ast} = F(v^{\\ast})$，其中 $F$ 是 SE 函数。$F$ 在该点的导数已知为 $F'(v^{\\ast}) = a$。\n\n首先，我们分析由以下递归式给出的无阻尼 SE：\n$$\nv_{t+1} = F(v_{t})\n$$\n为了研究不动点 $v^{\\ast}$ 附近的局部稳定性，我们考虑一个小的扰动 $\\epsilon_{t}$，使得 $v_{t} = v^{\\ast} + \\epsilon_{t}$。将此代入递归式，并对 $F(v_t)$ 在 $v^{\\ast}$ 附近进行一阶泰勒展开，得到：\n$$\nv^{\\ast} + \\epsilon_{t+1} = F(v^{\\ast} + \\epsilon_{t}) \\approx F(v^{\\ast}) + F'(v^{\\ast})\\epsilon_{t}\n$$\n利用不动点条件 $v^{\\ast} = F(v^{\\ast})$，扰动方程简化为：\n$$\n\\epsilon_{t+1} \\approx F'(v^{\\ast})\\epsilon_{t}\n$$\n因此，无阻尼情况下的线性化迭代映射为 $\\epsilon_{t+1} \\approx a\\,\\epsilon_{t}$，相应的线性化因子为 $a$。\n\n接下来，我们分析由以下递归式定义的阻尼 SE：\n$$\nv_{t+1} = (1-\\lambda)v_{t} + \\lambda\\,F(v_{t})\n$$\n其中 $\\lambda \\in (0,1]$ 是阻尼参数。我们可以将阻尼迭代映射定义为 $G_{\\lambda}(v) = (1-\\lambda)v + \\lambda F(v)$。很容易验证 $v^{\\ast}$ 也是这个阻尼映射的一个不动点：\n$$\nG_{\\lambda}(v^{\\ast}) = (1-\\lambda)v^{\\ast} + \\lambda F(v^{\\ast}) = (1-\\lambda)v^{\\ast} + \\lambda v^{\\ast} = v^{\\ast}\n$$\n为了找到阻尼系统的线性化因子，我们将 $G_{\\lambda}(v)$ 对 $v$求导：\n$$\nG'_{\\lambda}(v) = \\frac{d}{dv}\\left[ (1-\\lambda)v + \\lambda F(v) \\right] = (1-\\lambda) + \\lambda F'(v)\n$$\n在不动点 $v^{\\ast}$ 处计算该导数，得到阻尼 SE 的有效线性化因子，我们记为 $a_{\\text{damped}}$：\n$$\na_{\\text{damped}} = G'_{\\lambda}(v^{\\ast}) = 1-\\lambda + \\lambda F'(v^{\\ast}) = 1-\\lambda + \\lambda a\n$$\n阻尼动力学的线性化迭代为 $\\epsilon_{t+1} \\approx (1-\\lambda + \\lambda a)\\epsilon_{t}$。\n\n**任务 2：BP 与 SE 阻尼之间的概念联系**\n\n近似消息传递可以被理解为应用于由感知矩阵 $A$ 定义的稠密因子图的含环置信度传播 (BP) 的一种算法简化。在大系统极限 ($m, n \\to \\infty$) 下，中心极限定理证明了将 BP 中传递的消息分布近似为高斯分布是合理的。AMP 对这些消息的均值和方差进行操作。状态演化是一个确定性映射，它描述了这些分布参数（特别是方差，对应于 MSE $v_t$）从一次迭代到下一次迭代的演化过程。\n\n在具有许多短环的稠密图上，标准 BP 通常不稳定，表现出振荡或发散行为。一种改善收敛的常用启发式方法是阻尼，即在迭代 $t+1$ 时的消息更新是新计算的消息与前一次迭代 $t$ 的消息的凸组合。这种欠松弛可以防止更新过冲，并有助于稳定算法。\n\n由于 SE 跟踪的是一个其微观消息传递动力学被阻尼的算法的宏观状态（即 MSE $v_t$），因此阻尼也出现在 SE 层面。无阻尼映射 $v_{t+1} = F(v_t)$ 表示一次迭代后 MSE 的完整更新。使用参数 $\\lambda$ 进行阻尼意味着系统状态 $v_t$ 只向新状态 $F(v_t)$ 移动了 $\\lambda$ 的比例。这恰好被阻尼 SE 更新规则 $v_{t+1} = (1-\\lambda)v_{t} + \\lambda F(v_{t})$ 所捕獲。\n\n任何此类迭代映射在不动点附近的局部稳定性由其线性化决定。如果线性化因子的绝对值严格小于 1，则迭代收敛。对于阻尼 SE，该因子为 $a_{\\text{damped}} = 1 - \\lambda + \\lambda a$。$a$ 的负值表示无阻尼系统倾向于通过过冲不动点而振荡。如果 $a  -1$，这些振荡会被放大。阻尼提供了一种机制，通过修改有效线性化因子来控制这种行为，可能将其绝对值降至 1 以下以确保收敛。\n\n**任务 3：阻尼参数的计算**\n\n给定无阻尼线性化在不动点处的斜率为 $a = -\\frac{3}{2}$。我们必须找到保证局部线性收敛的最大阻尼参数 $\\lambda \\in (0,1]$。这要求阻尼线性化因子 $|a_{\\text{damped}}|$ 的绝对值严格小于 $1$。\n\n$a_{\\text{damped}}$ 的表达式为：\n$$\na_{\\text{damped}} = 1 - \\lambda + \\lambda a = 1 - \\lambda + \\lambda \\left(-\\frac{3}{2}\\right) = 1 - \\frac{5}{2}\\lambda\n$$\n局部线性收敛的条件是 $|a_{\\text{damped}}|  1$，这等价于复合不等式：\n$$\n-1  1 - \\frac{5}{2}\\lambda  1\n$$\n我们对该不等式求解 $\\lambda$。不等式的右侧，$1 - \\frac{5}{2}\\lambda  1$，意味着 $-\\frac{5}{2}\\lambda  0$，得出 $\\lambda > 0$。这与约束 $\\lambda \\in (0,1]$ 一致。\n\n不等式的左侧是：\n$$\n-1  1 - \\frac{5}{2}\\lambda\n$$\n$$\n-2  -\\frac{5}{2}\\lambda\n$$\n两边乘以 -1 会反转不等号：\n$$\n2 > \\frac{5}{2}\\lambda\n$$\n$$\n4 > 5\\lambda\n$$\n$$\n\\lambda  \\frac{4}{5}\n$$\n因此，保证局部线性收斂的条件是 $\\lambda > 0$ 和 $\\lambda  \\frac{4}{5}$，可以写成 $\\lambda \\in (0, \\frac{4}{5})$。问题要求满足此条件的最大 $\\lambda \\in (0,1]$。有效的 $\\lambda$ 集合是一个开区间 $(0, \\frac{4}{5})$，它没有最大元素。在这种情况下，这个问题通常被解释为寻找有效参数集合的上确界，它代表了稳定性的临界边界。对于此区间内的任何 $\\lambda$，收敛都得到保证。该集合的上确界是 $\\frac{4}{5}$。任何阻尼 $\\lambda \\ge \\frac{4}{5}$ 都会导致 $|a_{\\text{damped}}| \\geq 1$，不满足线性收敛的严格条件。因此，严格上界是 $\\frac{4}{5}$。",
            "answer": "$$\\boxed{\\frac{4}{5}}$$"
        }
    ]
}