{
    "hands_on_practices": [
        {
            "introduction": "相变是压缩感知中的一个核心现象，它精确地刻画了成功恢复信号所需的最少测量数。本练习将引导你使用现代几何的观点，从第一性原理出发，推导著名的 Donoho–Tanner 相变曲线 。通过这个过程，你将把下降锥和统计维度等抽象概念与一个具体的、可预测的公式联系起来，从而深刻理解相变的几何起源。",
            "id": "3451344",
            "problem": "考虑一个压缩感知模型，其测量矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的元素独立同分布于 $\\mathcal{N}(0,1/m)$。令 $x_{0} \\in \\mathbb{R}^{n}$ 是一个 $k$-稀疏向量，其稀疏度为 $\\rho = k/n \\in (0,1)$，并定义采样率为 $\\delta = m/n \\in (0,1)$。通过 $\\ell_{1}$-最小化进行重构：在约束条件 $Ax = y$ 下最小化 $\\|x\\|_{1}$，其中 $y = Ax_{0}$。在 $n \\to \\infty$ 且 $\\rho$ 固定的高维极限下，Donoho–Tanner 相变由一个临界采样率 $\\delta_{c}(\\rho)$ 表征，当 $\\delta > \\delta_{c}(\\rho)$ 时，精确重构的概率趋近于1；当 $\\delta  \\delta_{c}(\\rho)$ 时，重构失败。\n\n请仅使用适用于凸几何和随机投影的基本原理——即随机子空间的锥运动学公式、凸函数在某一点的下降锥的定义以及统计维度的定义——来推导在 $k$-稀疏向量 $x_{0}$ 处进行 $\\ell_{1}$-最小化的相变曲线 $\\delta_{c}(\\rho)$。您的推导应从第一性原理出发：刻画 $\\ell_{1}$ 范数在 $x_{0}$ 处的下降锥，将重构问题与 $A$ 的零空间联系起来，并利用锥运动学的观点，根据下降锥的统计维度来确定阈值。然后，通过将问题简化为一个关于标量参数的一维优化问题（该参数通过次微分的适当缩放引入），来计算统计维度，并明确地进行必要的高斯期望计算。\n\n您的最终答案必须是 $\\delta_{c}(\\rho)$ 的一个单一闭式解析表达式，该表达式以一个一维下确界的形式给出，其中包含标准正态密度函数 $\\varphi(t) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-t^{2}/2)$ 和标准正态上尾函数 $Q(t) = \\int_{t}^{\\infty} \\varphi(u)\\,du$。不需要数值近似。请仅提供 $\\delta_{c}(\\rho)$ 的表达式作为您的最终答案。",
            "solution": "该问题是有效的，因为它是压缩感知数学理论中一个标准的、适定的问题。它具有科学依据，是客观的，并包含了进行严谨推导所需的所有必要信息。\n\n问题要求解通过 $\\ell_1$-最小化从测量值 $y = A x_0$ 成功重构一个 $k$-稀疏向量 $x_0 \\in \\mathbb{R}^n$ 的相变曲线 $\\delta_c(\\rho)$。矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的元素是独立同分布于 $\\mathcal{N}(0, 1/m)$ 的。稀疏度为 $\\rho = k/n$，采样率为 $\\delta = m/n$。\n\n重构算法求解以下问题：\n$$\n\\min_{x \\in \\mathbb{R}^n} \\|x\\|_1 \\quad \\text{subject to} \\quad Ax = y.\n$$\n由于 $y = Ax_0$，真实信号 $x_0$ 是一个可行点。为了使 $x_0$ 成为唯一解，必须对于任何其他可行点 $x \\neq x_0$，都有 $\\|x\\|_1 > \\|x_0\\|_1$。\n任何可行点 $x$ 都可以写成 $x = x_0 + h$ 的形式，其中 $h$ 是某个非零向量。约束条件 $Ax=Ax_0$ 意味着 $A(x_0+h)=Ax_0$，化简后得到 $Ah=0$。因此，扰动向量 $h$ 必须位于 $A$ 的零空间中，记为 $\\operatorname{Null}(A)$。\n\n成功重构的条件是，对于所有 $h \\in \\operatorname{Null}(A) \\setminus \\{0\\}$，必须有 $\\|x_0+h\\|_1 > \\|x_0\\|_1$。这意味着 $A$ 的零空间中没有非零向量可以是 $\\ell_1$-范数在 $x_0$ 点的下降方向。\n\n凸函数 $f(x)$ 在点 $x_0$ 处的下降方向集合是锥 $\\mathcal{D}(f, x_0) = \\{ h \\in \\mathbb{R}^n : f'(x_0; h) \\le 0 \\}$，其中 $f'(x_0; h)$ 是方向导数。对于 $f(x) = \\|x\\|_1$，在 $x_0$ 点沿方向 $h$ 的方向导数由下式给出\n$$\nf'(x_0; h) = \\sum_{i \\in S} h_i \\text{sign}((x_0)_i) + \\sum_{j \\in S^c} |h_j|,\n$$\n其中 $S = \\operatorname{supp}(x_0)$ 是 $x_0$ 的支撑集，大小为 $k$，$S^c$ 是其补集，大小为 $n-k$。令 $s \\in \\mathbb{R}^k$ 是 $x_0$ 非零项的符号向量。那么下降锥为：\n$$\n\\mathcal{D}(\\|\\cdot\\|_1, x_0) = \\left\\{ h \\in \\mathbb{R}^n : \\langle s, h_S \\rangle + \\|h_{S^c}\\|_1 \\le 0 \\right\\},\n$$\n其中 $h_S$ 和 $h_{S^c}$ 是 $h$ 对应于索引集 $S$ 和 $S^c$ 的子向量。\n\n重构条件是下降锥与 $A$ 的零空间的交集只包含零向量：\n$$\n\\overline{\\mathcal{D}}(\\|\\cdot\\|_1, x_0) \\cap \\operatorname{Null}(A) = \\{0\\}.\n$$\n我们使用锥的闭包 $\\overline{\\mathcal{D}}$，因为对于一个随机子空间，这不会改变相交的概率。\n\n在高维极限 ($n \\to \\infty$) 和随机高斯矩阵 $A$ 的情况下，随机投影和凸几何理论（特别是锥运动学公式或 Gordon 的穿网定理）指出，该条件以高概率成立的充分必要条件是锥的维度与子空间的维度之和小于环境维度 $n$。锥的“维度”是其统计维度 $\\delta(C)$。$\\operatorname{Null}(A)$ 的维度是 $n-m$。相变边界出现在不等式取等时：\n$$\n\\delta(\\overline{\\mathcal{D}}) + \\dim(\\operatorname{Null}(A)) = n \\implies \\delta(\\overline{\\mathcal{D}}) + (n-m) = n \\implies \\delta(\\overline{\\mathcal{D}}) = m.\n$$\n两边除以 $n$，临界采样率 $\\delta_c = m/n$ 由下降锥的归一化统计维度给出：\n$$\n\\delta_c(\\rho) = \\lim_{n \\to \\infty} \\frac{\\delta(\\overline{\\mathcal{D}})}{n}.\n$$\n锥 $C$ 的统计维度可以通过其极锥 $C^\\circ$ 和关系式 $\\delta(C) + \\delta(C^\\circ) = n$ 来计算。另一个关键公式是 $\\delta(C) = \\mathbb{E}_{g \\sim \\mathcal{N}(0, I_n)}[\\operatorname{dist}(g, C^\\circ)^2]$。我们将使用后一个公式。\n\n首先，我们刻画极锥 $\\mathcal{D}^\\circ$（为简单起见，我们省略了闭包的横杠）。\n$$\n\\mathcal{D}^\\circ = \\{ v \\in \\mathbb{R}^n : \\langle v, h \\rangle \\le 0, \\forall h \\in \\overline{\\mathcal{D}} \\}.\n$$\n一个向量 $v$ 属于 $\\mathcal{D}^\\circ$ 的充分必要条件是它可以写成 $v_S = t s$ 且 $\\|v_{S^c}\\|_\\infty \\le t$ 的形式，其中 $t \\ge 0$ 是一个标量。这里，$v_S$ 和 $v_{S^c}$ 是 $v$ 的子向量。\n\n统计维度为 $\\delta(\\mathcal{D}) = \\mathbb{E}_g[ \\operatorname{dist}(g, \\mathcal{D}^\\circ)^2 ] = \\mathbb{E}_g[ \\min_{v \\in \\mathcal{D}^\\circ} \\|g - v\\|_2^2 ]$。令 $g=(g_S, g_{S^c})$ 是一个标准高斯向量。我们求解这个最小化问题：\n$$\n\\min_{t \\ge 0, v_{S^c}: \\|v_{S^c}\\|_\\infty \\le t} \\left( \\|g_S - ts\\|_2^2 + \\|g_{S^c} - v_{S^c}\\|_2^2 \\right).\n$$\n对于固定的 $t \\ge 0$，关于 $v_{S^c}$ 的最小化问题在坐标上是解耦的。对于每个 $j \\in S^c$，我们求解 $\\min_{|v_j| \\le t} (g_j - v_j)^2$。解为 $v_j = \\operatorname{sign}(g_j) \\min(|g_j|, t)$。当 $|g_j|>t$ 时，平方误差为 $(|g_j|-t)^2$，否则为 0。\n问题简化为关于 $t \\ge 0$ 的一维最小化问题：\n$$\n\\operatorname{dist}(g, \\mathcal{D}^\\circ)^2 = \\min_{t \\ge 0} \\left( \\|g_S - ts\\|_2^2 + \\sum_{j \\in S^c} (\\max\\{|g_j|-t, 0\\})^2 \\right).\n$$\n令 $L(t,g) = \\|g_S - ts\\|_2^2 + \\sum_{j \\in S^c, |g_j|>t} (|g_j|-t)^2$。归一化的相变阈值为\n$$\n\\delta_c(\\rho) = \\lim_{n \\to \\infty} \\frac{1}{n} \\mathbb{E}_g[\\min_{t \\ge 0} L(t,g)].\n$$\n在高维极限下，我们可以交换期望和最小化操作：\n$$\n\\delta_c(\\rho) = \\min_{t \\ge 0} \\lim_{n \\to \\infty} \\frac{1}{n} \\mathbb{E}_g[L(t,g)].\n$$\n我们来计算期望。$\\|g_S - ts\\|_2^2 = \\|g_S\\|_2^2 - 2t\\langle g_S, s \\rangle + t^2 \\|s\\|_2^2$。\n$\\mathbb{E}[\\|g_S\\|_2^2] = k$。$\\mathbb{E}[\\langle g_S, s \\rangle] = 0$。$\\|s\\|_2^2 = k$。\n因此，$\\mathbb{E}[\\|g_S - ts\\|_2^2] = k + kt^2$。\n对于第二项，根据期望的线性性：\n$$\n\\mathbb{E}\\left[\\sum_{j \\in S^c, |g_j|>t} (|g_j|-t)^2\\right] = (n-k) \\mathbb{E}_{Z \\sim \\mathcal{N}(0,1)}[ (\\max\\{|Z|-t, 0\\})^2 ].\n$$\n我们来计算关于标准正态变量 $Z$ 的期望：\n$$\n\\mathbb{E}[ (\\max\\{|Z|-t, 0\\})^2 ] = \\int_{-\\infty}^\\infty (\\max\\{|z|-t, 0\\})^2 \\varphi(z) dz = 2 \\int_t^\\infty (z-t)^2 \\varphi(z) dz.\n$$\n我们用分部积分法计算这个积分：\n$2 \\int_t^\\infty (z^2 - 2zt + t^2) \\varphi(z) dz = 2 \\left( \\int_t^\\infty z^2\\varphi(z)dz - 2t\\int_t^\\infty z\\varphi(z)dz + t^2\\int_t^\\infty \\varphi(z)dz \\right)$。\n使用恒等式 $\\int_t^\\infty \\varphi(z)dz = Q(t)$，$\\int_t^\\infty z\\varphi(z)dz = \\varphi(t)$，以及 $\\int_t^\\infty z^2\\varphi(z)dz = t\\varphi(t) + Q(t)$，我们得到：\n$2 \\left( (t\\varphi(t) + Q(t)) - 2t\\varphi(t) + t^2Q(t) \\right) = 2 \\left( (1+t^2)Q(t) - t\\varphi(t) \\right)$。\n\n现在，我们组合 $L(t,g)$ 的归一化期望：\n$$\n\\frac{1}{n} \\mathbb{E}_g[L(t,g)] = \\frac{1}{n} \\left( k+kt^2 + (n-k) \\cdot 2 \\left( (1+t^2)Q(t) - t\\varphi(t) \\right) \\right).\n$$\n取极限 $n\\to\\infty$，此时 $k/n \\to \\rho$ 且 $(n-k)/n \\to 1-\\rho$：\n$$\n\\lim_{n \\to \\infty} \\frac{1}{n} \\mathbb{E}_g[L(t,g)] = \\rho(1+t^2) + (1-\\rho) \\cdot 2 \\left( (1+t^2)Q(t) - t\\varphi(t) \\right).\n$$\n相变曲线是此表达式在 $t \\ge 0$ 上的下确界。\n$$\n\\delta_c(\\rho) = \\inf_{t \\ge 0} \\left\\{ \\rho(1+t^2) + 2(1-\\rho) \\left( (1+t^2)Q(t) - t\\varphi(t) \\right) \\right\\}.\n$$\n该表达式符合问题陈述的要求。参数 $t$ 是执行优化的标量。",
            "answer": "$$\n\\boxed{\\inf_{t \\ge 0} \\left\\{ \\rho(1+t^{2}) + 2(1-\\rho) \\left( (1+t^{2})Q(t) - t\\varphi(t) \\right) \\right\\}}\n$$"
        },
        {
            "introduction": "在建立统计维度的概念之后，我们可以用它来分析更复杂的场景。在现实应用中，我们可能不知道信号的真实结构，这会导致我们选用与问题不匹配的正则化项 。本练习通过一个具体的计算，量化了这种模型设定错误所带来的“代价”，即所需的测量数（相变阈值）会如何急剧增加，从而展示了正确选择正则化项的实际重要性。",
            "id": "3451293",
            "problem": "考虑以下从线性测量中恢复矩阵信号的理想化压缩感知设置。设 $X_{\\star} \\in \\mathbb{R}^{m \\times n}$ 是一个未知的秩为 $r$ 的矩阵，其奇异值分解为 $X_{\\star} = U \\Sigma V^{\\top}$，且 $X_{\\star}$ 的每个元素都非零。设 $\\mathcal{A} : \\mathbb{R}^{m \\times n} \\to \\mathbb{R}^{p}$ 是一个线性测量算子，其元素是独立同分布的、均值为零、方差为一的高斯随机变量。恢复是通过求解形式为 $\\min_{X} R(X)$ 且满足约束 $\\mathcal{A}(X) = \\mathcal{A}(X_{\\star})$ 的凸规划来实现的，其中 $R$ 是一个凸正则化子。\n\n考虑了两种不同的正则化子：\n- 正确指定的正则化子，核范数 $R_{\\text{nuc}}(X) = \\|X\\|_{\\ast}$，它与真实的低秩模型相符。\n- 错误指定的正则化子，逐元素的 $\\ell_{1}$ 范数 $R_{\\ell_{1}}(X) = \\|X\\|_{1}$，它在元素中引入稀疏性，尽管 $X_{\\star}$ 是逐元素稠密的。\n\n使用锥积分几何 (Conic Integral Geometry, CIG) 的框架，该框架将高斯测量下精确恢复的相变与下降锥的统计维度联系起来，具体如下：对于一个凸函数 $R$ 和点 $X_{\\star}$，下降锥 $\\mathcal{D}(R, X_{\\star})$ 是一个闭凸锥，其统计维度定义为 $\\delta(\\mathcal{D}(R, X_{\\star})) = \\mathbb{E}\\left[\\|\\Pi_{\\mathcal{D}(R, X_{\\star})}(G)\\|_{F}^{2}\\right]$，其中 $G$ 的元素是独立的标准正态分布，$\\Pi_{\\mathcal{D}}$ 表示到锥 $\\mathcal{D}$ 上的度量投影。CIG 相变原理指出，对于大规模问题和高斯测量，凸规划的几乎必然成功与失败之间的转变发生在测量数量 $p$ 越过统计维度 $\\delta(\\mathcal{D}(R, X_{\\star}))$ 时。\n\n假设 $m = 10$, $n = 10$, 且 $r = 1$。在这些条件下：\n- 量化由错误指定引起的超额统计维度 $\\Delta \\delta$，定义为\n$$\n\\Delta \\delta \\triangleq \\delta\\!\\left(\\mathcal{D}(R_{\\ell_{1}}, X_{\\star})\\right) - \\delta\\!\\left(\\mathcal{D}(R_{\\text{nuc}}, X_{\\star})\\right),\n$$\n并将其解释为，在 CIG 框架内，与正确指定的正则化子相比，使用错误指定的正则化子进行精确恢复时，测量阈值的预测增量。\n\n以单个精确实数的形式提供最终答案。无需四舍五入。",
            "solution": "该问题要求计算超额统计维度 $\\Delta \\delta$，这是在矩阵恢复问题中使用错误指定的正则化子所产生的。该量定义为 $\\Delta \\delta = \\delta(\\mathcal{D}(R_{\\ell_{1}}, X_{\\star})) - \\delta(\\mathcal{D}(R_{\\text{nuc}}, X_{\\star}))$。我们已知维度 $m = 10$，$n = 10$，以及真实信号矩阵 $X_{\\star}$ 的秩 $r = 1$。求解过程是先分别为每个正则化子计算统计维度，然后求出它们的差值。\n\n首先，我们考虑使用核范数正则化子 $R_{\\text{nuc}}(X) = \\|X\\|_{\\ast}$ 的正确指定情况。信号矩阵 $X_{\\star}$ 的秩为 $r$。对于一个一般的秩为 $r$ 的矩阵，下降锥 $\\mathcal{D}(R_{\\text{nuc}}, X_{\\star})$ 是秩为 $r$ 的矩阵流形在点 $X_{\\star}$ 处的切空间。这个切空间是 $\\mathbb{R}^{m \\times n}$ 的一个线性子空间。根据锥积分几何 (CIG) 的原理，一个线性子空间的统计维度等于其向量空间维度。秩为 $r$ 的 $m \\times n$ 矩阵流形的切空间维度由以下著名公式给出：\n$$\n\\dim(T_{X_{\\star}}) = mr + nr - r^2\n$$\n对于这个问题，我们有 $m = 10$，$n = 10$ 和 $r = 1$。将这些值代入公式，得到核范数情况下的统计维度：\n$$\n\\delta(\\mathcal{D}(R_{\\text{nuc}}, X_{\\star})) = \\dim(T_{X_{\\star}}) = (10)(1) + (10)(1) - (1)^2 = 10 + 10 - 1 = 19\n$$\n这个值预测了在使用核范数时，成功恢复大约需要19次测量。\n\n接下来，我们考虑使用逐元素的 $\\ell_1$ 范数正则化子 $R_{\\ell_{1}}(X) = \\|X\\|_{1} = \\sum_{i,j} |X_{ij}|$ 的错误指定情况。提供的一个关键信息是，真实矩阵 $X_{\\star}$ 的每个元素都非零。这意味着 $\\ell_1$ 范数在 $X_{\\star}$ 处是可微的。$\\ell_1$ 范数在 $X_{\\star}$ 处的次微分是一个只包含梯度的单元素集，这个梯度就是 $X_{\\star}$ 的符号矩阵：\n$$\n\\partial \\|X_{\\star}\\|_{1} = \\{\\operatorname{sign}(X_{\\star})\\}\n$$\n其中符号函数是逐元素应用的。下降锥 $\\mathcal{D}(R_{\\ell_{1}}, X_{\\star})$ 是所有与梯度内积为非正的矩阵 $Y$ 的集合：\n$$\n\\mathcal{D}(R_{\\ell_{1}}, X_{\\star}) = \\{ Y \\in \\mathbb{R}^{m \\times n} : \\langle \\operatorname{sign}(X_{\\star}), Y \\rangle_{F} \\le 0 \\}\n$$\n这在环境空间 $\\mathbb{R}^{m \\times n}$ 中定义了一个半空间。这个环境空间的维度是 $N = mn = (10)(10) = 100$。CIG 的一个标准结果表明，$\\mathbb{R}^{N}$ 中半空间的统计维度由下式给出：\n$$\n\\delta(\\text{half-space}) = N - \\frac{1}{2}\n$$\n这可以通过考虑极锥（它是一条射线）来推导。射线的统计维度是 $\\mathbb{E}[(\\max(0, Z))^2]$，其中 $Z \\sim \\mathcal{N}(0,1)$，这个值等于 $1/2$。根据 CIG 的基本关系式 $\\delta(K) + \\delta(K^{\\circ}) = N$（对于锥 $K$ 及其极锥 $K^{\\circ}$），半空间的统计维度是 $N - 1/2$。\n代入 $N = 100$，我们得到 $\\ell_1$ 范数情况下的统计维度：\n$$\n\\delta(\\mathcal{D}(R_{\\ell_{1}}, X_{\\star})) = mn - \\frac{1}{2} = 100 - 0.5 = 99.5\n$$\n这个值预测了在使用 $\\ell_1$ 范数时，恢复需要大约100次测量，这几乎是矩阵中的总自由度数。\n\n最后，我们通过将两个结果相减来计算超额统计维度 $\\Delta \\delta$：\n$$\n\\Delta \\delta = \\delta(\\mathcal{D}(R_{\\ell_{1}}, X_{\\star})) - \\delta(\\mathcal{D}(R_{\\text{nuc}}, X_{\\star})) = 99.5 - 19 = 80.5\n$$\n这个结果 $\\Delta \\delta = 80.5$ 量化了因使用与信号底层结构不匹配的正则化子而导致的惩罚（以所需测量数量来衡量）。核范数有效地利用了低秩结构，仅需要19次测量。相比之下，促进逐元素稀疏性的 $\\ell_1$ 范数对于稠密信号效率极低，需要多得多的测量次数（99.5次）才能恢复。80.5的差值代表了由于这种模型错误指定而导致的测量阈值的预测增量。",
            "answer": "$$\\boxed{80.5}$$"
        },
        {
            "introduction": "理论的魅力不仅在于其数学上的优美，更在于其对现实世界的预测能力。普适性猜想是压缩感知理论中一个惊人而深刻的结论：它断言相变曲线在很大程度上独立于测量矩阵的具体随机分布。本编程练习  旨在通过数值实验来检验这一猜想，你将亲手实现并比较高斯矩阵和随机傅里叶矩阵下的恢复性能，从而连接抽象理论与计算实践。",
            "id": "3451296",
            "problem": "考虑一个压缩感知模型，其中未知向量 $x_0 \\in \\mathbb{R}^n$ 是 $k$-稀疏的，意味着它最多有 $k$ 个非零项。测量值 $y \\in \\mathbb{C}^m$ 是通过一个线性算子 $A \\in \\mathbb{C}^{m \\times n}$ 获得的，满足 $y = A x_0$。重构通过基追踪规划完成，该规划在精确测量约束条件下最小化 $\\ell_1$ 范数。高维凸集的几何学表明，$\\ell_1$ 重构的成功或失败在欠采样率和稀疏度比构成的平面上表现出急剧的相变，这通常由一条相变曲线 $\\delta_c(\\rho)$ 来概括，其中 $\\delta = m/n$ 且 $\\rho = k/m$。这条曲线被推测在经过适当的随机化后，对于一类测量集成是普适的。\n\n从基本定义和经过充分检验的事实出发：\n- 通过 $\\ell_1$ 最小化实现的稀疏重构被定义为凸优化问题 $\\min \\|x\\|_1$，约束条件为 $A x = y$，其中 $\\|\\cdot\\|_1$ 表示各分量绝对值之和。\n- 压缩感知中的普适性假定，经验相变行为主要由随机多胞体的几何性质决定，并且在满足某些非相干性和各向同性条件的前提下，很大程度上独立于测量矩阵的具体分布。\n- 离散傅里叶变换（DFT）矩阵 $F \\in \\mathbb{C}^{n \\times n}$ 定义为 $F_{j,k} = \\exp\\!\\left(-2\\pi i \\frac{jk}{n}\\right)/\\sqrt{n}$，其中 $i$ 表示虚数单位。通过从 $F$ 中均匀随机选择 $m$ 行来构成一个部分傅里叶子采样矩阵。通过一个对角矩阵 $R \\in \\mathbb{R}^{n \\times n}$ 进行随机调制，其中对角线元素是独立的 Rademacher 变量（每个元素以等概率取值为 $+1$ 或 $-1$），得到 $A = P F R$，其中 $P$ 表示行选择。\n\n您的任务是实现一个程序，通过比较两种测量集成之间的估计相变来经验性地检验普适性：\n1. 一个高斯集成，其中 $A$ 的元素是均值为 $0$、方差为 $1/m$ 的独立同分布正态随机变量，记作 $A_{ij} \\sim \\mathcal{N}(0, 1/m)$。\n2. 一个随机调制的部分傅里叶集成，其中 $A = P F R$ 如上定义，且 $F$ 是标准正交的。\n\n对于每个测试用例，执行以下操作：\n- 固定 $n$ 和 $k$。对于给定列表中的每个候选 $m$，执行 $T$ 次独立试验。在每次试验中：\n  - 采样一个 $k$-稀疏向量 $x_0 \\in \\mathbb{R}^n$，其支撑集是均匀随机选择的，非零值从标准正态分布 $\\mathcal{N}(0,1)$ 中独立抽取。\n  - 分别为每个集成构建测量值 $y = A x_0$。\n  - 通过使用变量分裂 $x = u - v$（其中 $u \\ge 0, v \\ge 0$）的等价线性规划形式，求解基追踪问题 $\\min \\|x\\|_1$，约束条件为 $A x = y$。\n  - 如果相对 $\\ell_2$ 误差 $\\|x^\\star - x_0\\|_2 / \\max(\\|x_0\\|_2, \\varepsilon)$ 最多为指定的容差，则宣告成功，其中 $x^\\star$ 是重构解，$\\varepsilon$ 是一个小的正数以避免除以零。\n- 对于每个集成，计算每个 $m$ 对应的经验成功率，即成功试验所占的比例。\n- 对于每个集成，通过在候选 $m$ 值中选择其成功率至少达到指定阈值 $q$ 的最小 $\\delta = m/n$ 来估计给定 $k$ 时的 $\\delta_c$。如果没有候选 $m$ 达到该阈值，则宣告 $\\delta_c$ 未定义。\n- 为每个测试用例返回一个布尔结果，指示两个集成的估计临界欠采样率之间的绝对差 $|\\delta_c^{\\mathrm{Gauss}} - \\delta_c^{\\mathrm{Fourier}}|$ 是否小于或等于指定的容差 $\\epsilon$。如果一个或两个 $\\delta_c$ 值未定义，则该测试用例返回 false。\n\n算法约束：\n- 基追踪问题必须通过引入 $u, v \\in \\mathbb{R}^n$ 并求解一个线性规划来解决，即最小化 $\\mathbf{1}^\\top(u + v)$，约束条件为 $A(u - v) = y$, $u \\ge 0$, $v \\ge 0$。对于复数值的 $A$ 和 $y$，通过将其分解为实部和虚部来施加等式约束：$\\operatorname{Re}(A)(u - v) = \\operatorname{Re}(y)$ 和 $\\operatorname{Im}(A)(u - v) = \\operatorname{Im}(y)$。\n\n成功标准：\n- 使用相对误差容差 $\\tau = 10^{-6}$ 和分母稳定器 $\\varepsilon = 10^{-12}$。\n\n测试套件：\n- 用例 1：$n = 64$，$k = 4$，候选 $m$ 值为 $[12, 14, 16, 18, 20, 22, 24]$，试验次数 $T = 8$，成功阈值 $q = 0.75$，容差 $\\epsilon = 0.15$。\n- 用例 2：$n = 96$，$k = 8$，候选 $m$ 值为 $[24, 28, 32, 36, 40, 44]$，试验次数 $T = 6$，成功阈值 $q = 0.67$，容差 $\\epsilon = 0.20$。\n- 用例 3：$n = 128$，$k = 16$，候选 $m$ 值为 $[36, 44, 52, 60, 68, 76, 84]$，试验次数 $T = 5$，成功阈值 $q = 0.60$，容差 $\\epsilon = 0.20$。\n\n输出规格：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，`[result1,result2,result3]`），其中每个结果是与上述测试用例顺序对应的布尔值。\n\n所有答案都是无单位的实数和布尔值；不涉及物理单位。角度（若有）应解释为弧度，但本任务中不需要。",
            "solution": "该问题要求对压缩感知中的普适性猜想进行经验性研究。该猜想假定，通过 $\\ell_1$ 最小化实现的稀疏信号重构的相变行为，在满足某些通用条件的情况下，很大程度上独立于随机测量矩阵的具体分布。我们将比较两种常见矩阵集成的相变点：复高斯集成和随机调制的部分傅里叶集成。\n\n### 理论框架\n\n压缩感知的核心问题是从一组线性测量值 $y = A x_0$ 中重构一个 $k$-稀疏信号 $x_0 \\in \\mathbb{R}^n$（一个最多有 $k$ 个非零元素的向量）。测量矩阵 $A$ 是一个 $m \\times n$ 矩阵，其中 $m  n$，这使得方程组是欠定的。\n\n重构通常通过求解基追踪凸优化问题来实现：\n$$ \\min_{x \\in \\mathbb{R}^n} \\|x\\|_1 \\quad \\text{约束条件为} \\quad Ax = y $$\n其中 $\\|x\\|_1 = \\sum_{i=1}^n |x_i|$ 是 $\\ell_1$ 范数。如果测量次数 $m$ 相对于稀疏度 $k$ 和信号维度 $n$ 足够大，该规划就能成功精确重构 $x_0$。\n\n重构的成功与否表现出急剧的相变。对于固定的信号结构，随着欠采样率 $\\delta = m/n$ 的增加，成功重构的概率会从接近 $0$ 迅速过渡到接近 $1$。发生这种转变的临界值 $\\delta_c$ 取决于稀疏度比。问题将此比率定义为 $\\rho = k/m$。在 $(\\rho, \\delta)$ 平面上的曲线 $\\delta_c(\\rho)$ 被称为相变曲线。普适性猜想指出，对于广泛类别的随机矩阵集成，这条曲线是相同的。\n\n### 方法论与算法设计\n\n我们的任务是估计和比较两种集成的临界欠采样率 $\\delta_c$。\n\n1.  **高斯集成**：矩阵 $A_{\\text{Gauss}} \\in \\mathbb{C}^{m \\times n}$ 的元素是独立同分布的。问题规定 $A_{ij} \\sim \\mathcal{N}(0, 1/m)$。对于复数值矩阵，这通常被解释为元素是复正态变量，$A_{ij} \\sim \\mathcal{CN}(0, 1/m)$。这意味着 $A_{ij} = U + iV$，其中 $U, V$ 是独立同分布的实高斯随机变量 $\\mathcal{N}(0, 1/(2m))$。其方差为 $\\mathbb{E}[|A_{ij}|^2] = \\mathbb{E}[U^2 + V^2] = \\frac{1}{2m} + \\frac{1}{2m} = \\frac{1}{m}$，与问题陈述一致。\n\n2.  **随机调制的部分傅里叶集成**：该矩阵构造为 $A_{\\text{Fourier}} = PFR$。\n    -   $F \\in \\mathbb{C}^{n \\times n}$ 是标准正交的离散傅里叶变换（DFT）矩阵，其元素为 $F_{j,k} = \\frac{1}{\\sqrt{n}} \\exp(-2\\pi i \\frac{jk}{n})$，其中 $j, k \\in \\{0, \\dots, n-1\\}$。\n    -   $R \\in \\mathbb{R}^{n \\times n}$ 是一个对角矩阵，其对角线元素是独立的 Rademacher 随机变量（即以 $1/2$ 的概率取 $\\pm 1$）。这种随机调制对于确保非相干性至关重要。\n    -   $P$ 是一个投影算子，它从 $FR$ 中均匀随机地选择 $m$ 行。\n\n对于一个给定的测试用例 $(n, k, \\{m\\}_{\\text{cand}}, T, q, \\epsilon)$，实验流程如下：\n对于每个候选测量次数 $m \\in \\{m\\}_{\\text{cand}}$，我们执行 $T$ 次独立试验。在每次试验中：\n- 生成一个 $k$-稀疏信号 $x_0 \\in \\mathbb{R}^n$。其支撑集（非零元素的索引集合）是均匀随机选择的，非零值从标准正态分布 $\\mathcal{N}(0,1)$ 中抽取。\n- 为每个集成生成测量矩阵 $A$，并计算测量向量 $y = Ax_0$。\n- 求解基追踪问题以获得重构信号 $x^\\star$。\n- 如果相对 $\\ell_2$ 误差低于容差 $\\tau = 10^{-6}$，则宣告成功：\n  $$ \\frac{\\|x^\\star - x_0\\|_2}{\\max(\\|x_0\\|_2, \\varepsilon)} \\le \\tau $$\n  其中 $\\varepsilon = 10^{-12}$ 用于防止除以零。\n\n每个 $m$ 的经验成功率是成功试验的比例。临界欠采样率 $\\delta_c$ 估计为 $m_c/n$，其中 $m_c$ 是成功率至少达到阈值 $q$ 的最小候选 $m$。如果没有 $m$ 达到此成功率，则认为该集成的 $\\delta_c$ 未定义。\n\n最后，通过检查估计的临界比率之间的绝对差是否在容差 $\\epsilon$ 之内来检验普适性：$|\\delta_c^{\\mathrm{Gauss}} - \\delta_c^{\\mathrm{Fourier}}| \\le \\epsilon$。如果此条件未满足或任一 $\\delta_c$ 未定义，则测试失败。\n\n### 作为线性规划的基追踪\n\n$\\ell_1$ 最小化问题通过将其重新表述为一个线性规划（LP）来求解。我们使用变量分裂技术，将 $x \\in \\mathbb{R}^n$ 表示为两个非负向量的差，$x = u - v$，其中 $u,v \\in \\mathbb{R}^n$ 且 $u,v \\ge 0$。$\\ell_1$ 范数 $\\|x\\|_1$ 随后等价于最小化 $\\mathbf{1}^\\top(u+v)$，其中 $\\mathbf{1}$ 是一个全一向量。这是因为对于任何最优解，对于每个分量 $i$， $u_i$ 或 $v_i$ 中至少有一个必须为零。\n\n基追踪问题变为：\n$$ \\min_{u,v \\in \\mathbb{R}^n} \\mathbf{1}^\\top u + \\mathbf{1}^\\top v \\quad \\text{约束条件为} \\quad A(u-v) = y, \\ u \\ge 0, \\ v \\ge 0. $$\n由于矩阵 $A$ 和向量 $y$ 是复数，即 $A = \\operatorname{Re}(A) + i\\operatorname{Im}(A)$ 和 $y = \\operatorname{Re}(y) + i\\operatorname{Im}(y)$，单个复数等式约束 $A(u-v) = y$ 等价于两个实数等式约束：\n$$ \\operatorname{Re}(A)(u-v) = \\operatorname{Re}(y) $$\n$$ \\operatorname{Im}(A)(u-v) = \\operatorname{Im}(y) $$\n这个系统可以用标准的线性规划（LP）求解器来求解。我们定义一个新的变量向量 $z = [u^\\top, v^\\top]^\\top \\in \\mathbb{R}^{2n}$。该线性规划则为：\n- **最小化：** $c^\\top z$，其中 $c = \\mathbf{1}_{2n} \\in \\mathbb{R}^{2n}$。\n- **约束条件：** $A_{eq} z = b_{eq}$ 且 $z \\ge 0$。\n等式约束矩阵 $A_{eq} \\in \\mathbb{R}^{2m \\times 2n}$ 和向量 $b_{eq} \\in \\mathbb{R}^{2m}$ 构建如下：\n$$ A_{eq} = \\begin{pmatrix} \\operatorname{Re}(A)  -\\operatorname{Re}(A) \\\\ \\operatorname{Im}(A)  -\\operatorname{Im}(A) \\end{pmatrix}, \\quad b_{eq} = \\begin{pmatrix} \\operatorname{Re}(y) \\\\ \\operatorname{Im}(y) \\end{pmatrix} $$\n线性规划的解 $z^\\star = [(u^\\star)^\\top, (v^\\star)^\\top]^\\top$ 给出重构信号 $x^\\star = u^\\star - v^\\star$。该过程在每次试验中实施，以找到 $x^\\star$ 并评估重构成功率。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import linprog\nfrom scipy.fft import fft\n\ndef solve_bp_complex(A, y, n):\n    \"\"\"\n    Solves the basis pursuit problem min ||x||_1 s.t. Ax = y for complex A and y\n    using a linear programming formulation.\n    \"\"\"\n    m = A.shape[0]\n\n    # LP variable is z = [u, v] where x = u - v, u, v >= 0. Size is 2n.\n    # Objective function: min 1_T * u + 1_T * v, so c = [1, 1, ..., 1].\n    c = np.ones(2 * n)\n\n    # Equality constraints: A(u - v) = y\n    # This splits into real and imaginary parts:\n    # Re(A)(u - v) = Re(y)\n    # Im(A)(u - v) = Im(y)\n    # A_eq * z = b_eq, where z = [u, v]^T\n    A_re = np.real(A)\n    A_im = np.imag(A)\n    \n    A_eq = np.block([\n        [A_re, -A_re],\n        [A_im, -A_im]\n    ])\n\n    b_eq = np.concatenate([np.real(y), np.imag(y)])\n    \n    # All variables are non-negative\n    bounds = (0, None)\n\n    # Solve the linear program\n    res = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs', options={'presolve': True})\n\n    if res.success:\n        z = res.x\n        u = z[:n]\n        v = z[n:]\n        x_rec = u - v\n        return x_rec\n    else:\n        # Return a vector of NaNs to indicate failure, which will fail the success check.\n        return np.full(n, np.nan)\n\ndef check_success(x_rec, x_0, tau, eps_denom):\n    \"\"\"\n    Checks if the recovery was successful based on relative l2 error.\n    \"\"\"\n    if np.any(np.isnan(x_rec)):\n        return False\n    norm_x0 = np.linalg.norm(x_0)\n    error_norm = np.linalg.norm(x_rec - x_0)\n    relative_error = error_norm / max(norm_x0, eps_denom)\n    return relative_error = tau\n\ndef estimate_critical_delta(ensemble_type, n, k, m_candidates, T, q, tau, eps_denom, rng):\n    \"\"\"\n    Estimates the critical undersampling ratio delta_c for a given ensemble.\n    \"\"\"\n    # Pre-compute the orthonormal DFT matrix for the Fourier case\n    if ensemble_type == 'fourier':\n        F = fft(np.eye(n), norm='ortho', axis=0)\n\n    success_rates = {}\n\n    for m in m_candidates:\n        success_count = 0\n        for _ in range(T):\n            # 1. Generate k-sparse signal x_0\n            x_0 = np.zeros(n)\n            support = rng.choice(n, k, replace=False)\n            x_0[support] = rng.standard_normal(k)\n\n            # 2. Generate measurement matrix A and measurements y\n            if ensemble_type == 'gaussian':\n                # A_ij ~ CN(0, 1/m). Real and imag parts are N(0, 1/(2m)).\n                A = (rng.standard_normal((m, n)) + 1j * rng.standard_normal((m, n))) / np.sqrt(2 * m)\n            elif ensemble_type == 'fourier':\n                # A = PFR\n                signs = rng.choice([-1.0, 1.0], size=n)\n                R_mult = signs # For efficient multiplication\n                \n                rows = rng.choice(n, m, replace=False)\n                # A = (F @ np.diag(signs))[rows, :] is inefficient\n                # A = F_rows @ diag(signs) = F_rows * signs (broadcast)\n                A = F[rows, :] * R_mult\n            \n            y = A @ x_0\n\n            # 3. Solve for x_rec\n            x_rec = solve_bp_complex(A, y, n)\n\n            # 4. Check for success\n            if check_success(x_rec, x_0, tau, eps_denom):\n                success_count += 1\n        \n        success_rates[m] = success_count / T\n    \n    # 5. Estimate delta_c\n    delta_c = float('nan') # Using NaN to represent 'undefined'\n    sorted_m = sorted(m_candidates)\n    for m in sorted_m:\n        if success_rates[m] >= q:\n            delta_c = m / n\n            break # Found the smallest m that meets the threshold\n            \n    return delta_c\n\ndef run_single_test_case(n, k, m_candidates, T, q, epsilon, tau, eps_denom, seed):\n    \"\"\"\n    Runs the full comparison for a single test case.\n    \"\"\"\n    # Use a specific seed for each test case for reproducibility\n    rng = np.random.default_rng(seed)\n\n    delta_c_gauss = estimate_critical_delta(\n        'gaussian', n, k, m_candidates, T, q, tau, eps_denom, rng\n    )\n    delta_c_fourier = estimate_critical_delta(\n        'fourier', n, k, m_candidates, T, q, tau, eps_denom, rng\n    )\n\n    if np.isnan(delta_c_gauss) or np.isnan(delta_c_fourier):\n        return False\n        \n    return abs(delta_c_gauss - delta_c_fourier) = epsilon\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Success criterion parameters\n    tau = 1e-6\n    eps_denom = 1e-12\n\n    # Test suite from the problem statement.\n    test_cases = [\n        {'n': 64, 'k': 4, 'm_candidates': [12, 14, 16, 18, 20, 22, 24], 'T': 8, 'q': 0.75, 'epsilon': 0.15, 'seed': 0},\n        {'n': 96, 'k': 8, 'm_candidates': [24, 28, 32, 36, 40, 44], 'T': 6, 'q': 0.67, 'epsilon': 0.20, 'seed': 1},\n        {'n': 128, 'k': 16, 'm_candidates': [36, 44, 52, 60, 68, 76, 84], 'T': 5, 'q': 0.60, 'epsilon': 0.20, 'seed': 2},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_single_test_case(\n            case['n'], case['k'], case['m_candidates'], case['T'],\n            case['q'], case['epsilon'], tau, eps_denom, case['seed']\n        )\n        # Convert Python booleans (True/False) to JSON-style strings (true/false)\n        results.append(str(result).lower())\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}