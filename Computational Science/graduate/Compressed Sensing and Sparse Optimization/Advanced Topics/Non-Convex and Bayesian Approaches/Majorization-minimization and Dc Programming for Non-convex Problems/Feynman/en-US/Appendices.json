{
    "hands_on_practices": [
        {
            "introduction": "Proximal operators are the workhorse of many modern optimization algorithms, forming the core update step in methods for both convex and non-convex problems. This exercise  challenges you to derive the proximal map for the Smoothly Clipped Absolute Deviation (SCAD) penalty, a canonical non-convex regularizer used for sparse modeling. By mastering this fundamental calculation, you will gain a concrete understanding of how Majorization-Minimization algorithms can effectively handle non-convexity to promote sparsity while mitigating the bias associated with convex penalties like the $\\ell_1$-norm.",
            "id": "3458603",
            "problem": "Consider the role of proximal operators in Majorization-Minimization (MM) and Difference of Convex (DC) programming for sparse recovery. Let the Smoothly Clipped Absolute Deviation (SCAD) penalty, defined for parameters $a > 2$ and $\\lambda > 0$, be the nonconvex regularizer used in a one-dimensional surrogate subproblem. The SCAD penalty $p_{\\lambda,a}(x)$ is an even function with $p_{\\lambda,a}(0) = 0$, and its one-sided derivative for $x > 0$ is given by the piecewise rule: $p_{\\lambda,a}'(x) = \\lambda$ for $0 < x \\leq \\lambda$, $p_{\\lambda,a}'(x) = \\frac{a \\lambda - x}{a - 1}$ for $\\lambda < x \\leq a \\lambda$, and $p_{\\lambda,a}'(x) = 0$ for $x > a \\lambda$. These specifications are sufficient to characterize $p_{\\lambda,a}$ fully, due to symmetry about zero.\n\nStarting from the definition of the proximal operator of a proper lower semicontinuous function, $\\operatorname{prox}_{t p}(y)$ is the unique minimizer of the strictly convex quadratic perturbation:\n$$\n\\operatorname{prox}_{t p_{\\lambda,a}}(y) \\in \\arg\\min_{x \\in \\mathbb{R}} \\left\\{ \\frac{1}{2} (x - y)^{2} + t \\, p_{\\lambda,a}(x) \\right\\},\n$$\nwhere $t > 0$ is a given proximal parameter. Use first-order optimality and subdifferential conditions in one dimension to derive the proximal mapping of the SCAD penalty as a function of $y$. Identify the threshold values that partition the mapping into the three nontrivial regions for $y \\geq 0$. Then, for the specific parameters $\\lambda = 2$, $a = 3.5$, $t = 0.8$, and input $y = 4.3$, evaluate the proximal mapping $\\operatorname{prox}_{t p_{\\lambda,a}}(y)$ exactly.\n\nExpress your final answer as a single exact number, with no rounding.",
            "solution": "The problem requires us to first derive the proximal operator for the Smoothly Clipped Absolute Deviation (SCAD) penalty, $p_{\\lambda,a}(x)$, and then evaluate it for a specific set of parameters.\n\nThe proximal operator of a function $t p_{\\lambda,a}(x)$ is defined as the solution to the minimization problem:\n$$ \\operatorname{prox}_{t p_{\\lambda,a}}(y) = \\arg\\min_{x \\in \\mathbb{R}} \\left\\{ F(x) = \\frac{1}{2} (x - y)^{2} + t \\, p_{\\lambda,a}(x) \\right\\} $$\nwhere $t > 0$ is a proximal parameter.\n\nFor a minimizer $x^*$, the first-order optimality condition states that the zero vector must be in the subdifferential of the objective function $F(x)$ at $x^*$.\n$$ 0 \\in \\partial F(x^*) $$\nThe subdifferential of $F(x)$ is given by $\\partial F(x) = (x - y) + t \\, \\partial p_{\\lambda,a}(x)$. Thus, the optimality condition is:\n$$ 0 \\in (x^* - y) + t \\, \\partial p_{\\lambda,a}(x^*) \\quad \\iff \\quad y - x^* \\in t \\, \\partial p_{\\lambda,a}(x^*) $$\n\nThe SCAD penalty $p_{\\lambda,a}(x)$ is an even function, so $p_{\\lambda,a}(x) = p_{\\lambda,a}(-x)$. Its one-sided derivative for $x > 0$ is given as:\n$$ p_{\\lambda,a}'(x) = \\begin{cases} \\lambda & \\text{if } 0 < x \\leq \\lambda \\\\ \\frac{a \\lambda - x}{a - 1} & \\text{if } \\lambda < x \\leq a \\lambda \\\\ 0 & \\text{if } x > a \\lambda \\end{cases} $$\nThe SCAD penalty is continuously differentiable for $x \\neq 0$. At $x=0$, being an even function with derivative $\\lambda$ for $x \\to 0^+$, the subdifferential is the interval $[-\\lambda, \\lambda]$. Thus, the subdifferential $\\partial p_{\\lambda,a}(x)$ is:\n$$ \\partial p_{\\lambda,a}(x) = \\begin{cases} \\{ p_{\\lambda,a}'(x) \\} & \\text{if } x \\neq 0 \\\\ [-\\lambda, \\lambda] & \\text{if } x = 0 \\end{cases} $$\n\nDue to the symmetry of the problem ($p_{\\lambda,a}(x)$ is even), the sign of the solution $x^*$ will match the sign of the input $y$. That is, $\\operatorname{prox}_{t p_{\\lambda,a}}(y) = -\\operatorname{prox}_{t p_{\\lambda,a}}(-y)$. We can therefore derive the solution for $y \\geq 0$, which implies $x^* \\geq 0$.\n\nWe analyze the optimality condition $y - x^* \\in t \\, \\partial p_{\\lambda,a}(x^*)$ for $x^* \\ge 0$.\n\nCase 1: $x^*=0$.\nThe condition is $y - 0 \\in t \\, \\partial p_{\\lambda,a}(0)$, which is $y \\in t [-\\lambda, \\lambda]$. Since we assume $y \\ge 0$, this corresponds to $0 \\le y \\le t\\lambda$.\nSo, if $0 \\le y \\le t\\lambda$, the solution is $x^*=0$.\n\nCase 2: $0 < x^* \\leq \\lambda$.\nThe derivative is $p_{\\lambda,a}'(x^*) = \\lambda$. The optimality condition becomes $y - x^* = t \\lambda$.\nThis gives $x^* = y - t\\lambda$. For this solution to be in the range $(0, \\lambda]$, we must have $0 < y - t\\lambda \\leq \\lambda$, which implies $t\\lambda < y \\leq (t+1)\\lambda$.\n\nCase 3: $\\lambda < x^* \\leq a\\lambda$.\nThe derivative is $p_{\\lambda,a}'(x^*) = \\frac{a\\lambda - x^*}{a - 1}$. The optimality condition is $y - x^* = t \\left( \\frac{a\\lambda - x^*}{a - 1} \\right)$.\nWe solve for $x^*$:\n$$ (y - x^*)(a - 1) = t(a\\lambda - x^*) $$\n$$ (a - 1)y - (a - 1)x^* = at\\lambda - tx^* $$\n$$ (a - 1 - t)x^* = (a - 1)y - at\\lambda $$\nAssuming $a-1-t \\neq 0$, we have $x^* = \\frac{(a-1)y - at\\lambda}{a-1-t}$.\nFor SCAD, the parameter $a>2$ is standard. The quantity $t$ is a step size in algorithms, typically chosen such that $t < a-1$. This ensures the objective function remains sufficiently convex in this region. The problem parameters satisfy this ($a=3.5, t=0.8 \\implies a-1=2.5 > 0.8$).\nFor this solution to be in $(\\lambda, a\\lambda]$, we check the boundaries for $y$:\n$x^* > \\lambda \\implies \\frac{(a-1)y - at\\lambda}{a-1-t} > \\lambda \\implies (a-1)y - at\\lambda > \\lambda(a-1-t) \\implies (a-1)y > a\\lambda - \\lambda t + at\\lambda - \\lambda t \\implies (a-1)y > \\lambda(a-1) \\implies y > \\lambda$. Actually, the calculation in the original was `(a-1)y > a\\lambda(t+1) - \\lambda(t+1)`. Let's re-do it: $(a-1)y > at\\lambda + a\\lambda - \\lambda - t\\lambda = \\lambda(at+a-1-t) = \\lambda((a-1)(t+1))$. So $y > \\lambda(t+1)$. This seems correct.\n$x^* \\leq a\\lambda \\implies \\frac{(a-1)y - at\\lambda}{a-1-t} \\leq a\\lambda \\implies (a-1)y - at\\lambda \\leq a\\lambda(a-1-t) \\implies (a-1)y \\leq a\\lambda(a-1) \\implies y \\leq a\\lambda$.\nSo, this case holds for $(t+1)\\lambda < y \\leq a\\lambda$.\n\nCase 4: $x^* > a\\lambda$.\nThe derivative is $p_{\\lambda,a}'(x^*) = 0$. The optimality condition is $y - x^* = t \\cdot 0 = 0$, which gives $x^* = y$.\nFor this solution to be in the range $(a\\lambda, \\infty)$, we must have $y > a\\lambda$.\n\nCombining these cases for $y \\ge 0$, the proximal mapping is:\n$$ \\operatorname{prox}_{t p_{\\lambda,a}}(y) = \\begin{cases} 0 & \\text{if } 0 \\leq y \\leq t\\lambda \\\\ y - t\\lambda & \\text{if } t\\lambda < y \\leq (t+1)\\lambda \\\\ \\frac{(a-1)y - at\\lambda}{a-1-t} & \\text{if } (t+1)\\lambda < y \\leq a\\lambda \\\\ y & \\text{if } y > a\\lambda \\end{cases} $$\nThe threshold values that partition the mapping for $y \\ge 0$ into the three non-trivial regions are $t\\lambda$, $(t+1)\\lambda$, and $a\\lambda$.\n\nNow, we evaluate this for the given parameters: $\\lambda = 2$, $a = 3.5$, $t = 0.8$, and $y = 4.3$.\nFirst, calculate the threshold values:\n1. $t\\lambda = 0.8 \\times 2 = 1.6$.\n2. $(t+1)\\lambda = (0.8 + 1) \\times 2 = 1.8 \\times 2 = 3.6$.\n3. $a\\lambda = 3.5 \\times 2 = 7$.\n\nNext, we locate the input $y = 4.3$ with respect to these thresholds.\nWe see that $3.6 < 4.3 \\leq 7$. This means $y$ falls into the range $(t+1)\\lambda < y \\leq a\\lambda$.\n\nWe use the formula for this region:\n$$ x^* = \\frac{(a-1)y - at\\lambda}{a-1-t} $$\nSubstitute the given values:\n$$ a-1 = 3.5 - 1 = 2.5 $$\n$$ a-1-t = 2.5 - 0.8 = 1.7 $$\n$$ at\\lambda = 3.5 \\times 0.8 \\times 2 = 5.6 $$\n$$ y = 4.3 $$\nPlugging these into the formula:\n$$ x^* = \\frac{(2.5)(4.3) - 5.6}{1.7} = \\frac{10.75 - 5.6}{1.7} = \\frac{5.15}{1.7} = \\frac{515}{170} = \\frac{103}{34}$$\nTo ensure an exact answer, we can convert to fractions earlier:\n$a = \\frac{7}{2}$, $t = \\frac{4}{5}$, $y = \\frac{43}{10}$, $\\lambda = 2$.\n$a-1 = \\frac{5}{2}$.\n$a-1-t = \\frac{5}{2} - \\frac{4}{5} = \\frac{25 - 8}{10} = \\frac{17}{10}$.\n$at\\lambda = \\frac{7}{2} \\times \\frac{4}{5} \\times 2 = \\frac{28}{5}$.\nThe numerator is $(a-1)y - at\\lambda$:\n$$ \\left(\\frac{5}{2}\\right) \\left(\\frac{43}{10}\\right) - \\frac{28}{5} = \\frac{215}{20} - \\frac{112}{20} = \\frac{103}{20} $$\nNow, we compute the final value of $x^*$:\n$$ x^* = \\frac{\\frac{103}{20}}{\\frac{17}{10}} = \\frac{103}{20} \\times \\frac{10}{17} = \\frac{103}{2 \\times 17} = \\frac{103}{34} $$\nThe value is exact as required.",
            "answer": "$$\\boxed{\\frac{103}{34}}$$"
        },
        {
            "introduction": "Real-world datasets are often contaminated with outliers, making robust loss functions essential for reliable statistical modeling and machine learning. This practice  guides you through designing an algorithm for a challenging objective that combines the robust Tukey's biweight loss with a non-convex log-sum penalty. You will apply the Difference-of-Convex (DC) programming framework to construct a full convex surrogate, a key step in deriving a powerful Majorization-Minimization algorithm known as the Convex-Concave Procedure (CCP).",
            "id": "3458611",
            "problem": "Consider the compressed sensing model with measurement matrix $A \\in \\mathbb{R}^{m \\times n}$, rows $\\{a_{i}^{\\top}\\}_{i=1}^{m}$, and observations $y \\in \\mathbb{R}^{m}$. Define the residuals $r_{i}(x) = y_{i} - a_{i}^{\\top} x$ for $x \\in \\mathbb{R}^{n}$. The objective is a robust data-fit combined with a nonconvex sparse penalty:\n$$\nF(x) = \\sum_{i=1}^{m} \\rho_{\\mathrm{T}}(r_{i}(x); c) + \\lambda \\sum_{j=1}^{n} \\ln\\!\\big(1 + \\tfrac{|x_{j}|}{\\epsilon}\\big),\n$$\nwhere $\\rho_{\\mathrm{T}}(\\cdot; c)$ is the Tukey’s biweight loss with tuning parameter $c > 0$, given by\n$$\n\\rho_{\\mathrm{T}}(r; c) =\n\\begin{cases}\n\\tfrac{c^{2}}{6} \\Big( 1 - \\big( 1 - (r/c)^{2} \\big)^{3} \\Big), & |r| \\leq c, \\\\\n\\tfrac{c^{2}}{6}, & |r| > c,\n\\end{cases}\n$$\nand $\\lambda > 0$, $\\epsilon > 0$ are penalty parameters. Assume a bounded residual domain determined by a trust region\n$$\n\\mathcal{D} = \\big\\{ x \\in \\mathbb{R}^{n} \\,:\\, |r_{i}(x)| \\leq c \\text{ for all } i = 1,\\dots,m \\big\\}.\n$$\n\nYou will employ the Difference-of-Convex (DC) programming framework and the Convex-Concave Procedure (CCP), a form of Majorization-Minimization (MM) tailored to DC functions. Starting from first principles, complete the following:\n\n1. Show that on the domain $|r| \\leq c$ the Tukey’s biweight loss $\\rho_{\\mathrm{T}}(r; c)$ admits a DC decomposition by identifying the smallest constant $\\alpha \\geq 0$ such that $g(r) = \\rho_{\\mathrm{T}}(r; c) + \\alpha r^{2}$ is convex on $[-c, c]$, and hence $\\rho_{\\mathrm{T}}(r; c) = g(r) - h(r)$ with $h(r) = \\alpha r^{2}$.\n\n2. The nonconvex sparse penalty $\\phi(x) = \\lambda \\sum_{j=1}^{n} \\ln\\!\\big(1 + \\tfrac{|x_{j}|}{\\epsilon}\\big)$ is concave in $|x_{j}|$. Construct a DC decomposition of the total objective $F(x)$ of the form $F(x) = G(x) - H(x)$ with $G$ and $H$ convex functions, by introducing a parameter $\\gamma > 0$ and using the fact that $-\\ln(\\cdot)$ is convex.\n\n3. For an iterate $x^{k} \\in \\mathcal{D}$, write the one-step CCP subproblem that minimizes the affine majorization of $H$ at $x^{k}$ added to $G$. Use the chain rule to express the gradient contribution from the residual part and a valid subgradient for the penalty part at $x^{k}$. Provide the explicit closed-form expression for the convex surrogate objective to be minimized at iteration $k$.\n\nExpress your final result as a single closed-form analytic expression for the CCP surrogate objective at iteration $k$. No rounding is required. Angles, if any appear, must be in radians.",
            "solution": "We begin with definitions and basic properties required for the derivation.\n\nOn the bounded residual domain $|r| \\leq c$, the Tukey’s biweight loss simplifies to a polynomial. Specifically, for $|r| \\leq c$,\n$$\n\\rho_{\\mathrm{T}}(r; c) = \\tfrac{c^{2}}{6} \\Big( 1 - \\big( 1 - (r/c)^{2} \\big)^{3} \\Big).\n$$\nExpanding the cubic yields\n$$\n\\big( 1 - (r/c)^{2} \\big)^{3} = 1 - 3(r/c)^{2} + 3(r/c)^{4} - (r/c)^{6},\n$$\nso\n$$\n\\rho_{\\mathrm{T}}(r; c) = \\tfrac{c^{2}}{6} \\Big( 3(r/c)^{2} - 3(r/c)^{4} + (r/c)^{6} \\Big)\n= \\tfrac{1}{2} r^{2} - \\tfrac{1}{2 c^{2}} r^{4} + \\tfrac{1}{6 c^{4}} r^{6}.\n$$\nWe compute the second derivative on $|r| \\leq c$:\n$$\n\\rho_{\\mathrm{T}}'(r; c) = r - \\tfrac{2}{c^{2}} r^{3} + \\tfrac{1}{c^{4}} r^{5},\n\\quad\n\\rho_{\\mathrm{T}}''(r; c) = 1 - \\tfrac{6}{c^{2}} r^{2} + \\tfrac{5}{c^{4}} r^{4}.\n$$\nLet $t = (r^{2}/c^{2}) \\in [0, 1]$. Then\n$$\n\\rho_{\\mathrm{T}}''(r; c) = 1 - 6 t + 5 t^{2} = 5 t^{2} - 6 t + 1.\n$$\nThe quadratic $5 t^{2} - 6 t + 1$ attains its minimum at $t^{\\star} = \\tfrac{6}{2 \\cdot 5} = \\tfrac{3}{5}$, with minimum value\n$$\n5 \\Big(\\tfrac{3}{5}\\Big)^{2} - 6 \\Big(\\tfrac{3}{5}\\Big) + 1\n= 5 \\cdot \\tfrac{9}{25} - \\tfrac{18}{5} + 1\n= \\tfrac{9}{5} - \\tfrac{18}{5} + 1\n= -\\tfrac{9}{5} + 1\n= -\\tfrac{4}{5}.\n$$\nTherefore,\n$$\n\\min_{|r| \\leq c} \\rho_{\\mathrm{T}}''(r; c) = -\\tfrac{4}{5}.\n$$\nTo obtain a convex function $g(r) = \\rho_{\\mathrm{T}}(r; c) + \\alpha r^{2}$ on $[-c, c]$, we require\n$$\ng''(r) = \\rho_{\\mathrm{T}}''(r; c) + 2 \\alpha \\geq 0 \\quad \\text{for all } |r| \\leq c,\n$$\nwhich is ensured by choosing $\\alpha$ such that\n$$\n2 \\alpha \\geq \\tfrac{4}{5} \\quad \\Longleftrightarrow \\quad \\alpha \\geq \\tfrac{2}{5}.\n$$\nThe smallest admissible constant is $\\alpha^{\\star} = \\tfrac{2}{5}$. Hence the DC decomposition on $|r| \\leq c$ is\n$$\n\\rho_{\\mathrm{T}}(r; c) = g(r) - h(r), \\quad g(r) = \\rho_{\\mathrm{T}}(r; c) + \\tfrac{2}{5} r^{2}, \\quad h(r) = \\tfrac{2}{5} r^{2}.\n$$\nNote that $g$ is convex on $[-c, c]$ by construction, and $h$ is a convex quadratic.\n\nNext, we construct a DC decomposition for the full objective. The sparse penalty\n$$\n\\phi(x) = \\lambda \\sum_{j=1}^{n} \\ln\\!\\big(1 + \\tfrac{|x_{j}|}{\\epsilon}\\big)\n$$\nis a concave function. This is because it is a sum of terms of the form $\\lambda \\ln(1+|x_j|/\\epsilon)$, and each such term is a concave function of $x_j$. Introduce a parameter $\\gamma > 0$ and define\n$$\nq(x) = \\gamma \\|x\\|_{1} - \\phi(x) = \\gamma \\|x\\|_{1} - \\lambda \\sum_{j=1}^{n} \\ln\\!\\big(1 + \\tfrac{|x_{j}|}{\\epsilon}\\big).\n$$\nSince $\\|x\\|_{1}$ is convex and $-\\phi(x)$ is convex (as $\\phi(x)$ is concave), their sum $q(x)$ is convex for any $\\gamma \\ge 0$. Then\n$$\n\\phi(x) = \\gamma \\|x\\|_{1} - q(x),\n$$\nwhich is a DC decomposition of the penalty.\n\nCombining the DC decompositions for the loss and the penalty, the full objective can be written as\n$$\nF(x) = \\sum_{i=1}^{m} \\rho_{\\mathrm{T}}(r_{i}(x); c) + \\phi(x)\n= \\underbrace{\\sum_{i=1}^{m} g(r_{i}(x)) + \\gamma \\|x\\|_{1}}_{G(x)}\n- \\underbrace{\\Big( \\sum_{i=1}^{m} h(r_{i}(x)) + q(x) \\Big)}_{H(x)}.\n$$\nHere $G$ and $H$ are convex on the trust region $\\mathcal{D}$.\n\nWe now derive the Convex-Concave Procedure (CCP) subproblem at an iterate $x^{k} \\in \\mathcal{D}$. The CCP minimizes the affine majorization of $H$ at $x^{k}$ added to $G$, namely\n$$\nx^{k+1} \\in \\arg\\min_{x} \\Big\\{ G(x) - \\big( H(x^{k}) + \\langle \\nabla H(x^{k}), x - x^{k} \\rangle \\big) \\Big\\}.\n$$\nDropping constants independent of $x$, we must minimize\n$$\nf_{k}(x) = G(x) - \\langle \\nabla H(x^{k}), x \\rangle.\n$$\nWe compute $\\nabla H(x^{k})$ term by term. For the residual component,\n$$\nh(r) = \\tfrac{2}{5} r^{2} \\quad \\Rightarrow \\quad \\frac{\\mathrm{d}}{\\mathrm{d}r} h(r) = \\tfrac{4}{5} r.\n$$\nBy the chain rule,\n$$\n\\nabla_{x} h(r_{i}(x)) = \\tfrac{4}{5} r_{i}(x) \\, \\nabla_{x} r_{i}(x) = \\tfrac{4}{5} r_{i}(x) \\, (-a_{i}),\n$$\nso at $x^{k}$,\n$$\n\\nabla_{x} \\bigg( \\sum_{i=1}^{m} h(r_{i}(x)) \\bigg) \\bigg|_{x = x^{k}} = - \\tfrac{4}{5} \\sum_{i=1}^{m} r_{i}(x^{k}) \\, a_{i}.\n$$\nFor $q(x) = \\gamma \\|x\\|_{1} - \\lambda \\sum_{j=1}^{n} \\ln\\!\\big(1 + \\tfrac{|x_{j}|}{\\epsilon}\\big)$, a valid subgradient at $x^{k}$ is obtained componentwise. Let $s_{j}^{k} \\in \\partial |x_{j}| \\big|_{x_{j} = x_{j}^{k}}$, i.e., $s_{j}^{k} = \\operatorname{sign}(x_{j}^{k})$ if $x_{j}^{k} \\neq 0$ and $s_{j}^{k} \\in [-1, 1]$ if $x_{j}^{k} = 0$. Then\n$$\n\\partial_{x_{j}} \\bigg( - \\lambda \\ln\\!\\big(1 + \\tfrac{|x_{j}|}{\\epsilon}\\big) \\bigg) \\bigg|_{x_{j} = x_{j}^{k}}\n= - \\lambda \\cdot \\frac{1}{\\epsilon + |x_{j}^{k}|} \\cdot s_{j}^{k},\n$$\nand the subgradient of $q$ at $x^{k}$ is\n$$\nz_{j}^{k} = \\gamma \\, s_{j}^{k} - \\lambda \\cdot \\frac{s_{j}^{k}}{\\epsilon + |x_{j}^{k}|}, \\quad j = 1,\\dots,n,\n$$\nwhich we collect into $z^{k} \\in \\partial q(x^{k})$.\n\nTherefore, a valid subgradient for $H$ at $x^k$ is\n$$\n\\nabla H(x^{k}) = - \\tfrac{4}{5} \\sum_{i=1}^{m} r_{i}(x^{k}) \\, a_{i} \\;+\\; z^{k}.\n$$\nThe CCP surrogate objective to minimize at iteration $k$ is\n$$\nf_{k}(x) = \\sum_{i=1}^{m} g\\big(r_{i}(x)\\big) + \\gamma \\|x\\|_{1} - \\Big\\langle - \\tfrac{4}{5} \\sum_{i=1}^{m} r_{i}(x^{k}) \\, a_{i} + z^{k}, \\; x \\Big\\rangle.\n$$\nOn the domain $|r_{i}(x)| \\leq c$, we have\n$$\ng(r) = \\rho_{\\mathrm{T}}(r; c) + \\tfrac{2}{5} r^{2}\n= \\Big( \\tfrac{1}{2} r^{2} - \\tfrac{1}{2 c^{2}} r^{4} + \\tfrac{1}{6 c^{4}} r^{6} \\Big) + \\tfrac{2}{5} r^{2}\n= \\tfrac{9}{10} r^{2} - \\tfrac{1}{2 c^{2}} r^{4} + \\tfrac{1}{6 c^{4}} r^{6}.\n$$\nThus,\n$$\nf_{k}(x) =\n\\sum_{i=1}^{m} \\Big( \\tfrac{9}{10} \\big( y_{i} - a_{i}^{\\top} x \\big)^{2}\n- \\tfrac{1}{2 c^{2}} \\big( y_{i} - a_{i}^{\\top} x \\big)^{4}\n+ \\tfrac{1}{6 c^{4}} \\big( y_{i} - a_{i}^{\\top} x \\big)^{6} \\Big)\n+ \\gamma \\|x\\|_{1}\n+ \\tfrac{4}{5} \\sum_{i=1}^{m} r_{i}(x^{k}) \\, a_{i}^{\\top} x\n- \\sum_{j=1}^{n} \\Big( \\gamma - \\frac{\\lambda}{\\epsilon + |x_{j}^{k}|} \\Big) s_{j}^{k} \\, x_{j}.\n$$\nThis is a convex function of $x$ on the trust region $\\mathcal{D}$, as required by the Convex-Concave Procedure. It provides the explicit one-iteration CCP subproblem objective for minimizing the original nonconvex robust sparse objective under the DC programming framework, with the smallest convexifying constant $\\alpha^{\\star} = \\tfrac{2}{5}$ for Tukey’s biweight on $[-c, c]$ and the DC decomposition of the log-sum penalty via $\\gamma \\|x\\|_{1} - q(x)$.",
            "answer": "$$\\boxed{\\sum_{i=1}^{m}\\!\\Big(\\tfrac{9}{10}\\big(y_{i}-a_{i}^{\\top}x\\big)^{2}-\\tfrac{1}{2c^{2}}\\big(y_{i}-a_{i}^{\\top}x\\big)^{4}+\\tfrac{1}{6c^{4}}\\big(y_{i}-a_{i}^{\\top}x\\big)^{6}\\Big)+\\gamma\\|x\\|_{1}+\\tfrac{4}{5}\\sum_{i=1}^{m}r_{i}(x^{k})\\,a_{i}^{\\top}x-\\sum_{j=1}^{n}\\Big(\\gamma-\\frac{\\lambda}{\\epsilon+|x_{j}^{k}|}\\Big)s_{j}^{k}\\,x_{j}}$$"
        },
        {
            "introduction": "The practical performance of a Majorization-Minimization (MM) algorithm is highly dependent on the choice of the majorizing surrogate function, which often involves a trade-off between the tightness of the bound and computational simplicity. This hands-on coding exercise  directs you to implement and compare two distinct MM schemes for sparse recovery: one using a simple, global quadratic majorizer and another based on a tighter, separable quadratic majorizer. By analyzing the resulting sparsity patterns across different data conditions, you will develop practical intuition for how theoretical choices in algorithm design impact real-world outcomes.",
            "id": "3458632",
            "problem": "Consider the sparse recovery objective in compressed sensing given by the sum of a smooth data fidelity term and a nonconvex sparsity-inducing penalty. Let $A\\in\\mathbb{R}^{m\\times n}$, $b\\in\\mathbb{R}^{m}$, and $x\\in\\mathbb{R}^{n}$. Define the smooth term $f(x)=\\tfrac{1}{2}\\|Ax-b\\|_{2}^{2}$ and the concave separable penalty $p(x)=\\lambda\\sum_{i=1}^{n}\\log\\!\\big(1+\\tfrac{|x_{i}|}{\\varepsilon}\\big)$ with $\\lambda>0$ and $\\varepsilon>0$. The goal is to minimize the composite objective $F(x)=f(x)+p(x)$ via Majorization-Minimization (MM), and to compare two distinct majorizers for the smooth term: a quadratic majorizer based on a global Lipschitz bound and a separable diagonal majorizer based on Gershgorin-type bounds. You must implement both MM schemes and study their impact on the sparsity pattern of solutions.\n\nUse the following foundational principles:\n- The gradient of $f$ is $\\nabla f(x)=A^{\\top}(Ax-b)$ and has Lipschitz constant bounded by $L\\ge\\|A^{\\top}A\\|_{2}$.\n- A valid quadratic upper bound (majorizer) for $f$ at $y$ is $f(x)\\le f(y)+\\nabla f(y)^{\\top}(x-y)+\\tfrac{L}{2}\\|x-y\\|_{2}^{2}$ whenever $L\\ge\\|\\nabla^{2}f\\|_{2}$.\n- A separable quadratic upper bound can be constructed via a diagonal matrix $D=\\mathrm{diag}(d)$ with entries $d_{i}\\ge\\sum_{j=1}^{n}|(A^{\\top}A)_{ij}|$, ensuring $v^{\\top}A^{\\top}A\\,v\\le v^{\\top}Dv$ for all $v\\in\\mathbb{R}^{n}$.\n\nImplement two MM algorithms for minimizing $F(x)$:\n- In the first algorithm, majorize $f$ using a global quadratic bound parameterized by $L\\ge\\|A^{\\top}A\\|_{2}$ and use a first-order tangent majorization for each concave penalty component.\n- In the second algorithm, majorize $f$ using the separable diagonal bound $D=\\mathrm{diag}(d)$ constructed from $A^{\\top}A$ via Gershgorin-type row sums, together with the same first-order tangent majorization for the concave penalty.\n\nIn both cases, at each MM iteration, update the weights for the tangent majorization of $p$ using the derivative of the concave function with respect to $|x_{i}|$, and perform a proximal-like update that is separable across coordinates. Initialize $x$ at the zero vector and iterate until a stopping criterion based on relative change is satisfied. After convergence, determine the sparsity pattern (support) of the final estimate by thresholding at $\\tau=10^{-6}$, i.e., consider index $i$ active if $|x_{i}|\\ge\\tau$.\n\nStudy the impact on sparsity by reporting for each test case:\n- The number of active coordinates for the global quadratic majorizer (an integer).\n- The number of active coordinates for the separable diagonal majorizer (an integer).\n- Whether the two supports are identical (a boolean).\n- The size of the symmetric difference between the supports (an integer).\n\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list of four-element lists, enclosed in square brackets. Each four-element list should be of the form $[\\text{nnz\\_global},\\text{nnz\\_diag},\\text{supports\\_equal},\\text{symdiff\\_size}]$.\n\nTest Suite:\n- Case $1$ (general random design, moderate regularization, small noise): $m=40$, $n=60$, $A$ with independent and identically distributed standard normal entries scaled by $1/\\sqrt{m}$, a ground-truth $x^{\\star}$ with $8$ nonzero entries drawn from a standard normal distribution at random positions, $b=Ax^{\\star}+\\eta$ with $\\eta$ i.i.d. normal of standard deviation $0.01$, $\\lambda=0.15$, $\\varepsilon=10^{-3}$.\n- Case $2$ (orthonormal columns, no noise): $m=50$, $n=50$, $A$ obtained as the $Q$ factor from a QR decomposition of a random standard normal matrix (thereby $A^{\\top}A=I$), a ground-truth $x^{\\star}$ with $5$ nonzero entries at random positions from a standard normal distribution, $b=Ax^{\\star}$, $\\lambda=0.08$, $\\varepsilon=10^{-3}$. This case probes the boundary where the global and separable majorizers coincide.\n- Case $3$ (highly correlated columns, moderate noise): $m=40$, $n=40$, $A$ with standard normal entries scaled by $1/\\sqrt{m}$ and then modified so that columns $5$ through $9$ are nearly collinear with column $1$ by setting $A_{:,j}=A_{:,1}+\\delta_{j}$ with small i.i.d. normal perturbations $\\delta_{j}$ of standard deviation $0.01$, a ground-truth $x^{\\star}$ with $6$ nonzeros including indices from the correlated group, $b=Ax^{\\star}+\\eta$ with $\\eta$ i.i.d. normal of standard deviation $0.02$, $\\lambda=0.20$, $\\varepsilon=10^{-3}$.\n- Case $4$ (strong regularization, likely all-zero solution): $m=30$, $n=50$, $A$ with standard normal entries scaled by $1/\\sqrt{m}$, $b$ drawn from a standard normal distribution, $\\lambda=1.00$, $\\varepsilon=10^{-3}$.\n\nAll random instances must be generated with a fixed seed so that results are reproducible. The angle unit is not applicable. There are no physical units. The final output format must be exactly a single line containing the list of results for the four cases, e.g., $[[3,2,False,1],[\\dots]]$ with no extra spaces or text.",
            "solution": "The problem is valid. It is a well-posed numerical experiment in the field of non-convex optimization for sparse signal recovery, based on established scientific principles and stated with objective, formal precision.\n\nThe problem asks to minimize the composite objective function $F(x) = f(x) + p(x)$, where $x \\in \\mathbb{R}^n$. The function is composed of a smooth, convex data fidelity term $f(x) = \\frac{1}{2}\\|Ax-b\\|_2^2$ and a non-convex, sparsity-inducing penalty term $p(x) = \\lambda\\sum_{i=1}^{n}\\log(1+\\frac{|x_i|}{\\varepsilon})$. The minimization is to be performed using a Majorization-Minimization (MM) algorithm. At each iteration $k$ of an MM algorithm, the original complex objective function $F(x)$ is replaced by a simpler surrogate function $G(x|x^{(k)})$, which is an upper bound of $F(x)$ (i.e., $G(x|x^{(k)}) \\ge F(x)$ for all $x$) and is tight at the current iterate $x^{(k)}$ (i.e., $G(x^{(k)}|x^{(k)}) = F(x^{(k)})$). The next iterate is then found by minimizing this surrogate: $x^{(k+1)} = \\arg\\min_x G(x|x^{(k)})$.\n\nWe construct the surrogate $G(x|x^{(k)})$ by majorizing the two components of $F(x)$ separately, such that $G(x|x^{(k)}) = U_f(x|x^{(k)}) + U_p(x|x^{(k)})$, where $U_f$ and $U_p$ are majorizers for $f$ and $p$, respectively.\n\n**Majorization of the Penalty Term $p(x)$**\n\nThe penalty $p(x)$ is a sum of separable concave functions. Let $\\phi(t) = \\lambda \\log(1+t/\\varepsilon)$ for $t \\ge 0$. This function is concave. We can majorize it using its first-order Taylor expansion (the tangent line) at a point $t_k \\ge 0$:\n$$\n\\phi(t) \\le \\phi(t_k) + \\phi'(t_k)(t - t_k)\n$$\nThe derivative is $\\phi'(t) = \\frac{\\lambda}{\\varepsilon+t}$. Applying this to each component $|x_i|$ with $t = |x_i|$ and $t_k = |x_i^{(k)}|$, we get:\n$$\n\\lambda \\log\\left(1+\\frac{|x_i|}{\\varepsilon}\\right) \\le \\lambda \\log\\left(1+\\frac{|x_i^{(k)}|}{\\varepsilon}\\right) + \\frac{\\lambda}{\\varepsilon+|x_i^{(k)}|}(|x_i| - |x_i^{(k)}|)\n$$\nSumming over all $i=1, \\dots, n$, we obtain a majorizer for $p(x)$ at $x^{(k)}$:\n$$\nU_p(x|x^{(k)}) = p(x^{(k)}) + \\sum_{i=1}^n \\frac{\\lambda}{\\varepsilon+|x_i^{(k)}|}(|x_i| - |x_i^{(k)}|)\n$$\nIgnoring terms that are constant with respect to $x$, the variable part of this majorizer is a weighted $\\ell_1$-norm: $\\sum_{i=1}^n w_i^{(k)} |x_i|$, where the weights are $w_i^{(k)} = \\frac{\\lambda}{\\varepsilon+|x_i^{(k)}|}$. This linearization of the concave part is a key step in Difference-of-Convex (DC) programming.\n\n**Majorization of the Data Fidelity Term $f(x)$**\n\nThe function $f(x)$ is smooth and its gradient is $\\nabla f(x) = A^\\top(Ax-b)$ with Hessian $\\nabla^2 f(x) = A^\\top A$. A quadratic function $U_f(x|x^{(k)})$ is a majorizer for $f(x)$ at $x^{(k)}$ if $U_f(x|x^{(k)}) \\ge f(x)$ for all $x$, $U_f(x^{(k)}|x^{(k)}) = f(x^{(k)})$, and $\\nabla U_f(x^{(k)}|x^{(k)}) = \\nabla f(x^{(k)})$. A standard construction is:\n$$\nU_f(x|x^{(k)}) = f(x^{(k)}) + \\nabla f(x^{(k)})^\\top(x-x^{(k)}) + \\frac{1}{2}(x-x^{(k)})^\\top M (x-x^{(k)})\n$$\nwhere $M$ is a positive semi-definite matrix such that $M \\succeq A^\\top A$. We will explore two choices for $M$.\n\n**Algorithm 1: Global Quadratic Majorizer**\n\nThe first algorithm uses a simple isotropic majorant by setting $M = L I_n$, where $I_n$ is the $n \\times n$ identity matrix and $L$ is a scalar. The condition $L I_n \\succeq A^\\top A$ is satisfied if $L \\ge \\lambda_{\\max}(A^\\top A) = \\|A^\\top A\\|_2$, the spectral norm of $A^\\top A$. At iteration $k+1$, we minimize the surrogate:\n$$\nx^{(k+1)} = \\arg\\min_x \\left\\{ f(x^{(k)}) + \\nabla f(x^{(k)})^\\top(x-x^{(k)}) + \\frac{L}{2}\\|x-x^{(k)}\\|_2^2 + \\sum_{i=1}^n w_i^{(k)}|x_i| \\right\\}\n$$\nCompleting the square, this is equivalent to solving a proximal problem:\n$$\nx^{(k+1)} = \\arg\\min_x \\left\\{ \\frac{L}{2} \\left\\| x - \\left(x^{(k)} - \\frac{1}{L}\\nabla f(x^{(k)})\\right) \\right\\|_2^2 + \\sum_{i=1}^n w_i^{(k)}|x_i| \\right\\}\n$$\nThe solution is given by the soft-thresholding operator $S_{\\alpha}(\\cdot)$:\n$$\nx_i^{(k+1)} = S_{w_i^{(k)}/L}\\left(z_i^{(k)}\\right) = \\text{sign}(z_i^{(k)}) \\max\\left(0, |z_i^{(k)}| - \\frac{w_i^{(k)}}{L}\\right)\n$$\nwhere $z^{(k)} = x^{(k)} - \\frac{1}{L}A^\\top(Ax^{(k)}-b)$.\n\n**Algorithm 2: Separable Diagonal Majorizer**\n\nThe second algorithm employs a tighter, anisotropic majorant by choosing $M=D$, where $D$ is a diagonal matrix. The condition $D \\succeq A^\\top A$ is ensured if $D-A^\\top A$ is positive semi-definite. A sufficient condition is that $D-A^\\top A$ is diagonally dominant. This is achieved by setting the diagonal entries of $D$ using Gershgorin-type bounds:\n$$\nd_i = (D)_{ii} = \\sum_{j=1}^n |(A^\\top A)_{ij}|\n$$\nThis choice of $D$ provides a separable quadratic surrogate. The minimization problem becomes:\n$$\nx^{(k+1)} = \\arg\\min_x \\left\\{ \\frac{1}{2}(x - z^{(k)})^\\top D (x - z^{(k)}) + \\sum_{i=1}^n w_i^{(k)}|x_i| \\right\\}\n$$\nwhere $z^{(k)} = x^{(k)} - D^{-1}\\nabla f(x^{(k)})$. Since $D$ is diagonal, this problem decouples into $n$ independent scalar problems:\n$$\nx_i^{(k+1)} = \\arg\\min_{x_i} \\left\\{ \\frac{d_i}{2}(x_i - z_i^{(k)})^2 + w_i^{(k)}|x_i| \\right\\}\n$$\nThe solution is again given by soft-thresholding, but with coordinate-specific parameters:\n$$\nx_i^{(k+1)} = S_{w_i^{(k)}/d_i}\\left(z_i^{(k)}\\right) = \\text{sign}(z_i^{(k)}) \\max\\left(0, |z_i^{(k)}| - \\frac{w_i^{(k)}}{d_i}\\right)\n$$\nwhere $z_i^{(k)} = x_i^{(k)} - \\frac{1}{d_i} [A^\\top(Ax^{(k)}-b)]_i$.\n\n**Implementation and Analysis**\n\nFor each test case, both algorithms are initialized with $x^{(0)}=0$ and run until the relative change in the iterate, i.e., $\\|x^{(k+1)}-x^{(k)}\\|_2/(\\|x^{(k)}\\|_2+\\delta)$ for a small $\\delta > 0$, falls below a tolerance of $10^{-6}$, or a maximum of $5000$ iterations is reached. After convergence, the support (set of indices of non-zero entries) of each solution vector is determined by thresholding the absolute values of its components at $\\tau=10^{-6}$. Finally, we report the number of non-zeroes for each algorithm, whether their supports are identical, and the size of the symmetric difference between the two supports. All random quantities are generated using a fixed seed for reproducibility.",
            "answer": "```python\nimport numpy as np\n\ndef soft_threshold(z, t):\n    \"\"\"Soft-thresholding operator.\"\"\"\n    return np.sign(z) * np.maximum(0, np.abs(z) - t)\n\ndef run_mm_algorithm(A, b, lam, eps, majorizer_type, max_iter=5000, tol=1e-6):\n    \"\"\"\n    Runs the Majorization-Minimization algorithm for the sparse recovery problem.\n    'lam' is lambda, 'eps' is epsilon.\n    \"\"\"\n    m, n = A.shape\n    x = np.zeros(n)\n    AtA = A.T @ A\n\n    if majorizer_type == 'global':\n        # Use spectral norm of A.T @ A for the Lipschitz constant L\n        # L = ||A^T A||_2 = sigma_max(A)^2\n        try:\n            # Using eigvalsh is faster and more stable for symmetric matrices\n            L = np.linalg.eigvalsh(AtA)[-1]\n        except np.linalg.LinAlgError:\n            # Fallback to SVD if eigendecomposition fails\n             s = np.linalg.svd(A, compute_uv=False)\n             L = s[0]**2\n        \n        if L < 1e-9: # handle L being zero or very small\n            L = 1.0\n\n        for k in range(max_iter):\n            x_old = x.copy()\n            grad_f = AtA @ x - A.T @ b\n            weights = lam / (eps + np.abs(x))\n            \n            z = x - (1/L) * grad_f\n            x = soft_threshold(z, weights / L)\n\n            rel_change = np.linalg.norm(x - x_old) / (np.linalg.norm(x_old) + 1e-8)\n            if rel_change < tol:\n                break\n\n    elif majorizer_type == 'diag':\n        # Use Gershgorin-type bounds for the diagonal majorizer D\n        d = np.sum(np.abs(AtA), axis=1)\n        d[d < 1e-9] = 1.0 # Avoid division by zero\n\n        for k in range(max_iter):\n            x_old = x.copy()\n            grad_f = AtA @ x - A.T @ b\n            weights = lam / (eps + np.abs(x))\n\n            z = x - (1 / d) * grad_f\n            x = soft_threshold(z, weights / d)\n\n            rel_change = np.linalg.norm(x - x_old) / (np.linalg.norm(x_old) + 1e-8)\n            if rel_change < tol:\n                break\n    else:\n        raise ValueError(\"Invalid majorizer_type specified.\")\n\n    return x\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and generate the final output.\n    \"\"\"\n    rng = np.random.default_rng(0)\n    \n    test_cases = [\n        # Case 1\n        {'m': 40, 'n': 60, 'k': 8, 'noise_std': 0.01, 'lam': 0.15, 'eps': 1e-3, 'type': 'general'},\n        # Case 2\n        {'m': 50, 'n': 50, 'k': 5, 'noise_std': 0.0, 'lam': 0.08, 'eps': 1e-3, 'type': 'orthonormal'},\n        # Case 3\n        {'m': 40, 'n': 40, 'k': 6, 'noise_std': 0.02, 'lam': 0.20, 'eps': 1e-3, 'type': 'correlated'},\n        # Case 4\n        {'m': 30, 'n': 50, 'k': 0, 'noise_std': 0.0, 'lam': 1.00, 'eps': 1e-3, 'type': 'strong_reg'}\n    ]\n\n    results = []\n    support_thresh = 1e-6\n\n    for case in test_cases:\n        m, n, k, noise_std, lam, eps, case_type = \\\n            case['m'], case['n'], case['k'], case['noise_std'], case['lam'], case['eps'], case['type']\n            \n        # --- Data Generation ---\n        if case_type == 'general':\n            A = rng.standard_normal((m, n)) / np.sqrt(m)\n            x_star = np.zeros(n)\n            indices = rng.choice(n, k, replace=False)\n            x_star[indices] = rng.standard_normal(k)\n            b = A @ x_star + rng.normal(0, noise_std, size=m)\n        elif case_type == 'orthonormal':\n            # A's columns are orthonormal, so A.T @ A = I\n            A_rand = rng.standard_normal((m, n))\n            A, _ = np.linalg.qr(A_rand)\n            x_star = np.zeros(n)\n            indices = rng.choice(n, k, replace=False)\n            x_star[indices] = rng.standard_normal(k)\n            b = A @ x_star # Noiseless\n        elif case_type == 'correlated':\n            A = rng.standard_normal((m, n)) / np.sqrt(m)\n            # Make columns 5-9 nearly collinear with column 1\n            col1 = A[:, 1].copy()\n            for j in range(5, 10):\n                A[:, j] = col1 + rng.normal(0, 0.01, size=m)\n            x_star = np.zeros(n)\n            # Ensure some non-zeros are in the correlated group for a robust test\n            non_corr_indices = list(set(range(n)) - set([1, 5, 6, 7, 8, 9]))\n            chosen_indices = rng.choice(non_corr_indices, k - 2, replace=False).tolist() + [1, 5]\n            x_star[chosen_indices] = rng.standard_normal(len(chosen_indices))\n\n            b = A @ x_star + rng.normal(0, noise_std, size=m)\n        elif case_type == 'strong_reg':\n            A = rng.standard_normal((m, n)) / np.sqrt(m)\n            b = rng.standard_normal(m) # b is random, not from a sparse model\n        else:\n            raise ValueError(\"Unknown case type\")\n\n        # --- Run Algorithms ---\n        x_global = run_mm_algorithm(A, b, lam, eps, 'global')\n        x_diag = run_mm_algorithm(A, b, lam, eps, 'diag')\n\n        # --- Analysis ---\n        support_global = {i for i, val in enumerate(x_global) if np.abs(val) >= support_thresh}\n        support_diag = {i for i, val in enumerate(x_diag) if np.abs(val) >= support_thresh}\n        \n        nnz_global = len(support_global)\n        nnz_diag = len(support_diag)\n        supports_equal = support_global == support_diag\n        symdiff_size = len(support_global.symmetric_difference(support_diag))\n\n        results.append(f\"[{nnz_global},{nnz_diag},{'True' if supports_equal else 'False'},{symdiff_size}]\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}