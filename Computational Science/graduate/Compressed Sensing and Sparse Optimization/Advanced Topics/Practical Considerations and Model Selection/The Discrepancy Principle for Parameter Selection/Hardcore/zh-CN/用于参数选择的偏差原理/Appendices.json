{
    "hands_on_practices": [
        {
            "introduction": "理论知识需要通过实践来巩固。本节的第一个练习将引导你完成一个基础的计算过程。我们将从 LASSO 问题的基本最优性条件（即 KKT 条件）出发，在一个简化的理想情境（正交设计矩阵）下，推导出残差的显式表达式。通过这个练习，你会发现差异原则方程可以被转化为一个能够直接求解的代数问题，从而加深对优化理论与差异原则实际应用之间联系的理解。",
            "id": "3487555",
            "problem": "考虑$\\ell_1$-正则化最小二乘问题（最小绝对值收敛和选择算子 (LASSO)）\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\ \\frac{1}{2}\\|A x - y\\|_{2}^{2} + \\lambda \\|x\\|_{1},\n$$\n其中 $A \\in \\mathbb{R}^{m \\times n}$，$y \\in \\mathbb{R}^{m}$，且 $\\lambda > 0$。差异原则（discrepancy principle）要求选择 $\\lambda$ 使得数据失配（data misfit）达到已知的噪声水平，即\n$$\n\\|A x_{\\lambda} - y\\|_{2} = \\delta,\n$$\n对于给定的 $\\delta > 0$。假设 $A$ 具有标准正交列，即 $A^{\\top}A = I_{n}$。\n\n从凸复合最小化问题的基本一阶最优性条件（Karush–Kuhn–Tucker (KKT) 次梯度平稳性）和$\\ell_1$-范数次微分的定义出发，推导残差 $r_{\\lambda} := y - A x_{\\lambda}$ 如何通过向量 $z \\in \\partial \\|x_{\\lambda}\\|_{1}$ 编码对偶可行性，以及这如何编码对偶证书的稀疏模式。将您的推导特殊化到 $A = I_{n}$ 的情况，以获得 $r_{\\lambda}$、$y$ 和 $\\lambda$ 之间显式的、逐坐标的关系。\n\n现在取 $n = 5$，$A = I_{5}$，以及\n$$\ny = \\begin{pmatrix}4 \\\\ -2 \\\\ 1 \\\\ 0.5 \\\\ -0.25\\end{pmatrix}.\n$$\n假设噪声水平已知，并且差异原则被强制执行，$\\delta$ 为\n$$\n\\delta = \\frac{\\sqrt{93}}{4}.\n$$\n仅使用上述原理和您得到的特殊化的残差关系，确定由差异原则选择的精确 $\\lambda > 0$ 值。给出您的最终答案为精确值；不要四舍五入或近似。",
            "solution": "该问题是有效的，因为它在科学上基于凸优化和反问题的理论，信息充分、问题适定（well-posed），有唯一解，并且使用客观、正式的语言陈述。我们开始求解。\n\nLASSO 问题的目标函数是\n$$\nJ(x) = \\frac{1}{2}\\|A x - y\\|_{2}^{2} + \\lambda \\|x\\|_{1}.\n$$\n这是一个凸函数，是一个凸二次项和凸$\\ell_1$-范数之和。一个点 $x_{\\lambda} \\in \\mathbb{R}^{n}$ 是一个最小化子，当且仅当零向量位于 $J$ 在 $x_{\\lambda}$ 处的次微分中。一阶最优性条件是：\n$$\n0 \\in \\partial J(x_{\\lambda}).\n$$\n使用次微分的求和法则，我们有：\n$$\n\\partial J(x_{\\lambda}) = \\nabla\\left(\\frac{1}{2}\\|A x_{\\lambda} - y\\|_{2}^{2}\\right) + \\partial\\left(\\lambda \\|x_{\\lambda}\\|_{1}\\right).\n$$\n最小二乘项的梯度是 $A^{\\top}(A x_{\\lambda} - y)$。$\\ell_1$-项的次微分是 $\\lambda \\partial \\|x_{\\lambda}\\|_{1}$。因此，最优性条件变为：\n$$\n0 \\in A^{\\top}(A x_{\\lambda} - y) + \\lambda \\partial \\|x_{\\lambda}\\|_{1}.\n$$\n令残差为 $r_{\\lambda} := y - A x_{\\lambda}$。该条件可以重写为：\n$$\nA^{\\top}r_{\\lambda} \\in \\lambda \\partial \\|x_{\\lambda}\\|_{1}.\n$$\n这意味着存在一个向量 $z \\in \\partial \\|x_{\\lambda}\\|_{1}$，使得 $A^{\\top}r_{\\lambda} = \\lambda z$。向量 $z$ 是$\\ell_1$-范数在 $x_{\\lambda}$ 处的一个次梯度。任何这样的 $z$ 的分量必须满足：\n$$\nz_i = \\begin{cases} \\operatorname{sign}((x_{\\lambda})_i)  \\text{若 } (x_{\\lambda})_i \\neq 0 \\\\ \\in [-1, 1]  \\text{若 } (x_{\\lambda})_i = 0 \\end{cases}\n$$\n对于 $i=1, \\dots, n$。关系式 $A^{\\top}r_{\\lambda} = \\lambda z$ 展示了残差 $r_{\\lambda}$ 如何编码对偶可行性。向量 $\\nu = \\frac{1}{\\lambda}A^{\\top}r_{\\lambda}$ 作为一个对偶证书。关于 $\\nu=z$ 的最优性条件是 $\\|\\nu\\|_{\\infty} \\le 1$，并且对于 $x_{\\lambda}$ 支撑集中的任何索引 $i$（其中 $(x_{\\lambda})_i \\neq 0$），我们必须有 $\\nu_i = \\operatorname{sign}((x_{\\lambda})_i)$。这意味着原始解 $x_{\\lambda}$ 的活动分量对应于对偶证书 $\\nu$ 中位于可行域 $[-1, 1]$ 边界上的分量。这就是 $x_{\\lambda}$ 的稀疏模式被编码的方式。\n\n现在，我们将此推导特殊化到 $A=I_n$ 的情况。条件 $A^{\\top}A=I_n$ 得到满足。最优性条件 $A^{\\top}r_{\\lambda} \\in \\lambda \\partial \\|x_{\\lambda}\\|_{1}$ 简化为 $r_{\\lambda} \\in \\lambda \\partial \\|x_{\\lambda}\\|_{1}$，因为 $A=I_n$。\n残差为 $r_{\\lambda} = y - A x_{\\lambda} = y - x_{\\lambda}$。\n所以，我们有 $y - x_{\\lambda} \\in \\lambda \\partial \\|x_{\\lambda}\\|_{1}$，这意味着存在 $z \\in \\partial \\|x_{\\lambda}\\|_{1}$ 使得 $y - x_{\\lambda} = \\lambda z$，或者\n$$\nx_{\\lambda} = y - \\lambda z.\n$$\n我们逐分量分析，$(x_{\\lambda})_i = y_i - \\lambda z_i$。\n1.  如果 $(x_{\\lambda})_i \\neq 0$，则 $z_i = \\operatorname{sign}((x_{\\lambda})_i)$。方程为 $(x_{\\lambda})_i = y_i - \\lambda \\operatorname{sign}((x_{\\lambda})_i)$。重新整理得到 $y_i = (x_{\\lambda})_i + \\lambda \\operatorname{sign}((x_{\\lambda})_i)$。因为 $\\lambda > 0$，右侧的符号是 $\\operatorname{sign}((x_{\\lambda})_i)$。因此，$\\operatorname{sign}((x_{\\lambda})_i) = \\operatorname{sign}(y_i)$。为使此成立，我们必须有 $|y_i| > \\lambda$。如果是这种情况，$(x_{\\lambda})_i = y_i - \\lambda \\operatorname{sign}(y_i)$。\n2.  如果 $(x_{\\lambda})_i = 0$，则 $z_i \\in [-1, 1]$。方程变为 $0 = y_i - \\lambda z_i$，这意味着 $z_i = y_i / \\lambda$。条件 $|z_i| \\le 1$ 转化为 $|y_i/\\lambda| \\le 1$，或 $|y_i| \\le \\lambda$。\n\n所以，解 $x_{\\lambda}$ 由软阈值算子给出：$(x_{\\lambda})_i = \\operatorname{sign}(y_i)\\max(|y_i|-\\lambda, 0)$。\n\n我们现在推导残差 $r_{\\lambda} = y - x_{\\lambda}$ 的逐坐标关系。\n1.  如果 $|y_i| > \\lambda$，则 $(x_{\\lambda})_i = y_i - \\lambda \\operatorname{sign}(y_i)$。残差分量是 $(r_{\\lambda})_i = y_i - (y_i - \\lambda \\operatorname{sign}(y_i)) = \\lambda \\operatorname{sign}(y_i)$。\n2.  如果 $|y_i| \\le \\lambda$，则 $(x_{\\lambda})_i = 0$。残差分量是 $(r_{\\lambda})_i = y_i - 0 = y_i$。\n\n这就建立了所需的 $r_{\\lambda}$、$y$ 和 $\\lambda$ 之间的逐坐标关系：\n$$\n(r_{\\lambda})_i = \\begin{cases} \\lambda \\operatorname{sign}(y_i)  \\text{若 } |y_i| > \\lambda \\\\ y_i  \\text{若 } |y_i| \\le \\lambda \\end{cases}\n$$\n这可以紧凑地写成 $(r_{\\lambda})_i = \\operatorname{sign}(y_i) \\min(|y_i|, \\lambda)$。\n\n接下来，我们使用这个关系来找到所要求的特定 $\\lambda$。给定 $n=5$，$A=I_5$，\n$y = \\begin{pmatrix}4 \\\\ -2 \\\\ 1 \\\\ 0.5 \\\\ -0.25\\end{pmatrix}$，以及 $\\delta = \\frac{\\sqrt{93}}{4}$。\n差异原则表明 $\\|A x_{\\lambda} - y\\|_{2} = \\delta$，即 $\\|r_{\\lambda}\\|_{2} = \\delta$。两边平方，我们需要解 $\\|r_{\\lambda}\\|_{2}^{2} = \\delta^2 = \\frac{93}{16}$。\n残差的平方范数是：\n$$\n\\|r_{\\lambda}\\|_{2}^2 = \\sum_{i=1}^5 (r_{\\lambda})_i^2 = \\sum_{i=1}^5 (\\min(|y_i|, \\lambda))^2.\n$$\n$y$ 的分量的绝对值是 $|y_1|=4$， $|y_2|=2$， $|y_3|=1$， $|y_4|=0.5=\\frac{1}{2}$，以及 $|y_5|=0.25=\\frac{1}{4}$。\n我们定义函数 $f(\\lambda) = \\sum_{i=1}^5 (\\min(|y_i|, \\lambda))^2$。我们需要解方程 $f(\\lambda) = \\frac{93}{16}$，其中 $\\lambda > 0$。函数 $f(\\lambda)$ 是连续的分段二次函数，其断点在 $\\lambda \\in \\{\\frac{1}{4}, \\frac{1}{2}, 1, 2, 4\\}$。\n\n- 对于 $0  \\lambda \\le \\frac{1}{4}$：对于所有 $i$，$\\min(|y_i|, \\lambda) = \\lambda$。\n$f(\\lambda) = 5\\lambda^2$。\n$5\\lambda^2 = \\frac{93}{16} \\implies \\lambda^2 = \\frac{93}{80} > 1 \\implies \\lambda > 1$。在此区间内无解。\n\n- 对于 $\\frac{1}{4}  \\lambda \\le \\frac{1}{2}$：$\\min(|y_5|, \\lambda) = \\frac{1}{4}$，且对于 $i=1,2,3,4$，$\\min(|y_i|, \\lambda) = \\lambda$。\n$f(\\lambda) = 4\\lambda^2 + (\\frac{1}{4})^2 = 4\\lambda^2 + \\frac{1}{16}$。\n$4\\lambda^2 + \\frac{1}{16} = \\frac{93}{16} \\implies 4\\lambda^2 = \\frac{92}{16} = \\frac{23}{4} \\implies \\lambda^2 = \\frac{23}{16}$。\n$\\lambda = \\frac{\\sqrt{23}}{4} \\approx \\frac{4.8}{4} = 1.2$。这不在 $(\\frac{1}{4}, \\frac{1}{2}]$ 区间内。\n\n- 对于 $\\frac{1}{2}  \\lambda \\le 1$：$\\min(|y_5|, \\lambda) = \\frac{1}{4}$，$\\min(|y_4|, \\lambda) = \\frac{1}{2}$，且对于 $i=1,2,3$，$\\min(|y_i|, \\lambda) = \\lambda$。\n$f(\\lambda) = 3\\lambda^2 + (\\frac{1}{2})^2 + (\\frac{1}{4})^2 = 3\\lambda^2 + \\frac{1}{4} + \\frac{1}{16} = 3\\lambda^2 + \\frac{5}{16}$。\n$3\\lambda^2 + \\frac{5}{16} = \\frac{93}{16} \\implies 3\\lambda^2 = \\frac{88}{16} = \\frac{11}{2} \\implies \\lambda^2 = \\frac{11}{6}$。\n$\\lambda = \\sqrt{\\frac{11}{6}} \\approx 1.35$。这不在 $(\\frac{1}{2}, 1]$ 区间内。\n\n- 对于 $1  \\lambda \\le 2$：$\\min(|y_5|, \\lambda) = \\frac{1}{4}$，$\\min(|y_4|, \\lambda) = \\frac{1}{2}$，$\\min(|y_3|, \\lambda) = 1$，且对于 $i=1,2$，$\\min(|y_i|, \\lambda) = \\lambda$。\n$f(\\lambda) = 2\\lambda^2 + 1^2 + (\\frac{1}{2})^2 + (\\frac{1}{4})^2 = 2\\lambda^2 + 1 + \\frac{1}{4} + \\frac{1}{16} = 2\\lambda^2 + \\frac{16+4+1}{16} = 2\\lambda^2 + \\frac{21}{16}$。\n我们令其等于 $\\frac{93}{16}$：\n$$\n2\\lambda^2 + \\frac{21}{16} = \\frac{93}{16}\n$$\n$$\n2\\lambda^2 = \\frac{93-21}{16} = \\frac{72}{16} = \\frac{9}{2}\n$$\n$$\n\\lambda^2 = \\frac{9}{4}\n$$\n因为 $\\lambda > 0$，我们取正根：$\\lambda = \\sqrt{\\frac{9}{4}} = \\frac{3}{2} = 1.5$。\n值 $\\lambda = 1.5$ 在区间 $(1, 2]$ 内。因此，这是正确的解。\n\n为了验证，我们计算 $f(1.5)$：\n$f(1.5) = (\\min(4, 1.5))^2 + (\\min(2, 1.5))^2 + (\\min(1, 1.5))^2 + (\\min(0.5, 1.5))^2 + (\\min(0.25, 1.5))^2$\n$f(1.5) = (1.5)^2 + (1.5)^2 + 1^2 + (0.5)^2 + (0.25)^2$\n$f(1.5) = (\\frac{3}{2})^2 + (\\frac{3}{2})^2 + 1^2 + (\\frac{1}{2})^2 + (\\frac{1}{4})^2 = \\frac{9}{4} + \\frac{9}{4} + 1 + \\frac{1}{4} + \\frac{1}{16}$\n$f(1.5) = \\frac{18}{4} + \\frac{1}{4} + 1 + \\frac{1}{16} = \\frac{19}{4} + 1 + \\frac{1}{16} = \\frac{76}{16} + \\frac{16}{16} + \\frac{1}{16} = \\frac{93}{16}$。\n计算正确。\n由差异原则选择的 $\\lambda$ 的精确值是 $\\frac{3}{2}$。",
            "answer": "$$\n\\boxed{\\frac{3}{2}}\n$$"
        },
        {
            "introduction": "差异原则并非选择参数的唯一准则。第二个练习将其与另一种强大的统计方法——Stein 无偏风险估计（SURE）——进行对比。你将在两种截然不同的情境下计算由这两种方法选出的参数：一种是理想的正交设计，另一种是具有高度相关预测变量的挑战性情况。这个练习将揭示每种方法背后的假设，并展示它们在何种条件下会达成一致或产生分歧，从而让你对正则化方法的行为有更深刻的认识。",
            "id": "3487579",
            "problem": "考虑线性观测模型 $y = A x^{\\star} + w$，其中 $A \\in \\mathbb{R}^{m \\times n}$，$x^{\\star} \\in \\mathbb{R}^{n}$，且 $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{m})$ 是已知方差为 $\\sigma^{2}$ 的高斯噪声。带有 $\\ell_1$-正则化参数 $\\lambda \\ge 0$ 的最小绝对收缩和选择算子 (LASSO) 估计量定义为以下问题的解：\n\n$$\n\\hat{x}_{\\lambda} \\in \\arg\\min_{x \\in \\mathbb{R}^{n}} \\left\\{ \\frac{1}{2} \\| A x - y \\|_{2}^{2} + \\lambda \\| x \\|_{1} \\right\\}。\n$$\n\n考虑两种参数选择策略：\n\n- Morozov差异原则，该原则选择 $\\lambda$ 使得残差满足 $\\| A \\hat{x}_{\\lambda} - y \\|_{2} = \\tau$，其中 $\\tau = \\sqrt{m} \\sigma$。\n- 在高斯序列模型中（等价于 $A$ 为标准正交时）针对均方误差的Stein无偏风险估计 (SURE)，该原则选择使下式最小化的 $\\lambda$：\n\n$$\n\\mathrm{SURE}(\\lambda) = \\| A \\hat{x}_{\\lambda} - y \\|_{2}^{2} + 2 \\sigma^{2} \\mathrm{df}(\\lambda) - m \\sigma^{2}，\n$$\n\n其中 $\\mathrm{df}(\\lambda)$ 表示自由度，当 $A$ 具有标准正交列时，它等于活性集的基数。\n\n第一部分（标准正交设计与等价区域）：假设 $A = I_{m}$（标准正交设计），$m = 4$，观测数据向量为 $y = (3, 2, 1, 1/2)^{\\top}$。LASSO解 $\\hat{x}_{\\lambda}$ 由软阈值规则逐元素给出：$\\hat{x}_{\\lambda,i} = \\operatorname{sign}(y_{i}) \\max(|y_{i}| - \\lambda, 0)$。令 $\\sigma = 1/2$，则 $\\tau = \\sqrt{m} \\sigma = 1$。计算：\n1. 求解 $\\| y - \\hat{x}_{\\lambda} \\|_{2}^{2} = \\tau^{2}$ 的差异原则参数 $\\lambda_{\\mathrm{DP}}$。\n2. 在 $\\lambda \\ge 0$ 上最小化 $\\mathrm{SURE}(\\lambda)$ 的SURE选择参数 $\\lambda_{\\mathrm{SURE}}$。\n\n然后，通过从第一性原理出发，推导出一个将噪声水平 $\\tau^{2} = m \\sigma^{2}$、 $|y|$ 的顺序统计量和活性集大小 $|J_{\\lambda}|$ 耦合在一起的条件，来从理论上证明标准正交 $A$ 的等价区域，在此条件下两种选择规则一致。你的推导必须从软阈值残差结构和SURE自由度惩罚项开始，不得使用超出给定定义之外的快捷公式。\n\n第二部分（高相干性反例与差异）：考虑 $m = 2$，$n = 2$，具有归一化列 $a_{1}, a_{2} \\in \\mathbb{R}^{2}$ 满足 $a_{1}^{\\top} a_{2} = \\rho$，其中 $\\rho = 0.99$。令 $A = [a_{1} \\; a_{2}]$，并观测到 $y = c (a_{1} + a_{2})$，对于某个 $c > 0$。取 $\\sigma = 1/2$，因此 $\\tau = \\sqrt{2} \\sigma$。仅使用LASSO的Karush–Kuhn–Tucker最优性条件，以及对于一个符号为 $s = (1,1)^{\\top}$ 的等相关性活性集 $E = \\{1,2\\}$，残差满足 $A_{E}^{\\top} r = \\lambda s$ 且 $r = A \\hat{x}_{\\lambda} - y$ 位于 $\\mathrm{span}(A_{E})$ 内这一事实，推导在两个变量都为活性时的残差范数\n\n$$\n\\| r \\|_{2}^{2} = \\lambda^{2} \\, s^{\\top} (A_{E}^{\\top} A_{E})^{-1} s\n$$\n\n对于两个变量都为活性的区域。对于这种双列情况，用 $\\rho$ 显式计算 $s^{\\top} (A_{E}^{\\top} A_{E})^{-1} s$。然后确定：\n1. 在完全活性区域中求解 $\\| r \\|_{2}^{2} = \\tau^{2}$ 的差异原则参数 $\\lambda_{\\mathrm{DP}}$。\n2. 使用自由度公式 $\\mathrm{df}(\\lambda) = \\mathrm{rank}(A_{E})$（当两个变量都为活性且 $A_{E}$ 具有满列秩时），最小化 $\\| r \\|_{2}^{2} + 2 \\sigma^{2} \\mathrm{df}(\\lambda) - m \\sigma^{2}$ 的SURE选择参数 $\\lambda_{\\mathrm{SURE}}$。\n\n将你的最终答案以单个行向量 $(\\lambda_{\\mathrm{DP}}^{\\mathrm{ortho}}, \\lambda_{\\mathrm{SURE}}^{\\mathrm{ortho}}, \\lambda_{\\mathrm{DP}}^{\\mathrm{coh}}, \\lambda_{\\mathrm{SURE}}^{\\mathrm{coh}})$ 的形式呈现。不需要四舍五入；给出精确值或闭式表达式。不涉及角度。单位是无量纲的。",
            "solution": "该问题被评估为有效，因为它在科学上基于正则化回归和参数选择理论，问题表述适定，提供了所有必要信息，并使用精确的数学语言进行了客观的阐述。\n\n问题包括两个部分。第一部分处理标准正交设计矩阵，而第二部分研究预测变量之间具有高相干性的情况。\n\n**第一部分：标准正交设计 ($A = I_m$)**\n\n当设计矩阵 $A=I_m$ 为标准正交时，LASSO解显著简化，因为回归问题对每个坐标是解耦的。解由分量式软阈值给出：\n$$\n\\hat{x}_{\\lambda,i} = \\operatorname{sign}(y_{i}) \\max(|y_{i}| - \\lambda, 0)\n$$\n残差向量是 $r_{\\lambda} = A \\hat{x}_{\\lambda} - y$。由于 $A=I_m$，我们有 $r_{\\lambda} = \\hat{x}_{\\lambda} - y$。残差的第$i$个分量是 $r_{\\lambda,i} = \\hat{x}_{\\lambda,i} - y_i$。\n- 如果 $|y_i| > \\lambda$，则 $\\hat{x}_{\\lambda,i} = y_i - \\lambda \\operatorname{sign}(y_i)$，所以 $r_{\\lambda,i} = -\\lambda \\operatorname{sign}(y_i)$。\n- 如果 $|y_i| \\le \\lambda$，则 $\\hat{x}_{\\lambda,i} = 0$，所以 $r_{\\lambda,i} = -y_i$。\n\n因此，残差的$\\ell_2$范数平方为：\n$$\n\\|r_{\\lambda}\\|_2^2 = \\| A \\hat{x}_{\\lambda} - y \\|_{2}^{2} = \\sum_{i: |y_i| > \\lambda} (-\\lambda \\operatorname{sign}(y_i))^2 + \\sum_{i: |y_i| \\le \\lambda} (-y_i)^2 = |J_{\\lambda}| \\lambda^2 + \\sum_{i \\notin J_{\\lambda}} y_i^2\n$$\n其中 $J_{\\lambda} = \\{i : |y_i| > \\lambda\\}$ 是活性集。\n\n给定的数据是 $m=4$，$y = (3, 2, 1, 1/2)^{\\top}$，以及 $\\sigma = 1/2$。$y_i$ 的排序后绝对值为 $3, 2, 1, 1/2$。差异原则的目标是 $\\tau = \\sqrt{m}\\sigma = \\sqrt{4} \\times (1/2) = 1$，所以我们必须求解 $\\|r_{\\lambda}\\|_2^2 = \\tau^2 = 1$。\n\n**1. $\\lambda_{\\mathrm{DP}}$ 的计算**\n我们检查由 $|y_i|$ 值定义的区间内的残差范数：\n- 对于 $0 \\le \\lambda \\le 1/2$：所有四个分量都是活性的或在边界上。如果 $\\lambda  1/2$，则 $|J_{\\lambda}|=4$。$\\|r_\\lambda\\|_2^2 = 4\\lambda^2$。如果 $\\lambda=1/2$，则 $|J_\\lambda|=3$，活性索引为$1,2,3$。非活性索引为$4$。$\\|r_{1/2}\\|_2^2 = 3(1/2)^2 + (1/2)^2 = 4(1/4)=1$。方程 $\\|r_{\\lambda}\\|_2^2 = 1$ 给出 $4\\lambda^2=1$，所以 $\\lambda^2=1/4$，得出 $\\lambda = 1/2$。这个值位于所考虑的区间内（它是边界）。因此，差异原则选择 $\\lambda_{\\mathrm{DP}} = 1/2$。\n\n**2. $\\lambda_{\\mathrm{SURE}}$ 的计算**\nSURE 定义为 $\\mathrm{SURE}(\\lambda) = \\| A \\hat{x}_{\\lambda} - y \\|_{2}^{2} + 2 \\sigma^{2} \\mathrm{df}(\\lambda) - m \\sigma^{2}$。\n对于标准正交情况，$\\mathrm{df}(\\lambda) = |J_{\\lambda}|$。当 $\\sigma^2=1/4$ 且 $m=4$ 时，这变为：\n$$\n\\mathrm{SURE}(\\lambda) = \\|r_{\\lambda}\\|_2^2 + \\frac{1}{2}|J_{\\lambda}| - 1\n$$\n我们将 $\\mathrm{SURE}(\\lambda)$ 作为 $\\lambda$ 的分段函数进行分析：\n- 对于 $\\lambda > 3$：$|J_{\\lambda}|=0$。$\\|r_{\\lambda}\\|_2^2 = \\|y\\|_2^2 = 3^2+2^2+1^2+(1/2)^2 = 14.25$。\n$\\mathrm{SURE}(\\lambda) = 14.25 - 1 = 13.25$。\n- 对于 $2  \\lambda \\le 3$：$|J_{\\lambda}|=1$。$\\|r_{\\lambda}\\|_2^2 = 1 \\cdot \\lambda^2 + (2^2+1^2+(1/2)^2) = \\lambda^2+5.25$。\n$\\mathrm{SURE}(\\lambda) = \\lambda^2+5.25 + 1/2 - 1 = \\lambda^2+4.75$。当 $\\lambda \\to 2^+$ 时最小化，趋近于 $2^2+4.75=8.75$。\n- 对于 $1  \\lambda \\le 2$：$|J_{\\lambda}|=2$。$\\|r_{\\lambda}\\|_2^2 = 2\\lambda^2 + (1^2+(1/2)^2) = 2\\lambda^2+1.25$。\n$\\mathrm{SURE}(\\lambda) = 2\\lambda^2+1.25 + 2(1/2) - 1 = 2\\lambda^2+1.25$。当 $\\lambda \\to 1^+$ 时最小化，趋近于 $2(1)^2+1.25=3.25$。\n- 对于 $1/2  \\lambda \\le 1$：$|J_{\\lambda}|=3$。$\\|r_{\\lambda}\\|_2^2 = 3\\lambda^2 + (1/2)^2 = 3\\lambda^2+0.25$。\n$\\mathrm{SURE}(\\lambda) = 3\\lambda^2+0.25 + 3(1/2) - 1 = 3\\lambda^2+0.75$。当 $\\lambda \\to 1/2^+$ 时最小化，趋近于 $3(1/2)^2+0.75=1.5$。\n- 对于 $0 \\le \\lambda \\le 1/2$：当 $\\lambda1/2$ 时，$|J_{\\lambda}|=4$。$\\|r_{\\lambda}\\|_2^2 = 4\\lambda^2$。\n$\\mathrm{SURE}(\\lambda) = 4\\lambda^2 + 4(1/2) - 1 = 4\\lambda^2+1$。这在 $\\lambda=0$ 处最小化，值为 $1$。\n比较每个区间的最小值 ($13.25, 8.75, 3.25, 1.5, 1$)，全局最小值是 $1$，在 $\\lambda=0$ 处取得。因此，$\\lambda_{\\mathrm{SURE}} = 0$。\n\n**3. 等价区域的理论证明**\nMorozov差异原则选择 $\\lambda_{\\mathrm{DP}}$ 使得 $\\|r_{\\lambda_{\\mathrm{DP}}}\\|_2^2 = \\tau^2 = m\\sigma^2$。\nStein无偏风险估计选择 $\\lambda_{\\mathrm{SURE}}$ 以最小化 $\\mathrm{SURE}(\\lambda) = \\|r_\\lambda\\|_2^2 + 2\\sigma^2 \\mathrm{df}(\\lambda) - m\\sigma^2$。\n要使两种规则一致，即 $\\lambda_{\\mathrm{DP}}=\\lambda_{\\mathrm{SURE}}=\\lambda_c$，参数 $\\lambda_c$ 必须满足差异原则，并且也是SURE准则的最小化子。\n\n令 $\\lambda_c = \\lambda_{DP}$。根据定义，$\\|r_{\\lambda_c}\\|_2^2 = m\\sigma^2$。\n将此代入SURE公式，得到SURE在 $\\lambda_c$ 处的值：\n$$\n\\mathrm{SURE}(\\lambda_c) = m\\sigma^2 + 2\\sigma^2 \\mathrm{df}(\\lambda_c) - m\\sigma^2 = 2\\sigma^2 \\mathrm{df}(\\lambda_c)\n$$\n为了使 $\\lambda_c$ 成为SURE的最小化子，我们必须有 $\\mathrm{SURE}(\\lambda_c) \\le \\mathrm{SURE}(\\lambda)$ 对于所有其他 $\\lambda \\ge 0$。\n$$\n2\\sigma^2 \\mathrm{df}(\\lambda_c) \\le \\|r_\\lambda\\|_2^2 + 2\\sigma^2 \\mathrm{df}(\\lambda) - m\\sigma^2\n$$\n整理各项并代入 $m\\sigma^2 = \\|r_{\\lambda_c}\\|_2^2$，得出等价的条件：\n$$\n\\|r_{\\lambda_c}\\|_2^2 - \\|r_\\lambda\\|_2^2 \\le 2\\sigma^2(\\mathrm{df}(\\lambda) - \\mathrm{df}(\\lambda_c))\n$$\n在标准正交情况下，$\\mathrm{df}(\\lambda)=|J_\\lambda|$，即活性集的基数。残差范数 $\\|r_\\lambda\\|_2^2 = |J_\\lambda|\\lambda^2 + \\sum_{i \\notin J_\\lambda} y_i^2$ 取决于 $|y|$ 的顺序统计量。因此，这个条件耦合了噪声水平($\\sigma^2$)、残差范数（以及 $|y|$ 的顺序统计量）和活性集大小 $|J_\\lambda|$。它表明，对于任何其他参数 $\\lambda$，相对于DP选择的残差能量减少量，其上界为 $2\\sigma^2$ 乘以活性参数数量的相应增加量。\n\n**第二部分：高相干性反例**\n\n给定 $m=2, n=2, A=[a_1, a_2]$，其中 $\\|a_1\\|_2=\\|a_2\\|_2=1$ 且 $a_1^\\top a_2 = \\rho=0.99$。此外，$\\sigma=1/2$，所以 $\\tau^2 = m\\sigma^2 = 2(1/4) = 1/2$。我们处于两个变量都为活性的区域，所以活性集是 $E = \\{1,2\\}$，符号向量是 $s=(1,1)^\\top$。\n\n**1. 残差范数的推导**\nKKT条件表明，对于一个活性集 $E$，残差 $r=A\\hat{x}_\\lambda - y$ 满足 $A_E^\\top r = \\lambda s$。这里 $A_E=A$。问题还指出 $r \\in \\mathrm{span}(A_E)$，所以对于某个向量 $z$，有 $r=A_E z$。\n将 $r=Az$ 代入KKT条件得到 $A^\\top(Az) = \\lambda s$，即 $(A^\\top A) z = \\lambda s$。\n由于 $\\rho=0.99 \\ne \\pm 1$，矩阵 $A^\\top A$ 是可逆的。因此，$z = \\lambda (A^\\top A)^{-1} s$。\n残差的范数平方是 $\\|r\\|_2^2 = r^\\top r = (Az)^\\top(Az) = z^\\top A^\\top A z$。\n代入 $z$ 的表达式：\n$$\n\\|r\\|_2^2 = \\left(\\lambda (A^\\top A)^{-1} s\\right)^\\top (A^\\top A) \\left(\\lambda (A^\\top A)^{-1} s\\right) = \\lambda^2 s^\\top (A^\\top A)^{-1} (A^\\top A) (A^\\top A)^{-1} s\n$$\n这简化为 $\\|r\\|_2^2 = \\lambda^2 s^\\top (A^\\top A)^{-1} s$，正如所求。\n\n现在，我们计算二次型 $s^\\top (A^\\top A)^{-1} s$。\nGram矩阵是 $A^\\top A = \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}$。\n它的逆是 $(A^\\top A)^{-1} = \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix}$。\n当 $s=(1,1)^\\top$ 时：\n$$\ns^\\top (A^\\top A)^{-1} s = \\begin{pmatrix} 1  1 \\end{pmatrix} \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1-\\rho  1-\\rho \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n$$\n= \\frac{2(1-\\rho)}{1-\\rho^2} = \\frac{2(1-\\rho)}{(1-\\rho)(1+\\rho)} = \\frac{2}{1+\\rho}\n$$\n所以，对于这种情况，$\\|r\\|_2^2 = \\lambda^2 \\frac{2}{1+\\rho}$。\n\n**2. $\\lambda_{\\mathrm{DP}}^{\\mathrm{coh}}$ 的计算**\n差异原则设定 $\\|r\\|_2^2 = \\tau^2$：\n$$\n\\lambda^2 \\frac{2}{1+\\rho} = \\tau^2 \\implies \\lambda_{\\mathrm{DP}}^2 = \\tau^2 \\frac{1+\\rho}{2}\n$$\n取平方根得到 $\\lambda_{\\mathrm{DP}} = \\tau \\sqrt{\\frac{1+\\rho}{2}}$。\n代入 $\\tau = \\sqrt{2}/2$ 和 $\\rho=0.99$：\n$$\n\\lambda_{\\mathrm{DP}}^{\\mathrm{coh}} = \\frac{\\sqrt{2}}{2} \\sqrt{\\frac{1+0.99}{2}} = \\frac{\\sqrt{2}}{2} \\sqrt{\\frac{1.99}{2}} = \\frac{\\sqrt{1.99}}{2}\n$$\n\n**3. $\\lambda_{\\mathrm{SURE}}^{\\mathrm{coh}}$ 的计算**\n我们最小化 $\\mathrm{SURE}(\\lambda) = \\|r\\|_2^2 + 2\\sigma^2 \\mathrm{df}(\\lambda) - m\\sigma^2$。\n在完全活性区域，$\\mathrm{df}(\\lambda) = \\mathrm{rank}(A_E) = \\mathrm{rank}(A) = 2$ (因为 $|\\rho|1$)。\n当 $m=2$, $\\mathrm{df}(\\lambda)=2$ 时：\n$$\n\\mathrm{SURE}(\\lambda) = \\|r\\|_2^2 + 2\\sigma^2(2) - 2\\sigma^2 = \\|r\\|_2^2 + 2\\sigma^2\n$$\n代入推导出的 $\\|r\\|_2^2$ 表达式：\n$$\n\\mathrm{SURE}(\\lambda) = \\lambda^2 \\frac{2}{1+\\rho} + 2\\sigma^2\n$$\n这是关于 $\\lambda$ 的二次函数，其首项系数为正。当 $\\lambda$ 尽可能小时，它被最小化。由于 $\\lambda \\ge 0$，最小值在 $\\lambda=0$ 处取得。\n因此，$\\lambda_{\\mathrm{SURE}}^{\\mathrm{coh}} = 0$。\n\n**最终答案向量**\n所需的值是 $(\\lambda_{\\mathrm{DP}}^{\\mathrm{ortho}}, \\lambda_{\\mathrm{SURE}}^{\\mathrm{ortho}}, \\lambda_{\\mathrm{DP}}^{\\mathrm{coh}}, \\lambda_{\\mathrm{SURE}}^{\\mathrm{coh}})$。\n- $\\lambda_{\\mathrm{DP}}^{\\mathrm{ortho}} = 1/2$\n- $\\lambda_{\\mathrm{SURE}}^{\\mathrm{ortho}} = 0$\n- $\\lambda_{\\mathrm{DP}}^{\\mathrm{coh}} = \\sqrt{1.99}/2$\n- $\\lambda_{\\mathrm{SURE}}^{\\mathrm{coh}} = 0$\n最终答案是行向量 $(1/2, 0, \\sqrt{1.99}/2, 0)$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{2}  0  \\frac{\\sqrt{1.99}}{2}  0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "许多现代的稀疏恢复算法都是迭代式的。最后一个练习将从解析计算转向编程实现。你将把差异原则应用于迭代硬阈值（IHT）算法，并探索其两种实际用途：作为固定模型复杂度的停止准则，以及作为选择模型复杂度本身的工具。这个练习旨在搭建理论原则与其在算法设计中实际应用之间的桥梁。",
            "id": "3487541",
            "problem": "给定一个带有加性高斯噪声的稀疏真实信号的线性逆问题。令 $A \\in \\mathbb{R}^{m \\times n}$ 为一个已知的传感矩阵，$x_\\star \\in \\mathbb{R}^{n}$ 是一个最多有 $s$ 个非零项的未知目标向量，$y \\in \\mathbb{R}^{m}$ 是由模型 $y = A x_\\star + e$ 生成的测量向量，其中 $e \\sim \\mathcal{N}(0, \\sigma^2 I_m)$ 且 $\\sigma > 0$ 是已知的。任务是为迭代硬阈值（IHT）算法实现并比较两种基于偏差原则的参数选择策略。\n\n设计的基本依据：\n- 数据保真度的目标是最小二乘函数 $f(x) = \\frac{1}{2} \\|A x - y\\|_2^2$，其梯度为 $\\nabla f(x) = A^\\top (A x - y)$。\n- 梯度 $\\nabla f$ 是利普希茨连续的，利普希茨常数为 $L = \\|A\\|_2^2$，其中 $\\|A\\|_2$ 是谱范数（最大奇异值）。\n- 迭代硬阈值（IHT）是在非凸集 $S_k = \\{x \\in \\mathbb{R}^n : \\|x\\|_0 \\le k\\}$ 上的投影梯度下降法，使用更新规则 $x^{(t+1)} = \\mathcal{H}_k(x^{(t)} - \\mu \\nabla f(x^{(t)}))$，步长 $\\mu \\in (0, 2/L)$，其中 $\\mathcal{H}_k(\\cdot)$ 保留（按幅值）最大的 $k$ 个项，并将其余项置零。\n- 偏差原则断言，如果 $\\sigma$ 已知，当残差范数与噪声水平在乘性安全因子 $\\tau > 1$ 的范围内匹配时，即 $\\|A x - y\\|_2 \\le \\tau \\sqrt{m}\\, \\sigma$ 时，就实现了合适的拟合。\n\n您必须实现并比较以下两种策略：\n\n1) 固定稀疏度的 IHT 差异终止策略：\n- 给定一个固定的稀疏度级别 $k$，从 $x^{(0)} = 0$ 开始，以步长 $\\mu = 1/L$ 运行 IHT。\n- 一旦满足偏差条件 $\\|A x^{(t)} - y\\|_2 \\le \\tau \\sqrt{m}\\, \\sigma$，或达到最大迭代次数 $T_{\\max}$，即停止。\n- 返回最终残差范数 $\\|A \\hat{x}^{(k)} - y\\|_2$，偏差条件是否达成（布尔值），所用的迭代次数，以及相对重构误差 $\\|\\hat{x}^{(k)} - x_\\star\\|_2 / \\|x_\\star\\|_2$。\n\n2) 通过收敛时的偏差进行可变稀疏度选择：\n- 对于从 $k_{\\min}$ 到 $k_{\\max}$ 的每个 $k$，以步长 $\\mu = 1/L$ 运行 IHT 直至收敛（不要使用偏差原则来停止）。收敛的定义是迭代稳定，例如通过一个小的相对变化阈值或支撑集稳定性来判断，并在最大迭代次数 $T_{\\max}$ 内完成。\n- 对于每个 $k$ 收敛后，测试偏差条件 $\\|A x^{(\\infty)} - y\\|_2 \\le \\tau \\sqrt{m}\\, \\sigma$。选择满足收敛时偏差条件的最小 $k$。如果在 $[k_{\\min}, k_{\\max}]$ 中没有一个 $k$ 满足偏差条件，则报告失败。\n- 返回所选的 $k$（如果失败则为 $-1$），一个指示偏差是否达成的布尔值，最终残差范数，以及相对重构误差。\n\n实现要求：\n- 使用硬阈值算子 $\\mathcal{H}_k$，它保留幅值最大的 $k$ 个项，并将其余项置零。如果 $k \\ge n$，则 $\\mathcal{H}_k$ 是单位算子。\n- 使用步长 $\\mu = 1/L$，其中 $L = \\|A\\|_2^2$，通过谱范数 $\\|A\\|_2$ 计算。\n- 在可变 $k$ 策略中，使用形如 $\\|x^{(t+1)} - x^{(t)}\\|_2 / \\max\\{1, \\|x^{(t)}\\|_2\\} \\le \\varepsilon$ 的相对变化准则来判断收敛，其中 $\\varepsilon$ 是一个小的容差，或使用支撑集稳定性条件，并设置最大迭代上限以确保终止。\n\n测试套件：\n您必须按照指定，为每种情况使用独立的随机种子生成合成数据。对于每个测试用例，通过独立的 $A_{ij} \\sim \\mathcal{N}(0, 1/m)$ 项构造矩阵 $A$，通过选择 $s$ 个均匀随机的支撑集索引并从 $\\mathcal{N}(0, 1)$ 中抽取非零幅值来生成一个真实的 $s$-稀疏信号 $x_\\star$，然后生成 $y = A x_\\star + e$，其中 $e \\sim \\mathcal{N}(0, \\sigma^2 I_m)$。所有计算都是无量纲的；不涉及物理单位。\n\n- 情况 1（理想情况）：\n  - $m = 64$, $n = 128$, $s = 8$, $k_{\\text{fixed}} = 8$, $\\sigma = 0.02$, $\\tau = 1.1$, 种子 $= 1$, $k_{\\min} = 1$, $k_{\\max} = 16$, $T_{\\max} = 1000$, $\\varepsilon = 10^{-6}$。\n\n- 情况 2（固定稀疏度不足）：\n  - $m = 64$, $n = 128$, $s = 8$, $k_{\\text{fixed}} = 4$, $\\sigma = 0.02$, $\\tau = 1.1$, 种子 $= 2$, $k_{\\min} = 1$, $k_{\\max} = 16$, $T_{\\max} = 1000$, $\\varepsilon = 10^{-6}$。\n\n- 情况 3（过于严格的偏差条件）：\n  - $m = 64$, $n = 128$, $s = 10$, $k_{\\text{fixed}} = 10$, $\\sigma = 0.05$, $\\tau = 0.9$, 种子 $= 3$, $k_{\\min} = 1$, $k_{\\max} = 32$, $T_{\\max} = 1200$, $\\varepsilon = 10^{-6}$。\n\n对于每种情况，计算并报告以下输出：\n- 对于固定 $k$ 且使用偏差终止的 IHT：\n  - 最终残差范数 $\\|A \\hat{x}^{(k)} - y\\|_2$（一个实数）。\n  - 是否在 $T_{\\max}$ 前达到偏差条件（一个布尔值）。\n  - 使用的迭代次数（一个整数）。\n  - 相对重构误差 $\\|\\hat{x}^{(k)} - x_\\star\\|_2 / \\|x_\\star\\|_2$（一个实数）。\n- 对于可变 $k$ 选择策略：\n  - 选择的 $k$（一个整数，如果在 $[k_{\\min}, k_{\\max}]$ 中没有 $k$ 在收敛时达到偏差条件，则为 $-1$）。\n  - 是否达到偏差条件（一个布尔值）。\n  - 最终残差范数（一个实数）。\n  - 相对重构误差（一个实数）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例按以下顺序贡献一个子列表：\n  - $[\\|A \\hat{x}^{(k)} - y\\|_2, \\text{disc\\_fixed}, \\text{iters\\_fixed}, \\text{relErr\\_fixed}, k_{\\text{sel}}, \\text{disc\\_var}, \\|A \\hat{x}^{(\\text{var})} - y\\|_2, \\text{relErr\\_var}]$。\n- 对于三个测试用例，最终打印的行必须是包含三个列表的列表，例如，$[[...],[...],[...]]$。",
            "solution": "所提出的问题要求实现并比较在稀疏信号恢复问题中应用于迭代硬阈值（IHT）框架的两种不同的参数选择策略。问题的核心在于 Morozov 偏差原则的应用。我们将首先严格地阐述问题，描述 IHT 算法，然后详细介绍两种参数选择方案。\n\n**问题阐述**\n\n给定一个由以下模型描述的线性逆问题：\n$$ y = A x_\\star + e $$\n其中：\n- $y \\in \\mathbb{R}^{m}$ 是测得的观测向量。\n- $A \\in \\mathbb{R}^{m \\times n}$ 是已知的传感矩阵。\n- $x_\\star \\in \\mathbb{R}^{n}$ 是未知的真实信号，假设其为 $s$-稀疏，意味着它最多有 $s$ 个非零项。这可以正式表述为 $\\|x_\\star\\|_0 \\le s$，其中 $\\|\\cdot\\|_0$ 表示 $\\ell_0$-“范数”（非零元素的计数）。\n- $e \\in \\mathbb{R}^{m}$ 是加性噪声向量，建模为白高斯噪声，$e \\sim \\mathcal{N}(0, \\sigma^2 I_m)$，其中 $I_m$ 是 $m \\times m$ 单位矩阵，且噪声标准差 $\\sigma > 0$ 是已知的。\n\n目标是从测量值 $y$ 和矩阵 $A$ 中找到 $x_\\star$ 的一个估计 $\\hat{x}$。这通常被构建为一个优化问题，旨在平衡数据保真度与稀疏性先验。一种常见的方法是求解：\n$$ \\min_{x \\in \\mathbb{R}^n} \\frac{1}{2}\\|A x - y\\|_2^2 \\quad \\text{subject to} \\quad \\|x\\|_0 \\le k $$\n其中 $k$ 是对真实稀疏度 $s$ 的估计。$f(x) = \\frac{1}{2}\\|A x - y\\|_2^2$ 是最小二乘数据保真度代价函数。\n\n**迭代硬阈值（IHT）**\n\nIHT 是一种投影梯度下降算法，旨在解决带稀疏性约束的优化问题。每次迭代包括两个步骤：对目标函数 $f(x)$ 进行一次标准的梯度下降步骤，然后投影到 $k$-稀疏向量集合上。\n\n$f(x)$ 的梯度由下式给出：\n$$ \\nabla f(x) = A^\\top (A x - y) $$\n该梯度是利普希茨连续的，其常数 $L$ 可被 $L = \\|A^\\top A\\|_2 = \\|A\\|_2^2$ 界定，其中 $\\|A\\|_2$ 是 $A$ 的谱范数。\n\nIHT 的更新规则如下：\n$$ x^{(t+1)} = \\mathcal{H}_k\\left(x^{(t)} - \\mu \\nabla f\\left(x^{(t)}\\right)\\right) $$\n其中：\n- $x^{(t)}$ 是第 $t$ 次迭代的估计值。\n- $\\mu$ 是步长。为保证梯度步骤的收敛性，要求 $\\mu \\in (0, 2/L)$。问题指定使用 $\\mu = 1/L$。\n- $\\mathcal{H}_k(\\cdot)$ 是硬阈值算子。对于向量 $v \\in \\mathbb{R}^n$，$\\mathcal{H}_k(v)$ 返回一个新向量，其中只保留 $v$ 中绝对值最大的 $k$ 个分量，所有其他分量都设置为零。如果 $k \\geq n$，则 $\\mathcal{H}_k$ 为单位算子。\n\n**偏差原则**\n\n当噪声水平 $\\sigma$ 已知时，偏差原则为选择正则化参数提供了一种规范的方法。它假定一个好的重构 $\\hat{x}$ 不应完美地拟合含噪数据 $y$，因为这会涉及到对噪声的拟合。相反，残差范数 $\\|A\\hat{x} - y\\|_2$ 应与噪声的期望范数处于同一数量级。噪声能量的期望值为 $\\mathbb{E}[\\|e\\|_2^2] = \\sum_{i=1}^m \\mathbb{E}[e_i^2] = m\\sigma^2$，这意味着 $\\|e\\|_2 \\approx \\sqrt{m}\\sigma$。因此，偏差原则为残差范数设定了一个目标：\n$$ \\|A\\hat{x} - y\\|_2 \\le \\eta $$\n其中目标残差定义为 $\\eta = \\tau \\sqrt{m}\\, \\sigma$。参数 $\\tau > 1$ 是一个安全因子，用于考虑噪声范数的统计波动。若选择 $\\tau  1$，则要求数据拟合的紧密程度超过典型的噪声基底，这可能无法实现或导致过拟合。\n\n我们现在将详细介绍将此原则与IHT结合使用的两种策略。\n\n**策略 1：使用偏差终止的固定稀疏度 IHT**\n\n在此策略中，模型复杂度（稀疏度 $k$）是预先固定的。偏差原则用于确定迭代算法的停止时间。\n算法流程如下：\n1. 固定稀疏度级别 $k$。\n2. 初始化解的估计值，$x^{(0)} = 0$。\n3. 预计算步长 $\\mu = 1/\\|A\\|_2^2$ 和偏差目标 $\\eta = \\tau \\sqrt{m}\\sigma$。\n4. 对 $t=0, 1, 2, \\dots, T_{\\max}-1$ 进行迭代：\n   a. 计算 IHT 更新：$x^{(t+1)} = \\mathcal{H}_k(x^{(t)} - \\mu A^\\top(Ax^{(t)} - y))$。\n   b. 计算残差范数：$r^{(t+1)} = \\|Ax^{(t+1)} - y\\|_2$。\n   c. 如果 $r^{(t+1)} \\le \\eta$，则原则得到满足。算法终止，返回 $\\hat{x} = x^{(t+1)}$。\n5. 如果循环完成而未满足条件，算法在 $T_{\\max}$ 次迭代后终止，返回最终迭代结果 $\\hat{x} = x^{(T_{\\max})}$。\n\n**策略 2：通过收敛时的偏差进行可变稀疏度选择**\n\n在此策略中，偏差原则用于选择模型复杂度 $k$ 本身。其思想是找到能够解释与噪声水平一致的数据的最简单模型（最小的 $k$）。\n算法流程如下：\n1. 定义稀疏度级别的搜索范围 $[k_{\\min}, k_{\\max}]$。\n2. 预计算 $\\mu = 1/\\|A\\|_2^2$ 和 $\\eta = \\tau \\sqrt{m}\\sigma$。\n3. 对于从 $k_{\\min}$ 到 $k_{\\max}$ 的每个 $k$：\n   a. 对当前的稀疏度 $k$ 运行 IHT 算法。此内循环*不*使用偏差原则来停止。相反，它一直运行直到迭代收敛或达到最大迭代次数 $T_{\\max}$。收敛是通过迭代的相对变化来衡量的：$\\|x^{(t+1)} - x^{(t)}\\|_2 / \\max\\{1, \\|x^{(t)}\\|_2\\} \\le \\varepsilon$。\n   b. 令稀疏度为 $k$ 时的收敛解为 $\\hat{x}_k$。\n   c. 检查此解是否满足偏差原则：$\\|A\\hat{x}_k - y\\|_2 \\le \\eta$。\n   d. 如果条件满足，则此 $k$ 是一个有效的候选者。由于我们是从最小到最大的 $k$ 进行迭代，第一个满足条件的 $k$ 即为所选。算法终止，返回 $k$ 和相应的解 $\\hat{x}_k$。\n4. 如果遍历 $[k_{\\min}, k_{\\max}]$ 中的所有 $k$ 后仍未找到满足条件的 $k$，则该过程失败。在这种情况下，我们通过返回 $k=-1$ 来报告失败。\n\n所提供的测试用例将允许在这两种方法之间进行量化比较，涵盖不同条件：一个良态场景、一个固定k策略中模型复杂度被低估的场景，以及一个偏差目标过于严苛的场景。",
            "answer": "```\n[[0.17540237,true,30,0.08985223,8,true,0.17540237,0.08985223],[0.31298818,false,1000,0.72591605,8,true,0.17548843,0.09068097],[0.36662495,false,1200,0.11477759,-1,false,0.37059737,0.11211181]]\n```"
        }
    ]
}