{
    "hands_on_practices": [
        {
            "introduction": "鲁棒主成分分析（RPCA）的许多现代算法都依赖于一种被称为“近端梯度法”的优化框架。在这些算法的核心，是对低秩分量 $L$ 进行更新的关键一步，这通过核范数的近端算子（proximal operator）来实现。这个练习将引导你从第一性原理出发，推导出这个算子，即著名的奇异值阈值（Singular Value Thresholding, SVT）算子，并揭示它如何通过对奇异值进行“软阈值”操作来有效地降低矩阵的秩。",
            "id": "3474854",
            "problem": "考虑经典的稳健主成分分析（Robust Principal Component Analysis, RPCA）分解模型，该模型通过凸优化寻求一个低秩矩阵和一个稀疏矩阵。更新低秩分量的标准近端步骤使用核范数的近端算子。设核范数定义为 $\\lVert X \\rVert_{*} = \\sum_{i} \\sigma_{i}(X)$，其中 $\\sigma_{i}(X)$ 是矩阵 $X$ 的奇异值。一个真、下半连续、凸函数 $f$ 在点 $Y$ 处的近端算子定义为 $\\operatorname{prox}_{f}(Y) = \\arg\\min_{X} \\left\\{ f(X) + \\tfrac{1}{2}\\lVert X - Y \\rVert_{F}^{2} \\right\\}$，其中 $\\lVert \\cdot \\rVert_{F}$ 表示 Frobenius 范数。在 RPCA 的低秩更新中，使用缩放核范数 $f(X) = \\tau \\lVert X \\rVert_{*}$ 的近端算子，其中 $\\tau > 0$ 是一个阈值参数。\n\n仅从这些基本定义出发，结合 Frobenius 范数和核范数的酉不变性，推导由 $\\operatorname{prox}_{\\tau \\lVert \\cdot \\rVert_{*}}(Y)$（也称为奇异值阈值（Singular Value Thresholding, SVT）算子，首次使用时定义此缩写）引起的对奇异值的变换。然后，将您的推导应用于一个矩阵 $Y$，其奇异值分解（Singular Value Decomposition, SVD）为 $Y = U \\Sigma V^{\\top}$，奇异值为 $(\\sigma_{1}, \\sigma_{2}, \\sigma_{3}) = (5, 3, 0)$，并使用阈值 $\\tau = 2$。计算近端点 $L^{\\star} = \\operatorname{prox}_{\\tau \\lVert \\cdot \\rVert_{*}}(Y)$ 的奇异值以及 $L^{\\star}$ 的秩。\n\n将您的最终答案表示为单个表达式，列出 $L^{\\star}$ 的奇异值（按非递增顺序排列），后跟 $L^{\\star}$ 的秩。无需四舍五入，不涉及物理单位。",
            "solution": "该问题是有效的，因为它具有科学依据、良定且客观。它包含凸优化和矩阵分析领域内的标准推导和应用。所有必要的定义和数据均已提供。\n\n任务是推导缩放核范数的近端算子，并将其应用于一个特定矩阵。函数 $f(X) = \\tau \\lVert X \\rVert_{*}$ 的近端算子定义为以下优化问题的解：\n$$\nL^{\\star} = \\operatorname{prox}_{\\tau \\lVert \\cdot \\rVert_{*}}(Y) = \\arg\\min_{X} \\left\\{ \\tau \\lVert X \\rVert_{*} + \\tfrac{1}{2}\\lVert X - Y \\rVert_{F}^{2} \\right\\}\n$$\n其中 $\\lVert X \\rVert_{*} = \\sum_{i} \\sigma_{i}(X)$ 是核范数，$\\sigma_i(X)$ 是 $X$ 的奇异值，$\\lVert A \\rVert_{F} = \\sqrt{\\sum_{i,j} |A_{ij}|^2} = \\sqrt{\\operatorname{Tr}(A^{\\top}A)}$ 是 Frobenius 范数。\n\n设矩阵 $Y \\in \\mathbb{R}^{m \\times n}$ 的奇异值分解（SVD）为 $Y = U \\Sigma_Y V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是酉矩阵，$\\Sigma_Y$ 是一个大小为 $m \\times n$ 的矩形对角矩阵，其对角线上的非负元素 $\\sigma_i(Y)$（即 $Y$ 的奇异值）按非递增顺序排列。\n\n目标函数可以展开为：\n$$\nJ(X) = \\tau \\lVert X \\rVert_{*} + \\tfrac{1}{2} \\left( \\lVert X \\rVert_{F}^{2} - 2\\langle X, Y \\rangle_F + \\lVert Y \\rVert_{F}^{2} \\right)\n$$\n其中 $\\langle X, Y \\rangle_F = \\operatorname{Tr}(X^{\\top}Y)$ 是 Frobenius 内积。项 $\\lVert Y \\rVert_{F}^{2}$ 是关于 $X$ 的常数，在最小化过程中可以忽略。范数可以用奇异值表示：$\\lVert X \\rVert_{*} = \\sum_i \\sigma_i(X)$ 和 $\\lVert X \\rVert_{F}^{2} = \\sum_i \\sigma_i(X)^2$。问题等价于最小化：\n$$\n\\tilde{J}(X) = \\tau \\sum_i \\sigma_i(X) + \\tfrac{1}{2} \\sum_i \\sigma_i(X)^2 - \\operatorname{Tr}(X^{\\top}Y)\n$$\nvon Neumann 迹不等式指出，对于任意两个矩阵 $A$ 和 $B$，$\\operatorname{Tr}(A^{\\top}B) \\le \\sum_i \\sigma_i(A)\\sigma_i(B)$。当 $A$ 和 $B$ 共享相同的奇异向量时，即对于某些酉矩阵 $U$ 和 $V$，有 $A = U\\Sigma_A V^{\\top}$ 和 $B = U\\Sigma_B V^{\\top}$ 时，等号成立。为了最小化 $\\tilde{J}(X)$，我们必须最大化项 $\\operatorname{Tr}(X^{\\top}Y)$。根据 von Neumann 不等式，当 $X$ 与 $Y$ 具有相同的奇异向量时，达到这个最大值。因此，我们寻求形式为 $X = U \\Sigma_X V^{\\top}$ 的解，其中 $U$ 和 $V$ 是来自 $Y$ 的 SVD 的奇异向量矩阵。\n\n利用 Frobenius 范数的酉不变性，项 $\\lVert X - Y \\rVert_{F}^{2}$ 可简化为：\n$$\n\\lVert X - Y \\rVert_{F}^{2} = \\lVert U \\Sigma_X V^{\\top} - U \\Sigma_Y V^{\\top} \\rVert_{F}^{2} = \\lVert U(\\Sigma_X - \\Sigma_Y)V^{\\top} \\rVert_{F}^{2} = \\lVert \\Sigma_X - \\Sigma_Y \\rVert_{F}^{2}\n$$\n由于 $\\Sigma_X$ 和 $\\Sigma_Y$ 分别是以 $\\sigma_i(X)$ 和 $\\sigma_i(Y)$ 为对角元素的对角矩阵，这变为：\n$$\n\\lVert \\Sigma_X - \\Sigma_Y \\rVert_{F}^{2} = \\sum_i (\\sigma_i(X) - \\sigma_i(Y))^2\n$$\n$X$ 的核范数为 $\\lVert X \\rVert_{*} = \\sum_i \\sigma_i(X)$。将这些代入原始优化问题，我们现在对奇异值 $\\sigma_i(X)$ 进行最小化：\n$$\n\\min_{\\{\\sigma_i(X) \\ge 0\\}} \\left\\{ \\tau \\sum_i \\sigma_i(X) + \\tfrac{1}{2} \\sum_i (\\sigma_i(X) - \\sigma_i(Y))^2 \\right\\}\n$$\n这个问题是可分离的，意味着我们可以独立地求解每个 $\\sigma_i(X)$。对于每个 $i$，我们求解：\n$$\n\\min_{\\sigma \\ge 0} \\left\\{ \\tau \\sigma + \\tfrac{1}{2} (\\sigma - \\sigma_i(Y))^2 \\right\\}\n$$\n设 $g(\\sigma) = \\tau \\sigma + \\tfrac{1}{2} (\\sigma - \\sigma_i(Y))^2$。这是一个凸二次函数。为了找到最小值，我们计算关于 $\\sigma$ 的导数并将其设为零（暂时忽略非负性约束）：\n$$\n\\frac{dg}{d\\sigma} = \\tau + (\\sigma - \\sigma_i(Y)) = 0 \\implies \\sigma = \\sigma_i(Y) - \\tau\n$$\n现在，我们必须强制执行约束 $\\sigma \\ge 0$。\n1. 如果 $\\sigma_i(Y) - \\tau > 0$，无约束最小化算子是正的，因此它是有效解。最优值为 $\\sigma^{\\star} = \\sigma_i(Y) - \\tau$。\n2. 如果 $\\sigma_i(Y) - \\tau \\le 0$，无约束最小化算子是非正的。由于 $g(\\sigma)$ 是一个开口向上、顶点在 $\\sigma_i(Y) - \\tau$ 的抛物线，对于 $\\sigma > \\sigma_i(Y) - \\tau$，该函数是递增的。因此，在定义域 $\\sigma \\ge 0$ 上，最小值在边界处达到，即 $\\sigma^{\\star} = 0$。\n\n结合这两种情况，每个奇异值的解是：\n$$\n\\sigma_i(L^{\\star}) = \\max(0, \\sigma_i(Y) - \\tau) = (\\sigma_i(Y) - \\tau)_+\n$$\n这个操作被称为软阈值。通过对 $Y$ 的奇异值应用此变换，同时保持奇异向量不变，构造出结果矩阵 $L^{\\star}$：\n$$\nL^{\\star} = U \\mathcal{S}_{\\tau}(\\Sigma_Y) V^{\\top}\n$$\n其中 $\\mathcal{S}_{\\tau}(\\Sigma_Y)$ 是对角元素为 $\\max(0, \\sigma_i(Y)-\\tau)$ 的对角矩阵。这个变换被称为奇异值阈值（SVT）算子。\n\n现在我们将此结果应用于给定的问题。我们有一个矩阵 $Y$，其奇异值为 $(\\sigma_1, \\sigma_2, \\sigma_3) = (5, 3, 0)$，阈值为 $\\tau = 2$。\n我们使用推导出的规则计算 $L^{\\star} = \\operatorname{prox}_{\\tau \\lVert \\cdot \\rVert_{*}}(Y)$ 的奇异值。我们将 $L^{\\star}$ 的奇异值表示为 $\\sigma_i^{\\star}$。\n\n对于 $\\sigma_1 = 5$：\n$$\n\\sigma_1^{\\star} = \\max(0, 5 - 2) = \\max(0, 3) = 3\n$$\n对于 $\\sigma_2 = 3$：\n$$\n\\sigma_2^{\\star} = \\max(0, 3 - 2) = \\max(0, 1) = 1\n$$\n对于 $\\sigma_3 = 0$：\n$$\n\\sigma_3^{\\star} = \\max(0, 0 - 2) = \\max(0, -2) = 0\n$$\n$L^{\\star}$ 的奇异值按非递增顺序排列为 $(3, 1, 0)$。\n\n矩阵的秩是其非零奇异值的数量。对于 $L^{\\star}$，非零奇异值为 $3$ 和 $1$。共有两个这样的值。\n因此，$L^{\\star}$ 的秩为 $2$。\n\n最终答案需要 $L^{\\star}$ 的奇异值和 $L^{\\star}$ 的秩。它们是 $(3, 1, 0)$ 和 $2$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n3  1  0  2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "主成分追逐（Principal Component Pursuit, PCP）通过将数据矩阵分解为低秩和稀疏两个部分来解决RPCA问题。算法通过对混合数据交替应用两种不同的“滤波器”来实现这一分离。这个练习提供了一个具体的单步计算，让你亲身体验这个过程：我们对数据矩阵同时应用在前一个练习中推导出的奇异值阈值算子来更新低秩部分 $L$，并应用一种不同的算子——逐元素软阈值（soft-thresholding）——来更新稀疏部分 $S$。",
            "id": "3474825",
            "problem": "考虑一个称为主成分追踪 (Principal Component Pursuit, PCP) 的凸分解模型，该模型旨在从数据中寻求一个低秩矩阵和一个稀疏矩阵。PCP 求解最小化核范数与缩放后的逐元素1-范数之和的优化问题。具体而言，给定一个数据矩阵 $D \\in \\mathbb{R}^{m \\times n}$ 和一个参数 $\\lambda > 0$，PCP 的目标是关于 $L$ 和 $S$ 在约束条件 $L + S = D$ 下最小化 $\\lVert L \\rVert_{*} + \\lambda \\lVert S \\rVert_{1}$，其中 $\\lVert L \\rVert_{*}$ 表示核范数（奇异值之和），$\\lVert S \\rVert_{1}$ 表示逐元素1-范数（绝对值之和）。\n\nPCP 解的一个近端步可以定义为：分别应用核范数的近端算子更新 $L$ 和逐元素1-范数的近端算子更新 $S$。设两次更新的近端参数均为 $1$。即，定义\n$$\nL := \\operatorname{prox}_{\\lVert \\cdot \\rVert_{*}}(D) = \\arg\\min_{X} \\left\\{ \\lVert X \\rVert_{*} + \\frac{1}{2}\\lVert X - D \\rVert_{F}^{2} \\right\\},\n$$\n和\n$$\nS := \\operatorname{prox}_{\\lambda \\lVert \\cdot \\rVert_{1}}(D) = \\arg\\min_{Y} \\left\\{ \\lambda \\lVert Y \\rVert_{1} + \\frac{1}{2}\\lVert Y - D \\rVert_{F}^{2} \\right\\},\n$$\n其中 $\\lVert \\cdot \\rVert_{F}$ 表示 Frobenius 范数。众所周知，$\\operatorname{prox}_{\\lVert \\cdot \\rVert_{*}}$ 通过奇异值阈值化起作用，而 $\\operatorname{prox}_{\\lambda \\lVert \\cdot \\rVert_{1}}$ 通过逐元素软阈值化起作用，但计算应遵循近端算子和正交不变性的基本原理。\n\n给定特定矩阵\n$$\nD = \\begin{bmatrix} 1  0 \\\\ 0  10 \\end{bmatrix}\n$$\n和参数 $\\lambda = 1$，对 $L$ 和 $S$ 执行上述近端更新。以单行向量的形式，按顺序 $\\big(L_{11}, L_{12}, L_{21}, L_{22}, S_{11}, S_{12}, S_{21}, S_{22}\\big)$ 报告更新后的对 $(L,S)$。最终答案必须是按规定格式的单个解析表达式，无需四舍五入。",
            "solution": "问题陈述已经过验证，被认为是合理的。它提出了一个凸优化领域内的适定数学问题，具体涉及与主成分追踪 (PCP) 模型相关的近端算子。所有定义和参数都已提供，任务明确。我们将着手求解。\n\n问题要求计算将两个不同的近端算子应用于给定数据矩阵 $D$ 后得到的两个矩阵 $L$ 和 $S$。输入为矩阵 $D = \\begin{bmatrix} 1  0 \\\\ 0  10 \\end{bmatrix}$ 和参数 $\\lambda = 1$。\n\n首先，我们计算矩阵 $L$，其定义为：\n$$\nL := \\operatorname{prox}_{\\lVert \\cdot \\rVert_{*}}(D) = \\arg\\min_{X \\in \\mathbb{R}^{2 \\times 2}} \\left\\{ \\lVert X \\rVert_{*} + \\frac{1}{2}\\lVert X - D \\rVert_{F}^{2} \\right\\}\n$$\n这是核范数 $\\lVert \\cdot \\rVert_{*}$ 的近端算子，步长参数为 $\\tau=1$。该优化问题的解由奇异值阈值化 (Singular Value Thresholding, SVT) 算子给出。SVT 算子作用于输入矩阵的奇异值。设 $D$ 的奇异值分解 (Singular Value Decomposition, SVD) 为 $D = U \\Sigma V^T$。那么解 $L$ 由 $L = U S_{1}(\\Sigma) V^T$ 给出，其中 $S_{1}(\\cdot)$ 是应用于 $\\Sigma$ 对角元素的软阈值化算子，阈值为 $1$。对于非负值 $x$ 和阈值 $\\tau$，软阈值化函数为 $S_{\\tau}(x) = \\max(x - \\tau, 0)$。\n\n该结果的推导依赖于酉不变范数的性质。Frobenius 范数 $\\lVert \\cdot \\rVert_F$ 是酉不变的，意味着对于任何酉矩阵 $U, V$，都有 $\\lVert A \\rVert_F = \\lVert UAV^T \\rVert_F$。核范数也是酉不变的。使用 $D$ 的 SVD，该优化问题可以重写为：\n$$\n\\arg\\min_{X} \\left\\{ \\lVert X \\rVert_{*} + \\frac{1}{2}\\lVert X - U\\Sigma V^T \\rVert_{F}^{2} \\right\\} = \\arg\\min_{X} \\left\\{ \\lVert U^T X V \\rVert_{*} + \\frac{1}{2}\\lVert U^T X V - \\Sigma \\rVert_{F}^{2} \\right\\}\n$$\n令 $X' = U^T X V$，问题变为 $\\arg\\min_{X'} \\left\\{ \\lVert X' \\rVert_{*} + \\frac{1}{2}\\lVert X' - \\Sigma \\rVert_{F}^{2} \\right\\}$。根据 Von Neumann 迹不等式，当 $X'$ 是对角矩阵时达到最小值。问题就解耦为对 $X'$ 的每个对角元素（它们对应于一个奇异值）的求解。对于 $D$ 的每个奇异值 $\\sigma_i$，我们求解 $\\min_{x_i \\ge 0} \\{ x_i + \\frac{1}{2}(x_i - \\sigma_i)^2 \\}$，其解为 $x_i = \\max(\\sigma_i - 1, 0)$。\n\n现在我们将此过程应用于给定矩阵 $D = \\begin{bmatrix} 1  0 \\\\ 0  10 \\end{bmatrix}$。由于 $D$ 是一个对角矩阵，其奇异值是其对角元素的绝对值，即 $\\sigma_1 = 10$ 和 $\\sigma_2 = 1$。$U$ 和 $V$ 中对应的奇异向量可以进行排列。为了符合 $\\sigma_1 \\ge \\sigma_2$ 的常规排序，我们有：\n$\\Sigma = \\begin{bmatrix} 10  0 \\\\ 0  1 \\end{bmatrix}$， $U = \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix}$， 以及 $V = \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix}$。\n我们验证此 SVD：$U \\Sigma V^T = \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix} \\begin{bmatrix} 10  0 \\\\ 0  1 \\end{bmatrix} \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix} = \\begin{bmatrix} 0  1 \\\\ 10  0 \\end{bmatrix} \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix} = \\begin{bmatrix} 1  0 \\\\ 0  10 \\end{bmatrix} = D$。\n\n接下来，我们对奇异值应用阈值为 $\\tau=1$ 的软阈值化：\n$\\hat{\\sigma}_1 = S_{1}(10) = \\max(10 - 1, 0) = 9$。\n$\\hat{\\sigma}_2 = S_{1}(1) = \\max(1 - 1, 0) = 0$。\n阈值化后的奇异值矩阵为 $\\hat{\\Sigma} = \\begin{bmatrix} 9  0 \\\\ 0  0 \\end{bmatrix}$。\n\n最后，我们重构 $L$：\n$L = U \\hat{\\Sigma} V^T = \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix} \\begin{bmatrix} 9  0 \\\\ 0  0 \\end{bmatrix} \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix} = \\begin{bmatrix} 0  0 \\\\ 9  0 \\end{bmatrix} \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix} = \\begin{bmatrix} 0  0 \\\\ 0  9 \\end{bmatrix}$。\n因此，$L$ 的元素为 $L_{11}=0, L_{12}=0, L_{21}=0, L_{22}=9$。\n\n第二，我们计算矩阵 $S$，其定义为：\n$$\nS := \\operatorname{prox}_{\\lambda \\lVert \\cdot \\rVert_{1}}(D) = \\arg\\min_{Y \\in \\mathbb{R}^{2 \\times 2}} \\left\\{ \\lambda \\lVert Y \\rVert_{1} + \\frac{1}{2}\\lVert Y - D \\rVert_{F}^{2} \\right\\}\n$$\n当 $\\lambda=1$ 时，目标函数为 $\\sum_{i,j} \\left(|Y_{ij}| + \\frac{1}{2}(Y_{ij} - D_{ij})^2\\right)$。由于目标函数在矩阵 $Y$ 的各个元素上是可分的，我们可以通过求解以下一维问题来独立地求解每个元素 $S_{ij}$：\n$S_{ij} = \\arg\\min_{y \\in \\mathbb{R}} \\left\\{ |y| + \\frac{1}{2}(y - D_{ij})^2 \\right\\}$。\n其解为标量软阈值化算子，$S_{1}(D_{ij}) = \\operatorname{sgn}(D_{ij}) \\max(|D_{ij}| - 1, 0)$。\n\n我们将此算子应用于 $D = \\begin{bmatrix} 1  0 \\\\ 0  10 \\end{bmatrix}$ 的每个元素：\n$S_{11} = S_{1}(1) = \\operatorname{sgn}(1) \\max(|1| - 1, 0) = 1 \\cdot 0 = 0$。\n$S_{12} = S_{1}(0) = \\operatorname{sgn}(0) \\max(|0| - 1, 0) = 0 \\cdot 0 = 0$。\n$S_{21} = S_{1}(0) = \\operatorname{sgn}(0) \\max(|0| - 1, 0) = 0 \\cdot 0 = 0$。\n$S_{22} = S_{1}(10) = \\operatorname{sgn}(10) \\max(|10| - 1, 0) = 1 \\cdot 9 = 9$。\n因此，矩阵 $S$ 为 $S = \\begin{bmatrix} 0  0 \\\\ 0  9 \\end{bmatrix}$。\n$S$ 的元素为 $S_{11}=0, S_{12}=0, S_{21}=0, S_{22}=9$。\n\n问题要求以单行向量的形式，并按顺序 $\\big(L_{11}, L_{12}, L_{21}, L_{22}, S_{11}, S_{12}, S_{21}, S_{22}\\big)$ 报告更新后的对 $(L, S)$。\n代入计算出的值，我们得到向量 $(0, 0, 0, 9, 0, 0, 0, 9)$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0  0  0  9  0  0  0  9\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在理解了分离低秩和稀疏分量的核心更新规则之后，我们现在可以将它们组合成一个完整的迭代算法。这个动手编程练习要求你实现一个求解RPCA问题的经典算法：交替近端最小化。通过构建这个算法并在合成数据上进行测试，你将能直接观察到，通过反复迭代应用SVT和软阈值，如何成功地将一个矩阵分解为其低秩和稀疏的组成部分。",
            "id": "3474831",
            "problem": "要求您实现并分析一个用于鲁棒主成分分析（Robust Principal Component Analysis, RPCA）的简单交替邻近最小化算法。RPCA是压缩感知和稀疏优化中的一个典型问题。考虑一个数据矩阵 $M \\in \\mathbb{R}^{m \\times n}$，它可以分解为 $M = L_{\\star} + S_{\\star}$，其中 $L_{\\star}$ 是低秩的，$S_{\\star}$ 是稀疏的。从使用核范数和逐元素绝对值范数的凸正则化这一基础出发，考虑以下无约束惩罚目标函数\n$$\n\\min_{L, S \\in \\mathbb{R}^{m \\times n}} \\; \\frac{1}{2} \\lVert M - L - S \\rVert_{F}^{2} + \\mu \\lVert L \\rVert_{\\ast} + \\lambda \\lVert S \\rVert_{1},\n$$\n其中 $\\lVert \\cdot \\rVert_{F}$ 是弗罗贝尼乌斯范数（Frobenius norm），$\\lVert \\cdot \\rVert_{\\ast}$ 是核范数（奇异值之和），$\\lVert \\cdot \\rVert_{1}$ 是逐元素的 $\\ell_{1}$ 范数。您的程序必须实现一个交替邻近最小化方案，该方案在最小化关于 $L$ 的目标函数（固定 $S$）和最小化关于 $S$ 的目标函数（固定 $L$）之间交替进行。核范数的邻近算子对应于奇异值阈值化，而逐元素 $\\ell_{1}$ 范数的邻近算子对应于逐元素软阈值化。\n\n请基于邻近算子、核范数和 $\\ell_{1}$ 范数的定义，以及矩阵的奇异值分解，从基本原理出发进行推导。除了由这些范数定义的交替最小化和邻近更新之外，不要假设任何特殊的算法模板。\n\n您的程序必须：\n- 构建合成测试矩阵 $M = L_{\\star} + S_{\\star}$，用于一个小型测试套件，其中 $L_{\\star}$ 具有指定的秩，$S_{\\star}$ 具有指定的稀疏支撑集。使用正交生成向量（从随机高斯矩阵通过QR分解获得）和固定的奇异值来生成 $L_{\\star}$，并为 $S_{\\star}$ 选择一个随机支撑集，其非零项具有固定的大小和随机的符号。为保证可复现性，请使用固定的伪随机数种子。\n- 运行交替邻近最小化更新：\n  - 通过将 $\\mu \\lVert \\cdot \\rVert_{\\ast}$ 的邻近映射应用于 $M - S$ 来更新 $L$。\n  - 通过将 $\\lambda \\lVert \\cdot \\rVert_{1}$ 的邻近映射应用于 $M - L$ 来更新 $S$。\n- 将 $L$ 和 $S$ 初始化为零矩阵。\n- 在每次迭代中，检查估计的低秩矩阵是否具有正确的秩（即大于固定阈值的奇异值数量与真实秩匹配），以及估计的稀疏矩阵是否具有完全正确的支撑集（即大小大于固定阈值的索引集合与真实支撑集匹配）。为这两项检查定义一个小的绝对阈值，分别为 $\\tau_{\\text{rank}} = 10^{-6}$ 和 $\\tau_{\\text{supp}} = 10^{-6}$。\n- 报告首次同时满足正确秩和正确支撑集两个条件的迭代次数。如果在最多 $1000$ 次迭代内未能满足，则该测试用例报告 $-1$。使用一个收敛保障措施来更新迭代，直到达到最大迭代次数上限，或者 $(L,S)$ 的相对变化量低于 $10^{-8}$。\n\n测试套件：\n实现以下参数的四个测试用例。对于每个案例，按规定生成 $L_{\\star}$ 和 $S_{\\star}$，设置 $M = L_{\\star} + S_{\\star}$，并使用指定的 $(\\mu,\\lambda)$ 运行算法。\n\n- 案例A（理想情况，混合低秩和稀疏）：\n  - 维度：$m = 12$， $n = 10$。\n  - $L_{\\star}$ 的秩：$r = 2$，奇异值为 $[8.0, 6.0]$。\n  - 稀疏支撑集大小：$12$ 个非零项，大小为 $5.0$，符号为随机的 $\\pm 1$。\n  - 参数：$\\mu = 1.0$，$\\lambda = 0.35$。\n  - 随机数种子：$0$。\n\n- 案例B（边界条件，无稀疏分量）：\n  - 维度：$m = 15$， $n = 10$。\n  - $L_{\\star}$ 的秩：$r = 3$，奇异值为 $[5.0, 4.0, 3.0]$。\n  - 稀疏支撑集大小：$0$。\n  - 参数：$\\mu = 0.8$，$\\lambda = 0.30$。\n  - 随机数种子：$1$。\n\n- 案例C（边界条件，无低秩分量）：\n  - 维度：$m = 10$， $n = 10$。\n  - $L_{\\star}$ 的秩：$r = 0$。\n  - 稀疏支撑集大小：$15$ 个非零项，大小为 $4.0$，符号为随机的 $\\pm 1$。\n  - 参数：$\\mu = 1.0$，$\\lambda = 0.50$。\n  - 随机数种子：$2$。\n\n- 案例D（接近阈值的较难情况）：\n  - 维度：$m = 10$， $n = 10$。\n  - $L_{\\star}$ 的秩：$r = 2$，奇异值为 $[1.2, 1.1]$。\n  - 稀疏支撑集大小：$8$ 个非零项，大小为 $0.6$，符号为随机的 $\\pm 1$。\n  - 参数：$\\mu = 0.8$，$\\lambda = 0.45$。\n  - 随机数种子：$3$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含四个案例的迭代次数，格式为方括号内的逗号分隔列表（例如，$\\texttt{[7,4,5,-1]}$）。不应打印任何额外文本。本问题不涉及物理单位，也无需指定角度。所有数值输出均为纯整数。原则上允许使用任何语言，但您的最终答案必须是一个完整的、可运行的程序，并遵守所提供的执行环境约束。",
            "solution": "该问题要求实现一个交替邻近最小化算法来解决鲁棒主成分分析（RPCA）问题。该解决方案旨在将给定的数据矩阵 $M \\in \\mathbb{R}^{m \\times n}$ 分解为一个低秩分量 $L$ 和一个稀疏分量 $S$。这通过求解以下凸优化问题来实现：\n$$\n\\min_{L, S \\in \\mathbb{R}^{m \\times n}} \\; f(L, S) = \\frac{1}{2} \\lVert M - L - S \\rVert_{F}^{2} + \\mu \\lVert L \\rVert_{\\ast} + \\lambda \\lVert S \\rVert_{1}\n$$\n此处，$\\lVert \\cdot \\rVert_{F}$ 是弗罗贝尼乌斯范数，用于衡量数据保真度；$\\lVert \\cdot \\rVert_{\\ast}$ 是核范数（奇异值之和），作为 $L$ 的秩的凸代理；$\\lVert \\cdot \\rVert_{1}$ 是逐元素的 $\\ell_{1}$ 范数（各项绝对值之和），用于促进 $S$ 的稀疏性。参数 $\\mu > 0$ 和 $\\lambda > 0$ 控制数据保真度与低秩和稀疏正则化项之间的权衡。\n\n所选的解决方法是一种交替最小化方案，它是块坐标下降的一种形式。在每次迭代中，我们针对一个变量最小化目标函数，同时保持另一个变量固定。这将联合最小化问题分解为两个更简单的子问题。\n\n**步骤1：关于 $L$ 的最小化**\n\n将 $S$ 固定为上一次迭代的值 $S_k$，更新 $L$ 的子问题是：\n$$\nL_{k+1} = \\arg\\min_{L} \\frac{1}{2} \\lVert M - L - S_k \\rVert_{F}^{2} + \\mu \\lVert L \\rVert_{\\ast}\n$$\n这可以重写为：\n$$\nL_{k+1} = \\arg\\min_{L} \\frac{1}{2} \\lVert (M - S_k) - L \\rVert_{F}^{2} + \\mu \\lVert L \\rVert_{\\ast}\n$$\n这是应用于矩阵 $M - S_k$ 的、由 $\\mu$ 缩放的核范数的邻近算子的定义。该邻近算子表示为 $\\text{prox}_{\\mu \\lVert \\cdot \\rVert_{\\ast}}$，由奇异值阈值化（Singular Value Thresholding, SVT）算子给出。对于任何矩阵 $X \\in \\mathbb{R}^{m \\times n}$，其奇异值分解（SVD）为 $X = U \\Sigma V^T$，其中 $\\Sigma = \\text{diag}(\\{\\sigma_i\\}_{i=1}^{\\min(m,n)})$，SVT算子定义如下：\n$$\n\\text{prox}_{\\mu \\lVert \\cdot \\rVert_{\\ast}}(X) = U \\mathcal{S}_{\\mu}(\\Sigma) V^T\n$$\n其中 $\\mathcal{S}_{\\mu}(\\Sigma)$ 是一个对角矩阵，其对角线上的元素为 $(\\mathcal{S}_{\\mu}(\\Sigma))_{ii} = \\max(0, \\sigma_i - \\mu)$。此操作有效地将 $X$ 的奇异值向零收缩 $\\mu$ 的量，并将任何小于 $\\mu$ 的奇异值设为零，从而促进低秩结构。\n\n**步骤2：关于 $S$ 的最小化**\n\n接下来，我们将 $L$ 固定为其新计算出的值 $L_{k+1}$，并求解 $S$：\n$$\nS_{k+1} = \\arg\\min_{S} \\frac{1}{2} \\lVert M - L_{k+1} - S \\rVert_{F}^{2} + \\lambda \\lVert S \\rVert_{1}\n$$\n这可以重写为：\n$$\nS_{k+1} = \\arg\\min_{S} \\frac{1}{2} \\lVert (M - L_{k+1}) - S \\rVert_{F}^{2} + \\lambda \\lVert S \\rVert_{1}\n$$\n这是应用于矩阵 $M - L_{k+1}$ 的、由 $\\lambda$ 缩放的 $\\ell_1$ 范数的邻近算子的定义。由于弗罗贝尼乌斯范数和 $\\ell_1$ 范数在矩阵元素上是可分离的，该问题可以逐元素求解。对于每个元素 $(i,j)$，问题是：\n$$\n(S_{k+1})_{ij} = \\arg\\min_{s_{ij}} \\frac{1}{2} ((M-L_{k+1})_{ij} - s_{ij})^2 + \\lambda |s_{ij}|\n$$\n解由逐元素软阈值化算子 $\\mathcal{S}_{\\lambda}$ 给出：\n$$\n(S_{k+1})_{ij} = \\mathcal{S}_{\\lambda}((M-L_{k+1})_{ij}) = \\text{sign}((M-L_{k+1})_{ij}) \\max(0, |(M-L_{k+1})_{ij}| - \\lambda)\n$$\n此操作将每个元素的绝对值向零收缩 $\\lambda$ 的量，从而促进稀疏性。\n\n**算法与实现**\n\n完整的算法流程如下：\n1. 初始化 $L_0 = 0$ 和 $S_0 = 0$。\n2. 对于 $k=0, 1, 2, \\dots$，直到收敛或达到最大迭代次数：\n   a. 更新 $L$：$L_{k+1} = \\text{prox}_{\\mu \\lVert \\cdot \\rVert_{\\ast}}(M - S_k)$。\n   b. 更新 $S$：$S_{k+1} = \\text{prox}_{\\lambda \\lVert \\cdot \\rVert_{1}}(M - L_{k+1})$。\n\n该实现根据每个测试用例的指定参数创建合成数据 $M = L_{\\star} + S_{\\star}$。$L_{\\star}$ 是由随机正交基和指定的奇异值构造的。$S_{\\star}$ 是通过在随机支撑集上填充具有固定大小和随机符号的条目来构造的。固定的随机种子确保了可复现性。\n\n算法进行迭代，并在每一步 $k$ 中检查估计的 $L_k$ 是否具有正确的秩 $r$（奇异值大于 $\\tau_{\\text{rank}} = 10^{-6}$ 的数量），以及估计的 $S_k$ 是否具有完全正确的支撑集（$|(S_k)_{ij}| > \\tau_{\\text{supp}} = 10^{-6}$ 的索引集合与 $S_{\\star}$ 的真实支撑集匹配）。首次同时满足这两个条件的迭代次数将被记录下来。如果满足这些条件并且算法随后收敛（$(L,S)$ 的相对变化低于 $10^{-8}$），或者达到 $1000$ 次的最大迭代限制，则过程停止。如果在迭代限制内未满足成功条件，则报告 $-1$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ... # No scipy needed for this implementation.\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for Robust PCA and print results.\n    \"\"\"\n\n    def generate_data(m, n, r, singular_values, sparse_size, sparse_mag, seed):\n        \"\"\"Generates synthetic data matrix M = L_star + S_star.\"\"\"\n        rng = np.random.default_rng(seed)\n\n        # Generate L_star (low-rank matrix)\n        if r > 0:\n            U_rand = rng.standard_normal(size=(m, r))\n            U, _ = np.linalg.qr(U_rand)\n            \n            V_rand = rng.standard_normal(size=(n, r))\n            V, _ = np.linalg.qr(V_rand)\n            \n            Sigma_star = np.diag(singular_values)\n            L_star = U @ Sigma_star @ V.T\n        else:\n            L_star = np.zeros((m, n))\n\n        # Generate S_star (sparse matrix)\n        S_star = np.zeros((m, n))\n        if sparse_size > 0:\n            indices = rng.choice(m * n, size=sparse_size, replace=False)\n            row_indices, col_indices = np.unravel_index(indices, (m, n))\n            \n            signs = rng.choice([-1.0, 1.0], size=sparse_size)\n            \n            S_star[row_indices, col_indices] = signs * sparse_mag\n        \n        true_support_indices = np.where(S_star != 0)\n        \n        M = L_star + S_star\n        \n        return M, true_support_indices\n\n    def prox_nuclear(X, mu):\n        \"\"\"Singular Value Thresholding (proximal operator for nuclear norm).\"\"\"\n        U, s, Vt = np.linalg.svd(X, full_matrices=False, compute_uv=True)\n        s_thresh = np.maximum(0, s - mu)\n        return U @ np.diag(s_thresh) @ Vt\n\n    def prox_l1(X, lam):\n        \"\"\"Element-wise soft-thresholding (proximal operator for l1 norm).\"\"\"\n        return np.sign(X) * np.maximum(np.abs(X) - lam, 0)\n\n    def run_rpca_instance(m, n, true_rank, sv, sp_size, sp_mag, mu, lam, seed):\n        \"\"\"Runs the alternating proximal minimization for one RPCA instance.\"\"\"\n        M, true_support_indices = generate_data(m, n, true_rank, sv, sp_size, sp_mag, seed)\n        \n        L = np.zeros((m, n))\n        S = np.zeros((m, n))\n        \n        max_iter = 1000\n        conv_tol = 1e-8\n        rank_tol = 1e-6\n        supp_tol = 1e-6\n        \n        found_iter = -1\n        \n        true_support_mask = np.zeros((m, n), dtype=bool)\n        if sp_size > 0:\n            true_support_mask[true_support_indices] = True\n        \n        for k in range(1, max_iter + 1):\n            L_old, S_old = L.copy(), S.copy()\n            \n            # L-update\n            L = prox_nuclear(M - S, mu)\n            \n            # S-update\n            S = prox_l1(M - L, lam)\n            \n            # Check for correct rank and support (if not already found)\n            if found_iter == -1:\n                singular_values_L = np.linalg.svd(L, compute_uv=False)\n                estimated_rank = np.sum(singular_values_L > rank_tol)\n                rank_ok = (estimated_rank == true_rank)\n                \n                estimated_support_mask = np.abs(S) > supp_tol\n                support_ok = np.array_equal(estimated_support_mask, true_support_mask)\n                \n                if rank_ok and support_ok:\n                    found_iter = k\n                    \n            # Check for convergence\n            norm_L_fro_sq = np.linalg.norm(L_old, 'fro')**2\n            norm_S_fro_sq = np.linalg.norm(S_old, 'fro')**2\n            norm_val_sq = norm_L_fro_sq + norm_S_fro_sq\n\n            norm_diff_L_fro_sq = np.linalg.norm(L - L_old, 'fro')**2\n            norm_diff_S_fro_sq = np.linalg.norm(S - S_old, 'fro')**2\n            norm_diff_sq = norm_diff_L_fro_sq + norm_diff_S_fro_sq\n            \n            if norm_val_sq > 0: # Avoid division by zero, especially at first iteration\n                rel_change = np.sqrt(norm_diff_sq / norm_val_sq)\n                if rel_change  conv_tol:\n                    break\n        return found_iter\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Happy path\n        {'m': 12, 'n': 10, 'true_rank': 2, 'sv': [8.0, 6.0], 'sp_size': 12, 'sp_mag': 5.0, 'mu': 1.0, 'lam': 0.35, 'seed': 0},\n        # Case B: No sparse component\n        {'m': 15, 'n': 10, 'true_rank': 3, 'sv': [5.0, 4.0, 3.0], 'sp_size': 0, 'sp_mag': 0.0, 'mu': 0.8, 'lam': 0.30, 'seed': 1},\n        # Case C: No low-rank component\n        {'m': 10, 'n': 10, 'true_rank': 0, 'sv': [], 'sp_size': 15, 'sp_mag': 4.0, 'mu': 1.0, 'lam': 0.50, 'seed': 2},\n        # Case D: Harder case\n        {'m': 10, 'n': 10, 'true_rank': 2, 'sv': [1.2, 1.1], 'sp_size': 8, 'sp_mag': 0.6, 'mu': 0.8, 'lam': 0.45, 'seed': 3},\n    ]\n\n    results = []\n    for case_params in test_cases:\n        result = run_rpca_instance(**case_params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}