{
    "hands_on_practices": [
        {
            "introduction": "要想真正掌握一种算法，我们必须能够从头开始构建它。本练习将从第一性原理出发，为稀疏相位恢复问题推导一种基于Wirtinger流思想的投影梯度下降算法的核心迭代步骤。通过将Wirtinger微分应用于复数值的目标函数，你将巩固对此类非凸问题中梯度类方法构建方式的理解 。",
            "id": "3477906",
            "problem": "考虑复值稀疏相位恢复问题，其中一个未知的 $k$-稀疏信号 $x_{\\star} \\in \\mathbb{C}^n$ 通过二次强度 $y_i = \\lvert a_i^* x_{\\star} \\rvert^2$ 进行测量，其中 $i = 1,\\dots,m$。传感向量 $a_i \\in \\mathbb{C}^n$ 已知，且 $m \\ge n$。一种标准方法是最小化基于强度的经验损失\n$$\nf(z) = \\frac{1}{2m} \\sum_{i=1}^m \\left( \\lvert a_i^* z \\rvert^2 - y_i \\right)^2,\n$$\n其中 $z \\in \\mathbb{C}^n$ 是决策变量，使用 Wirtinger 算子来构建基于梯度的更新，同时通过投影来施加 $k$-稀疏性约束。令 $\\Sigma_k \\subset \\mathbb{C}^n$ 表示 $k$-稀疏向量的集合，并令 $\\mathcal{H}_k : \\mathbb{C}^n \\to \\Sigma_k$ 表示硬阈值算子，它保留幅值最大的 $k$ 个分量，并将其余分量置零。定义秩一埃尔米特矩阵 $M_i = a_i a_i^*$。\n\n从基本原理和经过充分检验的事实出发：\n- 测量值在 $x_{\\star}$ 上施加全局相位时保持不变，并且基于强度的损失 $f(z)$ 也遵循这种不变性。\n- 对于依赖于复变量的实值目标函数，最速下降方向由关于共轭变量的 Wirtinger 导数构成，即 $\\nabla f(z) := \\partial f(z)/\\partial \\bar{z}$。\n- 到 $\\Sigma_k$ 上的投影由 $\\mathcal{H}_k$ 实现。\n\n在步长为常数 $\\mu  0$ 的情况下，哪个选项正确地表述了用于稀疏相位恢复的投影梯度下降法的一次迭代？该迭代需使用基于强度的损失函数的恰当 Wirtinger 梯度，并通过硬阈值处理正确地投影到 $\\Sigma_k$ 上。\n\nA. $$z^{t+1} = \\mathcal{H}_k\\!\\left( z^t - \\mu \\cdot \\frac{1}{m} \\sum_{i=1}^m \\big( \\lvert a_i^* z^t \\rvert^2 - y_i \\big) \\, a_i a_i^* z^t \\right)$$\n\nB. $$z^{t+1} = \\mathcal{H}_k\\!\\left( z^t - \\mu \\cdot \\frac{2}{m} \\sum_{i=1}^m \\big( \\lvert a_i^* z^t \\rvert^2 - y_i \\big) \\, a_i a_i^* z^t \\right)$$\n\nC. $$z^{t+1} = \\mathcal{H}_k\\!\\left( z^t - \\mu \\cdot \\frac{1}{m} \\sum_{i=1}^m \\big( \\lvert a_i^\\top z^t \\rvert^2 - y_i \\big) \\, a_i a_i^\\top z^t \\right)$$\n\nD. $$z^{t+1} = \\mathcal{H}_k\\!\\left( z^t - \\mu \\cdot \\frac{1}{m} \\sum_{i=1}^m \\big( \\lvert a_i^* z^t \\rvert^2 - y_i \\big) \\, a_i z^t \\right)$$\n\nE. $$z^{t+1} = \\mathcal{S}_\\lambda\\!\\left( z^t - \\mu \\cdot \\frac{1}{m} \\sum_{i=1}^m \\big( \\lvert a_i^* z^t \\rvert - \\sqrt{y_i} \\big) \\, a_i \\right)$$\n\n这里，$\\mathcal{S}_\\lambda$ 表示参数为 $\\lambda  0$ 的复数软阈值（收缩）算子。请选择正确的选项。",
            "solution": "用户希望确定用于稀疏相位恢复的投影梯度下降法一次迭代的正确公式。\n\n### 问题验证\n\n首先，我将验证问题陈述。\n\n**步骤 1：提取已知条件**\n-   未知信号: $x_{\\star} \\in \\mathbb{C}^n$, $k$-稀疏。\n-   测量值: $y_i = \\lvert a_i^* x_{\\star} \\rvert^2$ for $i = 1, \\dots, m$。\n-   传感向量: $a_i \\in \\mathbb{C}^n$。\n-   测量数量: $m \\ge n$。\n-   损失函数: $f(z) = \\frac{1}{2m} \\sum_{i=1}^m \\left( \\lvert a_i^* z \\rvert^2 - y_i \\right)^2$。\n-   决策变量: $z \\in \\mathbb{C}^n$。\n-   稀疏性约束: 解必须位于 $k$-稀疏向量的集合 $\\Sigma_k \\subset \\mathbb{C}^n$ 中。\n-   投影算子: $\\mathcal{H}_k : \\mathbb{C}^n \\to \\Sigma_k$ 是硬阈值算子。\n-   矩阵定义: $M_i = a_i a_i^*$。\n-   算法: 步长为常数 $\\mu  0$ 的投影梯度下降法。\n-   梯度定义: 最速下降方向由 Wirtinger 导数 $\\nabla f(z) := \\partial f(z)/\\partial \\bar{z}$ 给出。\n\n**步骤 2：使用提取的已知条件进行验证**\n-   **科学基础：** 该问题描述了使用强度上的最小二乘损失来进行稀疏相位恢复的标准公式。使用 Wirtinger 算子优化复变量的实值函数是标准且正确的数学工具。带硬阈值的投影梯度下降是完成此任务的常用算法，称为迭代硬阈值（IHT）。该问题在信号处理、优化和压缩感知领域有坚实的理论基础。\n-   **适定性：** 问题要求推导一个特定的算法更新步骤。在给定损失函数、梯度定义和投影算子的情况下，这是一个明确定义的数学任务。\n-   **客观性：** 问题使用精确的数学语言和标准定义进行陈述。没有歧义或主观内容。\n\n**步骤 3：结论与行动**\n问题陈述是有效的。它具有科学合理性、适定性和客观性，提供了推导解所需的所有必要信息。我将继续进行推导。\n\n### 更新规则的推导\n\n该算法是投影梯度下降法。从当前估计 $z^t$ 开始的一次迭代由以下步骤给出：\n1.  计算梯度下降步骤：$z_{grad} = z^t - \\mu \\nabla f(z^t)$。\n2.  将结果投影到约束集上：$z^{t+1} = \\mathcal{H}_k(z_{grad})$。\n\n任务的核心是计算 Wirtinger 梯度 $\\nabla f(z) = \\partial f(z)/\\partial \\bar{z}$。损失函数为：\n$$\nf(z) = \\frac{1}{2m} \\sum_{i=1}^m \\left( \\lvert a_i^* z \\rvert^2 - y_i \\right)^2\n$$\n关于 $\\bar{z}$ 的梯度可以通过逐项求导得到：\n$$\n\\nabla f(z) = \\frac{\\partial f(z)}{\\partial \\bar{z}} = \\frac{1}{2m} \\sum_{i=1}^m \\frac{\\partial}{\\partial \\bar{z}} \\left( \\lvert a_i^* z \\rvert^2 - y_i \\right)^2\n$$\n我们应用 Wirtinger 导数的链式法则。令 $u_i(z, \\bar{z}) = \\lvert a_i^* z \\rvert^2 - y_i$。那么求和中的项是 $(u_i)^2$。\n$$\n\\frac{\\partial (u_i)^2}{\\partial \\bar{z}} = 2 u_i \\frac{\\partial u_i}{\\partial \\bar{z}} = 2 \\left( \\lvert a_i^* z \\rvert^2 - y_i \\right) \\frac{\\partial}{\\partial \\bar{z}} \\left( \\lvert a_i^* z \\rvert^2 - y_i \\right)\n$$\n由于 $y_i$ 是常数，其导数为零。我们只需要求 $\\lvert a_i^* z \\rvert^2$ 的导数。\n这一项可以写成二次型：\n$$\n\\lvert a_i^* z \\rvert^2 = (a_i^* z)^* (a_i^* z) = (z^* a_i) (a_i^* z) = z^* (a_i a_i^*) z\n$$\n矩阵 $M_i = a_i a_i^*$ 是埃尔米特矩阵，因为 $M_i^* = (a_i a_i^*)^* = (a_i^*)^* a_i^* = a_i a_i^* = M_i$。\n对于一个通用的埃尔米特矩阵 $Q$，二次型 $z^* Q z$ 关于 $\\bar{z}$ 的 Wirtinger 导数是一个标准结果：\n$$\n\\frac{\\partial (z^* Q z)}{\\partial \\bar{z}} = Q z\n$$\n将此结果应用于 $Q = M_i = a_i a_i^*$，我们得到：\n$$\n\\frac{\\partial}{\\partial \\bar{z}} \\left( \\lvert a_i^* z \\rvert^2 \\right) = (a_i a_i^*) z\n$$\n将此代回链式法则表达式中：\n$$\n\\frac{\\partial}{\\partial \\bar{z}} \\left( \\lvert a_i^* z \\rvert^2 - y_i \\right)^2 = 2 \\left( \\lvert a_i^* z \\rvert^2 - y_i \\right) (a_i a_i^*) z\n$$\n现在，我们可以整合出 $f(z)$ 的完整梯度：\n$$\n\\nabla f(z) = \\frac{1}{2m} \\sum_{i=1}^m 2 \\left( \\lvert a_i^* z \\rvert^2 - y_i \\right) (a_i a_i^*) z\n$$\n系数 $2$ 被约掉，得到：\n$$\n\\nabla f(z) = \\frac{1}{m} \\sum_{i=1}^m \\left( \\lvert a_i^* z \\rvert^2 - y_i \\right) (a_i a_i^*) z\n$$\n最后，我们构建在第 $t$ 次迭代时的投影梯度下降更新规则：\n$$\nz^{t+1} = \\mathcal{H}_k \\left( z^t - \\mu \\nabla f(z^t) \\right)\n$$\n$$\nz^{t+1} = \\mathcal{H}_k \\left( z^t - \\mu \\cdot \\frac{1}{m} \\sum_{i=1}^m \\left( \\lvert a_i^* z^t \\rvert^2 - y_i \\right) (a_i a_i^*) z^t \\right)\n$$\n这是基于问题规范的正确更新规则。\n\n### 逐项分析\n\n现在我将根据推导出的结果来评估每个选项。\n\n**A.** $$z^{t+1} = \\mathcal{H}_k\\!\\left( z^t - \\mu \\cdot \\frac{1}{m} \\sum_{i=1}^m \\big( \\lvert a_i^* z^t \\rvert^2 - y_i \\big) \\, a_i a_i^* z^t \\right)$$\n这个表达式与推导出的更新规则完全匹配。Wirtinger 梯度的计算是正确的，包括前导因子 $\\frac{1}{m}$，并且投影算子 $\\mathcal{H}_k$ 的应用也是正确的。\n**结论：正确。**\n\n**B.** $$z^{t+1} = \\mathcal{H}_k\\!\\left( z^t - \\mu \\cdot \\frac{2}{m} \\sum_{i=1}^m \\big( \\lvert a_i^* z^t \\rvert^2 - y_i \\big) \\, a_i a_i^* z^t \\right)$$\n这个选项在梯度项中包含一个错误的因子 $2$。对平方项求导的链式法则产生的因子 $2$ 与损失函数定义 $f(z) = \\frac{1}{2m} \\sum(\\dots)^2$ 中的因子 $\\frac{1}{2}$ 相抵消。求和的正确前置因子是 $\\frac{1}{m}$。\n**结论：不正确。**\n\n**C.** $$z^{t+1} = \\mathcal{H}_k\\!\\left( z^t - \\mu \\cdot \\frac{1}{m} \\sum_{i=1}^m \\big( \\lvert a_i^\\top z^t \\rvert^2 - y_i \\big) \\, a_i a_i^\\top z^t \\right)$$\n这个选项错误地使用了转置算子 ($^\\top$) 而不是共轭转置算子 ($^*$)。对于复值向量，内积和诱导范数是使用共轭转置定义的。问题陈述本身就是使用共轭转置来定义测量值 ($y_i = \\lvert a_i^* x_{\\star} \\rvert^2$)。在这种情况下，使用转置在数学上是不正确的。\n**结论：不正确。**\n\n**D.** $$z^{t+1} = \\mathcal{H}_k\\!\\left( z^t - \\mu \\cdot \\frac{1}{m} \\sum_{i=1}^m \\big( \\lvert a_i^* z^t \\rvert^2 - y_i \\big) \\, a_i z^t \\right)$$\n这个选项的梯度项格式不正确。表达式 $a_i z^t$ 不是标准的向量或矩阵运算。如果是逐元素相乘，会有不同的表示法。正确的梯度涉及矩阵-向量积 $(a_i a_i^*) z^t$。项 $a_i z^t$ 在维度和运算上都与 Wirtinger 算子的结果不一致。\n**结论：不正确。**\n\n**E.** $$z^{t+1} = \\mathcal{S}_\\lambda\\!\\left( z^t - \\mu \\cdot \\frac{1}{m} \\sum_{i=1}^m \\big( \\lvert a_i^* z^t \\rvert - \\sqrt{y_i} \\big) \\, a_i \\right)$$\n这个选项因多个原因而不正确。\n1.  它使用了软阈值算子 $\\mathcal{S}_\\lambda$，这是 $\\ell_1$-范数的近端算子，而不是问题中为施加 $k$-稀疏性而指定的硬阈值算子 $\\mathcal{H}_k$。\n2.  其梯度项是从基于幅值的损失函数 $\\sum (\\lvert a_i^* z \\rvert - \\sqrt{y_i})^2$ 推导出来的，而不是问题中给出的基于强度的损失函数 $\\sum (\\lvert a_i^* z \\rvert^2 - y_i)^2$。\n3.  即使对于基于幅值的损失，所示的梯度项也是不正确的。此更新规则对应于应用于不同优化问题的不同算法（如 FISTA 或 ISTA）。\n**结论：不正确。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "梯度类方法的成功在很大程度上取决于损失函数的地形（landscape）结构。在像相位恢复这样的非凸问题中，算法可能会被困在并非全局解的伪稳态点（spurious stationary points）。本练习通过构建一个具体的简单例子来让你动手探索这一挑战 。你将运用微积分知识验证该点的平稳性，并使用Hessian矩阵 $H$ 分析其性质，从而对非凸优化的难点获得关键的直觉。",
            "id": "3477917",
            "problem": "考虑在非高斯结构化测量下的稀疏相位恢复问题。其目标是从仅有强度的测量值 $y_{i}^{2} = |a_{i}^{\\top} x_{0}|^{2}$ 中恢复一个未知的稀疏信号 $x_{0} \\in \\mathbb{R}^{n}$，其中 $a_{i} \\in \\mathbb{R}^{n}$ 是测量向量。一种常见的方法（Wirtinger流，WF）是对四次强度损失函数执行梯度下降\n$$\nf(z) = \\frac{1}{4 m} \\sum_{i=1}^{m} \\left( |a_{i}^{\\top} z|^{2} - |a_{i}^{\\top} x_{0}|^{2} \\right)^{2},\n$$\n其中 $z \\in \\mathbb{R}^{n}$ 是重构变量。在实值设定中，Wirtinger梯度与标准梯度一致，临界点满足 $\\nabla f(z) = 0$。在测量是非高斯或结构化相干的情况下，全局最小值点的吸引盆之外可能存在虚假驻点。\n\n构造一个具体的反例，该反例在吸引盆之外存在一个虚假驻点。具体方法是指定一个稀疏的真实信号 $x_{0} \\in \\mathbb{R}^{2}$ 和三个结构化的测量向量 $a_{1}, a_{2}, a_{3} \\in \\mathbb{R}^{2}$，然后分析所引出的强度损失 $f$。使用以下数据：\n- 选择 $x_{0} = (1, 0)^{\\top}$，这是一个 $1$-稀疏向量。\n- 选择 $m = 3$ 以及结构化的非高斯测量向量 $a_{1} = (1, 0)^{\\top}$，$a_{2} = (0, 1)^{\\top}$ 和 $a_{3} = (1, 1)^{\\top}$。\n\n任务：\n1. 从 $f$ 的定义出发，仅使用基本的微分和代数法则，将 $f(z)$ 显式地写成关于 $z = (z_{1}, z_{2})^{\\top} \\in \\mathbb{R}^{2}$ 的函数。\n2. 在实值设定下，推导通用 $z$ 的梯度 $\\nabla f(z)$，然后在 $z = (0, 0)^{\\top}$ 处求值，以证明 $z = (0, 0)^{\\top}$ 是一个驻点。除了链式法则和乘积法则外，不要假设或使用任何现成的梯度公式。\n3. 计算 $f(0, 0)$ 并将其与 $f(x_{0})$ 比较，以表明 $z = (0, 0)^{\\top}$ 不是全局最小值点。\n4. 计算在 $z = (0, 0)^{\\top}$ 处的海森矩阵 $\\nabla^{2} f(z)$，并确定其最小特征值的精确形式。将最小特征值作为最终答案。\n\n最终答案必须是 $\\nabla^{2} f(0, 0)$ 的最小特征值，以单一闭式解析表达式的形式给出。不需要四舍五入。不涉及单位。",
            "solution": "该问题要求我们分析一个稀疏相位恢复特定实例的损失函数，证明存在一个虚假驻点，并通过计算海森矩阵及其特征值来刻画其性质。\n\n首先，我们验证问题陈述的有效性。\n问题提供了一个信号 $x_0 \\in \\mathbb{R}^n$、测量向量 $a_i \\in \\mathbb{R}^n$ 和一个损失函数 $f(z)$。给定的值为 $n=2$，$x_0=(1,0)^\\top$，$m=3$，$a_1=(1,0)^\\top$，$a_2=(0,1)^\\top$ 和 $a_3=(1,1)^\\top$。函数 $f(z) = \\frac{1}{4 m} \\sum_{i=1}^{m} \\left( |a_{i}^{\\top} z|^{2} - |a_{i}^{\\top} x_{0}|^{2} \\right)^{2}$ 在相位恢复文献中是标准的。该问题在科学上基于优化和信号处理理论，是适定的，提供了所有必要信息，并且陈述客观。该设置是说明此领域非凸优化挑战的有效且常用技术。该问题被认为是有效的。\n\n我们继续处理问题中概述的四个任务。\n\n首先，我们预先计算真实的测量强度 $|a_{i}^{\\top} x_{0}|^{2}$，它们在损失函数 $f(z)$ 中是常数。令 $y_i^2 = |a_{i}^{\\top} x_{0}|^{2}$。\n当 $x_0 = (1, 0)^\\top$ 时：\n对于 $i=1$：$a_1^\\top x_0 = (1, 0) \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 1$。因此，$y_1^2 = 1^2 = 1$。\n对于 $i=2$：$a_2^\\top x_0 = (0, 1) \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 0$。因此，$y_2^2 = 0^2 = 0$。\n对于 $i=3$：$a_3^\\top x_0 = (1, 1) \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 1$。因此，$y_3^2 = 1^2 = 1$。\n\n接下来，我们表示对于一个通用变量 $z = (z_1, z_2)^\\top$ 的项 $|a_i^\\top z|^2$。\n对于 $i=1$：$a_1^\\top z = (1, 0) \\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix} = z_1$。因此，$|a_1^\\top z|^2 = z_1^2$。\n对于 $i=2$：$a_2^\\top z = (0, 1) \\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix} = z_2$。因此，$|a_2^\\top z|^2 = z_2^2$。\n对于 $i=3$：$a_3^\\top z = (1, 1) \\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix} = z_1+z_2$。因此，$|a_3^\\top z|^2 = (z_1+z_2)^2$。\n\n任务1：显式地写出 $f(z)$。\n将这些表达式代入 $m=3$ 的 $f(z)$ 定义中：\n$$\nf(z) = \\frac{1}{4 \\cdot 3} \\sum_{i=1}^{3} \\left( |a_{i}^{\\top} z|^{2} - y_{i}^{2} \\right)^{2}\n$$\n$$\nf(z_1, z_2) = \\frac{1}{12} \\left[ \\left( |a_1^\\top z|^2 - y_1^2 \\right)^2 + \\left( |a_2^\\top z|^2 - y_2^2 \\right)^2 + \\left( |a_3^\\top z|^2 - y_3^2 \\right)^2 \\right]\n$$\n$$\nf(z_1, z_2) = \\frac{1}{12} \\left[ (z_1^2 - 1)^2 + (z_2^2 - 0)^2 + ((z_1+z_2)^2 - 1)^2 \\right]\n$$\n$$\nf(z_1, z_2) = \\frac{1}{12} \\left( (z_1^2 - 1)^2 + z_2^4 + ((z_1+z_2)^2 - 1)^2 \\right)\n$$\n\n任务2：推导梯度 $\\nabla f(z)$ 并在 $z=(0,0)^\\top$ 处求值。\n我们计算 $f(z_1, z_2)$ 关于 $z_1$ 和 $z_2$ 的偏导数。\n对于 $z_1$：\n$$\n\\frac{\\partial f}{\\partial z_1} = \\frac{1}{12} \\frac{\\partial}{\\partial z_1} \\left( (z_1^2 - 1)^2 + z_2^4 + ((z_1+z_2)^2 - 1)^2 \\right)\n$$\n使用链式法则：\n$$\n\\frac{\\partial f}{\\partial z_1} = \\frac{1}{12} \\left[ 2(z_1^2-1) \\cdot (2z_1) + 0 + 2((z_1+z_2)^2 - 1) \\cdot \\frac{\\partial}{\\partial z_1}((z_1+z_2)^2) \\right]\n$$\n$$\n\\frac{\\partial f}{\\partial z_1} = \\frac{1}{12} \\left[ 4z_1(z_1^2-1) + 2((z_1+z_2)^2 - 1) \\cdot 2(z_1+z_2) \\cdot 1 \\right]\n$$\n$$\n\\frac{\\partial f}{\\partial z_1} = \\frac{1}{3} \\left[ z_1(z_1^2-1) + (z_1+z_2)((z_1+z_2)^2-1) \\right]\n$$\n对于 $z_2$：\n$$\n\\frac{\\partial f}{\\partial z_2} = \\frac{1}{12} \\frac{\\partial}{\\partial z_2} \\left( (z_1^2 - 1)^2 + z_2^4 + ((z_1+z_2)^2 - 1)^2 \\right)\n$$\n$$\n\\frac{\\partial f}{\\partial z_2} = \\frac{1}{12} \\left[ 0 + 4z_2^3 + 2((z_1+z_2)^2-1) \\cdot \\frac{\\partial}{\\partial z_2}((z_1+z_2)^2) \\right]\n$$\n$$\n\\frac{\\partial f}{\\partial z_2} = \\frac{1}{12} \\left[ 4z_2^3 + 2((z_1+z_2)^2-1) \\cdot 2(z_1+z_2) \\cdot 1 \\right]\n$$\n$$\n\\frac{\\partial f}{\\partial z_2} = \\frac{1}{3} \\left[ z_2^3 + (z_1+z_2)((z_1+z_2)^2-1) \\right]\n$$\n梯度为 $\\nabla f(z) = \\begin{pmatrix} \\frac{\\partial f}{\\partial z_1} \\\\ \\frac{\\partial f}{\\partial z_2} \\end{pmatrix}$。\n现在，我们在 $z=(0, 0)^\\top$ 处计算梯度：\n$$\n\\frac{\\partial f}{\\partial z_1}\\bigg|_{(0,0)} = \\frac{1}{3} \\left[ 0(0^2-1) + (0+0)((0+0)^2-1) \\right] = 0\n$$\n$$\n\\frac{\\partial f}{\\partial z_2}\\bigg|_{(0,0)} = \\frac{1}{3} \\left[ 0^3 + (0+0)((0+0)^2-1) \\right] = 0\n$$\n由于 $\\nabla f(0,0) = (0,0)^\\top$，点 $z=(0,0)^\\top$ 是函数 $f(z)$ 的一个驻点（一个临界点）。\n\n任务3：计算 $f(0,0)$ 和 $f(x_0)$。\n在驻点 $z=(0,0)^\\top$ 处的损失函数值为：\n$$\nf(0,0) = \\frac{1}{12} \\left( (0^2 - 1)^2 + 0^4 + ((0+0)^2 - 1)^2 \\right) = \\frac{1}{12} ((-1)^2 + 0 + (-1)^2) = \\frac{1}{12}(1+1) = \\frac{2}{12} = \\frac{1}{6}\n$$\n$f(z)$ 的全局最小值点是满足对所有 $i$ 都有 $|a_i^\\top z|^2 = |a_i^\\top x_0|^2$ 的向量 $z$，这使得 $f(z)=0$。真实信号 $x_0$ 就是这样一个最小值点。我们来计算 $f(x_0) = f(1,0)$：\n$$\nf(1,0) = \\frac{1}{12} \\left( (1^2 - 1)^2 + 0^4 + ((1+0)^2 - 1)^2 \\right) = \\frac{1}{12} (0^2 + 0 + (1-1)^2) = 0\n$$\n由于 $f(0,0) = 1/6  f(x_0) = 0$，驻点 $z = (0,0)^\\top$ 不是全局最小值点。它是一个虚假驻点。\n\n任务4：计算海森矩阵 $\\nabla^2 f(0,0)$ 及其最小特征值。\n海森矩阵是 $\\nabla^2 f(z) = \\begin{pmatrix} \\frac{\\partial^2 f}{\\partial z_1^2}  \\frac{\\partial^2 f}{\\partial z_1 \\partial z_2} \\\\ \\frac{\\partial^2 f}{\\partial z_2 \\partial z_1}  \\frac{\\partial^2 f}{\\partial z_2^2} \\end{pmatrix}$。我们从梯度的分量计算二阶偏导数。\n$\\frac{\\partial^2 f}{\\partial z_1^2} = \\frac{\\partial}{\\partial z_1} \\left( \\frac{1}{3} \\left[ z_1^3-z_1 + (z_1+z_2)^3-(z_1+z_2) \\right] \\right) = \\frac{1}{3} \\left( 3z_1^2-1 + 3(z_1+z_2)^2-1 \\right)$。\n$\\frac{\\partial^2 f}{\\partial z_2^2} = \\frac{\\partial}{\\partial z_2} \\left( \\frac{1}{3} \\left[ z_2^3 + (z_1+z_2)^3-(z_1+z_2) \\right] \\right) = \\frac{1}{3} \\left( 3z_2^2 + 3(z_1+z_2)^2-1 \\right)$。\n$\\frac{\\partial^2 f}{\\partial z_2 \\partial z_1} = \\frac{\\partial}{\\partial z_2} \\left( \\frac{1}{3} \\left[ z_1^3-z_1 + (z_1+z_2)^3-(z_1+z_2) \\right] \\right) = \\frac{1}{3} \\left( 3(z_1+z_2)^2-1 \\right)$。\n根据克莱罗定理 (Clairaut's theorem)，$\\frac{\\partial^2 f}{\\partial z_1 \\partial z_2} = \\frac{\\partial^2 f}{\\partial z_2 \\partial z_1}$。\n\n现在，我们在 $z=(0,0)^\\top$ 处计算这些值：\n$\\frac{\\partial^2 f}{\\partial z_1^2}\\bigg|_{(0,0)} = \\frac{1}{3}(3 \\cdot 0^2 - 1 + 3(0+0)^2 - 1) = \\frac{1}{3}(-1-1) = -\\frac{2}{3}$。\n$\\frac{\\partial^2 f}{\\partial z_2^2}\\bigg|_{(0,0)} = \\frac{1}{3}(3 \\cdot 0^2 + 3(0+0)^2 - 1) = \\frac{1}{3}(-1) = -\\frac{1}{3}$。\n$\\frac{\\partial^2 f}{\\partial z_2 \\partial z_1}\\bigg|_{(0,0)} = \\frac{1}{3}(3(0+0)^2 - 1) = \\frac{1}{3}(-1) = -\\frac{1}{3}$。\n\n在原点处的海森矩阵为：\n$$\n\\nabla^2 f(0,0) = \\begin{pmatrix} -\\frac{2}{3}  -\\frac{1}{3} \\\\ -\\frac{1}{3}  -\\frac{1}{3} \\end{pmatrix}\n$$\n为了求特征值 $\\lambda$，我们求解特征方程 $\\det(\\nabla^2 f(0,0) - \\lambda I) = 0$：\n$$\n\\det \\begin{pmatrix} -\\frac{2}{3} - \\lambda  -\\frac{1}{3} \\\\ -\\frac{1}{3}  -\\frac{1}{3} - \\lambda \\end{pmatrix} = 0\n$$\n$$\n\\left(-\\frac{2}{3} - \\lambda\\right)\\left(-\\frac{1}{3} - \\lambda\\right) - \\left(-\\frac{1}{3}\\right)\\left(-\\frac{1}{3}\\right) = 0\n$$\n$$\n\\left(\\lambda + \\frac{2}{3}\\right)\\left(\\lambda + \\frac{1}{3}\\right) - \\frac{1}{9} = 0\n$$\n$$\n\\lambda^2 + \\frac{1}{3}\\lambda + \\frac{2}{3}\\lambda + \\frac{2}{9} - \\frac{1}{9} = 0\n$$\n$$\n\\lambda^2 + \\lambda + \\frac{1}{9} = 0\n$$\n我们使用二次方程求根公式 $\\lambda = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$，其中 $a=1$，$b=1$，且 $c=1/9$：\n$$\n\\lambda = \\frac{-1 \\pm \\sqrt{1^2 - 4(1)\\left(\\frac{1}{9}\\right)}}{2(1)} = \\frac{-1 \\pm \\sqrt{1 - \\frac{4}{9}}}{2} = \\frac{-1 \\pm \\sqrt{\\frac{5}{9}}}{2} = \\frac{-1 \\pm \\frac{\\sqrt{5}}{3}}{2}\n$$\n两个特征值是：\n$$\n\\lambda_1 = \\frac{-1 + \\frac{\\sqrt{5}}{3}}{2} = \\frac{-3 + \\sqrt{5}}{6} \\quad \\text{和} \\quad \\lambda_2 = \\frac{-1 - \\frac{\\sqrt{5}}{3}}{2} = \\frac{-3 - \\sqrt{5}}{6}\n$$\n为了找到最小的特征值，我们比较 $\\lambda_1$ 和 $\\lambda_2$。因为 $\\sqrt{5}  0$，所以项 $-3-\\sqrt{5}$ 小于 $-3+\\sqrt{5}$。因此，最小的特征值是 $\\lambda_2$。\n$$\n\\lambda_{\\min} = \\frac{-3 - \\sqrt{5}}{6}\n$$\n两个特征值都是负的，这表明原点处的驻点是一个局部最大值点，它会排斥梯度下降算法，导致它们从该点发散。这是相位恢复问题中虚假驻点的一个共同特征。",
            "answer": "$$\n\\boxed{\\frac{-3 - \\sqrt{5}}{6}}\n$$"
        },
        {
            "introduction": "除了数学上的正确性，一个算法的实用价值还取决于其计算效率。本练习将焦点转移到与相位恢复密切相关的盲反卷积问题，旨在分析其单次迭代的复杂度。你将研究一种分解式梯度下降方案，并确定当使用高效的快速傅里叶变换（FFT）来执行卷积时其计算成本，这是开发可扩展信号处理算法的一项关键技能 。",
            "id": "3477971",
            "problem": "考虑在分解参数化下对长度为 $n$ 的信号进行循环盲反卷积，其观测模型为 $y = h * x + w$，其中 $h \\in \\mathbb{C}^{n}$ 和 $x \\in \\mathbb{C}^{n}$ 未知，$w \\in \\mathbb{C}^{n}$ 为噪声，* 表示循环卷积。设目标为最小二乘损失 $f(h,x) = \\frac{1}{2}\\|h * x - y\\|_{2}^{2}$，可能与一个可分离的稀疏性促进正则化器相结合，该正则化器每次迭代只产生代价为 $O(n)$ 的元素级运算。假设复变量和梯度是使用 Wirtinger 算子计算的。该算法对 $(h,x)$ 使用分解梯度下降更新，所有卷积和相关都通过使用快速傅里叶变换 (FFT) 的离散傅里叶变换来实现。\n\n您可以使用以下基本事实：\n- 快速傅里叶变换 (FFT) 在 $O(n \\log n)$ 时间内计算离散傅里叶变换 (DFT)。\n- 时域中的循环卷积对应于频域中的逐点乘法，即，如果 $\\widehat{h} = \\mathcal{F}(h)$ 且 $\\widehat{x} = \\mathcal{F}(x)$，则 $\\mathcal{F}(h * x) = \\widehat{h} \\odot \\widehat{x}$，其中 $\\odot$ 表示逐元素乘法。\n- $\\frac{1}{2}\\|r\\|_{2}^{2}$ 关于其参数 $r$ 的梯度是 $r$，并且与 $x$ 的循环卷积的伴随算子是与 $x$ 的共轭反转 $\\tilde{x}$ 的循环相关。\n\n在一次分解梯度下降的迭代中，执行以下操作：\n- 分别对 $h$ 和 $x$ 应用 FFT 来计算 $\\widehat{h}$ 和 $\\widehat{x}$。$y$ 的傅里叶变换（记为 $\\widehat{y}$）被预先计算一次并在所有迭代中重复使用。\n- 在频域中构造残差 $\\widehat{r} = \\widehat{h} \\odot \\widehat{x} - \\widehat{y}$。\n- 通过频域乘法和随后的逆 FFT 计算梯度：\n  - $\\widehat{\\nabla_{h} f} = \\overline{\\widehat{x}} \\odot \\widehat{r}$，然后 $\\nabla_{h} f = \\mathcal{F}^{-1}(\\widehat{\\nabla_{h} f})$，\n  - $\\widehat{\\nabla_{x} f} = \\overline{\\widehat{h}} \\odot \\widehat{r}$，然后 $\\nabla_{x} f = \\mathcal{F}^{-1}(\\widehat{\\nabla_{x} f})$，\n  其中上划线表示复共轭。\n- 在时域中执行参数更新和任何逐元素的正则化步骤。\n\n假设频域和时域中所有的逐点乘法和加法都是 $O(n)$，FFT 和逆 FFT 的代价均为 $O(n \\log n)$，并且 $\\widehat{y}$ 在迭代内部不重新计算。在这些假设下，推导该分解梯度下降方案每次迭代的算术复杂度的闭式解析表达式（用 $n \\log n$ 表示），忽略低阶的 $n$ 项，并提取乘以 $n \\log n$ 的精确首项系数。最终答案必须是关于 $n \\log n$ 的单个解析表达式（不得包含不等式或渐近符号）。",
            "solution": "问题陈述已经过验证，被认为是自洽的、有科学依据且适定的。它提出了一个用于盲反卷积的标准算法流程，并要求基于一组清晰的假设进行计算复杂度分析。该问题是有效的，并将提供一个解法。\n\n目标是确定所述分解梯度下降算法的每次迭代计算复杂度。问题指定我们只应考虑最高阶的复杂度项，该项源于快速傅里叶变换 (FFT) 及其逆变换 (IFFT)，并忽略所有低阶项，例如复杂度为 $O(n)$ 的项。对长度为 $n$ 的向量进行单次 FFT 或 IFFT 操作的复杂度被给定为与 $n \\log n$ 成正比。我们被要求找到乘以 $n \\log n$ 项的精确首项系数。\n\n我们将分析所述算法在单次迭代中每个步骤的计算成本。\n\n1.  **步骤 1：对当前估计进行傅里叶变换。**\n    迭代从时域中信号 $h \\in \\mathbb{C}^{n}$ 和 $x \\in \\mathbb{C}^{n}$ 的当前估计开始。第一步是使用 FFT 算法计算它们的离散傅里叶变换 (DFT)。\n    -   计算 $\\widehat{h} = \\mathcal{F}(h)$：这需要一次 FFT 操作。\n    -   计算 $\\widehat{x} = \\mathcal{F}(x)$：这需要一次 FFT 操作。\n    此步骤中的变换总数为 $2$。\n\n2.  **步骤 2：在频域中构造残差。**\n    残差计算为 $\\widehat{r} = \\widehat{h} \\odot \\widehat{x} - \\widehat{y}$。这涉及一次逐元素乘法 ($\\odot$) 和一次逐元素减法。两个操作都作用于长度为 $n$ 的向量。此步骤的代价为 $O(n)$。根据问题的指示，我们忽略低阶项。\n\n3.  **步骤 3：计算梯度。**\n    计算关于 $h$ 和 $x$ 的梯度。流程规定如下：\n\n    a. **关于 $h$ 的梯度**：\n       -   首先，计算梯度的频域表示：$\\widehat{\\nabla_{h} f} = \\overline{\\widehat{x}} \\odot \\widehat{r}$。这涉及对长度为 $n$ 的向量进行逐元素复共轭和逐元素乘法。其代价为 $O(n)$，因此被忽略。\n       -   接着，将梯度变换回时域：$\\nabla_{h} f = \\mathcal{F}^{-1}(\\widehat{\\nabla_{h} f})$。这需要一次 IFFT 操作。\n\n    b. **关于 $x$ 的梯度**：\n       -   类似地，计算其频域表示：$\\widehat{\\nabla_{x} f} = \\overline{\\widehat{h}} \\odot \\widehat{r}$。其代价为 $O(n)$，被忽略。\n       -   然后将梯度变换回时域：$\\nabla_{x} f = \\mathcal{F}^{-1}(\\widehat{\\nabla_{x} f})$。这需要一次 IFFT 操作。\n\n    此步骤中的变换总数为 $1 + 1 = 2$。两次都是 IFFT。\n\n4.  **步骤 4：参数更新与正则化。**\n    迭代的最后一步涉及使用计算出的梯度更新参数 $h$ 和 $x$，例如，$h \\leftarrow h - \\mu \\nabla_{h} f$。问题还指出，任何稀疏性促进正则化都在此阶段应用，并且由逐元素操作组成。因此，此步骤中的所有操作都是对长度为 $n$ 的向量进行的逐元素操作。其代价为 $O(n)$，被忽略。\n\n**总复杂度计算**\n\n为了找到每次迭代的总复杂度，我们将主要操作（即 FFT 和 IFFT）的数量相加。\n-   来自步骤 1：$2$ 次 FFT。\n-   来自步骤 3：$2$ 次 IFFT。\n\n每次迭代的 FFT 或 IFFT 操作总数为 $2 + 2 = 4$。\n\n问题指出，每次此类变换的复杂度与 $n \\log n$ 成正比。通过要求“精确的首项系数”，问题要求我们将总复杂度表示为 $K \\cdot n \\log n$，其中 $K$ 是这些高成本变换的总次数。\n\n根据我们的分析，系数 $K$ 为 $4$。因此，忽略低阶项，每次迭代的总算术复杂度为 $4n \\log n$。",
            "answer": "$$\n\\boxed{4n \\log n}\n$$"
        }
    ]
}