{
    "hands_on_practices": [
        {
            "introduction": "信号逼近是一项基本任务。在小波分析中，我们常常希望找到一个既稀疏又能尊重其固有的父子层级结构的最佳逼近。这个练习旨在解决在父节点闭合约束下寻找最佳$k$项逼近的问题，它展示了如何利用树结构上的动态规划，精确而高效地解决这个看似复杂的组合问题 。掌握这一算法不仅为你提供了一个强大的结构化信号投影工具，也为更高级的基于树的追踪算法奠定了基础。",
            "id": "3494251",
            "problem": "给定一个有根树，它模拟了离散小波变换（DWT）中系数的父子结构，以及一个实值信号向量。对于给定的整数 $k$，考虑大小为 $k$ 的父闭合支撑集族，定义为索引子集 $S \\subset \\{0,1,\\dots,n-1\\}$ 的集合，满足 $\\lvert S \\rvert = k$，并且只要一个索引 $i \\in S$ 被选中，其在树中的所有祖先也必须在 $S$ 中。一个向量 $z \\in \\mathbb{R}^n$ 在支撑集属于该族的所有向量集合上的欧几里得投影，是优化问题 $x^\\star = \\Pi_{\\mathcal{T}_k}(z)$ 的解\n$$\n\\min_{x \\in \\mathbb{R}^n} \\left\\| x - z \\right\\|_2^2 \\quad \\text{subject to} \\quad \\operatorname{supp}(x) \\in \\mathcal{T}_k,\n$$\n其中 $\\mathcal{T}_k$ 表示相对于给定树的所有包含 $k$ 个节点的父闭合支撑集的集合。\n\n从基本原理出发：对于任何固定的支撑集 $S$，在相应坐标子空间上的欧几里得投影将 $i \\in S$ 的分量设为 $x_i = z_i$，其余分量设为 $x_i = 0$；并且目标函数简化为最小化不在 $S$ 中的坐标能量。由此可知，该投影问题可以简化为离散组合选择问题\n$$\n\\max_{S \\in \\mathcal{T}_k} \\sum_{i \\in S} z_i^2,\n$$\n因为投影误差为 $\\sum_{i \\notin S} z_i^2$，当保留的能量 $\\sum_{i \\in S} z_i^2$ 最大化时，该误差最小。\n\n你的任务是：\n\n1. 从第一性原理出发，推导一个动态规划递推关系，以精确解决树上父闭合支撑集的最大化问题，并返回最优目标值和一个具体的最优支撑集 $S^\\star \\in \\mathcal{T}_k$。\n\n2. 通过动态规划计算 $S^\\star$ 并构造 $x^\\star$（其中对于 $i \\in S^\\star$ 有 $x^\\star_i = z_i$，否则 $x^\\star_i = 0$），来实现精确投影 $\\Pi_{\\mathcal{T}_k}(z)$。你的实现必须是自包含且确定性的。\n\n3. 分析算法复杂度。具体来说，用节点数 $n$、基数 $k$ 和树的最大度 $\\Delta$ 来表示复杂度。解释在何种条件下复杂度可降至 $\\mathcal{O}(n)$（例如，有界度树和固定的 $k$），以及在何种条件下，对于某些树类型，复杂度表现为 $\\mathcal{O}(n \\log n)$（例如，当度随 $n$ 扩展且 $k$ 的增长类似 $\\mathcal{O}(\\log n)$ 时）。你的分析必须基于父闭合约束所引出的组合结构以及跨子节点的动态规划合并过程。\n\n实现程序以运行以下测试套件。对于每个测试用例，构建指定的树，使用给定的伪随机种子生成信号 $z$，计算精确的投影支撑集 $S^\\star$，并输出排序后的所选索引列表：\n\n- 测试用例 A（平衡二元小波树）：$n = 15$ 个节点，标记为 $0$ 到 $14$，父指针由一棵完全二叉树定义（节点 $i$ 的父节点为 $\\left\\lfloor \\frac{i-1}{2} \\right\\rfloor$，$i \\ge 1$），$k = 5$，种子为 $42$。\n- 测试用例 B（链式结构树）：$n = 20$ 个节点，标记为 $0$ 到 $19$，节点 $i$ 的父节点为 $i-1$（$i \\ge 1$，形成一条单路径），$k = 6$，种子为 $7$。\n- 测试用例 C（星形结构树）：$n = 64$ 个节点，标记为 $0$ 到 $63$，根节点为 $0$，其子节点为 $1$ 到 $63$，$k = 7$，种子为 $123$。\n\n信号 $z$ 必须通过从零均值、单位方差的正态分布中抽样生成，且为独立同分布样本，并使用指定的种子以保证可复现性。不涉及任何物理单位或角度。你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个测试用例的结果是一个整数列表（按升序排序的所选支撑集索引）。例如，你的最终输出应如下所示\n```\n[[i_1,i_2,...],[j_1,j_2,...],[l_1,l_2,...]]\n```",
            "solution": "用户提供的问题是有效的。它在科学上植根于稀疏信号处理领域，问题阐述清晰，目标明确，信息充分，并使用了精确、客观的语言。任务是为一个树上的结构化追踪问题推导并实现一个动态规划算法，并分析其复杂度。\n\n### 1. 问题建模与简化\n\n该问题要求计算一个向量 $z \\in \\mathbb{R}^n$ 在一个由 $k$ 元父闭合索引集支撑的向量集合上的欧几里得投影。这个有效的支撑集集合表示为 $\\mathcal{T}_k$。优化问题是：\n$$\nx^\\star = \\arg\\min_{x \\in \\mathbb{R}^n} \\left\\| x - z \\right\\|_2^2 \\quad \\text{subject to} \\quad \\operatorname{supp}(x) \\in \\mathcal{T}_k\n$$\n对于任意固定的支撑集 $S \\subseteq \\{0, 1, \\dots, n-1\\}$，向量 $z$ 在由 $S$ 支撑的向量子空间上的投影是一个向量 $x_S$，其中当 $i \\in S$ 时 $x_{S,i} = z_i$，当 $i \\notin S$ 时 $x_{S,i} = 0$。该投影的平方误差为：\n$$\n\\|x_S - z\\|_2^2 = \\sum_{i \\in S} (z_i - z_i)^2 + \\sum_{i \\notin S} (0 - z_i)^2 = \\sum_{i \\notin S} z_i^2\n$$\n最小化此误差等价于最大化*未*被置零的分量的能量。我们可以将总能量写成一个常数 $\\sum_{j=0}^{n-1} z_j^2$，这使我们能将最小化投影误差的问题改写为最大化保留能量的问题：\n$$\n\\min_{S \\in \\mathcal{T}_k} \\sum_{i \\notin S} z_i^2 = \\sum_{j=0}^{n-1} z_j^2 - \\max_{S \\in \\mathcal{T}_k} \\sum_{i \\in S} z_i^2\n$$\n因此，问题简化为通过求解以下问题来找到最优支撑集 $S^\\star$ 的组合任务：\n$$\nS^\\star = \\arg\\max_{S \\in \\mathcal{T}_k} \\sum_{i \\in S} z_i^2\n$$\n令 $w_i = z_i^2$ 为与每个节点 $i$ 关联的非负权重。问题就变成了找到一个大小为 $k$ 的父闭合支撑集 $S$，以最大化总权重 $\\sum_{i \\in S} w_i$。\n\n如果对于集合 $S$ 中任何非根节点 $i$，其父节点 $\\operatorname{parent}(i)$ 也在 $S$ 中，则称该集合为父闭合的。如果 $S$ 非空，这意味着树的根节点必须在 $S$ 中。此外，$S$ 中的节点集必须形成一个包含根节点的连通分量。在树中，这唯一地将 $S$ 定义为一个**包含根的大小为 $k$ 的子树**。\n\n### 2. 动态规划递推关系\n\n我们可以使用动态规划在给定的树上解决这个最大化问题。该算法通过后序遍历进行，从叶节点开始，向上移动到根节点。对于树中的每个节点 $u$，我们计算一个表，其中包含在以 $u$ 为根的子树上定义的子问题的最优解。\n\n**DP 状态：** 对于每个节点 $u$ 和每个可能的规模 $s \\in \\{1, 2, \\dots, k\\}$，令 $E(u, s)$ 为一个以 $u$ 为根（即必须包含 $u$）的大小为 $s$ 的子树可能的最大权重和。如果不存在这样的子树，我们可以将其权重定义为 $-\\infty$。\n\n**基本情况：** 对于一个叶节点 $u$，唯一可能以 $u$ 为根的子树是节点本身。因此，叶节点的 DP 表只包含一个条目：\n$$\nE(u, 1) = w_u = z_u^2\n$$\n对于任何 $s > 1$，$E(u, s) = -\\infty$，因为叶节点没有后代来形成更大的子树。\n\n**递归步骤：** 对于一个内部（非叶）节点 $u$，一个以 $u$ 为根的大小为 $s$ 的子树必须包含 $u$ 本身（贡献权重 $w_u$）以及总共 $s-1$ 个节点，这些节点分布在其子节点的子树中。设 $u$ 的子节点为 $c_1, c_2, \\dots, c_m$。对于每个子节点 $c_j$，我们可以选择不将其包含在内（从其整个子树贡献 $0$ 个节点和 $0$ 权重），或者选择一个以 $c_j$ 为根的大小为 $s_j \\ge 1$ 的子树（贡献 $s_j$ 个节点和权重 $E(c_j, s_j)$）。\n\n这个子问题是背包问题的一个变体。我们有 $s-1$ 个节点的“容量”可以“花费”在 $u$ 的子节点上。“物品”是子节点的子树。对于每个子节点 $c_j$，我们可以选择取一个大小为 $s_j$、价值为 $E(c_j, s_j)$ 的子树。\n\n让我们迭代地定义 DP 计算。我们从节点 $u$ 单独的解开始，这是一个大小为 $1$、权重为 $w_u$ 的子树。然后，我们依次合并来自每个子节点的最优解。令 $E_{\\text{current}}(s)$ 为考虑了 $u$ 的部分子节点后的 DP 表。当我们考虑下一个子节点 $c_j$ 时，我们将 $E_{\\text{current}}$ 与 $c_j$ 的 DP 表结合起来。对于子节点 $c_j$ 的选项是，取一个以 $c_j$ 为根的大小为 $s_j \\geq 1$ 的子树，其价值为 $E(c_j, s_j)$；或者什么都不取（大小为 $0$，价值为 $0$）。我们把子节点的这个增广表表示为 $E'(c_j, s_j)$，其中 $E'(c_j, 0) = 0$ 并且对于 $s_j > 0$ 有 $E'(c_j, s_j) = E(c_j, s_j)$。\n\n合并子节点 $c_j$ 的表的更新规则是一个 $(max, +)$-卷积：\n$$\nE_{\\text{new}}(s) = \\max_{s_{\\text{curr}} + s_j = s} \\left\\{ E_{\\text{current}}(s_{\\text{curr}}) + E'(c_j, s_j) \\right\\}\n$$\n对所有子节点重复此过程。在所有子节点都合并后，得到的表就是 $E(u, \\cdot)$。\n\n**最终解：** 后序遍历完成后，我们将计算出所有 $s \\in \\{1, \\dots, k\\}$ 的表 $E(\\text{root}, s)$。一个大小恰好为 $k$ 的有效支撑集的最大权重是 $E(\\text{root}, k)$。\n\n### 3. 最优支撑集的重构\n\n为了找到索引集 $S^\\star$，我们必须扩展 DP 以存储回溯指针。除了能量表 $E(u, s)$，我们还维护一个回溯表 $B(u, s)$，用于记录为达到该能量所做的决策。具体来说，当从 $E_{\\text{current}}(s_{\\text{curr}})$ 和 $E'(c_j, s_j)$ 计算 $E_{\\text{new}}(s)$ 时，我们存储当前合并组合的最优选择是从 $u$ 之前的局部子树中取 $s_{\\text{curr}}$ 个节点，并从子节点 $c_j$ 的子树中取 $s_j$ 个节点。\n\n在计算完直到根节点的所有 DP 表之后，我们启动回溯过程：\n1.  从根节点开始，目标大小为 $k$。将根节点添加到 $S^\\star$。\n2.  查找 $B(\\text{root}, k)$。此表提供了分配给根的每个子节点 $c_j$ 的最优大小 $s_j$。\n3.  对于每个子节点 $c_j$：\n    - 如果分配的大小 $s_j = 0$，则不执行任何操作。\n    - 如果 $s_j > 0$，这意味着 $c_j$ 在 $S^\\star$ 中。将 $c_j$ 添加到集合中，并以目标大小 $s_j$ 对节点 $c_j$ 递归调用回溯过程。\n4.  继续此过程，直到所有路径都终止（到达叶节点或分配大小为 $0$）。得到的集合 $S^\\star$ 就是最优支撑集。\n\n### 4. 算法复杂度分析\n\n设 $n$ 为节点数，$k$ 为目标支撑集大小，$\\Delta$ 为树的最大度。\n\n算法的核心是在每个节点上进行的 DP 计算，这涉及到合并来自其子节点的表。在一个有子节点 $c_1, \\dots, c_m$ 的节点 $u$ 处，计算涉及 $m-1$ 次合并操作。一个大小为 $k_1$ 的表和一个大小为 $k_2$ 的表之间的单次合并操作需要 $O(k_1 k_2)$ 时间。在我们的情况下，所有表的大小都以 $k$ 为界。\n\n在一个有 $d(u)$ 个子节点的节点 $u$ 处的计算成本主要由合并序列决定。设前 $i$ 个子节点组合的 DP 表大小为 $|M_i|$。与子节点 $c_{i+1}$（其表大小 $|M'_{c_{i+1}}| \\le k$）合并需要 $O(|M_i| \\cdot |M'_{c_{i+1}}|)$ 时间。由于 $|M_i|$ 也以 $k$ 为界，因此合并需要 $O(k^2)$ 时间。对所有 $d(u)$ 个子节点执行此操作，在节点 $u$ 处的成本为 $O(d(u) k^2)$。\n\n总复杂度是所有节点成本的总和：\n$$\n\\sum_{u \\in V} O(d(u) k^2) = O(k^2) \\sum_{u \\in V} d(u)\n$$\n所有节点的子节点数量之和是树中边的总数，即 $n-1$。因此，总复杂度为 $O(n k^2)$。\n\n**特殊情况：**\n\n-   **有界度树（$\\Delta$ 为常数）和固定的 $k$：** 在这种情况下，$d(u) \\le \\Delta-1$ 是一个常数，$k$ 也是一个常数。每个节点的成本是 $O(\\Delta k^2) = O(1)$。总复杂度变为 $\\sum_{u \\in V} O(1) = \\mathcal{O}(n)$。\n\n-   **星形结构树（$n$ 个节点，根有 $n-1$ 个叶子子节点）和 $k = \\mathcal{O}(\\log n)$：** 必须为 $n-1$ 个叶节点计算 DP，每个耗时 $O(1)$。在根节点，我们必须合并所有 $n-1$ 个子节点的解。每个子节点 $c_j$ 提供两个选择：什么都不取（大小为 $0$，权重为 $0$）或取叶节点本身（大小为 $1$，权重为 $w_{c_j}$）。根节点的问题是从 $n-1$ 个子节点中选择 $k-1$ 个，以最大化它们的权重之和，这是一个经典的 0/1 背包问题。解决这个背包问题的 DP 状态为 $(i, j)$，表示从前 $i$ 个子节点中选择大小为 $j$ 的集合所能获得的最大权重。递推关系是 $T(i, j) = \\max(T(i-1, j), T(i-1, j-1) + w_{c_i})$。这需要 $O((n-1) \\cdot (k-1)) = O(nk)$ 的时间。当 $k = \\mathcal{O}(\\log n)$ 时，根节点的复杂度为 $\\mathcal{O}(n \\log n)$。这主导了叶节点的 $O(n)$ 工作量，使得总复杂度为 $\\mathcal{O}(n \\log n)$。",
            "answer": "```python\nimport numpy as np\nfrom collections import defaultdict\nimport sys\n\n# It is necessary to increase the recursion limit for deep trees (like the chain).\nsys.setrecursionlimit(2000)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for structured projection.\n    \"\"\"\n\n    def _build_tree(parents):\n        \"\"\"Converts parent pointers to an adjacency list (children).\"\"\"\n        n = len(parents)\n        adj = [[] for _ in range(n)]\n        for i, p in enumerate(parents):\n            if p is not None and 0 = p  n:\n                adj[p].append(i)\n        return adj\n\n    def _dp_on_tree(u, adj, z_sq, k, memo):\n        \"\"\"\n        Performs dynamic programming on the tree to find max energy for subtrees.\n        \n        Args:\n            u (int): current node index.\n            adj (list of lists): Adjacency list for children.\n            z_sq (np.ndarray): Squared values of the signal z.\n            k (int): Maximum support size.\n            memo (dict): Memoization cache for DP results.\n\n        Returns:\n            A tuple (energies, choices):\n            - energies (dict): {size: max_energy} for subtrees rooted at u.\n            - choices (dict): {size: {child_index: child_size}} for backtracking.\n        \"\"\"\n        if u in memo:\n            return memo[u]\n\n        # Base case: Leaf node\n        if not adj[u]:\n            energies = {1: z_sq[u]}\n            choices = {1: {}}\n            memo[u] = (energies, choices)\n            return energies, choices\n\n        # Recursive step: Internal node\n        # Start with the solution of just the node u itself\n        current_energies = {1: z_sq[u]}\n        current_choices = {1: {}}\n\n        for child in adj[u]:\n            child_energies, child_choices = _dp_on_tree(child, adj, z_sq, k, memo)\n            \n            # Augment child energies with the option of not selecting the child's subtree\n            # This corresponds to a selection of size 0 with energy 0.\n            child_energies_aug = {0: 0.0}\n            child_energies_aug.update(child_energies)\n\n            new_energies = {}\n            new_choices = {}\n\n            # (max, +) convolution to merge child's DP table\n            for s_curr, e_curr in current_energies.items():\n                for s_child, e_child in child_energies_aug.items():\n                    s_new = s_curr + s_child\n                    if s_new > k:\n                        continue\n                    \n                    e_new = e_curr + e_child\n\n                    if e_new > new_energies.get(s_new, -1.0):\n                        new_energies[s_new] = e_new\n                        # Store choices for backtracking\n                        updated_choice = current_choices[s_curr].copy()\n                        updated_choice[child] = s_child\n                        new_choices[s_new] = updated_choice\n\n            current_energies = new_energies\n            current_choices = new_choices\n        \n        memo[u] = (current_energies, current_choices)\n        return current_energies, current_choices\n\n    def _reconstruct_support(u, s, choices, support_set):\n        \"\"\"\n        Backtracks through the choices table to build the optimal support set.\n        \"\"\"\n        support_set.add(u)\n        \n        if s not in choices[u]:\n            return\n\n        child_allocations = choices[u][s]\n        for child, child_size in child_allocations.items():\n            if child_size > 0:\n                _reconstruct_support(child, child_size, choices, support_set)\n\n    def compute_projection(n, parents, z, k):\n        \"\"\"\n        Computes the projection by finding the optimal parent-closed support.\n        \"\"\"\n        adj = _build_tree(parents)\n        z_sq = z**2\n        root = 0\n\n        # Memoization cache for the DP\n        memo = {}\n        \n        # This will populate the memo cache for all nodes via post-order traversal\n        _dp_on_tree(root, adj, z_sq, k, memo)\n        \n        # Extract choices for the entire tree stored in the memoization table\n        all_choices = {node: res[1] for node, res in memo.items()}\n        \n        # Check if a solution of size k exists\n        root_energies = memo[root][0]\n        if k not in root_energies:\n            # This case should not happen with valid inputs where k = n, but is a safeguard.\n            return []\n\n        support_set = set()\n        _reconstruct_support(root, k, all_choices, support_set)\n        \n        return sorted(list(support_set))\n\n    # --- Test Suite ---\n    test_cases = [\n        # Test Case A: Balanced binary wavelet tree\n        {'n': 15, 'k': 5, 'seed': 42, 'parents_func': lambda i: (i - 1) // 2 if i > 0 else None},\n        # Test Case B: Chain-structured tree\n        {'n': 20, 'k': 6, 'seed': 7, 'parents_func': lambda i: i - 1 if i > 0 else None},\n        # Test Case C: Star-structured tree\n        {'n': 64, 'k': 7, 'seed': 123, 'parents_func': lambda i: 0 if i > 0 else None},\n    ]\n\n    results = []\n    for case in test_cases:\n        n = case['n']\n        k = case['k']\n        seed = case['seed']\n        parents_func = case['parents_func']\n\n        parents = [parents_func(i) for i in range(n)]\n        \n        rng = np.random.default_rng(seed)\n        z = rng.normal(loc=0.0, scale=1.0, size=n)\n        \n        optimal_support = compute_projection(n, parents, z, k)\n        results.append(optimal_support)\n\n    # Format the final output string\n    # e.g., [[0, 1, 3], [0, 2]]\n    output_str = '[' + ','.join([f\"[{','.join(map(str, s))}]\" for s in results]) + ']'\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "除了简单的投影，许多现代信号恢复方法依赖于求解带正则化的优化问题。一种鼓励树结构稀疏性的关键罚项是分层组套索（hierarchical group lasso），它沿着从根到叶的路径上定义了重叠的组。这个练习揭示了一个关键思想：这个复杂的重叠罚项的近端算子（proximal operator）可以被高效计算。通过重新索引求和，该问题可以解耦为独立的块级收缩操作，其阈值由树上的一个简单的叶节点计数递归确定 。这项实践对于实现求解树正则化问题的迭代算法（如近端梯度下降）至关重要，是结构化稀疏优化的基石。",
            "id": "3494242",
            "problem": "考虑一个有根树 $\\mathcal{T} = (\\mathcal{V}, \\mathcal{E})$，其具有一个特殊的根节点 $r \\in \\mathcal{V}$，其中每个节点 $v \\in \\mathcal{V}$ 都有一组有限的子节点 $\\mathrm{ch}(v) \\subseteq \\mathcal{V}$。对于每个节点 $v \\in \\mathcal{V}$，定义了一个相关的变量块 $x_v \\in \\mathbb{R}^{d_v}$，其中 $d_v \\in \\mathbb{N}$ 是节点 $v$ 的块维度。令 $\\mathcal{L} \\subseteq \\mathcal{V}$ 表示叶节点（没有子节点的节点）的集合，对于每个叶节点 $\\ell \\in \\mathcal{L}$，令 $P(\\ell)$ 表示从根节点 $r$到 $\\ell$ 的唯一根到叶路径上的节点集合。设 $y_v \\in \\mathbb{R}^{d_v}$ 是在节点 $v$ 处的给定观测值。定义惩罚项\n$$\n\\Phi(x) = \\lambda \\sum_{\\ell \\in \\mathcal{L}} \\sum_{v \\in P(\\ell)} \\lVert x_v \\rVert_2,\n$$\n其中 $\\lambda  0$ 是一个给定的正则化参数，$\\lVert \\cdot \\rVert_2$ 表示欧几里得范数。考虑 $\\Phi$ 的近端映射，对于 $\\tau  0$ 定义为\n$$\n\\operatorname{prox}_{\\tau \\Phi}(y) = \\arg\\min_{x} \\left\\{ \\frac{1}{2} \\sum_{v \\in \\mathcal{V}} \\lVert x_v - y_v \\rVert_2^2 + \\tau \\lambda \\sum_{\\ell \\in \\mathcal{L}} \\sum_{v \\in P(\\ell)} \\lVert x_v \\rVert_2 \\right\\}。\n$$\n从近端映射和有根树的核心定义出发，从第一性原理推导近端映射 $\\operatorname{prox}_{\\tau \\Phi}(y)$ 可以通过树上的动态规划在 $\\mathcal{O}(n)$ 时间内计算，其中 $n = |\\mathcal{V}|$。具体来说，证明在对路径求和进行重新索引后，目标函数在节点间解耦，并且计算可以简化为带有节点特定权重的分块收缩，该权重可用叶节点计数的递归表示。显式推导叶节点计数 $c_v$ 的递归步骤，其中 $c_v$ 是以 $v$ 为根的子树中的叶节点数量，并根据 $c_v$ 实现每个节点上的分块近端更新。\n\n您的程序必须实现此推导，并为以下测试套件计算 $\\operatorname{prox}_{\\tau \\Phi}(y)$。在所有情况下，根节点索引为 $0$，树由每个节点 $v$ 的子节点列表指定，并且每个节点都有一个指定的块 $y_v \\in \\mathbb{R}^{d_v}$。对每种情况使用提供的 $\\lambda$ 和 $\\tau$ 值。\n\n测试用例 $\\mathbf{1}$（链式树，基准情况）：\n- 树：$0 \\rightarrow 1 \\rightarrow 2 \\rightarrow 3$。\n- 块维度：$d_0 = 2$, $d_1 = 2$, $d_2 = 2$, $d_3 = 2$。\n- 观测值：$y_0 = [0.6, -0.8]$, $y_1 = [0.1, 0.0]$, $y_2 = [0.0, 0.0]$, $y_3 = [3.0, 4.0]$。\n- 参数：$\\lambda = 0.5$, $\\tau = 0.5$。\n\n测试用例 $\\mathbf{2}$（星形树，突出根部聚合）：\n- 树：$0 \\rightarrow \\{1, 2, 3\\}$，其中 $1$, $2$, $3$ 是叶节点。\n- 块维度：$d_0 = 3$, $d_1 = 1$, $d_2 = 1$, $d_3 = 1$。\n- 观测值：$y_0 = [1.0, 0.0, 0.0]$, $y_1 = [0.3]$, $y_2 = [0.0]$, $y_3 = [0.5]$。\n- 参数：$\\lambda = 0.4$, $\\tau = 1.0$。\n\n测试用例 $\\mathbf{3}$（平衡二叉树，混合块大小）：\n- 树：$0 \\rightarrow \\{1, 2\\}$, $1 \\rightarrow \\{3, 4\\}$, $2 \\rightarrow \\{5, 6\\}$，叶节点为 $3$, $4$, $5$, $6$。\n- 块维度：$d_0 = 2$, $d_1 = 2$, $d_2 = 2$, $d_3 = 1$, $d_4 = 1$, $d_5 = 1$, $d_6 = 1$。\n- 观测值：$y_0 = [0.5, 0.5]$, $y_1 = [1.2, 0.0]$, $y_2 = [0.0, 0.9]$, $y_3 = [0.2]$, $y_4 = [1.0]$, $y_5 = [0.1]$, $y_6 = [0.0]$。\n- 参数：$\\lambda = 0.2$, $\\tau = 1.5$。\n\n测试用例 $\\mathbf{4}$（单节点树，边界情况）：\n- 树：单节点 $0$（一个叶节点）。\n- 块维度：$d_0 = 3$。\n- 观测值：$y_0 = [0.3, -0.4, 0.0]$。\n- 参数：$\\lambda = 0.7$, $\\tau = 0.5$。\n\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果是一个列表，其中包含按节点升序索引排列的近端块，这些块被连接并扁平化为单个实数列表。例如，格式为 $[ [\\ldots], [\\ldots], [\\ldots], [\\ldots] ]$，除了列表分隔符所需的空格外，不添加任何空格。不涉及物理单位或角度单位，答案必须是实值浮点数。最终输出必须是确定性的，并完全根据给定数据计算得出，无需任何外部输入。",
            "solution": "该问题要求推导一个高效算法来计算树结构正则化项 $\\Phi(x)$ 的近端映射，并实现该算法。近端映射定义为：\n$$\n\\operatorname{prox}_{\\tau \\Phi}(y) = \\arg\\min_{x} \\left\\{ F(x) = \\frac{1}{2} \\sum_{v \\in \\mathcal{V}} \\lVert x_v - y_v \\rVert_2^2 + \\tau \\Phi(x) \\right\\}\n$$\n其中惩罚项 $\\Phi(x)$ 由下式给出\n$$\n\\Phi(x) = \\lambda \\sum_{\\ell \\in \\mathcal{L}} \\sum_{v \\in P(\\ell)} \\lVert x_v \\rVert_2.\n$$\n变量是与有根树 $\\mathcal{T} = (\\mathcal{V}, \\mathcal{E})$ 的每个节点 $v$ 相关联的块 $x_v \\in \\mathbb{R}^{d_v}$。集合 $\\mathcal{L}$ 包含叶节点，$P(\\ell)$ 是从根到叶节点 $\\ell$ 的路径上的节点集合。参数 $\\lambda$ 和 $\\tau$ 是正标量。\n\n推导的核心在于重构惩罚项，以在变量块 $\\{x_v\\}_{v \\in \\mathcal{V}}$ 之间解耦优化问题。惩罚项涉及对叶节点及其祖先的双重求和。我们可以改变这个求和的顺序。我们可以不遍历每个叶节点并对其祖先求和，而是遍历每个节点 $v \\in \\mathcal{V}$，并对它所属的每个叶节点路径累加其贡献。\n\n让我们重写 $\\tau \\Phi(x)$ 项：\n$$\n\\tau \\Phi(x) = \\tau \\lambda \\sum_{\\ell \\in \\mathcal{L}} \\sum_{v \\in P(\\ell)} \\lVert x_v \\rVert_2.\n$$\n改变求和顺序得到：\n$$\n\\tau \\Phi(x) = \\tau \\lambda \\sum_{v \\in \\mathcal{V}} \\sum_{\\ell \\in \\mathcal{L} \\text{ s.t. } v \\in P(\\ell)} \\lVert x_v \\rVert_2.\n$$\n一个节点 $v$ 在到叶节点 $\\ell$ 的路径 $P(\\ell)$ 中，当且仅当 $\\ell$ 是以 $v$ 为根的子树中的一个叶节点。我们定义 $c_v$ 为以节点 $v$ 为根的子树中的叶节点数量。那么内部求和是 $c_v$ 个相同项 $\\lVert x_v \\rVert_2$ 的和：\n$$\n\\sum_{\\ell \\in \\mathcal{L} \\text{ s.t. } v \\in P(\\ell)} \\lVert x_v \\rVert_2 = c_v \\lVert x_v \\rVert_2.\n$$\n将其代回，惩罚项简化为：\n$$\n\\tau \\Phi(x) = \\tau \\lambda \\sum_{v \\in \\mathcal{V}} c_v \\lVert x_v \\rVert_2.\n$$\n现在，我们可以将这个简化的惩罚项代入目标函数 $F(x)$：\n$$\nF(x) = \\frac{1}{2} \\sum_{v \\in \\mathcal{V}} \\lVert x_v - y_v \\rVert_2^2 + \\tau \\lambda \\sum_{v \\in \\mathcal{V}} c_v \\lVert x_v \\rVert_2.\n$$\n我们可以按节点 $v$ 对各项进行重新组合：\n$$\nF(x) = \\sum_{v \\in \\mathcal{V}} \\left( \\frac{1}{2} \\lVert x_v - y_v \\rVert_2^2 + (\\tau \\lambda c_v) \\lVert x_v \\rVert_2 \\right).\n$$\n目标函数 $F(x)$ 已成功解耦为一系列独立函数的和，每个函数对应一个变量块 $x_v$。为了找到 $F(x)$ 的最小值，我们可以独立地最小化和中的每一项。对于每个节点 $v \\in \\mathcal{V}$，我们必须解决以下子问题：\n$$\nx_v^* = \\arg\\min_{x_v \\in \\mathbb{R}^{d_v}} \\left\\{ \\frac{1}{2} \\lVert x_v - y_v \\rVert_2^2 + (\\tau \\lambda c_v) \\lVert x_v \\rVert_2 \\right\\}.\n$$\n这是函数 $g(z) = \\alpha \\lVert z \\rVert_2$ 的近端算子的标准定义，在点 $y_v$ 处求值，其中缩放因子为 $\\alpha_v = \\tau \\lambda c_v$。其解由分块软阈值算子给出：\n$$\nx_v^* = \\left( 1 - \\frac{\\tau \\lambda c_v}{\\lVert y_v \\rVert_2} \\right)_+ y_v,\n$$\n其中 $(a)_+ = \\max(a, 0)$。该公式可展开为：\n$$\nx_v^* = \\begin{cases} \\left( 1 - \\frac{\\tau \\lambda c_v}{\\lVert y_v \\rVert_2} \\right) y_v  \\text{if } \\lVert y_v \\rVert_2 > \\tau \\lambda c_v \\\\ \\mathbf{0}  \\text{if } \\lVert y_v \\rVert_2 \\le \\tau \\lambda c_v \\end{cases}\n$$\n其中 $\\mathbf{0}$ 是 $\\mathbb{R}^{d_v}$ 中的零向量。\n\n要实现这个解法，我们首先需要计算所有 $v \\in \\mathcal{V}$ 的叶节点计数 $c_v$。这些计数可以通过树上的动态规划高效计算。节点 $v$ 的值 $c_v$ 由其子节点 $\\mathrm{ch}(v)$ 的计数决定。\n$c_v$ 的递归关系如下：\n1.  **基准情况**：如果节点 $v$ 是一个叶节点（即 $\\mathrm{ch}(v) = \\emptyset$），则以 $v$ 为根的子树只包含一个叶节点，即 $v$ 本身。因此，$c_v = 1$。\n2.  **递归步骤**：如果节点 $v$ 不是叶节点，其子树中的叶节点集合是其子节点子树中叶节点集合的不交并集。因此，总计数是其子节点计数的总和：\n    $$\n    c_v = \\sum_{u \\in \\mathrm{ch}(v)} c_u.\n    $$\n这个递归可以通过对树进行一次后序遍历（即从叶节点到根节点的自底向上遍历）来解决。对于每个节点 $v$，我们首先递归地计算其所有子节点 $u \\in \\mathrm{ch}(v)$ 的计数，然后使用上述公式计算 $c_v$。这需要 $\\mathcal{O}(|\\mathcal{V}|) = \\mathcal{O}(n)$ 的时间。\n\n计算 $\\operatorname{prox}_{\\tau \\Phi}(y)$ 的完整算法如下：\n1.  使用树的后序遍历为所有 $v \\in \\mathcal{V}$ 计算叶节点计数 $c_v$。这可以通过带记忆化的递归函数实现，需要 $\\mathcal{O}(n)$ 时间。\n2.  对于每个节点 $v \\in \\mathcal{V}$，使用其特定的阈值 $\\alpha_v = \\tau \\lambda c_v$ 和分块软阈值公式计算最优块 $x_v^*$。这涉及计算 $y_v$ 的 $\\ell_2$-范数并应用收缩公式，所需时间与块维度 $d_v$ 成正比。\n总时间复杂度是叶节点计数计算和分块更新的时间之和，即 $\\mathcal{O}(n + \\sum_{v \\in \\mathcal{V}} d_v)$。假设块维度很小且可视为常数，则复杂度为 $\\mathcal{O}(n)$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the proximal problem for all specified test cases.\n    \"\"\"\n    \n    # Test case 1: chain tree\n    tc1_children = [[1], [2], [3], []]\n    tc1_y_blocks = [np.array([0.6, -0.8]), np.array([0.1, 0.0]), np.array([0.0, 0.0]), np.array([3.0, 4.0])]\n    tc1_lambda = 0.5\n    tc1_tau = 0.5\n\n    # Test case 2: star tree\n    tc2_children = [[1, 2, 3], [], [], []]\n    tc2_y_blocks = [np.array([1.0, 0.0, 0.0]), np.array([0.3]), np.array([0.0]), np.array([0.5])]\n    tc2_lambda = 0.4\n    tc2_tau = 1.0\n\n    # Test case 3: balanced binary tree\n    tc3_children = [[1, 2], [3, 4], [5, 6], [], [], [], []]\n    tc3_y_blocks = [\n        np.array([0.5, 0.5]), np.array([1.2, 0.0]), np.array([0.0, 0.9]),\n        np.array([0.2]), np.array([1.0]), np.array([0.1]), np.array([0.0])\n    ]\n    tc3_lambda = 0.2\n    tc3_tau = 1.5\n\n    # Test case 4: single node tree\n    tc4_children = [[]]\n    tc4_y_blocks = [np.array([0.3, -0.4, 0.0])]\n    tc4_lambda = 0.7\n    tc4_tau = 0.5\n\n    test_cases = [\n        (tc1_children, tc1_y_blocks, tc1_lambda, tc1_tau),\n        (tc2_children, tc2_y_blocks, tc2_lambda, tc2_tau),\n        (tc3_children, tc3_y_blocks, tc3_lambda, tc3_tau),\n        (tc4_children, tc4_y_blocks, tc4_lambda, tc4_tau),\n    ]\n\n    results = []\n    \n    def compute_leaf_counts(children):\n        \"\"\"\n        Computes the number of leaves in the subtree of each node\n        using a post-order traversal (recursive DFS with memoization).\n        \"\"\"\n        num_nodes = len(children)\n        counts = -1 * np.ones(num_nodes, dtype=int)\n\n        def dfs(node_idx):\n            # If already computed, return the stored value\n            if counts[node_idx] != -1:\n                return counts[node_idx]\n\n            node_children = children[node_idx]\n            # Base case: if the node is a leaf\n            if not node_children:\n                counts[node_idx] = 1\n                return 1\n\n            # Recursive step: sum of leaf counts of children\n            current_count = 0\n            for child_idx in node_children:\n                current_count += dfs(child_idx)\n            \n            counts[node_idx] = current_count\n            return current_count\n\n        # The tree is rooted at index 0\n        dfs(0)\n        return counts\n\n    for case in test_cases:\n        children, y_blocks, lambda_val, tau_val = case\n        num_nodes = len(children)\n        \n        # Step 1: Compute leaf counts c_v for all nodes v\n        leaf_counts = compute_leaf_counts(children)\n        \n        # Step 2: Compute the proximal map for each block\n        x_blocks_result = []\n        for v in range(num_nodes):\n            y_v = y_blocks[v]\n            c_v = leaf_counts[v]\n            \n            # Compute the threshold T_v = tau * lambda * c_v\n            threshold = tau_val * lambda_val * c_v\n            \n            # Compute the L2 norm of the observation block y_v\n            norm_y_v = np.linalg.norm(y_v)\n            \n            # Apply the block soft-thresholding formula\n            if norm_y_v > threshold:\n                shrinkage_factor = 1.0 - threshold / norm_y_v\n                x_v = shrinkage_factor * y_v\n            else:\n                x_v = np.zeros_like(y_v)\n            \n            x_blocks_result.append(x_v)\n        \n        # Flatten the list of result blocks into a single list of floats\n        if x_blocks_result:\n            flat_result = np.concatenate(x_blocks_result).tolist()\n        else:\n            flat_result = []\n            \n        results.append(flat_result)\n\n    # Format the final output exactly as specified\n    # The string representation of a Python list of floats is used.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们已经学习了求解凸树稀疏模型的强大算法。但为什么选择这些模型呢？本练习旨在通过将它们与直观但计算上困难的离散选择模型联系起来，深入探讨其理论基础。本练习将指导你使用混合整数规划（MIP）来构建一个精确的树稀疏模型，然后推导其凸松弛——正是我们在前面练习中看到的那种模型，并通过计算整数规划间隙（integrality gap）来量化精确解和松弛解之间的差异 。这项实践让你深刻理解组合精确性与计算易解性之间的建模权衡，从而阐明了为何凸松弛在稀疏信号处理中得到广泛应用。",
            "id": "3494193",
            "problem": "考虑一个一维正交小波变换，其小波系数上有一个有根二叉树，该树编码了规范的父节点闭包性（即如果一个子系数被激活，那么它的父系数也必须被激活）。设该树由一个索引为 $0$ 的根节点和两个索引为 $1$ 和 $2$ 的子节点组成。假设测量值已经处于小波域（因此变换矩阵是单位矩阵），并且我们寻求系数 $x \\in \\mathbb{R}^{3}$，以在平方数据保真度和树结构模型选择成本之间进行权衡。\n\n从以下基本要素开始：\n- 小波变换是正交的，因此在小波域中，标准的最小二乘数据保真度为 $\\frac{1}{2}\\|x - y\\|_{2}^{2}$。\n- 父节点闭包性可以通过二元激活变量 $z_{j} \\in \\{0,1\\}$ 以及约束 $z_{1} \\leq z_{0}$ 和 $z_{2} \\leq z_{0}$ 来精确强制执行。\n- 激活与系数大小之间的联系可以通过一个大M约束 $|x_{j}| \\leq M z_{j}$ 来表示，其中 $M  0$ 是用户指定的上界。\n- 混合整数二次规划 (MIQP) 目标函数可以通过每个节点的成本 $\\lambda z_{j}$ 来惩罚激活。\n\n使用具体实例，其中 $M = 1$，$\\lambda = 0.12$，数据为 $y = (y_{0}, y_{1}, y_{2}) = (0.1, 0.7, 0.7)$。\n\n任务：\n1. 为此实例构建精确的混合离散-连续公式，通过二元变量强制执行父节点闭包性。您的公式必须包括数据保真度项 $\\frac{1}{2}\\sum_{j=0}^{2}(x_{j} - y_{j})^{2}$、激活惩罚项 $\\lambda \\sum_{j=0}^{2} z_{j}$、大M关联项 $|x_{j}| \\leq M z_{j}$、二元约束 $z_{j} \\in \\{0,1\\}$ 以及父节点闭包性约束 $z_{1} \\leq z_{0}$ 和 $z_{2} \\leq z_{0}$。\n2. 将二元约束松弛到区间 $z_{j} \\in [0,1]$ 以获得凸松弛。以闭式形式消去变量 $x_{j}$，从而获得一个仅含连续变量 $z_{j}$ 的等价凸目标函数。利用父节点闭包性意味着 $z_{0} \\geq \\max\\{z_{1}, z_{2}\\}$ 这一事实来简化父节点的贡献项。\n3. 计算此实例的精确混合整数模型的最优目标值。\n4. 计算此实例的凸松弛的最优目标值。\n5. 将此最小化问题的整数间隙定义为 $G = \\frac{p_{\\mathrm{MIP}}}{p_{\\mathrm{REL}}}$，其中 $p_{\\mathrm{MIP}}$ 是精确混合整数规划的最优目标值，$p_{\\mathrm{REL}}$ 是凸松弛的最优目标值。为此实例精确计算 $G$。\n\n给出您的最终答案，形式为单个实数（无单位）。不要四舍五入；以简化分数或闭式表达式的形式报告精确值。",
            "solution": "该问题提法明确，具有科学依据，并为获得唯一解提供了所有必要信息。我们验证该问题并按顺序解决这五个任务。\n\n给定参数如下：\n- 数据向量：$y = (y_{0}, y_{1}, y_{2}) = (0.1, 0.7, 0.7)$。\n- 大M常数：$M=1$。\n- 正则化参数：$\\lambda = 0.12$。\n- 小波变换是单位变换，因此我们直接处理系数 $x \\in \\mathbb{R}^{3}$。\n- 树结构意味着父子关系为 $(0,1)$ 和 $(0,2)$。\n\n### 任务1：混合整数二次规划 (MIQP) 公式\n\n目标函数结合了平方 $\\ell_2$ 数据保真度项和对激活系数数量的惩罚项。约束条件强制执行父节点闭包的树结构，并将连续系数 $x_j$ 与二元激活变量 $z_j$ 联系起来。\n\n一般公式为：\n$$ \\min_{x \\in \\mathbb{R}^{3}, z \\in \\{0,1\\}^{3}} \\quad \\frac{1}{2}\\sum_{j=0}^{2}(x_{j} - y_{j})^{2} + \\lambda \\sum_{j=0}^{2} z_{j} $$\n约束条件为：\n$$ |x_{j}| \\leq M z_{j} \\quad \\text{for } j \\in \\{0, 1, 2\\} $$\n$$ z_{1} \\leq z_{0} $$\n$$ z_{2} \\leq z_{0} $$\n\n代入具体实例值 ($y_{0}=0.1, y_{1}=0.7, y_{2}=0.7, M=1, \\lambda=0.12$)：\n$$ \\min_{x, z} \\quad \\frac{1}{2}\\left((x_{0} - 0.1)^{2} + (x_{1} - 0.7)^{2} + (x_{2} - 0.7)^{2}\\right) + 0.12(z_{0} + z_{1} + z_{2}) $$\n约束条件为：\n$$ |x_{0}| \\leq z_{0} $$\n$$ |x_{1}| \\leq z_{1} $$\n$$ |x_{2}| \\leq z_{2} $$\n$$ z_{1} \\leq z_{0} $$\n$$ z_{2} \\leq z_{0} $$\n$$ z_{0}, z_{1}, z_{2} \\in \\{0, 1\\} $$\n\n### 任务2：凸松弛和变量消去\n\n我们通过将二元约束 $z_{j} \\in \\{0,1\\}$ 松弛为连续约束 $z_{j} \\in [0,1]$ 来获得凸松弛。目标函数可以重构为：首先在固定 $z$ 的情况下对 $x$ 进行最小化，然后对 $z$ 进行最小化。\n$$ \\min_{z \\in [0,1]^3} \\left( \\lambda \\sum_{j=0}^{2} z_{j} + \\sum_{j=0}^{2} \\min_{x_j, |x_j| \\le Mz_j} \\frac{1}{2}(x_j-y_j)^2 \\right) $$\n对于每个系数 $x_j$ 的内部最小化是 $y_j$ 在区间 $[-Mz_j, Mz_j]$ 上的投影。解为 $x_j^* = \\text{sgn}(y_j)\\min(|y_j|, Mz_j)$。这个内部最小化的值为 $\\frac{1}{2}(x_j^*-y_j)^2$，可以简化为 $\\frac{1}{2}\\max(0, |y_j| - Mz_j)^2$。\n\n将此代回目标函数，我们得到一个仅关于 $z$ 的凸问题：\n$$ \\min_{z \\in [0,1]^3} \\quad \\lambda \\sum_{j=0}^{2} z_{j} + \\frac{1}{2}\\sum_{j=0}^{2} \\max(0, |y_j| - Mz_j)^2 $$\n约束条件为父节点闭包性约束 $z_{1} \\leq z_{0}$ 和 $z_{2} \\leq z_{0}$。\n\n对于我们的具体实例，这变为：\n$$ \\min_{z_{0},z_{1},z_{2}} \\quad 0.12(z_{0}+z_{1}+z_{2}) + \\frac{1}{2}\\max(0, 0.1-z_{0})^{2} + \\frac{1}{2}\\max(0, 0.7-z_{1})^{2} + \\frac{1}{2}\\max(0, 0.7-z_{2})^{2} $$\n约束条件为：\n$$ z_{1} \\leq z_{0} $$\n$$ z_{2} \\leq z_{0} $$\n$$ z_{0}, z_{1}, z_{2} \\in [0,1] $$\n父节点对目标的贡献是项 $0.12 z_{0} + \\frac{1}{2}\\max(0, 0.1-z_{0})^{2}$。父节点闭包性约束 $z_{0} \\geq \\max\\{z_1, z_2\\}$ 作为对优化变量的约束来处理。\n\n### 任务3：MIQP的最优值 ($p_{\\mathrm{MIP}}$)\n\n我们对所有满足父节点闭包性约束 $z_1 \\le z_0$ 和 $z_2 \\le z_0$ 的二元变量 $z_j$ 的有效组合来评估 MIQP 目标函数。对于每个固定的 $z$，最优的 $x_j$ 是 $\\text{sgn}(y_j)\\min(|y_j|, z_j)$。\n\n1.  $(z_{0},z_{1},z_{2})=(0,0,0)$: $x=(0,0,0)$。目标值：$\\frac{1}{2}((0-0.1)^2 + (0-0.7)^2 + (0-0.7)^2) + 0 = \\frac{1}{2}(0.01+0.49+0.49) = 0.495$。\n2.  $(z_{0},z_{1},z_{2})=(1,0,0)$: $x=(0.1,0,0)$。目标值：$\\frac{1}{2}(0 + (0-0.7)^2 + (0-0.7)^2) + 0.12(1) = 0.49 + 0.12 = 0.61$。\n3.  $(z_{0},z_{1},z_{2})=(1,1,0)$: $x=(0.1,0.7,0)$。目标值：$\\frac{1}{2}(0 + 0 + (0-0.7)^2) + 0.12(2) = 0.245+0.24 = 0.485$。\n4.  $(z_{0},z_{1},z_{2})=(1,0,1)$: $x=(0.1,0,0.7)$。根据与前一情况的对称性，目标值为 $0.485$。\n5.  $(z_{0},z_{1},z_{2})=(1,1,1)$: $x=(0.1,0.7,0.7)$。数据保真度项为 $0$。目标值：$0.12(3) = 0.36$。\n\n比较这些值：$\\{0.495, 0.61, 0.485, 0.36\\}$。最小值是 $0.36$。\n因此，混合整数规划的最优值是 $p_{\\mathrm{MIP}} = 0.36 = \\frac{9}{25}$。\n\n### 任务4：凸松弛的最优值 ($p_{\\mathrm{REL}}$)\n\n我们必须解决任务2中的凸规划问题。由于目标函数和约束关于 $z_1$ 和 $z_2$ 是对称的，最优解将具有 $z_1^*=z_2^*$。设这个共同的值为 $z_c$。问题简化为：\n$$ \\min_{z_0, z_c} \\quad p(z_0, z_c) = 0.12 z_0 + 0.24 z_c + \\frac{1}{2}\\max(0, 0.1-z_0)^2 + \\max(0, 0.7-z_c)^2 $$\n约束条件为 $0 \\leq z_c \\leq z_0 \\leq 1$。\n\n在可行域的内部，目标函数的梯度非零，因此最小值必定位于边界上。我们检查边界线 $z_c = z_0 = z$ (对于 $z \\in [0,1]$)。目标函数变为单个变量 $z$ 的函数：\n$$ g(z) = 0.36z + \\frac{1}{2}\\max(0, 0.1-z)^2 + \\max(0, 0.7-z)^2 $$\n我们分段分析此函数：\n- 对于 $z \\in [0.1, 0.7)$，目标函数为 $g(z) = 0.36z + (0.7-z)^2 = z^2 - 1.04z + 0.49$。其导数为 $g'(z) = 2z - 1.04$。令 $g'(z)=0$ 得 $z = 0.52$。该点位于区间 $[0.1, 0.7)$ 内，是最小值的候选点。其值为 $g(0.52) = (0.52)^2 - 1.04(0.52) + 0.49 = 0.2704 - 0.5408 + 0.49 = 0.2196$。\n- 对于 $z \\geq 0.7$，$g(z) = 0.36z$，在 $z=0.7$ 处取最小值，得 $g(0.7)=0.36(0.7)=0.252$。\n- 对于 $z  0.1$，$g(z)$ 的导数恒为负，因此函数朝 $z=0.1$ 方向递减。\n\n在直线 $z_c=z_0=z$ 上的最小值出现在 $z=0.52$ 处。通过检查完整三变量问题的卡罗需-库恩-塔克（KKT）条件，可以验证点 $(z_0, z_1, z_2) = (0.52, 0.52, 0.52)$ 是全局最小值。\n\n我们现在计算在 $z_0=z_1=z_2=0.52 = \\frac{13}{25}$ 时的最优值 $p_{\\mathrm{REL}}$。\n$$ p_{\\mathrm{REL}} = 0.12(3 \\times 0.52) + \\frac{1}{2}\\max(0, 0.1-0.52)^2 + 2 \\times \\frac{1}{2}\\max(0, 0.7-0.52)^2 $$\n$$ p_{\\mathrm{REL}} = 0.36(0.52) + 0 + (0.7-0.52)^2 = 0.1872 + (0.18)^2 = 0.1872 + 0.0324 = 0.2196 $$\n以分数形式表示，$z^* = \\frac{13}{25}$ 且 $\\lambda=\\frac{3}{25}$。\n$$ p_{\\mathrm{REL}} = 3 \\lambda z^* + (y_1-z^*)^2 = 3\\left(\\frac{3}{25}\\right)\\left(\\frac{13}{25}\\right) + \\left(\\frac{7}{10}-\\frac{13}{25}\\right)^2 = \\frac{117}{625} + \\left(\\frac{35-26}{50}\\right)^2 $$\n$$ p_{\\mathrm{REL}} = \\frac{117}{625} + \\left(\\frac{9}{50}\\right)^2 = \\frac{117}{625} + \\frac{81}{2500} = \\frac{468+81}{2500} = \\frac{549}{2500} $$\n\n### 任务5：整数间隙 ($G$)\n\n此最小化问题的整数间隙定义为 $G = \\frac{p_{\\mathrm{MIP}}}{p_{\\mathrm{REL}}}$。\n使用精确的分数值：\n$$ p_{\\mathrm{MIP}} = \\frac{9}{25} $$\n$$ p_{\\mathrm{REL}} = \\frac{549}{2500} $$\n间隙为：\n$$ G = \\frac{9/25}{549/2500} = \\frac{9}{25} \\times \\frac{2500}{549} = 9 \\times \\frac{100}{549} $$\n我们观察到 $549 = 5+4+9=18$，所以 $549$ 可以被 $9$ 整除。实际上，$549 \\div 9 = 61$。\n$$ G = \\frac{9 \\times 100}{9 \\times 61} = \\frac{100}{61} $$\n这是一个不可约分数，因为 $61$ 是一个素数。",
            "answer": "$$\\boxed{\\frac{100}{61}}$$"
        }
    ]
}