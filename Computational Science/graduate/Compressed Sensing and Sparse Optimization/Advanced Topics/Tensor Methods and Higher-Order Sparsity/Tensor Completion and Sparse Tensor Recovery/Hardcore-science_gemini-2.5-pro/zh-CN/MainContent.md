## 引言
在数据科学、信号处理和机器学习领域，我们经常面对高维数据，如视频、高[光谱](@entry_id:185632)图像或时空数据集。这些数据在自然形态下以张量（即多维数组）的形式存在，并且往往由于采集成本、传感器故障或物理限制而存在大量缺失。张量补全与[稀疏张量恢复](@entry_id:755131)技术应运而生，其核心目标是从这些不完整、甚至被污染的观测中重建出完整的、结构化的多维信号。这一任务的关键在于利用数据中固有的低维结构，最常见的就是“低秩”假设。

然而，如何精确定义和利用张量的“低秩”结构，并设计出既有理论保证又在计算上可行的恢复算法，是一个充满挑战的知识领域。本文旨在系统性地梳理这一领域的核心知识。我们将从最基本的原理出发，逐步深入到前沿的应用与算法。

在接下来的内容中，读者将首先在“原理与机制”一章中学习张量低秩结构的不同定义（[CP秩](@entry_id:748030)、[Tucker秩](@entry_id:756214)、管状秩），理解为何直接最小化秩是困难的，并掌握其可计算的凸代理方法。随后，在“应用与交叉学科联系”一章，我们将展示这些理论如何在压缩感知、结构化采样和多维[信号建模](@entry_id:181485)等实际问题中发挥作用。最后，通过“动手实践”部分的练习，您将有机会将理论知识应用于算法设计与实证分析，从而深化理解。让我们首先从张量恢复问题的核心原理与基本机制开始。

## 原理与机制

在理解了张量恢复问题的背景与重要性之后，本章将深入探讨其核心的科学原理与基本机制。我们将从张量低秩结构的不同定义出发，阐释为何[张量秩](@entry_id:266558)的最小化在计算上是困难的，并由此引出可计算的凸代理（convex surrogate）。随后，我们将探讨保证恢复成功所需满足的关键条件，如非相干性（incoherence）和受限等距性质（Restricted Isometry Property）。最后，我们将讨论一些高级模型，包括鲁棒张量恢复以及非凸方法带来的机遇与挑战。

### 张量低秩结构的定义

与矩阵不同，[张量秩](@entry_id:266558)的概念并非唯一，这既是[张量分析](@entry_id:161423)丰富性的体现，也是其复杂性的根源。选择不同的秩定义，等价于采用不同的[代数结构](@entry_id:137052)来描述数据，从而导致不同的恢复模型和算法。

#### 典范多元分解（CP）秩

最直观的[张量秩](@entry_id:266558)定义是 **典范多元分解（Canonical Polyadic, CP）秩**，也称为 [PARAFAC](@entry_id:753095) 秩。一个 $N$ 阶张量 $\mathcal{X}$ 的 CP 秩，记作 $\mathrm{rank}_{\mathrm{CP}}(\mathcal{X})$，是指能够将 $\mathcal{X}$ 表示为一系列秩-1张量之和的最小项数 $R$。一个秩-1张量是 $N$ 个向量的外积。对于一个三阶张量 $\mathcal{X} \in \mathbb{R}^{n_1 \times n_2 \times n_3}$，其 CP 分解形式为：
$$
\mathcal{X} = \sum_{i=1}^{R} \mathbf{a}_i \circ \mathbf{b}_i \circ \mathbf{c}_i
$$
其中 $\mathbf{a}_i \in \mathbb{R}^{n_1}, \mathbf{b}_i \in \mathbb{R}^{n_2}, \mathbf{c}_i \in \mathbb{R}^{n_3}$ 是因子向量，$\circ$ 表示外积。$\mathrm{rank}_{\mathrm{CP}}(\mathcal{X})$ 就是使得上式成立的最小 $R$ 值。CP 秩在概念上非常优雅，但其计算是一个臭名昭著的难题。对于三阶及更高阶的张量，确定其 CP 秩通常是 **NP-难** 的 。这种计算上的复杂性是促使研究者寻找替代性秩定义的主要原因。

#### Tucker 秩与多线性结构

另一个核心的秩定义是 **Tucker 秩**，或称多线性秩。它不是一个单一的数值，而是一个元组 $(r_1, r_2, \dots, r_N)$。为了定义 Tucker 秩，我们首先需要引入 **模-$n$ 展开（mode-$n$ unfolding）** 的概念。一个 $N$ 阶张量 $\mathcal{X}$ 的模-$n$ 展开，记作 $\mathbf{X}_{(n)}$，是将张量重新[排列](@entry_id:136432)成一个矩阵的过程。对于一个三阶张量 $\mathcal{X} \in \mathbb{R}^{n_1 \times n_2 \times n_3}$，其模-1展开 $\mathbf{X}_{(1)}$ 是一个 $n_1 \times (n_2 n_3)$ 的矩阵，它的列由张量沿着第一维的向量（称为模-1纤维）构成。类似地，可以定义 $\mathbf{X}_{(2)} \in \mathbb{R}^{n_2 \times (n_1 n_3)}$ 和 $\mathbf{X}_{(3)} \in \mathbb{R}^{n_3 \times (n_1 n_2)}$。

张量 $\mathcal{X}$ 的 Tucker 秩就是其所有模展开[矩阵的秩](@entry_id:155507)所组成的元组：$(r_1, r_2, r_3) = (\mathrm{rank}(\mathbf{X}_{(1)}), \mathrm{rank}(\mathbf{X}_{(2)}), \mathrm{rank}(\mathbf{X}_{(3)}))$。与 CP 秩不同，Tucker 秩可以通过对矩阵进行奇异值分解（SVD）在多项式时间内计算出来。

CP 秩和 Tucker 秩描述了根本不同的结构。一个张量的 CP 秩可能远大于其 Tucker 秩的任何一个分量。为了具体说明这一点，我们可以构造一个简单的例子 。考虑一个 $2 \times 2 \times 2$ 的张量 $\mathcal{X}$，它由两个秩-1张量的和构成：
$$
\mathcal{X} = \mathbf{a}_1 \circ \mathbf{b}_1 \circ \mathbf{c}_1 + \mathbf{a}_2 \circ \mathbf{b}_2 \circ \mathbf{c}_2
$$
其中向量为：
$$
\mathbf{a}_1 = \begin{pmatrix}1\\1\end{pmatrix}, \mathbf{b}_1 = \begin{pmatrix}1\\0\end{pmatrix}, \mathbf{c}_1=\begin{pmatrix}1\\0\end{pmatrix} \quad \text{以及} \quad \mathbf{a}_2 = \begin{pmatrix}1\\1\end{pmatrix}, \mathbf{b}_2 = \begin{pmatrix}0\\1\end{pmatrix}, \mathbf{c}_2=\begin{pmatrix}0\\1\end{pmatrix}.
$$
根据定义，$\mathcal{X}$ 的 CP 秩至多为 2。通过[反证法](@entry_id:276604)可以证明它不能表示为单个秩-1张量，因此其 CP 秩恰好为 2。现在，我们计算其 Tucker 秩。首先构造出张量的元素，其非零项为 $\mathcal{X}_{111} = 1, \mathcal{X}_{211} = 1, \mathcal{X}_{122} = 1, \mathcal{X}_{222} = 1$。其模-1展开矩阵为：
$$
\mathbf{X}_{(1)} = \begin{pmatrix} 1  0  0  1 \\ 1  0  0  1 \end{pmatrix}
$$
该矩阵的两行完全相同，因此其秩为 1。而其模-2 和模-3 展开矩阵均为：
$$
\mathbf{X}_{(2)} = \mathbf{X}_{(3)} = \begin{pmatrix} 1  1  0  0 \\ 0  0  1  1 \end{pmatrix}
$$
这个矩阵的两行是[线性无关](@entry_id:148207)的，因此其秩为 2。所以，张量 $\mathcal{X}$ 的 Tucker 秩为 $(1, 2, 2)$。这个例子清晰地表明，对于同一个张量，其 CP 秩 $r_{\mathrm{CP}}=2$ 与 Tucker 秩的第一个分量 $r_1=1$ 是不同的。这揭示了两种秩定义在描述张量结构上的本质差异。

Tucker 秩与 **Tucker 分解** 密切相关，该分解将一个[张量表示](@entry_id:180492)为一个[核心张量](@entry_id:747891)（core tensor）$\mathcal{G}$ 与一系列因子矩阵（factor matrices）$U_k$ 的多线性乘积：
$$
\mathcal{X} = \mathcal{G} \times_1 U_1 \times_2 U_2 \times_3 U_3
$$
其中 $U_k$ 的列构成了模-$k$ 展开矩阵 $\mathbf{X}_{(k)}$ 的列空间的一个基。如果这些基是标准正交的，该分解称为 **[高阶奇异值分解](@entry_id:197696) (Higher-Order Singular Value Decomposition, [HOSVD](@entry_id:197696))** 。这种分解形式为低秩近似提供了一个强大的工具。通过截断[核心张量](@entry_id:747891)和相应的因子矩阵，可以得到在[弗罗贝尼乌斯范数](@entry_id:143384)（Frobenius norm）意义下的最佳低多线性秩近似。

#### 管状秩与 t-SVD 框架

最近，一种基于[傅里叶变换](@entry_id:142120)的代数框架为三阶张量引入了新的结构定义。这个框架通过 **t-积（t-product）** 定义了一种新的张量乘法。其核心思想是将一个三阶张量 $\mathcal{X} \in \mathbb{R}^{n_1 \times n_2 \times n_3}$ 沿着第三个维度进行离散傅里叶变换（DFT），得到一系列位于傅里叶域的正面切片（frontal slices）$\{\widehat{\mathbf{X}}^{(l)}\}_{l=1}^{n_3}$。两个张量的 t-积在傅里叶域中对应于它们正面切片之间的逐个矩阵乘法。

这个框架催生了 **张量[奇异值分解](@entry_id:138057)（tensor SVD, t-SVD）** 和 **管状秩（tubal rank）** 的概念。张量 $\mathcal{X}$ 的管状秩被定义为其傅里叶域正面切片[矩阵秩](@entry_id:153017)的最大值：
$$
\mathrm{rank}_t(\mathcal{X}) = \max_{l \in \{1,\dots,n_3\}} \mathrm{rank}(\widehat{\mathbf{X}}^{(l)})
$$
管状秩提供了一种与 CP 秩和 Tucker 秩截然不同的衡量张量复杂性的方式。一个张量可以拥有很低的管状秩，但其 CP 秩却非常高 。这种差异源于 t-SVD 框架所依赖的特定[代数结构](@entry_id:137052)（沿管（tube）的[循环卷积](@entry_id:147898)），这种结构在[傅里叶变换](@entry_id:142120)下被[对角化](@entry_id:147016)。而在空间域中，这种结构可能表现得非常复杂。这种现象说明了“低秩”的相对性：一个张量是否“简单”取决于我们用来衡量它的代数工具。

### 张量恢复的计算挑战与代理

张量恢复的核心任务是从不完整的观测数据 $y = \mathcal{A}(\mathcal{X})$ 中重建出低秩张量 $\mathcal{X}$。理想情况下，我们希望求解一个秩最小化问题：
$$
\min_{\mathcal{X}} \mathrm{rank}(\mathcal{X}) \quad \text{s.t.} \quad \mathcal{A}(\mathcal{X}) = y
$$
然而，如前所述，$\mathrm{rank}(\mathcal{X})$ 本身就是一个难以处理的量。

#### 秩最小化的 intractable 本质

对于 CP 秩，由于其计算的 NP-难度，直接最小化 CP 秩是一个[组合优化](@entry_id:264983)问题，在计算上是不可行的。一个自然的想法是，借鉴矩阵恢复的成功经验，使用秩函数的[凸包](@entry_id:262864)（convex envelope）——[核范数](@entry_id:195543)（nuclear norm）——作为其凸代理。然而，张量的情形要复杂得多。三阶及以上张量的 CP 秩，其最紧的[凸松弛](@entry_id:636024)是所谓的 **[张量核范数](@entry_id:755857)**。不幸的是，计算这个[张量核范数](@entry_id:755857)本身也是一个 NP-难问题 。这意味着，对于 CP 秩，无论是直接最小化还是通过其“最佳”凸代理进行最小化，我们都面临着计算上的巨大障碍。

#### 可计算的凸代理：面向 Tucker 秩

与 CP 秩的困境形成鲜明对比，基于 Tucker 秩的恢复模型提供了一条切实可行的路径。由于 Tucker 秩的每个分量 $r_k = \mathrm{rank}(\mathbf{X}_{(k)})$ 都是一个[矩阵秩](@entry_id:153017)，我们可以对每个模态展开应用矩阵[核范数](@entry_id:195543)作为代理。这引出了 **重叠核范数（overlapped nuclear norm）**，也称为 **展开[核范数](@entry_id:195543)之和 (Sum of Nuclear Norms, SNN)**，作为低 Tucker 秩的一个凸代理：
$$
\| \mathcal{X} \|_{\text{SNN}} = \sum_{k=1}^{3} \lambda_k \|\mathbf{X}_{(k)}\|_*
$$
其中 $\|\cdot\|_*$ 表示矩阵核范数（奇异值之和），$\lambda_k > 0$ 是权重。这个目标函数是凸的，并且可以在多项式时间内计算，因为它只需要对每个展开矩阵进行 SVD。因此，基于 SNN 的恢复模型在计算上是可行的 。

SNN 并不是唯一的凸代理。**潜在核范数（latent nuclear norm）** 提供了另一种选择 。它通过将张量 $\mathcal{X}$ 分解为多个部分之和 $\mathcal{X} = \sum_{k=1}^3 \mathcal{Z}^{(k)}$，并最小化每个部分在其[对应模](@entry_id:200367)态展开下的核范数之和：
$$
\| \mathcal{X} \|_{\text{lat}} = \inf \left\{ \sum_{k=1}^{3} \|\mathbf{Z}^{(k)}_{(k)}\|_* : \mathcal{X} = \sum_{k=1}^{3} \mathcal{Z}^{(k)} \right\}
$$
这个定义引入了额外的优化变量 $\mathcal{Z}^{(k)}$，但它在理论上可以提供比 SNN 更紧的对低秩结构的近似。对于某些张量，潜在核范数的值可能远小于重叠核范数，这表明它可能是一个更有效的正则化器 。

对于管状秩，其凸代理是 **张量管状核范数（Tensor Tubal Nuclear Norm, TTNN）**，定义为傅里叶域中所有正面切片[矩阵的核](@entry_id:152429)范数之和（经过一个归一化因子）。由于 DFT 是线性变换，且矩阵核范数的和是凸的，TTNN 也是一个可计算的[凸函数](@entry_id:143075)。

### [恢复保证](@entry_id:754159)的理论基石

一个核心的理论问题是：在什么条件下，通过最小化凸代理能够成功恢复出真实的低秩张量？答案通常涉及两个关键概念：算子的性质和张量本身的性质。

#### 张量受限等距性质 (TRIP)

**受限等距性质（Restricted Isometry Property, RIP）** 是[压缩感知](@entry_id:197903)理论的基石。它要求测量算子 $\mathcal{A}$ 在作用于特定结构（如稀疏向量或低秩矩阵）的信号时，能够近似地保持信号的能量（即范数）。这个概念可以自然地推广到张量。

对于一个给定的多线性秩 $(r_1, r_2, r_3)$，我们定义 **张量受限等距性质 (Tensor Restricted Isometry Property, TRIP)** 。如果一个[线性算子](@entry_id:149003) $\mathcal{A}: \mathbb{R}^{n_1 \times n_2 \times n_3} \to \mathbb{R}^m$ 满足 TRIP，那么对于所有多线性秩不超过 $(r_1, r_2, r_3)$ 的张量 $\mathcal{X}$，都存在一个小的常数 $\delta \in [0, 1)$，使得以下不等式成立：
$$
(1 - \delta) \|\mathcal{X}\|_F^2 \le \|\mathcal{A}(\mathcal{X})\|_2^2 \le (1 + \delta) \|\mathcal{X}\|_F^2
$$
其中 $\|\cdot\|_F$ 是张量的[弗罗贝尼乌斯范数](@entry_id:143384)。这个性质意味着，测量过程 $\mathcal{A}$ 在低秩张量集合上表现得像一个近似的等距映射。如果一个算子（例如，随机高斯测量或随机条目采样）满足 TRIP，那么从理论上就可以保证低秩张量恢复的稳定性和准确性。

#### 非[相干性](@entry_id:268953)：为何随机采样有效

在张量补全问题中，测量算子 $\mathcal{A}$ 是一个采样算子，它只观测张量在一部分索引 $\Omega$ 上的值。为什么均匀[随机采样](@entry_id:175193)是一种有效的策略？答案在于 **非相干性（incoherence）** 的概念。

直观地说，如果一个低秩张量的[能量集中](@entry_id:203621)在极少数几个条目上（即张量是“尖峰状的”），那么[随机采样](@entry_id:175193)很可能会错过这些关键信息。相反，如果张量的能量“均匀地”[分布](@entry_id:182848)在所有条目中，那么[随机采样](@entry_id:175193)就有很大概率采集到具有代表性的信息。非[相干性](@entry_id:268953)正是对这种能量[分布](@entry_id:182848)[均匀性](@entry_id:152612)的数学刻画。

对于 Tucker 模型，非相干性是通过对因子矩阵 $U_k$ 的行范数施加限制来定义的 。具体来说，一个因子矩阵 $U_k \in \mathbb{R}^{n_k \times r_k}$（其列标准正交）的 **杠杆分数（leverage scores）** 被定义为其行的[欧几里得范数](@entry_id:172687)的平方，即 $\ell_{i,k} = \|U_k^\top e_i\|_2^2$。这些分数的平均值是 $r_k/n_k$。非相干性条件要求所有杠杆分数都接近其平均值，即存在一个小的常数 $\mu \ge 1$，使得：
$$
\max_{i} \|U_k^\top e_i\|_2^2 \le \mu \frac{r_k}{n_k}
$$
这个条件保证了因子矩阵中没有哪一行具有过大的范数，从而防止了张量中出现能量过于集中的“尖峰”。

对于 t-SVD 框架，非[相干性](@entry_id:268953)的概念被应用到傅里叶域的每一个正面切片上 。我们需要对所有切片 $\widehat{\mathbf{X}}^{(k)}$ 的左、[右奇异向量](@entry_id:754365)矩阵 $U^{(k)}, V^{(k)}$ 施加最坏情况下的非相干性约束。当张量满足这种非相干性条件时，均匀[随机采样](@entry_id:175193)才能保证为恢复算法提供足够的信息。

非相干性与样本复杂度密切相关。对于一个满足非[相干性](@entry_id:268953)条件的低管状秩张量，理论表明，为了高概率地成功恢复，所需的样本数量 $m$ 的尺度大致为 $m \gtrsim \mu r (n_1+n_2)n_3 \log(N)$，其中 $N = n_1 n_2 n_3$ 是总条目数，$\mu$ 是非[相干性](@entry_id:268953)参数， $r$ 是管状秩 。这揭示了样本数不仅依赖于秩，还依赖于张量的维度和非[相干性](@entry_id:268953)。

### 高级模型与前沿视角

#### 鲁棒张量恢复

在许多实际应用中，观测数据不仅是不完整的，还可能被稀疏但任意大的误差所污染。这引出了 **鲁棒张量主成分分析（Robust Tensor PCA, TRPCA）** 模型，它将观测张量 $\mathcal{Y}$ 分解为一个低秩部分 $\mathcal{L}$ 和一个稀疏部分 $\mathcal{S}$ 的和：$\mathcal{Y} = \mathcal{L} + \mathcal{S}$。

一个核心的挑战是 **可识别性（identifiability）**：在什么条件下，我们能唯一地从 $\mathcal{Y}$ 中分离出 $\mathcal{L}$ 和 $\mathcal{S}$？如果 $\mathcal{L}$ 的结构与 $\mathcal{S}$ 的结构有重叠（例如，一个低秩张量本身也很稀疏），那么这种分离就是模糊的。为了保证唯一分解，低秩部分和稀疏部分必须是 **非相干的**。

在 t-SVD 框架下，这组可识别性条件可以被精确地刻画 ：
1.  **低秩部分的非相干性**：低秩张量 $\mathcal{L}$ 在其 t-SVD [奇异向量](@entry_id:143538)空间上必须是 incoherent 的，这意味着其能量不能集中在少数坐标上。
2.  **稀疏部分的[扩散](@entry_id:141445)性**：稀疏张量 $\mathcal{S}$ 的非零项（其支撑集）必须是[扩散](@entry_id:141445)的，不能集中在具有低秩结构的[子集](@entry_id:261956)上（例如，少数几行或几列）。
3.  **代数上的不重叠**：最根本地，这两个条件确保了低秩张量空间与稀疏张量空间的交集仅包含零张量。

从几何角度看，恢复失败的一个典型场景是当稀疏误差 $\mathcal{S}$ 恰好位于低秩[流形](@entry_id:153038)在 $\mathcal{L}$ 点的 **[切空间](@entry_id:199137)（tangent space）** 内 。在这种情况下，$\mathcal{L}+\mathcal{S}$ 在[流形](@entry_id:153038)上只是一个微小的移动，算法无法将其与一个略微不同的低秩张量 $\mathcal{L}'$ 区分开来。例如，对于一个秩-1 张量 $L = e_1 \otimes e_1 \otimes e_1$，其切空间中包含形如 $S = e_2 \otimes e_1 \otimes e_1$ 的张量。这个 $S$ 本身是一个仅有一个非零项的极稀疏张量。这种低秩[流形](@entry_id:153038)与[稀疏结构](@entry_id:755138)之间的高度相干性（coherence）是恢复问题的根本障碍。

#### 超越[凸性](@entry_id:138568)：非凸方法的优势与挑战

尽管[凸松弛](@entry_id:636024)方法（如 SNN 和 TTNN）在理论和实践上都取得了巨大成功，但它们也存在固有的局限性。特别是，[核范数](@entry_id:195543)作为秩的代理会引入所谓的 **收缩偏误（shrinkage bias）**，即它会不成比例地惩罚所有[奇异值](@entry_id:152907)，包括那些对应于真实信号的大奇异值。

为了克服这一问题，研究者们转向了 **非凸代理** 。一个流行的选择是 **Schatten-$p$ 范数**（严格来说是拟范数，quasi-norm），其定义为 $\left(\sum_i \sigma_i^p\right)^{1/p}$，其中 $p \in (0, 1)$。当 $p \to 0$ 时，$\sum_i \sigma_i^p$ 趋近于[矩阵的秩](@entry_id:155507)。因此，对于 $p1$，Schatten-$p$ 范数是比核范数 ($p=1$) 更紧的秩近似。

使用[非凸惩罚](@entry_id:752554)项的优势在于：
- **更少的偏误**：它们对大奇异值的收缩更小，从而能得到更准确的估计。
- **更低的样本复杂度**：在某些情况下，它们可以从更少的样本中成功恢复信号。

然而，这种优势是有代价的：[目标函数](@entry_id:267263)变为非凸，这使得优化变得更加困难。非凸问题可能存在许多不良的局部最小值，算法可能会收敛到次优解。尽管如此，诸如 **迭代重加权最小二乘（Iteratively Reweighted Least Squares, IRLS）** 等算法在实践中表现出色。这类算法通过在每次迭代中求解一个加权的凸问题（通常是加权的[核范数最小化](@entry_id:634994)）来逐步逼近原非凸问题的解。虽然不能保证[全局收敛](@entry_id:635436)，但它们通常能够收敛到一个一阶[临界点](@entry_id:144653)，并且在有良好初始值的情况下能找到高质量的解 。

总而言之，从[凸松弛](@entry_id:636024)到[非凸正则化](@entry_id:636532)的演进，反映了张量恢复领域在追求更高精度和效率的过程中，不断在计算可行性与统计最优性之间进行权衡与探索。