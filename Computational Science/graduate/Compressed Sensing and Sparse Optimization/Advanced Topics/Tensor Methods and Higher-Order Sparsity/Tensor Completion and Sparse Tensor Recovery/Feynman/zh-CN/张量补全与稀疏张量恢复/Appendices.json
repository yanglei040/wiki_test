{
    "hands_on_practices": [
        {
            "introduction": "在低秩恢复理论中，非相干性是一个确保可以从少量样本中成功重建信号的关键条件。这个练习通过构建一个违反该条件的思想实验，来帮助你建立关于其重要性的直观理解。你将分析一个极度相干的（即信息高度集中的）秩一张量，并证明如果没有非相干性假设，即使知道真实的秩，恢复也可能失败。",
            "id": "3485381",
            "problem": "考虑非相干性在低秩张量补全中的作用。设 $d \\in \\mathbb{N}$ 且 $d \\geq 3$，并设 $X \\in \\mathbb{R}^{n_{1} \\times n_{2} \\times \\cdots \\times n_{d}}$ 是一个秩为1的典范多项分解 (CP) 张量，定义为 $X = \\alpha \\, \\mathbf{e}_{i_{1}^{\\star}} \\otimes \\mathbf{e}_{i_{2}^{\\star}} \\otimes \\cdots \\otimes \\mathbf{e}_{i_{d}^{\\star}}$，其中 $\\alpha > 0$ 是一个标量，$\\mathbf{e}_{i}$ 表示一个标准基向量。因此，$X$ 在索引 $(i_{1}^{\\star}, i_{2}^{\\star}, \\ldots, i_{d}^{\\star})$ 处有一个值为 $\\alpha$ 的唯一非零元素，而在其他位置均为零，这是一种高度相干的结构。设 $N = \\prod_{\\ell=1}^{d} n_{\\ell}$ 是 $X$ 中元素的总数。\n\n假设一个采样算子从 $N$ 个可能的索引中无放回地均匀随机选择并揭示 $X$ 的恰好 $m$ 个不同元素，并无噪声地返回它们的值。要求一个补全算法在秩为1的约束下从这些揭示的元素中恢复 $X$，但没有施加非相干性假设。\n\n仅使用张量代数和基本概率论的核心定义，通过论证当唯一的非零元素未被采样时，观测值恒为零，因此与任何支撑在未观测索引上的秩为1的张量（特别是零张量）同样一致，从而构建一个关于可辨识性的反例。然后，以 $n_{1}, n_{2}, \\ldots, n_{d}$ 和 $m$ 的形式，推导出此失败事件的确切概率的闭式解析表达式。\n\n你的最终答案必须是单一的解析表达式。不需要四舍五入，也不需要报告单位。",
            "solution": "问题陈述已被解析和验证。我们发现它具有科学依据、问题明确、客观且内部一致。它在张量补全领域提出了一个有效的理论问题。因此，我们可以进行完整解答。\n\n该问题要求两件事：首先，构建一个反例，证明当一个高度相干张量的唯一非零元素未被采样时，可辨识性会失效；其次，推导此失败事件的确切概率。\n\n设 $\\mathcal{X} \\in \\mathbb{R}^{n_{1} \\times n_{2} \\times \\cdots \\times n_{d}}$ 是一个 $d$ 阶张量。问题定义了一个特定的秩为1的典范多项分解 (CP) 张量 $X$，由标准基向量的外积给出：\n$$\nX = \\alpha \\, \\mathbf{e}_{i_{1}^{\\star}} \\otimes \\mathbf{e}_{i_{2}^{\\star}} \\otimes \\cdots \\otimes \\mathbf{e}_{i_{d}^{\\star}}\n$$\n其中 $\\alpha > 0$ 是一个标量，$\\mathbf{e}_{k} \\in \\mathbb{R}^{n}$ 是一个在第 $k$ 个位置为 $1$ 且其他位置为 $0$ 的向量，而 $(i_{1}^{\\star}, i_{2}^{\\star}, \\ldots, i_{d}^{\\star})$ 是一个特定的多重索引。这个张量 $X$ 恰好有一个非零元素 $X_{i_{1}^{\\star}, i_{2}^{\\star}, \\ldots, i_{d}^{\\star}} = \\alpha$，所有其他元素均为 $0$。这样的张量是最大程度相干的。\n\n设 $\\Omega$ 是所有可能的多重索引 $(j_{1}, j_{2}, \\ldots, j_{d})$ 的集合，其中对于 $\\ell = 1, \\ldots, d$ 有 $1 \\leq j_{\\ell} \\leq n_{\\ell}$。张量中元素的总数为 $N = |\\Omega| = \\prod_{\\ell=1}^{d} n_{\\ell}$。\n从 $\\Omega$ 中无放回地均匀随机选择一个包含 $m$ 个不同索引的集合 $\\Omega_{\\text{obs}} \\subset \\Omega$（其中 $|\\Omega_{\\text{obs}}| = m$）。观察者被给予这些值 $\\{X_{j} : j \\in \\Omega_{\\text{obs}}\\}$。张量补全问题是在恢复的张量必须是秩为1的约束下，从这些观测值中恢复 $X$。\n\n让我们将恢复的张量表示为 $\\hat{X}$。该问题可以表述为：\n$$\n\\text{寻找 } \\hat{X} \\text{ 使得 } \\text{rank}(\\hat{X}) \\leq 1 \\text{ 且 } P_{\\Omega_{\\text{obs}}}(\\hat{X}) = P_{\\Omega_{\\text{obs}}}(X)\n$$\n其中 $P_{\\Omega_{\\text{obs}}}$ 是一个投影算子，它将不在 $\\Omega_{\\text{obs}}$ 中的索引对应的所有元素设为零，或者更准确地说，在观测集上强制相等。\n\n现在，我们来构造这个反例。如果存在至少两个不同的张量 $\\hat{X}_{1}$ 和 $\\hat{X}_{2}$ 都满足给定的约束，那么可辨识性就会失效。我们考虑的具体失败事件是当 $X$ 的唯一非零元素未被采样时。设 $j^{\\star} = (i_{1}^{\\star}, i_{2}^{\\star}, \\ldots, i_{d}^{\\star})$ 为非零元素的索引。失败事件为 $j^{\\star} \\notin \\Omega_{\\text{obs}}$。\n\n如果这个事件发生，那么 $X$ 的每一个被采样的元素都为零，因为索引 $j^{\\star}$ 处的唯一非零元素被错过了。也就是说，对于每一个索引 $j \\in \\Omega_{\\text{obs}}$，我们有 $X_{j} = 0$。因此，观测数据恒为零。恢复问题变为：\n$$\n\\text{寻找 } \\hat{X} \\text{ 使得 } \\text{rank}(\\hat{X}) \\leq 1 \\text{ 且 } \\hat{X}_{j} = 0 \\text{ 对所有 } j \\in \\Omega_{\\text{obs}}\n$$\n我们可以立即确定满足这些条件的两个不同解：\n\n1. 零张量：设 $\\hat{X}_{1} = \\mathcal{O}$，即全零张量。零张量的秩为 $0$，满足约束 $\\text{rank}(\\hat{X}_{1}) \\leq 1$。它的所有元素都为 $0$，因此它自然地与 $\\Omega_{\\text{obs}}$ 上的零观测值相匹配。\n\n2. 真实张量：原始张量 $X$ 也是一个有效的候选解。我们知道 $\\text{rank}(X) = 1$。由于我们处于 $j^{\\star} \\notin \\Omega_{\\text{obs}}$ 的失败情况，索引在 $\\Omega_{\\text{obs}}$ 中的 $X$ 的所有元素确实都为 $0$。因此，$X$ 也满足约束。\n\n由于 $\\alpha > 0$，张量 $X$ 不是零张量 $\\mathcal{O}$。我们找到了两个不同的张量 $X$ 和 $\\mathcal{O}$，它们都是秩为1（或更低）并且与观测数据完全一致。在没有额外信息或假设（例如最小化某个范数，而许多范数会倾向于零解，从而无法恢复 $X$）的情况下，算法没有理由偏好其中一个。恢复问题是不适定的，因为它没有唯一解。这就构成了可辨识性的反例。事实上，任何秩为1的张量 $\\hat{X}' = \\beta \\, \\mathbf{e}_{k_{1}} \\otimes \\cdots \\otimes \\mathbf{e}_{k_{d}}$，其中索引 $(k_{1}, \\ldots, k_{d})$ 位于未观测集 $\\Omega \\setminus \\Omega_{\\text{obs}}$ 中，也是一个有效解，这意味着存在一个庞大的解族。\n\n接下来，我们推导这个失败事件的概率。该事件的特征是，单个特殊索引 $j^{\\star}$ 未被包含在随机选择的 $m$ 个索引的集合 $\\Omega_{\\text{obs}}$ 中。\n\n从 $N$ 个索引的总池中选择一个包含 $m$ 个不同索引的集合的总方法数由二项式系数 $\\binom{N}{m}$ 给出。这是我们样本空间的大小。\n\n失败事件的有利结果数是仅从张量 $X$ 为零的索引集合中选择 $m$ 个索引的方法数。有 $1$ 个非零元素，所以有 $N-1$ 个零元素。因此，我们必须从这 $N-1$ 个索引的集合中选择我们的 $m$ 个样本。这样做的方法数是 $\\binom{N-1}{m}$。只要 $m \\leq N-1$，这就是有效的。如果 $m=N$，失败概率为 $0$，我们的公式将正确反映这一点。\n\n失败的概率 $P(\\text{failure})$ 是有利结果数与所有可能结果总数的比率：\n$$\nP(\\text{failure}) = \\frac{\\binom{N-1}{m}}{\\binom{N}{m}}\n$$\n我们展开二项式系数：\n$$\n\\binom{N-1}{m} = \\frac{(N-1)!}{m!(N-1-m)!}\n$$\n$$\n\\binom{N}{m} = \\frac{N!}{m!(N-m)!}\n$$\n因此，该比率为：\n$$\nP(\\text{failure}) = \\frac{\\frac{(N-1)!}{m!(N-1-m)!}}{\\frac{N!}{m!(N-m)!}} = \\frac{(N-1)!}{N!} \\cdot \\frac{(N-m)!}{(N-1-m)!}\n$$\n我们简化这两个阶乘比：\n$$\n\\frac{(N-1)!}{N!} = \\frac{(N-1)!}{N \\cdot (N-1)!} = \\frac{1}{N}\n$$\n$$\n\\frac{(N-m)!}{(N-1-m)!} = \\frac{(N-m) \\cdot (N-m-1)!}{(N-m-1)!} = N-m\n$$\n将这两个结果相乘得到概率：\n$$\nP(\\text{failure}) = \\frac{1}{N} \\cdot (N-m) = \\frac{N-m}{N} = 1 - \\frac{m}{N}\n$$\n最后，我们将定义 $N = \\prod_{\\ell=1}^{d} n_{\\ell}$ 代入此表达式，以得到用给定问题参数表示的最终答案。\n$$\nP(\\text{failure}) = 1 - \\frac{m}{\\prod_{\\ell=1}^{d} n_{\\ell}}\n$$\n这个表达式表示一个大小为 $m$ 的随机样本未能观测到高度相干的秩为1张量 $X$ 的唯一非零元素的确切概率，从而导致一个模糊的恢复问题。",
            "answer": "$$\n\\boxed{1 - \\frac{m}{\\prod_{\\ell=1}^{d} n_{\\ell}}}\n$$"
        },
        {
            "introduction": "从理论概念转向算法实现，本练习关注张量鲁棒主成分分析（TRPCA），这是一个将数据分解为低秩和稀疏两部分的核心模型。你将使用交替方向乘子法（ADMM）——一种解决此类优化问题的强大框架——来推导其核心的近端更新步骤。通过这个过程，你将掌握如何处理张量核范数（TNN）并将其与傅里叶域中的奇异值阈值化联系起来。",
            "id": "3485361",
            "problem": "考虑张量鲁棒主成分分析 (TRPCA) 模型，它将一个给定的数据张量 $\\mathcal{M} \\in \\mathbb{R}^{n_1 \\times n_2 \\times n_3}$ 分解为 $\\mathcal{M} = \\mathcal{L} + \\mathcal{S}$，其中 $\\mathcal{L}$ 是一个低秩张量，$\\mathcal{S}$ 是一个稀疏张量。将 TRPCA 问题定义为\n$$\n\\min_{\\mathcal{L},\\mathcal{S}} \\ \\|\\mathcal{L}\\|_{\\mathrm{TNN}} + \\lambda \\|\\mathcal{S}\\|_{1} \\quad \\text{subject to} \\quad \\mathcal{M} = \\mathcal{L} + \\mathcal{S},\n$$\n其中张量核范数 (TNN) 定义为沿第三模进行离散傅里叶变换 (DFT) 后各正面切片的矩阵核范数的平均值：\n$$\n\\|\\mathcal{L}\\|_{\\mathrm{TNN}} \\triangleq \\frac{1}{n_3}\\sum_{k=1}^{n_3} \\|\\overline{\\mathcal{L}}^{(k)}\\|_{*}, \\quad \\overline{\\mathcal{L}} = \\mathrm{DFT}_3(\\mathcal{L}),\n$$\n而 $\\|\\mathcal{S}\\|_{1}$ 表示逐元素 $\\ell_1$ 范数。使用交替方向乘子法 (ADMM)，考虑带有罚参数 $\\mu > 0$ 的增广拉格朗日量，并推导出关于 $\\mathcal{L}$ 和 $\\mathcal{S}$ 的邻近子问题，形式如下\n$$\n\\mathcal{L}^{+} = \\arg\\min_{\\mathcal{L}} \\ \\|\\mathcal{L}\\|_{\\mathrm{TNN}} + \\frac{\\mu}{2}\\|\\mathcal{L} - \\mathcal{Q}\\|_{F}^{2},\n\\quad\n\\mathcal{S}^{+} = \\arg\\min_{\\mathcal{S}} \\ \\lambda\\|\\mathcal{S}\\|_{1} + \\frac{\\mu}{2}\\|\\mathcal{S} - \\mathcal{P}\\|_{F}^{2},\n$$\n其中合适的张量 $\\mathcal{Q}$ 和 $\\mathcal{P}$ 由当前的迭代值和乘子确定。仅从上述定义以及矩阵核范数邻近算子的定义出发，推导：\n- $\\mathcal{L}$ 的更新步骤，即在 DFT 域中对正面切片 $\\overline{\\mathcal{Q}}^{(k)}$ 应用傅里叶切片奇异值阈值 (SVT) 操作，然后沿第三模进行逆 DFT。\n- $\\mathcal{S}$ 的更新步骤，即逐元素的软阈值操作。\n\n使用以下关于长度为 $n_3$ 的第三模的离散傅里叶变换 (DFT) 约定：\n$$\n\\overline{\\mathcal{X}}(:,:,k) = \\sum_{t=1}^{n_3} \\mathcal{X}(:,:,t)\\exp\\!\\Big(-\\mathrm{i} 2\\pi \\frac{(k-1)(t-1)}{n_3}\\Big), \\quad\n\\mathcal{X}(:,:,t) = \\frac{1}{n_3}\\sum_{k=1}^{n_3} \\overline{\\mathcal{X}}(:,:,k)\\exp\\!\\Big(\\mathrm{i} 2\\pi \\frac{(k-1)(t-1)}{n_3}\\Big).\n$$\n此处 $\\mathrm{i}$ 表示虚数单位。\n\n然后，将您推导的 $\\mathcal{L}$-更新步骤实例化到以下大小为 $2 \\times 2 \\times 2$ 且 $\\mu = 1$ 的具体输入上：\n- 张量 $\\mathcal{Q}$ 的正面切片为\n$$\n\\mathcal{Q}(:,:,1) = \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix}, \\qquad\n\\mathcal{Q}(:,:,2) = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix}.\n$$\n计算更新后的张量 $\\mathcal{L}^{+}$ 的 $(1,1,1)$ 项。以单个数字形式提供您的最终答案。无需四舍五入。",
            "solution": "本任务要求推导张量鲁棒主成分分析 (TRPCA) 模型的邻近子问题，并进行一个具体的数值计算。我们将首先推导低秩张量 $\\mathcal{L}$ 和稀疏张量 $\\mathcal{S}$ 的更新步骤，然后使用推导出的 $\\mathcal{L}$ 更新规则来计算一个特定的元素。\n\n### 第1部分：$\\mathcal{L}$-更新的推导\n\n$\\mathcal{L}$ 的子问题由下式给出：\n$$\n\\mathcal{L}^{+} = \\arg\\min_{\\mathcal{L}} \\ \\|\\mathcal{L}\\|_{\\mathrm{TNN}} + \\frac{\\mu}{2}\\|\\mathcal{L} - \\mathcal{Q}\\|_{F}^{2}\n$$\n张量核范数 (TNN) 在傅里叶域中定义：$\\|\\mathcal{L}\\|_{\\mathrm{TNN}} \\triangleq \\frac{1}{n_3}\\sum_{k=1}^{n_3} \\|\\overline{\\mathcal{L}}^{(k)}\\|_{*}$，其中 $\\overline{\\mathcal{L}} = \\mathrm{DFT}_3(\\mathcal{L})$。为了解决这个问题，我们也必须在傅里叶域中表示弗罗贝尼乌斯范数项。\n\n根据所提供的定义，沿第三模的离散傅里叶变换 (DFT) 及其逆变换为：\n$$\n\\overline{\\mathcal{X}}(i,j,k) = \\sum_{t=1}^{n_3} \\mathcal{X}(i,j,t)\\exp\\left(-\\mathrm{i} 2\\pi \\frac{(k-1)(t-1)}{n_3}\\right)\n$$\n$$\n\\mathcal{X}(i,j,t) = \\frac{1}{n_3}\\sum_{k=1}^{n_3} \\overline{\\mathcal{X}}(i,j,k)\\exp\\left(\\mathrm{i} 2\\pi \\frac{(k-1)(t-1)}{n_3}\\right)\n$$\n对于任何固定的索引对 $(i,j)$，向量 $(\\overline{\\mathcal{X}}(i,j,1), \\dots, \\overline{\\mathcal{X}}(i,j,n_3))$ 是向量 $(\\mathcal{X}(i,j,1), \\dots, \\mathcal{X}(i,j,n_3))$ 的 DFT。对于此 DFT 约定，帕塞瓦尔定理表明 $\\sum_{k=1}^{n_3} |\\overline{\\mathcal{X}}(i,j,k)|^2 = n_3 \\sum_{t=1}^{n_3} |\\mathcal{X}(i,j,t)|^2$。\n\n对所有索引 $i$ 和 $j$求和，得到张量的弗罗贝尼乌斯范数与其傅里叶变换之间的关系：\n$$\n\\|\\overline{\\mathcal{X}}\\|_{F}^{2} = \\sum_{i=1}^{n_1}\\sum_{j=1}^{n_2}\\sum_{k=1}^{n_3} |\\overline{\\mathcal{X}}(i,j,k)|^2 = \\sum_{i=1}^{n_1}\\sum_{j=1}^{n_2} n_3 \\sum_{t=1}^{n_3} |\\mathcal{X}(i,j,t)|^2 = n_3 \\|\\mathcal{X}\\|_{F}^{2}\n$$\n因此，我们有 $\\|\\mathcal{L} - \\mathcal{Q}\\|_{F}^{2} = \\frac{1}{n_3}\\|\\overline{\\mathcal{L}} - \\overline{\\mathcal{Q}}\\|_{F}^{2}$。将此式和 TNN 定义代入目标函数：\n$$\nJ(\\mathcal{L}) = \\frac{1}{n_3}\\sum_{k=1}^{n_3} \\|\\overline{\\mathcal{L}}^{(k)}\\|_{*} + \\frac{\\mu}{2} \\left(\\frac{1}{n_3}\\|\\overline{\\mathcal{L}} - \\overline{\\mathcal{Q}}\\|_{F}^{2}\\right)\n$$\n张量 $\\overline{\\mathcal{L}} - \\overline{\\mathcal{Q}}$ 的弗罗贝尼乌斯范数可以写成其正面切片的弗罗贝尼乌斯范数平方和：$\\|\\overline{\\mathcal{L}} - \\overline{\\mathcal{Q}}\\|_{F}^{2} = \\sum_{k=1}^{n_3} \\|\\overline{\\mathcal{L}}^{(k)} - \\overline{\\mathcal{Q}}^{(k)}\\|_{F}^{2}$。目标函数变为：\n$$\nJ(\\mathcal{L}) = \\frac{1}{n_3} \\sum_{k=1}^{n_3} \\left( \\|\\overline{\\mathcal{L}}^{(k)}\\|_{*} + \\frac{\\mu}{2} \\|\\overline{\\mathcal{L}}^{(k)} - \\overline{\\mathcal{Q}}^{(k)}\\|_{F}^{2} \\right)\n$$\n在 $\\overline{\\mathcal{L}}$ 是实数张量的 DFT 这一约束下，对 $\\mathcal{L}$ 最小化此目标函数等价于对其傅里叶变换 $\\overline{\\mathcal{L}}$ 进行最小化。然而，该问题可以解耦为 $n_3$ 个独立的子问题，每个子问题对应一个正面切片 $\\overline{\\mathcal{L}}^{(k)}$：\n$$\n\\overline{\\mathcal{L}}^{+(k)} = \\arg\\min_{\\mathbf{X} \\in \\mathbb{C}^{n_1 \\times n_2}} \\|\\mathbf{X}\\|_{*} + \\frac{\\mu}{2} \\|\\mathbf{X} - \\overline{\\mathcal{Q}}^{(k)}\\|_{F}^{2}\n$$\n这是应用于矩阵 $\\overline{\\mathcal{Q}}^{(k)}$ 的矩阵核范数邻近算子的标准定义。其解由奇异值阈值 (SVT) 算子给出，记为 $\\mathcal{D}_{\\tau}(\\cdot)$，阈值为 $\\tau = 1/\\mu$。具体来说，如果 $\\overline{\\mathcal{Q}}^{(k)} = \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^*$ 是奇异值分解，那么 $\\overline{\\mathcal{L}}^{+(k)} = \\mathbf{U}\\mathcal{S}_{1/\\mu}(\\mathbf{\\Sigma})\\mathbf{V}^*$，其中 $\\mathcal{S}_{\\tau}(\\cdot)$ 是应用于 $\\mathbf{\\Sigma}$ 对角线元素（奇异值）的逐元素软阈值算子。\n\n在傅里叶域中对 $k=1, \\dots, n_3$ 求解每个切片 $\\overline{\\mathcal{L}}^{+(k)}$ 后，我们将它们组装成张量 $\\overline{\\mathcal{L}}^{+}$。最终更新的张量 $\\mathcal{L}^{+}$ 是通过沿第三模应用逆 DFT 获得的：\n$$\n\\mathcal{L}^{+} = \\mathrm{IDFT}_3(\\overline{\\mathcal{L}}^{+})\n$$\n这证实了 $\\mathcal{L}$-更新是一个傅里叶切片 SVT 步骤。\n\n### 第2部分：$\\mathcal{S}$-更新的推导\n\n$\\mathcal{S}$ 的子问题由下式给出：\n$$\n\\mathcal{S}^{+} = \\arg\\min_{\\mathcal{S}} \\lambda\\|\\mathcal{S}\\|_{1} + \\frac{\\mu}{2}\\|\\mathcal{S} - \\mathcal{P}\\|_{F}^{2}\n$$\n根据定义，$\\ell_1$ 范数和弗罗贝尼乌斯范数是逐元素可分的：\n$$\n\\lambda\\|\\mathcal{S}\\|_{1} + \\frac{\\mu}{2}\\|\\mathcal{S} - \\mathcal{P}\\|_{F}^{2} = \\lambda \\sum_{i,j,k} |\\mathcal{S}_{ijk}| + \\frac{\\mu}{2} \\sum_{i,j,k} (\\mathcal{S}_{ijk} - \\mathcal{P}_{ijk})^2\n$$\n总目标函数是各自独立的函数的总和，每个函数只涉及一个元素 $\\mathcal{S}_{ijk}$。因此，我们可以分别最小化每一项：\n$$\n\\mathcal{S}^{+}_{ijk} = \\arg\\min_{s \\in \\mathbb{R}} \\lambda|s| + \\frac{\\mu}{2}(s - \\mathcal{P}_{ijk})^2\n$$\n这是 $\\ell_1$ 范数（由 $\\lambda$ 缩放）的邻近算子。其解由阈值为 $\\tau = \\lambda/\\mu$ 的软阈值（或收缩）算子给出：\n$$\n\\mathcal{S}^{+}_{ijk} = \\text{sign}(\\mathcal{P}_{ijk}) \\max( |\\mathcal{P}_{ijk}| - \\lambda/\\mu, 0 )\n$$\n此操作应用于张量 $\\mathcal{P}$ 的每个元素。因此，$\\mathcal{S}$-更新是对张量 $\\mathcal{P}$ 的逐元素软阈值操作。\n\n### 第3部分：$\\mathcal{L}^{+}$的具体计算\n\n我们给定一个具体实例，其中 $n_1=2$, $n_2=2$, $n_3=2, \\mu=1$，以及具有以下正面切片的张量 $\\mathcal{Q}$：\n$$\n\\mathcal{Q}^{(1)} = \\mathcal{Q}(:,:,1) = \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix}, \\qquad \\mathcal{Q}^{(2)} = \\mathcal{Q}(:,:,2) = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix}\n$$\n我们遵循为 $\\mathcal{L}$-更新推导出的过程。\n\n**第1步：沿第三模对 $\\mathcal{Q}$ 进行 DFT**\n对于 $n_3=2$，正面切片的 DFT 公式为：\n$\\overline{\\mathcal{Q}}^{(1)} = \\mathcal{Q}^{(1)} + \\mathcal{Q}^{(2)}$\n$\\overline{\\mathcal{Q}}^{(2)} = \\mathcal{Q}^{(1)} - \\mathcal{Q}^{(2)}$\n代入给定的矩阵：\n$$\n\\overline{\\mathcal{Q}}^{(1)} = \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix} = \\begin{pmatrix} 4  0 \\\\ 0  0 \\end{pmatrix}\n$$\n$$\n\\overline{\\mathcal{Q}}^{(2)} = \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix} - \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix} = \\begin{pmatrix} 2  0 \\\\ 0  2 \\end{pmatrix}\n$$\n\n**第2步：对傅里叶切片进行奇异值阈值处理**\n阈值为 $\\tau = 1/\\mu = 1/1 = 1$。\n\n对于 $\\overline{\\mathcal{Q}}^{(1)} = \\begin{pmatrix} 4  0 \\\\ 0  0 \\end{pmatrix}$：\n奇异值为 $\\sigma_1=4$ 和 $\\sigma_2=0$。\n应用软阈值处理，$\\tau=1$：\n$\\hat{\\sigma}_1 = \\max(4-1, 0) = 3$\n$\\hat{\\sigma}_2 = \\max(0-1, 0) = 0$\n更新后的切片为 $\\overline{\\mathcal{L}}^{+(1)} = \\begin{pmatrix} 3  0 \\\\ 0  0 \\end{pmatrix}$。\n\n对于 $\\overline{\\mathcal{Q}}^{(2)} = \\begin{pmatrix} 2  0 \\\\ 0  2 \\end{pmatrix}$：\n奇异值为 $\\sigma_1=2$ 和 $\\sigma_2=2$。\n应用软阈值处理，$\\tau=1$：\n$\\hat{\\sigma}_1 = \\max(2-1, 0) = 1$\n$\\hat{\\sigma}_2 = \\max(2-1, 0) = 1$\n更新后的切片为 $\\overline{\\mathcal{L}}^{+(2)} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$。\n\n**第3步：对 $\\overline{\\mathcal{L}}^{+}$ 进行逆 DFT**\n我们需要计算 $\\mathcal{L}^{+}$ 的 $(1,1,1)$ 项，它是第一个正面切片 $\\mathcal{L}^{+(1)}$ 中的一个元素。对于 $n_3=2$，第一个切片（$t=1$）的逆 DFT 公式为：\n$$\n\\mathcal{L}^{+(1)} = \\frac{1}{2}\\left(\\overline{\\mathcal{L}}^{+(1)} + \\overline{\\mathcal{L}}^{+(2)}\\right)\n$$\n代入第2步中的矩阵：\n$$\n\\mathcal{L}^{+(1)} = \\frac{1}{2}\\left( \\begin{pmatrix} 3  0 \\\\ 0  0 \\end{pmatrix} + \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} \\right) = \\frac{1}{2} \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 2  0 \\\\ 0  \\frac{1}{2} \\end{pmatrix}\n$$\n\n**第4步：提取所需项**\n$\\mathcal{L}^{+}$ 的 $(1,1,1)$ 项，记为 $\\mathcal{L}^{+}(1,1,1)$，是第一个正面切片 $\\mathcal{L}^{+(1)}$ 中第一行第一列的元素。\n根据上面的结果，$\\mathcal{L}^{+}(1,1,1) = 2$。",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "理论的价值最终需要通过实践来检验。本练习要求你通过编码实验，来实证探究张量模型相对于传统矩阵方法的优势。你将设计特定的“对抗性”采样模式，这些模式会破坏矩阵展开后的非相干性，但仍然保留了足够的多模态信息，从而清晰地展示在何种情况下，基于张量的方法能够成功恢复信号，而基于矩阵的方法却会失败。",
            "id": "3485347",
            "problem": "您的任务是凭经验证明，在低多线性秩张量上精心设计的采样掩码可以在特定展开中违反矩阵非相干性，同时仍为基于张量的恢复提供足够的多模覆盖，从而导致矩阵补全方法失败而张量补全模型成功。\n\n您必须从基本概念开始构建推导过程，如下所示：\n\n- 从三阶张量、到观测条目的投影以及通过核范数的凸松弛的定义开始。设一个三阶张量表示为 $X \\in \\mathbb{R}^{n_1 \\times n_2 \\times n_3}$。设观测掩码为 $\\Omega \\subseteq \\{1,\\dots,n_1\\} \\times \\{1,\\dots,n_2\\} \\times \\{1,\\dots,n_3\\}$。设投影算子 $P_{\\Omega}$ 逐元素作用，即若 $(i,j,k) \\in \\Omega$，则 $(P_{\\Omega}(X))_{i,j,k} = X_{i,j,k}$，否则为 $0$。\n\n- 使用广泛接受的凸松弛：\n  1. 对于固定展开上的矩阵补全，最小化矩阵核范数，受限于观测条目：给定 $X$ 的一个展开 $M \\in \\mathbb{R}^{n \\times m}$，求解 $\\min_{Z} \\frac{1}{2}\\|P_{\\Omega}(Z - M)\\|_F^2 + \\lambda \\|Z\\|_*$，其中 $\\|\\cdot\\|_*$ 是矩阵核范数，$\\lambda > 0$ 是一个正则化参数。\n  2. 对于张量补全，使用跨模态展开的核范数之和：$\\min_{X} \\alpha_1 \\|X_{(1)}\\|_* + \\alpha_2 \\|X_{(2)}\\|_* + \\alpha_3 \\|X_{(3)}\\|_*$，约束条件为 $P_{\\Omega}(X) = P_{\\Omega}(X^{\\star})$，其中 $X^{\\star}$ 是基准张量，$X_{(i)}$ 表示模-$i$ 展开。\n\n- 假设基准张量为一个低多线性秩模型（Tucker 模型）：$X^{\\star} = \\mathcal{G} \\times_1 U_1 \\times_2 U_2 \\times_3 U_3$，其中 $\\mathcal{G} \\in \\mathbb{R}^{r_1 \\times r_2 \\times r_3}$ 是核心张量，$U_i \\in \\mathbb{R}^{n_i \\times r_i}$ 具有标准正交列，$\\times_i$ 表示模-$i$ 张量-矩阵乘积。这是一个在张量补全和稀疏优化中用于低秩结构的经过充分检验的模型。\n\n您的程序必须执行以下操作：\n\n1. 通过采样标准正交因子矩阵 $U_1,U_2,U_3$ 和一个小的随机核心 $\\mathcal{G}$（全部使用固定的随机种子），构建一个确定性的合成基准张量 $X^{\\star} \\in \\mathbb{R}^{n_1 \\times n_2 \\times n_3}$，其中 $n_1 = 15, n_2 = 15, n_3 = 10$，且具有低多线性秩 $(r_1,r_2,r_3) = (3,3,3)$。不添加噪声。\n\n2. 设计四个采样掩码 $\\Omega$ 组成一个测试套件，确保科学真实性和清晰的覆盖属性：\n   - 情况 A（对抗性多模覆盖）：选择一个小集合 $S_1 \\subset \\{1,\\dots,n_1\\}$，其中 $|S_1|=3$。对于 $i \\in S_1$，观测其模-1 纤维上的所有条目（即，对于所有的 $j, k$ 的 $(i,j,k)$）。对于 $i \\notin S_1$，为每个 $i$ 确定性地选择一个 $j = f(i)$，并包含所有 $k$ 的 $(i,j,k)$，从而观测其上恰好一个模-3 纤维上的所有条目。此外，确定性地撒上少量单个条目，以确保每个模-2 和模-3 索引在多个 $i$ 上都被覆盖。此掩码在模-1 展开 $X^{\\star}_{(1)}$ 的行上具有高度不均匀的覆盖（违反矩阵非相干性），但为张量恢复提供了跨模态的覆盖。\n   - 情况 B（近乎均匀采样）：使用固定的种子，以固定概率 $p = 0.2$ 独立地包含每个条目，近似于均匀采样，并提供一个两种方法都应表现良好的基线。\n   - 情况 C（极端对抗性）：设 $S_1 = \\{i_0\\}$，只有一个完全观测的模-1 纤维，并且在其他地方只有极小固定比例的剩余单个观测值，使得 $X^{\\star}_{(1)}$ 的许多行几乎完全未被观测。这会因信息不足而导致两种方法都失败。\n   - 情况 D（温和的对抗性多模覆盖）：设 $|S_1|=5$，对于每个 $i \\notin S_1$，通过选择两个确定性索引 $j_1(i), j_2(i)$ 并包含所有 $k$ 和 $\\ell \\in \\{1,2\\}$ 的 $(i,j_{\\ell}(i),k)$，来观测两个完整的模-3 纤维。这仍然违反了模-1 展开的矩阵非相干性，但改善了跨模态覆盖，使得张量方法可以成功。\n\n3. 实现两种恢复算法：\n   - 在模-1 展开上使用近端梯度算法（也称为 Soft-Impute）进行矩阵补全，该算法采用奇异值阈值化。使用目标函数 $\\min_{Z} \\frac{1}{2}\\|P_{\\Omega}(Z - M)\\|_F^2 + \\lambda \\|Z\\|_*$，其中 $M = X^{\\star}_{(1)}$。使用固定的 $\\lambda = 1.0$ 和步长 $t = 1$，从 $Z_0 = 0$ 开始，迭代直至达到 $200$ 次迭代或相对变化低于 $10^{-6}$。收敛后，将解重构成一个张量 $\\widehat{X}^{\\text{mat}}$。\n   - 使用交替方向乘子法（ADMM）进行张量补全，该方法用于各模态核范数之和，通常称为高精度低秩张量补全（HaLRTC）。构建问题\n     $$\\min_{X} \\sum_{i=1}^{3} \\alpha_i \\|X_{(i)}\\|_* \\quad \\text{约束条件为 } P_{\\Omega}(X) = P_{\\Omega}(X^{\\star}),$$\n     其中 $\\alpha_1 = \\alpha_2 = \\alpha_3 = \\frac{1}{3}$。为解耦核范数引入辅助变量 $Y_i$，并为 $i = 1,2,3$ 引入对偶变量 $\\Lambda_i$。使用 ADMM 迭代，参数为 $\\beta = 1.0$，奇异值阈值为 $\\tau_i = \\alpha_i / \\beta$，迭代次数为 $200$ 次或相对变化低于 $10^{-6}$。确保 $X$ 更新通过投影 $P_{\\Omega}(X) = P_{\\Omega}(X^{\\star})$ 精确地执行观测约束。\n\n4. 对于每个测试用例，计算两种方法在完整张量上的相对 Frobenius 范数重构误差：\n   $$\\text{err}_{\\text{mat}} = \\frac{\\|\\widehat{X}^{\\text{mat}} - X^{\\star}\\|_F}{\\|X^{\\star}\\|_F}, \\quad \\text{err}_{\\text{ten}} = \\frac{\\|\\widehat{X}^{\\text{ten}} - X^{\\star}\\|_F}{\\|X^{\\star}\\|_F}.$$\n\n5. 对于每种情况，根据以下决策规则输出一个表示为整数 $1$ 或 $0$ 的布尔值：\n   - 如果 $\\text{err}_{\\text{mat}} > 0.08$ 且 $\\text{err}_{\\text{ten}}  0.04$（矩阵补全失败而张量补全成功），则输出 $1$。\n   - 否则输出 $0$。\n\n您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，“[1,0,0,1]”），按顺序对应于情况 A、B、C 和 D。\n\n不涉及物理单位。如果存在任何角度，应以弧度为单位，但此处未使用。\n\n测试套件规范：\n- 张量维度：$(n_1,n_2,n_3) = (15,15,10)$。\n- 多线性秩：$(r_1,r_2,r_3) = (3,3,3)$。\n- 随机种子：所有随机抽样均使用 $42$。\n- 矩阵补全参数：$\\lambda = 1.0$，步长 $t=1$，最大迭代次数 $200$，容差 $10^{-6}$。\n- 张量补全参数：$\\alpha_1=\\alpha_2=\\alpha_3 = 1/3$，$\\beta=1.0$，最大迭代次数 $200$，容差 $10^{-6}$。\n- 掩码：\n  - 情况 A：$|S_1|=3$ 个完全观测的模-1 纤维；对于 $i \\notin S_1$，每个 $i$ 有一个由 $j = 1 + ((i-1) \\bmod n_2)$ 给出的完整模-3 纤维；外加对于所有 $i$ 在位置 $(i, 1 + ((i-1) \\bmod n_2), 1 + ((i-1) \\bmod n_3))$ 的确定性单个条目包含。\n  - 情况 B：使用种子 $42$ 进行独立伯努利采样，概率 $p=0.2$。\n  - 情况 C：$|S_1|=1$ 个完全观测的模-1 纤维；外加对于所有 $i$ 在位置 $(i, 1 + ((i-1) \\bmod n_2), 1 + ((2(i-1)) \\bmod n_3))$ 的单个条目包含。\n  - 情况 D：$|S_1|=5$ 个完全观测的模-1 纤维；对于 $i \\notin S_1$，每个 $i$ 有两个由 $j_1 = 1 + ((i-1) \\bmod n_2)$ 和 $j_2 = 1 + ((i-1)\\cdot 2 \\bmod n_2)$ 给出的完整模-3 纤维。\n\n您的实现必须严格遵守最终输出格式，不得包含任何额外文本，并且在给定固定种子和参数的情况下必须是完全确定性的。",
            "solution": "该问题要求通过经验性演示，比较矩阵补全与张量补全在从有限条目集合中恢复低秩张量方面的功效。待检验的核心假设是，一个精心构造的采样掩码可以违反矩阵补全在张量展开上成功所必需的非相干性假设，同时仍能为基于张量的方法提供足够的多模态信息以实现精确恢复。\n\n首先，我们建立数学框架。一个三阶张量是一个三维数组，表示为 $X \\in \\mathbb{R}^{n_1 \\times n_2 \\times n_3}$。我们假设底层的基准张量 $X^{\\star}$ 具有低秩结构，特别是低多线性秩 $(r_1, r_2, r_3)$。这通过 Tucker 分解来形式化：\n$$\nX^{\\star} = \\mathcal{G} \\times_1 U_1 \\times_2 U_2 \\times_3 U_3\n$$\n其中 $\\mathcal{G} \\in \\mathbb{R}^{r_1 \\times r_2 \\times r_3}$ 是核心张量，$U_i \\in \\mathbb{R}^{n_i \\times r_i}$ 是具有标准正交列的因子矩阵，$\\times_i$ 是模-$i$ 张量-矩阵乘积。一个张量 $X$ 与一个矩阵 $U \\in \\mathbb{R}^{m \\times n_i}$ 的模-$i$ 乘积是一个大小为 $n_1 \\times \\dots \\times n_{i-1} \\times m \\times n_{i+1} \\times \\dots \\times n_3$ 的张量 $Y = X \\times_i U$，其条目为 $Y_{j_1 \\dots j_{i-1} k j_{i+1} \\dots j_3} = \\sum_{j_i=1}^{n_i} X_{j_1 \\dots j_i \\dots j_3} U_{k, j_i}$。\n\n恢复是从一个由掩码 $\\Omega \\subseteq \\{1, \\dots, n_1\\} \\times \\{1, \\dots, n_2\\} \\times \\{1, \\dots, n_3\\}$ 指定的条目子集中进行的。观测算子 $P_{\\Omega}$ 是一个逐元素定义的投影，即若 $(i,j,k) \\in \\Omega$，则 $(P_{\\Omega}(X))_{i,j,k} = X_{i,j,k}$，否则为 $0$。\n\n该问题比较了两种恢复策略。\n\n第一种策略，矩阵补全，通过将张量展开成一个大矩阵来处理它。$X$ 的模-1 展开，记作 $X_{(1)}$，将张量重塑为一个大小为 $n_1 \\times (n_2 n_3)$ 的矩阵。恢复问题随后被表述为寻找一个低秩矩阵 $Z$，它能逼近展开后的基准矩阵 $M = X^{\\star}_{(1)}$。优化问题是一个正则化的最小二乘目标：\n$$\n\\min_{Z \\in \\mathbb{R}^{n_1 \\times (n_2 n_3)}} \\frac{1}{2}\\|P_{\\Omega}(Z - M)\\|_F^2 + \\lambda \\|Z\\|_*\n$$\n其中 $\\|\\cdot\\|_*$ 是核范数（奇异值之和），它是矩阵秩的一个凸代理，$\\lambda  0$ 是一个正则化参数。投影算子 $P_{\\Omega}$ 根据原始张量掩码 $\\Omega$ 应用于矩阵 $Z$。该问题使用近端梯度算法解决，也称为 Soft-Impute。步长 $t=1$ 的迭代更新为：\n$$\nZ_{k+1} = S_{\\lambda}( P_{\\Omega}(M) + P_{\\Omega^c}(Z_k) )\n$$\n其中 $S_{\\lambda}(Y) = U \\text{diag}(\\max(\\sigma_i - \\lambda, 0))V^T$ 是对 $Y=U\\Sigma V^T$ 的奇异值阈值化算子，$P_{\\Omega^c}$ 投影到未观测的条目上。矩阵补全的成功通常依赖于采样掩码足够均匀，这一性质被称为非相干性。\n\n第二种策略，张量补全，直接利用了多模态结构。“核范数之和”（SNN）模型求解：\n$$\n\\min_{X \\in \\mathbb{R}^{n_1 \\times n_2 \\times n_3}} \\sum_{i=1}^{3} \\alpha_i \\|X_{(i)}\\|_* \\quad \\text{约束条件为 } P_{\\Omega}(X) = P_{\\Omega}(X^{\\star})\n$$\n其中 $X_{(i)}$ 是张量 $X$ 的模-$i$ 展开，$\\alpha_i$ 是正常数权重。该模型同时促进所有模态的低秩性。我们使用交替方向乘子法（ADMM）来解决这个约束优化问题。我们引入辅助变量 $Y_1, Y_2, Y_3$ 和对偶变量 $\\Lambda_1, \\Lambda_2, \\Lambda_3$。ADMM 迭代过程如下：\n1.  **$Y_i$-更新**：对每个模态 $i=1,2,3$，通过解决一个近端问题来更新辅助变量，这相当于对一个展开后的张量进行奇异值阈值化：\n    $$ Y_{i, k+1} = \\text{fold}_i\\left( S_{\\alpha_i/\\beta}\\left( \\text{unfold}_i(X_k + \\Lambda_{i,k}/\\beta) \\right) \\right) $$\n2.  **$X$-更新**：通过平均辅助变量并强制执行数据保真度约束来更新主张量变量：\n    $$ X_{k+1} = P_{\\Omega}(X^{\\star}) + P_{\\Omega^c}\\left( \\frac{1}{3} \\sum_{i=1}^3 (Y_{i,k+1} - \\Lambda_{i,k}/\\beta) \\right) $$\n3.  **$\\Lambda_i$-更新**：更新对偶变量（缩放的拉格朗日乘子）：\n    $$ \\Lambda_{i,k+1} = \\Lambda_{i,k} + \\beta (X_{k+1} - Y_{i,k+1}) $$\n这里，$\\beta  0$ 是 ADMM 惩罚参数。即使采样模式对于某一模态是高度不均匀的，只要它在其他模态上提供了足够的覆盖，该方法也能成功。\n\n实验构建如下：\n一个具有多线性秩 $(3,3,3)$ 的基准张量 $X^{\\star} \\in \\mathbb{R}^{15 \\times 15 \\times 10}$ 被确定性地生成。创建四个采样掩码以测试不同的恢复场景：\n-   **情况 A（对抗性多模）**：采样三个完整的模-1 纤维，并为剩余的模-1 索引采样稀疏的、结构化的纤维。这种设计严重违反了模-1 矩阵展开的非相干性条件，但保持了在模 2 和 3 上的广泛覆盖。\n-   **情况 B（近乎均匀）**：标准随机采样，其中每个条目以概率 $p=0.2$ 被观测。预计两种方法都会表现良好。\n-   **情况 C（极端对抗性）**：仅采样一个完整的模-1 纤维和极少数其他条目。总信息量不足以让任何一种方法成功。\n-   **情况 D（温和的对抗性多模）**：与情况 A 类似，但具有更多完全观测的模-1 纤维，从而加强了多模覆盖。\n\n对于每种情况，都运行两种恢复算法。重构质量由相对 Frobenius 范数误差 $\\text{err} = \\|\\widehat{X} - X^{\\star}\\|_F / \\|X^{\\star}\\|_F$ 来衡量。如果 $\\text{err}_{\\text{mat}}  0.08$ 且 $\\text{err}_{\\text{ten}}  0.04$，则宣告张量方法成功而矩阵方法失败，这证明了在结构化非均匀采样下，基于张量的方法的优越性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef unfold(tensor, mode):\n    \"\"\"Unfolds a tensor into a matrix.\"\"\"\n    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1))\n\ndef fold(matrix, mode, shape):\n    \"\"\"Folds a matrix back into a tensor.\"\"\"\n    full_shape = list(shape)\n    mode_dim = full_shape.pop(mode)\n    full_shape.insert(0, mode_dim)\n    return np.moveaxis(np.reshape(matrix, full_shape), 0, mode)\n\ndef ttm(tensor, matrix, mode):\n    \"\"\"Tensor-times-matrix product (n-mode product).\"\"\"\n    shape = list(tensor.shape)\n    shape[mode] = matrix.shape[0]\n    unfolded_tensor = unfold(tensor, mode)\n    res = matrix @ unfolded_tensor\n    return fold(res, mode, tuple(shape))\n\ndef svt(matrix, tau):\n    \"\"\"Singular Value Thresholding operator.\"\"\"\n    U, s, Vh = np.linalg.svd(matrix, full_matrices=False)\n    s_thresh = np.maximum(s - tau, 0)\n    return (U * s_thresh) @ Vh\n\ndef generate_tensor(dims, ranks, seed):\n    \"\"\"Generates a low-rank tensor using Tucker decomposition.\"\"\"\n    np.random.seed(seed)\n    n1, n2, n3 = dims\n    r1, r2, r3 = ranks\n    \n    # Orthonormal factor matrices\n    U1, _ = np.linalg.qr(np.random.randn(n1, r1))\n    U2, _ = np.linalg.qr(np.random.randn(n2, r2))\n    U3, _ = np.linalg.qr(np.random.randn(n3, r3))\n    \n    # Core tensor\n    G = np.random.randn(r1, r2, r3)\n    \n    # Construct tensor\n    X = ttm(ttm(ttm(G, U1, 0), U2, 1), U3, 2)\n    return X\n\ndef generate_mask(case_id, dims, seed):\n    \"\"\"Generates a sampling mask for the given case.\"\"\"\n    n1, n2, n3 = dims\n    omega = np.zeros(dims, dtype=bool)\n\n    if case_id == 'A':\n        # Adversarial multimode coverage\n        s1_indices = [0, 1, 2] # 0-indexed\n        for i in s1_indices:\n            omega[i, :, :] = True\n        for i in range(n1):\n            if i not in s1_indices:\n                j = (i) % n2 # In Python, j=1+((i-1)%n2) is j = i % n2 for i>=1\n                omega[i, j, :] = True\n        # Add deterministic singletons to ensure cross-modal coverage\n        for i in range(n1):\n            j = (i) % n2\n            k = (i) % n3\n            omega[i, j, k] = True\n            \n    elif case_id == 'B':\n        # Near-uniform sampling\n        p = 0.2\n        np.random.seed(seed)\n        omega = np.random.rand(*dims)  p\n        \n    elif case_id == 'C':\n        # Extreme adversarial\n        omega[0, :, :] = True\n        for i in range(n1):\n            j = (i) % n2\n            k = (2 * i) % n3\n            omega[i, j, k] = True\n\n    elif case_id == 'D':\n        # Mild adversarial multimode coverage\n        s1_indices = [0, 1, 2, 3, 4]\n        for i in s1_indices:\n            omega[i, :, :] = True\n        for i in range(n1):\n            if i not in s1_indices:\n                j1 = (i) % n2\n                j2 = (i * 2) % n2\n                omega[i, j1, :] = True\n                omega[i, j2, :] = True\n    \n    return omega\n\ndef solve_matrix_completion(X_star, Omega, lambda_val, tol, max_iter):\n    \"\"\"Solves matrix completion via Soft-Impute on mode-1 unfolding.\"\"\"\n    dims = X_star.shape\n    M = unfold(X_star, 0)\n    Omega_mat = unfold(Omega, 0)\n    \n    Z = np.zeros_like(M)\n    M_obs = Omega_mat * M\n\n    for k in range(max_iter):\n        Z_prev = Z\n        \n        # Soft-Impute update\n        Y = M_obs + (1 - Omega_mat) * Z\n        Z = svt(Y, lambda_val)\n        \n        # Convergence check\n        norm_prev = np.linalg.norm(Z_prev)\n        if norm_prev > 0:\n            rel_change = np.linalg.norm(Z - Z_prev) / norm_prev\n            if rel_change  tol:\n                break\n    \n    X_hat = fold(Z, 0, dims)\n    return X_hat\n\ndef solve_tensor_completion(X_star, Omega, alphas, beta, tol, max_iter):\n    \"\"\"Solves tensor completion via ADMM for Sum-of-Nuclear-Norms (HaLRTC).\"\"\"\n    dims = X_star.shape\n    X_obs = X_star * Omega\n    \n    # Initialization\n    X = X_obs.copy()\n    Y = [np.zeros(dims) for _ in range(3)]\n    L = [np.zeros(dims) for _ in range(3)] # Lambda (dual variables)\n    \n    taus = [alpha / beta for alpha in alphas]\n\n    for k in range(max_iter):\n        X_prev = X\n        \n        # Y-updates\n        for i in range(3):\n            unfolded_val = unfold(X + L[i] / beta, i)\n            svt_res = svt(unfolded_val, taus[i])\n            Y[i] = fold(svt_res, i, dims)\n            \n        # X-update\n        X_unconstrained = np.mean([Y[i] - L[i] / beta for i in range(3)], axis=0)\n        X = X_obs + (1 - Omega) * X_unconstrained\n\n        # L-updates\n        for i in range(3):\n            L[i] += beta * (X - Y[i])\n        \n        # Convergence check\n        norm_prev = np.linalg.norm(X_prev)\n        if norm_prev > 0:\n            rel_change = np.linalg.norm(X - X_prev) / norm_prev\n            if rel_change  tol:\n                break\n                \n    return X\n\ndef solve():\n    # --- Problem Parameters ---\n    dims = (15, 15, 10)\n    ranks = (3, 3, 3)\n    seed = 42\n    \n    # Matrix completion params\n    lambda_val = 1.0\n    mat_max_iter = 200\n    mat_tol = 1e-6\n\n    # Tensor completion params\n    alphas = [1/3.0, 1/3.0, 1/3.0]\n    beta = 1.0\n    ten_max_iter = 200\n    ten_tol = 1e-6\n\n    # --- Ground Truth Generation ---\n    X_star = generate_tensor(dims, ranks, seed)\n    norm_X_star = np.linalg.norm(X_star)\n    if norm_X_star == 0: norm_X_star = 1.0 # Avoid division by zero\n\n    # --- Main Loop for Test Cases ---\n    results = []\n    case_ids = ['A', 'B', 'C', 'D']\n\n    # Convert 1-based indexing in problem to 0-based for Python code\n    # j=1+((i-1)%n2) becomes j=i%n2 for i>=1 if we assume i is 1-based.\n    # The code uses 0-based indices for loops. The logic is translated correctly.\n    # The problem description for case A is slightly ambiguous about i starting from 1 or 0.\n    # The code implements a deterministic, valid version of the mask.\n    # `j_1 = 1 + ((i-1) \\bmod n_2)` in 0-based is `j_1 = (i % n_2)`.\n    # `j_2 = 1 + ((i-1)\\cdot 2 \\bmod n_2)` in 0-based is `j_2 = (i*2) % n2`.\n    # This seems correctly implemented in the `generate_mask` function.\n\n    for case_id in case_ids:\n        # Generate mask\n        Omega = generate_mask(case_id, dims, seed)\n\n        # Run matrix completion\n        X_hat_mat = solve_matrix_completion(X_star, Omega, lambda_val, mat_tol, mat_max_iter)\n        err_mat = np.linalg.norm(X_hat_mat - X_star) / norm_X_star\n\n        # Run tensor completion\n        X_hat_ten = solve_tensor_completion(X_star, Omega, alphas, beta, ten_tol, ten_max_iter)\n        err_ten = np.linalg.norm(X_hat_ten - X_star) / norm_X_star\n\n        # Apply decision rule\n        decision = 1 if err_mat > 0.08 and err_ten  0.04 else 0\n        results.append(decision)\n    \n    # --- Final Output ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}