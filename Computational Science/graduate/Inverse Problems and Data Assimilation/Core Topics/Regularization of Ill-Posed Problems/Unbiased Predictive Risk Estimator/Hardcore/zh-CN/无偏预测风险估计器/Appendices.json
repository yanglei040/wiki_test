{
    "hands_on_practices": [
        {
            "introduction": "在处理逆问题时，我们常常会遇到来自不同传感器或通道的数据，这些数据的噪声水平可能各不相同。在这种情况下，为所有数据通道选择一个统一的正则化参数可能并非最佳策略。本练习将指导您在一个简化的双通道模型中，从第一性原理推导无偏预测风险估计器(UPRE)，并用它来比较单参数与双参数正则化方案的性能，从而直观地展示UPRE在自适应参数选择中的价值。",
            "id": "3429048",
            "problem": "考虑一个线性逆问题，其中包含对一个共同状态向量的两个独立观测通道。设正演模型为 $A = I_{2}$，正则化算子为 $L = I_{2}$。真实的无噪声数据为 $y_{\\text{true}} = x_{\\text{true}} \\in \\mathbb{R}^{2}$，观测数据为 $y = y_{\\text{true}} + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\Sigma)$，$\\Sigma$ 是对角协方差矩阵 $\\Sigma = \\operatorname{diag}(\\sigma_{1}^{2}, \\sigma_{2}^{2})$。在本问题中，设观测数据和噪声水平为\n$$\ny = \\begin{pmatrix} 3 \\\\ 2 \\end{pmatrix}, \\quad \\sigma_{1}^{2} = \\frac{1}{4}, \\quad \\sigma_{2}^{2} = 1.\n$$\n我们使用形式为 $x_{\\lambda} = \\arg\\min_{x \\in \\mathbb{R}^{2}} \\|A x - y\\|_{2}^{2} + \\lambda \\|L x\\|_{2}^{2}$ 的Tikhonov正则化估计量，此处其简化为线性收缩估计量 $x_{\\lambda} = S y$，其中 $S$ 取决于所选的正则化参数。我们将比较两种方案：\n- 单参数方案：对两个通道应用一个共同的 $\\lambda \\ge 0$，因此 $S = s I_{2}$，其中 $s = 1/(1+\\lambda)$。\n- 双参数方案：对不同通道应用独立的 $(\\lambda_{1}, \\lambda_{2}) \\ge 0$，因此 $S = \\operatorname{diag}(s_{1}, s_{2})$，其中对于 $j \\in \\{1,2\\}$，$s_{j} = 1/(1+\\lambda_{j})$。\n\n对于每种方案，考虑无噪声预测 $y_{\\text{true}}$ 的预测风险，即 $\\mathcal{R}(S) = \\mathbb{E}\\big[\\|S y - y_{\\text{true}}\\|_{2}^{2}\\big]$，其中期望是针对测量噪声计算的。无偏预测风险估计量 (Unbiased Predictive Risk Estimator, UPRE) 是数据 $y$ 和参数的任意函数，它是 $\\mathcal{R}(S)$ 的一个无偏估计量，并且可以通过关于 $S$ 最小化它来选择参数。\n\n任务：\n1. 从线性高斯数据模型出发，推导此设置下无偏预测风险估计量 (UPRE) 的显式表达式，该表达式应使用 $y$、$\\sigma_{1}^{2}$、$\\sigma_{2}^{2}$ 和 $S = \\operatorname{diag}(s_{1}, s_{2})$ 表示。您的推导必须从定义 $\\mathcal{R}(S) = \\mathbb{E}\\big[\\|S y - y_{\\text{true}}\\|_{2}^{2}\\big]$ 和高斯噪声下期望的性质开始，不得假定任何已有的 UPRE 公式。\n2. 在双参数方案下，最小化关于 $(s_{1}, s_{2})$ 的联合 UPRE，从而得到最小化联合 UPRE 的 $(\\lambda_{1}^{\\star}, \\lambda_{2}^{\\star})$。评估此方案的最小 UPRE。\n3. 在单参数方案下，最小化关于 $s$ (等价于 $\\lambda$) 的 UPRE，从而得到最小化 UPRE 的 $\\lambda^{\\star}$。评估此方案的最小 UPRE。\n4. 使用第2部分和第3部分的结果，计算精确差值\n$$\n\\Delta \\;=\\; \\big(\\min_{\\lambda \\ge 0} \\operatorname{UPRE}_{\\text{single}}(\\lambda)\\big) \\;-\\; \\big(\\min_{\\lambda_{1}, \\lambda_{2} \\ge 0} \\operatorname{UPRE}_{\\text{two}}(\\lambda_{1}, \\lambda_{2})\\big).\n$$\n请将您的最终答案表示为一个精确的有理数。这量化了通过无偏预测风险估计量 (UPRE) 在各通道上调整单个 $\\lambda$ 的方式，相对于通过最小化联合 UPRE 选择的双参数方案，在预测风险方面可能存在的次优性。",
            "solution": "该问题经评估为有效。其科学基础在于逆问题和统计估计理论，特别是关于Tikhonov正则化和无偏风险估计。该问题是适定的，为获得唯一解提供了所有必要的数据和定义。语言客观且数学上精确。因此，有必要提供完整解答。\n\n### 任务1：无偏预测风险估计量 (UPRE) 的推导\n\n预测风险定义为 $\\mathcal{R}(S) = \\mathbb{E}\\big[\\|S y - y_{\\text{true}}\\|_{2}^{2}\\big]$，其中期望是针对噪声分布 $\\varepsilon$ 计算的。数据模型为 $y = y_{\\text{true}} + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\Sigma)$。\n\n我们首先展开风险的定义，代入 $y = y_{\\text{true}} + \\varepsilon$：\n$$\n\\mathcal{R}(S) = \\mathbb{E}\\big[\\|S (y_{\\text{true}} + \\varepsilon) - y_{\\text{true}}\\|_{2}^{2}\\big] = \\mathbb{E}\\big[\\|(S - I)y_{\\text{true}} + S\\varepsilon\\|_{2}^{2}\\big]\n$$\n其中 $I$ 是单位矩阵。展开欧几里得范数的平方：\n$$\n\\mathcal{R}(S) = \\mathbb{E}\\big[ \\big( (S-I)y_{\\text{true}} \\big)^{T} \\big( (S-I)y_{\\text{true}} \\big) + 2 \\big( (S-I)y_{\\text{true}} \\big)^{T} (S\\varepsilon) + (S\\varepsilon)^{T} (S\\varepsilon) \\big]\n$$\n根据期望的线性性质，我们可以分配期望算子：\n$$\n\\mathcal{R}(S) = \\mathbb{E}\\big[ \\|(S-I)y_{\\text{true}}\\|_{2}^{2} \\big] + 2 \\mathbb{E}\\big[ y_{\\text{true}}^{T}(S-I)^{T}S\\varepsilon \\big] + \\mathbb{E}\\big[ \\|S\\varepsilon\\|_{2}^{2} \\big]\n$$\n第一项只涉及确定性量，因此 $\\mathbb{E}\\big[ \\|(S-I)y_{\\text{true}}\\|_{2}^{2} \\big] = \\|(S-I)y_{\\text{true}}\\|_{2}^{2}$。\n对于第二项，由于 $y_{\\text{true}}$ 和 $S$ 是确定性的，我们有 $2 y_{\\text{true}}^{T}(S-I)^{T}S \\, \\mathbb{E}[\\varepsilon]$。因为 $\\mathbb{E}[\\varepsilon]=0$，这个交叉项为零。\n因此，风险简化为：\n$$\n\\mathcal{R}(S) = \\|(S-I)y_{\\text{true}}\\|_{2}^{2} + \\mathbb{E}\\big[ \\|S\\varepsilon\\|_{2}^{2} \\big]\n$$\n第二项可以使用迹技巧进行评估：$\\mathbb{E}[\\|S\\varepsilon\\|_{2}^{2}] = \\mathbb{E}[\\varepsilon^{T}S^{T}S\\varepsilon] = \\mathbb{E}[\\operatorname{tr}(\\varepsilon^{T}S^{T}S\\varepsilon)] = \\mathbb{E}[\\operatorname{tr}(S^{T}S\\varepsilon\\varepsilon^{T})] = \\operatorname{tr}(S^{T}S\\mathbb{E}[\\varepsilon\\varepsilon^{T}]) = \\operatorname{tr}(S^{T}S\\Sigma)$。\n所以，真实风险为：\n$$\n\\mathcal{R}(S) = \\|(S-I)y_{\\text{true}}\\|_{2}^{2} + \\operatorname{tr}(S^{T}S\\Sigma)\n$$\n该表达式依赖于未知的 $y_{\\text{true}}$。一个无偏预测风险估计量 $\\operatorname{UPRE}(y, S)$ 必须是观测数据 $y$ 的函数，并满足 $\\mathbb{E}[\\operatorname{UPRE}(y, S)] = \\mathcal{R}(S)$。\n\n为了构造这样一个估计量，我们为未知项 $\\|(S-I)y_{\\text{true}}\\|_{2}^{2}$ 寻找一个无偏估计量。让我们考虑 $\\|(S-I)y\\|_{2}^{2}$ 这一项：\n$$\n\\|(S-I)y\\|_{2}^{2} = \\|(S-I)(y_{\\text{true}} + \\varepsilon)\\|_{2}^{2} = \\|(S-I)y_{\\text{true}} + (S-I)\\varepsilon\\|_{2}^{2}\n$$\n展开这个范数的平方可得：\n$$\n\\|(S-I)y\\|_{2}^{2} = \\|(S-I)y_{\\text{true}}\\|_{2}^{2} + 2y_{\\text{true}}^{T}(S-I)^{T}(S-I)\\varepsilon + \\|(S-I)\\varepsilon\\|_{2}^{2}\n$$\n对该表达式取期望：\n$$\n\\mathbb{E}\\big[\\|(S-I)y\\|_{2}^{2}\\big] = \\|(S-I)y_{\\text{true}}\\|_{2}^{2} + \\mathbb{E}\\big[\\|(S-I)\\varepsilon\\|_{2}^{2}\\big]\n$$\n交叉项的期望同样为零。对第二项使用迹技巧，我们得到 $\\mathbb{E}\\big[\\|(S-I)\\varepsilon\\|_{2}^{2}\\big] = \\operatorname{tr}\\big((S-I)^{T}(S-I)\\Sigma\\big)$。\n因此，我们有以下关系：\n$$\n\\|(S-I)y_{\\text{true}}\\|_{2}^{2} = \\mathbb{E}\\big[\\|(S-I)y\\|_{2}^{2}\\big] - \\operatorname{tr}\\big((S-I)^{T}(S-I)\\Sigma\\big)\n$$\n这意味着 $\\|(S-I)y\\|_{2}^{2} - \\operatorname{tr}\\big((S-I)^{T}(S-I)\\Sigma\\big)$ 这一项是 $\\|(S-I)y_{\\text{true}}\\|_{2}^{2}$ 的一个无偏估计量。将其代入 $\\mathcal{R}(S)$ 的表达式中，我们得到我们的 UPRE 函数：\n$$\n\\operatorname{UPRE}(y, S) = \\left( \\|(S-I)y\\|_{2}^{2} - \\operatorname{tr}\\big((S-I)^{T}(S-I)\\Sigma\\big) \\right) + \\operatorname{tr}(S^{T}S\\Sigma)\n$$\n矩阵 $S$ 是对称的，所以 $S^T=S$。因此 $(S-I)^{T}(S-I) = (S-I)^2 = S^2 - 2S + I$。\n$$\n\\operatorname{UPRE}(y, S) = \\|(S-I)y\\|_{2}^{2} - \\operatorname{tr}\\big((S^2 - 2S + I)\\Sigma\\big) + \\operatorname{tr}(S^2\\Sigma)\n$$\n利用迹的线性性质：\n$$\n\\operatorname{UPRE}(y, S) = \\|(S-I)y\\|_{2}^{2} - \\operatorname{tr}(S^2\\Sigma) + 2\\operatorname{tr}(S\\Sigma) - \\operatorname{tr}(\\Sigma) + \\operatorname{tr}(S^2\\Sigma)\n$$\n$$\n\\operatorname{UPRE}(y, S) = \\|(S-I)y\\|_{2}^{2} + 2\\operatorname{tr}(S\\Sigma) - \\operatorname{tr}(\\Sigma)\n$$\n对于 $S = \\operatorname{diag}(s_{1}, s_{2})$，$\\Sigma = \\operatorname{diag}(\\sigma_{1}^{2}, \\sigma_{2}^{2})$ 和 $y = \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix}$ 的特定情况：\n$\\|(S-I)y\\|_{2}^{2} = \\| \\operatorname{diag}(s_1-1, s_2-1)y \\|_{2}^{2} = (s_1-1)^2 y_1^2 + (s_2-1)^2 y_2^2$。\n$\\operatorname{tr}(S\\Sigma) = \\operatorname{tr}(\\operatorname{diag}(s_1\\sigma_1^2, s_2\\sigma_2^2)) = s_1\\sigma_1^2 + s_2\\sigma_2^2$。\n$\\operatorname{tr}(\\Sigma) = \\sigma_1^2 + \\sigma_2^2$。\n将这些代入通用的 UPRE 公式，得到显式表达式：\n$$\n\\operatorname{UPRE}(s_1, s_2) = (s_1-1)^2 y_1^2 + (s_2-1)^2 y_2^2 + 2(s_1\\sigma_1^2 + s_2\\sigma_2^2) - (\\sigma_1^2 + \\sigma_2^2)\n$$\n\n### 任务2：双参数方案优化\n\nUPRE 表达式在 $s_1$ 和 $s_2$ 上是可分的。我们可以通过独立地最小化每个分量函数来最小化它。对于 $j \\in \\{1,2\\}$，我们最小化 $f_j(s_j) = (s_j-1)^2 y_j^2 + 2s_j\\sigma_j^2$。\n对 $s_j$ 求导并令其为零：\n$$\n\\frac{df_j}{ds_j} = 2(s_j-1)y_j^2 + 2\\sigma_j^2 = 0 \\implies s_j y_j^2 - y_j^2 + \\sigma_j^2 = 0 \\implies s_j = \\frac{y_j^2 - \\sigma_j^2}{y_j^2} = 1 - \\frac{\\sigma_j^2}{y_j^2}\n$$\n约束 $\\lambda_j \\ge 0$ 意味着 $s_j = 1/(1+\\lambda_j) \\in (0, 1]$。由于 $y_j^2 > 0$ 且 $\\sigma_j^2 > 0$，无约束最小值 $s_j^\\star$ 总是小于 1。如果 $s_j^\\star \\le 0$，则在 $(0,1]$ 上的最小值位于边界，但通常收缩因子允许在 $[0,1]$ 内取值，对应于 $\\lambda_j \\in [0, \\infty]$，在这种情况下，最优值为 $s_j^{\\star} = \\max(0, 1-\\sigma_j^2/y_j^2)$。\n给定数据：$y_1=3$, $y_2=2$, $\\sigma_1^2 = 1/4$, $\\sigma_2^2 = 1$。\n$$\ns_1^{\\star} = 1 - \\frac{1/4}{3^2} = 1 - \\frac{1}{36} = \\frac{35}{36}\n$$\n$$\ns_2^{\\star} = 1 - \\frac{1}{2^2} = 1 - \\frac{1}{4} = \\frac{3}{4}\n$$\n两个值都在 $(0, 1]$ 区间内，因此它们是有效的最小值。\n相应的最优正则化参数为 $\\lambda_j^{\\star} = 1/s_j^{\\star} - 1$：\n$$\n\\lambda_1^{\\star} = \\frac{36}{35} - 1 = \\frac{1}{35}, \\quad \\lambda_2^{\\star} = \\frac{4}{3} - 1 = \\frac{1}{3}\n$$\n为了求得最小 UPRE 值，我们将 $s_j^{\\star}$ 代回 UPRE 公式。每个分量的最小值为 $f_j(s_j^{\\star}) = (\\sigma_j^4/y_j^4)y_j^2 + 2(1-\\sigma_j^2/y_j^2)\\sigma_j^2 = 2\\sigma_j^2 - \\sigma_j^4/y_j^2$。\n因此，总的最小 UPRE 为：\n$$\n\\min_{\\lambda_1, \\lambda_2} \\operatorname{UPRE}_{\\text{two}} = \\sum_{j=1}^2 \\left( 2\\sigma_j^2 - \\frac{\\sigma_j^4}{y_j^2} \\right) - (\\sigma_1^2+\\sigma_2^2) = \\sum_{j=1}^2 \\left( \\sigma_j^2 - \\frac{\\sigma_j^4}{y_j^2} \\right)\n$$\n代入数值：\n$$\n\\min \\operatorname{UPRE}_{\\text{two}} = \\left(\\frac{1}{4} - \\frac{(1/4)^2}{3^2}\\right) + \\left(1 - \\frac{1^2}{2^2}\\right) = \\left(\\frac{1}{4} - \\frac{1}{144}\\right) + \\left(1 - \\frac{1}{4}\\right) = 1 - \\frac{1}{144} = \\frac{143}{144}\n$$\n\n### 任务3：单参数方案优化\n\n在此方案中，$s_1 = s_2 = s$。UPRE 变为：\n$$\n\\operatorname{UPRE}_{\\text{single}}(s) = (s-1)^2 y_1^2 + (s-1)^2 y_2^2 + 2s\\sigma_1^2 + 2s\\sigma_2^2 - (\\sigma_1^2+\\sigma_2^2)\n$$\n$$\n\\operatorname{UPRE}_{\\text{single}}(s) = (s-1)^2 (y_1^2+y_2^2) + 2s(\\sigma_1^2+\\sigma_2^2) - (\\sigma_1^2+\\sigma_2^2)\n$$\n关于 $s$ 进行最小化：\n$$\n\\frac{d}{ds}\\operatorname{UPRE}_{\\text{single}} = 2(s-1)(y_1^2+y_2^2) + 2(\\sigma_1^2+\\sigma_2^2) = 0\n$$\n$$\ns^{\\star} = \\frac{(y_1^2+y_2^2) - (\\sigma_1^2+\\sigma_2^2)}{y_1^2+y_2^2} = 1 - \\frac{\\sigma_1^2+\\sigma_2^2}{y_1^2+y_2^2}\n$$\n数值：$y_1^2+y_2^2 = 3^2+2^2 = 13$ 和 $\\sigma_1^2+\\sigma_2^2 = 1/4+1 = 5/4$。\n$$\ns^{\\star} = 1 - \\frac{5/4}{13} = 1 - \\frac{5}{52} = \\frac{47}{52}\n$$\n该值位于 $(0, 1]$ 区间内。最优参数 $\\lambda^\\star$ 为：\n$$\n\\lambda^{\\star} = \\frac{1}{s^{\\star}} - 1 = \\frac{52}{47} - 1 = \\frac{5}{47}\n$$\n最小 UPRE 值为：\n$$\n\\min_{\\lambda} \\operatorname{UPRE}_{\\text{single}} = (s^{\\star}-1)^2(y_1^2+y_2^2) + 2s^{\\star}(\\sigma_1^2+\\sigma_2^2) - (\\sigma_1^2+\\sigma_2^2)\n$$\n一般最小值为 $(\\sigma_1^2+\\sigma_2^2) - \\frac{(\\sigma_1^2+\\sigma_2^2)^2}{y_1^2+y_2^2}$。\n$$\n\\min \\operatorname{UPRE}_{\\text{single}} = \\frac{5}{4} - \\frac{(5/4)^2}{13} = \\frac{5}{4} - \\frac{25/16}{13} = \\frac{5}{4} - \\frac{25}{208} = \\frac{5 \\times 52}{208} - \\frac{25}{208} = \\frac{260 - 25}{208} = \\frac{235}{208}\n$$\n\n### 任务4：计算差值 $\\Delta$\n\n差值定义为 $\\Delta = \\big(\\min_{\\lambda} \\operatorname{UPRE}_{\\text{single}}(\\lambda)\\big) - \\big(\\min_{\\lambda_{1}, \\lambda_{2}} \\operatorname{UPRE}_{\\text{two}}(\\lambda_{1}, \\lambda_{2})\\big)$。\n使用任务2和任务3的结果：\n$$\n\\Delta = \\frac{235}{208} - \\frac{143}{144}\n$$\n为了减去这两个分数，我们找到一个公分母。素数分解为 $208 = 2^4 \\times 13$ 和 $144 = 2^4 \\times 3^2$。\n最小公倍数是 $\\operatorname{lcm}(208, 144) = 2^4 \\times 3^2 \\times 13 = 16 \\times 9 \\times 13 = 1872$。\n$$\n\\Delta = \\frac{235 \\times 9}{1872} - \\frac{143 \\times 13}{1872}\n$$\n分子是：\n$235 \\times 9 = 2115$\n$143 \\times 13 = 1859$\n$$\n\\Delta = \\frac{2115 - 1859}{1872} = \\frac{256}{1872}\n$$\n为了化简分数，我们使用素数分解：$256 = 2^8$ 和 $1872=2^4 \\times 117$。\n$$\n\\Delta = \\frac{2^8}{2^4 \\times 117} = \\frac{2^4}{117} = \\frac{16}{117}\n$$\n这个正差值量化了使用更灵活的双参数正则化方案相对于单参数方案，在估计预测风险方面所获得的性能提升。",
            "answer": "$$\n\\boxed{\\frac{16}{117}}\n$$"
        },
        {
            "introduction": "为了通过最小化UPRE来寻找最优的正则化参数 $\\lambda$，我们需要借助数值优化算法。在这些算法中，基于梯度的方法是最基础也是最重要的一类。本练习将聚焦于推导Tikhonov正则化下UPRE函数关于 $\\lambda$ 的解析梯度，这是实现任何高效参数选择算法的关键一步。",
            "id": "3429094",
            "problem": "考虑一个线性逆问题，其中数据来自正向模型 $y = A x_{\\star} + \\epsilon$，其中 $A \\in \\mathbb{R}^{m \\times n}$，$x_{\\star} \\in \\mathbb{R}^{n}$，以及加性噪声 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2} I_{m})$，其方差 $\\sigma_{\\epsilon}^{2} > 0$ 已知。对于给定的正则化参数 $\\lambda > 0$，零阶吉洪诺夫估计量定义为\n$$\nx_{\\lambda} \\in \\arg\\min_{x \\in \\mathbb{R}^{n}} \\left\\{ \\|A x - y\\|_{2}^{2} + \\lambda^{2} \\|x\\|_{2}^{2} \\right\\}.\n$$\n令相关的预测数据为 $\\hat{y}_{\\lambda} = A x_{\\lambda} = H_{\\lambda} y$，其中线性“帽子”算子为\n$$\nH_{\\lambda} := A (A^{\\top} A + \\lambda^{2} I_{n})^{-1} A^{\\top} \\in \\mathbb{R}^{m \\times m}.\n$$\n用于预测损失的无偏预测风险估计量 (UPRE) 定义为\n$$\n\\mathrm{UPRE}(\\lambda) := \\|y - \\hat{y}_{\\lambda}\\|_{2}^{2} + 2 \\sigma_{\\epsilon}^{2} \\,\\mathrm{tr}(H_{\\lambda}) - m \\sigma_{\\epsilon}^{2}.\n$$\n假设 $A$ 的秩为 $r \\le \\min\\{m,n\\}$，其奇异值分解 (SVD) 为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交的，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 的对角线元素为 $\\sigma_{1} \\ge \\cdots \\ge \\sigma_{r} > 0$，且当 $i > r$ 时 $\\sigma_{i} = 0$。定义数据系数 $c_{i} := u_{i}^{\\top} y$，其中 $u_{i}$ 是 $U$ 的第 $i$ 列，以及数据空间吉洪诺夫滤波因子\n$$\n\\phi_{i}(\\lambda) := \\frac{\\sigma_{i}^{2}}{\\sigma_{i}^{2} + \\lambda^{2}} \\quad \\text{对于 } i = 1,\\ldots,r, \\quad \\text{以及} \\quad \\phi_{i}(\\lambda) := 0 \\quad \\text{对于 } i > r.\n$$\n\n从给定的 $\\mathrm{UPRE}(\\lambda)$ 定义、SVD 的基本性质以及矩阵微积分的标准法则出发，推导出一个完全用 $\\lambda$、$\\sigma_{\\epsilon}^{2}$、$\\{\\sigma_{i}\\}_{i=1}^{r}$、$\\{u_{i}^{\\top} y\\}_{i=1}^{m}$ 和 $\\{\\phi_{i}(\\lambda)\\}_{i=1}^{m}$ 表示的导数 $\\frac{d}{d\\lambda}\\mathrm{UPRE}(\\lambda)$ 的闭式表达式。你的最终答案必须是一个仅依赖于这些量的单一解析表达式。不要假设或引用任何关于 $\\phi_{i}(\\lambda)$ 的现成导数公式；相反，应从其定义计算 $\\frac{d}{d\\lambda}\\phi_{i}(\\lambda)$。\n\n最终答案必须是一个单一的闭式解析表达式。不需要进行数值计算。",
            "solution": "我们从无偏预测风险估计量 (UPRE) 的定义开始：\n$$\n\\mathrm{UPRE}(\\lambda) = \\|y - \\hat{y}_{\\lambda}\\|_{2}^{2} + 2 \\sigma_{\\epsilon}^{2}\\,\\mathrm{tr}(H_{\\lambda}) - m \\sigma_{\\epsilon}^{2},\n$$\n其中 $\\hat{y}_{\\lambda} = H_{\\lambda} y$ 且 $H_{\\lambda} = A (A^{\\top} A + \\lambda^{2} I_{n})^{-1} A^{\\top}$。\n\n为了在使这些算子对角化的基中分析 $\\mathrm{UPRE}(\\lambda)$，我们使用奇异值分解 (SVD) $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 是正交的，$V \\in \\mathbb{R}^{n \\times n}$ 是正交的，并且 $\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是对角矩阵，其对角线元素为 $(\\Sigma)_{ii} = \\sigma_{i}$（对于 $i = 1,\\ldots,r$）否则为零，其中 $r = \\mathrm{rank}(A)$。那么\n$$\nA^{\\top} A = V \\Sigma^{\\top} \\Sigma V^{\\top} = V \\,\\mathrm{diag}(\\sigma_{1}^{2},\\ldots,\\sigma_{r}^{2},0,\\ldots,0)\\, V^{\\top}.\n$$\n因此，\n$$\n(A^{\\top} A + \\lambda^{2} I_{n})^{-1} = V \\,\\mathrm{diag}\\!\\left(\\frac{1}{\\sigma_{1}^{2} + \\lambda^{2}},\\ldots,\\frac{1}{\\sigma_{r}^{2} + \\lambda^{2}},\\frac{1}{\\lambda^{2}},\\ldots,\\frac{1}{\\lambda^{2}}\\right) V^{\\top}.\n$$\n展开乘积，\n\\begin{align*}\nH_{\\lambda} \n= A (A^{\\top} A + \\lambda^{2} I_{n})^{-1} A^{\\top} \\\\\n= U \\Sigma V^{\\top} \\,\\left[V \\,\\mathrm{diag}\\!\\left(\\frac{1}{\\sigma_{1}^{2} + \\lambda^{2}},\\ldots,\\frac{1}{\\sigma_{r}^{2} + \\lambda^{2}},\\frac{1}{\\lambda^{2}},\\ldots,\\frac{1}{\\lambda^{2}}\\right) V^{\\top}\\right] V \\Sigma^{\\top} U^{\\top} \\\\\n= U \\left[\\Sigma \\,\\mathrm{diag}\\!\\left(\\frac{1}{\\sigma_{1}^{2} + \\lambda^{2}},\\ldots,\\frac{1}{\\sigma_{r}^{2} + \\lambda^{2}},\\frac{1}{\\lambda^{2}},\\ldots,\\frac{1}{\\lambda^{2}}\\right) \\Sigma^{\\top}\\right] U^{\\top}.\n\\end{align*}\n由于 $\\Sigma$ 只有前 $r$ 个对角线元素非零，且 $\\Sigma \\Sigma^{\\top}$ 具有相同的前 $r$ 个非零对角线元素 $\\sigma_{i}^{2}$ (当 $i \\le r$)，中间的括号项简化为具有以下元素的 $m \\times m$ 对角矩阵：\n$$\n\\phi_{i}(\\lambda) = \\frac{\\sigma_{i}^{2}}{\\sigma_{i}^{2} + \\lambda^{2}} \\quad \\text{对于 } i=1,\\ldots,r, \\qquad \\phi_{i}(\\lambda) = 0 \\quad \\text{对于 } i > r.\n$$\n因此\n$$\nH_{\\lambda} = U \\,\\mathrm{diag}\\!\\big(\\phi_{1}(\\lambda),\\ldots,\\phi_{m}(\\lambda)\\big)\\, U^{\\top}.\n$$\n\n令 $c_{i} := u_{i}^{\\top} y$ 表示 $y$ 在标准正交基 $\\{u_{i}\\}$ 中的系数，其中 $U^{\\top} y = (c_{1},\\ldots,c_{m})^{\\top}$。那么残差为\n$$\nr_{\\lambda} := y - \\hat{y}_{\\lambda} = (I_{m} - H_{\\lambda}) y = U \\,\\mathrm{diag}\\!\\big(1 - \\phi_{1}(\\lambda),\\ldots,1 - \\phi_{m}(\\lambda)\\big)\\, U^{\\top} y,\n$$\n因此\n$$\n\\|r_{\\lambda}\\|_{2}^{2} = \\sum_{i=1}^{m} \\big(1 - \\phi_{i}(\\lambda)\\big)^{2} c_{i}^{2}.\n$$\n此外，迹为\n$$\n\\mathrm{tr}(H_{\\lambda}) = \\sum_{i=1}^{m} \\phi_{i}(\\lambda) = \\sum_{i=1}^{r} \\phi_{i}(\\lambda),\n$$\n因为当 $i>r$ 时，$\\phi_{i}(\\lambda)=0$。因此，\n$$\n\\mathrm{UPRE}(\\lambda) = \\sum_{i=1}^{m} \\big(1 - \\phi_{i}(\\lambda)\\big)^{2} c_{i}^{2} + 2 \\sigma_{\\epsilon}^{2} \\sum_{i=1}^{r} \\phi_{i}(\\lambda) - m \\sigma_{\\epsilon}^{2}.\n$$\n注意，当 $i>r$ 时，$\\phi_{i}(\\lambda) \\equiv 0$，因此仅当 $i \\le r$ 时才存在对 $\\lambda$ 的依赖性。对 $\\lambda$ 求导并应用链式法则，\n\\begin{align*}\n\\frac{d}{d\\lambda} \\mathrm{UPRE}(\\lambda)\n= \\sum_{i=1}^{r} \\frac{d}{d\\lambda} \\left[ \\big(1 - \\phi_{i}(\\lambda)\\big)^{2} c_{i}^{2} + 2 \\sigma_{\\epsilon}^{2} \\phi_{i}(\\lambda) \\right] \\\\\n= \\sum_{i=1}^{r} \\left[ 2 \\big(1 - \\phi_{i}(\\lambda)\\big) \\big(-\\phi_{i}'(\\lambda)\\big) c_{i}^{2} + 2 \\sigma_{\\epsilon}^{2} \\phi_{i}'(\\lambda) \\right] \\\\\n= 2 \\sum_{i=1}^{r} \\phi_{i}'(\\lambda) \\left[ \\sigma_{\\epsilon}^{2} - \\big(1 - \\phi_{i}(\\lambda)\\big) c_{i}^{2} \\right].\n\\end{align*}\n剩下的任务是从其定义计算 $\\phi_{i}'(\\lambda)$。对于 $i \\le r$，\n$$\n\\phi_{i}(\\lambda) = \\frac{\\sigma_{i}^{2}}{\\sigma_{i}^{2} + \\lambda^{2}}.\n$$\n求导得，\n$$\n\\phi_{i}'(\\lambda) = \\frac{d}{d\\lambda} \\left( \\frac{\\sigma_{i}^{2}}{\\sigma_{i}^{2} + \\lambda^{2}} \\right) = - \\frac{2 \\lambda \\sigma_{i}^{2}}{(\\sigma_{i}^{2} + \\lambda^{2})^{2}}.\n$$\n通常将 $\\phi_{i}'(\\lambda)$ 仅用 $\\phi_{i}(\\lambda)$ 和 $\\sigma_{i}$ 表示会更方便。使用 $\\phi_{i}(\\lambda) = \\sigma_{i}^{2}/(\\sigma_{i}^{2} + \\lambda^{2})$，我们有\n$$\n\\phi_{i}(\\lambda)^{2} = \\frac{\\sigma_{i}^{4}}{(\\sigma_{i}^{2} + \\lambda^{2})^{2}} \\quad \\Longrightarrow \\quad \\phi_{i}'(\\lambda) = - \\frac{2 \\lambda \\sigma_{i}^{2}}{(\\sigma_{i}^{2} + \\lambda^{2})^{2}} = - \\frac{2 \\lambda}{\\sigma_{i}^{2}} \\,\\phi_{i}(\\lambda)^{2}.\n$$\n将此代入 $\\mathrm{UPRE}(\\lambda)$ 的导数中，得到\n\\begin{align*}\n\\frac{d}{d\\lambda} \\mathrm{UPRE}(\\lambda)\n= 2 \\sum_{i=1}^{r} \\left( - \\frac{2 \\lambda}{\\sigma_{i}^{2}} \\,\\phi_{i}(\\lambda)^{2} \\right) \\left[ \\sigma_{\\epsilon}^{2} - \\big(1 - \\phi_{i}(\\lambda)\\big) c_{i}^{2} \\right] \\\\\n= - 4 \\lambda \\sum_{i=1}^{r} \\frac{\\phi_{i}(\\lambda)^{2}}{\\sigma_{i}^{2}} \\left[ \\sigma_{\\epsilon}^{2} - \\big(1 - \\phi_{i}(\\lambda)\\big) c_{i}^{2} \\right].\n\\end{align*}\n回顾 $c_{i} = u_{i}^{\\top} y$，我们得到了完全用 $\\lambda$、$\\sigma_{\\epsilon}^{2}$、$\\{\\sigma_{i}\\}$、$\\{u_{i}^{\\top} y\\}$ 和 $\\{\\phi_{i}(\\lambda)\\}$ 表示的所需闭式表达式：\n$$\n\\frac{d}{d\\lambda} \\mathrm{UPRE}(\\lambda) = - 4 \\lambda \\sum_{i=1}^{r} \\frac{\\phi_{i}(\\lambda)^{2}}{\\sigma_{i}^{2}} \\left( \\sigma_{\\epsilon}^{2} - \\big(1 - \\phi_{i}(\\lambda)\\big) (u_{i}^{\\top} y)^{2} \\right).\n$$\n此表达式对任何 $\\lambda > 0$ 都有效，并且在 $A$ 是满秩或秩亏时（后者通过 $i>r$ 时 $\\phi_{i}(\\lambda) \\equiv 0$）都能正确简化。",
            "answer": "$$\\boxed{-4\\lambda \\sum_{i=1}^{r} \\frac{\\phi_{i}(\\lambda)^{2}}{\\sigma_{i}^{2}} \\left( \\sigma_{\\epsilon}^{2} - \\big(1 - \\phi_{i}(\\lambda)\\big)\\,(u_{i}^{\\top} y)^{2} \\right)}$$"
        },
        {
            "introduction": "虽然梯度下降法是有效的，但其收敛速度有时可能较慢，尤其是在接近最优点时。利用函数的二阶导数信息，牛顿法等二阶优化方法通常能实现更快的收敛。本练习在前一个练习计算梯度的基础上，将引导您进一步推导UPRE函数的Hessian矩阵（在此为二阶导数），并构建一个完整的牛顿法更新步骤，展示如何为UPRE最小化问题设计更高效的求解器。",
            "id": "3429134",
            "problem": "考虑一个带有加性高斯噪声的离散线性逆问题，其中观测数据向量 $y \\in \\mathbb{R}^{m}$ 被建模为 $y = A x_{\\star} + \\varepsilon$，其中 $A \\in \\mathbb{R}^{m \\times n}$，$x_{\\star} \\in \\mathbb{R}^{n}$ 是未知的真值，而 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{m})$ 是一个均值为零、方差为 $\\sigma^{2} > 0$ 的高斯噪声。我们考虑使用正则化参数 $\\lambda > 0$ 的零阶 Tikhonov 正则化，其定义为\n$$\n\\widehat{x}_{\\lambda} \\in \\arg\\min_{x \\in \\mathbb{R}^{n}} \\left\\{ \\|A x - y\\|_{2}^{2} + \\lambda^{2} \\|x\\|_{2}^{2} \\right\\}.\n$$\n相应的线性估计器可以写为 $\\widehat{x}_{\\lambda} = S(\\lambda) y$，其中 $S(\\lambda) = (A^{\\top} A + \\lambda^{2} I_{n})^{-1} A^{\\top}$。将数据空间的预测风险定义为 $R_{\\mathrm{pred}}(\\lambda) = \\mathbb{E}\\left[\\|A \\widehat{x}_{\\lambda} - A x_{\\star}\\|_{2}^{2}\\right]$。在高斯模型下，$R_{\\mathrm{pred}}(\\lambda)$ 的无偏预测风险估计器 (UPRE) 是函数\n$$\nU(\\lambda) \\equiv \\mathrm{UPRE}(\\lambda) = \\|(I_{m} - A S(\\lambda)) y\\|_{2}^{2} + 2 \\sigma^{2} \\,\\mathrm{tr}(A S(\\lambda)) - m \\sigma^{2}.\n$$\n设 $A$ 的奇异值分解 (SVD) 为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 在其前导 $r \\times r$ 块上的对角线元素为 $\\{\\sigma_{i}\\}_{i=1}^{r}$，满足 $\\sigma_{1} \\ge \\sigma_{2} \\ge \\cdots \\ge \\sigma_{r} > 0$，$r = \\mathrm{rank}(A) \\le \\min\\{m, n\\}$。数据系数记为 $w_{i} = u_{i}^{\\top} y$，其中 $i \\in \\{1, \\dots, m\\}$，$u_{i}$ 是 $U$ 的第 $i$ 列。\n\n任务：\n- 从 $U(\\lambda)$ 的定义和 $A$ 的 SVD 出发，通过消除矩阵的迹和范数，将 $U(\\lambda)$ 完全用 $\\{\\sigma_{i}\\}_{i=1}^{r}$、$\\{w_{i}\\}_{i=1}^{m}$ 和 $\\lambda$ 表示。然后求导，得到一阶导数 $U'(\\lambda)$ 和二阶导数 $U''(\\lambda)$ 的显式公式。\n- 陈述最小化 $U(\\lambda)$ 的一阶最优性条件以及用 $U'(\\lambda)$ 和 $U''(\\lambda)$ 表示的相应二阶条件。\n- 设计一个仅使用基于 SVD 的标量的牛顿或拟牛顿迭代法来求解 $\\lambda$。提供单步牛顿更新公式 $\\lambda_{\\mathrm{new}} = \\lambda - U'(\\lambda)/U''(\\lambda)$ 的一个闭式解析表达式，该表达式用 $\\{\\sigma_{i}\\}_{i=1}^{r}$、$\\{w_{i}\\}_{i=1}^{r}$、$\\sigma^{2}$ 和 $\\lambda$ 表示。\n\n答案格式要求：\n- 您的最终答案必须是单步牛顿更新 $\\lambda_{\\mathrm{new}}$ 的一个闭式解析表达式，用 $\\{\\sigma_{i}\\}_{i=1}^{r}$、$\\{w_{i}\\}_{i=1}^{r}$、$\\sigma^{2}$ 和 $\\lambda$ 表示。\n- 无需进行数值计算。\n- 不要在最终答案中包含任何单位。",
            "solution": "首先根据指定标准对问题进行验证。\n\n### 问题验证\n\n**第 1 步：提取已知条件**\n-   数据模型为 $y = A x_{\\star} + \\varepsilon$，其中 $y \\in \\mathbb{R}^{m}$，$A \\in \\mathbb{R}^{m \\times n}$，$x_{\\star} \\in \\mathbb{R}^{n}$，且 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{m})$，$\\sigma^{2} > 0$。\n-   Tikhonov 正则化解为 $\\widehat{x}_{\\lambda} \\in \\arg\\min_{x \\in \\mathbb{R}^{n}} \\left\\{ \\|A x - y\\|_{2}^{2} + \\lambda^{2} \\|x\\|_{2}^{2} \\right\\}$，对于 $\\lambda > 0$。\n-   估计器是线性的：$\\widehat{x}_{\\lambda} = S(\\lambda) y$，其中 $S(\\lambda) = (A^{\\top} A + \\lambda^{2} I_{n})^{-1} A^{\\top}$。\n-   预测风险为 $R_{\\mathrm{pred}}(\\lambda) = \\mathbb{E}\\left[\\|A \\widehat{x}_{\\lambda} - A x_{\\star}\\|_{2}^{2}\\right]$。\n-   无偏预测风险估计器 (UPRE) 由 $U(\\lambda) = \\|(I_{m} - A S(\\lambda)) y\\|_{2}^{2} + 2 \\sigma^{2} \\,\\mathrm{tr}(A S(\\lambda)) - m \\sigma^{2}$ 给出。\n-   $A$ 的奇异值分解 (SVD) 为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵。$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个对角矩阵，其非零奇异值为 $\\sigma_{1} \\ge \\sigma_{2} \\ge \\cdots \\ge \\sigma_{r} > 0$，其中 $r = \\mathrm{rank}(A)$。\n-   SVD 基中的数据系数为 $w_{i} = u_{i}^{\\top} y$，其中 $i \\in \\{1, \\dots, m\\}$，$u_{i}$ 是 $U$ 的第 $i$ 列。\n\n**第 2 步：使用提取的已知条件进行验证**\n-   **科学基础：** 该问题建立在线性逆问题和正则化理论的标准框架内。所有概念，包括 Tikhonov 正则化、SVD 和 UPRE，都是该领域公认且基础的概念。\n-   **适定性：** 问题陈述清晰，提供了所有必要的定义和量之间的关系。任务要求具体的、可推导的解析表达式，表明存在唯一的求解路径。\n-   **客观性：** 语言是形式化的、数学的，并且没有任何主观或含糊的术语。\n\n对缺陷列表的详细检查证实了问题的有效性。它在科学上是合理的、形式上是陈述的、完整的，并且提出了一个在数学分析中非平凡但可解的挑战。\n\n**第 3 步：结论与行动**\n-   **结论：** 问题有效。\n-   **行动：** 进行完整求解。\n\n### 求解\n\n求解过程首先将 UPRE 函数 $U(\\lambda)$ 及其导数用矩阵 $A$ 的 SVD 分量表示。\n\n**1. 在 SVD 坐标系中表示 $U(\\lambda)$**\n\n我们首先使用 $A = U \\Sigma V^{\\top}$ 的 SVD 来分析矩阵乘积 $A S(\\lambda)$。\n首先，考虑项 $A^{\\top} A + \\lambda^{2} I_{n}$：\n$$A^{\\top} A + \\lambda^{2} I_{n} = (U \\Sigma V^{\\top})^{\\top} (U \\Sigma V^{\\top}) + \\lambda^{2} I_{n} = V \\Sigma^{\\top} U^{\\top} U \\Sigma V^{\\top} + \\lambda^{2} V V^{\\top} = V (\\Sigma^{\\top} \\Sigma + \\lambda^{2} I_{n}) V^{\\top}$$\n其逆为：\n$$(A^{\\top} A + \\lambda^{2} I_{n})^{-1} = V (\\Sigma^{\\top} \\Sigma + \\lambda^{2} I_{n})^{-1} V^{\\top}$$\n现在，我们可以写出解算子 $S(\\lambda)$：\n$$S(\\lambda) = (A^{\\top} A + \\lambda^{2} I_{n})^{-1} A^{\\top} = V (\\Sigma^{\\top} \\Sigma + \\lambda^{2} I_{n})^{-1} V^{\\top} (V \\Sigma^{\\top} U^{\\top}) = V (\\Sigma^{\\top} \\Sigma + \\lambda^{2} I_{n})^{-1} \\Sigma^{\\top} U^{\\top}$$\n中心对象 $A S(\\lambda)$，通常称为影响矩阵，变为：\n$$A S(\\lambda) = (U \\Sigma V^{\\top}) S(\\lambda) = U \\Sigma V^{\\top} V (\\Sigma^{\\top} \\Sigma + \\lambda^{2} I_{n})^{-1} \\Sigma^{\\top} U^{\\top} = U \\left( \\Sigma (\\Sigma^{\\top} \\Sigma + \\lambda^{2} I_{n})^{-1} \\Sigma^{\\top} \\right) U^{\\top}$$\n矩阵 $\\Sigma (\\Sigma^{\\top} \\Sigma + \\lambda^{2} I_{n})^{-1} \\Sigma^{\\top}$ 是一个 $m \\times m$ 的对角矩阵。其对角线元素，称为滤波因子，为：\n$$f_{i} = \\begin{cases} \\frac{\\sigma_{i}^{2}}{\\sigma_{i}^{2} + \\lambda^{2}}  \\text{对于 } i = 1, \\dots, r \\\\ 0  \\text{对于 } i = r+1, \\dots, m \\end{cases}$$\n我们用 $\\Lambda_{f}$ 表示这个对角矩阵。那么 $A S(\\lambda) = U \\Lambda_{f} U^{\\top}$。\n\n现在我们可以重写 $U(\\lambda)$ 中的各项：\n-   残差范数项：\n    $$\\|(I_{m} - A S(\\lambda)) y\\|_{2}^{2} = \\|(I_{m} - U \\Lambda_{f} U^{\\top}) y\\|_{2}^{2} = \\|U (I_{m} - \\Lambda_{f}) U^{\\top} y\\|_{2}^{2}$$\n    由于 $U$ 是正交的，这等于 $\\|(I_{m} - \\Lambda_{f}) (U^{\\top} y)\\|_{2}^{2}$。设 $w = U^{\\top} y$，所以 $w_{i} = u_i^\\top y$。$(I_{m} - \\Lambda_{f}) w$ 的分量是 $(1-f_{i})w_{i}$。平方范数为：\n    $$\\sum_{i=1}^{m} (1 - f_{i})^{2} w_{i}^{2} = \\sum_{i=1}^{r} \\left(1 - \\frac{\\sigma_{i}^{2}}{\\sigma_{i}^{2} + \\lambda^{2}}\\right)^{2} w_{i}^{2} + \\sum_{i=r+1}^{m} (1-0)^{2} w_{i}^{2} = \\sum_{i=1}^{r} \\left(\\frac{\\lambda^{2}}{\\sigma_{i}^{2} + \\lambda^{2}}\\right)^{2} w_{i}^{2} + \\sum_{i=r+1}^{m} w_{i}^{2}$$\n-   迹项：\n    $$\\mathrm{tr}(A S(\\lambda)) = \\mathrm{tr}(U \\Lambda_{f} U^{\\top}) = \\mathrm{tr}(\\Lambda_{f} U^{\\top} U) = \\mathrm{tr}(\\Lambda_{f}) = \\sum_{i=1}^{m} f_{i} = \\sum_{i=1}^{r} \\frac{\\sigma_{i}^{2}}{\\sigma_{i}^{2} + \\lambda^{2}}$$\n结合这些，得到 $U(\\lambda)$ 的完整表达式：\n$$U(\\lambda) = \\sum_{i=1}^{r} \\frac{\\lambda^{4}}{(\\sigma_{i}^{2} + \\lambda^{2})^{2}} w_{i}^{2} + \\sum_{i=r+1}^{m} w_{i}^{2} + 2 \\sigma^{2} \\sum_{i=1}^{r} \\frac{\\sigma_{i}^{2}}{\\sigma_{i}^{2} + \\lambda^{2}} - m \\sigma^{2}$$\n\n**2. $U(\\lambda)$ 的一阶和二阶导数**\n\n为了找到 $U(\\lambda)$ 的最小值，我们计算它关于 $\\lambda$ 的导数。项 $\\sum_{i=r+1}^{m} w_{i}^{2}$ 和 $-m \\sigma^{2}$ 相对于 $\\lambda$ 是常数，在求导时会消失。\n\n对于一阶导数 $U'(\\lambda)$：\n$$ \\frac{d}{d\\lambda} \\left( \\frac{\\lambda^{4}}{(\\sigma_i^2+\\lambda^2)^2} \\right) = \\frac{4\\lambda^3(\\sigma_i^2+\\lambda^2)^2 - \\lambda^4 \\cdot 2(\\sigma_i^2+\\lambda^2)(2\\lambda)}{(\\sigma_i^2+\\lambda^2)^4} = \\frac{4\\lambda^3(\\sigma_i^2+\\lambda^2) - 4\\lambda^5}{(\\sigma_i^2+\\lambda^2)^3} = \\frac{4\\lambda^3\\sigma_i^2}{(\\sigma_i^2+\\lambda^2)^3} $$\n$$ \\frac{d}{d\\lambda} \\left( \\frac{\\sigma_i^2}{\\sigma_i^2+\\lambda^2} \\right) = \\sigma_i^2 \\frac{-1}{(\\sigma_i^2+\\lambda^2)^2} (2\\lambda) = \\frac{-2\\lambda\\sigma_i^2}{(\\sigma_i^2+\\lambda^2)^2} $$\n结合这些结果，我们得到 $U'(\\lambda)$：\n$$U'(\\lambda) = \\sum_{i=1}^{r} \\frac{4\\lambda^3\\sigma_i^2 w_i^2}{(\\sigma_i^2 + \\lambda^2)^3} - \\sum_{i=1}^{r} \\frac{4\\lambda\\sigma^2\\sigma_i^2}{(\\sigma_i^2 + \\lambda^2)^2}$$\n\n对于二阶导数 $U''(\\lambda)$，我们对 $U'(\\lambda)$ 求导：\n对于 $U'(\\lambda)$ 中的第一项：\n$$ \\frac{d}{d\\lambda} \\left( \\frac{4\\lambda^3\\sigma_i^2}{(\\sigma_i^2+\\lambda^2)^3} \\right) = 4\\sigma_i^2 \\frac{3\\lambda^2(\\sigma_i^2+\\lambda^2)^3 - \\lambda^3 \\cdot 3(\\sigma_i^2+\\lambda^2)^2(2\\lambda)}{(\\sigma_i^2+\\lambda^2)^6} = 4\\sigma_i^2 \\frac{3\\lambda^2(\\sigma_i^2+\\lambda^2) - 6\\lambda^4}{(\\sigma_i^2+\\lambda^2)^4} = \\frac{12\\lambda^2\\sigma_i^2(\\sigma_i^2-\\lambda^2)}{(\\sigma_i^2+\\lambda^2)^4} $$\n对于 $U'(\\lambda)$ 中的第二项：\n$$ \\frac{d}{d\\lambda} \\left( \\frac{-4\\lambda\\sigma^2\\sigma_i^2}{(\\sigma_i^2+\\lambda^2)^2} \\right) = -4\\sigma^2\\sigma_i^2 \\frac{1(\\sigma_i^2+\\lambda^2)^2 - \\lambda \\cdot 2(\\sigma_i^2+\\lambda^2)(2\\lambda)}{(\\sigma_i^2+\\lambda^2)^4} = -4\\sigma^2\\sigma_i^2 \\frac{\\sigma_i^2+\\lambda^2 - 4\\lambda^2}{(\\sigma_i^2+\\lambda^2)^3} = \\frac{-4\\sigma^2\\sigma_i^2(\\sigma_i^2-3\\lambda^2)}{(\\sigma_i^2+\\lambda^2)^3} $$\n结合这些，我们得到 $U''(\\lambda)$：\n$$U''(\\lambda) = \\sum_{i=1}^{r} \\frac{12\\lambda^2\\sigma_i^2(\\sigma_i^2-\\lambda^2)}{(\\sigma_i^2+\\lambda^2)^4} w_i^2 - \\sum_{i=1}^{r} \\frac{4\\sigma^2\\sigma_i^2(\\sigma_i^2-3\\lambda^2)}{(\\sigma_i^2+\\lambda^2)^3}$$\n\n**3. 最优性条件**\n\n为了找到使 $U(\\lambda)$ 最小化的 $\\lambda > 0$ 的值，我们使用标准的微积分极值条件。\n-   **一阶必要条件：** 一个候选最小值 $\\lambda^{\\ast}$ 必须是一个驻点，即它必须满足 $U'(\\lambda^{\\ast}) = 0$。\n-   **二阶充分条件：** 为使驻点成为局部最小值，二阶导数必须为正，即 $U''(\\lambda^{\\ast}) > 0$。\n\n**4. 用于最小化 $U(\\lambda)$ 的牛顿法**\n\n最小化 $U(\\lambda)$ 等价于找到其导数 $U'(\\lambda)=0$ 的根。用于寻找函数 $f(x)=0$ 根的牛顿法提供了迭代更新 $x_{k+1} = x_k - f(x_k)/f'(x_k)$。将此应用于 $f(\\lambda) = U'(\\lambda)$，我们得到 $f'(\\lambda) = U''(\\lambda)$，$\\lambda$ 的更新规则为：\n$$\\lambda_{\\mathrm{new}} = \\lambda - \\frac{U'(\\lambda)}{U''(\\lambda)}$$\n代入 $U'(\\lambda)$ 和 $U''(\\lambda)$ 的表达式，得到单步牛顿更新公式：\n$$\\lambda_{\\mathrm{new}} = \\lambda - \\frac{\\sum_{i=1}^{r} \\frac{4\\lambda^3\\sigma_i^2 w_i^2}{(\\sigma_i^2 + \\lambda^2)^3} - \\sum_{i=1}^{r} \\frac{4\\lambda\\sigma^2\\sigma_i^2}{(\\sigma_i^2 + \\lambda^2)^2}}{\\sum_{i=1}^{r} \\frac{12\\lambda^2\\sigma_i^2(\\sigma_i^2-\\lambda^2)}{(\\sigma_i^2+\\lambda^2)^4} w_i^2 - \\sum_{i=1}^{r} \\frac{4\\sigma^2\\sigma_i^2(\\sigma_i^2-3\\lambda^2)}{(\\sigma_i^2+\\lambda^2)^3}}$$\n我们可以约掉公因子 $4$ 以获得最终表达式。\n$$\\lambda_{\\mathrm{new}} = \\lambda - \\frac{\\sum_{i=1}^{r} \\frac{\\lambda^3\\sigma_i^2 w_i^2}{(\\sigma_i^2 + \\lambda^2)^3} - \\sum_{i=1}^{r} \\frac{\\lambda\\sigma^2\\sigma_i^2}{(\\sigma_i^2 + \\lambda^2)^2}}{\\sum_{i=1}^{r} \\frac{3\\lambda^2\\sigma_i^2 w_i^2(\\sigma_i^2-\\lambda^2)}{(\\sigma_i^2+\\lambda^2)^4} - \\sum_{i=1}^{r} \\frac{\\sigma^2\\sigma_i^2(\\sigma_i^2-3\\lambda^2)}{(\\sigma_i^2+\\lambda^2)^3}}$$\n此表达式符合要求的项：$\\{\\sigma_i\\}_{i=1}^r$、$\\{w_i\\}_{i=1}^r$、$\\sigma^2$ 和当前迭代值 $\\lambda$。",
            "answer": "$$\\boxed{\\lambda - \\frac{\\sum_{i=1}^{r} \\frac{\\lambda^{3}\\sigma_{i}^{2} w_{i}^{2}}{(\\sigma_{i}^{2} + \\lambda^{2})^{3}} - \\sum_{i=1}^{r} \\frac{\\lambda\\sigma^{2}\\sigma_{i}^{2}}{(\\sigma_{i}^{2} + \\lambda^{2})^{2}}}{\\sum_{i=1}^{r} \\frac{3\\lambda^{2}\\sigma_{i}^{2}w_{i}^{2}(\\sigma_{i}^{2}-\\lambda^{2})}{(\\sigma_{i}^{2}+\\lambda^{2})^{4}} - \\sum_{i=1}^{r} \\frac{\\sigma^{2}\\sigma_{i}^{2}(\\sigma_{i}^{2}-3\\lambda^{2})}{(\\sigma_{i}^{2}+\\lambda^{2})^{3}}}}$$"
        }
    ]
}