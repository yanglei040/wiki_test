{
    "hands_on_practices": [
        {
            "introduction": "理论学习之后，最好的消化方式就是动手实践。我们从一个最简单的情形入手，将 Landweber 迭代应用于一个标量线性方程。通过这个基础练习 ，你可以熟悉迭代公式的计算流程，直观地感受解是如何一步步逼近真值的，为后续处理更复杂的矩阵问题打下坚实的基础。",
            "id": "539080",
            "problem": "考虑 Landweber 迭代，这是一种用于求解形如 $A\\mathbf{x} = \\mathbf{b}$ 的线性方程组的迭代正则化方法。对于标量方程 $a x = b$（其中 $a, b \\in \\mathbb{R}$），其迭代格式定义为：\n$$\nx_{k+1} = x_k + \\tau a (b - a x_k),\n$$\n其中 $\\tau$ 是步长，而 $x_k$ 表示第 $k$ 次的迭代结果。\n\n给定标量方程 $2x = 3$，使用步长为 $\\tau = \\frac{1}{4}$ 和初始猜测为 $x_0 = 0$ 的 Landweber 迭代，计算第一次迭代的结果 $x_1$。给出 $x_1$ 的精确值。",
            "solution": "1. 针对标量问题 $a x = b$ 的 Landweber 迭代是\n$$\nx_{k+1} \\;=\\; x_k \\;+\\; \\tau\\,a\\,(b - a\\,x_k).\n$$\n2. 对于 $a=2$，$b=3$，$\\tau=\\tfrac14$ 以及 $x_0=0$，我们有\n$$\nb - a\\,x_0 = 3 - 2\\cdot 0 = 3.\n$$\n3. 因此\n$$\nx_1 = x_0 + \\tau\\,a\\,(b - a\\,x_0)\n    = 0 + \\frac14\\cdot 2\\cdot 3\n    = \\frac{6}{4}\n    = \\frac{3}{2}.\n$$",
            "answer": "$$\\boxed{3/2}$$"
        },
        {
            "introduction": "掌握了基本迭代步骤后，下一个关键问题是：迭代过程一定会收敛吗？步长 $ \\omega $ 的选择至关重要。这个练习  将引导你探究 Landweber 迭代的收敛边界，通过构造一个特定的例子，你会亲眼看到当步长超出理论允许的范围时，迭代误差是如何被放大的，从而深刻理解步长选择条件的理论依据和实践意义。",
            "id": "3372411",
            "problem": "考虑一个有限维欧几里得空间中的线性逆问题，其数据模型为 $y = A x^{\\ast}$，其中 $A \\in \\mathbb{R}^{2 \\times 2}$ 且真实状态为 $x^{\\ast} \\in \\mathbb{R}^{2}$。用于估计 $x^{\\ast}$ 的 Landweber 迭代定义为 $x_{k+1} = x_{k} + \\omega A^{\\top} \\big( y - A x_{k} \\big)$，其中 $\\omega  0$ 是一个固定的步长。对向量使用标准的欧几里得范数，对矩阵使用诱导算子范数，因此 $\\|A\\|$ 等于 $A$ 的最大奇异值。\n\n构建一个满足以下条件的具体示例：\n- 对于某个 $\\sigma  0$，$A = \\sigma u v^{\\top}$，其中 $u, v \\in \\mathbb{R}^{2}$ 是单位向量，\n- 选择 $u = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ 和 $v = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$，使得 $A = \\begin{pmatrix} \\sigma  0 \\\\ 0  0 \\end{pmatrix}$ 有一个等于 $\\|A\\| = \\sigma$ 的正奇异值，而另一个奇异值为零，\n- 设定数据为 $y = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，使得最小范数解为 $x^{\\dagger} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，\n- 将迭代初始化为 $x_{0} = v = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$，\n- 并选择步长为 $\\omega = \\dfrac{3}{\\|A\\|^{2}}$。\n\n从 Landweber 迭代的基本定义和奇异值分解（SVD）的性质出发，推导沿非零奇异方向的单步误差递推关系，并计算相应标量放大因子的幅值。你的最终答案必须是等于该幅值的单个实数。无需四舍五入。",
            "solution": "问题陈述经确认为具有科学依据、适定的、客观的且自洽的。确定唯一解所需的所有信息均已提供。\n\n线性逆问题由数据模型 $y = A x^{\\ast}$ 给出，其中 $y \\in \\mathbb{R}^{2}$ 是观测数据，$A \\in \\mathbb{R}^{2 \\times 2}$ 是正演算子，$x^{\\ast} \\in \\mathbb{R}^{2}$ 是待估计的真实状态。Landweber 迭代用于寻找 $x^{\\ast}$ 的一个估计 $x_k$，并由以下递推关系定义：\n$$\nx_{k+1} = x_{k} + \\omega A^{\\top} \\big( y - A x_{k} \\big)\n$$\n其中 $k$ 是迭代指数，$x_0$ 是初始猜测值，$\\omega  0$ 是一个固定的步长（松弛参数），$A^{\\top}$ 是 $A$ 的转置。\n\n该迭代的收敛性分析是通过研究误差向量的演化来进行的，误差向量定义为 $e_k = x_k - x^{\\dagger}$，其中 $x^{\\dagger}$ 是所寻求的真实解。在本问题中，指定了 $y = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。$Ax=y$ 的所有解的集合是 $A$ 的零空间，记作 $\\text{ker}(A)$。最小范数解 $x^{\\dagger}$ 是 $\\text{ker}(A)$ 中具有最小欧几里得范数的元素。当 $A = \\begin{pmatrix} \\sigma  0 \\\\ 0  0 \\end{pmatrix}$ 且 $\\sigma0$ 时，方程 $Ax=y$ 变为 $\\begin{pmatrix} \\sigma  0 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，这意味着 $\\sigma x_1 = 0$，所以 $x_1=0$。解集为 $\\{ (0,c) \\mid c \\in \\mathbb{R} \\}$。当 $c=0$ 时得到最小范数解，因此 $x^{\\dagger} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。因此，误差向量就是 $e_k = x_k$。\n\n我们现在可以推导误差递推关系。因为 $y = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ 且 $x^{\\dagger} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，我们有 $y = A x^{\\dagger}$。我们将此代入 Landweber 迭代公式中：\n$$\nx_{k+1} = x_k + \\omega A^{\\top} (A x^{\\dagger} - A x_k)\n$$\n从等式两边减去 $x^{\\dagger}$ 得到：\n$$\nx_{k+1} - x^{\\dagger} = x_k - x^{\\dagger} - \\omega A^{\\top} A (x_k - x^{\\dagger})\n$$\n这就得到了误差传播方程：\n$$\ne_{k+1} = e_k - \\omega A^{\\top} A e_k = \\left(I - \\omega A^{\\top} A\\right) e_k\n$$\n其中 $I$ 是 $2 \\times 2$ 单位矩阵。矩阵 $G = I - \\omega A^{\\top} A$ 是误差传播算子。\n\n问题的行为最好在由 $A$ 的奇异值分解（SVD）定义的坐标系中进行分析。设 $A$ 的 SVD 为 $A = U \\Sigma V^{\\top}$，其中 $U$ 和 $V$ 是正交矩阵，其列分别为左奇异向量和右奇异向量，而 $\\Sigma$ 是由奇异值 $\\sigma_j$ 构成的对角矩阵。右奇异向量 $\\{v_j\\}$ 构成了定义域 $\\mathbb{R}^2$ 的一个标准正交基。它们是 $A^{\\top} A$ 的特征向量，因为 $A^{\\top} A = (V \\Sigma^{\\top} U^{\\top}) (U \\Sigma V^{\\top}) = V (\\Sigma^{\\top} \\Sigma) V^{\\top}$。矩阵 $\\Sigma^{\\top} \\Sigma$ 是一个对角线上元素为 $\\sigma_j^2$ 的对角矩阵。因此，$A^{\\top} A v_j = \\sigma_j^2 v_j$。\n\n误差传播算子 $G$ 作用于右奇异向量 $v_j$ 的方式如下：\n$$\nG v_j = (I - \\omega A^{\\top} A) v_j = I v_j - \\omega (A^{\\top} A v_j) = v_j - \\omega \\sigma_j^2 v_j = (1 - \\omega \\sigma_j^2) v_j\n$$\n这表明 $A$ 的右奇异向量 $v_j$ 也是误差传播算子 $G$ 的特征向量。对应的特征值为 $\\lambda_j = 1 - \\omega \\sigma_j^2$。如果第 $k$ 步的误差有沿 $v_j$ 方向的分量，记作 $\\alpha_{k,j} v_j$，那么在第 $k+1$ 步，这个分量变为 $\\alpha_{k+1,j} v_j = \\lambda_j (\\alpha_{k,j} v_j)$。因此，值 $\\lambda_j$ 是 $v_j$ 方向上误差分量的标量放大因子。\n\n问题提供了具体的值。矩阵为 $A = \\begin{pmatrix} \\sigma  0 \\\\ 0  0 \\end{pmatrix}$，其中 $\\sigma  0$。奇异值为 $\\sigma_1 = \\sigma$ 和 $\\sigma_2 = 0$。对应的右奇异向量可选择为 $v_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ 和 $v_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。算子范数为 $\\|A\\| = \\max(\\sigma_1, \\sigma_2) = \\sigma$。\n\n“非零奇异方向”对应于奇异值 $\\sigma_1 = \\sigma$。问题要求计算沿此方向的标量放大因子，即 $\\lambda_1 = 1 - \\omega \\sigma_1^2 = 1 - \\omega \\sigma^2$。\n\n给定的步长为 $\\omega = \\dfrac{3}{\\|A\\|^{2}}$。因为 $\\|A\\| = \\sigma$，我们有 $\\omega = \\dfrac{3}{\\sigma^2}$。\n\n将此 $\\omega$ 值代入放大因子的表达式中：\n$$\n\\lambda_1 = 1 - \\left(\\frac{3}{\\sigma^2}\\right) \\sigma^2 = 1 - 3 = -2\n$$\n沿非零奇异方向的误差分量的标量放大因子为 $-2$。\n\n问题要求计算此标量放大因子的幅值。\n$$\n| \\lambda_1 | = | -2 | = 2\n$$\n这个结果表明，在每次迭代中，沿第一个奇异向量方向的误差分量被放大了 $2$ 倍，导致迭代发散。这是预料之中的，因为所提供的步长 $\\omega = \\frac{3}{\\|A\\|^2}$ 在 Landweber 迭代的标准收敛区间 $0  \\omega  \\frac{2}{\\|A\\|^2}$ 之外。",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "在实践中，选择一个固定的最优步长可能很困难，特别是当算子 $A$ 的范数难以估计时。一个更强大的策略是采用自适应步长，在每一步迭代中都计算当前的最优步长。这个编程实践  将指导你推导并实现“精确线搜索” Landweber 迭代法，并将其与固定步长法进行比较，让你在实践中体会自适应方法的优势，并锻炼解决反问题的编程能力。",
            "id": "3395628",
            "problem": "考虑一个有限维实希尔伯特空间中的线性反问题，其中给定一个矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和带噪数据 $y^\\delta \\in \\mathbb{R}^m$，需要最小化关于 $x \\in \\mathbb{R}^n$ 的二次数据失配泛函 $J(x) = \\tfrac{1}{2}\\lVert A x - y^\\delta \\rVert_2^2$。Landweber 迭代是针对此二次目标函数的梯度下降法，其基于一个基本恒等式，即 $J$ 的梯度为 $\\nabla J(x) = A^\\ast (A x - y^\\delta)$，其中 $A^\\ast$ 表示 $A$ 的伴随（转置）。从一个初始猜测 $x_0$ 开始，具有固定步长 $\\omega$ 的经典 Landweber 更新为 $x_{k+1} = x_k - \\omega A^\\ast (A x_k - y^\\delta)$，一个标准的收敛充分条件是 $0  \\omega  \\tfrac{2}{\\lVert A \\rVert_2^2}$，其中 $\\lVert A \\rVert_2$ 是谱范数（最大奇异值）。另一种方法是使用精确线搜索步长，该方法在每次迭代时选择 $\\omega_k$ 以最小化一维函数 $\\phi_k(\\omega) = \\lVert A(x_k - \\omega A^\\ast r_k) - y^\\delta \\rVert_2^2$，其中 $r_k = A x_k - y^\\delta$。\n\n您的任务是：\n- 从第一性原理推导 Landweber 迭代的精确线搜索步长选择 $\\omega_k = \\arg\\min_{\\omega \\in \\mathbb{R}} \\lVert A(x_k - \\omega A^\\ast r_k) - y^\\delta \\rVert_2^2$。实现此精确线搜索 Landweber 迭代，并将其与固定步长 Landweber 方法的实际性能进行比较。\n- 在您的实现中，对于固定步长方法，使用 $\\omega_{\\mathrm{fix}} = c \\, \\lVert A \\rVert_2^{-2}$（其中 $c$ 为给定常数），并通过检查 $\\omega_{\\mathrm{fix}}  \\tfrac{2}{\\lVert A \\rVert_2^2}$ 是否成立来验证理论稳定性条件。\n- 对于下述每个测试用例，使用初始猜测 $x_0 = 0$ 并运行指定次数的迭代。报告两种方法的最终数据失配范数 $\\lVert A x_K - y^\\delta \\rVert_2$。所有数值输出必须四舍五入到六位小数。\n\n测试套件定义如下。所有矩阵和数据都将按规定确定性地生成，所有随机数生成器均按指定设置种子，所有线性代数运算均在实数上执行：\n\n- 测试用例 1（良态方阵系统）：\n  - 维度：$m = 30$, $n = 30$。\n  - 矩阵：$A$ 的元素独立地从种子为 $0$ 的标准正态分布中抽取。\n  - 真值：$x^\\dagger \\in \\mathbb{R}^{30}$，其分量为 $x^\\dagger_i = i^{-2}$，其中 $i = 1, \\dots, 30$。\n  - 数据：$y = A x^\\dagger$。\n  - 噪声：加性噪声 $e$ 的元素独立地从种子为 $1$ 的标准正态分布中抽取，并进行缩放以满足 $\\lVert e \\rVert_2 = \\varepsilon \\lVert y \\rVert_2$，其中 $\\varepsilon = 10^{-3}$，得到 $y^\\delta = y + e$。\n  - 迭代次数：$K = 100$。\n  - 固定步长因子：$c = 1.0$，因此 $\\omega_{\\mathrm{fix}} = \\lVert A \\rVert_2^{-2}$。\n\n- 测试用例 2（病态高矩阵系统）：\n  - 维度：$m = 40$, $n = 30$。\n  - 矩阵：构造 $A = U \\Sigma V^\\top$，其中 $U \\in \\mathbb{R}^{40 \\times 40}$ 和 $V \\in \\mathbb{R}^{30 \\times 30}$ 是从种子分别为 $2$（用于 $U$）和 $3$（用于 $V$）的标准正态矩阵的简约 QR 分解中获得的正交矩阵。使用在 $1$ 和 $10^{-6}$ 之间对数等距分布的 $r = \\min(m,n) = 30$ 个奇异值 $\\sigma_j$（降序排列），使得 $\\Sigma = \\mathrm{diag}(\\sigma_1, \\dots, \\sigma_{30})$，并设置 $A = U_{:,1:r} \\Sigma V_{:,1:r}^\\top$。\n  - 真值：$x^\\dagger \\in \\mathbb{R}^{30}$，其分量为 $x^\\dagger_i = i^{-2}$。\n  - 数据和噪声：与测试用例 $1$ 相同，其中 $y = A x^\\dagger$，相对噪声水平 $\\varepsilon = 10^{-3}$，噪声使用种子 $4$。\n  - 迭代次数：$K = 200$。\n  - 固定步长因子：$c = 1.8$，因此 $\\omega_{\\mathrm{fix}} = 1.8 \\, \\lVert A \\rVert_2^{-2}$。\n\n- 测试用例 3（秩亏欠定系统）：\n  - 维度：$m = 30$, $n = 40$，目标秩 $r = 20$。\n  - 矩阵：构造 $A = U \\Sigma V^\\top$，其中 $U \\in \\mathbb{R}^{30 \\times 30}$ 和 $V \\in \\mathbb{R}^{40 \\times 40}$ 是从种子分别为 $5$（用于 $U$）和 $6$（用于 $V$）的标准正态矩阵的简约 QR 分解中获得的正交矩阵。使用在 $1$ 和 $10^{-4}$ 之间对数等距分布的 $r = 20$ 个奇异值 $\\sigma_j$（降序排列），并定义 $A = U_{:,1:r} \\Sigma V_{:,1:r}^\\top$，其秩为 $r$。\n  - 真值：$x^\\dagger \\in \\mathbb{R}^{40}$，其分量为 $x^\\dagger_i = i^{-2}$。\n  - 数据和噪声：与测试用例 $1$ 相同，其中 $y = A x^\\dagger$，相对噪声水平 $\\varepsilon = 10^{-3}$，噪声使用种子 $7$。\n  - 迭代次数：$K = 200$。\n  - 固定步长因子：$c = 1.0$，因此 $\\omega_{\\mathrm{fix}} = \\lVert A \\rVert_2^{-2}$。\n\n- 测试用例 4（使用对角系统的稳定性边界检查）：\n  - 维度：$m = n = 3$。\n  - 矩阵：$A = \\mathrm{diag}(3.0, 1.0, 0.5)$。\n  - 真值：$x^\\dagger = [1, -2, 3]^\\top$。\n  - 数据：$y^\\delta = y = A x^\\dagger$（无噪声）。\n  - 迭代次数：$K = 25$。\n  - 固定步长因子：$c = 2.2$，因此 $\\omega_{\\mathrm{fix}} = 2.2 \\, \\lVert A \\rVert_2^{-2}$，这超过了理论上界 $\\tfrac{2}{\\lVert A \\rVert_2^2}$。\n\n实现要求：\n- 实现固定步长 Landweber 和精确线搜索 Landweber 两种方法。对于精确线搜索，在每次迭代 $k$ 中，仅基于 $A$、$r_k$ 和 $A^\\ast r_k$，推导并实现 $\\phi_k(\\omega)$ 最小化子 $\\omega_k$ 的闭式表达式。\n- 对于测试用例 1–3，为每个用例报告：\n  1. 使用精确线搜索 Landweber 的最终数据失配范数 $\\lVert A x_K^{\\mathrm{els}} - y^\\delta \\rVert_2$（四舍五入到六位小数）。\n  2. 使用固定步长 Landweber 的最终数据失配范数 $\\lVert A x_K^{\\mathrm{fix}} - y^\\delta \\rVert_2$（四舍五入到六位小数）。\n  3. 一个布尔值，指示理论上的固定步长稳定性条件 $\\omega_{\\mathrm{fix}}  \\tfrac{2}{\\lVert A \\rVert_2^2}$ 是否成立。\n- 对于测试用例 4，报告：\n  1. 一个布尔值，指示 $\\omega_{\\mathrm{fix}} > \\tfrac{2}{\\lVert A \\rVert_2^2}$ 是否成立。\n  2. 一个布尔值，指示固定步长 Landweber 的残差范数 $\\lVert A x_k^{\\mathrm{fix}} - y^\\delta \\rVert_2$ 在 $K$ 次迭代中是否未能单调非增（当步长超过界限时，这应为真）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须按以下顺序汇总所有测试用例的结果：\n  - 测试用例 1：[$\\lVert A x_K^{\\mathrm{els}} - y^\\delta \\rVert_2$, $\\lVert A x_K^{\\mathrm{fix}} - y^\\delta \\rVert_2$, stable]\n  - 测试用例 2：[$\\lVert A x_K^{\\mathrm{els}} - y^\\delta \\rVert_2$, $\\lVert A x_K^{\\mathrm{fix}} - y^\\delta \\rVert_2$, stable]\n  - 测试用例 3：[$\\lVert A x_K^{\\mathrm{els}} - y^\\delta \\rVert_2$, $\\lVert A x_K^{\\mathrm{fix}} - y^\\delta \\rVert_2$, stable]\n  - 测试用例 4：[above_bound, nonmonotone]\n- 最终列表被展平为一个包含 $11$ 个条目的单一列表：测试用例 1-3 各有三个浮点数和一个布尔值，测试用例 4 有两个布尔值。所有浮点数必须四舍五入到六位小数。例如：$[f_{1,\\mathrm{els}}, f_{1,\\mathrm{fix}}, \\mathrm{stable}_1, f_{2,\\mathrm{els}}, f_{2,\\mathrm{fix}}, \\mathrm{stable}_2, f_{3,\\mathrm{els}}, f_{3,\\mathrm{fix}}, \\mathrm{stable}_3, \\mathrm{above\\_bound}_4, \\mathrm{nonmonotone}_4]$。",
            "solution": "该问题要求推导并实现用于求解线性反问题的精确线搜索 Landweber 迭代，并将其与固定步长变体进行比较。\n\n该问题被表述为最小化数据失配泛函 $J(x) = \\frac{1}{2}\\lVert A x - y^\\delta \\rVert_2^2$，其中 $x \\in \\mathbb{R}^n$ 是待恢复的参数向量，$A \\in \\mathbb{R}^{m \\times n}$ 是正演算子（矩阵），$y^\\delta \\in \\mathbb{R}^m$ 是带噪数据。Landweber 迭代是应用于此目标函数的梯度下降法。$J(x)$ 关于 $x$ 的梯度由 $\\nabla J(x) = A^\\ast (A x - y^\\delta)$ 给出，其中 $A^\\ast$ 是 $A$ 的伴随（转置）。\n\n迭代的一般形式是 $x_{k+1} = x_k - \\omega_k \\nabla J(x_k)$，其中 $\\omega_k$ 是第 $k$ 次迭代的步长。令 $r_k = A x_k - y^\\delta$ 为第 $k$ 次迭代的残差。梯度可以写成 $\\nabla J(x_k) = A^\\ast r_k$。因此，Landweber 更新为 $x_{k+1} = x_k - \\omega_k A^\\ast r_k$。\n\n考虑了两种步长 $\\omega_k$ 的选择：\n1.  **固定步长 Landweber**：$\\omega_k = \\omega$ 是一个常数。为了使迭代收敛到 $J(x)$ 的一个最小化子，对步长的一个充分条件是 $0  \\omega  \\frac{2}{\\lVert A \\rVert_2^2}$，其中 $\\lVert A \\rVert_2$ 是 $A$ 的谱范数。问题指定使用 $\\omega_{\\mathrm{fix}} = c \\, \\lVert A \\rVert_2^{-2}$，其中 $c$ 为给定常数。此时，稳定性条件等价于 $0  c  2$。\n\n2.  **精确线搜索 Landweber**：在每次迭代 $k$ 中，选择步长 $\\omega_k$ 以沿搜索方向 $- \\nabla J(x_k)$ 最小化目标泛函。也就是说，我们寻找 $\\omega_k$ 来最小化 $J(x_{k+1}) = J(x_k - \\omega A^\\ast r_k)$。这等价于最小化问题描述中定义的一维函数 $\\phi_k(\\omega)$：\n    $$\n    \\omega_k = \\arg\\min_{\\omega \\in \\mathbb{R}} \\phi_k(\\omega) = \\arg\\min_{\\omega \\in \\mathbb{R}} \\lVert A(x_k - \\omega A^\\ast r_k) - y^\\delta \\rVert_2^2\n    $$\n\n**精确线搜索步长 $\\omega_k$ 的推导**\n\n为了找到最优的 $\\omega_k$，我们求解 $\\phi_k(\\omega)$ 的最小化问题。\n首先，我们使用残差的定义 $r_k = A x_k - y^\\delta$ 来重写范数内的表达式：\n$$\nA(x_k - \\omega A^\\ast r_k) - y^\\delta = (A x_k - y^\\delta) - \\omega A A^\\ast r_k = r_k - \\omega A A^\\ast r_k\n$$\n因此，我们需要最小化 $\\phi_k(\\omega) = \\lVert r_k - \\omega A A^\\ast r_k \\rVert_2^2$。\n这是一个关于标量变量 $\\omega$ 的标准线性最小二乘问题。我们可以通过展开平方范数并将其关于 $\\omega$ 的导数设为零来找到最小值。平方范数是向量与其自身的内积：\n$$\n\\phi_k(\\omega) = \\langle r_k - \\omega A A^\\ast r_k, r_k - \\omega A A^\\ast r_k \\rangle\n$$\n展开内积：\n$$\n\\phi_k(\\omega) = \\langle r_k, r_k \\rangle - 2\\omega \\langle r_k, A A^\\ast r_k \\rangle + \\omega^2 \\langle A A^\\ast r_k, A A^\\ast r_k \\rangle\n$$\n利用伴随的性质 $\\langle u, Av \\rangle = \\langle A^\\ast u, v \\rangle$，中间项可以简化：\n$$\n\\langle r_k, A A^\\ast r_k \\rangle = \\langle A^\\ast r_k, A^\\ast r_k \\rangle = \\lVert A^\\ast r_k \\rVert_2^2\n$$\n$\\phi_k(\\omega)$ 的表达式变成一个关于 $\\omega$ 的二次式：\n$$\n\\phi_k(\\omega) = \\lVert r_k \\rVert_2^2 - 2\\omega \\lVert A^\\ast r_k \\rVert_2^2 + \\omega^2 \\lVert A A^\\ast r_k \\rVert_2^2\n$$\n为了找到最小值，我们对 $\\omega$ 求导并令其为零：\n$$\n\\frac{d\\phi_k}{d\\omega} = -2 \\lVert A^\\ast r_k \\rVert_2^2 + 2\\omega \\lVert A A^\\ast r_k \\rVert_2^2 = 0\n$$\n解出 $\\omega$ 得到最优步长 $\\omega_k$：\n$$\n\\omega_k = \\frac{\\lVert A^\\ast r_k \\rVert_2^2}{\\lVert A A^\\ast r_k \\rVert_2^2}\n$$\n这是精确线搜索步长的闭式表达式。分母为零当且仅当 $A A^\\ast r_k = 0$。这意味着 $\\langle A A^\\ast r_k, r_k \\rangle = \\lVert A^\\ast r_k \\rVert_2^2 = 0$，即分子也为零。这发生在梯度 $\\nabla J(x_k) = A^\\ast r_k$ 为零时，表明 $x_k$ 已经是一个驻点（正规方程的一个解），迭代已经收敛。在数值实现中，如果分母为零（或数值上接近于零），步长可以设置为 $0$。\n\n**实现策略**\n该解决方案使用 `numpy` 库在 Python 中实现。每个测试用例的流程如下：\n1.  **问题设置**：根据每个测试用例的规范生成矩阵 $A$、真值向量 $x^\\dagger$ 和数据 $y^\\delta$。这包括使用特定种子创建随机矩阵，从给定的奇异值分解构造矩阵，生成噪声并将其缩放到所需的相对水平。\n2.  **算法实现**：\n    - **固定步长 Landweber**：使用初始猜测 $x_0 = 0$。计算固定步长 $\\omega_{\\mathrm{fix}} = c / \\lVert A \\rVert_2^2$，其中 $\\lVert A \\rVert_2$ 使用 `np.linalg.norm(A, 2)` 确定。然后对迭代 $x_{k+1} = x_k - \\omega_{\\mathrm{fix}} A^\\top (A x_k - y^\\delta)$ 运行指定的迭代次数 $K$。\n    - **精确线搜索 Landweber**：从 $x_0 = 0$ 开始，执行迭代 $x_{k+1} = x_k - \\omega_k A^\\top (A x_k - y^\\delta)$ 共 $K$ 步。在每一步 $k$，使用推导出的公式 $\\omega_k = \\lVert A^\\top r_k \\rVert_2^2 / \\lVert A A^\\top r_k \\rVert_2^2$ 计算最优步长 $\\omega_k$。\n3.  **结果评估**：\n    - 对于测试用例 1-3，计算两种方法的最终数据失配范数 $\\lVert A x_K - y^\\delta \\rVert_2$。评估固定步长方法的稳定性条件 $c  2$。\n    - 对于测试用例 4，使用步长因子 $c > 2$ 测试固定步长方法，这违反了稳定性条件。检查布尔条件 $c > 2$。存储残差范数序列 $\\{\\lVert A x_k - y^\\delta \\rVert_2\\}_{k=0}^K$，并检查该序列是否未能单调非增，即是否存在任何 $k \\in \\{0, \\dots, K-1\\}$ 使得 $\\lVert r_{k+1} \\rVert_2 > \\lVert r_k \\rVert_2$。\n4.  **输出格式化**：将所有测试用例的结果收集到一个单一列表中。浮点数格式化为六位小数，并以指定的逗号分隔格式打印列表。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares fixed-step and exact line-search Landweber iterations\n    for several linear inverse problems.\n    \"\"\"\n    \n    test_cases_params = [\n        # Test Case 1: well-conditioned square system\n        {'m': 30, 'n': 30, 'seed_A': 0, 'seed_noise': 1, 'eps': 1e-3, 'K': 100, 'c': 1.0, 'type': 'randn'},\n        # Test Case 2: ill-conditioned tall system\n        {'m': 40, 'n': 30, 'r': 30, 'sv_range': (1.0, 1e-6), 'seed_U': 2, 'seed_V': 3, 'seed_noise': 4, 'eps': 1e-3, 'K': 200, 'c': 1.8, 'type': 'svd'},\n        # Test Case 3: rank-deficient underdetermined system\n        {'m': 30, 'n': 40, 'r': 20, 'sv_range': (1.0, 1e-4), 'seed_U': 5, 'seed_V': 6, 'seed_noise': 7, 'eps': 1e-3, 'K': 200, 'c': 1.0, 'type': 'svd'},\n        # Test Case 4: stability boundary check\n        {'m': 3, 'n': 3, 'A': np.diag([3.0, 1.0, 0.5]), 'x_dagger': np.array([1.0, -2.0, 3.0]), 'eps': 0.0, 'K': 25, 'c': 2.2, 'type': 'diag'}\n    ]\n\n    all_results = []\n\n    for i, params in enumerate(test_cases_params):\n        m, n, K, c, eps = params['m'], params['n'], params['K'], params['c'], params['eps']\n        \n        # Generate problem data (A, x_dagger, y_delta)\n        if params['type'] == 'randn':\n            rng_A = np.random.default_rng(params['seed_A'])\n            A = rng_A.standard_normal((m, n))\n            x_dagger = 1.0 / np.arange(1, n + 1)**2\n            y = A @ x_dagger\n            if eps > 0:\n                rng_noise = np.random.default_rng(params['seed_noise'])\n                e = rng_noise.standard_normal(m)\n                y_delta = y + e * (eps * np.linalg.norm(y) / np.linalg.norm(e))\n            else:\n                y_delta = y\n        elif params['type'] == 'svd':\n            r = params['r']\n            sv_start, sv_end = params['sv_range']\n            \n            rng_U = np.random.default_rng(params['seed_U'])\n            U, _ = np.linalg.qr(rng_U.standard_normal((m, m)))\n            \n            rng_V = np.random.default_rng(params['seed_V'])\n            V, _ = np.linalg.qr(rng_V.standard_normal((n, n)))\n            \n            sigmas = np.logspace(np.log10(sv_start), np.log10(sv_end), r)\n            Sigma = np.diag(sigmas)\n            \n            A = U[:, :r] @ Sigma @ V[:, :r].T\n\n            x_dagger = 1.0 / np.arange(1, n + 1)**2\n            y = A @ x_dagger\n            if eps > 0:\n                rng_noise = np.random.default_rng(params['seed_noise'])\n                e = rng_noise.standard_normal(m)\n                y_delta = y + e * (eps * np.linalg.norm(y) / np.linalg.norm(e))\n            else:\n                y_delta = y\n        elif params['type'] == 'diag':\n            A = params['A']\n            x_dagger = params['x_dagger']\n            y_delta = A @ x_dagger\n            \n        # Spectral norm of A\n        if params['type'] == 'svd':\n            norm_A = params['sv_range'][0]\n        else:\n            norm_A = np.linalg.norm(A, 2)\n\n        x0 = np.zeros(n)\n\n        # ----- Fixed-step Landweber -----\n        x_fix = np.copy(x0)\n        omega_fix = c / norm_A**2\n        \n        residuals_fix_norms = []\n        if i == 3: # For Test Case 4\n            residuals_fix_norms.append(np.linalg.norm(A @ x_fix - y_delta))\n        \n        for _ in range(K):\n            r_fix = A @ x_fix - y_delta\n            x_fix = x_fix - omega_fix * (A.T @ r_fix)\n            if i == 3:\n                residuals_fix_norms.append(np.linalg.norm(A @ x_fix - y_delta))\n\n        # ----- Exact Line-Search Landweber -----\n        x_els = np.copy(x0)\n        for _ in range(K):\n            r_els = A @ x_els - y_delta\n            grad = A.T @ r_els\n            A_grad = A @ grad\n            \n            num = np.dot(grad, grad)\n            den = np.dot(A_grad, A_grad)\n            \n            omega_els = num / den if den > 1e-15 else 0.0\n            \n            x_els = x_els - omega_els * grad\n\n        # Collect and format results for the current test case\n        if i  3: # Test Cases 1, 2, 3\n            misfit_els = np.linalg.norm(A @ x_els - y_delta)\n            misfit_fix = np.linalg.norm(A @ x_fix - y_delta)\n            stable = (c  2.0)\n            all_results.extend([misfit_els, misfit_fix, stable])\n        else: # Test Case 4\n            above_bound = (c > 2.0)\n            is_nonmonotone = False\n            for j in range(len(residuals_fix_norms) - 1):\n                if residuals_fix_norms[j+1] > residuals_fix_norms[j]:\n                    is_nonmonotone = True\n                    break\n            all_results.extend([above_bound, is_nonmonotone])\n    \n    # Format the final output string\n    final_output_list = []\n    for item in all_results:\n        if isinstance(item, float):\n            final_output_list.append(f\"{item:.6f}\")\n        else:\n            final_output_list.append(str(item).lower())\n            \n    print(f\"[{','.join(final_output_list)}]\")\n\nsolve()\n```"
        }
    ]
}