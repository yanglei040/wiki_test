{
    "hands_on_practices": [
        {
            "introduction": "本章的实践始于一个基础但至关重要的编码练习，旨在从头开始构建三维变分（3D-Var）系统的核心。通过为一个假设的一维扩散状态建立并求解正规方程，您将直接体验背景信息和观测信息是如何通过各自的误差协方差加权并融合成单一最优分析场的。这项实践不仅巩固了对 3D-Var 成本函数最小化的理论理解，还揭示了背景误差协方差模型在平滑分析场和在观测稀疏区域传播信息方面的关键作用 。",
            "id": "3427113",
            "problem": "考虑一个一维状态估计问题，该问题构建在三维变分同化（3D-Var）框架下。其中，三维变分（3D-Var）指的是一种变分方法，它通过最小化一个结合了背景项和观测项的代价泛函，来计算单个时刻的分析场。设状态为一个网格向量 $x \\in \\mathbb{R}^n$。假设背景先验为高斯分布，其精度（协方差逆）由 $B^{-1} = \\alpha I - \\beta D^{T}D$ 给出，其中 $I$ 是大小为 $n \\times n$ 的单位矩阵，$\\alpha > 0$ 和 $\\beta \\ge 0$ 是标量，其选择应确保 $B^{-1}$ 是正定的，$D \\in \\mathbb{R}^{(n-1)\\times n}$ 是一阶前向差分算子，定义为对于 $i = 1,\\dots,n-1$，$D_{i,i} = -1$ 且 $D_{i,i+1} = 1$，所有其他元素均为 $0$。观测是点测量，由一个选择特定网格点的线性算子 $H \\in \\mathbb{R}^{m \\times n}$ 建模，观测误差是独立的，其协方差 $R \\in \\mathbb{R}^{m \\times m}$ 为对角矩阵，且对角线元素严格为正。\n\n从高斯先验和线性高斯观测模型的基本假设出发，通过最小化由这些假设推导出的 3D-Var 代价泛函，推导出分析状态 $x_a$ 必须满足的线性系统。实现一个程序，对于下述每个测试用例，根据提供的参数构造 $D$、$B^{-1}$、$H$ 和 $R$，求解 $x_a$，并使用由下式定义的离散粗糙度度量来定量评估后验平滑度：\n$$\n\\mathcal{R}(x) = x^{T} D^{T} D\\, x = \\sum_{i=1}^{n-1} \\left(x_{i+1} - x_i\\right)^2.\n$$\n将平滑比定义为\n$$\nS = \\frac{\\mathcal{R}(x_a)}{\\mathcal{R}(x_b)},\n$$\n其中 $x_b$ 是该测试用例的背景状态。对于所有情况，确保 $B^{-1}$ 是正定的。\n\n您的程序必须处理以下代表不同信息含量和条件状况的测试套件：\n\n- 测试用例 1（一般情况）：$n = 6$，$\\alpha = 3.0$，$\\beta = 0.5$，背景场 $x_b = [0.0, 1.0, 1.5, 1.0, 0.5, 0.0]$，观测索引（从零开始）$\\{1,3,4\\}$，观测值 $y = [1.1, 0.9, 0.4]$，$R$ 对角线上的观测方差为 $[0.04, 0.01, 0.09]$。\n- 测试用例 2（无观测边界情况）：$n = 6$，$\\alpha = 3.0$，$\\beta = 0.5$，背景场 $x_b = [0.0, 1.0, 1.5, 1.0, 0.5, 0.0]$，无观测（$m = 0$），$H$ 是空矩阵，不使用 $R$。\n- 测试用例 3（密集高置信度观测）：$n = 6$，$\\alpha = 3.0$，$\\beta = 0.5$，背景场 $x_b = [0.3, -0.1, 0.8, 1.2, 0.7, 0.2]$，观测索引 $\\{0,1,2,3,4,5\\}$，观测值 $y = [0.0, 2.0, -1.0, 2.0, -1.0, 0.0]$，观测方差 $[0.01, 0.01, 0.01, 0.01, 0.01, 0.01]$。\n- 测试用例 4（接近病态但正定）：$n = 6$，$\\alpha = 4.5$，$\\beta = 1.1$，背景场 $x_b = [0.0, 0.5, 1.0, 0.5, -0.2, -0.4]$，观测索引 $\\{2,5\\}$，观测值 $y = [1.3, -0.6]$，观测方差 $[0.02, 0.02]$。\n\n对于每个案例：\n1. 完全按照上述定义构造 $D$、$B^{-1}$、$H$ 和 $R$。\n2. 建立并求解 3D-Var 最小化所蕴含的正规方程组，以获得 $x_a$。\n3. 计算平滑比 $S$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是一个包含两个元素的列表：分析状态分量（作为浮点数列表，四舍五入到六位小数）和平滑比（四舍五入到六位小数）。最终输出格式必须为\n$$\n\\text{\"[[[x_{a,1},\\dots,x_{a,n}],S_1],[[x_{a,1},\\dots,x_{a,n}],S_2],[[x_{a,1},\\dots,x_{a,n}],S_3],[[x_{a,1},\\dots,x_{a,n}],S_4]]\"}\n$$\n其中每个 $x_{a,i}$ 和 $S_k$ 都是小数点后有六位数的小数表示。",
            "solution": "该问题具有科学依据，是适定的、客观的，并为标准的三维变分（3D-Var）数据同化练习提供了一个完整且一致的设置。每个测试用例的参数，包括对背景精度矩阵 $B^{-1}$ 正定性的验证，均已核实。该问题是有效的，并且可以按所述方式求解。\n\n3D-Var 方法的核心是最小化一个代价泛函 $J(x)$，该泛函平衡了与背景估计的距离和与观测的距离，并由它们各自的误差协方差加权。状态向量表示为 $x \\in \\mathbb{R}^n$。\n\n代价泛函 $J(x)$ 由两项组成：背景项 $J_b(x)$ 和观测项 $J_o(x)$。\n$$\nJ(x) = J_b(x) + J_o(x)\n$$\n在高斯误差分布的假设下，这些项由以下公式给出：\n$$\nJ_b(x) = \\frac{1}{2} (x - x_b)^T B^{-1} (x - x_b)\n$$\n$$\nJ_o(x) = \\frac{1}{2} (y - Hx)^T R^{-1} (y - Hx)\n$$\n在这里，$x_b \\in \\mathbb{R}^n$ 是背景状态向量，$B \\in \\mathbb{R}^{n \\times n}$ 是背景误差协方差矩阵，$y \\in \\mathbb{R}^m$ 是观测向量，$H \\in \\mathbb{R}^{m \\times n}$ 是将状态空间映射到观测空间的观测算子，而 $R \\in \\mathbb{R}^{m \\times m}$ 是观测误差协方差矩阵。问题提供了精度（协方差逆）矩阵 $B^{-1}$ 和 $R^{-1}$（通过其对角线）。\n\n最优分析状态 $x_a$ 是使代价泛函 $J(x)$ 最小化的状态向量 $x$。最小值的必要条件是 $J(x)$ 相对于 $x$ 的梯度为零。\n$$\n\\nabla_x J(x_a) = 0\n$$\n我们分别计算每一项的梯度。背景项的梯度是：\n$$\n\\nabla_x J_b(x) = \\nabla_x \\left( \\frac{1}{2} (x - x_b)^T B^{-1} (x - x_b) \\right)\n$$\n由于 $B^{-1}$ 是对称的，这可以简化为：\n$$\n\\nabla_x J_b(x) = B^{-1} (x - x_b)\n$$\n观测项的梯度是：\n$$\n\\nabla_x J_o(x) = \\nabla_x \\left( \\frac{1}{2} (y - Hx)^T R^{-1} (y - Hx) \\right) = \\nabla_x \\left( \\frac{1}{2}(x^T H^T R^{-1} H x - 2y^T R^{-1} H x + y^T R^{-1} y) \\right)\n$$\n由于 $R^{-1}$ 是对称的（它是一个对角矩阵），矩阵 $H^T R^{-1} H$ 也是对称的。梯度为：\n$$\n\\nabla_x J_o(x) = H^T R^{-1} H x - H^T R^{-1} y = H^T R^{-1} (Hx - y)\n$$\n将 $x=x_a$ 处的总梯度设为零，得到：\n$$\n\\nabla_x J(x_a) = B^{-1} (x_a - x_b) + H^T R^{-1} (Hx_a - y) = 0\n$$\n该方程可以重排，形成一个关于分析状态 $x_a$ 的线性系统：\n$$\nB^{-1} x_a - B^{-1} x_b + H^T R^{-1} H x_a - H^T R^{-1} y = 0\n$$\n$$\n(B^{-1} + H^T R^{-1} H) x_a = B^{-1} x_b + H^T R^{-1} y\n$$\n这就是 $x_a$ 必须满足的线性系统。令 Hessian 矩阵为 $A = (B^{-1} + H^T R^{-1} H)$，右侧向量为 $b = (B^{-1} x_b + H^T R^{-1} y)$。该系统为 $A x_a = b$。由于 $B^{-1}$ 是正定的，而 $H^T R^{-1} H$ 是半正定的，它们的和 $A$ 是正定的，因此是可逆的，从而保证了 $x_a$ 的唯一解。\n\n矩阵的构造如下：\n- 状态维度为 $n$。\n- 一阶前向差分算子 $D \\in \\mathbb{R}^{(n-1)\\times n}$ 的构造方式为，对于每一行 $i \\in \\{0, \\dots, n-2\\}$，$D_{i,i} = -1$，$D_{i,i+1} = 1$，所有其他元素均为 $0$。\n- 背景精度矩阵为 $B^{-1} = \\alpha I - \\beta D^T D$，其中 $I$ 是 $n \\times n$ 的单位矩阵。\n- 观测算子 $H \\in \\mathbb{R}^{m \\times n}$ 是一个选择矩阵，其中 $m$ 是观测数量。对于在网格点 $j_k$ 的每个观测 $k \\in \\{0, \\dots, m-1\\}$，$H$ 的对应行有 $H_{k, j_k} = 1$，所有其他元素均为 $0$。\n- 观测误差协方差 $R$ 是一个对角矩阵，其对角线元素是给定的观测方差。它的逆矩阵 $R^{-1}$ 也是对角的，其元素等于方差的倒数。\n\n求解出 $x_a$ 后，为分析场 $x_a$ 和背景场 $x_b$ 计算离散粗糙度 $\\mathcal{R}(x)$：\n$$\n\\mathcal{R}(x) = x^T D^T D x\n$$\n然后将平滑比 $S$ 计算为这些粗糙度值的比率：\n$$\nS = \\frac{\\mathcal{R}(x_a)}{\\mathcal{R}(x_b)}\n$$\n如果没有观测（$m=0$），$J_o$ 项消失，代价泛函变为 $J(x)=J_b(x)$，其最小值显然是 $x_a = x_b$。在这种情况下，$\\mathcal{R}(x_a) = \\mathcal{R}(x_b)$ 且 $S=1$。该实现处理了这种特殊情况。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the 3D-Var data assimilation problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"n\": 6, \"alpha\": 3.0, \"beta\": 0.5,\n            \"x_b\": np.array([0.0, 1.0, 1.5, 1.0, 0.5, 0.0]),\n            \"obs_indices\": [1, 3, 4], \"y\": np.array([1.1, 0.9, 0.4]),\n            \"obs_variances\": np.array([0.04, 0.01, 0.09])\n        },\n        {\n            \"n\": 6, \"alpha\": 3.0, \"beta\": 0.5,\n            \"x_b\": np.array([0.0, 1.0, 1.5, 1.0, 0.5, 0.0]),\n            \"obs_indices\": [], \"y\": np.array([]),\n            \"obs_variances\": np.array([])\n        },\n        {\n            \"n\": 6, \"alpha\": 3.0, \"beta\": 0.5,\n            \"x_b\": np.array([0.3, -0.1, 0.8, 1.2, 0.7, 0.2]),\n            \"obs_indices\": [0, 1, 2, 3, 4, 5],\n            \"y\": np.array([0.0, 2.0, -1.0, 2.0, -1.0, 0.0]),\n            \"obs_variances\": np.array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01])\n        },\n        {\n            \"n\": 6, \"alpha\": 4.5, \"beta\": 1.1,\n            \"x_b\": np.array([0.0, 0.5, 1.0, 0.5, -0.2, -0.4]),\n            \"obs_indices\": [2, 5], \"y\": np.array([1.3, -0.6]),\n            \"obs_variances\": np.array([0.02, 0.02])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        n = case[\"n\"]\n        alpha = case[\"alpha\"]\n        beta = case[\"beta\"]\n        x_b = case[\"x_b\"]\n        obs_indices = case[\"obs_indices\"]\n        y = case[\"y\"]\n        obs_variances = case[\"obs_variances\"]\n        m = len(obs_indices)\n\n        # 1. Construct matrices D, B_inv, H, R\n        D = np.zeros((n - 1, n))\n        for i in range(n - 1):\n            D[i, i] = -1.0\n            D[i, i + 1] = 1.0\n        \n        DtD = D.T @ D\n        B_inv = alpha * np.eye(n) - beta * DtD\n\n        # 2. Form the linear system Ax_a = b\n        if m > 0:\n            H = np.zeros((m, n))\n            for i, idx in enumerate(obs_indices):\n                H[i, idx] = 1.0\n            \n            R_inv = np.diag(1.0 / obs_variances)\n            \n            # (B_inv + H.T @ R_inv @ H) @ x_a = B_inv @ x_b + H.T @ R_inv @ y\n            A = B_inv + H.T @ R_inv @ H\n            b = B_inv @ x_b + H.T @ R_inv @ y\n        else: # No observations\n            A = B_inv\n            b = B_inv @ x_b\n\n        # 3. Solve for x_a\n        x_a = np.linalg.solve(A, b)\n        \n        # 4. Compute smoothing ratio S\n        roughness_xa = x_a.T @ DtD @ x_a\n        roughness_xb = x_b.T @ DtD @ x_b\n        \n        smoothing_ratio = 0.0\n        if roughness_xb > 1e-12: # Avoid division by zero\n            smoothing_ratio = roughness_xa / roughness_xb\n        \n        # 5. Format results as required\n        x_a_rounded = [round(val, 6) for val in x_a]\n        S_rounded = round(smoothing_ratio, 6)\n        \n        results.append([x_a_rounded, S_rounded])\n\n    # Final print statement in the exact required format\n    case_strings = [str(res).replace(\" \", \"\") for res in results]\n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "在实际的数据同化应用中，我们经常遇到需要满足物理约束的变量，例如必须为正值的湿度或化学示踪剂浓度。直接对这些变量进行增量更新可能会导致非物理的负值。本练习通过一个关键技术——控制变量变换来解决这一挑战，您将探索如何使用对数变换来确保分析结果的物理正定性，并推导这种非线性变换如何改变控制变量空间中的背景误差协方差 。",
            "id": "3427106",
            "problem": "考虑一个两点湿度状态 $q \\in \\mathbb{R}^{2}$，其分量严格为正。一个三维变分同化 (3D-Var) 系统使用对数控制变量 $z = \\log(q)$，其中对数是逐分量计算的。物理空间（湿度空间）中的背景场和协方差为\n$$\nq_{b} = \\begin{pmatrix} 5 \\times 10^{-3} \\\\ 1 \\times 10^{-2} \\end{pmatrix}, \n\\qquad\nB_{q} = \\begin{pmatrix}\n(2 \\times 10^{-3})^{2} & \\rho \\,(2 \\times 10^{-3})(3 \\times 10^{-3}) \\\\\n\\rho \\,(2 \\times 10^{-3})(3 \\times 10^{-3}) & (3 \\times 10^{-3})^{2}\n\\end{pmatrix},\n$$\n其中 $\\rho = 0.3$。可获得一个关于 $q$ 的第一个分量的标量观测：\n$$\ny = 6.0 \\times 10^{-3},\n$$\n其观测误差方差为\n$$\nR = (5 \\times 10^{-4})^{2}.\n$$\n物理空间中的观测算子为 $H(q) = [1 \\;\\; 0]\\, q$，而在控制空间中，它是复合函数 $h(z) = H(\\exp(z))$，其中 $\\exp(z)$ 是逐分量应用的。\n\n任务：\n1) 从变量变换在背景场处的一阶线性化出发，并利用线性映射下协方差的定义，推导控制空间中的背景协方差 $B_{z}$ 和 $B_{q}$ 之间的解析关系，然后根据给定的 $q_{b}$ 和 $B_{q}$ 数值计算 $B_{z}$。证明该变换保持正定性。\n\n2) 利用控制变量 $z$ 的 3D-Var 代价函数的定义以及观测算子 $h$ 在 $z_{b} = \\log(q_{b})$ 附近的一阶线性化，推导出关于 $z_{b}$ 的高斯-牛顿分析增量 $\\delta z$ 的表达式，该表达式应使用 $B_{z}$、雅可比矩阵 $H_{z} = \\left.\\frac{\\partial h}{\\partial z}\\right|_{z_{b}}$、观测误差协方差 $R$ 和新息 $d = y - h(z_{b})$ 来表示。根据以上数据数值计算 $\\delta z$。\n\n3) 通过 $q_{a} = \\exp(z_{b} + \\delta z)$ 将更新后的控制变量映射回物理空间，并推导出隐含的物理空间分析增量 $\\delta q = q_{a} - q_{b}$ 的闭式解。计算第一个分量 $\\delta q_1$ 的精确闭式表达式（不要近似）。以 $\\mathrm{kg}\\,\\mathrm{kg}^{-1}$ 为单位表示您的最终值。\n\n您的最终答案必须仅为所要求的量 $\\delta q_1$ 的单个闭式解析表达式。不要在最终答案框中包含推导过程或单位。",
            "solution": "用户需要一个关于三维变分同化 (3D-Var) 的三部分问题的详细解答。我将首先验证问题陈述，然后按顺序解决每个部分。\n\n### 问题验证\n\n**第一步：提取已知条件**\n- 两点湿度状态：$q \\in \\mathbb{R}^{2}$，分量严格为正。\n- 对数控制变量：$z = \\log(q)$，其中对数是逐分量计算的。\n- 背景场（物理空间）：$q_{b} = \\begin{pmatrix} 5 \\times 10^{-3} \\\\ 1 \\times 10^{-2} \\end{pmatrix}$。\n- 背景协方差（物理空间）：$B_{q} = \\begin{pmatrix} (2 \\times 10^{-3})^{2}  \\rho \\,(2 \\times 10^{-3})(3 \\times 10^{-3}) \\\\ \\rho \\,(2 \\times 10^{-3})(3 \\times 10^{-3})  (3 \\times 10^{-3})^{2} \\end{pmatrix}$。\n- 相关系数：$\\rho = 0.3$。\n- 标量观测：$y = 6.0 \\times 10^{-3}$，是 $q$ 的第一个分量。\n- 观测误差方差：$R = (5 \\times 10^{-4})^{2}$。\n- 观测算子（物理空间）：$H(q) = \\begin{pmatrix} 1  0 \\end{pmatrix} q$。\n- 观测算子（控制空间）：$h(z) = H(\\exp(z))$。\n\n**第二步：使用提取的已知条件进行验证**\n- **科学依据：** 该问题是三维变分同化在处理像湿度这样的正值量时的标准应用，使用了对数控制变量变换。这是地球物理数据同化中一种常用且有效的方法。\n- **适定性：** 该问题是适定的。3D-Var 代价函数是凸函数，确保存在唯一的最小值。所有必要的数据和定义都已提供。为确保 $B_q$ 是一个有效的协方差矩阵，它必须是对称且正定的。根据其构造，它是对称的。其对角元素是方差，是正数。其行列式为 $\\det(B_q) = ((2 \\times 10^{-3})(3 \\times 10^{-3}))^2 (1 - \\rho^2) = (6 \\times 10^{-6})^2 (1 - 0.3^2) = 36 \\times 10^{-12} \\times 0.91 > 0$。由于第一个主子式为正，$B_q$ 是正定的。\n- **客观性：** 该问题以精确的数学术语陈述，没有主观或模糊的语言。\n\n**第三步：结论与行动**\n该问题具有科学依据，是自洽且适定的。它是**有效的**。我将继续进行完整解答。\n\n### 解答\n\n**第一部分：控制空间中的背景协方差**\n\n从控制变量 $z$ 到物理状态 $q$ 的变换由 $q(z) = \\exp(z)$ 给出，其中指数函数是逐分量应用的。此变换在控制空间的背景场 $z_b$ 附近进行一阶线性化，得到小增量 $\\delta z = z - z_b$ 和 $\\delta q = q - q_b$ 之间的关系：\n$$ \\delta q \\approx E_b \\delta z $$\n其中 $E_b = \\left.\\frac{\\partial q}{\\partial z}\\right|_{z_b}$ 是在 $z_b$ 处计算的变换的雅可比矩阵。\n对于 $q = (q_1, q_2)^T$ 和 $z = (z_1, z_2)^T$，我们有 $q_1 = \\exp(z_1)$ 和 $q_2 = \\exp(z_2)$。雅可比矩阵为：\n$$ E = \\frac{\\partial q}{\\partial z} = \\begin{pmatrix} \\frac{\\partial q_1}{\\partial z_1}  \\frac{\\partial q_1}{\\partial z_2} \\\\ \\frac{\\partial q_2}{\\partial z_1}  \\frac{\\partial q_2}{\\partial z_2} \\end{pmatrix} = \\begin{pmatrix} \\exp(z_1)  0 \\\\ 0  \\exp(z_2) \\end{pmatrix} = \\text{diag}(q_1, q_2) $$\n在背景场 $z_b$ 处计算，其中 $q_b = \\exp(z_b)$，雅可比矩阵为 $E_b = \\text{diag}(q_{b1}, q_{b2})$。\n在线性映射 $\\delta q \\approx E_b \\delta z$ 下，协方差矩阵之间的关系为 $B_q \\approx E_b B_z E_b^T$。由于 $E_b$ 是一个对角矩阵，其转置等于自身，因此 $B_q \\approx E_b B_z E_b$。\n为了求得控制空间中的背景协方差 $B_z$，我们对此关系求逆：\n$$ B_z \\approx E_b^{-1} B_q (E_b^T)^{-1} = E_b^{-1} B_q E_b^{-1} $$\n其中 $E_b^{-1} = \\text{diag}(1/q_{b1}, 1/q_{b2})$。\n这种被称为合同变换的变换保持正定性。由于 $q_{b1}$ 和 $q_{b2}$ 严格为正，$E_b$ 是可逆的。如果 $B_q$ 是正定的，那么对于任意非零向量 $x$，有 $x^T B_q x > 0$。对于任意非零向量 $y$，我们可以定义 $x = E_b^{-1} y$，它也是非零的。那么 $y^T B_z y = y^T E_b^{-1} B_q E_b^{-1} y = (E_b^{-1}y)^T B_q (E_b^{-1}y) = x^T B_q x > 0$。因此，$B_z$ 也是正定的。\n\n现在我们数值计算 $B_z$。$q_b$ 的分量是 $q_{b1} = 5 \\times 10^{-3}$ 和 $q_{b2} = 1 \\times 10^{-2}$。\n物理空间协方差矩阵 $B_q$ 的分量为：\n$B_{q,11} = (2 \\times 10^{-3})^2 = 4 \\times 10^{-6}$\n$B_{q,22} = (3 \\times 10^{-3})^2 = 9 \\times 10^{-6}$\n$B_{q,12} = B_{q,21} = \\rho (2 \\times 10^{-3})(3 \\times 10^{-3}) = 0.3 \\times (6 \\times 10^{-6}) = 1.8 \\times 10^{-6}$\n$B_z$ 的分量是：\n$B_{z,11} = \\frac{B_{q,11}}{q_{b1}^2} = \\frac{4 \\times 10^{-6}}{(5 \\times 10^{-3})^2} = \\frac{4 \\times 10^{-6}}{25 \\times 10^{-6}} = \\frac{4}{25} = 0.16$\n$B_{z,22} = \\frac{B_{q,22}}{q_{b2}^2} = \\frac{9 \\times 10^{-6}}{(1 \\times 10^{-2})^2} = \\frac{9 \\times 10^{-6}}{1 \\times 10^{-4}} = 0.09$\n$B_{z,12} = \\frac{B_{q,12}}{q_{b1}q_{b2}} = \\frac{1.8 \\times 10^{-6}}{(5 \\times 10^{-3})(1 \\times 10^{-2})} = \\frac{1.8 \\times 10^{-6}}{5 \\times 10^{-5}} = \\frac{1.8}{50} = 0.036$\n所以，$B_z = \\begin{pmatrix} 0.16  0.036 \\\\ 0.036  0.09 \\end{pmatrix}$。\n\n**第二部分：高斯-牛顿分析增量**\n\n控制变量 $z$ 的 3D-Var 代价函数为：\n$$ J(z) = \\frac{1}{2}(z - z_b)^T B_z^{-1} (z - z_b) + \\frac{1}{2}(h(z) - y)^T R^{-1} (h(z) - y) $$\n高斯-牛顿法将观测算子 $h(z)$ 在背景场 $z_b$ 附近线性化，因此 $h(z) \\approx h(z_b) + H_z(z-z_b)$，其中 $H_z = \\left.\\frac{\\partial h}{\\partial z}\\right|_{z_b}$。使得到的二次代价函数最小化的分析增量 $\\delta z = z_a - z_b$ 由标准公式给出：\n$$ \\delta z = B_z H_z^T (H_z B_z H_z^T + R)^{-1} d $$\n其中 $d = y - h(z_b)$ 是新息。\n首先，我们计算必要的组成部分：\n控制空间中的观测算子是 $h(z) = H(\\exp(z)) = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} \\exp(z_1) \\\\ \\exp(z_2) \\end{pmatrix} = \\exp(z_1)$。\n其雅可比矩阵为 $H_z = \\frac{\\partial h}{\\partial z} = \\begin{pmatrix} \\exp(z_1)  0 \\end{pmatrix}$。\n在 $z_b$ 处计算，$H_z = \\begin{pmatrix} \\exp(z_{b1})  0 \\end{pmatrix} = \\begin{pmatrix} q_{b1}  0 \\end{pmatrix} = \\begin{pmatrix} 5 \\times 10^{-3}  0 \\end{pmatrix}$。\n新息 $d$ 是一个标量：$d = y - h(z_b) = y - q_{b1} = 6.0 \\times 10^{-3} - 5 \\times 10^{-3} = 1 \\times 10^{-3}$。\n$H_z B_z H_z^T$ 项代表观测空间中的背景误差方差：\n$$ H_z B_z H_z^T = \\begin{pmatrix} q_{b1}  0 \\end{pmatrix} B_z \\begin{pmatrix} q_{b1} \\\\ 0 \\end{pmatrix} = q_{b1}^2 B_{z,11} $$\n使用第一部分的结果，$B_{z,11} = B_{q,11}/q_{b1}^2$，该式可简化为 $H_z B_z H_z^T = B_{q,11}$。\n需要求逆的项是观测空间中背景误差方差和观测误差方差的标量和：\n$H_z B_z H_z^T + R = B_{q,11} + R = (2 \\times 10^{-3})^2 + (5 \\times 10^{-4})^2 = 4 \\times 10^{-6} + 0.25 \\times 10^{-6} = 4.25 \\times 10^{-6}$。\n交叉协方差项是 $B_z H_z^T$：\n$$ B_z H_z^T = \\begin{pmatrix} B_{z,11}  B_{z,12} \\\\ B_{z,21}  B_{z,22} \\end{pmatrix} \\begin{pmatrix} q_{b1} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} B_{z,11}q_{b1} \\\\ B_{z,21}q_{b1} \\end{pmatrix} $$\n结合这些来求 $\\delta z$：\n$$ \\delta z = \\begin{pmatrix} B_{z,11}q_{b1} \\\\ B_{z,21}q_{b1} \\end{pmatrix} (B_{q,11} + R)^{-1} d = \\frac{d}{B_{q,11} + R} \\begin{pmatrix} B_{z,11}q_{b1} \\\\ B_{z,12}q_{b1} \\end{pmatrix} $$\n代入数值：\n前置因子是 $\\frac{1 \\times 10^{-3}}{4.25 \\times 10^{-6}} = \\frac{1000}{4.25} = \\frac{4000}{17}$。\n向量分量为：\n$B_{z,11}q_{b1} = 0.16 \\times (5 \\times 10^{-3}) = 0.8 \\times 10^{-3}$。\n$B_{z,12}q_{b1} = 0.036 \\times (5 \\times 10^{-3}) = 0.18 \\times 10^{-3}$。\n所以，增量向量为：\n$$ \\delta z = \\frac{4000}{17} \\begin{pmatrix} 0.8 \\times 10^{-3} \\\\ 0.18 \\times 10^{-3} \\end{pmatrix} = \\frac{1}{17} \\begin{pmatrix} 3.2 \\\\ 0.72 \\end{pmatrix} = \\begin{pmatrix} 3.2/17 \\\\ 0.72/17 \\end{pmatrix} = \\begin{pmatrix} 16/85 \\\\ 18/425 \\end{pmatrix} $$\n\n**第三部分：物理空间分析增量**\n\n通过将更新后的控制变量 $z_a = z_b + \\delta z$ 变换回物理空间，可以得到物理空间中的分析场 $q_a$：\n$$ q_a = \\exp(z_a) = \\exp(z_b + \\delta z) $$\n这可以写成哈达玛（逐元素）积：$q_a = \\exp(z_b) \\odot \\exp(\\delta z) = q_b \\odot \\exp(\\delta z)$。\n物理空间分析增量为 $\\delta q = q_a - q_b$：\n$$ \\delta q = q_b \\odot \\exp(\\delta z) - q_b = q_b \\odot (\\exp(\\delta z) - \\mathbf{1}) $$\n其中 $\\mathbf{1}$ 是一个全为1的向量。第一个分量 $\\delta q_1$ 是：\n$$ \\delta q_1 = q_{b1} (\\exp(\\delta z_1) - 1) $$\n我们在第二部分推导了 $\\delta z_1$ 的解析表达式：\n$$ \\delta z_1 = \\frac{(y - q_{b1}) B_{z,11} q_{b1}}{B_{q,11} + R} $$\n代入 $B_{z,11} = B_{q,11}/q_{b1}^2$，可得：\n$$ \\delta z_1 = \\frac{(y - q_{b1}) (B_{q,11}/q_{b1}^2) q_{b1}}{B_{q,11} + R} = \\frac{(y - q_{b1}) B_{q,11}/q_{b1}}{B_{q,11} + R} $$\n将数值代入 $\\delta z_1$ 的表达式中：\n$$ \\delta z_1 = \\frac{(6.0 \\times 10^{-3} - 5 \\times 10^{-3})(4 \\times 10^{-6})}{(5 \\times 10^{-3})(4 \\times 10^{-6} + 0.25 \\times 10^{-6})} = \\frac{(1 \\times 10^{-3})(4 \\times 10^{-6})}{(5 \\times 10^{-3})(4.25 \\times 10^{-6})} $$\n$$ \\delta z_1 = \\frac{4}{5 \\times 4.25} = \\frac{4}{21.25} = \\frac{4}{85/4} = \\frac{16}{85} $$\n这与第二部分的直接数值计算结果相符。\n最后，我们将这个 $\\delta z_1$ 的精确值代入 $\\delta q_1$ 的表达式中：\n$$ \\delta q_1 = (5 \\times 10^{-3}) \\left( \\exp\\left(\\frac{16}{85}\\right) - 1 \\right) $$\n这就是所求量的最终闭式解析表达式。",
            "answer": "$$\\boxed{(5 \\times 10^{-3}) \\left( \\exp\\left(\\frac{16}{85}\\right) - 1 \\right)}$$"
        },
        {
            "introduction": "许多真实世界的观测算子，例如模拟雷达反射率或卫星辐射亮温的算子，其响应本质上是非线性的，通常表现为阈值效应和饱和现象。增量 3D-Var 方法依赖于在背景状态附近对这些算子进行线性化，即切线性近似。本练习旨在通过一个假设的非线性观测算子，深入探讨切线性近似的有效性边界，并量化由非线性引起的分析误差，这对于理解和诊断实际同化系统的性能至关重要 。",
            "id": "3427109",
            "problem": "考虑一个三维变分同化（3D-Var）设定，其中观测算子通过一个平滑、饱和、带阈值的变换将状态向量映射到观测向量。令背景态为 $x_b \\in \\mathbb{R}^n$，并考虑增量态 $\\delta x \\in \\mathbb{R}^n$，因此试验态为 $x_b + \\delta x$。3D-Var 目标函数为\n$$\nJ(x) = (x - x_b)^\\top B^{-1}(x - x_b) + \\left(H(x) - y\\right)^\\top R^{-1} \\left(H(x) - y\\right),\n$$\n其中 $B \\in \\mathbb{R}^{n \\times n}$ 是背景误差协方差，$R \\in \\mathbb{R}^{n \\times n}$ 是观测误差协方差，而 $H : \\mathbb{R}^n \\to \\mathbb{R}^n$ 是观测算子。对于本问题，重点在于观测部分及其切线性有效性。\n\n逐分量定义观测算子 $H$ 为 $H(x)_i = h(x_i)$，其中\n$$\nh(x) = R_{\\max} \\tanh\\!\\left(a \\, S(b x - \\tau)\\right), \\quad S(s) = \\frac{1}{\\beta}\\log\\!\\left(1 + e^{\\beta s}\\right),\n$$\n其中 $R_{\\max} = 60$，$a = 1.8$，$b = 1$，$\\tau = 3$，以及 $\\beta = 4$。这一选择在 $x \\approx \\tau$ 附近（通过 $S$）产生一个平滑的阈值，并在 $x$ 较大时（通过双曲正切）达到饱和。假设观测误差协方差为对角矩阵 $R = \\operatorname{diag}(r_1,\\dots,r_n)$，其中所有分量 $i$ 的 $r_i = 0.25$，背景误差协方差为 $B = I_n$（$n \\times n$ 单位矩阵）。\n\n$H$ 在 $x_b$ 附近的增量式 3D-Var 线性化为 $H(x_b + \\delta x) \\approx H(x_b) + H'(x_b)\\delta x$，其中 $H'(x_b)$ 表示 $H$ 在 $x_b$ 处的雅可比矩阵。由非线性引起的观测空间失配累积通过余项 $r$ 来量化：\n$$\nr = H(x_b + \\delta x) - H(x_b) - H'(x_b)\\delta x.\n$$\n定义观测空间加权欧几里得范数\n$$\n\\|v\\|_{R} = \\left\\|R^{-1/2} v\\right\\|_2 = \\sqrt{\\sum_{i=1}^n \\frac{v_i^2}{r_i}}.\n$$\n增量失配累积比为\n$$\nE = \\frac{\\|r\\|_{R}}{\\left\\|H'(x_b)\\delta x\\right\\|_{R}},\n$$\n并约定如果分母在数值上为零（具体而言，小于 $10^{-12}$），则设 $E = 10^{12}$。\n\n提出一个基于 $H$ 的二阶导数的切线性有效性度量，对于逐分量算子，其定义为将Hessian矩阵与增量进行缩并：\n$$\nM = \\left\\|R^{-1/2} \\left(H''(x_b)\\delta x\\right)\\right\\|_2 = \\sqrt{\\sum_{i=1}^n \\frac{\\left(h''(x_{b,i}) \\, \\delta x_i\\right)^2}{r_i}},\n$$\n其中 $H''(x_b)\\delta x$ 被逐分量地理解为 $\\left(H''(x_b)\\delta x\\right)_i = h''(x_{b,i})\\delta x_i$。\n\n任务：\n- 仅以微积分的基本定义和法则（链式法则、乘积法则）为起点，为指定的 $h$ 实现函数 $h(x)$、$h'(x)$ 和 $h''(x)$。\n- 对以下每个测试用例，计算如上定义的数对 $(E, M)$，将每个值四舍五入到六位小数，并返回所有的数对。\n\n测试套件（所有用例均使用 $n = 4$，$R = \\operatorname{diag}(0.25, 0.25, 0.25, 0.25)$，$B = I_4$）：\n1. 背景低于阈值，小增量：$x_b = [1.0, 1.5, 2.0, 2.5]$, $\\delta x = [0.1, 0.1, 0.1, 0.1]$。\n2. 接近阈值，混合增量：$x_b = [2.9, 3.0, 3.1, 3.2]$, $\\delta x = [0.5, -0.3, 0.4, -0.2]$。\n3. 饱和区域，正增量：$x_b = [6.0, 7.0, 8.0, 9.0]$, $\\delta x = [0.5, 0.5, 0.5, 0.5]$。\n4. 深度饱和，负增量边缘情况：$x_b = [50.0, 50.0, 50.0, 50.0]$, $\\delta x = [-5.0, -5.0, -5.0, -5.0]$。\n5. 混合区域，大增量：$x_b = [1.0, 3.0, 6.0, 9.0]$, $\\delta x = [3.0, -0.1, 2.0, -3.0]$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含所有五个测试用例的结果，形式为一个逗号分隔的列表，并用方括号括起来，其中每个元素是对应测试用例的二元列表 $[E,M]$。例如，输出必须看起来像 $[[E_1,M_1],[E_2,M_2],[E_3,M_3],[E_4,M_4],[E_5,M_5]]$，每个数值条目四舍五入到六位小数。不需要单位；所有量均为无量纲。",
            "solution": "该问题被评估为有效。它在科学上基于三维变分数据同化（3D-Var）的成熟数学框架，这是反问题的一个子领域。该问题是适定的，提供了所有必要的定义、常数和函数形式。语言精确客观。任务定义清晰，需要应用标准的微积分和数值计算，这些都是该领域的核心。\n\n这个问题的核心是在增量式3D-Var背景下分析给定观测算子 $H$ 的非线性。此分析通过计算两个度量 $E$ 和 $M$ 来执行，这两个度量取决于算子的逐分量函数 $h(x)$ 的一阶和二阶导数。\n\n首先，我们必须推导函数 $h(x)$ 的一阶导数 $h'(x)$ 和二阶导数 $h''(x)$ 的解析形式。该函数是几个基本函数的复合：\n$$\nh(x) = R_{\\max} \\tanh\\!\\left(a \\, S(b x - \\tau)\\right)\n$$\n其中 $S(s)$ 是Softplus函数：\n$$\nS(s) = \\frac{1}{\\beta}\\log\\!\\left(1 + e^{\\beta s}\\right)\n$$\n让我们求 $S(s)$ 关于其参数 $s$ 的导数。使用链式法则：\n$$\nS'(s) = \\frac{d}{ds}\\left[\\frac{1}{\\beta}\\log\\!\\left(1 + e^{\\beta s}\\right)\\right] = \\frac{1}{\\beta} \\frac{1}{1 + e^{\\beta s}} \\left(\\beta e^{\\beta s}\\right) = \\frac{e^{\\beta s}}{1 + e^{\\beta s}} = \\frac{1}{1 + e^{-\\beta s}}\n$$\n这是 logistic sigmoid 函数。\n\n二阶导数 $S''(s)$ 是 $S'(s)$ 的导数：\n$$\nS''(s) = \\frac{d}{ds}\\left[\\left(1 + e^{-\\beta s}\\right)^{-1}\\right] = -1 \\left(1 + e^{-\\beta s}\\right)^{-2} \\left(-\\beta e^{-\\beta s}\\right) = \\frac{\\beta e^{-\\beta s}}{\\left(1 + e^{-\\beta s}\\right)^2}\n$$\n这也可以用 $S'(s)$ 表示为 $S''(s) = \\beta S'(s)(1 - S'(s))$。\n\n现在，我们使用链式法则推导 $h'(x)$。令 $u(x) = b x - \\tau$。则 $h(x) = R_{\\max} \\tanh(a S(u(x)))$。\n$$\nh'(x) = \\frac{d}{dx} \\left[ R_{\\max} \\tanh(a S(u(x))) \\right]\n$$\n$$\nh'(x) = R_{\\max} \\cdot \\sech^2(a S(u(x))) \\cdot \\frac{d}{dx}[a S(u(x))]\n$$\n$$\nh'(x) = R_{\\max} \\sech^2(a S(u(x))) \\cdot a \\cdot S'(u(x)) \\cdot \\frac{d}{dx}[u(x)]\n$$\n由于 $u'(x) = b$，我们有：\n$$\nh'(x) = R_{\\max} a b \\sech^2(a S(b x - \\tau)) S'(b x - \\tau)\n$$\n\n接下来，我们通过对 $h'(x)$ 关于 $x$求导来找到二阶导数 $h''(x)$，这里对 $\\sech^2(\\dots)$ 和 $S'(\\dots)$ 两项使用乘积法则。令 $C = R_{\\max} a b$。\n$$\nh'(x) = C \\cdot \\underbrace{\\sech^2(a S(b x - \\tau))}_{U(x)} \\cdot \\underbrace{S'(b x - \\tau)}_{V(x)}\n$$\n$$\nh''(x) = C \\left( U'(x)V(x) + U(x)V'(x) \\right)\n$$\n我们求 $U(x)$ 和 $V(x)$ 的导数：\n$$\nU'(x) = \\frac{d}{dx} \\sech^2(a S(u)) = 2 \\sech(a S(u)) \\cdot [-\\sech(a S(u)) \\tanh(a S(u))] \\cdot \\frac{d}{dx}[a S(u)]\n$$\n$$\nU'(x) = -2 \\sech^2(a S(u)) \\tanh(a S(u)) \\cdot a S'(u) \\cdot b\n$$\n$$\nV'(x) = \\frac{d}{dx} S'(u) = S''(u) \\cdot u'(x) = b S''(u)\n$$\n将这些代入乘积法则表达式中：\n$$\nh''(x) = C \\left( [-2 \\sech^2(a S(u)) \\tanh(a S(u)) a b S'(u)] \\cdot S'(u) + [\\sech^2(a S(u))] \\cdot [b S''(u)] \\right)\n$$\n提出公因子 $C$、$b$ 和 $\\sech^2(a S(u))$：\n$$\nh''(x) = C b \\sech^2(a S(u)) \\left( -2a \\tanh(a S(u)) (S'(u))^2 + S''(u) \\right)\n$$\n代入 $C = R_{\\max} a b$ 和 $u = b x - \\tau$：\n$$\nh''(x) = R_{\\max} a b^2 \\sech^2(a S(b x - \\tau)) \\left[ -2a \\tanh(a S(b x - \\tau)) (S'(b x - \\tau))^2 + S''(b x - \\tau) \\right]\n$$\n\n有了这些解析导数，我们就可以为每个测试用例计算所需的量。\n状态向量 $x_b$ 和 $\\delta x$ 是给定的。观测算子 $H$ 及其导数是逐分量作用的，因此对于向量 $x$，有 $(H(x))_i = h(x_i)$。\n\n1.  计算真实状态扰动：$x = x_b + \\delta x$。\n2.  计算观测向量：$H(x_b)$ 和 $H(x)$。\n3.  计算切线性项：$(H'(x_b)\\delta x)_i = h'(x_{b,i}) \\delta x_i$。\n4.  计算余项向量：$r = H(x) - H(x_b) - H'(x_b)\\delta x$。\n5.  计算观测空间加权范数 $\\|v\\|_R = \\sqrt{\\sum_i v_i^2 / r_i}$。由于 $R = \\operatorname{diag}(0.25, ..., 0.25)$，我们有对所有 $i$ 都有 $r_i = 0.25$，因此 $\\|v\\|_R = \\sqrt{\\sum_i v_i^2 / 0.25} = \\sqrt{4 \\sum_i v_i^2} = 2 \\|v\\|_2$。\n6.  计算增量失配累积比：$E = \\frac{\\|r\\|_{R}}{\\|H'(x_b)\\delta x\\|_{R}}$。如果分母小于 $10^{-12}$，则设 $E = 10^{12}$。\n7.  计算Hessian-增量乘积向量：$(H''(x_b)\\delta x)_i = h''(x_{b,i}) \\delta x_i$。\n8.  计算切线性有效性度量：$M = \\left\\|R^{-1/2} \\left(H''(x_b)\\delta x\\right)\\right\\|_2 = \\| H''(x_b)\\delta x \\|_{R}$。\n\n此过程应用于所提供的五个测试用例中的每一个。数值实现需要小心以保持稳定性，特别是对于Softplus函数及其导数中的指数项。建议使用 `scipy.special.expit` 来计算sigmoid函数 $S'(s)$，并使用 `numpy.logaddexp` 来计算 $S(s)$ 中的 $\\log(1+\\exp(\\cdot))$ 项。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import expit\n\ndef solve():\n    \"\"\"\n    Solves the 3D-Var tangent-linear validity problem.\n    \"\"\"\n    # Define constants from the problem statement\n    R_max = 60.0\n    a = 1.8\n    b = 1.0\n    tau = 3.0\n    beta = 4.0\n    n = 4\n    diag_r = np.full(n, 0.25)\n    \n    # --- Function Definitions ---\n    # Numerically stable Softplus function S(s)\n    def S(s):\n        return np.logaddexp(0, beta * s) / beta\n\n    # First derivative of Softplus, S'(s), which is the sigmoid function\n    def S_prime(s):\n        return expit(beta * s)\n\n    # Second derivative of Softplus, S''(s)\n    def S_double_prime(s):\n        s_prime_val = S_prime(s)\n        return beta * s_prime_val * (1.0 - s_prime_val)\n\n    # Observation operator component h(x)\n    def h(x):\n        u = b * x - tau\n        return R_max * np.tanh(a * S(u))\n\n    # First derivative h'(x)\n    def h_prime(x):\n        u = b * x - tau\n        s_val = S(u)\n        s_prime_val = S_prime(u)\n        # sech(z) = 1/cosh(z). sech^2(z) = 1/cosh^2(z)\n        sech2_val = 1.0 / np.cosh(a * s_val)**2\n        return R_max * a * b * sech2_val * s_prime_val\n\n    # Second derivative h''(x)\n    def h_double_prime(x):\n        u = b * x - tau\n        s_val = S(u)\n        s_prime_val = S_prime(u)\n        s_double_prime_val = S_double_prime(u)\n\n        tanh_val = np.tanh(a * s_val)\n        sech2_val = 1.0 / np.cosh(a * s_val)**2\n        \n        term1 = -2.0 * a * tanh_val * (s_prime_val**2)\n        term2 = s_double_prime_val\n        \n        return R_max * a * (b**2) * sech2_val * (term1 + term2)\n\n    # Observation-space weighted norm\n    def obs_norm(v, r_diag_vec):\n        return np.sqrt(np.sum(v**2 / r_diag_vec))\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        (np.array([1.0, 1.5, 2.0, 2.5]), np.array([0.1, 0.1, 0.1, 0.1])),\n        (np.array([2.9, 3.0, 3.1, 3.2]), np.array([0.5, -0.3, 0.4, -0.2])),\n        (np.array([6.0, 7.0, 8.0, 9.0]), np.array([0.5, 0.5, 0.5, 0.5])),\n        (np.array([50.0, 50.0, 50.0, 50.0]), np.array([-5.0, -5.0, -5.0, -5.0])),\n        (np.array([1.0, 3.0, 6.0, 9.0]), np.array([3.0, -0.1, 2.0, -3.0]))\n    ]\n\n    results = []\n    for x_b, delta_x in test_cases:\n        x_perturbed = x_b + delta_x\n\n        # Component-wise application of h, h', h''\n        H_xb = np.array([h(xi) for xi in x_b])\n        H_x_perturbed = np.array([h(xi) for xi in x_perturbed])\n        \n        h_prime_xb = np.array([h_prime(xi) for xi in x_b])\n        tl_term = h_prime_xb * delta_x\n        \n        # Calculate remainder r\n        r = H_x_perturbed - H_xb - tl_term\n\n        # Calculate norms\n        norm_r = obs_norm(r, diag_r)\n        norm_tl = obs_norm(tl_term, diag_r)\n        \n        # Calculate E\n        if norm_tl  1e-12:\n            E = 1e12\n        else:\n            E = norm_r / norm_tl\n        \n        # Calculate M\n        h_double_prime_xb = np.array([h_double_prime(xi) for xi in x_b])\n        hess_term = h_double_prime_xb * delta_x\n        M = obs_norm(hess_term, diag_r)\n        \n        results.append([round(E, 6), round(M, 6)])\n\n    # Format the final output string\n    # Using str() on a list gives a string '[...]', which is what we need for each sublist\n    # Then we join these strings with ',', and wrap the whole thing in '[...]'\n    output_str = f\"[{','.join(map(str, results))}]\"\n    # The output format requires no spaces between elements\n    output_str = output_str.replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}