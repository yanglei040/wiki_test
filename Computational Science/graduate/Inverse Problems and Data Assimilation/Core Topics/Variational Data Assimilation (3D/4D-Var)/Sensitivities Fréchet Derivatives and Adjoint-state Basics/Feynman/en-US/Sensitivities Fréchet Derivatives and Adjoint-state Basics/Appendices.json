{
    "hands_on_practices": [
        {
            "introduction": "The adjoint-state method is more than just a computational shortcut for gradients; it provides deep insights into the structure of an inverse problem. This first practice explores the fundamental concept of identifiability by connecting the Fréchet derivative of the forward model to the unobservable components of the parameter field. By deriving and computationally exploring the identifiability nullspace, you will gain a hands-on understanding of why certain parameter features cannot be resolved from a given set of observations .",
            "id": "3419154",
            "problem": "Consider a one-dimensional steady-state diffusion model on the closed interval $[0,1]$ with homogeneous Dirichlet boundary conditions. Let the interior of the interval be discretized into $n$ equally spaced points with spacing $h = 1/(n+1)$, and approximate the differential operator mapping $x$ to $-x''$ by the standard second-order finite-difference matrix $A \\in \\mathbb{R}^{n \\times n}$ defined by $A_{ii} = 2/h^2$ and $A_{i,i\\pm 1} = -1/h^2$ for valid indices. Let the parameter vector $m \\in \\mathbb{R}^n$ represent a discretized source term, and let the state vector $x \\in \\mathbb{R}^n$ solve the linear system\n$$\nA x = m.\n$$\nLet $S \\in \\mathbb{R}^{k \\times n}$ be a linear observation operator that selects a subset of coordinates of $x$ corresponding to $k$ sensor locations among the $n$ interior grid points. The forward map $F : \\mathbb{R}^n \\to \\mathbb{R}^k$ is defined by\n$$\nF(m) = S x(m) = S A^{-1} m.\n$$\nDefine the data misfit cost functional\n$$\n\\Phi(m) = \\tfrac{1}{2} \\| F(m) - d \\|_2^2,\n$$\nwhere $d \\in \\mathbb{R}^k$ is a given data vector and $\\|\\cdot\\|_2$ denotes the Euclidean norm. All quantities in this problem are dimensionless; no physical units are required.\n\nYour tasks are:\n\n1. Starting from the definition of the Fréchet derivative in finite-dimensional real Hilbert spaces, derive the expression for the Fréchet derivative $F'(m)[h]$ of the forward map $F$ at $m$ in the direction $h \\in \\mathbb{R}^n$. Express your derivation directly in terms of the linearized state equation $A x_h = h$ for the perturbation $x_h$ and the observation operator $S$.\n\n2. Using the adjoint-state method via the Lagrangian framework, derive the gradient of $\\Phi(m)$ with respect to $m$. Introduce an adjoint variable $\\lambda \\in \\mathbb{R}^n$, set up the Lagrangian\n$$\n\\mathcal{L}(x,m,\\lambda) = \\tfrac{1}{2} \\| S x - d \\|_2^2 + \\lambda^\\top (A x - m),\n$$\nand derive the adjoint equation and the final expression for $\\nabla \\Phi(m)$ in terms of $\\lambda$. Carefully justify each step from first principles and specify the boundary conditions encoded by the matrix $A$.\n\n3. Provide a precise characterization of the identifiability nullspace\n$$\n\\mathcal{N} = \\{ h \\in \\mathbb{R}^n : F'(m)[h] = 0 \\}.\n$$\nShow that $\\mathcal{N}$ is independent of $m$ and equals the nullspace of the matrix $S A^{-1}$. Prove the following constructive characterization: if there exists a vector $v \\in \\mathbb{R}^n$ that is zero at all sensor locations (i.e., $S v = 0$), then the perturbation $h = A v$ belongs to $\\mathcal{N}$. Explain how this relates to identifiability and the role of the adjoint operator in detecting unobservable directions.\n\n4. Design an algorithm to compute the dimension of the identifiability nullspace $\\dim(\\mathcal{N})$ by evaluating the numerical rank of the Jacobian matrix $J = S A^{-1}$ via singular value decomposition. Justify a thresholding rule of the form: count singular values strictly greater than $10^{-10}$ times the largest singular value as contributing to the rank, and define the nullspace dimension as $n$ minus this numerical rank.\n\n5. Implement a complete, runnable program that:\n   - Constructs the matrix $A$ for a given $n$ and the selection matrix $S$ for specified sensor indices.\n   - Computes the Jacobian matrix $J = S A^{-1}$ and its singular values.\n   - Computes the nullspace dimension via the thresholding rule described above.\n   - Demonstrates the constructive characterization from task 3 by building a vector $v$ that is identically zero at sensor locations and forming $h = A v$, and then computing $\\| J h \\|_2$.\n   - Aggregates results for a test suite and prints them in the exact specified format.\n\nThe test suite must cover the following cases:\n\n- Case 1 (Happy path): $n = 8$, sensors at all interior grid points. This corresponds to $k = n$ and $S$ equal to the identity matrix. Output the integer $\\dim(\\mathcal{N})$.\n- Case 2 (No data edge case): $n = 8$, no sensors selected. This corresponds to $k = 0$ and $S$ equal to the zero-row matrix. Output the integer $\\dim(\\mathcal{N})$.\n- Case 3 (Partial coverage and constructive nullspace): $n = 10$, sensors at indices $\\{2,5,8\\}$ (zero-based indexing among interior points). Construct $v \\in \\mathbb{R}^{10}$ such that $v_i = 0$ for the sensor indices and $v_i$ is nonzero elsewhere, set $h = A v$, and output the float $\\| J h \\|_2$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, namely $[\\text{result}_1,\\text{result}_2,\\text{result}_3]$, where $\\text{result}_1$ and $\\text{result}_2$ are integers and $\\text{result}_3$ is a float. No additional text should be printed.",
            "solution": "The problem statement is a valid exercise in the theory and computation of sensitivities for an inverse problem governed by a linear elliptic partial differential equation. It is scientifically sound, mathematically well-posed, and all necessary information for its resolution is provided.\n\nThe problem asks for a multi-part analysis of a one-dimensional steady-state diffusion problem from an inverse problems perspective. We will address each task in sequence.\n\nThe discretized state equation is given by the linear system $A x = m$, where $x, m \\in \\mathbb{R}^n$. The matrix $A \\in \\mathbb{R}^{n \\times n}$ is the finite-difference approximation of the negative second derivative operator $-d^2/ds^2$ on an interval $[0,1]$ with homogeneous Dirichlet boundary conditions. This matrix is symmetric and positive definite, and thus invertible. The forward map $F(m)$ from the source parameter $m$ to the observations is $F(m) = S A^{-1} m$, where $S \\in \\mathbb{R}^{k \\times n}$ is a linear observation operator.\n\n### 1. Fréchet Derivative of the Forward Map\n\nThe Fréchet derivative of a map $F$ at a point $m$ is a linear operator $F'(m)$ such that\n$$ F(m+h) = F(m) + F'(m)[h] + o(\\|h\\|) $$\nfor a small perturbation $h \\in \\mathbb{R}^n$.\n\nThe forward map is given by $F(m) = S A^{-1} m$. Since $A^{-1}$ and $S$ are constant matrices, the map $F$ is linear in $m$. For a linear operator $L$, its derivative is the operator itself, i.e., $L'(m)[h] = L(h)$. Therefore,\n$$ F'(m)[h] = S A^{-1} h. $$\nTo express this in terms of the linearized state equation as requested, let us consider the effect of the perturbation $h$ on the state $x$. The original state $x(m)$ satisfies $A x(m) = m$. The perturbed state $x(m+h)$ satisfies $A x(m+h) = m+h$.\n\nLet $x_h = x(m+h) - x(m)$ be the perturbation in the state. By the linearity of the matrix-vector product,\n$$ A x_h = A(x(m+h) - x(m)) = A x(m+h) - A x(m) = (m+h) - m = h. $$\nThis gives the linearized state equation for the state perturbation $x_h$:\n$$ A x_h = h. $$\nSince $A$ is invertible, $x_h = A^{-1} h$.\n\nNow, we examine the perturbation in the observation:\n$$ F(m+h) - F(m) = S x(m+h) - S x(m) = S(x(m+h) - x(m)) = S x_h. $$\nSubstituting the expression for $x_h$, we have\n$$ F(m+h) - F(m) = S (A^{-1} h). $$\nThe term $o(\\|h\\|)$ is zero because the relationship is exactly linear. Thus, the Fréchet derivative of $F$ at $m$ applied to the direction $h$ is:\n$$ F'(m)[h] = S x_h, \\quad \\text{where} \\quad A x_h = h. $$\nThis expression shows that the sensitivity of the observation to a perturbation $h$ in the source is given by observing the resulting state perturbation $x_h$ with the operator $S$. Notably, because $F$ is linear, its derivative $F'(m)[\\cdot] = SA^{-1}(\\cdot)$ is a constant operator, independent of the point $m$ at which it is evaluated.\n\n### 2. Gradient of the Cost Functional via the Adjoint-State Method\n\nWe seek the gradient of the cost functional $\\Phi(m) = \\frac{1}{2} \\| S x - d \\|_2^2$ subject to the state equation constraint $A x = m$. We use the Lagrangian framework. The Lagrangian is given as:\n$$ \\mathcal{L}(x, m, \\lambda) = \\tfrac{1}{2} \\| S x - d \\|_2^2 + \\lambda^\\top (A x - m), $$\nwhere $\\lambda \\in \\mathbb{R}^n$ is the adjoint state or Lagrange multiplier.\n\nTo find the gradient of the reduced functional $\\Phi(m)$, we find the stationary point of $\\mathcal{L}$ with respect to its arguments. The gradient $\\nabla \\Phi(m)$ is then given by the partial derivative of $\\mathcal{L}$ with respect to $m$, evaluated at the solution of the state and adjoint equations.\n\n1.  **Derivative with respect to $\\lambda$**: Taking the derivative of $\\mathcal{L}$ with respect to $\\lambda$ and setting it to zero recovers the state equation.\n    $$ \\nabla_\\lambda \\mathcal{L}(x, m, \\lambda) = A x - m = 0 \\implies A x = m. $$\n\n2.  **Derivative with respect to $x$**: We compute the directional derivative of $\\mathcal{L}$ with respect to $x$ in an arbitrary direction $\\delta x$.\n    $$ \\delta_x \\mathcal{L} = \\frac{d}{d\\epsilon} \\mathcal{L}(x+\\epsilon\\delta x, m, \\lambda) \\Big|_{\\epsilon=0}. $$\n    $$ \\delta_x \\mathcal{L} = \\frac{d}{d\\epsilon} \\left( \\tfrac{1}{2} (S(x+\\epsilon\\delta x) - d)^\\top (S(x+\\epsilon\\delta x) - d) + \\lambda^\\top (A(x+\\epsilon\\delta x) - m) \\right) \\Big|_{\\epsilon=0} $$\n    $$ = (S x - d)^\\top S \\delta x + \\lambda^\\top A \\delta x = (S^\\top(S x - d) + A^\\top \\lambda)^\\top \\delta x. $$\n    For this to be zero for all $\\delta x$, we must have $\\nabla_x \\mathcal{L} = S^\\top(S x - d) + A^\\top \\lambda = 0$. This gives the **adjoint equation**:\n    $$ A^\\top \\lambda = -S^\\top(S x - d). $$\n    The matrix $A$ as defined is symmetric ($A_{ij} = A_{ji}$), so $A^\\top = A$. The adjoint equation simplifies to:\n    $$ A \\lambda = -S^\\top(S x - d). $$\n    The structure of the matrix $A$ implies homogeneous Dirichlet boundary conditions for the underlying continuous problem. Since the adjoint operator is again $A$, the adjoint variable $\\lambda$ satisfies the same boundary conditions.\n\n3.  **Derivative with respect to $m$**: We compute the directional derivative of $\\mathcal{L}$ with respect to $m$ in an arbitrary direction $\\delta m$.\n    $$ \\delta_m \\mathcal{L} = \\frac{d}{d\\epsilon} \\mathcal{L}(x, m+\\epsilon\\delta m, \\lambda) \\Big|_{\\epsilon=0}. $$\n    $$ \\delta_m \\mathcal{L} = \\frac{d}{d\\epsilon} \\left( \\tfrac{1}{2} \\| S x - d \\|_2^2 + \\lambda^\\top (A x - (m+\\epsilon\\delta m)) \\right) \\Big|_{\\epsilon=0} = -\\lambda^\\top \\delta m. $$\n    The gradient of the reduced functional $\\Phi(m)$ is given by $\\nabla_m \\mathcal{L}$, which is the vector that satisfies $(\\nabla_m \\mathcal{L})^\\top \\delta m = -\\lambda^\\top \\delta m$ for all $\\delta m$.\n    Thus, the gradient is:\n    $$ \\nabla \\Phi(m) = -\\lambda. $$\n\nIn summary, the gradient of $\\Phi(m)$ is computed via the following three steps:\n(i) Solve the state equation for $x$: $A x = m$.\n(ii) Solve the adjoint equation for $\\lambda$: $A \\lambda = -S^\\top(S x - d)$.\n(iii) The gradient is $\\nabla \\Phi(m) = -\\lambda$.\n\n### 3. Identifiability Nullspace\n\nThe identifiability nullspace $\\mathcal{N}$ is the set of parameter perturbations $h$ that are unobservable, i.e., produce no change in the output of the forward map. It is defined as:\n$$ \\mathcal{N} = \\{ h \\in \\mathbb{R}^n : F'(m)[h] = 0 \\}. $$\nFrom Task 1, we have $F'(m)[h] = S A^{-1} h$. The condition $F'(m)[h] = 0$ is therefore $S A^{-1} h = 0$. This is the definition of the nullspace (or kernel) of the matrix $J = S A^{-1}$.\n$$ \\mathcal{N} = \\text{ker}(S A^{-1}). $$\nSince the matrices $S$ and $A$ are constant, the Jacobian matrix $J = S A^{-1}$ is also constant. It does not depend on the point $m$. Consequently, its nullspace $\\mathcal{N}$ is independent of $m$.\n\n**Constructive Characterization:**\nWe are asked to prove that if a vector $v \\in \\mathbb{R}^n$ exists such that $S v = 0$, then the perturbation $h = A v$ belongs to $\\mathcal{N}$.\nA vector $v$ with $S v = 0$ corresponds to a state that is zero at all sensor locations.\nLet's test if $h = A v$ is in the nullspace $\\mathcal{N}$ by applying the operator $J = S A^{-1}$ to it:\n$$ J h = (S A^{-1}) h = (S A^{-1}) (A v) = S (A^{-1} A) v = S I v = S v. $$\nBy our premise, $S v = 0$. Therefore, $J h = 0$, which means $h \\in \\text{ker}(J) = \\mathcal{N}$. This completes the proof.\n\nThis characterization provides a way to construct elements of the nullspace. Any source term $h$ that generates a state $v$ that is \"invisible\" to the sensors ($S v = 0$) is itself an unobservable parameter perturbation. An optimization algorithm based on the gradient will not be able to recover or correct components of the parameter $m$ that lie in this nullspace $\\mathcal{N}$. This is because the gradient $\\nabla \\Phi(m) = -\\lambda = A^{-1} S^\\top (S x - d)$ belongs to the range of the adjoint operator $J^\\top = (S A^{-1})^\\top = (A^{-1})^\\top S^\\top = A^{-1} S^\\top$. By the fundamental theorem of linear algebra, the range of the adjoint is the orthogonal complement of the nullspace of the original operator: $\\text{range}(J^\\top) \\perp \\text{ker}(J)$. Hence, gradient-based updates are always orthogonal to the unobservable directions.\n\n### 4. Algorithm for Computing Nullspace Dimension\n\nThe dimension of the identifiability nullspace, $\\dim(\\mathcal{N})$, is the nullity of the Jacobian matrix $J = S A^{-1}$. By the rank-nullity theorem for a matrix $J \\in \\mathbb{R}^{k \\times n}$:\n$$ \\text{rank}(J) + \\text{nullity}(J) = n. $$\nTherefore, $\\dim(\\mathcal{N}) = \\text{nullity}(J) = n - \\text{rank}(J)$.\n\nThe rank of a matrix can be computed reliably from its singular values. The rank is the number of non-zero singular values. In numerical computation, we must use a threshold to distinguish non-zero from zero singular values due to floating-point inaccuracies. The problem provides a specific thresholding rule.\n\nThe algorithm is as follows:\n1.  **Construct Matrices**: For a given grid size $n$ and a set of sensor locations, construct the finite-difference matrix $A \\in \\mathbb{R}^{n \\times n}$ and the observation matrix $S \\in \\mathbb{R}^{k \\times n}$.\n2.  **Compute Jacobian**: Compute the Jacobian matrix $J = S A^{-1}$. Numerically, this can be done by first computing $A^{-1}$ using `numpy.linalg.inv` and then multiplying by $S$.\n3.  **Compute Singular Values**: Compute the singular value decomposition (SVD) of $J$. Let the singular values be $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_p \\ge 0$, where $p = \\min(k, n)$.\n4.  **Determine Numerical Rank**: Find the largest singular value $\\sigma_1$. Apply the thresholding rule: the numerical rank, $\\text{rank}_{\\text{num}}(J)$, is the count of singular values $\\sigma_i$ such that $\\sigma_i > 10^{-10} \\sigma_1$. If $J$ has no non-zero singular values (e.g., if it is a zero matrix), its rank is $0$.\n5.  **Compute Nullspace Dimension**: The dimension of the nullspace is $\\dim(\\mathcal{N}) = n - \\text{rank}_{\\text{num}}(J)$.\n\n### 5. Implementation\nThe final step is to implement this algorithm in Python for the specified test cases. The code will construct the matrices, compute the Jacobian, its singular values, and then determine the nullspace dimension or test the constructive characterization as required by each case.",
            "answer": "```python\nimport numpy as np\n\ndef construct_A(n):\n    \"\"\"Constructs the finite-difference matrix A for a given n.\"\"\"\n    if n == 0:\n        return np.array([[]])\n    h = 1.0 / (n + 1)\n    h2_inv = 1.0 / (h * h)\n    \n    A = np.zeros((n, n))\n    \n    # Fill diagonal\n    np.fill_diagonal(A, 2.0 * h2_inv)\n    \n    # Fill off-diagonals\n    if n > 1:\n        diag_indices = np.arange(n - 1)\n        A[diag_indices, diag_indices + 1] = -1.0 * h2_inv\n        A[diag_indices + 1, diag_indices] = -1.0 * h2_inv\n        \n    return A\n\ndef construct_S(n, sensor_indices):\n    \"\"\"Constructs the observation matrix S for given n and sensor indices.\"\"\"\n    k = len(sensor_indices)\n    if k == 0:\n        return np.zeros((0, n))\n    \n    S = np.zeros((k, n))\n    for i, sensor_idx in enumerate(sensor_indices):\n        if 0 <= sensor_idx < n:\n            S[i, sensor_idx] = 1.0\n    return S\n\ndef get_nullspace_dim(n, sensor_indices):\n    \"\"\"Computes the dimension of the identifiability nullspace.\"\"\"\n    A = construct_A(n)\n    S = construct_S(n, sensor_indices)\n\n    if n == 0:\n        return 0\n    if S.shape[0] == 0: # No sensors\n        return n\n    \n    A_inv = np.linalg.inv(A)\n    J = S @ A_inv\n    \n    # singular values of J\n    singular_values = np.linalg.svd(J, compute_uv=False)\n    \n    if len(singular_values) == 0:\n        numerical_rank = 0\n    else:\n        sigma_max = np.max(singular_values)\n        if sigma_max == 0:\n            numerical_rank = 0\n        else:\n            threshold = 1e-10 * sigma_max\n            numerical_rank = np.sum(singular_values > threshold)\n\n    nullity = n - numerical_rank\n    return nullity\n\ndef solve():\n    \"\"\"\n    Solves the problem for the three specified test cases and prints the results.\n    \"\"\"\n    results = []\n\n    # Case 1: n = 8, sensors at all points\n    n1 = 8\n    sensor_indices1 = list(range(n1))\n    dim_N1 = get_nullspace_dim(n1, sensor_indices1)\n    results.append(int(dim_N1))\n\n    # Case 2: n = 8, no sensors\n    n2 = 8\n    sensor_indices2 = []\n    dim_N2 = get_nullspace_dim(n2, sensor_indices2)\n    results.append(int(dim_N2))\n\n    # Case 3: n = 10, sensors at {2, 5, 8}, constructive nullspace check\n    n3 = 10\n    sensor_indices3 = [2, 5, 8]\n    \n    A3 = construct_A(n3)\n    S3 = construct_S(n3, sensor_indices3)\n    \n    A3_inv = np.linalg.inv(A3)\n    J3 = S3 @ A3_inv\n    \n    # Construct vector v that is zero at sensor locations\n    v3 = np.ones(n3)\n    v3[sensor_indices3] = 0\n    \n    # Construct h = Av\n    h3 = A3 @ v3\n    \n    # Compute the norm ||Jh||_2\n    norm_Jh = np.linalg.norm(J3 @ h3)\n    results.append(float(norm_Jh))\n\n    # Print a single line of output in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Many real-world systems evolve over time, and assimilating data into such dynamic models is a core task in fields like meteorology and engineering. This practice extends the adjoint-state method to time-dependent problems, revealing a critical trade-off between memory and computation. You will implement the discrete-time adjoint method and tackle the \"curse of memory\"—the need to store the entire forward trajectory—by using a checkpointing strategy, a widely used technique in large-scale scientific computing .",
            "id": "3419136",
            "problem": "Consider the discrete-time, time-dependent linear state evolution model defined for a state vector $x_n \\in \\mathbb{R}^d$ with index $n \\in \\{0,1,\\dots,N\\}$ by the explicit Euler time-stepping rule\n$$\nx_{n+1} = x_n + \\Delta t \\left( A x_n + \\theta B x_n + s \\right),\n$$\nwhere $A \\in \\mathbb{R}^{d \\times d}$ and $B \\in \\mathbb{R}^{d \\times d}$ are fixed matrices, $s \\in \\mathbb{R}^d$ is a fixed source term, $\\Delta t > 0$ is a fixed time step, and $\\theta \\in \\mathbb{R}$ is a scalar parameter. The initial condition is $x_0 = 0$. Let the observation operator be $C \\in \\mathbb{R}^{d \\times d}$, and let observations $y_n \\in \\mathbb{R}^d$ for $n \\in \\{0,1,\\dots,N\\}$ be generated by the same model with a fixed \"true\" parameter $\\theta_{\\mathrm{true}}$ and the same initial condition, with no noise:\n$$\ny_n = C x_n(\\theta_{\\mathrm{true}}).\n$$\nDefine the data misfit at each time as\n$$\n\\ell_n(x_n) = \\tfrac{1}{2} \\left\\| C x_n - y_n \\right\\|_2^2,\n$$\nand the total objective function as\n$$\nJ(\\theta) = \\sum_{n=0}^{N} \\ell_n(x_n(\\theta)) + \\tfrac{\\alpha}{2} \\theta^2,\n$$\nwhere $\\alpha \\ge 0$ is a fixed regularization weight.\n\nYou will compute the sensitivity of $J$ with respect to $\\theta$ via the adjoint-state method in a memory-constrained setting using checkpointing, and you will verify the correctness against a finite-difference approximation.\n\nFoundational base definitions and assumptions for derivation:\n- The Fréchet derivative of a functional $\\Phi$ at an argument $u$ in direction $h$ is the linear map $D\\Phi(u)[h]$ satisfying $\\Phi(u+h) - \\Phi(u) = D\\Phi(u)[h] + o(\\|h\\|)$ as $\\|h\\|\\to 0$.\n- For the discrete-time map $F_\\theta(x) = x + \\Delta t \\left( A x + \\theta B x + s \\right)$, the Jacobian with respect to the state is $\\partial F_\\theta / \\partial x = I + \\Delta t (A + \\theta B)$, and the partial derivative with respect to the parameter is $\\partial F_\\theta / \\partial \\theta (x) = \\Delta t\\, B x$.\n- The adjoint recursion arises by enforcing the stationarity of the Lagrangian formed by the objective $J$ and the discrete dynamics constraints, introducing adjoint variables $\\lambda_n \\in \\mathbb{R}^d$.\n\nCheckpointing and memory:\n- When running the adjoint backward in time from $n = N$ to $n = 0$, one needs access to the forward states $x_n$ to evaluate the gradient contributions and the adjoint updates. Storing all $x_n$ may be infeasible when $N$ is large.\n- A checkpointing policy stores a selected subset of states $\\{x_{n_k}\\}$ at indices $\\{n_k\\}$ subject to a memory limit $\\mathsf{M}$ (the maximum number of stored states). When a needed state $x_n$ is not stored, it is recomputed on demand by re-running the forward model from the nearest preceding stored checkpoint index $n_k \\le n$ up to $n$. The number of extra forward steps performed beyond the original forward pass is tracked as the recomputation count.\n\nTasks:\n1. Derive, from the provided base definitions, the discrete adjoint recursion for $\\lambda_n$ and the expression for the gradient $\\mathrm{d}J/\\mathrm{d}\\theta$ in terms of the forward states, adjoint variables, and the model derivatives.\n2. Implement a program that:\n   - Generates observations $y_n$ by running the forward model at $\\theta_{\\mathrm{true}}$.\n   - Computes $\\mathrm{d}J/\\mathrm{d}\\theta$ using the adjoint-state method under a uniform checkpointing policy that stores $\\mathsf{M}$ states at evenly spaced time indices from $0$ to $N$, inclusive, subject to deduplication when spacing is not exact. When a needed $x_n$ is not stored, recompute it from the nearest preceding checkpoint.\n   - Counts the total number of additional forward steps performed during adjoint-time recomputation beyond the initial forward run of $N$ steps.\n   - Computes a central finite-difference approximation to $\\mathrm{d}J/\\mathrm{d}\\theta$ using a small step $\\varepsilon$:\n     $$\n     \\mathrm{d}J/\\mathrm{d}\\theta \\approx \\frac{J(\\theta+\\varepsilon) - J(\\theta-\\varepsilon)}{2\\varepsilon}.\n     $$\n   - Reports the absolute error between the adjoint-based gradient and the finite-difference gradient, the recomputation count, the number of stored states, and a boolean indicating whether the absolute error is below a specified tolerance.\n3. Use the following fixed model settings:\n   - Dimension $d = 3$.\n   - Time step $\\Delta t = 0.1$.\n   - Matrices\n     $$\n     A = \\begin{bmatrix}\n     -0.1 & 0.2 & 0 \\\\\n     -0.2 & -0.3 & 0.1 \\\\\n     0 & -0.1 & -0.2\n     \\end{bmatrix},\\quad\n     B = \\begin{bmatrix}\n     0.5 & 0 & 0 \\\\\n     0 & 0.1 & 0 \\\\\n     0 & 0 & 0.3\n     \\end{bmatrix},\\quad\n     C = I_3,\n     $$\n     and source\n     $$\n     s = \\begin{bmatrix} 0.1 \\\\ -0.05 \\\\ 0.2 \\end{bmatrix}.\n     $$\n   - Initial condition $x_0 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$.\n   - True parameter $\\theta_{\\mathrm{true}} = 0.3$.\n4. Implement the following test suite (each test case provides $N$, $\\mathsf{M}$, $\\theta$, $\\alpha$, and $\\varepsilon$):\n   - Test Case 1 (general case): $N = 50$, $\\mathsf{M} = 6$, $\\theta = 0.2$, $\\alpha = 0.01$, $\\varepsilon = 10^{-6}$.\n   - Test Case 2 (full-memory boundary): $N = 50$, $\\mathsf{M} = 51$, $\\theta = 0.2$, $\\alpha = 0.01$, $\\varepsilon = 10^{-6}$.\n   - Test Case 3 (minimal memory edge case): $N = 50$, $\\mathsf{M} = 1$, $\\theta = 0.2$, $\\alpha = 0.01$, $\\varepsilon = 10^{-6}$.\n   - Test Case 4 (short horizon boundary): $N = 1$, $\\mathsf{M} = 1$, $\\theta = 0.2$, $\\alpha = 0.01$, $\\varepsilon = 10^{-8}$.\n5. For each test case, your program must produce a result as a list in the format\n   $$\n   [g_{\\mathrm{adj}}, g_{\\mathrm{fd}}, \\lvert g_{\\mathrm{adj}} - g_{\\mathrm{fd}} \\rvert, \\text{recompute\\_count}, \\text{memory\\_used}, \\text{match}],\n   $$\n   where $g_{\\mathrm{adj}}$ is the adjoint-based gradient, $g_{\\mathrm{fd}}$ is the finite-difference gradient, $\\text{recompute\\_count}$ is an integer, $\\text{memory\\_used}$ is an integer number of stored states, and $\\text{match}$ is a boolean indicating whether the absolute error is less than $10^{-8}$ for Test Cases 1–3 and less than $10^{-10}$ for Test Case 4.\n6. Final output format requirement: Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, with each test case result itself formatted as the list specified in item 5. For example, a valid shape is\n   $$\n   [[\\cdots],[\\cdots],[\\cdots],[\\cdots]].\n   $$\n\nNo physical units or angle units are involved in this problem; all quantities are unitless real numbers. The output values must be floating-point numbers, integers, or booleans as specified.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in the established theory of optimal control and sensitivity analysis (specifically, the adjoint-state method), is well-posed with a clear and objective formulation, and provides all necessary data and definitions for a unique solution.\n\n### 1. Derivation of the Adjoint Equations and Gradient\n\nThe goal is to compute the gradient $\\mathrm{d}J/\\mathrm{d}\\theta$ of the objective function:\n$$\nJ(\\theta) = \\sum_{n=0}^{N} \\ell_n(x_n(\\theta)) + \\tfrac{\\alpha}{2} \\theta^2 = \\sum_{n=0}^{N} \\tfrac{1}{2} \\left\\| C x_n(\\theta) - y_n \\right\\|_2^2 + \\tfrac{\\alpha}{2} \\theta^2\n$$\nThe state vector $x_n$ evolves according to the discrete-time dynamics, which act as constraints on the optimization problem:\n$$\nx_{n+1} = F_\\theta(x_n) = x_n + \\Delta t \\left( A x_n + \\theta B x_n + s \\right) \\quad \\text{for } n = 0, \\dots, N-1\n$$\nwith initial condition $x_0=0$.\n\nWe use the method of Lagrange multipliers to derive the adjoint equations. The Lagrangian $\\mathcal{L}$ is constructed by augmenting the objective function with the constraints, weighted by the adjoint variables (Lagrange multipliers) $\\lambda_{n+1} \\in \\mathbb{R}^d$:\n$$\n\\mathcal{L}(x_1, \\dots, x_N, \\theta, \\lambda_1, \\dots, \\lambda_N) = J(\\theta) - \\sum_{n=0}^{N-1} \\lambda_{n+1}^T \\left( x_{n+1} - F_\\theta(x_n) \\right)\n$$\nSubstituting the expression for $J(\\theta)$ and noting that $x_0=0$ is a fixed condition:\n$$\n\\mathcal{L} = \\left(\\sum_{n=0}^{N} \\ell_n(x_n)\\right) + \\tfrac{\\alpha}{2} \\theta^2 - \\sum_{n=0}^{N-1} \\lambda_{n+1}^T \\left( x_{n+1} - F_\\theta(x_n) \\right)\n$$\nFor a trajectory $\\{x_n\\}$ that satisfies the state equations, the gradient $\\mathrm{d}J/\\mathrm{d}\\theta$ is the partial derivative of the Lagrangian with respect to $\\theta$, provided the adjoint variables satisfy the stationarity conditions $\\partial \\mathcal{L} / \\partial x_n = 0$ for each state variable $x_n$ ($n=1, \\dots, N$).\n\n**Adjoint Equations:**\nThe stationarity conditions define the adjoint recursion.\nFor the final state $x_N$ ($n=N$):\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial x_N} = \\nabla_{x_N} \\ell_N(x_N) - \\lambda_N^T = 0 \\implies \\lambda_N = (\\nabla_{x_N} \\ell_N(x_N))^T\n$$\nFor intermediate states $x_n$ ($n=1, \\dots, N-1$):\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial x_n} = \\nabla_{x_n} \\ell_n(x_n) - \\lambda_n^T + \\lambda_{n+1}^T \\frac{\\partial F_\\theta(x_n)}{\\partial x_n} = 0\n$$\nThis yields the backward recursion for the adjoint variables:\n$$\n\\lambda_n = \\left(\\frac{\\partial F_\\theta(x_n)}{\\partial x_n}\\right)^T \\lambda_{n+1} + (\\nabla_{x_n} \\ell_n(x_n))^T\n$$\nLet's identify the required derivatives:\n- The gradient of the misfit term $\\ell_n(x_n) = \\frac{1}{2}(Cx_n-y_n)^T(Cx_n-y_n)$ is $\\nabla_{x_n}\\ell_n(x_n) = (Cx_n-y_n)^T C$. Its transpose is $(\\nabla_{x_n}\\ell_n(x_n))^T = C^T(Cx_n-y_n)$.\n- The Jacobian of the state transition map $F_\\theta$ with respect to the state is $\\frac{\\partial F_\\theta(x_n)}{\\partial x_n} = I + \\Delta t(A + \\theta B)$. Let's denote this matrix as $M_\\theta$.\n\nThe full adjoint system is defined by a backward time evolution:\nTerminal condition at $n=N$:\n$$\n\\lambda_N = C^T (C x_N - y_N)\n$$\nAdjoint recursion for $n = N-1, \\dots, 0$:\n$$\n\\lambda_n = (I + \\Delta t(A + \\theta B))^T \\lambda_{n+1} + C^T (C x_n - y_n)\n$$\nNote that we include the recursion down to $n=0$, providing $\\lambda_0$, which represents the sensitivity of $J$ to the initial condition $x_0$. While not strictly needed for the parameter gradient, this defines the complete adjoint state trajectory.\n\n**Gradient Expression:**\nThe gradient $\\mathrm{d}J/\\mathrm{d}\\theta$ is found by differentiating the Lagrangian with respect to $\\theta$:\n$$\n\\frac{\\mathrm{d}J}{\\mathrm{d}\\theta} = \\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\frac{\\partial}{\\partial\\theta} \\left( \\tfrac{\\alpha}{2}\\theta^2 \\right) + \\sum_{n=0}^{N-1} \\lambda_{n+1}^T \\frac{\\partial F_\\theta(x_n)}{\\partial \\theta}\n$$\nThe partial derivative of $F_\\theta(x_n)$ with respect to $\\theta$ is:\n$$\n\\frac{\\partial F_\\theta(x_n)}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta} \\left( x_n + \\Delta t (Ax_n + \\theta Bx_n + s) \\right) = \\Delta t B x_n\n$$\nSubstituting this into the gradient expression gives the final formula for the adjoint-based gradient:\n$$\n\\frac{\\mathrm{d}J}{\\mathrm{d}\\theta} = \\alpha \\theta + \\Delta t \\sum_{n=0}^{N-1} \\lambda_{n+1}^T B x_n\n$$\n\n### 2. Computational Algorithm\n\nThe computation proceeds as follows:\n1.  **Generate Observations:** The \"true\" observations $y_n$ are generated by running the forward model with the parameter $\\theta_{\\mathrm{true}}$.\n    - Set $x_0 = 0$.\n    - For $n=0, \\dots, N-1$: $x_{n+1} = (I + \\Delta t(A+\\theta_{\\mathrm{true}} B))x_n + \\Delta t s$.\n    - For $n=0, \\dots, N$: $y_n = C x_n$.\n\n2.  **Finite-Difference Gradient:** To verify correctness, a central finite-difference approximation $g_{\\mathrm{fd}}$ is calculated:\n    - Define a function `compute_J(theta_eval)` that runs the forward model with `theta_eval` to get the trajectory $\\{x_n(\\theta_{\\mathrm{eval}})\\}$ and then computes $J(\\theta_{\\mathrm{eval}})$.\n    - Compute $g_{\\mathrm{fd}} = \\frac{J(\\theta+\\varepsilon) - J(\\theta-\\varepsilon)}{2\\varepsilon}$.\n\n3.  **Adjoint-State Gradient with Checkpointing:**\n    a.  **Forward Pass and Checkpointing:**\n        - Given parameters $N$ and $\\mathsf{M}$, determine the checkpoint indices. A uniform policy stores states at indices `k` given by `np.linspace(0, N, M, dtype=int)`, with duplicates removed. Let this set be $\\mathcal{K}$.\n        - Run the forward model from $n=0$ to $N$ for a given $\\theta$. Store the state vector $x_n$ in memory if and only if $n \\in \\mathcal{K}$. This constitutes the initial forward pass of $N$ steps.\n\n    b.  **Backward Pass and Gradient Assembly:**\n        - Initialize the gradient $g_{\\mathrm{adj}} = \\alpha \\theta$ and the recomputation step counter to $0$.\n        - To start the recursion, obtain $x_N$. If $N \\in \\mathcal{K}$, retrieve it from memory. Otherwise, find the largest checkpoint index $n_k \\in \\mathcal{K}$ such that $n_k < N$, retrieve $x_{n_k}$, and re-run the forward model from $n_k$ to $N$. The number of recomputation steps, $N-n_k$, is added to the count.\n        - Initialize the adjoint variable: $\\lambda_N = C^T(Cx_N - y_N)$.\n        - Iterate backwards from $n=N$ down to $1$:\n            i. At step $n$, we have the adjoint state $\\lambda_n$.\n            ii. Obtain the state $x_{n-1}$. If $n-1 \\notin \\mathcal{K}$, find the nearest preceding checkpoint $n_k \\le n-1$, retrieve $x_{n_k}$, and re-run the forward model for $(n-1) - n_k$ steps. Add this number to the recomputation counter.\n            iii. Update the gradient: $g_{\\mathrm{adj}} \\leftarrow g_{\\mathrm{adj}} + \\Delta t \\lambda_n^T B x_{n-1}$.\n            iv. Update the adjoint variable for the next iteration: $\\lambda_{n-1} = (I + \\Delta t(A+\\theta B))^T \\lambda_n + C^T(Cx_{n-1} - y_{n-1})$.\n        - The final value $g_{\\mathrm{adj}}$ is the desired gradient.\n\n    c.  **Output:** Report the computed gradients $g_{\\mathrm{adj}}$ and $g_{\\mathrm{fd}}$, their absolute difference, the total recomputation count, the number of stored states (`memory_used`), and a boolean indicating if the error is below the specified tolerance.\n\nThis procedure correctly implements the adjoint-state method under memory constraints, using checkpointing to manage the storage of the forward trajectory required during the backward pass.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function to run all test cases for the adjoint-state method problem.\n    \"\"\"\n\n    # Fixed model settings\n    d = 3\n    dt = 0.1\n    A = np.array([\n        [-0.1, 0.2, 0.0],\n        [-0.2, -0.3, 0.1],\n        [0.0, -0.1, -0.2]\n    ])\n    B = np.array([\n        [0.5, 0.0, 0.0],\n        [0.0, 0.1, 0.0],\n        [0.0, 0.0, 0.3]\n    ])\n    C = np.eye(d)\n    s = np.array([0.1, -0.05, 0.2])\n    x0 = np.zeros(d)\n    theta_true = 0.3\n\n    # Test suite\n    test_cases = [\n        # (N, M, theta, alpha, epsilon, tol)\n        (50, 6, 0.2, 0.01, 1e-6, 1e-8),\n        (50, 51, 0.2, 0.01, 1e-6, 1e-8),\n        (50, 1, 0.2, 0.01, 1e-6, 1e-8),\n        (1, 1, 0.2, 0.01, 1e-8, 1e-10),\n    ]\n\n    all_results = []\n\n    for N, M_mem, theta, alpha, epsilon, tol in test_cases:\n\n        # Step 1: Generate observations y_n using theta_true\n        y_obs = []\n        x_true_traj = [x0]\n        x = x0.copy()\n        \n        M_true = np.eye(d) + dt * (A + theta_true * B)\n\n        for _ in range(N):\n            x = M_true @ x + dt * s\n            x_true_traj.append(x)\n        \n        for x_val in x_true_traj:\n            y_obs.append(C @ x_val)\n\n        # Helper function to run the forward model for a given theta\n        def run_forward(theta_eval):\n            x_traj = [x0]\n            x = x0.copy()\n            M_eval = np.eye(d) + dt * (A + theta_eval * B)\n            for _ in range(N):\n                x = M_eval @ x + dt * s\n                x_traj.append(x)\n            return x_traj\n\n        # Helper function to compute the objective function J(theta)\n        def compute_J(theta_eval):\n            x_traj = run_forward(theta_eval)\n            misfit = 0.0\n            for n in range(N + 1):\n                misfit += 0.5 * np.linalg.norm(C @ x_traj[n] - y_obs[n])**2\n            return misfit + 0.5 * alpha * theta_eval**2\n\n        # Step 2: Compute finite-difference gradient\n        J_plus = compute_J(theta + epsilon)\n        J_minus = compute_J(theta - epsilon)\n        g_fd = (J_plus - J_minus) / (2 * epsilon)\n\n        # Step 3: Compute adjoint-state gradient with checkpointing\n        \n        # 3a: Forward pass and checkpointing\n        checkpoint_indices = sorted(list(set(np.linspace(0, N, M_mem, dtype=int))))\n        memory_used = len(checkpoint_indices)\n        checkpoints = {}\n        \n        x_fwd_traj = [x0]\n        x = x0.copy()\n        if 0 in checkpoint_indices:\n            checkpoints[0] = x0.copy()\n            \n        M_theta = np.eye(d) + dt * (A + theta * B)\n\n        for n in range(N):\n            x = M_theta @ x + dt * s\n            x_fwd_traj.append(x)\n            if (n + 1) in checkpoint_indices:\n                checkpoints[n + 1] = x.copy()\n        \n        recompute_count = 0\n\n        # Helper for on-demand state recomputation\n        memoized_states = {}\n        def get_state(n):\n            nonlocal recompute_count\n            if n in memoized_states:\n                return memoized_states[n]\n            if n in checkpoints:\n                memoized_states[n] = checkpoints[n]\n                return checkpoints[n]\n\n            # Find nearest preceding checkpoint\n            start_n = 0\n            for k in checkpoint_indices:\n                if k < n:\n                    start_n = k\n                else:\n                    break\n            \n            x_re = checkpoints[start_n].copy()\n            for i in range(start_n, n):\n                x_re = M_theta @ x_re + dt * s\n                recompute_count += 1\n            \n            memoized_states[n] = x_re\n            return x_re\n\n        # 3b: Backward pass\n        g_adj = alpha * theta\n        M_theta_T = M_theta.T\n\n        # Initialize adjoint at n=N\n        xN = get_state(N)\n        lam = C.T @ (C @ xN - y_obs[N])\n\n        # Backward recursion from n=N down to 1\n        for n in range(N, 0, -1):\n            # At start of loop, lam is lambda_n\n            \n            # Get state x_{n-1} for gradient and adjoint update\n            x_prev = get_state(n-1)\n\n            # Update gradient: term is dt * lambda_n^T * B * x_{n-1}\n            g_adj += dt * (lam.T @ B @ x_prev)\n            \n            # Update adjoint for next iteration: compute lambda_{n-1}\n            lam = M_theta_T @ lam + C.T @ (C @ x_prev - y_obs[n-1])\n\n        abs_err = abs(g_adj - g_fd)\n        match = abs_err < tol\n\n        all_results.append([g_adj, g_fd, abs_err, recompute_count, memory_used, match])\n\n    # Final print statement\n    result_str = ','.join([str(res) for res in all_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Gradient-based optimization relies on the differentiability of the objective function, but what happens when the observation process itself is non-smooth, such as with binary or thresholded data? This practice delves into this advanced challenge by introducing mollification, a technique to create a smooth approximation of a non-differentiable operator. You will compare the gradients derived from a naive least-squares objective versus a statistically principled negative log-likelihood, providing a crucial lesson on how modeling choices impact sensitivity analysis and the performance of data assimilation schemes .",
            "id": "3419096",
            "problem": "Consider a finite-dimensional linear forward model in which the state vector $u \\in \\mathbb{R}^m$ depends on the control vector $\\theta \\in \\mathbb{R}^n$ via a known matrix $M \\in \\mathbb{R}^{m \\times n}$, so that $u = M \\theta$. Observations are binary thresholdings of the state, defined componentwise by $H(u)_i = \\mathbf{1}\\{u_i > \\tau\\}$ for a fixed threshold $\\tau \\in \\mathbb{R}$, and the observed data vector is $y \\in \\{0,1\\}^m$. Because $H$ is discontinuous and not Fréchet differentiable, introduce a mollified observation $H_\\epsilon$ parameterized by $\\epsilon > 0$ using a smooth approximation to the Heaviside step. Assume $H_\\epsilon$ acts componentwise on $u$ and satisfies $H_\\epsilon(u) \\to H(u)$ as $\\epsilon \\to 0$.\n\nYour tasks are:\n- Starting from the definitions of the Fréchet derivative of a composition, the least-squares data misfit, and the adjoint of a linear operator, derive the gradient of a least-squares objective $J_\\epsilon(\\theta) = \\tfrac{1}{2} \\| H_\\epsilon(M\\theta) - y \\|_2^2$ with respect to $\\theta$ without using any pre-packaged shortcut formulas. Clearly identify the adjoint variable that arises from the chain rule and adjoint-state construction.\n- Using a Bernoulli data model and a smooth link that matches the chosen $H_\\epsilon$, derive the gradient of the negative log-likelihood for binary data with respect to $\\theta$.\n- Analyze, at the level of distributions, the limiting behavior as $\\epsilon \\to 0$ of the sensitivities with respect to $u$ induced by $H_\\epsilon$, and explain what happens to the gradients derived above in the limit.\n- Design a quantitative diagnostic that measures the gradient bias incurred by using the least-squares objective with $H_\\epsilon$ relative to the negative log-likelihood gradient with the same link; the diagnostic must be a dimensionless float computed from the two gradients.\n\nImplementation requirements:\n- Use the logistic function as the mollifier. Specifically, define $H_\\epsilon(u)_i = \\sigma\\!\\left(\\frac{u_i - \\tau}{\\epsilon}\\right)$ with $\\sigma(z) = \\frac{1}{1 + e^{-z}}$, applied componentwise.\n- Implement two gradient computations in your program: one corresponding to the least-squares objective with $H_\\epsilon$, and one corresponding to the negative log-likelihood under a Bernoulli model with the same logistic link. Use the adjoint-state perspective to structure the computations: compute a vector of adjoint variables in observation space and apply $M^\\top$ to obtain gradients with respect to $\\theta$.\n- Implement the diagnostic as the relative difference between the two gradients, defined as $b = \\frac{\\|g_{\\text{LS}} - g_{\\text{CE}}\\|_2}{\\|g_{\\text{CE}}\\|_2 + \\delta}$, where $g_{\\text{LS}}$ is the least-squares gradient, $g_{\\text{CE}}$ is the negative log-likelihood gradient, $\\|\\cdot\\|_2$ is the Euclidean norm, and $\\delta$ is a small positive constant to avoid division by zero. Use $\\delta = 10^{-12}$.\n\nTest suite:\n- Use $m = 4$, $n = 3$, threshold $\\tau = 0.5$, and the matrix\n$$\nM = \\begin{bmatrix}\n1.0 & -0.5 & 0.2 \\\\\n0.0 & 1.0 & 0.3 \\\\\n0.5 & 0.5 & -0.4 \\\\\n-0.3 & 0.2 & 1.0\n\\end{bmatrix}.\n$$\n- Evaluate the diagnostic $b$ for each case below and for each $\\epsilon$ in the set $\\{\\;0.5,\\;0.1,\\;0.02\\;\\}$:\n    1. Happy path (some $u_i$ near $\\tau$): $\\theta = \\begin{bmatrix} 1.0 \\\\ 0.0 \\\\ -0.1 \\end{bmatrix}$, $y = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{bmatrix}$.\n    2. Boundary condition (one $u_i$ exactly at $\\tau$): $\\theta = \\begin{bmatrix} 0.0 \\\\ 1.0 \\\\ 0.0 \\end{bmatrix}$, $y = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 0 \\end{bmatrix}$.\n    3. Consistent above-threshold case: $\\theta = \\begin{bmatrix} 2.5 \\\\ 2.0 \\\\ 1.0 \\end{bmatrix}$, $y = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$.\n    4. Mismatch far below threshold: $\\theta = \\begin{bmatrix} -1.0 \\\\ -0.5 \\\\ -0.5 \\end{bmatrix}$, $y = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a comma-separated list of floats corresponding to the diagnostic $b$ for each $\\epsilon$ in the order $\\epsilon \\in \\{\\;0.5,\\;0.1,\\;0.02\\;\\}$. For example, the output should have the shape $[\\,[b_{1,0.5},b_{1,0.1},b_{1,0.02}],\\,[b_{2,0.5},b_{2,0.1},b_{2,0.02}],\\,[b_{3,0.5},b_{3,0.1},b_{3,0.02}],\\,[b_{4,0.5},b_{4,0.1},b_{4,0.02}]\\,]$, with no additional text. No physical units are involved; all outputs are unitless floats.",
            "solution": "We begin with a finite-dimensional linear forward model defined by $u = M \\theta$, where $M \\in \\mathbb{R}^{m \\times n}$ is known, and $\\theta \\in \\mathbb{R}^n$. Observations are binary thresholdings $H(u)_i = \\mathbf{1}\\{u_i > \\tau\\}$ with a fixed threshold $\\tau \\in \\mathbb{R}$, and observed data are $y \\in \\{0,1\\}^m$. Because $H$ is discontinuous and not Fréchet differentiable, we mollify $H$ using the logistic function $\\sigma(z) = \\frac{1}{1 + e^{-z}}$, defining the smooth operator $H_\\epsilon(u)$ componentwise by\n$$\nH_\\epsilon(u)_i = \\sigma\\!\\left(\\frac{u_i - \\tau}{\\epsilon}\\right).\n$$\nThis $H_\\epsilon$ satisfies $H_\\epsilon(u) \\to H(u)$ pointwise as $\\epsilon \\to 0$.\n\nWe define the least-squares objective\n$$\nJ_\\epsilon(\\theta) = \\frac{1}{2} \\| H_\\epsilon(M\\theta) - y \\|_2^2,\n$$\nand seek $\\nabla_\\theta J_\\epsilon(\\theta)$ using Fréchet derivatives and the adjoint-state formalism.\n\nFundamental base:\n- For a differentiable map $F: X \\to Y$ between normed spaces, the Fréchet derivative $DF(x): X \\to Y$ is the unique bounded linear operator satisfying $F(x + h) = F(x) + DF(x) h + o(\\|h\\|)$ as $\\|h\\| \\to 0$.\n- For compositions, the chain rule for Fréchet derivatives gives $D(G \\circ F)(x) = DG(F(x)) \\circ DF(x)$.\n- For a linear map $A: X \\to Y$ between inner product spaces, its adjoint $A^\\top: Y \\to X$ satisfies $\\langle Ax, y \\rangle_Y = \\langle x, A^\\top y \\rangle_X$.\n- For the least-squares objective $J(\\theta) = \\frac{1}{2}\\|r(\\theta)\\|_2^2$ with residual $r: \\mathbb{R}^n \\to \\mathbb{R}^m$, the Fréchet derivative is $DJ(\\theta) h = \\langle r(\\theta), Dr(\\theta) h \\rangle$, so $\\nabla_\\theta J(\\theta) = (Dr(\\theta))^\\top r(\\theta)$.\n\nApply these to $r(\\theta) = H_\\epsilon(M\\theta) - y$. The Fréchet derivative of $H_\\epsilon$ with respect to $u$ is diagonal componentwise because $H_\\epsilon$ acts componentwise:\n$$\nD H_\\epsilon(u) = \\operatorname{diag}\\!\\left(h_\\epsilon'(u)\\right),\n$$\nwhere\n$$\nh_\\epsilon'(u_i) = \\frac{\\partial}{\\partial u_i} \\sigma\\!\\left(\\frac{u_i - \\tau}{\\epsilon}\\right) = \\sigma\\!\\left(\\frac{u_i - \\tau}{\\epsilon}\\right)\\left(1 - \\sigma\\!\\left(\\frac{u_i - \\tau}{\\epsilon}\\right)\\right)\\frac{1}{\\epsilon}.\n$$\nLet $p = H_\\epsilon(u)$ denote the vector with $p_i = \\sigma\\!\\left(\\frac{u_i - \\tau}{\\epsilon}\\right)$. Then $h_\\epsilon'(u_i) = \\frac{p_i (1 - p_i)}{\\epsilon}$. Using $u = M\\theta$ and the chain rule, the Fréchet derivative of $r$ at $\\theta$ is $Dr(\\theta) = D H_\\epsilon(u) \\, M = \\operatorname{diag}(h_\\epsilon'(u)) M$. Therefore,\n$$\n\\nabla_\\theta J_\\epsilon(\\theta) = \\left(Dr(\\theta)\\right)^\\top r(\\theta) = M^\\top \\left( \\operatorname{diag}(h_\\epsilon'(u)) \\, (H_\\epsilon(u) - y) \\right).\n$$\nThis exhibits the adjoint-state structure: define the adjoint variable\n$$\n\\lambda_\\epsilon = \\operatorname{diag}(h_\\epsilon'(u)) \\, (H_\\epsilon(u) - y) \\in \\mathbb{R}^m,\n$$\nthen the gradient is $\\nabla_\\theta J_\\epsilon(\\theta) = M^\\top \\lambda_\\epsilon$.\n\nNext, consider a Bernoulli data model for binary observations with the logistic link. Given $u$, model $y_i \\sim \\operatorname{Bernoulli}(p_i)$ with $p_i = \\sigma\\!\\left(\\frac{u_i - \\tau}{\\epsilon}\\right)$. The negative log-likelihood (up to constants) is\n$$\n\\mathcal{L}_\\epsilon(\\theta) = -\\sum_{i=1}^m \\left[ y_i \\log p_i + (1 - y_i) \\log (1 - p_i) \\right].\n$$\nCompute its gradient with respect to $u$. One has\n$$\n\\frac{\\partial \\mathcal{L}_\\epsilon}{\\partial p_i} = -\\frac{y_i}{p_i} + \\frac{1 - y_i}{1 - p_i} = \\frac{p_i - y_i}{p_i(1 - p_i)},\n$$\nand\n$$\n\\frac{\\partial p_i}{\\partial u_i} = \\sigma'\\!\\left(\\frac{u_i - \\tau}{\\epsilon}\\right)\\frac{1}{\\epsilon} = \\frac{p_i(1 - p_i)}{\\epsilon}.\n$$\nThus,\n$$\n\\frac{\\partial \\mathcal{L}_\\epsilon}{\\partial u_i} = \\frac{p_i - y_i}{p_i(1 - p_i)} \\cdot \\frac{p_i(1 - p_i)}{\\epsilon} = \\frac{p_i - y_i}{\\epsilon}.\n$$\nIn vector form, with $p = H_\\epsilon(u)$ and $u = M \\theta$, the adjoint variable for the likelihood is\n$$\n\\mu_\\epsilon = \\frac{p - y}{\\epsilon},\n$$\nand the gradient with respect to $\\theta$ is\n$$\n\\nabla_\\theta \\mathcal{L}_\\epsilon(\\theta) = M^\\top \\mu_\\epsilon = M^\\top \\left( \\frac{p - y}{\\epsilon} \\right).\n$$\n\nLimit analysis as $\\epsilon \\to 0$:\nThe logistic mollifier approximates the Heaviside function. Write $z_i = \\frac{u_i - \\tau}{\\epsilon}$. Then $p_i = \\sigma(z_i) \\to \\mathbf{1}\\{u_i > \\tau\\}$ as $\\epsilon \\to 0$. The sensitivity with respect to $u$ for the least-squares objective involves $h_\\epsilon'(u_i) = \\frac{p_i(1 - p_i)}{\\epsilon}$. As $\\epsilon \\to 0$, $p_i(1 - p_i)$ tends to zero away from the threshold while concentrating around $u_i = \\tau$ with width $O(\\epsilon)$ and amplitude $O(1)$, so $h_\\epsilon'(u_i)$ forms a sequence approximating a Dirac delta centered at $u_i = \\tau$ scaled by $1/\\epsilon$. More precisely, in the sense of distributions, for a smooth test function $\\varphi$,\n$$\n\\int \\varphi(u_i) \\, h_\\epsilon'(u_i) \\, \\mathrm{d}u_i \\to \\varphi(\\tau),\n$$\nwhich shows that $h_\\epsilon'$ approximates the derivative of the Heaviside step, i.e., a Dirac delta at the threshold. Consequently, the adjoint variable $\\lambda_\\epsilon = \\operatorname{diag}(h_\\epsilon'(u)) (p - y)$ is non-negligible only for components $u_i$ within $O(\\epsilon)$ of $\\tau$, and its magnitude scales like $\\frac{|p_i - y_i|}{\\epsilon}$. Therefore $\\nabla_\\theta J_\\epsilon(\\theta) = M^\\top \\lambda_\\epsilon$ becomes increasingly concentrated and can blow up as $\\epsilon \\to 0$ when the data are inconsistent at the threshold. Similarly, for the likelihood, $\\mu_\\epsilon = \\frac{p - y}{\\epsilon}$ has uniform scaling $1/\\epsilon$ wherever $p \\neq y$, so $\\nabla_\\theta \\mathcal{L}_\\epsilon(\\theta)$ also scales like $1/\\epsilon$ in regions of mismatch, but without the additional factor $p(1 - p)$ that localizes the least-squares gradient to the threshold neighborhood. Hence, relative to the log-likelihood gradient, the least-squares gradient is suppressed away from the threshold and amplified primarily near $u_i \\approx \\tau$, which can introduce bias in gradient-based data assimilation when using squared-error misfits for binary observations.\n\nDiagnostic for gradient bias:\nDefine a dimensionless scalar diagnostic comparing the two gradients,\n$$\nb(\\theta, \\epsilon) = \\frac{\\| \\nabla_\\theta J_\\epsilon(\\theta) - \\nabla_\\theta \\mathcal{L}_\\epsilon(\\theta) \\|_2}{\\| \\nabla_\\theta \\mathcal{L}_\\epsilon(\\theta) \\|_2 + \\delta},\n$$\nwith a small $\\delta > 0$ to avoid division by zero. This diagnostic interprets $b \\approx 0$ as close agreement and larger $b$ as significant bias in the least-squares gradient relative to the likelihood gradient.\n\nAlgorithmic design:\n- Compute $u = M \\theta$.\n- Compute $p = \\sigma\\left(\\frac{u - \\tau}{\\epsilon}\\right)$ componentwise.\n- Compute the least-squares adjoint variable $\\lambda_\\epsilon = \\left( \\frac{p \\odot (1 - p)}{\\epsilon} \\right) \\odot (p - y)$, where $\\odot$ denotes componentwise multiplication, and gradient $g_{\\text{LS}} = M^\\top \\lambda_\\epsilon$.\n- Compute the likelihood adjoint variable $\\mu_\\epsilon = \\frac{p - y}{\\epsilon}$ and gradient $g_{\\text{CE}} = M^\\top \\mu_\\epsilon$.\n- Compute the diagnostic $b = \\frac{\\|g_{\\text{LS}} - g_{\\text{CE}}\\|_2}{\\|g_{\\text{CE}}\\|_2 + \\delta}$.\n- Evaluate $b$ for the prescribed test suite over the specified $\\epsilon$ values, and return the results in the required output format.\n\nThe test suite covers:\n- A happy path with some $u_i$ near $\\tau$, revealing the localized effect of $p(1 - p)$.\n- A boundary case with $u_i = \\tau$, highlighting sensitivity concentration.\n- A consistent case with all $u_i \\gg \\tau$, where both gradients are small and the diagnostic tests numerical stability.\n- A mismatch case with $u_i \\ll \\tau$ but $y_i = 1$, where both gradients can be large and the diagnostic reveals systematic differences.\n\nNo physical units are involved, and all outputs are unitless floats.",
            "answer": "```python\nimport numpy as np\n\ndef logistic(z):\n    # Numerically stable logistic function\n    # For extreme z, np.exp(-z) can overflow; using standard formulation is fine for given test values.\n    return 1.0 / (1.0 + np.exp(-z))\n\ndef gradients(M, theta, y, tau, epsilon):\n    \"\"\"\n    Compute the least-squares gradient (with mollified observation) and the\n    negative log-likelihood gradient (Bernoulli with logistic link).\n    \"\"\"\n    u = M @ theta  # state\n    z = (u - tau) / epsilon\n    p = logistic(z)\n\n    # Least-squares adjoint variable: lambda = diag(h'(u)) * (p - y)\n    # h'(u) = (p*(1-p))/epsilon\n    hprime = (p * (1.0 - p)) / epsilon\n    lam = hprime * (p - y)\n    g_ls = M.T @ lam\n\n    # Negative log-likelihood adjoint variable: mu = (p - y)/epsilon\n    mu = (p - y) / epsilon\n    g_ce = M.T @ mu\n\n    return g_ls, g_ce\n\ndef bias_diagnostic(g_ls, g_ce, delta=1e-12):\n    \"\"\"\n    Relative difference diagnostic between least-squares gradient and\n    cross-entropy (negative log-likelihood) gradient.\n    \"\"\"\n    num = np.linalg.norm(g_ls - g_ce)\n    den = np.linalg.norm(g_ce) + delta\n    return float(num / den)\n\ndef solve():\n    # Define matrix M, threshold tau, epsilon values\n    M = np.array([[1.0, -0.5, 0.2],\n                  [0.0,  1.0, 0.3],\n                  [0.5,  0.5, -0.4],\n                  [-0.3, 0.2, 1.0]], dtype=float)\n    tau = 0.5\n    epsilons = [0.5, 0.1, 0.02]\n\n    # Test cases: (theta, y)\n    test_cases = [\n        (np.array([1.0, 0.0, -0.1], dtype=float), np.array([1.0, 0.0, 1.0, 0.0], dtype=float)),  # Happy path\n        (np.array([0.0, 1.0, 0.0], dtype=float), np.array([0.0, 1.0, 1.0, 0.0], dtype=float)),    # Boundary\n        (np.array([2.5, 2.0, 1.0], dtype=float), np.array([1.0, 1.0, 1.0, 1.0], dtype=float)),    # Consistent above threshold\n        (np.array([-1.0, -0.5, -0.5], dtype=float), np.array([1.0, 1.0, 1.0, 1.0], dtype=float)), # Mismatch far below threshold\n    ]\n\n    results = []\n    for theta, y in test_cases:\n        biases = []\n        for eps in epsilons:\n            g_ls, g_ce = gradients(M, theta, y, tau, eps)\n            b = bias_diagnostic(g_ls, g_ce)\n            biases.append(b)\n        results.append(biases)\n\n    # Format output exactly as required: a single line with a comma-separated list,\n    # where each element is a comma-separated list of floats.\n    # Convert inner lists to strings without spaces for consistency.\n    inner_strs = []\n    for biases in results:\n        inner_strs.append(\"[\" + \",\".join(f\"{x:.12g}\" for x in biases) + \"]\")\n    print(\"[\" + \",\".join(inner_strs) + \"]\")\n\nsolve()\n```"
        }
    ]
}