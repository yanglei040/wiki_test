{
    "hands_on_practices": [
        {
            "introduction": "The ultimate goal of a Markov chain Monte Carlo (MCMC) sampler is to generate samples that faithfully represent the target posterior distribution. A crucial first step in any MCMC analysis is therefore visual diagnostics, which helps us assess whether the sampler is achieving this goal. This exercise hones your ability to interpret the trace plot, a fundamental diagnostic tool, and connect the sampler's dynamic behavior to the underlying properties of the target distribution, such as its modality .",
            "id": "1932803",
            "problem": "A statistician is using a Markov Chain Monte Carlo (MCMC) method to generate samples from a one-dimensional posterior probability distribution for a parameter $\\theta$. After running the sampler for a large number of iterations and discarding an initial set of samples for burn-in, they examine the trace plot of the remaining samples. The plot shows the value of $\\theta$ at each iteration. They observe that the chain does not hover around a single central value. Instead, the sampled values for $\\theta$ consistently and frequently jump back and forth between two distinct, narrow regions: one centered near $\\theta = -5.2$ and another centered near $\\theta = 2.8$. The transitions between these two regions are abrupt and happen many times throughout the sampling run.\n\nWhich of the following statements provides the most accurate interpretation of this observation?\n\nA. The MCMC sampler has failed to converge to a stationary distribution. The length of the burn-in period must be increased.\n\nB. The posterior distribution for $\\theta$ is likely bimodal, and the sampler is performing well by successfully exploring both modes of the distribution.\n\nC. The samples are exhibiting extremely high autocorrelation, which indicates the sampler is mixing very poorly and getting stuck.\n\nD. The posterior distribution is highly skewed, and the sampler is struggling to explore the long tail of the distribution.\n\nE. The proposal distribution used by the MCMC algorithm has a variance that is too small, preventing the chain from exploring the parameter space effectively.",
            "solution": "We interpret the MCMC trace after burn-in in terms of convergence to a stationary target distribution $\\pi(\\theta \\mid \\text{data})$. If the chain has converged, the empirical distribution of the samples should reflect features of $\\pi(\\theta \\mid \\text{data})$. When $\\pi(\\theta \\mid \\text{data})$ is bimodal with modes near two separated regions, a well-mixing chain typically exhibits clusters of values around each mode, with transitions across the low-probability valley separating the modes.\n\nThe observation states that, after burn-in, the chain does not hover around a single central value; instead, it frequently and abruptly alternates between two narrow regions near $\\theta=-5.2$ and $\\theta=2.8$, with many transitions throughout sampling. These features indicate:\n- Two distinct high-density regions in the target, consistent with a bimodal posterior.\n- Frequent transitions imply the sampler is not getting stuck and is adequately exploring both modes, which is a sign of acceptable mixing across modes rather than poor mixing.\n\nWe now evaluate each option:\n- A: “Failed to converge; increase burn-in.” This is unlikely because persistent visits to two regions with frequent transitions suggest the stationary distribution itself has two modes. Increasing burn-in will not eliminate true bimodality.\n- B: “Posterior is likely bimodal; sampler is successfully exploring both modes.” This directly matches the trace characteristics: two narrow clusters with frequent switches indicate a bimodal posterior and satisfactory exploration of both modes.\n- C: “Extremely high autocorrelation; mixing is poor and chain is getting stuck.” High autocorrelation and getting stuck would produce long stretches trapped in a single region with rare transitions. The observation reports many transitions, contradicting this.\n- D: “Highly skewed posterior with a long tail.” A single skewed distribution would not typically produce two distinct narrow clusters; rather, it would show a single mode with extended excursions into a tail.\n- E: “Proposal variance too small.” Too small a proposal variance would cause tiny local moves and difficulty traversing between well-separated regions, leading to rare transitions instead of frequent, abrupt jumps between modes.\n\nTherefore, the most accurate interpretation is that the posterior is bimodal and the sampler is effectively exploring both modes.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "After learning to diagnose a sampler's exploratory behavior , the natural next step is to tune it for optimal efficiency. This practice delves into the theoretical foundations of the Random Walk Metropolis algorithm, guiding you to derive its famous optimal scaling rule in high dimensions. Understanding this derivation provides deep insight into why specific tuning parameters, like the often-cited acceptance rate of approximately $0.234$, are cornerstones of MCMC practice .",
            "id": "3415063",
            "problem": "Consider a linear inverse problem with a Gaussian prior and additive Gaussian observational noise, resulting in a Gaussian posterior over the state vector $x \\in \\mathbb{R}^{d}$ with mean $\\mu$ and covariance matrix $C \\in \\mathbb{R}^{d \\times d}$, that is, the posterior density is $\\pi(x) = \\mathcal{N}(\\mu, C)$. You seek to sample from $\\pi(x)$ using Markov chain Monte Carlo (MCMC), specifically the Random Walk Metropolis (RWM) algorithm, with a symmetric Gaussian proposal of the form\n$$\nq(x' \\mid x) = \\mathcal{N}\\big(x, \\Sigma_{\\text{prop}}\\big), \\quad \\Sigma_{\\text{prop}} = s^{2} C,\n$$\nwhere $s > 0$ is a scalar step-size and $C$ serves as a preconditioner targeting the posterior covariance structure.\n\nUsing a whitened coordinate transformation $u = C^{-1/2}(x - \\mu)$ so that the target becomes standard Gaussian $\\mathcal{N}(0, I_{d})$, the proposal in whitened coordinates is $u' = u + s z$ for $z \\sim \\mathcal{N}(0, I_{d})$. In high dimensions, to avoid vanishing or exploding acceptance probabilities, it is standard to consider the scaling $s = \\ell / \\sqrt{d}$, where $\\ell > 0$ is a dimensionless step-size constant.\n\nStarting from fundamental definitions of the Random Walk Metropolis acceptance probability and asymptotic distributional approximations valid for large $d$, derive the approximate large-$d$ acceptance probability as a function of $\\ell$, and then define an efficiency metric based on the expected squared jump distance (ESJD) in the whitened coordinates. Determine the value of $\\ell$ that maximizes this efficiency, and hence obtain the optimal proposal covariance $\\Sigma_{\\text{prop}}^{\\star}$ in the original coordinates as a function of $d$ and $C$.\n\nExpress your final answer for $\\Sigma_{\\text{prop}}^{\\star}$ as a single closed-form expression in terms of $d$ and $C$, with the optimal step-size constant $\\ell^{\\star}$ rounded to three significant figures. No units are required for the final expression.",
            "solution": "We begin by recalling the Random Walk Metropolis (RWM) acceptance probability for a symmetric proposal. Given a current state $x$ and proposed state $x'$, the acceptance probability is\n$$\n\\alpha(x, x') = \\min\\Big(1, \\frac{\\pi(x')}{\\pi(x)}\\Big).\n$$\nFor a Gaussian target $\\pi(x) = \\mathcal{N}(\\mu, C)$, it is convenient to work in whitened coordinates $u = C^{-1/2}(x - \\mu)$ so that the target density becomes $\\pi(u) \\propto \\exp\\big(-\\|u\\|^{2}/2\\big)$, i.e., standard Gaussian $\\mathcal{N}(0, I_{d})$. The proposal is taken as\n$$\nu' = u + s z, \\quad z \\sim \\mathcal{N}(0, I_{d}).\n$$\nTo obtain a nondegenerate limit for the acceptance probability as the dimension $d$ grows, we adopt the scaling\n$$\ns = \\frac{\\ell}{\\sqrt{d}},\n$$\nwhere $\\ell > 0$ is a dimensionless step-size constant to be determined.\n\nThe acceptance ratio in whitened coordinates is\n$$\nr(u, u') = \\frac{\\pi(u')}{\\pi(u)} = \\exp\\Big(-\\frac{1}{2}\\big(\\|u'\\|^{2} - \\|u\\|^{2}\\big)\\Big).\n$$\nDefine the proposal increment $\\delta = u' - u = s z = \\frac{\\ell}{\\sqrt{d}} z$. Then\n$$\n\\|u'\\|^{2} - \\|u\\|^{2} = \\|u + \\delta\\|^{2} - \\|u\\|^{2} = 2 u \\cdot \\delta + \\|\\delta\\|^{2},\n$$\nand hence the log acceptance ratio is\n$$\nA = \\ln r(u, u') = - u \\cdot \\delta - \\frac{1}{2} \\|\\delta\\|^{2} = - \\frac{\\ell}{\\sqrt{d}} u \\cdot z - \\frac{1}{2} \\frac{\\ell^{2}}{d} \\|z\\|^{2}.\n$$\nWe analyze $A$ in the limit $d \\to \\infty$. Since $u \\sim \\mathcal{N}(0, I_{d})$ and $z \\sim \\mathcal{N}(0, I_{d})$ are independent, we consider the random sum\n$$\n\\frac{1}{\\sqrt{d}} u \\cdot z = \\frac{1}{\\sqrt{d}} \\sum_{i=1}^{d} u_{i} z_{i}.\n$$\nThe terms $u_{i} z_{i}$ are independent, mean-zero, and have variance $1$ by independence and standard Gaussian properties. By the Central Limit Theorem (CLT), we have\n$$\n\\frac{1}{\\sqrt{d}} u \\cdot z \\Rightarrow W \\sim \\mathcal{N}(0, 1),\n$$\nas $d \\to \\infty$. Moreover, by the Law of Large Numbers, $\\|z\\|^{2}/d \\to 1$ almost surely as $d \\to \\infty$. Therefore, in the large-$d$ limit, the log acceptance ratio converges in distribution to\n$$\nA \\Rightarrow - \\ell W - \\frac{\\ell^{2}}{2}, \\quad W \\sim \\mathcal{N}(0, 1).\n$$\nThe acceptance probability, averaged over the stationary distribution of $u$ and the proposal $z$, then converges to\n$$\n\\alpha(\\ell) = \\mathbb{E}\\big[ \\min\\big(1, \\exp(A)\\big) \\big] = \\mathbb{E}\\big[ \\min\\big(1, \\exp(- \\ell W - \\frac{\\ell^{2}}{2})\\big) \\big],\n$$\nwith $W \\sim \\mathcal{N}(0, 1)$. We compute this expectation explicitly. Let $\\phi(w) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-w^{2}/2)$ denote the standard normal probability density function (PDF), and $\\Phi$ its cumulative distribution function (CDF). Observe that\n$$\n\\min\\big(1, \\exp(- \\ell W - \\frac{\\ell^{2}}{2})\\big) =\n\\begin{cases}\n1, & \\text{if } - \\ell W - \\frac{\\ell^{2}}{2} \\ge 0 \\iff W \\le - \\frac{\\ell}{2}, \\\\\n\\exp(- \\ell W - \\frac{\\ell^{2}}{2}), & \\text{if } W > - \\frac{\\ell}{2}.\n\\end{cases}\n$$\nThus\n$$\n\\alpha(\\ell) = \\int_{-\\infty}^{- \\ell/2} \\phi(w) \\, dw + \\int_{- \\ell/2}^{\\infty} \\exp\\Big(- \\ell w - \\frac{\\ell^{2}}{2}\\Big) \\phi(w) \\, dw.\n$$\nNote that\n$$\n\\exp\\Big(- \\ell w - \\frac{\\ell^{2}}{2}\\Big) \\phi(w) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\Big( - \\frac{w^{2}}{2} - \\ell w - \\frac{\\ell^{2}}{2} \\Big) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\Big( - \\frac{(w + \\ell)^{2}}{2} \\Big) = \\phi(w + \\ell).\n$$\nTherefore,\n$$\n\\alpha(\\ell) = \\Phi\\Big( - \\frac{\\ell}{2} \\Big) + \\int_{- \\ell/2}^{\\infty} \\phi(w + \\ell) \\, dw = \\Phi\\Big( - \\frac{\\ell}{2} \\Big) + \\int_{\\ell/2}^{\\infty} \\phi(u) \\, du = \\Phi\\Big( - \\frac{\\ell}{2} \\Big) + \\big(1 - \\Phi(\\ell/2)\\big).\n$$\nUsing the symmetry $\\Phi(-a) = 1 - \\Phi(a)$, we obtain\n$$\n\\alpha(\\ell) = 2 \\Phi\\Big( - \\frac{\\ell}{2} \\Big).\n$$\n\nWe now define the efficiency metric based on expected squared jump distance (ESJD) in whitened coordinates. The squared jump length is $\\|\\delta\\|^{2} = \\frac{\\ell^{2}}{d} \\|z\\|^{2}$, and $\\|z\\|^{2} \\approx d$ for large $d$. Hence, the ESJD in the whitened coordinates is asymptotically\n$$\nJ(\\ell) = \\mathbb{E}\\big[ \\|\\delta\\|^{2} \\, \\text{accept} \\big] \\approx \\ell^{2} \\, \\alpha(\\ell) = \\ell^{2} \\cdot 2 \\Phi\\Big( - \\frac{\\ell}{2} \\Big).\n$$\nWe seek $\\ell^{\\star}$ maximizing $J(\\ell)$. Differentiate:\n$$\n\\alpha(\\ell) = 2 \\Phi\\Big( - \\frac{\\ell}{2} \\Big), \\quad \\alpha'(\\ell) = 2 \\cdot \\Big( - \\frac{1}{2} \\Big) \\phi\\Big( \\frac{\\ell}{2} \\Big) = - \\phi\\Big( \\frac{\\ell}{2} \\Big).\n$$\nThus\n$$\nJ'(\\ell) = 2 \\ell \\alpha(\\ell) + \\ell^{2} \\alpha'(\\ell) = 2 \\ell \\cdot 2 \\Phi\\Big( - \\frac{\\ell}{2} \\Big) - \\ell^{2} \\phi\\Big( \\frac{\\ell}{2} \\Big).\n$$\nSetting $J'(\\ell) = 0$ and dividing by $\\ell > 0$ gives the first-order condition\n$$\n4 \\Phi\\Big( - \\frac{\\ell}{2} \\Big) = \\ell \\, \\phi\\Big( \\frac{\\ell}{2} \\Big).\n$$\nThis transcendental equation admits a unique positive solution $\\ell^{\\star}$, which we determine numerically. Using standard root-finding (for example, Newton's method) applied to\n$$\nf(\\ell) = \\ell \\, \\phi\\Big( \\frac{\\ell}{2} \\Big) - 4 \\Phi\\Big( - \\frac{\\ell}{2} \\Big),\n$$\nwe find\n$$\n\\ell^{\\star} \\approx 2.38,\n$$\nand the corresponding optimal acceptance rate is\n$$\n\\alpha(\\ell^{\\star}) = 2 \\Phi\\Big( - \\frac{\\ell^{\\star}}{2} \\Big) \\approx 2 \\Phi(-1.19) \\approx 0.234,\n$$\na well-known near-optimal acceptance rate for RWM in high dimensions.\n\nMapping back to the original coordinates, the optimal scaling is $s^{\\star} = \\ell^{\\star}/\\sqrt{d}$, and the optimal proposal covariance is\n$$\n\\Sigma_{\\text{prop}}^{\\star} = (s^{\\star})^{2} C = \\frac{\\ell^{\\star 2}}{d} \\, C.\n$$\nWith $\\ell^{\\star}$ rounded to three significant figures, the optimal covariance is\n$$\n\\Sigma_{\\text{prop}}^{\\star} = \\frac{(2.38)^{2}}{d} \\, C.\n$$\nThis choice achieves near-optimal efficiency in the sense of maximizing the asymptotic ESJD for Random Walk Metropolis targeting a $d$-dimensional Gaussian posterior with covariance $C$.",
            "answer": "$$\\boxed{\\frac{(2.38)^{2}}{d}\\,C}$$"
        },
        {
            "introduction": "A well-tuned random walk, as optimized in the previous exercise , is a powerful workhorse. However, some problems benefit from proposals that incorporate geometric information about the target distribution, such as its gradient. This exercise provides a practical cost-benefit analysis of the Metropolis-Adjusted Langevin Algorithm (MALA), helping you quantify the trade-offs in a complex, PDE-constrained setting and make informed decisions about when the investment in a more advanced sampler is computationally justified .",
            "id": "3415120",
            "problem": "Consider a Bayesian inverse problem constrained by a partial differential equation (PDE), where the unknown parameter field $m$ enters a forward model defined by an operator $A(m)$ through the state equation $A(m) u = f$ on a bounded domain, with suitable boundary conditions. Observations are given by $d = S u + \\varepsilon$, where $S$ is a linear observation operator and $\\varepsilon$ is additive observational noise modeled as a zero-mean Gaussian with covariance matrix $\\Gamma$. The log-posterior density over $m$ is defined by the sum of a log-prior and a data misfit term derived from the Gaussian likelihood, so that evaluating the log-posterior at a given $m$ requires solving the forward PDE for $u$.\n\nIn Markov chain Monte Carlo (MCMC), two proposal mechanisms are considered for generating new states in parameter space:\n\n- A random-walk proposal with symmetric Gaussian increments, which does not use gradients.\n- The Metropolis-Adjusted Langevin Algorithm (MALA), which uses the gradient of the log-posterior with respect to $m$ to construct a drift.\n\nTo compute the gradient of the log-posterior with respect to $m$ in PDE-constrained settings, assume the standard adjoint-state method: given the current forward solution $u$ at parameter $m$, one solves the adjoint PDE to obtain an adjoint state $p$, from which $\\nabla \\log \\pi(m \\mid d)$ is assembled. Assume the following cost model:\n\n- A single forward PDE solve has computational cost $C_f$.\n- A single adjoint PDE solve has computational cost $C_a$.\n- All other operations (assembly, vector algebra, draws from Gaussian distributions, and evaluation of the prior) have negligible cost compared to PDE solves.\n\nAssume the following cache policy and acceptance computation, consistent with the Metropolis–Hastings algorithm:\n\n- At each iteration, the forward solution $u$ and log-posterior at the current parameter $m$ are already available from the previous accepted step.\n- For a random-walk proposal, generating a proposal $y$ requires no gradient evaluations, and the acceptance probability depends on evaluating the log-posterior at $y$, which requires a forward solve for $u(y)$.\n- For a MALA proposal with step size $h$, proposals are drawn as $y = m + \\frac{h}{2} \\nabla \\log \\pi(m \\mid d) + \\sqrt{h} \\, \\eta$, with $\\eta$ a standard Gaussian in parameter space. The Metropolis–Hastings acceptance ratio involves both $\\log \\pi(y \\mid d)$ and the reverse proposal density $q(m \\mid y)$, which requires $\\nabla \\log \\pi(y \\mid d)$, hence one adjoint solve at $y$. Computing $\\nabla \\log \\pi(m \\mid d)$ at the current state requires one adjoint solve at $m$, given the cached forward solution.\n\nUnder these assumptions, derive a closed-form expression for the ratio of the computational cost per proposal of MALA to that of the random-walk proposal, expressed solely in terms of $C_f$ and $C_a$. Provide your final answer as a single analytic expression. No rounding is required, and no units are needed in the final answer.",
            "solution": "The objective is to determine the ratio of the computational cost per proposal for the Metropolis-Adjusted Langevin Algorithm (MALA) to that of a standard random-walk (RW) Metropolis algorithm, within the context of a PDE-constrained Bayesian inverse problem. The costs are to be expressed in terms of the cost of a single forward PDE solve, denoted $C_f$, and the cost of a single adjoint PDE solve, denoted $C_a$. All other computational costs are assumed to be negligible.\n\nFirst, let's analyze the computational cost per proposal for the random-walk Metropolis algorithm. Let the current state of the Markov chain be $m$. The problem states that the forward solution $u(m)$ and the log-posterior $\\log \\pi(m \\mid d)$ are available from the previous accepted step and are thus cached.\n1.  A proposal $y$ is generated from a symmetric distribution, such as $y = m + \\eta$ where $\\eta$ is a draw from a zero-mean Gaussian. According to the problem statement, this step has negligible cost.\n2.  To compute the Metropolis-Hastings acceptance probability, $\\alpha = \\min\\left(1, \\frac{\\pi(y \\mid d)}{\\pi(m \\mid d)}\\right)$, we need to evaluate the posterior density at the proposed state $y$. This involves evaluating $\\log \\pi(y \\mid d)$.\n3.  The problem states that evaluating the log-posterior at a given parameter requires solving the forward PDE. Therefore, to compute $\\log \\pi(y \\mid d)$, one must first solve the state equation $A(y)u = f$ for the state $u(y)$.\n4.  The cost of this single forward PDE solve is $C_f$.\n5.  All subsequent operations (e.g., computing the data misfit, evaluating the prior, drawing a random number for the acceptance test) are assumed to have negligible cost.\n\nThus, the total computational cost per proposal for the random-walk Metropolis algorithm, denoted $\\text{Cost}_{\\text{RW}}$, is dominated by the single forward PDE solve.\n$$\n\\text{Cost}_{\\text{RW}} = C_f\n$$\n\nNext, we analyze the computational cost per proposal for the Metropolis-Adjusted Langevin Algorithm (MALA). Let the current state of the chain be $m$. As before, the forward solution $u(m)$ and log-posterior $\\log \\pi(m \\mid d)$ are cached.\n1.  A proposal $y$ is generated using a gradient-based drift term: $y = m + \\frac{h}{2} \\nabla \\log \\pi(m \\mid d) + \\sqrt{h} \\, \\eta$. To construct this proposal, the gradient of the log-posterior at the current state, $\\nabla \\log \\pi(m \\mid d)$, must be computed.\n2.  The problem specifies using the adjoint-state method for this gradient computation. Since the forward solution $u(m)$ is already available (cached), computing the gradient requires only a single solve of the adjoint PDE. The cost of this operation is $C_a$.\n3.  After computing the gradient, the proposal $y$ is formed. The algebraic operations for this have negligible cost.\n4.  The Metropolis-Hastings acceptance probability for MALA is $\\alpha = \\min\\left(1, \\frac{\\pi(y \\mid d) q(m \\mid y)}{\\pi(m \\mid d) q(y \\mid m)}\\right)$. To evaluate this ratio, we need to compute two terms: the log-posterior at the proposal, $\\log \\pi(y \\mid d)$, and the density of the reverse proposal, $q(m \\mid y)$.\n5.  To evaluate $\\log \\pi(y \\mid d)$, we must, as in the random-walk case, solve the forward PDE at $y$ to obtain $u(y)$. The cost of this forward solve is $C_f$.\n6.  To evaluate the reverse proposal density $q(m \\mid y)$, we must compute the drift term for a proposal starting from $y$. This drift term depends on the gradient at the proposed state, $\\nabla \\log \\pi(y \\mid d)$.\n7.  To compute $\\nabla \\log \\pi(y \\mid d)$ using the adjoint-state method, we need the forward solution $u(y)$ and the corresponding adjoint solution $p(y)$. The forward solution $u(y)$ was already computed in the previous step (cost $C_f$). Therefore, we now only need to solve the adjoint PDE at state $y$. The cost of this second adjoint solve is $C_a$.\n\nSumming the costs of the dominant operations for a single MALA proposal:\n- One adjoint solve at the current state $m$ to compute the proposal drift: $C_a$.\n- One forward solve at the proposed state $y$ to evaluate the posterior: $C_f$.\n- One adjoint solve at the proposed state $y$ to compute the reverse proposal density: $C_a$.\n\nThe total computational cost per proposal for the MALA algorithm, denoted $\\text{Cost}_{\\text{MALA}}$, is the sum of these costs.\n$$\n\\text{Cost}_{\\text{MALA}} = C_a + C_f + C_a = C_f + 2C_a\n$$\n\nFinally, we compute the desired ratio of the computational cost per proposal of MALA to that of the random-walk proposal.\n$$\n\\text{Ratio} = \\frac{\\text{Cost}_{\\text{MALA}}}{\\text{Cost}_{\\text{RW}}} = \\frac{C_f + 2C_a}{C_f}\n$$\nThis expression can be simplified as:\n$$\n\\text{Ratio} = 1 + \\frac{2C_a}{C_f}\n$$\nHowever, the form showing the ratio of total costs is more direct. Both are equivalent. We will provide the unsimplified fraction.",
            "answer": "$$\n\\boxed{\\frac{C_f + 2C_a}{C_f}}\n$$"
        }
    ]
}