{
    "hands_on_practices": [
        {
            "introduction": "构建吉布斯采样器的第一步是为模型中的每个未知参数推导其全条件分布。本练习将通过一个在数据同化中常见的经典分层高斯模型，带你实践这一核心技能。通过处理中心化和非中心化这两种不同的参数化方案，你不仅能掌握如何利用贝叶斯定理和高斯分布的性质来推导条件分布，还能深入理解不同参数化策略对采样器性能的潜在影响。",
            "id": "3386530",
            "problem": "考虑一个数据同化场景，其中一个由 $n$ 个传感器组成的网络正在测量一个潜在的校准偏移场。设观测数据为 $y_{i} \\in \\mathbb{R}$（$i=1,\\dots,n$），并考虑以下分层随机效应反演模型\n- 观测（似然）：$y_{i} \\mid x_{i} \\sim \\mathcal{N}(x_{i}, \\sigma^{2})$，对于 $i=1,\\dots,n$ 独立。\n- 随机效应（状态模型）：$x_{i} \\mid \\mu \\sim \\mathcal{N}(\\mu, \\tau^{2})$，对于 $i=1,\\dots,n$ 独立。\n- 超先验：$\\mu \\sim \\mathcal{N}(0, \\kappa^{2})$。\n\n假设 $\\sigma^{2} > 0$、$\\tau^{2} > 0$ 和 $\\kappa^{2} > 0$ 均为已知。对于吉布斯抽样（一种马尔可夫链蒙特卡洛（MCMC）方法），我们对两种等价的参数化感兴趣：\n\n1) 中心化参数化：直接抽取潜在效应 $x_{1},\\dots,x_{n}$ 和超参数 $\\mu$。\n\n2) 非中心化参数化：重参数化为 $x_{i} = \\mu + \\tau z_{i}$，其中 $z_{i} \\sim \\mathcal{N}(0,1)$ 独立，并抽取 $z_{1},\\dots,z_{n}$ 和 $\\mu$。\n\n任务：\n1) 从模型所蕴含的联合密度出发，仅使用高斯分布的基本性质和共轭性，推导中心化参数化的全条件分布：对每个 $i$ 的 $x_{i} \\mid \\mu, y_{i}$，以及 $\\mu \\mid x_{1:n}, y_{1:n}$。\n\n2) 推导非中心化参数化的全条件分布：对每个 $i$ 的 $z_{i} \\mid \\mu, y_{i}$，以及 $\\mu \\mid z_{1:n}, y_{1:n}$。\n\n3) 通过解析地边缘化潜在效应 $x_{1:n}$，推导观测模型 $y_{i} \\mid \\mu$ 并用它来获得后验分布 $\\mu \\mid y_{1:n}$。请以 $\\{y_{i}\\}_{i=1}^{n}$、$\\sigma^{2}$、$\\tau^{2}$、$\\kappa^{2}$ 和 $n$ 的形式，为后验均值 $\\mathbb{E}[\\mu \\mid y_{1:n}]$ 提供一个单一的闭式解析表达式。不要代入数值；无需四舍五入。最终答案必须是一个单一的解析表达式。",
            "solution": "该问题提出了一个标准的贝叶斯分层模型，并要求推导与吉布斯抽样相关的几个条件分布和后验分布，以及推导一个边缘后验均值。该模型具有科学依据，问题设定良好，且所有必要信息均已提供。因此，该问题是有效的，可以推导出解。\n\n该分层模型定义如下：\n- 观测模型（似然）：$y_{i} \\mid x_{i} \\sim \\mathcal{N}(x_{i}, \\sigma^{2})$，对于 $i=1,\\dots,n$。\n- 状态模型：$x_{i} \\mid \\mu \\sim \\mathcal{N}(\\mu, \\tau^{2})$，对于 $i=1,\\dots,n$。\n- 超先验：$\\mu \\sim \\mathcal{N}(0, \\kappa^{2})$。\n方差 $\\sigma^{2}$、$\\tau^{2}$ 和 $\\kappa^{2}$ 均为已知常数。\n\n正态分布 $\\mathcal{N}(m, s^2)$ 的概率密度函数 (PDF) 由 $p(x) = (2\\pi s^2)^{-1/2} \\exp(-\\frac{(x-m)^2}{2s^2})$ 给出。在涉及高斯函数乘积的推导中，通常只需处理指数中的项，因为它们唯一地确定了结果高斯分布的均值和方差。如果 $\\ln p(z)$ 是 $z$ 的二次函数，则密度 $p(z)$ 是高斯的。具体来说，如果 $p(z) \\propto \\exp(-\\frac{1}{2}(Az^2 - 2Bz))$，则 $z$ 服从正态分布，其均值为 $B/A$，方差为 $1/A$。这等价于配方法。\n\n**1) 中心化参数化的全条件分布**\n\n**$p(x_{i} \\mid \\mu, y_{i})$ 的推导：**\n$x_i$ 的全条件分布由其与马尔可夫毯的关系决定，在该模型中，马尔可夫毯由 $y_i$ 和 $\\mu$ 组成。使用贝叶斯定理，条件分布正比于似然与 $x_i$ 的先验的乘积：\n$$p(x_{i} \\mid \\mu, y_{i}) \\propto p(y_i, x_i, \\mu) \\propto p(y_{i} \\mid x_{i}) p(x_{i} \\mid \\mu)$$\n这里，我们有 $p(y_{i} \\mid x_{i}) \\propto \\exp\\left(-\\frac{(y_i - x_i)^2}{2\\sigma^2}\\right)$ 和 $p(x_{i} \\mid \\mu) \\propto \\exp\\left(-\\frac{(x_i - \\mu)^2}{2\\tau^2}\\right)$。\n其乘积正比于各指数项之和的指数：\n$$p(x_{i} \\mid \\mu, y_{i}) \\propto \\exp\\left( -\\frac{(x_i - y_i)^2}{2\\sigma^2} - \\frac{(x_i - \\mu)^2}{2\\tau^2} \\right)$$\n为了找到结果高斯分布的参数，我们展开指数中关于 $x_i$ 的二次项：\n$$-\\frac{1}{2\\sigma^2}(x_i^2 - 2x_iy_i + y_i^2) - \\frac{1}{2\\tau^2}(x_i^2 - 2x_i\\mu + \\mu^2)$$\n收集包含 $x_i^2$ 和 $x_i$ 的项：\n$$-\\frac{1}{2} \\left[ x_i^2 \\left(\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}\\right) - 2x_i \\left(\\frac{y_i}{\\sigma^2} + \\frac{\\mu}{\\tau^2}\\right) \\right] + C$$\n其中 $C$ 包含不依赖于 $x_i$ 的项。这是 $x_i$ 的一个正态分布的指数部分。精度（方差的倒数）是 $x_i^2/2$ 的系数，均值是 $x_i$ 的系数除以精度。\n精度为 $\\frac{1}{\\sigma_{x_i}^2} = \\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2} = \\frac{\\sigma^2+\\tau^2}{\\sigma^2\\tau^2}$。因此，方差为 $\\sigma_{x_i}^2 = \\frac{\\sigma^2\\tau^2}{\\sigma^2+\\tau^2}$。\n均值 $\\mu_{x_i}$ 由 $\\mu_{x_i} / \\sigma_{x_i}^2 = \\frac{y_i}{\\sigma^2} + \\frac{\\mu}{\\tau^2}$ 给出。\n$$\\mu_{x_i} = \\left(\\frac{\\sigma^2\\tau^2}{\\sigma^2+\\tau^2}\\right)\\left(\\frac{y_i}{\\sigma^2} + \\frac{\\mu}{\\tau^2}\\right) = \\frac{\\tau^2y_i + \\sigma^2\\mu}{\\sigma^2+\\tau^2}$$\n所以，全条件分布为 $x_{i} \\mid \\mu, y_{i} \\sim \\mathcal{N}\\left(\\frac{y_i\\tau^2 + \\mu\\sigma^2}{\\sigma^2+\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2+\\tau^2}\\right)$。\n\n**$p(\\mu \\mid x_{1:n}, y_{1:n})$ 的推导：**\n给定潜在效应 $x_{1:n}$，$\\mu$ 条件独立于观测值 $y_{1:n}$。因此，$p(\\mu \\mid x_{1:n}, y_{1:n}) = p(\\mu \\mid x_{1:n})$。\n$$p(\\mu \\mid x_{1:n}) \\propto p(x_{1:n} \\mid \\mu) p(\\mu) = \\left(\\prod_{i=1}^n p(x_i \\mid \\mu)\\right) p(\\mu)$$\n指数部分是个体概率密度函数指数项的总和：\n$$\\sum_{i=1}^n \\left(-\\frac{(x_i - \\mu)^2}{2\\tau^2}\\right) - \\frac{(\\mu - 0)^2}{2\\kappa^2} = -\\frac{1}{2\\tau^2}\\sum_{i=1}^n(x_i - \\mu)^2 - \\frac{\\mu^2}{2\\kappa^2}$$\n展开关于 $\\mu$ 的二次项：\n$$-\\frac{1}{2\\tau^2}(\\sum x_i^2 - 2\\mu\\sum x_i + n\\mu^2) - \\frac{\\mu^2}{2\\kappa^2}$$\n收集包含 $\\mu^2$ 和 $\\mu$ 的项：\n$$-\\frac{1}{2} \\left[ \\mu^2 \\left(\\frac{n}{\\tau^2} + \\frac{1}{\\kappa^2}\\right) - 2\\mu \\left(\\frac{\\sum_{i=1}^n x_i}{\\tau^2}\\right) \\right] + C'$$\n$\\mu$ 的后验精度为 $\\frac{1}{\\sigma_{\\mu}^2} = \\frac{n}{\\tau^2} + \\frac{1}{\\kappa^2} = \\frac{n\\kappa^2+\\tau^2}{\\tau^2\\kappa^2}$。方差为 $\\sigma_{\\mu}^2 = \\frac{\\tau^2\\kappa^2}{n\\kappa^2+\\tau^2}$。\n后验均值 $\\mu_{\\mu}$ 由 $\\mu_{\\mu} / \\sigma_{\\mu}^2 = \\frac{\\sum x_i}{\\tau^2}$ 给出。\n$$\\mu_{\\mu} = \\left(\\frac{\\tau^2\\kappa^2}{n\\kappa^2+\\tau^2}\\right) \\left(\\frac{\\sum x_i}{\\tau^2}\\right) = \\frac{\\kappa^2 \\sum_{i=1}^n x_i}{n\\kappa^2+\\tau^2}$$\n所以，全条件分布为 $\\mu \\mid x_{1:n} \\sim \\mathcal{N}\\left(\\frac{\\kappa^2 \\sum_{i=1}^n x_i}{n\\kappa^2+\\tau^2}, \\frac{\\tau^2\\kappa^2}{n\\kappa^2+\\tau^2}\\right)$。\n\n**2) 非中心化参数化的全条件分布**\n\n这里，我们有 $x_i = \\mu + \\tau z_i$，其中 $z_i \\sim \\mathcal{N}(0, 1)$。似然函数变为 $y_i \\mid \\mu, z_i \\sim \\mathcal{N}(\\mu + \\tau z_i, \\sigma^2)$。\n\n**$p(z_{i} \\mid \\mu, y_{i})$ 的推导：**\n$z_i$ 的条件分布取决于 $y_i$ 和 $\\mu$。\n$$p(z_i \\mid \\mu, y_i) \\propto p(y_i \\mid z_i, \\mu) p(z_i)$$\n指数为 $-\\frac{(y_i - (\\mu + \\tau z_i))^2}{2\\sigma^2} - \\frac{z_i^2}{2(1)^2}$。展开关于 $z_i$ 的二次项：\n$$-\\frac{1}{2\\sigma^2}((y_i-\\mu)^2 - 2\\tau z_i(y_i-\\mu) + \\tau^2 z_i^2) - \\frac{z_i^2}{2}$$\n收集包含 $z_i^2$ 和 $z_i$ 的项：\n$$-\\frac{1}{2} \\left[ z_i^2 \\left(\\frac{\\tau^2}{\\sigma^2} + 1\\right) - 2z_i \\left(\\frac{\\tau(y_i-\\mu)}{\\sigma^2}\\right) \\right] + C''$$\n$z_i$ 的后验精度为 $\\frac{1}{\\sigma_{z_i}^2} = \\frac{\\tau^2}{\\sigma^2} + 1 = \\frac{\\tau^2+\\sigma^2}{\\sigma^2}$。方差为 $\\sigma_{z_i}^2 = \\frac{\\sigma^2}{\\sigma^2+\\tau^2}$。\n后验均值 $\\mu_{z_i}$ 由 $\\mu_{z_i} / \\sigma_{z_i}^2 = \\frac{\\tau(y_i-\\mu)}{\\sigma^2}$ 给出。\n$$\\mu_{z_i} = \\left(\\frac{\\sigma^2}{\\sigma^2+\\tau^2}\\right) \\left(\\frac{\\tau(y_i-\\mu)}{\\sigma^2}\\right) = \\frac{\\tau(y_i - \\mu)}{\\sigma^2+\\tau^2}$$\n所以，$z_i \\mid \\mu, y_i \\sim \\mathcal{N}\\left(\\frac{\\tau(y_i - \\mu)}{\\sigma^2+\\tau^2}, \\frac{\\sigma^2}{\\sigma^2+\\tau^2}\\right)$。\n\n**$p(\\mu \\mid z_{1:n}, y_{1:n})$ 的推导：**\n$\\mu$ 的条件分布通过 $p(\\mu \\mid z_{1:n}, y_{1:n}) \\propto p(y_{1:n} \\mid \\mu, z_{1:n}) p(\\mu)$ 求得。\n似然项为 $p(y_{1:n} \\mid \\mu, z_{1:n}) = \\prod_{i=1}^n p(y_i \\mid \\mu, z_i)$。我们定义 $w_i = y_i - \\tau z_i$。那么 $y_i - \\mu - \\tau z_i = w_i - \\mu$。单个观测的似然为 $p(y_i \\mid \\mu, z_i) \\propto \\exp(-\\frac{(w_i - \\mu)^2}{2\\sigma^2})$。这意味着我们观测到 $w_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$。\n现在的推断问题是，在给定来自 $\\mathcal{N}(\\mu, \\sigma^2)$ 分布的观测值 $w_{1:n}$ 和 $\\mu$ 的先验分布为 $\\mathcal{N}(0, \\kappa^2)$ 的情况下，求 $\\mu$ 的后验分布。这在结构上与 $p(\\mu \\mid x_{1:n})$ 的推导相同，只是将 $x_i$ 替换为 $w_i$，将 $\\tau^2$ 替换为 $\\sigma^2$。\n遵循相同的逻辑，$\\mu$ 的后验分布是一个正态分布，其均值和方差为：\n$$\\mu_{\\mu|z,y} = \\frac{\\kappa^2 \\sum_{i=1}^n w_i}{n\\kappa^2+\\sigma^2} = \\frac{\\kappa^2 \\sum_{i=1}^n (y_i - \\tau z_i)}{n\\kappa^2+\\sigma^2}$$\n$$\\sigma_{\\mu|z,y}^2 = \\frac{\\sigma^2\\kappa^2}{n\\kappa^2+\\sigma^2}$$\n因此，$\\mu \\mid z_{1:n}, y_{1:n} \\sim \\mathcal{N}\\left(\\frac{\\kappa^2 \\sum_{i=1}^n (y_i - \\tau z_i)}{n\\kappa^2+\\sigma^2}, \\frac{\\sigma^2\\kappa^2}{n\\kappa^2+\\sigma^2}\\right)$。\n\n**3) $\\mu$ 的边缘后验分布**\n\n首先，我们通过对 $x_i$ 积分来求出给定 $\\mu$ 时 $y_i$ 的边缘分布：\n$$p(y_i \\mid \\mu) = \\int p(y_i \\mid x_i) p(x_i \\mid \\mu) dx_i$$\n这是两个高斯分布的卷积。设 $x_i = \\mu + \\delta_i$ 其中 $\\delta_i \\sim \\mathcal{N}(0, \\tau^2)$，以及 $y_i = x_i + \\epsilon_i$ 其中 $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。那么 $y_i = \\mu + \\delta_i + \\epsilon_i$。\n给定 $\\mu$ 时 $y_i$ 的均值为 $\\mathbb{E}[y_i \\mid \\mu] = \\mathbb{E}[\\mu + \\delta_i + \\epsilon_i] = \\mu + 0 + 0 = \\mu$。\n给定 $\\mu$ 时 $y_i$ 的方差，因为 $\\delta_i$ 和 $\\epsilon_i$ 独立，为 $\\text{Var}(y_i \\mid \\mu) = \\text{Var}(\\delta_i) + \\text{Var}(\\epsilon_i) = \\tau^2 + \\sigma^2$。\n所以，边缘观测模型为 $y_i \\mid \\mu \\sim \\mathcal{N}(\\mu, \\sigma^2 + \\tau^2)$。\n\n现在，我们使用这个边缘似然来推导后验分布 $p(\\mu \\mid y_{1:n})$。\n$$p(\\mu \\mid y_{1:n}) \\propto p(y_{1:n} \\mid \\mu) p(\\mu) = \\left(\\prod_{i=1}^n p(y_i \\mid \\mu)\\right) p(\\mu)$$\n给定 $\\mu$ 时，观测值 $y_i$ 是独立的。我们有一个来自 $\\mathcal{N}(\\mu, \\sigma^2+\\tau^2)$ 的样本 $y_{1:n}$ 和一个先验 $\\mu \\sim \\mathcal{N}(0, \\kappa^2)$。这又是一个标准的共轭先验更新。该问题与 $p(\\mu \\mid x_{1:n})$ 的推导同构，只需将 $x_i$ 替换为 $y_i$，并将 $\\tau^2$ 替换为 $\\sigma^2+\\tau^2$。\n后验分布 $p(\\mu \\mid y_{1:n})$ 是一个正态分布。其均值为 $\\mathbb{E}[\\mu \\mid y_{1:n}]$。使用第1部分推导出的公式：\n$$\\mathbb{E}[\\mu \\mid y_{1:n}] = \\frac{\\kappa^2 \\sum_{i=1}^n y_i}{n\\kappa^2 + (\\sigma^2 + \\tau^2)}$$\n这是后验均值的最终表达式。它可以重写为：\n$$\\mathbb{E}[\\mu \\mid y_{1:n}] = \\frac{n\\kappa^2}{n\\kappa^2 + \\sigma^2 + \\tau^2} \\left(\\frac{1}{n} \\sum_{i=1}^n y_i\\right) + \\frac{\\sigma^2 + \\tau^2}{n\\kappa^2 + \\sigma^2 + \\tau^2} (0)$$\n这表明它是样本均值 $\\bar{y}$ 和先验均值 $0$ 的加权平均。\n\n最终答案要求是后验均值 $\\mathbb{E}[\\mu \\mid y_{1:n}]$ 的一个单一闭式解析表达式。",
            "answer": "$$\n\\boxed{\\frac{\\kappa^2 \\sum_{i=1}^{n} y_i}{n\\kappa^2 + \\sigma^2 + \\tau^2}}\n$$"
        },
        {
            "introduction": "在理想情况下，所有全条件分布都是我们可以直接采样的标准分布，但现实往往并非如此。当遇到一个形式复杂、难以直接抽样的全条件分布时，我们该怎么办？本练习介绍了一种强大的混合方法——吉布斯内部梅特罗波利斯（Metropolis-within-Gibbs）步骤。你将从细致平衡这一基本原理出发，为单变量更新推导正确的接受概率，从而确保即使在面对棘手的条件分布时，你的马尔可夫链也能收敛到目标后验分布。",
            "id": "3386603",
            "problem": "考虑一个数据同化中的贝叶斯逆问题，其中未知状态向量 $x \\in \\mathbb{R}^{d}$ 是从观测值 $y \\in \\mathbb{R}^{m}$ 推断出来的。设先验密度为 $p(x)$，似然为 $L(y \\mid x)$，两者在其支撑集上均严格为正。后验密度由 Bayes 定理定义为 $ \\pi(x \\mid y) \\propto L(y \\mid x)\\,p(x) $。您的任务是通过逐分量的马尔可夫链蒙特卡洛 (MCMC) 方法从 $ \\pi(x \\mid y) $ 中进行采样。\n\n假设您打算在给定 $x_{-i}$（即移除了第 $i$ 个分量的向量 $x$）的情况下对坐标 $x_{i}$ 进行 Gibbs 更新，但全条件密度 $ \\pi(x_{i} \\mid x_{-i}, y) $ 并没有易于处理的形式。作为替代，您设计了一个 Metropolis-within-Gibbs (MwG) 步骤，该步骤从一个提议密度 $ q(x_{i}' \\mid x_{-i}) $ 中提议一个新值 $x_{i}'$（该密度在 $ \\pi(x \\mid y) $ 为正的任意地方都有支撑），并保持 $x_{-i}$ 不变。\n\n仅使用 Metropolis-Hastings (MH) 方法的核心定义（即作为一个相对于目标分布强制满足细致平衡的马尔可夫核）以及后验分布的定义 $ \\pi(x \\mid y) \\propto L(y \\mid x)\\,p(x) $，推导此 MwG 移动的接受概率 $ \\alpha_{i}(x_{i} \\to x_{i}' ; x_{-i}) $。您的推导过程必须明确使用针对保持 $x_{-i}$ 固定的单坐标提议的细致平衡条件。将您的最终答案表示为用 $ L(y \\mid x) $、$ p(x) $ 和 $ q(x_{i}' \\mid x_{-i}) $ 表示的单一闭式解析表达式。\n\n给出接受概率的最终表达式。最终答案必须是单一的闭式解析表达式。不要在最终答案中提供步骤。",
            "solution": "该问题要求推导 Metropolis-within-Gibbs (MwG) 步骤的接受概率。推导过程必须基于细致平衡原理，该原理是 Metropolis-Hastings (MH) 算法的基石。\n\n设目标分布为后验密度 $\\pi(x \\mid y)$，其中 $x \\in \\mathbb{R}^{d}$ 是状态向量，$y \\in \\mathbb{R}^{m}$ 是观测值。对于任意两个状态 $x$ 和 $x'$，如果马尔可夫链转移核 $K(x' \\mid x)$ 满足以下相对于 $\\pi(x \\mid y)$ 的细致平衡条件：\n$$ \\pi(x \\mid y) K(x' \\mid x) = \\pi(x' \\mid y) K(x \\mid x') $$\nMH 算法构造了这样一个核。从状态 $x$ 到新状态 $x'$ 的转移是一个两步过程：\n1. 从提议分布 $Q(x' \\mid x)$ 中生成一个候选状态 $x'$。\n2. 候选状态 $x'$ 以概率 $\\alpha(x \\to x')$ 被接受。如果被拒绝，链将保持在状态 $x$。\n\n对于 $x' \\neq x$ 的转移，转移核由 $K(x' \\mid x) = Q(x' \\mid x) \\alpha(x \\to x')$ 给出。将此代入细致平衡方程可得：\n$$ \\pi(x \\mid y) Q(x' \\mid x) \\alpha(x \\to x') = \\pi(x' \\mid y) Q(x \\mid x') \\alpha(x' \\to x) $$\n满足此关系的接受概率的标准选择是 Metropolis-Hastings 接受概率：\n$$ \\alpha(x \\to x') = \\min \\left( 1, \\frac{\\pi(x' \\mid y) Q(x \\mid x')}{\\pi(x \\mid y) Q(x' \\mid x)} \\right) $$\n\n在给定问题的背景下，我们不是一次性更新整个向量 $x$，而是对单个坐标 $x_i$ 执行逐分量更新。这是通用 MH 框架的一个特定实例。设当前状态为 $x = (x_i, x_{-i})$，其中 $x_{-i}$ 是除 $x_i$ 外所有分量组成的向量。提议的移动只改变第 $i$ 个分量。提议一个新值 $x_i'$，得到候选状态 $x' = (x_i', x_{-i})$。其他分量保持固定，因此 $x'_{-i} = x_{-i}$。\n\n新分量 $x_i'$ 的提议是从一个指定为 $q(x_i' \\mid x_{-i})$ 的密度中抽取的。这定义了*完整状态向量*的提议分布，对于这个第 $i$ 个分量的更新步骤，我们将其记为 $Q_i(x' \\mid x)$。由于从 $x$ 到 $x'$ 的移动是通过随机选择 $x_i'$ 同时确定性地保持 $x_{-i}$ 固定而提议的，因此正向提议概率密度为：\n$$ Q_i(x' \\mid x) = q(x_i' \\mid x_{-i}) $$\n这里隐含了该提议是在给定 $x=(x_i, x_{-i})$ 的情况下针对 $x'=(x_i', x_{-i})$ 的。\n\n为了计算接受概率，我们还需要逆向提议概率密度 $Q_i(x \\mid x')$。这是从新状态 $x'$ 开始提议原始状态 $x$ 的概率。逆向移动是从 $x' = (x_i', x_{-i})$ 到 $x = (x_i, x_{-i})$。根据问题的定义，对一个分量新值（本例中为 $x_i$）的提议取决于做出提议的状态的其他分量（本例中为 $x_{-i}'$）。由于 $x_{-i}' = x_{-i}$，逆向提议概率密度为：\n$$ Q_i(x \\mid x') = q(x_i \\mid x_{-i}' ) = q(x_i \\mid x_{-i}) $$\n这表明对第 $i$ 个分量值的提议取决于其他分量的值，而不是第 $i$ 个分量本身当前的值。\n\n现在我们可以将这些特定形式的提议分布代入通用的 MH 接受公式。我们将使用记号 $\\alpha_i(x_i \\to x_i' ; x_{-i})$ 来表示这个特定于分量的接受概率。\n$$ \\alpha_{i}(x_{i} \\to x_{i}' ; x_{-i}) = \\min \\left( 1, \\frac{\\pi(x' \\mid y) Q_i(x \\mid x')}{\\pi(x \\mid y) Q_i(x' \\mid x)} \\right) = \\min \\left( 1, \\frac{\\pi(x' \\mid y) \\, q(x_i \\mid x_{-i})}{\\pi(x \\mid y) \\, q(x_i' \\mid x_{-i})} \\right) $$\n\n问题陈述后验密度由 Bayes 定理给出，$\\pi(x \\mid y) \\propto L(y \\mid x) p(x)$。比例常数与 $x$ 无关，在比率中会被消掉。因此，对于任何状态 $z$，我们可以用乘积 $L(y \\mid z) p(z)$ 来替换 $\\pi(z \\mid y)$：\n$$ \\alpha_{i}(x_{i} \\to x_{i}' ; x_{-i}) = \\min \\left( 1, \\frac{L(y \\mid x')p(x') \\, q(x_i \\mid x_{-i})}{L(y \\mid x)p(x) \\, q(x_i' \\mid x_{-i})} \\right) $$\n\n为了以完全显式的形式给出最终表达式，我们回顾 $x = (x_i, x_{-i})$ 和 $x' = (x_i', x_{-i})$，并用分量来写出似然 $L$ 和先验 $p$ 的参数：\n$$ \\alpha_{i}(x_{i} \\to x_{i}' ; x_{-i}) = \\min \\left( 1, \\frac{L(y \\mid x_{i}', x_{-i}) p(x_{i}', x_{-i}) \\, q(x_{i} \\mid x_{-i})}{L(y \\mid x_{i}, x_{-i}) p(x_{i}, x_{-i}) \\, q(x_{i}' \\mid x_{-i})} \\right) $$\n这就是指定的 Metropolis-within-Gibbs 步骤的接受概率的最终闭式表达式，它是直接从细致平衡条件推导出来的。",
            "answer": "$$\n\\boxed{\\min \\left( 1, \\frac{L(y \\mid x_{i}', x_{-i}) p(x_{i}', x_{-i}) \\, q(x_{i} \\mid x_{-i})}{L(y \\mid x_{i}, x_{-i}) p(x_{i}, x_{-i}) \\, q(x_{i}' \\mid x_{-i})} \\right)}\n$$"
        },
        {
            "introduction": "许多物理模型中的参数都带有自然约束，例如扩散系数必须为正，或者相关系数必须在 $(0,1)$ 区间内。直接在受限空间上进行吉布斯采样可能会导致采样器无法遍历整个后验分布，从而破坏遍历性。本练习探讨了这一关键的实际问题，并引导你应用变量变换技术，将受限参数映射到无约束空间。通过这个过程，你将学会如何正确运用雅可比行列式来调整目标密度，这是确保变换后采样结果正确性的核心步骤。",
            "id": "3386585",
            "problem": "考虑一个贝叶斯数据同化反问题，其中未知参数向量 $\\theta = (\\kappa,\\rho)$ 出现在一个状态空间模型中，该模型描述了通过带噪声的线性测量 $y$ 观测到的隐藏状态 $x$。假设 $\\kappa$ 是一个正的扩散系数，$\\rho$ 是一个自相关参数，因此自然参数空间为 $\\Theta = (0,\\infty) \\times (0,1)$。设后验分布为\n$$\n\\pi(\\kappa,\\rho,x \\mid y) \\propto \\pi(y \\mid x)\\,\\pi(x \\mid \\kappa,\\rho)\\,\\pi(\\kappa)\\,\\pi(\\rho),\n$$\n其中 $\\pi(y \\mid x)$ 是由线性观测算子诱导的高斯似然，$\\pi(x \\mid \\kappa,\\rho)$ 是一个高斯律，其均值和协方差通过一个物理推导的动力学模型依赖于 $(\\kappa,\\rho)$，而 $\\pi(\\kappa)$ 和 $\\pi(\\rho)$ 分别是支撑在 $(0,\\infty)$ 和 $(0,1)$ 上的正常先验。一个标准的 Gibbs 采样器通过从给定另一个块和数据 $y$ 的全条件分布中采样，交替更新块 $(x)$ 和 $(\\kappa,\\rho)$。\n\n你的任务是从第一性原理出发，论证约束条件 $\\kappa \\in (0,\\infty)$ 和 $\\rho \\in (0,1)$ 如何影响 $(\\kappa,\\rho)$ 块内坐标级 Gibbs 更新的遍历性，并提出一种变换，以实现无约束的 Gibbs 采样，同时保持 $(\\kappa,\\rho)$ 上的后验分布。\n\n选择所有正确的陈述。\n\nA. 在约束空间 $\\Theta = (0,\\infty)\\times(0,1)$ 中，一个从其正常全条件分布中采样 $\\kappa \\mid (\\rho,x,y)$ 和 $\\rho \\mid (\\kappa,x,y)$ 的坐标级 Gibbs 采样器必然是遍历的；如果每个条件分布在其受约束的支撑集上处处为正，则约束不会导致可约性。\n\nB. 映射 $(u,v) = T(\\kappa,\\rho)$，其中 $u = \\log \\kappa$ 和 $v = \\log\\!\\big(\\rho/(1-\\rho)\\big)$，是从 $\\Theta$ 到 $\\mathbb{R}^2$ 的一个双射连续可微变换，并且变换后坐标中相应的经雅可比行列式调整的联合密度正比于\n$$\n\\pi(y \\mid x)\\,\\pi\\!\\big(x \\mid \\kappa,\\rho\\big)\\,\\pi(\\kappa)\\,\\pi(\\rho)\\, e^{u}\\,\\sigma(v)\\,\\big(1-\\sigma(v)\\big),\n$$\n其中 $\\kappa = e^{u}$，$\\rho = \\sigma(v)$，且 $\\sigma(v) = (1+e^{-v})^{-1}$。对 $(u,v)$ 运行以这个变换后的密度为目标的 Gibbs 采样，通过逆映射得到的样本，其在 $(\\kappa,\\rho)$ 上的平稳分布与原始后验分布 $\\pi(\\kappa,\\rho \\mid y)$ 一致。\n\nC. 在由 $u = \\log \\kappa$ 和 $v = \\log\\!\\big(\\rho/(1-\\rho)\\big)$ 定义的 log-logit 变换下，$u$ 和 $v$ 的全条件分布必然是高斯的，这保证了 $(u,v)$ 的 Gibbs 链的几何遍历性。\n\nD. 如果 $(\\kappa,\\rho)$ 的后验支撑集是 $\\Theta$ 内若干不相交的轴对齐矩形的并集，那么在约束空间上的坐标级 Gibbs 采样器可能是可约的，因为给定一个坐标，另一个坐标的条件支撑集可能被限制在同一个矩形内，从而阻止了在不连通分量之间的移动。\n\nE. 如果在变换空间 $(u,v)$ 中的 Gibbs 采样器是 Harris 遍历的，其不变密度（在归一化常数意义下）等于 $(u,v)$ 中经雅可比行列式调整的目标密度，那么通过逆映射 $(\\kappa,\\rho) = T^{-1}(u,v)$ 将该链前推，会得到一个在约束空间上以 $\\pi(\\kappa,\\rho \\mid y)$ 为不变分布的 Harris 遍历链。",
            "solution": "我们从第一性原理开始：贝叶斯后验 $\\pi(\\kappa,\\rho,x \\mid y)$ 可以分解为似然和先验的乘积。Gibbs 采样器通过从全条件分布中迭代采样来构造马尔可夫链。该链在包括 $\\psi$-不可约性和非周期性在内的条件下是遍历的，在约束状态空间的背景下，这些条件关键地取决于支撑集的几何形状和转移核的正性。约束可以改变支撑集的连通性和条件支撑集的性质，从而影响不可约性。为了在保持目标分布的同时实现无约束采样，可以应用一个到欧几里得空间的双射可微变换，并使用变量替换定理来获得经雅可比行列式适当调整的目标密度。\n\n约束对遍历性的影响。考虑 $(\\kappa,\\rho)$ 块的坐标级 Gibbs 采样，其中在每次迭代中，我们从限制在约束支撑集 $(0,\\infty)$ 和 $(0,1)$ 上的 $\\pi(\\kappa \\mid \\rho,x,y)$ 和 $\\pi(\\rho \\mid \\kappa,x,y)$ 中进行采样。即使每个全条件分布在其支撑集上都是正常的且严格为正，整个链的遍历性也不是自动保证的。关键在于链是否是 $\\psi$-不可约的：对于任何具有正平稳概率的可测集 $A$，链应该能够从任何起点出发，在一定步数内以正概率到达 $A$。如果 $(\\kappa,\\rho)$ 的联合后验支撑集是不连通的，并且其连通方式使得条件支撑集阻止了在分量之间的跨越，那么坐标级 Gibbs 采样就可能是可约的。一个典型的构造是后验分布支撑在两个不相交的轴对齐矩形的并集上，\n$$\nS = \\big((a_1,b_1)\\times(c_1,d_1)\\big) \\,\\cup\\, \\big((a_2,b_2)\\times(c_2,d_2)\\big),\n$$\n其中 $(a_1,b_1)\\times(c_1,d_1)$ 与 $(a_2,b_2)\\times(c_2,d_2)$ 不相交，并且在交叉积 $(a_1,b_1)\\times(c_2,d_2)$ 或 $(a_2,b_2)\\times(c_1,d_1)$ 上没有质量。从第一个矩形开始，一个以 $\\kappa \\in (a_1,b_1)$ 为条件的坐标级 Gibbs 步骤必然将 $\\rho$ 限制在 $(c_1,d_1)$ 内，然后以 $\\rho \\in (c_1,d_1)$ 为条件又将 $\\kappa$ 限制在 $(a_1,b_1)$ 内。因此，链无法进入第二个矩形，这显示了可约性。这说明了约束和支撑集的几何形状如何损害不可约性，进而损害遍历性。\n\n到无约束空间的变换和后验保持。定义一个变换 $T:\\Theta \\to \\mathbb{R}^2$ 为\n$$\nu = \\log \\kappa, \\quad v = \\operatorname{logit}(\\rho) = \\log\\!\\Big(\\frac{\\rho}{1-\\rho}\\Big).\n$$\n这个映射是双射的，其逆映射由下式给出\n$$\n\\kappa = e^{u}, \\quad \\rho = \\sigma(v) = \\frac{1}{1+e^{-v}}.\n$$\n逆映射 $T^{-1}(u,v)$ 的雅可比矩阵是对角的，其对角线上的元素为\n$$\n\\frac{\\partial \\kappa}{\\partial u} = e^{u} = \\kappa, \\quad \\frac{\\partial \\rho}{\\partial v} = \\sigma(v)\\big(1-\\sigma(v)\\big) = \\rho(1-\\rho),\n$$\n因此 $T^{-1}$ 的雅可比行列式的绝对值为\n$$\n\\left|\\det J_{T^{-1}}(u,v)\\right| = e^{u}\\,\\sigma(v)\\,\\big(1-\\sigma(v)\\big).\n$$\n根据变量替换定理，变换后坐标 $(x,u,v)$ 下的联合后验密度，在忽略归一化常数的情况下，为\n$$\n\\tilde{\\pi}(u,v,x \\mid y) \\;\\propto\\; \\pi\\!\\big(y \\mid x\\big)\\,\\pi\\!\\big(x \\mid \\kappa,\\rho\\big)\\,\\pi(\\kappa)\\,\\pi(\\rho)\\,\\left|\\det J_{T^{-1}}(u,v)\\right|,\n$$\n其中 $\\kappa = e^{u}$ 且 $\\rho = \\sigma(v)$。因此，\n$$\n\\tilde{\\pi}(u,v,x \\mid y) \\;\\propto\\; \\pi\\!\\big(y \\mid x\\big)\\,\\pi\\!\\big(x \\mid e^{u},\\sigma(v)\\big)\\,\\pi\\!\\big(e^{u}\\big)\\,\\pi\\!\\big(\\sigma(v)\\big)\\, e^{u}\\,\\sigma(v)\\,\\big(1-\\sigma(v)\\big).\n$$\n一个为目标 $\\tilde{\\pi}(u,v,x \\mid y)$ 而构造的、在无约束空间 $\\mathbb{R}^2 \\times \\mathcal{X}$ 中使用正确的经雅可比行列式调整的密度的 Gibbs 采样器，其不变分布为 $\\tilde{\\Pi}$，该分布在 $T^{-1}$ 下的前推（pushforward）恰好是 $(\\kappa,\\rho,x)$ 上的原始后验分布 $\\Pi$。特别地，对于任何可测集 $A \\subset \\Theta \\times \\mathcal{X}$，\n$$\n\\Pi(A) \\;=\\; \\tilde{\\Pi}\\!\\big((T \\times \\mathrm{id}_{\\mathcal{X}})(A)\\big).\n$$\n此外，遍历性（如 Harris 遍历性）在可测同构下是保持的：如果变换后的链是 Harris 遍历的，其不变测度为 $\\tilde{\\Pi}$，那么在 $T^{-1}$ 下的像链也是 Harris 遍历的，其不变测度为 $\\Pi$。\n\n忽略雅可比行列式的后果。如果使用从未经调整的后验 $\\pi(\\kappa,\\rho,x \\mid y)$（与 $(\\kappa,\\rho)=(e^{u},\\sigma(v))$ 复合）推导出的全条件分布来采样 $(u,v)$，但没有使用雅可比因子 $e^{u}\\,\\sigma(v)\\,(1-\\sigma(v))$，那么在 $(u,v)$ 中得到的不变密度将正比于\n$$\n\\pi\\!\\big(y \\mid x\\big)\\,\\pi\\!\\big(x \\mid e^{u},\\sigma(v)\\big)\\,\\pi\\!\\big(e^{u}\\big)\\,\\pi\\!\\big(\\sigma(v)\\big),\n$$\n其在 $T^{-1}$ 下的前推不是 $\\pi(\\kappa,\\rho,x \\mid y)$，而是一个除以雅可比行列式的重加权版本。例如，即使在 $(0,1)$ 上对 $\\rho$ 使用均匀先验，并且似然不依赖于 $\\rho$，忽略雅可比行列式也会在错误方向的变量替换后，在 $v$ 上诱导出一个正比于 $\\sigma(v)\\,(1-\\sigma(v))^{-1}$ 的非均匀密度，从而使 $\\rho$ 上隐含的后验产生偏差。因此，雅可比因子是必不可少的。\n\n逐项分析。\n\n选项 A：该选项声称，如果条件分布在约束支撑集上是正常的且为正，则遍历性得到保证。这是不正确的。如前所述，当联合支撑集以某种方式不连通，使得坐标级条件分布将链限制在单个分量内时，就会出现可约性。条件支撑集上的正常性和正性并不能保证链可以在不连通的分量之间穿梭。结论：不正确。\n\n选项 B：该选项指明了对数和 logit 变换，确认了 $T:\\Theta \\to \\mathbb{R}^2$ 是双射且连续可微的，计算了雅可比因子 $e^{u}\\,\\sigma(v)\\,(1-\\sigma(v))$，并断言在 $(u,v)$ 中以经雅可比行列式调整的密度为目标的 Gibbs 采样所产生的样本，在逆映射下的像在 $(\\kappa,\\rho)$ 上具有正确的后验分布。所有这些都源于变量替换定理和双射下前推测度的不变性。结论：正确。\n\n选项 C：该选项断言，在 log-logit 变换下，全条件分布必然是高斯的，并且这能保证几何遍历性。一般来说，变换后的条件分布不一定是高斯的；它们的形式取决于 $\\pi(x \\mid \\kappa,\\rho)$、$\\pi(\\kappa)$ 和 $\\pi(\\rho)$。即使在线性高斯模型中为 $x$ 出现高斯结构，由于 $(\\kappa,\\rho)$ 对 $(u,v)$ 的非线性依赖以及雅可比因子的存在，$(u,v)$ 的诱导条件分布通常也不是高斯的。此外，仅凭某些条件分布的高斯性并不能保证几何遍历性。结论：不正确。\n\n选项 D：该选项指出，如果后验支撑集是轴对齐矩形的不相交并集，坐标级 Gibbs 采样可能是可约的，因为条件分布会将链困在单个矩形内。如 $S = \\big((a_1,b_1)\\times(c_1,d_1)\\big) \\cup \\big((a_2,b_2)\\times(c_2,d_2)\\big)$ 且交叉项上无质量的例子所示，给定一个坐标位于一个矩形内，另一个坐标的条件支撑集也保持在同一个矩形内，从而阻止了跨分量的转移。这证明了可约性。结论：正确。\n\n选项 E：该选项断言，当以 $(u,v)$ 中经正确雅可比行列式调整的密度为目标时，Harris 遍历性和不变分布在逆映射下会进行适当的变换。在一个具有可测逆的可测双射映射 $T$ 下，一个 Harris 遍历马尔可夫链的像链仍然是 Harris 遍历的，并且不变测度通过 $T$ 前推（通过 $T^{-1}$ 拉回）。在我们的情境中，以正确的变换密度为目标，可确保在 $T^{-1}$ 下的前推能恢复 $\\pi(\\kappa,\\rho \\mid y)$。结论：正确。",
            "answer": "$$\\boxed{BDE}$$"
        }
    ]
}