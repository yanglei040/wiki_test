{
    "hands_on_practices": [
        {
            "introduction": "本练习通过一个理想化的情景——正交特征——来清晰地揭示数据结构如何直接影响后验不确定性。您将推导出在这种特殊情况下，后验协方差矩阵如何简化为一个对角矩阵，从而实现模型参数的“解耦”。理解这一基本机制是掌握更复杂模型中不确定性量化方法的关键第一步。",
            "id": "3103067",
            "problem": "考虑贝叶斯线性回归 (BLR)，其中设计矩阵 $X \\in \\mathbb{R}^{N \\times D}$ 通过一个线性模型将权重向量 $w \\in \\mathbb{R}^{D}$ 映射到预测目标。观测到的目标向量为 $t \\in \\mathbb{R}^{N}$。假设似然为高斯分布，其噪声精度为 $\\beta  0$，并且系数的先验为一个独立的零均值高斯分布，其精度为 $\\alpha  0$。\n\n构造一个具有标准正交列的特定数据集如下：令 $N=3$ 和 $D=2$，并取\n$$\nX \\;=\\;\n\\begin{pmatrix}\n1  0 \\\\\n0  1 \\\\\n0  0\n\\end{pmatrix},\n\\qquad\nt \\;=\\;\n\\begin{pmatrix}\n4 \\\\ -1 \\\\ 2\n\\end{pmatrix}.\n$$\n验证 $X$ 的列是标准正交的。然后，从高斯似然 $p(t \\mid w, X, \\beta)$ 和高斯先验 $p(w \\mid \\alpha)$ 的定义出发，应用贝叶斯定理 $p(w \\mid t, X, \\alpha, \\beta) \\propto p(t \\mid w, X, \\beta)\\,p(w \\mid \\alpha)$，推导 $w$ 的后验分布。在你的推导中，通过配方法来确定后验均值和后验协方差矩阵，并利用 $X$ 列的标准正交性来简化后验协方差。\n\n根据你的推导，解释 $X$ 列的正交性如何使 $w$ 中各个系数的后验分布解耦。\n\n最后，当 $\\alpha = 2$ 和 $\\beta = 3$ 时，计算该数据集的精确后验协方差矩阵。将后验协方差矩阵作为你的最终答案。不需要四舍五入。",
            "solution": "该问题是有效的，因为它是贝叶斯线性回归中的一个标准练习，在科学和数学上是合理的，并为得到唯一解提供了所有必要的信息。\n\n首先，我们验证矩阵 $X$ 的列是标准正交的。令这些列表示为 $x_1$ 和 $x_2$。\n$$\nx_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\qquad x_2 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\n标准正交性要求内积 $x_i^T x_j = \\delta_{ij}$，其中 $\\delta_{ij}$ 是克罗内克δ函数。我们检查内积：\n$$\nx_1^T x_1 = (1)(1) + (0)(0) + (0)(0) = 1\n$$\n$$\nx_2^T x_2 = (0)(0) + (1)(1) + (0)(0) = 1\n$$\n$$\nx_1^T x_2 = (1)(0) + (0)(1) + (0)(0) = 0\n$$\n因为 $x_1^T x_1 = 1$，$x_2^T x_2 = 1$ 且 $x_1^T x_2 = 0$，所以这些列是标准正交的。一种更简洁的验证方法是计算 $X^T X$：\n$$\nX^T X = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} = I_2\n$$\n因为 $X^T X = I_D$（其中 $D=2$ 是列数），根据定义，$X$ 的列是标准正交的。\n\n接下来，我们推导权重 $w$ 的后验分布。该模型由一个高斯似然和一个高斯先验指定。\n似然为 $p(t \\mid w, X, \\beta) = \\mathcal{N}(t \\mid Xw, \\beta^{-1}I_N)$，其中 $I_N$ 是 $N \\times N$ 的单位矩阵。其概率密度函数为：\n$$\np(t \\mid w, X, \\beta) \\propto \\exp\\left( -\\frac{\\beta}{2} (t - Xw)^T (t - Xw) \\right)\n$$\n权重的先验为 $p(w \\mid \\alpha) = \\mathcal{N}(w \\mid 0, \\alpha^{-1}I_D)$，其中 $I_D$ 是 $D \\times D$ 的单位矩阵。其概率密度函数为：\n$$\np(w \\mid \\alpha) \\propto \\exp\\left( -\\frac{\\alpha}{2} w^T w \\right)\n$$\n根据贝叶斯定理，后验分布正比于似然与先验的乘积：\n$$\np(w \\mid t, X, \\alpha, \\beta) \\propto p(t \\mid w, X, \\beta) \\, p(w \\mid \\alpha)\n$$\n我们处理后验分布的对数，因为这将指数的乘积简化为其参数的和：\n$$\n\\ln p(w \\mid t, X, \\alpha, \\beta) = -\\frac{\\beta}{2} (t - Xw)^T (t - Xw) - \\frac{\\alpha}{2} w^T w + \\text{const}\n$$\n我们展开二次项：\n$$\n(t - Xw)^T (t - Xw) = t^T t - t^T Xw - w^T X^T t + w^T X^T Xw = t^T t - 2w^T X^T t + w^T X^T Xw\n$$\n将此代回对数后验表达式中：\n$$\n\\ln p(w \\mid t, \\dots) = -\\frac{\\beta}{2} (t^T t - 2w^T X^T t + w^T X^T Xw) - \\frac{\\alpha}{2} w^T w + \\text{const}\n$$\n我们对包含 $w$ 的项进行分组：\n$$\n\\ln p(w \\mid t, \\dots) = -\\frac{1}{2} w^T (\\beta X^T X + \\alpha I_D) w + \\beta w^T X^T t - \\frac{\\beta}{2} t^T t + \\text{const}\n$$\n去掉不依赖于 $w$ 的项：\n$$\n\\ln p(w \\mid t, \\dots) = -\\frac{1}{2} w^T (\\beta X^T X + \\alpha I_D) w + \\beta w^T X^T t + \\text{const'}\n$$\n这是关于 $w$ 的二次型，这意味着后验是一个高斯分布 $p(w \\mid t, \\dots) = \\mathcal{N}(w \\mid m_N, S_N)$。一个通用的多变量高斯分布 $\\mathcal{N}(w \\mid m_N, S_N)$ 的对数密度为：\n$$\n\\ln \\mathcal{N}(w \\mid m_N, S_N) = -\\frac{1}{2} (w - m_N)^T S_N^{-1} (w - m_N) + \\text{const} = -\\frac{1}{2} (w^T S_N^{-1} w - 2w^T S_N^{-1} m_N + m_N^T S_N^{-1} m_N) + \\text{const}\n$$\n$$\n\\ln \\mathcal{N}(w \\mid m_N, S_N) = -\\frac{1}{2} w^T S_N^{-1} w + w^T S_N^{-1} m_N + \\text{const''}\n$$\n通过比较我们的对数后验表达式与通用对数高斯密度中关于 $w$ 的二次项和线性项的系数，我们可以确定后验精度矩阵（逆协方差）$S_N^{-1}$ 和均值 $m_N$。\n比较二次项 ($w^T(\\cdot)w$)：\n$$\nS_N^{-1} = \\beta X^T X + \\alpha I_D\n$$\n因此，后验协方差矩阵为：\n$$\nS_N = (\\beta X^T X + \\alpha I_D)^{-1}\n$$\n比较线性项 ($w^T(\\cdot)$)：\n$$\nS_N^{-1} m_N = \\beta X^T t \\implies m_N = S_N (\\beta X^T t) = \\beta (\\beta X^T X + \\alpha I_D)^{-1} X^T t\n$$\n这些是贝叶斯线性回归中后验均值和协方差的一般表达式。\n\n现在，我们利用 $X$ 的列是标准正交的这一性质，即 $X^T X = I_D$。将此代入 $S_N$ 和 $m_N$ 的表达式中：\n对于后验协方差 $S_N$：\n$$\nS_N = (\\beta I_D + \\alpha I_D)^{-1} = ((\\beta + \\alpha) I_D)^{-1} = \\frac{1}{\\alpha + \\beta} I_D\n$$\n对于后验均值 $m_N$：\n$$\nm_N = \\beta \\left(\\frac{1}{\\alpha + \\beta} I_D\\right) X^T t = \\frac{\\beta}{\\alpha + \\beta} X^T t\n$$\n$X$ 列的标准正交性显著简化了后验参数。后验协方差矩阵 $S_N = \\frac{1}{\\alpha + \\beta} I_D$ 是一个对角矩阵。在多变量高斯分布中，对角协方差矩阵表示随机变量是不相关的。对于高斯变量，不相关等价于统计独立。\n联合后验密度为：\n$$\np(w \\mid t, \\dots) \\propto \\exp\\left(-\\frac{1}{2} (w-m_N)^T S_N^{-1} (w-m_N)\\right) = \\exp\\left(-\\frac{\\alpha+\\beta}{2} (w-m_N)^T (w-m_N)\\right)\n$$\n$$\n= \\exp\\left(-\\frac{\\alpha+\\beta}{2} \\sum_{j=1}^D (w_j - m_{N,j})^2\\right) = \\prod_{j=1}^D \\exp\\left(-\\frac{\\alpha+\\beta}{2} (w_j - m_{N,j})^2\\right)\n$$\n这表明联合后验 $p(w \\mid t, \\dots)$ 可以分解为每个系数 $w_j$ 的独立后验的乘积：$p(w_1, \\dots, w_D \\mid t, \\dots) = \\prod_{j=1}^D p(w_j \\mid t, \\dots)$。这种分解就是系数后验分布的“解耦”。每个 $w_j$ 都有一个单变量高斯后验分布，其均值为 $m_{N,j}$，方差为 $1/(\\alpha+\\beta)$。特征的标准正交性确保了学习一个权重 $w_j$ 不会提供关于任何其他权重 $w_k$ ($k \\neq j$) 的任何信息，超出了从先验中已知的信息。\n\n最后，我们针对给定的数据集，当 $\\alpha = 2$ 和 $\\beta = 3$ 时，计算精确的后验协方差矩阵。我们使用从 $X$ 列的标准正交性推导出的简化公式。权重向量的维度是 $D=2$。\n$$\nS_N = \\frac{1}{\\alpha + \\beta} I_D = \\frac{1}{2 + 3} I_2 = \\frac{1}{5} I_2\n$$\n将其写成矩阵形式：\n$$\nS_N = \\frac{1}{5} \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{5}  0 \\\\ 0  \\frac{1}{5} \\end{pmatrix}\n$$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{5}  0 \\\\ 0  \\frac{1}{5} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "现实世界的模型常常包含我们不感兴趣但必须考虑的“滋扰参数”（nuisance parameters），例如传感器偏差。本练习将探讨当我们必须同时估计这些滋扰参数时，我们感兴趣的关键参数的不确定性会发生什么变化。通过这个思想实验，您会发现一个违反直觉但至关重要的现象：由于参数间的耦合，同化新数据有时反而会增加某些参数的后验不确定性。",
            "id": "3411826",
            "problem": "考虑一个线性逆问题，其未知参数为一个二维向量 $x = (x_{1}, x_{2})^{\\top}$。根据模型 $y = h_{1} x_{1} + h_{2} x_{2} + b + \\epsilon$ 收集一个标量观测值 $y \\in \\mathbb{R}$，其中 $h_{1}, h_{2} \\in \\mathbb{R}$ 是已知的传感器灵敏度，$b \\in \\mathbb{R}$ 是一个未知的加性偏差，而 $\\epsilon \\in \\mathbb{R}$ 是观测噪声。假设高斯先验 $x \\sim \\mathcal{N}(0, C_{x})$，其中 $C_{x} = \\operatorname{diag}(\\sigma_{1}^{2}, \\sigma_{2}^{2})$，$b \\sim \\mathcal{N}(0, \\sigma_{b}^{2})$，以及高斯噪声 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2})$，且与 $(x,b)$ 独立。\n\n考虑两种数据同化设置：\n- 设置 A（偏差固定）：观测模型为 $y = h_{1} x_{1} + h_{2} x_{2} + \\epsilon$，其中 $b \\equiv 0$ 已知。\n- 设置 B（偏差未知）：观测模型为 $y = h_{1} x_{1} + h_{2} x_{2} + b + \\epsilon$，其中 $b$ 被视为一个具有其先验分布的未知参数。\n\n从线性高斯模型的贝叶斯推断基本原理出发，推导每种设置下 $x$ 的后验协方差。然后，关注第一个分量，以闭式形式计算因引入未知偏差 $b$ 而引起的 $x_{1}$ 后验方差的增量，定义为\n$$\\Delta \\operatorname{Var}(x_{1}) = \\operatorname{Var}(x_{1} \\mid y, \\text{ 设置 B}) - \\operatorname{Var}(x_{1} \\mid y, \\text{ 设置 A}).$$\n提供 $\\Delta \\operatorname{Var}(x_{1})$ 关于 $\\sigma_{1}^{2}$、$\\sigma_{2}^{2}$、$\\sigma_{\\epsilon}^{2}$、$\\sigma_{b}^{2}$、$h_{1}$ 和 $h_{2}$ 的最终表达式。\n\n基于您推导的代数，用语言解释参数-偏差耦合导致 $x$ 某些分量的后验方差增加的机制。\n\n您的最终答案必须是单一的闭式解析表达式。不需要进行数值舍入。",
            "solution": "该问题要求在线性高斯逆问题的两种不同建模假设下，推导和比较参数 $x_{1}$ 的后验方差。解决方案的核心在于对此类模型应用标准贝叶斯公式来计算后验分布。对于状态向量 $\\mathbf{z}$，其高斯先验为 $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{z}_{p}, C_{p})$，线性观测模型为 $\\mathbf{y} = M \\mathbf{z} + \\mathbf{e}$，高斯噪声为 $\\mathbf{e} \\sim \\mathcal{N}(0, R)$，则给定 $\\mathbf{y}$ 的 $\\mathbf{z}$ 的后验分布也是高斯分布，$\\mathbf{z} \\mid \\mathbf{y} \\sim \\mathcal{N}(\\mathbf{z}_{\\text{post}}, C_{\\text{post}})$，其后验协方差 $C_{\\text{post}}$ 由后验精度矩阵的逆给出：\n$$C_{\\text{post}}^{-1} = C_{p}^{-1} + M^{\\top} R^{-1} M$$\n\n我们将此框架应用于设置 A 和设置 B。\n\n**设置 A：偏差固定 ($b=0$)**\n\n在此设置中，未知状态向量为 $x = (x_{1}, x_{2})^{\\top}$。\n先验分布为 $x \\sim \\mathcal{N}(0, C_{x})$，因此先验均值为 $x_{p} = 0$，先验协方差为 $C_{p} = C_{x} = \\begin{pmatrix} \\sigma_{1}^{2}  0 \\\\ 0  \\sigma_{2}^{2} \\end{pmatrix}$。\n观测模型为 $y = h_{1} x_{1} + h_{2} x_{2} + \\epsilon$，可以写成 $y = Hx + \\epsilon$，其中观测算子是行矩阵 $H = \\begin{pmatrix} h_{1}  h_{2} \\end{pmatrix}$。\n观测噪声为 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2})$，因此观测误差协方差是标量 $R = \\sigma_{\\epsilon}^{2}$。\n\n$x$ 的后验协方差记为 $C_{A}$，首先通过计算后验精度矩阵 $C_{A}^{-1}$ 来求得：\n$$C_{A}^{-1} = C_{x}^{-1} + H^{\\top} R^{-1} H$$\n各组成部分为：\n$$C_{x}^{-1} = \\begin{pmatrix} 1/\\sigma_{1}^{2}  0 \\\\ 0  1/\\sigma_{2}^{2} \\end{pmatrix}$$\n$$H^{\\top} R^{-1} H = \\begin{pmatrix} h_{1} \\\\ h_{2} \\end{pmatrix} (\\sigma_{\\epsilon}^{-2}) \\begin{pmatrix} h_{1}  h_{2} \\end{pmatrix} = \\frac{1}{\\sigma_{\\epsilon}^{2}} \\begin{pmatrix} h_{1}^{2}  h_{1}h_{2} \\\\ h_{1}h_{2}  h_{2}^{2} \\end{pmatrix}$$\n将这些相加得到后验精度矩阵：\n$$C_{A}^{-1} = \\begin{pmatrix} \\frac{1}{\\sigma_{1}^{2}} + \\frac{h_{1}^{2}}{\\sigma_{\\epsilon}^{2}}  \\frac{h_{1}h_{2}}{\\sigma_{\\epsilon}^{2}} \\\\ \\frac{h_{1}h_{2}}{\\sigma_{\\epsilon}^{2}}  \\frac{1}{\\sigma_{2}^{2}} + \\frac{h_{2}^{2}}{\\sigma_{\\epsilon}^{2}} \\end{pmatrix}$$\n为了找到后验协方差 $C_{A}$，我们对这个 $2 \\times 2$ 矩阵求逆。给定 $y$ 时 $x_{1}$ 的方差，即 $\\operatorname{Var}(x_{1} \\mid y, \\text{设置 A})$，是 $C_{A}$ 的 $(1,1)$ 元素。\n$C_{A}^{-1}$ 的行列式为：\n$$\\det(C_{A}^{-1}) = \\left(\\frac{1}{\\sigma_{1}^{2}} + \\frac{h_{1}^{2}}{\\sigma_{\\epsilon}^{2}}\\right) \\left(\\frac{1}{\\sigma_{2}^{2}} + \\frac{h_{2}^{2}}{\\sigma_{\\epsilon}^{2}}\\right) - \\left(\\frac{h_{1}h_{2}}{\\sigma_{\\epsilon}^{2}}\\right)^2 = \\frac{\\sigma_{\\epsilon}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2}}{\\sigma_{1}^{2}\\sigma_{2}^{2}\\sigma_{\\epsilon}^{2}}$$\n$C_{A}$ 的 $(1,1)$ 元素是 $C_{A}^{-1}$ 的 $(2,2)$ 元素除以行列式：\n$$\\operatorname{Var}(x_{1} \\mid y, \\text{Setting A}) = (C_{A})_{11} = \\frac{\\frac{1}{\\sigma_{2}^{2}} + \\frac{h_{2}^{2}}{\\sigma_{\\epsilon}^{2}}}{\\det(C_{A}^{-1})} = \\frac{\\frac{\\sigma_{\\epsilon}^{2} + h_{2}^{2}\\sigma_{2}^{2}}{\\sigma_{2}^{2}\\sigma_{\\epsilon}^{2}}}{\\frac{\\sigma_{\\epsilon}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2}}{\\sigma_{1}^{2}\\sigma_{2}^{2}\\sigma_{\\epsilon}^{2}}}$$\n$$\\operatorname{Var}(x_{1} \\mid y, \\text{Setting A}) = \\frac{\\sigma_{1}^{2} (\\sigma_{\\epsilon}^{2} + h_{2}^{2}\\sigma_{2}^{2})}{\\sigma_{\\epsilon}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2}}$$\n\n**设置 B：偏差未知**\n\n在此设置中，未知偏差 $b$ 被视为一个随机变量。我们构建一个增广状态向量 $z = (x_{1}, x_{2}, b)^{\\top}$。\n$z$ 的先验是 $z \\sim \\mathcal{N}(0, C_{z})$，其中 $C_{z}$ 是由 $x$ 和 $b$ 的独立先验构成的块对角协方差矩阵：\n$$C_{z} = \\begin{pmatrix} C_{x}  0 \\\\ 0  \\sigma_{b}^{2} \\end{pmatrix} = \\begin{pmatrix} \\sigma_{1}^{2}  0  0 \\\\ 0  \\sigma_{2}^{2}  0 \\\\ 0  0  \\sigma_{b}^{2} \\end{pmatrix}$$\n观测模型是 $y = h_{1}x_{1} + h_{2}x_{2} + b + \\epsilon$，用增广状态表示为 $y = Kz + \\epsilon$，其中 $K = \\begin{pmatrix} h_{1}  h_{2}  1 \\end{pmatrix}$。噪声属性保持不变，$R = \\sigma_{\\epsilon}^{2}$。\n\n增广状态的后验协方差 $C_{B}$ 由其逆矩阵 $C_{B}^{-1}$ 求得：\n$$C_{B}^{-1} = C_{z}^{-1} + K^{\\top} R^{-1} K$$\n各组成部分为：\n$$C_{z}^{-1} = \\begin{pmatrix} 1/\\sigma_{1}^{2}  0  0 \\\\ 0  1/\\sigma_{2}^{2}  0 \\\\ 0  0  1/\\sigma_{b}^{2} \\end{pmatrix}$$\n$$K^{\\top} R^{-1} K = \\frac{1}{\\sigma_{\\epsilon}^{2}} \\begin{pmatrix} h_{1} \\\\ h_{2} \\\\ 1 \\end{pmatrix} \\begin{pmatrix} h_{1}  h_{2}  1 \\end{pmatrix} = \\frac{1}{\\sigma_{\\epsilon}^{2}} \\begin{pmatrix} h_{1}^{2}  h_{1}h_{2}  h_{1} \\\\ h_{1}h_{2}  h_{2}^{2}  h_{2} \\\\ h_{1}  h_{2}  1 \\end{pmatrix}$$\n将这些相加得到增广状态的后验精度矩阵：\n$$C_{B}^{-1} = \\begin{pmatrix} \\frac{1}{\\sigma_{1}^{2}} + \\frac{h_{1}^{2}}{\\sigma_{\\epsilon}^{2}}  \\frac{h_{1}h_{2}}{\\sigma_{\\epsilon}^{2}}  \\frac{h_{1}}{\\sigma_{\\epsilon}^{2}} \\\\ \\frac{h_{1}h_{2}}{\\sigma_{\\epsilon}^{2}}  \\frac{1}{\\sigma_{2}^{2}} + \\frac{h_{2}^{2}}{\\sigma_{\\epsilon}^{2}}  \\frac{h_{2}}{\\sigma_{\\epsilon}^{2}} \\\\ \\frac{h_{1}}{\\sigma_{\\epsilon}^{2}}  \\frac{h_{2}}{\\sigma_{\\epsilon}^{2}}  \\frac{1}{\\sigma_{b}^{2}} + \\frac{1}{\\sigma_{\\epsilon}^{2}} \\end{pmatrix}$$\n在此设置中 $x_{1}$ 的后验方差，即 $\\operatorname{Var}(x_{1} \\mid y, \\text{Setting B})$，是矩阵 $C_{B}$ 的 $(1,1)$ 元素。它通过计算 $C_{B}^{-1}$ 的 $(1,1)$ 代数余子式除以其行列式得到。\n行列式可以使用矩阵行列式引理 $\\det(A + \\mathbf{u}\\mathbf{v}^{\\top}) = (1+\\mathbf{v}^{\\top}A^{-1}\\mathbf{u})\\det(A)$ 求得。这里，$A=C_z^{-1}$，$\\mathbf{u}\\mathbf{v}^{\\top} = K^{\\top}R^{-1}K$。这给出：\n$$\\det(C_{B}^{-1}) = \\det(C_{z}^{-1}) \\left(1 + \\frac{K C_{z} K^{\\top}}{\\sigma_{\\epsilon}^{2}}\\right) = \\frac{1}{\\sigma_{1}^{2}\\sigma_{2}^{2}\\sigma_{b}^{2}} \\left(1 + \\frac{h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2} + \\sigma_{b}^{2}}{\\sigma_{\\epsilon}^{2}}\\right) = \\frac{\\sigma_{\\epsilon}^{2} + \\sigma_{b}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2}}{\\sigma_{1}^{2}\\sigma_{2}^{2}\\sigma_{b}^{2}\\sigma_{\\epsilon}^{2}}$$\n$C_{B}^{-1}$ 的 $(1,1)$ 代数余子式为：\n$$ (C_{B}^{-1})_{11}^{\\text{cofactor}} = \\det \\begin{pmatrix} \\frac{1}{\\sigma_{2}^{2}} + \\frac{h_{2}^{2}}{\\sigma_{\\epsilon}^{2}}  \\frac{h_{2}}{\\sigma_{\\epsilon}^{2}} \\\\ \\frac{h_{2}}{\\sigma_{\\epsilon}^{2}}  \\frac{1}{\\sigma_{b}^{2}} + \\frac{1}{\\sigma_{\\epsilon}^{2}} \\end{pmatrix} = \\frac{\\sigma_{\\epsilon}^{2} + \\sigma_{b}^{2} + h_{2}^{2}\\sigma_{2}^{2}}{\\sigma_{2}^{2}\\sigma_{b}^{2}\\sigma_{\\epsilon}^{2}}$$\n$x_{1}$ 的后验方差是以下比率：\n$$\\operatorname{Var}(x_{1} \\mid y, \\text{Setting B}) = (C_{B})_{11} = \\frac{(C_{B}^{-1})_{11}^{\\text{cofactor}}}{\\det(C_{B}^{-1})} = \\frac{\\sigma_{1}^{2}(\\sigma_{\\epsilon}^{2} + \\sigma_{b}^{2} + h_{2}^{2}\\sigma_{2}^{2})}{\\sigma_{\\epsilon}^{2} + \\sigma_{b}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2}}$$\n\n**后验方差的增量**\n\n我们现在计算 $\\Delta \\operatorname{Var}(x_{1}) = \\operatorname{Var}(x_{1} \\mid y, \\text{Setting B}) - \\operatorname{Var}(x_{1} \\mid y, \\text{Setting A})$。\n令 $V_{A} = \\operatorname{Var}(x_{1} \\mid y, \\text{A})$ 和 $V_{B} = \\operatorname{Var}(x_{1} \\mid y, \\text{B})$。\n令 $D_{A} = \\sigma_{\\epsilon}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2}$ 和 $D_{B} = \\sigma_{\\epsilon}^{2} + \\sigma_{b}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2} = D_{A} + \\sigma_{b}^{2}$。\n再令 $N_{A} = \\sigma_{1}^{2} (\\sigma_{\\epsilon}^{2} + h_{2}^{2}\\sigma_{2}^{2})$ 和 $N_{B} = \\sigma_{1}^{2}(\\sigma_{\\epsilon}^{2} + \\sigma_{b}^{2} + h_{2}^{2}\\sigma_{2}^{2}) = N_{A} + \\sigma_{1}^{2}\\sigma_{b}^{2}$。\n所以我们有 $V_{A} = N_{A}/D_{A}$ 和 $V_{B} = N_{B}/D_{B}$。\n\n$$\\Delta \\operatorname{Var}(x_{1}) = \\frac{N_{A} + \\sigma_{1}^{2}\\sigma_{b}^{2}}{D_{A} + \\sigma_{b}^{2}} - \\frac{N_{A}}{D_{A}} = \\frac{D_{A}(N_{A} + \\sigma_{1}^{2}\\sigma_{b}^{2}) - N_{A}(D_{A} + \\sigma_{b}^{2})}{D_{A}(D_{A} + \\sigma_{b}^{2})}$$\n$$\\Delta \\operatorname{Var}(x_{1}) = \\frac{D_{A}N_{A} + D_{A}\\sigma_{1}^{2}\\sigma_{b}^{2} - N_{A}D_{A} - N_{A}\\sigma_{b}^{2}}{D_{A}D_{B}} = \\frac{\\sigma_{b}^{2} (D_{A}\\sigma_{1}^{2} - N_{A})}{D_{A}D_{B}}$$\n分子中的项是：\n$$D_{A}\\sigma_{1}^{2} - N_{A} = (\\sigma_{\\epsilon}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2})\\sigma_{1}^{2} - \\sigma_{1}^{2} (\\sigma_{\\epsilon}^{2} + h_{2}^{2}\\sigma_{2}^{2}) = h_{1}^{2}\\sigma_{1}^{4}$$\n将其代回，我们得到方差增量的最终表达式：\n$$\\Delta \\operatorname{Var}(x_{1}) = \\frac{h_{1}^{2}\\sigma_{1}^{4}\\sigma_{b}^{2}}{(\\sigma_{\\epsilon}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2})(\\sigma_{\\epsilon}^{2} + \\sigma_{b}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2})}$$\n\n**方差增加的解释**\n\n当偏差 $b$ 未知时，$x_{1}$ 的后验方差增加是参数耦合和数据信息分配的一种表现。\n\n在设置 A 中，观测值 $y$ 提供信息来约束两个参数 $x_{1}$ 和 $x_{2}$。在设置 B 中，同一个单一观测值必须用于约束三个参数：$x_{1}$、$x_{2}$ 和 $b$。测量所提供的信息现在被“摊薄”到更多未知量上。\n\n其代数机制是观测模型引入的参数之间的耦合。在设置 B 中，后验精度矩阵 $C_{B}^{-1}$ 包含非零的非对角项，例如 $(C_{B}^{-1})_{13} = h_{1}/\\sigma_{\\epsilon}^{2}$，它将 $x_{1}$ 和 $b$ 联系起来。在设置 A 中该项为零（因为 $b$ 不是状态的一部分）。当这个精度矩阵被求逆以得到协方差矩阵 $C_{B}$ 时，这种耦合确保了一个参数的不确定性会传播到其他参数。具体来说，由 $\\sigma_{b}^{2}$ 量化的偏差的先验不确定性会“泄漏”到 $x_{1}$ 的后验不确定性中。观测值 $y = h_{1}x_{1} + h_{2}x_{2} + b + \\epsilon$ 无法完美区分由 $x_{1}$ 引起的变化和由 $b$ 引起的变化。这种模糊性导致 $x_1$ 的后验方差比 $b$ 已知时更大。\n\n推导出的 $\\Delta \\operatorname{Var}(x_{1})$ 表达式清晰地说明了这一点：\n- 增量与偏差的先验方差 $\\sigma_{b}^{2}$ 成正比。如果偏差没有先验不确定性，则没有方差增加。\n- 增量与 $h_{1}^{2}$ 成正比。如果 $x_1$ 不影响观测（$h_1=0$），它就不会通过测量与偏差耦合，其方差也不受 $b$ 中不确定性的影响。\n- 增量也与 $\\sigma_{1}^{4}$ 成正比，表明具有较高先验不确定性的参数更容易受到这种效应的影响。\n\n本质上，估计像偏差 $b$ 这样的滋扰参数，其代价是降低了对主要感兴趣参数估计的精度。",
            "answer": "$$\\boxed{\\frac{h_{1}^{2} \\sigma_{1}^{4} \\sigma_{b}^{2}}{(\\sigma_{\\epsilon}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2}) (\\sigma_{\\epsilon}^{2} + \\sigma_{b}^{2} + h_{1}^{2}\\sigma_{1}^{2} + h_{2}^{2}\\sigma_{2}^{2})}}$$"
        },
        {
            "introduction": "在许多实际应用中（如天气预报），数据是随时间序列性到达的。本练习旨在连接一次性处理所有数据的“批量”更新与更符合实际的“序列”更新方法。您不仅会证明这两种方法在理论上是等价的，更重要的是，将直面在有限精度计算中出现的数值稳定性问题，这是构建稳健数据同化系统的从业者必须掌握的关键一课。",
            "id": "3411817",
            "problem": "考虑一个线性高斯逆问题，其先验和观测模型定义如下。未知状态 $x \\in \\mathbb{R}^{n}$ 服从高斯先验分布 $x \\sim \\mathcal{N}(m_{\\text{prior}}, C_{\\text{prior}})$，其中 $C_{\\text{prior}} \\in \\mathbb{R}^{n \\times n}$ 是对称正定（SPD）协方差矩阵。观测值由线性模型 $y = H x + \\eta$ 生成，其中 $H \\in \\mathbb{R}^{m \\times n}$ 是观测算子，$\\eta \\sim \\mathcal{N}(0, R)$ 是零均值高斯噪声，其协方差矩阵 $R \\in \\mathbb{R}^{m \\times m}$ 是对称正定的。假设 $m \\geq 1$，并且随着新传感器的到来，观测行会在线添加。您将仅使用基本的高斯恒等式和分块矩阵求逆工具来比较批量更新和增量更新的后验协方差。\n\n从通过贝叶斯法则定义的后验密度以及高斯似然和先验的二次型出发，完成以下任务：\n\n1) 推导当两个标量传感器同时到达时，批量后验协方差 $C_{\\text{post}}^{\\text{batch}}$ 的表达式，其中\n- 第一个传感器：$y_1 \\in \\mathbb{R}$，观测向量 $h_1 \\in \\mathbb{R}^{n}$，噪声方差 $r_1 \\in \\mathbb{R}_{0}$，\n- 第二个传感器：$y_2 \\in \\mathbb{R}$，观测向量 $h_2 \\in \\mathbb{R}^{n}$，噪声方差 $r_2 \\in \\mathbb{R}_{0}$，\n使得 $H = \\begin{pmatrix} h_{1}^{\\top} \\\\ h_{2}^{\\top} \\end{pmatrix}$ 且 $R = \\operatorname{diag}(r_1, r_2)$。\n\n2) 现在假设传感器是在线到达的。处理第一个传感器以获得一个具有协方差 $C_1$ 的中间后验。然后，在给定 $y_1$ 的条件下，对 $(x, y_2)$ 的联合高斯分布使用分块矩阵求逆（舒尔补）论证来处理第二个传感器，并推导一个关于 $C_1$、$h_2$ 和 $r_2$ 的协方差 $C_2$ 的显式秩-1 更新公式。用代数方法证明 $C_2 = C_{\\text{post}}^{\\text{batch}}$。\n\n3) 针对第二个传感器，提供一个类似的秩-1后验均值更新公式，用 $C_1$、$h_2$、$r_2$ 和新息 $y_2 - h_2^{\\top} m_1$ 来表示，其中 $m_1$ 是同化第一个传感器后的后验均值。\n\n4) 使用以下具体、数值化的设置：\n- $n = 2$，\n- $C_{\\text{prior}} = \\begin{pmatrix} 2  3/5 \\\\ 3/5  1 \\end{pmatrix}$，\n- $h_1 = \\begin{pmatrix} 1 \\\\ 1/2 \\end{pmatrix}$，$r_1 = 1/2$，\n- $h_2 = \\begin{pmatrix} -1/3 \\\\ 1 \\end{pmatrix}$，$r_2 = 2/5$，\n计算 $C_{\\text{post}}^{\\text{batch}}$ 和通过先处理 $y_1$ 再处理 $y_2$ 并使用您推导的秩-1协方差更新得到的 $C_2$。报告两者差值的弗罗贝尼乌斯范数，\n$$\n\\left\\| C_{\\text{post}}^{\\text{batch}} - C_{2} \\right\\|_{F},\n$$\n作为您的最终答案。请提供精确值，无需四舍五入。\n\n5) 简要识别并论证在有限精度算术中应用增量秩-1协方差更新时出现的至少两个数值稳定性问题，并讨论平方根实现或Joseph稳定形式如何解决这些问题。\n\n您的最终答案必须是第4项中要求的弗罗贝尼乌斯范数的单个实数值。",
            "solution": "这是一个关于线性高斯模型的贝叶斯推断的标准练习，旨在探讨批量数据同化和序贯数据同化之间的等价性。我们将按顺序解决问题的每个部分。\n\n### 问题验证\n\n首先根据要求验证问题。\n\n**步骤1：提取已知条件**\n- **先验分布**：$x \\sim \\mathcal{N}(m_{\\text{prior}}, C_{\\text{prior}})$，其中 $x \\in \\mathbb{R}^{n}$，$C_{\\text{prior}} \\in \\mathbb{R}^{n \\times n}$ 是一个对称正定（SPD）协方差矩阵。\n- **观测模型**：$y = H x + \\eta$，其中 $H \\in \\mathbb{R}^{m \\times n}$ 是观测算子。\n- **观测噪声**：$\\eta \\sim \\mathcal{N}(0, R)$，其中 $R \\in \\mathbb{R}^{m \\times m}$ 是一个SPD协方差矩阵。\n- **批量设置（第1部分）**：两个标量传感器。\n  - 传感器1：$y_1 \\in \\mathbb{R}$，$h_1 \\in \\mathbb{R}^n$，噪声方差 $r_1  0$。\n  - 传感器2：$y_2 \\in \\mathbb{R}$，$h_2 \\in \\mathbb{R}^n$，噪声方差 $r_2  0$。\n  - 组合算子和噪声协方差：$H = \\begin{pmatrix} h_{1}^{\\top} \\\\ h_{2}^{\\top} \\end{pmatrix}$，$R = \\operatorname{diag}(r_{1}, r_{2})$。\n- **序贯设置（第2部分）**：传感器在线到达。首先处理 $y_1$ 以得到一个协方差为 $C_1$ 的中间后验。然后处理 $y_2$。\n- **数值（第4部分）**：\n  - $n = 2$\n  - $C_{\\text{prior}} = \\begin{pmatrix} 2  3/5 \\\\ 3/5  1 \\end{pmatrix}$\n  - $h_{1} = \\begin{pmatrix} 1 \\\\ 1/2 \\end{pmatrix}$，$r_{1} = 1/2$\n  - $h_{2} = \\begin{pmatrix} -1/3 \\\\ 1 \\end{pmatrix}$，$r_{2} = 2/5$\n\n**步骤2：使用提取的已知条件进行验证**\n问题是良定义的且科学上合理的。\n- **科学基础**：它涉及贝叶斯推断的基本概念，特别是针对线性高斯系统，这是卡尔曼滤波和数据同化的基础。一个核心结论是批量更新和序贯更新的等价性。\n- **适定性**：问题是完全指定的。目标是推导标准公式，证明它们的等价性，并执行一个具体的数值计算。所有必需的矩阵和参数都已提供。先验协方差 $C_{\\text{prior}}$ 是对称的，其主子式为 $2  0$ 和 $\\det(C_{\\text{prior}}) = 2(1) - (3/5)^2 = 2 - 9/25 = 41/25  0$，确认其为SPD。噪声方差 $r_1, r_2$ 为正，因此 $R$ 是SPD。\n- **目标**：问题使用精确的数学语言陈述，没有歧义或主观性。\n\n**步骤3：结论和行动**\n问题是有效的。我们将进行详细的解答。\n\n### 第1部分：批量后验协方差\n\n后验概率密度函数 $p(x|y)$ 由贝叶斯法则给出：$p(x|y) \\propto p(y|x)p(x)$。对于高斯分布，这等同于对概率密度的指数求和。负对数后验 $J(x)$ 是 $x$ 的二次函数：\n$$J(x) = \\frac{1}{2}(x - m_{\\text{prior}})^{\\top} C_{\\text{prior}}^{-1} (x - m_{\\text{prior}}) + \\frac{1}{2}(y - Hx)^{\\top} R^{-1} (y - Hx) + \\text{const.}$$\n后验分布也是高斯分布，$x|y \\sim \\mathcal{N}(m_{\\text{post}}, C_{\\text{post}})$。后验协方差的逆矩阵 $C_{\\text{post}}^{-1}$ 是 $J(x)$ 的Hessian矩阵，对应于 $x$ 的二次项。展开 $J(x)$ 得到：\n$$J(x) = \\frac{1}{2} x^{\\top} (C_{\\text{prior}}^{-1} + H^{\\top}R^{-1}H) x - x^{\\top} (C_{\\text{prior}}^{-1}m_{\\text{prior}} + H^{\\top}R^{-1}y) + \\text{const.}$$\n通过将各项与一般高斯形式 $\\frac{1}{2}(x - m_{\\text{post}})^{\\top} C_{\\text{post}}^{-1} (x - m_{\\text{post}})$ 对比，我们得到逆后验协方差：\n$$(C_{\\text{post}})^{-1} = C_{\\text{prior}}^{-1} + H^{\\top}R^{-1}H$$\n对于指定的具有两个标量传感器的批量更新，我们有 $H = \\begin{pmatrix} h_{1}^{\\top} \\\\ h_{2}^{\\top} \\end{pmatrix}$ 和 $R = \\begin{pmatrix} r_{1}  0 \\\\ 0  r_{2} \\end{pmatrix}$。其逆矩阵为 $R^{-1} = \\begin{pmatrix} r_{1}^{-1}  0 \\\\ 0  r_{2}^{-1} \\end{pmatrix}$。项 $H^{\\top}R^{-1}H$ 变为：\n$$H^{\\top}R^{-1}H = \\begin{pmatrix} h_{1}  h_{2} \\end{pmatrix} \\begin{pmatrix} r_{1}^{-1}  0 \\\\ 0  r_{2}^{-1} \\end{pmatrix} \\begin{pmatrix} h_{1}^{\\top} \\\\ h_{2}^{\\top} \\end{pmatrix} = r_{1}^{-1}h_{1}h_{1}^{\\top} + r_{2}^{-1}h_{2}h_{2}^{\\top}$$\n因此，批量逆后验协方差为：\n$$(C_{\\text{post}}^{\\text{batch}})^{-1} = C_{\\text{prior}}^{-1} + r_{1}^{-1}h_{1}h_{1}^{\\top} + r_{2}^{-1}h_{2}h_{2}^{\\top}$$\n批量后验协方差是该表达式的逆：\n$$C_{\\text{post}}^{\\text{batch}} = (C_{\\text{prior}}^{-1} + r_{1}^{-1}h_{1}h_{1}^{\\top} + r_{2}^{-1}h_{2}h_{2}^{\\top})^{-1}$$\n\n### 第2部分：序贯协方差更新与等价性\n\n首先，同化传感器1得到一个协方差为 $C_1$ 的后验。这是批量公式的一个特例，其中 $H=h_1^\\top$ 和 $R=r_1$。\n$$C_{1}^{-1} = C_{\\text{prior}}^{-1} + r_1^{-1} h_1 h_1^\\top$$\n接下来，我们同化传感器2，使用步骤1的后验作为新的先验：$x \\sim \\mathcal{N}(m_1, C_1)$。观测模型为 $y_2 = h_2^\\top x + \\eta_2$，其中 $\\eta_2 \\sim \\mathcal{N}(0, r_2)$。在给定 $y_1$ 的条件下，$(x, y_2)$ 的联合分布是高斯分布。这个联合分布的协方差是：\n$$\\text{Cov}\\left( \\begin{pmatrix} x \\\\ y_2 \\end{pmatrix} | y_1 \\right) = \\begin{pmatrix} C_1  C_1 h_2 \\\\ h_2^\\top C_1  h_2^\\top C_1 h_2 + r_2 \\end{pmatrix}$$\n使用条件高斯分布的公式，给定 $y_2$（以及 $y_1$）的 $x$ 的后验协方差由分块协方差矩阵的舒尔补给出：\n$$C_2 = C_1 - (C_1 h_2) (h_2^\\top C_1 h_2 + r_2)^{-1} (h_2^\\top C_1)$$\n由于 $h_2^\\top C_1 h_2 + r_2$ 是一个标量，这简化为秩-1更新：\n$$C_2 = C_1 - \\frac{C_1 h_2 h_2^\\top C_1}{r_2 + h_2^\\top C_1 h_2}$$\n为了证明 $C_2 = C_{\\text{post}}^{\\text{batch}}$，我们可以使用逆协方差（信息矩阵）。逆协方差的更新规则是加法性的：\n$$C_2^{-1} = C_1^{-1} + r_2^{-1} h_2 h_2^\\top$$\n这可以通过将Sherman-Morrison-Woodbury公式应用于 $C_2$ 的表达式来证明。令 $A=C_1^{-1}$，$U=h_2$，$C=r_2^{-1}$，$V=h_2^\\top$。那么 $(C_1^{-1} + r_2^{-1} h_2 h_2^\\top)^{-1} = C_1 - C_1 h_2 (r_2 + h_2^\\top C_1 h_2)^{-1} h_2^\\top C_1$，这与 $C_2$ 的公式相匹配。\n代入 $C_1^{-1}$ 的表达式：\n$$C_2^{-1} = (C_{\\text{prior}}^{-1} + r_1^{-1} h_1 h_1^\\top) + r_2^{-1} h_2 h_2^\\top = C_{\\text{prior}}^{-1} + r_1^{-1} h_1 h_1^\\top + r_2^{-1} h_2 h_2^\\top$$\n这正是 $(C_{\\text{post}}^{\\text{batch}})^{-1}$ 的表达式。因此，$C_2 = C_{\\text{post}}^{\\text{batch}}$，证明了序贯更新和批量更新产生相同的后验协方差。\n\n### 第3部分：后验均值更新\n\n后验均值更新公式也来自条件高斯分布的性质。更新后的均值 $m_2$ 由下式给出：\n$$m_2 = m_1 + (C_1 h_2) (h_2^\\top C_1 h_2 + r_2)^{-1} (y_2 - h_2^\\top m_1)$$\n其中 $m_1$ 是同化第一个传感器后的均值。项 $y_2 - h_2^\\top m_1$ 是新息，代表观测 $y_2$ 提供的新信息。更新可以写成：\n$$m_2 = m_1 + K_2 (y_2 - h_2^\\top m_1)$$\n其中 $K_2 = C_1 h_2 (h_2^\\top C_1 h_2 + r_2)^{-1}$ 是第二个传感器的卡尔曼增益。\n\n### 第4部分：数值计算和弗罗贝尼乌斯范数\n\n我们计算批量和序贯方法的逆协方差矩阵，并证明它们是相同的。这意味着矩阵本身是相同的，它们差的弗罗贝尼乌斯范数为0。这种方法避免了复杂的矩阵求逆和分数运算。\n\n首先，计算所需的组件：\n$C_{\\text{prior}} = \\begin{pmatrix} 2  3/5 \\\\ 3/5  1 \\end{pmatrix} \\implies C_{\\text{prior}}^{-1} = \\frac{1}{2-9/25}\\begin{pmatrix} 1  -3/5 \\\\ -3/5  2 \\end{pmatrix} = \\frac{25}{41}\\begin{pmatrix} 1  -3/5 \\\\ -3/5  2 \\end{pmatrix} = \\frac{1}{41}\\begin{pmatrix} 25  -15 \\\\ -15  50 \\end{pmatrix}$。\n$h_1 = \\begin{pmatrix} 1 \\\\ 1/2 \\end{pmatrix}, r_1 = 1/2 \\implies r_1^{-1}=2$。\n$r_1^{-1}h_1 h_1^\\top = 2 \\begin{pmatrix} 1 \\\\ 1/2 \\end{pmatrix} \\begin{pmatrix} 1  1/2 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 1  1/2 \\end{pmatrix}$。\n$h_2 = \\beginpmatrix} -1/3 \\\\ 1 \\end{pmatrix}, r_2 = 2/5 \\implies r_2^{-1}=5/2$。\n$r_2^{-1}h_2 h_2^\\top = \\frac{5}{2} \\beginpmatrix} -1/3 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} -1/3  1 \\end{pmatrix} = \\frac{5}{2} \\begin{pmatrix} 1/9  -1/3 \\\\ -1/3  1 \\end{pmatrix} = \\begin{pmatrix} 5/18  -5/6 \\\\ -5/6  5/2 \\end{pmatrix}$。\n\n**批量计算：**\n$$(C_{\\text{post}}^{\\text{batch}})^{-1} = C_{\\text{prior}}^{-1} + r_1^{-1}h_1 h_1^\\top + r_2^{-1}h_2 h_2^\\top$$\n$$(C_{\\text{post}}^{\\text{batch}})^{-1} = \\frac{1}{41}\\begin{pmatrix} 25  -15 \\\\ -15  50 \\end{pmatrix} + \\begin{pmatrix} 2  1 \\\\ 1  1/2 \\end{pmatrix} + \\begin{pmatrix} 5/18  -5/6 \\\\ -5/6  5/2 \\end{pmatrix}$$\n我们找一个公分母，即 $41 \\times 18 = 738$。\n$$(C_{\\text{post}}^{\\text{batch}})^{-1} = \\frac{18}{738}\\begin{pmatrix} 25  -15 \\\\ -15  50 \\end{pmatrix} + \\frac{738}{738}\\begin{pmatrix} 2  1 \\\\ 1  1/2 \\end{pmatrix} + \\frac{41}{738}\\begin{pmatrix} 5  -15 \\\\ -15  45 \\end{pmatrix}$$\n$$ = \\frac{1}{738} \\left[ \\begin{pmatrix} 450  -270 \\\\ -270  900 \\end{pmatrix} + \\begin{pmatrix} 1476  738 \\\\ 738  369 \\end{pmatrix} + \\begin{pmatrix} 205  -615 \\\\ -615  1845 \\end{pmatrix} \\right]$$\n合并各项：\n$$ = \\frac{1}{738} \\begin{pmatrix} 450+1476+205  -270+738-615 \\\\ -270+738-615  900+369+1845 \\end{pmatrix}$$\n$$ = \\frac{1}{738} \\begin{pmatrix} 2131  -147 \\\\ -147  3114 \\end{pmatrix}$$\n\n**序贯计算：**\n首先，求 $C_1^{-1}$：\n$$C_1^{-1} = C_{\\text{prior}}^{-1} + r_1^{-1}h_1 h_1^\\top = \\frac{1}{41}\\begin{pmatrix} 25  -15 \\\\ -15  50 \\end{pmatrix} + \\begin{pmatrix} 2  1 \\\\ 1  1/2 \\end{pmatrix}$$\n公分母是 $41 \\times 2 = 82$。\n$$C_1^{-1} = \\frac{2}{82}\\begin{pmatrix} 25  -15 \\\\ -15  50 \\end{pmatrix} + \\frac{82}{82}\\begin{pmatrix} 2  1 \\\\ 1  1/2 \\end{pmatrix} = \\frac{1}{82} \\left( \\begin{pmatrix} 50  -30 \\\\ -30  100 \\end{pmatrix} + \\begin{pmatrix} 164  82 \\\\ 82  41 \\end{pmatrix} \\right) = \\frac{1}{82}\\begin{pmatrix} 214  52 \\\\ 52  141 \\end{pmatrix}$$\n接下来，求 $C_2^{-1} = C_1^{-1} + r_2^{-1}h_2 h_2^\\top$：\n$$C_2^{-1} = \\frac{1}{82}\\begin{pmatrix} 214  52 \\\\ 52  141 \\end{pmatrix} + \\begin{pmatrix} 5/18  -5/6 \\\\ -5/6  5/2 \\end{pmatrix}$$\n$82=2 \\times 41$ 和 $18=2 \\times 9$ 的公分母是 $2 \\times 9 \\times 41 = 738$。\n$$C_2^{-1} = \\frac{9}{738}\\begin{pmatrix} 214  52 \\\\ 52  141 \\end{pmatrix} + \\frac{41}{738}\\begin{pmatrix} 5  -15 \\\\ -15  45 \\end{pmatrix}$$\n$$ = \\frac{1}{738} \\left[ \\begin{pmatrix} 1926  468 \\\\ 468  1269 \\end{pmatrix} + \\begin{pmatrix} 205  -615 \\\\ -615  1845 \\end{pmatrix} \\right] = \\frac{1}{738} \\begin{pmatrix} 2131  -147 \\\\ -147  3114 \\end{pmatrix}$$\n如推导所示，$(C_{\\text{post}}^{\\text{batch}})^{-1}$ 和 $C_2^{-1}$ 是相同的。由于矩阵的逆是唯一的，这意味着 $C_{\\text{post}}^{\\text{batch}} = C_2$。差矩阵是零矩阵：\n$$C_{\\text{post}}^{\\text{batch}} - C_2 = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}$$\n零矩阵的弗罗贝尼乌斯范数是：\n$$\\left\\| C_{\\text{post}}^{\\text{batch}} - C_2 \\right\\|_{F} = \\sqrt{0^2+0^2+0^2+0^2} = 0$$\n\n### 第5部分：数值稳定性问题\n\n标准的秩-1协方差更新公式 $C_k = C_{k-1} - K_k h_k^\\top C_{k-1}$ 虽然在代数上是正确的，但在有限精度算术中会遇到数值不稳定性问题。\n1.  **正定性的丧失**：该公式涉及两个矩阵的相减。理论上，$C_k$ 保证是对称正定的。然而，由于浮点舍入误差，计算结果可能会失去对称性，更严重的是，可能不再是正定的。如果协方差矩阵出现负特征值，滤波器可能会变得不稳定并发散。当不确定性显著减小，使得 $C_{k-1}$ 接近奇异时，这个问题尤其严重。\n2.  **灾难性抵消**：当先验不确定性很大（$C_{k-1}$ 的元素很大）且观测信息非常丰富时，更新项 $K_k h_k^\\top C_{k-1}$ 也可能是一个大矩阵，其元素在数量级上与 $C_{k-1}$ 的元素相近。两个近似相等的大数相减会导致相对精度的严重损失，这种效应被称为灾难性抵消。\n\n这些问题可以通过替代公式来解决：\n-   **平方根滤波器**：这些算法传播协方差的“平方根”$S_k$，其中 $C_k = S_k S_k^\\top$。更新规则是直接为 $S_k$ 推导的。通过构造，得到的协方差矩阵 $C_k = S_k S_k^\\top$ 总是对称半正定的，从而防止了由于舍入误差导致的正定性丧失。此外，$S_k$ 的条件数是 $C_k$ 条件数的平方根，这通常能改善问题的数值性质。\n-   **Joseph稳定形式**：一个更稳定的协方差更新替代公式是Joseph形式：\n    $$C_k = (I - K_k h_k^\\top) C_{k-1} (I - K_k h_k^\\top)^\\top + K_k r_k K_k^\\top$$\n    这个表达式在代数上与标准形式等价，但在数值上更优越。它通过对两个矩阵求和来计算新的协方差 $C_k$，而这两个矩阵根据它们的结构（$A A^\\top$）保证是半正定的。半正定矩阵之和总是半正定的。这种形式避免了导致正定性丧失的直接减法，代价是计算复杂度的增加。",
            "answer": "$$\\boxed{0}$$"
        }
    ]
}