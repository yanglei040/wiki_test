{
    "hands_on_practices": [
        {
            "introduction": "先验分布的构建是贝叶斯推断的基石。最大熵原理 (MaxEnt) 为我们提供了一种从第一性原理出发，构建满足已知约束且信息量最少的先验的严谨方法。这个练习将引导你应用最大熵原理，仅基于对未知参数 $\\ell^{1}$ 范数期望值的约束，来推导拉普拉斯 (Laplace) 分布——这是稀疏贝叶斯建模中的一个核心先验分布 。通过这个实践，你将深刻理解物理或统计约束如何直接决定先验分布的数学形式。",
            "id": "3414194",
            "problem": "考虑一个欠定线性反问题，其中未知参数向量为 $u \\in \\mathbb{R}^{n}$。您需要在反问题和数据同化的背景下为 $u$ 建立一个先验分布模型。假设有以下建模要求：\n- 坐标间独立：联合先验密度分解为 $\\pi(u) = \\prod_{i=1}^{n} p_{i}(u_{i})$。\n- 坐标可交换性：每个坐标都用相同的边缘分布 $p_{i} = p$ 进行建模。\n- 唯一可用的全局约束是期望 $\\ell^{1}$ 范数，$\\mathbb{E}\\!\\left[\\|u\\|_{1}\\right] = c$，对于给定的 $c  0$，其中 $\\|u\\|_{1} = \\sum_{i=1}^{n} |u_{i}|$，且期望是关于先验分布计算的。\n\n使用最大熵（MaxEnt）原理和香农微分熵，并从矩约束下熵最大化的第一性原理出发，推导在约束 $\\mathbb{E}\\!\\left[\\|u\\|_{1}\\right] = c$ 下，熵最大化的独立先验在 $\\mathbb{R}^{n}$ 上的形式。具体来说：\n1. 证明最大熵边缘分布 $p$ 必须仅依赖于 $|x|$，且相应的联合先验是相同边缘分布的乘积。\n2. 推导在归一化和 $\\mathbb{E}\\!\\left[|U|\\right] = c/n$（其中 $U \\sim p$ 是单个坐标）的约束下，通过最大化熵得到的边缘密度 $p$ 的显式函数形式。\n3. 计算该边缘分布的尺度参数，用 $c$ 和 $n$ 表示。\n\n您的最终答案必须是边缘先验尺度参数的单个闭式解析表达式，用 $c$ 和 $n$ 表示。无需四舍五入。最终答案中不要包含任何单位。",
            "solution": "本题旨在利用最大熵（MaxEnt）原理，在一组指定约束条件下，推导向量 $u \\in \\mathbb{R}^{n}$ 的先验分布 $\\pi(u)$ 的形式。解法将遵循最大熵方法的逻辑步骤来构建。\n\n首先，我们将问题形式化。我们希望最大化联合先验分布 $\\pi(u)$ 的香农微分熵，其表达式为：\n$$H[\\pi] = -\\int_{\\mathbb{R}^{n}} \\pi(u) \\ln \\pi(u) \\, du$$\n题目陈述了关于 $\\pi(u)$ 的两个建模要求：\n1.  坐标间独立：联合密度分解为边缘密度的乘积，即 $\\pi(u) = \\prod_{i=1}^{n} p_{i}(u_{i})$。\n2.  坐标可交换性：边缘密度相同，即对所有 $i=1, \\dots, n$ 都有 $p_{i} = p$。\n\n在这两个要求下，联合先验为 $\\pi(u) = \\prod_{i=1}^{n} p(u_{i})$。我们可以简化联合熵的表达式：\n$$H[\\pi] = -\\int_{\\mathbb{R}^{n}} \\left(\\prod_{j=1}^{n} p(u_{j})\\right) \\ln\\left(\\prod_{i=1}^{n} p(u_{i})\\right) \\, du$$\n$$H[\\pi] = -\\int_{\\mathbb{R}^{n}} \\left(\\prod_{j=1}^{n} p(u_j)\\right) \\left(\\sum_{i=1}^{n} \\ln p(u_i)\\right) \\, du$$\n$$H[\\pi] = -\\sum_{i=1}^{n} \\int_{\\mathbb{R}^{n}} \\ln p(u_i) \\left(\\prod_{j=1}^{n} p(u_j)\\right) \\, du_1 \\dots du_n$$\n对于和中的每一项 $i$，我们可以分离积分。对于 $j \\neq i$ 的 $u_j$ 的积分是 $\\int_{\\mathbb{R}} p(u_j) \\, du_j$，由于边缘概率密度 $p$ 的归一化，该积分等于 $1$。这样剩下：\n$$H[\\pi] = -\\sum_{i=1}^{n} \\int_{\\mathbb{R}} p(u_i) \\ln p(u_i) \\, du_i$$\n和中的每一项都是边缘分布 $p$ 的熵，记为 $H[p]$。因为有 $n$ 个相同的项，总熵为：\n$$H[\\pi] = n H[p] = -n \\int_{\\mathbb{R}} p(x) \\ln p(x) \\, dx$$\n因此，最大化联合熵 $H[\\pi]$ 等价于最大化边缘熵 $H[p]$。\n\n接下来，我们处理关于期望 $\\ell^1$ 范数的全局约束：\n$$\\mathbb{E}_{\\pi}\\!\\left[\\|u\\|_{1}\\right] = c$$\n其中 $\\|u\\|_{1} = \\sum_{i=1}^{n} |u_{i}|$。利用期望的线性性质：\n$$\\mathbb{E}_{\\pi}\\!\\left[\\sum_{i=1}^{n} |u_{i}|\\right] = \\sum_{i=1}^{n} \\mathbb{E}_{\\pi}[|u_{i}|] = c$$\n$|u_i|$ 关于联合分布 $\\pi(u)$ 的期望是：\n$$\\mathbb{E}_{\\pi}[|u_{i}|] = \\int_{\\mathbb{R}^{n}} |u_i| \\pi(u) \\, du = \\int_{\\mathbb{R}^{n}} |u_i| \\prod_{j=1}^{n} p(u_j) \\, du_1 \\dots du_n$$\n再次，对所有 $j \\neq i$ 的 $u_j$ 进行积分得到 $1$，剩下：\n$$\\mathbb{E}_{\\pi}[|u_{i}|] = \\int_{\\mathbb{R}} |u_i| p(u_i) \\, du_i$$\n这是随机变量 $X$（其分布为 $p$）的 $|X|$ 的期望。我们将其记为 $\\mathbb{E}_{p}[|X|]$。由于边缘分布相同，这个期望对所有 $i$ 都是一样的。该约束变为：\n$$\\sum_{i=1}^{n} \\mathbb{E}_{p}[|X|] = n \\mathbb{E}_{p}[|X|] = c$$\n这就得到了对边缘密度 $p$ 的一个约束：\n$$\\mathbb{E}_{p}[|X|] = \\int_{-\\infty}^{\\infty} |x| p(x) \\, dx = \\frac{c}{n}$$\n\n问题现在简化为寻找边缘密度 $p(x)$，使其在以下两个约束条件下最大化 $H[p]$：\n1.  归一化： $\\int_{-\\infty}^{\\infty} p(x) \\, dx = 1$\n2.  矩约束： $\\int_{-\\infty}^{\\infty} |x| p(x) \\, dx = \\frac{c}{n}$\n\n我们使用变分法来解决这个问题。我们定义要最大化的泛函，通过拉格朗日乘子 $\\lambda_0$ 和 $\\lambda_1$ 并入约束条件：\n$$L[p] = -\\int_{-\\infty}^{\\infty} p(x) \\ln p(x) \\, dx - (\\lambda_0-1) \\left(\\int_{-\\infty}^{\\infty} p(x) \\, dx - 1\\right) - \\lambda_1 \\left(\\int_{-\\infty}^{\\infty} |x| p(x) \\, dx - \\frac{c}{n}\\right)$$\n求 $L[p]$ 关于 $p(x)$ 的泛函导数并令其为零，得到：\n$$\\frac{\\delta L}{\\delta p(x)} = -\\ln p(x) - 1 - (\\lambda_0-1) - \\lambda_1 |x| = 0$$\n$$\\ln p(x) = -\\lambda_0 - \\lambda_1 |x|$$\n$$p(x) = \\exp(-\\lambda_0) \\exp(-\\lambda_1 |x|)$$\n这个形式明确表明 $p(x)$ 仅依赖于 $|x|$，这解决了任务1的第一部分。联合先验的因式分解是一个初始假设，此处证实了它与最大熵解的结构是一致的。\n\n现在，我们确定拉格朗日乘子。令 $Z = \\exp(\\lambda_0)$。则密度为 $p(x) = \\frac{1}{Z} \\exp(-\\lambda_1 |x|)$。\n\n使用归一化约束：\n$$\\int_{-\\infty}^{\\infty} \\frac{1}{Z} \\exp(-\\lambda_1 |x|) \\, dx = 1$$\n被积函数是偶函数，因此我们可以写成：\n$$\\frac{2}{Z} \\int_{0}^{\\infty} \\exp(-\\lambda_1 x) \\, dx = 1$$\n为使积分收敛，我们需要 $\\lambda_1  0$。\n$$\\frac{2}{Z} \\left[-\\frac{1}{\\lambda_1} \\exp(-\\lambda_1 x)\\right]_{0}^{\\infty} = \\frac{2}{Z} \\left(0 - \\left(-\\frac{1}{\\lambda_1}\\right)\\right) = \\frac{2}{Z \\lambda_1} = 1$$\n这得到 $Z = \\frac{2}{\\lambda_1}$。将其代回 $p(x)$ 的表达式，得到其显式函数形式，即拉普拉斯分布：\n$$p(x) = \\frac{\\lambda_1}{2} \\exp(-\\lambda_1 |x|)$$\n这就完成了任务2。\n\n使用矩约束：\n$$\\int_{-\\infty}^{\\infty} |x| p(x) \\, dx = \\frac{c}{n}$$\n$$\\int_{-\\infty}^{\\infty} |x| \\frac{\\lambda_1}{2} \\exp(-\\lambda_1 |x|) \\, dx = \\lambda_1 \\int_{0}^{\\infty} x \\exp(-\\lambda_1 x) \\, dx = \\frac{c}{n}$$\n左边的积分可以用分部积分法求解。令 $u=x$ 和 $dv=\\exp(-\\lambda_1 x) dx$。那么 $du=dx$ 且 $v = -\\frac{1}{\\lambda_1}\\exp(-\\lambda_1 x)$。\n$$\\int_{0}^{\\infty} x \\exp(-\\lambda_1 x) \\, dx = \\left[-\\frac{x}{\\lambda_1} \\exp(-\\lambda_1 x)\\right]_{0}^{\\infty} - \\int_{0}^{\\infty} \\left(-\\frac{1}{\\lambda_1}\\right) \\exp(-\\lambda_1 x) \\, dx$$\n$$= (0 - 0) + \\frac{1}{\\lambda_1} \\int_{0}^{\\infty} \\exp(-\\lambda_1 x) \\, dx = \\frac{1}{\\lambda_1} \\left[-\\frac{1}{\\lambda_1} \\exp(-\\lambda_1 x)\\right]_{0}^{\\infty} = \\frac{1}{\\lambda_1^2}$$\n将此结果代入矩约束方程：\n$$\\lambda_1 \\left(\\frac{1}{\\lambda_1^2}\\right) = \\frac{1}{\\lambda_1} = \\frac{c}{n}$$\n这意味着 $\\lambda_1 = \\frac{n}{c}$。因为 $n0$ 且 $c0$，所以条件 $\\lambda_10$ 得到满足。\n\n边缘密度的最终形式是：\n$$p(x) = \\frac{n}{2c} \\exp\\left(-\\frac{n|x|}{c}\\right)$$\n\n最后，对于任务3，我们计算尺度参数。位置参数为 $\\mu$、尺度参数为 $b  0$ 的拉普拉斯分布的概率密度函数是：\n$$f(x; \\mu, b) = \\frac{1}{2b} \\exp\\left(-\\frac{|x-\\mu|}{b}\\right)$$\n在我们的例子中，位置参数 $\\mu$ 为 $0$。将我们推导出的密度 $p(x)$ 与标准形式 $f(x; 0, b)$进行比较，我们得到：\n$$p(x) = \\frac{n}{2c} \\exp\\left(-\\frac{n|x|}{c}\\right) = \\frac{1}{2(c/n)} \\exp\\left(-\\frac{|x|}{c/n}\\right)$$\n通过直接比较，尺度参数 $b$ 为：\n$$b = \\frac{c}{n}$$\n这就是以 $c$ 和 $n$ 表示的边缘先验的尺度参数。",
            "answer": "$$\\boxed{\\frac{c}{n}}$$"
        },
        {
            "introduction": "在许多反演问题中，我们试图恢复的未知量是一个连续函数，例如图像强度或地下介质属性。然而，任何数值计算都必须在离散网格上进行，这就引出了一个关键问题：我们构建的先验是否依赖于离散化的选择？一个行为良好的先验模型应当在不同分辨率的网格上表现出一致的统计特性，即所谓的“网格无关性”。这个编码练习将直接应对这一挑战 ，你将对一个定义在函数空间上的高斯先验进行有限元离散化，并通过比较粗细网格上的协方差矩阵来量化其网格无关性。",
            "id": "3414123",
            "problem": "考虑单位区间 $[0,1]$ 上的一个零均值高斯先验，其具有齐次狄利克雷边界条件，并由以下精度双线性形式定义：对于 Sobolev 空间 $H_0^1([0,1])$ 中的函数 $u$ 和 $v$，精度算子 $L$ 导出对称双线性形式\n$$\na(u,v) = \\kappa^2 \\int_0^1 u(x) v(x)\\, dx + \\int_0^1 \\frac{du}{dx}(x)\\frac{dv}{dx}(x)\\, dx,\n$$\n其中 $\\kappa  0$ 是一个实参数。该高斯先验由协方差算子 $C = L^{-1}$ 表征，此算子在弱意义下解释。\n\n您需要使用有限元 (FE) 方法，在单位区间的两个均匀网格上，通过连续分片线性基函数，来推导、实现并比较与同一连续高斯先验相关的离散化协方差矩阵。这两个网格分别对应于具有 $N$ 个单元的粗网格和具有 $2N$ 个单元的细网格。离散化必须从第一性原理出发，使用上述弱形式和标准的伽辽金方法：通过在单元上对 $a(u,v)$ 的相应项进行积分来组装有限元刚度矩阵和质量矩阵。通过在排除边界基函数的子空间中进行操作来强制施加齐次狄利克雷边界条件。\n\n在这些基础上，构建两个网格上的离散精度矩阵，并通过对离散精度矩阵求逆来获得相应的离散协方差矩阵。为了以一种与网格无关的方式比较两种离散化，需将细网格协方差矩阵限制到粗网格的节点子集上：由于细网格是通过因子二进行的均匀细化，每个粗网格的内部节点都与一个细网格的内部节点重合。通过选取细网格协方差中对应于粗网格内部节点的行和列，来形成受限的细网格协方差子矩阵。\n\n对于每个指定的测试用例，定义并计算以下两个用于比较粗网格协方差 $C_h$ 与受限细网格协方差 $C_{h/2 \\to h}$ 的离散化不变性的定量度量：\n1. 最大相对方差差异\n$$\n\\delta_{\\mathrm{var}} = \\max_{i} \\left| \\frac{ \\left(C_h\\right)_{ii} - \\left(C_{h/2 \\to h}\\right)_{ii} }{ \\left(C_h\\right)_{ii} } \\right|.\n$$\n2. 相对弗罗贝尼乌斯范数差异\n$$\n\\delta_{\\mathrm{F}} = \\frac{ \\left\\| C_h - C_{h/2 \\to h} \\right\\|_F }{ \\left\\| C_h \\right\\|_F },\n$$\n其中 $\\|\\cdot\\|_F$ 表示弗罗贝尼烏斯范数。\n\n您的实现必须使用以下参数值测试套件，每个套件包含一对 $(N,\\kappa)$：\n- 测试用例 1 (一般情况)：$(N,\\kappa) = (16, 1.0)$。\n- 测试用例 2 (边缘情况，场更粗糙)：$(N,\\kappa) = (8, 0.3)$。\n- 测试用例 3 (边缘情况，场更平滑)：$(N,\\kappa) = (32, 3.0)$。\n\n所有计算都是纯数学的；不涉及物理单位，也不需要角度单位。\n\n您的程序必须输出单行，其中包含一个由六个浮点数组成的扁平列表，顺序如下\n$$\n\\left[ \\delta_{\\mathrm{var}}^{(1)}, \\delta_{\\mathrm{F}}^{(1)}, \\delta_{\\mathrm{var}}^{(2)}, \\delta_{\\mathrm{F}}^{(2)}, \\delta_{\\mathrm{var}}^{(3)}, \\delta_{\\mathrm{F}}^{(3)} \\right],\n$$\n对应于三个测试用例。每个数字必须四舍五入到八位小数。输出格式必须是严格的单行，结果为方括号内由逗号分隔的列表，例如，\n$$\n[\\delta_{\\mathrm{var}}^{(1)},\\delta_{\\mathrm{F}}^{(1)},\\delta_{\\mathrm{var}}^{(2)},\\delta_{\\mathrm{F}}^{(2)},\\delta_{\\mathrm{var}}^{(3)},\\delta_{\\mathrm{F}}^{(3)}].\n$$",
            "solution": "我们从先验的定义开始。设 $u$ 是 $H_0^1([0,1])$ 中的一个随机函数，服从零均值高斯分布，该分布由精度算子 $L$ 表征，其弱形式由下式给出\n$$\na(u,v) = \\kappa^2 \\int_0^1 u(x) v(x)\\, dx + \\int_0^1 \\frac{du}{dx}(x)\\frac{dv}{dx}(x)\\, dx.\n$$\n协方差算子 $C = L^{-1}$ 被定义为弱意义下的逆：对于对偶空间中的任意 $f,g$，$\\langle f, C g \\rangle$ 是方程 $a(C g, v) = \\langle g, v \\rangle$ 对所有 $v$ 的解。\n\n为了在一个包含 $N$ 个单元的网格上离散化此先验，我们选择标准的有限元 (FE) 空间，该空间由节点位于 $x_i = i h$（$i=0,1,\\ldots,N$ 且 $h = 1/N$）的连续分片线性函数构成。齐次狄利克雷边界条件意味着自由度对应于 $i = 1,\\ldots,N-1$ 的内部节点 $x_i$。设 $\\{\\phi_i\\}_{i=1}^{N-1}$ 表示与这些内部节点相关联的有限元基函数。使用伽辽金方法，离散精度矩阵 $Q_h \\in \\mathbb{R}^{(N-1)\\times(N-1)}$ 定义为\n$$\n(Q_h)_{ij} = a(\\phi_i, \\phi_j) = \\kappa^2 \\int_0^1 \\phi_i(x)\\phi_j(x)\\, dx + \\int_0^1 \\frac{d\\phi_i}{dx}(x)\\frac{d\\phi_j}{dx}(x)\\, dx.\n$$\n第一项是有限元质量矩阵，第二项是有限元刚度矩阵。有限元方法中的一个基本构造是通过局部单元贡献来组装质量和刚度矩阵以得到这些积分。对于均匀网格和分片线性基，刚度矩阵的元素源自梯度项，并涉及单元长度的倒数；而质量矩阵的元素源自 $L^2$ 内积，并涉及单元长度。具体来说，由于基函数的支撑域仅在相邻单元上重叠，这些矩阵是三对角的。\n\n根据构造，$Q_h$ 是对称正定的。离散协方差矩阵是离散精度矩阵的逆：\n$$\nC_h = Q_h^{-1}.\n$$\n这个在有限元系数上的离散化高斯分布逼近了连续先验，其中有限元解最小化了由 $a(\\cdot,\\cdot)$ 导出的能量。离散化的先验是一致的，因为将网格细化到 $2N$ 个单元定义的空间包含了粗网格空间，并且在细网格上的伽辽金离散化（其精度矩阵为 $Q_{h/2}$，协方差为 $C_{h/2} = Q_{h/2}^{-1}$）能更精细地逼近相同的连续先验。\n\n为了以一种与网格无关的方式比较粗网格协方差 $C_h$ 和细网格协方差 $C_{h/2}$，我们将细网格协方差限制到粗网格的节点子集上。由于细网格是因子为二的均匀细化，粗网格的内部节点与细网格在位置 $x_j = j h = 2 j h_f$（其中 $j=1,\\ldots,N-1$，$h_f = 1/(2N)$ 是细网格尺寸）的内部节点重合。用索引来说，粗网格内部节点对应于细网格内部索引 $2j$（在使用1-based索引时），或 $2j-1$（在数组使用0-based索引时）。通过选择 $C_{h/2}$ 中对应于这些细网格索引的行和列的子矩阵来定义限制。将此受限子矩阵表示为 $C_{h/2 \\to h}$。\n\n为了评估离散化不变性，我们计算两个度量：\n1. 最大相对方差差异\n$$\n\\delta_{\\mathrm{var}} = \\max_{i} \\left| \\frac{ \\left(C_h\\right)_{ii} - \\left(C_{h/2 \\to h}\\right)_{ii} }{ \\left(C_h\\right)_{ii} } \\right|,\n$$\n它比较了粗网格节点处的边际方差。\n2. 相对弗罗贝尼乌斯范数差异\n$$\n\\delta_{\\mathrm{F}} = \\frac{ \\left\\| C_h - C_{h/2 \\to h} \\right\\|_F }{ \\left\\| C_h \\right\\|_F },\n$$\n它衡量了协方差结构的全局差异。\n\n与这些原则一致的算法步骤：\n- 对于给定的 $N$ 和 $\\kappa$，计算均匀网格尺寸 $h = 1/N$ 并组装有限元质量矩阵和刚度矩阵。对于均匀网格上的分片线性基，全局质量矩阵 $M_h$ 和刚度矩阵 $K_h$ 是三对角的，其元素为\n$$\n(M_h)_{ii} = \\frac{2h}{3},\\quad (M_h)_{i,i\\pm 1} = \\frac{h}{6},\\quad (K_h)_{ii} = \\frac{2}{h},\\quad (K_h)_{i,i\\pm 1} = -\\frac{1}{h},\n$$\n对于 $i=1,\\ldots,N-1$，当索引超出内部范围时，非对角线元素为零。\n- 形成离散精度矩阵 $Q_h = \\kappa^2 M_h + K_h$ 并对其进行数值求逆以获得 $C_h = Q_h^{-1}$。\n- 对具有 $2N$ 个单元的细网格重复组装过程以获得 $C_{h/2}$。\n- 通过选择与粗网格内部节点相对应的细网格索引的行和列，将 $C_{h/2}$ 限制到粗网格内部节点上，以获得 $C_{h/2 \\to h}$。\n- 为每个测试用例计算 $\\delta_{\\mathrm{var}}$ 和 $\\delta_{\\mathrm{F}}$。\n\n这些步骤实现了弱形式精度的伽辽金离散化，通过排除边界自由度来施加边界条件，并利用粗细有限元空间之间的子空间关系为比较提供了一致的限制。因为离散化源自相同的连续先验，且细网格空间包含粗网格空间，所以当 $N$ 足够大且离散化是一致的时，$C_{h/2 \\to h}$ 应该能很好地逼近 $C_h$，从而导致两种差异度量的值都很小。该测试套件包括一个一般情况和两个边缘情况，旨在探究当 $\\kappa$ 变化时的行为，其中较小的 $\\kappa$ 会导致更粗糙的场，而较大的 $\\kappa$ 会导致更平滑的场。\n\n程序将为指定的测试用例计算这些度量，并打印单行，其中包含按 $[\\delta_{\\mathrm{var}}^{(1)},\\delta_{\\mathrm{F}}^{(1)},\\delta_{\\mathrm{var}}^{(2)},\\delta_{\\mathrm{F}}^{(2)},\\delta_{\\mathrm{var}}^{(3)},\\delta_{\\mathrm{F}}^{(3)}]$ 顺序排列的六个结果，每个结果四舍五入到八位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef assemble_fe_matrices(N: int):\n    \"\"\"\n    Assemble mass and stiffness matrices for 1D FE with N uniform elements\n    on [0,1] and homogeneous Dirichlet boundary conditions.\n    Returns M, K of size (N-1) x (N-1).\n    \"\"\"\n    if N  2:\n        raise ValueError(\"N must be at least 2 to have interior degrees of freedom.\")\n    n = N - 1  # number of interior nodes\n    h = 1.0 / N\n\n    # Mass matrix (tridiagonal)\n    diag_M = np.full(n, 2.0 * h / 3.0)\n    off_M = np.full(n - 1, h / 6.0)\n    M = np.diag(diag_M)\n    if n > 1:\n        M += np.diag(off_M, 1) + np.diag(off_M, -1)\n\n    # Stiffness matrix (tridiagonal)\n    diag_K = np.full(n, 2.0 / h)\n    off_K = np.full(n - 1, -1.0 / h)\n    K = np.diag(diag_K)\n    if n > 1:\n        K += np.diag(off_K, 1) + np.diag(off_K, -1)\n\n    return M, K\n\ndef covariance_matrix(N: int, kappa: float):\n    \"\"\"\n    Compute the discrete covariance matrix C_h = Q_h^{-1} for mesh with N elements.\n    \"\"\"\n    M, K = assemble_fe_matrices(N)\n    Q = (kappa ** 2) * M + K\n    # Invert Q using solve with identity for numerical stability\n    n = Q.shape[0]\n    I = np.eye(n)\n    C = np.linalg.solve(Q, I)\n    return C\n\ndef restrict_fine_to_coarse(C_fine: np.ndarray, N_coarse: int):\n    \"\"\"\n    Restrict the fine covariance matrix to the coarse interior nodes.\n    Fine mesh assumed to have 2*N_coarse elements.\n    Coarse interior indices j=1..N_coarse-1 correspond to fine indices i=2*j (1-based),\n    which are (2*j - 1) in 0-based array indexing.\n    \"\"\"\n    n_coarse = N_coarse - 1\n    fine_indices = [2 * j - 1 for j in range(1, N_coarse)]  # 0-based\n    C_restricted = C_fine[np.ix_(fine_indices, fine_indices)]\n    return C_restricted\n\ndef invariance_metrics(N: int, kappa: float):\n    \"\"\"\n    Compute the two discrepancy metrics:\n    - delta_var: maximum relative difference of variances (diagonal entries)\n    - delta_F: relative Frobenius norm difference\n    \"\"\"\n    # Coarse covariance\n    C_coarse = covariance_matrix(N, kappa)\n    # Fine covariance with twice as many elements\n    C_fine = covariance_matrix(2 * N, kappa)\n    # Restrict fine covariance to coarse nodes\n    C_fine_to_coarse = restrict_fine_to_coarse(C_fine, N)\n\n    # Variance discrepancy\n    diag_coarse = np.diag(C_coarse)\n    diag_fine_restricted = np.diag(C_fine_to_coarse)\n    # Avoid division by zero: diagonals of covariance should be positive\n    rel_var = np.abs((diag_coarse - diag_fine_restricted) / diag_coarse)\n    delta_var = float(np.max(rel_var)) if rel_var.size > 0 else 0.0\n\n    # Frobenius norm discrepancy\n    fro_diff = np.linalg.norm(C_coarse - C_fine_to_coarse, ord='fro')\n    fro_coarse = np.linalg.norm(C_coarse, ord='fro')\n    delta_F = float(fro_diff / fro_coarse) if fro_coarse > 0 else 0.0\n\n    return delta_var, delta_F\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (16, 1.0),  # general case\n        (8, 0.3),   # rougher field (smaller kappa)\n        (32, 3.0),  # smoother field (larger kappa)\n    ]\n\n    results = []\n    for N, kappa in test_cases:\n        d_var, d_F = invariance_metrics(N, kappa)\n        results.append(d_var)\n        results.append(d_F)\n\n    # Final print statement in the exact required format with 8 decimal places.\n    formatted = \",\".join(f\"{x:.8f}\" for x in results)\n    print(f\"[{formatted}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在实际应用中，我们不仅对未知参数本身不确定，也常常对其先验分布的参数（即超参数，如方差）不确定。分层贝叶斯建模通过为这些超参数赋予先验分布（即超先验）来优雅地处理这种不确定性，从而增强模型的鲁棒性。这个练习将带你探索为高斯先验的尺度参数选择不同超先验（例如，逆伽马分布与半柯西分布）所带来的影响 。通过数值积分和后验分析，你将进行一次完整的敏感性分析，这是确保贝叶斯推断结论可靠性的关键步骤。",
            "id": "3414106",
            "problem": "考虑一个具有高斯观测模型和层级高斯先验的线性逆问题。设 $A \\in \\mathbb{R}^{m \\times n}$ 为一个已知的正演算子，$x \\in \\mathbb{R}^n$ 为未知参数向量，$y \\in \\mathbb{R}^m$ 为观测数据。观测模型为\n$$\ny = A x + \\varepsilon,\n$$\n其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_m)$，具有已知的噪声方差 $\\sigma^2  0$，$I_m$ 是 $m \\times m$ 的单位矩阵。\n\n$x$ 的一个层级高斯先验由下式给出\n$$\nx \\mid \\tau \\sim \\mathcal{N}(0, \\tau^2 I_n),\n$$\n其中 $\\tau  0$ 是一个未知的尺度（标准差）参数。我们将比较 $\\tau$ 的两种超先验：\n\n1. $\\tau^2$ 的逆伽马超先验，其形状参数为 $a  1$，尺度参数为 $b  0$：\n$$\n\\tau^2 \\sim \\text{Inverse-Gamma}(a, b).\n$$\n2. $\\tau$ 的半柯西超先验，其尺度参数为 $s  0$：\n$$\n\\tau \\sim \\text{Half-Cauchy}(s).\n$$\n\n我们将通过比较两种超先验下的后验推断，进行先验预测检查和敏感性分析。分析必须从第一性原理开始：高斯似然的定义、层级先验以及边缘化法则。\n\n将使用的基本定义：\n- 高斯密度 $\\mathcal{N}(m, \\Sigma)$ 的密度函数为\n$$\np(z) = \\frac{1}{(2\\pi)^{k/2} \\det(\\Sigma)^{1/2}} \\exp\\left( -\\frac{1}{2} (z - m)^\\top \\Sigma^{-1} (z - m) \\right),\n$$\n对于 $z \\in \\mathbb{R}^k$。\n- 全概率定律和条件期望：\n$$\np(y) = \\int p(y \\mid \\tau) p(\\tau) \\, d\\tau, \\quad \\mathbb{E}[x \\mid y] = \\int \\mathbb{E}[x \\mid y, \\tau] \\, p(\\tau \\mid y) \\, d\\tau.\n$$\n\n任务：\n1. 在层级高斯先验和高斯似然下，推导边缘似然 $p(y \\mid \\tau)$，用 $A$, $y$, $\\sigma^2$, 和 $\\tau$ 表示。\n2. 推导条件后验 $x \\mid y, \\tau$，并用 $A$, $y$, $\\sigma^2$, 和 $\\tau$ 识别其均值向量和协方差矩阵。\n3. 对每种超先验，定义其超先验密度 $p(\\tau)$，确保对施加于 $\\tau^2$ 的逆伽马先验进行正确的变换。\n4. 对每种超先验，计算以下后验推断：\n   - 通过对超先验积分得到的 $x$ 的后验均值\n     $$\n     \\mathbb{E}[x \\mid y] = \\frac{\\int \\mathbb{E}[x \\mid y, \\tau] \\, p(y \\mid \\tau) \\, p(\\tau) \\, d\\tau}{\\int p(y \\mid \\tau) \\, p(\\tau) \\, d\\tau}.\n     $$\n   - 通过对超先验积分得到的 $x$ 的协方差的后验期望迹\n     $$\n     \\mathbb{E}[\\operatorname{tr}(\\operatorname{Cov}[x \\mid y, \\tau]) \\mid y] = \\frac{\\int \\operatorname{tr}(\\operatorname{Cov}[x \\mid y, \\tau]) \\, p(y \\mid \\tau) \\, p(\\tau) \\, d\\tau}{\\int p(y \\mid \\tau) \\, p(\\tau) \\, d\\tau}.\n     $$\n   - 在超先验下，数据的先验预测边缘密度 $p(y)$\n     $$\n     p(y) = \\int p(y \\mid \\tau) \\, p(\\tau) \\, d\\tau.\n     $$\n5. 使用以上结果，通过计算两种超先验下获得的后验均值之差的欧几里得范数，以及两种超先验下协方差的后验期望迹之差，进行敏感性分析。同时，报告每种超先验下的对数先验预测边缘密度 $\\log p(y)$。\n\n您必须以数值方式实现上述计算。第4项和第5项中关于 $\\tau$ 的积分必须通过在 $\\tau \\in (0, \\infty)$ 上的一维数值积分来计算，使用对高斯似然和超先验密度的稳定求值方法。对于逆伽马超先验，使用 $a = 2.5$ 和 $b = 1.0$。对于半柯西超先验，使用 $s = 1.0$。\n\n测试套件：\n在以下三个测试用例上评估您的程序。不涉及物理单位；所有量纲均为无量纲。\n\n- 测试用例1（良态，中等噪声）：\n  - $m = 3$, $n = 2$,\n  - $A = \\begin{bmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\end{bmatrix}$,\n  - $y = \\begin{bmatrix} 1.2 \\\\ -0.3 \\\\ 0.7 \\end{bmatrix}$,\n  - $\\sigma = 0.5$.\n\n- 测试用例2（秩亏正演模型，先验主导）：\n  - $m = 3$, $n = 2$,\n  - $A = \\begin{bmatrix} 0  0 \\\\ 0  0 \\\\ 0  0 \\end{bmatrix}$,\n  - $y = \\begin{bmatrix} 0.1 \\\\ -0.2 \\\\ 0.05 \\end{bmatrix}$,\n  - $\\sigma = 0.5$.\n\n- 测试用例3（单位正演模型，低噪声，数据主导）：\n  - $m = 2$, $n = 2$,\n  - $A = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$,\n  - $y = \\begin{bmatrix} 3.0 \\\\ -2.0 \\end{bmatrix}$,\n  - $\\sigma = 0.1$.\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果必须是一个包含四个浮点数的列表，顺序如下\n$$\n\\left[\\lVert \\mathbb{E}_{\\text{IG}}[x \\mid y] - \\mathbb{E}_{\\text{HC}}[x \\mid y] \\rVert_2, \\ \\mathbb{E}_{\\text{IG}}[\\operatorname{tr}(\\operatorname{Cov}[x \\mid y, \\tau]) \\mid y] - \\mathbb{E}_{\\text{HC}}[\\operatorname{tr}(\\operatorname{Cov}[x \\mid y, \\tau]) \\mid y], \\ \\log p_{\\text{IG}}(y), \\ \\log p_{\\text{HC}}(y) \\right],\n$$\n其中下标 $\\text{IG}$ 和 $\\text{HC}$ 分别表示逆伽马和半柯西超先验。因此，整个输出必须是一个包含三个此类列表的列表，每个测试用例一个，例如：\n$$\n\\big[ [r_{11}, r_{12}, r_{13}, r_{14}], [r_{21}, r_{22}, r_{23}, r_{24}], [r_{31}, r_{32}, r_{33}, r_{34}] \\big].\n$$",
            "solution": "该问题要求对一个具有层级高斯先验的线性逆问题进行全面的贝叶斯分析。该分析涉及比较先验尺度参数 $\\tau$ 的两种不同超先验。我们将首先推导出条件似然和后验的必要解析表达式，然后详细说明对超参数 $\\tau$ 进行边缘化以获得最终后验推断的数值策略。\n\n模型设置如下：\n- 似然：$p(y \\mid x) = \\mathcal{N}(y; Ax, \\sigma^2 I_m)$，其中 $y \\in \\mathbb{R}^m$ 是数据，$x \\in \\mathbb{R}^n$ 是参数，$A \\in \\mathbb{R}^{m \\times n}$ 是正演算子，$\\sigma^2  0$ 是已知的噪声方差。\n- 先验：$p(x \\mid \\tau) = \\mathcal{N}(x; 0, \\tau^2 I_n)$，其中 $\\tau  0$ 是一个超参数。\n- 超先验 $p(\\tau)$：考虑两种情况，$\\tau^2$ 上的逆伽马分布和 $\\tau$ 上的半柯西分布。\n\n我们的目标是通过对超参数 $\\tau$ 进行边缘化，计算并比较在这两种超先验选择下 $x$ 的后验统计量。\n\n1. 边缘似然 $p(y \\mid \\tau)$ 的推导\n\n给定超参数 $\\tau$ 的数据 $y$ 的边缘似然，记为 $p(y \\mid \\tau)$，是通过对 $y$ 和 $x$ 的联合概率在 $x$ 的所有可能值上积分得到的：\n$$\np(y \\mid \\tau) = \\int_{\\mathbb{R}^n} p(y \\mid x) p(x \\mid \\tau) \\, dx.\n$$\n这是两个高斯分布的标准卷积。由于模型是线性的且分布是高斯分布，因此 $y$ 的最终边缘分布也是高斯的。我们可以通过计算其均值和协方差来确定其参数。\n\n给定 $\\tau$ 时 $y$ 的均值为：\n$$\n\\mathbb{E}[y \\mid \\tau] = \\mathbb{E}[Ax + \\varepsilon \\mid \\tau] = A \\mathbb{E}[x \\mid \\tau] + \\mathbb{E}[\\varepsilon] = A \\cdot 0 + 0 = 0.\n$$\n给定 $\\tau$ 时 $y$ 的协方差，利用 $x$ 和 $\\varepsilon$ 的独立性，为：\n$$\n\\operatorname{Cov}(y \\mid \\tau) = \\operatorname{Cov}(Ax + \\varepsilon \\mid \\tau) = \\operatorname{Cov}(Ax \\mid \\tau) + \\operatorname{Cov}(\\varepsilon \\mid \\tau) = A \\operatorname{Cov}(x \\mid \\tau) A^\\top + \\sigma^2 I_m.\n$$\n由于 $\\operatorname{Cov}(x \\mid \\tau) = \\tau^2 I_n$，协方差变为：\n$$\n\\Sigma_{y \\mid \\tau} = \\tau^2 A A^\\top + \\sigma^2 I_m.\n$$\n因此，边缘似然是一个多元高斯分布的似然：\n$$\np(y \\mid \\tau) = \\mathcal{N}(y; 0, \\Sigma_{y \\mid \\tau}) = \\frac{1}{(2\\pi)^{m/2} \\det(\\Sigma_{y \\mid \\tau})^{1/2}} \\exp\\left( -\\frac{1}{2} y^\\top \\Sigma_{y \\mid \\tau}^{-1} y \\right).\n$$\n\n2. 条件后验 $p(x \\mid y, \\tau)$ 的推导\n\n使用贝叶斯定理，以数据 $y$ 和超参数 $\\tau$ 为条件的 $x$ 的后验分布为：\n$$\np(x \\mid y, \\tau) \\propto p(y \\mid x, \\tau) p(x \\mid \\tau) = p(y \\mid x) p(x \\mid \\tau).\n$$\n对数后验与对数似然和对数先验之和成正比：\n$$\n\\log p(x \\mid y, \\tau) \\propto -\\frac{1}{2\\sigma^2} \\|y - Ax\\|_2^2 - \\frac{1}{2\\tau^2} \\|x\\|_2^2.\n$$\n展开二次型，我们得到：\n$$\n\\log p(x \\mid y, \\tau) \\propto -\\frac{1}{2} \\left( \\frac{1}{\\sigma^2}(y^\\top y - 2y^\\top Ax + x^\\top A^\\top A x) + \\frac{1}{\\tau^2} x^\\top x \\right).\n$$\n收集包含 $x$ 的项：\n$$\n\\log p(x \\mid y, \\tau) \\propto -\\frac{1}{2} \\left( x^\\top \\left( \\frac{1}{\\sigma^2} A^\\top A + \\frac{1}{\\tau^2} I_n \\right) x - 2 \\frac{1}{\\sigma^2} y^\\top A x \\right).\n$$\n这是 $x$ 的一个二次函数，这意味着后验 $p(x \\mid y, \\tau)$ 是一个高斯分布 $\\mathcal{N}(\\mu_{x \\mid \\tau}, \\Sigma_{x \\mid \\tau})$。从上面的表达式中，我们可以确定后验精度（逆协方差）矩阵为：\n$$\n\\Sigma_{x \\mid \\tau}^{-1} = \\frac{1}{\\sigma^2} A^\\top A + \\frac{1}{\\tau^2} I_n.\n$$\n后验协方差矩阵是其逆矩阵：\n$$\n\\Sigma_{x \\mid \\tau} = \\operatorname{Cov}[x \\mid y, \\tau] = \\left( \\frac{1}{\\sigma^2} A^\\top A + \\frac{1}{\\tau^2} I_n \\right)^{-1}.\n$$\n后验均值 $\\mu_{x \\mid \\tau} = \\mathbb{E}[x \\mid y, \\tau]$ 满足 $\\Sigma_{x \\mid \\tau}^{-1} \\mu_{x \\mid \\tau} = \\frac{1}{\\sigma^2} A^\\top y$。因此，\n$$\n\\mu_{x \\mid \\tau} = \\left( \\frac{1}{\\sigma^2} A^\\top A + \\frac{1}{\\tau^2} I_n \\right)^{-1} \\frac{1}{\\sigma^2} A^\\top y.\n$$\n\n3. 超先验密度 $p(\\tau)$\n\n我们被给予了 $\\tau  0$ 的两种超先验。\n\na) $\\tau^2$ 的逆伽马分布：超先验被指定为 $\\tau^2 \\sim \\text{Inverse-Gamma}(a, b)$，形状参数为 $a=2.5$，尺度参数为 $b=1.0$。对于变量 $\\lambda \\sim \\text{Inverse-Gamma}(a, b)$，其概率密度函数为 $p(\\lambda) = \\frac{b^a}{\\Gamma(a)} \\lambda^{-(a+1)} e^{-b/\\lambda}$。为了找到 $\\tau$ 的密度，我们使用变量替换公式。令 $\\lambda = \\tau^2$，则 $\\frac{d\\lambda}{d\\tau} = 2\\tau$。对于 $\\tau  0$：\n$$\np_{\\text{IG}}(\\tau) = p_{\\lambda}(\\tau^2) \\left| \\frac{d\\lambda}{d\\tau} \\right| = \\frac{b^a}{\\Gamma(a)} (\\tau^2)^{-(a+1)} e^{-b/\\tau^2} \\cdot (2\\tau) = \\frac{2b^a}{\\Gamma(a)} \\tau^{-2a-1} e^{-b/\\tau^2}.\n$$\n\nb) $\\tau$ 的半柯西分布：超先验为 $\\tau \\sim \\text{Half-Cauchy}(s)$，尺度参数为 $s=1.0$。这是一个位置参数为0、尺度参数为s的柯西分布，截断到区间 $(0, \\infty)$ 并重新归一化。其密度为：\n$$\np_{\\text{HC}}(\\tau) = \\frac{2}{\\pi s(1 + (\\tau/s)^2)}.\n$$\n\n4. 后验推断的数值计算\n\n最终目标是通过对 $\\tau$ 进行边缘化来计算 $x$ 的后验量。$\\tau$ 的后验由 $p(\\tau \\mid y) \\propto p(y \\mid \\tau) p(\\tau)$ 给出。所需的量通过以下积分计算：\n- 先验预测边缘密度：$p(y) = \\int_0^\\infty p(y \\mid \\tau) p(\\tau) \\, d\\tau$。\n- $x$ 的后验均值：$\\mathbb{E}[x \\mid y] = \\int_0^\\infty \\mathbb{E}[x \\mid y, \\tau] p(\\tau \\mid y) \\, d\\tau = \\frac{\\int_0^\\infty \\mu_{x \\mid \\tau} p(y \\mid \\tau) p(\\tau) \\, d\\tau}{p(y)}$。\n- 协方差的后验期望迹：$\\mathbb{E}[\\operatorname{tr}(\\operatorname{Cov}[x \\mid y, \\tau]) \\mid y] = \\frac{\\int_0^\\infty \\operatorname{tr}(\\Sigma_{x \\mid \\tau}) p(y \\mid \\tau) p(\\tau) \\, d\\tau}{p(y)}$。\n\n这些在 $\\tau \\in (0, \\infty)$ 上的一维积分使用数值积分计算。为确保数值稳定性，特别是考虑到被积函数 $p(y \\mid \\tau) p(\\tau)$ 可能具有非常大的动态范围，我们使用对数进行计算。令 $L(\\tau) = \\log p(y \\mid \\tau) + \\log p(\\tau)$。被积函数的形式为 $f(\\tau) e^{L(\\tau)}$，其中 $f(\\tau)$ 是 $1$、$\\mu_{x \\mid \\tau}$ 或 $\\operatorname{tr}(\\Sigma_{x \\mid \\tau})$。\n\n数值积分策略如下：\ni. 定义 $\\tau$ 的未归一化对数后验 $L(\\tau)$。\nii. 找到使 $L(\\tau)$ 最大化的值 $\\tau_{\\text{max}}$。这是 $\\tau$ 的最大后验（MAP）估计。令 $L_{\\text{max}} = L(\\tau_{\\text{max}})$。\niii. 通过提出峰值来重写积分。例如，$p(y) = \\int_0^\\infty e^{L(\\tau)} \\, d\\tau = e^{L_{\\text{max}}} \\int_0^\\infty e^{L(\\tau) - L_{\\text{max}}} \\, d\\tau$。现在被积函数 $e^{L(\\tau) - L_{\\text{max}}}$ 的性态良好，其最大值为1。\niv. 使用数值积分例程（例如 `scipy.integrate.quad` 或 `scipy.integrate.quad_vec`）来计算归一化后的积分。\nv. 组合结果以获得最终的量。例如，$\\log p(y) = L_{\\text{max}} + \\log\\left(\\int_0^\\infty e^{L(\\tau) - L_{\\text{max}}} \\, d\\tau\\right)$。对于像 $\\mathbb{E}[x \\mid y]$ 这样的比率，项 $e^{L_{\\text{max}}}$ 会消掉，从而将计算简化为积分之比。\n\n此过程应用于每种超先验（IG 和 HC）。最后一步是根据问题陈述中对敏感性分析的要求，计算差异和对数密度。对于测试用例2，其中 $A=0$，数据不提供关于 $x$ 的任何信息，且 $p(y \\mid \\tau)$ 变得与 $\\tau$ 无关。因此，$\\tau$ 的后验就是其先验，$p(\\tau \\mid y) = p(\\tau)$。后验期望随之成为先验期望。在这种情况下，具有无限二阶矩 $\\mathbb{E}[\\tau^2]$ 的重尾半柯西先验会导致 $x$ 的后验方差为无穷大，数值积分应该能捕捉到这一结果。",
            "answer": "```python\nimport numpy as np\nfrom scipy.integrate import quad, quad_vec\nfrom scipy.optimize import minimize_scalar\nfrom scipy.special import gammaln\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian hierarchical inverse problem for three test cases\n    and compares results from Inverse-Gamma and Half-Cauchy hyperpriors.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"m\": 3, \"n\": 2,\n            \"A\": np.array([[1, 0], [0, 1], [1, 1]]),\n            \"y\": np.array([1.2, -0.3, 0.7]),\n            \"sigma\": 0.5,\n        },\n        {\n            \"m\": 3, \"n\": 2,\n            \"A\": np.array([[0, 0], [0, 0], [0, 0]]),\n            \"y\": np.array([0.1, -0.2, 0.05]),\n            \"sigma\": 0.5,\n        },\n        {\n            \"m\": 2, \"n\": 2,\n            \"A\": np.array([[1, 0], [0, 1]]),\n            \"y\": np.array([3.0, -2.0]),\n            \"sigma\": 0.1,\n        },\n    ]\n\n    all_results = []\n    \n    # Hyperprior parameters\n    ig_params = {\"a\": 2.5, \"b\": 1.0}\n    hc_params = {\"s\": 1.0}\n\n    for case in test_cases:\n        A, y, sigma = case[\"A\"], case[\"y\"], case[\"sigma\"]\n        m, n = case[\"m\"], case[\"n\"]\n        sigma_sq = sigma**2\n        \n        AtA = A.T @ A\n        AAt = A @ A.T\n        Aty = A.T @ y\n\n        # --- Helper functions for conditional quantities ---\n        def get_E_x_given_y_tau(tau, sigma_sq, AtA, Aty):\n            if tau == 0: return np.zeros_like(Aty)\n            tau_sq = tau**2\n            prec_x = (1 / sigma_sq) * AtA + (1 / tau_sq) * np.identity(n)\n            rhs = (1 / sigma_sq) * Aty\n            try:\n                mu_x = np.linalg.solve(prec_x, rhs)\n            except np.linalg.LinAlgError:\n                mu_x = np.linalg.pinv(prec_x) @ rhs\n            return mu_x\n\n        def get_tr_Cov_x_given_y_tau(tau, sigma_sq, AtA):\n            if tau == 0: return 0.0\n            tau_sq = tau**2\n            prec_x = (1 / sigma_sq) * AtA + (1 / tau_sq) * np.identity(n)\n            try:\n                cov_x = np.linalg.inv(prec_x)\n            except np.linalg.LinAlgError:\n                cov_x = np.linalg.pinv(prec_x)\n            return np.trace(cov_x)\n\n        def get_log_p_y_given_tau(tau, y, sigma_sq, AAt):\n            tau_sq = tau**2\n            cov_y = tau_sq * AAt + sigma_sq * np.identity(m)\n            try:\n                sign, log_det_cov_y = np.linalg.slogdet(cov_y)\n                if sign = 0: return -np.inf\n                chol = np.linalg.cholesky(cov_y)\n                y_inv_cov_y = np.linalg.solve(chol.T, np.linalg.solve(chol, y))\n                quad_form = y @ y_inv_cov_y\n            except np.linalg.LinAlgError:\n                return -np.inf\n            \n            log_p = -0.5 * m * np.log(2 * np.pi) - 0.5 * log_det_cov_y - 0.5 * quad_form\n            return log_p\n\n        # --- Hyperprior log-densities ---\n        def log_p_tau_ig(tau, a, b):\n            if tau = 0: return -np.inf\n            return np.log(2) + a * np.log(b) - gammaln(a) - (2 * a + 1) * np.log(tau) - b / (tau**2)\n\n        def log_p_tau_hc(tau, s):\n            if tau = 0: return -np.inf\n            return np.log(2) - np.log(np.pi) - np.log(s) - np.log(1 + (tau / s)**2)\n\n        def compute_posterior_quantities(hyperprior_type, params):\n            if hyperprior_type == 'IG':\n                log_p_tau = lambda t: log_p_tau_ig(t, **params)\n            else: # HC\n                log_p_tau = lambda t: log_p_tau_hc(t, **params)\n\n            log_joint_unnorm = lambda t: get_log_p_y_given_tau(t, y, sigma_sq, AAt) + log_p_tau(t)\n            \n            # Find MAP of tau to stabilize integration\n            res = minimize_scalar(lambda t: -log_joint_unnorm(t), bounds=(1e-9, 1e6), method='bounded')\n            tau_max = res.x\n            max_log_val = log_joint_unnorm(tau_max)\n            \n            if not np.isfinite(max_log_val):\n                 # This can happen if the posterior is improper or flat, like A=0 case\n                 # Pick an arbitrary reference point\n                 tau_max = 1.0\n                 max_log_val = log_joint_unnorm(tau_max)\n\n\n            # Integrands for numerical quadrature\n            integrand_Z  = lambda t: np.exp(log_joint_unnorm(t) - max_log_val)\n            integrand_Nx = lambda t: get_E_x_given_y_tau(t, sigma_sq, AtA, Aty) * integrand_Z(t)\n            integrand_Ntr = lambda t: get_tr_Cov_x_given_y_tau(t, sigma_sq, AtA) * integrand_Z(t)\n\n            # Perform integration\n            integral_Z, _ = quad(integrand_Z, 0, np.inf, limit=200)\n            integral_Nx, _ = quad_vec(integrand_Nx, 0, np.inf, limit=200)\n            integral_Ntr, _ = quad(integrand_Ntr, 0, np.inf, limit=200)\n\n            # Compute final quantities\n            E_x = integral_Nx / integral_Z\n            E_tr_Cov = integral_Ntr / integral_Z\n            log_p_y = max_log_val + np.log(integral_Z)\n\n            return E_x, E_tr_Cov, log_p_y\n            \n        # Calculate for both hyperpriors\n        E_x_ig, E_tr_Cov_ig, log_p_y_ig = compute_posterior_quantities('IG', ig_params)\n        E_x_hc, E_tr_Cov_hc, log_p_y_hc = compute_posterior_quantities('HC', hc_params)\n        \n        # Compute sensitivity metrics\n        norm_diff_mean = np.linalg.norm(E_x_ig - E_x_hc)\n        diff_trace_cov = E_tr_Cov_ig - E_tr_Cov_hc\n        \n        case_results = [norm_diff_mean, diff_trace_cov, log_p_y_ig, log_p_y_hc]\n        all_results.append(case_results)\n\n    # Format output\n    result_str = \", \".join(\n        f\"[{', '.join(f'{val:.10f}' for val in res)}]\" for res in all_results\n    )\n    print(f\"[{result_str}]\")\n\n\nif __name__ == '__main__':\n    solve()\n\n```"
        }
    ]
}