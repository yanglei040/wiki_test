{
    "hands_on_practices": [
        {
            "introduction": "要解决由偏微分方程（PDE）控制的反问题，我们首先需要一种在现代泛函分析框架下处理这些方程的方法。本练习将指导您完成两个基本步骤：推导 PDE 的弱（或变分）形式，然后使用强大的伴随状态法计算数据同化代价泛函的梯度。掌握这一过程对于将基于梯度的优化方法应用于广大的科学和工程问题至关重要。",
            "id": "3383674",
            "problem": "设 $\\Omega \\subset \\mathbb{R}^{d}$ 是一个有界 Lipschitz 域，其边界为 $\\partial \\Omega$。考虑在 $\\Omega$ 中的偏微分方程 (PDE) $-\\Delta u = f$，带有齐次 Dirichlet 边界条件 $u|_{\\partial \\Omega} = 0$，其中 $f \\in L^{2}(\\Omega)$。\n\n任务 1 (弱形式)：从 Sobolev 空间 $H_{0}^{1}(\\Omega)$ 的核心定义和 Gauss-Green 恒等式出发，通过将 PDE 乘以一个测试函数 $v \\in H_{0}^{1}(\\Omega)$ 并进行分部积分来推导弱形式。明确定义弱形式中出现的双线性形式 $a(u,v)$ 和线性泛函 $\\ell(v)$，确保严格陈述所有函数的空间归属。\n\n任务 2 (数据同化泛函和梯度)：定义观测算子 $C : H_{0}^{1}(\\Omega) \\to \\mathbb{R}^{m}$ 为\n$$\nC(u)_{k} = \\int_{\\Omega} u(x)\\,\\phi_{k}(x)\\,\\mathrm{d}x,\\quad k=1,\\dots,m,\n$$\n其中 $\\phi_{k} \\in L^{2}(\\Omega)$ 是给定的基函数，并假设 $d = (d_{1},\\dots,d_{m}) \\in \\mathbb{R}^{m}$ 是给定的数据。对于一个固定的正则化参数 $\\lambda  0$，定义最小二乘数据同化目标\n$$\nJ(f) = \\frac{1}{2}\\sum_{k=1}^{m}\\left(C(u(f))_{k} - d_{k}\\right)^{2} + \\frac{\\lambda}{2}\\,\\|f\\|_{L^{2}(\\Omega)}^{2},\n$$\n其中 $u(f) \\in H_{0}^{1}(\\Omega)$ 表示通过任务 1 与源 $f \\in L^{2}(\\Omega)$ 相关联的唯一弱解。推导 $J$ 在一个一般 $f$ 处的 $L^{2}(\\Omega)$-梯度，该梯度仅用 $f$、状态 $u(f)$ 以及一个伴随状态 $p \\in H_{0}^{1}(\\Omega)$ 来表示，你必须引入该伴随状态并通过一个弱形式来指定它。\n\n你的最终答案必须是 $J(f)$ 的 $L^{2}(\\Omega)$-梯度的一个单一闭式解析表达式，用 $f$ 和 $p$ 表示。无需四舍五入，也不涉及物理单位。",
            "solution": "该问题包含两个任务。第一个是为泊松问题推导弱形式。第二个是使用伴随方法推导数据同化目标泛函的梯度。我们将依次解决每个任务。\n\n**任务 1：弱形式**\n\n给定的偏微分方程 (PDE) 是带有齐次 Dirichlet 边界条件的泊松方程：\n$$\n-\\Delta u = f \\quad \\text{in } \\Omega\n$$\n$$\nu|_{\\partial \\Omega} = 0\n$$\n这里，$f$ 是一个源项，属于域 $\\Omega$ 上的平方可积函数空间 $L^{2}(\\Omega)$。解 $u$ 在 Sobolev 空间 $H_{0}^{1}(\\Omega)$ 中寻找。空间 $H_{0}^{1}(\\Omega)$ 是在 $\\Omega$ 中具有紧支集的无限可微函数空间 $C_{c}^{\\infty}(\\Omega)$ 在 $H^{1}$ 范数下的闭包。$H_{0}^{1}(\\Omega)$ 中的函数可以被认为是在广义（迹）意义下满足边界 $\\partial \\Omega$ 上的条件 $u=0$。\n\n为推导弱形式，我们将 PDE 乘以一个任意的测试函数 $v \\in H_{0}^{1}(\\Omega)$ 并在域 $\\Omega$ 上积分：\n$$\n\\int_{\\Omega} (-\\Delta u(x)) v(x) \\, \\mathrm{d}x = \\int_{\\Omega} f(x) v(x) \\, \\mathrm{d}x\n$$\n我们将 Gauss-Green 恒等式（一种分部积分形式）应用于左侧。对于域 $\\Omega$ 上具有边界 $\\partial\\Omega$ 和单位外法向量 $n$ 的足够光滑的函数 $u$ 和 $v$，该恒等式为：\n$$\n\\int_{\\Omega} (-\\Delta u) v \\, \\mathrm{d}x = \\int_{\\Omega} \\nabla u \\cdot \\nabla v \\, \\mathrm{d}x - \\int_{\\partial \\Omega} v (\\nabla u \\cdot n) \\, \\mathrm{d}S\n$$\n此恒等式可推广到 Sobolev 空间中的函数。由于测试函数 $v$ 属于 $H_{0}^{1}(\\Omega)$，其在边界 $\\partial \\Omega$ 上的迹为零，即 $v|_{\\partial \\Omega} = 0$。因此，边界积分为零：\n$$\n\\int_{\\partial \\Omega} v (\\nabla u \\cdot n) \\, \\mathrm{d}S = 0\n$$\n因此，我们得到弱形式：找到 $u \\in H_{0}^{1}(\\Omega)$，使得\n$$\n\\int_{\\Omega} \\nabla u(x) \\cdot \\nabla v(x) \\, \\mathrm{d}x = \\int_{\\Omega} f(x) v(x) \\, \\mathrm{d}x\n$$\n对所有测试函数 $v \\in H_{0}^{1}(\\Omega)$ 均成立。\n\n该方程具有一般形式 $a(u,v) = \\ell(v)$。双线性形式 $a(\\cdot, \\cdot)$ 和线性泛函 $\\ell(\\cdot)$ 定义如下：\n1.  双线性形式 $a: H_{0}^{1}(\\Omega) \\times H_{0}^{1}(\\Omega) \\to \\mathbb{R}$ 由下式给出：\n    $$\n    a(u,v) = \\int_{\\Omega} \\nabla u(x) \\cdot \\nabla v(x) \\, \\mathrm{d}x\n    $$\n2.  线性泛函 $\\ell: H_{0}^{1}(\\Omega) \\to \\mathbb{R}$ 由下式给出：\n    $$\n    \\ell(v) = \\int_{\\Omega} f(x) v(x) \\, \\mathrm{d}x\n    $$\n对于任意给定的 $f \\in L^2(\\Omega)$，解 $u \\in H_{0}^{1}(\\Omega)$ 的存在性和唯一性由 Lax-Milgram 定理保证，因为 $a(\\cdot,\\cdot)$ 在 $H_{0}^{1}(\\Omega)$ 上是连续且强制的，而 $\\ell(\\cdot)$ 在 $H_{0}^{1}(\\Omega)$ 上是连续线性泛函。\n\n**任务 2：数据同化泛函和梯度**\n\n待最小化的目标泛函由下式给出：\n$$\nJ(f) = \\frac{1}{2}\\sum_{k=1}^{m}\\left(C(u(f))_{k} - d_{k}\\right)^{2} + \\frac{\\lambda}{2}\\,\\|f\\|_{L^{2}(\\Omega)}^{2}\n$$\n其中 $u(f)$ 是对于给定源 $f \\in L^{2}(\\Omega)$ 的泊松问题的唯一弱解。我们寻求 $J(f)$ 的 $L^{2}(\\Omega)$-梯度，记为 $\\nabla_{f} J(f)$，它是 $L^{2}(\\Omega)$ 中的一个元素，由以下关系定义：\n$$\nDJ(f)[\\delta f] = \\langle \\nabla_{f} J(f), \\delta f \\rangle_{L^{2}(\\Omega)} = \\int_{\\Omega} (\\nabla_{f} J(f))(x) \\delta f(x) \\, \\mathrm{d}x\n$$\n对所有扰动 $\\delta f \\in L^{2}(\\Omega)$ 成立，其中 $DJ(f)[\\delta f]$ 是 $J$ 在 $f$ 处沿方向 $\\delta f$ 的 Gâteaux 导数。\n\nGâteaux 导数计算如下：\n$$\nDJ(f)[\\delta f] = \\lim_{\\epsilon \\to 0} \\frac{J(f + \\epsilon \\delta f) - J(f)}{\\epsilon} = \\frac{d}{d\\epsilon} \\left. J(f + \\epsilon \\delta f) \\right|_{\\epsilon=0}\n$$\n首先，我们分析状态 $u$ 对源 $f$ 的依赖性。由于弱形式的线性，映射 $f \\mapsto u(f)$ 是线性的。设 $u(f+\\epsilon\\delta f)$ 是对应于源 $f+\\epsilon\\delta f$ 的解。根据线性性质，$u(f+\\epsilon\\delta f) = u(f) + \\epsilon u(\\delta f)$。我们记 $\\delta u := u(\\delta f)$。函数 $\\delta u \\in H_{0}^{1}(\\Omega)$ 是以 $\\delta f$ 为源的 PDE 的唯一弱解，即它满足：\n$$\na(\\delta u, v) = \\int_{\\Omega} \\delta f(x) v(x) \\, \\mathrm{d}x \\quad \\forall v \\in H_{0}^{1}(\\Omega)\n$$\n现在我们计算 $J(f)$ 的导数。\n第一项（失配项）的导数是：\n$$\n\\frac{d}{d\\epsilon} \\left. \\left( \\frac{1}{2}\\sum_{k=1}^{m}\\left(C(u(f+\\epsilon\\delta f))_{k} - d_{k}\\right)^{2} \\right) \\right|_{\\epsilon=0}\n$$\n使用链式法则以及 $C$ 和 $u(f)$ 的线性性质：\n$$\n= \\sum_{k=1}^{m} \\left(C(u(f))_{k} - d_{k}\\right) \\left( \\frac{d}{d\\epsilon} \\left. C(u(f) + \\epsilon \\delta u)_{k} \\right|_{\\epsilon=0} \\right)\n$$\n$$\n= \\sum_{k=1}^{m} \\left(C(u(f))_{k} - d_{k}\\right) C(\\delta u)_{k}\n$$\n代入 $C(\\delta u)_k$ 的定义：\n$$\n= \\sum_{k=1}^{m} \\left(C(u(f))_{k} - d_{k}\\right) \\int_{\\Omega} \\delta u(x) \\phi_{k}(x) \\, \\mathrm{d}x\n$$\n$$\n= \\int_{\\Omega} \\delta u(x) \\left( \\sum_{k=1}^{m} (C(u(f))_{k} - d_{k}) \\phi_{k}(x) \\right) \\, \\mathrm{d}x\n$$\n第二项（正则化项）的导数是：\n$$\n\\frac{d}{d\\epsilon} \\left. \\left( \\frac{\\lambda}{2}\\,\\|f + \\epsilon \\delta f\\|_{L^{2}(\\Omega)}^{2} \\right) \\right|_{\\epsilon=0} = \\frac{\\lambda}{2} \\frac{d}{d\\epsilon} \\left. \\langle f + \\epsilon \\delta f, f + \\epsilon \\delta f \\rangle_{L^2} \\right|_{\\epsilon=0}\n$$\n$$\n= \\frac{\\lambda}{2} \\frac{d}{d\\epsilon} \\left. (\\|f\\|_{L^2}^2 + 2\\epsilon \\langle f, \\delta f \\rangle_{L^2} + \\epsilon^2 \\|\\delta f\\|_{L^2}^2) \\right|_{\\epsilon=0} = \\lambda \\langle f, \\delta f \\rangle_{L^{2}(\\Omega)} = \\lambda \\int_{\\Omega} f(x) \\delta f(x) \\, \\mathrm{d}x\n$$\n结合两项，Gâteaux 导数为：\n$$\nDJ(f)[\\delta f] = \\int_{\\Omega} \\delta u(x) \\left( \\sum_{k=1}^{m} (C(u(f))_{k} - d_{k}) \\phi_{k}(x) \\right) \\, \\mathrm{d}x + \\lambda \\int_{\\Omega} f(x) \\delta f(x) \\, \\mathrm{d}x\n$$\n这个表达式依赖于 $\\delta u$，而 $\\delta u$ 又依赖于 $\\delta f$。为了找到梯度，我们必须将 $DJ(f)[\\delta f]$ 表示为与 $\\delta f$ 的单个内积。这通过引入一个伴随状态 $p \\in H_{0}^{1}(\\Omega)$ 来实现。我们定义伴随问题以消除包含 $\\delta u$ 的项。设 $p \\in H_{0}^{1}(\\Omega)$ 是以下伴随方程的唯一弱解：\n$$\na(v,p) = \\int_{\\Omega} v(x) \\left( \\sum_{k=1}^{m} (C(u(f))_{k} - d_{k}) \\phi_{k}(x) \\right) \\, \\mathrm{d}x \\quad \\forall v \\in H_{0}^{1}(\\Omega)\n$$\n双线性形式 $a(\\cdot, \\cdot)$ 是对称的，即 $a(v,p) = a(p,v)$。伴随方程的强形式为在 $\\Omega$ 中 $-\\Delta p = \\sum_{k=1}^{m}(C(u(f))_k - d_k)\\phi_k$，并带有边界条件 $p|_{\\partial\\Omega}=0$。\n\n在伴随弱形式中选择测试函数 $v = \\delta u \\in H_{0}^{1}(\\Omega)$，我们得到：\n$$\na(\\delta u, p) = \\int_{\\Omega} \\delta u(x) \\left( \\sum_{k=1}^{m} (C(u(f))_{k} - d_{k}) \\phi_{k}(x) \\right) \\, \\mathrm{d}x\n$$\n这正是我们 $DJ(f)[\\delta f]$ 表达式中的第一项。所以，我们可以写成：\n$$\nDJ(f)[\\delta f] = a(\\delta u, p) + \\lambda \\langle f, \\delta f \\rangle_{L^{2}(\\Omega)}\n$$\n现在，我们使用 $\\delta u$ 的弱形式，即对所有 $v \\in H_{0}^{1}(\\Omega)$ 有 $a(\\delta u, v) = \\langle \\delta f, v \\rangle_{L^{2}(\\Omega)}$。在此形式中选择测试函数 $v=p \\in H_{0}^{1}(\\Omega)$ 得到：\n$$\na(\\delta u, p) = \\langle \\delta f, p \\rangle_{L^{2}(\\Omega)} = \\int_{\\Omega} \\delta f(x) p(x) \\, \\mathrm{d}x\n$$\n将此代回 $DJ(f)[\\delta f]$ 的表达式中：\n$$\nDJ(f)[\\delta f] = \\int_{\\Omega} p(x) \\delta f(x) \\, \\mathrm{d}x + \\lambda \\int_{\\Omega} f(x) \\delta f(x) \\, \\mathrm{d}x\n$$\n$$\nDJ(f)[\\delta f] = \\int_{\\Omega} (\\lambda f(x) + p(x)) \\delta f(x) \\, \\mathrm{d}x = \\langle \\lambda f + p, \\delta f \\rangle_{L^{2}(\\Omega)}\n$$\n根据 Riesz 表示定理（该定理定义了 Hilbert 空间中的梯度），我们可以将 $J$ 在 $f$ 处的 $L^2(\\Omega)$-梯度确定为与 $\\delta f$ 内积中的项。\n\n因此，$J(f)$ 的 $L^{2}(\\Omega)$-梯度是：\n$$\n\\nabla_{f} J(f) = \\lambda f + p\n$$\n其中 $p \\in H_{0}^{1}(\\Omega)$ 是由上述弱形式定义的伴随状态，它依赖于状态 $u(f)$ 和数据 $d$。",
            "answer": "$$\n\\boxed{\\lambda f + p}\n$$"
        },
        {
            "introduction": "在上一练习的基础上，我们现在探讨对未知参数选择不同的函数空间会如何影响优化过程。本练习揭示了一个深刻的原理：泛函的梯度不是一个绝对的量，它依赖于所选 Hilbert 空间的特定内积。这个练习的核心是向您展示，在不同的内积（例如 $L^2$ 和 $H^1$）下，同一个泛函的梯度有不同的表达式，而 Riesz 表示定理正是连接这些不同表示的桥梁。理解这一点使我们能够选择更“自然”的下降方向，从而显著加速收敛。",
            "id": "3383644",
            "problem": "考虑一个有界开区间域 $\\Omega = (0,\\pi)$，控制空间为具有齐次狄利克雷边界条件的索博列夫空间 $H^{1}_{0}(\\Omega)$。设状态 $u \\in H^{1}_{0}(\\Omega)$ 由一个带有源控制 $m \\in H^{1}_{0}(\\Omega)$ 的线性椭圆偏微分方程（PDE）确定：\n$$\n-\\frac{d^{2}u}{dx^{2}} + \\beta\\, u = m \\quad \\text{in } \\Omega, \\qquad u(0)=u(\\pi)=0,\n$$\n其中 $\\beta  0$ 是一个固定常数。观测算子为恒等算子，代价泛函为勒贝格 $L^{2}(\\Omega)$ 错配：\n$$\nJ(m) = \\frac{1}{2} \\int_{\\Omega} \\left(u(x) - d(x)\\right)^{2}\\, dx,\n$$\n其中给定数据为 $d \\in L^{2}(\\Omega)$。在反问题和数据同化的背景下，梯度是通过 Riesz 表示定理根据控制空间的几何结构来定义的。具体来说，$L^{2}(\\Omega)$ 内积由 $\\langle a,b \\rangle_{L^{2}}=\\int_{\\Omega} a\\,b\\,dx$ 给出，而 $H^{1}_{0}(\\Omega)$ 内积由 $\\langle a,b \\rangle_{H^{1}_{0}}=\\int_{\\Omega} \\nabla a \\cdot \\nabla b\\,dx$ 给出。\n\n从第一性原理出发——即 $J$ 的 Gâteaux 导数的定义、状态方程以及基于偏微分方程变分结构的伴随方法——推导关于 $L^{2}(\\Omega)$ 内积的伴随梯度，然后使用与 $H^{1}_{0}(\\Omega)$ 相关的 Riesz 映射来表示 $H^{1}_{0}(\\Omega)$ 几何中的梯度。请清楚地解释 Riesz 映射如何改变梯度的表达式以及在 $J$ 的迭代最小化过程中的相应下降方向。\n\n然后，对于特定选择 $d(x)=0$ 和 $m(x) = \\sin(x) + \\sin(2x)$，进行显式推导，并提供索博列夫 $H^{1}_{0}(\\Omega)$ 梯度 $\\nabla_{H^{1}} J(m)$ 作为 $x$ 和 $\\beta$ 的函数的最终解析表达式。\n\n你的最终答案必须是单个闭式解析表达式。无需四舍五入。",
            "solution": "我们首先推导代价泛函 $J(m)$ 关于控制变量 $m \\in H^{1}_{0}(\\Omega)$ 的梯度。推导过程分为三个主要阶段：首先，我们求出 $J(m)$ 的 Gâteaux 导数；其次，我们引入伴随状态将此导数表示为一个内积，从而得到 $L^{2}(\\Omega)$ 几何中的梯度；第三，我们使用 $H^{1}_{0}(\\Omega)$ 中的 Riesz 表示定理来求出索博列夫几何中的梯度。\n\n令 $u(m)$ 表示给定控制 $m$ 的状态方程的解。代价泛函为\n$$\nJ(m) = \\frac{1}{2} \\int_{\\Omega} (u(m)(x) - d(x))^{2}\\, dx\n$$\n\n**1. Gâteaux 导数**\n\n$J$ 在 $m$ 点沿方向 $h \\in H^{1}_{0}(\\Omega)$ 的 Gâteaux 导数定义为\n$$\nJ'(m; h) = \\lim_{\\epsilon \\to 0} \\frac{J(m+\\epsilon h) - J(m)}{\\epsilon}\n$$\n令 $u(m+\\epsilon h)$ 为对应于扰动控制 $m+\\epsilon h$ 的状态。状态方程是线性的，因此 $u(m+\\epsilon h) = u(m) + \\epsilon u_{h}$，其中 $u_h$ 是线性化状态方程的解：\n$$\n-\\frac{d^{2}u_{h}}{dx^{2}} + \\beta u_{h} = h \\quad \\text{in } \\Omega, \\qquad u_{h}(0)=u_{h}(\\pi)=0\n$$\n将此代入 Gâteaux 导数的定义中：\n\\begin{align*}\nJ(m+\\epsilon h) = \\frac{1}{2} \\int_{\\Omega} (u(m)(x) + \\epsilon u_{h}(x) - d(x))^{2}\\, dx \\\\\n= \\frac{1}{2} \\int_{\\Omega} \\left[ (u(m)(x) - d(x))^{2} + 2\\epsilon (u(m)(x) - d(x))u_{h}(x) + \\epsilon^{2} u_{h}(x)^{2} \\right] dx \\\\\n= J(m) + \\epsilon \\int_{\\Omega} (u(m)(x) - d(x))u_{h}(x)\\, dx + O(\\epsilon^{2})\n\\end{align*}\n因此，Gâteaux 导数为\n$$\nJ'(m; h) = \\int_{\\Omega} (u(m)(x) - d(x)) u_{h}(x)\\, dx\n$$\n\n**2. 伴随方法与 $L^{2}$ 梯度**\n\n$J'(m; h)$ 的表达式依赖于 $u_h$，而 $u_h$ 又通过一个微分方程依赖于 $h$。伴随方法提供了一种将该导数表示为与 $h$ 的直接内积的方式。我们引入一个伴随状态 $p \\in H^{1}_{0}(\\Omega)$，它是伴随方程的解。\n\n令 $\\mathcal{L} = -\\frac{d^{2}}{dx^{2}} + \\beta$ 为状态算子。扰动的状态方程为 $\\mathcal{L}u_{h} = h$。具有齐次狄利克雷边界条件的算子 $\\mathcal{L}$ 关于 $L^{2}(\\Omega)$ 内积是自伴的。也就是说，对于任何 $v,w \\in H^{1}_{0}(\\Omega)$，有 $\\langle \\mathcal{L}v, w \\rangle_{L^{2}} = \\langle v, \\mathcal{L}w \\rangle_{L^{2}}$。\n\n我们定义伴随状态 $p$ 为以下方程的解：\n$$\n\\mathcal{L}p = u(m) - d \\iff -\\frac{d^{2}p}{dx^{2}} + \\beta p = u(m) - d \\quad \\text{in } \\Omega, \\qquad p(0)=p(\\pi)=0\n$$\n现在，我们使用伴随状态重写 Gâteaux 导数：\n$$\nJ'(m; h) = \\int_{\\Omega} (u(m) - d) u_{h}\\, dx = \\int_{\\Omega} (\\mathcal{L}p) u_{h}\\, dx = \\langle \\mathcal{L}p, u_{h} \\rangle_{L^{2}}\n$$\n利用 $\\mathcal{L}$ 的自伴性：\n$$\nJ'(m; h) = \\langle p, \\mathcal{L}u_{h} \\rangle_{L^{2}} = \\int_{\\Omega} p (\\mathcal{L}u_{h})\\, dx\n$$\n由于 $\\mathcal{L}u_{h} = h$，我们有：\n$$\nJ'(m; h) = \\int_{\\Omega} p(x) h(x)\\, dx = \\langle p, h \\rangle_{L^{2}}\n$$\n根据 $L^{2}(\\Omega)$ 中的 Riesz 表示定理，关于 $L^{2}$ 内积的梯度就是伴随状态本身：\n$$\n\\nabla_{L^{2}} J(m) = p\n$$\n\n**3. Riesz 映射与 $H^{1}_{0}$ 梯度**\n\n我们现在寻求关于 $H^{1}_{0}(\\Omega)$ 内积的梯度，记为 $g = \\nabla_{H^{1}} J(m)$。根据定义，$g \\in H^{1}_{0}(\\Omega)$ 必须满足\n$$\nJ'(m; h) = \\langle g, h \\rangle_{H^{1}_{0}} \\quad \\forall h \\in H^{1}_{0}(\\Omega)\n$$\n其中 $\\langle g, h \\rangle_{H^{1}_{0}} = \\int_{\\Omega} \\nabla g \\cdot \\nabla h\\, dx = \\int_{0}^{\\pi} g'(x) h'(x)\\, dx$。\n令导数 $J'(m; h)$ 的两个表达式相等：\n$$\n\\langle g, h \\rangle_{H^{1}_{0}} = \\langle p, h \\rangle_{L^{2}} \\implies \\int_{0}^{\\pi} g'(x) h'(x)\\, dx = \\int_{0}^{\\pi} p(x) h(x)\\, dx\n$$\n这是关于 $g$ 的边值问题的弱形式。为了找到其强形式，我们对左侧进行分部积分：\n$$\n\\int_{0}^{\\pi} g'(x) h'(x)\\, dx = - \\int_{0}^{\\pi} g''(x) h(x)\\, dx + [g'(x)h(x)]_{0}^{\\pi}\n$$\n因为 $h \\in H^{1}_{0}(\\Omega)$，所以 $h(0) = h(\\pi) = 0$，边界项为零。该恒等式变为：\n$$\n\\int_{0}^{\\pi} (-g''(x)) h(x)\\, dx = \\int_{0}^{\\pi} p(x) h(x)\\, dx\n$$\n由于这对所有 $h \\in H^{1}_{0}(\\Omega)$ 均成立，根据变分法基本引理，被积函数必然相等：\n$$\n-g''(x) = p(x) \\quad \\text{in } \\Omega\n$$\n梯度 $g=\\nabla_{H^{1}} J(m)$ 必须在控制空间 $H^{1}_{0}(\\Omega)$ 中，因此它满足齐次狄利克雷边界条件，$g(0)=g(\\pi)=0$。\n\n从 $L^{2}$ 梯度 $p$ 到 $H^{1}_{0}$ 梯度 $g$ 的变换是一个 Riesz 映射。它涉及求解一个泊松方程，这是一个椭圆平滑算子。在迭代优化方案（$m_{k+1} = m_{k} - \\alpha_{k} \\nabla J(m_k)$）中，使用 $H^{1}_{0}$ 梯度 $g$ 而不是 $L^{2}$ 梯度 $p$ 构成了一种预处理形式。下降方向 $g$ 是 $p$ 的一个平滑版本，它惩罚高频振荡，并且通过采取更适应控制空间拓扑结构的步长，通常能显著加快收敛速度。\n\n**4. 针对特定情况的显式计算**\n\n给定 $d(x)=0$ 和 $m(x)=\\sin(x)+\\sin(2x)$。我们按步骤进行。\n\n首先，从 $-\\frac{d^{2}u}{dx^{2}} + \\beta u = \\sin(x)+\\sin(2x)$ 和 $u(0)=u(\\pi)=0$ 求解状态 $u(x)$。由于 $\\{\\sin(kx)\\}_{k=1}^\\infty$ 是 $-\\frac{d^2}{dx^2}$ 的特征函数，特征值为 $k^2$，我们假设解的形式为 $u(x) = c_1 \\sin(x) + c_2 \\sin(2x)$。\n$$\n(1^{2}c_1 \\sin(x) + 2^{2}c_2 \\sin(2x)) + \\beta (c_1 \\sin(x) + c_2 \\sin(2x)) = \\sin(x)+\\sin(2x)\n$$\n$$\n(1+\\beta)c_1 \\sin(x) + (4+\\beta)c_2 \\sin(2x) = \\sin(x)+\\sin(2x)\n$$\n匹配系数，我们得到 $c_1 = \\frac{1}{1+\\beta}$ 和 $c_2 = \\frac{1}{4+\\beta}$。因此，状态为：\n$$\nu(x) = \\frac{1}{1+\\beta}\\sin(x) + \\frac{1}{4+\\beta}\\sin(2x)\n$$\n其次，从 $-\\frac{d^{2}p}{dx^{2}} + \\beta p = u(x) - d(x) = u(x)$ 和 $p(0)=p(\\pi)=0$ 求解伴随状态 $p(x)$。\n$$\n-\\frac{d^{2}p}{dx^{2}} + \\beta p = \\frac{1}{1+\\beta}\\sin(x) + \\frac{1}{4+\\beta}\\sin(2x)\n$$\n再次假设解的形式为 $p(x) = p_1 \\sin(x) + p_2 \\sin(2x)$：\n$$\n(1+\\beta)p_1 \\sin(x) + (4+\\beta)p_2 \\sin(2x) = \\frac{1}{1+\\beta}\\sin(x) + \\frac{1}{4+\\beta}\\sin(2x)\n$$\n匹配系数，$p_1 = \\frac{1}{(1+\\beta)^{2}}$ 和 $p_2 = \\frac{1}{(4+\\beta)^{2}}$。伴随状态（即 $L^2$ 梯度）为：\n$$\np(x) = \\frac{1}{(1+\\beta)^{2}}\\sin(x) + \\frac{1}{(4+\\beta)^{2}}\\sin(2x)\n$$\n第三，从 $-g''(x) = p(x)$ 和 $g(0)=g(\\pi)=0$ 求解 $H^{1}_{0}$ 梯度 $g(x) = \\nabla_{H^{1}} J(m)$。\n$$\n-g''(x) = \\frac{1}{(1+\\beta)^{2}}\\sin(x) + \\frac{1}{(4+\\beta)^{2}}\\sin(2x)\n$$\n假设解的形式为 $g(x) = g_1 \\sin(x) + g_2 \\sin(2x)$：\n$$\n-(-(1)^{2}g_1 \\sin(x) - (2)^{2}g_2 \\sin(2x)) = g_1 \\sin(x) + 4 g_2 \\sin(2x)\n$$\n将其与 $p(x)$ 相等：\n$$\ng_1 \\sin(x) + 4g_2 \\sin(2x) = \\frac{1}{(1+\\beta)^{2}}\\sin(x) + \\frac{1}{(4+\\beta)^{2}}\\sin(2x)\n$$\n匹配系数，$g_1 = \\frac{1}{(1+\\beta)^{2}}$ 且 $4g_2 = \\frac{1}{(4+\\beta)^{2}}$，这意味着 $g_2 = \\frac{1}{4(4+\\beta)^{2}}$。\n$H^{1}_{0}$ 梯度的最终解析表达式为：\n$$\ng(x) = \\nabla_{H^{1}} J(m) = \\frac{1}{(1+\\beta)^{2}}\\sin(x) + \\frac{1}{4(4+\\beta)^{2}}\\sin(2x)\n$$",
            "answer": "$$\\boxed{\\frac{\\sin(x)}{(1+\\beta)^{2}} + \\frac{\\sin(2x)}{4(4+\\beta)^{2}}}$$"
        },
        {
            "introduction": "从理论走向实践，我们如何才能高效地求解反问题离散化后产生的大型线性系统？本练习展示了我们所发展的理论工具（如连接不同函数空间几何的 Riesz 映射）所具有的深刻数值意义。您将发现，Riesz 映射本身可以作为一个极其有效的预条件子。通过分析预处理后算子的谱，您将证明这种选择可以带来与网格尺寸无关的收敛速度，这是大规模计算中的一个关键特性。",
            "id": "3383675",
            "problem": "考虑一维有界域 $\\Omega=(0,1)$ 上的一个线性反问题，其未知量为 $u \\in H^{1}_{0}(\\Omega)$。给定数据 $y \\in L^{2}(\\Omega)$，观测算子 $C: H^{1}_{0}(\\Omega) \\to L^{2}(\\Omega)$ 为嵌入算子 $C u = u$，观测噪声协方差为 $\\Gamma = \\sigma^{2} I$（其中 $\\sigma0$），则带有二次 $H^{1}$ 先验的 Tikhonov 正则化最小二乘目标函数的正规方程为\n$$\n\\big(C^{*}\\Gamma^{-1} C + A\\big)u \\;=\\; C^{*}\\Gamma^{-1} y,\n$$\n其中正则化算子为 $A = \\alpha (I - \\Delta)$（$\\alpha0$），$\\Delta$ 是 $H^{1}_{0}(\\Omega)$ 上的拉普拉斯算子（狄利克雷边界条件）。算子 $R := I - \\Delta$ 是与 Sobolev 空间 $H^{1}_{0}(\\Omega)$ 相关联的 Riesz 映射，其意义在于，对于所有 $u,v \\in H^{1}_{0}(\\Omega)$，\n$$\n\\langle R u, v \\rangle_{H^{-1},H^{1}} \\;=\\; \\langle u, v \\rangle_{H^{1}} \\;=\\; \\int_{0}^{1} u v \\, dx \\;+\\; \\int_{0}^{1} u' v' \\, dx.\n$$\n我们旨在通过 Krylov 方法求解正规方程，并通过使用 $H^{1}$ Riesz 映射进行左预处理来加速收敛，即选择预处理器 $P := R = I - \\Delta$。分析此预处理器对预处理算子 $P^{-1}\\big(C^{*}\\Gamma^{-1} C + A\\big)$ 的谱效应，该算子作用于赋予了 $H^{1}$ 内积的 $H^{1}_{0}(\\Omega)$。\n\n仅使用关于 $(0,1)$ 上狄利克雷-拉普拉斯算子的基本性质（特别是其在 $L^{2}(\\Omega)$ 中的完备正交特征函数集，其特征值为 $\\{(k\\pi)^{2}\\}_{k\\in\\mathbb{N}}$）以及谱界的 Rayleigh-Ritz 特征，推导出预处理算子 $P^{-1}\\big(C^{*}\\Gamma^{-1} C + A\\big)$ 的谱条件数的最小一致上界（与离散化维度无关），该上界用 $\\alpha$ 和 $\\sigma$ 表示。将最终答案表述为仅含 $\\alpha$ 和 $\\sigma$ 的单个闭式解析表达式。最终答案中不要包含不等式。",
            "solution": "目标是确定预处理算子 $S := P^{-1}\\big(C^{*}\\Gamma^{-1} C + A\\big)$ 的谱条件数，该算子作用于赋予了内积 $\\langle u, v \\rangle_{H^{1}} = \\int_{0}^{1} u v \\, dx + \\int_{0}^{1} u' v' \\, dx$ 的希尔伯特空间 $V := H^{1}_{0}(\\Omega)$。条件数定义为 $\\kappa(S) = \\frac{\\lambda_{\\max}(S)}{\\lambda_{\\min}(S)}$，其中 $\\lambda_{\\max}(S)$ 和 $\\lambda_{\\min}(S)$ 分别是 $S$ 的最大和最小特征值。\n\n算子 $S$ 定义在 $V=H^1_0(\\Omega)$ 上，其特征值 $\\lambda$ 是相对于 $H^1$ 内积确定的。一个特征值 $\\lambda$ 及其对应的特征向量 $v \\in V \\setminus \\{0\\}$ 满足方程 $S v = \\lambda v$。\n\n为分析谱，我们将特征值问题表述为其弱（双线性形式）表示。特征值方程 $S v = \\lambda v$ 等价于找到 $\\lambda$，使得对于所有 $w \\in V$：\n$$\n\\langle S v, w \\rangle_{H^{1}} = \\lambda \\langle v, w \\rangle_{H^{1}}\n$$\n我们来分析左侧。预处理器 $P = R = I - \\Delta$ 是与 $H^{1}$ 内积相关联的 Riesz 映射。这意味着对于任意 $u, w \\in V$，有 $\\langle u, w \\rangle_{H^{1}} = \\langle R u, w \\rangle_{H^{-1},H^{1}}$，其中 $\\langle \\cdot, \\cdot \\rangle_{H^{-1},H^{1}}$ 表示 $V$ 与其对偶空间 $V' = H^{-1}(\\Omega)$ 之间的对偶配对。\n逆预处理器 $P^{-1}=R^{-1}$ 是一个从 $V'$ 到 $V$ 的算子。对于任意泛函 $f \\in V'$，其作用定义为 $\\langle R(R^{-1}f), w \\rangle_{H^{-1},H^{1}} = \\langle f, w \\rangle_{H^{-1},H^{1}}$。\n将此应用于特征值方程的左侧，令 $f = (C^{*}\\Gamma^{-1} C + A)v \\in V'$，我们得到：\n$$\n\\langle S v, w \\rangle_{H^{1}} = \\langle P^{-1}\\big(C^{*}\\Gamma^{-1} C + A\\big)v, w \\rangle_{H^{1}} = \\langle R(P^{-1}\\big(C^{*}\\Gamma^{-1} C + A\\big)v), w \\rangle_{H^{-1},H^{1}} = \\langle \\big(C^{*}\\Gamma^{-1} C + A\\big)v, w \\rangle_{H^{-1},H^{1}}\n$$\n因此，特征值方程变为：\n$$\n\\langle \\big(C^{*}\\Gamma^{-1} C + A\\big)v, w \\rangle_{H^{-1},H^{1}} = \\lambda \\langle v, w \\rangle_{H^{1}}\n$$\n现在，我们展开左侧的双线性形式。\n包含正则化算子 $A = \\alpha (I - \\Delta) = \\alpha R$ 的项贡献为：\n$$\n\\langle A v, w \\rangle_{H^{-1},H^{1}} = \\langle \\alpha R v, w \\rangle_{H^{-1},H^{1}} = \\alpha \\langle v, w \\rangle_{H^{1}}\n$$\n包含数据保真项算子 $C^{*}\\Gamma^{-1} C$ 的项贡献为：\n$$\n\\langle C^{*}\\Gamma^{-1} C v, w \\rangle_{H^{-1},H^{1}} = \\langle \\Gamma^{-1} C v, C w \\rangle_{L^{2}}\n$$\n已知 $C$ 是嵌入 $u \\mapsto u$，$\\Gamma = \\sigma^{2} I$，且 $\\Gamma^{-1} = \\sigma^{-2} I$，这变为：\n$$\n\\langle \\sigma^{-2} v, w \\rangle_{L^{2}} = \\sigma^{-2} \\int_{0}^{1} v w \\, dx = \\sigma^{-2} (v, w)_{L^{2}}\n$$\n将这些代回特征值方程的弱形式，得到：\n$$\n\\sigma^{-2}(v, w)_{L^{2}} + \\alpha \\langle v, w \\rangle_{H^{1}} = \\lambda \\langle v, w \\rangle_{H^{1}}\n$$\n此式必须对所有 $w \\in V$ 成立。通过选择 $w=v$，我们得到与特征向量 $v$ 对应的特征值 $\\lambda$ 的瑞利商：\n$$\n\\sigma^{-2}\\|v\\|_{L^{2}}^{2} + \\alpha \\|v\\|_{H^{1}}^{2} = \\lambda \\|v\\|_{H^{1}}^{2}\n$$\n求解 $\\lambda$：\n$$\n\\lambda = \\alpha + \\sigma^{-2} \\frac{\\|v\\|_{L^{2}}^{2}}{\\|v\\|_{H^{1}}^{2}}\n$$\n算子 $S$ 关于 $H^1$ 内积是自伴的，因此其谱是此瑞利商在所有 $v \\in V \\setminus \\{0\\}$ 上取值的闭包。最小和最大特征值可以通过求商 $Q(v) := \\frac{\\|v\\|_{L^{2}}^{2}}{\\|v\\|_{H^{1}}^{2}}$ 的下确界和上确界来找到。\n$$\n\\lambda_{\\min} = \\alpha + \\sigma^{-2} \\inf_{v \\in V \\setminus \\{0\\}} Q(v)\n$$\n$$\n\\lambda_{\\max} = \\alpha + \\sigma^{-2} \\sup_{v \\in V \\setminus \\{0\\}} Q(v)\n$$\n我们来分析 $Q(v) = \\frac{\\|v\\|_{L^{2}}^{2}}{\\|v\\|_{H^{1}}^{2}} = \\frac{\\int_{0}^{1} v^{2} dx}{\\int_{0}^{1} v^{2} dx + \\int_{0}^{1} (v')^{2} dx}$。\n为了找到界，我们使用在 $\\Omega=(0,1)$ 上的狄利克雷-拉普拉斯算子 $-\\Delta$ 的特征函数，即 $\\psi_k(x) = c \\sin(k\\pi x)$（$k \\in \\mathbb{N}$），其对应的特征值为 $\\mu_k = (k\\pi)^{2}$。这些特征函数构成了 $H_0^1(\\Omega)$ 的一个完备基。\n任何 $v \\in H^1_0(\\Omega)$ 都可以用这个基展开。\n拉普拉斯算子的瑞利商 $R_L(v) = \\frac{\\|v'\\|_{L^2}^2}{\\|v\\|_{L^2}^2}$ 的谱由特征值 $\\{\\mu_k\\}_{k\\in\\mathbb{N}}$ 给出。其最小值是最小特征值 $\\mu_1 = \\pi^{2}$。这是庞加莱不等式 $\\|v'\\|_{L^2}^2 \\ge \\pi^{2} \\|v\\|_{L^2}^2$ 的结果。\n\n我们可以将 $Q(v)$ 重写为：\n$$\nQ(v) = \\frac{\\|v\\|_{L^{2}}^{2}}{\\|v\\|_{L^{2}}^{2} + \\|v'\\|_{L^{2}}^{2}} = \\frac{1}{1 + \\frac{\\|v'\\|_{L^{2}}^{2}}{\\|v\\|_{L^{2}}^{2}}} = \\frac{1}{1 + R_L(v)}\n$$\n为了找到 $Q(v)$ 的上确界，我们必须找到 $R_L(v)$ 的下确界。\n$$\n\\sup_{v \\in V \\setminus \\{0\\}} Q(v) = \\frac{1}{1 + \\inf_{v \\in V \\setminus \\{0\\}} R_L(v)} = \\frac{1}{1 + \\mu_1} = \\frac{1}{1 + \\pi^{2}}\n$$\n当 $v$ 是拉普拉斯算子的第一个特征函数，即 $v(x) \\propto \\sin(\\pi x)$ 时，达到这个上确界。\n\n为了找到 $Q(v)$ 的下确界，我们必须找到 $R_L(v)$ 的上确界。拉普拉斯算子的谱是无界的，即 $\\{\\mu_k = (k\\pi)^2 \\to \\infty \\text{ 当 } k \\to \\infty\\}$。\n$$\n\\inf_{v \\in V \\setminus \\{0\\}} Q(v) = \\lim_{k\\to\\infty} \\frac{1}{1+\\mu_k} = 0\n$$\n这个下确界在 $H^1_0(\\Omega)$ 中无法达到，但它是谱的极限点。\n\n现在，我们可以计算 $S$ 的极值特征值：\n$$\n\\lambda_{\\min} = \\alpha + \\sigma^{-2} \\cdot 0 = \\alpha\n$$\n$$\n\\lambda_{\\max} = \\alpha + \\sigma^{-2} \\frac{1}{1 + \\pi^{2}}\n$$\n谱条件数 $\\kappa(S)$ 是这些特征值的比值：\n$$\n\\kappa(S) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\frac{\\alpha + \\frac{1}{\\sigma^{2}(1 + \\pi^{2})}}{\\alpha} = 1 + \\frac{1}{\\alpha \\sigma^{2} (1 + \\pi^{2})}\n$$\n这是条件数的最小一致上界，与任何离散化无关。它仅用问题参数 $\\alpha$ 和 $\\sigma$ 以及基本常数 $\\pi$ 来表示。",
            "answer": "$$\\boxed{1 + \\frac{1}{\\alpha \\sigma^{2} (1+\\pi^{2})}}$$"
        }
    ]
}