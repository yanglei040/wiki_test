{
    "hands_on_practices": [
        {
            "introduction": "在深入研究复杂的数据同化方法之前，掌握线性高斯模型中贝叶斯更新的基本计算至关重要。本练习将指导您从第一性原理出发，通过配方法推导并计算后验均值和协方差矩阵。通过这个具体的数值算例，您将巩固对后验分布核心公式的理解，并练习验证协方差矩阵的关键数学性质。",
            "id": "3384489",
            "problem": "考虑一个线性-高斯数据同化框架下的线性逆问题。设未知参数向量为 $m \\in \\mathbb{R}^{2}$，其高斯先验为 $m \\sim \\mathcal{N}(m_{0}, C_{0})$，观测模型为 $y = G m + \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, \\Gamma)$ 且与 $m$ 独立。给定\n$$\nm_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\quad\nC_{0} = \\begin{pmatrix} 1.2  0 \\\\ 0  0.8 \\end{pmatrix}, \\quad\nG = \\begin{pmatrix} 1  -0.5 \\\\ 0.2  1.5 \\end{pmatrix}, \\quad\n\\Gamma = \\begin{pmatrix} 0.5  0.1 \\\\ 0.1  0.2 \\end{pmatrix}, \\quad\ny = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}.\n$$\n从贝叶斯定理和高斯密度的二次型出发，通过对负对数后验进行配方，推导后验分布 $m \\mid y \\sim \\mathcal{N}(m_{\\text{post}}, C_{\\text{post}})$。然后，使用给定的数值矩阵，显式计算 $m_{\\text{post}}$ 和 $C_{\\text{post}}$。验证 $C_{\\text{post}}$ 是对称和对称正定(SPD)的，例如通过检查其顺序主子式的正性。最后，报告标量\n$$\ns \\equiv \\ln\\!\\big(\\det(C_{\\text{post}})\\big).\n$$\n将您最终报告的 $s$ 值四舍五入至 $4$ 位有效数字。最终答案以无单位的纯数字表示。",
            "solution": "此问题已经过验证。\n\n### 步骤1：提取给定信息\n问题提供了以下信息：\n- 未知参数向量为 $m \\in \\mathbb{R}^{2}$。\n- $m$ 的先验分布是高斯分布：$m \\sim \\mathcal{N}(m_{0}, C_{0})$。\n- 观测模型是线性的：$y = G m + \\epsilon$。\n- 观测噪声 $\\epsilon$ 是高斯的，且与 $m$ 独立：$\\epsilon \\sim \\mathcal{N}(0, \\Gamma)$。\n- 矩阵和向量的具体数值为：\n$$\nm_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\quad\nC_{0} = \\begin{pmatrix} 1.2  0 \\\\ 0  0.8 \\end{pmatrix}, \\quad\nG = \\begin{pmatrix} 1  -0.5 \\\\ 0.2  1.5 \\end{pmatrix}, \\quad\n\\Gamma = \\begin{pmatrix} 0.5  0.1 \\\\ 0.1  0.2 \\end{pmatrix}, \\quad\ny = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}.\n$$\n- 任务是推导后验分布 $m \\mid y \\sim \\mathcal{N}(m_{\\text{post}}, C_{\\text{post}})$，计算 $m_{\\text{post}}$ 和 $C_{\\text{post}}$，验证 $C_{\\text{post}}$ 是对称正定(SPD)的，并计算标量 $s \\equiv \\ln(\\det(C_{\\text{post}}))$，将其四舍五入至 $4$ 位有效数字。\n\n### 步骤2：使用提取的给定信息进行验证\n- **科学依据：** 该问题是贝叶斯推断在线性高斯模型中的标准应用，是数据同化、逆问题和统计学中的一个基本课题。它牢固地建立在公认的数学和统计学原理之上。\n- **适定性：** 该问题是适定的。给定的协方差矩阵 $C_0$ 和 $\\Gamma$ 需要是对称正定的。$C_0$ 是一个对角线上元素为正（$1.2 > 0$, $0.8 > 0$）的对角矩阵，因此它是对称正定的（SPD）。对于 $\\Gamma$，其顺序主子式为 $M_1 = 0.5 > 0$ 和 $M_2 = \\det(\\Gamma) = (0.5)(0.2) - (0.1)^2 = 0.1 - 0.01 = 0.09 > 0$。因此，$\\Gamma$ 也是对称正定的。所有矩阵和向量的维度对于所定义的操作都是一致的。问题要求根据所提供的数据给出一个唯一的解。\n- **客观性：** 该问题以精确、客观的数学语言陈述，没有任何主观性或模糊性。\n- **完整性：** 解决了该问题所需的所有必要信息（$m_0, C_0, G, \\Gamma, y$）均已提供。\n\n### 步骤3：结论与行动\n该问题被认为是有效的，因为它具有科学依据、适定、客观且完整。我将继续提供完整解答。\n\n### 后验分布的推导\n根据贝叶斯定理，后验概率密度函数 (PDF) $p(m|y)$ 与似然 $p(y|m)$ 和先验 $p(m)$ 的乘积成正比：\n$$p(m|y) \\propto p(y|m) p(m)$$\n先验给定为 $m \\sim \\mathcal{N}(m_0, C_0)$，所以其 PDF 具有以下形式：\n$$p(m) \\propto \\exp\\left(-\\frac{1}{2}(m-m_0)^T C_0^{-1} (m-m_0)\\right)$$\n观测模型 $y = Gm + \\epsilon$ 及 $\\epsilon \\sim \\mathcal{N}(0, \\Gamma)$ 意味着给定 $m$ 时 $y$ 的条件分布是 $y|m \\sim \\mathcal{N}(Gm, \\Gamma)$。因此，似然函数为：\n$$p(y|m) \\propto \\exp\\left(-\\frac{1}{2}(y-Gm)^T \\Gamma^{-1} (y-Gm)\\right)$$\n结合这些，后验 PDF 为：\n$$p(m|y) \\propto \\exp\\left(-\\frac{1}{2}(y-Gm)^T \\Gamma^{-1} (y-Gm) - \\frac{1}{2}(m-m_0)^T C_0^{-1} (m-m_0)\\right)$$\n后验分布也是高斯的，所以其 PDF 的形式为 $p(m|y) \\propto \\exp\\left(-\\frac{1}{2}(m-m_{\\text{post}})^T C_{\\text{post}}^{-1} (m-m_{\\text{post}})\\right)$。负对数后验（不计加法常数）是二次型 $J(m)$：\n$$J(m) = \\frac{1}{2}(y-Gm)^T \\Gamma^{-1} (y-Gm) + \\frac{1}{2}(m-m_0)^T C_0^{-1} (m-m_0)$$\n我们展开 $J(m)$ 中的项，并收集关于 $m$ 的二次项和线性项：\n$$2J(m) = (y^T - m^T G^T) \\Gamma^{-1} (y - Gm) + (m^T - m_0^T) C_0^{-1} (m - m_0)$$\n$$2J(m) = y^T \\Gamma^{-1} y - y^T \\Gamma^{-1} Gm - m^T G^T \\Gamma^{-1} y + m^T G^T \\Gamma^{-1} Gm + m^T C_0^{-1} m - m^T C_0^{-1} m_0 - m_0^T C_0^{-1} m + m_0^T C_0^{-1} m_0$$\n注意到标量项 $y^T \\Gamma^{-1} Gm$ 和 $m^T C_0^{-1} m_0$ 等于其转置，并将各项分组：\n$$2J(m) = m^T (G^T \\Gamma^{-1} G + C_0^{-1}) m - 2 m^T (G^T \\Gamma^{-1} y + C_0^{-1} m_0) + \\text{常数}$$\n通过配方法，我们可以确定后验精度矩阵 $C_{\\text{post}}^{-1}$ 和后验均值 $m_{\\text{post}}$。与一般二次型 $ (m-m_{\\text{post}})^T C_{\\text{post}}^{-1} (m-m_{\\text{post}}) = m^T C_{\\text{post}}^{-1} m - 2m^T C_{\\text{post}}^{-1} m_{\\text{post}} + \\text{常数}$ 进行比较，我们发现：\n$$C_{\\text{post}}^{-1} = C_0^{-1} + G^T \\Gamma^{-1} G$$\n$$C_{\\text{post}}^{-1} m_{\\text{post}} = C_0^{-1} m_0 + G^T \\Gamma^{-1} y$$\n由此，我们得到后验协方差矩阵和均值向量：\n$$C_{\\text{post}} = (C_0^{-1} + G^T \\Gamma^{-1} G)^{-1}$$\n$$m_{\\text{post}} = C_{\\text{post}} (C_0^{-1} m_0 + G^T \\Gamma^{-1} y)$$\n\n### 数值计算\n给定：\n$m_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, $C_{0} = \\begin{pmatrix} 1.2  0 \\\\ 0  0.8 \\end{pmatrix}$, $G = \\begin{pmatrix} 1  -0.5 \\\\ 0.2  1.5 \\end{pmatrix}$, $\\Gamma = \\begin{pmatrix} 0.5  0.1 \\\\ 0.1  0.2 \\end{pmatrix}$, $y = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$。\n\n首先，我们计算逆矩阵 $C_0^{-1}$ 和 $\\Gamma^{-1}$：\n$$C_0^{-1} = \\begin{pmatrix} \\frac{1}{1.2}  0 \\\\ 0  \\frac{1}{0.8} \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{6}  0 \\\\ 0  \\frac{5}{4} \\end{pmatrix}$$\n$$\\det(\\Gamma) = (0.5)(0.2) - (0.1)^2 = 0.1 - 0.01 = 0.09 = \\frac{9}{100}$$\n$$\\Gamma^{-1} = \\frac{1}{0.09} \\begin{pmatrix} 0.2  -0.1 \\\\ -0.1  0.5 \\end{pmatrix} = \\frac{100}{9} \\begin{pmatrix} \\frac{2}{10}  -\\frac{1}{10} \\\\ -\\frac{1}{10}  \\frac{5}{10} \\end{pmatrix} = \\frac{10}{9} \\begin{pmatrix} 2  -1 \\\\ -1  5 \\end{pmatrix} = \\begin{pmatrix} \\frac{20}{9}  -\\frac{10}{9} \\\\ -\\frac{10}{9}  \\frac{50}{9} \\end{pmatrix}$$\n接下来，我们计算 Hessian 项 $G^T\\Gamma^{-1}G$：\n$$G^T = \\begin{pmatrix} 1  0.2 \\\\ -0.5  1.5 \\end{pmatrix} = \\begin{pmatrix} 1  \\frac{1}{5} \\\\ -\\frac{1}{2}  \\frac{3}{2} \\end{pmatrix}$$\n$$G^T \\Gamma^{-1} = \\begin{pmatrix} 1  \\frac{1}{5} \\\\ -\\frac{1}{2}  \\frac{3}{2} \\end{pmatrix} \\begin{pmatrix} \\frac{20}{9}  -\\frac{10}{9} \\\\ -\\frac{10}{9}  \\frac{50}{9} \\end{pmatrix} = \\begin{pmatrix} \\frac{20}{9} - \\frac{2}{9}  -\\frac{10}{9} + \\frac{10}{9} \\\\ -\\frac{10}{9} - \\frac{15}{9}  \\frac{5}{9} + \\frac{75}{9} \\end{pmatrix} = \\begin{pmatrix} \\frac{18}{9}  0 \\\\ -\\frac{25}{9}  \\frac{80}{9} \\end{pmatrix} = \\begin{pmatrix} 2  0 \\\\ -\\frac{25}{9}  \\frac{80}{9} \\end{pmatrix}$$\n$$G^T \\Gamma^{-1} G = \\begin{pmatrix} 2  0 \\\\ -\\frac{25}{9}  \\frac{80}{9} \\end{pmatrix} \\begin{pmatrix} 1  -\\frac{1}{2} \\\\ \\frac{1}{5}  \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} 2  -1 \\\\ -\\frac{25}{9} + \\frac{16}{9}  \\frac{25}{18} + \\frac{120}{9} \\end{pmatrix} = \\begin{pmatrix} 2  -1 \\\\ -\\frac{9}{9}  \\frac{25}{18} + \\frac{240}{18} \\end{pmatrix} = \\begin{pmatrix} 2  -1 \\\\ -1  \\frac{265}{18} \\end{pmatrix}$$\n现在我们计算后验精度矩阵 $C_{\\text{post}}^{-1}$：\n$$C_{\\text{post}}^{-1} = C_0^{-1} + G^T \\Gamma^{-1} G = \\begin{pmatrix} \\frac{5}{6}  0 \\\\ 0  \\frac{5}{4} \\end{pmatrix} + \\begin{pmatrix} 2  -1 \\\\ -1  \\frac{265}{18} \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{6} + \\frac{12}{6}  -1 \\\\ -1  \\frac{45}{36} + \\frac{530}{36} \\end{pmatrix} = \\begin{pmatrix} \\frac{17}{6}  -1 \\\\ -1  \\frac{575}{36} \\end{pmatrix}$$\n为了找到 $C_{\\text{post}}$，我们对 $C_{\\text{post}}^{-1}$ 求逆：\n$$\\det(C_{\\text{post}}^{-1}) = \\left(\\frac{17}{6}\\right)\\left(\\frac{575}{36}\\right) - (-1)^2 = \\frac{9775}{216} - 1 = \\frac{9775 - 216}{216} = \\frac{9559}{216}$$\n$$C_{\\text{post}} = \\frac{1}{\\det(C_{\\text{post}}^{-1})} \\begin{pmatrix} \\frac{575}{36}  1 \\\\ 1  \\frac{17}{6} \\end{pmatrix} = \\frac{216}{9559} \\begin{pmatrix} \\frac{575}{36}  1 \\\\ 1  \\frac{17}{6} \\end{pmatrix} = \\frac{1}{9559} \\begin{pmatrix} 6 \\cdot 575  216 \\\\ 216  36 \\cdot 17 \\end{pmatrix}$$\n$$C_{\\text{post}} = \\frac{1}{9559} \\begin{pmatrix} 3450  216 \\\\ 216  612 \\end{pmatrix}$$\n现在我们计算 $m_{\\text{post}}$。由于 $m_0 = 0$，公式简化为 $m_{\\text{post}} = C_{\\text{post}} (G^T \\Gamma^{-1} y)$。\n$$G^T \\Gamma^{-1} y = \\begin{pmatrix} 2  0 \\\\ -\\frac{25}{9}  \\frac{80}{9} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -\\frac{25}{9} \\end{pmatrix}$$\n$$m_{\\text{post}} = C_{\\text{post}} \\begin{pmatrix} 2 \\\\ -\\frac{25}{9} \\end{pmatrix} = \\frac{1}{9559} \\begin{pmatrix} 3450  216 \\\\ 216  612 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -\\frac{25}{9} \\end{pmatrix} = \\frac{1}{9559} \\begin{pmatrix} 3450(2) + 216(-\\frac{25}{9}) \\\\ 216(2) + 612(-\\frac{25}{9}) \\end{pmatrix}$$\n$$m_{\\text{post}} = \\frac{1}{9559} \\begin{pmatrix} 6900 - 24(25) \\\\ 432 - 68(25) \\end{pmatrix} = \\frac{1}{9559} \\begin{pmatrix} 6900 - 600 \\\\ 432 - 1700 \\end{pmatrix} = \\frac{1}{9559} \\begin{pmatrix} 6300 \\\\ -1268 \\end{pmatrix}$$\n用十进制形式表示，这是 $m_{\\text{post}} \\approx \\begin{pmatrix} 0.65906 \\\\ -0.13265 \\end{pmatrix}$。\n\n### $C_{\\text{post}}$ 的验证\n- **对称性：** 矩阵 $C_{\\text{post}} = \\frac{1}{9559} \\begin{pmatrix} 3450  216 \\\\ 216  612 \\end{pmatrix}$ 显然是对称的，因为其非对角线元素相等。\n- **正定性：** 我们检查顺序主子式。\n第一个主子式是 $C_{\\text{post},11} = \\frac{3450}{9559} > 0$。\n第二个主子式是 $\\det(C_{\\text{post}})$。我们知道 $\\det(C_{\\text{post}}) = (\\det(C_{\\text{post}}^{-1}))^{-1}$。由于 $\\det(C_{\\text{post}}^{-1}) = \\frac{9559}{216} > 0$，我们有 $\\det(C_{\\text{post}}) = \\frac{216}{9559} > 0$。\n由于所有顺序主子式都是正的，所以 $C_{\\text{post}}$ 是对称正定的。\n\n### $s$ 的计算\n最后要计算的标量是 $s \\equiv \\ln(\\det(C_{\\text{post}}))$。\n$$s = \\ln\\left(\\frac{216}{9559}\\right)$$\n使用计算器：\n$$s \\approx \\ln(0.0225965059...) \\approx -3.78994114...$$\n四舍五入到 $4$ 位有效数字，我们得到：\n$$s \\approx -3.790$$",
            "answer": "$$\\boxed{-3.790}$$"
        },
        {
            "introduction": "计算出后验估计仅仅是数据同化流程的第一步，评估我们模型的有效性同样重要。本练习引入了一个关键的诊断工具：归一化失配统计量，用于量化模型预测与实际观测值之间的一致性。通过将观测到的失配值与其理论期望值进行比较，您可以学习如何识别模型可能存在的过拟合或欠拟合问题，这是确保反演结果可靠性的核心技能。",
            "id": "3384530",
            "problem": "考虑数据同化背景下的线性逆问题，其目标是从观测值 $y \\in \\mathbb{R}^n$ 推断未知参数向量 $m \\in \\mathbb{R}^p$。假设存在一个线性观测算子 $G \\in \\mathbb{R}^{n \\times p}$，一个均值为 $m_{\\text{prior}} \\in \\mathbb{R}^p$、协方差为 $C_{\\text{prior}} \\in \\mathbb{R}^{p \\times p}$ 的高斯先验 $m \\sim \\mathcal{N}(m_{\\text{prior}}, C_{\\text{prior}})$，以及一个观测噪声协方差为 $\\Gamma \\in \\mathbb{R}^{n \\times n}$ 的高斯似然模型 $y \\mid m \\sim \\mathcal{N}(G m, \\Gamma)$。所有协方差矩阵均为对称正定（Symmetric Positive Definite, SPD）矩阵。\n\n归一化失配定义为后验残差在观测噪声度量下的平方范数，即\n$$\n\\|y - G m_{\\text{post}}\\|_{\\Gamma^{-1}}^2 = (y - G m_{\\text{post}})^\\top \\Gamma^{-1} (y - G m_{\\text{post}}),\n$$\n其中 $m_{\\text{post}}$ 表示在上述模型假设下 $m$ 的后验均值。\n\n线性高斯模型下归一化失配的期望值提供了一个评估模型拟合质量的参考。将观测到的归一化失配与其期望值进行比较，可以识别潜在的过拟合或欠拟合。你的任务是仅从上述模型假设出发，利用多元高斯分布和线性算子的公认恒等式，推导后验均值 $m_{\\text{post}}$ 和归一化失配的期望值。然后，实现一个程序，该程序能够：\n\n1. 计算 $m_{\\text{post}}$。\n2. 计算归一化失配 $\\|y - G m_{\\text{post}}\\|_{\\Gamma^{-1}}^2$。\n3. 计算模型预测的归一化失配的期望值。\n4. 将拟合分类为：\n   - $-1$ 代表过拟合（观测失配显著低于期望水平），\n   - $0$ 代表充分拟合，\n   - $1$ 代表欠拟合（观测失配显著高于期望水平）。\n   使用期望值周围的双标准差带作为决策阈值，其中标准差在相同的线性高斯假设下导出。\n\n本问题不涉及物理单位。\n\n使用以下由 $(G, C_{\\text{prior}}, m_{\\text{prior}}, \\Gamma, y)$ 指定的三个测试用例组成的测试套件：\n\n- 测试用例 1（平衡，理想路径）：\n  - $n = 4$, $p = 3$,\n  - $G = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\\\ 1  1  1 \\end{bmatrix}$，\n  - $C_{\\text{prior}} = \\operatorname{diag}(1.0, 0.5, 2.0)$，\n  - $m_{\\text{prior}} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$，\n  - $\\Gamma = \\operatorname{diag}(0.5, 0.5, 0.5, 0.5)$，\n  - $y = \\begin{bmatrix} 1.0 \\\\ -1.0 \\\\ 0.5 \\\\ 0.5 \\end{bmatrix}$。\n\n- 测试用例 2（边界，零新息导致潜在的过拟合标志）：\n  - $n = 4$, $p = 3$,\n  - $G = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\\\ 1  1  1 \\end{bmatrix}$，\n  - $C_{\\text{prior}} = \\operatorname{diag}(1.0, 1.0, 1.0)$，\n  - $m_{\\text{prior}} = \\begin{bmatrix} 0.2 \\\\ -0.3 \\\\ 0.1 \\end{bmatrix}$，\n  - $\\Gamma = \\operatorname{diag}(1.0, 1.0, 1.0, 1.0)$，\n  - $y = \\begin{bmatrix} 0.2 \\\\ -0.3 \\\\ 0.1 \\\\ 0.0 \\end{bmatrix}$。\n\n- 测试用例 3（边缘情况，强先验和中等噪声导致潜在的欠拟合标志）：\n  - $n = 4$, $p = 3$,\n  - $G = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\\\ 1  1  1 \\end{bmatrix}$，\n  - $C_{\\text{prior}} = \\operatorname{diag}(10^{-3}, 10^{-3}, 10^{-3})$，\n  - $m_{\\text{prior}} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$，\n  - $\\Gamma = \\operatorname{diag}(0.3, 0.3, 0.3, 0.3)$，\n  - $y = \\begin{bmatrix} 5.0 \\\\ -4.0 \\\\ 3.0 \\\\ 10.0 \\end{bmatrix}$。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个测试用例对应一个条目。每个条目必须是一个三元组 $[\\text{misfit}, \\text{expected}, \\text{classification}]$，其中 $\\text{misfit}$ 和 $\\text{expected}$ 是实数（浮点数），$\\text{classification}$ 是 $\\{-1, 0, 1\\}$ 中的一个整数。例如，输出格式必须如下：\n$$\n[[\\text{misfit}_1,\\text{expected}_1,\\text{classification}_1],[\\text{misfit}_2,\\text{expected}_2,\\text{classification}_2],[\\text{misfit}_3,\\text{expected}_3,\\text{classification}_3]].\n$$",
            "solution": "用户提供的问题是关于线性高斯模型的贝叶斯推断的标准练习，这是数据同化和逆问题的基石。该问题有科学依据、适定、客观，并包含获得唯一解所需的所有信息。因此，该问题被认为是有效的，下面提供了完整的解决方案。\n\n解决方案分为两个主要部分。首先，我们提供所有所需量的理论推导。其次，我们在一个 Python 程序中实现这些推导，以解决具体的测试用例。\n\n### 理论推导\n\n建模框架由参数 $m$ 的先验分布和给定 $m$ 时观测值 $y$ 的似然函数定义。\n\n1.  **先验模型**：假设参数向量 $m \\in \\mathbb{R}^p$ 服从高斯分布，$m \\sim \\mathcal{N}(m_{\\text{prior}}, C_{\\text{prior}})$。其概率密度函数 (PDF) 由下式给出：\n    $$\n    p(m) \\propto \\exp\\left(-\\frac{1}{2} (m - m_{\\text{prior}})^\\top C_{\\text{prior}}^{-1} (m - m_{\\text{prior}})\\right)\n    $$\n    其中 $m_{\\text{prior}} \\in \\mathbb{R}^p$ 是先验均值，$C_{\\text{prior}} \\in \\mathbb{R}^{p \\times p}$ 是对称正定（SPD）的先验协方差矩阵。\n\n2.  **似然模型**：观测值 $y \\in \\mathbb{R}^n$ 通过线性算子 $G \\in \\mathbb{R}^{n \\times p}$ 与参数 $m$ 相关，并受到加性高斯噪声的污染。给定 $m$ 时 $y$ 的条件分布为 $y \\mid m \\sim \\mathcal{N}(G m, \\Gamma)$。似然函数为：\n    $$\n    p(y \\mid m) \\propto \\exp\\left(-\\frac{1}{2} (y - G m)^\\top \\Gamma^{-1} (y - G m)\\right)\n    $$\n    其中 $\\Gamma \\in \\mathbb{R}^{n \\times n}$ 是对称正定的观测噪声协方差矩阵。\n\n#### 1. 后验分布与后验均值\n\n根据贝叶斯定理，给定 $y$ 时 $m$ 的后验分布与似然和先验的乘积成正比，$p(m \\mid y) \\propto p(y \\mid m) p(m)$。\n因此，后验 PDF 正比于一个关于 $m$ 的二次型的指数，这意味着后验分布也是高斯分布，$m \\mid y \\sim \\mathcal{N}(m_{\\text{post}}, C_{\\text{post}})$。后验 PDF 的负对数（不计加性常数）为：\n$$\nJ(m) = \\frac{1}{2} (m - m_{\\text{prior}})^\\top C_{\\text{prior}}^{-1} (m - m_{\\text{prior}}) + \\frac{1}{2} (y - G m)^\\top \\Gamma^{-1} (y - G m)\n$$\n后验均值 $m_{\\text{post}}$ 是使后验 PDF 最大化的 $m$ 值，这等价于最小化二次代价函数 $J(m)$。我们通过将 $J(m)$ 对 $m$ 的梯度设为零来找到这个最小值：\n$$\n\\nabla_m J(m) = C_{\\text{prior}}^{-1} (m - m_{\\text{prior}}) - G^\\top \\Gamma^{-1} (y - G m) = 0\n$$\n$$\nC_{\\text{prior}}^{-1} m - C_{\\text{prior}}^{-1} m_{\\text{prior}} - G^\\top \\Gamma^{-1} y + G^\\top \\Gamma^{-1} G m = 0\n$$\n重新整理各项以求解 $m$：\n$$\n(C_{\\text{prior}}^{-1} + G^\\top \\Gamma^{-1} G) m = C_{\\text{prior}}^{-1} m_{\\text{prior}} + G^\\top \\Gamma^{-1} y\n$$\n项 $(C_{\\text{prior}}^{-1} + G^\\top \\Gamma^{-1} G)$ 是 $J(m)$ 的海森矩阵，也就是后验协方差矩阵的逆 $C_{\\text{post}}^{-1}$。由于 $C_{\\text{prior}}$ 和 $\\Gamma$ 是对称正定的， $C_{\\text{post}}^{-1}$ 也是对称正定且可逆的。\n$$\nC_{\\text{post}} = (C_{\\text{prior}}^{-1} + G^\\top \\Gamma^{-1} G)^{-1}\n$$\n后验均值 $m_{\\text{post}}$ 于是为：\n$$\nm_{\\text{post}} = C_{\\text{post}} (C_{\\text{prior}}^{-1} m_{\\text{prior}} + G^\\top \\Gamma^{-1} y)\n$$\n当参数维度 $p$ 较小时，这个表达式的计算效率很高，因为它需要对一个 $p \\times p$ 的矩阵求逆。\n\n#### 2. 归一化失配的期望值\n\n归一化失配定义为 $\\chi^2 = \\|y - G m_{\\text{post}}\\|_{\\Gamma^{-1}}^2$。我们寻求在数据的先验预测分布下其期望值 $\\mathbb{E}[\\chi^2]$。数据 $y$ 是一个随机变量，其分布通过将联合分布 $p(y, m) = p(y|m)p(m)$ 边缘化得到。\n$y$ 的均值为 $\\mathbb{E}[y] = \\mathbb{E}[\\mathbb{E}[y|m]] = \\mathbb{E}[Gm] = G m_{\\text{prior}}$。\n$y$ 的协方差为 $\\text{Cov}(y) = \\mathbb{E}[\\text{Cov}(y|m)] + \\text{Cov}(\\mathbb{E}[y|m]) = \\Gamma + G C_{\\text{prior}} G^\\top$。\n我们定义新息向量 $d = y - G m_{\\text{prior}}$。在该模型下，$d$ 是一个零均值高斯随机变量，$d \\sim \\mathcal{N}(0, S)$，其中 $S = \\Gamma + G C_{\\text{prior}} G^\\top$ 是新息协方差矩阵。\n\n我们可以使用卡尔曼增益公式来表示后验均值：$m_{\\text{post}} = m_{\\text{prior}} + K d$，其中 $K = C_{\\text{prior}} G^\\top S^{-1}$ 是卡尔曼增益。\n后验残差为 $r = y - G m_{\\text{post}} = (d + G m_{\\text{prior}}) - G(m_{\\text{prior}} + K d) = (I_n - GK)d$，其中 $I_n$ 是 $n \\times n$ 的单位矩阵。\n失配成为 $d$ 的一个二次型：\n$$\n\\chi^2 = r^\\top \\Gamma^{-1} r = d^\\top (I_n - GK)^\\top \\Gamma^{-1} (I_n - GK) d\n$$\n对于均值为 $\\mu_x$、协方差为 $\\Sigma_x$ 的随机向量 $x$，二次型 $x^\\top A x$ 的期望值为 $\\mathbb{E}[x^\\top A x] = \\text{Tr}(A \\Sigma_x) + \\mu_x^\\top A \\mu_x$。由于 $\\mu_d = 0$，我们有：\n$$\n\\mathbb{E}[\\chi^2] = \\text{Tr}\\left( (I_n - GK)^\\top \\Gamma^{-1} (I_n - GK) S \\right)\n$$\n使用恒等式 $(I_n - GK)S = \\Gamma$（这可以通过代入 $K$ 和 $S$ 的表达式来验证），表达式简化为：\n$$\n\\mathbb{E}[\\chi^2] = \\text{Tr}\\left( (I_n - GK)^\\top \\Gamma^{-1} \\Gamma \\right) = \\text{Tr}\\left( (I_n - GK)^\\top \\right) = \\text{Tr}(I_n - GK)\n$$\n$$\n\\mathbb{E}[\\chi^2] = n - \\text{Tr}(GK)\n$$\n为了计算方便，我们可以使用 $C_{\\text{post}}$ 来表示 $GK$：$K = C_{\\text{post}} G^\\top \\Gamma^{-1}$，这给出 $GK = G C_{\\text{post}} G^\\top \\Gamma^{-1}$。\n因此，期望失配为：\n$$\n\\mathbb{E}[\\chi^2] = n - \\text{Tr}(G C_{\\text{post}} G^\\top \\Gamma^{-1})\n$$\n\n#### 3. 归一化失配的标准差\n\n为了建立分类阈值，我们需要失配的方差 $\\text{Var}(\\chi^2)$。对于一个零均值高斯向量 $d \\sim \\mathcal{N}(0, S)$，二次型 $\\chi^2 = d^\\top A d$（其中 $A$ 是一个对称矩阵）的方差是 $\\text{Var}(\\chi^2) = 2 \\text{Tr}((AS)^2)$。\n我们的二次型的矩阵是 $A_0 = (I_n - GK)^\\top \\Gamma^{-1} (I_n - GK)$。对其进行对称化得到 $A = (A_0 + A_0^\\top)/2$。\n如前所示，$(I_n - GK)S = \\Gamma$，所以 $(I_n-GK) = \\Gamma S^{-1}$。\n$A_0 = (\\Gamma S^{-1})^\\top \\Gamma^{-1} (\\Gamma S^{-1}) = (S^{-1})^\\top \\Gamma^\\top \\Gamma^{-1} \\Gamma S^{-1} = S^{-1} \\Gamma S^{-1}$（因为 $\\Gamma$ 和 $S$ 是对称的）。这个矩阵 $A$ 已经是​​对称的。\n因此，$A = S^{-1}\\Gamma S^{-1}$。\n项 $AS$ 变为 $AS = (S^{-1} \\Gamma S^{-1}) S = S^{-1} \\Gamma$。\n方差则为：\n$$\n\\text{Var}(\\chi^2) = 2 \\text{Tr}((S^{-1} \\Gamma)^2)\n$$\n为了计算，我们用 $C_{\\text{post}}$ 来表示 $S^{-1}\\Gamma$。使用 Woodbury 矩阵恒等式，$S^{-1} = (\\Gamma + G C_{\\text{prior}} G^\\top)^{-1} = \\Gamma^{-1} - \\Gamma^{-1} G C_{\\text{post}} G^\\top \\Gamma^{-1}$。\n然后，$S^{-1}\\Gamma = (\\Gamma^{-1} - \\Gamma^{-1} G C_{\\text{post}} G^\\top \\Gamma^{-1})\\Gamma = I_n - \\Gamma^{-1} G C_{\\text{post}} G^\\top$。\n设 $M = I_n - \\Gamma^{-1} G C_{\\text{post}} G^\\top$。方差为：\n$$\n\\text{Var}(\\chi^2) = 2 \\text{Tr}(M^2)\n$$\n标准差为 $\\sigma_{\\chi^2} = \\sqrt{\\text{Var}(\\chi^2)}$。\n\n#### 4. 分类准则\n\n模型拟合的分类基于将观测到的失配 $\\chi^2_{\\text{obs}}$ 与其期望值周围的置信区间进行比较：\n- 过拟合（$-1$）：$\\chi^2_{\\text{obs}}  \\mathbb{E}[\\chi^2] - 2\\sigma_{\\chi^2}$\n- 欠拟合（$1$）：$\\chi^2_{\\text{obs}} > \\mathbb{E}[\\chi^2] + 2\\sigma_{\\chi^2}$\n- 充分拟合（$0$）：其他情况。\n\n这就完成了解决该问题所需的理论框架。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the linear inverse problem for three test cases, computing\n    the posterior mean, normalized misfit, its expected value, and a\n    fit classification.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1: balanced, happy path\n        {\n            \"G\": np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]]),\n            \"C_prior\": np.diag([1.0, 0.5, 2.0]),\n            \"m_prior\": np.array([0.0, 0.0, 0.0]),\n            \"Gamma\": np.diag([0.5, 0.5, 0.5, 0.5]),\n            \"y\": np.array([1.0, -1.0, 0.5, 0.5]),\n        },\n        # Test Case 2: boundary, zero innovation leading to potential overfitting flag\n        {\n            \"G\": np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]]),\n            \"C_prior\": np.diag([1.0, 1.0, 1.0]),\n            \"m_prior\": np.array([0.2, -0.3, 0.1]),\n            \"Gamma\": np.diag([1.0, 1.0, 1.0, 1.0]),\n            \"y\": np.array([0.2, -0.3, 0.1, 0.0]),\n        },\n        # Test Case 3: edge case, strong prior and moderate noise -> underfitting\n        {\n            \"G\": np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]]),\n            \"C_prior\": np.diag([1e-3, 1e-3, 1e-3]),\n            \"m_prior\": np.array([0.0, 0.0, 0.0]),\n            \"Gamma\": np.diag([0.3, 0.3, 0.3, 0.3]),\n            \"y\": np.array([5.0, -4.0, 3.0, 10.0]),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        G = case[\"G\"]\n        C_prior = case[\"C_prior\"]\n        m_prior = case[\"m_prior\"]\n        Gamma = case[\"Gamma\"]\n        y = case[\"y\"]\n\n        n, p = G.shape\n\n        # Matrix inversions. For diagonal matrices, this is trivial, but\n        # the general formulas are implemented for correctness.\n        try:\n            C_prior_inv = np.linalg.inv(C_prior)\n            Gamma_inv = np.linalg.inv(Gamma)\n        except np.linalg.LinAlgError:\n            # Handle singular matrices if they occurred, though not expected here.\n            results.append([float('nan'), float('nan'), 0])\n            continue\n\n        # 1. Compute posterior covariance C_post\n        # C_post_inv = C_prior_inv + G^T Gamma_inv G\n        # This involves a p x p inversion, which is efficient for p  n.\n        C_post_inv = C_prior_inv + G.T @ Gamma_inv @ G\n        C_post = np.linalg.inv(C_post_inv)\n\n        # 2. Compute posterior mean m_post\n        # m_post = C_post (C_prior_inv m_prior + G^T Gamma_inv y)\n        m_post = C_post @ (C_prior_inv @ m_prior + G.T @ Gamma_inv @ y)\n\n        # 3. Compute the observed normalized misfit\n        # misfit = (y - G m_post)^T Gamma_inv (y - G m_post)\n        residual = y - G @ m_post\n        misfit = residual.T @ Gamma_inv @ residual\n        \n        # 4. Compute the expected value of the misfit\n        # E[misfit] = n - Tr(G C_post G^T Gamma_inv)\n        trace_matrix_exp = G @ C_post @ G.T @ Gamma_inv\n        expected_misfit = n - np.trace(trace_matrix_exp)\n\n        # 5. Compute the standard deviation of the misfit\n        # Var[misfit] = 2 * Tr((I - Gamma_inv G C_post G^T)^2)\n        M = np.identity(n) - Gamma_inv @ G @ C_post @ G.T\n        var_misfit = 2 * np.trace(M @ M)\n        std_misfit = np.sqrt(var_misfit)\n\n        # 6. Classify the fit\n        lower_bound = expected_misfit - 2 * std_misfit\n        upper_bound = expected_misfit + 2 * std_misfit\n\n        classification = 0\n        if misfit  lower_bound:\n            classification = -1  # Overfitting\n        elif misfit > upper_bound:\n            classification = 1   # Underfitting\n\n        results.append([misfit, expected_misfit, classification])\n    \n    # Format the final output string as per the problem specification\n    # [[misfit_1,expected_1,classification_1],[misfit_2,expected_2,classification_2],...]\n    list_of_strings = []\n    for res in results:\n        list_of_strings.append(f\"[{res[0]},{res[1]},{res[2]}]\")\n    final_output = f\"[{','.join(list_of_strings)}]\"\n    \n    print(final_output)\n\n\nsolve()\n\n```"
        },
        {
            "introduction": "在处理地球物理或医学成像等领域的实际问题时，状态向量的维度可能非常高，这使得直接构建和求逆稠密的协方差矩阵变得不可行。本练习将带您进入大规模反演问题的前沿，探索如何使用无矩阵的克雷洛夫子空间方法来解决这一挑战。您将通过实现预条件共轭梯度法 (PCG) 和兰索斯方法，学习如何在不显式形成矩阵的情况下，高效地计算后验协方差算子的作用并从后验分布中采样。",
            "id": "3384561",
            "problem": "给定一个一维网格上的线性高斯逆问题，其中未知场被建模为零均值高斯随机场，并伴有带噪声的点态观测。先验模型由一个对称正定精度算子指定。似然源于点态限制，并带有独立高斯噪声。您的任务是设计并实现一个无矩阵算法，用于计算后验协方差对向量的作用，并使用Krylov子空间方法从后验分布中抽取近似样本，而无需形成稠密矩阵。\n\n设未知场位于一个包含$n$个点的均匀网格上。将未知量表示为 $x \\in \\mathbb{R}^n$，其先验分布为 $x \\sim \\mathcal{N}(0, C_{\\text{prior}})$，精度为 $Q = C_{\\text{prior}}^{-1}$。观测模型为 $y = A x + \\eta$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个限制算子，用于在$m$个网格位置上采样，而 $\\eta \\sim \\mathcal{N}(0, \\Gamma)$，其中 $\\Gamma = \\sigma^2 I_m$。\n\n根据线性逆问题中的高斯后验定律，后验分布是高斯分布，其精度由下式给出\n$$\nH \\equiv Q + A^\\top \\Gamma^{-1} A,\n$$\n后验协方差为 $C_{\\text{post}} = H^{-1}$。本任务要求的输出依赖于以无矩阵方式计算以下两种操作：\n1. 后验协方差对向量 $v \\in \\mathbb{R}^n$ 的作用，即计算 $C_{\\text{post}} v$，这是对称正定系统 $H w = v$ 的解 $w$。\n2. 对于给定的 $z \\in \\mathbb{R}^n$ 且 $z \\sim \\mathcal{N}(0, I_n)$，通过算子函数 $H^{-1/2}$ 对 $z$ 应用的 Lanczos 近似，生成一个近似的后验样本 $s \\approx C_{\\text{post}}^{1/2} z$。\n\n您必须遵守以下建模细节和算法约束：\n- 先验精度 $Q$ 是一维离散负拉普拉斯算子，带有 Neumann 边界条件，并加上一个点态质量项。在一个间距为 $h$ 的均匀网格上，为每个分量 $i \\in \\{0, 1, \\dots, n-1\\}$ 定义，\n$$\n(Q x)_i = \\lambda \\left( \\frac{2 x_i - x_{i-1} - x_{i+1}}{h^2} + \\beta x_i \\right),\n$$\n其中边界值为镜像边界 $x_{-1} = x_0$ 和 $x_{n} = x_{n-1}$，参数为 $\\lambda > 0$ 和 $\\beta > 0$。\n- 观测算子 $A$ 是在基数为 $m$ 的固定索引集 $\\mathcal{I} \\subset \\{0, 1, \\dots, n-1\\}$ 上的点态限制，因此 $A x \\in \\mathbb{R}^m$ 提取 $i \\in \\mathcal{I}$ 的条目 $x_i$。因此，\n$$\nA^\\top \\Gamma^{-1} A x = \\sum_{i \\in \\mathcal{I}} \\frac{1}{\\sigma^2} x_i e_i,\n$$\n其中 $e_i$ 是 $\\mathbb{R}^n$ 的第 $i$ 个标准基向量。\n- 您绝不能构建稠密矩阵 $H$ 或任何代表 $Q$、$A$ 或 $A^\\top \\Gamma^{-1} A$ 的稠密矩阵。相反，您应实现无矩阵的例程来将 $Q$ 和 $A^\\top \\Gamma^{-1} A$ 应用于向量，并组合它们以将 $H$ 应用于向量。\n- 要计算 $C_{\\text{post}} v$，请使用预条件共轭梯度法 (PCG)。预条件子必须是 Jacobi（对角）预条件子，即 $M = \\operatorname{diag}(H)$，并且必须通过逐元素除法来应用 $M^{-1}$。$Q$ 的对角线由下式给出\n$$\n\\operatorname{diag}(Q)_i = \\lambda \\left( \\beta + d_i \\right), \\quad d_i = \\begin{cases} \\dfrac{1}{h^2},  i \\in \\{0, n-1\\}, \\\\[6pt] \\dfrac{2}{h^2},  \\text{otherwise}, \\end{cases}\n$$\n$A^\\top \\Gamma^{-1} A$ 的对角线在索引集 $\\mathcal{I}$ 上的贡献为 $\\dfrac{1}{\\sigma^2}$，在其他位置为 $0$。\n- 要抽取近似样本 $s \\approx H^{-1/2} z$，请实现最多进行 $k$ 次迭代的 Lanczos 方法，以构建 Krylov 子空间 $\\mathcal{K}_k(H, z)$ 的一个标准正交基 $Q_k = [q_1, \\dots, q_k]$ 以及相应的三对角矩阵 $T_k$。然后使用标准的 Lanczos 泛函近似\n$$\nH^{-1/2} z \\approx \\| z \\|_2 \\, Q_k f(T_k) e_1, \\quad f(\\cdot) = (\\cdot)^{-1/2},\n$$\n通过计算 $T_k$ 的对称特征值分解，将 $f$ 应用于特征值，然后变换回来。不使用重正交化，并假设 $H$ 是对称正定的。Lanczos 方法的停止准则是固定的迭代次数 $k$。\n\n为了验证和测试覆盖，请为每个测试用例计算以下两个标量诊断值：\n- $w = C_{\\text{post}} v$ 的残差范数，\n$$\nr_{\\text{norm}} = \\| H w - v \\|_2,\n$$\n作为一个浮点数。\n- $s \\approx H^{-1/2} z$ 的能量恒等式误差，\n$$\n\\varepsilon_{\\text{energy}} = \\left| s^\\top H s - \\| z \\|_2^2 \\right|,\n$$\n作为一个浮点数。恒等式 $s^\\top H s = \\| z \\|_2^2$ 对于 $s = H^{-1/2} z$ 精确成立；您的近似样本应产生一个很小的误差。\n\n您必须为以下指定参数和输入的测试套件实现上述内容：\n- 案例 1（正常路径）：$n = 50$，$m = 15$，$\\lambda = 1.0$，$\\beta = 1.0$，$\\sigma = 0.2$，Lanczos 迭代次数 $k = 20$，观测索引 $\\mathcal{I}$ 选择为 $m$ 个近似均匀分布的网格索引。网格间距为 $h = \\dfrac{1}{n-1}$。使用确定性探针向量 $v \\in \\mathbb{R}^{n}$，其条目为 $v_i = \\sin\\left( 2 \\pi \\left( \\dfrac{i + 0.5}{n} \\right) \\right)$，其中 $i = 0, \\dots, n-1$。对于采样，使用标准正态分布 $z \\sim \\mathcal{N}(0, I_n)$，其生成种子固定为案例索引（$1$）。\n- 案例 2（高噪声边界）：$n = 50$，$m = 25$，$\\lambda = 1.0$，$\\beta = 0.5$，$\\sigma = 5.0$，$k = 25$，观测索引如上选择。使用相同的确定性 $v$ 定义。对于采样，使用 $z \\sim \\mathcal{N}(0, I_n)$，种子为 $2$。\n- 案例 3（无数据边缘情况）：$n = 50$，$m = 0$，$\\lambda = 2.0$，$\\beta = 0.1$，$\\sigma = 1.0$，$k = 20$，无观测索引。使用相同的确定性 $v$。对于采样，使用 $z \\sim \\mathcal{N}(0, I_n)$，种子为 $3$。\n- 案例 4（低噪声、密集观测）：$n = 50$，$m = 40$，$\\lambda = 1.0$，$\\beta = 1.0$，$\\sigma = 0.01$，$k = 30$，观测索引如上选择。使用相同的确定性 $v$。对于采样，使用 $z \\sim \\mathcal{N}(0, I_n)$，种子为 $4$。\n\n算法要求：\n- 为任意的 $n$、$m$、$\\lambda$、$\\beta$、$\\sigma$ 和观测索引集 $\\mathcal{I}$，实现一个无矩阵的例程来将 $Q$、$A^\\top \\Gamma^{-1} A$ 和 $H$ 应用于向量。\n- 实现带有 Jacobi 预条件子 $M = \\operatorname{diag}(H)$ 的预条件共轭梯度法 (PCG)，用于计算 $H w = v$ 的解 $w$，相对残差容差为 $10^{-8}$，最大迭代次数为 $200$。\n- 实现具有固定迭代次数 $k$ 的 Lanczos 方法，通过三对角投影和谱映射来近似 $H^{-1/2} z$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含四个测试用例的结果，格式为一个由方括号括起来的、逗号分隔的浮点数对列表，不含空格。每对数值对应一个测试用例的 $[r_{\\text{norm}}, \\varepsilon_{\\text{energy}}]$。例如，输出应如下所示\n$$\n[\\,[r_1,\\varepsilon_1],[r_2,\\varepsilon_2],[r_3,\\varepsilon_3],[r_4,\\varepsilon_4]\\,]\n$$\n但打印为不含空格的单行\n\"[[r1,eps1],[r2,eps2],[r3,eps3],[r4,eps4]]\"。",
            "solution": "该问题要求设计并实现无矩阵算法，以分析线性高斯逆问题中的后验分布。具体来说，我们需要计算后验协方差算子对向量的作用，并从后验分布中抽取一个近似样本。该问题是适定的，并且在贝叶斯逆问题和数据同化领域具有坚实的科学基础。指定的方法——用于函数逼近的预条件共轭梯度法 (PCG) 和 Lanczos 方法——在此背景下是标准且适用的。\n\n后验精度算子 $H$ 是先验精度 $Q$ 和数据精度项 $A^\\top \\Gamma^{-1} A$ 的和：\n$$\nH = Q + A^\\top \\Gamma^{-1} A\n$$\n该算子是对称正定的，因为他是一个对称正定算子 $Q$（因为 $\\lambda > 0, \\beta > 0$）和一个对称半正定算子 $A^\\top \\Gamma^{-1} A$ 的和。这一性质对于所选数值方法的稳定性和收敛性至关重要。\n\n我们将通过以下方式构建解决方案：首先定义算子的无矩阵应用，然后详细说明用于求解线性系统的 PCG 算法，最后解释基于 Lanczos 的方法来近似算子平方根矩阵向量乘积。\n\n**1. 无矩阵算子实现**\n\n一个核心要求是避免构建稠密矩阵。我们实现一些函数，用于计算算子 $Q$、$A^\\top \\Gamma^{-1} A$ 和 $H$ 对任意向量 $x \\in \\mathbb{R}^n$ 的作用。\n\n先验精度算子 $Q$ 定义为：\n$$\n(Q x)_i = \\lambda \\left( \\frac{2 x_i - x_{i-1} - x_{i+1}}{h^2} + \\beta x_i \\right)\n$$\n带有 Neumann 边界条件 $x_{-1} = x_0$ 和 $x_{n} = x_{n-1}$。这些条件可以使用数组切片高效实现。对于长度为 $n$ 的向量 $x$，其作用 $(Qx)$ 可计算如下：\n- 对于内部点 $i \\in \\{1, \\dots, n-2\\}$：$(Qx)_i = \\lambda \\left( \\frac{2x_i - x_{i-1} - x_{i+1}}{h^2} + \\beta x_i \\right)$。\n- 对于边界点 $i=0$：$(Qx)_0 = \\lambda \\left( \\frac{2x_0 - x_0 - x_1}{h^2} + \\beta x_0 \\right) = \\lambda \\left( \\frac{x_0 - x_1}{h^2} + \\beta x_0 \\right)$。\n- 对于边界点 $i=n-1$：$(Qx)_{n-1} = \\lambda \\left( \\frac{2x_{n-1} - x_{n-2} - x_{n-1}}{h^2} + \\beta x_{n-1} \\right) = \\lambda \\left( \\frac{x_{n-1} - x_{n-2}}{h^2} + \\beta x_{n-1} \\right)$。\n\n数据精度算子 $A^\\top \\Gamma^{-1} A$ 是一个对角算子，它通过缩放向量 $x$ 中对应于观测位置的分量来对其产生作用。给定观测噪声模型 $\\eta \\sim \\mathcal{N}(0, \\sigma^2 I_m)$，逆噪声协方差为 $\\Gamma^{-1} = \\frac{1}{\\sigma^2} I_m$。该算子的作用为：\n$$\n(A^\\top \\Gamma^{-1} A x)_i = \\begin{cases} \\frac{1}{\\sigma^2} x_i,  i \\in \\mathcal{I} \\\\ 0,  i \\notin \\mathcal{I} \\end{cases}\n$$\n其中 $\\mathcal{I}$ 是观测索引集。\n\n后验精度算子 $H$ 对向量 $x$ 的作用就是其各分量作用之和：\n$$\nH x = Q x + (A^\\top \\Gamma^{-1} A) x\n$$\n\n**2. 计算后验协方差作用**\n\n计算后验协方差作用 $w = C_{\\text{post}} v = H^{-1} v$ 的任务等同于求解线性系统 $H w = v$。由于 $H$ 是对称正定的，共轭梯度 (CG) 法是一个理想的选择。我们使用其预条件变体 (PCG) 来提高收敛速度。\n\n所选的预条件子是 Jacobi（或对角）预条件子，$M = \\operatorname{diag}(H)$。预条件子的逆 $M^{-1}$ 是一个对角矩阵，其元素是 $H$ 对角元素的倒数。它对向量的作用是一个简单的逐元素除法。$H$ 的对角线是 $Q$ 和 $A^\\top \\Gamma^{-1} A$ 对角线之和。\n$Q$ 的对角线由下式给出：\n$$\n\\operatorname{diag}(Q)_i = \\lambda \\left( \\beta + \\frac{1}{h^2} \\right) \\text{ for } i \\in \\{0, n-1\\}, \\quad \\operatorname{diag}(Q)_i = \\lambda \\left( \\beta + \\frac{2}{h^2} \\right) \\text{ otherwise.}\n$$\n$A^\\top \\Gamma^{-1} A$ 的对角线仅在观测索引处非零：\n$$\n\\operatorname{diag}(A^\\top \\Gamma^{-1} A)_i = \\begin{cases} \\frac{1}{\\sigma^2},  i \\in \\mathcal{I} \\\\ 0,  i \\notin \\mathcal{I} \\end{cases}\n$$\nPCG 算法从一个初始猜测（例如 $w_0=0$）开始，通过生成一系列 $H$-正交的搜索方向来迭代地优化解 $w$。当相对残差范数 $\\|Hw - v\\|_2 / \\|v\\|_2  10^{-8}$ 或达到最大迭代次数（$200$）时，算法终止。最终计算出的向量 $w$ 即为所求结果 $C_{\\text{post}}v$。残差范数 $\\|Hw - v\\|_2$ 作为诊断值进行计算。\n\n**3. 近似后验采样**\n\n第二个任务是从后验分布 $\\mathcal{N}(0, C_{\\text{post}})$ 中生成一个近似样本 $s$。这等同于计算 $s \\approx C_{\\text{post}}^{1/2} z = H^{-1/2} z$，其中 $z \\sim \\mathcal{N}(0, I_n)$。我们使用 Lanczos 方法来近似这个矩阵函数向量乘积。\n\nLanczos 算法是一种迭代方法，对于一个对称算子 $H$ 和一个起始向量 $z$，它会为 Krylov 子空间 $\\mathcal{K}_k(H, z) = \\operatorname{span}\\{z, Hz, H^2z, \\dots, H^{k-1}z\\}$ 构建一个标准正交基 $\\{q_1, \\dots, q_k\\}$。在这个基中，算子 $H$ 由一个小的 $k \\times k$ 对称三对角矩阵 $T_k = Q_k^\\top H Q_k$ 表示。\n\n该近似依赖于性质：对于一个函数 $f$，$f(H)z \\approx \\|z\\|_2 Q_k f(T_k) e_1$，其中 $e_1 = [1, 0, \\dots, 0]^\\top$。在我们的例子中，$f(\\cdot) = (\\cdot)^{-1/2}$。\n算法流程如下：\n1.  对 $H$ 和起始向量 $z$ 运行 $k$ 次 Lanczos 迭代，得到标准正交基矩阵 $Q_k = [q_1, \\dots, q_k]$ 和三对角矩阵 $T_k$。不执行重正交化。\n2.  计算小对称矩阵 $T_k$ 的谱分解 $T_k = V \\Lambda V^\\top$，其中 $\\Lambda$ 是特征值的对角矩阵，$V$ 是特征向量的正交矩阵。这可以通过专门的数值例程（如 `scipy.linalg.eigh_tridiagonal`）高效完成。\n3.  计算 $f(T_k) = V f(\\Lambda) V^\\top = V \\Lambda^{-1/2} V^\\top$。\n4.  样本 $s$ 的最终近似值计算如下：\n    $$\n    s \\approx \\|z\\|_2 \\, Q_k \\left( V \\Lambda^{-1/2} V^\\top \\right) e_1\n    $$\n    此计算通过计算每一项对向量 $e_1$ 的作用来高效执行，而无需构建完整的矩阵。\n\n此近似的质量通过能量恒等式误差 $\\varepsilon_{\\text{energy}} = \\left| s^\\top H s - \\|z\\|_2^2 \\right|$ 来评估。对于一个精确样本 $s = H^{-1/2} z$，我们有 $s^\\top H s = (H^{-1/2}z)^\\top H (H^{-1/2}z) = z^\\top H^{-1/2} H H^{-1/2} z = z^\\top z = \\|z\\|_2^2$。误差 $\\varepsilon_{\\text{energy}}$ 衡量了由 Lanczos 近似引起的与此恒等式的偏差。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import eigh_tridiagonal\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    test_cases = [\n        # Case 1: happy path\n        {'n': 50, 'm': 15, 'lam': 1.0, 'beta': 1.0, 'sigma': 0.2, 'k': 20, 'seed': 1},\n        # Case 2: high-noise boundary\n        {'n': 50, 'm': 25, 'lam': 1.0, 'beta': 0.5, 'sigma': 5.0, 'k': 25, 'seed': 2},\n        # Case 3: no-data edge\n        {'n': 50, 'm': 0, 'lam': 2.0, 'beta': 0.1, 'sigma': 1.0, 'k': 20, 'seed': 3},\n        # Case 4: low-noise, dense observations\n        {'n': 50, 'm': 40, 'lam': 1.0, 'beta': 1.0, 'sigma': 0.01, 'k': 30, 'seed': 4},\n    ]\n\n    # --- Matrix-Free Operator Implementations ---\n    \n    def apply_Q(x, n, h, lam, beta):\n        \"\"\"Matrix-free application of the prior precision operator Q.\"\"\"\n        h_sq = h**2\n        lap_x = np.zeros(n)\n        \n        # Interior points\n        if n > 2:\n            lap_x[1:-1] = (2 * x[1:-1] - x[:-2] - x[2:]) / h_sq\n        \n        # Boundary points (Neumann)\n        if n > 1:\n            lap_x[0] = (x[0] - x[1]) / h_sq\n            lap_x[-1] = (x[-1] - x[-2]) / h_sq\n        elif n == 1:\n            lap_x[0] = 0 # No neighbors\n            \n        return lam * (lap_x + beta * x)\n\n    def apply_A_T_Gamma_inv_A(x, obs_indices, sigma_sq_inv):\n        \"\"\"Matrix-free application of the data precision operator.\"\"\"\n        result = np.zeros_like(x)\n        if obs_indices.size > 0:\n            result[obs_indices] = x[obs_indices] * sigma_sq_inv\n        return result\n\n    # --- Preconditioner  PCG ---\n\n    def compute_diag_H(n, h, lam, beta, obs_indices, sigma_sq_inv):\n        \"\"\"Computes the diagonal of the posterior precision operator H.\"\"\"\n        h_sq = h**2\n        \n        # Diagonal of Q\n        diag_Q = np.full(n, lam * (beta + 2.0 / h_sq))\n        if n > 1:\n            diag_Q[0] = lam * (beta + 1.0 / h_sq)\n            diag_Q[-1] = lam * (beta + 1.0 / h_sq)\n        elif n == 1:\n             diag_Q[0] = lam * beta\n\n        # Diagonal of A^T*Gamma^-1*A\n        diag_A_part = np.zeros(n)\n        if obs_indices.size > 0:\n            diag_A_part[obs_indices] = sigma_sq_inv\n            \n        return diag_Q + diag_A_part\n\n    def pcg(apply_A, b, apply_M_inv, tol=1e-8, maxiter=200):\n        \"\"\"Preconditioned Conjugate Gradients algorithm.\"\"\"\n        x = np.zeros_like(b)\n        r = b - apply_A(x)\n        if np.linalg.norm(b) == 0:\n            return x\n            \n        norm_b = np.linalg.norm(b)\n        if norm_b == 0: norm_b = 1.0 # Handle b=0 case\n\n        z = apply_M_inv(r)\n        p = z\n        rs_old = np.dot(r, z)\n\n        for i in range(maxiter):\n            Ap = apply_A(p)\n            alpha = rs_old / np.dot(p, Ap)\n            x += alpha * p\n            r -= alpha * Ap\n            \n            if np.linalg.norm(r) / norm_b  tol:\n                break\n                \n            z = apply_M_inv(r)\n            rs_new = np.dot(r, z)\n            p = z + (rs_new / rs_old) * p\n            rs_old = rs_new\n            \n        return x\n\n    # --- Lanczos Algorithm  Function Approximation ---\n    \n    def lanczos(apply_H, z, k):\n        \"\"\"Lanczos algorithm to generate T_k and Q_k.\"\"\"\n        n = len(z)\n        Q = np.zeros((n, k))\n        alphas = np.zeros(k)\n        betas_sub = np.zeros(k - 1)\n\n        z_norm = np.linalg.norm(z)\n        if z_norm == 0:\n            return alphas, betas_sub, Q, z_norm\n        \n        q = z / z_norm\n        \n        for j in range(k):\n            Q[:, j] = q\n            u = apply_H(q)\n            alphas[j] = np.dot(q, u)\n            \n            if j  k - 1:\n                u = u - alphas[j] * q\n                if j > 0:\n                    u = u - betas_sub[j-1] * Q[:, j-1]\n                \n                beta_j = np.linalg.norm(u)\n                betas_sub[j] = beta_j\n                if beta_j  1e-14: # (Near) breakdown\n                    # Resize and return what we have\n                    return alphas[:j+1], betas_sub[:j], Q[:, :j+1], z_norm\n                q = u / beta_j\n                \n        return alphas, betas_sub, Q, z_norm\n\n    results = []\n    for case in test_cases:\n        n, m, lam, beta, sigma, k, seed = case.values()\n\n        # --- Setup for the current test case ---\n        h = 1.0 / (n - 1) if n > 1 else 1.0\n        sigma_sq_inv = 1.0 / sigma**2\n        obs_indices = np.unique(np.linspace(0, n - 1, m, dtype=int)) if m > 0 else np.array([], dtype=int)\n        \n        # Generate input vectors\n        v = np.sin(2 * np.pi * (np.arange(n) + 0.5) / n)\n        rng = np.random.default_rng(seed)\n        z = rng.normal(size=n)\n        \n        # Define operators for this case\n        def apply_H(x):\n            return apply_Q(x, n, h, lam, beta) + \\\n                   apply_A_T_Gamma_inv_A(x, obs_indices, sigma_sq_inv)\n                   \n        # --- Part 1: PCG for C_post * v ---\n        diag_H = compute_diag_H(n, h, lam, beta, obs_indices, sigma_sq_inv)\n        def apply_M_inv(r):\n            return r / diag_H\n            \n        w = pcg(apply_H, v, apply_M_inv, tol=1e-8, maxiter=200)\n        r_norm = np.linalg.norm(apply_H(w) - v)\n\n        # --- Part 2: Lanczos for approximate sample ---\n        alphas, betas_sub, Q_k, z_norm = lanczos(apply_H, z, k)\n        \n        # Adjust k if early breakdown occurred\n        actual_k = Q_k.shape[1]\n        \n        if actual_k > 0:\n            # Eigendecomposition of T_k\n            eivals, eivecs = eigh_tridiagonal(alphas, betas_sub, tol=1e-15)\n        \n            # Compute H^{-1/2} z approximation via spectral mapping\n            f_eivals = 1.0 / np.sqrt(eivals)\n            y = eivecs @ (f_eivals * eivecs[0, :])\n            s = z_norm * (Q_k @ y)\n\n            # Compute energy error\n            sHs = np.dot(s, apply_H(s))\n            z_norm_sq = z_norm**2\n            eps_energy = np.abs(sHs - z_norm_sq)\n        else: # Handle z=0 case\n            s = np.zeros(n)\n            eps_energy = 0.0\n\n        results.append(f\"[{r_norm},{eps_energy}]\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}