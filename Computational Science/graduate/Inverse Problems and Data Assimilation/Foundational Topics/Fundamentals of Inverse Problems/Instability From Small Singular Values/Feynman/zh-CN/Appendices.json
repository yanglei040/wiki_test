{
    "hands_on_practices": [
        {
            "introduction": "本练习旨在建立对奇异值与解的不稳定性之间关系的直观理解。通过一个简化的思想实验，我们将直接估算一个微小的奇异值如何将观测数据中的少量噪声放大成解中的巨大误差。这个量级估算练习突显了为何即使在噪声水平看似可控的情况下，不适定逆问题也亟需进行正则化处理 。",
            "id": "3391315",
            "problem": "考虑一个欧几里得空间中的线性反问题，其中观测数据向量由 $b = A x_{\\text{true}} + \\eta$ 给出，其中 $A \\in \\mathbb{R}^{m \\times n}$，$x_{\\text{true}} \\in \\mathbb{R}^{n}$，$\\eta \\in \\mathbb{R}^{m}$ 是加性噪声。重建解 $x^{\\dagger}$ 定义为通过 Moore–Penrose 伪逆得到的最小范数最小二乘解，即 $x^{\\dagger} = A^{\\dagger} b$。假设 $A$ 的奇异值分解 (SVD) 存在，且最小的非零奇异值为 $\\sigma_{r} = 10^{-6}$。噪声水平由 $\\|\\eta\\|_{2} / \\|b_{\\text{true}}\\|_{2} = 0.01$ 量化，其中 $b_{\\text{true}} = A x_{\\text{true}}$。为了分离由小奇异值引起的不稳定性，假设问题已被无量纲化，使得与 $b_{\\text{true}}$ 的主要部分相关联的有效奇异值约为 1 的量级，即 $\\|b_{\\text{true}}\\|_{2} / \\|x_{\\text{true}}\\|_{2} \\approx 1$，并且来自噪声的对解误差的主要贡献与对应于 $\\sigma_{r}$ 的右奇异向量对齐。\n\n仅使用奇异值分解和 Moore–Penrose 伪逆的基本性质，估计仅由噪声引起的重建相对误差的预期数量级，\n$$\n\\frac{\\|x^{\\dagger} - x_{\\text{true}}\\|_{2}}{\\|x_{\\text{true}}\\|_{2}},\n$$\n并将您的答案报告为单个无量纲数。不要包含任何单位。除非不可避免，否则不需要四舍五入。",
            "solution": "重建解 $x^{\\dagger}$ 由 Moore–Penrose 伪逆定义为 $x^{\\dagger} = A^{\\dagger} b$，其中 $b = b_{\\text{true}} + \\eta$ 且 $b_{\\text{true}} = A x_{\\text{true}}$。由加性噪声引起的重建误差为\n$$\nx^{\\dagger} - x_{\\text{true}} = A^{\\dagger}(b_{\\text{true}} + \\eta) - x_{\\text{true}} = A^{\\dagger} A x_{\\text{true}} + A^{\\dagger} \\eta - x_{\\text{true}} = A^{\\dagger} \\eta,\n$$\n因为 $A^{\\dagger} A x_{\\text{true}}$ 是 $x_{\\text{true}}$ 在 $A^{\\top}$ 的值域上的正交投影，对于与 $b_{\\text{true}} \\in \\text{range}(A)$ 一致的最小范数解，该投影等于 $x_{\\text{true}}$。\n\n设 $A$ 的奇异值分解 (SVD) 为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 的对角线元素为 $\\sigma_{1} \\geq \\sigma_{2} \\geq \\cdots \\geq \\sigma_{r}  0$，其中 $r = \\text{rank}(A)$。Moore–Penrose 伪逆是 $A^{\\dagger} = V \\Sigma^{\\dagger} U^{\\top}$，其中 $\\Sigma^{\\dagger}$ 的对角线元素在 $i \\leq r$ 时为 $\\sigma_{i}^{-1}$，否则为零。\n\n那么，由噪声引起的误差为\n$$\nx^{\\dagger} - x_{\\text{true}} = V \\Sigma^{\\dagger} U^{\\top} \\eta.\n$$\n取范数得到\n$$\n\\|x^{\\dagger} - x_{\\text{true}}\\|_{2} = \\|V \\Sigma^{\\dagger} U^{\\top} \\eta\\|_{2} = \\|\\Sigma^{\\dagger} U^{\\top} \\eta\\|_{2}.\n$$\n矩阵 $U$ 是正交的，所以 $\\|U^{\\top} \\eta\\|_{2} = \\|\\eta\\|_{2}$。$U^{\\top} \\eta$ 沿着第 $i$ 个左奇异向量的分量被放大的因子是 $\\sigma_{i}^{-1}$。在所述假设下，即来自噪声的对解误差的主要贡献与对应于最小奇异值 $\\sigma_{r}$ 的右奇异向量对齐，误差的大小由下式决定：\n$$\n\\|x^{\\dagger} - x_{\\text{true}}\\|_{2} \\approx \\frac{\\|\\eta\\|_{2}}{\\sigma_{r}}.\n$$\n我们要求解相对误差。使用无量纲化假设，即与 $b_{\\text{true}}$ 的主要部分相关联的有效奇异值约为 1 的量级，我们有\n$$\n\\frac{\\|b_{\\text{true}}\\|_{2}}{\\|x_{\\text{true}}\\|_{2}} \\approx 1 \\quad \\Longrightarrow \\quad \\|x_{\\text{true}}\\|_{2} \\approx \\|b_{\\text{true}}\\|_{2}.\n$$\n因此，\n$$\n\\frac{\\|x^{\\dagger} - x_{\\text{true}}\\|_{2}}{\\|x_{\\text{true}}\\|_{2}} \\approx \\frac{\\|\\eta\\|_{2}}{\\sigma_{r} \\|x_{\\text{true}}\\|_{2}} \\approx \\frac{\\|\\eta\\|_{2}}{\\sigma_{r} \\|b_{\\text{true}}\\|_{2}} = \\frac{1}{\\sigma_{r}} \\cdot \\frac{\\|\\eta\\|_{2}}{\\|b_{\\text{true}}\\|_{2}}.\n$$\n代入给定值 $\\sigma_{r} = 10^{-6}$ 和 $\\|\\eta\\|_{2} / \\|b_{\\text{true}}\\|_{2} = 0.01$ 得到\n$$\n\\frac{\\|x^{\\dagger} - x_{\\text{true}}\\|_{2}}{\\|x_{\\text{true}}\\|_{2}} \\approx \\frac{1}{10^{-6}} \\times 0.01 = 10^{6} \\times 10^{-2} = 10^{4}.\n$$\n因此，在隔离了最小奇异值导致的不稳定性的指定假设下，仅由噪声引起的重建相对误差的预期数量级为 $1 \\times 10^{4}$。",
            "answer": "$$\\boxed{1 \\times 10^{4}}$$"
        },
        {
            "introduction": "理解了小奇异值带来的不稳定性之后，下一步是学习如何抑制它。本实践练习将指导您通过编写代码来实现一种最经典和广泛使用的正则化方法——吉洪诺夫正则化（Tikhonov regularization）。您将使用莫罗佐夫差异原则（Morozov’s discrepancy principle）来自动选择正则化参数 $\\lambda$，并量化该方法如何有效抑制与小奇异值相关的模式，从而稳定反演结果 。",
            "id": "3391353",
            "problem": "考虑由方程 $A x = b$ 定义的带有加性噪声的线性反问题，其中 $b = A x_{\\mathrm{true}} + \\eta$，噪声向量 $\\eta$ 的分量是独立同分布的，方差为 $\\sigma_{\\eta}^2$。我们研究零阶 Tikhonov 正则化和 Morozov 差异原则，以解决由小奇异值引起的不稳定性问题。假设以下基本基础：最小二乘估计量最小化残差范数的平方，零阶 Tikhonov 正则化针对正则化参数 $\\lambda \\ge 0$ 最小化增广泛函 $J(x) = \\|A x - b\\|_2^2 + \\lambda^2 \\|x\\|_2^2$。矩阵 $A$ 的奇异值分解 (SVD) 定义为 $A = U \\Sigma V^\\top$，其中 $U$ 和 $V$ 是正交矩阵，$\\Sigma$ 是对角矩阵，其非负对角元等于奇异值。Morozov 差异原则选择 $\\lambda$，使得残差范数 $\\|A x_{\\lambda} - b\\|_2$ 等于一个与噪声水平一致的目标范数。本问题中任何三角函数定义所使用的所有角度都必须以弧度为单位进行解释。\n\n您的任务是实现一个完整且可运行的程序，对于每个测试用例，确定性地构造矩阵 $A$、干净信号 $x_{\\mathrm{true}}$ 和噪声向量 $\\eta$，根据 Morozov 差异原则计算正则化参数 $\\lambda$，并量化对小奇异值模态的抑制。具体来说：\n\n1. 对于零阶 Tikhonov 正则化，当 $A$ 具有满列秩时，将 $x_{\\lambda}$ 定义为 $J(x) = \\|A x - b\\|_2^2 + \\lambda^2 \\|x\\|_2^2$ 的唯一最小化子。对于每个测试用例，确定满足 Morozov 差异原则的 $\\lambda$，即：\n   $$\\|A x_{\\lambda} - b\\|_2 = \\tau \\sqrt{m} \\, \\sigma_{\\eta},$$\n   其中 $m$ 是 $A$ 的行数，$\\tau  0$ 是一个指定的差异因子。在下面包含的每个测试中，$\\tau$ 都是明确给出的。目标残差范数应使用精确的欧几里得范数 $\\|\\cdot\\|_2$ 计算和使用，除了指定的数学量外，不需要任何单位。\n\n2. 量化对小奇异值模态的抑制。给定 $A$ 的奇异值 $\\{\\sigma_i\\}_{i=1}^n$，将逐模态抑制因子定义为：\n   $$s_i(\\lambda) = \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2},$$\n   如果 $\\sigma_i \\le \\alpha \\lambda$ 且阈值 $\\alpha = 0.1$，则将一个模态解释为被强抑制。对于每个测试用例，计算：\n   - 强抑制模态的计数 $k(\\lambda) = \\#\\{i : \\sigma_i \\le 0.1 \\lambda\\}$，\n   - 强抑制模态的平均抑制：\n     $$\\bar{s}(\\lambda) = \\frac{1}{k(\\lambda)} \\sum_{\\{i : \\sigma_i \\le 0.1 \\lambda\\}} s_i(\\lambda),$$\n     约定当 $k(\\lambda) = 0$ 时，$\\bar{s}(\\lambda) = 0$。\n\n用于测试套件的 $A$、$x_{\\mathrm{true}}$ 和 $\\eta$ 的构造必须遵循以下确定性规则：\n- 在所有测试用例中，$A$ 都是 $m = n = 10$ 的方阵，并且是对角矩阵，其对角元等于指定的奇异值 $\\{\\sigma_i\\}_{i=1}^{10}$。因此，$A = \\mathrm{diag}(\\sigma_1, \\dots, \\sigma_{10})$，所以奇异值分解 (SVD) 为 $U = I_{10}$，$V = I_{10}$，以及 $\\Sigma = \\mathrm{diag}(\\sigma_1, \\dots, \\sigma_{10})$。\n- 干净信号必须选择为 $x_{\\mathrm{true}} = (1, \\tfrac{1}{2}, \\tfrac{1}{3}, \\dots, \\tfrac{1}{10})^\\top$。\n- 噪声向量必须根据一个模板向量 $w \\in \\mathbb{R}^{10}$ 确定性地构造，其分量定义为 $w_j = \\sin(j) + \\tfrac{1}{2} \\cos(2 j)$，其中 $j = 1, 2, \\dots, 10$，所有角度均以弧度为单位。通过设置以下公式来归一化此模板以满足 $\\|\\eta\\|_2 = \\sqrt{m}\\, \\sigma_{\\eta}$：\n  $$\\eta = w \\cdot \\frac{\\sqrt{m}\\, \\sigma_{\\eta}}{\\|w\\|_2}.$$\n- 数据向量为 $b = A x_{\\mathrm{true}} + \\eta$。\n\n程序必须通过使用一个不需要用户输入的稳健数值方法，求解上述第1项中的标量方程来计算 $\\lambda$。残差范数必须精确计算为 $A x_{\\lambda} - b$ 的欧几里得范数。\n\n测试套件：\n为以下四个测试用例提供结果，每个用例都具有 $m = n = 10$ 以及与上述相同的 $x_{\\mathrm{true}}$ 和噪声构造规则。对于每个用例，都明确指定了 $\\sigma_{\\eta}$ 和 $\\tau$，并给出了 $A$ 的对角元（奇异值）。\n\n- 测试 1 (病态，中等噪声): $\\{\\sigma_i\\} = \\{1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005\\}$, $\\sigma_{\\eta} = 0.02$, $\\tau = 1.0$。\n- 测试 2 (病态，高噪声): $\\{\\sigma_i\\} = \\{1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005\\}$, $\\sigma_{\\eta} = 0.10$, $\\tau = 1.0$。\n- 测试 3 (良态，中等噪声): $\\{\\sigma_i\\} = \\{1, 1, 1, 1, 1, 1, 1, 1, 1, 1\\}$, $\\sigma_{\\eta} = 0.02$, $\\tau = 1.0$。\n- 测试 4 (病态，近无噪声): $\\{\\sigma_i\\} = \\{1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005\\}$, $\\sigma_{\\eta} = 10^{-6}$, $\\tau = 1.0$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的结果列表。每个测试用例的结果本身必须是 $[\\lambda, k(\\lambda), \\bar{s}(\\lambda)]$ 形式的列表，其中 $\\lambda$ 和 $\\bar{s}(\\lambda)$ 是浮点数，$k(\\lambda)$ 是整数。例如，整体输出应类似于 $[[\\lambda_1,k_1,\\bar{s}_1],[\\lambda_2,k_2,\\bar{s}_2],[\\lambda_3,k_3,\\bar{s}_3],[\\lambda_4,k_4,\\bar{s}_4]]$。",
            "solution": "该问题要求实现用于线性反问题的零阶 Tikhonov 正则化，其中正则化参数 $\\lambda$ 由 Morozov 差异原则确定。任务的核心是为几个测试用例确定性地设置问题，求解 $\\lambda$，然后量化由此产生的对小奇异值对应模态的抑制。\n\n线性反问题由 $A x = b$ 给出，其中数据向量 $b$ 被加性噪声污染：$b = A x_{\\mathrm{true}} + \\eta$。零阶 Tikhonov 正则化通过最小化泛函\n$$J(x) = \\|A x - b\\|_2^2 + \\lambda^2 \\|x\\|_2^2$$\n来寻找一个稳定的近似解，其中 $\\lambda \\ge 0$ 是正则化参数。假设 $A$ 具有满列秩，$J(x)$ 的唯一最小化子 $x_{\\lambda}$ 是正规方程 $(A^\\top A + \\lambda^2 I) x = A^\\top b$ 的解。这得出\n$$x_{\\lambda} = (A^\\top A + \\lambda^2 I)^{-1} A^\\top b$$\n\n在本问题的特定背景下，矩阵 $A$ 是一个对角的 $n \\times n$ 矩阵，其对角元是奇异值 $\\sigma_i$。因此，$A = \\Sigma = \\mathrm{diag}(\\sigma_1, \\dots, \\sigma_n)$。其奇异值分解 (SVD) 是平凡的，有 $U = V = I_n$。将此代入 $x_{\\lambda}$ 的表达式可极大地简化计算：\n$$A^\\top A = \\Sigma^\\top \\Sigma = \\Sigma^2 = \\mathrm{diag}(\\sigma_1^2, \\dots, \\sigma_n^2)$$\n$$x_{\\lambda} = (\\Sigma^2 + \\lambda^2 I)^{-1} \\Sigma b$$\n这是一个对角系统，因此解可以按分量表示：\n$$(x_{\\lambda})_i = \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda^2} b_i$$\n\nMorozov 差异原则为选择 $\\lambda$ 提供了一个规则。它指出，应选择 $\\lambda$ 使得残差向量 $r(\\lambda) = A x_{\\lambda} - b$ 的范数与期望噪声水平相关的目标值相匹配。该原则正式表述为：\n$$\\|A x_{\\lambda} - b\\|_2 = \\delta$$\n其中 $\\delta = \\tau \\sqrt{m} \\, \\sigma_{\\eta}$ 是目标残差范数。这里，$m$ 是 $A$ 的行数，$\\sigma_{\\eta}$ 是噪声分量的标准差，$\\tau$ 是一个给定的因子。\n\n为应用此原则，我们首先推导出残差范数关于 $\\lambda$ 的显式表达式。残差的第 i 个分量是：\n$$(A x_{\\lambda} - b)_i = \\sigma_i (x_{\\lambda})_i - b_i = \\sigma_i \\left( \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda^2} b_i \\right) - b_i = \\left( \\frac{\\sigma_i^2}{\\sigma_i^2 + \\lambda^2} - 1 \\right) b_i = -\\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2} b_i$$\n残差向量的欧几里得范数的平方则为：\n$$\\|A x_{\\lambda} - b\\|_2^2 = \\sum_{i=1}^n \\left( \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2} \\right)^2 b_i^2$$\n这个表达式定义了一个关于 $\\lambda$ 的函数。令 $f(\\lambda) = \\|A x_{\\lambda} - b\\|_2$。对于 $\\lambda \\ge 0$，函数 $f(\\lambda)$ 是单调递增的，且 $f(0) = 0$ (因为对于所有 $i$，$\\sigma_i  0$，所以 $A$ 是可逆的) 并且 $\\lim_{\\lambda \\to \\infty} f(\\lambda) = \\|b\\|_2$。因此，对于在范围 $(0, \\|b\\|_2)$ 内的目标值 $\\delta$，存在一个唯一的 $\\lambda  0$ 满足差异原则。\n\n任务是求解标量方程 $f(\\lambda) = \\delta$，或者等价地 $g(\\lambda) = f(\\lambda) - \\delta = 0$。这个非线性方程可以使用一个稳健的求根算法进行数值求解。鉴于 $f(\\lambda)$ 的单调性，Brent 方法是一个极好的选择，因为它能保证收敛，只要找到一个初始区间 $[\\lambda_{min}, \\lambda_{max}]$ 使得 $g(\\lambda_{min})$ 和 $g(\\lambda_{max})$ 异号。我们可以为 $\\lambda_{min}$ 使用一个小的正数（例如，$10^{-12}$），此时 $g(\\lambda_{min}) \\approx -\\delta  0$。对于 $\\lambda_{max}$，一个足够大的值将确保 $f(\\lambda_{max}) \\approx \\|b\\|_2$，使得 $g(\\lambda_{max})  0$（假设 $\\delta  \\|b\\|_2$，这是符合预期的）。\n\n一旦为给定的测试用例确定了 $\\lambda$ 的值，我们就量化与小奇异值相关联的模态的抑制情况。第 $i$ 个模态的逐模态抑制因子由 $s_i(\\lambda) = \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2}$ 给出。如果一个模态对应的奇异值 $\\sigma_i$ 小于或等于正则化参数的一个分数，具体为 $\\sigma_i \\le \\alpha \\lambda$ 且 $\\alpha = 0.1$，则该模态被定义为“强抑制”。所需输出为：\n1. 强抑制模态的计数，$k(\\lambda) = \\#\\{i : \\sigma_i \\le 0.1 \\lambda\\}$。\n2. 这些模态的平均抑制，$\\bar{s}(\\lambda) = \\frac{1}{k(\\lambda)} \\sum_{\\{i : \\sigma_i \\le 0.1 \\lambda\\}} s_i(\\lambda)$，约定如果 $k(\\lambda)=0$ 则 $\\bar{s}(\\lambda) = 0$。\n\n每个测试用例的整体算法如下：\n1. 构造问题参数：设置 $m=n=10$。构造真实信号 $x_{\\mathrm{true}}$，其分量为 $(x_{\\mathrm{true}})_i = 1/i$。构造噪声模板向量 $w$，其分量为 $w_j = \\sin(j) + 0.5 \\cos(2j)$。\n2. 对于给定的奇异值 $\\{\\sigma_i\\}$、噪声水平 $\\sigma_{\\eta}$ 和差异因子 $\\tau$：\n    a. 构成对角矩阵 $A = \\mathrm{diag}(\\sigma_1, \\dots, \\sigma_{10})$。\n    b. 计算目标残差范数 $\\delta = \\tau \\sqrt{m} \\sigma_{\\eta}$。\n    c. 构造噪声向量 $\\eta = w \\cdot (\\sqrt{m} \\sigma_{\\eta} / \\|w\\|_2)$。\n    d. 构造数据向量 $b = A x_{\\mathrm{true}} + \\eta$。\n3. 定义函数 $g(\\lambda) = \\left( \\sum_{i=1}^n \\left( \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2} \\right)^2 b_i^2 \\right)^{1/2} - \\delta$。\n4. 使用数值求根器（Brent 方法）求解 $g(\\lambda) = 0$ 以得到 $\\lambda  0$。\n5. 使用求得的 $\\lambda$，根据其定义计算 $k(\\lambda)$ 和 $\\bar{s}(\\lambda)$。\n6. 为该测试用例组合结果 $[\\lambda, k(\\lambda), \\bar{s}(\\lambda)]$。\n对问题陈述中提供的所有测试用例重复此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Solves the Tikhonov regularization problem with Morozov's discrepancy\n    principle for a set of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005]), 0.02, 1.0),\n        (np.array([1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005]), 0.10, 1.0),\n        (np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), 0.02, 1.0),\n        (np.array([1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005]), 1e-6, 1.0)\n    ]\n\n    # Universal problem parameters\n    m = 10\n    n = 10\n    alpha = 0.1\n\n    # Construct the true signal x_true\n    x_true = 1.0 / np.arange(1, n + 1)\n\n    # Construct the noise template vector w\n    j = np.arange(1, m + 1)\n    w = np.sin(j) + 0.5 * np.cos(2 * j)\n    w_norm = np.linalg.norm(w)\n    \n    results = []\n\n    for case in test_cases:\n        sigmas, sigma_eta, tau = case\n\n        # 1. Construct problem-specific vectors and matrices\n        A = np.diag(sigmas)\n        \n        # Target residual norm from Morozov's principle\n        delta = tau * np.sqrt(m) * sigma_eta\n        \n        # Construct the noise vector eta\n        eta = w * (np.sqrt(m) * sigma_eta / w_norm)\n        \n        # Construct the data vector b\n        b = A @ x_true + eta\n        \n        # 2. Find the regularization parameter lambda\n        def residual_norm_func(lmbda):\n            # Calculates ||A * x_lambda - b||_2\n            if lmbda == 0:\n                return 0.0\n            \n            # Since A is diagonal, A*x_lambda - b has components\n            # - (lmbda^2 / (sigma_i^2 + lmbda^2)) * b_i\n            # The norm calculation squares these components, so the sign doesn't matter.\n            filter_factors = (lmbda**2) / (sigmas**2 + lmbda**2)\n            residual_components = filter_factors * b\n            return np.linalg.norm(residual_components)\n\n        def g(lmbda):\n            # Function to find the root of: ||A * x_lambda - b|| - delta = 0\n            return residual_norm_func(lmbda) - delta\n\n        # Find a bracketing interval for the root finder\n        # g(lambda->0) -> -delta  0\n        # g(lambda->inf) -> ||b|| - delta > 0\n        # We need a large enough upper bound for the bracket.\n        # A value like 100 is usually sufficient.\n        lambda_min_bracket = 1e-12\n        lambda_max_bracket = 100 \n        \n        # Check if upper bracket is valid\n        if g(lambda_max_bracket)  0:\n            # If our initial guess for the bracket is too small, increase it\n            # to a much larger value to ensure the function becomes positive.\n            lambda_max_bracket = 1e6\n\n        lambda_val = brentq(g, lambda_min_bracket, lambda_max_bracket)\n\n        # 3. Quantify suppression of small-singular-value modes\n        \n        # Find indices of strongly suppressed modes\n        suppressed_indices = np.where(sigmas = alpha * lambda_val)[0]\n        \n        # Count of strongly suppressed modes\n        k_lambda = len(suppressed_indices)\n        \n        # Average suppression factor\n        if k_lambda == 0:\n            s_bar_lambda = 0.0\n        else:\n            # s_i(lambda) = lambda^2 / (sigma_i^2 + lambda^2)\n            suppressed_sigmas = sigmas[suppressed_indices]\n            suppression_factors = lambda_val**2 / (suppressed_sigmas**2 + lambda_val**2)\n            s_bar_lambda = np.mean(suppression_factors)\n            \n        results.append([lambda_val, k_lambda, s_bar_lambda])\n\n    # Final print statement in the exact required format.\n    # The format required is a list of lists.\n    # The default string representation of a list is what's needed.\n    # The precision of floats is determined by numpy's default string conversion.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "小奇异值引起的不稳定性问题不仅存在于经典的最小二乘框架中，在贝叶斯推断中也扮演着关键角色。本练习从贝叶斯视角探讨了这个问题，要求您分析不恰当的先验分布何时会导致后验分布“病态”（即无法归一化）。通过区分不同的情况，您将深入理解为何正定先验（proper prior）能像正则化一样，即使在正向算子存在零空间或近似零空间时，也能保证后验分布的良态性 。",
            "id": "3391328",
            "problem": "考虑带有加性高斯噪声的线性逆模型，其关系式定义为 $y = A x + \\varepsilon$，其中 $A \\in \\mathbb{R}^{m \\times n}$，$x \\in \\mathbb{R}^{n}$，$y \\in \\mathbb{R}^{m}$，且 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_m)$，噪声水平 $\\sigma  0$ 已知。在数据同化中采用贝叶斯观点，其中 $x$ 的先验分布为非正常平坦先验 $p(x) \\propto 1$ 或精度为 $\\alpha  0$ 的正常高斯先验 $x \\sim \\mathcal{N}(0, \\alpha^{-1} I_n)$。在非正常平坦先验下，后验密度与似然 $p(y \\mid x) \\propto \\exp\\left( -\\|A x - y\\|_2^2 / (2 \\sigma^2) \\right)$ 成正比。\n\n你的任务是构造并分析一些示例，用以凸显在非正常平坦先验下，由正向算子 $A$ 的小奇异值引起的不稳定性，展示后验在何种情况下是不适定的（即不可归一化），以及在何种情况下因近零空间方向而导致数值不稳定。使用 $A$ 的奇异值分解（SVD）来推断后验的可积性和稳定性。你编写的程序必须对每个测试用例按如下方式对后验进行分类：\n\n- 如果在非正常平坦先验下的后验是不适定的（后验密度在 $x$ 上的积分不为有限值），则输出整数 $0$。\n- 如果在非正常平坦先验下的后验是适定的，但由于存在小的奇异值（由最小奇异值的阈值决定）而导致数值不稳定，则输出整数 $1$。\n- 如果在非正常平坦先验下的后验是适定的且数值稳定（所有奇异值均超过阈值），则输出整数 $2$。\n- 如果使用正常高斯先验，并且后验依构造是适定的（即使 $A$ 中存在零空间方向），则输出整数 $3$。\n\n从贝叶斯定理、高斯似然、线性变换和标准正交变量代换的性质等基本定义出发。你不能依赖任何预先提供的目标公式；必须从这些基础出发推导出所有必要条件。\n\n使用以下规范实现决策过程：\n- 对于非正常平坦先验的情况，后验是可归一化的当且仅当矩阵 $A$ 具有满列秩，这等价于 $A$ 的所有 $n$ 个奇异值都严格为正且 $m \\ge n$。对于数值稳定性，引入一个阈值 $\\tau  0$，如果最小奇异值小于 $\\tau$，则判定为不稳定。\n- 对于正常高斯先验 $x \\sim \\mathcal{N}(0, \\alpha^{-1} I_n)$ 的情况，由于增加了先验精度 $\\alpha  0$，后验对于任何 $A$ 以及任何 $m, n$ 都是适定的。将此类情况分类为 $3$。\n\n测试套件：\n- 案例 1（适定且稳定的非正常先验）：$m = 3$，$n = 3$，$A = \\mathrm{diag}(1, \\tfrac{1}{4}, \\tfrac{1}{10})$，$y = (1, -1, 0)^\\top$，$\\sigma = 10^{-2}$，$\\tau = 10^{-8}$，非正常平坦先验。\n- 案例 2（因零空间导致不适定的非正常先验）：$m = 2$，$n = 3$，$A = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix}$，$y = (0, 0)^\\top$，$\\sigma = 10^{-2}$，$\\tau = 10^{-8}$，非正常平坦先验。\n- 案例 3（因近零空间方向导致适定但数值不稳定的非正常先验）：$m = 3$，$n = 3$，$A = \\mathrm{diag}(1, 10^{-9}, \\tfrac{1}{2})$，$y = (0, 0, 0)^\\top$，$\\sigma = 10^{-2}$，$\\tau = 10^{-8}$，非正常平坦先验。\n- 案例 4（因欠定系统导致不适定的非正常先验）：$m = 3$，$n = 4$，$A = \\begin{pmatrix} 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  1  0 \\end{pmatrix}$，$y = (1, 2, 3)^\\top$，$\\sigma = 10^{-2}$，$\\tau = 10^{-8}$，非正常平坦先验。\n- 案例 5（正常高斯先验下的适定后验）：使用与案例 2 相同的 $A$ 和维度，但采用正常高斯先验 $x \\sim \\mathcal{N}(0, \\alpha^{-1} I_3)$，其中 $\\alpha = 10$，$y = (0, 0)^\\top$，$\\sigma = 10^{-2}$，$\\tau = 10^{-8}$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表（例如，$[result_1, result_2, result_3, result_4, result_5]$），每个 $result_i$ 是上面定义的整数 $0$、$1$、$2$ 或 $3$ 之一。",
            "solution": "问题要求在线性贝叶斯逆问题中分析后验分布，重点关注后验分布适定且数值稳定的条件。给定模型 $y = A x + \\varepsilon$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是正向算子，$x \\in \\mathbb{R}^{n}$ 是未知参数向量，$y \\in \\mathbb{R}^{m}$ 是数据向量，$\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_m)$ 是方差 $\\sigma^2 > 0$ 已知的加性高斯噪声。\n\n分析取决于对 $x$ 的先验分布 $p(x)$ 的选择。我们将从基本原理，特别是贝叶斯定理，推导出后验适定且稳定的条件。贝叶斯定理指出，后验概率密度与似然和先验的乘积成正比：\n$$p(x \\mid y) \\propto p(y \\mid x) p(x)$$\n\n似然函数 $p(y \\mid x)$ 由噪声模型确定。由于 $\\varepsilon = y - Ax$ 且 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_m)$，似然是一个多元高斯函数：\n$$p(y \\mid x) = \\frac{1}{(2\\pi\\sigma^2)^{m/2}} \\exp\\left( -\\frac{1}{2\\sigma^2} \\|y - Ax\\|_2^2 \\right)$$\n\n我们根据先验的选择考虑两种情况。\n\n**情况 1：非正常平坦先验**\n\n在这种情况下，假设先验在 $\\mathbb{R}^n$ 上是均匀的，即 $p(x) \\propto 1$。这是一个“非正常”先验，因为它在 $\\mathbb{R}^n$ 上的积分不是有限的。所得后验的有效性取决于似然函数本身是否可积。\n\n后验密度与似然成正比：\n$$p(x \\mid y) \\propto \\exp\\left( -\\frac{1}{2\\sigma^2} \\|Ax - y\\|_2^2 \\right)$$\n为使该后验“适定”或“可归一化”，其在 $x$ 所有可能值上的积分必须是有限的：\n$$Z = \\int_{\\mathbb{R}^n} \\exp\\left( -\\frac{1}{2\\sigma^2} \\|Ax - y\\|_2^2 \\right) dx  \\infty$$\n$Z$ 是归一化常数，也称为证据（evidence）。指数中包含一个关于 $x$ 的二次型：\n$$\\|Ax - y\\|_2^2 = (Ax - y)^\\top(Ax - y) = x^\\top A^\\top A x - 2y^\\top A x + y^\\top y$$\n积分 $\\int_{\\mathbb{R}^n} \\exp(-\\frac{1}{2\\sigma^2}(x^\\top A^\\top A x - 2y^\\top A x + y^\\top y)) dx$ 具有多元高斯积分的形式。这样的积分收敛当且仅当二次项的矩阵 $A^\\top A$ 是正定的。\n\n为了分析 $n \\times n$ 矩阵 $A^\\top A$ 的性质，我们使用 $A$ 的奇异值分解 (SVD)。设 $A = U S V^\\top$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$S \\in \\mathbb{R}^{m \\times n}$ 是包含奇异值 $s_1 \\ge s_2 \\ge \\dots \\ge 0$ 的矩形对角矩阵。\n将 SVD 代入 $A^\\top A$ 的表达式中：\n$$A^\\top A = (U S V^\\top)^\\top (U S V^\\top) = V S^\\top U^\\top U S V^\\top = V (S^\\top S) V^\\top$$\n这表明 $A^\\top A$ 与 $S^\\top S$ 相似。$S^\\top S$ 是一个 $n \\times n$ 的对角矩阵，其对角线元素对于 $i=1, \\dots, \\min(m, n)$ 是 $s_i^2$，其余为零。因此 $A^\\top A$ 的特征值是 $s_i^2 \\ge 0$。\n\n为使 $A^\\top A$ 正定，其所有特征值必须严格为正。这要求其所有 $n$ 个特征值都大于 $0$。这仅在 $A$ 具有满列秩，即 $\\text{rank}(A) = n$ 时才可能。这隐含了两个条件：\n1.  行数必须至少等于列数，即 $m \\ge n$。如果 $m  n$，则 $A$ 的秩最多为 $m$，因此 $A^\\top A$ 将至少有 $n-m$ 个零特征值。\n2.  $A$ 的所有 $n$ 个奇异值都必须严格为正，即 $s_n > 0$。\n\n如果 $\\text{rank}(A)  n$，则 $A$ 存在一个非平凡零空间。零空间 $\\mathcal{N}(A)$ 中的任何向量 $x_0$ 都满足 $Ax_0 = 0$。后验密度沿着零空间中的任何方向都变为常数，沿此无限方向积分会得到一个发散的积分。因此，后验是不适定的。这对应于**分类 $0$**。\n\n如果 $\\text{rank}(A) = n$，则后验是适定的。解的稳定性随后由 $A^\\top A$ 的条件数决定。相应最小二乘问题 $x_{LS} = (A^\\top A)^{-1} A^\\top y$ 的解涉及 $A^\\top A$ 的逆，其特征值为 $1/s_i^2$。如果任何奇异值 $s_i$ 非常小（但非零），相应的特征值 $1/s_i^2$ 就会非常大。这表明数据 $y$ 中的微小扰动，经 $1/s_i$ 放大后，可能导致解 $x$ 发生巨大变化，这是数值不稳定的一个标志。\n遵循问题的规范，我们使用一个阈值 $\\tau  0$。\n- 如果最小奇异值 $\\min(s_i)  \\tau$，问题是适定的但数值不稳定。这对应于**分类 $1$**。\n- 如果 $\\min(s_i) \\ge \\tau$，问题是适定的且数值稳定。这对应于**分类 $2$**。\n\n**情况 2：正常高斯先验**\n\n这里，先验是 $x \\sim \\mathcal{N}(0, \\alpha^{-1} I_n)$，其中精度 $\\alpha > 0$。先验密度为：\n$$p(x) \\propto \\exp\\left( -\\frac{\\alpha}{2} \\|x\\|_2^2 \\right) = \\exp\\left( -\\frac{\\alpha}{2} x^\\top x \\right)$$\n后验密度为：\n$$p(x \\mid y) \\propto \\exp\\left( -\\frac{1}{2\\sigma^2} \\|Ax - y\\|_2^2 \\right) \\exp\\left( -\\frac{\\alpha}{2} \\|x\\|_2^2 \\right)$$\n$$p(x \\mid y) \\propto \\exp\\left( -\\frac{1}{2} \\left( \\frac{1}{\\sigma^2} \\|Ax - y\\|_2^2 + \\alpha \\|x\\|_2^2 \\right) \\right)$$\n指数的自变量是 $x$ 的二次函数。关于 $x$ 的二次项是：\n$$\\frac{1}{\\sigma^2} x^\\top A^\\top A x + \\alpha x^\\top I_n x = x^\\top \\left( \\frac{1}{\\sigma^2} A^\\top A + \\alpha I_n \\right) x$$\n为使后验成为可归一化的高斯分布，矩阵 $H = \\frac{1}{\\sigma^2} A^\\top A + \\alpha I_n$ 必须是正定的。\n我们知道 $A^\\top A$ 是半正定的（其特征值为 $s_i^2 \\ge 0$）。由于 $\\alpha > 0$，矩阵 $\\alpha I_n$ 是正定的（其特征值均为 $\\alpha$）。一个半正定矩阵与一个正定矩阵之和总是正定的。\n因此，对于任何 $A$，无论其秩如何，$H$ 总是正定的。后验总是一个正常的、适定的高斯分布。先验对问题进行了“正则化”，即使在 $A$ 秩亏的情况下，也能确保后验分布的唯一性和稳定性。这种情况被赋予**分类 $3$**。\n\n**将决策逻辑应用于测试用例：**\n\n- **案例 1**：非正常先验。$A = \\mathrm{diag}(1, \\frac{1}{4}, \\frac{1}{10})$，因此 $m=3, n=3$。矩阵具有满秩（$\\text{rank}(A) = 3 = n$）。奇异值为 $1, 0.25, 0.1$。最小奇异值为 $0.1$。给定 $\\tau = 10^{-8}$，我们有 $0.1 \\ge 10^{-8}$。后验是适定且稳定的。**结果：$2$**。\n\n- **案例 2**：非正常先验。$A = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix}$，因此 $m=2, n=3$。由于 $m  n$，秩最多为 $2$。$\\text{rank}(A) = 2  n = 3$。矩阵不具有满列秩。后验是不适定的。**结果：$0$**。\n\n- **案例 3**：非正常先验。$A = \\mathrm{diag}(1, 10^{-9}, \\frac{1}{2})$，因此 $m=3, n=3$。矩阵具有满秩（$\\text{rank}(A) = 3 = n$）。奇异值为 $1, 0.5, 10^{-9}$。最小奇异值为 $10^{-9}$。给定 $\\tau = 10^{-8}$，我们有 $10^{-9}  10^{-8}$。后验是适定的但数值不稳定。**结果：$1$**。\n\n- **案例 4**：非正常先验。$A = \\begin{pmatrix} 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  1  0 \\end{pmatrix}$，因此 $m=3, n=4$。由于 $m  n$，秩最多为 $3$。$\\text{rank}(A) = 3  n = 4$。矩阵不具有满列秩。后验是不适定的。**结果：$0$**。\n\n- **案例 5**：正常高斯先验。矩阵 $A$ 与案例 $2$ 中相同，是秩亏的。然而，由于使用了正常高斯先验，后验依构造保证是适定的。**结果：$3$**。\n\n最终的程序将实现此决策逻辑。",
            "answer": "```python\nimport numpy as np\n\ndef classify_posterior(A, tau, prior_type):\n    \"\"\"\n    Classifies the posterior distribution based on the properties of the\n    forward operator A and the choice of prior.\n\n    Args:\n        A (np.ndarray): The forward operator matrix.\n        tau (float): The threshold for numerical stability.\n        prior_type (str): The type of prior ('improper' or 'proper').\n\n    Returns:\n        int: The classification code (0, 1, 2, or 3).\n    \"\"\"\n    if prior_type == 'proper':\n        # For a proper Gaussian prior, the posterior is always well-defined.\n        return 3\n\n    # For an improper flat prior, analyze the matrix A.\n    m, n = A.shape\n\n    # The posterior is normalizable if and only if A has full column rank.\n    # We check this using numpy.linalg.matrix_rank.\n    # Note: np.linalg.matrix_rank determines rank by counting singular values\n    # above a tolerance, which is the standard numerical approach.\n    rank = np.linalg.matrix_rank(A)\n\n    if rank  n:\n        # If A is not full column rank, the posterior is ill-defined.\n        return 0\n    else:\n        # If A is full column rank, the posterior is well-defined.\n        # Now check for numerical stability using singular values.\n        # We only need the singular values, not the full SVD.\n        singular_values = np.linalg.svd(A, compute_uv=False)\n        \n        # The smallest singular value determines stability.\n        # For a full-rank square or tall matrix, all singular values are non-zero.\n        min_singular_value = np.min(singular_values)\n\n        if min_singular_value  tau:\n            # Well-defined but numerically unstable.\n            return 1\n        else:\n            # Well-defined and numerically stable.\n            return 2\n\ndef solve():\n    \"\"\"\n    Runs the analysis on the test suite and prints the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"A\": np.diag([1.0, 1.0/4.0, 1.0/10.0]),\n            \"tau\": 1e-8,\n            \"prior_type\": \"improper\"\n        },\n        {\n            \"A\": np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]),\n            \"tau\": 1e-8,\n            \"prior_type\": \"improper\"\n        },\n        {\n            \"A\": np.diag([1.0, 1e-9, 0.5]),\n            \"tau\": 1e-8,\n            \"prior_type\": \"improper\"\n        },\n        {\n            \"A\": np.array([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0]]),\n            \"tau\": 1e-8,\n            \"prior_type\": \"improper\"\n        },\n        {\n            \"A\": np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]),\n            \"tau\": 1e-8,\n            \"prior_type\": \"proper\"\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = classify_posterior(case[\"A\"], case[\"tau\"], case[\"prior_type\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}