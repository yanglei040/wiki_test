{
    "hands_on_practices": [
        {
            "introduction": "理论知识告诉我们，小的奇异值会导致解的不稳定。但这种不稳定性究竟有多严重？本练习将通过一个直接的计算来量化这一效应。通过估算在存在观测噪声时解的相对误差，你将亲身体会到即使是很小的输入噪声，在经过一个具有微小奇异值的前向算子反演后，也可能被放大到灾难性的程度，从而建立对病态问题本质的直观理解 。",
            "id": "3391315",
            "problem": "考虑一个欧几里得空间中的线性反问题，其中观测数据向量由 $b = A x_{\\text{true}} + \\eta$ 给出，其中 $A \\in \\mathbb{R}^{m \\times n}$，$x_{\\text{true}} \\in \\mathbb{R}^{n}$，以及加性噪声 $\\eta \\in \\mathbb{R}^{m}$。重建 $x^{\\dagger}$ 定义为通过 Moore–Penrose 伪逆得到的最小范数最小二乘解，即 $x^{\\dagger} = A^{\\dagger} b$。假设 $A$ 的奇异值分解 (SVD) 存在，并且最小的非零奇异值为 $\\sigma_{r} = 10^{-6}$。噪声水平由 $\\|\\eta\\|_{2} / \\|b_{\\text{true}}\\|_{2} = 0.01$ 量化，其中 $b_{\\text{true}} = A x_{\\text{true}}$。为了分离由小奇异值引起的不稳定性，假设问题已被无量纲化，使得与 $b_{\\text{true}}$ 的主要部分相关的有效奇异值为 1 的量级，即 $\\|b_{\\text{true}}\\|_{2} / \\|x_{\\text{true}}\\|_{2} \\approx 1$，并且来自噪声的对解误差的主要贡献与对应于 $\\sigma_{r}$ 的右奇异向量对齐。\n\n仅使用奇异值分解和 Moore–Penrose 伪逆的基本性质，估计仅由噪声引起的重建相对误差的预期数量级，\n$$\n\\frac{\\|x^{\\dagger} - x_{\\text{true}}\\|_{2}}{\\|x_{\\text{true}}\\|_{2}},\n$$\n并将您的答案报告为一个无量纲数。不包括任何单位。除非不可避免，否则无需四舍五入。",
            "solution": "重建 $x^{\\dagger}$ 由 Moore–Penrose 伪逆定义为 $x^{\\dagger} = A^{\\dagger} b$，其中 $b = b_{\\text{true}} + \\eta$ 且 $b_{\\text{true}} = A x_{\\text{true}}$。由加性噪声引起的重建误差为\n$$\nx^{\\dagger} - x_{\\text{true}} = A^{\\dagger}(b_{\\text{true}} + \\eta) - x_{\\text{true}} = A^{\\dagger} A x_{\\text{true}} + A^{\\dagger} \\eta - x_{\\text{true}} = A^{\\dagger} \\eta,\n$$\n因为 $A^{\\dagger} A x_{\\text{true}}$ 是 $x_{\\text{true}}$ 在 $A^{\\top}$ 的值域上的正交投影，对于与 $b_{\\text{true}} \\in \\text{range}(A)$ 一致的最小范数解，它等于 $x_{\\text{true}}$。\n\n设 $A$ 的奇异值分解 (SVD) 为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 的对角线元素为 $\\sigma_{1} \\geq \\sigma_{2} \\geq \\cdots \\geq \\sigma_{r}  0$，其中 $r = \\text{rank}(A)$。Moore–Penrose 伪逆为 $A^{\\dagger} = V \\Sigma^{\\dagger} U^{\\top}$，其中 $\\Sigma^{\\dagger}$ 的对角线元素在 $i \\leq r$ 时为 $\\sigma_{i}^{-1}$，否则为零。\n\n则由噪声引起的误差为\n$$\nx^{\\dagger} - x_{\\text{true}} = V \\Sigma^{\\dagger} U^{\\top} \\eta.\n$$\n取范数可得\n$$\n\\|x^{\\dagger} - x_{\\text{true}}\\|_{2} = \\|V \\Sigma^{\\dagger} U^{\\top} \\eta\\|_{2} = \\|\\Sigma^{\\dagger} U^{\\top} \\eta\\|_{2}.\n$$\n矩阵 $U$ 是正交的，所以 $\\|U^{\\top} \\eta\\|_{2} = \\|\\eta\\|_{2}$。$U^{\\top} \\eta$ 中对应于第 $i$ 个左奇异向量的分量，其放大因子为 $\\sigma_{i}^{-1}$。根据所述假设，即来自噪声对解误差的主要贡献与最小奇异值 $\\sigma_{r}$ 对应的右奇异向量对齐，误差大小由下式决定：\n$$\n\\|x^{\\dagger} - x_{\\text{true}}\\|_{2} \\approx \\frac{\\|\\eta\\|_{2}}{\\sigma_{r}}.\n$$\n我们要求的是相对误差。利用无量纲化假设，即与 $b_{\\text{true}}$ 主要部分相关的有效奇异值为 1 的量级，我们有\n$$\n\\frac{\\|b_{\\text{true}}\\|_{2}}{\\|x_{\\text{true}}\\|_{2}} \\approx 1 \\quad \\Longrightarrow \\quad \\|x_{\\text{true}}\\|_{2} \\approx \\|b_{\\text{true}}\\|_{2}.\n$$\n因此，\n$$\n\\frac{\\|x^{\\dagger} - x_{\\text{true}}\\|_{2}}{\\|x_{\\text{true}}\\|_{2}} \\approx \\frac{\\|\\eta\\|_{2}}{\\sigma_{r} \\|x_{\\text{true}}\\|_{2}} \\approx \\frac{\\|\\eta\\|_{2}}{\\sigma_{r} \\|b_{\\text{true}}\\|_{2}} = \\frac{1}{\\sigma_{r}} \\cdot \\frac{\\|\\eta\\|_{2}}{\\|b_{\\text{true}}\\|_{2}}.\n$$\n代入给定值 $\\sigma_{r} = 10^{-6}$ 和 $\\|\\eta\\|_{2} / \\|b_{\\text{true}}\\|_{2} = 0.01$ 得出\n$$\n\\frac{\\|x^{\\dagger} - x_{\\text{true}}\\|_{2}}{\\|x_{\\text{true}}\\|_{2}} \\approx \\frac{1}{10^{-6}} \\times 0.01 = 10^{6} \\times 10^{-2} = 10^{4}.\n$$\n因此，在分离了来自最小奇异值的不稳定性的特定假设下，仅由噪声引起的重建相对误差的预期数量级为 $1 \\times 10^{4}$。",
            "answer": "$$\\boxed{1 \\times 10^{4}}$$"
        },
        {
            "introduction": "理解了问题的根源后，我们转向寻找解决方案。本实践练习将引导你动手编写代码，实现吉洪诺夫正则化（Tikhonov regularization），这是一种稳定反问题的基石技术。你将通过实施莫罗佐夫差异原则（Morozov’s discrepancy principle）来自动选择正则化参数，并直接观察该方法如何有效抑制被噪声主导的奇异模式 。",
            "id": "3391353",
            "problem": "考虑由方程 $A x = b$ 定义的带加性噪声的线性反问题，其中 $b = A x_{\\mathrm{true}} + \\eta$，噪声向量 $\\eta$ 的分量独立同分布，方差为 $\\sigma_{\\eta}^2$。我们研究零阶 Tikhonov 正则化和 Morozov 偏差原理，以解决由小奇异值引起的不稳定性。假设以下基本前提：最小二乘估计量最小化残差范数的平方，零阶 Tikhonov 正则化针对正则化参数 $\\lambda \\ge 0$ 最小化增广泛函 $J(x) = \\|A x - b\\|_2^2 + \\lambda^2 \\|x\\|_2^2$。矩阵 $A$ 的奇异值分解 (SVD) 定义为 $A = U \\Sigma V^\\top$，其中 $U$ 和 $V$ 是正交矩阵，$\\Sigma$ 是对角矩阵，其非负对角元等于奇异值。Morozov 偏差原理选择 $\\lambda$，使得残差范数 $\\|A x_{\\lambda} - b\\|_2$ 等于一个与噪声水平一致的目标范数。本问题中任何三角函数定义所使用的所有角度都必须以弧度为单位进行解释。\n\n您的任务是实现一个完整且可运行的程序，该程序为每个测试用例确定性地构造矩阵 $A$、干净信号 $x_{\\mathrm{true}}$ 和噪声向量 $\\eta$，根据 Morozov 偏差原理计算正则化参数 $\\lambda$，并量化小奇异值模式的抑制程度。具体而言：\n\n1. 对于零阶 Tikhonov 正则化，当 $A$ 具有满列秩时，将 $x_{\\lambda}$ 定义为 $J(x) = \\|A x - b\\|_2^2 + \\lambda^2 \\|x\\|_2^2$ 的唯一最小化子。对于每个测试用例，确定满足 Morozov 偏差原理的 $\\lambda$，即：\n   $$\\|A x_{\\lambda} - b\\|_2 = \\tau \\sqrt{m} \\, \\sigma_{\\eta},$$\n   其中 $m$ 是 $A$ 的行数，$\\tau  0$ 是一个指定的偏差因子。在下面包含的每个测试中，$\\tau$ 都会明确给出。目标残差范数应使用精确的欧几里得范数 $\\|\\cdot\\|_2$ 进行计算和使用，除了指定的数学量外，不需要任何单位。\n\n2. 量化小奇异值模式的抑制程度。给定 $A$ 的奇异值 $\\{\\sigma_i\\}_{i=1}^n$，将逐模式抑制因子定义为：\n   $$s_i(\\lambda) = \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2},$$\n   如果 $\\sigma_i \\le \\alpha \\lambda$ 且阈值 $\\alpha = 0.1$，则将一个模式解释为被强抑制。对于每个测试用例，计算：\n   - 强抑制模式的数量 $k(\\lambda) = \\#\\{i : \\sigma_i \\le 0.1 \\lambda\\}$，\n   - 强抑制模式的平均抑制程度：\n     $$\\bar{s}(\\lambda) = \\frac{1}{k(\\lambda)} \\sum_{\\{i : \\sigma_i \\le 0.1 \\lambda\\}} s_i(\\lambda),$$\n     约定当 $k(\\lambda) = 0$ 时 $\\bar{s}(\\lambda) = 0$。\n\n测试套件中 $A$、$x_{\\mathrm{true}}$ 和 $\\eta$ 的构造必须遵循以下确定性规则：\n- 在所有测试用例中，$A$ 都是方阵，其中 $m = n = 10$，且为对角矩阵，其对角元等于指定的奇异值 $\\{\\sigma_i\\}_{i=1}^{10}$。因此，$A = \\mathrm{diag}(\\sigma_1, \\dots, \\sigma_{10})$，所以奇异值分解 (SVD) 具有 $U = I_{10}$、$V = I_{10}$ 和 $\\Sigma = \\mathrm{diag}(\\sigma_1, \\dots, \\sigma_{10})$。\n- 干净信号必须选择为 $x_{\\mathrm{true}} = (1, \\tfrac{1}{2}, \\tfrac{1}{3}, \\dots, \\tfrac{1}{10})^\\top$。\n- 噪声向量必须根据模板向量 $w \\in \\mathbb{R}^{10}$ 确定性地构造，其分量由 $w_j = \\sin(j) + \\tfrac{1}{2} \\cos(2 j)$ 定义（$j = 1, 2, \\dots, 10$），所有角度均以弧度为单位。通过设置以下公式将此模板归一化以满足 $\\|\\eta\\|_2 = \\sqrt{m}\\, \\sigma_{\\eta}$：\n  $$\\eta = w \\cdot \\frac{\\sqrt{m}\\, \\sigma_{\\eta}}{\\|w\\|_2}.$$\n- 数据向量为 $b = A x_{\\mathrm{true}} + \\eta$。\n\n程序必须通过使用无需用户输入的鲁棒数值方法求解上述第 1 项中的标量方程来计算 $\\lambda$。残差范数必须精确计算为 $A x_{\\lambda} - b$ 的欧几里得范数。\n\n测试套件：\n为以下四个测试用例提供结果，每个用例的 $m = n = 10$，并使用与上述相同的 $x_{\\mathrm{true}}$ 和噪声构造规则。对于每个用例，都明确指定了 $\\sigma_{\\eta}$ 和 $\\tau$，并给出了 $A$ 的对角元（奇异值）。\n\n- 测试 1 (病态，中等噪声): $\\{\\sigma_i\\} = \\{1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005\\}$, $\\sigma_{\\eta} = 0.02$, $\\tau = 1.0$。\n- 测试 2 (病态，高噪声): $\\{\\sigma_i\\} = \\{1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005\\}$, $\\sigma_{\\eta} = 0.10$, $\\tau = 1.0$。\n- 测试 3 (良态，中等噪声): $\\{\\sigma_i\\} = \\{1, 1, 1, 1, 1, 1, 1, 1, 1, 1\\}$, $\\sigma_{\\eta} = 0.02$, $\\tau = 1.0$。\n- 测试 4 (病态，近无噪声): $\\{\\sigma_i\\} = \\{1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005\\}$, $\\sigma_{\\eta} = 10^{-6}$, $\\tau = 1.0$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。每个测试用例的结果本身必须是一个形式为 $[\\lambda, k(\\lambda), \\bar{s}(\\lambda)]$ 的列表，其中 $\\lambda$ 和 $\\bar{s}(\\lambda)$ 是浮点数，$k(\\lambda)$ 是整数。例如，整体输出应类似于 $[[\\lambda_1,k_1,\\bar{s}_1],[\\lambda_2,k_2,\\bar{s}_2],[\\lambda_3,k_3,\\bar{s}_3],[\\lambda_4,k_4,\\bar{s}_4]]$。",
            "solution": "该问题要求实现用于线性反问题的零阶 Tikhonov 正则化，其中正则化参数 $\\lambda$ 由 Morozov 偏差原理确定。任务的核心是为几个测试用例确定性地设置问题，求解 $\\lambda$，然后量化由此产生的对小奇异值对应模式的抑制程度。\n\n线性反问题由 $A x = b$ 给出，其中数据向量 $b$ 受到加性噪声的污染：$b = A x_{\\mathrm{true}} + \\eta$。零阶 Tikhonov 正则化旨在通过最小化泛函来寻找一个稳定的近似解\n$$J(x) = \\|A x - b\\|_2^2 + \\lambda^2 \\|x\\|_2^2$$\n其中 $\\lambda \\ge 0$ 是正则化参数。假设 $A$ 具有满列秩，$J(x)$ 的唯一最小化子 $x_{\\lambda}$ 是正规方程组 $(A^\\top A + \\lambda^2 I) x = A^\\top b$ 的解。这得出\n$$x_{\\lambda} = (A^\\top A + \\lambda^2 I)^{-1} A^\\top b$$\n\n在本问题的特定背景下，矩阵 $A$ 是一个对角的 $n \\times n$ 矩阵，其对角元是奇异值 $\\sigma_i$。因此，$A = \\Sigma = \\mathrm{diag}(\\sigma_1, \\dots, \\sigma_n)$。奇异值分解 (SVD) 是平凡的，有 $U = V = I_n$。将此代入 $x_{\\lambda}$ 的表达式可显著简化计算：\n$$A^\\top A = \\Sigma^\\top \\Sigma = \\Sigma^2 = \\mathrm{diag}(\\sigma_1^2, \\dots, \\sigma_n^2)$$\n$$x_{\\lambda} = (\\Sigma^2 + \\lambda^2 I)^{-1} \\Sigma b$$\n这是一个对角系统，因此解可以逐分量表示：\n$$(x_{\\lambda})_i = \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda^2} b_i$$\n\nMorozov 偏差原理提供了一个选择 $\\lambda$ 的规则。它指出，应选择 $\\lambda$，使得残差向量 $r(\\lambda) = A x_{\\lambda} - b$ 的范数与期望噪声水平相关的目标值相匹配。该原理正式表述为：\n$$\\|A x_{\\lambda} - b\\|_2 = \\delta$$\n其中 $\\delta = \\tau \\sqrt{m} \\, \\sigma_{\\eta}$ 是目标残差范数。这里，$m$ 是 $A$ 的行数，$\\sigma_{\\eta}$ 是噪声分量的标准差，$\\tau$ 是一个给定因子。\n\n为应用此原理，我们首先推导残差范数关于 $\\lambda$ 的显式表达式。残差的第 $i$ 个分量是：\n$$(A x_{\\lambda} - b)_i = \\sigma_i (x_{\\lambda})_i - b_i = \\sigma_i \\left( \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda^2} b_i \\right) - b_i = \\left( \\frac{\\sigma_i^2}{\\sigma_i^2 + \\lambda^2} - 1 \\right) b_i = -\\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2} b_i$$\n于是，残差向量的欧几里得范数平方为：\n$$\\|A x_{\\lambda} - b\\|_2^2 = \\sum_{i=1}^n \\left( \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2} \\right)^2 b_i^2$$\n这个表达式定义了一个关于 $\\lambda$ 的函数。令 $f(\\lambda) = \\|A x_{\\lambda} - b\\|_2$。函数 $f(\\lambda)$ 对于 $\\lambda \\ge 0$ 是单调递增的，有 $f(0) = 0$（因为对所有 $i$ 都有 $\\sigma_i  0$，$A$ 是可逆的）并且 $\\lim_{\\lambda \\to \\infty} f(\\lambda) = \\|b\\|_2$。因此，对于范围在 $(0, \\|b\\|_2)$ 内的目标值 $\\delta$，存在一个唯一的 $\\lambda  0$ 满足偏差原理。\n\n任务是求解标量方程 $f(\\lambda) = \\delta$，或等价地求解 $g(\\lambda) = f(\\lambda) - \\delta = 0$。这个非线性方程可以使用鲁棒的求根算法进行数值求解。鉴于 $f(\\lambda)$ 的单调性，Brent 方法是一个绝佳的选择，因为它能保证收敛，前提是能找到一个初始区间 $[\\lambda_{min}, \\lambda_{max}]$ 使得 $g(\\lambda_{min})$ 和 $g(\\lambda_{max})$ 异号。我们可以为 $\\lambda_{min}$ 使用一个小的正数（例如 $10^{-12}$），此时 $g(\\lambda_{min}) \\approx -\\delta  0$。对于 $\\lambda_{max}$，一个足够大的值将确保 $f(\\lambda_{max}) \\approx \\|b\\|_2$，使得 $g(\\lambda_{max})  0$（假设 $\\delta  \\|b\\|_2$，这是符合预期的）。\n\n一旦为给定测试用例确定了 $\\lambda$ 的值，我们便量化与小奇异值相关的模式的抑制程度。第 $i$ 个模式的逐模式抑制因子由 $s_i(\\lambda) = \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2}$ 给出。如果一个模式对应的奇异值 $\\sigma_i$ 小于或等于正则化参数的一个分数，具体为 $\\sigma_i \\le \\alpha \\lambda$ 且 $\\alpha = 0.1$，则该模式被定义为“强抑制”。要求的输出是：\n1. 强抑制模式的数量，$k(\\lambda) = \\#\\{i : \\sigma_i \\le 0.1 \\lambda\\}$。\n2. 这些模式的平均抑制程度，$\\bar{s}(\\lambda) = \\frac{1}{k(\\lambda)} \\sum_{\\{i : \\sigma_i \\le 0.1 \\lambda\\}} s_i(\\lambda)$，约定当 $k(\\lambda)=0$ 时 $\\bar{s}(\\lambda) = 0$。\n\n每个测试用例的总体算法如下：\n1. 构造问题参数：设置 $m=n=10$。构造真实信号 $x_{\\mathrm{true}}$，其分量为 $(x_{\\mathrm{true}})_i = 1/i$。构造噪声模板向量 $w$，其分量为 $w_j = \\sin(j) + 0.5 \\cos(2j)$。\n2. 对于给定的奇异值 $\\{\\sigma_i\\}$、噪声水平 $\\sigma_{\\eta}$ 和偏差因子 $\\tau$：\n    a. 构造对角矩阵 $A = \\mathrm{diag}(\\sigma_1, \\dots, \\sigma_{10})$。\n    b. 计算目标残差范数 $\\delta = \\tau \\sqrt{m} \\sigma_{\\eta}$。\n    c. 构造噪声向量 $\\eta = w \\cdot (\\sqrt{m} \\sigma_{\\eta} / \\|w\\|_2)$。\n    d. 构造数据向量 $b = A x_{\\mathrm{true}} + \\eta$。\n3. 定义函数 $g(\\lambda) = \\left( \\sum_{i=1}^n \\left( \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2} \\right)^2 b_i^2 \\right)^{1/2} - \\delta$。\n4. 使用数值求根器（Brent 方法）求解 $g(\\lambda) = 0$ 以得到 $\\lambda  0$。\n5. 使用获得的 $\\lambda$，根据其定义计算 $k(\\lambda)$ 和 $\\bar{s}(\\lambda)$。\n6. 为该测试用例组装结果 $[\\lambda, k(\\lambda), \\bar{s}(\\lambda)]$。\n对问题陈述中提供的所有测试用例重复此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Solves the Tikhonov regularization problem with Morozov's discrepancy\n    principle for a set of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005]), 0.02, 1.0),\n        (np.array([1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005]), 0.10, 1.0),\n        (np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), 0.02, 1.0),\n        (np.array([1.5, 1.0, 0.7, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005]), 1e-6, 1.0)\n    ]\n\n    # Universal problem parameters\n    m = 10\n    n = 10\n    alpha = 0.1\n\n    # Construct the true signal x_true\n    x_true = 1.0 / np.arange(1, n + 1)\n\n    # Construct the noise template vector w\n    j = np.arange(1, m + 1)\n    w = np.sin(j) + 0.5 * np.cos(2 * j)\n    w_norm = np.linalg.norm(w)\n    \n    results = []\n\n    for case in test_cases:\n        sigmas, sigma_eta, tau = case\n\n        # 1. Construct problem-specific vectors and matrices\n        A = np.diag(sigmas)\n        \n        # Target residual norm from Morozov's principle\n        delta = tau * np.sqrt(m) * sigma_eta\n        \n        # Construct the noise vector eta\n        eta = w * (np.sqrt(m) * sigma_eta / w_norm)\n        \n        # Construct the data vector b\n        b = A @ x_true + eta\n        \n        # 2. Find the regularization parameter lambda\n        def residual_norm_func(lmbda):\n            # Calculates ||A * x_lambda - b||_2\n            if lmbda == 0:\n                return 0.0\n            \n            # Since A is diagonal, A*x_lambda - b has components\n            # - (lmbda^2 / (sigma_i^2 + lmbda^2)) * b_i\n            # The norm calculation squares these components, so the sign doesn't matter.\n            filter_factors = (lmbda**2) / (sigmas**2 + lmbda**2)\n            residual_components = filter_factors * b\n            return np.linalg.norm(residual_components)\n\n        def g(lmbda):\n            # Function to find the root of: ||A * x_lambda - b|| - delta = 0\n            return residual_norm_func(lmbda) - delta\n\n        # Find a bracketing interval for the root finder\n        # g(lambda->0) -> -delta  0\n        # g(lambda->inf) -> ||b|| - delta > 0\n        # We need a large enough upper bound for the bracket.\n        # A value like 10 * max(sigmas) is usually sufficient.\n        lambda_min_bracket = 1e-12\n        lambda_max_bracket = 100 \n        \n        # Check if upper bracket is valid\n        if g(lambda_max_bracket)  0:\n            # If our initial guess for the bracket is too small, increase it\n            lambda_max_bracket = np.linalg.norm(b) # A very large lambda makes residual norm approach ||b||\n\n        lambda_val = brentq(g, lambda_min_bracket, lambda_max_bracket)\n\n        # 3. Quantify suppression of small-singular-value modes\n        \n        # Find indices of strongly suppressed modes\n        suppressed_indices = np.where(sigmas = alpha * lambda_val)[0]\n        \n        # Count of strongly suppressed modes\n        k_lambda = len(suppressed_indices)\n        \n        # Average suppression factor\n        if k_lambda == 0:\n            s_bar_lambda = 0.0\n        else:\n            # s_i(lambda) = lambda^2 / (sigma_i^2 + lambda^2)\n            suppressed_sigmas = sigmas[suppressed_indices]\n            suppression_factors = lambda_val**2 / (suppressed_sigmas**2 + lambda_val**2)\n            s_bar_lambda = np.mean(suppression_factors)\n            \n        results.append([lambda_val, k_lambda, s_bar_lambda])\n\n    # Final print statement in the exact required format.\n    # The format required is a list of lists.\n    # The default string representation of a list is what's needed.\n    # The precision of floats is determined by numpy's default string conversion.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "除了频率学派的正则化方法，贝叶斯框架为理解和解决不稳定性提供了另一个深刻的视角，这在数据同化中尤为核心。本练习将引导你从贝叶斯推断的角度探讨病态性，你会发现当使用无信息先验时，算子的零奇异值（或微小奇异值）如何导致后验分布的病态或数值不稳定。这个练习旨在揭示一个合适的先验分布本身所具有的内在正则化作用 。",
            "id": "3391328",
            "problem": "考虑带有加性高斯噪声的线性逆模型，由关系式 $y = A x + \\varepsilon$ 定义，其中 $A \\in \\mathbb{R}^{m \\times n}$，$x \\in \\mathbb{R}^{n}$，$y \\in \\mathbb{R}^{m}$，以及 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_m)$，噪声水平 $\\sigma  0$ 已知。在数据同化中采用贝叶斯观点，其中 $x$ 的先验分布为非正常平坦先验 $p(x) \\propto 1$ 或精度为 $\\alpha  0$ 的正常高斯先验 $x \\sim \\mathcal{N}(0, \\alpha^{-1} I_n)$。在非正常平坦先验下，后验密度与似然 $p(y \\mid x) \\propto \\exp\\left( -\\|A x - y\\|_2^2 / (2 \\sigma^2) \\right)$ 成正比。\n\n你的任务是构建并分析示例，以突显在非正常平坦先验下，由前向算子 $A$ 的小奇异值引起的不稳定性，展示后验何时是病态的（即不可归一化），以及何时因近零空间方向而数值不稳定。使用 $A$ 的奇异值分解 (SVD) 来推断后验的可积性和稳定性。你生成的程序必须对每个测试用例按如下方式对后验进行分类：\n\n- 如果在非正常平坦先验下的后验是病态的（后验密度在 $x$ 上的积分不为有限值），则输出整数 $0$。\n- 如果在非正常平坦先验下的后验是适定的但由于小奇异值而数值不稳定（由最小奇异值的阈值决定），则输出整数 $1$。\n- 如果在非正常平坦先验下的后验是适定的且数值稳定（所有奇异值都超过阈值），则输出整数 $2$。\n- 如果使用正常高斯先验，且后验在构造上是适定的（即使 $A$ 中存在零空间方向），则输出整数 $3$。\n\n从 Bayes 定理、高斯似然、线性变换性质和标准正交变量替换等基本定义出发。你不能依赖任何预先提供的目标公式；必须从这些基础推导出所有必要条件。\n\n使用以下规范实现决策过程：\n- 对于非正常平坦先验的情况，后验是可归一化的，当且仅当矩阵 $A$ 具有满列秩，等价于 $A$ 的所有 $n$ 个奇异值都严格为正且 $m \\ge n$。对于数值稳定性，引入一个阈值 $\\tau  0$，如果最小奇异值小于 $\\tau$，则声明为不稳定。\n- 对于正常高斯先验 $x \\sim \\mathcal{N}(0, \\alpha^{-1} I_n)$ 的情况，由于增加了先验精度 $\\alpha  0$，后验对于任何 $A$ 以及任何 $m, n$ 都是适定的。将此类情况分类为 $3$。\n\n测试套件：\n- 案例 1（适定且稳定的非正常先验）：$m = 3$，$n = 3$，$A = \\mathrm{diag}(1, \\tfrac{1}{4}, \\tfrac{1}{10})$，$y = (1, -1, 0)^\\top$，$\\sigma = 10^{-2}$，$\\tau = 10^{-8}$，非正常平坦先验。\n- 案例 2（因零空间导致的病态非正常先验）：$m = 2$，$n = 3$，$A = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix}$，$y = (0, 0)^\\top$，$\\sigma = 10^{-2}$，$\\tau = 10^{-8}$，非正常平坦先验。\n- 案例 3（适定但因近零空间方向而数值不稳定的非正常先验）：$m = 3$，$n = 3$，$A = \\mathrm{diag}(1, 10^{-9}, \\tfrac{1}{2})$，$y = (0, 0, 0)^\\top$，$\\sigma = 10^{-2}$，$\\tau = 10^{-8}$，非正常平坦先验。\n- 案例 4（因欠定系统导致的病态非正常先验）：$m = 3$，$n = 4$，$A = \\begin{pmatrix} 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  1  0 \\end{pmatrix}$，$y = (1, 2, 3)^\\top$，$\\sigma = 10^{-2}$，$\\tau = 10^{-8}$，非正常平坦先验。\n- 案例 5（正常高斯先验下的适定后验）：使用与案例 2 相同的 $A$ 和维度，但采用正常高斯先验 $x \\sim \\mathcal{N}(0, \\alpha^{-1} I_3)$，其中 $\\alpha = 10$，$y = (0, 0)^\\top$，$\\sigma = 10^{-2}$，$\\tau = 10^{-8}$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result_1, result_2, result_3, result_4, result_5]$），其中每个 $result_i$ 是上面定义的整数 $0$、$1$、$2$ 或 $3$ 之一。",
            "solution": "该问题要求在线性贝叶斯逆问题中分析后验分布，重点关注后验是适定且数值稳定的条件。我们给定的模型是 `$y = A x + \\varepsilon$`，其中 `$A \\in \\mathbb{R}^{m \\times n}$` 是前向算子，`$x \\in \\mathbb{R}^{n}$` 是未知参数向量，`$y \\in \\mathbb{R}^{m}$` 是数据向量，`$\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_m)$` 是已知方差 `$\\sigma^2  0$` 的加性高斯噪声。\n\n分析取决于对 `$x$` 的先验分布 `$p(x)$` 的选择。我们将从基本原理推导后验适定和稳定的条件，特别是 Bayes 定理，该定理指出后验概率密度与似然和先验的乘积成正比：\n$$p(x \\mid y) \\propto p(y \\mid x) p(x)$$\n\n似然函数 `$p(y \\mid x)$` 由噪声模型确定。由于 `$\\varepsilon = y - Ax$` 且 `$\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_m)$`，似然是一个多元高斯函数：\n$$p(y \\mid x) = \\frac{1}{(2\\pi\\sigma^2)^{m/2}} \\exp\\left( -\\frac{1}{2\\sigma^2} \\|y - Ax\\|_2^2 \\right)$$\n\n我们根据先验的选择考虑两种情况。\n\n**情况 1：非正常平坦先验**\n\n在这种情况下，假设先验在 `$\\mathbb{R}^n$` 上是均匀的，即 `$p(x) \\propto 1$`。这是一个“非正常”先验，因为它在 `$\\mathbb{R}^n$` 上的积分不是有限的。所得后验的有效性取决于似然函数本身是否可积。\n\n后验密度与似然成正比：\n$$p(x \\mid y) \\propto \\exp\\left( -\\frac{1}{2\\sigma^2} \\|Ax - y\\|_2^2 \\right)$$\n为了使该后验“适定”或“可归一化”，它在 `$x$` 的所有可能值上的积分必须是有限的：\n$$Z = \\int_{\\mathbb{R}^n} \\exp\\left( -\\frac{1}{2\\sigma^2} \\|Ax - y\\|_2^2 \\right) dx  \\infty$$\n项 `$Z$` 是归一化常数，也称为证据（evidence）。指数包含一个关于 `$x$` 的二次型：\n$$\\|Ax - y\\|_2^2 = (Ax - y)^\\top(Ax - y) = x^\\top A^\\top A x - 2y^\\top A x + y^\\top y$$\n积分 `$\\int_{\\mathbb{R}^n} \\exp(-\\frac{1}{2\\sigma^2}(x^\\top A^\\top A x - 2y^\\top A x + y^\\top y)) dx$` 具有多元高斯积分的形式。这种积分收敛当且仅当二次项的矩阵 `$A^\\top A$` 是正定的。\n\n为了分析 `$n \\times n$` 矩阵 `$A^\\top A$` 的性质，我们使用 `$A$` 的奇异值分解 (SVD)。设 `$A = U S V^\\top$`，其中 `$U \\in \\mathbb{R}^{m \\times m}$` 和 `$V \\in \\mathbb{R}^{n \\times n}$` 是正交矩阵，`$S \\in \\mathbb{R}^{m \\times n}$` 是包含奇异值 `$s_1 \\ge s_2 \\ge \\dots \\ge 0$` 的矩形对角矩阵。\n将 SVD 代入 `$A^\\top A$` 的表达式中：\n$$A^\\top A = (U S V^\\top)^\\top (U S V^\\top) = V S^\\top U^\\top U S V^\\top = V (S^\\top S) V^\\top$$\n这表明 `$A^\\top A$` 与 `$S^\\top S$` 相似。`$S^\\top S$` 是一个 `$n \\times n$` 的对角矩阵，其对角线元素对于 `$i=1, \\dots, \\min(m, n)$` 是 `$s_i^2$`，其余为零。因此，`$A^\\top A$` 的特征值为 `$s_i^2 \\ge 0$`。\n\n要使 `$A^\\top A$` 是正定的，其所有特征值都必须严格为正。这要求其所有 `$n$` 个特征值都大于 `$0$`。这只有在 `$A$` 具有满列秩，即 `$\\text{rank}(A) = n$` 时才可能。这蕴含两个条件：\n1.  行数必须至少等于列数，即 `$m \\ge n$`。如果 `$m  n$`，`$A$` 的秩最多为 `$m$`，因此 `$A^\\top A$` 将至少有 `$n-m$` 个零特征值。\n2.  `$A$` 的所有 `$n$` 个奇异值都必须严格为正，即 `$s_n  0$`。\n\n如果 `$\\text{rank}(A)  n$`，则 `$A$` 存在一个非平凡的零空间。零空间 `$\\mathcal{N}(A)$` 中的任何向量 `$x_0$` 都满足 `$Ax_0 = 0$`。后验密度沿着零空间中的任何方向变为常数，沿这个无限方向积分会得到一个发散的积分。因此，后验是病态的。这对应于 **分类 `$0$`**。\n\n如果 `$\\text{rank}(A) = n$`，则后验是适定的。解的稳定性随后由 `$A^\\top A$` 的条件数决定。相应最小二乘问题 `$x_{LS} = (A^\\top A)^{-1} A^\\top y$` 的解涉及到 `$A^\\top A$` 的逆，其特征值为 `$1/s_i^2$`。如果任何奇异值 `$s_i$` 非常小（但非零），相应的特征值 `$1/s_i^2$` 就会非常大。这表明数据 `$y$` 中的小扰动，经 `$1/s_i$` 放大后，可能导致解 `$x$` 发生巨大变化，这是数值不稳定性的一个标志。\n根据问题的规范，我们使用一个阈值 `$\\tau  0$`。\n- 如果最小奇异值 `$\\min(s_i)  \\tau$`，则问题是适定的但数值不稳定。这对应于 **分类 `$1$`**。\n- 如果 `$\\min(s_i) \\ge \\tau$`，则问题是适定的且数值稳定。这对应于 **分类 `$2$`**。\n\n**情况 2：正常高斯先验**\n\n这里，先验为 `$x \\sim \\mathcal{N}(0, \\alpha^{-1} I_n)`，其中精度 `$\\alpha  0$`。先验密度为：\n$$p(x) \\propto \\exp\\left( -\\frac{\\alpha}{2} \\|x\\|_2^2 \\right) = \\exp\\left( -\\frac{\\alpha}{2} x^\\top x \\right)$$\n后验密度为：\n$$p(x \\mid y) \\propto \\exp\\left( -\\frac{1}{2\\sigma^2} \\|Ax - y\\|_2^2 \\right) \\exp\\left( -\\frac{\\alpha}{2} \\|x\\|_2^2 \\right)$$\n$$p(x \\mid y) \\propto \\exp\\left( -\\frac{1}{2} \\left( \\frac{1}{\\sigma^2} \\|Ax - y\\|_2^2 + \\alpha \\|x\\|_2^2 \\right) \\right)$$\n指数的参数是 `$x$` 的一个二次函数。关于 `$x$` 的二次项是：\n$$\\frac{1}{\\sigma^2} x^\\top A^\\top A x + \\alpha x^\\top I_n x = x^\\top \\left( \\frac{1}{\\sigma^2} A^\\top A + \\alpha I_n \\right) x$$\n为了使后验成为一个可归一化的高斯分布，矩阵 `$H = \\frac{1}{\\sigma^2} A^\\top A + \\alpha I_n$` 必须是正定的。\n我们知道 `$A^\\top A$` 是半正定的（其特征值为 `$s_i^2 \\ge 0$`）。由于 `$\\alpha  0$`，矩阵 `$\\alpha I_n$` 是正定的（其特征值均为 `$\\alpha$`）。一个半正定矩阵与一个正定矩阵之和总是正定的。\n因此，对于任何 `$A$`，无论其秩如何，`$H$` 总是正定的。后验总是一个正常的、适定的高斯分布。先验对问题进行了“正则化”，确保了即使当 `$A$` 是秩亏的，后验分布也是唯一且稳定的。这种情况被赋予 **分类 `$3$`**。\n\n**将决策逻辑应用于测试用例：**\n\n- **案例 1**：非正常先验。`$A = \\mathrm{diag}(1, \\frac{1}{4}, \\frac{1}{10})$`，因此 `$m=3, n=3$`。矩阵是满秩的（`$\\text{rank}(A) = 3 = n$`）。奇异值为 `$1, 0.25, 0.1$`。最小奇异值为 `$0.1$`。给定 `$\\tau = 10^{-8}$`，我们有 `$0.1 \\ge 10^{-8}$`。后验是适定且稳定的。**结果：`$2$`**。\n\n- **案例 2**：非正常先验。`$A = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\end{pmatrix}`，因此 `$m=2, n=3$`。由于 `$m  n$`，秩最多为 `$2$`。`$\\text{rank}(A) = 2  n = 3$`。矩阵不是满列秩。后验是病态的。**结果：`$0$`**。\n\n- **案例 3**：非正常先验。`$A = \\mathrm{diag}(1, 10^{-9}, \\frac{1}{2})$`，因此 `$m=3, n=3$`。矩阵是满秩的（`$\\text{rank}(A) = 3 = n$`）。奇异值为 `$1, 0.5, 10^{-9}$`。最小奇异值为 `$10^{-9}$`。给定 `$\\tau = 10^{-8}$`，我们有 `$10^{-9}  10^{-8}$`。后验是适定的但数值不稳定。**结果：`$1$`**。\n\n- **案例 4**：非正常先验。`$A = \\begin{pmatrix} 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  1  0 \\end{pmatrix}`，因此 `$m=3, n=4$`。由于 `$m  n$`，秩最多为 `$3$`。`$\\text{rank}(A) = 3  n = 4$`。矩阵不是满列秩。后验是病态的。**结果：`$0$`**。\n\n- **案例 5**：正常高斯先验。矩阵 `$A$` 与案例 `$2$` 中相同，是秩亏的。然而，因为使用了正常高斯先验，后验在构造上保证是适定的。**结果：`$3$`**。\n\n最终的程序将实现这一决策逻辑。",
            "answer": "```python\nimport numpy as np\n\ndef classify_posterior(A, tau, prior_type):\n    \"\"\"\n    Classifies the posterior distribution based on the properties of the\n    forward operator A and the choice of prior.\n\n    Args:\n        A (np.ndarray): The forward operator matrix.\n        tau (float): The threshold for numerical stability.\n        prior_type (str): The type of prior ('improper' or 'proper').\n\n    Returns:\n        int: The classification code (0, 1, 2, or 3).\n    \"\"\"\n    if prior_type == 'proper':\n        # For a proper Gaussian prior, the posterior is always well-defined.\n        return 3\n\n    # For an improper flat prior, analyze the matrix A.\n    m, n = A.shape\n\n    # The posterior is normalizable if and only if A has full column rank.\n    # We check this using numpy.linalg.matrix_rank.\n    # Note: np.linalg.matrix_rank determines rank by counting singular values\n    # above a tolerance, which is the standard numerical approach.\n    rank = np.linalg.matrix_rank(A)\n\n    if rank  n:\n        # If A is not full column rank, the posterior is ill-defined.\n        return 0\n    else:\n        # If A is full column rank, the posterior is well-defined.\n        # Now check for numerical stability using singular values.\n        # We only need the singular values, not the full SVD.\n        singular_values = np.linalg.svd(A, compute_uv=False)\n        \n        # The smallest singular value determines stability.\n        # For a full-rank square or tall matrix, all singular values are non-zero.\n        min_singular_value = np.min(singular_values)\n\n        if min_singular_value  tau:\n            # Well-defined but numerically unstable.\n            return 1\n        else:\n            # Well-defined and numerically stable.\n            return 2\n\ndef solve():\n    \"\"\"\n    Runs the analysis on the test suite and prints the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"A\": np.diag([1.0, 1.0/4.0, 1.0/10.0]),\n            \"tau\": 1e-8,\n            \"prior_type\": \"improper\"\n        },\n        {\n            \"A\": np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]),\n            \"tau\": 1e-8,\n            \"prior_type\": \"improper\"\n        },\n        {\n            \"A\": np.diag([1.0, 1e-9, 0.5]),\n            \"tau\": 1e-8,\n            \"prior_type\": \"improper\"\n        },\n        {\n            \"A\": np.array([[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0]]),\n            \"tau\": 1e-8,\n            \"prior_type\": \"improper\"\n        },\n        {\n            \"A\": np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]),\n            \"tau\": 1e-8,\n            \"prior_type\": \"proper\"\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = classify_posterior(case[\"A\"], case[\"tau\"], case[\"prior_type\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}