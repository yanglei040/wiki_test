{
    "hands_on_practices": [
        {
            "introduction": "这个练习将指导你通过奇异值分解（SVD）来剖析一个有限维线性反问题。SVD 是一个强大的工具，它不仅能为我们提供解的表达式，还能揭示问题的不适定性根源。通过推导最小范数解及其对数据扰动的敏感性，你将亲身体会到小的奇异值是如何放大噪声，从而导致解的不稳定性的。",
            "id": "3387743",
            "problem": "设 $K \\in \\mathbb{R}^{m \\times n}$ 是一个实矩阵，其秩为 $r \\leq \\min\\{m,n\\}$，其奇异值分解 (SVD) 为 $K = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个对角矩阵，其非负对角元按 $\\sigma_{1} \\geq \\sigma_{2} \\geq \\cdots \\geq \\sigma_{r}  0$ 的顺序排列，其余为零。考虑线性反问题 $K x = y$，其中 $y \\in \\mathbb{R}^{m}$，以及最小范数解 $x^{\\dagger} := \\arg\\min \\{\\|x\\|_{2} : K x = y\\}$。\n\n仅从核心定义（正交性、奇异值分解 (SVD)、欧几里得 2-范数以及最小范数解的定义）出发，完成以下任务：\n\n- 推导 $x^{\\dagger}$ 用奇异三元组 $\\{(u_{i}, \\sigma_{i}, v_{i})\\}_{i=1}^{r}$ 表示的表达式。\n- 使用 Hadamard 准则（存在性、唯一性和对数据的连续依赖性），确定在什么条件下，从数据到解的映射是适定的。然后，对于扰动 $y^{\\delta} = y + \\varepsilon$，推导在欧几里得 2-范数下，限制在 $y \\in \\operatorname{range}(K)$ 上的数据到解的映射 $y \\mapsto x^{\\dagger}$ 的 Lipschitz 常数 $L$。\n- 在右奇异向量基下，解释 $x^{\\dagger}$ 的每个系数如何依赖于比率 $1/\\sigma_{i}$，以及为什么最小正奇异值 $\\sigma_{r}$ 控制了最坏情况下的噪声放大。\n\n将您的最终答案表示为 Lipschitz 常数 $L$ 关于奇异值的精确解析表达式。无需四舍五入。仅报告所要求的 L 表达式作为您的最终答案。",
            "solution": "该问题有效。我们按要求进行推导和分析。\n\n任务是分析线性反问题 $Kx=y$，其中 $K \\in \\mathbb{R}^{m \\times n}$ 是一个实矩阵，其秩 $\\operatorname{rank}(K) = r \\leq \\min\\{m,n\\}$。我们已知 $K$ 的奇异值分解 (SVD) 为 $K = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个对角矩阵，其奇异值为 $\\sigma_{1} \\geq \\sigma_{2} \\geq \\cdots \\geq \\sigma_{r}  0$ 且对于 $i  r$ 有 $\\sigma_i = 0$。$U$ 的列向量记为 $\\{u_i\\}_{i=1}^m$，$V$ 的列向量记为 $\\{v_i\\}_{i=1}^n$。\n\n### 最小范数解 $x^{\\dagger}$ 的推导\n\n我们寻求定义为 $x^{\\dagger} := \\arg\\min \\{\\|x\\|_{2} : K x = y\\}$ 的解 $x^{\\dagger}$。这个定义要求解集 $\\{x : Kx = y\\}$ 是非空的，这意味着我们假设 $y \\in \\operatorname{range}(K)$。\n\n我们首先将 SVD 代入方程 $Kx = y$ 中：\n$$U \\Sigma V^{\\top} x = y$$\n由于 $U$ 是一个正交矩阵，它的逆是它的转置，即 $U^{-1} = U^{\\top}$。我们在等式两边左乘 $U^{\\top}$：\n$$U^{\\top} (U \\Sigma V^{\\top} x) = U^{\\top} y$$\n$$(U^{\\top} U) \\Sigma V^{\\top} x = U^{\\top} y$$\n$$I_m \\Sigma V^{\\top} x = U^{\\top} y$$\n$$\\Sigma (V^{\\top} x) = U^{\\top} y$$\n我们为解 $x \\in \\mathbb{R}^n$ 和数据 $y \\in \\mathbb{R}^m$ 引入基变换。我们定义新坐标 $\\alpha \\in \\mathbb{R}^n$ 和 $\\beta \\in \\mathbb{R}^m$ 如下：\n$$\\alpha = V^{\\top} x \\quad (\\text{所以 } x = V \\alpha \\text{ 因为 } V \\text{ 是正交的})$$\n$$\\beta = U^{\\top} y \\quad (\\text{所以 } y = U \\beta \\text{ 因为 } U \\text{ 是正交的})$$\n这些向量的分量是 $\\alpha_i = v_i^{\\top} x$ 和 $\\beta_i = u_i^{\\top} y$。方程 $\\Sigma (V^{\\top} x) = U^{\\top} y$ 简化为：\n$$\\Sigma \\alpha = \\beta$$\n用分量形式表示，对于 $i=1, \\dots, \\min\\{m, n\\}$，该方程为 $\\sigma_i \\alpha_i = \\beta_i$。\n\n我们必须分析关于索引 $i$ 的两种情况：\n1.  对于 $i=1, \\dots, r$，奇异值为正，$\\sigma_i  0$。因此，系数 $\\alpha_i$ 是唯一确定的：\n    $$\\alpha_i = \\frac{\\beta_i}{\\sigma_i} = \\frac{u_i^{\\top} y}{\\sigma_i}$$\n2.  对于 $i  r$，奇异值为零，$\\sigma_i = 0$。方程变为 $0 \\cdot \\alpha_i = \\beta_i$。\n    为了使解存在，必须满足对所有 $i  r$ 都有 $\\beta_i = u_i^{\\top} y = 0$。这个条件等价于 $y$ 必须与向量 $\\{u_{r+1}, \\dots, u_m\\}$ 正交，而这些向量构成了 $K^{\\top}$ 的零空间 $\\operatorname{null}(K^{\\top})$ 的一个基。这与我们最初假设的条件 $y \\in \\operatorname{range}(K)$ 是相同的。\n    对于这些索引 $i  r$，系数 $\\alpha_i$ 不能由方程确定，可以是任意实数。\n\n任何解 $x$ 都可以用基 $\\{v_i\\}$ 表示为 $x = \\sum_{i=1}^{n} \\alpha_i v_i$。代入推导出的系数，得到解的通式：\n$$x = \\sum_{i=1}^{r} \\left(\\frac{u_i^{\\top} y}{\\sigma_i}\\right) v_i + \\sum_{i=r+1}^{n} \\alpha_i v_i$$\n第二个和式代表了 $K$ 的零空间中的一个任意向量，因为对于 $ir$，$K v_i = \\sigma_i u_i = 0$。\n\n现在，我们通过最小化 $\\|x\\|_2$ 来找到最小范数解 $x^{\\dagger}$。由于 $V$ 是一个正交矩阵，它保持欧几里得范数不变：\n$$\\|x\\|_{2}^{2} = \\|V\\alpha\\|_{2}^{2} = \\alpha^{\\top}V^{\\top}V\\alpha = \\alpha^{\\top}\\alpha = \\|\\alpha\\|_{2}^{2}$$\n范数的平方是：\n$$\\|x\\|_{2}^{2} = \\sum_{i=1}^{n} \\alpha_i^2 = \\sum_{i=1}^{r} \\left(\\frac{u_i^{\\top} y}{\\sigma_i}\\right)^2 + \\sum_{i=r+1}^{n} \\alpha_i^2$$\n为了最小化该范数，我们必须选择对于 $i  r$ 的任意系数 $\\alpha_i$ 为零。即，对于 $i=r+1, \\dots, n$，$\\alpha_i = 0$。这个选择消除了来自 $K$ 的零空间的任何分量，使得解与 $\\operatorname{null}(K)$ 正交。\n因此，最小范数解为：\n$$x^{\\dagger} = \\sum_{i=1}^{r} \\frac{u_i^{\\top} y}{\\sigma_i} v_i$$\n这就是 $x^{\\dagger}$ 用奇异三元组 $\\{(u_{i}, \\sigma_{i}, v_{i})\\}_{i=1}^{r}$ 表示的表达式。\n\n### Hadamard 适定性与 Lipschitz 常数\n\n适定问题的 Hadamard 准则包括解对数据的存在性、唯一性和连续依赖性。\n1.  **存在性**：$Kx=y$ 的解存在当且仅当 $y \\in \\operatorname{range}(K)$。对于任意 $y \\in \\mathbb{R}^m$，解可能不存在。因此，该问题在存在性上是不适定的。\n2.  **唯一性**：如果 $\\operatorname{rank}(K) = r  n$，$K$ 的零空间是非平凡的。在这种情况下，如果解存在，则存在无穷多个解。因此，该问题在唯一性上是不适定的。\n\n然而，如果我们将问题重新表述为对任何数据 $y \\in \\mathbb{R}^m$ 寻找唯一的最小范数解 $x^{\\dagger}$，这个新问题有唯一解，由 $x^{\\dagger} = K^{\\dagger} y$ 给出，其中 $K^{\\dagger} = V \\Sigma^{\\dagger} U^{\\top}$ 是 Moore-Penrose 伪逆，$\\Sigma^{\\dagger}$ 是一个 $n \\times m$ 矩阵，其对角元在 $i=1,\\dots,r$ 时为 $1/\\sigma_i$，其余为零。我们推导出的 $x^{\\dagger}$ 公式对于 $y \\in \\operatorname{range}(K)$ 与此等价。对于 $y \\notin \\operatorname{range}(K)$，$K^{\\dagger}y$ 得到最小范数最小二乘解。寻找 $x^{\\dagger}$ 的问题在存在性和唯一性上总是适定的。\n\n3.  **连续依赖性（稳定性）**：我们考察对于 $y \\in \\operatorname{range}(K)$ 的映射 $G: y \\mapsto x^{\\dagger}$ 的稳定性。设 $y_1, y_2 \\in \\operatorname{range}(K)$ 且 $x_1^{\\dagger} = G(y_1)$，$x_2^{\\dagger} = G(y_2)$。该映射是线性的，因为 $x^{\\dagger}$ 是 $y$ 的线性函数。我们想求此映射的 Lipschitz 常数 $L$，对于线性映射，它就是其算子范数。\n$$L = \\sup_{y \\in \\operatorname{range}(K), y \\neq 0} \\frac{\\|G(y)\\|_2}{\\|y\\|_2} = \\sup_{y \\in \\operatorname{range}(K), y \\neq 0} \\frac{\\|x^{\\dagger}\\|_2}{\\|y\\|_2}$$\n使用 $x^{\\dagger}$ 和 $y$ 在它们各自的奇异基下的表达式：\n$x^{\\dagger} = \\sum_{i=1}^{r} \\frac{u_i^{\\top} y}{\\sigma_i} v_i$。由于 $\\{v_i\\}$ 是标准正交的，$\\|x^{\\dagger}\\|_2^2 = \\sum_{i=1}^{r} \\left(\\frac{u_i^{\\top} y}{\\sigma_i}\\right)^2$。\n由于 $y \\in \\operatorname{range}(K)$，$y$ 可以写成 $y = \\sum_{i=1}^{r} (u_i^{\\top} y) u_i$。由于 $\\{u_i\\}_{i=1}^r$ 是标准正交的，$\\|y\\|_2^2 = \\sum_{i=1}^{r} (u_i^{\\top} y)^2$。\n\n范数平方的比值为：\n$$\\frac{\\|x^{\\dagger}\\|_2^2}{\\|y\\|_2^2} = \\frac{\\sum_{i=1}^{r} (u_i^{\\top} y)^2 / \\sigma_i^2}{\\sum_{j=1}^{r} (u_j^{\\top} y)^2}$$\n由于 $\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq \\sigma_r  0$，我们有 $1/\\sigma_i^2 \\leq 1/\\sigma_r^2$ 对所有 $i=1, \\dots, r$ 成立。\n$$\\frac{\\sum_{i=1}^{r} (u_i^{\\top} y)^2 / \\sigma_i^2}{\\sum_{j=1}^{r} (u_j^{\\top} y)^2} \\leq \\frac{\\sum_{i=1}^{r} (u_i^{\\top} y)^2 / \\sigma_r^2}{\\sum_{j=1}^{r} (u_j^{\\top} y)^2} = \\frac{1}{\\sigma_r^2} \\frac{\\sum_{i=1}^{r} (u_i^{\\top} y)^2}{\\sum_{j=1}^{r} (u_j^{\\top} y)^2} = \\frac{1}{\\sigma_r^2}$$\n这表明 $\\frac{\\|x^{\\dagger}\\|_2}{\\|y\\|_2} \\leq \\frac{1}{\\sigma_r}$。为了证明上确界恰好是 $1/\\sigma_r$，我们必须找到一个向量 $y$ 使得该界可以达到。我们选择 $y = u_r$。这个向量在 $\\operatorname{range}(K)$ 中。对于这个选择：\n$u_i^{\\top} y = u_i^{\\top} u_r = \\delta_{ir}$ (克罗内克 δ)。\n则 $\\|y\\|_2^2 = \\|u_r\\|_2^2 = 1$。\n且 $\\|x^{\\dagger}\\|_2^2 = \\sum_{i=1}^{r} (\\delta_{ir}/\\sigma_i)^2 = (1/\\sigma_r)^2$。\n因此，对于 $y = u_r$，我们有 $\\frac{\\|x^{\\dagger}\\|_2}{\\|y\\|_2} = \\frac{1/\\sigma_r}{1} = \\frac{1}{\\sigma_r}$。\n因为我们找到了一个达到上界的向量，所以上确界就是这个值。限制在 $y \\in \\operatorname{range}(K)$ 上的数据到解的映射 $y \\mapsto x^{\\dagger}$ 的 Lipschitz 常数是：\n$$L = \\frac{1}{\\sigma_r}$$\n只要 $\\sigma_r  0$，映射就是连续的。然而，如果 $\\sigma_r$ 非常小，Lipschitz 常数 $L$ 就会非常大，表明数据 $y$ 的微小扰动可能导致解 $x^{\\dagger}$ 的巨大变化。这是不适定（或者更准确地说，病态）问题的一个典型特征。\n\n### 噪声放大分析\n\n解 $x^{\\dagger}$ 在右奇异向量基 $\\{v_1, \\dots, v_n\\}$ 下表示为：\n$$x^{\\dagger} = \\sum_{i=1}^{r} \\alpha_i v_i, \\quad \\text{其中系数为 } \\alpha_i = \\frac{u_i^{\\top} y}{\\sigma_i}$$\n解的每个系数 $\\alpha_i$ 由数据 $y$ 在相应左奇异向量 $u_i$ 上的投影决定，并按奇异值的倒数 $1/\\sigma_i$ 进行缩放。\n\n现在，考虑受扰动的数据 $y^{\\delta} = y + \\varepsilon$，其中 $\\varepsilon$ 是一些噪声或误差。新的最小范数解是 $x^{\\delta\\dagger} = K^{\\dagger} y^{\\delta}$。解中的误差是 $\\Delta x = x^{\\delta\\dagger} - x^{\\dagger} = K^{\\dagger}(y+\\varepsilon) - K^{\\dagger}y = K^{\\dagger}\\varepsilon$。\n使用伪逆作用的公式：\n$$\\Delta x = \\sum_{i=1}^{r} \\frac{u_i^{\\top} \\varepsilon}{\\sigma_i} v_i$$\n解误差沿方向 $v_i$ 的系数是 $\\frac{u_i^{\\top} \\varepsilon}{\\sigma_i}$。这表明，数据噪声在方向 $u_i$ 上的分量，即 $u_i^{\\top} \\varepsilon$，被因子 $1/\\sigma_i$ 放大，从而产生了解误差在方向 $v_i$ 上的相应分量。\n\n放大因子为 $\\{1/\\sigma_1, 1/\\sigma_2, \\dots, 1/\\sigma_r\\}$。由于 $\\sigma_1 \\geq \\dots \\geq \\sigma_r  0$，这些因子中最大的是 $1/\\sigma_r$。因此，最小的正奇异值 $\\sigma_r$ 控制了最坏情况下的噪声放大。任何在 $u_r$ 上有非零投影的噪声分量 $\\varepsilon$ 都将被最大的因子 $1/\\sigma_r$ 放大。如果 $\\sigma_r$ 接近于零，这种放大可能是巨大的，会完全破坏解的稳定性。这说明了为什么最小非零奇异值的大小是衡量反问题病态程度的关键指标。",
            "answer": "$$\\boxed{\\frac{1}{\\sigma_{r}}}$$"
        },
        {
            "introduction": "在从有限维空间过渡到无限维函数空间时，不适定性的挑战变得更加普遍和微妙。这个练习探讨了一个经典的例子——$L^2$ 空间上的乘法算子。通过构建一个具体的函数序列，你将证明即使一个算子是单射的且其值域是稠密的，其逆算子也可能不是有界的，从而破坏了哈达玛适定性中的稳定性条件。",
            "id": "3387707",
            "problem": "考虑在勒贝格空间 $L^{2}(0,1)$ 上提出的线性逆问题 $T f = g$，其中正向算子 $T : L^{2}(0,1) \\to L^{2}(0,1)$ 定义为 $(T f)(x) = x f(x)$，对于 $x \\in (0,1)$。在 Hadamard 适定性的意义上，稳定性指的是解对数据的连续依赖性，对于线性逆问题，这等价于逆算子 $T^{-1}$ 在 $T$ 的值域 $\\operatorname{Ran}(T)$ 上的有界性。\n\n从单射性、稠密值域和稳定性的核心定义出发，并且只使用 $L^{2}(0,1)$ 和 $L^{2}$-范数的标准性质，完成以下任务：\n\n- 证明 $T$ 在 $L^{2}(0,1)$ 上是单射的。\n- 证明 $\\operatorname{Ran}(T)$ 在 $L^{2}(0,1)$ 中是稠密的。\n- 通过构造一个具体的序列 $\\{f_{n}\\}_{n\\in\\mathbb{N}} \\subset L^{2}(0,1)$ 来证明稳定性不成立，该序列的关联数据 $g_{n} = T f_{n}$ 满足 $\\|g_{n}\\|_{L^{2}(0,1)} \\to 0$，而同时 $\\|f_{n}\\|_{L^{2}(0,1)} \\to \\infty$。你的构造必须是显式的，并从第一性原理出发进行论证。\n\n对于由 $f_{n}(x) = n \\,\\chi_{(0,1/n)}(x)$ 给出的具体序列，其中 $\\chi_{(0,1/n)}$ 是区间 $(0,1/n)$ 的指示函数，计算放大因子\n$$\nA_{n} \\equiv \\frac{\\|f_{n}\\|_{L^{2}(0,1)}}{\\|T f_{n}\\|_{L^{2}(0,1)}}\n$$\n的精确解析表达式，其形式为关于 $n$ 的闭式。提供 $A_{n}$ 的表达式；无需四舍五入。",
            "solution": "该问题是适定的，并且在泛函分析和逆问题领域有其科学依据。我们进行求解。\n\n问题要求分析线性算子 $T: L^{2}(0,1) \\to L^{2}(0,1)$，该算子定义为 $(Tf)(x) = xf(x)$，对于 $x \\in (0,1)$。空间 $L^{2}(0,1)$ 是区间 $(0,1)$ 上的平方可积函数空间，配备内积 $\\langle f,g \\rangle = \\int_0^1 f(x)\\overline{g(x)}dx$ 及相应的范数 $\\|f\\|_{L^2} = \\left(\\int_0^1 |f(x)|^2 dx\\right)^{1/2}$。\n\n首先，我们证明算子 $T$ 是单射的。如果一个算子 $T$ 的零空间（或核）只包含零元素，则该算子是单射的。对于线性算子，这等价于证明 $Tf = 0$ 蕴含 $f = 0$。\n设 $f \\in L^2(0,1)$ 使得 $Tf = 0$。根据定义，这意味着对于几乎所有的 $x \\in (0,1)$，$(Tf)(x) = 0$。\n代入算子 $T$ 的定义，我们有 $x f(x) = 0$ 对于几乎所有的 $x \\in (0,1)$。\n对于开区间 $(0,1)$ 中的任意 $x$，我们有 $x \\neq 0$。因此，要使乘积 $xf(x)$ 为零，必须有 $f(x)=0$。这对于几乎所有的 $x \\in (0,1)$ 都成立。一个在其定义域上几乎处处为零的函数是 $L^2(0,1)$ 空间中的零元素。因此，在 $L^2(0,1)$ 中 $f = 0$。\n$T$ 的零空间为 $\\ker(T) = \\{0\\}$，这证明了 $T$ 是单射的。\n\n其次，我们证明 $T$ 的值域，记作 $\\operatorname{Ran}(T)$，在 $L^2(0,1)$ 中是稠密的。为证明这一点，我们必须表明对于任意函数 $h \\in L^2(0,1)$ 和任意 $\\epsilon  0$，都存在一个函数 $g \\in \\operatorname{Ran}(T)$ 使得 $\\|h - g\\|_{L^2}  \\epsilon$。\n设 $h \\in L^2(0,1)$ 是任意的。对于任意 $\\delta \\in (0,1)$，我们定义一个函数 $g_{\\delta}$ 为 $g_{\\delta}(x) = h(x) \\chi_{(\\delta,1)}(x)$，其中 $\\chi_{(\\delta,1)}$ 是区间 $(\\delta,1)$ 的指示函数。\n我们希望证明 $g_{\\delta} \\in \\operatorname{Ran}(T)$。这需要找到一个函数 $f_{\\delta} \\in L^2(0,1)$ 使得 $(T f_{\\delta})(x) = g_{\\delta}(x)$，即 $x f_{\\delta}(x) = g_{\\delta}(x)$。我们可以定义 $f_{\\delta}(x) = \\frac{g_{\\delta}(x)}{x} = \\frac{h(x)}{x} \\chi_{(\\delta,1)}(x)$。\n我们必须验证这个 $f_{\\delta}$ 确实在 $L^2(0,1)$ 中。我们计算其范数：\n$$\n\\|f_{\\delta}\\|_{L^2}^2 = \\int_0^1 |f_{\\delta}(x)|^2 dx = \\int_0^1 \\left|\\frac{h(x)}{x} \\chi_{(\\delta,1)}(x)\\right|^2 dx = \\int_{\\delta}^1 \\frac{|h(x)|^2}{x^2} dx\n$$\n在积分区间 $[\\delta,1]$ 上，我们有 $x \\ge \\delta  0$，这意味着 $\\frac{1}{x^2} \\le \\frac{1}{\\delta^2}$。因此，\n$$\n\\|f_{\\delta}\\|_{L^2}^2 \\le \\int_{\\delta}^1 \\frac{|h(x)|^2}{\\delta^2} dx = \\frac{1}{\\delta^2} \\int_{\\delta}^1 |h(x)|^2 dx \\le \\frac{1}{\\delta^2} \\int_0^1 |h(x)|^2 dx = \\frac{1}{\\delta^2} \\|h\\|_{L^2}^2\n$$\n由于 $h \\in L^2(0,1)$，其范数 $\\|h\\|_{L^2}$ 是有限的。对于任何固定的 $\\delta  0$，$\\|f_{\\delta}\\|_{L^2}^2$ 是有限的，所以 $f_{\\delta} \\in L^2(0,1)$。这证实了对于任何 $\\delta \\in (0,1)$，$g_{\\delta} \\in \\operatorname{Ran}(T)$。\n现在我们考察 $h$ 与我们的近似函数 $g_{\\delta}$ 之间的距离：\n$$\n\\|h - g_{\\delta}\\|_{L^2}^2 = \\int_0^1 |h(x) - g_{\\delta}(x)|^2 dx = \\int_0^1 |h(x) - h(x)\\chi_{(\\delta,1)}(x)|^2 dx = \\int_0^1 |h(x)(1 - \\chi_{(\\delta,1)}(x))|^2 dx\n$$\n由于对于 $x \\in [0,1]$，$1 - \\chi_{(\\delta,1)}(x) = \\chi_{[0,\\delta]}(x)$，我们有：\n$$\n\\|h - g_{\\delta}\\|_{L^2}^2 = \\int_0^1 |h(x)\\chi_{[0,\\delta]}(x)|^2 dx = \\int_0^{\\delta} |h(x)|^2 dx\n$$\n函数 $F(y) = \\int_0^y |h(x)|^2 dx$ 是 $y$ 的一个绝对连续函数。因为 $|h|^2$ 是一个可积函数（因为 $h \\in L^2$），我们有 $\\lim_{\\delta \\to 0^+} \\int_0^{\\delta} |h(x)|^2 dx = 0$。\n因此，对于任意给定的 $\\epsilon  0$，我们可以选择一个足够小的 $\\delta  0$，使得 $\\|h - g_{\\delta}\\|_{L^2}^2  \\epsilon^2$，这意味着 $\\|h - g_{\\delta}\\|_{L^2}  \\epsilon$。我们找到了 $\\operatorname{Ran}(T)$ 中的一个元素 $g_{\\delta}$，它与 $h$ 任意接近。这证明了 $\\operatorname{Ran}(T)$ 在 $L^2(0,1)$ 中是稠密的。\n\n第三，我们证明逆问题缺乏稳定性。在此背景下，稳定性意味着逆算子 $T^{-1}: \\operatorname{Ran}(T) \\to L^2(0,1)$ 是有界的。如果存在一个常数 $C$ 使得对于所有 $g \\in \\operatorname{Ran}(T)$ 都有 $\\|T^{-1}g\\|_{L^2} \\le C \\|g\\|_{L^2}$，则算子是有界的。我们将通过构造一个函数序列 $\\{f_n\\}_{n\\in\\mathbb{N}}$ 来证明 $T^{-1}$ 是无界的，该序列使得比值 $\\frac{\\|f_n\\|_{L^2}}{\\|Tf_n\\|_{L^2}}$ 是无界的。\n令 $f_n(x) = n \\chi_{(0,1/n)}(x)$，其中 $n \\in \\mathbb{N}$ 且 $n \\ge 2$。\n我们计算 $f_n$ 的 $L^2$-范数：\n$$\n\\|f_n\\|_{L^2}^2 = \\int_0^1 |f_n(x)|^2 dx = \\int_0^{1/n} n^2 dx = n^2 [x]_0^{1/n} = n^2 \\left(\\frac{1}{n}\\right) = n\n$$\n所以，$\\|f_n\\|_{L^2} = \\sqrt{n}$。当 $n \\to \\infty$ 时，$\\|f_n\\|_{L^2} \\to \\infty$。\n\n接下来，我们计算相应的数据 $g_n = Tf_n$ 及其范数。\n$$\ng_n(x) = (Tf_n)(x) = x f_n(x) = x(n \\chi_{(0,1/n)}(x)) = nx \\chi_{(0,1/n)}(x)\n$$\n$g_n$ 的 $L^2$-范数是：\n$$\n\\|g_n\\|_{L^2}^2 = \\|Tf_n\\|_{L^2}^2 = \\int_0^1 |g_n(x)|^2 dx = \\int_0^{1/n} (nx)^2 dx = n^2 \\int_0^{1/n} x^2 dx\n$$\n$$\n\\|Tf_n\\|_{L^2}^2 = n^2 \\left[\\frac{x^3}{3}\\right]_0^{1/n} = n^2 \\left(\\frac{(1/n)^3}{3}\\right) = n^2 \\left(\\frac{1}{3n^3}\\right) = \\frac{1}{3n}\n$$\n所以，$\\|Tf_n\\|_{L^2} = \\sqrt{\\frac{1}{3n}} = \\frac{1}{\\sqrt{3n}}$。当 $n \\to \\infty$ 时，$\\|Tf_n\\|_{L^2} \\to 0$。\n\n我们构造了一个序列 $\\{f_n\\}$，其范数趋于无穷大，而数据 $\\{Tf_n\\}$ 的范数趋于零。这表明数据中的微小扰动可能导致解的任意大扰动，这是不稳定性的标志。算子 $T^{-1}$ 是无界的，因为当 $n \\to \\infty$ 时，比值 $\\frac{\\|f_n\\|_{L^2}}{\\|Tf_n\\|_{L^2}}$ 无界增长。\n\n最后，我们计算放大因子 $A_n$ 的精确解析表达式：\n$$\nA_n \\equiv \\frac{\\|f_n\\|_{L^2}}{\\|T f_n\\|_{L^2}}\n$$\n使用我们先前计算的范数：\n$$\nA_n = \\frac{\\sqrt{n}}{\\frac{1}{\\sqrt{3n}}} = \\sqrt{n} \\cdot \\sqrt{3n} = \\sqrt{3n^2} = n\\sqrt{3}\n$$\n当 $n \\to \\infty$ 时，$A_n \\to \\infty$，这明确地证实了逆算子的无界性。",
            "answer": "$$\n\\boxed{n\\sqrt{3}}\n$$"
        },
        {
            "introduction": "理论的价值在于指导实践。本练习将理论与地球科学和工程领域中一个至关重要的应用——数据同化——联系起来。你将通过一个计算实验，模拟集合卡尔曼滤波器（EnKF）中的一个关键步骤，并探索在有限集合样本下出现的不适定性问题。通过亲手实现协方差膨胀和局域化这两种正则化技术，你将量化它们是如何改善问题的条件数，从而有效缓解数值不稳定性。",
            "id": "3387787",
            "problem": "考虑一个使用集成卡尔曼滤波器（EnKF）的线性高斯数据同化问题，其中分析步通过求解观测空间线性系统来获得分析均值。设预报（背景）状态的维度为 $n$，观测数量为 $m$，集合大小为 $N_e$，预报误差协方差为 $P^f \\in \\mathbb{R}^{n \\times n}$，线性观测算子为 $H \\in \\mathbb{R}^{m \\times n}$，观测误差协方差为 $R \\in \\mathbb{R}^{m \\times m}$。经典的分析公式引入了对称正定（SPD）矩阵 $$S = H P^f H^\\top + R,$$ 其逆矩阵将观测空间中的新息映射到分析增量。在 Hadamard 适定性（解的存在性、唯一性和稳定性）的意义上，分析步的数值稳定性由谱条件数来量化 $$\\kappa(S) = \\frac{\\lambda_{\\max}(S)}{\\lambda_{\\min}(S)},$$ 其中 $\\lambda_{\\max}$ 和 $\\lambda_{\\min}$ 分别表示最大和最小特征值。大的 $\\kappa(S)$ 表示病态，意味着数据中的小扰动可能导致分析增量的大扰动。\n\n两种标准的修正方法在形成 $S$ 之前修改 $P^f$：\n- 使用参数 $\\beta \\ge 0$ 的加性协方差膨胀，$$\\widetilde{P}^f_{\\text{add}} = P^f + \\beta I_n.$$\n- 使用相关矩阵 $L(\\ell) \\in \\mathbb{R}^{n \\times n}$ 进行协方差局地化，该矩阵由长度尺度为 $\\ell  0$ 的高斯相关函数构建，通过舒尔（Hadamard）积作用，$$\\widetilde{P}^f_{\\text{loc}} = L(\\ell) \\circ P^f,$$ 其中 $[L(\\ell)]_{ij} = \\exp\\!\\left(-\\left(\\frac{d_{ij}}{\\ell}\\right)^2\\right)$，$d_{ij}$ 是在 $[0,1]$ 上的均匀一维网格上点 $i$ 和 $j$ 之间的欧几里得距离，$\\circ$ 表示逐元素乘法。对于 $\\ell \\le 0$，定义 $L(\\ell)$ 为全1矩阵，这样局地化不起作用。两者结合得到 $$\\widetilde{P}^f_{\\text{both}} = \\left(L(\\ell) \\circ P^f\\right) + \\beta I_n.$$\n\n您的任务是实现一个确定性的、可复现的实验，该实验构建合成的 $P^f$ 并形成 $$S_{\\text{base}} = H P^f H^\\top + R,\\quad S_{\\text{add}} = H \\widetilde{P}^f_{\\text{add}} H^\\top + R,\\quad S_{\\text{loc}} = H \\widetilde{P}^f_{\\text{loc}} H^\\top + R,\\quad S_{\\text{both}} = H \\widetilde{P}^f_{\\text{both}} H^\\top + R,$$ 然后量化条件数改善因子 $$\\rho_{\\text{add}} = \\frac{\\kappa(S_{\\text{base}})}{\\kappa(S_{\\text{add}})},\\quad \\rho_{\\text{loc}} = \\frac{\\kappa(S_{\\text{base}})}{\\kappa(S_{\\text{loc}})},\\quad \\rho_{\\text{both}} = \\frac{\\kappa(S_{\\text{base}})}{\\kappa(S_{\\text{both}})}.$$ $\\rho  1$ 的值表示条件数改善（条件数变小），反映了稳定性的提高，从而使分析步向适定性恢复。\n\n使用以下基本基础和构造：\n- 分析步由线性高斯最小二乘代价函数定义 $$J(x) = \\frac{1}{2}\\|x - x^f\\|_{(P^f)^{-1}}^2 + \\frac{1}{2}\\|y - H x\\|_{R^{-1}}^2.$$ 观测空间中的正规方程涉及 $S = H P^f H^\\top + R$，其可逆性和条件数控制解的稳定性。\n- 观测算子是选择矩阵 $H = [I_m, 0] \\in \\mathbb{R}^{m \\times n}$，它精确观测前 $m$ 个状态分量。\n- 观测误差协方差是 $R = \\sigma_R^2 I_m$，其中给定标量 $\\sigma_R^2  0$。\n- 预报协方差 $P^f$ 根据下文规定，从一个合成集合或一个结构化低秩形式确定性地构造。当使用集合时，通过对列进行中心化并按 $\\sqrt{N_e - 1}$ 缩放来形成集合异常 $A \\in \\mathbb{R}^{n \\times N_e}$，然后设置 $P^f = A A^\\top$。\n\n在均匀网格点 $x_i = \\frac{i}{n-1}$（其中 $i \\in \\{0,1,\\dots,n-1\\}$）上实现高斯局地化 $L(\\ell)$，距离为 $d_{ij} = |x_i - x_j|$。对于 $\\ell \\le 0$，设置 $L(\\ell) = \\mathbf{1}\\mathbf{1}^\\top$。\n\n测试套件：\n对于下面的每个测试用例，根据指定的模式构造 $P^f$。如果模式是“ensemble”，则使用给定的种子确定性地抽取异常，通过对角缩放 $D = \\mathrm{diag}(s)$（其中对于 $i = 0,\\dots,n-1$，$s_i = \\exp\\!\\left(g \\cdot \\left(\\frac{i}{n-1} - \\frac{1}{2}\\right)\\right)$）施加一个参数为 $g$ 的各向异性剖面，并在形成 $P^f = A A^\\top$ 之前设置 $A \\leftarrow D A$。如果模式是“rank1”，则使用给定的种子确定性地抽取一个向量 $u \\in \\mathbb{R}^n$，将其归一化为 $\\|u\\|_2 = 1$，并设置 $P^f = \\sigma_r^2 u u^\\top + \\epsilon I_n$。\n\n- 测试用例1（典型路径，使用小R的欠分散低秩集合）：\n  - $n=40$, $m=40$, $N_e=8$, $\\sigma_R^2 = 10^{-4}$, $\\beta = 10^{-2}$, $\\ell = 0.15$, seed $=42$, mode $=$ “ensemble”, $g = \\log(10^5)$。\n\n- 测试用例2（边界情况，使用极小R的极端秩亏）：\n  - $n=60$, $m=30$, $N_e=3$, $\\sigma_R^2 = 10^{-6}$, $\\beta = 10^{-3}$, $\\ell = 0.2$, seed $=123$, mode $=$ “ensemble”, $g = \\log(10^8)$。\n\n- 测试用例3（边缘情况，已是良态，关闭修正）：\n  - $n=40$, $m=40$, $N_e=80$, $\\sigma_R^2 = 10^{-1}$, $\\beta = 0$, $\\ell = 0$, seed $=7$, mode $=$ “ensemble”, $g = \\log(10)$。\n\n- 测试用例4（边缘情况，凸显局地化在强虚假远程相关下的优势）：\n  - $n=50$, $m=50$, $N_e=10$ (未使用), $\\sigma_R^2 = 10^{-3}$, $\\beta = 0$, $\\ell = 0.25$, seed $=99$, mode $=$ “rank1”, $\\sigma_r = 5$, $\\epsilon = 10^{-8}$。\n\n计算与输出：\n- 对于每个测试用例，通过特征值计算 $\\kappa(S_{\\text{base}})$、$\\kappa(S_{\\text{add}})$、$\\kappa(S_{\\text{loc}})$、$\\kappa(S_{\\text{both}})$（使用对称特征值例程），然后计算 $\\rho_{\\text{add}}$、$\\rho_{\\text{loc}}$、$\\rho_{\\text{both}}$。\n- 您的程序应生成单行输出，其中包含按顺序排列的4个测试用例的各3个改善因子组成的平坦列表，每个值四舍五入到6位小数，格式如下\n  $$[\\rho_{\\text{add}}^{(1)},\\rho_{\\text{loc}}^{(1)},\\rho_{\\text{both}}^{(1)},\\rho_{\\text{add}}^{(2)},\\rho_{\\text{loc}}^{(2)},\\rho_{\\text{both}}^{(2)},\\rho_{\\text{add}}^{(3)},\\rho_{\\text{loc}}^{(3)},\\rho_{\\text{both}}^{(3)},\\rho_{\\text{add}}^{(4)},\\rho_{\\text{loc}}^{(4)},\\rho_{\\text{both}}^{(4)}].$$\n- 程序不应读取任何输入；所有参数均如上所述，且程序必须是自包含和确定性的。\n\n所有数学符号必须遵循标准线性代数惯例，此问题不涉及任何物理单位或角度。将所有最终数值输出表示为四舍五入到小数点后六位的十进制浮点数。",
            "solution": "用户要求对两种标准技术——加性协方差膨胀和协方差局地化——进行定量评估，这两种技术用于改善集成卡尔曼滤波器（EnKF）中分析步的数值稳定性。稳定性通过矩阵 $S = H P^f H^\\top + R$ 的谱条件数来衡量，该矩阵出现在正规方程中。较低的条件数表示在 Hadamard 意义上系统更稳定或更适定。该问题在科学上有效，是自包含的，且算法上定义明确。\n\n解决方案首先定义所有数学组件，然后概述为每个测试用例计算所需条件数改善因子的计算步骤。\n\n**1. 数学公式**\n\n数据同化分析步的核心是矩阵 $S \\in \\mathbb{R}^{m \\times m}$ 的形成和求逆，其定义为：\n$$S = H P^f H^\\top + R$$\n其中 $P^f \\in \\mathbb{R}^{n \\times n}$ 是预报误差协方差，$H \\in \\mathbb{R}^{m \\times n}$ 是观测算子，$R \\in \\mathbb{R}^{m \\times m}$ 是观测误差协方差。对于此问题，这些矩阵的构造如下：\n\n- **观测算子 $H$**：该算子是一个选择矩阵 $H = [I_m, 0] \\in \\mathbb{R}^{m \\times n}$，它观测 $n$ 个状态变量中的前 $m$ 个。一个关键的推论是，对于任何矩阵 $M \\in \\mathbb{R}^{n \\times n}$，矩阵乘积 $H M H^\\top$ 等效于选择 $M$ 的左上角 $m \\times m$ 子块。\n- **观测误差协方差 $R$**：此矩阵假定为对角且均匀的，由 $R = \\sigma_R^2 I_m$ 给出，其中 $\\sigma_R^2  0$ 是观测误差方差，$I_m$ 是 $m \\times m$ 的单位矩阵。\n- **预报误差协方差 $P^f$**：$P^f$ 的构造取决于指定的模式。\n    - **模式 \"ensemble\"**：$P^f$ 是从一个合成集合生成的。从标准正态分布中抽取一个原始状态集合 $X \\in \\mathbb{R}^{n \\times N_e}$，并为可复现性设置种子。通过对 $N_e$ 个成员（列）进行平均来计算集合平均状态 $\\bar{x} \\in \\mathbb{R}^n$。然后异常矩阵为 $A' = X - \\bar{x}$。问题陈述在“对列进行中心化”方面存在歧义；此处采用创建集合异常的科学标准解释，即从每个集合成员向量中减去平均状态向量（即 `mean(axis=1)`）。公式 $P^f = A A^\\top$ 中使用的矩阵 $A \\in \\mathbb{R}^{n \\times N_e}$ 定义为 $A = \\frac{1}{\\sqrt{N_e - 1}} A'$。这与样本协方差的定义一致。通过对角缩放矩阵 $D = \\mathrm{diag}(s)$（其中 $s_i = \\exp(g \\cdot (\\frac{i}{n-1} - \\frac{1}{2}))$）引入各向异性剖面。最终的异常变换为 $A \\rightarrow D A$，得到 $P^f = (D A)(D A)^\\top = D A A^\\top D^\\top$。\n    - **模式 \"rank1\"**：$P^f$ 被构造成一个秩-1矩阵加上一个小的正则化项。从标准正态分布中抽取一个向量 $u \\in \\mathbb{R}^n$，并将其归一化以使欧几里得范数为 $1$。然后协方差为 $P^f = \\sigma_r^2 u u^\\top + \\epsilon I_n$。这种结构模拟了一个由单一误差模式主导的系统，并带有少量各向同性的背景误差。\n\n- **稳定性度量**：数值稳定性通过 $S$ 的谱条件数 $\\kappa(S) = \\frac{\\lambda_{\\max}(S)}{\\lambda_{\\min}(S)}$ 来量化，其中 $\\lambda_{\\max}$ 和 $\\lambda_{\\min}$ 分别是 $S$ 的最大和最小特征值。由于 $P^f$ 是对称半正定的，$R$ 是对称正定的，因此 $S$ 是对称正定的，这保证了其特征值为实数且为正。\n\n**2. 协方差修正技术**\n\n在用于形成 $S$ 之前，有两种技术被应用于修改 $P^f$。\n\n- **加性膨胀**：将一个缩放后的单位矩阵加到 $P^f$ 上，以增加其方差并确保其是良态的。\n$$\\widetilde{P}^f_{\\text{add}} = P^f + \\beta I_n \\quad (\\beta \\ge 0)$$\n这直接将 $P^f$ 的所有特征值增加 $\\beta$，从而也增加了 $H P^f H^\\top$ 的特征值。\n\n- **协方差局地化**：通过与相关矩阵 $L(\\ell)$ 进行逐元素相乘，来抑制由小集合大小引起的虚假远程相关。\n$$\\widetilde{P}^f_{\\text{loc}} = L(\\ell) \\circ P^f$$\n矩阵 $L(\\ell)$ 由一个在一维均匀网格 $x_i = \\frac{i}{n-1}$（其中 $i=0, \\dots, n-1$）上的高斯相关函数构造。其元素为 $[L(\\ell)]_{ij} = \\exp(-\\frac{d_{ij}^2}{\\ell^2})$，其中 $d_{ij} = |x_i - x_j|$ 是网格点之间的距离，$\\ell  0$ 是局地化长度尺度。对于 $\\ell \\le 0$，$L(\\ell)$ 是全1矩阵，导致没有修正，即 $L(0) \\circ P^f = P^f$。\n\n- **组合方法**：两种技术可以相继应用。\n$$\\widetilde{P}^f_{\\text{both}} = (L(\\ell) \\circ P^f) + \\beta I_n$$\n\n**3. 算法实现**\n\n对四个测试用例中的每一个，执行以下步骤：\n1.  定义参数 $n, m, N_e, \\sigma_R^2, \\beta, \\ell$，以及构造 `mode` 及其特定参数。\n2.  根据指定的 `mode` 和 `seed` 确定性地构造基础预报协方差 $P^f$。\n3.  根据维度 $n$ 的网格构造局地化矩阵 $L(\\ell)$。\n4.  计算四个版本的 $S$ 矩阵：\n    - $S_{\\text{base}} = H P^f H^\\top + R$\n    - $S_{\\text{add}} = H (P^f + \\beta I_n) H^\\top + R$\n    - $S_{\\text{loc}} = H (L(\\ell) \\circ P^f) H^\\top + R$\n    - $S_{\\text{both}} = H ((L(\\ell) \\circ P^f) + \\beta I_n) H^\\top + R$\n    矩阵乘积 $H M H^\\top$ 通过对 $M$ 的左上角 $m \\times m$ 块进行切片来高效实现。\n5.  每个对称矩阵 $S$ 的特征值使用专门用于对称矩阵的数值例程（例如 `scipy.linalg.eigh`）计算。\n6.  每个 $S$ 矩阵的条件数计算为 $\\lambda_{\\max} / \\lambda_{\\min}$。\n7.  三个条件数改善因子计算为基线条件数与修正后条件数的比值：\n    - $\\rho_{\\text{add}} = \\kappa(S_{\\text{base}}) / \\kappa(S_{\\text{add}})$\n    - $\\rho_{\\text{loc}} = \\kappa(S_{\\text{base}}) / \\kappa(S_{\\text{loc}})$\n    - $\\rho_{\\text{both}} = \\kappa(S_{\\text{base}}) / \\kappa(S_{\\text{both}})$\n8.  收集并格式化得到的十二个浮点数（四个用例，每个用例三个因子）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef get_condition_number(matrix):\n    \"\"\"\n    Computes the spectral condition number of a real, symmetric matrix.\n    Uses scipy.linalg.eigh for numerical stability and efficiency.\n    \"\"\"\n    # eigh is designed for symmetric/Hermitian matrices and guarantees real eigenvalues.\n    eigenvalues = eigh(matrix, eigvals_only=True)\n    \n    # In theory, S should be positive definite, so all eigenvalues > 0.\n    # The check below handles cases where the smallest eigenvalue is non-positive\n    # due to rank deficiency or numerical precision issues.\n    min_eig = np.min(eigenvalues)\n    max_eig = np.max(eigenvalues)\n\n    # If min_eig is non-positive or very close to zero, the condition number is effectively infinite.\n    if min_eig = 1e-15:\n        return np.inf\n        \n    return max_eig / min_eig\n\ndef compute_factors_for_case(params: dict) -> list[float]:\n    \"\"\"\n    Runs a single test case to compute the conditioning improvement factors.\n    \"\"\"\n    n = params['n']\n    m = params['m']\n    Ne = params['Ne']\n    sigma_R_sq = params['sigma_R_sq']\n    beta = params['beta']\n    l_scale = params['l']\n    seed = params['seed']\n    mode = params['mode']\n    \n    rng = np.random.default_rng(seed)\n\n    # --- 1. Construct Forecast Error Covariance Pf ---\n    if mode == \"ensemble\":\n        g = params['g']\n        \n        # Draw a raw ensemble from a standard normal distribution.\n        ensemble = rng.standard_normal((n, Ne))\n        \n        # Center the ensemble to get anomalies.\n        ensemble_mean = ensemble.mean(axis=1, keepdims=True)\n        anomalies_prime = ensemble - ensemble_mean\n        \n        # Scale to form the matrix A such that Pf = A @ A.T.\n        if Ne > 1:\n            A = anomalies_prime / np.sqrt(Ne - 1)\n        else:\n            A = np.zeros((n, Ne))\n\n        # Apply anisotropy profile.\n        grid_points = np.linspace(0, 1, n)\n        s = np.exp(g * (grid_points - 0.5))\n        D = np.diag(s)\n        A_aniso = D @ A\n        \n        Pf = A_aniso @ A_aniso.T\n\n    elif mode == \"rank1\":\n        sigma_r = params['sigma_r']\n        epsilon = params['epsilon']\n        \n        u_raw = rng.standard_normal(n)\n        u = u_raw / np.linalg.norm(u_raw)\n        \n        Pf = sigma_r**2 * np.outer(u, u) + epsilon * np.eye(n)\n\n    # --- 2. Construct other components: R, L and H (implicitly) ---\n    # The action of H @ M @ H.T is to select the top-left m x m sub-block.\n    H_select = lambda M: M[:m, :m]\n    \n    R = sigma_R_sq * np.eye(m)\n    \n    if l_scale = 0:\n        L = np.ones((n, n))\n    else:\n        grid_points = np.linspace(0, 1, n)\n        dist_matrix = np.abs(grid_points[:, None] - grid_points)\n        L = np.exp(-(dist_matrix / l_scale)**2)\n\n    # --- 3. Construct modified Pf matrices ---\n    Pf_add = Pf + beta * np.eye(n)\n    Pf_loc = L * Pf  # Schur (element-wise) product\n    Pf_both = Pf_loc + beta * np.eye(n)\n\n    # --- 4. Construct S matrices ---\n    S_base = H_select(Pf) + R\n    S_add = H_select(Pf_add) + R\n    S_loc = H_select(Pf_loc) + R\n    S_both = H_select(Pf_both) + R\n    \n    # --- 5. Compute condition numbers ---\n    kappa_base = get_condition_number(S_base)\n    kappa_add = get_condition_number(S_add)\n    kappa_loc = get_condition_number(S_loc)\n    kappa_both = get_condition_number(S_both)\n    \n    # --- 6. Compute improvement factors ---\n    rho_add = kappa_base / kappa_add if kappa_add > 0 else np.inf\n    rho_loc = kappa_base / kappa_loc if kappa_loc > 0 else np.inf\n    rho_both = kappa_base / kappa_both if kappa_both > 0 else np.inf\n    \n    return [rho_add, rho_loc, rho_both]\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the experiment, and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {'n': 40, 'm': 40, 'Ne': 8, 'sigma_R_sq': 1e-4, 'beta': 1e-2, 'l': 0.15, \n         'seed': 42, 'mode': \"ensemble\", 'g': np.log(10**5)},\n        # Test case 2\n        {'n': 60, 'm': 30, 'Ne': 3, 'sigma_R_sq': 1e-6, 'beta': 1e-3, 'l': 0.2, \n         'seed': 123, 'mode': \"ensemble\", 'g': np.log(10**8)},\n        # Test case 3\n        {'n': 40, 'm': 40, 'Ne': 80, 'sigma_R_sq': 1e-1, 'beta': 0, 'l': 0, \n         'seed': 7, 'mode': \"ensemble\", 'g': np.log(10)},\n        # Test case 4\n        {'n': 50, 'm': 50, 'Ne': 10, 'sigma_R_sq': 1e-3, 'beta': 0, 'l': 0.25, \n         'seed': 99, 'mode': \"rank1\", 'sigma_r': 5, 'epsilon': 1e-8}\n    ]\n\n    all_results = []\n    for case in test_cases:\n        rhos = compute_factors_for_case(case)\n        all_results.extend(rhos)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.6f}\" for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}