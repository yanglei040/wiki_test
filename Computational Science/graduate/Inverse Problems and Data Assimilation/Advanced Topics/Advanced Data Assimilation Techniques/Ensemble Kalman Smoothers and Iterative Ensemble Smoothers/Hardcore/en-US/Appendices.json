{
    "hands_on_practices": [
        {
            "introduction": "This first practice serves as your entry point into constructing a smoother from fundamental principles. You will implement a \"two-time\" Ensemble Kalman Smoother (EnKS) for a simple linear system, which is the canonical model for understanding the core mechanics. By coding the update yourself, you will gain a concrete understanding of how ensemble-based cross-covariances are used to propagate information from a future observation backward in time to improve the estimate of a past state .",
            "id": "3379469",
            "problem": "Implement a two-time Ensemble Kalman Smoother (EnKS) for a linear scalar state-space system and compute the smoothed ensemble mean at the initial time after assimilating a single observation at the next time. Use the following base and definitions to derive your algorithm.\n\nThe system is linear, scalar, and Gaussian:\n- State evolution: $x_1 = a \\, x_0 + w_0$, where $w_0 \\sim \\mathcal{N}(0, q)$ and $x_0$ denotes the state at time $t = 0$, and $x_1$ at time $t = 1$.\n- Observation: $y_1 = H \\, x_1 + v_1$, where $H = 1$, $v_1 \\sim \\mathcal{N}(0, r)$, and $y_1$ is the observed value at time $t = 1$.\n\nAssume an ensemble of size $N$ is used to represent the prior at time $t = 0$ with prior distribution $x_0 \\sim \\mathcal{N}(m_0, P_0)$. The goal is to compute the smoothed ensemble mean at time $t = 0$ after assimilating the observation $y_1$ at time $t = 1$ using a two-time EnKS.\n\nUse these fundamental and well-tested definitions:\n- The sample mean of a vector $\\{z^{(n)}\\}_{n=1}^N$ is $\\bar{z} = \\frac{1}{N} \\sum_{n=1}^N z^{(n)}$.\n- The unbiased sample covariance between ensemble vectors $\\{x^{(n)}\\}_{n=1}^N$ and $\\{y^{(n)}\\}_{n=1}^N$ is $\\operatorname{Cov}(x, y) = \\frac{1}{N - 1} \\sum_{n=1}^N \\left(x^{(n)} - \\bar{x}\\right)\\left(y^{(n)} - \\bar{y}\\right)$, and the unbiased sample variance is $\\operatorname{Var}(x) = \\operatorname{Cov}(x, x)$.\n- The stochastic Ensemble Kalman Filter (EnKF) uses perturbed observations $\\tilde{y}^{(n)} = y_1 + \\epsilon^{(n)}$ with $\\epsilon^{(n)} \\sim \\mathcal{N}(0, r)$ independently for each ensemble member to ensure correct posterior variance in the linear-Gaussian case.\n\nImplement the following algorithmic outline from these base principles:\n- At time $t = 0$, draw an initial ensemble $\\{x_0^{(n)}\\}_{n=1}^N$ from $\\mathcal{N}(m_0, P_0)$.\n- Propagate each ensemble member forward to obtain the forecast ensemble at time $t = 1$: $x_1^{f,(n)} = a \\, x_0^{(n)} + w_0^{(n)}$, with $w_0^{(n)} \\sim \\mathcal{N}(0, q)$ independently.\n- Perform a stochastic EnKF analysis at time $t = 1$ using perturbed observations to obtain the analysis ensemble $\\{x_1^{a,(n)}\\}_{n=1}^N$ from $\\{x_1^{f,(n)}\\}_{n=1}^N$ by a best linear update based on ensemble covariances.\n- Apply the two-time EnKS update to map the analysis increment at time $t = 1$ back to time $t = 0$ using the best linear predictor based on ensemble cross-covariance between $\\{x_0^{(n)}\\}_{n=1}^N$ and $\\{x_1^{f,(n)}\\}_{n=1}^N$. If the sample variance at time $t = 1$ is numerically zero, set the smoother gain to $0$.\n- Output the smoothed ensemble mean $\\bar{x}_0^{s} = \\frac{1}{N} \\sum_{n=1}^N x_0^{s,(n)}$.\n\nUse the fixed parameters $a = 0.9$, $q = 0.1$, $r = 0.4$, and $N = 10$, and $H = 1$. For reproducibility, for each test case with index $i$ (starting at $i = 0$), set the random seed to $1000 + i$. When sampling from $\\mathcal{N}(m_0, P_0)$, if $P_0 = 0$, take all ensemble members to be exactly $m_0$.\n\nTest suite. For each parameter set below, compute the smoothed ensemble mean at time $t = 0$ after assimilating $y_1$:\n- Case $1$: $(m_0, P_0, y_1) = (1.0, 1.0, 0.5)$, seed $= 1000$.\n- Case $2$: $(m_0, P_0, y_1) = (0.0, 0.0, 0.0)$, seed $= 1001$.\n- Case $3$: $(m_0, P_0, y_1) = (-2.0, 4.0, 1.0)$, seed $= 1002$.\n- Case $4$: $(m_0, P_0, y_1) = (0.5, 0.5, 0.45)$, seed $= 1003$.\n- Case $5$: $(m_0, P_0, y_1) = (0.0, 1.0, 5.0)$, seed $= 1004$.\n\nFinal output format. Your program should produce a single line of output containing a list of the $5$ smoothed means, rounded to $6$ decimal places, as a comma-separated list enclosed in square brackets (for example, $[x_1, x_2, x_3, x_4, x_5]$).",
            "solution": "The problem requires the implementation of a two-time Ensemble Kalman Smoother (EnKS) for a linear, scalar, Gaussian state-space system. The objective is to compute the smoothed ensemble mean of the state at the initial time, $t=0$, after assimilating a single observation at time $t=1$. The solution is derived from the fundamental principles of ensemble-based data assimilation.\n\nThe system is defined by:\n1.  State evolution model: $x_1 = a \\, x_0 + w_0$, where $x_k$ is the state at time $t=k$, $a$ is a constant coefficient, and $w_0$ is the process noise, drawn from a normal distribution $w_0 \\sim \\mathcal{N}(0, q)$.\n2.  Observation model: $y_1 = H \\, x_1 + v_1$, where $y_1$ is the observation at $t=1$, $H$ is the observation operator (given as $H=1$), and $v_1$ is the observation noise, $v_1 \\sim \\mathcal{N}(0, r)$.\n\nThe algorithm proceeds in several steps, starting from an initial ensemble representing the prior knowledge of the state at $t=0$, and sequentially updating this knowledge based on the observation at $t=1$.\n\n**Step 1: Ensemble Initialization**\nThe prior knowledge about the state at $t=0$ is given by a normal distribution $x_0 \\sim \\mathcal{N}(m_0, P_0)$. This distribution is represented by an ensemble of $N$ members, $\\{x_0^{(n)}\\}_{n=1}^N$. Each member is a sample drawn from this distribution. For a non-zero prior variance $P_0 > 0$, the samples are generated as $x_0^{(n)} \\sim \\mathcal{N}(m_0, P_0)$. In the special case where the prior variance is zero, $P_0=0$, the state is known perfectly, and all ensemble members are set to the mean, $x_0^{(n)} = m_0$ for all $n \\in \\{1, \\dots, N\\}$.\n\n**Step 2: Forecast to Time $t=1$**\nEach member of the initial ensemble is propagated forward in time using the state evolution model. An independent realization of the process noise $w_0^{(n)} \\sim \\mathcal{N}(0, q)$ is added to each member. This produces the forecast ensemble at $t=1$, denoted by $\\{x_1^{f,(n)}\\}_{n=1}^N$:\n$$x_1^{f,(n)} = a \\, x_0^{(n)} + w_0^{(n)}$$\n\n**Step 3: Analysis at Time $t=1$**\nThe analysis step updates the forecast ensemble using the observation $y_1$. A stochastic Ensemble Kalman Filter (EnKF) is employed. The key idea is to compute a Kalman-like gain from sample statistics and update each ensemble member. To ensure the posterior ensemble has a statistically correct variance, perturbed observations are used.\n\nThe analysis update for each ensemble member is:\n$$x_1^{a,(n)} = x_1^{f,(n)} + K_1 \\left( \\tilde{y}^{(n)} - H x_1^{f,(n)} \\right)$$\nwhere $\\{x_1^{a,(n)}\\}_{n=1}^N$ is the analysis ensemble at $t=1$.\n\nThe components of this update are:\n-   **Perturbed Observations**: $\\tilde{y}^{(n)} = y_1 + \\epsilon^{(n)}$, where each $\\epsilon^{(n)}$ is an independent draw from the observation noise distribution, $\\epsilon^{(n)} \\sim \\mathcal{N}(0, r)$.\n-   **Forecast Observations**: Since $H=1$, the forecast observation for each member is $y_1^{f,(n)} = H x_1^{f,(n)} = x_1^{f,(n)}$.\n-   **Kalman Gain $K_1$**: The gain is computed using sample covariances. It is the ratio of the sample covariance of the state with the observations to the sample variance of the forecast observations, including observation error.\n    $$K_1 = \\frac{\\operatorname{Cov}(x_1^f, y_1^f)}{\\operatorname{Var}(y_1^f) + r}$$\n    Using the unbiased sample variance operator $\\operatorname{Var}(\\cdot)$ and $H=1$, this becomes:\n    $$K_1 = \\frac{\\operatorname{Var}(x_1^f)}{\\operatorname{Var}(x_1^f) + r}$$\n    where $\\operatorname{Var}(x_1^f) = \\frac{1}{N-1} \\sum_{n=1}^N \\left(x_1^{f,(n)} - \\bar{x}_1^f\\right)^2$, and $\\bar{x}_1^f$ is the mean of the forecast ensemble.\n\nCombining these, the analysis update is:\n$$x_1^{a,(n)} = x_1^{f,(n)} + \\frac{\\operatorname{Var}(x_1^f)}{\\operatorname{Var}(x_1^f) + r} \\left( y_1 + \\epsilon^{(n)} - x_1^{f,(n)} \\right)$$\n\n**Step 4: Smoothing to Time $t=0$**\nThe Ensemble Kalman Smoother (EnKS) updates the initial ensemble at $t=0$ to be consistent with the analysis at $t=1$. This is achieved by regressing the analysis increment at $t=1$, $(x_1^{a,(n)} - x_1^{f,(n)})$, onto the state at $t=0$. This regression is based on the cross-covariance between the states at $t=0$ and $t=1$.\n\nThe smoothed ensemble at $t=0$, $\\{x_0^{s,(n)}\\}_{n=1}^N$, is given by:\n$$x_0^{s,(n)} = x_0^{(n)} + K_0 \\left( x_1^{a,(n)} - x_1^{f,(n)} \\right)$$\n\n-   **Smoother Gain $K_0$**: This gain is the best linear predictor, computed from the ensemble, that maps anomalies at $t=1$ to anomalies at $t=0$.\n    $$K_0 = \\frac{\\operatorname{Cov}(x_0, x_1^f)}{\\operatorname{Var}(x_1^f)}$$\n    The unbiased sample cross-covariance is $\\operatorname{Cov}(x_0, x_1^f) = \\frac{1}{N-1} \\sum_{n=1}^N \\left(x_0^{(n)} - \\bar{x}_0\\right)\\left(x_1^{f,(n)} - \\bar{x}_1^f\\right)$.\n    \nA special case is handled: if $\\operatorname{Var}(x_1^f)$ is numerically zero, it implies the forecast ensemble has no spread, and no update can be performed. In this situation, the smoother gain $K_0$ is set to $0$. This also occurs if the initial ensemble has no spread ($P_0=0$), which leads to $\\operatorname{Cov}(x_0, x_1^f) = 0$ and thus $K_0 = 0$.\n\n**Step 5: Final Smoothed Mean**\nThe final result is the mean of the smoothed ensemble at $t=0$:\n$$\\bar{x}_0^{s} = \\frac{1}{N} \\sum_{n=1}^N x_0^{s,(n)}$$\n\nThis algorithm will be implemented for each test case, using the specified parameters: $a=0.9$, $q=0.1$, $r=0.4$, $N=10$, $H=1$. Random number generators will be seeded for reproducibility.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a two-time Ensemble Kalman Smoother (EnKS) for a linear scalar system\n    and computes the smoothed ensemble mean at the initial time for several test cases.\n    \"\"\"\n    # Fixed parameters from the problem statement\n    a = 0.9\n    q = 0.1\n    r = 0.4\n    N = 10\n    H = 1.0  # Observation operator\n\n    # Test cases from the problem statement\n    test_cases = [\n        (1.0, 1.0, 0.5),   # Case 1: (m0, P0, y1)\n        (0.0, 0.0, 0.0),   # Case 2\n        (-2.0, 4.0, 1.0),  # Case 3\n        (0.5, 0.5, 0.45),  # Case 4\n        (0.0, 1.0, 5.0),   # Case 5\n    ]\n\n    results = []\n    for i, (m0, P0, y1) in enumerate(test_cases):\n        # Set the random seed for reproducibility\n        seed = 1000 + i\n        rng = np.random.default_rng(seed)\n\n        # Step 1: Ensemble Initialization at t=0\n        if P0 == 0.0:\n            x0_ensemble = np.full(N, m0)\n        else:\n            x0_ensemble = rng.normal(loc=m0, scale=np.sqrt(P0), size=N)\n\n        # Step 2: Forecast to t=1\n        w0_noise = rng.normal(loc=0.0, scale=np.sqrt(q), size=N)\n        x1_forecast_ensemble = a * x0_ensemble + w0_noise\n\n        # Step 3: Analysis at t=1 (Stochastic EnKF)\n        # Calculate sample variance of the forecast ensemble\n        var_x1_forecast = np.var(x1_forecast_ensemble, ddof=1)\n\n        # Calculate Kalman gain K1\n        # Denominator is Var(H*x_f) + r = Var(x_f) + r, since H=1\n        K1 = var_x1_forecast / (var_x1_forecast + r)\n        \n        # Perturb observations\n        obs_perturbations = rng.normal(loc=0.0, scale=np.sqrt(r), size=N)\n        perturbed_obs = y1 + obs_perturbations\n        \n        # Apply analysis update to each ensemble member\n        # Forecast observations are H * x1_forecast_ensemble = x1_forecast_ensemble\n        innovation = perturbed_obs - x1_forecast_ensemble\n        x1_analysis_ensemble = x1_forecast_ensemble + K1 * innovation\n        \n        # Step 4: Smoothing to t=0 (EnKS)\n        # Calculate smoother gain K0\n        # K0 = Cov(x0, x1_f) / Var(x1_f)\n        if np.isclose(var_x1_forecast, 0.0):\n            K0 = 0.0\n        else:\n            # np.cov returns a 2x2 matrix for 2 1D inputs\n            # [[Var(x0), Cov(x0, x1f)], [Cov(x0, x1f), Var(x1f)]]\n            cov_matrix = np.cov(x0_ensemble, x1_forecast_ensemble, ddof=1)\n            cov_x0_x1f = cov_matrix[0, 1]\n            K0 = cov_x0_x1f / var_x1_forecast\n\n        # Apply smoothing update\n        analysis_increment = x1_analysis_ensemble - x1_forecast_ensemble\n        x0_smoothed_ensemble = x0_ensemble + K0 * analysis_increment\n        \n        # Step 5: Compute Smoothed Mean\n        smoothed_mean_x0 = np.mean(x0_smoothed_ensemble)\n        \n        # Round result to 6 decimal places and store\n        results.append(np.round(smoothed_mean_x0, 6))\n\n    # Print the final results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While standard smoothers excel in linear systems, real-world applications are often nonlinear, requiring a more robust approach. This exercise introduces the Iterative Ensemble Smoother (IES), which recasts the data assimilation problem as one of nonlinear optimization. You will implement a single Gauss-Newton iteration for a simple nonlinear observation model, demonstrating how iterative linear updates can effectively navigate the posterior landscape to find a solution that honors both the prior and the observations .",
            "id": "3379443",
            "problem": "Implement a single Gauss-Newton iteration within the framework of an Iterative Ensemble Smoother (IES) for a nonlinear scalar observation model. The fundamental base must start from the Bayesian inverse problem formulation with a Gaussian prior and Gaussian data error model. Specifically, consider a parameter $x \\in \\mathbb{R}$ with prior $x \\sim \\mathcal{N}(0,1)$ and an observation operator $h(x) = x^2$. The observed data is $y \\in \\mathbb{R}$ and the data error covariance is a scalar $R > 0$. Define the negative log-posterior objective function $J(x)$ from the Gaussian prior and Gaussian likelihood. Implement one Gauss-Newton iteration by linearizing $h(x)$ at the current ensemble mean and using the resulting approximate gradient and Hessian to compute a single update that is applied uniformly to all ensemble members. You must draw an ensemble of size $N$ independently from the prior $x \\sim \\mathcal{N}(0,1)$, compute the current ensemble mean $m$, perform one Gauss-Newton step based on the linearization at $m$, update the ensemble by translating each member by the computed step, and report the updated ensemble mean $m_{\\text{updated}}$.\n\nThe computational procedure must be self-contained and reproducible. For reproducibility, use a specified pseudo-random number generator seed for each test case. The program must implement the Iterative Ensemble Smoother (IES) step by:\n- Drawing $N$ independent samples from the prior $\\mathcal{N}(0,1)$ using the given seed.\n- Computing the current ensemble mean $m$.\n- Linearizing $h(x)$ at $m$ and constructing the Gauss-Newton search direction from the Bayesian objective, then updating all ensemble members by adding the same scalar increment to each member.\n- Reporting the updated ensemble mean $m_{\\text{updated}}$ after this single iteration.\n\nNo physical units are involved in this problem. Angles are not used. Percentages are not used. The target outputs are real numbers.\n\nTest Suite:\nProvide results for the following parameter sets $(y, R, N, \\text{seed})$:\n1. $(1.0, 0.1, 20, 0)$\n2. $(1.0, 1.0, 20, 1)$\n3. $(0.0, 0.1, 20, 2)$\n4. $(1.0, 0.001, 20, 3)$\n5. $(4.0, 0.1, 3, 4)$\n6. $(1.0, 0.1, 1, 5)$\n\nFinal Output Format:\nYour program should produce a single line of output containing the updated ensemble means for these six test cases as a comma-separated list enclosed in square brackets. Each number must be rounded to six decimal places. For example: \"[0.123456,0.234567,0.345678,0.456789,0.567890,0.678901]\".",
            "solution": "1.  **Bayesian Inverse Problem Formulation**: The problem is to estimate a parameter $x$ given an observation $y$. In a Bayesian framework, this is done by characterizing the posterior probability distribution $p(x|y)$. By Bayes' theorem, $p(x|y) \\propto p(y|x)p(x)$, where $p(x)$ is the prior distribution and $p(y|x)$ is the likelihood. The problem specifies a Gaussian prior $x \\sim \\mathcal{N}(0, 1)$ and a Gaussian likelihood derived from the observation model $y = h(x) + \\xi = x^2 + \\xi$, where the noise is $\\xi \\sim \\mathcal{N}(0, R)$.\n\n2.  **Negative Log-Posterior Objective Function $J(x)$**: Finding the maximum of the posterior distribution (the MAP estimate) is equivalent to minimizing the negative of its logarithm. The negative log-posterior, often called the cost or objective function $J(x)$, is the sum of the negative log-prior and negative log-likelihood terms (up to an additive constant).\n    -   Prior: $p(x) \\propto \\exp(-\\frac{1}{2}x^2)$, so $-\\log p(x) = \\frac{1}{2}x^2 + \\text{const}$.\n    -   Likelihood: $p(y|x) \\propto \\exp(-\\frac{1}{2R}(y-x^2)^2)$, so $-\\log p(y|x) = \\frac{1}{2R}(y-x^2)^2 + \\text{const}$.\n    \n    Combining these gives the objective function to be minimized:\n    $$J(x) = \\frac{1}{2}x^2 + \\frac{1}{2R}(y-x^2)^2$$\n\n3.  **Gauss-Newton Method Derivation**: The Gauss-Newton method is an iterative optimization algorithm for solving nonlinear least squares problems. It approximates the full Hessian of the objective function.\n    -   **Gradient**: First, we compute the gradient (first derivative) of $J(x)$:\n        $$g(x) = \\nabla J(x) = x + \\frac{1}{2R} \\cdot 2(y-x^2) \\cdot (-2x) = x - \\frac{2x}{R}(y-x^2)$$\n    -   **Gauss-Newton Hessian**: The Gauss-Newton method approximates the Hessian by ignoring terms involving second derivatives of the model residuals. The prior term $\\frac{1}{2}x^2$ is quadratic, and its Hessian is exactly 1. For the data misfit term $\\frac{1}{2R}(y-x^2)^2$, we consider the residual $\\frac{y-x^2}{\\sqrt{R}}$, whose derivative with respect to $x$ is $-\\frac{2x}{\\sqrt{R}}$. The Gauss-Newton approximation of this term's Hessian is the square of this derivative: $(-\\frac{2x}{\\sqrt{R}})^2 = \\frac{4x^2}{R}$. The full Gauss-Newton Hessian is therefore:\n        $$H_{GN}(x) = 1 + \\frac{4x^2}{R}$$\n    -   **Update Step**: A single Gauss-Newton step $\\delta x$ is found by solving the linear system $H_{GN}(x) \\delta x = -g(x)$. For this scalar problem, the update is:\n        $$\\delta x = -[H_{GN}(x)]^{-1} g(x) = -\\frac{x - \\frac{2x}{R}(y-x^2)}{1 + \\frac{4x^2}{R}}$$\n\n4.  **Iterative Ensemble Smoother (IES) Step**: In this IES implementation, the Gauss-Newton update is computed based on the current ensemble mean, $m$.\n    -   The linearization point for the nonlinear model $h(x)$ is the ensemble mean $m$.\n    -   The update step $\\delta m$ is computed using the gradient and Gauss-Newton Hessian evaluated at $m$:\n        $$\\delta m = -[H_{GN}(m)]^{-1} g(m) = -\\frac{m - \\frac{2m}{R}(y-m^2)}{1 + \\frac{4m^2}{R}}$$\n    -   This single scalar increment $\\delta m$ is then added uniformly to every member of the ensemble. The new ensemble is $\\{x^{(n)}_{\\text{new}} = x^{(n)} + \\delta m\\}_{n=1}^N$. Consequently, the new ensemble mean is simply the old mean plus the increment:\n        $$m_{\\text{updated}} = \\frac{1}{N}\\sum(x^{(n)} + \\delta m) = \\left(\\frac{1}{N}\\sum x^{(n)}\\right) + \\delta m = m + \\delta m$$\n\n5.  **Algorithm Summary**: For a given test case:\n    1.  Draw an initial ensemble of size $N$ from the prior $\\mathcal{N}(0,1)$.\n    2.  Compute the mean $m$ of this ensemble.\n    3.  Calculate the Gauss-Newton update step $\\delta m$ by evaluating the gradient and approximate Hessian at $m$.\n    4.  Compute the updated mean as $m_{\\text{updated}} = m + \\delta m$.\n    5.  Report $m_{\\text{updated}}$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a single Gauss-Newton iteration for an Iterative Ensemble Smoother (IES)\n    to solve a nonlinear scalar inverse problem.\n    \"\"\"\n    \n    test_cases = [\n        (1.0, 0.1, 20, 0),\n        (1.0, 1.0, 20, 1),\n        (0.0, 0.1, 20, 2),\n        (1.0, 0.001, 20, 3),\n        (4.0, 0.1, 3, 4),\n        (1.0, 0.1, 1, 5)\n    ]\n\n    results = []\n    \n    for y, R, N, seed in test_cases:\n        # Step 1: Draw an ensemble from the prior distribution.\n        # The prior is x ~ N(0, 1).\n        rng = np.random.default_rng(seed)\n        ensemble_x = rng.standard_normal(N)\n\n        # Step 2: Compute the current ensemble mean.\n        m = np.mean(ensemble_x)\n\n        # Step 3: Compute the Gauss-Newton update step based on the ensemble mean.\n        # The update step delta_m = -[H_GN(m)]^-1 * g(m),\n        # where g is the gradient and H_GN is the Gauss-Newton approximation of the Hessian\n        # of the negative log-posterior objective function J(x).\n        \n        # Gradient of J(x) at m: g(m) = m - 2*m/R * (y - m^2)\n        gradient_at_m = m - (2.0 * m / R) * (y - m**2)\n\n        # Gauss-Newton approximation of the Hessian of J(x) at m: H_GN(m) = 1 + 4*m^2/R\n        hessian_approx_at_m = 1.0 + (4.0 * m**2) / R\n        \n        # Check for division by zero, although it is mathematically impossible here\n        # since R > 0 implies hessian_approx_at_m >= 1.\n        if hessian_approx_at_m == 0:\n            # This case should not be reached. If it is, no update is performed.\n            delta_m = 0.0\n        else:\n            delta_m = -gradient_at_m / hessian_approx_at_m\n\n        # Step 4: Compute the updated ensemble mean.\n        # A uniform update is applied to all ensemble members: x_i_new = x_i + delta_m.\n        # The new mean is therefore m_updated = mean(x_i + delta_m) = mean(x_i) + delta_m = m + delta_m.\n        m_updated = m + delta_m\n        \n        results.append(m_updated)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Iterative methods can be sensitive to strong nonlinearities, and a key to making them robust is managing the update steps carefully. This practice explores tempering, a powerful technique used in methods like the Ensemble Smoother with Multiple Data Assimilations (ES-MDA) to ensure stable convergence. You will first derive the formal equivalence between tempering the likelihood and inflating the observation error covariance, and then determine an optimal schedule that balances the competing effects of linearization error and sampling error .",
            "id": "3379440",
            "problem": "Consider a Bayesian inverse problem with state vector $x \\in \\mathbb{R}^{n}$, prior density $p(x) \\propto \\exp\\!\\big(-\\tfrac{1}{2}(x-m^{b})^{\\top}(C^{b})^{-1}(x-m^{b})\\big)$ with mean $m^{b} \\in \\mathbb{R}^{n}$ and covariance $C^{b} \\in \\mathbb{R}^{n \\times n}$, and an observation model $y = h(x) + \\xi$ with $h:\\mathbb{R}^{n} \\to \\mathbb{R}^{p}$ possibly nonlinear, observation $\\xi \\sim \\mathcal{N}(0,R)$ with $R \\in \\mathbb{R}^{p \\times p}$ positive definite, and realized data $y^{\\mathrm{obs}} \\in \\mathbb{R}^{p}$. In an iterative ensemble smoother, likelihood tempering raises the likelihood to a power $\\beta \\in (0,1]$. Work from the following foundational bases: the Gaussian likelihood $p(y^{\\mathrm{obs}} \\mid x) \\propto \\exp\\!\\big(-\\tfrac{1}{2}(y^{\\mathrm{obs}} - h(x))^{\\top}R^{-1}(y^{\\mathrm{obs}} - h(x))\\big)$, Bayes’ theorem, and the fact that the Kalman analysis for linear $h$ minimizes a quadratic cost composed of the prior and data misfit terms.\n\nTask A. Starting from Bayes’ theorem and the Gaussian form of the likelihood, derive how tempering by a factor $\\beta \\in (0,1]$ is equivalent to replacing the observation error covariance $R$ by $R/\\beta$ in the likelihood. Explain how, in an Ensemble Smoother with Multiple Data Assimilations (ES-MDA), this equivalence implies that using an inflated covariance $\\alpha_{m} R$ at assimilation step $m \\in \\{1,\\dots,M\\}$ implements a tempering exponent $\\beta_{m} = 1/\\alpha_{m}$, and show that the condition $\\sum_{m=1}^{M} \\beta_{m} = 1$ is required to recover the untempered posterior after $M$ steps.\n\nTask B. Assume a sequence of $M$ tempered ES-MDA updates with exponents $\\{\\beta_{m}\\}_{m=1}^{M}$ and corresponding covariances $\\{R/\\beta_{m}\\}_{m=1}^{M}$. Model the competing errors at each step $m$ as follows:\n- A local linearization (modeling) error contribution upper-bounded by $c_{L}\\,\\beta_{m}^{2}$ for some constant $c_{L} > 0$ that does not depend on $m$.\n- A sampling error contribution in the stochastic ensemble update upper-bounded by $c_{S}/(N\\,\\beta_{m})$ for some constant $c_{S} > 0$ independent of $m$, where $N \\in \\mathbb{N}$ is the ensemble size.\n\nUnder these modeling assumptions, determine the schedule $\\{\\beta_{m}\\}_{m=1}^{M}$ that minimizes the aggregate upper bound $\\sum_{m=1}^{M}\\big(c_{L}\\,\\beta_{m}^{2} + c_{S}/(N\\,\\beta_{m})\\big)$ subject to the constraints $\\beta_{m} > 0$ for all $m$ and $\\sum_{m=1}^{M} \\beta_{m} = 1$. Express your schedule as a single closed-form analytic expression for each $\\beta_{m}$ in terms of $M$ only. State the conditions under which your answer is valid and briefly justify why it balances linearization and sampling errors in this idealized model.\n\nYour final answer must be a single closed-form analytic expression for $\\beta_{m}$ in terms of $M$ only. No numerical rounding is required. No physical units are involved. Do not include any additional commentary in your final answer beyond the requested expression.",
            "solution": "### Task A: Tempering, Covariance Inflation, and ES-MDA\n\nWe begin by analyzing the structure of the tempered likelihood and its connection to the Ensemble Smoother with Multiple Data Assimilations (ES-MDA) framework.\n\nThe posterior probability density function $p(x \\mid y^{\\mathrm{obs}})$ is given by Bayes' theorem as\n$$\np(x \\mid y^{\\mathrm{obs}}) \\propto p(y^{\\mathrm{obs}} \\mid x) \\, p(x)\n$$\nwhere $p(y^{\\mathrm{obs}} \\mid x)$ is the likelihood and $p(x)$ is the prior. The problem specifies a Gaussian prior and a Gaussian likelihood. The likelihood is given by\n$$\np(y^{\\mathrm{obs}} \\mid x) \\propto \\exp\\left(-\\frac{1}{2}(y^{\\mathrm{obs}} - h(x))^{\\top}R^{-1}(y^{\\mathrm{obs}} - h(x))\\right)\n$$\nLikelihood tempering involves raising the likelihood function to a power $\\beta \\in (0,1]$. A tempered posterior is thus proportional to $[p(y^{\\mathrm{obs}} \\mid x)]^{\\beta} p(x)$. Let's examine the tempered likelihood term:\n$$\n[p(y^{\\mathrm{obs}} \\mid x)]^{\\beta} \\propto \\left[\\exp\\left(-\\frac{1}{2}(y^{\\mathrm{obs}} - h(x))^{\\top}R^{-1}(y^{\\mathrm{obs}} - h(x))\\right)\\right]^{\\beta}\n$$\nUsing the property $(\\exp(a))^b = \\exp(ab)$, this becomes\n$$\n[p(y^{\\mathrm{obs}} \\mid x)]^{\\beta} \\propto \\exp\\left(-\\frac{\\beta}{2}(y^{\\mathrm{obs}} - h(x))^{\\top}R^{-1}(y^{\\mathrm{obs}} - h(x))\\right)\n$$\nTo show this is equivalent to replacing the observation error covariance $R$ by a new covariance $R_{\\text{new}}$, we need to write the exponent in the form $-\\frac{1}{2}(\\dots)^{\\top}R_{\\text{new}}^{-1}(\\dots)$. We can rewrite the scaled inverse covariance as\n$$\n\\beta R^{-1} = (R/\\beta)^{-1}\n$$\nwhere we have used the matrix identity $(cA)^{-1} = c^{-1}A^{-1}$ for a scalar $c$. Substituting this back into the expression for the tempered likelihood gives\n$$\n[p(y^{\\mathrm{obs}} \\mid x)]^{\\beta} \\propto \\exp\\left(-\\frac{1}{2}(y^{\\mathrm{obs}} - h(x))^{\\top}(R/\\beta)^{-1}(y^{\\mathrm{obs}} - h(x))\\right)\n$$\nThis expression has the exact functional form of a Gaussian likelihood with the observation error covariance replaced by $R/\\beta$. This completes the first part of Task A.\n\nFor the second part, ES-MDA performs a sequence of $M$ Kalman-type updates. At each step $m \\in \\{1, \\dots, M\\}$, the update is performed using an inflated observation error covariance matrix $\\alpha_m R$, where $\\alpha_m \\geq 1$. Based on the equivalence just derived, using a covariance of $\\alpha_m R$ is equivalent to using a tempering exponent $\\beta_m$ such that\n$$\n\\alpha_m R = \\frac{R}{\\beta_m}\n$$\nSince $R$ is invertible, we can multiply by $R^{-1}$ on the right to get $\\alpha_m I = \\beta_m^{-1} I$, which implies $\\beta_m = 1/\\alpha_m$.\n\nFinally, we show why the condition $\\sum_{m=1}^{M} \\beta_{m} = 1$ is required. The ES-MDA procedure sequentially updates the state by assimilating the same data $y^{\\mathrm{obs}}$ multiple times with modified likelihoods. Let the prior at step $m=1$ be $p_0(x) = p(x)$. The posterior after the first step, $p_1(x)$, is obtained using the tempering exponent $\\beta_1$:\n$$\np_1(x) \\propto [p(y^{\\mathrm{obs}} \\mid x)]^{\\beta_1} p_0(x) = [p(y^{\\mathrm{obs}} \\mid x)]^{\\beta_1} p(x)\n$$\nThis posterior $p_1(x)$ then serves as the prior for the second step. The posterior after the second step, $p_2(x)$, is\n$$\np_2(x) \\propto [p(y^{\\mathrm{obs}} \\mid x)]^{\\beta_2} p_1(x) \\propto [p(y^{\\mathrm{obs}} \\mid x)]^{\\beta_2} \\left( [p(y^{\\mathrm{obs}} \\mid x)]^{\\beta_1} p(x) \\right) = [p(y^{\\mathrm{obs}} \\mid x)]^{\\beta_1+\\beta_2} p(x)\n$$\nBy induction, after $M$ such steps, the final posterior distribution $p_M(x)$ is given by\n$$\np_M(x) \\propto [p(y^{\\mathrm{obs}} \\mid x)]^{\\sum_{m=1}^{M} \\beta_m} p(x)\n$$\nTo recover the true, untempered Bayesian posterior $p(x \\mid y^{\\mathrm{obs}})$, the total exponent on the likelihood must be equal to $1$. Therefore, the sequence of tempering exponents must satisfy the condition\n$$\n\\sum_{m=1}^{M} \\beta_{m} = 1\n$$\n\n### Task B: Optimal Tempering Schedule\n\nWe are tasked with finding the sequence of tempering exponents $\\{\\beta_m\\}_{m=1}^M$ that minimizes the aggregate upper bound on the error, subject to constraints. The objective function to minimize is\n$$\nJ(\\beta_1, \\dots, \\beta_M) = \\sum_{m=1}^{M}\\left(c_{L}\\,\\beta_{m}^{2} + \\frac{c_{S}}{N\\,\\beta_{m}}\\right)\n$$\nThe minimization is subject to the constraints $\\beta_m > 0$ for all $m \\in \\{1, \\dots, M\\}$ and the consistency condition derived in Task A:\n$$\n\\sum_{m=1}^{M} \\beta_{m} = 1\n$$\nThis is a constrained optimization problem. We can solve it using the method of Lagrange multipliers. The Lagrangian $\\mathcal{L}$ is defined as:\n$$\n\\mathcal{L}(\\beta_1, \\dots, \\beta_M, \\lambda) = \\sum_{m=1}^{M}\\left(c_{L}\\,\\beta_{m}^{2} + \\frac{c_{S}}{N\\,\\beta_{m}}\\right) - \\lambda \\left(\\sum_{m=1}^{M} \\beta_{m} - 1\\right)\n$$\nTo find the minimum, we set the partial derivatives of $\\mathcal{L}$ with respect to each $\\beta_k$ (for $k = 1, \\dots, M$) to zero:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\beta_k} = \\frac{\\partial}{\\partial \\beta_k} \\left(c_{L}\\,\\beta_{k}^{2} + \\frac{c_{S}}{N\\,\\beta_{k}}\\right) - \\lambda = 0\n$$\n$$\n2c_{L}\\,\\beta_{k} - \\frac{c_{S}}{N\\,\\beta_{k}^{2}} - \\lambda = 0\n$$\nThis equation must hold for every $k \\in \\{1, \\dots, M\\}$. The form of the equation is identical for all $\\beta_k$. This implies that at the optimal point, all $\\beta_k$ must be equal. Let us denote this common value by $\\beta$.\n$$\n\\beta_1 = \\beta_2 = \\dots = \\beta_M = \\beta\n$$\nA more rigorous justification comes from the fact that the objective function is a sum of identical, strictly convex functions of each $\\beta_m$ (since for $\\beta_m > 0$, the second derivative $2c_L + 2c_S/(N\\beta_m^3)$ is strictly positive given $c_L>0, c_S>0, N>0$), and the constraint is symmetric with respect to permutations of the $\\beta_m$. For such symmetric problems, the unique minimum must occur at the symmetric point where all variables are equal.\n\nSubstituting $\\beta_m = \\beta$ into the constraint equation:\n$$\n\\sum_{m=1}^{M} \\beta = M\\beta = 1\n$$\nSolving for $\\beta$, we find the optimal value for each exponent:\n$$\n\\beta = \\frac{1}{M}\n$$\nThus, the optimal schedule is $\\beta_m = 1/M$ for all $m = 1, \\dots, M$. This solution is independent of the constants $c_L$, $c_S$, and $N$, as required by the problem statement.\n\nThis answer is valid under the conditions given in the problem: $c_L > 0$, $c_S > 0$, $N \\in \\mathbb{N}$ is a positive integer, and $M \\in \\mathbb{N}$ is also a positive integer. The constraint $\\beta_m > 0$ is satisfied since $M \\geq 1$.\n\nThis constant schedule $\\beta_m = 1/M$ balances the two competing error sources in the following sense. The optimality condition requires that the marginal change in the total error with respect to any $\\beta_k$, which is $2c_{L}\\,\\beta_{k} - c_{S}/(N\\,\\beta_{k}^{2})$, must be the same for all $k$. By setting all $\\beta_k$ to the same value $1/M$, this condition is satisfied. This means that at the optimum, it is not possible to reduce the total error by slightly increasing one $\\beta_k$ while decreasing another $\\beta_j$ to maintain the sum constraint. The solution equalizes the marginal cost (or benefit) of allocating the tempering \"budget\" to any particular step, thereby achieving an optimal balance for the aggregate error bound.",
            "answer": "$$\\boxed{\\frac{1}{M}}$$"
        }
    ]
}