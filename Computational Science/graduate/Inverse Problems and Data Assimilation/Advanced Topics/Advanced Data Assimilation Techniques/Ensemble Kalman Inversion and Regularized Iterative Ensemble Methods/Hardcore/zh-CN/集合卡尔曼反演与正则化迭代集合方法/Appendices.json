{
    "hands_on_practices": [
        {
            "introduction": "本章的动手实践旨在将理论知识应用于实际问题，加深对集合卡尔曼反演 (EKI) 及其正则化方法的理解。我们从一个基础但至关重要的问题开始：EKI 迭代的稳定性。通过将 EKI 更新步骤与预处理梯度下降法联系起来，您可以亲手推导出保证算法收敛的步长条件，并理解问题的病态性如何影响稳定性的。",
            "id": "3379127",
            "problem": "考虑一个线性逆问题，其正演算子为 $A \\in \\mathbb{R}^{2 \\times 2}$，未知参数为 $u \\in \\mathbb{R}^{2}$，观测数据为 $y \\in \\mathbb{R}^{2}$，它们满足 $y = A u + \\eta$，其中 $\\eta$ 是均值为零、协方差为 $\\Gamma \\in \\mathbb{R}^{2 \\times 2}$ 的高斯观测噪声。数据失配目标是加权最小二乘泛函\n$$\n\\Phi(u) = \\frac{1}{2} \\left\\| \\Gamma^{-1/2} (A u - y) \\right\\|_{2}^{2}。\n$$\n在集合卡尔曼反演 (Ensemble Kalman Inversion, EKI) 中，于平均场极限下，对与 $\\Phi$ 相关联的预处理梯度流应用单个显式欧拉步，集合均值更新的形式为\n$$\nu_{1} = u_{0} - \\Delta t \\, C_{0}^{uu} A^{\\top} \\Gamma^{-1} \\big(A u_{0} - y\\big)，\n$$\n其中 $C_{0}^{uu} \\in \\mathbb{R}^{2 \\times 2}$ 是初始集合的经验协方差，$\\Delta t > 0$ 是所选的步长。由 $C_{0}^{uu}$ 实现的预处理体现了正则化迭代集合方法中的正则化。\n\n通过取值\n$$\nA = \\begin{pmatrix} 100  0 \\\\ 0  0.1 \\end{pmatrix}, \\qquad \\Gamma = I_{2}, \\qquad C_{0}^{uu} = I_{2}.\n$$\n构建一个具有病态正演算子和单位噪声协方差的具体 $2 \\times 2$ 例子。\n定义白化失配 $z = \\Gamma^{-1/2} (A u - y) \\in \\mathbb{R}^{2}$，并令 $S = \\Gamma^{-1/2} A C_{0}^{uu} A^{\\top} \\Gamma^{-1/2}$。从第一性原理（$\\Phi$ 的梯度和预处理梯度流）出发，推导单步失配更新以及确保白化失配范数 $\\|z\\|_{2}$ 单调递减的 $\\Delta t$ 条件。对于所构建的例子，计算精确的最大允许步长 $\\Delta t_{\\ast}$，使得对于任意初始白化失配 $z_{0} \\in \\mathbb{R}^{2}$，单步更新后的失配 $z_{1}$ 满足 $\\|z_{1}\\|_{2}  \\|z_{0}\\|_{2}$。\n\n你的最终答案必须是 $\\Delta t_{\\ast}$ 的单个精确值，以最简分数或等价的无单位闭式表达式给出。无需四舍五入。",
            "solution": "问题要求推导集合卡尔曼反演 (EKI) 过程的单步失配更新，失配范数单调递减对步长 $\\Delta t$ 的条件，以及针对一个具体例子计算最大允许步长 $\\Delta t_{\\ast}$。\n\n首先，我们推导白化失配 $z$ 的更新规则。数据失配目标函数由下式给出\n$$\n\\Phi(u) = \\frac{1}{2} \\left\\| \\Gamma^{-1/2} (A u - y) \\right\\|_{2}^{2}。\n$$\n令白化失配为 $z(u) = \\Gamma^{-1/2} (A u - y)$。则目标函数为 $\\Phi(u) = \\frac{1}{2} z(u)^{\\top} z(u)$。\n使用链式法则求 $\\Phi(u)$ 关于 $u$ 的梯度。$z(u)$ 关于 $u$ 的雅可比矩阵是 $\\nabla_u z(u) = \\Gamma^{-1/2} A$。\n因此，$\\Phi(u)$ 的梯度为\n$$\n\\nabla_u \\Phi(u) = (\\nabla_u z(u))^{\\top} z(u) = (\\Gamma^{-1/2} A)^{\\top} \\Gamma^{-1/2} (A u - y)。\n$$\n由于 $\\Gamma$ 是一个协方差矩阵，它是对称的，所以 $\\Gamma^{-1/2}$ 也是对称的。因此，$(\\Gamma^{-1/2})^{\\top} = \\Gamma^{-1/2}$。\n梯度变为\n$$\n\\nabla_u \\Phi(u) = A^{\\top} \\Gamma^{-1/2} \\Gamma^{-1/2} (A u - y) = A^{\\top} \\Gamma^{-1} (A u - y)。\n$$\n集合均值的单步 EKI 更新由下式给出\n$$\nu_{1} = u_{0} - \\Delta t \\, C_{0}^{uu} \\nabla_u \\Phi(u_0) = u_{0} - \\Delta t \\, C_{0}^{uu} A^{\\top} \\Gamma^{-1} (A u_{0} - y)。\n$$\n这证实了给定的更新规则对应于对 $\\Phi(u)$ 的一个预处理梯度下降步。\n\n现在，我们推导白化失配的更新，$z_{1} = z(u_1)$。\n$$\nz_{1} = \\Gamma^{-1/2} (A u_{1} - y)。\n$$\n代入 $u_1$ 的表达式：\n$$\nz_{1} = \\Gamma^{-1/2} \\left( A \\left( u_{0} - \\Delta t \\, C_{0}^{uu} A^{\\top} \\Gamma^{-1} (A u_{0} - y) \\right) - y \\right)。\n$$\n分配各项：\n$$\nz_{1} = \\Gamma^{-1/2} (A u_{0} - y) - \\Delta t \\, \\Gamma^{-1/2} A C_{0}^{uu} A^{\\top} \\Gamma^{-1} (A u_{0} - y)。\n$$\n我们识别出初始失配 $z_{0} = \\Gamma^{-1/2} (A u_{0} - y)$。我们也可以写出 $\\Gamma^{-1} (A u_{0} - y) = \\Gamma^{-1/2} z_0$。将这些代入 $z_1$ 的方程中：\n$$\nz_{1} = z_{0} - \\Delta t \\, \\Gamma^{-1/2} A C_{0}^{uu} A^{\\top} \\Gamma^{-1/2} z_{0}。\n$$\n使用定义 $S = \\Gamma^{-1/2} A C_{0}^{uu} A^{\\top} \\Gamma^{-1/2}$，单步失配更新为\n$$\nz_{1} = (I - \\Delta t \\, S) z_{0}。\n$$\n\n接下来，我们找到 $\\Delta t  0$ 需满足的条件，以确保白化失配范数单调递减，即对于任何非零初始失配 $z_{0} \\in \\mathbb{R}^{2}$ 都有 $\\|z_{1}\\|_{2}  \\|z_{0}\\|_{2}$。这等价于 $\\|z_{1}\\|_{2}^{2}  \\|z_{0}\\|_{2}^{2}$。\n$$\n\\|(I - \\Delta t \\, S) z_{0}\\|_{2}^{2}  \\|z_{0}\\|_{2}^{2}。\n$$\n展开左侧：\n$$\nz_{0}^{\\top} (I - \\Delta t \\, S)^{\\top} (I - \\Delta t \\, S) z_{0}  z_{0}^{\\top} z_{0}。\n$$\n矩阵 $S$ 是对称的，因为 $C_0^{uu}$ 和 $\\Gamma$ 是对称的：\n$$\nS^{\\top} = (\\Gamma^{-1/2} A C_{0}^{uu} A^{\\top} \\Gamma^{-1/2})^{\\top} = \\Gamma^{-1/2} A (C_{0}^{uu})^{\\top} A^{\\top} \\Gamma^{-1/2} = S。\n$$\n因此，更新算子 $M = I - \\Delta t \\, S$ 也是对称的。条件变为\n$$\nz_{0}^{\\top} (I - \\Delta t \\, S)^{2} z_{0}  z_{0}^{\\top} z_{0}。\n$$\n这个不等式必须对所有 $z_{0} \\neq 0$ 成立。这等价于要求算子 $M = I - \\Delta t \\, S$ 的算子范数严格小于 1，即 $\\|M\\|_{2}  1$。对于一个对称矩阵，其算子范数（或谱范数）是其特征值的最大绝对值。令 $\\lambda_i(S)$ 为 $S$ 的特征值。$M$ 的特征值为 $\\mu_i = 1 - \\Delta t \\, \\lambda_i(S)$。\n因此，我们需要对所有特征值 $\\lambda_i(S)$ 都有 $|1 - \\Delta t \\, \\lambda_i(S)|  1$。这等价于：\n$$\n-1  1 - \\Delta t \\, \\lambda_i(S)  1。\n$$\n矩阵 $S$ 是对称半正定的 (SPSD)，因为它可以写成 $S = K K^\\top$ 的形式，其中 $K = \\Gamma^{-1/2} A (C_{0}^{uu})^{1/2}$。因此，其特征值是非负的，$\\lambda_i(S) \\geq 0$。\n不等式的右侧，$1 - \\Delta t \\, \\lambda_i(S)  1$，意味着 $-\\Delta t \\, \\lambda_i(S)  0$。由于 $\\Delta t > 0$，这要求 $\\lambda_i(S) > 0$。如果一个特征值为零，则 $z_0$ 对应特征向量分量的范数将不会减小。为了对*任何*非零 $z_0$ 都实现严格减小，我们必须有所有的 $\\lambda_i(S) > 0$，这意味着 $S$ 是正定的。\n不等式的左侧，$-1  1 - \\Delta t \\, \\lambda_i(S)$，意味着 $\\Delta t \\, \\lambda_i(S)  2$，或 $\\Delta t  \\frac{2}{\\lambda_i(S)}$。\n这个条件必须对所有特征值都成立。为确保这一点，$\\Delta t$ 必须小于这些上界的最小值：\n$$\n\\Delta t  \\min_i \\left( \\frac{2}{\\lambda_i(S)} \\right) = \\frac{2}{\\max_i(\\lambda_i(S))} = \\frac{2}{\\lambda_{\\max}(S)}。\n$$\n允许步长的集合是区间 $(0, \\frac{2}{\\lambda_{\\max}(S)})$。最大允许步长 $\\Delta t_{\\ast}$ 是这个集合的上确界。\n$$\n\\Delta t_{\\ast} = \\frac{2}{\\lambda_{\\max}(S)}。\n$$\n\n现在我们将此应用于具体例子：\n$$\nA = \\begin{pmatrix} 100  0 \\\\ 0  0.1 \\end{pmatrix}, \\qquad \\Gamma = I_{2} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}, \\qquad C_{0}^{uu} = I_{2} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}。\n$$\n我们计算矩阵 $S$：\n$$\nS = \\Gamma^{-1/2} A C_{0}^{uu} A^{\\top} \\Gamma^{-1/2} = I_{2}^{-1/2} A I_{2} A^{\\top} I_{2}^{-1/2} = I_{2} A I_{2} A^{\\top} I_{2} = A A^{\\top}。\n$$\n由于 $A$ 是一个对角矩阵，它是对称的（$A=A^{\\top}$），所以 $S=A^2$。\n$$\nS = \\begin{pmatrix} 100  0 \\\\ 0  0.1 \\end{pmatrix} \\begin{pmatrix} 100  0 \\\\ 0  0.1 \\end{pmatrix} = \\begin{pmatrix} 100^2  0 \\\\ 0  (0.1)^2 \\end{pmatrix} = \\begin{pmatrix} 10000  0 \\\\ 0  0.01 \\end{pmatrix}。\n$$\n矩阵 $S$ 是对角的，所以其特征值是其对角元素：$\\lambda_1 = 10000$ 和 $\\lambda_2 = 0.01$。两者都为正，所以 $S$ 是正定的。\n$S$ 的最大特征值是 $\\lambda_{\\max}(S) = 10000$。\n最后，我们计算最大允许步长 $\\Delta t_{\\ast}$：\n$$\n\\Delta t_{\\ast} = \\frac{2}{\\lambda_{\\max}(S)} = \\frac{2}{10000} = \\frac{1}{5000}。\n$$",
            "answer": "$$\n\\boxed{\\frac{1}{5000}}\n$$"
        },
        {
            "introduction": "在理解了 EKI 的基本迭代机理后，我们转向反演问题中的核心挑战：正则化。这个实践将引导您探索并比较两种经典的正则化策略：Tikhonov 正则化和迭代正则化（即提前终止）。您将通过代码实现这两种方法，并应用差异原则来客观地确定正则化程度，从而深刻体会它们在平衡数据拟合与解的稳定性方面的作用和联系。",
            "id": "3379130",
            "problem": "要求您研究使用由偏差原理选择的参数序列的Tikhonov正则化集成卡尔曼反演 (TEKI)，并确定在何种条件下，提前停止能有效替代Tikhonov参数的作用。请在线性反问题和高斯统计的框架内进行研究，以确保所有推导和算法都能基于第一性原理。\n\n考虑一个未知参数向量 $u \\in \\mathbb{R}^n$，一个线性正演算子 $G(u) = A u$ (其中 $A \\in \\mathbb{R}^{m \\times n}$)，以及由 $y = A u_{\\mathrm{true}} + \\eta$ 生成的带噪声观测 $y \\in \\mathbb{R}^m$，其中 $\\eta \\sim \\mathcal{N}(0,R)$，$R \\in \\mathbb{R}^{m \\times m}$ 为对称正定矩阵。采用均值为 $u_{\\mathrm{ref}} \\in \\mathbb{R}^n$、协方差为 $\\Gamma_u \\in \\mathbb{R}^{n \\times n}$ 的高斯参考先验。您将使用一个大小为 $J$ 的集成 $\\{ u_k^{(j)} \\}_{j=1}^J$ 来近似解，并根据样本协方差确定性地计算数据驱动的更新。\n\n研究必须基于反问题和数据同化领域的以下基本原理：\n\n- 高斯噪声模型：加性观测噪声满足 $\\eta \\sim \\mathcal{N}(0,R)$，这意味着负对数似然项为 $\\frac{1}{2}\\| R^{-1/2}(A u - y) \\|_2^2$。\n- 通过集成协方差进行线性回归：确定性集成卡尔曼更新源于使用样本协方差，将状态对预测观测进行最小二乘回归，除核心高斯恒等式外，不使用任何简化公式。\n- 通过观测增广实现Tikhonov正则化：正则化目标函数 $\\frac{1}{2}\\| R^{-1/2}(A u - y) \\|_2^2 + \\frac{1}{2}\\alpha \\| \\Gamma_u^{-1/2}(u - u_{\\mathrm{ref}}) \\|_2^2$ 可以通过增广观测模型来表示，其中增广观测为 $z = \\begin{bmatrix} y \\\\ 0 \\end{bmatrix}$，增广算子为 $H(u) = \\begin{bmatrix} A u \\\\ u - u_{\\mathrm{ref}} \\end{bmatrix}$，块对角噪声协方差为 $\\Sigma = \\operatorname{blockdiag}(R, \\alpha^{-1}\\Gamma_u)$。\n\n您的任务：\n\n- 使用样本协方差为线性算子 $A$ 实现确定性集成卡尔曼反演以执行回归更新，分两种模式：\n  - TEKI模式：如上所述，通过增广观测实施Tikhonov正则化，每轮迭代的参数 $\\alpha_k$ 由偏差原理选择。\n  - 提前停止EKI模式：设置 $\\alpha_k = 0$（无Tikhonov正则化），一旦满足偏差原理即停止迭代。\n- 偏差原理：在第 $k$ 次迭代，定义失配 $r_k := \\| y - A \\bar{u}_k \\|_2$，其中 $\\bar{u}_k$ 是集成均值。设目标偏差为 $d := \\tau \\sqrt{\\mathrm{trace}(R)}$，其中标量 $\\tau  1$。在TEKI模式下，选择 $\\alpha_k \\geq 0$（例如，通过二分法），使得TEKI更新后的下一个均值失配 $r_{k+1}$ 尽可能接近 $d$。如果 $r_k \\leq d$，则停止（这是提前停止）。在提前停止EKI模式下，以 $\\alpha_k = 0$ 进行迭代，并在首次满足 $r_k \\leq d$ 时停止。\n- 比较指标：对于每个测试案例，分别比较通过偏差原理选择参数的TEKI运行和提前停止EKI运行得到的最终集成均值 $\\bar{u}_{\\mathrm{TEKI}}$ 和 $\\bar{u}_{\\mathrm{ES}}$。如果以下两个条件都成立，则宣告提前停止有效替代了 $\\alpha_k$：\n  - 相对差异 $\\frac{\\| \\bar{u}_{\\mathrm{TEKI}} - \\bar{u}_{\\mathrm{ES}} \\|_2}{\\| \\bar{u}_{\\mathrm{ES}} \\|_2 + 10^{-12}}$ 小于一个容差 $\\epsilon$。\n  - 两个最终失配都接近 $d$，即每个失配都满足 $\\left| \\frac{r_{\\mathrm{final}} - d}{d} \\right| \\leq \\delta$。\n  使用数值 $\\epsilon = 0.2$ 和 $\\delta = 0.1$。\n\n实现要求：\n\n- 使用从样本协方差计算的确定性集成卡尔曼更新。\n- 对于TEKI，如上所述通过增广观测实现Tikhonov正则化，通过对标量参数进行二分法来选择 $\\alpha_k$，以尽可能接近偏差目标。如果当前失配已经低于目标，则立即停止（提前停止）。\n- 对于提前停止EKI，以 $\\alpha_k=0$ 进行迭代，直到满足偏差原理，然后停止。\n- 使用最大迭代次数 $K_{\\max}$ 来防止无限循环。\n- 通过测试套件中指定的固定种子，使所有随机抽样可复现。\n\n测试套件：\n\n用以下参数集实现三个测试案例。在每个案例中，抽取真实状态 $u_{\\mathrm{true}} \\sim \\mathcal{N}(0, I_n)$，抽取加性噪声 $\\eta \\sim \\mathcal{N}(0, R)$，设置 $u_{\\mathrm{ref}} = 0$，$\\Gamma_u = I_n$，并通过从 $\\mathcal{N}(0, I_n)$ 中独立抽取 $J$ 个成员来初始化集成。通过 $A = U_r \\operatorname{diag}(s) V_r^\\top$ 构建 $A$，其中 $U_r \\in \\mathbb{R}^{m \\times r}$ 和 $V_r \\in \\mathbb{R}^{n \\times r}$ 是通过对具有指定种子的标准高斯矩阵进行QR分解得到的正交矩阵的前 $r = \\min\\{m,n\\}$ 列，而 $s \\in \\mathbb{R}^r$ 指定了奇异值。\n\n- 案例一（良态，集成充足）：\n  - 维度: $n = 20$, $m = 15$, $J = 80$。\n  - 奇异值: $s_i = 1$ for $i = 1, \\dots, r$。\n  - 观测噪声协方差: $R = \\sigma^2 I_m$ with $\\sigma = 0.05$。\n  - 偏差参数: $\\tau = 1.05$。\n  - 最大迭代次数: $K_{\\max} = 20$。\n  - 种子: 使用种子 $1001$ 构建 $U_r$ 和 $V_r$，种子 $2002$ 用于 $u_{\\mathrm{true}}$，种子 $3003$ 用于 $\\eta$；使用种子 $4004$ 用于初始集成。\n- 案例二（病态算子，集成充足）：\n  - 维度: $n = 40$, $m = 25$, $J = 120$。\n  - 奇异值: $s_i = 10^{- \\frac{i-1}{r-1}}$ for $i = 1, \\dots, r$。\n  - 观测噪声协方差: $R = \\sigma^2 I_m$ with $\\sigma = 0.05$。\n  - 偏差参数: $\\tau = 1.05$。\n  - 最大迭代次数: $K_{\\max} = 25$。\n  - 种子: 使用种子 $5005$ 构建 $U_r$ 和 $V_r$，种子 $6006$ 用于 $u_{\\mathrm{true}}$，种子 $7007$ 用于 $\\eta$；使用种子 $8008$ 用于初始集成。\n- 案例三（强病态算子，小集成）：\n  - 维度: $n = 60$, $m = 40$, $J = 5$。\n  - 奇异值: $s_i = 10^{- 2 \\frac{i-1}{r-1}}$ for $i = 1, \\dots, r$。\n  - 观测噪声协方差: $R = \\sigma^2 I_m$ with $\\sigma = 0.05$。\n  - 偏差参数: $\\tau = 1.05$。\n  - 最大迭代次数: $K_{\\max} = 30$。\n  - 种子: 使用种子 $9009$ 构建 $U_r$ 和 $V_r$，种子 $10010$ 用于 $u_{\\mathrm{true}}$，种子 $11011$ 用于 $\\eta$；使用种子 $12012$ 用于初始集成。\n\n输出规格：\n\n- 对于每个测试案例，根据上述两个条件计算提前停止是否有效替代了由偏差原理选择的 $\\alpha_k$，并返回一个布尔值。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，例如 $[b_1,b_2,b_3]$，其中每个 $b_i$ 是 $\\mathrm{True}$ 或 $\\mathrm{False}$。\n\n此问题不涉及角度或物理单位；所有量均为无量纲。所有计算必须遵守指定的种子和参数以确保确定性。确保数值线性代数是鲁棒的（例如，如果需要，添加微小的对角抖动），并且所有矩阵求逆都使用数值稳定的求解器。",
            "solution": "用户提供了一个在反问题和数据同化领域中定义明确的计算问题。任务是比较集成卡尔曼反演 (EKI) 算法的两种正则化策略：使用动态选择参数的Tikhonov正则化EKI (TEKI)，以及带提前停止准则的标准EKI。比较是基于一个特定的数值指标，该指标涉及最终解估计及其数据失配。\n\n该问题在科学上和数学上都是合理的，提供了所有必要的定义、参数和测试案例。这是计算科学中一个有效且有实质内容的练习。我将进行详细的推导和实现。\n\n### 1. 理论框架\n\n该问题是一个形式为\n$$\ny = A u_{\\mathrm{true}} + \\eta\n$$\n的线性反问题，其中 $y \\in \\mathbb{R}^m$ 是观测值，$u_{\\mathrm{true}} \\in \\mathbb{R}^n$ 是未知的真实参数向量，$A \\in \\mathbb{R}^{m \\times n}$ 是线性正演算子，$\\eta \\sim \\mathcal{N}(0,R)$ 是高斯噪声，其协方差 $R \\in \\mathbb{R}^{m \\times m}$ 是对称正定的。\n\n我们采用基于集成的方法来寻找 $u$ 的估计。设 $\\{u_k^{(j)}\\}_{j=1}^J$ 为第 $k$ 次迭代时由 $J$ 个参数向量组成的集成。集成均值为 $\\bar{u}_k = \\frac{1}{J} \\sum_{j=1}^J u_k^{(j)}$，中心化参数的集成为 $u_k^{\\prime(j)} = u_k^{(j)} - \\bar{u}_k$。\n\n该方法的核心是确定性集成卡尔曼更新，它源于贝叶斯背景下的线性回归原理。\n\n### 2. 标准EKI更新（用于提前停止）\n\n对于标准EKI，正演模型是 $G(u) = Au$。从迭代 $k$到 $k+1$ 对每个集成成员 $j$ 的更新步骤是：\n$$\nu_{k+1}^{(j)} = u_k^{(j)} + C_{up,k} (C_{pp,k} + R)^{-1} (y - p_k^{(j)})\n$$\n其中：\n-   $p_k^{(j)} = A u_k^{(j)}$ 是每个集成成员的预测观测值。\n-   $\\bar{p}_k = A \\bar{u}_k$ 是预测观测值的均值。\n-   $C_{up,k}$ 是参数 $u$ 和预测数据 $p$ 之间的样本交叉协方差：\n    $$\n    C_{up,k} = \\frac{1}{J-1} \\sum_{j=1}^J (u_k^{(j)} - \\bar{u}_k)(p_k^{(j)} - \\bar{p}_k)^T = C_{uu,k} A^T\n    $$\n-   $C_{pp,k}$ 是预测数据 $p$ 的样本自协方差：\n    $$\n    C_{pp,k} = \\frac{1}{J-1} \\sum_{j=1}^J (p_k^{(j)} - \\bar{p}_k)(p_k^{(j)} - \\bar{p}_k)^T = A C_{uu,k} A^T\n    $$\n-   $C_{uu,k} = \\frac{1}{J-1} \\sum_{j=1}^J (u_k^{(j)} - \\bar{u}_k)(u_k^{(j)} - \\bar{u}_k)^T$ 是参数的样本协方差。\n\n提前停止EKI (ES-EKI) 模式以 $\\alpha_k=0$ 迭代应用此更新，并在满足偏差原理时终止。\n\n### 3. Tikhonov正则化EKI (TEKI) 更新\n\nTikhonov正则化在数据失配上增加了一个惩罚项，由参数 $\\alpha_k  0$ 控制。目标函数为：\n$$\n\\frac{1}{2}\\| R^{-1/2}(A u - y) \\|_2^2 + \\frac{1}{2}\\alpha_k \\| \\Gamma_u^{-1/2}(u - u_{\\mathrm{ref}}) \\|_2^2\n$$\n按照规定，这是通过增广观测系统来实现的。\n-   增广算子: $H(u) = \\begin{bmatrix} A u \\\\ u - u_{\\mathrm{ref}} \\end{bmatrix}$\n-   增广数据: $z = \\begin{bmatrix} y \\\\ 0 \\end{bmatrix}$\n-   增广噪声协方差: $\\Sigma_k = \\operatorname{blockdiag}(R, \\alpha_k^{-1}\\Gamma_u)$\n\nTEKI更新使用与标准EKI更新相同的结构，但使用这些增广量：\n$$\nu_{k+1}^{(j)} = u_k^{(j)} + C_{uH,k} (C_{HH,k} + \\Sigma_k)^{-1} (z - H(u_k^{(j)}))\n$$\n其中 $C_{uH,k}$ 和 $C_{HH,k}$ 是增广系统的样本协方差。令 $u_k^{\\prime(j)} = u_k^{(j)} - \\bar{u}_k$。中心化的增广预测为 $H(u_k^{(j)}) - H(\\bar{u}_k) = \\begin{bmatrix} A u_k^{\\prime(j)} \\\\ u_k^{\\prime(j)} \\end{bmatrix}$。协方差变为：\n-   $C_{uH,k} = \\begin{bmatrix} C_{uu,k} A^T  C_{uu,k} \\end{bmatrix}$\n-   $C_{HH,k} = \\begin{bmatrix} A C_{uu,k} A^T  A C_{uu,k} \\\\ C_{uu,k} A^T  C_{uu,k} \\end{bmatrix}$\n\n待求逆的矩阵 $C_{HH,k} + \\Sigma_k$ 的大小为 $(m+n) \\times (m+n)$，由于其对角块上的满秩矩阵 $R$ 和 $\\alpha_k^{-1}\\Gamma_u$ 而变得可逆。\n\n### 4. 偏差原理与参数选择\n\n偏差原理为正则化提供了一个规则。\n-   第 $k$ 次迭代时的数据失配为 $r_k = \\| y - A \\bar{u}_k \\|_2$。\n-   目标偏差为 $d = \\tau \\sqrt{\\mathrm{trace}(R)}$，其中 $\\tau  1$ 是一个给定因子。由于 $R = \\sigma^2 I_m$，这可简化为 $d = \\tau \\sigma \\sqrt{m}$。\n-   如果当前失配 $r_k \\leq d$，两种方法都停止迭代。\n\n对于TEKI，如果 $r_k  d$，我们必须为下一步选择正则化参数 $\\alpha_k \\geq 0$。\n设 $\\bar{u}_{k+1}(\\alpha)$ 是使用参数 $\\alpha$ 进行一步TEKI更新后的集成均值。\n设 $r_{k+1}(\\alpha) = \\| y - A \\bar{u}_{k+1}(\\alpha) \\|_2$ 是由此产生的失配。\n选择参数 $\\alpha_k$ 使得 $r_{k+1}(\\alpha_k)$ 尽可能接近 $d$。\n对于 $\\alpha \\ge 0$，$r_{k+1}(\\alpha)$ 是关于 $\\alpha$ 的单调递增函数。其最小值在 $\\alpha=0$ 时取得（标准EKI步骤），当 $\\alpha \\to \\infty$ 时，它趋近于 $r_k$。\n-   如果 $r_{k+1}(0)  d$，则无法达到目标 $d$。我们能达到的最接近的值是通过使用 $\\alpha_k=0$。\n-   如果 $r_{k+1}(0) \\leq d$，则存在一个唯一的 $\\alpha_k  0$ 使得 $r_{k+1}(\\alpha_k) = d$。这个 $\\alpha_k$ 可以通过对函数 $f(\\alpha) = r_{k+1}(\\alpha) - d$ 使用如二分法之类的求根算法来高效地找到。\n\n### 5. 算法实现\n\n解决方案将使用Python和`numpy`库实现。\n\n1.  一个主函数 `solve()` 将遍历指定的三个测试案例。\n2.  对于每个案例：\n    a.  设置问题参数：维度、矩阵 $A$、$R$、$\\Gamma_u$、真实状态 $u_{\\mathrm{true}}$、观测值 $y$ 和初始集成，所有这些都使用指定的随机种子生成以保证可复现性。\n    b.  运行TEKI：实现一个 $k=0, \\dots, K_{\\max}-1$ 的循环。在每次迭代中，首先检查停止条件 $r_k \\leq d$。如果不满足，则使用上述基于二分法的策略确定 $\\alpha_k$。然后，执行一次增广EKI更新迭代。\n    c.  运行ES-EKI：实现一个 $k=0, \\dots, K_{\\max}-1$ 的循环。在每次迭代中，检查停止条件 $r_k \\leq d$。如果不满足，则执行一次标准EKI更新迭代（即 $\\alpha_k=0$）。\n    d.  比较结果：一旦两次运行都完成，计算两个指标：最终集成均值 $\\bar{u}_{\\mathrm{TEKI}}$ 和 $\\bar{u}_{\\mathrm{ES}}$ 之间的相对差异，以及它们的最终失配相对于目标 $d$ 的相对误差。仅当两个指定标准都满足时（即 $\\text{rel_diff}  \\epsilon=0.2$ 并且两个方法的 $|\\text{misfit_err}| \\leq \\delta=0.1$），比较返回 `True`。\n3.  最终输出将是一个包含三个布尔值的列表，每个布尔值对应一个测试案例。\n\n实现将使用数值稳定的例程，如 `np.linalg.solve`，而不是显式矩阵求逆。将创建辅助函数来管理设置问题和执行EKI步骤的复杂性。",
            "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    \n    test_cases = [\n        {\n            'n': 20, 'm': 15, 'J': 80,\n            'singular_values_type': 'well-conditioned',\n            'sigma': 0.05, 'tau': 1.05, 'K_max': 20,\n            'seed_A': 1001, 'seed_utrue': 2002, 'seed_eta': 3003, 'seed_ensemble': 4004,\n        },\n        {\n            'n': 40, 'm': 25, 'J': 120,\n            'singular_values_type': 'ill-conditioned',\n            'sigma': 0.05, 'tau': 1.05, 'K_max': 25,\n            'seed_A': 5005, 'seed_utrue': 6006, 'seed_eta': 7007, 'seed_ensemble': 8008,\n        },\n        {\n            'n': 60, 'm': 40, 'J': 5,\n            'singular_values_type': 'strongly-ill-conditioned',\n            'sigma': 0.05, 'tau': 1.05, 'K_max': 30,\n            'seed_A': 9009, 'seed_utrue': 10010, 'seed_eta': 11011, 'seed_ensemble': 12012,\n        },\n    ]\n\n    epsilon = 0.2\n    delta = 0.1\n    results = []\n\n    for case in test_cases:\n        # Setup problem for the current case\n        n, m, J = case['n'], case['m'], case['J']\n        r = min(m, n)\n        \n        # Generate A matrix\n        rng_A = np.random.default_rng(case['seed_A'])\n        U_full, _ = np.linalg.qr(rng_A.standard_normal(size=(m, m)))\n        V_full, _ = np.linalg.qr(rng_A.standard_normal(size=(n, n)))\n        U, V = U_full[:, :r], V_full[:, :r]\n        \n        if case['singular_values_type'] == 'well-conditioned':\n            s = np.ones(r)\n        elif case['singular_values_type'] == 'ill-conditioned':\n            s = np.power(10.0, -np.arange(r) / (r - 1))\n        else: # 'strongly-ill-conditioned'\n            s = np.power(10.0, -2.0 * np.arange(r) / (r - 1))\n            \n        A = U @ np.diag(s) @ V.T\n\n        # Generate true state and data\n        rng_true = np.random.default_rng(case['seed_utrue'])\n        u_true = rng_true.standard_normal(size=n)\n        \n        R = case['sigma']**2 * np.eye(m)\n        rng_eta = np.random.default_rng(case['seed_eta'])\n        eta = rng_eta.multivariate_normal(np.zeros(m), R)\n        y = A @ u_true + eta\n        \n        # Priors and initial ensemble\n        u_ref = np.zeros(n)\n        Gamma_u = np.eye(n)\n        rng_ens = np.random.default_rng(case['seed_ensemble'])\n        initial_ensemble = rng_ens.standard_normal(size=(n, J))\n\n        d = case['tau'] * np.sqrt(np.trace(R))\n\n        # Run both algorithms\n        u_teki, r_teki = run_eki(initial_ensemble.copy(), y, A, R, Gamma_u, u_ref, d, case['K_max'], 'teki')\n        u_es, r_es = run_eki(initial_ensemble.copy(), y, A, R, Gamma_u, u_ref, d, case['K_max'], 'es-eki')\n\n        # Compare results\n        rel_diff = np.linalg.norm(u_teki - u_es) / (np.linalg.norm(u_es) + 1e-12)\n        misfit_err_teki = abs(r_teki - d) / d\n        misfit_err_es = abs(r_es - d) / d\n        \n        cond1 = rel_diff  epsilon\n        cond2 = misfit_err_teki = delta and misfit_err_es = delta\n        \n        results.append(cond1 and cond2)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef perform_eki_step(u_ensemble, y, A, R, Gamma_u, u_ref, alpha):\n    \"\"\"Performs one step of EKI, standard or Tikhonov-augmented.\"\"\"\n    n, J = u_ensemble.shape\n    m = y.shape[0]\n\n    u_mean = np.mean(u_ensemble, axis=1)\n    U_prime = u_ensemble - u_mean[:, np.newaxis]\n    \n    if alpha == 0:\n        # Standard EKI\n        p_ensemble = A @ u_ensemble\n        p_mean = A @ u_mean\n        P_prime = p_ensemble - p_mean[:, np.newaxis]\n        \n        C_up = (1 / (J - 1)) * (U_prime @ P_prime.T)\n        C_pp = (1 / (J - 1)) * (P_prime @ P_prime.T)\n        \n        M_inv = C_pp + R\n        innovations = y[:, np.newaxis] - p_ensemble\n        \n        # Solve M_inv * X = innovations\n        try:\n            X = linalg.solve(M_inv, innovations, assume_a='pos')\n        except linalg.LinAlgError:\n            X = linalg.solve(M_inv, innovations, assume_a='sym')\n        \n        update_term = C_up @ X\n    else:\n        # Tikhonov-regularized (augmented) EKI\n        z = np.concatenate([y, np.zeros(n)])\n        H_u_ensemble = np.vstack([A @ u_ensemble, u_ensemble - u_ref[:, np.newaxis]])\n        \n        H_u_mean = np.mean(H_u_ensemble, axis=1)\n        H_P_prime = H_u_ensemble - H_u_mean[:, np.newaxis]\n\n        C_uH = (1 / (J - 1)) * (U_prime @ H_P_prime.T)\n        C_HH = (1 / (J - 1)) * (H_P_prime @ H_P_prime.T)\n\n        Sigma_aug = linalg.block_diag(R, (1 / alpha) * Gamma_u)\n        \n        M_inv = C_HH + Sigma_aug\n        innovations = z[:, np.newaxis] - H_u_ensemble\n        \n        try:\n            X = linalg.solve(M_inv, innovations, assume_a='pos')\n        except linalg.LinAlgError:\n            X = linalg.solve(M_inv, innovations, assume_a='sym')\n\n        update_term = C_uH @ X\n\n    return u_ensemble + update_term\n\ndef run_eki(initial_ensemble, y, A, R, Gamma_u, u_ref, d, K_max, mode):\n    \"\"\"Runs either TEKI or ES-EKI algorithm.\"\"\"\n    u_ensemble = initial_ensemble\n\n    for k in range(K_max):\n        u_mean = np.mean(u_ensemble, axis=1)\n        current_misfit = np.linalg.norm(y - A @ u_mean)\n\n        if current_misfit = d:\n            break\n\n        if mode == 'es-eki':\n            alpha_k = 0.0\n        else: # teki\n            # Find optimal alpha for this step\n            def get_next_misfit(alpha):\n                u_next_ensemble = perform_eki_step(u_ensemble, y, A, R, Gamma_u, u_ref, alpha)\n                u_next_mean = np.mean(u_next_ensemble, axis=1)\n                return np.linalg.norm(y - A @ u_next_mean)\n            \n            def objective_func(alpha):\n                return get_next_misfit(alpha) - d\n\n            # If unregularized step doesn't overfit, use alpha=0\n            if objective_func(0) >= 0:\n                alpha_k = 0.0\n            else:\n                # Bisection to find alpha where misfit matches d\n                alpha_min, alpha_max = 0.0, 1.0\n                # Find a bracket [min, max] where signs differ\n                for _ in range(10): \n                    if objective_func(alpha_max) > 0:\n                        break\n                    alpha_max *= 10.0\n                \n                # Perform bisection\n                for _ in range(50):\n                    alpha_mid = (alpha_min + alpha_max) / 2.0\n                    if objective_func(alpha_mid)  0:\n                        alpha_min = alpha_mid\n                    else:\n                        alpha_max = alpha_mid\n                alpha_k = (alpha_min + alpha_max) / 2.0\n        \n        u_ensemble = perform_eki_step(u_ensemble, y, A, R, Gamma_u, u_ref, alpha_k)\n\n    final_mean = np.mean(u_ensemble, axis=1)\n    final_misfit = np.linalg.norm(y - A @ final_mean)\n    return final_mean, final_misfit\n\nif __name__ == '__main__':\n    solve()\n\n```"
        },
        {
            "introduction": "最后，我们关注一个集合方法特有的高级实践问题：过早坍缩（premature collapse），即集合在收敛到最优解之前就丧失了多样性。本练习将介绍一种基于几何直觉的、更为精巧的解决方案——自适应协方差膨胀。您将设计并实现一个与集合子空间和目标函数梯度方向之间夹角相关联的膨胀规则，从而亲身体验如何诊断并有效缓解 EKI 在实践中遇到的这一关键瓶颈。",
            "id": "3379138",
            "problem": "考虑一个确定性逆问题，其参数向量为 $u \\in \\mathbb{R}^n$，正向映射为 $G:\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$。设观测数据为 $y \\in \\mathbb{R}^m$，并假设存在协方差矩阵为 $\\Gamma \\in \\mathbb{R}^{m \\times m}$ 的加性高斯噪声。定义最小二乘数据失配泛函\n$$\n\\Phi(u) = \\frac{1}{2}\\left\\| \\Gamma^{-1/2}\\left(G(u)-y\\right)\\right\\|_2^2.\n$$\n假设 $G$ 可微，并将其在 $u$ 处的雅可比矩阵表示为 $J(u) \\in \\mathbb{R}^{m \\times n}$。高斯-牛顿法使用梯度 $\\nabla \\Phi(u) = J(u)^\\top \\Gamma^{-1}\\left(G(u)-y\\right)$ 和一个正规矩阵近似 $J(u)^\\top \\Gamma^{-1} J(u)$。集成卡尔曼反演 (Ensemble Kalman Inversion, EKI) 通过在第 $k$ 次迭代时用集成协方差 $C^{uu}_k \\in \\mathbb{R}^{n \\times n}$ 替换与Hessian相关的项来近似高斯-牛顿步，从而产生一个增益\n$$\nK_k = C^{uu}_k\\, J(\\bar u_k)^\\top \\left(J(\\bar u_k)\\, C^{uu}_k\\, J(\\bar u_k)^\\top + \\alpha_k\\, \\Gamma\\right)^{-1},\n$$\n其中 $\\bar u_k$ 是集成均值，$\\alpha_k  0$ 是一个Tikhonov正则化参数。正则化迭代集成卡尔曼方法通过以下方式更新集成成员 $\\{u_j^k\\}_{j=1}^E$：\n$$\nu_j^{k+1} = u_j^k + K_k \\left(y - G(u_j^k)\\right), \\qquad j=1,\\dots,E,\n$$\n其中 $E$ 是集成大小。令集成异常为 $A_k = [u_1^k-\\bar u_k,\\dots,u_E^k-\\bar u_k] \\in \\mathbb{R}^{n \\times E}$，样本协方差为 $C^{uu}_k = \\frac{1}{E-1} A_k A_k^\\top$。过早崩溃是指在失配达到偏差原则目标之前，$C^{uu}_k$ 发生不希望出现的快速收缩；在此，如果在均值失配达到偏差目标\n$$\n\\Phi(\\bar u_k) \\le \\tau \\cdot \\frac{m}{2},\n$$\n之前，发生了\n$$\n\\frac{\\operatorname{tr}(C^{uu}_k)}{\\operatorname{tr}(C^{uu}_0)}  \\epsilon\n$$\n的情况，我们就在第 $k$ 次迭代声明发生了一次过早崩溃事件。其中 $(m/2)$ 是 $\\Phi$ 在噪声模型下的期望值（因为如果 $G(u)=y+$ 噪声且协方差为单位矩阵，那么 $2\\Phi$ 近似服从具有 $m$ 个自由度的卡方分布），$\\tau \\ge 1$ 是一个容差因子。\n\n设计并实现一个有原则的协方差膨胀规则，该规则使用集成子空间与梯度 $\\nabla \\Phi(\\bar u_k)$ 之间的夹角。令 $P_k$ 为到 $A_k$ 列空间上的正交投影算子，定义为\n$$\nP_k = A_k \\left(A_k^\\top A_k\\right)^\\dagger A_k^\\top,\n$$\n其中 $(\\cdot)^\\dagger$ 表示Moore–Penrose伪逆。通过下式定义该角度的余弦值：\n$$\n\\cos(\\theta_k) = \\frac{\\left\\|P_k \\nabla \\Phi(\\bar u_k)\\right\\|_2}{\\left\\|\\nabla \\Phi(\\bar u_k)\\right\\|_2},\n$$\n约定当 $\\nabla \\Phi(\\bar u_k)=0$ 时，$\\cos(\\theta_k)=1$。使用它来构建一个膨胀参数\n$$\n\\delta_k = \\min\\left\\{\\rho \\left(1 - \\cos(\\theta_k)\\right), \\, \\delta_{\\max}\\right\\},\n$$\n其中 $\\rho  0$ 和 $\\delta_{\\max}  0$ 是预设的常数。通过在增益计算中缩放协方差来应用膨胀：\n$$\nC^{uu}_k \\leftarrow (1+\\delta_k)\\, C^{uu}_k,\n$$\n此操作仅在增益 $K_k$ 内部进行，保持集成异常不变。\n\n您的任务是：\n- 实现上述带有膨胀规则的正则化迭代集成卡尔曼方法。\n- 比较两种配置：基准配置（无膨胀，设 $\\delta_k \\equiv 0$）和所定义的基于角度的膨胀配置。\n- 根据给定的准则检测过早崩溃，并测试基于角度的膨胀是否能在达到偏差目标的同时避免过早崩溃。\n\n使用以下正向模型和设置以确保科学真实性。令 $G(u)$ 为一个轻度非线性映射：\n$$\nG(u) = H u + b \\cdot \\sin(C u),\n$$\n其中 $H \\in \\mathbb{R}^{m \\times n}$ 是一个已知矩阵，$b  0$ 是一个标量非线性振幅，$C \\in \\mathbb{R}^{m \\times n}$ 是一个已知矩阵，并且正弦函数逐分量地应用于向量 $C u \\in \\mathbb{R}^m$。雅可比矩阵为\n$$\nJ(u) = H + b \\cdot \\operatorname{diag}\\left(\\cos(C u)\\right)\\, C.\n$$\n假设 $\\Gamma = \\sigma^2 I_m$，其中 $\\sigma  0$ 为标量，$I_m \\in \\mathbb{R}^{m \\times m}$ 为单位矩阵。通过抽取一个真实参数 $u^\\star$ 并设置 $y = G(u^\\star) + \\eta$（其中 $\\eta \\sim \\mathcal{N}(0,\\Gamma)$）来生成合成数据。通过从均值为 $\\mu_0$、协方差为 $\\beta^2 I_n$ 的高斯先验中采样来初始化集成。\n\n对所有测试固定以下算法常数：\n- 正则化参数 $\\alpha_k \\equiv \\alpha$，其中 $\\alpha = 0.05$。\n- 偏差容差因子 $\\tau = 1.5$。\n- 崩溃阈值 $\\epsilon = 0.05$。\n- 膨胀强度 $\\rho = 2.0$ 和上限 $\\delta_{\\max} = 3.0$。\n- 最大迭代次数 $K_{\\max} = 20$。\n- 使用基于均值的梯度 $\\nabla \\Phi(\\bar u_k) = J(\\bar u_k)^\\top \\Gamma^{-1}\\left(G(\\bar u_k)-y\\right)$。\n\n测试套件。在以下每组参数上实现并运行该方法，通过提供的随机种子确保可复现性。在每种情况下，构造 $H$ 以满足所述的条件，并将 $C$ 设置为密集的随机矩阵：\n- 情况 1：$n=8$, $m=5$, 集成大小 $E=6$, 噪声水平 $\\sigma=0.05$, 非线性振幅 $b=0.1$, 良态的 $H$；随机种子 $1$。\n- 情况 2：$n=8$, $m=5$, 集成大小 $E=3$, 噪声水平 $\\sigma=0.05$, 非线性振幅 $b=0.1$, 良态的 $H$；随机种子 $2$。\n- 情况 3：$n=10$, $m=6$, 集成大小 $E=5$, 噪声水平 $\\sigma=0.05$, 非线性振幅 $b=0.2$, 近乎秩亏的 $H$（奇异值快速衰减）；随机种子 $3$。\n\nH的构造：对于良态的 $H$，抽取一个随机高斯矩阵并通过奇异值分解进行正交化，然后将奇异值统一设置在 $[0.8,1.2]$ 区间内。对于近乎秩亏的 $H$，将奇异值设置为几何衰减，例如 $s_i = 10^{-i/(m)}$，其中 $i=1,\\dots,m$。\n\n对于每种情况，同时运行基准配置（无膨胀）和角度膨胀配置。当且仅当满足以下条件时，声明该情况为布尔成功：\n- 基准配置在某次迭代中发生了过早崩溃，并且\n- 角度膨胀配置没有发生过早崩溃，并且\n- 角度膨胀配置在 $K_{\\max}$ 次迭代内达到了偏差目标。\n\n最终输出格式。您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，第 $i$ 个条目是测试套件中第 $i$ 个情况的布尔成功值。例如，输出必须是 $[\\texttt{result1},\\texttt{result2},\\texttt{result3}]$ 的形式，其中每个 $\\texttt{resulti}$ 是 $\\texttt{True}$ 或 $\\texttt{False}$。",
            "solution": "问题陈述已经过验证，被认为是科学合理的、适定的和客观的。它在逆问题和数据同化领域内提出了一个清晰而正式的任务，特别关注集成卡尔曼反演 (EKI) 方法。所提供的定义、方程和常数是自洽且数学上一致的。该问题要求实现一种特定的协方差膨胀技术，旨在缓解集成方法中一个已知问题——过早的集成崩溃。测试用例旨在挑战算法在容易出现此故障模式的条件下的表现，例如小集成大小和病态正向算子。成功标准被明确定义。对于真实参数 $u^\\star$、初始集成均值 $\\mu_0$ 和方差尺度 $\\beta^2$ 的分布缺乏具体说明，这一小问题将通过使用标准且合理的选择来解决：$u^\\star \\sim N(0, I_n)$，$\\mu_0=0_n$ 和 $\\beta=1$。\n\n解决方案首先实现正则化迭代集成卡尔曼方法，然后并入指定的基于角度的协方差膨胀规则。接着，我们将在三个提供的测试用例上执行此方法，比较基准算法（无膨胀）与带角度膨胀的算法的性能。\n\n### 理论框架\n\n集成卡尔曼反演 (EKI) 是一种用于解决逆问题的迭代、无导数方法，可被解释为高斯-牛顿优化方法的一种基于集成的近似。目标是找到一个参数向量 $u$，以最小化数据失配泛函：\n$$\n\\Phi(u) = \\frac{1}{2}\\left\\| \\Gamma^{-1/2}\\left(G(u)-y\\right)\\right\\|_2^2\n$$\n在第 $k$ 次迭代时，对参数集成 $\\{u_j^k\\}_{j=1}^E$ 的更新规则由下式给出：\n$$\nu_j^{k+1} = u_j^k + K_k \\left(y - G(u_j^k)\\right)\n$$\n关键组件是类卡尔曼增益矩阵 $K_k$，在正则化EKI中为：\n$$\nK_k = C^{uu}_k J(\\bar u_k)^\\top \\left(J(\\bar u_k) C^{uu}_k J(\\bar u_k)^\\top + \\alpha_k \\Gamma\\right)^{-1}\n$$\n此处，$C^{uu}_k$ 是集成的样本协方差，它近似了参数协方差，$J(\\bar u_k)$ 是在集成均值 $\\bar u_k$ 处评估的正向映射 $G$ 的雅可比矩阵。项 $\\alpha_k \\Gamma$ 提供Tikhonov正则化。\n\nEKI 的一个关键失败模式是**过早崩溃**，即在参数收敛到低数据失配区域之前，由 $\\operatorname{tr}(C^{uu}_k)$ 衡量的集成方差收缩到其初始值的可忽略不计的一小部分。这是因为更新步骤将所有集成成员投影到一个低维子空间上，导致它们失去多样性。当集成子空间与真实下降方向（梯度方向 $\\nabla\\Phi$）正交时，该方法便会停滞。\n\n### 基于角度的协方差膨胀\n\n针对此问题的建议解决方案是一个有原则的协方差膨胀方案。核心思想是检测集成何时未能张成梯度方向，并相应地膨胀集成协方差。集成子空间与梯度之间的一致性通过 $\\nabla \\Phi(\\bar u_k)$ 与其在集成异常子空间 $\\operatorname{span}(A_k)$ 上的投影之间的角度 $\\theta_k$ 的余弦来衡量。\n$$\n\\cos(\\theta_k) = \\frac{\\left\\|P_k \\nabla \\Phi(\\bar u_k)\\right\\|_2}{\\left\\|\\nabla \\Phi(\\bar u_k)\\right\\|_2}\n$$\n其中 $P_k$ 是到异常矩阵 $A_k$ 列空间上的正交投影算子。$\\cos(\\theta_k) \\approx 0$ 的值表明梯度几乎与集成所张成的子空间正交，这预示着集成更新将是无效的。在这种情况下，集成需要更多的多样性来在梯度的方向上探索搜索空间。\n\n膨胀参数 $\\delta_k$ 被构造成当 $\\cos(\\theta_k)$ 小时值较大：\n$$\n\\delta_k = \\min\\left\\{\\rho \\left(1 - \\cos(\\theta_k)\\right), \\, \\delta_{\\max}\\right\\}\n$$\n然后，此膨胀被选择性地应用于增益计算中使用的协方差矩阵，$C^{uu}_k \\leftarrow (1+\\delta_k) C^{uu}_k$。这种干预在不改变底层集成成员的情况下增加了更新步长的大小，有效地将集成沿着其能够表示的方向“推”得更远，并帮助其在后续步骤中与梯度重新对齐。\n\n### 实现细节\n\n解决方案使用 Python 的 `numpy` 库实现。\n\n1.  **设置和数据生成**：对于每个测试用例，为了可复现性，会设置一个随机数生成器的种子。根据规范构造矩阵 $H$ 和 $C$。从标准正态分布中抽取一个真实参数 $u^\\star$，并通过评估正向模型 $G(u^\\star)$ 并添加协方差为 $\\Gamma = \\sigma^2 I_m$ 的高斯噪声来生成合成数据 $y$。从标准正态先验分布中抽取初始集成 $\\{u_j^0\\}$。\n\n2.  **EKI求解器**：一个函数实现了迭代 EKI 循环。在每次迭代 $k$ 中：\n    a. 计算集成均值 $\\bar u_k$ 和异常矩阵 $A_k$。\n    b. 形成样本协方差 $C^{uu}_k$。\n    c. 检查过早崩溃条件 $\\operatorname{tr}(C^{uu}_k) / \\operatorname{tr}(C^{uu}_0)  \\epsilon$。如果满足此条件且尚未达到偏差目标，则将该次运行标记为过早崩溃。\n    d. 检查收敛停止准则 $\\Phi(\\bar u_k) \\le \\tau \\cdot m/2$。如果满足，则将该次运行标记为已收敛。\n    e. 如果 `use_inflation` 为真，则计算膨胀因子 $\\delta_k$。这涉及计算梯度 $\\nabla \\Phi(\\bar u_k)$、投影算子 $P_k$（通过对梯度进行操作来隐式计算）和 $\\cos(\\theta_k)$。\n    f. 使用膨胀后的协方差 $C^{uu, \\text{inflated}}_k = (1+\\delta_k)C^{uu}_k$ 来计算增益矩阵 $K_k$。对于基准情况，$\\delta_k=0$。\n    g. 使用增益 $K_k$ 和残差 $(y - G(u_j^k))$ 来更新每个集成成员 $u_j^k$ 至 $u_j^{k+1}$。\n\n3.  **评估**：对于每个测试用例，EKI 求解器运行两次：一次用于基准配置（无膨胀），一次用于角度膨胀配置。通过同时验证问题要求的三个条件来确定该情况的布尔成功：\n    1. 基准运行导致了“premature_collapse”。\n    2. 膨胀运行*没有*导致“premature_collapse”。\n    3. 膨胀运行导致了“converged”（即，它达到了偏差目标）。\n\n最终输出是这些布尔成功标志的列表，每个测试用例一个。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the final results.\n    \"\"\"\n    test_cases = [\n        {'n': 8, 'm': 5, 'E': 6, 'sigma': 0.05, 'b': 0.1, 'h_type': 'well', 'seed': 1},\n        {'n': 8, 'm': 5, 'E': 3, 'sigma': 0.05, 'b': 0.1, 'h_type': 'well', 'seed': 2},\n        {'n': 10, 'm': 6, 'E': 5, 'sigma': 0.05, 'b': 0.2, 'h_type': 'rank_def', 'seed': 3},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_one_case(**params)\n        results.append(result)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\ndef G(u, H, C, b):\n    \"\"\"Forward model G(u) = H*u + b*sin(C*u).\"\"\"\n    # Ensure u is a 1D vector for consistent matrix-vector products\n    if u.ndim > 1:\n        u = u.flatten()\n    return H @ u + b * np.sin(C @ u)\n\ndef J(u, H, C, b):\n    \"\"\"Jacobian of the forward model J(u).\"\"\"\n    if u.ndim > 1:\n        u = u.flatten()\n    return H + b * np.diag(np.cos(C @ u)) @ C\n\ndef phi(G_u, y, sigma_sq):\n    \"\"\"Data misfit functional Phi(u).\"\"\"\n    residual = G_u - y\n    return 0.5 * np.dot(residual, residual) / sigma_sq\n\ndef eki_solver(u_ens_initial, y, H, C, b, sigma, alpha, tau, epsilon, K_max, use_inflation, rho, delta_max):\n    \"\"\"\n    Implements the Ensemble Kalman Inversion algorithm.\n\n    Returns a tuple of (status, final_iteration_count).\n    Status can be 'converged', 'premature_collapse', or 'max_iter'.\n    \"\"\"\n    u_ens = u_ens_initial.copy()\n    n, E = u_ens.shape\n    m = y.shape[0]\n\n    sigma_sq = sigma**2\n    gamma_inv = (1.0 / sigma_sq) * np.eye(m)\n    gamma = sigma_sq * np.eye(m)\n    discrepancy_target = tau * m / 2.0\n\n    A0 = u_ens - u_ens.mean(axis=1, keepdims=True)\n    C_uu_0 = (1.0 / (E - 1)) * (A0 @ A0.T) if E > 1 else np.zeros((n,n))\n    trace_C0 = np.trace(C_uu_0)\n\n    if trace_C0  1e-15:\n        return 'error_zero_initial_trace', 0\n\n    for k in range(K_max):\n        u_mean = u_ens.mean(axis=1)\n        A_k = u_ens - u_mean[:, np.newaxis]\n        C_uu_k = (1.0 / (E - 1)) * (A_k @ A_k.T) if E > 1 else np.zeros((n, n))\n\n        # 1. Check for premature collapse\n        trace_Ck = np.trace(C_uu_k)\n        if trace_Ck / trace_C0  epsilon:\n            G_mean_check = G(u_mean, H, C, b)\n            misfit_val_check = phi(G_mean_check, y, sigma_sq)\n            if misfit_val_check > discrepancy_target:\n                return 'premature_collapse', k\n\n        # 2. Check for convergence\n        G_mean = G(u_mean, H, C, b)\n        misfit_val = phi(G_mean, y, sigma_sq)\n        if misfit_val = discrepancy_target:\n            return 'converged', k\n            \n        # 3. Calculate inflation\n        delta_k = 0.0\n        J_mean = J(u_mean, H, C, b)\n        if use_inflation:\n            grad = J_mean.T @ gamma_inv @ (G_mean - y)\n            norm_grad = np.linalg.norm(grad)\n            \n            if norm_grad > 1e-12 and E > 1:\n                # Project grad onto span(A_k): P_k * grad = A_k * pinv(A_k.T @ A_k) @ A_k.T @ grad\n                # We use pinv for stability, though inv might work if A_k.T @ A_k is full rank.\n                AT_grad = A_k.T @ grad\n                AT_A = A_k.T @ A_k\n                proj_grad = A_k @ (np.linalg.pinv(AT_A) @ AT_grad)\n                cos_theta_k = np.linalg.norm(proj_grad) / norm_grad\n            else:\n                cos_theta_k = 1.0\n            \n            delta_k = min(rho * (1.0 - cos_theta_k), delta_max)\n        \n        C_k_for_gain = (1.0 + delta_k) * C_uu_k\n        \n        # 4. Calculate Gain K_k\n        term = J_mean @ C_k_for_gain @ J_mean.T + alpha * gamma\n        K_k = C_k_for_gain @ J_mean.T @ np.linalg.inv(term)\n\n        # 5. Update ensemble\n        u_ens_new = np.zeros_like(u_ens)\n        for j in range(E):\n            G_j = G(u_ens[:, j], H, C, b)\n            u_ens_new[:, j] = u_ens[:, j] + K_k @ (y - G_j)\n        u_ens = u_ens_new\n    \n    # Check misfit one last time after max iterations\n    u_mean = u_ens.mean(axis=1)\n    G_mean = G(u_mean, H, C, b)\n    misfit_val = phi(G_mean, y, sigma_sq)\n    if misfit_val = discrepancy_target:\n        return 'converged', K_max\n    \n    return 'max_iter', K_max\n\ndef run_one_case(n, m, E, sigma, b, h_type, seed):\n    \"\"\"\n    Sets up and runs a single test case, returning the boolean success criteria.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Construct matrices H and C\n    A_rand = rng.standard_normal(size=(m, n))\n    U, s_vals, Vt = np.linalg.svd(A_rand, full_matrices=False)\n    \n    if h_type == 'well':\n        s_new = rng.uniform(0.8, 1.2, size=m)\n    else: # 'rank_def'\n        s_new = 10.0**(-np.arange(1, m + 1) / m)\n    \n    H = U @ np.diag(s_new) @ Vt\n    C = rng.standard_normal(size=(m, n))\n\n    # 2. Generate synthetic data\n    u_star = rng.standard_normal(size=n)\n    y = G(u_star, H, C, b) + rng.normal(0, sigma, size=m)\n\n    # 3. Generate initial ensemble (mean 0, variance 1)\n    mu0 = np.zeros(n)\n    beta = 1.0\n    u_ens_initial = rng.multivariate_normal(mu0, beta**2 * np.eye(n), size=E).T\n\n    # 4. Define constants\n    alpha = 0.05\n    tau = 1.5\n    epsilon = 0.05\n    rho = 2.0\n    delta_max = 3.0\n    K_max = 20\n\n    # 5. Run simulations\n    base_status, _ = eki_solver(u_ens_initial, y, H, C, b, sigma, alpha, tau, epsilon, K_max, use_inflation=False, rho=rho, delta_max=delta_max)\n    infl_status, _ = eki_solver(u_ens_initial, y, H, C, b, sigma, alpha, tau, epsilon, K_max, use_inflation=True, rho=rho, delta_max=delta_max)\n    \n    # 6. Evaluate success criterion\n    baseline_collapsed = (base_status == 'premature_collapse')\n    inflated_ok = (infl_status != 'premature_collapse')\n    inflated_converged = (infl_status == 'converged')\n\n    return baseline_collapsed and inflated_ok and inflated_converged\n\nif __name__ == '__main__':\n    solve()\n\n```"
        }
    ]
}