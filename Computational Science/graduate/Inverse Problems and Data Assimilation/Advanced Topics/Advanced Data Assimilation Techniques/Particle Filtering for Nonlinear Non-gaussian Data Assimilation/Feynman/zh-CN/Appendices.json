{
    "hands_on_practices": [
        {
            "introduction": "在非线性、非高斯系统中，诸如扩展卡尔曼滤波器 (EKF) 等经典方法依赖于局部线性化，但这可能引入显著误差。本练习将引导您通过直接比较 EKF 的估计结果与精确的数值贝叶斯更新，亲手量化这种近似的局限性 。这个过程将清晰地揭示，为何我们需要粒子滤波器这类更强大的、基于采样的方法来处理复杂模型。",
            "id": "3409807",
            "problem": "考虑一个用于数据同化的标量隐马尔可夫模型，其具有非线性观测算子和非高斯观测噪声。令时间 $t$ 的隐藏状态为 $x_t \\in \\mathbb{R}$。假设在时间 $t$ 的先验（也称为一步预测）是均值为 $m_t^{-}$、方差为 $P_t^{-}$ 的高斯分布，即 $p(x_t \\mid y_{1:t-1}) = \\mathcal{N}(x_t \\mid m_t^{-}, P_t^{-})$。时间 $t$ 的观测值为 $y_t \\in \\mathbb{R}$，通过一个已知的非线性函数 $h(\\cdot)$ 和加性噪声与状态相关联，$y_t = h(x_t) + \\varepsilon_t$，其中噪声 $\\varepsilon_t$ 服从自由度为 $\\nu$、尺度为 $s$ 的学生t分布，因此其概率密度函数为\n$$\np_{\\varepsilon}(e) = \\frac{\\Gamma\\!\\left(\\frac{\\nu + 1}{2}\\right)}{\\Gamma\\!\\left(\\frac{\\nu}{2}\\right)\\sqrt{\\nu \\pi}\\, s} \\left(1 + \\frac{1}{\\nu}\\left(\\frac{e}{s}\\right)^2\\right)^{-\\frac{\\nu + 1}{2}}.\n$$\n观测算子由下式给出\n$$\nh(x) = x + a \\sin(b x),\n$$\n其中参数为 $a \\in \\mathbb{R}$ 和 $b \\in \\mathbb{R}$。对于此问题，假设所有量都是无量纲的，不涉及物理单位。\n\n您的任务是：\n\n1. 使用贝叶斯定理以及给定的先验、似然和观测算子，定义滤波后验密度\n$$\np(x_t \\mid y_{1:t}) \\propto p(y_t \\mid x_t) \\, p(x_t \\mid y_{1:t-1}),\n$$\n并对下述每个测试用例，数值计算其前两个矩，即后验均值\n$$\n\\mu_t = \\mathbb{E}[x_t \\mid y_{1:t}],\n$$\n和后验方差\n$$\n\\sigma_t^2 = \\mathbb{V}[x_t \\mid y_{1:t}],\n$$\n数值计算必须通过对 $x \\in \\mathbb{R}$ 上的未归一化后验进行直接数值积分来执行，不使用任何高斯近似或线性化。\n\n2. 计算由扩展卡尔曼滤波器 (EKF) 预测的矩，在本问题中其定义如下。使用一阶泰勒展开在预测均值 $m_t^{-}$ 处对观测算子进行线性化，\n$$\nh(x) \\approx h(m_t^{-}) + H_t (x - m_t^{-}), \\quad \\text{其中 } H_t = \\left.\\frac{dh}{dx}\\right|_{x = m_t^{-}} = 1 + a b \\cos(b m_t^{-}).\n$$\n将观测噪声近似为与学生t分布具有相同方差的高斯分布，即\n$$\nR = \\frac{\\nu}{\\nu - 2} s^2 \\quad \\text{对于 } \\nu > 2.\n$$\n然后使用标准标量卡尔曼滤波器公式计算均值和方差的 EKF 更新，\n$$\nS_t = H_t^2 P_t^{-} + R, \\quad K_t = \\frac{P_t^{-} H_t}{S_t}, \\quad m_t^{\\text{EKF}} = m_t^{-} + K_t \\left(y_t - h(m_t^{-})\\right), \\quad P_t^{\\text{EKF}} = \\left(1 - K_t H_t\\right) P_t^{-}.\n$$\n\n对于每个测试用例，您的程序必须生成数值后验矩 $\\mu_t$ 和 $\\sigma_t^2$、EKF 矩 $m_t^{\\text{EKF}}$ 和 $P_t^{\\text{EKF}}$，以及绝对差 $\\lvert \\mu_t - m_t^{\\text{EKF}} \\rvert$ 和 $\\lvert \\sigma_t^2 - P_t^{\\text{EKF}} \\rvert$。\n\n使用以下参数值的测试套件 $(m_t^{-}, P_t^{-}, y_t, a, b, \\nu, s)$，该套件涵盖了一个典型案例、一个线性化预期会很准确的小方差情况、一个高度非线性和分散的先验案例，以及一个重尾异常值案例：\n\n- 测试用例 1：$(0.0, 1.0, 1.0, 0.5, 1.0, 5.0, 0.5)$。\n- 测试用例 2：$(0.5, 0.01, 0.2, 0.8, 2.0, 7.0, 0.3)$。\n- 测试用例 3：$(-1.0, 4.0, 2.5, 1.2, 2.0, 4.0, 0.7)$。\n- 测试用例 4：$(0.0, 1.5, 4.0, 0.7, 1.5, 3.1, 1.0)$。\n\n对于数值积分，您必须在 $x \\in (-\\infty, \\infty)$ 上进行积分，并计算归一化常数、一阶原始矩和二阶原始矩，然后通过相减获得方差。所有积分都必须使用标准的自适应求积法计算到合理的数值精度；不要对线进行粗略离散化。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。对于四个测试用例，该列表必须按以下固定顺序平铺：对于按上述顺序排列的每个测试用例，输出 $[\\mu_t, \\sigma_t^2, m_t^{\\text{EKF}}, P_t^{\\text{EKF}}, \\lvert \\mu_t - m_t^{\\text{EKF}} \\rvert, \\lvert \\sigma_t^2 - P_t^{\\text{EKF}} \\rvert]$，然后将所有测试用例的这些结果连接成一个单一列表。例如，输出应类似于 $[\\text{case1\\_mu}, \\text{case1\\_var}, \\text{case1\\_m\\_ekf}, \\text{case1\\_P\\_ekf}, \\text{case1\\_dmu}, \\text{case1\\_dvar}, \\text{case2\\_mu}, \\ldots, \\text{case4\\_dvar}]$，其中每个占位符都是一个实数。",
            "solution": "该问题是有效的，因为它在科学上基于贝叶斯滤波和数据同化的原理，问题陈述清晰且提供了所有必要信息，并且表述客观。我们将提供一个完整的解决方案。\n\n问题的核心是为时间 $t$ 的标量隐藏状态 $x_t \\in \\mathbb{R}$ 执行贝叶斯更新。该更新将关于状态的先验信念与来自观测值 $y_t$ 的新信息相结合。给定截至时间 $t$ 的所有观测值（表示为 $y_{1:t}$），$x_t$ 的后验概率密度函数 (PDF) 由贝叶斯定理给出：\n$$\np(x_t \\mid y_{1:t}) \\propto p(y_t \\mid x_t) \\, p(x_t \\mid y_{1:t-1})\n$$\n这里，$p(x_t \\mid y_{1:t-1})$ 是先验 PDF（来自前一时间步的预测），$p(y_t \\mid x_t)$ 是似然函数，它量化了在给定特定状态 $x_t$ 时观测到 $y_t$ 的概率。\n\n问题将先验分布指定为高斯分布：\n$$\np(x_t \\mid y_{1:t-1}) = \\mathcal{N}(x_t \\mid m_t^{-}, P_t^{-}) = \\frac{1}{\\sqrt{2 \\pi P_t^{-}}} \\exp\\left(-\\frac{(x_t - m_t^{-})^2}{2 P_t^{-}}\\right)\n$$\n其中 $m_t^{-}$ 是先验均值，$P_t^{-}$ 是先验方差。\n\n观测模型为 $y_t = h(x_t) + \\varepsilon_t$，具有非线性观测算子 $h(x) = x + a \\sin(b x)$ 和加性噪声 $\\varepsilon_t$。噪声服从自由度为 $\\nu$、尺度参数为 $s$ 的学生t分布。因此，似然函数是在残差 $e = y_t - h(x_t)$ 处求值的噪声 PDF：\n$$\np(y_t \\mid x_t) = p_{\\varepsilon}(y_t - h(x_t)) = \\frac{\\Gamma\\!\\left(\\frac{\\nu + 1}{2}\\right)}{\\Gamma\\!\\left(\\frac{\\nu}{2}\\right)\\sqrt{\\nu \\pi}\\, s} \\left(1 + \\frac{1}{\\nu}\\left(\\frac{y_t - h(x_t)}{s}\\right)^2\\right)^{-\\frac{\\nu + 1}{2}}\n$$\n\n未归一化的后验密度，我们称之为 $q(x_t)$，是先验和似然的乘积。为了进行数值计算，我们可以通过去掉常数因子来使用一个与真实未归一化后验成比例的 $q(x_t)$ 版本：\n$$\nq(x_t) \\propto \\exp\\left(-\\frac{(x_t - m_t^{-})^2}{2 P_t^{-}}\\right) \\left(1 + \\frac{1}{\\nu}\\left(\\frac{y_t - (x_t + a \\sin(b x_t))}{s}\\right)^2\\right)^{-\\frac{\\nu + 1}{2}}\n$$\n\n**1. 后验矩的数值计算**\n为了找到精确的后验均值 $\\mu_t$ 和方差 $\\sigma_t^2$，我们必须执行数值积分。我们首先计算未归一化后验 $q(x_t)$ 的必要原始矩：\n归一化常数（零阶矩）：\n$$\nZ = \\int_{-\\infty}^{\\infty} q(x_t) \\, dx_t\n$$\n一阶原始矩：\n$$\nM_1 = \\int_{-\\infty}^{\\infty} x_t \\, q(x_t) \\, dx_t\n$$\n二阶原始矩：\n$$\nM_2 = \\int_{-\\infty}^{\\infty} x_t^2 \\, q(x_t) \\, dx_t\n$$\n这些积分是使用自适应求积法在定义域 $(-\\infty, \\infty)$ 上计算的。然后，后验均值和方差计算如下：\n$$\n\\mu_t = \\mathbb{E}[x_t \\mid y_{1:t}] = \\frac{M_1}{Z}\n$$\n$$\n\\sigma_t^2 = \\mathbb{V}[x_t \\mid y_{1:t}] = \\mathbb{E}[x_t^2 \\mid y_{1:t}] - (\\mathbb{E}[x_t \\mid y_{1:t}])^2 = \\frac{M_2}{Z} - \\mu_t^2\n$$\n\n**2. 扩展卡尔曼滤波器 (EKF) 近似**\nEKF 通过做出两个关键近似来简化问题：\n1. 非线性观测算子 $h(x_t)$ 在先验均值 $m_t^{-}$ 周围通过一阶泰勒展开进行线性化：\n$$\nh(x_t) \\approx h(m_t^{-}) + H_t (x_t - m_t^{-})\n$$\n其中 $H_t$ 是 $h$ 在 $m_t^{-}$ 处求值的雅可比矩阵。对于给定的标量函数，这是导数：\n$$\nH_t = \\left.\\frac{dh}{dx}\\right|_{x = m_t^{-}} = 1 + a b \\cos(b m_t^{-})\n$$\n2. 非高斯观测噪声 $\\varepsilon_t$ 被近似为零均值高斯分布，其方差与学生t分布相同。对于 $\\nu > 2$，该方差为：\n$$\nR = \\frac{\\nu}{\\nu - 2} s^2\n$$\n通过这些近似，问题变成了一个标准的线性高斯更新，卡尔曼滤波器方程为此提供了精确的后验矩。这些是 EKF 近似的矩：\n新息协方差：\n$$\nS_t = H_t^2 P_t^{-} + R\n$$\n卡尔曼增益：\n$$\nK_t = \\frac{P_t^{-} H_t}{S_t}\n$$\nEKF 后验均值：\n$$\nm_t^{\\text{EKF}} = m_t^{-} + K_t \\left(y_t - h(m_t^{-})\\right)\n$$\nEKF 后验方差：\n$$\nP_t^{\\text{EKF}} = \\left(1 - K_t H_t\\right) P_t^{-}\n$$\n下面的程序为每个指定的测试用例实现了用于精确矩的数值积分和用于近似矩的 EKF 方程。然后计算所需的绝对差 $\\lvert \\mu_t - m_t^{\\text{EKF}} \\rvert$ 和 $\\lvert \\sigma_t^2 - P_t^{\\text{EKF}} \\rvert$，以比较这两种方法。",
            "answer": "```python\nimport numpy as np\nfrom scipy import integrate\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Computes and compares numerical Bayesian and EKF updates for a scalar HMM.\n    \"\"\"\n    test_cases = [\n        # (m_minus, P_minus, y_t, a, b, nu, s)\n        (0.0, 1.0, 1.0, 0.5, 1.0, 5.0, 0.5),  # Case 1: Typical case\n        (0.5, 0.01, 0.2, 0.8, 2.0, 7.0, 0.3),  # Case 2: Small prior variance\n        (-1.0, 4.0, 2.5, 1.2, 2.0, 4.0, 0.7), # Case 3: High nonlinearity\n        (0.0, 1.5, 4.0, 0.7, 1.5, 3.1, 1.0),   # Case 4: Heavy-tailed outlier\n    ]\n\n    results = []\n\n    def h_func(x, a, b):\n        \"\"\" The nonlinear observation operator h(x). \"\"\"\n        return x + a * np.sin(b * x)\n\n    def unnormalized_posterior(x, m_minus, P_minus, y, a, b, nu, s):\n        \"\"\"\n        Computes the unnormalized posterior density q(x) = p(y|x)p(x).\n        \"\"\"\n        # Likelihood term p(y|x)\n        residual = y - h_func(x, a, b)\n        likelihood = stats.t.pdf(residual, df=nu, loc=0, scale=s)\n        \n        # Prior term p(x)\n        prior = stats.norm.pdf(x, loc=m_minus, scale=np.sqrt(P_minus))\n        \n        return likelihood * prior\n\n    for case in test_cases:\n        m_minus, P_minus, y, a, b, nu, s = case\n        params = (m_minus, P_minus, y, a, b, nu, s)\n\n        # 1. Numerical Bayesian Update\n        \n        # Define integrands for moments\n        integrand_Z = lambda x, *p: unnormalized_posterior(x, *p)\n        integrand_M1 = lambda x, *p: x * unnormalized_posterior(x, *p)\n        integrand_M2 = lambda x, *p: x**2 * unnormalized_posterior(x, *p)\n\n        # Numerically integrate using adaptive quadrature\n        Z, _ = integrate.quad(integrand_Z, -np.inf, np.inf, args=params)\n        M1, _ = integrate.quad(integrand_M1, -np.inf, np.inf, args=params)\n        M2, _ = integrate.quad(integrand_M2, -np.inf, np.inf, args=params)\n\n        # Calculate posterior mean and variance\n        mu_t = M1 / Z\n        sigma2_t = M2 / Z - mu_t**2\n\n        # 2. Extended Kalman Filter (EKF) Update\n        \n        # Linearization\n        h_m_minus = h_func(m_minus, a, b)\n        H_t = 1.0 + a * b * np.cos(b * m_minus)\n        \n        # Observation noise variance approximation\n        R = (nu / (nu - 2.0)) * s**2\n        \n        # Standard Kalman filter update equations\n        S_t = H_t**2 * P_minus + R\n        K_t = (P_minus * H_t) / S_t\n        m_ekf = m_minus + K_t * (y - h_m_minus)\n        P_ekf = (1.0 - K_t * H_t) * P_minus\n        \n        # 3. Compute Absolute Differences\n        d_mu = np.abs(mu_t - m_ekf)\n        d_sigma2 = np.abs(sigma2_t - P_ekf)\n        \n        results.extend([mu_t, sigma2_t, m_ekf, P_ekf, d_mu, d_sigma2])\n\n    # Format and print the final output string\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在明确了基于采样方法的需求后，本练习将深入探讨粒子滤波器在连续时间设定下的核心机制。您将实现一个完整的预测-更新循环，包括使用欧拉-丸山 (Euler-Maruyama) 方法传播粒子，并计算至关重要的重要性权重 。此练习着重于处理提议动态与模型动态之间的差异以及非高斯观测数据的影响，这些都是高级数据同化中的核心挑战。",
            "id": "3409822",
            "problem": "您需要实现一个连续时间引导粒子滤波器的一个时间步，用于解决一个非线性、非高斯的数据同化问题。潜在状态根据一个具有恒定扩散和非线性漂移的随机微分方程（SDE, stochastic differential equation）演化。一组粒子近似在时间 $t$ 的滤波分布，并且必须使用欧拉-丸山（Euler-Maruyama）离散化方法传播到时间 $t + \\Delta t$，并重新加权以同时考虑模型转移和一个带有重尾噪声的观测。\n\n基本设置：\n- 潜在状态 $x_t \\in \\mathbb{R}$ 根据SDE演化\n$$\n\\mathrm{d}x_t = f(x_t) \\,\\mathrm{d}t + \\sigma \\,\\mathrm{d}W_t,\n$$\n其中 $W_t$ 是布朗运动，$\\sigma > 0$ 是一个已知的标量扩散系数，而 $f$ 是一个非线性漂移。用于粒子传播的提议由一个可能与真实漂移 $f$ 不同的漂移 $g$ 给出。\n- 用于提议的欧拉-丸山（EM, Euler-Maruyama）离散化方法对每个粒子 $x^{(i)}_t$ 进行如下计算：\n$$\nx^{(i)}_{t+\\Delta t} = x^{(i)}_t + g\\big(x^{(i)}_t\\big)\\,\\Delta t + \\sigma \\,\\Delta W^{(i)},\n$$\n其中布朗增量 $\\Delta W^{(i)}$ 是从一个均值为 $0$、方差为 $\\Delta t$ 的正态分布中抽取的随机变量。\n- 在时间 $t+\\Delta t$ 的一次观测通过以下方式提供：\n$$\ny = h\\big(x_{t+\\Delta t}\\big) + v,\n$$\n其中 $h$ 是非线性的，而 $v$ 是从一个自由度为 $\\nu$、尺度为 $s > 0$ 的学生t分布中抽取的。观测噪声是重尾的，而非高斯的。\n\n单个时间步的任务：\n1. 从指定的分布中初始化 $N$ 个在时间 $t$ 的粒子，并赋予它们均匀的权重。\n2. 使用带有漂移 $g$ 和扩散 $\\sigma$ 的EM提议，将粒子传播到时间 $t+\\Delta t$。\n3. 基于SDE中常数扩散下测度变换的基本原理，计算由于目标模型转移（漂移为 $f$）和提议转移（漂移为 $g$）在时间步上的不匹配所导致的重要性权重校正。必须使用一个连续时间拉东-尼科迪姆导数在单步上的原则性离散化：它必须依赖于漂移差异、扩散、时间步长以及每个粒子已实现的布朗增量。\n4. 结合带有学生t噪声的非线性测量 $h$ 的观测似然。使用似然直到一个常数因子是可接受的，因为归一化的重要性权重会消除所有粒子共有的常数。\n5. 归一化更新后的权重，并计算有效样本量（ESS, effective sample size），定义为\n$$\n\\mathrm{ESS} = \\frac{1}{\\sum_{i=1}^N \\big(w^{(i)}\\big)^2},\n$$\n其中 $w^{(i)}$ 是在时间 $t+\\Delta t$ 的归一化权重。\n6. 不执行重采样；仅报告ESS。\n\n模型规格：\n- 漂移 $f$ 是\n$$\nf(x) = \\alpha \\,\\tanh(x),\n$$\n其中 $\\alpha > 0$ 是一个已知的标量参数。\n- 提议漂移 $g$ 是以下之一：\n  - $g(x) = f(x)$ (无不匹配),\n  - $g(x) = \\alpha x$ (线性化不匹配),\n  - $g(x) = 0$ (零漂移不匹配)。\n- 测量函数是\n$$\nh(x) = x^3.\n$$\n\n粒子初始化：\n- 粒子数量 $N = 250$。\n- 初始粒子 $x^{(i)}_t$ 是独立同分布的，服从均值为 $0$、方差为 $1$ 的标准正态分布，使用固定的随机种子生成以保证可复现性。\n- 初始权重是均匀的 $w^{(i)}_t = \\frac{1}{N}$。\n\n随机性与可复现性：\n- 您必须使用指定的随机种子来初始化粒子和在每个测试案例中生成布朗增量。\n- 每个测试案例使用其自身的种子来生成布朗增量；初始粒子使用指定的种子生成一次，并在所有案例中重复使用。\n\n测试套件与参数：\n- 所有测试案例的通用参数：$\\alpha = 1.3$，$\\sigma = 0.6$，$N = 250$，初始粒子种子 $= 2025$，$h(x) = x^3$，自由度 $\\nu = 5$，尺度 $s = 0.7$。\n- 测试案例A（理想路径）：\n  - 时间步长 $\\Delta t = 0.1$，\n  - 提议漂移类型：$g(x) = f(x)$ (无不匹配)，\n  - 观测值 $y = 1.0$，\n  - 布朗增量种子 $= 10$。\n- 测试案例B（动力学显著不匹配）：\n  - 时间步长 $\\Delta t = 0.1$，\n  - 提议漂移类型：$g(x) = 0$ (零漂移)，\n  - 观测值 $y = 1.0$，\n  - 布朗增量种子 $= 20$。\n- 测试案例C（小时间步边界）：\n  - 时间步长 $\\Delta t = 10^{-3}$，\n  - 提议漂移类型：$g(x) = \\alpha x$ (线性化)，\n  - 观测值 $y = 1.0$，\n  - 布朗增量种子 $= 30$。\n- 测试案例D（离群观测）：\n  - 时间步长 $\\Delta t = 0.1$，\n  - 提议漂移类型：$g(x) = \\alpha x$ (线性化)，\n  - 观测值 $y = 8.0$，\n  - 布朗增量种子 $= 40$。\n\n算法约束：\n- 动力学的重要性权重校正必须从适用于常数扩散SDE的第一性原理推导得出，以确保科学真实性，并针对单个欧拉-丸山步骤和已实现的布朗增量进行实现。\n- 观测似然必须反映 $y - h(x_{t+\\Delta t})$ 的学生t噪声，其自由度为 $\\nu$，尺度为 $s$，直到一个常数因子。\n- 所有计算必须是数值稳定的；例如，在适当的情况下，在对数域中执行权重计算。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，即按顺序排列的测试案例A、B、C和D的四个计算出的 $\\mathrm{ESS}$ 值，均为浮点数。例如，输出格式为\n$$\n[\\mathrm{ESS}_A,\\mathrm{ESS}_B,\\mathrm{ESS}_C,\\mathrm{ESS}_D].\n$$\n不应打印任何额外文本。\n\n您的实现必须是一个完整、可运行的Python程序，版本为 $3.12$，仅使用标准库、NumPy版本 $1.23.5$ 和 SciPy版本 $1.11.4$（无其他库）。程序必须是自包含的，没有任何外部输入或文件。",
            "solution": "用户提供的问题陈述被认为是有效的。它在科学上基于随机微分方程和粒子滤波的理论，是适定的，定义了所有必要的参数和条件，并且其表述是客观的。因此，我们可以进行完整的解答。\n\n该问题要求实现一个引导粒子滤波器在连续时间内定义的状态空间模型中的单个时间步。潜在状态 $x_t \\in \\mathbb{R}$ 根据一个随机微分方程（SDE）演化，观测是非线性的，并被重尾噪声所污染。任务的核心是传播一个粒子系综，并根据模型动力学和新的观测来更新它们的重要性权重。\n\n从时间 $t$到 $t+\\Delta t$ 的单个时间步的总体流程如下：\n1.  **传播：** 每个粒子 $x^{(i)}_t$ 通过一个提议分布前进到一个新状态 $x^{(i)}_{t+\\Delta t}$。\n2.  **加权：** 更新每个粒子的重要性权重，以反映其与真实模型动力学和时间 $t+\\Delta t$ 处观测的吻合程度。\n3.  **评估：** 从新的、归一化的权重计算有效样本量（ESS），以量化权重退化程度。\n\n我们现在根据提供的模型规格详细说明每个步骤。\n\n**1. 粒子传播**\n\n每个粒子 $i \\in \\{1, \\dots, N\\}$ 的状态使用提议SDE的欧拉-丸山离散化从时间 $t$ 传播到 $t+\\Delta t$。提议动力学使用一个漂移函数 $g(x)$，该函数可能与真实模型漂移 $f(x)$ 不同。\n\n粒子 $i$ 的更新规则是：\n$$\nx^{(i)}_{t+\\Delta t} = x^{(i)}_t + g\\big(x^{(i)}_t\\big)\\,\\Delta t + \\sigma \\,\\Delta W^{(i)}\n$$\n其中 $\\Delta W^{(i)}$ 是一个随机样本，代表在长度为 $\\Delta t$ 的区间上的布朗增量。这些增量是为每个粒子独立地从均值为 $0$、方差为 $\\Delta t$ 的正态分布中抽取的，即 $\\Delta W^{(i)} \\sim \\mathcal{N}(0, \\Delta t)$。\n\n**2. 重要性权重更新**\n\n给定时间 $t$ 的均匀权重 $w^{(i)}_t = 1/N$，时间 $t+\\Delta t$ 的新的未归一化权重 $\\tilde{w}^{(i)}_{t+\\Delta t}$ 由一个动力学校正因子和一个观测似然项的乘积给出：\n$$\n\\tilde{w}^{(i)}_{t+\\Delta t} \\propto w_{\\text{dyn}}^{(i)} \\times L^{(i)}\n$$\n为保证数值稳定性，计算在对数域中进行：\n$$\n\\log \\tilde{w}^{(i)}_{t+\\Delta t} = \\log w_{\\text{dyn}}^{(i)} + \\log L^{(i)} + C\n$$\n其中 $C$ 是一个任意常数。\n\n**2.1. 动力学校正权重 ($w_{\\text{dyn}}^{(i)}$)**\n\n该项校正了提议动力学（漂移为 $g$）与目标动力学（漂移为 $f$）之间的差异。重要性权重是目标转移概率密度与提议转移概率密度的比率，即 $w_{\\text{dyn}}^{(i)} = p(x^{(i)}_{t+\\Delta t} | x^{(i)}_t) / q(x^{(i)}_{t+\\Delta t} | x^{(i)}_t)$。\n\n对于具有恒定扩散 $\\sigma$ 的欧拉-丸山方案，两种密度都是高斯分布：\n-   目标：$p(x_{t+\\Delta t} | x_t) = \\mathcal{N}(x_{t+\\Delta t} | x_t + f(x_t)\\Delta t, \\sigma^2 \\Delta t)$\n-   提议：$q(x_{t+\\Delta t} | x_t) = \\mathcal{N}(x_{t+\\Delta t} | x_t + g(x_t)\\Delta t, \\sigma^2 \\Delta t)$\n\n这两个密度之比的对数，在消去公共项后，得到对数重要性权重。这个结果是Girsanov定理的拉东-尼科迪姆导数的一阶离散化。对于粒子 $i$，动力学校正的对数权重为：\n$$\n\\log w_{\\text{dyn}}^{(i)} = \\frac{f(x_t^{(i)}) - g(x_t^{(i)})}{\\sigma^2} \\left( \\sigma \\Delta W^{(i)} \\right) - \\frac{1}{2} \\left( \\frac{f(x_t^{(i)}) - g(x_t^{(i)})}{\\sigma} \\right)^2 \\Delta t\n$$\n这里，$f(x) = \\alpha \\tanh(x)$ 是真实漂移，$g(x)$ 是由测试案例指定的提议漂移，而 $\\sigma \\Delta W^{(i)} = x^{(i)}_{t+\\Delta t} - x^{(i)}_t - g(x_t^{(i)})\\Delta t$ 是在提议步骤中实现的随机分量。如果提议漂移与真实漂移匹配（$g=f$），则此项为零，无需校正。\n\n**2.2. 观测似然 ($L^{(i)}$)**\n\n观测模型为 $y = h(x_{t+\\Delta t}) + v$，其中噪声 $v$ 服从自由度为 $\\nu$、尺度参数为 $s$ 的学生t分布。该分布的概率密度函数（PDF）为：\n$$\np(v; \\nu, s) = \\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\Gamma\\left(\\frac{\\nu}{2}\\right)\\sqrt{\\pi\\nu}s} \\left(1 + \\frac{1}{\\nu}\\left(\\frac{v}{s}\\right)^2\\right)^{-\\frac{\\nu+1}{2}}\n$$\n给定其传播状态 $x^{(i)}_{t+\\Delta t}$，粒子 $i$ 的观测似然是在残差 $v^{(i)} = y - h(x^{(i)}_{t+\\Delta t})$ 处评估的PDF。因为最终权重是归一化的，所以似然中的任何常数乘法因子都无关紧要。因此，粒子 $i$ 的对数似然为：\n$$\n\\log L^{(i)} \\propto -\\frac{\\nu+1}{2} \\log\\left(1 + \\frac{1}{\\nu}\\left(\\frac{y - h\\left(x^{(i)}_{t+\\Delta t}\\right)}{s}\\right)^2\\right)\n$$\n该表达式捕捉了对于每个粒子的提议状态观测到 $y$ 的相对概率。\n\n**3. 权重归一化与ESS计算**\n\n将总的未归一化对数权重 $\\log \\tilde{w}^{(i)}_{t+\\Delta t}$ 合并，然后归一化使其总和为一。为防止数值下溢，采用log-sum-exp技巧。首先，我们找到最大对数权重 $C = \\max_i(\\log \\tilde{w}^{(i)}_{t+\\Delta t})$。然后，归一化权重 $w^{(i)}_{t+\\Delta t}$ 计算如下：\n$$\nw^{(i)}_{t+\\Delta t} = \\frac{\\exp\\left(\\log \\tilde{w}^{(i)}_{t+\\Delta t} - C\\right)}{\\sum_{j=1}^{N} \\exp\\left(\\log \\tilde{w}^{(j)}_{t+\\Delta t} - C\\right)}\n$$\n最后，计算有效样本量（ESS）以评估粒子权重的退化情况。一个低的ESS值表明少数粒子具有非常高的权重，而其余的则可以忽略不计，这表明分布的粒子表示较差。ESS由以下公式给出：\n$$\n\\mathrm{ESS} = \\frac{1}{\\sum_{i=1}^N \\left(w^{(i)}_{t+\\Delta t}\\right)^2}\n$$\n一个接近粒子总数 $N$ 的ESS值表明权重几乎是均匀的，这是理想情况。一个接近 $1$ 的ESS值则表示极端退化。对四个指定的测试案例分别进行此分析。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import t as student_t\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Implements a single time-step of a bootstrap particle filter for a nonlinear,\n    non-Gaussian data assimilation problem and computes the Effective Sample Size (ESS)\n    for four different test cases.\n    \"\"\"\n    \n    # Common parameters across all test cases\n    alpha = 1.3\n    sigma = 0.6\n    N = 250\n    initial_particle_seed = 2025\n    nu = 5.0\n    s_scale = 0.7\n\n    # Define the core model functions\n    f_drift = lambda x: alpha * np.tanh(x)\n    h_obs = lambda x: x**3\n\n    # Define the parameters for each test case\n    test_cases_params = [\n        {'dt': 0.1, 'g_type': 'identity', 'y_obs': 1.0, 'brownian_seed': 10}, # Case A\n        {'dt': 0.1, 'g_type': 'zero', 'y_obs': 1.0, 'brownian_seed': 20},     # Case B\n        {'dt': 1e-3, 'g_type': 'linear', 'y_obs': 1.0, 'brownian_seed': 30},  # Case C\n        {'dt': 0.1, 'g_type': 'linear', 'y_obs': 8.0, 'brownian_seed': 40},   # Case D\n    ]\n\n    # --- Step 1: Initialize particles (done once for all cases) ---\n    # These are the particles at time t, x_t.\n    rng_initial = np.random.default_rng(initial_particle_seed)\n    x_t = rng_initial.normal(loc=0.0, scale=1.0, size=N)\n\n    results_ess = []\n    \n    for case_params in test_cases_params:\n        dt = case_params['dt']\n        g_type = case_params['g_type']\n        y_obs = case_params['y_obs']\n        brownian_seed = case_params['brownian_seed']\n\n        # Define the proposal drift function g(x) based on the test case\n        if g_type == 'identity':\n            g_drift = f_drift\n        elif g_type == 'zero':\n            g_drift = lambda x: np.zeros_like(x)\n        elif g_type == 'linear':\n            g_drift = lambda x: alpha * x\n        else:\n            # This path should not be reached with the given test cases\n            raise ValueError(f\"Unknown proposal drift type: {g_type}\")\n\n        # --- Step 2: Propagate particles (Prediction) ---\n        # Generate Brownian increments for this specific case\n        rng_brownian = np.random.default_rng(brownian_seed)\n        delta_W = rng_brownian.normal(loc=0.0, scale=np.sqrt(dt), size=N)\n        \n        g_val_t = g_drift(x_t)\n        # These are the propagated particles at time t+dt, x_{t+dt}\n        x_t_plus_dt = x_t + g_val_t * dt + sigma * delta_W\n\n        # --- Step 3  4: Compute unnormalized log weights (Update) ---\n        \n        # Part 1: Log importance weight correction for dynamics mismatch\n        f_val_t = f_drift(x_t)\n        drift_diff = f_val_t - g_val_t\n        \n        log_dyn_correction = (drift_diff / sigma**2) * (sigma * delta_W) - 0.5 * (drift_diff / sigma)**2 * dt\n\n        # Part 2: Log likelihood from the observation\n        h_val_t_plus_dt = h_obs(x_t_plus_dt)\n        log_obs_likelihood = student_t.logpdf(y_obs, df=nu, loc=h_val_t_plus_dt, scale=s_scale)\n\n        # Combine log weights\n        log_weights_unnorm = log_dyn_correction + log_obs_likelihood\n\n        # --- Step 5: Normalize weights and compute ESS ---\n        \n        # Use logsumexp for robust normalization\n        log_sum_weights = logsumexp(log_weights_unnorm)\n        log_normalized_weights = log_weights_unnorm - log_sum_weights\n        normalized_weights = np.exp(log_normalized_weights)\n        \n        # Compute Effective Sample Size (ESS)\n        ess = 1.0 / np.sum(normalized_weights**2)\n        results_ess.append(ess)\n\n    # Print the final results in the required format\n    print(f\"[{','.join(map(str, results_ess))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "粒子滤波中的一个普遍挑战是权重退化，您可能已通过前一个练习中的有效样本量 (ESS) 注意到此现象。本练习聚焦于解决此问题的关键技术——重采样，您将通过分步实现分层重采样算法来掌握它 。掌握这种方差缩减方法对于开发能够长期保持粒子多样性的、稳健高效的粒子滤波器至关重要。",
            "id": "3409843",
            "problem": "考虑一个在序贯蒙特卡洛（SMC）框架内使用粒子滤波器（PF）估计的非线性、非高斯状态空间模型。在给定的同化周期，假设您有 $N$ 个粒子，其未归一化的重要性权重为 $\\tilde{w}_{1},\\ldots,\\tilde{w}_{N}$，其中 $N=10$ 且\n$$\n\\tilde{w}_{1}=2,\\ \\tilde{w}_{2}=1,\\ \\tilde{w}_{3}=1,\\ \\tilde{w}_{4}=1,\\ \\tilde{w}_{5}=5,\\ \\tilde{w}_{6}=2,\\ \\tilde{w}_{7}=3,\\ \\tilde{w}_{8}=1,\\ \\tilde{w}_{9}=3,\\ \\tilde{w}_{10}=1.\n$$\n为了减轻权重退化并减少抽样方差，您使用分层重采样执行重采样步骤，该方法在 $[0,1)$ 上等宽的每个分层中抽取一个均匀变量。\n\n从SMC中重要性采样和重采样的核心定义出发，归一化权重以获得 $w_{j}=\\tilde{w}_{j}/\\sum_{k=1}^{N}\\tilde{w}_{k}$，为 $j=1,\\ldots,N$ 构建累积分布函数（CDF）$C_{j}=\\sum_{k=1}^{j}w_{k}$，并使用每个分层中以下特定的均匀样本执行分层重采样：\n$$\nu_{i}=\\frac{i-\\tfrac{1}{2}}{N},\\quad i=1,\\ldots,N,\n$$\n因此明确地\n$$\nu_{1}=0.05,\\ u_{2}=0.15,\\ u_{3}=0.25,\\ u_{4}=0.35,\\ u_{5}=0.45,\\ u_{6}=0.55,\\ u_{7}=0.65,\\ u_{8}=0.75,\\ u_{9}=0.85,\\ u_{10}=0.95.\n$$\n使用逆CDF法则来分配祖先索引 $a_{i}$，其定义为满足 $u_{i}\\leq C_{j}$ 的最小 $j$。然后计算后代计数 $n_{j}$，其定义为索引 $j$ 在 $\\{a_{1},\\ldots,a_{N}\\}$ 中出现的次数。\n\n请提供一个单行矩阵作为最终答案，该矩阵首先连接后代计数 $(n_{1},\\ldots,n_{N})$，然后是祖先索引 $(a_{1},\\ldots,a_{N})$，按此顺序排列。无需四舍五入，也不涉及单位。您的推理应从SMC的基本原理开始，而不是使用快捷公式。",
            "solution": "问题要求我们为粒子滤波器（PF）执行一个分层重采样步骤，并报告由此产生的后代计数和祖先索引。该过程是用于非线性、非高斯系统中状态估计的序贯蒙特卡洛（SMC）方法论的一部分。重采样的核心思想是解决权重退化问题，即在少数几个同化周期后，大多数粒子的重要性权重都变得可以忽略不计。重采样通过复制高权重的粒子并丢弃低权重的粒子来更新粒子集，从而有效地将计算资源集中在状态空间中更可能的区域。\n\n首先，我们验证问题陈述的有效性。问题提供了一组明确的未归一化重要性权重、一个特定的重采样方案（分层重采样）、一个清晰的执行算法以及一个精确的输出格式。所有定义在数据同化领域都是标准的。所提供的数据是自包含的、一致的且数值上是合理的。该问题具有科学依据、提法恰当、客观且可验证。因此，该问题是有效的，我们可以继续进行求解。\n\n过程始于给定的一组 $N=10$ 个未归一化重要性权重，$\\tilde{w}_{j}$ 对于 $j=1,\\ldots,10$：\n$$\n\\tilde{w}_{1}=2,\\ \\tilde{w}_{2}=1,\\ \\tilde{w}_{3}=1,\\ \\tilde{w}_{4}=1,\\ \\tilde{w}_{5}=5,\\ \\tilde{w}_{6}=2,\\ \\tilde{w}_{7}=3,\\ \\tilde{w}_{8}=1,\\ \\tilde{w}_{9}=3,\\ \\tilde{w}_{10}=1.\n$$\n第一步是归一化这些权重，使它们的总和为 $1$。未归一化权重的总和是：\n$$\n\\sum_{k=1}^{10} \\tilde{w}_{k} = 2+1+1+1+5+2+3+1+3+1 = 20.\n$$\n归一化权重 $w_{j}$ 通过将每个未归一化权重除以这个总和得到：$w_{j} = \\tilde{w}_{j} / \\sum_{k=1}^{10} \\tilde{w}_{k}$。\n$$\n\\begin{aligned}\nw_{1} = \\frac{2}{20} = 0.1 \\\\\nw_{2} = \\frac{1}{20} = 0.05 \\\\\nw_{3} = \\frac{1}{20} = 0.05 \\\\\nw_{4} = \\frac{1}{20} = 0.05 \\\\\nw_{5} = \\frac{5}{20} = 0.25 \\\\\nw_{6} = \\frac{2}{20} = 0.1 \\\\\nw_{7} = \\frac{3}{20} = 0.15 \\\\\nw_{8} = \\frac{1}{20} = 0.05 \\\\\nw_{9} = \\frac{3}{20} = 0.15 \\\\\nw_{10} = \\frac{1}{20} = 0.05\n\\end{aligned}\n$$\n这些归一化权重定义了粒子索引上的一个离散概率分布。下一步是构建累积分布函数（CDF），$C_{j} = \\sum_{k=1}^{j} w_{k}$。\n$$\n\\begin{aligned}\nC_{1} = w_{1} = 0.1 \\\\\nC_{2} = C_{1} + w_{2} = 0.1 + 0.05 = 0.15 \\\\\nC_{3} = C_{2} + w_{3} = 0.15 + 0.05 = 0.20 \\\\\nC_{4} = C_{3} + w_{4} = 0.20 + 0.05 = 0.25 \\\\\nC_{5} = C_{4} + w_{5} = 0.25 + 0.25 = 0.50 \\\\\nC_{6} = C_{5} + w_{6} = 0.50 + 0.1 = 0.60 \\\\\nC_{7} = C_{6} + w_{7} = 0.60 + 0.15 = 0.75 \\\\\nC_{8} = C_{7} + w_{8} = 0.75 + 0.05 = 0.80 \\\\\nC_{9} = C_{8} + w_{9} = 0.80 + 0.15 = 0.95 \\\\\nC_{10} = C_{9} + w_{10} = 0.95 + 0.05 = 1.00\n\\end{aligned}\n$$\n重采样步骤涉及从当前粒子集中抽取 $N$ 个新粒子，其中抽取粒子 $j$ 的概率是 $w_{j}$。分层重采样将区间 $[0,1)$ 划分为 $N$ 个相等的层，$[\\frac{i-1}{N}, \\frac{i}{N})$，对于 $i=1,\\ldots,N$。从每个分层中抽取一个单一的均匀随机样本。问题指定了要使用的确切样本：\n$$\nu_{i} = \\frac{i - \\frac{1}{2}}{N} \\quad \\text{for } i=1,\\ldots,10.\n$$\n给定的样本是：\n$$\nu_{1}=0.05,\\ u_{2}=0.15,\\ u_{3}=0.25,\\ u_{4}=0.35,\\ u_{5}=0.45,\\ u_{6}=0.55,\\ u_{7}=0.65,\\ u_{8}=0.75,\\ u_{9}=0.85,\\ u_{10}=0.95.\n$$\n我们使用逆CDF方法为每个样本 $u_i$ 找到祖先索引 $a_i$。规则是找到满足 $u_i \\leq C_j$ 的最小索引 $j$。这等同于找到哪个区间 $(C_{j-1}, C_j]$（其中 $C_0=0$）包含 $u_i$。\n\n- 对于 $u_1=0.05$：我们需要满足 $0.05 \\le C_j$ 的最小 $j$。因为 $C_1=0.1$，所以条件对 $j=1$ 成立。因此，$a_1=1$。\n- 对于 $u_2=0.15$：我们需要满足 $0.15 \\le C_j$ 的最小 $j$。$C_1=0.1  0.15$，但 $C_2=0.15 \\ge 0.15$。满足条件的最小 $j$ 是 $2$。因此，$a_2=2$。\n- 对于 $u_3=0.25$：我们需要满足 $0.25 \\le C_j$ 的最小 $j$。$C_3=0.20  0.25$，但 $C_4=0.25 \\ge 0.25$。满足条件的最小 $j$ 是 $4$。因此，$a_3=4$。\n- 对于 $u_4=0.35$：我们需要满足 $0.35 \\le C_j$ 的最小 $j$。$C_4=0.25  0.35$，但 $C_5=0.50 \\ge 0.35$。满足条件的最小 $j$ 是 $5$。因此，$a_4=5$。\n- 对于 $u_5=0.45$：我们需要满足 $0.45 \\le C_j$ 的最小 $j$。$C_4=0.25  0.45$，但 $C_5=0.50 \\ge 0.45$。满足条件的最小 $j$ 是 $5$。因此，$a_5=5$。\n- 对于 $u_6=0.55$：我们需要满足 $0.55 \\le C_j$ 的最小 $j$。$C_5=0.50  0.55$，但 $C_6=0.60 \\ge 0.55$。满足条件的最小 $j$ 是 $6$。因此，$a_6=6$。\n- 对于 $u_7=0.65$：我们需要满足 $0.65 \\le C_j$ 的最小 $j$。$C_6=0.60  0.65$，但 $C_7=0.75 \\ge 0.65$。满足条件的最小 $j$ 是 $7$。因此，$a_7=7$。\n- 对于 $u_8=0.75$：我们需要满足 $0.75 \\le C_j$ 的最小 $j$。$C_6=0.60  0.75$，但 $C_7=0.75 \\ge 0.75$。满足条件的最小 $j$ 是 $7$。因此，$a_8=7$。\n- 对于 $u_9=0.85$：我们需要满足 $0.85 \\le C_j$ 的最小 $j$。$C_8=0.80  0.85$，但 $C_9=0.95 \\ge 0.85$。满足条件的最小 $j$ 是 $9$。因此，$a_9=9$。\n- 对于 $u_{10}=0.95$：我们需要满足 $0.95 \\le C_j$ 的最小 $j$。$C_8=0.80  0.95$，但 $C_9=0.95 \\ge 0.95$。满足条件的最小 $j$ 是 $9$。因此，$a_{10}=9$。\n\n祖先索引的集合是 $\\{a_1,\\ldots,a_{10}\\} = \\{1, 2, 4, 5, 5, 6, 7, 7, 9, 9\\}$。新的粒子集将由这些祖先粒子的副本组成。\n\n最后，我们计算后代计数 $n_j$，即每个原始粒子索引 $j$ 被选为祖先的次数。我们计算集合 $\\{a_1, \\ldots, a_{10}\\}$ 中每个索引出现的次数。\n- $n_1$（1的计数）：$1$\n- $n_2$（2的计数）：$1$\n- $n_3$（3的计数）：$0$\n- $n_4$（4的计数）：$1$\n- $n_5$（5的计数）：$2$\n- $n_6$（6的计数）：$1$\n- $n_7$（7的计数）：$2$\n- $n_8$（8的计数）：$0$\n- $n_9$（9的计数）：$2$\n- $n_{10}$（10的计数）：$0$\n\n后代计数的向量是 $(n_1,\\ldots,n_{10}) = (1, 1, 0, 1, 2, 1, 2, 0, 2, 0)$。作为检查，后代计数的总和必须是 $N$：$1+1+0+1+2+1+2+0+2+0=10$。\n祖先索引的向量是 $(a_1,\\ldots,a_{10}) = (1, 2, 4, 5, 5, 6, 7, 7, 9, 9)$。\n\n最终答案是后代计数和祖先索引连接成一个单行矩阵。\n$$\n(n_1,\\ldots,n_{10}, a_1,\\ldots,a_{10}) = (1, 1, 0, 1, 2, 1, 2, 0, 2, 0, 1, 2, 4, 5, 5, 6, 7, 7, 9, 9).\n$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1  1  0  1  2  1  2  0  2  0  1  2  4  5  5  6  7  7  9  9\n\\end{pmatrix}\n}\n$$"
        }
    ]
}