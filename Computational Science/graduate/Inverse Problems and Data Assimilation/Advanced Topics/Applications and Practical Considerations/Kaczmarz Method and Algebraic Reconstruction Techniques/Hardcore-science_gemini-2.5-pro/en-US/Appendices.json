{
    "hands_on_practices": [
        {
            "introduction": "The Kaczmarz method is perhaps most famously known as the Algebraic Reconstruction Technique (ART) in the field of computed tomography. This first exercise provides a concrete, hands-on application of the method by asking you to build a small-scale tomographic system from scratch. By manually assembling the system matrix and performing the first few iterations, you will gain a fundamental intuition for how ART sequentially incorporates information from each measurement ray to build up an image estimate .",
            "id": "3393590",
            "problem": "Consider a simple parallel-beam Computed Tomography (CT) discretization on a $3\\times 3$ pixel grid of unit square pixels. Let the unknown image be represented by a vector $x \\in \\mathbb{R}^{9}$ in row-major order, i.e., $x = (x_{1}, x_{2}, x_{3}, x_{4}, x_{5}, x_{6}, x_{7}, x_{8}, x_{9})$ corresponds to rows from top to bottom and columns from left to right. The forward model is the standard line integral discretization: each measurement is the sum of pixel values weighted by the path length of the ray through that pixel. The measurements are modeled as $A x = b$, where each row of $A$ corresponds to a ray, and $b$ contains the corresponding recorded line integrals.\n\nYou are given four rays:\n- Ray $R_{1}$: horizontal through the middle row, crossing pixels $(x_{4}, x_{5}, x_{6})$ with path lengths $1, 1, 1$.\n- Ray $R_{2}$: vertical through the middle column, crossing pixels $(x_{2}, x_{5}, x_{8})$ with path lengths $1, 1, 1$.\n- Ray $R_{3}$: main diagonal from the top-left to the bottom-right crossing pixels $(x_{1}, x_{5}, x_{9})$ along the diagonal with path length $\\sqrt{2}$ in each crossed pixel.\n- Ray $R_{4}$: anti-diagonal from the top-right to the bottom-left crossing pixels $(x_{3}, x_{5}, x_{7})$ along the diagonal with path length $\\sqrt{2}$ in each crossed pixel.\n\nThe recorded measurements are\n$$\nb = \\big(4,\\ 6,\\ 4\\sqrt{2},\\ 5\\sqrt{2}\\big).\n$$\n\nTasks:\n1. Assemble the system matrix $A \\in \\mathbb{R}^{4\\times 9}$ explicitly from the stated geometry.\n2. Starting from the initial guess $x^{(0)} = 0 \\in \\mathbb{R}^{9}$, perform two successive iterations of the Algebraic Reconstruction Technique (ART) using the Kaczmarz method with relaxation parameter equal to $1$, projecting sequentially onto the hyperplanes defined by $R_{1}$ and then $R_{2}$ (i.e., use the first row of $A$ and its measurement in the first step, and the second row in the second step).\n3. Report the updated pixel vector $x^{(2)}$ after exactly two ART steps as a single row vector.\n\nExpress your final answer in exact form; do not round. Provide the answer as a single row matrix.",
            "solution": "We begin from the standard linear forward model for line-integral tomography: for each ray indexed by $i$, the measurement is $b_{i} = \\sum_{j=1}^{9} a_{ij} x_{j}$, where $a_{ij}$ is the path length of ray $i$ through pixel $j$. Assembling $A$ requires identifying which pixels are intersected by each ray and setting entries to the corresponding path lengths; all other entries are zero.\n\nFrom the given geometry:\n- For ray $R_{1}$ (middle row), the nonzero entries are at pixels $(x_{4}, x_{5}, x_{6})$ with path lengths $1, 1, 1$, so the first row is\n$$\na_{1}^\\top = (0,\\ 0,\\ 0,\\ 1,\\ 1,\\ 1,\\ 0,\\ 0,\\ 0).\n$$\n- For ray $R_{2}$ (middle column), the nonzero entries are at pixels $(x_{2}, x_{5}, x_{8})$ with path lengths $1, 1, 1$, so the second row is\n$$\na_{2}^\\top = (0,\\ 1,\\ 0,\\ 0,\\ 1,\\ 0,\\ 0,\\ 1,\\ 0).\n$$\n- For ray $R_{3}$ (main diagonal), the nonzero entries are at pixels $(x_{1}, x_{5}, x_{9})$ with path lengths $\\sqrt{2}$, so the third row is\n$$\na_{3}^\\top = (\\sqrt{2},\\ 0,\\ 0,\\ 0,\\ \\sqrt{2},\\ 0,\\ 0,\\ 0,\\ \\sqrt{2}).\n$$\n- For ray $R_{4}$ (anti-diagonal), the nonzero entries are at pixels $(x_{3}, x_{5}, x_{7})$ with path lengths $\\sqrt{2}$, so the fourth row is\n$$\na_{4}^\\top = (0,\\ 0,\\ \\sqrt{2},\\ 0,\\ \\sqrt{2},\\ 0,\\ \\sqrt{2},\\ 0,\\ 0).\n$$\n\nThus,\n$$\nA = \n\\begin{pmatrix}\n0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 1 & 0 & 0 & 1 & 0 \\\\\n\\sqrt{2} & 0 & 0 & 0 & \\sqrt{2} & 0 & 0 & 0 & \\sqrt{2} \\\\\n0 & 0 & \\sqrt{2} & 0 & \\sqrt{2} & 0 & \\sqrt{2} & 0 & 0\n\\end{pmatrix},\n\\quad\nb = \n\\begin{pmatrix}\n4 \\\\ 6 \\\\ 4\\sqrt{2} \\\\ 5\\sqrt{2}\n\\end{pmatrix}.\n$$\n\nNext, we apply the Algebraic Reconstruction Technique (ART). The Kaczmarz update for a single row $a_{i}^\\top$ with relaxation parameter $\\omega=1$ is an orthogonal projection onto the hyperplane $\\{x: a_{i}^\\top x = b_{i}\\}$. The update is:\n$$\nx^{(k+1)} = x^{(k)} + \\frac{b_{i} - a_{i}^\\top x^{(k)}}{\\|a_{i}\\|^{2}}\\, a_{i},\n$$\nWe perform two successive iterations starting from $x^{(0)} = 0$, first using row 1 and then row 2.\n\nStep 1 (use $i=1$):\n- Compute the squared norm $\\|a_{1}\\|^{2}$. Since $a_{1}$ has three entries equal to $1$ and the rest zero, we have $\\|a_{1}\\|^{2} = 1^{2} + 1^{2} + 1^{2} = 3$.\n- Compute $a_{1}^\\top x^{(0)} = 0$ because $x^{(0)} = 0$.\n- Compute the update:\n$$\nx^{(1)} = x^{(0)} + \\frac{b_1 - a_1^\\top x^{(0)}}{\\|a_1\\|^2} a_1 = 0 + \\frac{4-0}{3} a_1\n$$\nSince $a_{1}$ has ones at positions $4, 5, 6$ and zeros elsewhere, we obtain\n$$\nx^{(1)} = \\left(0,\\ 0,\\ 0,\\ \\tfrac{4}{3},\\ \\tfrac{4}{3},\\ \\tfrac{4}{3},\\ 0,\\ 0,\\ 0\\right).\n$$\n\nStep 2 (use $i=2$):\n- Compute the squared norm $\\|a_{2}\\|^{2}$. There are three entries equal to $1$, so $\\|a_{2}\\|^{2} = 3$.\n- Compute $a_{2}^\\top x^{(1)} = x_{2}^{(1)} + x_{5}^{(1)} + x_{8}^{(1)} = 0 + \\tfrac{4}{3} + 0 = \\tfrac{4}{3}$.\n- Compute the update:\n$$\nx^{(2)} = x^{(1)} + \\frac{b_2 - a_2^\\top x^{(1)}}{\\|a_2\\|^2} a_2 = x^{(1)} + \\frac{6 - \\tfrac{4}{3}}{3} a_2 = x^{(1)} + \\frac{\\tfrac{14}{3}}{3} a_2 = x^{(1)} + \\frac{14}{9} a_2\n$$\nSince $a_{2}$ has ones at positions $2, 5, 8$ and zeros elsewhere, we add $\\frac{14}{9}$ to these components of $x^{(1)}$:\n$$\nx^{(2)} = \\left(0,\\ 0+\\tfrac{14}{9},\\ 0,\\ \\tfrac{4}{3},\\ \\tfrac{4}{3} + \\tfrac{14}{9},\\ \\tfrac{4}{3},\\ 0,\\ 0+\\tfrac{14}{9},\\ 0\\right).\n$$\nCombine the middle element:\n$$\n\\tfrac{4}{3} + \\tfrac{14}{9} = \\tfrac{12}{9} + \\tfrac{14}{9} = \\tfrac{26}{9}.\n$$\nThus,\n$$\nx^{(2)} = \\left(0,\\ \\tfrac{14}{9},\\ 0,\\ \\tfrac{4}{3},\\ \\tfrac{26}{9},\\ \\tfrac{4}{3},\\ 0,\\ \\tfrac{14}{9},\\ 0\\right).\n$$\n\nThis is the exact updated pixel vector after two ART steps in the specified order.",
            "answer": "$$\\boxed{\\begin{pmatrix}0 & \\tfrac{14}{9} & 0 & \\tfrac{4}{3} & \\tfrac{26}{9} & \\tfrac{4}{3} & 0 & \\tfrac{14}{9} & 0\\end{pmatrix}}$$"
        },
        {
            "introduction": "Moving from mechanics to theory, we now investigate how to optimize the convergence of the Kaczmarz method. This practice explores the crucial role of the relaxation parameter, $\\omega$, which controls the step size of each projection. By analyzing a simplified two-dimensional system, you will derive a bound on the expected error reduction and use it to find the optimal $\\omega$ that guarantees the fastest convergence, linking the algorithm's performance directly to the geometric properties of the underlying system .",
            "id": "3266569",
            "problem": "Consider a consistent linear system $A x = b$ in $\\mathbb{R}^{2}$ with two measurement rows $a_{1}^{\\top} x = b_{1}$ and $a_{2}^{\\top} x = b_{2}$, where $a_{1}, a_{2} \\in \\mathbb{R}^{2}$ satisfy $\\|a_{1}\\| = \\|a_{2}\\| = 1$ and $a_{1}^{\\top} a_{2} = \\mu$ with $0 \\leq \\mu < 1$. Let $x^{\\star}$ denote the exact solution. The Kaczmarz method, also known as the Algebraic Reconstruction Technique (ART), with relaxation parameter $\\omega \\in [0, 2]$ performs updates of the form\n$$\nx_{k+1} = x_{k} + \\omega \\frac{b_{i} - a_{i}^{\\top} x_{k}}{\\|a_{i}\\|^{2}} a_{i},\n$$\nwhere at iteration $k$, the row index $i \\in \\{1, 2\\}$ is selected uniformly at random. Let $e_{k} = x_{k} - x^{\\star}$ denote the error vector.\n\nStarting from fundamental definitions of orthogonal projections and their properties (symmetry and idempotence), derive a bound on the conditional expectation $\\mathbb{E}\\left[\\|e_{k+1}\\|^{2} \\mid e_{k}\\right]$ in terms of $\\omega$, $\\mu$, and $\\|e_{k}\\|^{2}$, by explicitly relating the average projected energy $\\frac{1}{2}\\sum_{i=1}^{2}\\|P_{i} e_{k}\\|^{2}$ to the eigenvalues of the operator $\\sum_{i=1}^{2} P_{i}$, where $P_{i}$ is the orthogonal projector onto $\\text{span}(a_{i})$. Use the coherence parameter $\\mu$ to bound this operator and obtain a guaranteed one-step contraction bound on the expected error.\n\nThen, using this coherence-based bound, choose the relaxation parameter $\\omega \\in [0, 2]$ that optimizes the guaranteed expected convergence (i.e., minimizes the upper bound on $\\mathbb{E}\\left[\\|e_{k+1}\\|^{2} \\mid e_{k}\\right]$). Provide your final choice of $\\omega$ as a single exact value. No rounding is required.",
            "solution": "The error vector is $e_{k} = x_{k} - x^{\\star}$. Since $a_i^\\top x^\\star = b_i$ and $\\|a_i\\|=1$, the Kaczmarz update rule for the error vector is:\n$$\ne_{k+1} = e_k - \\omega (a_i^\\top e_k) a_i\n$$\nThe term $(a_i^\\top e_k) a_i$ is the orthogonal projection of $e_k$ onto the span of $a_i$. Let $P_i = a_i a_i^\\top$ be the projection operator. The error update becomes:\n$$\ne_{k+1} = (I - \\omega P_i) e_k\n$$\nWe compute the squared norm of the error. Since projectors are symmetric ($P_i^\\top = P_i$) and idempotent ($P_i^2 = P_i$):\n\\begin{align*}\n\\|e_{k+1}\\|^2 = \\|(I - \\omega P_i) e_k\\|^2 \\\\\n= \\langle (I - \\omega P_i) e_k, (I - \\omega P_i) e_k \\rangle \\\\\n= \\langle e_k, (I - \\omega P_i)^\\top(I - \\omega P_i) e_k \\rangle \\\\\n= \\langle e_k, (I - 2\\omega P_i + \\omega^2 P_i^2) e_k \\rangle \\\\\n= \\langle e_k, (I - (2\\omega - \\omega^2) P_i) e_k \\rangle \\\\\n= \\|e_k\\|^2 - (2\\omega - \\omega^2) \\langle e_k, P_i e_k \\rangle \\\\\n= \\|e_k\\|^2 - (2\\omega - \\omega^2) \\|P_i e_k\\|^2\n\\end{align*}\nNow, we take the conditional expectation over the random choice of $i \\in \\{1, 2\\}$, which is uniform with probability $1/2$:\n\\begin{align*}\n\\mathbb{E}\\left[\\|e_{k+1}\\|^2 \\mid e_k\\right] = \\frac{1}{2} \\sum_{i=1}^{2} \\left( \\|e_k\\|^2 - (2\\omega - \\omega^2) \\|P_i e_k\\|^2 \\right) \\\\\n= \\|e_k\\|^2 - \\frac{1}{2}(2\\omega - \\omega^2) \\sum_{i=1}^{2} \\|P_i e_k\\|^2\n\\end{align*}\nThe sum of squared projected norms can be related to the operator $S = \\sum_{i=1}^2 P_i$:\n$$ \\sum_{i=1}^{2} \\|P_i e_k\\|^2 = \\sum_{i=1}^{2} \\langle e_k, P_i e_k \\rangle = \\left\\langle e_k, \\left(\\sum_{i=1}^{2} P_i\\right) e_k \\right\\rangle = \\langle e_k, S e_k \\rangle $$\nTo get a guaranteed contraction bound, we use the Rayleigh-Ritz theorem, which states that $\\langle e_k, S e_k \\rangle \\ge \\lambda_{\\min}(S) \\|e_k\\|^2$, where $\\lambda_{\\min}(S)$ is the smallest eigenvalue of $S$. Since $2\\omega - \\omega^2 \\ge 0$ for $\\omega \\in [0,2]$, we have:\n$$ \\mathbb{E}\\left[\\|e_{k+1}\\|^2 \\mid e_k\\right] \\le \\|e_k\\|^2 - \\frac{1}{2}(2\\omega - \\omega^2) \\lambda_{\\min}(S) \\|e_k\\|^2 = \\left( 1 - \\frac{1}{2}(2\\omega - \\omega^2) \\lambda_{\\min}(S) \\right) \\|e_k\\|^2 $$\nThe eigenvalues of $S = a_1 a_1^\\top + a_2 a_2^\\top$ are found from its trace and determinant. The Gram matrix of the column vectors $(a_1, a_2)$ is $A^\\top A = \\begin{pmatrix} 1  \\mu \\\\ \\mu  1 \\end{pmatrix}$. The matrix $S = AA^\\top$ has the same non-zero eigenvalues as $A^\\top A$.\nThe eigenvalues $\\lambda$ of the Gram matrix solve $\\det(A^\\top A - \\lambda I) = (1-\\lambda)^2 - \\mu^2 = 0$, so $1-\\lambda = \\pm\\mu$, which gives $\\lambda = 1 \\mp \\mu$.\nThe smallest eigenvalue is $\\lambda_{\\min}(S) = 1-\\mu$.\n\nThe expected contraction factor is bounded by $C(\\omega) = 1 - \\frac{1}{2}(2\\omega - \\omega^2)(1-\\mu)$. To optimize the guaranteed convergence rate, we must minimize this factor by maximizing the subtracted term. Since $1-\\mu > 0$, this is equivalent to maximizing the function $f(\\omega) = 2\\omega - \\omega^2$ for $\\omega \\in [0, 2]$. This is a downward-opening parabola with its vertex at $\\omega = -2/(2(-1)) = 1$. The maximum value on the interval $[0,2]$ occurs at this vertex.\nTherefore, the optimal choice for the relaxation parameter $\\omega$ that minimizes the upper bound on the expected error is $\\omega=1$.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Real-world inverse problems often include prior knowledge, such as non-negativity, which is enforced by projecting iterates onto a convex constraint set. This advanced exercise explores the subtle interaction between the Kaczmarz update and such projections, revealing a potential pitfall where the algorithm can become trapped in a cycle instead of converging. By constructing a counterexample and then deriving a condition on the relaxation parameter $\\omega$ to prevent this cycling, you will develop a more sophisticated understanding of how to design robust iterative methods for constrained problems .",
            "id": "3393618",
            "problem": "Consider a two-dimensional linearized tomography toy model for Algebraic Reconstruction Technique (ART), where the reconstruction vector is $x \\in \\mathbb{R}^{2}$. The sensing rays produce two affine hyperplanes $H_{1}$ and $H_{2}$ defined by $a^{\\top} x = b_{i}$, with $a = (1, 1)^{\\top}$, $b_{1} = 2 + d$, and $b_{2} = -d$, for a fixed parameter $d > 0$. The admissible prior constraint set is the axis-aligned box $\\mathcal{C} = [0,1]^{2}$. The ART update alternates between projecting onto $H_{i}$ using the relaxed Kaczmarz step and then enforcing the constraint by projecting onto $\\mathcal{C}$. Specifically, for index $i \\in \\{1, 2\\}$, the Kaczmarz update with relaxation parameter $\\omega \\in (0,2)$ is\n$$\nx^{+} = x + \\omega \\frac{b_{i} - a^{\\top} x}{\\|a\\|^{2}} a,\n$$\nand the constraint enforcement is $x \\leftarrow P_{\\mathcal{C}}(x)$, where $P_{\\mathcal{C}}$ denotes the Euclidean projector onto $\\mathcal{C}$.\n\nStart the iteration at $x_{0} = (1,1)^{\\top}$ and alternate indices cyclically $(i=2)$ then $(i=1)$, each time applying the relaxed Kaczmarz step followed by projection onto $\\mathcal{C}$. Your tasks are:\n\n1. Using only the definitions above (orthogonal projection onto an affine hyperplane, Kaczmarz update with relaxation, and Euclidean projection onto a closed convex set), construct a counterexample for the choice $\\omega = 1$ showing that the sequence cycles between distinct points when $d > 0$.\n\n2. Derive, from first principles, a sharp upper bound $\\omega_{\\max}$ as a function of $d$ such that for any $\\omega \\in (0,\\omega_{\\max}]$ the two-step composition \"project onto $H_{2}$, project onto $\\mathcal{C}$, then project onto $H_{1}$, project onto $\\mathcal{C}$\" starting from $x_{0}$ produces iterates that remain in $\\mathcal{C}$ without activating the clipping at the boundary, thereby preventing cycling and yielding a linear contraction along the symmetry axis $x_{1} = x_{2}$.\n\nSet $d = \\sqrt{7}$ for numerical specificity. Provide the exact closed-form expression for $\\omega_{\\max}$ in terms of $d$ and evaluate it at $d = \\sqrt{7}$. Express your final answer as a single exact expression. No rounding is required, and no units are involved.",
            "solution": "The problem is analyzed in two parts. First, we demonstrate the cycling behavior for the standard Kaczmarz method ($\\omega=1$). Second, we derive the sharp upper bound on the relaxation parameter $\\omega$ that prevents this cycling by avoiding the activation of the boundary projection.\n\nThe problem defines two parallel affine hyperplanes $H_1$ and $H_2$ in $\\mathbb{R}^2$:\n$$H_1: x_1 + x_2 = 2+d$$\n$$H_2: x_1 + x_2 = -d$$\nwhere $x = (x_1, x_2)^{\\top}$. These equations can be written in the form $a^{\\top}x = b_i$ with $a = (1,1)^{\\top}$, $b_1 = 2+d$, and $b_2 = -d$. The squared norm of $a$ is $\\|a\\|^2 = 1^2 + 1^2 = 2$.\n\nThe ART iteration involves two operators:\n1.  The relaxed Kaczmarz step for hyperplane $H_i$:\n    $$K_i(x) = x + \\omega \\frac{b_i - a^{\\top}x}{\\|a\\|^2}a$$\n2.  The Euclidean projection onto the constraint set $\\mathcal{C}=[0,1]^2$:\n    $$P_{\\mathcal{C}}(y) = (\\max(0, \\min(1, y_1)), \\max(0, \\min(1, y_2)))^{\\top}$$\n\nThe full operator for a single step is $T_i(x) = P_{\\mathcal{C}}(K_i(x))$. The sequence of iterates is defined by $x_{k+1} = T_{i_k}(x_k)$ with initial point $x_0 = (1,1)^{\\top}$ and indices cycling as $i_k \\in \\{2, 1, 2, 1, \\dots\\}$.\n\n**Part 1: Counterexample for $\\omega=1$**\n\nFor $\\omega=1$, the Kaczmarz step becomes the orthogonal projection onto the hyperplane, $P_{H_i}(x)$. We start with $x_0 = (1,1)^{\\top}$.\n\n**Iteration 1 (k=0, i=2):**\nFirst, we apply the Kaczmarz step for $H_2$.\n$$x_{0.5} = K_2(x_0) = x_0 + \\frac{b_2 - a^{\\top}x_0}{\\|a\\|^2}a$$\nWith $a^{\\top}x_0 = 1+1=2$, $b_2=-d$, and $\\|a\\|^2=2$:\n$$x_{0.5} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} + \\frac{-d - 2}{2} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{d+2}{2} \\\\ 1 - \\frac{d+2}{2} \\end{pmatrix} = \\begin{pmatrix} -\\frac{d}{2} \\\\ -\\frac{d}{2} \\end{pmatrix}$$\nNext, we project onto $\\mathcal{C}=[0,1]^2$. Since $d0$, we have $-d/2  0$.\n$$x_1 = T_2(x_0) = P_{\\mathcal{C}}(x_{0.5}) = P_{\\mathcal{C}}\\left(\\begin{pmatrix} -d/2 \\\\ -d/2 \\end{pmatrix}\\right) = \\begin{pmatrix} \\max(0, \\min(1, -d/2)) \\\\ \\max(0, \\min(1, -d/2)) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\n\n**Iteration 2 (k=1, i=1):**\nNow we apply the operators starting from $x_1=(0,0)^{\\top}$. The Kaczmarz step is for $H_1$.\n$$x_{1.5} = K_1(x_1) = x_1 + \\frac{b_1 - a^{\\top}x_1}{\\|a\\|^2}a$$\nWith $a^{\\top}x_1 = 0+0=0$ and $b_1=2+d$:\n$$x_{1.5} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\frac{2+d - 0}{2} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 + \\frac{d}{2} \\\\ 1 + \\frac{d}{2} \\end{pmatrix}$$\nNext, we project onto $\\mathcal{C}$. Since $d0$, we have $1+d/2  1$.\n$$x_2 = T_1(x_1) = P_{\\mathcal{C}}(x_{1.5}) = P_{\\mathcal{C}}\\left(\\begin{pmatrix} 1+d/2 \\\\ 1+d/2 \\end{pmatrix}\\right) = \\begin{pmatrix} \\max(0, \\min(1, 1+d/2)) \\\\ \\max(0, \\min(1, 1+d/2)) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\nWe find that $x_2=x_0$. Continuing the process will yield $x_3=x_1=(0,0)^{\\top}$, $x_4=x_2=(1,1)^{\\top}$, and so on. The sequence cycles between the two distinct points $(1,1)^{\\top}$ and $(0,0)^{\\top}$. This provides the required counterexample.\n\n**Part 2: Derivation of $\\omega_{\\max}(d)$**\n\nWe seek the sharp upper bound $\\omega_{\\max}$ on $\\omega$ such that the sequence remains in $\\mathcal{C}$ without activating the clipping projection. This means that at every step, the output of the Kaczmarz operator $K_i$ must already lie within $\\mathcal{C}$. Due to symmetry, all iterates will lie on the line $x_1=x_2$. Let $x_k = (\\xi_k, \\xi_k)^{\\top}$.\n\nThe \"no clipping\" constraint means that for any iterate $x_k$ where $\\xi_k \\in [0,1]$, all subsequent Kaczmarz steps must produce points that remain in $\\mathcal{C}$. The most stringent test is on the very first step, starting from the boundary point $x_0 = (1,1)^\\top$ (so $\\xi_0 = 1$).\n\nThe first Kaczmarz step is for $H_2$:\n$$x_{0.5} = K_2(x_0) = x_0 + \\omega \\frac{b_2 - a^{\\top}x_0}{\\|a\\|^2}a = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} + \\omega \\frac{-d - 2}{2} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\nThe components of this point are $\\xi_{0.5} = 1 - \\omega \\frac{d+2}{2}$.\nFor this point to be in $\\mathcal{C}$, we need $0 \\le \\xi_{0.5} \\le 1$.\nThe upper bound is always satisfied for $\\omega \\in (0,2)$ and $d>0$:\n$$1 - \\omega \\frac{d+2}{2}  1$$\nThe critical constraint is the lower bound:\n$$0 \\le 1 - \\omega \\frac{d+2}{2}$$\n$$ \\omega \\frac{d+2}{2} \\le 1 $$\n$$ \\omega \\le \\frac{2}{d+2} $$\nThis condition is necessary. If it holds, we can show that all subsequent iterates also remain in the box without clipping. The sequence of scalar components $\\xi_k$ converges to a fixed point $\\xi^* = \\frac{1+\\omega d/2}{2-\\omega}$. The condition $\\omega \\le \\frac{2}{d+2}$ ensures that $\\xi^* \\in [0,1]$ and that the sequence of iterates $\\xi_k$ starting from $\\xi_0=1$ is monotonic and remains within $[0,1]$. Furthermore, it ensures all intermediate points also remain within the interval.\n\nThe bound is sharp because if we choose $\\omega = \\frac{2}{d+2} + \\epsilon$ for any small $\\epsilon > 0$, the first step will yield a point with component $\\xi_{0.5} = 1 - (\\frac{2}{d+2} + \\epsilon)\\frac{d+2}{2} = 1 - (1 + \\epsilon \\frac{d+2}{2})  0$. This point is outside $\\mathcal{C}$ and would activate the clipping projection onto the origin $(0,0)$, leading to the cycling behavior shown in Part 1.\n\nTherefore, the sharp upper bound is:\n$$\\omega_{\\max} = \\frac{2}{d+2}$$\n\nFinally, we evaluate this expression for $d=\\sqrt{7}$:\n$$\\omega_{\\max} = \\frac{2}{2+\\sqrt{7}}$$\nTo rationalize the denominator, we multiply the numerator and denominator by the conjugate $(2-\\sqrt{7})$:\n$$\\omega_{\\max} = \\frac{2(2-\\sqrt{7})}{(2+\\sqrt{7})(2-\\sqrt{7})} = \\frac{2(2-\\sqrt{7})}{4-7} = \\frac{2(2-\\sqrt{7})}{-3} = \\frac{2(\\sqrt{7}-2)}{3}$$",
            "answer": "$$\\boxed{\\frac{2(\\sqrt{7}-2)}{3}}$$"
        }
    ]
}