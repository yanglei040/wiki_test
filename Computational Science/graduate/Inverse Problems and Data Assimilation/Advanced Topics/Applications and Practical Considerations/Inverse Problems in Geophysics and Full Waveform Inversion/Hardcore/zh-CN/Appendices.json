{
    "hands_on_practices": [
        {
            "introduction": "本练习将通过探索线性反演理论的核心原理，为后续学习奠定基础。我们将使用奇异值分解 ($SVD$) 这一强大的分析工具，来理解贝叶斯推断中高斯先验的使用如何等同于吉洪诺夫 (Tikhonov) 正则化。这项练习 () 对于建立模型分辨率与后验不确定性之间基本权衡的直觉至关重要，这些概念是解释任何地球物理反演结果的核心。",
            "id": "3392079",
            "problem": "考虑地震成像中关于背景模型的一个线性化全波形反演 (FWI) 步骤，其中数据残差建模为 $d = G \\, \\delta m + \\varepsilon$。这里，$G$ 是在背景模型处计算的线性化 Fréchet 导数（雅可比矩阵），$\\delta m$ 是模型扰动，$\\varepsilon$ 是附加观测噪声。假设 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{d}^{2} I)$ 的高斯似然和关于 $\\delta m$ 的独立高斯先验 $\\delta m \\sim \\mathcal{N}(0, \\sigma_{m}^{2} I)$。$\\delta m$ 的后验分布是高斯分布。在这种线性高斯设定下，模型分辨率算子量化了真实模型的各分量如何映射到 $\\delta m$ 的后验均值估计量中。\n\n仅使用这些假设，并从第一性原理（贝叶斯线性高斯推断和 $G$ 的奇异值分解 (SVD)）出发，完成以下任务：\n\n1) 在与 $G$ 的右奇异向量对齐的基中，推导后验协方差算子和模型分辨率算子。设奇异值分解为 $G = U \\Sigma V^{\\top}$，其中 $U$ 和 $V$ 是正交矩阵，$\\Sigma$ 是具有非负元素 $\\{\\sigma_{i}\\}$ 的对角矩阵。引入标量 $\\lambda^{2} = \\sigma_{d}^{2} / \\sigma_{m}^{2}$，并用 $\\{\\sigma_{i}\\}$ 和 $\\lambda$ 表示模型分辨率算子的特征值和沿右奇异向量方向的后验方差。\n\n2) 解释增加先验精度（等效于减小 $\\sigma_{m}^{2}$，从而在固定的 $\\sigma_{d}^{2}$ 下增加 $\\lambda^{2}$）如何影响沿每个奇异方向的后验方差和模型分辨率特征值。\n\n3) 现在，特化到一个有限维情况，其中 $G$ 的秩为 $r = 4$，奇异值为 $\\{\\sigma_{1}, \\sigma_{2}, \\sigma_{3}, \\sigma_{4}\\} = \\{20, 5, 1, 0.2\\}$。设 $\\sigma_{d} = 0.5$ 和 $\\sigma_{m} = 2$，并取模型维度等于秩，因此没有零空间贡献。计算模型分辨率算子的迹。您的最终答案必须是一个无量纲的实数，并四舍五入到四位有效数字。",
            "solution": "首先验证问题，确认其有效、适定且具有科学依据。它代表了一个标准的线性高斯贝叶斯反演问题。我们开始求解。\n\n问题要求从第一性原理出发，对一个线性化贝叶斯反演问题进行三部分分析。连接数据残差 $d$ 和模型扰动 $\\delta m$ 的模型由 $d = G \\delta m + \\varepsilon$ 给出。\n\n似然函数基于高斯噪声的假设 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{d}^{2} I)$，这意味着给定模型 $\\delta m$ 时数据 $d$ 的概率密度函数 (PDF) 为：\n$$p(d|\\delta m) \\propto \\exp\\left(-\\frac{1}{2\\sigma_{d}^{2}} \\|d - G\\delta m\\|^2\\right)$$\n模型扰动的先验也是高斯的，$\\delta m \\sim \\mathcal{N}(0, \\sigma_{m}^{2} I)$，其概率密度函数为：\n$$p(\\delta m) \\propto \\exp\\left(-\\frac{1}{2\\sigma_{m}^{2}} \\|\\delta m\\|^2\\right)$$\n\n根据贝叶斯定理，后验概率密度函数 $p(\\delta m|d)$ 与似然和先验的乘积成正比：\n$$p(\\delta m|d) \\propto p(d|\\delta m) \\, p(\\delta m)$$\n$$p(\\delta m|d) \\propto \\exp\\left(-\\frac{1}{2\\sigma_{d}^{2}} \\|d - G\\delta m\\|^2\\right) \\exp\\left(-\\frac{1}{2\\sigma_{m}^{2}} \\|\\delta m\\|^2\\right)$$\n合并指数，我们得到：\n$$p(\\delta m|d) \\propto \\exp\\left\\{ -\\frac{1}{2} \\left( \\frac{1}{\\sigma_{d}^{2}} \\|d - G\\delta m\\|^2 + \\frac{1}{\\sigma_{m}^{2}} \\|\\delta m\\|^2 \\right) \\right\\}$$\n这是 $\\delta m$ 的多元高斯分布的概率密度函数。对于均值为 $\\mu$、协方差为 $\\Sigma_{cov}$ 的向量 $x$，其通用多元高斯概率密度函数与 $\\exp\\left(-\\frac{1}{2}(x - \\mu)^{\\top} \\Sigma_{cov}^{-1} (x - \\mu)\\right)$ 成正比。展开我们指数中的二次型，可以确定后验协方差 $C_{\\text{post}}$ 和后验均值 $\\delta m_{\\text{post}}$。指数中关于 $\\delta m$ 的二次型部分是：\n$$\\frac{1}{\\sigma_{d}^{2}}(G\\delta m)^{\\top}(G\\delta m) + \\frac{1}{\\sigma_{m}^{2}} \\delta m^{\\top}\\delta m = \\delta m^{\\top} \\left( \\frac{1}{\\sigma_{d}^{2}}G^{\\top}G + \\frac{1}{\\sigma_{m}^{2}}I \\right) \\delta m$$\n由此，我们确定后验协方差矩阵的逆：\n$$C_{\\text{post}}^{-1} = \\frac{1}{\\sigma_{d}^{2}}G^{\\top}G + \\frac{1}{\\sigma_{m}^{2}}I = \\frac{1}{\\sigma_{d}^{2}}\\left(G^{\\top}G + \\frac{\\sigma_{d}^{2}}{\\sigma_{m}^{2}}I\\right)$$\n使用定义 $\\lambda^{2} = \\sigma_{d}^{2} / \\sigma_{m}^{2}$，我们有：\n$$C_{\\text{post}}^{-1} = \\frac{1}{\\sigma_{d}^{2}}(G^{\\top}G + \\lambda^2 I)$$\n因此，后验协方差算子为：\n$$C_{\\text{post}} = \\sigma_{d}^{2}(G^{\\top}G + \\lambda^2 I)^{-1}$$\n\n**第1部分：SVD基中的后验协方差和模型分辨率算子**\n\n我们引入 $G$ 的奇异值分解 (SVD)：$G = U \\Sigma V^{\\top}$，其中 $U$ 和 $V$ 是正交矩阵，$\\Sigma$ 是奇异值 $\\{\\sigma_i\\}$ 构成的对角矩阵。我们有 $G^{\\top}G = (V \\Sigma^{\\top} U^{\\top})(U \\Sigma V^{\\top}) = V \\Sigma^{\\top}\\Sigma V^{\\top} = V \\Sigma^2 V^{\\top}$。\n\n将此代入 $C_{\\text{post}}$ 的表达式中：\n$$C_{\\text{post}} = \\sigma_{d}^{2}(V \\Sigma^2 V^{\\top} + \\lambda^2 V V^{\\top})^{-1} = \\sigma_{d}^{2}(V(\\Sigma^2 + \\lambda^2 I)V^{\\top})^{-1}$$\n使用属性 $(ABC)^{-1} = C^{-1}B^{-1}A^{-1}$ 和 $V^{-1}=V^{\\top}$，我们得到：\n$$C_{\\text{post}} = \\sigma_{d}^{2}V(\\Sigma^2 + \\lambda^2 I)^{-1}V^{\\top}$$\n此表达式表明，后验协方差算子在 $G$ 的右奇异向量 $\\{v_i\\}$ 构成的基中是对角的。$C_{\\text{post}}$ 的特征值代表了沿这些主方向的后验方差，它们是矩阵 $\\sigma_{d}^{2}(\\Sigma^2 + \\lambda^2 I)^{-1}$ 的对角线元素。沿第 $i$ 个右奇异向量 $v_i$ 方向的后验方差是：\n$$ \\text{Var}(\\delta m_i) = \\frac{\\sigma_{d}^{2}}{\\sigma_i^2 + \\lambda^2} $$\n\n模型分辨率算子 $R$ 将真实模型扰动 $\\delta m_{\\text{true}}$ 映射到后验均值估计 $\\delta m_{\\text{post}}$。后验均值是使负对数后验最小化的 $\\delta m$ 值，这给出了标准的Tikhonov正则化解：$\\delta m_{\\text{post}} = (G^{\\top}G + \\lambda^2 I)^{-1}G^{\\top}d$。为了定义 $R$，我们考虑估计量如何作用于真实模型，即代入 $d=G \\delta m_{\\text{true}}$：\n$$\\delta m_{\\text{post}} = (G^{\\top}G + \\lambda^2 I)^{-1}G^{\\top}G \\delta m_{\\text{true}}$$\n因此，模型分辨率算子是 $R = (G^{\\top}G + \\lambda^2 I)^{-1}G^{\\top}G$。\n将SVD代入此表达式：\n$$R = (V \\Sigma^2 V^{\\top} + \\lambda^2 I)^{-1}(V \\Sigma^2 V^{\\top}) = (V(\\Sigma^2 + \\lambda^2 I)V^{\\top})^{-1}(V \\Sigma^2 V^{\\top})$$\n$$R = V(\\Sigma^2 + \\lambda^2 I)^{-1}V^{\\top}V \\Sigma^2 V^{\\top} = V \\left[ (\\Sigma^2 + \\lambda^2 I)^{-1} \\Sigma^2 \\right] V^{\\top}$$\n这表明 $R$ 在右奇异向量 $\\{v_i\\}$ 构成的基中也是对角的。模型分辨率算子 $\\{\\mu_i\\}$ 的特征值是矩阵 $(\\Sigma^2 + \\lambda^2 I)^{-1}\\Sigma^2$ 的对角线元素。第 $i$ 个特征值是：\n$$ \\mu_i = \\frac{\\sigma_i^2}{\\sigma_i^2 + \\lambda^2} $$\n\n**第2部分：增加先验精度的解释**\n\n增加先验精度意味着减小先验方差 $\\sigma_m^2$。对于固定的数据噪声方差 $\\sigma_d^2$，这会导致正则化参数 $\\lambda^2 = \\sigma_d^2 / \\sigma_m^2$ 增加。我们分析 $\\lambda^2 \\to \\infty$ 时的影响。\n\n对于沿方向 $v_i$ 的后验方差：\n$$ \\lim_{\\lambda^2 \\to \\infty} \\frac{\\sigma_{d}^{2}}{\\sigma_i^2 + \\lambda^2} = 0 $$\n一个更强的先验（更小的 $\\sigma_m^2$）会更强力地将后验分布拉向先验均值（即0），从而将后验不确定性（方差）减小到零。解变得由先验主导，而与数据无关。\n\n对于模型分辨率特征值：\n$$ \\lim_{\\lambda^2 \\to \\infty} \\mu_i = \\lim_{\\lambda^2 \\to \\infty} \\frac{\\sigma_i^2}{\\sigma_i^2 + \\lambda^2} = 0 $$\n分辨率特征值，通常称为滤波因子，量化了真实模型沿方向 $v_i$ 的分量在解中被恢复得有多好。接近 $1$ 的 $\\mu_i$ 值表示分辨率好，而接近 $0$ 的值表示分辨率差。随着先验精度的增加，$\\lambda^2$ 增加，所有分辨率特征值都趋于 $0$。这意味着估计的模型扰动 $\\delta m_{\\text{post}}$ 对真实模型扰动 $\\delta m_{\\text{true}}$ 变得不敏感，而是被收缩到先验均值 $0$。高正则化牺牲分辨率以减小方差。\n\n**第3部分：模型分辨率算子迹的计算**\n\n矩阵的迹是其特征值之和。因此，模型分辨率算子的迹 $\\text{Tr}(R)$ 是其特征值 $\\mu_i$ 的和：\n$$\\text{Tr}(R) = \\sum_{i} \\mu_i = \\sum_{i} \\frac{\\sigma_i^2}{\\sigma_i^2 + \\lambda^2}$$\n给定以下值：\n奇异值：$\\{\\sigma_1, \\sigma_2, \\sigma_3, \\sigma_4\\} = \\{20, 5, 1, 0.2\\}$\n数据标准差：$\\sigma_d = 0.5$\n先验标准差：$\\sigma_m = 2$\n模型维度等于秩，$r=4$，所以求和是针对这4个模式。\n\n首先，我们计算 $\\lambda^2$：\n$$\\lambda^2 = \\frac{\\sigma_d^2}{\\sigma_m^2} = \\frac{(0.5)^2}{2^2} = \\frac{0.25}{4} = 0.0625$$\n接下来，我们计算奇异值的平方：\n$\\sigma_1^2 = 20^2 = 400$\n$\\sigma_2^2 = 5^2 = 25$\n$\\sigma_3^2 = 1^2 = 1$\n$\\sigma_4^2 = 0.2^2 = 0.04$\n\n现在我们计算 $R$ 的特征值之和：\n$$\\text{Tr}(R) = \\frac{400}{400 + 0.0625} + \\frac{25}{25 + 0.0625} + \\frac{1}{1 + 0.0625} + \\frac{0.04}{0.04 + 0.0625}$$\n$$\\text{Tr}(R) = \\frac{400}{400.0625} + \\frac{25}{25.0625} + \\frac{1}{1.0625} + \\frac{0.04}{0.1025}$$\n$$\\text{Tr}(R) \\approx 0.99984377 + 0.99750623 + 0.94117647 + 0.39024390$$\n$$\\text{Tr}(R) \\approx 3.32877037$$\n四舍五入到四位有效数字，我们得到 $3.329$。",
            "answer": "$$\\boxed{3.329}$$"
        },
        {
            "introduction": "虽然线性理论提供了坚实的基础，但大多数现实世界中的地球物理问题，包括全波形反演 ($FWI$)，都是高度非线性的。本练习 () 使用一个简化但富有洞察力的解析模型，来揭示 $FWI$ 中最重大的挑战之一：周波跳跃 (cycle skipping)。通过推导目标函数的结构，您将看到局部极小值是如何产生的，如果初始模型不够准确，这些局部极小值会“捕获”基于梯度的优化算法，导致物理上不正确的结果。",
            "id": "3392074",
            "problem": "在全波形反演（Full Waveform Inversion, FWI）的背景下，考虑一个理想化的一维地震道模型，其中预测位移信号为 $u(t)=\\sin(\\omega t)$，观测位移信号为 $v(t)=\\sin(\\omega(t-\\tau))$，角频率 $\\omega0$，时间偏移 $\\tau \\in \\mathbb{R}$ 未知。假设采集时间窗口恰好为 $T=N \\cdot \\frac{2\\pi}{\\omega}$，其中 $N \\in \\mathbb{N}$，并在区间 $t \\in [0,T]$ 上进行计算。FWI 的 $L_{2}$ 残差定义为数据差的 $L_{2}$ 范数的平方，\n$$\nJ(\\tau)=\\frac{1}{2}\\int_{0}^{T}\\big(u(t)-v(t)\\big)^{2}\\,\\mathrm{d}t.\n$$\n从 $L_{2}$ 范数的定义和基本三角恒等式出发，推导 $J(\\tau)$ 作为 $\\tau$、$\\omega$ 和 $T$ 的函数的闭式表达式。然后，分析 $J(\\tau)$ 关于 $\\tau$ 的驻点的位置和性质（局部最小值与局部最大值），并解释这些如何导致 FWI 中的周波跳跃（cycle skipping）。\n\n所有角度均以弧度表示。无需进行数值计算或四舍五入。你的最终答案必须是 $J(\\tau)$ 关于 $\\tau$、$\\omega$ 和 $T$ 的单个闭式解析表达式。",
            "solution": "该问题陈述被认为是有效的，因为它具有科学依据、适定且客观。它提出了一个用于分析全波形反演（FWI）中目标函数的理想化但标准的模型，并且没有指令中列出的导致无效的缺陷。\n\n我们首先陈述给定的量。\n预测位移为 $u(t) = \\sin(\\omega t)$。\n观测位移为 $v(t) = \\sin(\\omega(t - \\tau))$。\n采集时间区间为 $[0, T]$，其中 $T = N \\cdot \\frac{2\\pi}{\\omega}$，对于某个整数 $N \\in \\mathbb{N}$。\n$L_2$ 残差函数由下式给出\n$$\nJ(\\tau) = \\frac{1}{2} \\int_{0}^{T} (u(t) - v(t))^2 \\, \\mathrm{d}t\n$$\n代入 $u(t)$ 和 $v(t)$ 的表达式，我们得到\n$$\nJ(\\tau) = \\frac{1}{2} \\int_{0}^{T} (\\sin(\\omega t) - \\sin(\\omega(t - \\tau)))^2 \\, \\mathrm{d}t\n$$\n为了推导 $J(\\tau)$ 的闭式表达式，我们首先展开被积函数：\n$$\n(\\sin(\\omega t) - \\sin(\\omega(t - \\tau)))^2 = \\sin^2(\\omega t) - 2\\sin(\\omega t)\\sin(\\omega(t - \\tau)) + \\sin^2(\\omega(t - \\tau))\n$$\n现在我们可以将 $J(\\tau)$ 写成三个积分的和：\n$$\nJ(\\tau) = \\frac{1}{2} \\left[ \\int_{0}^{T} \\sin^2(\\omega t) \\, \\mathrm{d}t - 2\\int_{0}^{T} \\sin(\\omega t)\\sin(\\omega(t - \\tau)) \\, \\mathrm{d}t + \\int_{0}^{T} \\sin^2(\\omega(t - \\tau)) \\, \\mathrm{d}t \\right]\n$$\n让我们分别计算每个积分。\n\n对于第一个积分，我们使用恒等式 $\\sin^2(x) = \\frac{1}{2}(1 - \\cos(2x))$：\n$$\n\\int_{0}^{T} \\sin^2(\\omega t) \\, \\mathrm{d}t = \\int_{0}^{T} \\frac{1}{2}(1 - \\cos(2\\omega t)) \\, \\mathrm{d}t = \\frac{1}{2} \\left[ t - \\frac{\\sin(2\\omega t)}{2\\omega} \\right]_{0}^{T}\n$$\n在积分上下限处求值，我们得到：\n$$\n\\frac{1}{2} \\left( T - \\frac{\\sin(2\\omega T)}{2\\omega} - (0 - 0) \\right) = \\frac{T}{2} - \\frac{\\sin(2\\omega T)}{4\\omega}\n$$\n使用给定条件 $T = N \\frac{2\\pi}{\\omega}$，我们有 $2\\omega T = 2\\omega (N \\frac{2\\pi}{\\omega}) = 4\\pi N$。由于 $N$ 是一个整数，$\\sin(4\\pi N) = 0$。因此，第一个积分为：\n$$\n\\int_{0}^{T} \\sin^2(\\omega t) \\, \\mathrm{d}t = \\frac{T}{2}\n$$\n第三个积分的计算结果相同。函数 $\\sin^2(\\omega(t-\\tau))$ 只是 $\\sin^2(\\omega t)$ 的一个时移版本，并且由于积分区间长度 $T$ 是信号周期（$P = 2\\pi/\\omega$）的整数倍，所以该周期函数的积分是相同的。形式上，在一个长度等于其周期 $\\pi$ 整数倍的任何区间上对 $\\sin^2(x)$ 进行积分，得到的结果是区间长度乘以该函数的平均值（$1/2$）。$\\sin^2(\\omega t)$ 的周期是 $\\pi/\\omega$，而 $T=2N(\\pi/\\omega)$，所以我们是在 $2N$ 个周期上进行积分。\n$$\n\\int_{0}^{T} \\sin^2(\\omega(t - \\tau)) \\, \\mathrm{d}t = \\frac{T}{2}\n$$\n对于第二个积分，即交叉项，我们使用积化和差三角恒等式 $\\sin(A)\\sin(B) = \\frac{1}{2}(\\cos(A-B) - \\cos(A+B))$：\n$$\n\\int_{0}^{T} \\sin(\\omega t)\\sin(\\omega(t - \\tau)) \\, \\mathrm{d}t = \\int_{0}^{T} \\frac{1}{2}(\\cos(\\omega t - \\omega(t - \\tau)) - \\cos(\\omega t + \\omega(t - \\tau))) \\, \\mathrm{d}t\n$$\n$$\n= \\frac{1}{2} \\int_{0}^{T} (\\cos(\\omega\\tau) - \\cos(2\\omega t - \\omega\\tau)) \\, \\mathrm{d}t\n$$\n由于 $\\cos(\\omega\\tau)$ 相对于 $t$ 是一个常数，我们可以分离积分：\n$$\n= \\frac{1}{2} \\left( \\int_{0}^{T} \\cos(\\omega\\tau) \\, \\mathrm{d}t - \\int_{0}^{T} \\cos(2\\omega t - \\omega\\tau) \\, \\mathrm{d}t \\right)\n$$\n第一部分是 $\\int_{0}^{T} \\cos(\\omega\\tau) \\, \\mathrm{d}t = T\\cos(\\omega\\tau)$。\n对于第二部分，被积函数 $\\cos(2\\omega t - \\omega\\tau)$ 是一个关于 $t$ 的正弦函数，周期为 $P' = 2\\pi/(2\\omega) = \\pi/\\omega$。积分区间是 $T = N(2\\pi/\\omega) = 2N P'$。由于我们是在整数个（$2N$）完整周期上进行积分，所以积分为零。\n$$\n\\int_{0}^{T} \\cos(2\\omega t - \\omega\\tau) \\, \\mathrm{d}t = 0\n$$\n因此，交叉项积分的计算结果为：\n$$\n\\int_{0}^{T} \\sin(\\omega t)\\sin(\\omega(t - \\tau)) \\, \\mathrm{d}t = \\frac{1}{2} (T\\cos(\\omega\\tau) - 0) = \\frac{T}{2}\\cos(\\omega\\tau)\n$$\n现在，我们将这些结果代回 $J(\\tau)$ 的表达式中：\n$$\nJ(\\tau) = \\frac{1}{2} \\left[ \\frac{T}{2} - 2\\left(\\frac{T}{2}\\cos(\\omega\\tau)\\right) + \\frac{T}{2} \\right] = \\frac{1}{2} [T - T\\cos(\\omega\\tau)]\n$$\n这就给出了残差函数的最终闭式表达式：\n$$\nJ(\\tau) = \\frac{T}{2}(1 - \\cos(\\omega\\tau))\n$$\n接下来，我们通过找到 $J(\\tau)$ 关于 $\\tau$ 的导数为零的点来分析其驻点。\n$$\n\\frac{\\mathrm{d}J}{\\mathrm{d}\\tau} = \\frac{\\mathrm{d}}{\\mathrm{d}\\tau} \\left[ \\frac{T}{2}(1 - \\cos(\\omega\\tau)) \\right] = \\frac{T}{2}(-(-\\omega\\sin(\\omega\\tau))) = \\frac{T\\omega}{2}\\sin(\\omega\\tau)\n$$\n将导数设为零，$\\frac{\\mathrm{d}J}{\\mathrm{d}\\tau} = 0$，意味着 $\\sin(\\omega\\tau) = 0$，因为 $T  0$ 且 $\\omega  0$。当 $\\omega\\tau = k\\pi$（对于任意整数 $k \\in \\mathbb{Z}$）时，此条件成立。因此，驻点为 $\\tau_k = \\frac{k\\pi}{\\omega}$。\n\n为了对这些点进行分类，我们使用二阶导数检验。\n$$\n\\frac{\\mathrm{d}^2J}{\\mathrm{d}\\tau^2} = \\frac{\\mathrm{d}}{\\mathrm{d}\\tau} \\left[ \\frac{T\\omega}{2}\\sin(\\omega\\tau) \\right] = \\frac{T\\omega^2}{2}\\cos(\\omega\\tau)\n$$\n我们在驻点 $\\tau_k$ 处计算二阶导数：\n$$\n\\left. \\frac{\\mathrm{d}^2J}{\\mathrm{d}\\tau^2} \\right|_{\\tau=\\tau_k} = \\frac{T\\omega^2}{2}\\cos\\left(\\omega \\frac{k\\pi}{\\omega}\\right) = \\frac{T\\omega^2}{2}\\cos(k\\pi)\n$$\n- 如果 $k$ 是偶数（$k=2m$ 对于 $m \\in \\mathbb{Z}$），则 $\\cos(k\\pi)=1$。二阶导数为 $\\frac{T\\omega^2}{2}  0$，表明这是一个**局部最小值**。这些点出现在 $\\tau = \\frac{2m\\pi}{\\omega}$。这些点对应于等于信号周期 $P = 2\\pi/\\omega$ 整数倍的时间偏移。在这些点上，$u(t) = v(t)$ 且残差 $J(\\tau)=0$，所以它们是全局最小值。\n- 如果 $k$ 是奇数（$k=2m+1$ 对于 $m \\in \\mathbb{Z}$），则 $\\cos(k\\pi)=-1$。二阶导数为 $-\\frac{T\\omega^2}{2}  0$，表明这是一个**局部最大值**。这些点出现在 $\\tau = \\frac{(2m+1)\\pi}{\\omega}$。这些点对应于等于周期半整数倍的时间偏移，此时信号完全反相，残差达到最大。\n\n该分析揭示了 FWI 中**周波跳跃**（cycle skipping）的原因。目标函数 $J(\\tau)$ 是周期性的，并拥有多个局部最小值。在 FWI 中作为标准方法的基于梯度的优化算法，会迭代地沿着残差曲面下降以寻找最小值。如果模型参数 $\\tau$ 的初始猜测值与真实值相差太远，算法将收敛到最近的局部最小值，而不一定是全局最小值（真实解）。\n\n在一般情况下，如果真实时间偏移为 $\\tau_{true}$，则对于模型参数 $\\tau_{model}$ 的残差函数为 $J(\\tau_{model}) \\propto 1 - \\cos(\\omega(\\tau_{model} - \\tau_{true}))$。其最小值位于 $\\tau_{model} - \\tau_{true} = \\frac{2m\\pi}{\\omega}$。局部优化方法只有在初始误差 $|\\tau_{model,0} - \\tau_{true}|$ 小于半个周期，即 $|\\tau_{model,0} - \\tau_{true}|  \\frac{\\pi}{\\omega}$ 的情况下，才会收敛到真实解 $\\tau_{model} = \\tau_{true}$（即 $m=0$）。如果初始误差大于此值，梯度将指向一个“错误”的最小值（其中 $m \\neq 0$），算法就会陷入困境。这就是周波跳跃：反演跳过了一个或多个波的周期（periods），并收敛到一个物理上不正确但仍能产生低残差的模型。",
            "answer": "$$\n\\boxed{\\frac{T}{2}(1 - \\cos(\\omega\\tau))}\n$$"
        },
        {
            "introduction": "本练习将理论与应用相结合，旨在解决在基于高斯-牛顿 (Gauss-Newton) 法的 $FWI$ 算法的每次迭代中出现的大规模线性系统的求解这一实际挑战。我们将实现共轭梯度 ($CG$) 方法，并构建一个基于物理动机的对角预条件子来加速其收敛。这项动手编程练习 () 将展示预处理对计算效率的巨大影响，这是大规模反演项目可行性的一个关键因素。",
            "id": "3392061",
            "problem": "考虑一个一维地下介质的线性化声学散射问题，其中模型参数向量表示为 $m \\in \\mathbb{R}^{n_m}$，观测数据向量表示为 $d \\in \\mathbb{R}^{n_d}$。线性化正演算子（在Born近似下波形图的Fréchet导数）表示为 $J \\in \\mathbb{R}^{n_d \\times n_m}$。我们采用简化的采集方式和物理模型，得到一个灵敏度矩阵 $S \\in \\mathbb{R}^{n_d \\times n_m}$，并设 $J = S$。最小二乘数据残差定义为 $\\frac{1}{2}\\lVert J m - d \\rVert_2^2$，采用单位权重。高斯-牛顿（GN）步长 $\\delta m$ 求解正规方程 $H_{\\text{GN}} \\, \\delta m = -g$，其中 $H_{\\text{GN}} = J^{\\top} J$ 且 $g = J^{\\top}(J m - d)$。我们将考虑 $m = m_0$ 的情况，其中 $m_0$ 是一个初始模型，并定义残差 $r = d - J m_0$。那么，GN步长是以下方程的解：\n$$\nH_{\\text{GN}} \\, \\delta m = J^{\\top} r.\n$$\n我们将使用共轭梯度（CG）法来求解这个对称正定线性系统。为了加速收敛，我们通过偏移-反偏移构建正演算子的近似逆，从而构造一个左预条件子 $P \\approx H_{\\text{GN}}^{-1}$。具体来说，将逆时偏移（RTM）类型的近似正演算子定义为 $N_{\\text{approx}} \\approx J^{\\top} J$。对于模型空间中的每个标准基向量 $e_i$，执行一次反偏移 $y_i = J e_i$，然后进行一次偏移 $z_i = J^{\\top} y_i$。使用标量 $[z_i]_i$（即 $z_i$ 的第 $i$ 个分量）作为 $H_{\\text{GN}}$ 第 $i$ 个对角线元素的近似。构建一个对角预条件子 $P$，其元素为 $P_{ii} = \\frac{1}{[z_i]_i + \\varepsilon}$，其中 $\\varepsilon$ 是一个小的正数，以确保数值稳定性。评估在使用和不使用预处理的情况下，求解 $\\delta m$ 时CG方法的收敛行为。\n\n灵敏度矩阵 $S$ 由一个物理上合理的核函数指定，该核函数模拟了单个震源和多个检波器与每个模型单元之间振幅随距离的衰减。设模型网格位置为 $x_i = i \\Delta x$，其中 $i \\in \\{0, 1, \\dots, n_m - 1\\}$，覆盖长度为 $L$ 的一条线，且 $\\Delta x = \\frac{L}{n_m - 1}$。设震源位置为 $x_s$，检波器位置为 $x_{r_k}$，其中 $k \\in \\{0, 1, \\dots, n_d - 1\\}$，均匀分布在同一条线上。定义\n$$\nS_{k,i} = \\exp\\!\\big(-\\alpha \\lvert x_i - x_s \\rvert\\big) \\, \\exp\\!\\big(-\\alpha \\lvert x_i - x_{r_k} \\rvert\\big),\n$$\n其中 $\\alpha  0$ 控制衰减。这种构造产生一个矩阵 $S$，其列代表了每个模型单元处单位扰动的点扩散函数。数据生成方式为 $d = S m_{\\text{true}}$，不添加噪声，初始模型为 $m_0 = 0$（零向量），因此 $r = d$。\n\n实现CG方法求解 $H_{\\text{GN}} \\, \\delta m = J^{\\top} r$，其中 $J = S$。同时实现非预处理CG和使用通过偏移-反偏移构建的对角预条件子 $P$ 的预处理CG，并通过达到相对残差容差 $10^{-8}$ 所需的迭代次数来衡量收敛性，即 $\\frac{\\lVert b - H_{\\text{GN}} \\delta m \\rVert_2}{\\lVert b \\rVert_2} \\leq 10^{-8}$，其中 $b = J^{\\top} r$。使用最多 $n_m$ 次迭代。\n\n您的程序必须实现以下参数集的测试套件，每个测试套件都会为非预处理和预处理情况产生等于CG迭代次数的整数输出：\n\n- 测试用例1（理想情况）：\n  - $L = 1.0$, $n_m = 60$, $n_d = 30$, $\\alpha = 3.0$, $x_s = 0.0$，\n  - 检波器位置 $x_{r_k}$ 在 $[0, L]$ 上均匀分布，\n  - 真实模型 $m_{\\text{true}}$ 在位置 $0.2 L$、$0.5 L$、$0.8 L$ 处有三个振幅分别为 $1.0$、$-0.8$、$0.6$ 的尖峰，其他地方为零。\n\n- 测试用例2（病态覆盖）：\n  - $L = 1.0$, $n_m = 60$, $n_d = 8$, $\\alpha = 0.5$, $x_s = 0.0$，\n  - 检波器位置 $x_{r_k}$ 在 $[0, L]$ 上均匀分布，\n  - $m_{\\text{true}}$ 与测试用例1中相同。\n\n- 测试用例3（边界情况，单位正演算子）：\n  - $n_m = 60$, $n_d = 60$，\n  - 设置 $S = I$（单位矩阵），\n  - $m_{\\text{true}}$ 与测试用例1中相同，其中 $L = 1.0$ 仅用于定义位置。\n\n此问题中的所有量都是无量纲的；将所有最终结果表示为整数。您的程序应生成一行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。顺序必须是 $[t_1^{\\text{unpre}}, t_1^{\\text{pre}}, t_2^{\\text{unpre}}, t_2^{\\text{pre}}, t_3^{\\text{unpre}}, t_3^{\\text{pre}}]$，其中 $t_j^{\\text{unpre}}$ 和 $t_j^{\\text{pre}}$ 分别表示测试用例 $j$ 在无预处理和有预处理情况下的CG迭代次数。",
            "solution": "该问题要求解一个线性化声学散射问题的高斯-牛顿正规方程，并比较共轭梯度（CG）方法在使用和不使用对角预条件子时的收敛性。\n\n**1. 问题形式化**\n\n核心任务是求解以下线性方程组：\n$$\nH_{\\text{GN}} \\, \\delta m = b\n$$\n其中 $H_{\\text{GN}} = J^{\\top} J$ 是近似Hessian矩阵（或正演算子），$\\delta m \\in \\mathbb{R}^{n_m}$ 是模型更新向量，$b = J^{\\top} r$ 是转置为右端项的梯度向量。正演算子是 $J=S \\in \\mathbb{R}^{n_d \\times n_m}$，初始模型是 $m_0=0$，数据是人工合成生成的 $d = S m_{\\text{true}}$。这导致残差 $r = d - S m_0 = d$。因此，待解系统是：\n$$\n(S^{\\top} S) \\, \\delta m = S^{\\top} S \\, m_{\\text{true}}\n$$\n这是一个形式为 $A x = b$ 的线性系统，其中 $A = S^{\\top} S$，$x = \\delta m$，$b = S^{\\top} S \\, m_{\\text{true}}$。矩阵 $A$ 是对称半正定的。\n\n值得对问题陈述做一个小的修正。它将 $H_{\\text{GN}}$ 称为“对称正定线性系统”。形如 $J^{\\top} J$ 的矩阵仅在 $J$ 具有满列秩（即其列线性无关）时才是正定的。在测试用例1和2中，数据点数量 $n_d$ 小于模型参数数量 $n_m$。因此，大小为 $n_d \\times n_m$ 的矩阵 $S$ 不可能具有满列秩，而 $H_{\\text{GN}} = S^{\\top} S$ 将是奇异的，使其成为半正定而非正定。然而，该系统在计算上仍然是可解的。由于右端项 $b = S^{\\top} S m_{\\text{true}}$ 被构造为在算子 $A = S^{\\top} S$ 的值域内，该系统是相容的。从零向量开始的共轭梯度法保证收敛到唯一的最小 $L_2$ 范数解。\n\n**2. 共轭梯度（CG）法**\n\nCG法是一种用于求解线性方程组 $Ax=b$ 的迭代算法，其中 $A$ 是对称正定的。它可以扩展到半正定系统，只要它们是相容的。从初始猜测 $x_0 = 0$ 开始，算法迭代地优化解。关键步骤如下：\n1. 初始化：$x_0 = 0$, $r_0 = b - A x_0 = b$, $p_0 = r_0$。\n2. 对于 $k = 0, 1, 2, \\dots$：\n   a. 计算步长：$\\alpha_k = \\frac{r_k^{\\top} r_k}{p_k^{\\top} A p_k}$。\n   b. 更新解：$x_{k+1} = x_k + \\alpha_k p_k$。\n   c. 更新残差：$r_{k+1} = r_k - \\alpha_k A p_k$。\n   d. 检查收敛性：如果 $\\frac{\\lVert b - A x_{k+1} \\rVert_2}{\\lVert b \\rVert_2} \\leq \\tau_{\\text{tol}}$，则终止。\n   e. 计算改进因子：$\\beta_k = \\frac{r_{k+1}^{\\top} r_{k+1}}{r_k^{\\top} r_k}$。\n   f. 更新搜索方向：$p_{k+1} = r_{k+1} + \\beta_k p_k$。\n\n收敛所需的迭代次数被记录为性能指标。\n\n**3. 对角预处理**\n\nCG方法的收敛速率取决于矩阵 $A$ 的条件数。预处理是一种技术，用于将线性系统转换为具有更有利谱特性的系统，从而加速收敛。我们求解一个修改后的系统，例如 $P A x = P b$，其中预条件子 $P$ 是 $A^{-1}$ 的一个近似。\n\n问题指定构建一个对角（或Jacobi）预条件子。这涉及用其对角线（我们称之为 $D$）来近似 $A = H_{\\text{GN}}$。预条件子 $P$ 则是该对角线的逆，带有一个小的稳定项 $\\varepsilon  0$。$H_{\\text{GN}} = S^{\\top} S$ 的对角线元素由 $(H_{\\text{GN}})_{ii} = \\sum_{k=0}^{n_d-1} S_{ki}^2$ 给出。问题描述了使用“偏移-反偏移”方法计算这些元素：对于每个模型基向量 $e_i$，先进行“反偏移” $y_i=Se_i$（即 $S$ 的第 $i$ 列），然后进行“偏移” $z_i=S^{\\top}y_i$（即 $S^\\top S$ 的第 $i$ 列），对角线元素即为 $[z_i]_i$。这在计算上等同于计算 $S$ 的每一列的 $L_2$ 范数的平方。\n\n预条件子 $P$ 是一个对角矩阵，其元素为：\n$$\nP_{ii} = \\frac{1}{(H_{\\text{GN}})_{ii} + \\varepsilon} = \\frac{1}{\\sum_{k=0}^{n_d-1} S_{ki}^2 + \\varepsilon}\n$$\n\n**4. 预处理共轭梯度（PCG）法**\n\nPCG算法将预条件子 $P$ 融入CG迭代中。在实践中，这是通过在每一步求解系统 $M z_k = r_k$ 来完成的，其中 $M = P^{-1} \\approx A$。在我们的情况下，$M$ 是 $A$ 的（稳定化的）对角线，所以这个“求解”步骤变成了一个简单的逐元素相除。标准的PCG算法是：\n1. 初始化：$x_0 = 0$, $r_0 = b - A x_0 = b$。\n2. 求解 $M z_0 = r_0$。令 $p_0 = z_0$。\n3. 对于 $k = 0, 1, 2, \\dots$：\n   a. 计算步长：$\\alpha_k = \\frac{r_k^{\\top} z_k}{p_k^{\\top} A p_k}$。\n   b. 更新解：$x_{k+1} = x_k + \\alpha_k p_k$。\n   c. 更新残差：$r_{k+1} = r_k - \\alpha_k A p_k$。\n   d. 检查收敛性。\n   e. 求解 $M z_{k+1} = r_{k+1}$。\n   f. 计算改进因子：$\\beta_k = \\frac{r_{k+1}^{\\top} z_{k+1}}{r_k^{\\top} z_k}$。\n   g. 更新搜索方向：$p_{k+1} = z_{k+1} + \\beta_k p_k$。\n\n在这里，求解 $M z = r$ 对应于 $z_i = r_i / M_{ii}$，根据我们对 $P$ 的定义，这等价于逐元素乘积 $z = P r$。\n\n**5. 测试用例的实现**\n\n对于每个测试用例，程序将：\n1. 构建模型参数 $x_i$ 和检波器位置 $x_{r_k}$ 的网格。\n2. 对于测试用例1和2，根据提供的指数衰减公式组装灵敏度矩阵 $S$；对于测试用例3，则将其设为单位矩阵。\n3. 通过在最接近给定分数位置的网格节点上放置指定振幅的尖峰来定义真实模型向量 $m_{\\text{true}}$。\n4. 形式化线性系统 $A x = b$，其中 $A = S^{\\top} S$ 且 $b=S^{\\top}(S m_{\\text{true}})$。\n5. 运行非预处理CG算法并记录迭代次数。\n6. 从 $A$ 的对角线构建对角预条件子 $P$。\n7. 运行预处理CG算法并记录其迭代次数。\n最终输出将这些整数计数汇总到一个列表中。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by implementing and comparing unpreconditioned and\n    preconditioned Conjugate Gradient methods for a series of test cases.\n    \"\"\"\n\n    def cg_solver(A, b, tol, max_iter, P_diag=None):\n        \"\"\"\n        Solves the system Ax = b using the Conjugate Gradient method.\n\n        Args:\n            A (np.ndarray): The system matrix (n x n).\n            b (np.ndarray): The right-hand side vector (n,).\n            tol (float): The relative residual tolerance for convergence.\n            max_iter (int): The maximum number of iterations.\n            P_diag (np.ndarray, optional): The diagonal of the preconditioner matrix,\n                                            which is an approximation of A^-1.\n\n        Returns:\n            int: The number of iterations required for convergence.\n        \"\"\"\n        x = np.zeros_like(b, dtype=float)\n        \n        norm_b = np.linalg.norm(b)\n        if norm_b == 0:\n            return 0\n\n        # The initial residual is checked against the absolute tolerance,\n        # but the loop check uses the problem-specified relative tolerance.\n        r = b - A @ x\n        if np.linalg.norm(r) = tol * norm_b:\n            return 0\n\n        if P_diag is not None:\n            z = P_diag * r\n            p = z.copy()\n            rz_old = np.dot(r, z)\n        else:\n            p = r.copy()\n            rz_old = np.dot(r, r)\n\n        for k in range(max_iter):\n            Ap = A @ p\n            \n            pAp = np.dot(p, Ap)\n            # If A is only semi-definite, pAp can be zero.\n            if pAp = 0:\n                return k\n\n            alpha = rz_old / pAp\n            x += alpha * p\n            \n            # The convergence criterion from the problem uses the explicitly\n            # calculated residual, which is more robust to floating-point drift.\n            current_residual_norm = np.linalg.norm(b - A @ x)\n            if current_residual_norm / norm_b = tol:\n                return k + 1\n\n            # Update residual and search direction using standard CG recurrence.\n            r -= alpha * Ap\n\n            if P_diag is not None:\n                z = P_diag * r\n                rz_new = np.dot(r, z)\n                beta = rz_new / rz_old\n                p = z + beta * p\n                rz_old = rz_new\n            else:\n                rz_new = np.dot(r, r)\n                beta = rz_new / rz_old\n                p = r + beta * p\n                rz_old = rz_new\n        \n        return max_iter\n\n    def run_case(params):\n        \"\"\"\n        Sets up and runs a single test case.\n        \"\"\"\n        L, n_m, n_d = params['L'], params['n_m'], params['n_d']\n        alpha, x_s = params.get('alpha'), params.get('x_s')\n        m_true_spec = params['m_true_spec']\n        receiver_locs = params['receiver_locs']\n        is_identity = params.get('is_identity', False)\n        \n        # 1. Build sensitivity matrix S\n        if is_identity:\n            S = np.identity(n_m)\n        else:\n            x_model = np.linspace(0, L, n_m)\n            dist_s_to_model = np.abs(x_model - x_s)\n            \n            # Broadcasting for receiver-model distances\n            dist_r_to_model = np.abs(x_model.reshape(1, n_m) - receiver_locs.reshape(n_d, 1))\n\n            exp_s = np.exp(-alpha * dist_s_to_model)\n            exp_r = np.exp(-alpha * dist_r_to_model)\n            \n            # S_{k,i} = exp_r_{k,i} * exp_s_{i}\n            S = exp_r * exp_s\n            \n        # 2. Build true model m_true\n        m_true = np.zeros(n_m)\n        # Use L_grid for spike placement, which is L unless L is None (case 3)\n        L_grid = L if L is not None else 1.0 \n        if n_m > 1:\n            delta_x = L_grid / (n_m - 1)\n            for pos, amp in m_true_spec:\n                # Find the nearest grid index for the spike\n                idx = int(round(pos * L_grid / delta_x))\n                if 0 = idx  n_m:\n                    m_true[idx] = amp\n\n        # 3. Set up the linear system Ax = b\n        H_gn = S.T @ S\n        d = S @ m_true\n        b = S.T @ d\n\n        # 4. Define parameters for CG solver\n        tol = 1e-8\n        max_iter = n_m\n        epsilon = np.finfo(float).eps\n\n        # 5. Solve without preconditioning\n        iters_unpre = cg_solver(H_gn, b, tol=tol, max_iter=max_iter)\n\n        # 6. Solve with preconditioning\n        H_gn_diag = np.sum(S**2, axis=0)\n        P_diag = 1.0 / (H_gn_diag + epsilon)\n        iters_pre = cg_solver(H_gn, b, tol=tol, max_iter=max_iter, P_diag=P_diag)\n        \n        return iters_unpre, iters_pre\n\n    # Define the test cases from the problem statement.\n    m_true_spec = [(0.2, 1.0), (0.5, -0.8), (0.8, 0.6)]\n    \n    test_cases = [\n        {\n            'L': 1.0, 'n_m': 60, 'n_d': 30, 'alpha': 3.0, 'x_s': 0.0,\n            'receiver_locs': np.linspace(0.0, 1.0, 30),\n            'm_true_spec': m_true_spec\n        },\n        {\n            'L': 1.0, 'n_m': 60, 'n_d': 8, 'alpha': 0.5, 'x_s': 0.0,\n            'receiver_locs': np.linspace(0.0, 1.0, 8),\n            'm_true_spec': m_true_spec\n        },\n        {\n            'L': 1.0, 'n_m': 60, 'n_d': 60,\n            'is_identity': True,\n            'receiver_locs': None, # Not used\n            'm_true_spec': m_true_spec\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        iters_unpre, iters_pre = run_case(case)\n        results.extend([iters_unpre, iters_pre])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}