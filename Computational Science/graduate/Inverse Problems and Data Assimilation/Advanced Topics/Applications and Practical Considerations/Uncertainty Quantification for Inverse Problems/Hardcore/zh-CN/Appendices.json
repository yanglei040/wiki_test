{
    "hands_on_practices": [
        {
            "introduction": "本次实践将贝叶斯推断的抽象理论置于一个具体的数值任务中。通过为一个简单的线性高斯系统手动计算后验均值和协方差，您将对观测数据如何更新先验知识并减少不确定性获得切实的理解。这个练习是为数据同化机制建立直觉的基础。",
            "id": "3429478",
            "problem": "考虑一个线性逆问题，其未知参数向量为 $x \\in \\mathbb{R}^{2}$，观测值为 $y \\in \\mathbb{R}^{2}$，由正演模型 $y = A x + \\eta$ 控制，其中 $\\eta$ 是均值为零且独立于 $x$ 的噪声。假设高斯先验为 $x \\sim \\mathcal{N}(m_{0}, C_{0})$，高斯观测噪声为 $\\eta \\sim \\mathcal{N}(0, \\Gamma)$。取以下具体数值\n$$\nA = \\begin{pmatrix}\n2  1 \\\\\n1  3\n\\end{pmatrix}, \\quad\nC_{0} = \\mathrm{diag}(1, 4), \\quad\n\\Gamma = 0.25\\, I_{2}, \\quad\nm_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\quad\ny = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix},\n$$\n其中 $I_{2}$ 表示 $2 \\times 2$ 的单位矩阵。\n\n从贝叶斯法则和多元高斯密度的定义出发，推导给定 $y$ 时 $x$ 的后验分布，从而得到该线性高斯逆问题的后验均值向量 $m^{y}$ 和后验协方差矩阵 $C^{y}$。根据给定数据，数值计算 $m^{y}$ 和 $C^{y}$。然后，通过比较先验和后验协方差，解释不确定性在哪些方向上减少得最多，并阐明测量算子 $A$ 和噪声统计量如何影响这些方向。\n\n以精确值（不进行四舍五入）给出 $m^{y}$ 和 $C^{y}$ 的最终数值。最终答案必须是一个单行矩阵，按顺序包含 $m^{y}$ 的两个分量，然后是按行逐一列出的 $C^{y}$ 的四个分量。",
            "solution": "用户要求我解决一个贝叶斯逆问题。\n\n以下是我的思考过程：\n\n1.  **问题验证**：\n    *   **步骤1：提取已知条件**：我将逐字列出所有给定的矩阵、向量和分布。\n        *   正演模型：$y = Ax + \\eta$\n        *   未知参数：$x \\in \\mathbb{R}^{2}$\n        *   观测值：$y \\in \\mathbb{R}^{2}$\n        *   噪声：$\\eta$ 均值为零且独立于 $x$。\n        *   先验分布：$x \\sim \\mathcal{N}(m_{0}, C_{0})$\n        *   噪声分布：$\\eta \\sim \\mathcal{N}(0, \\Gamma)$\n        *   正演算子：$A = \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix}$\n        *   先验协方差：$C_{0} = \\mathrm{diag}(1, 4)$\n        *   噪声协方差：$\\Gamma = 0.25\\, I_{2}$\n        *   先验均值：$m_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$\n        *   观测向量：$y = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$\n    *   **步骤2：使用提取的已知条件进行验证**：\n        *   **科学依据**：该问题是贝叶斯推断在线性高斯系统中的经典应用。它依赖于概率论（贝叶斯法则、多元高斯分布的性质）和线性代数的基本原理。在统计信号处理、数据同化和逆问题等领域，这是一个标准且成熟的问题。它在科学上是合理的。\n        *   **适定性**：该问题要求计算后验均值和协方差。对于线性高斯模型，这些量是唯一确定的，并且可以通过既定的解析公式计算。给定的矩阵 $A$、$C_0$ 和 $\\Gamma$ 都是可逆的（$det(A) = 2 \\cdot 3 - 1 \\cdot 1 = 5 \\neq 0$，$det(C_0) = 4 \\neq 0$，$det(\\Gamma) = 0.25^2 \\neq 0$），这确保了所有后续的矩阵运算（如求逆）都是明确定义的，并且存在唯一解。该问题是适定的。\n        *   **客观性**：该问题使用精确的数学语言和符号陈述，并带有具体的数值。没有主观、模糊或基于观点性的陈述。\n    *   **步骤3：结论与行动**：该问题是有效的。我将继续推导和计算解答。\n\n2.  **解答推导与计算**：\n    *   **第1部分：解析推导**：\n        *   我将从贝叶斯法则开始：$p(x|y) \\propto p(y|x) p(x)$。\n        *   我将写出先验和似然的概率密度函数（PDF）。\n            *   先验：$p(x) = \\mathcal{N}(m_0, C_0) \\propto \\exp\\left(-\\frac{1}{2}(x - m_0)^T C_0^{-1} (x - m_0)\\right)$。\n            *   似然：给定 $x$，模型 $y = Ax + \\eta$ 且 $\\eta \\sim \\mathcal{N}(0, \\Gamma)$ 意味着给定 $x$ 时 $y$ 的条件分布为 $y|x \\sim \\mathcal{N}(Ax, \\Gamma)$。似然函数为 $p(y|x) \\propto \\exp\\left(-\\frac{1}{2}(y - Ax)^T \\Gamma^{-1} (y - Ax)\\right)$。\n        *   接下来，我将它们合并为后验 PDF：$p(x|y) \\propto \\exp\\left(-\\frac{1}{2}\\left[(y - Ax)^T \\Gamma^{-1} (y - Ax) + (x - m_0)^T C_0^{-1} (x - m_0)\\right]\\right)$。\n        *   关键步骤是证明指数中的表达式是关于 $x$ 的二次型，这意味着后验分布也是高斯的。我将展开各项并对 $x$ 进行配方。\n        *   指数的参数正比于：\n            $J(x) = (y - Ax)^T \\Gamma^{-1} (y - Ax) + (x - m_0)^T C_0^{-1} (x - m_0)$\n            $J(x) = (x^T A^T - y^T)\\Gamma^{-1}(Ax - y) + (x^T - m_0^T)C_0^{-1}(x-m_0)$\n            $J(x) = x^T A^T \\Gamma^{-1} A x - x^T A^T \\Gamma^{-1} y - y^T \\Gamma^{-1} A x + y^T \\Gamma^{-1} y + x^T C_0^{-1} x - x^T C_0^{-1} m_0 - m_0^T C_0^{-1} x + m_0^T C_0^{-1} m_0$\n        *   按 $x$ 的项分组：\n            二次项：$x^T (A^T \\Gamma^{-1} A + C_0^{-1}) x$\n            线性项：$-2x^T(A^T \\Gamma^{-1} y + C_0^{-1} m_0)$（利用标量项等于其转置的性质，例如 $y^T\\Gamma^{-1}Ax = x^T A^T \\Gamma^{-1}y$）\n            常数项：不含 $x$ 的项。\n        *   这与高斯指数的标准形式相匹配，正比于 $(x-m^y)^T(C^y)^{-1}(x-m^y) = x^T(C^y)^{-1}x - 2x^T(C^y)^{-1}m^y + \\text{const}$。\n        *   通过比较二次项和线性项，我将确定后验协方差的逆和后验均值：\n            *   $(C^y)^{-1} = C_0^{-1} + A^T \\Gamma^{-1} A$\n            *   $(C^y)^{-1} m^y = C_0^{-1} m_0 + A^T \\Gamma^{-1} y$\n        *   这导出了最终的公式：\n            *   $C^y = (C_0^{-1} + A^T \\Gamma^{-1} A)^{-1}$\n            *   $m^y = C^y (C_0^{-1} m_0 + A^T \\Gamma^{-1} y)$\n    *   **第2部分：数值计算**：\n        *   我将把给定的数值代入这些公式。\n        *   $C_0^{-1} = \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix}^{-1} = \\begin{pmatrix} 1  0 \\\\ 0  1/4 \\end{pmatrix}$。\n        *   $\\Gamma^{-1} = (0.25 I_2)^{-1} = 4 I_2 = \\begin{pmatrix} 4  0 \\\\ 0  4 \\end{pmatrix}$。\n        *   计算 $A^T \\Gamma^{-1} A = \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} 4  0 \\\\ 0  4 \\end{pmatrix} \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix} = \\begin{pmatrix} 8  4 \\\\ 4  12 \\end{pmatrix} \\begin{pmatrix} 2  1 \\\\ 1  3 \\end{pmatrix} = \\begin{pmatrix} 20  20 \\\\ 20  40 \\end{pmatrix}$。\n        *   计算后验协方差的逆（精度矩阵）：$(C^y)^{-1} = \\begin{pmatrix} 1  0 \\\\ 0  1/4 \\end{pmatrix} + \\begin{pmatrix} 20  20 \\\\ 20  40 \\end{pmatrix} = \\begin{pmatrix} 21  20 \\\\ 20  40.25 \\end{pmatrix} = \\begin{pmatrix} 21  20 \\\\ 20  161/4 \\end{pmatrix}$。\n        *   将其求逆以得到 $C^y$：\n            *   $\\det((C^y)^{-1}) = 21 \\times \\frac{161}{4} - 20 \\times 20 = \\frac{3381}{4} - 400 = \\frac{3381 - 1600}{4} = \\frac{1781}{4}$。\n            *   $C^y = \\frac{4}{1781} \\begin{pmatrix} 161/4  -20 \\\\ -20  21 \\end{pmatrix} = \\frac{1}{1781} \\begin{pmatrix} 161  -80 \\\\ -80  84 \\end{pmatrix}$。\n        *   现在计算均值 $m^y$。由于 $m_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，项 $C_0^{-1} m_0$ 为零。\n        *   计算 $A^T \\Gamma^{-1} y = \\begin{pmatrix} 8  4 \\\\ 4  12 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 8 - 4 \\\\ 4 - 12 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ -8 \\end{pmatrix}$。\n        *   $m^y = C^y (A^T \\Gamma^{-1} y) = \\frac{1}{1781} \\begin{pmatrix} 161  -80 \\\\ -80  84 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ -8 \\end{pmatrix} = \\frac{1}{1781} \\begin{pmatrix} 161(4) - 80(-8) \\\\ -80(4) + 84(-8) \\end{pmatrix} = \\frac{1}{1781} \\begin{pmatrix} 644 + 640 \\\\ -320 - 672 \\end{pmatrix} = \\frac{1}{1781} \\begin{pmatrix} 1284 \\\\ -992 \\end{pmatrix}$。\n    *   **第3部分：解释**：\n        *   我将比较先验协方差 $C_0$ 和后验协方差 $C^y$ 的对角元素（方差）。\n        *   $C_0 = \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix}$。$\\text{Var}(x_1)=1$，$\\text{Var}(x_2)=4$。\n        *   $C^y \\approx \\begin{pmatrix} 0.0904  -0.0449 \\\\ -0.0449  0.0472 \\end{pmatrix}$。$\\text{Var}(x_1|y) \\approx 0.09$，$\\text{Var}(x_2|y) \\approx 0.047$。\n        *   我会注意到两个方差都显著减小，尤其是 $x_2$ 的方差。\n        *   我将通过检查正演算子 $A$ 来解释 $x_2$ 不确定性减小得更多的原因。$A$ 的列决定了数据对每个参数的敏感度。$A$ 的第二列的范数 ($||\\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}||_2 = \\sqrt{10}$) 大于第一列的范数 ($||\\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}||_2 = \\sqrt{5}$)，这表明测量值对 $x_2$ 的变化更敏感。这使得对 $x_2$ 的约束更强，从而导致其不确定性更大幅度地减小。\n        *   我还会评论非对角线项，指出测量过程将参数耦合在一起，引入了先验中不存在的负相关性（$C^y_{12}  0$）。\n    *   **最终答案格式化**：\n        *   问题要求一个单行矩阵，其中包含 $m^y$ 的分量，然后是 $C^y$ 按行排列的分量。\n        *   顺序将是 $[m^y_1, m^y_2, C^y_{11}, C^y_{12}, C^y_{21}, C^y_{22}]$。\n        *   我将把精确的分数值放入一个 LaTeX `pmatrix` 中。\n\n这个结构化的计划涵盖了问题的所有方面，确保了正确性和对格式规则的遵守。我现在将生成最终输出。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix} \\frac{1284}{1781}  -\\frac{992}{1781}  \\frac{161}{1781}  -\\frac{80}{1781}  -\\frac{80}{1781}  \\frac{84}{1781} \\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "本次实践超越了低维度的例子，介绍了一种系统性的计算方法来分析复杂反问题中的不确定性。您将编写一个程序，对一个预处理的前向算子进行奇异值分解，从而识别出参数空间中哪些方向被数据充分约束，哪些方向没有。这个练习弥合了线性代数理论与后验不确定性结构（例如与数值零空间相关的“脊”）的实际诊断之间的鸿沟。",
            "id": "3429460",
            "problem": "考虑一个线性化的贝叶斯逆问题，其参数向量为 $x \\in \\mathbb{R}^n$，线性正演映射为 $G \\in \\mathbb{R}^{m \\times n}$，加性测量噪声为 $\\eta \\in \\mathbb{R}^m$（建模为协方差为 $C_n \\in \\mathbb{R}^{m \\times m}$ 的零均值高斯噪声），以及 $x$ 的高斯先验，其均值为零，协方差为 $C_0 \\in \\mathbb{R}^{n \\times n}$。观测数据为 $y \\in \\mathbb{R}^m$，满足 $y = G x + \\eta$。假设 $C_0$ 和 $C_n$ 是对称正定矩阵。目标是通过使用线性化正演映射的奇异函数，分析沿零空间的辨识度，从而刻画后验不确定性脊。\n\n从高斯测度的贝叶斯法则和在参考点处的线性化出发，$x$ 的后验分布是高斯的，其协方差由先验精度 $C_0^{-1}$ 和数据失配曲率 $G^\\top C_n^{-1} G$ 之间的相互作用决定。定义先验预处理正演算子 $A$ 为\n$$\nA = C_n^{-1/2} \\, G \\, C_0^{1/2},\n$$\n其中 $C_0^{1/2}$ 和 $C_n^{-1/2}$ 分别表示 $C_0$ 的唯一对称正定平方根和 $C_n$ 的平方根的逆。设 $A$ 的奇异值分解通过其右奇异向量表示为对称矩阵的特征分解\n$$\nH = A^\\top A = C_0^{1/2} \\, G^\\top \\, C_n^{-1} \\, G \\, C_0^{1/2}.\n$$\n如果 $\\lambda_i$ 是 $H$ 的特征值，对应的标准正交特征向量为 $v_i \\in \\mathbb{R}^n$（即 $A$ 的右奇异向量），那么奇异值为 $s_i = \\sqrt{\\lambda_i}$。在由 $z = C_0^{-1/2} x$ 给出的先验坐标系中，后验协方差沿 $v_i$ 方向的特征值为\n$$\n\\gamma_i = \\frac{1}{1 + s_i^2}.\n$$\n$s_i$ 较小的方向对应于较弱的数据信息和较大的后验方差因子 $\\gamma_i$，从而形成后验脊。精确的零空间方向具有 $s_i = 0$ 并得出 $\\gamma_i = 1$，表示与先验相比没有减少。\n\n你的任务是实现一个程序，对于给定的矩阵测试套件 $(G, C_0, C_n)$，计算：\n- 通过 $H = A^\\top A$ 的特征值计算 $A$ 的全套奇异值 $s_i$，\n- 沿右奇异向量 $v_i$ 的后验方差因子 $\\gamma_i = 1/(1 + s_i^2)$，\n- 每个方向的二元脊分类，定义为如果 $s_i \\le s_{\\text{thresh}}$ 则 $\\text{ridge}_i = \\text{True}$，否则为 $\\text{False}$，\n- 数值零空间的维度，定义为 $s_i \\le s_{\\text{zero}}$ 的数量。\n\n使用以下数值阈值：\n- $s_{\\text{thresh}} = 10^{-3}$ 用于脊分类，\n- $s_{\\text{zero}} = 10^{-12}$ 用于零空间维度。\n\n对于每个测试用例，输出一个包含以下内容的列表：\n- 整数形式的零空间维度，\n- 按降序排序的奇异值 $s_i$ 列表，每个值四舍五入到 $8$ 位小数，\n- 顺序相同的后验方差因子 $\\gamma_i$ 列表，每个值四舍五入到 $8$ 位小数，\n- 顺序相同的布尔型脊标志列表。\n\n构建并使用以下测试套件：\n- 测试用例 1 (秩亏，有明显的零空间)：$m = 2$, $n = 3$, $G = \\begin{bmatrix}1  0  0 \\\\ 0  0  0\\end{bmatrix}$, $C_0 = \\mathrm{diag}(1, 4, 9)$, $C_n = \\mathrm{diag}(0.01, 0.01)$。\n- 测试用例 2 (阈值边界情况)：$m = 2$, $n = 3$, $G = \\begin{bmatrix}10^{-3}  0  0 \\\\ 0  0  10^{-3}\\end{bmatrix}$, $C_0 = \\mathrm{diag}(1, 1, 1)$, $C_n = \\mathrm{diag}(1, 1)$。\n- 测试用例 3 (满秩，强可辨识)：$m = 3$, $n = 3$, $G = \\mathrm{diag}(5, 2, 1)$, $C_0 = I_{3 \\times 3}$, $C_n = \\mathrm{diag}(0.04, 0.04, 0.04)$。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 $[ \\text{result1}, \\text{result2}, \\text{result3} ]$），其中每个 $\\text{result}$ 是按上述规定格式化的测试用例列表。不涉及物理单位或角度单位。数值答案必须是所要求的浮点数或整数，列表必须由这些类型或布尔值组成。",
            "solution": "用户希望我解决一个关于逆问题不确定性量化的问题。我被要求首先对问题陈述进行严格验证。\n\n### 第 1 步：提取已知信息\n- **模型**：线性化贝叶斯逆问题，观测方程为 $y = G x + \\eta$。\n- **参数**：$x \\in \\mathbb{R}^n$ 是参数向量。\n- **正演算子**：$G \\in \\mathbb{R}^{m \\times n}$ 是线性正演映射。\n- **观测**：$y \\in \\mathbb{R}^m$ 是观测数据。\n- **噪声模型**：$\\eta \\in \\mathbb{R}^m$ 是测量噪声，建模为协方差为 $C_n \\in \\mathbb{R}^{m \\times m}$ 的零均值高斯噪声。$C_n$ 是对称正定的。\n- **先验模型**：$x$ 服从零均值、协方差为 $C_0 \\in \\mathbb{R}^{n \\times n}$ 的高斯先验。$C_0$ 是对称正定的。\n- **先验预处理算子**：$A = C_n^{-1/2} \\, G \\, C_0^{1/2}$。\n- **预处理后的Hessian矩阵**：$H = A^\\top A = C_0^{1/2} \\, G^\\top \\, C_n^{-1} \\, G \\, C_0^{1/2}$。\n- **奇异值**：$A$ 的奇异值 $s_i$ 与 $H$ 的特征值 $\\lambda_i$ 相关，关系为 $s_i = \\sqrt{\\lambda_i}$。$A$ 的右奇异向量是 $H$ 的特征向量 $v_i$。\n- **后验方差因子**：$\\gamma_i = \\frac{1}{1 + s_i^2}$。\n- **数值阈值**：\n    - 脊分类阈值：$s_{\\text{thresh}} = 10^{-3}$。\n    - 零空间维度阈值：$s_{\\text{zero}} = 10^{-12}$。\n- **测试用例**：\n    1.  $m = 2$, $n = 3$, $G = \\begin{bmatrix}1  0  0 \\\\ 0  0  0\\end{bmatrix}$, $C_0 = \\mathrm{diag}(1, 4, 9)$, $C_n = \\mathrm{diag}(0.01, 0.01)$。\n    2.  $m = 2$, $n = 3$, $G = \\begin{bmatrix}10^{-3}  0  0 \\\\ 0  0  10^{-3}\\end{bmatrix}$, $C_0 = \\mathrm{diag}(1, 1, 1)$, $C_n = \\mathrm{diag}(1, 1)$。\n    3.  $m = 3$, $n = 3$, $G = \\mathrm{diag}(5, 2, 1)$, $C_0 = I_{3 \\times 3}$, $C_n = \\mathrm{diag}(0.04, 0.04, 0.04)$。\n- **输出要求**：对于每个测试用例，输出一个列表，包含：\n    1.  整数形式的零空间维度 ( $s_i \\le s_{\\text{zero}}$ 的数量 )。\n    2.  按降序排列的奇异值 $s_i$ 列表，四舍五入到 $8$ 位小数。\n    3.  顺序相同的后验方差因子 $\\gamma_i$ 列表，四舍五入到 $8$ 位小数。\n    4.  顺序相同的布尔型脊标志列表 ( $s_i \\le s_{\\text{thresh}}$ )。\n\n### 第 2 步：使用提取的已知信息进行验证\n根据验证标准评估问题：\n\n-   **科学依据**：该问题牢固地植根于贝叶斯逆问题理论，这是计算科学、工程和统计学的核心课题。使用高斯先验和噪声模型是标准做法。通过预处理算子的奇异值分解进行分析是一种成熟的不确定性量化技术。所有概念都是标准的并且在事实上是健全的。\n-   **适定性**：问题为每个案例提供了所有必要的输入（$G$，$C_0$，$C_n$），清晰的定义，以及具体的计算任务和输出格式。由于 $C_0$ 和 $C_n$ 被给定为对称正定矩阵，唯一对称正定平方根 $C_0^{1/2}$ 和 $C_n^{1/2}$ 的存在性得到保证。随后的计算为每个测试用例带来唯一且稳定的解。\n-   **客观性**：问题以精确的数学语言陈述。任务是定量的，不涉及主观解释。\n-   **未检测到缺陷**：问题没有违反任何指定的缺陷类别。它在科学上是健全的、可形式化的、完整的且结构良好。\n\n### 第 3 步：结论与行动\n问题是**有效的**。将提供一个完整的、有理据的解决方案。\n\n### 解决方案\n\n该问题要求对线性贝叶斯逆问题的后验不确定性进行分析。解决方案涉及计算从先验预处理正演算子的奇异值得出的几个量。\n\n**理论框架**\n\n问题的基础在于贝叶斯定理。给定先验概率密度函数 (PDF) $\\pi_{\\text{pr}}(x)$ 和似然函数 $\\pi_{\\text{like}}(y|x)$，后验 PDF $\\pi_{\\text{post}}(x|y)$ 与它们的乘积成正比：\n$$\n\\pi_{\\text{post}}(x|y) \\propto \\pi_{\\text{like}}(y|x) \\pi_{\\text{pr}}(x)\n$$\n在这个问题中，$x$ 的先验是零均值、协方差为 $C_0$ 的高斯分布，因此其 PDF 与 $\\exp\\left(-\\frac{1}{2} x^\\top C_0^{-1} x\\right)$ 成正比。加性噪声 $\\eta$ 是零均值、协方差为 $C_n$ 的高斯分布，因此对于观测 $y = Gx + \\eta$ 的似然函数与 $\\exp\\left(-\\frac{1}{2} (y - Gx)^\\top C_n^{-1} (y - Gx)\\right)$ 成正比。\n\n结合这些，后验 PDF 与 $x$ 的二次型的指数成正比，表明后验也是高斯分布。后验协方差矩阵 $C_{\\text{post}}$ 由先验精度和数据失配Hessian矩阵之和的逆给出：\n$$\nC_{\\text{post}} = (C_0^{-1} + G^\\top C_n^{-1} G)^{-1}\n$$\n\n**预处理与奇异值分解**\n\n为了分析后验不确定性的结构，在一个先验被白化的坐标系中工作是有利的。我们定义一个变量变换 $z = C_0^{-1/2} x$，其中 $C_0^{1/2}$ 是 $C_0$ 的对称正定平方根。在这些坐标中，$z$ 的先验是标准正态分布，$z \\sim \\mathcal{N}(0, I)$。正演模型变为 $y = G C_0^{1/2} z + \\eta$。\n\n通过对数据空间进行白化，可以进一步简化。我们将模型乘以 $C_n^{-1/2}$，即噪声协方差的对称平方根的逆。这导致一个变换后的问题：\n$$\n\\tilde{y} = C_n^{-1/2} G C_0^{1/2} z + \\tilde{\\eta}\n$$\n其中 $\\tilde{y} = C_n^{-1/2} y$，变换后的噪声 $\\tilde{\\eta} = C_n^{-1/2} \\eta$ 是标准正态的，$\\tilde{\\eta} \\sim \\mathcal{N}(0, I)$。算子 $A = C_n^{-1/2} G C_0^{1/2}$ 是先验预处理正演算子。\n\n$z$ 的后验精度是 $(I + A^\\top A)$。设 $A$ 的奇异值分解 (SVD) 为 $A = U S V^\\top$，其中 $V$ 是一个正交矩阵，其列 $v_i$ 是 $A$ 的右奇异向量，$S$ 是一个奇异值的矩形对角矩阵。$v_i$ 的列构成了 $z$ 坐标下参数空间的一个标准正交基。矩阵 $A^\\top A$ 可以写成：\n$$\nA^\\top A = (U S V^\\top)^\\top (U S V^\\top) = V S^\\top U^\\top U S V^\\top = V S^\\top S V^\\top\n$$\n矩阵 $H = A^\\top A$ 是对称的，其特征向量是 $A$ 的右奇异向量 $v_i$。相关的特征值是 $\\lambda_i = s_i^2$。\n\n**后验不确定性分析**\n\n$z$ 的后验协方差是 $C_{\\text{post},z} = (I + A^\\top A)^{-1}$。在特征向量 $v_i$ 的基下，该协方差是对角矩阵：\n$$\nC_{\\text{post},z} = (V (I + S^\\top S) V^\\top)^{-1} = V (I + S^\\top S)^{-1} V^\\top\n$$\n$(I + S^\\top S)^{-1}$ 的对角线项是后验方差因子 $\\gamma_i = \\frac{1}{1+s_i^2}$。这些因子量化了从先验到后验沿每个主方向 $v_i$ 的方差减少程度。\n- 如果 $s_i \\gg 1$，则 $\\gamma_i \\approx 1/s_i^2 \\ll 1$。数据强烈约束该方向，不确定性显著减少。\n- 如果 $s_i \\ll 1$，则 $\\gamma_i \\approx 1$。数据提供的信息很少，后验方差几乎等于先验方差（在 $z$ 坐标中为 $1$）。这些方向形成了高后验概率的“脊”。\n- 如果 $s_i = 0$，该方向位于 $A$ 的零空间中。则 $\\gamma_i = 1$，后验方差等于先验方差；数据在该方向上没有提供任何信息。\n\n**计算算法**\n\n对于每个测试用例 $(G, C_0, C_n)$：\n1.  计算先验协方差的对称正定平方根 $C_0^{1/2}$。由于给定的 $C_0$ 矩阵是对角矩阵，所以 $C_{0,ii}^{1/2} = \\sqrt{C_{0,ii}}$。对于一般的对称正定矩阵，可以使用像 `scipy.linalg.sqrtm` 这样的函数。\n2.  计算噪声协方差的逆 $C_n^{-1}$。由于给定的 $C_n$ 矩阵是对角矩阵，所以 $C_{n,ii}^{-1} = 1/C_{n,ii}$。对于一般矩阵，可以使用 `numpy.linalg.inv`。\n3.  构建预处理后的Hessian矩阵 $H = C_0^{1/2} G^\\top C_n^{-1} G C_0^{1/2}$。注意，由于 $C_0$ 和 $C_0^{1/2}$ 是对称的，$(C_0^{1/2})^\\top = C_0^{1/2}$。\n4.  使用数值稳定的算法（例如，`numpy.linalg.eigh`）计算对称矩阵 $H$ 的特征值 $\\lambda_i$。\n5.  将特征值按降序排序：$\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_n$。\n6.  计算 $A$ 的奇异值 $s_i = \\sqrt{\\lambda_i}$。由于潜在的浮点误差，任何小的负特征值在取平方根之前应被视为零。\n7.  计算每个方向的后验方差因子：$\\gamma_i = 1 / (1 + s_i^2)$。\n8.  将每个方向分类为脊或非脊：如果 $s_i \\le s_{\\text{thresh}} = 10^{-3}$，则 $\\text{ridge}_i = \\text{True}$，否则为 $\\text{False}$。\n9.  通过计算奇异值 $s_i$ 中满足 $s_i \\le s_{\\text{zero}} = 10^{-12}$ 的数量来计算数值零空间的维度。\n10. 按照指定的格式和舍入要求将结果组装成一个列表。\n\n此过程将应用于提供的三个测试用例中的每一个。",
            "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian inverse problem uncertainty quantification task\n    for a given suite of test cases.\n    \"\"\"\n    \n    # Define the numerical thresholds from the problem statement.\n    s_thresh = 1e-3\n    s_zero = 1e-12\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"G\": np.array([[1.0, 0.0, 0.0], [0.0, 0.0, 0.0]]),\n            \"C0\": np.diag([1.0, 4.0, 9.0]),\n            \"Cn\": np.diag([0.01, 0.01])\n        },\n        {\n            \"G\": np.array([[1e-3, 0.0, 0.0], [0.0, 0.0, 1e-3]]),\n            \"C0\": np.diag([1.0, 1.0, 1.0]),\n            \"Cn\": np.diag([1.0, 1.0])\n        },\n        {\n            \"G\": np.diag([5.0, 2.0, 1.0]),\n            \"C0\": np.identity(3),\n            \"Cn\": np.diag([0.04, 0.04, 0.04])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        G = case[\"G\"]\n        C0 = case[\"C0\"]\n        Cn = case[\"Cn\"]\n\n        # Step 1: Compute matrix square roots and inverses.\n        # For a symmetric positive definite matrix, scipy.linalg.sqrtm gives the\n        # unique symmetric positive definite square root.\n        # For diagonal matrices as in the test cases, this is equivalent to\n        # taking the square root of the diagonal elements.\n        C0_sqrt = linalg.sqrtm(C0)\n        Cn_inv = np.linalg.inv(Cn)\n\n        # Step 2: Construct the preconditioned Hessian matrix H = A^T A.\n        # H = (C0^1/2)^T G^T Cn^-1 G C0^1/2\n        # Since C0_sqrt is symmetric, (C0_sqrt)^T = C0_sqrt.\n        H = C0_sqrt @ G.T @ Cn_inv @ G @ C0_sqrt\n\n        # Step 3: Compute eigenvalues of H.\n        # numpy.linalg.eigh is used for symmetric matrices. It returns eigenvalues\n        # in ascending order. We reverse them to get descending order.\n        eigenvalues = np.linalg.eigh(H)[0][::-1]\n\n        # Step 4: Calculate singular values s_i = sqrt(lambda_i).\n        # We clamp eigenvalues at 0 to handle potential minor negative values\n        # from floating-point errors before taking the square root.\n        singular_values = np.sqrt(np.maximum(0, eigenvalues))\n\n        # Step 5: Calculate posterior variance factors gamma_i.\n        # gamma_i = 1 / (1 + s_i^2). Note that s_i^2 is the eigenvalue.\n        variance_factors = 1.0 / (1.0 + eigenvalues)\n\n        # Step 6: Perform ridge classification.\n        ridge_flags = (singular_values = s_thresh).tolist()\n\n        # Step 7: Compute the dimension of the numerical nullspace.\n        nullspace_dim = np.sum(singular_values = s_zero)\n\n        # Step 8: Format results for output.\n        # Round lists to 8 decimal places as required.\n        s_list = np.round(singular_values, 8).tolist()\n        gamma_list = np.round(variance_factors, 8).tolist()\n        \n        # Assemble the final list for the current test case.\n        case_result = [\n            int(nullspace_dim),\n            s_list,\n            gamma_list,\n            ridge_flags\n        ]\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    # Convert each case's result list to its string representation\n    # and join them with commas.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现实世界的数据往往含有异常值，标准的 高斯噪声假设可能过于理想化。本次实践将探讨如何通过使用具有重尾的 学生-$t$ 分布来构建对异常值更具鲁棒性的反问题模型。通过推导其后验势并分析其梯度，您将理解为什么这种选择能够自动降低异常数据点的影响，这是构建可靠推断系统的关键一步。",
            "id": "3429455",
            "problem": "考虑一个线性逆问题，其中未知状态向量 $u \\in \\mathbb{R}^{d}$ 通过模型 $y = A u + \\varepsilon$ 被一个已知的线性正演算子 $A \\in \\mathbb{R}^{n \\times d}$ 映射到观测值 $y \\in \\mathbb{R}^{n}$。考虑到传感器中偶尔出现的严重误差，假设加性噪声分量 $\\varepsilon_{i}$ 统计独立，并服从自由度为 $\\nu  2$、正尺度为 $s  0$ 的学生t分布。同时，假设 $u$ 的先验为高斯分布 $u \\sim \\mathcal{N}(m_{0}, C_{0})$，其均值为 $m_{0} \\in \\mathbb{R}^{d}$，协方差为对称正定矩阵 $C_{0} \\in \\mathbb{R}^{d \\times d}$。令 $a_{i}^{\\top}$ 表示 $A$ 的第 $i$ 行，则残差为 $r_{i}(u) = y_{i} - a_{i}^{\\top} u$。\n\n从贝叶斯定理和标准分布定义出发，推导在给定 $y$ 的条件下 $u$ 的后验密度，推导结果可以忽略一个乘法归一化常数。通过给出负对数后验势 $\\Phi(u)$ 关于 $A$, $y$, $m_{0}$, $C_{0}$, $\\nu$ 和 $s$ 的显式解析表达式，将后验分布表示为 $\\pi(u \\mid y) \\propto \\exp(-\\Phi(u))$ 的形式。\n\n然后，从基本原理出发，分析梯度 $\\nabla \\Phi(u)$，以解释与高斯似然相比，重尾的学生t似然如何减小离群值对后验分布的影响。具体来说，请确定每个残差对 $\\nabla \\Phi(u)$ 的贡献，并证明当 $|r_{i}(u)| \\to \\infty$ 时，其贡献的大小是有界的且趋于零。\n\n最后，为与数据同化实践建立联系，请使用学生t分布的尺度混合表示法引入潜精度变量，并推导在给定这些潜变量的条件下 $u$ 的条件后验分布。解释这种表示法如何揭示一种自适应的残差重加权机制，该机制会降低离群值的权重。\n\n以负对数后验势 $\\Phi(u)$ 的单一闭式解析表达式的形式提供最终答案，该表达式可与真实值相差一个加法常数。无需进行数值计算。",
            "solution": "该问题在科学上基于贝叶斯统计学和逆问题理论，是适定的，提供了所有必要信息，并且陈述客观。我们开始解答。\n\n给定观测值 $y$ 的条件下，未知状态向量 $u$ 的后验概率密度函数 (PDF)，记作 $\\pi(u \\mid y)$，由贝叶斯定理给出。在不考虑乘法归一化常数的情况下，后验分布与似然 $\\pi(y \\mid u)$ 和先验 $\\pi(u)$ 的乘积成正比：\n$$\n\\pi(u \\mid y) \\propto \\pi(y \\mid u) \\pi(u)\n$$\n\n首先，我们定义先验项。问题陈述 $u$ 的先验是一个多元高斯分布，$u \\sim \\mathcal{N}(m_{0}, C_{0})$，其均值为 $m_{0}$，协方差为对称正定矩阵 $C_{0}$。其PDF为：\n$$\n\\pi(u) \\propto \\exp\\left(-\\frac{1}{2} (u - m_{0})^{\\top} C_{0}^{-1} (u - m_{0})\\right)\n$$\n这里我们省略了归一化常数。\n\n接下来，我们定义似然项。模型为 $y = A u + \\varepsilon$，其中噪声分量 $\\varepsilon_{i} = y_{i} - a_{i}^{\\top} u$ 独立同分布，服从自由度为 $\\nu  2$、尺度为 $s  0$ 的学生t分布。单个噪声分量 $\\varepsilon_{i}$ 的PDF由下式给出：\n$$\n\\pi(\\varepsilon_{i}) = \\frac{\\Gamma((\\nu+1)/2)}{\\sqrt{\\nu\\pi} s \\Gamma(\\nu/2)} \\left(1 + \\frac{\\varepsilon_{i}^2}{\\nu s^2}\\right)^{-(\\nu+1)/2}\n$$\n由于 $\\varepsilon_i = y_i - a_i^\\top u = r_i(u)$，且噪声分量是独立的，因此整个观测向量 $y$ 的似然函数是各个独立密度的乘积：\n$$\n\\pi(y \\mid u) = \\prod_{i=1}^{n} \\pi(y_{i} \\mid u) = \\prod_{i=1}^{n} \\frac{\\Gamma((\\nu+1)/2)}{\\sqrt{\\nu\\pi} s \\Gamma(\\nu/2)} \\left(1 + \\frac{(y_i - a_i^\\top u)^2}{\\nu s^2}\\right)^{-(\\nu+1)/2}\n$$\n忽略常数项，似然函数为：\n$$\n\\pi(y \\mid u) \\propto \\prod_{i=1}^{n} \\left(1 + \\frac{(y_i - a_i^\\top u)^2}{\\nu s^2}\\right)^{-(\\nu+1)/2}\n$$\n\n结合先验和似然，后验PDF为：\n$$\n\\pi(u \\mid y) \\propto \\exp\\left(-\\frac{1}{2} (u - m_{0})^{\\top} C_{0}^{-1} (u - m_{0})\\right) \\prod_{i=1}^{n} \\left(1 + \\frac{(y_i - a_i^\\top u)^2}{\\nu s^2}\\right)^{-(\\nu+1)/2}\n$$\n后验分布表示为 $\\pi(u \\mid y) \\propto \\exp(-\\Phi(u))$ 的形式，其中 $\\Phi(u)$ 是负对数后验势。对上式右侧取负对数，我们得到：\n$$\n\\Phi(u) = \\frac{1}{2} (u - m_{0})^{\\top} C_{0}^{-1} (u - m_{0}) - \\sum_{i=1}^{n} \\ln\\left( \\left(1 + \\frac{(y_i - a_i^\\top u)^2}{\\nu s^2}\\right)^{-(\\nu+1)/2} \\right)\n$$\n化简后得到：\n$$\n\\Phi(u) = \\frac{1}{2} (u - m_{0})^{\\top} C_{0}^{-1} (u - m_{0}) + \\frac{\\nu+1}{2} \\sum_{i=1}^{n} \\ln\\left(1 + \\frac{(y_i - a_i^\\top u)^2}{\\nu s^2}\\right)\n$$\n这就是负对数后验势的显式解析表达式（与真实值相差一个加法常数）。\n\n接下来，我们分析 $\\Phi(u)$ 的梯度以理解离群值的影响。$\\Phi(u)$ 关于 $u$ 的梯度是：\n$$\n\\nabla \\Phi(u) = \\nabla_u \\left( \\frac{1}{2} (u - m_{0})^{\\top} C_{0}^{-1} (u - m_{0}) \\right) + \\nabla_u \\left( \\frac{\\nu+1}{2} \\sum_{i=1}^{n} \\ln\\left(1 + \\frac{(y_i - a_i^\\top u)^2}{\\nu s^2}\\right) \\right)\n$$\n先验项的梯度是 $C_{0}^{-1}(u-m_{0})$。对于似然项，我们使用链式法则。注意到 $\\nabla_u (y_i - a_i^\\top u) = -a_i$：\n$$\n\\nabla_u \\ln\\left(1 + \\frac{(y_i - a_i^\\top u)^2}{\\nu s^2}\\right) = \\frac{1}{1 + \\frac{(y_i - a_i^\\top u)^2}{\\nu s^2}} \\cdot \\frac{2(y_i - a_i^\\top u)}{\\nu s^2} \\cdot (-a_i) = - \\frac{2(y_i - a_i^\\top u) a_i}{\\nu s^2 + (y_i - a_i^\\top u)^2}\n$$\n将此代入 $\\nabla \\Phi(u)$ 的表达式中：\n$$\n\\nabla \\Phi(u) = C_{0}^{-1}(u - m_{0}) - \\sum_{i=1}^{n} \\frac{(\\nu+1)(y_i - a_i^\\top u)}{\\nu s^2 + (y_i - a_i^\\top u)^2} a_i\n$$\n对于残差 $r_i(u) = y_i - a_i^\\top u$，似然项中每个残差对梯度的贡献是 $-w_i(r_i(u)) a_i$，其中标量权重为 $w_i(r_i) = \\frac{(\\nu+1)r_i}{\\nu s^2 + r_i^2}$。对于精度为 $1/\\sigma^2$ 的高斯似然，等效权重为 $\\frac{r_i}{\\sigma^2}$，它会随着 $|r_i|$ 线性且无界地增长。相比之下，对于学生t分布的情况，权重的大小为 $|w_i(r_i)| = \\frac{(\\nu+1)|r_i|}{\\nu s^2 + r_i^2}$。当 $|r_i| \\to \\infty$ 时，权重的行为类似于 $|w_i(r_i)| \\sim \\frac{(\\nu+1)}{|r_i|}$，该值会趋于零。权重的大小是有界的，其最大值在 $|r_i| = \\sqrt{\\nu}s$ 处取得。这个性质确保了大残差（离群值）对梯度的影响逐渐减小，从而防止后验估计被过度地拉向去拟合这些离群值。这使得推断过程对离群值具有稳健性。\n\n最后，我们使用学生t分布的尺度混合表示法。一个服从学生t分布的随机变量 $\\varepsilon_i$ 可以通过引入一个潜精度变量 $\\lambda_i  0$ 进行分层建模：\n$$\n\\varepsilon_i \\mid \\lambda_i \\sim \\mathcal{N}(0, s^2/\\lambda_i) \\quad \\text{and} \\quad \\lambda_i \\sim \\text{Gamma}(\\nu/2, \\nu/2)\n$$\n其中 $\\text{Gamma}(a, b)$ 分布的形状参数为 $a$，率参数为 $b$。将此应用于我们的逆问题，我们用潜变量 $\\lambda_1, \\dots, \\lambda_n$ 来扩展模型：\n$$\ny \\mid u, \\Lambda \\sim \\mathcal{N}(Au, s^2 \\Lambda^{-1}), \\quad \\text{where } \\Lambda = \\text{diag}(\\lambda_1, \\dots, \\lambda_n)\n$$\n$u$ 的先验分布保持为 $u \\sim \\mathcal{N}(m_0, C_0)$，潜变量的先验分布为 $\\lambda_i \\sim \\text{Gamma}(\\nu/2, \\nu/2)$。\n在给定潜变量 $\\Lambda$ 和数据 $y$ 的条件下，$u$ 的条件后验分布可以通过结合两个高斯分布（条件似然和 $u$ 的先验）得到：\n$$\n\\pi(u \\mid y, \\Lambda) \\propto \\pi(y \\mid u, \\Lambda) \\pi(u) \\propto \\exp\\left(-\\frac{1}{2s^2}(y-Au)^\\top \\Lambda(y-Au)\\right) \\exp\\left(-\\frac{1}{2}(u-m_0)^\\top C_0^{-1}(u-m_0)\\right)\n$$\n这是一个高斯分布 $\\mathcal{N}(\\mu_{u \\mid \\Lambda}, C_{u \\mid \\Lambda})$，其后验精度矩阵为 $C_{u \\mid \\Lambda}^{-1} = C_0^{-1} + \\frac{1}{s^2}A^\\top \\Lambda A$，均值为 $\\mu_{u \\mid \\Lambda} = C_{u \\mid \\Lambda}(C_0^{-1}m_0 + \\frac{1}{s^2}A^\\top \\Lambda y)$。\n这种表示法揭示了一种自适应的重加权机制。后验精度中的数据项包含矩阵 $\\Lambda$，它为每个残差的贡献分配一个特定的权重 $\\lambda_i$。为了解这个权重是如何确定的，我们求 $\\lambda_i$ 的全条件分布：\n$$\n\\pi(\\lambda_i \\mid u, y_i) \\propto \\pi(y_i \\mid u, \\lambda_i) \\pi(\\lambda_i) \\propto \\lambda_i^{1/2} \\exp\\left(-\\frac{\\lambda_i(y_i-a_i^\\top u)^2}{2s^2}\\right) \\cdot \\lambda_i^{\\nu/2 - 1} \\exp\\left(-\\frac{\\nu}{2}\\lambda_i\\right)\n$$\n$$\n\\pi(\\lambda_i \\mid u, y_i) \\propto \\lambda_i^{(\\nu+1)/2 - 1} \\exp\\left( - \\lambda_i \\left(\\frac{\\nu}{2} + \\frac{(y_i-a_i^\\top u)^2}{2s^2}\\right) \\right)\n$$\n这是一个Gamma分布：$\\lambda_i \\mid u, y_i \\sim \\text{Gamma}\\left(\\frac{\\nu+1}{2}, \\frac{\\nu}{2} + \\frac{r_i(u)^2}{2s^2}\\right)$。这个潜精度的后验期望是：\n$$\n\\mathbb{E}[\\lambda_i \\mid u, y_i] = \\frac{(\\nu+1)/2}{(\\nu/2) + r_i(u)^2/(2s^2)} = \\frac{\\nu+1}{\\nu + r_i(u)^2/s^2}\n$$\n随着残差 $|r_i(u)|$ 的大小增加，期望精度 $\\mathbb{E}[\\lambda_i]$ 减小并趋于零。这意味着模型拟合得不好的观测值（离群值）在 $u$ 的更新中被自动赋予较低的权重，从而有效地降低了它们的影响。这证实了从梯度分析中观察到的稳健性。",
            "answer": "$$\n\\boxed{\\frac{1}{2} (u - m_{0})^{\\top} C_{0}^{-1} (u - m_{0}) + \\frac{\\nu+1}{2} \\sum_{i=1}^{n} \\ln\\left(1 + \\frac{(y_i - a_i^{\\top} u)^{2}}{\\nu s^{2}}\\right)}\n$$"
        }
    ]
}