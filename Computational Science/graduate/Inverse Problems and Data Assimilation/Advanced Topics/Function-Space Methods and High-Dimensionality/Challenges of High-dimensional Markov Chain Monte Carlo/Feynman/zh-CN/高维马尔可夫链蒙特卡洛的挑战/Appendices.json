{
    "hands_on_practices": [
        {
            "introduction": "高维MCMC方法的核心挑战源于“维度灾难”，即随着状态空间维度 $d$ 的增加，标准算法的效率会急剧下降。这项练习旨在通过第一性原理的推导，将这一模糊概念具体化。通过分析随机游走Metropolis算法，您将精确计算有效样本量（ESS）如何依赖于维度 $d$，从而揭示性能下降的根本尺度定律()。这项基础性的计算练习，为理解为何需要更高级的算法奠定了坚实的理论基础。",
            "id": "3370964",
            "problem": "考虑一个线性高斯数据同化问题，其中经过先验预处理的适当白化和观测算子线性化后，离散化状态的后验分布是一个 $d$ 维标准正态目标分布 $\\mathcal{N}(0, I_{d})$。您运行一个随机游走 Metropolis (RWM) 马尔可夫链蒙特卡洛 (MCMC) 算法，其高斯提议为 $y = x + \\sigma_{d} \\,\\xi$，其中 $\\xi \\sim \\mathcal{N}(0, I_{d})$ 独立于当前状态 $x$，且提议方差按 $\\sigma_{d}^{2} = \\ell^{2}/d$ 进行缩放，其中 $\\ell > 0$ 为一固定值。假设链从稳态开始。令 $f(x) = v^{\\top} x$ 为一个标量线性泛函，其中 $\\|v\\|_{2} = 1$。\n\n仅使用基本原理和经过充分检验的事实作为出发点，包括：\n- 对称提议下的 Metropolis-Hastings 接受概率。\n- 在上述缩放条件下，高维 $d$ 的大数定律。\n- 针对独立同分布乘积测度的随机游走 Metropolis 的经典扩散极限，在按 $d$ 进行时间重缩放下，该极限对于任何固定坐标或固定单位方向投影产生一个 Ornstein–Uhlenbeck (OU) 过程极限。\n- 有效样本量 (ESS) 的定义：对于一个滞后 $k$ 自相关为 $\\rho_{k}$ 的平稳标量时间序列，其积分自相关时间为 $\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_{k}$，而 $n$ 次迭代的有效样本量为 $\\mathrm{ESS}_{n} = n/\\tau_{\\mathrm{int}}$。\n\n从这些基础出发，推导 $f(x)$ 的滞后 $k$ 自相关，然后计算 $\\mathrm{ESS}_{n}$ 作为 $n$、$d$ 和 $\\ell$ 的显式函数。您的推导应：\n- 用标准正态累积分布函数 $\\Phi(\\cdot)$ 表示高维接受率。\n- 通过匹配极限中的无穷小漂移和方差，从第一性原理确定 OU 极限生成元系数 $g(\\ell)$。\n- 利用此结果获得滞后 $k$ 自相关 $\\rho_{k}$ 的闭式表达式，然后对得到的几何级数求和以计算 $\\tau_{\\mathrm{int}}$。\n- 仅使用 $n$、$d$、$\\ell$、初等函数和 $\\Phi(\\cdot)$，以闭式形式表示最终的 $\\mathrm{ESS}_{n}(d,\\ell)$。\n\n答案形式：提供 $\\mathrm{ESS}_{n}(d,\\ell)$ 的单个闭式解析表达式。不需要数值近似或四舍五入。使用标准数学符号，并定义您引入的任何特殊函数。不要包含物理单位。假设角度是无量纲的。",
            "solution": "该问题定义严谨、自洽，并且科学地基于马尔可夫链蒙特卡洛 (MCMC) 方法及其高维扩散极限的既定理论。所有提供的数据和定义在该领域内都是标准的。问题陈述是有效的。\n\n目标是推导一个在随机游走 Metropolis (RWM) 算法下演化的状态的标量线性泛函 $f(x) = v^{\\top} x$ 的有效样本量 $\\mathrm{ESS}_{n}$。目标分布是一个 $d$ 维标准正态分布，$\\pi(x) \\propto \\exp(-\\frac{1}{2} x^{\\top}x)$。\n\n步骤 1：高维接受率\nRWM 提议为 $y = x + \\sigma_{d} \\xi$，其中 $\\xi \\sim \\mathcal{N}(0, I_{d})$ 且提议方差为 $\\sigma_{d}^{2} = \\ell^{2}/d$。由于提议分布是对称的，$q(y|x) = q(x|y)$，Metropolis-Hastings 接受概率为 $\\alpha(x, y) = \\min\\left(1, \\frac{\\pi(y)}{\\pi(x)}\\right)$。\n\n目标密度的比率为：\n$$ \\frac{\\pi(y)}{\\pi(x)} = \\frac{\\exp(-\\frac{1}{2}y^{\\top}y)}{\\exp(-\\frac{1}{2}x^{\\top}x)} = \\exp\\left(-\\frac{1}{2}(y^{\\top}y - x^{\\top}x)\\right) $$\n代入 $y = x + \\sigma_d \\xi$：\n$$ y^{\\top}y = (x + \\sigma_d \\xi)^{\\top}(x + \\sigma_d \\xi) = x^{\\top}x + 2\\sigma_d x^{\\top}\\xi + \\sigma_d^2 \\xi^{\\top}\\xi $$\n因此，指数的参数变为：\n$$ \\log\\left(\\frac{\\pi(y)}{\\pi(x)}\\right) = -\\sigma_d x^{\\top}\\xi - \\frac{1}{2}\\sigma_d^2 \\xi^{\\top}\\xi $$\n我们分析在 $d \\rightarrow \\infty$ 极限下指数中各项的行为。假设链处于稳态，因此 $x \\sim \\mathcal{N}(0, I_{d})$。\n第二项是 $\\frac{1}{2}\\sigma_d^2 \\xi^{\\top}\\xi = \\frac{1}{2} \\frac{\\ell^2}{d} \\sum_{i=1}^{d} \\xi_i^2$。根据大数定律，当 $d \\to \\infty$ 时，$\\frac{1}{d}\\sum_{i=1}^{d} \\xi_i^2 \\to \\mathbb{E}[\\xi_1^2] = 1$。此项依概率收敛于 $\\frac{1}{2}\\ell^2$。\n第一项是 $\\sigma_d x^{\\top}\\xi = \\frac{\\ell}{\\sqrt{d}} \\sum_{i=1}^{d} x_i \\xi_i$。由于 $x$ 和 $\\xi$ 是独立标准正态的，$x_i \\xi_i$ 项是独立同分布的，其均值为 $\\mathbb{E}[x_i\\xi_i]=\\mathbb{E}[x_i]\\mathbb{E}[\\xi_i]=0$，方差为 $\\mathrm{Var}(x_i\\xi_i) = \\mathbb{E}[(x_i\\xi_i)^2] - (\\mathbb{E}[x_i\\xi_i])^2 = \\mathbb{E}[x_i^2]\\mathbb{E}[\\xi_i^2] = 1 \\cdot 1 = 1$。根据中心极限定理，和 $\\frac{1}{\\sqrt{d}} \\sum_{i=1}^{d} x_i \\xi_i$ 在分布上收敛于一个标准正态变量 $U \\sim \\mathcal{N}(0, 1)$。因此，$\\sigma_d x^{\\top}\\xi$ 在分布上收敛于 $\\mathcal{N}(0, \\ell^2)$。令 $Z \\sim \\mathcal{N}(0, \\ell^2)$。\n\n在高维极限下，接受概率变得与具体状态 $x$ 无关，平均接受率 $\\bar{\\alpha}(\\ell)$ 由对数比率的极限分布的期望给出：\n$$ \\bar{\\alpha}(\\ell) = \\mathbb{E}_{Z}\\left[\\min\\left(1, \\exp\\left(-Z - \\frac{\\ell^2}{2}\\right)\\right)\\right] $$\n其中 $Z \\sim \\mathcal{N}(0, \\ell^2)$。令 $Z = \\ell U$，其中 $U \\sim \\mathcal{N}(0, 1)$。令 $\\phi(u)$ 为标准正态概率密度函数 (PDF)。\n$$ \\bar{\\alpha}(\\ell) = \\int_{-\\infty}^{\\infty} \\min\\left(1, \\exp\\left(-\\ell u - \\frac{\\ell^2}{2}\\right)\\right) \\phi(u) du $$\n当指数的参数为正时，即 $-\\ell u - \\ell^2/2 > 0$，这意味着 $u  -\\ell/2$，项 $\\exp(-\\ell u - \\ell^2/2)$ 大于 1。因此我们把积分分成两部分：\n$$ \\bar{\\alpha}(\\ell) = \\int_{-\\infty}^{-\\ell/2} 1 \\cdot \\phi(u) du + \\int_{-\\ell/2}^{\\infty} \\exp\\left(-\\ell u - \\frac{\\ell^2}{2}\\right) \\phi(u) du $$\n第一个积分是标准正态累积分布函数 (CDF) $\\Phi(-\\ell/2)$ 的定义。\n对于第二个积分，我们代入 $\\phi(u) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-u^2/2)$ 并在指数中配方：\n$$ -\\ell u - \\frac{\\ell^2}{2} - \\frac{u^2}{2} = -\\frac{1}{2}(u^2 + 2\\ell u + \\ell^2) = -\\frac{1}{2}(u+\\ell)^2 $$\n第二个积分变为 $\\int_{-\\ell/2}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{1}{2}(u+\\ell)^2) du$。令 $v=u+\\ell$，则 $dv=du$。积分上下限从 $u=-\\ell/2 \\to v=\\ell/2$ 以及 $u \\to \\infty \\to v \\to \\infty$ 改变。\n$$ \\int_{\\ell/2}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{v^2}{2}\\right) dv = P(V  \\ell/2) = 1 - \\Phi(\\ell/2) $$\n其中 $V \\sim \\mathcal{N}(0, 1)$。由于标准正态分布的对称性，$1 - \\Phi(z) = \\Phi(-z)$，所以这个积分等于 $\\Phi(-\\ell/2)$。\n结合两部分，渐近接受率为：\n$$ \\bar{\\alpha}(\\ell) = \\Phi(-\\ell/2) + \\Phi(-\\ell/2) = 2\\Phi(-\\ell/2) $$\n\n步骤 2：Ornstein-Uhlenbeck (OU) 极限和自相关\n问题陈述指出，在时间重缩放 $t=k/d$ 下，任何固定单位方向投影的过程收敛到一个 OU 过程。令 $F_t = f(x_{\\lfloor dt \\rfloor}) = v^{\\top}x_{\\lfloor dt \\rfloor}$。由于目标分布 $\\mathcal{N}(0, I_d)$ 是各向同性的且 $\\|v\\|_2=1$，我们可以选择一个坐标系使得 $v = (1, 0, ..., 0)^{\\top}$，因此 $F_t$ 就是状态向量的第一个坐标。\n\n坐标过程的极限随机微分方程 (SDE) 形式为 $dF_t = -\\theta F_t dt + \\sigma dW_t$。此过程的平稳分布为 $\\mathcal{N}(0, \\sigma^2/(2\\theta))$。我们需要它与 $f(x) = v^{\\top}x$ 的平稳分布 $\\mathcal{N}(0, v^{\\top}I_d v) = \\mathcal{N}(0,1)$ 相匹配。因此，必须有 $\\sigma^2=2\\theta$。\n\n扩散系数 $\\sigma^2$ 通过计算重缩放后的期望平方跳跃距离得到：\n$$ \\sigma^2 = \\lim_{d \\to \\infty} d \\cdot \\mathbb{E}[ (f(x_{k+1}) - f(x_k))^2 | x_k=x ] $$\n变化量是 $f(x_{k+1}) - f(x_k) = v^{\\top}(x_{k+1}-x_k)$。状态更新为 $x_{k+1} = x_k + \\sigma_d \\xi \\cdot \\mathbb{I}(\\text{接受})$，其中 $\\mathbb{I}$ 是一个接受指示函数。\n$$ \\mathbb{E}[(v^{\\top}(\\sigma_d \\xi \\cdot \\mathbb{I}(\\text{接受})))^2 | x] = \\sigma_d^2 \\mathbb{E}[(v^{\\top}\\xi)^2 \\alpha(x, x+\\sigma_d \\xi) | x] $$\n在 $d \\to \\infty$ 的极限下，$\\alpha$ 收敛于常数 $\\bar{\\alpha}(\\ell)$。因此：\n$$ \\sigma^2 \\approx d \\cdot \\sigma_d^2 \\mathbb{E}[(v^{\\top}\\xi)^2] \\bar{\\alpha}(\\ell) = d \\cdot \\frac{\\ell^2}{d} \\cdot \\mathrm{Var}(v^{\\top}\\xi) \\cdot \\bar{\\alpha}(\\ell) $$\n因为 $\\xi \\sim \\mathcal{N}(0, I_d)$ 且 $\\|v\\|_2=1$，所以 $\\mathrm{Var}(v^{\\top}\\xi) = v^{\\top}\\mathrm{Var}(\\xi)v = v^{\\top}I_d v = \\|v\\|_2^2=1$。\n因此，$\\sigma^2 = \\ell^2 \\bar{\\alpha}(\\ell) = 2\\ell^2 \\Phi(-\\ell/2)$。\n根据平稳条件 $\\sigma^2 = 2\\theta$，漂移系数为 $\\theta = \\frac{1}{2}\\sigma^2 = \\ell^2 \\Phi(-\\ell/2)$。\n这对应于问题隐含框架中的系数 $g(\\ell)$。SDE 为 $dF_t = -(\\ell^2 \\Phi(-\\ell/2)) F_t dt + \\sqrt{2\\ell^2 \\Phi(-\\ell/2)} dW_t$。\n\n漂移系数为 $\\theta$ 的 OU 过程的自相关函数为 $\\rho(\\tau) = \\exp(-\\theta \\tau)$。对于离散的 MCMC 链，时间滞后 $\\tau$ 对应于 $k/d$ 步。滞后 $k$ 自相关为：\n$$ \\rho_k = \\rho(k/d) = \\exp(-\\theta k/d) = \\exp\\left(-k \\frac{\\ell^2 \\Phi(-\\ell/2)}{d}\\right) $$\n\n步骤 3：积分自相关时间 ($\\tau_{\\mathrm{int}}$) 和 ESS\n积分自相关时间定义为 $\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_{k}$。该和是一个几何级数。令 $r = \\rho_1 = \\exp\\left(-\\frac{\\ell^2 \\Phi(-\\ell/2)}{d}\\right)$。\n$$ \\sum_{k=1}^{\\infty} \\rho_k = \\sum_{k=1}^{\\infty} r^k = \\frac{r}{1-r} $$\n将此代入 $\\tau_{\\mathrm{int}}$ 的表达式中：\n$$ \\tau_{\\mathrm{int}} = 1 + 2\\frac{r}{1-r} = \\frac{(1-r) + 2r}{1-r} = \\frac{1+r}{1-r} $$\n代入 $r$ 的表达式：\n$$ \\tau_{\\mathrm{int}} = \\frac{1 + \\exp\\left(-\\frac{\\ell^2 \\Phi(-\\ell/2)}{d}\\right)}{1 - \\exp\\left(-\\frac{\\ell^2 \\Phi(-\\ell/2)}{d}\\right)} $$\n这个表达式可以用双曲余切函数写出，$\\coth(z) = \\frac{\\exp(z)+\\exp(-z)}{\\exp(z)-\\exp(-z)} = \\frac{\\exp(2z)+1}{\\exp(2z)-1}$。令 $z = \\frac{\\ell^2 \\Phi(-\\ell/2)}{2d}$。那么 $\\tau_{\\mathrm{int}} = \\coth(z)$。\n$$ \\tau_{\\mathrm{int}} = \\coth\\left(\\frac{\\ell^2 \\Phi(-\\ell/2)}{2d}\\right) $$\n$n$ 次迭代的有效样本量为 $\\mathrm{ESS}_n = n/\\tau_{\\mathrm{int}}$。\n$$ \\mathrm{ESS}_{n}(d,\\ell) = \\frac{n}{\\coth\\left(\\frac{\\ell^2 \\Phi(-\\ell/2)}{2d}\\right)} = n \\tanh\\left(\\frac{\\ell^2 \\Phi(-\\ell/2)}{2d}\\right) $$\n这提供了 $\\mathrm{ESS}_{n}$ 作为 $n$、$d$ 和 $\\ell$ 的函数的最终闭式表达式，使用了初等函数和标准正态 CDF $\\Phi$。",
            "answer": "$$\n\\boxed{n \\tanh\\left(\\frac{\\ell^{2} \\Phi(-\\ell/2)}{2d}\\right)}\n$$"
        },
        {
            "introduction": "在理论上理解性能随维度下降后，下一个关键问题是如何在实践中可靠地诊断MCMC采样器的混合（mixing）情况。在高维空间中，简单的可视化检查（如轨迹图）往往具有欺骗性，可能掩盖沿某些方向的缓慢混合。这项练习 () 强调了一个核心原则：采样性能是与“可观测量”相关的。您将通过分析积分自相关时间（IACT）与维度的关系，学习为何基于感兴趣量（quantity of interest）的量化诊断方法远优于朴素的诊断方法。",
            "id": "3370978",
            "problem": "您正在分析一个$d$维贝叶斯线性反问题中的马尔可夫链蒙特卡罗 (MCMC) 方法，该问题具有高斯先验和线性观测算子。经过白化处理后，假设白化坐标下的后验分布近似于$\\mathbb{R}^d$上的乘积高斯分布。您运行一个随机游走 Metropolis (RWM) 算法，其高斯提议增量被缩放为$l/\\sqrt{d}$，其中$l0$为某个常数。令$f:\\mathbb{R}^d\\to\\mathbb{R}$表示一个标量“感兴趣量”(QoI)，例如数据失配、某个传感器上的后验预测值或状态的线性泛函，并令$X_t$表示平稳的马尔可夫链。$f(X_t)$的积分自相关时间 (IACT) 定义为\n$$\n\\tau_{\\text{int}}[f] \\;=\\; 1 + 2\\sum_{k=1}^{\\infty} \\rho_f(k),\n$$\n其中$\\rho_f(k)$是平稳时间序列$\\{f(X_t)\\}_{t\\ge 0}$的滞后$k$阶自相关。对于$N$次抽样，有效样本量 (ESS) 为$N/\\tau_{\\text{int}}[f]$。可以定义一个挂钟时间成本归一化的效率指标为$N/(\\tau_{\\text{int}}[f]\\cdot T)$，其中$T$是总计算时间。\n\n请仅使用 IACT 和 ESS 的基本定义，以及关于 RWM 在近似乘积目标上的最优缩放的经过充分检验的事实（例如，提议方差按$O(1/d)$缩放且接受率在$O(1)$量级时，能最大化期望平方跳跃距离），来推断对维度$d$的敏感性如何影响$f(X_t)$的混合。然后选择一个选项，该选项提出了一个基于$\\tau_{\\text{int}}$的、针对特定可观测量且在$d$增大时仍具有信息量的诊断方法，并通过分析其对$d$的敏感性，正确地证明了为什么它对于高维链优于朴素的轨迹图。\n\nA. 对于每个具有科学意义的标量可观测量$f$，计算$\\tau_{\\text{int}}[f]$的一致谱估计量（等价于，由$f$的边际方差缩放的频率为$0$处的谱密度），并报告成本归一化的效率$N/(\\tau_{\\text{int}}[f]\\cdot T)$。对于目标为近似乘积高斯分布、提议方差为$l^2/d$的RWM，对于典型的线性泛函，$\\tau_{\\text{int}}[f]$以$d$的量级增长，因为$f$中的期望平方跳跃按$O(1/d)$缩放，因此报告的效率以$O(1/d)$的速度衰减。这种诊断方法优于坐标的轨迹图，因为轨迹图是投影，无论相关长度如何，它们看起来都可能具有欺骗性的“嘈雜”，不能量化相关时间，并且随着$d$的增加，可能会完全错过在绘制的坐标中不可见的慢方向。\n\nB. 仅监视总接受率。因为对于乘积目标，RWM 的最优调整接受率约为$0.234$且不随$d$变化，所以它是维度稳健的，因此优于轨迹图和任何基于$\\tau_{\\text{int}}$的诊断方法。\n\nC. 对几条并行链，仅计算第一个坐标的盖尔曼-鲁宾潜在尺度缩减因子 (PSRF)。因为在近似乘积后验分布下所有坐标都是可交换的，所以第一个坐标反映了全局混合属性，因此这个标量 PSRF 既是维度稳健的，也优于任何基于$\\tau_{\\text{int}}$的诊断方法。\n\nD. 绘制平方范数$\\|X_t\\|^2$的轨迹图。由于在乘积高斯分布下$\\operatorname{Var}(\\|X_t\\|^2)$随$d$增长，这样的轨迹图对$d$越来越敏感，因此优于针对特定可观测量的基于$\\tau_{\\text{int}}$的诊断方法。\n\nE. 通过将所有$d$个坐标的单变量自相关相加然后除以$d$来定义一个“全状态”IACT，并使用此平均值作为全状态的维度不变ESS。因为该平均值由$d$归一化，所以它消除了对$d$的依赖性，并且优于针对特定可观测量的$\\tau_{\\text{int}}$估计。\n\n选择正确的选项。",
            "solution": "用户提供了一个关于在高维贝叶斯反问题中诊断马尔可夫链蒙特卡罗 (MCMC) 采样器性能的问题。任务是验证问题陈述的有效性，如果有效，则通过分析采样器性能随维度$d$的缩放行为，从给定选项中确定最佳诊断策略。\n\n### 问题验证\n\n首先必须验证问题陈述的科学合理性、清晰性和完整性。\n\n**步骤1：提取已知条件**\n\n-   **背景**：$d$维贝叶斯线性反问题。\n-   **模型**：白化坐标中的后验分布近似为$\\mathbb{R}^d$上的乘积高斯分布。\n-   **算法**：随机游走Metropolis (RWM)，使用高斯提议$Y_t = X_t + \\xi_t$，其中$\\xi_t \\sim \\mathcal{N}(0, (l^2/d)I_d)$，常数$l  0$。\n-   **可观测量**：标量感兴趣量 (QoI)，$f:\\mathbb{R}^d\\to\\mathbb{R}$。\n-   **定义**：\n    -   积分自相关时间 (IACT)：$\\tau_{\\text{int}}[f] = 1 + 2\\sum_{k=1}^{\\infty} \\rho_f(k)$，其中$\\rho_f(k)$是平稳时间序列$\\{f(X_t)\\}_{t\\ge 0}$的滞后$k$阶自相关。\n    -   有效样本量 (ESS)：$N/\\tau_{\\text{int}}[f]$。\n    -   成本归一化效率：$N/(\\tau_{\\text{int}}[f]\\cdot T)$，其中$T$是总计算时间。\n-   **前提**：分析应利用以下事实：对于类乘积目标，在高$d$极限下，提议方差按$O(1/d)$缩放会产生$O(1)$的接受率，并最大化期望平方跳跃距离。\n-   **目标**：识别一种基于$\\tau_{\\text{int}}$的、针对特定可观测量的诊断方法，该方法对于大的$d$仍具有信息量，并通过分析其维度敏感性来证明其相对于朴素方法的优越性。\n\n**步骤2：使用提取的已知条件进行验证**\n\n1.  **科学依据**：该问题设置是研究高维MCMC的典范模型，由开创性工作（例如 Roberts, Gelman,  Gilks, 1997; Roberts  Rosenthal, 2001）所确立。其假设——近似乘积高斯后验、提议方差为$O(1/d)$的RWM——是理论分析的标准配置。IACT和ESS的定义是正确的。关于最优缩放的陈述前提是现代MCMC理论的基石。该问题在科学上和数学上都是合理的。\n2.  **良定性**：这个问题是良定的。它要求基于已建立的高维MCMC缩放定律对诊断工具进行概念性分析。可以从理论中推导出一个唯一且有意义的答案。\n3.  **客观性**：语言精确且客观。\n4.  **其他缺陷**：该问题不完整、不矛盾、不切实际、非良定或过于简单。它解决的是计算科学中一个关键且不平凡的挑战。\n\n**步骤3：结论与行动**\n\n问题陈述是有效的。可以进行分析。\n\n### 推导与选项分析\n\n问题的核心是理解当维度$d \\to \\infty$时，可观测量$f(X_t)$的混合时间表现如何。设目标分布为标准的$d$维高斯分布，$\\pi(x) \\propto \\exp(-\\|x\\|^2/2)$，它是$d$个一维标准高斯分布的乘积。这是“近似乘积高斯”后验分布的理想化版本。\n\n**IACT随维度的缩放**\n\nIACT与链探索状态空间的速率成反比，此速率由可观测量$f$来衡量。一个有用的近似是$\\tau_{\\text{int}}[f] \\approx \\frac{2\\operatorname{Var}_{\\pi}(f)}{\\mathbb{E}_{\\pi}[(f(X_{t+1}) - f(X_{t}))^2]}$，尤其是在RWM对大$d$趋近的扩散极限情况下。我们必须分析分子和分母的缩放行为。\n\n我们考虑一个“典型”的线性可观测量，$f(x) = c \\cdot x = \\sum_{i=1}^d c_i x_i$，其中$c \\in \\mathbb{R}^d$是一个固定向量，不失一般性，我们可以将其歸一化为$\\|c\\|=1$。\n\n1.  **分子：可观测量的方差**：在平稳分布$\\pi$下，$f(X)$的方差为$\\operatorname{Var}_{\\pi}(f) = \\operatorname{Var}_{\\pi}(c \\cdot X)$。由于$X \\sim \\mathcal{N}(0, I_d)$，分量$X_i$是独立的，方差为1。因此，$\\operatorname{Var}_{\\pi}(c \\cdot X) = c^T \\operatorname{Cov}(X) c = c^T I_d c = \\|c\\|^2 = 1$。方差相对于$d$是$O(1)$的。\n\n2.  **分母：可观测量的期望平方跳跃距离 (ESJD)**：链状态的变化是$X_{t+1} - X_t$，如果移动被接受，它就是提议步长$\\xi_t \\sim \\mathcal{N}(0, (l^2/d)I_d)$，否则为$0$。在$d \\to \\infty$的极限下，当$l$被适当地选择时，接受概率$\\alpha(X_t, X_t+\\xi_t)$会收敛到一个常数$\\bar{\\alpha}  0$。可观测量的跳跃是$\\Delta f = f(X_{t+1}) - f(X_t) = c \\cdot (X_{t+1} - X_t)$。期望平方跳跃是$\\mathbb{E}[(\\Delta f)^2] = \\mathbb{E}[\\alpha(X, X+\\xi) (c \\cdot \\xi)^2]$。在高$d$极限下，这大约是$\\bar{\\alpha} \\mathbb{E}[(c \\cdot \\xi)^2]$。随机变量$c \\cdot \\xi$是$\\xi$分量的线性组合。其方差为$\\operatorname{Var}(c \\cdot \\xi) = c^T \\operatorname{Cov}(\\xi) c = c^T (l^2/d)I_d c = (l^2/d)\\|c\\|^2 = l^2/d$。由于$\\mathbb{E}[c \\cdot \\xi] = 0$，我们有$\\mathbb{E}[(c \\cdot \\xi)^2] = \\operatorname{Var}(c \\cdot \\xi) = l^2/d$。因此，可观测量$f$的ESJD的缩放行为是$\\mathbb{E}[(\\Delta f)^2] \\approx \\bar{\\alpha} \\cdot (l^2/d) = O(1/d)$。\n\n3.  **IACT缩放**：结合这些结果，我们发现IACT的缩放行为是：\n    $$\n    \\tau_{\\text{int}}[f] \\sim \\frac{\\operatorname{Var}_{\\pi}(f)}{\\mathbb{E}[(\\Delta f)^2]} \\sim \\frac{O(1)}{O(1/d)} = O(d).\n    $$\n    对于一个典型的线性可观测量，IACT随维度线性增长。这意味着要获得一个$f$的“独立”样本，需要运行链$O(d)$步。\n\n现在，我们基于这一理解来评估每个选项。\n\n**A. 对于每个具有科学意义的标量可观测量$f$，计算$\\tau_{\\text{int}}[f]$的一致谱估计量（等价于，由$f$的边际方差缩放的频率为$0$处的谱密度），并报告成本归一化的效率$N/(\\tau_{\\text{int}}[f]\\cdot T)$。对于目标为近似乘积高斯分布、提议方差为$l^2/d$的RWM，对于典型的线性泛函，$\\tau_{\\text{int}}[f]$以$d$的量级增长，因为$f$中的期望平方跳跃按$O(1/d)$缩放，因此报告的效率以$O(1/d)$的速度衰减。这种诊断方法优于坐标的轨迹图，因为轨迹图是投影，无论相关长度如何，它们看起来都可能具有欺骗性的“嘈雜”，不能量化相关时间，并且随着$d$的增加，可能会完全错过在绘制的坐标中不可见的慢方向。**\n\n-   **提议的诊断方法**：为每个相关的可观测量$f$计算$\\tau_{\\text{int}}[f]$。这是正确的现代方法。MCMC性能是依赖于可观测量的。\n-   **$\\tau_{\\text{int}}$缩放分析**：该选项正确地陈述了$\\tau_{\\text{int}}[f]$以$O(d)$增长，并提供了正确的原因：$f$的ESJD按$O(1/d)$缩放。这与我们的推导相符。\n-   **效率分析**：该选项声称效率以$O(1/d)$衰減。效率是$1/(\\tau_{\\text{int}}[f] \\cdot T_1)$，其中$T_1$是每样本的成本。对于RWM，评估对数后验比率的成本至少为$O(d)$（以计算像$x \\cdot \\xi$这样的点积）。因此，$T_1=O(d)$。完整的计算效率是$1/(O(d) \\cdot O(d)) = O(d^{-2})$。该选项声称的$O(1/d)$对应于统计效率$1/\\tau_{\\text{int}}[f]$，它忽略了每一步的计算成本。在理论文献中，这是对术语的常见滥用。鉴于陈述的其余部分完全合理，这很可能是其意图。\n-   **相对于轨迹图的优越性**：其理由非常充分。单个坐标的轨迹图是低维投影，无法捕捉高维空间中的集体、慢混合模式。它们不提供混合时间的量化度量，并且可能具有高度误导性。\n-   **结论**：此选项正确地指出了核心问题，提出了正确的诊断工具($\\tau_{\\text{int}}[f]$)，正确地分析了其随维度的缩放行为，并正确地解释了它为何优于朴素方法。关于“成本归一化效率”的轻微不精确之处与该提议的根本正确性相比是次要的。**正确**。\n\n**B. 仅监视总接受率。因为对于乘积目标，RWM 的最优调整接受率约为$0.234$且不随$d$变化，所以它是维度稳健的，因此优于轨迹图和任何基于$\\tau_{\\text{int}}$的诊断方法。**\n\n-   **分析**：虽然$O(1)$的接受率是高维RWM采样器高效的必要条件，但它不是性能的充分诊断。接受率告诉我们提议步长大小合理，但它没有告诉我们链需要多長時間才能去相关。如上所述，即使有最优接受率，IACT仍然按$O(d)$缩放。$0.234$的接受率可以与任意慢的混合速度并存。它是一个调整参数，而不是性能度量。\n-   **结论**：**不正确**。\n\n**C. 对几条并行链，仅计算第一个坐标的盖尔曼-鲁宾潜在尺度缩减因子 (PSRF)。因为在近似乘积后验分布下所有坐标都是可交换的，所以第一个坐标反映了全局混合属性，因此这个标量 PSRF 既是维度稳健的，也优于任何基于$\\tau_{\\text{int}}$的诊断方法。**\n\n-   **分析**：这与使用轨迹图有相同的根本缺陷。监视单个坐标（或任何固定的、小的子集）是一种低维投影。虽然在理想情况下坐标是可交换的，但慢混合模式可能是$\\mathbb{R}^d$中的一个方向（例如，$v = (1/\\sqrt{d}, \\dots, 1/\\sqrt{d})$），它在任何单个坐标轴上的投影都很小。$x_1$的PSRF可能表示收敛（$\\hat{R} \\approx 1$），而链实际上未能沿方向$v$探索后验分布。需要针对特定可观测量的诊断，例如$\\tau_{\\text{int}}[v \\cdot x]$，来检测此类问题。\n-   **结论**：**不正确**。\n\n**D. 绘制平方范数$\\|X_t\\|^2$的轨迹图。由于在乘积高斯分布下$\\operatorname{Var}(\\|X_t\\|^2)$随$d$增长，这样的轨迹图对$d$越来越敏感，因此优于针对特定可观测量的基于$\\tau_{\\text{int}}$的诊断方法。**\n\n-   **分析**：绘制$\\|X_t\\|^2$的轨迹只是监视一个特定的可观测量，$f(x) = \\|x\\|^2$。这是特定可观测量方法的一个例子，而不是它的一个更优越的替代方案。评估其混合的定量方法是计算$\\tau_{\\text{int}}[\\|X_t\\|^2]$。因此，关于优越性的说法在逻辑上是不连贯的。虽然$\\|X_t\\|^2$可以是一个有用的诊断，但所提供的理由是有缺陷的，并且它不能替代检查所有相关可观测量的通用策略。\n-   **结论**：**不正确**。\n\n**E. 通过将所有$d$个坐标的单变量自相关相加然后除以$d$来定义一个“全状态”IACT，并使用此平均值作为全状态的维度不变ESS。因为该平均值由$d$归一化，所以它消除了对$d$的依赖性，并且优于针对特定可观测量的$\\tau_{\\text{int}}$估计。**\n\n-   **分析**：提议的诊断是逐坐标IACT的平均值，$\\bar{\\tau} = \\frac{1}{d}\\sum_{i=1}^d \\tau_{\\text{int}}[x_i]$。对于乘积高斯目标，由于对称性，各坐标是独立同分布的，所以所有$i$的$\\tau_{\\text{int}}[x_i]$都相同。设其为$\\tau_{\\text{coord}}$。作为一个线性泛函，其IACT按$\\tau_{\\text{coord}} = O(d)$缩放。那么平均值为$\\bar{\\tau} = \\frac{1}{d} (d \\cdot \\tau_{\\text{coord}}) = \\tau_{\\text{coord}} = O(d)$。“它消除了对$d$的依赖性”这一说法实际上是错误的。平均IACT仍然随$d$线性增长。此外，与其他平均或单分量方法一样，这可能掩盖在未与坐标轴对齐的特定方向上的慢混合。\n-   **结论**：**不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在实际应用中，高级MCMC算法通常利用问题的特定结构（如似然信息子空间, LIS）来提高效率，但这可能引入新的、更微妙的失效模式。这项编码练习 () 让您直面一种名为“假收敛”的危险现象：采样器在重要的子空间中看起来已经收敛，但在其正交补空间中却混合得非常糟糕。通过实现一个子空间感知的采样器并使用多变量诊断工具，您将学习如何揭露这种隐藏的收敛问题，这是对任何MCMC从业者都至关重要的实践技能。",
            "id": "3370944",
            "problem": "考虑一个 $d$ 维线性高斯逆问题，其具有高斯先验和高斯观测噪声。设未知参数为 $x \\in \\mathbb{R}^d$，其先验为 $x \\sim \\mathcal{N}(0, I_d)$。设观测值满足 $y = A x + \\eta$，其中 $A \\in \\mathbb{R}^{m \\times d}$ 是一个已知矩阵，$\\eta \\sim \\mathcal{N}(0, \\sigma^2 I_m)$ 是独立的观测噪声。负对数似然为 $\\Phi(x) = \\frac{1}{2 \\sigma^2} \\lVert y - A x \\rVert_2^2$。后验密度正比于 $\\exp\\left(-\\frac{1}{2}\\lVert x \\rVert_2^2 - \\Phi(x)\\right)$。\n\n对于这个具有单位先验协方差的线性问题，其似然信息子空间（LIS）可以取为对称矩阵 $H = A^\\top \\Gamma^{-1} A$（其中 $\\Gamma = \\sigma^2 I_m$，即 $H = \\frac{1}{\\sigma^2} A^\\top A$）的主特征向量的张成空间。给定一个阈值 $\\tau  0$，将 LIS 基 $U \\in \\mathbb{R}^{d \\times r}$ 定义为 $H$ 对应于严格大于 $\\tau$ 的特征值的标准正交特征向量矩阵，因此 $r = \\mathrm{rank}_\\tau(H)$ 是高于 $\\tau$ 的特征值的数量。其正交补子空间的维度为 $d-r$。\n\n为了从后验中采样，考虑使用 $K$ 条独立的平行马尔可夫链，采用分块预处理克朗克-尼科尔森（pCN）提议，该提议在 LIS 及其正交补上以不同方式混合。令 $P = U U^\\top$ 为到 LIS 上的正交投影算子， $Q = I_d - P$ 为到正交补上的投影算子。对于当前状态 $x \\in \\mathbb{R}^d$，定义提议为\n$$\nx' = \\sqrt{1 - \\beta_{\\mathrm{LIS}}^2}\\, P x + \\beta_{\\mathrm{LIS}}\\, \\xi_{\\mathrm{LIS}} \\;+\\; \\sqrt{1 - \\beta_{\\perp}^2}\\, Q x + \\beta_{\\perp}\\, \\xi_{\\perp},\n$$\n其中 $\\xi_{\\mathrm{LIS}} \\sim \\mathcal{N}(0, P)$ 和 $\\xi_{\\perp} \\sim \\mathcal{N}(0, Q)$ 是分别支撑在各自子空间上的独立高斯向量。使用接受概率\n$$\n\\alpha(x, x') = \\min\\left(1, \\exp(-\\Phi(x') + \\Phi(x))\\right),\n$$\n执行一步 Metropolis–Hastings 接受/拒绝步骤，从而使得先验不变的提议与此接受步骤相结合，以采纳后验分布。\n\n每条链使用 $n_{\\mathrm{tot}}$ 步，并舍弃 $n_{\\mathrm{burn}}$ 步的老化（burn-in）过程。用 $\\{x_{j,t}\\}_{t=1}^{n}$（$j=1,\\dots,K$）表示老化期后的样本，其中 $n = n_{\\mathrm{tot}} - n_{\\mathrm{burn}}$。定义 LIS 坐标 $z_{j,t} = U^\\top x_{j,t} \\in \\mathbb{R}^r$ 和正交补坐标 $w_{j,t} = Q_{\\perp}^\\top x_{j,t} \\in \\mathbb{R}^{d-r}$，其中 $Q_{\\perp} \\in \\mathbb{R}^{d \\times (d-r)}$ 是满足 $Q_{\\perp}^\\top U = 0$ 和 $Q_{\\perp}^\\top Q_{\\perp} = I_{d-r}$ 的正交补的任意标准正交基。\n\n为评估收敛性，对 LIS 坐标使用多元势尺度缩减因子（多元 $\\hat{R}$）进行计算，并对正交补坐标按坐标逐个计算通常的一元 $\\hat{R}$。从 $K$ 组 $n$ 个 $z \\in \\mathbb{R}^r$ 样本的链内协方差和链间协方差为 LIS 构建多元 $\\hat{R}$，并从 $K$ 组 $n$ 个样本的链内方差和链间方差为 $w \\in \\mathbb{R}^{d-r}$ 的每个坐标构建一元 $\\hat{R}$。精确地说：\n- 对于任何 $p$ 维坐标 $v_{j,t} \\in \\mathbb{R}^p$，为每条链 $j$ 定义样本均值 $\\bar{v}_j = \\frac{1}{n}\\sum_{t=1}^n v_{j,t}$ 和样本协方差 $S_j$（当 $p=1$ 时，这是标量样本方差），除数为 $n-1$。令 $\\bar{v} = \\frac{1}{K} \\sum_{j=1}^K \\bar{v}_j$。链内协方差为 $W = \\frac{1}{K} \\sum_{j=1}^K S_j$。链间协方差为 $B = n \\cdot \\mathrm{Cov}(\\bar{v}_1,\\dots,\\bar{v}_K)$，其中协方差是基于 $K$ 个链均值计算的；对于 $p=1$，$B = n$ 乘以 $K$ 个链均值的样本方差。\n- 使用这些矩阵形成尺度比较诊断。对于 $p=1$，一元 $\\hat{R}$ 将一个混合方差估计量与 $W$ 进行比较。对于 $p1$，定义一个多元类似物，当 $p=1$ 时它退化为一元情况，并基于从链内到链间离散度的相对扩大。\n\n定义一个停止规则：对于阈值 $t  1$，当且仅当 LIS 的多元 $\\hat{R} \\le t$ 时，宣布收敛。如果同时，正交补坐标上的最大一元 $\\hat{R}$ 满足 $\\max_{1 \\le k \\le d-r} \\hat{R}_k \\ge 1.1$，则称此为一次假收敛事件。\n\n你的任务是编写一个完整的、可运行的程序，该程序：\n1. 合成问题，使用给定的参数运行 $K$ 链分块 pCN 采样器，构建 LIS 及其正交补，并根据样本（协）方差的第一性原理计算上述所需的诊断指标。\n2. 对于下述每个测试用例和每个阈值 $t \\in \\{1.1, 1.05, 1.01\\}$，返回一个布尔值，指示停止规则是否会产生假收敛事件。\n\n使用以下测试套件。在所有情况下，生成 entries 服从 $\\mathcal{N}(0, d^{-1})$ 分布的 $A$，生成真实状态 $x^\\star \\sim \\mathcal{N}(0, I_d)$，并生成观测值 $y = A x^\\star + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0, \\sigma^2 I_m)$。使用 $K=4$ 条链，并从先验 $\\mathcal{N}(0, I_d)$ 中独立设置每条链的初始状态。使用固定的随机种子，以使结果具有确定性。\n\n- 测试用例 1（正交补混合不佳的理想路径）：\n  - 维度 $d = 128$，观测数 $m = 48$，噪声标准差 $\\sigma = 1$，LIS 特征阈值 $\\tau = 0.18$。\n  - pCN 步长：$\\beta_{\\mathrm{LIS}} = 0.5$，$\\beta_{\\perp} = 0.02$。\n  - 总步数 $n_{\\mathrm{tot}} = 1200$，老化步数 $n_{\\mathrm{burn}} = 300$，因此保留 $n = 900$ 步。\n\n- 测试用例 2（所有方向混合良好）：\n  - $d, m, \\sigma, \\tau$ 与测试用例 1 相同。\n  - pCN 步长：$\\beta_{\\mathrm{LIS}} = 0.5$，$\\beta_{\\perp} = 0.5$。\n  - 总步数 $n_{\\mathrm{tot}} = 1200$，老化步数 $n_{\\mathrm{burn}} = 300$，因此保留 $n = 900$ 步。\n\n- 测试用例 3（无正交补的边界情况）：\n  - 维度 $d = 32$，观测数 $m = 32$，噪声标准差 $\\sigma = 1$，LIS 特征阈值 $\\tau = -0.1$（确保几乎必然有 $r = d$）。\n  - pCN 步长：$\\beta_{\\mathrm{LIS}} = 0.5$，$\\beta_{\\perp} = 0.02$。\n  - 总步数 $n_{\\mathrm{tot}} = 900$，老化步数 $n_{\\mathrm{burn}} = 200$，因此保留 $n = 700$ 步。\n\n对于每个测试用例和每个阈值 $t \\in \\{1.1, 1.05, 1.01\\}$（按此顺序），输出一个布尔值，指示是否发生假收敛事件。将这九个布尔值（三个测试用例中的每一个的三个阈值，按顺序）聚合到一个列表中。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，“[true,false,true,false,...]”）。条目应为小写布尔值（“true”或“false”）。",
            "solution": "用户提供了一个问题陈述，在尝试解决方案之前需要对其进行验证。\n\n### 步骤 1：提取给定信息\n- **问题类型**：$d$ 维线性高斯逆问题。\n- **模型参数**：$x \\in \\mathbb{R}^d$ 是未知参数。\n- **先验分布**：$x \\sim \\mathcal{N}(0, I_d)$，其中 $I_d$ 是 $d \\times d$ 单位矩阵。\n- **观测模型**：$y = A x + \\eta$，其中 $A \\in \\mathbb{R}^{m \\times d}$ 是一个已知矩阵，$\\eta \\in \\mathbb{R}^m$ 是观测噪声。\n- **噪声模型**：$\\eta \\sim \\mathcal{N}(0, \\sigma^2 I_m)$，其中 $I_m$ 是 $m \\times m$ 单位矩阵。\n- **负对数似然**：$\\Phi(x) = \\frac{1}{2 \\sigma^2} \\lVert y - A x \\rVert_2^2$。\n- **后验密度**：$\\pi(x|y) \\propto \\exp\\left(-\\frac{1}{2}\\lVert x \\rVert_2^2 - \\Phi(x)\\right)$。\n- **似然信息子空间（LIS）**：由矩阵 $H = \\frac{1}{\\sigma^2} A^\\top A$ 的对应于严格大于阈值 $\\tau  0$ 的特征值的特征向量张成的空间。该子空间的标准正交基为 $U \\in \\mathbb{R}^{d \\times r}$。\n- **投影算子**：$P = U U^\\top$（到 LIS）和 $Q = I_d - P$（到正交补）。\n- **MCMC 采样器**：带有 Metropolis-Hastings 校正的分块预处理克朗克-尼科尔森（pCN）算法。\n- **pCN 提议**：$x' = \\sqrt{1 - \\beta_{\\mathrm{LIS}}^2}\\, P x + \\beta_{\\mathrm{LIS}}\\, \\xi_{\\mathrm{LIS}} \\;+\\; \\sqrt{1 - \\beta_{\\perp}^2}\\, Q x + \\beta_{\\perp}\\, \\xi_{\\perp}$。\n- **提议噪声**：$\\xi_{\\mathrm{LIS}} \\sim \\mathcal{N}(0, P)$ 和 $\\xi_{\\perp} \\sim \\mathcal{N}(0, Q)$ 是独立的。\n- **接受概率**：$\\alpha(x, x') = \\min\\left(1, \\exp(-\\Phi(x') + \\Phi(x))\\right)$。\n- **模拟参数**：$K$ 条平行链，每条链总步数 $n_{\\mathrm{tot}}$，老化步数 $n_{\\mathrm{burn}}$。\n- **坐标系**：LIS 坐标 $z_{j,t} = U^\\top x_{j,t} \\in \\mathbb{R}^r$ 和正交补坐标 $w_{j,t} = Q_{\\perp}^\\top x_{j,t} \\in \\mathbb{R}^{d-r}$，其中 $Q_\\perp$ 是补空间的一个标准正交基。\n- **收敛诊断**：用于 LIS 坐标的多元势尺度缩减因子（m$\\hat{R}$）和用于正交补每个坐标的一元 $\\hat{R}$。\n- **诊断定义（$p$ 维坐标 $v_{j,t}$）**：\n    - 链内协方差：$W = \\frac{1}{K} \\sum_{j=1}^K S_j$，其中 $S_j$ 是链 $j$ 的样本协方差，除数为 $n-1 = (n_{\\mathrm{tot}}-n_{\\mathrm{burn}})-1$。\n    - 链间协方差：$B = n \\cdot \\mathrm{Cov}(\\bar{v}_1,\\dots,\\bar{v}_K)$，其中 $\\bar{v}_j$ 是链均值。\n- **假收敛事件**：定义为对于给定的阈值 $t  1$，同时发生两个条件：\n    1. LIS 的多元 $\\hat{R} \\le t$。\n    2. 正交补坐标上的最大一元 $\\hat{R}$，$\\max_{k} \\hat{R}_k \\ge 1.1$。\n- **数据生成**：$A$ 的元素来自 $\\mathcal{N}(0, d^{-1})$；真实状态 $x^\\star \\sim \\mathcal{N}(0, I_d)$；观测值 $y = A x^\\star + \\eta$；MCMC 链的初始状态从先验 $\\mathcal{N}(0, I_d)$ 中抽取。必须使用固定的随机种子。\n- **测试用例**：提供了三个具体的测试用例，包含参数 $(d, m, \\sigma, \\tau)$、$(\\beta_{\\mathrm{LIS}}, \\beta_{\\perp})$ 和 $(n_{\\mathrm{tot}}, n_{\\mathrm{burn}})$。\n- **任务**：对于每个测试用例和每个阈值 $t \\in \\{1.1, 1.05, 1.01\\}$，确定是否发生假收敛事件。\n\n### 步骤 2：使用提取的给定信息进行验证\n对问题陈述进行严格审查，以对照验证标准。\n\n1.  **科学依据**：该问题牢固地植根于贝叶斯逆问题理论和 MCMC 方法。线性高斯模型、pCN 采样器和 LIS 分解是计算统计学和科学计算中标准且有据可查的技术。收敛诊断（$\\hat{R}$ 及其多元扩展）是评估 MCMC 性能的基础工具。没有科学或事实上的违规。\n2.  **形式化能力**：问题以数学精度进行了规定。从模型到采样器和诊断的所有组件都得到了正式定义，允许直接和明确的实现。\n3.  **完整性和一致性**：\n    - 问题为每个测试用例提供了所有必要的参数。\n    - 对收敛诊断的定义已明确。虽然多元 $\\hat{R}$ 的确切公式是函数性描述的（“退化为一元情况……”），但这唯一地指向了文献中的一个标准定义，该定义基于链间和链内协方差矩阵的广义特征值。这不构成致命的歧义，但要求解决者知道或推导出标准形式，这对于教授级专家是合适的。\n    - LIS 定义中有一个小的不一致之处，即 $\\tau  0$，但测试用例 3 使用了 $\\tau = -0.1$。然而，问题陈述立即阐明了意图：“确保几乎必然有 $r=d$”。这解决了不一致性；对非负特征值使用负阈值仅意味着所有维度都包含在 LIS 中。\n    - 在测试用例 3 中，$r = d$，正交补的维度为 0。条件 $\\max_{k} \\hat{R}_k \\ge 1.1$ 必须在空集上评估。逻辑上，此条件为假，因此假收敛事件是不可能的。这不是一个缺陷，而是一个需要由实现来处理的定义明确的边界情况。\n4.  **现实性和可行性**：该问题虽然是一个合成基准，但使用的参数值和维度在计算上是可行的，并代表了在现实世界应用中遇到的挑战。\n5.  **良置性**：如前所述，对多元 $\\hat{R}$ 的标准解释以及对测试用例 3 中边界情况的逻辑处理使问题成为良置的，允许唯一且有意义的解决方案。\n6.  **琐碎性**：问题非同小可，需要实现一个完整的 MCMC 模拟和分析流程，包括数值线性代数和统计计算。被测试的核心概念——依赖于子空间的收敛率导致误导性诊断——是 MCMC 理论中的一个复杂主题。\n7.  **可验证性**：要求使用固定的随机种子确保整个模拟是确定性的，其结果是完全可验证和可复现的。\n\n### 步骤 3：结论与行动\n该问题被判定为**有效**。它规范良好、科学合理且计算上可行。微小的歧义可以通过该领域的标准解释来解决。我现在将继续进行解决方案。\n\n### 解决方案设计与原则\n\n该解决方案涉及模拟一个贝叶斯推断过程并分析其收敛特性。核心思想是展示一个采样器在观察特定的“重要”子空间（LIS）时可能看起来已经收敛，但在互补的“不重要”子空间中仍然混合得很差。这可能导致过早宣布收敛，问题中称之为“假收敛事件”。\n\n**1. 后验与采样器**\n后验分布是一个多元高斯分布。pCN 采样器非常适合此问题，因为其提议是从先验分布中生成的。这一特性，被称为“先验可逆性”，将 Metropolis-Hastings 接受率简化为仅依赖于似然，如 $\\alpha(x, x') = \\min(1, \\exp(-\\Phi(x') + \\Phi(x)))$ 所给出。提议的分块性质允许在 LIS 及其补空间中使用不同的步长（$\\beta_{\\mathrm{LIS}}$, $\\beta_{\\perp}$），使我们能够模拟不同混合率的情景。\n\n**2. 子空间分解**\n似然信息子空间由矩阵 $H = \\frac{1}{\\sigma^2} A^\\top A$ 的特征向量构建。该矩阵与后验精度（协方差的逆）的数据信息部分相关。其主导特征向量对应于参数空间中受数据 $y$ 信息最充分的方向。算法将使用 `scipy.linalg.eigh` 对对称矩阵 $H$ 进行稳定高效的特征分解。特征值大于 $\\tau$ 的特征向量将构成 LIS 的基 $U$，其余特征向量将构成其正交补的基 $Q_\\perp$。\n\n**3. 收敛诊断 (PSRF)**\n势尺度缩减因子 $\\hat{R}$ 是一种比较平行链内部方差与它们之间方差的诊断工具。如果链已收敛到平稳分布，这些方差应该相似，$\\hat{R}$ 将接近 1。\n\n- **一元 $\\hat{R}_k$**：对于正交补空间的每个坐标 $k$，我们计算标准的 Gelman-Rubin 诊断。对于 $n$ 个样本和 $K$ 条链，其平方值为：\n$$\n\\hat{R}_k^2 = \\frac{\\widehat{\\mathrm{Var}}_k}{W_k} = \\frac{\\frac{n-1}{n}W_k + \\frac{1}{n}B_k}{W_k} = \\frac{n-1}{n} + \\frac{B_k}{n W_k}\n$$\n其中 $W_k$ 是坐标 $k$ 的平均链内方差，$B_k$ 是 $n$ 倍的链间方差。\n\n- **多元 $\\hat{R}$**：对于 $r$ 维 LIS 坐标，需要一个多元泛化。遵循它应退化为一元情况并表示最大相对方差膨胀的原则，我们基于涉及链内 ($W_z$) 和链间 ($B_z$) 协方差矩阵的广义特征值问题来定义它：\n$$\n(\\text{m}\\hat{R})^2 = \\frac{n-1}{n} + \\frac{1}{n} \\lambda_{\\max}(W_z^{-1} B_z)\n$$\n其中 $\\lambda_{\\max}(W_z^{-1} B_z)$ 是 $W_z^{-1} B_z$ 的最大特征值。这通过求解广义特征值问题 $B_z v = \\lambda W_z v$ 来实现，以避免矩阵求逆。\n\n**4. 实现策略**\n将开发一个 Python 脚本来执行完整的模拟和分析流程。\n- 一个主函数将管理测试用例并整理结果。\n- 一个核心函数将处理单个测试用例的模拟：生成数据、执行 LIS 分解、运行 $K$ 条 MCMC 链并存储样本。\n- 辅助函数将根据 MCMC 样本计算多元和一元 $\\hat{R}$ 值，封装统计公式。\n- 对于测试用例 3，其中正交补的维度为零，最大一元 $\\hat{R}$ 被认为不满足 $\\ge 1.1$ 的条件，从而正确地不产生假收敛。\n- 所有随机过程都将使用种子以确保确定性输出。最终结果将格式化为小写布尔值的列表。\n\n这种系统化的方法确保了正确性、对问题规范的遵守以及与 MCMC 诊断的既定科学原则的一致性。",
            "answer": "```python\nimport numpy as np\nimport scipy.linalg\n\ndef _compute_mle_r_hat(samples, n, K):\n    \"\"\"\n    Computes the multivariate potential scale reduction factor (m-R-hat).\n    \n    Args:\n        samples (np.ndarray): MCMC samples of shape (K, n, p).\n        n (int): Number of post-burn-in samples.\n        K (int): Number of chains.\n        \n    Returns:\n        float: The multivariate R-hat value.\n    \"\"\"\n    p = samples.shape[2]\n    if p == 0:\n        return 1.0\n\n    # Chain means (shape K, p)\n    chain_means = np.mean(samples, axis=1)\n\n    # Within-chain covariance matrix W (shape p, p)\n    # S_j variable is not explicitly needed, can compute W directly\n    W = np.zeros((p, p))\n    for j in range(K):\n        # np.cov expects (p, n)\n        W += np.cov(samples[j, :, :], rowvar=False, ddof=1)\n    W /= K\n\n    # Check for singularity of W\n    if np.linalg.cond(W)  1e12:\n        return np.inf\n\n    # Between-chain covariance matrix B (shape p, p)\n    B = n * np.cov(chain_means, rowvar=False, ddof=1)\n    \n    # Generalized eigenvalue problem: B v = lambda W v\n    # This is more stable than computing inv(W) @ B\n    try:\n        eigvals = scipy.linalg.eig(B, W, right=True, left=False)\n        # We need the largest real part of the eigenvalues\n        lambda_max = np.max(np.real(eigvals))\n    except (np.linalg.LinAlgError, ValueError):\n        return np.inf\n\n    # Multivariate R-hat squared\n    mR_hat_sq = (n - 1) / n + lambda_max / n\n    \n    if mR_hat_sq  0: # Should not happen with well-behaved chains\n        return np.inf\n        \n    return np.sqrt(mR_hat_sq)\n\ndef _compute_uni_r_hats_max(samples, n, K):\n    \"\"\"\n    Computes the maximum of univariate R-hats over all given dimensions.\n    \n    Args:\n        samples (np.ndarray): MCMC samples of shape (K, n, p).\n        n (int): Number of post-burn-in samples.\n        K (int): Number of chains.\n        \n    Returns:\n        float: The maximum R-hat value, or -inf if p=0.\n    \"\"\"\n    d_perp = samples.shape[2]\n    if d_perp == 0:\n        return -np.inf\n\n    max_r_hat = 0.0\n    for k in range(d_perp):\n        samples_1d = samples[:, :, k]  # Shape (K, n)\n        \n        # Within-chain variances\n        within_chain_vars = np.var(samples_1d, axis=1, ddof=1)\n        W = np.mean(within_chain_vars)\n\n        # Between-chain variance\n        chain_means = np.mean(samples_1d, axis=1)\n        B = n * np.var(chain_means, ddof=1)\n\n        if W  1e-20:\n             # Chains are stuck, if at different points, R-hat is infinite\n            r_hat = 1.0 if B  1e-20 else np.inf\n        else:\n            r_hat_sq = (n - 1) / n + B / (n * W)\n            r_hat = np.sqrt(r_hat_sq)\n        \n        if r_hat  max_r_hat:\n            max_r_hat = r_hat\n            \n    return max_r_hat\n\ndef run_single_case(d, m, sigma, tau, beta_lis, beta_perp, n_tot, n_burn, K, rng):\n    \"\"\"\n    Runs one full test case simulation and analysis.\n    \"\"\"\n    n = n_tot - n_burn\n    \n    # 1. Synthesize problem\n    A = rng.normal(loc=0.0, scale=1.0/np.sqrt(d), size=(m, d))\n    x_star = rng.normal(loc=0.0, scale=1.0, size=d)\n    eta = rng.normal(loc=0.0, scale=sigma, size=m)\n    y = A @ x_star + eta\n\n    # 2. LIS decomposition\n    H = (1 / sigma**2) * (A.T @ A)\n    eigvals, eigvecs = scipy.linalg.eigh(H)\n    \n    lis_indices = eigvals  tau\n    r = np.sum(lis_indices)\n    U = eigvecs[:, lis_indices]\n    Q_perp = eigvecs[:, ~lis_indices]\n    d_perp = d - r\n\n    # 3. Run MCMC chains\n    x_chains = rng.normal(loc=0.0, scale=1.0, size=(K, d))\n    all_samples = np.zeros((K, n_tot, d))\n    \n    def neg_log_likelihood(x_vec):\n        return (0.5 / sigma**2) * np.linalg.norm(y - A @ x_vec)**2\n\n    for j in range(K):\n        x_current = x_chains[j]\n        phi_current = neg_log_likelihood(x_current)\n        for t in range(n_tot):\n            z_current = U.T @ x_current\n            w_current = Q_perp.T @ x_current\n\n            xi_z = rng.standard_normal(size=r)\n            xi_w = rng.standard_normal(size=d_perp)\n            \n            z_prop = np.sqrt(1 - beta_lis**2) * z_current + beta_lis * xi_z\n            w_prop = np.sqrt(1 - beta_perp**2) * w_current + beta_perp * xi_w\n            \n            x_prop = U @ z_prop + Q_perp @ w_prop\n            \n            phi_prop = neg_log_likelihood(x_prop)\n            \n            log_alpha = phi_current - phi_prop\n            \n            if np.log(rng.uniform())  log_alpha:\n                x_current = x_prop\n                phi_current = phi_prop\n\n            all_samples[j, t, :] = x_current\n\n    # 4. Compute diagnostics\n    post_burn_samples = all_samples[:, n_burn:, :]\n    \n    z_samples = post_burn_samples @ U\n    w_samples = post_burn_samples @ Q_perp\n    \n    mR_hat_lis = _compute_mle_r_hat(z_samples, n, K)\n    max_R_hat_perp = _compute_uni_r_hats_max(w_samples, n, K)\n    \n    return mR_hat_lis, max_R_hat_perp\n\n\ndef solve():\n    # Use a fixed random seed for reproducibility\n    rng = np.random.default_rng(42)\n    \n    # Fixed parameters\n    K = 4\n    \n    test_cases = [\n        # TC 1: Poor mixing in orthogonal complement\n        dict(d=128, m=48, sigma=1.0, tau=0.18, \n             beta_lis=0.5, beta_perp=0.02, \n             n_tot=1200, n_burn=300),\n        # TC 2: Good mixing everywhere\n        dict(d=128, m=48, sigma=1.0, tau=0.18,\n             beta_lis=0.5, beta_perp=0.5,\n             n_tot=1200, n_burn=300),\n        # TC 3: No orthogonal complement\n        dict(d=32, m=32, sigma=1.0, tau=-0.1,\n             beta_lis=0.5, beta_perp=0.02,\n             n_tot=900, n_burn=200),\n    ]\n\n    thresholds = [1.1, 1.05, 1.01]\n    results = []\n\n    for case_params in test_cases:\n        mR_hat_lis, max_R_hat_perp = run_single_case(**case_params, K=K, rng=rng)\n        \n        for t in thresholds:\n            converged_lis = mR_hat_lis = t\n            unconverged_perp = max_R_hat_perp = 1.1\n            \n            is_false_convergence = converged_lis and unconverged_perp\n            results.append(is_false_convergence)\n\n    # Format output as a list of lowercase boolean strings\n    output_str = f\"[{','.join(map(lambda b: str(b).lower(), results))}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}