{
    "hands_on_practices": [
        {
            "introduction": "为了开始我们的动手实践，首先需要理解活性子空间矩阵 $C$ 的构造和性质。第一个练习  将引导您在一个基础的线性高斯反演问题中推导 $C$，揭示其作为Fisher信息矩阵的本质。通过一个具体的计算，您将巩固对参数敏感性的主导方向如何被编码在 $C$ 的特征值和特征向量中的理解。",
            "id": "3362741",
            "problem": "考虑一个加性高斯噪声的线性逆问题，由 $y = A \\theta + \\eta$ 给出，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个已知的正演算子，$\\theta \\in \\mathbb{R}^{n}$ 是目标参数，而 $\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\eta})$ 是高斯噪声，其具有已知的对称正定协方差矩阵 $\\Gamma_{\\eta} \\in \\mathbb{R}^{m \\times m}$。负对数似然（在不考虑一个与 $\\theta$ 无关的加性常数的情况下）定义为\n$\\ell(\\theta; y) = \\frac{1}{2} (y - A \\theta)^{\\top} \\Gamma_{\\eta}^{-1} (y - A \\theta)$。\n定义活性子空间矩阵\n$C = \\mathbb{E}_{y \\mid \\theta} \\left[ \\nabla_{\\theta} \\ell(\\theta; y) \\, \\nabla_{\\theta} \\ell(\\theta; y)^{\\top} \\right]$，\n其中期望是关于给定 $\\theta$ 时 $y$ 的条件分布计算的。仅使用高斯似然的基本定义以及梯度和期望的基本性质来：\n\n1. 用 $A$ 和 $\\Gamma_{\\eta}$ 明确地推导出 $C$，并证明 $C$ 的特征向量与 $\\Gamma_{\\eta}^{-1/2} A$ 的非零奇异值所对应的右奇异向量一致。解释非活性方向（即与 $C$ 的零特征值相关的方向）与逆问题中的不可辨识性之间的关系。\n\n2. 对于具体实例\n$A = \\begin{pmatrix} 2  0  0 \\\\ 0  1  1 \\end{pmatrix}$ 和 $\\Gamma_{\\eta} = \\mathrm{diag}(1, 4)$，\n计算 $C$ 的特征值，并确定最小活性维度 $r$，使得最大的 $r$ 个特征值的和至少是 $C$ 的迹的 $\\alpha = 0.95$ 倍；也就是说，找到最小的整数 $r$ 满足\n$\\sum_{i=1}^{r} \\lambda_{i} \\ge \\alpha \\sum_{i=1}^{n} \\lambda_{i}$，\n其中 $\\lambda_{1} \\ge \\lambda_{2} \\ge \\cdots \\ge \\lambda_{n} \\ge 0$ 是 $C$ 按非增序排列的特征值。\n\n给出你的最终答案，为 $r$ 的单个整数值。不需要单位。除了精确算术外，不需要进行舍入。",
            "solution": "该问题分为两部分。首先，我们推导线性高斯逆问题的活性子空间矩阵 $C$ 并分析其性质。其次，我们针对一个具体实例计算 $C$ 并根据其特征值谱确定最小活性维度 $r$。\n\n### 第1部分：活性子空间矩阵 $C$ 的推导与分析\n\n负对数似然函数由下式给出\n$$ \\ell(\\theta; y) = \\frac{1}{2} (y - A \\theta)^{\\top} \\Gamma_{\\eta}^{-1} (y - A \\theta) $$\n其中 $y \\in \\mathbb{R}^{m}$，$\\theta \\in \\mathbb{R}^{n}$，$A \\in \\mathbb{R}^{m \\times n}$，且 $\\Gamma_{\\eta} \\in \\mathbb{R}^{m \\times m}$ 是对称正定矩阵。\n\n**1. $C$ 的推导**\n\n首先，我们计算 $\\ell(\\theta; y)$ 关于 $\\theta$ 的梯度。展开二次型：\n$$ \\ell(\\theta; y) = \\frac{1}{2} (y^{\\top}\\Gamma_{\\eta}^{-1}y - y^{\\top}\\Gamma_{\\eta}^{-1}A\\theta - \\theta^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}y + \\theta^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}A\\theta) $$\n由于 $\\ell(\\theta; y)$ 是一个标量，项 $y^{\\top}\\Gamma_{\\eta}^{-1}A\\theta$ 等于其转置。因为 $\\Gamma_{\\eta}$ 是对称的，所以矩阵 $\\Gamma_{\\eta}^{-1}$ 也是对称的。因此，$(y^{\\top}\\Gamma_{\\eta}^{-1}A\\theta)^{\\top} = \\theta^{\\top}A^{\\top}(\\Gamma_{\\eta}^{-1})^{\\top}y = \\theta^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}y$。该表达式简化为：\n$$ \\ell(\\theta; y) = \\frac{1}{2} (y^{\\top}\\Gamma_{\\eta}^{-1}y - 2 \\theta^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}y + \\theta^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}A\\theta) $$\n使用标准的矩阵微积分恒等式，对于对称矩阵 $B$，有 $\\nabla_{x}(c^{\\top}x) = c$ 和 $\\nabla_{x}(x^{\\top}Bx) = 2Bx$，我们求出关于 $\\theta$ 的梯度：\n$$ \\nabla_{\\theta} \\ell(\\theta; y) = \\frac{1}{2} (-2 A^{\\top}\\Gamma_{\\eta}^{-1}y + 2 A^{\\top}\\Gamma_{\\eta}^{-1}A\\theta) = A^{\\top}\\Gamma_{\\eta}^{-1}A\\theta - A^{\\top}\\Gamma_{\\eta}^{-1}y = A^{\\top}\\Gamma_{\\eta}^{-1}(A\\theta - y) $$\n活性子空间矩阵 $C$ 定义为该梯度的外积的期望：\n$$ C = \\mathbb{E}_{y \\mid \\theta} \\left[ \\nabla_{\\theta} \\ell(\\theta; y) \\, \\nabla_{\\theta} \\ell(\\theta; y)^{\\top} \\right] $$\n代入梯度的表达式：\n$$ C = \\mathbb{E}_{y \\mid \\theta} \\left[ \\left( A^{\\top}\\Gamma_{\\eta}^{-1}(A\\theta - y) \\right) \\left( A^{\\top}\\Gamma_{\\eta}^{-1}(A\\theta - y) \\right)^{\\top} \\right] $$\n$$ C = \\mathbb{E}_{y \\mid \\theta} \\left[ A^{\\top}\\Gamma_{\\eta}^{-1}(A\\theta - y)(A\\theta - y)^{\\top}\\Gamma_{\\eta}^{-1}A \\right] $$\n由于 $A$ 和 $\\Gamma_{\\eta}$ 相对于关于 $y$ 的期望是常数，我们可以将它们移到外面：\n$$ C = A^{\\top}\\Gamma_{\\eta}^{-1} \\mathbb{E}_{y \\mid \\theta} \\left[ (A\\theta - y)(A\\theta - y)^{\\top} \\right] \\Gamma_{\\eta}^{-1}A $$\n根据问题陈述，$y = A\\theta + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\eta})$。这意味着 $A\\theta - y = -\\eta$。因此，期望是关于 $(-\\eta)(-\\eta)^{\\top} = \\eta\\eta^{\\top}$ 的。\n$$ \\mathbb{E}_{y \\mid \\theta} \\left[ (A\\theta - y)(A\\theta - y)^{\\top} \\right] = \\mathbb{E}[\\eta\\eta^{\\top}] $$\n根据定义，零均值随机向量 $\\eta$ 的协方差矩阵是 $\\text{Cov}(\\eta) = \\mathbb{E}[(\\eta-\\mathbb{E}[\\eta])(\\eta-\\mathbb{E}[\\eta])^{\\top}] = \\mathbb{E}[\\eta\\eta^{\\top}]$。我们已知 $\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\eta})$，所以 $\\mathbb{E}[\\eta\\eta^{\\top}] = \\Gamma_{\\eta}$。\n将此代回 $C$ 的表达式中：\n$$ C = A^{\\top}\\Gamma_{\\eta}^{-1} \\Gamma_{\\eta} \\Gamma_{\\eta}^{-1}A = A^{\\top}\\Gamma_{\\eta}^{-1}A $$\n这就是 $C$ 的显式形式。这也是 $\\theta$ 的费雪信息矩阵。\n\n**2. $C$ 的特征向量与 $\\Gamma_{\\eta}^{-1/2} A$ 的奇异向量**\n\n令 $B = \\Gamma_{\\eta}^{-1/2} A$。由于 $\\Gamma_{\\eta}$ 是对称正定的，其逆矩阵 $\\Gamma_{\\eta}^{-1}$ 和平方根 $\\Gamma_{\\eta}^{-1/2}$ 存在且也是对称正定的。我们可以将 $C$ 表示为：\n$$ C = A^{\\top}\\Gamma_{\\eta}^{-1}A = A^{\\top}(\\Gamma_{\\eta}^{-1/2})^{\\top}\\Gamma_{\\eta}^{-1/2}A = ( \\Gamma_{\\eta}^{-1/2} A )^{\\top} ( \\Gamma_{\\eta}^{-1/2} A ) = B^{\\top}B $$\n设 $B = \\Gamma_{\\eta}^{-1/2} A$ 的奇异值分解 (SVD) 为 $B = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是由奇异值 $\\sigma_{i} \\ge 0$ 构成的对角矩阵。$V$ 的列是 $B$ 的右奇异向量。\n现在，将 SVD 代入 $C$ 的表达式中：\n$$ C = B^{\\top}B = (U \\Sigma V^{\\top})^{\\top} (U \\Sigma V^{\\top}) = (V \\Sigma^{\\top} U^{\\top}) (U \\Sigma V^{\\top}) $$\n由于 $U$ 是正交的，$U^{\\top}U = I_{m}$。\n$$ C = V \\Sigma^{\\top} (U^{\\top}U) \\Sigma V^{\\top} = V (\\Sigma^{\\top}\\Sigma) V^{\\top} $$\n矩阵 $V$ 是正交的，所以 $V^{\\top} = V^{-1}$。方程 $C = V (\\Sigma^{\\top}\\Sigma) V^{-1}$ 是 $C$ 的特征分解。$V$ 的列是 $C$ 的特征向量。矩阵 $\\Sigma^{\\top}\\Sigma$ 是一个 $n \\times n$ 的对角矩阵，其元素对于 $i=1, \\dots, \\min(m,n)$ 是 $\\sigma_i^2$，其余为零。因此，$C$ 的特征值是 $B = \\Gamma_{\\eta}^{-1/2} A$ 的奇异值的平方。\n因此，$C$ 的特征向量恰好是 $\\Gamma_{\\eta}^{-1/2} A$ 的右奇异向量。\n\n**3. 非活性方向与不可辨识性**\n\n非活性方向被定义为与 $C$ 的零特征值相关的特征向量。设 $v$ 是 $C$ 的一个特征向量，其特征值为 $\\lambda=0$。那么，$Cv=0$。\n$$ C v = (A^{\\top}\\Gamma_{\\eta}^{-1}A)v = 0 $$\n从左边乘以 $v^{\\top}$：\n$$ v^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}A v = 0 $$\n这可以写成 $(Av)^{\\top}\\Gamma_{\\eta}^{-1}(Av) = 0$。令 $w = Av$。则 $w^{\\top}\\Gamma_{\\eta}^{-1}w = 0$。由于 $\\Gamma_{\\eta}$ 是对称正定的，$\\Gamma_{\\eta}^{-1}$ 也是对称正定的。根据正定性的定义，对于任何非零向量 $w \\in \\mathbb{R}^m$，都有 $w^{\\top}\\Gamma_{\\eta}^{-1}w > 0$。因此，$w^{\\top}\\Gamma_{\\eta}^{-1}w=0$ 意味着 $w=0$。\n所以，我们必须有 $Av = 0$。这意味着 $v$ 位于正演算子 $A$ 的零空间中。$A$ 的零空间中的任何向量都无法从数据中辨识。具体来说，如果我们用 $v$ 的一个倍数来扰动参数向量 $\\theta$，即 $\\theta' = \\theta + k v$（其中 $k$ 是某个标量），模型的预测保持不变：\n$$ A \\theta' = A(\\theta + k v) = A\\theta + k(Av) = A\\theta + k(0) = A\\theta $$\n由于数据 $y$ 仅通过 $A\\theta$ 依赖于 $\\theta$，数据没有提供任何信息来区分 $\\theta$ 和 $\\theta'$。沿着方向 $v$ 的参数组合是不可辨识的。由 $C$ 的零特征值的特征向量张成的空间是 $A$ 的零空间，它代表了所有不可辨识的参数方向的集合。\n\n### 第2部分：具体计算\n\n我们得到具体实例：\n$$ A = \\begin{pmatrix} 2  0  0 \\\\ 0  1  1 \\end{pmatrix} \\quad \\text{和} \\quad \\Gamma_{\\eta} = \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix} $$\n首先，我们计算协方差矩阵的逆：\n$$ \\Gamma_{\\eta}^{-1} = \\begin{pmatrix} 1^{-1}  0 \\\\ 0  4^{-1} \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  \\frac{1}{4} \\end{pmatrix} $$\n接下来，我们计算活性子空间矩阵 $C = A^{\\top}\\Gamma_{\\eta}^{-1}A$。$A$ 的转置是：\n$$ A^{\\top} = \\begin{pmatrix} 2  0 \\\\ 0  1 \\\\ 0  1 \\end{pmatrix} $$\n现在，我们进行矩阵乘法：\n$$ C = \\begin{pmatrix} 2  0 \\\\ 0  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  \\frac{1}{4} \\end{pmatrix} \\begin{pmatrix} 2  0  0 \\\\ 0  1  1 \\end{pmatrix} $$\n$$ C = \\begin{pmatrix} 2  0 \\\\ 0  \\frac{1}{4} \\\\ 0  \\frac{1}{4} \\end{pmatrix} \\begin{pmatrix} 2  0  0 \\\\ 0  1  1 \\end{pmatrix} = \\begin{pmatrix} (2)(2) + (0)(0)  (2)(0) + (0)(1)  (2)(0) + (0)(1) \\\\ (0)(2) + (\\frac{1}{4})(0)  (0)(0) + (\\frac{1}{4})(1)  (0)(0) + (\\frac{1}{4})(1) \\\\ (0)(2) + (\\frac{1}{4})(0)  (0)(0) + (\\frac{1}{4})(1)  (0)(0) + (\\frac{1}{4})(1) \\end{pmatrix} $$\n$$ C = \\begin{pmatrix} 4  0  0 \\\\ 0  \\frac{1}{4}  \\frac{1}{4} \\\\ 0  \\frac{1}{4}  \\frac{1}{4} \\end{pmatrix} $$\n为了找到 $C$ 的特征值 $\\lambda$，我们求解特征方程 $\\det(C - \\lambda I) = 0$：\n$$ \\det \\begin{pmatrix} 4-\\lambda  0  0 \\\\ 0  \\frac{1}{4}-\\lambda  \\frac{1}{4} \\\\ 0  \\frac{1}{4}  \\frac{1}{4}-\\lambda \\end{pmatrix} = 0 $$\n$$ (4-\\lambda) \\left[ \\left(\\frac{1}{4}-\\lambda\\right)^2 - \\left(\\frac{1}{4}\\right)^2 \\right] = 0 $$\n这个方程立即给出一个特征值：$\\lambda = 4$。另外两个特征值可以从括号中的项得到：\n$$ \\left(\\frac{1}{4}-\\lambda\\right)^2 - \\frac{1}{16} = 0 \\implies \\left(\\frac{1}{4}-\\lambda\\right)^2 = \\frac{1}{16} $$\n$$ \\frac{1}{4}-\\lambda = \\pm \\frac{1}{4} $$\n这给出了两种可能性：\n1. $\\frac{1}{4}-\\lambda = \\frac{1}{4} \\implies \\lambda = 0$\n2. $\\frac{1}{4}-\\lambda = -\\frac{1}{4} \\implies \\lambda = \\frac{1}{4} + \\frac{1}{4} = \\frac{1}{2}$\n$C$ 的特征值为 $\\{4, \\frac{1}{2}, 0\\}$。我们按非增序排列它们：$\\lambda_{1} = 4$，$\\lambda_{2} = \\frac{1}{2}$，$\\lambda_{3} = 0$。\n\n$C$ 的迹是其特征值的和：\n$$ \\text{Tr}(C) = \\sum_{i=1}^{3} \\lambda_{i} = 4 + \\frac{1}{2} + 0 = 4.5 $$\n我们需要找到最小的整数 $r$，使得前 $r$ 个最大特征值的和至少是总和（迹）的 $\\alpha = 0.95$ 倍。阈值是：\n$$ \\alpha \\sum_{i=1}^{3} \\lambda_{i} = 0.95 \\times 4.5 = \\frac{19}{20} \\times \\frac{9}{2} = \\frac{171}{40} = 4.275 $$\n我们检查有序特征值的累积和：\n对于 $r=1$：\n$$ \\sum_{i=1}^{1} \\lambda_{i} = \\lambda_{1} = 4 $$\n由于 $4  4.275$，条件不满足。\n对于 $r=2$：\n$$ \\sum_{i=1}^{2} \\lambda_{i} = \\lambda_{1} + \\lambda_{2} = 4 + \\frac{1}{2} = 4.5 $$\n由于 $4.5 \\ge 4.275$，条件满足。\n满足条件的最小整数 $r$ 是 $2$。",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "现实世界中的模型很少是线性的，这给敏感性分析带来了重要的复杂性。这个练习  提出了一个非线性前向模型，用以比较全局平均的活性子空间与局部定义的似然信息子空间 (LIS) 方法。通过计算这两个子空间并发现它们是正交的，您将深刻洞察局部与全局降维方法之间的关键区别。",
            "id": "3362773",
            "problem": "考虑一个贝叶斯逆问题，其参数向量为二维的 $x \\in \\mathbb{R}^{2}$，先验为高斯分布 $x \\sim \\mathcal{N}(0, I)$，观测模型为带有单位噪声协方差的高斯模型。正向模型是由下式给出的非线性映射 $G:\\mathbb{R}^{2} \\to \\mathbb{R}^{2}$：\n$$\nG(x) = \\begin{pmatrix} x_{1} \\\\ x_{2}^{3} \\end{pmatrix}.\n$$\n设观测数据为 $y = G(0) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。定义负对数后验（在相差一个加性常数的意义下）为\n$$\n\\Phi(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2} + \\frac{1}{2}\\|x\\|_{2}^{2},\n$$\n其中 $\\|\\cdot\\|_{2}$ 表示欧几里得范数。假设最大后验 (MAP) 点为 $x_{\\ast} = 0$。\n\n我们对两种子空间构造感兴趣：\n- 似然信息子空间 (Likelihood-Informed Subspace, LIS)，它由在 MAP 点处的负对数似然的黑塞矩阵的高斯-牛顿近似构造而来。对于单位噪声协方差，该近似简化为矩阵 $J(x_{\\ast})^{\\top}J(x_{\\ast})$，其中 $J(x)$ 是 $G$ 在 $x$ 处的雅可比矩阵。\n- 最小二乘失配 $m(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2}$ 的梯度-协方差活性子空间，定义为矩阵\n$$\nC = \\mathbb{E}_{x \\sim \\mathcal{N}(0, I)}\\left[\\nabla m(x)\\,\\nabla m(x)^{\\top}\\right]\n$$\n的主特征向量所张成的空间。\n\n计算针对此问题得到的一维 LIS 和一维梯度-协方差活性子空间之间的主角。以弧度为单位，将最终答案表示为精确值。然后，从第一性原理出发，解释为什么在这个非线性例子中这两个子空间不同，并指出这两种构造之间差异的来源。",
            "solution": "该问题要求计算从一个贝叶斯逆问题设置中派生出的两个一维子空间——似然信息子空间 (LIS) 和梯度-协方差活性子空间——之间的主角。它还要求从第一性原理出发，解释为什么这些子空间不同。\n\n首先，我们验证问题陈述。\n给定信息如下：\n- 参数向量：$x = (x_1, x_2)^{\\top} \\in \\mathbb{R}^{2}$\n- 先验分布：$x \\sim \\mathcal{N}(0, I)$，其中 $I$ 是 $2 \\times 2$ 单位矩阵。\n- 正向模型：$G(x) = \\begin{pmatrix} x_{1} \\\\ x_{2}^{3} \\end{pmatrix}$\n- 观测模型：高斯模型，具有单位噪声协方差。\n- 观测数据：$y = G(0) = (0, 0)^{\\top}$\n- 负对数后验（忽略一个常数）：$\\Phi(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2} + \\frac{1}{2}\\|x\\|_{2}^{2}$\n- 最大后验 (MAP) 点：$x_{\\ast} = (0, 0)^{\\top}$\n- LIS 定义：在 MAP 点处，负对数似然的黑塞矩阵的高斯-牛顿近似 $J(x_{\\ast})^{\\top}J(x_{\\ast})$ 的主特征向量所张成的空间。\n- 活性子空间 (AS) 定义：矩阵 $C = \\mathbb{E}_{x \\sim \\mathcal{N}(0, I)}\\left[\\nabla m(x)\\,\\nabla m(x)^{\\top}\\right]$ 的主特征向量所张成的空间，其中 $m(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2}$。\n\n该问题在逆问题和不确定性量化领域有科学依据，数学上是适定的，内部一致，并使用了精确、客观的语言。所有必要的信息都已提供。因此，该问题是有效的。\n\n我们分三部分进行求解：计算 LIS，计算活性子空间，以及计算主角，然后给出所要求的解释。\n\n**1. 似然信息子空间 (LIS) 的计算**\n\nLIS 是根据在 MAP 点 $x_{\\ast} = 0$ 处求值的负对数似然的黑塞矩阵的高斯-牛顿近似来构造的。负对数似然函数为 $l(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2}$。高斯-牛顿黑塞矩阵由 $H_{GN} = J(x_{\\ast})^{\\top}J(x_{\\ast})$ 给出，其中 $J(x)$ 是正向模型 $G(x)$ 的雅可比矩阵。\n\n正向模型为 $G(x) = \\begin{pmatrix} x_{1} \\\\ x_{2}^{3} \\end{pmatrix}$。其雅可比矩阵 $J(x)$ 是：\n$$\nJ(x) = \\frac{\\partial G}{\\partial x} = \\begin{pmatrix} \\frac{\\partial (x_1)}{\\partial x_1}  \\frac{\\partial (x_1)}{\\partial x_2} \\\\ \\frac{\\partial (x_2^3)}{\\partial x_1}  \\frac{\\partial (x_2^3)}{\\partial x_2} \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  3x_{2}^{2} \\end{pmatrix}\n$$\n我们在 MAP 点 $x_{\\ast} = (0, 0)^{\\top}$ 处计算雅可比矩阵：\n$$\nJ(x_{\\ast}) = J(0) = \\begin{pmatrix} 1  0 \\\\ 0  3(0)^{2} \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}\n$$\n现在，我们计算高斯-牛顿黑塞矩阵：\n$$\nH_{GN} = J(0)^{\\top}J(0) = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}^{\\top} \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}\n$$\n$H_{GN}$ 的特征值为 $\\lambda_1 = 1$ 和 $\\lambda_2 = 0$。对应的特征向量分别为 $u_1 = (1, 0)^{\\top}$ 和 $u_2 = (0, 1)^{\\top}$。一维 LIS 是对应于最大特征值的特征向量所张成的空间。\n因此，LIS 由向量 $u_1 = (1, 0)^{\\top}$ 张成。\n\n**2. 梯度-协方差活性子空间 (AS) 的计算**\n\n活性子空间由矩阵 $C = \\mathbb{E}_{x \\sim \\mathcal{N}(0, I)}\\left[\\nabla m(x)\\,\\nabla m(x)^{\\top}\\right]$ 的特征系统定义。\n首先，我们求出标量值函数 $m(x)$，即最小二乘失配。当 $y = (0, 0)^{\\top}$ 时，我们有：\n$$\nm(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2} = \\frac{1}{2}\\left\\| \\begin{pmatrix} x_1 \\\\ x_2^3 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\right\\|_{2}^{2} = \\frac{1}{2}(x_1^2 + x_2^6)\n$$\n接下来，我们计算 $m(x)$ 的梯度：\n$$\n\\nabla m(x) = \\begin{pmatrix} \\frac{\\partial m}{\\partial x_1} \\\\ \\frac{\\partial m}{\\partial x_2} \\end{pmatrix} = \\begin{pmatrix} x_1 \\\\ 3x_2^5 \\end{pmatrix}\n$$\n现在我们构造外积 $\\nabla m(x)\\,\\nabla m(x)^{\\top}$：\n$$\n\\nabla m(x)\\,\\nabla m(x)^{\\top} = \\begin{pmatrix} x_1 \\\\ 3x_2^5 \\end{pmatrix} \\begin{pmatrix} x_1  3x_2^5 \\end{pmatrix} = \\begin{pmatrix} x_1^2  3x_1x_2^5 \\\\ 3x_1x_2^5  9x_2^{10} \\end{pmatrix}\n$$\n矩阵 $C$ 是该矩阵在先验分布 $x \\sim \\mathcal{N}(0, I)$ 下的期望。这意味着 $x_1$ 和 $x_2$ 是独立的标准正态随机变量，$x_1, x_2 \\sim \\mathcal{N}(0, 1)$。我们计算每个元素的期望：\n$$\nC = \\begin{pmatrix} \\mathbb{E}[x_1^2]  \\mathbb{E}[3x_1x_2^5] \\\\ \\mathbb{E}[3x_1x_2^5]  \\mathbb{E}[9x_2^{10}] \\end{pmatrix}\n$$\n对于标准正态变量 $Z \\sim \\mathcal{N}(0, 1)$，其矩为：当 $k$ 为奇数时 $\\mathbb{E}[Z^k] = 0$，当 $k=2n$ 时 $\\mathbb{E}[Z^{2n}] = (2n-1)!! = (2n-1)(2n-3)\\cdots 1$。\n- $\\mathbb{E}[x_1^2] = 1$。\n- 由于独立性，$\\mathbb{E}[3x_1x_2^5] = 3\\,\\mathbb{E}[x_1]\\,\\mathbb{E}[x_2^5] = 3 \\cdot 0 \\cdot 0 = 0$。\n- $\\mathbb{E}[x_2^{10}] = (10-1)!! = 9!! = 9 \\cdot 7 \\cdot 5 \\cdot 3 \\cdot 1 = 945$。\n- $\\mathbb{E}[9x_2^{10}] = 9 \\cdot \\mathbb{E}[x_2^{10}] = 9 \\cdot 945 = 8505$。\n\n将这些值代回矩阵 $C$：\n$$\nC = \\begin{pmatrix} 1  0 \\\\ 0  8505 \\end{pmatrix}\n$$\n这个对角矩阵的特征值为 $\\mu_1 = 8505$ 和 $\\mu_2 = 1$。对应的特征向量分别为 $v_1 = (0, 1)^{\\top}$ 和 $v_2 = (1, 0)^{\\top}$。一维活性子空间是对应于最大特征值的特征向量所张成的空间。\n因此，活性子空间由向量 $v_1 = (0, 1)^{\\top}$ 张成。\n\n**3. 主角的计算**\n\n由单位向量 $u = (1, 0)^{\\top}$ (对于LIS) 和 $v = (0, 1)^{\\top}$ (对于AS) 张成的两个一维子空间（直线）之间的主角 $\\theta$ 由以下公式给出：\n$$\n\\cos(\\theta) = |u^{\\top}v|\n$$\n计算内积：\n$$\nu^{\\top}v = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = 1 \\cdot 0 + 0 \\cdot 1 = 0\n$$\n因此，$\\cos(\\theta) = 0$。主角为 $\\theta = \\arccos(0) = \\frac{\\pi}{2}$ 弧度。这两个子空间是正交的。\n\n**4. 差异解释**\n\nLIS 和活性子空间之间差异的根本原因在于它们的构造方式：LIS 是一种*局部*方法，而活性子空间是一种*全局*方法。\n\n**似然信息子空间 (LIS)** 基于正向模型 $G(x)$ 在单一点（即 MAP 估计 $x_{\\ast}$）周围的线性化。高斯-牛顿黑塞矩阵 $J(x_{\\ast})^{\\top}J(x_{\\ast})$ 衡量了模型输出对 $x_{\\ast}$ 周围无穷小扰动的敏感度。在这个问题中，$x_{\\ast}=0$。在该点，雅可比矩阵为 $J(0) = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}$。$(2,2)$ 位置的零是由于非线性项 $x_2^3$ 的导数 $3x_2^2$ 在 $x_2=0$ 处的值为 $0$。因此，模型在原点附近的局部线性近似 $G(\\delta x) \\approx J(0)\\delta x = (\\delta x_1, 0)^{\\top}$ 对 $x_2$ 方向的扰动完全不敏感。LIS 的构造仅依赖于此局部信息，因此正确地得出结论：在 MAP 点处，受似然信息影响的方向是 $x_1$ 方向。它对偏离该特定点的任何敏感性都视而不见。\n\n与此相反，**活性子空间 (AS)** 基于全局敏感性分析。矩阵 $C = \\mathbb{E}[\\nabla m(x) \\nabla m(x)^{\\top}]$ 将失配函数 $m(x)$ 的敏感性在整个参数空间上进行平均，并由先验概率分布加权。失配的梯度是 $\\nabla m(x) = (x_1, 3x_2^5)^{\\top}$。项 $3x_2^5$ 在 $x_2=0$ 时为零，但随着 $|x_2|$ 的增加而迅速增长。$C$ 矩阵 $(2,2)$ 分量的期望积分涉及 $\\mathbb{E}[9x_2^{10}]$，它将这种快速增长的敏感性在由先验决定的所有 $x_2$ 可能值上的贡献进行求和。这导致了一个非常大的值 ($8505$)，表明失配函数对参数 $x_2$ 具有巨大的平均敏感性。而 $x_1$ 分量的期望 $\\mathbb{E}[x_1^2]$ 仅为 $1$。因此，活性子空间的构造正确地识别出 $x_2$ 方向是失配函数平均变化最大的方向，使其成为从全局角度看参数敏感性的主导方向。\n\n总而言之，这种差异是正向模型在 $x_2$ 变量上强非线性的直接结果。LIS 方法是局部的，因此被 $x_2^3$ 在线性化点 $x_2=0$ 处的消失导数所“欺骗”。活性子空间方法是全局的，它在整个先验上进行积分，并正确捕捉到强非线性项 $x_2$ 的主导影响。这两个子空间的正交性代表了该问题的局部和全局敏感性分析之间的完全不一致。",
            "answer": "$$\\boxed{\\frac{\\pi}{2}}$$"
        },
        {
            "introduction": "在学习了如何识别活性子空间之后，下一个自然而然的步骤是利用这些知识来获得实际的益处。最后一个练习  是一个动手编程问题，它将活性子空间的概念应用于优化实验设计。您将实现一个策略来选择传感器，使其对于由活性子空间识别出的主导参数方向最为敏感，从而提供一个具体的例子，说明这种降维技术如何指导科学研究。",
            "id": "3362746",
            "problem": "考虑一个传感器选择设计下的线性高斯逆问题。设未知参数为一个向量 $u \\in \\mathbb{R}^d$，其服从标准高斯先验。假设每个潜在的传感器 $i$ 产生一个线性测量 $y_i = s_i^\\top u + \\varepsilon_i$，其中 $s_i \\in \\mathbb{R}^d$ 是第 $i$ 个候选传感器的行向量，$\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ 是方差为 $\\sigma^2$ 的独立高斯噪声。如果从 $p$ 个候选中选择了一组包含 $m$ 个传感器的集合 $\\mathcal{S}$，那么其信息贡献（为设计目的忽略先验）由对称正半定矩阵表示\n$$\nC(\\mathcal{S}) = \\frac{1}{\\sigma^2} \\sum_{i \\in \\mathcal{S}} s_i s_i^\\top \\in \\mathbb{R}^{d \\times d}.\n$$\n对于任意单位方向 $v \\in \\mathbb{S}^{d-1}$，瑞利商 $v^\\top C(\\mathcal{S}) v$ 衡量了所选传感器沿方向 $v$ 的信息集中度。\n\n活性子空间降维方法通过一个标量关注量 $q(u)$ 的梯度协方差矩阵来形式化一个优选方向，\n$$\nC_{\\text{active}} = \\mathbb{E}\\left[ \\nabla q(u) \\nabla q(u)^\\top \\right],\n$$\n其主特征向量确定了主导的一维活性子空间。在此问题中，您将使用一个形式化但科学上一致的 $C_{\\text{active}}$ 代理模型，以设计能够最大化沿一个知情方向的瑞利商的传感器，并与一个朴素方向进行比较。\n\n使用的基本原理和约束：\n- 瑞利商性质：对于任意对称正半定矩阵 $M$ 和单位向量 $v$，$v^\\top M v \\in [0, \\lambda_{\\max}(M)]$，其中 $\\lambda_{\\max}(M)$ 是 $M$ 的最大特征值。\n- 对于一组传感器行 $\\{s_i\\}$ 和一个单位方向 $v$，$v^\\top C(\\mathcal{S}) v = \\frac{1}{\\sigma^2} \\sum_{i \\in \\mathcal{S}} (s_i^\\top v)^2$。\n- 活性子空间矩阵被建模为一个低秩对称正半定矩阵，它是由单位向量 $a$ 和 $b$ 的秩一分量之和构成，反映了 $\\nabla q(u)$ 的主导方向。\n\n设计问题说明：\n- 感知活性子空间的设计：选择一组包含 $m$ 个传感器的集合 $\\mathcal{S}_{\\text{AS}}$，使得当 $v$ 是 $C_{\\text{active}}$ 的主特征向量时，$v^\\top C(\\mathcal{S}) v$ 最大化。\n- 朴素设计：选择一组包含 $m$ 个传感器的集合 $\\mathcal{S}_{\\text{NV}}$，使得当 $v$ 是第一个坐标轴 $e_1 = (1,0,\\dots,0)^\\top$ 时，$v^\\top C(\\mathcal{S}) v$ 最大化。\n- 为每个测试用例报告的比较指标：比率\n$$\nR = \\frac{v_{\\text{true}}^\\top C(\\mathcal{S}_{\\text{AS}}) v_{\\text{true}}}{v_{\\text{true}}^\\top C(\\mathcal{S}_{\\text{NV}}) v_{\\text{true}}},\n$$\n其中 $v_{\\text{true}}$ 是 $C_{\\text{active}}$ 的主特征向量，且所有向量均为单位范数。\n\n活性方向和候选传感器的构造：\n- 活性子空间代理 $C_{\\text{active}}$ 由两个单位向量 $a,b \\in \\mathbb{R}^d$ 指定，其分量定义为\n$$\na_j = \\cos(j+1), \\quad b_j = \\sin(2j+1), \\quad \\text{对于 } j \\in \\{0,1,\\dots,d-1\\},\n$$\n然后归一化为单位范数，使得 $\\|a\\|_2 = 1$ 和 $\\|b\\|_2 = 1$。该矩阵为\n$$\nC_{\\text{active}} = a a^\\top + \\rho \\, b b^\\top,\n$$\n其中 $\\rho  0$ 是一个给定的权重，角度应解释为弧度。\n- $p$ 个候选传感器行 $s_i^\\top$ 构成一个 $p \\times d$ 矩阵 $S$。其元素定义为\n$$\ns_{i,j} = \\sin\\!\\big((i+1)(j+1)\\big) + 0.25\\,\\cos(i + 2j),\n$$\n对于 $i \\in \\{0,1,\\dots,p-1\\}$ 和 $j \\in \\{0,1,\\dots,d-1\\}$，角度单位为弧度。\n- 传感器噪声方差为 $\\sigma^2$。\n\n算法要求：\n- 对于任何固定的单位方向 $v$，在 $|\\mathcal{S}| = m$ 的约束下，最大化 $v^\\top C(\\mathcal{S}) v$ 的集合 $\\mathcal{S}$ 由对应于 $(s_i^\\top v)^2$ 最大值的 $m$ 个索引组成。利用这一事实来构造 $\\mathcal{S}_{\\text{AS}}$ 和 $\\mathcal{S}_{\\text{NV}}$。\n- 评估方向 $v_{\\text{true}}$ 是 $C_{\\text{active}}$ 的主特征向量（单位范数）。\n- 矩阵 $C(\\mathcal{S})$ 根据所选的行和 $\\sigma^2$ 精确计算。\n\n测试套件：\n实现您的程序，为以下每个测试用例计算 $R$。所有三角函数参数均为弧度，且每个指定的向量都必须进行归一化。\n- 用例 1 (理想情况): $d=6$, $p=14$, $m=3$, $\\sigma^2=0.25$, $\\rho=0.25$。\n- 用例 2 ($m$ 的边界情况): $d=6$, $p=14$, $m=1$, $\\sigma^2=1.0$, $\\rho=1.0$。\n- 用例 3 (更高维度和噪声): $d=8$, $p=20$, $m=4$, $\\sigma^2=4.0$, $\\rho=0.05$。\n\n您的任务：\n- 编写一个完整的、可运行的程序，该程序构造 $S$、$C_{\\text{active}}$ 并计算 $v_{\\text{true}}$；然后分别通过最大化沿活性方向和朴素方向的瑞利商来形成 $\\mathcal{S}_{\\text{AS}}$ 和 $\\mathcal{S}_{\\text{NV}}$；最后为每个用例计算比率 $R$。\n- 数值输出要求：产生三个浮点数，对应于三个用例，每个数使用标准舍入规则四舍五入到六位小数。\n\n最终输出格式：\n您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，\"[r1,r2,r3]\"），其中每个 $r_k$ 是用例 $k$ 的 $R$ 值，四舍五入后小数点后恰好有六位数字。不允许有其他输出。",
            "solution": "用户提供的问题已经过分析，并被确定为有效。该问题具有科学依据、良态且客观。其中没有矛盾、歧义或缺失信息。此问题是优化实验设计领域中一个明确定义的计算练习，特别关注于由活性子空间方法提供信息的传感器选择。\n\n该问题要求比较针对线性高斯逆问题的两种传感器选择策略。第一种策略称为“感知活性子空间”策略（$\\mathcal{S}_{\\text{AS}}$），它利用了关于参数对关注量的影响的信息。第二种是“朴素”策略（$\\mathcal{S}_{\\text{NV}}$），它使用一种简单的、无信息的启发式方法。通过一个比率 $R$ 来量化比较，该比率衡量了每个传感器集在真实的最大参数敏感性方向上所捕获的相对信息量。\n\n对每个测试用例，解决方案按以下步骤系统地进行：\n\n**步骤 1：定义问题参数和核心对象**\n\n对于每个测试用例，我们给定了参数维度 $d$、候选传感器数量 $p$、要选择的传感器数量 $m$、传感器噪声方差 $\\sigma^2$ 以及用于构建活性子空间矩阵的权重 $\\rho$。\n\n$p$ 个候选传感器响应向量的集合 $\\{s_i\\}_{i=0}^{p-1}$（其中 $s_i \\in \\mathbb{R}^d$）作为 $p \\times d$ 矩阵 $S$ 的行给出。$S$ 的分量由以下公式给出：\n$$\ns_{i,j} = \\sin\\big((i+1)(j+1)\\big) + 0.25\\,\\cos(i + 2j)\n$$\n对于 $i \\in \\{0, 1, \\dots, p-1\\}$ 和 $j \\in \\{0, 1, \\dots, d-1\\}$。三角函数的参数以弧度为单位。\n\n**步骤 2：构造活性子空间并确定目标方向**\n\n问题为梯度协方差矩阵提供了一个代理模型 $C_{\\text{active}}$，该模型识别了参数空间中最敏感的方向。该矩阵由两个向量 $a$ 和 $b$ 构造，其分量定义如下：\n$$\na'_j = \\cos(j+1), \\quad b'_j = \\sin(2j+1) \\quad \\text{对于 } j \\in \\{0, 1, \\dots, d-1\\}\n$$\n然后将这些向量归一化，使其具有单位欧几里得范数：\n$$\na = \\frac{a'}{\\|a'\\|_2}, \\quad b = \\frac{b'}{\\|b'\\|_2}\n$$\n活性子空间矩阵则通过秩-2 更新形成：\n$$\nC_{\\text{active}} = a a^\\top + \\rho \\, b b^\\top\n$$\n主要关注方向，记为 $v_{\\text{true}}$，是 $C_{\\text{active}}$ 的主特征向量，即对应其最大特征值的单位范数特征向量。此向量代表一维活性子空间。我们通过求解对称正半定矩阵 $C_{\\text{active}}$ 的特征值问题来找到 $v_{\\text{true}}$。\n\n**步骤 3：实施传感器选择策略**\n\n设计任务的核心是从 $p$ 个候选中选择一个包含 $m$ 个传感器的最优子集。最优性标准是对于给定的方向 $v$，最大化瑞利商 $v^\\top C(\\mathcal{S}) v$。如问题所述，这等价于最大化传感器向量在 $v$ 上投影的平方和：\n$$\nv^\\top C(\\mathcal{S}) v = v^\\top \\left(\\frac{1}{\\sigma^2} \\sum_{i \\in \\mathcal{S}} s_i s_i^\\top\\right) v = \\frac{1}{\\sigma^2} \\sum_{i \\in \\mathcal{S}} (v^\\top s_i)^2 = \\frac{1}{\\sigma^2} \\sum_{i \\in \\mathcal{S}} (s_i^\\top v)^2\n$$\n对于固定的方向 $v$ 和大小 $m$，该量可通过贪心选择来最大化：选择其向量 $s_i$ 能够产生最大得分 $(s_i^\\top v)^2$ 的 $m$ 个传感器。\n\n-   **感知活性子空间的选择 ($\\mathcal{S}_{\\text{AS}}$)**: 设计方向是 $v_{\\text{AS}} = v_{\\text{true}}$。我们计算所有 $i \\in \\{0, \\dots, p-1\\}$ 的得分 $(s_i^\\top v_{\\text{true}})^2$，并选择对应最大得分的 $m$ 个索引的集合 $\\mathcal{S}_{\\text{AS}}$。\n\n-   **朴素选择 ($\\mathcal{S}_{\\text{NV}}$)**: 设计方向是第一个标准基向量，$v_{\\text{NV}} = e_1 = [1, 0, \\dots, 0]^\\top$。我们计算所有 $i \\in \\{0, \\dots, p-1\\}$ 的得分 $(s_i^\\top e_1)^2 = s_{i,0}^2$，并选择对应最大得分的 $m$ 个索引的集合 $\\mathcal{S}_{\\text{NV}}$。\n\n**步骤 4：评估和比较设计**\n\n两种设计的性能通过计算它们在最重要的方向 $v_{\\text{true}}$ 上提供的信息来评估。比较指标是比率 $R$：\n$$\nR = \\frac{v_{\\text{true}}^\\top C(\\mathcal{S}_{\\text{AS}}) v_{\\text{true}}}{v_{\\text{true}}^\\top C(\\mathcal{S}_{\\text{NV}}) v_{\\text{true}}}\n$$\n代入瑞利商的表达式，我们得到：\n$$\nR = \\frac{\\frac{1}{\\sigma^2} \\sum_{i \\in \\mathcal{S}_{\\text{AS}}} (s_i^\\top v_{\\text{true}})^2}{\\frac{1}{\\sigma^2} \\sum_{i \\in \\mathcal{S}_{\\text{NV}}} (s_i^\\top v_{\\text{true}})^2} = \\frac{\\sum_{i \\in \\mathcal{S}_{\\text{AS}}} (s_i^\\top v_{\\text{true}})^2}{\\sum_{i \\in \\mathcal{S}_{\\text{NV}}} (s_i^\\top v_{\\text{true}})^2}\n$$\n值得注意的是，噪声方差 $\\sigma^2$ 从最终的比率中消除了。让评估分数为 $\\gamma_i = (s_i^\\top v_{\\text{true}})^2$。分子是 $\\{\\gamma_i\\}_{i=0}^{p-1}$ 中最大的 $m$ 个值的和。分母是那些被朴素策略选中的索引 $i$ 的 $\\gamma_i$ 之和（即那些最大化了 $(s_i^\\top e_1)^2$ 的索引）。对每个测试用例重复此过程，并将得到的 $R$ 值四舍五入到六位小数。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the sensor design comparison ratio R for a set of test cases.\n    \"\"\"\n    test_cases = [\n        # (d, p, m, sigma^2, rho)\n        (6, 14, 3, 0.25, 0.25),\n        (6, 14, 1, 1.0, 1.0),\n        (8, 20, 4, 4.0, 0.05),\n    ]\n\n    results = []\n    for case in test_cases:\n        d, p, m, sigma_sq, rho = case\n\n        # Step 1: Construct the candidate sensor matrix S\n        i_indices = np.arange(p).reshape(p, 1)\n        j_indices = np.arange(d).reshape(1, d)\n        S_matrix = np.sin((i_indices + 1) * (j_indices + 1)) + 0.25 * np.cos(i_indices + 2 * j_indices)\n\n        # Step 2: Construct C_active and find the true active direction v_true\n        j_vec = np.arange(d)\n        \n        # Construct unnormalized vectors a' and b'\n        a_prime = np.cos(j_vec + 1)\n        b_prime = np.sin(2 * j_vec + 1)\n\n        # Normalize to get unit vectors a and b\n        a = a_prime / np.linalg.norm(a_prime)\n        b = b_prime / np.linalg.norm(b_prime)\n        \n        # Construct C_active matrix\n        C_active = np.outer(a, a) + rho * np.outer(b, b)\n        \n        # Find the leading eigenvector (v_true) of C_active\n        eigenvalues, eigenvectors = np.linalg.eigh(C_active)\n        v_true = eigenvectors[:, -1] # Eigenvector for the largest eigenvalue\n\n        # Step 3: Implement sensor selection strategies\n        \n        # Naive design direction\n        v_naive = np.zeros(d)\n        v_naive[0] = 1.0\n\n        # Scores for AS-aware design (based on v_true)\n        scores_as_design = (S_matrix @ v_true)**2\n        \n        # Scores for naive design (based on v_naive)\n        scores_nv_design = (S_matrix @ v_naive)**2\n        \n        # Get indices for the top m sensors for each strategy\n        indices_as = np.argsort(scores_as_design)[-m:]\n        indices_nv = np.argsort(scores_nv_design)[-m:]\n\n        # Step 4: Evaluate and compare the designs\n\n        # The evaluation is performed along v_true for both sets of sensors.\n        # The scores used for evaluation are the same as those for the AS design.\n        evaluation_scores = scores_as_design\n        \n        # Numerator: sum of evaluation scores for the AS-selected sensors\n        # This is equivalent to summing the top m evaluation scores.\n        numerator = np.sum(evaluation_scores[indices_as])\n        \n        # Denominator: sum of evaluation scores for the naively-selected sensors\n        denominator = np.sum(evaluation_scores[indices_nv])\n\n        # Compute the ratio R\n        if denominator == 0:\n            # This case is unlikely given the problem construction but is handled for robustness.\n            # If the naive selection is orthogonal to the true direction, the ratio is infinite\n            # assuming the AS selection is not also orthogonal.\n            R = np.inf\n        else:\n            R = numerator / denominator\n        \n        results.append(R)\n\n    # Format the final output as specified\n    formatted_results = [f'{round(r, 6):.6f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}