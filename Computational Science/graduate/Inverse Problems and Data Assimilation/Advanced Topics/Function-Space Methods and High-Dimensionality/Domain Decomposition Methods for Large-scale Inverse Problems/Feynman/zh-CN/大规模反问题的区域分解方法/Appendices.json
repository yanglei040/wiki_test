{
    "hands_on_practices": [
        {
            "introduction": "要掌握区域分解方法，我们首先需要理解其代数核心。本练习将引导您完成一个非重叠区域分解（也称为子结构化）的基本步骤。通过求解一个小型离散泊松问题，您将亲手构建舒尔补系统（Schur complement system），这是将大型问题简化为一系列较小的子域问题和一个界面问题的关键。这个过程将揭示界面算子如何有效地封装子域的物理信息，为您理解更复杂的实现打下坚实的代数基础 。",
            "id": "3377575",
            "problem": "考虑一个受泊松型偏微分方程约束的 Tikhonov 正则化反源识别问题的单次线性化高斯-牛顿步。计算域被分解为两个不重叠的子域，状态被离散化为 $6$ 个自由度，并分组为两个大小各为 $3$ 的子域向量。通过两个等式约束来施加界面连续性，每个界面自由度对应一个约束。在标准拉格朗日乘子法中，该线性系统呈现为鞍点形式\n$$\n\\begin{pmatrix}\n\\mathbf{K}  \\mathbf{B}^{\\top} \\\\\n\\mathbf{B}  \\mathbf{0}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf{u} \\\\\n\\boldsymbol{\\lambda}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\mathbf{f} \\\\\n\\mathbf{0}\n\\end{pmatrix},\n$$\n其中 $\\mathbf{u}\\in\\mathbb{R}^{6}$ 汇集了子域的状态未知数，$\\boldsymbol{\\lambda}\\in\\mathbb{R}^{2}$ 是界面拉格朗日乘子，$\\mathbf{K}\\in\\mathbb{R}^{6\\times 6}$ 是一个块对角矩阵，其对角块为两个 $3\\times 3$ 的子域算子，而 $\\mathbf{B}\\in\\mathbb{R}^{2\\times 6}$ 用于强制界面连续性。\n\n假设每个子域算子是在均匀网格上带有狄利克雷边界条件的标准一维泊松刚度矩阵，即\n$$\n\\mathbf{K}_1=\\mathbf{K}_2=\\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix},\n$$\n并且\n$$\n\\mathbf{K}=\\mathrm{diag}(\\mathbf{K}_1,\\mathbf{K}_2).\n$$\n设 $\\mathbf{u}$ 的分量排序为 $\\mathbf{u}=\\begin{pmatrix}u_{1,a}  u_{1,b}  u_{1,c}  u_{2,a}  u_{2,b}  u_{2,c}\\end{pmatrix}^{\\top}$，并施加两个界面连续性约束 $u_{1,b}-u_{2,a}=0$ 和 $u_{1,c}-u_{2,b}=0$，即\n$$\n\\mathbf{B}=\\begin{pmatrix}\n0  1  0  -1  0  0 \\\\\n0  0  1  0  -1  0\n\\end{pmatrix}.\n$$\n取右端项为\n$$\n\\mathbf{f}=\\begin{pmatrix}1  0  0  0  1  0\\end{pmatrix}^{\\top}.\n$$\n\n从约束最小二乘子问题的一阶最优性（Karush–Kuhn–Tucker）条件出发，仅使用块高斯消元作为代数工具，消去内部状态变量 $\\mathbf{u}$ 以形成关于界面乘子的舒尔补，然后求解简化后的系统以得到 $\\boldsymbol{\\lambda}$。通过回代恢复 $\\mathbf{u}$。最后，将关于界面乘子的 $2\\times 2$ 舒尔补矩阵的行列式以精确有理数的形式报告。不需要四舍五入。你的最终答案必须是一个无单位的单个实数。",
            "solution": "该问题陈述已经过验证，被认为是数值线性代数中一个源于偏微分方程区域分解的适定问题。因此，我们可以进行正式求解。\n\n待求解的系统是一个鞍点线性系统，由一个约束优化问题的 Karush–Kuhn–Tucker (KKT) 条件给出。该系统以块矩阵形式表示为：\n$$\n\\begin{pmatrix}\n\\mathbf{K}  \\mathbf{B}^{\\top} \\\\\n\\mathbf{B}  \\mathbf{0}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\mathbf{u} \\\\\n\\boldsymbol{\\lambda}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\mathbf{f} \\\\\n\\mathbf{0}\n\\end{pmatrix}\n$$\n这对应于两个块方程：\n$$\n\\mathbf{K}\\mathbf{u} + \\mathbf{B}^{\\top}\\boldsymbol{\\lambda} = \\mathbf{f} \\quad (1)\n$$\n$$\n\\mathbf{B}\\mathbf{u} = \\mathbf{0} \\quad (2)\n$$\n任务是通过首先为拉格朗日乘子 $\\boldsymbol{\\lambda}$ 构造一个舒尔补系统来求解此系统。这可以通过块高斯消元实现。\n\n首先，我们必须确定矩阵 $\\mathbf{K}$ 是可逆的。矩阵 $\\mathbf{K}$ 被给出为 $\\mathbf{K}=\\mathrm{diag}(\\mathbf{K}_1,\\mathbf{K}_2)$，其中：\n$$\n\\mathbf{K}_1=\\mathbf{K}_2=\\begin{pmatrix} 2  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  2 \\end{pmatrix}\n$$\n这是一个对称三对角矩阵。其行列式为 $\\det(\\mathbf{K}_1) = 2(2 \\cdot 2 - (-1)(-1)) - (-1)(-1 \\cdot 2 - 0) = 2(3) - 2 = 4$。由于行列式非零，$\\mathbf{K}_1$ 是可逆的。因为 $\\mathbf{K}_2 = \\mathbf{K}_1$，所以它也是可逆的。因此，$\\mathbf{K}$ 作为一个由可逆块组成的块对角矩阵，其本身也是可逆的。\n\n从方程 (1) 中，我们可以将 $\\mathbf{u}$ 形式上表示为：\n$$\n\\mathbf{u} = \\mathbf{K}^{-1}(\\mathbf{f} - \\mathbf{B}^{\\top}\\boldsymbol{\\lambda})\n$$\n将 $\\mathbf{u}$ 的这个表达式代入方程 (2) 中，可以消去状态变量 $\\mathbf{u}$：\n$$\n\\mathbf{B} \\left( \\mathbf{K}^{-1}(\\mathbf{f} - \\mathbf{B}^{\\top}\\boldsymbol{\\lambda}) \\right) = \\mathbf{0}\n$$\n根据线性性质，我们可以将 $\\mathbf{B}$ 分配进去：\n$$\n\\mathbf{B}\\mathbf{K}^{-1}\\mathbf{f} - \\mathbf{B}\\mathbf{K}^{-1}\\mathbf{B}^{\\top}\\boldsymbol{\\lambda} = \\mathbf{0}\n$$\n重新整理该方程，得到关于 $\\boldsymbol{\\lambda}$ 的舒尔补系统：\n$$\n(\\mathbf{B}\\mathbf{K}^{-1}\\mathbf{B}^{\\top})\\boldsymbol{\\lambda} = \\mathbf{B}\\mathbf{K}^{-1}\\mathbf{f}\n$$\n舒尔补矩阵，我们记为 $\\mathbf{S}$，是左侧的 $2 \\times 2$ 矩阵：\n$$\n\\mathbf{S} = \\mathbf{B}\\mathbf{K}^{-1}\\mathbf{B}^{\\top}\n$$\n问题要求计算 $\\mathbf{S}$ 的行列式。要计算 $\\mathbf{S}$，我们首先需要 $\\mathbf{K}$ 的逆矩阵。由于 $\\mathbf{K} = \\mathrm{diag}(\\mathbf{K}_1, \\mathbf{K}_2)$，其逆矩阵为 $\\mathbf{K}^{-1} = \\mathrm{diag}(\\mathbf{K}_1^{-1}, \\mathbf{K}_2^{-1})$。我们使用伴随矩阵法计算 $\\mathbf{K}_1^{-1}$：\n$$\n\\mathbf{K}_1^{-1} = \\frac{1}{\\det(\\mathbf{K}_1)}\\mathrm{adj}(\\mathbf{K}_1)^{\\top} = \\frac{1}{4} \\begin{pmatrix} 3  2  1 \\\\ 2  4  2 \\\\ 1  2  3 \\end{pmatrix}\n$$\n由于 $\\mathbf{K}_1 = \\mathbf{K}_2$，我们有 $\\mathbf{K}_2^{-1} = \\mathbf{K}_1^{-1}$。因此，\n$$\n\\mathbf{K}^{-1} = \\frac{1}{4} \\begin{pmatrix}\n3  2  1  0  0  0 \\\\\n2  4  2  0  0  0 \\\\\n1  2  3  0  0  0 \\\\\n0  0  0  3  2  1 \\\\\n0  0  0  2  4  2 \\\\\n0  0  0  1  2  3\n\\end{pmatrix}\n$$\n矩阵 $\\mathbf{B}$ 给出如下：\n$$\n\\mathbf{B}=\\begin{pmatrix}\n0  1  0  -1  0  0 \\\\\n0  0  1  0  -1  0\n\\end{pmatrix}\n$$\n我们现在计算乘积 $\\mathbf{B}\\mathbf{K}^{-1}$：\n$$\n\\mathbf{B}\\mathbf{K}^{-1} = \\begin{pmatrix}\n0  1  0  -1  0  0 \\\\\n0  0  1  0  -1  0\n\\end{pmatrix} \\frac{1}{4} \\begin{pmatrix}\n3  2  1  0  0  0 \\\\\n2  4  2  0  0  0 \\\\\n1  2  3  0  0  0 \\\\\n0  0  0  3  2  1 \\\\\n0  0  0  2  4  2 \\\\\n0  0  0  1  2  3\n\\end{pmatrix}\n$$\n结果的第一行是 $\\frac{1}{4}$ 乘以（$\\mathbf{K}^{-1}$ 的第2行减去其第4行），第二行是 $\\frac{1}{4}$ 乘以（$\\mathbf{K}^{-1}$ 的第3行减去其第5行）。这得到：\n$$\n\\mathbf{B}\\mathbf{K}^{-1} = \\frac{1}{4} \\begin{pmatrix}\n2  4  2  -3  -2  -1 \\\\\n1  2  3  -2  -4  -2\n\\end{pmatrix}\n$$\n接下来，我们将此结果乘以 $\\mathbf{B}^{\\top}$ 以构成 $\\mathbf{S}$：\n$$\n\\mathbf{B}^{\\top} = \\begin{pmatrix} 0  0 \\\\ 1  0 \\\\ 0  1 \\\\ -1  0 \\\\ 0  -1 \\\\ 0  0 \\end{pmatrix}\n$$\n$$\n\\mathbf{S} = (\\mathbf{B}\\mathbf{K}^{-1})\\mathbf{B}^{\\top} = \\frac{1}{4} \\begin{pmatrix}\n2  4  2  -3  -2  -1 \\\\\n1  2  3  -2  -4  -2\n\\end{pmatrix} \\begin{pmatrix} 0  0 \\\\ 1  0 \\\\ 0  1 \\\\ -1  0 \\\\ 0  -1 \\\\ 0  0 \\end{pmatrix}\n$$\n执行矩阵乘法：\n$$\nS_{11} = \\frac{1}{4} (2(0) + 4(1) + 2(0) - 3(-1) - 2(0) - 1(0)) = \\frac{1}{4}(4+3) = \\frac{7}{4}\n$$\n$$\nS_{12} = \\frac{1}{4} (2(0) + 4(0) + 2(1) - 3(0) - 2(-1) - 1(0)) = \\frac{1}{4}(2+2) = \\frac{4}{4} = 1\n$$\n$$\nS_{21} = \\frac{1}{4} (1(0) + 2(1) + 3(0) - 2(-1) - 4(0) - 2(0)) = \\frac{1}{4}(2+2) = \\frac{4}{4} = 1\n$$\n$$\nS_{22} = \\frac{1}{4} (1(0) + 2(0) + 3(1) - 2(0) - 4(-1) - 2(0)) = \\frac{1}{4}(3+4) = \\frac{7}{4}\n$$\n因此，舒尔补矩阵为：\n$$\n\\mathbf{S} = \\begin{pmatrix} \\frac{7}{4}  1 \\\\ 1  \\frac{7}{4} \\end{pmatrix}\n$$\n问题要求计算该矩阵的行列式。\n$$\n\\det(\\mathbf{S}) = \\left(\\frac{7}{4}\\right)\\left(\\frac{7}{4}\\right) - (1)(1) = \\frac{49}{16} - 1 = \\frac{49}{16} - \\frac{16}{16} = \\frac{33}{16}\n$$\n这就是所求的值。为完整起见，可以利用 $\\mathbf{S}\\boldsymbol{\\lambda} = \\mathbf{B}\\mathbf{K}^{-1}\\mathbf{f}$ 解出 $\\boldsymbol{\\lambda}$，然后回代求得 $\\mathbf{u} = \\mathbf{K}^{-1}(\\mathbf{f} - \\mathbf{B}^{\\top}\\boldsymbol{\\lambda})$。然而，题目所要求的最终答案仅是 $\\mathbf{S}$ 的行列式。",
            "answer": "$$\\boxed{\\frac{33}{16}}$$"
        },
        {
            "introduction": "在解决了理想化的匹配网格问题之后，我们转向一个更贴近实际的挑战：当子域在界面处具有不匹配的网格时该如何处理。本练习介绍了一种强大的技术——“砂浆法”（mortar methods），它为在非匹配网格上施加耦合条件提供了严谨的框架。通过这个编码实践，您将探索砂浆空间维度对反演问题中目标函数梯度计算精度的影响，并量化由几何不一致性引入的误差 。",
            "id": "3377564",
            "problem": "考虑一个在共享界面的两个子域上提出的线性椭圆反问题。设界面为开放线段 $\\Gamma = (0,1)$，由 $s \\in (0,1)$ 参数化。子域通过在界面上施加连续性条件进行耦合。区域分解方法产生作用于状态变量沿 $\\Gamma$ 的迹的界面算子。为了抽象而又真实地对该设定进行建模，假设离散 Dirichlet-to-Neumann 映射在界面两侧的作用由一个对称正定有限差分算子近似，其形式为\n$$\n\\mathsf{S}_n = \\frac{1}{h_n^2} \\operatorname{tridiag}(-1,2,-1) + \\mathsf{I}_n,\n$$\n在 $s=0$ 和 $s=1$ 处具有齐次 Dirichlet 条件，其中 $n$ 是给定一侧的界面网格点数，$h_n = \\frac{1}{n-1}$ 是均匀网格间距，$\\mathsf{I}_n$ 是 $n \\times n$ 单位矩阵。这是一个经过充分检验的、与椭圆偏微分方程相关的界面 Schur 补的代理模型。\n\n设 $\\theta \\in \\mathbb{R}^m$ 通过一个维度为 $m$ 的砂浆空间（Mortar space）参数化界面上的 Dirichlet 控制，该空间由在 $[0,1]$ 上的一个均匀剖分上的连续分段线性（帽子）函数张成，剖分节点为 $\\{t_k\\}_{k=0}^{m-1}$，其中 $t_k = \\frac{k}{m-1}$。控制 $\\theta$ 与其在砂浆节点上的节点值等同。\n\n对于两个大小为 $n_1$ 和 $n_2$ 的不匹配界面网格（$n_1 \\neq n_2$），定义线性插值（延拓）矩阵 $\\mathsf{P}_1 \\in \\mathbb{R}^{n_1 \\times m}$ 和 $\\mathsf{P}_2 \\in \\mathbb{R}^{n_2 \\times m}$，它们将砂浆系数 $\\theta$ 映射到在每个子域相应界面网格节点上采样的迹值。设 $\\mathsf{I}_{\\text{eval}\\leftarrow n}$ 表示从大小为 $n$ 的网格到大小为 $n_{\\text{eval}}$ 的公共评估网格（在 $[0,1]$ 上均匀分布）的线性插值矩阵。这定义了复合算子\n$$\n\\mathsf{R}_m = \\mathsf{I}_{\\text{eval}\\leftarrow n_1} \\, \\mathsf{S}_{n_1} \\, \\mathsf{P}_1 \\;+\\; \\mathsf{I}_{\\text{eval}\\leftarrow n_2} \\, \\mathsf{S}_{n_2} \\, \\mathsf{P}_2 \\;\\in\\; \\mathbb{R}^{n_{\\text{eval}} \\times m}.\n$$\n考虑二次代价泛函\n$$\nJ(\\theta) \\;=\\; \\frac{1}{2} \\, \\lVert \\mathsf{R}_m \\, \\theta \\rVert_2^2,\n$$\n它惩罚在公共评估网格上评估的通量失配的 $L^2$ 范数的平方。这抽象地模拟了界面耦合条件中的残差，是降空间反问题中的一种标准结构。对于这个线性最小二乘问题，关于控制的约化梯度为\n$$\nJ'(\\theta) \\;=\\; \\mathsf{R}_m^\\top \\mathsf{R}_m \\, \\theta.\n$$\n\n为了量化在不匹配网格和有限维砂浆空间下 $J'(\\theta)$ 的一致性，定义一个高保真参考，其两侧具有大小为 $n_{\\text{ref}}$ 的匹配界面网格，使用相同的算子构造 $\\mathsf{S}_{n_{\\text{ref}}}$，以及一个从砂浆节点到参考网格通过线性插值构建的砂浆到参考的延拓矩阵 $\\mathsf{P}_{\\text{ref}} \\in \\mathbb{R}^{n_{\\text{ref}} \\times m}$。相应的参考算子是\n$$\n\\mathsf{R}_{\\text{true}} \\;=\\; 2 \\, \\mathsf{I}_{\\text{eval}\\leftarrow n_{\\text{ref}}} \\, \\mathsf{S}_{n_{\\text{ref}}} \\, \\mathsf{P}_{\\text{ref}} \\;\\in\\; \\mathbb{R}^{n_{\\text{eval}} \\times m},\n$$\n且在砂浆空间中相关的参考梯度为\n$$\nJ'_{\\text{true}}(\\theta) \\;=\\; \\mathsf{R}_{\\text{true}}^\\top \\mathsf{R}_{\\text{true}} \\, \\theta.\n$$\n注意，因子 $2$ 代表了在匹配网格极限下，两侧相同贡献的总和。\n\n你的任务是：\n1.  从线性最小二乘问题的 $J(\\theta)$ 定义出发，推导在不匹配网格砂浆设定和高保真参考设定下约化梯度 $J'(\\theta)$ 的表达式。解释为什么差值 $J'(\\theta) - J'_{\\text{true}}(\\theta)$ 衡量了由不匹配网格和有限砂浆空间维度 $m$ 共同导致的梯度一致性误差。\n2.  利用均匀剖分上连续分段线性基函数的插值误差估计，解释为什么砂浆空间维度 $m$ 控制了一致性误差，并讨论在固定的 $n_1$、$n_2$ 和 $n_{\\text{eval}}$ 下，当 $m$ 增加时 $\\lVert J'(\\theta) - J'_{\\text{true}}(\\theta) \\rVert_2$ 的预期渐近行为。\n3.  实现一个程序，构建上述算子，并为一个在砂浆节点上由平滑函数 $\\theta_k = \\sin(\\pi t_k)$ 定义的固定测试控制 $\\theta$ 评估梯度的相对一致性误差。在所有有限差分算子中，于 $s=0$ 和 $s=1$ 处使用齐次 Dirichlet 条件。\n\n使用以下参数测试套件来探究砂浆空间维度的影响：\n- 不匹配的界面网格大小：$n_1 = 53$，$n_2 = 77$。\n- 评估网格大小：$n_{\\text{eval}} = 301$。\n- 参考网格大小：$n_{\\text{ref}} = 401$。\n- 砂浆空间维度：$m \\in \\{2, 5, 10, 20, 40\\}$。\n- 测试控制：$\\theta_k = \\sin(\\pi t_k)$，对于 $k = 0, 1, \\dots, m-1$。\n\n对于测试套件中的每个砂浆维度 $m$，计算梯度一致性误差的相对 $2$-范数\n$$\n\\varepsilon(m) \\;=\\; \\frac{\\lVert J'(\\theta) - J'_{\\text{true}}(\\theta) \\rVert_2}{\\lVert J'_{\\text{true}}(\\theta) \\rVert_2}.\n$$\n\n你的程序应生成一行输出，其中包含一个由方括号括起来的逗号分隔列表（例如，“[result1,result2,result3]”），其中每个结果对应于上面列出的砂浆维度 $m$ 的 $\\varepsilon(m)$ 值，顺序相同。所有输出必须是实数，并使用 Python 默认的浮点格式。此问题不涉及物理单位；所有量均为无量纲。",
            "solution": "该问题经评估有效。它在科学上基于偏微分方程和反问题的数值分析，特别是使用了区域分解和砂浆方法的概念。问题提法得当，目标明确，并包含获得唯一解所需的所有信息。\n\n### 第 1 部分：约化梯度的推导\n\n二次代价泛函由下式给出\n$$\nJ(\\theta) = \\frac{1}{2} \\lVert \\mathsf{R}_m \\theta \\rVert_2^2\n$$\n其中 $\\theta \\in \\mathbb{R}^m$ 是控制参数向量，$\\mathsf{R}_m \\in \\mathbb{R}^{n_{\\text{eval}} \\times m}$ 是一个线性算子。\n\n$L^2$-范数的平方可以用内积（点积）表示为 $\\lVert v \\rVert_2^2 = v^\\top v$。因此，泛函可以写成：\n$$\nJ(\\theta) = \\frac{1}{2} (\\mathsf{R}_m \\theta)^\\top (\\mathsf{R}_m \\theta)\n$$\n利用乘积转置的性质 $(AB)^\\top = B^\\top A^\\top$，我们有：\n$$\nJ(\\theta) = \\frac{1}{2} \\theta^\\top \\mathsf{R}_m^\\top \\mathsf{R}_m \\theta\n$$\n这是一个关于 $\\theta$ 的二次型。为了找到问题中记为 $J'(\\theta)$ 的梯度，我们可以对向量 $\\theta$ 的每个分量 $\\theta_k$ 求导。根据矩阵微积分中关于二次型 $f(x) = \\frac{1}{2} x^\\top A x$（其中 $A$ 为对称矩阵）的一个标准结果，可知 $\\nabla f(x) = A x$。矩阵 $\\mathsf{H} = \\mathsf{R}_m^\\top \\mathsf{R}_m$ 是对称的，因为 $(\\mathsf{R}_m^\\top \\mathsf{R}_m)^\\top = \\mathsf{R}_m^\\top (\\mathsf{R}_m^\\top)^\\top = \\mathsf{R}_m^\\top \\mathsf{R}_m$。\n\n因此，$J(\\theta)$ 的梯度是：\n$$\nJ'(\\theta) = \\nabla_\\theta J(\\theta) = \\mathsf{R}_m^\\top \\mathsf{R}_m \\theta\n$$\n这证实了问题陈述中给出的不匹配网格砂浆设定的表达式。\n\n对于高保真参考设定的推导是相同的。我们只需将不匹配算子 $\\mathsf{R}_m$ 替换为参考算子 $\\mathsf{R}_{\\text{true}}$：\n$$\nJ_{\\text{true}}(\\theta) = \\frac{1}{2} \\lVert \\mathsf{R}_{\\text{true}} \\theta \\rVert_2^2 = \\frac{1}{2} \\theta^\\top \\mathsf{R}_{\\text{true}}^\\top \\mathsf{R}_{\\text{true}} \\theta\n$$\n相应的梯度是：\n$$\nJ'_{\\text{true}}(\\theta) = \\mathsf{R}_{\\text{true}}^\\top \\mathsf{R}_{\\text{true}} \\theta\n$$\n这证实了提供的第二个表达式。\n\n差值 $J'(\\theta) - J'_{\\text{true}}(\\theta)$ 代表了梯度的一致性误差。在反问题的优化算法中，梯度 $J'(\\theta)$ 是一个决定搜索方向的关键量。其计算中的任何误差都可能导致收敛变慢或收敛到非最优解。此误差的产生是因为在实际的不匹配网格设定中使用的算子 $\\mathsf{R}_m$ 是对理想算子（此处由 $\\mathsf{R}_{\\text{true}}$ 作为代理）的一种近似。$\\mathsf{R}_m$ 的结构结合了两种不同的离散化（在大小为 $n_1$ 和 $n_2$ 的网格上），而 $\\mathsf{R}_{\\text{true}}$ 基于单一、更精细、匹配的离散化（$n_{\\text{ref}}$）。此外，两个算子都依赖于从抽象的 $m$ 维砂浆控制空间到物理界面网格的投影。因此，差值 $J'(\\theta) - J'_{\\text{true}}(\\theta) = (\\mathsf{R}_m^\\top \\mathsf{R}_m - \\mathsf{R}_{\\text{true}}^\\top \\mathsf{R}_{\\text{true}}) \\theta$ 衡量了两种数值近似误差源的综合影响：不匹配网格的几何不一致性以及通过砂浆空间对控制函数的有限维表示。\n\n### 第 2 部分：砂浆空间维度的作用及渐近行为\n\n砂浆空间的维度 $m$ 在控制一致性误差方面起着关键作用。控制向量 $\\theta \\in \\mathbb{R}^m$ 并不直接代表界面函数，而是其在一组分段线性帽子函数基 $\\{B_k^m(s)\\}_{k=0}^{m-1}$ 中的系数，这组基定义在 $[0,1]$ 上的一个均匀剖分上，网格间距为 $h_m = 1/(m-1)$。界面上的连续函数为 $u_m(s) = \\sum_{k=0}^{m-1} \\theta_k B_k^m(s)$。\n\n测试控制被选为 $\\theta_k = \\sin(\\pi t_k)$，其中 $t_k = k/(m-1)$ 是砂浆节点。这意味着 $u_m(s)$ 是光滑函数 $u(s) = \\sin(\\pi s)$ 的分段线性插值。此插值的精度由砂浆网格间距 $h_m$ 控制。根据标准数值分析理论，对于像 $u(s)=\\sin(\\pi s)$ 这样足够光滑的函数，插值误差是有界的。例如，最大误差有界为：\n$$\n\\lVert u(s) - u_m(s) \\rVert_{L^\\infty[0,1]} \\leq C h_m^2 \\lVert u''(s) \\rVert_{L^\\infty[0,1]} = O(1/m^2)\n$$\n其中 $C$ 是一个与 $m$ 无关的常数。\n\n不匹配算子 $\\mathsf{R}_m$ 和参考算子 $\\mathsf{R}_{\\text{true}}$ 都作用于这个相同的底层函数 $u_m(s)$，尽管通过不同的离散化和投影步骤。随着 $m$ 的增加，$u_m(s)$ 成为光滑函数 $u(s) = \\sin(\\pi s)$ 的一个越来越好的近似。\n\n梯度一致性误差 $\\lVert J'(\\theta) - J'_{\\text{true}}(\\theta) \\rVert_2$ 量化了连续泛函梯度的两种不同离散近似之间的差异。随着 $m$ 的增加，这些离散系统的输入（向量 $\\mathsf{P}_1\\theta$、$\\mathsf{P}_2\\theta$、$\\mathsf{P}_{\\text{ref}}\\theta$）成为同一底层光滑函数 $u(s)$ 的更准确的离散表示。因此，不匹配系统和参考系统处理此函数的不同方式应该产生更接近的结果。随着它们所模拟的函数被控制参数化更好地解析，两种离散模型之间的误差预计会减小。\n\n因此，对于中小值的 $m$，当砂浆空间是系统中最粗糙的近似时（即 $h_m > h_{n_1}, h_{n_2}$），我们预计一致性误差 $\\lVert J'(\\theta) - J'_{\\text{true}}(\\theta) \\rVert_2$ 会随着 $m$ 的增加而减小。收敛速度与分段线性基的近似性质和所涉及算子的阶数有关。由于算子 $\\mathsf{S}_n$ 包含一个二阶有限差分，梯度的误差预计会以 $h_m$ 的某个幂次缩放，即 $O(m^{-p})$，其中 $p>0$。\n\n然而，这种改善不会无限持续下去。物理网格（$n_1$、$n_2$、$n_{\\text{ref}}$）上的离散化是固定的。一旦砂浆网格变得比物理网格精细得多（即 $m \\gg n_1, n_2$），误差将不再由砂浆近似质量主导。相反，它将由不匹配离散化（在网格 $n_1, n_2$ 上平均）和参考离散化（$n_{\\text{ref}}$）之间的内在差异主导。此时，进一步增加 $m$ 将产生递减的回报，误差 $\\varepsilon(m)$ 将会达到一个平台期。误差将收敛到一个非零值，该值代表了对于固定的网格 $n_1$ 和 $n_2$ 的不可约一致性误差。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the relative consistency error of the gradient for a mortar-based\n    domain decomposition problem with nonmatching grids.\n    \"\"\"\n\n    def construct_s_operator(n):\n        \"\"\"\n        Constructs the symmetric positive definite operator S_n.\n        S_n = (1/h^2) * tridiag(-1, 2, -1) + I_n\n        \"\"\"\n        if n == 1:\n            return np.array([[1.0]])\n        h = 1.0 / (n - 1)\n        h2_inv = 1.0 / (h * h)\n        \n        diag_main = (2.0 * h2_inv + 1.0) * np.ones(n)\n        diag_off = -h2_inv * np.ones(n - 1)\n        \n        s_op = np.diag(diag_main) + np.diag(diag_off, k=1) + np.diag(diag_off, k=-1)\n        return s_op\n\n    def construct_interpolation_matrix(target_nodes, source_nodes):\n        \"\"\"\n        Constructs a linear interpolation matrix P that maps function values from\n        source_nodes to target_nodes.\n        Resulting matrix has shape (len(target_nodes), len(source_nodes)).\n        \"\"\"\n        n_target = len(target_nodes)\n        n_source = len(source_nodes)\n        \n        if n_source == 0:\n            return np.zeros((n_target, 0))\n        if n_source == 1:\n            return np.ones((n_target, 1))\n\n        p_matrix = np.zeros((n_target, n_source))\n        h_source = 1.0 / (n_source - 1)\n        \n        for j in range(n_target):\n            s_j = target_nodes[j]\n            \n            # Handle edge case where s_j is exactly 1.0\n            if s_j >= 1.0:\n                p_matrix[j, -1] = 1.0\n                continue\n\n            # Find k such that s_j is in [source_nodes[k], source_nodes[k+1]]\n            k_float = s_j / h_source\n            k = int(k_float)\n            \n            # Linear interpolation weights\n            # The value at s_j is w * source[k] + (1-w) * source[k+1]\n            # No, it's (1-alpha)*source[k] + alpha*source[k+1] where alpha = (s_j-t_k)/h\n            alpha = k_float - k\n\n            p_matrix[j, k] = 1.0 - alpha\n            if k + 1  n_source:\n                p_matrix[j, k + 1] = alpha\n                \n        return p_matrix\n\n    # --- Problem Parameters ---\n    n1 = 53\n    n2 = 77\n    neval = 301\n    nref = 401\n    m_values = [2, 5, 10, 20, 40]\n    \n    results = []\n\n    # --- Pre-construct grids and S operators which are constant for all m ---\n    n1_nodes = np.linspace(0, 1, n1)\n    n2_nodes = np.linspace(0, 1, n2)\n    neval_nodes = np.linspace(0, 1, neval)\n    nref_nodes = np.linspace(0, 1, nref)\n\n    S1 = construct_s_operator(n1)\n    S2 = construct_s_operator(n2)\n    S_ref = construct_s_operator(nref)\n\n    I_eval1 = construct_interpolation_matrix(neval_nodes, n1_nodes)\n    I_eval2 = construct_interpolation_matrix(neval_nodes, n2_nodes)\n    I_eval_ref = construct_interpolation_matrix(neval_nodes, nref_nodes)\n\n    for m in m_values:\n        # --- Construct m-dependent entities ---\n        m_nodes = np.linspace(0, 1, m)\n        theta = np.sin(np.pi * m_nodes)\n\n        # Prolongation operators from mortar space to interface grids\n        P1 = construct_interpolation_matrix(n1_nodes, m_nodes)\n        P2 = construct_interpolation_matrix(n2_nodes, m_nodes)\n        P_ref = construct_interpolation_matrix(nref_nodes, m_nodes)\n        \n        # --- Construct composite operators R_m and R_true ---\n        # Nonmatching-grid operator\n        R_m = (I_eval1 @ S1 @ P1) + (I_eval2 @ S2 @ P2)\n        \n        # High-fidelity reference operator\n        R_true = 2.0 * I_eval_ref @ S_ref @ P_ref\n\n        # --- Compute gradients ---\n        # Gradient for nonmatching-grid functional\n        grad_J = R_m.T @ R_m @ theta\n        \n        # Gradient for reference functional\n        grad_J_true = R_true.T @ R_true @ theta\n\n        # --- Compute relative consistency error ---\n        error_norm = np.linalg.norm(grad_J - grad_J_true)\n        ref_norm = np.linalg.norm(grad_J_true)\n        \n        relative_error = 0.0\n        if ref_norm > 1e-15: # Avoid division by zero\n            relative_error = error_norm / ref_norm\n        \n        results.append(relative_error)\n\n    # --- Format and print the final output ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现在，让我们将所有知识融会贯通，在一个完整的应用场景中检验区域分解的威力。这个终极实践将子结构化方法作为一个高性能线性求解器，嵌入到一个非线性反问题的优化流程中。您将为一个实际的参数辨识问题实现一个完整的高斯-牛顿（Gauss–Newton）迭代步，并使用区域分解来高效求解其中涉及的正问题和灵敏度方程，从而真正体验到这些方法在解决大规模数据同化问题中的核心作用 。",
            "id": "3377614",
            "problem": "考虑一维非线性扩散边界值问题\n$$ -\\frac{d}{dx}\\big(\\kappa(m(x)) \\frac{du(x)}{dx}\\big) = f(x), \\quad x \\in (0,1), \\quad u(0)=0,\\;u(1)=0, $$\n其中扩散通过 $\\kappa(m)=\\exp(m)$ 在一个标量参数场中呈非线性。域 $(0,1)$ 被分解为两个不重叠的子域 $\\Omega_1=(0,0.5]$ 和 $\\Omega_2=[0.5,1)$，在界面处状态和通量保持连续。参数场被限制为在分解上是分段常数，即在 $\\Omega_1$ 上 $m(x)=m_1$，在 $\\Omega_2$ 上 $m(x)=m_2$，因此在 $\\Omega_1$ 上 $\\kappa(x)=\\exp(m_1)$，在 $\\Omega_2$ 上 $\\kappa(x)=\\exp(m_2)$。\n\n使用具有 $N=33$ 个节点的均匀网格对区间 $[0,1]$ 进行离散化，节点位于点 $x_i = i h$，其中 $h = 1/(N-1)$ 且 $i \\in \\{0,1,\\dots,N-1\\}$。令界面位于节点索引 $i_{\\mathrm{I}} = 16$ 处（即 $x_{i_{\\mathrm{I}}}=0.5$）。使用标准的二阶守恒有限差分格式（带可变系数）来近似扩散算子，其中边心系数 $\\kappa_{i+\\frac{1}{2}}$ 在每个子域上是常数，对于边 $i+\\frac{1}{2} \\in \\{0.5,1.5,\\dots,15.5\\}$ 取为 $\\exp(m_1)$，对于边 $i+\\frac{1}{2} \\in \\{16.5,17.5,\\dots,31.5\\}$ 取为 $\\exp(m_2)$。在所有内部节点 $i \\in \\{1,2,\\dots,N-2\\}$ 处使用源项值 $f_i = 1$，且 $f_0=f_{N-1}=0$。在 $x_0=0$ 和 $x_{N-1}=1$ 处施加 Dirichlet 边界条件。使用 Schur 补或子结构化方法，通过界面未知数耦合两个子域的求解，从而在界面上强制离散解的连续性以及跨界面节点的离散外向通量平衡。\n\n定义观测算子，该算子在节点索引 $\\{6,12,20,26\\}$ 处采样离散状态，对应空间位置 $\\{x_6,x_{12},x_{20},x_{26}\\} = \\{6h,12h,20h,26h\\}$。通过使用真值参数 $m_{\\mathrm{true}} = [0.2,-0.1]$ 求解正问题来生成合成数据，以获得离散解 $u^{\\mathrm{true}}$，提取其观测分量 $y^{\\mathrm{true}} \\in \\mathbb{R}^4$，并添加一个固定的噪声向量 $\\eta = [10^{-4},-2\\cdot 10^{-4},1.5\\cdot 10^{-4},-10^{-4}]$（与 $u$ 的单位相同）以获得数据 $d = y^{\\mathrm{true}} + \\eta$。\n\n对于给定的初始猜测 $m^{(0)}=[m^{(0)}_1,m^{(0)}_2]$，对带有零阶正则化和单位数据协方差的 Tikhonov 正则化最小二乘问题执行一个 Gauss–Newton 步，\n$$ \\min_{m \\in \\mathbb{R}^2} \\; \\frac{1}{2}\\|F(m)-d\\|_2^2 + \\frac{\\gamma}{2}\\|m - m_{\\mathrm{ref}}\\|_2^2, $$\n其中 $F(m)$ 将参数对 $m$ 映射到 4 个观测值，$m_{\\mathrm{ref}}=[0,0]$，$\\gamma0$ 是正则化参数。使用在 $m^{(0)}$ 处数据失配项的 Gauss–Newton 线性化，并通过求解由法方程和 Hessian 矩阵的 Gauss–Newton 近似产生的 $2\\times 2$ 线性系统来计算参数增量。雅可比 (Jacobian) 作用必须通过离散正模型的线性化所导出的灵敏度方程获得，并且所有正向和灵敏度线性系统都必须使用如上所述的、在界面处耦合的双子域分解方法来求解。在计算出更新后的参数 $m^{(1)}=m^{(0)}+\\delta m$ 后，报告数据失配项的变化，\n$$ \\Delta \\Phi = \\frac{1}{2}\\|F(m^{(0)})-d\\|_2^2 - \\frac{1}{2}\\|F(m^{(1)})-d\\|_2^2. $$\n\n您的程序必须实现以上内容，并运行以下包含三个案例的测试套件，每个案例由一个初始猜测和一个正则化参数指定：\n- 案例 A（理想路径）：$m^{(0)} = [0.0,0.0]$，$\\gamma = 10^{-2}$。\n- 案例 B（高对比度初始猜测）：$m^{(0)} = [-1.0,1.0]$，$\\gamma = 10^{-2}$。\n- 案例 C（强正则化）：$m^{(0)} = [0.0,0.0]$，$\\gamma = 1.0$。\n\n所有计算都是无量纲的；不需要物理单位。不涉及角度。不涉及百分比。\n\n您的程序应生成单行输出，其中包含案例 A、B 和 C 的三个失配减少量，分别为一个用方括号括起来的逗号分隔列表，每个数字都以小数点后六位四舍五入的十进制浮点数形式打印（例如，$[0.123456,0.000001,0.987654]$）。",
            "solution": "该问题要求对一个由一维非线性扩散方程控制的参数估计问题执行一步 Gauss-Newton 优化。求解过程涉及几个阶段：偏微分方程 (PDE) 的数值离散化、域分解求解器的实现、合成数据的生成、雅可比 (Jacobian) 灵敏度方程的推导和求解，以及最后 Gauss-Newton 系统的组装和求解。\n\n首先，我们定义离散化的正问题。控制方程为\n$$ -\\frac{d}{dx}\\left(\\kappa(m(x)) \\frac{du(x)}{dx}\\right) = f(x), \\quad x \\in (0,1) $$\n边界条件为 $u(0)=0$ 和 $u(1)=0$。该域使用 $N=33$ 个节点 $x_i = i h$（其中 $i \\in \\{0, 1, \\dots, N-1\\}$，$h=1/(N-1) = 1/32$）进行离散化。参数场是分段常数：在 $\\Omega_1=(0, 0.5]$ 上 $m(x)=m_1$，在 $\\Omega_2=[0.5, 1)$ 上 $m(x)=m_2$，因此扩散系数在 $\\Omega_1$ 上为 $\\kappa(x)=\\kappa_1=\\exp(m_1)$，在 $\\Omega_2$ 上为 $\\kappa(x)=\\kappa_2=\\exp(m_2)$。\n\n在内部节点 $i \\in \\{1, 2, \\dots, N-2\\}$ 上使用守恒有限差分格式，我们得到离散方程：\n$$ -\\frac{1}{h}\\left( \\kappa_{i+\\frac{1}{2}} \\frac{u_{i+1}-u_i}{h} - \\kappa_{i-\\frac{1}{2}} \\frac{u_i-u_{i-1}}{h} \\right) = f_i $$\n这对 $N-2=31$ 个内部未知数向量 $u_{int} = [u_1, u_2, \\dots, u_{31}]^T$ 构成了一个线性方程组 $A(m)u_{int} = f_{int}$。源项对于所有内部节点为 $f_i=1$。边界条件 $u_0=0$ 和 $u_{32}=0$ 已被纳入。\n\n该问题指定了一种基于子结构化的域分解方法。内部节点被划分为三组：$\\Omega_1$ 中的未知数（$u_{\\Omega_1} = [u_1, \\dots, u_{15}]^T$）、界面 $i_I=16$ 处的未知数（$u_I = u_{16}$）以及 $\\Omega_2$ 中的未知数（$u_{\\Omega_2} = [u_{17}, \\dots, u_{31}]^T$）。该系统被重排为：\n$$\n\\begin{pmatrix}\nA_{11}  0  A_{1I} \\\\\n0  A_{22}  A_{2I} \\\\\nA_{I1}  A_{I2}  A_{II}\n\\end{pmatrix}\n\\begin{pmatrix}\nu_{\\Omega_1} \\\\\nu_{\\Omega_2} \\\\\nu_I\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nf_{\\Omega_1} \\\\\nf_{\\Omega_2} \\\\\nf_I\n\\end{pmatrix}\n$$\n对角块 $A_{11}$ 和 $A_{22}$ 是 $15 \\times 15$ 的对称三对角矩阵，表示在每个子域上的离散拉普拉斯算子，在外部边界和界面处具有 Dirichlet 条件：\n$$ A_{11} = \\frac{\\kappa_1}{h^2} \\text{tridiag}(-1, 2, -1), \\quad A_{22} = \\frac{\\kappa_2}{h^2} \\text{tridiag}(-1, 2, -1) $$\n耦合块源于界面节点 $i_I=16$ 处的有限差分方程：\n$$ \\frac{1}{h^2} (-\\kappa_1 u_{15} + (\\kappa_1 + \\kappa_2) u_{16} - \\kappa_2 u_{17}) = f_{16} $$\n这定义了 $A_{II} = (\\kappa_1+\\kappa_2)/h^2$ 以及非对角耦合向量。\n\n这个分块系统使用 Schur 补约简法求解。界面未知数 $u_I$ 通过求解 Schur 补系统得到：\n$$ S u_I = f_I - A_{I1} A_{11}^{-1} f_{\\Omega_1} - A_{I2} A_{22}^{-1} f_{\\Omega_2} $$\n其中 Schur 补 $S$ 是一个标量，由 $S = A_{II} - A_{I1} A_{11}^{-1} A_{1I} - A_{I2} A_{22}^{-1} A_{2I}$ 给出。涉及 $A_{11}$ 和 $A_{22}$ 逆的必要矩阵向量积是通过求解每个子域上的线性系统来计算的。一旦 $u_I$ 已知，子域的解通过回代求得：\n$$ u_{\\Omega_1} = A_{11}^{-1} (f_{\\Omega_1} - A_{1I} u_I), \\quad u_{\\Omega_2} = A_{22}^{-1} (f_{\\Omega_2} - A_{2I} u_I) $$\n此过程定义了正向算子 $F(m)$，它将参数向量 $m=[m_1, m_2]^T$ 映射到节点 $\\{6, 12, 20, 26\\}$ 处的 4 个观测值向量。\n\n合成数据 $d$ 通过计算 $d = F(m_{\\mathrm{true}}) + \\eta$ 生成，其中 $m_{\\mathrm{true}}=[0.2,-0.1]$ 且 $\\eta = [10^{-4}, -2 \\cdot 10^{-4}, 1.5 \\cdot 10^{-4}, -10^{-4}]$。逆问题是找到最小化 Tikhonov 正则化成本函数的 $m$：\n$$ \\min_{m \\in \\mathbb{R}^2} \\; \\mathcal{J}(m) = \\frac{1}{2}\\|F(m)-d\\|_2^2 + \\frac{\\gamma}{2}\\|m - m_{\\mathrm{ref}}\\|_2^2 $$\n其中 $m_{\\mathrm{ref}}=[0,0]$。我们从初始猜测 $m^{(0)}$ 开始，执行一步 Gauss-Newton。参数更新量 $\\delta m$ 通过求解源于法方程的 $2 \\times 2$ 线性系统得到：\n$$ (J^T J + \\gamma I) \\delta m = J^T(d - F(m^{(0)})) - \\gamma(m^{(0)} - m_{\\mathrm{ref}}) $$\n其中 $J$ 是 $F$ 在 $m^{(0)}$ 处求值的雅可比矩阵，而 $I$ 是 $2 \\times 2$ 单位矩阵。\n\n雅可比矩阵的列 $J_j = \\partial F / \\partial m_j$（对于 $j \\in \\{1,2\\}$）是使用灵敏度分析计算的。对正向系统 $A(m)u_{int}(m) = f_{int}$ 关于 $m_j$ 求导，得到关于灵敏度向量 $s_j = \\partial u_{int} / \\partial m_j$ 的线性系统：\n$$ A(m) s_j = -\\frac{\\partial A(m)}{\\partial m_j} u_{int}(m) =: g_j $$\n这个关于 $s_j$ 的系统涉及与正问题相同的矩阵 $A(m)$，并使用相同的 Schur 补方法进行高效求解。右端向量 $g_j$ 由离散算子的导数组装而成。对于 $j=1$，$g_1$ 的非零分量对应于节点 $i \\in \\{1, \\dots, 16\\}$ 的方程；对于 $j=2$，它们对应于节点 $i \\in \\{16, \\dots, 31\\}$ 的方程。具体来说，利用 $(A u)_i = f_i$ 这一事实，在 $m^{(0)}$ 处的灵敏度右端项的分量是：\n$$ (g_1)_i = \\begin{cases} -f_i = -1  i \\in \\{1, \\dots, 15\\} \\\\ -\\frac{\\kappa_1}{h^2}(-u_{15}+u_{16})  i=16 \\\\ 0  \\text{otherwise} \\end{cases} \\quad \\text{and} \\quad (g_2)_i = \\begin{cases} -\\frac{\\kappa_2}{h^2}(u_{16}-u_{17})  i=16 \\\\ -f_i = -1  i \\in \\{17, \\dots, 31\\} \\\\ 0  \\text{otherwise} \\end{cases} $$\n求解出 $s_1$ 和 $s_2$ 后，通过应用观测算子获得雅可比矩阵的列：$J_j = s_j|_{\\text{obs_indices}}$。\n\n每个测试案例的算法流程如下：\n1.  给定 $m^{(0)}$ 和 $\\gamma$，求解正问题得到 $u^{(0)}=u(m^{(0)})$，以找到预测数据 $F(m^{(0)})$ 和初始数据失配 $\\Phi_0 = \\frac{1}{2}\\|F(m^{(0)})-d\\|_2^2$。\n2.  使用 $u^{(0)}$ 和 $m^{(0)}$ 计算灵敏度右端项 $g_1$ 和 $g_2$。\n3.  求解灵敏度系统 $A(m^{(0)})s_j=g_j$ 以得到 $s_1$ 和 $s_2$。\n4.  根据 $s_1$ 和 $s_2$ 的观测分量构成 $4 \\times 2$ 的雅可比矩阵 $J$。\n5.  为参数更新量 $\\delta m$ 组装并求解 $2 \\times 2$ 的 Gauss-Newton 系统。\n6.  计算更新后的参数 $m^{(1)} = m^{(0)} + \\delta m$。\n7.  求解正问题得到 $u^{(1)}=u(m^{(1)})$，以找到新的预测数据 $F(m^{(1)})$ 和最终数据失配 $\\Phi_1 = \\frac{1}{2}\\|F(m^{(1)})-d\\|_2^2$。\n8.  最终结果是数据失配的变化量 $\\Delta \\Phi = \\Phi_0 - \\Phi_1$。\n对指定的三个测试案例中的每一个重复此过程。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the entire process for the given test cases.\n    \"\"\"\n    N = 33\n    h = 1.0 / (N - 1)\n    i_I = 16  # Interface node index\n\n    # Observation nodes (1-based index)\n    obs_nodes = np.array([6, 12, 20, 26])\n    # Corresponding 0-based index in the interior solution vector u_int[0...30]\n    obs_indices_in_u_int = obs_nodes - 1\n\n    # Ground truth and data generation\n    m_true = np.array([0.2, -0.1])\n    eta = np.array([1e-4, -2e-4, 1.5e-4, -1e-4])\n    m_ref = np.array([0.0, 0.0])\n\n    u_true_int, _ = solve_forward(m_true, N, h, i_I)\n    y_true = u_true_int[obs_indices_in_u_int]\n    d = y_true + eta\n    \n    # Test cases\n    test_cases = [\n        # Case A\n        {'m0': np.array([0.0, 0.0]), 'gamma': 1e-2},\n        # Case B\n        {'m0': np.array([-1.0, 1.0]), 'gamma': 1e-2},\n        # Case C\n        {'m0': np.array([0.0, 0.0]), 'gamma': 1.0},\n    ]\n\n    results = []\n    for case in test_cases:\n        m0 = case['m0']\n        gamma = case['gamma']\n\n        # 1. Evaluate forward model and Jacobian at m0\n        u0_int, F_m0 = solve_forward(m0, N, h, i_I, obs_indices_in_u_int)\n        \n        g1_rhs = compute_sensitivity_rhs(m0, u0_int, 1, h, N, i_I)\n        g2_rhs = compute_sensitivity_rhs(m0, u0_int, 2, h, N, i_I)\n        \n        s1_int, J_col1 = solve_forward(m0, N, h, i_I, obs_indices_in_u_int, rhs=g1_rhs)\n        s2_int, J_col2 = solve_forward(m0, N, h, i_I, obs_indices_in_u_int, rhs=g2_rhs)\n        \n        J = np.vstack((J_col1, J_col2)).T\n\n        # 2. Compute misfit and Gauss-Newton step\n        residual = d - F_m0\n        phi0 = 0.5 * np.dot(residual, residual)\n\n        H_GN = J.T @ J + gamma * np.eye(2)\n        rhs_GN = J.T @ residual - gamma * (m0 - m_ref)\n        \n        delta_m = np.linalg.solve(H_GN, rhs_GN)\n        m1 = m0 + delta_m\n\n        # 3. Evaluate forward model at m1 and compute final misfit\n        _, F_m1 = solve_forward(m1, N, h, i_I, obs_indices_in_u_int)\n        phi1 = 0.5 * np.dot(d - F_m1, d - F_m1)\n\n        delta_phi = phi0 - phi1\n        results.append(delta_phi)\n\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\n\ndef solve_schur_system(k1, k2, h, i_I, rhs_int):\n    \"\"\"\n    Solves a linear system using the Schur complement (substructuring) method.\n    `rhs_int` is the right-hand side for the interior nodes [1, ..., N-2].\n    \"\"\"\n    num_sub_nodes = i_I - 1  # 15 nodes in each subdomain interior\n\n    # Partition the RHS\n    rhs1 = rhs_int[:num_sub_nodes]\n    rhs_I = rhs_int[num_sub_nodes]\n    rhs2 = rhs_int[num_sub_nodes+1:]\n\n    # Build subdomain matrices A11 and A22 (banded format for solve_banded)\n    # A = diag(d) + diag(e, 1) + diag(e, -1) has banded form:\n    # [e, d, e] - ab = [[0, *e], [d], [*e, 0]]\n    A11_banded = np.zeros((3, num_sub_nodes))\n    A11_banded[0, 1:] = -1.0\n    A11_banded[1, :] = 2.0\n    A11_banded[2, :-1] = -1.0\n    A11_banded *= k1 / h**2\n\n    A22_banded = np.zeros((3, num_sub_nodes))\n    A22_banded[0, 1:] = -1.0\n    A22_banded[1, :] = 2.0\n    A22_banded[2, :-1] = -1.0\n    A22_banded *= k2 / h**2\n\n    # Coupling vectors\n    A1I = np.zeros(num_sub_nodes); A1I[-1] = -k1 / h**2\n    A2I = np.zeros(num_sub_nodes); A2I[0] = -k2 / h**2\n    AI1 = A1I\n    AI2 = A2I\n\n    # Interface 'matrix'\n    AII = (k1 + k2) / h**2\n\n    # Solve for constituents of Schur complement system\n    # v1 = A11^{-1} f1\n    v1 = solve_banded((1, 1), A11_banded, rhs1)\n    # v2 = A22^{-1} f2\n    v2 = solve_banded((1, 1), A22_banded, rhs2)\n    # w1 = A11^{-1} A1I\n    w1 = solve_banded((1, 1), A11_banded, A1I)\n    # w2 = A22^{-1} A2I\n    w2 = solve_banded((1, 1), A22_banded, A2I)\n    \n    # Schur complement and its RHS (both are scalars)\n    S = AII - np.dot(AI1, w1) - np.dot(AI2, w2)\n    rhs_S = rhs_I - np.dot(AI1, v1) - np.dot(AI2, v2)\n    \n    # Solve for interface unknown\n    u_I = rhs_S / S\n    \n    # Back-substitute for subdomain unknowns\n    u1 = v1 - w1 * u_I\n    u2 = v2 - w2 * u_I\n    \n    # Assemble full interior solution\n    u_int = np.concatenate((u1, [u_I], u2))\n    return u_int\n\n\ndef solve_forward(m, N, h, i_I, obs_indices_in_u_int=None, rhs=None):\n    \"\"\"\n    Solves the forward or sensitivity problem. If rhs is None, solves the\n    forward problem with source f=1. Otherwise, solves with the given rhs.\n    Returns the full interior solution and optionally the observed values.\n    \"\"\"\n    k1, k2 = np.exp(m[0]), np.exp(m[1])\n    num_int_nodes = N - 2\n\n    if rhs is None:\n        # Standard forward problem RHS (f_i = 1 for all interior nodes)\n        rhs = np.ones(num_int_nodes)\n        \n    u_int = solve_schur_system(k1, k2, h, i_I, rhs)\n\n    if obs_indices_in_u_int is not None:\n        return u_int, u_int[obs_indices_in_u_int]\n    return u_int, None\n\n\ndef compute_sensitivity_rhs(m, u_int, param_idx, h, N, i_I):\n    \"\"\"\n    Computes the right-hand side vector g_j for the sensitivity equation.\n    param_idx is 1 for m1, 2 for m2.\n    \"\"\"\n    k1, k2 = np.exp(m[0]), np.exp(m[1])\n    num_int_nodes = N - 2\n    num_sub_nodes = i_I - 1\n\n    g = np.zeros(num_int_nodes)\n    \n    u_full = np.concatenate(([0], u_int, [0]))\n    u_15 = u_full[i_I - 1]\n    u_16 = u_full[i_I]\n    u_17 = u_full[i_I + 1]\n\n    if param_idx == 1:\n        g[:num_sub_nodes] = -1.0 # correspoding to nodes 1...15\n        g[num_sub_nodes] = -(k1 / h**2) * (-u_15 + u_16)\n    elif param_idx == 2:\n        g[num_sub_nodes] = -(k2 / h**2) * (u_16 - u_17)\n        g[num_sub_nodes+1:] = -1.0 # correspoding to nodes 17...31\n    \n    return g\n\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}