{
    "hands_on_practices": [
        {
            "introduction": "最优输运的核心思想可以通过一个简单的离散形式来理解。这个练习  提供了一个具体的起点，它将最优输运问题构建为一个线性规划问题，这是优化领域的一个基本概念。通过解决这个小规模的例子，你将能够亲手计算耦合矩阵，从而对“输运方案”的结构建立起直观的认识。",
            "id": "3408143",
            "problem": "考虑一个离散设置中的贝叶斯推断，其中一个由粒子 $\\{x_i\\}_{i=1}^{m}$ 支持、概率为 $\\{p_i\\}_{i=1}^{m}$ 的离散先验分布，被更新为一个由粒子 $\\{y_j\\}_{j=1}^{n}$ 支持、概率为 $\\{q_j\\}_{j=1}^{n}$ 的离散后验分布。在二次运输成本下，贝叶斯更新可以通过求解一个线性规划得到一个最优运输方案来表示，该方案将先验分布与后验分布耦合起来。\n\n任务1（公式化）：仅从最优运输的 Kantorovich 公式出发，写出寻求耦合矩阵 $\\Gamma=\\{\\gamma_{ij}\\}\\in\\mathbb{R}_{+}^{m\\times n}$ 的线性规划，该规划旨在最小化期望二次成本，同时满足关于先验和后验概率的质量守恒约束。请用数学形式清晰地陈述目标和约束。\n\n任务2（在一个小例子上进行计算）：设 $m=3$ 且 $n=2$。考虑以下一维粒子和概率：\n- 先验支持集 $\\{x_1,x_2,x_3\\}=\\{0,1,3\\}$，概率为 $\\{p_1,p_2,p_3\\}=\\left\\{\\frac{1}{2},\\frac{1}{3},\\frac{1}{6}\\right\\}$，\n- 后验支持集 $\\{y_1,y_2\\}=\\left\\{\\frac{1}{2},\\frac{5}{2}\\right\\}$，概率为 $\\{q_1,q_2\\}=\\left\\{\\frac{2}{3},\\frac{1}{3}\\right\\}$。\n\n在 $\\mathbb{R}$ 上使用二次成本 $c_{ij}=\\|x_i-y_j\\|^2$。通过求解任务1中的线性规划，为此实例计算一个最优耦合 $\\Gamma^{\\star}$。然后计算得到的最优总二次运输成本 $\\sum_{i=1}^{3}\\sum_{j=1}^{2}\\gamma^{\\star}_{ij}\\,\\|x_i-y_j\\|^{2}$。\n\n答案规格：仅报告最优总二次运输成本，以最简分数形式的精确值给出。不要四舍五入。在最终答案中不要包含单位或任何附加文本。",
            "solution": "该问题是有效的，因为它在科学上基于最优运输理论，是适定的（提供了所有必要信息），并且表述客观。该问题包含两个任务：首先，为离散最优运输问题建立一个线性规划；其次，解决该问题的一个具体实例。\n\n**任务1：线性规划的公式化**\n\n在两个离散概率测度之间寻找最优运输方案的问题被称为 Kantorovich 问题。设先验测度为 $\\mu = \\sum_{i=1}^{m} p_i \\delta_{x_i}$，后验测度为 $\\nu = \\sum_{j=1}^{n} q_j \\delta_{y_j}$，其中 $\\delta_z$ 表示在点 $z$ 处的狄拉克 delta 测度。概率满足 $\\sum_{i=1}^{m} p_i = 1$ 和 $\\sum_{j=1}^{n} q_j = 1$。\n\n$\\mu$ 和 $\\nu$ 之间的一个耦合（或运输方案）是乘积空间上的一个测度，其边际分布为 $\\mu$ 和 $\\nu$。在离散情况下，这对应于一个矩阵 $\\Gamma = \\{\\gamma_{ij}\\} \\in \\mathbb{R}^{m \\times n}$，其中 $\\gamma_{ij}$ 表示从位置 $x_i$ 运输到位置 $y_j$ 的质量量。要使 $\\Gamma$ 成为一个有效的耦合，它必须满足边际约束：\n1.  从 $x_i$ 运出的总质量必须等于该点的质量 $p_i$。这对应于 $\\Gamma$ 的行和：\n    $$ \\sum_{j=1}^{n} \\gamma_{ij} = p_i, \\quad \\text{for } i = 1, 2, \\ldots, m $$\n2.  运输到 $y_j$ 的总质量必须等于该点的质量 $q_j$。这对应于 $\\Gamma$ 的列和：\n    $$ \\sum_{i=1}^{m} \\gamma_{ij} = q_j, \\quad \\text{for } j = 1, 2, \\ldots, n $$\n3.  运输的质量不能为负：\n    $$ \\gamma_{ij} \\ge 0, \\quad \\text{for all } i, j $$\n\n将单位质量从 $x_i$ 运输到 $y_j$ 的成本由欧几里得距离的平方 $c_{ij} = \\|x_i - y_j\\|^2$ 给出。总运输成本是关于耦合 $\\Gamma$ 的期望成本。目标是找到使该总成本最小化的耦合 $\\Gamma^{\\star}$。\n\n这个问题可以公式化为一个线性规划：\n\n**目标函数：**\n最小化总运输成本 $Z$：\n$$ \\min_{\\Gamma} Z = \\sum_{i=1}^{m} \\sum_{j=1}^{n} c_{ij} \\gamma_{ij} $$\n\n**约束条件：**\n$$\n\\begin{align*}\n\\sum_{j=1}^{n} \\gamma_{ij} = p_i,  \\forall i \\in \\{1, \\ldots, m\\} \\\\\n\\sum_{i=1}^{m} \\gamma_{ij} = q_j,  \\forall j \\in \\{1, \\ldots, n\\} \\\\\n\\gamma_{ij} \\ge 0,  \\forall i \\in \\{1, \\ldots, m\\}, \\forall j \\in \\{1, \\ldots, n\\}\n\\end{align*}\n$$\n\n**任务2：在一个小例子上进行计算**\n\n我们被给予以下实例：\n-   先验支持集 $\\{x_1, x_2, x_3\\} = \\{0, 1, 3\\}$，概率为 $\\{p_1, p_2, p_3\\} = \\{\\frac{1}{2}, \\frac{1}{3}, \\frac{1}{6}\\}$。\n-   后验支持集 $\\{y_1, y_2\\} = \\{\\frac{1}{2}, \\frac{5}{2}\\}$，概率为 $\\{q_1, q_2\\} = \\{\\frac{2}{3}, \\frac{1}{3}\\}$。\n\n首先，我们计算成本矩阵 $C = \\{c_{ij}\\}$，其中 $c_{ij} = (x_i - y_j)^2$：\n$c_{11} = (0 - \\frac{1}{2})^2 = \\frac{1}{4}$\n$c_{12} = (0 - \\frac{5}{2})^2 = \\frac{25}{4}$\n$c_{21} = (1 - \\frac{1}{2})^2 = (\\frac{1}{2})^2 = \\frac{1}{4}$\n$c_{22} = (1 - \\frac{5}{2})^2 = (-\\frac{3}{2})^2 = \\frac{9}{4}$\n$c_{31} = (3 - \\frac{1}{2})^2 = (\\frac{5}{2})^2 = \\frac{25}{4}$\n$c_{32} = (3 - \\frac{5}{2})^2 = (\\frac{1}{2})^2 = \\frac{1}{4}$\n\n成本矩阵为：\n$$ C = \\begin{pmatrix} \\frac{1}{4}  \\frac{25}{4} \\\\ \\frac{1}{4}  \\frac{9}{4} \\\\ \\frac{25}{4}  \\frac{1}{4} \\end{pmatrix} $$\n\n线性规划问题是最小化 $Z = \\frac{1}{4}\\gamma_{11} + \\frac{25}{4}\\gamma_{12} + \\frac{1}{4}\\gamma_{21} + \\frac{9}{4}\\gamma_{22} + \\frac{25}{4}\\gamma_{31} + \\frac{1}{4}\\gamma_{32}$，约束条件为：\n\\begin{align*}\n\\gamma_{11} + \\gamma_{12} = \\frac{1}{2} \\\\\n\\gamma_{21} + \\gamma_{22} = \\frac{1}{3} \\\\\n\\gamma_{31} + \\gamma_{32} = \\frac{1}{6} \\\\\n\\gamma_{11} + \\gamma_{21} + \\gamma_{31} = \\frac{2}{3} \\\\\n\\gamma_{12} + \\gamma_{22} + \\gamma_{32} = \\frac{1}{3} \\\\\n\\gamma_{ij} \\ge 0\n\\end{align*}\n我们使用行和约束来用 $\\gamma_{i1}$ 表示 $\\gamma_{i2}$：$\\gamma_{12} = \\frac{1}{2} - \\gamma_{11}$，$\\gamma_{22} = \\frac{1}{3} - \\gamma_{21}$，$\\gamma_{32} = \\frac{1}{6} - \\gamma_{31}$。将这些代入目标函数：\n$$ Z = \\frac{1}{4}\\gamma_{11} + \\frac{25}{4}(\\frac{1}{2} - \\gamma_{11}) + \\frac{1}{4}\\gamma_{21} + \\frac{9}{4}(\\frac{1}{3} - \\gamma_{21}) + \\frac{25}{4}\\gamma_{31} + \\frac{1}{4}(\\frac{1}{6} - \\gamma_{31}) $$\n$$ Z = (\\frac{1}{4} - \\frac{25}{4})\\gamma_{11} + (\\frac{1}{4} - \\frac{9}{4})\\gamma_{21} + (\\frac{25}{4} - \\frac{1}{4})\\gamma_{31} + \\frac{25}{8} + \\frac{9}{12} + \\frac{1}{24} $$\n$$ Z = -6\\gamma_{11} - 2\\gamma_{21} + 6\\gamma_{31} + \\frac{75+18+1}{24} = -6\\gamma_{11} - 2\\gamma_{21} + 6\\gamma_{31} + \\frac{47}{12} $$\n剩下的独立约束是：\n\\begin{align*}\n\\gamma_{11} + \\gamma_{21} + \\gamma_{31} = \\frac{2}{3} \\\\\n0 \\le \\gamma_{11} \\le \\frac{1}{2} \\\\\n0 \\le \\gamma_{21} \\le \\frac{1}{3} \\\\\n0 \\le \\gamma_{31} \\le \\frac{1}{6}\n\\end{align*}\n为了最小化 $Z$，我们需要使 $\\gamma_{11}$ 和 $\\gamma_{21}$ 尽可能大（因为系数为负的 $-6$ 和 $-2$），并使 $\\gamma_{31}$ 尽可能小（因为系数为正的 $6$）。\n让我们尝试将 $\\gamma_{31}$ 设置为其最小值 $\\gamma_{31} = 0$。约束变为 $\\gamma_{11} + \\gamma_{21} = \\frac{2}{3}$。\n为了最小化目标函数，我们优先使 $\\gamma_{11}$ 最大。我们将 $\\gamma_{11}$ 设置为其上界：$\\gamma_{11} = \\frac{1}{2}$。\n这意味着 $\\gamma_{21} = \\frac{2}{3} - \\gamma_{11} = \\frac{2}{3} - \\frac{1}{2} = \\frac{1}{6}$。\n让我们检查这个解是否可行：\n- $\\gamma_{11} = \\frac{1}{2}$，在 $[0, \\frac{1}{2}]$ 范围内。\n- $\\gamma_{21} = \\frac{1}{6}$，在 $[0, \\frac{1}{3}]$ 范围内。\n- $\\gamma_{31} = 0$，在 $[0, \\frac{1}{6}]$ 范围内。\n该解是可行的，并且根据我们基于目标函数系数的贪婪构造方法，它是最优的。\n\n现在我们找出最优耦合矩阵 $\\Gamma^{\\star}$ 的其余分量：\n$\\gamma^{\\star}_{11} = \\frac{1}{2}$\n$\\gamma^{\\star}_{21} = \\frac{1}{6}$\n$\\gamma^{\\star}_{31} = 0$\n$\\gamma^{\\star}_{12} = p_1 - \\gamma^{\\star}_{11} = \\frac{1}{2} - \\frac{1}{2} = 0$\n$\\gamma^{\\star}_{22} = p_2 - \\gamma^{\\star}_{21} = \\frac{1}{3} - \\frac{1}{6} = \\frac{1}{6}$\n$\\gamma^{\\star}_{32} = p_3 - \\gamma^{\\star}_{31} = \\frac{1}{6} - 0 = \\frac{1}{6}$\n\n最优耦合矩阵是：\n$$ \\Gamma^{\\star} = \\begin{pmatrix} \\frac{1}{2}  0 \\\\ \\frac{1}{6}  \\frac{1}{6} \\\\ 0  \\frac{1}{6} \\end{pmatrix} $$\n\n最后，我们将 $\\Gamma^{\\star}$ 代入目标函数来计算最优总运输成本：\n$$ Z^{\\star} = \\sum_{i=1}^{3}\\sum_{j=1}^{2} c_{ij} \\gamma^{\\star}_{ij} $$\n$$ Z^{\\star} = c_{11}\\gamma^{\\star}_{11} + c_{21}\\gamma^{\\star}_{21} + c_{22}\\gamma^{\\star}_{22} + c_{32}\\gamma^{\\star}_{32} $$\n$$ Z^{\\star} = (\\frac{1}{4})(\\frac{1}{2}) + (\\frac{1}{4})(\\frac{1}{6}) + (\\frac{9}{4})(\\frac{1}{6}) + (\\frac{1}{4})(\\frac{1}{6}) $$\n$$ Z^{\\star} = \\frac{1}{8} + \\frac{1}{24} + \\frac{9}{24} + \\frac{1}{24} $$\n$$ Z^{\\star} = \\frac{3}{24} + \\frac{1+9+1}{24} = \\frac{3}{24} + \\frac{11}{24} = \\frac{14}{24} $$\n化简分数得到最优成本：\n$$ Z^{\\star} = \\frac{7}{12} $$\n这个结果可以用简化的目标函数来验证：\n$Z^{\\star} = -6(\\frac{1}{2}) - 2(\\frac{1}{6}) + 6(0) + \\frac{47}{12} = -3 - \\frac{1}{3} + \\frac{47}{12} = -\\frac{10}{3} + \\frac{47}{12} = -\\frac{40}{12} + \\frac{47}{12} = \\frac{7}{12}$。\n计算结果一致。",
            "answer": "$$\\boxed{\\frac{7}{12}}$$"
        },
        {
            "introduction": "在贝叶斯推断中，我们常常需要在离散分布和连续分布之间建立联系。这个练习  探讨了一个关键的理论问题：何时我们必须放弃寻找一个简单的确定性映射（Monge 解），而转向使用更通用的概率性耦合（Kantorovich 方案）？通过这个例子，你将理解 Kantorovich formulation 的必要性，并学会使用分位数函数来处理一维空间中的最优输运问题。",
            "id": "3408183",
            "problem": "考虑一个数据同化中的标量反问题，其中未知参数为 $x \\in \\mathbb{R}$。初始的先验信念由两点概率测度 $\\mu = p\\,\\delta_{-a} + (1-p)\\,\\delta_{a}$ 表示，其中 $a \\in (0,\\infty)$ 且 $p \\in (0,1)$。假设希望采用最优输运 (Optimal Transport, OT) 方法，将先验 $\\mu$ 映射到一个目标后验分布 $\\nu$，该后验分布相对于勒贝格测度是绝对连续的（例如，数据同化中常用的高斯后验近似）。设输运成本为二次成本 $c(x,y) = (x-y)^2$。\n\n任务：\n- 仅使用前推测度、狄拉克测度和蒙日 (Monge) 公式的核心定义，证明当 $\\nu$ 存在密度时，不存在确定性的可测输运映射 $T:\\mathbb{R}\\to\\mathbb{R}$ 满足 $T_{\\#}\\mu=\\nu$。由此断定，在此设定下蒙日问题无解，必须转而采用坎托罗维奇 (Kantorovich) 输运方案（一种概率耦合）。\n- 为配对 $(\\mu,\\nu)$ 和成本 $c(x,y)=(x-y)^2$ 构建坎托罗维奇问题，并回顾该问题的最小值等于沃瑟斯坦-2 (W2) 距離的平方 $W_{2}^{2}(\\mu,\\nu)$。\n- 将问题具体化到 $p=\\tfrac{1}{2}$，$a=1$ 且 $\\nu=\\mathcal{N}(0,1)$（标准正态分布）的实例。仅使用一维最优输运的基本性质（特别是单调重排或分位数表示）和基础微积分，推導坎托罗维奇最小成本 $W_{2}^{2}(\\mu,\\nu)$ 的封闭形式解析表达式。\n\n答案规格：\n- 您的最终答案必须是单个封闭形式的解析表达式。\n- 无需四舍五入，最终答案中不包含单位。",
            "solution": "我们从适用于贝叶斯推断的最优输运的第一性原理出发，从前推测度、蒙日 (Monge) 和坎托罗维奇 (Kantorovich) 公式的核心定义，以及沃瑟斯坦-2 (W2) 距离的一维单调重排刻画开始。\n\n1. 从离散先验到连续后验的蒙日输运映射的不存在性。\n- 设 $\\mu = p\\,\\delta_{-a} + (1-p)\\,\\delta_{a}$，其中 $p \\in (0,1)$ 且 $a \\in (0,\\infty)$。根据定义，狄拉克测度 $\\delta_{x_{0}}$ 将单位质量赋予点 $x_{0}$。在可测映射 $T:\\mathbb{R}\\to\\mathbb{R}$ 下，测度 $\\mu$ 的前推是测度 $T_{\\#}\\mu$，定义为 $T_{\\#}\\mu(B) = \\mu(T^{-1}(B))$，对所有博雷尔集 $B \\subset \\mathbb{R}$ 成立。\n- 如果 $\\mu$ 是有限支撑的，例如 $\\mu=\\sum_{i=1}^{m}\\alpha_{i}\\,\\delta_{x_{i}}$，其中 $\\alpha_{i}>0$，$\\sum_{i}\\alpha_{i}=1$，那么对于任何可测的 $T$，我们有\n$$\nT_{\\#}\\mu \\;=\\; \\sum_{i=1}^{m}\\alpha_{i}\\,\\delta_{T(x_{i})}.\n$$\n因此，$T_{\\#}\\mu$ 也是有限支撑的，最多有 $m$ 个原子。特别地，如果 $m=2$，则 $T_{\\#}\\mu$ 的支撑集基数最多为 $2$。\n- 假设目标后验 $\\nu$ 相对于勒贝格测度是绝对连续的，并且存在密度 $\\rho_{\\nu}(y)$，因此对于每个单点集 $\\{y_{0}\\}$ 我们有 $\\nu(\\{y_{0}\\})=0$。一个有限支撑的测度不能等于一个绝对连续的测度。因此，在这种情况下，不存在可测映射 $T$ 使得 $T_{\\#}\\mu=\\nu$。\n- 因此，寻求一个确定性的可测映射 $T$ 满足 $T_{\\#}\\mu=\\nu$ 并最小化输运成本 $\\int (x-T(x))^{2}\\,\\mathrm{d}\\mu(x)$ 的蒙日问题无解。必须转而使用坎托罗维奇公式，它允许通过耦合进行质量分裂。\n\n2. 坎托罗维奇公式与沃瑟斯坦-2 距离。\n- 坎托罗维奇问题寻求一个在 $\\mathbb{R}\\times\\mathbb{R}$ 上的耦合 $\\gamma$，其边缘分布为 $\\mu$ 和 $\\nu$，即 $\\gamma \\in \\Gamma(\\mu,\\nu)$，其中\n$$\n\\Gamma(\\mu,\\nu) \\;=\\; \\left\\{ \\gamma \\in \\mathcal{P}(\\mathbb{R}\\times\\mathbb{R}) \\,:\\, \\gamma(A\\times \\mathbb{R})=\\mu(A),\\; \\gamma(\\mathbb{R}\\times B)=\\nu(B)\\;\\text{对所有博雷尔集 }A,B \\right\\},\n$$\n以最小化期望成本\n$$\n\\inf_{\\gamma \\in \\Gamma(\\mu,\\nu)} \\int_{\\mathbb{R}\\times\\mathbb{R}} (x-y)^{2}\\,\\mathrm{d}\\gamma(x,y).\n$$\n- 根据定义，这个下确界等于沃瑟斯坦-2 (W2) 距离的平方：\n$$\nW_{2}^{2}(\\mu,\\nu) \\;=\\; \\inf_{\\gamma \\in \\Gamma(\\mu,\\nu)} \\int_{\\mathbb{R}\\times\\mathbb{R}} (x-y)^{2}\\,\\mathrm{d}\\gamma(x,y).\n$$\n由于 $\\nu$ 是绝对连续的，存在一个最优耦合，在一维情况下，该耦合由单调重排耦合导出。\n\n3. 计算 $p=\\tfrac{1}{2}$，$a=1$ 且 $\\nu=\\mathcal{N}(0,1)$ 时的 $W_{2}^{2}$。\n- 在一维情况下，二次成本的最优耦合由增序重排给出，并且可以写成\n$$\nW_{2}^{2}(\\mu,\\nu) \\;=\\; \\int_{0}^{1} \\bigl(F_{\\mu}^{-1}(u) - F_{\\nu}^{-1}(u)\\bigr)^{2}\\,\\mathrm{d}u,\n$$\n其中 $F_{\\mu}^{-1}$ 和 $F_{\\nu}^{-1}$ 是 $\\mu$ 和 $\\nu$ 的分位数函数。这是一维最优输运中一个标准的、经过充分检验的结果。\n- 对于 $\\mu=\\tfrac{1}{2}\\delta_{-1}+\\tfrac{1}{2}\\delta_{1}$，其分位数函数为\n$$\nF_{\\mu}^{-1}(u) \\;=\\; \\begin{cases}\n-1,  u \\in [0,\\tfrac{1}{2}),\\\\\n1,  u \\in [\\tfrac{1}{2},1].\n\\end{cases}\n$$\n对于 $\\nu=\\mathcal{N}(0,1)$，$F_{\\nu}^{-1}(u)=\\Phi^{-1}(u)$，其中 $\\Phi$ 是标准正态累积分布函数，$\\Phi^{-1}$ 是其分位数函数。\n- 因此，\n$$\nW_{2}^{2}(\\mu,\\nu) \\;=\\; \\int_{0}^{\\tfrac{1}{2}} \\bigl(-1 - \\Phi^{-1}(u)\\bigr)^{2} \\,\\mathrm{d}u \\;+\\; \\int_{\\tfrac{1}{2}}^{1} \\bigl(1 - \\Phi^{-1}(u)\\bigr)^{2} \\,\\mathrm{d}u.\n$$\n在第二个积分中使用对称性 $\\Phi^{-1}(1-u)=-\\Phi^{-1}(u)$ 和换元 $v=1-u$，可知这两个积分相等，得到\n$$\nW_{2}^{2}(\\mu,\\nu) \\;=\\; 2 \\int_{0}^{\\tfrac{1}{2}} \\bigl(\\Phi^{-1}(u)+1\\bigr)^{2}\\,\\mathrm{d}u.\n$$\n- 做变量替换 $z=\\Phi^{-1}(u)$，于是有 $\\mathrm{d}u=\\phi(z)\\,\\mathrm{d}z$，其中 $\\phi(z)=\\tfrac{1}{\\sqrt{2\\pi}}\\exp(-z^{2}/2)$ 是标准正态密度。当 $u$ 从 $0$ 变到 $\\tfrac{1}{2}$ 时，$z$ 从 $-\\infty$ 变到 $0$。因此\n$$\nW_{2}^{2}(\\mu,\\nu) \\;=\\; 2 \\int_{-\\infty}^{0} (z+1)^{2}\\,\\phi(z)\\,\\mathrm{d}z \\;=\\; 2 \\left[ \\int_{-\\infty}^{0} z^{2}\\phi(z)\\,\\mathrm{d}z \\;+\\; 2 \\int_{-\\infty}^{0} z\\,\\phi(z)\\,\\mathrm{d}z \\;+\\; \\int_{-\\infty}^{0} \\phi(z)\\,\\mathrm{d}z \\right].\n$$\n我们现在使用标准正态分布的基本性质来计算每一项：\n- 由于 $z^{2}\\phi(z)$ 是偶函数且 $\\int_{\\mathbb{R}} z^{2}\\phi(z)\\,\\mathrm{d}z = 1$，我们有\n$$\n\\int_{-\\infty}^{0} z^{2}\\phi(z)\\,\\mathrm{d}z \\;=\\; \\tfrac{1}{2}.\n$$\n- 使用 $\\tfrac{\\mathrm{d}}{\\mathrm{d}z}\\phi(z)=-z\\phi(z)$，我们得到\n$$\n\\int_{-\\infty}^{0} z\\,\\phi(z)\\,\\mathrm{d}z \\;=\\; -\\phi(0) \\;=\\; -\\tfrac{1}{\\sqrt{2\\pi}}.\n$$\n- 根据对称性，\n$$\n\\int_{-\\infty}^{0} \\phi(z)\\,\\mathrm{d}z \\;=\\; \\tfrac{1}{2}.\n$$\n代入计算，\n$$\nW_{2}^{2}(\\mu,\\nu) \\;=\\; 2 \\left[ \\tfrac{1}{2} \\;+\\; 2\\left(-\\tfrac{1}{\\sqrt{2\\pi}}\\right) \\;+\\; \\tfrac{1}{2} \\right] \\;=\\; 2 \\left[ 1 \\;-\\; \\tfrac{2}{\\sqrt{2\\pi}} \\right] \\;=\\; 2 \\;-\\; \\tfrac{4}{\\sqrt{2\\pi}}.\n$$\n该值是在二次成本下将两点先验 $\\mu$ 映射到连续目标 $\\nu$ 的最小坎托罗维奇输运成本，它量化了在蒙日映射不存在时诉诸概率耦合的必要性（以及代价）。",
            "answer": "$$\\boxed{2-\\frac{4}{\\sqrt{2\\pi}}}$$"
        },
        {
            "introduction": "虽然最优输运理论优美，但直接求解在处理大规模问题时计算成本可能很高。这个练习  将理论与现代计算方法相结合，介绍了熵正则化方法和 Sinkhorn 算法，这是一种高效计算近似输运方案的强大技术。这个实践的价值不仅在于实现这一关键算法，更在于分析近似所引入的偏差，这是任何从业者都必须掌握的重要技能。",
            "id": "3408171",
            "problem": "考虑一个一维空间中的贝叶斯逆问题，其中未知参数为 $\\theta \\in \\mathbb{R}$。设先验为高斯分布 $\\mu = \\mathcal{N}(0,\\tau^2)$，其中 $\\tau  0$；观测模型为 $y_{\\mathrm{obs}} = G(\\theta) + \\eta$，其中 $G(\\theta) = \\theta$，噪声 $\\eta$ 为零均值高斯噪声，$\\eta \\sim \\mathcal{N}(0,\\sigma^2)$，且 $\\sigma  0$。根据贝叶斯法则，后验分布也是高斯分布 $\\nu = p(\\theta \\mid y_{\\mathrm{obs}}) = \\mathcal{N}(m,s^2)$，其中 $s^2 = (\\tau^{-2} + \\sigma^{-2})^{-1}$，$m = s^2 \\, \\sigma^{-2} \\, y_{\\mathrm{obs}}$。我们考虑通过最优输运（OT）方法来解决贝叶斯推断问题，具体方法是使用从先验到后验的输运映射的熵正则化近似（Sinkhorn算法）。\n\n使用的基本定义：\n- 两个概率测度 $\\mu$ 和 $\\nu$（在 $\\mathbb{R}$ 上）之间的一个耦合 $\\pi$ 是在 $\\mathbb{R} \\times \\mathbb{R}$ 上的一个联合概率测度，其边缘分布为 $\\mu$ 和 $\\nu$。对于一个成本函数 $c(x,y)$，（Kantorovich）最优输运问题旨在求解 $\\inf_{\\pi \\in \\Pi(\\mu,\\nu)} \\int c(x,y) \\, d\\pi(x,y)$。\n- 熵正则化最优输运问题将目标函数替换为 $\\int c(x,y) \\, d\\pi(x,y) + \\varepsilon \\, \\mathrm{KL}(\\pi \\,\\|\\, \\mu \\otimes \\nu)$，其中正则化参数 $\\varepsilon  0$，$\\mathrm{KL}$ 表示 Kullback–Leibler 散度，$\\mu \\otimes \\nu$ 是乘积测度。在离散、均匀权重的情况下，对于二次成本 $c(x,y) = \\frac{1}{2}\\| x - y \\|^2$，Gibbs 核为 $K_{ij} = \\exp(-C_{ij}/\\varepsilon)$，其中 $C_{ij} = \\frac{1}{2}(x_i - y_j)^2$，而 Sinkhorn 缩放算法可以得到具有指定边缘分布的耦合 $\\pi_\\varepsilon$。\n- 与 $\\pi_\\varepsilon$ 相关的重心投影输运近似是映射 $T_\\varepsilon(x) = \\mathbb{E}[Y \\mid X=x]$，它是从 $\\pi_\\varepsilon$ 计算得出的。相应的近似后验是前推测度 $T_\\varepsilon \\# \\mu$。\n\n推导任务：\n1. 从 $\\nu$ 的贝叶斯法则、OT 的 Kantorovich 公式以及熵正则化的定义出发，论证在经验测度 $\\hat{\\mu}$ 和 $\\hat{\\nu}$（由从 $\\mu$ 和 $\\nu$ 中抽取的独立同分布样本构成）之间为二次成本 $c(x,y) = \\frac{1}{2}\\| x - y \\|^2$ 构建离散 Sinkhorn 耦合 $\\pi_\\varepsilon$ 的合理性，并定义重心映射 $T_\\varepsilon$。\n2. 对于一个 Lipschitz 常数为 $L$ 的 Lipschitz 函数 $f:\\mathbb{R} \\to \\mathbb{R}$，推导用 $\\mathbb{E}_{T_\\varepsilon \\# \\mu}[f(\\theta)]$ 估计 $\\mathbb{E}_{\\nu}[f(\\theta)]$ 时产生的偏差的一个界，该界用 $\\varepsilon$ 和 $L$ 表示，且在 $\\varepsilon \\to 0$ 时成立。从 Kantorovich–Rubinstein 型不等式 $|\\mathbb{E}_{\\nu}[f] - \\mathbb{E}_{T_\\varepsilon \\# \\mu}[f]| \\leq L \\, \\mathbb{E}_{\\pi_\\varepsilon}[\\| Y - T_\\varepsilon(X)\\|]$ 出发，仅使用适用于二次成本的标准凸性和集中性论证，得到一个与 $\\varepsilon$ 相关的显式缩放关系。清晰地陈述使你的界成立所需的任何条件，并确保每一步都源自一个基本原理或一个经过充分检验的结果（例如，对数凹测度的性质或 Poincaré 不等式）。\n3. 将前述的界具体化到一维情况以及具有已知 Lipschitz 常数的函数 $f$。\n\n数值实验与测试套件：\n- 固定 $d=1$（一维参数），$\\tau = 1$，$\\sigma = 0.3$ 以及 $y_{\\mathrm{obs}} = 0.7$。这些参数定义了后验分布 $\\nu = \\mathcal{N}(m,s^2)$，其中 $s^2 = (1/\\tau^2 + 1/\\sigma^2)^{-1}$，$m = s^2(y_{\\mathrm{obs}}/\\sigma^2)$。从 $\\mu = \\mathcal{N}(0,\\tau^2)$ 中抽取 $n=128$ 个独立同分布样本 $\\{x_i\\}_{i=1}^n$，并从 $\\nu = \\mathcal{N}(m,s^2)$ 中抽取 $\\{y_j\\}_{j=1}^n$ 个样本，以构成经验测度 $\\hat{\\mu}$ 和 $\\hat{\\nu}$。\n- 对于每一个 $\\varepsilon \\in \\{1.0, 0.5, 0.2\\}$，计算 $\\hat{\\mu}$ 和 $\\hat{\\nu}$ 之间在成本函数 $c(x,y) = \\frac{1}{2}(x - y)^2$ 下的 Sinkhorn 耦合 $\\pi_\\varepsilon$，以及相关的重心映射值 $T_\\varepsilon(x_i)$。考虑以下函数：\n  - $f_1(\\theta) = \\theta$，Lipschitz 常数为 $L_1 = 1$，\n  - $f_2(\\theta) = |\\theta|$，Lipschitz 常数为 $L_2 = 1$，\n  - $f_3(\\theta) = \\sin(2\\theta)$，Lipschitz 常数为 $L_3 = 2$。\n- 对于每一对 $(\\varepsilon, f_k)$，其中 $k \\in \\{1,2,3\\}$，计算经验偏差 $B(\\varepsilon,f_k) = \\left|\\frac{1}{n}\\sum_{j=1}^n f_k(y_j) - \\frac{1}{n}\\sum_{i=1}^n f_k\\big(T_\\varepsilon(x_i)\\big)\\right|$。使用你推导的一维 $\\varepsilon$-缩放关系，构建一个仅基于 $\\varepsilon$ 和 $L_k$ 的显式可计算上界 $U(\\varepsilon,f_k)$（不含不可观测的常数），并测试不等式 $B(\\varepsilon,f_k) \\leq U(\\varepsilon,f_k) + \\delta$ 是否成立。这里固定数值容差 $\\delta = 0.05$ 以考虑采样误差和有限次迭代的数值计算误差。\n- 测试套件包含由 $\\{\\varepsilon \\in \\{1.0, 0.5, 0.2\\}\\}$ 和 $\\{f_1,f_2,f_3\\}$ 的笛卡尔积构成的 9 个案例。对于每个案例，程序必须输出一个布尔值，指示经验不等式是否被满足。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个逗号分隔的 9 个布尔值列表，按 $\\varepsilon = 1.0, 0.5, 0.2$ 和 $f_1, f_2, f_3$ 的嵌套顺序排列，并用方括号括起来（例如， $[{\\tt True},{\\tt False},\\dots]$）。不涉及物理单位，也没有出现角度，因此不需要单位转换。",
            "solution": "该问题是有效的。这是一个适定且有科学依据的计算统计学练习，将贝叶斯推断与计算最优输运联系起来。所有定义都是标准的，数值实验所需的所有参数均已提供。\n\n### 1. 离散 Sinkhorn 方法的合理性论证\n\n任务是从先验分布 $\\mu = \\mathcal{N}(0,\\tau^2)$ 出发，使用一个最优输运映射来近似贝叶斯后验分布 $\\nu = \\mathcal{N}(m,s^2)$。经典的（Kantorovich）最优输运问题旨在寻找 $\\mu$ 和 $\\nu$ 之间的一个耦合 $\\pi$，以最小化总输运成本，即 $\\inf_{\\pi \\in \\Pi(\\mu,\\nu)} \\int c(x,y) \\, d\\pi(x,y)$。对于二次成本 $c(x,y) = \\frac{1}{2}(x-y)^2$，Brenier 定理指出，最优耦合是确定性的，即 $\\pi = (\\mathrm{Id} \\times T_0)_\\# \\mu$，其中 $T_0: \\mathbb{R} \\to \\mathbb{R}$ 是最优输运映射。\n\n该问题的熵正则化引入了一个惩罚项，将目标修改为寻找一个能最小化 $\\int c(x,y) \\, d\\pi(x,y) + \\varepsilon \\, \\mathrm{KL}(\\pi \\,\\|\\, \\mu \\otimes \\nu)$ 的耦合 $\\pi_\\varepsilon$，其中 $\\varepsilon > 0$ 是正则化强度。这个正则化问题是严格凸的，并且总存在唯一解 $\\pi_\\varepsilon$，该解相对于 $\\mu \\otimes \\nu$ 是绝对连续的。最优耦合 $\\pi_\\varepsilon$ 不再是确定性的，而是最优映射 $T_0$ 的一个“模糊”版本。\n\n为了进行数值计算，我们通过从 $\\mu$ 中抽取 $n$ 个独立同分布样本 $\\{x_i\\}_{i=1}^n$ 和从 $\\nu$ 中抽取 $n$ 个独立同分布样本 $\\{y_j\\}_{j=1}^n$ 来离散化测度 $\\mu$ 和 $\\nu$。这得到了经验测度 $\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^n \\delta_{x_i}$ 和 $\\hat{\\nu} = \\frac{1}{n}\\sum_{j=1}^n \\delta_{y_j}$。熵正则化最优输运问题的离散版本是找到一个输运方案（一个矩阵）$\\pi_\\varepsilon \\in \\mathbb{R}^{n \\times n}$，它最小化：\n$$\n\\sum_{i,j=1}^n \\pi_{ij} C_{ij} + \\varepsilon \\sum_{i,j=1}^n \\pi_{ij} \\log(n^2 \\pi_{ij})\n$$\n同时满足边缘约束 $\\sum_{j=1}^n \\pi_{ij} = \\frac{1}{n}$ 对所有 $i$ 成立，以及 $\\sum_{i=1}^n \\pi_{ij} = \\frac{1}{n}$ 对所有 $j$ 成立。成本矩阵为 $C_{ij} = \\frac{1}{2}(x_i - y_j)^2$。\n\n这个最小化问题的解具有一个特定的结构：$\\pi_{ij} = u_i K_{ij} v_j$，其中 $K_{ij} = \\exp(-C_{ij}/\\varepsilon)$ 是 Gibbs 核，$u, v \\in \\mathbb{R}^n$ 是缩放向量。Sinkhorn 算法是寻找这些向量的迭代过程。给定目标均匀边缘分布 $a=b=\\frac{1}{n}\\mathbf{1}$，该算法交替缩放 $K$ 的行和列：\n$$\nu \\leftarrow \\frac{a}{K v} \\quad \\text{和} \\quad v \\leftarrow \\frac{b}{K^T u}\n$$\n（其中除法是逐元素的）直到收敛。一旦找到最优耦合 $\\pi_\\varepsilon$，重心映射 $T_\\varepsilon$ 就被定义为在给定源变量 $X$ 的条件下，目标变量 $Y$ 的条件期望。对于离散样本，这表示为：\n$$\nT_\\varepsilon(x_i) = \\mathbb{E}_{\\pi_\\varepsilon}[Y | X=x_i] = \\sum_{j=1}^n y_j P(Y=y_j | X=x_i) = \\sum_{j=1}^n y_j \\frac{\\pi_{ij}}{\\sum_{k=1}^n \\pi_{ik}} = \\sum_{j=1}^n y_j \\frac{\\pi_{ij}}{1/n} = n \\sum_{j=1}^n y_j \\pi_{ij}\n$$\n然后，前推测度 $T_\\varepsilon \\# \\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^n \\delta_{T_\\varepsilon(x_i)}$ 被用作后验分布 $\\hat{\\nu}$ 的基于输运的近似。\n\n### 2. 偏差界的推导\n\n我们的目标是为一个 Lipschitz 常数为 $L$ 的函数 $f$ 的偏差 $|\\mathbb{E}_{\\nu}[f(\\theta)] - \\mathbb{E}_{T_\\varepsilon \\# \\mu}[f(\\theta)]|$ 找到一个界。问题提供了出发点：\n$$\n|\\mathbb{E}_{\\nu}[f] - \\mathbb{E}_{T_\\varepsilon \\# \\mu}[f]| = \\left| \\iint (f(y) - f(T_\\varepsilon(x))) d\\pi_\\varepsilon(x,y) \\right| \\leq L \\iint |y - T_\\varepsilon(x)| d\\pi_\\varepsilon(x,y) = L \\, \\mathbb{E}_{\\pi_\\varepsilon}[|Y - T_\\varepsilon(X)|]\n$$\n通过对凹函数 $\\phi(z)=\\sqrt{z}$ 应用 Jensen 不等式，我们得到 $(\\mathbb{E}[Z])^2 \\leq \\mathbb{E}[Z^2]$。因此：\n$$\n\\mathbb{E}_{\\pi_\\varepsilon}[|Y - T_\\varepsilon(X)|] \\leq \\sqrt{\\mathbb{E}_{\\pi_\\varepsilon}[|Y - T_\\varepsilon(X)|^2]}\n$$\n根据定义，$T_\\varepsilon(X) = \\mathbb{E}_{\\pi_\\varepsilon}[Y|X]$。因此，平方根内的项是在 $X$ 上平均的、$Y$ 以 $X$ 为条件的方差：\n$$\n\\mathbb{E}_{\\pi_\\varepsilon}[|Y - T_\\varepsilon(X)|^2] = \\mathbb{E}_{X \\sim \\mu}[\\mathrm{Var}_{\\pi_\\varepsilon(Y|X)}(Y)]\n$$\n为了界定这个方差，我们分析条件分布 $\\pi_\\varepsilon(y|x)$ 的结构。它相对于 Lebesgue 测度的密度与 $e^{(-c(x,y) + \\phi(x) + \\psi(y))/\\varepsilon}$ 成正比，其中 $\\phi, \\psi$ 是对偶 OT 位势。一个更直接的论证依赖于这样一个事实：条件测度 $d\\pi_\\varepsilon(y|x) \\propto e^{-c(x,y)/\\varepsilon} e^{\\psi(y)/\\varepsilon} d\\nu(y)$。其密度的负对数为 $V_x(y) = \\frac{c(x,y)}{\\varepsilon} - \\frac{\\psi(y)}{\\varepsilon} - \\log p_\\nu(y)$，其中 $p_\\nu(y)$ 是 $\\nu=\\mathcal{N}(m,s^2)$ 的密度。$\\nu$ 的负对数密度是 $\\frac{1}{2s^2}(y-m)^2$（忽略常数项）。所以，\n$$\nV_x(y) = \\frac{1}{2\\varepsilon}(y-x)^2 - \\frac{\\psi(y)}{\\varepsilon} + \\frac{1}{2s^2}(y-m)^2 + \\text{const}\n$$\nOT 理论中的一个关键性质是，对于二次成本和对数凹测度（高斯分布即是如此），对偶位势 $\\psi(y)$ 是一个凹函数。因此，其二阶导数 $\\psi''(y) \\leq 0$。$V_x(y)$ 关于 $y$ 的二阶导数是：\n$$\nV_x''(y) = \\frac{1}{\\varepsilon} - \\frac{\\psi''(y)}{\\varepsilon} + \\frac{1}{s^2} \\geq \\frac{1}{\\varepsilon} + \\frac{1}{s^2}\n$$\n这表明条件分布 $\\pi_\\varepsilon(y|x)$ 是强对数凹的，其参数 $\\lambda \\geq \\frac{1}{\\varepsilon} + \\frac{1}{s^2}$。Brascamp-Lieb 不等式指出，参数为 $\\lambda$ 的强对数凹分布的方差上界为 $1/\\lambda$。因此，\n$$\n\\mathrm{Var}_{\\pi_\\varepsilon(Y|X=x)}(Y) \\leq \\left(\\frac{1}{\\varepsilon} + \\frac{1}{s^2}\\right)^{-1} = \\frac{\\varepsilon s^2}{\\varepsilon + s^2}\n$$\n这个界对 $x$ 是一致的。对 $X \\sim \\mu$ 取期望得到：\n$$\n\\mathbb{E}_{X \\sim \\mu}[\\mathrm{Var}_{\\pi_\\varepsilon(Y|X)}(Y)] \\leq \\frac{\\varepsilon s^2}{\\varepsilon + s^2}\n$$\n将此结果代回到我们的不等式链中，我们得到偏差的最终界：\n$$\n|\\mathbb{E}_{\\nu}[f] - \\mathbb{E}_{T_\\varepsilon \\# \\mu}[f]| \\leq L \\sqrt{\\frac{\\varepsilon s^2}{\\varepsilon + s^2}}\n$$\n\n### 3. 具体化与数值测试\n\n对于一维数值实验，后验方差为 $s^2 = (1/\\tau^2 + 1/\\sigma^2)^{-1}$，后验均值为 $m = s^2(y_{\\mathrm{obs}}/\\sigma^2)$。上面推导出的界可以直接应用。对于 Lipschitz 常数为 $L_k$ 的函数 $f_k$，可计算的上界为：\n$$\nU(\\varepsilon, f_k) = L_k \\sqrt{\\frac{\\varepsilon s^2}{\\varepsilon + s^2}}\n$$\n数值测试包括计算经验偏差 $B(\\varepsilon, f_k) = |\\frac{1}{n}\\sum_j f_k(y_j) - \\frac{1}{n}\\sum_i f_k(T_\\varepsilon(x_i))|$，并检查不等式 $B(\\varepsilon, f_k) \\leq U(\\varepsilon, f_k) + \\delta$ 是否成立，其中 $\\delta = 0.05$ 是一个容差，用于考虑采样带来的统计波动和有限次迭代的 Sinkhorn 算法产生的数值误差。\n\n对于 $f_1(\\theta) = \\theta$ 的特殊情况，理论偏差精确为零，如下所示：\n$$\n\\mathbb{E}_{T_\\varepsilon \\# \\mu}[\\theta] = \\int T_\\varepsilon(x)d\\mu(x) = \\iint y \\, d\\pi_\\varepsilon(y|x)d\\mu(x) = \\iint y \\, d\\pi_\\varepsilon(x,y) = \\int y \\, d\\nu(y) = \\mathbb{E}_\\nu[\\theta]\n$$\n因此，$\\mathbb{E}_{\\nu}[f_1] - \\mathbb{E}_{T_\\varepsilon \\# \\mu}[f_1] = 0$。经验偏差 $B(\\varepsilon,f_1)$ 应该接近于零，仅受数值精度的限制。界 $U(\\varepsilon, f_1)$ 是非零的，因此预期不等式会成立。\n\n以下是实现数值实验的 Python 代码：\n```python\nimport numpy as np\n\ndef solve():\n    # Problem Parameters\n    tau = 1.0\n    sigma = 0.3\n    y_obs = 0.7\n    n = 128\n    delta = 0.05\n    \n    # Random number generator for reproducibility\n    rng = np.random.default_rng(42)\n\n    # Posterior distribution parameters\n    tau_sq_inv = 1.0 / (tau**2)\n    sigma_sq_inv = 1.0 / (sigma**2)\n    s_sq = 1.0 / (tau_sq_inv + sigma_sq_inv)\n    m = s_sq * (y_obs / sigma**2)\n    s = np.sqrt(s_sq)\n\n    # Generate samples from prior and posterior\n    samples_x = rng.normal(loc=0.0, scale=tau, size=n).reshape(-1, 1)\n    samples_y = rng.normal(loc=m, scale=s, size=n).reshape(-1, 1)\n\n    # Define test functions and their Lipschitz constants\n    f1 = lambda theta: theta\n    f2 = lambda theta: np.abs(theta)\n    f3 = lambda theta: np.sin(2 * theta)\n    functions = [(f1, 1.0), (f2, 1.0), (f3, 2.0)]\n\n    # Epsilon values for regularization\n    epsilons = [1.0, 0.5, 0.2]\n    \n    # Store results\n    results = []\n    \n    def compute_sinkhorn_coupling(x, y, epsilon, num_iter=1000, tol=1e-9):\n        n_samples = x.shape[0]\n        C = 0.5 * (x - y.T)**2\n        K = np.exp(-C / epsilon)\n        a = np.ones(n_samples) / n_samples\n        b = np.ones(n_samples) / n_samples\n        v = np.ones(n_samples)\n        for _ in range(num_iter):\n            u = a / (K @ v + tol)\n            v = b / (K.T @ u + tol)\n        pi_eps = np.diag(u) @ K @ np.diag(v)\n        return pi_eps\n\n    # Main loop for experiments\n    for epsilon in epsilons:\n        pi_epsilon = compute_sinkhorn_coupling(samples_x, samples_y, epsilon)\n        T_eps_x = n * (pi_epsilon @ samples_y)\n        \n        for f, L in functions:\n            bias_empirical = np.abs(np.mean(f(samples_y)) - np.mean(f(T_eps_x)))\n            bound_theoretical = L * np.sqrt((epsilon * s_sq) / (epsilon + s_sq))\n            is_satisfied = bias_empirical = bound_theoretical + delta\n            results.append(bool(is_satisfied))\n            \n    # Print results in the specified format\n    # print(f\"[{','.join(map(str, results))}]\") # This would print the result string\n```",
            "answer": "[True,True,True,True,True,True,True,True,True]"
        }
    ]
}