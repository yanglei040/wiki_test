{
    "hands_on_practices": [
        {
            "introduction": "在高维逆问题中，我们遇到的先验协方差矩阵可能是奇异的（即半正定但非满秩），而非严格正定。这种情况挑战了我们对高斯分布的常规理解。这个练习  旨在探讨奇异协方差的深远影响：在这种情况下，“高斯先验”究竟意味着什么，以及我们何时仍然可以获得一个性质良好的后验分布。这对于理解高斯模型的几何与测度论基础至关重要。",
            "id": "3385468",
            "problem": "考虑一个有限维逆问题，其中未知状态向量 $x \\in \\mathbb{R}^{n}$ 被赋予一个高斯先验，其均值为 $m \\in \\mathbb{R}^{n}$，协方差矩阵为 $C \\in \\mathbb{R}^{n \\times n}$。假设 $C$ 是对称、半正定，且秩为 $r  n$。观测值 $y \\in \\mathbb{R}^{p}$ 是通过一个线性正向算子 $H \\in \\mathbb{R}^{p \\times n}$ 和加性噪声 $\\varepsilon \\in \\mathbb{R}^{p}$ 得到的，其中 $\\varepsilon$ 是均值为 $0$、协方差为对称正定矩阵 $R \\in \\mathbb{R}^{p \\times p}$ 的高斯分布。\n\n从高斯分布作为标准正态分布的线性映像这一基本表示出发，分析 $C$ 是半正定但非满秩的这一事实，对先验作为 $\\mathbb{R}^{n}$ 上的概率测度的存在性与性质，以及在线性高斯似然条件下正常后验密度存在性的影响。您的分析应采用以下基础：\n- 多元高斯分布可以表示为 $x = m + A z$ 的定义，其中 $z \\in \\mathbb{R}^{n}$ 的分量是独立的标准正态分布，且 $A \\in \\mathbb{R}^{n \\times n}$ 满足 $C = A A^{\\top}$。\n- 关于先验或后验相对于 $\\mathbb{R}^{n}$ 上的勒贝格测度的正常性（properness）的解释，通过绝对连续性和 Radon–Nikodym 导数的存在性来定义。\n- 后验分布的刻画，即最小化一个由先验和似然构造的二次目标函数，以及唯一性和正常性对严格凸性的要求。\n\n下列哪个陈述是正确的？\n\nA. 如果 $C$ 是半正定但奇异的，则先验是一个退化高斯概率测度，其支撑集在仿射子空间 $m + \\operatorname{range}(C)$ 上，并且不承认相对于 $\\mathbb{R}^{n}$ 上勒贝格测度的密度。对于线性高斯似然 $y = H x + \\varepsilon$ 且 $R \\succ 0$，后验分布承认一个勒贝格密度（是正常的）当且仅当 $\\ker(C) \\cap \\ker(H) = \\{0\\}$，等价地，当且仅当对称矩阵 $C^{\\dagger} + H^{\\top} R^{-1} H$ 是正定的，其中 $C^{\\dagger}$ 是 $C$ 的 Moore–Penrose 伪逆。\n\nB. 如果 $C$ 是奇异的，则高斯先验不是一个概率测度（其总质量不为 $1$），必须通过将 $C$ 替换为 $C + \\epsilon I$（对于某个 $\\epsilon > 0$）来进行正则化，才能变得正常。\n\nC. 因为 $R \\succ 0$，所以无论 $H$ 和 $C$ 如何，后验分布总是正常的；$R$ 的正定性保证了 $H^{\\top} R^{-1} H$ 在 $\\mathbb{R}^{n}$ 上是正定的。\n\nD. 奇异的 $C$ 意味着在 $\\ker(C)$ 的方向上具有无限方差，因此先验是重尾的，但仍然在 $\\mathbb{R}^{n}$ 上有勒贝格密度。\n\nE. 仅当 $H$ 是列满秩时，后验均值才存在且唯一；后验协方差是否正常不依赖于 $C$。",
            "solution": "用户要求对一个涉及奇异先验协方差矩阵的贝叶斯逆问题进行详细分析。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n-   状态向量：$x \\in \\mathbb{R}^{n}$。\n-   $x$ 的先验分布：高斯分布，均值为 $m \\in \\mathbb{R}^{n}$，协方差为 $C \\in \\mathbb{R}^{n \\times n}$。\n-   $C$ 的性质：对称、半正定，$\\operatorname{rank}(C) = r  n$（即 $C$ 是奇异的）。\n-   观测向量：$y \\in \\mathbb{R}^{p}$。\n-   观测模型：$y = H x + \\varepsilon$，具有线性正向算子 $H \\in \\mathbb{R}^{p \\times n}$。\n-   $\\varepsilon$ 的噪声分布：高斯分布，均值为 $0$，协方差为 $R \\in \\mathbb{R}^{p \\times p}$。\n-   $R$ 的性质：对称正定（$R \\succ 0$）。\n-   指定的分析框架：\n    1.  表示法 $x = m + A z$，其中 $z \\sim \\mathcal{N}(0, I)$ 且 $C = A A^{\\top}$。\n    2.  正常性（Properness）定义为相对于 $\\mathbb{R}^{n}$ 上的勒贝格测度的绝对连续性（存在 Radon-Nikodym 导数）。\n    3.  通过最小化二次目标函数来刻画后验分布，将正常性与严格凸性联系起来。\n\n**步骤2：使用提取的已知条件进行验证**\n-   **科学依据：** 该问题是贝叶斯统计、逆问题和数据同化中的一个标准但高级的主题。所有概念（高斯分布、奇异协方差、Moore-Penrose 伪逆、正常性）都定义明确且在数学上是合理的。\n-   **适定性：** 问题要求分析奇异先验的后果，并评估给定的陈述。这是一个清晰且可解决的任务。\n-   **客观性：** 语言是技术性的且无歧义。\n-   **完整性与一致性：** 问题提供了所有必要的信息。使用二次目标最小化框架的指令为分析提供了明确的路径，解决了定义后验分布时可能出现的歧义。问题内部一致，不包含矛盾的约束。\n\n**步骤3：结论与行动**\n该问题是有效的。分析将从给定的原则出发推导解决方案。\n\n### 推导\n\n分析分两部分进行：首先刻画先验分布，然后刻画后验分布。\n\n**1. 先验分布分析**\n\n对于任何对称半正定协方差矩阵 $C$，高斯分布 $\\mathcal{N}(m, C)$ 都是有定义的。其对应的特征函数是 $\\phi_x(t) = \\exp(i t^\\top m - \\frac{1}{2} t^\\top C t)$，这总是定义了一个有效的概率测度。\n\n协方差矩阵 $C$ 是奇异的，且 $\\operatorname{rank}(C) = r  n$。设 $C$ 的特征分解为 $C = U \\Lambda U^\\top$，其中 $U$ 是一个由特征向量构成的正交矩阵，$\\Lambda = \\operatorname{diag}(\\lambda_1, \\dots, \\lambda_r, 0, \\dots, 0)$ 是特征值的对角矩阵，其中对于 $i=1, \\dots, r$，$\\lambda_i > 0$。\n\n一个随机向量 $x \\sim \\mathcal{N}(m, C)$ 可以通过 $x = m + U \\Lambda^{1/2} z$ 生成，其中 $z \\sim \\mathcal{N}(0, I_n)$。\n向量 $x-m = U \\Lambda^{1/2} z$ 是标准正态向量 $z$ 的一个线性变换。$x-m$ 分布的支撑集是这个线性映射的值域，即 $\\operatorname{range}(U \\Lambda^{1/2})$。这个空间由 $U$ 的前 $r$ 列张成，这些列是对应于 $C$ 的正特征值的特征向量。这个子空间恰好是协方差矩阵本身的值域，即 $\\operatorname{range}(C)$。\n\n因此，随机向量 $x$ 被约束在仿射子空间 $m + \\operatorname{range}(C)$ 上。这是 $\\mathbb{R}^n$ 的一个 r 维子空间。由于 $r  n$，这个子空间在 $\\mathbb{R}^n$ 中的勒贝格测度为零。一个集中在测度为零的集合上的概率测度，不可能相对于更大空间上的勒贝格测度是绝对连续的。因此，它在 $\\mathbb{R}^n$ 上不承认概率密度函数（Radon-Nikodym 导数）。这种分布被称为退化高斯分布。它是一个有效的概率测度，但不是问题所定义意义上的“正常”分布。\n\n**2. 后验分布分析**\n\n后验分布结合了来自先验和似然的信息。给定 $x$ 时观测值 $y$ 的似然是从噪声模型 $\\varepsilon = y - Hx \\sim \\mathcal{N}(0, R)$ 推导出来的。由于 $R \\succ 0$，似然在 $\\mathbb{R}^p$ 上有一个密度，其正比于 $\\exp(-\\frac{1}{2} (y-Hx)^\\top R^{-1} (y-Hx))$。\n\n问题指导我们通过最小化一个二次目标函数 $J(x)$ 来刻画后验分布。对于高斯分布，后验密度的负对数与 $J(x)$ 成正比。$J(x)$ 的标准形式是：\n$$J(x) = \\frac{1}{2} (y-Hx)^\\top R^{-1} (y-Hx) + \\frac{1}{2} (x-m)^\\top C^{-1} (x-m)$$\n这个公式假定 $C$ 是可逆的。对于奇异的 $C$，先验项必须被推广。标准的推广是用 Moore-Penrose 伪逆 $C^\\dagger$ 替换 $C^{-1}$，得到：\n$$J(x) = \\frac{1}{2} (y-Hx)^\\top R^{-1} (y-Hx) + \\frac{1}{2} (x-m)^\\top C^\\dagger (x-m)$$\n该目标函数需要在 $x \\in \\mathbb{R}^n$ 上最小化。后验分布则被形式化地视为一个高斯分布，其密度正比于 $\\exp(-J(x))$。当且仅当 $J(x)$ 是一个严格凸的二次函数时，后验分布才是 $\\mathbb{R}^n$ 上的一个正常高斯分布，这保证了 $\\exp(-J(x))$ 在 $\\mathbb{R}^n$ 上是可积的。\n\n$J(x)$ 的严格凸性由其 Hessian 矩阵是否正定决定。我们来求 Hessian 矩阵：\n$J(x) = \\frac{1}{2} (x^\\top H^\\top R^{-1} H x - 2y^\\top R^{-1} H x + y^\\top R^{-1}y) + \\frac{1}{2} (x^\\top C^\\dagger x - 2m^\\top C^\\dagger x + m^\\top C^\\dagger m)$\n这是 x 的一个二次型。Hessian 矩阵是二次项的矩阵：\n$$\\nabla^2_x J(x) = C^\\dagger + H^\\top R^{-1} H$$\n这个矩阵是后验精度矩阵。为了使后验分布在 $\\mathbb{R}^n$ 上是正常的，这个矩阵必须是对称正定的。\n\n我们来分析 $C^\\dagger + H^\\top R^{-1} H$ 这一项。\n-   由于 $C$ 是对称半正定的（SPSD），其伪逆 $C^\\dagger$ 也是对称半正定的。$C^\\dagger$ 的零空间与 $C$ 的零空间相同，即 $\\ker(C^\\dagger) = \\ker(C)$。对于一个向量 $v \\in \\mathbb{R}^n$，$v^\\top C^\\dagger v \\ge 0$，等号成立当且仅当 $v \\in \\ker(C)$。\n-   由于 $R$ 是正定的（$R \\succ 0$），其逆 $R^{-1}$ 也是正定的。矩阵 $H^\\top R^{-1} H$ 是对称半正定的。对于一个向量 $v \\in \\mathbb{R}^n$，$v^\\top (H^\\top R^{-1} H) v = (Hv)^\\top R^{-1} (Hv) \\ge 0$。等号成立当且仅当 $Hv=0$，这意味着 $v \\in \\ker(H)$。所以，$\\ker(H^\\top R^{-1} H) = \\ker(H)$。\n-   两个对称半正定矩阵之和 $A+B$ 是正定的，当且仅当不存在非零向量 v 同时满足 $v^\\top A v = 0$ 和 $v^\\top B v = 0$。这等价于 $\\ker(A) \\cap \\ker(B) = \\{0\\}$。\n\n将此应用于后验精度矩阵，$C^\\dagger + H^\\top R^{-1} H$ 是正定的，当且仅当 $\\ker(C^\\dagger) \\cap \\ker(H^\\top R^{-1} H) = \\{0\\}$。\n这可以简化为：\n$$\\ker(C) \\cap \\ker(H) = \\{0\\}$$\n这个条件意味着，任何先验不提供信息的方向（即 C 的零空间中的向量），都必须是一个能被观测“看到”的方向（即不在 H 的零空间中）。\n\n### 选项评估\n\n**A. 如果 $C$ 是半正定但奇异的，则先验是一个退化高斯概率测度，其支撑集在仿射子空间 $m + \\operatorname{range}(C)$ 上，并且不承认相对于 $\\mathbb{R}^{n}$ 上勒贝格测度的密度。对于线性高斯似然 $y = H x + \\varepsilon$ 且 $R \\succ 0$，后验分布承认一个勒贝格密度（是正常的）当且仅当 $\\ker(C) \\cap \\ker(H) = \\{0\\}$，等价地，当且仅当对称矩阵 $C^{\\dagger} + H^{\\top} R^{-1} H$ 是正定的，其中 $C^{\\dagger}$ 是 $C$ 的 Moore–Penrose 伪逆。**\n-   陈述的第一部分，关于先验的性质，如我们的分析所示，是严格正确的。\n-   第二部分，关于后验，在问题规定的分析框架下（最小化广义二次目标）也是正确的。后验精度矩阵 $C^\\dagger + H^\\top R^{-1} H$ 为正定的条件恰好是 $\\ker(C) \\cap \\ker(H) = \\{0\\}$。该矩阵的正定性确保了得到的后验高斯分布是非退化的，并且在 $\\mathbb{R}^n$ 上有正常的密度。\n-   **结论：正确。**\n\n**B. 如果 $C$ 是奇异的，则高斯先验不是一个概率测度（其总质量不为 $1$），必须通过将 $C$ 替换为 $C + \\epsilon I$（对于某个 $\\epsilon > 0$）来进行正则化，才能变得正常。**\n-   这是不正确的。具有奇异协方差矩阵的高斯分布是一个总质量为1的有效概率测度。它只是一个退化测度。正则化是用于其他目的的技术，而不是为了使一个有效的测度成为一个测度。\n-   **结论：不正确。**\n\n**C. 因为 $R \\succ 0$，所以无论 $H$ 和 $C$ 如何，后验分布总是正常的；$R$ 的正定性保证了 $H^{\\top} R^{-1} H$ 在 $\\mathbb{R}^{n}$ 上是正定的。**\n-   这是不正确的。虽然 $R \\succ 0$，但矩阵 $H^\\top R^{-1} H$ 通常只是半正定的。其零空间是 $\\ker(H)$，除非 H 是列满秩的，否则该零空间非平凡。因此，后验的正常性无法保证，并且依赖于 $\\ker(C)$ 和 $\\ker(H)$ 之间的相互作用。\n-   **结论：不正确。**\n\n**D. 奇异的 $C$ 意味着在 $\\ker(C)$ 的方向上具有无限方差，因此先验是重尾的，但仍然在 $\\mathbb{R}^{n}$ 上有勒贝格密度。**\n-   这在多个方面都是不正确的。奇异的 $C$ 意味着在 $\\ker(C)$ 的方向上方差为*零*。一个向量 $v \\in \\ker(C)$ 对应于特征值 0，因此投影 $v^\\top x$ 的方差为 $v^\\top C v = 0$。这与无限方差相反。高斯分布不是重尾的。如前所述，奇异先验在 $\\mathbb{R}^n$ 上没有勒贝格密度。\n-   **结论：不正确。**\n\n**E. 仅当 $H$ 是列满秩时，后验均值才存在且唯一；后验协方差是否正常不依赖于 $C$。**\n-   这是不正确的。后验均值的唯一性与后验精度矩阵 $C^\\dagger + H^\\top R^{-1} H$ 的正定性相关，这要求 $\\ker(C) \\cap \\ker(H) = \\{0\\}$。即使 H 不是列满秩，这个条件也可以满足（例如，如果 C 是非奇异的，即 $\\ker(C)=\\{0\\}$）。正常性的条件明确地涉及到 $\\ker(C)$，所以它绝对依赖于 C。\n-   **结论：不正确。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在结合先验和似然形成后验分布之后，我们通常需要为未知参数提供一个单一的点估计。这个练习  深入探讨了两种最常见的选择：最大后验 (MAP) 估计和后验均值。它揭示了这两种估计在不同损失函数下的最优性，以及它们在参数重整化下的不同表现，从而阐明了它们的独特作用，并突出了在线性高斯问题中两者恰好相等的特殊情况。",
            "id": "3367437",
            "problem": "考虑一个贝叶斯逆问题，其中未知参数向量 $x \\in \\mathbb{R}^{n}$ 通过已知的带加性噪声的正演映射 $G:\\mathbb{R}^{n} \\to \\mathbb{R}^{m}$ 从数据 $y \\in \\mathbb{R}^{m}$ 中推断出来，由似然 $p(y \\mid x)$ 和先验 $\\pi_{\\mathrm{prior}}(x)$ 表示。后验密度为 $\\pi(x \\mid y) \\propto p(y \\mid x)\\,\\pi_{\\mathrm{prior}}(x)$，除非另有说明，否则假定其为 $\\mathbb{R}^{n}$ 上的一个概率密度。在损失 $L:\\mathbb{R}^{n} \\times \\mathbb{R}^{n} \\to [0,\\infty)$ 下，贝叶斯估计量是任何能够最小化后验期望损失 $\\int_{\\mathbb{R}^{n}} L(x,a)\\,\\pi(x \\mid y)\\,\\mathrm{d}x$ 的可测决策规则 $a(y) \\in \\mathbb{R}^{n}$。最大后验 (MAP) 估计量为 $\\hat{x}_{\\mathrm{MAP}}(y) := \\arg\\max_{x \\in \\mathbb{R}^{n}} \\pi(x \\mid y)$，而后验均值为 $\\mathbb{E}[x \\mid y] := \\int_{\\mathbb{R}^{n}} x\\,\\pi(x \\mid y)\\,\\mathrm{d}x$（当一阶矩存在时）。对于一个光滑、双射的重参数化 $z = g(x)$，其具有光滑逆 $g^{-1}$ 和雅可比矩阵 $Dg^{-1}(z)$，变换后关于 $z$ 的后验密度为 $\\pi_{Z}(z \\mid y) = \\pi_{X}(g^{-1}(z) \\mid y)\\,\\big|\\det Dg^{-1}(z)\\big|$。\n\n选择所有关于 $\\hat{x}_{\\mathrm{MAP}}$ 和 $\\mathbb{E}[x \\mid y]$ 在重参数化下的不变性、它们的存在性以及在不同损失函数下的贝叶斯最优性的正确陈述：\n\nA. 在平方误差损失 $L(x,a) = \\|x - a\\|^2$ 下，贝叶斯估计量是后验均值 $\\mathbb{E}[x \\mid y]$。\n\nB. 在连续参数空间中，在 0-1 损失 $L(x,a) = \\mathbf{1}\\{x \\neq a\\}$ 下，贝叶斯估计量是 $\\hat{x}_{\\mathrm{MAP}}$。\n\nC. 在一般的光滑、双射重参数化 $z = g(x)$ 下，$\\hat{x}_{\\mathrm{MAP}}$ 和 $\\mathbb{E}[x \\mid y]$ 都不是不变的；通常 $g\\big(\\hat{x}_{\\mathrm{MAP}}\\big) \\neq \\hat{z}_{\\mathrm{MAP}}$ 且 $g\\big(\\mathbb{E}[x \\mid y]\\big) \\neq \\mathbb{E}[z \\mid y]$，不变性的特例仅在某些仿射或线性 $g$ 的情况下出现。\n\nD. 在线性高斯逆问题（高斯先验和高斯似然）中，后验是高斯的，并且满足 $\\hat{x}_{\\mathrm{MAP}} = \\mathbb{E}[x \\mid y]$。\n\nE. 如果后验是多峰的，则后验均值未定义。\n\nF. 如果后验密度在 $\\mathbb{R}^{n}$ 上是正常的，那么唯一的 $\\hat{x}_{\\mathrm{MAP}}$ 总是存在。\n\nG. 在有限参数空间中（例如，一个有限的模型集合），在 0-1 损失 $L(x,a) = \\mathbf{1}\\{x \\neq a\\}$ 下，MAP 准则是贝叶斯最优的。",
            "solution": "问题陈述是应用于逆问题的贝叶斯决策理论的一个有效练习。它为后验密度、贝叶斯估计量、最大后验 (MAP) 估计量、后验均值以及概率密度的变量替换公式提供了标准定义。所有术语都是标准的、自洽的，并基于概率论和统计学。该问题要求基于这些定义评估几个陈述，这是一个适定的、客观的任务。没有发现任何缺陷。\n\n接下来分析每个陈述：\n\n**A. 在平方误差损失 $L(x,a) = \\|x - a\\|^2$ 下，贝叶斯估计量是后验均值 $\\mathbb{E}[x \\mid y]$。**\n\n为了找到贝叶斯估计量，我们必须找到最小化后验期望损失的行动 $a \\in \\mathbb{R}^{n}$。后验期望损失 $R(a)$ 由下式给出：\n$$\nR(a) = \\int_{\\mathbb{R}^{n}} L(x,a)\\,\\pi(x \\mid y)\\,\\mathrm{d}x = \\int_{\\mathbb{R}^{n}} \\|x - a\\|^2\\,\\pi(x \\mid y)\\,\\mathrm{d}x\n$$\n我们针对 $a$ 最小化该函数。假设积分及其导数存在，我们可以通过将关于 $a$ 的梯度设为零来找到最小值。\n$$\n\\nabla_a R(a) = \\nabla_a \\int_{\\mathbb{R}^{n}} (x - a)^T (x - a)\\,\\pi(x \\mid y)\\,\\mathrm{d}x\n$$\n在允许交换微分和积分的正则性条件下，我们有：\n$$\n\\nabla_a R(a) = \\int_{\\mathbb{R}^{n}} \\nabla_a \\left( x^T x - 2a^T x + a^T a \\right) \\,\\pi(x \\mid y)\\,\\mathrm{d}x\n$$\n积分内项关于 $a$ 的梯度是 $-2x + 2a$。\n$$\n\\nabla_a R(a) = \\int_{\\mathbb{R}^{n}} (2a - 2x) \\,\\pi(x \\mid y)\\,\\mathrm{d}x = 2a \\int_{\\mathbb{R}^{n}} \\pi(x \\mid y)\\,\\mathrm{d}x - 2 \\int_{\\mathbb{R}^{n}} x \\,\\pi(x \\mid y)\\,\\mathrm{d}x\n$$\n由于 $\\pi(x \\mid y)$ 是一个概率密度，它在 $\\mathbb{R}^{n}$ 上的积分为 1。第二个积分是后验均值 $\\mathbb{E}[x \\mid y]$ 的定义。\n$$\n\\nabla_a R(a) = 2a - 2\\mathbb{E}[x \\mid y]\n$$\n将梯度设为零得到 $2a - 2\\mathbb{E}[x \\mid y] = 0$，这意味着 $a = \\mathbb{E}[x \\mid y]$。$R(a)$ 关于 $a$ 的海森矩阵是 $2I$，其中 $I$ 是单位矩阵。由于这是正定的，该解对应于一个唯一的最小值。\n\n因此，在平方误差损失下，贝叶斯估计量是后验均值。该陈述是**正确的**。\n\n**B. 在连续参数空间中，在 0-1 损失 $L(x,a) = \\mathbf{1}\\{x \\neq a\\}$ 下，贝叶斯估计量是 $\\hat{x}_{\\mathrm{MAP}}$。**\n\n对于一个给定的决策 $a$，后验期望损失为：\n$$\nR(a) = \\int_{\\mathbb{R}^{n}} \\mathbf{1}\\{x \\neq a\\}\\,\\pi(x \\mid y)\\,\\mathrm{d}x = \\int_{\\mathbb{R}^{n}} (1 - \\mathbf{1}\\{x = a\\})\\,\\pi(x \\mid y)\\,\\mathrm{d}x\n$$\n$$\nR(a) = \\int_{\\mathbb{R}^{n}} \\pi(x \\mid y)\\,\\mathrm{d}x - \\int_{\\mathbb{R}^{n}} \\mathbf{1}\\{x = a\\}\\,\\pi(x \\mid y)\\,\\mathrm{d}x\n$$\n第一项是 1。对于一个具有概率密度函数 $\\pi(x \\mid y)$ 的连续随机变量 $x$， $x$ 取任何单个值 $a$ 的概率为零。这对应于在一个勒贝格测度为零的集合上对密度进行积分，结果为零。\n$$\n\\int_{\\mathbb{R}^{n}} \\mathbf{1}\\{x = a\\}\\,\\pi(x \\mid y)\\,\\mathrm{d}x = P(x=a \\mid y) = 0\n$$\n因此，对于 $\\mathbb{R}^{n}$ 中的任何选择 $a$，$R(a) = 1 - 0 = 1$。后验期望损失是恒定的。任何决策 $a$ 都会产生相同的最小（也是最大）损失 1。因此，不存在唯一的最小化器，寻找“那个”贝叶斯估计量的问题是病态的。声称贝叶斯估计量是 MAP 的说法并不严格正确。虽然 MAP 估计量可以被形式化地推导为在“局部”0-1 损失 $L(x,a) = 1 - \\mathbf{1}\\{\\|x-a\\|  \\epsilon\\}$ 下，当 $\\epsilon \\to 0$ 时贝叶斯估计量的极限，但按所写的那样，使用严格的 0-1 损失，该陈述在连续空间中是错误的。\n\n因此，该陈述是**不正确的**。\n\n**C. 在一般的光滑、双射重参数化 $z = g(x)$ 下，$\\hat{x}_{\\mathrm{MAP}}$ 和 $\\mathbb{E}[x \\mid y]$ 都不是不变的；通常 $g\\big(\\hat{x}_{\\mathrm{MAP}}\\big) \\neq \\hat{z}_{\\mathrm{MAP}}$ 且 $g\\big(\\mathbb{E}[x \\mid y]\\big) \\neq \\mathbb{E}[z \\mid y]$，不变性的特例仅在某些仿射或线性 $g$ 的情况下出现。**\n\n我们先来分析 MAP 估计量。在 $x$ 参数化下的 MAP 估计量是 $\\hat{x}_{\\mathrm{MAP}} = \\arg\\max_{x} \\pi_{X}(x \\mid y)$。在 $z$ 参数化下的 MAP 估计量是 $\\hat{z}_{\\mathrm{MAP}} = \\arg\\max_{z} \\pi_{Z}(z \\mid y)$。使用变量替换公式：\n$$\n\\pi_{Z}(z \\mid y) = \\pi_{X}(g^{-1}(z) \\mid y)\\,\\big|\\det Dg^{-1}(z)\\big|\n$$\n最大化器 $\\hat{z}_{\\mathrm{MAP}}$ 使整个表达式最大化。然而，$g(\\hat{x}_{\\mathrm{MAP}})$ 这个点只使第一项 $\\pi_{X}(g^{-1}(z) \\mid y)$ 最大化。除非雅可比行列式项 $|\\det Dg^{-1}(z)|$ 是常数，否则最大值的位置会改变。常数雅可比行列式出现在仿射变换中，即 $z=g(x)=Ax+b$，其中 $Dg^{-1}(z) = A^{-1}$ 是一个常数矩阵。对于任何一般的非线性变换，雅可比矩阵不是常数，因此 $g(\\hat{x}_{\\mathrm{MAP}}) \\neq \\hat{z}_{\\mathrm{MAP}}$。所以 MAP 估计量不是不变的（或等变的）。\n\n接下来，我们分析后验均值。$z$ 的后验均值是 $\\mathbb{E}[z \\mid y] = \\int z\\,\\pi_Z(z \\mid y)\\,\\mathrm{d}z$。我们进行变量替换为 $x$，其中 $z=g(x)$, $\\mathrm{d}z = |\\det Dg(x)|\\,\\mathrm{d}x$。\n$$\n\\mathbb{E}[z \\mid y] = \\int g(x) \\, \\pi_Z(g(x) \\mid y) \\, |\\det Dg(x)| \\, \\mathrm{d}x\n$$\n代入公式 $\\pi_Z(g(x) \\mid y) = \\pi_{X}(x \\mid y)\\,|\\det Dg^{-1}(g(x))|$：\n$$\n\\mathbb{E}[z \\mid y] = \\int g(x) \\, \\pi_{X}(x \\mid y)\\,|\\det Dg^{-1}(g(x))| \\, |\\det Dg(x)| \\, \\mathrm{d}x\n$$\n由于 $Dg^{-1}(g(x)) = (Dg(x))^{-1}$，行列式的乘积为 1。\n$$\n\\mathbb{E}[z \\mid y] = \\int g(x)\\,\\pi_X(x \\mid y)\\,\\mathrm{d}x \\equiv \\mathbb{E}[g(x) \\mid y]\n$$\n问题是 $\\mathbb{E}[g(x) \\mid y]$ 是否等于 $g(\\mathbb{E}[x \\mid y])$。根据琴生不等式，这个等式成立当且仅当 $g$ 是一个仿射函数。对于任何一般的非线性 $g$，$\\mathbb{E}[g(x)] \\neq g(\\mathbb{E}[x])$。\n\n因此，在非线性重参数化下，这两种估计量通常都不会被保持，该性质仅对仿射变换成立。该陈述准确地描述了这种情况。该陈述是**正确的**。\n\n**D. 在线性高斯逆问题（高斯先验和高斯似然）中，后验是高斯的，并且满足 $\\hat{x}_{\\mathrm{MAP}} = \\mathbb{E}[x \\mid y]$。**\n\n一个线性高斯问题具有高斯先验 $\\pi_{\\mathrm{prior}}(x) \\sim \\mathcal{N}(\\mu_{pr}, C_{pr})$ 和一个由带加性高斯噪声 $y = Gx + \\epsilon$（其中 $\\epsilon \\sim \\mathcal{N}(0, C_{e})$）的线性正演模型产生的高斯似然。似然为 $p(y \\mid x) \\sim \\mathcal{N}(Gx, C_e)$。\n后验密度与两个高斯密度的乘积成正比：\n$$\n\\pi(x \\mid y) \\propto p(y \\mid x)\\,\\pi_{\\mathrm{prior}}(x) \\propto \\exp\\left(-\\frac{1}{2}(y-Gx)^T C_e^{-1} (y-Gx)\\right) \\exp\\left(-\\frac{1}{2}(x-\\mu_{pr})^T C_{pr}^{-1} (x-\\mu_{pr})\\right)\n$$\n指数的参数是 $x$ 的两个二次型之和。结果是 $x$ 的另一个二次型。一个负二次型的指数定义了一个高斯密度。因此，后验 $\\pi(x \\mid y)$ 是一个高斯分布。\n任何高斯分布（或任何对称单峰分布）的一个关键性质是其均值、中位数和众数都相同。MAP 估计量 $\\hat{x}_{\\mathrm{MAP}}$ 是后验的众数，而后验均值 $\\mathbb{E}[x \\mid y]$ 是后验的均值。\n由于后验是高斯的，其众数和均值重合。因此，$\\hat{x}_{\\mathrm{MAP}} = \\mathbb{E}[x \\mid y]$。\n\n该陈述是**正确的**。\n\n**E. 如果后验是多峰的，则后验均值未定义。**\n\n这个陈述是错误的。多峰性指的是概率密度函数中存在多个局部最大值。均值（一阶矩）的存在性取决于分布尾部的行为。具体来说，后验均值 $\\mathbb{E}[x \\mid y] = \\int x\\,\\pi(x \\mid y)\\,\\mathrm{d}x$ 有定义，当且仅当 $\\int \\|x\\|\\,\\pi(x \\mid y)\\,\\mathrm{d}x  \\infty$。\n一个简单的反例是两个高斯分布的混合：\n$$\n\\pi(x \\mid y) = w_1 \\mathcal{N}(x; \\mu_1, \\Sigma_1) + w_2 \\mathcal{N}(x; \\mu_2, \\Sigma_2)\n$$\n其中 $w_1+w_2=1$。如果 $\\mu_1$ 和 $\\mu_2$ 分离得足够远，这个分布就是多峰的。它的均值是良定义的，并由各分量均值的加权平均给出：\n$$\n\\mathbb{E}[x \\mid y] = w_1 \\mu_1 + w_2 \\mu_2\n$$\n由于均值是明确定义的，该陈述是不正确的。人们可以有一个均值未定义的单峰分布（例如，柯西分布），也可以有一个均值良定义的多峰分布。\n\n该陈述是**不正确的**。\n\n**F. 如果后验密度在 $\\mathbb{R}^{n}$ 上是正常的，那么唯一的 $\\hat{x}_{\\mathrm{MAP}}$ 总是存在。**\n\n这个陈述提出了两个主张：存在性和唯一性。两者都是错误的。\n*   **存在性**：一个正常的密度（积分为1）不保证其最大值能够达到。考虑一个在 $\\mathbb{R}$ 上的连续密度，它由一系列窄的三角形函数（凸起）构成，中心位于整数 $k=1, 2, ...$，其中第 $k$ 个凸起的高度是 $1-1/k$，面积是 $1/2^k$。总面积是 $\\sum 1/2^k = 1$，所以它是一个正常的密度。该密度的上确界是 1，但对于任何有限的 $x$ 都永远达不到这个值。因此，$\\arg\\max_x \\pi(x \\mid y)$ 不存在。\n*   **唯一性**：一个后验可以是多峰的，具有两个或多个相同高度的全局最大值。例如，对于足够大的 $\\mu_0$，两个高斯分布的对称混合 $\\pi(x \\mid y) = \\frac{1}{2} \\mathcal{N}(x; -\\mu_0, \\Sigma) + \\frac{1}{2} \\mathcal{N}(x; \\mu_0, \\Sigma)$ 将有两个后验密度相等的众数。在这种情况下，MAP 估计量不是一个唯一的点，而是一个包含两个点的集合。另一个反例是在一个紧集上的均匀后验密度，例如 $\\pi(x|y) = \\mathcal{U}[-1, 1]$。区间 $[-1, 1]$ 中的每个点都是最大化器，所以 MAP 不是唯一的。\n\n该陈述是**不正确的**。\n\n**G. 在有限参数空间中（例如，一个有限的模型集合），在 0-1 损失 $L(x,a) = \\mathbf{1}\\{x \\neq a\\}$ 下，MAP 准则是贝叶斯最优的。**\n\n设有限参数空间为 $\\mathcal{X} = \\{x_1, x_2, \\ldots, x_K\\}$。后验是一个概率质量函数 $P(x=x_k \\mid y)$，对于 $k \\in \\{1, \\ldots, K\\}$。我们的决策 $a$ 必须是 $\\mathcal{X}$ 中的元素之一。我们选择 $a=x_j$，对于某个 $j \\in \\{1, \\ldots, K\\}$。\n后验期望损失为：\n$$\nR(a=x_j) = \\sum_{k=1}^{K} L(x_k, x_j) P(x=x_k \\mid y) = \\sum_{k=1}^{K} \\mathbf{1}\\{x_k \\neq x_j\\} P(x=x_k \\mid y)\n$$\n指示函数对于所有 $k \\neq j$ 为 1，对于 $k=j$ 为 0。所以求和变为：\n$$\nR(x_j) = \\sum_{k \\neq j} P(x=x_k \\mid y)\n$$\n由于所有后验概率的总和为 1，我们有 $\\sum_{k \\neq j} P(x=x_k \\mid y) = 1 - P(x=x_j \\mid y)$。\n贝叶斯估计量是最小化此风险的选择 $x_j$：\n$$\n\\hat{a} = \\arg\\min_{x_j \\in \\mathcal{X}} R(x_j) = \\arg\\min_{x_j \\in \\mathcal{X}} \\left( 1 - P(x=x_j \\mid y) \\right)\n$$\n最小化 $1 - P(x=x_j \\mid y)$ 等价于最大化 $P(x=x_j \\mid y)$。根据定义，最大化后验概率的估计量是 MAP 估计量。\n$$\n\\hat{x}_{\\mathrm{MAP}} = \\arg\\max_{x_j \\in \\mathcal{X}} P(x=x_j \\mid y)\n$$\n因此，在有限参数空间中，MAP 估计量确实是 0-1 损失下的贝叶斯最优准则。这解决了在连续情况下（陈述 B）遇到的模糊性。\n\n该陈述是**正确的**。",
            "answer": "$$\\boxed{ACDG}$$"
        },
        {
            "introduction": "贝叶斯建模中的一个关键挑战是选择先验分布。这个练习  介绍了一种强大的、由数据驱动的方法，称为经验贝叶斯。你将学习如何将先验分布中的超参数（在本例中是协方差的缩放因子）视为一个可通过最大化边际似然（也称为“证据”）来优化的参数。这个练习提供了一个常见且实用的建模任务的第一性原理推导和计算。",
            "id": "3385456",
            "problem": "考虑一个数据同化中的线性反问题，其先验为高斯分布，似然也为高斯分布。设未知状态为 $x \\in \\mathbb{R}^{n}$，其先验分布为 $x \\sim \\mathcal{N}(m, \\lambda C)$，其中 $m \\in \\mathbb{R}^{n}$ 为已知， $C \\in \\mathbb{R}^{n \\times n}$ 为已知的对称正定矩阵，$\\lambda \\in \\mathbb{R}_{+}$ 是一个待确定的未知膨胀因子。观测值 $y \\in \\mathbb{R}^{p}$ 通过线性模型 $y = H x + \\varepsilon$ 与 $x$ 相关，其中 $H \\in \\mathbb{R}^{p \\times n}$ 是已知的，$\\varepsilon \\sim \\mathcal{N}(0, R)$，而 $R \\in \\mathbb{R}^{p \\times p}$ 是一个已知的对称正定矩阵。目标是通过最大化边际似然（也称为证据）$p(y \\mid \\lambda)$ 来选择膨胀因子 $\\lambda$。\n\n从多元高斯概率密度函数和贝叶斯定理的定义出发，仅使用从这些定义中推导出的标准矩阵微积分恒等式，从第一性原理推导使 $\\lambda$ 最大化的解析平稳性条件。该条件通过对 $\\ln p(y \\mid \\lambda)$ 关于 $\\lambda$ 求导并令其导数为零得到。然后，将您的结果特化到标量情况 $n=p=1$，参数为 $m = m_{0}$、$C = c_{0}$、$H = h$ 和 $R = r$，并证明最大化的 $\\lambda$ 存在一个用 $y$、$m_{0}$、$c_{0}$、$h$ 和 $r$ 表示的封闭形式表达式。\n\n最后，对具体的标量实例 $m_{0} = 0.3$、$c_{0} = 0.2$、$h = 1.5$、$r = 0.25$ 和观测值 $y = 3.0$ 计算此表达式，并报告所得的 $\\lambda$。\n\n将您的答案四舍五入到四位有效数字。最终答案必须是一个没有单位的实数。",
            "solution": "用户提供的问题经评估有效。它在科学上基于线性反问题的贝叶斯推断标准框架，问题设定良好，目标明确，并且包含了所有必要信息，没有任何矛盾或歧义。\n\n我们首先定义贝叶斯模型的各个组成部分。状态变量为 $x \\in \\mathbb{R}^{n}$。$x$ 的先验分布是高斯分布，由膨胀因子 $\\lambda \\in \\mathbb{R}_{+}$ 参数化：\n$$x \\mid \\lambda \\sim \\mathcal{N}(m, \\lambda C)$$\n其中 $m \\in \\mathbb{R}^{n}$ 是先验均值，$\\lambda C$ 是先验协方差矩阵，而 $C \\in \\mathbb{R}^{n \\times n}$ 是对称正定的。先验的概率密度函数（PDF）为：\n$$p(x \\mid \\lambda) = \\frac{1}{\\sqrt{(2\\pi)^{n} \\det(\\lambda C)}} \\exp\\left(-\\frac{1}{2}(x-m)^T (\\lambda C)^{-1} (x-m)\\right)$$\n\n观测值 $y \\in \\mathbb{R}^{p}$ 通过带有加性高斯噪声的线性模型与状态 $x$ 相关：\n$$y = H x + \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, R)$$\n其中 $H \\in \\mathbb{R}^{p \\times n}$ 是观测算子，$R \\in \\mathbb{R}^{p \\times p}$ 是噪声 $\\varepsilon$ 的对称正定协方差矩阵。这定义了似然函数，即给定状态 $x$ 时数据 $y$ 的条件概率：\n$$p(y \\mid x) = \\mathcal{N}(y \\mid Hx, R) = \\frac{1}{\\sqrt{(2\\pi)^{p} \\det(R)}} \\exp\\left(-\\frac{1}{2}(y-Hx)^T R^{-1} (y-Hx)\\right)$$\n\n目标是找到最大化边际似然（或证据）$p(y \\mid \\lambda)$ 的 $\\lambda$ 值。这可以通过将联合分布 $p(y, x \\mid \\lambda) = p(y \\mid x) p(x \\mid \\lambda)$ 对所有可能的状态 $x$ 进行积分来找到：\n$$p(y \\mid \\lambda) = \\int_{\\mathbb{R}^n} p(y \\mid x) p(x \\mid \\lambda) dx$$\n由于这是一个线性高斯模型， $y$ 的边际分布也是高斯分布。我们可以如下确定其参数：\n$y$ 的均值为：\n$$E[y \\mid \\lambda] = E[Hx + \\varepsilon \\mid \\lambda] = H E[x \\mid \\lambda] + E[\\varepsilon] = Hm + 0 = Hm$$\n$y$ 的协方差（注意到 $x$ 和 $\\varepsilon$ 是独立的）为：\n$$\\text{Cov}(y \\mid \\lambda) = \\text{Cov}(Hx + \\varepsilon) = \\text{Cov}(Hx) + \\text{Cov}(\\varepsilon) = H \\text{Cov}(x) H^T + R = H(\\lambda C)H^T + R = \\lambda HCH^T + R$$\n因此，边际似然是一个多元正态分布的PDF：\n$$y \\mid \\lambda \\sim \\mathcal{N}(Hm, \\lambda HCH^T + R)$$\n我们将 $y$ 的协方差矩阵表示为 $S(\\lambda) = \\lambda HCH^T + R$。其PDF为：\n$$p(y \\mid \\lambda) = \\frac{1}{\\sqrt{(2\\pi)^{p} \\det(S(\\lambda))}} \\exp\\left(-\\frac{1}{2}(y-Hm)^T S(\\lambda)^{-1} (y-Hm)\\right)$$\n\n为了最大化 $p(y \\mid \\lambda)$，更方便的做法是最大化其对数，即对数边际似然，记为 $\\mathcal{L}(\\lambda)$：\n$$\\mathcal{L}(\\lambda) = \\ln p(y \\mid \\lambda) = -\\frac{p}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln \\det(S(\\lambda)) - \\frac{1}{2}(y-Hm)^T S(\\lambda)^{-1} (y-Hm)$$\n我们通过对 $\\mathcal{L}(\\lambda)$ 关于 $\\lambda$ 求导并将结果设为零来找到最优的 $\\lambda$。我们使用以下标准矩阵微积分恒等式：\n1. $\\frac{\\partial}{\\partial \\lambda} \\ln \\det(S(\\lambda)) = \\text{tr}\\left(S(\\lambda)^{-1} \\frac{\\partial S(\\lambda)}{\\partial \\lambda}\\right)$\n2. $\\frac{\\partial}{\\partial \\lambda} S(\\lambda)^{-1} = -S(\\lambda)^{-1} \\frac{\\partial S(\\lambda)}{\\partial \\lambda} S(\\lambda)^{-1}$\n\n首先，我们求 $S(\\lambda)$ 的导数：\n$$\\frac{\\partial S(\\lambda)}{\\partial \\lambda} = \\frac{\\partial}{\\partial \\lambda}(\\lambda HCH^T + R) = HCH^T$$\n现在我们对 $\\mathcal{L}(\\lambda)$ 求导：\n$$\\frac{\\partial \\mathcal{L}(\\lambda)}{\\partial \\lambda} = 0 - \\frac{1}{2} \\frac{\\partial}{\\partial \\lambda}\\ln \\det(S(\\lambda)) - \\frac{1}{2}(y-Hm)^T \\left(\\frac{\\partial}{\\partial \\lambda}S(\\lambda)^{-1}\\right) (y-Hm)$$\n代入恒等式：\n$$\\frac{\\partial \\mathcal{L}(\\lambda)}{\\partial \\lambda} = -\\frac{1}{2} \\text{tr}\\left(S(\\lambda)^{-1} HCH^T\\right) - \\frac{1}{2}(y-Hm)^T \\left(-S(\\lambda)^{-1} (HCH^T) S(\\lambda)^{-1}\\right) (y-Hm)$$\n$$\\frac{\\partial \\mathcal{L}(\\lambda)}{\\partial \\lambda} = -\\frac{1}{2} \\text{tr}\\left(S(\\lambda)^{-1} HCH^T\\right) + \\frac{1}{2}(y-Hm)^T S(\\lambda)^{-1} HCH^T S(\\lambda)^{-1} (y-Hm)$$\n令导数为零，得到平稳性条件：\n$$\\text{tr}\\left(S(\\lambda)^{-1} HCH^T\\right) = (y-Hm)^T S(\\lambda)^{-1} HCH^T S(\\lambda)^{-1} (y-Hm)$$\n将 $S(\\lambda) = \\lambda HCH^T + R$ 代回，我们得到该条件的最终一般形式：\n$$\\text{tr}\\left((\\lambda HCH^T + R)^{-1} HCH^T\\right) = (y-Hm)^T (\\lambda HCH^T + R)^{-1} HCH^T (\\lambda HCH^T + R)^{-1} (y-Hm)$$\n\n接下来，我们将此结果特化到 $n=p=1$ 的标量情况。变量和矩阵变为标量：\n$x \\in \\mathbb{R}$, $y \\in \\mathbb{R}$, $m \\rightarrow m_0 \\in \\mathbb{R}$, $C \\rightarrow c_0 \\in \\mathbb{R}_{++}$, $H \\rightarrow h \\in \\mathbb{R}$, $R \\rightarrow r \\in \\mathbb{R}_{++}$。\n平稳性条件中的各项变为：\n$HCH^T \\rightarrow h c_0 h = h^2 c_0$\n$S(\\lambda) \\rightarrow \\lambda h^2 c_0 + r$\n$y-Hm \\rightarrow y - h m_0$\n标量的迹就是该标量本身。平稳性条件简化为：\n$$(\\lambda h^2 c_0 + r)^{-1} (h^2 c_0) = (y - h m_0) (\\lambda h^2 c_0 + r)^{-1} (h^2 c_0) (\\lambda h^2 c_0 + r)^{-1} (y - h m_0)$$\n$$\\frac{h^2 c_0}{\\lambda h^2 c_0 + r} = \\frac{(y - h m_0)^2 h^2 c_0}{(\\lambda h^2 c_0 + r)^2}$$\n假设 $h \\neq 0$ 和 $c_0 > 0$，我们可以在两边同除以 $h^2 c_0$：\n$$\\frac{1}{\\lambda h^2 c_0 + r} = \\frac{(y - h m_0)^2}{(\\lambda h^2 c_0 + r)^2}$$\n由于 $\\lambda > 0$、$c_0 > 0$、$h^2 \\ge 0$ 和 $r > 0$，分母 $\\lambda h^2 c_0 + r$ 严格为正。我们可以乘以 $(\\lambda h^2 c_0 + r)^2$：\n$$\\lambda h^2 c_0 + r = (y - h m_0)^2$$\n求解 $\\lambda$ 得到封闭形式的表达式：\n$$\\lambda = \\frac{(y - h m_0)^2 - r}{h^2 c_0}$$\n这个关于 $\\lambda \\in \\mathbb{R}_{+}$ 的解是有效的，条件是分子为正，即 $(y - h m_0)^2 > r$。\n\n最后，我们用给定的数值 $m_{0} = 0.3$、$c_{0} = 0.2$、$h = 1.5$、$r = 0.25$ 和 $y = 3.0$ 计算这个表达式。\n首先，计算表达式所需的各项：\n$$h m_0 = 1.5 \\times 0.3 = 0.45$$\n$$y - h m_0 = 3.0 - 0.45 = 2.55$$\n$$(y - h m_0)^2 = (2.55)^2 = 6.5025$$\n$$h^2 c_0 = (1.5)^2 \\times 0.2 = 2.25 \\times 0.2 = 0.45$$\n$\\lambda$ 为正的条件是 $(y - h m_0)^2 > r$，即 $6.5025 > 0.25$。此条件满足。\n现在，将这些值代入 $\\lambda$ 的表达式中：\n$$\\lambda = \\frac{6.5025 - 0.25}{0.45} = \\frac{6.2525}{0.45} \\approx 13.89444...$$\n将结果四舍五入到四位有效数字，得到 $13.89$。",
            "answer": "$$\\boxed{13.89}$$"
        }
    ]
}