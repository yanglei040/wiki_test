{
    "hands_on_practices": [
        {
            "introduction": "本练习旨在探讨“相干性”（coherence）这一随机线性代数中的核心概念，它用于衡量矩阵奇异向量的能量集中程度。通过构建一个具体的例子，您将深入理解为何简单的均匀随机采样在处理高相干性矩阵时可能会失效，以及为何基于重要性采样的杠杆分数（leverage-score）方法能够有效克服这一挑战 。这项实践将帮助您掌握设计和评判随机算法时的一个关键原则。",
            "id": "3416430",
            "problem": "考虑一个线性化观测算子 $A \\in \\mathbb{R}^{m \\times n}$，它产生于一个高维逆问题的变分数据同化过程，其目标是通过对列和行进行随机采样来构造 $A$ 的一个低秩 $C U R$ 近似。$C U R$ 近似从 $A$ 中选取一个列子集 $C$ 和行子集 $R$，以及一个连接矩阵 $U$，以便在谱范数下近似 $A$。随机采样的质量由占主导地位的奇异子空间的相干性决定。设 $A$ 的奇异值分解（SVD）为 $A = U \\Sigma V^{\\top}$，秩为 $k$ 的占主导地位的右奇异子空间为 $V_k \\in \\mathbb{R}^{n \\times k}$。列杠杆分数定义为 $\\ell_j = \\lVert e_j^{\\top} V_k \\rVert_2^2$ for $j \\in \\{1,\\dots,n\\}$，右奇异子空间的相干性为 $\\mu(V_k) = \\frac{n}{k} \\max_j \\ell_j$。高相干性（即 $\\mu(V_k) \\gg 1$）表示占主导地位的右奇异子空间的能量高度集中在少数几个坐标上，已知这会降低均匀随机采样的性能。相比之下，杠杆分数采样以与 $\\ell_j$ 成正比的概率选择列 $j$，并以与 $\\lVert e_i^{\\top} U_k \\rVert_2^2$ 成正比的概率选择行 $i$，其中 $U_k \\in \\mathbb{R}^{m \\times k}$ 是秩为 $k$ 的占主导地位的左奇异子空间。\n\n您将评估一个高相干性矩阵 $A$ 的构造方案和解释，在该情况下，均匀采样对于 $C U R$ 近似会失败，并解释杠杆分数采样如何缓解这种失败。假设 $m = n$ 很大，我们寻求一个秩 $k=1$ 的近似，并且采样是无放回的：均匀随机地抽取 $s_c$ 个不同的列和 $s_r$ 个不同的行。\n\n哪个选项正确地构造了这样一个矩阵，并解释了均匀采样的失败和通过杠杆分数采样的缓解方法？\n\nA. 设 $m=n$，并定义 $A = \\sigma \\, e_1 e_1^{\\top} + \\varepsilon Z$，其中 $\\sigma > 0$，$\\varepsilon > 0$ 满足 $\\varepsilon \\ll \\sigma$，且 $Z \\in \\mathbb{R}^{n \\times n}$ 的元素 $Z_{ij}$ 是独立的，均值为零，方差为单位一。那么顶层奇异方向在左右子空间中都集中在 $e_1$ 上，因此秩为1的列杠杆分数满足 $\\ell_1 \\approx 1$ 和 $\\ell_j \\approx 0$（对于 $j > 1$），从而得到 $\\mu(V_1) \\approx n$。在无放回的均匀采样下，错过信息丰富的列1的概率是 $\\frac{n - s_c}{n}$，错过信息丰富的行1的概率是 $\\frac{n - s_r}{n}$；因此，两次失败中至少发生一次的概率为 $1 - \\frac{s_c}{n} \\cdot \\frac{s_r}{n}$。因此，当 $s_c, s_r \\ll n$ 时，$C U R$ 近似通常只捕捉到噪声而失败，产生一个 $O(\\sigma)$ 的谱范数误差。杠杆分数采样为选择列1和行1分配了近似为1的概率，从而以高概率捕捉到秩为1的结构；$C U R$ 于是可以恢复 $\\sigma \\, e_1 e_1^{\\top}$ 直到 $O(\\varepsilon)$ 的误差，从而缓解了失败。\n\nB. 设 $m=n$，并定义 $A = \\sigma \\, u v^{\\top}$，其中 $u, v \\in \\mathbb{R}^{n}$ 的分量对于所有 $i$ 均为 $u_i = v_i = \\frac{1}{\\sqrt{n}}$。那么秩为1的右奇异向量的所有分量都等于 $\\frac{1}{\\sqrt{n}}$，所以列杠杆分数是均匀的，为 $\\ell_j = \\frac{1}{n}$，相干性为 $\\mu(V_1) = 1$。对 $s_c$ 个列和 $s_r$ 个行的均匀采样会以高概率失败，因为质量均匀分布在所有坐标上，而杠杆分数采样没有帮助，因为杠杆分数是恒定的。\n\nC. 设 $m=n$，并定义 $A = \\sigma \\, e_1 w^{\\top}$，其中 $w \\in \\mathbb{R}^{n}$ 满足 $w_1 = 1$ 且对于 $j>1$ 有 $w_j = 0$，外加一个如上所述的小扰动 $\\varepsilon Z$。尽管质量集中在列1上，但杠杆分数是恒定的，因为它们只依赖于 $A$ 的 Frobenius 范数，而不依赖于其奇异结构，所以杠杆分数采样无法缓解均匀采样的失败。\n\nD. 设 $m=n$，并定义 $A = \\sigma \\, e_1 e_1^{\\top}$ 如选项A中所示，但没有扰动。即使质量集中在单个坐标上，由于赠券收集者效应，对 $s_c = c \\log n$ 个列和 $s_r = c \\log n$ 个行（对于一个固定的常数 $c>0$）的均匀采样仍以高概率成功，因此杠杆分数采样没有提供渐近优势。\n\n选择唯一的最佳选项。",
            "solution": "首先根据指定协议验证问题陈述。\n\n### 第1步：提取已知条件\n- $A \\in \\mathbb{R}^{m \\times n}$ 是一个线性化观测算子。\n- 目标是构造 $A$ 的一个低秩 $C U R$ 近似。\n- $C U R$ 近似使用 $A$ 的一个列子集 $C$ 和行子集 $R$，以及一个连接矩阵 $U$。\n- $A$ 的奇异值分解是 $A = U \\Sigma V^{\\top}$。\n- 秩为 $k$ 的占主导地位的右奇异子空间是 $V_k \\in \\mathbb{R}^{n \\times k}$。\n- 列杠杆分数定义为 $\\ell_j = \\lVert e_j^{\\top} V_k \\rVert_2^2$，其中 $j \\in \\{1,\\dots,n\\}$。\n- 右奇异子空间的相干性为 $\\mu(V_k) = \\frac{n}{k} \\max_j \\ell_j$。\n- 杠杆分数采样以与 $\\ell_j$ 成正比的概率选择列 $j$，并以与 $\\lVert e_i^{\\top} U_k \\rVert_2^2$ 成正比的概率选择行 $i$，其中 $U_k \\in \\mathbb{R}^{m \\times k}$ 是秩为 $k$ 的占主导地位的左奇异子空间。\n- 用于评估的具体假设：\n    - $m = n$ 很大。\n    - 寻求秩 $k=1$ 的近似。\n    - 采样是无放回的。\n    - 均匀随机地抽取 $s_c$ 个不同的列和 $s_r$ 个不同的行。\n- 问题：评估各个选项，找出哪一个正确地构造了一个高相干性矩阵 $A$，解释了均匀采样对 $C U R$ 近似的失败，并解释了杠杆分数采样的缓解作用。\n\n### 第2步：使用提取的已知条件进行验证\n问题陈述在科学上和数学上是合理的。所提供的奇异值分解（SVD）、杠杆分数和相干性的定义是随机数值线性代数及其应用领域的标准定义。所描述的情景——对于高相干性矩阵，均匀采样的潜在失败以及杠杆分数采样的缓解效果——是该领域的核心概念。问题陈述清晰，目标明确，且自洽，提供了评估选项所需的所有必要信息，这些信息均基于已建立的原则。它没有违反任何无效性标准。\n\n### 第3步：结论与行动\n问题是**有效的**。现在开始解题过程。\n\n### 问题分析\n问题的核心在于理解矩阵相干性的概念及其对随机采样算法的影响。\n\n对于一个秩为 $k$ 的近似，杠杆分数 $\\ell_j = \\lVert e_j^\\top V_k \\rVert_2^2$ 衡量了第 $j$ 个标准基向量 $e_j$ 与由前 $k$ 个右奇异向量张成的空间的对齐程度。由于 $\\sum_{j=1}^n \\ell_j = \\lVert V_k \\rVert_F^2 = k$，平均杠杆分数为 $k/n$。\n相干性 $\\mu(V_k) = \\frac{n}{k} \\max_j \\ell_j$ 衡量了杠杆分数的集中程度。低相干性，$\\mu(V_k) \\approx 1$，意味着所有的 $\\ell_j$ 都接近平均值 $k/n$，奇异向量是“弥散”的。高相干性，$\\mu(V_k) \\gg 1$，意味着至少有一个 $\\ell_j$ 远大于平均值，表明某个奇异向量是“尖峰状的”或集中在少数几个坐标上。\n\n对于这个问题，$k=1$。顶层右奇异向量是 $v_1 \\in \\mathbb{R}^n$，杠杆分数为 $\\ell_j = (v_{1j})^2$，其中 $v_{1j}$ 是 $v_1$ 的第 $j$ 个分量。相干性为 $\\mu(V_1) = n \\max_j (v_{1j})^2$。高相干性意味着 $v_1$ 有少数几个大分量和许多小分量。\n\n- **均匀采样的失败：** 如果矩阵 $A$ 是高相干性的，其占主导地位的奇异结构集中在少数几个列（和/或行）中。为了得到一个好的低秩近似，必须采样到这些特定的列。均匀采样以相等的概率选择列。如果样本数量 $s_c$ 远小于总列数 $n$，那么捕获到这几个关键列的概率很低。这会导致一个近似效果差、误差大的结果。\n\n- **杠杆分数采样的成功：** 杠杆分数采样是一种重要性采样方案。它为具有更高杠杆分数的列分配更高的选择概率。对于高相干性矩阵，这意味着关键列会以高概率被采样到，从而得到一个精确的低秩近似。\n\n### 逐项分析选项\n\n**选项A：**\n设 $A = \\sigma \\, e_1 e_1^{\\top} + \\varepsilon Z$，其中 $m=n$, $\\sigma > 0$ 且 $0  \\varepsilon \\ll \\sigma$。矩阵 $\\sigma \\, e_1 e_1^{\\top}$ 是一个秩为1的矩阵，其奇异值为 $\\sigma$，左奇异向量为 $u_1=e_1$，右奇异向量为 $v_1=e_1$。项 $\\varepsilon Z$ 是一个小的随机扰动。根据矩阵扰动理论，由于 $\\varepsilon Z$ 的谱范数是 $O(\\varepsilon \\sqrt{n})$，并且第一个奇异值（$\\approx \\sigma$）与其他奇异值（$\\approx O(\\varepsilon \\sqrt{n})$）之间存在很大的差距，因此 $A$ 的占主导地位的秩为1的奇异向量将非常接近于 $\\sigma \\, e_1 e_1^{\\top}$ 的奇异向量。因此，$v_1 \\approx e_1$ 且 $u_1 \\approx e_1$。\n\n- **杠杆分数和相干性：** 对于 $k=1$，列杠杆分数为 $\\ell_j = (v_{1j})^2$。由于 $v_1 \\approx e_1$，我们有 $v_{1,1} \\approx 1$ 和 $v_{1,j} \\approx 0$（对于 $j > 1$）。因此，$\\ell_1 \\approx 1$ 和 $\\ell_j \\approx 0$（对于 $j1$）。相干性为 $\\mu(V_1) = n \\max_j \\ell_j \\approx n \\cdot 1 = n$。由于 $n$ 很大，$\\mu(V_1) \\gg 1$，所以这是一个高相干性矩阵。\n- **均匀采样的失败：** $A$ 的主导结构几乎完全在其第一列和第一行中。要成功进行 $C U R$ 近似，必须同时采样到第1列和第1行。使用均匀采样，选择第1列的概率是 $s_c/n$，选择第1行的概率是 $s_r/n$。假设行和列的采样是独立的，成功捕获两者的概率是 $P(\\text{成功}) = \\frac{s_c}{n} \\cdot \\frac{s_r}{n}$。失败（至少错过其中一个）的概率是 $P(\\text{失败}) = 1 - P(\\text{成功}) = 1 - \\frac{s_c s_r}{n^2}$。选项中使用的表述“两次失败中至少发生一次的概率”，其计算结果与此一致。对于 $s_c, s_r \\ll n$，这个概率接近1。如果错过了第一列或第一行，近似就只能恢复噪声项 $\\varepsilon Z$，近似误差将是被错过分量的量级，即 $\\|\\sigma e_1 e_1^\\top\\|_2 = \\sigma$。误差为 $O(\\sigma)$。这个推理是正确的。\n- **杠杆分数的缓解作用：** 列杠杆分数 $\\ell_1$ 近似为1，其他分数接近0。杠杆分数采样将以近乎确定的概率选择第1列。类似地，基于 $u_1 \\approx e_1$ 的行杠杆分数将确保第1行被选中。因此，主导结构 $\\sigma e_1 e_1^\\top$ 被捕获，误差由扰动决定，量级为 $O(\\varepsilon)$。这正确地描述了缓解作用。\n\n该选项提供了一个正确的构造和一个合理的解释，既解释了均匀采样的失败，也解释了杠杆分数采样的成功。\n**结论：** 正确。\n\n**选项B：**\n设 $A = \\sigma \\, u v^{\\top}$，其中 $u_i = v_i = \\frac{1}{\\sqrt{n}}$。这是一个秩为1的矩阵。右奇异向量是 $v_1 = v = (1/\\sqrt{n}, \\dots, 1/\\sqrt{n})^{\\top}$。\n- **杠杆分数和相干性：** 列杠杆分数为 $\\ell_j = (v_{1j})^2 = (1/\\sqrt{n})^2 = 1/n$，对于所有 $j \\in \\{1, \\dots, n\\}$。分数是均匀的。相干性为 $\\mu(V_1) = n \\max_j \\ell_j = n \\cdot (1/n) = 1$。这是一个完全不相干（低相干性）的矩阵，与问题要求相反。\n- **对主张的分析：** 该选项正确计算出相干性为1。然而，它接着声称“均匀采样...会以高概率失败，因为质量均匀分布在所有坐标上”。这是不正确的。低相干性是均匀采样的理想情景，因为任何随机的列子集都代表了整个空间。这个论点是有缺陷的。关于“杠杆分数采样没有帮助，因为杠杆分数是恒定的”的说法是正确的，因为它简化为均匀采样，但均匀采样失败的前提是错误的。\n\n这个选项描述了一个低相干性矩阵，对于这种矩阵，均匀采样是有效的。\n**结论：** 不正确。\n\n**选项C：**\n定义的矩阵是 $A = \\sigma e_1 w^\\top$，其中 $w=e_1$，外加扰动，这与选项A中的矩阵相同。这是一个高相干性矩阵。\n- **对主张的分析：** 该选项声称“杠杆分数是恒定的，因为它们只依赖于 $A$ 的 Frobenius 范数，而不依赖于其奇异结构”。这个陈述是根本错误的。正如问题中所定义的，杠杆分数 $\\ell_j = \\lVert e_j^\\top V_k \\rVert_2^2$ 明确地根据奇异子空间 $V_k$ 定义。这个说法可能将杠杆分数与与列范数平方成正比的采样概率（即 $\\lVert A e_j \\rVert_2^2$）相混淆，后者是另一种（尽管相关）的采样策略。对于矩阵 $A \\approx \\sigma e_1 e_1^\\top$，杠杆分数是高度非均匀的，$\\ell_1 \\approx 1$。因此，杠杆分数采样不能缓解失败的结论也是不正确的。\n\n这个选项包含一个关于杠杆分数定义的重要误解。\n**结论：** 不正确。\n\n**选项D：**\n矩阵是 $A = \\sigma e_1 e_1^\\top$。这是一个确定性的高相干性矩阵。该选项考虑采样 $s_c = c \\log n$ 个列。\n- **对主张的分析：** 该选项声称均匀采样“由于赠券收集者效应，会以高概率成功”。这是对该概念的误用。赠券收集者问题通常解决的是收集到*所有*不同赠券所需的试验次数。在这里，我们关心的是收集一个*特定的*赠券（第1列）。当从 $n$ 列中无放回地抽取 $s_c$ 列时，选中特定一列（第1列）的概率是 $s_c/n$。*错过*第1列的概率是 $1 - s_c/n$。对于 $s_c = c \\log n$，错过第1列的概率是 $1 - \\frac{c \\log n}{n}$。当 $n \\to \\infty$ 时，这个概率趋向于1。因此，使用 $s_c = c \\log n$ 个列的均匀采样将以高概率*失败*。该选项中提出的推理是不正确的。因此，“杠杆分数采样没有提供渐近优势”的结论也是错误的；它提供了决定性的优势。\n\n这个选项关于均匀采样成功的推理是有缺陷的。\n**结论：** 不正确。\n\n### 总结\n选项A提供了唯一正确的构造和有效的推理。它正确地识别了一个高相干性矩阵，准确地解释了为什么均匀采样很可能失败，并正确地描述了杠杆分数采样如何解决这个失败。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在理解了随机采样的理论挑战后，本实践将引导您将理论付诸行动。您将亲手实现随机奇异值分解（Randomized Singular Value Decomposition, RSVD）算法，并将其应用于求解吉洪诺夫（Tikhonov）正则化逆问题——这是数据同化和科学计算中的一项经典任务 。通过完整地执行从构建低秩近似到计算近似解，再到与精确解进行误差分析的整个流程，您将获得宝贵的算法实现与性能评估经验。",
            "id": "3416448",
            "problem": "给定一个带 Tikhonov 正则化的线性逆问题。设 $A \\in \\mathbb{R}^{m \\times n}$，$b \\in \\mathbb{R}^{m}$，且 $\\lambda  0$。Tikhonov 正则化解 $x_{\\lambda} \\in \\mathbb{R}^{n}$ 是以下目标的最小化子：\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\ \\|A x - b\\|_{2}^{2} + \\lambda^{2} \\|x\\|_{2}^{2}.\n$$\n您将使用 $A$ 的随机化低秩近似来计算一个近似的 Tikhonov 解，并量化其误差。\n\n从核心定义和经过充分检验的事实出发，以严谨的方式实现以下步骤。\n\n1) 实现一个带有过采样和幂迭代的随机化奇异值分解（RSVD）子空间寻找器。给定目标秩 $k$、过采样参数 $p$ 和幂迭代次数 $q$，构建一个标准正交矩阵 $Q \\in \\mathbb{R}^{m \\times \\ell}$（其中 $\\ell = \\min(m,n,k+p)$），其近似张成 $A$ 的值域。然后形成小矩阵 $B = Q^{\\top} A \\in \\mathbb{R}^{\\ell \\times n}$，接着计算其紧奇异值分解 (SVD) $B = \\tilde{U} \\Sigma V^{\\top}$。通过 $U \\approx Q \\tilde{U}$ 形成近似的前 $k$ 列奇异向量，并保留前 $k$ 个奇异值和右奇异向量，作为近似的秩-$k$ 分解 $A \\approx U_{k} \\Sigma_{k} V_{k}^{\\top}$。\n\n2) 仅使用近似因子 $U_{k}$、$\\Sigma_{k}$ 和 $V_{k}$，计算一个近似的 Tikhonov 解 $\\tilde{x}_{\\lambda}$。该解是通过将解限制在前 $k$ 个主右奇异向量所张成的子空间中得到的。您必须从 Tikhonov 目标和低秩因子中推导出正确的投影表达式，不能假定任何快捷公式。\n\n3) 使用基于 $A$ 的完全奇异值分解（SVD）的可靠数值线性代数方法，精确求解 Tikhonov 问题，从而计算出精确的 Tikhonov 解 $x_{\\lambda}$。\n\n4) 量化以下两种误差：\n- 欧几里得范数下的解误差 $E_{x} = \\|\\tilde{x}_{\\lambda} - x_{\\lambda}\\|_{2}$。\n- 残差范数的差异 $E_{r} = \\left| \\|A \\tilde{x}_{\\lambda} - b\\|_{2} - \\|A x_{\\lambda} - b\\|_{2} \\right|$。\n\n您的程序必须以科学上真实且可复现的方式合成测试数据，具体如下：\n- 对所有随机性使用固定的伪随机种子 $0$。\n- 为了生成 $A$，通过对具有独立标准正态分布条目的矩阵应用经济尺寸 QR 分解，构建薄的标准正交因子 $U \\in \\mathbb{R}^{m \\times r}$ 和 $V \\in \\mathbb{R}^{n \\times r}$，其中 $r = \\min(m,n)$。然后设置 $A = U \\operatorname{diag}(s) V^{\\top}$，其中奇异值 $s \\in \\mathbb{R}^{r}$ 由一个衰减定律指定：\n  - 比率为 $\\rho \\in (0,1)$ 的几何衰减：$s_{i} = \\max(s_{\\min}, \\rho^{i-1})$，对于 $i = 1,2,\\dots,r$，其中 $s_{\\min}  0$。\n  - 指数为 $\\alpha  0$ 的幂律衰减：$s_{i} = (i)^{-\\alpha}$，对于 $i = 1,2,\\dots,r$。\n- 生成一个真实向量 $x_{\\mathrm{true}} \\in \\mathbb{R}^{n}$，其条目为独立标准正态分布。\n- 形成 $b = A x_{\\mathrm{true}} + \\eta$，其中噪声向量 $\\eta \\in \\mathbb{R}^{m}$ 具有独立的、均值为 $0$ 且标准差等于给定噪声水平的正态分布条目。\n\n仅使用与上述构造一致的矩阵乘法和标准正交化来实现带有过采样 $p$ 和幂迭代 $q$ 的 RSVD。投影的 Tikhonov 解必须使用近似的秩-$k$ 因子推导和评估。精确的 Tikhonov 解必须使用 $A$ 的完全 SVD 计算。\n\n测试套件。您的程序必须运行以下五个测试用例并收集所要求的误差。在每种情况下，元组列出了 $(m,n,\\text{衰减类型},\\text{衰减参数},s_{\\min},k,p,q,\\lambda,\\text{噪声水平})$：\n- 用例 1：$(80,60,\\text{几何衰减},\\rho=0.9,10^{-12},20,10,1,10^{-1},10^{-3})$。\n- 用例 2：$(60,60,\\text{幂律衰减},\\alpha=2.0,10^{-12},60,5,0,10^{-6},0)$。\n- 用例 3：$(80,50,\\text{几何衰减},\\rho=0.8,10^{-12},5,5,2,10^{1},10^{-4})$。\n- 用例 4：$(40,100,\\text{幂律衰减},\\alpha=1.5,10^{-12},25,10,1,10^{-2},5 \\cdot 10^{-3})$。\n- 用例 5：$(120,80,\\text{几何衰减},\\rho=0.95,10^{-12},15,5,3,10^{-2},10^{-2})$。\n\n输出规范。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于上述顺序中的每个测试用例，附加两个使用科学记数法表示且具有 $10$ 位有效数字的浮点数：首先是 $E_{x}$，然后是 $E_{r}$。因此，输出将是一个长度为 $10$ 的列表，顺序如下：\n$$\n[E_{x}^{(1)}, E_{r}^{(1)}, E_{x}^{(2)}, E_{r}^{(2)}, E_{x}^{(3)}, E_{r}^{(3)}, E_{x}^{(4)}, E_{r}^{(4)}, E_{x}^{(5)}, E_{r}^{(5)}].\n$$\n除此单行外，不应打印任何其他文本。此问题不涉及角度，也不需要物理单位。所有浮点输出必须以具有 $10$ 位有效数字的科学记数法打印。",
            "solution": "该问题要求实现并比较两种解决 Tikhonov 正则化线性逆问题的方法。目标是找到 $x \\in \\mathbb{R}^{n}$，以最小化\n$$\nJ(x) = \\|A x - b\\|_{2}^{2} + \\lambda^{2} \\|x\\|_{2}^{2}\n$$\n其中 $A \\in \\mathbb{R}^{m \\times n}$，$b \\in \\mathbb{R}^{m}$，$\\lambda  0$ 是正则化参数。我们将首先使用 $A$ 的奇异值分解（SVD）推导精确解，然后使用随机化 SVD（RSVD）推导近似解，最后量化它们之间的差异。\n\n### 数据生成\n根据问题规范，测试数据以一种受控、可复现的方式合成。我们将全局伪随机种子设置为 $0$。\n1.  设 $r = \\min(m, n)$。我们生成两个大小为 $m \\times r$ 和 $n \\times r$ 的随机矩阵，其条目从标准正态分布 $\\mathcal{N}(0, 1)$ 中抽取。对这些矩阵应用经济尺寸 QR 分解，得到标准正交矩阵 $U \\in \\mathbb{R}^{m \\times r}$ 和 $V \\in \\mathbb{R}^{n \\times r}$。\n2.  根据几何衰减定律 $s_i = \\max(s_{\\min}, \\rho^{i-1})$ 或幂律衰减 $s_i = i^{-\\alpha}$（对于 $i=1, \\dots, r$）构造奇异值向量 $s \\in \\mathbb{R}^{r}$。\n3.  矩阵 $A$ 由 $A = U \\operatorname{diag}(s) V^{\\top}$ 形成。根据构造，$A = U \\Sigma V^{\\top}$ 是 $A$ 的紧 SVD。\n4.  生成一个真实解 $x_{\\mathrm{true}} \\in \\mathbb{R}^{n}$，其条目来自 $\\mathcal{N}(0, 1)$。\n5.  观测向量 $b \\in \\mathbb{R}^{m}$ 通过 $b = A x_{\\mathrm{true}} + \\eta$ 形成，其中 $\\eta \\in \\mathbb{R}^{m}$ 是一个噪声向量，其条目为独立同分布（i.i.d.），来自 $\\mathcal{N}(0, \\sigma_{\\text{noise}}^2)$，其中 $\\sigma_{\\text{noise}}$ 是指定的噪声水平。\n\n### 通过完全 SVD 求解精确 Tikhonov 解\n为了找到 Tikhonov 目标 $J(x)$ 的精确最小化子 $x_{\\lambda}$，我们利用 $A$ 的 SVD，即 $A = U \\Sigma V^{\\top}$。我们进行变量替换，令 $x = Vz$，其中 $z \\in \\mathbb{R}^{r}$。由于 $V$ 的列是标准正交的，$\\|x\\|_{2} = \\|Vz\\|_{2} = \\|z\\|_{2}$。目标函数变为：\n$$\nJ(z) = \\|U \\Sigma V^{\\top} (Vz) - b\\|_{2}^{2} + \\lambda^{2} \\|z\\|_{2}^{2} = \\|U \\Sigma z - b\\|_{2}^{2} + \\lambda^{2} \\|z\\|_{2}^{2}\n$$\n利用欧几里得范数的酉不变性，$\\|U y\\|_{2} = \\|y\\|_{2}$，我们可以写出：\n$$\nJ(z) = \\|\\Sigma z - U^{\\top}b\\|_{2}^{2} + \\lambda^{2}\\|z\\|_{2}^{2}\n$$\n令 $c = U^{\\top}b$，目标函数在 $z$ 的各分量上是可分离的：\n$$\nJ(z) = \\sum_{i=1}^{r} (\\sigma_i z_i - c_i)^2 + \\lambda^{2} \\sum_{i=1}^{r} z_i^2 = \\sum_{i=1}^{r} \\left( (\\sigma_i z_i - c_i)^2 + \\lambda^{2} z_i^2 \\right)\n$$\n为了找到最小值，我们对每个 $z_i$ 求导并令其为零：\n$$\n\\frac{\\partial J}{\\partial z_i} = 2\\sigma_i(\\sigma_i z_i - c_i) + 2\\lambda^2 z_i = 0 \\implies (\\sigma_i^2 + \\lambda^2)z_i = \\sigma_i c_i\n$$\n解出 $z_i$ 得 $z_i = \\frac{\\sigma_i c_i}{\\sigma_i^2 + \\lambda^2}$。变换回原始变量 $x = Vz$，精确的 Tikhonov 解为：\n$$\nx_{\\lambda} = Vz = \\sum_{i=1}^{r} v_i z_i = \\sum_{i=1}^{r} v_i \\frac{\\sigma_i (u_i^{\\top}b)}{\\sigma_i^2 + \\lambda^2}\n$$\n其中 $u_i$ 和 $v_i$ 分别是 $U$ 和 $V$ 的第 $i$ 列。\n\n### 通过随机化 SVD 求解近似 Tikhonov 解\n随机化 SVD（RSVD）提供了一种计算上高效的方法来找到 $A$ 的低秩近似。我们计算一个近似的秩-$k$ 分解 $A \\approx U_k \\Sigma_k V_k^{\\top}$。\n\n1.  **子空间寻找**：我们构建一个标准正交矩阵 $Q \\in \\mathbb{R}^{m \\times \\ell}$，其列近似于 $A$ 的值域。这里，$\\ell = \\min(m, n, k+p)$，其中 $k$ 是目标秩，$p$ 是过采样参数。\n    a. 抽取一个高斯随机矩阵 $\\Omega \\in \\mathbb{R}^{n \\times \\ell}$。\n    b. 形成样本矩阵 $Y = A \\Omega$。\n    c. 为了提高准确性，特别是在奇异值衰减缓慢的情况下，我们应用 $q$ 次幂迭代。使用一种数值稳定的方案：首先对 $Y$ 进行QR分解得到 $Q$，然后迭代 $q$ 次：$Q \\leftarrow \\text{QR}(A(\\text{QR}(A^\\top Q)))$。\n    d. 最终的矩阵 $Q$ 是我们的标准正交基。\n\n2.  **投影**：我们将 $A$ 投影到由 $Q$ 张成的子空间上：$B = Q^{\\top}A \\in \\mathbb{R}^{\\ell \\times n}$。\n\n3.  **分解**：计算小矩阵 $B = \\tilde{U} \\Sigma V^{\\top}$ 的 SVD（其中维度为 $\\ell \\times \\ell$, $\\ell \\times n$, $n \\times n$）。我们形成近似的左奇异向量 $U = Q\\tilde{U}$。\n\n4.  **截断**：我们取前 $k$ 个分量来得到秩-$k$ 近似 $A \\approx U_k \\Sigma_k V_k^{\\top}$，其中 $U_k \\in \\mathbb{R}^{m \\times k}$，$\\Sigma_k \\in \\mathbb{R}^{k \\times k}$，以及 $V_k \\in \\mathbb{R}^{n \\times k}$。\n\n问题指出，近似解 $\\tilde{x}_{\\lambda}$ 是“仅使用近似因子”计算的。这被解释为在 Tikhonov 问题中用其近似 $A_k = U_k \\Sigma_k V_k^{\\top}$ 替换 $A$。解的结构与精确情况相同，但在秩 $k$ 处截断并使用近似因子：\n$$\n\\tilde{x}_{\\lambda} = \\sum_{i=1}^{k} (v_k)_i \\frac{(\\sigma_k)_i ((u_k)_i^{\\top}b)}{(\\sigma_k)_i^2 + \\lambda^2}\n$$\n这里，$(u_k)_i, (\\sigma_k)_i, (v_k)_i$ 是来自 RSVD 的第 $i$ 个近似奇异向量和奇异值。\n\n### 误差量化\n计算以下两种误差以比较近似解和精确解：\n1.  **解误差**：两个解向量之间的欧几里得距离。\n    $E_x = \\|\\tilde{x}_{\\lambda} - x_{\\lambda}\\|_{2}$\n2.  **残差范数差异**：相应残差的欧几里得范数的绝对差。\n    $E_r = \\left| \\|A \\tilde{x}_{\\lambda} - b\\|_{2} - \\|A x_{\\lambda} - b\\|_{2} \\right|$\n这些指标评估了随机化近似方案在 Tikhonov 正则化背景下的表现。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Tikhonov regularization problem using full SVD and Randomized SVD,\n    and computes the error between the two solutions.\n    \"\"\"\n    \n    class TestCase:\n        \"\"\"Helper class to store test case parameters.\"\"\"\n        def __init__(self, m, n, decay_type, decay_param, s_min, k, p, q, lambda_reg, noise_level):\n            self.m = m\n            self.n = n\n            self.decay_type = decay_type\n            self.decay_param = decay_param\n            self.s_min = s_min\n            self.k = k\n            self.p = p\n            self.q = q\n            self.lambda_reg = lambda_reg\n            self.noise_level = noise_level\n\n    def generate_data(params: TestCase, rng: np.random.Generator):\n        \"\"\"Generates problem data (A, b) and the true SVD of A.\"\"\"\n        m, n = params.m, params.n\n        r = min(m, n)\n        \n        # Orthonormal factors U and V from QR of Gaussian matrices\n        U, _ = np.linalg.qr(rng.standard_normal((m, r)))\n        V, _ = np.linalg.qr(rng.standard_normal((n, r)))\n        \n        # Singular values with specified decay\n        indices = np.arange(1, r + 1)\n        if params.decay_type == 'geometric':\n            s = np.maximum(params.s_min, params.decay_param ** (indices - 1))\n        elif params.decay_type == 'powerlaw':\n            s = indices ** (-params.decay_param)\n        else:\n            raise ValueError(\"Unknown decay type\")\n            \n        A = U @ np.diag(s) @ V.T\n        \n        x_true = rng.standard_normal((n, 1))\n        noise = rng.normal(0, params.noise_level, (m, 1))\n        b = A @ x_true + noise\n        \n        return A, b, (U, s, V.T)\n\n    def randomized_svd(A, k, p, q, rng):\n        \"\"\"\n        Computes an approximate rank-k SVD of A using a randomized algorithm\n        with oversampling and power iterations.\n        \"\"\"\n        m, n = A.shape\n        ell = min(m, n, k + p)\n        \n        # Stage A: Sketching and Power Iterations\n        Omega = rng.standard_normal((n, ell))\n        Y = A @ Omega\n        \n        # Stabilized power iteration scheme\n        Q, _ = np.linalg.qr(Y)\n        for _ in range(q):\n            Y_star = A.T @ Q\n            Q_star, _ = np.linalg.qr(Y_star)\n            Y = A @ Q_star\n            Q, _ = np.linalg.qr(Y)\n            \n        # Stage B: Project and Factorize\n        B = Q.T @ A\n        U_tilde, s_approx, V_T_approx = np.linalg.svd(B, full_matrices=False)\n        U_approx = Q @ U_tilde\n        \n        # Truncate to desired rank k\n        U_k = U_approx[:, :k]\n        s_k = s_approx[:k]\n        V_T_k = V_T_approx[:k, :]\n        \n        return U_k, s_k, V_T_k\n\n    # Use a single RNG for reproducibility across all test cases\n    rng = np.random.default_rng(0)\n\n    test_cases = [\n        TestCase(80, 60, 'geometric', 0.9, 1e-12, 20, 10, 1, 1e-1, 1e-3),\n        TestCase(60, 60, 'powerlaw', 2.0, 1e-12, 60, 5, 0, 1e-6, 0.0),\n        TestCase(80, 50, 'geometric', 0.8, 1e-12, 5, 5, 2, 1e1, 1e-4),\n        TestCase(40, 100, 'powerlaw', 1.5, 1e-12, 25, 10, 1, 1e-2, 5e-3),\n        TestCase(120, 80, 'geometric', 0.95, 1e-12, 15, 5, 3, 1e-2, 1e-2)\n    ]\n    \n    results = []\n\n    for case in test_cases:\n        A, b, (U_true, s_true, V_T_true) = generate_data(case, rng)\n        V_true = V_T_true.T\n        lambda_sq = case.lambda_reg**2\n        \n        # 1. Compute exact Tikhonov solution using full SVD\n        c_true = U_true.T @ b\n        s_true_col = s_true.reshape(-1, 1)\n        d_true = s_true_col / (s_true_col**2 + lambda_sq)\n        x_lambda = V_true @ (d_true * c_true)\n        \n        # 2. Compute approximate Tikhonov solution using RSVD\n        U_k, s_k, V_T_k = randomized_svd(A, case.k, case.p, case.q, rng)\n        V_k = V_T_k.T\n        \n        c_k = U_k.T @ b\n        s_k_col = s_k.reshape(-1, 1)\n        # Add a small epsilon to denominator to avoid division by zero if s_k is zero.\n        d_k = s_k_col / (s_k_col**2 + lambda_sq + np.finfo(float).eps)\n        x_tilde_lambda = V_k @ (d_k * c_k)\n\n        # 3. Quantify errors\n        E_x = np.linalg.norm(x_tilde_lambda - x_lambda)\n        \n        res_tilde = np.linalg.norm(A @ x_tilde_lambda - b)\n        res_exact = np.linalg.norm(A @ x_lambda - b)\n        E_r = np.abs(res_tilde - res_exact)\n        \n        # Format output to scientific notation with 10 significant digits\n        results.append(\"{:.9e}\".format(E_x))\n        results.append(\"{:.9e}\".format(E_r))\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "最后的练习将视角从算法的理论精度转向在真实硬件环境下的实际性能。我们假设一个数据大到无法完全载入内存（即“核外”计算）的场景，要求您在两种不同的随机“草图”（sketching）方法——高斯草图与基于哈达玛变换的结构化草图——之间做出选择 。通过对磁盘I/O、内存占用和计算吞吐量进行建模分析，您将学会如何在面对实际工程约束时，做出有数据支持的、性能驱动的算法决策，这对于处理大规模问题至关重要。",
            "id": "3416535",
            "problem": "一个数据同化工作流需要一个随机化奇异值分解 (SVD) 值域探测器，用于处理一个存储在单个磁盘上的非常大的核外（out-of-core）高矩阵 $A \\in \\mathbb{R}^{n \\times d}$。矩阵 $A$ 有 $n = 5 \\times 10^{7}$ 行和 $d = 512$ 列，并以双精度存储（每个元素为 $8$ 字节）。该计算系统具有 $B_{\\mathrm{disk}} = 2.0 \\times 10^{9}$ 字节/秒的持续顺序磁盘带宽和 $R_{\\mathrm{flop}} = 3.0 \\times 10^{11}$ 次浮点运算/秒的峰值持续浮点吞吐量。可用随机存取存储器 (RAM) 为 $M = 3.2 \\times 10^{10}$ 字节。目标草图大小为 $l = 256$，算法必须在 $T_{\\max} = 120$ 秒的时间预算内完成。假设使用单遍值域探测器来形成 $Y = A \\Omega$，并且磁盘输入/输出与计算不重叠。您可以忽略后续对 $Y$ 进行正交规范化的成本以及任何小的常数时间任务的成本。\n\n有两种草图构建方案可供选择：\n\n- 一个 Gaussian 草图，其中 $\\Omega \\in \\mathbb{R}^{d \\times l}$ 的条目是独立同分布的标准正态分布，作为稠密矩阵乘法应用。\n\n- 一个 Subsampled Randomized Hadamard Transform (SRHT) 草图，定义为 $\\Omega_{\\mathrm{SRHT}} = \\sqrt{\\frac{d}{l}} D H R$，其中 $D$ 是一个对角 Rademacher 矩阵，$H$ 是长度为 $d$ 的 Walsh–Hadamard 变换，$R$ 无放回地均匀选择 $l$ 列。\n\n您必须为每种草图的墙钟时间建模，其模型为从磁盘读取一次 $A$ 的时间与执行所需浮点运算以形成 $Y = A \\Omega$ 的时间之和。对于 Gaussian 草图，将稠密矩阵乘法视为 $2ndl$ 次浮点运算。对于 SRHT 草图，将应用 $D H$ 的每行成本视为 $2 d \\log_{2}(d)$ 次浮点加法加上 $d$ 次符号翻转，即每行总共 $2 d \\log_{2}(d) + d$ 次浮点运算，并假设通过 $R$ 进行的采样成本可以忽略不计。\n\n计算以 $m_{b}$ 行的流式块进行；在任何时刻，内存都必须容纳一个大小为 $m_{b} \\times d$ 的 $A$ 块、一个大小为 $m_{b} \\times l$ 的相应 $Y$ 块，以及大小为 $d \\times l$ 的草图矩阵（或变换数据）。对所有数组使用双精度存储。在 RAM 限制下确定一个可行的 $m_{b}$，并假设这些块达到了计算吞吐量 $R_{\\mathrm{flop}}$。\n\n决定哪种草图满足时间预算，并报告所选草图的预测总墙钟时间（以秒为单位）。将您的答案四舍五入到三位有效数字，并以秒为单位表示最终时间。",
            "solution": "任务是估算形成 $Y = A \\Omega$ 的墙钟时间，即输入/输出（I/O）时间和计算时间之和，然后决定哪种草图构建方案（Gaussian 或 Subsampled Randomized Hadamard Transform, SRHT）满足时间预算 $T_{\\max}$。\n\n我们从基本定义开始：\n\n- 矩阵 $A$ 的总字节数为\n$$\n\\text{bytes}(A) = n d \\times 8.\n$$\n\n- 在带宽 $B_{\\mathrm{disk}}$ 下，对 $A$ 进行一次遍历的磁盘读取时间为\n$$\nT_{\\mathrm{io}} = \\frac{\\text{bytes}(A)}{B_{\\mathrm{disk}}}.\n$$\n\n- 对于 Gaussian 草图，浮点运算次数（稠密矩阵乘法）为\n$$\n\\text{flops}_{\\mathrm{Gauss}} = 2 n d l,\n$$\n相应的计算时间为\n$$\nT_{\\mathrm{comp}}^{\\mathrm{Gauss}} = \\frac{\\text{flops}_{\\mathrm{Gauss}}}{R_{\\mathrm{flop}}}.\n$$\n\n- 对于 SRHT 草图，每行应用 $D H$ 的成本为 $2 d \\log_{2}(d) + d$ 次浮点运算，因此总浮点运算次数为\n$$\n\\text{flops}_{\\mathrm{SRHT}} = n \\left( 2 d \\log_{2}(d) + d \\right),\n$$\n计算时间为\n$$\nT_{\\mathrm{comp}}^{\\mathrm{SRHT}} = \\frac{\\text{flops}_{\\mathrm{SRHT}}}{R_{\\mathrm{flop}}}.\n$$\n\n每种方法的总时间建模为\n$$\nT_{\\mathrm{total}}^{(\\cdot)} = T_{\\mathrm{io}} + T_{\\mathrm{comp}}^{(\\cdot)},\n$$\nI/O 和计算之间没有重叠。\n\n我们还必须检查以 $m_{b}$ 行的流式块处理的 RAM 可行性。在任何时候，内存都必须容纳以下数组：\n\n- 一个大小为 $m_{b} \\times d$ 的 $A$ 块（双精度数）：$8 m_{b} d$ 字节。\n- 一个大小为 $m_{b} \\times l$ 的 $Y$ 块（双精度数）：$8 m_{b} l$ 字节。\n- 草图矩阵或变换数据，大小为 $d \\times l$（双精度数）：$8 d l$ 字节。\n\n因此 RAM 约束为\n$$\n8 \\left( m_{b} d + m_{b} l + d l \\right) \\leq M.\n$$\n求解 $m_{b}$，\n$$\nm_{b} \\leq \\frac{\\frac{M}{8} - d l}{d + l}.\n$$\n我们将验证是否存在一个正整数 $m_{b}$，从而确保流式处理的可行性。\n\n现在我们代入给定的数值：\n\n- $n = 5 \\times 10^{7}$，\n- $d = 512$，\n- $l = 256$，\n- $B_{\\mathrm{disk}} = 2.0 \\times 10^{9} \\ \\text{字节/秒}$，\n- $R_{\\mathrm{flop}} = 3.0 \\times 10^{11} \\ \\text{浮点运算/秒}$，\n- $M = 3.2 \\times 10^{10} \\ \\text{字节}$。\n\n首先，计算 $A$ 的大小和 I/O 时间：\n$$\n\\text{bytes}(A) = n d \\times 8 = \\left( 5 \\times 10^{7} \\right) \\cdot 512 \\cdot 8 \\ \\text{字节}.\n$$\n注意 $512 \\cdot 8 = 4096$，因此\n$$\n\\text{bytes}(A) = \\left( 5 \\times 10^{7} \\right) \\cdot 4096 = 2.048 \\times 10^{11} \\ \\text{字节}.\n$$\n因此，\n$$\nT_{\\mathrm{io}} = \\frac{2.048 \\times 10^{11}}{2.0 \\times 10^{9}} = 1.024 \\times 10^{2} \\ \\text{s} = 102.4 \\ \\text{s}.\n$$\n\n接下来，检查 RAM 的可行性。将 $M$ 转换为双精度数的数量：\n$$\n\\frac{M}{8} = \\frac{3.2 \\times 10^{10}}{8} = 4.0 \\times 10^{9} \\ \\text{双精度数}.\n$$\n计算 $d l$ 和 $d + l$：\n$$\nd l = 512 \\cdot 256 = 131{,}072, \\quad d + l = 512 + 256 = 768.\n$$\n然后，\n$$\nm_{b} \\leq \\frac{4.0 \\times 10^{9} - 131{,}072}{768}.\n$$\n计算分子：\n$$\n4.0 \\times 10^{9} - 131{,}072 = 3{,}999{,}868{,}928.\n$$\n除以 $768$：\n$$\nm_{b} \\leq \\frac{3{,}999{,}868{,}928}{768} = 5{,}208{,}149.0\\overline{6}.\n$$\n因此，存在一个大的正整数 $m_{b}$（例如 $m_{b} = 5{,}208{,}149$），在 RAM 限制下流式处理是可行的，同时能保持高吞吐量。\n\n现在计算 Gaussian 草图的计算时间。浮点运算次数为\n$$\n\\text{flops}_{\\mathrm{Gauss}} = 2 n d l = 2 \\cdot \\left( 5 \\times 10^{7} \\right) \\cdot 512 \\cdot 256.\n$$\n首先计算 $n d$：\n$$\nn d = \\left( 5 \\times 10^{7} \\right) \\cdot 512 = 2.56 \\times 10^{10}.\n$$\n然后乘以 $l$：\n$$\nn d l = \\left( 2.56 \\times 10^{10} \\right) \\cdot 256 = 6.5536 \\times 10^{12}.\n$$\n乘以 $2$：\n$$\n\\text{flops}_{\\mathrm{Gauss}} = 1.31072 \\times 10^{13}.\n$$\n因此，\n$$\nT_{\\mathrm{comp}}^{\\mathrm{Gauss}} = \\frac{1.31072 \\times 10^{13}}{3.0 \\times 10^{11}} = 4.369066\\overline{6} \\times 10^{1} \\ \\text{s} \\approx 43.6906667 \\ \\text{s}.\n$$\nGaussian 草图的总时间：\n$$\nT_{\\mathrm{total}}^{\\mathrm{Gauss}} = T_{\\mathrm{io}} + T_{\\mathrm{comp}}^{\\mathrm{Gauss}} = 102.4 + 43.6906667 \\approx 146.0906667 \\ \\text{s}.\n$$\n\n现在计算 SRHT 的计算时间。当 $d=512$ 时，我们有 $\\log_{2}(d) = 9$。浮点运算次数为\n$$\n\\text{flops}_{\\mathrm{SRHT}} = n \\left( 2 d \\log_{2}(d) + d \\right) = \\left( 5 \\times 10^{7} \\right) \\left( 2 \\cdot 512 \\cdot 9 + 512 \\right).\n$$\n计算每行的成本：\n$$\n2 \\cdot 512 \\cdot 9 = 9216, \\quad 9216 + 512 = 9728.\n$$\n因此，\n$$\n\\text{flops}_{\\mathrm{SRHT}} = \\left( 5 \\times 10^{7} \\right) \\cdot 9728 = 4.864 \\times 10^{11}.\n$$\n因此，\n$$\nT_{\\mathrm{comp}}^{\\mathrm{SRHT}} = \\frac{4.864 \\times 10^{11}}{3.0 \\times 10^{11}} = 1.621333\\overline{3} \\ \\text{s} \\approx 1.6213333 \\ \\text{s}.\n$$\nSRHT 的总时间：\n$$\nT_{\\mathrm{total}}^{\\mathrm{SRHT}} = T_{\\mathrm{io}} + T_{\\mathrm{comp}}^{\\mathrm{SRHT}} = 102.4 + 1.6213333 \\approx 104.0213333 \\ \\text{s}.\n$$\n\n将每个总时间与预算 $T_{\\max} = 120$ 秒进行比较：\n- $T_{\\mathrm{total}}^{\\mathrm{Gauss}} \\approx 146.09 \\ \\text{s}  120 \\ \\text{s}$，所以 Gaussian 草图不满足时间预算。\n- $T_{\\mathrm{total}}^{\\mathrm{SRHT}} \\approx 104.02 \\ \\text{s}  120 \\ \\text{s}$，所以 SRHT 草图满足时间预算。\n\n因此，应选择 SRHT 草图。预测的总墙钟时间为 $T_{\\mathrm{total}}^{\\mathrm{SRHT}} \\approx 104.0213333$ 秒。四舍五入到三位有效数字，最终时间为 $104$ 秒。",
            "answer": "$$\\boxed{104}$$"
        }
    ]
}