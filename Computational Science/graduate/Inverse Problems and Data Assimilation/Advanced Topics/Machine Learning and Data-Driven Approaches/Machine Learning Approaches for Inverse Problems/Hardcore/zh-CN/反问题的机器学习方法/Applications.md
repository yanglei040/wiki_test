## 应用与[交叉](@entry_id:147634)学科联系

在前几章中，我们已经详细阐述了解决[逆问题](@entry_id:143129)的机器学习方法的核心原理和机制。我们探讨了如何将深度神经网络构建为直接的逆映射，如何将优化算法展开为可学习的架构，以及如何利用[生成模型](@entry_id:177561)来定义强大的数据驱动先验。这些基本构建模块为解决现实世界中的复杂问题提供了坚实的基础。

然而，这些原理的真正力量在于它们在不同科学和工程领域的广泛适用性以及它们与其它学科[交叉](@entry_id:147634)融合的能力。本章的目标是超越核心理论，通过一系列具有[代表性](@entry_id:204613)的应用问题，展示这些机器学习方法如何被用于解决从地球物理学到机器人学等多个领域的实际挑战。我们将不再重复介绍基本概念，而是聚焦于展示这些概念在实际应用中的效用、扩展和整合。通过这些例子，我们将看到，机器学习不仅为[逆问题](@entry_id:143129)提供了新的求解工具，更重要的是，它为我们理解和建模复杂系统开辟了新的[范式](@entry_id:161181)。

### 混合经典方法与学习方法

将机器学习集成到逆问题求解中的一个最富有成效的途径，并非完全抛弃经过数十年发展的经典数值方法，而是将两者进行有机结合。[机器学习模型](@entry_id:262335)可以被嵌入到传统框架中，以增强其性能、修正其缺陷或加速其计算。

#### 学习化优化器与[算法展开](@entry_id:746359)

许多经典的[逆问题](@entry_id:143129)求解器都基于迭代[优化算法](@entry_id:147840)，如梯度下降法或[近端梯度法](@entry_id:634891)。一个深刻的见解是，这些迭代过程本身可以被看作是一个[深度神经网络](@entry_id:636170)的层。这一“[算法展开](@entry_id:746359)”（Algorithm Unrolling）的观点允许我们将算法的特定组件（如步长、正则化参数，甚至梯度方向）参数化，并利用数据进行端到端的训练，从而学习出一个针对特定问题类别的高度优化的求解器。

一个典型的例子是在求解带有图结构正则化的逆问题时学习优化的步长。考虑一个目标函数 $J(x) = \frac{1}{2}\|A x - y\|_2^2 + \frac{\lambda}{2} x^\top L x$，其中 $L$ 是图拉普拉斯算子。标准的梯度下降迭代为 $x^{t+1} = x^t - \eta_t \nabla J(x^t)$。传统的步长 $\eta_t$ 选择策略（如固定步长或[线搜索](@entry_id:141607)）通常是通用的，未必是针对特定数据[分布](@entry_id:182848)最优的。在学习化方法中，我们可以设计一个[神经网](@entry_id:276355)络来在每次迭代时动态地生成步长 $\eta_t$。例如，一个[图神经网络](@entry_id:136853)（GNN）可以被用来处理定义在图上的状态 $x^t$。该GNN可以将当前迭代的局部特征（如每个节点的梯度分量大小 $|[A^\top (A x^t - y)]_i|$ 和正则项分量大小 $|[L x^t]_i|$）作为输入，通过消息传播机制聚合邻域信息，最终输出一个全局或局部的步长。这种架构允许优化器“感知”当前的误差[分布](@entry_id:182848)和解的结构，并作出更智能的步长决策。然而，为了保证整个优化过程的稳定性，这些学习到的步长通常需要被投影到一个安全的范围内。这个范围由目标函数的海森矩阵 $H = A^\top A + \lambda L$ 的谱特性决定，一个经典的[收敛条件](@entry_id:166121)是$\eta_t  2 / \lambda_{\max}(H)$。因此，学习化优化器往往包含一个“安全投影”层，将GNN的输出 $\widetilde{\eta}_t$ 限制在 $\eta_t = \min\{\widetilde{\eta}_t, \gamma \cdot 2 / \|H\|_2\}$，其中 $\gamma \in (0, 1)$ 是一个安全因子 。

同样，对于包含非光滑正则项（如总变分, Total Variation, TV）的[优化问题](@entry_id:266749)，其近端梯度步骤也可以被展开为一个网络模块。求解带有TV正则项的[MAP估计](@entry_id:751667)问题，$\min_x \frac{1}{2}\|Ax-y\|_2^2 + \lambda \|x\|_{TV}$，其一次迭代更新涉及数据保真项的梯度步和TV正则项的[近端算子](@entry_id:635396)。这个[近端算子](@entry_id:635396)本身可以被近似地实现为一个由卷积（计算[离散梯度](@entry_id:171970)）、一个逐点的[非线性](@entry_id:637147)函数（[梯度向量](@entry_id:141180)的归一化）和另一个卷积（计算离散散度）组成的序列。将这个模块与数据保真梯度步组合起来，就构成了一个可学习的TV去噪层。通过堆叠这样的层并进行端到端训练，可以学习到比经典迭代方法收敛更快、效果更好的模型 。

#### 数据驱动的[数据同化](@entry_id:153547)模型修正

在地球科学、[天气预报](@entry_id:270166)和[海洋学](@entry_id:149256)等领域，数据同化（Data Assimilation, DA）是一个核心的逆问题。其目标是融合稀疏、带噪声的观测数据与一个描述系统演化的物理模型，以获得对系统状态的最佳估计。经典的[数据同化方法](@entry_id:748186)，如卡尔曼滤波器及其变体，严重依赖于对模型误差和[观测误差](@entry_id:752871)统计特性的精确描述。然而，在实际应用中，这些统计特性（特别是[模型误差协方差](@entry_id:752074)）往往是未知或不精确的，这会导致滤波器性能下降甚至发散。

机器学习为此提供了强大的修正工具。我们可以保留经典滤波器的结构（如[集合卡尔曼滤波](@entry_id:166109)器, Ensemble Kalman Filter, EnKF），但将其中的关键参数从静态假设变为从数据中学习。例如，EnKF中一个常见的做法是通过一个“[协方差膨胀](@entry_id:635604)”因子 $\alpha$ 来放大[模型误差协方差](@entry_id:752074)，以弥补因模型不完美和集合规模有限而导致的协[方差](@entry_id:200758)过低问题。传统上，$\alpha$ 是一个需要手动调节的超参数。然而，我们可以设计一个数据驱动的框架来学习最优的 $\alpha$。

具体来说，滤波过程中的“新息”（innovation），即观测值与模型预测值之差，其统计特性直接反映了滤波器的性能。在一个调校良好的滤波器中，新息应该服从一个零均值、其协[方差](@entry_id:200758)由模型预测协[方差](@entry_id:200758)和[观测误差协方差](@entry_id:752872)共同决定的[高斯分布](@entry_id:154414)。我们可以利用历史新息数据，通过最大化其高斯似然函数来反推出最优的膨胀因子 $\hat{\alpha}$。这个过程可以被形式化为一个简单的[优化问题](@entry_id:266749)，其解将数据统计特性（新息的样本[方差](@entry_id:200758)）与模型参数联系起来。此外，滤波器的稳定性对 $\alpha$ 的值有下界要求，以保证误差不会无限增长。这个下界可以通过分析[误差传播](@entry_id:147381)[算子的谱半径](@entry_id:261858)来导出。最终，一个稳健的混合策略是将数据驱动的估计值 $\hat{\alpha}$ 与稳定性驱动的最小值 $\alpha_{\min}$ 相结合，采用 $\alpha^{\star} = \max\{\hat{\alpha}, \alpha_{\min}\}$ 作为实际使用的膨胀因子。这种方法巧妙地融合了[贝叶斯滤波](@entry_id:137269)理论、[稳定性分析](@entry_id:144077)和从数据中学习的统计思想 。

### 采用学习化先验与采样器的先进[贝叶斯推断](@entry_id:146958)

贝叶斯方法为[逆问题](@entry_id:143129)提供了一个完整的框架，它不仅提供一个[点估计](@entry_id:174544)，而且还能通过后验分布来[量化不确定性](@entry_id:272064)。然而，[贝叶斯推断](@entry_id:146958)的两个核心挑战在于：如何定义一个能够捕捉解的复杂结构信息的[先验分布](@entry_id:141376)，以及如何有效地从通常很高维且复杂的后验分布中进行采样。机器学习，特别是[深度生成模型](@entry_id:748264)，为应对这两个挑战提供了革命性的工具。

#### [生成模型](@entry_id:177561)作为复杂结构化先验

传统的[正则化方法](@entry_id:150559)，如吉洪诺夫（Tikhonov）正则化和总变分（TV）正则化，可以被解释为对解施加了简单的[高斯先验](@entry_id:749752)或拉普拉斯先验。例如，[TV正则化](@entry_id:756242)鼓励解是分片常数的，这在某些图像处理问题中是有效的，但对于具有复杂纹理或[精细结构](@entry_id:140861)的解来说，这种先验过于简单，可能会导致“[阶梯效应](@entry_id:755345)”等不自然的伪影。

[深度生成模型](@entry_id:748264)，如[变分自编码器](@entry_id:177996)（VAEs）、[生成对抗网络](@entry_id:634268)（GANs）或[归一化流](@entry_id:272573)（Normalizing Flows），能够从大量数据中学习到复杂的数据[分布](@entry_id:182848)。在[贝叶斯逆问题](@entry_id:634644)的背景下，这些训练好的[生成模型](@entry_id:177561) $G(z)$（其中 $z$ 是一个低维的[潜变量](@entry_id:143771)）可以被用作一个强大的结构化先验。解 $x$ 被约束在生成模型的[流形](@entry_id:153038)上，即 $x=G(z)$。[逆问题](@entry_id:143129)就从求解高维空间中的 $x$ 转化为了求解低维潜空间中的 $z$。这种方法的优势在于，只要生成模型捕捉到了目标解的真实结构（例如，医学图像的解剖结构或自然图像的纹理），那么即便在观测数据严重不足的情况下，它也能够生成高度逼真且符合物理约束的解。

将[TV正则化](@entry_id:756242)与生成模型先验联系起来，可以为我们提供更深的理解。TV范数从几何角度看，是对函数所有水平集周长的积分（根据coarea公式）。一个显式构建分片常数图像的生成模型——例如，通过学习一组区域掩模及其对应的强度值——其正则化项可以被设计为惩罚这些区域边界的总长度。当区域数量足够多时，这种基于边界[周长](@entry_id:263239)的先验在概念上就逼近了TV先验。因此，传统的TV方法可以被看作是这类更灵活的、可学习的、基于几何的生成模型先验的一个特例 。

在更广阔的应用中，例如逆[强化学习](@entry_id:141144)（Inverse Reinforcement Learning, IRL），生成模型先验也显示出其独特的价值。IRL的目标是从观察到的专家行为中推断其背后的[奖励函数](@entry_id:138436)，这是一个典型的逆问题。然而，IRL存在严重的“[不适定性](@entry_id:635673)”：许多不同的[奖励函数](@entry_id:138436)可以导致相同的[最优策略](@entry_id:138495)。这就是所谓的“策略等价”问题。简单的先验，如 $\ell_1$ 或 $\ell_2$ 范数，可以从策略[等价类](@entry_id:156032)中选出一个解（例如，最稀疏或范数最小的[奖励函数](@entry_id:138436)），但这并不能保证找到语义上正确的[奖励函数](@entry_id:138436)。相比之下，一个在大量[奖励函数](@entry_id:138436)数据上训练的[生成模型](@entry_id:177561)可以学习到[奖励函数](@entry_id:138436)通常具有的结构，例如“奖励通常是稀疏的，并且集中在特定的目标状态上”。利用这样的学习化先验，可以在[贝叶斯推断](@entry_id:146958)框架中，从一个巨大的策略等价类中筛选出最“合理”的[奖励函数](@entry_id:138436)，从而极大地提高了问题的可识别性 。

#### 加速贝叶斯计算的学习化策略

当我们的目标是探索整个[后验分布](@entry_id:145605)而不仅仅是寻找最大后验（MAP）估计时，通常需要借助[马尔可夫链蒙特卡洛](@entry_id:138779)（MCMC）等采样算法。然而，对于高维或病态的[后验分布](@entry_id:145605)，标准[MCMC算法](@entry_id:751788)（如[随机游走Metropolis](@entry_id:754036)-Hastings）的混合速度非常慢。[朗之万动力学](@entry_id:142305)（Langevin dynamics）和[哈密顿蒙特卡洛](@entry_id:144208)（Hamiltonian Monte Carlo, HMC）等更先进的算法利用梯度信息来指导采样，从而提高了效率，但它们的性能严重依赖于对后验分布几何的适应性。

具体来说，这些算法的效率取决于一个“[预条件子](@entry_id:753679)”矩阵或“质量”矩阵 $M$ 的选择，理想情况下，$M$ 应该近似于[后验协方差矩阵](@entry_id:753631)（即负对数后验的海森矩阵的逆）。这相当于对参数空间进行重新缩放，使得后验分布看起来更像一个各向同性的高斯分布，从而使得采样过程能够以较大的步长高效地探索整个空间。

机器学习为学习这个理想的[几何变换](@entry_id:150649)提供了可能。一个特别强大的[范式](@entry_id:161181)是使用[归一化流](@entry_id:272573)（normalizing flows）等可逆的[深度神经网络](@entry_id:636170)来学习一个从简单[先验分布](@entry_id:141376)（如[标准正态分布](@entry_id:184509)）到复杂[后验分布](@entry_id:145605)的映射 $x = T(z)$。这个映射 $T$ 可以被看作是学习了一个最优的、与位置相关的[坐标变换](@entry_id:172727)。一旦这个映射被学习到，我们就可以在简单的[潜空间](@entry_id:171820) $z$ 中轻松地进行采样（例如，通过简单的[朗之万动力学](@entry_id:142305)），然后通过前向变换 $x = T(z)$ 将这些样本推送到目标空间，从而得到服从复杂[后验分布](@entry_id:145605)的样本。这种方法将寻找最优[预条件子](@entry_id:753679)这一困难问题，转化为了一个可以通过最大化[证据下界](@entry_id:634110)（ELBO）或其它[变分推断](@entry_id:634275)目标函数来解决的[表示学习](@entry_id:634436)问题。这极大地加速了对复杂[后验分布](@entry_id:145605)的探索，使得全[贝叶斯分析](@entry_id:271788)在以往难以处理的大规模逆问题中成为可能 。

### 联结机器学习与基本物理原理

将机器学习应用于物理系统相关的逆问题时，一个独特且关键的挑战是确保学习到的模型尊重底层物理定律，并表现出与物理系统一致的行为。例如，模型是否应该满足守恒律？其预测是否应该对离散化方式不敏感？其稳定性是否可以被分析？

#### 离散化[不变性](@entry_id:140168)与[算子学习](@entry_id:752958)

许多逆问题涉及由[偏微分方程](@entry_id:141332)（PDE）描述的连续物理过程。为了进行数值计算，这些PDE必须在离散的网格上进行近似。一个常见的陷阱是，在一个特定分辨率的网格上训练的[机器学习模型](@entry_id:262335)，在被部署到另一个不同分辨率的网格上时，其性能可能会灾难性地下降。这是因为一个“朴素”的[机器学习模型](@entry_id:262335)（如一个在像素网格上操作的卷积网络）可能会学习到与特定网格间距 $h$ 相关的数值模式，而不是底层的、连续的物理规律。

例如，考虑从状态 $u$ 恢复[力场](@entry_id:147325) $f$ 的一维椭圆逆问题，其物理关系为 $f(x) = -k u_{xx}(x) + \alpha u(x)$。在离散网格上，[二阶导数](@entry_id:144508) $u_{xx}$ 通常用[中心差分](@entry_id:173198) $\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2}$ 来近似。如果一个模型被训练来用一个通用的三点卷积核 $(w_{-1}, w_0, w_{+1})$ 从 $u$ 预测 $f$，它实际上会学到 $w_{-1} \approx -k/h^2$, $w_0 \approx 2k/h^2 + \alpha$, $w_{+1} \approx -k/h^2$。这些权重中“烘焙”了训练时的网格间距 $h$。当网格变精细（例如 $h' = h/2$）时，这些权重就不再正确，因为分母应该是 $(h/2)^2 = h^2/4$。直接重用这些权重会导致对[微分](@entry_id:158718)项的估计产生一个固定的尺度误差。

解决这一问题的关键在于设计具有“物理[归纳偏置](@entry_id:137419)”的模型架构。一种有效的方法是“[算子学习](@entry_id:752958)”（Operator Learning）。与其让模型学习一个黑箱的映射，不如让模型学习底层物理算子的参数。在上述例子中，模型不应学习卷积核权重，而应学习物理参数 $(k, \alpha)$。模型架构可以显式地包含一个计算[离散拉普拉斯算子](@entry_id:634690)的层，其输出乘以一个可学习的参数 $\hat{k}$，再加上一个由可学习参数 $\hat{\alpha}$ 缩放的恒等映射。由于物理参数 $k$ 和 $\alpha$ 是独立于离散化的，这样学习到的模型可以自然地推广到任何分辨率的网格上，只需在应用时使用对应网格的正确差分算子即可。

另一种处理[多尺度结构](@entry_id:752336)的方法受到经典数值方法中[多重网格](@entry_id:172017)（Multigrid）思想的启发。我们可以设计一个包含“限制”（restriction，从精细网格到粗糙网格的降采样）和“延拓”（prolongation，从粗糙网格到精细网格的[上采样](@entry_id:275608)）操作的[神经网](@entry_id:276355)络。在这种架构中，一个在粗糙网格上学习到的算子可以被用来处理输入数据中的低频分量，而高频分量则可能由其他尺度的算子处理。然而，需要注意的是，这种方法对于输入数据中的高频分量的鲁棒性较差，因为限制操作本质上是一个低通滤波器，可能会丢失高频信息 。

#### 学习化求解器的稳定性与鲁棒性

在科学和工程的关键应用中部署[机器学习模型](@entry_id:262335)之前，必须对其可靠性进行严格的评估。一个核心问题是模型的鲁棒性，即当输入数据受到微小扰动时，模型的输出会如何变化。在[逆问题](@entry_id:143129)的背景下，这意味着我们需要评估学习到的逆映射 $f: y \mapsto x$ 对观测数据 $y$ 中噪声或扰动的敏感性。

传统的[对抗性攻击](@entry_id:635501)研究通常考虑对输入进行任意的、$\ell_p$ 范数有界的扰动。然而，在物理逆问题中，更有意义的扰动类型是那些与系统[固有噪声](@entry_id:261197)模型“物理一致”的扰动。例如，如果观测噪声 $\eta$ 服从协[方差](@entry_id:200758)为 $\Sigma$ 的[高斯分布](@entry_id:154414)，那么一个物理一致的扰动 $\delta y$ 应该位于由 $\Sigma$ 定义的[马氏距离](@entry_id:269828)（Mahalanobis norm）的球内，即 $\|\Sigma^{-1/2} \delta y\|_2 \le \varepsilon$。

在这种设定下，我们可以为任意线性逆映射 $M$（无论是经典的[伪逆](@entry_id:140762) $A^\dagger$ 还是一个学习到的线性网络 $W$）定义一个“对抗脆弱性”度量 $\mathcal{V}(M; \Sigma, \varepsilon)$，它表示在所有物理一致的扰动下，输出产生的[最大范数](@entry_id:268962)误差。通过简单的变量代换和[算子范数](@entry_id:752960)的定义，可以证明这个脆弱性等于 $\mathcal{V}(M; \Sigma, \varepsilon) = \varepsilon \|M \Sigma^{1/2}\|_2$。这个简洁的公式将脆弱性与逆映射 $M$ 的[谱范数](@entry_id:143091)（对于[神经网](@entry_id:276355)络，即其[利普希茨常数](@entry_id:146583)）以及噪声协[方差](@entry_id:200758) $\Sigma$ 的谱特性直接联系起来。对于经典的[伪逆](@entry_id:140762)解 $M=A^\dagger$，在各向同性噪声 $\Sigma = \sigma^2 I$ 的情况下，脆弱性简化为 $\varepsilon \sigma / \sigma_{\min}(A)$，这与我们熟知的、由前向算子 $A$ 的最小奇异值决定的[条件数](@entry_id:145150)有关。这个框架允许我们以一种与经典稳定性分析兼容的、严谨的方式来量化和比较学习化求解器与传统方法的鲁棒性，为在安全攸关的应用中认证机器学习模型提供了理论工具 。

### 前沿：逆问题中的学习与决策

机器学习不仅改变了我们如何求解给定的逆问题，它还开始重塑我们如何构建和与这些问题互动。两个前沿方向分别是：学习如何快速解决一系列相关的[逆问题](@entry_id:143129)，以及在[逆问题](@entry_id:143129)求解过程中主动进行决策以更好地收集信息。

#### 面向[逆问题](@entry_id:143129)族的[元学习](@entry_id:635305)

在许多科学应用中，我们面临的不是单个孤立的逆问题，而是一族共享某些共性的相关问题。例如，在医学成像中，不同病人的解剖结构略有不同，但都遵循相同的基本规律；在[材料科学](@entry_id:152226)中，不同样本的微观结构可能不同，但都由相同的物理过程生成。[元学习](@entry_id:635305)（Meta-Learning），或称“学习如何学习”，正是为了解决这类问题而设计的。其目标不是学习一个针对单一任务的求解器，而是学习一个能够快速适应新任务的“元模型”。

[模型无关元学习](@entry_id:634830)（Model-Agnostic Meta-Learning, MAML）是实现这一目标的强大框架。在逆问题的背景下，我们可以将每个特定的物理系统（例如，由特定的前向算子 $A_t$ 或先验参数 $\Lambda_t$ 定义）视为一个独立的“任务”。MAML的目标是学习一个全局的初始参数 $\theta$，这个 $\theta$ 具有这样的特性：从 $\theta$ 出发，仅需在新任务的少量训练数据上进行一或两步[梯度下降](@entry_id:145942)，就能得到一个在该新任务上表现优异的模型。

这个过程被构建为一个[双层优化](@entry_id:637138)问题。在内层循环中，模型从通用初始化 $\theta$ 出发，通过在任务 $t$ 的“支持集”数据上最小化损失函数 $L_t^{\text{train}}$，适应为任务特定的参数 $\phi_t(\theta) = \theta - \alpha \nabla_\theta L_t^{\text{train}}(\theta)$。在外层循环中，我们通过最小化所有任务上适应后的模型在各自“查询集”数据上的总损失 $\sum_t L_t^{\text{val}}(\phi_t(\theta))$ 来更新通用初始化 $\theta$。计算这个“元梯度”$\nabla_\theta L^{\text{meta}}(\theta)$ 时，需要通过链式法则对内层优化步骤进行[微分](@entry_id:158718)。一个完整的元梯度表达式不仅包含[验证集](@entry_id:636445)损失的梯度，还包含一个乘以海森矩阵 $H_t = \nabla^2_\theta L_t^{\text{train}}(\theta)$ 的二阶项。这个海森矩阵项捕捉了任务训练[损失景观](@entry_id:635571)的“曲率”。它允许[元学习](@entry_id:635305)过程发现这样一个初始点 $\theta$：它不仅本身位于一个平均损失较低的区域，更重要的是，它位于一个平坦的、易于优化的“盆地”中，从而能够向任何一个新任务的方向快速、稳定地进行微调 。

#### 主体性与控制中的逆问题

最后，机器学习与[逆问题](@entry_id:143129)的[交叉](@entry_id:147634)正在催生一个激动人心的新领域，其中[逆问题](@entry_id:143129)求解本身就涉及到主动决策和控制。

在逆强化学习（IRL）中，我们已经看到，逆问题（推断奖励）是理解智能体“主体性”（agency）的关键 。但我们可以更进一步：如果逆问题求解器本身就是一个能够影响环境的智能体呢？这就引出了“[主动学习](@entry_id:157812)”或“实验设计”的思想，但将其置于一个动态的、闭环的系统中。

考虑一个[数据同化](@entry_id:153547)场景，我们不仅要被动地接收观测数据来估计系统状态，而且还可以主动地施加控制 $u_t$ 来改变系统的演化动态，例如 $x_{t+1} = F(u_t)x_t + w_t$。在这种“闭环[数据同化](@entry_id:153547)”中，控制决策和[状态估计](@entry_id:169668)是紧密耦合的。我们可以设计一个策略，选择在每个时间步施加何种控制，以最大化我们对系统状态的认知。

这自然地导出了一个权衡。某些控制动作可能会将系统引导到一个更容易被观测到的状态（例如，一个能激发[观测算子](@entry_id:752875) $H$ 最敏感模式的状态），从而最大化单步的“[信息增益](@entry_id:262008)”。[信息增益](@entry_id:262008)可以通过[贝叶斯更新](@entry_id:179010)前后状态估计[分布](@entry_id:182848)的熵减来量化。另一些控制动作则可能旨在稳定系统，使其演化到一个[方差](@entry_id:200758)较小的状态，从而最小化最终的“重构误差”，这通常与[后验协方差矩阵](@entry_id:753631)的迹（trace）有关。

一个实用的“控制感知”逆问题求解策略可以被设计为一个在每个时间步贪婪地最大化一个组合目标的[近视](@entry_id:178989)策略（myopic policy）：$J(u_t) = \alpha \cdot (\text{信息增益}) - \beta \cdot (\text{重构误差})$。通过实时求解这个小规模的[优化问题](@entry_id:266749)，系统可以自主地选择探测性动作来减少不确定性，或者选择稳定化动作来提高精度。这种将控制理论、信息论和[贝叶斯推断](@entry_id:146958)结合在一起的框架，代表了机器学习驱动的逆问题求解的一个重要前沿方向，它将求解器从一个被动的推断引擎转变为一个主动的科学探索者 。