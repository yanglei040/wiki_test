{
    "hands_on_practices": [
        {
            "introduction": "理解迭代重加权最小二乘法（Iteratively Reweighted Least Squares, IRLS）应从其处理异常值的核心机制入手。本练习将使用鲁棒统计的基石——Huber损失函数，提供一个具体的、分步的计算过程。通过为一个包含明显异常值的小型数据集手动计算残差、权重和更新解，您将对IRLS如何系统性地降低问题数据点的影响力获得切实的理解。",
            "id": "3393330",
            "problem": "考虑一个线性数据同化问题，其前向算子由矩阵 $A \\in \\mathbb{R}^{3 \\times 2}$ 表示，观测值为 $b \\in \\mathbb{R}^{3}$，其中第三个观测值相对于前两个是一个大的离群值。目标是在存在该离群值的情况下，使用基于 Huber 损失的一次迭代重加权最小二乘（IRLS）迭代，鲁棒地估计状态 $x \\in \\mathbb{R}^{2}$。设\n$$\nA \\;=\\; \\begin{pmatrix}\n1  0 \\\\\n0  1 \\\\\n1  1\n\\end{pmatrix},\n\\qquad\nb \\;=\\; \\begin{pmatrix}\n1 \\\\ -1 \\\\ 20\n\\end{pmatrix},\n\\qquad\nx^{(0)} \\;=\\; \\begin{pmatrix}\n0 \\\\ 0\n\\end{pmatrix}.\n$$\n具有阈值参数 $\\delta0$ 的 Huber 损失由以下分段函数定义\n$$\n\\rho_{\\delta}(r) \\;=\\;\n\\begin{cases}\n\\frac{1}{2} r^{2},  \\text{if } |r| \\leq \\delta \\\\\n\\delta |r| - \\frac{1}{2} \\delta^{2},  \\text{if } |r|  \\delta\n\\end{cases}\n$$\n使用 $\\delta = 2$。从上面 $\\rho_{\\delta}(r)$ 的定义和鲁棒 M 估计的原理出发，执行一次 IRLS 迭代如下：\n1. 使用失配 $r = A x - b$ 计算在 $x^{(0)}$ 处的残差，记为 $r^{(0)} \\in \\mathbb{R}^{3}$。\n2. 从与 $\\rho_{\\delta}(r)$ 相关的 Huber 影响函数中推导出相应的 IRLS 权重 $w_{i}$，并组装对角权重矩阵 $W = \\operatorname{diag}(w_{1}, w_{2}, w_{3})$。\n3. 构建加权正规方程 $(A^{\\top} W A) x^{(1)} = A^{\\top} W b$ 并求解得到的 $2 \\times 2$ 线性系统以获得 $x^{(1)}$。\n\n只报告更新后估计值的第二个分量 $x_{2}^{(1)}$ 的值。不需要四舍五入，也不涉及物理单位。",
            "solution": "我们从反问题中的鲁棒 M 估计公式开始，其中估计值 $x \\in \\mathbb{R}^{2}$ 最小化了应用于数据失配的鲁棒惩罚项之和。对于残差 $r_{i} = a_{i}^{\\top} x - b_{i}$，具有阈值参数 $\\delta  0$ 的 Huber 损失定义为\n$$\n\\rho_{\\delta}(r) \\;=\\;\n\\begin{cases}\n\\frac{1}{2} r^{2},  \\text{if } |r| \\leq \\delta \\\\\n\\delta |r| - \\frac{1}{2} \\delta^{2},  \\text{if } |r|  \\delta\n\\end{cases}\n$$\n相应的影响函数（关于 $r$ 的导数）是\n$$\n\\psi_{\\delta}(r) \\;=\\; \\frac{\\mathrm{d}}{\\mathrm{d}r}\\rho_{\\delta}(r) \\;=\\;\n\\begin{cases}\nr,  \\text{if } |r| \\leq \\delta \\\\\n\\delta \\,\\operatorname{sign}(r),  \\text{if } |r|  \\delta\n\\end{cases}\n$$\n在迭代重加权最小二乘（IRLS）中，权重构造为 $w_{i} = \\frac{\\psi_{\\delta}(r_{i})}{r_{i}}$（对于 $r_{i} \\neq 0$）；这得到\n$$\nw_{i} \\;=\\;\n\\begin{cases}\n1,  \\text{if } |r_{i}| \\leq \\delta \\\\\n\\frac{\\delta}{|r_{i}|},  \\text{if } |r_{i}|  \\delta\n\\end{cases}\n$$\n并且根据连续性，如果 $r_{i} = 0$，则 $w_{i} = 1$。\n\n步骤 1：使用 $r = A x - b$ 计算在 $x^{(0)}$ 处的残差。给定\n$$\nA \\;=\\; \\begin{pmatrix}\n1  0 \\\\\n0  1 \\\\\n1  1\n\\end{pmatrix},\n\\qquad\nb \\;=\\; \\begin{pmatrix}\n1 \\\\ -1 \\\\ 20\n\\end{pmatrix},\n\\qquad\nx^{(0)} \\;=\\; \\begin{pmatrix}\n0 \\\\ 0\n\\end{pmatrix},\n$$\n我们得到\n$$\nr^{(0)} \\;=\\; A x^{(0)} - b \\;=\\; \\begin{pmatrix}0 \\\\ 0 \\\\ 0\\end{pmatrix} - \\begin{pmatrix}1 \\\\ -1 \\\\ 20\\end{pmatrix} \\;=\\; \\begin{pmatrix} -1 \\\\ 1 \\\\ -20 \\end{pmatrix}.\n$$\n\n步骤 2：从 $\\delta = 2$ 的 Huber 影响函数推导 IRLS 权重。残差的绝对值分别为 $|r_{1}^{(0)}| = 1$， $|r_{2}^{(0)}| = 1$ 和 $|r_{3}^{(0)}| = 20$。因此，\n- 对于 $i = 1$：$|r_{1}^{(0)}| = 1 \\leq \\delta$ 意味着 $w_{1} = 1$。\n- 对于 $i = 2$：$|r_{2}^{(0)}| = 1 \\leq \\delta$ 意味着 $w_{2} = 1$。\n- 对于 $i = 3$：$|r_{3}^{(0)}| = 20  \\delta$ 意味着 $w_{3} = \\frac{\\delta}{|r_{3}^{(0)}|} = \\frac{2}{20} = 0.1$。\n\n因此，\n$$\nW \\;=\\; \\operatorname{diag}(1,\\, 1,\\, 0.1).\n$$\n\n步骤 3：构建并求解加权正规方程 $(A^{\\top} W A) x^{(1)} = A^{\\top} W b$。\n\n首先计算 $A^{\\top} W A$。将 $A$ 的行表示为 $a_{1}^{\\top} = (1, 0)$，$a_{2}^{\\top} = (0, 1)$，$a_{3}^{\\top} = (1, 1)$。那么\n$$\nA^{\\top} W A \\;=\\; \\sum_{i=1}^{3} w_{i} \\, a_{i} a_{i}^{\\top}.\n$$\n我们有\n$$\nw_{1} a_{1} a_{1}^{\\top} \\;=\\; 1 \\cdot \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\begin{pmatrix} 1  0 \\end{pmatrix} \\;=\\; \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix},\n$$\n$$\nw_{2} a_{2} a_{2}^{\\top} \\;=\\; 1 \\cdot \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\\begin{pmatrix} 0  1 \\end{pmatrix} \\;=\\; \\begin{pmatrix} 0  0 \\\\ 0  1 \\end{pmatrix},\n$$\n$$\nw_{3} a_{3} a_{3}^{\\top} \\;=\\; 0.1 \\cdot \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\begin{pmatrix} 1  1 \\end{pmatrix} \\;=\\; \\begin{pmatrix} 0.1  0.1 \\\\ 0.1  0.1 \\end{pmatrix}.\n$$\n求和，\n$$\nA^{\\top} W A \\;=\\; \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} 0.1  0.1 \\\\ 0.1  0.1 \\end{pmatrix} \\;=\\; \\begin{pmatrix} 1.1  0.1 \\\\ 0.1  1.1 \\end{pmatrix}.\n$$\n\n接下来计算 $A^{\\top} W b$。注意 $W b = \\begin{pmatrix} 1 \\cdot 1 \\\\ 1 \\cdot (-1) \\\\ 0.1 \\cdot 20 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -1 \\\\ 2 \\end{pmatrix}$。然后\n$$\nA^{\\top} W b \\;=\\; A^{\\top} \\begin{pmatrix} 1 \\\\ -1 \\\\ 2 \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n1  0  1 \\\\\n0  1  1\n\\end{pmatrix}\n\\begin{pmatrix} 1 \\\\ -1 \\\\ 2 \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n1 \\cdot 1 + 0 \\cdot (-1) + 1 \\cdot 2 \\\\\n0 \\cdot 1 + 1 \\cdot (-1) + 1 \\cdot 2\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}.\n$$\n\n我们必须求解以下 $2 \\times 2$ 线性系统\n$$\n\\begin{pmatrix} 1.1  0.1 \\\\ 0.1  1.1 \\end{pmatrix}\n\\begin{pmatrix} x_{1}^{(1)} \\\\ x_{2}^{(1)} \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}.\n$$\n系数矩阵的行列式是\n$$\n\\det \\;=\\; 1.1 \\cdot 1.1 \\;-\\; 0.1 \\cdot 0.1 \\;=\\; 1.21 - 0.01 \\;=\\; 1.20.\n$$\n其逆矩阵是\n$$\n\\left(\\begin{pmatrix} 1.1  0.1 \\\\ 0.1  1.1 \\end{pmatrix}\\right)^{-1}\n\\;=\\;\n\\frac{1}{1.20}\n\\begin{pmatrix}\n1.1  -0.1 \\\\\n-0.1  1.1\n\\end{pmatrix}.\n$$\n因此\n$$\n\\begin{pmatrix} x_{1}^{(1)} \\\\ x_{2}^{(1)} \\end{pmatrix}\n\\;=\\;\n\\frac{1}{1.20}\n\\begin{pmatrix}\n1.1  -0.1 \\\\\n-0.1  1.1\n\\end{pmatrix}\n\\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}\n\\;=\\;\n\\frac{1}{1.20}\n\\begin{pmatrix}\n1.1 \\cdot 3 + (-0.1) \\cdot 1 \\\\\n(-0.1) \\cdot 3 + 1.1 \\cdot 1\n\\end{pmatrix}\n\\;=\\;\n\\frac{1}{1.20}\n\\begin{pmatrix}\n3.3 - 0.1 \\\\\n-0.3 + 1.1\n\\end{pmatrix}\n\\;=\\;\n\\frac{1}{1.20}\n\\begin{pmatrix}\n3.2 \\\\\n0.8\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n\\frac{3.2}{1.2} \\\\\n\\frac{0.8}{1.2}\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n\\frac{8}{3} \\\\\n\\frac{2}{3}\n\\end{pmatrix}.\n$$\n\n因此，所要求的值是第二个分量 $x_{2}^{(1)} = \\frac{2}{3}$。",
            "answer": "$$\\boxed{\\frac{2}{3}}$$"
        },
        {
            "introduction": "掌握了基本迭代步骤后，我们可以将IRLS应用于科学计算中常见的、更复杂的结构化问题。本练习将探讨一个合成的层析成像问题，其正向算子具有特殊的稀疏结构。您将发现这种结构如何简化IRLS的更新步骤，将一个大型耦合系统转化为一系列独立的加权平均计算，这对于开发高效的大规模反演算法是至关重要的见解。",
            "id": "3605220",
            "problem": "考虑一个合成的线性化走时层析成像实验，其中正演算子为 $G \\in \\mathbb{R}^{50 \\times 20}$，代表网格慢度的模型向量为 $m \\in \\mathbb{R}^{20}$，代表观测走时的数据向量为 $d \\in \\mathbb{R}^{50}$。假设线性观测模型为 $d = G m + \\varepsilon$，其中 $\\varepsilon$ 代表测量噪声和异常值。对于这个合成设计，50条射线中的每一条都恰好穿过一个模型网格，路径长度为单位长度，而不穿过其他网格，因此 $G$ 的每一行都包含一个 $1$ 和其余位置为零。射线和网格之间的映射关系如下：\n- 对于网格 $j \\in \\{1,2,\\dots,10\\}$，恰好有 $3$ 条射线穿过网格 $j$。\n- 对于网格 $j \\in \\{11,12,\\dots,20\\}$，恰好有 $2$ 条射线穿过网格 $j$。\n\n假设我们使用迭代重加权最小二乘法（IRLS）的一次迭代进行稳健反演，其中 Huber 损失函数的阈值参数为 $\\delta = 1$。设初始模型为 $m^{(0)} = 0$。相应的初始残差为 $r^{(0)} = d - G m^{(0)} = d$。测得的残差被以下网格模式的异常值污染：\n- 对于每个网格 $j \\in \\{1,2,\\dots,10\\}$，与该网格中 $3$ 条射线相关的 $3$ 个残差为 $\\{0.1, 0.1, 5.0\\}$。\n- 对于每个网格 $j \\in \\{11,12,\\dots,20\\}$，与该网格中 $2$ 条射线相关的 $2$ 个残差为 $\\{0.1, 5.0\\}$。\n\n使用 Huber 损失函数\n$$\n\\rho_{\\delta}(r) \\;=\\; \n\\begin{cases}\n\\frac{1}{2} r^{2},  \\text{if } |r| \\le \\delta \\\\\n\\delta|r| - \\frac{1}{2}\\delta^{2},  \\text{if } |r| > \\delta\n\\end{cases}\n$$\n从 $m^{(0)}$ 开始，进行一次 IRLS 迭代，以获得更新后的模型 $m^{(1)}$。具体来说：\n1. 计算初始残差 $r^{(0)}$ 和从 Huber 损失函数导出的相应 IRLS 权重。\n2. 构建与此次迭代的加权最小二乘代理相关的加权正规方程。\n3. 求解这些加权正规方程以获得 $m^{(1)}$。\n\n将最终更新的模型向量 $m^{(1)}$ 表示为一个包含 $20$ 个元素的单行向量。无需四舍五入；如果出现自然产生的精确值，请提供精确值。最终答案必须仅为指定的更新后模型向量。答案中不要包含物理单位。",
            "solution": "问题要求从初始模型 $m^{(0)} = 0$ 开始，经过一次迭代重加权最小二乘法（IRLS）迭代后更新的模型向量 $m^{(1)}$。线性模型由 $d = G m + \\varepsilon$ 给出。\n\n一次IRLS迭代通过求解一个加权最小二乘问题来更新模型。更新后的模型 $m^{(k+1)}$ 是通过最小化残差的加权平方和找到的，这等同于求解加权正规方程：\n$$ (G^T W^{(k)} G) m^{(k+1)} = G^T W^{(k)} d $$\n其中 $W^{(k)}$ 是一个对角权重矩阵，其权重由前一次迭代的残差 $r^{(k)} = d - G m^{(k)}$ 计算得出。\n\n在我们的问题中，我们从 $k=0$ 开始执行一次迭代。初始模型是 $m^{(0)} = 0 \\in \\mathbb{R}^{20}$。\n因此，初始残差为 $r^{(0)} = d - G m^{(0)} = d$。题目给出了这些残差的值。\n\n首先，我们确定权重。权重由阈值 $\\delta=1$ 的 Huber 损失函数 $\\rho_{\\delta}(r)$ 导出。IRLS 的权重函数 $w(r)$ 由 $w(r) = \\frac{\\psi(r)}{r}$ 给出，其中 $\\psi(r) = \\rho'_{\\delta}(r)$ 是影响函数（损失函数的导数）。\nHuber 损失函数为：\n$$\n\\rho_{\\delta}(r) = \n\\begin{cases}\n\\frac{1}{2} r^{2},  |r| \\le \\delta \\\\\n\\delta|r| - \\frac{1}{2}\\delta^{2},  |r| > \\delta\n\\end{cases}\n$$\n其导数为：\n$$\n\\psi(r) = \n\\begin{cases}\nr,  |r| \\le \\delta \\\\\n\\delta \\cdot \\text{sgn}(r),  |r| > \\delta\n\\end{cases}\n$$\n相应的 IRLS 权重为：\n$$\nw(r) = \\frac{\\psi(r)}{r} = \n\\begin{cases}\n1,  |r| \\le \\delta \\\\\n\\frac{\\delta}{|r|},  |r| > \\delta\n\\end{cases}\n$$\n给定 $\\delta=1$，第 $i$ 个残差 $r_i$ 的权重是 $w_i = \\min(1, 1/|r_i|)$。\n\n我们得到了两组初始残差 $r^{(0)}$：$0.1$ 和 $5.0$。我们来计算它们的权重：\n- 对于残差 $r_i = 0.1$，我们有 $|r_i| = 0.1 \\le 1$。权重是 $w_i = 1$。\n- 对于残差 $r_i = 5.0$，我们有 $|r_i| = 5.0 > 1$。权重是 $w_i = \\frac{1}{|5.0|} = \\frac{1}{5} = 0.2$。\n\n接下来，我们分析加权正规方程的结构。矩阵 $A = G^T W^{(0)} G$ 是一个 $20 \\times 20$ 的矩阵。题目说明 $G$ 的每一行只包含一个 $1$ 和其余位置为零。这意味着对于每条射线 $i$，都恰好存在一个网格 $j$ 使得 $G_{ij} = 1$，并且对于所有 $k \\neq j$ 都有 $G_{ik} = 0$。\n$A$ 的第 $(j,k)$ 个元素是 $A_{jk} = \\sum_{i=1}^{50} G_{ij} w_i G_{ik}$。这个和仅在 $j=k$ 时非零，因为如果 $j \\neq k$，对于任何给定的行 $i$， $G_{ij}$ 或 $G_{ik}$ 中至少有一个必须为零。因此，$A = G^T W^{(0)} G$ 是一个对角矩阵。\n\n对角元素为：\n$$ A_{jj} = (G^T W^{(0)} G)_{jj} = \\sum_{i=1}^{50} G_{ij}^2 w_i^{(0)} = \\sum_{i \\in \\text{rays in cell } j} w_i^{(0)} $$\n右侧向量为 $b = G^T W^{(0)} d$。其第 $j$ 个分量为：\n$$ b_j = (G^T W^{(0)} d)_j = \\sum_{i=1}^{50} G_{ij} w_i^{(0)} d_i = \\sum_{i \\in \\text{rays in cell } j} w_i^{(0)} d_i $$\n由于 $A$ 是对角的，方程组 $A m^{(1)} = b$ 解耦，我们可以独立求解每个分量 $m_j^{(1)}$：\n$$ m_j^{(1)} = \\frac{b_j}{A_{jj}} = \\frac{\\sum_{i \\in \\text{rays in cell } j} w_i^{(0)} d_i}{\\sum_{i \\in \\text{rays in cell } j} w_i^{(0)}} $$\n这表明网格 $j$ 的更新慢度是穿过该网格的射线的初始残差（数据）的加权平均值。\n\n现在我们计算两组网格的 $m_j^{(1)}$ 的值。\n\n第一组：网格 $j \\in \\{1, 2, \\dots, 10\\}$\n对于这些网格中的每一个，都有 $3$ 条相关的射线。初始残差为 $\\{0.1, 0.1, 5.0\\}$。相应的权重为 $\\{1, 1, 0.2\\}$。\n权重之和为：\n$$ \\sum w_i^{(0)} = 1 + 1 + 0.2 = 2.2 $$\n加权残差之和为：\n$$ \\sum w_i^{(0)} d_i = (1 \\times 0.1) + (1 \\times 0.1) + (0.2 \\times 5.0) = 0.1 + 0.1 + 1.0 = 1.2 $$\n因此，对于 $j \\in \\{1, \\dots, 10\\}$，更新后的模型分量为：\n$$ m_j^{(1)} = \\frac{1.2}{2.2} = \\frac{12}{22} = \\frac{6}{11} $$\n\n第二组：网格 $j \\in \\{11, 12, \\dots, 20\\}$\n对于这些网格中的每一个，都有 $2$ 条相关的射线。初始残差为 $\\{0.1, 5.0\\}$。相应的权重为 $\\{1, 0.2\\}$。\n权重之和为：\n$$ \\sum w_i^{(0)} = 1 + 0.2 = 1.2 $$\n加权残差之和为：\n$$ \\sum w_i^{(0)} d_i = (1 \\times 0.1) + (0.2 \\times 5.0) = 0.1 + 1.0 = 1.1 $$\n因此，对于 $j \\in \\{11, \\dots, 20\\}$，更新后的模型分量为：\n$$ m_j^{(1)} = \\frac{1.1}{1.2} = \\frac{11}{12} $$\n\n最终更新的模型向量 $m^{(1)} \\in \\mathbb{R}^{20}$ 由这些值组成。前 $10$ 个条目是 $\\frac{6}{11}$，其余 $10$ 个条目是 $\\frac{11}{12}$。\n$$ m^{(1)} = \\left[ \\underbrace{\\frac{6}{11}, \\dots, \\frac{6}{11}}_{10 \\text{ times}}, \\underbrace{\\frac{11}{12}, \\dots, \\frac{11}{12}}_{10 \\text{ times}} \\right] $$",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{6}{11}  \\frac{6}{11}  \\frac{6}{11}  \\frac{6}{11}  \\frac{6}{11}  \\frac{6}{11}  \\frac{6}{11}  \\frac{6}{11}  \\frac{6}{11}  \\frac{6}{11}  \\frac{11}{12}  \\frac{11}{12}  \\frac{11}{12}  \\frac{11}{12}  \\frac{11}{12}  \\frac{11}{12}  \\frac{11}{12}  \\frac{11}{12}  \\frac{11}{12}  \\frac{11}{12} \\end{pmatrix} } $$"
        },
        {
            "introduction": "得到一个鲁棒的拟合结果并非终点；我们常常需要诊断哪些数据点在重加权方案下仍然具有显著影响力。这个高级实践将引导您推导出一个关键的诊断工具，用以量化每个数据点对最终解的影响。通过探索数据点的杠杆值（leverage）和其鲁棒残差之间的相互作用，您将学会识别那些可能需要进一步研究的高影响力观测值。",
            "id": "3605266",
            "problem": "考虑一个计算地球物理学中的线性化地震走时层析成像问题，其中一组 $n$ 个观测走时 $d \\in \\mathbb{R}^{n}$ 通过一个灵敏度矩阵 $G \\in \\mathbb{R}^{n \\times p}$ 与模型 $m \\in \\mathbb{R}^{p}$ 相关，关系式为 $d = G m + \\varepsilon$，其中 $\\varepsilon$ 代表加性噪声。为了减轻离群值和非高斯噪声的影响，反演使用迭代重加权最小二乘法 (IRLS) 进行，在给定的一次迭代中，当前的模型估计 $\\hat{m}$ 求解白化变量下的加权最小二乘法正规方程。定义白化设计矩阵 $\\tilde{X} = W^{1/2} G$ 和白化数据向量 $\\tilde{y} = W^{1/2} d$，其中 $W = \\operatorname{diag}(w_{1},\\dots,w_{n})$ 是一个对角权重矩阵，由一个带有影响函数 $\\psi$ 的稳健M估计器确定，使得在当前迭代中 $w_{i} = \\psi(u_{i}) / u_{i}$，并且 $u_{i}$ 是由 $u_{i} = z_{i} / s$ 定义的稳健残差，其中 $z_{i}$ 是白化残差向量 $z = \\tilde{y} - \\tilde{X} \\hat{m}$ 的第 $i$ 个分量，$s  0$ 是 $z$ 的一个稳健尺度估计。本次迭代的加权帽子矩阵是 $H = \\tilde{X} \\left(\\tilde{X}^{\\top} \\tilde{X}\\right)^{-1} \\tilde{X}^{\\top}$，第 $i$ 个数据点的杠杆值是 $h_{i} = H_{ii}$。\n\n从上述定义和正规方程的秩一更新的线性代数恒等式出发，推导一个在当前迭代中量化第 $i$ 个数据点（即使在降权后）对估计模型 $\\hat{m}$ 影响的无量纲诊断量。你的诊断量应该用杠杆值 $h_{i}$、稳健残差 $u_{i}$ 和参数维度 $p$ 来表示，并且它应该能捕捉到移除第 $i$ 个观测值时的“留一法”效应。请以单一的封闭形式解析表达式提供你的最终诊断量。不需要进行数值计算。将最终诊断量表示为一个无量纲的量。如果你引入任何辅助符号，请确保它们在问题陈述中已有定义。最终答案必须是单一的解析表达式。不要包含单位。",
            "solution": "用户要求我推导一个无量纲诊断量，用于在迭代重加权最小二乘法 (IRLS) 算法的背景下，量化第 $i$ 个数据点对估计模型参数 $\\hat{m}$ 的影响。该诊断量应基于“留一法”，并用杠杆值 $h_i$、稳健残差 $u_i$ 和参数维度 $p$ 来表示。\n\n该问题被表述为单次迭代中的加权最小二乘问题。模型估计 $\\hat{m}$ 最小化了加权残差平方和，这等价于对白化变量求解一个普通最小二乘 (OLS) 问题：\n$$ \\tilde{y} = \\tilde{X} m + \\tilde{\\varepsilon} $$\n模型参数的 OLS 解由正规方程给出：\n$$ \\hat{m} = (\\tilde{X}^{\\top} \\tilde{X})^{-1} \\tilde{X}^{\\top} \\tilde{y} $$\n\n第 $i$ 个数据点的影响是通过比较模型估计 $\\hat{m}$（用所有 $n$ 个数据点计算）和移除第 $i$ 个数据点后计算出的估计 $\\hat{m}_{(i)}$ 来确定的。令 $\\tilde{X}_{(i)}$ 为矩阵 $\\tilde{X}$ 去掉其第 $i$ 行 $\\tilde{x}_i^{\\top}$ 后的矩阵。类似地，令 $\\tilde{y}_{(i)}$ 为向量 $\\tilde{y}$ 去掉其第 $i$ 个元素 $\\tilde{y}_i$ 后的向量。那么“留一法”估计 $\\hat{m}_{(i)}$ 为：\n$$ \\hat{m}_{(i)} = (\\tilde{X}_{(i)}^{\\top} \\tilde{X}_{(i)})^{-1} \\tilde{X}_{(i)}^{\\top} \\tilde{y}_{(i)} $$\n\n问题陈述建议使用秩一更新的恒等式。$\\hat{m}_{(i)}$ 表达式中的矩阵可以与完整数据矩阵关联如下：\n$$ \\tilde{X}^{\\top} \\tilde{X} = \\sum_{j=1}^{n} \\tilde{x}_j \\tilde{x}_j^{\\top} = \\tilde{X}_{(i)}^{\\top} \\tilde{X}_{(i)} + \\tilde{x}_i \\tilde{x}_i^{\\top} $$\n$$ \\tilde{X}^{\\top} \\tilde{y} = \\sum_{j=1}^{n} \\tilde{x}_j \\tilde{y}_j = \\tilde{X}_{(i)}^{\\top} \\tilde{y}_{(i)} + \\tilde{x}_i \\tilde{y}_i $$\n所以，$\\tilde{X}_{(i)}^{\\top} \\tilde{X}_{(i)} = \\tilde{X}^{\\top} \\tilde{X} - \\tilde{x}_i \\tilde{x}_i^{\\top}$。这是正规方程矩阵的秩一降阶更新。我们使用 Sherman-Morrison-Woodbury 公式来求其逆，对于秩一更新，该公式为 $(A - uv^{\\top})^{-1} = A^{-1} + \\frac{A^{-1}uv^{\\top}A^{-1}}{1 - v^{\\top}A^{-1}u}$。这里，$A = \\tilde{X}^{\\top} \\tilde{X}$，且 $u = v = \\tilde{x}_i$。\n$$ (\\tilde{X}_{(i)}^{\\top} \\tilde{X}_{(i)})^{-1} = (\\tilde{X}^{\\top} \\tilde{X})^{-1} + \\frac{(\\tilde{X}^{\\top} \\tilde{X})^{-1} \\tilde{x}_i \\tilde{x}_i^{\\top} (\\tilde{X}^{\\top} \\tilde{X})^{-1}}{1 - \\tilde{x}_i^{\\top} (\\tilde{X}^{\\top} \\tilde{X})^{-1} \\tilde{x}_i} $$\n分母中包含杠杆值 $h_i$。帽子矩阵为 $H = \\tilde{X}(\\tilde{X}^{\\top} \\tilde{X})^{-1}\\tilde{X}^{\\top}$，其第 $i$ 个对角元素是 $h_i = H_{ii} = \\tilde{x}_i^{\\top} (\\tilde{X}^{\\top} \\tilde{X})^{-1} \\tilde{x}_i$。所以分母是 $1 - h_i$。\n\n现在我们可以表示差值 $\\hat{m} - \\hat{m}_{(i)}$：\n$$ \\hat{m}_{(i)} = \\left[ (\\tilde{X}^{\\top} \\tilde{X})^{-1} + \\frac{(\\tilde{X}^{\\top} \\tilde{X})^{-1} \\tilde{x}_i \\tilde{x}_i^{\\top} (\\tilde{X}^{\\top} \\tilde{X})^{-1}}{1 - h_i} \\right] (\\tilde{X}^{\\top} \\tilde{y} - \\tilde{x}_i \\tilde{y}_i) $$\n展开此表达式并代入 $\\hat{m} = (\\tilde{X}^{\\top} \\tilde{X})^{-1} \\tilde{X}^{\\top} \\tilde{y}$ 会导致冗长的计算。一个更直接的方法是计算变化量 $\\Delta \\hat{m}_i = \\hat{m} - \\hat{m}_{(i)}$。\n一个可以从上述步骤推导出的著名恒等式，将估计值的变化与被省略点的残差和杠杆值联系起来：\n$$ \\Delta \\hat{m}_i = \\hat{m} - \\hat{m}_{(i)} = \\frac{(\\tilde{X}^{\\top} \\tilde{X})^{-1} \\tilde{x}_i (\\tilde{y}_i - \\tilde{x}_i^{\\top} \\hat{m})}{1 - h_i} $$\n项 $\\tilde{y}_i - \\tilde{x}_i^{\\top} \\hat{m}$ 是第 $i$ 个白化残差，在问题中定义为 $z_i$，即向量 $z = \\tilde{y} - \\tilde{X} \\hat{m}$ 的第 $i$ 个分量。\n$$ \\Delta \\hat{m}_i = \\frac{z_i}{1 - h_i} (\\tilde{X}^{\\top} \\tilde{X})^{-1} \\tilde{x}_i $$\n\n一个用于衡量对整个参数向量 $\\hat{m}$ 影响的标准无量纲诊断量是库克距离 (Cook's distance)，$D_i$。它测量 $\\hat{m}$ 和 $\\hat{m}_{(i)}$ 之间的马氏距离 (Mahalanobis distance) 的平方。该度量源自 $\\hat{m}$ 的协方差矩阵，对于白化问题，该矩阵为 $\\text{Cov}(\\hat{m}) = \\sigma^2 (\\tilde{X}^{\\top} \\tilde{X})^{-1}$，其中 $\\sigma^2$ 是白化误差的方差。该诊断量定义为：\n$$ D_i = \\frac{(\\hat{m} - \\hat{m}_{(i)})^{\\top} (\\tilde{X}^{\\top} \\tilde{X}) (\\hat{m} - \\hat{m}_{(i)})}{p \\hat{\\sigma}^2} $$\n因子 $p$ 是模型空间的维度，$\\hat{\\sigma}^2$ 是误差方差的估计。在这种稳健的设定下，我们使用提供的稳健尺度估计 $s$，因此 $\\hat{\\sigma}^2 = s^2$。\n\n我们来计算分子：\n$$ (\\Delta \\hat{m}_i)^{\\top} (\\tilde{X}^{\\top} \\tilde{X}) (\\Delta \\hat{m}_i) = \\left( \\frac{z_i}{1 - h_i} \\tilde{x}_i^{\\top} (\\tilde{X}^{\\top} \\tilde{X})^{-1} \\right) (\\tilde{X}^{\\top} \\tilde{X}) \\left( \\frac{z_i}{1 - h_i} (\\tilde{X}^{\\top} \\tilde{X})^{-1} \\tilde{x}_i \\right) $$\n$$ = \\frac{z_i^2}{(1 - h_i)^2} \\left( \\tilde{x}_i^{\\top} (\\tilde{X}^{\\top} \\tilde{X})^{-1} (\\tilde{X}^{\\top} \\tilde{X}) (\\tilde{X}^{\\top} \\tilde{X})^{-1} \\tilde{x}_i \\right) $$\n$$ = \\frac{z_i^2}{(1 - h_i)^2} \\left( \\tilde{x}_i^{\\top} (\\tilde{X}^{\\top} \\tilde{X})^{-1} \\tilde{x}_i \\right) $$\n括号中的项恰好是杠杆值 $h_i$。所以分子是：\n$$ (\\Delta \\hat{m}_i)^{\\top} (\\tilde{X}^{\\top} \\tilde{X}) (\\Delta \\hat{m}_i) = \\frac{z_i^2 h_i}{(1 - h_i)^2} $$\n\n将此结果代入 $D_i$ 的表达式，并令 $\\hat{\\sigma}^2 = s^2$：\n$$ D_i = \\frac{1}{p s^2} \\frac{z_i^2 h_i}{(1 - h_i)^2} $$\n问题要求最终表达式用 $u_i$、$h_i$ 和 $p$ 表示。我们已知稳健残差的定义为 $u_i = z_i / s$，这意味着 $z_i = s u_i$。将此代入我们的 $D_i$ 表达式中：\n$$ D_i = \\frac{1}{p s^2} \\frac{(s u_i)^2 h_i}{(1 - h_i)^2} = \\frac{s^2 u_i^2 h_i}{p s^2 (1 - h_i)^2} $$\n尺度估计 $s^2$ 被消去，得到最终的无量纲诊断量：\n$$ D_i = \\frac{u_i^2 h_i}{p (1 - h_i)^2} $$\n这个表达式捕捉了第 $i$ 个数据点的影响。如果稳健残差 $u_i$ 很大（该点在 $y$ 方向上是离群值），或者如果杠杆值 $h_i$ 很高（该点在模型空间或 $x$ 方向上是离群值），则影响很大。杠杆值接近 1 的点具有极大的影响力。该诊断量是无量纲的，并且只依赖于问题陈述中指定的量。",
            "answer": "$$\\boxed{\\frac{u_i^2 h_i}{p(1 - h_i)^2}}$$"
        }
    ]
}