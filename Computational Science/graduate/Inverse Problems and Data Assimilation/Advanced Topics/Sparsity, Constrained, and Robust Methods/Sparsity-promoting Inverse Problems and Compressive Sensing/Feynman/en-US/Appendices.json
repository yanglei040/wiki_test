{
    "hands_on_practices": [
        {
            "introduction": "The Basis Pursuit (BP) problem is a cornerstone of sparse recovery, seeking the solution with the minimum $\\ell_1$ norm that perfectly fits the observed data. While modern algorithms can solve large-scale versions of this problem, understanding its solution through the lens of convex duality provides invaluable insight into the fundamental structure of sparsity-promoting inverse problems. This exercise  guides you through deriving and solving the dual problem, using the resulting optimality conditions to uncover the unique sparse solution, thereby connecting abstract theory to a tangible result.",
            "id": "3420230",
            "problem": "Consider a data assimilation setting in which an unknown two-dimensional state vector $x \\in \\mathbb{R}^{2}$ is observed by a single linear sensor. The observation operator is represented by the matrix $A \\in \\mathbb{R}^{1 \\times 2}$ and the measured datum is $y \\in \\mathbb{R}$. In order to promote sparsity in the recovered state, we solve the Basis Pursuit (BP) inverse problem, which minimizes the $\\ell_{1}$ norm of $x$ subject to the observation constraint. Specifically, take\n$$\nA = \\begin{pmatrix} 2  -1 \\end{pmatrix}, \\quad y = 3,\n$$\nand consider the BP problem\n$$\n\\min_{x \\in \\mathbb{R}^{2}} \\|x\\|_{1} \\quad \\text{subject to} \\quad A x = y.\n$$\nStarting from first principles of convex analysis and duality, use the definitions of the convex conjugate, dual norm, and saddle-point optimality conditions to:\n1. Derive the dual problem associated with the above BP formulation by eliminating the primal variable through the Lagrangian and identifying the dual feasible set via the $\\ell_{\\infty}$ norm.\n2. Solve the resulting dual problem explicitly for the optimal multiplier.\n3. Recover the primal minimizer by enforcing feasibility and complementary slackness through the subgradient characterization of the $\\ell_{1}$ norm.\n\nExpress your final answer as the primal minimizer $x^{\\star}$, written exactly as a single row vector with rational entries. No rounding is required and no units are to be reported.",
            "solution": "The user wants me to solve a Basis Pursuit (BP) problem using duality theory.\n\n**Problem Breakdown:**\n\n1.  **Primal Problem:**\n    -   Minimize $\\|x\\|_1$ for $x \\in \\mathbb{R}^2$.\n    -   Subject to the constraint $Ax = y$.\n    -   Given: $A = \\begin{pmatrix} 2  -1 \\end{pmatrix}$ and $y = 3$.\n\n2.  **Tasks:**\n    -   **Task 1: Derive the Dual Problem.**\n        -   Use the Lagrangian.\n        -   Eliminate the primal variable $x$.\n        -   Identify the dual feasible set using the $\\ell_\\infty$ norm. This hints at the relationship between the $\\ell_1$ and $\\ell_\\infty$ norms being duals.\n    -   **Task 2: Solve the Dual Problem.**\n        -   Find the optimal dual variable (Lagrange multiplier).\n    -   **Task 3: Recover the Primal Solution.**\n        -   Use feasibility ($Ax^\\star = y$).\n        -   Use complementary slackness, which will involve the subgradient of the $\\ell_1$ norm.\n\n**Step-by-Step Plan:**\n\n**Part 1: Validation**\n\n1.  **Extract Givens:**\n    -   $x \\in \\mathbb{R}^2$ is the unknown state vector.\n    -   $A = \\begin{pmatrix} 2  -1 \\end{pmatrix} \\in \\mathbb{R}^{1 \\times 2}$ is the observation operator.\n    -   $y = 3 \\in \\mathbb{R}$ is the measured datum.\n    -   The problem is: $\\min_{x \\in \\mathbb{R}^{2}} \\|x\\|_{1} \\quad \\text{subject to} \\quad A x = y$.\n    -   $\\|x\\|_1 = |x_1| + |x_2|$.\n    -   The task requires using convex analysis, duality, convex conjugate, dual norm, saddle-point optimality, and subgradients.\n\n2.  **Validate:**\n    -   **Scientifically Grounded:** The problem is a standard exercise in convex optimization, specifically in the field of compressive sensing and inverse problems. The concepts (Basis Pursuit, $\\ell_1$ norm, Lagrangian duality) are well-established in mathematics and signal processing. Yes, it's grounded.\n    -   **Well-Posed:** The problem is a linear program (can be rewritten as one). The objective function is convex ($\\ell_1$ norm) and the constraint set is a non-empty affine subspace (a line in $\\mathbb{R}^2$). A minimizer is guaranteed to exist. Whether it's unique is part of the problem's interest, but the problem of finding *a* minimizer is well-posed. The problem is structured to have a unique solution in this case, as we'll likely see.\n    -   **Objective:** The language is precise and mathematical. No subjective statements.\n    -   **Invalidity Checklist:**\n        1.  No scientific/factual unsoundness.\n        2.  Directly related to the topic of sparsity-promoting inverse problems. It's a classic example.\n        3.  The setup is complete. $A$ and $y$ are given. The problem is fully specified.\n        4.  The conditions are not physically impossible. It's a mathematical problem.\n        5.  Not ill-posed.\n        6.  Not trivial. It requires a solid understanding of duality theory. It's not pseudo-profound but a standard textbook-level problem.\n        7.  It is verifiable through mathematical derivation.\n\n3.  **Verdict:** The problem is **valid**. I will proceed with the solution.\n\n**Part 2: Solution Derivation**\n\n**Task 1: Derive the Dual Problem**\n\n1.  **Form the Lagrangian:**\n    The problem is $\\min_x \\|x\\|_1$ subject to $Ax - y = 0$.\n    The Lagrangian is $\\mathcal{L}(x, \\lambda) = \\|x\\|_1 + \\lambda^T(Ax - y)$.\n    Here, $x \\in \\mathbb{R}^2$ is the primal variable, and $\\lambda \\in \\mathbb{R}^1$ (a scalar) is the dual variable (Lagrange multiplier).\n    $\\mathcal{L}(x, \\lambda) = \\|x\\|_1 + \\lambda(Ax - y) = \\|x\\|_1 + \\lambda A x - \\lambda y$.\n    Since $\\lambda$ is a scalar and $A$ is a row vector, $\\lambda A$ is a row vector. So this should be $\\lambda (A_{11} x_1 + A_{12} x_2 - y)$.\n    It is more standard to write the inner product as $\\langle \\lambda, Ax - y \\rangle$.\n    Since the dual space of $\\mathbb{R}^1$ is $\\mathbb{R}^1$, $\\lambda$ is just a scalar.\n    $\\mathcal{L}(x, \\lambda) = \\|x\\|_1 + \\lambda ( (2, -1) \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} - 3 ) = \\|x\\|_1 + \\lambda(2x_1 - x_2 - 3)$.\n    Rearranging terms:\n    $\\mathcal{L}(x, \\lambda) = \\|x\\|_1 + (2\\lambda x_1 - \\lambda x_2) - 3\\lambda$.\n    This can be written using dot products: $\\mathcal{L}(x, \\lambda) = \\|x\\|_1 + \\langle A^T \\lambda, x \\rangle - \\langle y, \\lambda \\rangle$.\n    Here, $A^T = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$. $A^T \\lambda = \\begin{pmatrix} 2\\lambda \\\\ -\\lambda \\end{pmatrix}$.\n    So, $\\langle A^T \\lambda, x \\rangle = (2\\lambda) x_1 + (-\\lambda) x_2$. This matches.\n\n2.  **Find the Lagrange Dual Function:**\n    The dual function $g(\\lambda)$ is the infimum of the Lagrangian over the primal variable $x$:\n    $g(\\lambda) = \\inf_{x \\in \\mathbb{R}^2} \\mathcal{L}(x, \\lambda) = \\inf_{x \\in \\mathbb{R}^2} (\\|x\\|_1 + \\langle A^T \\lambda, x \\rangle - y \\lambda)$.\n    The term $-y\\lambda$ is constant with respect to $x$.\n    $g(\\lambda) = -y \\lambda + \\inf_{x \\in \\mathbb{R}^2} (\\|x\\|_1 + \\langle A^T \\lambda, x \\rangle)$.\n\n3.  **Use the Convex Conjugate:**\n    The convex conjugate of a function $f(x)$ is $f^*(z) = \\sup_x (\\langle z, x \\rangle - f(x))$.\n    So, $\\inf_x (f(x) - \\langle z, x \\rangle) = - \\sup_x (\\langle z, x \\rangle - f(x)) = -f^*(z)$.\n    In our case, $f(x) = \\|x\\|_1$. We have $\\inf_x (\\|x\\|_1 + \\langle A^T \\lambda, x \\rangle)$.\n    This is $\\inf_x(f(x) - \\langle -A^T\\lambda, x \\rangle)$.\n    So, we need the conjugate of the $\\ell_1$ norm.\n    Let $z = -A^T \\lambda$. We need to compute $f^*(z)$.\n    $f^*(z) = \\sup_x (\\langle z, x \\rangle - \\|x\\|_1) = \\sup_x \\left( \\sum_i z_i x_i - \\sum_i |x_i| \\right) = \\sum_i \\sup_{x_i} (z_i x_i - |x_i|)$.\n    Consider the term $\\sup_{x_i} (z_i x_i - |x_i|)$.\n    - If $|z_i|  1$, say $z_i  1$, we can choose $x_i  0$. Then $z_i x_i - |x_i| = (z_i - 1)x_i$. As $x_i \\to \\infty$, this goes to $\\infty$.\n    - If $z_i  -1$, we can choose $x_i  0$. Then $z_i x_i - |x_i| = z_i x_i - (-x_i) = (z_i+1)x_i$. As $x_i \\to -\\infty$, this goes to $\\infty$.\n    - If $|z_i| \\le 1$, then $z_i x_i \\le |z_i||x_i| \\le |x_i|$. So $z_i x_i - |x_i| \\le 0$. The supremum is achieved at $x_i=0$, where the value is $0$.\n    So, the conjugate of the $\\ell_1$ norm is an indicator function:\n    $f^*(z) = (\\|\\cdot\\|_1)^*(z) = \\begin{cases} 0  \\text{if } \\|z\\|_{\\infty} \\le 1 \\\\ \\infty  \\text{if } \\|z\\|_{\\infty}  1 \\end{cases}$.\n    Here, $\\|z\\|_\\infty = \\max_i |z_i|$.\n\n4.  **Connect back to the Dual Function:**\n    $g(\\lambda) = -y \\lambda + \\inf_{x \\in \\mathbb{R}^2} (\\|x\\|_1 + \\langle A^T \\lambda, x \\rangle)$.\n    Let $v = A^T \\lambda$. The infimum term is $\\inf_x (\\|x\\|_1 + \\langle v, x \\rangle) = -\\sup_x(-\\langle v, x \\rangle - \\|x\\|_1) = -\\sup_x(\\langle -v, x \\rangle - \\|x\\|_1)$.\n    This is the negative of the conjugate of $\\|\\cdot\\|_1$ evaluated at $-v = -A^T\\lambda$.\n    So, $\\inf_x (\\|x\\|_1 + \\langle A^T \\lambda, x \\rangle) = -(\\|\\cdot\\|_1)^*(-A^T\\lambda)$.\n    From the previous step, this is:\n    $\\begin{cases} 0  \\text{if } \\|-A^T\\lambda\\|_{\\infty} \\le 1 \\\\ -\\infty  \\text{if } \\|-A^T\\lambda\\|_{\\infty}  1 \\end{cases}$.\n    Note that $\\| -v \\|_\\infty = \\|v\\|_\\infty$, so the condition is $\\|A^T\\lambda\\|_{\\infty} \\le 1$.\n\n5.  **Formulate the Dual Problem:**\n    The dual problem is to maximize the dual function $g(\\lambda)$:\n    $\\max_{\\lambda \\in \\mathbb{R}} g(\\lambda)$.\n    Since $g(\\lambda) = -\\infty$ outside the feasible set, this is equivalent to:\n    $\\max_{\\lambda \\in \\mathbb{R}} \\quad -y \\lambda$\n    subject to $\\quad \\|A^T \\lambda\\|_{\\infty} \\le 1$.\n\n    This completes Task 1. Let's write it out with the specific values.\n    $A = \\begin{pmatrix} 2  -1 \\end{pmatrix}$, so $A^T = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$.\n    $A^T \\lambda = \\begin{pmatrix} 2\\lambda \\\\ -\\lambda \\end{pmatrix}$.\n    $\\|A^T \\lambda\\|_{\\infty} = \\max(|2\\lambda|, |-\\lambda|) = \\max(2|\\lambda|, |\\lambda|) = 2|\\lambda|$.\n    The constraint is $2|\\lambda| \\le 1$, which is $|\\lambda| \\le 1/2$.\n    The dual problem is:\n    $\\max_{\\lambda \\in \\mathbb{R}} \\quad -3\\lambda$\n    subject to $\\quad -1/2 \\le \\lambda \\le 1/2$.\n\n**Task 2: Solve the Dual Problem**\n\n-   We need to maximize $f(\\lambda) = -3\\lambda$ over the interval $[-1/2, 1/2]$.\n-   The function $f(\\lambda)$ is a decreasing linear function of $\\lambda$.\n-   To maximize it, we must choose the smallest possible value of $\\lambda$.\n-   The minimum value of $\\lambda$ in the feasible set $[-1/2, 1/2]$ is $\\lambda = -1/2$.\n-   So, the dual optimal solution is $\\lambda^\\star = -1/2$.\n-   The optimal value of the dual problem is $-3(\\lambda^\\star) = -3(-1/2) = 3/2$.\n-   By strong duality (which holds for this convex problem, e.g., Slater's condition is satisfied), the optimal value of the primal problem is also $3/2$. So, $\\|x^\\star\\|_1 = 3/2$. This is a good check.\n\n**Task 3: Recover the Primal Solution**\n\nWe use the Karush-Kuhn-Tucker (KKT) conditions, or more generally, the saddle point optimality conditions.\nAt the optimum $(x^\\star, \\lambda^\\star)$, we have:\n$\\mathcal{L}(x^\\star, \\lambda^\\star) = \\inf_x \\mathcal{L}(x, \\lambda^\\star) = \\sup_\\lambda \\mathcal{L}(x^\\star, \\lambda)$.\n\nThe first condition, $\\mathcal{L}(x^\\star, \\lambda^\\star) = \\inf_x \\mathcal{L}(x, \\lambda^\\star)$, means that $x^\\star$ minimizes the Lagrangian with the optimal dual variable fixed.\n$x^\\star \\in \\arg\\min_x (\\|x\\|_1 + \\langle A^T \\lambda^\\star, x \\rangle - y\\lambda^\\star)$.\nThis is equivalent to $x^\\star \\in \\arg\\min_x (\\|x\\|_1 + \\langle A^T \\lambda^\\star, x \\rangle)$.\nThe optimality condition for this unconstrained minimization is that $0$ must be in the subdifferential of the objective function at $x^\\star$.\n$0 \\in \\partial (\\|x^\\star\\|_1 + \\langle A^T \\lambda^\\star, x^\\star \\rangle) = \\partial \\|x^\\star\\|_1 + A^T \\lambda^\\star$.\nThis gives the condition:\n$-A^T \\lambda^\\star \\in \\partial \\|x^\\star\\|_1$.\n\nLet's compute $-A^T \\lambda^\\star$:\n$\\lambda^\\star = -1/2$.\n$A^T = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$.\n$-A^T \\lambda^\\star = - \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} (-1/2) = \\begin{pmatrix} 1 \\\\ -1/2 \\end{pmatrix}$.\nLet this vector be $v = \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -1/2 \\end{pmatrix}$.\n\nNow we need the subdifferential of the $\\ell_1$ norm.\n$\\partial \\|x\\|_1 = \\{ z \\in \\mathbb{R}^n \\mid z_i = \\text{sgn}(x_i) \\text{ if } x_i \\ne 0, \\text{ and } z_i \\in [-1, 1] \\text{ if } x_i=0 \\}$.\nThe condition $v \\in \\partial \\|x^\\star\\|_1$ means:\n$v_i = \\text{sgn}(x^\\star_i)$ if $x^\\star_i \\ne 0$.\n$|v_i| \\le 1$ if $x^\\star_i = 0$.\n\nThis implies:\n- From $v_1 = 1$: since $|v_1|=1$, we know that $\\text{sgn}(x^\\star_1)$ must be $1$ if $x^\\star_1 \\ne 0$. So $x^\\star_1 \\ge 0$.\n- From $v_2 = -1/2$: since $|v_2|  1$, we must have $x^\\star_2 = 0$.\n\nSo far, $x^\\star = \\begin{pmatrix} x^\\star_1 \\\\ 0 \\end{pmatrix}$ with $x^\\star_1 \\ge 0$.\n\nPrimal feasibility:\n$A x^\\star = y$.\n$(2, -1) \\begin{pmatrix} x^\\star_1 \\\\ 0 \\end{pmatrix} = 3$.\n$2 x^\\star_1 = 3$.\n$x^\\star_1 = 3/2$.\n\nThis result, $x^\\star_1=3/2$, is consistent with the condition $x_1^\\star \\ge 0$.\nThus, the primal minimizer is $x^\\star = \\begin{pmatrix} 3/2 \\\\ 0 \\end{pmatrix}$.\nThe final answer must be a row vector with rational entries: $\\begin{pmatrix} \\frac{3}{2}  0 \\end{pmatrix}$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{3}{2}  0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While duality offers a complete theoretical picture for simple problems, most real-world applications rely on iterative algorithms to handle noise and scale. The Iterative Shrinkage-Thresholding Algorithm (ISTA) is a fundamental first-order method for solving the LASSO and related problems, elegantly decomposing the optimization into a standard gradient step and a simple proximal step. This hands-on implementation practice  will solidify your understanding of ISTA's mechanics and allow you to empirically verify its theoretical convergence guarantee, a critical skill for any practitioner in the field.",
            "id": "3420203",
            "problem": "Consider the composite convex objective function $f(x) = g(x) + \\lambda \\|x\\|_{1}$, where $g(x)$ is a differentiable convex function with Lipschitz continuous gradient $\\nabla g$ and $\\lambda \\geq 0$. In the standard sparse linear inverse problem model, let $g(x) = \\tfrac{1}{2}\\|A x - b\\|_{2}^{2}$, where $A \\in \\mathbb{R}^{m \\times n}$ and $b \\in \\mathbb{R}^{m}$ are given. The gradient is $\\nabla g(x) = A^{\\top}(A x - b)$, and a valid Lipschitz constant for $\\nabla g$ is $L = \\lambda_{\\max}(A^{\\top}A)$, where $\\lambda_{\\max}$ denotes the largest eigenvalue. The Iterative Shrinkage-Thresholding Algorithm (ISTA) for $f(x)$ with step size $\\alpha$ satisfying $\\alpha \\leq 1/L$ updates $x$ by\n$$\nx^{k+1} = S_{\\lambda \\alpha}\\left(x^{k} - \\alpha \\nabla g(x^{k})\\right),\n$$\nwhere $S_{\\tau}$ is the coordinate-wise soft-thresholding operator defined by $S_{\\tau}(u)_{i} = \\operatorname{sign}(u_{i}) \\max(|u_{i}| - \\tau, 0)$.\n\nStarting from the zero vector $x^{0} = 0$, implement ISTA for a fixed number of iterations $T$ on each of the following test cases. For each test case, compute $L = \\lambda_{\\max}(A^{\\top}A)$ exactly, set $\\alpha = \\eta/L$ using the provided factor $\\eta$, run ISTA for $T$ iterations, and record the sequence of objective values $f(x^{k})$ for $k = 0, 1, \\dots, T$. Use the Euclidean norm $\\|\\cdot\\|_{2}$ and the one-norm $\\|\\cdot\\|_{1}$. The entries below are exact rational values. No physical units apply.\n\nTest suite:\n- Case $1$ (general well-conditioned, boundary step size):\n  - $A \\in \\mathbb{R}^{4 \\times 6}$ is\n    $$\n    A = \\begin{bmatrix}\n    1  0  1  0  2  -1 \\\\\n    0  1  -1  2  0  1 \\\\\n    2  -1  0  1  1  0 \\\\\n    0  2  1  -1  0  1\n    \\end{bmatrix}.\n    $$\n  - $b \\in \\mathbb{R}^{4}$ is $b = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ -1 \\end{bmatrix}$.\n  - $\\lambda = 0.1$.\n  - $T = 10$.\n  - $\\eta = 1.0$ (so $\\alpha = 1/L$).\n- Case $2$ (rank-deficient sensing, zero data, conservative step size):\n  - $A \\in \\mathbb{R}^{3 \\times 5}$ is\n    $$\n    A = \\begin{bmatrix}\n    1  0  1  0  2 \\\\\n    0  1  0  1  1 \\\\\n    1  0  1  0  2\n    \\end{bmatrix}.\n    $$\n  - $b \\in \\mathbb{R}^{3}$ is $b = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$.\n  - $\\lambda = 0.2$.\n  - $T = 8$.\n  - $\\eta = 0.9$ (so $\\alpha = 0.9/L$).\n- Case $3$ (diagonal sensing, strong sparsity penalty, boundary step size):\n  - $A \\in \\mathbb{R}^{5 \\times 5}$ is\n    $$\n    A = \\begin{bmatrix}\n    1  0  0  0  0 \\\\\n    0  0.5  0  0  0 \\\\\n    0  0  2  0  0 \\\\\n    0  0  0  1.5  0 \\\\\n    0  0  0  0  0.8\n    \\end{bmatrix}.\n    $$\n  - $b \\in \\mathbb{R}^{5}$ is $b = \\begin{bmatrix} 1 \\\\ -1 \\\\ 2 \\\\ -2 \\\\ 0.5 \\end{bmatrix}$.\n  - $\\lambda = 0.5$.\n  - $T = 8$.\n  - $\\eta = 1.0$ (so $\\alpha = 1/L$).\n- Case $4$ (moderate regularization off, under boundary):\n  - $A \\in \\mathbb{R}^{4 \\times 4}$ is\n    $$\n    A = \\begin{bmatrix}\n    2  -1  0  1 \\\\\n    0  1  2  -1 \\\\\n    1  0  -1  2 \\\\\n    -2  1  0  1\n    \\end{bmatrix}.\n    $$\n  - $b \\in \\mathbb{R}^{4}$ is $b = \\begin{bmatrix} 1 \\\\ -2 \\\\ 0 \\\\ 3 \\end{bmatrix}$.\n  - $\\lambda = 0$.\n  - $T = 6$.\n  - $\\eta = 0.8$ (so $\\alpha = 0.8/L$).\n\nFor each case, output two items: the list of objective values $[f(x^{0}), f(x^{1}), \\dots, f(x^{T})]$ and a boolean indicating whether the sequence is nonincreasing (monotone decrease in the sense of $f(x^{k+1}) \\leq f(x^{k})$ for all $k$). Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a two-element list of the form $[\\text{objective\\_sequence}, \\text{is\\_monotone}]$. For example, the overall output format is $[[\\cdots, \\cdots],[\\cdots, \\cdots],[\\cdots, \\cdots],[\\cdots, \\cdots]]$ with no additional text.",
            "solution": "The user wants to implement the Iterative Shrinkage-Thresholding Algorithm (ISTA) to solve a sparse inverse problem and analyze its behavior across several test cases.\n\n### Step 1: Extract Givens\nThe problem defines a composite convex objective function $f(x) = g(x) + \\lambda \\|x\\|_{1}$, where $g(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$.\nThe gradient of the smooth part $g(x)$ is $\\nabla g(x) = A^{\\top}(A x - b)$.\nThe Lipschitz constant of the gradient $\\nabla g$ is given by $L = \\lambda_{\\max}(A^{\\top}A)$, where $\\lambda_{\\max}$ is the largest eigenvalue.\nThe ISTA update rule is given by:\n$$x^{k+1} = S_{\\lambda \\alpha}\\left(x^{k} - \\alpha \\nabla g(x^{k})\\right)$$\nwhere $S_{\\tau}$ is the soft-thresholding operator, defined coordinate-wise as $S_{\\tau}(u)_{i} = \\operatorname{sign}(u_{i}) \\max(|u_{i}| - \\tau, 0)$.\nThe initial condition is $x^{0} = 0$.\nThe step size is $\\alpha = \\eta/L$.\nThe task is to compute the sequence of objective values $f(x^k)$ for $k=0, 1, \\dots, T$ and to check if this sequence is non-increasing.\n\nThe problem provides four test cases with specific parameters:\n- **Case 1**:\n  - $A = \\begin{bmatrix} 1  0  1  0  2  -1 \\\\ 0  1  -1  2  0  1 \\\\ 2  -1  0  1  1  0 \\\\ 0  2  1  -1  0  1 \\end{bmatrix}$\n  - $b = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ -1 \\end{bmatrix}$\n  - $\\lambda = 0.1$\n  - $T = 10$\n  - $\\eta = 1.0$\n- **Case 2**:\n  - $A = \\begin{bmatrix} 1  0  1  0  2 \\\\ 0  1  0  1  1 \\\\ 1  0  1  0  2 \\end{bmatrix}$\n  - $b = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$\n  - $\\lambda = 0.2$\n  - $T = 8$\n  - $\\eta = 0.9$\n- **Case 3**:\n  - $A = \\mathrm{diag}(1, 0.5, 2, 1.5, 0.8)$\n  - $b = \\begin{bmatrix} 1 \\\\ -1 \\\\ 2 \\\\ -2 \\\\ 0.5 \\end{bmatrix}$\n  - $\\lambda = 0.5$\n  - $T = 8$\n  - $\\eta = 1.0$\n- **Case 4**:\n  - $A = \\begin{bmatrix} 2  -1  0  1 \\\\ 0  1  2  -1 \\\\ 1  0  -1  2 \\\\ -2  1  0  1 \\end{bmatrix}$\n  - $b = \\begin{bmatrix} 1 \\\\ -2 \\\\ 0 \\\\ 3 \\end{bmatrix}$\n  - $\\lambda = 0$\n  - $T = 6$\n  - $\\eta = 0.8$\n\nThe required output for each case is a list containing two elements: the sequence of objective values $[f(x^0), \\dots, f(x^T)]$ and a boolean indicating if the sequence is non-increasing ($f(x^{k+1}) \\le f(x^k)$ for all $k$).\n\n### Step 2: Validate Using Extracted Givens\nThe problem is validated against the specified criteria.\n- **Scientifically Grounded**: The problem statement is based on the well-established theory of convex optimization and sparse signal recovery. The ISTA algorithm, the LASSO objective function, the concept of Lipschitz continuity, and the choice of step size are all standard and correct elements of this field.\n- **Well-Posed**: The problem is a computational task, not a theoretical one about the existence of a minimizer. For each test case, all necessary components ($A$, $b$, $\\lambda$, $T$, $\\eta$, $x^0$) are provided. The algorithm is deterministic and can be executed for the specified number of iterations to produce a unique computational result.\n- **Objective**: The problem is stated using precise mathematical definitions and numerical data. There is no subjective or ambiguous language.\n- **Completeness and Consistency**: The problem is self-contained. All matrices, vectors, and parameters are fully specified. There are no contradictions. For instance, in Case 4 where $\\lambda=0$, the $\\ell_1$ term vanishes, and ISTA correctly simplifies to gradient descent for a quadratic function, which is a consistent special case.\n- **Realism and Feasibility**: The problem involves numerical simulations. The matrix and vector dimensions are small and the number of iterations is low, making the computations entirely feasible. The numerical values are standard for such examples.\n- **Other Flaws**: The problem is a direct and non-trivial application of a standard numerical algorithm. It is not tautological, metaphorical, or outside the scope of scientific verifiability.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided by implementing the ISTA algorithm as described.\n\n### Algorithmic Design and Implementation\nThe solution involves implementing the ISTA algorithm and applying it to each of the four test cases. The core logic for each case is as follows:\n\n1.  **Initialization**: Given the matrices $A$, $b$, and parameters $\\lambda$, $T$, $\\eta$ for a case, initialize the solution vector $x^k$ at $k=0$ as the zero vector, $x^0 = 0 \\in \\mathbb{R}^n$.\n\n2.  **L-constant Calculation**: Compute the Lipschitz constant $L = \\lambda_{\\max}(A^{\\top}A)$. Since $A^{\\top}A$ is a real, symmetric, positive semi-definite matrix, its eigenvalues are real and non-negative. We can compute them reliably using a numerical linear algebra library. The largest eigenvalue is $L$.\n\n3.  **Step-Size Calculation**: Determine the algorithm's step size $\\alpha = \\eta/L$. Also, pre-calculate the threshold for the soft-thresholding operator, $\\tau = \\lambda \\alpha$.\n\n4.  **Iteration**: Loop for $k = 0, 1, \\dots, T$. In each step of the loop:\n    a.  **Objective Evaluation**: Calculate the objective function value $f(x^k) = \\frac{1}{2}\\|A x^k - b\\|_{2}^{2} + \\lambda \\|x^k\\|_{1}$. Store this value in a sequence.\n    b.  **Update Step (for $k  T$)**: If it is not the last iteration, compute the next iterate $x^{k+1}$.\n        i.  **Gradient Calculation**: Compute the gradient of the smooth term, $\\nabla g(x^k) = A^{\\top}(A x^k - b)$.\n        ii. **Gradient Descent Step**: Take a step in the negative gradient direction: $u = x^k - \\alpha \\nabla g(x^k)$.\n        iii. **Proximal Step (Soft-Thresholding)**: Apply the soft-thresholding operator to obtain the next iterate: $x^{k+1} = S_{\\tau}(u)$. The operator acts element-wise.\n\n5.  **Monotonicity Check**: After the loop concludes, the sequence of objective values $[f(x^0), f(x^1), \\dots, f(x^T)]$ is complete. Check if the sequence is non-increasing, i.e., $f(x^{k+1}) \\leq f(x^k)$ for all $k \\in \\{0, \\dots, T-1\\}$. A small tolerance is used in the comparison to account for potential floating-point inaccuracies. The theoretical guarantee is that for $\\alpha \\in (0, 1/L]$, the sequence of function values generated by ISTA is non-increasing. All test cases satisfy this condition on $\\alpha$ (since $\\eta \\le 1.0$), so the sequence is expected to be non-increasing.\n\n6.  **Output Formatting**: For each case, combine the list of objective values and the boolean monotonicity flag into a two-element list. These results are then aggregated into a final list containing the results of all four cases. The final output is formatted into a single-line string representation of this nested list structure, with no spaces.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the ISTA problem for a suite of test cases.\n    \"\"\"\n\n    def soft_thresholding(u, tau):\n        \"\"\"Coordinate-wise soft-thresholding operator.\"\"\"\n        return np.sign(u) * np.maximum(np.abs(u) - tau, 0.0)\n\n    def objective_function(x, A, b, lam):\n        \"\"\"Composite objective function f(x) = g(x) + lambda*||x||_1.\"\"\"\n        residual = A @ x - b\n        # Using np.dot for ||v||_2^2 is more efficient than np.linalg.norm(v)**2\n        g_x = 0.5 * np.dot(residual, residual)\n        h_x = lam * np.linalg.norm(x, 1)\n        return g_x + h_x\n\n    def gradient_g(x, A, b):\n        \"\"\"Gradient of the smooth part g(x) = 0.5*||Ax-b||_2^2.\"\"\"\n        return A.T @ (A @ x - b)\n    \n    def run_ista(A, b, lam, T, eta):\n        \"\"\"\n        Runs the Iterative Shrinkage-Thresholding Algorithm (ISTA).\n        Returns the sequence of objective values and a boolean for monotonicity.\n        \"\"\"\n        _, n = A.shape\n        \n        # Initialize x\n        x = np.zeros(n, dtype=float)\n        \n        # Compute Lipschitz constant L = lambda_max(A^T A)\n        AtA = A.T @ A\n        # For real symmetric matrices, eigvalsh is numerically stable and efficient.\n        eigenvalues = np.linalg.eigvalsh(AtA)\n        L = np.max(eigenvalues) if eigenvalues.size > 0 else 0.0\n\n        # Handle the case where L is zero or near-zero to avoid division by zero.\n        if L  1e-15:\n            # If L is zero, A must be the zero matrix. The gradient is always zero,\n            # so x will not update from x_0 = 0. The objective is constant.\n            obj_val = objective_function(x, A, b, lam)\n            obj_sequence = [obj_val] * (T + 1)\n            is_monotone = True\n            return obj_sequence, is_monotone\n\n        # Set step size and threshold parameter\n        alpha = eta / L\n        tau = lam * alpha\n        \n        obj_sequence = []\n        \n        for k in range(T + 1):\n            # Calculate and store objective value for the current iterate x^k\n            current_obj = objective_function(x, A, b, lam)\n            obj_sequence.append(current_obj)\n            \n            # Compute the next iterate x^(k+1)\n            if k  T:\n                grad = gradient_g(x, A, b)\n                u = x - alpha * grad\n                x = soft_thresholding(u, tau)\n        \n        # Check for non-increasing property f(x^{k+1}) = f(x^k)\n        # A small tolerance is used for robust floating-point comparisons.\n        is_monotone = True\n        for i in range(len(obj_sequence) - 1):\n            if obj_sequence[i+1] > obj_sequence[i] + 1e-12:\n                is_monotone = False\n                break\n                \n        return obj_sequence, is_monotone\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {\"A\": np.array([[1,0,1,0,2,-1],[0,1,-1,2,0,1],[2,-1,0,1,1,0],[0,2,1,-1,0,1]], dtype=float), \"b\": np.array([1,0,2,-1], dtype=float), \"lambda\": 0.1, \"T\": 10, \"eta\": 1.0},\n        # Case 2\n        {\"A\": np.array([[1,0,1,0,2],[0,1,0,1,1],[1,0,1,0,2]], dtype=float), \"b\": np.array([0,0,0], dtype=float), \"lambda\": 0.2, \"T\": 8, \"eta\": 0.9},\n        # Case 3\n        {\"A\": np.array([[1,0,0,0,0],[0,0.5,0,0,0],[0,0,2,0,0],[0,0,0,1.5,0],[0,0,0,0,0.8]], dtype=float), \"b\": np.array([1,-1,2,-2,0.5], dtype=float), \"lambda\": 0.5, \"T\": 8, \"eta\": 1.0},\n        # Case 4\n        {\"A\": np.array([[2,-1,0,1],[0,1,2,-1],[1,0,-1,2],[-2,1,0,1]], dtype=float), \"b\": np.array([1,-2,0,3], dtype=float), \"lambda\": 0.0, \"T\": 6, \"eta\": 0.8}\n    ]\n    \n    all_results = []\n    for case in test_cases:\n        result_seq, result_mono = run_ista(case[\"A\"], case[\"b\"], case[\"lambda\"], case[\"T\"], case[\"eta\"])\n        all_results.append([result_seq, result_mono])\n    \n    # Format the final output string as a compact, space-free list representation.\n    # repr() creates a string representation, and .replace(' ', '') removes all spaces.\n    final_output_string = repr(all_results).replace(\" \", \"\")\n    \n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "The principles of promoting simple structures extend beyond vector sparsity to problems like matrix completion, where the goal is to recover a low-rank matrix from a small subset of its entries. In this context, the nuclear norm serves as the convex surrogate for rank, much like the $\\ell_1$ norm does for sparsity. This practice  demonstrates the power of this analogy by applying the proximal gradient method to a matrix completion task, where the familiar soft-thresholding operator is replaced by its matrix-valued counterpart, the Singular Value Thresholding (SVT) operator.",
            "id": "3420172",
            "problem": "Consider the matrix completion problem formulated as minimizing the sum of a data misfit and a low-rank regularization term. Let the observation operator be the orthogonal projector $P_{\\Omega} : \\mathbb{R}^{2 \\times 2} \\to \\mathbb{R}^{2 \\times 2}$ defined by $P_{\\Omega}(X)_{ij} = X_{ij}$ if $(i,j) \\in \\Omega$ and $P_{\\Omega}(X)_{ij} = 0$ otherwise, with $\\Omega = \\{(1,1),(2,2)\\}$. Let the observed data be the matrix $M \\in \\mathbb{R}^{2 \\times 2}$ given by\n$$\nM = \\begin{pmatrix}\n5  0 \\\\\n0  1\n\\end{pmatrix}.\n$$\nDefine the smooth loss $g(X) = \\frac{1}{2} \\| P_{\\Omega}(X) - P_{\\Omega}(M) \\|_{F}^{2}$, where $\\| \\cdot \\|_{F}$ denotes the Frobenius norm, and the nonsmooth regularizer $h(X) = \\tau \\| X \\|_{*}$, where $\\| X \\|_{*}$ denotes the nuclear norm, equal to the sum of the singular values of $X$. Consider one step of the proximal gradient method (also known as Forwardâ€“Backward Splitting) applied to $g+h$ starting from the zero matrix $X^{(0)} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}$, with step size $\\mu = \\frac{1}{3}$ and regularization weight $\\tau = 2$. The proximal operator of a proper, lower-semicontinuous, convex function $h$ with parameter $\\lambda  0$ is defined by\n$$\n\\operatorname{prox}_{\\lambda h}(Y) = \\arg\\min_{X} \\left\\{ \\lambda h(X) + \\frac{1}{2} \\| X - Y \\|_{F}^{2} \\right\\}.\n$$\nYou will need to compute the gradient of $g$, perform the gradient step $Y = X^{(0)} - \\mu \\nabla g(X^{(0)})$, and then apply the proximal operator $\\operatorname{prox}_{\\mu h}(Y)$. In this context, the proximal operator of the nuclear norm is the Singular Value Thresholding (SVT) operator; you may use the Singular Value Decomposition (SVD) $Y = U \\operatorname{diag}(\\sigma_{i}) V^{\\top}$ in your derivation.\n\nAfter executing this single proximal gradient iteration, compute the value of the objective function\n$$\nJ\\big(X^{(1)}\\big) = \\frac{1}{2} \\| P_{\\Omega}\\big(X^{(1)}\\big) - P_{\\Omega}(M) \\|_{F}^{2} + \\tau \\| X^{(1)} \\|_{*}.\n$$\nProvide your final answer as a single exact number. Do not round. Express the final answer without units.",
            "solution": "The problem is validated as scientifically grounded, well-posed, objective, and self-contained. All necessary information is provided, and the task is to perform a standard calculation within the field of optimization for inverse problems. We may therefore proceed with the solution.\n\nThe problem asks for the value of the objective function $J(X^{(1)})$ after one iteration of the proximal gradient method. The objective function is $J(X) = g(X) + h(X)$, where $g(X) = \\frac{1}{2} \\| P_{\\Omega}(X) - P_{\\Omega}(M) \\|_{F}^{2}$ is the smooth data-fidelity term and $h(X) = \\tau \\| X \\|_{*}$ is the nonsmooth regularization term.\n\nThe proximal gradient iteration is given by:\n$$\nX^{(k+1)} = \\operatorname{prox}_{\\mu h}\\left(X^{(k)} - \\mu \\nabla g(X^{(k)})\\right)\n$$\nWe are asked to compute $X^{(1)}$ starting from $X^{(0)} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}$. The parameters are the step size $\\mu = \\frac{1}{3}$ and the regularization weight $\\tau = 2$. The observed data matrix is $M = \\begin{pmatrix} 5  0 \\\\ 0  1 \\end{pmatrix}$, and the observation set is $\\Omega = \\{(1,1), (2,2)\\}$.\n\nFirst, we compute the gradient of the smooth term $g(X)$. The function $g(X)$ is a composition of the squared Frobenius norm and a linear operator. The gradient of $g(X) = \\frac{1}{2} \\| A(X) - B \\|_{F}^{2}$, where $A(X) = P_{\\Omega}(X)$ and $B = P_{\\Omega}(M)$, is given by $\\nabla g(X) = A^*(A(X)-B)$, where $A^*$ is the adjoint of the operator $A$. The operator $P_{\\Omega}$ is an orthogonal projector, so it is self-adjoint, i.e., $P_{\\Omega}^* = P_{\\Omega}$. Furthermore, since $P_{\\Omega}$ is a projector, $P_{\\Omega} \\circ P_{\\Omega} = P_{\\Omega}$.\nTherefore, the gradient of $g(X)$ is:\n$$\n\\nabla g(X) = P_{\\Omega}^*(P_{\\Omega}(X) - P_{\\Omega}(M)) = P_{\\Omega}(P_{\\Omega}(X) - P_{\\Omega}(M)) = P_{\\Omega}(X) - P_{\\Omega}(M)\n$$\nWe evaluate this gradient at the initial point $X^{(0)} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}$:\n$$\n\\nabla g(X^{(0)}) = P_{\\Omega}(X^{(0)}) - P_{\\Omega}(M)\n$$\nGiven $X^{(0)}$ is the zero matrix, $P_{\\Omega}(X^{(0)})$ is also the zero matrix. The operator $P_{\\Omega}$ acts by setting entries outside $\\Omega = \\{(1,1), (2,2)\\}$ to zero. For the given matrix $M$, we have:\n$$\nP_{\\Omega}(M) = P_{\\Omega}\\left(\\begin{pmatrix} 5  0 \\\\ 0  1 \\end{pmatrix}\\right) = \\begin{pmatrix} 5  0 \\\\ 0  1 \\end{pmatrix} = M\n$$\nThus, the gradient at $X^{(0)}$ is:\n$$\n\\nabla g(X^{(0)}) = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix} - \\begin{pmatrix} 5  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} -5  0 \\\\ 0  -1 \\end{pmatrix}\n$$\nNext, we perform the gradient descent step (the \"forward\" step) to find the intermediate matrix $Y$:\n$$\nY = X^{(0)} - \\mu \\nabla g(X^{(0)}) = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix} - \\frac{1}{3} \\begin{pmatrix} -5  0 \\\\ 0  -1 \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{3}  0 \\\\ 0  \\frac{1}{3} \\end{pmatrix}\n$$\nNow, we apply the proximal operator (the \"backward\" step) to $Y$ to find $X^{(1)}$:\n$$\nX^{(1)} = \\operatorname{prox}_{\\mu h}(Y) = \\operatorname{prox}_{\\mu \\tau \\| \\cdot \\|_{*}}(Y)\n$$\nThe proximal operator of the nuclear norm is the Singular Value Thresholding (SVT) operator. For a matrix $Y$ with Singular Value Decomposition (SVD) $Y = U \\Sigma V^{\\top}$, where $\\Sigma = \\operatorname{diag}(\\sigma_i)$, the SVT operator with threshold $\\lambda$ is defined as $S_{\\lambda}(Y) = U S_{\\lambda}(\\Sigma) V^{\\top}$, where $S_{\\lambda}(\\Sigma) = \\operatorname{diag}(\\max(0, \\sigma_i - \\lambda))$.\nIn our case, the threshold is $\\lambda = \\mu \\tau = \\frac{1}{3} \\times 2 = \\frac{2}{3}$.\nThe matrix $Y$ is already diagonal, so its SVD is trivial. The singular values are the absolute values of the diagonal entries: $\\sigma_1 = \\frac{5}{3}$ and $\\sigma_2 = \\frac{1}{3}$. The corresponding left and right singular vectors are the standard basis vectors, so $U = V = I = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$.\n\nWe apply the soft-thresholding function to the singular values:\n$$\n\\hat{\\sigma}_1 = \\max\\left(0, \\sigma_1 - \\lambda\\right) = \\max\\left(0, \\frac{5}{3} - \\frac{2}{3}\\right) = \\max\\left(0, \\frac{3}{3}\\right) = 1\n$$\n$$\n\\hat{\\sigma}_2 = \\max\\left(0, \\sigma_2 - \\lambda\\right) = \\max\\left(0, \\frac{1}{3} - \\frac{2}{3}\\right) = \\max\\left(0, -\\frac{1}{3}\\right) = 0\n$$\nWe reconstruct the matrix $X^{(1)}$ using the thresholded singular values:\n$$\nX^{(1)} = U \\operatorname{diag}(\\hat{\\sigma}_1, \\hat{\\sigma}_2) V^{\\top} = I \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} I^{\\top} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}\n$$\nFinally, we compute the value of the objective function $J(X^{(1)})$:\n$$\nJ\\big(X^{(1)}\\big) = \\frac{1}{2} \\| P_{\\Omega}\\big(X^{(1)}\\big) - P_{\\Omega}(M) \\|_{F}^{2} + \\tau \\| X^{(1)} \\|_{*}\n$$\nFirst, we compute the data-fidelity term:\n$$\n P_{\\Omega}\\big(X^{(1)}\\big) = P_{\\Omega}\\left(\\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}\\right) = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}\n$$\nThe difference term is:\n$$\nP_{\\Omega}\\big(X^{(1)}\\big) - P_{\\Omega}(M) = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} - \\begin{pmatrix} 5  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} -4  0 \\\\ 0  -1 \\end{pmatrix}\n$$\nThe squared Frobenius norm of this difference is:\n$$\n\\| P_{\\Omega}\\big(X^{(1)}\\big) - P_{\\Omega}(M) \\|_{F}^{2} = (-4)^2 + 0^2 + 0^2 + (-1)^2 = 16 + 1 = 17\n$$\nSo, the data-fidelity term is $\\frac{1}{2} \\times 17 = \\frac{17}{2}$.\n\nNext, we compute the regularization term, $\\tau \\| X^{(1)} \\|_{*}$. The nuclear norm $\\| X^{(1)} \\|_{*}$ is the sum of its singular values. The singular values of $X^{(1)} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}$ are $\\sigma_1=1$ and $\\sigma_2=0$.\n$$\n\\| X^{(1)} \\|_{*} = 1 + 0 = 1\n$$\nThe regularization term is $\\tau \\| X^{(1)} \\|_{*} = 2 \\times 1 = 2$.\n\nThe total value of the objective function is the sum of the two terms:\n$$\nJ\\big(X^{(1)}\\big) = \\frac{17}{2} + 2 = \\frac{17}{2} + \\frac{4}{2} = \\frac{21}{2}\n$$",
            "answer": "$$\n\\boxed{\\frac{21}{2}}\n$$"
        }
    ]
}