{
    "hands_on_practices": [
        {
            "introduction": "A primary task after running a non-equilibrium molecular dynamics (NEMD) simulation is to process the resulting data to extract transport properties. This exercise guides you through the essential steps of analyzing steady-state temperature and velocity profiles from a boundary-driven simulation. By learning to identify the linear 'bulk' region and fit it to extract gradients, you will practice a core skill in NEMD data analysis and gain insight into the nature of boundary effects like interfacial resistance. ",
            "id": "3469013",
            "problem": "You are given a one-dimensional steady-state, boundary-driven non-equilibrium molecular dynamics (NEMD) configuration of a planar slab of length $L$ subdivided into $N$ spatial bins along the $x$-axis. Each bin has a center coordinate $x_i$ and measured steady-state bin-averaged fields: temperature $T_i$ (in Kelvin) and streamwise velocity $u_i$ (in meters per second). Thermostatted slabs occupy $W_L$ bins at the left boundary and $W_R$ bins at the right boundary. The aim is to extract bulk gradients by fitting linear regions and to quantify boundary-layer deviations near the thermostatted slabs.\n\nFundamental base and assumptions:\n- Steady-state transport of heat and momentum in a simple fluid with constant transport coefficients implies a linear bulk profile for temperature and velocity under uniform driving along one dimension, provided the bulk region is free of direct thermostatting. This follows from Fourier’s law and the Newtonian constitutive relation when combined with steady-state balance and absence of sources in the bulk.\n- The thermostatted slabs introduce non-bulk behavior near the boundaries; to prevent contamination of the bulk fit, a guard of $g$ bins adjacent to each thermostatted slab must be excluded in addition to the thermostatted bins themselves.\n\nYour program must do the following for each test case:\n1. Construct $x_i$ for $i \\in \\{0,\\dots,N-1\\}$ as bin centers $x_i = \\left(i + \\frac{1}{2}\\right)\\Delta x$ with $\\Delta x = L/N$.\n2. Identify the bulk fitting region by excluding indices in the left thermostatted slab $\\{0,\\dots,W_L-1\\}$ and the right thermostatted slab $\\{N-W_R,\\dots,N-1\\}$, and then excluding an additional guard of $g=1$ bin next to each slab. That is, fit only on indices $i \\in \\{W_L+g,\\dots,N-W_R-g-1\\}$.\n3. Using ordinary least squares, fit linear models $T(x) \\approx a_T x + b_T$ and $u(x) \\approx a_u x + b_u$ on the bulk region to extract the bulk gradients $a_T = \\mathrm{d}T/\\mathrm{d}x$ and $a_u = \\mathrm{d}u/\\mathrm{d}x$. Report $a_T$ in $\\mathrm{K}/\\mathrm{m}$ and $a_u$ in $\\mathrm{s}^{-1}$.\n4. Quantify deviations in the thermostatted slabs by computing, for each side separately:\n   - The interfacial jump at the first bulk bin adjacent to each slab, defined as the measured value minus the bulk fit prediction at that location. On the left, use the first bulk index $i_L = W_L + g$ and compute $J_T^{(L)} = T_{i_L} - (a_T x_{i_L} + b_T)$ and $J_u^{(L)} = u_{i_L} - (a_u x_{i_L} + b_u)$; on the right, use $i_R = N - W_R - g - 1$ and compute $J_T^{(R)}$ and $J_u^{(R)}$ analogously. Report $J_T^{(L)}$ and $J_T^{(R)}$ in $\\mathrm{K}$, and $J_u^{(L)}$ and $J_u^{(R)}$ in $\\mathrm{m}/\\mathrm{s}$.\n   - The root-mean-square (RMS) deviation in each thermostatted slab relative to the bulk fit, normalized by the total bulk drop across the domain for the respective field. For the left slab indices $\\{0,\\dots,W_L-1\\}$ and the right slab indices $\\{N-W_R,\\dots,N-1\\}$, compute the RMS of the residuals $T_i - (a_T x_i + b_T)$ and $u_i - (a_u x_i + b_u)$. Normalize the temperature RMS by $|a_T| L$ and the velocity RMS by $|a_u| L$. Report dimensionless values $D_T^{(L)}$, $D_T^{(R)}$, $D_u^{(L)}$, and $D_u^{(R)}$ as decimals. All provided test cases have nonzero bulk gradients so that the normalization is well-defined.\n5. For each test case, output the list of results in the following fixed order:\n   - $a_T$ (in $\\mathrm{K}/\\mathrm{m}$),\n   - $a_u$ (in $\\mathrm{s}^{-1}$),\n   - $J_T^{(L)}$ (in $\\mathrm{K}$),\n   - $J_T^{(R)}$ (in $\\mathrm{K}$),\n   - $J_u^{(L)}$ (in $\\mathrm{m}/\\mathrm{s}$),\n   - $J_u^{(R)}$ (in $\\mathrm{m}/\\mathrm{s}$),\n   - $D_T^{(L)}$ (dimensionless),\n   - $D_T^{(R)}$ (dimensionless),\n   - $D_u^{(L)}$ (dimensionless),\n   - $D_u^{(R)}$ (dimensionless).\n\nTest suite construction:\n- For each test case, you must synthesize $T_i$ and $u_i$ from specified parameters as follows. For $i \\in \\{0,\\dots,N-1\\}$:\n  - $x_i = \\left(i + \\frac{1}{2}\\right)\\Delta x$, with $\\Delta x = L/N$.\n  - Baseline linear fields:\n    - $T_i^{\\mathrm{lin}} = T_0 + a_T^{\\mathrm{true}} x_i$,\n    - $u_i^{\\mathrm{lin}} = u_0 + a_u^{\\mathrm{true}} x_i$.\n  - Thermostat-localized deviations applied only inside the thermostatted bins:\n    - Left slab indices $i \\in \\{0,\\dots,W_L-1\\}$:\n      - $T_i \\leftarrow T_i^{\\mathrm{lin}} + A_T^{(L)} \\exp\\left(-\\frac{x_i}{\\ell_T^{(L)}}\\right)$,\n      - $u_i \\leftarrow u_i^{\\mathrm{lin}} + A_u^{(L)} \\exp\\left(-\\frac{x_i}{\\ell_u^{(L)}}\\right)$.\n    - Right slab indices $i \\in \\{N-W_R,\\dots,N-1\\}$:\n      - $T_i \\leftarrow T_i^{\\mathrm{lin}} + A_T^{(R)} \\exp\\left(-\\frac{L - x_i}{\\ell_T^{(R)}}\\right)$,\n      - $u_i \\leftarrow u_i^{\\mathrm{lin}} + A_u^{(R)} \\exp\\left(-\\frac{L - x_i}{\\ell_u^{(R)}}\\right)$.\n    - All other indices (bulk) have $T_i \\leftarrow T_i^{\\mathrm{lin}}$ and $u_i \\leftarrow u_i^{\\mathrm{lin}}$ before noise addition.\n  - Small spatially smooth noise applied to all bins:\n    - $T_i \\leftarrow T_i + A_T^{\\mathrm{noise}} \\sin\\left(2\\pi k_T \\frac{x_i}{L}\\right)$,\n    - $u_i \\leftarrow u_i + A_u^{\\mathrm{noise}} \\sin\\left(2\\pi k_u \\frac{x_i}{L}\\right)$.\n- Use the following three test cases, all in SI units:\n  - Test case $1$ (happy path):\n    - $L = 50 \\times 10^{-9} \\,\\mathrm{m}$, $N = 50$, $W_L = 6$, $W_R = 6$, $g = 1$,\n    - $T_0 = 400 \\,\\mathrm{K}$, $a_T^{\\mathrm{true}} = -2.0 \\times 10^{9} \\,\\mathrm{K}/\\mathrm{m}$,\n    - $u_0 = 0 \\,\\mathrm{m}/\\mathrm{s}$, $a_u^{\\mathrm{true}} = 1.0 \\times 10^{7} \\,\\mathrm{s}^{-1}$,\n    - $A_T^{(L)} = 10 \\,\\mathrm{K}$, $\\ell_T^{(L)} = 2 \\Delta x$; $A_T^{(R)} = -8 \\,\\mathrm{K}$, $\\ell_T^{(R)} = 2 \\Delta x$,\n    - $A_u^{(L)} = 0.02 \\,\\mathrm{m}/\\mathrm{s}$, $\\ell_u^{(L)} = 2 \\Delta x$; $A_u^{(R)} = -0.015 \\,\\mathrm{m}/\\mathrm{s}$, $\\ell_u^{(R)} = 2 \\Delta x$,\n    - $A_T^{\\mathrm{noise}} = 0.5 \\,\\mathrm{K}$ with $k_T = 7$, $A_u^{\\mathrm{noise}} = 0.002 \\,\\mathrm{m}/\\mathrm{s}$ with $k_u = 5$.\n  - Test case $2$ (asymmetric slabs and opposite gradients):\n    - $L = 100 \\times 10^{-9} \\,\\mathrm{m}$, $N = 80$, $W_L = 4$, $W_R = 10$, $g = 1$,\n    - $T_0 = 300 \\,\\mathrm{K}$, $a_T^{\\mathrm{true}} = 1.2 \\times 10^{9} \\,\\mathrm{K}/\\mathrm{m}$,\n    - $u_0 = 0.1 \\,\\mathrm{m}/\\mathrm{s}$, $a_u^{\\mathrm{true}} = -5.0 \\times 10^{6} \\,\\mathrm{s}^{-1}$,\n    - $A_T^{(L)} = -12 \\,\\mathrm{K}$, $\\ell_T^{(L)} = 1.5 \\Delta x$; $A_T^{(R)} = 6 \\,\\mathrm{K}$, $\\ell_T^{(R)} = 1.5 \\Delta x$,\n    - $A_u^{(L)} = 0.01 \\,\\mathrm{m}/\\mathrm{s}$, $\\ell_u^{(L)} = 1.5 \\Delta x$; $A_u^{(R)} = -0.01 \\,\\mathrm{m}/\\mathrm{s}$, $\\ell_u^{(R)} = 1.5 \\Delta x$,\n    - $A_T^{\\mathrm{noise}} = 1.0 \\,\\mathrm{K}$ with $k_T = 9$, $A_u^{\\mathrm{noise}} = 0.001 \\,\\mathrm{m}/\\mathrm{s}$ with $k_u = 4$.\n  - Test case $3$ (minimal slabs and stronger boundary-layer amplitudes):\n    - $L = 40 \\times 10^{-9} \\,\\mathrm{m}$, $N = 40$, $W_L = 1$, $W_R = 1$, $g = 1$,\n    - $T_0 = 350 \\,\\mathrm{K}$, $a_T^{\\mathrm{true}} = -1.0 \\times 10^{9} \\,\\mathrm{K}/\\mathrm{m}$,\n    - $u_0 = 0 \\,\\mathrm{m}/\\mathrm{s}$, $a_u^{\\mathrm{true}} = 2.0 \\times 10^{6} \\,\\mathrm{s}^{-1}$,\n    - $A_T^{(L)} = 20 \\,\\mathrm{K}$, $\\ell_T^{(L)} = 1 \\Delta x$; $A_T^{(R)} = -15 \\,\\mathrm{K}$, $\\ell_T^{(R)} = 1 \\Delta x$,\n    - $A_u^{(L)} = 0.03 \\,\\mathrm{m}/\\mathrm{s}$, $\\ell_u^{(L)} = 1 \\Delta x$; $A_u^{(R)} = -0.02 \\,\\mathrm{m}/\\mathrm{s}$, $\\ell_u^{(R)} = 1 \\Delta x$,\n    - $A_T^{\\mathrm{noise}} = 0.2 \\,\\mathrm{K}$ with $k_T = 6$, $A_u^{\\mathrm{noise}} = 0.0005 \\,\\mathrm{m}/\\mathrm{s}$ with $k_u = 3$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for all three test cases as a list of lists, with each inner list ordered as specified above. Use scientific notation with six digits after the decimal point for all numbers. For example, a valid output shape is\n  - $[[a_T^{(1)},a_u^{(1)},J_T^{(L,1)},J_T^{(R,1)},J_u^{(L,1)},J_u^{(R,1)},D_T^{(L,1)},D_T^{(R,1)},D_u^{(L,1)},D_u^{(R,1)}],[\\dots],[\\dots]]$.\nAll gradients must be expressed in the specified units ($\\mathrm{K}/\\mathrm{m}$ and $\\mathrm{s}^{-1}$), the jumps in ($\\mathrm{K}$ and $\\mathrm{m}/\\mathrm{s}$), and the deviations in dimensionless decimal form. The program must print exactly one line: the single aggregated list as described, with no additional text.",
            "solution": "The posed problem is scientifically sound, well-posed, and computationally tractable. It involves the analysis of synthetic data mimicking results from a non-equilibrium molecular dynamics (NEMD) simulation of a fluid slab under thermal and velocity gradients. The solution requires a two-phase process for each test case: first, the generation of the specified data profiles, and second, the analysis of these profiles to extract physical quantities.\n\nThe methodical approach to the solution is as follows:\n\nFirst, for each test case, the one-dimensional spatial domain of length $L$ is discretized into $N$ bins. The center coordinate of each bin $i$ (for $i \\in \\{0, \\dots, N-1\\}$) is calculated as $x_i = (i + \\frac{1}{2})\\Delta x$, where the bin width is $\\Delta x = L/N$.\n\nSecond, realistic temperature $T_i$ and velocity $u_i$ profiles are synthesized. This process begins by creating ideal linear bulk profiles according to the provided true gradients ($a_T^{\\mathrm{true}}$, $a_u^{\\mathrm{true}}$) and intercepts ($T_0$, $u_0$):\n$$T_i^{\\mathrm{lin}} = T_0 + a_T^{\\mathrm{true}} x_i$$\n$$u_i^{\\mathrm{lin}} = u_0 + a_u^{\\mathrm{true}} x_i$$\nTo simulate the localized, non-linear effects of thermostats at the boundaries, exponential deviation terms are added to these linear profiles within the thermostatted regions. For the left thermostatted slab, comprising indices $i \\in \\{0, \\dots, W_L-1\\}$, the fields are modified as:\n$$T_i \\leftarrow T_i^{\\mathrm{lin}} + A_T^{(L)} \\exp\\left(-\\frac{x_i}{\\ell_T^{(L)}}\\right)$$\n$$u_i \\leftarrow u_i^{\\mathrm{lin}} + A_u^{(L)} \\exp\\left(-\\frac{x_i}{\\ell_u^{(L)}}\\right)$$\nA similar modification is applied for the right thermostatted slab, covering indices $i \\in \\{N-W_R, \\dots, N-1\\}$, using the corresponding right-side parameters. Finally, to represent statistical fluctuations inherent in molecular dynamics, a small, spatially smooth sinusoidal noise term is added to all bins across the entire domain for both the temperature and velocity fields.\n\nThird, the analysis phase begins by identifying the bulk region of the slab. This region is defined by excluding the thermostatted slabs at both ends ($W_L$ bins on the left, $W_R$ on the right) and an additional guard region of $g=1$ bin adjacent to each slab. The resulting bulk fitting region consists of bin indices $i \\in \\{W_L+g, \\dots, N-W_R-g-1\\}$.\n\nFourth, within this identified bulk region, ordinary least squares (OLS) regression is employed to fit linear models, $T(x) \\approx a_T x + b_T$ and $u(x) \\approx a_u x + b_u$. This is accomplished using `numpy.polyfit` with a degree of $1$. The slopes of these fits, $a_T$ and $a_u$, represent the numerically extracted bulk thermal gradient ($\\mathrm{d}T/\\mathrm{d}x$) and velocity gradient ($\\mathrm{d}u/\\mathrm{d}x$), respectively.\n\nFifth, the deviations from this ideal bulk behavior near the boundaries are quantified. Two metrics are calculated:\n1.  The interfacial jump, which measures the local deviation at the interface between the guard region and the bulk. This is computed as the residual between the measured data and the linear fit's prediction at the first bulk bin on each side. For the left side at index $i_L = W_L + g$, the jumps are $J_T^{(L)} = T_{i_L} - (a_T x_{i_L} + b_T)$ and $J_u^{(L)} = u_{i_L} - (a_u x_{i_L} + b_u)$. Analogous calculations are performed on the right side at index $i_R = N-W_R-g-1$.\n2.  The normalized root-mean-square (RMS) deviation, which quantifies the overall non-linearity within the thermostatted regions. For each slab (left: $i \\in \\{0,\\dots,W_L-1\\}$; right: $i \\in \\{N-W_R,\\dots,N-1\\}$), the RMS of the residuals between the measured data ($T_i, u_i$) and the extrapolated bulk fit ($a_T x_i + b_T, a_u x_i + b_u$) is calculated. This RMS value is then normalized by the total magnitude of the bulk field change across the entire domain, $|a_T|L$ for temperature and $|a_u|L$ for velocity, yielding the dimensionless deviation metrics $D_T^{(L)}$, $D_T^{(R)}$, $D_u^{(L)}$, and $D_u^{(R)}$.\n\nThis entire procedure is systematically applied to each of the three test cases, and the ten specified output quantities for each case are collected and formatted as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the processing of all test cases and print the final output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        {\n            \"L\": 50e-9, \"N\": 50, \"W_L\": 6, \"W_R\": 6, \"g\": 1,\n            \"T0\": 400.0, \"a_T_true\": -2.0e9,\n            \"u0\": 0.0, \"a_u_true\": 1.0e7,\n            \"A_T_L\": 10.0, \"l_T_L_factor\": 2.0,\n            \"A_T_R\": -8.0, \"l_T_R_factor\": 2.0,\n            \"A_u_L\": 0.02, \"l_u_L_factor\": 2.0,\n            \"A_u_R\": -0.015, \"l_u_R_factor\": 2.0,\n            \"A_T_noise\": 0.5, \"k_T\": 7.0,\n            \"A_u_noise\": 0.002, \"k_u\": 5.0,\n        },\n        # Test case 2\n        {\n            \"L\": 100e-9, \"N\": 80, \"W_L\": 4, \"W_R\": 10, \"g\": 1,\n            \"T0\": 300.0, \"a_T_true\": 1.2e9,\n            \"u0\": 0.1, \"a_u_true\": -5.0e6,\n            \"A_T_L\": -12.0, \"l_T_L_factor\": 1.5,\n            \"A_T_R\": 6.0, \"l_T_R_factor\": 1.5,\n            \"A_u_L\": 0.01, \"l_u_L_factor\": 1.5,\n            \"A_u_R\": -0.01, \"l_u_R_factor\": 1.5,\n            \"A_T_noise\": 1.0, \"k_T\": 9.0,\n            \"A_u_noise\": 0.001, \"k_u\": 4.0,\n        },\n        # Test case 3\n        {\n            \"L\": 40e-9, \"N\": 40, \"W_L\": 1, \"W_R\": 1, \"g\": 1,\n            \"T0\": 350.0, \"a_T_true\": -1.0e9,\n            \"u0\": 0.0, \"a_u_true\": 2.0e6,\n            \"A_T_L\": 20.0, \"l_T_L_factor\": 1.0,\n            \"A_T_R\": -15.0, \"l_T_R_factor\": 1.0,\n            \"A_u_L\": 0.03, \"l_u_L_factor\": 1.0,\n            \"A_u_R\": -0.02, \"l_u_R_factor\": 1.0,\n            \"A_T_noise\": 0.2, \"k_T\": 6.0,\n            \"A_u_noise\": 0.0005, \"k_u\": 3.0,\n        },\n    ]\n\n    all_results = []\n    for params in test_cases:\n        case_results = process_case(params)\n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    inner_lists_str = []\n    for res_list in all_results:\n        formatted_nums = [f\"{num:.6e}\" for num in res_list]\n        inner_lists_str.append(f\"[{','.join(formatted_nums)}]\")\n    \n    print(f\"[{','.join(inner_lists_str)}]\")\n\ndef process_case(params: dict) -> list:\n    \"\"\"\n    Generates synthetic data and performs analysis for a single test case.\n    \"\"\"\n    L = params[\"L\"]\n    N = params[\"N\"]\n    W_L = params[\"W_L\"]\n    W_R = params[\"W_R\"]\n    g = params[\"g\"]\n    \n    # Step 1: Construct coordinates and generate data profiles\n    delta_x = L / N\n    i_coords = np.arange(N)\n    x = (i_coords + 0.5) * delta_x\n\n    # Baseline linear fields\n    T = params[\"T0\"] + params[\"a_T_true\"] * x\n    u = params[\"u0\"] + params[\"a_u_true\"] * x\n\n    # Add thermostat-localized deviations\n    # Left slab\n    if W_L > 0:\n      l_slab_indices = np.arange(W_L)\n      x_l_slab = x[l_slab_indices]\n      l_T_L = params[\"l_T_L_factor\"] * delta_x\n      l_u_L = params[\"l_u_L_factor\"] * delta_x\n      T[l_slab_indices] += params[\"A_T_L\"] * np.exp(-x_l_slab / l_T_L)\n      u[l_slab_indices] += params[\"A_u_L\"] * np.exp(-x_l_slab / l_u_L)\n\n    # Right slab\n    if W_R > 0:\n      r_slab_indices = np.arange(N - W_R, N)\n      x_r_slab = x[r_slab_indices]\n      l_T_R = params[\"l_T_R_factor\"] * delta_x\n      l_u_R = params[\"l_u_R_factor\"] * delta_x\n      T[r_slab_indices] += params[\"A_T_R\"] * np.exp(-(L - x_r_slab) / l_T_R)\n      u[r_slab_indices] += params[\"A_u_R\"] * np.exp(-(L - x_r_slab) / l_u_R)\n\n    # Add spatially smooth noise to all bins\n    T += params[\"A_T_noise\"] * np.sin(2 * np.pi * params[\"k_T\"] * x / L)\n    u += params[\"A_u_noise\"] * np.sin(2 * np.pi * params[\"k_u\"] * x / L)\n\n    # Step 2 & 3: Identify bulk region and perform OLS fit\n    bulk_start_idx = W_L + g\n    bulk_end_idx = N - W_R - g - 1\n    bulk_indices = np.arange(bulk_start_idx, bulk_end_idx + 1)\n    \n    x_bulk = x[bulk_indices]\n    T_bulk = T[bulk_indices]\n    u_bulk = u[bulk_indices]\n\n    a_T, b_T = np.polyfit(x_bulk, T_bulk, 1)\n    a_u, b_u = np.polyfit(x_bulk, u_bulk, 1)\n\n    # Step 4: Quantify deviations from the bulk fit\n    # Interfacial jumps at the first/last bulk bin\n    i_L = W_L + g\n    T_fit_L = a_T * x[i_L] + b_T\n    J_T_L = T[i_L] - T_fit_L\n    u_fit_L = a_u * x[i_L] + b_u\n    J_u_L = u[i_L] - u_fit_L\n\n    i_R = N - W_R - g - 1\n    T_fit_R = a_T * x[i_R] + b_T\n    J_T_R = T[i_R] - T_fit_R\n    u_fit_R = a_u * x[i_R] + b_u\n    J_u_R = u[i_R] - u_fit_R\n\n    # RMS of residuals in thermostatted slabs, normalized\n    def rms(v):\n        return np.sqrt(np.mean(np.square(v)))\n\n    # Left slab RMSD\n    if W_L > 0:\n        x_slab_L = x[l_slab_indices]\n        T_res_L = T[l_slab_indices] - (a_T * x_slab_L + b_T)\n        u_res_L = u[l_slab_indices] - (a_u * x_slab_L + b_u)\n        D_T_L = rms(T_res_L) / (np.abs(a_T) * L)\n        D_u_L = rms(u_res_L) / (np.abs(a_u) * L)\n    else:\n        D_T_L, D_u_L = 0.0, 0.0\n\n    # Right slab RMSD\n    if W_R > 0:\n        x_slab_R = x[r_slab_indices]\n        T_res_R = T[r_slab_indices] - (a_T * x_slab_R + b_T)\n        u_res_R = u[r_slab_indices] - (a_u * x_slab_R + b_u)\n        D_T_R = rms(T_res_R) / (np.abs(a_T) * L)\n        D_u_R = rms(u_res_R) / (np.abs(a_u) * L)\n    else:\n        D_T_R, D_u_R = 0.0, 0.0\n\n    # Step 5: Return results in the specified order\n    return [a_T, a_u, J_T_L, J_T_R, J_u_L, J_u_R, D_T_L, D_T_R, D_u_L, D_u_R]\n\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        },
        {
            "introduction": "Molecular dynamics simulations are necessarily performed on finite systems, yet our goal is often to predict the properties of bulk materials. This practice addresses the critical issue of finite-size effects, which cause transport coefficients to depend on system size. You will analyze a set of hypothetical NEMD results for thermal conductivity, $\\kappa(L)$, at various system lengths $L$, and use a common scaling law to extrapolate to the infinite-system limit, thereby extracting the true bulk thermal conductivity $\\kappa_\\infty$. ",
            "id": "3468983",
            "problem": "You are analyzing the results of non-equilibrium molecular dynamics (NEMD) simulations of heat transport in a one-dimensional nanowire. The objective is to infer the bulk thermal conductivity, $\\kappa_\\infty$, by performing a finite-size scaling analysis. In simulations, the calculated effective thermal conductivity, $\\kappa(L)$, depends on the system length $L$. A common method to find the bulk value is to fit simulation data at different lengths to a model and extrapolate to the infinite-system limit ($L \\to \\infty$). For this problem, you will use the linear model $\\kappa(L) = \\kappa_\\infty + m \\cdot (1/L)$, which is equivalent to $y = b+mx$ where $y=\\kappa(L)$, $x=1/L$, and the intercept $b = \\kappa_\\infty$.\n\nYour task is to write a program that, for each test case, estimates $\\kappa_\\infty$ and a characteristic length scale $\\lambda$ by fitting the linear model $\\kappa(L) = b + m x$ where $x=1/L$. Use ordinary least squares and assume uniform uncertainties for the provided data.\n\nRequirements:\n- Use the linear regression formulation $y_i = b + m x_i$ with $x_i = 1/L_i$ and $y_i = \\kappa(L_i)$ to determine $b$ and $m$ from the data in each test case, then set $\\kappa_\\infty = b$ and compute the characteristic length $\\lambda = m/b$.\n- Express $\\kappa_\\infty$ in watts per meter-kelvin (W/(m·K)) and $\\lambda$ in nanometers (nm). Round each reported float to six decimal places.\n- The independent variable $L$ is provided in nanometers (nm), and all reported lengths must be in nanometers (nm). The conductivities are provided in W/(m·K).\n\nTest Suite:\n- Case $1$ (happy path, moderate lengths): $L = [\\,100,\\,200,\\,400,\\,800\\,]$ nm, $\\kappa(L) = [\\,300,\\,200,\\,150,\\,125\\,]$ W/(m·K).\n- Case $2$ (large-$L$ regime): $L = [\\,1000,\\,2000,\\,4000,\\,8000\\,]$ nm, $\\kappa(L) = [\\,375,\\,312.5,\\,281.25,\\,265.625\\,]$ W/(m·K).\n- Case $3$ (short-$L$ ballistic-leaning regime): $L = [\\,50,\\,75,\\,100,\\,150\\,]$ nm, $\\kappa(L) = [\\,90,\\,70,\\,60,\\,50\\,]$ W/(m·K).\n- Case $4$ (minimal data, two points): $L = [\\,200,\\,400\\,]$ nm, $\\kappa(L) = [\\,120,\\,100\\,]$ W/(m·K).\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case, output the pair $(\\kappa_\\infty, \\lambda)$ in order of the cases, flattened into a single list. For example, the output must look like $[r_1,r_2,\\dots]$ where $r_{2k-1} = \\kappa_\\infty$ in W/(m·K) and $r_{2k} = \\lambda$ in nm for case $k$, with each float rounded to six decimal places.",
            "solution": "The problem has been assessed and is deemed valid. It is scientifically grounded within the context of analyzing simulation data in computational physics, providing a well-defined mathematical model and a clear, objective procedure for parameter estimation. The problem is self-contained, and the provided data are internally consistent with the specified model, allowing for a unique and meaningful solution.\n\nThe objective is to determine the bulk thermal conductivity, $\\kappa_\\infty$, and a characteristic phonon mean free path, $\\lambda$, by analyzing the finite-size dependence of the effective thermal conductivity, $\\kappa(L)$, in a one-dimensional system. The analysis is based on the provided model relating the effective conductivity at a finite length $L$ to the bulk conductivity $\\kappa_\\infty$:\n$$ \\kappa(L) = \\kappa_\\infty \\left(1 + \\frac{a}{L}\\right) $$\nHere, $a$ is a parameter with units of length, which is to be identified with the phonon mean free path, $\\lambda$. This model describes a system where the leading-order finite-size correction to conductivity scales as $L^{-1}$.\n\nTo estimate the parameters $\\kappa_\\infty$ and $a$, we linearize the model. By defining an independent variable $x = 1/L$ and a dependent variable $y = \\kappa(L)$, the equation can be rewritten in the standard form of a linear equation, $y = mx + b$:\n$$ \\kappa(L) = \\kappa_\\infty + (\\kappa_\\infty a) \\frac{1}{L} $$\nBy comparing this to the general linear form $y = b + mx$, we can make the following identifications between the physical parameters and the regression coefficients:\n- The intercept $b$ corresponds to the bulk thermal conductivity: $\\kappa_\\infty = b$.\n- The slope $m$ is related to both parameters: $m = \\kappa_\\infty a$.\n\nThe problem requires using ordinary least squares (OLS) to find the best-fit values for the slope $m$ and the intercept $b$ for the given data sets $(x_i, y_i)$, where $x_i = 1/L_i$ and $y_i = \\kappa(L_i)$. The OLS estimators for $m$ and $b$ for a sample of $n$ data points are given by:\n$$ m = \\frac{n \\sum_{i=1}^{n} x_i y_i - (\\sum_{i=1}^{n} x_i)(\\sum_{i=1}^{n} y_i)}{n \\sum_{i=1}^{n} x_i^2 - (\\sum_{i=1}^{n} x_i)^2} $$\n$$ b = \\bar{y} - m\\bar{x} = \\frac{1}{n} \\left( \\sum_{i=1}^{n} y_i - m \\sum_{i=1}^{n} x_i \\right) $$\nOnce $m$ and $b$ are determined, we can solve for the physical parameters. From the intercept, we directly obtain $\\kappa_\\infty$:\n$$ \\kappa_\\infty = b $$\nThen, using the expression for the slope, we can solve for the parameter $a$, assuming $\\kappa_\\infty \\neq 0$:\n$$ a = \\frac{m}{\\kappa_\\infty} = \\frac{m}{b} $$\nThe problem states that the phonon mean free path $\\lambda$ is to be identified with this parameter $a$, so:\n$$ \\lambda = a = \\frac{m}{b} $$\nThe provided data sets in each test case are constructed to perfectly satisfy the linear model. Consequently, the OLS regression will yield an exact fit, and we can determine the parameters $m$ and $b$ algebraically by solving the system of linear equations for any two data points.\n\nWe now apply this procedure to each test case.\n\nCase $1$: $L = [\\,100,\\,200,\\,400,\\,800\\,]$ nm and $\\kappa(L) = [\\,300,\\,200,\\,150,\\,125\\,]$ W/(m·K).\nWe select the first two data points. Let $x_1 = 1/100$ nm$^{-1}$ and $y_1 = 300$ W/(m·K), and $x_2 = 1/200$ nm$^{-1}$ and $y_2 = 200$ W/(m·K).\nWe solve the system:\n$$ 300 = b + m \\cdot \\frac{1}{100} $$\n$$ 200 = b + m \\cdot \\frac{1}{200} $$\nSubtracting the second equation from the first yields $100 = m(1/100 - 1/200) = m(1/200)$, which gives $m = 20000$ W·nm/(m·K).\nSubstituting $m$ into the first equation: $300 = b + 20000/100 = b + 200$, which gives $b = 100$ W/(m·K).\nThus, $\\kappa_\\infty = b = 100$ W/(m·K).\nThe mean free path is $\\lambda = m/b = 20000/100 = 200$ nm.\n\nCase $2$: $L = [\\,1000,\\,2000,\\,4000,\\,8000\\,]$ nm and $\\kappa(L) = [\\,375,\\,312.5,\\,281.25,\\,265.625\\,]$ W/(m·K).\nUsing the first two points, ($x_1=1/1000$, $y_1=375$) and ($x_2=1/2000$, $y_2=312.5$):\n$$ 375 = b + m \\cdot \\frac{1}{1000} $$\n$$ 312.5 = b + m \\cdot \\frac{1}{2000} $$\nSubtracting the second equation from the first gives $62.5 = m(1/2000)$, so $m = 125000$ W·nm/(m·K).\nSubstituting back: $375 = b + 125000/1000 = b + 125$, which gives $b = 250$ W/(m·K).\nThus, $\\kappa_\\infty = b = 250$ W/(m·K).\nThe mean free path is $\\lambda = m/b = 125000/250 = 500$ nm.\n\nCase $3$: $L = [\\,50,\\,75,\\,100,\\,150\\,]$ nm and $\\kappa(L) = [\\,90,\\,70,\\,60,\\,50\\,]$ W/(m·K).\nUsing the first two points, ($x_1=1/50$, $y_1=90$) and ($x_2=1/75$, $y_2=70$):\n$$ 90 = b + m \\cdot \\frac{1}{50} $$\n$$ 70 = b + m \\cdot \\frac{1}{75} $$\nFrom the first equation, $m = 50(90 - b)$. From the second, $m = 75(70 - b)$.\nEquating them: $50(90 - b) = 75(70 - b) \\implies 4500 - 50b = 5250 - 75b \\implies 25b = 750$, so $b = 30$ W/(m·K).\nThen $m = 50(90 - 30) = 3000$ W·nm/(m·K).\nThus, $\\kappa_\\infty = b = 30$ W/(m·K).\nThe mean free path is $\\lambda = m/b = 3000/30 = 100$ nm.\n\nCase $4$: $L = [\\,200,\\,400\\,]$ nm and $\\kappa(L) = [\\,120,\\,100\\,]$ W/(m·K).\nWith only two points, the line is determined exactly. Let ($x_1=1/200$, $y_1=120$) and ($x_2=1/400$, $y_2=100$):\n$$ 120 = b + m \\cdot \\frac{1}{200} $$\n$$ 100 = b + m \\cdot \\frac{1}{400} $$\nSubtracting the second from the first: $20 = m(1/200 - 1/400) = m(1/400)$, so $m = 8000$ W·nm/(m·K).\nSubstituting back: $100 = b + 8000/400 = b + 20$, which gives $b = 80$ W/(m·K).\nThus, $\\kappa_\\infty = b = 80$ W/(m·K).\nThe mean free path is $\\lambda = m/b = 8000/80 = 100$ nm.\n\nThe calculated parameters for each case are:\n- Case $1$: $\\kappa_\\infty = 100$ W/(m·K), $\\lambda = 200$ nm.\n- Case $2$: $\\kappa_\\infty = 250$ W/(m·K), $\\lambda = 500$ nm.\n- Case $3$: $\\kappa_\\infty = 30$ W/(m·K), $\\lambda = 100$ nm.\n- Case $4$: $\\kappa_\\infty = 80$ W/(m·K), $\\lambda = 100$ nm.\n\nThese results will be formatted and printed as required by the program.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes finite-size scaling of thermal conductivity to infer bulk\n    conductivity and phonon mean free path using linear regression.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (happy path, moderate lengths)\n        ([100, 200, 400, 800], [300, 200, 150, 125]),\n        # Case 2 (large-L regime)\n        ([1000, 2000, 4000, 8000], [375, 312.5, 281.25, 265.625]),\n        # Case 3 (short-L ballistic-leaning regime)\n        ([50, 75, 100, 150], [90, 70, 60, 50]),\n        # Case 4 (minimal data, two points)\n        ([200, 400], [120, 100]),\n    ]\n\n    results = []\n    for L_vals, kappa_vals in test_cases:\n        # Convert input lists to NumPy arrays for vectorized operations.\n        # The data types are explicitly float to ensure floating point division.\n        L_np = np.array(L_vals, dtype=float)\n        kappa_np = np.array(kappa_vals, dtype=float)\n\n        # The model is kappa(L) = kappa_inf * (1 + a/L).\n        # This linearizes to kappa(L) = kappa_inf + (kappa_inf * a) * (1/L).\n        # We fit a line y = m*x + b, where:\n        # y = kappa(L)\n        # x = 1/L\n        # The regression coefficients are then identified as:\n        # b = kappa_inf\n        # m = kappa_inf * a\n        \n        x = 1.0 / L_np\n        y = kappa_np\n\n        # Perform ordinary least squares for a first-degree polynomial (a line)\n        # using numpy.polyfit. It returns the coefficients [m, b] for y = mx + b.\n        m, b = np.polyfit(x, y, 1)\n\n        # From the relationships derived above, calculate the physical parameters.\n        # kappa_inf is the y-intercept of the fit.\n        kappa_inf = b\n        \n        # The phonon mean free path lambda is identified with parameter 'a'.\n        # a = m / kappa_inf.\n        # A check for kappa_inf being close to zero is good practice, though not\n        # necessary for the provided test cases.\n        if np.isclose(kappa_inf, 0):\n            # This case implies zero bulk conductivity, which is physically\n            # unusual and would make 'a' and 'lambda' indeterminate.\n            lambda_mfp = np.nan\n        else:\n            a = m / kappa_inf\n            lambda_mfp = a\n            \n        results.append(kappa_inf)\n        results.append(lambda_mfp)\n\n    # Final print statement in the exact required format.\n    # The output is a single flattened list of [kappa_inf_1, lambda_1, kappa_inf_2, lambda_2, ...].\n    # Each float is rounded to six decimal places.\n    print(f\"[{','.join(f'{val:.6f}' for val in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The accuracy of any transport coefficient calculated from NEMD depends on the correct microscopic expression for the corresponding flux. For molecular systems with rigid constraints, a frequently overlooked but critical component is the contribution of constraint forces to the virial part of the stress tensor. This exercise demonstrates the importance of this term by asking you to quantify the systematic error introduced in the shear viscosity, $\\eta$, when this contribution is neglected, providing a clear lesson on the rigorous application of the Irving-Kirkwood formalism. ",
            "id": "3469012",
            "problem": "You will write a complete, runnable program that compares shear viscosity estimates obtained from Non-Equilibrium Molecular Dynamics (NEMD) with and without including constraint-force contributions to the microscopic momentum flux and quantifies the resulting bias. The scenario is a homogeneous simple fluid composed of rigid diatomic molecules (rigid dumbbells) undergoing steady planar Couette flow at a small shear rate. The derivation must begin from fundamental base principles and accepted definitions, specifically Newton’s laws, the Irving–Kirkwood microscopic stress definition, and the linear constitutive relation linking the average shear stress to the shear rate.\n\nAssumptions and modeling base:\n- The microscopic shear stress tensor component is given by the Irving–Kirkwood expression, which in a particle system under Newton’s laws decomposes into kinetic and interaction (virial) parts, with internal constraints entering as additional pairwise forces. Denoting the off-diagonal shear component by $\\sigma_{xy}$, the full expression includes the constraint contribution.\n- Under steady homogeneous shear in the linear-response regime, the average shear stress satisfies $\\langle \\sigma_{xy} \\rangle = - \\eta \\, \\dot{\\gamma}$, where $\\eta$ is the shear viscosity and $\\dot{\\gamma}$ is the applied shear rate.\n- For a molecular fluid with holonomic internal constraints, the total microscopic shear stress decomposes as $\\sigma_{xy}(t) = \\sigma_{xy}^{\\mathrm{K}}(t) + \\sigma_{xy}^{\\mathrm{W}}(t) + \\sigma_{xy}^{\\mathrm{C}}(t)$, where $\\mathrm{K}$ denotes the kinetic part, $\\mathrm{W}$ the interparticle virial part that excludes constraint forces, and $\\mathrm{C}$ the virial due solely to constraint forces (Lagrange multipliers).\n- In the linear-response regime, the average of each contribution is assumed to be proportional to the shear rate, so that $\\langle \\sigma_{xy}^{\\alpha} \\rangle = - a_{\\alpha} \\, \\dot{\\gamma}$ for $\\alpha \\in \\{\\mathrm{K}, \\mathrm{W}, \\mathrm{C}\\}$ with nonnegative coefficients $a_{\\alpha}$ that depend on the thermodynamic state and molecular architecture but not on the shear rate in the linear regime. The true viscosity is then $\\eta_{\\mathrm{true}} = a_{\\mathrm{K}} + a_{\\mathrm{W}} + a_{\\mathrm{C}}$.\n- A common but incorrect practice is to neglect the constraint-force contribution to the flux when estimating viscosity from NEMD, which yields an “omit-constraints” estimate $\\eta_{\\mathrm{omit}} = a_{\\mathrm{K}} + a_{\\mathrm{W}}$.\n\nYour program must compute, for a set of test cases, the following four quantities for each case:\n1. The true viscosity $\\eta_{\\mathrm{true}}$,\n2. The omit-constraints viscosity $\\eta_{\\mathrm{omit}}$,\n3. The absolute bias $\\Delta \\eta = \\eta_{\\mathrm{omit}} - \\eta_{\\mathrm{true}}$,\n4. The fractional bias $\\delta = \\Delta \\eta / \\eta_{\\mathrm{true}}$.\n\nAll quantities are dimensionless in reduced units, so no physical units are required; report all values as dimensionless numbers.\n\nInput and data generation:\n- There is no external input. Your program must use the following test suite, where each test case is a tuple ($a_{\\mathrm{K}}$, $a_{\\mathrm{W}}$, $a_{\\mathrm{C}}$, $\\dot{\\gamma}$) that defines the linear-response coefficients and the shear rate.\n- Test suite:\n  - Case A (happy path, mixed contributions): ($a_{\\mathrm{K}}$, $a_{\\mathrm{W}}$, $a_{\\mathrm{C}}$, $\\dot{\\gamma}$) = (0.3, 0.5, 0.2, 0.1).\n  - Case B (no constraints, edge case): ($a_{\\mathrm{K}}$, $a_{\\mathrm{W}}$, $a_{\\mathrm{C}}$, $\\dot{\\gamma}$) = (0.4, 0.6, 0.0, 0.5).\n  - Case C (constraint dominated): ($a_{\\mathrm{K}}$, $a_{\\mathrm{W}}$, $a_{\\mathrm{C}}$, $\\dot{\\gamma}$) = (0.05, 0.05, 0.9, 0.2).\n  - Case D (boundary, very small shear rate): ($a_{\\mathrm{K}}$, $a_{\\mathrm{W}}$, $a_{\\mathrm{C}}$, $\\dot{\\gamma}$) = (0.3, 0.5, 0.2, $10^{-4}$).\n\nComputation requirements:\n- For each case, compute $\\eta_{\\mathrm{true}} = a_{\\mathrm{K}} + a_{\\mathrm{W}} + a_{\\mathrm{C}}$, $\\eta_{\\mathrm{omit}} = a_{\\mathrm{K}} + a_{\\mathrm{W}}$, $\\Delta \\eta = \\eta_{\\mathrm{omit}} - \\eta_{\\mathrm{true}}$, and $\\delta = \\Delta \\eta / \\eta_{\\mathrm{true}}$.\n- Round each reported number to $6$ decimal places.\n\nFinal output format:\n- Your program should produce a single line of output containing the results aggregated over all test cases in order A, B, C, D as a comma-separated list of lists, where each inner list is $[\\eta_{\\mathrm{true}}, \\eta_{\\mathrm{omit}}, \\Delta \\eta, \\delta]$ with each float rounded to $6$ decimal places. For example, the printed line should look like:\n\"[[x11,x12,x13,x14],[x21,x22,x23,x24],[x31,x32,x33,x34],[x41,x42,x43,x44]]\"\nwhere $x_{ij}$ are the numeric entries.\n\nDeliverables:\n- A complete and runnable program in Python that implements the above and prints the final result line exactly as specified.",
            "solution": "We begin from Newton’s laws for a classical many-body system and the Irving–Kirkwood definition of the microscopic stress tensor. For particles with positions $\\mathbf{r}_{i}$, velocities $\\mathbf{v}_{i}$, masses $m_{i}$, and pairwise forces $\\mathbf{F}_{ij}$, the Irving–Kirkwood shear stress component $\\sigma_{xy}$ can be written as the sum of a kinetic term and a virial term,\n$$\n\\sigma_{xy}(t) \\;=\\; - \\frac{1}{V}\\left[\\sum_{i} m_{i} v_{i,x}(t) v_{i,y}(t) \\;+\\; \\frac{1}{2}\\sum_{i\\neq j} r_{ij,x}(t)\\, F_{ij,y}(t)\\right],\n$$\nwhere $V$ is the system volume, $r_{ij,x} = r_{i,x} - r_{j,x}$, and $F_{ij,y}$ is the $y$-component of the force on particle $i$ due to $j$. In a molecular fluid with holonomic constraints (for example, rigid bond-length constraints), the total pairwise forces decompose into physical interaction forces and constraint forces generated by Lagrange multipliers. Denoting the constraint force between constrained partners $a$ and $b$ as $\\mathbf{F}^{(\\mathrm{C})}_{ab}$, the virial splits accordingly:\n$$\n\\sigma_{xy}(t) \\;=\\; \\sigma_{xy}^{\\mathrm{K}}(t) \\;+\\; \\sigma_{xy}^{\\mathrm{W}}(t) \\;+\\; \\sigma_{xy}^{\\mathrm{C}}(t),\n$$\nwith\n$$\n\\sigma_{xy}^{\\mathrm{K}}(t) = -\\frac{1}{V}\\sum_{i} m_{i} v_{i,x}(t) v_{i,y}(t), \\quad\n\\sigma_{xy}^{\\mathrm{W}}(t) = -\\frac{1}{2V}\\sum_{i\\neq j}^{\\text{non-constraint}} r_{ij,x}(t) F_{ij,y}(t), \\quad\n\\sigma_{xy}^{\\mathrm{C}}(t) = -\\frac{1}{2V}\\sum_{(a,b)} r_{ab,x}(t) F^{(\\mathrm{C})}_{ab,y}(t).\n$$\nUnder steady planar Couette flow with shear rate $\\dot{\\gamma}$ in the linear-response regime, the constitutive relation is\n$$\n\\langle \\sigma_{xy} \\rangle \\;=\\; - \\eta \\, \\dot{\\gamma},\n$$\nwhere $\\eta$ is the shear viscosity, and $\\langle \\cdot \\rangle$ denotes a stationary ensemble or long-time average. It follows that each additive microscopic contribution has a corresponding average that is linear in $\\dot{\\gamma}$ at small $\\dot{\\gamma}$:\n$$\n\\langle \\sigma_{xy}^{\\mathrm{K}} \\rangle \\;=\\; - a_{\\mathrm{K}}\\, \\dot{\\gamma}, \\quad\n\\langle \\sigma_{xy}^{\\mathrm{W}} \\rangle \\;=\\; - a_{\\mathrm{W}}\\, \\dot{\\gamma}, \\quad\n\\langle \\sigma_{xy}^{\\mathrm{C}} \\rangle \\;=\\; - a_{\\mathrm{C}}\\, \\dot{\\gamma},\n$$\nwith nonnegative, shear-rate independent coefficients $a_{\\mathrm{K}}$, $a_{\\mathrm{W}}$, and $a_{\\mathrm{C}}$ that depend on state variables and molecular architecture. Summing these averages yields\n$$\n\\langle \\sigma_{xy} \\rangle \\;=\\; - (a_{\\mathrm{K}} + a_{\\mathrm{W}} + a_{\\mathrm{C}})\\, \\dot{\\gamma} \\;\\equiv\\; - \\eta_{\\mathrm{true}}\\, \\dot{\\gamma},\n$$\nso the true viscosity is\n$$\n\\eta_{\\mathrm{true}} \\;=\\; a_{\\mathrm{K}} + a_{\\mathrm{W}} + a_{\\mathrm{C}}.\n$$\nIf one erroneously neglects the constraint-force contribution when forming the flux, the measured average becomes\n$$\n\\langle \\sigma_{xy} \\rangle_{\\text{omit}} \\;=\\; \\langle \\sigma_{xy}^{\\mathrm{K}} \\rangle + \\langle \\sigma_{xy}^{\\mathrm{W}} \\rangle \\;=\\; - (a_{\\mathrm{K}} + a_{\\mathrm{W}})\\, \\dot{\\gamma},\n$$\nand the corresponding omit-constraints viscosity is\n$$\n\\eta_{\\mathrm{omit}} \\;=\\; a_{\\mathrm{K}} + a_{\\mathrm{W}}.\n$$\nTherefore, the absolute bias introduced by neglecting constraint-force contributions is\n$$\n\\Delta \\eta \\;\\equiv\\; \\eta_{\\mathrm{omit}} - \\eta_{\\mathrm{true}} \\;=\\; (a_{\\mathrm{K}} + a_{\\mathrm{W}}) - (a_{\\mathrm{K}} + a_{\\mathrm{W}} + a_{\\mathrm{C}}) \\;=\\; - a_{\\mathrm{C}},\n$$\nwhich is nonpositive and equals minus the constraint coefficient. The fractional bias relative to the true viscosity is\n$$\n\\delta \\;\\equiv\\; \\frac{\\Delta \\eta}{\\eta_{\\mathrm{true}}} \\;=\\; - \\frac{a_{\\mathrm{C}}}{a_{\\mathrm{K}} + a_{\\mathrm{W}} + a_{\\mathrm{C}}}.\n$$\nThese expressions show that the bias does not depend on the magnitude of the shear rate in the linear-response regime; rather, it depends solely on the fraction of the total viscosity arising from constraint forces.\n\nAlgorithmic design for the program:\n1. For each test case, read the tuple $(a_{\\mathrm{K}}, a_{\\mathrm{W}}, a_{\\mathrm{C}}, \\dot{\\gamma})$.\n2. Compute $\\eta_{\\mathrm{true}} = a_{\\mathrm{K}} + a_{\\mathrm{W}} + a_{\\mathrm{C}}$.\n3. Compute $\\eta_{\\mathrm{omit}} = a_{\\mathrm{K}} + a_{\\mathrm{W}}$.\n4. Compute $\\Delta \\eta = - a_{\\mathrm{C}}$.\n5. Compute $\\delta = \\Delta \\eta / \\eta_{\\mathrm{true}}$ with the convention that if $\\eta_{\\mathrm{true}} = 0$ then $\\delta$ is defined as $0$ to avoid division by zero, although this case does not occur in the provided suite because $a_{\\mathrm{K}} + a_{\\mathrm{W}} + a_{\\mathrm{C}} > 0$.\n6. Round each number to $6$ decimal places for reporting.\n7. Aggregate the results in the order A, B, C, D as a list of lists $[\\eta_{\\mathrm{true}}, \\eta_{\\mathrm{omit}}, \\Delta \\eta, \\delta]$ and print a single line string representation of this list.\n\nVerification on the provided test suite:\n- Case A: $(a_{\\mathrm{K}}, a_{\\mathrm{W}}, a_{\\mathrm{C}}, \\dot{\\gamma}) = ($0.3$, $0.5$, $0.2$, $0.1$)$. Then $\\eta_{\\mathrm{true}} = $1.0$, $\\eta_{\\mathrm{omit}} = $0.8$, $\\Delta \\eta = -$0.2$, $\\delta = -$0.2$.\n- Case B: $(a_{\\mathrm{K}}, a_{\\mathrm{W}}, a_{\\mathrm{C}}, \\dot{\\gamma}) = ($0.4$, $0.6$, $0.0$, $0.5$)$. Then $\\eta_{\\mathrm{true}} = $1.0$, $\\eta_{\\mathrm{omit}} = $1.0$, $\\Delta \\eta = $0.0$, $\\delta = $0.0$.\n- Case C: $(a_{\\mathrm{K}}, a_{\\mathrm{W}}, a_{\\mathrm{C}}, \\dot{\\gamma}) = ($0.05$, $0.05$, $0.9$, $0.2$)$. Then $\\eta_{\\mathrm{true}} = $1.0$, $\\eta_{\\mathrm{omit}} = $0.1$, $\\Delta \\eta = -$0.9$, $\\delta = -$0.9$.\n- Case D: $(a_{\\mathrm{K}}, a_{\\mathrm{W}}, a_{\\mathrm{C}}, \\dot{\\gamma}) = ($0.3$, $0.5$, $0.2$, $10^{-4}$)$. Identical to Case A for viscosities and biases in linear response: $\\eta_{\\mathrm{true}} = $1.0$, $\\eta_{\\mathrm{omit}} = $0.8$, $\\Delta \\eta = -$0.2$, $\\delta = -$0.2$.\n\nThe program implements these calculations and prints the results as a single line in the specified format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_biases(a_k, a_w, a_c, gdot):\n    # True viscosity (dimensionless, reduced units)\n    eta_true = a_k + a_w + a_c\n    # Omit-constraints viscosity\n    eta_omit = a_k + a_w\n    # Absolute bias\n    delta_eta = eta_omit - eta_true  # equals -a_c\n    # Fractional bias, safe guard for zero (not expected in provided tests)\n    frac_bias = 0.0 if eta_true == 0.0 else delta_eta / eta_true\n    return eta_true, eta_omit, delta_eta, frac_bias\n\ndef rounded_list(vals, decimals=6):\n    return [float(f\"{v:.{decimals}f}\") for v in vals]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (a_K, a_W, a_C, gamma_dot)\n    test_cases = [\n        (0.3, 0.5, 0.2, 0.1),     # Case A\n        (0.4, 0.6, 0.0, 0.5),     # Case B\n        (0.05, 0.05, 0.9, 0.2),   # Case C\n        (0.3, 0.5, 0.2, 1e-4),    # Case D\n    ]\n\n    results = []\n    for a_k, a_w, a_c, gdot in test_cases:\n        eta_true, eta_omit, delta_eta, frac_bias = compute_biases(a_k, a_w, a_c, gdot)\n        results.append(rounded_list([eta_true, eta_omit, delta_eta, frac_bias], decimals=6))\n\n    # Final print statement in the exact required format.\n    # Single line containing list of lists with 4 floats per case.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}