{
    "hands_on_practices": [
        {
            "introduction": "在计算材料科学中，一个常见的核心任务是将有限尺寸模拟的结果外推到热力学极限。本练习将贝叶斯线性回归应用于一个实际的有限尺寸标度模型，旨在从含有噪声的模拟数据中推断点缺陷的形成能。通过这个实践，您将学习如何构建设计矩阵，应用贝叶斯定理来更新参数的后验分布，并最终量化外推物理量的不确定性，这是评估计算预测可靠性的基本技能。",
            "id": "3499812",
            "problem": "给定一个用于晶体材料中缺陷形成能的有限尺寸标度模型，该材料使用包含 $N$ 个原子的周期性超胞进行模拟。该模型为\n$$\nE_f(N) = E_\\infty + \\frac{a}{N} + \\frac{b}{N^{3/2}},\n$$\n其中 $E_f(N)$ 是以电子伏特 (eV) 为单位测得的缺陷形成能，$E_\\infty$ 是以 eV 为单位的热力学极限形成能，$a$ 和 $b$ 是有限尺寸修正系数。参数 $a$ 和 $b$ 具有不确定性，必须作为随机变量处理。观测到的能量 $E_f(N)$ 受到独立同分布的加性测量噪声的影响，该噪声被建模为均值为零、方差已知的 $\\sigma^2$ 的高斯分布。\n\n您的任务是实现一个程序，通过在以下假设下使用贝叶斯推断计算 $E_\\infty$ 的后验分布，来进行不确定性量化和误差传播：\n- 测量模型在参数上是线性的，并且具有加性高斯噪声，即 $E_f(N_i)$ 由 $E_\\infty + a/N_i + b/N_i^{3/2}$ 加上方差为 $\\sigma^2$ 的高斯噪声建模。\n- 参数的先验是高斯分布。$a$ 和 $b$ 的不确定性由有限的先验方差编码。通过使用较大的先验方差，将 $E_\\infty$ 的先验视为弱信息或无信息先验。\n\n从条件概率和贝叶斯定理的定义以及高斯似然和高斯先验的假设出发，推导出一个算法来计算 $E_\\infty$ 的后验均值和方差。然后用它为下面的每个测试用例计算 $E_\\infty$ 的中心 $0.95$ 置信区间。所有输出必须以电子伏特 (eV) 表示，并四舍五入到六位小数。\n\n程序必须实现以下参数集的测试套件。每个测试用例提供：\n- 超胞尺寸 $N_i$ 的列表。\n- 以 eV 为单位的测量形成能 $E_f(N_i)$ 的列表。\n- 以 $\\text{eV}^2$ 为单位的已知测量噪声方差 $\\sigma^2$。\n- 以 eV 和 eV 标度单位表示的先验均值向量 $\\mu_0 = [\\mu_{E_\\infty}, \\mu_a, \\mu_b]$。\n- 以 $\\text{eV}^2$ 为单位的对角先验协方差矩阵 $\\Sigma_0 = \\mathrm{diag}([\\sigma^2_{E_\\infty}, \\sigma^2_a, \\sigma^2_b])$。\n\n测试套件：\n1. 具有多种尺寸和中等噪声的正常路径：\n   - $N = [\\,64,\\,216,\\,512,\\,1000\\,]$\n   - $E_f(N) = [\\,4.529063,\\,3.731086,\\,3.443474,\\,3.360513\\,]$ in eV\n   - $\\sigma^2 = 0.0009$ in $\\text{eV}^2$\n   - $\\mu_0 = [\\,3.0,\\,100.0,\\,-200.0\\,]$\n   - $\\Sigma_0 = \\mathrm{diag}([\\,10000.0,\\,2500.0,\\,10000.0\\,])$\n2. 尺寸最小的边界条件：\n   - $N = [\\,64,\\,216\\,]$\n   - $E_f(N) = [\\,4.534063,\\,3.716086\\,]$ in eV\n   - $\\sigma^2 = 0.0009$ in $\\text{eV}^2$\n   - $\\mu_0 = [\\,3.0,\\,100.0,\\,-200.0\\,]$\n   - $\\Sigma_0 = \\mathrm{diag}([\\,10000.0,\\,900.0,\\,3600.0\\,])$\n3. 尺寸相近且较大的病态设计：\n   - $N = [\\,800,\\,900,\\,1000\\,]$\n   - $E_f(N) = [\\,4.162897,\\,4.099815,\\,4.084189\\,]$ in eV\n   - $\\sigma^2 = 0.0025$ in $\\text{eV}^2$\n   - $\\mu_0 = [\\,3.0,\\,200.0,\\,-400.0\\,]$\n   - $\\Sigma_0 = \\mathrm{diag}([\\,1000.0,\\,10000.0,\\,22500.0\\,])$\n4. 强偏置先验场景：\n   - $N = [\\,64,\\,216,\\,512,\\,1000\\,]$\n   - $E_f(N) = [\\,4.062500,\\,2.847531,\\,2.647191,\\,2.542649\\,]$ in eV\n   - $\\sigma^2 = 0.0004$ in $\\text{eV}^2$\n   - $\\mu_0 = [\\,2.0,\\,-100.0,\\,-300.0\\,]$\n   - $\\Sigma_0 = \\mathrm{diag}([\\,500.0,\\,100.0,\\,400.0\\,])$\n\n算法要求：\n- 基于模型 $E_f(N) = E_\\infty + a/N + b/N^{3/2}$ 构建线性设计矩阵。\n- 使用高斯似然和高斯先验来获得参数上的高斯后验分布。\n- 提取 $E_\\infty$ 的后验均值和方差。\n- 使用标准正态分位数计算 $E_\\infty$ 的中心 $0.95$ 置信区间。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，其本身是一个包含三个浮点数的列表 $[\\,\\text{mean},\\,\\text{lower},\\,\\text{upper}\\,]$，表示 $E_\\infty$ 的值（单位为 eV），所有数值均四舍五入到六位小数。例如：\n$[\\, [\\,x_1,\\,\\ell_1,\\,u_1\\,],\\,[\\,x_2,\\,\\ell_2,\\,u_2\\,],\\,[\\,x_3,\\,\\ell_3,\\,u_3\\,],\\,[\\,x_4,\\,\\ell_4,\\,u_4\\,]\\,]$。",
            "solution": "用户提供了一个关于贝叶斯推断应用于计算材料科学中有限尺寸标度模型的问题。该问题是推导并实现一个算法，以计算模型参数 $E_\\infty$ 的后验分布及其置信区间。\n\n### 第 1 步：问题验证\n\n**提取给定条件：**\n- **模型方程**：缺陷形成能 $E_f(N)$ 被建模为超胞尺寸 $N$ 的函数：\n$$ E_f(N) = E_\\infty + \\frac{a}{N} + \\frac{b}{N^{3/2}} $$\n其中 $\\theta = [E_\\infty, a, b]^T$ 是待推断的参数。\n- **测量模型**：观测到的能量 $E_f(N_i)$ 受到独立同分布 (IID) 的加性高斯噪声的影响，该噪声均值为 $0$，方差已知为 $\\sigma^2$。这定义了似然函数。\n- **先验分布**：参数 $\\theta$ 的先验是一个多元高斯分布 $p(\\theta) = \\mathcal{N}(\\theta|\\mu_0, \\Sigma_0)$，具有给定的先验均值向量 $\\mu_0$ 和对角先验协方差矩阵 $\\Sigma_0$。\n- **目标**：计算参数 $E_\\infty$ 的后验均值和中心 $0.95$ 置信区间。\n- **测试用例**：提供了四个具体的测试用例，每个用例都有一组超胞尺寸 $\\{N_i\\}$、相应的测量能量 $\\{E_f(N_i)\\}$、噪声方差 $\\sigma^2$、先验均值 $\\mu_0$ 和先验协方差 $\\Sigma_0$。\n\n**使用提取的给定条件进行验证：**\n1.  **科学依据**：该问题具有科学合理性。有限尺寸标度模型是凝聚态物理和材料科学中的标准工具，用于将有限系统模拟的结果外推到热力学极限。贝叶斯线性回归是统计推断中的一种基本且稳健的方法。所选模型和方法是恰当且成熟的。\n2.  **适定性**：该问题是适定的。它涉及为具有高斯噪声和高斯先验的线性模型参数寻找后验分布。这是贝叶斯统计中的一个标准共轭先验场景，它保证了存在一个唯一的、定义明确的高斯后验分布。提供一个满秩的先验协方差矩阵 $\\Sigma_0$ 确保了即使数据本身不足以识别所有参数（例如，在测试用例2中，数据点的数量少于参数的数量），后验分布也是明确定义的。\n3.  **客观性**：该问题使用精确的数学和统计语言表述，没有主观或含糊的术语。\n4.  **完整性与一致性**：为每个测试用例提供了所有必要的数据和参数（$\\{N_i\\}$, $\\{E_f(N_i)\\}$, $\\sigma^2$, $\\mu_0$, $\\Sigma_0$）。单位和维度在整个问题中保持一致。\n5.  **无其他缺陷**：该问题并非无关紧要、比喻性的，也未受任何其他无效性标准的影响。测试用例设计精良，旨在探究模型的不同方面，如病态条件和先验的影响。\n\n**结论：**\n该问题是有效的。它是一项定义明确的应用贝叶斯统计任务，基于计算材料科学中的一个现实场景。\n\n### 第 2 步：原则性解决方案\n\n该问题可以被构建为一个贝叶斯线性回归问题。目标是在给定一组 $M$ 个测量值的情况下，推断参数向量 $\\theta = [E_\\infty, a, b]^T$。\n\n**1. 线性模型构建**\n设观测能量向量为 $\\mathbf{y} = [E_f(N_1), E_f(N_2), \\dots, E_f(N_M)]^T$。对于每个测量 $i=1, \\dots, M$，模型方程为：\n$$ E_f(N_i) = [1, N_i^{-1}, N_i^{-3/2}] \\begin{pmatrix} E_\\infty \\\\ a \\\\ b \\end{pmatrix} $$\n我们可以将其写成矩阵形式：\n$$ \\mathbf{y} = X\\theta + \\mathbf{\\epsilon} $$\n其中 $X$ 是 $M \\times 3$ 的设计矩阵，$\\mathbf{\\epsilon}$ 是测量噪声向量。$X$ 的第 $i$ 行由 $\\mathbf{x}_i^T = [1, N_i^{-1}, N_i^{-3/2}]$ 给出。\n\n**2. 似然函数**\n假设测量噪声 $\\mathbf{\\epsilon}$ 是均值为零、方差为 $\\sigma^2$ 的独立同分布高斯噪声。这意味着 $\\mathbf{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 I)$，其中 $I$ 是 $M \\times M$ 的单位矩阵。在给定参数 $\\theta$ 的条件下观测到数据 $\\mathbf{y}$ 的似然为：\n$$ p(\\mathbf{y}|\\theta, \\sigma^2) = \\mathcal{N}(\\mathbf{y}|X\\theta, \\sigma^2 I) \\propto \\exp\\left( -\\frac{1}{2\\sigma^2}(\\mathbf{y} - X\\theta)^T(\\mathbf{y} - X\\theta) \\right) $$\n\n**3. 先验分布**\n关于参数 $\\theta$ 的先验信念由一个均值为 $\\mu_0$、协方差为 $\\Sigma_0$ 的多元高斯分布建模：\n$$ p(\\theta) = \\mathcal{N}(\\theta|\\mu_0, \\Sigma_0) \\propto \\exp\\left( -\\frac{1}{2}(\\theta - \\mu_0)^T\\Sigma_0^{-1}(\\theta - \\mu_0) \\right) $$\n\n**4. 后验分布**\n根据贝叶斯定理，参数的后验分布正比于似然和先验的乘积：\n$$ p(\\theta|\\mathbf{y}, \\sigma^2) \\propto p(\\mathbf{y}|\\theta, \\sigma^2) p(\\theta) $$\n由于似然（作为 $\\theta$ 的函数）和先验都是高斯分布，因此后验也是一个高斯分布，$p(\\theta|\\mathbf{y}, \\sigma^2) = \\mathcal{N}(\\theta|\\mu_p, \\Sigma_p)$。后验的对数（不计常数项）为：\n$$ \\ln p(\\theta|\\mathbf{y}) = -\\frac{1}{2\\sigma^2}(\\mathbf{y} - X\\theta)^T(\\mathbf{y} - X\\theta) -\\frac{1}{2}(\\theta - \\mu_0)^T\\Sigma_0^{-1}(\\theta - \\mu_0) + \\text{const.} $$\n展开并收集关于 $\\theta$ 的项：\n$$ \\ln p(\\theta|\\mathbf{y}) = -\\frac{1}{2} \\left[ \\theta^T \\left(\\frac{1}{\\sigma^2}X^T X + \\Sigma_0^{-1}\\right)\\theta - 2\\theta^T \\left(\\frac{1}{\\sigma^2}X^T\\mathbf{y} + \\Sigma_0^{-1}\\mu_0\\right) \\right] + \\text{const.} $$\n通过对 $\\theta$ 配方，我们可以确定后验协方差 $\\Sigma_p$ 和均值 $\\mu_p$。多元高斯指数的一般形式为 $-\\frac{1}{2}(\\theta - \\mu_p)^T\\Sigma_p^{-1}(\\theta - \\mu_p) = -\\frac{1}{2}(\\theta^T\\Sigma_p^{-1}\\theta - 2\\theta^T\\Sigma_p^{-1}\\mu_p + \\dots)$。比较各项，我们得到后验协方差的逆（或精度矩阵）：\n$$ \\Sigma_p^{-1} = \\Sigma_0^{-1} + \\frac{1}{\\sigma^2}X^TX $$\n以及后验均值：\n$$ \\mu_p = \\Sigma_p \\left( \\Sigma_0^{-1}\\mu_0 + \\frac{1}{\\sigma^2}X^T\\mathbf{y} \\right) $$\n其中后验协方差为 $\\Sigma_p = (\\Sigma_p^{-1})^{-1}$。\n\n**5. $E_\\infty$ 的边际后验分布和置信区间**\n联合后验分布 $p(\\theta|\\mathbf{y}, \\sigma^2)$ 是一个多元高斯分布。任何单个参数的边际分布也是高斯分布。我们感兴趣的是 $E_\\infty$，即向量 $\\theta$ 的第一个分量。\n- $E_\\infty$ 的后验均值是后验均值向量 $\\mu_p$ 的第一个元素：\n$$ \\mu_{p, E_\\infty} = (\\mu_p)_1 $$\n- $E_\\infty$ 的后验方差是后验协方差矩阵 $\\Sigma_p$ 的第一个对角元素：\n$$ \\sigma^2_{p, E_\\infty} = (\\Sigma_p)_{11} $$\n后验标准差是 $\\sigma_{p, E_\\infty} = \\sqrt{\\sigma^2_{p, E_\\infty}}$。\n\n$E_\\infty$ 的中心 $0.95$ 置信区间由其高斯后验分布构建。该区间由以下公式给出：\n$$ [\\mu_{p, E_\\infty} - z \\cdot \\sigma_{p, E_\\infty}, \\quad \\mu_{p, E_\\infty} + z \\cdot \\sigma_{p, E_\\infty}] $$\n其中 $z$ 是标准正态分布中对应于累积概率为 $1 - (1 - 0.95)/2 = 0.975$ 的分位数。该值为 $z \\approx 1.959964$。\n\n**算法摘要：**\n对于每个测试用例：\n1.  接收输入：$\\{N_i\\}$, $\\{E_f(N_i)\\}$, $\\sigma^2$, $\\mu_0$, $\\Sigma_0$。\n2.  构建数据向量 $\\mathbf{y}$ 和设计矩阵 $X$。\n3.  计算先验协方差的逆矩阵 $\\Sigma_0^{-1}$。\n4.  计算矩阵乘积 $X^TX$ 和 $X^T\\mathbf{y}$。\n5.  计算后验协方差的逆矩阵 $\\Sigma_p^{-1} = \\Sigma_0^{-1} + (1/\\sigma^2)X^TX$。\n6.  求逆以得到后验协方差 $\\Sigma_p = (\\Sigma_p^{-1})^{-1}$。\n7.  计算后验均值向量 $\\mu_p = \\Sigma_p ( \\Sigma_0^{-1}\\mu_0 + (1/\\sigma^2)X^T\\mathbf{y} )$。\n8.  提取后验均值 $\\mu_{p, E_\\infty} = (\\mu_p)_1$ 和方差 $\\sigma^2_{p, E_\\infty} = (\\Sigma_p)_{11}$。\n9.  计算标准差 $\\sigma_{p, E_\\infty} = \\sqrt{\\sigma^2_{p, E_\\infty}}$。\n10. 确定 $0.95$ 置信区间的 $z$ 分数。\n11. 计算置信区间的下界和上界。\n12. 将结果格式化为 $[\\text{mean}, \\text{lower bound}, \\text{upper bound}]$，并四舍五入到六位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to solve the Bayesian inference problem for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1. Happy path with multiple sizes and moderate noise\n        {\n            'N': [64., 216., 512., 1000.],\n            'Ef': [4.529063, 3.731086, 3.443474, 3.360513],\n            'sigma2': 0.0009,\n            'mu0': [3.0, 100.0, -200.0],\n            'Sigma0_diag': [10000.0, 2500.0, 10000.0]\n        },\n        # 2. Boundary condition with minimal sizes\n        {\n            'N': [64., 216.],\n            'Ef': [4.534063, 3.716086],\n            'sigma2': 0.0009,\n            'mu0': [3.0, 100.0, -200.0],\n            'Sigma0_diag': [10000.0, 900.0, 3600.0]\n        },\n        # 3. Ill-conditioned design with close, large sizes\n        {\n            'N': [800., 900., 1000.],\n            'Ef': [4.162897, 4.099815, 4.084189],\n            'sigma2': 0.0025,\n            'mu0': [3.0, 200.0, -400.0],\n            'Sigma0_diag': [1000.0, 10000.0, 22500.0]\n        },\n        # 4. Strongly biased prior scenario\n        {\n            'N': [64., 216., 512., 1000.],\n            'Ef': [4.062500, 2.847531, 2.647191, 2.542649],\n            'sigma2': 0.0004,\n            'mu0': [2.0, -100.0, -300.0],\n            'Sigma0_diag': [500.0, 100.0, 400.0]\n        }\n    ]\n\n    results = []\n    \n    # Z-score for a 95% credible interval\n    z_score = norm.ppf(1 - (1 - 0.95) / 2.0)\n\n    for case in test_cases:\n        N = np.array(case['N'], dtype=float)\n        y = np.array(case['Ef'], dtype=float)\n        sigma2 = case['sigma2']\n        mu0 = np.array(case['mu0'], dtype=float)\n        Sigma0 = np.diag(case['Sigma0_diag'])\n        \n        # 1. Construct the design matrix X\n        # The model is E_f(N) = E_inf * 1 + a * N^(-1) + b * N^(-3/2)\n        X = np.c_[np.ones_like(N), 1.0/N, 1.0/N**1.5]\n        \n        # 2. Calculate the posterior distribution parameters\n        \n        # Inverse of the prior covariance matrix\n        Sigma0_inv = np.linalg.inv(Sigma0)\n        \n        # Precision (inverse variance) from the likelihood\n        likelihood_precision = 1.0 / sigma2\n        \n        # Calculate the inverse of the posterior covariance matrix (posterior precision)\n        # Sigma_p^-1 = Sigma_0^-1 + (1/sigma^2) * X^T * X\n        XtX = X.T @ X\n        Sigma_p_inv = Sigma0_inv + likelihood_precision * XtX\n        \n        # Calculate the posterior covariance matrix by inverting the precision matrix\n        Sigma_p = np.linalg.inv(Sigma_p_inv)\n        \n        # Calculate the posterior mean vector\n        # mu_p = Sigma_p * (Sigma_0^-1 * mu_0 + (1/sigma^2) * X^T * y)\n        Xty = X.T @ y\n        term_in_paren = Sigma0_inv @ mu0 + likelihood_precision * Xty\n        mu_p = Sigma_p @ term_in_paren\n        \n        # 3. Extract marginal posterior for E_infinity\n        # E_infinity is the first parameter\n        mean_E_inf = mu_p[0]\n        var_E_inf = Sigma_p[0, 0]\n        std_E_inf = np.sqrt(var_E_inf)\n        \n        # 4. Compute the 95% credible interval\n        margin_of_error = z_score * std_E_inf\n        lower_bound = mean_E_inf - margin_of_error\n        upper_bound = mean_E_inf + margin_of_error\n        \n        results.append([mean_E_inf, lower_bound, upper_bound])\n\n    # Format the final output string as specified\n    formatted_results = []\n    for res in results:\n        # Round each value to six decimal places and format as a string\n        formatted_list = [f\"{v:.6f}\" for v in res]\n        formatted_results.append(f\"[{','.join(formatted_list)}]\")\n        \n    final_output = f\"[{','.join(formatted_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "通常，我们必须将来自不完美实验数据的信息与理论知识相结合，以建立更稳健的物理模型，并对其预测能力进行量化。本实践探讨了一个非线性参数估计问题，在一个贝叶斯框架中，利用第一性原理计算的结果作为先验约束来拟合一个简化的一级共振模型。您将通过实践掌握如何使用拉普拉斯近似来表征后验分布，并将参数不确定性传播到外推的物理量上，从而深刻理解理论先验如何显著提高模型的预测精度。",
            "id": "3542512",
            "problem": "实现一个考虑不确定性的共振矩阵 (R-矩阵) 拟合，用于 $^{10}\\mathrm{B}(p,\\gamma)^{11}\\mathrm{C}$ 反应的简化单能级、单通道辐射俘获模型，并量化关于能级能量和约化宽度的高斯先验约束如何提高低能天体物理 $S$ 因子外推的精度。使用以下基本依据和定义作为出发点。\n\n1. 通过恒等式定义天体物理 $S$ 因子\n$$\nS(E) \\equiv \\sigma(E)\\, E\\, e^{2\\pi \\eta(E)},\n$$\n其中 $E$ 是质心能量，$\\sigma(E)$ 是辐射俘获截面，$\\eta(E)$ 是索末菲参数。\n\n2. 对于共振矩阵 (R-矩阵) 理论中轨道角动量 $\\ell=0$ 且光子宽度为常数的单个孤立能级，使用 Breit–Wigner 形式对俘获截面进行建模\n$$\n\\sigma(E) = \\frac{\\pi}{k^2(E)} \\, \\omega \\, \\frac{\\Gamma_p(E)\\, \\Gamma_\\gamma}{(E - E_\\lambda)^2 + \\left(\\frac{\\Gamma_p(E) + \\Gamma_\\gamma}{2}\\right)^2},\n$$\n在本练习中，自旋统计因子 $\\omega$ 固定为 $1$，能量依赖的质子宽度为\n$$\n\\Gamma_p(E) = 2\\, P_0(E)\\, \\gamma_p^2,\n$$\n其中 $\\gamma_p$ 是约化宽度振幅，$P_0(E)$ 是 s-波势垒穿透率。对于此问题，将穿透率近似为\n$$\nP_0(E) = e^{-2 \\pi \\eta(E)}.\n$$\n\n3. 使用自然核单位中的非相对论运动学计算每个组分：\n- 波数\n$$\nk(E) = \\frac{\\sqrt{2\\, \\mu\\, E}}{\\hbar c},\n$$\n其中 $\\mu$ 是以能量单位表示的约化质量。\n- 索末菲参数\n$$\n\\eta(E) = \\alpha Z_1 Z_2 \\sqrt{\\frac{\\mu}{2E}},\n$$\n其中 $Z_1 = 1$ 和 $Z_2 = 5$ 分别是入射粒子和靶核的电荷，$\\alpha$ 是精细结构常数。\n\n4. 采用以下常数和单位换算：\n- 精细结构常数 $\\alpha = 1/137.035999084$。\n- $^{10}\\mathrm{B}+p$ 的约化质量，以能量单位表示：$\\mu = \\mu_{\\mathrm{amu}}\\, (m_u c^2)$，其中 $\\mu_{\\mathrm{amu}} = \\frac{A_1 A_2}{A_1 + A_2}$，$A_1 = 1$，$A_2 = 10$，以及 $m_u c^2 = 931494.10242\\,\\mathrm{keV}$。\n- $\\hbar c = 197326.9804\\,\\mathrm{keV\\cdot fm}$。\n- $1\\,\\mathrm{b} = 100\\,\\mathrm{fm}^2$。\n- $S$ 因子必须以 $\\mathrm{keV\\cdot b}$ 为单位报告，能量必须以 $\\mathrm{keV}$ 处理。\n\n5. 合成数据生成协议 (所有解法均同样使用，无外部文件)：\n- 真实参数：$E_\\lambda^{(\\mathrm{true})} = 500\\,\\mathrm{keV}$，$\\gamma_p^{(\\mathrm{true})} = 0.70\\,\\mathrm{keV}^{1/2}$，$\\Gamma_\\gamma^{(\\mathrm{true})} = 0.20\\,\\mathrm{keV}$。\n- 测量能量：$E_i$ 从 $200\\,\\mathrm{keV}$ 到 $900\\,\\mathrm{keV}$ 线性等间距分布，共 $12$ 个点。\n- 计算无噪声的 $S_i^{(\\mathrm{true})} = S(E_i \\mid E_\\lambda^{(\\mathrm{true})}, \\gamma_p^{(\\mathrm{true})}, \\Gamma_\\gamma^{(\\mathrm{true})})$。\n- 指定独立的标准差为 $\\sigma_i = 0.05\\, S_i^{(\\mathrm{true})}$ 的高斯测量噪声，并使用固定的伪随机数种子 $123456$ 抽取观测数据 $y_i \\sim \\mathcal{N}(S_i^{(\\mathrm{true})}, \\sigma_i^2)$。\n\n6. 贝叶斯推断模型：\n- 参数为 $\\theta = (E_\\lambda, \\gamma_p, \\Gamma_\\gamma)$，约束条件为 $E_\\lambda \\in [200,900]\\,\\mathrm{keV}$，$\\gamma_p > 0$ 和 $\\Gamma_\\gamma > 0$。\n- 数据 $\\{(E_i,y_i,\\sigma_i)\\}_{i=1}^{N}$ 的似然函数是高斯的，\n$$\n\\mathcal{L}(\\theta) \\propto \\prod_{i=1}^{N} \\exp\\left[-\\frac{(y_i - S(E_i \\mid \\theta))^2}{2\\sigma_i^2}\\right].\n$$\n- (来自第一性原理约束的) 高斯先验被独立地施加于每个参数上：\n$$\nE_\\lambda \\sim \\mathcal{N}(\\mu_E, \\sigma_E^2), \\quad \\gamma_p \\sim \\mathcal{N}(\\mu_\\gamma, \\sigma_\\gamma^2), \\quad \\Gamma_\\gamma \\sim \\mathcal{N}(\\mu_\\Gamma, \\sigma_\\Gamma^2).\n$$\n\n7. 后验量化与外推：\n- 通过最小化负对数后验来计算最大后验 (MAP) 估计。\n- 使用拉普拉斯近似 (LA) 将 MAP 附近的后验近似为高斯分布：协方差是负对数后验在 MAP 处的黑塞矩阵的逆。\n- 预测在低能 $E_0 = 10\\,\\mathrm{keV}$ 处的天体物理 $S$ 因子，并通过线性误差传播量化其后验不确定性：\n$$\n\\mathrm{Var}[S(E_0)] \\approx \\nabla_\\theta S(E_0 \\mid \\hat{\\theta})^\\top \\, \\Sigma \\, \\nabla_\\theta S(E_0 \\mid \\hat{\\theta}),\n$$\n其中 $\\hat{\\theta}$ 是 MAP 估计，$\\Sigma$ 是 LA 协方差。\n\n实现以上内容，并评估以下三种先验情景 (测试套件)：\n\n- 案例 A (无信息)：$\\mu_E = 600\\,\\mathrm{keV}$，$\\sigma_E = 10^6\\,\\mathrm{keV}$；$\\mu_\\gamma = 1.50\\,\\mathrm{keV}^{1/2}$，$\\sigma_\\gamma = 10^3\\,\\mathrm{keV}^{1/2}$；$\\mu_\\Gamma = 0.40\\,\\mathrm{keV}$，$\\sigma_\\Gamma = 10^3\\,\\mathrm{keV}$。\n- 案例 B (中等第一性原理)：$\\mu_E = 520\\,\\mathrm{keV}$，$\\sigma_E = 50\\,\\mathrm{keV}$；$\\mu_\\gamma = 0.90\\,\\mathrm{keV}^{1/2}$，$\\sigma_\\gamma = 0.30\\,\\mathrm{keV}^{1/2}$；$\\mu_\\Gamma = 0.25\\,\\mathrm{keV}$，$\\sigma_\\Gamma = 0.10\\,\\mathrm{keV}$。\n- 案例 C (强第一性原理)：$\\mu_E = 500\\,\\mathrm{keV}$，$\\sigma_E = 5\\,\\mathrm{keV}$；$\\mu_\\gamma = 0.70\\,\\mathrm{keV}^{1/2}$，$\\sigma_\\gamma = 0.05\\,\\mathrm{keV}^{1/2}$；$\\mu_\\Gamma = 0.20\\,\\mathrm{keV}$，$\\sigma_\\Gamma = 0.02\\,\\mathrm{keV}$。\n\n数值要求和交付成果：\n\n- 使用中心有限差分公式计算在 MAP 处的负对数后验的黑塞矩阵和 $S(E_0)$ 关于 $(E_\\lambda,\\gamma_p,\\Gamma_\\gamma)$ 的梯度，步长自适应地选择为参数量级的一小部分。\n- 如果需要，通过向黑塞矩阵添加一个小的单位矩阵正倍数来稳定协方差求逆。\n- 对于每个案例 A、B、C，报告后验标准差 $\\sqrt{\\mathrm{Var}[S(E_0)]}$，单位为 $\\mathrm{keV\\cdot b}$，四舍五入到六位小数。\n- 你的程序应产生单行输出，包含一个用方括号括起来的逗号分隔列表的结果。\n\n所有带物理单位的量必须完全按规定处理，不使用角度。最终输出是三个浮点数，按顺序对应案例 A、B 和 C，每个都以 $\\mathrm{keV\\cdot b}$ 为单位，并四舍五入到六位小数。",
            "solution": "我们构建一个计算模型，用于在 $^{10}\\mathrm{B}(p,\\gamma)^{11}\\mathrm{C}$ 反应的单能级共振矩阵 (R-矩阵) 描述下，根据高斯先验约束进行天体物理 $S$ 因子的外推。该过程遵循一系列基于物理的步骤。\n\n1. 基本定义。天体物理 $S$ 因子定义为 $S(E) = \\sigma(E)\\, E\\, e^{2\\pi \\eta(E)}$，其中 $E$ 的单位是 $\\mathrm{keV}$，俘获截面 $\\sigma(E)$ 的单位是 $\\mathrm{b}$，$\\eta(E)$ 是索末菲参数。对于 $\\ell=0$ 且光子宽度为常数的孤立能级，Breit–Wigner 表达式给出 $\\sigma(E) = \\frac{\\pi}{k^2(E)} \\, \\omega \\, \\frac{\\Gamma_p(E)\\, \\Gamma_\\gamma}{(E - E_\\lambda)^2 + \\left(\\frac{\\Gamma_p(E) + \\Gamma_\\gamma}{2}\\right)^2}$。为了清晰起见，我们选择 $\\omega=1$。质子分宽度通过 $\\Gamma_p(E) = 2\\, P_0(E)\\, \\gamma_p^2$ 依赖于能量，并且我们将穿透率近似为 $P_0(E) = e^{-2 \\pi \\eta(E)}$，这抓住了低能带电粒子 s-波的主要隧穿依赖性。\n\n2. 运动学和单位。我们在混合核单位制下工作，能量单位为 $\\mathrm{keV}$，长度单位为 $\\mathrm{fm}$。波数为 $k(E) = \\sqrt{2\\, \\mu\\, E}/(\\hbar c)$，其中 $\\mu$ 是以 $\\mathrm{keV}$ 为单位的约化质量 (作为质量能量)，并且 $\\hbar c = 197326.9804\\,\\mathrm{keV\\cdot fm}$。索末菲参数为 $\\eta(E) = \\alpha Z_1 Z_2 \\sqrt{\\mu/(2E)}$，其中质子的 $Z_1=1$，$ ^{10}\\mathrm{B}$ 的 $Z_2=5$。约化质量为 $\\mu = \\mu_{\\mathrm{amu}} (m_u c^2)$，其中 $\\mu_{\\mathrm{amu}} = \\frac{A_1 A_2}{A_1 + A_2} = \\frac{1 \\cdot 10}{1+10}$，以及 $m_u c^2 = 931494.10242\\,\\mathrm{keV}$。如果 $k$ 的单位是 $\\mathrm{fm}^{-1}$，截面公式将以 $\\mathrm{fm}^2$ 为单位产生 $\\sigma(E)$；使用 $1\\,\\mathrm{b} = 100\\,\\mathrm{fm}^2$ 转换为靶。然后通过 $S(E) = \\sigma(E)\\, E\\, e^{2\\pi\\eta(E)}$ 得出天体物理 $S$ 因子的单位为 $\\mathrm{keV\\cdot b}$。\n\n3. 合成数据。我们生成模拟数据来模拟测量。使用固定的真实参数 $E_\\lambda^{(\\mathrm{true})} = 500\\,\\mathrm{keV}$，$\\gamma_p^{(\\mathrm{true})} = 0.70\\,\\mathrm{keV}^{1/2}$ 和 $\\Gamma_\\gamma^{(\\mathrm{true})} = 0.20\\,\\mathrm{keV}$，我们产生从 $200\\,\\mathrm{keV}$到 $900\\,\\mathrm{keV}$ 均匀分布的 $N=12$ 个能量点 $E_i$。无噪声值 $S_i^{(\\mathrm{true})}$ 由上述公式计算。使用伪随机数种子 $123456$ 添加标准差为 $\\sigma_i = 0.05\\, S_i^{(\\mathrm{true})}$ 的独立高斯噪声，从而产生观测值 $y_i$。\n\n4. 贝叶斯推断。我们采用高斯似然函数 $\\mathcal{L}(\\theta)\\propto \\exp\\left[-\\sum_i (y_i - S(E_i\\mid\\theta))^2/(2\\sigma_i^2)\\right]$ 和独立的高斯先验 $E_\\lambda\\sim\\mathcal{N}(\\mu_E,\\sigma_E^2)$，$\\gamma_p\\sim\\mathcal{N}(\\mu_\\gamma,\\sigma_\\gamma^2)$，以及 $\\Gamma_\\gamma\\sim\\mathcal{N}(\\mu_\\Gamma,\\sigma_\\Gamma^2)$。负对数后验 (不计与 $\\theta$ 无关的常数) 为\n$$\n\\mathcal{N}(\\theta) = \\frac{1}{2}\\sum_{i=1}^{N}\\frac{(y_i - S(E_i \\mid \\theta))^2}{\\sigma_i^2} + \\frac{1}{2}\\left(\\frac{E_\\lambda - \\mu_E}{\\sigma_E}\\right)^2 + \\frac{1}{2}\\left(\\frac{\\gamma_p - \\mu_\\gamma}{\\sigma_\\gamma}\\right)^2 + \\frac{1}{2}\\left(\\frac{\\Gamma_\\gamma - \\mu_\\Gamma}{\\sigma_\\Gamma}\\right)^2.\n$$\n我们通过在 $E_\\lambda\\in[200,900]\\,\\mathrm{keV}$，$\\gamma_p>0$ 和 $\\Gamma_\\gamma>0$ 约束条件下最小化 $\\mathcal{N}(\\theta)$ 来计算最大后验 (MAP) 估计 $\\hat{\\theta}$。\n\n5. 拉普拉斯近似和不确定性传播。为了量化在低能 $E_0 = 10\\,\\mathrm{keV}$ 处外推的 $S$ 因子的后验不确定性，我们通过一个高斯分布来近似 $\\hat{\\theta}$ 附近的后验，其协方差矩阵 $\\Sigma$ 等于 $\\mathcal{N}(\\theta)$ 在 $\\hat{\\theta}$ 处求值的黑塞矩阵 $H$ 的逆。我们通过中心有限差分数值计算 $H$：\n- 对于对角元素，\n$$\nH_{ii} \\approx \\frac{\\mathcal{N}(\\hat{\\theta}+h_i e_i) - 2\\mathcal{N}(\\hat{\\theta}) + \\mathcal{N}(\\hat{\\theta}-h_i e_i)}{h_i^2},\n$$\n- 对于 $i\\neq j$ 的非对角元素，\n$$\nH_{ij} \\approx \\frac{\\mathcal{N}(\\hat{\\theta}+h_i e_i + h_j e_j) - \\mathcal{N}(\\hat{\\theta}+h_i e_i - h_j e_j) - \\mathcal{N}(\\hat{\\theta}-h_i e_i + h_j e_j) + \\mathcal{N}(\\hat{\\theta}-h_i e_i - h_j e_j)}{4 h_i h_j},\n$$\n其中 $e_i$ 是坐标单位向量，$h_i$ 是选择为 $|\\hat{\\theta}_i|$ 一小部分的小步长，并设有安全下限以避免为零。\n\n我们类似地通过中心差分计算梯度 $g = \\nabla_\\theta S(E_0\\mid\\hat{\\theta})$。$S(E_0)$ 的线性化后验方差为\n$$\n\\mathrm{Var}[S(E_0)] \\approx g^\\top \\Sigma g,\n$$\n标准差是其平方根。\n\n6. 先验情景与预期。我们评估三种先验案例：A (无信息，极宽)，B (中等第一性原理约束) 和 C (强第一性原理约束)。通常，添加信息先验会增加 MAP 附近后验的曲率，从而缩小 $\\Sigma$ 并减小外推不确定性。因此，我们预期在 $E_0=10\\,\\mathrm{keV}$ 处的后验标准差近似满足 $\\mathrm{sd}_\\mathrm{C}  \\mathrm{sd}_\\mathrm{B}  \\mathrm{sd}_\\mathrm{A}$。\n\n7. 算法总结。\n- 计算常数 $\\alpha$、$\\mu$、$\\hbar c$ 和到靶的转换因子。\n- 实现 $k(E)$、$\\eta(E)$、$P_0(E)$、$\\Gamma_p(E)$、$\\sigma(E)$ 和 $S(E)$。\n- 使用指定的种子和噪声模型生成合成数据 $\\{E_i,y_i,\\sigma_i\\}$。\n- 对于每种先验情况，从一个合理的初始猜测开始，在边界条件下最小化 $\\mathcal{N}(\\theta)$，得到 $\\hat{\\theta}$。\n- 通过中心有限差分计算在 $\\hat{\\theta}$ 处的黑塞矩阵 $H$；如有必要，通过添加一个小的单位矩阵倍数来确保正定性以进行稳定；求逆得到 $\\Sigma$。\n- 计算在 $E_0=10\\,\\mathrm{keV}$ 处的梯度 $g$ 和后验标准差 $\\sqrt{g^\\top \\Sigma g}$。\n- 以单行逗号分隔列表的形式报告对应于案例 A, B, C 的三个浮点数，用方括号括起，单位为 $\\mathrm{keV\\cdot b}$，每个都四舍五入到六位小数。\n\n最终程序遵循这些步骤，并使用指定的伪随机数种子可复现地生成所需的输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import optimize\n\n# Constants\nALPHA = 1.0 / 137.035999084  # fine-structure constant\nHBAR_C_keV_fm = 197326.9804  # keV*fm\nAMU_C2_keV = 931_494.10242   # keV\nZ1 = 1\nZ2 = 5\n\n# Reduced mass mu in keV (mass-energy), using A1=1 (p) and A2=10 (B-10)\nA1 = 1.0\nA2 = 10.0\nmu_amu = (A1 * A2) / (A1 + A2)  # in atomic mass units\nMU_keV = mu_amu * AMU_C2_keV    # reduced mass energy in keV\n\n# Conversion: sigma in fm^2 - barns: 1 b = 100 fm^2\nFM2_TO_B = 1.0 / 100.0\n\ndef sommerfeld_eta(E_keV):\n    # E in keV\n    # eta = alpha Z1 Z2 sqrt(mu/(2E))\n    E = np.asarray(E_keV, dtype=float)\n    return ALPHA * Z1 * Z2 * np.sqrt(MU_keV / (2.0 * E))\n\ndef wavenumber_k_fm_inv(E_keV):\n    # k = sqrt(2 mu E) / (hbar c), with mu in keV, E in keV, k in fm^-1\n    return np.sqrt(2.0 * MU_keV * E_keV) / HBAR_C_keV_fm\n\ndef penetrability_P0(E_keV):\n    # s-wave penetrability approximation\n    eta = sommerfeld_eta(E_keV)\n    return np.exp(-2.0 * np.pi * eta)\n\ndef gamma_p_width(E_keV, gamma_p_keV_sqrt):\n    # Gamma_p(E) = 2 P0(E) gamma_p^2, returns keV\n    return 2.0 * penetrability_P0(E_keV) * (gamma_p_keV_sqrt ** 2)\n\ndef sigma_barns(E_keV, E_lambda_keV, gamma_p_keV_sqrt, Gamma_gamma_keV, omega=1.0):\n    # Breit-Wigner capture cross section in barns\n    k = wavenumber_k_fm_inv(E_keV)\n    Gamma_p = gamma_p_width(E_keV, gamma_p_keV_sqrt)\n    Gamma_tot = Gamma_p + Gamma_gamma_keV\n    numer = Gamma_p * Gamma_gamma_keV\n    denom = (E_keV - E_lambda_keV) ** 2 + (Gamma_tot / 2.0) ** 2\n    sigma_fm2 = (np.pi / (k ** 2)) * omega * (numer / denom)\n    return sigma_fm2 * FM2_TO_B\n\ndef s_factor_keV_b(E_keV, params):\n    # params: (E_lambda_keV, gamma_p_keV_sqrt, Gamma_gamma_keV)\n    E_lambda_keV, gamma_p_keV_sqrt, Gamma_gamma_keV = params\n    sigma_b = sigma_barns(E_keV, E_lambda_keV, gamma_p_keV_sqrt, Gamma_gamma_keV, omega=1.0)\n    eta = sommerfeld_eta(E_keV)\n    return sigma_b * E_keV * np.exp(2.0 * np.pi * eta)\n\ndef generate_synthetic_data(seed=123456):\n    rng = np.random.default_rng(seed)\n    # True parameters\n    E_lambda_true = 500.0  # keV\n    gamma_p_true = 0.70    # keV^0.5\n    Gamma_gamma_true = 0.20  # keV\n    # Energies\n    E_data = np.linspace(200.0, 900.0, 12)\n    S_true = s_factor_keV_b(E_data, (E_lambda_true, gamma_p_true, Gamma_gamma_true))\n    sigma = 0.05 * S_true  # 5% relative noise\n    y = rng.normal(loc=S_true, scale=sigma)\n    return E_data, y, sigma\n\ndef neg_log_posterior(theta, E_data, y, sigma, prior_mu, prior_sigma):\n    # theta = (E_lambda, gamma_p, Gamma_gamma)\n    # enforce positivity softly via bounds in optimizer; here just compute model\n    E_lambda, gamma_p, Gamma_gamma = theta\n    # Small penalty if parameters go non-physical (helps optimizer)\n    if gamma_p = 0 or Gamma_gamma = 0:\n        return 1e100\n    S_model = s_factor_keV_b(E_data, theta)\n    resid = (y - S_model) / sigma\n    nll = 0.5 * np.sum(resid ** 2)\n    # Gaussian prior penalties (independent)\n    prior_terms = 0.5 * (((E_lambda - prior_mu[0]) / prior_sigma[0]) ** 2 +\n                         ((gamma_p - prior_mu[1]) / prior_sigma[1]) ** 2 +\n                         ((Gamma_gamma - prior_mu[2]) / prior_sigma[2]) ** 2)\n    return nll + prior_terms\n\ndef finite_diff_hessian(f, x, step):\n    # Central finite difference Hessian for 3D x\n    x = np.asarray(x, dtype=float)\n    n = x.size\n    H = np.zeros((n, n), dtype=float)\n    fx = f(x)\n    # Diagonal terms\n    for i in range(n):\n        ei = np.zeros(n); ei[i] = 1.0\n        hi = step[i]\n        fp = f(x + hi * ei)\n        fm = f(x - hi * ei)\n        H[i, i] = (fp - 2.0 * fx + fm) / (hi ** 2)\n    # Off-diagonal terms\n    for i in range(n):\n        for j in range(i + 1, n):\n            ei = np.zeros(n); ei[i] = 1.0\n            ej = np.zeros(n); ej[j] = 1.0\n            hi = step[i]; hj = step[j]\n            fpp = f(x + hi * ei + hj * ej)\n            fpm = f(x + hi * ei - hj * ej)\n            fmp = f(x - hi * ei + hj * ej)\n            fmm = f(x - hi * ei - hj * ej)\n            val = (fpp - fpm - fmp + fmm) / (4.0 * hi * hj)\n            H[i, j] = val\n            H[j, i] = val\n    return H\n\ndef finite_diff_gradient_S(E0, theta, step):\n    # Central finite difference gradient of S(E0) wrt theta\n    theta = np.asarray(theta, dtype=float)\n    n = theta.size\n    g = np.zeros(n, dtype=float)\n    for i in range(n):\n        ei = np.zeros(n); ei[i] = 1.0\n        hi = step[i]\n        Sp = s_factor_keV_b(E0, theta + hi * ei)\n        Sm = s_factor_keV_b(E0, theta - hi * ei)\n        g[i] = (Sp - Sm) / (2.0 * hi)\n    return g\n\ndef map_and_uncertainty(E_data, y, sigma, prior_mu, prior_sigma, E0=10.0):\n    # Bounds: E_lambda in [200,900], gamma_p in [1e-6, 5], Gamma_gamma in [1e-6, 1]\n    bounds = [(200.0, 900.0), (1e-6, 5.0), (1e-6, 1.0)]\n    # Initial guess: prior mean projected into bounds\n    x0 = np.array([\n        np.clip(prior_mu[0], bounds[0][0], bounds[0][1]),\n        np.clip(prior_mu[1], bounds[1][0], bounds[1][1]),\n        np.clip(prior_mu[2], bounds[2][0], bounds[2][1]),\n    ], dtype=float)\n\n    def obj(theta_vec):\n        return neg_log_posterior(theta_vec, E_data, y, sigma, prior_mu, prior_sigma)\n\n    res = optimize.minimize(obj, x0, method=\"L-BFGS-B\", bounds=bounds, options={\"maxiter\": 1000})\n    theta_map = res.x\n\n    # Finite-difference steps relative to parameter scales\n    steps = np.array([\n        max(1e-3 * max(1.0, abs(theta_map[0])), 1e-3),\n        max(1e-3 * max(1.0, abs(theta_map[1])), 1e-4),\n        max(1e-3 * max(1.0, abs(theta_map[2])), 1e-4),\n    ], dtype=float)\n\n    # Hessian\n    H = finite_diff_hessian(obj, theta_map, steps)\n    # Stabilize Hessian if not positive definite\n    jitter = 1e-9\n    # Ensure symmetry\n    H = 0.5 * (H + H.T)\n    # Add jitter until invertible\n    Sigma = np.eye(3) # Fallback value\n    for _ in range(10):\n        try:\n            H_reg = H + jitter * np.eye(3)\n            # Check positive definiteness\n            if np.all(np.linalg.eigvalsh(H_reg) > 0):\n                Sigma = np.linalg.inv(H_reg)\n                break\n        except np.linalg.LinAlgError:\n            pass\n        jitter *= 10.0\n    else: # If loop completes without break\n        # Fallback: pseudo-inverse if still failing\n        Sigma = np.linalg.pinv(H + jitter * np.eye(3))\n\n\n    # Gradient of S at E0\n    g = finite_diff_gradient_S(E0, theta_map, steps)\n    var_S0 = float(np.dot(g, Sigma @ g))\n    var_S0 = max(var_S0, 0.0)\n    sd_S0 = np.sqrt(var_S0)\n    return sd_S0\n\ndef solve():\n    # Generate synthetic dataset\n    E_data, y_obs, y_sigma = generate_synthetic_data(seed=123456)\n\n    # Prior cases\n    cases = [\n        # Case A: uninformative\n        (np.array([600.0, 1.50, 0.40]), np.array([1e6, 1e3, 1e3])),\n        # Case B: moderate ab initio\n        (np.array([520.0, 0.90, 0.25]), np.array([50.0, 0.30, 0.10])),\n        # Case C: tight ab initio\n        (np.array([500.0, 0.70, 0.20]), np.array([5.0, 0.05, 0.02])),\n    ]\n\n    results = []\n    for mu_prior, sigma_prior in cases:\n        sd = map_and_uncertainty(E_data, y_obs, y_sigma, mu_prior, sigma_prior, E0=10.0)\n        results.append(sd)\n\n    # Round to six decimal places\n    results_str = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(results_str)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "除了参数估计，材料科学中的一个关键任务是评估材料的可靠性并预测罕见但关键事件（如材料断裂）的发生概率。本练习介绍了重要性采样和强大的交叉熵方法，用于高效地估计极小的概率。通过实现一种自适应算法来寻找最优采样分布，您将深入了解对于可靠性分析和随机过程建模至关重要的高级蒙特卡洛技术。",
            "id": "3499844",
            "problem": "考虑在线性弹性断裂力学中的一个脆性断裂准则，当I型应力强度因子超过材料的断裂韧性时，发生失效。设应力强度因子由下式给出：$$K_I(a,\\sigma) = Y\\,\\sigma\\,\\sqrt{\\pi a},$$ 其中 $a$ 是以米为单位的裂纹长度，$\\sigma$ 是以兆帕 (MPa) 为单位的施加拉伸应力，$Y$ 是一个无量纲的几何因子。设材料断裂韧性为 $K_{IC}$，其单位为 $\\text{MPa}\\sqrt{\\text{m}}$。定义性能函数 $$f(\\theta) = K_I(a,\\sigma) - K_{IC},$$ 其中 $\\theta = (a,\\sigma,K_{IC})$，并考虑对于给定的阈值 $\\tau$ 的稀有事件概率 $$p = \\mathbb{P}\\left(f(\\theta) > \\tau\\right),$$ 在本问题中，设 $\\tau = 0$，因此当 $K_I(a,\\sigma) > K_{IC}$ 时发生失效。\n\n假设输入的标称不确定性模型为 $a$、$\\sigma$ 和 $K_{IC}$ 是独立的对数正态随机变量，其参数分别为 $(\\mu_{\\ell a},\\sigma_{\\ell a})$、$(\\mu_{\\ell \\sigma},\\sigma_{\\ell \\sigma})$ 和 $(\\mu_{\\ell K},\\sigma_{\\ell K})$。具体来说，如果 $X$ 是一个对数空间参数为 $(\\mu_{\\ell},\\sigma_{\\ell})$ 的对数正态变量，那么它的概率密度函数是 $$\\pi_X(x) = \\frac{1}{x\\,\\sigma_{\\ell}\\sqrt{2\\pi}}\\exp\\left(-\\frac{\\left(\\ln x - \\mu_{\\ell}\\right)^2}{2\\sigma_{\\ell}^2}\\right),\\quad x>0.$$ 将联合标称密度记为 $$\\pi(\\theta) = \\pi_a(a)\\,\\pi_{\\sigma}(\\sigma)\\,\\pi_K(K_{IC}).$$\n\n任务1（推导）：从蒙特卡洛估计中重要性抽样的基本定义出发，推导用于估计 $p = \\mathbb{P}(f(\\theta) > 0)$ 的零方差重要性抽样密度 $q^\\star(\\theta)$，其中抽样来自提议分布 $q(\\theta)$ 并使用标称密度 $\\pi(\\theta)$ 进行评估。具体来说：\n- 从指示函数、测度变换恒等式以及重要性抽样估计量方差的定义开始。\n- 使用这些原则推导能产生零估计量方差的 $q^\\star(\\theta)$ 的形式。\n\n任务2（交叉熵方法）：在实践中，$q^\\star(\\theta)$ 是难以处理的。考虑参数化提议分布族 $q(\\theta;v)$，其中 $q$ 是三个独立对数正态密度的乘积，其参数为 $v = (\\mu_{\\ell a},\\sigma_{\\ell a},\\mu_{\\ell \\sigma},\\sigma_{\\ell \\sigma},\\mu_{\\ell K},\\sigma_{\\ell K})$。通过最小化 $q^\\star(\\theta)$ 与 $q(\\theta;v)$ 之间的 Kullback-Leibler 散度，推导如何选择 $v$。证明这等价于在与 $\\mathbb{I}\\{f(\\theta)>0\\}\\pi(\\theta)$ 成比例的截断标称分布下最大化期望对数似然，并推导当从当前提议分布 $q(\\theta;v_t)$ 抽样时，对数正态参数的加权最大似然更新方程：\n- 设权重定义为 $$w(\\theta) = \\frac{\\pi(\\theta)}{q(\\theta;v_t)},$$ 并设精英集由一个自适应选择的阈值 $\\gamma_t$ 定义，使得固定比例 $\\rho$ 的样本满足 $f(\\theta)\\ge \\gamma_t$。\n- 使用精英样本和权重 $w(\\theta)$ 推导对数空间均值和标准差的更新公式。\n\n实现要求：\n- 实现一个程序，使用带平滑的交叉熵方法来近似最优提议分布 $q(\\theta;v)$。使用以下算法结构：\n  1. 将 $v_0$ 初始化为标称参数。\n  2. 对于 $t=1,\\dots,T$：\n     - 从 $q(\\cdot;v_{t-1})$ 中抽取 $N$ 个样本 $\\theta_i$。\n     - 计算 $f(\\theta_i)$ 并选择 $\\gamma_t$ 作为 $\\{f(\\theta_i)\\}$ 的 $(1-\\rho)$-分位数。\n     - 形成精英集 $\\mathcal{E}_t = \\{\\theta_i: f(\\theta_i)\\ge \\gamma_t\\}$。\n     - 计算权重 $w_i = \\pi(\\theta_i)/q(\\theta_i;v_{t-1})$，并在 $\\mathcal{E}_t$ 上对它们进行归一化。\n     - 通过在 $\\mathcal{E}_t$ 上进行加权最大似然来更新参数 $v_t$，并将指数平滑参数 $\\alpha \\in (0,1)$ 应用于对数空间中的均值和标准差。\n  3. 经过 $T$ 次迭代后，使用 $q(\\cdot;v_T)$ 通过重要性抽样（使用 $M$ 个独立样本）来估计 $p$，并报告估计量 $$\\hat{p} = \\frac{1}{M}\\sum_{i=1}^M \\mathbb{I}\\{f(\\theta_i)>0\\}\\frac{\\pi(\\theta_i)}{q(\\theta_i;v_T)}.$$ 同时计算标准误差，即重要性权重乘以指示函数的样本方差除以 $M$ 的平方根，并在内部使用它来确保数值稳定性。您应仅输出概率估计值。\n\n- 单位：对输入变量统一使用国际单位制 (SI)。具体来说：\n  - $a$ 以米 (m) 为单位。\n  - $\\sigma$ 以兆帕 (MPa) 为单位。\n  - $K_{IC}$ 以 $\\text{MPa}\\sqrt{\\text{m}}$ 为单位。\n  - $Y$ 是无量纲的。\n  输出的概率是一个无量纲的十进制数。\n\n- 角度单位不适用于本问题。\n\n测试套件：\n使用以下测试用例，所有用例均设置 $\\tau=0$，并使用相同的算法超参数 $N=8000$，$T=6$，$\\rho=0.1$，$\\alpha=0.7$，$M=150000$，以及一个固定的随机种子以保证可复现性。\n\n1. 案例 A (稀有事件基线，理想路径)：\n   - $Y = 1.12$\n   - 标称对数正态参数：\n     - $\\mu_{\\ell a} = \\ln(3.0\\times 10^{-5})$, $\\sigma_{\\ell a} = 0.5$\n     - $\\mu_{\\ell \\sigma} = \\ln(120)$, $\\sigma_{\\ell \\sigma} = 0.25$\n     - $\\mu_{\\ell K} = \\ln(60)$, $\\sigma_{\\ell K} = 0.15$\n\n2. 案例 B (不那么稀有，裂纹长度增加，韧性降低)：\n   - $Y = 1.12$\n   - 标称对数正态参数：\n     - $\\mu_{\\ell a} = \\ln(2.0\\times 10^{-4})$, $\\sigma_{\\ell a} = 0.45$\n     - $\\mu_{\\ell \\sigma} = \\ln(150)$, $\\sigma_{\\ell \\sigma} = 0.25$\n     - $\\mu_{\\ell K} = \\ln(30)$, $\\sigma_{\\ell K} = 0.20$\n\n3. 案例 C (极其稀有，几乎不可能失效)：\n   - $Y = 1.12$\n   - 标称对数正态参数：\n     - $\\mu_{\\ell a} = \\ln(5.0\\times 10^{-6})$, $\\sigma_{\\ell a} = 0.4$\n     - $\\mu_{\\ell \\sigma} = \\ln(80)$, $\\sigma_{\\ell \\sigma} = 0.20$\n     - $\\mu_{\\ell K} = \\ln(120)$, $\\sigma_{\\ell K} = 0.20$\n\n您的程序应生成单行输出，其中包含三个案例的估计稀有事件概率，形式为用方括号括起来的逗号分隔列表（例如，“[pA,pB,pC]”）。每个条目必须是十进制形式的浮点数。不应打印任何其他文本。",
            "solution": "该问题是有效的，因为它在科学上基于线性弹性断裂力学和统计可靠性理论，问题定义良好，目标明确，数据充分，并且没有任何逻辑矛盾或事实错误。我们将继续进行推导和实现。\n\n解决方案分三部分呈现。前两部分处理任务1和任务2中要求的理论推导。第三部分描述了在最终答案中实现的实现逻辑。\n\n### 任务1：零方差重要性抽样密度的推导\n\n目标是估计失效概率 $p$，定义为：\n$$p = \\mathbb{P}(f(\\theta) > 0) = \\int_{\\Theta} \\mathbb{I}\\{f(\\theta) > 0\\} \\pi(\\theta) d\\theta$$\n其中 $\\theta = (a, \\sigma, K_{IC})$，$\\pi(\\theta)$ 是输入参数的联合概率密度函数 (PDF)，$\\mathbb{I}\\{\\cdot\\}$ 是指示函数，如果其参数为真则为 $1$，否则为 $0$。\n\n重要性抽样 (IS) 是一种用于蒙特卡洛积分的方差缩减技术。我们不从标称密度 $\\pi(\\theta)$ 中抽取样本，而是从一个提议密度 $q(\\theta)$ 中抽样，并对样本重新加权以保持无偏估计。期望被重写为：\n$$p = \\int_{\\Theta} \\mathbb{I}\\{f(\\theta) > 0\\} \\frac{\\pi(\\theta)}{q(\\theta)} q(\\theta) d\\theta = \\mathbb{E}_{q}\\left[ \\mathbb{I}\\{f(\\theta) > 0\\} \\frac{\\pi(\\theta)}{q(\\theta)} \\right]$$\n其中 $\\mathbb{E}_q[\\cdot]$ 表示关于提议密度 $q(\\theta)$ 的期望。$w(\\theta) = \\pi(\\theta)/q(\\theta)$ 项是重要性权重。\n\n基于从 $q(\\theta)$ 中抽取的 $M$ 个独立同分布样本 $\\{\\theta_i\\}_{i=1}^M$，$p$ 的 IS 估计量为：\n$$\\hat{p} = \\frac{1}{M} \\sum_{i=1}^M \\mathbb{I}\\{f(\\theta_i) > 0\\} \\frac{\\pi(\\theta_i)}{q(\\theta_i)}$$\n该估计量的方差由 $\\frac{1}{M}\\text{Var}_q(Z(\\theta))$ 给出，其中 $Z(\\theta) = \\mathbb{I}\\{f(\\theta) > 0\\} \\frac{\\pi(\\theta)}{q(\\theta)}$。单个样本 $Z(\\theta)$ 的方差是：\n$$\\text{Var}_q(Z(\\theta)) = \\mathbb{E}_q[Z(\\theta)^2] - (\\mathbb{E}_q[Z(\\theta)])^2$$\n我们已知 $\\mathbb{E}_q[Z(\\theta)] = p$。第一项是：\n$$\\mathbb{E}_q[Z(\\theta)^2] = \\int_{\\Theta} \\left( \\mathbb{I}\\{f(\\theta) > 0\\} \\frac{\\pi(\\theta)}{q(\\theta)} \\right)^2 q(\\theta) d\\theta = \\int_{\\Theta} \\mathbb{I}\\{f(\\theta) > 0\\}^2 \\frac{\\pi(\\theta)^2}{q(\\theta)} d\\theta$$\n由于 $\\mathbb{I}\\{\\cdot\\}^2 = \\mathbb{I}\\{\\cdot\\}$，这可以简化为：\n$$\\mathbb{E}_q[Z(\\theta)^2] = \\int_{f(\\theta)>0} \\frac{\\pi(\\theta)^2}{q(\\theta)} d\\theta$$\n当且仅当对于所有 $q(\\theta) > 0$ 的 $\\theta$，随机变量 $Z(\\theta)$ 是一个常数时，方差为零。由于其期望为 $p$，该常数必须是 $p$。\n$$Z(\\theta) = \\mathbb{I}\\{f(\\theta) > 0\\} \\frac{\\pi(\\theta)}{q(\\theta)} = p$$\n对 $q(\\theta)$ 求解，我们得到最优的零方差提议密度，记为 $q^\\star(\\theta)$:\n$$q^\\star(\\theta) = \\frac{\\mathbb{I}\\{f(\\theta) > 0\\} \\pi(\\theta)}{p}$$\n这是一个有效的PDF，因为它是非负的，并且积分结果为 $1$:\n$$\\int_{\\Theta} q^\\star(\\theta) d\\theta = \\frac{1}{p} \\int_{\\Theta} \\mathbb{I}\\{f(\\theta) > 0\\} \\pi(\\theta) d\\theta = \\frac{p}{p} = 1$$\n这个最优密度 $q^\\star(\\theta)$ 是在失效事件 $\\{f(\\theta) > 0\\}$ 条件下的标称密度 $\\pi(\\theta)$。在实践中，$q^\\star(\\theta)$ 是难以处理的，因为它依赖于 $p$（正是我们希望估计的量），并且它需要从截断分布中抽样，这通常是一个难题。\n\n### 任务2：交叉熵方法更新方程的推导\n\n由于 $q^\\star(\\theta)$ 难以处理，交叉熵 (CE) 方法从一个选定的参数化密度族 $\\{q(\\theta;v)\\}$ 中寻找对 $q^\\star(\\theta)$ 的最佳近似。“最佳”近似是指最小化从 $q^\\star(\\theta)$ 到 $q(\\theta;v)$ 的 Kullback-Leibler (KL) 散度的那个：\n$$v_{\\text{opt}} = \\arg\\min_v D_{KL}(q^\\star || q(\\cdot;v))$$\nKL 散度定义为：\n$$D_{KL}(q^\\star || q) = \\int_{\\Theta} q^\\star(\\theta) \\ln\\left(\\frac{q^\\star(\\theta)}{q(\\theta;v)}\\right) d\\theta = \\mathbb{E}_{q^\\star}\\left[ \\ln q^\\star(\\theta) \\right] - \\mathbb{E}_{q^\\star}\\left[ \\ln q(\\theta;v) \\right]$$\n最小化关于 $v$ 的 KL 散度等价于最大化第二项，因为第一项不依赖于 $v$：\n$$v_{\\text{opt}} = \\arg\\max_v \\mathbb{E}_{q^\\star}\\left[ \\ln q(\\theta;v) \\right]$$\n代入 $q^\\star(\\theta)$ 的表达式：\n$$\\mathbb{E}_{q^\\star}\\left[ \\ln q(\\theta;v) \\right] = \\int_{\\Theta} \\frac{\\mathbb{I}\\{f(\\theta) > 0\\} \\pi(\\theta)}{p} \\ln q(\\theta;v) d\\theta$$\n去掉常数因子 $1/p$，该优化问题等价于求解一个随机规划问题：\n$$v_{\\text{opt}} = \\arg\\max_v \\int_{\\Theta} \\mathbb{I}\\{f(\\theta) > 0\\} \\pi(\\theta) \\ln q(\\theta;v) d\\theta$$\n这个积分通常使用蒙特卡洛抽样进行评估。在 CE 方法中，我们使用迭代方法。在第 $t$ 次迭代时，我们有一个参数向量 $v_t$。我们从 $q(\\theta;v_t)$ 生成样本，并使用重要性加权来近似最大化过程。为了处理稀有事件，基于一个自适应选择的性能阈值 $\\gamma_t$ 定义了一个样本的“精英集”。这引出了以下问题：\n$$v_{t+1} = \\arg\\max_v \\mathbb{E}_{q(\\cdot;v_t)}\\left[ \\mathbb{I}\\{f(\\theta) \\ge \\gamma_t\\} \\frac{\\pi(\\theta)}{q(\\theta;v_t)} \\ln q(\\theta;v) \\right]$$\n给定从 $q(\\cdot;v_t)$ 中抽取的 $N$ 个样本 $\\{\\theta_i\\}_{i=1}^N$，该问题的基于样本的版本是：\n$$v_{t+1} = \\arg\\max_v \\sum_{i=1}^N \\mathbb{I}\\{f(\\theta_i) \\ge \\gamma_t\\} w_i \\ln q(\\theta_i;v)$$\n其中 $w_i = \\pi(\\theta_i)/q(\\theta_i;v_t)$ 是重要性权重。求和是在精英集 $\\mathcal{E}_t = \\{\\theta_i : f(\\theta_i) \\ge \\gamma_t\\}$ 上进行的。\n\n提议分布族 $q(\\theta;v)$ 是关于 $a$、$\\sigma$ 和 $K_{IC}$ 的三个独立对数正态密度的乘积。因此，$\\ln q(\\theta;v)$ 可以分解为对数PDF的和，并且可以对每个变量的参数独立进行最大化。让我们推导变量 $a$ 的更新公式，其对数空间参数为 $v_a = (\\mu_{\\ell a}, \\sigma_{\\ell a})$。我们想要最大化：\n$$L_a(\\mu_{\\ell a}, \\sigma_{\\ell a}) = \\sum_{\\theta_i \\in \\mathcal{E}_t} w_i \\ln q_a(a_i; \\mu_{\\ell a}, \\sigma_{\\ell a})$$\n对于一个对数空间参数为 $(\\mu_\\ell, \\sigma_\\ell)$ 的变量 $x$ 的对数正态分布，其对数PDF为 $\\ln \\pi_X(x) = -\\ln x - \\ln \\sigma_\\ell - \\ln\\sqrt{2\\pi} - \\frac{(\\ln x - \\mu_\\ell)^2}{2\\sigma_\\ell^2}$。去掉不依赖于 $(\\mu_\\ell, \\sigma_\\ell)$ 的项，我们最大化：\n$$L_a(\\mu_{\\ell a}, \\sigma_{\\ell a}) \\propto \\sum_{\\theta_i \\in \\mathcal{E}_t} w_i \\left( -\\ln \\sigma_{\\ell a} - \\frac{(\\ln a_i - \\mu_{\\ell a})^2}{2\\sigma_{\\ell a}^2} \\right)$$\n这是对变量 $y_a = \\ln a$ 的正态分布参数的标准加权最大似然估计。通过对 $\\mu_{\\ell a}$ 和 $\\sigma_{\\ell a}$ 求导并令其为零，我们得到新参数的估计量，我们用帽子符号 ($\\hat{\\cdot}$) 表示：\n$$\\hat{\\mu}_{\\ell a} = \\frac{\\sum_{i \\in \\mathcal{E}_t} w_i \\ln a_i}{\\sum_{i \\in \\mathcal{E}_t} w_i}$$\n$$\\hat{\\sigma}_{\\ell a}^2 = \\frac{\\sum_{i \\in \\mathcal{E}_t} w_i (\\ln a_i - \\hat{\\mu}_{\\ell a})^2}{\\sum_{i \\in \\mathcal{E}_t} w_i}$$\n权重 $w_i$ 可以在精英集 $\\mathcal{E}_t$ 上进行预归一化，使其总和为1，从而简化分母。$\\sigma$ 和 $K_{IC}$ 的对数空间参数的更新是类似的。\n\n最后，CE算法使用指数平滑来稳定收敛。更新后的参数 $v_{t}$ 是先前参数 $v_{t-1}$ 和新计算出的最大似然估计 $\\hat{v}_{t}$ 的凸组合：\n$$\\mu_{\\ell, t} = \\alpha \\hat{\\mu}_{\\ell} + (1-\\alpha)\\mu_{\\ell, t-1}$$\n$$\\sigma_{\\ell, t} = \\alpha \\hat{\\sigma}_{\\ell} + (1-\\alpha)\\sigma_{\\ell, t-1}$$\n这适用于所有六个对数空间参数，其中 $\\hat{\\sigma}_{\\ell} = \\sqrt{\\hat{\\sigma}_{\\ell}^2}$。\n\n### 实现逻辑\n\n实现遵循推导出的交叉熵过程。\n1.  **初始化**：算法以设置为标称分布参数的提议参数 $v_0$ 开始。\n2.  **迭代**：对于 $t = 1, \\dots, T$:\n    a.  从当前的提议分布 $q(\\cdot;v_{t-1})$（一组三个独立的对数正态分布）中抽取 $N$ 个关于 $(a, \\sigma, K_{IC})$ 的样本。\n    b.  对每个样本计算性能函数 $f(\\theta_i) = Y\\sigma_i\\sqrt{\\pi a_i} - K_{IC,i}$。\n    c.  阈值 $\\gamma_t$ 被确定为计算出的 $f$ 值的 $(1-\\rho)$-分位数。\n    d.  精英集 $\\mathcal{E}_t$ 由所有满足 $f(\\theta_i) \\ge \\gamma_t$ 的样本 $\\theta_i$ 组成。\n    e.  对于精英集 $\\mathcal{E}_t$ 中的每个样本，计算重要性权重 $w_i = \\pi(\\theta_i)/q(\\theta_i; v_{t-1})$。为保证数值稳定性，此操作在对数空间中进行：$\\ln w_i = \\ln \\pi(\\theta_i) - \\ln q(\\theta_i; v_{t-1})$。PDF是各个对数正态分布的对数PDF之和。然后将这些权重归一化，使其总和为1。\n    f.  使用上面推导的加权最大似然估计公式，在精英集上计算新的参数估计值 $\\hat{v}_t$。\n    g.  使用参数为 $\\alpha$ 的指数平滑规则将提议参数更新为 $v_t$。\n3.  **最终估计**：经过 $T$ 次迭代后，使用优化后的提议分布 $q(\\cdot;v_T)$。\n    a.  从 $q(\\cdot;v_T)$ 中抽取大量样本 $M$。\n    b.  使用标准重要性抽样估计器计算最终的概率估计值 $\\hat{p}$：$\\hat{p} = \\frac{1}{M}\\sum_{i=1}^M \\mathbb{I}\\{f(\\theta_i)>0\\} \\frac{\\pi(\\theta_i)}{q(\\theta_i;v_T)}$。\n\n此过程应用于每个测试用例，使用指定的超参数和固定的随机种子以确保可复现性。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import lognorm\n\ndef cross_entropy_solver(case_params):\n    \"\"\"\n    Estimates the rare-event probability using the Cross-Entropy method.\n    \"\"\"\n    # Unpack case parameters\n    Y, nominal_params, hyperparams = case_params\n    N, T, rho, alpha, M = hyperparams\n\n    # Unpack nominal parameters (log-space)\n    mu_la_nom, sig_la_nom = nominal_params['a']\n    mu_ls_nom, sig_ls_nom = nominal_params['sigma']\n    mu_lk_nom, sig_lk_nom = nominal_params['k_ic']\n\n    # Initialize proposal distribution parameters with nominal values\n    v_t = {\n        'a': [mu_la_nom, sig_la_nom],\n        'sigma': [mu_ls_nom, sig_ls_nom],\n        'k_ic': [mu_lk_nom, sig_lk_nom],\n    }\n\n    # Cross-Entropy iteration loop\n    for t in range(T):\n        # 1. Draw N samples from the current proposal distribution q(.; v_t-1)\n        mu_la, sig_la = v_t['a']\n        mu_ls, sig_ls = v_t['sigma']\n        mu_lk, sig_lk = v_t['k_ic']\n\n        samples_a = np.random.lognormal(mean=mu_la, sigma=sig_la, size=N)\n        samples_sigma = np.random.lognormal(mean=mu_ls, sigma=sig_ls, size=N)\n        samples_k_ic = np.random.lognormal(mean=mu_lk, sigma=sig_lk, size=N)\n\n        # 2. Compute performance function f(theta_i)\n        f_theta = Y * samples_sigma * np.sqrt(np.pi * samples_a) - samples_k_ic\n\n        # 3. Select elite-set threshold gamma_t\n        gamma_t = np.quantile(f_theta, 1 - rho)\n\n        # 4. Form the elite set\n        elite_indices = np.where(f_theta >= gamma_t)[0]\n        if len(elite_indices) == 0:\n            # If no samples are elite, stop updating to avoid errors.\n            # This can happen in extreme cases or if rho is too small.\n            break\n\n        elite_a = samples_a[elite_indices]\n        elite_sigma = samples_sigma[elite_indices]\n        elite_k_ic = samples_k_ic[elite_indices]\n\n        # 5. Compute and normalize importance weights\n        # log_pdf(x, mu_log, sig_log)\n        def log_pdf(x, mu, sig):\n            return lognorm.logpdf(x, s=sig, scale=np.exp(mu))\n\n        # Log of nominal density PI(theta)\n        log_pi_a = log_pdf(elite_a, mu_la_nom, sig_la_nom)\n        log_pi_sigma = log_pdf(elite_sigma, mu_ls_nom, sig_ls_nom)\n        log_pi_k_ic = log_pdf(elite_k_ic, mu_lk_nom, sig_lk_nom)\n        log_pi = log_pi_a + log_pi_sigma + log_pi_k_ic\n\n        # Log of proposal density Q(theta)\n        log_q_a = log_pdf(elite_a, mu_la, sig_la)\n        log_q_sigma = log_pdf(elite_sigma, mu_ls, sig_ls)\n        log_q_k_ic = log_pdf(elite_k_ic, mu_lk, sig_lk)\n        log_q = log_q_a + log_q_sigma + log_q_k_ic\n\n        log_weights = log_pi - log_q\n        # Subtract max for numerical stability before exponentiating\n        log_weights -= np.max(log_weights)\n        weights = np.exp(log_weights)\n        normalized_weights = weights / np.sum(weights)\n\n        # 6. Update parameters via weighted MLE with smoothing\n        params_to_update = [\n            ('a', elite_a, mu_la, sig_la),\n            ('sigma', elite_sigma, mu_ls, sig_ls),\n            ('k_ic', elite_k_ic, mu_lk, sig_lk),\n        ]\n        \n        v_t_next = {}\n        for name, elite_samples, mu_current, sig_current in params_to_update:\n            log_elite_samples = np.log(elite_samples)\n            \n            # Weighted MLE for lognormal parameters\n            mu_hat = np.sum(normalized_weights * log_elite_samples)\n            var_hat = np.sum(normalized_weights * (log_elite_samples - mu_hat)**2)\n            sig_hat = np.sqrt(var_hat)\n            \n            # Exponential smoothing\n            mu_next = alpha * mu_hat + (1 - alpha) * mu_current\n            sig_next = alpha * sig_hat + (1 - alpha) * sig_current\n            v_t_next[name] = [mu_next, sig_next]\n            \n        v_t = v_t_next\n\n    # Final estimation step\n    mu_la_final, sig_la_final = v_t['a']\n    mu_ls_final, sig_ls_final = v_t['sigma']\n    mu_lk_final, sig_lk_final = v_t['k_ic']\n    \n    # Draw M samples from the final proposal distribution\n    final_samples_a = np.random.lognormal(mean=mu_la_final, sigma=sig_la_final, size=M)\n    final_samples_sigma = np.random.lognormal(mean=mu_ls_final, sigma=sig_ls_final, size=M)\n    final_samples_k_ic = np.random.lognormal(mean=mu_lk_final, sigma=sig_lk_final, size=M)\n\n    # Compute performance function\n    final_f_theta = Y * final_samples_sigma * np.sqrt(np.pi * final_samples_a) - final_samples_k_ic\n\n    # Indicator for failure events\n    indicator = (final_f_theta > 0).astype(float)\n    \n    # Final importance weights\n    log_pi_final_a = log_pdf(final_samples_a, mu_la_nom, sig_la_nom)\n    log_pi_final_sigma = log_pdf(final_samples_sigma, mu_ls_nom, sig_ls_nom)\n    log_pi_final_k_ic = log_pdf(final_samples_k_ic, mu_lk_nom, sig_lk_nom)\n    log_pi_final = log_pi_final_a + log_pi_final_sigma + log_pi_final_k_ic\n    \n    log_q_final_a = log_pdf(final_samples_a, mu_la_final, sig_la_final)\n    log_q_final_sigma = log_pdf(final_samples_sigma, mu_ls_final, sig_ls_final)\n    log_q_final_k_ic = log_pdf(final_samples_k_ic, mu_lk_final, sig_lk_final)\n    log_q_final = log_q_final_a + log_q_final_sigma + log_q_final_k_ic\n\n    final_weights = np.exp(log_pi_final - log_q_final)\n\n    # Final probability estimate\n    p_hat = np.mean(indicator * final_weights)\n\n    return p_hat\n\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the solver.\n    \"\"\"\n    np.random.seed(42)\n\n    hyperparams = [8000, 6, 0.1, 0.7, 150000] # N, T, rho, alpha, M\n\n    test_cases = [\n        # Case A\n        (1.12, {\n            'a': [np.log(3.0e-5), 0.5],\n            'sigma': [np.log(120), 0.25],\n            'k_ic': [np.log(60), 0.15],\n        }, hyperparams),\n        # Case B\n        (1.12, {\n            'a': [np.log(2.0e-4), 0.45],\n            'sigma': [np.log(150), 0.25],\n            'k_ic': [np.log(30), 0.20],\n        }, hyperparams),\n        # Case C\n        (1.12, {\n            'a': [np.log(5.0e-6), 0.4],\n            'sigma': [np.log(80), 0.20],\n            'k_ic': [np.log(120), 0.20],\n        }, hyperparams),\n    ]\n\n    results = []\n    for case in test_cases:\n        p_estimate = cross_entropy_solver(case)\n        results.append(f\"{p_estimate:.8e}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}