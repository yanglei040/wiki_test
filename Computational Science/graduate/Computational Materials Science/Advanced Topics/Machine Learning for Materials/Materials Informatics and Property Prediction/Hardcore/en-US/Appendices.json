{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of computational materials science is determining the thermodynamic stability of a compound. This practice introduces the convex hull construction, a geometric method for identifying the set of ground-state phases in a material system at zero temperature . By implementing this algorithm, you will gain hands-on experience in translating raw formation energy data into a physically meaningful stability map, a critical skill for screening new materials.",
            "id": "3464191",
            "problem": "You are given a set of candidate phases in a binary material system $\\mathrm{A}$â€“$\\mathrm{B}$, each represented by a composition $x \\in [0,1]$ and a formation energy $E_f(x)$ in electronvolts per atom (eV/atom). A fundamental principle in computational materials science is that, at a given composition $x$, the thermodynamically favored energy is the minimum over all possible two-phase mixtures consistent with mass conservation. Mathematically, for any two compositions $x_a$ and $x_b$ with $x_a < x_b$, the energy of a mixture that gives composition $x$ as a convex combination $x = \\lambda x_b + (1-\\lambda) x_a$ with $\\lambda \\in [0,1]$ is given by $E_{\\mathrm{mix}}(x) = \\lambda E_f(x_b) + (1-\\lambda) E_f(x_a)$. The convex hull of the set of points $\\{(x_i, E_f(x_i))\\}$ is the lower envelope of all such chords.\n\nYour task is to derive and implement an algorithm that:\n- Sorts input points $(x_i, E_i)$ by composition $x_i$.\n- Constructs the lower convex hull by iteratively adding points and removing those that violate convexity.\n- Computes the signed distance $d_i = E_i - E_{\\mathrm{hull}}(x_i)$ for each original input point, where $E_{\\mathrm{hull}}(x)$ is the piecewise-linear energy of the lower hull evaluated at $x$.\n- Classifies each input point as stable if $d_i \\le \\varepsilon$ and unstable otherwise, for a tolerance $\\varepsilon$.\n\nStart from the following fundamental bases:\n- The energy of an ideal two-phase mixture at composition $x$ is $E_{\\mathrm{mix}}(x) = \\lambda E_f(x_b) + (1-\\lambda) E_f(x_a)$, where $\\lambda = \\dfrac{x - x_a}{x_b - x_a}$, and $x \\in [x_a, x_b]$.\n- The lower convex hull in two dimensions can be constructed by the monotone chain method: after sorting by $x$, iteratively maintain a stack of hull points and remove the last point whenever the orientation test indicates a nonconvex (clockwise or colinear for strict convexity) turn for the lower hull.\n\nAlgorithmic specification:\n1. Preprocessing: If two points share the same composition $x$, keep only the one with minimum energy $E$, since higher energy entries at the same $x$ cannot be on the lower hull. Retain all original points for distance evaluation.\n2. Hull construction: Sort the deduplicated set $(x_j, E_j)$ by $x_j$ ascending. For the lower hull, use the orientation test defined by the cross product\n   $$\\mathrm{cross}(o,a,b) = (x_a - x_o)(E_b - E_o) - (E_a - E_o)(x_b - x_o).$$\n   While there are at least two points on the hull and $\\mathrm{cross}(o,a,b) \\le 0$, remove $a$ from the hull; finally append $b$.\n3. Hull evaluation: For any $x$, locate the segment endpoints $(x_L,E_L)$ and $(x_R,E_R)$ with $x_L \\le x \\le x_R$ and compute\n   $$E_{\\mathrm{hull}}(x) = E_L + \\frac{E_R - E_L}{x_R - x_L}(x - x_L).$$\n4. Signed distance and classification: For each original $(x_i,E_i)$, compute $d_i = E_i - E_{\\mathrm{hull}}(x_i)$ and classify as stable if $d_i \\le \\varepsilon$. Distances are in eV/atom; clip small negative $d_i$ to $0$ due to numerical roundoff. Use $\\varepsilon = 10^{-8}$ eV/atom.\n\nPhysical units and output requirements:\n- Energies and distances must be handled in eV/atom.\n- The final output must be a single line containing a list whose $k$-th element corresponds to the $k$-th test case. Each element must itself be a list: the first item is the sorted list of stable indices for that test case (integers referring to the original input order), and the second item is the maximum signed distance across all points in that test case, rounded to $6$ decimal places (eV/atom). For example: $[[[i_1,i_2],d_1],[[j_1],d_2]]$.\n- Angles are not involved in this problem.\n\nTest suite:\nImplement your program to process the following five test cases. For each case, report $[ \\text{stable\\_indices}, \\text{max\\_distance\\_rounded} ]$ as specified.\n- Case $1$ (general): $x = [0.0, 0.2, 0.5, 0.8, 1.0]$, $E = [0.0, -0.05, -0.2, -0.05, 0.0]$ eV/atom.\n- Case $2$ (duplicates at same composition): $x = [0.0, 0.5, 0.5, 1.0]$, $E = [0.0, -0.15, -0.10, 0.0]$ eV/atom.\n- Case $3$ (endpoints only on hull): $x = [0.0, 0.3, 0.6, 1.0]$, $E = [0.0, 0.05, 0.04, 0.0]$ eV/atom.\n- Case $4$ (colinear interior point on a hull segment): $x = [0.0, 0.25, 0.5, 1.0]$, $E = [0.0, -0.05, -0.1, 0.0]$ eV/atom.\n- Case $5$ (near-hull tolerance): $x = [0.0, 0.4, 1.0]$, $E = [0.0, 1\\times 10^{-12}, 0.0]$ eV/atom.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the exact format described above.",
            "solution": "The user has provided a well-defined problem from the field of computational materials science, specifically concerning the determination of phase stability from formation energy data. The problem is scientifically grounded, mathematically consistent, and algorithmically specified. The core of the task is to compute the lower convex hull of a set of 2D points, representing formation energy versus composition, and then to evaluate the stability of each input phase based on its energy difference from this hull.\n\nThe solution proceeds by implementing the specified algorithm, which is a variant of the monotone chain method for constructing a convex hull. The steps are as follows:\n\n1.  **Data Representation and Preprocessing**: The input consists of compositions $x_i$ and formation energies $E_i$. These are paired as points $(x_i, E_i)$ in a 2D plane, while also retaining their original indices for the final output. As per the problem specification, for any set of points sharing the same composition $x$, only the one with the minimum formation energy can lie on the lower convex hull. Therefore, a preliminary filtering step is performed to create a unique set of points for the hull construction algorithm, where uniqueness is defined by composition. This deduplicated set is then sorted in ascending order of composition $x$.\n\n2.  **Lower Convex Hull Construction**: The lower convex hull is constructed using the monotone chain algorithm on the preprocessed, sorted list of points. A list, which we can call `hull`, is maintained to store the vertices of the hull. Points are processed one by one in sorted order. For each new point $b$ being considered, we look at the last two points on the `hull`, let them be $o$ (second to last) and $a$ (last). We perform an orientation test using the 2D cross product:\n    $$ \\mathrm{cross}(o,a,b) = (x_a - x_o)(E_b - E_o) - (E_a - E_o)(x_b - x_o) $$\n    A positive result indicates a counter-clockwise (or \"left\") turn, a negative result indicates a clockwise (or \"right\") turn, and zero indicates that the points are colinear. For a lower convex hull, the sequence of vertices must form a chain of consecutive \"left\" turns (or remain colinear). If adding point $b$ would create a \"right\" turn (i.e., $\\mathrm{cross}(o,a,b) \\le 0$), it means point $a$ lies above the line segment connecting $o$ and $b$ and is therefore not on the lower hull. In this case, point $a$ is removed from the `hull`. This check is repeated until the `hull` has fewer than two points or the turn becomes convex (left). Finally, point $b$ is added to the `hull`. This process ensures that the resulting `hull` list contains the vertices of the lower convex hull in order of increasing composition.\n\n3.  **Hull Energy Evaluation**: With the vertices of the lower convex hull determined, the hull energy $E_{\\mathrm{hull}}(x)$ can be calculated for any composition $x$. The hull itself is a piecewise-linear function. For a given $x_i$ from an original input point, we must first identify which linear segment of the hull it corresponds to. The hull vertices are already sorted by composition. We can efficiently find the segment defined by vertices $(x_L, E_L)$ and $(x_R, E_R)$ such that $x_L \\le x_i \\le x_R$. This can be done using a binary search, for which `numpy.searchsorted` is highly suitable. Once the segment is found, the hull energy is calculated via linear interpolation:\n    $$ E_{\\mathrm{hull}}(x_i) = E_L + \\frac{E_R - E_L}{x_R - x_L}(x_i - x_L) $$\n    If $x_i$ coincides with a hull vertex, this formula correctly yields the energy of that vertex.\n\n4.  **Stability Analysis**: For each original input point $(x_i, E_i)$, the signed distance to the hull, $d_i$, also known as the decomposition energy, is computed:\n    $$ d_i = E_i - E_{\\mathrm{hull}}(x_i) $$\n    By construction of the lower hull, $d_i$ must be non-negative. However, due to finite floating-point precision, points lying exactly on the hull might yield a very small negative distance. As instructed, any such small negative values are clipped to $0$. A point is classified as thermodynamically \"stable\" if its energy is on or very close to the convex hull. This is determined by comparing its distance $d_i$ to a small tolerance, $\\varepsilon = 10^{-8}$ eV/atom. If $d_i \\le \\varepsilon$, the point (and its corresponding phase) is classified as stable. Otherwise, it is unstable.\n\n5.  **Output Formatting**: Following the analysis of all points in a test case, the list of original indices of the stable points is collected and sorted. The maximum signed distance $d_i$ across all points in that test case is also determined. These two pieces of information are formatted into the required string representation, `[[stable_indices], max_distance_rounded]`, for each test case. The final output is an aggregation of these results for all test cases into a single-line list.\n\nThis procedure correctly models the physical principle of phase stability analysis at zero temperature and provides a robust computational method to perform this analysis.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the convex hull phase stability problem for a set of test cases.\n    \"\"\"\n    # Tolerance for stability classification\n    EPSILON = 1e-8\n\n    # Test cases as provided in the problem description\n    test_cases = [\n        # Case 1 (general)\n        {'x': [0.0, 0.2, 0.5, 0.8, 1.0], 'E': [0.0, -0.05, -0.2, -0.05, 0.0]},\n        # Case 2 (duplicates at same composition)\n        {'x': [0.0, 0.5, 0.5, 1.0], 'E': [0.0, -0.15, -0.10, 0.0]},\n        # Case 3 (endpoints only on hull)\n        {'x': [0.0, 0.3, 0.6, 1.0], 'E': [0.0, 0.05, 0.04, 0.0]},\n        # Case 4 (colinear interior point on a hull segment)\n        {'x': [0.0, 0.25, 0.5, 1.0], 'E': [0.0, -0.05, -0.1, 0.0]},\n        # Case 5 (near-hull tolerance)\n        {'x': [0.0, 0.4, 1.0], 'E': [0.0, 1e-12, 0.0]},\n    ]\n    \n    final_results = []\n\n    for case_data in test_cases:\n        x_coords, e_vals = case_data['x'], case_data['E']\n        \n        # Store original points with their indices\n        original_points = [(x, e, i) for i, (x, e) in enumerate(zip(x_coords, e_vals))]\n\n        # 1. Preprocessing: Keep only the point with minimum energy for each unique composition\n        unique_points_map = {}\n        for x, e, _ in original_points:\n            if x not in unique_points_map or e  unique_points_map[x][1]:\n                unique_points_map[x] = (x, e)\n        \n        # Sort the unique points by composition for the hull algorithm\n        points_for_hull = sorted(unique_points_map.values())\n\n        # 2. Hull construction (Monotone Chain Algorithm)\n        def cross_product(p1, p2, p3):\n            # (x_a - x_o)(E_b - E_o) - (E_a - E_o)(x_b - x_o)\n            # o=p1, a=p2, b=p3\n            return (p2[0] - p1[0]) * (p3[1] - p1[1]) - (p2[1] - p1[1]) * (p3[0] - p1[0])\n\n        lower_hull = []\n        for p in points_for_hull:\n            while len(lower_hull) >= 2 and cross_product(lower_hull[-2], lower_hull[-1], p) = 0:\n                lower_hull.pop()\n            lower_hull.append(p)\n        \n        # 3. Hull evaluation and 4. Signed distance calculation\n        distances = []\n        stable_indices = []\n        \n        hull_x = [p[0] for p in lower_hull]\n\n        for x_i, e_i, original_idx in original_points:\n            # Find the hull segment for the current point x_i\n            # np.searchsorted finds insertion point, which helps locate the segment\n            j = np.searchsorted(hull_x, x_i, side='left')\n            \n            e_hull = 0.0\n            if j  len(hull_x) and np.isclose(hull_x[j], x_i):\n                # Point x_i is a hull vertex\n                e_hull = lower_hull[j][1]\n            else:\n                # Point x_i is between two hull vertices\n                p_left = lower_hull[j - 1]\n                p_right = lower_hull[j]\n                \n                x_L, e_L = p_left\n                x_R, e_R = p_right\n                \n                # Linear interpolation\n                if np.isclose(x_R, x_L):\n                    e_hull = e_L\n                else:\n                    slope = (e_R - e_L) / (x_R - x_L)\n                    e_hull = e_L + slope * (x_i - x_L)\n\n            # Compute signed distance, clip small negative values to 0\n            d_i = e_i - e_hull\n            d_i = max(0.0, d_i)\n            distances.append(d_i)\n\n            # Classify as stable if distance is within tolerance\n            if d_i = EPSILON:\n                stable_indices.append(original_idx)\n\n        # Prepare results for the current test case\n        max_distance = max(distances) if distances else 0.0\n        stable_indices.sort()\n        \n        # Format the result list as a string\n        case_result_str = f\"[[{','.join(map(str, stable_indices))}],{max_distance:.6f}]\"\n        final_results.append(case_result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(final_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While the convex hull provides a deterministic criterion for stability, our predictions of formation energy from machine learning models are inherently uncertain. This exercise explores how to manage and interpret this uncertainty by calculating the probability of stability for a candidate material . By treating the predicted energy as a probability distribution, you will learn to quantify confidence in a prediction, a vital step in making robust decisions during materials screening.",
            "id": "3464202",
            "problem": "In data-driven phase stability screening within materials informatics, a candidate compound at composition $x$ is considered thermodynamically stable with respect to decomposition if its energy above the convex hull, defined as $d(x) = E_{f}(x) - E_{\\mathrm{hull}}(x)$, satisfies $d(x)  0$. Here, $E_{f}(x)$ is the formation energy per atom of the candidate and $E_{\\mathrm{hull}}(x)$ is the convex hull line value determined from competing phases at the same composition. In a predictive setting, $E_{f}(x)$ is treated as a random variable due to model uncertainty, while $E_{\\mathrm{hull}}(x)$ is treated as deterministic, having been computed from a set of known phases.\n\nAssume that at $x = 0.4$, the predictive distribution for the formation energy is Gaussian, $E_{f}(0.4) \\sim \\mathcal{N}(\\mu, \\sigma^{2})$ with $\\mu = -0.12$ and $\\sigma = 0.03$, and that the hull line value is $\\hat{E}_{\\mathrm{hull}}(0.4) = -0.10$. Using the definitions of the probability density function (PDF) and cumulative distribution function (CDF) of a normal random variable, and the definition of $d(x)$ above, compute the probability of stability $P(d(0.4)  0)$.\n\nRound your final answer to four significant figures and express it as a unitless decimal between $0$ and $1$.",
            "solution": "The problem is found to be valid as it is scientifically grounded in the principles of computational thermodynamics, well-posed with all necessary information provided, and stated objectively.\n\nThe objective is to compute the probability of thermodynamic stability for a candidate compound at composition $x=0.4$. The condition for stability is given by the energy above the convex hull, $d(x)$, being less than zero.\n$$\nd(x) = E_{f}(x) - E_{\\mathrm{hull}}(x)  0\n$$\nWe are asked to find the probability $P(d(0.4)  0)$. Substituting the definition of $d(x)$ into the probability statement, we get:\n$$\nP(E_{f}(0.4) - E_{\\mathrm{hull}}(0.4)  0)\n$$\nThis inequality can be rearranged to isolate the random variable, $E_{f}(0.4)$:\n$$\nP(E_{f}(0.4)  E_{\\mathrm{hull}}(0.4))\n$$\nThe problem states that the formation energy $E_{f}(0.4)$ is a normally distributed random variable, $E_{f}(0.4) \\sim \\mathcal{N}(\\mu, \\sigma^{2})$, with mean $\\mu = -0.12$ and standard deviation $\\sigma = 0.03$. The energy of the convex hull is given as a deterministic value, $\\hat{E}_{\\mathrm{hull}}(0.4) = -0.10$.\n\nLet the random variable for the formation energy be denoted by $Y = E_{f}(0.4)$. We are therefore tasked with calculating $P(Y  -0.10)$, where $Y \\sim \\mathcal{N}(-0.12, (0.03)^{2})$.\n\nTo compute this probability, we standardize the random variable $Y$ by transforming it into a standard normal random variable, $Z$, which has a mean of $0$ and a standard deviation of $1$. The transformation is given by:\n$$\nZ = \\frac{Y - \\mu}{\\sigma}\n$$\nApplying this transformation to our inequality:\n$$\nP(Y  -0.10) = P\\left(\\frac{Y - \\mu}{\\sigma}  \\frac{-0.10 - \\mu}{\\sigma}\\right)\n$$\nThis is equivalent to finding the probability that the standard normal variable $Z$ is less than a specific value, which is the z-score of the threshold $-0.10$:\n$$\nP\\left(Z  \\frac{-0.10 - \\mu}{\\sigma}\\right)\n$$\nWe now substitute the given numerical values for $\\mu$ and $\\sigma$:\n$$\nP\\left(Z  \\frac{-0.10 - (-0.12)}{0.03}\\right) = P\\left(Z  \\frac{0.02}{0.03}\\right) = P\\left(Z  \\frac{2}{3}\\right)\n$$\nThe probability $P(Z  z)$ for a standard normal variable $Z$ is given by its cumulative distribution function (CDF), typically denoted as $\\Phi(z)$. Therefore, the required probability is:\n$$\nP(\\text{stability}) = \\Phi\\left(\\frac{2}{3}\\right)\n$$\nTo obtain a numerical value, we evaluate the CDF at $z = \\frac{2}{3} \\approx 0.6666...$. Using standard statistical tables or computational software, we find:\n$$\n\\Phi\\left(\\frac{2}{3}\\right) \\approx 0.74750746\n$$\nThe problem requires the final answer to be rounded to four significant figures. The first four significant figures are $7, 4, 7, 5$. The digit following the fifth place is $0$, so we round down.\n$$\nP(\\text{stability}) \\approx 0.7475\n$$\nThus, the probability that the candidate compound is stable at composition $x=0.4$ is approximately $0.7475$.",
            "answer": "$$\\boxed{0.7475}$$"
        },
        {
            "introduction": "With the ability to make probabilistic predictions, we can design more efficient strategies for materials discovery. This practice delves into Bayesian optimization, a powerful active learning framework for finding optima of expensive functions, by focusing on its core component: the acquisition function . By deriving and applying the Expected Improvement ($EI$) metric, you will understand how to strategically balance exploring new, uncertain regions of the chemical space with exploiting regions already known to be promising, thereby accelerating the discovery of novel high-performance materials.",
            "id": "3464220",
            "problem": "You are running Bayesian optimization to maximize a costly-to-evaluate materials property (for example, the room-temperature bulk modulus) over a discrete set of alloy compositions. A Gaussian process (GP) surrogate model provides, for each candidate composition, a posterior predictive distribution that is Gaussian with mean $\\mu$ and standard deviation $\\sigma$. The current best observed property value across all completed experiments is $y^{*}$.\n\nFor three new candidate compositions, the GP posterior summaries are:\n- Means: $\\boldsymbol{\\mu} = [0.5, 0.7, 0.6]$,\n- Standard deviations: $\\boldsymbol{\\sigma} = [0.1, 0.2, 0.15]$,\n- Current best: $y^{*} = 0.65$.\n\nAssume that at any candidate, the predictive distribution of the unknown property $Y$ is $Y \\sim \\mathcal{N}(\\mu, \\sigma^{2})$ and define the improvement over the current best for maximization as $I = \\max(0, Y - y^{*})$. Starting from the definition of $I$ and the Gaussian probability density function and cumulative distribution function, derive an analytical expression for the expected improvement $\\operatorname{EI} = \\mathbb{E}[I]$ at a single candidate in terms of $\\mu$, $\\sigma$, and $y^{*}$, without using any pre-memorized formula. Then evaluate $\\operatorname{EI}$ numerically for each of the three candidates using the given $\\boldsymbol{\\mu}$, $\\boldsymbol{\\sigma}$, and $y^{*}$.\n\nSelect the next experiment as the candidate with the largest expected improvement. Report only the index $i \\in \\{1,2,3\\}$ (using $1$-based indexing) of the selected candidate as your final answer. The final answer is unitless and does not require rounding.",
            "solution": "The user has provided a problem that is scientifically grounded, well-posed, and objective. It is a standard application of Bayesian optimization principles within the field of computational materials science. All necessary data and definitions are provided, and no inconsistencies or ambiguities are present. The problem is valid.\n\nThe problem requires the derivation of the analytical expression for the Expected Improvement (EI) acquisition function and its subsequent application to select the next experimental point.\n\nLet the unknown materials property at a candidate composition be a random variable $Y$, which follows a Gaussian (normal) distribution given by the Gaussian process posterior: $Y \\sim \\mathcal{N}(\\mu, \\sigma^{2})$. The probability density function (PDF) of $Y$ is given by:\n$$\nf(y; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{y-\\mu}{\\sigma}\\right)^2\\right)\n$$\nThe current best observed value is denoted by $y^{*}$. The improvement $I$ for a maximization problem is defined as the amount by which $Y$ exceeds $y^{*}$, and is zero if $Y$ is not better than $y^{*}$. This is mathematically expressed as:\n$$\nI = \\max(0, Y - y^{*})\n$$\nThe Expected Improvement, $\\operatorname{EI}$, is the expectation of $I$ with respect to the posterior distribution of $Y$.\n$$\n\\operatorname{EI} = \\mathbb{E}[I] = \\mathbb{E}[\\max(0, Y - y^{*})]\n$$\nBy the definition of expectation for a continuous random variable, this is calculated by integrating the improvement over its distribution:\n$$\n\\operatorname{EI} = \\int_{-\\infty}^{\\infty} \\max(0, y - y^{*}) f(y; \\mu, \\sigma) \\, dy\n$$\nThe term $\\max(0, y - y^{*})$ is non-zero only for $y  y^{*}$. Therefore, the integral's lower limit can be changed to $y^{*}$, and the integrand becomes $(y - y^{*})$:\n$$\n\\operatorname{EI} = \\int_{y^{*}}^{\\infty} (y - y^{*}) f(y; \\mu, \\sigma) \\, dy\n$$\nWe can split this integral into two parts:\n$$\n\\operatorname{EI} = \\int_{y^{*}}^{\\infty} y f(y; \\mu, \\sigma) \\, dy - y^{*} \\int_{y^{*}}^{\\infty} f(y; \\mu, \\sigma) \\, dy\n$$\nTo evaluate these integrals, we perform a change of variables to standardize the distribution. Let $z = \\frac{y - \\mu}{\\sigma}$. This implies $y = \\sigma z + \\mu$ and $dy = \\sigma \\, dz$. The PDF of the standard normal distribution $\\mathcal{N}(0, 1)$ is $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{z^2}{2})$, and its cumulative distribution function (CDF) is $\\Phi(z) = \\int_{-\\infty}^{z} \\phi(t) \\, dt$. The original PDF can be written in terms of the standard normal PDF as $f(y; \\mu, \\sigma) = \\frac{1}{\\sigma}\\phi\\left(\\frac{y-\\mu}{\\sigma}\\right)$. Therefore, $f(y; \\mu, \\sigma) \\, dy = \\phi(z) \\, dz$.\n\nThe lower integration limit $y = y^{*}$ transforms to $z = \\frac{y^{*} - \\mu}{\\sigma}$. Let us denote this standardized value as $z_{y^{*}} = \\frac{y^{*} - \\mu}{\\sigma}$. The integrals become:\n$$\n\\operatorname{EI} = \\int_{z_{y^{*}}}^{\\infty} (\\sigma z + \\mu) \\phi(z) \\, dz - y^{*} \\int_{z_{y^{*}}}^{\\infty} \\phi(z) \\, dz\n$$\nLet's expand the first term:\n$$\n\\operatorname{EI} = \\sigma \\int_{z_{y^{*}}}^{\\infty} z \\phi(z) \\, dz + \\mu \\int_{z_{y^{*}}}^{\\infty} \\phi(z) \\, dz - y^{*} \\int_{z_{y^{*}}}^{\\infty} \\phi(z) \\, dz\n$$\n$$\n\\operatorname{EI} = (\\mu - y^{*}) \\int_{z_{y^{*}}}^{\\infty} \\phi(z) \\, dz + \\sigma \\int_{z_{y^{*}}}^{\\infty} z \\phi(z) \\, dz\n$$\nThe first integral is the probability $P(Z  z_{y^{*}})$ for a standard normal variable $Z$, which is $1 - \\Phi(z_{y^{*}})$.\nThe second integral can be solved directly:\n$$\n\\int z \\phi(z) \\, dz = \\int z \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{z^2}{2}\\right) \\, dz\n$$\nUsing the substitution $u = -z^2/2$, we have $du = -z \\, dz$.\n$$\n\\int -\\frac{1}{\\sqrt{2\\pi}} \\exp(u) \\, du = -\\frac{1}{\\sqrt{2\\pi}} \\exp(u) = -\\phi(z)\n$$\nEvaluating the definite integral:\n$$\n\\int_{z_{y^{*}}}^{\\infty} z \\phi(z) \\, dz = [-\\phi(z)]_{z_{y^{*}}}^{\\infty} = -\\lim_{z \\to \\infty}\\phi(z) - (-\\phi(z_{y^{*}})) = 0 + \\phi(z_{y^{*}}) = \\phi(z_{y^{*}})\n$$\nSubstituting these results back into the expression for $\\operatorname{EI}$:\n$$\n\\operatorname{EI} = (\\mu - y^{*}) [1 - \\Phi(z_{y^{*}})] + \\sigma \\phi(z_{y^{*}})\n$$\nwhere $z_{y^{*}} = \\frac{y^{*} - \\mu}{\\sigma}$.\nFor notational convenience, let's define a new variable $Z = \\frac{\\mu - y^{*}}{\\sigma} = -z_{y^{*}}$. Using the properties of the standard normal distribution, $\\phi(-z) = \\phi(z)$ and $1 - \\Phi(-z) = \\Phi(z)$, the expression becomes:\n$$\n\\operatorname{EI} = (\\mu - y^{*}) \\Phi(Z) + \\sigma \\phi(Z)\n$$\nThis is the final analytical expression for Expected Improvement.\n\nNow, we evaluate $\\operatorname{EI}$ for the three given candidates.\nThe data are:\n- Means: $\\mu_1 = 0.5$, $\\mu_2 = 0.7$, $\\mu_3 = 0.6$.\n- Standard deviations: $\\sigma_1 = 0.1$, $\\sigma_2 = 0.2$, $\\sigma_3 = 0.15$.\n- Current best: $y^{*} = 0.65$.\n\nFor Candidate 1 ($i=1$):\n$\\mu_1 = 0.5$, $\\sigma_1 = 0.1$.\n$Z_1 = \\frac{\\mu_1 - y^{*}}{\\sigma_1} = \\frac{0.5 - 0.65}{0.1} = -1.5$.\n$\\operatorname{EI}_1 = (0.5 - 0.65) \\Phi(-1.5) + 0.1 \\phi(-1.5)$.\nUsing standard tables or a calculator, $\\Phi(-1.5) \\approx 0.066807$ and $\\phi(-1.5) = \\phi(1.5) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-1.5^2/2) \\approx 0.129518$.\n$\\operatorname{EI}_1 \\approx (-0.15)(0.066807) + (0.1)(0.129518) \\approx -0.010021 + 0.0129518 \\approx 0.00293$.\n\nFor Candidate 2 ($i=2$):\n$\\mu_2 = 0.7$, $\\sigma_2 = 0.2$.\n$Z_2 = \\frac{\\mu_2 - y^{*}}{\\sigma_2} = \\frac{0.7 - 0.65}{0.2} = \\frac{0.05}{0.2} = 0.25$.\n$\\operatorname{EI}_2 = (0.7 - 0.65) \\Phi(0.25) + 0.2 \\phi(0.25)$.\nUsing standard tables or a calculator, $\\Phi(0.25) \\approx 0.598706$ and $\\phi(0.25) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-0.25^2/2) \\approx 0.386668$.\n$\\operatorname{EI}_2 \\approx (0.05)(0.598706) + (0.2)(0.386668) \\approx 0.029935 + 0.077334 \\approx 0.10727$.\n\nFor Candidate 3 ($i=3$):\n$\\mu_3 = 0.6$, $\\sigma_3 = 0.15$.\n$Z_3 = \\frac{\\mu_3 - y^{*}}{\\sigma_3} = \\frac{0.6 - 0.65}{0.15} = \\frac{-0.05}{0.15} = -\\frac{1}{3}$.\n$\\operatorname{EI}_3 = (0.6 - 0.65) \\Phi(-1/3) + 0.15 \\phi(-1/3)$.\nUsing a calculator, $\\Phi(-1/3) \\approx 0.369441$ and $\\phi(-1/3) = \\phi(1/3) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-(1/3)^2/2) \\approx 0.377383$.\n$\\operatorname{EI}_3 \\approx (-0.05)(0.369441) + (0.15)(0.377383) \\approx -0.018472 + 0.056607 \\approx 0.038135$.\n\nComparing the computed Expected Improvement values:\n$\\operatorname{EI}_1 \\approx 0.00293$\n$\\operatorname{EI}_2 \\approx 0.10727$\n$\\operatorname{EI}_3 \\approx 0.03814$\n\nThe largest value is $\\operatorname{EI}_2$. Therefore, the next experiment should be performed on Candidate 2. The problem asks for the $1$-based index of this candidate. The index is $2$.",
            "answer": "$$\\boxed{2}$$"
        }
    ]
}