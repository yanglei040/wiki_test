{
    "hands_on_practices": [
        {
            "introduction": "主动学习的核心是利用模型的不确定性来指导数据采集。本练习将引导您从头开始构建一个完整的不确定性量化（Uncertainty Quantification, UQ）和校准流程。您将学习如何使用深度集成方法来估计和分离偶然不确定性（aleatoric uncertainty）与认知不确定性（epistemic uncertainty），并通过温度缩放（temperature scaling）对预测方差进行校准，使其具有统计意义，最终利用校准后的不确定性在分子动力学模拟中智能地触发高精度的量子力学计算。",
            "id": "3431917",
            "problem": "给定一个用于图神经网络（GNN）原子间势不确定性校准的综合但科学上一致的设置，该设置使用深度集成和温度缩放方法，以及随后使用校准后的预测区间来决定在分子动力学（MD）过程中何时触发动态（on-the-fly）密度泛函理论（DFT）评估。所有能量单位为电子伏特，所有方差单位为平方电子伏特。您的任务是纯粹基于概率论和统计学的首要原则，实现一个完整的程序来执行以下步骤。\n\n定义和假设：\n- 深度集成由 $M$ 个独立训练的模型组成。对于构型索引 $i$，模型索引 $m$ 提供一个预测的平均能量 $\\mu_{i,m}$ 和一个预测的偶然不确定性方差 $s^{2}_{i,m}$。对于任何 $M$ 个模型的集合，集成预测平均值是算术平均值，集成预测方差是预测的偶然不确定性方差的平均值与模型均值的方差（认知不确定性贡献）之和，两者都作为跨 $M$ 个模型的总体矩计算。\n- 在一个具有已知真实能量 $y_{i}$ 的校准集上，我们假设一个高斯似然，其残差为 $r_{i} = y_{i} - \\bar{\\mu}_{i}$，校准前的集成方差为 $v_{i}$。温度缩放将每个方差乘以一个公共因子 $\\tau^{2}$，该因子通过在高斯假设下最小化平均负对数似然来确定，而不引入任何额外的正则化。\n- 对于一个目标名义双边覆盖率 $c = 1 - \\alpha$，预测区间是通过使用标准正态分布的分位数来构建的。对于没有基准真相的MD帧，DFT触发由绝对误差超过用户指定的容差 $\\varepsilon$ 的高斯尾部概率决定：如果绝对误差超过 $\\varepsilon$ 的概率大于或等于 $\\alpha$，则触发。\n\n数值稳定性：\n- 为避免退化，在进行任何除法或平方根运算之前，始终将任何非正方差替换为一个小的下限值 $v_{\\min} > 0$。该下限值应一致地应用于校准和MD方差。\n\n单位和格式：\n- 能量单位为电子伏特。方差单位为平方电子伏特。最终输出按指定为无量纲或整数，并且您必须将任何浮点数输出四舍五入到小数点后恰好六位。\n\n必须实现的数学和计算要求：\n1.  对于每个测试用例，通过以下公式计算校准构型的集成均值 $\\bar{\\mu}_{i}$ 和校准前方差 $v_{i}$：\n    - $\\bar{\\mu}_{i} = \\frac{1}{M} \\sum_{m=1}^{M} \\mu_{i,m}$,\n    - $v_{\\text{ale},i} = \\frac{1}{M} \\sum_{m=1}^{M} s^{2}_{i,m}$,\n    - $v_{\\text{epi},i} = \\frac{1}{M} \\sum_{m=1}^{M} \\left(\\mu_{i,m} - \\bar{\\mu}_{i}\\right)^{2}$,\n    - $v_{i} = \\max\\left(v_{\\text{ale},i} + v_{\\text{epi},i}, v_{\\min}\\right)$。\n2.  通过仅从上述定义出发，在高斯假设下对校准集最小化平均负对数似然来确定温度缩放因子 $\\tau > 0$。不要使用任何未从似然定义推导出的替代或快捷表达式。\n3.  使用校准后的方差 $\\tilde{v}_{i} = \\tau^{2} v_{i}$，通过计算 $y_{i}$ 落在双边区间 $\\left[\\bar{\\mu}_{i} - z \\sqrt{\\tilde{v}_{i}}, \\bar{\\mu}_{i} + z \\sqrt{\\tilde{v}_{i}}\\right]$ 内的比例，报告在名义覆盖率 $c = 1 - \\alpha$ 下校准集上的经验覆盖率，其中 $z$ 是对应于 $(1+c)/2$ 的标准正态分位数。\n4.  对于每个MD帧 $j$，以相同方式计算集成均值 $\\bar{\\mu}_{j}$ 和方差 $v_{j}$，应用校准得到 $\\tilde{v}_{j} = \\tau^{2} v_{j}$，计算尾部概率 $p_{j} = 2 \\left[1 - \\Phi\\left(\\varepsilon / \\sqrt{\\tilde{v}_{j}}\\right)\\right]$，其中 $\\Phi$ 是标准正态分布的累积分布函数，并在 $p_{j} \\ge \\alpha$ 时决定触发DFT。将每个测试用例的总触发次数报告为整数。\n\n四舍五入与输出：\n- 对于每个测试用例，输出一个由 $\\tau$（四舍五入到六位小数）、经验覆盖率（作为小数，四舍五入到六位小数）和触发次数（一个整数）组成的三元组。将所有测试用例的三元组聚合到单行中，打印为列表的列表格式，无空格，例如 $[[\\tau_{1},\\text{cov}_{1},n_{1}],[\\tau_{2},\\text{cov}_{2},n_{2}],\\dots]$，其中每个 $\\tau_{k}$ 和覆盖率都四舍五入到恰好六位小数。\n- 最终输出必须是恰好一行，包含以此格式聚合的结果。\n\n测试套件：\n实现您的程序以运行以下三个测试用例。所有能量单位为电子伏特，所有方差单位为平方电子伏特，所有角度（如果有）都将是弧度，但此处未使用。\n\n测试用例 1（包含偶然不确定性和认知不确定性贡献的通用集成）：\n- 集成大小 $M = 3$。\n- 校准集真实能量 $y = [0.10, -0.05, 0.20, -0.10, 0.00]$。\n- 校准集各模型的预测均值和方差：\n  - 模型 1: $\\mu_{:,1} = [0.12, -0.06, 0.18, -0.12, 0.02]$, $s^{2}_{:,1} = [0.0025, 0.0025, 0.0036, 0.0025, 0.0036]$。\n  - 模型 2: $\\mu_{:,2} = [0.11, -0.04, 0.22, -0.08, -0.01]$, $s^{2}_{:,2} = [0.0036, 0.0025, 0.0036, 0.0036, 0.0025]$。\n  - 模型 3: $\\mu_{:,3} = [0.09, -0.05, 0.21, -0.11, -0.02]$, $s^{2}_{:,3} = [0.0025, 0.0025, 0.0049, 0.0025, 0.0036]$。\n- MD各模型的预测均值和方差：\n  - 模型 1: $\\mu^{\\text{MD}}_{:,1} = [0.05, -0.02, 0.15, -0.08]$, $(s^{2})^{\\text{MD}}_{:,1} = [0.0036, 0.0025, 0.0036, 0.0025]$。\n  - 模型 2: $\\mu^{\\text{MD}}_{:,2} = [0.04, -0.01, 0.17, -0.07]$, $(s^{2})^{\\text{MD}}_{:,2} = [0.0025, 0.0036, 0.0036, 0.0036]$。\n  - 模型 3: $\\mu^{\\text{MD}}_{:,3} = [0.06, -0.03, 0.16, -0.09]$, $(s^{2})^{\\text{MD}}_{:,3} = [0.0036, 0.0025, 0.0049, 0.0025]$。\n- 误差容差 $\\varepsilon = 0.05$.\n- 风险阈值 $\\alpha = 0.10$.\n- 方差下限 $v_{\\min} = 10^{-8}$.\n- 报告三元组 $[\\tau,\\text{coverage},\\text{triggers}]$，其中 $\\tau$ 和 coverage 四舍五入到六位小数。\n\n测试用例 2（具有精确单位温度缩放的边界触发构造）：\n- 集成大小 $M = 2$。\n- 校准集真实能量 $y = [0.50, -0.30, 0.10]$。\n- 选择校准残差 $r = [0.10, -0.20, 0.05]$ 并定义相同的各模型均值 $\\mu_{:,1} = \\mu_{:,2} = y - r = [0.40, -0.10, 0.05]$。选择相同的各模型方差 $s^{2}_{:,1} = s^{2}_{:,2} = [0.01, 0.04, 0.0025]$，使得所有 $i$ 的比率 $r_{i}^{2} / v_{i}$ 等于 $1$，这意味着从高斯似然推导出的最优 $\\tau$ 等于 $1$。\n- MD构造以将一个帧精确放置在DFT触发边界上：设误差容差为 $\\varepsilon = 0.10$，风险阈值为 $\\alpha = 0.10$，并定义 $z_{\\alpha} = \\Phi^{-1}(1 - \\alpha/2)$。设 $\\sigma_{\\text{th}} = \\varepsilon / z_{\\alpha}$，并构造三个MD帧，其两个模型具有相同的均值（任何合理的值），且每个帧的各模型方差如下：\n  - 帧 A：各模型方差等于 $\\sigma_{\\text{th}}^{2}$（精确边界）。\n  - 帧 B：各模型方差等于 $(0.9 \\sigma_{\\text{th}})^{2}$（低于边界）。\n  - 帧 C：各模型方差等于 $(1.1 \\sigma_{\\text{th}})^{2}$（高于边界）。\n  因为每个帧上的模型是相同的，所以集成预测方差等于这些值，使得在规则 $p \\ge \\alpha$ 下的触发结果为 $(\\text{equal},\\text{no},\\text{yes})$。\n- 使用方差下限 $v_{\\min} = 10^{-12}$.\n- 报告三元组 $[\\tau,\\text{coverage},\\text{triggers}]$，其中 $\\tau$ 和 coverage 四舍五入到六位小数。\n\n测试用例 3（一个模型中偶然不确定性方差接近零且存在不可忽略的认知不确定性扩展的边缘案例）：\n- 集成大小 $M = 3$。\n- 校准集真实能量 $y = [0.00, 0.10, -0.10, 0.05]$。\n- 校准集各模型的预测均值和方差：\n  - 模型 1: $\\mu_{:,1} = [0.02, 0.08, -0.12, 0.04]$, $s^{2}_{:,1} = [0.0, 10^{-8}, 0.0, 10^{-8}]$。\n  - 模型 2: $\\mu_{:,2} = [0.00, 0.12, -0.08, 0.06]$, $s^{2}_{:,2} = [0.0025, 0.0036, 0.0025, 0.0036]$。\n  - 模型 3: $\\mu_{:,3} = [-0.01, 0.09, -0.11, 0.07]$, $s^{2}_{:,3} = [0.0025, 0.0025, 0.0036, 0.0025]$。\n- MD各模型的预测均值和方差：\n  - 模型 1: $\\mu^{\\text{MD}}_{:,1} = [0.03, -0.02, 0.12, -0.05]$, $(s^{2})^{\\text{MD}}_{:,1} = [0.0, 0.0, 0.0, 0.0]$。\n  - 模型 2: $\\mu^{\\text{MD}}_{:,2} = [-0.04, -0.01, 0.08, -0.06]$, $(s^{2})^{\\text{MD}}_{:,2} = [0.0025, 0.0025, 0.0025, 0.0025]$。\n  - 模型 3: $\\mu^{\\text{MD}}_{:,3} = [0.00, -0.03, 0.10, -0.04]$, $(s^{2})^{\\text{MD}}_{:,3} = [0.0025, 0.0049, 0.0036, 0.0025]$。\n- 误差容差 $\\varepsilon = 0.05$.\n- 风险阈值 $\\alpha = 0.10$.\n- 方差下限 $v_{\\min} = 10^{-8}$.\n- 报告三元组 $[\\tau,\\text{coverage},\\text{triggers}]$，其中 $\\tau$ 和 coverage 四舍五入到六位小数。\n\n整个程序的最终输出格式：\n- 您的程序应生成单行输出，包含用方括号括起来的三个三元组的逗号分隔列表形式的结果。确切格式为 $[[\\tau_{1},\\text{cov}_{1},n_{1}],[\\tau_{2},\\text{cov}_{2},n_{2}],[\\tau_{3},\\text{cov}_{3},n_{3}]]$, 其中每个 $\\tau_{k}$ 和 $\\text{cov}_{k}$ 四舍五入到六位小数，每个 $n_{k}$ 是一个整数。",
            "solution": "该问题要求实现一个完整的工作流，用于深度集成原子间势的不确定性校准及其在分子动力学（MD）模拟的主动学习背景下的后续应用。该方法论基于坚实的概率论和统计学原理。我们将首先从首要原则推导必要的公式，然后概述计算算法。\n\n**1. 集成预测：均值和方差**\n\n深度集成由 $M$ 个独立训练的模型组成。对于给定的原子构型（索引为 $i$），每个模型 $m \\in \\{1, \\dots, M\\}$ 提供能量均值的预测 $\\mu_{i,m}$ 和相关的偶然不确定性方差 $s^{2}_{i,m}$。偶然不确定性是数据固有的（例如，由于训练数据中的热噪声），由模型自身预测。\n\n集成的共识预测能量均值是各个模型均值的算术平均值：\n$$ \\bar{\\mu}_{i} = \\frac{1}{M} \\sum_{m=1}^{M} \\mu_{i,m} $$\n\n集成的总预测方差 $v_i$ 分解为两个部分：平均偶然不确定性方差和认知不确定性方差。认知不确定性源于模型的知识缺乏，通过集成成员之间的分歧来捕捉。\n\n平均偶然不确定性方差 $v_{\\text{ale},i}$ 是每个模型预测的方差的均值：\n$$ v_{\\text{ale},i} = \\frac{1}{M} \\sum_{m=1}^{M} s^{2}_{i,m} $$\n\n认知不确定性方差 $v_{\\text{epi},i}$ 是集成成员预测均值的方差，作为总体方差计算：\n$$ v_{\\text{epi},i} = \\frac{1}{M} \\sum_{m=1}^{M} \\left(\\mu_{i,m} - \\bar{\\mu}_{i}\\right)^{2} $$\n\n校准前的总方差是这两个贡献之和：\n$$ v_i^{\\text{raw}} = v_{\\text{ale},i} + v_{\\text{epi},i} $$\n为了数值稳定性，特别是在计算对数或平方根倒数时，任何非正方差都设定一个小的正数下限 $v_{\\min}$。因此，校准前的最终方差是：\n$$ v_{i} = \\max\\left(v_i^{\\text{raw}}, v_{\\min}\\right) $$\n\n**2. 通过温度缩放进行校准**\n\n来自集成的原始预测方差通常是校准不准的，这意味着预测的不确定性不能准确反映真实的误差分布。温度缩放是一种简单而有效的事后校准方法，它通过一个单一的乘法因子 $\\tau^2$ 来校正方差。校准后的方差为 $\\tilde{v}_i = \\tau^2 v_i$。\n\n最优温度 $\\tau > 0$ 是通过在高斯假设下最大化校准数据集的对数似然来确定的。设校准集包含 $N$ 个具有已知真实能量 $y_i$ 的构型。我们将每个构型的真实能量建模为从均值为 $\\bar{\\mu}_i$、方差为 $\\tilde{v}_i$ 的正态分布中抽取的一个样本：\n$$ p(y_i | \\bar{\\mu}_i, v_i, \\tau) = \\mathcal{N}(y_i; \\bar{\\mu}_i, \\tau^2 v_i) = \\frac{1}{\\sqrt{2\\pi \\tau^2 v_i}} \\exp\\left(-\\frac{(y_i - \\bar{\\mu}_i)^2}{2 \\tau^2 v_i}\\right) $$\n单个数据点的对数似然是：\n$$ \\ln p(y_i) = -\\frac{1}{2} \\ln(2\\pi) - \\frac{1}{2} \\ln(\\tau^2 v_i) - \\frac{r_i^2}{2 \\tau^2 v_i} $$\n其中 $r_i = y_i - \\bar{\\mu}_i$ 是残差。假设数据点是独立的，该集合的总负对数似然（NLL）是：\n$$ \\text{NLL}(\\tau) = -\\sum_{i=1}^{N} \\ln p(y_i) = \\sum_{i=1}^{N} \\left( \\frac{1}{2} \\ln(2\\pi) + \\ln(\\tau) + \\frac{1}{2} \\ln(v_i) + \\frac{r_i^2}{2 \\tau^2 v_i} \\right) $$\n为了找到最小化此NLL的最优 $\\tau$，我们计算关于 $\\tau$ 的导数并令其为零。\n$$ \\frac{\\partial(\\text{NLL})}{\\partial \\tau} = \\sum_{i=1}^{N} \\left( \\frac{1}{\\tau} - \\frac{r_i^2}{v_i \\tau^3} \\right) = 0 $$\n$$ \\frac{N}{\\tau} = \\frac{1}{\\tau^3} \\sum_{i=1}^{N} \\frac{r_i^2}{v_i} $$\n解出 $\\tau^2$ 得：\n$$ \\tau^2 = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{r_i^2}{v_i} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{(y_i - \\bar{\\mu}_i)^2}{v_i} $$\n最优温度是此数量的平方根：\n$$ \\tau = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} \\frac{(y_i - \\bar{\\mu}_i)^2}{v_i}} $$\n这个结果提供了一种从校准数据中找到校准因子的直接解析方法。\n\n**3. 经验覆盖率和预测区间**\n\n确定 $\\tau$ 后，我们可以通过计算校准集上的经验覆盖率来评估校准的质量。对于目标名义覆盖率概率 $c = 1-\\alpha$，$y_i$ 的双边预测区间构造为：\n$$ \\left[ \\bar{\\mu}_i - z \\sqrt{\\tilde{v}_i}, \\; \\bar{\\mu}_i + z \\sqrt{\\tilde{v}_i} \\right] $$\n其中 $\\tilde{v}_i = \\tau^2 v_i$ 是校准后的方差，$z = \\Phi^{-1}\\left(\\frac{1+c}{2}\\right) = \\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)$ 是标准正态分布 $\\mathcal{N}(0,1)$ 的分位数，其中 $\\Phi$ 是其累积分布函数（CDF）。\n经验覆盖率是真实能量 $y_i$ 落在此区间内的校准点的分数：\n$$ \\text{coverage} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{I}\\left( |y_i - \\bar{\\mu}_i| \\le z \\sqrt{\\tilde{v}_i} \\right) $$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。一个校准良好的模型应该有接近名义覆盖率 $c$ 的经验覆盖率。\n\n**4. 基于不确定性的动态DFT触发**\n\n在MD的主动学习中，校准后的不确定性用于决定何时执行计算成本高昂的量子力学计算（如DFT），而不是依赖于更便宜的GNN势。如果给定构型的模型不确定性太高，则会触发DFT计算。\n\n这个决策通过设定能量容差 $\\varepsilon$ 和风险水平 $\\alpha$ 来形式化。如果绝对误差 $|y_j - \\bar{\\mu}_j|$ 超过 $\\varepsilon$ 的预测概率大于或等于 $\\alpha$，则触发。在校准的高斯模型下，这个概率 $p_j$ 是：\n$$ p_j = P(|y_j - \\bar{\\mu}_j| > \\varepsilon) = P\\left(\\frac{|y_j - \\bar{\\mu}_j|}{\\sqrt{\\tilde{v}_j}} > \\frac{\\varepsilon}{\\sqrt{\\tilde{v}_j}}\\right) $$\n由于 $(y_j - \\bar{\\mu}_j)/\\sqrt{\\tilde{v}_j}$ 被假定遵循标准正态分布，这个尾部概率是：\n$$ p_j = 2 \\left[1 - \\Phi\\left(\\frac{\\varepsilon}{\\sqrt{\\tilde{v}_j}}\\right)\\right] $$\n因此，MD帧 $j$ 的触发条件是：\n$$ 2 \\left[1 - \\Phi\\left(\\frac{\\varepsilon}{\\sqrt{\\tilde{v}_j}}\\right)\\right] \\ge \\alpha $$\n总触发次数是满足此条件的MD帧的数量。\n\n**计算算法摘要**\n\n对于每个测试用例，程序将执行以下序列：\n\n1.  **处理校准数据**：\n    a.  对于 $N$ 个校准点中的每一个，计算集成均值 $\\bar{\\mu}_i$ 和校准前方差 $v_i = \\max(v_{\\text{ale},i} + v_{\\text{epi},i}, v_{\\min})$。\n    b.  使用推导出的公式计算最优温度 $\\tau$。\n    c.  计算校准后的方差 $\\tilde{v}_i = \\tau^2 v_i$。\n    d.  确定名义覆盖率 $c = 1 - \\alpha$ 的标准正态分位数 $z$。\n    e.  通过检查有多少真实能量 $y_i$ 在它们各自的预测区间内来计算经验覆盖率。\n\n2.  **处理MD数据**：\n    a.  对于每个MD帧 $j$，使用与校准数据相同的方法计算集成均值 $\\bar{\\mu}_j$ 和校准前方差 $v_j$。\n    b.  应用温度缩放因子得到校准后的方差 $\\tilde{v}_j = \\tau^2 v_j$。\n    c.  根据误差容差 $\\varepsilon$ 计算触发概率 $p_j$。\n    d.  计算 $p_j \\ge \\alpha$ 的帧数。\n\n3.  **报告结果**：对于每个测试用例，将计算出的 $\\tau$、经验覆盖率（两者都四舍五入到六位小数）和整数触发次数收集到一个三元组中。将这些三元组聚合到一个列表的列表中，作为最终输出。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases and print the results.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1\n        {\n            \"M\": 3,\n            \"calib_y\": np.array([0.10, -0.05, 0.20, -0.10, 0.00]),\n            \"calib_mu\": np.array([\n                [0.12, -0.06, 0.18, -0.12, 0.02],\n                [0.11, -0.04, 0.22, -0.08, -0.01],\n                [0.09, -0.05, 0.21, -0.11, -0.02]\n            ]).T,\n            \"calib_s2\": np.array([\n                [0.0025, 0.0025, 0.0036, 0.0025, 0.0036],\n                [0.0036, 0.0025, 0.0036, 0.0036, 0.0025],\n                [0.0025, 0.0025, 0.0049, 0.0025, 0.0036]\n            ]).T,\n            \"md_mu\": np.array([\n                [0.05, -0.02, 0.15, -0.08],\n                [0.04, -0.01, 0.17, -0.07],\n                [0.06, -0.03, 0.16, -0.09]\n            ]).T,\n            \"md_s2\": np.array([\n                [0.0036, 0.0025, 0.0036, 0.0025],\n                [0.0025, 0.0036, 0.0036, 0.0036],\n                [0.0036, 0.0025, 0.0049, 0.0025]\n            ]).T,\n            \"epsilon\": 0.05,\n            \"alpha\": 0.10,\n            \"v_min\": 1e-8,\n        },\n        # Test Case 2\n        {\n            \"M\": 2,\n            \"calib_y\": np.array([0.50, -0.30, 0.10]),\n            \"calib_mu\": np.array([\n                [0.40, -0.10, 0.05],\n                [0.40, -0.10, 0.05]\n            ]).T,\n            \"calib_s2\": np.array([\n                [0.01, 0.04, 0.0025],\n                [0.01, 0.04, 0.0025]\n            ]).T,\n            \"epsilon\": 0.10,\n            \"alpha\": 0.10,\n            \"v_min\": 1e-12,\n            # MD part needs to be constructed\n            \"md_construction\": True,\n        },\n        # Test Case 3\n        {\n            \"M\": 3,\n            \"calib_y\": np.array([0.00, 0.10, -0.10, 0.05]),\n            \"calib_mu\": np.array([\n                [0.02, 0.08, -0.12, 0.04],\n                [0.00, 0.12, -0.08, 0.06],\n                [-0.01, 0.09, -0.11, 0.07]\n            ]).T,\n            \"calib_s2\": np.array([\n                [0.0, 1e-8, 0.0, 1e-8],\n                [0.0025, 0.0036, 0.0025, 0.0036],\n                [0.0025, 0.0025, 0.0036, 0.0025]\n            ]).T,\n            \"md_mu\": np.array([\n                [0.03, -0.02, 0.12, -0.05],\n                [-0.04, -0.01, 0.08, -0.06],\n                [0.00, -0.03, 0.10, -0.04]\n            ]).T,\n            \"md_s2\": np.array([\n                [0.0, 0.0, 0.0, 0.0],\n                [0.0025, 0.0025, 0.0025, 0.0025],\n                [0.0025, 0.0049, 0.0036, 0.0025]\n            ]).T,\n            \"epsilon\": 0.05,\n            \"alpha\": 0.10,\n            \"v_min\": 1e-8,\n        }\n    ]\n\n    # Construct MD data for Test Case 2\n    tc2 = test_cases[1]\n    alpha_tc2 = tc2[\"alpha\"]\n    epsilon_tc2 = tc2[\"epsilon\"]\n    z_alpha_tc2 = norm.ppf(1 - alpha_tc2 / 2)\n    sigma_th_sq = (epsilon_tc2 / z_alpha_tc2)**2\n    # Define some reasonable identical means\n    tc2[\"md_mu\"] = np.array([[0.1, 0.1], [0.2, 0.2], [0.3, 0.3]])\n    tc2[\"md_s2\"] = np.array([\n        [sigma_th_sq, sigma_th_sq],             # Frame A\n        [(0.9**2) * sigma_th_sq, (0.9**2) * sigma_th_sq], # Frame B\n        [(1.1**2) * sigma_th_sq, (1.1**2) * sigma_th_sq]  # Frame C\n    ])\n\n    results = []\n    for case in test_cases:\n        result = process_case(case)\n        results.append(result)\n\n    # Print the final result in the exact required format\n    print(str(results).replace(\" \", \"\"))\n\ndef get_ensemble_predictions(mu_models, s2_models, v_min):\n    \"\"\"\n    Computes ensemble mean and variance.\n    \n    Args:\n        mu_models (np.ndarray): Per-model mean predictions, shape (N_points, M).\n        s2_models (np.ndarray): Per-model aleatoric variances, shape (N_points, M).\n        v_min (float): Minimum variance floor.\n        \n    Returns:\n        tuple: (ensemble_mean, ensemble_variance)\n    \"\"\"\n    mu_bar = np.mean(mu_models, axis=1)\n    v_ale = np.mean(s2_models, axis=1)\n    # ddof=0 for population variance\n    v_epi = np.var(mu_models, axis=1, ddof=0)\n    v_raw = v_ale + v_epi\n    v = np.maximum(v_raw, v_min)\n    return mu_bar, v\n\ndef process_case(case_data):\n    \"\"\"\n    Processes a single test case.\n    \"\"\"\n    # Unpack data\n    y_calib = case_data[\"calib_y\"]\n    mu_calib_models = case_data[\"calib_mu\"]\n    s2_calib_models = case_data[\"calib_s2\"]\n    mu_md_models = case_data[\"md_mu\"]\n    s2_md_models = case_data[\"md_s2\"]\n    alpha = case_data[\"alpha\"]\n    epsilon = case_data[\"epsilon\"]\n    v_min = case_data[\"v_min\"]\n    N_calib = len(y_calib)\n\n    # 1. Calibration Phase\n    mu_bar_calib, v_calib = get_ensemble_predictions(mu_calib_models, s2_calib_models, v_min)\n    \n    # 2. Determine temperature scaling factor tau\n    residuals_sq = (y_calib - mu_bar_calib)**2\n    tau_sq = np.mean(residuals_sq / v_calib)\n    tau = np.sqrt(tau_sq)\n    \n    # 3. Compute empirical coverage on calibration set\n    v_calib_calibrated = tau_sq * v_calib\n    nominal_coverage_c = 1 - alpha\n    z = norm.ppf((1 + nominal_coverage_c) / 2)\n    \n    interval_half_width = z * np.sqrt(v_calib_calibrated)\n    is_covered = np.abs(y_calib - mu_bar_calib) = interval_half_width\n    empirical_coverage = np.sum(is_covered) / N_calib\n    \n    # 4. MD Phase - Triggering\n    mu_bar_md, v_md = get_ensemble_predictions(mu_md_models, s2_md_models, v_min)\n    v_md_calibrated = tau_sq * v_md\n    \n    # To prevent division by zero for any pathological variance\n    std_dev_md_calibrated = np.sqrt(np.maximum(v_md_calibrated, v_min))\n    \n    # Probability P(|error| > epsilon)\n    # This is 2 * (1 - CDF(epsilon / std_dev))\n    arg = epsilon / std_dev_md_calibrated\n    p_values = 2 * (1 - norm.cdf(arg))\n    \n    triggers = np.sum(p_values >= alpha)\n\n    # Round and format output for the case\n    tau_rounded = round(tau, 6)\n    coverage_rounded = round(empirical_coverage, 6)\n    \n    return [tau_rounded, coverage_rounded, int(triggers)]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "在掌握了不确定性量化的基础上，我们可以通过融入物理先验知识来设计更智能的采集函数。一个基本的物理约束是，原子在极短距离内会相互排斥，以防止体系发生非物理性的坍缩。本练习探讨了如何将这一物理原理形式化为一个能量下界，并结合模型的不确定性，使用预测的置信下界（Lower Confidence Bound, LCB）来主动选择那些可能违反此物理边界的构型，从而高效地修正模型的行为。",
            "id": "3431926",
            "problem": "一位材料建模师正在使用主动学习（Active Learning, AL）为多物种体系开发原子间势 $E_{\\theta}(\\mathbf{R})$。该势的训练目标是再现密度泛函理论（Density Functional Theory, DFT）计算的能量，同时在短原子间距下保持物理一致性。根据量子力学，包含库仑相互作用的非相对论多体哈密顿量意味着，当两个原子核相互靠近时，核-核排斥项按 $Z_i Z_j e^2/(4\\pi\\epsilon_0 r_{ij})$ 的形式变化，而泡利不相容原理（Pauli exclusion principle）在极端压缩下会使电子动能升高。这些机制共同确保了当原子被拉得非常近时，总能量不应低于一个排斥能下限。为了引入这一物理原理，建模师定义了一个解析的短程排斥能下限 $E_{\\text{core}}(\\mathbf{R})$，例如通过对所有原子对的 Born-Mayer 形式的对势 $V_{\\text{BM}}(r_{ij})=A_{ij}\\exp(-B_{ij}r_{ij})$ 求和得到，它基于经过充分检验的短程物理学，作为一个下界代理。\n\n由于 $E_{\\theta}(\\mathbf{R})$ 是通过学习得到的，并且在当前训练数据覆盖范围之外存在不确定性，建模师使用了一个模型集成（ensemble）。在构型 $\\mathbf{R}$ 处，该集成的预测分布被近似为均值为 $\\mu(\\mathbf{R})$、标准差为 $\\sigma(\\mathbf{R})$ 的高斯分布。AL 的目标是优先查询那些处于压缩状态下、模型可能违反物理边界条件 $E_{\\theta}(\\mathbf{R})\\ge E_{\\text{core}}(\\mathbf{R})$ 的构型的 DFT 标签，同时要考虑预测不确定性，以控制产生非物理预测的风险。\n\n下面哪个采集规则正确地形式化了一个基于物理的查询策略，该策略旨在找到那些在选定置信度内的预测最坏情况能量可能低于排斥能下限的构型，从而标记出潜在的违规以进行修正？假设用户选择了一个置信度参数 $\\kappa>0$，对应于一个单边置信水平。\n\nA. 查询具有最负边际值 $M_{\\text{LCB}}(\\mathbf{R})=\\mu(\\mathbf{R})-\\kappa\\sigma(\\mathbf{R})-E_{\\text{core}}(\\mathbf{R})$ 的构型 $\\mathbf{R}$，即选择满足 $\\mu(\\mathbf{R})-\\kappa\\sigma(\\mathbf{R})  E_{\\text{core}}(\\mathbf{R})$ 的构型。\n\nB. 查询具有最小均值 $\\mu(\\mathbf{R})$ 的构型 $\\mathbf{R}$。\n\nC. 查询具有最大不确定性 $\\sigma(\\mathbf{R})$ 的构型 $\\mathbf{R}$。\n\nD. 查询具有最大化上置信界（Upper Confidence Bound, UCB）$\\mu(\\mathbf{R}) + \\kappa\\sigma(\\mathbf{R})$ 的构型 $\\mathbf{R}$。",
            "solution": "用户希望我扮演一位STEM教授，解决一个与开发原子间势的主动学习（AL）相关的问题。\n\n### 步骤1：问题验证\n\n对问题陈述的科学有效性、完整性和清晰度进行严格评估。\n\n#### 提取已知条件\n-   **模型**：一个正在通过主动学习（AL）为多物种体系开发的原子间势 $E_{\\theta}(\\mathbf{R})$。\n-   **参考数据**：来自密度泛函理论（DFT）的能量。\n-   **物理约束**：该势在短原子间距下必须物理上一致，意味着总能量不应低于一个排斥能下限。\n-   **排斥能下限模型**：定义了一个解析的短程排斥能下限 $E_{\\text{core}}(\\mathbf{R})$ 作为下界代理，例如，通过对 Born-Mayer 对势 $V_{\\text{BM}}(r_{ij})=A_{ij}\\exp(-B_{ij}r_{ij})$ 求和得到。\n-   **不确定性量化**：该模型是一个集成模型，其对构型 $\\mathbf{R}$ 的预测分布被近似为均值为 $\\mu(\\mathbf{R})$、标准差为 $\\sigma(\\mathbf{R})$ 的高斯分布。\n-   **AL 目标**：为那些模型可能违反物理边界 $E_{\\theta}(\\mathbf{R}) \\ge E_{\\text{core}}(\\mathbf{R})$ 的构型查询 DFT 标签。\n-   **采集策略要求**：该策略必须考虑预测不确定性，以控制产生非物理预测的风险。\n-   **参数**：一个用户选择的置信度参数 $\\kappa > 0$。\n-   **问题**：确定一个采集规则，该规则形式化了一个查询策略，旨在找到那些在选定置信水平内的预测最坏情况能量可能低于排斥能下限 $E_{\\text{core}}(\\mathbf{R})$ 的构型。\n\n#### 使用提取的已知条件进行验证\n-   **科学基础**：该问题在计算材料科学和机器学习领域有坚实的基础。主动学习、DFT、基于集成的不确定性量化、高斯预测分布以及基于物理的约束（特别是通过像 Born-Mayer 这样的势来建模的短程排斥）等概念都是该领域标准的、成熟的实践。关于核-核排斥和泡利不相容原理的物理推理是正确的。\n-   **适定性**：该问题是适定的。它提供了一个明确的目标和所有必要的组成部分（$\\mu(\\mathbf{R})$、$\\sigma(\\mathbf{R})$、$E_{\\text{core}}(\\mathbf{R})$、$\\kappa$）来构建所要求的唯一且有意义的采集函数。\n-   **客观性**：语言技术性强、精确，没有主观或模棱两可的术语。\n\n#### 结论\n问题陈述是有效的。它描述了现代材料建模中一个真实且科学合理的情景。我将继续进行解答。\n\n### 步骤2：求解推导\n\n核心任务是制定一个主动学习采集规则，以识别学习到的势 $E_{\\theta}(\\mathbf{R})$ 可能违反物理下限 $E_{\\text{core}}(\\mathbf{R})$ 的构型。该公式必须是风险规避的，并包含模型的预测不确定性。\n\n1.  在构型 $\\mathbf{R}$ 处，学习到的势的预测不是一个单一值，而是一个概率分布，近似为均值为 $\\mu(\\mathbf{R})$、标准差为 $\\sigma(\\mathbf{R})$ 的高斯分布。\n\n2.  目标是找到那些模型可能预测出非物理低能量（特别是 $E_{\\theta}(\\mathbf{R})  E_{\\text{core}}(\\mathbf{R})$）的构型。\n\n3.  为了规避风险，我们不应只检查平均预测值 $\\mu(\\mathbf{R})$ 是否违反边界。我们必须考虑整个预测分布。在某个置信水平内的“最坏情况”预测对应于预测分布的下端。\n\n4.  对于高斯分布，单边置信区间是使用标准差的倍数构建的。置信下界（Lower Confidence Bound, LCB）为预测值提供了一个统计下限。其定义为：\n    $$ E_{\\text{LCB}}(\\mathbf{R}) = \\mu(\\mathbf{R}) - \\kappa\\sigma(\\mathbf{R}) $$\n    这里，$\\kappa > 0$ 是一个控制置信水平的参数。越大的 $\\kappa$ 对应于越保守的下界（即，真实值高于 $E_{\\text{LCB}}$ 的置信度更高）。\n\n5.  如果一个构型的“最坏情况”预测能量，即 LCB，低于物理下限 $E_{\\text{core}}(\\mathbf{R})$，那么采集规则就应该标记该构型以进行标注。这个条件在数学上表示为：\n    $$ E_{\\text{LCB}}(\\mathbf{R})  E_{\\text{core}}(\\mathbf{R}) $$\n    代入 LCB 的定义，我们得到：\n    $$ \\mu(\\mathbf{R}) - \\kappa\\sigma(\\mathbf{R})  E_{\\text{core}}(\\mathbf{R}) $$\n\n6.  在主动学习循环中，我们通常每次迭代只有预算查询一个或几个构型。因此，我们需要对满足违规条件的候选构型进行排序。一个合乎逻辑的排序方案是优先选择显示出最严重潜在违规的构型。\n\n7.  我们可以定义一个边际值或分数 $M(\\mathbf{R})$，代表 LCB 与物理下限之间的差距：\n    $$ M(\\mathbf{R}) = (\\mu(\\mathbf{R}) - \\kappa\\sigma(\\mathbf{R})) - E_{\\text{core}}(\\mathbf{R}) $$\n    $M(\\mathbf{R})$ 的负值表示潜在的违规。采集规则将是选择使该边际值最小化，即具有最负的 $M(\\mathbf{R})$ 值的构型 $\\mathbf{R}$。这将 AL 过程集中在最受关注的区域。\n\n### 步骤3：逐项分析选项\n\n现在，我将根据推导出的公式评估每个提供的选项。\n\n**A. 查询具有最负边际值 $M_{\\text{LCB}}(\\mathbf{R})=\\mu(\\mathbf{R})-\\kappa\\sigma(\\mathbf{R})-E_{\\text{core}}(\\mathbf{R})$ 的构型 $\\mathbf{R}$，即选择满足 $\\mu(\\mathbf{R})-\\kappa\\sigma(\\mathbf{R})  E_{\\text{core}}(\\mathbf{R})$ 的构型。**\n这个选项直接实现了我们的推导。它定义了一个边际值，即 LCB 与物理下限之间的差值。选择具有“最负”边际值的构型，等同于找到使 $M_{\\text{LCB}}(\\mathbf{R})$ 最小的 $\\mathbf{R}$。这精确地识别出 LCB 最严重地低于物理下限的构型，这正是 AL 目标所要求的。\n**结论：正确**\n\n**B. 查询具有最小均值 $\\mu(\\mathbf{R})$ 的构型 $\\mathbf{R}$。**\n这个策略是朴素的，因为它完全忽略了预测不确定性 $\\sigma(\\mathbf{R})$。一个具有非常低均值但极高确定性（小 $\\sigma$）的预测可能比一个具有稍高均值但极高不确定性（大 $\\sigma$）的预测风险要小得多。它不符合“考虑预测不确定性”的要求。\n**结论：不正确**\n\n**C. 查询具有最大不确定性 $\\sigma(\\mathbf{R})$ 的构型 $\\mathbf{R}$。**\n这是标准的不确定性采样。虽然在探索模型知识的未知领域方面很有用，但它不直接针对物理边界的违反。一个模型可能对某个高能垒区域非常不确定，但这与短程排斥边界的违反无关。该策略没有使用 $E_{\\text{core}}(\\mathbf{R})$ 的信息，因此不是最优的。\n**结论：不正确**\n\n**D. 查询具有最大化上置信界（Upper Confidence Bound, UCB）$\\mu(\\mathbf{R}) + \\kappa\\sigma(\\mathbf{R})$ 的构型 $\\mathbf{R}$。**\n这是一种探索性策略，通常用于寻找具有高潜在回报的区域（例如，在优化问题中）。它与当前的目标（避免非物理的低能量）正好相反。我们关心的是下界，而不是上界。\n**结论：不正确**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "除了物理边界，基本的对称性原理是另一类极其强大的物理先验知识。任何原子体系的总能量都必须在刚体旋转、平移以及相同种类原子置换下保持不变，而力则相应地表现出协变性（equivariance）。本练习将挑战您思考如何将这些基本的对称性原理编码到一个采集函数中，通过主动寻找并修正模型违反这些对称性的构型，从而系统性地提升势函数模型的物理真实性。",
            "id": "3431884",
            "problem": "考虑一个原子间势模型，对于一个由 $N$ 个原子组成的构型，其位置为 $\\mathbf{R} = (\\mathbf{R}_1,\\dots,\\mathbf{R}_N) \\in \\mathbb{R}^{3N}$，种类标签为 $\\mathbf{Z} = (Z_1,\\dots,Z_N)$，该模型可预测总能量 $\\hat{E}(\\mathbf{R},\\mathbf{Z})$ 和原子受力 $\\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) = -\\nabla_{\\mathbf{R}_i} \\hat{E}(\\mathbf{R},\\mathbf{Z})$，其中 $i \\in \\{1,\\dots,N\\}$。在用于原子间势开发的主动学习（AL）中，研究者旨在选择未标记的构型，以使用密度泛函理论（DFT）进行查询，从而使模型得到最快的改进。一种物理感知策略是强制要求真实能量 $E(\\mathbf{R},\\mathbf{Z})$ 对 $\\mathbf{R}$ 的刚体旋转和平移以及同种原子间的排列保持不变，而真实力在这些变换下是等变的（力在旋转下旋转，在平移下保持不变，并在同种原子间随原子标签一起排列）。\n\n设 $\\mathbf{Q} \\in \\mathrm{SO}(3)$ 为旋转矩阵，$\\mathbf{a} \\in \\mathbb{R}^3$ 为平移向量，并定义刚体变换 $T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}) = \\mathbf{Q}\\mathbf{R} + \\mathbf{1} \\otimes \\mathbf{a}$，其中 $\\mathbf{1} \\otimes \\mathbf{a}$ 表示 $N$ 元组 $(\\mathbf{a},\\dots,\\mathbf{a})$。设 $\\Pi(\\mathbf{Z})$ 表示所有仅在由 $\\mathbf{Z}$ 决定的每个同种原子子集内部排列索引的排列集合，对于 $\\pi \\in \\Pi(\\mathbf{Z})$，记 $\\pi \\cdot \\mathbf{R}$ 和 $\\pi \\cdot \\mathbf{Z}$ 为排列后的位置和种类标签。\n\n你需要设计一个主动学习采集泛函 $S(\\mathbf{R},\\mathbf{Z}; \\hat{E}, \\hat{\\mathbf{F}})$，该泛函仅使用模型预测来為候选的未标记构型打分，从而使最大化 $S$ 的过程优先选择那些最强烈违反物理不变性和等变性先验的构型。请从以下选项中选择唯一最佳的一项。\n\nA. \n$$\nS_A(\\mathbf{R},\\mathbf{Z}) = \\mathbb{E}_{\\mathbf{Q},\\mathbf{a}}\\!\\left[ \\left| \\hat{E}\\!\\left(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}\\right) - \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\right| + \\frac{1}{N}\\sum_{i=1}^N \\left\\| \\hat{\\mathbf{F}}_i\\!\\left(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}\\right) - \\mathbf{Q}\\,\\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\| \\right] \n+ \\left\\| \\sum_{i=1}^N \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\| + \\left\\| \\sum_{i=1}^N \\mathbf{R}_i \\times \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\|\n+ \\mathbb{E}_{\\pi \\in \\Pi(\\mathbf{Z})}\\!\\left[ \\left| \\hat{E}(\\pi \\cdot \\mathbf{R}, \\pi \\cdot \\mathbf{Z}) - \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\right| + \\frac{1}{N}\\sum_{i=1}^N \\left\\| \\hat{\\mathbf{F}}_{\\pi(i)}(\\pi \\cdot \\mathbf{R}, \\pi \\cdot \\mathbf{Z}) - \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\| \\right].\n$$\n\nB.\n$$\nS_B(\\mathbf{R},\\mathbf{Z}) = \\left\\| \\sum_{i=1}^N \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\| + \\left\\| \\sum_{i=1}^N \\mathbf{R}_i \\times \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\|.\n$$\n\nC.\n$$\nS_C(\\mathbf{R},\\mathbf{Z}) = \\mathbb{E}_{\\mathbf{Q},\\mathbf{a}}\\!\\left[ \\left| \\hat{E}\\!\\left(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}\\right) - \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\right| + \\frac{1}{N}\\sum_{i=1}^N \\left\\| \\hat{\\mathbf{F}}_i\\!\\left(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}\\right) - \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\| \\right].\n$$\n\nD.\n$$\nS_D(\\mathbf{R},\\mathbf{Z}) = \\mathbb{E}_{\\pi \\in S_N}\\!\\left[ \\left| \\hat{E}(\\pi \\cdot \\mathbf{R}, \\mathbf{Z}) - \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\right| \\right],\n$$\n其中 $S_N$ 是作用于 $N$ 个索引上的全排列群，它作用于位置，但保持 $\\mathbf{Z}$ 不变。\n\nE.\n$$\nS_E(\\mathbf{R},\\mathbf{Z}) = \\mathrm{Var}\\!\\left( \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\;\\text{under stochastic weight perturbations (e.g., dropout)} \\right),\n$$\n它使用模型的认知不确定性作为选择标准。\n\n选择一个选项，该选项通过仅使用模型预测，显式地针对旋转和平移不变性、逐种类的排列不变性以及相应的力等变性条件的违反情况，从而最好地实现了受物理先验约束的主动学习。从不变性和力定义的第一性原理出发，证明你的选择。",
            "solution": "用户希望我扮演一名 STEM 教授，验证所提供的问题陈述，然后通过评估所有选项来推导出正确的解决方案。\n\n### 步骤1：提取已知信息\n\n- **系统：** 一个由 $N$ 个原子组成的构型。\n- **位置：** $\\mathbf{R} = (\\mathbf{R}_1,\\dots,\\mathbf{R}_N) \\in \\mathbb{R}^{3N}$。\n- **种类：** $\\mathbf{Z} = (Z_1,\\dots,Z_N)$。\n- **模型预测：** 总能量 $\\hat{E}(\\mathbf{R},\\mathbf{Z})$ 和原子受力 $\\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) = -\\nabla_{\\mathbf{R}_i} \\hat{E}(\\mathbf{R},\\mathbf{Z})$。\n- **主动学习目标：** 选择未标记的构型，用密度泛函理论（DFT）进行查询，以快速改进模型。\n- **采集策略：** 采集泛函 $S(\\mathbf{R},\\mathbf{Z}; \\hat{E}, \\hat{\\mathbf{F}})$ 应根据模型预测违反物理不变性和等变性先验的强度来为构型打分。\n- **物理先验（对于真实能量 $E$ 和力 $\\mathbf{F}_i$）：**\n    1.  能量 $E$ 对刚体旋转和平移是不变的。\n    2.  能量 $E$ 对同种原子间的排列是不变的。\n    3.  力 $\\mathbf{F}_i$ 在这些相同变换下是等变的。具体来说，力在旋转下旋转，在平移下不变，并随同种原子内的原子标签一起排列。\n- **变换：**\n    - 刚体变换: $T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}) = \\mathbf{Q}\\mathbf{R} + \\mathbf{1} \\otimes \\mathbf{a}$，其中 $\\mathbf{Q} \\in \\mathrm{SO}(3)$ 且 $\\mathbf{a} \\in \\mathbb{R}^3$。\n    - 排列: $\\pi \\in \\Pi(\\mathbf{Z})$，其中 $\\Pi(\\mathbf{Z})$ 是仅在同种原子子集内作用于索引的排列集合。排列后的位置和种类表示为 $\\pi \\cdot \\mathbf{R}$ 和 $\\pi \\cdot \\mathbf{Z}$。\n\n### 步骤2：使用提取的已知信息进行验证\n\n- **科学基础：** 该问题牢固地植根于计算材料科学和机器学习。原子间势、主动学习、DFT 和物理对称性（不变性/等变性）等概念是标准的，并且描述正确。其物理原理是健全的。\n- **适定性：** 任务是基于一组清晰的物理约束来构造一个数学函数（采集泛函）。问题定义明确，通过严谨的分析可以在选项中确定一个唯一的最佳答案。\n- **客观性：** 问题以精确、客观的数学语言陈述。没有主观因素。\n- **缺陷检查：**\n    1.  **科学/事實不健全性：** 无。关于不变性和等变性及其与能量和力的关系的陈述是正确的。例如，将力定义为能量的负梯度是基本原理。\n    2.  **无法形式化/不相关：** 无。该问题是形式化的，并且与指定主题直接相关。\n    3.  **不完整/矛盾的设置：** 无。提供了理解和评估先验所需的所有必要定义。\n    4.  **不切实际/不可行：** 无。在材料科学的主动学习中，基于物理先验设计采集函数是一个实用且已得到研究的领域。\n    5.  **不适定/结构不良：** 无。问题结构清晰，术语在该领域的上下文中定义明确。\n    6.  **伪深刻/琐碎：** 无。该问题需要对物理学中的对称性原理及其数学表示有扎实的理解，使其成为一项不平凡的评估。\n    7.  **超出科学可验证性：** 无。所提出的泛函是可通过计算验证的。\n\n### 步骤3：结论与行动\n\n问题陈述是有效的。我们可以继续进行解答。\n\n### 推导与选项分析\n\n该问题要求构建一个采集泛函 $S(\\mathbf{R},\\mathbf{Z})$，用以量化模型预测 $\\hat{E}$ 和 $\\hat{\\mathbf{F}}$ 对几个物理先验的违反程度。高分应表示严重违反，从而使该构型成为使用 DFT 进行标记的良好候选者。我们将分析每个先验所需的数学形式，然后评估给定的选项。\n\n**1. 刚体对称性：**\n- **能量不变性：** 能量在刚体变换 $T_{\\mathbf{Q},\\mathbf{a}}$ 下必须保持不变。违反程度由差值 $|\\hat{E}(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}), \\mathbf{Z}) - \\hat{E}(\\mathbf{R}, \\mathbf{Z})|$ 来衡量，对于一个完美的模型，该值应为零。\n- **力等变性：** 平移不影响力。旋转 $\\mathbf{Q}$ 会变换力矢量。变换后构型中原子 $i$ 上的力必须是旋转后的原始力：$\\mathbf{F}_i(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}) = \\mathbf{Q} \\mathbf{F}_i(\\mathbf{R},\\mathbf{Z})$。这可以通过链式法则从能量不变性推导出来：$\\mathbf{F}_i(\\mathbf{Q}\\mathbf{R}) = -\\nabla_{\\mathbf{Q}\\mathbf{R}_i} E(\\mathbf{Q}\\mathbf{R}) = -\\mathbf{Q}\\nabla_{\\mathbf{R}_i} E(\\mathbf{R}) = \\mathbf{Q}\\mathbf{F}_i(\\mathbf{R})$。违反程度由差值的范数来衡量：$\\|\\hat{\\mathbf{F}}_i(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}), \\mathbf{Z}) - \\mathbf{Q}\\hat{\\mathbf{F}}_i(\\mathbf{R}, \\mathbf{Z})\\|$。\n- **无穷小形式：** 平移能量不变性意味着所有力的总和为零（$\\sum_i \\mathbf{F}_i = \\mathbf{0}$）。旋转能量不变性意味着总力矩为零（$\\sum_i \\mathbf{R}_i \\times \\mathbf{F}_i = \\mathbf{0}$）。这些是对相同对称性的计算高效的检查方法。违反分数是 $\\|\\sum_i \\hat{\\mathbf{F}}_i\\|$ 和 $\\|\\sum_i \\mathbf{R}_i \\times \\hat{\\mathbf{F}}_i\\|$。\n\n**2. 排列对称性：**\n- **能量不变性：** 对于同种原子的排列 $\\pi \\in \\Pi(\\mathbf{Z})$，能量必须保持不变：$E(\\pi\\cdot\\mathbf{R}, \\pi\\cdot\\mathbf{Z}) = E(\\mathbf{R}, \\mathbf{Z})$。违反程度由 $|\\hat{E}(\\pi\\cdot\\mathbf{R}, \\pi\\cdot\\mathbf{Z}) - \\hat{E}(\\mathbf{R}, \\mathbf{Z})|$ 来衡量。\n- **力等变性：** 如果我们排列原子，新列表中移动到第 $\\pi(i)$ 位置的原子上的力矢量必须等于原始列表中第 $i$ 个原子上的力矢量。即 $\\mathbf{F}_{\\pi(i)}(\\pi \\cdot \\mathbf{R}) = \\mathbf{F}_i(\\mathbf{R})$。违反程度由 $\\|\\hat{\\mathbf{F}}_{\\pi(i)}(\\pi \\cdot \\mathbf{R}) - \\hat{\\mathbf{F}}_i(\\mathbf{R})\\|$ 来衡量。\n\n一个全面的泛函应该结合所有这些违反情况的度量。\n\n---\n\n### 逐项选项分析\n\n**A. $S_A(\\mathbf{R},\\mathbf{Z}) = \\dots$**\n\n这个泛函是三部分的总和：\n1.  $\\mathbb{E}_{\\mathbf{Q},\\mathbf{a}}\\!\\left[ |\\dots| + \\frac{1}{N}\\sum_i \\|\\dots\\| \\right]$: 该项衡量了在有限剛体变换下能量不变性和力等变性的违反情况。它对旋转 $\\mathbf{Q}$ 和平移 $\\mathbf{a}$ 的分布进行平均。能量违反的表达式 $|\\hat{E}(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}) - \\hat{E}(\\mathbf{R},\\mathbf{Z})|$ 是正确的。力违反的表达式 $\\|\\hat{\\mathbf{F}}_i(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}) - \\mathbf{Q}\\,\\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z})\\|$ 正确地捕捉了旋转等变性。\n2.  $\\| \\sum_{i=1}^N \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\| + \\| \\sum_{i=1}^N \\mathbf{R}_i \\times \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\|$: 这些分别是总力和总力矩的范数。它们以无穷小的形式衡量平移和旋转不变性的违反情况。这是一个正确且计算高效的组成部分。\n3.  $\\mathbb{E}_{\\pi \\in \\Pi(\\mathbf{Z})}\\!\\left[ |\\dots| + \\frac{1}{N}\\sum_i \\|\\dots\\| \\right]$: 该项衡量了排列对称性的违反情况。它正确地将排列限制在 $\\pi \\in \\Pi(\\mathbf{Z})$，即仅限于同种原子间的排列。能量项 $|\\hat{E}(\\pi \\cdot \\mathbf{R}, \\pi \\cdot \\mathbf{Z}) - \\hat{E}(\\mathbf{R},\\mathbf{Z})|$ 是正确的。力项 $\\|\\hat{\\mathbf{F}}_{\\pi(i)}(\\pi \\cdot \\mathbf{R}, \\pi \\cdot \\mathbf{Z}) - \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z})\\|$ 正确地捕捉了排列下所需的力等变性。\n\n这个泛函是全面的，包括对刚体对称性的有限和无穷小检查，以及对能量和力的同种原子排列对称性的正确检查。所有组成部分在物理上和数学上都是正确的。\n**结论：正确**\n\n**B. $S_B(\\mathbf{R},\\mathbf{Z}) = \\dots$**\n\n这个泛函仅包含总力和总力矩的检查，即 $\\|\\sum_i \\hat{\\mathbf{F}}_i\\|$ 和 $\\|\\sum_i \\mathbf{R}_i \\times \\hat{\\mathbf{F}}_i\\|$。虽然这些是衡量平移和旋转不变性违反情况的有效度量，但该泛函是不完整的。它完全忽略了对排列对称性的检查，也忽略了对有限（非无穷小）刚体变换的测试，而后者是问题描述范围的一部分。\n**结论：不正确**\n\n**C. $S_C(\\mathbf{R},\\mathbf{Z}) = \\dots$**\n\n这个泛函试图检查刚体对称性的违反情况。能量部分是正确的。然而，力部分是 $\\frac{1}{N}\\sum_i \\|\\hat{\\mathbf{F}}_i(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}) - \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z})\\|$。这个表达式检查的是力在旋转下的*不变性*，即 $\\hat{\\mathbf{F}}_i(\\mathbf{Q}\\mathbf{R}) = \\hat{\\mathbf{F}}_i(\\mathbf{R})$。这在物理上是不正确的。力是矢量，必须随系统旋转；它们是*等变的*，而不是不变的。正确的条件是 $\\hat{\\mathbf{F}}_i(\\mathbf{Q}\\mathbf{R}) = \\mathbf{Q}\\hat{\\mathbf{F}}_i(\\mathbf{R})$。此外，这个泛函完全忽略了对排列对称性的任何检查。\n**结论：不正确**\n\n**D. $S_D(\\mathbf{R},\\mathbf{Z}) = \\dots$**\n\n这个泛函 $\\mathbb{E}_{\\pi \\in S_N}\\!\\left[ \\left| \\hat{E}(\\pi \\cdot \\mathbf{R}, \\mathbf{Z}) - \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\right| \\right]$ 有两个主要缺陷。首先，它对全对称群 $S_N$ 进行平均，该群排列所有 $N$ 个原子而不考虑种类。物理不变性仅对*同种*原子的排列成立，即 $\\pi \\in \\Pi(\\mathbf{Z})$。对于多物种系统，强制在 $S_N$ 下不变会训练出物理上错误模型（例如，无法区分碳原子和氧原子）。其次，它只考虑了能量不变性，完全忽略了力等变性以及所有刚体对称性。\n**结论：不正确**\n\n**E. $S_E(\\mathbf{R},\\mathbf{Z}) = \\dots$**\n\n这个泛函基于模型预测在权重扰动下的方差，是模型认知不确定性的一种度量。这是主动学习中一种有效且常见的策略，通常被称为“委员会查询”或不确定性抽样。然而，问题陈述明確要求一个“显式地针对物理不变性和等变性先验的违反情况”的泛函。选项 E 没有做到这一点；它是一个通用的不确定性度量，而不是一个物理违反度量。因此，它不满足规定的设计要求。\n**结论：不正确**\n\n### 结论\n\n选项A是唯一一个正确且全面地基于所有指定物理先验（能量的旋转、平移和排列对称性（不变性）以及力的相应对称性（等变性））的违反情况来构建采集泛函的选项。它是问题陈述中所需策略的最完整和最正确的实现。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}