{
    "hands_on_practices": [
        {
            "introduction": "一个有效的原子间势模型必须遵守基础的物理对称性原理。主动学习的一个高明策略，正是去寻找当前模型最可能违反这些物理定律的构型，并进行标注，因为这些构型能提供最丰富的新信息。本练习将引导你思考如何将能量的不变性（invariance）和力的等变性（equivariance）这些物理先验知识，精确地转化为一个数学形式的采集函数 ()。",
            "id": "3431884",
            "problem": "考虑一个原子间势模型，对于一个由$N$个原子组成的构型，其位置为$\\mathbf{R} = (\\mathbf{R}_1,\\dots,\\mathbf{R}_N) \\in \\mathbb{R}^{3N}$，物种标签为$\\mathbf{Z} = (Z_1,\\dots,Z_N)$，该模型预测总能量$\\hat{E}(\\mathbf{R},\\mathbf{Z})$和原子受力$\\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) = -\\nabla_{\\mathbf{R}_i} \\hat{E}(\\mathbf{R},\\mathbf{Z})$，其中$i \\in \\{1,\\dots,N\\}$。在用于原子间势开发的主动学习（Active Learning, AL）中，研究者试图选择未标记的构型，以使用密度泛函理论（Density Functional Theory, DFT）进行查询，从而使模型能够最快地改进。一种考虑物理规律的策略是强制真实能量$E(\\mathbf{R},\\mathbf{Z})$对$\\mathbf{R}$的刚体旋转和平移以及同种原子间的置换保持不变，而真实力在这些变换下是等变的（力在旋转下随之旋转，在平移下保持不变，并在同种原子内随原子标签一起置换）。\n\n令$\\mathbf{Q} \\in \\mathrm{SO}(3)$为一个旋转矩阵，$\\mathbf{a} \\in \\mathbb{R}^3$为一个平移向量，并定义刚体变换$T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}) = \\mathbf{Q}\\mathbf{R} + \\mathbf{1} \\otimes \\mathbf{a}$，其中$\\mathbf{1} \\otimes \\mathbf{a}$表示$N$元组$(\\mathbf{a},\\dots,\\mathbf{a})$。令$\\Pi(\\mathbf{Z})$表示所有仅在由$\\mathbf{Z}$决定的每个同种物种子集内部置换索引的置换集合，对于$\\pi \\in \\Pi(\\mathbf{Z})$，使用$\\pi \\cdot \\mathbf{R}$和$\\pi \\cdot \\mathbf{Z}$表示置换后的位置和物种标签。\n\n你的任务是设计一个主动学习的采集函数$S(\\mathbf{R},\\mathbf{Z}; \\hat{E}, \\hat{\\mathbf{F}})$，该函数仅使用模型预测来对候选的未标记构型进行评分，从而使得最大化$S$会优先选择那些最严重违反物理不变性和等变性先验的构型。请从以下选项中选择唯一最佳的一项。\n\nA. \n$$\nS_A(\\mathbf{R},\\mathbf{Z}) = \\mathbb{E}_{\\mathbf{Q},\\mathbf{a}}\\!\\left[ \\left| \\hat{E}\\!\\left(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}\\right) - \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\right| + \\frac{1}{N}\\sum_{i=1}^N \\left\\| \\hat{\\mathbf{F}}_i\\!\\left(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}\\right) - \\mathbf{Q}\\,\\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\| \\right] \n+ \\left\\| \\sum_{i=1}^N \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\| + \\left\\| \\sum_{i=1}^N \\mathbf{R}_i \\times \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\|\n+ \\mathbb{E}_{\\pi \\in \\Pi(\\mathbf{Z})}\\!\\left[ \\left| \\hat{E}(\\pi \\cdot \\mathbf{R}, \\pi \\cdot \\mathbf{Z}) - \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\right| + \\frac{1}{N}\\sum_{i=1}^N \\left\\| \\hat{\\mathbf{F}}_{\\pi(i)}(\\pi \\cdot \\mathbf{R}, \\pi \\cdot \\mathbf{Z}) - \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\| \\right].\n$$\n\nB.\n$$\nS_B(\\mathbf{R},\\mathbf{Z}) = \\left\\| \\sum_{i=1}^N \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\| + \\left\\| \\sum_{i=1}^N \\mathbf{R}_i \\times \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\|.\n$$\n\nC.\n$$\nS_C(\\mathbf{R},\\mathbf{Z}) = \\mathbb{E}_{\\mathbf{Q},\\mathbf{a}}\\!\\left[ \\left| \\hat{E}\\!\\left(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}\\right) - \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\right| + \\frac{1}{N}\\sum_{i=1}^N \\left\\| \\hat{\\mathbf{F}}_i\\!\\left(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}\\right) - \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\right\\| \\right].\n$$\n\nD.\n$$\nS_D(\\mathbf{R},\\mathbf{Z}) = \\mathbb{E}_{\\pi \\in S_N}\\!\\left[ \\left| \\hat{E}(\\pi \\cdot \\mathbf{R}, \\mathbf{Z}) - \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\right| \\right],\n$$\n其中$S_N$是作用于位置但保持$\\mathbf{Z}$不变的$N$个索引上的全置换群。\n\nE.\n$$\nS_E(\\mathbf{R},\\mathbf{Z}) = \\mathrm{Var}\\!\\left( \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\;\\text{under stochastic weight perturbations (e.g., dropout)} \\right),\n$$\n该方法使用模型的认知不确定性作为选择标准。\n\n请选择能够通过明确地针对旋转和平移不变性、按物种的置换不变性以及相应的力等变性条件的违反情况，仅使用模型预测来最佳实现基于物理先验约束的主动学习的选项。从不变性和力的第一性原理定义出发，证明您的选择是正确的。",
            "solution": "用户希望我扮演一名STEM教授，验证所提供的问题陈述，然后通过评估所有选项来推导出正确的解决方案。\n\n### 第一步：提取已知条件\n\n- **系统：** 一个由$N$个原子组成的构型。\n- **位置：** $\\mathbf{R} = (\\mathbf{R}_1,\\dots,\\mathbf{R}_N) \\in \\mathbb{R}^{3N}$。\n- **物种：** $\\mathbf{Z} = (Z_1,\\dots,Z_N)$。\n- **模型预测：** 总能量 $\\hat{E}(\\mathbf{R},\\mathbf{Z})$ 和原子受力 $\\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) = -\\nabla_{\\mathbf{R}_i} \\hat{E}(\\mathbf{R},\\mathbf{Z})$。\n- **主动学习目标：** 选择未标记的构型，用密度泛函理论（DFT）进行查询，以快速改进模型。\n- **采集策略：** 采集函数 $S(\\mathbf{R},\\mathbf{Z}; \\hat{E}, \\hat{\\mathbf{F}})$ 应根据模型预测违反物理不变性和等变性先验的程度对构型进行评分。\n- **物理先验（针对真实能量 $E$ 和力 $\\mathbf{F}_i$）：**\n    1.  能量 $E$ 对刚体旋转和平移是不变的。\n    2.  能量 $E$ 对同种原子间的置换是不变的。\n    3.  力 $\\mathbf{F}_i$ 在这些相同的变换下是等变的。具体来说，力在旋转下会随之旋转，在平移下保持不变，并在同种原子内随原子标签一起置换。\n- **变换：**\n    - 刚体变换：$T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}) = \\mathbf{Q}\\mathbf{R} + \\mathbf{1} \\otimes \\mathbf{a}$，其中 $\\mathbf{Q} \\in \\mathrm{SO}(3)$ 且 $\\mathbf{a} \\in \\mathbb{R}^3$。\n    - 置换：$\\pi \\in \\Pi(\\mathbf{Z})$，其中 $\\Pi(\\mathbf{Z})$ 是仅在同种物种子集内作用于索引的置换集合。置换后的位置和物种记为 $\\pi \\cdot \\mathbf{R}$ 和 $\\pi \\cdot \\mathbf{Z}$。\n\n### 第二步：使用提取的已知条件进行验证\n\n- **科学基础：** 该问题牢固地植根于计算材料科学和机器学习领域。原子间势、主动学习、DFT 以及物理对称性（不变性/等变性）等概念都是标准的，并且描述正确。其物理原理是合理的。\n- **适定性：** 任务是基于一组清晰的物理约束来构造一个数学函数（采集函数）。问题定义明确，并且可以通过严谨的分析从选项中确定唯一的最佳答案。\n- **客观性：** 问题以精确、客观的数学语言陈述。没有主观因素。\n- **缺陷检查：**\n    1.  **科学/事实不健全：** 无。关于不变性、等变性及其与能量和力的关系的陈述是正确的。例如，将力定义为能量的负梯度是基本原理。\n    2.  **无法形式化/不相关：** 无。问题是形式化的，并且与指定主题直接相关。\n    3.  **设置不完整/矛盾：** 无。提供了理解和评估先验所需的所有必要定义。\n    4.  **不切实际/不可行：** 无。在材料科学的主动学习中，基于物理先验设计采集函数是一个实用且经过研究的领域。\n    5.  **不适定/结构不良：** 无。问题结构清晰，术语在该领域的背景下定义明确。\n    6.  **伪深刻/琐碎：** 无。该问题要求对物理学中的对称性原理及其数学表示有扎实的理解，使其成为一个不平凡的评估。\n    7.  **无法科学验证：** 无。所提出的泛函在计算上是可验证的。\n\n### 第三步：结论与行动\n\n问题陈述是**有效的**。我们可以继续进行求解。\n\n### 推导与选项分析\n\n该问题要求构造一个采集函数 $S(\\mathbf{R},\\mathbf{Z})$，该函数通过模型预测 $\\hat{E}$ 和 $\\hat{\\mathbf{F}}$ 来量化对若干物理先验的违反程度。高分应表示严重的违反，从而使该构型成为使用 DFT 进行标记的良好候选者。我们将分析每个先验所需的数学形式，然后评估给定的选项。\n\n**1. 刚体对称性：**\n- **能量不变性：** 能量在刚体变换 $T_{\\mathbf{Q},\\mathbf{a}}$ 下必须是不变的。违反程度由差值 $|\\hat{E}(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}), \\mathbf{Z}) - \\hat{E}(\\mathbf{R}, \\mathbf{Z})|$ 来衡量，对于一个完美的模型，该值应为零。\n- **力等变性：** 平移不影响力。旋转 $\\mathbf{Q}$ 会变换力矢量。变换后构型中原子 $i$ 上的力必须是旋转后的原始力：$\\mathbf{F}_i(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}) = \\mathbf{Q} \\mathbf{F}_i(\\mathbf{R},\\mathbf{Z})$。这可以通过链式法则从能量不变性推导得出：$\\mathbf{F}_i(\\mathbf{Q}\\mathbf{R}) = -\\nabla_{\\mathbf{Q}\\mathbf{R}_i} E(\\mathbf{Q}\\mathbf{R}) = -\\mathbf{Q}\\nabla_{\\mathbf{R}_i} E(\\mathbf{R}) = \\mathbf{Q}\\mathbf{F}_i(\\mathbf{R})$。违反程度由差值的范数来衡量：$\\|\\hat{\\mathbf{F}}_i(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}), \\mathbf{Z}) - \\mathbf{Q}\\hat{\\mathbf{F}}_i(\\mathbf{R}, \\mathbf{Z})\\|$。\n- **无穷小形式：** 平移能量不变性意味着所有力的总和为零（$\\sum_i \\mathbf{F}_i = \\mathbf{0}$）。旋转能量不变性意味着总力矩为零（$\\sum_i \\mathbf{R}_i \\times \\mathbf{F}_i = \\mathbf{0}$）。这些是对相同对称性的计算高效的检查。违反分数是 $\\|\\sum_i \\hat{\\mathbf{F}}_i\\|$ 和 $\\|\\sum_i \\mathbf{R}_i \\times \\hat{\\mathbf{F}}_i\\|$。\n\n**2. 置换对称性：**\n- **能量不变性：** 对于同种原子的置换 $\\pi \\in \\Pi(\\mathbf{Z})$，能量必须是不变的：$E(\\pi\\cdot\\mathbf{R}, \\pi\\cdot\\mathbf{Z}) = E(\\mathbf{R}, \\mathbf{Z})$。违反程度由 $|\\hat{E}(\\pi\\cdot\\mathbf{R}, \\pi\\cdot\\mathbf{Z}) - \\hat{E}(\\mathbf{R}, \\mathbf{Z})|$ 来衡量。\n- **力等变性：** 如果我们置换原子，新列表中移动到第 $\\pi(i)$ 个位置的原子上的力矢量必须等于原始列表中第 $i$ 个原子上的力矢量。即 $\\mathbf{F}_{\\pi(i)}(\\pi \\cdot \\mathbf{R}) = \\mathbf{F}_i(\\mathbf{R})$。违反程度由 $\\|\\hat{\\mathbf{F}}_{\\pi(i)}(\\pi \\cdot \\mathbf{R}) - \\hat{\\mathbf{F}}_i(\\mathbf{R})\\|$ 来衡量。\n\n一个全面的泛函应该结合所有这些违反情况的度量。\n\n---\n\n### 逐项选项分析\n\n**A. $S_A(\\mathbf{R},\\mathbf{Z}) = \\dots$**\n\n该泛函是三部分之和：\n1.  $\\mathbb{E}_{\\mathbf{Q},\\mathbf{a}}\\!\\left[ |\\dots| + \\frac{1}{N}\\sum_i \\|\\dots\\| \\right]$：该项衡量在有限刚体变换下对能量不变性和力等变性的违反情况。它对旋转 $\\mathbf{Q}$ 和平移 $\\mathbf{a}$ 的分布进行平均。能量违反的表达式 $|\\hat{E}(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}) - \\hat{E}(\\mathbf{R},\\mathbf{Z})|$ 是正确的。力违反的表达式 $\\|\\hat{\\mathbf{F}}_i(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}) - \\mathbf{Q}\\,\\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z})\\|$ 正确地捕捉了旋转等变性。\n2.  $\\| \\sum_{i=1}^N \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\| + \\| \\sum_{i=1}^N \\mathbf{R}_i \\times \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z}) \\|$：这两项分别是总力和总力矩的范数。它们以无穷小形式衡量对平移和旋转不变性的违反情况。这是一个正确且计算高效的组成部分。\n3.  $\\mathbb{E}_{\\pi \\in \\Pi(\\mathbf{Z})}\\!\\left[ |\\dots| + \\frac{1}{N}\\sum_i \\|\\dots\\| \\right]$：该项衡量对置换对称性的违反情况。它正确地将置换限制在 $\\pi \\in \\Pi(\\mathbf{Z})$ 内，即仅限于同种物种的置换。能量项 $|\\hat{E}(\\pi \\cdot \\mathbf{R}, \\pi \\cdot \\mathbf{Z}) - \\hat{E}(\\mathbf{R},\\mathbf{Z})|$ 是正确的。力项 $\\|\\hat{\\mathbf{F}}_{\\pi(i)}(\\pi \\cdot \\mathbf{R}, \\pi \\cdot \\mathbf{Z}) - \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z})\\|$ 正确地捕捉了置换下所需的力等变性。\n\n该泛函是全面的，包括对刚体对称性的有限和无穷小检查，以及对能量和力的同种物种置换对称性的正确检查。所有组成部分在物理上和数学上都是正确的。\n**结论：正确**\n\n**B. $S_B(\\mathbf{R},\\mathbf{Z}) = \\dots$**\n\n该泛函仅包含总力和总力矩的检查，即 $\\|\\sum_i \\hat{\\mathbf{F}}_i\\|$ 和 $\\|\\sum_i \\mathbf{R}_i \\times \\hat{\\mathbf{F}}_i\\|$。虽然这些是衡量平移和旋转不变性违反情况的有效度量，但该泛函是不完整的。它完全忽略了对置换对称性的检查，也忽略了对有限（非无穷小）刚体变换的测试，而后者是问题描述范围的一部分。\n**结论：不正确**\n\n**C. $S_C(\\mathbf{R},\\mathbf{Z}) = \\dots$**\n\n该泛函试图检查刚体对称性的违反情况。能量部分是正确的。然而，力部分是 $\\frac{1}{N}\\sum_i \\|\\hat{\\mathbf{F}}_i(T_{\\mathbf{Q},\\mathbf{a}}(\\mathbf{R}),\\mathbf{Z}) - \\hat{\\mathbf{F}}_i(\\mathbf{R},\\mathbf{Z})\\|$。此表达式检查的是力在旋转下的*不变性*，即 $\\hat{\\mathbf{F}}_i(\\mathbf{Q}\\mathbf{R}) = \\hat{\\mathbf{F}}_i(\\mathbf{R})$。这在物理上是不正确的。力是矢量，必须随系统旋转；它们是*等变的*，而不是不变的。正确的条件是 $\\hat{\\mathbf{F}}_i(\\mathbf{Q}\\mathbf{R}) = \\mathbf{Q}\\hat{\\mathbf{F}}_i(\\mathbf{R})$。此外，该泛函完全忽略了对置换对称性的任何检查。\n**结论：不正确**\n\n**D. $S_D(\\mathbf{R},\\mathbf{Z}) = \\dots$**\n\n该泛函 $\\mathbb{E}_{\\pi \\in S_N}\\!\\left[ \\left| \\hat{E}(\\pi \\cdot \\mathbf{R}, \\mathbf{Z}) - \\hat{E}(\\mathbf{R},\\mathbf{Z}) \\right| \\right]$ 有两个主要缺陷。首先，它对整个对称群 $S_N$ 进行平均，该群不分物种地置换所有 $N$ 个原子。物理不变性仅对*相同*物种的置换成立，即 $\\pi \\in \\Pi(\\mathbf{Z})$。对于多物种系统，强制在 $S_N$ 下不变会训练出物理上错误模型（例如，无法区分碳原子和氧原子）。其次，它只考虑了能量不变性，完全忽略了力等变性以及所有刚体对称性。\n**结论：不正确**\n\n**E. $S_E(\\mathbf{R},\\mathbf{Z}) = \\dots$**\n\n该泛函基于权重扰动下模型预测的方差，是模型认知不确定性的一种度量。这是主动学习中一种有效且常见的策略，通常称为“委员会查询”或不确定性抽样。然而，问题陈述明确要求一个能够“明确地针对物理不变性和等变性先验的违反情况”的泛函。选项E没有这样做；它是一个通用的不确定性度量，而不是一个物理违反度量。因此，它不满足规定的设计要求。\n**结论：不正确**\n\n### 结论\n\n选项A是唯一一个根据所有指定的物理先验（能量的旋转、平移和置换不变性，以及力的相应等变性）的违反情况，正确且全面地构建了采集函数的选项。它是问题陈述中提出的所需策略的最完整和最正确的实现。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在计算资源有限的现实情况下，主动学习往往需要一次性选择一批（a batch）构型进行标注，而非仅仅挑选单个最优者。这个选择过程是一个典型的成本效益优化问题：如何在给定的计算总预算内，挑选一组构型，以实现模型精度的最大化提升。本练习将此问题抽象为经典的0-1背包问题 ()，通过编程实践，你将学会如何制定最优的批量标注策略。",
            "id": "3431900",
            "problem": "您正在计算材料科学领域中使用主动学习方法开发原子间势。在每个主动学习轮次中，您必须选择候选原子构型（下文称为“帧”）的一个子集，以使用密度泛函理论（DFT）进行第一性原理计算来标记它们。标记每个帧都会消耗计算资源，并受固定预算的限制。假设给定一组 $n$ 个帧，索引为 $i \\in \\{0,1,\\dots,n-1\\}$。每个帧 $i$ 都有一个预期误差减少效用 $u_i$（无量纲，表示如果该帧被标记并纳入训练，模型泛化误差的预期减少量）和一个以核时单位计量的标记成本 $c_i$。您还有一个总预算 $B$（核时单位）。您的目标是选择一个帧的子集，以在遵守DFT预算约束的同时，最大化总预期误差减少量。\n\n形式上，定义二元决策变量 $x_i \\in \\{0,1\\}$ 表示是否选择帧 $i$。选择问题如下：\n$$\n\\text{maximize } \\sum_{i=0}^{n-1} u_i x_i \\quad \\text{subject to} \\quad \\sum_{i=0}^{n-1} c_i x_i \\le B, \\quad x_i \\in \\{0,1\\}.\n$$\n假设 $c_i$ 和 $B$ 是以核时单位计量的非负整数，而 $u_i$ 是非负实数。请注意，成本 $c_i = 0$ 是允许的，它模拟了帧已被廉价标记或无需额外成本即可获得的情况。\n\n决胜规则必须是确定性的，并遵循以下顺序：\n- 在预算内所有能达到最大总效用的子集中，选择总成本（以核时单位计）最小的那个。\n- 如果仍然存在平局，选择当索引按升序排列时字典序最小的索引集（即，偏好在对排序索引列表进行标准字典序比较时更小的子集）。\n\n您的程序必须实现一个算法，根据上述规范为每个测试用例返回所选的索引。索引必须以零为基准进行报告。所有返回的选择必须按升序排序。\n\n测试套件：\n请为以下测试用例提供结果。在每个用例中，报告所选索引的列表。\n\n- 测试用例 1（正常路径，预算适中）：\n  - 效用：$\\mathbf{u} = [0.8, 1.0, 1.2, 0.3]$。\n  - 成本（核时单位）：$\\mathbf{c} = [4, 5, 6, 2]$。\n  - 预算（核时单位）：$B = 10$。\n\n- 测试用例 2（边界条件，预算为零）：\n  - 效用：$\\mathbf{u} = [1.1, 0.9]$。\n  - 成本（核时单位）：$\\mathbf{c} = [3, 4]$。\n  - 预算（核时单位）：$B = 0$。\n\n- 测试用例 3（所有项目都符合预算）：\n  - 效用：$\\mathbf{u} = [0.5, 0.7, 0.9]$。\n  - 成本（核时单位）：$\\mathbf{c} = [1, 2, 3]$。\n  - 预算（核时单位）：$B = 6$。\n\n- 测试用例 4（需要字典序决胜的平局情况）：\n  - 效用：$\\mathbf{u} = [1.0, 1.0, 0.1]$。\n  - 成本（核时单位）：$\\mathbf{c} = [3, 3, 1]$。\n  - 预算（核时单位）：$B = 4$。\n\n- 测试用例 5（存在零成本项目）：\n  - 效用：$\\mathbf{u} = [0.6, 0.4, 0.9]$。\n  - 成本（核时单位）：$\\mathbf{c} = [0, 2, 2]$。\n  - 预算（核时单位）：$B = 2$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个条目是相应测试用例的已排序选择索引列表。例如，一个包含三个测试用例的输出可能看起来像 $[\\,[0,2],[\\,],[1,3]\\ ]$（不需要空格）。唯一打印的行必须是这个严格符合要求格式的列表。",
            "solution": "用户提供了一个有效的问题陈述。\n\n该问题是经典 **0-1背包问题** 的一个变种。我们被要求选择一个项目（原子构型帧）的子集，以最大化总效用（预期误差减少量），同时受限于一个重量约束（总计算成本不超过预算 $B$）。这些项目是离散的，不能部分选择（$x_i \\in \\{0,1\\}$）。\n\n该问题由以下整数线性规划定义：\n$$\n\\text{maximize } \\sum_{i=0}^{n-1} u_i x_i \\\\\n\\text{subject to } \\sum_{i=0}^{n-1} c_i x_i \\le B \\\\\nx_i \\in \\{0,1\\}\n$$\n其中 $u_i$ 是帧 $i$ 的效用， $c_i$ 是其成本， $B$ 是总预算。问题因一个三层的确定性决胜规则而变得复杂：\n1.  最大化总效用 $\\sum u_i x_i$。\n2.  对于具有相同最大效用的子集，最小化总成本 $\\sum c_i x_i$。\n3.  如果仍然存在平局，选择其排序后的索引列表在字典序上最小的子集。\n\n考虑到整数成本和预算，以及测试用例中项目集规模相对较小，**动态规划（DP）**方法是合适且高效的。为了处理复杂的决胜规则，我们DP表中存储的状态必须包含所有三个标准的信息。\n\n让我们将给定预算容量 $w$ 的DP状态定义为一个元组：$(\\text{效用}, \\text{成本}, \\text{索引})$。“最佳”状态由一个自定义比较函数确定，该函数实现了指定的决胜规则。如果满足以下任一条件，状态 $S_1 = (u_1, c_1, \\text{idx}_1)$ 被认为优于状态 $S_2 = (u_2, c_2, \\text{idx}_2)$：\n- $u_1 > u_2$，或\n- $u_1 = u_2$ 且 $c_1 < c_2$，或\n- $u_1 = u_2$，$c_1 = c_2$，且列表 $\\text{idx}_1$ 的字典序小于 $\\text{idx}_2$。\n\n我们将使用一个大小为 $B+1$ 的一维DP数组 `dp`。`dp[w]` 将存储在预算最多为 $w$ 时可达到的最佳状态。该数组被初始化为一个表示零效用、零成本和空索引集的状态：$(0.0, 0, [])$。\n\n算法通过按索引递增的顺序遍历每个帧 $i \\in \\{0, 1, \\dots, n-1\\}$ 来进行。这个特定的顺序对于正确解决字典序决胜规则至关重要。对于每个具有效用 $u_i$ 和成本 $c_i$ 的帧 $i$，我们更新 `dp` 表。为确保每个帧最多被考虑一次（0-1约束），我们按相反的顺序遍历预算 $w$，从 $B$ 向下到 $c_i$。\n\n对于每个预算容量 $w$，我们考虑帧 $i$ 的两种可能性：\n1.  **不选择帧 $i$**：预算 $w$ 的最佳状态仍然是由前面帧确定的 `dp[w]`。\n2.  **选择帧 $i$**：这仅在 $w \\ge c_i$ 时可能。新的候选状态通过获取剩余预算 `dp[w - c_i]` 的最优状态，并加上帧 $i$ 的效用、成本和索引来形成。\n\n状态更新的递推关系为：\n`dp[w] = better_of(dp[w], dp[w - c_i] + {u_i, c_i, i})`\n\n状态上的 `+` 操作意味着创建一个新状态，其中效用和成本相加，索引 $i$ 被附加到索引列表中。由于我们按索引 $i$ 的递增顺序处理帧，并且 `dp` 中的索引列表始终是排序的，因此将 $i$ 附加到较小索引的列表后仍能保持排序顺序。\n\n遍历所有帧后，`dp[B]` 将持有预算上限为 $B$ 的最优状态。DP的构建方式确保了 `dp[w]` 代表预算小于或等于 $w$ 的最佳结果，因为任何针对较小预算的解对于较大预算也是一个有效的候选解。因此，整个问题的解就是存储在 `dp[B]` 中的索引集。\n\n该算法的时间复杂度为 $O(n \\cdot B \\cdot k)$，其中 $n$ 是帧的数量， $B$ 是预算， $k$ 是解中项目的平均数量，它决定了列表操作（复制和比较）的成本。对于给定的问题约束（其中 $n$ 很小），这是非常高效的。空间复杂度为 $O(B \\cdot k)$。",
            "answer": "```python\nimport numpy as np\n\ndef _is_better(s1, s2):\n    \"\"\"\n    Compares two states s1 and s2 based on the problem's tie-breaking rules.\n    A state is a tuple: (utility, cost, indices).\n    Returns True if s1 is better than s2.\n    \"\"\"\n    u1, c1, idx1 = s1\n    u2, c2, idx2 = s2\n    \n    if u1 > u2:\n        return True\n    if u1  u2:\n        return False\n    \n    # Utilities are equal, compare costs (lower is better)\n    if c1  c2:\n        return True\n    if c1 > c2:\n        return False\n        \n    # Utilities and costs are equal, compare index lists (lexicographically smaller is better)\n    # Python's default list comparison is lexicographical.\n    return idx1  idx2\n\ndef _solve_knapsack(utilities, costs, budget):\n    \"\"\"\n    Solves the 0-1 Knapsack problem with special tie-breaking rules using dynamic programming.\n    \"\"\"\n    n = len(utilities)\n    \n    # dp[w] stores the best (utility, cost, indices) tuple for a budget of at most w.\n    base_state = (0.0, 0, [])\n    dp = [base_state] * (budget + 1)\n\n    # Process items in their natural order (sorted by index 0, 1, ..., n-1)\n    for i in range(n):\n        u_i, c_i = utilities[i], costs[i]\n        \n        # Iterate backwards over the budget for 0-1 knapsack logic\n        for w in range(budget, c_i - 1, -1):\n            \n            # The state we can build upon if we add item i\n            prev_state = dp[w - c_i]\n            prev_u, prev_c, prev_indices = prev_state\n            \n            # Create candidate state by adding item i\n            candidate_state = (\n                prev_u + u_i,\n                prev_c + c_i,\n                prev_indices + [i]\n            )\n\n            # Compare candidate with current best for budget w\n            current_state = dp[w]\n            \n            if _is_better(candidate_state, current_state):\n                dp[w] = candidate_state\n    \n    # The best solution for a budget up to B is at dp[B].\n    final_state = dp[budget]\n    \n    # The indices list is already sorted due to the processing order.\n    return final_state[2]\n\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print the final output.\n    \"\"\"\n    test_cases = [\n        {'u': [0.8, 1.0, 1.2, 0.3], 'c': [4, 5, 6, 2], 'B': 10},\n        {'u': [1.1, 0.9], 'c': [3, 4], 'B': 0},\n        {'u': [0.5, 0.7, 0.9], 'c': [1, 2, 3], 'B': 6},\n        {'u': [1.0, 1.0, 0.1], 'c': [3, 3, 1], 'B': 4},\n        {'u': [0.6, 0.4, 0.9], 'c': [0, 2, 2], 'B': 2},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = _solve_knapsack(case['u'], case['c'], case['B'])\n        results.append(result)\n\n    # Format the final output string to be a compact representation of a list of lists.\n    # e.g., [[0,2],[],[0,1,2]]\n    print(str(results).replace(' ', ''))\n\nsolve()\n```"
        },
        {
            "introduction": "机器学习势函数给出的不确定性预测，只有在经过良好校准后才具有可靠的指导意义。本练习将指导你完成一个完整的实践流程：首先，使用温度缩放（temperature scaling）方法校准深度集成（deep ensemble）模型预测的不确定性；然后，利用校准后的置信区间，在分子动力学模拟中动态触发高精度的DFT计算 ()。这个从头构建的编程任务，旨在加深你对不确定性量化在自适应模拟中关键作用的理解。",
            "id": "3431917",
            "problem": "您将获得一个用于图神经网络 (GNN) 原子间势的不确定性校准的综合但科学上一致的设置，该设置使用深度集成和温度缩放，并随后使用校准后的预测区间来决定在分子动力学 (MD) 过程中何时实时触发密度泛函理论 (DFT) 评估。所有能量单位均为电子伏特，所有方差单位均为平方电子伏特。您的任务是实现一个完整的程序，纯粹基于概率论和统计学的基本原理来执行以下步骤。\n\n定义与假设：\n- 深度集成由 $M$ 个独立训练的模型组成。对于构型索引 $i$，模型索引 $m$ 提供预测的平均能量 $\\mu_{i,m}$ 和预测的偶然不确定性方差 $s^{2}_{i,m}$。对于任意 $M$ 个模型的集合，集成预测均值是算术平均值，集成预测方差是预测的偶然方差的平均值与模型均值的方差（认知不确定性贡献）之和，两者都作为 $M$ 个模型的总体矩计算。\n- 在一个具有已知真实能量 $y_{i}$ 的校准集上，我们假设一个高斯似然，其残差为 $r_{i} = y_{i} - \\bar{\\mu}_{i}$，校准前的集成方差为 $v_{i}$。温度缩放将每个方差乘以一个公共因子 $\\tau^{2}$，该因子通过在高斯假设下最小化平均负对数似然而确定，不引入任何额外的正则化。\n- 对于目标名义双边覆盖率 $c = 1 - \\alpha$，预测区间通过使用标准正态分布的分位数构建。对于没有基准真相的 MD 帧，DFT 触发由高斯尾部概率决定，即绝对误差超过用户指定的容差 $\\varepsilon$ 的概率：如果绝对误差超过 $\\varepsilon$ 的概率大于或等于 $\\alpha$，则触发。\n\n数值稳定性：\n- 为避免简并情况，在进行任何除法或平方根运算之前，务必将任何非正方差替换为一个小的下限值 $v_{\\min}  0$。该下限值应一致地应用于校准和 MD 的方差。\n\n单位与格式：\n- 能量单位为电子伏特。方差单位为平方电子伏特。最终输出为指定的无量纲数或整数，并且您必须将任何浮点输出四舍五入到小数点后恰好六位。\n\n必须实现的数学和计算要求：\n1. 对每个测试用例，通过以下公式计算校准构型的集成均值 $\\bar{\\mu}_{i}$ 和校准前方差 $v_{i}$：\n   - $\\bar{\\mu}_{i} = \\frac{1}{M} \\sum_{m=1}^{M} \\mu_{i,m}$，\n   - $v_{\\text{ale},i} = \\frac{1}{M} \\sum_{m=1}^{M} s^{2}_{i,m}$，\n   - $v_{\\text{epi},i} = \\frac{1}{M} \\sum_{m=1}^{M} \\left(\\mu_{i,m} - \\bar{\\mu}_{i}\\right)^{2}$，\n   - $v_{i} = \\max\\left(v_{\\text{ale},i} + v_{\\text{epi},i}, v_{\\min}\\right)$。\n2. 仅从上述定义出发，通过最小化校准集在高斯假设下的平均负对数似然（相对于 $\\tau$）来确定温度缩放因子 $\\tau  0$。不要使用任何非从似然定义推导出的替代或简化表达式。\n3. 使用校准后的方差 $\\tilde{v}_{i} = \\tau^{2} v_{i}$，在名义覆盖率 $c = 1 - \\alpha$ 下报告校准集上的经验覆盖率，方法是计算落入双边区间 $\\left[\\bar{\\mu}_{i} - z \\sqrt{\\tilde{v}_{i}}, \\bar{\\mu}_{i} + z \\sqrt{\\tilde{v}_{i}}\\right]$ 内的 $y_{i}$ 的比例，其中 $z$ 是对应于 $(1+c)/2$ 的标准正态分位数。\n4. 对每个 MD 帧 $j$，以相同方式计算集成均值 $\\bar{\\mu}_{j}$ 和方差 $v_{j}$，应用校准得到 $\\tilde{v}_{j} = \\tau^{2} v_{j}$，计算尾部概率 $p_{j} = 2 \\left[1 - \\Phi\\left(\\varepsilon / \\sqrt{\\tilde{v}_{j}}\\right)\\right]$（其中 $\\Phi$ 是标准正态分布的累积分布函数），并在 $p_{j} \\ge \\alpha$ 时决定触发 DFT。以整数形式报告每个测试用例的总触发次数。\n\n四舍五入与输出：\n- 对于每个测试用例，输出一个三元组，包含四舍五入到六位小数的 $\\tau$、四舍五入到六位小数的经验覆盖率（以小数形式表示）以及触发次数（一个整数）。将所有测试用例的三元组聚合为单行打印输出，形式为不含空格的列表之列表，例如 $[[\\tau_{1},\\text{cov}_{1},n_{1}],[\\tau_{2},\\text{cov}_{2},n_{2}],\\dots]$，其中每个 $\\tau_{k}$ 和覆盖率都四舍五入到恰好六位小数。\n- 最终输出必须是且仅是包含此格式聚合结果的一行。\n\n测试套件：\n实现您的程序以运行以下三个测试用例。所有能量单位均为电子伏特，所有方差单位均为平方电子伏特，所有角度（若有）单位应为弧度，但此处未使用。\n\n测试用例 1（包含偶然和认知贡献的一般集成）：\n- 集成大小 $M = 3$。\n- 校准集真实能量 $y = [0.10, -0.05, 0.20, -0.10, 0.00]$。\n- 校准集各模型预测的均值和方差：\n  - 模型 1： $\\mu_{:,1} = [0.12, -0.06, 0.18, -0.12, 0.02]$, $s^{2}_{:,1} = [0.0025, 0.0025, 0.0036, 0.0025, 0.0036]$。\n  - 模型 2： $\\mu_{:,2} = [0.11, -0.04, 0.22, -0.08, -0.01]$, $s^{2}_{:,2} = [0.0036, 0.0025, 0.0036, 0.0036, 0.0025]$。\n  - 模型 3： $\\mu_{:,3} = [0.09, -0.05, 0.21, -0.11, -0.02]$, $s^{2}_{:,3} = [0.0025, 0.0025, 0.0049, 0.0025, 0.0036]$。\n- MD 各模型预测的均值和方差：\n  - 模型 1： $\\mu^{\\text{MD}}_{:,1} = [0.05, -0.02, 0.15, -0.08]$, $(s^{2})^{\\text{MD}}_{:,1} = [0.0036, 0.0025, 0.0036, 0.0025]$。\n  - 模型 2： $\\mu^{\\text{MD}}_{:,2} = [0.04, -0.01, 0.17, -0.07]$, $(s^{2})^{\\text{MD}}_{:,2} = [0.0025, 0.0036, 0.0036, 0.0036]$。\n  - 模型 3： $\\mu^{\\text{MD}}_{:,3} = [0.06, -0.03, 0.16, -0.09]$, $(s^{2})^{\\text{MD}}_{:,3} = [0.0036, 0.0025, 0.0049, 0.0025]$。\n- 误差容差 $\\varepsilon = 0.05$。\n- 风险阈值 $\\alpha = 0.10$。\n- 方差下限 $v_{\\min} = 10^{-8}$。\n- 报告三元组 $[\\tau,\\text{coverage},\\text{triggers}]$，其中 $\\tau$ 和 coverage 四舍五入到六位小数。\n\n测试用例 2（构造边界触发条件，其中精确的温度缩放因子为 1）：\n- 集成大小 $M = 2$。\n- 校准集真实能量 $y = [0.50, -0.30, 0.10]$。\n- 选择校准残差 $r = [0.10, -0.20, 0.05]$ 并定义相同的各模型均值 $\\mu_{:,1} = \\mu_{:,2} = y - r = [0.40, -0.10, 0.05]$。选择相同的各模型方差 $s^{2}_{:,1} = s^{2}_{:,2} = [0.01, 0.04, 0.0025]$，使得对所有 i，比率 $r_{i}^{2} / v_{i}$ 都等于 1，这意味着从高斯似然推导出的最优 $\\tau$ 等于 1。\n- MD 构型构造，将一个帧精确置于 DFT 触发边界上：设误差容差为 $\\varepsilon = 0.10$，风险阈值为 $\\alpha = 0.10$，并定义 $z_{\\alpha} = \\Phi^{-1}(1 - \\alpha/2)$。令 $\\sigma_{\\text{th}} = \\varepsilon / z_{\\alpha}$，并构造三个 MD 帧，其两个模型具有相同的均值（任何合理值），且每帧的各模型方差相同，如下所示：\n  - 帧 A：各模型方差等于 $\\sigma_{\\text{th}}^{2}$ (精确边界)。\n  - 帧 B：各模型方差等于 $(0.9 \\sigma_{\\text{th}})^{2}$ (低于边界)。\n  - 帧 C：各模型方差等于 $(1.1 \\sigma_{\\text{th}})^{2}$ (高于边界)。\n  因为每个帧上的模型都相同，集成预测方差就等于这些值，使得在规则 $p \\ge \\alpha$ 下的触发结果为（触发、不触发、触发）。\n- 使用方差下限 $v_{\\min} = 10^{-12}$。\n- 报告三元组 $[\\tau,\\text{coverage},\\text{triggers}]$，其中 $\\tau$ 和 coverage 四舍五入到六位小数。\n\n测试用例 3（一个模型中偶然方差接近于零而认知分布不容忽视的边缘情况）：\n- 集成大小 $M = 3$。\n- 校准集真实能量 $y = [0.00, 0.10, -0.10, 0.05]$。\n- 校准集各模型预测的均值和方差：\n  - 模型 1： $\\mu_{:,1} = [0.02, 0.08, -0.12, 0.04]$, $s^{2}_{:,1} = [0.0, 10^{-8}, 0.0, 10^{-8}]$。\n  - 模型 2： $\\mu_{:,2} = [0.00, 0.12, -0.08, 0.06]$, $s^{2}_{:,2} = [0.0025, 0.0036, 0.0025, 0.0036]$。\n  - 模型 3： $\\mu_{:,3} = [-0.01, 0.09, -0.11, 0.07]$, $s^{2}_{:,3} = [0.0025, 0.0025, 0.0036, 0.0025]$。\n- MD 各模型预测的均值和方差：\n  - 模型 1： $\\mu^{\\text{MD}}_{:,1} = [0.03, -0.02, 0.12, -0.05]$, $(s^{2})^{\\text{MD}}_{:,1} = [0.0, 0.0, 0.0, 0.0]$。\n  - 模型 2： $\\mu^{\\text{MD}}_{:,2} = [-0.04, -0.01, 0.08, -0.06]$, $(s^{2})^{\\text{MD}}_{:,2} = [0.0025, 0.0025, 0.0025, 0.0025]$。\n  - 模型 3： $\\mu^{\\text{MD}}_{:,3} = [0.00, -0.03, 0.10, -0.04]$, $(s^{2})^{\\text{MD}}_{:,3} = [0.0025, 0.0049, 0.0036, 0.0025]$。\n- 误差容差 $\\varepsilon = 0.05$。\n- 风险阈值 $\\alpha = 0.10$。\n- 方差下限 $v_{\\min} = 10^{-8}$。\n- 报告三元组 $[\\tau,\\text{coverage},\\text{triggers}]$，其中 $\\tau$ 和 coverage 四舍五入到六位小数。\n\n整个程序的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由三个三元组组成的逗号分隔列表，并用方括号括起来，不含空格。确切格式为 $[[\\tau_{1},\\text{cov}_{1},n_{1}],[\\tau_{2},\\text{cov}_{2},n_{2}],[\\tau_{3},\\text{cov}_{3},n_{3}]]$，其中每个 $\\tau_{k}$ 和 $\\text{cov}_{k}$ 都四舍五入到六位小数，每个 $n_{k}$ 都是一个整数。",
            "solution": "该问题要求为深度集成原子间势实现一个完整的不确定性校准工作流程，并将其应用于分子动力学 (MD) 模拟的主动学习场景中。该方法基于坚实的概率论和统计学原理。我们将首先从基本原理推导必要的公式，然后概述计算算法。\n\n**1. 集成预测：均值和方差**\n\n深度集成由 $M$ 个独立训练的模型组成。对于给定的原子构型（索引为 $i$），每个模型 $m \\in \\{1, \\dots, M\\}$ 提供对平均能量 $\\mu_{i,m}$ 的预测，以及相关的偶然不确定性方差 $s^{2}_{i,m}$。偶然不确定性是数据固有的（例如，由于训练数据中的热噪声），由模型自身预测。\n\n集成的共识预测平均能量是各个模型均值的算术平均值：\n$$ \\bar{\\mu}_{i} = \\frac{1}{M} \\sum_{m=1}^{M} \\mu_{i,m} $$\n\n集成的总预测方差 $v_i$ 分解为两个部分：平均偶然方差和认知方差。认知不确定性源于模型的知识缺乏，通过集成成员之间的不一致性来捕捉。\n\n平均偶然方差 $v_{\\text{ale},i}$ 是每个模型预测的方差的均值：\n$$ v_{\\text{ale},i} = \\frac{1}{M} \\sum_{m=1}^{M} s^{2}_{i,m} $$\n\n认知方差 $v_{\\text{epi},i}$ 是集成成员预测均值的方差，作为总体方差计算：\n$$ v_{\\text{epi},i} = \\frac{1}{M} \\sum_{m=1}^{M} \\left(\\mu_{i,m} - \\bar{\\mu}_{i}\\right)^{2} $$\n\n校准前的总方差是这两个贡献之和：\n$$ v_i^{\\text{raw}} = v_{\\text{ale},i} + v_{\\text{epi},i} $$\n为了数值稳定性，尤其是在计算对数或平方根倒数时，任何非正方差都会被一个小的正值下限 $v_{\\min}$ 所截断。因此，最终的校准前方差为：\n$$ v_{i} = \\max\\left(v_i^{\\text{raw}}, v_{\\min}\\right) $$\n\n**2. 通过温度缩放进行校准**\n\n来自集成的原始预测方差通常是未校准的，这意味着预测的不确定性不能准确反映真实的误差分布。温度缩放是一种简单有效的后处理校准方法，它通过单个乘法因子 $\\tau^2$ 来校正方差。校准后的方差为 $\\tilde{v}_i = \\tau^2 v_i$。\n\n最优温度 $\\tau  0$ 是通过在高斯假设下最大化校准数据集的对数似然来确定的。设校准集包含 $N$ 个具有已知真实能量 $y_i$ 的构型。我们将每个构型的真实能量建模为从均值为 $\\bar{\\mu}_i$、方差为 $\\tilde{v}_i$ 的正态分布中抽取的样本：\n$$ p(y_i | \\bar{\\mu}_i, v_i, \\tau) = \\mathcal{N}(y_i; \\bar{\\mu}_i, \\tau^2 v_i) = \\frac{1}{\\sqrt{2\\pi \\tau^2 v_i}} \\exp\\left(-\\frac{(y_i - \\bar{\\mu}_i)^2}{2 \\tau^2 v_i}\\right) $$\n单个数据点的对数似然为：\n$$ \\ln p(y_i) = -\\frac{1}{2} \\ln(2\\pi) - \\frac{1}{2} \\ln(\\tau^2 v_i) - \\frac{r_i^2}{2 \\tau^2 v_i} $$\n其中 $r_i = y_i - \\bar{\\mu}_i$ 是残差。假设数据点是独立的，该集合的总负对数似然 (NLL) 为：\n$$ \\text{NLL}(\\tau) = -\\sum_{i=1}^{N} \\ln p(y_i) = \\sum_{i=1}^{N} \\left( \\frac{1}{2} \\ln(2\\pi) + \\ln(\\tau) + \\frac{1}{2} \\ln(v_i) + \\frac{r_i^2}{2 \\tau^2 v_i} \\right) $$\n为了找到最小化此 NLL 的最优 $\\tau$，我们计算其关于 $\\tau$ 的导数并将其设为零。\n$$ \\frac{\\partial(\\text{NLL})}{\\partial \\tau} = \\sum_{i=1}^{N} \\left( \\frac{1}{\\tau} - \\frac{r_i^2}{v_i \\tau^3} \\right) = 0 $$\n$$ \\frac{N}{\\tau} = \\frac{1}{\\tau^3} \\sum_{i=1}^{N} \\frac{r_i^2}{v_i} $$\n解出 $\\tau^2$ 得：\n$$ \\tau^2 = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{r_i^2}{v_i} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{(y_i - \\bar{\\mu}_i)^2}{v_i} $$\n最优温度是该数量的平方根：\n$$ \\tau = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} \\frac{(y_i - \\bar{\\mu}_i)^2}{v_i}} $$\n该结果提供了一种从校准数据中直接找到校准因子的解析方法。\n\n**3. 经验覆盖率与预测区间**\n\n在确定 $\\tau$ 后，我们可以通过计算校准集上的经验覆盖率来评估校准的质量。对于目标名义覆盖概率 $c = 1-\\alpha$， $y_i$ 的双边预测区间构造如下：\n$$ \\left[ \\bar{\\mu}_i - z \\sqrt{\\tilde{v}_i}, \\; \\bar{\\mu}_i + z \\sqrt{\\tilde{v}_i} \\right] $$\n其中 $\\tilde{v}_i = \\tau^2 v_i$ 是校准后的方差， $z = \\Phi^{-1}\\left(\\frac{1+c}{2}\\right) = \\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)$ 是标准正态分布 $\\mathcal{N}(0,1)$ 的分位数，$\\Phi$ 是其累积分布函数 (CDF)。\n经验覆盖率是真实能量 $y_i$ 落在此区间内的校准点的比例：\n$$ \\text{coverage} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{I}\\left( |y_i - \\bar{\\mu}_i| \\le z \\sqrt{\\tilde{v}_i} \\right) $$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。一个校准良好的模型应具有接近名义覆盖率 $c$ 的经验覆盖率。\n\n**4. 基于不确定性的实时 DFT 触发**\n\n在 MD 的主动学习中，校准后的不确定性用于决定何时执行计算成本高昂的量子力学计算（例如 DFT），而不是依赖于更廉价的 GNN 势。如果模型对给定构型的不确定性过高，则触发 DFT 计算。\n\n该决策通过设置能量容差 $\\varepsilon$ 和风险水平 $\\alpha$ 来形式化。如果预测的绝对误差 $|y_j - \\bar{\\mu}_j|$ 超过 $\\varepsilon$ 的概率大于或等于 $\\alpha$，则触发。在校准的高斯模型下，此概率 $p_j$ 为：\n$$ p_j = P(|y_j - \\bar{\\mu}_j|  \\varepsilon) = P\\left(\\frac{|y_j - \\bar{\\mu}_j|}{\\sqrt{\\tilde{v}_j}}  \\frac{\\varepsilon}{\\sqrt{\\tilde{v}_j}}\\right) $$\n由于假定 $(y_j - \\bar{\\mu}_j)/\\sqrt{\\tilde{v}_j}$ 服从标准正态分布，这个尾部概率为：\n$$ p_j = 2 \\left[1 - \\Phi\\left(\\frac{\\varepsilon}{\\sqrt{\\tilde{v}_j}}\\right)\\right] $$\n因此，MD 帧 $j$ 的触发条件是：\n$$ 2 \\left[1 - \\Phi\\left(\\frac{\\varepsilon}{\\sqrt{\\tilde{v}_j}}\\right)\\right] \\ge \\alpha $$\n总触发次数是满足此条件的 MD 帧的数量。\n\n**计算算法摘要**\n\n对于每个测试用例，程序将执行以下序列：\n\n1.  **处理校准数据**:\n    a. 对于 $N$ 个校准点中的每一个，计算集成均值 $\\bar{\\mu}_i$ 和校准前方差 $v_i = \\max(v_{\\text{ale},i} + v_{\\text{epi},i}, v_{\\min})$。\n    b. 使用推导的公式计算最优温度 $\\tau$。\n    c. 计算校准后的方差 $\\tilde{v}_i = \\tau^2 v_i$。\n    d. 确定名义覆盖率 $c = 1 - \\alpha$ 对应的标准正态分位数 $z$。\n    e. 通过检查有多少真实能量 $y_i$ 落在其各自的预测区间内来计算经验覆盖率。\n\n2.  **处理 MD 数据**:\n    a. 对于每个 MD 帧 $j$，使用与校准数据相同的方法计算集成均值 $\\bar{\\mu}_j$ 和校准前方差 $v_j$。\n    b. 应用温度缩放因子得到校准后的方差 $\\tilde{v}_j = \\tau^2 v_j$。\n    c. 根据误差容差 $\\varepsilon$ 计算触发概率 $p_j$。\n    d. 统计满足 $p_j \\ge \\alpha$ 的帧数。\n\n3.  **报告结果**: 对于每个测试用例，将计算出的 $\\tau$、经验覆盖率（均四舍五入到六位小数）和整数触发次数收集到一个三元组中。将这些三元组聚合为单个列表之列表作为最终输出。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases and print the results.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1\n        {\n            \"M\": 3,\n            \"calib_y\": np.array([0.10, -0.05, 0.20, -0.10, 0.00]),\n            \"calib_mu\": np.array([\n                [0.12, -0.06, 0.18, -0.12, 0.02],\n                [0.11, -0.04, 0.22, -0.08, -0.01],\n                [0.09, -0.05, 0.21, -0.11, -0.02]\n            ]).T,\n            \"calib_s2\": np.array([\n                [0.0025, 0.0025, 0.0036, 0.0025, 0.0036],\n                [0.0036, 0.0025, 0.0036, 0.0036, 0.0025],\n                [0.0025, 0.0025, 0.0049, 0.0025, 0.0036]\n            ]).T,\n            \"md_mu\": np.array([\n                [0.05, -0.02, 0.15, -0.08],\n                [0.04, -0.01, 0.17, -0.07],\n                [0.06, -0.03, 0.16, -0.09]\n            ]).T,\n            \"md_s2\": np.array([\n                [0.0036, 0.0025, 0.0036, 0.0025],\n                [0.0025, 0.0036, 0.0036, 0.0036],\n                [0.0036, 0.0025, 0.0049, 0.0025]\n            ]).T,\n            \"epsilon\": 0.05,\n            \"alpha\": 0.10,\n            \"v_min\": 1e-8,\n        },\n        # Test Case 2\n        {\n            \"M\": 2,\n            \"calib_y\": np.array([0.50, -0.30, 0.10]),\n            \"calib_mu\": np.array([\n                [0.40, -0.10, 0.05],\n                [0.40, -0.10, 0.05]\n            ]).T,\n            \"calib_s2\": np.array([\n                [0.01, 0.04, 0.0025],\n                [0.01, 0.04, 0.0025]\n            ]).T,\n            \"epsilon\": 0.10,\n            \"alpha\": 0.10,\n            \"v_min\": 1e-12,\n            # MD part needs to be constructed\n            \"md_construction\": True,\n        },\n        # Test Case 3\n        {\n            \"M\": 3,\n            \"calib_y\": np.array([0.00, 0.10, -0.10, 0.05]),\n            \"calib_mu\": np.array([\n                [0.02, 0.08, -0.12, 0.04],\n                [0.00, 0.12, -0.08, 0.06],\n                [-0.01, 0.09, -0.11, 0.07]\n            ]).T,\n            \"calib_s2\": np.array([\n                [0.0, 1e-8, 0.0, 1e-8],\n                [0.0025, 0.0036, 0.0025, 0.0036],\n                [0.0025, 0.0025, 0.0036, 0.0025]\n            ]).T,\n            \"md_mu\": np.array([\n                [0.03, -0.02, 0.12, -0.05],\n                [-0.04, -0.01, 0.08, -0.06],\n                [0.00, -0.03, 0.10, -0.04]\n            ]).T,\n            \"md_s2\": np.array([\n                [0.0, 0.0, 0.0, 0.0],\n                [0.0025, 0.0025, 0.0025, 0.0025],\n                [0.0025, 0.0049, 0.0036, 0.0025]\n            ]).T,\n            \"epsilon\": 0.05,\n            \"alpha\": 0.10,\n            \"v_min\": 1e-8,\n        }\n    ]\n\n    # Construct MD data for Test Case 2\n    tc2 = test_cases[1]\n    alpha_tc2 = tc2[\"alpha\"]\n    epsilon_tc2 = tc2[\"epsilon\"]\n    z_alpha_tc2 = norm.ppf(1 - alpha_tc2 / 2)\n    sigma_th_sq = (epsilon_tc2 / z_alpha_tc2)**2\n    # Define some reasonable identical means\n    tc2[\"md_mu\"] = np.array([[0.1, 0.1], [0.2, 0.2], [0.3, 0.3]])\n    tc2[\"md_s2\"] = np.array([\n        [sigma_th_sq, sigma_th_sq],             # Frame A\n        [(0.9**2) * sigma_th_sq, (0.9**2) * sigma_th_sq], # Frame B\n        [(1.1**2) * sigma_th_sq, (1.1**2) * sigma_th_sq]  # Frame C\n    ])\n\n    results = []\n    for case in test_cases:\n        result = process_case(case)\n        results.append(result)\n\n    # Print the final result in the exact required format\n    print(str(results).replace(\" \", \"\"))\n\ndef get_ensemble_predictions(mu_models, s2_models, v_min):\n    \"\"\"\n    Computes ensemble mean and variance.\n    \n    Args:\n        mu_models (np.ndarray): Per-model mean predictions, shape (N_points, M).\n        s2_models (np.ndarray): Per-model aleatoric variances, shape (N_points, M).\n        v_min (float): Minimum variance floor.\n        \n    Returns:\n        tuple: (ensemble_mean, ensemble_variance)\n    \"\"\"\n    mu_bar = np.mean(mu_models, axis=1)\n    v_ale = np.mean(s2_models, axis=1)\n    # ddof=0 for population variance\n    v_epi = np.var(mu_models, axis=1, ddof=0)\n    v_raw = v_ale + v_epi\n    v = np.maximum(v_raw, v_min)\n    return mu_bar, v\n\ndef process_case(case_data):\n    \"\"\"\n    Processes a single test case.\n    \"\"\"\n    # Unpack data\n    y_calib = case_data[\"calib_y\"]\n    mu_calib_models = case_data[\"calib_mu\"]\n    s2_calib_models = case_data[\"calib_s2\"]\n    mu_md_models = case_data[\"md_mu\"]\n    s2_md_models = case_data[\"md_s2\"]\n    alpha = case_data[\"alpha\"]\n    epsilon = case_data[\"epsilon\"]\n    v_min = case_data[\"v_min\"]\n    N_calib = len(y_calib)\n\n    # 1. Calibration Phase\n    mu_bar_calib, v_calib = get_ensemble_predictions(mu_calib_models, s2_calib_models, v_min)\n    \n    # 2. Determine temperature scaling factor tau\n    residuals_sq = (y_calib - mu_bar_calib)**2\n    tau_sq = np.mean(residuals_sq / v_calib)\n    tau = np.sqrt(tau_sq)\n    \n    # 3. Compute empirical coverage on calibration set\n    v_calib_calibrated = tau_sq * v_calib\n    nominal_coverage_c = 1 - alpha\n    z = norm.ppf((1 + nominal_coverage_c) / 2)\n    \n    interval_half_width = z * np.sqrt(v_calib_calibrated)\n    is_covered = np.abs(y_calib - mu_bar_calib) = interval_half_width\n    empirical_coverage = np.sum(is_covered) / N_calib\n    \n    # 4. MD Phase - Triggering\n    mu_bar_md, v_md = get_ensemble_predictions(mu_md_models, s2_md_models, v_min)\n    v_md_calibrated = tau_sq * v_md\n    \n    # To prevent division by zero for any pathological variance\n    std_dev_md_calibrated = np.sqrt(np.maximum(v_md_calibrated, v_min))\n    \n    # Probability P(|error| > epsilon)\n    # This is 2 * (1 - CDF(epsilon / std_dev))\n    arg = epsilon / std_dev_md_calibrated\n    p_values = 2 * (1 - norm.cdf(arg))\n    \n    triggers = np.sum(p_values >= alpha)\n\n    # Round and format output for the case\n    tau_rounded = round(tau, 6)\n    coverage_rounded = round(empirical_coverage, 6)\n    \n    return [tau_rounded, coverage_rounded, int(triggers)]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}