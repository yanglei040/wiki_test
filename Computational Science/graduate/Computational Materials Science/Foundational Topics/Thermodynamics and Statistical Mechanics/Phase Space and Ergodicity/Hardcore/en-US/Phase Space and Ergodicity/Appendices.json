{
    "hands_on_practices": [
        {
            "introduction": "Simulations of Hamiltonian systems, which govern the microscopic world, must respect the fundamental geometric structure of phase space. A cornerstone of this structure is described by Liouville's theorem, which mandates the conservation of phase-space volume during time evolution. This exercise  makes this abstract principle tangible by having you numerically verify this property for the velocity-Verlet integrator, a widely used symplectic algorithm. By calculating the Jacobian matrix of the discrete time-step map and evaluating its determinant, you will directly test the integrator's ability to preserve phase-space volume, a crucial factor for ensuring the long-term stability and accuracy of molecular dynamics simulations.",
            "id": "3475273",
            "problem": "Consider a one-dimensional Lennard–Jones dimer composed of two identical particles of mass $m$ interacting via the Lennard–Jones potential $U(r) = 4\\varepsilon\\left[\\left(\\dfrac{\\sigma}{r}\\right)^{12} - \\left(\\dfrac{\\sigma}{r}\\right)^{6}\\right]$, where $r = |x_1 - x_2|$, $x_1$ and $x_2$ are the particle positions, and the particles have velocities $v_1$ and $v_2$. Let the system be described in reduced units with $m = 1$, $\\varepsilon = 1$, and $\\sigma = 1$. The Hamiltonian is $H = \\dfrac{p_1^2}{2m} + \\dfrac{p_2^2}{2m} + U(|x_1 - x_2|)$ with canonical variables $(x_1,x_2,p_1,p_2)$ and $p_i = m v_i$.\n\nA time-discrete map $T_{\\Delta t}$ is defined by one step of the velocity–Verlet integrator applied to the state vector $y = (x_1,x_2,v_1,v_2)$:\n- First half-kick: $v_i^{n+1/2} = v_i^n + \\dfrac{\\Delta t}{2} a_i(x_1^n,x_2^n)$.\n- Drift: $x_i^{n+1} = x_i^n + \\Delta t \\, v_i^{n+1/2}$.\n- Second half-kick: $v_i^{n+1} = v_i^{n+1/2} + \\dfrac{\\Delta t}{2} a_i(x_1^{n+1},x_2^{n+1})$.\n\nHere $a_i = F_i/m$ and $F_i$ is the Lennard–Jones force on particle $i$, computed from $U(r)$ by $F_1 = -\\dfrac{dU}{dr} \\dfrac{x_1 - x_2}{r}$ and $F_2 = -F_1$.\n\nYour task is to numerically estimate the Jacobian matrix $J(\\Delta t) = \\dfrac{\\partial T_{\\Delta t}}{\\partial y}$ at a fixed reference state $y$ by central finite differences and to evaluate the determinant $\\det J(\\Delta t)$. Because the velocity–Verlet map is symplectic, the true determinant is exactly $1$. However, your numerical estimate will deviate from $1$ due to truncation in the finite-difference approximation. Use a central-difference perturbation amplitude $\\varepsilon_{\\text{fd}} = c \\, \\Delta t$ with $c = 10^{-2}$ applied independently to each component of $y$ to approximate the Jacobian columns:\n$$\nJ_{\\cdot,i}(\\Delta t) \\approx \\frac{T_{\\Delta t}(y + \\varepsilon_{\\text{fd}} e_i) - T_{\\Delta t}(y - \\varepsilon_{\\text{fd}} e_i)}{2 \\, \\varepsilon_{\\text{fd}}}, \\quad i \\in \\{1,2,3,4\\},\n$$\nwhere $e_i$ is the $i$-th unit vector in $\\mathbb{R}^4$. Define the absolute deviation $\\delta(\\Delta t) = \\left|\\det J(\\Delta t) - 1\\right|$.\n\nImplement a complete, runnable program that:\n1. Uses the velocity–Verlet map $T_{\\Delta t}$ in one dimension with the Lennard–Jones forces for two particles in reduced units with $m = 1$, $\\varepsilon = 1$, and $\\sigma = 1$.\n2. Computes the finite-difference Jacobian at the fixed reference state $y = (x_1, x_2, v_1, v_2) = (0, 1.5, 0.1, -0.05)$ for each specified time step $\\Delta t$ using the central-difference stencil with $\\varepsilon_{\\text{fd}} = c \\, \\Delta t$ and $c = 10^{-2}$.\n3. Returns the list of absolute deviations $\\delta(\\Delta t)$ for the provided test suite.\n\nTest Suite:\n- Use the time steps $\\Delta t \\in \\{0.001, 0.002, 0.005, 0.01, 0.02\\}$.\n- Use the finite-difference scaling factor $c = 10^{-2}$ so that $\\varepsilon_{\\text{fd}} = c \\, \\Delta t$ for each $\\Delta t$.\n- Use the fixed initial state $y = (0, 1.5, 0.1, -0.05)$.\n\nFinal Output Specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, i.e., of the form $[r_1,r_2,r_3,r_4,r_5]$, where $r_k$ is the floating-point value of $\\delta(\\Delta t_k)$ for the $k$-th time step in the test suite.\n- All outputs must be unitless real numbers (floats).",
            "solution": "The problem is valid. It is a well-posed, scientifically sound problem in computational physics that probes the properties of numerical integrators for Hamiltonian systems.\n\nThe core task is to numerically assess the symplecticity of the velocity-Verlet integration algorithm. A key property of a symplectic map $T$, which describes the evolution of a Hamiltonian system in phase space, is that it preserves phase space volume. This is mathematically expressed by the condition that the determinant of the map's Jacobian matrix $J$ is exactly one: $\\det(J) = 1$. The velocity-Verlet algorithm is a well-known geometric integrator, designed to be symplectic. However, we are asked to compute its Jacobian not analytically, but numerically using a finite-difference approximation. This introduces a truncation error, and our calculated determinant will deviate from $1$. The problem asks for this deviation, $\\delta(\\Delta t) = |\\det J(\\Delta t) - 1|$, for a specific system and a set of time steps $\\Delta t$.\n\nFirst, we define the physical system. It consists of two identical particles of mass $m=1$ in one dimension, interacting via the Lennard-Jones (LJ) potential. In the specified reduced units where $\\varepsilon=1$ and $\\sigma=1$, the potential is:\n$$\nU(r) = 4\\left(r^{-12} - r^{-6}\\right)\n$$\nwhere $r = |x_1 - x_2|$ is the distance between the particles at positions $x_1$ and $x_2$. The Hamiltonian of the system is $H = \\frac{p_1^2}{2m} + \\frac{p_2^2}{2m} + U(|x_1 - x_2|)$. The equations of motion are given by Newton's second law, $m a_i = F_i$, where $a_i$ is the acceleration of particle $i$ and $F_i$ is the force acting on it. Since $m=1$, we have $a_i = F_i$. The force is the negative gradient of the potential. For particle $1$, the force is given as $F_1 = -\\frac{dU}{dr} \\frac{x_1 - x_2}{r}$. By Newton's third law, the force on particle $2$ is $F_2 = -F_1$.\n\nThe derivative of the LJ potential with respect to $r$ is:\n$$\n\\frac{dU}{dr} = 4\\left(-12r^{-13} + 6r^{-7}\\right) = \\frac{24}{r}\\left(-2r^{-12} + r^{-6}\\right)\n$$\nThis expression allows us to compute the forces, and thus accelerations, for any given pair of particle positions $(x_1, x_2)$.\n\nNext, we formalize the time evolution using the velocity-Verlet integrator. The state of the system is described by a $4$-dimensional vector $y = (x_1, x_2, v_1, v_2)$. A single integration step of duration $\\Delta t$ maps the state $y^n$ at time $t_n$ to the state $y^{n+1}$ at time $t_{n+1} = t_n + \\Delta t$. This map is denoted $T_{\\Delta t}$, so $y^{n+1} = T_{\\Delta t}(y^n)$. The algorithm proceeds in three steps:\n1.  Compute velocities at the mid-step: $v_i^{n+1/2} = v_i^n + \\frac{\\Delta t}{2} a_i(x_1^n, x_2^n)$ for $i \\in \\{1,2\\}$.\n2.  Update positions using these mid-step velocities: $x_i^{n+1} = x_i^n + \\Delta t \\, v_i^{n+1/2}$ for $i \\in \\{1,2\\}$.\n3.  Compute accelerations at the new positions, $a_i(x_1^{n+1}, x_2^{n+1})$, and complete the velocity update: $v_i^{n+1} = v_i^{n+1/2} + \\frac{\\Delta t}{2} a_i(x_1^{n+1}, x_2^{n+1})$ for $i \\in \\{1,2\\}$.\n\nThe central part of the problem is to compute the Jacobian matrix $J(\\Delta t)$ of this map, evaluated at the specific reference state $y = (0, 1.5, 0.1, -0.05)$. The Jacobian is a $4 \\times 4$ matrix whose elements are $J_{ij} = \\frac{\\partial (T_{\\Delta t}(y))_i}{\\partial y_j}$. We will approximate each column of the Jacobian using the central finite-difference formula. For the $j$-th column ($j \\in \\{1,2,3,4\\}$):\n$$\nJ_{\\cdot,j}(\\Delta t) \\approx \\frac{T_{\\Delta t}(y + \\varepsilon_{\\text{fd}} e_j) - T_{\\Delta t}(y - \\varepsilon_{\\text{fd}} e_j)}{2 \\varepsilon_{\\text{fd}}}\n$$\nHere, $e_j$ is the $j$-th standard basis vector in $\\mathbb{R}^4$ (e.g., $e_1 = (1,0,0,0)$), and $\\varepsilon_{\\text{fd}}$ is a small perturbation amplitude. The problem specifies that this amplitude should be scaled with the time step: $\\varepsilon_{\\text{fd}} = c \\, \\Delta t$, where $c = 10^{-2}$.\n\nThe overall algorithm will be:\n1.  For each time step $\\Delta t$ in the given test suite $\\{0.001, 0.002, 0.005, 0.01, 0.02\\}$.\n2.  Set the finite-difference perturbation $\\varepsilon_{\\text{fd}} = c \\, \\Delta t$.\n3.  Initialize an empty $4 \\times 4$ matrix $J$.\n4.  For each column index $j$ from $1$ to $4$:\n    a. Define the perturbed initial states $y^+ = y + \\varepsilon_{\\text{fd}} e_j$ and $y^- = y - \\varepsilon_{\\text{fd}} e_j$.\n    b. Evolve both $y^+$ and $y^-$ for one time step using the velocity-Verlet map to get $y'^+ = T_{\\Delta t}(y^+)$ and $y'^- = T_{\\Delta t}(y^-)$.\n    c. Compute the $j$-th column of the Jacobian as $(y'^+ - y'^-) / (2 \\varepsilon_{\\text{fd}})$.\n5.  After constructing the full matrix $J$, compute its determinant, $\\det J(\\Delta t)$.\n6.  Calculate the absolute deviation $\\delta(\\Delta t) = |\\det J(\\Delta t) - 1|$.\n7.  Collect the values of $\\delta(\\Delta t)$ for all specified $\\Delta t$.\n\nThis procedure will be implemented in a Python program using the `numpy` library for efficient vector and matrix operations, including the determinant calculation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the deviation of the numerically computed Jacobian determinant of the\n    velocity-Verlet map from 1 for a 1D Lennard-Jones dimer.\n    \"\"\"\n\n    # Reduced unit constants from the problem statement\n    M = 1.0\n    EPSILON = 1.0\n    SIGMA = 1.0\n    \n    # Finite-difference scaling factor\n    C_FD = 1e-2\n\n    # Fixed reference state y = (x1, x2, v1, v2)\n    y_ref = np.array([0.0, 1.5, 0.1, -0.05])\n    \n    # Test suite of time steps\n    test_cases = [0.001, 0.002, 0.005, 0.01, 0.02]\n\n    def calculate_accelerations(positions):\n        \"\"\"\n        Computes the accelerations of the two particles based on their positions.\n        \n        Args:\n            positions (np.ndarray): A 2-element array [x1, x2].\n            \n        Returns:\n            np.ndarray: A 2-element array [a1, a2].\n        \"\"\"\n        x1, x2 = positions[0], positions[1]\n        r_vec = x1 - x2\n        r = abs(r_vec)\n\n        # Avoid division by zero, though unlikely with the LJ potential\n        if r == 0.0:\n            return np.array([0.0, 0.0])\n\n        r_inv = SIGMA / r\n        r_inv6 = r_inv**6\n        r_inv12 = r_inv6**2\n\n        # Force calculation based on F = -dU/dr * (x1-x2)/r\n        # dU/dr = (24 * EPSILON / r) * (-2 * (SIGMA/r)**12 + (SIGMA/r)**6)\n        dU_dr = (24.0 * EPSILON / r) * (-2.0 * r_inv12 + r_inv6)\n        \n        # In 1D, (x1-x2)/r is just sign(x1-x2)\n        force_on_1 = -dU_dr * np.sign(r_vec) if r_vec != 0 else 0\n\n        # Acceleration a = F/m\n        accel_1 = force_on_1 / M\n        accel_2 = -accel_1  # By Newton's third law\n\n        return np.array([accel_1, accel_2])\n\n    def velocity_verlet_step(y, dt):\n        \"\"\"\n        Performs one step of the velocity-Verlet integration.\n        \n        Args:\n            y (np.ndarray): The 4-element state vector [x1, x2, v1, v2].\n            dt (float): The time step.\n            \n        Returns:\n            np.ndarray: The new state vector after one time step.\n        \"\"\"\n        pos_n = y[0:2]\n        vel_n = y[2:4]\n\n        # First half-kick\n        accel_n = calculate_accelerations(pos_n)\n        vel_half = vel_n + 0.5 * dt * accel_n\n\n        # Drift\n        pos_new = pos_n + dt * vel_half\n\n        # Second half-kick\n        accel_new = calculate_accelerations(pos_new)\n        vel_new = vel_half + 0.5 * dt * accel_new\n\n        return np.concatenate((pos_new, vel_new))\n\n    results = []\n    for dt in test_cases:\n        eps_fd = C_FD * dt\n        jacobian = np.zeros((4, 4))\n        \n        for i in range(4):\n            # Create perturbation vectors\n            perturbation = np.zeros(4)\n            perturbation[i] = eps_fd\n\n            y_plus = y_ref + perturbation\n            y_minus = y_ref - perturbation\n\n            # Evolve perturbed states\n            y_next_plus = velocity_verlet_step(y_plus, dt)\n            y_next_minus = velocity_verlet_step(y_minus, dt)\n\n            # Compute column of the Jacobian using central differences\n            jacobian_col = (y_next_plus - y_next_minus) / (2.0 * eps_fd)\n            jacobian[:, i] = jacobian_col\n\n        # Calculate determinant and its deviation from 1\n        det_J = np.linalg.det(jacobian)\n        deviation = abs(det_J - 1.0)\n        results.append(deviation)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While symplectic integrators are designed to preserve the geometric structure of phase space, their discrete nature introduces subtle deviations from the true dynamics over long timescales. These methods exactly conserve a \"shadow\" Hamiltonian, which may possess different conservation laws than the original system, potentially breaking ergodicity. This exercise  uses the classic Fermi-Pasta-Ulam (FPU) lattice model to explore this phenomenon, showing how numerical discretization can create spurious invariants that confine the trajectory. By measuring the variance of energy in specific modes, $\\mathrm{Var}(I)$, you will quantify the extent of this ergodicity breaking and understand its connection to the integrator's accuracy and step size.",
            "id": "3475280",
            "problem": "You are asked to design, implement, and analyze a Hamiltonian splitting method for a one-dimensional lattice model of phonon dynamics in nondimensional units. The core objective is to examine whether time discretization errors from Trotter factorization give rise to additional effective invariants and to quantify the emergence of such spurious constants via a variance-based measure of an observable in phase space. The problem must be solved by writing a complete, runnable program that carries out the numerical simulations and produces the requested numerical outputs in the specified format.\n\nConsider a periodic chain of $N$ identical particles of unit mass coupled by nearest-neighbor nonlinear springs described by the Fermi-Pasta-Ulam (FPU) potential. The nondimensional Hamiltonian is\n$$\nH(\\mathbf{q},\\mathbf{p}) \\;=\\; \\sum_{i=0}^{N-1} \\frac{p_i^2}{2 m} \\;+\\; \\sum_{i=0}^{N-1} \\left[ \\frac{K}{2}\\left(q_{i+1}-q_i\\right)^2 \\;+\\; \\frac{\\alpha}{4}\\left(q_{i+1}-q_i\\right)^4 \\right],\n$$\nwith periodic boundary conditions $q_N \\equiv q_0$, where $\\mathbf{q} = (q_0,\\dots,q_{N-1})$ are positions and $\\mathbf{p} = (p_0,\\dots,p_{N-1})$ are momenta, $m$ is the mass, $K$ is the linear spring constant, and $\\alpha$ is the nonlinear coefficient. All quantities must be treated in nondimensional units.\n\nThe phase-space evolution obeys Hamilton's equations,\n$$\n\\dot{q}_i \\,=\\, \\frac{\\partial H}{\\partial p_i} \\,=\\, \\frac{p_i}{m}, \\qquad\n\\dot{p}_i \\,=\\, -\\frac{\\partial H}{\\partial q_i} \\,=\\, f_i(\\mathbf{q}),\n$$\nwhere the force $\\mathbf{f}(\\mathbf{q})$ is determined by the gradient of the potential energy. You must use operator splitting to construct a time integrator based on the decomposition $H = T(\\mathbf{p}) + V(\\mathbf{q})$ with\n$$\nT(\\mathbf{p}) \\,=\\, \\sum_{i=0}^{N-1} \\frac{p_i^2}{2 m}, \\qquad\nV(\\mathbf{q}) \\,=\\, \\sum_{i=0}^{N-1} \\left[ \\frac{K}{2}\\left(q_{i+1}-q_i\\right)^2 \\;+\\; \\frac{\\alpha}{4}\\left(q_{i+1}-q_i\\right)^4 \\right].\n$$\nImplement the following two symplectic splitting schemes:\n- Lie–Trotter (first order) splitting over a single step of size $\\Delta t$: apply a drift map for $T$ followed by a kick map for $V$,\n$$\n\\text{drift: } \\mathbf{q} \\leftarrow \\mathbf{q} + \\frac{\\Delta t}{m}\\,\\mathbf{p}, \\qquad\n\\text{kick: } \\mathbf{p} \\leftarrow \\mathbf{p} + \\Delta t\\,\\mathbf{f}(\\mathbf{q}).\n$$\n- Strang (second order) splitting over a single step of size $\\Delta t$: apply a half-kick, full drift, and half-kick,\n$$\n\\mathbf{p} \\leftarrow \\mathbf{p} + \\frac{\\Delta t}{2}\\,\\mathbf{f}(\\mathbf{q}), \\quad\n\\mathbf{q} \\leftarrow \\mathbf{q} + \\frac{\\Delta t}{m}\\,\\mathbf{p}, \\quad\n\\mathbf{p} \\leftarrow \\mathbf{p} + \\frac{\\Delta t}{2}\\,\\mathbf{f}(\\mathbf{q}).\n$$\n\nDefine the linearized normal mode energies as a diagnostic observable. Let $\\mathcal{F}$ be the unitary discrete Fourier transform of length $N$ (using normalization such that Parseval's identity holds), and write $\\mathbf{Q} = \\mathcal{F}\\mathbf{q}$ and $\\mathbf{P} = \\mathcal{F}\\mathbf{p}$. For the linear chain with $\\alpha = 0$, the discrete dispersion factor is\n$$\n\\lambda_k \\,=\\, 4 \\sin^2\\!\\left( \\frac{\\pi k}{N} \\right), \\quad k = 0,1,\\dots,N-1,\n$$\nand the linear normal mode energy at wavenumber $k$ is\n$$\nE_k^{\\text{lin}}(\\mathbf{q},\\mathbf{p}) \\,=\\, \\frac{1}{2m}\\,\\lvert P_k \\rvert^2 \\;+\\; \\frac{K}{2}\\,\\lambda_k\\,\\lvert Q_k \\rvert^2.\n$$\nUse this linear normal mode energy as a phase-space observable even when $\\alpha \\neq 0$ to detect spurious invariants induced by discretization. Specifically, define the low-frequency band energy\n$$\nI(t) \\,=\\, \\sum_{k \\in \\mathcal{S}} E_k^{\\text{lin}}(\\mathbf{q}(t),\\mathbf{p}(t)),\n$$\nwhere $\\mathcal{S} = \\{1,2,\\dots,k_c\\} \\cup \\{N-k_c,\\dots,N-1\\}$ for a chosen cutoff $k_c$. Compute the time variance $\\mathrm{Var}(I)$ over the simulated trajectory as\n$$\n\\mathrm{Var}(I) \\,=\\, \\frac{1}{M}\\sum_{j=1}^{M} \\left( I(t_j) - \\overline{I} \\right)^2, \\qquad\n\\overline{I} \\,=\\, \\frac{1}{M}\\sum_{j=1}^{M} I(t_j),\n$$\nwhere $M$ is the number of recorded time samples. In nondimensional units, report $\\mathrm{Var}(I)$ as a floating-point number.\n\nInitialization must excite a single low-frequency mode to probe energy exchange: set\n$$\nq_i(0) \\,=\\, A \\cos\\!\\left( \\frac{2\\pi k_0 i}{N} \\right), \\qquad p_i(0) \\,=\\, 0,\n$$\nwith amplitude $A$ and mode index $k_0 = 1$.\n\nExplain the link between small $\\mathrm{Var}(I)$ and reduced ergodicity: in the truly nonlinear chain, energy should exchange among modes, but if the integrator's Trotter error induces effective invariants, the low-frequency band energy $I(t)$ changes less than expected, making $\\mathrm{Var}(I)$ small. Conversely, larger $\\mathrm{Var}(I)$ indicates better exploration of phase space and less constraint from spurious invariants.\n\nYou must implement both splitting methods, simulate the dynamics for the specified test suite, compute $\\mathrm{Var}(I)$ for each case, and output the results in a single line as a comma-separated list inside square brackets.\n\nAll quantities are nondimensional; therefore, no physical units need to be reported. Angles are not involved beyond trigonometric arguments on the unit circle and do not require an explicit unit. Express all numerical answers as floating-point numbers.\n\nTest Suite:\n- Case $1$ (edge case: integrable baseline): $N = 16$, $m = 1$, $K = 1$, $\\alpha = 0$, $\\Delta t = 0.04$, number of steps $M = 4000$, method = Strang, cutoff $k_c = 2$, amplitude $A = 0.4$.\n- Case $2$ (happy path nonlinear, small step): $N = 16$, $m = 1$, $K = 1$, $\\alpha = 0.5$, $\\Delta t = 0.01$, $M = 8000$, method = Strang, $k_c = 2$, $A = 0.4$.\n- Case $3$ (nonlinear, larger step): $N = 16$, $m = 1$, $K = 1$, $\\alpha = 0.5$, $\\Delta t = 0.05$, $M = 8000$, method = Strang, $k_c = 2$, $A = 0.4$.\n- Case $4$ (nonlinear, larger step, lower order splitting): $N = 16$, $m = 1$, $K = 1$, $\\alpha = 0.5$, $\\Delta t = 0.05$, $M = 8000$, method = Lie–Trotter, $k_c = 2$, $A = 0.4$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3,r_4]$), where $r_i$ is the computed $\\mathrm{Var}(I)$ for case $i$ in nondimensional units, represented as a floating-point number.",
            "solution": "The problem statement has been rigorously validated and is determined to be valid. It presents a well-posed, scientifically grounded problem from computational statistical mechanics, specifically concerning the simulation of the Fermi-Pasta-Ulam (FPU) lattice model. All parameters, initial conditions, and analysis methods are clearly and consistently defined.\n\nThe core of the problem is to investigate how numerical integration schemes affect the long-time behavior of a nonlinear Hamiltonian system. The FPU model is a canonical example where energy, initially placed in a single low-frequency mode, can either remain localized or spread throughout the available modes, a process related to ergodicity. The numerical method itself, through its discretization error, can introduce spurious (non-physical) conserved quantities that artificially restrict this energy flow. We will quantify this effect by measuring the time variance of the energy contained within a low-frequency band of linear normal modes.\n\nFirst, we define the system's dynamics. The Hamiltonian is given by\n$$\nH(\\mathbf{q},\\mathbf{p}) \\;=\\; T(\\mathbf{p}) + V(\\mathbf{q})\n$$\nwhere $T(\\mathbf{p})$ is the kinetic energy and $V(\\mathbf{q})$ is the potential energy:\n$$\nT(\\mathbf{p}) \\,=\\, \\sum_{i=0}^{N-1} \\frac{p_i^2}{2 m}, \\qquad\nV(\\mathbf{q}) \\,=\\, \\sum_{i=0}^{N-1} \\left[ \\frac{K}{2}\\left(q_{i+1}-q_i\\right)^2 \\;+\\; \\frac{\\alpha}{4}\\left(q_{i+1}-q_i\\right)^4 \\right]\n$$\nThe equations of motion are Hamilton's equations:\n$$\n\\dot{q}_i \\,=\\, \\frac{\\partial H}{\\partial p_i} \\,=\\, \\frac{p_i}{m}, \\qquad\n\\dot{p}_i \\,=\\, -\\frac{\\partial H}{\\partial q_i} \\,=\\, f_i(\\mathbf{q})\n$$\nThe force $f_i$ on particle $i$ is derived from the potential energy. A particle $i$ is influenced by its neighbors $i-1$ and $i+1$. The force is\n$$\nf_i(\\mathbf{q}) = -\\frac{\\partial V}{\\partial q_i} = - \\left( \\frac{\\partial V_{i-1}}{\\partial q_i} + \\frac{\\partial V_i}{\\partial q_i} \\right)\n$$\nwhere $V_j$ is the potential term for the spring between particles $j$ and $j+1$. Let $\\Delta q_j = q_{j+1} - q_j$. The potential for one spring is $U(x) = \\frac{K}{2}x^2 + \\frac{\\alpha}{4}x^4$, and its derivative is $U'(x) = Kx + \\alpha x^3$. The force on particle $i$ can be expressed as:\n$$\nf_i(\\mathbf{q}) = U'(\\Delta q_i) - U'(\\Delta q_{i-1}) = \\left[ K(q_{i+1}-q_i) + \\alpha(q_{i+1}-q_i)^3 \\right] - \\left[ K(q_i-q_{i-1}) + \\alpha(q_i-q_{i-1})^3 \\right]\n$$\nThese equations are solved numerically using operator splitting methods. The time evolution operator $e^{\\Delta t L_H}$ associated with the Liouvillian $L_H = \\{\\cdot, H\\}$ is approximated by splitting $L_H$ into $L_T$ and $L_V$. The exact flows for $T$ and $V$ are known as a drift and a kick, respectively.\nThe Lie–Trotter method is a first-order symmetric splitting:\n$$\n\\mathbf{q}(t+\\Delta t) = \\mathbf{q}(t) + \\frac{\\Delta t}{m}\\mathbf{p}(t) \\quad (\\text{drift}) \\\\\n\\mathbf{p}(t+\\Delta t) = \\mathbf{p}(t) + \\Delta t\\,\\mathbf{f}(\\mathbf{q}(t+\\Delta t)) \\quad (\\text{kick})\n$$\nThe Strang splitting method is a second-order symmetric composition:\n$$\n\\mathbf{p}(t+\\Delta t/2) = \\mathbf{p}(t) + \\frac{\\Delta t}{2}\\,\\mathbf{f}(\\mathbf{q}(t)) \\quad (\\text{half-kick}) \\\\\n\\mathbf{q}(t+\\Delta t) = \\mathbf{q}(t) + \\frac{\\Delta t}{m}\\,\\mathbf{p}(t+\\Delta t/2) \\quad (\\text{full drift}) \\\\\n\\mathbf{p}(t+\\Delta t) = \\mathbf{p}(t+\\Delta t/2) + \\frac{\\Delta t}{2}\\,\\mathbf{f}(\\mathbf{q}(t+\\Delta t)) \\quad (\\text{half-kick})\n$$\nThese integrators are symplectic, meaning they exactly preserve a \"shadow\" Hamiltonian close to the original one. The deviation of the shadow Hamiltonian from the true Hamiltonian depends on the time step $\\Delta t$ and the order of the method. This deviation can introduce spurious invariants of motion.\n\nTo diagnose the system's ergodicity, we use the normal modes of the corresponding linear system ($\\alpha=0$). The mode-space coordinates are obtained via a unitary discrete Fourier transform, $\\mathbf{Q} = \\mathcal{F}\\mathbf{q}$ and $\\mathbf{P} = \\mathcal{F}\\mathbf{p}$. The unitary normalization ensures that Parseval's identity holds, i.e., $\\sum_i |q_i|^2 = \\sum_k |Q_k|^2$. The linear normal mode energy for mode $k$ is\n$$\nE_k^{\\text{lin}} \\,=\\, \\frac{1}{2m}\\,\\lvert P_k \\rvert^2 \\;+\\; \\frac{K}{2}\\,\\lambda_k\\,\\lvert Q_k \\rvert^2, \\quad \\text{with} \\quad \\lambda_k \\,=\\, 4 \\sin^2\\!\\left( \\frac{\\pi k}{N} \\right).\n$$\nWhile these modes are uncoupled and their energies are conserved for the linear case ($\\alpha=0$), they are coupled by the $\\alpha$ term in the FPU model, allowing energy to be exchanged. We monitor the energy in a low-wavenumber band, $I(t) = \\sum_{k \\in \\mathcal{S}} E_k^{\\text{lin}}$, where $\\mathcal{S} = \\{1, \\dots, k_c\\} \\cup \\{N-k_c, \\dots, N-1\\}$. In a truly ergodic system, $I(t)$ should fluctuate significantly over time as energy flows in and out of the band $\\mathcal{S}$. In a system constrained by spurious invariants, this flow is restricted, and $I(t)$ remains more constant. The time variance, $\\mathrm{Var}(I)$, quantifies these fluctuations. A smaller $\\mathrm{Var}(I)$ indicates stronger spurious conservation and reduced ergodicity.\n\nThe algorithm proceeds as follows for each test case:\n1. Initialize the position and momentum arrays, $\\mathbf{q}(0)$ and $\\mathbf{p}(0)$, according to the specified single-mode excitation: $q_i(0) = A \\cos(2\\pi k_0 i / N)$ with $k_0 = 1$, and $p_i(0)=0$.\n2. Simulate the system for $M$ time steps using the specified integrator (Lie-Trotter or Strang).\n3. At each time step $t_j = j\\Delta t$, calculate the diagnostic quantity $I(t_j)$. This involves:\n    a. Computing the Fourier transforms $\\mathbf{Q}(t_j)$ and $\\mathbf{P}(t_j)$ using the `ortho` normalization.\n    b. Calculating the linear mode energies $E_k^{\\text{lin}}(t_j)$ for all $k$.\n    c. Summing the energies for $k$ in the specified set $\\mathcal{S}$ to get $I(t_j)$.\n4. After completing the simulation, compute the variance of the stored time series $\\{I(t_j)\\}_{j=1}^M$.\n\nThis procedure is applied to each of the four test cases, and the resulting variances are reported. In Case 1 ($\\alpha=0$), we expect $\\mathrm{Var}(I) \\approx 0$, as the linear mode energies are exactly conserved. For the nonlinear cases, we expect the variance to reflect the degree of spurious conservation. A lower-order method (Lie-Trotter) or a larger time step $\\Delta t$ generally leads to a larger deviation in the shadow Hamiltonian, which can strengthen spurious invariants and thus lead to a smaller variance.",
            "answer": "```python\nimport numpy as np\nimport scipy.fft\n\ndef solve():\n    \"\"\"\n    Main function to run the FPU simulation for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Case 1: integrable baseline\n        {'N': 16, 'm': 1, 'K': 1, 'alpha': 0, 'dt': 0.04, 'M': 4000, \n         'method': 'Strang', 'k_c': 2, 'A': 0.4, 'k0': 1},\n        # Case 2: happy path nonlinear, small step\n        {'N': 16, 'm': 1, 'K': 1, 'alpha': 0.5, 'dt': 0.01, 'M': 8000, \n         'method': 'Strang', 'k_c': 2, 'A': 0.4, 'k0': 1},\n        # Case 3: nonlinear, larger step\n        {'N': 16, 'm': 1, 'K': 1, 'alpha': 0.5, 'dt': 0.05, 'M': 8000, \n         'method': 'Strang', 'k_c': 2, 'A': 0.4, 'k0': 1},\n        # Case 4: nonlinear, larger step, lower order splitting\n        {'N': 16, 'm': 1, 'K': 1, 'alpha': 0.5, 'dt': 0.05, 'M': 8000, \n         'method': 'Lie–Trotter', 'k_c': 2, 'A': 0.4, 'k0': 1},\n    ]\n\n    results = []\n    for params in test_cases:\n        var_I = run_simulation(**params)\n        results.append(var_I)\n\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\ndef calculate_force(q, K, alpha):\n    \"\"\"\n    Calculates the force on each particle in the FPU chain.\n    f_i = (K(q_{i+1}-q_i) + alpha(q_{i+1}-q_i)^3) - (K(q_i-q_{i-1}) + alpha(q_i-q_{i-1})^3)\n    \"\"\"\n    # Difference with the particle to the right (i+1)\n    delta_q_plus = np.roll(q, -1) - q\n    # Difference with the particle to the left (i-1)\n    delta_q_minus = q - np.roll(q, 1)\n\n    # Force contribution from the right and left springs\n    force_plus = K * delta_q_plus + alpha * np.power(delta_q_plus, 3)\n    force_minus = K * delta_q_minus + alpha * np.power(delta_q_minus, 3)\n\n    return force_plus - force_minus\n\ndef calculate_band_energy(q, p, N, m, K, k_c):\n    \"\"\"\n    Calculates the low-frequency band energy diagnostic I(t).\n    \"\"\"\n    # Unitary Discrete Fourier Transform (norm='ortho')\n    Q = scipy.fft.fft(q, norm='ortho')\n    P = scipy.fft.fft(p, norm='ortho')\n    \n    k_vals = np.arange(N)\n    \n    # Dispersion factor\n    lambda_k = 4 * np.sin(np.pi * k_vals / N)**2\n    \n    # Linear normal mode energies\n    E_k_lin = (0.5 / m) * np.abs(P)**2 + (0.5 * K) * lambda_k * np.abs(Q)**2\n    \n    # Define the set S for low-frequency modes\n    # S = {1, 2, ..., k_c} U {N-k_c, ..., N-1}\n    indices_low = np.arange(1, k_c + 1)\n    indices_high = np.arange(N - k_c, N)\n    s_indices = np.concatenate((indices_low, indices_high))\n    \n    # Sum energies over the band\n    I_t = np.sum(E_k_lin[s_indices])\n    \n    return I_t\n\ndef run_simulation(N, m, K, alpha, dt, M, method, k_c, A, k0):\n    \"\"\"\n    Runs a single FPU simulation and returns the variance of the band energy.\n    \"\"\"\n    # Initialization\n    i_vals = np.arange(N)\n    q = A * np.cos(2 * np.pi * k0 * i_vals / N)\n    p = np.zeros(N)\n    \n    I_series = np.zeros(M)\n\n    for j in range(M):\n        # Apply the selected integration scheme\n        if method == 'Lie–Trotter':\n            # Drift\n            q = q + (dt / m) * p\n            # Kick\n            force = calculate_force(q, K, alpha)\n            p = p + dt * force\n        elif method == 'Strang':\n            # Half-kick\n            force1 = calculate_force(q, K, alpha)\n            p_half = p + (dt / 2.0) * force1\n            # Full Drift\n            q = q + (dt / m) * p_half\n            # Half-kick\n            force2 = calculate_force(q, K, alpha)\n            p = p_half + (dt / 2.0) * force2\n\n        # Record the diagnostic quantity\n        I_series[j] = calculate_band_energy(q, p, N, m, K, k_c)\n        \n    # Calculate the time variance of the band energy\n    # np.var computes population variance by default, matching the problem spec\n    var_I = np.var(I_series)\n    \n    return var_I\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "After generating a sufficiently long and ergodic trajectory, the practical goal is to compute macroscopic observables by replacing ensemble averages with time averages. The ergodic hypothesis provides the theoretical foundation for this, but a critical practical question remains: how long must the trajectory be to yield a statistically reliable result? This practice  directly tackles this issue by connecting the dynamics of the system to the statistics of its observables. You will derive and implement the core formula that links the variance of a time-averaged quantity to the system's integrated autocorrelation time, $\\tau_{\\text{int}}$, providing a powerful tool for estimating the required simulation length for a given level of precision.",
            "id": "3475291",
            "problem": "Consider a Lennard-Jones (LJ) fluid simulated using Molecular Dynamics (MD). Let $U(t)$ denote the instantaneous potential energy as a function of time $t$. Assume the process is stationary and ergodic in the sense that the time-average equals the ensemble average as the trajectory length approaches infinity. Define the time-average of the potential energy over a trajectory of length $T$ as\n$$\n\\overline{U}_T = \\frac{1}{T} \\int_{0}^{T} U(t)\\, dt,\n$$\nand denote the ensemble average by\n$$\n\\langle U \\rangle = \\mathbb{E}[U(t)].\n$$\nLet the fluctuation be $\\delta U(t) = U(t) - \\langle U \\rangle$. Define the autocovariance function\n$$\nC(\\tau) = \\langle \\delta U(0)\\,\\delta U(\\tau) \\rangle,\n$$\nand the normalized autocorrelation function (ACF)\n$$\n\\rho(\\tau) = \\frac{C(\\tau)}{C(0)},\n$$\nwhere $C(0) = \\sigma^2$ is the variance of $U(t)$. The Integrated Autocorrelation Time (IAT) for a continuous-time process is\n$$\n\\tau_{\\mathrm{int}} = \\int_{0}^{\\infty} \\rho(\\tau)\\, d\\tau,\n$$\nand for a discrete-time sampled process with sampling interval $\\Delta t$ and lags indexed by integers $k \\in \\{0,1,2,\\dots\\}$, the IAT in units of steps is\n$$\n\\tau_{\\mathrm{int,steps}} = \\frac{1}{2} + \\sum_{k=1}^{\\infty} \\rho_k,\n$$\nwith the time-unit IAT given by $\\tau_{\\mathrm{int,time}} = \\Delta t \\,\\tau_{\\mathrm{int,steps}}$.\n\nStarting only from these definitions, properties of stationary processes, and fundamental probability calculus, derive an expression for the minimal trajectory length $T$ such that the root-mean-square deviation of $\\overline{U}_T$ from $\\langle U \\rangle$ does not exceed a given tolerance $\\varepsilon$ in energy units. The final expression must show how $T$ depends on $\\sigma^2$, $\\varepsilon$, and the Integrated Autocorrelation Time (IAT).\n\nImplement a program that, for each of the following test cases, computes the minimal trajectory length $T$ required so that the root-mean-square deviation is at most $\\varepsilon$. All $T$ values must be reported in picoseconds. For continuous-time cases, use the continuous-time IAT. For discrete-time cases, compute $\\tau_{\\mathrm{int,steps}}$ by summing the ACF until the term magnitude falls below a threshold of $10^{-12}$ and then convert to time units using $\\Delta t$.\n\nTest suite specifications:\n- Case $1$ (continuous-time exponential ACF):\n  - $\\rho(\\tau) = \\exp\\left(-\\frac{\\tau}{\\tau_c}\\right)$,\n  - $\\tau_c = 2.5$ $\\mathrm{ps}$,\n  - $\\sigma^2 = 25$ $(\\mathrm{kJ/mol})^2$,\n  - $\\varepsilon = 0.5$ $\\mathrm{kJ/mol}$.\n- Case $2$ (continuous-time stretched-exponential ACF):\n  - $\\rho(\\tau) = \\exp\\left(-\\left(\\frac{\\tau}{\\tau_c}\\right)^{\\beta}\\right)$,\n  - $\\tau_c = 1.0$ $\\mathrm{ps}$,\n  - $\\beta = 0.5$,\n  - $\\sigma^2 = 9$ $(\\mathrm{kJ/mol})^2$,\n  - $\\varepsilon = 0.3$ $\\mathrm{kJ/mol}$.\n- Case $3$ (discrete-time exponential ACF):\n  - $\\rho_k = \\exp\\left(-\\frac{k\\,\\Delta t}{\\tau_c}\\right)$,\n  - $\\Delta t = 0.693147$ $\\mathrm{ps}$,\n  - $\\tau_c = 1.0$ $\\mathrm{ps}$,\n  - $\\sigma^2 = 4$ $(\\mathrm{kJ/mol})^2$,\n  - $\\varepsilon = 0.2$ $\\mathrm{kJ/mol}$.\n- Case $4$ (discrete-time uncorrelated edge case):\n  - $\\rho_k = 0$ for all $k \\ge 1$,\n  - $\\Delta t = 0.5$ $\\mathrm{ps}$,\n  - $\\sigma^2 = 16$ $(\\mathrm{kJ/mol})^2$,\n  - $\\varepsilon = 1.0$ $\\mathrm{kJ/mol}$.\n\nAngle units are not applicable. All physical units must be consistently handled. Express the final trajectory length $T$ in picoseconds, rounded to 3 decimal places.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as $[T_1, T_2, T_3, T_4]$ for Cases $1$ through $4$, for example, $[T_1,T_2,T_3,T_4]$, where each $T_i$ is a float in picoseconds rounded to 3 decimal places.",
            "solution": "The problem statement is a valid and well-posed exercise in the statistical analysis of time-series data from a computational simulation, a standard topic in computational materials science. It is scientifically grounded in the principles of statistical mechanics, particularly the theory of fluctuations and time-correlation functions. The definitions provided for time averages, ensemble averages, autocorrelation functions (ACF), and integrated autocorrelation time (IAT) are standard. All parameters for the test cases are explicitly provided, and the problem is self-contained and internally consistent. There are no scientific inaccuracies, ambiguities, or contradictions.\n\nThe central task is to derive an expression for the minimal simulation time $T$ required to estimate the ensemble average of the potential energy, $\\langle U \\rangle$, with a specified statistical precision. The precision is defined by the condition that the root-mean-square deviation of the time-averaged potential energy, $\\overline{U}_T$, from the true ensemble average does not exceed a tolerance $\\varepsilon$. This condition is formally expressed as:\n$$\n\\sqrt{\\mathbb{E}\\left[ (\\overline{U}_T - \\langle U \\rangle)^2 \\right]} \\le \\varepsilon\n$$\nwhere $\\mathbb{E}[\\cdot]$ denotes the expectation operator. Squaring both sides yields the condition on the variance of the time-average, $\\text{Var}(\\overline{U}_T)$:\n$$\n\\text{Var}(\\overline{U}_T) = \\mathbb{E}\\left[ (\\overline{U}_T - \\langle U \\rangle)^2 \\right] \\le \\varepsilon^2\n$$\nNote that for a stationary process, $\\mathbb{E}[\\overline{U}_T] = \\langle U \\rangle$. Our first step is to derive an expression for $\\text{Var}(\\overline{U}_T)$.\n\nStarting from the definition of the time-average $\\overline{U}_T$ for a continuous-time process:\n$$\n\\overline{U}_T = \\frac{1}{T} \\int_{0}^{T} U(t)\\, dt\n$$\nThe variance is:\n$$\n\\text{Var}(\\overline{U}_T) = \\mathbb{E}\\left[ \\left( \\frac{1}{T} \\int_{0}^{T} U(t)\\, dt - \\langle U \\rangle \\right)^2 \\right]\n$$\nUsing the fluctuation $\\delta U(t) = U(t) - \\langle U \\rangle$, we can rewrite this as:\n$$\n\\text{Var}(\\overline{U}_T) = \\mathbb{E}\\left[ \\left( \\frac{1}{T} \\int_{0}^{T} \\delta U(t)\\, dt \\right)^2 \\right] = \\frac{1}{T^2} \\mathbb{E}\\left[ \\int_{0}^{T} \\int_{0}^{T} \\delta U(t) \\delta U(t')\\, dt\\, dt' \\right]\n$$\nBy applying Fubini's theorem to interchange the expectation and integration operators, we obtain:\n$$\n\\text{Var}(\\overline{U}_T) = \\frac{1}{T^2} \\int_{0}^{T} \\int_{0}^{T} \\mathbb{E}[ \\delta U(t) \\delta U(t') ]\\, dt\\, dt'\n$$\nThe term within the integral is the autocovariance function, which for a stationary process depends only on the time difference $\\tau = t - t'$: $C(t-t') = \\langle \\delta U(t) \\delta U(t') \\rangle$.\n$$\n\\text{Var}(\\overline{U}_T) = \\frac{1}{T^2} \\int_{0}^{T} \\int_{0}^{T} C(t - t')\\, dt\\, dt'\n$$\nThis double integral over a square domain can be simplified. By changing variables or evaluating the integral geometrically, one obtains the standard result:\n$$\n\\int_{0}^{T} \\int_{0}^{T} C(t - t')\\, dt\\, dt' = 2 \\int_{0}^{T} (T-\\tau) C(\\tau)\\, d\\tau\n$$\nThus, the variance becomes:\n$$\n\\text{Var}(\\overline{U}_T) = \\frac{2}{T} \\int_{0}^{T} \\left(1 - \\frac{\\tau}{T}\\right) C(\\tau)\\, d\\tau\n$$\nFor a trajectory of length $T$ that is much longer than the time scale over which correlations decay (i.e., $T \\gg \\tau$ for all $\\tau$ where $C(\\tau)$ is non-negligible), the term $\\tau/T$ becomes insignificant, and the upper limit of integration can be extended to infinity without substantial error. This approximation yields:\n$$\n\\text{Var}(\\overline{U}_T) \\approx \\frac{2}{T} \\int_{0}^{\\infty} C(\\tau)\\, d\\tau\n$$\nUsing the definitions $C(\\tau) = C(0) \\rho(\\tau) = \\sigma^2 \\rho(\\tau)$ and $\\tau_{\\mathrm{int}} = \\int_{0}^{\\infty} \\rho(\\tau)\\, d\\tau$, we find:\n$$\n\\text{Var}(\\overline{U}_T) \\approx \\frac{2 \\sigma^2}{T} \\int_{0}^{\\infty} \\rho(\\tau)\\, d\\tau = \\frac{2 \\sigma^2 \\tau_{\\mathrm{int}}}{T}\n$$\nSubstituting this into our precision requirement, $\\text{Var}(\\overline{U}_T) \\le \\varepsilon^2$:\n$$\n\\frac{2 \\sigma^2 \\tau_{\\mathrm{int}}}{T} \\le \\varepsilon^2\n$$\nSolving for the minimal trajectory length $T$ gives the principal result:\n$$\nT \\ge \\frac{2 \\sigma^2 \\tau_{\\mathrm{int}}}{\\varepsilon^2}\n$$\nThe minimal length is therefore $T = \\frac{2 \\sigma^2 \\tau_{\\mathrm{int}}}{\\varepsilon^2}$.\n\nFor a discrete-time process with sampling interval $\\Delta t$, an analogous derivation leads to the variance of the mean of $N$ samples being $\\text{Var}(\\overline{U}_N) \\approx \\frac{\\sigma^2}{N} \\left( 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k \\right)$. Using the problem's definition for the IAT in steps, $\\tau_{\\mathrm{int,steps}} = \\frac{1}{2} + \\sum_{k=1}^{\\infty} \\rho_k$, the term in parenthesis is $2 \\tau_{\\mathrm{int,steps}}$. Thus, $\\text{Var}(\\overline{U}_N) \\approx \\frac{2 \\sigma^2 \\tau_{\\mathrm{int,steps}}}{N}$. The total time is $T = N \\Delta t$. The condition becomes $\\frac{2 \\sigma^2 \\tau_{\\mathrm{int,steps}}}{T / \\Delta t} \\le \\varepsilon^2$, which simplifies to $T \\ge \\frac{2 \\sigma^2 (\\tau_{\\mathrm{int,steps}} \\Delta t)}{\\varepsilon^2}$. Defining $\\tau_{\\mathrm{int,time}} = \\tau_{\\mathrm{int,steps}} \\Delta t$, the formula for $T$ retains the same form as the continuous case.\n\nWe now apply this master formula, $T = \\frac{2 \\sigma^2 \\tau_{\\mathrm{int}}}{\\varepsilon^2}$, to each test case.\n\n**Case 1: Continuous-time exponential ACF**\n- Givens: $\\rho(\\tau) = \\exp(-\\tau/\\tau_c)$, $\\tau_c = 2.5$ $\\mathrm{ps}$, $\\sigma^2 = 25$ $(\\mathrm{kJ/mol})^2$, $\\varepsilon = 0.5$ $\\mathrm{kJ/mol}$.\n- First, we compute the IAT:\n  $$ \\tau_{\\mathrm{int}} = \\int_{0}^{\\infty} \\exp\\left(-\\frac{\\tau}{\\tau_c}\\right) d\\tau = \\left[ -\\tau_c \\exp\\left(-\\frac{\\tau}{\\tau_c}\\right) \\right]_0^\\infty = 0 - (-\\tau_c) = \\tau_c = 2.5 \\text{ ps} $$\n- Then, we compute the minimal trajectory length $T$:\n  $$ T_1 = \\frac{2 \\cdot 25 \\cdot 2.5}{(0.5)^2} = \\frac{125}{0.25} = 500.0 \\text{ ps} $$\n\n**Case 2: Continuous-time stretched-exponential ACF**\n- Givens: $\\rho(\\tau) = \\exp(-(\\tau/\\tau_c)^\\beta)$, $\\tau_c = 1.0$ $\\mathrm{ps}$, $\\beta = 0.5$, $\\sigma^2 = 9$ $(\\mathrm{kJ/mol})^2$, $\\varepsilon = 0.3$ $\\mathrm{kJ/mol}$.\n- We compute the IAT via a change of variables, $x = (\\tau/\\tau_c)^\\beta$:\n  $$ \\tau_{\\mathrm{int}} = \\int_{0}^{\\infty} \\exp\\left(-\\left(\\frac{\\tau}{\\tau_c}\\right)^\\beta\\right) d\\tau = \\frac{\\tau_c}{\\beta} \\int_{0}^{\\infty} x^{\\frac{1}{\\beta}-1} e^{-x} dx = \\frac{\\tau_c}{\\beta} \\Gamma\\left(\\frac{1}{\\beta}\\right) $$\n- With $\\beta = 0.5$, we have $1/\\beta = 2$. Using $\\Gamma(2) = 1! = 1$:\n  $$ \\tau_{\\mathrm{int}} = \\frac{1.0}{0.5} \\Gamma(2) = 2 \\cdot 1 = 2.0 \\text{ ps} $$\n- Then, we compute $T$:\n  $$ T_2 = \\frac{2 \\cdot 9 \\cdot 2.0}{(0.3)^2} = \\frac{36}{0.09} = 400.0 \\text{ ps} $$\n\n**Case 3: Discrete-time exponential ACF**\n- Givens: $\\rho_k = \\exp(-k \\Delta t/\\tau_c)$, $\\Delta t = 0.693147$ $\\mathrm{ps}$, $\\tau_c = 1.0$ $\\mathrm{ps}$, $\\sigma^2 = 4$ $(\\mathrm{kJ/mol})^2$, $\\varepsilon = 0.2$ $\\mathrm{kJ/mol}$.\n- We compute $\\tau_{\\mathrm{int,steps}} = \\frac{1}{2} + \\sum_{k=1}^{\\infty} \\rho_k$. The sum is a geometric series $\\sum_{k=1}^{\\infty} r^k$ with $r = \\exp(-\\Delta t/\\tau_c) = \\exp(-0.693147) \\approx 0.5$. The sum is $\\frac{r}{1-r} = \\frac{0.5}{1-0.5} = 1$. The numerical summation up to a tolerance of $10^{-12}$ will closely approximate this value.\n  $$ \\tau_{\\mathrm{int,steps}} = 0.5 + 1.0 = 1.5 $$\n- The IAT in time units is:\n  $$ \\tau_{\\mathrm{int,time}} = \\tau_{\\mathrm{int,steps}} \\cdot \\Delta t = 1.5 \\cdot 0.693147 \\text{ ps} \\approx 1.0397205 \\text{ ps} $$\n- Then, we compute $T$:\n  $$ T_3 = \\frac{2 \\cdot 4 \\cdot 1.0397205}{(0.2)^2} = \\frac{8 \\cdot 1.0397205}{0.04} = 200 \\cdot 1.0397205 \\approx 207.944 \\text{ ps} $$\n\n**Case 4: Discrete-time uncorrelated edge case**\n- Givens: $\\rho_k = 0$ for $k \\ge 1$, $\\Delta t = 0.5$ $\\mathrm{ps}$, $\\sigma^2 = 16$ $(\\mathrm{kJ/mol})^2$, $\\varepsilon = 1.0$ $\\mathrm{kJ/mol}$.\n- We compute $\\tau_{\\mathrm{int,steps}}$:\n  $$ \\tau_{\\mathrm{int,steps}} = \\frac{1}{2} + \\sum_{k=1}^{\\infty} 0 = 0.5 $$\n- This case represents a completely uncorrelated process (white noise). The IAT in time units is:\n  $$ \\tau_{\\mathrm{int,time}} = \\tau_{\\mathrm{int,steps}} \\cdot \\Delta t = 0.5 \\cdot 0.5 \\text{ ps} = 0.25 \\text{ ps} $$\n- Then, we compute $T$:\n  $$ T_4 = \\frac{2 \\cdot 16 \\cdot 0.25}{(1.0)^2} = 32 \\cdot 0.25 = 8.0 \\text{ ps} $$\nThis corresponds to needing $N = T/\\Delta t = 8.0/0.5 = 16$ samples, for which the variance of the mean is $\\sigma^2/N = 16/16 = 1 = \\varepsilon^2$, as expected for independent samples.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gamma\n\ndef solve():\n    \"\"\"\n    Computes the minimal trajectory length T required for a given statistical tolerance\n    based on the integrated autocorrelation time of a stationary process.\n    \"\"\"\n    \n    # Test cases defined in the problem statement.\n    # Structure: (case_type, parameters_dict)\n    test_cases = [\n        ('continuous', {\n            'type': 'exponential', 'tau_c': 2.5, 'sigma_sq': 25.0, 'epsilon': 0.5\n        }),\n        ('continuous', {\n            'type': 'stretched_exponential', 'tau_c': 1.0, 'beta': 0.5, 'sigma_sq': 9.0, 'epsilon': 0.3\n        }),\n        ('discrete', {\n            'type': 'exponential', 'delta_t': 0.693147, 'tau_c': 1.0, 'sigma_sq': 4.0, 'epsilon': 0.2\n        }),\n        ('discrete', {\n            'type': 'uncorrelated', 'delta_t': 0.5, 'sigma_sq': 16.0, 'epsilon': 1.0\n        })\n    ]\n\n    results = []\n\n    for case_type, params in test_cases:\n        sigma_sq = params['sigma_sq']\n        epsilon = params['epsilon']\n\n        if case_type == 'continuous':\n            if params['type'] == 'exponential':\n                # For rho(tau) = exp(-tau/tau_c), the IAT is tau_c.\n                tau_int = params['tau_c']\n            elif params['type'] == 'stretched_exponential':\n                # For rho(tau) = exp(-(tau/tau_c)^beta), IAT = (tau_c/beta) * Gamma(1/beta)\n                tau_c = params['tau_c']\n                beta = params['beta']\n                tau_int = (tau_c / beta) * gamma(1.0 / beta)\n        \n        elif case_type == 'discrete':\n            delta_t = params['delta_t']\n            \n            sum_rho_k = 0.0\n            if params['type'] == 'exponential':\n                tau_c = params['tau_c']\n                k = 1\n                ratio = delta_t / tau_c\n                # Sum ACF terms until they are smaller than the given threshold.\n                while True:\n                    term = np.exp(-k * ratio)\n                    if term  1e-12:\n                        break\n                    sum_rho_k += term\n                    k += 1\n            elif params['type'] == 'uncorrelated':\n                # rho_k = 0 for k>=1, so the sum is 0.\n                sum_rho_k = 0.0\n            \n            # IAT in units of steps\n            tau_int_steps = 0.5 + sum_rho_k\n            # IAT in units of time\n            tau_int = tau_int_steps * delta_t\n            \n        # The master formula for minimal trajectory length T\n        # T = (2 * sigma^2 * tau_int) / epsilon^2\n        T = (2.0 * sigma_sq * tau_int) / (epsilon**2)\n        results.append(T)\n\n    # Format the final output as a comma-separated list of floats\n    # rounded to 3 decimal places, enclosed in brackets.\n    formatted_results = [f\"{res:.3f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        }
    ]
}