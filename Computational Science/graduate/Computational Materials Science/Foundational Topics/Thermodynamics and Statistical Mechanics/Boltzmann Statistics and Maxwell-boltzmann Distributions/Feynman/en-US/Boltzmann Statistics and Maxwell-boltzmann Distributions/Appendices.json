{
    "hands_on_practices": [
        {
            "introduction": "In computational materials science, we rely on simulations to correctly sample the statistical ensembles that describe physical systems. This first practice moves from theory to verification, tasking you with designing a statistically robust procedure to test whether velocity data from a molecular dynamics simulation truly conforms to the Maxwell-Boltzmann distribution. Mastering this process is essential for validating your simulations and building confidence in their predictive power, ensuring that your computational results have a sound physical basis .",
            "id": "3435506",
            "problem": "You are tasked with designing a statistically principled computational test that verifies whether a Molecular Dynamics (MD) simulation of a Lennard–Jones fluid at temperature $T$ produces velocity components that follow the Gaussian distribution predicted by Boltzmann statistics and whether the resulting speed distribution matches the three-dimensional Maxwell–Boltzmann form. Your program must be fully self-contained and must run without any user input or external data. It must implement the following requirements using only well-tested scientific principles and definitions as a base.\n\nFundamental base the solution must start from:\n- The canonical ensemble at fixed temperature $T$ implies the phase-space probability density proportional to $\\exp(-\\beta H)$, with $\\beta = 1 / (k_B T)$ and $H$ the Hamiltonian.\n- The kinetic energy for a non-relativistic particle of mass $m$ is $E_{\\mathrm{kin}} = \\frac{1}{2} m (v_x^2 + v_y^2 + v_z^2)$.\n- The isotropy of space in equilibrium implies that the distribution of the velocity vector depends only on its magnitude.\n- The Boltzmann constant is $k_B$; use $k_B = 1.380649 \\times 10^{-23}$ in $\\mathrm{J/K}$.\n- The expected statistical behavior follows from these definitions and isotropy, but you must not assume any shortcut formulas.\n\nVerification tasks to implement:\n- Derive the theoretical cumulative distribution function (CDF) for one Cartesian velocity component $v_x$ at temperature $T$ for mass $m$ implied by the canonical ensemble and isotropy, and use it to test whether a sample of $v_x$ is consistent with the corresponding Gaussian distribution at the given $T$ and $m$.\n- Derive the theoretical CDF for the speed $s = \\sqrt{v_x^2 + v_y^2 + v_z^2}$ at temperature $T$ for mass $m$, and use it to test whether a sample of speeds is consistent with the resulting three-dimensional speed distribution.\n- Use a statistically principled goodness-of-fit procedure that compares a sample to a fully specified theoretical CDF. Use a one-sample goodness-of-fit test that yields a $p$-value based on the exact CDFs you derive, and choose a significance level $\\alpha = 10^{-4}$ for each test.\n- In addition to goodness-of-fit for the one-dimensional components, include a test that the sample mean of each Cartesian velocity component is consistent with zero, using the standard error implied by the theoretical variance and a two-sided $z$-score threshold of $|z| \\le 4.0$.\n- Declare that the MD sample passes if and only if all three component tests pass simultaneously and the speed test passes, at the specified $\\alpha$ and $z$-score threshold.\n\nData generation for an internal test suite:\n- Because the program must be standalone and reproducible, you must generate synthetic \"putative MD\" velocity data via independent sampling in three Cartesian directions. For a given simulation mass $m$, a \"simulation temperature\" $T_{\\mathrm{sim}}$, a theory temperature $T_{\\mathrm{theory}}$ (the value against which the test assesses the data), a drift vector $(\\mu_x, \\mu_y, \\mu_z)$ in $\\mathrm{m/s}$, and anisotropy scale factors $(a_x, a_y, a_z)$, generate $N$ samples as follows:\n  - For each component $i \\in \\{x,y,z\\}$, draw $v_i$ independently from a normal distribution with mean $\\mu_i$ and standard deviation $\\sigma_i = a_i \\sqrt{k_B T_{\\mathrm{sim}} / m}$.\n  - The statistical tests must be evaluated against the theoretical model at $T_{\\mathrm{theory}}$ and $m$.\n- All velocities must be expressed in $\\mathrm{m/s}$, all temperatures in $\\mathrm{K}$, and the mass in $\\mathrm{kg}$.\n\nYour program must implement the following test suite of parameter sets, each of which generates a separate synthetic dataset. For each case, the program must output one boolean indicating whether the data passes all verification tasks. The parameters are tuples $(N, m, T_{\\mathrm{theory}}, T_{\\mathrm{sim}}, \\mu_x, \\mu_y, \\mu_z, a_x, a_y, a_z, \\mathrm{seed})$ with units:\n- Case $1$ (happy path, isotropic, correct temperature): $(N = 20000, m = 6.63 \\times 10^{-26}\\ \\mathrm{kg}, T_{\\mathrm{theory}} = 120\\ \\mathrm{K}, T_{\\mathrm{sim}} = 120\\ \\mathrm{K}, \\mu_x = 0\\ \\mathrm{m/s}, \\mu_y = 0\\ \\mathrm{m/s}, \\mu_z = 0\\ \\mathrm{m/s}, a_x = 1, a_y = 1, a_z = 1, \\mathrm{seed} = 12345)$.\n- Case $2$ (mismatched temperature): $(N = 15000, m = 6.63 \\times 10^{-26}\\ \\mathrm{kg}, T_{\\mathrm{theory}} = 120\\ \\mathrm{K}, T_{\\mathrm{sim}} = 150\\ \\mathrm{K}, \\mu_x = 0\\ \\mathrm{m/s}, \\mu_y = 0\\ \\mathrm{m/s}, \\mu_z = 0\\ \\mathrm{m/s}, a_x = 1, a_y = 1, a_z = 1, \\mathrm{seed} = 2024)$.\n- Case $3$ (nonzero drift in one direction): $(N = 15000, m = 6.63 \\times 10^{-26}\\ \\mathrm{kg}, T_{\\mathrm{theory}} = 120\\ \\mathrm{K}, T_{\\mathrm{sim}} = 120\\ \\mathrm{K}, \\mu_x = 40\\ \\mathrm{m/s}, \\mu_y = 0\\ \\mathrm{m/s}, \\mu_z = 0\\ \\mathrm{m/s}, a_x = 1, a_y = 1, a_z = 1, \\mathrm{seed} = 777)$.\n- Case $4$ (anisotropy in one direction): $(N = 15000, m = 6.63 \\times 10^{-26}\\ \\mathrm{kg}, T_{\\mathrm{theory}} = 120\\ \\mathrm{K}, T_{\\mathrm{sim}} = 120\\ \\mathrm{K}, \\mu_x = 0\\ \\mathrm{m/s}, \\mu_y = 0\\ \\mathrm{m/s}, \\mu_z = 0\\ \\mathrm{m/s}, a_x = 1, a_y = 1, a_z = 1.5, \\mathrm{seed} = 314159)$.\n- Case $5$ (high temperature, correct model, moderate sample size): $(N = 5000, m = 6.63 \\times 10^{-26}\\ \\mathrm{kg}, T_{\\mathrm{theory}} = 3000\\ \\mathrm{K}, T_{\\mathrm{sim}} = 3000\\ \\mathrm{K}, \\mu_x = 0\\ \\mathrm{m/s}, \\mu_y = 0\\ \\mathrm{m/s}, \\mu_z = 0\\ \\mathrm{m/s}, a_x = 1, a_y = 1, a_z = 1, \\mathrm{seed} = 424242)$.\n\nAcceptance criterion per case:\n- For each of the three components, compute a two-sided $z$-score for the sample mean against the theoretical standard deviation at $T_{\\mathrm{theory}}$ and $m$ and require $|z| \\le 4.0$.\n- Perform a one-sample goodness-of-fit test for each component against the derived Gaussian CDF at the given $T_{\\mathrm{theory}}$ and $m$ with significance level $\\alpha = 10^{-4}$, and independently perform a one-sample goodness-of-fit test on the speed sample against the derived three-dimensional speed CDF at the same $T_{\\mathrm{theory}}$ and $m$ with the same $\\alpha$. All four tests must yield $p \\ge \\alpha$.\n- The case passes if and only if all these conditions are simultaneously satisfied.\n\nFinal output format:\n- Your program should produce a single line of output containing the pass/fail results for the five cases as a comma-separated Python-style list of booleans with no spaces, for example, $[True,False,True,True,False]$.\n\nAngle units are not applicable. All physical units are as stated above and all velocities must be treated in $\\mathrm{m/s}$. Round nothing; booleans are exact.",
            "solution": "The objective is to construct a computational procedure for validating whether simulated velocity data from a molecular dynamics (MD) simulation of a fluid at a specified temperature $T$ conforms to the predictions of classical statistical mechanics, specifically Boltzmann statistics. The validation is performed by deriving the theoretical probability distributions for velocity components and particle speed from first principles and then using these distributions in rigorous statistical tests.\n\nFirst, we establish the theoretical foundation. In the canonical ensemble, for a system at a fixed temperature $T$, the probability of observing a microstate with energy $E$ is proportional to the Boltzmann factor, $\\exp(-\\beta E)$, where $\\beta = 1/(k_B T)$ and $k_B$ is the Boltzmann constant. For a system of non-interacting particles, or when considering only the kinetic part of the Hamiltonian, the energy of a single particle of mass $m$ with velocity vector $\\mathbf{v} = (v_x, v_y, v_z)$ is its kinetic energy, $E_{\\mathrm{kin}} = \\frac{1}{2} m (v_x^2 + v_y^2 + v_z^2)$.\n\nThe probability density function (PDF) for the velocity vector $\\mathbf{v}$ is therefore given by:\n$$P(v_x, v_y, v_z) \\propto \\exp\\left(-\\beta E_{\\mathrm{kin}}\\right) = \\exp\\left(-\\frac{\\beta m}{2} (v_x^2 + v_y^2 + v_z^2)\\right)$$\nThis expression can be factorized into three independent terms:\n$$P(v_x, v_y, v_z) \\propto \\exp\\left(-\\frac{\\beta m v_x^2}{2}\\right) \\exp\\left(-\\frac{\\beta m v_y^2}{2}\\right) \\exp\\left(-\\frac{\\beta m v_z^2}{2}\\right)$$\nThis factorization implies that the velocity components $v_x$, $v_y$, and $v_z$ are statistically independent random variables. The problem's assumption of isotropy implies that the distributions for each component are identical. We can thus analyze a single component, say $v_x$. Its PDF is:\n$$P(v_x) = C \\exp\\left(-\\frac{\\beta m v_x^2}{2}\\right)$$\nwhere $C$ is a normalization constant. This is the form of a Gaussian (normal) distribution with a mean of $0$. To find the variance $\\sigma^2$, we normalize the PDF: $\\int_{-\\infty}^{\\infty} P(v_x) dv_x = 1$. Using the standard Gaussian integral $\\int_{-\\infty}^{\\infty} e^{-ax^2} dx = \\sqrt{\\pi/a}$, with $a = \\beta m / 2$, we find $C = \\sqrt{\\beta m / (2\\pi)}$. The PDF is:\n$$P(v_x) = \\sqrt{\\frac{m}{2\\pi k_B T}} \\exp\\left(-\\frac{m v_x^2}{2 k_B T}\\right)$$\nBy comparing this to the standard form of a zero-mean Gaussian PDF, $P(x) = (1/(\\sigma \\sqrt{2\\pi})) \\exp(-x^2/(2\\sigma^2))$, we identify the theoretical variance as $\\sigma^2_{\\mathrm{theory}} = k_B T / m$.\n\nFor the goodness-of-fit test, we require the cumulative distribution function (CDF), $F(v_x) = \\int_{-\\infty}^{v_x} P(u) du$. This integral is related to the error function, $\\mathrm{erf}(z) = (2/\\sqrt{\\pi}) \\int_0^z e^{-t^2} dt$. The resulting CDF for a velocity component is:\n$$F(v_x) = \\frac{1}{2} \\left[1 + \\mathrm{erf}\\left(v_x \\sqrt{\\frac{m}{2 k_B T}}\\right)\\right]$$\nThis fully specifies the theoretical distribution against which a sample of $v_x$ values will be tested.\n\nNext, we derive the distribution for the particle speed, $s = |\\mathbf{v}| = \\sqrt{v_x^2 + v_y^2 + v_z^2}$. Due to isotropy, it is convenient to switch to spherical coordinates in velocity space. The volume element $dv_x dv_y dv_z$ becomes $4\\pi s^2 ds$. The probability of finding a particle with a speed between $s$ and $s+ds$ is the joint PDF integrated over the corresponding spherical shell:\n$$P(s)ds = 4\\pi s^2 P(v_x, v_y, v_z)|_{|\\mathbf{v}|=s} ds = 4\\pi s^2 \\left(\\frac{m}{2\\pi k_B T}\\right)^{3/2} \\exp\\left(-\\frac{m s^2}{2 k_B T}\\right) ds$$\nThis is the Maxwell-Boltzmann speed distribution. The corresponding CDF for speed, $F(s) = \\int_0^s P(u)du$ for $s \\ge 0$, is found by integrating this expression. The result is:\n$$F(s) = \\mathrm{erf}\\left(s\\sqrt{\\frac{m}{2 k_B T}}\\right) - \\sqrt{\\frac{2m}{\\pi k_B T}} s \\exp\\left(-\\frac{m s^2}{2 k_B T}\\right)$$\nThis CDF will be used to test the sample of speeds.\n\nThe computational procedure implements two statistical checks based on these derivations.\n1.  **Mean Verification**: For each Cartesian component $v_i$, we test if its sample mean $\\bar{v}_i$ is consistent with the theoretical mean of $0$. A $z$-score is computed as $z_i = \\bar{v}_i / SE_i$, where $SE_i$ is the standard error of the mean. This is given by $SE_i = \\sigma_{\\mathrm{theory}} / \\sqrt{N}$, with $\\sigma_{\\mathrm{theory}} = \\sqrt{k_B T_{\\mathrm{theory}} / m}$ and $N$ being the sample size. The MD sample passes this test if $|z_i| \\le 4.0$ for all three components, corresponding to a very stringent confidence level.\n\n2.  **Distribution Verification**: We use the one-sample Kolmogorov-Smirnov (K-S) test to compare the empirical distribution of the sampled data against the theoretical CDFs derived above. This test computes the maximum absolute difference between the empirical and theoretical CDFs. This difference is used to calculate a $p$-value. The sample passes this test if the $p$-value is greater than or equal to the specified significance level $\\alpha = 10^{-4}$. This test is performed independently for each of the three velocity components and for the speed.\n\nA given synthetic MD dataset is deemed to pass the overall validation if and only if all seven conditions are met simultaneously: the three $z$-score tests for the means and the four K-S tests (three for components, one for speed) must all pass at their specified thresholds.\n\nThe implementation generates synthetic velocity data according to the problem specification, using a simulation temperature $T_{\\mathrm{sim}}$, drift $\\boldsymbol{\\mu}$, and anisotropy factors $\\mathbf{a}$, while the statistical tests are conducted against the theoretical model at temperature $T_{\\mathrm{theory}}$. This setup allows for testing the robustness of the verification procedure against common deviations from ideal equilibrium, such as incorrect temperature, bulk system motion, or anisotropic kinetic energy distribution.",
            "answer": "```python\nimport numpy as np\nfrom scipy import special, stats\n\ndef solve():\n    \"\"\"\n    Performs a statistically principled validation of synthetic MD velocity data.\n    \"\"\"\n    k_B = 1.380649e-23  # Boltzmann constant in J/K\n\n    test_cases = [\n        # Case 1: Happy path, isotropic, correct temperature\n        (20000, 6.63e-26, 120.0, 120.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 12345),\n        # Case 2: Mismatched temperature\n        (15000, 6.63e-26, 120.0, 150.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2024),\n        # Case 3: Nonzero drift in one direction\n        (15000, 6.63e-26, 120.0, 120.0, 40.0, 0.0, 0.0, 1.0, 1.0, 1.0, 777),\n        # Case 4: Anisotropy in one direction\n        (15000, 6.63e-26, 120.0, 120.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.5, 314159),\n        # Case 5: High temperature, correct model, moderate sample size\n        (5000, 6.63e-26, 3000.0, 3000.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 424242),\n    ]\n\n    def cdf_vx(v, T, m):\n        \"\"\"\n        Theoretical CDF for a Cartesian velocity component.\n        \"\"\"\n        arg = v * np.sqrt(m / (2 * k_B * T))\n        return 0.5 * (1.0 + special.erf(arg))\n\n    def cdf_s(s, T, m):\n        \"\"\"\n        Theoretical CDF for the 3D speed (Maxwell-Boltzmann).\n        \"\"\"\n        # CDF is 0 for s  0\n        s_safe = np.maximum(s, 0)\n        \n        a = m / (2 * k_B * T)\n        sqrt_a = np.sqrt(a)\n        \n        term1 = special.erf(s_safe * sqrt_a)\n        term2 = np.sqrt(4 * a / np.pi) * s_safe * np.exp(-a * s_safe**2)\n        \n        return term1 - term2\n\n    results = []\n    alpha = 1e-4\n    z_threshold = 4.0\n\n    for case in test_cases:\n        N, m, T_theory, T_sim, mu_x, mu_y, mu_z, a_x, a_y, a_z, seed = case\n        \n        rng = np.random.default_rng(seed)\n\n        # Generate synthetic data\n        sigma_sim_base = np.sqrt(k_B * T_sim / m)\n        v_x = rng.normal(loc=mu_x, scale=a_x * sigma_sim_base, size=N)\n        v_y = rng.normal(loc=mu_y, scale=a_y * sigma_sim_base, size=N)\n        v_z = rng.normal(loc=mu_z, scale=a_z * sigma_sim_base, size=N)\n        speeds = np.sqrt(v_x**2 + v_y**2 + v_z**2)\n        \n        # --- Run Verification Tests ---\n        \n        all_checks_passed = True\n        \n        # 1. Mean verification (z-score tests)\n        sigma_theory = np.sqrt(k_B * T_theory / m)\n        std_err = sigma_theory / np.sqrt(N)\n        \n        if std_err == 0:  # Avoid division by zero\n            all_checks_passed = False\n        else:\n            for v_comp in [v_x, v_y, v_z]:\n                mean_v = np.mean(v_comp)\n                z_score = mean_v / std_err\n                if abs(z_score)  z_threshold:\n                    all_checks_passed = False\n                    break\n        \n        if not all_checks_passed:\n            results.append(False)\n            continue\n            \n        # 2. Distribution verification (K-S tests)\n        # Components\n        for v_comp in [v_x, v_y, v_z]:\n            ks_result = stats.kstest(v_comp, lambda v: cdf_vx(v, T_theory, m))\n            if ks_result.pvalue  alpha:\n                all_checks_passed = False\n                break\n        \n        if not all_checks_passed:\n            results.append(False)\n            continue\n        \n        # Speed\n        ks_result_speed = stats.kstest(speeds, lambda s: cdf_s(s, T_theory, m))\n        if ks_result_speed.pvalue  alpha:\n            all_checks_passed = False\n\n        results.append(all_checks_passed)\n        \n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\".replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "Once we are confident that our simulations generate data consistent with Boltzmann statistics, we can leverage this theoretical foundation to perform inference. This exercise challenges you to tackle the inverse problem: instead of predicting distributions from a known temperature, you will infer the temperature from particle speed data using the powerful method of Maximum Likelihood Estimation (MLE). This practice develops your skills in connecting microscopic data to macroscopic thermodynamic properties and introduces the formal statistical machinery for quantifying the uncertainty in your estimates .",
            "id": "3435467",
            "problem": "You are given a histogram of particle speeds extracted from Molecular Dynamics (MD) trajectories of a monatomic, non-interacting gas. Assume that the instantaneous particle speeds are independent and identically distributed in three dimensions according to the Maxwell–Boltzmann (MB) speed distribution, where the probability density function for speed $v \\ge 0$ at absolute temperature $T$ is\n$$\nf(v \\mid T) = 4\\pi \\left(\\frac{m}{2\\pi k_B T}\\right)^{3/2} v^2 \\exp\\!\\left(-\\frac{m v^2}{2 k_B T}\\right).\n$$\nHere, $m$ is the particle mass and $k_B$ is the Boltzmann constant.\n\nFundamental bases to use:\n- The definition of the Maxwell–Boltzmann speed distribution in three dimensions for a monatomic ideal gas.\n- The definition of the likelihood of independent samples and the principle of maximum likelihood estimation.\n- The Fisher information for a parametric family and its use for uncertainty propagation via the Cramér–Rao bound.\n\nYour task is to derive, from first principles, the maximum likelihood estimator (MLE) for the absolute temperature $T$ using the above distribution and a binned histogram of speeds. Use the midpoint approximation for binned data: if a histogram has bin midpoints $\\{v_j\\}$ (in m/s) and integer counts $\\{c_j\\}$, then treat it as if it represents $c_j$ independent samples equal to $v_j$. Using this approximation, derive the MLE for $T$ and derive an analytic expression for the Fisher information-based approximate standard uncertainty of the estimator for $T$.\n\nThen implement a program to compute, for each test case, the MLE $\\hat{T}$ and its Fisher information-based standard uncertainty $\\sigma_{\\hat{T}}$. The numerical output must be in Kelvin (K), rounded to three decimal places.\n\nImportant details and requirements:\n- Use the provided particle mass $m$ (in kilograms), Boltzmann constant $k_B$ (in joules per kelvin), histogram midpoints $\\{v_j\\}$ (in m/s), and counts $\\{c_j\\}$ (dimensionless).\n- Assume the midpoint approximation is valid because the bins are sufficiently narrow relative to the distribution’s scale.\n- Express the final temperatures and uncertainties in kelvin (K), rounded to three decimal places.\n- Angle units do not apply.\n- Do not use percentage signs; any fractional quantities must be expressed as decimals.\n\nTest suite:\nProvide results for the following four test cases. For each case, you are given $m$, $k_B$, the list of bin midpoints (m/s), and the list of integer bin counts:\n1) Happy-path, moderately large sample:\n- $m = 6.6335209\\times 10^{-26}$ kg\n- $k_B = 1.380649\\times 10^{-23}$ J/K\n- midpoints (m/s): $[100, 200, 300, 400, 500, 600, 700]$\n- counts: $[20, 80, 200, 400, 220, 70, 10]$\n2) Low-sample edge case with a single occupied bin:\n- $m = 6.6335209\\times 10^{-26}$ kg\n- $k_B = 1.380649\\times 10^{-23}$ J/K\n- midpoints (m/s): $[790]$\n- counts: $[5]$\n3) Sparse histogram with zero-count bins:\n- $m = 6.6335209\\times 10^{-26}$ kg\n- $k_B = 1.380649\\times 10^{-23}$ J/K\n- midpoints (m/s): $[50, 150, 250, 350, 450, 550]$\n- counts: $[0, 0, 10, 30, 10, 0]$\n4) Different species (different mass) with the same histogram as case $1$:\n- $m = 3.350917\\times 10^{-26}$ kg\n- $k_B = 1.380649\\times 10^{-23}$ J/K\n- midpoints (m/s): $[100, 200, 300, 400, 500, 600, 700]$\n- counts: $[20, 80, 200, 400, 220, 70, 10]$\n\nOutput specification:\n- For each test case, compute the pair $[\\hat{T}, \\sigma_{\\hat{T}}]$ in kelvin.\n- Round both $\\hat{T}$ and $\\sigma_{\\hat{T}}$ to three decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list of these pairs, enclosed in square brackets. For example, the output must look like:\n\"[[T1,SE1],[T2,SE2],[T3,SE3],[T4,SE4]]\"\nwhere each $T_i$ and $SE_i$ are floats rounded to three decimal places and expressed in kelvin.",
            "solution": "**Derivation of the Maximum Likelihood Estimator ($\\hat{T}$)**\n\nThe derivation begins with the Maxwell-Boltzmann PDF provided:\n$$ f(v \\mid T) = 4\\pi \\left(\\frac{m}{2\\pi k_B T}\\right)^{3/2} v^2 \\exp\\!\\left(-\\frac{m v^2}{2 k_B T}\\right) $$\nAccording to the problem statement, the histogram data, consisting of bin midpoints $\\{v_j\\}$ and counts $\\{c_j\\}$, are treated as a set of independent observations where each speed $v_j$ is observed $c_j$ times.\n\nThe likelihood function, $L(T)$, represents the joint probability of this dataset for a given temperature $T$. Assuming independence, it is the product of the individual probabilities:\n$$ L(T) = \\prod_{j} \\left[ f(v_j \\mid T) \\right]^{c_j} $$\nFor analytical convenience, we work with the log-likelihood function, $\\mathcal{L}(T) = \\ln L(T)$. Maximizing $\\mathcal{L}(T)$ is equivalent to maximizing $L(T)$.\n$$ \\mathcal{L}(T) = \\ln \\left( \\prod_{j} \\left[ f(v_j \\mid T) \\right]^{c_j} \\right) = \\sum_j c_j \\ln f(v_j \\mid T) $$\nWe first find the logarithm of the PDF, $\\ln f(v \\mid T)$:\n$$ \\ln f(v \\mid T) = \\ln\\left(4\\pi\\right) + \\frac{3}{2}\\ln\\left(\\frac{m}{2\\pi k_B}\\right) - \\frac{3}{2}\\ln T + 2\\ln v - \\frac{m v^2}{2 k_B T} $$\nThe log-likelihood function is obtained by summing this expression over all observations:\n$$ \\mathcal{L}(T) = \\sum_j c_j \\left[ \\left( \\ln(4\\pi) + \\frac{3}{2}\\ln\\left(\\frac{m}{2\\pi k_B}\\right) + 2\\ln v_j \\right) - \\frac{3}{2}\\ln T - \\frac{m v_j^2}{2 k_B T} \\right] $$\nWe can separate terms that are constant with respect to $T$. Let $N = \\sum_j c_j$ be the total number of particles and $S = \\sum_j c_j v_j^2$ be the weighted sum of squared speeds.\n$$ \\mathcal{L}(T) = \\text{Constant} - \\left(\\sum_j c_j\\right) \\frac{3}{2}\\ln T - \\frac{m}{2 k_B T} \\left(\\sum_j c_j v_j^2\\right) $$\n$$ \\mathcal{L}(T) = \\text{Constant} - \\frac{3N}{2}\\ln T - \\frac{mS}{2 k_B T} $$\nTo find the MLE, $\\hat{T}$, we take the derivative of $\\mathcal{L}(T)$ with respect to $T$ and set it to zero:\n$$ \\frac{d\\mathcal{L}}{dT} = 0 \\implies -\\frac{3N}{2T} + \\frac{mS}{2 k_B T^2} = 0 $$\nAssuming $T \\neq 0$, we multiply by $2k_B T^2$ and rearrange:\n$$ -3 N k_B T + m S = 0 $$\nSolving for $T$ yields the maximum likelihood estimator:\n$$ \\hat{T} = \\frac{mS}{3 N k_B} = \\frac{m \\sum_j c_j v_j^2}{3 k_B \\sum_j c_j} $$\nThis result is consistent with the equipartition theorem, which states that the average kinetic energy of a monatomic particle in three dimensions is $\\langle E_k \\rangle = \\frac{3}{2}k_B T$. The sample mean kinetic energy is $\\frac{1}{2N}\\sum_j c_j m v_j^2 = \\frac{mS}{2N}$. Equating these gives the same expression for $\\hat{T}$.\n\n**Derivation of the Standard Uncertainty ($\\sigma_{\\hat{T}}$)**\n\nThe standard uncertainty of the MLE, $\\sigma_{\\hat{T}}$, is approximated using the Cramér-Rao lower bound. For large $N$, the variance of an unbiased estimator is well-approximated by the inverse of the Fisher information. We will use the observed Fisher information, $J(\\hat{T})$, defined as the negative of the second derivative of the log-likelihood function evaluated at the MLE, $T = \\hat{T}$.\n$$ J(T) = -\\frac{d^2\\mathcal{L}}{dT^2} \\quad \\text{and} \\quad \\sigma_{\\hat{T}} \\approx \\sqrt{J(\\hat{T})^{-1}} $$\nWe first compute the second derivative of $\\mathcal{L}(T)$ from its first derivative:\n$$ \\frac{d\\mathcal{L}}{dT} = -\\frac{3N}{2}T^{-1} + \\frac{mS}{2 k_B}T^{-2} $$\n$$ \\frac{d^2\\mathcal{L}}{dT^2} = \\frac{d}{dT}\\left(-\\frac{3N}{2}T^{-1} + \\frac{mS}{2 k_B}T^{-2}\\right) = \\frac{3N}{2}T^{-2} - \\frac{2mS}{2 k_B}T^{-3} = \\frac{3N}{2T^2} - \\frac{mS}{k_B T^3} $$\nThe observed Fisher information is:\n$$ J(T) = -\\left(\\frac{3N}{2T^2} - \\frac{mS}{k_B T^3}\\right) = \\frac{mS}{k_B T^3} - \\frac{3N}{2T^2} $$\nWe evaluate this at $T = \\hat{T}$. Using the relation $mS = 3Nk_B\\hat{T}$ derived for the MLE simplifies the expression:\n$$ J(\\hat{T}) = \\frac{3Nk_B\\hat{T}}{k_B \\hat{T}^3} - \\frac{3N}{2\\hat{T}^2} = \\frac{3N}{\\hat{T}^2} - \\frac{3N}{2\\hat{T}^2} = \\frac{3N}{2\\hat{T}^2} $$\nThe variance of the estimator is thus approximated by:\n$$ \\text{Var}(\\hat{T}) \\approx J(\\hat{T})^{-1} = \\frac{2\\hat{T}^2}{3N} $$\nThe standard uncertainty, $\\sigma_{\\hat{T}}$, is the square root of the variance:\n$$ \\sigma_{\\hat{T}} = \\sqrt{\\frac{2\\hat{T}^2}{3N}} = \\hat{T} \\sqrt{\\frac{2}{3N}} $$\nwhere $N = \\sum_j c_j$ is the total number of observed particles.\n\n**Computational Algorithm**\nThe program will implement the derived formulas as follows for each test case:\n1.  Calculate the total count $N = \\sum_j c_j$.\n2.  Calculate the weighted sum of squared speeds $S = \\sum_j c_j v_j^2$.\n3.  Compute the temperature estimate $\\hat{T} = \\frac{mS}{3Nk_B}$.\n4.  Compute the standard uncertainty $\\sigma_{\\hat{T}} = \\hat{T} \\sqrt{\\frac{2}{3N}}$.\n5.  Round both values to three decimal places and format the output as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and computes the Maximum Likelihood Estimator (MLE) for temperature\n    and its standard uncertainty from binned particle speed data.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Happy-path, moderately large sample\n        {\n            \"m\": 6.6335209e-26, # kg\n            \"k_B\": 1.380649e-23, # J/K\n            \"midpoints\": np.array([100, 200, 300, 400, 500, 600, 700], dtype=float), # m/s\n            \"counts\": np.array([20, 80, 200, 400, 220, 70, 10], dtype=float), # dimensionless\n        },\n        # Case 2: Low-sample edge case with a single occupied bin\n        {\n            \"m\": 6.6335209e-26,\n            \"k_B\": 1.380649e-23,\n            \"midpoints\": np.array([790], dtype=float),\n            \"counts\": np.array([5], dtype=float),\n        },\n        # Case 3: Sparse histogram with zero-count bins\n        {\n            \"m\": 6.6335209e-26,\n            \"k_B\": 1.380649e-23,\n            \"midpoints\": np.array([50, 150, 250, 350, 450, 550], dtype=float),\n            \"counts\": np.array([0, 0, 10, 30, 10, 0], dtype=float),\n        },\n        # Case 4: Different species (different mass) with the same histogram as case 1\n        {\n            \"m\": 3.350917e-26,\n            \"k_B\": 1.380649e-23,\n            \"midpoints\": np.array([100, 200, 300, 400, 500, 600, 700], dtype=float),\n            \"counts\": np.array([20, 80, 200, 400, 220, 70, 10], dtype=float),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        m = case[\"m\"]\n        k_B = case[\"k_B\"]\n        vj = case[\"midpoints\"]\n        cj = case[\"counts\"]\n\n        # Step 1: Compute the total number of particles, N.\n        # N = sum(c_j)\n        N = np.sum(cj)\n        \n        # Guard against division by zero if all counts are zero.\n        if N == 0:\n            T_hat = np.nan\n            sigma_T_hat = np.nan\n        else:\n            # Step 2: Compute the sum of squared speeds weighted by counts, S.\n            # S = sum(c_j * v_j^2)\n            S = np.sum(cj * vj**2)\n\n            # Step 3: Calculate the estimated temperature T_hat using the MLE formula.\n            # T_hat = (m * S) / (3 * N * k_B)\n            T_hat = (m * S) / (3.0 * N * k_B)\n\n            # Step 4: Calculate the standard uncertainty sigma_T_hat.\n            # sigma_T_hat = T_hat * sqrt(2 / (3 * N))\n            sigma_T_hat = T_hat * np.sqrt(2.0 / (3.0 * N))\n\n        # Format the results to three decimal places as required.\n        # The .3f format specifier handles rounding and ensures trailing zeros.\n        results.append(f\"[{T_hat:.3f},{sigma_T_hat:.3f}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The principles of statistical mechanics are not confined to isotropic gases and can be generalized to describe more complex phenomena in solids. This final practice extends the Maxwell-Boltzmann framework to the case of quasiparticles in an anisotropic crystal, where the scalar mass is replaced by an effective mass tensor. By deriving and simulating the resulting velocity distribution, you will explore how fundamental results like the equipartition theorem hold even in anisotropic systems, while directional properties reveal the underlying crystal symmetry .",
            "id": "3435458",
            "problem": "A single non-interacting quasiparticle in a crystalline solid has kinetic energy determined by an anisotropic effective mass tensor. In computational materials science, the effective mass approximation models the quasiparticle velocity as a continuous variable, and the kinetic energy as a quadratic form determined by a symmetric positive-definite effective mass tensor. Consider a quasiparticle with velocity vector $\\mathbf{v}\\in\\mathbb{R}^3$ and a symmetric positive-definite effective mass tensor $\\mathbf{m}\\in\\mathbb{R}^{3\\times 3}$. The kinetic energy is $H_{\\mathrm{kin}}(\\mathbf{v})=\\tfrac{1}{2}\\,\\mathbf{v}^\\top \\mathbf{m}\\,\\mathbf{v}$. In thermal equilibrium at absolute temperature $T$, the canonical ensemble assigns the probability density for microstates according to the Boltzmann factor. The Boltzmann constant is $k_B=1.380649\\times 10^{-23}\\,\\mathrm{J/K}$.\n\nYour tasks are:\n\n- Using the canonical ensemble and the Boltzmann factor as the fundamental base, derive the equilibrium velocity-space probability density $p(\\mathbf{v}\\,|\\,T,\\mathbf{m})$ for the quasiparticle whose energy is $H_{\\mathrm{kin}}(\\mathbf{v})=\\tfrac{1}{2}\\,\\mathbf{v}^\\top \\mathbf{m}\\,\\mathbf{v}$. Explicitly compute the normalization constant by evaluating the corresponding Gaussian integral. Do not assume isotropy. You must start from the canonical probability density $p(\\mathbf{v})\\propto\\exp(-\\beta H_{\\mathrm{kin}}(\\mathbf{v}))$ with $\\beta=1/(k_B T)$ and derive all steps needed to obtain $p(\\mathbf{v}\\,|\\,T,\\mathbf{m})$ and the partition function in velocity space $Z_{\\mathbf{v}}(T,\\mathbf{m})$.\n- From your derived $p(\\mathbf{v}\\,|\\,T,\\mathbf{m})$, obtain a closed-form expression for the covariance matrix of $\\mathbf{v}$, namely $\\mathbb{E}[\\mathbf{v}\\,\\mathbf{v}^\\top]$, expressed in terms of $k_B$, $T$, and $\\mathbf{m}$.\n- Define the directional kinetic energy along a unit vector $\\mathbf{n}\\in\\mathbb{R}^3$ as $E_{\\mathbf{n}}=\\tfrac{1}{2}\\,(\\mathbf{n}^\\top\\mathbf{m}\\,\\mathbf{n})\\,(\\mathbf{n}^\\top\\mathbf{v})^2$. Derive closed-form expressions for the mean $\\mathbb{E}[E_{\\mathbf{n}}]$ and the variance $\\mathrm{Var}(E_{\\mathbf{n}})$ in terms of $k_B$, $T$, $\\mathbf{m}$, and $\\mathbf{n}$, without assuming that $\\mathbf{n}$ is an eigenvector of $\\mathbf{m}$.\n- Derive the distribution of the total kinetic energy $E=\\tfrac{1}{2}\\,\\mathbf{v}^\\top\\mathbf{m}\\,\\mathbf{v}$ under the equilibrium $p(\\mathbf{v}\\,|\\,T,\\mathbf{m})$, and obtain $\\mathbb{E}[E]$ and $\\mathrm{Var}(E)$. Explain whether these results depend on the anisotropy of $\\mathbf{m}$.\n\nThen, design and implement a simulation that samples $\\mathbf{v}$ from the derived equilibrium distribution and estimates the sample mean of $E_{\\mathbf{n}}$ for specified $\\mathbf{m}$, $T$, and $\\mathbf{n}$. Use the following test suite of parameter values. All masses must be in kilograms, all temperatures must be in kelvins, and all energies must be in joules. When an angle is provided, it is in degrees.\n\nConstants:\n- $k_B=1.380649\\times 10^{-23}\\,\\mathrm{J/K}$.\n- Electron rest mass $m_e=9.1093837015\\times 10^{-31}\\,\\mathrm{kg}$.\n\nFor each test case below, generate $N$ independent samples from $p(\\mathbf{v}\\,|\\,T,\\mathbf{m})$, compute the sample mean of $E_{\\mathbf{n}}$, and report the absolute relative error between the sample mean and your derived theoretical mean of $E_{\\mathbf{n}}$ as a decimal (not a percentage).\n\nTest suite:\n- Case $1$: $T=300\\,\\mathrm{K}$, $\\mathbf{m}=0.5\\,m_e\\,\\mathbf{I}_{3}$, $\\mathbf{n}=(1,0,0)$, $N=100000$.\n- Case $2$: $T=300\\,\\mathrm{K}$, $\\mathbf{m}=\\mathrm{diag}(0.2,1.0,0.5)\\,m_e$, $\\mathbf{n}=(0,0,1)$, $N=120000$.\n- Case $3$: $T=300\\,\\mathrm{K}$, $\\mathbf{m}=\\mathrm{diag}(0.2,1.0,0.5)\\,m_e$, $\\mathbf{n}=(1,1,0)/\\sqrt{2}$, $N=150000$.\n- Case $4$: $T=800\\,\\mathrm{K}$, $\\mathbf{m}=\\mathbf{R}(\\theta)\\,\\mathrm{diag}(0.1,1.5,0.3)\\,m_e\\,\\mathbf{R}(\\theta)^\\top$, where $\\mathbf{R}(\\theta)$ is the rotation about the $\\hat{\\mathbf{z}}$ axis by $\\theta=45$ degrees, $\\mathbf{n}=(1,0,0)$, $N=180000$. The rotation matrix is\n$$\n\\mathbf{R}(\\theta)=\\begin{pmatrix}\n\\cos\\theta  -\\sin\\theta  0\\\\\n\\sin\\theta  \\cos\\theta  0\\\\\n0  0  1\n\\end{pmatrix}.\n$$\n- Case $5$: $T=100\\,\\mathrm{K}$, $\\mathbf{m}=\\mathrm{diag}(0.01,5.0,0.5)\\,m_e$, $\\mathbf{n}=(\\sqrt{3}/2,\\,1/2,\\,0)$, $N=150000$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3,r_4,r_5]$), where each $r_i$ is the absolute relative error for the corresponding case, formatted as a floating-point number. The final numerical outputs are unitless decimals.",
            "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information for a complete solution. It consists of a theoretical derivation part followed by a computational part that verifies a subset of the derived results. We will first perform the requested derivations and then design the simulation.\n\nThe kinetic energy of the quasiparticle is given by $H_{\\mathrm{kin}}(\\mathbf{v})=\\tfrac{1}{2}\\,\\mathbf{v}^\\top \\mathbf{m}\\,\\mathbf{v}$, where $\\mathbf{v} \\in \\mathbb{R}^3$ is the velocity and $\\mathbf{m} \\in \\mathbb{R}^{3\\times 3}$ is the symmetric positive-definite effective mass tensor. The system is in thermal equilibrium at temperature $T$. The Boltzmann constant is $k_B$. We define $\\beta = 1/(k_B T)$.\n\n### 1. Derivation of the Equilibrium Velocity-Space Probability Density $p(\\mathbf{v}\\,|\\,T,\\mathbf{m})$\n\nAccording to the canonical ensemble, the probability density for a microstate with velocity $\\mathbf{v}$ is proportional to the Boltzmann factor:\n$$\np(\\mathbf{v}) \\propto \\exp(-\\beta H_{\\mathrm{kin}}(\\mathbf{v})) = \\exp\\left(-\\frac{\\beta}{2} \\mathbf{v}^\\top \\mathbf{m} \\mathbf{v}\\right)\n$$\nThis is the kernel of a multivariate normal distribution in $\\mathbf{v}$. The general form for a $d$-dimensional multivariate normal distribution with mean $\\boldsymbol{\\mu}$ and covariance matrix $\\mathbf{\\Sigma}$ is:\n$$\nf(\\mathbf{x}) = \\frac{1}{\\sqrt{(2\\pi)^d \\det(\\mathbf{\\Sigma})}} \\exp\\left(-\\frac{1}{2} (\\mathbf{x}-\\boldsymbol{\\mu})^\\top \\mathbf{\\Sigma}^{-1} (\\mathbf{x}-\\boldsymbol{\\mu})\\right)\n$$\nIn our case, the quadratic form $\\mathbf{v}^\\top \\mathbf{m} \\mathbf{v}$ indicates the distribution is centered at $\\boldsymbol{\\mu}=\\mathbf{0}$. By comparing the exponents, we have:\n$$\n\\frac{1}{2} \\mathbf{v}^\\top \\mathbf{\\Sigma}^{-1} \\mathbf{v} = \\frac{\\beta}{2} \\mathbf{v}^\\top \\mathbf{m} \\mathbf{v}\n$$\nThis implies that the inverse of the covariance matrix is $\\mathbf{\\Sigma}^{-1} = \\beta \\mathbf{m}$. Since $\\mathbf{m}$ is positive-definite, it is invertible. The covariance matrix is therefore:\n$$\n\\mathbf{\\Sigma} = (\\beta \\mathbf{m})^{-1} = \\frac{1}{\\beta} \\mathbf{m}^{-1} = k_B T \\mathbf{m}^{-1}\n$$\nThe normalization constant is the partition function in velocity space, $Z_{\\mathbf{v}}(T,\\mathbf{m})$, obtained by integrating the unnormalized density over all possible velocities:\n$$\nZ_{\\mathbf{v}}(T,\\mathbf{m}) = \\int_{\\mathbb{R}^3} \\exp\\left(-\\frac{\\beta}{2} \\mathbf{v}^\\top \\mathbf{m} \\mathbf{v}\\right) d^3\\mathbf{v}\n$$\nThis is a standard Gaussian integral. For a general quadratic form $\\frac{1}{2}\\mathbf{x}^\\top\\mathbf{A}\\mathbf{x}$, the integral is $\\sqrt{(2\\pi)^d \\det(\\mathbf{A}^{-1})}$. Here, $d=3$ and the matrix in the quadratic form is $\\beta\\mathbf{m}$.\n$$\nZ_{\\mathbf{v}}(T,\\mathbf{m}) = \\sqrt{(2\\pi)^3 \\det((\\beta\\mathbf{m})^{-1})} = \\sqrt{(2\\pi)^3 \\det(\\beta^{-1}\\mathbf{m}^{-1})}\n$$\nUsing the determinant property $\\det(c\\mathbf{A}) = c^d \\det(\\mathbf{A})$:\n$$\nZ_{\\mathbf{v}}(T,\\mathbf{m}) = \\sqrt{(2\\pi)^3 (\\beta^{-1})^3 \\det(\\mathbf{m}^{-1})} = \\sqrt{(2\\pi)^3 (k_B T)^3 (\\det\\mathbf{m})^{-1}} = (2\\pi k_B T)^{3/2} (\\det\\mathbf{m})^{-1/2}\n$$\nThe normalized probability density function is then $p(\\mathbf{v}\\,|\\,T,\\mathbf{m}) = \\frac{1}{Z_{\\mathbf{v}}} \\exp(-\\beta H_{\\mathrm{kin}}(\\mathbf{v}))$, which is:\n$$\np(\\mathbf{v}\\,|\\,T,\\mathbf{m}) = \\frac{\\sqrt{\\det(\\mathbf{m})}}{(2\\pi k_B T)^{3/2}} \\exp\\left(-\\frac{1}{2k_B T} \\mathbf{v}^\\top \\mathbf{m} \\mathbf{v}\\right)\n$$\nThis shows that $\\mathbf{v}$ follows a 3-dimensional multivariate normal distribution, $\\mathbf{v} \\sim \\mathcal{N}(\\mathbf{0}, k_B T \\mathbf{m}^{-1})$.\n\n### 2. Derivation of the Covariance Matrix $\\mathbb{E}[\\mathbf{v}\\,\\mathbf{v}^\\top]$\n\nThe covariance matrix of a random vector $\\mathbf{v}$ with mean $\\boldsymbol{\\mu} = \\mathbb{E}[\\mathbf{v}]$ is defined as $\\mathrm{Cov}(\\mathbf{v}) = \\mathbb{E}[(\\mathbf{v}-\\boldsymbol{\\mu})(\\mathbf{v}-\\boldsymbol{\\mu})^\\top]$. From the derived distribution $p(\\mathbf{v}\\,|\\,T,\\mathbf{m})$, we see that the distribution is $\\mathcal{N}(\\mathbf{0}, k_B T \\mathbf{m}^{-1})$. The mean is $\\mathbb{E}[\\mathbf{v}]=\\mathbf{0}$. Therefore, the covariance matrix is simply:\n$$\n\\mathbb{E}[\\mathbf{v}\\,\\mathbf{v}^\\top] = \\mathrm{Cov}(\\mathbf{v}) = \\mathbf{\\Sigma} = k_B T \\mathbf{m}^{-1}\n$$\n\n### 3. Mean and Variance of Directional Kinetic Energy $E_{\\mathbf{n}}$\n\nThe directional kinetic energy is $E_{\\mathbf{n}}=\\tfrac{1}{2}\\,(\\mathbf{n}^\\top\\mathbf{m}\\,\\mathbf{n})\\,(\\mathbf{n}^\\top\\mathbf{v})^2$. The term $c_{\\mathbf{n}} = \\frac{1}{2}(\\mathbf{n}^\\top\\mathbf{m}\\,\\mathbf{n})$ is a scalar constant representing one-half the effective mass in direction $\\mathbf{n}$.\nThe mean of $E_{\\mathbf{n}}$ is:\n$$\n\\mathbb{E}[E_{\\mathbf{n}}] = \\mathbb{E}\\left[\\frac{1}{2}(\\mathbf{n}^\\top\\mathbf{m}\\,\\mathbf{n})\\,(\\mathbf{n}^\\top\\mathbf{v})^2\\right] = \\frac{1}{2}(\\mathbf{n}^\\top\\mathbf{m}\\,\\mathbf{n}) \\mathbb{E}[(\\mathbf{n}^\\top\\mathbf{v})^2]\n$$\nThe expectation term $\\mathbb{E}[(\\mathbf{n}^\\top\\mathbf{v})^2]$ can be expanded as $\\mathbb{E}[(\\mathbf{n}^\\top\\mathbf{v})(\\mathbf{v}^\\top\\mathbf{n})] = \\mathbb{E}[\\mathbf{n}^\\top(\\mathbf{v}\\mathbf{v}^\\top)\\mathbf{n}]$. Using the linearity of expectation:\n$$\n\\mathbb{E}[(\\mathbf{n}^\\top\\mathbf{v})^2] = \\mathbf{n}^\\top \\mathbb{E}[\\mathbf{v}\\mathbf{v}^\\top] \\mathbf{n} = \\mathbf{n}^\\top (k_B T \\mathbf{m}^{-1}) \\mathbf{n} = k_B T (\\mathbf{n}^\\top \\mathbf{m}^{-1} \\mathbf{n})\n$$\nSubstituting this back, we get the mean directional energy:\n$$\n\\mathbb{E}[E_{\\mathbf{n}}] = \\frac{1}{2} (\\mathbf{n}^\\top\\mathbf{m}\\,\\mathbf{n}) (k_B T (\\mathbf{n}^\\top \\mathbf{m}^{-1} \\mathbf{n})) = \\frac{1}{2} k_B T (\\mathbf{n}^\\top\\mathbf{m}\\,\\mathbf{n})(\\mathbf{n}^\\top \\mathbf{m}^{-1} \\mathbf{n})\n$$\nFor the variance, we first note that the random variable $X = \\mathbf{n}^\\top\\mathbf{v}$ is a linear combination of components of a multivariate normal vector, and is therefore itself a normal random variable. Its mean is $\\mathbb{E}[X] = \\mathbf{n}^\\top \\mathbb{E}[\\mathbf{v}] = 0$. Its variance is $\\sigma_X^2 = \\mathrm{Var}(X) = \\mathbb{E}[X^2] = k_B T (\\mathbf{n}^\\top \\mathbf{m}^{-1} \\mathbf{n})$. Thus, $X \\sim \\mathcal{N}(0, \\sigma_X^2)$.\nWe need to find $\\mathrm{Var}(E_{\\mathbf{n}}) = \\mathrm{Var}(c_{\\mathbf{n}} X^2) = c_{\\mathbf{n}}^2 \\mathrm{Var}(X^2)$.\nThe variance of a squared zero-mean normal variable is $\\mathrm{Var}(X^2) = \\mathbb{E}[X^4] - (\\mathbb{E}[X^2])^2$. For $X \\sim \\mathcal{N}(0, \\sigma_X^2)$, the moments are $\\mathbb{E}[X^2] = \\sigma_X^2$ and $\\mathbb{E}[X^4] = 3(\\sigma_X^2)^2$.\nThus, $\\mathrm{Var}(X^2) = 3(\\sigma_X^2)^2 - (\\sigma_X^2)^2 = 2(\\sigma_X^2)^2$.\nThe variance of the directional energy is:\n$$\n\\mathrm{Var}(E_{\\mathbf{n}}) = c_{\\mathbf{n}}^2 \\cdot 2(\\sigma_X^2)^2 = 2 \\left( \\frac{1}{2}(\\mathbf{n}^\\top\\mathbf{m}\\,\\mathbf{n}) \\right)^2 (k_B T (\\mathbf{n}^\\top \\mathbf{m}^{-1} \\mathbf n))^2 = \\frac{1}{2} (k_B T)^2 (\\mathbf{n}^\\top\\mathbf{m}\\,\\mathbf{n})^2 (\\mathbf{n}^\\top \\mathbf{m}^{-1} \\mathbf{n})^2\n$$\n\n### 4. Distribution, Mean, and Variance of Total Kinetic Energy $E$\n\nThe total kinetic energy is $E = H_{\\mathrm{kin}}(\\mathbf{v})=\\tfrac{1}{2}\\,\\mathbf{v}^\\top \\mathbf{m}\\,\\mathbf{v}$.\nTo find its mean, we use the trace property $\\mathbf{x}^\\top\\mathbf{A}\\mathbf{x} = \\mathrm{Tr}(\\mathbf{A}\\mathbf{x}\\mathbf{x}^\\top)$:\n$$\n\\mathbb{E}[E] = \\mathbb{E}\\left[\\frac{1}{2} \\mathbf{v}^\\top \\mathbf{m} \\mathbf{v}\\right] = \\frac{1}{2}\\mathbb{E}[\\mathrm{Tr}(\\mathbf{m}\\mathbf{v}\\mathbf{v}^\\top)] = \\frac{1}{2}\\mathrm{Tr}(\\mathbb{E}[\\mathbf{m}\\mathbf{v}\\mathbf{v}^\\top])\n$$\n$$\n\\mathbb{E}[E] = \\frac{1}{2}\\mathrm{Tr}(\\mathbf{m}\\mathbb{E}[\\mathbf{v}\\mathbf{v}^\\top]) = \\frac{1}{2}\\mathrm{Tr}(\\mathbf{m}(k_B T \\mathbf{m}^{-1})) = \\frac{1}{2} k_B T \\mathrm{Tr}(\\mathbf{m}\\mathbf{m}^{-1}) = \\frac{1}{2} k_B T \\mathrm{Tr}(\\mathbf{I}_3)\n$$\nSince $\\mathrm{Tr}(\\mathbf{I}_3) = 3$, the mean total kinetic energy is:\n$$\n\\mathbb{E}[E] = \\frac{3}{2} k_B T\n$$\nTo find the distribution of $E$, we perform a change of variables. Let $\\mathbf{m}^{1/2}$ be the unique symmetric positive-definite square root of $\\mathbf{m}$. Let $\\mathbf{u} = \\sqrt{\\beta} \\mathbf{m}^{1/2} \\mathbf{v}$. The exponent in $p(\\mathbf{v})$ becomes:\n$$\n-\\frac{\\beta}{2} \\mathbf{v}^\\top \\mathbf{m} \\mathbf{v} = -\\frac{1}{2} (\\sqrt{\\beta}\\mathbf{m}^{1/2}\\mathbf{v})^\\top (\\sqrt{\\beta}\\mathbf{m}^{1/2}\\mathbf{v}) = -\\frac{1}{2} \\mathbf{u}^\\top\\mathbf{u} = -\\frac{1}{2} \\sum_{i=1}^3 u_i^2\n$$\nThe Jacobian of the transformation $\\mathbf{u} \\to \\mathbf{v}$ is $| \\det((\\sqrt{\\beta}\\mathbf{m}^{1/2})^{-1}) | = (\\beta)^{-3/2} (\\det \\mathbf{m})^{-1/2}$. The probability density for $\\mathbf{u}$ is $p(\\mathbf{u}) = p(\\mathbf{v}(\\mathbf{u})) |J|$, which simplifies to $p(\\mathbf{u}) = (2\\pi)^{-3/2} \\exp(-\\frac{1}{2}\\mathbf{u}^\\top\\mathbf{u})$. This shows that the components $u_1, u_2, u_3$ are independent standard normal random variables, $u_i \\sim \\mathcal{N}(0, 1)$.\nThe total energy $E$ can be expressed in terms of $\\mathbf{u}$:\n$$\nE = \\frac{1}{2\\beta} (\\mathbf{u}^\\top \\mathbf{u}) = \\frac{1}{2} k_B T (u_1^2 + u_2^2 + u_3^2)\n$$\nThe sum of squares of $d$ independent standard normal variables follows a chi-squared distribution with $d$ degrees of freedom, $\\chi_d^2$. Here, $\\sum u_i^2 \\sim \\chi_3^2$. The distribution of $E$ is that of a constant $\\frac{1}{2}k_B T$ multiplied by a $\\chi_3^2$ random variable. The probability density function for $E$ is a gamma distribution, specifically:\n$$\np(E) = \\frac{2\\sqrt{E}}{\\sqrt{\\pi}(k_B T)^{3/2}} \\exp\\left(-\\frac{E}{k_B T}\\right) \\quad \\text{for } E \\ge 0\n$$\nThe variance of $E$ is:\n$$\n\\mathrm{Var}(E) = \\mathrm{Var}\\left(\\frac{1}{2} k_B T \\chi_3^2\\right) = \\left(\\frac{1}{2} k_B T\\right)^2 \\mathrm{Var}(\\chi_3^2)\n$$\nThe variance of a $\\chi_d^2$ distribution is $2d$. For $d=3$, $\\mathrm{Var}(\\chi_3^2) = 6$.\n$$\n\\mathrm{Var}(E) = \\frac{1}{4}(k_B T)^2 \\cdot 6 = \\frac{3}{2}(k_B T)^2\n$$\nBoth the mean $\\mathbb{E}[E]$ and variance $\\mathrm{Var}(E)$, as well as the entire distribution of $E$, depend only on the temperature $T$ and the dimensionality of the space ($d=3$). They are independent of the specific form (anisotropy) of the effective mass tensor $\\mathbf{m}$.\n\n### Simulation Design\n\nThe simulation will estimate $\\mathbb{E}[E_{\\mathbf{n}}]$ by averaging over a large number of samples and compare this to the theoretical value.\n1.  **Generate Samples**: Sample the velocity vector $\\mathbf{v}$ from its distribution $\\mathcal{N}(\\mathbf{0}, \\mathbf{\\Sigma})$ where $\\mathbf{\\Sigma} = k_B T \\mathbf{m}^{-1}$.\n    - Generate a vector $\\mathbf{z}$ of 3 independent standard normal random variables.\n    - Compute the Cholesky decomposition of the covariance matrix: $\\mathbf{\\Sigma} = \\mathbf{L}\\mathbf{L}^\\top$.\n    - A sample of $\\mathbf{v}$ is obtained by the linear transformation $\\mathbf{v} = \\mathbf{L}\\mathbf{z}$.\n2.  **Calculate Sample Mean**: For each sample $\\mathbf{v}_i$, compute $E_{\\mathbf{n},i} = \\frac{1}{2}(\\mathbf{n}^\\top\\mathbf{m}\\,\\mathbf{n})\\,(\\mathbf{n}^\\top\\mathbf{v}_i)^2$. The sample mean is $\\bar{E}_{\\mathbf{n}} = \\frac{1}{N}\\sum_{i=1}^N E_{\\mathbf{n},i}$.\n3.  **Compute Error**: Calculate the absolute relative error $|\\bar{E}_{\\mathbf{n}} - \\mathbb{E}[E_{\\mathbf{n}}]| / |\\mathbb{E}[E_{\\mathbf{n}}]|$, where $\\mathbb{E}[E_{\\mathbf{n}}]$ is the closed-form expression derived above.\nThis procedure will be implemented for each test case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the absolute relative error between the theoretical mean and\n    the sample mean of the directional kinetic energy for a quasiparticle.\n    \"\"\"\n    # Define constants\n    K_B = 1.380649e-23  # J/K\n    M_E = 9.1093837015e-31  # kg\n\n    # Define the rotation matrix function\n    def get_rotation_matrix(theta_deg):\n        theta_rad = np.deg2rad(theta_deg)\n        c, s = np.cos(theta_rad), np.sin(theta_rad)\n        return np.array([[c, -s, 0], [s, c, 0], [0, 0, 1]])\n\n    # Test suite of parameters\n    test_cases = [\n        {\n            \"T\": 300.0,\n            \"m\": 0.5 * M_E * np.identity(3),\n            \"n\": np.array([1.0, 0.0, 0.0]),\n            \"N\": 100000,\n        },\n        {\n            \"T\": 300.0,\n            \"m\": np.diag([0.2, 1.0, 0.5]) * M_E,\n            \"n\": np.array([0.0, 0.0, 1.0]),\n            \"N\": 120000,\n        },\n        {\n            \"T\": 300.0,\n            \"m\": np.diag([0.2, 1.0, 0.5]) * M_E,\n            \"n\": np.array([1.0, 1.0, 0.0]) / np.sqrt(2.0),\n            \"N\": 150000,\n        },\n        {\n            \"T\": 800.0,\n            \"m\": get_rotation_matrix(45) @ np.diag([0.1, 1.5, 0.3]) @ get_rotation_matrix(45).T * M_E,\n            \"n\": np.array([1.0, 0.0, 0.0]),\n            \"N\": 180000,\n        },\n        {\n            \"T\": 100.0,\n            \"m\": np.diag([0.01, 5.0, 0.5]) * M_E,\n            \"n\": np.array([np.sqrt(3.0) / 2.0, 1.0 / 2.0, 0.0]),\n            \"N\": 150000,\n        },\n    ]\n\n    results = []\n    # Use a fixed seed for reproducibility.\n    rng = np.random.default_rng(seed=42)\n\n    for case in test_cases:\n        T = case[\"T\"]\n        m = case[\"m\"]\n        n = case[\"n\"]\n        N = case[\"N\"]\n\n        # 1. Calculate theoretical mean of directional kinetic energy\n        m_inv = np.linalg.inv(m)\n        term_m = n.T @ m @ n\n        term_m_inv = n.T @ m_inv @ n\n        E_n_mean_theory = 0.5 * K_B * T * term_m * term_m_inv\n\n        # 2. Set up the sampling procedure\n        # Covariance matrix of velocity: Sigma = k_B * T * m^-1\n        Sigma = K_B * T * m_inv\n        \n        # Cholesky decomposition: Sigma = L * L.T\n        # We sample v = L @ z, where z ~ N(0, I)\n        # Using numpy, if Z is (N,3) with z_i in rows, then V = Z @ L.T\n        try:\n            L = np.linalg.cholesky(Sigma)\n        except np.linalg.LinAlgError:\n            # Fallback for matrices that might have precision issues\n            # For a symmetric matrix, eigendecomposition Sigma = Q*D*Q.T\n            # L can be Q*sqrt(D)\n            eigvals, eigvecs = np.linalg.eigh(Sigma)\n            if np.any(eigvals  0): # Should not happen for SPD matrices\n                raise ValueError(\"Covariance matrix is not positive semi-definite.\")\n            L = eigvecs @ np.diag(np.sqrt(eigvals))\n\n        # 3. Generate N samples of v\n        # Z contains N samples of 3D standard normal vectors (row-wise)\n        Z = rng.standard_normal(size=(N, 3))\n        # Transform to samples from N(0, Sigma)\n        # v_row^T = z_row^T @ L^T, so V = Z @ L.T\n        V = Z @ L.T\n\n        # 4. Calculate sample mean of directional kinetic energy\n        # Directional effective mass scalar\n        m_n_eff = term_m\n        \n        # Velocity component along n for all samples\n        v_n = V @ n  # (N, 3) @ (3,) -> (N,)\n        \n        # Directional kinetic energy for each sample\n        E_n_samples = 0.5 * m_n_eff * v_n**2\n        \n        # Sample mean\n        E_n_mean_sample = np.mean(E_n_samples)\n\n        # 5. Compute absolute relative error\n        # Avoid division by zero if theoretical mean is zero, although not expected here.\n        if E_n_mean_theory == 0:\n            error = np.abs(E_n_mean_sample)\n        else:\n            error = np.abs(E_n_mean_sample - E_n_mean_theory) / np.abs(E_n_mean_theory)\n        \n        results.append(error)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}