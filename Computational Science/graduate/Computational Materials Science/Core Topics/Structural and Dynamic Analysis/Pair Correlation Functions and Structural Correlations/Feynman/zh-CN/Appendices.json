{
    "hands_on_practices": [
        {
            "introduction": "对相关函数 $g(r)$ 是描述材料结构的基石，但它仅提供了一维的径向分布信息。对于像硅这样具有强方向性共价键的材料，仅依赖于距离的各向同性对势模型，即使能很好地匹配 $g(r)$ 的第一峰，也往往无法正确预测其能量和稳定性。这个实践将通过一个思想实验，清晰地揭示为何必须引入对角度敏感的三体相互作用项（如Stillinger-Weber势中的角项），才能在能量上稳定开放的四面体网络结构，而不是错误地偏向于高配位的密堆积结构。",
            "id": "3472556",
            "problem": "您需要设计并实现一个完整的、可运行的程序，该程序使用基本原理和标准定义，定量地证明，仅通过纯粹的二体势来匹配对关联函数 $g(r)$ 不足以稳定单质硅中的四面体网络，而一个显式的、Stillinger–Weber (SW) 类型的角度（三体）项是必要的。您的程序必须基于以下基本原理和定义。\n\n定义和基本原理：\n- 对于一个体积为 $V$、包含 $N$ 个粒子、数密度为 $\\rho = N/V$ 的系统，其对关联函数 $g(r)$ 定义为对间距的壳层归一化平均值，\n$$\ng(r) = \\frac{1}{4\\pi r^2 \\rho} \\frac{1}{N} \\left\\langle \\sum_{i \\neq j} \\delta(r - r_{ij}) \\right\\rangle,\n$$\n其中 $r_{ij}$ 是粒子 $i$ 和 $j$ 之间的标量距离，尖括号表示系综平均。在有限周期性盒子内的离散计算中，$g(r)$ 可以通过将最小镜像约定下的所有对间距集合分箱到厚度为 $\\Delta r$ 的球壳中，并通过 $4\\pi r^2 \\Delta r \\rho N$ 对每个箱的计数进行归一化来估算。\n- 一个结合了二体项和三体项的对相加能量模型 $U$ 为\n$$\nU = \\sum_{i",
            "solution": "该问题要求定量地证明一个简单的二体势，即使通过对关联函数 $g(r)$ 匹配了正确的键长，也不足以稳定单质硅的开放式四面体网络结构。它假设一个对键角敏感的显式三体项是必要的。这个证明是计算材料科学中的一个基本概念，阐释了径向对称势在描述共价键方面的局限性。\n\n**1. 科学原理与势能模型**\n\n一个原子系统的总势能 $U$ 被建模为二体和三体相互作用的总和：\n$$\nU = U_2 + U_3 = \\sum_{i",
            "answer": "```python\nimport numpy as np\n\ndef generate_fcc_supercell(a, sc_dims):\n    \"\"\"Generates an FCC supercell.\"\"\"\n    basis = np.array([[0, 0, 0], [0.5, 0.5, 0], [0.5, 0, 0.5], [0, 0.5, 0.5]]) * a\n    atoms = []\n    for i in range(sc_dims[0]):\n        for j in range(sc_dims[1]):\n            for k in range(sc_dims[2]):\n                shift = np.array([i, j, k]) * a\n                atoms.extend(basis + shift)\n    return np.array(atoms)\n\ndef generate_dc_supercell(a, sc_dims):\n    \"\"\"Generates a diamond cubic supercell.\"\"\"\n    fcc_basis = np.array([[0, 0, 0], [0.5, 0.5, 0], [0.5, 0, 0.5], [0, 0.5, 0.5]])\n    dc_basis = np.vstack([fcc_basis, fcc_basis + 0.25]) * a\n    atoms = []\n    for i in range(sc_dims[0]):\n        for j in range(sc_dims[1]):\n            for k in range(sc_dims[2]):\n                shift = np.array([i, j, k]) * a\n                atoms.extend(dc_basis + shift)\n    return np.array(atoms)\n\ndef mic_vector(vec, box_dims):\n    \"\"\"Applies the minimum image convention to a vector.\"\"\"\n    return vec - box_dims * np.round(vec / box_dims)\n\ndef get_neighbors_and_distances(atoms, box_dims, cutoff):\n    \"\"\"Finds neighbors and distances for all atoms within a cutoff.\"\"\"\n    N = len(atoms)\n    neighbors = [[] for _ in range(N)]\n    distances = [[] for _ in range(N)]\n    all_rij = []\n    \n    for i in range(N):\n        for j in range(i + 1, N):\n            vec = mic_vector(atoms[i] - atoms[j], box_dims)\n            dist = np.linalg.norm(vec)\n            all_rij.append(dist)\n            if dist = cutoff:\n                neighbors[i].append(j)\n                neighbors[j].append(i)\n                distances[i].append(dist)\n                distances[j].append(dist)\n                \n    return neighbors, distances, all_rij\n\ndef calculate_energies(atoms, box_dims, r_c, r0, eps, lam, gam):\n    \"\"\"Calculates two-body and three-body energies.\"\"\"\n    N = len(atoms)\n    u2_total = 0.0\n    u3_total = 0.0\n\n    # Neighbor finding\n    neighbors_map = [[] for _ in range(N)]\n    for i in range(N):\n        for j in range(i + 1, N):\n            vec_ij = mic_vector(atoms[j] - atoms[i], box_dims)\n            r_ij = np.linalg.norm(vec_ij)\n            if r_ij = r_c:\n                u2_total += eps * ((r0 / r_ij)**12 - 2 * (r0 / r_ij)**6)\n                neighbors_map[i].append(j)\n                neighbors_map[j].append(i)\n\n    # Three-body energy\n    if lam > 0:\n        for i in range(N):\n            neighbors_of_i = neighbors_map[i]\n            if len(neighbors_of_i)  2:\n                continue\n            for idx_j, j in enumerate(neighbors_of_i):\n                for k in neighbors_of_i[idx_j + 1:]:\n                    vec_ij = mic_vector(atoms[j] - atoms[i], box_dims)\n                    vec_ik = mic_vector(atoms[k] - atoms[i], box_dims)\n                    r_ij = np.linalg.norm(vec_ij)\n                    r_ik = np.linalg.norm(vec_ik)\n                    \n                    cos_theta = np.dot(vec_ij, vec_ik) / (r_ij * r_ik)\n                    \n                    exp_term = np.exp(-gam * (r_ij - r0)**2) * np.exp(-gam * (r_ik - r0)**2)\n                    angle_term = (cos_theta + 1/3)**2\n                    \n                    u3_total += lam * exp_term * angle_term\n\n    return u2_total / N, u3_total / N\n\ndef calculate_g_r(atoms, box_dims, max_r, dr, r0):\n    \"\"\"Calculates g(r) and finds the first peak.\"\"\"\n    N = len(atoms)\n    V = box_dims[0]**3\n    rho = N / V\n    \n    bins = np.arange(0, max_r + dr, dr)\n    hist = np.zeros(len(bins) - 1)\n    \n    for i in range(N):\n        for j in range(i + 1, N):\n            r_ij = np.linalg.norm(mic_vector(atoms[j] - atoms[i], box_dims))\n            if r_ij  max_r:\n                bin_idx = int(r_ij / dr)\n                hist[bin_idx] += 2\n\n    r_vals = bins[:-1] + dr / 2\n    shell_volumes = 4 * np.pi * r_vals**2 * dr\n    \n    # Avoid division by zero at r=0\n    non_zero_vols = shell_volumes > 1e-9\n    g_r = np.zeros_like(r_vals)\n    g_r[non_zero_vols] = hist[non_zero_vols] / (shell_volumes[non_zero_vols] * rho * N)\n    \n    # Find peak in specified range\n    peak_range_mask = (r_vals >= 0.8 * r0)  (r_vals = 1.2 * r0)\n    if not np.any(peak_range_mask): return r0 # Failsafe\n    \n    peak_idx = np.argmax(g_r[peak_range_mask])\n    r_peak = r_vals[peak_range_mask][peak_idx]\n\n    return r_peak\n\ndef calculate_q_avg(atoms, box_dims):\n    \"\"\"Calculates the average tetrahedral order parameter"
        },
        {
            "introduction": "静态结构因子 $S(q)$ 是 $g(r)$ 的傅里叶变换，它在倒易空间中提供了更丰富的结构信息，并能与衍射实验直接对比。然而，从数值计算得到的 $g(r)$（其数据总是在有限距离 $r_{\\text{max}}$ 处被截断）计算 $S(q)$ 时，会引入被称为“截断效应”的严重数值伪影。本练习旨在量化这些截断误差，并演示如何通过应用窗函数（如Lorch函数）和平滑外推等标准技术，来显著减轻这些伪影，从而获得更准确的 $S(q)$，尤其是在与材料宏观热力学性质相关的长波极限 $q \\to 0$ 处。",
            "id": "3472561",
            "problem": "构建一个程序，量化有限径向截断和截断修正如何通过一维球面傅里叶变换，影响从径向对关联函数 $g(r)$ 计算静态结构因子 $S(q)$。您的程序将生成合成的、各向同性的三维 $g(r)$ 数据，该数据通过可压缩性方程具有解析可控的长波长极限 $S(0)$。然后，对于几种测试场景，它将使用不同的窗函数和小 $q$ 值外推策略，从截断的 $g(r)$ 计算 $S(q)$，并报告恢复的 $S(0)$ 的准确性。\n\n使用的基本定义和关系：\n- 对关联函数为 $g(r)$，总关联函数为 $h(r)=g(r)-1$。\n- 对于三维的各向同性、均匀系统，静态结构因子 $S(q)$ 和 $h(r)$ 的关系如下\n$$\nS(q)=1+\\rho \\int_{\\mathbb{R}^3} h(\\mathbf{r}) e^{i\\mathbf{q}\\cdot\\mathbf{r}}\\,d^3r \\;=\\; 1+ \\rho\\,4\\pi \\int_0^{\\infty} r^2 h(r)\\,\\frac{\\sin(qr)}{qr}\\,dr,\n$$\n其中 $\\rho$ 是数密度，$q=\\|\\mathbf{q}\\|$。\n- 可压缩性方程将静态结构因子的零波数极限与等温可压缩性联系起来：\n$$\nS(0)=\\rho\\,k_B T\\,\\kappa_T,\n$$\n其中 $k_B$ 是玻尔兹曼常数，$T$ 是绝对温度，$\\kappa_T$ 是等温可压缩性。\n\n$g(r)$ 的合成模型规范：\n- 使用高斯总关联函数 $h(r)=A\\exp\\!\\left(-\\frac{r^2}{2\\sigma^2}\\right)$，因此 $g(r)=1+h(r)$。\n- 此选择会得到一个解析结构因子，形式为\n$$\nS(q)=1+(S(0)-1)\\,\\exp\\!\\left(-\\frac{\\sigma^2 q^2}{2}\\right),\n$$\n这可由高斯函数的三维傅里叶变换和可压缩性方程推导得出。\n- 通过选择 $A$ 来匹配目标 $S(0)=\\rho\\,k_B T\\,\\kappa_T$，以强制满足可压缩性方程。使用球面积分，从下式确定 $A$\n$$\nS(0)=1+\\rho\\,4\\pi\\int_0^{\\infty} r^2 A\\exp\\!\\left(-\\frac{r^2}{2\\sigma^2}\\right)\\,dr\n=1+\\rho\\,A\\,4\\pi\\,\\sigma^3\\,\\sqrt{\\frac{\\pi}{2}},\n$$\n所以\n$$\nA=\\frac{S(0)-1}{\\rho\\,4\\pi\\,\\sigma^3\\,\\sqrt{\\frac{\\pi}{2}}}.\n$$\n\n带截断和加窗的数值变换：\n- 在实践中，径向积分在有限的 $r_{\\max}$ 处被截断，并在箱中心 $r_i=i\\,\\Delta r$（其中 $i=1,2,\\dots,N$，$N=\\lfloor r_{\\max}/\\Delta r \\rfloor$）处以箱宽 $\\Delta r$ 进行离散化。\n- 计算离散近似\n$$\nS(q)\\approx 1+\\rho\\,4\\pi\\,\\sum_{i=1}^{N} r_i^2\\,h(r_i)\\,w(r_i)\\,\\frac{\\sin(q r_i)}{q r_i}\\,\\Delta r,\n$$\n其中 $w(r)$ 是一个窗函数，用于减轻接近 $r_{\\max}$ 时的截断伪影。\n- 实现以下窗函数：\n  1. 无窗函数：$w(r)=1$。\n  2. Lorch 窗函数：$w(r)=\\frac{\\sin\\!\\left(\\pi r/r_{\\max}\\right)}{\\pi r/r_{\\max}}$。\n  3. Hann 窗函数：$w(r)=\\frac{1}{2}\\left(1-\\cos\\!\\left(2\\pi r/r_{\\max}\\right)\\right)$，对于 $0\\le r\\le r_{\\max}$。\n- 对于每个场景，在一组小的 $q$ 值上计算 $S(q)$，并使用两种外推策略估计 $S(0)$：\n  1. 最小-$q$ 值策略：取 $S(q_{\\min})$ 作为 $S(0)$ 的估计值，其中 $q_{\\min}$ 是您网格中的最小正波数。\n  2. $q^2$ 的二次策略：使用线性模型 $S(q)\\approx a+b\\,q^2$ 在前几个小的 $q$ 值上拟合 $S(q)$ 与 $q^2$ 的关系，并取截距 $a$ 作为 $S(0)$ 的估计值。\n\n程序任务和规范：\n- 所有量均使用无量纲单位。您报告的任何量都不能带有物理单位。\n- 固定参数 $\\rho=0.85$，$k_B T=1.0$，目标 $S(0)=0.20$ 和 $\\sigma=2.0$。从可压缩性方程计算 $\\kappa_T$，然后从上述表达式计算 $A$，以确保合成的 $g(r)$ 满足 $S(0)=\\rho\\,k_B T\\,\\kappa_T$。\n- 构建一个 $q$ 网格，包含从 $q_{\\min}=0.01$ 到 $q_{\\max}=0.5$（均为无量纲）的 $M=60$ 个线性间隔点。对于二次外推，使用此网格中的前 $K=12$ 个值进行拟合。\n- 对于下面的每个测试用例，计算离散加窗的 $S(q)$，使用指定的策略估计 $S(0)$，然后计算相对于目标 $S(0)=0.20$ 的绝对误差 $|S_{\\text{est}}(0)-S(0)|$。\n\n测试套件：\n- 每个测试用例是一个元组 $(r_{\\max},\\Delta r,\\text{window},\\text{strategy})$。使用以下六种情况：\n  1. $(20.0,0.02,\\text{none},\\text{min\\_q})$。\n  2. $(8.0,0.02,\\text{none},\\text{min\\_q})$。\n  3. $(8.0,0.02,\\text{lorch},\\text{min\\_q})$。\n  4. $(8.0,0.02,\\text{hann},\\text{min\\_q})$。\n  5. $(8.0,0.10,\\text{lorch},\\text{quadratic})$。\n  6. $(20.0,0.02,\\text{lorch},\\text{quadratic})$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含六个绝对误差，按测试套件的顺序排列，格式为逗号分隔的列表，小数点后保留六位数字，并用方括号括起来。例如，输出必须具有以下形式\n$$\n[\\epsilon_1,\\epsilon_2,\\epsilon_3,\\epsilon_4,\\epsilon_5,\\epsilon_6],\n$$\n其中每个 $\\epsilon_i$ 是一个小数点后有六位数字的十进制浮点数。",
            "solution": "用户提供的问题陈述已经过分析，并被认为是有效的。它在科学上是合理的、适定的、客观的，并包含了进行求解所需的所有必要信息。\n\n目标是量化在从截断的对关联函数 $g(r)$ 计算静态结构因子 $S(q)$ 时产生的数值误差，特别关注长波长极限 $S(0)$ 的准确性。这将通过创建一个具有已知解析 $S(q)$ 的合成 $g(r)$，然后将此基准真值与在各种截断和处理场景下数值傅里叶变换的结果进行比较来完成。\n\n该问题的理论基础在于液体和非晶态固体的统计力学。这种系统的结构由对关联函数 $g(r)$ 表征，它与在距离参考粒子 $r$ 处找到另一个粒子的概率成正比。总关联函数 $h(r) = g(r) - 1$ 描述了系统与完全不相关（理想气体）系统的偏差。静态结构因子 $S(q)$ 是粒子密度关联的空间傅里叶变换，可通过散射实验获得。对于数密度为 $\\rho$ 的均匀、各向同性系统，在三维空间中 $S(q)$ 和 $h(r)$ 之间的关系由球面傅里叶变换给出：\n$$S(q) = 1 + \\rho\\,4\\pi \\int_0^{\\infty} r^2 h(r) \\frac{\\sin(qr)}{qr} dr$$\n其中 $q$ 是波矢的模。\n\n一个关键的热力学联系是可压缩性求和规则，它将结构因子的 $q \\to 0$ 极限与系统的等温可压缩性 $\\kappa_T$ 联系起来：\n$$S(0) = \\rho k_B T \\kappa_T$$\n其中 $k_B$ 是玻尔兹曼常数，$T$ 是温度。这个方程为任何物理上真实的 $g(r)$ 及其对应的 $S(q)$ 提供了严格的约束。\n\n为了给我们的数值方法创建一个测试平台，我们定义了一个具有简单解析傅里叶变换的合成总关联函数：一个高斯函数，$h(r) = A \\exp\\left(-\\frac{r^2}{2\\sigma^2}\\right)$。参数 $A$ 不是任意的；必须设置它以确保模型对于选定的目标 $S(0)$ 值符合可压缩性方程。通过在 $q=0$ 处计算 $S(q)$ 积分（此时 $\\sin(qr)/(qr) \\to 1$），我们找到以下关系：\n$$S(0) = 1 + \\rho\\,4\\pi \\int_0^{\\infty} r^2 A \\exp\\left(-\\frac{r^2}{2\\sigma^2}\\right) dr = 1 + \\rho A (2\\pi\\sigma^2)^{3/2}$$\n解出振幅 $A$ 得：\n$$A = \\frac{S(0)-1}{\\rho (2\\pi\\sigma^2)^{3/2}} = \\frac{S(0)-1}{\\rho\\,4\\pi\\sigma^3\\sqrt{\\frac{\\pi}{2}}}$$\n使用固定参数 $\\rho=0.85$、目标 $S(0)=0.20$ 和 $\\sigma=2.0$，我们可以为我们的模型系统计算所需的 $A$ 值。该模型的解析结构因子在 $q$ 空间中也是一个高斯函数：\n$$S(q)_{\\text{analytic}} = 1 + (S(0)-1)\\exp\\left(-\\frac{\\sigma^2 q^2}{2}\\right)$$\n这为我们衡量数值估计的准确性提供了基准真值。\n\n问题的核心在于傅里叶积分的数值计算，该计算总是基于仅在有限截断半径 $r_{\\max}$ 内可用且在离散点上采样的数据。因此，积分被近似为一个和：\n$$S(q)_{\\text{numeric}} \\approx 1 + \\rho\\,4\\pi \\sum_{i=1}^{N} r_i^2 h(r_i) w(r_i) \\frac{\\sin(qr_i)}{qr_i} \\Delta r$$\n其中径向网格为 $r_i = i\\,\\Delta r$，对于 $i=1, 2, \\dots, N$，且 $N = \\lfloor r_{\\max}/\\Delta r \\rfloor$。在 $r_{\\max}$ 处对积分的急剧截断会在计算出的 $S(q)$ 中引入虚假的振荡（吉布斯现象）。为减轻此影响，应用一个窗函数 $w(r)$，使被积函数在 $r \\to r_{\\max}$ 时平滑地衰减至零。我们将研究 $w(r)$ 的三种情况：\n1.  **无窗函数**：$w(r)=1$。这代表了具有最大截断误差的基线情况。\n2.  **Lorch 窗函数**：$w(r)=\\frac{\\sin(\\pi r/r_{\\max})}{\\pi r/r_{\\max}}$。这是一个类似 sinc 的函数，在 $r=r_{\\max}$ 时变为零。\n3.  **Hann 窗函数**：$w(r)=\\frac{1}{2}\\left(1-\\cos(2\\pi r/r_{\\max})\\right)$。这个基于余弦的窗函数也确保了在 $r=r_{\\max}$ 处平滑衰减至零。\n\n最后，我们必须根据在小的、非零的 $q$ 值下数值计算出的 $S(q)$ 值来估计 $S(0)$。指定了两种策略：\n1.  **最小-$q$ 值策略**：一个直接但可能不准确的估计，$S_{\\text{est}}(0) \\approx S(q_{\\min})$，其中 $q_{\\min}$ 是计算的最小正波数。\n2.  **$q^2$ 的二次策略**：一种基于 $S(q)$ 在 $q=0$ 附近解析行为的更稳健的方法。对于任何各向同性系统，$S(q)$ 必须是 $q$ 的偶函数，因此其在 $q=0$ 附近的泰勒展开仅包含偶次幂：$S(q) = S(0) + c_2 q^2 + c_4 q^4 + \\dots$。对于小 $q$，这可以很好地用 $S(q)$ 和 $q^2$ 之间的线性关系来近似。我们可以用模型 $S(q) \\approx a+b\\,q^2$ 对前 $K=12$ 个小 $q$ 点的计算值进行拟合。截距 $a$ 为 $S(0)$ 提供了一个更稳定的估计。\n\n算法流程如下：\n1.  定义所有物理和数值常数：$\\rho$、$S(0)_{\\text{target}}$、$\\sigma$，以及 $q$-网格（$q_{\\min}, q_{\\max}, M$）和二次拟合（$K$）的参数。\n2.  计算模型振幅 $A$ 以满足可压缩性求和规则。\n3.  为总关联函数 $h(r)$ 和三种窗函数实现函数。\n4.  对于六个测试用例中的每一个（$\\{r_{\\max}, \\Delta r, \\text{window}, \\text{strategy}\\}$）：\n    a. 构建离散的径向网格 $r_i$。\n    b. 使用数值求和公式，在指定的 $q$-网格上计算 $S(q)$，并应用适当的窗函数。对于 $x \\to 0$ 的情况，$\\sin(x)/x$ 项需要被谨慎处理。\n    c. 将指定的外推策略（`min_q` 或 `quadratic`）应用于计算出的 $S(q)$ 值，以获得估计值 $S_{\\text{est}}(0)$。对于二次策略，这涉及到使用 `numpy.polyfit` 对 $S(q)$ 与 $q^2$ 进行线性最小二乘拟合。\n    d. 计算绝对误差 $|S_{\\text{est}}(0) - S(0)_{\\text{target}}|$。\n5.  收集六个误差值，并将它们格式化为所需的单行输出字符串。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the error in the static structure factor S(0) estimation\n    from a truncated pair correlation function g(r) for several test scenarios.\n    \"\"\"\n    # Define fixed physical and numerical parameters in dimensionless units.\n    RHO = 0.85\n    KBT = 1.0  # k_B * T\n    S0_TARGET = 0.20\n    SIGMA = 2.0\n    M_Q_POINTS = 60\n    Q_MIN = 0.01\n    Q_MAX = 0.5\n    K_FIT_POINTS = 12\n\n    # Calculate the amplitude A for the synthetic h(r) to ensure it satisfies\n    # the compressibility equation for the target S(0).\n    A_H = (S0_TARGET - 1) / (RHO * 4 * np.pi * SIGMA**3 * np.sqrt(np.pi / 2))\n\n    # --- Helper Functions ---\n\n    def h_func(r):\n        \"\"\"Synthetic total correlation function h(r) = A*exp(-r^2 / (2*sigma^2)).\"\"\"\n        return A_H * np.exp(-r**2 / (2 * SIGMA**2))\n\n    def sinc_func(x):\n        \"\"\"Custom implementation of sinc(x) = sin(x)/x, handling x=0.\"\"\"\n        # Note: np.sinc(y) evaluates sin(pi*y)/(pi*y). We use our own for clarity.\n        # The 'out' and 'where' arguments handle the limit at x=0, which is 1.\n        return np.divide(np.sin(x), x, out=np.ones_like(x, dtype=float), where=x != 0)\n\n    # Define the window functions.\n    def w_none(r, r_max):\n        \"\"\"No window function (equivalent to a rectangular window).\"\"\"\n        return 1.0\n\n    def w_lorch(r, r_max):\n        \"\"\"Lorch window function.\"\"\"\n        arg = np.pi * r / r_max\n        return sinc_func(arg)\n\n    def w_hann(r, r_max):\n        \"\"\"Hann window function.\"\"\"\n        return 0.5 * (1 - np.cos(2 * np.pi * r / r_max))\n    \n    # Map window names to functions for easy access.\n    window_map = {\n        'none': w_none,\n        'lorch': w_lorch,\n        'hann': w_hann\n    }\n\n    def compute_s_q(r_max, delta_r, window_func, q_grid):\n        \"\"\"\n        Numerically computes S(q) from h(r) for a given set of q values.\n        \"\"\"\n        N = int(r_max / delta_r)  # N = floor(r_max / delta_r)\n        r_grid = np.arange(1, N + 1) * delta_r\n        \n        h_vals = h_func(r_grid)\n        w_vals = window_func(r_grid, r_max)\n        \n        prefactor = RHO * 4 * np.pi * delta_r\n        # Pre-calculate the part of the integrand that doesn't depend on q.\n        integrand_base = r_grid**2 * h_vals * w_vals\n        \n        s_q_vals = []\n        for q in q_grid:\n            sinc_vals = sinc_func(q * r_grid)\n            integral = np.sum(integrand_base * sinc_vals)\n            s_q = 1.0 + prefactor * integral\n            s_q_vals.append(s_q)\n            \n        return np.array(s_q_vals)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (20.0, 0.02, 'none', 'min_q'),\n        (8.0, 0.02, 'none', 'min_q'),\n        (8.0, 0.02, 'lorch', 'min_q'),\n        (8.0, 0.02, 'hann', 'min_q'),\n        (8.0, 0.10, 'lorch', 'quadratic'),\n        (20.0, 0.02, 'lorch', 'quadratic'),\n    ]\n\n    # Construct the wavenumber grid.\n    q_grid = np.linspace(Q_MIN, Q_MAX, M_Q_POINTS)\n    \n    results = []\n    # --- Main Loop: Iterate through test cases ---\n    for r_max, delta_r, window_name, strategy in test_cases:\n        \n        # Select the appropriate window function.\n        window_function = window_map[window_name]\n        \n        # Compute S(q) numerically for the current case.\n        s_q = compute_s_q(r_max, delta_r, window_function, q_grid)\n        \n        s0_est = 0.0\n        # Apply the specified extrapolation strategy to estimate S(0).\n        if strategy == 'min_q':\n            s0_est = s_q[0]  # S(q_min)\n        elif strategy == 'quadratic':\n            # Use the first K points for the fit.\n            q_fit = q_grid[:K_FIT_POINTS]\n            s_q_fit = s_q[:K_FIT_POINTS]\n            \n            # Fit S(q) vs q^2 to a line: S(q) = a + b*q^2.\n            # np.polyfit returns coefficients [b, a]. We need the intercept 'a'.\n            coeffs = np.polyfit(q_fit**2, s_q_fit, 1)\n            s0_est = coeffs[1]\n            \n        # Calculate the absolute error and store it.\n        error = abs(s0_est - S0_TARGET)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在实际的分子动力学模拟中，我们获得的 $g(r)$ 是一个时间序列上的均值，它不仅有统计噪声，而且不同时间步的数据点之间通常存在时间相关性。直接计算样本方差会严重低估真实的不确定性。本练习将指导你实现一个完整的不确定性量化流程，使用“块平均法”(block averaging)来处理时间相关性，从而准确估计 $g(r)$ 及其协方差矩阵，并最终通过线性误差传播，计算出结构因子 $S(q)$ 的置信区间。",
            "id": "3472523",
            "problem": "实现一个完整的、可运行的程序，该程序对从时间序列数据中获得的对相关函数 $g(r)$ 的估计进行不确定性量化，并通过各向同性的三维傅里叶关系将该不确定性传播到静态结构因子 $S(q)$。该程序必须仅从定义和标准统计构造出发，不依赖任何外部数据或用户输入，完成以下所有任务。\n\n给定一个合成的、随时间变化的、在均匀径向网格 $r_i = i \\,\\Delta r$（其中 $i \\in \\{1,\\dots,N_r\\}$）上分箱的估计值 $g_t(r_i)$，其中 $t \\in \\{1,\\dots,T\\}$ 索引离散的时间帧。径向网格从 $r_1=\\Delta r$ 开始，到 $r_{N_r}=r_{\\max}$ 结束。每个分箱中的时间序列由一个平滑、稳态的底层轮廓 $g_{\\text{true}}(r)$ 和一个随时间呈一阶自回归依赖的、序列相关的零均值波动的总和生成。您的任务是使用以下科学标准原则，在指定的波数 $q$ 处计算 $S(q)$ 的不确定性感知估计。\n\n1. 对各向同性且均匀的三维系统，使用对相关函数 $g(r)$ 和静态结构因子 $S(q)$ 的定义。您必须将 $S(q)$ 视为三维空间中总相关函数 $h(r) = g(r)-1$ 在数密度为 $\\rho$ 时的各向同性变换。对于网格上的数值计算，请使用带有适当径向权重的、一致的 Riemann 和。将 $q$ 的单位表示为 $\\text{\\AA}^{-1}$，$r$ 的单位表示为 $\\text{\\AA}$。最终报告的 $S(q)$ 必须是无量纲的。\n\n2. 通过考虑时间相关性，估计分箱时间平均 $\\hat{g}(r_i)$ 中的统计不确定性：\n   - 对每个 $r_i$，计算时间序列 $g_t(r_i)$ 的归一化自相关函数，然后通过将归一化自相关函数从延迟 1 累加到第一个非正值处，并结合延迟 0 的贡献，来估计积分自相关时间 $\\tau_{\\text{int}}(r_i)$，以获得一个有限样本估计量。\n   - 根据 $\\{\\tau_{\\text{int}}(r_i)\\}_{i=1}^{N_r}$ 的中位数选择一个单一的块长度 $B$（以帧为单位），例如 $B = \\lceil 2 \\,\\text{median}_i \\,\\tau_{\\text{int}}(r_i)\\rceil$，并将 $T$ 帧划分为 $M=\\lfloor T/B\\rfloor$ 个长度为 $B$ 的不重叠的连续块。丢弃任何剩余的帧。\n   - 为每个块 $m \\in \\{1,\\dots,M\\}$ 和每个分箱 $i$ 计算块均值 $\\bar{g}^{(m)}(r_i)$。将 $M$ 个块均值向量视为 $g(r)$ 的近似独立样本，以块均值的样本协方差除以 $M$ 来估计分箱估计量 $\\hat{g}(r_i)$ 的协方差矩阵。对这 $M$ 个块均值使用无偏样本协方差。\n\n3. 使用向量上可微映射的线性误差传播方法，将不确定性从 $\\hat{g}(r)$ 传播到 $S(q)$。具体来说，通过加权 Riemann 和，将径向网格上的 $S(q)$ 表示为向量 $\\hat{\\mathbf{g}}-\\mathbf{1}$ 的线性泛函。然后，通过 $g(r)$ 协方差矩阵与相应权重向量的二次型，获得标量 $S(q)$ 的方差。使用此方差为 $S(q)$ 构建对称双边置信区间，其名义覆盖概率对应于 $0.95$ 水平的双边高斯分位数。\n\n4. 使用一个由物理上合理的、平滑的 $g_{\\text{true}}(r)$ 和每个径向分箱的自回归波动定义的合成数据生成器来验证您的方法。对于下文的每个测试用例，按如下方式生成 $g_t(r_i)$：\n   $$\n   g_t(r_i) \\;=\\; g_{\\text{true}}(r_i) \\;+\\; x_t^{(i)} \\,,\n   $$\n   其中 $x_t^{(i)}$ 服从一阶自回归递归关系\n   $$\n   x_t^{(i)} \\;=\\; \\phi \\, x_{t-1}^{(i)} \\;+\\; \\sqrt{1-\\phi^2}\\,\\sigma \\,\\varepsilon_t^{(i)} \\,,\n   $$\n   其中 $\\varepsilon_t^{(i)}$ 是随时间独立同分布的标准正态新息，且在不同 $i$ 之间相互独立，并且 $x_0^{(i)}$ 在其稳态分布中初始化，使得 $\\operatorname{Var}(x_t^{(i)})=\\sigma^2$。在所有测试用例中使用相同的底层 $g_{\\text{true}}(r)$ 和密度 $\\rho$：\n   $$\n   g_{\\text{true}}(r) \\;=\\; 1 \\;+\\; c \\,\\exp\\!\\left(-\\frac{r}{\\xi}\\right)\\,\\frac{\\sin\\!\\left(\\frac{2\\pi r}{d}\\right)}{\\frac{2\\pi r}{d}} \\,,\n   $$\n   其中 $c=0.25$，$\\xi=4.0\\,\\text{\\AA}$，$d=2.5\\,\\text{\\AA}$。对于离散化，在从 $r=\\Delta r$ 到 $r=r_{\\max}$（含两端）的均匀网格上使用梯形法则，网格间距为 $\\Delta r$。\n\n5. 对于每个测试用例，在指定的 $q$ 值处计算估计的均值 $\\hat{S}(q)$ 及其 $95\\%$ 水平的置信区间，然后报告这些 $q$ 值中有多少个的真值 $S_{\\text{true}}(q)$（通过对 $g_{\\text{true}}(r)$ 应用相同的数值积分计算得出）落在了相应的置信区间内。\n\n物理和数值单位：$r$ 的单位使用 $\\text{\\AA}$，$q$ 的单位使用 $\\text{\\AA}^{-1}$，$\\rho$ 的单位使用 $\\text{\\AA}^{-3}$。最终输出报告为无量纲整数。\n\n测试套件。对于下面的每个参数集，生成合成数据并执行上述完整分析。除非另有说明，否则使用共享参数 $\\rho=0.033\\,\\text{\\AA}^{-3}$、$r_{\\max}=10.0\\,\\text{\\AA}$ 和 $\\Delta r=0.05\\,\\text{\\AA}$，并在波数 $q \\in \\{1.0,\\,3.0,\\,6.0\\}\\,\\text{\\AA}^{-1}$ 处进行评估。\n\n- 测试用例 A (理想情况)：$T=2048$，$\\phi=0.6$，$\\sigma=0.03$。\n- 测试用例 B (时间相关性可忽略的边界情况)：$T=256$，$\\phi=0.0$，$\\sigma=0.05$。\n- 测试用例 C (强时间相关性)：$T=4096$，$\\phi=0.95$，$\\sigma=0.02$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须包含 3 个整数，按 A、B、C 的顺序每个测试用例一个，其中每个整数等于 $S_{\\text{true}}(q)$ 落在计算出的 $95\\%$ 水平置信区间内的 $q$ 值（在 $q \\in \\{1.0,\\,3.0,\\,6.0\\}\\,\\text{\\AA}^{-1}$ 中）的数量。例如，一个有效的输出行可能看起来像 $[3,3,2]$。",
            "solution": "该问题要求实现一个完整的程序，用于对从对相关函数 $g(r)$ 的时间序列数据推导出的静态结构因子 $S(q)$ 进行不确定性量化计算。该过程涉及生成合成的时间相关数据，使用块平均法估计时间平均 $g(r)$ 的统计不确定性，通过线性误差传播将此不确定性传播到 $S(q)$，并根据已知的真值验证所得的置信区间。\n\n### 1. 理论框架：从 $g(r)$ 到 $S(q)$\n\n对于三维空间中统计上均匀且各向同性的系统，静态结构因子 $S(q)$ 通过傅里叶变换与对相关函数 $g(r)$ 相关联。总相关函数 $h(r)$ 定义为：\n$$\nh(r) = g(r) - 1\n$$\n此函数描述了粒子对相对于完全随机（理想气体）分布的相关性。结构因子 $S(q)$ 则由下式给出：\n$$\nS(q) = 1 + \\rho \\int_{\\mathbb{R}^3} h(r) e^{-i\\mathbf{q}\\cdot\\mathbf{r}} d^3\\mathbf{r}\n$$\n其中 $\\rho$ 是粒子的数密度，$q = |\\mathbf{q}|$ 是波矢的模。对于各向同性系统，此积分简化为：\n$$\nS(q) = 1 + 4\\pi\\rho \\int_0^\\infty [g(r)-1] \\frac{\\sin(qr)}{qr} r^2 dr\n$$\n对于数值计算，我们在离散的径向网格 $r_i=i\\,\\Delta r$（其中 $i \\in \\{1, \\dots, N_r\\}$）上进行操作。该积分使用数值积分法则进行近似。按照规定，我们在区间 $[0, r_{\\max}]$ 上采用梯形法则。由于被积函数在 $r=0$ 时为零，从 $0$ 到 $r_{\\max}$ 的积分可近似为在网格点 $r_1, \\dots, r_{N_r}$ 处被积函数值的加权和：\n$$\n\\int_0^{r_{\\max}} f(r) dr \\approx \\sum_{i=1}^{N_r} w_i f(r_i)\n$$\n其中梯形权重 $w_i$ 为 $w_1=w_{N_r}=\\Delta r/2$，$1  i  N_r$ 时为 $w_i=\\Delta r$。这将估计量 $\\hat{S}(q)$ 表示为分箱总相关函数向量估计量 $\\hat{\\mathbf{h}} = \\hat{\\mathbf{g}} - \\mathbf{1}$ 的线性函数：\n$$\n\\hat{S}(q) = 1 + \\mathbf{k}_q^T \\hat{\\mathbf{h}}\n$$\n其中向量 $\\mathbf{k}_q$ 的元素为 $(k_q)_i = 4\\pi\\rho w_i \\frac{\\sin(qr_i)}{qr_i} r_i^2$。\n\n### 2. 使用块平均法进行不确定性量化\n\n输入数据包含一系列分箱估计值 $g_t(r_i)$，这些数据表现出时间相关性。对所有时间帧的均值简单地计算样本方差会低估真实的不确定性。块平均法通过将 $T$ 个时间帧分组为 $M$ 个长度为 $B$ 的不重叠块来解决此问题。如果 $B$ 足够大，特别是大于过程的特征相关时间，则块平均值可以被视为近似独立的样本。\n\n该过程如下：\n1.  **估计相关时间：** 对于每个径向分箱 $r_i$，我们首先估计积分自相关时间 $\\tau_{\\text{int}}(r_i)$。其形式化定义为 $\\tau_{\\text{int}} = \\sum_{k=-\\infty}^\\infty C(k)$，其中 $C(k)$ 是延迟为 $k$ 时的归一化自相关函数。对于一个稳态过程，这可以简化为 $\\tau_{\\text{int}} = 1 + 2\\sum_{k=1}^\\infty C(k)$。问题描述中指定了一个实用的估计量，即在样本自相关函数（ACF）首次出现非正值的延迟 $K$ 处截断求和。尽管问题陈述中忽略了关键的因子 2，但我们采用科学上标准的估计量 $\\hat{\\tau}_{\\text{int}}(r_i) = 1 + 2\\sum_{k=1}^{K_i} C(k, r_i)$，其中 $C(k, r_i)$ 是时间序列 $\\{g_t(r_i)\\}_t$ 的样本 ACF，$K_i$ 是 $C(k, r_i) \\leq 0$ 的第一个延迟。这个选择正确地考虑了来自正延迟和负延迟的相关性贡献。\n\n2.  **确定块大小：** 根据估计的自相关时间的中位数，为所有径向分箱选择一个单一的块长度 $B$：$B = \\lceil 2 \\cdot \\text{median}_i\\{\\hat{\\tau}_{\\text{int}}(r_i)\\}\\rceil$。因子 2 提供了一个保守的余量，以确保块与块之间的独立性。\n\n3.  **计算块平均值和协方差：** 时间序列被划分为 $M = \\lfloor T/B \\rfloor$ 个块。对每个块 $m \\in \\{1, \\dots, M\\}$，计算一个块平均向量 $\\bar{\\mathbf{g}}^{(m)}$。这 $M$ 个向量被视为平均 $g(r)$ 轮廓的独立观测值。这些块均值的样本协方差矩阵使用无偏估计量计算：\n    $$\n    \\mathbf{C}_{\\text{block}} = \\frac{1}{M-1} \\sum_{m=1}^{M} (\\bar{\\mathbf{g}}^{(m)} - \\hat{\\mathbf{g}})(\\bar{\\mathbf{g}}^{(m)} - \\hat{\\mathbf{g}})^T\n    $$\n    其中 $\\hat{\\mathbf{g}} = \\frac{1}{M}\\sum_{m=1}^M \\bar{\\mathbf{g}}^{(m)}$ 是块平均值的均值。然后，整体均值估计量 $\\hat{\\mathbf{g}}$ 的协方差矩阵由独立样本均值的标准误差公式给出：\n    $$\n    \\mathbf{\\Sigma}_{\\hat{\\mathbf{g}}} = \\frac{\\mathbf{C}_{\\text{block}}}{M}\n    $$\n\n### 3. 误差传播和置信区间\n\n鉴于 $\\hat{S}(q)$ 是 $\\hat{\\mathbf{g}}$ 的线性变换，$\\hat{\\mathbf{g}}$ 中的不确定性（由其协方差矩阵 $\\mathbf{\\Sigma}_{\\hat{\\mathbf{g}}}$ 表示）可以被传播以求得 $\\hat{S}(q)$ 的方差。$\\hat{S}(q)$ 的方差仅取决于 $\\hat{\\mathbf{g}}$ 的方差（因为 $\\mathbf{k}_q$ 和向量 $\\mathbf{1}$ 是常数）。根据线性误差传播的规则，标量 $\\hat{S}(q)$ 的方差由以下二次型给出：\n$$\n\\mathrm{Var}(\\hat{S}(q)) = \\mathbf{k}_q^T \\mathbf{\\Sigma}_{\\hat{\\mathbf{g}}} \\mathbf{k}_q\n$$\n假设估计量 $\\hat{S}(q)$ 近似服从正态分布（这可以通过应用于块平均值的中心极限定理来证明），可以为 $S(q)$ 构建一个双边 $95\\%$ 置信区间，如下所示：\n$$\n\\left[ \\hat{S}(q) - z_{0.975} \\sqrt{\\mathrm{Var}(\\hat{S}(q))}, \\quad \\hat{S}(q) + z_{0.975} \\sqrt{\\mathrm{Var}(\\hat{S}(q))} \\right]\n$$\n其中 $z_{0.975} \\approx 1.96$ 是标准正态分布的第 $97.5$ 百分位数。\n\n### 4. 合成数据生成与验证\n\n为验证该方法，根据以下模型生成合成的时间序列数据：\n$$\ng_t(r_i) = g_{\\text{true}}(r_i) + x_t^{(i)}\n$$\n噪声项 $x_t^{(i)}$ 服从一阶自回归 (AR(1)) 过程，该过程引入了时间相关性：\n$$\nx_t^{(i)} = \\phi \\, x_{t-1}^{(i)} + \\sqrt{1-\\phi^2} \\, \\sigma \\, \\varepsilon_t^{(i)}\n$$\n其中 $\\varepsilon_t^{(i)}$ 是独立同分布的标准正态随机变量。该过程从其稳态分布初始化，即 $x_0^{(i)} \\sim \\mathcal{N}(0, \\sigma^2)$。底层的平滑轮廓 $g_{\\text{true}}(r)$ 是解析指定的。“真实”的结构因子 $S_{\\text{true}}(q)$ 是通过对 $g_{\\text{true}}(r)$ 应用相同的数值积分来计算的。验证过程包括检查每个指定的 $q$ 值，看 $S_{\\text{true}}(q)$ 是否落在为 $\\hat{S}(q)$ 计算的 $95\\%$ 置信区间内。每个测试用例的最终输出是这种成功覆盖的次数。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Implements a full uncertainty quantification pipeline for the static structure\n    factor S(q) derived from time-series data of the pair correlation function g(r).\n    \"\"\"\n\n    def generate_synthetic_data(T, phi, sigma, g_true_values, rng):\n        \"\"\"\n        Generates synthetic time-series data for g(r).\n        g_t(r_i) = g_true(r_i) + x_t^(i)\n        where x_t is an AR(1) process.\n        \"\"\"\n        Nr = len(g_true_values)\n        x = np.zeros((T, Nr))\n        \n        # Initialize from stationary distribution: x_0 ~ N(0, sigma^2)\n        x[0, :] = rng.normal(loc=0.0, scale=sigma, size=Nr)\n        \n        # Pre-generate all innovations for efficiency\n        innovations = rng.normal(loc=0.0, scale=1.0, size=(T - 1, Nr))\n        \n        # Propagate AR(1) process\n        noise_factor = np.sqrt(1 - phi**2) * sigma\n        for t in range(1, T):\n            x[t, :] = phi * x[t - 1, :] + noise_factor * innovations[t - 1, :]\n            \n        g_t_data = g_true_values[np.newaxis, :] + x\n        return g_t_data\n\n    def calculate_S_q(g_r_profile, r, dr, rho, q_values):\n        \"\"\"\n        Computes the static structure factor S(q) for a given g(r) profile.\n        Uses the trapezoidal rule for numerical integration.\n        \"\"\"\n        h_r = g_r_profile - 1.0\n        Nr = len(r)\n        \n        # Trapezoidal weights for a grid that starts away from zero,\n        # but the integral is defined from r=0 where the integrand is zero.\n        trapz_weights = np.full(Nr, dr)\n        if Nr > 1:\n            trapz_weights[0] *= 0.5\n            trapz_weights[-1] *= 0.5\n\n        # Use broadcasting to compute for all q values at once\n        q = q_values[:, np.newaxis] # Shape (Nq, 1)\n        # sinc(x) = sin(pi*x)/(pi*x), so sin(y)/y = sinc(y/pi)\n        sinc_term = np.sinc(q * r / np.pi) # Shape (Nq, Nr)\n        \n        integrand = h_r * sinc_term * r**2 # Shape (Nq, Nr)\n        \n        # Perform trapezoidal integration\n        integral_values = np.sum(integrand * trapz_weights, axis=1)\n        \n        S_q_values = 1.0 + 4.0 * np.pi * rho * integral_values\n        return S_q_values\n\n    def run_analysis_for_case(case_params, shared_params, rng):\n        \"\"\"\n        Executes the full analysis for a single test case.\n        \"\"\"\n        rho = shared_params['rho']\n        r_max = shared_params['r_max']\n        dr = shared_params['dr']\n        q_values = shared_params['q_values']\n        g_true_params = shared_params['g_true_params']\n\n        T = case_params['T']\n        phi = case_params['phi']\n        sigma = case_params['sigma']\n\n        # 1. Setup grid and true profile\n        r_grid = np.arange(dr, r_max + dr / 2, dr)\n        Nr = len(r_grid)\n\n        def g_true_func(r, c, xi, d):\n            # sinc(x) = sin(pi*x)/(pi*x)\n            # sin(2*pi*r/d) / (2*pi*r/d) = sinc(2*r/d)\n            # Use np.sinc to handle r=0 case, though not in grid.\n            arg = 2 * r / d\n            return 1.0 + c * np.exp(-r / xi) * np.sinc(arg)\n\n        g_true_on_grid = g_true_func(r_grid, **g_true_params)\n\n        # 2. Generate synthetic data\n        g_t_data = generate_synthetic_data(T, phi, sigma, g_true_on_grid, rng)\n\n        # 3. Estimate mean and uncertainty of g(r)\n        \n        # 3a. Estimate integrated autocorrelation time for each bin\n        tau_int_values = np.ones(Nr)\n        g_t_mean = g_t_data.mean(axis=0)\n        \n        for i in range(Nr):\n            series = g_t_data[:, i]\n            series_demeaned = series - g_t_mean[i]\n            \n            # Biased ACF estimator using numpy.correlate\n            acf_unnormalized = np.correlate(series_demeaned, series_demeaned, 'full')[T-1:]\n            if acf_unnormalized[0] > 0:\n                acf = acf_unnormalized / acf_unnormalized[0]\n                # Find first non-positive lag\n                positive_lags = np.where(acf[1:] = 0)[0]\n                K = len(acf) - 1 if len(positive_lags) == 0 else positive_lags[0] + 1\n                # Standard estimator for tau_int\n                tau_int = 1.0 + 2.0 * np.sum(acf[1:K])\n                # Ensure tau_int is positive; sample ACF can be noisy\n                tau_int_values[i] = max(1.0, tau_int)\n\n        # 3b. Blocking analysis\n        median_tau_int = np.median(tau_int_values)\n        B = int(np.ceil(2 * median_tau_int))\n        if B  1: B = 1\n        M = T // B\n        \n        if M  2:\n            # Not enough blocks to estimate covariance, a sign of insufficient data.\n            # This should not happen with the provided test cases.\n            # We return 0 coverage as the analysis is invalid.\n            return 0\n            \n        g_t_truncated = g_t_data[:M * B, :]\n        block_means = g_t_truncated.reshape(M, B, Nr).mean(axis=1)\n\n        # 3c. Covariance matrix of the mean g(r) estimate\n        # Unbiased sample covariance of block means\n        cov_block_means = np.cov(block_means, rowvar=False, ddof=1)\n        # Covariance of the overall mean estimate\n        cov_g_hat = cov_block_means / M\n\n        # 4. Propagate uncertainty to S(q)\n        g_hat = block_means.mean(axis=0)\n        S_hat_q = calculate_S_q(g_hat, r_grid, dr, rho, q_values)\n        \n        # Trapezoidal weights\n        trapz_weights = np.full(Nr, dr)\n        if Nr > 1:\n            trapz_weights[0] *= 0.5\n            trapz_weights[-1] *= 0.5\n        \n        var_S_q = np.zeros(len(q_values))\n        for i, q in enumerate(q_values):\n            # Construct weight vector for linear propagation\n            sinc_term = np.sinc(q * r_grid / np.pi)\n            k_q_vec = 4 * np.pi * rho * trapz_weights * sinc_term * r_grid**2\n            \n            # Variance of S(q) is k^T * Sigma * k\n            var_S_q[i] = k_q_vec.T @ cov_g_hat @ k_q_vec\n\n\n        std_S_q = np.sqrt(np.maximum(0, var_S_q)) # Ensure non-negative variance\n        z_975 = norm.ppf(0.975)\n        \n        # 5. Validate against true values\n        S_true_q = calculate_S_q(g_true_on_grid, r_grid, dr, rho, q_values)\n        \n        lower_bounds = S_hat_q - z_975 * std_S_q\n        upper_bounds = S_hat_q + z_975 * std_S_q\n        \n        coverage_count = np.sum((S_true_q >= lower_bounds)  (S_true_q = upper_bounds))\n        \n        return coverage_count\n\n    # --- Main execution ---\n    \n    # Use a fixed seed for reproducibility.\n    rng = np.random.default_rng(seed=12345)\n\n    shared_params = {\n        'rho': 0.033,           # atoms/A^3\n        'r_max': 10.0,          # A\n        'dr': 0.05,             # A\n        'q_values': np.array([1.0, 3.0, 6.0]), # A^-1\n        'g_true_params': {'c': 0.25, 'xi': 4.0, 'd': 2.5}\n    }\n\n    test_cases = [\n        {'T': 2048, 'phi': 0.60, 'sigma': 0.03}, # Case A\n        {'T': 256,  'phi': 0.00, 'sigma': 0.05}, # Case B\n        {'T': 4096, 'phi': 0.95, 'sigma': 0.02}, # Case C\n    ]\n\n    results = []\n    for case in test_cases:\n        count = run_analysis_for_case(case, shared_params, rng)\n        results.append(int(count))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}