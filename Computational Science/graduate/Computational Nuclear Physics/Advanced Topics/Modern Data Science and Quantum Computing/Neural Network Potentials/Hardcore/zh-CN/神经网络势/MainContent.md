## 引言
精确描述[核子](@entry_id:158389)间的相互作用是[核物理](@entry_id:136661)学的核心挑战之一。尽管传统模型（如唯象势和手征[有效场论](@entry_id:145328)）取得了巨大成功，但它们在灵活性与精度之间往往需要权衡。近年来，源于机器学习的[神经网](@entry_id:276355)络势（NNP）作为一种功能强大的[函数逼近](@entry_id:141329)器，为构建高保真度的核力模型提供了全新的[范式](@entry_id:161181)。然而，其“黑箱”特性也引发了一个关键问题：我们如何确保这些数据驱动的模型不仅能精确拟[合数](@entry_id:263553)据，更能遵守量子力学的基本原理，并具备可靠的物理[可解释性](@entry_id:637759)和预测能力？

本文旨在系统性地解答这一问题，为读者构建一个从理论基础到前沿应用的完整知识框架。我们将分为三个章节进行深入探讨：

*   在“原理与机制”一章中，我们将深入剖析构建物理上自洽的NNP所必需的核心原则。内容将涵盖如何通过架构设计来强制实现[厄米性](@entry_id:141899)、[旋转不变性](@entry_id:137644)等[基本对称性](@entry_id:161256)，探讨不同表象（坐标空间与[动量空间](@entry_id:148936)）的适用场景，以及如何将手征[有效场论](@entry_id:145328)的理论先验知识融入模型。

*   随后的“应用与跨学科交叉”一章，将展示这些原理在实际研究中的应用。我们将探讨如何将NNP与“从头算”多体方法相结合以预测[原子核](@entry_id:167902)性质，如何量化模型的不确定性以指导[主动学习](@entry_id:157812)，并揭示其与[计算化学](@entry_id:143039)、[材料科学](@entry_id:152226)等领域的深刻联系。

*   最后，在“动手实践”部分，我们将通过一系列精心设计的编程练习，帮助读者将理论知识转化为解决实际计算问题的能力。

通过这一系列的学习，读者将掌握构建、应用和评估[神经网](@entry_id:276355)络[核势](@entry_id:752727)的关键技能，为在[计算核物理](@entry_id:747629)领域开展前沿研究奠定坚实的基础。

## 原理与机制

本章旨在深入探讨构建和应用[神经网](@entry_id:276355)络势（NNP）以模[拟核](@entry_id:178267)相互作用所需的核心原理和关键机制。在前一章介绍其背景和动机的基础上，我们将系统地阐述如何从第一性原理出发，将基本的物理约束、对称性和理论先验融入神经[网络模型](@entry_id:136956)中。我们的目标是构建不仅能精确拟合实验数据，而且在物理上健全、可解释且具有预测能力的[势函数](@entry_id:176105)。本章将逐一剖析确保物理一致性的[结构设计](@entry_id:196229)、在不同表象中进行计算的优劣权衡、与[有效场论](@entry_id:145328)的融合策略，以及处理[逆散射问题](@entry_id:750808)固有模糊性的方法。

### 基本原理：对称性与[核势](@entry_id:752727)结构

任何有效的[核力](@entry_id:143248)模型都必须遵循其底层理论——[量子色动力学](@entry_id:143869)（QCD）——在低能下的对称性。这些对称性极大地约束了[核势](@entry_id:752727)算符的数学形式。对于一个两[核子](@entry_id:158389)系统，关键的对称性要求包括：

1.  **平移不变性**：物理定律不应依赖于坐标原点的选择。这意味着相互作用势只能依赖于两个[核子](@entry_id:158389)间的相对坐标 $\boldsymbol{r} = \boldsymbol{r}_1 - \boldsymbol{r}_2$ 或相对动量 $\boldsymbol{p} = (\boldsymbol{p}_1 - \boldsymbol{p}_2)/2$。
2.  **伽利略不变性**：物理定律在所有[惯性参考系](@entry_id:276742)中都应相同。这要求势函数不能依赖于系统的[质心动量](@entry_id:171180)。结合[平移不变性](@entry_id:195885)，这意味着势函数完全由相对运动的[运动学](@entry_id:173318)变量决定。
3.  **[旋转不变性](@entry_id:137644)**：物理定律不应依赖于[坐标系](@entry_id:156346)的朝向。这要求势算符在空间旋转下是一个标量。因此，[势函数](@entry_id:176105)中的任何标量系数只能依赖于可用向量（如相对坐标 $\boldsymbol{r}$、相对动量 $\boldsymbol{p}, \boldsymbol{p}'$）构建的[旋转不变量](@entry_id:170459)。
4.  **宇称（P）和[时间反演](@entry_id:182076)（T）不变性**：强相互作用和电磁相互作用在极大精度上是 P 和 T 对称的。这禁止了[势函数](@entry_id:176105)中出现[赝标量](@entry_id:196696)和时间反演奇性的结构。
5.  **[厄米性](@entry_id:141899)**：作为[量子力学中的可观测量](@entry_id:152184)，[哈密顿量](@entry_id:172864)必须是厄米的，以确保[能量本征值](@entry_id:144381)为实数。这意味着势算符 $\hat{V}$ 必须满足 $\hat{V} = \hat{V}^\dagger$。

为了系统地满足这些要求，特别是[旋转不变性](@entry_id:137644)，一个强大且通用的方法是将势算符 $V$ 展开为一组算符基 $\{O_i\}$ 的线性组合 ：
$$
V = \sum_{i} f_{i}(x) O_{i}
$$
在这个展开式中，$\{O_i\}$ 是一组在自旋和[同位旋](@entry_id:199830)空间中作用的、具有确定变换性质的[厄米算符](@entry_id:153410)。$\{f_i(x)\}$ 是一组标量系数函数，它们是[神经网](@entry_id:276355)络学习的核心目标。这些函数的输入 $x$ 必须是由系统中的运动学向量（如相对位置或动量）构成的[旋转不变量](@entry_id:170459)，从而保证整个势算符 $V$ 是一个旋转标量。

在[动量空间](@entry_id:148936)中，相互作用将初始相对动量 $\boldsymbol{p}$ 的态散射到末态相对动量 $\boldsymbol{p}'$。我们通常使用动量转移 $\boldsymbol{q} = \boldsymbol{p}' - \boldsymbol{p}$ 和平均动量 $\boldsymbol{k} = (\boldsymbol{p}' + \boldsymbol{p})/2$ 来描述这一过程。最通用的一组[旋转不变量](@entry_id:170459)输入是 $q^2 = |\boldsymbol{q}|^2$、$k^2 = |\boldsymbol{k}|^2$ 和 $\boldsymbol{k} \cdot \boldsymbol{q}$。在局域的坐标空间表象中，输入简化为相对距离 $r = |\boldsymbol{r}|$。

一个完备且被广泛应用的两[核子](@entry_id:158389)算符基 $\{O_i\}$ 包括 ：
- **[中心力](@entry_id:267832)部分**: $O_C = 1$
- **自旋-自旋部分**: $O_{\sigma} = \boldsymbol{\sigma}_1 \cdot \boldsymbol{\sigma}_2$
- **[张量力](@entry_id:161961)部分**: $O_T = S_{12}(\hat{\boldsymbol{q}}) = 3(\boldsymbol{\sigma}_1 \cdot \hat{\boldsymbol{q}})(\boldsymbol{\sigma}_2 \cdot \hat{\boldsymbol{q}}) - \boldsymbol{\sigma}_1 \cdot \boldsymbol{\sigma}_2$ (在坐标空间中为 $S_{12}(\hat{\boldsymbol{r}})$)
- **自旋-[轨道](@entry_id:137151)部分**: $O_{LS} = \boldsymbol{L} \cdot \boldsymbol{S}$ (在动量空间中对应于 $i\boldsymbol{S} \cdot (\boldsymbol{k} \times \boldsymbol{q})$)

每一项通常还会乘以同位旋算符，如 $1$ 或 $\boldsymbol{\tau}_1 \cdot \boldsymbol{\tau}_2$，但在一个固定的总同位旋通道中，同位旋算符的作用等效于一个常数。

[神经网](@entry_id:276355)络势（NNP）的核心思想就是利用[人工神经网络](@entry_id:140571)（ANN）作为一种通用的函数逼近器，来[参数化](@entry_id:272587)这些未知的标量函数 $f_i(q^2, k^2, \boldsymbol{k} \cdot \boldsymbol{q})$。这种方法的优势在于其极大的灵活性，能够以高精度拟合复杂的散射数据。然而，它也带来了挑战：与基于物理图像（如[介子交换](@entry_id:751912)）的有效场论（EFT）模型相比，[神经网](@entry_id:276355)络的权重和偏置通常缺乏直接的物理可解释性，使其成为一个“黑箱”。而手征有效场论（Chiral EFT）则提供了一个基于对称性的、系统的、可解释的框架，但其在给定阶数下的灵活性有限。NNP和EFT的结合旨在集两者之所长。

### 依构造确保物理一致性

为了使NNP成为一个有效的物理模型，仅靠拟合数据是远远不够的。我们必须将基本的物理原理直接构建到网络的架构中。这种“依构造”（by construction）的设计确保模型在任何情况下都遵守这些原理，而无需从数据中“学习”它们。

#### [厄米性](@entry_id:141899)：保证实数[可观测量](@entry_id:267133)

[哈密顿量](@entry_id:172864)的[厄米性](@entry_id:141899)是量子力学的基石。对于一个非局域势核 $V(\boldsymbol{r}, \boldsymbol{r}')$，[厄米性](@entry_id:141899)条件 $\hat{V} = \hat{V}^\dagger$ 转化为核的对称性关系：$V(\boldsymbol{r}, \boldsymbol{r}') = V^*(\boldsymbol{r}', \boldsymbol{r})$ 。若将核分解为实部和虚部 $V = \text{Re}[V] + i\,\text{Im}[V]$，该条件等价于：
1.  核的实部必须是对称的：$\text{Re}[V(\boldsymbol{r}, \boldsymbol{r}')] = \text{Re}[V(\boldsymbol{r}', \boldsymbol{r})]$。
2.  核的虚部必须是反对称的：$\text{Im}[V(\boldsymbol{r}, \boldsymbol{r}')] = -\text{Im}[V(\boldsymbol{r}', \boldsymbol{r})]$。

有两种主要的架构策略可以依构造保证[厄米性](@entry_id:141899)：

-   **显式对称化**：让[神经网](@entry_id:276355)络输出两个无约束的实函数 $f(\boldsymbol{r}, \boldsymbol{r}')$ 和 $g(\boldsymbol{r}, \boldsymbol{r}')$。然后，通过构造来形成势核的实部和虚部：
    $$
    \text{Re}[V(\boldsymbol{r}, \boldsymbol{r}')] = S(\boldsymbol{r}, \boldsymbol{r}') = \frac{1}{2} [f(\boldsymbol{r}, \boldsymbol{r}') + f(\boldsymbol{r}', \boldsymbol{r})]
    $$
    $$
    \text{Im}[V(\boldsymbol{r}, \boldsymbol{r}')] = A(\boldsymbol{r}, \boldsymbol{r}') = \frac{1}{2} [g(\boldsymbol{r}, \boldsymbol{r}') - g(\boldsymbol{r}', \boldsymbol{r})]
    $$
    这种构造自动满足了实部对称和虚部反对称的要求 。

-   **谱分解**：另一种更抽象但同样严谨的方法是基于[谱定理](@entry_id:136620)。任何有限秩的[厄米算符](@entry_id:153410)都可以写成谱分解形式：
    $$
    \hat{V} = \sum_{n=1}^{N} \lambda_{n} |\phi_{n}\rangle\langle\phi_{n}|
    $$
    在此架构中，[神经网](@entry_id:276355)络被设计为输出一组实数标量 $\lambda_n$（[本征值](@entry_id:154894)）和一组相互正交的函数 $\phi_n(\boldsymbol{r})$（本征函数）。由于[本征值](@entry_id:154894)是实的，并且 $|\phi_{n}\rangle\langle\phi_{n}|$ 是厄米投影算符，它们的[线性组合](@entry_id:154743)构成的 $\hat{V}$ 必定是厄米的 。

值得强调的是，通过在损失函数中添加惩罚项（所谓的“软约束”）来鼓励[厄米性](@entry_id:141899)，通常是不够的。这种方法不能保证在整个[函数空间](@entry_id:143478)中严格满足该性质，而只能在训练数据点附近近似满足。

#### 旋转[等变性](@entry_id:636671)：内建对称性

[旋转不变性](@entry_id:137644)是另一个必须严格遵守的基本原理。如果一个网络的设计能保证当输入被旋转时，其输出也以一种可预测的方式相应旋转，我们就称该网络具有**旋转[等变性](@entry_id:636671) (rotational equivariance)**。对于一个标量输出（如[中心势](@entry_id:148563) $V_C(r)$），[等变性](@entry_id:636671)简化为**[不变性](@entry_id:140168) (invariance)**，即输出不随输入旋转而改变。对于一个张量输出（如张量势），[等变性](@entry_id:636671)则要求张量本身随[坐标系](@entry_id:156346)正确旋转。

将[等变性](@entry_id:636671)构建到网络架构中，可以极大地提高数据效率和模型的物理真实性。同样，有两种主流方法 ：

-   **方法一：[不变性](@entry_id:140168)网络与解析基**：这是一种直接且有效的方法。我们设计一个[神经网](@entry_id:276355)络，其输入和输出都严格限制为[旋转不变量](@entry_id:170459)。例如，网络只接受相对距离 $r=|\boldsymbol{r}|$ 作为输入，并输出标量系数函数，如 $V_C(r)$ 和 $V_T(r)$。然后，具有特定变换性质的物理输出是通过将这些不变的系数函数与解析上已知的、具有正确变换性质的几何[基函数](@entry_id:170178)（或称张量基）相乘来构造的。例如，二阶张量势可以构造为：
    $$
    T_{ij}(\boldsymbol{r}) = V_T(r) \left( \hat{r}_i \hat{r}_j - \frac{1}{3}\delta_{ij} \right)
    $$
    这里，[神经网](@entry_id:276355)络学习的是简单的标量函数 $V_T(r)$，而整个表达式的二阶张量（角动量 $l=2$）变换性质由解析部分 $(\hat{r}_i \hat{r}_j - \frac{1}{3}\delta_{ij})$ 保证。

-   **方法二：球谐[张量网络](@entry_id:142149)**：这是一种更通用、更强大的方法，源于[几何深度学习](@entry_id:636472)。其核心思想是将网络中流动的所有特征（包括输入、隐藏层和输出）都表示为[三维旋转](@entry_id:148533)群 [SO(3)](@entry_id:138200) 的不可约表示（irreps），这些表示由角动量量子数 $l=0, 1, 2, \dots$ 来标记。
    -   每一层的特征被组织成不同 $l$ 值的通道。
    -   网络中的线性操作（如卷积）被设计成等变操作，确保它们不会混合不同 $l$ 类型的特征。
    -   [非线性激活函数](@entry_id:635291)通过[张量积](@entry_id:140694)（Clebsch-Gordan耦合）来实现，将两个具有角动量 $l_1$ 和 $l_2$ 的特征耦合，产生一组新的、具有确定角动量 $L \in \{|l_1-l_2|, \dots, l_1+l_2\}$ 的特征。
    -   最终的物理输出是通过从最后一层特征中射影出所需的 $l$ 分量来获得的（例如，标量势对应 $l=0$，张量势对应 $l=2$）。
    这种方法确保了网络的每一步操作都严格遵守[旋转对称](@entry_id:137077)性。

需要避免的常见错误是，对向量或张量的笛卡尔分量直接应用标准的、[非线性](@entry_id:637147)的激活函数（如ReLU），因为这会破坏[等变性](@entry_id:636671)。例如，一般来说 $\text{ReLU}(R\boldsymbol{v}) \neq R(\text{ReLU}(\boldsymbol{v}))$。

### 选择正确的表象：架构与领域

在构建NNP时，研究者面临着关键的实践选择：势函数应该在哪个空间（坐标空间或[动量空间](@entry_id:148936)）中表示？应该采用哪种[网络架构](@entry_id:268981)？这些选择深刻地影响着计算成本、数值稳定性和模型[表达能力](@entry_id:149863)。

#### 局域性、非局域性及其表示

在薛定谔方程中，势算符的作用方式区分了局域势和非局域势。
-   **局域势** $V(\boldsymbol{r})$ 以乘法方式作用于[波函数](@entry_id:147440)：$(\hat{V}\psi)(\boldsymbol{r}) = V(\boldsymbol{r})\psi(\boldsymbol{r})$。其势核可以写为 $V(\boldsymbol{r}, \boldsymbol{r}') = V(\boldsymbol{r})\delta^{(3)}(\boldsymbol{r}-\boldsymbol{r}')$。
-   **非局域势** 通过一个积分核 $V(\boldsymbol{r}, \boldsymbol{r}')$ 作用，将[波函数](@entry_id:147440)在整个空间中的值关联起来：$(\hat{V}\psi)(\boldsymbol{r}) = \int d^3\boldsymbol{r}'\, V(\boldsymbol{r}, \boldsymbol{r}') \psi(\boldsymbol{r}')$。

现代核力理论表明，核力本质上是非局域的。为了在NNP中灵活地模拟[非局域性](@entry_id:140165)，一种常见的[参数化](@entry_id:272587)方法是引入一个“[初生δ函数](@entry_id:270942)”（nascent delta function），例如一个归一化的高斯函数，其宽度 $R_0$ 控制着[非局域性](@entry_id:140165)的范围 ：
$$
V(\boldsymbol{r}, \boldsymbol{r}') = \mathcal{W}(\boldsymbol{r}, \boldsymbol{r}') \frac{\exp\left(-\frac{|\boldsymbol{r}-\boldsymbol{r}'|^2}{2R_0^2}\right)}{(2\pi R_0^2)^{3/2}}
$$
其中，$\mathcal{W}(\boldsymbol{r}, \boldsymbol{r}')$ 是一个由[神经网](@entry_id:276355)络学习的、变化平缓的函数。当 $R_0 \to 0$ 时，[高斯函数](@entry_id:261394)趋于[狄拉克δ函数](@entry_id:153299)，势函数也随之退化为局域势 $V_{\text{loc}}(\boldsymbol{r}) = \mathcal{W}(\boldsymbol{r}, \boldsymbol{r})$。参数 $R_0$ 因此明确地设定了非局域相互作用的特征尺度。

#### 坐标空间 vs. 动量空间

求解两体散射问题的两个主要计算框架分别是坐标空间中的薛定谔方程和[动量空间](@entry_id:148936)中的李普曼-施温格（Lippmann-Schwinger, LS）方程。选择在哪一个空间中表示NNP，是一个关乎[计算效率](@entry_id:270255)和问题适配性的重要决策 。

-   **坐标空间 (r-space)**：
    -   **方法**：将分波后的薛定谔方程作为一个常微分方程（ODE）进行[数值积分](@entry_id:136578)。
    -   **优点**：对于局域势，[计算效率](@entry_id:270255)极高，每个分波、每个能量点的计算成本大致为 $O(N_r)$，其中 $N_r$ 是径向格点数。内存占用低。直接给出渐进行为，易于提取在壳（on-shell）观测量，如相移。
    -   **缺点**：表示非局域势较为复杂。获取离壳（off-shell）信息需要额外的计算步骤。对于长程力（如库仑力），需要很大的积分上限 $r_{\text{max}}$。

-   **动量空间 (p-space)**：
    -   **方法**：将分波后的LS方程离散化，转化为一个大型的线性[代数方程](@entry_id:272665)组。
    -   **优点**：天然地处理非局域势。直接求解得到完整的[T矩阵](@entry_id:145367) $T(p, p'; E)$，其中包含了在壳（$p=p'=\sqrt{2\mu E}/\hbar$）和离壳（$p \neq p'$）的全部信息。[动量空间](@entry_id:148936)的调节器（regulator）易于实现。
    -   **缺点**：计算成本高昂。由于势核矩阵通常是稠密的，直接求解的计算[时间复杂度](@entry_id:145062)为 $O(N_k^3)$，内存占用为 $O(N_k^2)$，其中 $N_k$ 是动量格点数。长程势在坐标空间的缓变对应于动量空间在 $k \to 0$ 处的尖锐结构，需要非常精细的格点来分辨。

**选择标准**：最终选择应基于目标任务。如果目标是计算局域势的在壳相移，坐标空间是更优越的选择。如果需要研究离壳行为（这对于[三体](@entry_id:265960)及多体计算至关重要），或者势本身具有显著的[非局域性](@entry_id:140165)，那么[动量空间](@entry_id:148936)是更自然的框架。

#### 匹配网络架构与物理属性

成功的建模还需要为特定任务选择具有合适**[归纳偏置](@entry_id:137419) (inductive bias)** 的网络架构。[归纳偏置](@entry_id:137419)是模型为从有限数据中泛化而做出的内在假设。

[核势](@entry_id:752727)在不同表象中展现出不同的函数特性，这为架构选择提供了线索 ：
-   在**坐标空间**中，$V(r)$ 通常是多尺度的：在短程（$r \lesssim 0.5$ fm）存在一个由调节器引起的、变化剧烈的“核芯”；在长程（$r \gtrsim 1.4$ fm）则表现为平滑的指数衰减（汤川势）。对于这类具有局域化、多尺度特征的函数，**[径向基函数](@entry_id:754004)（RBF）网络** 是一个理想的选择。RBF网络通过放置不同宽度和位置的[基函数](@entry_id:170178)（如[高斯函数](@entry_id:261394)）的[线性组合](@entry_id:154743)来构建函数，能够高效地分别描述势的核芯和尾部。
-   在**动量空间**中，$V(\boldsymbol{p}, \boldsymbol{p}')$ 由于物理调节器的存在，其在动量大小 $p, p'$ 上的依赖通常是**带限的 (band-limited)**，即在高动量区域被平滑地压低。其对角度的依赖也通常是平滑的，可以由少数几个分波精确描述。对于这类平滑的、带限的函数，**傅里叶特征网络**（或正弦表示网络，如SIREN）具有天然的优势。这类网络将输入坐标嵌入到一组正弦特征中，其[归纳偏置](@entry_id:137419)非常适合学习具有特定频率成分的函数。

相比之下，使用带有[ReLU激活函数](@entry_id:138370)的多层感知机（MLP）来拟合平滑的物理势是一个糟糕的选择，因为它会产生一个连续但处处不可导（$C^0$）的、由[分段线性函数](@entry_id:273766)拼接而成的结果，引入了非物理的“扭结”。

### 融合[有效场论](@entry_id:145328)的理论先验

虽然NNP是数据驱动的，但我们不应忽视从成熟的物理理论中获得的宝贵知识。将手征有效场论（Chiral EFT）的见解作为[先验信息](@entry_id:753750)（prior）融入NNP的训练中，是构建高保真度[核势](@entry_id:752727)的关键一步。

#### 强制正确的长程行为

从理论上我们确知，在较大距离上（$r \gtrsim 1.4$ fm），[核子](@entry_id:158389)间的相互作用由最轻的介子——$\pi$[介子](@entry_id:184535)——的交换主导。这种单π[交换势](@entry_id:749153)（OPE）具有汤川形式 $V_\pi(r) \propto e^{-m_\pi r}/r$。强制NNP在长程区域重现这一行为，可以显著提高其外推能力和物理真实性。

这通常通过在[损失函数](@entry_id:634569)中加入一个物理约束项来实现 ：
$$
\mathcal{L}_{\text{OPE}} = \int_{R_{\pi}}^{\infty} dr\, w(r) \left|V_{\text{NN}}(r) - V_{\pi}(r)\right|^2
$$
其中 $w(r)$ 是一个权重函数，$R_\pi$ 是一个匹配半径。$R_\pi$ 的选择至关重要：
-   如果 $R_\pi$ **太小**（例如 $0.7$ fm），就会在两π交换等其他物理效应依然显著的区域错误地强制OPE形式，从而损害模型对中程物理的描述。
-   如果 $R_\pi$ **太大**（例如 $5.0$ fm），约束只在[势函数](@entry_id:176105)已指数衰减至极小的渐近区域生效，导致该约束项的梯度微乎其微，对训练几乎没有指导作用。
-   一个物理上合理且数值上稳健的选择是将 $R_\pi$ 设在单π交换开始主导的尺度附近，即**π介子的[康普顿波长](@entry_id:151482) $\lambda_\pi \approx 1.4$ fm**。

#### 嵌入手征[幂次计数](@entry_id:158814)

Chiral EFT的一个核心特征是其系统性的**[幂次计数](@entry_id:158814) (power counting)** 方案，它将[势函数](@entry_id:176105)组织成一个关于小动量标度 $Q/\Lambda_b$ 的展开式，其中 $\Lambda_b$ 是理论的破缺标度。展开式中更高阶的项贡献越来越小。将这种层级结构嵌入NNP，可以规范模型的行为，防止其在拟合数据时产生非物理的“高阶污染”。

实现这一目标的正确方法不是使用一个通用的黑箱网络，而是设计一个明确反映EFT结构的“白箱”模型 ：
1.  **架构**：将NNP的输出构造为EFT算符的[线性组合](@entry_id:154743)：$V = \sum_{\nu, i} c_i^{(\nu)} \mathcal{O}_i^{(\nu)}$。其中，$\mathcal{O}_i^{(\nu)}$ 是固定的、来自EFT的、具有确定幂次 $\nu$ 的算符基。
2.  **参数**：[神经网](@entry_id:276355)络学习的不再是复杂的[非线性](@entry_id:637147)函数，而是展开系数，即**[低能常数](@entry_id:751501)（LECs）$c_i^{(\nu)}$**。这些LECs被实现为与运动学无关的、可学习的标量参数。
3.  **先验**：使用**[贝叶斯先验](@entry_id:183712)**来实施[幂次计数](@entry_id:158814)。具体而言，为每个LEC $c_i^{(\nu)}$ 赋予一个[高斯先验](@entry_id:749752) $\mathcal{N}(0, \sigma_\nu^2)$。先验的[方差](@entry_id:200758) $\sigma_\nu^2$ 应随阶数 $\nu$ 的增加而减小（例如，$\sigma_\nu = \sigma_0 r^\nu$, $0<r<1$），以惩罚更高阶的贡献。
这种方法确保了NNP在拥有EFT系统性优势的同时，仍能通过数据驱动的LECs优化来获得高精度，从而实现了理论先验与[数据拟合](@entry_id:149007)的最佳结合。