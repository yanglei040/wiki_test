{
    "hands_on_practices": [
        {
            "introduction": "Before embarking on solving the complex coupled-cluster equations, a crucial first step is to understand the scale of the problem. The core unknowns in the Coupled-Cluster Doubles (CCD) approximation are the doubles amplitudes, $t_{ij}^{ab}$, which form a large tensor. This exercise  guides you through the process of counting the number of unique, independent amplitudes by applying fundamental principles of fermionic antisymmetry and isospin conservation, giving you a direct measure of the memory required for a calculation.",
            "id": "3553374",
            "problem": "Consider the Coupled Cluster (CC) method applied to a closed-shell nucleus in a single-particle basis, where the cluster operator includes only the doubles excitation component. The doubles cluster operator is written in second quantization as\n$$\nT_{2} = \\frac{1}{4} \\sum_{i j a b} t_{i j}^{a b}\\, a_{a}^{\\dagger} a_{b}^{\\dagger} a_{j} a_{i},\n$$\nwhere $a_{p}^{\\dagger}$ and $a_{p}$ are fermionic creation and annihilation operators obeying the canonical anticommutation relations, and $t_{i j}^{a b}$ are the doubles amplitudes connecting occupied single-particle states $(i,j)$ to virtual single-particle states $(a,b)$. The indices carry both spin and isospin quantum numbers, with $i,j$ drawn from the occupied manifold and $a,b$ drawn from the virtual manifold of the reference Slater determinant. The nuclear Hamiltonian conserves isospin and parity, and the species labels (neutron or proton) are used to block the amplitude tensor into three non-overlapping channels: neutron–neutron, proton–proton, and neutron–proton. Due to fermionic antisymmetry, amplitudes in like-species channels satisfy antisymmetry under exchange of either the occupied indices or the virtual indices. In contrast, for mixed-species channels, exchange across species does not create redundancy because the exchanged objects belong to different blocks.\n\nAn implementation stores only the independent doubles amplitudes by exploiting these antisymmetries and the species block structure. Specifically:\n- In the neutron–neutron block, only unordered pairs of occupied neutron indices and unordered pairs of virtual neutron indices are stored.\n- In the proton–proton block, only unordered pairs of occupied proton indices and unordered pairs of virtual proton indices are stored.\n- In the neutron–proton block, all combinations of one occupied neutron with one occupied proton and one virtual neutron with one virtual proton are stored without further reduction.\n\nStarting from the fermionic anticommutation relations and the operator structure of $T_{2}$, derive the counting rules for the number of independent doubles amplitudes stored in each block. Then, for a model space with $n_{o}^{n} = 10$ occupied neutrons, $n_{v}^{n} = 30$ virtual neutrons, $n_{o}^{p} = 8$ occupied protons, and $n_{v}^{p} = 24$ virtual protons, compute the exact total number of stored doubles amplitudes across all three blocks.\n\nExpress your final count as an exact integer without units.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of many-body quantum mechanics and the coupled-cluster formalism, is well-posed with a clear objective and sufficient data, and is free from any scientific or logical contradictions. We can therefore proceed with the derivation and calculation.\n\nThe problem asks for the total number of independent doubles amplitudes, $t_{i j}^{a b}$, stored in a coupled-cluster calculation for a nucleus. The storage scheme exploits symmetries arising from fermionic antisymmetry and the block structure based on particle type (neutron or proton). The total number of amplitudes is the sum of the independent amplitudes in the three distinct channels: neutron–neutron ($nn$), proton–proton ($pp$), and neutron–proton ($np$).\n\nThe cluster operator for doubles, $T_2$, is given by\n$$\nT_{2} = \\frac{1}{4} \\sum_{i j a b} t_{i j}^{a b}\\, a_{a}^{\\dagger} a_{b}^{\\dagger} a_{j} a_{i}\n$$\nwhere indices $i, j$ run over occupied single-particle states and $a, b$ run over virtual (unoccupied) single-particle states. The operators $a^{\\dagger}$ and $a$ are fermionic creation and annihilation operators. Due to the anticommutation relations $\\{a_p, a_q\\} = 0$ and $\\{a_p^{\\dagger}, a_q^{\\dagger}\\} = 0$, the operator product $a_{a}^{\\dagger} a_{b}^{\\dagger} a_{j} a_{i}$ is antisymmetric under the exchange $i \\leftrightarrow j$ and $a \\leftrightarrow b$. To ensure that each distinct physical excitation is counted only once in the summation, the amplitudes must possess the same antisymmetry:\n$$\nt_{ij}^{ab} = -t_{ji}^{ab} \\quad \\text{and} \\quad t_{ij}^{ab} = -t_{ij}^{ba}\n$$\nThis implies $t_{ij}^{ab} = t_{ji}^{ba}$. These relations are fundamental to determining the number of unique amplitudes.\n\nWe analyze each channel separately.\n\n**1. Neutron–Neutron ($nn$) Channel**\nIn this channel, all four indices ($i, j, a, b$) correspond to neutron states. Let the number of occupied neutron states be $n_{o}^{n}$ and the number of virtual neutron states be $n_{v}^{n}$. The amplitudes are of the form $t_{i_n j_n}^{a_n b_n}$.\nDue to the antisymmetry $t_{i_n j_n}^{a_n b_n} = -t_{j_n i_n}^{a_n b_n}$, we must have $i_n \\neq j_n$. To count the number of independent amplitudes, we can adopt a convention, for instance, storing only those amplitudes where $i_n < j_n$. The number of ways to choose two distinct occupied neutron indices without regard to order is given by the binomial coefficient $\\binom{n_{o}^{n}}{2}$.\nSimilarly, due to the antisymmetry $t_{i_n j_n}^{a_n b_n} = -t_{i_n j_n}^{b_n a_n}$, we must have $a_n \\neq b_n$. We store only amplitudes where, by convention, $a_n < b_n$. The number of ways to choose two distinct virtual neutron indices without regard to order is $\\binom{n_{v}^{n}}{2}$.\nThe total number of independent neutron-neutron amplitudes, $N_{nn}$, is the product of the number of unique hole pairs and unique particle pairs.\n$$\nN_{nn} = \\binom{n_{o}^{n}}{2} \\binom{n_{v}^{n}}{2}\n$$\n\n**2. Proton–Proton ($pp$) Channel**\nThe logic for this channel is identical to the neutron-neutron channel. All four indices correspond to proton states. Let the number of occupied proton states be $n_{o}^{p}$ and the number of virtual proton states be $n_{v}^{p}$. The amplitudes are of the form $t_{i_p j_p}^{a_p b_p}$.\nThe number of independent proton-proton amplitudes, $N_{pp}$, is:\n$$\nN_{pp} = \\binom{n_{o}^{p}}{2} \\binom{n_{v}^{p}}{2}\n$$\n\n**3. Neutron–Proton ($np$) Channel**\nIn this channel, the excitation involves one neutron and one proton. The amplitude corresponds to moving an occupied neutron-proton pair to a virtual neutron-proton pair, e.g., $t_{i_n j_p}^{a_n b_p}$. The indices $i_n, a_n$ are neutron states and $j_p, b_p$ are proton states.\nBecause neutrons and protons are distinguishable particles, there is no antisymmetry constraint upon exchanging a neutron index with a proton index. For example, $t_{i_n j_p}^{a_n b_p}$ and $t_{j_p i_n}^{a_n b_p}$ are entirely different amplitudes, as the latter would represent an excitation from an occupied proton-neutron state pair. The problem statement correctly notes that \"exchange across species does not create redundancy\".\nTherefore, to count the number of independent amplitudes, we simply count all possible combinations of one state from each of the four categories:\n- Number of choices for the occupied neutron state $i_n$: $n_{o}^{n}$\n- Number of choices for the occupied proton state $j_p$: $n_{o}^{p}$\n- Number of choices for the virtual neutron state $a_n$: $n_{v}^{n}$\n- Number of choices for the virtual proton state $b_p$: $n_{v}^{p}$\nThe total number of independent neutron-proton amplitudes, $N_{np}$, is the product of these counts:\n$$\nN_{np} = n_{o}^{n} \\cdot n_{o}^{p} \\cdot n_{v}^{n} \\cdot n_{v}^{p}\n$$\n\n**Total Number of Amplitudes**\nThe total number of stored doubles amplitudes, $N_{\\text{total}}$, is the sum of the counts from these three mutually exclusive blocks:\n$$\nN_{\\text{total}} = N_{nn} + N_{pp} + N_{np}\n$$\n\n**Calculation**\nWe are given the following parameters for the model space:\n- $n_{o}^{n} = 10$\n- $n_{v}^{n} = 30$\n- $n_{o}^{p} = 8$\n- $n_{v}^{p} = 24$\n\nNow, we compute the number of amplitudes for each block.\n\nFor the $nn$ block:\n$$\nN_{nn} = \\binom{10}{2} \\binom{30}{2} = \\left(\\frac{10 \\times 9}{2 \\times 1}\\right) \\left(\\frac{30 \\times 29}{2 \\times 1}\\right) = 45 \\times 435 = 19575\n$$\n\nFor the $pp$ block:\n$$\nN_{pp} = \\binom{8}{2} \\binom{24}{2} = \\left(\\frac{8 \\times 7}{2 \\times 1}\\right) \\left(\\frac{24 \\times 23}{2 \\times 1}\\right) = 28 \\times 276 = 7728\n$$\n\nFor the $np$ block:\n$$\nN_{np} = 10 \\times 8 \\times 30 \\times 24 = 80 \\times 720 = 57600\n$$\n\nFinally, the total number of stored amplitudes is the sum of these values:\n$$\nN_{\\text{total}} = N_{nn} + N_{pp} + N_{np} = 19575 + 7728 + 57600 = 84903\n$$\nThe total number of stored doubles amplitudes is $84903$.",
            "answer": "$$\\boxed{84903}$$"
        },
        {
            "introduction": "With an understanding of the size of the amplitude tensor, the next challenge is to solve the nonlinear CCD equations iteratively. A frequent and critical difficulty in this process is the emergence of \"intruder states,\" where near-zero energy denominators can cause numerical solvers to diverge. This hands-on practice  provides a computational laboratory to investigate this numerical breakdown, allowing you to quantify the ill-conditioning of the problem and test practical regularization techniques that are essential for building robust and reliable coupled-cluster codes.",
            "id": "3553397",
            "problem": "Consider a closed-shell reference state in computational nuclear physics and a model Hamiltonian written in second quantization. The Coupled-Cluster Doubles (CCD) approximation parameterizes the correlated ground state by an exponential ansatz with a doubles excitation operator acting on the reference. In iterative or Newton-like solution strategies, breakdown near intruder states can occur when energy denominators become small and the Jacobian of the residual with respect to the doubles amplitudes becomes ill-conditioned. In this problem you will formally define and then computationally quantify such breakdown and assess two regularization strategies.\n\nStart from the following foundational elements:\n\n- The single-particle orbital energies $\\epsilon_p$ define a mean-field partitioning. Indices $i,j$ denote occupied orbitals, and indices $a,b$ denote unoccupied (virtual) orbitals. Doubles excitations are built from pairs with $i<j$ and $a<b$.\n- The doubles denominators are defined by the difference of sums of orbital energies,\n$$D_{ij}^{ab} = \\epsilon_a + \\epsilon_b - \\epsilon_i - \\epsilon_j,$$\nwith all energies expressed in megaelectronvolts ($\\mathrm{MeV}$).\n- The antisymmetrized two-body interaction matrix elements $\\langle pq \\Vert rs \\rangle$ enter the CCD residual. For this task, you will use deterministic pseudorandom generation to model these quantities in $\\mathrm{MeV}$ for the required index combinations.\n- A linearized CCD residual map for doubles amplitudes $t_{ij}^{ab}$ is constructed such that the Jacobian with respect to the amplitudes has the structure\n$$J_{(ijab),(klcd)} = D_{ij}^{ab}\\,\\delta_{(ijab),(klcd)} - \\alpha\\, v_{ij}^{ab}\\, v_{kl}^{cd},$$\nwhere $v_{ij}^{ab} = \\langle ij \\Vert ab \\rangle$ and $\\alpha$ is a scalar with units $\\mathrm{MeV}^{-1}$. The condition number of $J$ in the $2$-norm, denoted $\\kappa_2(J)$, quantifies sensitivity and is dimensionless.\n\nYou will evaluate the following regularizations to mitigate breakdown near intruder states:\n\n1. A uniform denominator shift by a scalar $s$,\n$$D'_{ij}^{ab} = D_{ij}^{ab} + s,$$\nwith $s$ in $\\mathrm{MeV}$.\n\n2. An Epstein–Nesbet partitioning adjustment that augments the denominators by the difference of diagonal antisymmetrized interaction matrix elements in the excited and reference sectors,\n$$D_{ij}^{ab,\\mathrm{EN}} = D_{ij}^{ab} + \\left( W_{ab}^{ab} - W_{ij}^{ij} \\right),$$\nwhere $W_{ab}^{ab} = \\langle ab \\Vert ab \\rangle$ and $W_{ij}^{ij} = \\langle ij \\Vert ij \\rangle$, each in $\\mathrm{MeV}$.\n\nYour computational task is:\n\n- For each provided test case, generate the lists of occupied pairs $(i,j)$ with $i<j$ and virtual pairs $(a,b)$ with $a<b$, form all doubles excitations $(ij \\rightarrow ab)$, compute the raw denominators $D_{ij}^{ab}$, the shifted denominators $D'_{ij}^{ab}$, and the Epstein–Nesbet denominators $D_{ij}^{ab,\\mathrm{EN}}$.\n- Construct $v_{ij}^{ab}$ by deterministic pseudorandom sampling from a normal distribution with mean $0$ and standard deviation $0.5\\,\\mathrm{MeV}$ using the specified random seeds. Construct $W_{ij}^{ij}$ and $W_{ab}^{ab}$ similarly for each occupied and virtual pair, respectively, from the same seeded generator sequence.\n- Build the Jacobian matrices $J$ corresponding to the raw, shifted, and Epstein–Nesbet denominators using the rank-one coupling model above with the given $\\alpha$.\n- Compute the minimal absolute denominator across all $(ij \\rightarrow ab)$ excitations and the Jacobian condition number $\\kappa_2(J)$ in each of the three cases (raw, shifted, Epstein–Nesbet). Report the minimal denominators in $\\mathrm{MeV}$ as floating-point numbers and the condition numbers as floating-point numbers.\n\nUse the following test suite, designed to cover a general case, an exact intruder degeneracy, and an extreme near-degeneracy:\n\n- Test case $1$ (general well-separated): $n_\\mathrm{occ}=2$, $\\epsilon_\\mathrm{occ}=[-10.0,-9.0]\\,\\mathrm{MeV}$, $n_\\mathrm{vir}=3$, $\\epsilon_\\mathrm{vir}=[0.0,1.0,2.0]\\,\\mathrm{MeV}$, $\\alpha=0.2\\,\\mathrm{MeV}^{-1}$, $s=0.5\\,\\mathrm{MeV}$, seed $=42$.\n- Test case $2$ (exact intruder degeneracy): $n_\\mathrm{occ}=2$, $\\epsilon_\\mathrm{occ}=[-10.0,-9.0]\\,\\mathrm{MeV}$, $n_\\mathrm{vir}=3$, $\\epsilon_\\mathrm{vir}=[-10.0,-9.0,0.5]\\,\\mathrm{MeV}$, $\\alpha=0.2\\,\\mathrm{MeV}^{-1}$, $s=0.5\\,\\mathrm{MeV}$, seed $=123$.\n- Test case $3$ (near-degeneracy at the microelectronvolt scale): $n_\\mathrm{occ}=2$, $\\epsilon_\\mathrm{occ}=[-10.0,-9.0]\\,\\mathrm{MeV}$, $n_\\mathrm{vir}=3$, $\\epsilon_\\mathrm{vir}=[-10.0+10^{-6},-9.0,1.0]\\,\\mathrm{MeV}$, $\\alpha=0.2\\,\\mathrm{MeV}^{-1}$, $s=0.5\\,\\mathrm{MeV}$, seed $=7$.\n\nYour program must produce, for each test case in order, a list of six floating-point numbers:\n$[\\min |D|,\\ \\kappa_2(J_\\mathrm{raw}),\\ \\min |D'|,\\ \\kappa_2(J_\\mathrm{shift}),\\ \\min |D^{\\mathrm{EN}}|,\\ \\kappa_2(J_\\mathrm{EN})]$.\nAggregate the three per-case lists into a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[[r_{1,1},r_{1,2},\\ldots,r_{1,6}],[r_{2,1},\\ldots,r_{2,6}],[r_{3,1},\\ldots,r_{3,6}]]$.\n\nAll energies must be handled in $\\mathrm{MeV}$ and condition numbers are dimensionless. Angles are not involved. No percentages appear in this task. The output must adhere exactly to the specified single-line list format.",
            "solution": "The user's problem requires the quantitative analysis of numerical instability in a simplified model of the Coupled-Cluster Doubles (CCD) method, specifically focusing on the ill-conditioning of the Jacobian matrix near so-called \"intruder states.\" The solution involves constructing this Jacobian for three different definitions of the energy denominators (raw, uniformly shifted, and Epstein-Nesbet-style) and then computing metrics that characterize the instability.\n\nThe overall algorithmic design is as follows:\nFirst, for each test case, we must define the problem space. The space of doubles excitations is spanned by all possible promotions of two particles from occupied orbitals to virtual orbitals. Given $n_{\\mathrm{occ}}$ occupied orbitals indexed by $i, j$ and $n_{\\mathrm{vir}}$ virtual orbitals indexed by $a, b$, we form all unique occupied pairs $(i,j)$ with $i<j$ and virtual pairs $(a,b)$ with $a<b$. The total number of doubles excitations, $N_D$, which is the dimension of the Jacobian matrix, is the product of the number of such pairs: $N_D = \\binom{n_{\\mathrm{occ}}}{2} \\binom{n_{\\mathrm{vir}}}{2}$. A unique integer index $k \\in [0, N_D-1]$ is mapped to each excitation, denoted by the collective index $(ijab)$.\n\nSecond, we generate the necessary physical quantities. The problem provides a simplified, rank-one model for the Jacobian of the CCD residual with respect to the doubles amplitudes $t_{ij}^{ab}$:\n$$\nJ_{(ijab),(klcd)} = D_{ij}^{ab}\\,\\delta_{(ijab),(klcd)} - \\alpha\\, v_{ij}^{ab}\\, v_{kl}^{cd}\n$$\nIn matrix form, this can be written as $J = \\mathbf{D} - \\alpha \\vec{v}\\vec{v}^T$, where $\\mathbf{D}$ is a diagonal matrix of energy denominators and $\\vec{v}$ is a vector of two-body interaction matrix elements.\n\nThe procedure for generating the components for each test case is deterministic:\n1.  **Denominator Vector $\\vec{D}$**: Three versions of the denominator vector are constructed. An element $D_k$ of the vector corresponds to the excitation $(ij \\rightarrow ab)$.\n    -   **Raw**: $D_{ij}^{ab} = \\epsilon_a + \\epsilon_b - \\epsilon_i - \\epsilon_j$.\n    -   **Shifted**: $D'_{ij}^{ab} = D_{ij}^{ab} + s$, using the given scalar shift $s$.\n    -   **Epstein-Nesbet (EN)**: $D_{ij}^{ab,\\mathrm{EN}} = D_{ij}^{ab} + (W_{ab}^{ab} - W_{ij}^{ij})$.\n    The single-particle energies $\\epsilon_p$ are provided in each test case.\n2.  **Interaction Terms**: The interaction matrix elements are generated using a seeded pseudorandom number generator sampling from a normal distribution with mean $0$ and standard deviation $0.5\\,\\mathrm{MeV}$. To ensure reproducibility, the random numbers are generated in a strict order:\n    a. The vector $\\vec{v}$ of elements $v_{ij}^{ab} = \\langle ij \\Vert ab \\rangle$ is generated, one element for each of the $N_D$ excitations.\n    b. The diagonal elements for occupied pairs, $W_{ij}^{ij} = \\langle ij \\Vert ij \\rangle$, are generated, one for each unique pair $(i,j)$.\n    c. The diagonal elements for virtual pairs, $W_{ab}^{ab} = \\langle ab \\Vert ab \\rangle$, are generated, one for each unique pair $(a,b)$.\n\nThird, we compute the required metrics for each of the three denominator schemes (raw, shifted, EN).\n1.  **Minimal Absolute Denominator**: For each of the three denominator vectors ($\\vec{D}_{\\mathrm{raw}}$, $\\vec{D}_{\\mathrm{shift}}$, $\\vec{D}_{\\mathrm{EN}}$), the minimum of the absolute values of its elements, e.g., $\\min |D|$, is calculated. This value directly indicates proximity to a degeneracy, where a denominator approaches zero.\n2.  **Jacobian Condition Number**: For each denominator scheme, the corresponding Jacobian matrix ($J_{\\mathrm{raw}}$, $J_{\\mathrm{shift}}$, $J_{\\mathrm{EN}}$) is constructed. The $2$-norm condition number, $\\kappa_2(J)$, is then computed. The condition number quantifies the sensitivity of the solution of a linear system involving $J$ to perturbations in the input. A large or infinite condition number signals the numerical breakdown associated with intruder states. This is calculated using `numpy.linalg.cond`.\n\nFinally, the results for each test case—a set of six floating-point numbers comprising the three minimal denominators and three condition numbers—are aggregated and formatted into a single-line string representing a list of lists, as specified. This process is repeated for all test cases. The implementation uses `numpy` for numerical linear algebra and `itertools.combinations` to systematically generate the particle-hole excitation space.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport itertools\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the formatted results.\n    \"\"\"\n    # Test cases as defined in the problem statement.\n    # Structure: (n_occ, eps_occ, n_vir, eps_vir, alpha, s, seed)\n    test_cases = [\n        (2, [-10.0, -9.0], 3, [0.0, 1.0, 2.0], 0.2, 0.5, 42),\n        (2, [-10.0, -9.0], 3, [-10.0, -9.0, 0.5], 0.2, 0.5, 123),\n        (2, [-10.0, -9.0], 3, [-10.0 + 1e-6, -9.0, 1.0], 0.2, 0.5, 7),\n    ]\n\n    all_results = []\n    for case_params in test_cases:\n        results = process_case(*case_params)\n        all_results.append(results)\n\n    # Format the final output string as a list of lists, without spaces.\n    case_strings = []\n    for res_list in all_results:\n        case_strings.append(f\"[{','.join(map(str, res_list))}]\")\n    \n    final_output_string = f\"[{','.join(case_strings)}]\"\n    print(final_output_string)\n\ndef process_case(n_occ, eps_occ, n_vir, eps_vir, alpha, s, seed):\n    \"\"\"\n    Computes the required metrics for a single test case.\n    \n    Args:\n        n_occ (int): Number of occupied orbitals.\n        eps_occ (list): List of occupied orbital energies.\n        n_vir (int): Number of virtual orbitals.\n        eps_vir (list): List of virtual orbital energies.\n        alpha (float): Coupling constant for the Jacobian.\n        s (float): Uniform denominator shift value.\n        seed (int): Seed for the pseudorandom number generator.\n\n    Returns:\n        list: A list of six floating-point numbers representing the computed metrics.\n    \"\"\"\n    # 1. Initialize the deterministic random number generator.\n    rng = np.random.default_rng(seed)\n\n    # 2. Generate the doubles excitation space.\n    occ_pairs = list(itertools.combinations(range(n_occ), 2))\n    vir_pairs = list(itertools.combinations(range(n_vir), 2))\n    \n    num_occ_pairs = len(occ_pairs)\n    num_vir_pairs = len(vir_pairs)\n    num_doubles = num_occ_pairs * num_vir_pairs\n    \n    # Early exit if no doubles excitations are possible.\n    if num_doubles == 0:\n        return [np.nan] * 6\n\n    # Create a canonical mapping from an excitation index k to the orbital indices (i,j,a,b).\n    excitations = []\n    for i, j in occ_pairs:\n        for a, b in vir_pairs:\n            excitations.append({'occ': (i, j), 'vir': (a, b)})\n    \n    occ_pair_map = {pair: i for i, pair in enumerate(occ_pairs)}\n    vir_pair_map = {pair: i for i, pair in enumerate(vir_pairs)}\n\n    # 3. Generate interaction matrix elements in a fixed, deterministic order.\n    # v_ij^ab for all doubles excitations\n    v_vec = rng.normal(loc=0.0, scale=0.5, size=num_doubles)\n    \n    # W_ij^ij for all occupied pairs\n    w_occ_diag = rng.normal(loc=0.0, scale=0.5, size=num_occ_pairs)\n    \n    # W_ab^ab for all virtual pairs\n    w_vir_diag = rng.normal(loc=0.0, scale=0.5, size=num_vir_pairs)\n\n    # 4. Compute the three types of denominators.\n    D_raw = np.zeros(num_doubles)\n    D_en = np.zeros(num_doubles)\n    \n    for k, exc in enumerate(excitations):\n        i, j = exc['occ']\n        a, b = exc['vir']\n        \n        # Raw Møller-Plesset denominator\n        d_raw = eps_vir[a] + eps_vir[b] - eps_occ[i] - eps_occ[j]\n        D_raw[k] = d_raw\n        \n        # Epstein-Nesbet denominator\n        occ_pair_idx = occ_pair_map[(i, j)]\n        vir_pair_idx = vir_pair_map[(a, b)]\n        en_correction = w_vir_diag[vir_pair_idx] - w_occ_diag[occ_pair_idx]\n        D_en[k] = d_raw + en_correction\n\n    # Uniformly shifted denominator\n    D_shifted = D_raw + s\n\n    # 5. Compute minimal absolute denominators.\n    min_abs_D_raw = np.min(np.abs(D_raw))\n    min_abs_D_shifted = np.min(np.abs(D_shifted))\n    min_abs_D_en = np.min(np.abs(D_en))\n\n    # 6. Build Jacobians and compute condition numbers.\n    def get_kappa(D_vec, v_vec, alpha_val):\n        \"\"\"Helper to build Jacobian and compute its 2-norm condition number.\"\"\"\n        J = np.diag(D_vec) - alpha_val * np.outer(v_vec, v_vec)\n        return np.linalg.cond(J, p=2)\n\n    kappa_raw = get_kappa(D_raw, v_vec, alpha)\n    kappa_shifted = get_kappa(D_shifted, v_vec, alpha)\n    kappa_en = get_kappa(D_en, v_vec, alpha)\n    \n    # 7. Aggregate and return the six computed metrics.\n    return [\n        min_abs_D_raw, kappa_raw,\n        min_abs_D_shifted, kappa_shifted,\n        min_abs_D_en, kappa_en\n    ]\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "A stable CCD algorithm is only useful if it can be run in a reasonable amount of time. The computational cost of coupled-cluster methods is dominated by a series of complex tensor contractions, with some terms scaling as high as $n_v^4 n_o^2$. This final exercise  shifts the focus from algorithmic stability to computational performance, teaching you how to analyze a dominant contraction using the roofline model. By calculating the arithmetic intensity and predicting performance on different architectures like CPUs and GPUs, you will learn to identify computational bottlenecks and understand the interplay between algorithms and hardware.",
            "id": "3553409",
            "problem": "You are to implement a complete program that models the computational performance of a contraction appearing in the Coupled Cluster Doubles (CCD) approximation used in computational nuclear physics. The focus is the contraction term $W_{ab}^{ef} t_{ij}^{ef}$ that contributes to the doubles residual. Derive and compute the arithmetic intensity and roofline performance prediction for this contraction when mapped to dense matrix multiplication, and predict the speedup of a Graphics Processing Unit (GPU) over a Central Processing Unit (CPU).\n\nStart from the following foundational bases:\n- The time-independent Schrödinger equation $H|\\Psi\\rangle = E|\\Psi\\rangle$ with a coupled-cluster parametrization $|\\Psi\\rangle = e^{T}|\\Phi_0\\rangle$, truncated at the doubles level so that $T = T_2$.\n- The contraction $W_{ab}^{ef} t_{ij}^{ef}$ sums over the indices $e$ and $f$; $a$, $b$ label virtual orbitals and $i$, $j$ label occupied orbitals. Model this contraction as a dense matrix multiplication by grouping $(a,b)$ into one composite row index, $(e,f)$ into one composite inner dimension index, and $(i,j)$ into one composite column index, so that a matrix $A$ of shape $(M,K)$ multiplies a matrix $B$ of shape $(K,N)$ to produce a matrix $C$ of shape $(M,N)$, where $M = n_v^2$, $K = n_v^2$, and $N = n_o^2$ for $n_v$ virtual orbitals and $n_o$ occupied orbitals.\n- Assume double-precision floating point numbers, each occupying $8$ bytes.\n\nYou must do the following for each test case:\n1. Compute the total floating-point operations (FLOPs) required by the dense matrix multiplication mapping of the contraction, using a well-tested arithmetic model for dense general matrix multiplication.\n2. Compute a lower bound on data movement between main memory and the processor using a well-tested bandwidth model that accounts for reading both input matrices once and writing the output matrix once, under ideal tiling and reuse assumptions.\n3. Derive the arithmetic intensity $I$ defined as FLOPs per byte moved.\n4. Using the roofline model, predict the sustained performance for both the Central Processing Unit (CPU) and the Graphics Processing Unit (GPU) in gigaflops per second (GFLOP/s): $P = \\min(P_{\\text{peak}}, I B)$, where $P_{\\text{peak}}$ is peak floating-point performance, $B$ is memory bandwidth, and $I$ is arithmetic intensity. Clarify whether the computation is memory-bound or compute-bound by comparing $I B$ to $P_{\\text{peak}}$.\n5. Compute the speedup $S$ (dimensionless) as the ratio of predicted GPU performance to predicted CPU performance.\n\nHardware parameters to use for all test cases:\n- CPU peak double-precision performance $P_{\\text{CPU,peak}} = 500$ GFLOP/s.\n- CPU memory bandwidth $B_{\\text{CPU}} = 100$ GB/s.\n- GPU peak double-precision performance $P_{\\text{GPU,peak}} = 5000$ GFLOP/s.\n- GPU memory bandwidth $B_{\\text{GPU}} = 800$ GB/s.\n\nAll numerical answers involving performance must be expressed in gigaflops per second (GFLOP/s). All bandwidths are in gigabytes per second (GB/s). The speedup must be expressed as a decimal ratio without a unit. The arithmetic intensity must be expressed as a float in units of FLOPs per byte. Angles are not involved. Use double precision ($8$ bytes per number).\n\nTest suite:\n- Case $1$: $n_o = 2$, $n_v = 2$.\n- Case $2$: $n_o = 8$, $n_v = 8$.\n- Case $3$: $n_o = 8$, $n_v = 20$.\n- Case $4$: $n_o = 64$, $n_v = 64$.\n- Case $5$: $n_o = 1$, $n_v = 64$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, append four floats in this order: arithmetic intensity $I$, predicted CPU performance $P_{\\text{CPU}}$ in GFLOP/s, predicted GPU performance $P_{\\text{GPU}}$ in GFLOP/s, and predicted speedup $S$. The overall output is thus a flat list of $4 \\times 5 = 20$ floats. Each float must be rounded to $6$ decimal places. For example, the output should have the form $[I_1,P_{\\text{CPU},1},P_{\\text{GPU},1},S_1,\\dots,I_5,P_{\\text{CPU},5},P_{\\text{GPU},5},S_5]$.",
            "solution": "The coupled-cluster method starts from the time-independent Schrödinger equation $H|\\Psi\\rangle = E|\\Psi\\rangle$ and the coupled-cluster ansatz $|\\Psi\\rangle = e^{T}|\\Phi_0\\rangle$, where $|\\Phi_0\\rangle$ is a reference Slater determinant and $T$ is the cluster operator. In the Coupled Cluster Doubles (CCD) approximation, the truncation $T = T_2$ retains only double excitations, which dominate the computational cost in many nuclear structure applications.\n\nWithin CCD, the doubles amplitude equations contain contractions involving intermediates $W$ and the doubles amplitudes $t$. A representative term is $W_{ab}^{ef} t_{ij}^{ef}$, which sums over the virtual indices $e$ and $f$ for each combination of $(a,b,i,j)$. To analyze computational complexity and performance, we map this contraction onto dense general matrix multiplication (often referred to as GEMM). We form composite indices:\n- $(a,b)$ becomes a single row index for matrix $A$, with size $M = n_v^2$.\n- $(e,f)$ becomes the inner dimension index with size $K = n_v^2$.\n- $(i,j)$ becomes a single column index for matrix $B$, with size $N = n_o^2$.\n\nThe contraction $W_{ab}^{ef} t_{ij}^{ef}$ is then equivalent to computing $C = A \\times B$, where $A \\in \\mathbb{R}^{M \\times K}$, $B \\in \\mathbb{R}^{K \\times N}$, and $C \\in \\mathbb{R}^{M \\times N}$, with $C_{ab}^{ij}$ as the output mapped back to the composite indices.\n\nWe now derive the arithmetic intensity using well-established performance models for dense matrix multiplication and memory traffic:\n- The total number of floating-point operations for multiplying an $(M \\times K)$ matrix by a $(K \\times N)$ matrix is\n$$\n\\text{FLOPs} = 2 M N K,\n$$\ncounting one multiply and one add per inner-dimension contribution to each output element.\n- Under ideal tiling and reuse, a lower bound on data movement between main memory and the processor is given by reading $A$ and $B$ once and writing $C$ once. With double precision, each element occupies $8$ bytes. Therefore, a lower bound on bytes transferred is\n$$\n\\text{Bytes}_{\\min} = 8 \\left(MK + KN + MN\\right).\n$$\nThis lower bound assumes optimized blocking such that each input element is reused as much as possible in cache or on-chip memory, and the output elements are accumulated in registers and written once.\n\nThe arithmetic intensity, defined as floating-point operations per byte moved, is thus\n$$\nI = \\frac{\\text{FLOPs}}{\\text{Bytes}_{\\min}} = \\frac{2 M N K}{8 \\left(MK + KN + MN\\right)} = \\frac{M N K}{4 \\left(MK + KN + MN\\right)}.\n$$\n\nThe roofline model connects arithmetic intensity to sustained performance. For a processor with peak double-precision floating-point performance $P_{\\text{peak}}$ (in GFLOP/s) and memory bandwidth $B$ (in GB/s), the predicted sustained performance $P$ (in GFLOP/s) is\n$$\nP = \\min\\left(P_{\\text{peak}}, I \\, B\\right).\n$$\nIf $I B < P_{\\text{peak}}$, the computation is memory-bound; otherwise, it is compute-bound.\n\nWe consider two devices: a Central Processing Unit (CPU) and a Graphics Processing Unit (GPU). Given $P_{\\text{CPU,peak}}$, $B_{\\text{CPU}}$, $P_{\\text{GPU,peak}}$, and $B_{\\text{GPU}}$, the predicted performances are\n$$\nP_{\\text{CPU}} = \\min\\left(P_{\\text{CPU,peak}}, I \\, B_{\\text{CPU}}\\right), \\quad\nP_{\\text{GPU}} = \\min\\left(P_{\\text{GPU,peak}}, I \\, B_{\\text{GPU}}\\right).\n$$\nThe speedup is the dimensionless ratio\n$$\nS = \\frac{P_{\\text{GPU}}}{P_{\\text{CPU}}}.\n$$\n\nFor each test case, we compute $M = n_v^2$, $K = n_v^2$, $N = n_o^2$, then apply the formulas above to obtain $I$, $P_{\\text{CPU}}$, $P_{\\text{GPU}}$, and $S$. The units are:\n- Arithmetic intensity $I$ in FLOPs per byte.\n- Predicted performances $P_{\\text{CPU}}$ and $P_{\\text{GPU}}$ in GFLOP/s.\n- Speedup $S$ is dimensionless.\n\nWe use the following hardware parameters for all cases: $P_{\\text{CPU,peak}} = 500$ GFLOP/s, $B_{\\text{CPU}} = 100$ GB/s, $P_{\\text{GPU,peak}} = 5000$ GFLOP/s, $B_{\\text{GPU}} = 800$ GB/s. Each numerical result is rounded to $6$ decimal places and the outputs for all test cases are concatenated into a single flat list in the order $[I, P_{\\text{CPU}}, P_{\\text{GPU}}, S]$ for each case.\n\nThis approach provides a principled roofline analysis for the dominant CCD contraction mapped to a dense matrix multiplication, clarifies whether the contraction is memory-bound or compute-bound for different problem sizes, and predicts GPU speedup over CPU.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef roofline_predictions(n_o, n_v, cpu_peak_gflops, cpu_bw_gbs, gpu_peak_gflops, gpu_bw_gbs, dtype_bytes=8):\n    # Map CCD contraction W_ab^{ef} t_ij^{ef} to GEMM with composite indices:\n    # M = n_v^2 (rows A and C), K = n_v^2 (inner dimension), N = n_o^2 (cols B and C)\n    M = n_v * n_v\n    K = n_v * n_v\n    N = n_o * n_o\n\n    # FLOPs for dense GEMM: 2 * M * N * K\n    flops = 2.0 * M * N * K\n\n    # Minimal bytes moved under ideal tiling: read A and B once, write C once\n    bytes_min = dtype_bytes * (M * K + K * N + M * N)\n\n    # Arithmetic intensity: FLOPs per byte\n    intensity = flops / bytes_min if bytes_min > 0 else 0.0\n\n    # Roofline predicted performance\n    cpu_perf = min(cpu_peak_gflops, intensity * cpu_bw_gbs)\n    gpu_perf = min(gpu_peak_gflops, intensity * gpu_bw_gbs)\n\n    # Speedup GPU vs CPU\n    speedup = gpu_perf / cpu_perf if cpu_perf > 0 else float('inf')\n\n    return intensity, cpu_perf, gpu_perf, speedup\n\ndef solve():\n    # Hardware parameters (double precision)\n    cpu_peak_gflops = 500.0   # GFLOP/s\n    cpu_bw_gbs = 100.0        # GB/s\n    gpu_peak_gflops = 5000.0  # GFLOP/s\n    gpu_bw_gbs = 800.0        # GB/s\n    dtype_bytes = 8           # bytes per double\n\n    # Define the test cases from the problem statement.\n    # Each case is (n_o, n_v)\n    test_cases = [\n        (2, 2),    # Case 1: small, likely memory-bound\n        (8, 8),    # Case 2: moderate, mixed-bound behavior possible\n        (8, 20),   # Case 3: typical nuclear sizes, likely compute-bound\n        (64, 64),  # Case 4: large, compute-bound\n        (1, 64),   # Case 5: boundary case with N=1, likely memory-bound\n    ]\n\n    results = []\n    for n_o, n_v in test_cases:\n        intensity, cpu_perf, gpu_perf, speedup = roofline_predictions(\n            n_o, n_v, cpu_peak_gflops, cpu_bw_gbs, gpu_peak_gflops, gpu_bw_gbs, dtype_bytes\n        )\n        # Round to 6 decimal places as required and append in the specified order\n        results.extend([\n            f\"{intensity:.6f}\",\n            f\"{cpu_perf:.6f}\",\n            f\"{gpu_perf:.6f}\",\n            f\"{speedup:.6f}\",\n        ])\n\n    # Final print statement in the exact required format (single line, comma-separated list in brackets).\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}