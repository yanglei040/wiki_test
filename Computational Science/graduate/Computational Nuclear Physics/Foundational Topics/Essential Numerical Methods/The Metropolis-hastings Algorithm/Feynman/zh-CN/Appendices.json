{
    "hands_on_practices": [
        {
            "introduction": "在许多物理问题中，模型的参数需要满足特定的物理约束。在贝叶斯框架中，一种巧妙的处理方法是引入拉格朗日乘子，将约束柔和地纳入后验分布中，从而构成一个增广的目标空间。本练习  将指导你如何为这样一个增广系统推导正确的Metropolis-Hastings接受概率，并特别关注如何处理常用于乘子的非对称提议分布，这对于保证细致平衡条件至关重要。",
            "id": "3604490",
            "problem": "考虑在饱和密度 $\\rho_{0} = 0.16$ $\\mathrm{fm}^{-3}$ 下建模的对称核物质，其中每个核子的能量由一个类 Skyrme 平均场代理模型 $E/A(\\theta)$ 表示，其参数矢量为 $\\theta = (t_{0}, t_{3}, \\sigma)$。定义\n$$\n\\frac{E(\\theta)}{A} \\equiv \\alpha + \\beta\\, t_{0} + \\zeta\\, t_{3}\\, \\rho_{0}^{\\sigma},\n$$\n其中已知常数为 $\\alpha = 22$，$\\beta = 0.02$ 和 $\\zeta = -0.001$。为强制执行体性质 $\\frac{E(\\theta)}{A} = E_{0}$（其中 $E_{0} = -16$），引入一个正的拉格朗日乘子 $\\lambda$，并根据以下公式增广 $(\\theta, \\lambda)$ 的后验分布\n$$\n\\pi(\\theta,\\lambda) \\propto p(D \\mid \\theta)\\, \\exp\\!\\big[-\\lambda\\big(\\tfrac{E(\\theta)}{A} - E_{0}\\big)\\big]\\, p(\\theta)\\, p(\\lambda),\n$$\n其中 $p(D \\mid \\theta)$ 是数据似然，$p(\\theta)$ 是 $\\theta$ 的先验，$p(\\lambda)$ 是 $\\lambda$ 的先验。观测代理数据由高斯似然建模\n$$\np(D \\mid \\theta) \\propto \\exp\\!\\Big(-\\frac{(y(\\theta) - y_{D})^{2}}{2 s^{2}}\\Big),\n$$\n其中 $y(\\theta) \\equiv d_{0} + d_{1}\\, t_{0} + d_{3}\\, t_{3}$，$d_{0} = 0$，$d_{1} = 0.001$，$d_{3} = -0.00005$，$y_{D} = 5$，以及 $s = 2$。假设独立的先验高斯分布\n$$\nt_{0} \\sim \\mathcal{N}(\\mu_{0}, \\sigma_{0}^{2}), \\quad t_{3} \\sim \\mathcal{N}(\\mu_{3}, \\sigma_{3}^{2}), \\quad \\sigma \\sim \\mathcal{N}(\\mu_{\\sigma}, \\sigma_{\\sigma}^{2}),\n$$\n其中 $(\\mu_{0}, \\sigma_{0}) = (-1900, 300)$，$(\\mu_{3}, \\sigma_{3}) = (13000, 2000)$，$(\\mu_{\\sigma}, \\sigma_{\\sigma}) = (0.5, 0.05)$，以及 $\\lambda$ 的 Gamma 先验\n$$\n\\lambda \\sim \\mathrm{Gamma}(a,b), \\quad a = 2, \\quad b = 1,\n$$\n其密度为 $p(\\lambda) \\propto \\lambda^{a-1} \\exp(-b \\lambda)$。考虑在增广空间 $(\\theta,\\lambda)$ 上的 Metropolis-Hastings (MH) 采样器，其建议分布如下：\n- 对 $\\theta$ 的对称高斯随机游走建议：$\\theta' = \\theta + \\xi$，其中 $\\xi \\sim \\mathcal{N}(0, \\Sigma_{q})$，$\\Sigma_{q}$ 是一个固定的正定协方差矩阵。\n- 对 $\\ln \\lambda$ 的随机游走：$\\ln \\lambda' = \\ln \\lambda + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0, s_{\\ell}^{2})$，这意味着边际建议密度 $q(\\lambda' \\mid \\lambda)$ 是对数正态的。\n\n任务：\n1. 从贝叶斯定理和 Metropolis-Hastings (MH) 接受概率的定义出发，推导针对此增广目标 $\\pi(\\theta,\\lambda)$ 和指定建议分布的一般 MH 接受概率 $\\alpha\\big((\\theta,\\lambda) \\to (\\theta',\\lambda')\\big)$。您的推导必须明确说明由 $\\lambda$ 的对数正态建议分布引起的建议分布不对称性。\n2. 使用以下数值，计算从当前状态 $(\\theta,\\lambda)$ 到建议状态 $(\\theta',\\lambda')$ 的单次更新的接受概率：\n   - 当前状态：$t_{0} = -1800$, $t_{3} = 14000$, $\\sigma = 0.5$, $\\lambda = 0.8$。\n   - 建议状态：$t_{0}' = -1750$, $t_{3}' = 15000$, $\\sigma' = 0.45$, $\\lambda' = 1.1$。\n使用上面给出的量和模型，不要进行任何额外的近似。将您最终的接受概率数值答案表示为纯小数，并四舍五入到四位有效数字。",
            "solution": "该问题要求完成两项任务：首先，为给定的增广后验和建议机制推导通用的 Metropolis-Hastings (MH) 接受概率；其次，为特定的状态转移计算此概率。\n\n## 第1部分：接受概率的推导\n\n马尔可夫链的状态由向量 $X = (\\theta, \\lambda)$ 给出，其中 $\\theta = (t_0, t_3, \\sigma)$。目标分布是后验分布 $\\pi(\\theta, \\lambda)$。从当前状态 $X$ 移动到建议状态 $X'$ 的 MH 接受概率 $\\alpha(X \\to X')$ 定义为：\n$$\n\\alpha(X \\to X') = \\min\\left(1, R\\right)\n$$\n其中 $R$ 是 Hastings 比率，由下式给出：\n$$\nR = \\frac{\\pi(X') q(X|X')}{\\pi(X) q(X'|X)}\n$$\n此处，$\\pi(X) = \\pi(\\theta, \\lambda)$ 是目标后验密度，$q(X'|X)$ 是建议密度。\n\n建议分布可分解为 $\\theta$ 和 $\\lambda$ 的独立建议：$q(X'|X) = q(\\theta'|\\theta)q(\\lambda'|\\lambda)$。\n\n1.  **$\\theta$ 的建议比率**：对 $\\theta$ 的建议是一个对称高斯随机游走，$\\theta' = \\theta + \\xi$，其中 $\\xi \\sim \\mathcal{N}(0, \\Sigma_q)$。建议密度为 $q(\\theta'|\\theta) = \\mathcal{N}(\\theta'; \\theta, \\Sigma_q)$。高斯密度的一个关键性质是其参数的对称性，即 $\\mathcal{N}(\\theta'; \\theta, \\Sigma_q) = \\mathcal{N}(\\theta; \\theta', \\Sigma_q)$。因此，$q(\\theta'|\\theta) = q(\\theta|\\theta')$，$\\theta$ 的建议比率为1：\n    $$\n    \\frac{q(\\theta|\\theta')}{q(\\theta'|\\theta)} = 1\n    $$\n\n2.  **$\\lambda$ 的建议比率**：对 $\\lambda$ 的建议是在 $\\lambda$ 的对数上进行随机游走，即 $\\ln \\lambda' = \\ln \\lambda + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0, s_\\ell^2)$。设 $g(\\eta)$ 是 $\\eta$ 的密度，它是对称的：$g(\\eta) = g(-\\eta)$。为求得建议密度 $q(\\lambda'|\\lambda)$，我们使用变量变换公式。令 $u = \\ln \\lambda$，则建议为 $u' = u + \\eta$。用 $u$ 表示的建议密度为 $q_u(u'|u) = g(u'-u)$。那么 $\\lambda$ 的建议密度为：\n    $$\n    q(\\lambda'|\\lambda) = q_u(\\ln\\lambda'|\\ln\\lambda) \\left|\\frac{d(\\ln \\lambda')}{d\\lambda'}\\right| = g(\\ln\\lambda' - \\ln\\lambda) \\frac{1}{\\lambda'}\n    $$\n    类似地，逆向建议密度为：\n    $$\n    q(\\lambda|\\lambda') = g(\\ln\\lambda - \\ln\\lambda') \\frac{1}{\\lambda}\n    $$\n    因此，$\\lambda$ 的建议比率为：\n    $$\n    \\frac{q(\\lambda|\\lambda')}{q(\\lambda'|\\lambda)} = \\frac{g(\\ln\\lambda - \\ln\\lambda') / \\lambda}{g(\\ln\\lambda' - \\ln\\lambda) / \\lambda'} = \\frac{g(-(\\ln\\lambda' - \\ln\\lambda)) / \\lambda}{g(\\ln\\lambda' - \\ln\\lambda) / \\lambda'}\n    $$\n    利用 $g$ 的对称性，这可以简化为众所周知雅可比校正因子：\n    $$\n    \\frac{q(\\lambda|\\lambda')}{q(\\lambda'|\\lambda)} = \\frac{1/\\lambda}{1/\\lambda'} = \\frac{\\lambda'}{\\lambda}\n    $$\n\n结合这些结果，完整的建议比率为 $\\frac{q(X|X')}{q(X'|X)} = \\frac{\\lambda'}{\\lambda}$。\n\nHastings 比率 $R$ 变为：\n$$\nR = \\frac{\\pi(\\theta', \\lambda')}{\\pi(\\theta, \\lambda)} \\frac{\\lambda'}{\\lambda}\n$$\n\n现在我们来表示后验密度的比率。后验分布由下式给出：\n$$\n\\pi(\\theta,\\lambda) \\propto p(D \\mid \\theta)\\, \\exp\\!\\big[-\\lambda\\big(\\tfrac{E(\\theta)}{A} - E_{0}\\big)\\big]\\, p(\\theta)\\, p(\\lambda)\n$$\n该比率为：\n$$\n\\frac{\\pi(\\theta', \\lambda')}{\\pi(\\theta, \\lambda)} = \\frac{p(D \\mid \\theta')}{p(D \\mid \\theta)} \\frac{\\exp[-\\lambda'(\\frac{E(\\theta')}{A}-E_0)]}{\\exp[-\\lambda(\\frac{E(\\theta)}{A}-E_0)]} \\frac{p(\\theta')}{p(\\theta)} \\frac{p(\\lambda')}{p(\\lambda)}\n$$\n让我们分析比率中的每一项：\n-   **似然比**： $p(D \\mid \\theta) \\propto \\exp(-\\frac{(y(\\theta) - y_{D})^{2}}{2 s^{2}})$\n    $$\n    \\frac{p(D \\mid \\theta')}{p(D \\mid \\theta)} = \\exp\\left( \\frac{(y(\\theta) - y_{D})^{2} - (y(\\theta') - y_{D})^{2}}{2 s^{2}} \\right)\n    $$\n-   **约束项比率**：\n    $$\n    \\frac{\\exp[-\\lambda'(\\frac{E(\\theta')}{A}-E_0)]}{\\exp[-\\lambda(\\frac{E(\\theta)}{A}-E_0)]} = \\exp\\left( \\lambda\\left(\\tfrac{E(\\theta)}{A} - E_{0}\\right) - \\lambda'\\left(\\tfrac{E(\\theta')}{A} - E_{0}\\right) \\right)\n    $$\n-   **参数先验比率**：由于独立性，$p(\\theta) = p(t_0)p(t_3)p(\\sigma)$。\n    $$\n    \\frac{p(\\theta')}{p(\\theta)} = \\frac{p(t_0')}{p(t_0)} \\frac{p(t_3')}{p(t_3)} \\frac{p(\\sigma')}{p(\\sigma)}\n    $$\n    对于一个通用的高斯先验 $x \\sim \\mathcal{N}(\\mu_x, \\sigma_x^2)$，其比率为 $\\frac{p(x')}{p(x)} = \\exp\\left( \\frac{(x - \\mu_x)^2 - (x' - \\mu_x)^2}{2\\sigma_x^2} \\right)$。\n-   **拉格朗日乘子先验比率**：$\\lambda \\sim \\mathrm{Gamma}(a,b)$，所以 $p(\\lambda) \\propto \\lambda^{a-1} \\exp(-b\\lambda)$。\n    $$\n    \\frac{p(\\lambda')}{p(\\lambda)} = \\frac{(\\lambda')^{a-1}\\exp(-b\\lambda')}{\\lambda^{a-1}\\exp(-b\\lambda)} = \\left(\\frac{\\lambda'}{\\lambda}\\right)^{a-1} \\exp(-b(\\lambda' - \\lambda))\n    $$\n将 $\\lambda$ 的先验比率与建议比率 $\\lambda'/\\lambda$ 结合：\n$$\n\\frac{p(\\lambda')}{p(\\lambda)} \\frac{\\lambda'}{\\lambda} = \\left(\\frac{\\lambda'}{\\lambda}\\right)^{a-1} \\exp(-b(\\lambda' - \\lambda)) \\frac{\\lambda'}{\\lambda} = \\left(\\frac{\\lambda'}{\\lambda}\\right)^{a} \\exp(-b(\\lambda' - \\lambda))\n$$\n最后，整合所有部分，Hastings 比率 $R$ 为：\n$$\nR = \\left(\\frac{\\lambda'}{\\lambda}\\right)^{a} \\exp\\left(-b(\\lambda' - \\lambda)\\right) \\times \\exp\\left( \\frac{(y(\\theta) - y_{D})^{2} - (y(\\theta') - y_{D})^{2}}{2 s^{2}} \\right) \\times \\exp\\left( \\lambda\\left(\\tfrac{E(\\theta)}{A} - E_{0}\\right) - \\lambda'\\left(\\tfrac{E(\\theta')}{A} - E_{0}\\right) \\right) \\times \\prod_{i \\in \\{0,3,\\sigma\\}} \\exp\\left( \\frac{(x_i - \\mu_i)^2 - (x_i' - \\mu_i)^2}{2\\sigma_i^2} \\right)\n$$\n其中乘积遍及参数 $t_0, t_3, \\sigma$。接受概率为 $\\alpha = \\min(1,R)$。\n\n## 第2部分：数值计算\n\n我们已知当前状态 $(\\theta, \\lambda)$ 和建议状态 $(\\theta', \\lambda')$，以及所有必要的常数和模型参数。我们接下来计算 Hastings 比率 $R$ 的每一项。\n\n**给定值：**\n-   当前状态：$t_0 = -1800$, $t_3 = 14000$, $\\sigma = 0.5$, $\\lambda = 0.8$。\n-   建议状态：$t'_0 = -1750$, $t'_3 = 15000$, $\\sigma' = 0.45$, $\\lambda' = 1.1$。\n-   常数：$\\rho_0=0.16$, $\\alpha=22$, $\\beta=0.02$, $\\zeta=-0.001$, $E_0=-16$。\n-   似然：$d_0=0$, $d_1=0.001$, $d_3=-0.00005$, $y_D=5$, $s=2$。\n-   先验：$(\\mu_0, \\sigma_0) = (-1900, 300)$, $(\\mu_3, \\sigma_3) = (13000, 2000)$, $(\\mu_\\sigma, \\sigma_\\sigma) = (0.5, 0.05)$。\n-   Gamma 先验：$a=2, b=1$。\n\n**1. 似然比：**\n$y(\\theta) = d_1 t_0 + d_3 t_3 = 0.001(-1800) - 0.00005(14000) = -1.8 - 0.7 = -2.5$。\n$y(\\theta') = d_1 t'_0 + d_3 t'_3 = 0.001(-1750) - 0.00005(15000) = -1.75 - 0.75 = -2.5$。\n由于 $y(\\theta) = y(\\theta')$, 似然比为 $\\exp(0) = 1$。\n\n**2. 约束项比率：**\n$E/A(\\theta) = \\alpha + \\beta t_0 + \\zeta t_3 \\rho_0^\\sigma = 22 + 0.02(-1800) - 0.001(14000)(0.16)^{0.5} = 22 - 36 - 14(0.4) = -19.6$。\n$E/A(\\theta') = \\alpha + \\beta t'_0 + \\zeta t'_3 \\rho_0^{\\sigma'} = 22 + 0.02(-1750) - 0.001(15000)(0.16)^{0.45}$。\n我们计算 $(0.16)^{0.45} \\approx 0.4383845$。\n$E/A(\\theta') \\approx 22 - 35 - 15(0.4383845) = -13 - 6.5757675 = -19.5757675$。\n该比率的指数为 $\\lambda(\\tfrac{E(\\theta)}{A} - E_0) - \\lambda'(\\tfrac{E(\\theta')}{A} - E_0)$。\n$0.8(-19.6 - (-16)) - 1.1(-19.5757675 - (-16)) = 0.8(-3.6) - 1.1(-3.5757675) = -2.88 + 3.93334425 = 1.05334425$。\n该比率为 $\\exp(1.05334425) \\approx 2.86725$。\n\n**3. 参数先验比率：**\n-   **$t_0$ 先验：** $\\exp\\left( \\frac{(-1800 - (-1900))^2 - (-1750 - (-1900))^2}{2(300)^2} \\right) = \\exp\\left( \\frac{100^2 - 150^2}{180000} \\right) = \\exp\\left( \\frac{-12500}{180000} \\right) = \\exp(-5/72) \\approx 0.93291$。\n-   **$t_3$ 先验：** $\\exp\\left( \\frac{(14000 - 13000)^2 - (15000 - 13000)^2}{2(2000)^2} \\right) = \\exp\\left( \\frac{1000^2 - 2000^2}{8000000} \\right) = \\exp\\left( \\frac{-3000000}{8000000} \\right) = \\exp(-3/8) \\approx 0.68729$。\n-   **$\\sigma$ 先验：** $\\exp\\left( \\frac{(0.5 - 0.5)^2 - (0.45 - 0.5)^2}{2(0.05)^2} \\right) = \\exp\\left( \\frac{0 - (-0.05)^2}{0.005} \\right) = \\exp\\left( \\frac{-0.0025}{0.005} \\right) = \\exp(-0.5) \\approx 0.60653$。\n\n**4. $\\lambda$ 先验与建议比率（合并）：**\n当 $a=2, b=1, \\lambda=0.8, \\lambda'=1.1$ 时：\n比率为 $\\left(\\frac{1.1}{0.8}\\right)^{2} \\exp(-1(1.1 - 0.8)) = (1.375)^2 \\exp(-0.3) = 1.890625 \\times 0.740818 \\approx 1.40061$。\n\n**5. 总 Hastings 比率 R：**\n$R$ 是所有这些项的乘积：似然比、约束项比率、$t_0$先验比率、$t_3$先验比率、$\\sigma$先验比率以及合并的$\\lambda$项。\n$R \\approx 1 \\times 2.86725 \\times 0.93291 \\times 0.68729 \\times 0.60653 \\times 1.40061$。\n$R \\approx 1.56150$。\n\n**6. 接受概率 $\\alpha$：**\n接受概率为 $\\alpha = \\min(1, R)$。\n由于 $R \\approx 1.5615 > 1$，接受概率为 $\\alpha = 1$。\n四舍五入到四位有效数字，结果为 $1.000$。",
            "answer": "$$\\boxed{1.000}$$"
        },
        {
            "introduction": "为了提高采样效率，我们可以利用目标分布的梯度信息，这就是Metropolis调整的朗之万算法（MALA）的核心思想。然而，在实际应用中，参数常常受到如正定性等约束。本练习  旨在通过一个实际的编程任务，让你掌握如何实现一个能够处理正定性约束的MALA采样器，其关键在于使用反射边界和折叠高斯提议，并推导满足细致平衡条件的相应接受概率。",
            "id": "3604515",
            "problem": "考虑通过一种基于 Metropolis-Adjusted Langevin Algorithm (MALA) 的约束马尔可夫链蒙特卡洛 (MCMC) 方法，在一个包含 $\\,d\\,$ 个半径的网格上对离散化的非负径向核子密度 $\\,\\rho(r)\\,$ 进行抽样。我们将未归一化的目标建模为一个带有正性约束的对数凹场后验：\n$$\n\\log \\pi(\\boldsymbol{\\rho}) \\;\\propto\\; -\\tfrac{1}{2}\\,\\boldsymbol{\\rho}^\\top \\mathbf{K}\\,\\boldsymbol{\\rho} \\;+\\; \\mathbf{b}^\\top \\boldsymbol{\\rho}, \n\\quad \\text{with} \\quad \\boldsymbol{\\rho}\\in \\mathbb{R}^d,\\;\\; \\rho_i \\geq 0 \\;\\text{for all}\\; i,\n$$\n其中 $\\,\\mathbf{K}\\,$ 是一个对称正定精度矩阵，其编码了来自离散化半正定微分算子的平滑性，而 $\\,\\mathbf{b}\\,$ 编码了数据驱动的线性项。令 $\\,\\nabla \\log \\pi(\\boldsymbol{\\rho}) = -\\mathbf{K}\\boldsymbol{\\rho} + \\mathbf{b}\\,$.\n\n你需要实现一个保持正性、使用反射边界的 MALA 积分器，该积分器使用投影梯度和折叠高斯提议，并推导用于校正边界碰撞的接受概率。该构造必须遵循以下基本原理：\n- 用于在凸域中对目标密度 $\\,\\pi(\\cdot)\\,$ 进行抽样的带反射的过阻尼朗之万扩散，$\\,\\mathrm{d}\\mathbf{X}_t = \\tfrac{1}{2}\\nabla \\log \\pi(\\mathbf{X}_t)\\,\\mathrm{d}t + \\mathrm{d}\\mathbf{W}_t\\,$，在边界上具有瞬时反射。\n- Metropolis-Hastings 算法，它使用提议核 $\\,q(\\cdot\\mid\\cdot)\\,$ 和接受概率 $\\,\\alpha(\\mathbf{x},\\mathbf{y}) = \\min\\!\\left\\{1, \\dfrac{\\pi(\\mathbf{y})\\,q(\\mathbf{x}\\mid\\mathbf{y})}{\\pi(\\mathbf{x})\\,q(\\mathbf{y}\\mid\\mathbf{x})}\\right\\}\\,$ 来构建一条关于 $\\,\\pi(\\cdot)\\,$ 可逆的马尔可夫链。\n\n待实现的算法规范：\n1. 给定当前状态 $\\,\\mathbf{x}\\in \\mathbb{R}^d_{\\geq 0}\\,$，按坐标计算投影梯度 $\\,\\mathbf{g}_{\\mathrm{proj}}(\\mathbf{x})\\,$：\n$$\ng_{\\mathrm{proj},i}(\\mathbf{x}) \\;=\\; \n\\begin{cases}\n0,  & \\text{if } x_i=0 \\text{ and } \\left[ \\nabla \\log\\pi(\\mathbf{x}) \\right]_i  < 0, \\\\\n\\left[ \\nabla \\log\\pi(\\mathbf{x}) \\right]_i,  & \\text{otherwise}.\n\\end{cases}\n$$\n2. 形成预提议均值\n$$\n\\boldsymbol{\\mu}(\\mathbf{x}) \\;=\\; \\mathbf{x} + \\tfrac{\\varepsilon^2}{2}\\,\\mathbf{g}_{\\mathrm{proj}}(\\mathbf{x}),\n$$\n其中 $\\,\\varepsilon > 0\\,$ 是步长。\n3. 抽取一个高斯增量 $\\,\\boldsymbol{\\xi}\\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I}_d)\\,$，计算一个暂定点 $\\,\\mathbf{z}=\\boldsymbol{\\mu}(\\mathbf{x})+\\varepsilon\\,\\boldsymbol{\\xi}\\,$，然后逐分量进行反射以强制正性，从而获得提议\n$$\n\\mathbf{y} \\;=\\; |\\mathbf{z}| \\quad \\text{with}\\quad y_i \\;=\\; |z_i|\\;\\;\\text{for all}\\;\\;i.\n$$\n4. 对于 $\\,\\mathbf{y}\\in \\mathbb{R}^d_{\\geq 0}\\,$，正向提议密度 $\\,q_R(\\mathbf{y}\\mid \\mathbf{x})\\,$ 是由反射映射引出的折叠高斯分布：\n$$\nq_R(\\mathbf{y}\\mid \\mathbf{x}) \\;=\\; \\sum_{\\mathbf{s}\\in\\{-1,+1\\}^d} \n\\varphi_d\\!\\left(\\mathbf{s}\\odot \\mathbf{y};\\, \\boldsymbol{\\mu}(\\mathbf{x}),\\, \\varepsilon^2 \\mathbf{I}_d\\right),\n$$\n其中 $\\,\\mathbf{s}\\odot \\mathbf{y}\\,$ 是逐元素乘积，$\\,\\varphi_d(\\cdot;\\boldsymbol{\\mu},\\varepsilon^2\\mathbf{I}_d)\\,$ 是均值为 $\\,\\boldsymbol{\\mu}\\,$、各向同性协方差为 $\\,\\varepsilon^2\\mathbf{I}_d\\,$ 的 $\\,d\\,$ 维高斯密度。对于各向同性协方差，这可以分解为一维折叠正态分布的乘积：\n$$\nq_R(\\mathbf{y}\\mid \\mathbf{x}) \\;=\\; \\prod_{i=1}^d \\left[ \\varphi_1\\!\\left(y_i;\\,\\mu_i(\\mathbf{x}),\\,\\varepsilon^2\\right) + \\varphi_1\\!\\left(-y_i;\\,\\mu_i(\\mathbf{x}),\\,\\varepsilon^2\\right) \\right].\n$$\n5. 使用 Metropolis-Hastings 接受概率\n$$\n\\alpha(\\mathbf{x},\\mathbf{y}) \\;=\\; \\min\\!\\left\\{1,\\; \n\\frac{\\pi(\\mathbf{y})\\, q_R(\\mathbf{x}\\mid \\mathbf{y})}{\\pi(\\mathbf{x})\\, q_R(\\mathbf{y}\\mid \\mathbf{x})} \\right\\}.\n$$\n\n任务：\n- 从第一性原理推导，当使用投影梯度漂移和反射提议时，为什么上述接受概率会产生一条关于 $\\,\\pi(\\cdot)\\,$ 可逆的马尔可夫链。明确论证 $\\,q_R(\\cdot\\mid\\cdot)\\,$ 中的折叠高斯混合分布作为边界碰撞的接受校正所起的作用。\n- 实现一个完整的程序，该程序：\n  - 计算 $\\,\\log \\pi(\\mathbf{x}) = -\\tfrac{1}{2}\\mathbf{x}^\\top \\mathbf{K}\\mathbf{x} + \\mathbf{b}^\\top \\mathbf{x}\\,$，其中 $\\,\\mathbf{x}\\in\\mathbb{R}^d_{\\geq 0}\\,$，否则为 $\\, -\\infty\\,$。\n  - 计算 $\\,\\nabla \\log \\pi(\\mathbf{x}) = -\\mathbf{K}\\mathbf{x} + \\mathbf{b}\\,$ 和投影梯度 $\\,\\mathbf{g}_{\\mathrm{proj}}(\\mathbf{x})\\,$。\n  - 形成 $\\,\\boldsymbol{\\mu}(\\mathbf{x})\\,$，应用反射，通过稳定的 log-sum-exp 方法计算 $\\,\\log q_R(\\mathbf{y}\\mid \\mathbf{x})\\,$ 和 $\\,\\log q_R(\\mathbf{x}\\mid \\mathbf{y})\\,$，并返回 $\\,\\alpha(\\mathbf{x},\\mathbf{y})$。\n  - 对于一个测试，通过计算两个对数通量的绝对差 $\\,\\left|\\log\\left(\\pi(\\mathbf{x})\\,q_R(\\mathbf{y}\\mid \\mathbf{x})\\,\\alpha(\\mathbf{x},\\mathbf{y})\\right) - \\log\\left(\\pi(\\mathbf{y})\\,q_R(\\mathbf{x}\\mid \\mathbf{y})\\,\\alpha(\\mathbf{y},\\mathbf{x})\\right)\\right|\\,$，来数值上验证细致平衡。\n\n测试套件：\n使用以下参数化测试。所有向量均按索引递增的行主序排列。所有常量必须严格按照规定实现。\n\n- 测试 $\\,1\\,$ (内部，无边界碰撞, $\\,d=1$):\n  - $\\,\\mathbf{K} = [ [ 1.0 ] ]\\,$, $\\,\\mathbf{b} = [ 1.0 ]\\,$,\n  - $\\,\\mathbf{x} = [ 0.8 ]\\,$, $\\,\\varepsilon = 0.3\\,$, 噪声 $\\,\\boldsymbol{\\xi} = [ 0.2 ]\\,$.\n  - 输出接受概率 $\\,\\alpha(\\mathbf{x},\\mathbf{y})\\,$。\n\n- 测试 $\\,2\\,$ (边界碰撞, $\\,d=1$):\n  - $\\,\\mathbf{K} = [ [ 1.0 ] ]\\,$, $\\,\\mathbf{b} = [ -0.2 ]\\,$,\n  - $\\,\\mathbf{x} = [ 0.0 ]\\,$, $\\,\\varepsilon = 0.2\\,$, 噪声 $\\,\\boldsymbol{\\xi} = [ -1.5 ]\\,$.\n  - 输出接受概率 $\\,\\alpha(\\mathbf{x},\\mathbf{y})\\,$。\n\n- 测试 $\\,3\\,$ (混合坐标, $\\,d=3$): 构建 $\\,\\mathbf{K} = \\gamma \\mathbf{I}_3 + \\beta \\mathbf{S}\\,$，其中 $\\,\\gamma=0.1\\,$, $\\,\\beta=0.5\\,$，且 $\\,\\mathbf{S}\\,$ 是主对角线元素为 $\\,2\\,$、紧邻的次对角线元素为 $\\, -1\\,$ 的三对角矩阵。令 $\\,\\mathbf{b}\\,$ 的元素为 $\\,b_i = \\kappa \\exp\\!\\left( - (r_i/R_0)^2 \\right)\\,$，其中 $\\,\\kappa=0.8\\,$, $\\,R_0=2.0\\,$，半径 $\\,r_i = (i+1)\\Delta r\\,$，$\\,\\Delta r = 1.0\\,$ 且 $\\,i=0,1,2\\,$. 使用\n  - $\\,\\mathbf{x} = [ 0.0,\\; 0.2,\\; 0.0 ]\\,$, $\\,\\varepsilon = 0.25\\,$, 噪声 $\\,\\boldsymbol{\\xi} = [ -0.3,\\; 0.1,\\; -0.7 ]\\,$.\n  - 输出接受概率 $\\,\\alpha(\\mathbf{x},\\mathbf{y})\\,$。\n\n- 测试 $\\,4\\,$ (在测试 $\\,3\\,$ 的点对上的数值细致平衡残差):\n  - 使用测试 $\\,3\\,$ 中的 $\\,\\mathbf{x}\\,$ 和得到的 $\\,\\mathbf{y}\\,$，计算\n    $$\n    \\delta \\;=\\; \\left| \\log\\!\\left(\\pi(\\mathbf{x})\\,q_R(\\mathbf{y}\\mid \\mathbf{x})\\,\\alpha(\\mathbf{x},\\mathbf{y})\\right) \\;-\\; \\log\\!\\left(\\pi(\\mathbf{y})\\,q_R(\\mathbf{x}\\mid \\mathbf{y})\\,\\alpha(\\mathbf{y},\\mathbf{x})\\right) \\right|.\n    $$\n  - 输出 $\\,\\delta\\,$。\n\n最终输出格式：\n您的程序必须生成单行结果，格式为方括号内包含的逗号分隔列表，按测试 $\\,1\\,$ 到 $\\,4\\,$ 的顺序排列。所有值都必须是四舍五入到 $\\,6\\,$ 位小数的十进制浮点数。例如：\"[0.123456,0.234567,0.345678,0.000001]\".",
            "solution": "该问题要求一个两部分的回答：对反射边界 Metropolis-Adjusted Langevin Algorithm (MALA) 的接受概率进行理论推导，并实现该算法以解决四个特定的计算任务。该问题陈述被验证为科学上合理、适定且客观。所有提供的数据和定义都是一致的，并且足以得到唯一解。\n\n### 理论推导\n\n目标是构建一条马尔可夫链，该链对于定义在非负象限 $\\mathbb{R}^d_{\\geq 0}$ 上的目标概率分布 $\\pi(\\boldsymbol{\\rho})$ 是可逆的。可逆性，也称为细致平衡条件，是确保 $\\pi$ 为该链的平稳分布的一个充分条件。对于任意两个状态 $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^d_{\\geq 0}$，细致平衡条件由下式给出：\n$$\n\\pi(\\mathbf{x})\\,P(\\mathbf{y} \\mid \\mathbf{x}) = \\pi(\\mathbf{y})\\,P(\\mathbf{x} \\mid \\mathbf{y})\n$$\n其中 $P(\\mathbf{y} \\mid \\mathbf{x})$ 是马尔可夫链的转移核，表示从状态 $\\mathbf{x}$ 移动到状态 $\\mathbf{y}$ 的概率密度。\n\nMetropolis-Hastings (MH) 算法为构造此类核提供了一个通用框架。转移是一个两阶段过程：从提议分布 $q(\\mathbf{y} \\mid \\mathbf{x})$ 生成一个提议，然后以概率 $\\alpha(\\mathbf{x}, \\mathbf{y})$ 接受该提议。从 $\\mathbf{x}$ 到 $\\mathbf{y}$（其中 $\\mathbf{y} \\neq \\mathbf{x}$）的完整转移核为 $P(\\mathbf{y} \\mid \\mathbf{x}) = q(\\mathbf{y} \\mid \\mathbf{x})\\,\\alpha(\\mathbf{x}, \\mathbf{y})$。著名的接受概率选择是：\n$$\n\\alpha(\\mathbf{x}, \\mathbf{y}) = \\min\\left\\{1, \\frac{\\pi(\\mathbf{y})\\,q(\\mathbf{x} \\mid \\mathbf{y})}{\\pi(\\mathbf{x})\\,q(\\mathbf{y} \\mid \\mathbf{x})}\\right\\}\n$$\n对于接受的移动，此形式确定性地满足细致平衡方程。为了验证这一点，我们可以检查乘积 $\\pi(\\mathbf{x})\\,q(\\mathbf{y} \\mid \\mathbf{x})\\,\\alpha(\\mathbf{x}, \\mathbf{y})$ 并展示其在交换 $\\mathbf{x}$ 和 $\\mathbf{y}$ 时的对称性：\n\\begin{align*} \\label{eq:1}\n\\pi(\\mathbf{x})\\,q(\\mathbf{y} \\mid \\mathbf{x})\\,\\alpha(\\mathbf{x}, \\mathbf{y}) &= \\pi(\\mathbf{x})\\,q(\\mathbf{y} \\mid \\mathbf{x})\\,\\min\\left\\{1, \\frac{\\pi(\\mathbf{y})\\,q(\\mathbf{x} \\mid \\mathbf{y})}{\\pi(\\mathbf{x})\\,q(\\mathbf{y} \\mid \\mathbf{x})}\\right\\} \\\\\n&= \\min\\left\\{\\pi(\\mathbf{x})\\,q(\\mathbf{y} \\mid \\mathbf{x}), \\pi(\\mathbf{y})\\,q(\\mathbf{x} \\mid \\mathbf{y})\\right\\} \\\\\n&= \\pi(\\mathbf{y})\\,q(\\mathbf{x} \\mid \\mathbf{y})\\,\\min\\left\\{\\frac{\\pi(\\mathbf{x})\\,q(\\mathbf{y} \\mid \\mathbf{x})}{\\pi(\\mathbf{y})\\,q(\\mathbf{x} \\mid \\mathbf{y})}, 1\\right\\} \\\\\n&= \\pi(\\mathbf{y})\\,q(\\mathbf{x} \\mid \\mathbf{y})\\,\\alpha(\\mathbf{y}, \\mathbf{x})\n\\end{align*}\n只要提议分布 $q(\\cdot \\mid \\cdot)$ 在整个状态空间上都有支撑，该等式对任何选择的 $q$ 都成立。因此，挑战的核心不是论证 MH 公式本身，而是正确推导出与指定算法过程相对应的提议密度 $q_R(\\mathbf{y} \\mid \\mathbf{x})$。\n\n该算法通过以下步骤从当前状态 $\\mathbf{x}$ 提议一个新状态 $\\mathbf{y}$：\n1. 计算一个漂移项（预提议均值）：$\\boldsymbol{\\mu}(\\mathbf{x}) = \\mathbf{x} + \\tfrac{\\varepsilon^2}{2}\\,\\mathbf{g}_{\\mathrm{proj}}(\\mathbf{x})$。\n2. 从高斯分布中抽取一个暂定点 $\\mathbf{z}$：$\\mathbf{z} \\sim \\mathcal{N}(\\boldsymbol{\\mu}(\\mathbf{x}), \\varepsilon^2 \\mathbf{I}_d)$。\n3. 通过将 $\\mathbf{z}$ 反射到非负象限中获得最终提议 $\\mathbf{y}$：$\\mathbf{y} = |\\mathbf{z}|$。\n\n暂定点 $\\mathbf{z}$ 的密度，我们记为 $p_{\\mathbf{x}}(\\mathbf{z})$，是多元高斯概率密度函数 (PDF)：\n$$\np_{\\mathbf{x}}(\\mathbf{z}) = \\varphi_d(\\mathbf{z}; \\boldsymbol{\\mu}(\\mathbf{x}), \\varepsilon^2 \\mathbf{I}_d) = \\frac{1}{(2\\pi\\varepsilon^2)^{d/2}} \\exp\\left(-\\frac{\\|\\mathbf{z} - \\boldsymbol{\\mu}(\\mathbf{x})\\|^2}{2\\varepsilon^2}\\right)\n$$\n提议 $\\mathbf{y}$ 是随机变量 $\\mathbf{z}$ 的一个确定性函数，通过逐分量绝对值映射 $\\mathbf{y} = |\\mathbf{z}|$ 实现。这个映射不是一对一的（非单射的）。对于任何给定的 $\\mathbf{y} \\in \\mathbb{R}^d_{\\geq 0}$（所有 $i$ 满足 $y_i > 0$），其原像中有 $2^d$ 个不同的点，即有 $2^d$ 个不同的 $\\mathbf{z}$ 值映射到 $\\mathbf{y}$。这些原像的形式为 $\\mathbf{s} \\odot \\mathbf{y}$，其中 $\\mathbf{s} \\in \\{-1, +1\\}^d$ 是一个符号向量，$\\odot$ 表示逐元素乘积。对于 $y_i=0$ 的分量，原像 $z_i=0$ 是唯一的。\n\n提议 $\\mathbf{y}$ 的概率密度 $q_R(\\mathbf{y} \\mid \\mathbf{x})$ 是其所有原像在 $\\mathbf{z}$ 的高斯定律下的密度之和。这是非单射变换的变量替换公式的一个标准结果。\n$$\nq_R(\\mathbf{y} \\mid \\mathbf{x}) = \\sum_{\\mathbf{z} \\text{ s.t. } |\\mathbf{z}| = \\mathbf{y}} p_{\\mathbf{x}}(\\mathbf{z}) = \\sum_{\\mathbf{s} \\in \\{-1, +1\\}^d} p_{\\mathbf{x}}(\\mathbf{s} \\odot \\mathbf{y})\n$$\n代入高斯 PDF，我们得到：\n$$\nq_R(\\mathbf{y} \\mid \\mathbf{x}) = \\sum_{\\mathbf{s} \\in \\{-1, +1\\}^d} \\varphi_d(\\mathbf{s} \\odot \\mathbf{y}; \\boldsymbol{\\mu}(\\mathbf{x}), \\varepsilon^2 \\mathbf{I}_d)\n$$\n这正是问题中指定的折叠高斯提议密度。因为协方差矩阵 $\\varepsilon^2 \\mathbf{I}_d$ 是对角阵，所以 $\\,d\\,$ 维高斯密度可以分解为 $\\,d\\,$ 个一维密度的乘积。求和也可以分配到乘积上，从而得到：\n\\begin{align*}\nq_R(\\mathbf{y} \\mid \\mathbf{x}) &= \\prod_{i=1}^d \\sum_{s_i \\in \\{-1, +1\\}} \\varphi_1(s_i y_i; \\mu_i(\\mathbf{x}), \\varepsilon^2) \\\\\n&= \\prod_{i=1}^d \\left[ \\varphi_1(y_i; \\mu_i(\\mathbf{x}), \\varepsilon^2) + \\varphi_1(-y_i; \\mu_i(\\mathbf{x}), \\varepsilon^2) \\right]\n\\end{align*}\n这证实了提议密度 $q_R(\\cdot\\mid\\cdot)$ 是“抽取并反射”过程的正确统计表示。正是反射（边界碰撞）迫使提议密度成为高斯混合分布。如果未能考虑多个原像（即，仅使用 $\\varphi_d(\\mathbf{y}; \\boldsymbol{\\mu}(\\mathbf{x}), \\varepsilon^2 \\mathbf{I}_d)$），将会导致不正确的提议密度，从而破坏细致平衡，并导致采样器具有不正确的平稳分布。\n\n漂移项 $\\boldsymbol{\\mu}(\\mathbf{x})$ 中投影梯度 $\\mathbf{g}_{\\mathrm{proj}}(\\mathbf{x})$ 的作用是为底层的反射朗之万随机微分方程（SDE）提供一个更好的类 Euler-Maruyama 离散化。通过防止漂移在边界处指向允许域的“外部”，它倾向于产生具有更高接受概率的提议，从而提高算法效率。然而，Metropolis-Hastings 方案的形式正确性仅依赖于这样一个事实：对于任何提议机制，相应的提议密度 $q_R$ 都在接受率中被正确指定。在这里，过程是计算一个漂移 $\\boldsymbol{\\mu}(\\mathbf{x})$，抽取一个高斯分布，然后反射。逆向提议密度 $q_R(\\mathbf{x} \\mid \\mathbf{y})$ 通过完全相同的逻辑计算，但从状态 $\\mathbf{y}$ 开始：首先计算 $\\boldsymbol{\\mu}(\\mathbf{y}) = \\mathbf{y} + \\tfrac{\\varepsilon^2}{2}\\,\\mathbf{g}_{\\mathrm{proj}}(\\mathbf{y})$，然后以 $\\boldsymbol{\\mu}(\\mathbf{y})$ 为均值计算在 $\\mathbf{x}$ 处的折叠高斯密度。\n\n总而言之，指定的接受概率 $\\alpha(\\mathbf{x},\\mathbf{y}) = \\min\\{1, \\frac{\\pi(\\mathbf{y})\\, q_R(\\mathbf{x}\\mid \\mathbf{y})}{\\pi(\\mathbf{x})\\, q_R(\\mathbf{y}\\mid \\mathbf{x})}\\}$ 与折叠高斯分布 $q_R$ 正确地解释了包括边界反射在内的提议生成机制。这种对 Metropolis-Hastings 原则的遵守保证了所得到的马尔可夫链满足细致平衡，因此能从目标分布 $\\pi(\\boldsymbol{\\rho})$ 中正确地抽样。\n\n### 实现与数值验证\n\n该算法被实现为一组 Python 函数，以执行四个测试用例所需的计算。\n\n-   `log_pi(rho, K, b)`：计算对数目标密度，如果 $\\boldsymbol{\\rho}$ 的任何分量为负，则返回 $-\\infty$。\n-   `grad_log_pi(rho, K, b)`：计算对数目标的梯度。\n-   `projected_gradient(rho, K, b)`：按规定计算投影梯度。\n-   `log_q_R(prop, mean, epsilon)`：对每个分量使用数值稳定的 log-sum-exp 方法，计算折叠高斯提议密度的对数。\n-   `acceptance_prob(x, y, K, b, epsilon)`：协调 MH 比率对数的计算，包括调用以计算正向和逆向提议密度，并返回接受概率。\n-   主脚本为每个测试用例定义参数，从 $\\mathbf{x}$ 和给定的噪声 $\\boldsymbol{\\xi}$ 计算提议 $\\mathbf{y}$，然后计算所需的量：测试 1-3 的 $\\alpha(\\mathbf{x}, \\mathbf{y})$，以及测试 4 的细致平衡残差 $\\delta$。`detailed_balance_residual` 函数通过显式计算正向和逆向转移对数概率来计算此值。测试 4 的小的非零结果在浮点精度范围内证实了分析推导。",
            "answer": "```python\nimport numpy as np\nimport math\n\n# --- Helper Functions ---\n\ndef log_pi(rho, K, b):\n    \"\"\"Computes the log of the unnormalized target density.\"\"\"\n    if np.any(rho < 0):\n        return -np.inf\n    log_p = -0.5 * rho.T @ K @ rho + b.T @ rho\n    return log_p\n\ndef grad_log_pi(rho, K, b):\n    \"\"\"Computes the gradient of the log-target density.\"\"\"\n    return -K @ rho + b\n\ndef projected_gradient(rho, K, b):\n    \"\"\"Computes the projected gradient.\"\"\"\n    grad = grad_log_pi(rho, K, b)\n    g_proj = grad.copy()\n    g_proj[(rho == 0.0) & (grad < 0)] = 0.0\n    return g_proj\n\ndef log_q_R(prop, mean, epsilon):\n    \"\"\"\n    Computes the log of the reflecting (folded-Gaussian) proposal density\n    using a numerically stable log-sum-exp.\n    \"\"\"\n    d = len(prop)\n    log_norm_const = -0.5 * np.log(2 * np.pi * epsilon**2)\n    e2_2 = 2 * epsilon**2\n    \n    total_log_q = 0.0\n    for i in range(d):\n        yi = prop[i]\n        mui = mean[i]\n        \n        log_p1 = log_norm_const - ((yi - mui)**2) / e2_2\n        log_p2 = log_norm_const - ((-yi - mui)**2) / e2_2\n        \n        max_log = np.maximum(log_p1, log_p2)\n        term_log = max_log + np.log(np.exp(log_p1 - max_log) + np.exp(log_p2 - max_log))\n        total_log_q += term_log\n        \n    return total_log_q\n\ndef acceptance_prob(x, y, K, b, epsilon):\n    \"\"\"Computes the Metropolis-Hastings acceptance probability alpha(x, y).\"\"\"\n    log_pi_x = log_pi(x, K, b)\n    log_pi_y = log_pi(y, K, b)\n\n    if log_pi_y == -np.inf:\n        return 0.0\n\n    # Forward proposal: x -> y\n    g_proj_x = projected_gradient(x, K, b)\n    mu_x = x + (epsilon**2 / 2) * g_proj_x\n    log_q_y_given_x = log_q_R(y, mu_x, epsilon)\n\n    # Reverse proposal: y -> x\n    g_proj_y = projected_gradient(y, K, b)\n    mu_y = y + (epsilon**2 / 2) * g_proj_y\n    log_q_x_given_y = log_q_R(x, mu_y, epsilon)\n    \n    log_ratio = (log_pi_y + log_q_x_given_y) - (log_pi_x + log_q_y_given_x)\n    \n    return min(1.0, np.exp(log_ratio))\n\ndef detailed_balance_residual(x, y, K, b, epsilon):\n    \"\"\"Computes the numerical residual of the detailed balance equation.\"\"\"\n    log_pi_x = log_pi(x, K, b)\n    log_pi_y = log_pi(y, K, b)\n    \n    if log_pi_x == -np.inf or log_pi_y == -np.inf:\n        return 0.0\n\n    # Forward proposal info\n    g_proj_x = projected_gradient(x, K, b)\n    mu_x = x + (epsilon**2 / 2) * g_proj_x\n    log_q_y_given_x = log_q_R(y, mu_x, epsilon)\n\n    # Reverse proposal info\n    g_proj_y = projected_gradient(y, K, b)\n    mu_y = y + (epsilon**2 / 2) * g_proj_y\n    log_q_x_given_y = log_q_R(x, mu_y, epsilon)\n    \n    # Acceptance probabilities\n    log_ratio_xy = (log_pi_y + log_q_x_given_y) - (log_pi_x + log_q_y_given_x)\n    alpha_xy = min(1.0, np.exp(log_ratio_xy))\n    \n    log_ratio_yx = -log_ratio_xy\n    alpha_yx = min(1.0, np.exp(log_ratio_yx))\n\n    # To avoid log(0) if acceptance is zero\n    if alpha_xy == 0.0 or alpha_yx == 0.0:\n        # Check if fluxes are both zero\n        log_p_forward = -np.inf if alpha_xy == 0.0 else log_pi_x + log_q_y_given_x + np.log(alpha_xy)\n        log_p_reverse = -np.inf if alpha_yx == 0.0 else log_pi_y + log_q_x_given_y + np.log(alpha_yx)\n        if log_p_forward == log_p_reverse:\n            return 0.0\n\n    log_p_forward = log_pi_x + log_q_y_given_x + np.log(alpha_xy)\n    log_p_reverse = log_pi_y + log_q_x_given_y + np.log(alpha_yx)\n    \n    delta = np.abs(log_p_forward - log_p_reverse)\n    return delta\n\n# --- Main Execution ---\n\ndef solve():\n    \"\"\"Runs all test cases and prints the results.\"\"\"\n    results = []\n\n    # Test 1\n    K1 = np.array([[1.0]])\n    b1 = np.array([1.0])\n    x1 = np.array([0.8])\n    eps1 = 0.3\n    xi1 = np.array([0.2])\n    g_proj_x1 = projected_gradient(x1, K1, b1)\n    mu_x1 = x1 + (eps1**2 / 2) * g_proj_x1\n    z1 = mu_x1 + eps1 * xi1\n    y1 = np.abs(z1)\n    alpha1 = acceptance_prob(x1, y1, K1, b1, eps1)\n    results.append(f\"{alpha1:.6f}\")\n\n    # Test 2\n    K2 = np.array([[1.0]])\n    b2 = np.array([-0.2])\n    x2 = np.array([0.0])\n    eps2 = 0.2\n    xi2 = np.array([-1.5])\n    g_proj_x2 = projected_gradient(x2, K2, b2)\n    mu_x2 = x2 + (eps2**2 / 2) * g_proj_x2\n    z2 = mu_x2 + eps2 * xi2\n    y2 = np.abs(z2)\n    alpha2 = acceptance_prob(x2, y2, K2, b2, eps2)\n    results.append(f\"{alpha2:.6f}\")\n\n    # Test 3\n    gamma3 = 0.1\n    beta3 = 0.5\n    S3 = np.array([[2.0, -1.0, 0.0], [-1.0, 2.0, -1.0], [0.0, -1.0, 2.0]])\n    K3 = gamma3 * np.identity(3) + beta3 * S3\n    kappa3 = 0.8\n    R0_3 = 2.0\n    delta_r3 = 1.0\n    radii = np.array([(i + 1) * delta_r3 for i in range(3)])\n    b3 = kappa3 * np.exp(-(radii / R0_3)**2)\n    x3 = np.array([0.0, 0.2, 0.0])\n    eps3 = 0.25\n    xi3 = np.array([-0.3, 0.1, -0.7])\n    g_proj_x3 = projected_gradient(x3, K3, b3)\n    mu_x3 = x3 + (eps3**2 / 2) * g_proj_x3\n    z3 = mu_x3 + eps3 * xi3\n    y3 = np.abs(z3)\n    alpha3 = acceptance_prob(x3, y3, K3, b3, eps3)\n    results.append(f\"{alpha3:.6f}\")\n\n    # Test 4\n    delta4 = detailed_balance_residual(x3, y3, K3, b3, eps3)\n    results.append(f\"{delta4:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "Metropolis-Hastings算法最强大的扩展之一是能够对不同复杂度的模型进行比较，这通常涉及在不同维度的参数空间之间跳转。可逆跳转MCMC（RJMCMC）为此提供了坚实的理论框架。本练习  将引导你详细推导一个“诞生”移动的接受概率，该移动使采样器从一个简单模型转换到一个更复杂的模型。这个过程将阐明如何正确地处理模型先验、提议概率和维度匹配变换的雅可比行列式，这些都是RJMCMC的核心要素。",
            "id": "3604527",
            "problem": "在从头计算核理论中，人们经常将一个两体 (2N) 相互作用模型 $M_{1}$ 与一个增强模型 $M_{2}$ 进行比较，后者在 2N 力的基础上还包含了一个领头三体 (3N) 力。考虑一个可逆跳转 Metropolis-Hastings (RJ-MH) 方案，用于从模型指数 $M \\in \\{M_{1},M_{2}\\}$ 和以数据 $\\mathcal{D}$ 为条件的模型参数的联合后验分布中进行抽样。目标分布是由贝叶斯定理得出的联合后验分布，即 $p(\\theta_{k},M_{k}\\mid \\mathcal{D}) \\propto p(\\mathcal{D}\\mid \\theta_{k},M_{k})\\,p(\\theta_{k}\\mid M_{k})\\,p(M_{k})$，其中 $k\\in\\{1,2\\}$。\n\n假设以下与低能核物理校准相关的具有科学动机的设定：\n- 2N 模型 $M_{1}$ 的参数向量为 $\\theta_{1}=(C_{S},C_{T})\\in \\mathbb{R}^{2}$。2N+3N 模型 $M_{2}$ 的参数向量为 $\\theta_{2}=(C_{S},C_{T},c_{E})\\in \\mathbb{R}^{3}$，其中 $c_{E}\\in \\mathbb{R}$ 是一个 3N 低能常数。\n- 在两个模型下，2N 参数共享相同的先验分布：$p(\\theta_{1}\\mid M_{1})=p(\\theta_{1}\\mid M_{2})$（因此在保持固定的情况下，它们在比值中会相互抵消）。\n- 3N 耦合的先验分布是高斯分布：$p(c_{E}\\mid M_{2})=\\mathcal{N}(0,\\tau^{2})$，其中 $\\tau=1$。\n- 模型先验概率为 $p(M_{1})=0.6$ 和 $p(M_{2})=0.4$。\n- 观测到一个标量差异统计量 $y$，它概括了氚核结合能的残差（实验值减理论值），其值为 $y=0$。数据模型为高斯分布，已知误差标准差为 $\\sigma=0.3$：\n  - 在模型 $M_{1}$ 下，$y\\mid \\theta_{1},M_{1}\\sim \\mathcal{N}(\\mu_{1},\\sigma^{2})$，其中 $\\mu_{1}=b$ 且 $b=0.5$。\n  - 在模型 $M_{2}$ 下，$y\\mid \\theta_{2},M_{2}\\sim \\mathcal{N}(\\mu_{2},\\sigma^{2})$，其中 $\\mu_{2}=b+a\\,c_{E}$，$a=-2.0$ 表示在当前校准点附近，残差对 $c_{E}$ 的线性化灵敏度。\n\n考虑一个从 $(M_{1},\\theta_{1})$ 到 $(M_{2},\\theta_{2})$ 的“诞生”移动，该移动由确定性维度匹配映射 $\\mathcal{T}:(\\theta_{1},u)\\mapsto \\theta_{2}=(\\theta_{1},c_{E})$ 定义，其中 $c_{E}=u$。辅助变量从 $u\\sim q_{12}(u\\mid \\theta_{1})=\\mathcal{N}(m,s^{2})$ 中提议生成，其中 $m=-0.1$ 且 $s=0.5$。从 $(M_{2},\\theta_{2})$ 到 $(M_{1},\\theta_{1})$ 的逆向“死亡”移动确定性地舍弃 $c_{E}$，并且没有逆向辅助抽样，因此在逆向随机变量的零测集上，$q_{21}(\\cdot\\mid \\theta_{2})$ 是常数 $1$。变换的雅可比行列式为 $J=\\left|\\partial \\theta_{2}/\\partial(\\theta_{1},u)\\right|=1$。假设移动类型的选择概率为 $r_{12}=r_{21}=0.5$。\n\n您当前处于模型 $M_{1}$，具有某个固定的 $\\theta_{1}$，并且一个特定的前向提议抽样的实现值为 $u^{\\star}=-0.3$，因此 $c_{E}^{\\star}=-0.3$ 且 $\\theta_{2}^{\\star}=(\\theta_{1},c_{E}^{\\star})$。使用马尔可夫链的细致平衡定义和贝叶斯定理作为基本原则，推导这个特定“诞生”移动的 RJ-MH 接受概率 $\\alpha_{\\text{birth}}$，并对其进行数值计算。将最终答案表示为四舍五入到四位有效数字的小数。不要包含单位。",
            "solution": "该问题要求在可逆跳转 Metropolis-Hastings (RJ-MH) 框架中计算一个“诞生”移动的接受概率。此移动尝试从模型 $M_1$ 中的一个状态跃迁到更高维模型 $M_2$ 中的一个状态。\n\n模型 $M_k$ 中的状态由模型指数 $k$ 和参数向量 $\\theta_k$ 指定。目标分布是联合后验分布 $p(\\theta_k, M_k \\mid \\mathcal{D})$，其中数据 $\\mathcal{D}$ 包含单个观测值 $y=0$。当前状态是 $x = (M_1, \\theta_1)$。提议的状态是 $x' = (M_2, \\theta_2^\\star)$。\n\nRJ-MH 接受概率 $\\alpha(x \\to x')$ 的通用公式为：\n$$ \\alpha(x \\to x') = \\min(1, R) $$\n其中 $R$ 是接受率。对于从状态 $(M_1, \\theta_1)$ 到 $(M_2, \\theta_2^\\star)$ 的特定“诞生”移动，比率 $R \\equiv \\alpha_{\\text{birth}}$ 由以下公式给出：\n$$ R = \\underbrace{\\frac{p(M_2, \\theta_2^\\star \\mid y)}{p(M_1, \\theta_1 \\mid y)}}_{\\text{后验比率}} \\times \\underbrace{\\frac{r_{21} \\, q_{21}(\\cdot \\mid \\theta_2^\\star)}{r_{12} \\, q_{12}(u^\\star \\mid \\theta_1)}}_{\\text{提议比率}} \\times \\underbrace{|J|}_{\\text{雅可比行列式}} $$\n这里，$u^\\star$ 是从辅助变量分布 $q_{12}$ 中抽取的特定值，用于在 $M_2$ 中生成新参数。在此问题中，提议将 $(\\theta_1, u)$ 通过 $c_E = u$ 映射到 $\\theta_2 = (\\theta_1, c_E)$，因此提议的参数是 $c_E^\\star = u^\\star=-0.3$ 和 $\\theta_2^\\star = (\\theta_1, c_E^\\star)$。逆向移动是确定性的，因此没有逆向辅助变量，其提议密度 $q_{21}$ 为 $1$。维度匹配映射的雅可比行列式 $|J|$ 已知为 $1$。\n\n让我们分析比率 $R$ 的每一项。\n\n首先，是后验比率，使用贝叶斯定理 $p(\\theta_k, M_k \\mid y) \\propto p(y \\mid \\theta_k, M_k) p(\\theta_k \\mid M_k) p(M_k)$：\n$$ \\frac{p(M_2, \\theta_2^\\star \\mid y)}{p(M_1, \\theta_1 \\mid y)} = \\frac{p(y \\mid \\theta_2^\\star, M_2) \\, p(\\theta_2^\\star \\mid M_2) \\, p(M_2)}{p(y \\mid \\theta_1, M_1) \\, p(\\theta_1 \\mid M_1) \\, p(M_1)} $$\n参数向量 $\\theta_2^\\star$ 是 $(\\theta_1, c_E^\\star)$。我们可以将先验 $p(\\theta_2^\\star \\mid M_2)$ 分解为 $p(c_E^\\star \\mid \\theta_1, M_2) p(\\theta_1 \\mid M_2)$。假设 $c_E$ 的先验独立于 $\\theta_1$，这可以简化为 $p(c_E^\\star \\mid M_2) p(\\theta_1 \\mid M_2)$。问题陈述，共享参数 $\\theta_1$ 的先验在两个模型下是相同的，即 $p(\\theta_1 \\mid M_1) = p(\\theta_1 \\mid M_2)$。因此这些项相互抵消。后验比率简化为：\n$$ \\frac{p(M_2, \\theta_2^\\star \\mid y)}{p(M_1, \\theta_1 \\mid y)} = \\frac{p(y \\mid \\theta_2^\\star, M_2) \\, p(c_E^\\star \\mid M_2) \\, p(M_2)}{p(y \\mid \\theta_1, M_1) \\, p(M_1)} $$\n\n现在，让我们代入给定的分布：\n似然比为：\n$$ \\frac{p(y \\mid \\theta_2^\\star, M_2)}{p(y \\mid \\theta_1, M_1)} = \\frac{\\mathcal{N}(y \\mid b+ac_E^\\star, \\sigma^2)}{\\mathcal{N}(y \\mid b, \\sigma^2)} = \\frac{\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y - (b+ac_E^\\star))^2}{2\\sigma^2}\\right)}{\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y-b)^2}{2\\sigma^2}\\right)} $$\n当 $y=0$ 时，该式变为：\n$$ \\exp\\left(\\frac{b^2 - (b+ac_E^\\star)^2}{2\\sigma^2}\\right) $$\n$c_E$ 的参数先验为 $p(c_E^\\star \\mid M_2) = \\mathcal{N}(c_E^\\star \\mid 0, \\tau^2) = \\frac{1}{\\sqrt{2\\pi\\tau^2}} \\exp\\left(-\\frac{(c_E^\\star)^2}{2\\tau^2}\\right)$。\n模型先验比为 $\\frac{p(M_2)}{p(M_1)}$。\n\n其次，是提议比率：\n$$ \\frac{r_{21} \\, q_{21}(\\cdot \\mid \\theta_2^\\star)}{r_{12} \\, q_{12}(u^\\star \\mid \\theta_1)} $$\n给定 $r_{12}=r_{21}=0.5$，这个比率为 $1$。逆向提议 $q_{21}=1$。辅助变量的前向提议为 $q_{12}(u^\\star \\mid \\theta_1) = \\mathcal{N}(u^\\star \\mid m, s^2) = \\frac{1}{\\sqrt{2\\pi s^2}} \\exp\\left(-\\frac{(u^\\star - m)^2}{2s^2}\\right)$。因此，提议比率项的计算结果为 $\\frac{1}{q_{12}(u^\\star \\mid \\theta_1)}$。\n\n第三，雅可比行列式已知为 $|J|=1$。\n\n综合所有项，并回顾 $c_E^\\star=u^\\star$，完整的接受率 $R$ 为：\n$$ R = \\frac{p(y \\mid \\theta_2^\\star, M_2)}{p(y \\mid \\theta_1, M_1)} \\times \\frac{p(M_2)}{p(M_1)} \\times p(c_E^\\star \\mid M_2) \\times \\frac{1}{q_{12}(u^\\star \\mid \\theta_1)} \\times 1 $$\n代入概率密度函数：\n$$ R = \\exp\\left(\\frac{b^2 - (b+au^\\star)^2}{2\\sigma^2}\\right) \\times \\frac{p(M_2)}{p(M_1)} \\times \\frac{\\frac{1}{\\sqrt{2\\pi\\tau^2}} \\exp\\left(-\\frac{(u^\\star)^2}{2\\tau^2}\\right)}{\\frac{1}{\\sqrt{2\\pi s^2}} \\exp\\left(-\\frac{(u^\\star-m)^2}{2s^2}\\right)} $$\n$$ R = \\exp\\left(\\frac{b^2 - (b+au^\\star)^2}{2\\sigma^2}\\right) \\times \\frac{p(M_2)}{p(M_1)} \\times \\frac{s}{\\tau} \\exp\\left(\\frac{(u^\\star-m)^2}{2s^2} - \\frac{(u^\\star)^2}{2\\tau^2}\\right) $$\n现在，我们代入所提供的数值：\n$b=0.5$, $a=-2.0$, $\\sigma=0.3$, $u^\\star=-0.3$, $p(M_1)=0.6$, $p(M_2)=0.4$, $\\tau=1$, $m=-0.1$, $s=0.5$。\n\n1.  似然相关项的指数：\n    $M_2$ 的均值为 $\\mu_2 = b + a u^\\star = 0.5 + (-2.0)(-0.3) = 0.5 + 0.6 = 1.1$。\n    指数为 $\\frac{b^2 - \\mu_2^2}{2\\sigma^2} = \\frac{(0.5)^2 - (1.1)^2}{2(0.3)^2} = \\frac{0.25 - 1.21}{2(0.09)} = \\frac{-0.96}{0.18} = -\\frac{16}{3}$。\n\n2.  模型先验比：\n    $\\frac{p(M_2)}{p(M_1)} = \\frac{0.4}{0.6} = \\frac{2}{3}$。\n\n3.  先验/提议项：\n    预因子为 $\\frac{s}{\\tau} = \\frac{0.5}{1} = 0.5$。\n    指数为 $\\frac{(u^\\star-m)^2}{2s^2} - \\frac{(u^\\star)^2}{2\\tau^2} = \\frac{(-0.3 - (-0.1))^2}{2(0.5)^2} - \\frac{(-0.3)^2}{2(1)^2} = \\frac{(-0.2)^2}{0.5} - \\frac{0.09}{2} = \\frac{0.04}{0.5} - 0.045 = 0.08 - 0.045 = 0.035$。\n\n将这些部分组合到 $R$ 的表达式中：\n$$ R = \\exp\\left(-\\frac{16}{3}\\right) \\times \\frac{2}{3} \\times 0.5 \\times \\exp(0.035) $$\n$$ R = \\exp\\left(-\\frac{16}{3} + 0.035\\right) \\times \\left(\\frac{2}{3} \\times \\frac{1}{2}\\right) $$\n$$ R = \\exp\\left(-5.3333... + 0.035\\right) \\times \\frac{1}{3} $$\n$$ R = \\exp\\left(-5.298333...\\right) \\times \\frac{1}{3} $$\n$$ R \\approx (0.005000406) \\times \\frac{1}{3} \\approx 0.001666802 $$\n接受概率 $\\alpha_{\\text{birth}} = \\min(1, R)$。由于 $R < 1$，我们有 $\\alpha_{\\text{birth}} = R$。\n将结果四舍五入到四位有效数字得到 $0.001667$。",
            "answer": "$$\\boxed{0.001667}$$"
        }
    ]
}