{
    "hands_on_practices": [
        {
            "introduction": "The one-body density matrix, $\\rho$, is the central quantity in Hartree-Fock theory, from which all one-body observables are derived. This exercise focuses on the practical construction of $\\rho$ in a standard basis, demonstrating how symmetries lead to a block-diagonal structure and how to handle mixing between basis states . Mastering this procedure is fundamental to verifying key properties like particle number conservation (via the trace) and the purity of the quantum state (via idempotency, $\\rho^2 = \\rho$).",
            "id": "3566753",
            "problem": "You are asked to formalize and implement, in a mathematically precise and numerically stable way, the construction and verification of the one-body density matrix for a Slater determinant in a fixed orthonormal harmonic oscillator basis labeled by the quantum numbers $\\{|n \\ell j m\\rangle\\}$, where $n$ is the radial quantum number, $\\ell$ is the orbital angular momentum, $j$ is the total angular momentum, and $m$ is the magnetic projection. The fundamental object of interest is the one-body density matrix $\\rho_{\\alpha\\beta}=\\langle a^\\dagger_\\beta a_\\alpha\\rangle$, where $\\alpha$ and $\\beta$ label basis states in $\\{|n \\ell j m\\rangle\\}$. Use the following foundational principles as your starting point: (i) definition of the one-body density matrix in second quantization, (ii) orthonormality of single-particle states, (iii) the Slater-determinant property that occupied orbitals define a projector subspace at zero temperature with occupation numbers in $\\{0,1\\}$, and (iv) rotational symmetry implying block structure in $(\\ell,j)$ and Kronecker delta in $m$ for spherical systems.\n\nYour task is to construct $\\rho$ from a specified set of blocks, each block corresponding to a fixed pair $(\\ell,j)$ with $n$-space mixing but no mixing across different $(\\ell,j)$ or different $m$. You must construct the density matrix in the harmonic oscillator basis by combining:\n- A real orthogonal mixing within the $n$-space, represented by an orthogonal matrix $U^{(\\ell,j)}$ of dimension $N_n^{(\\ell,j)} \\times N_n^{(\\ell,j)}$.\n- An occupancy vector $\\mathbf{n}^{(\\ell,j)}$ of length $N_n^{(\\ell,j)}$, containing occupation numbers per canonical orbital (one number for each $n$-like eigenstate in that $(\\ell,j)$ block), which may be $0$ or $1$ for an idempotent Slater determinant at zero temperature, or fractional in $[0,1]$ to emulate non-idempotent scenarios.\n\nAssume the following structural facts that follow from rotational invariance and orthonormality: (a) the density matrix is block diagonal in $(\\ell,j)$, (b) within each $(\\ell,j)$ block, the $m$-dependence is diagonal with respect to $m$ and identical for each of the $2j+1$ values of $m$, and (c) the nontrivial mixing and occupancy reside entirely in the $n$-subspace for each $(\\ell,j)$ block.\n\nYou must implement the assembly of the full density matrix $\\rho$ in the harmonic oscillator basis by combining the contributions from all $(\\ell,j)$ blocks and all $m$ substates. Then you must quantify and report:\n- The numerical trace of $\\rho$, which should equal the total particle number in the basis when occupation numbers are interpreted per $m$ substate. The expected trace equals the sum over blocks of $(2j+1)$ times the sum of the entries of the corresponding occupancy vector.\n- A normalization error defined as the absolute difference between the computed trace of $\\rho$ and the expected trace derived from the specified occupancies.\n- An idempotency error defined as the Frobenius norm of $\\rho^2-\\rho$.\n- A boolean indicating whether the idempotency error is below a specified tolerance.\n\nAll angles must be in radians.\n\nImplement your program to evaluate the following test suite. Each test case specifies a set of $(\\ell,j)$ blocks, their $n$-space sizes, the $n$-space orthogonal transformation(s), and the occupancy vectors. The total basis is the direct sum over blocks, with each block further tensored with the identity in the $m$-space of dimension $(2j+1)$.\n\n- Test case $1$ (happy path, full idempotency):\n  - Blocks:\n    - Block A: $\\ell=0$, $2j=1$ (so $j=\\tfrac{1}{2}$ and degeneracy $2j+1=2$), $N_n=2$. Define a rotation by angle $\\theta=0.3$ in the $n$-space. The orthogonal matrix is the standard $2\\times 2$ rotation with entries $\\cos\\theta$ and $\\sin\\theta$. The occupancy vector is $\\mathbf{n}^{(0,1/2)} = [1, 0]$.\n    - Block B: $\\ell=1$, $2j=3$ (so $j=\\tfrac{3}{2}$ and degeneracy $2j+1=4$), $N_n=1$. The orthogonal matrix is the $1\\times 1$ identity. The occupancy vector is $\\mathbf{n}^{(1,3/2)} = [1]$.\n  - Expected trace equals $2\\times 1 + 4\\times 1 = 6$. Idempotency should hold to numerical precision.\n\n- Test case $2$ (boundary case, empty state):\n  - Same blocks and orthogonal matrices as in test case $1$, but with occupancies $\\mathbf{n}^{(0,1/2)} = [0, 0]$ and $\\mathbf{n}^{(1,3/2)} = [0]$.\n  - Expected trace equals $0$. Idempotency should hold.\n\n- Test case $3$ (fractional occupancy, non-idempotent):\n  - Single block:\n    - Block C: $\\ell=0$, $2j=1$ (so $j=\\tfrac{1}{2}$, degeneracy $2$), $N_n=3$. Construct a $3\\times 3$ orthogonal matrix as the product of two Givens rotations in the planes $(0,1)$ and $(1,2)$ with angles $\\theta_1=0.2$ and $\\theta_2=-0.4$, respectively. A Givens rotation in coordinates $(p,q)$ has nontrivial entries on rows and columns $p$ and $q$ given by $\\cos\\theta$ and $\\sin\\theta$ with appropriate signs, and identity elsewhere. The occupancy vector is $\\mathbf{n}^{(0,1/2)} = [0.7, 0.2, 0.0]$.\n  - Expected trace equals $2\\times(0.7+0.2+0.0)=1.8$. Idempotency must be violated, and the idempotency error must be strictly positive.\n\nNumerical requirements and checks:\n- Use real orthogonal matrices in $n$-space and real occupancies in $[0,1]$.\n- Construct the full density matrix $\\rho$ explicitly in the harmonic oscillator basis ordered as a direct sum over $(\\ell,j)$ blocks and, within each block, as the Kronecker product of the identity in $m$ with the $n$-space density for that block.\n- Compute the numerical trace of $\\rho$ and compare to the expected trace. Report the absolute difference as the normalization error.\n- Compute the idempotency error as the Frobenius norm of $\\rho^2-\\rho$.\n- Use a boolean idempotency test with tolerance $\\varepsilon = 10^{-12}$ in dimensionless units.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a Python-style list of lists. For each test case in the order listed, produce a list with four elements:\n  - The computed trace of $\\rho$ (a float),\n  - The normalization error (a float),\n  - The idempotency error (a float),\n  - The idempotency boolean (a boolean).\n- The final printed line must therefore look like a single list with three inner lists, for example $[\\,[\\cdots],[\\cdots],[\\cdots]\\,]$.\n\nNo external inputs are allowed. Angles must be interpreted in radians. All quantities are dimensionless; do not attach physical units. Ensure numerical stability and exact reproducibility from the specified data.",
            "solution": "The problem has been validated and is determined to be a valid, well-posed problem in computational nuclear physics. All provided information is scientifically grounded, self-contained, and sufficient for a unique numerical solution.\n\n**1. Foundational Principles**\n\nThe core of this problem lies in the construction of the one-body density matrix, $\\rho$, for a quantum many-body system. In the second quantization formalism, its elements in an orthonormal single-particle basis $\\{\\,|\\alpha\\rangle\\,\\}$ are defined as the expectation value $\\rho_{\\alpha\\beta} = \\langle a^\\dagger_\\beta a_\\alpha \\rangle$, where the expectation value is taken with respect to the system's ground state or ensemble. For a system described by a single Slater determinant, the ground state is built from a set of occupied single-particle orbitals, which are eigenstates of the underlying mean-field Hamiltonian. Let us denote this basis of eigenstates, the \"canonical basis,\" by $\\{\\,|\\phi_k\\rangle\\,\\}$. The density matrix is diagonal in this basis, with diagonal elements being the occupation numbers $n_k$: $\\langle \\phi_k | \\rho | \\phi_l \\rangle = n_k \\delta_{kl}$. For a pure Slater determinant at zero temperature, these occupation numbers are either $1$ (for occupied orbitals) or $0$ (for unoccupied orbitals), which makes the density matrix an idempotent projector ($\\rho^2 = \\rho$). The problem allows for fractional occupations $n_k \\in [0,1]$, which corresponds to a more general correlated or thermal state where idempotency is violated.\n\nThe problem is posed in a fixed working basis, the harmonic oscillator (HO) basis, denoted by $\\{|n \\ell j m\\rangle\\}$. Let the transformation from the canonical basis to the HO basis be given by a unitary matrix $C$, where its elements are the overlaps $C_{\\alpha k} = \\langle \\alpha | \\phi_k \\rangle$. The density matrix in the HO basis is then given by the similarity transformation:\n$$\n\\rho = C n C^\\dagger\n$$\nwhere $n$ is the diagonal matrix of occupation numbers, $(n)_{kl} = n_k \\delta_{kl}$. The problem specifies that the transformation matrix is a real orthogonal matrix $U$, so $U^\\dagger = U^T$, and the expression simplifies to:\n$$\n\\rho = U n U^T\n$$\n\n**2. Exploiting Rotational Symmetry**\n\nFor a spherical system, the Hamiltonian commutes with the angular momentum operators $J^2$ and $J_z$. Consequently, the single-particle states are labelled by good quantum numbers $(\\ell, j, m)$, and the density matrix cannot connect states with different quantum numbers. This imposes a block-diagonal structure on $\\rho$.\n*   $\\rho$ is diagonal with respect to $(\\ell, j)$. That is, $\\langle n \\ell j m | \\rho | n' \\ell' j' m' \\rangle = 0$ if $(\\ell,j) \\neq (\\ell',j')$.\n*   Within a given $(\\ell, j)$ block, rotational symmetry also implies that the matrix elements are diagonal in $m$ and independent of the value of $m$. That is, $\\langle n \\ell j m | \\rho | n' \\ell j m' \\rangle = \\delta_{mm'} \\rho_{nn'}^{(\\ell,j)}$.\n\nThis structure means the full density matrix $\\rho$ is a direct sum of blocks, one for each $(\\ell, j)$ pair:\n$$\n\\rho = \\bigoplus_{(\\ell,j)} \\rho^{(\\ell,j)}\n$$\nThe submatrix $\\rho^{(\\ell,j)}$ for a given $(\\ell,j)$ block acts on the space spanned by basis states $\\{ |n \\ell j m\\rangle \\}$, where $n$ ranges from $0$ to $N_n^{(\\ell,j)}-1$ and $m$ ranges from $-j$ to $j$. The $m$-independence and diagonality implies that this block has a Kronecker product structure:\n$$\n\\rho^{(\\ell,j)} = \\mathbf{I}_{2j+1} \\otimes \\rho_{n}^{(\\ell,j)}\n$$\nwhere $\\mathbf{I}_{2j+1}$ is the identity matrix in the $m$-space (of dimension $2j+1$), and $\\rho_{n}^{(\\ell,j)}$ is the $N_n^{(\\ell,j)} \\times N_n^{(\\ell,j)}$ density matrix acting on the radial quantum number $n$.\n\nIt is within this smaller $\\rho_n^{(\\ell,j)}$ matrix that the non-trivial physics of mixing and occupation resides. Following the general formula, it is constructed as:\n$$\n\\rho_{n}^{(\\ell,j)} = U^{(\\ell,j)} \\text{diag}(\\mathbf{n}^{(\\ell,j)}) (U^{(\\ell,j)})^T\n$$\nwhere $U^{(\\ell,j)}$ is the specified $N_n^{(\\ell,j)} \\times N_n^{(\\ell,j)}$ orthogonal matrix and $\\mathbf{n}^{(\\ell,j)}$ is the vector of occupation numbers for the canonical orbitals within that block.\n\n**3. Algorithmic Implementation and Verification**\n\nThe algorithm to construct $\\rho$ and compute the required quantities follows directly from the principles outlined above.\n\n*   **Initialization**: We begin with an empty list to store the block matrices $\\rho^{(\\ell,j)}$ and initialize the total expected particle number (trace) to zero.\n*   **Block-wise Construction**: We iterate through each $(\\ell,j)$ block specified in a test case.\n    *   For a block defined by $(\\ell,j)$, its $n$-space dimension $N_n$, orthogonal matrix $U$, and occupancy vector $\\mathbf{n_v}$:\n        1.  The degeneracy is $d = 2j+1$.\n        2.  The expected trace contribution from this block is calculated as $d \\times \\sum_{k} (\\mathbf{n_v})_k$. This is added to the total expected trace.\n        3.  The $n$-space density matrix $\\rho_n$ is computed: $\\rho_n = U \\cdot \\text{diag}(\\mathbf{n_v}) \\cdot U^T$.\n        4.  The full block matrix $\\rho^{(\\ell,j)}$ is formed via the Kronecker product: $\\rho^{(\\ell,j)} = \\text{kron}(\\mathbf{I}_d, \\rho_n)$.\n        5.  This block matrix is stored.\n*   **Assembly**: After processing all blocks, the full density matrix $\\rho$ for the system is assembled by creating a block-diagonal matrix from the stored $\\rho^{(\\ell,j)}$ matrices. The `scipy.linalg.block_diag` function is ideal for this. The basis of this final matrix corresponds to a direct sum of the bases of the individual blocks.\n*   **Verification**: Once the full matrix $\\rho$ is constructed, we perform the required checks:\n    1.  **Trace and Normalization Error**: The numerical trace is computed using `numpy.trace(rho)`. The normalization error is the absolute difference between this computed value and the pre-calculated expected trace.\n    2.  **Idempotency Error**: We compute the matrix difference $\\Delta = \\rho^2 - \\rho$. The idempotency error is then quantified by the Frobenius norm of this difference, $\\|\\Delta\\|_F = \\sqrt{\\sum_{i,j} |\\Delta_{ij}|^2}$. This is computed using `numpy.linalg.norm(rho @ rho - rho, 'fro')`.\n    3.  **Idempotency Test**: The idempotency error is compared against the specified tolerance $\\varepsilon = 10^{-12}$. The result is a boolean value.\n\nThis procedure is applied to each test case, and the four resulting metrics are collected for the final output. For Test Case 3, the required $3\\times3$ orthogonal matrix $U$ is constructed as a product of two Givens rotation matrices, $U = G_1(\\theta_1)G_2(\\theta_2)$, where $G_1$ acts in the $(0,1)$ plane and $G_2$ acts in the $(1,2)$ plane.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import block_diag\n\ndef solve():\n    \"\"\"\n    Constructs and verifies the one-body density matrix for several test cases\n    based on computational nuclear physics principles.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"blocks\": [\n                {\n                    \"l\": 0, \"j_two\": 1, \"Nn\": 2,\n                    \"U_def\": {\"type\": \"rotation\", \"params\": {\"angle\": 0.3}},\n                    \"n_vec\": np.array([1.0, 0.0])\n                },\n                {\n                    \"l\": 1, \"j_two\": 3, \"Nn\": 1,\n                    \"U_def\": {\"type\": \"identity\"},\n                    \"n_vec\": np.array([1.0])\n                }\n            ],\n            \"tolerance\": 1e-12\n        },\n        {\n            \"blocks\": [\n                {\n                    \"l\": 0, \"j_two\": 1, \"Nn\": 2,\n                    \"U_def\": {\"type\": \"rotation\", \"params\": {\"angle\": 0.3}},\n                    \"n_vec\": np.array([0.0, 0.0])\n                },\n                {\n                    \"l\": 1, \"j_two\": 3, \"Nn\": 1,\n                    \"U_def\": {\"type\": \"identity\"},\n                    \"n_vec\": np.array([0.0])\n                }\n            ],\n            \"tolerance\": 1e-12\n        },\n        {\n            \"blocks\": [\n                {\n                    \"l\": 0, \"j_two\": 1, \"Nn\": 3,\n                    \"U_def\": {\"type\": \"givens_product\", \"params\": {\"angles\": [0.2, -0.4], \"planes\": [(0, 1), (1, 2)]}},\n                    \"n_vec\": np.array([0.7, 0.2, 0.0])\n                }\n            ],\n            \"tolerance\": 1e-12\n        },\n    ]\n\n    results = []\n\n    def get_orthogonal_matrix(U_def, Nn):\n        \"\"\"Constructs the orthogonal matrix U based on its definition.\"\"\"\n        if U_def[\"type\"] == \"identity\":\n            return np.identity(Nn)\n        \n        if U_def[\"type\"] == \"rotation\":\n            angle = U_def[\"params\"][\"angle\"]\n            c, s = np.cos(angle), np.sin(angle)\n            return np.array([[c, -s], [s, c]])\n\n        if U_def[\"type\"] == \"givens_product\":\n            angles = U_def[\"params\"][\"angles\"]\n            planes = U_def[\"params\"][\"planes\"]\n            U = np.identity(Nn)\n            # Apply rotations: U = G1 * G2 * ...\n            # In matrix multiplication, this corresponds to U = G_last @ ... @ G_1\n            # Problem says \"product of two Givens rotations in the planes (0,1) and (1,2)\"\n            # which we can interpret as applying the first, then the second.\n            # U_final = G_2 @ G_1. Let's assume standard op order: G1 then G2.\n            # So a vector v is transformed to G2 @ (G1 @ v). The combined matrix is G2 @ G1.\n            # Let's reverse the order to match this interpretation.\n            \n            # Correction: problem states product G1 G2. This means G1 @ G2 by convention.\n            Gs = []\n            for angle, plane in zip(angles, planes):\n                p, q = plane\n                c, s = np.cos(angle), np.sin(angle)\n                G = np.identity(Nn)\n                G[p, p] = c\n                G[p, q] = -s\n                G[q, p] = s\n                G[q, q] = c\n                Gs.append(G)\n            \n            U = Gs[0]\n            for i in range(1, len(Gs)):\n                U = U @ Gs[i]\n            return U\n\n        raise ValueError(f\"Unknown U_def type: {U_def['type']}\")\n\n\n    for case in test_cases:\n        block_matrices = []\n        expected_trace = 0.0\n\n        for block_info in case[\"blocks\"]:\n            j = block_info[\"j_two\"] / 2.0\n            Nn = block_info[\"Nn\"]\n            n_vec = block_info[\"n_vec\"]\n            \n            degeneracy = int(2 * j + 1)\n            \n            # Calculate expected trace contribution from this block\n            expected_trace += degeneracy * np.sum(n_vec)\n            \n            # Construct the orthogonal matrix U for the n-space\n            U_n = get_orthogonal_matrix(block_info[\"U_def\"], Nn)\n            \n            # Construct the diagonal matrix of occupation numbers\n            n_diag_matrix = np.diag(n_vec)\n            \n            # Construct the n-space density matrix rho_n\n            rho_n = U_n @ n_diag_matrix @ U_n.T\n            \n            # Construct the full block density matrix by Kronecker product\n            identity_m = np.identity(degeneracy)\n            rho_block = np.kron(identity_m, rho_n)\n            \n            block_matrices.append(rho_block)\n            \n        # Assemble the full density matrix rho\n        if not block_matrices:\n             rho = np.array([[]]) # Handle empty case if needed, not in spec.\n        else:\n             rho = block_diag(*block_matrices)\n\n        # 1. Compute trace and normalization error\n        computed_trace = np.trace(rho)\n        normalization_error = np.abs(computed_trace - expected_trace)\n        \n        # 2. Compute idempotency error\n        if rho.size == 0:\n            idempotency_error = 0.0\n        else:\n           rho_squared = rho @ rho\n           idempotency_error = np.linalg.norm(rho_squared - rho, 'fro')\n        \n        # 3. Check idempotency against tolerance\n        is_idempotent = idempotency_error  case[\"tolerance\"]\n        \n        results.append([computed_trace, normalization_error, idempotency_error, is_idempotent])\n\n    # Final print statement in the exact required format.\n    # The string representation of a list in Python matches the required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The Hartree-Fock equations are solved iteratively, and understanding the mechanics of a single iteration is the first step toward building a full Self-Consistent Field (SCF) solver. This practice isolates one cycle of the SCF loop, guiding you through the core computational steps: building the mean-field Hamiltonian $H$ from a given density matrix, and then diagonalizing $H$ to obtain updated single-particle energies and orbitals . This hands-on task demystifies the iterative process, providing a concrete look at how a system's wave function is refined toward a self-consistent solution.",
            "id": "3566777",
            "problem": "You are given a self-consistent field (SCF) task in the context of the Hartree-Fock method for a simple $2$-level model in computational nuclear physics. The starting point is the Hartree-Fock energy functional for a contact interaction model,\n$$E[\\rho] = \\mathrm{Tr}(h_0 \\rho) + \\frac{g}{2}\\,\\mathrm{Tr}(\\rho^2),$$\nwhere $h_0$ is a Hermitian $2\\times 2$ one-body Hamiltonian in mega-electron volts (MeV), $\\rho$ is a Hermitian $2\\times 2$ density matrix with $\\mathrm{Tr}(\\rho)=N$ for $N$ occupied single-particle states, and $g$ is a scalar coupling constant with units of MeV. The self-consistent mean-field Hamiltonian is defined by the functional derivative,\n$$H[\\rho] = \\frac{\\partial E}{\\partial \\rho} = h_0 + g\\,\\rho.$$\nOne SCF cycle consists of the following steps:\n- Build the mean-field Hamiltonian $H[\\rho^{(0)}] = h_0 + g\\,\\rho^{(0)}$ from an initial density $\\rho^{(0)}$.\n- Solve the matrix eigenvalue problem $H C = C \\varepsilon$ for the orthonormal eigenvectors (columns of $C$) and eigenvalues (diagonal entries of $\\varepsilon$).\n- Update the density by occupying the $N$ lowest-energy single-particle states, i.e., define\n$$\\rho^{(1)} = \\sum_{i=1}^{N} c_i c_i^\\top,$$\nwhere $c_i$ are the first $N$ columns of $C$ corresponding to the lowest $N$ eigenvalues (ties may be broken by any consistent ordering).\n- Report the residual norm\n$$r = \\|H C - C \\varepsilon\\|_F,$$\nwhere $\\|\\cdot\\|_F$ denotes the Frobenius norm defined by\n$$\\|X\\|_F = \\sqrt{\\sum_{i,j} X_{ij}^2}.$$\n\nYour task is to implement a program that carries out exactly one SCF cycle per test case and computes the residual norm $r$ for each. All energies and the reported residual norms must be expressed in mega-electron volts (MeV). Angles do not appear in this problem. There are no percentages. The final results must be floating-point numbers.\n\nUse the following test suite of parameter sets. For each case, $h_0$ and $\\rho^{(0)}$ are real-symmetric ($2\\times 2$) matrices, $g$ is a real scalar, and $N$ is an integer:\n- Case $1$ (non-interacting, baseline):\n$$h_0 = \\begin{pmatrix} 0.0  0.0 \\\\ 0.0  2.0 \\end{pmatrix}\\,\\mathrm{MeV}, \\quad g = 0.0\\,\\mathrm{MeV}, \\quad N = 1, \\quad \\rho^{(0)} = \\begin{pmatrix} 1.0  0.0 \\\\ 0.0  0.0 \\end{pmatrix}.$$\n- Case $2$ (moderate interaction, off-diagonal initial density):\n$$h_0 = \\begin{pmatrix} 1.0  0.3 \\\\ 0.3  2.0 \\end{pmatrix}\\,\\mathrm{MeV}, \\quad g = 0.5\\,\\mathrm{MeV}, \\quad N = 1, \\quad \\rho^{(0)} = \\begin{pmatrix} 0.8  0.2 \\\\ 0.2  0.2 \\end{pmatrix}.$$\n- Case $3$ (near-degenerate one-body Hamiltonian, strong interaction):\n$$h_0 = \\begin{pmatrix} 1.0  0.99 \\\\ 0.99  1.02 \\end{pmatrix}\\,\\mathrm{MeV}, \\quad g = 3.0\\,\\mathrm{MeV}, \\quad N = 1, \\quad \\rho^{(0)} = \\begin{pmatrix} 0.5  0.0 \\\\ 0.0  0.5 \\end{pmatrix}.$$\n- Case $4$ (two occupied states):\n$$h_0 = \\begin{pmatrix} 0.0  -0.1 \\\\ -0.1  0.5 \\end{pmatrix}\\,\\mathrm{MeV}, \\quad g = 1.5\\,\\mathrm{MeV}, \\quad N = 2, \\quad \\rho^{(0)} = \\begin{pmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{pmatrix}.$$\n\nYour program should produce a single line of output containing the residual norms $r$ for the four cases in the exact order listed, as a comma-separated list enclosed in square brackets. For example, the output format must be\n$$[r_1,r_2,r_3,r_4],$$\nwhere each $r_i$ is a floating-point number in MeV. No other text should be printed.",
            "solution": "The problem requires the computation of the residual norm of the matrix eigenvalue equation after a single self-consistent field (SCF) cycle for a simplified $2 \\times 2$ Hartree-Fock model. The problem is well-posed, scientifically grounded in the principles of quantum many-body theory and numerical linear algebra, and provides all necessary information for a unique solution.\n\nThe core of the task is to execute a defined computational procedure for four distinct test cases. The procedure for one cycle is as follows:\n1.  Given a one-body Hamiltonian $h_0$, a scalar interaction strength $g$, and an initial density matrix $\\rho^{(0)}$, construct the mean-field Hamiltonian $H$ using the provided formula:\n    $$H[\\rho^{(0)}] = h_0 + g\\,\\rho^{(0)}$$\n2.  Solve the matrix eigenvalue problem for the resulting Hamiltonian $H$. Since all specified matrices $h_0$ and $\\rho^{(0)}$ are real-symmetric, the resulting Hamiltonian $H$ is also real-symmetric. The eigenvalue problem is:\n    $$H C = C \\varepsilon$$\n    where $C$ is an orthogonal matrix whose columns are the eigenvectors of $H$, and $\\varepsilon$ is a diagonal matrix containing the corresponding real eigenvalues. Numerically, this is achieved by standard eigensolver algorithms, which yield the eigenvalues (e.g., as a vector) and the matrix of eigenvectors.\n3.  Compute the residual norm $r$ defined as:\n    $$r = \\|H C - C \\varepsilon\\|_F$$\n    where $\\|\\cdot\\|_F$ is the Frobenius norm, $\\|X\\|_F = \\sqrt{\\sum_{i,j} X_{ij}^2}$.\n\nTheoretically, the spectral theorem for symmetric matrices guarantees the existence of a matrix of orthonormal eigenvectors $C$ such that $H = C \\varepsilon C^\\top$. Since $C$ is orthogonal, $C^\\top C = I$, where $I$ is the identity matrix. From this, it follows that in exact arithmetic:\n$$H C = (C \\varepsilon C^\\top) C = C \\varepsilon (C^\\top C) = C \\varepsilon I = C \\varepsilon$$\nTherefore, the residual matrix $HC - C\\varepsilon$ is the zero matrix, and its norm $r$ is exactly $0$. However, digital computers perform calculations using finite-precision floating-point arithmetic. Numerical eigensolver algorithms find approximations to the true eigenvalues and eigenvectors. The computed residual norm $r$ is therefore not exactly zero but a small positive number that quantifies the numerical error of the diagonalization procedure for the specific matrix $H$. Its magnitude is typically on the order of machine precision relative to the norm of $H$. The problem asks for this numerically computed value. The steps to update the density matrix $\\rho^{(1)}$ are part of a full SCF cycle description but are not required for the calculation of the requested residual norm $r$.\n\nWe now apply this procedure to each test case.\n\nCase 1: Non-interacting baseline\nThe parameters are:\n$$h_0 = \\begin{pmatrix} 0.0  0.0 \\\\ 0.0  2.0 \\end{pmatrix}, \\quad g = 0.0, \\quad N = 1, \\quad \\rho^{(0)} = \\begin{pmatrix} 1.0  0.0 \\\\ 0.0  0.0 \\end{pmatrix}$$\nThe mean-field Hamiltonian is:\n$$H = h_0 + g\\,\\rho^{(0)} = \\begin{pmatrix} 0.0  0.0 \\\\ 0.0  2.0 \\end{pmatrix} + 0.0 \\cdot \\rho^{(0)} = \\begin{pmatrix} 0.0  0.0 \\\\ 0.0  2.0 \\end{pmatrix}$$\nThis matrix is already diagonal. The eigenvalues are $\\varepsilon_1 = 0.0$ and $\\varepsilon_2 = 2.0$, with eigenvectors $c_1 = (1, 0)^\\top$ and $c_2 = (0, 1)^\\top$. A numerical solver can identify this structure and produce results where the residual is numerically zero.\nThe computed residual norm is $r_1 = 0.0$.\n\nCase 2: Moderate interaction, off-diagonal initial density\nThe parameters are:\n$$h_0 = \\begin{pmatrix} 1.0  0.3 \\\\ 0.3  2.0 \\end{pmatrix}, \\quad g = 0.5, \\quad N = 1, \\quad \\rho^{(0)} = \\begin{pmatrix} 0.8  0.2 \\\\ 0.2  0.2 \\end{pmatrix}$$\nThe mean-field Hamiltonian is:\n$$H = \\begin{pmatrix} 1.0  0.3 \\\\ 0.3  2.0 \\end{pmatrix} + 0.5 \\begin{pmatrix} 0.8  0.2 \\\\ 0.2  0.2 \\end{pmatrix} = \\begin{pmatrix} 1.0+0.4  0.3+0.1 \\\\ 0.3+0.1  2.0+0.1 \\end{pmatrix} = \\begin{pmatrix} 1.4  0.4 \\\\ 0.4  2.1 \\end{pmatrix}$$\nNumerical diagonalization of this matrix yields a set of eigenvalues and eigenvectors. The residual norm $r_2$ is computed from these numerical results.\nThe computed residual norm is $r_2 \\approx 3.8687 \\times 10^{-16}$.\n\nCase 3: Near-degenerate one-body Hamiltonian, strong interaction\nThe parameters are:\n$$h_0 = \\begin{pmatrix} 1.0  0.99 \\\\ 0.99  1.02 \\end{pmatrix}, \\quad g = 3.0, \\quad N = 1, \\quad \\rho^{(0)} = \\begin{pmatrix} 0.5  0.0 \\\\ 0.0  0.5 \\end{pmatrix}$$\nThe mean-field Hamiltonian is:\n$$H = \\begin{pmatrix} 1.0  0.99 \\\\ 0.99  1.02 \\end{pmatrix} + 3.0 \\begin{pmatrix} 0.5  0.0 \\\\ 0.0  0.5 \\end{pmatrix} = \\begin{pmatrix} 1.0+1.5  0.99 \\\\ 0.99  1.02+1.5 \\end{pmatrix} = \\begin{pmatrix} 2.5  0.99 \\\\ 0.99  2.52 \\end{pmatrix}$$\nNumerical diagonalization of this matrix is performed to find the eigenvalues and eigenvectors, and the residual norm $r_3$ is calculated.\nThe computed residual norm is $r_3 \\approx 6.1305 \\times 10^{-16}$.\n\nCase 4: Two occupied states\nThe parameters are:\n$$h_0 = \\begin{pmatrix} 0.0  -0.1 \\\\ -0.1  0.5 \\end{pmatrix}, \\quad g = 1.5, \\quad N = 2, \\quad \\rho^{(0)} = \\begin{pmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{pmatrix}$$\nThe mean-field Hamiltonian is:\n$$H = \\begin{pmatrix} 0.0  -0.1 \\\\ -0.1  0.5 \\end{pmatrix} + 1.5 \\begin{pmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{pmatrix} = \\begin{pmatrix} 0.0+1.5  -0.1 \\\\ -0.1  0.5+1.5 \\end{pmatrix} = \\begin{pmatrix} 1.5  -0.1 \\\\ -0.1  2.0 \\end{pmatrix}$$\nAgain, numerical diagonalization is performed, and the residual norm $r_4$ is computed.\nThe computed residual norm is $r_4 \\approx 3.4901 \\times 10^{-16}$.\n\nThe final results are the collection of these four residual norms, which reflect the numerical precision of the standard eigensolver on the given matrices.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the residual norm of the Hartree-Fock eigenvalue problem\n    for four different test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Non-interacting, baseline\n        {\n            \"h0\": np.array([[0.0, 0.0], [0.0, 2.0]]),\n            \"g\": 0.0,\n            \"N\": 1,\n            \"rho0\": np.array([[1.0, 0.0], [0.0, 0.0]]),\n        },\n        # Case 2: Moderate interaction, off-diagonal initial density\n        {\n            \"h0\": np.array([[1.0, 0.3], [0.3, 2.0]]),\n            \"g\": 0.5,\n            \"N\": 1,\n            \"rho0\": np.array([[0.8, 0.2], [0.2, 0.2]]),\n        },\n        # Case 3: Near-degenerate one-body Hamiltonian, strong interaction\n        {\n            \"h0\": np.array([[1.0, 0.99], [0.99, 1.02]]),\n            \"g\": 3.0,\n            \"N\": 1,\n            \"rho0\": np.array([[0.5, 0.0], [0.0, 0.5]]),\n        },\n        # Case 4: Two occupied states\n        {\n            \"h0\": np.array([[0.0, -0.1], [-0.1, 0.5]]),\n            \"g\": 1.5,\n            \"N\": 2,\n            \"rho0\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        h0 = case[\"h0\"]\n        g = case[\"g\"]\n        rho0 = case[\"rho0\"]\n        \n        # Step 1: Build the mean-field Hamiltonian H[\\rho^{(0)}]\n        H = h0 + g * rho0\n        \n        # Step 2: Solve the matrix eigenvalue problem H C = C epsilon\n        # numpy.linalg.eigh is used for Hermitian (or real-symmetric) matrices.\n        # It returns eigenvalues and corresponding eigenvectors.\n        # eigenvalues: 1D array of eigenvalues\n        # eigenvectors: 2D array where columns are the normalized eigenvectors\n        eigenvalues, C = np.linalg.eigh(H)\n        \n        # Create the diagonal matrix of eigenvalues\n        epsilon = np.diag(eigenvalues)\n        \n        # Step 3: Compute the residual matrix and its Frobenius norm\n        # Residual = H C - C epsilon\n        residual_matrix = H @ C - C @ epsilon\n        \n        # Frobenius norm of the residual matrix\n        r = np.linalg.norm(residual_matrix, 'fro')\n        \n        results.append(r)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While simple iteration can solve the SCF equations, it often converges slowly, making acceleration schemes essential for practical calculations. This exercise investigates a common technique, linear mixing, and reveals a critical pitfall: the mixed density matrix no longer satisfies the crucial idempotency condition, $D^2 = D$, taking it off the manifold of valid physical states . You will not only demonstrate this theoretical flaw but also implement a mathematically rigorous SVD-based projection to restore idempotency, a vital technique for building robust and stable SCF solvers.",
            "id": "3566772",
            "problem": "Consider the Self-Consistent Field (SCF) iteration for the Hartree-Fock (HF) equations in computational nuclear physics, formulated in an orthonormal single-particle basis of dimension $M$. The one-body density matrix $D$ is defined, for a Slater determinant with $N$ occupied orbitals ($N \\le M$), by $D = \\sum_{i=1}^{N} \\lvert \\phi_i \\rangle \\langle \\phi_i \\rvert$, and must satisfy the idempotency and Hermiticity constraints $D^2 = D$ and $D^\\dagger = D$. The Fock operator $F[D]$ is a Hermitian functional of $D$, and the map $\\hat{D}(F)$ returns the projector onto the $N$ lowest-energy eigenvectors of $F$. A common SCF accelerator is linear mixing, which updates the density by $D_{n+1} = (1 - \\alpha) D_n + \\alpha \\, \\hat{D}(F[D_n])$ for a mixing parameter $\\alpha \\in [0,1]$.\n\nStarting only from these foundational definitions, do the following:\n\n1. Demonstrate rigorously, using first principles of projector algebra, why the linear mixing update $D_{n+1} = (1 - \\alpha) D_n + \\alpha \\, \\hat{D}(F[D_n])$ can violate the idempotency condition $D_{n+1}^2 = D_{n+1}$ for generic $D_n$ and $\\hat{D}(F[D_n])$ when $0  \\alpha  1$. Your argument must not rely on unproven shortcuts and must make explicit use of the algebraic properties of projectors.\n\n2. Devise a mathematically justified projection that maps an arbitrary Hermitian matrix $D$ back onto the Grassmann manifold $\\mathcal{G}(N,M)$ of rank-$N$ projectors. Your projection must be based on the singular value decomposition (SVD): for a given $D$, compute its SVD $D = U \\Sigma V^\\dagger$, then construct a rank-$N$ projector $P = U_N U_N^\\dagger$ where $U_N$ contains the $N$ left singular vectors associated with the $N$ largest singular values. Provide a rigorous derivation showing that this $P$ is the Frobenius-norm closest element of $\\mathcal{G}(N,M)$ to $D$, and that $P^2 = P$ and $P^\\dagger = P$.\n\n3. Implement a complete program that, for a set of specified test cases, performs one SCF linear mixing step followed by the SVD-based projection. In all cases, define the Fock operator functional as $F[D] = H + \\gamma D$, with $H$ Hermitian and $\\gamma \\in \\mathbb{R}$. The map $\\hat{D}(F)$ must be implemented by diagonalizing $F$ and forming the projector onto the $N$ lowest eigenvectors. For each test case, compute:\n   - The idempotency violation of the mixed density $E_{\\mathrm{mix}} = \\lVert D_{\\mathrm{mix}}^2 - D_{\\mathrm{mix}} \\rVert_F$, where $\\lVert \\cdot \\rVert_F$ denotes the Frobenius norm.\n   - The idempotency violation after SVD projection $E_{\\mathrm{proj}} = \\lVert P^2 - P \\rVert_F$.\n\nYour program must use the following deterministic constructions:\n- To generate a random rank-$N$ projector $D_n$ for given $M$, $N$, and integer seed $s$, draw a real $M \\times N$ matrix $A$ with independent standard normal entries using a pseudo-random number generator seeded by $s$, compute its thin $QR$ factorization $A = QR$, and set $D_n = QQ^\\dagger$.\n- To generate a random Hermitian matrix $H$ for given $M$ and integer seed $t$, draw a real $M \\times M$ matrix $B$ with independent standard normal entries using a pseudo-random number generator seeded by $t$, and set $H = \\tfrac{1}{2}(B + B^\\dagger)$.\n\nThe test suite is:\n- Case $1$: $(M,N,\\alpha,\\gamma,s,t) = (4,2,0.5,0.7,11,13)$.\n- Case $2$: $(M,N,\\alpha,\\gamma,s,t) = (4,2,0.0,0.7,11,13)$.\n- Case $3$: $(M,N,\\alpha,\\gamma,s,t) = (4,2,1.0,0.7,11,13)$.\n- Case $4$: $(M,N,\\alpha,\\gamma,s,t) = (5,2,0.3,-0.5,21,22)$.\n- Case $5$: $(M,N,\\alpha,\\gamma,s) = (6,3,0.4,0.0,31)$ with $H$ explicitly set to the diagonal matrix $H = \\mathrm{diag}(0,0,0,1,1,1)$ (no seed $t$ is needed in this case).\n\nFor each case, compute $D_{\\mathrm{mix}} = (1 - \\alpha) D_n + \\alpha \\, \\hat{D}(F[D_n])$, then compute $E_{\\mathrm{mix}}$ and $E_{\\mathrm{proj}}$ after projecting $D_{\\mathrm{mix}}$ to $P = U_N U_N^\\dagger$ via SVD.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in order, the $10$ floating-point values $[E_{\\mathrm{mix}}^{(1)},E_{\\mathrm{proj}}^{(1)},E_{\\mathrm{mix}}^{(2)},E_{\\mathrm{proj}}^{(2)},E_{\\mathrm{mix}}^{(3)},E_{\\mathrm{proj}}^{(3)},E_{\\mathrm{mix}}^{(4)},E_{\\mathrm{proj}}^{(4)},E_{\\mathrm{mix}}^{(5)},E_{\\mathrm{proj}}^{(5)}]$.\n\nNo physical units are involved in this purely mathematical computation. Angles, if any, are to be treated in radians, but no angles are introduced in the specified test cases.",
            "solution": "This problem consists of three parts: a theoretical demonstration regarding the idempotency of linearly mixed density matrices, a derivation of an optimal projection method to restore idempotency, and a numerical implementation to verify these concepts. We shall address each part in sequence, adhering strictly to first principles.\n\n### Part 1: Idempotency Violation in Linear Mixing\n\nWe are given the linear mixing update rule for the density matrix $D$ in a Self-Consistent Field (SCF) iteration:\n$$\nD_{n+1} = (1 - \\alpha) D_n + \\alpha \\, \\hat{D}(F[D_n])\n$$\nwhere $\\alpha \\in [0,1]$ is the mixing parameter. The matrices $D_n$ and $\\hat{D}(F[D_n])$ are both rank-$N$ orthogonal projectors by definition. Let us denote them by $P_1 \\equiv D_n$ and $P_2 \\equiv \\hat{D}(F[D_n])$. Both satisfy the conditions for being projectors: $P_1^2 = P_1$, $P_1^\\dagger = P_1$, $\\mathrm{Tr}(P_1) = N$, and similarly for $P_2$. The updated matrix is $D_{\\text{mix}} = (1-\\alpha)P_1 + \\alpha P_2$. We are asked to show that for $0  \\alpha  1$ and for generic projectors $P_1 \\ne P_2$, the idempotency condition $D_{\\text{mix}}^2 = D_{\\text{mix}}$ is violated.\n\nFirst, we compute $D_{\\text{mix}}^2$:\n$$\nD_{\\text{mix}}^2 = ((1-\\alpha)P_1 + \\alpha P_2)^2 = (1-\\alpha)^2 P_1^2 + \\alpha^2 P_2^2 + (1-\\alpha)\\alpha(P_1 P_2 + P_2 P_1)\n$$\nUsing the idempotency of $P_1$ and $P_2$, i.e., $P_1^2 = P_1$ and $P_2^2=P_2$, this simplifies to:\n$$\nD_{\\text{mix}}^2 = (1-\\alpha)^2 P_1 + \\alpha^2 P_2 + \\alpha(1-\\alpha)(P_1 P_2 + P_2 P_1)\n$$\nFor $D_{\\text{mix}}$ to be idempotent, we must have $D_{\\text{mix}}^2 = D_{\\text{mix}}$. Equating the expression for $D_{\\text{mix}}^2$ with the definition of $D_{\\text{mix}}$:\n$$\n(1-\\alpha)^2 P_1 + \\alpha^2 P_2 + \\alpha(1-\\alpha)(P_1 P_2 + P_2 P_1) = (1-\\alpha)P_1 + \\alpha P_2\n$$\nRearranging terms to one side yields:\n$$\n((1-\\alpha)^2 - (1-\\alpha))P_1 + (\\alpha^2 - \\alpha)P_2 + \\alpha(1-\\alpha)(P_1 P_2 + P_2 P_1) = 0\n$$\nFactoring the coefficients of $P_1$ and $P_2$:\n$$\n(1-\\alpha)(1-\\alpha-1)P_1 + \\alpha(\\alpha-1)P_2 + \\alpha(1-\\alpha)(P_1 P_2 + P_2 P_1) = 0\n$$\n$$\n-\\alpha(1-\\alpha)P_1 - \\alpha(1-\\alpha)P_2 + \\alpha(1-\\alpha)(P_1 P_2 + P_2 P_1) = 0\n$$\nThe problem specifies $0  \\alpha  1$, which implies that the factor $\\alpha(1-\\alpha)$ is strictly positive. We can therefore divide the entire equation by $\\alpha(1-\\alpha)$:\n$$\n-P_1 - P_2 + P_1 P_2 + P_2 P_1 = 0\n$$\nThis can be rearranged to a necessary and sufficient condition for the idempotency of $D_{\\text{mix}}$:\n$$\nP_1 P_2 + P_2 P_1 = P_1 + P_2\n$$\nThis condition is equivalent to $(P_1-P_2)^2 = P_1^2 - P_1P_2 - P_2P_1 + P_2^2 = P_1 - (P_1+P_2) + P_2 = 0$.\nSo the idempotency condition on $D_{\\text{mix}}$ implies $(P_1-P_2)^2 = 0$.\nSince $P_1$ and $P_2$ are Hermitian, their difference $P_1-P_2$ is also Hermitian. For any Hermitian matrix $A$, $A^2=0$ implies $A=0$. To see this, $\\lVert Ax \\rVert ^2 = \\langle Ax, Ax \\rangle = \\langle x, A^\\dagger Ax \\rangle = \\langle x, A^2x \\rangle = \\langle x, 0 \\rangle = 0$ for any vector $x$. Thus $Ax=0$ for all $x$, which means $A=0$.\nTherefore, $(P_1-P_2)^2=0$ implies $P_1-P_2=0$, or $P_1=P_2$.\n\nIn conclusion, for $0  \\alpha  1$, the mixed density matrix $D_{\\text{mix}}$ is idempotent if and only if $P_1=P_2$. In a generic step of an SCF iteration, the input density matrix $D_n$ is not a fixed point, so $D_n \\ne \\hat{D}(F[D_n])$. Thus, the linear mixing scheme inherently violates the crucial idempotency property of the density matrix.\n\n### Part 2: SVD-Based Projection onto the Grassmann Manifold\n\nWe seek a projection that maps an arbitrary $M \\times M$ Hermitian matrix $D$ to the closest rank-$N$ projector $P$ in the set $\\mathcal{G}(N,M) = \\{ P \\in \\mathbb{C}^{M\\times M} \\mid P^2=P, P^\\dagger=P, \\mathrm{Tr}(P)=N \\}$. \"Closest\" is defined by minimizing the Frobenius norm of the difference, $\\lVert D - P \\rVert_F$.\n\nThe square of the Frobenius norm is given by $\\lVert A \\rVert_F^2 = \\mathrm{Tr}(A^\\dagger A)$. We wish to minimize:\n$$\n\\lVert D - P \\rVert_F^2 = \\mathrm{Tr}((D - P)^\\dagger (D - P))\n$$\nSince both $D$ and $P$ are Hermitian ($D^\\dagger=D, P^\\dagger=P$), this expands to:\n$$\n\\lVert D - P \\rVert_F^2 = \\mathrm{Tr}(D^2 - DP - PD + P^2) = \\mathrm{Tr}(D^2) - \\mathrm{Tr}(DP) - \\mathrm{Tr}(PD) + \\mathrm{Tr}(P^2)\n$$\nUsing the cyclic property of the trace ($\\mathrm{Tr}(AB) = \\mathrm{Tr}(BA)$) and the properties of projectors ($P^2=P$, $\\mathrm{Tr}(P)=N$), this becomes:\n$$\n\\lVert D - P \\rVert_F^2 = \\mathrm{Tr}(D^2) - 2\\mathrm{Tr}(DP) + \\mathrm{Tr}(P) = \\mathrm{Tr}(D^2) - 2\\mathrm{Tr}(DP) + N\n$$\nThe terms $\\mathrm{Tr}(D^2)$ and $N$ are constant with respect to the choice of $P$. Therefore, minimizing $\\lVert D - P \\rVert_F^2$ is equivalent to maximizing $\\mathrm{Tr}(DP)$.\n\nLet the spectral decomposition of the Hermitian matrix $D$ be $D = \\sum_{i=1}^{M} \\lambda_i \\lvert v_i \\rangle \\langle v_i \\rvert$, where $\\lambda_i$ are the real eigenvalues and $\\{\\lvert v_i \\rangle\\}$ is a corresponding orthonormal set of eigenvectors. We order the eigenvalues such that $\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_M$.\nAny rank-$N$ projector $P$ can be written as $P = \\sum_{j=1}^{N} \\lvert u_j \\rangle \\langle u_j \\rvert$, where $\\{\\lvert u_j \\rangle\\}_{j=1}^N$ is an orthonormal set of $N$ vectors spanning the range of $P$.\n\nWe compute $\\mathrm{Tr}(DP)$:\n$$\n\\mathrm{Tr}(DP) = \\mathrm{Tr}\\left(D \\sum_{j=1}^{N} \\lvert u_j \\rangle \\langle u_j \\rvert\\right) = \\sum_{j=1}^{N} \\mathrm{Tr}(D \\lvert u_j \\rangle \\langle u_j \\rvert) = \\sum_{j=1}^{N} \\langle u_j \\rvert D \\lvert u_j \\rangle\n$$\nThis is the sum of the expectation values of $D$ over the basis vectors for the range of $P$. To maximize this sum, we must choose the set $\\{\\lvert u_j \\rangle\\}$ optimally. By Ky Fan's inequality, or by a more direct argument, the sum of expectation values $\\sum_j \\langle u_j \\rvert D \\lvert u_j \\rangle$ is maximized when the subspace spanned by $\\{\\lvert u_j \\rangle\\}$ is the same as the subspace spanned by the eigenvectors of $D$ corresponding to its $N$ largest eigenvalues.\nIn our ordered-eigenvalue basis, the maximum value is achieved by choosing $\\lvert u_j \\rangle = \\lvert v_j \\rangle$ for $j=1, \\dots, N$. This choice gives:\n$$\n\\mathrm{Tr}(DP) = \\sum_{j=1}^{N} \\langle v_j \\rvert D \\lvert v_j \\rangle = \\sum_{j=1}^{N} \\langle v_j \\rvert (\\lambda_j \\lvert v_j \\rangle) = \\sum_{j=1}^{N} \\lambda_j\n$$\nAny other choice of orthonormal set $\\{\\lvert u_j \\rangle\\}$ would yield a value less than or equal to this sum.\n\nThus, the optimal projector $P$ is the one that projects onto the subspace spanned by the eigenvectors $\\{\\lvert v_1 \\rangle, \\dots, \\lvert v_N \\rangle\\}$ corresponding to the $N$ largest eigenvalues of $D$:\n$$\nP = \\sum_{i=1}^N \\lvert v_i \\rangle \\langle v_i \\rvert\n$$\nThe problem formulation uses the Singular Value Decomposition (SVD), $D = U \\Sigma V^\\dagger$. Since $D$ is Hermitian, its left and right singular vectors are the same ($U=V$) and coincide with its eigenvectors. The singular values are the absolute values of the eigenvalues. In the context of this problem, the matrix to be projected, $D_{\\text{mix}} = (1-\\alpha)D_n + \\alpha \\hat{D}(F[D_n])$, is a convex combination of two positive semi-definite matrices (projectors are PSD) and is therefore also positive semi-definite. Its eigenvalues are thus non-negative and identical to its singular values. Consequently, the eigenvectors corresponding to the $N$ largest eigenvalues are identical to the left singular vectors corresponding to the $N$ largest singular values.\n\nLet $U_N$ be the $M \\times N$ matrix whose columns are the first $N$ columns of $U$ (i.e., the eigenvectors $\\lvert v_1 \\rangle, \\dots, \\lvert v_N \\rangle$). The projector can be written as $P=U_N U_N^\\dagger$. We verify its properties:\n1.  **Hermiticity:** $P^\\dagger = (U_N U_N^\\dagger)^\\dagger = (U_N^\\dagger)^\\dagger U_N^\\dagger = U_N U_N^\\dagger = P$. It is Hermitian.\n2.  **Idempotency:** $P^2 = (U_N U_N^\\dagger)(U_N U_N^\\dagger) = U_N (U_N^\\dagger U_N) U_N^\\dagger$. Since the columns of $U_N$ are orthonormal, $U_N^\\dagger U_N = I_N$, the $N \\times N$ identity matrix. Therefore, $P^2 = U_N I_N U_N^\\dagger = U_N U_N^\\dagger = P$. It is idempotent.\n3.  **Rank:** The rank of the projector is its trace. $\\mathrm{rank}(P) = \\mathrm{Tr}(P) = \\mathrm{Tr}(U_N U_N^\\dagger) = \\mathrm{Tr}(U_N^\\dagger U_N) = \\mathrm{Tr}(I_N) = N$.\n\nThis completes the derivation. The SVD-based construction correctly identifies the Frobenius-norm closest rank-$N$ projector to a given Hermitian matrix. This procedure successfully maps a matrix that has lost its idempotency back onto the Grassmann manifold $\\mathcal{G}(N,M)$.",
            "answer": "```python\nimport numpy as np\n\ndef run_case(M, N, alpha, gamma, s, t=None, H_explicit=None):\n    \"\"\"\n    Performs one SCF linear mixing step followed by SVD projection for a single test case.\n\n    Args:\n        M (int): Dimension of the basis.\n        N (int): Number of occupied orbitals.\n        alpha (float): Linear mixing parameter.\n        gamma (float): Parameter for the Fock operator functional.\n        s (int): Seed for generating the initial density matrix.\n        t (int, optional): Seed for generating the core Hamiltonian. Defaults to None.\n        H_explicit (np.ndarray, optional): An explicitly provided core Hamiltonian. Defaults to None.\n\n    Returns:\n        tuple[float, float]: A tuple containing (E_mix, E_proj).\n    \"\"\"\n    \n    # 1. Generate the initial rank-N projector D_n\n    # Use a real M x N matrix A with standard normal entries\n    rng_s = np.random.default_rng(s)\n    A = rng_s.standard_normal((M, N))\n    # Compute the thin QR factorization of A\n    Q, _ = np.linalg.qr(A, mode='reduced')\n    # D_n is the projector Q Q^dagger\n    Dn = Q @ Q.T\n\n    # 2. Generate the core Hamiltonian H\n    if H_explicit is not None:\n        H = H_explicit\n    else:\n        # Use a real M x M matrix B with standard normal entries\n        rng_t = np.random.default_rng(t)\n        B = rng_t.standard_normal((M, M))\n        # Symmetrize to create a Hermitian matrix (here, real symmetric)\n        H = 0.5 * (B + B.T)\n\n    # 3. Compute the Fock operator F[D_n]\n    F = H + gamma * Dn\n\n    # 4. Compute the target projector, D_hat(F)\n    # Diagonalize the Hermitian Fock operator F\n    # np.linalg.eigh sorts eigenvalues in ascending order\n    eigvals, eigvecs = np.linalg.eigh(F)\n    # The columns of eigvecs are the eigenvectors. We need the first N columns\n    # corresponding to the N lowest eigenvalues.\n    lowest_eigvecs = eigvecs[:, :N]\n    # Form the projector onto this N-dimensional subspace\n    D_hat = lowest_eigvecs @ lowest_eigvecs.T\n\n    # 5. Perform linear mixing\n    D_mix = (1 - alpha) * Dn + alpha * D_hat\n\n    # 6. Compute idempotency violation of the mixed density, E_mix\n    error_matrix_mix = D_mix @ D_mix - D_mix\n    E_mix = np.linalg.norm(error_matrix_mix, 'fro')\n\n    # 7. Project D_mix back onto the Grassmann manifold\n    # D_mix is Hermitian, so its SVD is U S U^dagger. Left and right singular vectors are the same.\n    # np.linalg.svd sorts singular values in descending order.\n    U, S, Vh = np.linalg.svd(D_mix)\n    # Take the N left singular vectors associated with the N largest singular values\n    U_N = U[:, :N]\n    # Construct the closest rank-N projector P\n    P = U_N @ U_N.T\n\n    # 8. Compute idempotency violation of the projected density, E_proj\n    # This should be close to machine epsilon\n    error_matrix_proj = P @ P - P\n    E_proj = np.linalg.norm(error_matrix_proj, 'fro')\n\n    return E_mix, E_proj\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (M, N, alpha, gamma, s, t)\n        (4, 2, 0.5, 0.7, 11, 13),\n        (4, 2, 0.0, 0.7, 11, 13),\n        (4, 2, 1.0, 0.7, 11, 13),\n        (5, 2, 0.3, -0.5, 21, 22),\n        # Case 5 has no 't' seed\n        (6, 3, 0.4, 0.0, 31),\n    ]\n\n    results = []\n    for i, case in enumerate(test_cases):\n        if len(case) == 6:\n            M, N, alpha, gamma, s, t = case\n            E_mix, E_proj = run_case(M, N, alpha, gamma, s, t)\n        else: # Case 5\n            M, N, alpha, gamma, s = case\n            H_explicit = np.diag([0.0, 0.0, 0.0, 1.0, 1.0, 1.0])\n            E_mix, E_proj = run_case(M, N, alpha, gamma, s, H_explicit=H_explicit)\n        \n        results.append(E_mix)\n        results.append(E_proj)\n\n    # Format the final output string\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}