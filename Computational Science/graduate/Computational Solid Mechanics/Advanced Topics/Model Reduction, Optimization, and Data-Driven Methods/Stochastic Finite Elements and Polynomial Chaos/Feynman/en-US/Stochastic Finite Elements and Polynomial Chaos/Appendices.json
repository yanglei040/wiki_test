{
    "hands_on_practices": [
        {
            "introduction": "Before constructing any Polynomial Chaos Expansion (PCE) model, a crucial first step is to define the set of polynomial basis functions, which in turn determines the model's complexity and computational cost. This exercise  will guide you through calculating the size of two common basis truncation schemes: the total-degree and the hyperbolic-cross sets. Mastering this fundamental combinatorics is essential for setting up and scaling Stochastic Finite Element Method (SFEM) simulations.",
            "id": "3603225",
            "problem": "A plane-stress linear elastic solid is modeled using the Finite Element Method (FEM) within the Stochastic Finite Element Method (SFEM). The material stiffness tensor is parameterized by a Polynomial Chaos Expansion (PCE) in terms of independent standard Gaussian random variables. Let the random input dimension be $d=5$, and let the multivariate Hermite polynomial basis be truncated by two different index sets over multi-indices $\\boldsymbol{\\alpha}=(\\alpha_{1},\\dots,\\alpha_{d})\\in\\mathbb{N}_{0}^{d}$.\n\nDefine the total-degree truncation set\n$$\n\\mathcal{I}_{\\mathrm{TD}}(d,p)=\\left\\{\\boldsymbol{\\alpha}\\in\\mathbb{N}_{0}^{d}:\\sum_{i=1}^{d}\\alpha_{i}\\leq p\\right\\},\n$$\nand the hyperbolic-cross $q$-quasi-norm truncation set\n$$\n\\mathcal{I}_{q}(d,p)=\\left\\{\\boldsymbol{\\alpha}\\in\\mathbb{N}_{0}^{d}:\\sum_{i=1}^{d}\\alpha_{i}^{q}\\leq p^{q}\\right\\},\n$$\nwith $q\\in(0,1]$. These sets determine the number of stochastic basis functions retained in the PCE, which directly controls the number of stochastic degrees of freedom in the SFEM formulation.\n\nFor $d=5$ and $p=3$:\n1. Compute the exact cardinality $|\\mathcal{I}_{\\mathrm{TD}}(5,3)|$.\n2. For the hyperbolic-cross set with $q=0.5$, provide an explicit upper bound on $|\\mathcal{I}_{0.5}(5,3)|$ expressed as an exact integer.\n\nExpress both answers as exact integers. No rounding is required. No physical units are required in the final answer.",
            "solution": "The problem asks for two quantities related to the cardinality of multi-index sets used in Polynomial Chaos Expansions. The given parameters are the number of random dimensions $d=5$ and a maximum polynomial degree parameter $p=3$.\n\nPart 1: Compute the exact cardinality of the total-degree truncation set $|\\mathcal{I}_{\\mathrm{TD}}(5,3)|$.\n\nThe total-degree truncation set is defined as\n$$\n\\mathcal{I}_{\\mathrm{TD}}(d,p)=\\left\\{\\boldsymbol{\\alpha}\\in\\mathbb{N}_{0}^{d}:\\sum_{i=1}^{d}\\alpha_{i}\\leq p\\right\\}\n$$\nFor the given parameters $d=5$ and $p=3$, we need to find the number of non-negative integer solutions to the inequality:\n$$\n\\alpha_{1}+\\alpha_{2}+\\alpha_{3}+\\alpha_{4}+\\alpha_{5}\\leq 3\n$$\nThis is a classic combinatorial problem. We can convert the inequality into an equality by introducing a non-negative integer slack variable, $\\alpha_{6}\\geq 0$. The problem then becomes finding the number of non-negative integer solutions to the equation:\n$$\n\\alpha_{1}+\\alpha_{2}+\\alpha_{3}+\\alpha_{4}+\\alpha_{5}+\\alpha_{6}=3\n$$\nThis is equivalent to distributing $p=3$ identical items (stars) into $d+1=6$ distinct bins (bars). The number of ways to do this is given by the multiset coefficient, which is expressed using a binomial coefficient:\n$$\n|\\mathcal{I}_{\\mathrm{TD}}(d,p)| = \\binom{p+d}{d} = \\binom{p+(d+1)-1}{(d+1)-1}\n$$\nUsing the first form with our values $d=5$ and $p=3$:\n$$\n|\\mathcal{I}_{\\mathrm{TD}}(5,3)| = \\binom{3+5}{5} = \\binom{8}{5}\n$$\nUsing the property $\\binom{n}{k} = \\binom{n}{n-k}$, we can write this as:\n$$\n\\binom{8}{5} = \\binom{8}{8-5} = \\binom{8}{3}\n$$\nNow, we compute the value:\n$$\n\\binom{8}{3} = \\frac{8!}{3!(8-3)!} = \\frac{8!}{3!5!} = \\frac{8 \\times 7 \\times 6}{3 \\times 2 \\times 1} = 8 \\times 7 = 56\n$$\nThus, the exact cardinality of the total-degree set is $56$.\n\nPart 2: Provide an explicit upper bound on the cardinality of the hyperbolic-cross set $|\\mathcal{I}_{0.5}(5,3)|$.\n\nThe hyperbolic-cross $q$-quasi-norm truncation set is defined as\n$$\n\\mathcal{I}_{q}(d,p)=\\left\\{\\boldsymbol{\\alpha}\\in\\mathbb{N}_{0}^{d}:\\sum_{i=1}^{d}\\alpha_{i}^{q}\\leq p^{q}\\right\\}\n$$\nFor this part, the parameters are $d=5$, $p=3$, and $q=0.5$. The condition defining the set $\\mathcal{I}_{0.5}(5,3)$ is:\n$$\n\\sum_{i=1}^{5}\\alpha_{i}^{0.5}\\leq 3^{0.5} \\quad \\text{or equivalently} \\quad \\sum_{i=1}^{5}\\sqrt{\\alpha_{i}}\\leq \\sqrt{3}\n$$\nwhere $\\boldsymbol{\\alpha}=(\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4, \\alpha_5)$ is a vector of non-negative integers. The numerical value of the bound is $\\sqrt{3} \\approx 1.732$.\n\nWe are asked for an upper bound. The exact cardinality is, by definition, the least upper bound. For the given parameters, the exact cardinality can be computed directly by analyzing the defining inequality.\n\nLet us analyze the possible values for the components $\\alpha_i \\in \\mathbb{N}_0$.\nConsider any two distinct components, $\\alpha_i$ and $\\alpha_j$, from the multi-index $\\boldsymbol{\\alpha}$. If both were non-zero, then $\\alpha_i \\geq 1$ and $\\alpha_j \\geq 1$. In this case, the sum on the left-hand side of the inequality would be:\n$$\n\\sum_{k=1}^{5}\\sqrt{\\alpha_{k}} \\geq \\sqrt{\\alpha_i} + \\sqrt{\\alpha_j} \\geq \\sqrt{1} + \\sqrt{1} = 2\n$$\nSince $2 > \\sqrt{3}$, this configuration violates the defining inequality. This leads to a powerful conclusion: for any multi-index $\\boldsymbol{\\alpha}$ in the set $\\mathcal{I}_{0.5}(5,3)$, at most one component can be non-zero.\n\nThis allows us to enumerate all possible multi-indices in the set:\n1.  Case 1: All components are zero.\n    The multi-index is $\\boldsymbol{\\alpha} = (0,0,0,0,0)$. The sum is $\\sum \\sqrt{0} = 0 \\leq \\sqrt{3}$. This is one valid multi-index.\n2.  Case 2: Exactly one component is non-zero.\n    Let this component be $\\alpha_j = k$ for some integer $k > 0$. The other four components are zero. The inequality becomes:\n    $$\n    \\sqrt{k} \\leq \\sqrt{3}\n    $$\n    Squaring both sides gives $k \\leq 3$. Since $k$ must be a positive integer, the possible values for $k$ are $1$, $2$, and $3$.\n    - If $k=1$, we have a multi-index with one component equal to $1$ and the rest zero. There are $\\binom{5}{1}=5$ such multi-indices (e.g., $(1,0,0,0,0)$).\n    - If $k=2$, we have a multi-index with one component equal to $2$ and the rest zero. There are $\\binom{5}{1}=5$ such multi-indices (e.g., $(2,0,0,0,0)$).\n    - If $k=3$, we have a multi-index with one component equal to $3$ and the rest zero. There are $\\binom{5}{1}=5$ such multi-indices (e.g., $(3,0,0,0,0)$).\n\nSumming the counts from all possible cases gives the total cardinality of the set:\n$$\n|\\mathcal{I}_{0.5}(5,3)| = 1 \\text{ (zero vector)} + 5 \\text{ (for } k=1) + 5 \\text{ (for } k=2) + 5 \\text{ (for } k=3) = 16\n$$\nSince we have found the exact cardinality of the set, this value serves as the tightest possible integer upper bound.\n\nThe two requested values are $56$ and $16$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 56 & 16 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "A powerful feature of SFEM is its ability to model spatially varying material properties using random fields. However, the parameters of the underlying stochastic model (e.g., a Gaussian field) are often abstract and not directly measurable. This practice  demonstrates the essential process of calibrating these abstract parameters from tangible engineering statistics, such as the target mean and coefficient of variation of Young's modulus. You will derive and apply these relationships for a lognormal random field, a widely used model for positive-definite physical quantities.",
            "id": "3603286",
            "problem": "Consider a one-dimensional linear elastic bar in computational solid mechanics whose spatially varying Young's modulus field is modeled as a lognormal transformation of a Gaussian random field. Specifically, let $Z(x,\\omega)$ be a Gaussian random field with mean $\\mu_{Z}(x)$ and covariance $C_{Z}(x,y)$, and define the modulus field by $E(x,\\omega) = E_{\\mathrm{ref}} \\exp(Z(x,\\omega))$, where $E_{\\mathrm{ref}}$ is a fixed positive reference modulus introduced so that the logarithm is dimensionless. In generalized Polynomial Chaos (gPC), $Z(x,\\omega)$ is represented in terms of Hermite polynomials of a standard Gaussian germ; for a homogeneous single-mode approximation this reduces to $Z(x,\\omega)=\\mu_{Z}+\\sigma_{Z}\\,\\xi(\\omega)$ with $\\xi(\\omega)\\sim \\mathcal{N}(0,1)$.\n\nUsing only fundamental properties of Gaussian random variables and their moment generating functions, derive expressions for the pointwise mean $\\mathbb{E}[E(x,\\omega)]$ and pointwise variance $\\mathrm{Var}[E(x,\\omega)]$ in terms of $\\mu_{Z}(x)$ and $C_{Z}(x,x)$. Then, specialize to a spatially homogeneous field where $\\mu_{Z}(x)\\equiv \\mu_{Z}$ and $C_{Z}(x,x)\\equiv \\sigma_{Z}^{2}$ are constants, and the engineering targets for the modulus field are a pointwise mean $\\bar{E} = 210\\,\\mathrm{GPa}$ and a pointwise coefficient of variation $c_{E} = 0.15$. Take $E_{\\mathrm{ref}} = 1\\,\\mathrm{GPa}$ so that the modulus mean ratio $\\bar{E}/E_{\\mathrm{ref}}$ is dimensionless.\n\nBy enforcing that the derived mean and variance match the engineering targets, solve for the Gaussian parameters $\\mu_{Z}$ and $\\sigma_{Z}^{2}$. Express your final numerical values without units, and round your final numerical answers to four significant figures.",
            "solution": "The first part of the task is to derive expressions for the pointwise mean $\\mathbb{E}[E(x,\\omega)]$ and variance $\\mathrm{Var}[E(x,\\omega)]$ of the Young's modulus field $E(x,\\omega) = E_{\\mathrm{ref}} \\exp(Z(x,\\omega))$. The field $Z(x,\\omega)$ is a Gaussian random field. At any fixed spatial coordinate $x$, the quantity $Z(x,\\omega)$ is a Gaussian random variable, which we denote as $Z_x$. This variable has a mean $\\mu_Z(x) = \\mathbb{E}[Z(x,\\omega)]$ and a variance equal to the pointwise value of the covariance function, $C_Z(x,x) = \\mathbb{E}[(Z(x,\\omega) - \\mu_Z(x))^2]$. Thus, $Z_x \\sim \\mathcal{N}(\\mu_Z(x), C_Z(x,x))$.\n\nThe statistical moments of $E(x,\\omega)$ can be determined using the moment-generating function (MGF) of the Gaussian random variable $Z_x$. The MGF of a general Gaussian random variable $Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$ is given by $M_Y(t) = \\mathbb{E}[\\exp(tY)] = \\exp(\\mu t + \\frac{1}{2}\\sigma^2 t^2)$.\n\nTo find the mean of $E(x,\\omega)$, we compute its expectation:\n$$\n\\mathbb{E}[E(x,\\omega)] = \\mathbb{E}[E_{\\mathrm{ref}} \\exp(Z_x)]\n$$\nSince $E_{\\mathrm{ref}}$ is a constant, we can write:\n$$\n\\mathbb{E}[E(x,\\omega)] = E_{\\mathrm{ref}} \\mathbb{E}[\\exp(Z_x)]\n$$\nThe term $\\mathbb{E}[\\exp(Z_x)]$ is the MGF of $Z_x$ evaluated at $t=1$. Using the MGF formula with $\\mu = \\mu_Z(x)$ and $\\sigma^2 = C_Z(x,x)$, we have:\n$$\n\\mathbb{E}[\\exp(Z_x)] = M_{Z_x}(1) = \\exp\\left(\\mu_Z(x) \\cdot 1 + \\frac{1}{2}C_Z(x,x) \\cdot 1^2\\right) = \\exp\\left(\\mu_Z(x) + \\frac{1}{2}C_Z(x,x)\\right)\n$$\nTherefore, the pointwise mean of the Young's modulus is:\n$$\n\\mathbb{E}[E(x,\\omega)] = E_{\\mathrm{ref}} \\exp\\left(\\mu_Z(x) + \\frac{1}{2}C_Z(x,x)\\right)\n$$\n\nNext, we derive the variance, $\\mathrm{Var}[E(x,\\omega)] = \\mathbb{E}[E(x,\\omega)^2] - (\\mathbb{E}[E(x,\\omega)])^2$. We first need the second moment, $\\mathbb{E}[E(x,\\omega)^2]$.\n$$\n\\mathbb{E}[E(x,\\omega)^2] = \\mathbb{E}[(E_{\\mathrm{ref}} \\exp(Z_x))^2] = E_{\\mathrm{ref}}^2 \\mathbb{E}[\\exp(2Z_x)]\n$$\nThe term $\\mathbb{E}[\\exp(2Z_x)]$ corresponds to the MGF of $Z_x$ evaluated at $t=2$:\n$$\n\\mathbb{E}[\\exp(2Z_x)] = M_{Z_x}(2) = \\exp\\left(\\mu_Z(x) \\cdot 2 + \\frac{1}{2}C_Z(x,x) \\cdot 2^2\\right) = \\exp\\left(2\\mu_Z(x) + 2C_Z(x,x)\\right)\n$$\nSo, the second moment of the modulus is:\n$$\n\\mathbb{E}[E(x,\\omega)^2] = E_{\\mathrm{ref}}^2 \\exp\\left(2\\mu_Z(x) + 2C_Z(x,x)\\right)\n$$\nNow, we can compute the variance:\n$$\n\\mathrm{Var}[E(x,\\omega)] = E_{\\mathrm{ref}}^2 \\exp\\left(2\\mu_Z(x) + 2C_Z(x,x)\\right) - \\left(E_{\\mathrm{ref}} \\exp\\left(\\mu_Z(x) + \\frac{1}{2}C_Z(x,x)\\right)\\right)^2\n$$\n$$\n\\mathrm{Var}[E(x,\\omega)] = E_{\\mathrm{ref}}^2 \\exp\\left(2\\mu_Z(x) + 2C_Z(x,x)\\right) - E_{\\mathrm{ref}}^2 \\exp\\left(2\\mu_Z(x) + C_Z(x,x)\\right)\n$$\nFactoring out common terms yields the expression for the pointwise variance:\n$$\n\\mathrm{Var}[E(x,\\omega)] = E_{\\mathrm{ref}}^2 \\exp\\left(2\\mu_Z(x) + C_Z(x,x)\\right) \\left(\\exp(C_Z(x,x)) - 1\\right)\n$$\n\nFor the second part of the problem, we specialize to a spatially homogeneous field, where $\\mu_Z(x) \\equiv \\mu_Z$ and $C_Z(x,x) \\equiv \\sigma_Z^2$ are constants. The expressions for the mean and variance simplify to:\n$$\n\\bar{E} = \\mathbb{E}[E] = E_{\\mathrm{ref}} \\exp\\left(\\mu_Z + \\frac{1}{2}\\sigma_Z^2\\right) \\quad (1)\n$$\n$$\n\\mathrm{Var}[E] = E_{\\mathrm{ref}}^2 \\exp\\left(2\\mu_Z + \\sigma_Z^2\\right) \\left(\\exp(\\sigma_Z^2) - 1\\right) \\quad (2)\n$$\nThe problem provides target engineering values: a mean modulus $\\bar{E} = 210\\,\\mathrm{GPa}$ and a coefficient of variation $c_E = 0.15$. The reference modulus is $E_{\\mathrm{ref}} = 1\\,\\mathrm{GPa}$. We must solve for the parameters $\\mu_Z$ and $\\sigma_Z^2$.\n\nThe coefficient of variation is defined as $c_E = \\frac{\\sqrt{\\mathrm{Var}[E]}}{\\bar{E}}$. Squaring this gives $c_E^2 = \\frac{\\mathrm{Var}[E]}{\\bar{E}^2}$.\nSubstituting our expressions for $\\bar{E}$ and $\\mathrm{Var}[E]$:\n$$\nc_E^2 = \\frac{E_{\\mathrm{ref}}^2 \\exp(2\\mu_Z + \\sigma_Z^2) (\\exp(\\sigma_Z^2) - 1)}{\\left(E_{\\mathrm{ref}} \\exp(\\mu_Z + \\frac{1}{2}\\sigma_Z^2)\\right)^2} = \\frac{E_{\\mathrm{ref}}^2 \\exp(2\\mu_Z + \\sigma_Z^2) (\\exp(\\sigma_Z^2) - 1)}{E_{\\mathrm{ref}}^2 \\exp(2\\mu_Z + \\sigma_Z^2)}\n$$\n$$\nc_E^2 = \\exp(\\sigma_Z^2) - 1\n$$\nThis equation allows us to solve for $\\sigma_Z^2$ directly from the target coefficient of variation:\n$$\n\\exp(\\sigma_Z^2) = 1 + c_E^2 \\implies \\sigma_Z^2 = \\ln(1 + c_E^2)\n$$\nSubstituting the given value $c_E = 0.15$:\n$$\n\\sigma_Z^2 = \\ln(1 + 0.15^2) = \\ln(1 + 0.0225) = \\ln(1.0225)\n$$\n$$\n\\sigma_Z^2 \\approx 0.0222535 \\approx 0.02225 \\quad \\text{(to four significant figures)}\n$$\nNext, we use Equation $(1)$ to solve for $\\mu_Z$.\n$$\n\\bar{E} = E_{\\mathrm{ref}} \\exp\\left(\\mu_Z + \\frac{1}{2}\\sigma_Z^2\\right)\n$$\n$$\n\\frac{\\bar{E}}{E_{\\mathrm{ref}}} = \\exp\\left(\\mu_Z + \\frac{1}{2}\\sigma_Z^2\\right)\n$$\nTaking the natural logarithm of both sides:\n$$\n\\ln\\left(\\frac{\\bar{E}}{E_{\\mathrm{ref}}}\\right) = \\mu_Z + \\frac{1}{2}\\sigma_Z^2\n$$\nSolving for $\\mu_Z$:\n$$\n\\mu_Z = \\ln\\left(\\frac{\\bar{E}}{E_{\\mathrm{ref}}}\\right) - \\frac{1}{2}\\sigma_Z^2\n$$\nSubstituting the expression for $\\sigma_Z^2$:\n$$\n\\mu_Z = \\ln\\left(\\frac{\\bar{E}}{E_{\\mathrm{ref}}}\\right) - \\frac{1}{2}\\ln(1 + c_E^2) = \\ln\\left(\\frac{\\bar{E}}{E_{\\mathrm{ref}}\\sqrt{1+c_E^2}}\\right)\n$$\nNow, we substitute the numerical values $\\bar{E} = 210\\,\\mathrm{GPa}$ and $E_{\\mathrm{ref}} = 1\\,\\mathrm{GPa}$, so the ratio $\\bar{E}/E_{\\mathrm{ref}} = 210$.\n$$\n\\mu_Z = \\ln\\left(\\frac{210}{\\sqrt{1+0.15^2}}\\right) = \\ln\\left(\\frac{210}{\\sqrt{1.0225}}\\right)\n$$\n$$\n\\mu_Z \\approx \\ln\\left(\\frac{210}{1.0111874}\\right) \\approx \\ln(207.67401)\n$$\n$$\n\\mu_Z \\approx 5.33597 \\approx 5.336 \\quad \\text{(to four significant figures)}\n$$\nThe required Gaussian parameters are $\\mu_Z$ and $\\sigma_Z^2$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 5.336 & 0.02225 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Theory comes to life through implementation. This computational exercise  challenges you to build a PCE surrogate for the response of a simple mechanical system with a non-Gaussian random input. The core task is to compare the accuracy of a \"matched\" basis (Jacobi polynomials for a Beta distribution) against a \"mismatched\" one (Legendre polynomials). This practice will illuminate the practical consequences of basis selection within the Wiener-Askey framework and demonstrate the mechanics of a non-intrusive Galerkin projection.",
            "id": "3603221",
            "problem": "Consider a prismatic circular bar of initial radius subject to torsion by a deterministic applied torque. In the linear elastic regime, the angle of twist is inversely proportional to the polar moment of inertia. For a circular cross-section, the polar moment of inertia scales with the radius to the fourth power. Let a geometric imperfection amplitude modify the radius multiplicatively as a factor of the form $1 + \\varepsilon A$, where $\\varepsilon \\ge 0$ is a deterministic imperfection scale and $A \\in [0,1]$ is a scalar random variable. After nondimensionalization by the deterministic constants, the quantity of interest is the nondimensional twist response $u(A)$\n$$\nu(A) = \\left(1 + \\varepsilon A\\right)^{-4}.\n$$\nAssume the amplitude $A$ is distributed as a Beta distribution on $[0,1]$ with shape parameters $\\alpha_B > 0$ and $\\beta_B > 0$. Let $X$ be a random variable with the same distribution as $A$. The goal is to compute and compare approximations to the variance $\\mathrm{Var}[u(X)]$ using two different polynomial chaos expansions from the Wiener–Askey scheme:\n- A Jacobi polynomial basis that is orthogonal with respect to the Beta distribution measure.\n- A Legendre polynomial basis that is orthogonal with respect to the uniform measure on $[-1,1]$, but used here together with the true Beta distribution measure for projection, thereby constituting a mismatched basis under the correct measure.\n\nBegin from fundamental definitions: the torsion relation that twist is inversely proportional to the polar moment of inertia, the dependence of the polar moment of inertia on the radius for a circular cross-section, and the definition of variance $\\mathrm{Var}[Y] = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2$. Use the following construction to ensure a consistent and unambiguous formulation.\n1. Map the amplitude $A \\in [0,1]$ to $t \\in [-1,1]$ via $t = 2A - 1$. Under this map, the Beta$(\\alpha_B,\\beta_B)$ probability measure on $[0,1]$ is equivalent to a probability measure on $[-1,1]$ with density proportional to $(1-t)^{\\beta_B - 1} (1+t)^{\\alpha_B - 1}$.\n2. Consider a polynomial chaos expansion of order $p \\in \\mathbb{N}_0$ for $u$ in either basis:\n   - Jacobi basis: use $\\{\\phi_n(t)\\}_{n=0}^p$ with $\\phi_n(t) = P_n^{(\\beta_B-1,\\alpha_B-1)}(t)$, where $P_n^{(a,b)}$ are Jacobi polynomials orthogonal with respect to the weight $(1-t)^a (1+t)^b$ on $[-1,1]$. Compute coefficients $\\{c_n\\}_{n=0}^p$ by orthogonal projection with respect to the true Beta probability measure on $t \\in [-1,1]$.\n   - Legendre basis: use $\\{\\psi_n(t)\\}_{n=0}^p$ with $\\psi_n(t)$ the Legendre polynomials on $[-1,1]$. Compute coefficients $\\{d_n\\}_{n=0}^p$ by least-squares (Galerkin) projection with respect to the true Beta probability measure on $t \\in [-1,1]$; equivalently, solve the normal equations given by the mass matrix of the basis under this measure.\n3. For each basis, form the truncated approximation $u_p^{\\mathrm{Jac}}(t) = \\sum_{n=0}^p c_n \\phi_n(t)$ and $u_p^{\\mathrm{Leg}}(t) = \\sum_{n=0}^p d_n \\psi_n(t)$. Compute the corresponding approximate variances $\\mathrm{Var}[u_p^{\\mathrm{Jac}}(X)]$ and $\\mathrm{Var}[u_p^{\\mathrm{Leg}}(X)]$.\n4. Compute a high-accuracy reference value for $\\mathrm{Var}[u(X)]$ using high-order Gaussian quadrature with respect to the Beta distribution on $[-1,1]$ for expectations $\\mathbb{E}[u(X)]$ and $\\mathbb{E}[u(X)^2]$, then combining them via the definition of variance.\n\nImportant numerical specification:\n- All expectations with respect to the Beta distribution must be evaluated using Gaussian quadrature exact for the unnormalized Jacobi weight on $[-1,1]$, then normalized by the integral of the weight to obtain probability expectations. Specifically, use Gauss–Jacobi quadrature with parameters $(\\beta_B - 1, \\alpha_B - 1)$ on $[-1,1]$. For numerical accuracy, use at least $Q = 300$ quadrature nodes; larger values are permitted.\n- Do not assume any closed forms for the coefficients or variances; construct them by numerical projection as described above.\n- Angles or dimensional units need not be reported because the response $u$ is nondimensional by construction.\n\nTest suite:\nCompute the triple of values $[\\mathrm{Var}[u(X)],\\, \\mathrm{Var}[u_p^{\\mathrm{Jac}}(X)],\\, \\mathrm{Var}[u_p^{\\mathrm{Leg}}(X)]]$ for each of the following parameter sets $(\\varepsilon, \\alpha_B, \\beta_B, p)$:\n- Case 1 (boundary/no randomness in response amplitude): $(\\varepsilon, \\alpha_B, \\beta_B, p) = (0,\\, 2,\\, 3,\\, 4)$.\n- Case 2 (moderate skew): $(\\varepsilon, \\alpha_B, \\beta_B, p) = (0.1,\\, 2,\\, 5,\\, 3)$.\n- Case 3 (U-shaped distribution): $(\\varepsilon, \\alpha_B, \\beta_B, p) = (0.3,\\, 0.5,\\, 0.5,\\, 5)$.\n- Case 4 (right-skew, larger imperfection): $(\\varepsilon, \\alpha_B, \\beta_B, p) = (0.5,\\, 5,\\, 2,\\, 4)$.\n- Case 5 (uniform distribution): $(\\varepsilon, \\alpha_B, \\beta_B, p) = (0.2,\\, 1,\\, 1,\\, 3)$.\n\nFinal output format:\nYour program should produce a single line of output containing a list of results for all five cases. Each case contributes a list with three floating-point numbers in the order $[\\mathrm{Var}[u(X)],\\, \\mathrm{Var}[u_p^{\\mathrm{Jac}}(X)],\\, \\mathrm{Var}[u_p^{\\mathrm{Leg}}(X)]]$. Round every reported floating-point number to $8$ decimal places. Aggregate them into a single list in the order of the cases above. For example, the output must have the structure\n$$\n\\big[ [v_1^{\\mathrm{true}}, v_1^{\\mathrm{Jac}}, v_1^{\\mathrm{Leg}}], \\ldots, [v_5^{\\mathrm{true}}, v_5^{\\mathrm{Jac}}, v_5^{\\mathrm{Leg}}] \\big],\n$$\nprinted on a single line exactly as a valid Python list literal with decimals rounded to $8$ places and no additional text.",
            "solution": "### 1. Model Formulation and Stochastic Input\nThe physical problem concerns the torsional twist of a circular bar with a random geometric imperfection in its radius. The angle of twist is inversely proportional to the polar moment of inertia, $J$, which for a circular cross-section scales with the radius to the fourth power, $J \\propto r^4$. A multiplicative imperfection is modeled, where the radius $r$ is a random variable given by $r = r_{nom}(1 + \\varepsilon A)$, with $r_{nom}$ a nominal radius, $\\varepsilon$ a deterministic imperfection scale, and $A$ a random variable. The nondimensional system response, representing the twist, is thus given by\n$$\nu(A) = \\frac{k/r^4}{k/r_{nom}^4} = \\frac{r_{nom}^4}{(r_{nom}(1+\\varepsilon A))^4} = (1 + \\varepsilon A)^{-4}.\n$$\nThe random amplitude $A$ is defined on the interval $[0,1]$ and follows a Beta distribution, $A \\sim \\text{Beta}(\\alpha_B, \\beta_B)$, with shape parameters $\\alpha_B, \\beta_B > 0$. The probability density function (PDF) of $A$ is\n$$\nf_A(a) = \\frac{1}{B(\\alpha_B, \\beta_B)} a^{\\alpha_B-1} (1-a)^{\\beta_B-1}, \\quad a \\in [0,1],\n$$\nwhere $B(\\alpha_B, \\beta_B)$ is the Beta function.\n\nFor compatibility with standard orthogonal polynomial bases, we transform the random variable $A \\in [0,1]$ to a new variable $X$ on $[-1,1]$ via the affine map $X = 2A - 1$, which implies $A = (X+1)/2$. The response function in terms of $X$ is\n$$\nu(X) = \\left(1 + \\varepsilon \\frac{X+1}{2}\\right)^{-4}.\n$$\nThe PDF of $X$ is obtained through a change of variables:\n$$\nf_X(x) = f_A\\left(\\frac{x+1}{2}\\right) \\left|\\frac{dA}{dX}\\right| = \\frac{1}{2^{\\alpha_B+\\beta_B-1} B(\\alpha_B, \\beta_B)} (1-x)^{\\beta_B-1} (1+x)^{\\alpha_B-1}, \\quad x \\in [-1,1].\n$$\nThis PDF corresponds to the weight function $w(x) = (1-x)^{\\beta_B-1} (1+x)^{\\alpha_B-1}$, which is the canonical weight for Jacobi polynomials $P_n^{(\\beta_B-1, \\alpha_B-1)}(x)$.\n\n### 2. Expectation and Numerical Quadrature\nThe expectation of a function $g(X)$ is given by $\\mathbb{E}[g(X)] = \\int_{-1}^{1} g(x) f_X(x) dx$. This can be written in terms of the weight function $w(x)$ as\n$$\n\\mathbb{E}[g(X)] = \\frac{\\int_{-1}^{1} g(x) w(x) dx}{\\int_{-1}^{1} w(x) dx}.\n$$\nAll integrals involving $w(x)$ are computed numerically using Gauss-Jacobi quadrature. For the weight $w(x) = (1-x)^a (1+x)^b$ with $a=\\beta_B-1$ and $b=\\alpha_B-1$, we use a $Q$-point quadrature rule with nodes $\\{x_i\\}_{i=1}^Q$ and weights $\\{w_i\\}_{i=1}^Q$. The integral is then approximated as $\\int_{-1}^{1} g(x) w(x) dx \\approx \\sum_{i=1}^{Q} w_i g(x_i)$. The normalization constant, which is the integral of the weight function, is simply the sum of the quadrature weights, $\\int_{-1}^{1} w(x) dx = \\sum_{i=1}^{Q} w_i$. Thus, expectations are computed as\n$$\n\\mathbb{E}[g(X)] \\approx \\frac{\\sum_{i=1}^{Q} w_i g(x_i)}{\\sum_{i=1}^{Q} w_i}.\n$$\nAs specified, a high-order quadrature with $Q=300$ points is used for all calculations to ensure high accuracy.\n\n### 3. Reference Variance Calculation\nThe \"true\" variance of the response, $\\mathrm{Var}[u(X)]$, serves as a reference. It is computed from its definition:\n$$\n\\mathrm{Var}[u(X)] = \\mathbb{E}[u(X)^2] - \\left(\\mathbb{E}[u(X)]\\right)^2.\n$$\nThe two required expectation terms, $\\mathbb{E}[u(X)]$ and $\\mathbb{E}[u(X)^2]$, are calculated using the high-order Gauss-Jacobi quadrature described above.\n\n### 4. Polynomial Chaos Expansion with a Matched Jacobi Basis\nThe first approximation uses a polynomial chaos expansion based on Jacobi polynomials, which are orthogonal with respect to the measure of the random variable $X$. The basis functions are $\\phi_n(x) = P_n^{(\\beta_B-1, \\alpha_B-1)}(x)$. The truncated PCE of order $p$ is\n$$\nu_p^{\\mathrm{Jac}}(x) = \\sum_{n=0}^{p} c_n \\phi_n(x).\n$$\nThe coefficients $c_n$ are determined by orthogonal projection:\n$$\nc_n = \\frac{\\langle u, \\phi_n \\rangle_w}{\\langle \\phi_n, \\phi_n \\rangle_w} = \\frac{\\int_{-1}^{1} u(x)\\phi_n(x)w(x)dx}{\\int_{-1}^{1} \\phi_n(x)^2 w(x)dx}.\n$$\nThese inner products are computed numerically using the Gauss-Jacobi quadrature.\nDue to the orthogonality of the basis functions with respect to the probability measure (i.e., $\\mathbb{E}[\\phi_n \\phi_m]=0$ for $n \\neq m$), the variance of the PCE approximation simplifies significantly. The mean is $\\mathbb{E}[u_p^{\\mathrm{Jac}}] = c_0 \\mathbb{E}[\\phi_0] = c_0$ (since $\\phi_0=1$). The variance is\n$$\n\\mathrm{Var}[u_p^{\\mathrm{Jac}}(X)] = \\mathbb{E}[(u_p^{\\mathrm{Jac}} - c_0)^2] = \\mathbb{E}\\left[\\left(\\sum_{n=1}^{p} c_n \\phi_n(X)\\right)^2\\right] = \\sum_{n=1}^{p} c_n^2 \\mathbb{E}[\\phi_n(X)^2].\n$$\nEach term $\\mathbb{E}[\\phi_n^2]$ is computed using quadrature.\n\n### 5. Polynomial Chaos Expansion with a Mismatched Legendre Basis\nThe second approximation uses a Legendre polynomial basis, $\\{\\psi_n(x) = P_n(x)\\}_{n=0}^p$. This basis is orthogonal with respect to the uniform measure on $[-1,1]$, but not with respect to the true Beta-derived measure of $X$. The PCE is\n$$\nu_p^{\\mathrm{Leg}}(x) = \\sum_{n=0}^{p} d_n \\psi_n(x).\n$$\nThe coefficients $d_n$ are found via a Galerkin projection, which minimizes the mean-squared error $\\mathbb{E}[(u - u_p^{\\mathrm{Leg}})^2]$. This leads to a system of linear equations known as the normal equations:\n$$\n\\sum_{j=0}^{p} d_j \\mathbb{E}[\\psi_j(X) \\psi_k(X)] = \\mathbb{E}[u(X) \\psi_k(X)], \\quad \\text{for } k=0, 1, \\ldots, p.\n$$\nThis system is expressed in matrix form as $\\mathbf{M}\\mathbf{d} = \\mathbf{f}$, where:\n- $\\mathbf{M}$ is the $(p+1) \\times (p+1)$ mass matrix with entries $M_{kj} = \\mathbb{E}[\\psi_k(X) \\psi_j(X)]$.\n- $\\mathbf{f}$ is the $(p+1) \\times 1$ right-hand side vector with entries $f_k = \\mathbb{E}[u(X) \\psi_k(X)]$.\n- $\\mathbf{d}$ is the vector of unknown coefficients $[d_0, d_1, \\ldots, d_p]^T$.\nAll expectations required to build $\\mathbf{M}$ and $\\mathbf{f}$ are computed with the same Gauss-Jacobi quadrature. The system is then solved for $\\mathbf{d}$.\n\nSince the Legendre basis is not orthogonal with respect to the measure, the variance of the approximation must be computed from the general definition:\n$$\n\\mathrm{Var}[u_p^{\\mathrm{Leg}}(X)] = \\mathbb{E}[(u_p^{\\mathrm{Leg}}(X))^2] - (\\mathbb{E}[u_p^{\\mathrm{Leg}}(X)])^2.\n$$\nThe mean is $\\mathbb{E}[u_p^{\\mathrm{Leg}}(X)] = \\sum_{n=0}^{p} d_n \\mathbb{E}[\\psi_n(X)]$. The mean of the square is $\\mathbb{E}[(u_p^{\\mathrm{Leg}}(X))^2] = \\mathbb{E}[(\\sum_j d_j \\psi_j)(\\sum_k d_k \\psi_k)] = \\sum_j \\sum_k d_j d_k \\mathbb{E}[\\psi_j \\psi_k] = \\mathbf{d}^T \\mathbf{M} \\mathbf{d}$. All required expectations, $\\mathbb{E}[\\psi_n(X)]$, are again computed using quadrature before assembling the final variance value.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_jacobi, eval_jacobi, eval_legendre\n\ndef solve():\n    \"\"\"\n    Computes and compares variance approximations for a stochastic structural mechanics problem\n    using two different polynomial chaos expansion (PCE) bases.\n    \"\"\"\n    test_cases = [\n        (0.0, 2.0, 3.0, 4),  # Case 1: No randomness in response\n        (0.1, 2.0, 5.0, 3),  # Case 2: Moderate skew\n        (0.3, 0.5, 0.5, 5),  # Case 3: U-shaped distribution\n        (0.5, 5.0, 2.0, 4),  # Case 4: Right-skew, larger imperfection\n        (0.2, 1.0, 1.0, 3),  # Case 5: Uniform distribution\n    ]\n\n    Q = 300  # Number of quadrature points\n    \n    all_results = []\n\n    for case in test_cases:\n        epsilon, alpha_B, beta_B, p = case\n\n        # Parameters for Jacobi polynomials P_n^(a,b)\n        # The weight is (1-x)^a * (1+x)^b\n        a = beta_B - 1.0\n        b = alpha_B - 1.0\n\n        # Get Gauss-Jacobi quadrature nodes and weights for the true probability measure\n        nodes, weights = roots_jacobi(Q, a, b)\n        \n        # Normalization constant for probability expectations\n        integral_w = np.sum(weights)\n\n        def expectation(func, nodes_arr, weights_arr, norm_const):\n            \"\"\"Computes expectation of a function using quadrature.\"\"\"\n            integrand_values = func(nodes_arr)\n            return np.sum(weights_arr * integrand_values) / norm_const\n\n        # Define the nondimensional response function u(x) where x is in [-1, 1]\n        def u_func(x):\n            A = (x + 1.0) / 2.0\n            return (1.0 + epsilon * A)**(-4.0)\n\n        # 1. High-accuracy reference variance calculation\n        E_u = expectation(u_func, nodes, weights, integral_w)\n        def u_squared_func(x):\n            return u_func(x)**2.0\n        E_u2 = expectation(u_squared_func, nodes, weights, integral_w)\n        var_true = E_u2 - E_u**2\n\n        # 2. Jacobi PCE (matched basis) variance calculation\n        var_jac = 0.0\n        if epsilon > 0:\n            c = np.zeros(p + 1)\n            phi_p_vals = eval_jacobi(np.arange(p + 1), a, b, nodes[:, None]).T\n\n            for n in range(p + 1):\n                # Numerator for c_n: <u, phi_n>\n                num = np.sum(weights * u_func(nodes) * phi_p_vals[n, :])\n                # Denominator for c_n: <phi_n, phi_n>\n                den = np.sum(weights * phi_p_vals[n, :]**2)\n                c[n] = num / den if den != 0 else 0\n            \n            # Variance from coefficients: sum_{n=1 to p} c_n^2 * E[phi_n^2]\n            var_sum = 0.0\n            for n in range(1, p + 1):\n                E_phi_n_2 = np.sum(weights * phi_p_vals[n, :]**2) / integral_w\n                var_sum += c[n]**2 * E_phi_n_2\n            var_jac = var_sum\n        else: # Handle the deterministic case analytically\n            var_jac = 0.0\n\n\n        # 3. Legendre PCE (mismatched basis) variance calculation\n        var_leg = 0.0\n        if epsilon > 0:\n            d = np.zeros(p + 1)\n            M = np.zeros((p + 1, p + 1))\n            f = np.zeros(p + 1)\n\n            # Evaluate Legendre polynomials at quadrature nodes\n            psi_p_vals = eval_legendre(np.arange(p + 1), nodes[:, None]).T\n\n            # Build mass matrix M and RHS vector f\n            for k in range(p + 1):\n                f[k] = np.sum(weights * u_func(nodes) * psi_p_vals[k, :]) / integral_w\n                for j in range(p + 1):\n                    M[k, j] = np.sum(weights * psi_p_vals[k, :] * psi_p_vals[j, :]) / integral_w\n\n            # Solve for coefficients d\n            d = np.linalg.solve(M, f)\n            \n            # Compute variance of the Legendre PCE\n            # E[u_p^Leg]\n            E_psi_n = np.array([np.sum(weights * psi_p_vals[n, :]) / integral_w for n in range(p + 1)])\n            E_u_leg = np.dot(d, E_psi_n)\n            \n            # E[(u_p^Leg)^2] = d^T * M * d\n            E_u2_leg = d.T @ M @ d\n            \n            var_leg = E_u2_leg - E_u_leg**2\n        else: # Handle the deterministic case\n            var_leg = 0.0\n\n        all_results.append([var_true, var_jac, var_leg])\n\n\n    # Format and print the final output exactly as specified\n    formatted_results = []\n    for res_triple in all_results:\n        rounded_triple = [round(v, 8) for v in res_triple]\n        formatted_results.append(str(rounded_triple))\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}