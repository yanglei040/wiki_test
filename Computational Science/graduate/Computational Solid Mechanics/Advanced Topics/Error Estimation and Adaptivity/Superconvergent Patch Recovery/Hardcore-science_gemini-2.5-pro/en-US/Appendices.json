{
    "hands_on_practices": [
        {
            "introduction": "At the heart of Superconvergent Patch Recovery (SPR) lies a classic numerical method: least-squares fitting. This first exercise isolates this core mathematical engine from the broader complexities of a full finite element analysis. By working with a given set of stress values at superconvergent Gauss points, you will practice constructing a continuous, higher-order stress field over a local patch, which is the foundational step of the entire recovery process .",
            "id": "3603832",
            "problem": "Consider a stress recovery task in the Finite Element Method (FEM), where a nodal stress is to be obtained by smoothing Gauss-point stresses on a patch using a least-squares fit of a linear field. In the Superconvergent Patch Recovery (SPR), one approximates a single stress component by a polynomial over a local patch and determines its coefficients by minimizing the sum of squared residuals, consistent with an $L^{2}$ projection viewpoint. Assume the stress component of interest is the normal stress in the $x$-direction, denoted by $\\sigma_{xx}$, and that it is modeled over the patch by the linear field\n$$\n\\sigma_{xx}(x,y) = a_{0} + a_{1} x + a_{2} y\n$$\nwhere $x$ and $y$ are the global Cartesian coordinates (in $\\mathrm{mm}$), and the coefficients $a_{0}$, $a_{1}$, and $a_{2}$ are to be determined.\n\nYou are given Gauss-point data from a patch surrounding a node located at $(0, 0)$. The Gauss-point coordinates $(x_{i},y_{i})$ and their corresponding computed values of $\\sigma_{xx}$ (in $\\mathrm{MPa}$) are:\n- $(x_{1},y_{1}) = (1.0, 0.0)$, with $\\sigma_{xx,1} = 122$\n- $(x_{2},y_{2}) = (-1.0, 0.0)$, with $\\sigma_{xx,2} = 79$\n- $(x_{3},y_{3}) = (0.0, 1.0)$, with $\\sigma_{xx,3} = 91$\n- $(x_{4},y_{4}) = (0.0, -1.0)$, with $\\sigma_{xx,4} = 107$\n- $(x_{5},y_{5}) = (1.0, 1.0)$, with $\\sigma_{xx,5} = 110$\n- $(x_{6},y_{6}) = (-1.0, -1.0)$, with $\\sigma_{xx,6} = 92$\n\nUsing an unweighted least-squares criterion over the above data, determine the coefficients $a_{0}$, $a_{1}$, and $a_{2}$ of the best-fit linear field $\\sigma_{xx}(x,y)$. Then evaluate the recovered nodal stress at the node $(x,y) = (0.0, 0.0)$. Express the final recovered nodal stress in $\\mathrm{MPa}$ and round your answer to four significant figures.",
            "solution": "The user wants to find the recovered nodal stress at the center of a patch of Gauss points by performing an unweighted least-squares fit of a linear stress field to the given data.\n\n### Step 1: Problem Validation\n\nThe givens are:\n- The stress field model: $\\sigma_{xx}(x,y) = a_{0} + a_{1} x + a_{2} y$.\n- The node location for stress recovery: $(x,y) = (0, 0)$.\n- The set of $6$ Gauss-point data $(x_i, y_i, \\sigma_{xx,i})$:\n  1. $(1.0, 0.0)$, $\\sigma_{xx,1} = 122$\n  2. $(-1.0, 0.0)$, $\\sigma_{xx,2} = 79$\n  3. $(0.0, 1.0)$, $\\sigma_{xx,3} = 91$\n  4. $(0.0, -1.0)$, $\\sigma_{xx,4} = 107$\n  5. $(1.0, 1.0)$, $\\sigma_{xx,5} = 110$\n  6. $(-1.0, -1.0)$, $\\sigma_{xx,6} = 92$\n  All coordinates are in $\\mathrm{mm}$ and all stresses are in $\\mathrm{MPa}$.\n- The method: Unweighted least-squares criterion.\n- The final output requirement: The recovered nodal stress at $(0,0)$ rounded to four significant figures.\n\nThe problem is scientifically grounded, as it describes the Superconvergent Patch Recovery (SPR) method, a standard and well-established post-processing technique in computational solid mechanics. It is well-posed, objective, self-contained, and free of any contradictions or ambiguities. The data provided allow for a unique solution. Therefore, the problem is deemed valid.\n\n### Step 2: Solution Formulation\n\nThe goal is to find the coefficients $a_{0}$, $a_{1}$, and $a_{2}$ that minimize the sum of the squared errors, $S$, between the linear model and the given Gauss-point stresses. The objective function to minimize is:\n$$\nS(a_{0}, a_{1}, a_{2}) = \\sum_{i=1}^{6} \\left[ \\sigma_{xx}(x_i, y_i) - \\sigma_{xx,i} \\right]^2 = \\sum_{i=1}^{6} \\left[ (a_{0} + a_{1} x_i + a_{2} y_i) - \\sigma_{xx,i} \\right]^2\n$$\nThis is a standard linear least-squares problem. We can express the problem in matrix form. Let $\\mathbf{a}$ be the vector of unknown coefficients, $\\boldsymbol{\\sigma}$ be the vector of known stress values, and $\\mathbf{A}$ be the design matrix:\n$$\n\\mathbf{a} = \\begin{pmatrix} a_0 \\\\ a_1 \\\\ a_2 \\end{pmatrix}, \\quad \\boldsymbol{\\sigma} = \\begin{pmatrix} \\sigma_{xx,1} \\\\ \\sigma_{xx,2} \\\\ \\sigma_{xx,3} \\\\ \\sigma_{xx,4} \\\\ \\sigma_{xx,5} \\\\ \\sigma_{xx,6} \\end{pmatrix}, \\quad \\mathbf{A} = \\begin{pmatrix} 1 & x_1 & y_1 \\\\ 1 & x_2 & y_2 \\\\ 1 & x_3 & y_3 \\\\ 1 & x_4 & y_4 \\\\ 1 & x_5 & y_5 \\\\ 1 & x_6 & y_6 \\end{pmatrix}\n$$\nThe minimization of $S = \\|\\mathbf{A}\\mathbf{a} - \\boldsymbol{\\sigma}\\|^2$ leads to the normal equations:\n$$\n(\\mathbf{A}^T \\mathbf{A}) \\mathbf{a} = \\mathbf{A}^T \\boldsymbol{\\sigma}\n$$\nLet's construct the matrices using the given data. All coordinates $(x_i, y_i)$ are in $\\mathrm{mm}$ and stresses $\\sigma_{xx,i}$ are in $\\mathrm{MPa}$.\n$$\n\\mathbf{A} = \\begin{pmatrix} 1 & 1.0 & 0.0 \\\\ 1 & -1.0 & 0.0 \\\\ 1 & 0.0 & 1.0 \\\\ 1 & 0.0 & -1.0 \\\\ 1 & 1.0 & 1.0 \\\\ 1 & -1.0 & -1.0 \\end{pmatrix}, \\quad \\boldsymbol{\\sigma} = \\begin{pmatrix} 122 \\\\ 79 \\\\ 91 \\\\ 107 \\\\ 110 \\\\ 92 \\end{pmatrix}\n$$\nNow, we compute the matrix $\\mathbf{A}^T \\mathbf{A}$ and the vector $\\mathbf{A}^T \\boldsymbol{\\sigma}$. The components of $\\mathbf{A}^T \\mathbf{A}$ involve sums of powers and products of the coordinates:\n$$\n\\mathbf{A}^T \\mathbf{A} = \\begin{pmatrix} \\sum 1 & \\sum x_i & \\sum y_i \\\\ \\sum x_i & \\sum x_i^2 & \\sum x_i y_i \\\\ \\sum y_i & \\sum x_i y_i & \\sum y_i^2 \\end{pmatrix}\n$$\nLet's compute the sums over the $N=6$ data points:\n$\\sum 1 = 6$\n$\\sum x_i = 1.0 - 1.0 + 0.0 + 0.0 + 1.0 - 1.0 = 0$\n$\\sum y_i = 0.0 + 0.0 + 1.0 - 1.0 + 1.0 - 1.0 = 0$\n$\\sum x_i^2 = (1.0)^2 + (-1.0)^2 + (0.0)^2 + (0.0)^2 + (1.0)^2 + (-1.0)^2 = 1.0 + 1.0 + 0.0 + 0.0 + 1.0 + 1.0 = 4.0$\n$\\sum y_i^2 = (0.0)^2 + (0.0)^2 + (1.0)^2 + (-1.0)^2 + (1.0)^2 + (-1.0)^2 = 0.0 + 0.0 + 1.0 + 1.0 + 1.0 + 1.0 = 4.0$\n$\\sum x_i y_i = (1.0)(0.0) + (-1.0)(0.0) + (0.0)(1.0) + (0.0)(-1.0) + (1.0)(1.0) + (-1.0)(-1.0) = 0.0 + 0.0 + 0.0 + 0.0 + 1.0 + 1.0 = 2.0$\n\nThus, the matrix $\\mathbf{A}^T \\mathbf{A}$ is:\n$$\n\\mathbf{A}^T \\mathbf{A} = \\begin{pmatrix} 6 & 0 & 0 \\\\ 0 & 4 & 2 \\\\ 0 & 2 & 4 \\end{pmatrix}\n$$\nNext, we compute the vector $\\mathbf{A}^T \\boldsymbol{\\sigma}$:\n$$\n\\mathbf{A}^T \\boldsymbol{\\sigma} = \\begin{pmatrix} \\sum \\sigma_{xx,i} \\\\ \\sum x_i \\sigma_{xx,i} \\\\ \\sum y_i \\sigma_{xx,i} \\end{pmatrix}\n$$\nLet's compute these sums:\n$\\sum \\sigma_{xx,i} = 122 + 79 + 91 + 107 + 110 + 92 = 601$\n$\\sum x_i \\sigma_{xx,i} = (1.0)(122) + (-1.0)(79) + (0.0)(91) + (0.0)(107) + (1.0)(110) + (-1.0)(92) = 122 - 79 + 110 - 92 = 43 + 18 = 61$\n$\\sum y_i \\sigma_{xx,i} = (0.0)(122) + (0.0)(79) + (1.0)(91) + (-1.0)(107) + (1.0)(110) + (-1.0)(92) = 91 - 107 + 110 - 92 = -16 + 18 = 2$\n\nSo, the vector $\\mathbf{A}^T \\boldsymbol{\\sigma}$ is:\n$$\n\\mathbf{A}^T \\boldsymbol{\\sigma} = \\begin{pmatrix} 601 \\\\ 61 \\\\ 2 \\end{pmatrix}\n$$\nThe normal equations are:\n$$\n\\begin{pmatrix} 6 & 0 & 0 \\\\ 0 & 4 & 2 \\\\ 0 & 2 & 4 \\end{pmatrix} \\begin{pmatrix} a_0 \\\\ a_1 \\\\ a_2 \\end{pmatrix} = \\begin{pmatrix} 601 \\\\ 61 \\\\ 2 \\end{pmatrix}\n$$\nThis gives us a system of three linear equations:\n1. $6 a_0 = 601$\n2. $4 a_1 + 2 a_2 = 61$\n3. $2 a_1 + 4 a_2 = 2$\n\nFrom equation (1), we immediately find $a_0$:\n$$\na_0 = \\frac{601}{6}\n$$\nEquations (2) and (3) form a $2 \\times 2$ system for $a_1$ and $a_2$. We can solve this system. Multiply equation (3) by $2$:\n$$\n4 a_1 + 8 a_2 = 4\n$$\nSubtract equation (2) from this new equation:\n$$\n(4 a_1 + 8 a_2) - (4 a_1 + 2 a_2) = 4 - 61\n$$\n$$\n6 a_2 = -57 \\implies a_2 = -\\frac{57}{6} = -\\frac{19}{2} = -9.5\n$$\nSubstitute $a_2$ back into equation (3):\n$$\n2 a_1 + 4 (-9.5) = 2 \\implies 2 a_1 - 38 = 2 \\implies 2 a_1 = 40 \\implies a_1 = 20\n$$\nThe coefficients of the best-fit linear field are:\n$$\na_0 = \\frac{601}{6}, \\quad a_1 = 20, \\quad a_2 = -9.5\n$$\nThe smoothed stress field is:\n$$\n\\sigma_{xx}(x,y) = \\frac{601}{6} + 20 x - 9.5 y\n$$\nThe problem asks for the recovered nodal stress at the node $(x,y) = (0,0)$. We evaluate the fitted field at this point:\n$$\n\\sigma_{xx}(0,0) = a_0 + a_1(0) + a_2(0) = a_0 = \\frac{601}{6}\n$$\nNow, we compute the numerical value and round to four significant figures.\n$$\n\\sigma_{xx}(0,0) = \\frac{601}{6} \\approx 100.1666... \\, \\mathrm{MPa}\n$$\nRounding to four significant figures, we look at the fifth significant digit. The first four are $1, 0, 0, 1$. The fifth digit is $6$, which is greater than or equal to $5$, so we round up the fourth digit.\n$$\n\\sigma_{xx}(0,0) \\approx 100.2 \\, \\mathrm{MPa}\n$$",
            "answer": "$$\n\\boxed{100.2}\n$$"
        },
        {
            "introduction": "Beyond simply smoothing results, the primary motivation for SPR is often *a posteriori* error estimation, a technique to assess the quality of a finite element solution after it has been computed. This practice demonstrates how the recovered stress field, $\\sigma^*$, serves as a higher-accuracy benchmark against which the raw finite element stress, $\\sigma_h$, can be compared. By calculating the Zienkiewicz-Zhu (ZZ) error indicator for a simple 1D bar, you will see how SPR provides a quantitative measure of the error in the energy norm, a critical tool for driving adaptive mesh refinement .",
            "id": "3604343",
            "problem": "Consider a straight, prismatic, one-dimensional elastic bar of length $2$ m, modeled with two equal linear finite elements with nodes at $x=0$, $x=1$, and $x=2$. The bar has constant cross-sectional area $A = 1.0 \\times 10^{-2} \\, \\text{m}^2$ and Young's modulus $E = 1.0 \\times 10^{7} \\, \\text{Pa}$. The computed finite element nodal displacements are $u(0)=0$, $u(1)=1.0 \\times 10^{-3} \\, \\text{m}$, and $u(2)=1.5 \\times 10^{-3} \\, \\text{m}$.\n\nYou are to construct a Zienkiewicz–Zhu (ZZ) error indicator using Superconvergent Patch Recovery (SPR), under the assumptions of small strain and linear elasticity. Begin from the fundamental definitions $\\varepsilon(x) = \\mathrm{d}u/\\mathrm{d}x$ and $\\sigma(x) = E \\, \\varepsilon(x)$, and the energy-norm error density as the product of a constitutive inverse and the stress error.\n\nPerform the following steps:\n\n1. Compute the piecewise-constant finite element stress field $\\sigma_{h}$ on each element from the given nodal displacements, starting from $\\varepsilon(x) = \\mathrm{d}u/\\mathrm{d}x$ and $\\sigma(x) = E \\, \\varepsilon(x)$ for a linear two-node element.\n\n2. Construct a recovered stress field $\\sigma^{\\ast}(x)$ over the entire bar by a patch-based least-squares fit restricted to the linear ansatz $\\sigma^{\\ast}(x) = c_{0} + c_{1} x$, using the two superconvergent sampling points located at the element centers $x=0.5$ and $x=1.5$; take the target values at these points to be the corresponding elementwise finite element stresses $\\sigma_{h}$.\n\n3. Define the squared ZZ energy-norm error indicator for this bar as\n$$\n\\eta^{2} \\;=\\; \\sum_{e=1}^{2} \\int_{x_{e}}^{x_{e+1}} \\left(\\sigma^{\\ast}(x) - \\sigma_{h,e}\\right)^{2} \\,\\frac{A}{E}\\,\\mathrm{d}x,\n$$\nwhere $\\sigma_{h,e}$ is the constant finite element stress on element $e$. Evaluate each element integral using two-point Gauss–Legendre quadrature on the parent interval $[-1,1]$ with exact mapping, and justify why this quadrature is exact for this integrand.\n\nCompute $\\eta^{2}$ explicitly as a single real number. Express the final indicator energy in Joules and round your answer to four significant figures.",
            "solution": "The problem statement is evaluated as valid. It is self-contained, scientifically grounded in the principles of computational solid mechanics and the Finite Element Method (FEM), and well-posed, providing all necessary data and a clear, objective procedure for obtaining a unique solution.\n\nThe problem requires the computation of a squared Zienkiewicz–Zhu (ZZ) energy-norm error indicator, $\\eta^2$, for a one-dimensional elastic bar modeled with two linear finite elements. The solution proceeds by following the three steps outlined in the problem.\n\nGiven constants are:\nYoung's modulus, $E = 1.0 \\times 10^{7}$ Pa.\nCross-sectional area, $A = 1.0 \\times 10^{-2}$ m$^2$.\nThe ratio $A/E$ is $A/E = (1.0 \\times 10^{-2}) / (1.0 \\times 10^7) = 1.0 \\times 10^{-9}$ m$^2$/Pa.\n\nThe nodal coordinates are $x_1 = 0$ m, $x_2 = 1$ m, and $x_3 = 2$ m.\nThe nodal displacements are $u_1 = u(0) = 0$ m, $u_2 = u(1) = 1.0 \\times 10^{-3}$ m, and $u_3 = u(2) = 1.5 \\times 10^{-3}$ m.\n\n**1. Computation of the Finite Element Stress Field $\\sigma_h$**\n\nFor a one-dimensional, two-node linear finite element spanning from coordinate $x_a$ to $x_b$ with nodal displacements $u_a$ and $u_b$, the displacement field $u(x)$ is given by linear interpolation:\n$$\nu(x) = u_a \\frac{x_b - x}{x_b - x_a} + u_b \\frac{x - x_a}{x_b - x_a}\n$$\nThe strain $\\varepsilon(x) = \\mathrm{d}u/\\mathrm{d}x$ is constant within the element:\n$$\n\\varepsilon_h = \\frac{\\mathrm{d}u}{\\mathrm{d}x} = \\frac{u_b - u_a}{x_b - x_a}\n$$\nThe stress $\\sigma(x) = E \\varepsilon(x)$ is also constant, $\\sigma_h = E \\varepsilon_h$.\n\nFor element $1$ (from $x=0$ to $x=1$):\nThe nodal displacements are $u_1 = u(0) = 0$ and $u_2 = u(1) = 1.0 \\times 10^{-3}$.\nThe element length is $L_1 = 1 - 0 = 1$ m.\nThe strain is:\n$$\n\\varepsilon_{h,1} = \\frac{u(1) - u(0)}{1 - 0} = \\frac{1.0 \\times 10^{-3} - 0}{1} = 1.0 \\times 10^{-3}\n$$\nThe stress in element $1$ is:\n$$\n\\sigma_{h,1} = E \\varepsilon_{h,1} = (1.0 \\times 10^{7} \\, \\text{Pa}) \\times (1.0 \\times 10^{-3}) = 1.0 \\times 10^{4} \\, \\text{Pa}\n$$\n\nFor element $2$ (from $x=1$ to $x=2$):\nThe nodal displacements are $u_2 = u(1) = 1.0 \\times 10^{-3}$ and $u_3 = u(2) = 1.5 \\times 10^{-3}$.\nThe element length is $L_2 = 2 - 1 = 1$ m.\nThe strain is:\n$$\n\\varepsilon_{h,2} = \\frac{u(2) - u(1)}{2 - 1} = \\frac{1.5 \\times 10^{-3} - 1.0 \\times 10^{-3}}{1} = 0.5 \\times 10^{-3} = 5.0 \\times 10^{-4}\n$$\nThe stress in element $2$ is:\n$$\n\\sigma_{h,2} = E \\varepsilon_{h,2} = (1.0 \\times 10^{7} \\, \\text{Pa}) \\times (5.0 \\times 10^{-4}) = 5.0 \\times 10^{3} \\, \\text{Pa}\n$$\n\n**2. Construction of the Recovered Stress Field $\\sigma^{\\ast}(x)$**\n\nThe recovered stress field is assumed to be a linear function of position, $\\sigma^{\\ast}(x) = c_0 + c_1 x$. The coefficients $c_0$ and $c_1$ are determined by a least-squares fit using the finite element stresses at the superconvergent points. For linear elements, the center of each element is a superconvergent point for stress.\nThe sampling points are the centers of the elements: $x_{s1} = 0.5$ for element $1$, and $x_{s2} = 1.5$ for element $2$.\nThe target values for the fit are the constant FE stresses within each element: $\\sigma_h(0.5) = \\sigma_{h,1}$ and $\\sigma_h(1.5) = \\sigma_{h,2}$.\n\nSince there are two parameters ($c_0, c_1$) and two sampling points, the least-squares fit becomes an exact interpolation. We solve the following system of linear equations:\n$$\n\\sigma^{\\ast}(0.5) = c_0 + c_1(0.5) = \\sigma_{h,1} = 1.0 \\times 10^4 \\\\\n\\sigma^{\\ast}(1.5) = c_0 + c_1(1.5) = \\sigma_{h,2} = 5.0 \\times 10^3\n$$\nSubtracting the first equation from the second gives:\n$$\n(c_0 + 1.5 c_1) - (c_0 + 0.5 c_1) = 5.0 \\times 10^3 - 1.0 \\times 10^4 \\\\\nc_1 = -5.0 \\times 10^3\n$$\nSubstituting $c_1$ back into the first equation:\n$$\nc_0 + 0.5(-5.0 \\times 10^3) = 1.0 \\times 10^4 \\\\\nc_0 - 2.5 \\times 10^3 = 1.0 \\times 10^4 \\\\\nc_0 = 1.25 \\times 10^4\n$$\nThus, the recovered stress field is:\n$$\n\\sigma^{\\ast}(x) = 1.25 \\times 10^4 - (5.0 \\times 10^3) x \\quad (\\text{in Pa})\n$$\n\n**3. Evaluation of the Squared Error Indicator $\\eta^2$**\n\nThe squared ZZ energy-norm error indicator is given by:\n$$\n\\eta^{2} = \\sum_{e=1}^{2} \\int_{x_{e}}^{x_{e+1}} (\\sigma^{\\ast}(x) - \\sigma_{h,e})^{2} \\frac{A}{E} \\mathrm{d}x = \\frac{A}{E} \\left[ \\int_{0}^{1} (\\sigma^{\\ast}(x) - \\sigma_{h,1})^{2} \\mathrm{d}x + \\int_{1}^{2} (\\sigma^{\\ast}(x) - \\sigma_{h,2})^{2} \\mathrm{d}x \\right]\n$$\nThe integrands for each element are:\nFor element $1$: $(\\sigma^{\\ast}(x) - \\sigma_{h,1})^2 = (1.25 \\times 10^4 - 5.0 \\times 10^3 x - 1.0 \\times 10^4)^2 = (2.5 \\times 10^3 - 5.0 \\times 10^3 x)^2$.\nFor element $2$: $(\\sigma^{\\ast}(x) - \\sigma_{h,2})^2 = (1.25 \\times 10^4 - 5.0 \\times 10^3 x - 5.0 \\times 10^3)^2 = (7.5 \\times 10^3 - 5.0 \\times 10^3 x)^2$.\n\nThe problem requires evaluation using two-point Gauss–Legendre quadrature. This quadrature rule integrates polynomials of degree up to $2n-1 = 2(2)-1 = 3$ exactly. The integrands here are both quadratic polynomials ($\\text{degree } 2$), so the two-point rule will yield the exact result.\n\nLet $I_1 = \\int_{0}^{1} (2.5 \\times 10^3 - 5.0 \\times 10^3 x)^2 \\mathrm{d}x$ and $I_2 = \\int_{1}^{2} (7.5 \\times 10^3 - 5.0 \\times 10^3 x)^2 \\mathrm{d}x$.\n\nFor integral $I_1$ on $[0,1]$:\nMap $x \\in [0,1]$ to $\\xi \\in [-1,1]$ using $x = \\frac{1}{2}(\\xi+1)$, so $\\mathrm{d}x = \\frac{1}{2}\\mathrm{d}\\xi$.\nThe integrand becomes: $(2.5 \\times 10^3 - 5.0 \\times 10^3 \\frac{\\xi+1}{2})^2 = (2.5 \\times 10^3 - 2.5 \\times 10^3 (\\xi+1))^2 = (-2.5 \\times 10^3 \\xi)^2 = (6.25 \\times 10^6) \\xi^2$.\nSo, $I_1 = \\int_{-1}^{1} (6.25 \\times 10^6) \\xi^2 \\frac{1}{2} \\mathrm{d}\\xi = (3.125 \\times 10^6) \\int_{-1}^{1} \\xi^2 \\mathrm{d}\\xi$.\nThe two-point Gauss rule has points $\\xi = \\pm 1/\\sqrt{3}$ and weights $w=1$.\nLet $f(\\xi) = (3.125 \\times 10^6) \\xi^2$.\n$I_1 = f(-1/\\sqrt{3}) \\cdot 1 + f(1/\\sqrt{3}) \\cdot 1 = (3.125 \\times 10^6) (-\\frac{1}{\\sqrt{3}})^2 + (3.125 \\times 10^6) (\\frac{1}{\\sqrt{3}})^2 = 2 \\times (3.125 \\times 10^6) (\\frac{1}{3}) = \\frac{6.25 \\times 10^6}{3}$.\n\nFor integral $I_2$ on $[1,2]$:\nMap $x \\in [1,2]$ to $\\xi \\in [-1,1]$ using $x = \\frac{1}{2}(\\xi+3)$, so $\\mathrm{d}x = \\frac{1}{2}\\mathrm{d}\\xi$.\nThe integrand becomes: $(7.5 \\times 10^3 - 5.0 \\times 10^3 \\frac{\\xi+3}{2})^2 = (7.5 \\times 10^3 - 2.5 \\times 10^3 (\\xi+3))^2 = (7.5 \\times 10^3 - 2.5 \\times 10^3 \\xi - 7.5 \\times 10^3)^2 = (-2.5 \\times 10^3 \\xi)^2 = (6.25 \\times 10^6) \\xi^2$.\nThe integral $I_2$ is identical to $I_1$ in the parent coordinate system:\n$I_2 = \\int_{-1}^{1} (6.25 \\times 10^6) \\xi^2 \\frac{1}{2} \\mathrm{d}\\xi = \\frac{6.25 \\times 10^6}{3}$.\n\nTotal squared error:\n$$\n\\eta^2 = \\frac{A}{E} (I_1 + I_2) = (1.0 \\times 10^{-9}) \\left( \\frac{6.25 \\times 10^6}{3} + \\frac{6.25 \\times 10^6}{3} \\right)\n$$\n$$\n\\eta^2 = (1.0 \\times 10^{-9}) \\left( 2 \\times \\frac{6.25 \\times 10^6}{3} \\right) = (1.0 \\times 10^{-9}) \\left( \\frac{12.5 \\times 10^6}{3} \\right)\n$$\n$$\n\\eta^2 = \\frac{12.5}{3} \\times 10^{-3} \\approx 4.1666... \\times 10^{-3}\n$$\nThe units of $\\eta^2$ are $(\\text{m}^2/\\text{Pa}) \\times (\\text{Pa}^2 \\cdot \\text{m}) = \\text{N} \\cdot \\text{m} = \\text{J}$.\nRounding the result to four significant figures gives:\n$$\n\\eta^2 = 4.167 \\times 10^{-3} \\, \\text{J}\n$$",
            "answer": "$$\n\\boxed{4.167 \\times 10^{-3}}\n$$"
        },
        {
            "introduction": "Bridging the gap from theory to application requires translating algorithmic steps into functional code. This comprehensive capstone exercise challenges you to implement a complete SPR workflow for a 2D problem from first principles. You will manage mesh data, compute element-wise gradients, identify nodal patches, and perform the least-squares recovery programmatically. This hands-on implementation solidifies the concepts and provides a practical understanding of how SPR functions within a larger computational system .",
            "id": "3272888",
            "problem": "You are to implement a Superconvergent Patch Recovery scheme in the context of the Finite Element Method (FEM) using shape functions for piecewise linear triangular elements. The goal is to compute a more accurate gradient at each mesh node by performing a least-squares fit over the gradients computed from surrounding elements. The work must be grounded in first principles of numerical methods and scientific computing.\n\nStarting point and core definitions:\n- Consider a scalar field $u(x,y)$ defined on a two-dimensional domain, approximated by a piecewise linear finite element function using triangular elements. Each element uses linear Lagrange shape functions associated with its vertices. Within each triangle, the approximate solution can be represented as an affine function $u_h(x,y) = a + b x + c y$, where $a$, $b$, and $c$ are coefficients determined by nodal values. The element-wise gradient $\\nabla u_h$ is constant within a triangle.\n- The element-wise gradient is computed from the nodal values by using the definition of shape functions and the property that the gradient of an affine function is constant in the element. No shortcut formulas are provided in the statement; derive from the definition of affine interpolation and basic linear algebra.\n- Superconvergent Patch Recovery aims to recover a nodal gradient $\\nabla u^*(x_i,y_i)$ at node $(x_i,y_i)$ by fitting, via least-squares, a low-order polynomial model to the set of element-wise gradients from all elements that share that node. Use an affine model for each gradient component: fit $g_x(x,y)$ and $g_y(x,y)$ independently using an affine form over the element sampling locations in the patch.\n\nTask requirements:\n1. Construct triangular meshes and use piecewise linear shape functions to compute element-wise gradients for the discrete field $u_h(x,y)$. For the purposes of this task, define the analytic target field as $u(x,y) = \\sin(\\pi x)\\cos(\\pi y)$, where $\\pi$ denotes the circle constant. Angles must be treated in radians. The exact analytic gradient is $\\nabla u(x,y) = \\left(\\pi \\cos(\\pi x)\\cos(\\pi y),\\,-\\pi \\sin(\\pi x)\\sin(\\pi y)\\right)$.\n2. For each node $(x_i,y_i)$, form its patch consisting of all elements that include the node. For each element in the patch, compute the element-wise gradient $\\nabla u_h$ and record it together with a representative sampling location $(x_e,y_e)$ for the element (take the element centroid).\n3. For each node, fit $g_x(x,y)$ and $g_y(x,y)$ to the collected element gradient data in its patch via least squares using an affine model. If the patch is underdetermined or ill-conditioned (for example, fewer than $3$ sampling points or numerically singular), fall back to a constant model equal to the average of the element gradients in the patch to ensure numerical robustness.\n4. Evaluate the recovered gradient at the node coordinate by evaluating the fitted model at $(x_i,y_i)$ to obtain $\\nabla u^*(x_i,y_i)$.\n5. Define the raw nodal gradient approximation as the average of the element-wise gradients over the node’s patch. Define the recovered nodal gradient as $\\nabla u^*(x_i,y_i)$ from the least-squares fit. Compute the mean nodal error for both raw and recovered gradients across all nodes as the average of the Euclidean norm of the difference between the approximation and the exact analytic gradient at each node.\n6. For each test case, compute the improvement ratio defined as the mean raw gradient error divided by the mean recovered gradient error. A value greater than $1$ indicates improvement.\n7. All angles must be interpreted in radians when evaluating trigonometric functions.\n\nTest suite:\nImplement and evaluate the algorithm on the following mesh configurations:\n- Case $1$: Uniform rectangular mesh on the unit square $[0,1]\\times[0,1]$ with $n_x = 8$, $n_y = 8$ rectangular cells, each split into two triangles with alternating diagonal orientation to avoid bias.\n- Case $2$: Coarser rectangular mesh on the unit square $[0,1]\\times[0,1]$ with $n_x = 3$, $n_y = 3$ rectangular cells, split as above.\n- Case $3$: Anisotropic rectangular mesh on the unit square $[0,1]\\times[0,1]$ with $n_x = 12$, $n_y = 4$ rectangular cells, split as above.\n- Case $4$: Single triangle domain with vertices $(0,0)$, $(1,0)$, and $(0,1)$.\n\nOutput specification:\n- For each of the $4$ cases, compute the improvement ratio defined in item $6$.\n- Your program should produce a single line of output containing the $4$ improvement ratios as a comma-separated list enclosed in square brackets, with each ratio rounded to $6$ decimal places (for example, $[r_1,r_2,r_3,r_4]$ where each $r_i$ is a float rounded to $6$ decimal places).",
            "solution": "The user's request is to implement and evaluate a Superconvergent Patch Recovery (SPR) scheme for computing gradients of a scalar field approximated using piecewise linear triangular finite elements. The problem is scientifically grounded, well-posed, and objective. It outlines a standard and verifiable numerical method, providing all necessary definitions, test cases, and evaluation metrics. The problem is therefore deemed valid.\n\nThe solution is developed based on the first principles of the Finite Element Method (FEM) and numerical linear algebra. We will proceed by first establishing the theoretical framework for element-wise gradient calculation and the SPR technique, followed by a description of the algorithmic implementation and error analysis.\n\n**1. Finite Element Approximation and Element Gradient**\n\nWe consider a scalar field $u(x,y)$ approximated over a domain partitioned into triangular elements. Within each element, the discrete field $u_h(x,y)$ is a linear combination of nodal values $u_i$ weighted by linear Lagrange shape functions $N_i(x,y)$:\n$$u_h(x,y) = \\sum_{i=1}^{3} N_i(x,y) u_i$$\nwhere the summation is over the three vertices of the triangle. Since the shape functions are linear in position $(x,y)$, the approximation $u_h(x,y)$ within the element is an affine function of the form:\n$$u_h(x,y) = a + b x + c y$$\nThe gradient of this function, $\\nabla u_h$, is constant throughout the element:\n$$\\nabla u_h = \\begin{pmatrix} \\frac{\\partial u_h}{\\partial x} \\\\ \\frac{\\partial u_h}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} b \\\\ c \\end{pmatrix}$$\nThe coefficients $(a, b, c)$ are determined by requiring the function to match the nodal values $(u_1, u_2, u_3)$ at the element's vertices $(x_1, y_1)$, $(x_2, y_2)$, and $(x_3, y_3)$. This yields a system of linear equations:\n$$\n\\begin{pmatrix} 1 & x_1 & y_1 \\\\ 1 & x_2 & y_2 \\\\ 1 & x_3 & y_3 \\end{pmatrix}\n\\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix} =\n\\begin{pmatrix} u_1 \\\\ u_2 \\\\ u_3 \\end{pmatrix}\n$$\nSolving this system for the gradient components $(b,c)$ gives:\n$$\nb = \\frac{\\partial u_h}{\\partial x} = \\frac{1}{2A} \\left[ (y_2 - y_3)u_1 + (y_3 - y_1)u_2 + (y_1 - y_2)u_3 \\right]\n$$\n$$\nc = \\frac{\\partial u_h}{\\partial y} = \\frac{1}{2A} \\left[ (x_3 - x_2)u_1 + (x_1 - x_3)u_2 + (x_2 - x_1)u_3 \\right]\n$$\nwhere $A$ is the area of the triangular element, calculated as:\n$$A = \\frac{1}{2} \\det \\begin{pmatrix} x_1 & y_1 & 1 \\\\ x_2 & y_2 & 1 \\\\ x_3 & y_3 & 1 \\end{pmatrix} = \\frac{1}{2} \\left[ x_1(y_2 - y_3) + x_2(y_3 - y_1) + x_3(y_1 - y_2) \\right]$$\nThis element-wise gradient is known to be less accurate at the element domain than at certain specific points within the element, known as superconvergent points.\n\n**2. Superconvergent Patch Recovery (SPR)**\n\nSPR is a post-processing technique to obtain a more accurate, continuous gradient field defined at the mesh nodes. The procedure for a given node $(x_i, y_i)$ is as follows:\n\n- **Patch Definition:** A \"patch\" is formed, consisting of all elements that share the node $(x_i, y_i)$.\n- **Data Collection:** For each element $k$ in the patch, we have a pair of data: the constant element gradient $(\\nabla u_h)_k$ and a representative sampling location $(x_e, y_e)_k$, which is taken to be the element's centroid.\n- **Least-Squares Fit:** A continuous, low-order polynomial model is fitted to the discrete gradient data from the patch. We use an affine model for each gradient component independently:\n  $$g_x(x,y) = c_{0x} + c_{1x}x + c_{2x}y$$\n  $$g_y(x,y) = c_{0y} + c_{1y}x + c_{2y}y$$\n  Let the patch consist of $M$ elements, yielding gradient data $\\{ (\\nabla u_h)_k = (g_{xk}, g_{yk}) \\}_{k=1}^M$ at centroids $\\{ (x_k, y_k) \\}_{k=1}^M$. To find the coefficients for $g_x$, we solve the overdetermined system $\\mathbf{A}\\mathbf{c}_x = \\mathbf{g}_x$ in a least-squares sense:\n  $$\n  \\underbrace{\\begin{pmatrix} 1 & x_1 & y_1 \\\\ 1 & x_2 & y_2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & x_M & y_M \\end{pmatrix}}_{\\mathbf{A}}\n  \\underbrace{\\begin{pmatrix} c_{0x} \\\\ c_{1x} \\\\ c_{2x} \\end{pmatrix}}_{\\mathbf{c}_x} =\n  \\underbrace{\\begin{pmatrix} g_{x1} \\\\ g_{x2} \\\\ \\vdots \\\\ g_{xM} \\end{pmatrix}}_{\\mathbf{g}_x}\n  $$\n  The least-squares solution is found via the normal equations, $\\mathbf{A}^T\\mathbf{A}\\mathbf{c}_x = \\mathbf{A}^T\\mathbf{g}_x$. This procedure is repeated for the $y$-component to find $\\mathbf{c}_y$.\n- **Robustness:** For a unique affine fit, at least $3$ non-collinear sampling points (centroids) are required. If the number of elements $M < 3$, or if the matrix $\\mathbf{A}$ is rank-deficient (i.e., the centroids are collinear), the system is ill-conditioned. In such cases, we fall back to a constant model, where the recovered gradient is simply the average of the element gradients in the patch.\n- **Recovered Gradient:** The recovered nodal gradient $\\nabla u^*(x_i, y_i)$ is obtained by evaluating the fitted affine models at the node's own coordinate $(x_i, y_i)$:\n  $$\\nabla u^*(x_i, y_i) = \\begin{pmatrix} g_x(x_i, y_i) \\\\ g_y(x_i, y_i) \\end{pmatrix}$$\n\n**3. Error Evaluation and Improvement Ratio**\n\nTo quantify the effectiveness of SPR, we compare the \"recovered\" gradient to a \"raw\" approximation and the exact analytical gradient.\n- **Analytic Field:** The problem specifies the field $u(x,y) = \\sin(\\pi x)\\cos(\\pi y)$.\n- **Exact Gradient:** The exact gradient is $\\nabla u(x,y) = \\left(\\pi \\cos(\\pi x)\\cos(\\pi y),\\,-\\pi \\sin(\\pi x)\\sin(\\pi y)\\right)$.\n- **Raw Nodal Gradient:** For each node, this is defined as the simple average of the constant gradients of all elements in its patch.\n- **Mean Nodal Error:** The error is calculated at each node $i$ as the Euclidean norm of the difference between an approximate gradient ($\\nabla u_{approx}$) and the exact gradient ($\\nabla u$): $E_i = \\|\\nabla u_{approx}(x_i, y_i) - \\nabla u(x_i, y_i)\\|_2$. The mean nodal error is the average of these errors over all nodes in the mesh.\n- **Improvement Ratio:** The final metric is the ratio of the mean raw gradient error to the mean recovered gradient error:\n  $$\\text{Improvement Ratio} = \\frac{\\text{Mean Raw Gradient Error}}{\\text{Mean Recovered Gradient Error}}$$\n  A ratio greater than $1$ indicates that SPR improves the gradient accuracy.\n\n**4. Algorithmic Steps**\n\nFor each test case, the algorithm proceeds as follows:\n1.  **Mesh Generation:** Construct the nodal coordinates array and the element connectivity array for the specified mesh configuration. For rectangular domains, a grid of $n_x \\times n_y$ cells is created, with each cell split into two triangles using alternating diagonals.\n2.  **Nodal Value Calculation:** Evaluate the analytic function $u(x,y)$ at each node to obtain the nodal values $u_i$.\n3.  **Element-wise Computations:** For each element, calculate its constant gradient $\\nabla u_h$ using the nodal values and coordinates, and compute its centroid.\n4.  **Patch Assembly:** Create a map from each node index to the list of indices of elements belonging to its patch.\n5.  **Nodal Gradient Recovery and Error Calculation:** Iterate through each node in the mesh:\n    a. Identify the patch elements and collect their pre-computed gradients and centroids.\n    b. Calculate the raw nodal gradient by averaging the patch gradients.\n    c. Determine if the patch is well-conditioned for an affine fit ($M \\ge 3$ and non-collinear centroids).\n    d. If well-conditioned, perform the least-squares fit to find the coefficients of $g_x$ and $g_y$. Evaluate these at the node's coordinate to get the recovered gradient $\\nabla u^*$.\n    e. If ill-conditioned, set the recovered gradient equal to the raw gradient.\n    f. Calculate the exact gradient at the node's coordinate.\n    g. Compute and accumulate the nodal errors for both the raw and recovered gradients.\n6.  **Final Metric:** After processing all nodes, compute the mean raw error and mean recovered error. Calculate their ratio to obtain the final improvement ratio. This process is repeated for all four test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef u_analytic(x, y):\n    \"\"\"Computes the analytic scalar field u(x,y).\"\"\"\n    return np.sin(np.pi * x) * np.cos(np.pi * y)\n\ndef grad_u_analytic(x, y):\n    \"\"\"Computes the analytic gradient of the scalar field u(x,y).\"\"\"\n    grad_x = np.pi * np.cos(np.pi * x) * np.cos(np.pi * y)\n    grad_y = -np.pi * np.sin(np.pi * x) * np.sin(np.pi * y)\n    return np.array([grad_x, grad_y])\n\ndef generate_rect_mesh(nx, ny):\n    \"\"\"Generates a triangular mesh on the unit square.\"\"\"\n    x_coords = np.linspace(0.0, 1.0, nx + 1)\n    y_coords = np.linspace(0.0, 1.0, ny + 1)\n    nodes = np.array([[x, y] for y in y_coords for x in x_coords])\n    \n    elements = []\n    for j in range(ny):\n        for i in range(nx):\n            # Node indices for the rectangular cell (i,j)\n            n1 = j * (nx + 1) + i          # bottom-left\n            n2 = j * (nx + 1) + (i + 1)    # bottom-right\n            n3 = (j + 1) * (nx + 1) + i    # top-left\n            n4 = (j + 1) * (nx + 1) + (i + 1) # top-right\n            \n            # Alternating diagonal split to avoid mesh bias\n            if (i + j) % 2 == 0:\n                # Diagonal from bottom-left to top-right\n                elements.append([n1, n2, n4])\n                elements.append([n1, n4, n3])\n            else:\n                # Diagonal from bottom-right to top-left\n                elements.append([n1, n2, n3])\n                elements.append([n2, n4, n3])\n                \n    return nodes, np.array(elements, dtype=int)\n\ndef generate_single_tri_mesh():\n    \"\"\"Generates a mesh with a single triangle.\"\"\"\n    nodes = np.array([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0]])\n    elements = np.array([[0, 1, 2]], dtype=int)\n    return nodes, elements\n\ndef compute_element_gradient(node_coords, u_elem_nodes):\n    \"\"\"Computes the constant gradient for a single linear triangular element.\"\"\"\n    (x1, y1), (x2, y2), (x3, y3) = node_coords\n    u1, u2, u3 = u_elem_nodes\n    \n    # Using the formulation based on shape function derivatives\n    area2 = x1 * (y2 - y3) + x2 * (y3 - y1) + x3 * (y1 - y2)\n    if abs(area2)  1e-15:\n        return np.zeros(2) # Degenerate triangle\n        \n    grad_x = ((y2 - y3) * u1 + (y3 - y1) * u2 + (y1 - y2) * u3) / area2\n    grad_y = ((x3 - x2) * u1 + (x1 - x3) * u2 + (x2 - x1) * u3) / area2\n    \n    return np.array([grad_x, grad_y])\n\ndef solve():\n    \"\"\"Main function to run the SPR analysis for all test cases.\"\"\"\n    test_cases = [\n        {'type': 'rect', 'nx': 8, 'ny': 8},\n        {'type': 'rect', 'nx': 3, 'ny': 3},\n        {'type': 'rect', 'nx': 12, 'ny': 4},\n        {'type': 'single_tri'},\n    ]\n\n    results = []\n    for case in test_cases:\n        # 1. Generate mesh (nodes, elements)\n        if case['type'] == 'rect':\n            nodes, elements = generate_rect_mesh(case['nx'], case['ny'])\n        else:\n            nodes, elements = generate_single_tri_mesh()\n        \n        num_nodes = len(nodes)\n        num_elements = len(elements)\n\n        # 2. Compute nodal values from analytic function\n        u_nodal = u_analytic(nodes[:, 0], nodes[:, 1])\n\n        # 3. Compute element-wise gradients and centroids\n        elem_gradients = np.zeros((num_elements, 2))\n        elem_centroids = np.zeros((num_elements, 2))\n        for i, elem_node_indices in enumerate(elements):\n            node_coords = nodes[elem_node_indices]\n            u_vals = u_nodal[elem_node_indices]\n            elem_gradients[i] = compute_element_gradient(node_coords, u_vals)\n            elem_centroids[i] = np.mean(node_coords, axis=0)\n\n        # 4. Build node-to-element mapping (patches)\n        node_to_elements = [[] for _ in range(num_nodes)]\n        for i, elem_node_indices in enumerate(elements):\n            for node_idx in elem_node_indices:\n                node_to_elements[node_idx].append(i)\n\n        # 5. Loop through nodes to compute errors\n        total_raw_error = 0.0\n        total_recovered_error = 0.0\n\n        for i in range(num_nodes):\n            node_coord = nodes[i]\n            patch_elem_indices = node_to_elements[i]\n            \n            if not patch_elem_indices:\n                continue\n\n            patch_gradients = elem_gradients[patch_elem_indices]\n            patch_centroids = elem_centroids[patch_elem_indices]\n\n            # Raw gradient: simple average of gradients in the patch\n            raw_gradient = np.mean(patch_gradients, axis=0)\n\n            # Recovered gradient: via least-squares fit\n            recovered_gradient = None\n            M = len(patch_elem_indices)\n\n            # Build the matrix A for the least-squares system\n            A = np.ones((M, 3))\n            A[:, 1:] = patch_centroids\n            \n            # Fallback condition: not enough points or centroids are collinear\n            if M  3 or np.linalg.matrix_rank(A)  3:\n                recovered_gradient = raw_gradient\n            else:\n                # Solve for coefficients for gx and gy using lstsq for robustness\n                gx_coeffs, _, _, _ = np.linalg.lstsq(A, patch_gradients[:, 0], rcond=None)\n                gy_coeffs, _, _, _ = np.linalg.lstsq(A, patch_gradients[:, 1], rcond=None)\n\n                # Evaluate the fitted affine models at the node's coordinate\n                node_vec = np.array([1, node_coord[0], node_coord[1]])\n                rec_grad_x = node_vec @ gx_coeffs\n                rec_grad_y = node_vec @ gy_coeffs\n                recovered_gradient = np.array([rec_grad_x, rec_grad_y])\n\n            # Compute exact gradient\n            exact_grad = grad_u_analytic(node_coord[0], node_coord[1])\n            \n            # Calculate and accumulate L2 norm of the error vector\n            raw_error = np.linalg.norm(raw_gradient - exact_grad)\n            recovered_error = np.linalg.norm(recovered_gradient - exact_grad)\n            \n            total_raw_error += raw_error\n            total_recovered_error += recovered_error\n\n        # 6. Calculate mean errors and the improvement ratio\n        mean_raw_error = total_raw_error / num_nodes if num_nodes > 0 else 0.0\n        mean_recovered_error = total_recovered_error / num_nodes if num_nodes > 0 else 0.0\n\n        if mean_recovered_error > 1e-15:\n            ratio = mean_raw_error / mean_recovered_error\n        else: # If both errors are zero or tiny, there's no improvement\n            ratio = 1.0\n\n        results.append(ratio)\n\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n\n```"
        }
    ]
}