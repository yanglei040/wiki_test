{
    "hands_on_practices": [
        {
            "introduction": "In computational mechanics, a residual norm is not merely an abstract number used to terminate an iteration; it can possess a deep physical meaning. The residual force vector represents an imbalance, and this exercise  guides you to quantify this imbalance in terms of the energy associated with it. By computing the stiffness-inverse weighted norm of the residual, you will connect a mathematical quantity to the physical concept of strain energy, providing a more profound basis for your convergence criteria.",
            "id": "3595528",
            "problem": "A linearized static equilibrium in computational solid mechanics for a condensed two-degree-of-freedom subsystem can be written as $K u = f$, where $K$ is the symmetric positive definite (SPD) condensed stiffness matrix with entries in $\\mathrm{N/m}$, $u$ is the displacement vector with entries in $\\mathrm{m}$, and $f$ is the external force vector with entries in $\\mathrm{N}$. At a given nonlinear iteration $k$, the residual (unbalanced nodal force) is $r^{(k)} = f - K u^{(k)}$, with entries in $\\mathrm{N}$. Consider the following specific SPD stiffness matrix and residual vector, representative of a $2 \\times 2$ condensed subsystem:\n$$\nK = \\begin{pmatrix}\n3.0 \\times 10^{6} & -1.0 \\times 10^{6} \\\\\n-1.0 \\times 10^{6} & 2.0 \\times 10^{6}\n\\end{pmatrix} \\ \\mathrm{N/m}, \n\\qquad\nr = \\begin{pmatrix}\n5.00 \\times 10^{2} \\\\\n-2.00 \\times 10^{2}\n\\end{pmatrix} \\ \\mathrm{N}.\n$$\nUsing first principles of energy in linear elasticity and the norm induced by the inverse stiffness, interpret the residual norm induced by $K^{-1}$ as an energy-based measure of imbalance and compute it. Specifically, compute the value of the $K^{-1}$-induced norm of the residual, $\\|r\\|_{K^{-1}}$, and the associated complementary energy-like measure $\\tfrac{1}{2} \\, r^{\\mathsf{T}} K^{-1} r$. Explain the physical units of both quantities and the meaning of their magnitudes in terms of strain energy consistency of the current iterate.\n\nExpress the complementary energy-like measure in $\\mathrm{J}$ and the norm in $\\sqrt{\\mathrm{J}}$. Round the norm $\\|r\\|_{K^{-1}}$ to four significant figures. Report only the numerical value of $\\|r\\|_{K^{-1}}$.",
            "solution": "The linearized static equilibrium statement for a condensed subsystem is $K u = f$, where $K$ is symmetric positive definite (SPD). At an iteration with displacement $u^{(k)}$, the residual is $r = f - K u^{(k)}$, with entries in $\\mathrm{N}$. In energy terms, for an SPD matrix $M$, the $M$-induced norm of a vector $x$ is defined by $\\|x\\|_{M} = \\sqrt{x^{\\mathsf{T}} M x}$. Choosing $M = K^{-1}$ yields the $K^{-1}$-induced norm $\\|r\\|_{K^{-1}} = \\sqrt{r^{\\mathsf{T}} K^{-1} r}$. The quantity $r^{\\mathsf{T}} K^{-1} r$ has units $\\mathrm{N} \\cdot \\mathrm{m} = \\mathrm{J}$ because $K$ has units $\\mathrm{N/m}$, so $K^{-1}$ has units $\\mathrm{m/N}$, and $r^{\\mathsf{T}} K^{-1} r$ carries $\\mathrm{N} \\cdot \\mathrm{m/N} \\cdot \\mathrm{N} = \\mathrm{N} \\cdot \\mathrm{m} = \\mathrm{J}$. Thus, $\\|r\\|_{K^{-1}}$ has units $\\sqrt{\\mathrm{J}}$. The scalar $\\tfrac{1}{2} r^{\\mathsf{T}} K^{-1} r$ is an energy-like quantity equal to the complementary energy associated with equilibrating the residual through a compliant displacement increment; it measures the strain energy inconsistency of the current iterate.\n\nWe now compute $K^{-1}$. For a $2 \\times 2$ matrix,\n$$\nK^{-1} = \\frac{1}{\\det K} \\begin{pmatrix} K_{22} & -K_{12} \\\\ -K_{21} & K_{11} \\end{pmatrix}.\n$$\nCompute the determinant:\n$$\n\\det K = (3.0 \\times 10^{6})(2.0 \\times 10^{6}) - (-1.0 \\times 10^{6})(-1.0 \\times 10^{6}) = 6.0 \\times 10^{12} - 1.0 \\times 10^{12} = 5.0 \\times 10^{12} \\ \\mathrm{N^{2}/m^{2}}.\n$$\nTherefore,\n$$\nK^{-1} = \\frac{1}{5.0 \\times 10^{12}}\n\\begin{pmatrix}\n2.0 \\times 10^{6} & 1.0 \\times 10^{6} \\\\\n1.0 \\times 10^{6} & 3.0 \\times 10^{6}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n4.0 \\times 10^{-7} & 2.0 \\times 10^{-7} \\\\\n2.0 \\times 10^{-7} & 6.0 \\times 10^{-7}\n\\end{pmatrix} \\ \\mathrm{m/N}.\n$$\nNext compute $r^{\\mathsf{T}} K^{-1} r$. First, compute $K^{-1} r$:\n$$\nK^{-1} r\n=\n\\begin{pmatrix}\n4.0 \\times 10^{-7} & 2.0 \\times 10^{-7} \\\\\n2.0 \\times 10^{-7} & 6.0 \\times 10^{-7}\n\\end{pmatrix}\n\\begin{pmatrix}\n5.00 \\times 10^{2} \\\\\n-2.00 \\times 10^{2}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n(4.0 \\times 10^{-7})(5.00 \\times 10^{2}) + (2.0 \\times 10^{-7})(-2.00 \\times 10^{2}) \\\\\n(2.0 \\times 10^{-7})(5.00 \\times 10^{2}) + (6.0 \\times 10^{-7})(-2.00 \\times 10^{2})\n\\end{pmatrix}.\n$$\nCompute each component:\n$$\n(4.0 \\times 10^{-7})(5.00 \\times 10^{2}) = 2.00 \\times 10^{-4}, \\quad\n(2.0 \\times 10^{-7})(-2.00 \\times 10^{2}) = -4.00 \\times 10^{-5},\n$$\nso the first component is $2.00 \\times 10^{-4} - 4.00 \\times 10^{-5} = 1.60 \\times 10^{-4} \\ \\mathrm{m}$.\nFor the second component,\n$$\n(2.0 \\times 10^{-7})(5.00 \\times 10^{2}) = 1.00 \\times 10^{-4}, \\quad\n(6.0 \\times 10^{-7})(-2.00 \\times 10^{2}) = -1.20 \\times 10^{-4},\n$$\nso the second component is $1.00 \\times 10^{-4} - 1.20 \\times 10^{-4} = -2.00 \\times 10^{-5} \\ \\mathrm{m}$.\nTherefore,\n$$\nK^{-1} r = \\begin{pmatrix} 1.60 \\times 10^{-4} \\\\ -2.00 \\times 10^{-5} \\end{pmatrix} \\ \\mathrm{m}.\n$$\nNow compute\n$$\nr^{\\mathsf{T}} K^{-1} r = \n\\begin{pmatrix}\n5.00 \\times 10^{2} & -2.00 \\times 10^{2}\n\\end{pmatrix}\n\\begin{pmatrix}\n1.60 \\times 10^{-4} \\\\\n-2.00 \\times 10^{-5}\n\\end{pmatrix}\n= (5.00 \\times 10^{2})(1.60 \\times 10^{-4}) + (-2.00 \\times 10^{2})(-2.00 \\times 10^{-5}).\n$$\nCompute the terms:\n$$\n(5.00 \\times 10^{2})(1.60 \\times 10^{-4}) = 8.00 \\times 10^{-2}, \\quad\n(-2.00 \\times 10^{2})(-2.00 \\times 10^{-5}) = 4.00 \\times 10^{-3}.\n$$\nHence,\n$$\nr^{\\mathsf{T}} K^{-1} r = 8.00 \\times 10^{-2} + 4.00 \\times 10^{-3} = 8.40 \\times 10^{-2} \\ \\mathrm{J}.\n$$\nThe complementary energy-like measure is\n$$\n\\frac{1}{2} \\, r^{\\mathsf{T}} K^{-1} r = \\frac{1}{2} \\times 8.40 \\times 10^{-2} = 4.20 \\times 10^{-2} \\ \\mathrm{J}.\n$$\nThe $K^{-1}$-induced norm of the residual is\n$$\n\\|r\\|_{K^{-1}} = \\sqrt{r^{\\mathsf{T}} K^{-1} r} = \\sqrt{8.40 \\times 10^{-2}} \\ \\sqrt{\\mathrm{J}} \\approx 2.898275349 \\times 10^{-1} \\ \\sqrt{\\mathrm{J}}.\n$$\nRounded to four significant figures, this is $2.898 \\times 10^{-1} \\ \\sqrt{\\mathrm{J}} = 0.2898 \\ \\sqrt{\\mathrm{J}}$.\n\nInterpretation: The scalar $\\tfrac{1}{2} r^{\\mathsf{T}} K^{-1} r = 4.20 \\times 10^{-2} \\ \\mathrm{J}$ is the complementary energy required to equilibrate the residual through the system compliance. As an energy-based convergence criterion, driving this quantity toward zero enforces consistency of internal and external work. The norm $\\|r\\|_{K^{-1}}$ provides a square-root-of-energy measure of imbalance that is invariant under orthonormal changes of basis and directly reflects the stiffness-weighted severity of the unbalanced forces.",
            "answer": "$$\\boxed{0.2898}$$"
        },
        {
            "introduction": "After establishing that norms can have physical meaning, a practical question arises: which mathematical norm should we use? The choice is not arbitrary, as different norms, such as the Euclidean ($\\ell_2$) and maximum ($\\ell_{\\infty}$) norms, exhibit different sensitivities to the distribution of errors within the residual vector. This practice  demonstrates why a single norm may not suffice, highlighting how the $\\ell_{\\infty}$ norm is crucial for detecting localized issues like incipient material failure or contact problems, which can be averaged out and missed by the $\\ell_2$ norm.",
            "id": "3595529",
            "problem": "You are given the discrete static equilibrium setting of computational solid mechanics, where the residual vector $r \\in \\mathbb{R}^n$ represents the current nodal force imbalance derived from the equilibrium equation $K(u) u = f$ via the internal and external force mismatch $r(u) = f_{\\text{ext}} - f_{\\text{int}}(u)$. Convergence in a nonlinear solver such as the Newton–Raphson method is commonly monitored by norms of $r$. Two canonical choices are the Euclidean norm (also known as the $\\ell_2$ norm) and the maximum norm (also known as the $\\ell_{\\infty}$ norm), defined by\n$$\n\\|r\\|_2 = \\left( \\sum_{i=1}^n r_i^2 \\right)^{1/2}, \\quad \\|r\\|_{\\infty} = \\max_{1 \\le i \\le n} |r_i|.\n$$\nIn practice, when localized failure emerges (for example, a single node develops a large imbalance), $\\|r\\|_{\\infty}$ is highly sensitive because it directly measures the largest imbalance, whereas $\\|r\\|_2$ aggregates contributions and may underreport localized spikes while being more robust to random noise. To balance sensitivity and robustness, define two hybrid measures that both explicitly incorporate the maximum imbalance and reduce noise sensitivity:\n\n1) A norm-like mixed measure that aggregates normalized $\\ell_2$ and $\\ell_{\\infty}$ information:\n$$\n\\|r\\|_{\\text{hyb1}} = \\left( \\left(\\frac{\\|r\\|_2}{\\Theta_2}\\right)^2 + \\left(\\frac{\\|r\\|_{\\infty}}{\\Theta_{\\infty}}\\right)^2 \\right)^{1/2}.\n$$\n\n2) A Huber-augmented max measure that clips the quadratic growth of large components while still bounding the maximum:\n$$\n\\phi_{\\delta}(x) = \\begin{cases}\nx^2, & |x| \\le \\delta,\\\\\n2\\delta |x| - \\delta^2, & |x| > \\delta,\n\\end{cases}\n\\qquad\n\\|r\\|_{\\text{Huber}} = \\left( \\sum_{i=1}^n \\phi_{\\delta}(r_i) \\right)^{1/2}, \\qquad\n\\|r\\|_{\\text{hyb2}} = \\max\\!\\left( \\frac{\\|r\\|_{\\infty}}{\\Theta_{\\infty}}, \\frac{\\|r\\|_{\\text{Huber}}}{\\Theta_2} \\right).\n$$\n\nLet the per-node tolerance be $\\Theta_{\\infty} = \\theta$ and the aggregate tolerance be $\\Theta_2 = \\sqrt{n}\\,\\theta$, which corresponds to the case where all components are allowed up to the per-node tolerance $\\theta$ simultaneously. Take the Huber parameter $\\delta > 0$ fixed. Define the following dimensionless decision rules, each returning a boolean:\n- $\\text{det}_{\\infty} = \\left(\\frac{\\|r\\|_{\\infty}}{\\Theta_{\\infty}} > 1\\right)$,\n- $\\text{det}_2 = \\left(\\frac{\\|r\\|_2}{\\Theta_2} > 1\\right)$,\n- $\\text{det}_{\\text{hyb1}} = \\left(\\|r\\|_{\\text{hyb1}} > 1\\right)$,\n- $\\text{det}_{\\text{hyb2}} = \\left(\\|r\\|_{\\text{hyb2}} > 1\\right)$.\n\nYou must write a complete, runnable program that, for a prescribed test suite of residual vectors, computes the four dimensionless measures\n$$\nm_2 = \\frac{\\|r\\|_2}{\\Theta_2}, \\quad m_{\\infty} = \\frac{\\|r\\|_{\\infty}}{\\Theta_{\\infty}}, \\quad m_{\\text{hyb1}} = \\|r\\|_{\\text{hyb1}}, \\quad m_{\\text{hyb2}} = \\|r\\|_{\\text{hyb2}},\n$$\nand the corresponding boolean decisions $\\text{det}_2$, $\\text{det}_{\\infty}$, $\\text{det}_{\\text{hyb1}}$, $\\text{det}_{\\text{hyb2}}$.\n\nUse the following parameters for all test cases:\n- Per-node tolerance $\\theta = 10$ so that $\\Theta_{\\infty} = \\theta$ and $\\Theta_2 = \\sqrt{n}\\,\\theta$ with $n$ equal to the length of each residual vector.\n- Huber parameter $\\delta = 1$.\n\nTest suite (each residual vector is dimensionless and must be used exactly as listed; all vectors have $n = 12$):\n- Case A (localized outlier plus small noise): $r = [0.1,\\,-0.05,\\,0.12,\\,-0.08,\\,12.0,\\,0.07,\\,-0.03,\\,0.02,\\,-0.01,\\,0.04,\\,-0.06,\\,0.09]$.\n- Case B (distributed moderate imbalance, sub-threshold per node): $r = [6.0,\\,-5.5,\\,6.2,\\,-5.8,\\,0.3,\\,-0.2,\\,0.1,\\,0.0,\\,0.2,\\,-0.1,\\,0.05,\\,-0.05]$.\n- Case C (small random-like noise): $r = [0.1,\\,-0.07,\\,0.05,\\,-0.09,\\,0.08,\\,-0.04,\\,0.02,\\,-0.03,\\,0.01,\\,-0.02,\\,0.0,\\,0.03]$.\n- Case D (exact equilibrium): $r = [0.0,\\,0.0,\\,0.0,\\,0.0,\\,0.0,\\,0.0,\\,0.0,\\,0.0,\\,0.0,\\,0.0,\\,0.0,\\,0.0]$.\n- Case E (two severe localized outliers): $r = [50.0,\\,-45.0,\\,0.2,\\,-0.1,\\,0.0,\\,0.0,\\,0.0,\\,0.15,\\,-0.05,\\,0.0,\\,0.0,\\,0.0]$.\n- Case F (borderline single-node at tolerance): $r = [10.0,\\,0.1,\\,-0.1,\\,0.05,\\,-0.05,\\,0.02,\\,-0.02,\\,0.0,\\,0.0,\\,0.01,\\,-0.01,\\,0.0]$.\n- Case G (many nodes near tolerance, alternating signs): $r = [9.5,\\,-9.5,\\,9.5,\\,-9.5,\\,9.5,\\,-9.5,\\,9.5,\\,-9.5,\\,9.5,\\,-9.5,\\,9.5,\\,-9.5]$.\n\nYour program must:\n- For each case, compute $m_2$, $m_{\\infty}$, $m_{\\text{hyb1}}$, $m_{\\text{hyb2}}$ as defined above, and the four booleans $\\text{det}_2$, $\\text{det}_{\\infty}$, $\\text{det}_{\\text{hyb1}}$, $\\text{det}_{\\text{hyb2}}$.\n- Produce a single line of output containing a top-level list with one entry per test case. Each entry must be a list of eight items in the exact order:\n  $[m_2, m_{\\infty}, m_{\\text{hyb1}}, m_{\\text{hyb2}}, \\text{det}_2, \\text{det}_{\\infty}, \\text{det}_{\\text{hyb1}}, \\text{det}_{\\text{hyb2}}]$.\n- All floating-point values must be rounded to exactly $6$ decimal places.\n- The final printed line must contain no whitespace characters. For example, it must look like $[[\\dots],[\\dots],\\dots]$ with commas as separators and no spaces.\n\nThe expected outputs are dimensionless floats and booleans as specified. No physical units are required, and no angles or percentages are involved. The test suite covers a localized outlier, distributed sub-threshold imbalances, small noise, exact zero, multiple extreme outliers, a borderline threshold case, and many near-threshold entries to assess outlier sensitivity and the behavior of the proposed hybrid measures.",
            "solution": "The problem as stated is formally sound, scientifically grounded in the principles of computational solid mechanics and numerical analysis, and well-posed. All definitions, parameters, and test cases are provided with sufficient clarity and consistency to permit a unique and verifiable solution. We may therefore proceed directly to the analysis.\n\nThe objective is to compute four dimensionless convergence measures and their corresponding boolean decision flags for a suite of residual vectors $r \\in \\mathbb{R}^n$. The analysis is conducted under the following fixed parameters:\n- Vector dimension: $n = 12$.\n- Per-node tolerance parameter: $\\theta = 10$.\n- Huber function parameter: $\\delta = 1$.\n\nFrom these, we define the tolerance thresholds for the maximum norm and Euclidean norm:\n- Per-node tolerance: $\\Theta_{\\infty} = \\theta = 10$.\n- Aggregate tolerance: $\\Theta_2 = \\sqrt{n}\\,\\theta = \\sqrt{12}\\,\\theta = 2\\sqrt{3}\\,\\theta \\approx 34.641016$.\n\nThe four dimensionless measures to be calculated are:\n1.  Normalized Euclidean norm: $m_2 = \\frac{\\|r\\|_2}{\\Theta_2}$, where $\\|r\\|_2 = \\left( \\sum_{i=1}^n r_i^2 \\right)^{1/2}$. This measure is greater than $1$ if the root-mean-square of the residual components exceeds the per-node tolerance $\\theta$.\n2.  Normalized maximum norm: $m_{\\infty} = \\frac{\\|r\\|_{\\infty}}{\\Theta_{\\infty}}$, where $\\|r\\|_{\\infty} = \\max_{1 \\le i \\le n} |r_i|$. This measure is greater than $1$ if any single nodal residual exceeds the per-node tolerance $\\theta$.\n3.  Hybrid measure 1: $m_{\\text{hyb1}} = \\|r\\|_{\\text{hyb1}} = \\left( m_2^2 + m_{\\infty}^2 \\right)^{1/2}$. This measure combines the normalized $\\ell_2$ and $\\ell_{\\infty}$ criteria, flagging convergence failure if the vector $(m_2, m_{\\infty})$ lies outside the unit circle in $\\mathbb{R}^2$.\n4.  Hybrid measure 2: $m_{\\text{hyb2}} = \\|r\\|_{\\text{hyb2}} = \\max\\!\\left( \\frac{\\|r\\|_{\\infty}}{\\Theta_{\\infty}}, \\frac{\\|r\\|_{\\text{Huber}}}{\\Theta_2} \\right) = \\max(m_{\\infty}, \\frac{\\|r\\|_{\\text{Huber}}}{\\Theta_2})$. This measure uses the Huber function $\\phi_{\\delta}(x)$ to define a robust norm-like quantity $\\|r\\|_{\\text{Huber}} = \\left( \\sum_{i=1}^n \\phi_{\\delta}(r_i) \\right)^{1/2}$, with $\\phi_{\\delta}(x) = x^2$ for $|x| \\le \\delta$ and $\\phi_{\\delta}(x) = 2\\delta|x| - \\delta^2$ for $|x| > \\delta$. It triggers if either the normalized max norm exceeds $1$ or a robustly-aggregated residual exceeds the aggregate tolerance.\n\nFor each measure $m_j$, a boolean decision flag $\\text{det}_j$ is computed as $(m_j > 1)$. We will now evaluate these quantities for each test case.\n\n**Case A: Localized outlier plus small noise**\n$r = [0.1, -0.05, 0.12, -0.08, 12.0, 0.07, -0.03, 0.02, -0.01, 0.04, -0.06, 0.09]$\n$\\|r\\|_{\\infty} = 12.0$, $\\|r\\|_2 \\approx 12.0022$, $\\|r\\|_{\\text{Huber}} \\approx 4.8013$\n$m_{\\infty} = 12.0 / 10 = 1.2$\n$m_2 = 12.0022 / 34.6410 = 0.3465$\n$m_{\\text{hyb1}} = \\sqrt{1.2^2 + 0.3465^2} \\approx 1.2490$\n$m_{\\text{hyb2}} = \\max(1.2, 4.8013 / 34.6410) = 1.2$\nDecisions: $\\text{det}_{\\infty}=\\text{True}$, $\\text{det}_2=\\text{False}$, $\\text{det}_{\\text{hyb1}}=\\text{True}$, $\\text{det}_{\\text{hyb2}}=\\text{True}$.\nThe localized outlier at $r_5=12$ correctly triggers all max-norm sensitive criteria. The $\\ell_2$ norm criterion fails to detect this localized issue as the large value is \"smeared out\" over the vector's dimension.\n\n**Case B: Distributed moderate imbalance**\n$r = [6.0, -5.5, 6.2, -5.8, 0.3, -0.2, 0.1, 0.0, 0.2, -0.1, 0.05, -0.05]$\n$\\|r\\|_{\\infty} = 6.2$, $\\|r\\|_2 \\approx 11.7697$, $\\|r\\|_{\\text{Huber}} \\approx 6.5723$\n$m_{\\infty} = 6.2 / 10 = 0.62$\n$m_2 = 11.7697 / 34.6410 = 0.3400$\n$m_{\\text{hyb1}} = \\sqrt{0.62^2 + 0.3400^2} \\approx 0.7071$\n$m_{\\text{hyb2}} = \\max(0.62, 6.5723 / 34.6410) = 0.62$\nDecisions: $\\text{det}_{\\infty}=\\text{False}$, $\\text{det}_2=\\text{False}$, $\\text{det}_{\\text{hyb1}}=\\text{False}$, $\\text{det}_{\\text{hyb2}}=\\text{False}$.\nAlthough several components are moderately large, none exceed the per-node tolerance $\\theta=10$, and their aggregate value is not large enough to trigger the $\\ell_2$ criterion. All measures indicate convergence.\n\n**Case C: Small random-like noise**\n$r = [0.1, -0.07, 0.05, -0.09, 0.08, -0.04, 0.02, -0.03, 0.01, -0.02, 0.0, 0.03]$\n$\\|r\\|_{\\infty} = 0.1$, $\\|r\\|_2 \\approx 0.1918$, $\\|r\\|_{\\text{Huber}} \\approx 0.1918$ (since all $|r_i| \\le \\delta=1$)\n$m_{\\infty} = 0.1 / 10 = 0.01$\n$m_2 = 0.1918 / 34.6410 = 0.0055$\n$m_{\\text{hyb1}} = \\sqrt{0.01^2 + 0.0055^2} \\approx 0.0114$\n$m_{\\text{hyb2}} = \\max(0.01, 0.1918 / 34.6410) = 0.01$\nDecisions: $\\text{det}_{\\infty}=\\text{False}$, $\\text{det}_2=\\text{False}$, $\\text{det}_{\\text{hyb1}}=\\text{False}$, $\\text{det}_{\\text{hyb2}}=\\text{False}$.\nAs expected for a small residual, all measures are very small and indicate convergence.\n\n**Case D: Exact equilibrium**\n$r = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]$\n$\\|r\\|_{\\infty} = 0.0$, $\\|r\\|_2 = 0.0$, $\\|r\\|_{\\text{Huber}} = 0.0$\n$m_{\\infty} = 0.0$, $m_2 = 0.0$, $m_{\\text{hyb1}} = 0.0$, $m_{\\text{hyb2}} = 0.0$\nDecisions: $\\text{det}_{\\infty}=\\text{False}$, $\\text{det}_2=\\text{False}$, $\\text{det}_{\\text{hyb1}}=\\text{False}$, $\\text{det}_{\\text{hyb2}}=\\text{False}$.\nThe trivial zero vector correctly yields zero for all measures.\n\n**Case E: Two severe localized outliers**\n$r = [50.0, -45.0, 0.2, -0.1, 0.0, 0.0, 0.0, 0.15, -0.05, 0.0, 0.0, 0.0]$\n$\\|r\\|_{\\infty} = 50.0$, $\\|r\\|_2 \\approx 67.2713$, $\\|r\\|_{\\text{Huber}} \\approx 13.7840$\n$m_{\\infty} = 50.0 / 10 = 5.0$\n$m_2 = 67.2713 / 34.6410 = 1.9428$\n$m_{\\text{hyb1}} = \\sqrt{5.0^2 + 1.9428^2} \\approx 5.3638$\n$m_{\\text{hyb2}} = \\max(5.0, 13.7840 / 34.6410) = 5.0$\nDecisions: $\\text{det}_{\\infty}=\\text{True}$, $\\text{det}_2=\\text{True}$, $\\text{det}_{\\text{hyb1}}=\\text{True}$, $\\text{det}_{\\text{hyb2}}=\\text{True}$.\nThe extremely large outliers ensure that all criteria are triggered, including the $\\ell_2$ norm, which is now large enough in aggregate despite being localized.\n\n**Case F: Borderline single-node at tolerance**\n$r = [10.0, 0.1, -0.1, 0.05, -0.05, 0.02, -0.02, 0.0, 0.0, 0.01, -0.01, 0.0]$\n$\\|r\\|_{\\infty} = 10.0$, $\\|r\\|_2 \\approx 10.0016$, $\\|r\\|_{\\text{Huber}} \\approx 4.3592$\n$m_{\\infty} = 10.0 / 10 = 1.0$\n$m_2 = 10.0016 / 34.6410 = 0.2887$\n$m_{\\text{hyb1}} = \\sqrt{1.0^2 + 0.2887^2} \\approx 1.0409$\n$m_{\\text{hyb2}} = \\max(1.0, 4.3592 / 34.6410) = 1.0$\nDecisions: $\\text{det}_{\\infty}=\\text{False}$, $\\text{det}_2=\\text{False}$, $\\text{det}_{\\text{hyb1}}=\\text{True}$, $\\text{det}_{\\text{hyb2}}=\\text{False}$.\nHere, since the decision rule is strict inequality $(>1)$, the standard criteria $\\text{det}_{\\infty}$ and $\\text{det}_{\\text{hyb2}}$ do not fire. However, $\\text{det}_{\\text{hyb1}}$ does fire, because even with $m_\\infty=1$, the contribution from $m_2$ makes $m_{\\text{hyb1}} > 1$. This shows its sensitivity near the boundary of the convergence region.\n\n**Case G: Many nodes near tolerance**\n$r = [9.5, -9.5, 9.5, -9.5, 9.5, -9.5, 9.5, -9.5, 9.5, -9.5, 9.5, -9.5]$\n$\\|r\\|_{\\infty} = 9.5$, $\\|r\\|_2 \\approx 32.9090$, $\\|r\\|_{\\text{Huber}} = \\sqrt{216} \\approx 14.6969$\n$m_{\\infty} = 9.5 / 10 = 0.95$\n$m_2 = 32.9090 / 34.6410 = 0.95$\n$m_{\\text{hyb1}} = \\sqrt{0.95^2 + 0.95^2} \\approx 1.3435$\n$m_{\\text{hyb2}} = \\max(0.95, 14.6969 / 34.6410) = 0.95$\nDecisions: $\\text{det}_{\\infty}=\\text{False}$, $\\text{det}_2=\\text{False}$, $\\text{det}_{\\text{hyb1}}=\\text{True}$, $\\text{det}_{\\text{hyb2}}=\\text{False}$.\nThis case is illustrative. Both standard criteria indicate convergence because no single node exceeds tolerance and the RMS value is also just below tolerance. However, the system is clearly in a poor state, being close to the tolerance limit at every degree of freedom. The $\\text{hyb1}$ measure correctly identifies this problematic state by combining the information from both norms, demonstrating its utility.\n\nIn summary, the test suite effectively probes the distinct behaviors of the four convergence criteria, highlighting the sensitivity of $\\| \\cdot \\|_{\\infty}$ to outliers and the aggregate nature of $\\| \\cdot \\|_2$. The hybrid measures showcase different ways to balance these behaviors, with $\\| \\cdot \\|_{\\text{hyb1}}$ proving sensitive to both localized and distributed borderline cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes four convergence measures and decision flags for a suite of residual vectors.\n    \"\"\"\n    \n    def format_item(item):\n        \"\"\"Formats an item for the final output string.\"\"\"\n        if isinstance(item, (float, np.floating)):\n            return f\"{item:.6f}\"\n        elif isinstance(item, (bool, np.bool_)):\n            return str(item)\n        else:\n            return str(item)\n\n    # Define parameters\n    theta = 10.0\n    delta = 1.0\n\n    # Define the test suite of residual vectors\n    test_cases = {\n        'A': [0.1, -0.05, 0.12, -0.08, 12.0, 0.07, -0.03, 0.02, -0.01, 0.04, -0.06, 0.09],\n        'B': [6.0, -5.5, 6.2, -5.8, 0.3, -0.2, 0.1, 0.0, 0.2, -0.1, 0.05, -0.05],\n        'C': [0.1, -0.07, 0.05, -0.09, 0.08, -0.04, 0.02, -0.03, 0.01, -0.02, 0.0, 0.03],\n        'D': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n        'E': [50.0, -45.0, 0.2, -0.1, 0.0, 0.0, 0.0, 0.15, -0.05, 0.0, 0.0, 0.0],\n        'F': [10.0, 0.1, -0.1, 0.05, -0.05, 0.02, -0.02, 0.0, 0.0, 0.01, -0.01, 0.0],\n        'G': [9.5, -9.5, 9.5, -9.5, 9.5, -9.5, 9.5, -9.5, 9.5, -9.5, 9.5, -9.5],\n    }\n    \n    # Order of cases as specified in problem\n    case_order = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n\n    all_results = []\n    \n    for case_key in case_order:\n        r_list = test_cases[case_key]\n        r = np.array(r_list, dtype=np.float64)\n        n = len(r)\n\n        # Calculate tolerances\n        Theta_inf = theta\n        Theta_2 = np.sqrt(n) * theta\n\n        # Calculate norms\n        norm_2 = np.linalg.norm(r, 2)\n        norm_inf = np.linalg.norm(r, np.inf)\n\n        # Calculate Huber-based norm\n        r_abs = np.abs(r)\n        phi_vals = np.where(r_abs <= delta, r_abs**2, 2 * delta * r_abs - delta**2)\n        norm_huber = np.sqrt(np.sum(phi_vals))\n\n        # Calculate dimensionless measures\n        m_2 = norm_2 / Theta_2\n        m_inf = norm_inf / Theta_inf\n        m_hyb1 = np.sqrt(m_2**2 + m_inf**2)\n        m_hyb2 = np.maximum(m_inf, norm_huber / Theta_2)\n        \n        # Calculate boolean decision flags\n        det_2 = m_2 > 1.0\n        det_inf = m_inf > 1.0\n        det_hyb1 = m_hyb1 > 1.0\n        det_hyb2 = m_hyb2 > 1.0\n\n        case_result = [m_2, m_inf, m_hyb1, m_hyb2, det_2, det_inf, det_hyb1, det_hyb2]\n        all_results.append(case_result)\n        \n    # Format final output string\n    final_case_strings = []\n    for case_result in all_results:\n        formatted_items = [format_item(item) for item in case_result]\n        final_case_strings.append(f'[{\",\".join(formatted_items)}]')\n\n    # Print in the exact required format with no whitespace\n    print(f'[{\",\".join(final_case_strings)}]')\n\nsolve()\n```"
        },
        {
            "introduction": "A small residual norm is a necessary condition for convergence, but is it sufficient? This final practice  confronts a critical challenge in robust solver design: the risk of \"false convergence.\" By implementing a nonlinear solver, you will discover scenarios where relying solely on a residual check is dangerously misleading. This exercise makes a compelling case for using a dual criterion, which monitors both the force imbalance (residual) and the solution increment (update), to reliably distinguish true equilibrium from numerical stagnation.",
            "id": "3595519",
            "problem": "Consider a one-dimensional, prismatic, nonlinear elastic bar of length $L$, cross-sectional area $A$, and material characterized by a constitutive law that relates axial stress $\\sigma$ to axial strain $\\varepsilon$ by $\\sigma(\\varepsilon) = E \\,\\varepsilon + \\alpha \\,\\varepsilon^3$, where $E$ is the Young’s modulus and $\\alpha$ is a scalar nonlinearity parameter. Let the bar be fixed at $x=0$ and subject to an externally applied axial force $F$ at $x=L$. Assume small strains with the standard kinematics $\\varepsilon = u/L$, where $u$ is the axial displacement at the free end.\n\nThe static equilibrium condition is defined by the residual of forces\n$$\nr(u) = F - f_{\\text{int}}(u),\n$$\nwhere the internal force at the free end is given by $f_{\\text{int}}(u) = A\\,\\sigma(\\varepsilon(u))$. The goal is to solve for the displacement $u$ that satisfies $r(u) = 0$.\n\nStarting only from these foundations of continuum mechanics and equilibrium, implement a Newton-type iteration to find $u$ by linearizing the residual about the current iterate $u_k$ and updating the displacement using the consistent linearization of the internal force. Let the tangent stiffness be the derivative of the internal force with respect to displacement, derived from the given constitutive law. To examine realistic algorithmic behavior in computational solid mechanics, include the following generalized controls in the update law:\n- A constant scalar damping factor $\\lambda$ multiplying the update at each iteration.\n- A penalty stiffness $\\kappa$ added to the tangent stiffness to emulate stiff constraints such as contact or penalty enforcement.\n- A tangent scaling factor $s$ multiplying the consistent tangent to emulate quasi-Newton or inconsistent tangents.\n\nThe residual-based convergence criterion is defined by the Euclidean norm condition $|r| < \\tau$, and the update-based criterion is defined by the Euclidean norm condition $|\\Delta u| < \\tau_{\\Delta}$. These norms are scalar absolute values in this single-degree-of-freedom setting. To prevent false stagnation, enforce the dual convergence criteria simultaneously: accept convergence at iteration $k$ only when both $|r_k| < \\tau$ (expressed in $\\mathrm{N}$) and $|\\Delta u_k| < \\tau_{\\Delta}$ (expressed in $\\mathrm{m}$). Additionally, at each iteration, record whether either single criterion would have declared convergence incorrectly if used alone, thereby revealing cases where one quantity shrinks while the other stalls:\n- Residual-only would declare convergence if $|r_k| < \\tau$ but $|\\Delta u_k| \\ge \\tau_{\\Delta}$.\n- Update-only would declare convergence if $|\\Delta u_k| < \\tau_{\\Delta}$ but $|r_k| \\ge \\tau$.\n\nYour program must implement the iteration starting from the initial guess $u_0 = 0$ and proceed for up to a specified maximum number of iterations. At each iteration, compute the residual $r(u_k)$, the consistent tangent stiffness from the constitutive law, form the effective tangent $K_{\\text{eff}} = s\\,K_t(u_k) + \\kappa$, compute the update $\\Delta u_k$ using this effective tangent together with the damping factor $\\lambda$, and update $u_{k+1} = u_k + \\Delta u_k$. After each iteration $k$, assess the dual criteria and the single-criterion misclassification flags as described above. If the dual criteria are satisfied, terminate and report convergence; otherwise continue until the iteration limit is reached. Report the total number of iterations performed, the final residual norm $|r|$ in $\\mathrm{N}$, and the final update norm $|\\Delta u|$ in $\\mathrm{m}$, along with booleans indicating dual convergence and whether residual-only or update-only would have (incorrectly) declared convergence at any iteration before dual convergence.\n\nFundamental base to use:\n- Kinematics: $\\varepsilon = u/L$.\n- Constitutive law: $\\sigma(\\varepsilon) = E\\,\\varepsilon + \\alpha\\,\\varepsilon^3$.\n- Internal force: $f_{\\text{int}}(u) = A \\,\\sigma(\\varepsilon(u))$.\n- Equilibrium residual: $r(u) = F - f_{\\text{int}}(u)$.\n- Consistent tangent stiffness: $K_t(u) = \\dfrac{\\mathrm{d}f_{\\text{int}}}{\\mathrm{d}u}$ derived from the above.\n\nTest suite:\nImplement the solver and run the following four cases to explore different algorithmic regimes. Use all quantities and comparisons in the specified units, and express any numerical outputs having physical units as pure numbers in those units (no unit strings), following the output format below.\n\n- Case $1$ (well-conditioned, undamped Newton, happy path):\n  - $E = 2.00\\times 10^{11}\\,\\mathrm{Pa}$, $\\alpha = 1.00\\times 10^{12}\\,\\mathrm{Pa}$, $L = 1.0\\,\\mathrm{m}$, $A = 1.0\\,\\mathrm{m}^2$, $F = 1.00\\times 10^{8}\\,\\mathrm{N}$.\n  - $\\lambda = 1.0$, $\\kappa = 0.0\\,\\mathrm{N/m}$, $s = 1.0$.\n  - Tolerances: $\\tau = 1.0\\times 10^{-2}\\,\\mathrm{N}$, $\\tau_{\\Delta} = 1.0\\times 10^{-12}\\,\\mathrm{m}$.\n  - Maximum iterations: $25$.\n\n- Case $2$ (penalty-stiff tangent, update stalls while residual remains large; false stagnation if using update-only):\n  - $E = 2.00\\times 10^{11}\\,\\mathrm{Pa}$, $\\alpha = 1.00\\times 10^{12}\\,\\mathrm{Pa}$, $L = 1.0\\,\\mathrm{m}$, $A = 1.0\\,\\mathrm{m}^2$, $F = 1.00\\times 10^{8}\\,\\mathrm{N}$.\n  - $\\lambda = 1.0$, $\\kappa = 1.00\\times 10^{13}\\,\\mathrm{N/m}$, $s = 1.0$.\n  - Tolerances: $\\tau = 1.0\\times 10^{5}\\,\\mathrm{N}$, $\\tau_{\\Delta} = 2.0\\times 10^{-5}\\,\\mathrm{m}$.\n  - Maximum iterations: $20$.\n\n- Case $3$ (heavy damping of updates, residual stalls; false stagnation if using update-only):\n  - $E = 2.00\\times 10^{11}\\,\\mathrm{Pa}$, $\\alpha = 1.00\\times 10^{12}\\,\\mathrm{Pa}$, $L = 1.0\\,\\mathrm{m}$, $A = 1.0\\,\\mathrm{m}^2$, $F = 1.00\\times 10^{8}\\,\\mathrm{N}$.\n  - $\\lambda = 1.0\\times 10^{-6}$, $\\kappa = 0.0\\,\\mathrm{N/m}$, $s = 1.0$.\n  - Tolerances: $\\tau = 1.0\\times 10^{4}\\,\\mathrm{N}$, $\\tau_{\\Delta} = 1.0\\times 10^{-9}\\,\\mathrm{m}$.\n  - Maximum iterations: $20$.\n\n- Case $4$ (excessively soft effective tangent, residual initially tiny but update large; false acceptance if using residual-only):\n  - $E = 2.00\\times 10^{11}\\,\\mathrm{Pa}$, $\\alpha = 1.00\\times 10^{12}\\,\\mathrm{Pa}$, $L = 1.0\\,\\mathrm{m}$, $A = 1.0\\,\\mathrm{m}^2$, $F = 5.00\\times 10^{-1}\\,\\mathrm{N}$.\n  - $\\lambda = 1.0$, $\\kappa = 0.0\\,\\mathrm{N/m}$, $s = 1.0\\times 10^{-8}$.\n  - Tolerances: $\\tau = 1.0\\,\\mathrm{N}$, $\\tau_{\\Delta} = 1.0\\times 10^{-6}\\,\\mathrm{m}$.\n  - Maximum iterations: $5$.\n\nRequired final output format:\nYour program should produce a single line of output containing the results for the four cases as a comma-separated list enclosed in square brackets, where each case’s result is a list of six values:\n$[\\text{dual\\_converged}, \\text{iterations}, |r|, |\\Delta u|, \\text{residual\\_only\\_flag}, \\text{update\\_only\\_flag}]$.\nFor example, the overall output should look like\n$[[\\dots],[\\dots],[\\dots],[\\dots]]$,\nwith $|r|$ in $\\mathrm{N}$ and $|\\Delta u|$ in $\\mathrm{m}$ represented as decimal numbers without unit strings. All booleans must be literal $\\mathrm{True}$ or $\\mathrm{False}$, and the iteration count must be an integer.",
            "solution": "The problem requires the implementation of a modified Newton-Raphson algorithm to solve for the static equilibrium displacement of a one-dimensional nonlinear elastic bar. The solution is derived by first establishing the governing equations from the principles of continuum mechanics and then constructing the numerical iteration scheme with the specified controls.\n\nFirst, we formalize the relationship between displacement, internal force, and the external load. The bar has length $L$, cross-sectional area $A$, and is subject to an external force $F$ at its free end. The displacement at this end is denoted by $u$.\n\nThe axial strain $\\varepsilon$ is defined under the assumption of small deformations as:\n$$\n\\varepsilon(u) = \\frac{u}{L}\n$$\nThe material's nonlinear constitutive law relates the axial stress $\\sigma$ to the strain $\\varepsilon$:\n$$\n\\sigma(\\varepsilon) = E\\,\\varepsilon + \\alpha\\,\\varepsilon^3\n$$\nwhere $E$ is the Young’s modulus and $\\alpha$ is the nonlinearity parameter.\n\nThe internal force $f_{\\text{int}}$ at the free end is the stress integrated over the cross-sectional area, which for a uniform stress field is simply $f_{\\text{int}} = A\\,\\sigma$. Substituting the constitutive and kinematic relations yields the internal force as a function of the displacement $u$:\n$$\nf_{\\text{int}}(u) = A\\,\\sigma(\\varepsilon(u)) = A \\left( E\\left(\\frac{u}{L}\\right) + \\alpha\\left(\\frac{u}{L}\\right)^3 \\right)\n$$\n$$\nf_{\\text{int}}(u) = \\left(\\frac{AE}{L}\\right)u + \\left(\\frac{A\\alpha}{L^3}\\right)u^3\n$$\nStatic equilibrium requires that the internal forces balance the external forces. The residual force $r(u)$ represents this imbalance:\n$$\nr(u) = F - f_{\\text{int}}(u) = F - \\left[ \\left(\\frac{AE}{L}\\right)u + \\left(\\frac{A\\alpha}{L^3}\\right)u^3 \\right]\n$$\nThe goal is to find the displacement $u$ that solves the nonlinear equation $r(u) = 0$.\n\nThe Newton-Raphson method is an iterative procedure for finding roots of a function. It begins with an initial guess $u_0$ and generates a sequence of improved estimates $u_1, u_2, \\dots$. The update from iterate $u_k$ to $u_{k+1}$ is found by linearizing the residual function $r(u)$ around $u_k$:\n$$\nr(u_k + \\Delta u_k) \\approx r(u_k) + \\frac{\\mathrm{d}r}{\\mathrm{d}u}\\bigg|_{u_k} \\Delta u_k\n$$\nSetting the linearized residual to zero, $r(u_k + \\Delta u_k) = 0$, gives the standard Newton update equation:\n$$\n\\frac{\\mathrm{d}r}{\\mathrm{d}u}\\bigg|_{u_k} \\Delta u_k = -r(u_k)\n$$\nThe derivative of the residual is related to the tangent stiffness $K_t(u) = \\frac{\\mathrm{d}f_{\\text{int}}}{\\mathrm{d}u}$. Since $F$ is a constant, $\\frac{\\mathrm{d}r}{\\mathrm{d}u} = -\\frac{\\mathrm{d}f_{\\text{int}}}{\\mathrm{d}u} = -K_t(u)$. The equation becomes:\n$$\n-K_t(u_k) \\Delta u_k = -r(u_k) \\implies K_t(u_k) \\Delta u_k = r(u_k)\n$$\nThe consistent tangent stiffness $K_t(u)$ is derived by differentiating the internal force expression with respect to $u$:\n$$\nK_t(u) = \\frac{\\mathrm{d}f_{\\text{int}}}{\\mathrm{d}u} = \\frac{\\mathrm{d}}{\\mathrm{d}u} \\left[ \\left(\\frac{AE}{L}\\right)u + \\left(\\frac{A\\alpha}{L^3}\\right)u^3 \\right] = \\frac{AE}{L} + \\frac{3A\\alpha}{L^3}u^2\n$$\nThe problem introduces modifications to this standard procedure. The tangent stiffness is generalized to an effective stiffness $K_{\\text{eff}}$ by introducing a scaling factor $s$ and a penalty stiffness $\\kappa$:\n$$\nK_{\\text{eff}}(u_k) = s\\,K_t(u_k) + \\kappa\n$$\nThe displacement update $\\Delta u_k$ is computed using this effective stiffness and then scaled by a damping factor $\\lambda$:\n$$\n\\Delta u_{k, \\text{raw}} = \\frac{r(u_k)}{K_{\\text{eff}}(u_k)}\n$$\n$$\n\\Delta u_k = \\lambda \\cdot \\Delta u_{k, \\text{raw}} = \\frac{\\lambda \\, r(u_k)}{s\\,K_t(u_k) + \\kappa}\n$$\nThe displacement is then updated for the next iteration:\n$$\nu_{k+1} = u_k + \\Delta u_k\n$$\nThe iterative process begins with an initial guess $u_0=0$ and continues until convergence is achieved or a maximum number of iterations is reached.\n\nConvergence is assessed at each iteration $k$ using a dual criterion that simultaneously checks the norm of the residual and the norm of the update. In this one-dimensional context, these norms are the absolute values $|r(u_k)|$ and $|\\Delta u_k|$. Convergence is declared if and only if both conditions are met:\n$$\n|r(u_k)| < \\tau \\quad \\text{AND} \\quad |\\Delta u_k| < \\tau_{\\Delta}\n$$\nwhere $\\tau$ is the residual force tolerance (in $\\mathrm{N}$) and $\\tau_{\\Delta}$ is the displacement update tolerance (in $\\mathrm{m}$).\n\nTo analyze potential failure modes of single-criterion convergence, two boolean flags are maintained throughout the iteration. These flags are set if, at any iteration prior to achieving dual convergence, one criterion is met while the other is not:\n- `residual_only_flag` is set to `True` if $|r(u_k)| < \\tau$ and $|\\Delta u_k| \\ge \\tau_{\\Delta}$. This identifies a state where the force imbalance is small, but the solution is still changing significantly, risking a false declaration of convergence.\n- `update_only_flag` is set to `True` if $|\\Delta u_k| < \\tau_{\\Delta}$ and $|r(u_k)| \\ge \\tau$. This identifies a state where the solution update is negligible, but the force imbalance remains large, indicating solver stagnation rather than true convergence.\n\nThe complete algorithm proceeds as follows for each test case:\n1. Initialize displacement $u=0$, iteration count $k=0$, and boolean flags `dual_converged`, `residual_only_flag`, `update_only_flag` to `False`.\n2. Loop for a maximum number of iterations:\n   a. Compute the residual force $r_k = r(u_k)$ and its norm $|r_k|$.\n   b. Compute the consistent tangent stiffness $K_{t,k} = K_t(u_k)$.\n   c. Form the effective tangent stiffness $K_{\\text{eff},k} = s\\,K_{t,k} + \\kappa$.\n   d. Compute the displacement update $\\Delta u_k = \\lambda \\, r_k / K_{\\text{eff},k}$ and its norm $|\\Delta u_k|$.\n   e. Check for dual convergence: if $|r_k| < \\tau$ and $|\\Delta u_k| < \\tau_{\\Delta}$, set `dual_converged` to `True` and terminate the loop.\n   f. If not converged, update the single-criterion flags:\n      - If $|r_k| < \\tau$ and $|\\Delta u_k| \\ge \\tau_{\\Delta}$, set `residual_only_flag` to `True`.\n      - If $|\\Delta u_k| < \\tau_{\\Delta}$ and $|r_k| \\ge \\tau$, set `update_only_flag` to `True`.\n   g. Update the displacement: $u_{k+1} = u_k + \\Delta u_k$.\n   h. Increment the iteration count.\n3. Upon termination, report the final state: whether dual convergence was achieved, the total number of iterations, the final residual and update norms, and the status of the two boolean flags. This procedure is implemented for the provided test suite.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test cases and print the results.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: well-conditioned, undamped Newton, happy path\n        {\n            \"E\": 2.00e11, \"alpha\": 1.00e12, \"L\": 1.0, \"A\": 1.0, \"F\": 1.00e8,\n            \"lambda_damp\": 1.0, \"kappa\": 0.0, \"s\": 1.0,\n            \"tau\": 1.0e-2, \"tau_delta\": 1.0e-12, \"max_iter\": 25\n        },\n        # Case 2: penalty-stiff tangent, update stalls\n        {\n            \"E\": 2.00e11, \"alpha\": 1.00e12, \"L\": 1.0, \"A\": 1.0, \"F\": 1.00e8,\n            \"lambda_damp\": 1.0, \"kappa\": 1.00e13, \"s\": 1.0,\n            \"tau\": 1.0e5, \"tau_delta\": 2.0e-5, \"max_iter\": 20\n        },\n        # Case 3: heavy damping, update stalls\n        {\n            \"E\": 2.00e11, \"alpha\": 1.00e12, \"L\": 1.0, \"A\": 1.0, \"F\": 1.00e8,\n            \"lambda_damp\": 1.0e-6, \"kappa\": 0.0, \"s\": 1.0,\n            \"tau\": 1.0e4, \"tau_delta\": 1.0e-9, \"max_iter\": 20\n        },\n        # Case 4: excessively soft tangent, residual-only false acceptance\n        {\n            \"E\": 2.00e11, \"alpha\": 1.00e12, \"L\": 1.0, \"A\": 1.0, \"F\": 5.00e-1,\n            \"lambda_damp\": 1.0, \"kappa\": 0.0, \"s\": 1.0e-8,\n            \"tau\": 1.0, \"tau_delta\": 1.0e-6, \"max_iter\": 5\n        },\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_nonlinear_solver(**params)\n        results.append(result)\n\n    # Format the final output string exactly as required.\n    # str() on a list produces the required '[]' format.\n    formatted_results = [str(res) for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef run_nonlinear_solver(E, alpha, L, A, F, lambda_damp, kappa, s, tau, tau_delta, max_iter):\n    \"\"\"\n    Implements the modified Newton-Raphson iteration for a single test case.\n    \"\"\"\n    u = 0.0\n    \n    dual_converged = False\n    residual_only_flag = False\n    update_only_flag = False\n    \n    res_norm = np.inf\n    delta_u_norm = np.inf\n\n    # Constants derived from problem parameters\n    const_linear_stiffness = A * E / L\n    const_nonlinear_stiffness = A * alpha / L**3\n\n    for k in range(max_iter):\n        # Calculate internal force and residual at current displacement u\n        f_int = const_linear_stiffness * u + const_nonlinear_stiffness * u**3\n        res = F - f_int\n        res_norm = abs(res)\n        \n        # Calculate consistent tangent stiffness\n        K_t = const_linear_stiffness + 3.0 * const_nonlinear_stiffness * u**2\n        \n        # Form effective tangent stiffness\n        K_eff = s * K_t + kappa\n        \n        # Handle potential division by zero, though not expected with given parameters\n        if K_eff == 0:\n            # Singular stiffness matrix, cannot proceed\n            break\n            \n        # Compute displacement update\n        delta_u = lambda_damp * res / K_eff\n        delta_u_norm = abs(delta_u)\n        \n        # Check convergence criteria\n        res_conv_met = res_norm < tau\n        upd_conv_met = delta_u_norm < tau_delta\n        \n        if res_conv_met and upd_conv_met:\n            dual_converged = True\n            # Return results upon convergence, iterations performed is k+1\n            return [dual_converged, k + 1, res_norm, delta_u_norm, residual_only_flag, update_only_flag]\n\n        # If not dual-converged, check for single-criterion satisfaction to set flags\n        if res_conv_met and not upd_conv_met:\n            residual_only_flag = True\n        \n        if upd_conv_met and not res_conv_met:\n            update_only_flag = True\n            \n        # Update displacement for the next iteration\n        u += delta_u\n\n    # If the loop completes without convergence, return the state after max_iter iterations\n    return [dual_converged, max_iter, res_norm, delta_u_norm, residual_only_flag, update_only_flag]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}