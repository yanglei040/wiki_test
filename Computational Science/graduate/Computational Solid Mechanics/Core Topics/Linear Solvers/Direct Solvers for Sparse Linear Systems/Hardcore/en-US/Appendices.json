{
    "hands_on_practices": [
        {
            "introduction": "This exercise provides a foundational understanding of how matrix structure and fill-in are direct consequences of node ordering in the finite element method. By manually tracing the Cholesky factorization on a simple 1D problem, you will see why a \"natural\" ordering can be optimal, producing no fill-in, while a simple permutation can degrade performance by creating new non-zero entries. This hands-on analysis builds intuition for the graph-based algorithms used in modern sparse solvers .",
            "id": "3557846",
            "problem": "Consider a uniform one-dimensional bar discretized into $n=8$ linear finite elements with nodes labeled under the natural left-to-right ordering $1,2,\\dots,8$. After enforcing essential boundary conditions at the two ends, the assembled global stiffness matrix $K \\in \\mathbb{R}^{8 \\times 8}$ is real symmetric positive definite (SPD) and has the sparsity graph of a path graph (a $1$D chain), that is, nonzero off-diagonal entries occur only between adjacent nodes in the chain. Treat $K$ abstractly via its sparsity pattern; specific numerical values of its entries are not required.\n\nUsing only first principles about finite element assembly for a $1$D bar, the definition of the sparsity graph of $K$, and the graph-theoretic interpretation of fill-in under Gaussian elimination specialized to Cholesky factorization (symmetric elimination that factors $K=L L^{\\top}$), do the following:\n\n- Determine, under the natural ordering $1,2,\\dots,8$, the upper bandwidth of $K$ and the profile of $K$ viewed row-wise from the lower triangle. Justify both quantities directly from the nonzero pattern that results from assembling nearest-neighbor couplings on the chain.\n\n- Explain, by reasoning on the elimination graph, why the Cholesky factorization of $K$ under the natural ordering produces no fill-in beyond the original nonzeros.\n\n- Now consider the perturbed ordering given by the permutation $p=(1,3,5,7,2,4,6,8)$. Let $P$ be the permutation matrix that maps the natural ordering to $p$, and consider the Cholesky factorization of the permuted matrix $\\tilde{K}=P^{\\top} K P$. Using the graph-fill rule for symmetric elimination (eliminating a node makes its later neighbors a clique), determine the exact number of strictly lower-triangular fill-in entries that appear in the Cholesky factor of $\\tilde{K}$ which were not present in the strictly lower triangle of $\\tilde{K}$ prior to factorization.\n\nProvide complete reasoning for each step. The final reported quantity must be only the integer number of strictly lower-triangular fill-in entries for the perturbed ordering $p$, with no units and no additional text. No rounding is required; report the exact integer.",
            "solution": "The problem is found to be valid as it is scientifically grounded in the principles of the Finite Element Method and numerical linear algebra, is well-posed with a clear objective, and is free of contradictions or ambiguities.\n\nThis problem addresses the sparsity pattern of a global stiffness matrix $K$ for a one-dimensional bar and the concept of fill-in during its Cholesky factorization under different node orderings.\n\nFirst, we analyze the structure of the matrix $K$ under the natural ordering of nodes $1, 2, \\dots, 8$. The problem states the bar is discretized into $n=8$ linear finite elements. A linear element connects two adjacent nodes. For the natural numbering, element $e$ connects node $e$ and node $e+1$. The global stiffness matrix $K$ is assembled from element stiffness matrices. An entry $K_{ij}$ is non-zero if and only if nodes $i$ and $j$ belong to the same element. In a $1$D chain, node $i$ is connected to node $i-1$ (for $i>1$) and node $i+1$ (for $i<8$). Therefore, $K_{ij}$ is non-zero only if $|i-j| \\le 1$. This structure defines a symmetric tridiagonal matrix.\n\n- **Upper Bandwidth and Profile of $K$ (Natural Ordering)**\n\nThe upper bandwidth of a matrix $A$ is defined as $\\max \\{j-i \\mid A_{ij} \\neq 0\\}$. For the tridiagonal matrix $K$, the non-zero entries are on the main diagonal ($j=i$), the first super-diagonal ($j=i+1$), and the first sub-diagonal ($j=i-1$). The maximum difference $j-i$ for a non-zero entry is $1$. Therefore, the upper bandwidth of $K$ is $1$.\n\nThe profile of a symmetric matrix, for the purpose of skyline storage, is determined by the first non-zero entry in each row when scanning from the left. For the lower triangle of $K$, we consider for each row $i$ the minimum column index $j \\le i$ such that $K_{ij} \\neq 0$. For row $i=1$, the only non-zero is the diagonal entry $K_{11}$, so the first non-zero is at column $j=1$. For any row $i \\in \\{2, 3, \\dots, 8\\}$, the non-zero entries in the lower triangle and on the diagonal are $K_{ii}$ and $K_{i, i-1}$. The first non-zero entry is at column $j=i-1$. The profile thus consists of the diagonal entries $K_{ii}$ for $i=1, \\dots, 8$ and the sub-diagonal entries $K_{i,i-1}$ for $i=2, \\dots, 8$.\n\n- **Fill-in for $K$ under Natural Ordering**\n\nThe process of Cholesky factorization $K = L L^{\\top}$ can be interpreted using elimination on the graph associated with $K$. The graph $G(K)$ has vertices corresponding to the nodes $\\{1, 2, \\dots, 8\\}$ and an edge $(i, j)$ if $K_{ij} \\neq 0$ for $i \\neq j$. For our tridiagonal matrix, $G(K)$ is a path graph: $1-2-3-4-5-6-7-8$.\n\nSymmetric elimination of a variable $k$ corresponds to removing node $k$ from the graph and making all of its neighbors (that are yet to be eliminated) a clique, i.e., adding edges between all pairs of them. These new edges represent fill-in. We eliminate the nodes in the natural order $1, 2, \\dots, 8$.\n\n1.  Eliminate node $1$: Its only neighbor is node $2$. A set with one node is trivially a clique, so no edges are added.\n2.  Eliminate node $2$: In the remaining graph, its neighbors are node $1$ (already eliminated) and node $3$. The only neighbor yet to be eliminated is node $3$. No new edges can be formed.\n3.  In general, when we eliminate node $k$ (for $k  8$), its neighbors in the original graph are $k-1$ and $k+1$. Since all nodes $1, \\dots, k-1$ have already been eliminated, the only neighbor of $k$ in the active graph is $k+1$. No clique can be formed from a single neighbor, so no edges are added.\n\nThis process continues until the end. Since no new edges are added to the graph at any step, the Cholesky factorization of $K$ under the natural ordering produces zero fill-in. The structure of the factor $L$ is identical to the structure of the lower triangle of $K$.\n\n- **Fill-in for $\\tilde{K}$ under Perturbed Ordering**\n\nNow, we consider the perturbed ordering $p=(1,3,5,7,2,4,6,8)$. We analyze the fill-in by simulating the elimination process on the original path graph $G(K)$ using this new node order. A fill-in entry corresponds to a new edge added to the graph that was not present initially. The number of strictly lower-triangular fill-in entries is equal to the number of such new edges.\n\nThe initial graph $G_0$ is the path $1-2-3-4-5-6-7-8$.\n\n1.  **Eliminate node $1$**: Neighbors are $\\{2\\}$. No fill-in. The graph remains $G_0$.\n2.  **Eliminate node $3$**: Neighbors are $\\{2, 4\\}$. These nodes are not yet eliminated. They must be made a clique. We add an edge $(2, 4)$. This edge is not in $G_0$, so it is a fill-in.\n    - **Fill-in edges: $\\{(2,4)\\}$**.\n3.  **Eliminate node $5$**: Neighbors are $\\{4, 6\\}$. These are not yet eliminated. We add an edge $(4, 6)$. This is a fill-in.\n    - **Fill-in edges: $\\{(2,4), (4,6)\\}$**.\n4.  **Eliminate node $7$**: Neighbors are $\\{6, 8\\}$. These are not yet eliminated. We add an edge $(6, 8)$. This is a fill-in.\n    - **Fill-in edges: $\\{(2,4), (4,6), (6,8)\\}$**.\n\nAt this point, the odd-indexed nodes have been eliminated. The current graph has the original edges (minus those incident to eliminated nodes) plus the fill-in edges. The active nodes are $\\{2,4,6,8\\}$, and the edges between them are $(2,4)$, $(4,6)$, and $(6,8)$. The subgraph on the active nodes is now a path $2-4-6-8$. The remaining elimination order is $(2,4,6,8)$.\n\n5.  **Eliminate node $2$**: In the current graph, its only neighbor yet to be eliminated is node $4$. No clique formation from a single node. No new fill-in.\n6.  **Eliminate node $4$**: Its only neighbor yet to be eliminated is node $6$. No new fill-in.\n7.  **Eliminate node $6$**: Its only neighbor yet to be eliminated is node $8$. No new fill-in.\n8.  **Eliminate node $8$**: This is the last node.\n\nThe elimination process generated new edges that were not in the original path graph. These fill-in edges are $(2,4)$, $(4,6)$, and $(6,8)$. Each new edge $(i, j)$ with $i  j$ corresponds to a fill-in entry in the strictly lower triangle of the Cholesky factor of the permuted matrix $\\tilde{K}$ (specifically, at position $(j,i)$ in the factor corresponding to the permuted matrix, or at position $(p^{-1}(j), p^{-1}(i))$ in the factor of $\\tilde{K}$ itself if we label rows/columns $1$ to $8$). The question asks for the number of these entries. The number of such edges is $3$.\n\nTherefore, the total number of strictly lower-triangular fill-in entries is $3$.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "While the previous practice visualized fill-in, this exercise quantifies its computational cost in a more realistic two-dimensional setting. You will derive the asymptotic complexity for a banded Cholesky solver, a common result of using an intuitive but inefficient lexicographical ordering. This analysis  highlights why such orderings are prohibitive for large-scale problems and provides a powerful motivation for the development of advanced ordering algorithms like nested dissection.",
            "id": "3309453",
            "problem": "Consider the symmetric positive definite linear system arising from a finite-difference discretization of the two-dimensional Poisson equation on a square domain with homogeneous Dirichlet boundary conditions. Let the grid have $n$ interior points per side, so the total number of unknowns is $N=n^2$. Suppose the unknowns are ordered lexicographically by rows, resulting in a sparse matrix with a banded structure whose semi-bandwidth $w$ equals the maximum index distance from the diagonal at which nonzero entries occur. For the standard five-point stencil on the $n \\times n$ grid with lexicographic ordering, one has $w \\sim n$.\n\nStarting from the definition of the Cholesky factorization for symmetric positive definite matrices and the property that banded matrices retain their banded structure under Cholesky, analyze the operation count of a banded Cholesky factorization: derive the leading-order number of floating-point operations in terms of $N$ and $w$ by summing the per-column contributions, and derive the leading-order memory (measured as the total number of stored nonzero entries in the factor) in terms of $N$ and $w$ by summing the nonzeros contributed per column. Then specialize your expressions using $N=n^2$ and $w \\sim n$ to obtain leading-order expressions in $N$ only. Briefly explain why these asymptotics demonstrate inefficiency relative to nested dissection (ND) ordering in two dimensions.\n\nExpress your final result as a two-entry row matrix containing, in order, the leading-order flop count and the leading-order memory as analytic expressions in $N$ only. No rounding is needed, and no physical units are required.",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded, well-posed, objective, and contains sufficient information for a rigorous analysis. We may proceed with the solution.\n\nThe problem requires an analysis of the computational complexity (operation count and memory) for a banded Cholesky factorization of a matrix arising from a finite-difference discretization of the two-dimensional Poisson equation.\n\nLet $A$ be an $N \\times N$ symmetric positive definite (SPD) matrix with a semi-bandwidth of $w$. By definition, this implies that $A_{ij} = 0$ for all $i, j$ such that $|i - j|  w$. The Cholesky factorization of $A$ is given by $A = LL^T$, where $L$ is a lower triangular matrix. A fundamental theorem of numerical linear algebra states that for a banded matrix, its Cholesky factor $L$ preserves the band structure. Specifically, $L$ will also have a semi-bandwidth of $w$, meaning $L_{ij} = 0$ for $i - j  w$. This absence of \"fill-in\" outside the band is crucial for the efficiency of the factorization.\n\nWe will now derive the leading-order number of floating-point operations (flops) and the memory required to store the factor $L$.\n\n**1. Operation Count (Flop Count)**\n\nThe Cholesky factorization algorithm computes the matrix $L$ column by column. The formula for the entries of column $j$ of $L$ is:\n$$L_{jj} = \\sqrt{A_{jj} - \\sum_{k=1}^{j-1} L_{jk}^2}$$\n$$L_{ij} = \\frac{1}{L_{jj}} \\left( A_{ij} - \\sum_{k=1}^{j-1} L_{ik}L_{jk} \\right) \\quad \\text{for } i  j$$\nDue to the band structure, $L_{jk}$ is non-zero only for $k \\ge j-w$. Thus, the sums are not over all preceding indices.\n\nLet us analyze the cost to compute a generic column $j$, assuming $j  w$ to avoid boundary effects at the start of the matrix.\nThe non-zero entries in column $j$ are $L_{ij}$ for $j \\le i \\le \\min(j+w, N)$.\nTo compute the diagonal element $L_{jj}$, the sum $\\sum L_{jk}^2$ runs over $k$ from $j-w$ to $j-1$. This involves $w$ multiplications and $w-1$ additions, which is $O(w)$ flops.\n\nThe main computational effort lies in calculating the off-diagonal elements $L_{ij}$ for $i=j+1, \\dots, \\min(j+w, N)$. For each such $i$, we must compute a dot product $\\sum_{k} L_{ik}L_{jk}$. The non-zero terms in this sum occur for $k$ in the intersection of the non-zero supports of row $i$ and row $j$ of $L^T$. This corresponds to $k \\in [\\max(1, j-w, i-w), j-1]$. Since $ij$, the lower bound is $i-w$. Thus, the sum is over $k$ from $i-w$ to $j-1$. The number of terms is $(j-1) - (i-w) + 1 = j-i+w$. A dot product with this many terms requires approximately $2(j-i+w)$ flops (multiplications and additions).\n\nThe total number of flops to compute the off-diagonal entries of column $j$ (for $j \\gg w$) is:\n$$ \\text{Flops}_j \\approx \\sum_{i=j+1}^{j+w} 2(j-i+w) $$\nLet $p = i-j$. The sum becomes:\n$$ \\text{Flops}_j \\approx \\sum_{p=1}^{w} 2(w-p+1) = 2 \\left( \\sum_{p=1}^{w} w - \\sum_{p=1}^{w} p + \\sum_{p=1}^{w} 1 \\right) = 2 \\left( w^2 - \\frac{w(w+1)}{2} + w \\right) = 2 \\left( \\frac{w^2-w}{2} + w \\right) = w^2+w $$\nFor large $w$, the leading-order cost per column is $O(w^2)$. Summing over all $N$ columns gives the total flop count:\n$$ \\text{Total Flops} \\approx \\sum_{j=1}^{N} w^2 = N w^2 $$\nThis is the leading-order expression for the operation count in terms of $N$ and $w$.\n\n**2. Memory Requirement**\n\nThe memory required is the number of non-zero entries that must be stored for the Cholesky factor $L$. As established, $L$ has a semi-bandwidth of $w$.\nFor each column $j$, the non-zero entries are $L_{ij}$ for $j \\le i \\le \\min(j+w, N)$. The number of non-zero entries in column $j$ is thus $\\min(w, N-j) + 1$.\n\nThe total number of non-zeros in $L$ is the sum over all columns:\n$$ \\text{Memory} = \\sum_{j=1}^{N} (\\min(w, N-j) + 1) $$\nAssuming $N \\gg w$, we can approximate this sum. For the majority of columns ($j=1, \\dots, N-w$), the number of non-zeros is $w+1$. For the last $w$ columns, the count decreases linearly to $1$.\n$$ \\text{Memory} = \\sum_{j=1}^{N-w} (w+1) + \\sum_{j=N-w+1}^{N} (N-j+1) $$\n$$ \\text{Memory} = (N-w)(w+1) + \\left( w + (w-1) + \\dots + 1 \\right) $$\n$$ \\text{Memory} = Nw + N - w^2 - w + \\frac{w(w+1)}{2} = Nw + N - \\frac{w^2+w}{2} $$\nFor large $N$ and $w$ where $N \\gg w$, the dominant term is $Nw$. Thus, the leading-order expression for memory is:\n$$ \\text{Memory} \\approx N w $$\n\n**3. Specialization for the 2D Poisson Problem**\n\nFor the finite-difference discretization of the 2D Poisson equation on an $n \\times n$ grid, we are given the total number of unknowns $N=n^2$ and that lexicographic ordering results in a semi-bandwidth $w \\sim n$. We take $w=n$.\nWe substitute these into our derived leading-order expressions.\n\n- **Flop Count in terms of $N$**:\n$$ \\text{Flops} \\approx N w^2 = (n^2)(n^2) = n^4 $$\nSince $n = N^{1/2}$, we have:\n$$ \\text{Flops} \\approx (N^{1/2})^4 = N^2 $$\nThe leading-order flop count is $O(N^2)$.\n\n- **Memory in terms of $N$**:\n$$ \\text{Memory} \\approx N w = (n^2)(n) = n^3 $$\nSince $n = N^{1/2}$, we have:\n$$ \\text{Memory} \\approx (N^{1/2})^3 = N^{3/2} $$\nThe leading-order memory requirement is $O(N^{3/2})$.\n\n**4. Inefficiency Relative to Nested Dissection (ND)**\n\nThe derived asymptotics, $O(N^2)$ for operations and $O(N^{3/2})$ for memory, demonstrate the inefficiency of using a standard banded solver with lexicographic ordering for 2D problems when compared to more sophisticated ordering schemes.\n\nNested dissection (ND) is an alternative ordering strategy based on graph partitioning. For a problem on a 2D grid, ND reorders the unknowns to produce a matrix structure that, while not narrowly banded, exhibits substantially less fill-in during factorization. The complexity of Cholesky factorization with ND ordering for 2D problems is:\n- **Flop Count**: $O(N^{3/2})$\n- **Memory**: $O(N \\log N)$\n\nComparing the exponents, we see that $2  3/2$ for the flop count and $3/2  1$ (since $\\log N$ grows more slowly than any power of $N$) for memory. Therefore, nested dissection is asymptotically superior in both computational cost and storage. The banded approach with lexicographic ordering is inefficient because it fails to exploit the geometric structure of the 2D grid as effectively as ND, leading to extensive fill-in within the band and consequently higher computational work and memory usage.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} N^2  N^{3/2} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Having established the need for advanced orderings, this final practice delves into the primary benefit of Nested Dissection: exposing massive parallelism. You will implement a simplified geometric version of the algorithm to construct an elimination tree, which represents the data dependencies and parallel workflow of the factorization. By analyzing this tree's structure , you will quantify the available concurrency, gaining insight into how modern direct solvers achieve high performance on parallel architectures.",
            "id": "3309452",
            "problem": "You are given a computational task related to constructing a parallel schedule for a direct solver performing the Cholesky factorization of a sparse, symmetric positive definite matrix arising from a Three-Dimensional (3D) finite difference discretization of the Poisson equation in Computational Fluid Dynamics (CFD). The mathematical and algorithmic basis must derive from first principles: discretization leading to a symmetric positive definite structure, the existence of a Cholesky factorization, and the elimination dependencies captured by the elimination tree. The objective is to construct the elimination tree using a geometric Nested Dissection ordering and then compute the parallel concurrency at each level as the number of independent supernodes scheduled at that level. Finally, report the peak concurrency for each test case.\n\nFundamental base:\n- The 3D scalar Poisson equation on a rectilinear grid is $$-\\nabla^2 u = f,$$ discretized by standard second-order finite differences on a Cartesian mesh of size $n_x \\times n_y \\times n_z$. This gives a sparse, symmetric positive definite (SPD) linear system $$A \\mathbf{u} = \\mathbf{f}$$ where $A$ is SPD, ensuring a Cholesky factorization $$A = L L^\\top$$ exists.\n- In a direct, column-elimination Cholesky process, the elimination dependencies can be captured by the elimination tree. The elimination tree is a rooted tree whose nodes correspond to supernodes (aggregated columns sharing identical fill-in patterns), and where a parent-child relation expresses data dependency: a parent supernode cannot be eliminated until all its child supernodes are eliminated.\n- Nested Dissection is a geometric ordering strategy that recursively partitions the domain with separators, producing a hierarchy of subdomains and separators. This produces a well-defined elimination tree where separator regions become parents of the subdomains they separate.\n\nDefinitions to use:\n- A supernode is a contiguous group of columns that share identical nonzero patterns in their Cholesky factor below the diagonal. In a geometric Nested Dissection partition of a structured grid, treat each region (subdomain or separator) as a supernode for scheduling purposes.\n- The elimination tree is constructed by recursive partitioning: at each step, split the current region along the longest axis into a left subdomain, a separator of thickness $s$, and a right subdomain. The separator becomes the parent node with children equal to the resulting subdomains.\n- Define the scheduling level for each node as follows: leaves (regions that are not further partitioned) have level $0$, and an internal node has level equal to $1$ plus the maximum level of its children. Nodes at the same level are independent and can be eliminated in parallel at that level. The concurrency at a level is the count of nodes at that level. The peak concurrency is the maximum concurrency over all levels.\n\nImplementation requirements:\n- Implement a recursive geometric partitioning to generate the elimination tree for a rectangular domain of size $n_x \\times n_y \\times n_z$. At each recursion, split along the dimension with the largest size. If that largest size is less than or equal to the separator thickness $s$, or if the total number of cells $n_x n_y n_z$ is less than or equal to a user-specified threshold $N_{\\min}$, stop partitioning and create a leaf node.\n- When splitting along axis $a \\in \\{x, y, z\\}$ with extent $n_a$, create two subdomains and one separator of thickness $s$. The left subdomain has extent $\\left\\lfloor \\frac{n_a - s}{2} \\right\\rfloor$, the right subdomain has extent $n_a - s - \\left\\lfloor \\frac{n_a - s}{2} \\right\\rfloor$. If either left or right extent is non-positive, stop and create a leaf node.\n- Construct the elimination tree where the separator is the parent of the two subdomains. Assign levels bottom-up: leaves at level $0$, internal nodes at $1 + \\max(\\text{child levels})$.\n- Compute the concurrency per level as the number of nodes at that level, and define the peak concurrency as the maximum over all levels.\n\nTest suite:\nFor each tuple $(n_x, n_y, n_z, s, N_{\\min})$, construct the elimination tree as described and compute the peak concurrency. Use the following test cases:\n1. $(n_x, n_y, n_z, s, N_{\\min}) = (64, 32, 32, 2, 512)$ as a general, well-balanced case.\n2. $(n_x, n_y, n_z, s, N_{\\min}) = (128, 8, 8, 1, 256)$ as a slender-domain case to test deep splitting along a single axis.\n3. $(n_x, n_y, n_z, s, N_{\\min}) = (3, 3, 3, 2, 10)$ as a tiny-domain edge case where partitioning quickly terminates.\n4. $(n_x, n_y, n_z, s, N_{\\min}) = (50, 50, 50, 3, 5000)$ as a moderately large, symmetric cube.\n\nFinal output specification:\n- Your program should produce a single line of output containing the peak concurrency for each test case, in order, formatted as a comma-separated list enclosed in square brackets. For example, the output must look like `[c_1, c_2, c_3, c_4]` where each $c_i$ is an integer peak concurrency value for the $i$-th test case.\n- No physical units are required.",
            "solution": "The problem requires the determination of the peak parallel concurrency for the Cholesky factorization of a sparse matrix, derived from a three-dimensional finite difference discretization of the Poisson equation. The analysis is based on an elimination tree constructed using a geometric Nested Dissection ordering.\n\nThe foundation of this problem lies in the numerical solution of the Poisson equation, $-\\nabla^2 u = f$, on a Cartesian grid of size $n_x \\times n_y \\times n_z$. A standard second-order finite difference scheme discretizes this partial differential equation into a large, sparse system of linear equations, $A \\mathbf{u} = \\mathbf{f}$. The matrix $A$ resulting from this discretization is symmetric and positive definite (SPD). This SPD property is critical as it guarantees the existence and numerical stability of a Cholesky factorization, $A = L L^\\top$, where $L$ is a lower triangular matrix known as the Cholesky factor.\n\nThe process of computing $L$ column by column is known as a column-Cholesky factorization. During this process, the elimination of a variable (or column) introduces new non-zero entries, called fill-in, into the factor $L$. The dependencies between column computations can be modeled by a directed acyclic graph, which for Cholesky factorization simplifies to a rooted tree called the elimination tree. In this tree, each node represents a unit of computational work, and a parent-child relationship indicates a data dependency: a parent node cannot be computed until all its child nodes have been computed.\n\nFor scheduling purposes, we aggregate columns with identical fill-in patterns into supernodes. In this problem, we adopt a geometric abstraction where each region defined by the Nested Dissection partitioning scheme is treated as a single supernode.\n\nThe Nested Dissection algorithm provides a strategy for ordering the matrix variables to reduce fill-in and expose parallelism. It operates by recursively partitioning the physical domain. The prescribed algorithm is as follows:\n\nA given rectangular domain of size $n_x \\times n_y \\times n_z$ is considered a node in the elimination tree. The partitioning proceeds recursively:\n1.  **Identify Split Axis**: The domain is split along its longest dimension. Let this dimension have size $n_a$. If there is a tie, any of the longest dimensions may be chosen; a deterministic choice such as the first-occurring longest dimension is used.\n2.  **Partition**: The domain is divided into three regions: two smaller subdomains and a separator of thickness $s$ that separates them. The current domain itself represents the separator, which becomes a parent node in the elimination tree. The two subdomains become its children. The sizes of the subdomains along the split axis $a$ are calculated as:\n    $$ n_{\\text{left}} = \\left\\lfloor \\frac{n_a - s}{2} \\right\\rfloor $$\n    $$ n_{\\text{right}} = n_a - s - n_{\\text{left}} $$\n3.  **Termination**: The recursion for a given domain stops, and it becomes a leaf node in the tree, under any of the following conditions:\n    a. The total number of cells in the domain is below a threshold: $n_x n_y n_z \\le N_{\\min}$.\n    b. The domain is too thin to be split: the size of the longest dimension, $n_{\\max}$, is not greater than the separator thickness, $n_{\\max} \\le s$.\n    c. The partitioning arithmetic results in a non-positive subdomain size: $n_{\\text{left}} \\le 0$ or $n_{\\text{right}} \\le 0$.\n\nOnce the elimination tree is constructed, we can analyze the potential for parallel execution. The tasks (supernodes) that can be executed concurrently are those that are independent of each other. In the elimination tree model, all nodes at the same level are independent. The level of each node is defined bottom-up:\n- **Leaf Nodes**: Nodes that are not partitioned have a level of $L=0$.\n- **Internal (Parent) Nodes**: A node $P$ with children $\\{C_1, C_2, \\ldots, C_k\\}$ has a level defined by $L_P = 1 + \\max(L_{C_1}, L_{C_2}, \\ldots, L_{C_k})$.\n\nAt any stage of the factorization, all nodes at a given level can be processed in parallel. The number of nodes at level $k$ is the concurrency at that level, $C(k)$. The peak concurrency, $C_{\\text{peak}}$, is the maximum concurrency over all levels:\n$$ C_{\\text{peak}} = \\max_{k} C(k) $$\nThis value represents the maximum degree of parallelism exposed by the Nested Dissection ordering and is a critical metric for predicting the performance of a parallel direct solver.\n\nThe solution is implemented by a recursive function that models the partitioning process. This function constructs a tree of nodes, where each node represents a geometric region. The function checks the termination conditions. If they are not met, it performs the split, makes two recursive calls for the resulting subdomains, and sets itself as the parent, calculating its level based on the levels of its children. By collecting all nodes created during this process, we can count the number of nodes at each distinct level and find the maximum count, which yields the peak concurrency. This procedure is applied to each test case provided.",
            "answer": "```python\nimport numpy as np\nfrom collections import Counter\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        (64, 32, 32, 2, 512),\n        (128, 8, 8, 1, 256),\n        (3, 3, 3, 2, 10),\n        (50, 50, 50, 3, 5000),\n    ]\n\n    results = []\n    for case in test_cases:\n        nx, ny, nz, s, N_min = case\n        peak_concurrency = compute_peak_concurrency(nx, ny, nz, s, N_min)\n        results.append(peak_concurrency)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nclass Node:\n    \"\"\"\n    A simple class to represent a node in the elimination tree.\n    Each node corresponds to a geometric region (subdomain or separator).\n    \"\"\"\n    def __init__(self, dims):\n        self.dims = dims\n        self.children = []\n        self.level = 0 # Default level is 0, for a leaf node.\n\ndef compute_peak_concurrency(nx, ny, nz, s, N_min):\n    \"\"\"\n    Computes the peak parallel concurrency for a given domain and parameters.\n\n    Args:\n        nx, ny, nz (int): Dimensions of the computational domain.\n        s (int): Thickness of the separator.\n        N_min (int): Minimum number of cells to allow partitioning.\n\n    Returns:\n        int: The peak concurrency.\n    \"\"\"\n    all_nodes = []\n\n    def build_tree(dims):\n        \"\"\"\n        Recursively partitions the domain to build the elimination tree.\n\n        Args:\n            dims (tuple): A tuple (nx, ny, nz) representing the domain dimensions.\n\n        Returns:\n            Node: The root node of the subtree for the given domain.\n        \"\"\"\n        # Create a node for the current domain and add it to the global list.\n        current_node = Node(dims)\n        all_nodes.append(current_node)\n        \n        current_nx, current_ny, current_nz = dims\n\n        # 1. Termination condition: Volume threshold\n        if current_nx * current_ny * current_nz = N_min:\n            return current_node # It's a leaf node\n\n        # 2. Termination condition: Split not possible if longest dim = separator thickness\n        dim_array = np.array([current_nx, current_ny, current_nz])\n        split_axis_idx = np.argmax(dim_array)\n        max_dim_size = dim_array[split_axis_idx]\n\n        if max_dim_size = s:\n            return current_node # It's a leaf node\n\n        # Calculate subdomain sizes\n        n_a = max_dim_size\n        n_left = (n_a - s) // 2\n        \n        # 3. Termination condition: Non-positive subdomain size\n        if n_left = 0:\n            return current_node # It's a leaf node\n            \n        n_right = n_a - s - n_left\n        if n_right = 0: # This check is redundant if n_left  0 and n_a  s\n            return current_node # It's a leaf node\n\n        # If we reach here, this node is an internal node (a separator).\n        # We recurse to generate its children.\n        left_dims = list(dims)\n        left_dims[split_axis_idx] = n_left\n        child1 = build_tree(tuple(left_dims))\n\n        right_dims = list(dims)\n        right_dims[split_axis_idx] = n_right\n        child2 = build_tree(tuple(right_dims))\n\n        # This node is the parent. Set its children and update its level.\n        current_node.children = [child1, child2]\n        current_node.level = 1 + max(child1.level, child2.level)\n        \n        return current_node\n\n    # Start the recursive construction of the entire tree.\n    build_tree((nx, ny, nz))\n\n    # Count the number of nodes at each level.\n    if not all_nodes:\n        return 0\n    \n    level_counts = Counter(node.level for node in all_nodes)\n    \n    # Peak concurrency is the maximum count over all levels.\n    return max(level_counts.values())\n\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}