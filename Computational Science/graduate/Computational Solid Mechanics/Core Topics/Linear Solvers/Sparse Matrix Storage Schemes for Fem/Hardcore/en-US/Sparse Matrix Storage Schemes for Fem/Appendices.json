{
    "hands_on_practices": [
        {
            "introduction": "The choice of a sparse matrix storage scheme is a critical decision that impacts both memory usage and computational speed in a Finite Element Method (FEM) analysis. This first exercise challenges you to move beyond abstract definitions by performing a rigorous, first-principles comparison of the Diagonal (DIA) and Compressed Sparse Row (CSR) formats for a structured 3D mesh. By deriving the exact storage costs as a function of mesh size, you will gain a concrete understanding of their performance trade-offs and see how a matrix's structure arises directly from mesh topology and node ordering .",
            "id": "3601714",
            "problem": "Consider a finite element discretization of a linear scalar elliptic boundary value problem on a unit cube domain using a structured three-dimensional hexahedral mesh with linear $Q_1$ elements. Let there be $n$ mesh nodes along each Cartesian axis, with $n \\geq 3$, and adopt the natural degree-of-freedom (DOF) ordering in lexicographic row-major sequence: $(i,j,k)$ maps to the global index $p = i + n j + n^2 k$, where $i,j,k \\in \\{0,1,\\dots,n-1\\}$. Assume one scalar DOF per node. The assembled global stiffness matrix $\\boldsymbol{K} \\in \\mathbb{R}^{N \\times N}$, with $N = n^3$, is sparse due to the locality of $Q_1$ shape functions. In particular, for interior nodes, $\\boldsymbol{K}$ exhibits nonzero couplings between a node and all nodes that share at least one element with it. Define the Diagonal (DIA) storage scheme as one that stores all diagonals of $\\boldsymbol{K}$ defined by constant column-minus-row index offsets, each as a full-length array of $N$ entries, together with a single integer offset per diagonal. Define the Compressed Sparse Row (CSR) storage scheme in the standard way: an array of $nnz$ values, an array of $nnz$ integer column indices, and a row-pointer array of length $N+1$. \n\nStarting from the core definitions of $Q_1$ shape function support and the natural DOF ordering given above, and without invoking any pre-tabulated stencil counts or storage formulas, derive:\n1. The exact number of distinct diagonals present in $\\boldsymbol{K}$ under the DIA scheme.\n2. An exact closed-form expression, as a function of $n$, for the ratio of total DIA storage to total CSR storage, where “total storage” counts scalar value entries and integer index entries equally.\n\nExpress your final answer as a two-entry row vector, with the first entry equal to the number of distinct diagonals and the second entry equal to the DIA-to-CSR storage ratio $\\eta(n)$. No numerical approximation is required; provide a closed-form expression in $n$. If any intermediate quantities require counting lattice points or offsets, derive them from first principles of the finite element method (FEM), Diagonal (DIA), and Compressed Sparse Row (CSR) definitions. The final answer must be a single analytical expression or a pair of analytical expressions organized as requested. No physical units are required.",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded in the principles of the Finite Element Method (FEM) and numerical linear algebra, is well-posed with a clear and complete set of definitions, and is expressed in objective, formal language. There are no contradictions, ambiguities, or factual unsoundness. We may therefore proceed with a full solution.\n\nThe solution requires deriving two quantities related to the sparse global stiffness matrix $\\boldsymbol{K}$ arising from a $Q_1$ finite element discretization on a structured $n \\times n \\times n$ grid of nodes.\n\nThe key information provided includes:\n- The total number of nodes is $N=n^3$.\n- Nodes are indexed by $(i,j,k)$ where $i,j,k \\in \\{0, 1, \\dots, n-1\\}$.\n- A lexicographic row-major mapping translates a node's $3$D index $(i,j,k)$ to a global $1$D index $p$:\n$$p(i,j,k) = i + n j + n^2 k$$\n- A non-zero entry $\\boldsymbol{K}_{pq}$ exists if and only if the nodes corresponding to global indices $p$ and $q$ share at least one element. For $Q_1$ (trilinear hexahedral) elements, this means node $p$ is coupled to all nodes that form the vertices of any element to which node $p$ belongs.\n\n### Part 1: Number of Distinct Diagonals\nThe \"diagonals\" in the DIA scheme correspond to sets of matrix entries $(r,c)$ having a constant offset $d = c-r$. We need to find the number of unique values for $d$ where $\\boldsymbol{K}_{rc} \\neq 0$ for at least one pair $(r,c)$.\n\nLet node $r$ have coordinates $(i_r, j_r, k_r)$ and node $c$ have coordinates $(i_c, j_c, k_c)$. The condition $\\boldsymbol{K}_{rc} \\neq 0$ implies that node $c$ must be a neighbor of node $r$ in the finite element mesh connectivity sense. For an interior node $(i_r, j_r, k_r)$ (where $1 \\le i_r, j_r, k_r \\le n-2$, which exists since $n \\ge 3$), it belongs to 8 adjacent hexahedral elements. The set of all unique nodes making up these 8 elements forms a $3 \\times 3 \\times 3$ cube of nodes centered at $(i_r, j_r, k_r)$.\nTherefore, node $c$ must have coordinates $(i_r + \\Delta i, j_r + \\Delta j, k_r + \\Delta k)$, where $\\Delta i, \\Delta j, \\Delta k \\in \\{-1, 0, 1\\}$.\nThere are $3^3 = 27$ such combinations for $(\\Delta i, \\Delta j, \\Delta k)$, which define the 26 neighbors plus the node itself.\n\nThe offset $d = c-r$ can be expressed in terms of the grid index differences:\n$$\nd = p(i_c, j_c, k_c) - p(i_r, j_r, k_r) \\\\\n= (i_c + n j_c + n^2 k_c) - (i_r + n j_r + n^2 k_r) \\\\\n= (i_c - i_r) + n(j_c - j_r) + n^2(k_c - k_r) \\\\\n= \\Delta i + n \\Delta j + n^2 \\Delta k\n$$\nWe must determine if each of the 27 possible integer vectors $(\\Delta i, \\Delta j, \\Delta k)$ yields a unique offset $d$. Suppose two different vectors, $(\\Delta i_1, \\Delta j_1, \\Delta k_1)$ and $(\\Delta i_2, \\Delta j_2, \\Delta k_2)$, produce the same offset:\n$$\n\\Delta i_1 + n \\Delta j_1 + n^2 \\Delta k_1 = \\Delta i_2 + n \\Delta j_2 + n^2 \\Delta k_2 \\\\\n\\implies (\\Delta i_1 - \\Delta i_2) + n(\\Delta j_1 - \\Delta j_2) + n^2(\\Delta k_1 - \\Delta k_2) = 0\n$$\nLet $\\delta_i = \\Delta i_1 - \\Delta i_2$, $\\delta_j = \\Delta j_1 - \\Delta j_2$, and $\\delta_k = \\Delta k_1 - \\Delta k_2$. Since $\\Delta i, \\Delta j, \\Delta k \\in \\{-1, 0, 1\\}$, the differences must be in $\\{-2, -1, 0, 1, 2\\}$. The equation is $\\delta_i + n\\delta_j + n^2\\delta_k = 0$.\nThis equation can be viewed as the number $0$ written in base $n$. We can show that the only solution is $\\delta_i = \\delta_j = \\delta_k = 0$.\nFrom the equation, we have $n^2\\delta_k = -(\\delta_i + n\\delta_j)$.\nTaking the absolute value: $n^2 |\\delta_k| = |\\delta_i + n\\delta_j| \\le |\\delta_i| + n|\\delta_j|$.\nSince $|\\delta_i| \\le 2$ and $|\\delta_j| \\le 2$, we have $n^2 |\\delta_k| \\le 2 + n(2) = 2(n+1)$.\n$|\\delta_k| \\le \\frac{2(n+1)}{n^2}$.\nFor $n \\ge 3$, we have $n^2 > 2n+2 = 2(n+1)$, which implies $\\frac{2(n+1)}{n^2}  1$.\nSince $|\\delta_k|$ must be an integer, the only possibility is $|\\delta_k|=0$, so $\\delta_k=0$.\nThe equation reduces to $\\delta_i + n\\delta_j = 0$, or $\\delta_i = -n\\delta_j$.\nGiven $|\\delta_i| \\le 2$ and $n \\ge 3$, this equality can only hold if $\\delta_j=0$, which in turn implies $\\delta_i=0$.\nThus, $\\delta_i = \\delta_j = \\delta_k = 0$, which means $(\\Delta i_1, \\Delta j_1, \\Delta k_1) = (\\Delta i_2, \\Delta j_2, \\Delta k_2)$.\nThis proves that each of the $27$ structural neighbor relationships corresponds to a unique integer offset. Since interior nodes exist for $n \\ge 3$, all $27$ types of connections are present in the matrix $\\boldsymbol{K}$. Therefore, there are exactly $27$ distinct diagonals.\n\n### Part 2: Ratio of DIA Storage to CSR Storage\nLet $\\eta(n)$ be the ratio of total DIA storage to total CSR storage. We count value and index entries equally.\n\n**DIA Storage ($S_{DIA}$):**\nThe DIA scheme stores each of the $27$ diagonals as a full-length array of size $N=n^3$. This accounts for $27 \\times N = 27n^3$ value entries. Additionally, it stores one integer offset for each diagonal, which is $27$ integer entries.\n$$S_{DIA} = 27n^3 + 27$$\n\n**CSR Storage ($S_{CSR}$):**\nThe CSR scheme uses three arrays: a value array of length $nnz$, a column index array of length $nnz$, and a row pointer array of length $N+1$.\n$nnz$ is the total number of non-zero entries in $\\boldsymbol{K}$.\n$$S_{CSR} = nnz (\\text{values}) + nnz (\\text{indices}) + (N+1) (\\text{pointers}) = 2 \\cdot nnz + n^3 + 1$$\nTo find $nnz$, we sum the number of non-zero entries over all rows. The number of non-zeros in a row corresponds to the number of nodes connected to the node of that row (including itself). This number depends on the node's location.\n\n1.  **Node Classification and Counts:**\n    -   **Corner nodes:** $8$ nodes. A corner node (e.g., $(0,0,0)$) connects to nodes in a $2 \\times 2 \\times 2$ block. Number of connections: $2^3 = 8$.\n    -   **Edge nodes (not corners):** $12(n-2)$ nodes. An edge node (e.g., $(0,0,k)$ with $1 \\le k \\le n-2$) connects to nodes in a $2 \\times 2 \\times 3$ block. Number of connections: $2 \\times 2 \\times 3 = 12$.\n    -   **Face nodes (not edges):** $6(n-2)^2$ nodes. A face node (e.g., $(0,j,k)$ with $1 \\le j,k \\le n-2$) connects to nodes in a $2 \\times 3 \\times 3$ block. Number of connections: $2 \\times 3 \\times 3 = 18$.\n    -   **Interior nodes:** $(n-2)^3$ nodes. An interior node connects to nodes in a $3 \\times 3 \\times 3$ block. Number of connections: $3^3 = 27$.\n\n2.  **Calculation of $nnz$:**\n    Summing the number of connections over all nodes gives $nnz$:\n    $$nnz = 8 \\times 8 + 12(n-2) \\times 12 + 6(n-2)^2 \\times 18 + (n-2)^3 \\times 27$$\n    $$nnz = 64 + 144(n-2) + 108(n-2)^2 + 27(n-2)^3$$\n    Let $x = n-2$. The expression is a polynomial in $x$: $27x^3 + 108x^2 + 144x + 64$.\n    This is the binomial expansion of $(3x+4)^3$:\n    $$(3x+4)^3 = (3x)^3 + 3(3x)^2(4) + 3(3x)(4)^2 + 4^3 = 27x^3 + 108x^2 + 144x + 64$$\n    Substituting $x = n-2$ back:\n    $$nnz = (3(n-2) + 4)^3 = (3n - 6 + 4)^3 = (3n - 2)^3$$\n\n3.  **Final Storage Calculation and Ratio:**\n    Now we can write the expression for $S_{CSR}$:\n    $$S_{CSR} = 2(3n-2)^3 + n^3 + 1$$\n    Expanding the cubic term:\n    $$(3n-2)^3 = 27n^3 - 54n^2 + 36n - 8$$\n    $$S_{CSR} = 2(27n^3 - 54n^2 + 36n - 8) + n^3 + 1$$\n    $$S_{CSR} = 54n^3 - 108n^2 + 72n - 16 + n^3 + 1$$\n    $$S_{CSR} = 55n^3 - 108n^2 + 72n - 15$$\n    The storage ratio $\\eta(n)$ is:\n    $$\\eta(n) = \\frac{S_{DIA}}{S_{CSR}} = \\frac{27n^3 + 27}{55n^3 - 108n^2 + 72n - 15}$$\n    This can be written as:\n    $$\\eta(n) = \\frac{27(n^3 + 1)}{55n^3 - 108n^2 + 72n - 15}$$\n    This is the final closed-form expression for the ratio.\n\nThe final answer comprises two parts: the number of diagonals and the storage ratio expression.\n1. Number of diagonals: $27$.\n2. Storage ratio $\\eta(n)$: $\\frac{27(n^3 + 1)}{55n^3 - 108n^2 + 72n - 15}$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n27  \\frac{27(n^3 + 1)}{55n^3 - 108n^2 + 72n - 15}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While some storage schemes like CSR are insensitive to node ordering, the performance of many direct and iterative solvers is deeply tied to the matrix profile or bandwidth. This practice moves from passive analysis to active optimization by introducing node reordering as a tool for bandwidth reduction. You will manually execute the classic Reverse Cuthill-McKee (RCM) algorithm on an unstructured mesh, providing a hands-on understanding of how graph theory can be leveraged to significantly improve the numerical properties of a stiffness matrix .",
            "id": "3601692",
            "problem": "Consider a two-dimensional linear elasticity model discretized by the Finite Element Method (FEM) using linear triangular elements on an unstructured mesh. Assume one scalar displacement degree of freedom (DOF) per mesh node, so that the global stiffness matrix is symmetric and a nonzero off-diagonal entry $K_{ij}$ exists if and only if nodes $i$ and $j$ appear together in at least one element. This induces the usual adjacency graph on the nodes. The computational cost of profile-based schemes is governed by the matrix bandwidth, which for a given node ordering $p:\\{1,\\dots,N\\}\\to\\{1,\\dots,N\\}$ is defined by\n$$\nb \\;=\\; \\max\\{\\, |p(i)-p(j)| \\;:\\; (i,j)\\ \\text{is an adjacency edge}\\,\\}.\n$$\nYou are given an unstructured triangular mesh with $N=12$ nodes labeled by their current ordering $p_{\\text{old}}(i)=i$, and the element connectivity\n$$\n(1,2,5),\\ (1,4,5),\\ (2,3,6),\\ (2,5,6),\\ (4,5,8),\\ (4,7,8),\\ (5,6,9),\\ (5,8,9),\\ (7,8,11),\\ (7,10,11),\\ (8,9,12),\\ (8,11,12).\n$$\nFrom first principles of FEM assembly and graph theory, construct the adjacency graph implied by this connectivity. Then perform one pass of the Reverse Cuthill-McKee (RCM) reordering to obtain a new node ordering $p_{\\text{new}}$ as follows:\n- Choose a starting node with minimum degree; if there is a tie, choose the smallest label.\n- Execute Breadth-First Search (BFS), and when visiting a node, enqueue its unvisited neighbors sorted by nondecreasing degree; if there is a tie, sort by increasing label.\n- The Cuthill-McKee ordering is the BFS visitation order; the Reverse Cuthill-McKee ordering reverses that sequence to produce $p_{\\text{new}}$.\n\nCompute the original bandwidth $b_{\\text{old}}$ under $p_{\\text{old}}$, the new bandwidth $b_{\\text{new}}$ under $p_{\\text{new}}$, and the bandwidth reduction ratio\n$$\nr \\;=\\; \\frac{b_{\\text{old}} - b_{\\text{new}}}{b_{\\text{old}}}.\n$$\nExpress the final ratio $r$ as an exact fraction with no units.",
            "solution": "The problem is well-posed and scientifically grounded in the field of computational mechanics and numerical linear algebra. We shall proceed with a full solution. The problem requires us to analyze the bandwidth of a sparse matrix arising from a Finite Element Method (FEM) discretization, perform a bandwidth-reduction reordering using the Reverse Cuthill-McKee (RCM) algorithm, and compute the resulting improvement.\n\nThe process is structured as follows:\n1.  Construct the adjacency graph from the given element connectivity and determine the degree of each node.\n2.  Calculate the bandwidth $b_{\\text{old}}$ for the original node ordering $p_{\\text{old}}(i)=i$.\n3.  Execute the RCM algorithm to obtain a new node ordering $p_{\\text{new}}$.\n4.  Calculate the bandwidth $b_{\\text{new}}$ for the new ordering.\n5.  Compute the bandwidth reduction ratio $r$.\n\n**1. Adjacency Graph Construction and Node Degrees**\n\nThe global stiffness matrix $K$ has a non-zero off-diagonal entry $K_{ij}$ if and only if nodes $i$ and $j$ share at least one element. This defines the edges of the adjacency graph. We derive the edges from the provided element connectivity list:\n$(1,2,5), (1,4,5), (2,3,6), (2,5,6), (4,5,8), (4,7,8), (5,6,9), (5,8,9), (7,8,11), (7,10,11), (8,9,12), (8,11,12)$.\n\nFrom these $12$ elements, we compile the unique edges to form the adjacency list for each of the $N=12$ nodes. The degree of a node, denoted $\\text{deg}(i)$, is the number of nodes adjacent to it.\n\n-   Node $1$: Neighbors $\\{2, 4, 5\\}$. $\\text{deg}(1) = 3$.\n-   Node $2$: Neighbors $\\{1, 3, 5, 6\\}$. $\\text{deg}(2) = 4$.\n-   Node $3$: Neighbors $\\{2, 6\\}$. $\\text{deg}(3) = 2$.\n-   Node $4$: Neighbors $\\{1, 5, 7, 8\\}$. $\\text{deg}(4) = 4$.\n-   Node $5$: Neighbors $\\{1, 2, 4, 6, 8, 9\\}$. $\\text{deg}(5) = 6$.\n-   Node $6$: Neighbors $\\{2, 3, 5, 9\\}$. $\\text{deg}(6) = 4$.\n-   Node $7$: Neighbors $\\{4, 8, 10, 11\\}$. $\\text{deg}(7) = 4$.\n-   Node $8$: Neighbors $\\{4, 5, 7, 9, 11, 12\\}$. $\\text{deg}(8) = 6$.\n-   Node $9$: Neighbors $\\{5, 6, 8, 12\\}$. $\\text{deg}(9) = 4$.\n-   Node $10$: Neighbors $\\{7, 11\\}$. $\\text{deg}(10) = 2$.\n-   Node $11$: Neighbors $\\{7, 8, 10, 12\\}$. $\\text{deg}(11) = 4$.\n-   Node $12$: Neighbors $\\{8, 9, 11\\}$. $\\text{deg}(12) = 3$.\n\n**2. Original Bandwidth $b_{\\text{old}}$**\n\nThe initial ordering is the identity permutation, $p_{\\text{old}}(i) = i$ for $i \\in \\{1, \\dots, 12\\}$. The bandwidth $b_{\\text{old}}$ is the maximum difference $|p_{\\text{old}}(i) - p_{\\text{old}}(j)| = |i-j|$ over all edges $(i,j)$ in the graph. We examine the edges to find this maximum.\n\nFor example, for node $8$, its neighbors are $\\{4, 5, 7, 9, 11, 12\\}$. The differences in labels are:\n$|8-4|=4$, $|8-5|=3$, $|8-7|=1$, $|8-9|=1$, $|8-11|=3$, $|8-12|=4$.\nThe maximum difference for node $8$ is $4$.\nBy inspecting all edges, we find several instances resulting in this difference, such as edge $(1,5)$ with $|1-5|=4$, edge $(2,6)$ with $|2-6|=4$, edge $(7,11)$ with $|7-11|=4$, and edge $(8,12)$ with $|8-12|=4$. There is no edge $(i,j)$ for which $|i-j| > 4$.\nTherefore, the original bandwidth is $b_{\\text{old}} = 4$.\n\n**3. Reverse Cuthill-McKee (RCM) Reordering**\n\nThe RCM algorithm is performed as specified.\n\n**a. Starting Node Selection:**\nWe seek a node with the minimum degree. The minimum degree is $2$, which is shared by nodes $3$ and $10$. According to the tie-breaking rule, we choose the one with the smallest label. Thus, the starting node is $3$.\n\n**b. Breadth-First Search (BFS):**\nWe initialize a queue $Q$ with the starting node $3$. Let $R$ be the list storing the Cuthill-McKee (CM) ordering.\n1.  $Q=[3]$. Dequeue $3$, $R=(3)$. Neighbors of $3$ are $\\{2,6\\}$. Both have degree $4$. Tie-breaking by label, we sort them as $(2,6)$. Enqueue $2$, then $6$. $Q=[2,6]$.\n2.  $Q=[2,6]$. Dequeue $2$, $R=(3,2)$. Unvisited neighbors of $2$ are $\\{1,5\\}$. $\\text{deg}(1)=3$, $\\text{deg}(5)=6$. Sorted by degree: $(1,5)$. Enqueue $1$, then $5$. $Q=[6,1,5]$.\n3.  $Q=[6,1,5]$. Dequeue $6$, $R=(3,2,6)$. Unvisited neighbor of $6$ is $\\{9\\}$. $\\text{deg}(9)=4$. Enqueue $9$. $Q=[1,5,9]$.\n4.  $Q=[1,5,9]$. Dequeue $1$, $R=(3,2,6,1)$. Unvisited neighbor of $1$ is $\\{4\\}$. $\\text{deg}(4)=4$. Enqueue $4$. $Q=[5,9,4]$.\n5.  $Q=[5,9,4]$. Dequeue $5$, $R=(3,2,6,1,5)$. Unvisited neighbor of $5$ is $\\{8\\}$. $\\text{deg}(8)=6$. Enqueue $8$. $Q=[9,4,8]$.\n6.  $Q=[9,4,8]$. Dequeue $9$, $R=(3,2,6,1,5,9)$. Unvisited neighbor of $9$ is $\\{12\\}$. $\\text{deg}(12)=3$. Enqueue $12$. $Q=[4,8,12]$.\n7.  $Q=[4,8,12]$. Dequeue $4$, $R=(3,2,6,1,5,9,4)$. Unvisited neighbor of $4$ is $\\{7\\}$. $\\text{deg}(7)=4$. Enqueue $7$. $Q=[8,12,7]$.\n8.  $Q=[8,12,7]$. Dequeue $8$, $R=(3,2,6,1,5,9,4,8)$. Unvisited neighbor of $8$ is $\\{11\\}$. $\\text{deg}(11)=4$. Enqueue $11$. $Q=[12,7,11]$.\n9.  $Q=[12,7,11]$. Dequeue $12$, $R=(3,2,6,1,5,9,4,8,12)$. Node $12$ has no unvisited neighbors. $Q=[7,11]$.\n10. $Q=[7,11]$. Dequeue $7$, $R=(3,2,6,1,5,9,4,8,12,7)$. Unvisited neighbor of $7$ is $\\{10\\}$. $\\text{deg}(10)=2$. Enqueue $10$. $Q=[11,10]$.\n11. $Q=[11,10]$. Dequeue $11$, $R=(3,2,6,1,5,9,4,8,12,7,11)$. Node $11$ has no unvisited neighbors. $Q=[10]$.\n12. $Q=[10]$. Dequeue $10$, $R=(3,2,6,1,5,9,4,8,12,7,11,10)$. Node $10$ has no unvisited neighbors. $Q=[]$.\n\nThe CM ordering is $R = (3, 2, 6, 1, 5, 9, 4, 8, 12, 7, 11, 10)$.\n\n**c. New Ordering $p_{\\text{new}}$:**\nThe RCM ordering is the reverse of the CM ordering. This defines the new permutation $p_{\\text{new}}$, which maps the original node labels to their new positions from $1$ to $12$.\nRCM order: $(10, 11, 7, 12, 8, 4, 9, 5, 1, 6, 2, 3)$.\nThe mapping $p_{\\text{new}}$ is:\n$p_{\\text{new}}(10)=1$, $p_{\\text{new}}(11)=2$, $p_{\\text{new}}(7)=3$, $p_{\\text{new}}(12)=4$, $p_{\\text{new}}(8)=5$, $p_{\\text{new}}(4)=6$, $p_{\\text{new}}(9)=7$, $p_{\\text{new}}(5)=8$, $p_{\\text{new}}(1)=9$, $p_{\\text{new}}(6)=10$, $p_{\\text{new}}(2)=11$, $p_{\\text{new}}(3)=12$.\n\n**4. New Bandwidth $b_{\\text{new}}$**\n\nWe compute the new bandwidth $b_{\\text{new}} = \\max \\{ |p_{\\text{new}}(i) - p_{\\text{new}}(j)| \\}$ over all edges $(i,j)$.\nLet's check some edges that might produce a large difference:\n-   Edge $(1,4)$: $|p_{\\text{new}}(1) - p_{\\text{new}}(4)| = |9 - 6| = 3$.\n-   Edge $(2,5)$: $|p_{\\text{new}}(2) - p_{\\text{new}}(5)| = |11 - 8| = 3$.\n-   Edge $(4,7)$: $|p_{\\text{new}}(4) - p_{\\text{new}}(7)| = |6 - 3| = 3$.\n-   Edge $(5,8)$: $|p_{\\text{new}}(5) - p_{\\text{new}}(8)| = |8 - 5| = 3$.\n-   Edge $(6,9)$: $|p_{\\text{new}}(6) - p_{\\text{new}}(9)| = |10 - 7| = 3$.\n-   Edge $(8,11)$: $|p_{\\text{new}}(8) - p_{\\text{new}}(11)| = |5 - 2| = 3$.\n-   Edge $(9,12)$: $|p_{\\text{new}}(9) - p_{\\text{new}}(12)| = |7 - 4| = 3$.\n\nA thorough check of all $23$ edges confirms that the maximum difference in new labels for any connected pair of nodes is $3$.\nThus, the new bandwidth is $b_{\\text{new}} = 3$.\n\n**5. Bandwidth Reduction Ratio $r$**\n\nThe bandwidth reduction ratio $r$ is defined as:\n$$\nr = \\frac{b_{\\text{old}} - b_{\\text{new}}}{b_{\\text{old}}}\n$$\nSubstituting the computed values:\n$$\nr = \\frac{4 - 3}{4} = \\frac{1}{4}\n$$\nThe RCM reordering achieved a bandwidth reduction of $25\\%$.",
            "answer": "$$\\boxed{\\frac{1}{4}}$$"
        },
        {
            "introduction": "The final step in mastering sparse matrices is understanding their construction. This exercise addresses a crucial, practical detail of the FEM assembly process: efficiently handling the duplicate entries that arise when multiple elements contribute to the same global degree of freedom. You will design and implement an in-place algorithm to consolidate a raw CSR structure, a task that requires careful memory management and showcases the skills needed to write robust and efficient computational mechanics code .",
            "id": "3601707",
            "problem": "Consider an assembly process in computational solid mechanics that yields a global sparse matrix represented in Compressed Sparse Row (CSR) format. Compressed Sparse Row (CSR) stores a real matrix using three one-dimensional arrays: $\\text{rowptr}$, $\\text{colind}$, and $\\text{val}$. The array $\\text{rowptr}$ has length $n+1$ for an $n \\times m$ matrix, and $\\text{rowptr}[r]$ and $\\text{rowptr}[r+1]$ delimit the half-open interval of indices in $\\text{colind}$ and $\\text{val}$ corresponding to row $r$. The array $\\text{colind}$ has length $\\text{nnz}$ and stores the column indices of nonzero entries, and the array $\\text{val}$ has length $\\text{nnz}$ and stores the corresponding real values. Due to finite element method assembly, duplicate structural entries may appear within a row, meaning the same column index occurs multiple times in $\\text{colind}$ between $\\text{rowptr}[r]$ and $\\text{rowptr}[r+1]-1$ for the same $r$. Your task is to design an in-place algorithm that, for each row, detects duplicate structural entries and replaces them by a single entry whose value is the sum of the duplicates, without converting the matrix out of CSR format. The algorithm must operate directly on $\\text{rowptr}$, $\\text{colind}$, and $\\text{val}$, and may use temporary workspace of size proportional to the number of entries in a single row, but must not build any auxiliary global matrix structure. The algorithm must produce a CSR in which, for each row $r$, each column index appears at most once, and the value stored at that column index equals the sum of the original values at that index within the row. Entries whose summed value is $0$ must be retained; the algorithm must not perform value-based sparsification.\n\nStarting from first principles, derive the algorithm and prove its correctness by appealing to linearity of assembly and properties of addition. Establish that the in-place compaction that reduces the total number of stored entries preserves all row-wise sums and does not overwrite unread data. Present a step-by-step reasoning that shows the algorithm is correct for arbitrary real values and arbitrary distributions of duplicates within rows.\n\nFinally, implement the algorithm as a complete, runnable program that processes a fixed test suite. For each test case, the program should take as input arrays $\\text{rowptr}$, $\\text{colind}$, and $\\text{val}$, perform the in-place duplicate summation and compaction, and then compare the resulting arrays to the expected arrays. The program should output a single line containing a comma-separated list enclosed in square brackets with one boolean per test case indicating whether the computed arrays match the expected arrays exactly, with floating-point comparisons evaluated to within a tolerance of $10^{-12}$.\n\nUse the following test suite. In all cases, the arrays represent the CSR of a matrix with the specified number of rows $n$; all values are real numbers and all indices are zero-based integers. For determinism, the final algorithm must sort the unique column indices within each row in strictly ascending order before compaction.\n\nTest case $1$ (general case with duplicates and an empty row):\n$$n = 4$$\n$$\\text{rowptr} = [\\,0,4,6,6,7\\,]$$\n$$\\text{colind} = [\\,0,2,0,1,2,2,3\\,]$$\n$$\\text{val} = [\\,1.0,2.5,-0.5,3.0,4.0,-1.0,7.0\\,]$$\nExpected:\n$$\\text{rowptr} = [\\,0,3,4,4,5\\,]$$\n$$\\text{colind} = [\\,0,1,2,2,3\\,]$$\n$$\\text{val} = [\\,0.5,3.0,2.5,3.0,7.0\\,]$$\n\nTest case $2$ (no duplicates, unsorted columns within rows):\n$$n = 2$$\n$$\\text{rowptr} = [\\,0,2,3\\,]$$\n$$\\text{colind} = [\\,3,1,0\\,]$$\n$$\\text{val} = [\\,1.0,2.0,5.0\\,]$$\nExpected:\n$$\\text{rowptr} = [\\,0,2,3\\,]$$\n$$\\text{colind} = [\\,1,3,0\\,]$$\n$$\\text{val} = [\\,2.0,1.0,5.0\\,]$$\n\nTest case $3$ (single row with heavy duplication):\n$$n = 1$$\n$$\\text{rowptr} = [\\,0,7\\,]$$\n$$\\text{colind} = [\\,2,2,2,2,2,0,0\\,]$$\n$$\\text{val} = [\\,1.0,1.0,-2.0,0.5,3.5,10.0,-3.0\\,]$$\nExpected:\n$$\\text{rowptr} = [\\,0,2\\,]$$\n$$\\text{colind} = [\\,0,2\\,]$$\n$$\\text{val} = [\\,7.0,4.0\\,]$$\n\nTest case $4$ (summations to zero retained):\n$$n = 3$$\n$$\\text{rowptr} = [\\,0,3,4,4\\,]$$\n$$\\text{colind} = [\\,1,1,2,0\\,]$$\n$$\\text{val} = [\\,2.0,-2.0,1.0,0.0\\,]$$\nExpected:\n$$\\text{rowptr} = [\\,0,2,3,3\\,]$$\n$$\\text{colind} = [\\,1,2,0\\,]$$\n$$\\text{val} = [\\,0.0,1.0,0.0\\,]$$\n\nTest case $5$ (mixed duplicates across multiple rows):\n$$n = 3$$\n$$\\text{rowptr} = [\\,0,6,9,11\\,]$$\n$$\\text{colind} = [\\,0,1,2,2,1,5,3,3,4,0,0\\,]$$\n$$\\text{val} = [\\,1.0,2.0,3.0,-1.0,0.5,10.0,7.0,-7.0,1.0,-1.0,1.0\\,]$$\nExpected:\n$$\\text{rowptr} = [\\,0,4,6,7\\,]$$\n$$\\text{colind} = [\\,0,1,2,5,3,4,0\\,]$$\n$$\\text{val} = [\\,1.0,2.5,2.0,10.0,0.0,1.0,0.0\\,]$$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\left[\\,\\text{result}_1,\\text{result}_2,\\dots\\,\\right]$), where each $\\text{result}_i$ is a boolean indicating whether the processed CSR arrays match the expected arrays for test case $i$ within a floating-point tolerance of $10^{-12}$.",
            "solution": "The user-provided problem is assessed to be valid. It is scientifically grounded in the principles of computational linear algebra and finite element methods, is well-posed with a clear objective and sufficient data, and is expressed in precise, objective language. Therefore, a solution is warranted.\n\n### Principle-Based Derivation of the Algorithm\n\nThe problem requires an in-place algorithm to sum duplicate entries in a sparse matrix stored in Compressed Sparse Row (CSR) format. The CSR format consists of three arrays: $\\text{rowptr}$, $\\text{colind}$, and $\\text{val}$. For a matrix with $n$ rows, $\\text{rowptr}$ is an array of length $n+1$, where the entries for row $r$ are found in the $\\text{colind}$ and $\\text{val}$ arrays in the index range $[\\text{rowptr}[r], \\text{rowptr}[r+1]-1]$.\n\nThe core task is to process the arrays $\\text{colind}$ and $\\text{val}$ to eliminate duplicate column indices within each row by summing their corresponding values, and then to compact these arrays and update $\\text{rowptr}$ accordingly. The algorithm must be \"in-place,\" meaning it modifies the existing arrays rather than creating new global arrays, and it must do so without overwriting data that has not yet been read.\n\n#### Row-Wise Processing\nThe structure of the CSR format naturally partitions the problem by rows. The entries for any given row $r$ are stored contiguously. Operations on one row's data do not affect the data of another row, apart from their relative storage locations in a compacted format. Thus, we can design an algorithm that iterates through the matrix row by row, from $r=0$ to $r=n-1$.\n\n#### Summation of Duplicates within a Row\nFor a single row $r$, its non-zero entries are specified by the slices $\\text{colind}[\\text{rowptr}[r] : \\text{rowptr}[r+1]]$ and $\\text{val}[\\text{rowptr}[r] : \\text{rowptr}[r+1]]$. The fundamental principle of matrix assembly in the Finite Element Method (FEM) is linearity. The final value of a matrix entry $(r,c)$ is the sum of all contributions to that entry from all constituent element matrices. Our algorithm must replicate this summation. A hash map (or a dictionary in Python) is the ideal temporary data structure for this task.\nLet's consider an arbitrary row $r$. We can iterate through its entries from index $i = \\text{rowptr}[r]$ to $\\text{rowptr}[r+1]-1$. For each entry, we use its column index, $\\text{colind}[i]$, as a key in our hash map and add its value, $\\text{val}[i]$, to the value associated with that key. If the key is not yet in the map, it is initialized with the entry's value. This process correctly accumulates all values for each unique column index, satisfying the principle of linear superposition. The problem statement constrains temporary workspace to be proportional to the number of entries in a single row. A hash map for one row satisfies this, as its size is bounded by the number of non-zero entries in that row.\n\n#### Sorting and Compaction\nAfter summing all duplicates for row $r$, the problem requires that the resulting unique column indices be sorted in ascending order. We extract the keys (unique column indices) from the hash map and sort them.\n\nThe final and most critical step is the in-place compaction. We must overwrite the existing $\\text{colind}$ and $\\text{val}$ arrays with the new, compacted data. This is achieved by maintaining a single `write_idx` pointer, initialized to $0$, which tracks the position of the next available slot in the $\\text{colind}$ and $\\text{val}$ arrays.\n\nThe algorithm proceeds as follows:\n1. Initialize a write pointer: `write_idx` = $0$.\n2. Create a copy of the original $\\text{rowptr}$ array. This is necessary because we will be overwriting $\\text{rowptr}$ as we proceed, but we need the original pointers to locate the data for each row.\n3. For each row $r$ from $0$ to $n-1$:\n    a. Update the new row pointer for the current row: $\\text{rowptr}[r] = \\text{write\\_idx}$.\n    b. Using the *original* row pointers, identify the slice of data for row $r$.\n    c. Populate a temporary hash map to sum values for duplicate column indices, as described above.\n    d. Extract the unique column indices from the hash map and sort them.\n    e. For each sorted unique column $c_{unique}$ and its summed value $v_{sum}$:\n        i.  Write to the compacted arrays: $\\text{colind}[\\text{write\\_idx}] = c_{unique}$ and $\\text{val}[\\text{write\\_idx}] = v_{sum}$.\n        ii. Increment the write pointer: `write_idx` = `write_idx` $+ 1$.\n4. After the loop completes, set the final entry in the row-pointer array: $\\text{rowptr}[n] = \\text{write\\_idx}$.\n5. The valid data now occupies the slices $\\text{colind}[0:\\text{write\\_idx}]$ and $\\text{val}[0:\\text{write\\_idx}]$. The remainder of these arrays can be truncated.\n\n#### Proof of Correctness for In-Place Operation\nThe correctness of the in-place write-back hinges on the guarantee that the write operations for a given row do not overwrite data from subsequent rows that have not yet been read.\nLet $\\text{rowptr}_{orig}$ be the original row pointer array and $\\text{rowptr}_{new}$ be the new, updated array.\nFor any row $r$, the algorithm reads data from the index range $[\\text{rowptr}_{orig}[r], \\text{rowptr}_{orig}[r+1]-1]$.\nIt writes the new, compacted data for row $r$ into the index range starting at $\\text{rowptr}_{new}[r]$.\nThe position $\\text{rowptr}_{new}[r]$ is the sum of the number of unique non-zero entries in all preceding rows $k  r$:\n$$ \\text{rowptr}_{new}[r] = \\sum_{k=0}^{r-1} (\\text{number of unique entries in row } k) $$\nThe position $\\text{rowptr}_{orig}[r]$ is the sum of the total number of non-zero entries (including duplicates) in all preceding rows $k  r$:\n$$ \\text{rowptr}_{orig}[r] = \\sum_{k=0}^{r-1} (\\text{total number of entries in row } k) $$\nFor any row $k$, the number of unique entries is less than or equal to the total number of entries. Therefore, term by term, we have:\n$$ (\\text{number of unique entries in row } k) \\le (\\text{total number of entries in row } k) $$\nSumming over all rows $k$ from $0$ to $r-1$ gives:\n$$ \\sum_{k=0}^{r-1} (\\text{number of unique entries in row } k) \\le \\sum_{k=0}^{r-1} (\\text{total number of entries in row } k) $$\nThis directly implies:\n$$ \\text{rowptr}_{new}[r] \\le \\text{rowptr}_{orig}[r] $$\nThis inequality proves that the starting write-position for row $r$ is always less than or equal to the starting read-position for row $r$. Since we are processing rows sequentially, the block of data being written for row $r$ will never overtake and corrupt the block of data that needs to be read for row $r$ or any subsequent row. The algorithm is therefore correct and safe.\n\nThe problem requires that entries summing to $0$ be retained. The described algorithm naturally handles this, as the hash map will store a value of $0.0$ for any column index whose contributions sum to zero, and this entry will be written back to the compacted arrays like any other.\n\nThis step-by-step, row-wise, in-place compaction algorithm is correct, efficient, and adheres to all constraints specified in the problem statement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef sum_duplicates_csr(n, rowptr, colind, val):\n    \"\"\"\n    Performs in-place summation of duplicate entries and compaction of a CSR matrix.\n\n    This algorithm processes a CSR-formatted sparse matrix to sum entries with\n    duplicate column indices within each row. It operates in-place on the\n    provided `colind` and `val` lists and the `rowptr` numpy array.\n\n    Args:\n        n (int): The number of rows in the matrix.\n        rowptr (np.ndarray): The row pointer array of shape (n + 1). Modified in-place.\n        colind (list): The column index list. Modified in-place.\n        val (list): The value list. Modified in-place.\n    \"\"\"\n    write_idx = 0\n    # A copy of the original rowptr is needed to know where the original data for each row is.\n    original_rowptr = list(rowptr)\n\n    for r in range(n):\n        # The new row will start at the current write position.\n        rowptr[r] = write_idx\n\n        # Get the slice of the original data for the current row.\n        start = original_rowptr[r]\n        end = original_rowptr[r+1]\n        \n        # Use a dictionary as a temporary workspace to sum duplicates.\n        # This workspace is proportional to the number of entries in the current row.\n        summed_entries = {}\n        for i in range(start, end):\n            col = colind[i]\n            v = val[i]\n            summed_entries[col] = summed_entries.get(col, 0.0) + v\n\n        # The problem requires the final column indices to be sorted within each row.\n        unique_cols = sorted(summed_entries.keys())\n\n        # Write the compacted, sorted, and summed data back into the arrays.\n        # The write_idx is always = the read index `i` from the original data,\n        # so we never overwrite data we haven't processed yet.\n        for col in unique_cols:\n            colind[write_idx] = col\n            val[write_idx] = summed_entries[col]\n            write_idx += 1\n            \n    # Set the final entry of rowptr.\n    rowptr[n] = write_idx\n\n    # Truncate the colind and val lists to their new, compacted size.\n    del colind[write_idx:]\n    del val[write_idx:]\n\n\ndef solve():\n    \"\"\"\n    Defines the test suite, runs the algorithm, and prints the results.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (general case with duplicates and an empty row)\n        {\n            \"n\": 4,\n            \"rowptr\": [0, 4, 6, 6, 7],\n            \"colind\": [0, 2, 0, 1, 2, 2, 3],\n            \"val\": [1.0, 2.5, -0.5, 3.0, 4.0, -1.0, 7.0],\n            \"expected_rowptr\": [0, 3, 4, 4, 5],\n            \"expected_colind\": [0, 1, 2, 2, 3],\n            \"expected_val\": [0.5, 3.0, 2.5, 3.0, 7.0],\n        },\n        # Test case 2 (no duplicates, unsorted columns within rows)\n        {\n            \"n\": 2,\n            \"rowptr\": [0, 2, 3],\n            \"colind\": [3, 1, 0],\n            \"val\": [1.0, 2.0, 5.0],\n            \"expected_rowptr\": [0, 2, 3],\n            \"expected_colind\": [1, 3, 0],\n            \"expected_val\": [2.0, 1.0, 5.0],\n        },\n        # Test case 3 (single row with heavy duplication)\n        {\n            \"n\": 1,\n            \"rowptr\": [0, 7],\n            \"colind\": [2, 2, 2, 2, 2, 0, 0],\n            \"val\": [1.0, 1.0, -2.0, 0.5, 3.5, 10.0, -3.0],\n            \"expected_rowptr\": [0, 2],\n            \"expected_colind\": [0, 2],\n            \"expected_val\": [7.0, 4.0],\n        },\n        # Test case 4 (summations to zero retained)\n        {\n            \"n\": 3,\n            \"rowptr\": [0, 3, 4, 4],\n            \"colind\": [1, 1, 2, 0],\n            \"val\": [2.0, -2.0, 1.0, 0.0],\n            \"expected_rowptr\": [0, 2, 3, 3],\n            \"expected_colind\": [1, 2, 0],\n            \"expected_val\": [0.0, 1.0, 0.0],\n        },\n        # Test case 5 (mixed duplicates across multiple rows)\n        {\n            \"n\": 3,\n            \"rowptr\": [0, 6, 9, 11],\n            \"colind\": [0, 1, 2, 2, 1, 5, 3, 3, 4, 0, 0],\n            \"val\": [1.0, 2.0, 3.0, -1.0, 0.5, 10.0, 7.0, -7.0, 1.0, -1.0, 1.0],\n            \"expected_rowptr\": [0, 4, 6, 7],\n            \"expected_colind\": [0, 1, 2, 5, 3, 4, 0],\n            \"expected_val\": [1.0, 2.5, 2.0, 10.0, 0.0, 1.0, 0.0],\n        },\n    ]\n\n    results = []\n    \n    # Process each test case\n    for case in test_cases:\n        # Create copies of data to be modified in-place\n        n_in = case[\"n\"]\n        rowptr_in = np.array(case[\"rowptr\"], dtype=np.int64)\n        colind_in = list(case[\"colind\"])\n        val_in = list(case[\"val\"])\n        \n        sum_duplicates_csr(n_in, rowptr_in, colind_in, val_in)\n        \n        # Compare results with expected values\n        expected_rowptr = np.array(case[\"expected_rowptr\"], dtype=np.int64)\n        expected_colind = np.array(case[\"expected_colind\"], dtype=np.int64)\n        expected_val = np.array(case[\"expected_val\"], dtype=float)\n\n        rowptr_match = np.array_equal(rowptr_in, expected_rowptr)\n        colind_match = np.array_equal(np.array(colind_in, dtype=np.int64), expected_colind)\n        # Use absolute tolerance for floating point comparison, robust for values close to zero.\n        val_match = np.allclose(np.array(val_in, dtype=float), expected_val, atol=1e-12, rtol=0)\n        \n        results.append(rowptr_match and colind_match and val_match)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\".replace(\"True\", \"true\").replace(\"False\", \"false\"))\n\nsolve()\n```"
        }
    ]
}