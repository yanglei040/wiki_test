{
    "hands_on_practices": [
        {
            "introduction": "The Conjugate Gradient method is exceptionally effective for linear systems $\\boldsymbol{A}\\boldsymbol{x}=\\boldsymbol{b}$ where the matrix $\\boldsymbol{A}$ is Symmetric Positive Definite (SPD). A key reason for its prevalence in computational solid mechanics is that stiffness matrices derived from stable finite element models naturally possess this property. This exercise grounds the abstract requirement of positive-definiteness in a physical context, guiding you through the assembly of a stiffness matrix for a simple elastic bar and the verification of its SPD nature through its eigenvalues .",
            "id": "3550398",
            "problem": "Consider a small-strain, one-dimensional linear elastic bar of total length $2h$, Young’s modulus $E>0$, and constant cross-sectional area $A>0$. The bar is discretized into $2$ linear, two-node finite elements with nodes located at $x_{0}=0$, $x_{1}=h$, and $x_{2}=2h$. Impose a homogeneous Dirichlet boundary condition $u(0)=0$ at $x=0$ and a traction-free natural boundary at $x=2h$. The finite element approximation uses standard linear shape functions on each element.\n\nStarting from the fundamental principle that the internal elastic energy of the bar is given by\n$$\n\\Pi_{\\text{int}}(u)=\\frac{1}{2}\\int_{0}^{2h}EA\\left(\\frac{du}{dx}\\right)^{2}\\,dx,\n$$\nand using the Galerkin procedure for the weak form of axial equilibrium along with the definitions of the element-level shape functions and their spatial derivatives, do the following:\n- Derive the consistent $2\\times 2$ element stiffness matrix for a generic element of length $h$ in terms of $E$ and $A$.\n- Assemble the global stiffness matrix for the three-node mesh and then apply the Dirichlet boundary condition at $x=0$ to obtain the reduced $2\\times 2$ global stiffness matrix associated with the unknown nodal displacements at $x=h$ and $x=2h$.\n- Compute the eigenvalues of the reduced $2\\times 2$ global stiffness matrix in closed form and use them to justify that the matrix is symmetric positive definite, ensuring convergence of the Conjugate Gradient (CG) method within the Krylov subspace framework for this problem.\n\nExpress the final eigenvalues as closed-form analytic expressions in terms of $E$, $A$, and $h$. No numerical substitution or rounding is required. Provide your final answer as the pair of eigenvalues.",
            "solution": "The problem is governed by linear elasticity in one dimension under small strain. The internal elastic energy functional is\n$$\n\\Pi_{\\text{int}}(u)=\\frac{1}{2}\\int_{0}^{2h}EA\\left(\\frac{du}{dx}\\right)^{2}\\,dx,\n$$\nwhere $E>0$ is the Young’s modulus and $A>0$ is the cross-sectional area. The weak form of axial equilibrium can be derived by requiring the first variation of the total potential energy to vanish for all admissible variations:\n$$\n\\delta \\Pi_{\\text{int}}(u)=\\int_{0}^{2h}EA\\left(\\frac{du}{dx}\\right)\\left(\\frac{d\\,\\delta u}{dx}\\right)\\,dx=0,\n$$\nin the absence of body forces and with a traction-free boundary at $x=2h$. Using the Galerkin method and a finite element approximation $u(x)\\approx \\sum_{i}N_{i}(x)u_{i}$ with linear shape functions, the element stiffness entries follow from\n$$\nk^{(e)}_{ij}=\\int_{x_{e}}^{x_{e}+h}EA\\,\\frac{dN_{i}}{dx}\\,\\frac{dN_{j}}{dx}\\,dx,\n$$\nfor a generic element $e$ spanning $[x_{e},x_{e}+h]$.\n\nFor a linear two-node element on $[x_{e},x_{e}+h]$, the shape functions are\n$$\nN_{1}(x)=\\frac{x_{e}+h-x}{h},\\qquad N_{2}(x)=\\frac{x-x_{e}}{h},\n$$\nand their spatial derivatives are constant over the element:\n$$\n\\frac{dN_{1}}{dx}=-\\frac{1}{h},\\qquad \\frac{dN_{2}}{dx}=\\frac{1}{h}.\n$$\nTherefore,\n$$\nk^{(e)}_{11}=\\int_{x_{e}}^{x_{e}+h}EA\\left(-\\frac{1}{h}\\right)\\left(-\\frac{1}{h}\\right)\\,dx=\\frac{EA}{h},\\quad\nk^{(e)}_{12}=\\int_{x_{e}}^{x_{e}+h}EA\\left(-\\frac{1}{h}\\right)\\left(\\frac{1}{h}\\right)\\,dx=-\\frac{EA}{h},\n$$\n$$\nk^{(e)}_{21}=\\int_{x_{e}}^{x_{e}+h}EA\\left(\\frac{1}{h}\\right)\\left(-\\frac{1}{h}\\right)\\,dx=-\\frac{EA}{h},\\quad\nk^{(e)}_{22}=\\int_{x_{e}}^{x_{e}+h}EA\\left(\\frac{1}{h}\\right)\\left(\\frac{1}{h}\\right)\\,dx=\\frac{EA}{h}.\n$$\nHence, the consistent element stiffness matrix is\n$$\n\\boldsymbol{K}^{(e)}=\\frac{EA}{h}\\begin{bmatrix}1 & -1 \\\\ -1 & 1\\end{bmatrix}.\n$$\n\nWe now assemble the global stiffness matrix for the mesh with nodes $x_{0}=0$, $x_{1}=h$, and $x_{2}=2h$. Element $1$ connects nodes $(0,1)$, and element $2$ connects nodes $(1,2)$. Assembling the contributions yields the global $3\\times 3$ stiffness matrix\n$$\n\\boldsymbol{K}=\\frac{EA}{h}\\begin{bmatrix}\n1 & -1 & 0 \\\\\n-1 & 2 & -1 \\\\\n0 & -1 & 1\n\\end{bmatrix}.\n$$\nThe homogeneous Dirichlet boundary condition $u(0)=0$ eliminates the degree of freedom at node $0$, producing the reduced $2\\times 2$ global stiffness matrix associated with unknown displacements at nodes $1$ and $2$:\n$$\n\\boldsymbol{K}_{r}=\\frac{EA}{h}\\begin{bmatrix}\n2 & -1 \\\\\n-1 & 1\n\\end{bmatrix}.\n$$\n\nTo verify symmetric positive definiteness and to connect with the convergence guarantees for the Conjugate Gradient (CG) method in Krylov subspace methods, we compute the eigenvalues of $\\boldsymbol{K}_{r}$. Let\n$$\n\\boldsymbol{M}=\\begin{bmatrix}\n2 & -1 \\\\\n-1 & 1\n\\end{bmatrix}.\n$$\nThe characteristic polynomial of $\\boldsymbol{M}$ is\n$$\np(\\lambda)=\\det(\\boldsymbol{M}-\\lambda \\boldsymbol{I})=\\det\\begin{bmatrix}2-\\lambda & -1 \\\\ -1 & 1-\\lambda\\end{bmatrix}=(2-\\lambda)(1-\\lambda)-1=\\lambda^{2}-3\\lambda+1.\n$$\nThe eigenvalues of $\\boldsymbol{M}$ are the roots of $p(\\lambda)=0$:\n$$\n\\lambda_{1,2}=\\frac{3\\pm\\sqrt{9-4}}{2}=\\frac{3\\pm\\sqrt{5}}{2}.\n$$\nTherefore, the eigenvalues of $\\boldsymbol{K}_{r}=(EA/h)\\,\\boldsymbol{M}$ are\n$$\n\\mu_{1}=\\frac{EA}{h}\\cdot\\frac{3-\\sqrt{5}}{2},\\qquad \\mu_{2}=\\frac{EA}{h}\\cdot\\frac{3+\\sqrt{5}}{2}.\n$$\nSince $E>0$, $A>0$, $h>0$, and both $(3\\pm\\sqrt{5})/2>0$, we have $\\mu_{1}>0$ and $\\mu_{2}>0$. Hence, $\\boldsymbol{K}_{r}$ is symmetric positive definite. This property guarantees that the Conjugate Gradient (CG) method, which is a Krylov subspace method specialized for symmetric positive definite systems, will converge for this discretized problem, with its rate influenced by the condition number $\\kappa(\\boldsymbol{K}_{r})=\\mu_{2}/\\mu_{1}$.\n\nThe required closed-form eigenvalues are thus given explicitly in terms of $E$, $A$, and $h$ as above.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\dfrac{EA}{2h}\\left(3-\\sqrt{5}\\right) & \\dfrac{EA}{2h}\\left(3+\\sqrt{5}\\right)\\end{pmatrix}}$$"
        },
        {
            "introduction": "Krylov subspace methods, including Conjugate Gradient, build an approximate solution from a special, incrementally constructed subspace. This \"Krylov subspace,\" denoted $\\mathcal{K}_{k}(\\boldsymbol{A}, \\boldsymbol{r}_{0})$, is the heart of the method, defining the search space for the optimal solution at each iteration. This practice provides a direct, hands-on opportunity to construct the fundamental basis vectors $\\{\\boldsymbol{r}_0, \\boldsymbol{A}\\boldsymbol{r}_0, \\boldsymbol{A}^2\\boldsymbol{r}_0, \\dots\\}$ that span this subspace for a small system, solidifying your intuition for where the CG iterates live .",
            "id": "3550446",
            "problem": "In small-strain linear elasticity, the Finite Element Method (FEM) yields a linear system of the form $\\boldsymbol{A}\\boldsymbol{x} = \\boldsymbol{b}$, where $\\boldsymbol{A}$ is the symmetric stiffness matrix of the discretized structure, $\\boldsymbol{x}$ is the vector of nodal displacements, and $\\boldsymbol{b}$ is the nodal force vector. For a stable structure with appropriate essential boundary conditions, the stiffness matrix $\\boldsymbol{A}$ is Symmetric Positive Definite (SPD). Krylov subspace methods, such as the Conjugate Gradient (CG) method, construct iterates in the Krylov subspace generated by the residual $\\boldsymbol{r}_{0} = \\boldsymbol{b} - \\boldsymbol{A} \\boldsymbol{x}_{0}$.\n\nConsider a $3 \\times 3$ SPD stiffness matrix arising from a three-degree-of-freedom discretization,\n$$\n\\boldsymbol{A} = \\begin{pmatrix}\n4 & 1 & 0 \\\\\n1 & 3 & 1 \\\\\n0 & 1 & 2\n\\end{pmatrix},\n$$\na nodal force vector\n$$\n\\boldsymbol{b} = \\begin{pmatrix}\n1 \\\\\n2 \\\\\n3\n\\end{pmatrix},\n$$\nand the initial guess $\\boldsymbol{x}_{0} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$.\n\nUsing only fundamental definitions, do the following:\n1. Compute the initial residual $\\boldsymbol{r}_{0} = \\boldsymbol{b} - \\boldsymbol{A} \\boldsymbol{x}_{0}$.\n2. Using the definition of the Krylov subspace, explicitly construct a basis for $\\mathcal{K}_{3}(\\boldsymbol{A}, \\boldsymbol{r}_{0})$.\n3. Form the $3 \\times 3$ Gram matrix of these three vectors and assess their linear independence through a determinant-based criterion.\n\nReport as your final answer the determinant of the Gram matrix you formed in step 3. No rounding is required. The final answer must be presented as a single real number with no units.",
            "solution": "The problem is validated as scientifically grounded, well-posed, objective, complete, and consistent. The matrix $\\boldsymbol{A}$ is symmetric, and its positive definiteness is confirmed by Sylvester's criterion, as its leading principal minors are all positive: $4 > 0$, $4(3)-1(1) = 11 > 0$, and $\\det(\\boldsymbol{A}) = 4(3 \\cdot 2 - 1 \\cdot 1) - 1(1 \\cdot 2 - 1 \\cdot 0) = 4(5) - 2 = 18 > 0$. All conditions for a valid problem are met.\n\nThe solution proceeds in three steps as requested by the problem statement.\n\nStep 1: Compute the initial residual $\\boldsymbol{r}_{0}$.\nThe initial residual $\\boldsymbol{r}_{0}$ is defined as $\\boldsymbol{r}_{0} = \\boldsymbol{b} - \\boldsymbol{A} \\boldsymbol{x}_{0}$. We are given the nodal force vector $\\boldsymbol{b}$ and the initial guess for the displacement vector $\\boldsymbol{x}_{0}$.\n$$\n\\boldsymbol{b} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}, \\quad \\boldsymbol{x}_{0} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThe product $\\boldsymbol{A} \\boldsymbol{x}_{0}$ is:\n$$\n\\boldsymbol{A} \\boldsymbol{x}_{0} = \\begin{pmatrix} 4 & 1 & 0 \\\\ 1 & 3 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nTherefore, the initial residual is:\n$$\n\\boldsymbol{r}_{0} = \\boldsymbol{b} - \\boldsymbol{A} \\boldsymbol{x}_{0} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}\n$$\n\nStep 2: Construct a basis for the Krylov subspace $\\mathcal{K}_{3}(\\boldsymbol{A}, \\boldsymbol{r}_{0})$.\nThe Krylov subspace $\\mathcal{K}_{k}(\\boldsymbol{A}, \\boldsymbol{r})$ is defined as the span of the vectors $\\{\\boldsymbol{r}, \\boldsymbol{A}\\boldsymbol{r}, \\boldsymbol{A}^2\\boldsymbol{r}, \\dots, \\boldsymbol{A}^{k-1}\\boldsymbol{r}\\}$. For our case, $k=3$ and the generating vector is $\\boldsymbol{r}_{0}$. The standard basis for $\\mathcal{K}_{3}(\\boldsymbol{A}, \\boldsymbol{r}_{0})$ is the set of vectors $\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\boldsymbol{v}_3\\}$ where $\\boldsymbol{v}_1 = \\boldsymbol{r}_0$, $\\boldsymbol{v}_2 = \\boldsymbol{A}\\boldsymbol{r}_0$, and $\\boldsymbol{v}_3 = \\boldsymbol{A}^2\\boldsymbol{r}_0$.\n\nThe first basis vector is $\\boldsymbol{v}_1 = \\boldsymbol{r}_0$.\n$$\n\\boldsymbol{v}_1 = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}\n$$\nThe second basis vector is $\\boldsymbol{v}_2 = \\boldsymbol{A} \\boldsymbol{v}_1$.\n$$\n\\boldsymbol{v}_2 = \\boldsymbol{A} \\boldsymbol{r}_{0} = \\begin{pmatrix} 4 & 1 & 0 \\\\ 1 & 3 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 4(1) + 1(2) + 0(3) \\\\ 1(1) + 3(2) + 1(3) \\\\ 0(1) + 1(2) + 2(3) \\end{pmatrix} = \\begin{pmatrix} 6 \\\\ 10 \\\\ 8 \\end{pmatrix}\n$$\nThe third basis vector is $\\boldsymbol{v}_3 = \\boldsymbol{A}^2 \\boldsymbol{r}_{0} = \\boldsymbol{A} (\\boldsymbol{A} \\boldsymbol{r}_{0}) = \\boldsymbol{A} \\boldsymbol{v}_2$.\n$$\n\\boldsymbol{v}_3 = \\boldsymbol{A} \\boldsymbol{v}_{2} = \\begin{pmatrix} 4 & 1 & 0 \\\\ 1 & 3 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix} \\begin{pmatrix} 6 \\\\ 10 \\\\ 8 \\end{pmatrix} = \\begin{pmatrix} 4(6) + 1(10) + 0(8) \\\\ 1(6) + 3(10) + 1(8) \\\\ 0(6) + 1(10) + 2(8) \\end{pmatrix} = \\begin{pmatrix} 24+10 \\\\ 6+30+8 \\\\ 10+16 \\end{pmatrix} = \\begin{pmatrix} 34 \\\\ 44 \\\\ 26 \\end{pmatrix}\n$$\nThus, the constructed basis for $\\mathcal{K}_{3}(\\boldsymbol{A}, \\boldsymbol{r}_{0})$ is $\\left\\{ \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}, \\begin{pmatrix} 6 \\\\ 10 \\\\ 8 \\end{pmatrix}, \\begin{pmatrix} 34 \\\\ 44 \\\\ 26 \\end{pmatrix} \\right\\}$.\n\nStep 3: Form the Gram matrix and compute its determinant.\nThe Gram matrix $\\boldsymbol{G}$ of a set of vectors $\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\boldsymbol{v}_3\\}$ is given by $G_{ij} = \\boldsymbol{v}_i^{\\mathsf{T}} \\boldsymbol{v}_j$, which is the matrix of inner products (dot products).\n$$\n\\boldsymbol{G} = \\begin{pmatrix} \\boldsymbol{v}_1^{\\mathsf{T}} \\boldsymbol{v}_1 & \\boldsymbol{v}_1^{\\mathsf{T}} \\boldsymbol{v}_2 & \\boldsymbol{v}_1^{\\mathsf{T}} \\boldsymbol{v}_3 \\\\ \\boldsymbol{v}_2^{\\mathsf{T}} \\boldsymbol{v}_1 & \\boldsymbol{v}_2^{\\mathsf{T}} \\boldsymbol{v}_2 & \\boldsymbol{v}_2^{\\mathsf{T}} \\boldsymbol{v}_3 \\\\ \\boldsymbol{v}_3^{\\mathsf{T}} \\boldsymbol{v}_1 & \\boldsymbol{v}_3^{\\mathsf{T}} \\boldsymbol{v}_2 & \\boldsymbol{v}_3^{\\mathsf{T}} \\boldsymbol{v}_3 \\end{pmatrix}\n$$\nWe compute the individual elements:\n$\\boldsymbol{v}_1^{\\mathsf{T}} \\boldsymbol{v}_1 = (1)^2 + (2)^2 + (3)^2 = 1+4+9 = 14$.\n$\\boldsymbol{v}_1^{\\mathsf{T}} \\boldsymbol{v}_2 = (1)(6) + (2)(10) + (3)(8) = 6+20+24 = 50$.\n$\\boldsymbol{v}_1^{\\mathsf{T}} \\boldsymbol{v}_3 = (1)(34) + (2)(44) + (3)(26) = 34+88+78 = 200$.\n$\\boldsymbol{v}_2^{\\mathsf{T}} \\boldsymbol{v}_2 = (6)^2 + (10)^2 + (8)^2 = 36+100+64 = 200$.\n$\\boldsymbol{v}_2^{\\mathsf{T}} \\boldsymbol{v}_3 = (6)(34) + (10)(44) + (8)(26) = 204+440+208 = 852$.\n$\\boldsymbol{v}_3^{\\mathsf{T}} \\boldsymbol{v}_3 = (34)^2 + (44)^2 + (26)^2 = 1156+1936+676 = 3768$.\n\nDue to the symmetry of the inner product ($\\boldsymbol{v}_i^{\\mathsf{T}} \\boldsymbol{v}_j = \\boldsymbol{v}_j^{\\mathsf{T}} \\boldsymbol{v}_i$), the Gram matrix is symmetric:\n$$\n\\boldsymbol{G} = \\begin{pmatrix} 14 & 50 & 200 \\\\ 50 & 200 & 852 \\\\ 200 & 852 & 3768 \\end{pmatrix}\n$$\nThe determinant of the Gram matrix, $\\det(\\boldsymbol{G})$, is a criterion for linear independence. The vectors are linearly independent if and only if $\\det(\\boldsymbol{G}) \\neq 0$. A powerful property relates the Gram determinant to the determinant of the matrix formed by the vectors as columns. Let $\\boldsymbol{V} = \\begin{pmatrix} \\boldsymbol{v}_1 & \\boldsymbol{v}_2 & \\boldsymbol{v}_3 \\end{pmatrix}$. Then $\\det(\\boldsymbol{G}) = (\\det(\\boldsymbol{V}))^2$.\n$$\n\\boldsymbol{V} = \\begin{pmatrix} 1 & 6 & 34 \\\\ 2 & 10 & 44 \\\\ 3 & 8 & 26 \\end{pmatrix}\n$$\nWe compute the determinant of $\\boldsymbol{V}$ using cofactor expansion along the first row:\n$$\n\\det(\\boldsymbol{V}) = 1 \\cdot \\det\\begin{pmatrix} 10 & 44 \\\\ 8 & 26 \\end{pmatrix} - 6 \\cdot \\det\\begin{pmatrix} 2 & 44 \\\\ 3 & 26 \\end{pmatrix} + 34 \\cdot \\det\\begin{pmatrix} 2 & 10 \\\\ 3 & 8 \\end{pmatrix}\n$$\n$$\n\\det(\\boldsymbol{V}) = 1(10 \\cdot 26 - 44 \\cdot 8) - 6(2 \\cdot 26 - 44 \\cdot 3) + 34(2 \\cdot 8 - 10 \\cdot 3)\n$$\n$$\n\\det(\\boldsymbol{V}) = 1(260 - 352) - 6(52 - 132) + 34(16 - 30)\n$$\n$$\n\\det(\\boldsymbol{V}) = 1(-92) - 6(-80) + 34(-14) = -92 + 480 - 476 = -88\n$$\nThe determinant of the Gram matrix is the square of this value:\n$$\n\\det(\\boldsymbol{G}) = (\\det(\\boldsymbol{V}))^2 = (-88)^2 = 7744\n$$\nSince $\\det(\\boldsymbol{G}) = 7744 \\neq 0$, the vectors $\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\boldsymbol{v}_3\\}$ are linearly independent and form a basis for $\\mathbb{R}^3$. This is expected, as the dimension of the Krylov subspace $\\mathcal{K}_n(\\boldsymbol{A},\\boldsymbol{r}_0)$ is $n$ for a non-derogatory matrix $\\boldsymbol{A}$ of size $n \\times n$ and a suitable starting vector $\\boldsymbol{r}_0$. The determinant of the Gram matrix is the final answer requested.",
            "answer": "$$\n\\boxed{7744}\n$$"
        },
        {
            "introduction": "With an understanding of SPD matrices and the Krylov subspace, we can now dissect the Conjugate Gradient algorithm itself. This exercise provides a step-by-step walkthrough of the first two iterations, allowing you to compute the residuals, step-sizes, and A-conjugate search directions that drive the method's convergence. By explicitly verifying the A-conjugacy of the search directions, you will witness the core mechanism that ensures CG finds the optimal solution within the subspace at each step .",
            "id": "3550427",
            "problem": "In a small-strain linear elasticity boundary value problem discretized by the Finite Element Method (FEM), the equilibrium equations reduce to a symmetric positive definite (SPD) linear system of the form $\\boldsymbol{A}\\boldsymbol{x} = \\boldsymbol{b}$, where $\\boldsymbol{A}$ is the global stiffness matrix and $\\boldsymbol{b}$ is the load vector. The solution $\\boldsymbol{x}$ minimizes the quadratic potential energy functional $E(\\boldsymbol{x}) = \\tfrac{1}{2} \\boldsymbol{x}^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{x} - \\boldsymbol{b}^{\\mathsf{T}} \\boldsymbol{x}$. The Conjugate Gradient (CG) method constructs iterates by minimizing this functional over successive Krylov subspaces generated by the initial residual and $\\boldsymbol{A}$ under the Euclidean inner product. \n\nConsider the unpreconditioned CG method applied to the SPD system with \n$$\n\\boldsymbol{A} = \\begin{pmatrix}\n4 & 1 & 0 \\\\\n1 & 3 & 1 \\\\\n0 & 1 & 2\n\\end{pmatrix}, \n\\quad\n\\boldsymbol{b} = \\begin{pmatrix}\n4 \\\\\n2 \\\\\n2\n\\end{pmatrix},\n\\quad\n\\boldsymbol{x}_0 = \\begin{pmatrix}\n0 \\\\\n0 \\\\\n0\n\\end{pmatrix}.\n$$\nUse the standard unpreconditioned Conjugate Gradient (CG) method (with $\\boldsymbol{p}_0 = \\boldsymbol{r}_0$ and the Euclidean inner product) to execute exactly two iterations. Compute the first and second iterates $\\boldsymbol{x}_1$ and $\\boldsymbol{x}_2$, the corresponding residuals $\\boldsymbol{r}_1$ and $\\boldsymbol{r}_2$, and verify the $A$-conjugacy condition $\\boldsymbol{p}_0^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{p}_1 = 0$ for the first two search directions $\\boldsymbol{p}_0$ and $\\boldsymbol{p}_1$. \n\nFinally, report the value of $\\boldsymbol{p}_0^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{p}_1$ as your single numerical answer. No rounding is required.",
            "solution": "The problem is well-posed, scientifically grounded, and contains all necessary information to proceed. The matrix $\\boldsymbol{A}$ is symmetric, and its positive definiteness can be confirmed by verifying that its leading principal minors are positive:\n$D_1 = \\det([4]) = 4 > 0$.\n$D_2 = \\det \\begin{pmatrix} 4 & 1 \\\\ 1 & 3 \\end{pmatrix} = 4(3) - 1(1) = 11 > 0$.\n$D_3 = \\det(\\boldsymbol{A}) = 4(3 \\cdot 2 - 1 \\cdot 1) - 1(1 \\cdot 2 - 1 \\cdot 0) = 4(5) - 1(2) = 18 > 0$.\nSince all leading principal minors are positive, the matrix $\\boldsymbol{A}$ is symmetric positive definite (SPD), which is a prerequisite for the standard Conjugate Gradient (CG) method. The problem is therefore valid.\n\nThe unpreconditioned CG algorithm for solving $\\boldsymbol{A} \\boldsymbol{x} = \\boldsymbol{b}$ with an initial guess $\\boldsymbol{x}_0$ is as follows:\nInitialize:\n$\\boldsymbol{r}_0 = \\boldsymbol{b} - \\boldsymbol{A} \\boldsymbol{x}_0$\n$\\boldsymbol{p}_0 = \\boldsymbol{r}_0$\nFor $k=0, 1, 2, \\dots$\n$\\alpha_k = \\frac{\\boldsymbol{r}_k^{\\mathsf{T}} \\boldsymbol{r}_k}{\\boldsymbol{p}_k^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{p}_k}$\n$\\boldsymbol{x}_{k+1} = \\boldsymbol{x}_k + \\alpha_k \\boldsymbol{p}_k$\n$\\boldsymbol{r}_{k+1} = \\boldsymbol{r}_k - \\alpha_k \\boldsymbol{A} \\boldsymbol{p}_k$\n$\\beta_k = \\frac{\\boldsymbol{r}_{k+1}^{\\mathsf{T}} \\boldsymbol{r}_{k+1}}{\\boldsymbol{r}_k^{\\mathsf{T}} \\boldsymbol{r}_k}$\n$\\boldsymbol{p}_{k+1} = \\boldsymbol{r}_{k+1} + \\beta_k \\boldsymbol{p}_k$\n\nWe are given:\n$$\n\\boldsymbol{A} = \\begin{pmatrix}\n4 & 1 & 0 \\\\\n1 & 3 & 1 \\\\\n0 & 1 & 2\n\\end{pmatrix}, \n\\quad\n\\boldsymbol{b} = \\begin{pmatrix}\n4 \\\\\n2 \\\\\n2\n\\end{pmatrix},\n\\quad\n\\boldsymbol{x}_0 = \\begin{pmatrix}\n0 \\\\\n0 \\\\\n0\n\\end{pmatrix}\n$$\n\n**Iteration $k=0$**\n\n1.  Calculate the initial residual $\\boldsymbol{r}_0$:\n    $$\n    \\boldsymbol{r}_0 = \\boldsymbol{b} - \\boldsymbol{A} \\boldsymbol{x}_0 = \\begin{pmatrix} 4 \\\\ 2 \\\\ 2 \\end{pmatrix} - \\begin{pmatrix} 4 & 1 & 0 \\\\ 1 & 3 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 2 \\\\ 2 \\end{pmatrix}\n    $$\n2.  Set the initial search direction $\\boldsymbol{p}_0$:\n    $$\n    \\boldsymbol{p}_0 = \\boldsymbol{r}_0 = \\begin{pmatrix} 4 \\\\ 2 \\\\ 2 \\end{pmatrix}\n    $$\n3.  Calculate the step size $\\alpha_0$:\n    First, compute the numerator $\\boldsymbol{r}_0^{\\mathsf{T}} \\boldsymbol{r}_0$:\n    $$\n    \\boldsymbol{r}_0^{\\mathsf{T}} \\boldsymbol{r}_0 = \\begin{pmatrix} 4 & 2 & 2 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ 2 \\\\ 2 \\end{pmatrix} = 4^2 + 2^2 + 2^2 = 16 + 4 + 4 = 24\n    $$\n    Next, compute the denominator $\\boldsymbol{p}_0^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{p}_0$. We first need $\\boldsymbol{A} \\boldsymbol{p}_0$:\n    $$\n    \\boldsymbol{A} \\boldsymbol{p}_0 = \\begin{pmatrix} 4 & 1 & 0 \\\\ 1 & 3 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ 2 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 4(4) + 1(2) + 0(2) \\\\ 1(4) + 3(2) + 1(2) \\\\ 0(4) + 1(2) + 2(2) \\end{pmatrix} = \\begin{pmatrix} 18 \\\\ 12 \\\\ 6 \\end{pmatrix}\n    $$\n    Then, $\\boldsymbol{p}_0^{\\mathsf{T}} (\\boldsymbol{A} \\boldsymbol{p}_0)$:\n    $$\n    \\boldsymbol{p}_0^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{p}_0 = \\begin{pmatrix} 4 & 2 & 2 \\end{pmatrix} \\begin{pmatrix} 18 \\\\ 12 \\\\ 6 \\end{pmatrix} = 4(18) + 2(12) + 2(6) = 72 + 24 + 12 = 108\n    $$\n    The step size $\\alpha_0$ is:\n    $$\n    \\alpha_0 = \\frac{\\boldsymbol{r}_0^{\\mathsf{T}} \\boldsymbol{r}_0}{\\boldsymbol{p}_0^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{p}_0} = \\frac{24}{108} = \\frac{2}{9}\n    $$\n4.  Update the solution to get $\\boldsymbol{x}_1$:\n    $$\n    \\boldsymbol{x}_1 = \\boldsymbol{x}_0 + \\alpha_0 \\boldsymbol{p}_0 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} + \\frac{2}{9} \\begin{pmatrix} 4 \\\\ 2 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} \\frac{8}{9} \\\\ \\frac{4}{9} \\\\ \\frac{4}{9} \\end{pmatrix}\n    $$\n5.  Update the residual to get $\\boldsymbol{r}_1$:\n    $$\n    \\boldsymbol{r}_1 = \\boldsymbol{r}_0 - \\alpha_0 \\boldsymbol{A} \\boldsymbol{p}_0 = \\begin{pmatrix} 4 \\\\ 2 \\\\ 2 \\end{pmatrix} - \\frac{2}{9} \\begin{pmatrix} 18 \\\\ 12 \\\\ 6 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 2 \\\\ 2 \\end{pmatrix} - \\begin{pmatrix} 4 \\\\ \\frac{8}{3} \\\\ \\frac{4}{3} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 2 - \\frac{8}{3} \\\\ 2 - \\frac{4}{3} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\\\ \\frac{2}{3} \\end{pmatrix}\n    $$\n6.  Calculate $\\beta_0$ to find the next search direction:\n    First, compute $\\boldsymbol{r}_1^{\\mathsf{T}} \\boldsymbol{r}_1$:\n    $$\n    \\boldsymbol{r}_1^{\\mathsf{T}} \\boldsymbol{r}_1 = \\begin{pmatrix} 0 & -\\frac{2}{3} & \\frac{2}{3} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\\\ \\frac{2}{3} \\end{pmatrix} = 0^2 + \\left(-\\frac{2}{3}\\right)^2 + \\left(\\frac{2}{3}\\right)^2 = \\frac{4}{9} + \\frac{4}{9} = \\frac{8}{9}\n    $$\n    Then, $\\beta_0$:\n    $$\n    \\beta_0 = \\frac{\\boldsymbol{r}_1^{\\mathsf{T}} \\boldsymbol{r}_1}{\\boldsymbol{r}_0^{\\mathsf{T}} \\boldsymbol{r}_0} = \\frac{8/9}{24} = \\frac{8}{9 \\cdot 24} = \\frac{1}{27}\n    $$\n7.  Update the search direction to get $\\boldsymbol{p}_1$:\n    $$\n    \\boldsymbol{p}_1 = \\boldsymbol{r}_1 + \\beta_0 \\boldsymbol{p}_0 = \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\\\ \\frac{2}{3} \\end{pmatrix} + \\frac{1}{27} \\begin{pmatrix} 4 \\\\ 2 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{27} \\\\ -\\frac{18}{27} + \\frac{2}{27} \\\\ \\frac{18}{27} + \\frac{2}{27} \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{27} \\\\ -\\frac{16}{27} \\\\ \\frac{20}{27} \\end{pmatrix}\n    $$\n\nThis completes the first iteration. We have $\\boldsymbol{x}_1$, $\\boldsymbol{r}_1$, and $\\boldsymbol{p}_1$.\n\n**Iteration $k=1$**\n\n1.  Calculate the step size $\\alpha_1$:\n    The numerator is $\\boldsymbol{r}_1^{\\mathsf{T}} \\boldsymbol{r}_1 = \\frac{8}{9}$.\n    For the denominator, we first compute $\\boldsymbol{A} \\boldsymbol{p}_1$:\n    $$\n    \\boldsymbol{A} \\boldsymbol{p}_1 = \\begin{pmatrix} 4 & 1 & 0 \\\\ 1 & 3 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix} \\begin{pmatrix} \\frac{4}{27} \\\\ -\\frac{16}{27} \\\\ \\frac{20}{27} \\end{pmatrix} = \\frac{1}{27} \\begin{pmatrix} 4(4) + 1(-16) + 0(20) \\\\ 1(4) + 3(-16) + 1(20) \\\\ 0(4) + 1(-16) + 2(20) \\end{pmatrix} = \\frac{1}{27} \\begin{pmatrix} 0 \\\\ -24 \\\\ 24 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -\\frac{8}{9} \\\\ \\frac{8}{9} \\end{pmatrix}\n    $$\n    Then, $\\boldsymbol{p}_1^{\\mathsf{T}} (\\boldsymbol{A} \\boldsymbol{p}_1)$:\n    $$\n    \\boldsymbol{p}_1^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{p}_1 = \\begin{pmatrix} \\frac{4}{27} & -\\frac{16}{27} & \\frac{20}{27} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -\\frac{8}{9} \\\\ \\frac{8}{9} \\end{pmatrix} = \\frac{1}{27} \\left( 4(0) - 16\\left(-\\frac{8}{9}\\right) + 20\\left(\\frac{8}{9}\\right) \\right) = \\frac{1}{27} \\left( \\frac{128}{9} + \\frac{160}{9} \\right) = \\frac{1}{27} \\left( \\frac{288}{9} \\right) = \\frac{32}{27}\n    $$\n    The step size $\\alpha_1$ is:\n    $$\n    \\alpha_1 = \\frac{\\boldsymbol{r}_1^{\\mathsf{T}} \\boldsymbol{r}_1}{\\boldsymbol{p}_1^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{p}_1} = \\frac{8/9}{32/27} = \\frac{8}{9} \\cdot \\frac{27}{32} = \\frac{1}{1} \\cdot \\frac{3}{4} = \\frac{3}{4}\n    $$\n2.  Update the solution to get $\\boldsymbol{x}_2$:\n    $$\n    \\boldsymbol{x}_2 = \\boldsymbol{x}_1 + \\alpha_1 \\boldsymbol{p}_1 = \\begin{pmatrix} \\frac{8}{9} \\\\ \\frac{4}{9} \\\\ \\frac{4}{9} \\end{pmatrix} + \\frac{3}{4} \\begin{pmatrix} \\frac{4}{27} \\\\ -\\frac{16}{27} \\\\ \\frac{20}{27} \\end{pmatrix} = \\begin{pmatrix} \\frac{8}{9} \\\\ \\frac{4}{9} \\\\ \\frac{4}{9} \\end{pmatrix} + \\begin{pmatrix} \\frac{1}{9} \\\\ -\\frac{4}{9} \\\\ \\frac{5}{9} \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}\n    $$\n3.  Update the residual to get $\\boldsymbol{r}_2$:\n    $$\n    \\boldsymbol{r}_2 = \\boldsymbol{r}_1 - \\alpha_1 \\boldsymbol{A} \\boldsymbol{p}_1 = \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\\\ \\frac{2}{3} \\end{pmatrix} - \\frac{3}{4} \\begin{pmatrix} 0 \\\\ -\\frac{8}{9} \\\\ \\frac{8}{9} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\\\ \\frac{2}{3} \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ -\\frac{2}{3} \\\\ \\frac{2}{3} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n    $$\n\nThe iterates are $\\boldsymbol{x}_1 = \\begin{pmatrix} 8/9 \\\\ 4/9 \\\\ 4/9 \\end{pmatrix}$ and $\\boldsymbol{x}_2 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}$. The residuals are $\\boldsymbol{r}_1 = \\begin{pmatrix} 0 \\\\ -2/3 \\\\ 2/3 \\end{pmatrix}$ and $\\boldsymbol{r}_2 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$. The residual $\\boldsymbol{r}_2$ is the zero vector, which indicates that $\\boldsymbol{x}_2$ is the exact solution. This is possible because CG guarantees convergence in at most $N$ steps for an $N \\times N$ system in exact arithmetic, and here $N=3$.\n\n**Verification of $A$-conjugacy and Final Answer**\n\nThe problem asks to verify the $A$-conjugacy condition $\\boldsymbol{p}_0^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{p}_1 = 0$ and report the computed value.\nUsing the vectors $\\boldsymbol{p}_0$ and $\\boldsymbol{A} \\boldsymbol{p}_1$ derived above:\n$$\n\\boldsymbol{p}_0 = \\begin{pmatrix} 4 \\\\ 2 \\\\ 2 \\end{pmatrix} \\quad \\text{and} \\quad \\boldsymbol{A} \\boldsymbol{p}_1 = \\begin{pmatrix} 0 \\\\ -\\frac{8}{9} \\\\ \\frac{8}{9} \\end{pmatrix}\n$$\nWe compute the scalar product:\n$$\n\\boldsymbol{p}_0^{\\mathsf{T}} \\boldsymbol{A} \\boldsymbol{p}_1 = \\begin{pmatrix} 4 & 2 & 2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -\\frac{8}{9} \\\\ \\frac{8}{9} \\end{pmatrix} = 4(0) + 2\\left(-\\frac{8}{9}\\right) + 2\\left(\\frac{8}{9}\\right) = 0 - \\frac{16}{9} + \\frac{16}{9} = 0\n$$\nThe condition is verified; the search directions are $A$-conjugate. The numerical value is $0$.",
            "answer": "$$\n\\boxed{0}\n$$"
        }
    ]
}