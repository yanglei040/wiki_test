{
    "hands_on_practices": [
        {
            "introduction": "A fundamental property of Hamiltonian dynamics is the preservation of the symplectic two-form, a condition mathematically expressed as $J^{\\top} S J = S$ for the map's Jacobian $J$. This exercise provides a direct, hands-on method for numerically verifying whether a given integrator implementation adheres to this crucial geometric constraint. By approximating the Jacobian with finite differences, you will build a powerful diagnostic tool to distinguish truly symplectic maps from non-symplectic ones .",
            "id": "3493143",
            "problem": "Design and implement a program that numerically diagnoses the symplecticity of a discrete-time map generated by an $N$-body Hamiltonian integrator used in numerical cosmology. The diagnostic must evaluate the deviation from the canonical symplectic condition by computing the quantity $J^{\\top} S J - S$, where $J$ is the Jacobian of the one-step map of the integrator and $S$ is the canonical symplectic form. The program must report a scalar deviation per test case by taking a matrix norm of $J^{\\top} S J - S$ and aggregating this norm over an ensemble of random phase-space states.\n\nUse this context-appropriate fundamental base:\n- Hamiltonian mechanics in canonical form for positions $q$ and momenta $p$, with $dq/dt = \\partial H / \\partial p$ and $dp/dt = -\\partial H / \\partial q$.\n- For $N$ bodies with dimensionless parameters, use the gravitational Hamiltonian with Plummer softening: $H(q,p) = \\sum_{i=1}^{N} \\frac{\\|p_i\\|^2}{2 m_i} - \\sum_{1 \\le i < j \\le N} \\frac{G m_i m_j}{\\sqrt{\\|q_i - q_j\\|^2 + \\epsilon_s^2}}$.\n- The canonical symplectic form in block matrix representation on phase space coordinates $x = (q,p)$ is $S = \\begin{pmatrix} 0 & I \\\\ -I & 0 \\end{pmatrix}$, where $I$ is the identity matrix of size equal to the dimension of $q$ (positions).\n- A map is symplectic if and only if its Jacobian $J$ satisfies $J^{\\top} S J = S$.\n\nThe program must do the following:\n1. Construct a dimensionless $N$-body system with $G = 1$ and $m_i = 1$ for all $i$, working in $2$ spatial dimensions. All quantities are unitless and no physical units are required.\n2. Implement two one-step integrators for the Hamiltonian system:\n   - A time-reversible, second-order symplectic scheme (velocity Verlet/leapfrog).\n   - A standard explicit fourth-order Runge–Kutta method.\n3. For a given integrator, timestep $h$, and random state $x = (q,p)$, approximate the Jacobian $J$ of the one-step map by central finite differences. Use a fixed perturbation $10^{-7}$ along each canonical coordinate in $x$ to compute the columns of $J$.\n4. Compute the canonical symplecticity deviation for the step map at that state as the Frobenius norm $\\|J^{\\top} S J - S\\|_F$.\n5. Generate an ensemble of random states for each test case:\n   - Positions $q_i$ are drawn uniformly in the square $[-1,1]^2$.\n   - Momenta $p_i$ are drawn uniformly in $[-0.5,0.5]^2$.\n   - For $N \\ge 2$, enforce a minimum pairwise separation of $\\delta = 0.2$ by rejection sampling, to avoid near-singular configurations.\n   - Use Plummer softening $\\epsilon_s = 0.01$ in the gravitational potential.\n6. For each test case, compute the symplecticity deviation for each random state and report the median of these deviations as the test case’s result.\n\nDesign for coverage:\n- Use the following test suite of parameter values that exercises different conditions, including a nominal case, larger timesteps, and a boundary case of a free particle ($N = 1$):\n  - Case $1$: integrator type $=$ leapfrog, $N = 3$, $h = 0.005$, number of states $M = 4$, random seed $= 42$.\n  - Case $2$: integrator type $=$ leapfrog, $N = 3$, $h = 0.1$, number of states $M = 4$, random seed $= 43$.\n  - Case $3$: integrator type $=$ leapfrog, $N = 3$, $h = 0.3$, number of states $M = 4$, random seed $= 44$.\n  - Case $4$: integrator type $=$ Runge–Kutta $4$, $N = 3$, $h = 0.005$, number of states $M = 4$, random seed $= 45$.\n  - Case $5$: integrator type $=$ Runge–Kutta $4$, $N = 3$, $h = 0.1$, number of states $M = 4$, random seed $= 46$.\n  - Case $6$: integrator type $=$ Runge–Kutta $4$, $N = 3$, $h = 0.3$, number of states $M = 4$, random seed $= 47$.\n  - Case $7$: integrator type $=$ leapfrog, $N = 1$, $h = 0.3$, number of states $M = 4$, random seed $= 48$.\n  - Case $8$: integrator type $=$ Runge–Kutta $4$, $N = 1$, $h = 0.3$, number of states $M = 4$, random seed $= 49$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets and ordered exactly as the test suite above (for example, $[r_1,r_2,\\dots,r_8]$), where each $r_k$ is the median Frobenius norm of $J^{\\top} S J - S$ over the $M$ random states for the $k$-th test case. All results must be reported as floating-point numbers without any units.",
            "solution": "The problem requires the design and implementation of a numerical diagnostic to assess the symplecticity of discrete-time maps generated by N-body Hamiltonian integrators. This involves evaluating the preservation of the canonical symplectic structure, a fundamental geometric property of Hamiltonian dynamics.\n\n\nFirst, we establish the theoretical framework. An $N$-body system in $D$ spatial dimensions is described in phase space by a state vector $x = (q, p)$, where $q = (q_1, \\dots, q_N)$ are the generalized positions and $p = (p_1, \\dots, p_N)$ are the conjugate momenta. The total dimension of the phase space is $2DN$. For this problem, we consider $D=2$ spatial dimensions, so the phase space has dimension $4N$. The dynamics are governed by a Hamiltonian function $H(q,p)$. The equations of motion are Hamilton's canonical equations:\n$$\n\\frac{dq_i}{dt} = \\frac{\\partial H}{\\partial p_i}, \\quad \\frac{dp_i}{dt} = -\\frac{\\partial H}{\\partial q_i}\n$$\nThe problem specifies a dimensionless gravitational Hamiltonian with Plummer softening $\\epsilon_s$ for $N$ bodies, with gravitational constant $G=1$ and particle masses $m_i=1$:\n$$\nH(q,p) = \\sum_{i=1}^{N} \\frac{\\|p_i\\|^2}{2} - \\sum_{1 \\le i < j \\le N} \\frac{1}{\\sqrt{\\|q_i - q_j\\|^2 + \\epsilon_s^2}}\n$$\nThe time evolution of the system over a time interval $h$ is described by the flow map $\\phi_h$, such that $x(t+h) = \\phi_h(x(t))$. A numerical integrator provides an approximation to this map, which we denote as the one-step map $\\Phi_h$. A key property of the exact flow $\\phi_h$ is that it is a symplectic transformation. This means its Jacobian matrix, $J = D\\phi_h$, satisfies the symplectic condition:\n$$\nJ^{\\top} S J = S\n$$\nHere, $S$ is the canonical symplectic form, a block matrix defined on the phase space coordinates $x=(q,p)$ as:\n$$\nS = \\begin{pmatrix} 0 & I \\\\ -I & 0 \\end{pmatrix}\n$$\nwhere $I$ is the $2N \\times 2N$ identity matrix and $0$ is the $2N \\times 2N$ zero matrix. An integrator is called symplectic if its one-step map $\\Phi_h$ is also a symplectic transformation. Such integrators are crucial for long-term simulations, as in numerical cosmology, because they conserve a \"shadow\" Hamiltonian, leading to excellent long-term energy stability and preservation of phase space volume.\n\nThe task is to diagnose this property for two different integrators:\n\n1.  **Leapfrog (Velocity Verlet)**: This is a second-order, time-reversible integrator, well-known to be symplectic. Its one-step map $\\Phi_h^{\\text{LF}}$ is given by the sequence:\n    \n    $p_{n+1/2} = p_n + a(q_n) \\frac{h}{2}$\n    \n    $q_{n+1} = q_n + p_{n+1/2} h$\n    \n    $p_{n+1} = p_{n+1/2} + a(q_{n+1}) \\frac{h}{2}$\n    \n    where $a(q) = -\\nabla_q V(q)$ is the acceleration derived from the potential energy $V(q)$. Because this map is symplectic, its exact Jacobian should satisfy the symplectic condition.\n\n2.  **Explicit Fourth-Order Runge–Kutta (RK4)**: This is a general-purpose, high-order integrator. For an autonomous system $\\dot{x} = f(x)$, the one-step map $\\Phi_h^{\\text{RK4}}$ is:\n    \n    $k_1 = f(x_n)$\n    \n    $k_2 = f(x_n + \\frac{h}{2} k_1)$\n    \n    $k_3 = f(x_n + \\frac{h}{2} k_2)$\n    \n    $k_4 = f(x_n + h k_3)$\n    \n    $x_{n+1} = x_n + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)$\n    \n    where $f(x) = f(q,p) = (\\dot{q}, \\dot{p}) = (\\partial H/\\partial p, -\\partial H/\\partial q) = (p, a(q))$. In general, the RK4 map is not symplectic, and thus provides a point of contrast.\n\nThe diagnostic protocol is as follows. For a given integrator's one-step map $\\Phi_h$ and a state $x$ in phase space, we first compute the Jacobian matrix $J = D\\Phi_h(x)$. Since an analytical derivation of $J$ is cumbersome, we approximate it numerically using central finite differences. The $j$-th column of $J$ is approximated as:\n$$\nJ_{\\cdot, j} \\approx \\frac{\\Phi_h(x + \\delta e_j) - \\Phi_h(x - \\delta e_j)}{2\\delta}\n$$\nwhere $e_j$ is the $j$-th canonical basis vector and $\\delta = 10^{-7}$ is the specified small perturbation.\n\nWith the numerical Jacobian $J$ computed, we evaluate the deviation from the symplectic condition by forming the matrix $\\Delta = J^{\\top} S J - S$. For a perfect symplectic map and an exact Jacobian, $\\Delta$ would be the zero matrix. For a non-symplectic map or an approximate Jacobian, $\\Delta$ will be non-zero. The magnitude of this deviation is quantified by a scalar value, the Frobenius norm:\n$$\n\\|\\Delta\\|_F = \\sqrt{\\sum_{i,j} |\\Delta_{ij}|^2}\n$$\nThe deviation can be state-dependent. To obtain a representative measure for a given set of parameters (integrator type, $N$, $h$), an ensemble of $M$ random phase-space states is generated. For each state, the deviation norm is calculated. The final reported value for a test case is the median of these $M$ norms. The median is a robust statistical measure, less sensitive to potential outliers than the mean. The initial states are generated by drawing positions $q_i$ and momenta $p_i$ from uniform distributions, with a rejection sampling step to enforce a minimum particle separation $\\delta=0.2$ for $N \\ge 2$, avoiding near-singularities in the force calculation.\n\nFor the symplectic Leapfrog integrator, the theoretical map is exactly symplectic. The measured deviation is therefore expected to be small, primarily arising from floating-point arithmetic and the approximation error in the finite-difference Jacobian calculation. Conversely, for the non-symplectic RK4 integrator, the deviation is intrinsic to the method and is expected to be significantly larger and dependent on the timestep $h$. The special case of $N=1$ (a free particle) serves as a valuable sanity check, as the motion is trivial ($p(t) = \\text{const}, q(t) = q_0 + p_0 t$) and both integrators yield the exact, symplectic solution, predicting a near-zero deviation for both.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to run the symplecticity diagnostics for all test cases.\n    \"\"\"\n\n    test_cases = [\n        # (integrator_type, N, h, M, seed)\n        ('leapfrog', 3, 0.005, 4, 42),\n        ('leapfrog', 3, 0.1, 4, 43),\n        ('leapfrog', 3, 0.3, 4, 44),\n        ('rk4', 3, 0.005, 4, 45),\n        ('rk4', 3, 0.1, 4, 46),\n        ('rk4', 3, 0.3, 4, 47),\n        ('leapfrog', 1, 0.3, 4, 48),\n        ('rk4', 1, 0.3, 4, 49),\n    ]\n\n    G = 1.0\n    EPSILON_S = 0.01\n    FINITE_DIFF_PERT = 1e-7\n    MIN_SEP = 0.2\n\n    def get_acceleration(q, n_particles):\n        \"\"\"\n        Calculates the acceleration of N particles.\n        q has shape (n_particles, 2).\n        Returns acceleration of shape (n_particles, 2).\n        \"\"\"\n        if n_particles <= 1:\n            return np.zeros_like(q)\n\n        # Vectorized calculation of pairwise forces\n        # q shape: (N, D) -> (1, N, D) and (N, 1, D)\n        # diff shape: (N, N, D) where diff[i, j, :] is q[j] - q[i]\n        diff = q[None, :, :] - q[:, None, :]\n\n        # dist_sq shape: (N, N) where dist_sq[i, j] is ||q[j] - q[i]||^2\n        dist_sq = np.sum(diff**2, axis=-1)\n\n        # inv_r3 shape: (N, N) where inv_r3[i, j] = (dist_sq[i, j] + eps^2)^(-3/2)\n        # We use mass=1 and G=1. Force on i from j is - (q_i - q_j) / r^3\n        # accel on i is sum_j (q_j-q_i)/r^3\n        with np.errstate(divide='ignore', invalid='ignore'):\n            inv_r3 = (dist_sq + EPSILON_S**2)**(-1.5)\n        np.fill_diagonal(inv_r3, 0.0) # No self-force\n\n        # accel[i,:] = sum_j (q_j-q_i)*inv_r3[i,j]\n        # diff is qj-qi, so we need to sum over axis 1 (j)\n        accel = np.sum(diff * inv_r3[:, :, None], axis=1) * G\n        \n        return accel\n\n    def leapfrog_step(x, h, n_particles):\n        \"\"\"\n        Performs one step of the velocity Verlet/leapfrog integrator.\n        x is a flat array of shape (4*n_particles,).\n        \"\"\"\n        dim = 2 * n_particles\n        q0 = x[:dim].reshape((n_particles, 2))\n        p0 = x[dim:].reshape((n_particles, 2))\n\n        a0 = get_acceleration(q0, n_particles)\n        p_half = p0 + a0 * h / 2.0\n        q1 = q0 + p_half * h\n        a1 = get_acceleration(q1, n_particles)\n        p1 = p_half + a1 * h / 2.0\n        \n        return np.concatenate((q1.flatten(), p1.flatten()))\n\n    def rk4_step(x, h, n_particles):\n        \"\"\"\n        Performs one step of the RK4 integrator.\n        x is a flat array of shape (4*n_particles,).\n        \"\"\"\n        dim = 2 * n_particles\n\n        def f(state_vec):\n            q_vec = state_vec[:dim].reshape((n_particles, 2))\n            p_vec = state_vec[dim:].reshape((n_particles, 2))\n            \n            dq_dt = p_vec\n            dp_dt = get_acceleration(q_vec, n_particles)\n            \n            return np.concatenate((dq_dt.flatten(), dp_dt.flatten()))\n\n        k1 = f(x)\n        k2 = f(x + 0.5 * h * k1)\n        k3 = f(x + 0.5 * h * k2)\n        k4 = f(x + h * k3)\n        \n        x_next = x + (h / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n        return x_next\n\n    def generate_random_state(rng, n_particles, min_sep):\n        \"\"\"\n        Generates a single random state (q, p) with rejection sampling for q.\n        \"\"\"\n        dim_pos = 2 * n_particles\n        q_flat = np.zeros(dim_pos)\n\n        if n_particles >= 2:\n            while True:\n                q = rng.uniform(-1.0, 1.0, size=(n_particles, 2))\n                \n                # Check pairwise separation\n                diff = q[None, :, :] - q[:, None, :]\n                dist_sq = np.sum(diff**2, axis=-1)\n                np.fill_diagonal(dist_sq, np.inf)\n                \n                if np.sqrt(np.min(dist_sq)) > min_sep:\n                    q_flat = q.flatten()\n                    break\n        else: # n_particles == 1\n            q = rng.uniform(-1.0, 1.0, size=(n_particles, 2))\n            q_flat = q.flatten()\n\n        p = rng.uniform(-0.5, 0.5, size=(n_particles, 2))\n        p_flat = p.flatten()\n\n        return np.concatenate((q_flat, p_flat))\n\n    def compute_jacobian(one_step_map, x, h, n_particles, pert):\n        \"\"\"\n        Computes the Jacobian of the one-step map using central finite differences.\n        \"\"\"\n        phase_space_dim = 4 * n_particles\n        jacobian = np.zeros((phase_space_dim, phase_space_dim))\n        \n        for j in range(phase_space_dim):\n            e_j = np.zeros(phase_space_dim)\n            e_j[j] = 1.0\n            \n            x_plus = x + pert * e_j\n            x_minus = x - pert * e_j\n            \n            map_plus = one_step_map(x_plus, h, n_particles)\n            map_minus = one_step_map(x_minus, h, n_particles)\n\n            jacobian[:, j] = (map_plus - map_minus) / (2 * pert)\n            \n        return jacobian\n\n    results = []\n    integrators = {'leapfrog': leapfrog_step, 'rk4': rk4_step}\n\n    for case in test_cases:\n        integrator_type, N, h, M, seed = case\n        \n        rng = np.random.default_rng(seed)\n        one_step_map = integrators[integrator_type]\n        \n        phase_space_dim = 4 * N\n        pos_dim = 2 * N\n        \n        # Construct the symplectic matrix S\n        I = np.identity(pos_dim)\n        Z = np.zeros((pos_dim, pos_dim))\n        S = np.block([[Z, I], [-I, Z]])\n        \n        deviations = []\n        for _ in range(M):\n            # 1. Generate a random state\n            x0 = generate_random_state(rng, N, MIN_SEP)\n            \n            # 2. Compute the Jacobian at this state\n            J = compute_jacobian(one_step_map, x0, h, N, FINITE_DIFF_PERT)\n            \n            # 3. Compute the deviation matrix and its norm\n            deviation_matrix = J.T @ S @ J - S\n            deviation_norm = np.linalg.norm(deviation_matrix, 'fro')\n            deviations.append(deviation_norm)\n            \n        # 4. Report the median deviation for the test case\n        median_deviation = np.median(deviations)\n        results.append(median_deviation)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Having explored how to verify symplecticity, we now turn to *why* this property is paramount for long-term simulations in cosmology. This practice contrasts a symplectic integrator with a standard, high-order non-symplectic method in the context of a toy galactic halo model. By tracking the system's energy and other adiabatic invariants over many dynamical times, you will observe firsthand the superior stability and fidelity that symplectic methods provide .",
            "id": "3493173",
            "problem": "Consider the long-time numerical integration of a two-dimensional toy model for a barred dark matter halo in a rotating frame. The system is modeled by a Hamiltonian that is autonomous in the rotating frame, with canonical coordinates $q = (x,y)$ and momenta $p = (p_x,p_y)$, given by\n$$\nH(q,p) \\equiv \\frac{1}{2}\\left(p_x^2 + p_y^2\\right) + \\frac{1}{2}\\left(\\omega_x^2 x^2 + \\omega_y^2 y^2\\right) - \\Omega \\left( x p_y - y p_x \\right),\n$$\nwhere $\\omega_x$ and $\\omega_y$ are the characteristic frequencies of an anisotropic harmonic background (representing a triaxial or barred deformation) and $\\Omega$ is the constant pattern speed of the bar. The equations of motion are the Hamilton equations $\\dot{q} = \\partial H/\\partial p$ and $\\dot{p} = -\\partial H/\\partial q$. The quantity $H$ is the Jacobi integral in the rotating frame and is exactly conserved by the continuous dynamics.\n\nA central goal in numerical cosmology is to preserve long-time structure (phase-space volume and invariants) when integrating Hamiltonian systems. Symplectic integrators are designed to preserve the symplectic structure and, by backward error analysis, exactly conserve a modified Hamiltonian, while generic non-symplectic integrators do not. In near-integrable regimes, one also monitors adiabatic invariants such as action-like quantities. For the model above, define the action-like diagnostics\n$$\nJ_x(t) \\equiv \\frac{\\frac{1}{2}p_x(t)^2 + \\frac{1}{2}\\omega_x^2 x(t)^2}{\\omega_x}, \\quad\nJ_y(t) \\equiv \\frac{\\frac{1}{2}p_y(t)^2 + \\frac{1}{2}\\omega_y^2 y(t)^2}{\\omega_y},\n$$\nwhich are exact invariants of the uncoupled isotropic case when $\\Omega = 0$ and $\\omega_x = \\omega_y$. In the general rotating, anisotropic setting, $J_x$ and $J_y$ are not exact invariants, but serve as adiabatic diagnostics of numerical fidelity.\n\nTask. Write a complete, runnable program that:\n- Implements two integrators for the above Hamiltonian: \n  1) a second-order symmetric Strang splitting symplectic method obtained by splitting $H = T + U + G$ with \n  $T(p) = \\frac{1}{2}(p_x^2 + p_y^2)$, $U(q) = \\frac{1}{2}(\\omega_x^2 x^2 + \\omega_y^2 y^2)$, and $G(q,p) = -\\Omega (x p_y - y p_x)$; and \n  2) a standard explicit fourth-order Runge–Kutta method applied to the full Hamilton equations.\n- Uses the following fixed initial condition shared by all test cases: $x(0) = 1.0$, $y(0) = 0.2$, $p_x(0) = 0.0$, $p_y(0) = 0.9$ (dimensionless).\n- For each numerical trajectory, computes two scalar error diagnostics over the full integration time interval $[0,T]$:\n  1) the maximum relative deviation of the Jacobi integral,\n  $$\n  \\epsilon_H \\equiv \\max_{0 \\le t \\le T} \\frac{\\left| H(t) - H(0) \\right|}{\\left| H(0) \\right| + 10^{-12}},\n  $$\n  and \n  2) the relative root-mean-square deviation of the sum of actions $J_x + J_y$,\n  $$\n  \\epsilon_J \\equiv \\left[ \\frac{1}{N+1}\\sum_{n=0}^{N} \\left( \\frac{J_x(t_n) + J_y(t_n) - \\left[J_x(0) + J_y(0)\\right]}{\\left|J_x(0) + J_y(0)\\right| + 10^{-12}} \\right)^2 \\right]^{1/2},\n  $$\n  where $t_n = n \\,\\Delta t$ and $N = \\lfloor T/\\Delta t \\rfloor$.\n- Integration is performed with a fixed time step $\\Delta t$ without adaptive control and all quantities are dimensionless.\n\nIntegrator specification. The Strang splitting symplectic method must be built from the exact flows of $T$, $U$, and $G$:\n- $T$-flow over $\\tau$: $q \\mapsto q + p\\,\\tau$, $p \\mapsto p$.\n- $U$-flow over $\\tau$: $q \\mapsto q$, $p \\mapsto p - \\nabla U(q)\\,\\tau$, with $\\nabla U(q) = (\\omega_x^2 x, \\omega_y^2 y)$.\n- $G$-flow over $\\tau$: simultaneous rotations $q \\mapsto R(\\Omega \\tau)\\,q$ and $p \\mapsto R(\\Omega \\tau)\\,p$, where $R(\\theta)$ is the planar rotation with matrix $R(\\theta) = \\begin{pmatrix}\\cos\\theta & \\sin\\theta \\\\ -\\sin\\theta & \\cos\\theta \\end{pmatrix}$.\nOne time step $\\Delta t$ of the symmetric second-order method must be the composition $U(\\Delta t/2) \\circ G(\\Delta t/2) \\circ T(\\Delta t) \\circ G(\\Delta t/2) \\circ U(\\Delta t/2)$.\n\nRunge–Kutta specification. The fourth-order Runge–Kutta method must be applied to the full Hamilton equations with\n$$\n\\dot{x} = p_x + \\Omega y, \\quad \\dot{y} = p_y - \\Omega x, \\quad\n\\dot{p}_x = -\\omega_x^2 x + \\Omega p_y, \\quad \\dot{p}_y = -\\omega_y^2 y - \\Omega p_x.\n$$\n\nTest suite. Your program must run the following six test cases, each defined by the tuple $(\\text{method}, \\omega_x, \\omega_y, \\Omega, T, \\Delta t)$:\n- Case $1$: $(\\text{S2},\\, 1.0,\\, 1.2,\\, 0.3,\\, 1000.0,\\, 0.05)$.\n- Case $2$: $(\\text{RK4},\\, 1.0,\\, 1.2,\\, 0.3,\\, 1000.0,\\, 0.05)$.\n- Case $3$: $(\\text{S2},\\, 1.0,\\, 1.2,\\, 0.3,\\, 1000.0,\\, 0.20)$.\n- Case $4$: $(\\text{RK4},\\, 1.0,\\, 1.2,\\, 0.3,\\, 1000.0,\\, 0.20)$.\n- Case $5$: $(\\text{S2},\\, 1.0,\\, 1.0,\\, 0.0,\\, 1000.0,\\, 0.05)$.\n- Case $6$: $(\\text{RK4},\\, 1.0,\\, 1.0,\\, 0.0,\\, 1000.0,\\, 0.05)$.\n\nOutput. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case in the order above, append the two floats $(\\epsilon_H, \\epsilon_J)$, so the final output contains $12$ numbers in the order\n$$\n[\\epsilon_H^{(1)},\\epsilon_J^{(1)}, \\epsilon_H^{(2)},\\epsilon_J^{(2)}, \\ldots, \\epsilon_H^{(6)},\\epsilon_J^{(6)}].\n$$\n\nNotes.\n- All quantities are dimensionless, so no physical units are required.\n- Angles are assumed to be in radians.\n- The program must be self-contained, must not read any input, and must not access external files or the network.",
            "solution": "The user requests a program to solve the equations of motion for a two-dimensional Hamiltonian system, a toy model relevant to galactic dynamics, using two different numerical integrators: a second-order symplectic Strang splitting method (S2) and a standard fourth-order Runge-Kutta method (RK4). The objective is to compare their performance in conserving system invariants over long integration times.\n\nThe state of the system is described by the canonical coordinates $q = (x, y)$ and momenta $p = (p_x, p_y)$. All quantities are dimensionless. The state vector can be represented as a $4$-dimensional vector $z(t) = (x(t), y(t), p_x(t), p_y(t))$. The dynamics are governed by the Hamiltonian:\n$$\nH(q,p) = \\frac{1}{2}\\left(p_x^2 + p_y^2\\right) + \\frac{1}{2}\\left(\\omega_x^2 x^2 + \\omega_y^2 y^2\\right) - \\Omega \\left( x p_y - y p_x \\right)\n$$\nThis Hamiltonian is the Jacobi integral of the system in a frame rotating with constant pattern speed $\\Omega$. The parameters $\\omega_x$ and $\\omega_y$ are characteristic frequencies of a background potential. The equations of motion are Hamilton's equations, $\\dot{z} = \\mathbf{J} \\nabla H$, where $\\mathbf{J}$ is the standard symplectic matrix.\n\nThe solution involves implementing the two specified numerical integrators and two diagnostic error metrics, $\\epsilon_H$ and $\\epsilon_J$.\n\n**1. Symplectic Integrator: Second-Order Strang Splitting (S2)**\n\nSymplectic integrators are a class of geometric numerical methods designed to preserve the symplectic structure of Hamiltonian systems. This property ensures the conservation of phase-space volume and leads to excellent long-term stability, particularly the bounded error of an exactly conserved \"shadow\" Hamiltonian.\n\nThe problem specifies a splitting of the Hamiltonian into three parts, $H = T + U + G$, where:\n- $T(p) = \\frac{1}{2}(p_x^2 + p_y^2)$: The kinetic energy.\n- $U(q) = \\frac{1}{2}(\\omega_x^2 x^2 + \\omega_y^2 y^2)$: The potential energy from the anisotropic harmonic oscillator.\n- $G(q,p) = -\\Omega (x p_y - y p_x)$: The term arising from the Coriolis force in the rotating frame.\n\nEach of these sub-Hamiltonians generates a flow that can be integrated exactly. A single time step of size $\\Delta t$ is constructed by composing these exact flows. The specified symmetric Strang splitting composition is:\n$$\n\\Phi_{\\Delta t}^{\\text{S2}} = \\phi_U(\\Delta t/2) \\circ \\phi_G(\\Delta t/2) \\circ \\phi_T(\\Delta t) \\circ \\phi_G(\\Delta t/2) \\circ \\phi_U(\\Delta t/2)\n$$\nwhere $\\phi_K(\\tau)$ denotes the exact flow of the subsystem with Hamiltonian $K$ over a time interval $\\tau$. The individual flows are:\n-   **Flow $\\phi_T(\\tau)$:** The solution to $\\dot{q} = \\partial T/\\partial p = p$ and $\\dot{p} = -\\partial T/\\partial q = 0$. This is a free-particle drift: $q(t_0+\\tau) = q(t_0) + p(t_0)\\tau$, $p(t_0+\\tau) = p(t_0)$.\n-   **Flow $\\phi_U(\\tau)$:** The solution to $\\dot{q} = 0$ and $\\dot{p} = -\\nabla U(q)$. This is an impulse: $q(t_0+\\tau) = q(t_0)$, $p(t_0+\\tau) = p(t_0) - \\nabla U(q(t_0))\\tau$, where $\\nabla U(q) = (\\omega_x^2 x, \\omega_y^2 y)$.\n-   **Flow $\\phi_G(\\tau)$:** The solution to Hamilton's equations for $H=G$. This corresponds to a simultaneous rotation of the coordinate vector $q$ and momentum vector $p$. The state vectors $q$ and $p$ are updated by applying the rotation matrix $R(\\theta) = \\begin{pmatrix}\\cos\\theta & \\sin\\theta \\\\ -\\sin\\theta & \\cos\\theta \\end{pmatrix}$ with rotation angle $\\theta = \\Omega \\tau$.\n\nThe implementation combines these transformations in the specified sequence to advance the state vector $z$ by one time step $\\Delta t$.\n\n**2. Non-Symplectic Integrator: Fourth-Order Runge-Kutta (RK4)**\n\nThe explicit fourth-order Runge-Kutta method is a widely used, general-purpose solver for systems of ordinary differential equations of the form $\\dot{z} = f(t, z)$. For this problem, the function $f$ is derived from the full Hamilton's equations:\n$$\nf(z) = \\begin{pmatrix} \\dot{x} \\\\ \\dot{y} \\\\ \\dot{p}_x \\\\ \\dot{p}_y \\end{pmatrix} = \\begin{pmatrix} p_x + \\Omega y \\\\ p_y - \\Omega x \\\\ -\\omega_x^2 x + \\Omega p_y \\\\ -\\omega_y^2 y - \\Omega p_x \\end{pmatrix}\n$$\nA single step from $z_n$ to $z_{n+1}$ over time step $\\Delta t$ is calculated as:\n$$\n\\begin{align*}\nk_1 &= f(z_n) \\\\\nk_2 &= f(z_n + \\frac{\\Delta t}{2} k_1) \\\\\nk_3 &= f(z_n + \\frac{\\Delta t}{2} k_2) \\\\\nk_4 &= f(z_n + \\Delta t k_3) \\\\\nz_{n+1} &= z_n + \\frac{\\Delta t}{6} (k_1 + 2k_2 + 2k_3 + k_4)\n\\end{align*}\n$$\nWhile highly accurate for a given step size, RK4 does not preserve the symplectic structure and typically leads to secular drift in the energy and other conserved quantities over long integrations.\n\n**3. Diagnostics and Main Loop**\n\nFor each test case, the program initializes the state vector to $z(0) = (1.0, 0.2, 0.0, 0.9)$. It then runs the integration from $t=0$ to $t=T$ with a fixed step $\\Delta t$. During the simulation, the values of the Hamiltonian $H(t)$ and the sum of actions $J_x(t) + J_y(t)$ are stored at each time step $t_n = n \\Delta t$ for $n = 0, \\ldots, N$, where $N = \\lfloor T/\\Delta t \\rfloor$.\n\nAfter the integration is complete, two error metrics are computed:\n-   The maximum relative deviation of the Jacobi integral, $\\epsilon_H$, quantifies the conservation of the system's energy-like invariant.\n-   The relative root-mean-square deviation of the sum of actions, $\\epsilon_J$, measures the preservation of an adiabatic invariant, which is exactly conserved only in a simplified, uncoupled version of the system.\n\nThe code is structured to loop through the six specified test cases, run the corresponding simulation for each, calculate the two diagnostics, and collect the results for final output. The NumPy library is used for efficient vector and array operations.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ...\n\ndef hamiltonian(z, wx2, wy2, Omega):\n    \"\"\"Computes the Hamiltonian H(q,p).\"\"\"\n    x, y, px, py = z\n    T = 0.5 * (px**2 + py**2)\n    U = 0.5 * (wx2 * x**2 + wy2 * y**2)\n    G = -Omega * (x * py - y * px)\n    return T + U + G\n\ndef actions(z, wx, wy):\n    \"\"\"Computes the action-like diagnostics J_x and J_y.\"\"\"\n    x, y, px, py = z\n    # Add a small epsilon to denominators to avoid division by zero if wx or wy is 0\n    eps = 1e-16\n    jx = (0.5 * px**2 + 0.5 * wx**2 * x**2) / (wx + eps)\n    jy = (0.5 * py**2 + 0.5 * wy**2 * y**2) / (wy + eps)\n    return jx, jy\n\n# --- S2 Integrator Components ---\ndef flow_T(z, dt):\n    \"\"\"Exact flow for H=T(p).\"\"\"\n    x, y, px, py = z\n    x_new = x + px * dt\n    y_new = y + py * dt\n    return np.array([x_new, y_new, px, py])\n\ndef flow_U(z, wx2, wy2, dt):\n    \"\"\"Exact flow for H=U(q).\"\"\"\n    x, y, px, py = z\n    px_new = px - wx2 * x * dt\n    py_new = py - wy2 * y * dt\n    return np.array([x, y, px_new, py_new])\n\ndef flow_G(z, Omega, dt):\n    \"\"\"Exact flow for H=G(q,p).\"\"\"\n    theta = Omega * dt\n    c, s = np.cos(theta), np.sin(theta)\n    x, y, px, py = z\n    x_new = c * x + s * y\n    y_new = -s * x + c * y\n    px_new = c * px + s * py\n    py_new = -s * px + c * py\n    return np.array([x_new, y_new, px_new, py_new])\n\ndef s2_step(z, wx2, wy2, Omega, dt):\n    \"\"\"One step of the second-order Strang splitting integrator.\"\"\"\n    dt_half = 0.5 * dt\n    z_new = flow_U(z, wx2, wy2, dt_half)\n    z_new = flow_G(z_new, Omega, dt_half)\n    z_new = flow_T(z_new, dt)\n    z_new = flow_G(z_new, Omega, dt_half)\n    z_new = flow_U(z_new, wx2, wy2, dt_half)\n    return z_new\n\n# --- RK4 Integrator Components ---\ndef rk4_derivatives(z, wx2, wy2, Omega):\n    \"\"\"Computes the time derivative of the state vector for RK4.\"\"\"\n    x, y, px, py = z\n    dx_dt = px + Omega * y\n    dy_dt = py - Omega * x\n    dpx_dt = -wx2 * x + Omega * py\n    dpy_dt = -wy2 * y - Omega * px\n    return np.array([dx_dt, dy_dt, dpx_dt, dpy_dt])\n\ndef rk4_step(z, wx2, wy2, Omega, dt):\n    \"\"\"One step of the fourth-order Runge-Kutta integrator.\"\"\"\n    k1 = rk4_derivatives(z, wx2, wy2, Omega)\n    k2 = rk4_derivatives(z + 0.5 * dt * k1, wx2, wy2, Omega)\n    k3 = rk4_derivatives(z + 0.5 * dt * k2, wx2, wy2, Omega)\n    k4 = rk4_derivatives(z + dt * k3, wx2, wy2, Omega)\n    return z + (dt / 6.0) * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n\ndef run_simulation(method, wx, wy, Omega, T, dt, initial_state):\n    \"\"\"Runs a full simulation for a given method and parameters.\"\"\"\n    z = initial_state.copy()\n    wx2, wy2 = wx**2, wy**2\n    \n    num_steps = int(T / dt)\n    \n    # Store history for diagnostics\n    H_history = np.zeros(num_steps + 1)\n    J_sum_history = np.zeros(num_steps + 1)\n\n    # Initial values at t=0\n    H_history[0] = hamiltonian(z, wx2, wy2, Omega)\n    jx, jy = actions(z, wx, wy)\n    J_sum_history[0] = jx + jy\n\n    # Integration loop\n    for i in range(num_steps):\n        if method == 'S2':\n            z = s2_step(z, wx2, wy2, Omega, dt)\n        elif method == 'RK4':\n            z = rk4_step(z, wx2, wy2, Omega, dt)\n        \n        H_history[i + 1] = hamiltonian(z, wx2, wy2, Omega)\n        jx, jy = actions(z, wx, wy)\n        J_sum_history[i + 1] = jx + jy\n\n    # Calculate diagnostics\n    H0 = H_history[0]\n    J_sum0 = J_sum_history[0]\n    \n    # Epsilon H\n    eps_H_num = np.abs(H_history - H0)\n    eps_H_den = np.abs(H0) + 1e-12\n    epsilon_H = np.max(eps_H_num / eps_H_den)\n\n    # Epsilon J\n    eps_J_num = J_sum_history - J_sum0\n    eps_J_den = np.abs(J_sum0) + 1e-12\n    sq_rel_dev = (eps_J_num / eps_J_den)**2\n    epsilon_J = np.sqrt(np.mean(sq_rel_dev))\n    \n    return epsilon_H, epsilon_J\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (method, omega_x, omega_y, Omega, T, dt)\n        ('S2', 1.0, 1.2, 0.3, 1000.0, 0.05),\n        ('RK4', 1.0, 1.2, 0.3, 1000.0, 0.05),\n        ('S2', 1.0, 1.2, 0.3, 1000.0, 0.20),\n        ('RK4', 1.0, 1.2, 0.3, 1000.0, 0.20),\n        ('S2', 1.0, 1.0, 0.0, 1000.0, 0.05),\n        ('RK4', 1.0, 1.0, 0.0, 1000.0, 0.05),\n    ]\n\n    initial_state = np.array([1.0, 0.2, 0.0, 0.9])\n    \n    results = []\n    for case in test_cases:\n        method, wx, wy, Omega, T, dt = case\n        eps_H, eps_J = run_simulation(method, wx, wy, Omega, T, dt, initial_state)\n        results.append(eps_H)\n        results.append(eps_J)\n\n    # Final print statement in the exact required format.\n    # Using 'g' format for clean representation of small and regular numbers.\n    print(f\"[{','.join(f'{r:.7g}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Cosmological simulations often feature a vast range of timescales, which can be efficiently handled by multiple time-stepping methods like the Reference System Propagator Algorithm (RESPA). While RESPA is designed to be symplectic, this practice reveals a critical subtlety: improper tuning of its timesteps can excite numerical resonances, leading to instability. You will analyze the linear stability of the integrator by examining the eigenvalues of its transfer matrix, uncovering the 'stability tongues' that define safe integration parameters .",
            "id": "3493180",
            "problem": "Consider the softened Kepler problem in the plane with gravitational parameter $\\mu > 0$ and Plummer softening length $\\varepsilon \\ge 0$, whose potential is $V(r) = -\\mu / \\sqrt{r^2 + \\varepsilon^2}$. Fix a circular orbit at radius $r_0 > 0$. In dimensionless units where the particle mass is $1$, the circular angular frequency is determined by the balance condition $r_0 \\Omega^2 = \\partial V/\\partial r \\big|_{r_0}$, and the radial epicyclic frequency $\\kappa$ is defined by the standard central-potential relation $\\kappa^2 = (3/r) \\, \\partial V / \\partial r + \\partial^2 V / \\partial r^2$ evaluated at $r=r_0$. Derive $\\Omega^2$ and $\\kappa^2$ explicitly in terms of $\\mu$, $r_0$, and $\\varepsilon$.\n\nUsing the fundamental fact that small radial perturbations about a circular orbit in a smooth central potential evolve as a linear harmonic oscillator with frequency $\\kappa$ to leading order, model the radial degree of freedom $(x,p)$ with the quadratic Hamiltonian $H_r = \\tfrac{1}{2} p^2 + \\tfrac{1}{2} \\kappa^2 x^2$. Consider a reversible Reference System Propagator Algorithm (RESPA) multiple time step scheme that splits the stiffness between a “fast” and a “slow” quadratic potential:\n- A fraction $\\alpha \\in [0,1]$ of the curvature is assigned to the fast potential, with $k_{\\mathrm{fast}} = \\alpha \\kappa^2$.\n- The remainder is assigned to the slow potential, with $k_{\\mathrm{slow}} = (1-\\alpha) \\kappa^2$.\n\nOne macro-step of size $\\Delta t$ is defined by:\n- A slow half-kick: $p \\leftarrow p - \\tfrac{1}{2} \\Delta t \\, k_{\\mathrm{slow}} \\, x$.\n- $m \\in \\mathbb{N}$ inner velocity-Verlet substeps of size $\\delta t = \\Delta t/m$ applied to the fast Hamiltonian $H_{\\mathrm{fast}} = \\tfrac{1}{2} p^2 + \\tfrac{1}{2} k_{\\mathrm{fast}} x^2$.\n- A slow half-kick identical to the first.\n\nLinearize this RESPA macro-step about the circular orbit’s radial equilibrium to obtain the $2 \\times 2$ linear map $M_{\\mathrm{RESPA}}(\\Delta t, m, \\alpha; \\kappa^2)$ acting on the vector $(x,p)^{\\top}$. Use the following well-tested formulas as your base:\n- The velocity-Verlet substep for a one-dimensional harmonic oscillator with spring constant $k$ and substep size $s$ maps $(x,p)^{\\top}$ linearly via the matrix\n$$\nM_{\\mathrm{VV}}(k,s) =\n\\begin{bmatrix}\n1 - \\tfrac{1}{2} k s^2 & s \\\\\n- k s + \\tfrac{1}{4} k^2 s^3 & 1 - \\tfrac{1}{2} k s^2\n\\end{bmatrix},\n$$\nwhich is symplectic and stable for $k s^2 < 4$.\n- A pure potential half-kick with curvature $k$ and duration $\\tau$ maps $(x,p)^{\\top}$ via\n$$\nK(k,\\tau) = \\begin{bmatrix} 1 & 0 \\\\ -k \\tau & 1 \\end{bmatrix}.\n$$\n\nYour tasks:\n- Starting from the definitions above, derive $\\Omega^2$ and $\\kappa^2$ for the softened Kepler potential, and assemble the macro-step matrix\n$$\nM_{\\mathrm{RESPA}} = K\\!\\left(k_{\\mathrm{slow}}, \\tfrac{\\Delta t}{2}\\right) \\, \\left( M_{\\mathrm{VV}}(k_{\\mathrm{fast}}, \\delta t) \\right)^{m} \\, K\\!\\left(k_{\\mathrm{slow}}, \\tfrac{\\Delta t}{2}\\right).\n$$\n- Explain why the spectral radius condition for linear stability of the macro-step is equivalent to the requirement that all eigenvalues of $M_{\\mathrm{RESPA}}$ have unit modulus, or equivalently $\\lvert \\mathrm{tr}(M_{\\mathrm{RESPA}}) \\rvert \\le 2$ for a $2 \\times 2$ symplectic matrix.\n- Implement a program that computes, for given parameters $(\\mu, r_0, \\varepsilon, \\alpha, m, \\Delta t)$, whether the RESPA macro-step is linearly stable about the circular orbit. Use a numerical tolerance of $\\tau = 10^{-12}$ when comparing the spectral radius to $1$.\n- Work in dimensionless units; no physical units are required in the final answer.\n\nTest suite:\nEvaluate the stability indicator (a boolean) for the following cases. Each case is a tuple $(\\mu, r_0, \\varepsilon, \\alpha, m, \\Delta t)$, and each output must be a boolean:\n1. $(1.0, 1.0, 0.01, 0.7, 4, 0.1)$\n2. $(1.0, 1.0, 0.01, 0.7, 1, 2.6)$\n3. $(1.0, 1.0, 0.3, 0.2, 1, 1.9)$\n4. $(1.0, 1.0, 0.3, 0.2, 8, 1.9)$\n5. $(1.0, 1.0, 0.0, 1.0, 1, 2.0)$\n6. $(1.0, 1.0, 0.01, 0.05, 1, 6.0)$\n7. $(1.0, 2.0, 0.1, 0.5, 16, 0.05)$\n8. $(1.0, 0.5, 0.05, 0.8, 3, 0.8)$\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[{\\tt True},{\\tt False},\\dots]$) in the same order as the test suite above. Angles and physical units are not required because all quantities are dimensionless by construction. No other text should be printed.",
            "solution": "The problem requires the derivation of orbital frequencies for a softened Kepler potential, the construction of a RESPA integrator macro-step matrix, an explanation of its linear stability criterion, and a numerical implementation to test this stability for several parameter sets.\n\n### Step 1: Derivation of Orbital Frequencies $\\Omega^2$ and $\\kappa^2$\n\nThe softened Kepler potential is given by:\n$$V(r) = -\\frac{\\mu}{\\sqrt{r^2 + \\varepsilon^2}}$$\nwhere $\\mu > 0$ is the gravitational parameter and $\\varepsilon \\ge 0$ is the softening length. We work in units where the particle mass is $m=1$.\n\nTo find the circular and epicyclic frequencies, we first need the first and second radial derivatives of the potential.\nLet $s(r) = \\sqrt{r^2 + \\varepsilon^2}$. Then $V(r) = -\\mu s(r)^{-1}$.\n\nThe first derivative is:\n$$\n\\frac{\\partial V}{\\partial r} = \\frac{d}{dr} \\left( -\\mu (r^2 + \\varepsilon^2)^{-1/2} \\right) = -\\mu \\left(-\\frac{1}{2}\\right) (r^2 + \\varepsilon^2)^{-3/2} (2r) = \\frac{\\mu r}{(r^2 + \\varepsilon^2)^{3/2}}\n$$\n\nThe second derivative is found using the quotient rule or product rule on the expression for $\\partial V / \\partial r$:\n$$\n\\frac{\\partial^2 V}{\\partial r^2} = \\mu \\frac{d}{dr} \\left( r (r^2 + \\varepsilon^2)^{-3/2} \\right) = \\mu \\left[ 1 \\cdot (r^2 + \\varepsilon^2)^{-3/2} + r \\cdot \\left(-\\frac{3}{2}\\right) (r^2 + \\varepsilon^2)^{-5/2} (2r) \\right]\n$$\n$$\n\\frac{\\partial^2 V}{\\partial r^2} = \\mu \\left[ (r^2 + \\varepsilon^2)^{-3/2} - 3r^2 (r^2 + \\varepsilon^2)^{-5/2} \\right]\n$$\nTo simplify, we use a common denominator of $(r^2 + \\varepsilon^2)^{5/2}$:\n$$\n\\frac{\\partial^2 V}{\\partial r^2} = \\mu \\left[ \\frac{r^2 + \\varepsilon^2}{(r^2 + \\varepsilon^2)^{5/2}} - \\frac{3r^2}{(r^2 + \\varepsilon^2)^{5/2}} \\right] = \\mu \\frac{\\varepsilon^2 - 2r^2}{(r^2 + \\varepsilon^2)^{5/2}}\n$$\n\nNow, we evaluate these derivatives at the circular orbit radius $r_0$.\n\nThe circular angular frequency, $\\Omega$, is determined by the balance between the gravitational force and the centrifugal force: $r_0 \\Omega^2 = (\\partial V / \\partial r)|_{r_0}$.\n$$\n\\Omega^2 = \\frac{1}{r_0} \\left. \\frac{\\partial V}{\\partial r} \\right|_{r_0} = \\frac{1}{r_0} \\frac{\\mu r_0}{(r_0^2 + \\varepsilon^2)^{3/2}} = \\frac{\\mu}{(r_0^2 + \\varepsilon^2)^{3/2}}\n$$\n\nThe radial epicyclic frequency, $\\kappa$, is given by the formula for central potentials: $\\kappa^2 = (3/r)(\\partial V / \\partial r) + \\partial^2 V / \\partial r^2$, evaluated at $r=r_0$.\n$$\n\\kappa^2 = \\frac{3}{r_0} \\left. \\frac{\\partial V}{\\partial r} \\right|_{r_0} + \\left. \\frac{\\partial^2 V}{\\partial r^2} \\right|_{r_0} = \\frac{3}{r_0} \\left( \\frac{\\mu r_0}{(r_0^2 + \\varepsilon^2)^{3/2}} \\right) + \\frac{\\mu(\\varepsilon^2 - 2r_0^2)}{(r_0^2 + \\varepsilon^2)^{5/2}}\n$$\n$$\n\\kappa^2 = \\frac{3\\mu}{(r_0^2 + \\varepsilon^2)^{3/2}} + \\frac{\\mu(\\varepsilon^2 - 2r_0^2)}{(r_0^2 + \\varepsilon^2)^{5/2}}\n$$\nUsing a common denominator of $(r_0^2 + \\varepsilon^2)^{5/2}$:\n$$\n\\kappa^2 = \\frac{3\\mu(r_0^2 + \\varepsilon^2)}{(r_0^2 + \\varepsilon^2)^{5/2}} + \\frac{\\mu(\\varepsilon^2 - 2r_0^2)}{(r_0^2 + \\varepsilon^2)^{5/2}} = \\frac{\\mu (3r_0^2 + 3\\varepsilon^2 + \\varepsilon^2 - 2r_0^2)}{(r_0^2 + \\varepsilon^2)^{5/2}}\n$$\nThis simplifies to the final expression for the epicyclic frequency squared:\n$$\n\\kappa^2 = \\frac{\\mu (r_0^2 + 4\\varepsilon^2)}{(r_0^2 + \\varepsilon^2)^{5/2}}\n$$\n\n### Step 2: Assembling the RESPA Macro-Step Matrix\n\nThe radial degree of freedom is modeled by the harmonic oscillator Hamiltonian $H_r = \\tfrac{1}{2} p^2 + \\tfrac{1}{2} \\kappa^2 x^2$. The potential term is split into a fast part and a slow part, with spring constants $k_{\\mathrm{fast}} = \\alpha \\kappa^2$ and $k_{\\mathrm{slow}} = (1-\\alpha) \\kappa^2$.\n\nThe RESPA macro-step is a symmetric composition of operators (a leapfrog-style scheme): a half-step for the slow potential, followed by $m$ full steps for the fast Hamiltonian, followed by another half-step for the slow potential. In matrix form for the linearized system, this translates to a product of propagator matrices.\n\nThe matrix for a slow half-kick of duration $\\Delta t/2$ is given by:\n$$\nK\\left(k_{\\mathrm{slow}}, \\frac{\\Delta t}{2}\\right) = \\begin{bmatrix} 1 & 0 \\\\ -k_{\\mathrm{slow}} \\frac{\\Delta t}{2} & 1 \\end{bmatrix}\n$$\n\nThe matrix for a single inner velocity-Verlet substep of size $\\delta t = \\Delta t/m$ for the fast Hamiltonian is:\n$$\nM_{\\mathrm{VV}}(k_{\\mathrm{fast}}, \\delta t) =\n\\begin{bmatrix}\n1 - \\tfrac{1}{2} k_{\\mathrm{fast}} \\delta t^2 & \\delta t \\\\\n- k_{\\mathrm{fast}} \\delta t + \\tfrac{1}{4} k_{\\mathrm{fast}}^2 \\delta t^3 & 1 - \\tfrac{1}{2} k_{\\mathrm{fast}} \\delta t^2\n\\end{bmatrix}\n$$\n\nThe full macro-step matrix $M_{\\mathrm{RESPA}}$ is the product of these matrices in the specified order:\n$$\nM_{\\mathrm{RESPA}} = K\\left(k_{\\mathrm{slow}}, \\frac{\\Delta t}{2}\\right) \\left( M_{\\mathrm{VV}}(k_{\\mathrm{fast}}, \\delta t) \\right)^{m} K\\left(k_{\\mathrm{slow}}, \\frac{\\Delta t}{2}\\right)\n$$\nThis expression defines the assembly of the matrix. A numerical program would compute the matrix power $(M_{\\mathrm{VV}})^m$ and then perform the matrix multiplications.\n\n### Step 3: The Linear Stability Criterion\n\nThe evolution of the state vector $(x, p)^{\\top}$ over $N$ macro-steps is given by $(x_N, p_N)^{\\top} = (M_{\\mathrm{RESPA}})^N (x_0, p_0)^{\\top}$. The system is linearly stable if the states $(x_N, p_N)^{\\top}$ remain bounded for all $N$ and all initial states $(x_0, p_0)$. This requires that the matrix powers $(M_{\\mathrm{RESPA}})^N$ remain bounded as $N \\to \\infty$. This condition is equivalent to requiring the spectral radius of $M_{\\mathrm{RESPA}}$ to be less than or equal to $1$, i.e., $\\rho(M_{\\mathrm{RESPA}}) \\le 1$.\n\nThe matrices $K$ and $M_{\\mathrm{VV}}$ are symplectic, meaning they have a determinant of $1$. The product of symplectic matrices is also symplectic. Therefore, $M_{\\mathrm{RESPA}}$ is a $2 \\times 2$ symplectic matrix with $\\det(M_{\\mathrm{RESPA}}) = 1$.\n\nThe eigenvalues $\\lambda$ of any $2 \\times 2$ matrix $M$ are given by the characteristic equation $\\lambda^2 - \\mathrm{tr}(M)\\lambda + \\det(M) = 0$. For $M_{\\mathrm{RESPA}}$, this becomes:\n$$\n\\lambda^2 - \\mathrm{tr}(M_{\\mathrm{RESPA}})\\lambda + 1 = 0\n$$\nThe solutions are:\n$$\n\\lambda_{\\pm} = \\frac{\\mathrm{tr}(M_{\\mathrm{RESPA}}) \\pm \\sqrt{\\mathrm{tr}(M_{\\mathrm{RESPA}})^2 - 4}}{2}\n$$\n\nThere are two cases for the eigenvalues based on the trace:\n1.  **Stable Case: $|\\mathrm{tr}(M_{\\mathrm{RESPA}})| \\le 2$**\n    The discriminant $\\mathrm{tr}(M_{\\mathrm{RESPA}})^2 - 4$ is non-positive. The eigenvalues are a complex conjugate pair. Let $\\mathrm{tr}(M_{\\mathrm{RESPA}}) = 2\\cos\\theta$ for some $\\theta$. Then:\n    $$\n    \\lambda_{\\pm} = \\frac{2\\cos\\theta \\pm \\sqrt{4\\cos^2\\theta - 4}}{2} = \\cos\\theta \\pm i\\sin\\theta = e^{\\pm i\\theta}\n    $$\n    The modulus of both eigenvalues is $|\\lambda_{\\pm}| = 1$. The spectral radius is $\\rho(M_{\\mathrm{RESPA}}) = 1$. The matrix is diagonalizable (unless $|\\mathrm{tr}(M)|=2$ and it's a defective shear), and its powers remain bounded. This corresponds to a stable evolution (a rotation in a transformed phase space).\n\n2.  **Unstable Case: $|\\mathrm{tr}(M_{\\mathrm{RESPA}})| > 2$**\n    The discriminant is positive, and the eigenvalues are real and distinct. Since their product $\\lambda_{+}\\lambda_{-} = 1$, one eigenvalue must have a magnitude greater than $1$ and the other less than $1$. The spectral radius is $\\rho(M_{\\mathrm{RESPA}}) > 1$. If an initial state has any component along the eigenvector corresponding to the eigenvalue with magnitude greater than $1$, its trajectory will grow exponentially. This is an unstable evolution.\n\nTherefore, the condition for linear stability of the macro-step is precisely that all eigenvalues have unit modulus, which for a $2 \\times 2$ symplectic matrix is equivalent to the condition $|\\mathrm{tr}(M_{\\mathrm{RESPA}})| \\le 2$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of determining the stability of a RESPA integrator\n    for the softened Kepler problem for a given set of test cases.\n    \"\"\"\n    \n    # Test suite from the problem statement.\n    # Each case is a tuple: (mu, r0, epsilon, alpha, m, Delta_t)\n    test_cases = [\n        (1.0, 1.0, 0.01, 0.7, 4, 0.1),\n        (1.0, 1.0, 0.01, 0.7, 1, 2.6),\n        (1.0, 1.0, 0.3, 0.2, 1, 1.9),\n        (1.0, 1.0, 0.3, 0.2, 8, 1.9),\n        (1.0, 1.0, 0.0, 1.0, 1, 2.0),\n        (1.0, 1.0, 0.01, 0.05, 1, 6.0),\n        (1.0, 2.0, 0.1, 0.5, 16, 0.05),\n        (1.0, 0.5, 0.05, 0.8, 3, 0.8),\n    ]\n\n    results = []\n    tolerance = 1e-12\n\n    for case in test_cases:\n        mu, r0, epsilon, alpha, m, Delta_t = case\n\n        # Step 1: Calculate the epicyclic frequency squared, kappa^2.\n        # Handling the special case epsilon = 0 separately to avoid potential 0/0 issues\n        # with a generic formula, although the derived formula works fine.\n        if epsilon == 0.0:\n            if r0 > 0:\n                kappa2 = mu / r0**3\n            else:\n                # r0=0 is physically singular, but for completeness handle it.\n                # Assuming this case won't be tested as it's not well-defined.\n                results.append(False) # Unstable/undefined\n                continue\n        else:\n            r0_sq = r0**2\n            eps_sq = epsilon**2\n            denominator = (r0_sq + eps_sq)**2.5\n            numerator = mu * (r0_sq + 4 * eps_sq)\n            kappa2 = numerator / denominator\n        \n        # Step 2: Define the parameters for the RESPA scheme.\n        k_fast = alpha * kappa2\n        k_slow = (1.0 - alpha) * kappa2\n        delta_t = Delta_t / m\n\n        # Step 3: Assemble the macro-step matrix M_RESPA.\n        \n        # Kick matrix for the slow potential (half-step)\n        K_half = np.array([\n            [1.0, 0.0],\n            [-0.5 * k_slow * Delta_t, 1.0]\n        ])\n\n        # Velocity-Verlet matrix for the fast Hamiltonian (one sub-step)\n        k_dt_sq = k_fast * delta_t**2\n        \n        # Check if the inner-step is outside its stability regime.\n        # This is not strictly necessary as the final trace/eigenvalue check will\n        # reveal instability, but it's a useful diagnostic.\n        # The condition is k_fast * delta_t**2 < 4.\n        \n        # Elements of the M_VV matrix\n        m_vv_11 = 1.0 - 0.5 * k_dt_sq\n        m_vv_12 = delta_t\n        m_vv_21 = -k_fast * delta_t + 0.25 * k_fast**2 * delta_t**3\n        m_vv_22 = m_vv_11\n        \n        M_vv = np.array([\n            [m_vv_11, m_vv_12],\n            [m_vv_21, m_vv_22]\n        ])\n\n        # Compute the matrix for m inner steps\n        try:\n            M_vv_m = np.linalg.matrix_power(M_vv, m)\n        except np.linalg.LinAlgError:\n            # This can happen if the matrix is singular or not square,\n            # which shouldn't occur here but is good practice to handle.\n            results.append(False)\n            continue\n        \n        # Assemble the full macro-step matrix\n        M_respa = K_half @ M_vv_m @ K_half\n        \n        # Step 4: Check for linear stability.\n        # The condition is that the spectral radius is <= 1.\n        # We compute eigenvalues and check their maximum modulus against 1 with tolerance.\n        try:\n            eigenvalues = np.linalg.eigvals(M_respa)\n            spectral_radius = np.max(np.abs(eigenvalues))\n            \n            # The system is stable if the spectral radius is <= 1.\n            # We use a tolerance to account for floating-point inaccuracies.\n            is_stable = spectral_radius <= 1.0 + tolerance\n            results.append(is_stable)\n\n        except np.linalg.LinAlgError:\n            # If eigenvalue computation fails, the system is unstable.\n            results.append(False)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}