## 引言
在现代宇宙学中，从海量的观测数据（如宇宙微波背景辐射、超新星巡天）中精确推断宇宙学模型的参数，是揭示宇宙起源、演化和最终命运的核心任务。随着模型复杂性和数据精度的不断提升，我们所面临的参数空间变得异常高维且复杂。直接计算描述[参数不确定性](@entry_id:264387)的[后验概率](@entry_id:153467)[分布](@entry_id:182848)在数学上和计算上都变得不可行。这一挑战催生了对强大、高效的统计[采样方法](@entry_id:141232)的需求，而马尔可夫链蒙特卡洛（MCMC）方法正是应对这一挑战的基石。

本文旨在系统性地介绍MCMC在[参数推断](@entry_id:753157)中的应用。我们将从“原理与机制”一章开始，奠定贝叶斯推断的[概率基础](@entry_id:187304)，并深入剖析Metropolis-Hastings、[Gibbs采样](@entry_id:139152)和[哈密顿蒙特卡洛](@entry_id:144208)等核心[MCMC算法](@entry_id:751788)的运作原理。接着，在“应用与交叉学科联系”一章中，我们将展示这些方法如何在现代宇宙学分析中发挥关键作用，如何通过高级技术应对多峰、高相关性等复杂[后验分布](@entry_id:145605)，并探讨其在系统生物学等其他领域的广泛联系。最后，通过“动手实践”中的具体问题，您将有机会将理论知识应用于实际计算。

通过本系列的学习，您将不仅理解MCMC的“如何做”，更能深刻领会其“为什么”有效，从而具备在科研实践中自信地应用这一强大工具的能力。

## 原理与机制

在[宇宙学参数](@entry_id:161338)推断中，我们的目标是利用观测数据来约束理论模型的自由参数。[贝叶斯推断](@entry_id:146958)为此提供了一个强大的、自洽的概率框架。本章将深入探讨支撑现代贝叶斯计算（尤其是[马尔可夫链蒙特卡洛方法](@entry_id:137183)）的核心原理与关键机制。我们将从[贝叶斯定理](@entry_id:151040)的基本构成出发，逐步建立起支撑复杂[宇宙学模型](@entry_id:203562)[参数推断](@entry_id:753157)的理论与算法基础。

### 用于[参数推断](@entry_id:753157)的贝叶斯框架

贝叶斯推断的核心在于[贝叶斯定理](@entry_id:151040)，它以一种严谨的方式更新我们对参数的认知。给定一个理论模型 $M$、一组参数 $\theta$ 和观测数据 $d$，[贝叶斯定理](@entry_id:151040)将参数的**后验概率[分布](@entry_id:182848) (posterior probability distribution)** $p(\theta | d, M)$ 与另外三个关键量联系起来：

$$
p(\theta | d, M) = \frac{p(d | \theta, M) p(\theta | M)}{p(d | M)}
$$

这个表达式的各个组成部分具有明确的统计学意义：

1.  **[后验概率](@entry_id:153467)** $p(\theta | d, M)$：这是我们在观测到数据 $d$ 之后，对参数 $\theta$ 所处状态的认知。它是贝叶斯推断的主要目标，包含了我们关于参数的所有可用信息。

2.  **[似然](@entry_id:167119) (Likelihood)** $p(d | \theta, M)$：似然描述了在给定一组特定参数 $\theta$ 的情况下，观测到当前数据集 $d$ 的概率。它将理论模型与观测数据联系起来。在宇宙学中，这通常涉及一个“正演模型” $m(\theta)$，它将[宇宙学参数](@entry_id:161338)（如[物质密度](@entry_id:263043)参数 $\Omega_{\mathrm{m}}$、物质涨落幅度 $\sigma_{8}$ 等）映射到可观测的量（如[弱引力透镜功率谱](@entry_id:756671)或宇宙微波背景辐射的[角功率谱](@entry_id:161125)），并结合一个描述测量不确定性（即噪声）的[统计模型](@entry_id:165873)。因此，似然函数会根据模型预测与数据的吻合程度，为参数空间中的不同区域赋予权重。

3.  **先验概率 (Prior)** $p(\theta | M)$：先验代表了我们在接触当前数据之前对参数 $\theta$ 的已有知识或信念。它可以包含基础物理约束（例如，[密度参数](@entry_id:265044)不能为负），或来自其他独立实验的结果。先验的作用是排除不符合物理直觉的参数区域，并对推断结果起到正则化作用。在先验为有界[均匀分布](@entry_id:194597)的情况下，[后验分布](@entry_id:145605)在先验支撑集内的形状将完全由似然决定。

4.  **证据 (Evidence)** 或 **边缘[似然](@entry_id:167119) (Marginal Likelihood)** $p(d | M)$：证据是通过对[参数空间](@entry_id:178581)所有可能的 $\theta$ 值进行积分（或[边缘化](@entry_id:264637)）得到的：
    $$
    p(d | M) = \int p(d | \theta, M) p(\theta | M) \, d\theta
    $$
    对于一个给定的模型 $M$ 和数据 $d$，证据是一个常数。它的作用是确保[后验概率](@entry_id:153467)[分布](@entry_id:182848)在整个[参数空间](@entry_id:178581)上的积分为1，使其成为一个合法的概率密度函数。

在[现代宇宙学](@entry_id:752086)中，[参数空间](@entry_id:178581)通常具有很高的维度（例如，一个标准的 $\Lambda$CDM 模型就有6个或更多参数），这使得直接计算或绘制后验分布 $p(\theta | d, M)$ 变得不切实际。我们面临的挑战不再是寻找后验分布的解析表达式，而是从这个[分布](@entry_id:182848)中生成一系列的样本。[马尔可夫链蒙特卡洛](@entry_id:138779)（MCMC）方法正是为解决这一挑战而生的。

### MCMC 的理论基础

MCMC 方法通过构建一个**[马尔可夫链](@entry_id:150828) (Markov chain)** 来生成一系列样本点 $\{\theta_0, \theta_1, \theta_2, \dots\}$。[马尔可夫链](@entry_id:150828)的构建方式特殊，其最终会收敛到一个**[平稳分布](@entry_id:194199) (stationary distribution)** $\pi(\theta)$，而这个平稳分布恰好就是我们想要采样的目标[后验分布](@entry_id:145605) $p(\theta | d, M)$。一旦我们从这个链中收集了足够多的样本，就可以用这些样本的统计特性（如均值、[方差](@entry_id:200758)、分位数等）来近似后验分布的相应特性。

为了使 MCMC 采样有效，其所依赖的[马尔可夫链](@entry_id:150828)必须满足几个关键的理论性质：

-   **不可约性 (Irreducibility)**：此性质保证马尔可夫链可以从任何一个状态出发，在有限步内到达[参数空间](@entry_id:178581)中的任何其他区域。在实践中，这意味着我们的采样算法（或称“提议机制”）必须能够探索整个有意义的[参数空间](@entry_id:178581)，而不会被困在某个子区域内。 

-   **[正常返](@entry_id:195139) (Positive Harris Recurrence)**：此性质保证链不仅会访问参数空间的任何区域，而且返回这些区域的期望时间是有限的。这确保了链存在一个唯一的平稳[概率分布](@entry_id:146404)。对于行为良好的[后验分布](@entry_id:145605)（例如，不是[重尾分布](@entry_id:142737)），这个条件通常是满足的。

-   **[非周期性](@entry_id:275873) (Aperiodicity)**：此性质防止链陷入固定长度的循环中。在大多数 MCMC 算法中，由于存在一个非零的概率拒绝提议并停留在当前状态，这一性质通常能够自然满足。

一个同时满足不可约性、[正常返](@entry_id:195139)和[非周期性](@entry_id:275873)的[马尔可夫链](@entry_id:150828)被称为**遍历的 (ergodic)**。遍历性是 MCMC 方法有效性的理论基石，它保证了**[遍历定理](@entry_id:261967) (ergodic theorem)** 的成立：对于任何[可积函数](@entry_id:191199) $f(\theta)$，其在[马尔可夫链](@entry_id:150828)轨迹上的时间平均值会收敛到其在平稳分布下的空间平均值（即[期望值](@entry_id:153208)）：
$$
\lim_{N \to \infty} \frac{1}{N} \sum_{i=1}^{N} f(\theta_i) = \int f(\theta) \, \pi(\theta) \, d\theta
$$
这正是我们能够使用 MCMC 样本来估计[后验均值](@entry_id:173826)、[方差](@entry_id:200758)等统计量的根本原因。

为了构建一个以目标后验 $\pi(\theta)$ 为平稳分布的马尔可夫链，我们通常会利用一个比[平稳性](@entry_id:143776)更强的条件：**细致平衡 (detailed balance)**。设链的转移核（从状态 $\theta$ 转移到 $\theta'$ 的概率密度）为 $k(\theta, \theta')$，[细致平衡条件](@entry_id:265158)表述为：
$$
\pi(\theta) k(\theta, \theta') = \pi(\theta') k(\theta', \theta)
$$
这个条件意味着在平稳状态下，从 $\theta$ 流向 $\theta'$ 的“[概率流](@entry_id:150949)”与从 $\theta'$ 流向 $\theta$ 的[概率流](@entry_id:150949)相等。满足细致平衡的链必然以 $\pi$ 为其平稳分布，但反之不成立（即存在不满足[细致平衡](@entry_id:145988)但仍有[平稳分布](@entry_id:194199)的链）。然而，[细致平衡](@entry_id:145988)为设计 MCMC 算法提供了一个极其方便的构造性配方。

### 核心 MCMC 算法

#### Metropolis-Hastings 算法

Metropolis-Hastings (MH) 算法是 MCMC 方法的基石。它通过一个“提议-接受/拒绝”机制来满足[细致平衡条件](@entry_id:265158)。算法的每一步如下：
1.  **提议**：给定当前状态 $\theta_t$，从一个**[提议分布](@entry_id:144814) (proposal distribution)** $q(\theta' | \theta_t)$ 中抽取一个候选状态 $\theta'$。
2.  **计算[接受概率](@entry_id:138494)**：计算接受这个候选状态的概率 $\alpha(\theta_t, \theta')$。这个概率被巧妙地设计为：
    $$
    \alpha(\theta_t, \theta') = \min \left( 1, \frac{\pi(\theta') q(\theta_t | \theta')}{\pi(\theta_t) q(\theta' | \theta_t)} \right)
    $$
3.  **接受或拒绝**：从一个 $[0, 1]$ 上的[均匀分布](@entry_id:194597)中生成一个随机数 $u$。如果 $u  \alpha(\theta_t, \theta')$，则接受提议，令 $\theta_{t+1} = \theta'$；否则，拒绝提议，令 $\theta_{t+1} = \theta_t$。

MH 算法的一个关键优势在于其接受概率的计算。注意到接受概率依赖于目标分布的比值 $\pi(\theta') / \pi(\theta_t)$。如果我们代入[贝叶斯定理](@entry_id:151040)的表达式 $\pi(\theta) = p(d|\theta)p(\theta)/p(d)$，会发现证据项 $p(d)$ 在分子和分母中被抵消了：
$$
\frac{\pi(\theta')}{\pi(\theta_t)} = \frac{p(d|\theta')p(\theta')/p(d)}{p(d|\theta_t)p(\theta_t)/p(d)} = \frac{p(d|\theta')p(\theta')}{p(d|\theta_t)p(\theta_t)}
$$
这意味着我们只需要计算一个正比于后验的函数（即[似然](@entry_id:167119)与先验的乘积），而无需计算那个通常难以处理的[高维积分](@entry_id:143557)——证据 $p(d)$。这是 MCMC 能够在实践中广泛应用的核心原因之一。 

如果提议分布是对称的，即 $q(\theta' | \theta) = q(\theta | \theta')$，那么 MH 算法就简化为最初的 **Metropolis 算法**。在这种情况下，接受概率变为：
$$
\alpha(\theta, \theta') = \min \left(1, \frac{\pi(\theta')}{\pi(\theta)}\right)
$$
一个常见的[对称提议](@entry_id:755726)是在当前状态附近进行[随机游走](@entry_id:142620)，例如，从一个以当前状态为中心的多维[高斯分布](@entry_id:154414)中提议新点：$q(\theta' | \theta) = \mathcal{N}(\theta'; \theta, \Sigma)$。由于[高斯分布](@entry_id:154414)的对称性，这种提议的[概率密度函数](@entry_id:140610)满足 $q(\theta'|\theta) = q(\theta|\theta')$，因此其[接受概率](@entry_id:138494)可以直接使用简化的 Metropolis 形式。

#### Gibbs 采样

Gibbs 采样是另一种强大的 MCMC 算法，它适用于多维参数的后验分布。与 MH 算法一次性更新整个参数矢量 $\theta$ 不同，Gibbs 采样通过迭代地对每个参数（或参数块）进行采样，而每次采样都以所有其他参数的当前值为条件。

对于一个参数矢量 $\theta = (\theta_1, \theta_2, \dots, \theta_d)$，Gibbs 采样的第 $t+1$ 步包含以下一系列子步骤：
1.  从 **[全条件分布](@entry_id:266952) (full conditional distribution)** $p(\theta_1 | \theta_{2,t}, \dots, \theta_{d,t}, d)$ 中抽取 $\theta_{1, t+1}$。
2.  从 $p(\theta_2 | \theta_{1,t+1}, \theta_{3,t}, \dots, \theta_{d,t}, d)$ 中抽取 $\theta_{2, t+1}$。
3.  ...
4.  从 $p(\theta_d | \theta_{1,t+1}, \dots, \theta_{d-1,t+1}, d)$ 中抽取 $\theta_{d, t+1}$。

可以证明，这个迭代过程构成的[马尔可夫链](@entry_id:150828)的[平稳分布](@entry_id:194199)就是联合[后验分布](@entry_id:145605) $p(\theta_1, \dots, \theta_d | d)$。Gibbs 采样的吸[引力](@entry_id:175476)在于，如果所有的[全条件分布](@entry_id:266952)都是已知的标准[分布](@entry_id:182848)（如高斯分布、伽马[分布](@entry_id:182848)等），那么采样过程就非常高效，因为每个子步骤都只是从一个标准[分布](@entry_id:182848)中直接抽样，没有接受/拒绝环节。

在许多宇宙学问题中，特别是涉及**层级贝叶斯模型 (hierarchical Bayesian models)** 的情况，纯粹的 Gibbs 采样并不总是可行。例如，在一个分析[Ia型超新星](@entry_id:160917)数据的模型中，参数可能包括[宇宙学参数](@entry_id:161338) $\theta_{\mathrm{cosmo}}$、光变曲线的线性参数（如[绝对星等](@entry_id:157959) $M$ 和斜率 $\alpha$）以及未知的内在弥散 $\sigma_{\mathrm{int}}^2$。在这种模型中：
-   如果线性参数的先验是[高斯分布](@entry_id:154414)，那么它们的联合[全条件分布](@entry_id:266952)通常也是一个多维高斯分布，这得益于**条件共轭性 (conditional conjugacy)**。
-   然而，[宇宙学参数](@entry_id:161338) $\theta_{\mathrm{cosmo}}$ 通常[非线性](@entry_id:637147)地出现在[似然函数](@entry_id:141927)中，其[全条件分布](@entry_id:266952)不是[标准形式](@entry_id:153058)。
-   类似地，内在弥散项 $\sigma_{\mathrm{int}}^2$ 可能出现在[方差](@entry_id:200758)项中（例如，总[方差](@entry_id:200758)为 $\sigma_i^2 + \sigma_{\mathrm{int}}^2$），这也破坏了标准共轭性，导致其[全条件分布](@entry_id:266952)非标准。

在这种情况下，一种常见的策略是采用 **[Metropolis-within-Gibbs](@entry_id:751940)**（或称[混合采样器](@entry_id:750435)）。对于那些[全条件分布](@entry_id:266952)是[标准形式](@entry_id:153058)的参数（如上述的 $M, \alpha$），我们使用 Gibbs 采样步骤。对于那些[全条件分布](@entry_id:266952)非标准的参数（如 $\theta_{\mathrm{cosmo}}, \sigma_{\mathrm{int}}^2$），我们则嵌入一个 Metropolis-Hastings 步骤来对其进行采样。这种[混合方法](@entry_id:163463)结合了两种算法的优点。

#### [哈密顿蒙特卡洛](@entry_id:144208)

[随机游走](@entry_id:142620)式的 Metropolis-Hastings 算法在探索高维[参数空间](@entry_id:178581)时效率可能较低，因为其提议是盲目的。**[哈密顿蒙特卡洛](@entry_id:144208) (Hamiltonian [Monte Carlo](@entry_id:144354), HMC)** 是一种更先进的 MCMC 算法，它利用[后验分布](@entry_id:145605)的梯度信息来生成更智能的、距离更远的提议，从而显著提高[采样效率](@entry_id:754496)。

HMC 引入了物理学中的[哈密顿动力学](@entry_id:156273)概念。它将参数 $\theta$ 视为一个粒子的“位置”，并为其引入一个辅助的“动量”变量 $p$。这个扩展后的系统状态由 $(\theta, p)$ 描述，其总能量由一个**[哈密顿量](@entry_id:172864) (Hamiltonian)** $H(\theta, p)$ 定义：
$$
H(\theta, p) = U(\theta) + K(p)
$$
其中：
-   **势能 (Potential Energy)** $U(\theta)$ 定义为目标[后验分布](@entry_id:145605)的负对数：$U(\theta) = -\ln \pi(\theta)$。
-   **动能 (Kinetic Energy)** $K(p)$ 通常取为二次型：$K(p) = \frac{1}{2} p^T M^{-1} p$，其中 $M$ 是一个被称为“质量矩阵”的对称正定矩阵。

HMC 的采样过程如下：
1.  给定当前位置 $\theta_t$，从一个高斯分布（其协[方差](@entry_id:200758)为 $M$）中随机抽取一个动量 $p_t$。
2.  从初始状态 $(\theta_t, p_t)$ 开始，沿着由[哈密顿量](@entry_id:172864)定义的[能量守恒](@entry_id:140514)[曲面](@entry_id:267450)，使用[数值积分](@entry_id:136578)（如**[蛙跳法](@entry_id:751210) (leapfrog method)**）模拟系统演化一段有限时间 $\tau$。这会产生一个候选状态 $(\theta', p')$。
3.  由于[数值积分](@entry_id:136578)存在离散误差，[哈密顿量](@entry_id:172864)并非严格守恒。为了修正这个误差，HMC 像 MH 算法一样引入一个接受步骤。[接受概率](@entry_id:138494)为：
    $$
    \alpha = \min\left(1, \exp[-H(\theta', p') + H(\theta_t, p_t)]\right)
    $$
    如果提议被接受，则 $\theta_{t+1} = \theta'$；否则 $\theta_{t+1} = \theta_t$。

HMC 的成功依赖于[数值积分器](@entry_id:752799)的两个关键特性：
-   **辛性 (Symplecticity)**：像[蛙跳法](@entry_id:751210)这样的辛积分器能精确地保持相空间的体积。这意味着从 $(\theta, p)$ 到 $(\theta', p')$ 的映射的雅可比行列式恰好为 1。这极大地简化了 MH 接受概率的计算，使其只依赖于[哈密顿量](@entry_id:172864)的变化，而无需计算复杂的雅可比行列式项。
-   **[时间可逆性](@entry_id:274492) (Time-reversibility)**：积分器是时间可逆的，这保证了整个提议过程满足[细致平衡条件](@entry_id:265158)，使得 MH 修正步骤在理论上是正确的。

通过模拟物理轨迹，HMC 能够进行长距离的、高接受率的移动，有效避免了[随机游走](@entry_id:142620)的缓[慢扩散](@entry_id:161635)，特别适合处理具有复杂相关性结构的高维[后验分布](@entry_id:145605)。

### 实践中的诊断与评估

运行 MCMC 算法后，我们得到了一系列参数样本。然而，在使用这些样本进行[科学推断](@entry_id:155119)之前，必须严格评估链的收敛性和[采样效率](@entry_id:754496)。

#### 收敛性诊断

[马尔可夫链](@entry_id:150828)需要一定的时间来“忘记”其初始状态并收敛到[平稳分布](@entry_id:194199)。这个初始阶段被称为**预烧期 (burn-in)**。我们必须丢弃预烧期的样本，只使用链已达到平稳状态后的样本进行分析。

-   **迹图 (Trace Plots)**：判断收敛性的第一步是目视检查每个参数的迹图，即参数值随迭代次数变化的图形。一个健康的迹图应该看起来像围绕一个稳定均值波动的“毛毛虫”，没有任何明显的趋势或漂移。如果迹图显示出缓慢的漂移或周期性结构，则表明链尚未收敛到平稳分布。

-   **Geweke 诊断**: 这是一种更定量的检验方法，它比较链的早期部分和晚期部分的均值。其[原假设](@entry_id:265441)是两个部分的样本都来自同一个[平稳分布](@entry_id:194199)，因此它们的均值应该相等。检验统计量（$z$-score）的计算方式为：
    $$
    Z_G = \frac{\bar{x}_A - \bar{x}_B}{\sqrt{\text{Var}(\bar{x}_A) + \text{Var}(\bar{x}_B)}}
    $$
    其中 $\bar{x}_A$ 和 $\bar{x}_B$ 是早期和晚期部分的样本均值。一个关键点是，在计算均值的[方差](@entry_id:200758) $\text{Var}(\bar{x})$ 时，必须考虑样本间的**[自相关](@entry_id:138991)性 (autocorrelation)**。对于包含 $n$ 个样本、样本[方差](@entry_id:200758)为 $s^2$、[积分自相关时间](@entry_id:637326)为 $\tau$ 的链，均值的[方差近似](@entry_id:268585)为 $s^2 \tau / n$。忽略自相关会严重低估不确定性，可能导致错误的结论。如果 $Z_G$ 的[绝对值](@entry_id:147688)很大（例如大于2或3），则强烈表明链尚未收敛。

-   **Gelman-Rubin 诊断 ($\hat{R}$)**：该诊断要求从[参数空间](@entry_id:178581)中多个分散的初始点并行运行多条（$m$ 条）马尔可夫链。其核心思想是比较**链间[方差](@entry_id:200758) (between-chain variance, $B$)** 和**链内[方差](@entry_id:200758) (within-chain variance, $W$)**。如果所有链都已经收敛到同一个平稳分布，那么不同链的均值应该彼此接近，链间[方差](@entry_id:200758) $B$ 应该很小；同时，每条链内部的波动 $W$ 应该能代表整个[后验分布](@entry_id:145605)的[方差](@entry_id:200758)。$\hat{R}$ 统计量（又称[潜在尺度缩减因子](@entry_id:753645)）正是这两个[方差](@entry_id:200758)的量度：
    $$
    \hat{R} = \sqrt{\frac{\hat{V}}{W}}
    $$
    其中 $\hat{V}$ 是对后验总[方差](@entry_id:200758)的一个估计，它结合了 $W$ 和 $B$。当链收敛时，$\hat{V}$ 和 $W$ 会趋于一致，因此 $\hat{R}$ 会趋近于 1。通常，$\hat{R}  1.01$ 被认为是收敛的一个可接受标准。然而，$\hat{R}$ 诊断的一个局限性在于，如果后验分布是多峰的，并且所有链都不幸地被困在了同一个局域模态中，那么 $\hat{R}$ 可能会错误地指示收敛。

#### [采样效率](@entry_id:754496)评估

链收敛后，我们还需要评估其探索后验分布的效率。效率低下的采样器会产生高度自相关的样本，这意味着需要非常长的链才能获得对后验的可靠估计。

-   **[积分自相关时间](@entry_id:637326) (Integrated Autocorrelation Time, IAT)**：对于链中的某个函数 $f(\theta)$，其[自相关函数](@entry_id:138327) $\rho_k$ 衡量了相隔 $k$ 步的样本之间的相关性。IAT, $\tau_{\mathrm{int}}$, 是对总相关性的一个度量：
    $$
    \tau_{\mathrm{int}} = 1 + 2\sum_{k=1}^{\infty} \rho_k
    $$
    $\tau_{\mathrm{int}}$ 的直观解释是：我们需要大约 $\tau_{\mathrm{int}}$ 个相关样本，才能获得相当于一个[独立样本](@entry_id:177139)的信息量。IAT 越小，[采样效率](@entry_id:754496)越高。

-   **[有效样本量](@entry_id:271661) (Effective Sample Size, ESS)**：给定一个总长度为 $N$ 的马尔可夫链，其[有效样本量](@entry_id:271661) $N_{\mathrm{eff}}$ 定义为：
    $$
    N_{\mathrm{eff}} = \frac{N}{\tau_{\mathrm{int}}}
    $$
    $N_{\mathrm{eff}}$ 告诉我们，这 $N$ 个相关样本在估计[后验均值](@entry_id:173826)等统计量时，其统计能力等价于多少个来自后验分布的[独立样本](@entry_id:177139)。例如，一个长度为 $N=50000$ 的链，如果其 IAT 为 $\tau_{\mathrm{int}} \approx 99$，那么它的[有效样本量](@entry_id:271661)仅为 $N_{\mathrm{eff}} \approx 505$。在报告 MCMC 结果时，提供 ESS 是至关重要的，因为它直接反映了推断结果的统计精度。

### [模型比较](@entry_id:266577)的角色

最后，值得重申证据 $p(d|M)$ 的双重角色。在对一个**固定模型**进行[参数推断](@entry_id:753157)时，由于证据对于参数 $\theta$ 是一个常数，它在 MCMC 的[接受概率](@entry_id:138494)计算中被消去，因此可以被忽略。然而，当我们想要比较两个或多个**不同模型**（例如，$\Lambda$CDM 模型与一个包含[暗能量状态方程](@entry_id:158117)参数 $w$ 的 $w$CDM 模型）时，证据就变得至关重要。

[贝叶斯模型比较](@entry_id:637692)的核心是计算**[贝叶斯因子](@entry_id:143567) (Bayes factor)** $K$，即两个[模型证据](@entry_id:636856)的比值：
$$
K = \frac{p(d | M_2)}{p(d | M_1)}
$$
[贝叶斯因子](@entry_id:143567)量化了数据在多大程度上支持一个模型胜过另一个模型。计算证据本身是一个艰巨的[数值积分](@entry_id:136578)任务，它超出了标准 MCMC [参数推断](@entry_id:753157)的范畴，需要如嵌套采样 (nested sampling) 或[热力学积分](@entry_id:156321) (thermodynamic integration) 等专门的算法。