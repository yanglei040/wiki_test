{
    "hands_on_practices": [
        {
            "introduction": "Real cosmological surveys are fundamentally limited as they can only observe a fraction of the full sky. This practice guides you through a foundational calculation in cosmological statistics: deriving how this partial sky coverage increases the variance of a cross-power spectrum estimator. Understanding the origin of the famous $1/f_{\\mathrm{sky}}$ penalty on variance is essential for correctly interpreting the statistical power of any cosmological analysis and for designing future surveys .",
            "id": "3469920",
            "problem": "Consider two statistically isotropic, mean-zero, Gaussian scalar cosmological fields $X(\\hat{\\boldsymbol{n}})$ and $Y(\\hat{\\boldsymbol{n}})$ defined on the celestial sphere, where $\\hat{\\boldsymbol{n}}$ is a unit direction. Let their spherical harmonic coefficients be $a_{\\ell m}^{X}$ and $a_{\\ell m}^{Y}$, defined by $X(\\hat{\\boldsymbol{n}})=\\sum_{\\ell m} a_{\\ell m}^{X} Y_{\\ell m}(\\hat{\\boldsymbol{n}})$ and $Y(\\hat{\\boldsymbol{n}})=\\sum_{\\ell m} a_{\\ell m}^{Y} Y_{\\ell m}(\\hat{\\boldsymbol{n}})$, with $Y_{\\ell m}$ the spherical harmonics. The ensemble-mean two-point statistics on the full sky are\n$$\n\\langle a_{\\ell m}^{X} a_{\\ell' m'}^{Y*} \\rangle = \\delta_{\\ell \\ell'} \\delta_{m m'} C_{\\ell}^{XY}, \\quad\n\\langle a_{\\ell m}^{X} a_{\\ell' m'}^{X*} \\rangle = \\delta_{\\ell \\ell'} \\delta_{m m'} C_{\\ell}^{XX}, \\quad\n\\langle a_{\\ell m}^{Y} a_{\\ell' m'}^{Y*} \\rangle = \\delta_{\\ell \\ell'} \\delta_{m m'} C_{\\ell}^{YY},\n$$\nwhere $C_{\\ell}^{XY}$ is the full-sky cross-power spectrum and $C_{\\ell}^{XX}$, $C_{\\ell}^{YY}$ are the auto-power spectra. Let the observed maps be masked by deterministic window functions $W_{X}(\\hat{\\boldsymbol{n}})$ and $W_{Y}(\\hat{\\boldsymbol{n}})$, respectively, with $0 \\le W_{X}, W_{Y} \\le 1$, not necessarily identical, and define the masked (pseudo) harmonic coefficients\n$$\n\\tilde{a}_{\\ell m}^{X} = \\int \\mathrm{d}\\Omega\\, W_{X}(\\hat{\\boldsymbol{n}})\\, X(\\hat{\\boldsymbol{n}})\\, Y_{\\ell m}^{*}(\\hat{\\boldsymbol{n}}), \\quad\n\\tilde{a}_{\\ell m}^{Y} = \\int \\mathrm{d}\\Omega\\, W_{Y}(\\hat{\\boldsymbol{n}})\\, Y(\\hat{\\boldsymbol{n}})\\, Y_{\\ell m}^{*}(\\hat{\\boldsymbol{n}}),\n$$\nand the pseudo cross-spectrum estimator\n$$\n\\tilde{C}_{\\ell}^{XY} \\equiv \\frac{1}{2\\ell+1} \\sum_{m=-\\ell}^{\\ell} \\tilde{a}_{\\ell m}^{X}\\, \\tilde{a}_{\\ell m}^{Y*}.\n$$\nAssume additive instrumental or shot noise contributions $n^{X}$ and $n^{Y}$ that are statistically isotropic, Gaussian, and uncorrelated between the two probes, such that the observed auto-power spectra are $C_{\\ell}^{XX,\\mathrm{tot}} = C_{\\ell}^{XX} + N_{\\ell}^{X}$ and $C_{\\ell}^{YY,\\mathrm{tot}} = C_{\\ell}^{YY} + N_{\\ell}^{Y}$, with $\\langle a_{\\ell m}^{X} n_{\\ell' m'}^{Y*} \\rangle = 0$ and $\\langle n_{\\ell m}^{X} n_{\\ell' m'}^{Y*} \\rangle = 0$. Define the effective overlapping sky fraction\n$$\nf_{\\mathrm{sky}}^{XY} \\equiv \\frac{1}{4\\pi} \\int \\mathrm{d}\\Omega\\, W_{X}(\\hat{\\boldsymbol{n}})\\, W_{Y}(\\hat{\\boldsymbol{n}}),\n$$\nwhich reduces to the geometric overlap fraction for binary masks.\n\nStarting from the above statistical assumptions and definitions, and using only Gaussianity, statistical isotropy, and the orthonormality of spherical harmonics, derive how partial sky overlap enters the covariance of $\\tilde{C}_{\\ell}^{XY}$ as a suppression of the effective number of independent $m$-modes. Then, consider the standard deconvolution of mask-induced mode coupling via the mode-coupling matrix $M_{\\ell \\ell'}^{XY}$, defining a deconvolved estimator $\\hat{C}_{\\ell}^{XY} \\equiv \\sum_{\\ell'} (M^{-1})_{\\ell \\ell'}^{XY}\\, \\tilde{C}_{\\ell'}^{XY}$, and under the approximation that $M_{\\ell \\ell'}^{XY}$ is sufficiently narrow around the diagonal, propagate the pseudo-spectrum covariance to obtain an approximate analytic expression for the variance of $\\hat{C}_{\\ell}^{XY}$ in terms of $f_{\\mathrm{sky}}^{XY}$ and the underlying full-sky spectra.\n\nYour final answer must be a single closed-form expression for $\\mathrm{Var}\\!\\left(\\hat{C}_{\\ell}^{XY}\\right)$, expressed in terms of $\\ell$, $f_{\\mathrm{sky}}^{XY}$, $C_{\\ell}^{XX}$, $C_{\\ell}^{YY}$, $C_{\\ell}^{XY}$, $N_{\\ell}^{X}$, and $N_{\\ell}^{Y}$. No numerical evaluation is required. If you introduce any additional definitions or intermediate quantities, ensure they are eliminated in the final expression. Express the final result without units.",
            "solution": "The goal is to derive the variance of the deconvolved cross-power spectrum estimator, $\\mathrm{Var}(\\hat{C}_{\\ell}^{XY})$, under a set of simplifying approximations. The derivation proceeds in three main stages: first, expressing the covariance of the pseudo-spectrum estimator $\\tilde{C}_{\\ell}^{XY}$; second, propagating this covariance to the deconvolved estimator $\\hat{C}_{\\ell}^{XY}$ using the narrow-band approximation; and third, applying a crucial simplification to the window function geometry to match the required form of the answer.\n\nLet the observed fields be $X'(\\hat{\\boldsymbol{n}}) = X(\\hat{\\boldsymbol{n}}) + n^X(\\hat{\\boldsymbol{n}})$ and $Y'(\\hat{\\boldsymbol{n}}) = Y(\\hat{\\boldsymbol{n}}) + n^Y(\\hat{\\boldsymbol{n}})$. The total auto-power spectra are $C_{\\ell}^{XX, \\mathrm{tot}} = C_{\\ell}^{XX} + N_{\\ell}^{X}$ and $C_{\\ell}^{YY, \\mathrm{tot}} = C_{\\ell}^{YY} + N_{\\ell}^{Y}$. Since the signal and noises are uncorrelated between the two probes, the total cross-power spectrum is simply $C_{\\ell}^{XY, \\mathrm{tot}} = C_{\\ell}^{XY}$.\n\nThe fields $X$, $Y$, $n^X$, and $n^Y$ are assumed to be statistically isotropic, mean-zero, and Gaussian. Consequently, the masked harmonic coefficients $\\tilde{a}_{\\ell m}^{X}$ and $\\tilde{a}_{\\ell m}^{Y}$ are also mean-zero Gaussian random variables.\n\nThe variance of the pseudo cross-spectrum estimator $\\tilde{C}_{\\ell}^{XY}$ is a special case of the covariance $\\mathrm{Cov}(\\tilde{C}_{\\ell_1}^{XY}, \\tilde{C}_{\\ell_2}^{XY}) = \\langle \\tilde{C}_{\\ell_1}^{XY} \\tilde{C}_{\\ell_2}^{XY} \\rangle - \\langle \\tilde{C}_{\\ell_1}^{XY} \\rangle \\langle \\tilde{C}_{\\ell_2}^{XY} \\rangle$. For $\\ell_1 = \\ell_2 = \\ell$:\n$$\n\\mathrm{Var}(\\tilde{C}_{\\ell}^{XY}) = \\left\\langle \\left( \\frac{1}{2\\ell+1} \\sum_{m} \\tilde{a}_{\\ell m}^{X} \\tilde{a}_{\\ell m}^{Y*} \\right)^2 \\right\\rangle - \\left\\langle \\frac{1}{2\\ell+1} \\sum_{m} \\tilde{a}_{\\ell m}^{X} \\tilde{a}_{\\ell m}^{Y*} \\right\\rangle^2\n$$\n$$\n\\mathrm{Var}(\\tilde{C}_{\\ell}^{XY}) = \\frac{1}{(2\\ell+1)^2} \\sum_{m_1, m_2} \\left[ \\langle \\tilde{a}_{\\ell m_1}^{X} \\tilde{a}_{\\ell m_1}^{Y*} \\tilde{a}_{\\ell m_2}^{X} \\tilde{a}_{\\ell m_2}^{Y*} \\rangle - \\langle \\tilde{a}_{\\ell m_1}^{X} \\tilde{a}_{\\ell m_1}^{Y*} \\rangle \\langle \\tilde{a}_{\\ell m_2}^{X} \\tilde{a}_{\\ell m_2}^{Y*} \\rangle \\right]\n$$\nApplying Wick's theorem for zero-mean complex Gaussian variables, the four-point function expands as:\n$$\n\\langle \\tilde{a}_{\\ell m_1}^{X} \\tilde{a}_{\\ell m_1}^{Y*} \\tilde{a}_{\\ell m_2}^{X} \\tilde{a}_{\\ell m_2}^{Y*} \\rangle = \\langle \\tilde{a}_{\\ell m_1}^{X} \\tilde{a}_{\\ell m_1}^{Y*} \\rangle \\langle \\tilde{a}_{\\ell m_2}^{X} \\tilde{a}_{\\ell m_2}^{Y*} \\rangle + \\langle \\tilde{a}_{\\ell m_1}^{X} \\tilde{a}_{\\ell m_2}^{X*} \\rangle \\langle \\tilde{a}_{\\ell m_1}^{Y*} \\tilde{a}_{\\ell m_2}^{Y} \\rangle + \\langle \\tilde{a}_{\\ell m_1}^{X} \\tilde{a}_{\\ell m_2}^{Y*} \\rangle \\langle \\tilde{a}_{\\ell m_1}^{Y*} \\tilde{a}_{\\ell m_2}^{X} \\rangle\n$$\nAssuming statistical reality for the fields (i.e., $\\langle ab \\rangle = 0$), the last term vanishes. The first term cancels the subtracted term in the variance expression. Therefore,\n$$\n\\mathrm{Var}(\\tilde{C}_{\\ell}^{XY}) = \\frac{1}{(2\\ell+1)^2} \\sum_{m_1, m_2} \\langle \\tilde{a}_{\\ell m_1}^{X} \\tilde{a}_{\\ell m_2}^{X*} \\rangle \\langle \\tilde{a}_{\\ell m_1}^{Y*} \\tilde{a}_{\\ell m_2}^{Y} \\rangle\n$$\nThe covariance of the pseudo-harmonic coefficients can be expressed as:\n$$\n\\langle \\tilde{a}_{\\ell m_1}^{A} \\tilde{a}_{\\ell m_2}^{B*} \\rangle = \\iint d\\Omega_1 d\\Omega_2 W_A(\\hat{\\boldsymbol{n}}_1) W_B(\\hat{\\boldsymbol{n}}_2) \\langle A'(\\hat{\\boldsymbol{n}}_1) B'(\\hat{\\boldsymbol{n}}_2)^* \\rangle Y_{\\ell m_1}^*(\\hat{\\boldsymbol{n}}_1) Y_{\\ell m_2}(\\hat{\\boldsymbol{n}}_2)\n$$\nUsing the two-point correlation function $\\langle A'(\\hat{\\boldsymbol{n}}_1) B'(\\hat{\\boldsymbol{n}}_2)^* \\rangle = \\sum_{\\ell'} \\frac{2\\ell'+1}{4\\pi} C_{\\ell'}^{AB,\\mathrm{tot}} P_{\\ell'}(\\hat{\\boldsymbol{n}}_1 \\cdot \\hat{\\boldsymbol{n}}_2)$, we can write:\n$$\n\\langle \\tilde{a}_{\\ell m_1}^{A} \\tilde{a}_{\\ell m_2}^{B*} \\rangle = \\sum_{\\ell'} C_{\\ell'}^{AB,\\mathrm{tot}} \\iint d\\Omega_1 d\\Omega_2 W_A(\\hat{\\boldsymbol{n}}_1) W_B(\\hat{\\boldsymbol{n}}_2) \\frac{2\\ell'+1}{4\\pi} P_{\\ell'}(\\hat{\\boldsymbol{n}}_1 \\cdot \\hat{\\boldsymbol{n}}_2) Y_{\\ell m_1}^*(\\hat{\\boldsymbol{n}}_1) Y_{\\ell m_2}(\\hat{\\boldsymbol{n}}_2)\n$$\nUnder the approximation that the spectra $C_{\\ell'}^{AB,\\mathrm{tot}}$ are slowly varying with $\\ell'$, we can replace $C_{\\ell'}^{AB,\\mathrm{tot}}$ with $C_{\\ell}^{AB,\\mathrm{tot}}$ and use the completeness relation $\\sum_{\\ell'} \\frac{2\\ell'+1}{4\\pi} P_{\\ell'}(\\hat{\\boldsymbol{n}}_1 \\cdot \\hat{\\boldsymbol{n}}_2) = \\delta(\\hat{\\boldsymbol{n}}_1 - \\hat{\\boldsymbol{n}}_2)$. This yields the small-angle or high-$\\ell$ approximation for the covariance:\n$$\n\\langle \\tilde{a}_{\\ell m_1}^{A} \\tilde{a}_{\\ell m_2}^{B*} \\rangle \\approx C_{\\ell}^{AB,\\mathrm{tot}} \\int d\\Omega\\, W_A(\\hat{\\boldsymbol{n}}) W_B(\\hat{\\boldsymbol{n}}) Y_{\\ell m_1}^*(\\hat{\\boldsymbol{n}}) Y_{\\ell m_2}(\\hat{\\boldsymbol{n}}) \\equiv C_{\\ell}^{AB,\\mathrm{tot}} K_{\\ell m_1, \\ell m_2}^{W_A W_B}\n$$\nHere $K_{\\ell m_1, \\ell m_2}^{W_A W_B}$ is the mode-coupling matrix for the product window $W_A W_B$. Substituting this into the variance expression:\n$$\n\\mathrm{Var}(\\tilde{C}_{\\ell}^{XY}) \\approx \\frac{1}{(2\\ell+1)^2} \\sum_{m_1, m_2} (C_{\\ell}^{XX,\\mathrm{tot}} K_{\\ell m_1, \\ell m_2}^{W_X^2}) (C_{\\ell}^{YY,\\mathrm{tot}} K_{\\ell m_2, \\ell m_1}^{W_Y^2}) = \\frac{C_{\\ell}^{XX,\\mathrm{tot}} C_{\\ell}^{YY,\\mathrm{tot}}}{(2\\ell+1)^2} \\mathrm{Tr}( \\mathbf{K}^{W_X^2} \\mathbf{K}^{W_Y^2} )\n$$\nNote that for real fields, we have used $C_{\\ell}^{YX}=(C_{\\ell}^{XY})^*=C_{\\ell}^{XY}$ and the cross-part of the variance becomes $\\langle \\tilde{a}^X \\tilde{a}^{Y*} \\rangle \\langle \\tilde{a}^Y \\tilde{a}^{X*} \\rangle = |\\langle \\tilde{a}^X \\tilde{a}^{Y*} \\rangle|^2$. The full variance should include both auto- and cross- terms from the Wick expansion:\n$$\n\\mathrm{Var}(\\tilde{C}_{\\ell}^{XY}) \\approx \\frac{1}{(2\\ell+1)^2} \\left[ C_{\\ell}^{XX,\\mathrm{tot}} C_{\\ell}^{YY,\\mathrm{tot}} \\mathrm{Tr}(\\mathbf{K}^{W_X^2} \\mathbf{K}^{W_Y^2}) + (C_{\\ell}^{XY})^2 \\mathrm{Tr}(\\mathbf{K}^{W_X W_Y} \\mathbf{K}^{W_Y W_X}) \\right]\n$$\nThe trace of a product of coupling matrices can be approximated in the high-$\\ell$ limit:\n$$\n\\mathrm{Tr}(\\mathbf{K}^{W_A} \\mathbf{K}^{W_B}) = \\iint d\\Omega_1 d\\Omega_2 W_A(\\hat{\\boldsymbol{n}}_1)W_B(\\hat{\\boldsymbol{n}}_2) \\left(\\frac{2\\ell+1}{4\\pi} P_\\ell(\\hat{\\boldsymbol{n}}_1 \\cdot \\hat{\\boldsymbol{n}}_2)\\right)^2 \\approx (2\\ell+1)\\frac{\\int W_A(\\hat{\\boldsymbol{n}})W_B(\\hat{\\boldsymbol{n}}) d\\Omega}{4\\pi}\n$$\nApplying this gives:\n$$\n\\mathrm{Var}(\\tilde{C}_{\\ell}^{XY}) \\approx \\frac{1}{2\\ell+1} \\left[ C_{\\ell}^{XX,\\mathrm{tot}} C_{\\ell}^{YY,\\mathrm{tot}} \\frac{\\int W_X^2 W_Y^2 d\\Omega}{4\\pi} + (C_{\\ell}^{XY})^2 \\frac{\\int (W_X W_Y)^2 d\\Omega}{4\\pi} \\right]\n$$\nNext, we propagate this to the deconvolved estimator $\\hat{C}_{\\ell}^{XY} = \\sum_{\\ell'} (M^{-1})_{\\ell \\ell'}^{XY} \\tilde{C}_{\\ell'}^{XY}$. The narrow-band approximation implies $M_{\\ell\\ell'}^{XY}$ is diagonally dominant, so $(M^{-1})_{\\ell\\ell'}^{XY} \\approx \\delta_{\\ell\\ell'} (M_{\\ell\\ell}^{XY})^{-1}$. The expectation of the pseudo-spectrum is $\\langle \\tilde{C}_\\ell^{XY} \\rangle = \\sum_{\\ell'} M_{\\ell\\ell'}^{XY} C_{\\ell'}^{XY}$. Under the same approximations, $\\langle \\tilde{C}_\\ell^{XY} \\rangle \\approx C_\\ell^{XY} \\sum_{\\ell'} M_{\\ell\\ell'}^{XY} \\approx C_\\ell^{XY} f_{\\mathrm{sky}}^{XY, \\mathrm{quad}}$, where $f_{\\mathrm{sky}}^{XY, \\mathrm{quad}}=\\frac{1}{4\\pi}\\int W_X W_Y d\\Omega = f_{\\mathrm{sky}}^{XY}$. Thus, the deconvolution step is approximately division by $f_{\\mathrm{sky}}^{XY}$, so $\\hat{C}_{\\ell}^{XY} \\approx \\tilde{C}_{\\ell}^{XY} / f_{\\mathrm{sky}}^{XY}$.\nThe variance is then $\\mathrm{Var}(\\hat{C}_{\\ell}^{XY}) \\approx \\mathrm{Var}(\\tilde{C}_{\\ell}^{XY}) / (f_{\\mathrm{sky}}^{XY})^2$.\n$$\n\\mathrm{Var}(\\hat{C}_{\\ell}^{XY}) \\approx \\frac{1}{(f_{\\mathrm{sky}}^{XY})^2 (2\\ell+1)} \\left[ C_{\\ell}^{XX,\\mathrm{tot}} C_{\\ell}^{YY,\\mathrm{tot}} \\frac{\\int W_X^2 W_Y^2 d\\Omega}{4\\pi} + (C_{\\ell}^{XY})^2 \\frac{\\int (W_X W_Y)^2 d\\Omega}{4\\pi} \\right]\n$$\nThis expression still contains integrals that are not specified in the required list of final variables. To proceed, we must make a further simplification. The problem text gives a hint by mentioning \"which reduces to the geometric overlap fraction for binary masks\". If we assume the masks are binary, i.e., $W_X, W_Y \\in \\{0, 1\\}$, then $W_X^2 = W_X$ and $W_Y^2 = W_Y$.\nThis simplifies the integrals significantly:\n$$\n\\frac{\\int W_X^2 W_Y^2 d\\Omega}{4\\pi} = \\frac{\\int W_X W_Y d\\Omega}{4\\pi} = f_{\\mathrm{sky}}^{XY}\n$$\n$$\n\\frac{\\int (W_X W_Y)^2 d\\Omega}{4\\pi} = \\frac{\\int W_X W_Y d\\Omega}{4\\pi} = f_{\\mathrm{sky}}^{XY}\n$$\nAlthough this assumption is strong and not strictly required by the condition $0 \\le W_{X,Y} \\le 1$, it is necessary to reduce the expression to the variables allowed in the final answer. Substituting these results:\n$$\n\\mathrm{Var}(\\hat{C}_{\\ell}^{XY}) \\approx \\frac{1}{(f_{\\mathrm{sky}}^{XY})^2 (2\\ell+1)} \\left[ C_{\\ell}^{XX,\\mathrm{tot}} C_{\\ell}^{YY,\\mathrm{tot}} f_{\\mathrm{sky}}^{XY} + (C_{\\ell}^{XY})^2 f_{\\mathrm{sky}}^{XY} \\right]\n$$\n$$\n\\mathrm{Var}(\\hat{C}_{\\ell}^{XY}) \\approx \\frac{f_{\\mathrm{sky}}^{XY}}{(f_{\\mathrm{sky}}^{XY})^2 (2\\ell+1)} \\left[ C_{\\ell}^{XX,\\mathrm{tot}} C_{\\ell}^{YY,\\mathrm{tot}} + (C_{\\ell}^{XY})^2 \\right]\n$$\n$$\n\\mathrm{Var}(\\hat{C}_{\\ell}^{XY}) \\approx \\frac{1}{(2\\ell+1) f_{\\mathrm{sky}}^{XY}} \\left[ (C_{\\ell}^{XX} + N_{\\ell}^{X})(C_{\\ell}^{YY} + N_{\\ell}^{Y}) + (C_{\\ell}^{XY})^2 \\right]\n$$\nThis is the final expression for the variance of the deconvolved cross-power spectrum under the stated approximations, most notably the high-$\\ell$ limit and the assumption of binary masks. The factor $1/f_{\\mathrm{sky}}^{XY}$ represents the increase in variance due to the reduction in the number of modes from observing only a fraction of the sky.",
            "answer": "$$\\boxed{\\frac{1}{(2\\ell+1) f_{\\mathrm{sky}}^{XY}} \\left[ \\left(C_{\\ell}^{XX} + N_{\\ell}^{X}\\right) \\left(C_{\\ell}^{YY} + N_{\\ell}^{Y}\\right) + \\left(C_{\\ell}^{XY}\\right)^2 \\right]}$$"
        },
        {
            "introduction": "Beyond the cosmological signal, our maps are often contaminated by astrophysical foregrounds or instrumental effects. This practice explores the statistical consequences of mode projection, a powerful technique to mitigate these contaminants by removing the modes they occupy. This exercise demonstrates from first principles how this cleaning process introduces a predictable increase in the variance of our estimators, a cost that must be quantified to build a robust error budget .",
            "id": "3469891",
            "problem": "Consider a cross-correlation analysis between Cosmic Microwave Background (CMB) lensing convergence, denoted by the field $\\kappa$, and a galaxy overdensity field, denoted by $g$. In a single spherical harmonic band at multipole $\\ell$, assume the following setup.\n\nThe fundamental base consists of the definitions of spherical harmonic coefficients $a_{\\ell m}$, Gaussian random field properties, and unbiased estimators constructed from these coefficients. Let $a_{\\ell m}^{\\kappa}$ and $a_{\\ell m}^{g}$ denote the spherical harmonic coefficients of $\\kappa$ and $g$, respectively, for a fixed multipole $\\ell$ and $m$ running over the $M$ available modes in the band. Assume the fields are mean-zero, statistically isotropic Gaussian random fields with per-mode covariance\n$$\n\\mathbb{E}\\left[a_{\\ell m}^{\\kappa} a_{\\ell m}^{\\kappa}\\right] = C_{\\ell}^{\\kappa\\kappa}, \\quad\n\\mathbb{E}\\left[a_{\\ell m}^{g} a_{\\ell m}^{g}\\right] = C_{\\ell}^{gg}, \\quad\n\\mathbb{E}\\left[a_{\\ell m}^{\\kappa} a_{\\ell m}^{g}\\right] = C_{\\ell}^{\\kappa g},\n$$\nand modes are independent across $m$. The observed galaxy field is contaminated by observational systematics (e.g., stellar density, dust, seeing), modeled by a set of $p$ linearly independent template vectors forming the columns of a matrix $T \\in \\mathbb{R}^{M \\times p}$. These templates span the subspace of contaminant modes to be removed. Define the mode projection operator\n$$\nP \\equiv I - T\\left(T^{\\top}T\\right)^{-1}T^{\\top},\n$$\nwhich projects any vector onto the orthogonal complement of the template subspace. The projected observed galaxy coefficients are $P\\,a_{\\ell}^{g,\\mathrm{obs}}$, and the naive cross-spectrum estimator is\n$$\n\\widehat{C}_{\\ell,\\mathrm{naive}}^{\\kappa g} \\equiv \\frac{1}{M}\\left(a_{\\ell}^{\\kappa}\\right)^{\\top} P\\, a_{\\ell}^{g,\\mathrm{obs}}.\n$$\n\nStarting from these definitions and Gaussian field properties (including Wick’s theorem), derive from first principles:\n1. The expectation value of $\\widehat{C}_{\\ell,\\mathrm{naive}}^{\\kappa g}$ in terms of $M$, $p$, and $C_{\\ell}^{\\kappa g}$, and define the residual bias\n$$\nb_{\\ell} \\equiv \\mathbb{E}\\left[\\widehat{C}_{\\ell,\\mathrm{naive}}^{\\kappa g}\\right] - C_{\\ell}^{\\kappa g}.\n$$\n2. The variance of the unbiased, corrected estimator\n$$\n\\widehat{C}_{\\ell,\\mathrm{corr}}^{\\kappa g} \\equiv \\frac{1}{M-p}\\left(a_{\\ell}^{\\kappa}\\right)^{\\top} P\\, a_{\\ell}^{g,\\mathrm{obs}},\n$$\nand the variance of the baseline estimator without projection\n$$\n\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g} \\equiv \\frac{1}{M}\\left(a_{\\ell}^{\\kappa}\\right)^{\\top} a_{\\ell}^{g},\n$$\nto obtain the variance inflation factor due to template marginalization,\n$$\nF_{\\ell} \\equiv \\frac{\\mathrm{Var}\\left(\\widehat{C}_{\\ell,\\mathrm{corr}}^{\\kappa g}\\right)}{\\mathrm{Var}\\left(\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g}\\right)}.\n$$\nYour derivation must begin only from the stated Gaussian field properties and the definition of $P$, avoid any shortcut formulas, and must demonstrate the logic by transforming the problem into an orthonormal basis where the projector $P$ is diagonal.\n\nAlgorithmic task. Implement a program that, given the number of modes $M$, the number of templates $p$, and the bandpower values $C_{\\ell}^{\\kappa g}$, $C_{\\ell}^{\\kappa\\kappa}$, and $C_{\\ell}^{gg}$, computes:\n- The residual bias $b_{\\ell}$ for the naive estimator defined above (a float).\n- The variance inflation factor $F_{\\ell}$ for the corrected estimator relative to the baseline (a float).\n\nBoth quantities are dimensionless numbers. Use the derived closed-form expressions rather than Monte Carlo simulation.\n\nTest suite. Evaluate the program on the following four parameter sets, covering a general case, moderate marginalization, heavy marginalization, and a near-boundary case:\n- Case $1$: $M=1024$, $p=1$, $C_{\\ell}^{\\kappa g}=2.0$, $C_{\\ell}^{\\kappa\\kappa}=10.0$, $C_{\\ell}^{gg}=8.0$.\n- Case $2$: $M=64$, $p=8$, $C_{\\ell}^{\\kappa g}=2.0$, $C_{\\ell}^{\\kappa\\kappa}=10.0$, $C_{\\ell}^{gg}=8.0$.\n- Case $3$: $M=200$, $p=100$, $C_{\\ell}^{\\kappa g}=1.2$, $C_{\\ell}^{\\kappa\\kappa}=5.0$, $C_{\\ell}^{gg}=4.0$.\n- Case $4$: $M=20$, $p=19$, $C_{\\ell}^{\\kappa g}=0.5$, $C_{\\ell}^{\\kappa\\kappa}=3.0$, $C_{\\ell}^{gg}=2.0$.\n\nAnswer specification and final output format. For each case, compute two floats in the order $(b_{\\ell}, F_{\\ell})$ and aggregate all eight floats into a single list. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each float rounded to six decimal places (for example, $\\left[\\dots\\right]$). No other text should be printed.",
            "solution": "The core of the problem is to determine the statistical properties of cross-spectrum estimators when modes contaminated by systematics are removed via projection. We are given vectors of spherical harmonic coefficients $a_{\\ell}^{\\kappa}$ and $a_{\\ell}^{g}$ for a fixed multipole $\\ell$, each being a vector of $M$ modes. These are instances of zero-mean Gaussian random fields. Their covariance structure is given by:\n$$\n\\mathbb{E}\\left[a_{\\ell i}^{X} a_{\\ell j}^{Y}\\right] = \\delta_{ij} C_{\\ell}^{XY}\n$$\nwhere $X, Y \\in \\{\\kappa, g\\}$, $i$ and $j$ are mode indices from $1$ to $M$, $\\delta_{ij}$ is the Kronecker delta, and $C_{\\ell}^{XY}$ are the auto- and cross-power spectra. We assume, as is standard, that the observed galaxy field $a_{\\ell}^{g, \\mathrm{obs}}$ upon which the projection is performed is equivalent to the true cosmological signal $a_{\\ell}^{g}$ for the purposes of this calculation. This allows us to isolate the statistical cost of the projection operation itself.\n\nThe projection operator $P = I - T(T^{\\top}T)^{-1}T^{\\top}$ projects onto the subspace orthogonal to the one spanned by the $p$ template vectors in $T$. $P$ is a symmetric ($P=P^\\top$) and idempotent ($P^2=P$) matrix. Its rank, which is equal to its trace, is $\\mathrm{rank}(P) = \\mathrm{Tr}(P) = \\mathrm{Tr}(I) - \\mathrm{Tr}(T(T^{\\top}T)^{-1}T^{\\top}) = M - \\mathrm{Tr}((T^{\\top}T)^{-1}T^{\\top}T) = M - \\mathrm{Tr}(I_p) = M-p$.\n\n### 1. Derivation of the Residual Bias $b_{\\ell}$\n\nThe naive estimator is defined as $\\widehat{C}_{\\ell,\\mathrm{naive}}^{\\kappa g} \\equiv \\frac{1}{M}\\left(a_{\\ell}^{\\kappa}\\right)^{\\top} P a_{\\ell}^{g}$. In index notation, this is:\n$$\n\\widehat{C}_{\\ell,\\mathrm{naive}}^{\\kappa g} = \\frac{1}{M} \\sum_{i=1}^{M} \\sum_{j=1}^{M} a_{\\ell i}^{\\kappa} P_{ij} a_{\\ell j}^{g}\n$$\nTo find its expectation value, we apply the expectation operator and use its linearity:\n$$\n\\mathbb{E}\\left[\\widehat{C}_{\\ell,\\mathrm{naive}}^{\\kappa g}\\right] = \\frac{1}{M} \\sum_{i=1}^{M} \\sum_{j=1}^{M} P_{ij} \\mathbb{E}\\left[a_{\\ell i}^{\\kappa} a_{\\ell j}^{g}\\right]\n$$\nUsing the given covariance property $\\mathbb{E}\\left[a_{\\ell i}^{\\kappa} a_{\\ell j}^{g}\\right] = \\delta_{ij} C_{\\ell}^{\\kappa g}$:\n$$\n\\mathbb{E}\\left[\\widehat{C}_{\\ell,\\mathrm{naive}}^{\\kappa g}\\right] = \\frac{1}{M} \\sum_{i=1}^{M} \\sum_{j=1}^{M} P_{ij} \\delta_{ij} C_{\\ell}^{\\kappa g}\n$$\nThe Kronecker delta $\\delta_{ij}$ collapses the sum over $j$, setting $j=i$:\n$$\n\\mathbb{E}\\left[\\widehat{C}_{\\ell,\\mathrm{naive}}^{\\kappa g}\\right] = \\frac{C_{\\ell}^{\\kappa g}}{M} \\sum_{i=1}^{M} P_{ii}\n$$\nThe sum of the diagonal elements of $P$ is its trace, $\\mathrm{Tr}(P)$. As shown earlier, $\\mathrm{Tr}(P) = M-p$.\n$$\n\\mathbb{E}\\left[\\widehat{C}_{\\ell,\\mathrm{naive}}^{\\kappa g}\\right] = \\frac{C_{\\ell}^{\\kappa g}}{M} (M-p) = C_{\\ell}^{\\kappa g} \\left(1 - \\frac{p}{M}\\right)\n$$\nThe residual bias $b_{\\ell}$ is defined as the difference between this expectation and the true value $C_{\\ell}^{\\kappa g}$:\n$$\nb_{\\ell} \\equiv \\mathbb{E}\\left[\\widehat{C}_{\\ell,\\mathrm{naive}}^{\\kappa g}\\right] - C_{\\ell}^{\\kappa g} = C_{\\ell}^{\\kappa g} \\left(1 - \\frac{p}{M}\\right) - C_{\\ell}^{\\kappa g} = -C_{\\ell}^{\\kappa g} \\frac{p}{M}\n$$\nThis bias is a direct consequence of removing $p$ modes from the total of $M$ available modes, reducing the total signal power proportionally, which the naive normalization by $1/M$ does not account for.\n\n### 2. Derivation of the Variance Inflation Factor $F_{\\ell}$\n\nThe variance inflation factor is the ratio of the variances of the corrected and baseline estimators. We must first derive the variance for each.\n\n#### Variance of the Baseline Estimator\nThe baseline estimator is $\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g} = \\frac{1}{M}\\left(a_{\\ell}^{\\kappa}\\right)^{\\top} a_{\\ell}^{g} = \\frac{1}{M} \\sum_{i=1}^{M} a_{\\ell i}^{\\kappa} a_{\\ell i}^{g}$.\nFirst, its expectation value is $\\mathbb{E}[\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g}] = \\frac{1}{M} \\sum_{i=1}^{M} \\mathbb{E}[a_{\\ell i}^{\\kappa} a_{\\ell i}^{g}] = \\frac{1}{M} \\sum_{i=1}^{M} C_{\\ell}^{\\kappa g} = C_{\\ell}^{\\kappa g}$. It is an unbiased estimator.\nThe variance is $\\mathrm{Var}(\\hat{C}) = \\mathbb{E}[\\hat{C}^2] - (\\mathbb{E}[\\hat{C}])^2$. We need to compute the second moment:\n$$\n\\mathbb{E}\\left[\\left(\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g}\\right)^2\\right] = \\frac{1}{M^2} \\mathbb{E}\\left[ \\left(\\sum_{i=1}^{M} a_{\\ell i}^{\\kappa} a_{\\ell i}^{g}\\right) \\left(\\sum_{j=1}^{M} a_{\\ell j}^{\\kappa} a_{\\ell j}^{g}\\right) \\right] = \\frac{1}{M^2} \\sum_{i,j=1}^{M} \\mathbb{E}\\left[a_{\\ell i}^{\\kappa} a_{\\ell i}^{g} a_{\\ell j}^{\\kappa} a_{\\ell j}^{g}\\right]\n$$\nThis is an expectation of a four-point product of Gaussian random variables. We apply Wick's theorem:\n$$\n\\mathbb{E}[X_1 X_2 X_3 X_4] = \\mathbb{E}[X_1 X_2]\\mathbb{E}[X_3 X_4] + \\mathbb{E}[X_1 X_3]\\mathbb{E}[X_2 X_4] + \\mathbb{E}[X_1 X_4]\\mathbb{E}[X_2 X_3]\n$$\nFor $X_1=a_{\\ell i}^{\\kappa}, X_2=a_{\\ell i}^{g}, X_3=a_{\\ell j}^{\\kappa}, X_4=a_{\\ell j}^{g}$, and using $\\mathbb{E}[a_{\\ell i}^{A} a_{\\ell j}^{B}] = \\delta_{ij} C_{\\ell}^{AB}$, we have:\n\\begin{align*}\n\\mathbb{E}\\left[a_{\\ell i}^{\\kappa} a_{\\ell i}^{g} a_{\\ell j}^{\\kappa} a_{\\ell j}^{g}\\right] = \\mathbb{E}[a_{\\ell i}^{\\kappa} a_{\\ell i}^{g}] \\mathbb{E}[a_{\\ell j}^{\\kappa} a_{\\ell j}^{g}] + \\mathbb{E}[a_{\\ell i}^{\\kappa} a_{\\ell j}^{\\kappa}] \\mathbb{E}[a_{\\ell i}^{g} a_{\\ell j}^{g}] + \\mathbb{E}[a_{\\ell i}^{\\kappa} a_{\\ell j}^{g}] \\mathbb{E}[a_{\\ell i}^{g} a_{\\ell j}^{\\kappa}] \\\\\n= \\left(C_{\\ell}^{\\kappa g}\\right)^2 + \\left(\\delta_{ij} C_{\\ell}^{\\kappa\\kappa}\\right) \\left(\\delta_{ij} C_{\\ell}^{gg}\\right) + \\left(\\delta_{ij} C_{\\ell}^{\\kappa g}\\right) \\left(\\delta_{ij} C_{\\ell}^{\\kappa g}\\right) \\\\\n= \\left(C_{\\ell}^{\\kappa g}\\right)^2 + \\delta_{ij} \\left( C_{\\ell}^{\\kappa\\kappa} C_{\\ell}^{gg} + \\left(C_{\\ell}^{\\kappa g}\\right)^2 \\right)\n\\end{align*}\nNote that $\\delta_{ij}^2 = \\delta_{ij}$. Now we substitute this back into the sum:\n$$\n\\mathbb{E}\\left[\\left(\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g}\\right)^2\\right] = \\frac{1}{M^2} \\sum_{i,j=1}^{M} \\left[ \\left(C_{\\ell}^{\\kappa g}\\right)^2 + \\delta_{ij} \\left( C_{\\ell}^{\\kappa\\kappa} C_{\\ell}^{gg} + \\left(C_{\\ell}^{\\kappa g}\\right)^2 \\right) \\right]\n$$\nThe first term sums to $M^2 (C_{\\ell}^{\\kappa g})^2$. The second term is non-zero only for $i=j$, so the sum over $i,j$ yields $M$ terms.\n$$\n\\mathbb{E}\\left[\\left(\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g}\\right)^2\\right] = \\frac{1}{M^2} \\left[ M^2\\left(C_{\\ell}^{\\kappa g}\\right)^2 + M\\left( C_{\\ell}^{\\kappa\\kappa} C_{\\ell}^{gg} + \\left(C_{\\ell}^{\\kappa g}\\right)^2 \\right) \\right] = \\left(C_{\\ell}^{\\kappa g}\\right)^2 + \\frac{1}{M}\\left( C_{\\ell}^{\\kappa\\kappa} C_{\\ell}^{gg} + \\left(C_{\\ell}^{\\kappa g}\\right)^2 \\right)\n$$\nThe variance is thus:\n$$\n\\mathrm{Var}\\left(\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g}\\right) = \\mathbb{E}\\left[\\left(\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g}\\right)^2\\right] - \\left(\\mathbb{E}\\left[\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g}\\right]\\right)^2 = \\frac{1}{M}\\left( C_{\\ell}^{\\kappa\\kappa} C_{\\ell}^{gg} + \\left(C_{\\ell}^{\\kappa g}\\right)^2 \\right)\n$$\n\n#### Variance of the Corrected Estimator\nThe corrected estimator is $\\widehat{C}_{\\ell,\\mathrm{corr}}^{\\kappa g} = \\frac{1}{M-p}\\left(a_{\\ell}^{\\kappa}\\right)^{\\top} P a_{\\ell}^{g}$. As instructed, we transform to an orthonormal basis where $P$ is diagonal. Since $P$ is a real, symmetric projection matrix, it is diagonalizable by an orthogonal matrix $U$, such that $P = U D U^{\\top}$. The diagonal matrix $D$ contains the eigenvalues of $P$, which are $1$ (with multiplicity $M-p$) and $0$ (with multiplicity $p$). Let's order the basis such that $D = \\mathrm{diag}(\\underbrace{1,\\dots,1}_{M-p}, \\underbrace{0,\\dots,0}_{p})$.\n\nDefine the rotated harmonic coefficient vectors $b_{\\ell}^{\\kappa} \\equiv U^{\\top}a_{\\ell}^{\\kappa}$ and $b_{\\ell}^{g} \\equiv U^{\\top}a_{\\ell}^{g}$. These are still zero-mean Gaussian variables. Their covariance is:\n$$\n\\mathbb{E}\\left[b_{\\ell i}^{X} b_{\\ell j}^{Y}\\right] = \\mathbb{E}\\left[ (U^{\\top}a_{\\ell}^{X})_i (U^{\\top}a_{\\ell}^{Y})_j \\right] = \\sum_{k,m} U_{ki} U_{mj} \\mathbb{E}\\left[a_{\\ell k}^{X} a_{\\ell m}^{Y}\\right] = \\sum_{k,m} U_{ki} U_{mj} \\delta_{km}C_{\\ell}^{XY} = C_{\\ell}^{XY} \\sum_k U_{ki} U_{kj}\n$$\nSince $U$ is orthogonal, $U^{\\top}U=I$, which means $\\sum_k U_{ki} U_{kj} = (U^{\\top}U)_{ij} = \\delta_{ij}$. Thus:\n$$\n\\mathbb{E}\\left[b_{\\ell i}^{X} b_{\\ell j}^{Y}\\right] = \\delta_{ij} C_{\\ell}^{XY}\n$$\nThe statistical properties of the modes are invariant under this rotation. The modes $b_{\\ell i}$ are independent with the same variances as the original modes $a_{\\ell i}$.\n\nNow, rewrite the quadratic form in the estimator:\n$$\n\\left(a_{\\ell}^{\\kappa}\\right)^{\\top} P a_{\\ell}^{g} = \\left(a_{\\ell}^{\\kappa}\\right)^{\\top} U D U^{\\top} a_{\\ell}^{g} = \\left(U^{\\top} a_{\\ell}^{\\kappa}\\right)^{\\top} D \\left(U^{\\top} a_{\\ell}^{g}\\right) = \\left(b_{\\ell}^{\\kappa}\\right)^{\\top} D b_{\\ell}^{g}\n$$\nIn index notation, this becomes:\n$$\n\\sum_{i=1}^{M} b_{\\ell i}^{\\kappa} D_{ii} b_{\\ell i}^{g} = \\sum_{i=1}^{M-p} b_{\\ell i}^{\\kappa} b_{\\ell i}^{g}\n$$\nThe estimator is transformed into:\n$$\n\\widehat{C}_{\\ell,\\mathrm{corr}}^{\\kappa g} = \\frac{1}{M-p} \\sum_{i=1}^{M-p} b_{\\ell i}^{\\kappa} b_{\\ell i}^{g}\n$$\nThis expression is identical in form to the baseline estimator $\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g}$, but with the number of modes being $M-p$ instead of $M$. By direct analogy with the baseline variance derivation, we can replace $M$ with $M-p$ to find the variance of the corrected estimator:\n$$\n\\mathrm{Var}\\left(\\widehat{C}_{\\ell,\\mathrm{corr}}^{\\kappa g}\\right) = \\frac{1}{M-p}\\left( C_{\\ell}^{\\kappa\\kappa} C_{\\ell}^{gg} + \\left(C_{\\ell}^{\\kappa g}\\right)^2 \\right)\n$$\nThe prefactor $1/(M-p)$ makes this estimator unbiased, as $\\mathbb{E}[\\widehat{C}_{\\ell,\\mathrm{corr}}^{\\kappa g}] = \\frac{1}{M-p} \\sum_{i=1}^{M-p} C_{\\ell}^{\\kappa g} = C_{\\ell}^{\\kappa g}$.\n\n#### Variance Inflation Factor\nFinally, the inflation factor $F_{\\ell}$ is the ratio of these two variances:\n$$\nF_{\\ell} \\equiv \\frac{\\mathrm{Var}\\left(\\widehat{C}_{\\ell,\\mathrm{corr}}^{\\kappa g}\\right)}{\\mathrm{Var}\\left(\\widehat{C}_{\\ell,\\mathrm{base}}^{\\kappa g}\\right)} = \\frac{\\frac{1}{M-p}\\left( C_{\\ell}^{\\kappa\\kappa} C_{\\ell}^{gg} + \\left(C_{\\ell}^{\\kappa g}\\right)^2 \\right)}{\\frac{1}{M}\\left( C_{\\ell}^{\\kappa\\kappa} C_{\\ell}^{gg} + \\left(C_{\\ell}^{\\kappa g}\\right)^2 \\right)}\n$$\nThe spectral term $(C_{\\ell}^{\\kappa\\kappa} C_{\\ell}^{gg} + (C_{\\ell}^{\\kappa g})^2)$ cancels, yielding:\n$$\nF_{\\ell} = \\frac{M}{M-p}\n$$\nThis factor quantifies the increase in statistical uncertainty (variance) incurred by projecting out $p$ templates, effectively reducing the number of modes available for the estimation from $M$ to $M-p$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the residual bias and variance inflation factor for a cosmological\n    cross-correlation analysis with template marginalization, based on derived\n    closed-form expressions.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each tuple contains (M, p, C_lgk, C_lkk, C_lgg).\n    # M: number of modes\n    # p: number of templates\n    # C_lgk: cross-power spectrum C_l^{kappa g}\n    # C_lkk: auto-power spectrum C_l^{kappa kappa}\n    # C_lgg: auto-power spectrum C_l^{gg}\n    test_cases = [\n        (1024, 1, 2.0, 10.0, 8.0),\n        (64, 8, 2.0, 10.0, 8.0),\n        (200, 100, 1.2, 5.0, 4.0),\n        (20, 19, 0.5, 3.0, 2.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        M, p, C_lgk, C_lkk, C_lgg = case\n\n        # 1. Calculate the residual bias for the naive estimator.\n        # The derived formula is b_l = -C_l^{kg} * (p / M).\n        # This represents the systematic underestimation of the cross-spectrum\n        # when using a naive 1/M normalization after projecting out p modes.\n        b_l = -C_lgk * p / M\n\n        # 2. Calculate the variance inflation factor for the corrected estimator.\n        # The corrected estimator's variance is higher than the baseline\n        # estimator's variance because fewer modes are used.\n        # The derived formula is F_l = M / (M - p).\n        # This factor is always  1 for p  0.\n        # The problem statement ensures M  p, so M - p != 0.\n        F_l = M / (M - p)\n\n        results.append(b_l)\n        results.append(F_l)\n\n    # Final print statement must produce a single line containing a\n    # comma-separated list of 8 floats (b_l, F_l for each of the 4 cases),\n    # enclosed in square brackets. Each float must be rounded to six decimal places.\n    formatted_results = [f\"{x:.6f}\" for x in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "After applying all corrections, how can we be sure that no residual systematic errors are masquerading as a cosmological signal? Null tests provide a powerful answer. This exercise challenges you to forecast the expected statistical noise level for a specific null test—the cross-correlation between CMB lensing curl-modes and galaxy density . This calculation is crucial as it defines the threshold for detection, allowing us to distinguish a true systematic contaminant from expected statistical fluctuations.",
            "id": "3469900",
            "problem": "A central challenge in cross-correlation studies between cosmological probes is distinguishing true cosmological signal from spurious correlations induced by systematics. Consider a null test constructed from the Cosmic Microwave Background (CMB) lensing reconstruction, where the deflection field is decomposed into a gradient (convergence) and a curl component. In the standard cosmological model with scalar perturbations, the curl component vanishes, so its cross-correlation with a large-scale structure tracer should be null. This test can be implemented by cross-correlating the reconstructed CMB lensing curl-mode field, denoted by $\\omega$, with a galaxy overdensity map, denoted by $g$. Under the null hypothesis, the true cross-power spectrum $C_{L}^{\\omega g}$ is zero, and any measured residual arises from noise and finite sampling on a partial sky.\n\nStarting from the assumptions of Gaussian random fields and statistical isotropy on the sphere, and adopting the standard full-sky spherical harmonic formalism, the covariance of the cross-power spectrum estimator between two isotropic fields $X$ and $Y$ at multipole $L$ is given by\n$$\n\\mathrm{Var}\\!\\left(\\hat{C}_{L}^{XY}\\right)=\\frac{\\left(C_{L}^{XX}+N_{L}^{X}\\right)\\left(C_{L}^{YY}+N_{L}^{Y}\\right)}{f_{\\mathrm{sky}}\\left(2L+1\\right)},\n$$\nwhere $f_{\\mathrm{sky}}$ is the observed sky fraction, $C_{L}^{XX}$ and $C_{L}^{YY}$ are the true auto-power spectra, and $N_{L}^{X}$ and $N_{L}^{Y}$ are the corresponding noise power spectra. Construct a single bandpower amplitude estimator by inverse-variance weighting the cross-spectrum across a multipole band $L\\in[L_{\\min},L_{\\max}]$:\n$$\n\\hat{A}=\\frac{\\sum_{L=L_{\\min}}^{L_{\\max}}w_{L}\\,\\hat{C}_{L}^{\\omega g}}{\\sum_{L=L_{\\min}}^{L_{\\max}}w_{L}},\n\\quad\\text{with}\\quad\nw_{L}=\\frac{f_{\\mathrm{sky}}\\left(2L+1\\right)}{\\left(C_{L}^{\\omega\\omega}+N_{L}^{\\omega}\\right)\\left(C_{L}^{gg}+N_{L}^{g}\\right)}.\n$$\nUnder the null hypothesis, the expectation $\\mathbb{E}\\!\\left[\\hat{A}\\right]=0$, and the residual level is quantified by the root-mean-square (RMS) $\\sqrt{\\mathrm{Var}\\!\\left(\\hat{A}\\right)}$, where for independent multipoles and optimal inverse-variance weights,\n$$\n\\mathrm{Var}\\!\\left(\\hat{A}\\right)=\\left[\\sum_{L=L_{\\min}}^{L_{\\max}}w_{L}\\right]^{-1}.\n$$\n\nAssume the following scientifically plausible auto-power spectra and instrument/noise characteristics over the multipole range $L\\in[100,1000]$ and sky fraction $f_{\\mathrm{sky}}=0.25$:\n- CMB lensing curl-mode auto-power is negligible: $C_{L}^{\\omega\\omega}=0$.\n- CMB lensing curl-mode reconstruction noise is approximately white over the band: $N_{L}^{\\omega}=N_{0}$ with $N_{0}=2.0\\times 10^{-8}$.\n- Galaxy overdensity auto-power follows a weak power-law: $C_{L}^{gg}=A_{g}L^{-1}$ with $A_{g}=5.0\\times 10^{-7}$.\n- Galaxy shot noise is flat: $N_{L}^{g}=n^{-1}$ with $n^{-1}=2.0\\times 10^{-6}$.\n\nTreat multipoles as independent and neglect any residual mode coupling beyond the $f_{\\mathrm{sky}}$ factor. Under these assumptions, derive the closed-form expression for $\\sqrt{\\mathrm{Var}\\!\\left(\\hat{A}\\right)}$ and evaluate its numerical value for the specified parameters. Round your final numerical answer to three significant figures. Express the final amplitude in dimensionless units.",
            "solution": "The objective is to calculate the root-mean-square (RMS) of the bandpower amplitude estimator, $\\sqrt{\\mathrm{Var}\\!\\left(\\hat{A}\\right)}$. According to the problem statement, the variance of the estimator $\\hat{A}$ is given by the inverse of the sum of the optimal weights $w_L$ over the specified multipole band.\n$$\n\\mathrm{Var}\\!\\left(\\hat{A}\\right) = \\left[\\sum_{L=L_{\\min}}^{L_{\\max}} w_{L}\\right]^{-1}\n$$\nThe weights $w_L$ are defined as the inverse of the variance of the cross-power spectrum estimator $\\hat{C}_{L}^{\\omega g}$ at each multipole $L$. The expression for the weights is given as:\n$$\nw_{L} = \\frac{f_{\\mathrm{sky}}\\left(2L+1\\right)}{\\left(C_{L}^{\\omega\\omega}+N_{L}^{\\omega}\\right)\\left(C_{L}^{gg}+N_{L}^{g}\\right)}\n$$\nWe are given the following models for the auto-power spectra and noise power spectra:\n- CMB lensing curl-mode signal: $C_{L}^{\\omega\\omega}=0$.\n- CMB lensing curl-mode noise: $N_{L}^{\\omega}=N_{0}$.\n- Galaxy overdensity signal: $C_{L}^{gg}=A_{g}L^{-1}$.\n- Galaxy shot noise: $N_{L}^{g}=n^{-1}$.\n\nSubstituting these expressions into the formula for the weights $w_L$, we obtain:\n$$\nw_{L} = \\frac{f_{\\mathrm{sky}}\\left(2L+1\\right)}{\\left(0+N_{0}\\right)\\left(A_{g}L^{-1}+n^{-1}\\right)} = \\frac{f_{\\mathrm{sky}}\\left(2L+1\\right)}{N_{0}\\left(\\frac{A_{g}}{L}+n^{-1}\\right)}\n$$\nTo simplify the denominator, we find a common denominator for the term in the parenthesis:\n$$\nw_{L} = \\frac{f_{\\mathrm{sky}}\\left(2L+1\\right)}{N_{0}\\left(\\frac{A_{g}+n^{-1}L}{L}\\right)} = \\frac{f_{\\mathrm{sky}}L\\left(2L+1\\right)}{N_{0}\\left(A_{g}+n^{-1}L\\right)}\n$$\nNow, we must compute the sum of these weights over the multipole range $L\\in[L_{\\min}, L_{\\max}]$.\n$$\n\\sum_{L=L_{\\min}}^{L_{\\max}} w_{L} = \\sum_{L=L_{\\min}}^{L_{\\max}} \\frac{f_{\\mathrm{sky}}L\\left(2L+1\\right)}{N_{0}\\left(A_{g}+n^{-1}L\\right)} = \\frac{f_{\\mathrm{sky}}}{N_{0}} \\sum_{L=L_{\\min}}^{L_{\\max}} \\frac{2L^2+L}{A_{g}+n^{-1}L}\n$$\nSince the multipole range is large ($L_{\\min}=100$ to $L_{\\max}=1000$), the summation can be accurately approximated by an integral. We treat $L$ as a continuous variable:\n$$\n\\sum_{L=L_{\\min}}^{L_{\\max}} w_{L} \\approx \\int_{L_{\\min}}^{L_{\\max}} \\frac{f_{\\mathrm{sky}}L\\left(2L+1\\right)}{N_{0}\\left(A_{g}+n^{-1}L\\right)} dL = \\frac{f_{\\mathrm{sky}}}{N_{0}} \\int_{L_{\\min}}^{L_{\\max}} \\frac{2L^2+L}{A_{g}+n^{-1}L} dL\n$$\nTo evaluate the integral, we perform polynomial long division on the integrand, $\\frac{2L^2+L}{n^{-1}L+A_{g}}$. Let's rewrite the integrand by factoring $n^{-1}$ from the denominator: $\\frac{2L^2+L}{n^{-1}(L+A_g n)}$. The integral becomes:\n$$\n\\int \\frac{2L^2+L}{A_{g}+n^{-1}L} dL = n \\int \\frac{2L^2+L}{L+A_{g}n} dL\n$$\nThe polynomial division of $\\frac{2L^2+L}{L+A_{g}n}$ yields:\n$$\n\\frac{2L^2+L}{L+A_{g}n} = 2L + (1-2A_{g}n) - \\frac{A_{g}n(1-2A_{g}n)}{L+A_{g}n}\n$$\nIntegrating this expression with respect to $L$ gives:\n$$\n\\int \\left( 2L + (1-2A_{g}n) - \\frac{A_{g}n(1-2A_{g}n)}{L+A_{g}n} \\right) dL = L^2 + (1-2A_{g}n)L - A_{g}n(1-2A_{g}n)\\ln\\left|L+A_{g}n\\right|\n$$\nLet's define $F(L) = L^2 + (1-2A_{g}n)L - A_{g}n(1-2A_{g}n)\\ln\\left(L+A_{g}n\\right)$. The term $L+A_{g}n$ is positive over the integration range, so absolute value is not needed.\nThe sum of the weights is then:\n$$\n\\sum_{L=L_{\\min}}^{L_{\\max}} w_{L} \\approx \\frac{n f_{\\mathrm{sky}}}{N_{0}} \\left[ F(L) \\right]_{L_{\\min}}^{L_{\\max}} = \\frac{n f_{\\mathrm{sky}}}{N_{0}} \\left( F(L_{\\max}) - F(L_{\\min}) \\right)\n$$\nThis provides the closed-form expression for the sum of weights. The desired quantity is $\\sqrt{\\mathrm{Var}\\!\\left(\\hat{A}\\right)} = \\left(\\sum w_{L}\\right)^{-1/2}$.\n\nNow we substitute the given numerical values:\n- $f_{\\mathrm{sky}} = 0.25$\n- $L_{\\min} = 100$, $L_{\\max} = 1000$\n- $N_{0} = 2.0 \\times 10^{-8}$\n- $A_{g} = 5.0 \\times 10^{-7}$\n- $n^{-1} = 2.0 \\times 10^{-6}$, which implies $n = \\frac{1}{2.0 \\times 10^{-6}} = 5.0 \\times 10^{5}$\n\nFirst, we calculate the dimensionless constant terms:\n$$\nA_g n = (5.0 \\times 10^{-7}) (5.0 \\times 10^{5}) = 0.25\n$$\n$$\n1-2A_{g}n = 1 - 2(0.25) = 0.5\n$$\n$$\nA_{g}n(1-2A_{g}n) = 0.25 \\times 0.5 = 0.125\n$$\nSo the function $F(L)$ simplifies to:\n$$\nF(L) = L^2 + 0.5L - 0.125\\ln(L+0.25)\n$$\nNext, we evaluate the prefactor of the integral:\n$$\n\\frac{n f_{\\mathrm{sky}}}{N_{0}} = \\frac{(5.0 \\times 10^{5})(0.25)}{2.0 \\times 10^{-8}} = \\frac{1.25 \\times 10^{5}}{2.0 \\times 10^{-8}} = 0.625 \\times 10^{13} = 6.25 \\times 10^{12}\n$$\nNow we compute $F(L_{\\max}) - F(L_{\\min})$:\n$$\nF(1000) = (1000)^2 + 0.5(1000) - 0.125\\ln(1000+0.25) = 1000500 - 0.125\\ln(1000.25)\n$$\n$$\nF(100) = (100)^2 + 0.5(100) - 0.125\\ln(100+0.25) = 10050 - 0.125\\ln(100.25)\n$$\nThe difference is:\n$$\nF(1000) - F(100) = (1000500 - 10050) - 0.125\\left(\\ln(1000.25) - \\ln(100.25)\\right)\n$$\n$$\nF(1000) - F(100) = 990450 - 0.125\\ln\\left(\\frac{1000.25}{100.25}\\right)\n$$\nUsing natural logarithms: $\\ln(1000.25) \\approx 6.907995$ and $\\ln(100.25) \\approx 4.607650$.\n$$\nF(1000) - F(100) = 990450 - 0.125(6.907995 - 4.607650) = 990450 - 0.125(2.300345) \\approx 990450 - 0.287543 \\approx 990449.712\n$$\nThe sum of weights is:\n$$\n\\sum w_L \\approx (6.25 \\times 10^{12}) \\times 990449.712 \\approx 6.19031 \\times 10^{18}\n$$\nThe variance is the inverse of this sum:\n$$\n\\mathrm{Var}\\!\\left(\\hat{A}\\right) = \\left(\\sum w_L\\right)^{-1} \\approx \\frac{1}{6.19031 \\times 10^{18}} \\approx 1.61542 \\times 10^{-19}\n$$\nFinally, the RMS value is the square root of the variance:\n$$\n\\sqrt{\\mathrm{Var}\\!\\left(\\hat{A}\\right)} \\approx \\sqrt{1.61542 \\times 10^{-19}} = \\sqrt{16.1542 \\times 10^{-20}} = \\sqrt{16.1542} \\times 10^{-10}\n$$\n$$\n\\sqrt{\\mathrm{Var}\\!\\left(\\hat{A}\\right)} \\approx 4.01923 \\times 10^{-10}\n$$\nRounding to three significant figures, we get the final result.\n$$\n\\sqrt{\\mathrm{Var}\\!\\left(\\hat{A}\\right)} \\approx 4.02 \\times 10^{-10}\n$$\nThis value represents the expected $1\\sigma$ statistical uncertainty on the null-test amplitude $\\hat{A}$ due to instrumental noise and cosmic variance on a finite sky patch.",
            "answer": "$$\\boxed{4.02 \\times 10^{-10}}$$"
        }
    ]
}