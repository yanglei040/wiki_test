{
    "hands_on_practices": [
        {
            "introduction": "Before running any $N$-body simulation, a crucial first step is choosing the initial redshift $z_i$. Starting too late can invalidate the perturbation theory used to set up initial particle positions and velocities. This exercise () guides you through translating physical requirements—ensuring particle displacements are small and second-order effects are subdominant—into a concrete criterion for selecting a safe starting redshift, ensuring your simulation begins from a physically valid state.",
            "id": "3468236",
            "problem": "You are preparing constrained initial conditions for a cosmological $N$-body simulation of the local universe, where the displacement field is reconstructed from observed peculiar velocities via a Wiener filter and augmented with small-scale modes. To ensure reliable initialization, the starting redshift $z_i$ must be chosen so that two requirements are simultaneously satisfied at the beginning of the simulation.\n\nBase the analysis on Lagrangian Perturbation Theory (LPT), which models the comoving mapping from Lagrangian coordinates $\\boldsymbol{q}$ to Eulerian coordinates $\\boldsymbol{x}$ at scale factor $a$ as a perturbative series in the displacement field, with first-order (Zel’dovich) and second-order corrections characterized by growth factors. Assume the early-time expansion is well described by an Einstein–de Sitter (EdS) universe, normalized such that the first-order growth factor is $D_1(1)=1$, and the second-order growth factor is $D_2(1)=-\\frac{3}{7}$ (standard EdS normalization). Define the Root Mean Square (RMS) as the Root Mean Square (RMS) norm over the simulation volume.\n\nImpose the following two criteria at $a_i$, the scale factor corresponding to the starting redshift $z_i$:\n\n1. The maximum first-order (1LPT) particle displacement at $a_i$ is a small fraction of the grid spacing, i.e.,\n$$\n|D_1(a_i)|\\, s_{\\max} \\le \\epsilon\\, \\Delta,\n$$\nwhere $s_{\\max}$ is the maximum magnitude of the reconstructed 1LPT displacement field at $z=0$, $\\Delta$ is the comoving grid spacing, and $\\epsilon$ is a chosen fraction.\n\n2. The RMS amplitude of the second-order (2LPT) correction at $a_i$ is subdominant to the RMS amplitude of the 1LPT term,\n$$\n|D_2(a_i)|\\, \\sigma_t \\le \\eta\\, |D_1(a_i)|\\, \\sigma_s,\n$$\nwhere $\\sigma_s$ and $\\sigma_t$ are the RMS magnitudes of the 1LPT and 2LPT displacement fields at $z=0$, respectively, and $\\eta$ is a chosen small number quantifying the desired subdominance at start.\n\nAssume EdS growth at early times and adopt the standard EdS scalings for $D_1(a)$ and $D_2(a)$ with the above normalization. Derive, from first principles, a closed-form expression for the minimal $z_i$ that simultaneously satisfies both criteria. Then evaluate the expression using the following scientifically plausible parameters for a local-universe constrained setup:\n- Grid spacing $\\Delta = 0.5 \\, h^{-1}\\,\\mathrm{Mpc}$,\n- Fraction $\\epsilon = 0.2$,\n- Maximum 1LPT displacement at $z=0$, $s_{\\max} = 5.0 \\, h^{-1}\\,\\mathrm{Mpc}$,\n- RMS 1LPT displacement at $z=0$, $\\sigma_s = 1.5 \\, h^{-1}\\,\\mathrm{Mpc}$,\n- RMS 2LPT displacement at $z=0$, $\\sigma_t = 3.0 \\, h^{-1}\\,\\mathrm{Mpc}$,\n- Subdominance parameter $\\eta = 0.1$.\n\nExpress the final answer as the dimensionless number $z_i$ rounded to three significant figures. No units should be included in the final answer.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in standard cosmological perturbation theory, well-posed with a clear objective and sufficient data, and free from internal contradictions or ambiguities. The parameters provided are physically plausible for simulations of the local universe.\n\nThe goal is to determine the minimal starting redshift $z_i$ for an $N$-body simulation, which corresponds to the maximal starting scale factor $a_i = (1+z_i)^{-1}$, such that two criteria are simultaneously met. The analysis is based on an Einstein–de Sitter (EdS) model for the early universe.\n\nIn an EdS universe, the first-order (1LPT) and second-order (2LPT) growth factors scale with the scale factor $a$ as $D_1(a) \\propto a$ and $D_2(a) \\propto a^2$. The problem provides the normalization at the present day ($z=0$, corresponding to $a=1$): $D_1(1)=1$ and $D_2(1)=-3/7$. Using this normalization, we can write the explicit expressions for the growth factors at any scale factor $a$:\n$$\nD_1(a) = D_1(1) \\left(\\frac{a}{1}\\right) = a\n$$\n$$\nD_2(a) = D_2(1) \\left(\\frac{a}{1}\\right)^2 = -\\frac{3}{7}a^2\n$$\nThe absolute values of these growth factors at the initial scale factor $a_i$ are therefore:\n$$\n|D_1(a_i)| = a_i\n$$\n$$\n|D_2(a_i)| = \\left|-\\frac{3}{7}a_i^2\\right| = \\frac{3}{7}a_i^2\n$$\nsince $a_i$ is positive.\n\nWe now apply the two criteria at the initial scale factor $a_i$.\n\n**Criterion 1: Maximum 1LPT displacement**\nThe first criterion limits the maximum particle displacement at the start of the simulation:\n$$\n|D_1(a_i)|\\, s_{\\max} \\le \\epsilon\\, \\Delta\n$$\nSubstituting $|D_1(a_i)| = a_i$, we get:\n$$\na_i\\, s_{\\max} \\le \\epsilon\\, \\Delta\n$$\nThis imposes an upper bound on the initial scale factor $a_i$:\n$$\na_i \\le \\frac{\\epsilon \\Delta}{s_{\\max}}\n$$\n\n**Criterion 2: Subdominance of 2LPT correction**\nThe second criterion ensures that the second-order correction to the displacement field is subdominant to the first-order term in an RMS sense:\n$$\n|D_2(a_i)|\\, \\sigma_t \\le \\eta\\, |D_1(a_i)|\\, \\sigma_s\n$$\nSubstituting the expressions for $|D_1(a_i)|$ and $|D_2(a_i)|$:\n$$\n\\left(\\frac{3}{7}a_i^2\\right) \\sigma_t \\le \\eta\\, a_i\\, \\sigma_s\n$$\nSince $a_i > 0$, we can divide both sides by $a_i$ without changing the inequality direction:\n$$\n\\frac{3}{7}a_i\\, \\sigma_t \\le \\eta\\, \\sigma_s\n$$\nThis yields a second upper bound on $a_i$:\n$$\na_i \\le \\frac{7 \\eta \\sigma_s}{3 \\sigma_t}\n$$\n\n**Combined Constraint and Minimal Redshift**\nFor the simulation to be validly initialized, both criteria must be satisfied simultaneously. This means $a_i$ must be less than or equal to both derived upper bounds. The most restrictive constraint determines the maximum allowable value for $a_i$:\n$$\na_{i, \\text{max}} = \\min\\left(\\frac{\\epsilon \\Delta}{s_{\\max}}, \\frac{7 \\eta \\sigma_s}{3 \\sigma_t}\\right)\n$$\nThe relationship between redshift $z$ and scale factor $a$ is $z = a^{-1} - 1$. This is a monotonically decreasing function. Therefore, the minimal starting redshift $z_i$ corresponds to the maximal starting scale factor $a_{i, \\text{max}}$.\n$$\nz_i = \\frac{1}{a_{i, \\text{max}}} - 1 = \\frac{1}{\\min\\left(\\frac{\\epsilon \\Delta}{s_{\\max}}, \\frac{7 \\eta \\sigma_s}{3 \\sigma_t}\\right)} - 1\n$$\nThis expression can be rewritten using the property that $1/\\min(x,y) = \\max(1/x, 1/y)$:\n$$\nz_i = \\max\\left(\\frac{s_{\\max}}{\\epsilon \\Delta}, \\frac{3 \\sigma_t}{7 \\eta \\sigma_s}\\right) - 1\n$$\nThis is the desired closed-form expression for the minimal starting redshift $z_i$.\n\n**Numerical Evaluation**\nWe now substitute the given parameter values into this expression. The parameters are:\n- $\\Delta = 0.5$ $h^{-1}\\,\\mathrm{Mpc}$\n- $\\epsilon = 0.2$\n- $s_{\\max} = 5.0$ $h^{-1}\\,\\mathrm{Mpc}$\n- $\\sigma_s = 1.5$ $h^{-1}\\,\\mathrm{Mpc}$\n- $\\sigma_t = 3.0$ $h^{-1}\\,\\mathrm{Mpc}$\n- $\\eta = 0.1$\n\nAll length units ($h^{-1}\\,\\mathrm{Mpc}$) cancel out in the ratios, leaving dimensionless quantities as required.\nLet's evaluate the two arguments of the $\\max$ function.\n\nFirst argument (from Criterion 1):\n$$\n\\frac{s_{\\max}}{\\epsilon \\Delta} = \\frac{5.0}{0.2 \\times 0.5} = \\frac{5.0}{0.1} = 50\n$$\n\nSecond argument (from Criterion 2):\n$$\n\\frac{3 \\sigma_t}{7 \\eta \\sigma_s} = \\frac{3 \\times 3.0}{7 \\times 0.1 \\times 1.5} = \\frac{9.0}{1.05} = \\frac{900}{105} = \\frac{180}{21} = \\frac{60}{7} \\approx 8.5714\n$$\n\nWe now take the maximum of these two values:\n$$\n\\max\\left(50, \\frac{60}{7}\\right) = 50\n$$\nThe first criterion is the more restrictive one. Therefore, the minimum value for $1+z_i$ is $50$.\nThe minimal starting redshift is:\n$$\nz_i = 50 - 1 = 49\n$$\nThe problem requires the answer to be rounded to three significant figures. The exact value is $49$. Expressed with three significant figures, this is $49.0$.",
            "answer": "$$\n\\boxed{49.0}\n$$"
        },
        {
            "introduction": "A central task in simulating the local universe is working backward from observed galaxy positions to their initial locations in the early universe. This practice () immerses you in this process by implementing the reverse Zeldovich approximation, a cornerstone of Lagrangian perturbation theory. You will not only apply the method but also critically evaluate its performance by testing its sensitivity to assumptions about cosmic growth and higher-order corrections, a vital skill for assessing the robustness of any reconstruction.",
            "id": "3468288",
            "problem": "You are tasked with implementing the reverse Zeldovich approximation in a periodic cubic domain to infer the initial Lagrangian displacements from observed Eulerian galaxy positions, and to test the sensitivity of the inference to the assumed linear growth factor and to the inclusion of second-order corrections. Work entirely within the framework of Newtonian gravity in an expanding universe with comoving coordinates and periodic boundary conditions. All quantities must be treated in three spatial dimensions, and all spatial coordinates must be expressed in units of megaparsecs divided by the Hubble parameter, specifically in $\\mathrm{Mpc}/h$. The angle unit does not apply here.\n\nStart from the following foundational base:\n\n- The Zeldovich approximation (ZA) is the first-order solution of Lagrangian perturbation theory (LPT). The Eulerian position $\\mathbf{x}$ of a mass element labeled by its Lagrangian coordinate $\\mathbf{q}$ at scale factor $a$ is written as\n$$\n\\mathbf{x}(\\mathbf{q}, a) = \\mathbf{q} + \\mathbf{\\Psi}(\\mathbf{q}, a),\n$$\nwhere the displacement field admits a perturbative expansion\n$$\n\\mathbf{\\Psi}(\\mathbf{q}, a) = D(a)\\,\\mathbf{\\Psi}^{(1)}(\\mathbf{q}) + D_2(a)\\,\\mathbf{\\Psi}^{(2)}(\\mathbf{q}) + \\cdots,\n$$\nwith $D(a)$ the linear growth factor and $D_2(a)$ the second-order growth factor. In an Einstein–de Sitter background, one has $D_2(a) = -\\frac{3}{7}D(a)^2$.\n\n- The first-order displacement is curl-free and related to the linear density contrast via a scalar potential $\\phi^{(1)}(\\mathbf{q})$ satisfying\n$$\n\\nabla^2 \\phi^{(1)}(\\mathbf{q}) = \\delta^{(1)}(\\mathbf{q}), \\quad \\mathbf{\\Psi}^{(1)}(\\mathbf{q}) = -\\nabla \\phi^{(1)}(\\mathbf{q}),\n$$\nwhere $\\delta^{(1)}(\\mathbf{q})$ is the linear density contrast. In Fourier space with wavevector $\\mathbf{k}$, this implies\n$$\n\\tilde{\\mathbf{\\Psi}}^{(1)}(\\mathbf{k}) = i\\,\\frac{\\mathbf{k}}{k^2}\\,\\tilde{\\delta}^{(1)}(\\mathbf{k}),\n$$\nfor $k \\equiv \\|\\mathbf{k}\\| \\neq 0$, and $\\tilde{\\cdot}$ denotes the Fourier transform.\n\n- The second-order displacement can be expressed via a second-order potential $\\phi^{(2)}(\\mathbf{q})$ satisfying\n$$\n\\nabla^2 \\phi^{(2)}(\\mathbf{q}) = S_2(\\mathbf{q}),\n$$\nwhere the quadratic source is built from derivatives of $\\phi^{(1)}$ as\n$$\nS_2(\\mathbf{q}) = \\sum_{ij} \\left[ \\phi^{(1)}_{,ii}(\\mathbf{q})\\,\\phi^{(1)}_{,jj}(\\mathbf{q}) - \\left(\\phi^{(1)}_{,ij}(\\mathbf{q})\\right)^2 \\right],\n$$\nand\n$$\n\\mathbf{\\Psi}^{(2)}(\\mathbf{q}) = -\\nabla \\phi^{(2)}(\\mathbf{q}).\n$$\n\nImplement the following computational experiment in a cubic periodic box of side length $L$ with $N^3$ grid points representing equal-mass tracers:\n\n1. Construct a synthetic linear density field $\\delta^{(1)}(\\mathbf{q})$ in the box as a superposition of two orthogonal single-mode cosine waves:\n$$\n\\delta^{(1)}(\\mathbf{q}) = A\\left[\\cos\\left(\\mathbf{k}_1\\cdot \\mathbf{q}\\right) + \\cos\\left(\\mathbf{k}_2\\cdot \\mathbf{q}\\right)\\right],\n$$\nwith $\\mathbf{k}_1 = \\frac{2\\pi}{L}(1,0,0)$, $\\mathbf{k}_2 = \\frac{2\\pi}{L}(0,1,0)$, and amplitude $A$. Using Fourier methods, compute $\\mathbf{\\Psi}^{(1)}(\\mathbf{q})$ and $\\mathbf{\\Psi}^{(2)}(\\mathbf{q})$ under periodic boundary conditions.\n\n2. Perform forward evolution to Eulerian positions at scale factor $a$:\n$$\n\\mathbf{x}(\\mathbf{q}, a) = \\mathbf{q} + D_{\\mathrm{true}}(a)\\,\\mathbf{\\Psi}^{(1)}(\\mathbf{q}) + D_{2,\\mathrm{true}}(a)\\,\\mathbf{\\Psi}^{(2)}(\\mathbf{q}),\n$$\nwith $D_{2,\\mathrm{true}}(a) = -\\frac{3}{7}\\left(D_{\\mathrm{true}}(a)\\right)^2$ if second-order evolution is included, and $D_{2,\\mathrm{true}}(a)=0$ otherwise. Treat the positions $\\mathbf{x}$ as observed.\n\n3. Implement reverse Zeldovich estimation of the initial displacement by assuming values $D_{\\mathrm{assumed}}(a)$ and optionally subtracting a second-order term with $D_{2,\\mathrm{assumed}}(a)$:\n- Naive reverse ZA (ignoring second order):\n$$\n\\hat{\\mathbf{\\Psi}}^{(1)}(\\mathbf{q}) = \\frac{\\mathbf{x}(\\mathbf{q}, a) - \\mathbf{q}}{D_{\\mathrm{assumed}}(a)}.\n$$\n- Second-order corrected reverse ZA:\n$$\n\\hat{\\mathbf{\\Psi}}^{(1)}(\\mathbf{q}) = \\frac{\\mathbf{x}(\\mathbf{q}, a) - \\mathbf{q} - D_{2,\\mathrm{assumed}}(a)\\,\\mathbf{\\Psi}^{(2)}(\\mathbf{q})}{D_{\\mathrm{assumed}}(a)}.\n$$\n\n4. Quantify the inference quality for each test case using the root-mean-square relative error between the inferred $\\hat{\\mathbf{\\Psi}}^{(1)}(\\mathbf{q})$ and the true $\\mathbf{\\Psi}^{(1)}(\\mathbf{q})$ over all $N^3$ tracers:\n$$\n\\varepsilon = \\frac{\\left[\\frac{1}{N^3}\\sum_{\\mathbf{q}}\\left\\|\\hat{\\mathbf{\\Psi}}^{(1)}(\\mathbf{q}) - \\mathbf{\\Psi}^{(1)}(\\mathbf{q})\\right\\|^2\\right]^{1/2}}{\\left[\\frac{1}{N^3}\\sum_{\\mathbf{q}}\\left\\|\\mathbf{\\Psi}^{(1)}(\\mathbf{q})\\right\\|^2\\right]^{1/2}}.\n$$\n\nUse a cubic box of side length $L = 100\\,\\mathrm{Mpc}/h$ with $N = 32$ grid points per dimension. Evaluate the following test suite, each defined by the tuple $(A, D_{\\mathrm{true}}, \\mathrm{include\\_2LPT}, D_{\\mathrm{assumed}}, \\mathrm{subtract\\_2LPT}, D_{2,\\mathrm{assumed}})$:\n\n- Test $1$: $(0.05, 1.0, \\mathrm{True}, 1.0, \\mathrm{False}, -\\frac{3}{7}\\cdot 1.0^2)$.\n- Test $2$: $(0.05, 1.0, \\mathrm{True}, 0.9, \\mathrm{False}, -\\frac{3}{7}\\cdot 0.9^2)$.\n- Test $3$: $(0.05, 1.0, \\mathrm{True}, 1.0, \\mathrm{True}, -\\frac{3}{7}\\cdot 1.0^2)$.\n- Test $4$: $(10^{-4}, 1.0, \\mathrm{True}, 1.0, \\mathrm{False}, -\\frac{3}{7}\\cdot 1.0^2)$.\n- Test $5$: $(0.2, 1.0, \\mathrm{False}, 1.0, \\mathrm{False}, 0.0)$.\n\nFor each test, compute $\\varepsilon$ as defined above. Your program should produce a single line of output containing the five $\\varepsilon$ values as a comma-separated list enclosed in square brackets, for example, $\\left[\\varepsilon_1,\\varepsilon_2,\\varepsilon_3,\\varepsilon_4,\\varepsilon_5\\right]$. All spatial quantities and the box size must be in $\\mathrm{Mpc}/h$, and the errors are dimensionless floats. No additional text should be printed.",
            "solution": "The user-provided problem is a valid, well-posed computational physics problem grounded in standard cosmological perturbation theory. It requires the implementation and testing of the reverse Zeldovich approximation for reconstructing initial cosmic displacement fields. The provided parameters and equations are self-contained, scientifically correct, and sufficient for deriving a unique numerical solution. We now proceed with the step-by-step derivation and implementation plan.\n\nThe core of the problem is to solve a set of Poisson-like equations on a three-dimensional periodic grid using Fourier methods and to evaluate the accuracy of a reconstruction scheme based on this framework.\n\n### 1. Discretization and Fourier Space Representation\nWe operate on a cubic grid of side length $L$ with $N^3$ points. The Lagrangian coordinates $\\mathbf{q}$ occupy the grid nodes. We can represent any scalar or vector field on this grid, for instance, a generic field $f(\\mathbf{q})$. The discrete Fourier transform (DFT) and its inverse are defined as:\n$$\n\\tilde{f}(\\mathbf{k}) = \\sum_{\\mathbf{q}} f(\\mathbf{q}) e^{-i\\mathbf{k}\\cdot\\mathbf{q}}\n$$\n$$\nf(\\mathbf{q}) = \\frac{1}{N^3} \\sum_{\\mathbf{k}} \\tilde{f}(\\mathbf{k}) e^{i\\mathbf{k}\\cdot\\mathbf{q}}\n$$\nThe wavevectors $\\mathbf{k}$ also form a grid in Fourier space. For a grid point indexed by integers $(n_x, n_y, n_z) \\in [0, N-1]^3$, the physical coordinates are $q_i = n_i \\frac{L}{N}$. The corresponding wavevector components are $k_i = m_i \\frac{2\\pi}{L}$, where the integer frequency indices $m_i$ are typically arranged in the order $\\{0, 1, \\dots, N/2-1, -N/2, \\dots, -1\\}$.\n\nCrucially, differential operators become algebraic in Fourier space. The gradient and Laplacian operators transform as:\n$$\n\\widetilde{\\nabla f}(\\mathbf{k}) = i\\mathbf{k} \\tilde{f}(\\mathbf{k}), \\quad \\widetilde{\\nabla^2 f}(\\mathbf{k}) = -k^2 \\tilde{f}(\\mathbf{k})\n$$\nwhere $k^2 = \\|\\mathbf{k}\\|^2 = k_x^2 + k_y^2 + k_z^2$. This allows us to solve Poisson's equation $\\nabla^2 \\phi = \\rho$ by simple division in Fourier space: $\\tilde{\\phi}(\\mathbf{k}) = -\\frac{1}{k^2} \\tilde{\\rho}(\\mathbf{k})$, with special handling for the $k=0$ mode.\n\n### 2. Construction of the True Displacement Fields\n\n#### 2.1. First-Order Field $\\mathbf{\\Psi}^{(1)}$\nThe process begins by defining the linear density contrast $\\delta^{(1)}(\\mathbf{q})$. Instead of constructing it in real space and then transforming, it is more direct to construct its Fourier transform $\\tilde{\\delta}^{(1)}(\\mathbf{k})$. The given density field is:\n$$\n\\delta^{(1)}(\\mathbf{q}) = A\\left[\\cos\\left(\\mathbf{k}_1\\cdot \\mathbf{q}\\right) + \\cos\\left(\\mathbf{k}_2\\cdot \\mathbf{q}\\right)\\right]\n$$\nwith fundamental modes $\\mathbf{k}_1 = \\frac{2\\pi}{L}(1,0,0)$ and $\\mathbf{k}_2 = \\frac{2\\pi}{L}(0,1,0)$. The discrete Fourier transform of a cosine term $\\cos(\\mathbf{k}_j \\cdot \\mathbf{q})$ on an $N^3$ grid has two non-zero components at wavevectors $\\pm\\mathbf{k}_j$. Thus, $\\tilde{\\delta}^{(1)}(\\mathbf{k})$ is non-zero only at four specific wavevectors: $\\pm \\mathbf{k}_1$ and $\\pm \\mathbf{k}_2$. The amplitude of each of these delta functions in Fourier space is $\\frac{A N^3}{2}$.\n\nFrom the relation $\\tilde{\\mathbf{\\Psi}}^{(1)}(\\mathbf{k}) = i\\,\\frac{\\mathbf{k}}{k^2}\\,\\tilde{\\delta}^{(1)}(\\mathbf{k})$, we calculate the three components of the displacement field in Fourier space. For $k=0$, $\\tilde{\\delta}^{(1)}(\\mathbf{0})=0$ as the mean density fluctuation is zero, so we set $\\tilde{\\mathbf{\\Psi}}^{(1)}(\\mathbf{0})=\\mathbf{0}$. Finally, we perform an inverse DFT on each component to obtain the real-space field $\\mathbf{\\Psi}^{(1)}(\\mathbf{q})$.\n\n#### 2.2. Second-Order Field $\\mathbf{\\Psi}^{(2)}$\nThe computation of $\\mathbf{\\Psi}^{(2)}$ is more involved.\n1.  **First-Order Potential $\\phi^{(1)}$**: We first find the potential $\\phi^{(1)}$ from $\\nabla^2 \\phi^{(1)} = \\delta^{(1)}$. In Fourier space, this is $\\tilde{\\phi}^{(1)}(\\mathbf{k}) = -\\frac{1}{k^2} \\tilde{\\delta}^{(1)}(\\mathbf{k})$. The $k=0$ mode $\\tilde{\\phi}^{(1)}(\\mathbf{0})$ is set to zero.\n\n2.  **Derivatives of $\\phi^{(1)}$**: The second-order source term $S_2(\\mathbf{q})$ requires the six unique second derivatives of $\\phi^{(1)}$, i.e., $\\phi^{(1)}_{,ij} \\equiv \\frac{\\partial^2 \\phi^{(1)}}{\\partial q_i \\partial q_j}$. These are computed efficiently using Fourier transforms:\n    $$\n    \\phi^{(1)}_{,ij}(\\mathbf{q}) = \\mathcal{F}^{-1}\\left[ (i k_i)(i k_j) \\tilde{\\phi}^{(1)}(\\mathbf{k}) \\right] = \\mathcal{F}^{-1}\\left[ -k_i k_j \\tilde{\\phi}^{(1)}(\\mathbf{k}) \\right]\n    $$\n    where $\\mathcal{F}^{-1}$ denotes the inverse DFT. We compute each of the six fields ($\\phi^{(1)}_{,xx}, \\phi^{(1)}_{,yy}, \\phi^{(1)}_{,zz}, \\phi^{(1)}_{,xy}, \\phi^{(1)}_{,xz}, \\phi^{(1)}_{,yz}$) this way.\n\n3.  **Source Term $S_2$**: In real space, we construct the source term $S_2(\\mathbf{q})$ from the computed derivatives:\n    $$\n    S_2(\\mathbf{q}) = \\left[\\phi^{(1)}_{,xx}\\phi^{(1)}_{,yy} - (\\phi^{(1)}_{,xy})^2\\right] + \\left[\\phi^{(1)}_{,xx}\\phi^{(1)}_{,zz} - (\\phi^{(1)}_{,xz})^2\\right] + \\left[\\phi^{(1)}_{,yy}\\phi^{(1)}_{,zz} - (\\phi^{(1)}_{,yz})^2\\right]\n    $$\n\n4.  **Solving for $\\mathbf{\\Psi}^{(2)}$**: With $S_2(\\mathbf{q})$ known, we solve for $\\mathbf{\\Psi}^{(2)}(\\mathbf{q})$ in the same manner as for $\\mathbf{\\Psi}^{(1)}$. We have $\\nabla^2 \\phi^{(2)} = S_2$ and $\\mathbf{\\Psi}^{(2)} = -\\nabla \\phi^{(2)}$, which leads to $\\tilde{\\mathbf{\\Psi}}^{(2)}(\\mathbf{k}) = i\\,\\frac{\\mathbf{k}}{k^2}\\,\\tilde{S}_2(\\mathbf{k})$. We compute $\\tilde{S}_2(\\mathbf{k})$ via a forward DFT of $S_2(\\mathbf{q})$, then calculate the components of $\\tilde{\\mathbf{\\Psi}}^{(2)}(\\mathbf{k})$, and finally perform an inverse DFT to obtain $\\mathbf{\\Psi}^{(2)}(\\mathbf{q})$. The $k=0$ mode $\\tilde{\\mathbf{\\Psi}}^{(2)}(\\mathbf{0})$ is set to zero, which is justified as this mode represents a uniform translation of the entire grid, which is physically irrelevant.\n\n### 3. Forward Evolution and Reverse Estimation\n\nFor each test case, we perform the following steps using the pre-computed fields $\\mathbf{\\Psi}^{(1)}$ and $\\mathbf{\\Psi}^{(2)}$ (which depend on the amplitude $A$).\n\n1.  **Forward Evolution**: We compute the \"observed\" Eulerian positions $\\mathbf{x}(\\mathbf{q})$ from the true Lagrangian positions $\\mathbf{q}$ (our grid points) using the parameters $D_{\\mathrm{true}}$ and `include_2LPT`:\n    $$\n    D_{2,\\mathrm{true}} = \\begin{cases} - (3/7) D_{\\mathrm{true}}^2  \\text{if include\\_2LPT is True} \\\\ 0  \\text{if include\\_2LPT is False} \\end{cases}\n    $$\n    $$\n    \\mathbf{x}(\\mathbf{q}) = \\mathbf{q} + D_{\\mathrm{true}}\\,\\mathbf{\\Psi}^{(1)}(\\mathbf{q}) + D_{2,\\mathrm{true}}\\,\\mathbf{\\Psi}^{(2)}(\\mathbf{q})\n    $$\n\n2.  **Reverse Estimation**: We then infer the initial displacement field, $\\hat{\\mathbf{\\Psi}}^{(1)}(\\mathbf{q})$, from the \"data\" ($\\mathbf{x}$ and $\\mathbf{q}$) and the assumed model parameters. The problem is simplified by assuming $\\mathbf{q}$ is known.\n    -   If `subtract_2LPT` is `False`, we use the naive reverse Zeldovich approximation:\n        $$\n        \\hat{\\mathbf{\\Psi}}^{(1)}(\\mathbf{q}) = \\frac{\\mathbf{x}(\\mathbf{q}) - \\mathbf{q}}{D_{\\mathrm{assumed}}}\n        $$\n    -   If `subtract_2LPT` is `True`, we use the second-order corrected formula, which requires the true $\\mathbf{\\Psi}^{(2)}$ field and the assumed second-order growth factor $D_{2,\\mathrm{assumed}}$:\n        $$\n        \\hat{\\mathbf{\\Psi}}^{(1)}(\\mathbf{q}) = \\frac{\\mathbf{x}(\\mathbf{q}) - \\mathbf{q} - D_{2,\\mathrm{assumed}}\\,\\mathbf{\\Psi}^{(2)}(\\mathbf{q})}{D_{\\mathrm{assumed}}}\n        $$\n\n### 4. Error Quantification\nThe quality of the reconstruction is measured by the relative root-mean-square (RMS) error $\\varepsilon$:\n$$\n\\varepsilon = \\frac{\\left[\\frac{1}{N^3}\\sum_{\\mathbf{q}}\\left\\|\\hat{\\mathbf{\\Psi}}^{(1)}(\\mathbf{q}) - \\mathbf{\\Psi}^{(1)}(\\mathbf{q})\\right\\|^2\\right]^{1/2}}{\\left[\\frac{1}{N^3}\\sum_{\\mathbf{q}}\\left\\|\\mathbf{\\Psi}^{(1)}(\\mathbf{q})\\right\\|^2\\right]^{1/2}} = \\sqrt{\\frac{\\sum_{\\mathbf{q}}\\|\\Delta \\mathbf{\\Psi}(\\mathbf{q})\\|^2}{\\sum_{\\mathbf{q}}\\|\\mathbf{\\Psi}^{(1)}(\\mathbf{q})\\|^2}}\n$$\nwhere $\\Delta \\mathbf{\\Psi}(\\mathbf{q}) = \\hat{\\mathbf{\\Psi}}^{(1)}(\\mathbf{q}) - \\mathbf{\\Psi}^{(1)}(\\mathbf{q})$, and the sum is over all $N^3$ grid points. This metric compares the RMS magnitude of the error vector to the RMS magnitude of the true displacement vector.\n\nThe test cases are designed to probe different sources of error: Test 1 demonstrates the error from neglecting the second-order term, Test 2 from an incorrect growth factor, Test 3 is a control case with a perfect model (expecting $\\varepsilon \\approx 0$), Test 4 shows behavior at very low amplitude (linear regime), and Test 5 is a baseline first-order-only scenario.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Implements the reverse Zeldovich approximation experiment as specified.\n    \"\"\"\n    L = 100.0  # Box size in Mpc/h\n    N = 32     # Grid points per dimension\n\n    # Define test cases:\n    # (A, D_true, include_2LPT, D_assumed, subtract_2LPT, D2_assumed)\n    test_cases = [\n        (0.05, 1.0, True, 1.0, False, -3.0/7.0 * 1.0**2),\n        (0.05, 1.0, True, 0.9, False, -3.0/7.0 * 0.9**2),\n        (0.05, 1.0, True, 1.0, True, -3.0/7.0 * 1.0**2),\n        (1e-4, 1.0, True, 1.0, False, -3.0/7.0 * 1.0**2),\n        (0.2, 1.0, False, 1.0, False, 0.0),\n    ]\n\n    # --- Setup Grids ---\n    # Real space grid coordinates (Lagrangian)\n    q_coords_1d = np.arange(N) * (L / N)\n    q_grid = np.array(np.meshgrid(q_coords_1d, q_coords_1d, q_coords_1d, indexing='ij'))\n\n    # Fourier space grid of wavevectors\n    k_vals = 2 * np.pi * np.fft.fftfreq(N, d=L/N)\n    k_grid = np.array(np.meshgrid(k_vals, k_vals, k_vals, indexing='ij'))\n    k_sq = np.sum(k_grid**2, axis=0)\n\n    # For safe division, set k=0 component of k_sq to 1 (it will be zeroed out later)\n    inv_k_sq_safe = np.copy(k_sq)\n    if N % 2 == 0:\n        center = (0, 0, 0)\n    else:\n        center = (N//2, N//2, N//2) # Not strictly needed for even N but good practice\n    \n    if k_sq[center] == 0:\n        inv_k_sq_safe[center] = 1.0\n    inv_k_sq_safe = 1.0 / inv_k_sq_safe\n    if k_sq[center] == 0:\n        inv_k_sq_safe[center] = 0.0\n\n    results = []\n    computed_fields = {} # Cache fields based on amplitude A\n\n    for case in test_cases:\n        A, D_true, include_2LPT, D_assumed, subtract_2LPT, D2_assumed = case\n\n        if A not in computed_fields:\n            # --- 1. Construct True Fields ---\n            \n            # 1a. Linear density field in Fourier space\n            delta_k = np.zeros((N, N, N), dtype=np.complex128)\n            # Factor of N**3 comes from numpy's FFT normalization convention\n            val = A * (N**3) / 2.0\n            delta_k[1, 0, 0] = val\n            delta_k[N-1, 0, 0] = val\n            delta_k[0, 1, 0] = val\n            delta_k[0, N-1, 0] = val\n\n            # 1b. First-order displacement field Psi^(1)\n            psi1_k_x = 1j * k_grid[0] * inv_k_sq_safe * delta_k\n            psi1_k_y = 1j * k_grid[1] * inv_k_sq_safe * delta_k\n            psi1_k_z = 1j * k_grid[2] * inv_k_sq_safe * delta_k\n            \n            psi1_x = np.real(np.fft.ifftn(psi1_k_x))\n            psi1_y = np.real(np.fft.ifftn(psi1_k_y))\n            psi1_z = np.real(np.fft.ifftn(psi1_k_z))\n            psi1 = np.array([psi1_x, psi1_y, psi1_z])\n\n            # 1c. Second-order displacement field Psi^(2)\n            # Find first-order potential phi^(1)\n            phi1_k = -inv_k_sq_safe * delta_k\n            \n            # Find second derivatives of phi^(1)\n            phi1_xx = np.real(np.fft.ifftn(-k_grid[0] * k_grid[0] * phi1_k))\n            phi1_yy = np.real(np.fft.ifftn(-k_grid[1] * k_grid[1] * phi1_k))\n            phi1_zz = np.real(np.fft.ifftn(-k_grid[2] * k_grid[2] * phi1_k))\n            phi1_xy = np.real(np.fft.ifftn(-k_grid[0] * k_grid[1] * phi1_k))\n            phi1_xz = np.real(np.fft.ifftn(-k_grid[0] * k_grid[2] * phi1_k))\n            phi1_yz = np.real(np.fft.ifftn(-k_grid[1] * k_grid[2] * phi1_k))\n\n            # Compute source term S2\n            S2 = ((phi1_xx * phi1_yy) - phi1_xy**2 +\n                  (phi1_xx * phi1_zz) - phi1_xz**2 +\n                  (phi1_yy * phi1_zz) - phi1_yz**2)\n            \n            # Solve for Psi^(2)\n            S2_k = np.fft.fftn(S2)\n            psi2_k_x = 1j * k_grid[0] * inv_k_sq_safe * S2_k\n            psi2_k_y = 1j * k_grid[1] * inv_k_sq_safe * S2_k\n            psi2_k_z = 1j * k_grid[2] * inv_k_sq_safe * S2_k\n            \n            psi2_x = np.real(np.fft.ifftn(psi2_k_x))\n            psi2_y = np.real(np.fft.ifftn(psi2_k_y))\n            psi2_z = np.real(np.fft.ifftn(psi2_k_z))\n            psi2 = np.array([psi2_x, psi2_y, psi2_z])\n\n            computed_fields[A] = (psi1, psi2)\n        \n        psi1, psi2 = computed_fields[A]\n\n        # --- 2. Forward Evolution ---\n        D2_true = -3.0/7.0 * D_true**2 if include_2LPT else 0.0\n        x_pos = q_grid + D_true * psi1 + D2_true * psi2\n\n        # --- 3. Reverse Estimation ---\n        if not subtract_2LPT: # Naive reverse ZA\n            psi1_hat = (x_pos - q_grid) / D_assumed\n        else: # Second-order corrected\n            psi1_hat = (x_pos - q_grid - D2_assumed * psi2) / D_assumed\n\n        # --- 4. Quantify Error ---\n        error_vec = psi1_hat - psi1\n        numerator_sq_sum = np.sum(error_vec**2)\n        denominator_sq_sum = np.sum(psi1**2)\n        \n        if denominator_sq_sum == 0:\n            epsilon = 0.0 if numerator_sq_sum == 0 else np.inf\n        else:\n            epsilon = np.sqrt(numerator_sq_sum / denominator_sq_sum)\n        \n        results.append(epsilon)\n\n    # --- Final Output ---\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The inference of cosmic structures, such as the local bulk flow, depends critically on our assumed cosmological model. This practice () delves into a key source of systematic uncertainty: the value of the Hubble parameter, $H_0$. By building a Bayesian linear model, you will directly quantify how an incorrect assumption about $H_0$ propagates through the analysis and systematically shifts the inferred values of the local bulk flow and large-scale density, illustrating the interplay between cosmological priors and local constraints.",
            "id": "3468244",
            "problem": "You are given a simplified, physically grounded linear model for constrained reconstruction of the near-field peculiar velocity field under variations in the Hubble parameter prior. The model links the assumed Hubble parameter prior $H_0$ to the inference of the bulk flow vector $\\mathbf{v}_{\\mathrm{bulk}}$ and the long-wavelength density mode $\\delta(k \\to 0)$ in a homogeneous and isotropic Universe at late times. The goal is to quantify how changing the prior $H_0$ within $\\pm 5\\%$ shifts the posterior means of $\\mathbf{v}_{\\mathrm{bulk}}$ and $\\delta(k \\to 0)$, starting from fundamental equations.\n\nAssume the following fundamental basis and definitions:\n- The linearized continuity equation at scale factor $a$ is $\\nabla \\cdot \\mathbf{v}(\\mathbf{r}) = -a\\,H\\,f\\,\\delta(\\mathbf{r})$, where $\\mathbf{v}$ is the peculiar velocity field, $H$ is the Hubble parameter, $f$ is the linear growth rate, and $\\delta$ is the matter overdensity.\n- For a spatially uniform overdensity $\\delta(\\mathbf{r}) = \\delta_0$, the divergence is constant, and the irrotational solution implies $\\mathbf{v}(\\mathbf{r}) = -\\dfrac{1}{3} a\\,H\\,f\\,\\delta_0\\,\\mathbf{r}$. At redshift $z \\approx 0$, take $a = 1$.\n- The observed recession velocity at low redshift is $v^{z} \\approx H_{\\mathrm{true}}\\,d + u_{r}$, where $d$ is the comoving distance in $\\mathrm{Mpc}$, $H_{\\mathrm{true}}$ is the true Hubble parameter in $\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$, and $u_{r}$ is the line-of-sight peculiar velocity in $\\mathrm{km\\,s^{-1}}$. For a tracer at position $\\mathbf{r}$ with unit line-of-sight vector $\\hat{\\mathbf{n}}$ and distance $d = \\|\\mathbf{r}\\|$, the radial peculiar velocity is $u_{r} = \\hat{\\mathbf{n}}\\cdot\\mathbf{v}_{\\mathrm{bulk}} - \\dfrac{1}{3} H_{\\mathrm{true}} f \\delta_0\\,d$.\n\nThe data set consists of $N = 8$ tracers with comoving positions in $\\mathrm{Mpc}$:\n- $\\mathbf{r}_1 = (10, 0, 0)$,\n- $\\mathbf{r}_2 = (0, 12, 0)$,\n- $\\mathbf{r}_3 = (0, 0, 8)$,\n- $\\mathbf{r}_4 = (-9, 0, 0)$,\n- $\\mathbf{r}_5 = (0, -11, 0)$,\n- $\\mathbf{r}_6 = (0, 0, -7)$,\n- $\\mathbf{r}_7 = (7, 7, 0)$,\n- $\\mathbf{r}_8 = (0, 5, 5)$.\n\nLet the true parameters be:\n- $H_{\\mathrm{true}} = 70\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$,\n- $f = 0.5$ (dimensionless),\n- $\\mathbf{v}_{\\mathrm{bulk,true}} = (100, -50, 30)\\,\\mathrm{km\\,s^{-1}}$,\n- $\\delta_{0,\\mathrm{true}} = 0.03$ (dimensionless).\n\nAssume Gaussian measurement noise with standard deviation $\\sigma_i = 50\\,\\mathrm{km\\,s^{-1}}$ for all tracers, with zero actual noise realization added in the forward generation of the synthetic observations. For each tracer $i$, let $d_i = \\|\\mathbf{r}_i\\|$ and $\\hat{\\mathbf{n}}_i = \\mathbf{r}_i / d_i$. The noiseless observed redshift-space velocities are constructed as\n$$\nv_i^{z} = H_{\\mathrm{true}}\\,d_i + \\hat{\\mathbf{n}}_i \\cdot \\mathbf{v}_{\\mathrm{bulk,true}} - \\frac{1}{3} H_{\\mathrm{true}} f \\delta_{0,\\mathrm{true}} \\, d_i.\n$$\n\nTo infer parameters under an assumed Hubble parameter prior $H_0$, define the inferred radial peculiar velocity data by subtracting the assumed Hubble flow,\n$$\nu_i^{\\mathrm{obs}}(H_0) = v_i^{z} - H_0\\, d_i.\n$$\nUnder linear theory with the same assumed $H_0$ entering the velocity-density coupling, the forward model for the data is\n$$\nu_i^{\\mathrm{model}} = \\hat{\\mathbf{n}}_i \\cdot \\mathbf{v}_{\\mathrm{bulk}} - \\frac{1}{3} H_0 f \\delta_0 \\, d_i.\n$$\nStack the data into a vector $\\mathbf{y} \\in \\mathbb{R}^N$, and define the design matrix $\\mathbf{A} \\in \\mathbb{R}^{N \\times 4}$, parameter vector $\\boldsymbol{\\theta} \\in \\mathbb{R}^4$, and noise covariance $\\mathbf{N} \\in \\mathbb{R}^{N \\times N}$ by\n- $\\boldsymbol{\\theta} = (v_x, v_y, v_z, \\delta_0)$,\n- the first three columns of $\\mathbf{A}$ are the components of $\\hat{\\mathbf{n}}_i$, and the fourth column has entries $-\\dfrac{1}{3} H_0 f d_i$,\n- $\\mathbf{N} = \\mathrm{diag}(\\sigma_1^2,\\ldots,\\sigma_N^2)$.\n\nAssume independent Gaussian priors for $\\boldsymbol{\\theta}$ with zero mean and diagonal covariance $\\mathbf{\\Sigma}_0 = \\mathrm{diag}(\\sigma_v^2, \\sigma_v^2, \\sigma_v^2, \\sigma_\\delta^2)$, where $\\sigma_v = 300\\,\\mathrm{km\\,s^{-1}}$ and $\\sigma_\\delta = 0.2$. The posterior for $\\boldsymbol{\\theta}$ under Gaussian likelihood and prior is Gaussian with mean\n$$\n\\boldsymbol{\\mu}_{\\mathrm{post}} = \\left(\\mathbf{A}^\\top \\mathbf{N}^{-1} \\mathbf{A} + \\mathbf{\\Sigma}_0^{-1}\\right)^{-1} \\mathbf{A}^\\top \\mathbf{N}^{-1} \\mathbf{y}.\n$$\n\nTask:\n- Using the above definitions, construct $\\{v_i^{z}\\}_{i=1}^N$ once from the true parameters.\n- For each assumed Hubble parameter prior $H_0$ in the test suite, build $\\mathbf{y}(H_0)$ and $\\mathbf{A}(H_0)$, and compute the posterior mean $\\boldsymbol{\\mu}_{\\mathrm{post}}(H_0)$.\n- Define the baseline as $H_0 = 70\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$. For each test case, compute:\n  - The magnitude of the shift in the posterior mean bulk flow vector relative to the baseline, $\\|\\mathbf{v}_{\\mathrm{bulk}}(H_0) - \\mathbf{v}_{\\mathrm{bulk}}(70)\\|$, in $\\mathrm{km\\,s^{-1}}$.\n  - The shift in the posterior mean $\\delta_0$ relative to the baseline, $\\delta_0(H_0) - \\delta_0(70)$, dimensionless.\n- Express the bulk flow shift in $\\mathrm{km\\,s^{-1}}$ and the density shift as a dimensionless number. Do not include unit symbols in the printed output; they must be understood as specified here.\n\nTest suite:\n- Case $1$: $H_0 = 70.0\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$ (baseline, zero shift expected by construction).\n- Case $2$: $H_0 = 73.5\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$ (a $+5\\%$ variation).\n- Case $3$: $H_0 = 66.5\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$ (a $-5\\%$ variation).\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a two-element list with the bulk-flow magnitude shift and the density shift. The required format is\n$[\\,[\\Delta v_1,\\Delta \\delta_1],[\\Delta v_2,\\Delta \\delta_2],[\\Delta v_3,\\Delta \\delta_3]\\,]$,\nwhere $\\Delta v_i$ is in $\\mathrm{km\\,s^{-1}}$ and $\\Delta \\delta_i$ is dimensionless. For example: $[[0.0,0.0],[12.34,-0.0567],[11.11,0.0555]]$.\n\nYour program must be a complete, runnable script with no user input, and it must implement the full calculation as specified above.",
            "solution": "The problem requires an analysis of the systematic shift in inferred cosmological parameters—specifically the local bulk flow velocity $\\mathbf{v}_{\\mathrm{bulk}}$ and the long-wavelength density mode $\\delta_0$—arising from a mismatched prior on the Hubble parameter, $H_0$. The framework provided is a simplified linear model grounded in the principles of physical cosmology, solved within a Bayesian linear regression context. The solution proceeds in four main stages: generation of synthetic observational data, establishment of the Bayesian inference model for varying $H_0$ priors, computation of the posterior parameter estimates, and quantification of the resulting systematic shifts.\n\nFirst, we generate a synthetic, noiseless dataset of observed redshift-space velocities, $\\{v_i^z\\}_{i=1}^N$. These represent the \"true\" observations we would make in a universe described by the given true parameters. For each of the $N=8$ tracers at a given comoving position $\\mathbf{r}_i$, we compute its comoving distance $d_i = \\|\\mathbf{r}_i\\|$ and its line-of-sight unit vector $\\hat{\\mathbf{n}}_i = \\mathbf{r}_i / d_i$. The observed redshift-space velocity $v_i^z$ is the sum of the Hubble expansion velocity and the projection of the peculiar velocity along the line of sight. According to the problem statement, this is given by:\n$$\nv_i^{z} = H_{\\mathrm{true}}\\,d_i + u_{r,i}\n$$\nwhere $H_{\\mathrm{true}} = 70\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$ is the true Hubble parameter and $u_{r,i}$ is the radial peculiar velocity. The peculiar velocity field is modeled as a superposition of a uniform bulk flow, $\\mathbf{v}_{\\mathrm{bulk,true}} = (100, -50, 30)\\,\\mathrm{km\\,s^{-1}}$, and a velocity component arising from a uniform matter overdensity $\\delta_{0,\\mathrm{true}} = 0.03$. This leads to the expression for the radial peculiar velocity:\n$$\nu_{r,i} = \\hat{\\mathbf{n}}_i \\cdot \\mathbf{v}_{\\mathrm{bulk,true}} - \\frac{1}{3} H_{\\mathrm{true}} f \\delta_{0,\\mathrm{true}} \\, d_i\n$$\nHere, the linear growth rate is $f = 0.5$, and we operate at redshift $z \\approx 0$ where the scale factor $a=1$. Combining these gives the final expression for our synthetic data:\n$$\nv_i^{z} = H_{\\mathrm{true}}\\,d_i + \\hat{\\mathbf{n}}_i \\cdot \\mathbf{v}_{\\mathrm{bulk,true}} - \\frac{1}{3} H_{\\mathrm{true}} f \\delta_{0,\\mathrm{true}} \\, d_i\n$$\nThese $N=8$ values for $v_i^z$ are computed once and serve as the fixed observational data for the subsequent inference steps.\n\nSecond, we formulate the Bayesian inference problem. The goal is to infer the parameter vector $\\boldsymbol{\\theta} = (v_x, v_y, v_z, \\delta_0)^\\top$ from the data. The inference process, however, assumes a Hubble parameter prior $H_0$ which may differ from $H_{\\mathrm{true}}$. This assumed $H_0$ affects both the interpretation of the data and the physical model. The \"observed\" peculiar velocities are derived by subtracting the assumed Hubble flow:\n$$\ny_i \\equiv u_i^{\\mathrm{obs}}(H_0) = v_i^{z} - H_0\\, d_i\n$$\nThe vector $\\mathbf{y}(H_0) = (y_1, \\ldots, y_N)^\\top$ is our data vector for the regression. The model that predicts these observations is:\n$$\nu_i^{\\mathrm{model}} = \\hat{\\mathbf{n}}_i \\cdot \\mathbf{v}_{\\mathrm{bulk}} - \\frac{1}{3} H_0 f \\delta_0 \\, d_i\n$$\nThis can be written in the form of a linear system $\\mathbf{y} = \\mathbf{A}\\boldsymbol{\\theta}$. The design matrix $\\mathbf{A}(H_0) \\in \\mathbb{R}^{N \\times 4}$ is constructed such that for each tracer $i$, the corresponding row is $[\\hat{n}_{ix}, \\hat{n}_{iy}, \\hat{n}_{iz}, -\\frac{1}{3} H_0 f d_i]$. Both the data vector $\\mathbf{y}$ and the design matrix $\\mathbf{A}$ are functions of the assumed $H_0$.\n\nThird, we compute the posterior mean of the parameters $\\boldsymbol{\\theta}$. The problem specifies a Gaussian likelihood with a diagonal noise covariance matrix $\\mathbf{N} = \\mathrm{diag}(\\sigma_1^2, \\ldots, \\sigma_N^2)$, where each $\\sigma_i = 50\\,\\mathrm{km\\,s^{-1}}$. The prior on $\\boldsymbol{\\theta}$ is a zero-mean Gaussian with a diagonal covariance matrix $\\mathbf{\\Sigma}_0 = \\mathrm{diag}(\\sigma_v^2, \\sigma_v^2, \\sigma_v^2, \\sigma_\\delta^2)$, where $\\sigma_v = 300\\,\\mathrm{km\\,s^{-1}}$ and $\\sigma_\\delta = 0.2$. For a Bayesian linear model with Gaussian prior and likelihood, the posterior distribution is also Gaussian. Its mean, which represents our best estimate for the parameters, is given by the standard formula:\n$$\n\\boldsymbol{\\mu}_{\\mathrm{post}}(H_0) = \\left(\\mathbf{A}(H_0)^\\top \\mathbf{N}^{-1} \\mathbf{A}(H_0) + \\mathbf{\\Sigma}_0^{-1}\\right)^{-1} \\mathbf{A}(H_0)^\\top \\mathbf{N}^{-1} \\mathbf{y}(H_0)\n$$\nWe compute this posterior mean vector $\\boldsymbol{\\mu}_{\\mathrm{post}}(H_0)$ for each of the three specified values of $H_0$: the baseline $H_0 = 70.0\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$, the positive variation $H_0 = 73.5\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$, and the negative variation $H_0 = 66.5\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$. The resulting vector for each case contains the inferred parameters, i.e., $\\boldsymbol{\\mu}_{\\mathrm{post}} = (\\hat{v}_x, \\hat{v}_y, \\hat{v}_z, \\hat{\\delta}_0)^\\top$.\n\nFinally, we quantify the shifts in the inferred parameters relative to the baseline case ($H_0 = 70.0\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$). Let $\\boldsymbol{\\mu}_{\\mathrm{post}}(70) = (\\mathbf{v}_{\\mathrm{bulk}}(70), \\delta_0(70))^\\top$ be the posterior mean for the baseline. For each test case with a given $H_0$, we calculate its posterior mean $\\boldsymbol{\\mu}_{\\mathrm{post}}(H_0) = (\\mathbf{v}_{\\mathrm{bulk}}(H_0), \\delta_0(H_0))^\\top$. The shift in the bulk flow is the Euclidean norm of the difference between the inferred velocity vectors:\n$$\n\\Delta v = \\|\\mathbf{v}_{\\mathrm{bulk}}(H_0) - \\mathbf{v}_{\\mathrm{bulk}}(70)\\|\n$$\nThe shift in the density parameter is the simple arithmetic difference:\n$$\n\\Delta \\delta = \\delta_0(H_0) - \\delta_0(70)\n$$\nFor the baseline case itself ($H_0=70$), these shifts are tautologically zero. For the other two cases, these shifts measure the systematic error introduced into the parameter inference by a $\\pm 5\\%$ error in the assumed Hubble parameter. The numerical implementation will involve constructing the specified vectors and matrices using NumPy and solving the matrix equations for each case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the cosmological inference problem as specified.\n    \"\"\"\n\n    # 1. Define Givens and Constants\n    # Tracer positions in Mpc\n    r_tracers = np.array([\n        [10.0, 0.0, 0.0],\n        [0.0, 12.0, 0.0],\n        [0.0, 0.0, 8.0],\n        [-9.0, 0.0, 0.0],\n        [0.0, -11.0, 0.0],\n        [0.0, 0.0, -7.0],\n        [7.0, 7.0, 0.0],\n        [0.0, 5.0, 5.0]\n    ])\n    num_tracers = r_tracers.shape[0]\n\n    # True cosmological parameters\n    H_true = 70.0  # km/s/Mpc\n    f_growth = 0.5  # dimensionless\n    v_bulk_true = np.array([100.0, -50.0, 30.0])  # km/s\n    delta_0_true = 0.03  # dimensionless\n    theta_true = np.array([100.0, -50.0, 30.0, 0.03])\n\n    # Measurement and prior standard deviations\n    sigma_noise = 50.0  # km/s\n    sigma_v_prior = 300.0  # km/s\n    sigma_delta_prior = 0.2  # dimensionless\n\n    # Test suite for H0\n    H0_cases = [70.0, 73.5, 66.5]  # km/s/Mpc\n\n    # 2. Generate Synthetic Observational Data\n    # Calculate geometric quantities for tracers\n    dists = np.linalg.norm(r_tracers, axis=1)\n    n_hats = r_tracers / dists[:, np.newaxis]\n\n    # Calculate true radial peculiar velocities\n    u_r_true = n_hats @ v_bulk_true - (1.0/3.0) * H_true * f_growth * delta_0_true * dists\n\n    # Calculate noiseless observed redshift-space velocities (v_z)\n    v_z = H_true * dists + u_r_true\n\n    # 3. Setup Inference Covariance Matrices (constant across cases)\n    # Noise covariance matrix (and its inverse)\n    N_inv = np.diag(np.full(num_tracers, 1.0 / sigma_noise**2))\n\n    # Prior covariance matrix (and its inverse)\n    prior_variances = np.array([sigma_v_prior**2, sigma_v_prior**2, sigma_v_prior**2, sigma_delta_prior**2])\n    Sigma0_inv = np.diag(1.0 / prior_variances)\n\n    # 4. Perform Bayesian Inference for Each H0 Case\n    posterior_means = []\n    for H0 in H0_cases:\n        # Construct data vector y(H0)\n        y = v_z - H0 * dists\n\n        # Construct design matrix A(H0)\n        A = np.zeros((num_tracers, 4))\n        A[:, 0:3] = n_hats\n        A[:, 3] = -(1.0/3.0) * H0 * f_growth * dists\n\n        # Calculate posterior mean using the provided formula\n        # Posterior precision matrix P = A^T N^-1 A + Sigma_0^-1\n        A_T_N_inv = A.T @ N_inv\n        P = A_T_N_inv @ A + Sigma0_inv\n        \n        # Inverse of posterior precision matrix is posterior covariance\n        P_inv = np.linalg.inv(P)\n\n        # Posterior mean mu_post = P^-1 A^T N^-1 y\n        mu_post = P_inv @ A_T_N_inv @ y\n        posterior_means.append(mu_post)\n\n    # 5. Calculate shifts relative to the baseline (H0 = 70)\n    mu_baseline = posterior_means[0]\n    v_bulk_baseline = mu_baseline[0:3]\n    delta_0_baseline = mu_baseline[3]\n\n    results = []\n    for mu_post in posterior_means:\n        v_bulk_post = mu_post[0:3]\n        delta_0_post = mu_post[3]\n\n        # Magnitude of the shift in the bulk flow vector\n        delta_v_mag = np.linalg.norm(v_bulk_post - v_bulk_baseline)\n\n        # Shift in the density mode\n        delta_delta = delta_0_post - delta_0_baseline\n\n        results.append([delta_v_mag, delta_delta])\n    \n    # 6. Format and Print Final Output\n    # Create the final string representation as required.\n    # e.g., [[0.0,0.0],[12.34,-0.0567],[11.11,0.0555]]\n    # Using f-strings and a loop to format numbers to a reasonable precision\n    result_str = \",\".join([f\"[{v:.4f},{d:.4f}]\" for v, d in results])\n    \n    # Per problem spec, the first case should be exactly [0.0, 0.0]\n    # Small floating point errors might make it non-zero. Let's enforce it.\n    results[0] = [0.0, 0.0]\n    final_output_str = f\"[[{results[0][0]},{results[0][1]}],\"\n    final_output_str += \",\".join([f\"[{v},{d}]\" for v, d in results[1:]])\n    final_output_str += \"]\"\n\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}