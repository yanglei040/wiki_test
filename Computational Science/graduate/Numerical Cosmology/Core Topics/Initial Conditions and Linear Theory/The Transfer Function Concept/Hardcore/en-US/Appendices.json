{
    "hands_on_practices": [
        {
            "introduction": "The most prominent feature of the matter transfer function, $T(k)$, is its characteristic \"turnover,\" which separates large-scale modes that grew unimpeded from small-scale modes whose growth was suppressed. This shape is a direct fossil of a key transition in cosmic history: the epoch of matter-radiation equality. This exercise () challenges you to connect theory to this observable feature by deriving, from first principles, why the turnover scale is set by the horizon size at equality, and to calculate this scale, $k_{\\mathrm{eq}}$, in terms of fundamental cosmological parameters.",
            "id": "3499458",
            "problem": "A spatially flat Friedmann–Lemaître–Robertson–Walker (FLRW) cosmology is filled with non-relativistic matter and relativistic species (photons and effectively massless neutrinos), with present-day density parameters denoted by $\\Omega_{m}$ and $\\Omega_{r}$, respectively. The linear Cold Dark Matter (CDM) matter transfer function $T(k)$ encodes the scale dependence of the suppression of growth caused by modes that enter the horizon during radiation domination. For adiabatic initial conditions, modes with comoving wavenumber $k$ that enter the Hubble horizon during radiation domination experience suppressed growth relative to modes that enter after matter–radiation equality, leading to a turnover of $T(k)$ at a characteristic wavenumber set by the horizon scale at equality.\n\nUsing only the Friedmann equation for the background expansion, the scalings $\\rho_{m}\\propto a^{-3}$ and $\\rho_{r}\\propto a^{-4}$, and the definition of matter–radiation equality, do the following:\n\n- Starting from first principles, argue why the turnover scale of $T(k)$ is proportional to the comoving Hubble scale at matter–radiation equality, and hence to the equality wavenumber $k_{\\mathrm{eq}}$. Your argument should begin from the physical growth of subhorizon perturbations across radiation and matter domination and should not assume any specific fitting formula for $T(k)$.\n\n- Derive an explicit, closed-form expression for the equality wavenumber $k_{\\mathrm{eq}}$ in terms of the combinations $\\Omega_{m}h^{2}$ and $\\Omega_{r}h^{2}$ only, where $H_{0}=100\\,h\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$. Take the speed of light to be $c=299{,}792.458\\,\\mathrm{km\\,s^{-1}}$ and neglect spatial curvature and dark energy at equality.\n\nExpress your final answer for $k_{\\mathrm{eq}}$ in units of $\\mathrm{Mpc}^{-1}$ as a single, closed-form analytic expression involving only the symbols $\\Omega_{m}h^{2}$, $\\Omega_{r}h^{2}$, and numerical constants. Do not evaluate numerically and do not round.",
            "solution": "The problem asks for two components: a physical argument for the significance of the equality wavenumber $k_{\\mathrm{eq}}$ for the matter transfer function $T(k)$, and a derivation of an explicit expression for $k_{\\mathrm{eq}}$.\n\n**Part 1: Physical Argument for the Turnover Scale**\n\nThe matter transfer function, $T(k)$, quantifies the evolution of a density perturbation with comoving wavenumber $k$ from the early universe to the present, relative to the growth of a mode on very large scales that is always outside the Hubble horizon. The shape of $T(k)$ is determined by the physics of perturbation growth, which depends critically on whether a mode is inside or outside the comoving Hubble horizon, $(aH)^{-1}$, and whether the universe is dominated by radiation or matter.\n\nA density perturbation mode with comoving wavenumber $k$ has a physical wavelength $\\lambda_{\\mathrm{phys}} = 2\\pi a(t)/k$. The mode is said to \"enter the horizon\" when its physical wavelength becomes comparable to the Hubble radius $H^{-1}$, which is the characteristic causal scale of the universe at time $t$. The condition for horizon entry is thus $a/k \\sim H^{-1}$, or $k \\sim aH$.\n\nThe growth of cold dark matter (CDM) density perturbations, $\\delta_{m} \\equiv \\delta\\rho_{m}/\\rho_{m}$, is governed by the interplay between gravitational instability and the expansion of the universe.\n\n1.  **Radiation-Dominated (RD) Era ($a  a_{\\mathrm{eq}}$)**: In this epoch, the total energy density is dominated by relativistic species, $\\rho \\approx \\rho_r$, so the Friedmann equation gives $H^2 \\propto \\rho_r \\propto a^{-4}$. For a matter perturbation deep inside the horizon ($k \\gg aH$), the expansion term $2H\\dot{\\delta}_{m}$ is large and prevents efficient growth. The pressure of the dominant radiation component prevents it from clustering, causing the gravitational potentials of sub-horizon modes to decay. The result is that CDM perturbations experience only very slow, logarithmic growth, a phenomenon known as the Mészáros effect: $\\delta_{m} \\propto \\ln(a)$.\n\n2.  **Matter-Dominated (MD) Era ($a > a_{\\mathrm{eq}}$)**: In this epoch, non-relativistic matter dominates the energy density, $\\rho \\approx \\rho_m$, so $H^2 \\propto \\rho_m \\propto a^{-3}$. For subhorizon modes, gravity is now fully effective and drives growth, leading to the standard solution $\\delta_{m} \\propto a$.\n\nThe shape of the transfer function arises from the different growth histories of modes that enter the horizon at different times:\n\n-   **Large-scale modes ($k \\ll k_{\\mathrm{eq}}$)**: These modes enter the horizon during the matter-dominated era ($a_{\\mathrm{enter}} > a_{\\mathrm{eq}}$). After horizon entry, they immediately begin to grow linearly with the scale factor, $\\delta_{m} \\propto a$. They do not experience the period of stagnation. We normalize the transfer function such that $T(k) \\to 1$ for these modes as $k \\to 0$.\n\n-   **Small-scale modes ($k \\gg k_{\\mathrm{eq}}$)**: These modes enter the horizon during the radiation-dominated era ($a_{\\mathrm{enter}}  a_{\\mathrm{eq}}$). Upon entering the horizon, their growth stagnates and proceeds only logarithmically until the universe becomes matter-dominated at $a_{\\mathrm{eq}}$. After $a_{\\mathrm{eq}}$, they resume linear growth, $\\delta_{m} \\propto a$. Because they spent a period of their evolution with suppressed growth, their final amplitude is significantly smaller compared to the large-scale modes. This leads to a suppression in the transfer function, $T(k)  1$.\n\nThe transition between these two regimes occurs for modes that enter the horizon precisely at the time of matter-radiation equality, $a_{\\mathrm{eq}}$. The comoving wavenumber for such modes is defined as the equality wavenumber, $k_{\\mathrm{eq}}$, given by the condition $k_{\\mathrm{eq}} = a_{\\mathrm{eq}}H(a_{\\mathrm{eq}})$. This wavenumber, $k_{\\mathrm{eq}}$, therefore marks the \"turnover\" or \"break\" in the transfer function. For $k  k_{\\mathrm{eq}}$, $T(k)$ is approximately constant, while for $k > k_{\\mathrm{eq}}$, $T(k)$ decreases. Thus, the turnover scale of $T(k)$ is directly set by the comoving Hubble scale at matter-radiation equality.\n\n**Part 2: Derivation of the Equality Wavenumber $k_{\\mathrm{eq}}$**\n\nThe equality wavenumber is defined as the comoving Hubble rate at the epoch of matter-radiation equality, $a_{\\mathrm{eq}}$:\n$$k_{\\mathrm{eq}} = a_{\\mathrm{eq}} H(a_{\\mathrm{eq}})$$\n\nFirst, we determine $a_{\\mathrm{eq}}$ from the condition $\\rho_{m}(a_{\\mathrm{eq}}) = \\rho_{r}(a_{\\mathrm{eq}})$. Using $\\rho_{m} = \\rho_{m,0} a^{-3}$ and $\\rho_{r} = \\rho_{r,0} a^{-4}$:\n$$\\rho_{m,0} a_{\\mathrm{eq}}^{-3} = \\rho_{r,0} a_{\\mathrm{eq}}^{-4} \\implies a_{\\mathrm{eq}} = \\frac{\\rho_{r,0}}{\\rho_{m,0}} = \\frac{\\Omega_{r}}{\\Omega_{m}}$$\n\nNext, we find $H(a_{\\mathrm{eq}})$ from the Friedmann equation for a flat universe, neglecting dark energy at early times:\n$$H^{2}(a) = H_{0}^{2} \\left( \\Omega_{m}a^{-3} + \\Omega_{r}a^{-4} \\right)$$\nAt $a=a_{\\mathrm{eq}}$, $\\Omega_{m}a_{\\mathrm{eq}}^{-3} = \\Omega_{r}a_{\\mathrm{eq}}^{-4}$. Substituting this into the Friedmann equation:\n$$H^{2}(a_{\\mathrm{eq}}) = H_{0}^{2} \\left( \\Omega_{r}a_{\\mathrm{eq}}^{-4} + \\Omega_{r}a_{\\mathrm{eq}}^{-4} \\right) = 2 H_{0}^{2} \\Omega_{r} a_{\\mathrm{eq}}^{-4}$$\nTaking the square root gives:\n$$H(a_{\\mathrm{eq}}) = \\sqrt{2} H_{0} \\sqrt{\\Omega_{r}} a_{\\mathrm{eq}}^{-2}$$\n\nNow we combine these results to find $k_{\\mathrm{eq}}$:\n$$k_{\\mathrm{eq}} = a_{\\mathrm{eq}} H(a_{\\mathrm{eq}}) = a_{\\mathrm{eq}} \\left( \\sqrt{2} H_{0} \\sqrt{\\Omega_{r}} a_{\\mathrm{eq}}^{-2} \\right) = \\frac{\\sqrt{2} H_{0} \\sqrt{\\Omega_{r}}}{a_{\\mathrm{eq}}}$$\nSubstituting our expression for $a_{\\mathrm{eq}} = \\Omega_{r}/\\Omega_{m}$:\n$$k_{\\mathrm{eq}} = \\frac{\\sqrt{2} H_{0} \\sqrt{\\Omega_{r}}}{\\Omega_{r}/\\Omega_{m}} = \\sqrt{2} H_{0} \\frac{\\Omega_{m}}{\\sqrt{\\Omega_{r}}}$$\nTo obtain $k_{\\mathrm{eq}}$ in units of $\\mathrm{Mpc}^{-1}$, we must divide by the speed of light $c$:\n$$k_{\\mathrm{eq}} \\left[\\mathrm{Mpc}^{-1}\\right] = \\frac{\\sqrt{2} H_{0}}{c} \\frac{\\Omega_{m}}{\\sqrt{\\Omega_{r}}}$$\nWe are asked to express this in terms of $\\Omega_{m}h^{2}$ and $\\Omega_{r}h^{2}$. We substitute $H_{0} = 100\\,h\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$:\n$$k_{\\mathrm{eq}} = \\frac{\\sqrt{2} (100h)}{c} \\frac{\\Omega_{m}}{\\sqrt{\\Omega_{r}}} = \\frac{100\\sqrt{2}}{c} \\frac{h \\Omega_{m}}{\\sqrt{\\Omega_{r}}}$$\nTo introduce the required parameter combinations, we rearrange the expression:\n$$k_{\\mathrm{eq}} = \\frac{100\\sqrt{2}}{c} \\frac{\\Omega_{m}h^2 / h}{\\sqrt{\\Omega_{r}h^2 / h^2}} = \\frac{100\\sqrt{2}}{c} \\frac{\\Omega_{m}h^2 / h}{\\sqrt{\\Omega_{r}h^2} / h} = \\frac{100\\sqrt{2}}{c} \\frac{\\Omega_{m}h^{2}}{\\sqrt{\\Omega_{r}h^{2}}}$$\nFinally, we insert the numerical value for $c = 299792.458\\,\\mathrm{km\\,s^{-1}}$:\n$$k_{\\mathrm{eq}} = \\frac{100\\sqrt{2}}{299792.458} \\frac{\\Omega_{m}h^{2}}{\\sqrt{\\Omega_{r}h^{2}}}$$\nThe units are consistently $\\mathrm{Mpc}^{-1}$ as the prefactor becomes dimensionless.",
            "answer": "$$\\boxed{\\frac{100\\sqrt{2}}{299792.458} \\frac{\\Omega_{m}h^{2}}{\\sqrt{\\Omega_{r}h^{2}}}}$$"
        },
        {
            "introduction": "While analytical arguments can explain the general shape of the transfer function, calculating it with high precision requires solving a complex system of coupled Boltzmann-Einstein equations. This numerical task presents significant challenges, particularly when resolving fine-scale features like Baryon Acoustic Oscillations (BAO) or handling the extreme conditions of the early universe. This practice () delves into the sophisticated numerical strategies at the heart of modern Boltzmann solvers, forcing you to consider how to handle stiff differential equations and design an efficient wavenumber sampling scheme to ensure both stability and accuracy.",
            "id": "3499494",
            "problem": "Consider the computation of the matter transfer function $T(k)$ in linear theory, defined through $P(k,z) = P_{\\mathrm{prim}}(k)\\,T^2(k,z)$ with $P_{\\mathrm{prim}}(k) \\propto k^{n_s}$ for adiabatic initial conditions, where $P(k,z)$ is the matter power spectrum, $P_{\\mathrm{prim}}(k)$ is the primordial power spectrum, $n_s$ is the scalar spectral index, and $z$ is the redshift. A numerical Boltzmann–Einstein solver integrates the coupled linearized perturbation equations for photons, baryons, cold dark matter, and metric potentials in conformal time $\\eta$. Before recombination, the photon–baryon fluid is in the tight-coupling regime with large Thomson scattering rate $\\dot{\\tau}(\\eta) = a(\\eta)\\,n_e(\\eta)\\,\\sigma_T$, where $a(\\eta)$ is the scale factor, $n_e(\\eta)$ is the free-electron number density, and $\\sigma_T$ is the Thomson cross section. This regime induces stiffness because the collision term timescale $t_c \\sim 1/|\\dot{\\tau}|$ can be much shorter than the acoustic timescale $(k c_s)^{-1}$ or the expansion timescale $\\mathcal{H}^{-1}$, where $c_s$ is the photon–baryon sound speed and $\\mathcal{H} = aH$ is the conformal Hubble parameter.\n\nAs a function of $k$, the transfer function $T(k)$ exhibits physically induced features that must be resolved: a turnover near the matter–radiation equality scale $k_{\\mathrm{eq}}$ set by the horizon at equality, Baryon Acoustic Oscillation (BAO) wiggles with characteristic spacing $\\Delta k \\sim \\pi/r_s$ where $r_s$ is the comoving sound horizon at recombination, and Silk damping setting a suppression scale $k_{\\mathrm{Silk}}$. Assume a target fractional error tolerance $\\epsilon$ on $T(k)$ at $z=0$ of order $\\epsilon \\sim 10^{-2}$.\n\nWhich numerical strategy most robustly ensures stability and accuracy for computing $T(k)$ across $k \\in [k_{\\min}, k_{\\max}]$, taking into account both $k$-sampling and stiffness handling in the tight-coupling regime?\n\nA. Use a logarithmic $k$ grid to cover multiple decades with base step $\\Delta \\ln k$ and apply adaptive local refinement triggered by curvature of $T(k)$ so that near the BAO regime and any region with $|T''(k)|/|T(k)|$ large, the local spacing satisfies $\\Delta k \\lesssim \\pi/(m\\,r_s)$ for some integer $m \\ge 3$ to capture oscillations at the target $\\epsilon$, and refine around $k_{\\mathrm{eq}}$ to resolve the turnover. Integrate the stiff photon–baryon subsystem with an implicit–explicit scheme that treats collision terms proportional to $\\dot{\\tau}$ implicitly (or with a tight-coupling asymptotic reduction), and switch to a nonstiff explicit integrator when $|\\dot{\\tau}| \\lesssim \\alpha \\max(k c_s,\\mathcal{H})$ for some $\\alpha = \\mathcal{O}(1)$, enforcing continuity of variables and their first derivatives across the switch and monitoring local truncation error to meet $\\epsilon$.\n\nB. Use a uniform linear $k$ grid with constant spacing $\\Delta k$ and a single explicit Runge–Kutta time integrator for all species and epochs, reducing the conformal time step $\\Delta \\eta$ so that $\\Delta \\eta \\ll 1/|\\dot{\\tau}|$ during tight coupling, without employing tight-coupling asymptotics or any implicit treatment. Do not perform any targeted refinement near $k_{\\mathrm{eq}}$ or BAO; rely on the uniform grid for resolution.\n\nC. Use a logarithmic $k$ grid with coarse constant $\\Delta \\ln k$ across the full domain and handle stiffness by tightening the error tolerances of an explicit adaptive integrator during tight coupling while keeping all collision terms explicit. Do not include a dedicated refinement policy near BAO or the equality turnover.\n\nD. Fit $T(k)$ globally with a high-order polynomial on $k \\in [k_{\\min},k_{\\max}]$ sampled at Chebyshev nodes and compute coefficients from a reduced set of $k$ modes. Integrate the perturbations once on this sparse set using an explicit scheme with a smoothed collision term to mitigate stiffness, and reconstruct $T(k)$ elsewhere via polynomial interpolation.\n\nE. Use an adaptive logarithmic $k$ grid that refines only where $|T(k)|$ is large and coarsens where $|T(k)|$ is small, without reference to derivatives of $T(k)$ or known physical scales. Evolve all species with a fully implicit scheme at all times, never switching to explicit schemes after recombination, and do not employ tight-coupling asymptotics; accept any artificial damping or phase distortion introduced by the unconditional implicit treatment.\n\nSelect the option that best satisfies the stability and accuracy requirements consistent with the physical origin of features in $T(k)$ and the stiffness induced by $\\dot{\\tau}$ in the tight-coupling regime, for error tolerance $\\epsilon$ at $z=0$.",
            "solution": "This problem requires identifying the most robust numerical strategy for computing the cosmological matter transfer function, $T(k)$. A successful strategy must address two main challenges: resolving the complex features of $T(k)$ over a wide range of wavenumbers $k$, and stably integrating the stiff system of Boltzmann-Einstein equations through time.\n\n**1. Wavenumber ($k$) Sampling:**\nThe transfer function $T(k)$ has features spanning many orders of magnitude, including a broad turnover at $k_{\\mathrm{eq}}$, quasi-periodic Baryon Acoustic Oscillations (BAO), and a sharp Silk damping cutoff.\n-   A **logarithmic grid** is efficient for spanning many decades in $k$.\n-   **Adaptive refinement** is crucial for accurately capturing the BAO wiggles, which are roughly periodic in $k$, not $\\ln k$. A good strategy is to add more points where the function's curvature is high (e.g., where $|T''(k)|$ is large), ensuring the sampling density is sufficient to resolve oscillations.\n\n**2. Time Integration and Stiffness:**\nBefore recombination, the high rate of Thomson scattering ($\\dot{\\tau}$) makes the Boltzmann equations a stiff system of differential equations. The scattering timescale is much shorter than the cosmological expansion or perturbation evolution timescales.\n-   Using a standard **explicit integrator** (like Runge-Kutta) is computationally infeasible, as its stability would require an impractically small time step ($\\Delta \\eta \\ll 1/|\\dot{\\tau}|$).\n-   The correct approach is to use methods designed for stiff systems. The state-of-the-art solutions are **implicit-explicit (IMEX) schemes** or a **tight-coupling approximation (TCA)**. These methods handle the stiff scattering terms in a stable manner, allowing for much larger, more efficient time steps.\n-   After recombination, the system is no longer stiff. For maximum efficiency, the code should **switch to a fast explicit integrator** in this regime.\n\nBased on these principles, we can evaluate the options:\n\n-   **Option A** correctly combines all elements of a robust strategy: an adaptive logarithmic $k$-grid to resolve physical features and a specialized stiff integrator (IMEX or TCA) that switches to an explicit method when the system is no longer stiff. This represents the modern approach used in codes like CAMB and CLASS.\n\n-   **Option B** is numerically naive. A linear $k$-grid is highly inefficient, and using a purely explicit integrator for a stiff system is computationally prohibitive.\n\n-   **Option C** fails on both counts. A coarse, non-adaptive grid will not resolve the BAO. Attempting to handle stiffness by tightening the tolerance of an explicit integrator does not solve the underlying stability problem and is extremely inefficient.\n\n-   **Option D** proposes inappropriate methods. Global polynomial fitting is poorly suited for a function with both oscillatory and sharp features. Smoothing the collision term is physically inaccurate and would corrupt the result.\n\n-   **Option E** uses a flawed refinement criterion (refining based on magnitude instead of curvature) and an inefficient time-integration scheme (fully implicit at all times). It also explicitly accepts numerical errors, which is contrary to a high-accuracy goal.\n\nTherefore, Option A is the only choice that describes a complete, accurate, and efficient numerical strategy for this problem.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Cosmology is increasingly a data-driven science, where we infer physical models from observations rather than only predicting them. This practice () shifts your perspective from forward-modeling to this inverse problem: given noisy measurements of the matter power spectrum, how can we reconstruct the underlying transfer function? You will implement a deconvolution pipeline using Tikhonov regularization, a powerful technique for stabilizing solutions to ill-posed inverse problems, providing hands-on experience with the challenges and methods of cosmological signal reconstruction.",
            "id": "3499485",
            "problem": "You are to implement a complete deconvolution pipeline that infers the cosmological transfer function squared from mock observations of the matter power spectrum using Tikhonov regularization. The starting point is the linear-theory relation between the matter power spectrum and the transfer function: for each wavenumber $k$ and redshift $z$, the matter power spectrum $P(k,z)$ can be written as $P(k,z) = P_{\\rm prim}(k)\\,T^{2}(k,z)$, where $P_{\\rm prim}(k)$ is the primordial power spectrum and $T(k,z)$ is the transfer function. You are given a prior that $P_{\\rm prim}(k) \\propto k^{n_s - 4}$, where $n_s$ is the scalar spectral index. You must formalize the inverse problem to recover $T(k,z)$ from noisy measurements of $P(k,z)$.\n\nUse the following definitions and modeling choices to generate a self-consistent mock dataset and to define the inverse problem:\n\n- Define a logarithmically spaced wavenumber grid with $N_k = 64$ points from $k_{\\min} = 5\\times 10^{-3}$ to $k_{\\max} = 1$ in arbitrary inverse-length units. The precise physical unit is not required because the final reported metrics are dimensionless.\n\n- Construct a physically plausible, smooth, positive, and monotonic \"true\" transfer function as\n$$\nT_{\\rm true}(k,z) = D(z)\\,T_0(k),\n$$\nwhere $D(z)$ is the linear growth factor approximated as $D(z) = \\frac{1}{1+z}$ and\n$$\nT_0(k) = \\frac{1}{1 + \\frac{k}{k_0} + \\left(\\frac{k}{k_1}\\right)^2},\n$$\nwith $k_0 = 0.05$ and $k_1 = 0.2$. These constants are chosen to mimic the qualitative suppression of power on small scales while remaining numerically simple.\n\n- Adopt a unit-amplitude primordial prior\n$$\nP_{\\rm prim}(k) = k^{n_s - 4},\n$$\nso that the mock \"true\" power spectrum is given by\n$$\nP_{\\rm true}(k,z) = P_{\\rm prim}(k)\\,T_{\\rm true}^2(k,z).\n$$\n\n- Create a noisy observation vector $y(k;z)$ by adding independent Gaussian noise to each $k$-bin,\n$$\ny(k;z) = P_{\\rm true}(k,z) + \\epsilon(k),\n$$\nwith $\\epsilon(k) \\sim \\mathcal{N}(0,\\sigma^2(k))$ and heteroscedastic variance\n$$\n\\sigma(k) = \\sigma_{\\rm rel}\\,P_{\\rm true}(k,z),\n$$\nwhere $\\sigma_{\\rm rel}$ is a specified relative noise amplitude. To ensure deterministic reproducibility, use a fixed random seed $s = 12345$.\n\n- Pose the inversion in terms of the unknown nonnegative vector $x(k;z) = T^2(k,z)$. Let $A$ denote the diagonal operator $A = \\operatorname{diag}(P_{\\rm prim}(k))$, let $y$ denote the observed data vector $y(k;z)$, and let $W$ be the diagonal weighting operator $W = \\operatorname{diag}(1/\\sigma(k))$. Introduce a smoothness operator $L$ as the second-order finite-difference on the $k$-grid interior (unscaled), acting along the $k$-index so that $(Lx)_i = x_{i-1} - 2 x_i + x_{i+1}$ for interior indices. Recover $x$ by minimizing the weighted Tikhonov-regularized objective\n$$\nJ(x) = \\lVert W(Ax - y) \\rVert_2^2 + \\lambda^2 \\lVert L x \\rVert_2^2,\n$$\nwith regularization parameter $\\lambda \\ge 0$. After solving for $x$, recover the transfer function as $T_{\\rm est}(k;z) = \\sqrt{\\max(x(k;z),\\epsilon_x)}$ with a small nonnegativity floor $\\epsilon_x = 10^{-12}$ to avoid floating point issues.\n\n- Quantify performance using the relative root-mean-square error (dimensionless) over the $k$-grid,\n$$\nR = \\sqrt{\\frac{1}{N_k} \\sum_{i=1}^{N_k} \\left(\\frac{T_{\\rm est}(k_i;z) - T_{\\rm true}(k_i;z)}{T_{\\rm true}(k_i;z)}\\right)^2}.\n$$\n\nYour program must implement the full pipeline above and compute $R$ for each of the following test cases, which together form the test suite to probe a general case, a no-regularization boundary, higher redshift, high noise with stronger regularization, and the effect of a different spectral index:\n\n- Test case $1$: $(n_s, z, \\sigma_{\\rm rel}, \\lambda) = (0.965, 0.0, 0.05, 10^{-3})$.\n- Test case $2$: $(n_s, z, \\sigma_{\\rm rel}, \\lambda) = (0.965, 0.0, 0.05, 0)$.\n- Test case $3$: $(n_s, z, \\sigma_{\\rm rel}, \\lambda) = (0.965, 1.0, 0.10, 10^{-3})$.\n- Test case $4$: $(n_s, z, \\sigma_{\\rm rel}, \\lambda) = (0.965, 0.0, 0.20, 10^{-2})$.\n- Test case $5$: $(n_s, z, \\sigma_{\\rm rel}, \\lambda) = (1.0, 0.0, 0.05, 10^{-1})$.\n\nImplementation requirements:\n\n- Solve the Tikhonov problem exactly as posed using the normal equations for the minimizer of $J(x)$, assuming full-rank matrices after regularization. You must use a deterministic random seed $s = 12345$ for noise generation so that results are reproducible.\n\n- For each test case, return a single floating-point number equal to $R$ for that case. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order of the test cases. Each floating-point result must be formatted to exactly six digits after the decimal point.\n\n- No physical units are required in the output; all outputs are dimensionless numbers.\n\nYour final deliverable must be a complete, runnable program that implements the pipeline and prints the single required output line. No user input or external files are permitted.",
            "solution": "This problem requires implementing a Tikhonov regularization pipeline to solve a linear inverse problem: inferring the squared transfer function, $x(k;z) = T^2(k,z)$, from a vector of noisy mock power spectrum measurements, $y(k;z)$. Although the analytical form for the primordial power spectrum is a simplification for this exercise, it is used consistently throughout the problem's own definitions and does not invalidate the task. The core of the problem is to set up and solve this well-posed numerical challenge.\n\nThe solution process involves several distinct steps:\n\n1.  **Mock Data Generation**: First, a synthetic \"true\" universe is created based on the provided models. A logarithmically spaced grid of wavenumbers, $k$, is defined. The true transfer function $T_{\\rm true}(k,z)$, primordial power spectrum $P_{\\rm prim}(k)$, and resulting true matter power spectrum $P_{\\rm true}(k,z)$ are computed. Then, a vector of noisy observations, $y(k;z)$, is generated by adding heteroscedastic Gaussian noise to $P_{\\rm true}(k,z)$, using a fixed random seed for reproducibility.\n\n2.  **Posing the Inverse Problem**: The goal is to find the best estimate for $x = T^2(k,z)$ given the data $y$ and the linear model $y \\approx Ax$, where $A = \\operatorname{diag}(P_{\\rm prim}(k))$. Direct inversion is ill-posed, meaning noise in $y$ can cause large, unphysical oscillations in the solution. Tikhonov regularization stabilizes the solution by minimizing an objective function that balances data fidelity with solution smoothness:\n    $$\n    J(x) = \\lVert W(Ax - y) \\rVert_2^2 + \\lambda^2 \\lVert Lx \\rVert_2^2\n    $$\n    Here, the first term measures the weighted mismatch between the model prediction and the data, where $W = \\operatorname{diag}(1/\\sigma(k))$ is a weighting matrix based on the noise standard deviation. The second term is a regularization penalty that enforces smoothness, where $L$ is a finite-difference operator approximating the second derivative and $\\lambda$ is the regularization parameter.\n\n3.  **Solving the Normal Equations**: The vector $x$ that minimizes the quadratic objective function $J(x)$ can be found by setting the gradient $\\nabla_x J(x)$ to zero. This yields a system of linear equations known as the normal equations:\n    $$\n    \\left( A^T W^2 A + \\lambda^2 L^T L \\right) x = A^T W^2 y\n    $$\n    This is a standard matrix equation of the form $\\mathbf{M}x = \\mathbf{b}$, which can be solved numerically for $x$. The regularization term $\\lambda^2 L^T L$ ensures the matrix $\\mathbf{M}$ is well-conditioned and invertible.\n\n4.  **Performance Evaluation**: After solving for the estimated squared transfer function, $x$, the estimated transfer function is recovered via $T_{\\rm est}(k,z) = \\sqrt{\\max(x, \\epsilon_x)}$. The performance of the reconstruction is then quantified by calculating the relative root-mean-square error, $R$, between the estimated and true transfer functions.\n\nThe provided Python code implements this full pipeline, executing each step for all specified test cases and printing the results in the required format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a Tikhonov regularization pipeline to infer the cosmological\n    transfer function from mock power spectrum data.\n    \"\"\"\n\n    # Define constants from the problem statement.\n    N_k = 64\n    k_min = 5e-3\n    k_max = 1.0\n    k0 = 0.05\n    k1 = 0.2\n    epsilon_x = 1e-12\n    seed = 12345\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n_s, z, sigma_rel, lambda)\n        (0.965, 0.0, 0.05, 10**-3),\n        (0.965, 0.0, 0.05, 0.0),\n        (0.965, 1.0, 0.10, 10**-3),\n        (0.965, 0.0, 0.20, 10**-2),\n        (1.0, 0.0, 0.05, 10**-1),\n    ]\n\n    results = []\n\n    # Construct the wavenumber grid (same for all cases).\n    k = np.logspace(np.log10(k_min), np.log10(k_max), N_k)\n\n    # Construct the second-order finite-difference operator L (same for all cases).\n    # L has zeros on the first and last rows as it acts on interior points.\n    L = np.zeros((N_k, N_k))\n    for i in range(1, N_k - 1):\n        L[i, i - 1] = 1.0\n        L[i, i] = -2.0\n        L[i, i + 1] = 1.0\n    \n    # Pre-compute L^T L for efficiency.\n    L_T_L = L.T @ L\n\n    # Initialize a single random number generator for deterministic reproducibility.\n    rng = np.random.default_rng(seed)\n\n    # Iterate through each test case.\n    for n_s, z, sigma_rel, lam in test_cases:\n        # Step 1: Generate the \"true\" signals.\n        D_z = 1.0 / (1.0 + z)\n        T0_k = 1.0 / (1.0 + k / k0 + (k / k1)**2)\n        T_true = D_z * T0_k\n        \n        P_prim = k**(n_s - 4.0)\n        P_true = P_prim * T_true**2\n\n        # Step 2: Generate the noisy observation vector y.\n        sigma_k = sigma_rel * P_true\n        noise = rng.normal(loc=0.0, scale=sigma_k, size=N_k)\n        y = P_true + noise\n\n        # Step 3: Set up and solve the normal equations for Tikhonov regularization.\n        # The system to solve is (A.T @ W^2 @ A + lambda^2 * L.T @ L) @ x = A.T @ W^2 @ y\n        # A = diag(P_prim), W = diag(1/sigma_k)\n        # We can implement this efficiently without creating full diagonal matrices.\n        \n        # Left-hand side matrix M = A.T @ W^2 @ A + lambda^2 * L.T @ L\n        # A.T @ W^2 @ A is diagonal with entries (P_prim/sigma_k)^2\n        lhs_diag_part = (P_prim / sigma_k)**2\n        M_lhs = np.diag(lhs_diag_part) + lam**2 * L_T_L\n\n        # Right-hand side vector b = A.T @ W^2 @ y\n        # This is a vector with entries P_prim[i] * y[i] / sigma_k[i]^2\n        b_rhs = (P_prim / sigma_k**2) * y\n        \n        # Solve the linear system M @ x = b for x\n        x = np.linalg.solve(M_lhs, b_rhs)\n\n        # Step 4: Recover the estimated transfer function T_est.\n        # Enforce non-negativity with a small floor and take the square root.\n        x_nonneg = np.maximum(x, epsilon_x)\n        T_est = np.sqrt(x_nonneg)\n\n        # Step 5: Quantify performance with the relative RMSE.\n        relative_errors_sq = ((T_est - T_true) / T_true)**2\n        R = np.sqrt(np.mean(relative_errors_sq))\n        \n        results.append(R)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}