{
    "hands_on_practices": [
        {
            "introduction": "The amplitude of the matter power spectrum is not constant; it grows over cosmic time as gravity amplifies initial density fluctuations. This growth is sensitive to the universe's expansion history, which is in turn dictated by its energy content and geometry. This exercise explores the linear growth factor, $D(z)$, which captures the time-dependent evolution of density perturbations. By numerically solving the growth equation for different background cosmologies, you will gain a first-hand understanding of how the universe's composition ($\\Omega_m, \\Omega_\\Lambda$) and spatial curvature ($\\Omega_k$) directly impact the growth rate of large-scale structure .",
            "id": "3497156",
            "problem": "You are asked to derive and implement a numerical method to compute the linear growth factor $D(z)$ for a class of Friedmann-Robertson-Walker (FRW) cosmologies with matter, spatial curvature, and a cosmological constant. Your implementation must then assess the consequent change in the large-scale amplitude of the linear matter power spectrum $P(k)$ for three cosmologies that share an identical present-day matter density parameter $\\Omega_{m,0}$ but differ in spatial curvature and the cosmological constant. The derivation and algorithm must start from fundamental principles and well-tested facts and must not use shortcut formulas supplied in the problem statement.\n\nBegin from the following context-appropriate fundamental base:\n- The Friedmann equation for a homogeneous and isotropic universe described by the FRW metric and General Relativity (GR), with matter, spatial curvature, and the cosmological constant, and the relation between the Hubble expansion rate $H(a)$ and the energy densities.\n- The linearized continuity, Euler, and Poisson equations for a pressureless fluid in an expanding background, which imply the second-order homogeneous ordinary differential equation (ODE) for the matter density contrast $\\delta$ under the Newtonian approximation in an expanding FRW background.\n- The definition of the linear growth factor $D(a)$ through $\\delta(a) \\propto D(a)$ during linear evolution, and the fact that on sufficiently large scales (well above the nonlinear scale) the linear matter power spectrum scales as $P(k,a) \\propto D(a)^2$.\n\nYour program must implement a numerically stable ODE solver to compute $D(z)$ for the following three cosmologies that share an identical present-day matter density parameter:\n- Open cosmology: $\\Omega_{m,0} = 0.3$, $\\Omega_{\\Lambda,0} = 0.0$, $\\Omega_{k,0} = 1 - \\Omega_{m,0} - \\Omega_{\\Lambda,0}$.\n- Flat cosmology: $\\Omega_{m,0} = 0.3$, $\\Omega_{\\Lambda,0} = 1 - \\Omega_{m,0}$, $\\Omega_{k,0} = 0$.\n- Closed cosmology: $\\Omega_{m,0} = 0.3$, $\\Omega_{\\Lambda,0} = 0.8$, $\\Omega_{k,0} = 1 - \\Omega_{m,0} - \\Omega_{\\Lambda,0}$.\n\nAssumptions and requirements:\n- Neglect radiation at all redshifts considered.\n- Work with the scale factor $a$ related to redshift by $a = 1/(1+z)$.\n- Use an initial scale factor $a_{\\mathrm{init}} = 10^{-4}$ where matter domination holds and impose identical initial conditions across all cosmologies, namely $D(a_{\\mathrm{init}}) = a_{\\mathrm{init}}$ and $\\frac{dD}{d\\ln a}\\big|_{a_{\\mathrm{init}}} = a_{\\mathrm{init}}$, so that differences in $D(z)$ arise solely from the different background expansion histories.\n- Do not renormalize $D(z)$ at $z = 0$; instead, keep the normalization induced by the identical initial conditions at $a_{\\mathrm{init}}$.\n- The Hubble expansion rate $H(a)$ must be consistently computed from the Friedmann equation with the specified $\\Omega_{m,0}$, $\\Omega_{\\Lambda,0}$, and $\\Omega_{k,0}$, and the ODE for $D(a)$ must be formulated in terms of $a$ or $\\ln a$ with coefficients derived from $H(a)$. Every intermediate quantity must be mathematically well-defined.\n\nFrom the computed $D(z)$, define the large-scale amplitude factor $A(z) \\equiv D(z)^2$ for each cosmology, which captures the change in the overall normalization of $P(k)$ at large scales (neglecting transfer-function shape differences). For each test redshift, compute the ratios $A_{\\mathrm{open}}(z)/A_{\\mathrm{flat}}(z)$ and $A_{\\mathrm{closed}}(z)/A_{\\mathrm{flat}}(z)$ to quantify the amplitude differences relative to the flat case.\n\nTest suite:\n- Use the set of redshifts $\\{z\\} = \\{0, 1, 3, 10\\}$.\n- For each $z$ in the set, compute and report the following quantities for the three cosmologies defined above:\n  1. $D_{\\mathrm{open}}(z)$,\n  2. $D_{\\mathrm{flat}}(z)$,\n  3. $D_{\\mathrm{closed}}(z)$,\n  4. $A_{\\mathrm{open}}(z) = D_{\\mathrm{open}}(z)^2$,\n  5. $A_{\\mathrm{flat}}(z) = D_{\\mathrm{flat}}(z)^2$,\n  6. $A_{\\mathrm{closed}}(z) = D_{\\mathrm{closed}}(z)^2$,\n  7. $A_{\\mathrm{open}}(z)/A_{\\mathrm{flat}}(z)$,\n  8. $A_{\\mathrm{closed}}(z)/A_{\\mathrm{flat}}(z)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for all redshifts as a comma-separated list enclosed in square brackets, where each element is itself a list representing one redshift. For each redshift $z$, the sublist must be ordered as\n  $[z, D_{\\mathrm{open}}(z), D_{\\mathrm{flat}}(z), D_{\\mathrm{closed}}(z), A_{\\mathrm{open}}(z), A_{\\mathrm{flat}}(z), A_{\\mathrm{closed}}(z), A_{\\mathrm{open}}(z)/A_{\\mathrm{flat}}(z), A_{\\mathrm{closed}}(z)/A_{\\mathrm{flat}}(z)]$.\n- All numbers are dimensionless; no physical units are required.\n- The single line must match the exact formatting of a Python list of lists with numbers, for example\n  $[[\\cdots],[\\cdots],[\\cdots],[\\cdots]]$.\n\nEdge cases to be covered by the test suite:\n- $z = 0$ tests the present-day boundary and verifies that the different cosmologies yield different $D(0)$ due to distinct background histories when not renormalized.\n- $z = 10$ probes the early-time regime where matter domination is more pronounced and differences among cosmologies are reduced but still quantifiable.\n- $z = 1$ and $z = 3$ test intermediate regimes where curvature and the cosmological constant begin to alter growth significantly.\n\nYour final answer must be the complete, runnable program that carries out the above computations and prints the required single-line output in the exact format described.",
            "solution": "The user wants to compute the linear growth factor, $D(z)$, for three different Friedmann-Robertson-Walker (FRW) cosmologies and analyze the impact on the amplitude of the matter power spectrum, $P(k)$. This requires deriving the governing differential equation for $D(z)$ from fundamental principles and then solving it numerically.\n\n### 1. Theoretical Foundation\n\n#### The Friedmann Equation\nThe expansion dynamics of a homogeneous and isotropic universe are described by the Friedmann equation. For a universe containing non-relativistic matter (dust), a cosmological constant ($\\Lambda$), and spatial curvature, the equation for the Hubble parameter $H(a) = \\dot{a}/a$ (where $a$ is the scale factor and the dot denotes a derivative with respect to cosmic time $t$) is:\n$$\nH^2(a) = \\frac{8\\pi G}{3}\\left(\\rho_m(a) + \\rho_\\Lambda\\right) - \\frac{k c^2}{a^2}\n$$\nHere, $G$ is the gravitational constant, $\\rho_m(a)$ is the matter density, $\\rho_\\Lambda$ is the constant energy density associated with the cosmological constant, $k$ is the curvature index ($-1$, $0$, $1$ for open, flat, closed geometries), and $c$ is the speed of light.\n\nIt is standard practice to express this equation in terms of dimensionless density parameters, defined as the ratio of an energy density to the critical density $\\rho_{c,0} = 3H_0^2/(8\\pi G)$ at the present day ($a=1$), where $H_0$ is the Hubble constant.\nThe density parameters are:\n- Matter: $\\Omega_{m,0} = \\rho_{m,0}/\\rho_{c,0}$\n- Cosmological Constant: $\\Omega_{\\Lambda,0} = \\rho_\\Lambda/\\rho_{c,0}$\n- Curvature: $\\Omega_{k,0} = -kc^2/(H_0^2 a_0^2)$ where we set $a_0 = 1$.\n\nGiven that $\\rho_m(a) = \\rho_{m,0} a^{-3}$, the Friedmann equation can be rewritten as:\n$$\nH^2(a) = H_0^2 \\left[ \\Omega_{m,0} a^{-3} + \\Omega_{k,0} a^{-2} + \\Omega_{\\Lambda,0} \\right]\n$$\nwhere the parameters satisfy the sum rule $\\Omega_{m,0} + \\Omega_{\\Lambda,0} + \\Omega_{k,0} = 1$. We define the dimensionless Hubble parameter $E(a) = H(a)/H_0$, such that $E(a)^2 = \\Omega_{m,0} a^{-3} + \\Omega_{k,0} a^{-2} + \\Omega_{\\Lambda,0}$.\n\n#### The Linear Growth Equation\nThe evolution of small matter density perturbations, $\\delta(\\mathbf{x}, t) = (\\rho_m(\\mathbf{x}, t) - \\bar{\\rho}_m(t))/\\bar{\\rho}_m(t)$, in an expanding universe is governed by the linearized fluid equations. For a pressureless fluid (dust) on sub-horizon scales, these combine to yield a second-order linear ordinary differential equation for the density contrast $\\delta$:\n$$\n\\ddot{\\delta} + 2H\\dot{\\delta} - 4\\pi G \\bar{\\rho}_m \\delta = 0\n$$\nSince this equation is linear and does not depend on the wavenumber $k$ (in the Newtonian limit), all Fourier modes $\\delta_k$ grow at the same rate. We can therefore separate the time-dependent and spatial parts, $\\delta(\\mathbf{x}, a) = D(a) \\delta_{\\mathrm{init}}(\\mathbf{x})$, where $D(a)$ is the linear growth factor. The growth factor obeys the same ODE:\n$$\n\\ddot{D} + 2H\\dot{D} - 4\\pi G \\bar{\\rho}_m D = 0\n$$\nUsing $\\bar{\\rho}_m(a) = \\bar{\\rho}_{m,0} a^{-3} = \\Omega_{m,0} \\rho_{c,0} a^{-3} = \\Omega_{m,0} \\frac{3H_0^2}{8\\pi G} a^{-3}$, we can rewrite the equation as:\n$$\n\\ddot{D} + 2H\\dot{D} - \\frac{3}{2} H_0^2 \\Omega_{m,0} a^{-3} D = 0\n$$\n\n### 2. Equation for Numerical Integration\nTo solve this ODE numerically, it is convenient to change the independent variable from cosmic time $t$ to the natural logarithm of the scale factor, $x = \\ln a$. The derivatives transform as:\n$$\n\\frac{d}{dt} = \\frac{da}{dt} \\frac{d}{da} = \\dot{a} \\frac{d}{da} = aH \\frac{d}{da} = H \\frac{d}{d(\\ln a)} = H \\frac{d}{dx}\n$$\nSo, $\\dot{D} = H D'$ and $\\ddot{D} = \\dot{H}D' + H(HD')' = \\dot{H}D' + H^2D''$, where primes denote derivatives with respect to $x$. We can show that $\\dot{H} = H H'$.\nSubstituting these into the growth equation gives:\n$$\n(H H' D' + H^2 D'') + 2H(H D') - \\frac{3}{2} H_0^2 \\Omega_{m,0} a^{-3} D = 0\n$$\nDividing by $H^2$:\n$$\nD'' + \\left(2 + \\frac{H'}{H}\\right)D' - \\frac{3}{2} \\frac{H_0^2 \\Omega_{m,0} a^{-3}}{H^2} D = 0\n$$\nThe coefficients can be expressed in terms of the time-dependent density parameters $\\Omega_m(a) = \\frac{\\Omega_{m,0} a^{-3}}{E(a)^2}$, $\\Omega_k(a) = \\frac{\\Omega_{k,0} a^{-2}}{E(a)^2}$, and $\\Omega_\\Lambda(a) = \\frac{\\Omega_{\\Lambda,0}}{E(a)^2}$. The equation simplifies to:\n$$\n\\frac{d^2D}{dx^2} + \\left(1 - \\frac{1}{2}\\Omega_m(a) + \\Omega_\\Lambda(a)\\right)\\frac{dD}{dx} - \\frac{3}{2}\\Omega_m(a) D = 0\n$$\nwhere $a = e^x$. This is a second-order linear homogenous ODE for $D(x)$, which can be solved as an initial value problem.\n\n### 3. Numerical Implementation\n\nTo solve the ODE, we convert it into a system of two first-order equations. Let the state vector be $\\mathbf{y} = [y_1, y_2]^T$, where $y_1 = D$ and $y_2 = dD/dx$. The system is:\n$$\n\\frac{d\\mathbf{y}}{dx} = \n\\begin{pmatrix}\n\\frac{dy_1}{dx} \\\\\n\\frac{dy_2}{dx}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\ny_2 \\\\\n-\\left(1 - \\frac{1}{2}\\Omega_m(a) + \\Omega_\\Lambda(a)\\right)y_2 + \\frac{3}{2}\\Omega_m(a) y_1\n\\end{pmatrix}\n$$\nThe initial conditions are set in the early, matter-dominated universe. At $a_{\\mathrm{init}} = 10^{-4}$, all three specified cosmologies are effectively matter-dominated ($\\Omega_m(a_{\\mathrm{init}}) \\approx 1$). In a matter-dominated universe, the growing mode solution is $D(a) \\propto a$. This implies $D(x) \\propto e^x$, so $dD/dx = D$. The initial conditions are therefore set to $D(a_{\\mathrm{init}}) = a_{\\mathrm{init}}$ and $(dD/d\\ln a)|_{a_{\\mathrm{init}}} = a_{\\mathrm{init}}$. This corresponds to an initial state vector $\\mathbf{y}(x_{\\mathrm{init}}) = [a_{\\mathrm{init}}, a_{\\mathrm{init}}]$ at $x_{\\mathrm{init}} = \\ln(a_{\\mathrm{init}})$.\n\nThe procedure is as follows:\n1.  For each of the three cosmologies (Open, Flat, Closed), define the parameters $\\Omega_{m,0}$ and $\\Omega_{\\Lambda,0}$, with $\\Omega_{k,0} = 1 - \\Omega_{m,0} - \\Omega_{\\Lambda,0}$.\n2.  Set up the system of first-order ODEs as defined above.\n3.  Use a numerical ODE solver (such as a Runge-Kutta method from `scipy.integrate.solve_ivp`) to integrate the system from $x_{\\mathrm{init}} = \\ln(10^{-4})$ up to $x=0$ (present day, $a=1$).\n4.  The solver evaluates the solution $D(a)$ at the scale factors corresponding to the test redshifts $z \\in \\{0, 1, 3, 10\\}$, where $a = 1/(1+z)$.\n5.  With the growth factors $D_{\\mathrm{open}}(z)$, $D_{\\mathrm{flat}}(z)$, and $D_{\\mathrm{closed}}(z)$ computed, calculate the power spectrum amplitude factors $A(z) = D(z)^2$.\n6.  Finally, compute the ratios $A_{\\mathrm{open}}(z)/A_{\\mathrm{flat}}(z)$ and $A_{\\mathrm{closed}}(z)/A_{\\mathrm{flat}}(z)$ for each redshift to quantify the difference in growth history. The results are then formatted as requested.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Computes and compares the linear growth factor D(z) for three different cosmologies.\n    \"\"\"\n    # Define test cases: (name, Omega_m0, Omega_L0)\n    test_cases = [\n        (\"open\", 0.3, 0.0),\n        (\"flat\", 0.3, 0.7),\n        (\"closed\", 0.3, 0.8),\n    ]\n\n    # Redshifts for evaluation\n    test_redshifts = np.array([0.0, 1.0, 3.0, 10.0])\n\n    # Store results D(z) for each model {model_name: array_of_D_values}\n    growth_factors = {}\n\n    # Initial conditions\n    a_init = 1e-4\n    x_init = np.log(a_init)  # ln(a) as the independent variable\n    # Initial state vector [D, dD/dln(a)]\n    y_init = np.array([a_init, a_init])\n\n    # The evaluation points for the ODE solver must be sorted.\n    # We sort redshifts in descending order, so 'a' and 'x=ln(a)' are ascending.\n    z_sorted_indices = np.argsort(test_redshifts)[::-1]\n    z_sorted = test_redshifts[z_sorted_indices]\n    \n    a_eval_sorted = 1.0 / (1.0 + z_sorted)\n    x_eval_sorted = np.log(a_eval_sorted)\n\n    # Integration span from initial time to today (a=1, x=0)\n    x_span = [x_init, 0.0]\n\n    for name, omega_m0, omega_l0 in test_cases:\n        omega_k0 = 1.0 - omega_m0 - omega_l0\n\n        def growth_ode(x, y):\n            \"\"\"\n            Defines the system of ODEs for the growth factor D.\n            State vector y = [D, dD/d(ln a)], independent variable x = ln(a).\n            \"\"\"\n            a = np.exp(x)\n            \n            # Dimensionless Hubble parameter squared, E(a)^2 = H(a)^2 / H0^2\n            e2 = omega_m0 * a**-3 + omega_k0 * a**-2 + omega_l0\n            if e2 <= 0:\n                # Should not be reached for the specified models\n                return np.zeros_like(y)\n            \n            # Density parameters as a function of scale factor 'a'\n            omega_m_a = (omega_m0 * a**-3) / e2\n            omega_l_a = omega_l0 / e2\n            \n            dydx = np.zeros_like(y)\n            dydx[0] = y[1]  # d(D)/dx = dD/dx\n            # d(dD/dx)/dx = -(1-0.5*Om_a+Ol_a)*(dD/dx) + 1.5*Om_a*D\n            dydx[1] = -(1.0 - 0.5 * omega_m_a + omega_l_a) * y[1] + 1.5 * omega_m_a * y[0]\n            \n            return dydx\n\n        # Solve the ODE system\n        sol = solve_ivp(\n            growth_ode,\n            x_span,\n            y_init,\n            t_eval=x_eval_sorted,\n            method='RK45',\n            rtol=1e-9,\n            atol=1e-12\n        )\n\n        # The solution sol.y[0] corresponds to the sorted redshifts 'z_sorted'.\n        # We reorder it to match the original 'test_redshifts' order.\n        d_values_sorted = sol.y[0]\n        d_values = np.empty_like(d_values_sorted)\n        d_values[z_sorted_indices] = d_values_sorted\n        \n        growth_factors[name] = d_values\n\n    # Assemble the final results into the required format\n    output_rows = []\n    for i, z in enumerate(test_redshifts):\n        D_open = growth_factors[\"open\"][i]\n        D_flat = growth_factors[\"flat\"][i]\n        D_closed = growth_factors[\"closed\"][i]\n\n        A_open = D_open**2\n        A_flat = D_flat**2\n        A_closed = D_closed**2\n\n        if A_flat == 0:\n            ratio_open_flat = np.nan\n            ratio_closed_flat = np.nan\n        else:\n            ratio_open_flat = A_open / A_flat\n            ratio_closed_flat = A_closed / A_flat\n            \n        result_row = [\n            z,\n            D_open, D_flat, D_closed,\n            A_open, A_flat, A_closed,\n            ratio_open_flat, ratio_closed_flat\n        ]\n        output_rows.append(result_row)\n\n    # Final print statement must produce a single line in the specified format.\n    # The format f\"[{','.join(map(str, list_of_lists))}]\" correctly\n    # reproduces the string representation of a Python list of lists.\n    print(f\"[{','.join(map(str, output_rows))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A theoretical power spectrum requires its overall amplitude to be calibrated against observations. This normalization is commonly expressed using two different parameters: the primordial amplitude $A_s$, constrained by the Cosmic Microwave Background, and the late-time mass fluctuation $\\sigma_8$, measured from galaxy surveys. This practice focuses on the integral relationship between the matter power spectrum $P(k)$ and the variance of mass fluctuations, $\\sigma_R^2$. You will implement a robust numerical algorithm to translate between $A_s$ and $\\sigma_8$, a fundamental skill for connecting theoretical models with diverse cosmological datasets .",
            "id": "3497194",
            "problem": "You are to write a complete, runnable program that calibrates the normalization of the linear matter power spectrum by relating an amplitude parameter at a pivot wavenumber to the root-mean-square mass fluctuation within spheres of a specified radius. The task is to implement a physically consistent and numerically robust algorithm that, for a fixed cosmological background and a fixed power-spectrum shape, infers the amplitude parameter that yields a target mass fluctuation, while preserving the power-spectrum shape.\n\nUse the following fundamental base and definitions. The linear matter power spectrum is modeled as a separable product of a shape function and a scalar normalization. Let $P(k;A_s)$ denote the matter power spectrum as a function of comoving wavenumber $k$ and an amplitude parameter $A_s$. Define the shape function as\n$$\nS(k) \\equiv \\left(\\frac{k}{k_0}\\right)^{n_s} \\, T^2(k),\n$$\nso that\n$$\nP(k;A_s) = A_s \\, S(k).\n$$\nHere $k$ is measured in units of $h\\,\\mathrm{Mpc}^{-1}$, $A_s$ carries the units of $\\left(\\mathrm{Mpc}/h\\right)^3$, and $k_0$ is a specified pivot (also in $h\\,\\mathrm{Mpc}^{-1}$). The transfer function $T(k)$ is taken to be the cold dark matter transfer function in the Bardeen–Bond–Kaiser–Szalay (BBKS) fitting form with the Sugiyama shape-parameter correction,\n$$\n\\Gamma_{\\mathrm{eff}} = \\Omega_m \\, h \\, \\exp\\!\\left[-\\Omega_b\\left(1+\\frac{\\sqrt{2h}}{\\Omega_m}\\right)\\right],\n\\qquad\nq = \\frac{k}{\\Gamma_{\\mathrm{eff}}},\n$$\n$$\nT(k) = \\frac{\\ln(1+2.34 q)}{2.34 q} \\left[1 + 3.89 q + (16.1 q)^2 + (5.46 q)^3 + (6.71 q)^4 \\right]^{-1/4}.\n$$\nAll trigonometric functions must use angles in radians.\n\nDefine the top-hat window in Fourier space by\n$$\nW(x) = \\frac{3}{x^3}\\left[\\sin x - x \\cos x\\right],\n\\qquad x \\equiv k R,\n$$\nwith $R$ in units of $h^{-1}\\,\\mathrm{Mpc}$. The variance on scale $R$ is\n$$\n\\sigma_R^2(A_s) = \\frac{1}{2\\pi^2}\\int_{0}^{\\infty} k^2 \\, P(k;A_s)\\, W^2(kR)\\, \\mathrm{d}k.\n$$\nSet $R$ to $R_8 \\equiv 8\\,h^{-1}\\,\\mathrm{Mpc}$ and define $\\sigma_8(A_s) \\equiv \\sigma_{R_8}(A_s)$. Under a fixed shape $S(k)$, $P(k;A_s)$ scales linearly with $A_s$, so that $\\sigma_8^2(A_s)$ is proportional to $A_s$.\n\nYour program must do the following.\n\n- Implement a numerically stable evaluation of $W(x)$ that handles the $x \\to 0$ limit by using the small-$x$ series expansion $W(x) = 1 - x^2/10 + \\mathcal{O}(x^4)$ to avoid catastrophic cancellation.\n- Compute $\\sigma_8(A_s)$ by numerically integrating the defining integral on a logarithmically spaced grid in $k$ from $k_{\\min} = 10^{-4}\\,h\\,\\mathrm{Mpc}^{-1}$ to $k_{\\max} = 10^{2}\\,h\\,\\mathrm{Mpc}^{-1}$. The numerical result must be stable to at least four significant digits with respect to grid refinement.\n- Design and implement an iterative multiplicative rescaling algorithm that infers $A_s$ given a target $\\sigma_8^{\\mathrm{(tar)}}$. Starting from an initial guess $A_s^{(0)}$, generate iterates\n$$\nA_s^{(i+1)} = A_s^{(i)} \\left[\\frac{\\sigma_8^{\\mathrm{(tar)}}}{\\sigma_8\\!\\left(A_s^{(i)}\\right)}\\right]^2,\n$$\nand terminate when the relative update in $A_s$ satisfies\n$$\n\\left|\\frac{A_s^{(i+1)} - A_s^{(i)}}{A_s^{(i)}}\\right| < \\varepsilon,\n$$\nwith a specified tolerance $\\varepsilon$, or after a maximum number of iterations. This update preserves the shape $S(k)$ and rescales only the normalization. Return the converged value of $A_s$.\n- Verify that, for a given $A_s$, the program can compute the corresponding $\\sigma_8(A_s)$.\n\nAdopt the following fixed cosmological and model parameters for all test cases: $\\Omega_m = 0.3$, $\\Omega_b = 0.05$, $h = 0.7$, $n_s = 0.965$, $k_0 = 0.05\\,h\\,\\mathrm{Mpc}^{-1}$, $R_8 = 8\\,h^{-1}\\,\\mathrm{Mpc}$. Use a numerical tolerance $\\varepsilon = 10^{-10}$ and a maximum of $N_{\\mathrm{it}} = 50$ iterations. Use a grid with $N_k = 5000$ logarithmically spaced points between $k_{\\min}$ and $k_{\\max}$.\n\nImplement the following test suite. Each test case is a tuple; the first element is a string mode and the remaining elements specify parameters. Your program must execute them in order and aggregate the scalar results.\n\n- Test case $1$: infer $A_s$ from $\\sigma_8^{\\mathrm{(tar)}} = 0.8$ with initial guess $A_s^{(0)} = 2.0\\times 10^{-9}$.\n- Test case $2$: infer $A_s$ from $\\sigma_8^{\\mathrm{(tar)}} = 0.83$ with initial guess $A_s^{(0)} = 2.0\\times 10^{-9}$.\n- Test case $3$: infer $A_s$ from $\\sigma_8^{\\mathrm{(tar)}} = 0.3$ with initial guess $A_s^{(0)} = 2.0\\times 10^{-9}$.\n- Test case $4$: infer $A_s$ from $\\sigma_8^{\\mathrm{(tar)}} = 1.2$ with initial guess $A_s^{(0)} = 1.0\\times 10^{-10}$.\n- Test case $5$: compute $\\sigma_8$ for $A_s = 2.1\\times 10^{-9}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test cases. For the inverse problems (test cases $1$ through $4$), output the inferred $A_s$ in units of $\\left(\\mathrm{Mpc}/h\\right)^3$ as floating-point numbers. For the forward problem (test case $5$), output $\\sigma_8$ as a floating-point number. For example, the output must look like\n$[x_1,x_2,x_3,x_4,x_5]$\nwith no spaces and where each $x_i$ is the corresponding scalar result.",
            "solution": "The problem has been validated and is deemed sound. It is a well-posed, scientifically grounded, and self-contained problem in numerical cosmology. All necessary physical models, parameters, and numerical specifications are provided without ambiguity or contradiction. We may therefore proceed with a solution.\n\nThe core of the problem is to establish a robust numerical mapping between two key parameters of the linear matter power spectrum, $P(k)$: the normalization amplitude $A_s$ at a pivot scale $k_0$, and the root-mean-square (RMS) mass fluctuation $\\sigma_8$ in spheres of radius $R_8 = 8 \\,h^{-1}\\,\\mathrm{Mpc}$. We will first detail the physical model and then describe a numerical strategy to implement both the forward problem (calculating $\\sigma_8$ from $A_s$) and the inverse problem (inferring $A_s$ from a target $\\sigma_8^{\\mathrm{(tar)}}$).\n\nThe linear matter power spectrum is defined as:\n$$\nP(k; A_s) = A_s S(k) = A_s \\left(\\frac{k}{k_0}\\right)^{n_s} T^2(k)\n$$\nwhere $A_s$ is the amplitude in units of $(\\mathrm{Mpc}/h)^3$, $k$ is the comoving wavenumber in $h\\,\\mathrm{Mpc}^{-1}$, $k_0 = 0.05\\,h\\,\\mathrm{Mpc}^{-1}$ is the pivot scale, and $n_s = 0.965$ is the scalar spectral index. The function $T(k)$ is the matter transfer function. The problem specifies the Bardeen–Bond–Kaiser–Szalay (BBKS) form with the Sugiyama correction for the shape parameter $\\Gamma_{\\mathrm{eff}}$:\n$$\n\\Gamma_{\\mathrm{eff}} = \\Omega_m h \\exp\\!\\left[-\\Omega_b\\left(1+\\frac{\\sqrt{2h}}{\\Omega_m}\\right)\\right]\n$$\nWith the cosmological parameters $\\Omega_m = 0.3$, $\\Omega_b = 0.05$, and $h = 0.7$, we can pre-compute $\\Gamma_{\\mathrm{eff}}$. Let $q = k/\\Gamma_{\\mathrm{eff}}$. The transfer function is then:\n$$\nT(k) = \\frac{\\ln(1+2.34 q)}{2.34 q} \\left[1 + 3.89 q + (16.1 q)^2 + (5.46 q)^3 + (6.71 q)^4 \\right]^{-1/4}\n$$\n\nThe variance of mass fluctuations in spheres of radius $R$ is given by the integral:\n$$\n\\sigma_R^2(A_s) = \\frac{1}{2\\pi^2}\\int_{0}^{\\infty} k^2 \\, P(k;A_s)\\, W^2(kR)\\, \\mathrm{d}k\n$$\nwhere $W(x)$ is the Fourier transform of the spherical top-hat window function:\n$$\nW(x) = \\frac{3}{x^3}\\left[\\sin x - x \\cos x\\right]\n$$\nFor this problem, we are interested in $\\sigma_8$, which corresponds to $R = R_8 = 8 \\,h^{-1}\\,\\mathrm{Mpc}$.\n\nThe numerical implementation proceeds in several stages.\n\n1.  **Parameter Pre-computation and Grid Generation**:\n    The shape parameter $\\Gamma_{\\mathrm{eff}}$ depends only on fixed cosmological parameters and is computed once. The wavenumber grid for numerical integration is a set of $N_k = 5000$ points logarithmically spaced from $k_{\\min} = 10^{-4}\\,h\\,\\mathrm{Mpc}^{-1}$ to $k_{\\max} = 10^{2}\\,h\\,\\mathrm{Mpc}^{-1}$. Since the power spectrum shape $S(k)$ is independent of the amplitude $A_s$, we can pre-compute the values of $T(k)$ and subsequently $S(k)$ on this grid for efficiency.\n\n2.  **Numerically Stable Function Evaluation**:\n    Direct evaluation of $W(x)$ for small $x$ (i.e., $x \\to 0$) is subject to catastrophic cancellation, as $\\sin x \\approx x - x^3/6$ and $x\\cos x \\approx x(1-x^2/2) = x - x^3/2$. To ensure stability, we use the Taylor series expansion for small arguments:\n    $$\n    W(x) = 1 - \\frac{x^2}{10} + \\frac{x^4}{280} - \\dots\n    $$\n    A threshold, e.g., $x < 10^{-4}$, is chosen. Below this threshold, the expansion $W(x) \\approx 1 - x^2/10$ is used; otherwise, the full expression is evaluated. Similarly, the term $\\frac{\\ln(1+2.34 q)}{2.34 q}$ in $T(k)$ approaches $1$ as $q \\to 0$. Numerical libraries often provide a function like `log1p(z)` to accurately compute $\\ln(1+z)$ for small $z$, which avoids precision loss.\n\n3.  **Forward Problem: Computing $\\sigma_8$ from $A_s$**:\n    Given an amplitude $A_s$, the full power spectrum is $P(k;A_s) = A_s S(k)$. The variance $\\sigma_8^2$ is then computed by numerically integrating its defining expression. The integral can be expressed as:\n    $$\n    \\sigma_8^2(A_s) = A_s \\left[ \\frac{1}{2\\pi^2}\\int_{k_{\\min}}^{k_{\\max}} k^2 S(k) W^2(kR_8) \\mathrm{d}k \\right]\n    $$\n    The term in the brackets is a constant for a fixed cosmology and power spectrum shape. The integrand, $I(k) = k^2 S(k) W^2(kR_8)$, is evaluated at each point on the $k$-grid. The integral is then computed using the trapezoidal rule, which is suitable for non-uniformly spaced points, as provided by `scipy.integrate.trapezoid`. Finally, $\\sigma_8 = \\sqrt{\\sigma_8^2}$.\n\n4.  **Inverse Problem: Inferring $A_s$ from $\\sigma_8^{\\mathrm{(tar)}}$**:\n    The goal is to find the value of $A_s$ that yields a specified target value $\\sigma_8^{\\mathrm{(tar)}}$. The problem provides an iterative multiplicative rescaling algorithm:\n    $$\n    A_s^{(i+1)} = A_s^{(i)} \\left[\\frac{\\sigma_8^{\\mathrm{(tar)}}}{\\sigma_8\\!\\left(A_s^{(i)}\\right)}\\right]^2\n    $$\n    This algorithm is remarkably efficient. Since $\\sigma_8^2(A_s)$ is directly proportional to $A_s$, we have $\\sigma_8(A_s) = C \\sqrt{A_s}$, where $C$ is a constant determined by the shape $S(k)$ and the integral. Substituting this into the update rule:\n    $$\n    A_s^{(i+1)} = A_s^{(i)} \\left[\\frac{\\sigma_8^{\\mathrm{(tar)}}}{C\\sqrt{A_s^{(i)}}}\\right]^2 = A_s^{(i)} \\frac{(\\sigma_8^{\\mathrm{(tar)}})^2}{C^2 A_s^{(i)}} = \\frac{(\\sigma_8^{\\mathrm{(tar)}})^2}{C^2}\n    $$\n    This result is independent of the iteration number $i$, meaning the algorithm converges to the exact analytical solution in a single step, up to numerical precision. The implementation nonetheless adheres to the specified iterative structure, starting from an initial guess $A_s^{(0)}$ and iterating until the relative change in $A_s$ falls below the tolerance $\\varepsilon = 10^{-10}$ or a maximum of $N_{\\mathrm{it}} = 50$ iterations is reached.\n\nThe overall program is structured to handle the specified test cases. A main solver function encapsulates the logic for both the forward and inverse problems. This function is called for each test case, and the results are aggregated into a list for final output in the specified format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import integrate\n\ndef solve():\n    \"\"\"\n    Solves the problem of calibrating the linear matter power spectrum normalization.\n    \"\"\"\n\n    # --- Fixed Cosmological and Model Parameters ---\n    # These are constant for all test cases as per the problem statement.\n    COSMO_PARAMS = {\n        'Omega_m': 0.3,\n        'Omega_b': 0.05,\n        'h': 0.7,\n        'n_s': 0.965,\n        'k0': 0.05,  # in h/Mpc\n        'R8': 8.0,   # in Mpc/h\n    }\n\n    # --- Numerical Integration and Iteration Parameters ---\n    NUM_PARAMS = {\n        'k_min': 1e-4, # in h/Mpc\n        'k_max': 1e2,  # in h/Mpc\n        'N_k': 5000,\n        'tol': 1e-10,\n        'max_iter': 50,\n    }\n\n    def w_tophat(x):\n        \"\"\"\n        Computes the spherical top-hat window function W(x) in Fourier space.\n        Uses a small-x Taylor expansion to avoid numerical instability.\n        x = k*R\n        \"\"\"\n        # Threshold for switching to Taylor expansion\n        small_x_thold = 1e-4\n        \n        # Condition to use Taylor expansion for small x\n        use_expansion = np.abs(x) < small_x_thold\n        \n        # Initialize result array\n        w = np.zeros_like(x, dtype=float)\n\n        # Full expression for large x\n        # Use np.logical_not to avoid re-evaluating the condition\n        # This handles both scalar and array inputs correctly\n        non_expansion_indices = np.logical_not(use_expansion)\n        x_safe = x[non_expansion_indices]\n        w[non_expansion_indices] = 3.0 * (np.sin(x_safe) - x_safe * np.cos(x_safe)) / (x_safe**3)\n\n        # Small-x expansion: W(x) = 1 - x^2/10 + O(x^4)\n        x_small = x[use_expansion]\n        w[use_expansion] = 1.0 - x_small**2 / 10.0\n        \n        return w\n\n    def bbks_transfer_function(k, gamma_eff):\n        \"\"\"\n        Computes the BBKS transfer function T(k) with Sugiyama correction.\n        k is an array of wavenumbers in h/Mpc.\n        gamma_eff is the shape parameter.\n        \"\"\"\n        q = k / gamma_eff\n        \n        # Use log1p for numerical stability when q is small\n        log_term = np.log1p(2.34 * q) / (2.34 * q)\n        # Handle the q=0 case explicitly, where log_term -> 1\n        log_term[q == 0] = 1.0\n\n        poly_term = (1.0 + 3.89 * q + (16.1 * q)**2 + (5.46 * q)**3 + (6.71 * q)**4)**(-0.25)\n        \n        return log_term * poly_term\n\n    class PowerSpectrumCalculator:\n        \"\"\"\n        A class to pre-compute shape-dependent quantities and calculate sigma8.\n        \"\"\"\n        def __init__(self, cosmo_params, num_params):\n            self.p = cosmo_params\n            self.n = num_params\n            \n            # Pre-compute fixed quantities\n            self._precompute()\n\n        def _precompute(self):\n            \"\"\"Pre-computes k-grid and power spectrum shape.\"\"\"\n            # Effective shape parameter Gamma_eff\n            self.gamma_eff = self.p['Omega_m'] * self.p['h'] * np.exp(\n                -self.p['Omega_b'] * (1 + np.sqrt(2 * self.p['h']) / self.p['Omega_m'])\n            )\n            \n            # Logarithmically spaced wavenumber grid\n            self.k = np.logspace(np.log10(self.n['k_min']), np.log10(self.n['k_max']), self.n['N_k'])\n            \n            # Transfer function T(k)\n            transfer_vals = bbks_transfer_function(self.k, self.gamma_eff)\n            \n            # Power spectrum shape function S(k)\n            self.pk_shape = (self.k / self.p['k0'])**self.p['n_s'] * transfer_vals**2\n\n        def compute_sigma8(self, As):\n            \"\"\"\n            Computes sigma_8 for a given amplitude A_s.\n            \"\"\"\n            # Full power spectrum P(k) = A_s * S(k)\n            pk_full = As * self.pk_shape\n            \n            # Window function values W(k*R8)\n            x = self.k * self.p['R8']\n            window_sq = w_tophat(x)**2\n            \n            # Integrand for sigma_8^2\n            integrand = self.k**2 * pk_full * window_sq / (2 * np.pi**2)\n            \n            # Numerical integration using trapezoidal rule for non-uniform grid\n            sigma8_sq = integrate.trapezoid(integrand, self.k)\n            \n            return np.sqrt(sigma8_sq)\n\n        def infer_As(self, sigma8_target, As_initial):\n            \"\"\"\n            Infers A_s to match a target sigma_8 using an iterative algorithm.\n            \"\"\"\n            As_current = As_initial\n            \n            for _ in range(self.n['max_iter']):\n                sigma8_current = self.compute_sigma8(As_current)\n                \n                # Multiplicative rescaling update rule\n                As_next = As_current * (sigma8_target / sigma8_current)**2\n                \n                # Check for convergence\n                if np.abs((As_next - As_current) / As_current) < self.n['tol']:\n                    return As_next\n                \n                As_current = As_next\n            \n            return As_current # Return the last value if max_iter is reached\n\n    # --- Test Case Execution ---\n    test_cases = [\n        ('infer', {'sigma8_target': 0.8, 'As_initial': 2.0e-9}),\n        ('infer', {'sigma8_target': 0.83, 'As_initial': 2.0e-9}),\n        ('infer', {'sigma8_target': 0.3, 'As_initial': 2.0e-9}),\n        ('infer', {'sigma8_target': 1.2, 'As_initial': 1.0e-10}),\n        ('compute', {'As': 2.1e-9}),\n    ]\n\n    calculator = PowerSpectrumCalculator(COSMO_PARAMS, NUM_PARAMS)\n    results = []\n\n    for mode, params in test_cases:\n        if mode == 'infer':\n            result = calculator.infer_As(**params)\n        elif mode == 'compute':\n            result = calculator.compute_sigma8(**params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Any numerical pipeline, no matter how complex, must be validated to ensure its results are trustworthy. For a tool that calculates the matter power spectrum, this means testing it against simplified cases where the expected output is known analytically. This practice applies the principle of code verification by constructing a benchmark suite based on toy models of the power spectrum. You will develop estimators to recover known input parameters—such as the primordial power-law slope, the period of Baryon Acoustic Oscillations (BAO), and the super-horizon scaling—from analytically defined spectra, a critical skill for producing reliable scientific code .",
            "id": "3497142",
            "problem": "You are tasked with designing and implementing a small, self-contained benchmark suite to validate a newly implemented linear matter power spectrum pipeline in numerical cosmology. The validation must rely only on analytically controlled limits and toy models that capture well-tested features of the linear regime. Your suite will test three distinct aspects: a pure power-law spectrum, an oscillatory Baryon Acoustic Oscillations (BAO) modulation with a known wavenumber period, and the super-horizon scaling limit.\n\nUse the following physical and mathematical bases, which are standard in the field:\n\n- The linear matter power spectrum is defined via the two-point statistics of the density contrast in Fourier space, $$\\langle \\delta(\\mathbf{k}) \\,\\delta^{\\ast}(\\mathbf{k}^{\\prime}) \\rangle = (2\\pi)^3 \\,\\delta_{\\mathrm{D}}(\\mathbf{k}-\\mathbf{k}^{\\prime})\\,P(k)\\,,$$ where $\\delta_{\\mathrm{D}}$ is the Dirac delta distribution and $k \\equiv \\lVert \\mathbf{k} \\rVert$ is the comoving wavenumber.\n- In the linear regime at redshift $z=0$, a widely used representation is $$P(k) = A\\,k^{n_{\\mathrm{s}}}\\,T^2(k)\\,,$$ where $A$ is a positive amplitude, $n_{\\mathrm{s}}$ is the spectral index, and $T(k)$ is the transfer function.\n- To generate controlled benchmarks, use a toy transfer function composed of a smooth “no-wiggle” part and a BAO modulation:\n  - Smooth turnover (no-wiggle) component: $$T_{\\mathrm{nw}}(k;k_{\\mathrm{eq}},\\alpha) = \\left[1+\\left(\\frac{k}{k_{\\mathrm{eq}}}\\right)^2\\right]^{-\\alpha/2}\\,,$$ which satisfies $T_{\\mathrm{nw}}(k)\\to 1$ as $k\\to 0$ and decays for $k\\gg k_{\\mathrm{eq}}$.\n  - BAO modulation component (Baryon Acoustic Oscillations (BAO)): $$M_{\\mathrm{bao}}(k;B,k_{\\mathrm{bao}},k_{\\mathrm{d}})=1 + B\\,\\sin\\!\\left(2\\pi\\,\\frac{k}{k_{\\mathrm{bao}}}\\right)\\,\\exp\\!\\left[-\\left(\\frac{k}{k_{\\mathrm{d}}}\\right)^2\\right]\\,,$$ where $k_{\\mathrm{bao}}$ is the fundamental wavenumber period to be validated, $B$ is a small dimensionless amplitude, and $k_{\\mathrm{d}}$ provides a Gaussian damping envelope.\n  - Compose these as $$T(k) = T_{\\mathrm{nw}}(k;k_{\\mathrm{eq}},\\alpha)\\,M_{\\mathrm{bao}}(k;B,k_{\\mathrm{bao}},k_{\\mathrm{d}})\\,,$$ and then $P(k)=A\\,k^{n_{\\mathrm{s}}}\\,T^2(k)$.\n\nYour program must implement estimators to validate:\n- A power-law slope using linear regression in $\\ln P$ versus $\\ln k$.\n- The BAO period by locating successive local maxima in $P(k)$, refining peak positions by quadratic interpolation, and computing a robust estimate of the period as the median of successive peak spacings.\n- The super-horizon scaling $k\\to 0$, where $T_{\\mathrm{nw}}(k)\\to 1$, by measuring the maximum fractional deviation of $P(k)/(A\\,k^{n_{\\mathrm{s}}})$ from $1$ over a domain of sufficiently small $k$.\n\nUnits:\n- Always interpret $k$ in units of $h\\,\\mathrm{Mpc}^{-1}$ and $P(k)$ in units of $(\\mathrm{Mpc}/h)^3$ throughout.\n- Where the result is a length in wavenumber space (e.g., a BAO period or an error in period), report it in units of $h\\,\\mathrm{Mpc}^{-1}$ as a floating-point number.\n- All angles (phases) are implicit in the sinusoidal term and need not be reported. No angle unit is required.\n- Do not report percentages; any fractional errors must be pure decimals.\n\nImplement the following four test cases precisely as specified. For all uses of the BAO estimator, define the following acceptance rule: if fewer than three successive inter-peak spacings can be computed (i.e., fewer than four distinct peaks are found) or if the relative error in the estimated period exceeds $0.3$ (as a decimal), then declare the BAO period estimate “under-resolved” and return a failure flag for that BAO detection.\n\n- Test 1 (power-law slope consistency):\n  - Parameters: $A = 10^3$, $n_{\\mathrm{s}} = 1.4$, $k_{\\mathrm{eq}} = +\\infty$, $\\alpha$ is irrelevant, $B=0$, $k_{\\mathrm{bao}}$ irrelevant, $k_{\\mathrm{d}}$ irrelevant.\n  - Domain: $k \\in [10^{-3}, 10^{0}]$ sampled at $N=600$ logarithmically spaced points.\n  - Task: Fit a straight line to $(\\ln k, \\ln P)$ and obtain the slope $\\hat{s}$. Declare the test pass if $\\lvert \\hat{s}-n_{\\mathrm{s}}\\rvert \\le \\tau_{\\mathrm{s}}$ with $\\tau_{\\mathrm{s}} = 10^{-3}$. Output a boolean.\n- Test 2 (BAO period recovery in a clean setting):\n  - Parameters: $A = 1$, $n_{\\mathrm{s}} = 0$, $k_{\\mathrm{eq}} = +\\infty$, $\\alpha$ irrelevant, $B=0.05$, $k_{\\mathrm{bao}} = 0.06$, $k_{\\mathrm{d}} = 0.30$.\n  - Domain: $k \\in [10^{-2}, 5\\times 10^{-1}]$ sampled at $N=4000$ linearly spaced points.\n  - Task: Estimate the BAO period $\\widehat{\\Delta k}$ from peak spacings as described above and return the absolute error $\\lvert \\widehat{\\Delta k} - k_{\\mathrm{bao}} \\rvert$ in $h\\,\\mathrm{Mpc}^{-1}$ as a float. If the estimator is under-resolved by the above rule, still return a float but ensure it equals not-a-number is avoided; use a finite numeric surrogate only if you can compute at least one spacing; otherwise, return any finite placeholder (but your implementation should aim to compute multiple spacings here).\n- Test 3 (super-horizon scaling):\n  - Parameters: $A = 2\\times 10^4$, $n_{\\mathrm{s}} = 0.965$, $k_{\\mathrm{eq}} = 0.015$, $\\alpha = 2.0$, $B=0$, $k_{\\mathrm{bao}}$ irrelevant, $k_{\\mathrm{d}}$ irrelevant.\n  - Domain: $k \\in [10^{-4},10^{-2}]$ sampled at $N=600$ logarithmically spaced points.\n  - Task: Compute $$R(k) \\equiv \\frac{P(k)}{A\\,k^{n_{\\mathrm{s}}}}$$ and return the maximum deviation $\\max_{k}\\lvert R(k) - 1\\rvert$ over this domain as a dimensionless float.\n- Test 4 (edge case: too short $k$-range for BAO detection):\n  - Parameters: $A = 1$, $n_{\\mathrm{s}}=0$, $k_{\\mathrm{eq}} = +\\infty$, $\\alpha$ irrelevant, $B=0.05$, $k_{\\mathrm{bao}} = 0.05$, $k_{\\mathrm{d}} = 0.25$.\n  - Domain: $k \\in [10^{-2}, 1.1\\times 10^{-1}]$ sampled at $N=100$ linearly spaced points. This interval contains fewer than three full oscillations.\n  - Task: Run your BAO estimator and return a boolean that is true if and only if the estimator declares the signal under-resolved by the above rule.\n\nAlgorithmic requirements and numerical details:\n- The power-law slope must be estimated by standard least squares on $(\\ln k, \\ln P)$.\n- Local maxima must be identified by sign changes in the discrete derivative or by comparing each sample to its neighbors. Improve the peak location by a quadratic interpolation using three neighboring points to estimate the vertex position. For a uniform grid with spacing $\\Delta k$, if $y_{-1},y_0,y_{+1}$ are the values at $k-\\Delta k, k, k+\\Delta k$, the vertex offset in units of $\\Delta k$ can be taken as $$\\delta = \\frac{1}{2}\\,\\frac{y_{-1}-y_{+1}}{y_{-1}-2y_0+y_{+1}}\\,,$$ and the refined peak position is $k+\\delta\\,\\Delta k$.\n- The robust BAO period estimator must be the median of successive refined-peak separations.\n- For the super-horizon test, ensure that $k$ is sufficiently small and report a supremum norm deviation over the specified domain.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order: $[$result of Test $1$, result of Test $2$, result of Test $3$, result of Test $4]$. The first and last entries must be booleans. The second entry must be a float in $h\\,\\mathrm{Mpc}^{-1}$. The third entry must be a dimensionless float. For example, the printed line should resemble $[True,0.0123,0.0045,False]$ but with the four values that your program actually computes using the parameters above.",
            "solution": "The problem statement is valid. It is scientifically grounded in the principles of modern cosmology, specifically the theory of the linear matter power spectrum. The problem is well-posed, with a clear and mathematically precise definition of the physical model, the required numerical estimators, and the four test cases. All parameters, domains, and tasks are specified without ambiguity or contradiction, and the required computations are feasible. The problem constitutes a standard and meaningful task in computational science: the validation of a numerical pipeline through comparison with analytically controlled benchmarks.\n\nThe solution involves implementing three distinct numerical estimators corresponding to an equal number of validation principles for the linear matter power spectrum, $P(k)$. The overall model for the power spectrum is given by\n$$P(k) = A\\,k^{n_{\\mathrm{s}}}\\,T^2(k)$$\nwhere the transfer function $T(k)$ is a toy model composed of a smooth part and an oscillatory part:\n$$T(k) = T_{\\mathrm{nw}}(k;k_{\\mathrm{eq}},\\alpha)\\,M_{\\mathrm{bao}}(k;B,k_{\\mathrm{bao}},k_{\\mathrm{d}})$$\nwith\n$$T_{\\mathrm{nw}}(k;k_{\\mathrm{eq}},\\alpha) = \\left[1+\\left(\\frac{k}{k_{\\mathrm{eq}}}\\right)^2\\right]^{-\\alpha/2}$$\n$$M_{\\mathrm{bao}}(k;B,k_{\\mathrm{bao}},k_{\\mathrm{d}})=1 + B\\,\\sin\\!\\left(2\\pi\\,\\frac{k}{k_{\\mathrm{bao}}}\\right)\\,\\exp\\!\\left[-\\left(\\frac{k}{k_{\\mathrm{d}}}\\right)^2\\right]$$\nThe implementation will be structured into four distinct test functions, each targeting a specific validation case.\n\n**Test 1: Power-Law Slope Consistency**\nThis test validates the primordial power-law behavior of $P(k)$. The parameters are set such that the transfer function becomes unity: $k_{\\mathrm{eq}} \\to +\\infty$ implies $T_{\\mathrm{nw}}(k) \\to 1$, and $B=0$ implies $M_{\\mathrm{bao}}(k)=1$. Consequently, $T(k)=1$ for all $k$. The power spectrum simplifies to a pure power law:\n$$P(k) = A\\,k^{n_{\\mathrm{s}}}$$\nTaking the natural logarithm of this equation yields a linear relationship:\n$$\\ln P(k) = \\ln A + n_{\\mathrm{s}} \\ln k$$\nThis equation is of the form $y = c + s x$, where $y = \\ln P(k)$, $x = \\ln k$, the intercept is $c = \\ln A$, and the slope is $s = n_{\\mathrm{s}}$. The algorithm generates $P(k)$ for the given parameters ($A=10^3$, $n_{\\mathrm{s}}=1.4$) on a logarithmically spaced grid of $N=600$ points in the range $k \\in [10^{-3}, 10^{0}]\\,h\\,\\mathrm{Mpc}^{-1}$. A linear least-squares regression is performed on the $(\\ln k, \\ln P)$ data points to estimate the slope, $\\hat{s}$. The test passes if the absolute difference between the estimated slope and the true slope is within a specified tolerance, $\\lvert \\hat{s}-n_{\\mathrm{s}}\\rvert \\le \\tau_{\\mathrm{s}} = 10^{-3}$. The function returns a boolean value indicating the outcome.\n\n**Test 2 & 4: Baryon Acoustic Oscillation (BAO) Period Recovery**\nThese tests validate the pipeline's ability to measure a characteristic scale from oscillatory features. Here, $k_{\\mathrm{eq}} \\to +\\infty$ and $n_s=0$, which isolates the BAO component:\n$$P(k) = A\\, (M_{\\mathrm{bao}}(k))^2$$\nThe fundamental period of the oscillations in $k$-space is given by the parameter $k_{\\mathrm{bao}}$. The algorithmic procedure to estimate this period is as follows:\n1.  **Peak Identification**: Local maxima in the discrete $P(k)$ array are identified. A point $P_i$ at wavenumber $k_i$ is considered a peak if it is greater than its immediate neighbors, $P_{i-1}$ and $P_{i+1}$.\n2.  **Peak Refinement**: The discrete peak locations are refined using quadratic interpolation on a three-point stencil $(P_{i-1}, P_i, P_{i+1})$ around each peak. The true vertex of the parabola passing through these points provides a sub-grid estimate of the peak's position. For a uniform grid spacing $\\Delta k$, the correction $\\delta_k$ to the discrete peak position $k_i$ is calculated using the formula provided:\n    $$\\delta_k = \\left(\\frac{1}{2}\\,\\frac{P_{i-1}-P_{i+1}}{P_{i-1}-2P_i+P_{i+1}}\\right) \\Delta k$$\n    The refined peak position is $k_{\\text{refined}} = k_i + \\delta_k$.\n3.  **Period Estimation**: The spacings between successive refined peak positions are calculated. The median of these spacings is taken as the robust estimator for the BAO period, $\\widehat{\\Delta k}$.\n\n**Test 2** uses parameters ($B=0.05, k_{\\mathrm{bao}}=0.06\\,h\\,\\mathrm{Mpc}^{-1}, k_{\\mathrm{d}}=0.30\\,h\\,\\mathrm{Mpc}^{-1}$) and a dense, linearly spaced domain ($k \\in [0.01, 0.5]\\,h\\,\\mathrm{Mpc}^{-1}$, $N=4000$) designed for successful period recovery. The function returns the absolute error $\\lvert\\widehat{\\Delta k} - k_{\\mathrm{bao}}\\rvert$.\n\n**Test 4** is an edge case designed to fail. The domain ($k \\in [0.01, 0.11]\\,h\\,\\mathrm{Mpc}^{-1}$) is intentionally chosen to be too short to contain a sufficient number of oscillations for the given period $k_{\\mathrm{bao}}=0.05\\,h\\,\\mathrm{Mpc}^{-1}$. The test must return a boolean indicating whether the estimator correctly identifies the signal as \"under-resolved\". A signal is declared under-resolved if fewer than three inter-peak spacings are found (i.e., fewer than four peaks) or if the estimated period's relative error, $\\lvert\\widehat{\\Delta k} - k_{\\mathrm{bao}}\\rvert/k_{\\mathrm{bao}}$, exceeds $0.3$.\n\n**Test 3: Super-Horizon Scaling**\nThis test verifies the correct behavior of the power spectrum on very large scales, corresponding to the limit $k \\to 0$. In this limit, the transfer function $T(k)$ should approach $1$. The test uses parameters where the BAO component is switched off ($B=0$), so the behavior is governed by $T_{\\mathrm{nw}}(k)$. The test computes the ratio:\n$$R(k) = \\frac{P(k)}{A\\,k^{n_{\\mathrm{s}}}} = T_{\\mathrm{nw}}^2(k) = \\left[1+\\left(\\frac{k}{k_{\\mathrm{eq}}}\\right)^2\\right]^{-\\alpha}$$\nFor $k \\ll k_{\\mathrm{eq}}$, this ratio should be close to $1$. The test quantifies the deviation from this ideal behavior by computing the maximum absolute difference, $\\max_k \\lvert R(k) - 1\\rvert$, over the specified super-horizon domain $k \\in [10^{-4}, 10^{-2}]\\,h\\,\\mathrm{Mpc}^{-1}$, with parameters $A=2\\times 10^4, n_{\\mathrm{s}} = 0.965, k_{\\mathrm{eq}} = 0.015\\,h\\,\\mathrm{Mpc}^{-1}, \\alpha=2.0$. The function returns this maximum deviation as a float.\n\nThe final program integrates these four tests, executes them in sequence, and prints the collected results in the specified format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_power_spectrum(k, A, n_s, k_eq, alpha, B, k_bao, k_d):\n    \"\"\"\n    Computes the toy model linear matter power spectrum P(k).\n    \"\"\"\n    if np.isinf(k_eq):\n        # Simplification for infinite k_eq (no turnover)\n        T_nw_sq = 1.0\n    else:\n        T_nw = (1.0 + (k / k_eq)**2)**(-alpha / 2.0)\n        T_nw_sq = T_nw**2\n\n    if B == 0:\n        # Simplification for no BAO wiggles\n        T_sq = T_nw_sq\n    else:\n        M_bao = 1.0 + B * np.sin(2.0 * np.pi * k / k_bao) * np.exp(-(k / k_d)**2)\n        T_sq = T_nw_sq * (M_bao**2)\n\n    P_k = A * (k**n_s) * T_sq\n    return P_k\n\ndef estimate_bao_period(k, P_k):\n    \"\"\"\n    Estimates the BAO period from a given power spectrum.\n    \n    This function finds peaks, refines their locations using quadratic interpolation,\n    and returns the calculated spacings and refined peak locations.\n    Assumes k is linearly spaced.\n    \"\"\"\n    # Find peak indices by comparing each point to its neighbours.\n    # We add 1 to the resulting indices because the slice P_k[1:-1] starts at index 1.\n    peak_indices = np.where((P_k[1:-1] > P_k[:-2]) & (P_k[1:-1] > P_k[2:]))[0] + 1\n\n    if len(peak_indices) < 2:\n        return np.array([]), np.array([]) # Not enough peaks for any spacing\n\n    refined_peaks_k = []\n    delta_k = k[1] - k[0] # Grid spacing for linear grid\n\n    for i in peak_indices:\n        # Cannot interpolate if the peak is at the very edge of the array\n        if i == 0 or i == len(P_k) - 1:\n            continue\n\n        y_minus_1, y_0, y_plus_1 = P_k[i-1], P_k[i], P_k[i+1]\n        \n        # Denominator of the quadratic interpolation formula\n        denominator = y_minus_1 - 2.0 * y_0 + y_plus_1\n        \n        # Avoid division by zero if the peak is flat or not quadratic\n        if np.abs(denominator) < 1e-12:\n            refined_k = k[i]\n        else:\n            offset_in_grid_units = 0.5 * (y_minus_1 - y_plus_1) / denominator\n            refined_k = k[i] + offset_in_grid_units * delta_k\n        \n        refined_peaks_k.append(refined_k)\n\n    if len(refined_peaks_k) < 2:\n        return np.array([]), np.array(refined_peaks_k)\n\n    spacings = np.diff(refined_peaks_k)\n    return spacings, np.array(refined_peaks_k)\n\ndef run_test1():\n    \"\"\"Test 1: Power-law slope consistency.\"\"\"\n    A, n_s, k_eq, B = 1000.0, 1.4, np.inf, 0.0\n    k_min, k_max, N = 1e-3, 1.0, 600\n    k = np.logspace(np.log10(k_min), np.log10(k_max), N)\n    \n    P_k = get_power_spectrum(k, A, n_s, k_eq, alpha=0, B=B, k_bao=1, k_d=1)\n    \n    # Perform linear regression on log-log data\n    log_k, log_P = np.log(k), np.log(P_k)\n    slope, _ = np.polyfit(log_k, log_P, 1)\n    \n    tau_s = 1e-3\n    return np.abs(slope - n_s) <= tau_s\n\ndef run_test2():\n    \"\"\"Test 2: BAO period recovery in a clean setting.\"\"\"\n    A, n_s, k_eq = 1.0, 0.0, np.inf\n    B, k_bao, k_d = 0.05, 0.06, 0.30\n    k_min, k_max, N = 1e-2, 5e-1, 4000\n    k = np.linspace(k_min, k_max, N)\n\n    P_k = get_power_spectrum(k, A, n_s, k_eq, alpha=0, B=B, k_bao=k_bao, k_d=k_d)\n    \n    spacings, _ = estimate_bao_period(k, P_k)\n\n    if len(spacings) == 0:\n        # Return a placeholder if no spacings could be computed.\n        # This case is not expected for Test 2's parameters.\n        estimated_period = -1.0\n    else:\n        estimated_period = np.median(spacings)\n\n    return np.abs(estimated_period - k_bao)\n\ndef run_test3():\n    \"\"\"Test 3: Super-horizon scaling.\"\"\"\n    A, n_s, k_eq, alpha, B = 2e4, 0.965, 0.015, 2.0, 0.0\n    k_min, k_max, N = 1e-4, 1e-2, 600\n    k = np.logspace(np.log10(k_min), np.log10(k_max), N)\n\n    P_k = get_power_spectrum(k, A, n_s, k_eq, alpha, B, k_bao=1, k_d=1)\n    \n    R_k = P_k / (A * k**n_s)\n    \n    max_deviation = np.max(np.abs(R_k - 1.0))\n    return max_deviation\n\ndef run_test4():\n    \"\"\"Test 4: Edge case for BAO detection (under-resolved).\"\"\"\n    A, n_s, k_eq = 1.0, 0.0, np.inf\n    B, k_bao, k_d = 0.05, 0.05, 0.25\n    k_min, k_max, N = 1e-2, 1.1e-1, 100\n    k = np.linspace(k_min, k_max, N)\n    \n    P_k = get_power_spectrum(k, A, n_s, k_eq, alpha=0, B=B, k_bao=k_bao, k_d=k_d)\n    \n    spacings, _ = estimate_bao_period(k, P_k)\n\n    # Condition 1: Not enough peaks to compute 3 spacings\n    if len(spacings) < 3:\n        return True\n    \n    # Condition 2: High relative error in the estimated period\n    estimated_period = np.median(spacings)\n    relative_error = np.abs(estimated_period - k_bao) / k_bao\n    if relative_error > 0.3:\n        return True\n\n    return False\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Each test is self-contained with its parameters defined inside.\n    test_cases = [\n        run_test1,\n        run_test2,\n        run_test3,\n        run_test4,\n    ]\n\n    results = []\n    for test_func in test_cases:\n        result = test_func()\n        results.append(result)\n\n    # The final print statement must produce the exact required format.\n    # Python's str() of a boolean is capitalized ('True', 'False'), which is\n    # consistent with the problem's example format `[True, ...]`.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}