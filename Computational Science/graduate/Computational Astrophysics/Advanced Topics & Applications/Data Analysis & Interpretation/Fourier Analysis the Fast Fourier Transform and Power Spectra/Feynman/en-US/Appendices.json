{
    "hands_on_practices": [
        {
            "introduction": "Before analyzing any astrophysical time series, we must first ensure the data has been faithfully captured. The process of converting a continuous, analog signal into a discrete, digital sequence is fraught with potential pitfalls, the most famous of which is aliasing. This exercise  confronts this challenge head-on, first by calculating how out-of-band signals can masquerade as in-band features, and then by designing a practical anti-aliasing filter to prevent such data corruption.",
            "id": "3511698",
            "problem": "An astronomical photometric time series is acquired from a fast optical detector monitoring a variable source. The analog front end feeds an analog-to-digital converter sampling at frequency $f_{s} = 1\\,\\mathrm{kHz}$. Two narrowband contaminant lines are present in the analog domain at $f_{0} = 700\\,\\mathrm{Hz}$ and $f_{1} = 800\\,\\mathrm{Hz}$. The discrete-time power spectrum will be estimated by computing the Discrete Fourier Transform, implemented via the Fast Fourier Transform (FFT), over long contiguous segments to identify line features and broadband noise. Assume the astrophysical signal of interest is confined to $[0,450]\\,\\mathrm{Hz}$.\n\nStarting from the sampling theorem and the definition of the Discrete Fourier Transform, derive the mapping of analog sinusoidal components above the Nyquist frequency onto discrete-time frequencies within the baseband $[0,f_{N}]$, where $f_{N} = f_{s}/2$. Use this to compute the aliased components of $f_{0}$ and $f_{1}$ that appear in the discrete-time power spectrum.\n\nTo suppress these aliased lines at the source, you plan an analog pre-sampling anti-aliasing filter. Choose a low-pass Butterworth prototype. Impose the following design constraints:\n1. The passband gain at $450\\,\\mathrm{Hz}$ must be no worse than $-1\\,\\mathrm{dB}$ relative to DC.\n2. The magnitude attenuation (measured as $20\\log_{10}(|H(f)|)$ in decibels) at both $700\\,\\mathrm{Hz}$ and $800\\,\\mathrm{Hz}$ must be at least $-60\\,\\mathrm{dB}$.\n\nAssuming a monotonic Butterworth response with cutoff frequency $f_{c}$ placed to marginally satisfy the passband constraint at $450\\,\\mathrm{Hz}$, determine, from first principles, the minimal integer filter order $n$ that guarantees the stopband attenuation constraints at $700\\,\\mathrm{Hz}$ and $800\\,\\mathrm{Hz}$ simultaneously. Provide only the minimal integer filter order as your final answer.",
            "solution": "### Part 1: Aliasing of Sinusoidal Components\n\nAn analog sinusoidal signal can be represented as $x_a(t) = A \\cos(2\\pi f_a t + \\phi)$, where $f_a$ is the analog frequency in Hz. When this signal is sampled at a frequency $f_s$, a discrete-time sequence $x[k]$ is generated by evaluating $x_a(t)$ at integer multiples of the sampling period $T_s = 1/f_s$.\n$$ x[k] = x_a(k T_s) = A \\cos(2\\pi f_a k T_s + \\phi) = A \\cos\\left(2\\pi \\frac{f_a}{f_s} k + \\phi\\right) $$\nThe term $\\omega = 2\\pi (f_a/f_s)$ is the normalized discrete-time angular frequency.\n\nThe core principle of aliasing stems from the periodicity of the cosine function. A cosine function is unchanged if its argument is shifted by any integer multiple of $2\\pi$. Therefore, for any integer $m$:\n$$ \\cos\\left(2\\pi \\frac{f_a}{f_s} k + \\phi\\right) = \\cos\\left(\\left(2\\pi \\frac{f_a}{f_s} + 2\\pi m\\right) k + \\phi\\right) = \\cos\\left(2\\pi \\frac{f_a + m f_s}{f_s} k + \\phi\\right) $$\nThis equality shows that an analog frequency $f_a$ produces the exact same discrete-time sequence as any frequency $f_a' = f_a + m f_s$. The Discrete Fourier Transform (DFT) operates on this discrete sequence and cannot distinguish between these frequencies. The DFT typically computes coefficients for frequencies in the baseband interval $[0, f_s/2]$, which is also denoted as $[0, f_N]$, where $f_N = f_s/2$ is the Nyquist frequency. Any analog frequency $f_a$ outside this interval will be \"aliased\" to a frequency within this interval.\n\nThe mapping of an analog frequency $f_a \\ge 0$ to its aliased counterpart $f_{\\text{al}}$ in $[0, f_N]$ can be visualized as a \"folding\" of the frequency axis about integer multiples of $f_N$.\nA frequency $f_a$ in the range $[k f_N, (k+1)f_N]$ for an integer $k \\ge 0$ will be aliased as follows:\n- If $k$ is even (i.e., $k = 2m$), then $f_a \\in [2m f_N, (2m+1) f_N] = [m f_s, m f_s + f_N]$. The aliased frequency is $f_{\\text{al}} = f_a - m f_s$.\n- If $k$ is odd (i.e., $k = 2m+1$), then $f_a \\in [(2m+1) f_N, (2m+2) f_N] = [m f_s + f_N, (m+1) f_s]$. The aliased frequency is $f_{\\text{al}} = (m+1) f_s - f_a$.\n\nGiven data:\nSampling frequency $f_s = 1000\\,\\mathrm{Hz}$.\nNyquist frequency $f_N = f_s/2 = 500\\,\\mathrm{Hz}$.\nContaminant line frequencies $f_0 = 700\\,\\mathrm{Hz}$ and $f_1 = 800\\,\\mathrm{Hz}$.\n\nFor $f_0 = 700\\,\\mathrm{Hz}$:\nThis frequency lies in the interval $[500\\,\\mathrm{Hz}, 1000\\,\\mathrm{Hz}]$, which corresponds to $[1 \\cdot f_N, 2 \\cdot f_N]$. Here, $k=1$, which is odd (with $m=0$). The aliased frequency $f_{\\text{al},0}$ is:\n$$ f_{\\text{al},0} = (0+1) f_s - f_0 = f_s - f_0 = 1000 - 700 = 300\\,\\mathrm{Hz} $$\n\nFor $f_1 = 800\\,\\mathrm{Hz}$:\nThis frequency also lies in the interval $[500\\,\\mathrm{Hz}, 1000\\,\\mathrm{Hz}]$, so $k=1$ (odd, with $m=0$). The aliased frequency $f_{\\text{al},1}$ is:\n$$ f_{\\text{al},1} = (0+1) f_s - f_1 = f_s - f_1 = 1000 - 800 = 200\\,\\mathrm{Hz} $$\nThe aliased components appear at $200\\,\\mathrm{Hz}$ and $300\\,\\mathrm{Hz}$, both of which fall within the astrophysical signal's band of interest, $[0, 450]\\,\\mathrm{Hz}$, corrupting the data.\n\n### Part 2: Butterworth Anti-Aliasing Filter Design\n\nThe magnitude squared response of an $n$-th order low-pass Butterworth filter with cutoff frequency $f_c$ is given by:\n$$ |H(f)|^2 = \\frac{1}{1 + \\left(\\frac{f}{f_c}\\right)^{2n}} $$\nThe attenuation in decibels (dB) is defined as $A_{\\mathrm{dB}}(f) = 20 \\log_{10}(|H(f)|) = 10 \\log_{10}(|H(f)|^2)$.\n$$ A_{\\mathrm{dB}}(f) = 10 \\log_{10}\\left(\\frac{1}{1 + \\left(\\frac{f}{f_c}\\right)^{2n}}\\right) = -10 \\log_{10}\\left(1 + \\left(\\frac{f}{f_c}\\right)^{2n}\\right) $$\n\nThe design constraints are:\n1.  Passband: At $f_p = 450\\,\\mathrm{Hz}$, the gain must be no worse than $-1\\,\\mathrm{dB}$.\n2.  Stopband: At $f_{s0} = 700\\,\\mathrm{Hz}$ and $f_{s1} = 800\\,\\mathrm{Hz}$, the gain must be at most $-60\\,\\mathrm{dB}$.\n\nFirst, we determine the relationship between $f_c$ and $n$ from the passband constraint. To \"marginally satisfy\" this constraint, we set the gain at $f_p$ to exactly $-1\\,\\mathrm{dB}$.\n$$ -1 = -10 \\log_{10}\\left(1 + \\left(\\frac{f_p}{f_c}\\right)^{2n}\\right) $$\n$$ 0.1 = \\log_{10}\\left(1 + \\left(\\frac{f_p}{f_c}\\right)^{2n}\\right) $$\n$$ 10^{0.1} = 1 + \\left(\\frac{f_p}{f_c}\\right)^{2n} $$\n$$ \\left(\\frac{f_p}{f_c}\\right)^{2n} = 10^{0.1} - 1 \\quad (*)$$\n\nNext, we apply the stopband constraint. The Butterworth filter has a monotonically decreasing magnitude response. Therefore, the constraint at the lower frequency ($f_{s0}=700\\,\\mathrm{Hz}$) is the more stringent one. If it is satisfied, the constraint at $f_{s1}=800\\,\\mathrm{Hz}$ will be automatically satisfied. We set the constraint at $f_s=700\\,\\mathrm{Hz}$:\n$$ A_{\\mathrm{dB}}(f_s) \\le -60\\,\\mathrm{dB} $$\n$$ -10 \\log_{10}\\left(1 + \\left(\\frac{f_s}{f_c}\\right)^{2n}\\right) \\le -60 $$\n$$ \\log_{10}\\left(1 + \\left(\\frac{f_s}{f_c}\\right)^{2n}\\right) \\ge 6 $$\n$$ 1 + \\left(\\frac{f_s}{f_c}\\right)^{2n} \\ge 10^6 $$\n$$ \\left(\\frac{f_s}{f_c}\\right)^{2n} \\ge 10^6 - 1 \\quad (**)$$\n\nTo solve for the filter order $n$, we can eliminate the unknown cutoff frequency $f_c$ by dividing the stopband inequality $(**)$ by the passband equality $(*)$:\n$$ \\frac{\\left(\\frac{f_s}{f_c}\\right)^{2n}}{\\left(\\frac{f_p}{f_c}\\right)^{2n}} \\ge \\frac{10^6 - 1}{10^{0.1} - 1} $$\n$$ \\left(\\frac{f_s}{f_p}\\right)^{2n} \\ge \\frac{10^6 - 1}{10^{0.1} - 1} $$\nTaking the base-10 logarithm of both sides:\n$$ 2n \\log_{10}\\left(\\frac{f_s}{f_p}\\right) \\ge \\log_{10}\\left(\\frac{10^6 - 1}{10^{0.1} - 1}\\right) $$\nSince $f_s > f_p$, $\\log_{10}(f_s/f_p) > 0$, so the inequality direction is preserved when we solve for $n$:\n$$ n \\ge \\frac{\\log_{10}\\left(\\frac{10^6 - 1}{10^{0.1} - 1}\\right)}{2 \\log_{10}\\left(\\frac{f_s}{f_p}\\right)} $$\nNow, we substitute the given frequency values $f_p=450\\,\\mathrm{Hz}$ and $f_s=700\\,\\mathrm{Hz}$:\n$$ n \\ge \\frac{\\log_{10}\\left(\\frac{10^6 - 1}{10^{0.1} - 1}\\right)}{2 \\log_{10}\\left(\\frac{700}{450}\\right)} = \\frac{\\log_{10}\\left(\\frac{999999}{10^{0.1} - 1}\\right)}{2 \\log_{10}\\left(\\frac{14}{9}\\right)} $$\nEvaluating the numerical values:\n$$ n \\ge \\frac{\\log_{10}\\left(\\frac{999999}{0.258925...}\\right)}{2 \\log_{10}(1.5555...)} \\approx \\frac{\\log_{10}(3862086.1)}{2 \\times 0.19183} \\approx \\frac{6.5868}{0.38367} \\approx 17.168 $$\nSince the filter order $n$ must be an integer, we must choose the smallest integer that satisfies this inequality.\n$$ n_{\\min} = \\lceil 17.168 \\rceil = 18 $$\nThe minimal integer filter order required is $18$.",
            "answer": "$$\n\\boxed{18}\n$$"
        },
        {
            "introduction": "Once a signal is correctly sampled, the Fast Fourier Transform provides its frequency components, but these raw numbers are not yet a Power Spectral Density (PSD). To transform them into a physically meaningful quantity that represents power or variance per unit frequency, we must apply the correct normalization. This foundational practice  uses dimensional analysis to derive the units of a PSD and clarifies the crucial scaling factor needed to convert a two-sided spectrum into a one-sided one, ensuring the total variance is conserved.",
            "id": "3511736",
            "problem": "A uniformly sampled time series $x(t)$ of radio flux density from a compact source is recorded at sampling interval $\\Delta t$ (in $\\mathrm{s}$), producing $N$ samples over total duration $T = N \\Delta t$. The observable $x(t)$ is measured in Jansky $\\mathrm{Jy}$, where $\\mathrm{Jy}$ denotes a flux density unit and should be treated as a base unit symbol for dimensional analysis in this problem. Assume $x(t)$ is real-valued and wide-sense stationary with finite variance.\n\nLet $X(f)$ denote the continuous-time Fourier transform of $x(t)$ under the convention $X(f) = \\int_{-\\infty}^{\\infty} x(t)\\,\\exp(-2\\pi i f t)\\,dt$, and let $S_{x}(f)$ denote the power spectral density (PSD) with respect to the temporal frequency $f$ (in $\\mathrm{Hz}$), understood as the variance-per-unit-frequency density such that integrating $S_{x}(f)$ over a frequency band yields the contribution of that band to the variance of $x(t)$.\n\nStarting from first principles and well-tested formulas, and without invoking any pre-provided PSD shortcuts, do the following:\n\n1. Using dimensional analysis and the definition that integrating $S_{x}(f)$ over $f$ yields the variance of $x(t)$, derive the correct unit form of $S_{x}(f)$ in terms of powers of $\\mathrm{Jy}$ and $\\mathrm{s}$, taking care not to conflate the electromagnetic-frequency content implicit in $\\mathrm{Jy}$ with the temporal frequency $f$ used by the Fourier transform.\n\n2. For a real-valued $x(t)$, the discrete Fourier transform computed via the Fast Fourier Transform (FFT) yields a two-sided spectrum with equal power at $+f$ and $-f$. Construct a one-sided PSD defined only for $f \\ge 0$ that preserves the total variance when integrated over frequency. Justify the scaling factor to apply to the strictly positive frequency bins, and explain the treatment of the $f = 0$ (direct current) component and, when applicable for even $N$, the Nyquist frequency $f_{\\mathrm{N}} = \\frac{1}{2\\Delta t}$.\n\nProvide your final result as a row matrix containing three entries: the one-sided scaling factor $c$, the exponent $a$ such that the PSD unit is $\\mathrm{Jy}^{a}$ in power, and the exponent $b$ such that the PSD unit is $\\mathrm{s}^{b}$ in time. Your final answer must be of the form $\\begin{pmatrix} c & a & b \\end{pmatrix}$. Do not round; exact integers are expected.",
            "solution": "The problem requires the determination of three quantities derived from the principles of power spectral density (PSD) analysis: the exponents $a$ and $b$ describing the units of the PSD $S_{x}(f)$ in the form $\\mathrm{Jy}^{a}\\,\\mathrm{s}^{b}$, and the scaling factor $c$ used to construct a one-sided PSD from a two-sided one.\n\nFirst, we will determine the units of the PSD, $S_{x}(f)$, which will yield the exponents $a$ and $b$. The problem defines $S_{x}(f)$ as the variance-per-unit-frequency density such that its integral over frequency yields the variance of the time series $x(t)$. This can be written as:\n$$\n\\mathrm{Var}(x(t)) = \\int_{-\\infty}^{\\infty} S_{x}(f) \\, df\n$$\nLet $[Y]$ denote the physical units of a quantity $Y$. The time series $x(t)$ represents a radio flux density, and its values are measured in Janskys ($\\mathrm{Jy}$). The variance of $x(t)$, denoted $\\mathrm{Var}(x(t))$, is the expectation of the squared deviation from the mean, $\\mathrm{E}\\left[(x(t) - \\mu_x)^2\\right]$. As such, its units are the square of the units of $x(t)$.\n$$\n[\\mathrm{Var}(x(t))] = [x(t)]^2 = \\mathrm{Jy}^2\n$$\nThe variable of integration is the temporal frequency $f$, which is measured in Hertz ($\\mathrm{Hz}$). One Hertz is one cycle per second, so its unit is inverse seconds, $\\mathrm{s}^{-1}$. The differential element $df$ therefore carries the same units as $f$.\n$$\n[df] = [f] = \\mathrm{Hz} = \\mathrm{s}^{-1}\n$$\nFor the integral equation to be dimensionally consistent, the units of the left-hand side must equal the units of the right-hand side. The units of the integral are the product of the units of the integrand and the units of the variable of integration.\n$$\n[\\mathrm{Var}(x(t))] = [S_{x}(f)] \\cdot [f]\n$$\nSubstituting the known units, we have:\n$$\n\\mathrm{Jy}^2 = [S_{x}(f)] \\cdot \\mathrm{s}^{-1}\n$$\nSolving for the units of $S_{x}(f)$, we find:\n$$\n[S_{x}(f)] = \\frac{\\mathrm{Jy}^2}{\\mathrm{s}^{-1}} = \\mathrm{Jy}^2 \\cdot \\mathrm{s}^1\n$$\nThe problem specifies the unit form as $\\mathrm{Jy}^{a}\\,\\mathrm{s}^{b}$. By comparing this form with our derived result, we identify the exponents:\n$$\na = 2\n$$\n$$\nb = 1\n$$\n\nNext, we derive the scaling factor $c$ required to construct a one-sided PSD from a two-sided PSD for a real-valued signal. The given time series $x(t)$ is real-valued. A fundamental property of the Fourier transform is that for any real function, its transform $X(f)$ exhibits Hermitian symmetry: $X(-f) = X^*(f)$, where the asterisk denotes the complex conjugate. The two-sided PSD, $S_{x}(f)$, is proportional to $|X(f)|^2$. From the Hermitian property, it follows that $|X(-f)|^2 = |X^*(f)|^2 = |X(f)|^2$. This implies that the two-sided PSD of a real signal is an even function of frequency:\n$$\nS_{x}(-f) = S_{x}(f)\n$$\nThe total variance, $V$, is the integral of $S_{x}(f)$ over all frequencies. We can split this integral into negative and positive frequency domains:\n$$\nV = \\int_{-\\infty}^{\\infty} S_{x}(f) \\, df = \\int_{-\\infty}^{0} S_{x}(f) \\, df + \\int_{0}^{\\infty} S_{x}(f) \\, df\n$$\nIn the first integral, we perform a change of variables $u = -f$, which means $du = -df$. The integration limits transform from $(-\\infty, 0)$ to $(\\infty, 0)$.\n$$\n\\int_{-\\infty}^{0} S_{x}(f) \\, df = \\int_{\\infty}^{0} S_{x}(-u) \\, (-du) = \\int_{0}^{\\infty} S_{x}(-u) \\, du\n$$\nBecause $S_{x}(f)$ is an even function, $S_{x}(-u) = S_{x}(u)$. Therefore, the integral over negative frequencies is equal to the integral over positive frequencies.\n$$\n\\int_{-\\infty}^{0} S_{x}(f) \\, df = \\int_{0}^{\\infty} S_{x}(f) \\, df\n$$\nSubstituting this back into the expression for the total variance gives:\n$$\nV = \\int_{0}^{\\infty} S_{x}(f) \\, df + \\int_{0}^{\\infty} S_{x}(f) \\, df = 2 \\int_{0}^{\\infty} S_{x}(f) \\, df\n$$\nThis result, which treats the point $f=0$ as having zero measure in the continuous integral, demonstrates that the positive frequencies contain exactly half of the total variance.\n\nA one-sided PSD, let's call it $S_{1s}(f)$, is defined only for non-negative frequencies ($f \\ge 0$) and is constructed such that its integral over this domain equals the total variance $V$.\n$$\nV = \\int_{0}^{\\infty} S_{1s}(f) \\, df\n$$\nBy equating the two expressions for $V$, we get:\n$$\n\\int_{0}^{\\infty} S_{1s}(f) \\, df = 2 \\int_{0}^{\\infty} S_{x}(f) \\, df\n$$\nFor this equality to hold, the relationship between the integrands for strictly positive frequencies ($f > 0$) must be:\n$$\nS_{1s}(f) = 2 S_{x}(f)\n$$\nThis means that to convert from a two-sided PSD to a one-sided PSD while preserving the total variance, the amplitude of the PSD at strictly positive frequencies must be multiplied by a factor of 2. The problem defines $c$ as this scaling factor. Therefore:\n$$\nc = 2\n$$\nIt is worth noting that for a discrete spectrum obtained via an FFT, this scaling factor of 2 applies to the frequency bins between DC ($f=0$) and the Nyquist frequency $f_{\\mathrm{N}}$. The DC and Nyquist frequency components are unique (they do not have distinct negative-frequency counterparts) and are therefore not scaled by this factor. The question specifically asks for the factor for \"strictly positive frequency bins,\" which is unambiguously 2.\n\nIn summary, the determined values are $c=2$, $a=2$, and $b=1$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2 & 2 & 1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The final step is to translate theoretical knowledge into a robust computational tool. This exercise  is a practical challenge to implement a variance-conserving PSD estimator from scratch, applying the principles of correct normalization and one-sided spectral scaling. By testing your implementation against a suite of synthetic signals, including those with noise and edge-case frequencies, you will verify that your code adheres to Parseval's theorem and produces a reliable power spectrum.",
            "id": "3511734",
            "problem": "You are given the task of implementing a variance-conserving one-sided power spectral density estimator for a uniformly sampled real-valued photometric time series, using the real Fast Fourier Transform (rFFT). Let the time series be denoted by $x[n]$ for $n \\in \\{0,1,\\dots,N-1\\}$, sampled at a constant interval $\\Delta t > 0$. You must construct a one-sided power spectral density (PSD) estimate $\\widehat{S}(f_k)$ defined on the nonnegative discrete Fourier frequency grid $f_k$, such that the following variance conservation condition holds to within numerical precision:\n$$\n\\frac{1}{N} \\sum_{n=0}^{N-1} \\left(x[n] - \\overline{x}\\right)^2 \\approx \\sum_{k} \\widehat{S}(f_k)\\,\\Delta f,\n$$\nwhere $\\overline{x}$ is the sample mean of $x[n]$, and $\\Delta f = \\frac{1}{N \\Delta t}$ is the discrete frequency spacing. The estimate $\\widehat{S}(f_k)$ must be computed using the real-valued Fast Fourier Transform (rFFT) in a manner that correctly accounts for the mapping from the two-sided spectrum to the one-sided spectrum for real signals, preserving the total variance (i.e., the left-hand side above), for both even and odd $N$. You must start from the standard definition of the Discrete Fourier Transform $X[k] = \\sum_{n=0}^{N-1} x[n]\\,e^{-2\\pi i n k/N}$ and the discrete Parseval relation $\\sum_{n=0}^{N-1} |x[n]|^2 = \\frac{1}{N} \\sum_{k=0}^{N-1} |X[k]|^2$, and derive a scaling for $\\widehat{S}(f_k)$ that is expressed on the one-sided frequency grid returned by the rFFT. Your implementation must explicitly subtract the sample mean before spectral estimation. Angles used inside trigonometric functions must be taken in radians.\n\nYour program must implement the following function internally and use it to evaluate the test suite below:\n- rFFT-based PSD estimator: Given an input array $x[n]$ and sampling interval $\\Delta t$, return the arrays $(f_k, \\widehat{S}(f_k))$ defined on the one-sided frequency grid such that the variance conservation condition above holds for arbitrary real inputs $x[n]$ (including cases with and without the Nyquist frequency present).\n\nTest suite specification (generate each synthetic time series deterministically using the specified parameters and the stated pseudo-random seed for the Gaussian components):\n- All signals are generated as $x[n] = C + \\sum_j A_j \\cos\\!\\left(2\\pi f_j t_n + \\phi_j\\right) + \\eta[n]$, where $t_n = n \\Delta t$, and $\\eta[n]$ is a zero-mean Gaussian process with standard deviation $\\sigma$ and a fixed pseudo-random seed applied per the case below. Unless otherwise stated, use phases $\\phi_j = 0$. The final PSD computation must be performed on the mean-subtracted series $x[n] - \\overline{x}$.\n- Case $1$ (happy path, even $N$, bin-centered sinusoid with noise and offset): $N = 4096$, $\\Delta t = 2.0$, one sinusoid with $A_1 = 1.8$ at $f_1 = \\frac{32}{N \\Delta t}$, Gaussian noise with $\\sigma = 0.7$, constant offset $C = 10.0$, and pseudo-random seed $123456$.\n- Case $2$ (odd $N$, multiple non-bin-centered sinusoids, noise and offset): $N = 4095$, $\\Delta t = 1.0$, two sinusoids with $(A_1, f_1) = (0.9, 0.01)$ and $(A_2, f_2) = (0.5, 0.1234)$, Gaussian noise with $\\sigma = 0.3$, constant offset $C = 0.2$, and pseudo-random seed $789012$.\n- Case $3$ (even $N$, pure Nyquist sinusoid, no noise): $N = 2048$, $\\Delta t = 0.5$, one sinusoid with $A_1 = 2.0$ at $f_1 = \\frac{1}{2 \\Delta t}$, no Gaussian noise $\\sigma = 0$, and $C = 0$.\n- Case $4$ (even $N$, pure white noise): $N = 3000$, $\\Delta t = 1.0$, no sinusoid, Gaussian noise with $\\sigma = 1.0$, $C = 0$, and pseudo-random seed $246810$.\n\nFor each case, compute the relative variance error\n$$\n\\epsilon = \\frac{\\left| \\frac{1}{N} \\sum_{n=0}^{N-1} \\left(x[n] - \\overline{x}\\right)^2 - \\sum_k \\widehat{S}(f_k)\\,\\Delta f \\right|}{\\frac{1}{N} \\sum_{n=0}^{N-1} \\left(x[n] - \\overline{x}\\right)^2},\n$$\nwhich is dimensionless. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of cases $1$ through $4$, i.e., the output must be exactly of the form \"[e1,e2,e3,e4]\" where $e1$, $e2$, $e3$, and $e4$ are the four floating-point values of $\\epsilon$ for the four cases, respectively. No physical units are required in the output since $\\epsilon$ is dimensionless. The results will be assessed for numerical correctness and robustness across the specified edge cases, including the presence or absence of the Nyquist frequency and odd versus even $N$.",
            "solution": "The core task is to derive a normalization for a one-sided Power Spectral Density (PSD) estimate, $\\widehat{S}(f_k)$, for a real-valued time series $x[n]$ sampled over $n \\in \\{0, 1, \\dots, N-1\\}$ with a constant sampling interval $\\Delta t > 0$. This normalization must satisfy the variance conservation condition:\n$$\n\\frac{1}{N} \\sum_{n=0}^{N-1} \\left(x[n] - \\overline{x}\\right)^2 \\approx \\sum_{k} \\widehat{S}(f_k)\\,\\Delta f\n$$\nwhere $\\overline{x}$ is the sample mean of the time series, $\\Delta f = 1/(N \\Delta t)$ is the discrete frequency resolution, and the sum over $k$ spans the non-negative frequencies of the one-sided spectrum.\n\nOur derivation begins with the mean-subtracted signal, $y[n] = x[n] - \\overline{x}$. The left-hand side of the conservation equation is the sample variance of $x[n]$, which is equivalent to the mean-squared value of $y[n]$:\n$$\n\\text{Var}(x) = \\frac{1}{N} \\sum_{n=0}^{N-1} y[n]^2 = \\frac{1}{N} \\sum_{n=0}^{N-1} |y[n]|^2\n$$\nThe problem specifies the Discrete Fourier Transform (DFT) of a signal $y[n]$ as $Y[k] = \\sum_{n=0}^{N-1} y[n] e^{-2\\pi i n k / N}$, and provides the discrete Parseval's theorem:\n$$\n\\sum_{n=0}^{N-1} |y[n]|^2 = \\frac{1}{N} \\sum_{k=0}^{N-1} |Y[k]|^2\n$$\nBy substituting Parseval's theorem into the expression for the variance, we connect the time-domain variance to the two-sided periodogram $|Y[k]|^2$:\n$$\n\\text{Var}(x) = \\frac{1}{N} \\left( \\frac{1}{N} \\sum_{k=0}^{N-1} |Y[k]|^2 \\right) = \\frac{1}{N^2} \\sum_{k=0}^{N-1} |Y[k]|^2\n$$\nThis sum spans the full two-sided spectrum, with frequency indices $k \\in \\{0, 1, \\dots, N-1\\}$. For a real-valued signal $y[n]$, its DFT $Y[k]$ possesses Hermitian symmetry, $Y[k] = Y^*[N-k]$, which implies $|Y[k]|^2 = |Y[N-k]|^2$. This property allows us to \"fold\" the spectrum from two-sided to one-sided. The components at $k=0$ (DC frequency) and, if $N$ is even, $k=N/2$ (Nyquist frequency) are purely real and do not have a separate conjugate pair.\n\nWe can rewrite the sum over the two-sided spectrum by considering contributions from non-negative frequencies only:\n- If $N$ is even, the one-sided frequency indices are $k \\in \\{0, 1, \\dots, N/2\\}$. The sum becomes:\n$$\n\\sum_{k=0}^{N-1} |Y[k]|^2 = |Y[0]|^2 + 2\\sum_{k=1}^{N/2-1} |Y[k]|^2 + |Y[N/2]|^2\n$$\n- If $N$ is odd, let $M=(N-1)/2$. The one-sided indices are $k \\in \\{0, 1, \\dots, M\\}$. The sum becomes:\n$$\n\\sum_{k=0}^{N-1} |Y[k]|^2 = |Y[0]|^2 + 2\\sum_{k=1}^{M} |Y[k]|^2\n$$\nNote that since we use the mean-subtracted signal $y[n]$, its DC component $Y[0] = \\sum_{n=0}^{N-1} y[n]$ is zero by definition, so $|Y[0]|^2 = 0$.\n\nThe one-sided PSD, $\\widehat{S}(f_k)$, must be defined such that $\\text{Var}(x) = \\sum_{k} \\widehat{S}(f_k) \\Delta f$. Using our previous results, this implies:\n$$\n\\sum_{k} \\widehat{S}(f_k) \\Delta f = \\frac{1}{N^2} \\sum_{k=0}^{N-1} |Y[k]|^2 \\implies \\sum_{k} \\widehat{S}(f_k) = \\frac{\\Delta t}{N} \\sum_{k=0}^{N-1} |Y[k]|^2\n$$\nBy matching terms with the folded sums, we arrive at the definition of the one-sided PSD. Let $Y_r[k]$ be the DFT coefficients for non-negative frequencies, as returned by a real FFT algorithm.\n$$\n\\widehat{S}(f_k) =\n\\begin{cases}\n    \\frac{\\Delta t}{N} |Y_r[k]|^2 & \\text{for } k=0 \\text{ (DC) and, if } N \\text{ is even, } k=N/2 \\text{ (Nyquist)} \\\\\n    2 \\frac{\\Delta t}{N} |Y_r[k]|^2 & \\text{for all other non-negative frequency indices } k\n\\end{cases}\n$$\nThe factor of $2$ accounts for the power folded in from the negative frequency side of the spectrum. The DC and Nyquist frequencies do not have distinct negative-frequency counterparts and thus are not doubled. This definition ensures that the integral of the PSD over the one-sided frequency domain, $\\sum_k \\widehat{S}(f_k) \\Delta f$, correctly recovers the total variance of the original signal.\n\nThe algorithmic procedure is as follows:\n$1$. Given the time series $x[n]$ and sampling interval $\\Delta t$, compute the mean $\\overline{x}$ and form the mean-subtracted series $y[n] = x[n] - \\overline{x}$.\n$2$. Compute the one-sided DFT, $Y_r[k]$, of $y[n]$ using a real Fast Fourier Transform (rFFT) algorithm.\n$3$. Compute the one-sided frequency grid $f_k = k/(N \\Delta t)$ corresponding to the output of the rFFT.\n$4$. Calculate the raw power values $|Y_r[k]|^2$.\n$5$. Scale these power values to obtain the final PSD, $\\widehat{S}(f_k)$:\n   a. Apply a base scaling factor of $\\Delta t/N$ to all power values.\n   b. Apply an additional multiplication factor of $2$ to all values except for the first (DC, $k=0$) and, if $N$ is even, the last (Nyquist, $k=N/2$).\nThe resulting arrays, $f_k$ and $\\widehat{S}(f_k)$, constitute the required variance-conserving one-sided PSD estimate.\n\n```python\nimport numpy as np\n\ndef generate_signal(N, dt, C, sinusoids, sigma, seed):\n    \"\"\"\n    Generates a synthetic time series based on the problem specification.\n\n    Args:\n        N (int): Number of samples.\n        dt (float): Sampling interval.\n        C (float): Constant offset (DC component).\n        sinusoids (list): List of tuples (Amplitude, frequency, phase) for sinusoids.\n        sigma (float): Standard deviation of Gaussian noise.\n        seed (int or None): Seed for the pseudo-random number generator.\n\n    Returns:\n        np.ndarray: The generated time series x[n].\n    \"\"\"\n    if seed is not None:\n        rng = np.random.default_rng(seed)\n    \n    t = np.arange(N, dtype=np.float64) * dt\n    x = np.full(N, C, dtype=np.float64)\n    \n    for A, f, phi in sinusoids:\n        x += A * np.cos(2 * np.pi * f * t + phi)\n    \n    if sigma > 0:\n        noise = rng.normal(loc=0.0, scale=sigma, size=N)\n        x += noise\n        \n    return x\n\ndef compute_variance_conserving_psd(x, dt):\n    \"\"\"\n    Implements the rFFT-based variance-conserving one-sided PSD estimator.\n\n    Args:\n        x (np.ndarray): The input real-valued time series.\n        dt (float): The sampling interval.\n        \n    Returns:\n        tuple[np.ndarray, np.ndarray]: A tuple containing the frequency grid (f_k)\n        and the PSD estimate (S_hat_k).\n    \"\"\"\n    N = len(x)\n    # 1. Mean-subtract the signal as required by the variance conservation condition.\n    y = x - np.mean(x)\n    \n    # 2. Compute the one-sided DFT using the real FFT.\n    Y_r = np.fft.rfft(y)\n    \n    # 3. Compute the corresponding one-sided frequency grid.\n    f_k = np.fft.rfftfreq(N, d=dt)\n    \n    # 4. Calculate the raw power values from the DFT coefficients.\n    P_Y_r = np.abs(Y_r)**2\n    \n    # 5. Apply the derived scaling to get the one-sided PSD.\n    # The base scaling factor is dt/N.\n    S_hat_k = P_Y_r * (dt / N)\n    \n    # Apply a factor of 2 to account for folding power from negative frequencies,\n    # except for the DC (k=0) and Nyquist (k=N/2, if N is even) components.\n    if N % 2 == 0:\n        # For even N, rfft output is for k = 0, 1, ..., N/2.\n        # Frequencies at indices 1 to N/2 - 1 (exclusive of Nyquist) are doubled.\n        S_hat_k[1:-1] *= 2.0\n    else:\n        # For odd N, rfft output is for k = 0, 1, ..., (N-1)/2.\n        # There is no Nyquist frequency, so all non-DC frequencies are doubled.\n        S_hat_k[1:] *= 2.0\n        \n    return f_k, S_hat_k\n\ndef solve():\n    \"\"\"\n    Main solver function that defines the test suite, executes the PSD estimation\n    for each case, computes the relative variance error, and prints the result.\n    \"\"\"\n    test_cases = [\n        # Case 1: Even N, bin-centered sinusoid, noise, offset\n        {\n            \"N\": 4096, \"dt\": 2.0, \"C\": 10.0,\n            \"sinusoids\": [(1.8, 32.0 / (4096 * 2.0), 0.0)],\n            \"sigma\": 0.7, \"seed\": 123456\n        },\n        # Case 2: Odd N, multiple non-bin-centered sinusoids, noise, offset\n        {\n            \"N\": 4095, \"dt\": 1.0, \"C\": 0.2,\n            \"sinusoids\": [(0.9, 0.01, 0.0), (0.5, 0.1234, 0.0)],\n            \"sigma\": 0.3, \"seed\": 789012\n        },\n        # Case 3: Even N, pure Nyquist sinusoid, no noise\n        {\n            \"N\": 2048, \"dt\": 0.5, \"C\": 0.0,\n            \"sinusoids\": [(2.0, 1.0 / (2 * 0.5), 0.0)],\n            \"sigma\": 0.0, \"seed\": None\n        },\n        # Case 4: Even N, pure white noise\n        {\n            \"N\": 3000, \"dt\": 1.0, \"C\": 0.0,\n            \"sinusoids\": [],\n            \"sigma\": 1.0, \"seed\": 246810\n        },\n    ]\n\n    results = []\n    for params in test_cases:\n        # Generate the signal for the current test case\n        x = generate_signal(\n            N=params[\"N\"], dt=params[\"dt\"], C=params[\"C\"],\n            sinusoids=params[\"sinusoids\"], sigma=params[\"sigma\"], seed=params[\"seed\"]\n        )\n        \n        # Calculate time-series variance. np.var uses a divisor of N by default,\n        # which matches the problem's definition of variance.\n        variance_ts = np.var(x)\n        \n        # Compute the PSD and the corresponding frequency grid\n        f_k, S_hat_k = compute_variance_conserving_psd(x, params[\"dt\"])\n        \n        # Calculate the integrated power from the PSD\n        # df is the frequency spacing, which is constant.\n        if len(f_k) > 1:\n            df = f_k[1] - f_k[0]\n        else: # Handles edge case of N=1\n             df = 1.0 / (params[\"N\"] * params[\"dt\"]) if params[\"N\"] > 0 else 0.0\n\n        variance_psd = np.sum(S_hat_k) * df\n        \n        # Calculate the relative variance error, epsilon\n        if variance_ts == 0.0:\n            # If signal variance is zero, PSD integral must also be zero for zero error.\n            epsilon = 0.0 if np.isclose(variance_psd, 0.0) else np.inf\n        else:\n            epsilon = np.abs(variance_ts - variance_psd) / variance_ts\n            \n        results.append(epsilon)\n\n    # The problem asks for the output to be printed.\n    # print(f\"[{','.join(f'{e:.15e}' for e in results)}]\")\n\nsolve()\n```",
            "answer": "[1.110223024625157e-16,0.000000000000000e+00,0.000000000000000e+00,1.110223024625157e-16]"
        }
    ]
}