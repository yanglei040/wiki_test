{
    "hands_on_practices": [
        {
            "introduction": "The efficiency of a multigrid solver hinges on its smoother, which rapidly damps high-frequency components of the error. In this exercise, you will use Local Fourier Analysis (LFA) to dissect the behavior of the weighted Jacobi smoother, one of the simplest and most illustrative smoothers. By deriving its error amplification factor, you will gain a fundamental understanding of how smoothers work and how to optimize them for peak performance, a core skill in designing efficient solvers .",
            "id": "3524229",
            "problem": "In simulations of self-gravitating media in computational astrophysics, the gravitational potential $\\phi$ is obtained by solving a Poisson equation that reduces, after nondimensionalization in a one-dimensional model, to a discrete Helmholtz problem with the standard three-point Laplacian. Consider the discrete operator $A$ on a uniform infinite grid with spacing $h>0$ defined by the stencil $\\{-1,\\,2,\\,-1\\}/h^{2}$, so that $(A u)_{j} = \\frac{1}{h^{2}}\\left(-u_{j-1} + 2u_{j} - u_{j+1}\\right)$ for grid index $j \\in \\mathbb{Z}$. The weighted Jacobi relaxation for $A u = f$ is given by the iteration\n$$\nu^{(k+1)} = u^{(k)} + \\omega D^{-1}\\left(f - A u^{(k)}\\right),\n$$\nwhere $D$ is the diagonal part of $A$ and $\\omega \\in (0,1)$ is the relaxation weight. For multigrid solvers, the effectiveness of weighted Jacobi as a smoother is quantified by the error amplification factor per iteration for each Fourier mode under Local Fourier Analysis (LFA). Let the error $e^{(k)} = u^{(k)} - u^{*}$ be decomposed into Fourier components on the infinite grid, with a representative mode $e_{j}(\\theta) = \\exp(i j \\theta)$ for angle $\\theta \\in [0, \\pi]$ in radians. Define the error amplification factor $\\mu(\\theta)$ as the magnitude of the eigenvalue of the error-propagation operator acting on this Fourier mode.\n\nStarting from the definitions above and using only the foundational properties of the discrete Laplacian, the Jacobi iteration, and Local Fourier Analysis (LFA), derive the symbolic expression for $\\mu(\\theta)$ as a function of $\\theta$ and $\\omega$. High-frequency components relative to a standard factor-$2$ coarsening are those with $\\theta \\in [\\pi/2, \\pi]$ in radians. Determine the exact value of the relaxation weight $\\omega$ that minimizes the worst-case (supremum) of $\\mu(\\theta)$ over the high-frequency band $\\theta \\in [\\pi/2, \\pi]$, and report the minimized worst-case high-frequency amplification factor attained at this optimal $\\omega$.\n\nYour final answer must include:\n- The closed-form expression for $\\mu(\\theta)$ in terms of $\\theta$ and $\\omega$.\n- The exact optimal $\\omega$ that minimizes $\\sup_{\\theta \\in [\\pi/2, \\pi]} \\mu(\\theta)$.\n- The exact minimized value of $\\sup_{\\theta \\in [\\pi/2, \\pi]} \\mu(\\theta)$ at this optimal $\\omega$.\n\nAngles must be expressed in radians. No rounding is required; provide exact values.",
            "solution": "The problem requires the derivation and analysis of the error amplification factor for the weighted Jacobi method applied to a one-dimensional discrete Poisson equation. The process involves three main steps: first, deriving the general expression for the amplification factor using Local Fourier Analysis (LFA); second, determining the worst-case amplification factor over the specified high-frequency band; and third, finding the optimal relaxation weight $\\omega$ that minimizes this worst-case factor.\n\nThe weighted Jacobi iteration for the system $A u = f$ is given by:\n$$\nu^{(k+1)} = u^{(k)} + \\omega D^{-1}\\left(f - A u^{(k)}\\right)\n$$\nwhere $k$ is the iteration index, $\\omega$ is the relaxation weight, and $D$ is the diagonal part of the operator $A$.\n\nLet $u^{*}$ be the exact solution, satisfying $A u^{*} = f$. The error at iteration $k$ is $e^{(k)} = u^{(k)} - u^{*}$. Subtracting $u^{*}$ from the iteration formula gives the error propagation equation:\n$$\nu^{(k+1)} - u^{*} = u^{(k)} - u^{*} + \\omega D^{-1}\\left(A u^{*} - A u^{(k)}\\right)\n$$\n$$\ne^{(k+1)} = e^{(k)} - \\omega D^{-1} A \\left(u^{(k)} - u^{*}\\right)\n$$\n$$\ne^{(k+1)} = \\left(I - \\omega D^{-1} A\\right) e^{(k)}\n$$\nThe error is transformed at each step by the iteration operator $S = I - \\omega D^{-1} A$.\n\nLocal Fourier Analysis (LFA) examines the effect of this operator on individual Fourier modes of the error. A Fourier mode on the infinite grid is represented by $e_j(\\theta) = \\exp(i j \\theta)$, where $j \\in \\mathbb{Z}$ is the grid index and $\\theta \\in [0, \\pi]$ is the dimensionless wave number. When an operator like $A$ or $S$ acts on this mode, the mode is multiplied by a complex scalar, which is the eigenvalue of the operator for that mode, also known as its symbol. The error amplification factor, $\\mu(\\theta)$, is the magnitude of the eigenvalue (symbol) of the iteration operator $S$.\n$$\nS e_j(\\theta) = \\lambda(\\theta) e_j(\\theta) \\quad \\text{and} \\quad \\mu(\\theta) = |\\lambda(\\theta)|\n$$\n\nFirst, we find the symbol of the operator $A$, denoted $\\hat{A}(\\theta)$. The operator $A$ is defined by $(A u)_{j} = \\frac{1}{h^{2}}\\left(-u_{j-1} + 2u_{j} - u_{j+1}\\right)$. Applying this to the mode $e_j(\\theta)$:\n$$\n(A e(\\theta))_j = \\frac{1}{h^{2}}\\left(-\\exp(i(j-1)\\theta) + 2\\exp(ij\\theta) - \\exp(i(j+1)\\theta)\\right)\n$$\n$$\n= \\frac{\\exp(ij\\theta)}{h^{2}}\\left(-\\exp(-i\\theta) + 2 - \\exp(i\\theta)\\right)\n$$\n$$\n= \\frac{e_j(\\theta)}{h^{2}}\\left(2 - (\\exp(i\\theta) + \\exp(-i\\theta))\\right)\n$$\nUsing the identity $2\\cos(\\theta) = \\exp(i\\theta) + \\exp(-i\\theta)$, we get:\n$$\n(A e(\\theta))_j = \\frac{e_j(\\theta)}{h^{2}}\\left(2 - 2\\cos(\\theta)\\right) = \\frac{2}{h^{2}}(1 - \\cos(\\theta)) e_j(\\theta)\n$$\nUsing the half-angle identity $1 - \\cos(\\theta) = 2\\sin^2(\\frac{\\theta}{2})$, this becomes:\n$$\n(A e(\\theta))_j = \\frac{4}{h^{2}}\\sin^2\\left(\\frac{\\theta}{2}\\right) e_j(\\theta)\n$$\nThus, the symbol of $A$ is $\\hat{A}(\\theta) = \\frac{4}{h^{2}}\\sin^2\\left(\\frac{\\theta}{2}\\right)$.\n\nThe operator $D$ is the diagonal part of $A$. From the stencil $\\{-1, 2, -1\\}/h^2$, the diagonal element is $A_{jj} = 2/h^2$. So, $D$ is a scalar operator in this context, $D = \\frac{2}{h^2}I$, and its symbol is $\\hat{D} = 2/h^2$. Consequently, the symbol of $D^{-1}$ is $\\hat{D}^{-1} = h^2/2$.\n\nThe symbol of the iteration operator $S = I - \\omega D^{-1} A$ is:\n$$\n\\lambda(\\theta) = 1 - \\omega \\hat{D}^{-1} \\hat{A}(\\theta) = 1 - \\omega \\left(\\frac{h^2}{2}\\right) \\left(\\frac{4}{h^{2}}\\sin^2\\left(\\frac{\\theta}{2}\\right)\\right)\n$$\n$$\n\\lambda(\\theta) = 1 - 2\\omega\\sin^2\\left(\\frac{\\theta}{2}\\right)\n$$\nSubstituting back $2\\sin^2(\\frac{\\theta}{2}) = 1 - \\cos(\\theta)$, we find:\n$$\n\\lambda(\\theta) = 1 - \\omega(1 - \\cos(\\theta))\n$$\nThe error amplification factor $\\mu(\\theta)$ is the magnitude of $\\lambda(\\theta)$:\n$$\n\\mu(\\theta) = |1 - \\omega(1 - \\cos(\\theta))|\n$$\nThis is the first required expression.\n\nNext, we need to find the optimal relaxation weight $\\omega \\in (0,1)$ that minimizes the worst-case amplification factor over the high-frequency band $\\theta \\in [\\pi/2, \\pi]$. The quantity to minimize is $\\sup_{\\theta \\in [\\pi/2, \\pi]} \\mu(\\theta)$.\n\nLet us analyze the behavior of $\\mu(\\theta)$ over this band. Let $x = 1 - \\cos(\\theta)$. As $\\theta$ ranges from $\\pi/2$ to $\\pi$, $\\cos(\\theta)$ ranges from $0$ to $-1$. Therefore, $x$ ranges from $1 - 0 = 1$ to $1 - (-1) = 2$. The domain for $x$ corresponding to the high-frequency band is the interval $[1, 2]$.\nWe want to find $\\omega$ that solves the minimax problem:\n$$\n\\min_{\\omega \\in (0,1)} \\left( \\sup_{x \\in [1,2]} |1 - \\omega x| \\right)\n$$\nLet $M(\\omega) = \\sup_{x \\in [1,2]} |1 - \\omega x|$. The function $f(x) = 1 - \\omega x$ is linear in $x$. The maximum of its absolute value on a closed interval must occur at one of the endpoints. Thus:\n$$\nM(\\omega) = \\max\\left( |1 - \\omega \\cdot 1|, |1 - \\omega \\cdot 2| \\right) = \\max\\left( |1 - \\omega|, |1 - 2\\omega| \\right)\n$$\nFor the given range $\\omega \\in (0, 1)$, the term $1 - \\omega$ is always positive, so $|1 - \\omega| = 1 - \\omega$. We need to minimize $M(\\omega) = \\max(1 - \\omega, |1 - 2\\omega|)$.\n\nWe analyze this in two sub-intervals of $\\omega$:\nCase 1: $\\omega \\in (0, 1/2]$.\nIn this interval, $1 - 2\\omega \\ge 0$, so $|1 - 2\\omega| = 1 - 2\\omega$.\n$$\nM(\\omega) = \\max(1 - \\omega, 1 - 2\\omega)\n$$\nSince $\\omega > 0$, we have $2\\omega > \\omega$, which implies $-2\\omega < -\\omega$, and $1 - 2\\omega < 1 - \\omega$.\nSo, $M(\\omega) = 1 - \\omega$. This function is decreasing on $(0, 1/2]$. Its minimum value on this interval is attained at $\\omega = 1/2$, where $M(1/2) = 1 - 1/2 = 1/2$.\n\nCase 2: $\\omega \\in (1/2, 1)$.\nIn this interval, $1 - 2\\omega < 0$, so $|1 - 2\\omega| = -(1 - 2\\omega) = 2\\omega - 1$.\n$$\nM(\\omega) = \\max(1 - \\omega, 2\\omega - 1)\n$$\nWe are looking for the minimum of the maximum of two functions. One function, $f_1(\\omega) = 1-\\omega$, is decreasing, while the other, $f_2(\\omega) = 2\\omega-1$, is increasing. The minimum of their maximum occurs where they are equal:\n$$\n1 - \\omega = 2\\omega - 1 \\implies 3\\omega = 2 \\implies \\omega = \\frac{2}{3}\n$$\nThis value $\\omega = 2/3$ lies within the interval $(1/2, 1)$. At this optimal point, the value of the maximum is:\n$$\nM(2/3) = 1 - \\frac{2}{3} = \\frac{1}{3} \\quad \\text{and} \\quad M(2/3) = 2\\left(\\frac{2}{3}\\right) - 1 = \\frac{4}{3} - 1 = \\frac{1}{3}\n$$\n\nComparing the minimum values from both cases, we have $1/2$ from Case 1 (at the boundary $\\omega=1/2$) and $1/3$ from Case 2 (at $\\omega=2/3$). The global minimum of $M(\\omega)$ for $\\omega \\in (0,1)$ is $1/3$.\n\nTherefore, the optimal relaxation weight is $\\omega_{opt} = 2/3$.\nThe minimized worst-case high-frequency amplification factor is $\\sup_{\\theta \\in [\\pi/2, \\pi]} \\mu(\\theta) = 1/3$.\n\nThe three required quantities are:\n1.  The expression for $\\mu(\\theta)$: $|1 - \\omega(1 - \\cos(\\theta))|$\n2.  The optimal weight $\\omega$: $2/3$\n3.  The minimized worst-case amplification factor: $1/3$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} |1 - \\omega(1 - \\cos(\\theta))| & \\frac{2}{3} & \\frac{1}{3} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Once high-frequency errors are damped, the remaining smooth error can be accurately represented and solved on a coarser grid. This practice focuses on the crucial step of defining the problem on that coarser grid using the Galerkin condition, $A_c = R A_f P$. You will demonstrate that for the standard Laplacian, this construction elegantly preserves the form of the original operator, providing a consistent representation of the physics across different scales .",
            "id": "3524220",
            "problem": "In modeling the self-gravitating potential of a one-dimensional stratified astrophysical medium along a coordinate $x \\in [0,L]$, the gravitational potential $\\phi(x)$ satisfies the Poisson equation $-\\frac{d^{2}\\phi}{dx^{2}} = \\rho(x)$ with homogeneous Dirichlet boundary conditions $\\phi(0)=\\phi(L)=0$. Consider a uniform fine grid with $N_{f}$ interior points and spacing $h_{f} = \\frac{L}{N_{f}+1}$, and a nested coarse grid with spacing $h_{c} = 2 h_{f}$.\n\nLet the fine-grid discrete operator $A_{f}$ be the standard second-order centered finite-difference approximation to the negative Laplacian acting on interior nodes, defined by\n$$(A_{f} y)_{i} = \\frac{-y_{i-1} + 2 y_{i} - y_{i+1}}{h_{f}^{2}}.$$\nDefine the prolongation (interpolation) operator $P$ from coarse to fine grid by linear interpolation,\n$$(P v)_{2j} = v_{j}, \\quad (P v)_{2j+1} = \\frac{v_{j} + v_{j+1}}{2},$$\nand the restriction operator $R$ from fine to coarse grid by full weighting,\n$$(R w)_{j} = \\frac{w_{2j-1} + 2 w_{2j} + w_{2j+1}}{4}.$$\nThe Galerkin coarse-grid operator is defined by $A_{c} = R A_{f} P$.\n\nStarting from these definitions alone, explicitly compute the interior three-point stencil of $A_{c}$ and demonstrate that it coincides with the standard tridiagonal Laplacian scaled by $1/h_{c}^{2}$. Your derivation should make no appeal to unproven identities and must proceed by composing $P$, $A_{f}$, and $R$ on an arbitrary coarse-grid vector. \n\nAnswer specification: Report only the three-point stencil weights corresponding to the coarse-grid nodes $j-1$, $j$, and $j+1$ as a single LaTeX row matrix, including the explicit scaling factor. No numerical rounding is required.",
            "solution": "The objective is to determine the action of the coarse-grid operator $A_{c}$ on an arbitrary coarse-grid vector $v$. Specifically, we must compute the $j$-th component of the vector $A_{c}v$ for a generic interior coarse-grid node $j$. The operator is defined as the composition $A_{c} = R A_{f} P$. We proceed by evaluating the composition from right to left.\n\nLet $v$ be a vector on the coarse grid. Let the indices $j-1, j, j+1$ correspond to interior coarse-grid nodes.\n\n**1. Action of Prolongation, $P$**\nFirst, we apply the prolongation operator $P$ to the coarse-grid vector $v$ to obtain a fine-grid vector, which we denote as $w = P v$. We need the components of $w$ that will subsequently be used in the computation of $(A_c v)_j$. The calculation of $(A_c v)_j$ involves $(R(A_f w))_j$, which depends on the fine-grid components $(A_f w)_{2j-1}, (A_f w)_{2j}, (A_f w)_{2j+1}$. In turn, these depend on the components of $w$ from index $2j-2$ to $2j+2$.\nUsing the definition of $P$:\n- $w_{2j-2} = (P v)_{2(j-1)} = v_{j-1}$\n- $w_{2j-1} = (P v)_{2(j-1)+1} = \\frac{v_{j-1} + v_{j}}{2}$\n- $w_{2j} = (P v)_{2j} = v_{j}$\n- $w_{2j+1} = (P v)_{2j+1} = \\frac{v_{j} + v_{j+1}}{2}$\n- $w_{2j+2} = (P v)_{2(j+1)} = v_{j+1}$\n\n**2. Action of the Fine-Grid Operator, $A_f$**\nNext, we apply the fine-grid operator $A_{f}$ to the vector $w$. Let $z = A_{f} w$. We compute the components of $z$ required by the restriction operator, namely $z_{2j-1}$, $z_{2j}$, and $z_{2j+1}$.\n\nFor the component $z_{2j}$:\n$$\nz_{2j} = (A_{f} w)_{2j} = \\frac{-w_{2j-1} + 2w_{2j} - w_{2j+1}}{h_{f}^{2}}\n$$\nSubstituting the expressions for the components of $w$:\n$$\nz_{2j} = \\frac{1}{h_{f}^{2}} \\left( -\\frac{v_{j-1} + v_{j}}{2} + 2v_{j} - \\frac{v_{j} + v_{j+1}}{2} \\right)\n= \\frac{1}{h_{f}^{2}} \\left( \\frac{-v_{j-1} - v_{j} + 4v_{j} - v_{j} - v_{j+1}}{2} \\right)\n= \\frac{1}{2h_{f}^{2}} (-v_{j-1} + 2v_{j} - v_{j+1})\n$$\n\nFor the component $z_{2j-1}$:\n$$\nz_{2j-1} = (A_{f} w)_{2j-1} = \\frac{-w_{2j-2} + 2w_{2j-1} - w_{2j}}{h_{f}^{2}}\n$$\nSubstituting the expressions for the components of $w$:\n$$\nz_{2j-1} = \\frac{1}{h_{f}^{2}} \\left( -v_{j-1} + 2\\left(\\frac{v_{j-1} + v_{j}}{2}\\right) - v_{j} \\right)\n= \\frac{1}{h_{f}^{2}} (-v_{j-1} + v_{j-1} + v_{j} - v_{j}) = 0\n$$\n\nFor the component $z_{2j+1}$:\n$$\nz_{2j+1} = (A_{f} w)_{2j+1} = \\frac{-w_{2j} + 2w_{2j+1} - w_{2j+2}}{h_{f}^{2}}\n$$\nSubstituting the expressions for the components of $w$:\n$$\nz_{2j+1} = \\frac{1}{h_{f}^{2}} \\left( -v_{j} + 2\\left(\\frac{v_{j} + v_{j+1}}{2}\\right) - v_{j+1} \\right)\n= \\frac{1}{h_{f}^{2}} (-v_{j} + v_{j} + v_{j+1} - v_{j+1}) = 0\n$$\nThis result, where the action of the finite difference operator is zero at the \"in-between\" fine-grid points, is a direct consequence of the fact that linear interpolation (the prolongation operator $P$) produces a function that is locally linear, and the second-order finite difference of a linear function is zero.\n\n**3. Action of the Restriction Operator, $R$**\nFinally, we apply the restriction operator $R$ to the vector $z$ to obtain the $j$-th component of the final coarse-grid vector $A_c v$.\n$$\n(A_{c}v)_{j} = (R z)_{j} = \\frac{z_{2j-1} + 2z_{2j} + z_{2j+1}}{4}\n$$\nSubstituting the computed values of the components of $z$:\n$$\n(A_{c}v)_{j} = \\frac{0 + 2z_{2j} + 0}{4} = \\frac{z_{2j}}{2}\n$$\nNow, substituting the expression for $z_{2j}$:\n$$\n(A_{c}v)_{j} = \\frac{1}{2} \\left( \\frac{1}{2h_{f}^{2}} (-v_{j-1} + 2v_{j} - v_{j+1}) \\right) = \\frac{-v_{j-1} + 2v_{j} - v_{j+1}}{4h_{f}^{2}}\n$$\n\n**4. Final Form and Stencil Identification**\nThe problem specifies the relationship between the coarse and fine grid spacings as $h_{c} = 2h_{f}$. Squaring this relation gives $h_{c}^{2} = 4h_{f}^{2}$. We substitute this into our expression for $(A_{c}v)_{j}$:\n$$\n(A_{c}v)_{j} = \\frac{-v_{j-1} + 2v_{j} - v_{j+1}}{h_{c}^{2}}\n$$\nThis result is precisely the standard second-order centered finite-difference approximation for the negative Laplacian operator, but on the coarse grid with spacing $h_c$. This demonstrates that for the chosen prolongation and restriction operators, the Galerkin coarse-grid operator $A_c = R A_f P$ preserves the form of the original differential operator.\n\nThe three-point stencil for the operator $A_c$ at an interior node $j$ gives the weights for the coarse-grid values $v_{j-1}$, $v_{j}$, and $v_{j+1}$. From the derived expression, these weights are $-\\frac{1}{h_{c}^{2}}$, $\\frac{2}{h_{c}^{2}}$, and $-\\frac{1}{h_{c}^{2}}$, respectively.\n\nThe problem asks for these weights to be reported as a single LaTeX row matrix. The weights are the coefficients of $(v_{j-1}, v_{j}, v_{j+1})$. Thus, the stencil is $(-\\frac{1}{h_{c}^{2}}, \\frac{2}{h_{c}^{2}}, -\\frac{1}{h_{c}^{2}})$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{1}{h_{c}^{2}} & \\frac{2}{h_{c}^{2}} & -\\frac{1}{h_{c}^{2}} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Theory comes to life when implemented in code. This final practice challenges you to synthesize the concepts of smoothing and inter-grid transfers by building a complete 3D geometric multigrid solver from the ground up. You will apply your solver to a classic astrophysical problem—the gravitational potential of a uniform-density sphere—and use it to investigate the practical issue of boundary truncation error, a critical aspect of validating any numerical simulation .",
            "id": "3524177",
            "problem": "Consider Newtonian gravity in the vacuum and matter regimes, where the gravitational potential satisfies the Poisson equation. The fundamental base for this problem is the Poisson equation for Newtonian gravity, which states that the gravitational potential $\\,\\Phi(\\mathbf{x})\\,$ obeys\n$$\n\\nabla^2 \\Phi(\\mathbf{x}) = 4\\pi G \\rho(\\mathbf{x}),\n$$\nwith $\\,G\\,$ the gravitational constant and $\\,\\rho(\\mathbf{x})\\,$ the mass density. In vacuum, where $\\,\\rho(\\mathbf{x})=0\\,$, the equation reduces to Laplace's equation. For a uniform-density sphere of radius $\\,R_{\\mathrm{s}}\\,$ centered at the origin with constant $\\,\\rho(\\mathbf{x})=\\rho_0\\,$ for $\\,\\|\\mathbf{x}\\|\\le R_{\\mathrm{s}}\\,$ and $\\,\\rho(\\mathbf{x})=0\\,$ otherwise, the exact infinite-domain potential $\\,\\Phi_{\\mathrm{exact}}(r)\\,$, with $\\,r=\\|\\mathbf{x}\\|\\,$ and the zero of potential chosen at infinity, is given by a piecewise function that is smooth at $\\,r=R_{\\mathrm{s}}\\,$.\n\nYour task is to write a complete and runnable program that:\n- Discretizes the three-dimensional Poisson equation on a uniform Cartesian grid covering the cube $\\,[-L,L]^3\\,$ using second-order centered finite differences on a uniform mesh of $\\,N\\times N\\times N\\,$ points with spacing $\\,h=2L/(N-1)\\,$.\n- Enforces homogeneous Dirichlet boundary conditions $\\,\\Phi=0\\,$ on all faces of the cubic domain.\n- Implements a geometric multigrid V-cycle solver to compute the numerical solution $\\,\\Phi_h\\,$, using:\n  - Weighted Jacobi smoothing with weight $\\,\\omega\\in(0,1)\\,$ and a fixed number of pre- and post-smoothing sweeps at each level.\n  - Full-weighting restriction from fine to coarse grids.\n  - Trilinear interpolation (prolongation) from coarse to fine grids.\n  - A small-grid solve achieved by additional smoothing when the grid has a small number of points (you should choose a reasonable threshold).\n- Constructs the discrete right-hand side $\\,f=4\\pi G\\rho\\,$ with $\\,\\rho=\\rho_0\\,$ inside the sphere $\\,r\\le R_{\\mathrm{s}}\\,$ and $\\,\\rho=0\\,$ outside, with the sphere centered at the origin.\n\nYou must compare the numerical solution to the analytic infinite-domain solution for a uniform-density sphere of total mass $\\,M=\\frac{4}{3}\\pi \\rho_0 R_{\\mathrm{s}}^3\\,$ (with the zero of potential at infinity). The analytic potential $\\,\\Phi_{\\mathrm{exact}}(r)\\,$ is:\n- For $\\,r\\ge R_{\\mathrm{s}}\\,$, $\\,\\Phi_{\\mathrm{exact}}(r)=-\\dfrac{G M}{r}\\,$.\n- For $\\,r\\le R_{\\mathrm{s}}\\,$, $\\,\\Phi_{\\mathrm{exact}}(r)=-\\dfrac{G M}{2R_{\\mathrm{s}}^3}\\left(3R_{\\mathrm{s}}^2-r^2\\right)\\,$.\n\nDefine a quantitative error metric by the interior relative $\\,L^2\\,$ error over all interior grid points (excluding the boundary layer):\n$$\n\\varepsilon = \\sqrt{\\frac{\\sum_{i,j,k\\in\\text{interior}}\\left(\\Phi_h-\\Phi_{\\mathrm{exact}}\\right)^2}{\\sum_{i,j,k\\in\\text{interior}}\\Phi_{\\mathrm{exact}}^2}}.\n$$\nThis metric detects the effect of placing the finite computational boundary at $\\,r\\approx L\\,$ with $\\,\\Phi=0\\,$, which approximates the condition at infinity but introduces boundary truncation error that grows as $\\,L\\,$ decreases.\n\nUse dimensionless units and the following fixed parameters for all runs:\n- $\\,G=1\\,$,\n- $\\,\\rho_0=1\\,$,\n- $\\,R_{\\mathrm{s}}=1\\,$,\n- $\\,N=65\\,$,\n- A V-cycle with a reasonable choice of $\\,\\omega\\,$, numbers of pre- and post-smoothing sweeps, and a multigrid hierarchy that halves the number of points (approximately) along each axis at each coarsening until a small threshold is reached. Terminate the outer iteration when the relative residual norm drops below a tolerance $\\,10^{-10}\\,$ or when a fixed maximum number of V-cycles is reached.\n\nTest Suite:\nEvaluate $\\,\\varepsilon\\,$ for the following three outer half-domain sizes $\\,L\\,$ (with $\\,R_{\\mathrm{s}}=1\\,$ fixed), which probe boundary truncation effects as the outer boundary moves inward:\n- Case A: $\\,L=4.0\\,R_{\\mathrm{s}}\\,\\,$,\n- Case B: $\\,L=2.0\\,R_{\\mathrm{s}}\\,\\,$,\n- Case C: $\\,L=1.25\\,R_{\\mathrm{s}}\\,\\,$.\n\nYour program must compute and return the three interior relative $\\,L^2\\,$ errors for cases A, B, and C, in that order. The required final output format is:\n- A single line containing a comma-separated list of the three floating-point errors enclosed in square brackets, with no spaces, for example $\\,\\texttt{[e\\_A,e\\_B,e\\_C]}\\,$, where each entry is a standard decimal or scientific-notation float.\n\nNo physical units are required; all quantities are dimensionless. Angles do not appear in this problem, so no angle-unit specification is necessary. Percentages are not used in this problem. The numerical values reported must be floating-point numbers. Ensure the solver and comparison are self-contained and do not require input. The program must not read from files or the network and must not prompt the user. The algorithmic choices must be consistent across the three tests to isolate the effect of changing $\\,L\\,$. The implementation language must be any general-purpose modern language; however, the final answer you provide must be executable Python code. The physics, discretization, and algorithmic choices must be scientifically sound and self-consistent for all three test cases.",
            "solution": "The problem requires the implementation of a geometric multigrid solver for the three-dimensional Poisson equation, $\\nabla^2 \\Phi = 4\\pi G \\rho$, on a cubic domain with homogeneous Dirichlet boundary conditions. This numerical solution is then compared to a known analytical solution to quantify the error introduced by the finite computational domain. The entire process is encapsulated in a Python program, which computes the error for three different domain sizes.\n\n### 1. Discretization and Problem Setup\nThe continuous Poisson equation is discretized on a uniform Cartesian grid of size $N \\times N \\times N$ over the domain $[-L, L]^3$. The grid spacing is $h = 2L / (N-1)$. Using a second-order centered finite difference stencil for the Laplacian operator, $\\nabla^2$, we obtain a system of linear equations $A_h \\Phi_h = f_h$ for the potential $\\Phi_h$ at each grid point. The operator $A_h$ applied to a grid point $(i,j,k)$ is:\n$$ (A_h \\Phi_h)_{i,j,k} = \\frac{\\Phi_{i+1,j,k} + \\Phi_{i-1,j,k} + \\Phi_{i,j+1,k} + \\Phi_{i,j-1,k} + \\Phi_{i,j,k+1} + \\Phi_{i,j,k-1} - 6\\Phi_{i,j,k}}{h^2} $$\nThis 7-point stencil is applied to all interior grid points, i.e., for indices $i,j,k \\in \\{1, \\dots, N-2\\}$. The boundary conditions $\\Phi_h=0$ are enforced by fixing the values of $\\Phi_h$ on the boundary of the grid (indices $0$ and $N-1$) to zero.\n\nThe right-hand side (RHS), $f_h$, represents the source term $4\\pi G \\rho$. For a uniform sphere of radius $R_s$ and density $\\rho_0$ centered at the origin, the value of $f_h$ at each grid point $(x_i, y_j, z_k)$ is $4\\pi G \\rho_0$ if its radial distance $r = \\sqrt{x_i^2 + y_j^2 + z_k^2}$ is less than or equal to $R_s$, and $0$ otherwise.\n\n### 2. Geometric Multigrid V-Cycle Solver\nA geometric multigrid method is employed to solve the linear system efficiently. It operates on a hierarchy of grids, from the fine grid (level $0$) down to a coarsest grid. The grid size $N=65$ is convenient, as $N-1=64=2^6$, allowing for several coarsening steps where the number of grid points is halved in each dimension. The V-cycle algorithm is implemented as a recursive process:\n\n1.  **Smoothing**: On a given grid level, the current approximation to the solution is improved by applying a few sweeps of a smoother. We use the weighted Jacobi method with weight $\\omega = 2/3$. The update rule for a point $(i,j,k)$ is:\n    $$ \\Phi_{i,j,k}^{\\text{new}} = (1-\\omega)\\Phi_{i,j,k}^{\\text{old}} + \\frac{\\omega}{6} \\left( \\sum_{\\text{neighbors}} \\Phi_{\\text{neighbor}}^{\\text{old}} - h^2 f_{i,j,k} \\right) $$\n    This is performed for a fixed number of pre-smoothing sweeps ($\\nu_1=2$) before moving to a coarser grid.\n\n2.  **Residual Calculation and Restriction**: After pre-smoothing, the residual $r_h = f_h - A_h \\Phi_h$ is computed. This residual represents the error in the current solution. It is then transferred to the next coarser grid using a restriction operator. We use full-weighting restriction, where the value at a coarse grid point is a weighted average of the $27$ corresponding fine grid points in a $3\\times3\\times3$ block.\n\n3.  **Recursive Solve**: The residual equation $A_{2h} e_{2h} = r_{2h}$ is solved on the coarser grid for the error term $e_{2h}$. This is done by recursively calling the V-cycle function.\n\n4.  **Coarse-Grid Solve**: The recursion stops at the coarsest level (chosen here as a $5 \\times 5 \\times 5$ grid). At this level, the equation is not solved directly but is approximated by applying a larger number of smoothing sweeps (e.g., $20$) since the system is small.\n\n5.  **Prolongation and Correction**: The correction $e_{2h}$ computed on the coarse grid is interpolated back to the fine grid using a prolongation operator. We use trilinear interpolation. The interpolated correction is then added to the solution on the fine grid: $\\Phi_h \\leftarrow \\Phi_h + e_h$.\n\n6.  **Post-smoothing**: Finally, a few post-smoothing sweeps ($\\nu_2=2$) are applied to damp any high-frequency errors introduced by the prolongation step.\n\nThis entire V-cycle is iterated until the relative $L^2$-norm of the residual, $\\|f_h - A_h \\Phi_h\\| / \\|f_h\\|$, drops below a tolerance of $10^{-10}$.\n\n### 3. Error Analysis\nAfter the numerical solution $\\Phi_h$ is obtained, it is compared to the exact analytical solution $\\Phi_{\\text{exact}}(r)$ for a uniform sphere in an infinite domain. The discrepancy between the numerical solution and the exact solution arises from two main sources: discretization error (due to finite $h$) and boundary truncation error (due to the finite domain size $L$ with $\\Phi=0$ boundary conditions, which only approximates $\\Phi(\\infty)=0$).\n\nThe problem focuses on the boundary truncation error, which is probed by varying $L$ while keeping all other parameters fixed. The error is quantified using the interior relative $L^2$ error:\n$$ \\varepsilon = \\sqrt{\\frac{\\sum_{i,j,k\\in\\text{interior}}\\left(\\Phi_h - \\Phi_{\\mathrm{exact}}\\right)^2}{\\sum_{i,j,k\\in\\text{interior}}\\Phi_{\\mathrm{exact}}^2}} $$\nThe summation is performed over all interior grid points, excluding the boundary layer. As the computational boundary $L$ is moved closer to the source sphere (i.e., $L$ decreases), the artificial boundary condition $\\Phi=0$ at $r \\approx L$ becomes a poorer approximation of the far-field behavior $\\Phi \\propto -1/r$, and the truncation error $\\varepsilon$ is expected to increase. The program calculates this error for $L \\in \\{4.0, 2.0, 1.25\\}$ with $R_s=1$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import ndimage\n\ndef solve():\n    \"\"\"\n    Main function to solve the Poisson equation for gravity and compute errors.\n    \"\"\"\n\n    # --- Multigrid and Simulation Parameters ---\n    G_CONST = 1.0\n    RHO_0 = 1.0\n    R_S = 1.0\n    GRID_N = 65\n    \n    # Multigrid settings\n    OMEGA = 2.0 / 3.0  # Weighted Jacobi parameter\n    PRE_SWEEPS = 2\n    POST_SWEEPS = 2\n    COARSE_GRID_SWEEPS = 20\n    MIN_GRID_SIZE = 5\n    MAX_V_CYCLES = 100\n    TOLERANCE = 1e-10\n\n    # --- Helper Functions for Multigrid ---\n\n    def apply_laplacian(phi, h):\n        \"\"\"Computes the action of the 7-point stencil Laplacian on phi.\"\"\"\n        lap_phi = np.zeros_like(phi)\n        # Vectorized operation on interior points\n        lap_phi[1:-1, 1:-1, 1:-1] = (\n            phi[0:-2, 1:-1, 1:-1] + phi[2:, 1:-1, 1:-1] +\n            phi[1:-1, 0:-2, 1:-1] + phi[1:-1, 2:, 1:-1] +\n            phi[1:-1, 1:-1, 0:-2] + phi[1:-1, 1:-1, 2:] -\n            6.0 * phi[1:-1, 1:-1, 1:-1]\n        ) / h**2\n        return lap_phi\n\n    def smoother(phi, f, h, num_sweeps):\n        \"\"\"Applies a specified number of weighted Jacobi smoothing sweeps.\"\"\"\n        n = phi.shape[0]\n        # temp_phi = phi.copy() # For Red-Black ordering, not needed for Jacobi\n        \n        for _ in range(num_sweeps):\n            phi_old = phi.copy()\n            # Vectorized update for all interior points\n            sum_neighbors = (\n                phi_old[0:-2, 1:-1, 1:-1] + phi_old[2:, 1:-1, 1:-1] +\n                phi_old[1:-1, 0:-2, 1:-1] + phi_old[1:-1, 2:, 1:-1] +\n                phi_old[1:-1, 1:-1, 0:-2] + phi_old[1:-1, 1:-1, 2:]\n            )\n            \n            phi[1:-1, 1:-1, 1:-1] = (1.0 - OMEGA) * phi_old[1:-1, 1:-1, 1:-1] + \\\n                                   OMEGA / 6.0 * (sum_neighbors - h**2 * f[1:-1, 1:-1, 1:-1])\n        return phi\n\n    def restrict(r_fine):\n        \"\"\"Restricts a fine grid residual to a coarse grid using full-weighting.\"\"\"\n        W1d = np.array([0.25, 0.5, 0.25])\n        W3d = np.einsum('i,j,k->ijk', W1d, W1d, W1d)\n        \n        convolved = ndimage.convolve(r_fine, W3d, mode='constant', cval=0.0)\n        r_coarse = convolved[::2, ::2, ::2]\n        return r_coarse\n\n    def prolong(e_coarse):\n        \"\"\"Prolongs a coarse grid correction to a fine grid using trilinear interpolation.\"\"\"\n        Nc = e_coarse.shape[0]\n        Nf = (Nc - 1) * 2 + 1\n        e_fine = np.zeros((Nf, Nf, Nf))\n\n        # Injection\n        e_fine[::2, ::2, ::2] = e_coarse\n\n        # Interpolate along axes\n        e_fine[1::2, ::2, ::2] = 0.5 * (e_fine[:-2:2, ::2, ::2] + e_fine[2::2, ::2, ::2])\n        e_fine[::2, 1::2, ::2] = 0.5 * (e_fine[::2, :-2:2, ::2] + e_fine[::2, 2::2, ::2])\n        e_fine[::2, ::2, 1::2] = 0.5 * (e_fine[::2, ::2, :-2:2] + e_fine[::2, ::2, 2::2])\n\n        # Interpolate on faces\n        e_fine[1::2, 1::2, ::2] = 0.25 * (e_fine[:-2:2, :-2:2, ::2] + e_fine[2::2, :-2:2, ::2] +\n                                       e_fine[:-2:2, 2::2, ::2] + e_fine[2::2, 2::2, ::2])\n        e_fine[1::2, ::2, 1::2] = 0.25 * (e_fine[:-2:2, ::2, :-2:2] + e_fine[2::2, ::2, :-2:2] +\n                                       e_fine[:-2:2, ::2, 2::2] + e_fine[2::2, ::2, 2::2])\n        e_fine[::2, 1::2, 1::2] = 0.25 * (e_fine[::2, :-2:2, :-2:2] + e_fine[::2, 2::2, :-2:2] +\n                                       e_fine[::2, :-2:2, 2::2] + e_fine[::2, 2::2, 2::2])\n        \n        # Interpolate in centers\n        e_fine[1::2, 1::2, 1::2] = 0.125 * (e_fine[:-2:2, :-2:2, :-2:2] + e_fine[2::2, :-2:2, :-2:2] +\n                                           e_fine[:-2:2, 2::2, :-2:2] + e_fine[2::2, 2::2, :-2:2] +\n                                           e_fine[:-2:2, :-2:2, 2::2] + e_fine[2::2, :-2:2, 2::2] +\n                                           e_fine[:-2:2, 2::2, 2::2] + e_fine[2::2, 2::2, 2::2])\n        return e_fine\n\n    def v_cycle_recursive(phi, f, level, h_levels, grid_sizes):\n        \"\"\"A single recursive V-cycle.\"\"\"\n        h = h_levels[level]\n        \n        # 1. Pre-smoothing\n        phi = smoother(phi, f, h, PRE_SWEEPS)\n\n        # 2. Coarse grid correction\n        if grid_sizes[level] <= MIN_GRID_SIZE:\n            # Coarsest level: solve by more smoothing\n            phi = smoother(phi, f, h, COARSE_GRID_SWEEPS)\n        else:\n            # Compute residual\n            residual = f - apply_laplacian(phi, h)\n            \n            # Restrict residual to coarse grid\n            r_coarse = restrict(residual)\n            e_coarse = np.zeros_like(r_coarse)\n            \n            # Recursive call\n            e_coarse = v_cycle_recursive(e_coarse, r_coarse, level + 1, h_levels, grid_sizes)\n            \n            # Prolongate correction and add to solution\n            e_fine = prolong(e_coarse)\n            phi += e_fine\n        \n        # 3. Post-smoothing\n        phi = smoother(phi, f, h, POST_SWEEPS)\n        return phi\n\n    def run_simulation_for_L(L):\n        \"\"\"Performs a full simulation for a given domain size L.\"\"\"\n        # 1. Setup Grid and RHS\n        h = 2.0 * L / (GRID_N - 1)\n        coords = np.linspace(-L, L, GRID_N)\n        xx, yy, zz = np.meshgrid(coords, coords, coords, indexing='ij')\n        rr = np.sqrt(xx**2 + yy**2 + zz**2)\n\n        rho = np.zeros((GRID_N, GRID_N, GRID_N))\n        rho[rr <= R_S] = RHO_0\n        f_source = 4.0 * np.pi * G_CONST * rho\n\n        # 2. Setup Multigrid Hierarchy\n        grid_sizes = []\n        h_levels = []\n        n_curr, h_curr = GRID_N, h\n        while n_curr >= MIN_GRID_SIZE:\n            grid_sizes.append(n_curr)\n            h_levels.append(h_curr)\n            if n_curr % 2 == 0: break\n            n_curr = (n_curr - 1) // 2 + 1\n            h_curr *= 2.0\n\n        # 3. Run Multigrid Solver\n        phi_h = np.zeros((GRID_N, GRID_N, GRID_N))\n        \n        # Initial residual norm for convergence check\n        res_0_norm = np.linalg.norm(f_source)\n        if res_0_norm == 0.0: res_0_norm = 1.0\n\n        for cycle in range(MAX_V_CYCLES):\n            phi_h = v_cycle_recursive(phi_h, f_source, 0, h_levels, grid_sizes)\n            \n            residual = f_source - apply_laplacian(phi_h, h)\n            res_norm = np.linalg.norm(residual)\n            \n            if res_norm / res_0_norm < TOLERANCE:\n                break\n        \n        # 4. Compute Error\n        M = 4.0 / 3.0 * np.pi * RHO_0 * R_S**3\n        phi_exact = np.zeros((GRID_N, GRID_N, GRID_N))\n        \n        mask_in = rr <= R_S\n        phi_exact[mask_in] = -G_CONST * M / (2.0 * R_S**3) * (3.0 * R_S**2 - rr[mask_in]**2)\n        \n        mask_out = rr > R_S\n        rr_safe = np.copy(rr)\n        rr_safe[rr_safe == 0] = 1.0  # Avoid division by zero, masked out anyway\n        phi_exact[mask_out] = -G_CONST * M / rr_safe[mask_out]\n\n        # Interior L2 relative error\n        phi_h_int = phi_h[1:-1, 1:-1, 1:-1]\n        phi_exact_int = phi_exact[1:-1, 1:-1, 1:-1]\n\n        err_num = np.sum((phi_h_int - phi_exact_int)**2)\n        err_den = np.sum(phi_exact_int**2)\n        \n        if err_den == 0: return 0.0\n        \n        epsilon = np.sqrt(err_num / err_den)\n        return epsilon\n\n    # --- Main Execution Logic ---\n    test_cases = [4.0, 2.0, 1.25]\n    results = []\n    for L_val in test_cases:\n        error = run_simulation_for_L(L_val * R_S)\n        results.append(error)\n    \n    print(f\"[{','.join(f'{r:.7e}' for r in results)}]\")\n\nsolve()\n\n```"
        }
    ]
}