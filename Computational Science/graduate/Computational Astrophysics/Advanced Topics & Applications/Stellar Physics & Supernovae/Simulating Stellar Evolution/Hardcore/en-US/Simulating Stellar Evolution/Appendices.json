{
    "hands_on_practices": [
        {
            "introduction": "Stellar evolution models, despite their complexity, often contain free parameters that are not determined by fundamental theory. A crucial step in ensuring a model's physical realism is calibrating these parameters against well-constrained observations, with the Sun serving as the ultimate benchmark. In this exercise, you will perform one of the most fundamental calibrations in stellar astrophysics: tuning the mixing-length parameter $\\alpha_{\\mathrm{MLT}}$, which governs the efficiency of convection, to reproduce the known radius and luminosity of our Sun. This practice provides hands-on experience with numerical optimization and reveals the sensitive dependence of a star's global structure on its treatment of energy transport. ",
            "id": "3534126",
            "problem": "You are tasked with constructing and calibrating a reduced-order solar model that captures, in a physically motivated but computationally tractable way, the dependence of the solar radius and luminosity on the mixing-length parameter of Mixing-Length Theory (MLT) and on the initial helium mass fraction. Your goal is to programmatically calibrate the dimensionless mixing-length parameter $ \\alpha_{\\mathrm{MLT}} $ by jointly matching the present-day solar radius and luminosity at age $ t_{\\odot} = 4.57\\,\\mathrm{Gyr} $, and then quantify the sensitivity of this calibration to the initial helium mass fraction $ Y $. All calculations must be in International System of Units (SI) when applicable, and all outputs that are dimensional must be converted to dimensionless ratios with respect to the solar values specified below. All angles (if any appear) must be in radians. The final program should compute and print the requested calibration values numerically.\n\nYou must work from the following fundamental laws and core definitions, and use only the reduced-order approximations specified below.\n\nFundamental bases:\n- Hydrostatic equilibrium: $ \\mathrm{d}P / \\mathrm{d}r = - G M(r)\\rho / r^{2} $.\n- Ideal-gas equation of state: $ P = \\rho k_{\\mathrm{B}} T / (\\mu m_{\\mathrm{u}}) $, where $ \\mu $ is the mean molecular weight and $ m_{\\mathrm{u}} $ is the atomic mass unit.\n- Radiative diffusion (used indirectly): $ \\nabla_{\\mathrm{rad}} = \\left( \\mathrm{d}\\ln T / \\mathrm{d}\\ln P \\right)_{\\mathrm{rad}} = \\dfrac{3 \\kappa P L(r)}{16 \\pi a c G M(r) T^{4}} $.\n- Convective transport scaling from Mixing-Length Theory (MLT): the superadiabaticity satisfies a scaling relationship $ \\Delta \\nabla \\propto F^{2/3} g^{-2/3} \\alpha_{\\mathrm{MLT}}^{-4/3} $ in the inefficient surface layers, where $ F $ is the energy flux, $ g $ is the local gravity, and $ \\alpha_{\\mathrm{MLT}} $ is the mixing-length parameter. This scaling provides the functional dependence used below.\n- Nuclear energy generation in the proton-proton chain: $ \\epsilon \\propto \\rho X^{2} T^{\\nu} $ with $ \\nu \\approx 4 $ near solar conditions, where $ X $ is the hydrogen mass fraction.\n\nReduced-order model definition:\n- Fix the stellar mass at the solar mass $ M = M_{\\odot} $ and the metallicity at a constant $ Z = 0.0134 $ for all cases. The initial hydrogen mass fraction is $ X = 1 - Y - Z $. The mean molecular weight for a fully ionized gas is\n  $$ \\mu^{-1} = 2 X + \\tfrac{3}{4} Y + \\tfrac{1}{2} Z. $$\n- Denote the present-day solar luminosity and radius by $ L_{\\odot} $ and $ R_{\\odot} $, respectively. You must use the following numerical constants in SI units, even though the equations below are normalized to solar values:\n  - $ L_{\\odot} = 3.828 \\times 10^{26}\\,\\mathrm{W} $,\n  - $ R_{\\odot} = 6.957 \\times 10^{8}\\,\\mathrm{m} $,\n  - $ M_{\\odot} = 1.98847 \\times 10^{30}\\,\\mathrm{kg} $,\n  - $ G = 6.67430 \\times 10^{-11}\\,\\mathrm{m^{3}\\,kg^{-1}\\,s^{-2}} $,\n  - $ k_{\\mathrm{B}} = 1.380649 \\times 10^{-23}\\,\\mathrm{J\\,K^{-1}} $,\n  - $ m_{\\mathrm{u}} = 1.66053906660 \\times 10^{-27}\\,\\mathrm{kg} $,\n  - $ a = 7.5657 \\times 10^{-16}\\,\\mathrm{J\\,m^{-3}\\,K^{-4}} $,\n  - $ c = 2.99792458 \\times 10^{8}\\,\\mathrm{m\\,s^{-1}} $.\n  Although the reduced-order model uses dimensionless ratios relative to solar values, these constants are provided for clarity and completeness.\n- The nuclear luminosity scaling is defined by the homology-inspired relation\n  $$ \\frac{L}{L_{\\odot}} = \\left( \\frac{X}{X_{\\odot}} \\right)^{2} \\left( \\frac{\\mu}{\\mu_{\\odot}} \\right)^{\\nu} \\left( \\frac{R}{R_{\\odot}} \\right)^{-(\\nu + 3)}, $$\n  where $ \\nu = 4 $ is to be used in this problem, and the subscript $ \\odot $ denotes evaluation at the baseline composition $ Y_{\\odot} = 0.27 $ and $ Z = 0.0134 $, so that $ X_{\\odot} = 1 - Y_{\\odot} - Z $ and $ \\mu_{\\odot} $ is computed from $ X_{\\odot}, Y_{\\odot}, Z $.\n- The radius is determined from a one-zone envelope relation that encodes the entropy jump induced by inefficient convection near the surface. Model the fractional radius inflation over the adiabatic limit using the MLT-inspired scaling of the superadiabaticity. Specifically, solve for $ R $ from the implicit equation\n  $$ \\frac{R}{R_{\\odot}} = c \\left( \\frac{\\mu_{\\odot}}{\\mu} \\right)^{s} \\left[ 1 + B \\left( \\frac{L}{L_{\\odot}} \\right)^{2/3} \\left( \\frac{g}{g_{\\odot}} \\right)^{-2/3} \\left( \\frac{\\alpha_{\\mathrm{MLT}}}{\\alpha_{\\mathrm{ref}}} \\right)^{-4/3} \\right], $$\n  where $ g = G M / R^{2} $ and $ g_{\\odot} = G M_{\\odot} / R_{\\odot}^{2} $. Use the fixed numerical choices $ s = 0.4 $, $ c = 0.98 $, and $ \\alpha_{\\mathrm{ref}} = 1.8 $. The parameter $ B $ is determined by requiring that, at the baseline composition $ Y_{\\odot} $ and $ \\alpha_{\\mathrm{MLT}} = \\alpha_{\\mathrm{ref}} $, one recovers $ R = R_{\\odot} $ and $ L = L_{\\odot} $, which yields\n  $$ B = \\frac{1}{c} - 1. $$\n  This definition ensures that $ R \\to c R_{\\odot} (\\mu_{\\odot}/\\mu)^{s} $ in the adiabatic limit $ \\alpha_{\\mathrm{MLT}} \\to \\infty $, and that the present-day Sun at $ Y_{\\odot} $ is reproduced when $ \\alpha_{\\mathrm{MLT}} = \\alpha_{\\mathrm{ref}} $. Note that $ L $ in the bracket depends on $ R $, and $ g $ depends on $ R $, so the $ R $ equation must be solved iteratively for each $ \\alpha_{\\mathrm{MLT}} $ and $ Y $.\n- The present-day calibration problem is posed at fixed age $ t_{\\odot} = 4.57\\,\\mathrm{Gyr} $. Because the reduced-order model is time-independent and uses present-day scalings, you may regard the age as a label enforcing the present-day solar state rather than as an explicit variable in the equations.\n\nCalibration and sensitivity tasks:\n- For a given $ Y $, define the objective function\n  $$ \\Phi(\\alpha_{\\mathrm{MLT}}; Y) = \\left( \\frac{R(\\alpha_{\\mathrm{MLT}}, Y)}{R_{\\odot}} - 1 \\right)^{2} + \\left( \\frac{L(\\alpha_{\\mathrm{MLT}}, Y)}{L_{\\odot}} - 1 \\right)^{2}. $$\n  The calibrated $ \\alpha_{\\mathrm{MLT}} $ for that $ Y $ is the scalar that minimizes $ \\Phi $ over a search interval $ \\alpha_{\\mathrm{MLT}} \\in [\\alpha_{\\min}, \\alpha_{\\max}] $ with $ \\alpha_{\\min} = 1.0 $ and $ \\alpha_{\\max} = 3.5 $. Your solver must be deterministic and use a bracketing one-dimensional search algorithm that does not require derivatives.\n- Define the sensitivity as the finite-difference derivative\n  $$ \\left. \\frac{\\mathrm{d}\\alpha_{\\mathrm{MLT}}}{\\mathrm{d}Y} \\right|_{Y=Y_{\\odot}} \\approx \\frac{\\alpha_{\\mathrm{MLT}}(Y_{\\odot} + \\Delta Y) - \\alpha_{\\mathrm{MLT}}(Y_{\\odot} - \\Delta Y)}{2 \\Delta Y}, $$\n  with $ \\Delta Y = 0.01 $.\n\nNumerical instructions:\n- Iteratively solve the implicit radius equation at fixed $ \\alpha_{\\mathrm{MLT}} $ and $ Y $ by fixed-point iteration and under-relaxation until the relative change in $ R $ is below $ 10^{-12} $ or a maximum of $ 200 $ iterations is reached. Initialize $ R $ at $ R_{\\odot} $ for each invocation.\n- Use a bracketing derivative-free minimization method such as the golden-section search with a strict tolerance of $ 10^{-8} $ in $ \\alpha_{\\mathrm{MLT}} $ or $ 200 $ iterations, whichever comes first.\n- All calculations of $ R/R_{\\odot} $ and $ L/L_{\\odot} $ must be performed in dimensionless form as defined above. The final outputs are dimensionless numbers.\n\nTest suite and required output:\n- Compute calibrated $ \\alpha_{\\mathrm{MLT}} $ for the following helium mass fractions: $ Y = 0.26 $, $ Y = 0.27 $, $ Y = 0.28 $, and $ Y = 0.29 $, with $ Z = 0.0134 $ in all cases and $ M = M_{\\odot} $.\n- Compute the sensitivity $ \\left. \\mathrm{d}\\alpha_{\\mathrm{MLT}}/\\mathrm{d}Y \\right|_{Y=0.27} $ using the finite-difference formula above with $ \\Delta Y = 0.01 $.\n- Your program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n  $$ \\big[ \\alpha_{\\mathrm{MLT}}(0.26), \\alpha_{\\mathrm{MLT}}(0.27), \\alpha_{\\mathrm{MLT}}(0.28), \\alpha_{\\mathrm{MLT}}(0.29), \\left. \\mathrm{d}\\alpha_{\\mathrm{MLT}}/\\mathrm{d}Y \\right|_{0.27} \\big], $$\n  where each entry is a floating-point number rounded to six decimal places. No other text may be printed.\n\nScientific realism:\n- The above scalings arise from hydrostatic support with an ideal gas, homology-inspired luminosity scaling for proton-proton burning, and the MLT superadiabatic scaling $ \\Delta \\nabla \\propto F^{2/3} g^{-2/3} \\alpha_{\\mathrm{MLT}}^{-4/3} $. The exponents $ s $, $ \\nu $, and the adiabatic factor $ c $ are chosen to be realistic for solar-type stars. While this is not a full stellar evolution calculation, it captures the leading dependences necessary for the requested calibration and sensitivity analysis.\n\nAnswer specification:\n- The result for each test case must be a float.\n- The final program must implement the model and produce exactly one line with the list of results in the specified order and format.",
            "solution": "The user has provided a computational astrophysics problem that requires the calibration of a reduced-order solar model. The first step is to validate the problem statement.\n\n### Step 1: Extract Givens\nThe problem provides the following data and definitions verbatim:\n- **Fundamental laws**: Hydrostatic equilibrium, ideal-gas equation of state, radiative diffusion, convective transport scaling from Mixing-Length Theory (MLT) ($ \\Delta \\nabla \\propto F^{2/3} g^{-2/3} \\alpha_{\\mathrm{MLT}}^{-4/3} $), and nuclear energy generation ($ \\epsilon \\propto \\rho X^{2} T^{\\nu} $ with $ \\nu = 4 $).\n- **Model specifications**:\n    - Stellar mass $ M = M_{\\odot} $, metallicity $ Z = 0.0134 $.\n    - Hydrogen mass fraction $ X = 1 - Y - Z $.\n    - Mean molecular weight $ \\mu^{-1} = 2 X + \\tfrac{3}{4} Y + \\tfrac{1}{2} Z $.\n    - Baseline composition: $ Y_{\\odot} = 0.27 $, $ Z = 0.0134 $.\n    - Luminosity scaling law: $ \\frac{L}{L_{\\odot}} = \\left( \\frac{X}{X_{\\odot}} \\right)^{2} \\left( \\frac{\\mu}{\\mu_{\\odot}} \\right)^{\\nu} \\left( \\frac{R}{R_{\\odot}} \\right)^{-(\\nu + 3)} $ with $ \\nu = 4 $.\n    - Implicit radius equation: $ \\frac{R}{R_{\\odot}} = c \\left( \\frac{\\mu_{\\odot}}{\\mu} \\right)^{s} \\left[ 1 + B \\left( \\frac{L}{L_{\\odot}} \\right)^{2/3} \\left( \\frac{g}{g_{\\odot}} \\right)^{-2/3} \\left( \\frac{\\alpha_{\\mathrm{MLT}}}{\\alpha_{\\mathrm{ref}}} \\right)^{-4/3} \\right] $.\n    - Parameters for radius equation: $ s = 0.4 $, $ c = 0.98 $, $ \\alpha_{\\mathrm{ref}} = 1.8 $.\n    - Parameter $ B = \\frac{1}{c} - 1 $.\n- **Calibration task**:\n    - Minimize the objective function $ \\Phi(\\alpha_{\\mathrm{MLT}}; Y) = \\left( \\frac{R}{R_{\\odot}} - 1 \\right)^{2} + \\left( \\frac{L}{L_{\\odot}} - 1 \\right)^{2} $.\n    - Minimization search interval for $ \\alpha_{\\mathrm{MLT}} $ is $ [1.0, 3.5] $.\n- **Sensitivity task**:\n    - Compute the finite-difference derivative $ \\left. \\frac{\\mathrm{d}\\alpha_{\\mathrm{MLT}}}{\\mathrm{d}Y} \\right|_{Y=Y_{\\odot}} \\approx \\frac{\\alpha_{\\mathrm{MLT}}(Y_{\\odot} + \\Delta Y) - \\alpha_{\\mathrm{MLT}}(Y_{\\odot} - \\Delta Y)}{2 \\Delta Y} $ with $ \\Delta Y = 0.01 $.\n- **Numerical instructions**:\n    - Implicit radius solver: fixed-point iteration with relative tolerance $ 10^{-12} $ and max $ 200 $ iterations.\n    - Minimization: derivative-free bracketing method with tolerance $ 10^{-8} $ on $ \\alpha_{\\mathrm{MLT}} $ and max $ 200 $ iterations.\n- **Output requirements**:\n    - Compute calibrated $ \\alpha_{\\mathrm{MLT}} $ for $ Y \\in \\{0.26, 0.27, 0.28, 0.29\\} $.\n    - Compute the sensitivity $ \\mathrm{d}\\alpha_{\\mathrm{MLT}}/\\mathrm{d}Y $ at $ Y=0.27 $.\n    - Print a single line: $ \\big[ \\alpha_{\\mathrm{MLT}}(0.26), \\alpha_{\\mathrm{MLT}}(0.27), \\alpha_{\\mathrm{MLT}}(0.28), \\alpha_{\\mathrm{MLT}}(0.29), \\left. \\mathrm{d}\\alpha_{\\mathrm{MLT}}/\\mathrm{d}Y \\right|_{0.27} \\big] $, with floats rounded to six decimal places.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria.\n- **Scientifically Grounded**: The problem is based on simplified but physically-motivated scaling relations (homology relations, mixing-length theory) commonly used in astrophysics for survey-level or pedagogical models. It does not violate fundamental principles but rather approximates their consequences. This is a standard practice in computational science. The problem is sound.\n- **Well-Posed**: The problem is mathematically well-defined. It provides a system of coupled non-linear algebraic equations and a clear objective function to be minimized. All necessary parameters and constants for the model are specified. The numerical methods and their tolerances are also clearly defined.\n- **Objective**: The language is precise, quantitative, and free of subjective claims.\n- **Completeness and Consistency**: The setup is self-consistent. The parameter $ B $ is defined to ensure that the baseline solar model ($ Y=Y_\\odot $, $ \\alpha_{\\mathrm{MLT}}=\\alpha_{\\mathrm{ref}} $) correctly reproduces $ R=R_\\odot $ and $ L=L_\\odot $, which is a verifiable property of the equations. The problem is neither underspecified nor overconstrained.\n- **Feasibility**: The tasks are computationally feasible. The numerical solution involves a nested structure of a 1D root-finder (or fixed-point iteration) within a 1D minimizer, which can be executed rapidly on modern hardware.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, and computationally tractable. It is a valid problem. I will proceed to construct the solution.\n\n### Principle-Based Design\nThe solution is designed by implementing the reduced-order model and the numerical optimization procedures as specified.\n\n**1. Model Formulation:**\nLet $ r = R/R_{\\odot} $ and $ l = L/L_{\\odot} $ be the dimensionless radius and luminosity. The mass is fixed at $ M = M_{\\odot} $. The local gravity scales as $ g = GM/R^2 $, so $ g/g_{\\odot} = (R/R_{\\odot})^{-2} = r^{-2} $.\nThe two governing equations are:\n1. Luminosity-Structure Relation:\n   $$ l = \\left( \\frac{X}{X_{\\odot}} \\right)^{2} \\left( \\frac{\\mu}{\\mu_{\\odot}} \\right)^{\\nu} r^{-(\\nu + 3)} = \\left( \\frac{X}{X_{\\odot}} \\right)^{2} \\left( \\frac{\\mu}{\\mu_{\\odot}} \\right)^{4} r^{-7} $$\n   where $\\nu=4$. $ X $ and $ \\mu $ are functions of the helium mass fraction $ Y $ via $ X = 1 - Y - Z $ and $ \\mu^{-1} = 2X + \\frac{3}{4}Y + \\frac{1}{2}Z $. The baseline values $ X_{\\odot} $ and $ \\mu_{\\odot} $ are computed at $ Y_{\\odot} = 0.27 $.\n2. Radius-Envelope Relation:\n   $$ r = c \\left( \\frac{\\mu_{\\odot}}{\\mu} \\right)^{s} \\left[ 1 + B \\, l^{2/3} (r^{-2})^{-2/3} \\left( \\frac{\\alpha_{\\mathrm{MLT}}}{\\alpha_{\\mathrm{ref}}} \\right)^{-4/3} \\right] = c \\left( \\frac{\\mu_{\\odot}}{\\mu} \\right)^{s} \\left[ 1 + B \\, l^{2/3} r^{4/3} \\left( \\frac{\\alpha_{\\mathrm{MLT}}}{\\alpha_{\\mathrm{ref}}} \\right)^{-4/3} \\right] $$\n   where $ s=0.4 $, $ c=0.98 $, $ B = 1/c - 1 $, and $ \\alpha_{\\mathrm{ref}} = 1.8 $.\n\nFor a given set of input parameters ($ Y $, $ \\alpha_{\\mathrm{MLT}} $), these two equations form a coupled system for $ r $ and $ l $. By substituting the expression for $ l $ into the radius equation, we obtain a single implicit equation for $ r $:\n$$ r = c \\left( \\frac{\\mu_{\\odot}}{\\mu} \\right)^{s} \\left[ 1 + B \\left( \\left( \\frac{X}{X_{\\odot}} \\right)^{2} \\left( \\frac{\\mu}{\\mu_{\\odot}} \\right)^{4} r^{-7} \\right)^{2/3} r^{4/3} \\left( \\frac{\\alpha_{\\mathrm{MLT}}}{\\alpha_{\\mathrm{ref}}} \\right)^{-4/3} \\right] $$\nSimplifying the exponents leads to:\n$$ r = c \\left( \\frac{\\mu_{\\odot}}{\\mu} \\right)^{s} \\left[ 1 + B \\left( \\frac{X}{X_{\\odot}} \\right)^{4/3} \\left( \\frac{\\mu}{\\mu_{\\odot}} \\right)^{8/3} r^{-14/3} r^{4/3} \\left( \\frac{\\alpha_{\\mathrm{MLT}}}{\\alpha_{\\mathrm{ref}}} \\right)^{-4/3} \\right] $$\n$$ r = c \\left( \\frac{\\mu_{\\odot}}{\\mu} \\right)^{s} \\left[ 1 + B \\left( \\frac{X}{X_{\\odot}} \\right)^{4/3} \\left( \\frac{\\mu}{\\mu_{\\odot}} \\right)^{8/3} \\left( \\frac{\\alpha_{\\mathrm{MLT}}}{\\alpha_{\\mathrm{ref}}} \\right)^{-4/3} r^{-10/3} \\right] $$\nThis non-linear equation for $ r $ can be written as $ r = F(r) $ and solved using fixed-point iteration, as specified. Let $ r_0 = 1.0 $. The iterative scheme is $ r_{k+1} = (1-\\omega)r_k + \\omega F(r_k) $, where $ \\omega $ is an under-relaxation factor (e.g., $ \\omega=0.5 $) to enhance stability. The iteration continues until the relative difference $ |(r_{k+1} - r_k)/r_k| $ is below the tolerance $ 10^{-12} $. Once $ r $ is found, $ l $ is computed directly.\n\n**2. Calibration Procedure:**\nThe calibration objective is to find the mixing-length parameter $ \\alpha_{\\mathrm{MLT}} $ for a given $ Y $ that minimizes the function:\n$$ \\Phi(\\alpha_{\\mathrm{MLT}}; Y) = (r - 1)^2 + (l - 1)^2 $$\nThis is a one-dimensional optimization problem. We will implement the Golden-Section Search algorithm, a derivative-free bracketing method, to find the minimum of $ \\Phi $ within the interval $ \\alpha_{\\mathrm{MLT}} \\in [1.0, 3.5] $. The search terminates when the interval width is less than the tolerance $ 10^{-8} $.\n\n**3. Sensitivity Analysis:**\nThe sensitivity of the calibrated $ \\alpha_{\\mathrm{MLT}} $ to $ Y $ is calculated using a second-order central finite-difference approximation:\n$$ \\frac{\\mathrm{d}\\alpha_{\\mathrm{MLT}}}{\\mathrm{d}Y} \\approx \\frac{\\alpha_{\\mathrm{MLT}}(Y_{\\odot} + \\Delta Y) - \\alpha_{\\mathrm{MLT}}(Y_{\\odot} - \\Delta Y)}{2 \\Delta Y} $$\nWith $ Y_{\\odot} = 0.27 $ and $ \\Delta Y = 0.01 $, this requires computing the calibrated $ \\alpha_{\\mathrm{MLT}} $ for $ Y = 0.28 $ and $ Y=0.26 $. These are already required by the test suite.\n\n**4. Implementation details:**\nA Python script will be developed. All parameters and constants are defined at the beginning. A function `evaluate_model(alpha_mlt, Y)` will solve for $ r $ and $ l $. A function `objective_function(alpha_mlt, Y)` will compute $ \\Phi $. The `golden_section_search` function will perform the minimization. The main part of the script will loop through the specified $ Y $ values, call the optimizer, collect the results, compute the sensitivity, and print the final output in the required format. The calculation for $Y=0.27$ serves as a validation check, as the result must be $ \\alpha_{\\mathrm{MLT}} = \\alpha_{\\mathrm{ref}} = 1.8 $.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to solve the stellar model calibration problem.\n    \"\"\"\n\n    class ModelParameters:\n        \"\"\"\n        Container for model parameters and constants.\n        All calculations are dimensionless, so physical constants are not used directly.\n        \"\"\"\n        def __init__(self):\n            # Model definition parameters\n            self.Z = 0.0134\n            self.nu = 4.0\n            self.s = 0.4\n            self.c = 0.98\n            self.alpha_ref = 1.8\n            self.B = 1.0 / self.c - 1.0\n\n            # Baseline solar composition\n            self.Y_sun = 0.27\n            self.X_sun = 1.0 - self.Y_sun - self.Z\n            self.mu_sun = 1.0 / (2.0 * self.X_sun + 0.75 * self.Y_sun + 0.5 * self.Z)\n\n    params = ModelParameters()\n\n    memoized_model_results = {}\n\n    def get_composition(Y, Z):\n        \"\"\"Calculate X and mu for a given Y and Z.\"\"\"\n        X = 1.0 - Y - Z\n        mu = 1.0 / (2.0 * X + 0.75 * Y + 0.5 * Z)\n        return X, mu\n\n    def evaluate_model(alpha_mlt, Y, p):\n        \"\"\"\n        For a given alpha_mlt and Y, solve for the dimensionless radius and luminosity.\n        \"\"\"\n        key = (alpha_mlt, Y)\n        if key in memoized_model_results:\n            return memoized_model_results[key]\n\n        # Numerical parameters for the iterative solver\n        r_tol = 1e-12\n        max_iter_r = 200\n        omega = 0.5  # Under-relaxation factor\n\n        # Composition for the given Y\n        X, mu = get_composition(Y, p.Z)\n\n        # Pre-calculate terms for the radius equation\n        mu_ratio = mu / p.mu_sun\n        X_ratio = X / p.X_sun\n        alpha_ratio = alpha_mlt / p.alpha_ref\n        \n        # Coefficients for the implicit radius equation: r = term_A * (1 + term_B * r**(-10/3))\n        term_A = p.c * (1.0 / mu_ratio)**p.s\n        term_B = p.B * X_ratio**(4.0/3.0) * mu_ratio**(8.0/3.0) * alpha_ratio**(-4.0/3.0)\n\n        # Iteratively solve for r using fixed-point iteration with under-relaxation\n        r = 1.0  # Initial guess\n        for _ in range(max_iter_r):\n            r_old = r\n            if r_old == 0:  # Avoid division by zero\n                r = r_tol\n                continue\n\n            r_guess = term_A * (1.0 + term_B * r_old**(-10.0/3.0))\n            r = (1.0 - omega) * r_old + omega * r_guess\n            \n            if abs((r - r_old) / r_old)  r_tol:\n                break\n        \n        # Calculate l from the converged r\n        l = X_ratio**2 * mu_ratio**p.nu * r**(-(p.nu + 3.0))\n        \n        memoized_model_results[key] = (r, l)\n        return r, l\n\n    def objective_function(alpha_mlt, Y, p):\n        \"\"\"\n        Objective function to be minimized.\n        \"\"\"\n        r, l = evaluate_model(alpha_mlt, Y, p)\n        return (r - 1.0)**2 + (l - 1.0)**2\n\n    def golden_section_search(f, a, b, args=(), tol=1e-8, max_iter=200):\n        \"\"\"\n        Golden-section search to find the minimum of a 1D function.\n        \"\"\"\n        inv_phi = (np.sqrt(5) - 1) / 2  # 1/phi\n        inv_phi_sq = (3 - np.sqrt(5)) / 2 # 1/phi^2\n\n        h = b - a\n        c = a + inv_phi_sq * h\n        d = a + inv_phi * h\n        yc = f(c, *args)\n        yd = f(d, *args)\n\n        for _ in range(max_iter - 1):\n            if yc  yd:\n                b = d\n                d = c\n                yd = yc\n                h = b - a\n                c = a + inv_phi_sq * h\n                yc = f(c, *args)\n            else:\n                a = c\n                c = d\n                yc = yd\n                h = b - a\n                d = a + inv_phi * h\n                yd = f(d, *args)\n            \n            if h  tol:\n                break\n        \n        return (a + b) / 2\n\n    # --- Main computation ---\n    \n    test_cases = [0.26, 0.27, 0.28, 0.29]\n    alpha_min = 1.0\n    alpha_max = 3.5\n\n    calibrated_alphas = []\n    for y_val in test_cases:\n        alpha_opt = golden_section_search(\n            objective_function, \n            alpha_min, \n            alpha_max, \n            args=(y_val, params)\n        )\n        calibrated_alphas.append(alpha_opt)\n\n    # Compute sensitivity using central difference\n    d_alpha_dY = (calibrated_alphas[2] - calibrated_alphas[0]) / (2.0 * 0.01)\n\n    # Prepare final results list\n    final_results = calibrated_alphas + [d_alpha_dY]\n    \n    # Format and print output\n    output_str = \",\".join([f\"{res:.6f}\" for res in final_results])\n    print(f\"[{output_str}]\")\n\n\nsolve()\n```"
        },
        {
            "introduction": "A stellar evolution code is a tapestry woven from various physical modules, many of which rely on pre-computed data tables for quantities like the equation of state or radiative opacity. This practice focuses on the critical task of interpolating these tables accurately, a challenge made difficult by the sharp features present in the data, such as ionization edges in opacity. You will design and compare a simple bilinear interpolator with a more sophisticated, monotonicity-preserving cubic scheme, quantifying their performance against a known analytical function. This exercise will highlight the sources of numerical error and demonstrate why robust interpolation is essential for preventing unphysical artifacts in simulations. ",
            "id": "3534104",
            "problem": "Consider radiative opacity tables such as those provided by the Opacity Project at Livermore (OPAL), which tabulate the mass absorption coefficient $\\kappa$ (with units $\\mathrm{cm^2\\,g^{-1}}$) as a function of $\\log_{10} T$ (temperature in Kelvin) and $\\log_{10} R$ where $R$ is a density-temperature composite variable. In numerical stellar evolution, opacities are evaluated from these tables at arbitrary points $(\\log_{10} T, \\log_{10} R)$ by interpolation. Near ionization edges with rapid variation in $\\kappa$, it is critical to avoid introducing spurious extrema due to interpolation. Design and implement both a bilinear interpolation and a monotonicity-preserving bicubic-like interpolation based on one-dimensional monotone cubic Hermite interpolation constructed in tensor-product fashion.\n\nTo make the problem self-contained and to quantify interpolation errors, use the following physically plausible synthetic \"solar composition\" opacity model as the ground truth. For hydrogen mass fraction $X=0.70$, helium mass fraction $Y=0.28$, and metal mass fraction $Z=0.02$, define for $x = \\log_{10} T$ and $y = \\log_{10} R$ the true $\\log_{10} \\kappa$ by\n$$\n\\log_{10}\\kappa(x,y) = \\log_{10}\\left(A (1+X)\\right) + y - 3.5 x + \\sum_{i=1}^{4} a_i \\exp\\!\\left(-\\left(\\frac{x - x_i}{w_i}\\right)^2\\right)\\left(1 + \\beta_i\\,\\tanh\\!\\left(\\gamma_i\\, y\\right)\\right),\n$$\nwhere $A = 10^{24}$, with four Gaussian-like enhancements modeling ionization edges centered at\n$$\nx_1 = 3.90 \\quad (\\text{Hydrogen}), \\quad x_2 = 4.20 \\quad (\\text{Helium I}), \\quad x_3 = 4.60 \\quad (\\text{Helium II}), \\quad x_4 = 4.90 \\quad (\\text{Metals}),\n$$\nand amplitudes and widths given by\n$$\na_1 = 0.30,\\; w_1 = 0.035,\\;\\beta_1 = 0.2,\\;\\gamma_1=0.8;\\quad\na_2 = 0.25,\\; w_2 = 0.040,\\;\\beta_2 = 0.15,\\;\\gamma_2=0.8;\n$$\n$$\na_3 = 0.20,\\; w_3 = 0.045,\\;\\beta_3 = 0.10,\\;\\gamma_3=0.8;\\quad\na_4 = 0.15 \\frac{Z}{0.02},\\; w_4 = 0.060,\\;\\beta_4 = 0.25,\\;\\gamma_4=0.8.\n$$\nThis model combines a Kramers-law-like baseline (free-free opacity scaling $\\propto R\\,T^{-3.5}$) with smooth, narrow enhancements to mimic ionization edges. All logarithms are base $10$.\n\nConstruct a rectangular opacity table on the coarse grid\n$$\nx \\in [3.75, 5.00],\\quad y \\in [-7.0, -2.0],\n$$\nwith $N_x = 16$ equispaced points in $x$ and $N_y = 11$ equispaced points in $y$. Compute the table values as $\\log_{10} \\kappa(x_i,y_j)$ by evaluating the synthetic truth above at each grid node.\n\nImplement two interpolators from this table:\n- A bilinear interpolator derived from linear interpolation along each axis, producing an estimate $\\tilde{f}_{\\mathrm{bilin}}(x_q,y_q)$ at test query $(x_q,y_q)$ by convex combination of the four surrounding cell-corner values.\n- A monotonicity-preserving bicubic-like interpolator $\\tilde{f}_{\\mathrm{mono}}(x_q,y_q)$ constructed as follows: for fixed $y$, interpolate $x \\mapsto \\log_{10}\\kappa(x,y)$ at $x_q$ using monotone cubic Hermite interpolation that preserves monotonicity of the tabulated values along $x$; then, using the set of intermediate values indexed by $y$, interpolate along $y$ at $y_q$ with the same monotone cubic Hermite method. The method must not introduce new extrema along either axis compared to the tabulated data. Implement this using a standard monotone piecewise cubic Hermite interpolator.\n\nUsing these two interpolators, evaluate and compare absolute interpolation errors near ionization edges by computing\n$$\ne_{\\mathrm{bilin}} = \\left|\\tilde{f}_{\\mathrm{bilin}}(x_q,y_q) - \\log_{10}\\kappa(x_q,y_q)\\right|,\\quad\ne_{\\mathrm{mono}} = \\left|\\tilde{f}_{\\mathrm{mono}}(x_q,y_q) - \\log_{10}\\kappa(x_q,y_q)\\right|,\n$$\nfor the following eight test queries $(x_q,y_q)$:\n1. $x_q = 3.90$, $y_q = -5.00$ (center of hydrogen ionization bump),\n2. $x_q = 3.92$, $y_q = -6.00$ (steep gradient region near hydrogen bump),\n3. $x_q = 4.20$, $y_q = -4.00$ (center of helium I bump),\n4. $x_q = 4.60$, $y_q = -6.50$ (center of helium II bump),\n5. $x_q = 4.80$, $y_q = -3.00$ (smooth baseline region),\n6. $x_q = 3.76$, $y_q = -2.10$ (near low-$x$ and high-$y$ boundary),\n7. $x_q = 4.99$, $y_q = -6.90$ (near high-$x$ and low-$y$ boundary),\n8. $x_q = 4.23$, $y_q = -5.50$ (off-center near helium I bump).\n\nAll errors must be expressed in decimal logarithmic units (dex), which are dimensionless. Angles do not appear in this problem. Your program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$\n\\left[e_{\\mathrm{bilin}}^{(1)}, e_{\\mathrm{mono}}^{(1)}, e_{\\mathrm{bilin}}^{(2)}, e_{\\mathrm{mono}}^{(2)}, \\ldots, e_{\\mathrm{bilin}}^{(8)}, e_{\\mathrm{mono}}^{(8)}\\right].\n$$\n\nThe design must start from first principles of numerical interpolation and physically motivated opacity behavior, and must ensure scientific realism. No user input or external files are permitted; all computations are to be performed within the program.",
            "solution": "The problem is first validated against the specified criteria.\n- **Scientific Grounding**: The problem is scientifically sound. It uses a physically-motivated synthetic opacity function that models Kramers' law and ionization edges, which are established concepts in stellar astrophysics. The task involves applying standard numerical interpolation techniques, a core practice in computational science.\n- **Well-Posedness**: The problem is well-posed. All parameters, functions, and evaluation points are explicitly defined, leading to a unique set of numerical results.\n- **Objectivity**: The problem is stated in precise, objective, and quantitative terms.\n- **Completeness and Consistency**: The problem is self-contained, providing all necessary data and definitions. There are no apparent contradictions.\n- **Realism**: The scenario represents a simplified but realistic challenge encountered in computational stellar evolution, where tabulated physical data must be interpolated accurately and robustly.\n\nThe problem is deemed valid. A solution will now be provided.\n\nThe objective is to implement and compare two different two-dimensional interpolation schemes, bilinear and a monotonicity-preserving bicubic-like method, for interpolating stellar opacity data. The accuracy of these methods will be quantified by comparing their results against a known analytical \"ground truth\" model, particularly in regions of rapid variation corresponding to ionization edges. All logarithms are base $10$.\n\nFirst, we define the synthetic \"ground truth\" model for the Rosseland mean opacity, $\\kappa$. The model provides $\\log_{10} \\kappa$ as a function of $x = \\log_{10} T$ (where $T$ is temperature in Kelvin) and $y = \\log_{10} R$ (where $R$ is a density-temperature variable defined as $\\rho / T_6^3$, with $\\rho$ in $\\mathrm{g\\,cm^{-3}}$ and $T_6$ in units of $10^6 \\mathrm{K}$). The composition is fixed with hydrogen mass fraction $X=0.70$, helium mass fraction $Y=0.28$, and metal mass fraction $Z=0.02$.\n\nThe function for $\\log_{10}\\kappa$ is given by:\n$$\n\\log_{10}\\kappa(x,y) = \\log_{10}\\left(A (1+X)\\right) + y - 3.5 x + \\sum_{i=1}^{4} a_i \\exp\\!\\left(-\\left(\\frac{x - x_i}{w_i}\\right)^2\\right)\\left(1 + \\beta_i\\,\\tanh\\!\\left(\\gamma_i\\, y\\right)\\right)\n$$\nThis model is comprised of a baseline term, $\\log_{10}(A(1+X)) + y - 3.5x$, which represents the Kramers' law scaling for free-free opacity, $\\kappa \\propto R T^{-3.5}$. Superimposed on this are four Gaussian-like peaks that model the significant increase in opacity due to the ionization of hydrogen, helium I, helium II, and a representative metal species. The parameters are:\n- Constant: $A = 10^{24}$\n- Peak centers (in $\\log_{10} T$): $x_1 = 3.90$ (H), $x_2 = 4.20$ (He I), $x_3 = 4.60$ (He II), $x_4 = 4.90$ (Metals).\n- Peak parameters (amplitudes $a_i$, widths $w_i$, and density-dependence modifiers $\\beta_i, \\gamma_i$):\n  - $a_1 = 0.30$, $w_1 = 0.035$, $\\beta_1 = 0.2$, $\\gamma_1=0.8$\n  - $a_2 = 0.25$, $w_2 = 0.040$, $\\beta_2 = 0.15$, $\\gamma_2=0.8$\n  - $a_3 = 0.20$, $w_3 = 0.045$, $\\beta_3 = 0.10$, $\\gamma_3=0.8$\n  - $a_4 = 0.15 \\frac{Z}{0.02} = 0.15$, $w_4 = 0.060$, $\\beta_4 = 0.25$, $\\gamma_4=0.8$\n\nA discrete opacity table, $f_{ij} = \\log_{10}\\kappa(x_i, y_j)$, is constructed on a coarse rectangular grid defined by:\n- $x \\in [3.75, 5.00]$ with $N_x = 16$ equispaced points ($x_i$).\n- $y \\in [-7.0, -2.0]$ with $N_y = 11$ equispaced points ($y_j$).\n\nWe will implement two methods to interpolate within this table. Let a query point be $(x_q, y_q)$ which lies in the grid cell defined by the corners $(x_i, y_j)$, $(x_{i+1}, y_j)$, $(x_i, y_{j+1})$, and $(x_{i+1}, y_{j+1})$. Let the corresponding function values at these corners be $f_{i,j}$, $f_{i+1,j}$, $f_{i,j+1}$, and $f_{i+1,j+1}$.\n\n1.  **Bilinear Interpolation**\nThis method approximates the function within a grid cell as a surface that is linear in each direction. It is equivalent to performing three linear interpolations. First, we interpolate along the $x$-direction at the lower and upper $y$-boundaries of the cell:\n$$\nf(x_q, y_j) \\approx \\frac{x_{i+1} - x_q}{x_{i+1} - x_i} f_{i,j} + \\frac{x_q - x_i}{x_{i+1} - x_i} f_{i+1,j}\n$$\n$$\nf(x_q, y_{j+1}) \\approx \\frac{x_{i+1} - x_q}{x_{i+1} - x_i} f_{i,j+1} + \\frac{x_q - x_i}{x_{i+1} - x_i} f_{i+1,j+1}\n$$\nThen, we interpolate linearly in the $y$-direction between these two intermediate values to find the final value at $(x_q, y_q)$:\n$$\n\\tilde{f}_{\\mathrm{bilin}}(x_q, y_q) \\approx \\frac{y_{j+1} - y_q}{y_{j+1} - y_j} f(x_q, y_j) + \\frac{y_q - y_j}{y_{j+1} - y_j} f(x_q, y_{j+1})\n$$\nThis scheme is continuous ($C^0$) but its derivatives are discontinuous at cell boundaries. This can lead to unphysical kinks in the interpolated function and relatively low accuracy.\n\n2.  **Monotonicity-Preserving Bicubic-like Interpolation**\nNear the sharp ionization edges, a simple bilinear interpolation can be inaccurate, while standard bicubic spline interpolation can introduce spurious oscillations (overshoots/undershoots), which are physically nonsensical. A more robust approach is a Piecewise Cubic Hermite Interpolating Polynomial (PCHIP) that preserves the monotonicity of the original data. A 2D interpolator is constructed via a tensor product of 1D PCHIP interpolators. The procedure is as follows:\n- **Step 1: Interpolation along the $x$-axis.** For each grid line corresponding to a constant $y_j$ (for $j=0, \\dots, N_y-1$), we construct a 1D PCHIP interpolator for the data points $(x_i, f_{i,j})$. This yields $N_y$ separate 1D interpolating functions. We evaluate each of these at $x_q$ to obtain a set of intermediate values, $\\{ v_j = \\tilde{f}(x_q, y_j) \\}_{j=0}^{N_y-1}$.\n- **Step 2: Interpolation along the $y$-axis.** We now have a new 1D dataset consisting of points $(y_j, v_j)$. We construct a final 1D PCHIP interpolator for this dataset and evaluate it at $y_q$ to obtain the final interpolated value, $\\tilde{f}_{\\mathrm{mono}}(x_q, y_q)$.\n\nThis method ensures that if the table data is monotonic along an axis within a segment, the interpolated values along that axis will also be monotonic. It provides $C^1$ continuity and is generally more accurate than bilinear interpolation, without the risk of unphysical oscillations associated with standard cubic splines.\n\nFinally, we will evaluate the absolute interpolation error for both methods at eight specified query points $(x_q^{(k)}, y_q^{(k)})$:\n$$\ne_{\\mathrm{bilin}}^{(k)} = \\left|\\tilde{f}_{\\mathrm{bilin}}(x_q^{(k)},y_q^{(k)}) - \\log_{10}\\kappa(x_q^{(k)},y_q^{(k)})\\right|\n$$\n$$\ne_{\\mathrm{mono}}^{(k)} = \\left|\\tilde{f}_{\\mathrm{mono}}(x_q^{(k)},y_q^{(k)}) - \\log_{10}\\kappa(x_q^{(k)},y_q^{(k)})\\right|\n$$\nThese errors, expressed in dimensionless logarithmic units (dex), will be computed and reported.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import PchipInterpolator\n\ndef solve():\n    \"\"\"\n    Implements and compares bilinear and monotonicity-preserving bicubic-like interpolation\n    for a synthetic stellar opacity model.\n    \"\"\"\n    \n    # --------------------------------------------------------------------------\n    # 1. Define the synthetic opacity model (ground truth)\n    # --------------------------------------------------------------------------\n    X, Y, Z = 0.70, 0.28, 0.02\n    A = 1e24\n    \n    # Gaussian-like enhancement parameters for ionization edges\n    params = [\n        # H ionization\n        {'x_i': 3.90, 'a_i': 0.30, 'w_i': 0.035, 'beta_i': 0.2, 'gamma_i': 0.8},\n        # He I ionization\n        {'x_i': 4.20, 'a_i': 0.25, 'w_i': 0.040, 'beta_i': 0.15, 'gamma_i': 0.8},\n        # He II ionization\n        {'x_i': 4.60, 'a_i': 0.20, 'w_i': 0.045, 'beta_i': 0.10, 'gamma_i': 0.8},\n        # Metals ionization\n        {'x_i': 4.90, 'a_i': 0.15 * (Z / 0.02), 'w_i': 0.060, 'beta_i': 0.25, 'gamma_i': 0.8},\n    ]\n    \n    def log_kappa_true(x, y):\n        \"\"\"\n        Calculates the true log10(kappa) from the synthetic model.\n        x = log10(T), y = log10(R)\n        \"\"\"\n        baseline = np.log10(A * (1.0 + X)) + y - 3.5 * x\n        enhancements = 0.0\n        for p in params:\n            gauss_term = np.exp(-((x - p['x_i']) / p['w_i'])**2)\n            tanh_term = 1.0 + p['beta_i'] * np.tanh(p['gamma_i'] * y)\n            enhancements += p['a_i'] * gauss_term * tanh_term\n        return baseline + enhancements\n\n    # --------------------------------------------------------------------------\n    # 2. Construct the coarse opacity table\n    # --------------------------------------------------------------------------\n    Nx, Ny = 16, 11\n    x_grid = np.linspace(3.75, 5.00, Nx)\n    y_grid = np.linspace(-7.0, -2.0, Ny)\n    \n    # Note: np.meshgrid with default indexing='xy' creates X of shape (Ny, Nx)\n    # This means Z_table[j, i] corresponds to (x_grid[i], y_grid[j])\n    X_mesh, Y_mesh = np.meshgrid(x_grid, y_grid)\n    Z_table = log_kappa_true(X_mesh, Y_mesh)\n\n    # --------------------------------------------------------------------------\n    # 3. Implement the interpolators\n    # --------------------------------------------------------------------------\n    \n    def bilinear_interp(xq, yq, x_grid, y_grid, Z_table):\n        \"\"\"Performs bilinear interpolation on the grid.\"\"\"\n        # Find cell indices\n        ix = np.searchsorted(x_grid, xq) - 1\n        iy = np.searchsorted(y_grid, yq) - 1\n        \n        # Clamp indices to be within the grid bounds for interpolation\n        ix = np.clip(ix, 0, len(x_grid) - 2)\n        iy = np.clip(iy, 0, len(y_grid) - 2)\n        \n        # Grid points for the cell\n        x1, x2 = x_grid[ix], x_grid[ix+1]\n        y1, y2 = y_grid[iy], y_grid[iy+1]\n        \n        # Values at the four corners of the cell\n        # Z_table is indexed (y, x)\n        z11 = Z_table[iy, ix]\n        z12 = Z_table[iy+1, ix]\n        z21 = Z_table[iy, ix+1]\n        z22 = Z_table[iy+1, ix+1]\n        \n        # Normalized coordinates\n        tx = (xq - x1) / (x2 - x1)\n        ty = (yq - y1) / (y2 - y1)\n        \n        # Interpolate\n        interp_val = (z11 * (1 - tx) * (1 - ty) +\n                      z21 * tx * (1 - ty) +\n                      z12 * (1 - tx) * ty +\n                      z22 * tx * ty)\n                      \n        return interp_val\n\n    def monotonic_interp(xq, yq, x_grid, y_grid, Z_table):\n        \"\"\"Performs monotonicity-preserving bicubic-like interpolation.\"\"\"\n        # Step 1: Interpolate along x for each y_j\n        y_interp_values = np.zeros(len(y_grid))\n        for j in range(len(y_grid)):\n            # Z_table[j, :] is the slice at y_grid[j]\n            pchip_x = PchipInterpolator(x_grid, Z_table[j, :])\n            y_interp_values[j] = pchip_x(xq)\n            \n        # Step 2: Interpolate along y using the intermediate values\n        pchip_y = PchipInterpolator(y_grid, y_interp_values)\n        final_value = pchip_y(yq)\n        \n        return final_value\n\n    # --------------------------------------------------------------------------\n    # 4. Evaluate errors at test query points\n    # --------------------------------------------------------------------------\n    test_cases = [\n        (3.90, -5.00),  # 1. center of hydrogen ionization bump\n        (3.92, -6.00),  # 2. steep gradient region near hydrogen bump\n        (4.20, -4.00),  # 3. center of helium I bump\n        (4.60, -6.50),  # 4. center of helium II bump\n        (4.80, -3.00),  # 5. smooth baseline region\n        (3.76, -2.10),  # 6. near low-x and high-y boundary\n        (4.99, -6.90),  # 7. near high-x and low-y boundary\n        (4.23, -5.50),  # 8. off-center near helium I bump\n    ]\n\n    results = []\n    for xq, yq in test_cases:\n        true_val = log_kappa_true(xq, yq)\n        \n        bilin_val = bilinear_interp(xq, yq, x_grid, y_grid, Z_table)\n        mono_val = monotonic_interp(xq, yq, x_grid, y_grid, Z_table)\n        \n        e_bilin = np.abs(bilin_val - true_val)\n        e_mono = np.abs(mono_val - true_val)\n        \n        results.extend([e_bilin, e_mono])\n\n    # --------------------------------------------------------------------------\n    # 5. Format and print the final output\n    # --------------------------------------------------------------------------\n    output_str = f\"[{','.join(f'{r:.8f}' for r in results)}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "The \"evolution\" in stellar evolution arises from coupling various physical processes—such as nuclear burning, energy transport, and chemical mixing—that often operate on vastly different timescales. This practice delves into the core numerical strategies for handling such multi-physics problems by comparing two competing paradigms: monolithic and operator-splitting methods. By implementing both to solve a representative reaction-diffusion system, you will conduct a numerical experiment to measure the accuracy and computational cost of each approach. This will provide invaluable insight into the concept of splitting error and the fundamental trade-offs between solver complexity, efficiency, and fidelity that guide the architectural design of modern simulation codes. ",
            "id": "3534097",
            "problem": "Construct a complete, runnable program that performs a controlled numerical experiment on a linear reaction–diffusion system representative of simplified stellar interior composition transport, to quantify operator-splitting error versus timestep and to compare accuracy and an operation-count cost proxy against a monolithic implicit solve. The program must implement and compare a Strang-split method and a monolithic backward Euler method for a linear two-species reaction–diffusion problem on a periodic domain, and must compute their errors against an exact discrete reference obtained by a numerically computed matrix exponential. Use dimensionless units throughout.\n\nStart from the following foundational principles and definitions. Consider two scalar fields $u(x,t)$ and $v(x,t)$ evolved by Fickian diffusion and linear mass-action kinetics on a periodic interval of length $L$. Let $D_u$ and $D_v$ be positive diffusion coefficients, and let the reversible linear reaction $u \\rightleftharpoons v$ have forward and backward rate constants $k_{1}$ and $k_{2}$. The continuous governing equations are the reaction–diffusion system\n$$\n\\frac{\\partial u}{\\partial t} = D_u \\frac{\\partial^2 u}{\\partial x^2} - k_1 u + k_2 v,\n\\qquad\n\\frac{\\partial v}{\\partial t} = D_v \\frac{\\partial^2 v}{\\partial x^2} + k_1 u - k_2 v,\n$$\nwith periodic boundary conditions in $x$.\n\nDiscretize space using a uniform grid with $N$ points over the interval $[0,L)$, grid spacing $\\Delta x = L/N$, and the standard second-order centered finite-difference Laplacian with periodic wrap, so that for a grid function $w_i \\approx w(x_i)$, the discrete Laplacian operator $\\mathcal{L}$ acts as\n$$\n(\\mathcal{L} w)_i = \\frac{w_{i+1} - 2 w_i + w_{i-1}}{\\Delta x^2},\n$$\nwhere indices are taken modulo $N$. Stack the species into a single state vector $U \\in \\mathbb{R}^{2N}$ in the order $U = [u_0, u_1, \\ldots, u_{N-1}, v_0, v_1, \\ldots, v_{N-1}]^{\\mathsf{T}}$. Then the semi-discrete system is a linear ordinary differential equation (ODE) of the form\n$$\n\\frac{\\mathrm{d}U}{\\mathrm{d}t} = A U,\n$$\nwhere the system matrix $A \\in \\mathbb{R}^{2N \\times 2N}$ is\n$$\nA = \\begin{bmatrix}\nD_u \\mathcal{L} - k_1 I_N  k_2 I_N \\\\\nk_1 I_N  D_v \\mathcal{L} - k_2 I_N\n\\end{bmatrix},\n$$\nwith $I_N$ the $N \\times N$ identity matrix and $\\mathcal{L}$ the $N \\times N$ discrete Laplacian matrix with periodic boundary conditions.\n\nImplement the following time integrators over a final time $T$ using a timestep $\\Delta t$ with $T/\\Delta t$ an integer:\n\n- Monolithic backward Euler (implicit) for the full coupled system,\n$$\n\\left(I_{2N} - \\Delta t \\, A\\right) U^{n+1} = U^n,\n$$\napplied for $n = 0,1,\\ldots, T/\\Delta t - 1$.\n\n- Strang splitting between reaction and diffusion. Define the reaction-only operator $R \\in \\mathbb{R}^{2 \\times 2}$ at a single grid point as\n$$\nR = \\begin{bmatrix}\n- k_1  k_2 \\\\\nk_1  -k_2\n\\end{bmatrix}.\n$$\nA Strang-split step of size $\\Delta t$ advances $U^n \\mapsto U^{n+1}$ by\n  1. Half reaction: at each grid point $i$, update the local two-vector $[u_i, v_i]^{\\mathsf{T}} \\leftarrow \\exp\\!\\left(\\tfrac{\\Delta t}{2} R\\right) [u_i, v_i]^{\\mathsf{T}}$.\n  2. Full diffusion implicit by backward Euler separately for each species:\n  $$\n  \\left(I_N - \\Delta t \\, D_u \\mathcal{L}\\right) u \\leftarrow u, \\qquad \\left(I_N - \\Delta t \\, D_v \\mathcal{L}\\right) v \\leftarrow v,\n  $$\n  where each line denotes solving a linear system for the updated species.\n  3. Half reaction again as in step $1$.\n\nUse as the exact discrete reference the matrix exponential solution $U(T) = \\exp(T A) U(0)$, computed numerically by a reliable matrix exponential routine.\n\nUse the following fixed parameters and initial condition, in dimensionless units: $L = 1$, $N = 32$, $D_u = 10^{-3}$, $D_v = 5 \\times 10^{-4}$, $k_1 = 40$, $k_2 = 10$, and $T = 5 \\times 10^{-2}$. Initialize\n$$\nu(x,0) = 1 + 10^{-1} \\sin\\!\\left(2 \\pi x / L\\right), \\qquad v(x,0) = 0,\n$$\nsampled on the grid points $x_i = i \\Delta x$ for $i = 0,1,\\ldots,N-1$.\n\nQuantify the error at $t = T$ for each method by the discrete $\\ell^2$-norm over both species and the grid,\n$$\nE = \\left(\\Delta x \\sum_{i=0}^{N-1} \\left[ \\left(u_i^{\\mathrm{num}} - u_i^{\\mathrm{ref}}\\right)^2 + \\left(v_i^{\\mathrm{num}} - v_i^{\\mathrm{ref}}\\right)^2 \\right]\\right)^{1/2},\n$$\nwhere the reference $(u^{\\mathrm{ref}}, v^{\\mathrm{ref}})$ is obtained from $U(T) = \\exp(T A) U(0)$.\n\nQuantify the computational cost by a proxy operation count that counts dense linear solves per step with cubic complexity in the dimension of the system being solved, and ignores costs that are strictly linear in $N$. Specifically, define the per-step cost of the monolithic implicit method as $(2N)^3$, and the per-step cost of the Strang-split method as $2 N^3$ (one backward Euler solve of size $N$ per species). The total cost is the per-step cost multiplied by the number of steps $T/\\Delta t$.\n\nDesign a test suite over three timesteps to assess splitting error versus timestep and to compare accuracy and cost across scales:\n- Case A: $\\Delta t = 5 \\times 10^{-4}$,\n- Case B: $\\Delta t = 5 \\times 10^{-3}$,\n- Case C: $\\Delta t = 5 \\times 10^{-2}$.\n\nFor each case, compute and report a list of four floats in the order $[E_{\\text{split}}, E_{\\text{mono}}, C_{\\text{split}}, C_{\\text{mono}}]$, where $E_{\\text{split}}$ is the Strang-split error, $E_{\\text{mono}}$ is the monolithic backward Euler error, $C_{\\text{split}}$ is the total cost proxy for the Strang-split method, and $C_{\\text{mono}}$ is the total cost proxy for the monolithic method, all at $t = T$.\n\nYour program should produce a single line of output containing the results for the three cases as a comma-separated list of the three per-case lists enclosed in square brackets (for example, a list of lists like $[[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot]]$). Because the problem is dimensionless, no physical unit conversion is required, and all reported values must be plain floating-point numbers.",
            "solution": "The user-provided problem is a well-posed numerical experiment designed to compare the accuracy and computational cost of two different time integration schemes for a linear reaction–diffusion system. The problem is scientifically grounded, mathematically precise, and contains all necessary information for a unique solution. Therefore, the problem is deemed valid. We proceed with a full solution.\n\n### 1. System Discretization and Matrix Formulation\n\nFirst, we discretize the continuous governing equations on a uniform periodic grid. The state of the system is described by a single vector $U \\in \\mathbb{R}^{2N}$, which concatenates the concentration values of the two species, $u$ and $v$, at each of the $N$ grid points: $U = [u_0, u_1, \\ldots, u_{N-1}, v_0, v_1, \\ldots, v_{N-1}]^{\\mathsf{T}}$. The spatial derivatives are approximated using a second-order centered finite-difference scheme. This results in a discrete Laplacian operator, represented by an $N \\times N$ matrix $\\mathcal{L}$. Given the periodic boundary conditions, $\\mathcal{L}$ is a circulant matrix. Specifically, for a grid spacing of $\\Delta x = L/N$, the entries of $\\mathcal{L}$ are $(\\mathcal{L})_{i,i} = -2/\\Delta x^2$, $(\\mathcal{L})_{i,i\\pm 1} = 1/\\Delta x^2$ (with indices taken modulo $N$).\n\nThe full semi-discrete system can be written as $\\frac{\\mathrm{d}U}{\\mathrm{d}t} = AU$. The system matrix $A \\in \\mathbb{R}^{2N \\times 2N}$ is a block matrix composed of the diffusion and reaction operators:\n$$\nA = \\begin{bmatrix}\nD_u \\mathcal{L} - k_1 I_N  k_2 I_N \\\\\nk_1 I_N  D_v \\mathcal{L} - k_2 I_N\n\\end{bmatrix}\n$$\nwhere $I_N$ is the $N \\times N$ identity matrix. This matrix will be constructed explicitly in the program.\n\n### 2. Numerical Integration Methods\n\n**a. Exact Discrete Reference Solution**\nFor a linear system $\\dot{U} = AU$, the exact solution over a time interval $T$ starting from an initial state $U(0)$ is given by the action of the matrix exponential: $U(T) = \\exp(TA)U(0)$. We compute this reference solution with high precision using the `scipy.linalg.expm` function, which implements a robust algorithm for the matrix exponential. This provides the benchmark against which the other methods are evaluated.\n\n**b. Monolithic Backward Euler Method**\nThe backward Euler method is a first-order, A-stable implicit integrator. For the full system, a single time step from $t_n$ to $t_{n+1} = t_n + \\Delta t$ is given by:\n$$\n\\frac{U^{n+1} - U^n}{\\Delta t} = A U^{n+1} \\implies \\left(I_{2N} - \\Delta t A\\right) U^{n+1} = U^n\n$$\nTo advance the solution, we must solve this $2N \\times 2N$ linear system for $U^{n+1}$ at each time step. The matrix $(I_{2N} - \\Delta t A)$ is constant for a fixed $\\Delta t$, so it can be constructed once before the time-stepping loop begins. The linear system is then solved using `scipy.linalg.solve`.\n\n**c. Strang Splitting Method**\nOperator splitting methods decompose a complex operator into simpler parts. Here, we split the system matrix $A$ into a diffusion part $A_D$ and a reaction part $A_R$, such that $A = A_D + A_R$.\n$$\nA_D = \\begin{bmatrix} D_u \\mathcal{L}  0 \\\\ 0  D_v \\mathcal{L} \\end{bmatrix}, \\quad A_R = \\begin{bmatrix} -k_1 I_N  k_2 I_N \\\\ k_1 I_N  -k_2 I_N \\end{bmatrix}\n$$\nStrang splitting is a second-order accurate scheme that approximates the solution by applying the sub-problem propagators symmetrically:\n$$\nU^{n+1} \\approx \\exp\\left(\\frac{\\Delta t}{2} A_R\\right) \\exp\\left(\\Delta t A_D\\right) \\exp\\left(\\frac{\\Delta t}{2} A_R\\right) U^n\n$$\nThe implementation follows these three steps:\n1.  **Half Reaction Step:** The reaction part $A_R$ couples species only at the same grid point. We can apply the reaction propagator $\\exp(\\frac{\\Delta t}{2} R)$ to each $[u_i, v_i]^{\\mathsf{T}}$ pair, where $R = \\begin{bmatrix}-k_1  k_2 \\\\ k_1  -k_2 \\end{bmatrix}$. This is done by computing the $2 \\times 2$ matrix exponential once and applying it to all grid points in a vectorized manner.\n2.  **Full Diffusion Step:** The diffusion operator $A_D$ is block-diagonal, meaning the diffusion of species $u$ and $v$ are decoupled from each other. We use backward Euler to solve implicitly for this step:\n    $$\n    u \\leftarrow (I_N - \\Delta t D_u \\mathcal{L})^{-1} u, \\quad v \\leftarrow (I_N - \\Delta t D_v \\mathcal{L})^{-1} v\n    $$\n    This requires solving two independent $N \\times N$ linear systems, which is computationally cheaper than solving one $2N \\times 2N$ system.\n3.  **Half Reaction Step:** The second symmetric reaction step is applied.\n\n### 3. Error and Cost Evaluation\n\nAfter running each simulation up to the final time $T$, we quantify performance.\n-   **Error:** The accuracy is measured by the discrete $\\ell^2$-norm of the difference between the numerical solution ($U^{\\mathrm{num}}$) and the reference solution ($U^{\\mathrm{ref}}$):\n    $$\n    E = \\left(\\Delta x \\sum_{i=0}^{N-1} \\left[ \\left(u_i^{\\mathrm{num}} - u_i^{\\mathrm{ref}}\\right)^2 + \\left(v_i^{\\mathrm{num}} - v_i^{\\mathrm{ref}}\\right)^2 \\right]\\right)^{1/2} = \\sqrt{\\Delta x} \\, \\| U^{\\mathrm{num}} - U^{\\mathrm{ref}} \\|_2\n    $$\n-   **Cost:** The computational cost is estimated using a proxy. For a linear system of size $M$, a dense solve is assumed to cost $M^3$ operations. The total cost is this per-step cost multiplied by the number of steps, $T/\\Delta t$.\n    -   Monolithic cost: $C_{\\text{mono}} = (2N)^3 \\times (T/\\Delta t)$\n    -   Splitting cost: $C_{\\text{split}} = (N^3 + N^3) \\times (T/\\Delta t) = 2N^3 \\times (T/\\Delta t)$\n\nThe program iterates through the specified $\\Delta t$ values, calculates these four metrics for each, and reports the results in the required format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import expm, solve, circulant\n\ndef solve_problem():\n    \"\"\"\n    Implements and compares monolithic and Strang-split time integration methods\n    for a linear reaction-diffusion system, evaluating them against a matrix\n    exponential reference solution.\n    \"\"\"\n    \n    # 1. Define fixed parameters and initial conditions in dimensionless units\n    L = 1.0\n    N = 32\n    Du = 1e-3\n    Dv = 5e-4\n    k1 = 40.0\n    k2 = 10.0\n    T = 5e-2\n\n    # Define the test cases for the timestep dt\n    test_cases_dt = [\n        5e-4,  # Case A\n        5e-3,  # Case B\n        5e-2   # Case C\n    ]\n    \n    # 2. Set up the spatial grid and initial state vector U0\n    dx = L / N\n    x = np.arange(N) * dx\n    u0 = 1.0 + 0.1 * np.sin(2 * np.pi * x / L)\n    v0 = np.zeros(N)\n    U0 = np.concatenate([u0, v0])\n\n    # 3. Construct the discrete operators and the full system matrix A\n    # Construct the N x N periodic discrete Laplacian matrix L\n    laplacian_col = np.zeros(N)\n    laplacian_col[0] = -2.0\n    laplacian_col[1] = 1.0\n    laplacian_col[-1] = 1.0  # Periodicity\n    L_matrix = circulant(laplacian_col) / (dx**2)\n    \n    # Construct the 2N x 2N system matrix A\n    I_N = np.identity(N)\n    A_uu = Du * L_matrix - k1 * I_N\n    A_uv = k2 * I_N\n    A_vu = k1 * I_N\n    A_vv = Dv * L_matrix - k2 * I_N\n    A = np.block([[A_uu, A_uv], [A_vu, A_vv]])\n\n    # 4. Compute the exact discrete reference solution at time T\n    # U(T) = exp(T * A) * U(0)\n    U_ref = expm(T * A) @ U0\n\n    # List to store the results for each test case\n    results = []\n\n    # 5. Loop over the test cases defined by different timesteps\n    for dt in test_cases_dt:\n        num_steps = int(round(T / dt))\n\n        # --- Solve with Monolithic Backward Euler ---\n        U_mono = U0.copy()\n        # Pre-compute the matrix for the linear system\n        M_mono = np.identity(2 * N) - dt * A\n        for _ in range(num_steps):\n            U_mono = solve(M_mono, U_mono, assume_a='gen')\n\n        # --- Solve with Strang Splitting ---\n        U_split = U0.copy()\n        \n        # Pre-compute the reaction propagator matrix for a half time-step\n        R = np.array([[-k1, k2], [k1, -k2]], dtype=float)\n        Prop_R_half = expm(0.5 * dt * R)\n\n        # Pre-compute matrices for the implicit diffusion solves\n        M_diff_u = np.identity(N) - dt * Du * L_matrix\n        M_diff_v = np.identity(N) - dt * Dv * L_matrix\n\n        for _ in range(num_steps):\n            u_current = U_split[:N]\n            v_current = U_split[N:]\n            \n            # Form a 2xN array for vectorized reaction calculation\n            uv_current = np.stack([u_current, v_current])\n            \n            # Step 1: Half reaction step\n            uv_reacted1 = Prop_R_half @ uv_current\n            \n            # Step 2: Full diffusion step (implicit)\n            u_diffused = solve(M_diff_u, uv_reacted1[0, :], assume_a='gen')\n            v_diffused = solve(M_diff_v, uv_reacted1[1, :], assume_a='gen')\n            \n            # Form a 2xN array for the second reaction step\n            uv_diffused_stack = np.stack([u_diffused, v_diffused])\n            \n            # Step 3: Second half reaction step\n            uv_reacted2 = Prop_R_half @ uv_diffused_stack\n            \n            # Reconstruct the flat state vector\n            U_split = np.concatenate([uv_reacted2[0, :], uv_reacted2[1, :]])\n        \n        # 6. Quantify error and computational cost\n        # Error calculation using the specified discrete l2-norm\n        err_split = np.sqrt(dx) * np.linalg.norm(U_split - U_ref)\n        err_mono = np.sqrt(dx) * np.linalg.norm(U_mono - U_ref)\n        \n        # Cost proxy calculation\n        cost_split = float(2 * (N**3) * num_steps)\n        cost_mono = float((2 * N)**3 * num_steps)\n        \n        # Append results for the current test case\n        results.append([err_split, err_mono, cost_split, cost_mono])\n\n    # 7. Format and print the final output\n    case_strings = [f\"[{r[0]},{r[1]},{r[2]},{r[3]}]\" for r in results]\n    final_output_string = f\"[{','.join(case_strings)}]\"\n    print(final_output_string)\n\n\n# Execute the main function\nsolve_problem()\n```"
        }
    ]
}