{
    "hands_on_practices": [
        {
            "introduction": "Before implementing softening in a complex simulation, it is crucial to understand the properties of different softening kernels. This first practice invites you to derive and compare the force laws for two widely used forms—Plummer and cubic-spline softening—and to quantify their deviation from pure Newtonian gravity. By analyzing the relative force error , you will gain a quantitative understanding of the trade-offs involved in choosing a specific softening scheme.",
            "id": "3535229",
            "problem": "Consider a point mass with total mass $m$ and gravitational constant $G$. Let $r$ denote the physical separation and let $\\epsilon$ denote a softening length. Define the dimensionless separation $u \\equiv r/\\epsilon$. The unsoftened Newtonian gravitational force magnitude between two point masses is $F_{N}(r) = G m / r^{2}$. Two widely used softened models are considered:\n\n1. Plummer softening: The potential is modeled by a regularized form of the inverse-distance potential. From first principles and appropriate differentiation of the potential, derive the corresponding force magnitude $F_{\\mathrm{P}}(r)$ and express the relative force error with respect to Newtonian gravity as a function of $u$.\n\n2. Cubic-spline softening: The softened gravitational field is obtained by replacing the point mass by a spherically symmetric mass density equal to the three-dimensional cubic-spline kernel with smoothing length $h=\\epsilon$ and compact support $2\\epsilon$. The kernel is defined by\n$$\nW(r,\\epsilon) = \\frac{1}{\\pi \\epsilon^{3}} \\, w(u), \\quad u \\equiv \\frac{r}{\\epsilon},\n$$\nwith the dimensionless profile\n$$\nw(u) =\n\\begin{cases}\n1 - \\frac{3}{2} u^{2} + \\frac{3}{4} u^{3}, & 0 \\le u < 1, \\\\\n\\frac{1}{4} (2 - u)^{3}, & 1 \\le u < 2, \\\\\n0, & u \\ge 2.\n\\end{cases}\n$$\nStarting from Newton’s law of gravity and the shell theorem for spherically symmetric mass distributions, derive the enclosed mass fraction $M(u)$ and hence the softened force magnitude $F_{\\mathrm{S}}(r)$, and express the relative force error with respect to Newtonian gravity as a function of $u$.\n\nYou must compute and compare the maximum relative force error\n$$\n\\max_{u \\in [0.5, 2]} \\left\\{ \\frac{\\left| F_{\\epsilon}(r) - F_{N}(r) \\right|}{F_{N}(r)} \\right\\}\n$$\nfor Plummer softening versus cubic-spline softening, where $F_{\\epsilon}$ denotes the softened force for the given model. No physical units are required because the quantity is dimensionless by construction.\n\nYour program must produce numerical results for the following test suite, which explores sampling resolution effects over the interval $u \\in [0.5, 2]$:\n- Test case 1: Uniform grid with $N=1001$ sample points.\n- Test case 2: Uniform grid with $N=10001$ sample points.\n- Test case 3: Uniform grid with $N=501$ sample points.\n\nFor each test case, compute two floats: the maximum relative force error for Plummer softening and for cubic-spline softening. Your program should produce a single line of output containing the six results as a comma-separated list enclosed in square brackets in the order\n$$\n[\\text{Plummer}_{1001}, \\text{Spline}_{1001}, \\text{Plummer}_{10001}, \\text{Spline}_{10001}, \\text{Plummer}_{501}, \\text{Spline}_{501}],\n$$\nwhere each entry is a float. Angles are not involved in this problem, and therefore no angle unit is required.",
            "solution": "The user-provided problem statement is critically evaluated and found to be valid. It is scientifically sound, well-posed, and objective, based on established principles of computational astrophysics. The problem asks for the derivation and comparison of the maximum relative force error for two gravitational softening models, Plummer and cubic-spline, over a specified interval.\n\nThe solution proceeds in three stages:\n1.  Derivation of the relative force error for the Plummer softening model and analysis of its behavior.\n2.  Derivation of the relative force error for the cubic-spline softening model and analysis of its behavior.\n3.  Calculation of the maximum error for both models and implementation of the numerical solution.\n\nAll mathematical entities are typeset in LaTeX as per the specified formatting rules.\n\n**1. Plummer Softening Analysis**\n\nThe Plummer potential is a standard regularized form of the Newtonian potential, given by:\n$$\n\\Phi_{\\mathrm{P}}(r) = - \\frac{G m}{\\sqrt{r^2 + \\epsilon^2}}\n$$\nThe gravitational force is a central force, and its magnitude is the negative radial derivative of the potential:\n$$\nF_{\\mathrm{P}}(r) = - \\frac{d\\Phi_{\\mathrm{P}}}{dr} = - \\frac{d}{dr} \\left( - \\frac{G m}{(r^2 + \\epsilon^2)^{1/2}} \\right) = G m \\left( - \\frac{1}{2} (r^2 + \\epsilon^2)^{-3/2} \\cdot 2r \\right)\n$$\nThe magnitude of the force is thus:\n$$\nF_{\\mathrm{P}}(r) = \\frac{G m r}{(r^2 + \\epsilon^2)^{3/2}}\n$$\nThe unsoftened Newtonian force is $F_{N}(r) = G m / r^2$. The relative force error, $E_{\\mathrm{P}}$, is defined as:\n$$\nE_{\\mathrm{P}}(r) = \\frac{\\left| F_{\\mathrm{P}}(r) - F_{N}(r) \\right|}{F_{N}(r)} = \\left| \\frac{F_{\\mathrm{P}}(r)}{F_{N}(r)} - 1 \\right|\n$$\nThe ratio of the forces is:\n$$\n\\frac{F_{\\mathrm{P}}(r)}{F_{N}(r)} = \\frac{G m r}{(r^2 + \\epsilon^2)^{3/2}} \\cdot \\frac{r^2}{G m} = \\frac{r^3}{(r^2 + \\epsilon^2)^{3/2}}\n$$\nUsing the dimensionless separation $u = r/\\epsilon$, this ratio becomes:\n$$\n\\frac{F_{\\mathrm{P}}(u)}{F_{N}(u)} = \\frac{(u\\epsilon)^3}{((u\\epsilon)^2 + \\epsilon^2)^{3/2}} = \\frac{u^3 \\epsilon^3}{(\\epsilon^2(u^2 + 1))^{3/2}} = \\frac{u^3}{(u^2 + 1)^{3/2}}\n$$\nFor any $u > 0$, we have $u^2 < u^2 + 1$, which implies $u^3 < (u^2 + 1)^{3/2}$. Therefore, the ratio is always less than $1$, and the softened force is weaker than the Newtonian force. The relative error simplifies to:\n$$\nE_{\\mathrm{P}}(u) = 1 - \\frac{u^3}{(u^2 + 1)^{3/2}}\n$$\nTo find the maximum error on the interval $u \\in [0.5, 2]$, we analyze the derivative of $E_{\\mathrm{P}}(u)$ with respect to $u$:\n$$\n\\frac{d E_{\\mathrm{P}}}{d u} = - \\frac{d}{du} \\left( \\frac{u^3}{(u^2 + 1)^{3/2}} \\right) = - \\frac{3u^2(u^2+1)^{3/2} - u^3 \\cdot \\frac{3}{2}(u^2+1)^{1/2}(2u)}{(u^2+1)^3}\n$$\n$$\n\\frac{d E_{\\mathrm{P}}}{d u} = - \\frac{3u^2(u^2+1) - 3u^4}{(u^2+1)^{5/2}} = - \\frac{3u^4 + 3u^2 - 3u^4}{(u^2+1)^{5/2}} = - \\frac{3u^2}{(u^2+1)^{5/2}}\n$$\nSince $u > 0$, the derivative $\\frac{d E_{\\mathrm{P}}}{d u}$ is always negative. This proves that $E_{\\mathrm{P}}(u)$ is a monotonically decreasing function for $u > 0$. Consequently, its maximum value on the interval $[0.5, 2]$ must occur at the left endpoint, $u = 0.5$.\n\n**2. Cubic-Spline Softening Analysis**\n\nFor a spherically symmetric mass distribution, the Shell Theorem states that the gravitational force at a radius $r$ is determined by the total mass $M(r)$ enclosed within that radius:\n$$\nF_{\\mathrm{S}}(r) = \\frac{G M(r)}{r^2}\n$$\nThe enclosed mass $M(r)$ is found by integrating the mass density $\\rho(r') = m W(r', \\epsilon)$ over a sphere of radius $r$:\n$$\nM(r) = \\int_0^r 4\\pi r'^2 \\rho(r') dr' = \\int_0^r 4\\pi r'^2 m W(r', \\epsilon) dr'\n$$\nThe problem requests the enclosed mass fraction, $M_{\\text{frac}}(u) = M(r)/m$. Converting the integral to the dimensionless variable $u' = r'/\\epsilon$ (where $dr' = \\epsilon du'$):\n$$\nM_{\\text{frac}}(u) = \\int_0^u 4\\pi (u'\\epsilon)^2 W(u'\\epsilon, \\epsilon) \\epsilon du' = \\int_0^u 4\\pi u'^2 \\epsilon^3 \\left( \\frac{1}{\\pi \\epsilon^3} w(u') \\right) du' = 4 \\int_0^u u'^2 w(u') du'\n$$\nThe integration must be performed piecewise according to the definition of $w(u)$.\nFor $0 \\le u < 1$:\n$$\nM_{\\text{frac}}(u) = 4 \\int_0^u u'^2 \\left(1 - \\frac{3}{2} u'^2 + \\frac{3}{4} u'^3\\right) du' = 4 \\left[ \\frac{u'^3}{3} - \\frac{3}{10} u'^5 + \\frac{1}{8} u'^6 \\right]_0^u\n$$\n$$\nM_{\\text{frac}}(u) = \\frac{4}{3} u^3 - \\frac{6}{5} u^5 + \\frac{1}{2} u^6\n$$\nFor $1 \\le u < 2$:\nThe integral is $M_{\\text{frac}}(1) + 4 \\int_1^u u'^2 w(u') du'$. First, $M_{\\text{frac}}(1) = \\frac{4}{3} - \\frac{6}{5} + \\frac{1}{2} = \\frac{40 - 36 + 15}{30} = \\frac{19}{30}$.\nThe integral is:\n$$\n4 \\int_1^u u'^2 \\left(\\frac{1}{4}(2-u')^3\\right) du' = \\int_1^u u'^2(8 - 12u' + 6u'^2 - u'^3) du'\n$$\n$$\n= \\left[ \\frac{8}{3}u'^3 - 3u'^4 + \\frac{6}{5}u'^5 - \\frac{1}{6}u'^6 \\right]_1^u = \\left(\\frac{8}{3}u^3 - 3u^4 + \\frac{6}{5}u^5 - \\frac{1}{6}u^6\\right) - \\left(\\frac{8}{3} - 3 + \\frac{6}{5} - \\frac{1}{6}\\right)\n$$\nThe constant term is $\\frac{80 - 90 + 36 - 5}{30} = \\frac{21}{30}$. Thus, for $1 \\le u < 2$:\n$$\nM_{\\text{frac}}(u) = \\frac{19}{30} + \\left(\\frac{8}{3}u^3 - 3u^4 + \\frac{6}{5}u^5 - \\frac{1}{6}u^6\\right) - \\frac{21}{30} = \\frac{8}{3}u^3 - 3u^4 + \\frac{6}{5}u^5 - \\frac{1}{6}u^6 - \\frac{1}{15}\n$$\nFor $u \\ge 2$, the entire mass is enclosed, so $M_{\\text{frac}}(u)=1$. The relative force error is:\n$$\nE_{\\mathrm{S}}(r) = \\left| \\frac{F_{\\mathrm{S}}(r)}{F_{N}(r)} - 1 \\right| = \\left| \\frac{G M(r)/r^2}{G m/r^2} - 1 \\right| = \\left| \\frac{M(r)}{m} - 1 \\right| = |M_{\\text{frac}}(u) - 1|\n$$\nSince $M(r) \\le m$ for $r < 2\\epsilon$, the enclosed mass fraction is less than or equal to $1$. The error is:\n$$\nE_{\\mathrm{S}}(u) = 1 - M_{\\text{frac}}(u)\n$$\nTo find the maximum error, we analyze its derivative:\n$$\n\\frac{d E_{\\mathrm{S}}}{d u} = - \\frac{d M_{\\text{frac}}}{d u} = - 4 u^2 w(u)\n$$\nThe kernel profile $w(u)$ is non-negative on its support $[0, 2]$. Therefore, $\\frac{d E_{\\mathrm{S}}}{d u} \\le 0$, meaning $E_{\\mathrm{S}}(u)$ is also a monotonically decreasing function. Its maximum value on the interval $[0.5, 2]$ must occur at the left endpoint, $u = 0.5$.\n\n**3. Numerical Calculation**\n\nThe analytical investigation reveals that for both softening models, the maximum relative error on the interval $u \\in [0.5, 2]$ occurs at $u=0.5$. This insight means the maximum error is independent of the sampling resolution $N$ specified in the test cases, as any uniform grid starting at $u=0.5$ will have its maximum value at the first point. The problem reduces to calculating the error values at $u=0.5$.\n\nFor Plummer softening:\n$$\n\\max E_{\\mathrm{P}} = E_{\\mathrm{P}}(0.5) = 1 - \\frac{(0.5)^3}{(0.5^2 + 1)^{3/2}} = 1 - \\frac{0.125}{(1.25)^{1.5}} \\approx 0.9105572809\n$$\nFor cubic-spline softening, $u=0.5$ falls in the first case ($0 \\le u < 1$):\n$$\n\\max E_{\\mathrm{S}} = E_{\\mathrm{S}}(0.5) = 1 - M_{\\text{frac}}(0.5) = 1 - \\left( \\frac{4}{3} (0.5)^3 - \\frac{6}{5} (0.5)^5 + \\frac{1}{2} (0.5)^6 \\right)\n$$\n$$\n\\max E_{\\mathrm{S}} = 1 - \\left( \\frac{4}{3} \\cdot \\frac{1}{8} - \\frac{6}{5} \\cdot \\frac{1}{32} + \\frac{1}{2} \\cdot \\frac{1}{64} \\right) = 1 - \\left( \\frac{1}{6} - \\frac{3}{80} + \\frac{1}{128} \\right) = 1 - \\frac{263}{1920} \\approx 0.8630208333\n$$\nThe program will compute these two values and report them for each test case as required.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the maximum relative force error for Plummer and cubic-spline softening\n    for different sampling resolutions.\n    \"\"\"\n    # The problem defines three test cases with different sampling resolutions (N).\n    # Test cases: N=1001, N=10001, N=501\n    test_cases = [1001, 10001, 501]\n\n    # As derived in the solution, the relative error functions for both Plummer and\n    # cubic-spline softening are monotonically decreasing on the interval u in [0.5, 2].\n    # Therefore, the maximum error for both models occurs at the minimum value of u,\n    # which is u = 0.5. This result is independent of the sampling resolution N.\n\n    # We calculate these maximum values once.\n    u_max = 0.5\n\n    # --- Plummer Softening Calculation ---\n    # The relative error is E_P(u) = 1 - u^3 / (u^2 + 1)^(3/2).\n    max_err_plummer = 1.0 - u_max**3 / (u_max**2 + 1.0)**1.5\n\n    # --- Cubic-Spline Softening Calculation ---\n    # For u in [0, 1), the relative error is E_S(u) = 1 - (4/3*u^3 - 6/5*u^5 + 1/2*u^6).\n    # Since u_max = 0.5 is in this range, we use this formula.\n    max_err_spline = 1.0 - (\n        (4.0/3.0) * u_max**3 -\n        (6.0/5.0) * u_max**5 +\n        (1.0/2.0) * u_max**6\n    )\n\n    # The problem asks for numerical results for each test case. Since the maximum\n    # is analytically determined to be at u=0.5, the result is the same for all N.\n    # The order of results must be:\n    # [Plummer_1001, Spline_1001, Plummer_10001, Spline_10001, Plummer_501, Spline_501]\n    \n    results = []\n    for _ in test_cases:\n        results.append(max_err_plummer)\n        results.append(max_err_spline)\n\n    # The loop over `test_cases = [1001, 10001, 501]` naturally produces\n    # the results in the specified order.\n\n    # Format the final output as a comma-separated list in brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "With a grasp of softening kernels, the next step is to integrate one into a dynamic simulation. This exercise challenges you to build a complete N-body code that evolves a cold Plummer sphere under its own softened self-gravity . Verifying fundamental conservation laws, such as total energy, and tracking the system's evolution towards virial equilibrium will solidify your understanding of how to correctly and robustly implement softened gravity in a time-stepping code.",
            "id": "3535189",
            "problem": "You are to implement a complete, runnable program that constructs a reproducible unit test for the numerical evolution of a self-gravitating system whose initial configuration is a cold Plummer sphere and whose gravitational interactions are softened. The purpose is to verify, over many dynamical times, conservation of total energy and the behavior of the virial ratio, based on first principles of Newtonian dynamics, without relying on any shortcut formula explicitly given here. The program must be fully self-contained and use dimensionless units.\n\nThe fundamental base to be used is as follows. Newtonian gravity states that a particle of mass $m$ at position $\\mathbf{x}$ experiences acceleration $\\mathbf{a}$ due to other masses according to $\\mathbf{a} = - \\nabla \\Phi$, where $\\Phi$ is the gravitational potential. The total energy $E$ of a system of particles is the sum of kinetic energy $T$ and potential energy $W$, with $T = \\sum_{i} \\tfrac{1}{2} m_i \\lVert \\mathbf{v}_i \\rVert^2$ and $W$ defined by pairwise interactions consistent with the chosen potential. The virial theorem for systems in equilibrium states that $2 T + W = 0$, and the virial ratio is $Q = T / \\lvert W \\rvert$. To regularize close encounters in computational astrophysics, gravity is commonly softened; you must implement a softened self-gravity that is consistent between the computed force and the computed potential energy.\n\nYou must:\n\n- Construct an $N$-body realization of a Plummer sphere with scale radius $a$ and total mass $M$, sampled in three spatial dimensions, such that the generated particle positions follow the Plummer profile and the center of mass lies at the origin. All particles must have equal mass. The system is cold, meaning all initial particle velocities are set to zero.\n- Use dimensionless units where $G = 1$, $M = 1$, and $a = 1$. The characteristic dynamical time is defined by $t_{\\mathrm{dyn}} = \\sqrt{a^3 / (G M)}$, which in these units is $t_{\\mathrm{dyn}} = 1$. All times in this problem are expressed in units of $t_{\\mathrm{dyn}}$, and no physical unit conversion is needed.\n- Implement a time-reversible symplectic integrator to evolve the system for a specified number of dynamical times. The time step must be constant. You must compute particle accelerations from the softened gravitational interaction, ensuring that the expression used for acceleration is the negative gradient of the same softened potential energy function used to compute the potential energy $W$.\n- At every step (including the initial state), compute the total energy $E = T + W$ and the instantaneous virial ratio $Q = T / \\lvert W \\rvert$. Track the maximum fractional deviation of $E$ from its initial value over the entire integration interval, defined as $\\max_t \\left( \\lvert E(t) - E(0) \\rvert / \\lvert E(0) \\rvert \\right)$. For the virial ratio, compute the time-average of $Q(t)$ over the interval $t \\in [t_{\\mathrm{transient}}, t_{\\mathrm{end}}]$, where $t_{\\mathrm{transient}} = 3 \\, t_{\\mathrm{dyn}}$.\n- For each test case, return two booleans:\n  1. An energy conservation boolean, which is true if the maximum fractional deviation of $E$ is less than or equal to a specified tolerance.\n  2. A virial ratio boolean, which is true if the time-averaged $Q$ over $[t_{\\mathrm{transient}}, t_{\\mathrm{end}}]$ lies within a specified tolerance interval around $0.5$; i.e., $Q_{\\mathrm{avg}} \\in [0.5 - \\delta_Q, 0.5 + \\delta_Q]$.\n\nYou must design and run the following test suite, covering different facets of the problem including a general case, small number of particles, large softening, and stronger self-gravity:\n\n- Test Case 1 (general, happy path): $N = 64$, $\\epsilon = 0.05$, $\\Delta t = 0.005$, $t_{\\mathrm{end}} = 10$, energy tolerance $\\delta_E = 0.005$, virial tolerance $\\delta_Q = 0.12$, random seed $s = 42$.\n- Test Case 2 (boundary on particle number): $N = 16$, $\\epsilon = 0.05$, $\\Delta t = 0.005$, $t_{\\mathrm{end}} = 8$, energy tolerance $\\delta_E = 0.02$, virial tolerance $\\delta_Q = 0.22$, random seed $s = 12345$.\n- Test Case 3 (large softening): $N = 64$, $\\epsilon = 0.30$, $\\Delta t = 0.01$, $t_{\\mathrm{end}} = 10$, energy tolerance $\\delta_E = 0.007$, virial tolerance $\\delta_Q = 0.10$, random seed $s = 31415$.\n- Test Case 4 (stronger interactions): $N = 64$, $\\epsilon = 0.008$, $\\Delta t = 0.003$, $t_{\\mathrm{end}} = 8$, energy tolerance $\\delta_E = 0.01$, virial tolerance $\\delta_Q = 0.15$, random seed $s = 271828$.\n\nIn all cases, the gravitational constant is $G = 1$, the Plummer scale radius is $a = 1$, and the total mass is $M = 1$. Ensure the softened interaction is used consistently in both force and potential energy calculations.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry corresponds to one test case and is itself a two-element list of booleans $[b_E, b_Q]$ in that order, with $b_E$ the energy conservation boolean and $b_Q$ the virial ratio boolean. For example, a valid output format is $[[\\mathrm{True},\\mathrm{False}],[\\mathrm{True},\\mathrm{True}]]$ for two cases. No other text should be printed.",
            "solution": "The problem statement is assessed to be valid. It presents a well-posed and scientifically grounded task in computational astrophysics. It requires the implementation of a standard N-body simulation, including initial condition generation for a Plummer sphere, numerical integration using a symplectic scheme, and the consistent application of a softened gravitational potential. All necessary parameters for the simulation and verification are provided. The problem is a standard exercise in the field and is free from scientific flaws, ambiguities, or contradictions. The solution requires making standard, well-documented choices for specific algorithms, which is an expected part of the task for an expert in the field.\n\nThe following solution outlines the theoretical basis and algorithmic design for the required program.\nWe will use dimensionless units where the gravitational constant $G=1$, total system mass $M=1$, and Plummer scale radius $a=1$. Consequently, the unit of time, the dynamical time $t_{\\mathrm{dyn}} = \\sqrt{a^3/(GM)}$, is also $1$.\n\n### Initial Conditions: A Cold Plummer Sphere\n\nThe simulation begins with a collection of $N$ particles representing a Plummer sphere, which is a spherically symmetric model for a stellar system. The density profile $\\rho(r)$ is given by:\n$$\n\\rho(r) = \\frac{3M}{4\\pi a^3} \\left(1 + \\frac{r^2}{a^2}\\right)^{-5/2}\n$$\nTo generate particle positions that follow this distribution, we use the method of inverse transform sampling, as described by Aarseth, Henon, and Wielen (1974). This involves relating the cumulative mass function $M(r)$ to a uniformly distributed random variable. The cumulative mass enclosed within a radius $r$ is:\n$$\nM(r) = M \\frac{r^3}{(a^2 + r^2)^{3/2}}\n$$\nWe sample a particle's radius $r$ by setting $M(r)/M = u$, where $u$ is a random number drawn from a uniform distribution on $[0,1)$. Solving for $r$ yields the sampling formula:\n$$\nr(u) = a \\left( u^{-2/3} - 1 \\right)^{-1/2}\n$$\nOnce a radius $r$ is generated for each of the $N$ particles, a position vector $\\mathbf{x}$ is assigned by selecting a random, isotropic direction on a sphere of that radius. This is robustly achieved by generating a 3D vector from a standard normal distribution and normalizing it to unit length, then scaling by $r$.\n\nAll particles are assigned an equal mass, $m_i = M/N = 1/N$. The system is \"cold,\" meaning all initial velocities are zero: $\\mathbf{v}_i(0) = \\mathbf{0}$. Finally, to ensure the center of mass (COM) is at the origin, the COM of the generated particle positions is computed, $\\mathbf{x}_{\\mathrm{COM}} = \\frac{1}{N} \\sum_{i=1}^N \\mathbf{x}_i$, and this vector is subtracted from each particle's position vector, $\\mathbf{x}_i \\rightarrow \\mathbf{x}_i - \\mathbf{x}_{\\mathrm{COM}}$.\n\n### Equations of Motion with Softened Gravity\n\nTo avoid numerical infinities and mitigate the effects of strong two-body scattering during close encounters, the Newtonian potential is \"softened.\" We employ Plummer-style softening, which is consistent with the initial density profile. The softened potential energy between two particles $i$ and $j$ is:\n$$\nW_{ij} = -\\frac{G m_i m_j}{\\sqrt{\\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert^2 + \\epsilon^2}}\n$$\nwhere $\\epsilon$ is the softening length. The total potential energy of the system is the sum over all unique pairs:\n$$\nW = \\sum_{i<j} W_{ij} = \\frac{1}{2}\\sum_{i \\neq j} W_{ij}\n$$\nThe problem requires that the force be derived from this potential. The force on particle $i$ due to particle $j$ is $\\mathbf{F}_{ij} = -\\nabla_i W_{ij}$. The acceleration $\\mathbf{a}_i$ of particle $i$ is the sum of accelerations from all other particles $j \\neq i$:\n$$\n\\mathbf{a}_i = \\frac{1}{m_i} \\sum_{j \\neq i} \\mathbf{F}_{ij} = \\sum_{j \\neq i} -\\nabla_i \\left(-\\frac{G m_j}{\\sqrt{\\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert^2 + \\epsilon^2}}\\right)\n$$\nCalculating the gradient gives the expression for acceleration:\n$$\n\\mathbf{a}_i = - \\sum_{j \\neq i} \\frac{G m_j (\\mathbf{x}_i - \\mathbf{x}_j)}{\\left(\\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert^2 + \\epsilon^2\\right)^{3/2}}\n$$\nThis direct $O(N^2)$ summation will be computed at each time step.\n\n### Time Integration: The Leapfrog Scheme\n\nTo evolve the system in time, a time-reversible, symplectic integrator is required. We will implement the \"Kick-Drift-Kick\" (KDK) form of the second-order leapfrog integrator. This method is well-suited for gravitational dynamics due to its excellent long-term energy conservation properties for appropriate time steps.\nGiven the state $(\\mathbf{x}_n, \\mathbf{v}_n)$ at time $t_n = n \\Delta t$, the state at $t_{n+1}$ is computed in three steps:\n1.  **Kick (half step):** Update velocity from $t_n$ to $t_n + \\Delta t/2$.\n    $$ \\mathbf{v}_{n+1/2} = \\mathbf{v}_n + \\mathbf{a}(\\mathbf{x}_n) \\frac{\\Delta t}{2} $$\n2.  **Drift (full step):** Update position from $t_n$ to $t_{n+1}$ using the half-step velocity.\n    $$ \\mathbf{x}_{n+1} = \\mathbf{x}_n + \\mathbf{v}_{n+1/2} \\Delta t $$\n3.  **Kick (half step):** Compute the new acceleration $\\mathbf{a}(\\mathbf{x}_{n+1})$ and update velocity to $t_{n+1}$.\n    $$ \\mathbf{v}_{n+1} = \\mathbf{v}_{n+1/2} + \\mathbf{a}(\\mathbf{x}_{n+1}) \\frac{\\Delta t}{2} $$\nThis sequence yields the full state $(\\mathbf{x}_{n+1}, \\mathbf{v}_{n+1})$ at time $t_{n+1}$.\n\n### System Diagnostics and Verification\n\nAt each time step $t$, including the initial state $t=0$, we compute several diagnostic quantities.\nThe total kinetic energy is $T = \\sum_i \\frac{1}{2} m_i \\lVert \\mathbf{v}_i \\rVert^2$.\nThe total potential energy $W$ is calculated as defined previously.\nThe total energy is $E = T + W$.\n\nThe first verification test concerns the conservation of total energy. Since the gravitational force is conservative and the integrator is symplectic, $E$ should remain nearly constant. We calculate the initial energy $E(0) = W(0)$ (since $T(0)=0$) and track the maximum fractional deviation over the entire simulation:\n$$\n\\Delta E_{\\max} = \\max_{t} \\left( \\frac{\\lvert E(t) - E(0) \\rvert}{\\lvert E(0) \\rvert} \\right)\n$$\nThe energy conservation boolean, $b_E$, is true if $\\Delta E_{\\max} \\le \\delta_E$, where $\\delta_E$ is the specified tolerance.\n\nThe second test concerns the virial ratio, $Q = T / \\lvert W \\rvert$. A self-gravitating system in equilibrium, according to the virial theorem, satisfies $2\\langle T \\rangle = -\\langle W \\rangle$, where $\\langle \\cdot \\rangle$ denotes a time average. This implies an average virial ratio of $\\langle Q \\rangle = 0.5$. The initial \"cold\" collapse leads to a process called violent relaxation, after which the system settles into a quasi-equilibrium virialized state. We compute the time-average of $Q(t)$ over the interval $t \\in [t_{\\mathrm{transient}}, t_{\\mathrm{end}}]$, where $t_{\\mathrm{transient}} = 3 \\, t_{\\mathrm{dyn}} = 3$, to capture the behavior of the virialized state. Let this average be $Q_{\\mathrm{avg}}$. The virial ratio boolean, $b_Q$, is true if $Q_{\\mathrm{avg}}$ is within the tolerance interval $[0.5 - \\delta_Q, 0.5 + \\delta_Q]$.\n\nThe combination of these components—initial condition generation, consistent force and potential calculation, symplectic time integration, and diagnostic analysis—forms the basis of the required unit test program.",
            "answer": "```python\nimport numpy as np\n\ndef generate_plummer_sphere(N, a, seed):\n    \"\"\"\n    Generates N-body realization of a Plummer sphere.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # Generate radii using inverse transform sampling\n    u_r = rng.uniform(0, 1, size=N)\n    radii = a / np.sqrt(u_r**(-2.0/3.0) - 1.0)\n    \n    # Generate isotropic directions\n    vecs = rng.normal(size=(N, 3))\n    norms = np.linalg.norm(vecs, axis=1)\n    valid_indices = norms > 1e-15\n    vecs[valid_indices] /= norms[valid_indices, np.newaxis]\n    \n    # Create positions\n    pos = radii[:, np.newaxis] * vecs\n    \n    # Center the COM\n    com = np.mean(pos, axis=0)\n    pos -= com\n    \n    return pos\n\ndef get_acceleration(pos, mass, G, epsilon):\n    \"\"\"\n    Calculates acceleration on each particle using direct summation.\n    pos: (N, 3) array of positions\n    mass: scalar mass of each particle\n    \"\"\"\n    N = pos.shape[0]\n    acc = np.zeros_like(pos)\n    \n    # Use broadcasting to get all pairwise differences\n    diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n    \n    # Calculate squared distances\n    dist_sq = np.sum(diff**2, axis=-1)\n    \n    # Softened inverse cube law, setting diagonal to 0 to avoid self-force\n    inv_r3 = (dist_sq + epsilon**2)**(-1.5)\n    np.fill_diagonal(inv_r3, 0.0)\n    \n    # Sum forces. Note mass is scalar (m_j = m for all j)\n    # The sum is over the j index, for each particle i.\n    acc = -G * mass * np.sum(diff * inv_r3[..., np.newaxis], axis=1)\n    \n    return acc\n\ndef get_potential_energy(pos, mass, G, epsilon):\n    \"\"\"\n    Calculates total potential energy of the system.\n    \"\"\"\n    N = pos.shape[0]\n    \n    # Get pairwise separation vectors and squared distances\n    diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n    dist_sq = np.sum(diff**2, axis=-1)\n    \n    # Calculate softened pairwise potentials\n    # Add a large value to the diagonal to avoid division by zero, though we only sum upper triangle\n    np.fill_diagonal(dist_sq, np.inf) \n    rij = np.sqrt(dist_sq + epsilon**2)\n    \n    potential_pairs = -G * mass * mass / rij\n    \n    # Sum over unique pairs (upper triangle of the matrix)\n    total_potential = np.sum(np.triu(potential_pairs))\n    \n    return total_potential\n\ndef get_kinetic_energy(vel, mass):\n    \"\"\"\n    Calculates total kinetic energy of the system.\n    \"\"\"\n    return 0.5 * mass * np.sum(vel**2)\n\ndef run_simulation(N, M, a, G, epsilon, dt, t_end, t_transient, seed):\n    \"\"\"\n    Runs a single N-body simulation test case.\n    \"\"\"\n    m = M / N\n    pos = generate_plummer_sphere(N, a, seed)\n    vel = np.zeros_like(pos)\n    \n    # Initial state diagnostics\n    W0 = get_potential_energy(pos, m, G, epsilon)\n    E0 = W0  # T0 is 0\n    \n    if abs(E0) < 1e-15:\n        # Avoid division by zero if initial potential is unexpectedly zero\n        return -1.0, -1.0 \n\n    max_frac_E_dev = 0.0\n    Q_values_for_avg = []\n    \n    num_steps = int(round(t_end / dt))\n    \n    # Main KDK leapfrog integration loop\n    for n in range(num_steps):\n        # Kick (half step)\n        accel_n = get_acceleration(pos, m, G, epsilon)\n        vel_half_step = vel + accel_n * dt / 2.0\n        \n        # Drift (full step)\n        pos += vel_half_step * dt\n        \n        # Kick (half step)\n        accel_n_plus_1 = get_acceleration(pos, m, G, epsilon)\n        vel = vel_half_step + accel_n_plus_1 * dt / 2.0\n        \n        # Diagnostics at step n+1\n        T = get_kinetic_energy(vel, m)\n        W = get_potential_energy(pos, m, G, epsilon)\n        E = T + W\n        \n        frac_E_dev = abs((E - E0) / E0)\n        if frac_E_dev > max_frac_E_dev:\n            max_frac_E_dev = frac_E_dev\n            \n        current_t = (n + 1) * dt\n        if current_t >= t_transient:\n            if abs(W) > 1e-15:\n                Q = T / abs(W)\n                Q_values_for_avg.append(Q)\n\n    avg_Q = np.mean(Q_values_for_avg) if Q_values_for_avg else 0.0\n    \n    return max_frac_E_dev, avg_Q\n\ndef solve():\n    \"\"\"\n    Main function to run test suite and print results.\n    \"\"\"\n    # Dimensionless units\n    G = 1.0\n    M = 1.0\n    a = 1.0\n    t_transient = 3.0\n\n    test_cases = [\n        # (N, epsilon, dt, t_end, delta_E, delta_Q, seed)\n        (64, 0.05, 0.005, 10.0, 0.005, 0.12, 42),\n        (16, 0.05, 0.005, 8.0, 0.02, 0.22, 12345),\n        (64, 0.30, 0.01, 10.0, 0.007, 0.10, 31415),\n        (64, 0.008, 0.003, 8.0, 0.01, 0.15, 271828),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, epsilon, dt, t_end, delta_E, delta_Q, seed = case\n        \n        max_frac_E_dev, avg_Q = run_simulation(\n            N, M, a, G, epsilon, dt, t_end, t_transient, seed\n        )\n        \n        b_E = max_frac_E_dev <= delta_E\n        b_Q = abs(avg_Q - 0.5) <= delta_Q\n        \n        results.append([b_E, b_Q])\n\n    # Format the final output string precisely as required\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "The final and most scientifically pressing question is how to choose an appropriate value for the softening length, $\\epsilon$. This advanced practice places you in the role of a computational cosmologist tasked with calibrating a simulation to produce physically meaningful results . You will develop a model for how softening suppresses structure formation and build a pipeline to select an optimal $\\epsilon$ that balances numerical stability with the accurate reproduction of key cosmological observables like the matter power spectrum and halo mass function.",
            "id": "3535195",
            "problem": "You are tasked with implementing a calibration pipeline in the domain of computational astrophysics that scans the gravitational potential softening length and automatically selects a softening length that matches both matter power spectra and halo mass functions of a given small pilot cosmological run to high-resolution benchmark targets within specified tolerances. The calibration must be derived from first principles of Newtonian gravity and standard cosmological structure formation theory. The final product must be a complete, runnable program.\n\nAssume a non-relativistic, collisionless, self-gravitating system governed by Newtonian gravity, and that the pilot simulation uses a softened gravitational potential to control short-range numerical artifacts. The physical goal is to find a softening length $\\,\\epsilon\\,$ that keeps small-scale forces stable without significantly distorting clustering statistics relative to a high-resolution benchmark.\n\nStart from the following fundamental base:\n\n- Newtonian gravity and the Poisson equation: the gravitational potential $\\,\\phi(\\mathbf{r})\\,$ due to a mass density $\\,\\rho(\\mathbf{r})\\,$ satisfies $\\,\\nabla^2 \\phi(\\mathbf{r}) = 4\\pi G \\rho(\\mathbf{r})\\,$, and in Fourier space $\\,\\phi(\\mathbf{k})\\,$ is proportional to $\\,\\rho(\\mathbf{k})/k^2\\,$, where $\\,k = \\lVert \\mathbf{k} \\rVert\\,$.\n- The softened potential should be modeled by a Plummer-type replacement of the Newtonian Green’s function, wherein the $\\,1/r\\,$ singularity is regulated by a nonzero softening length $\\,\\epsilon\\,$. You must derive the corresponding Fourier-space kernel modification and explain how this changes the linear response of the system at wavenumber $\\,k\\,$.\n- In linear theory for collisionless matter, the growth of density perturbations $\\,\\delta(\\mathbf{k})\\,$ can be connected to the gravitational potential via the Poisson equation and the equations of motion. From this, derive a suppression factor $\\,S(k,\\epsilon)\\,$ that encodes how a softened gravitational kernel reduces the strength of gravitational coupling at wavenumber $\\,k\\,$ relative to the unsmoothed case.\n- For the matter power spectrum $\\,P(k)\\,$, assume that the softened kernel leads to a scale-dependent modification of growth such that $\\,P(k)\\,$ is suppressed by a function of $\\,S(k,\\epsilon)\\,$; you must justify how a power of $\\,S(k,\\epsilon)\\,$ enters the modification of $\\,P(k)\\,$ from first principles rather than by shortcut formulas.\n- For the halo mass function $\\,n(M)\\,$, assume that the suppression can be treated through the dependence of the variance of the density field on scale. Use the idea that a halo mass $\\,M\\,$ is associated with a characteristic real-space smoothing radius $\\,R(M)\\,$ and wavenumber $\\,k(M)\\,$ via standard Press–Schechter logic, without using a detailed fitting function. Derive how a softened gravitational kernel translates into a suppression factor $\\,S_M(M,\\epsilon)\\,$ and how it affects $\\,n(M)\\,$.\n\nYou must implement a pipeline that, for a set of candidate softening lengths $\\,\\epsilon\\,$ on a uniform grid within a specified interval, computes two quantitative metrics:\n\n1. A root-mean-square fractional deviation of the matter power spectrum between the softened prediction and the benchmark,\n$$\n\\Delta_P(\\epsilon) \\equiv \\sqrt{\\frac{1}{N_k} \\sum_{i=1}^{N_k} \\left(\\frac{P_{\\mathrm{pred}}(k_i;\\epsilon)-P_{\\mathrm{bench}}(k_i)}{P_{\\mathrm{bench}}(k_i)}\\right)^2 },\n$$\nwhere $\\,\\{k_i\\}\\,$ are provided discrete wavenumbers.\n\n2. A root-mean-square fractional deviation of the halo mass function between the softened prediction and the benchmark,\n$$\n\\Delta_H(\\epsilon) \\equiv \\sqrt{\\frac{1}{N_M} \\sum_{j=1}^{N_M} \\left(\\frac{n_{\\mathrm{pred}}(M_j;\\epsilon)-n_{\\mathrm{bench}}(M_j)}{n_{\\mathrm{bench}}(M_j)}\\right)^2 },\n$$\nwhere $\\,\\{M_j\\}\\,$ are provided discrete halo masses.\n\nThe pipeline must select the largest softening length $\\,\\epsilon\\,$ on the provided grid that satisfies both $\\,\\Delta_P(\\epsilon) \\le \\tau_P\\,$ and $\\,\\Delta_H(\\epsilon) \\le \\tau_H\\,$, subject to a physical lower bound $\\,\\epsilon \\ge f \\,\\bar{\\ell}\\,$, where $\\,\\bar{\\ell}\\,$ is the mean interparticle spacing and $\\,f\\,$ is a dimensionless factor to avoid excessive collisionality. If no $\\,\\epsilon\\,$ satisfies the constraints, the pipeline must return $-1.0$ for that test case.\n\nYou must explicitly handle physical units consistently:\n- Report $\\,\\epsilon\\,$ in $\\,h^{-1}\\,\\mathrm{kpc}\\,$.\n- Use wavenumbers $\\,k\\,$ in $\\,h\\,\\mathrm{Mpc}^{-1}\\,$.\n- Use masses $\\,M\\,$ in $\\,h^{-1}\\,M_\\odot\\,$.\n- Use mean matter density $\\,\\bar{\\rho}\\,$ in $\\,h^2\\,M_\\odot\\,\\mathrm{Mpc}^{-3}\\,$.\n- Convert length scales consistently between $\\,h^{-1}\\,\\mathrm{Mpc}\\,$ and $\\,h^{-1}\\,\\mathrm{kpc}\\,$ as needed.\n\nThe program must implement the following specific test suite. For each test case, use the provided benchmark arrays and parameters. The benchmark arrays are fixed numerical sequences; leave them unchanged.\n\nDefine the benchmark wavenumbers and matter power spectrum values:\n- Wavenumbers in $\\,h\\,\\mathrm{Mpc}^{-1}\\,$:\n$$\n\\{k_i\\}_{i=1}^{7} = \\{0.1,\\ 0.2,\\ 0.5,\\ 1.0,\\ 1.5,\\ 2.0,\\ 3.0\\}.\n$$\n- High-resolution benchmark matter power spectrum values in arbitrary consistent units:\n$$\n\\{P_{\\mathrm{bench}}(k_i)\\}_{i=1}^{7} = \\{1000,\\ 900,\\ 750,\\ 500,\\ 350,\\ 250,\\ 150\\}.\n$$\n\nDefine the benchmark halo masses and halo mass function values:\n- Halo masses in $\\,h^{-1}\\,M_\\odot\\,$:\n$$\n\\{M_j\\}_{j=1}^{7} = \\{10^{12},\\ 3\\times 10^{12},\\ 10^{13},\\ 3\\times 10^{13},\\ 10^{14},\\ 3\\times 10^{14},\\ 10^{15}\\}.\n$$\n- High-resolution benchmark halo mass function values in $\\,(\\mathrm{Mpc}/h)^{-3}\\,$ per unit logarithmic mass:\n$$\n\\{n_{\\mathrm{bench}}(M_j)\\}_{j=1}^{7} = \\{10^{-3},\\ 6\\times 10^{-4},\\ 3\\times 10^{-4},\\ 10^{-4},\\ 3\\times 10^{-5},\\ 5\\times 10^{-6},\\ 10^{-6}\\}.\n$$\n\nUse a mean matter density appropriate for a standard cosmology with matter density parameter $\\,\\Omega_{\\mathrm{m}} = 0.315\\,$,\n$$\n\\bar{\\rho} = 2.775\\times 10^{11}\\,\\Omega_{\\mathrm{m}}\\,h^2\\,M_\\odot\\,\\mathrm{Mpc}^{-3}.\n$$\n\nMap mass to characteristic scale using the top-hat relation\n$$\nR(M) = \\left(\\frac{3M}{4\\pi \\bar{\\rho}}\\right)^{1/3},\n$$\nand associate a characteristic wavenumber\n$$\nk(M) = \\frac{\\pi}{R(M)}.\n$$\n\nFor softened predictions, you must derive and implement a Fourier-space suppression factor $\\,S(k,\\epsilon)\\,$ from the softened potential and then construct\n$$\nP_{\\mathrm{pred}}(k;\\epsilon) = P_{\\mathrm{bench}}(k)\\,\\left[S(k,\\epsilon)\\right]^\\nu,\n$$\nwith a physically justified exponent $\\,\\nu\\,$ emerging from your derivation, and\n$$\nn_{\\mathrm{pred}}(M;\\epsilon) = n_{\\mathrm{bench}}(M)\\,\\left[S(k(M),\\epsilon)\\right]^\\gamma,\n$$\nwith a physically justified exponent $\\,\\gamma\\,$ grounded in how softened gravity alters small-scale collapse statistics. You must choose and defend values of $\\,\\nu\\,$ and $\\,\\gamma\\,$.\n\nApply the following three test cases. In each case, the uniform grid of candidate softening lengths is in $\\,h^{-1}\\,\\mathrm{Mpc}\\,$, and the mean interparticle spacing constraint uses $\\,\\epsilon \\ge f\\bar{\\ell}\\,$ with $\\,f=0.3\\,$.\n\n- Test case 1 (general case):\n    - $\\,\\bar{\\ell} = 0.25\\,h^{-1}\\,\\mathrm{Mpc}\\,$.\n    - Grid: $\\,\\epsilon \\in [0.05,\\,0.30]\\,h^{-1}\\,\\mathrm{Mpc}\\,$ with step $\\,0.005\\,h^{-1}\\,\\mathrm{Mpc}\\,$.\n    - Tolerances: $\\,\\tau_P = 0.08\\,$, $\\,\\tau_H = 0.12\\,$.\n\n- Test case 2 (tight tolerances, possible boundary pressure):\n    - $\\,\\bar{\\ell} = 0.20\\,h^{-1}\\,\\mathrm{Mpc}\\,$.\n    - Grid: $\\,\\epsilon \\in [0.02,\\,0.18]\\,h^{-1}\\,\\mathrm{Mpc}\\,$ with step $\\,0.004\\,h^{-1}\\,\\mathrm{Mpc}\\,$.\n    - Tolerances: $\\,\\tau_P = 0.03\\,$, $\\,\\tau_H = 0.05\\,$.\n\n- Test case 3 (loose tolerances, high softening allowed):\n    - $\\,\\bar{\\ell} = 0.35\\,h^{-1}\\,\\mathrm{Mpc}\\,$.\n    - Grid: $\\,\\epsilon \\in [0.10,\\,0.60]\\,h^{-1}\\,\\mathrm{Mpc}\\,$ with step $\\,0.01\\,h^{-1}\\,\\mathrm{Mpc}\\,$.\n    - Tolerances: $\\,\\tau_P = 0.30\\,$, $\\,\\tau_H = 0.30\\,$.\n\nSelection rule:\n- Among grid values satisfying $\\,\\epsilon \\ge 0.3\\,\\bar{\\ell}\\,$ and both $\\,\\Delta_P(\\epsilon) \\le \\tau_P\\,$ and $\\,\\Delta_H(\\epsilon) \\le \\tau_H\\,$, select the largest $\\,\\epsilon\\,$.\n- If no $\\,\\epsilon\\,$ satisfies the constraints, return $-1.0$ for that test case.\n\nFinal output format:\n- Your program should produce a single line of output containing the selected softening lengths for the three test cases in $\\,h^{-1}\\,\\mathrm{kpc}\\,$, each rounded to three decimal places, as a comma-separated list enclosed in square brackets, for example $\\,\\left[\\epsilon_1,\\epsilon_2,\\epsilon_3\\right]\\,$. The entries must be plain decimal floats without any unit string.\n\nYour program must be self-contained and may use the NumPy and SciPy libraries. No external input or files are allowed, and no network access is permitted.",
            "solution": "The problem statement has been critically validated and is deemed to be scientifically grounded, well-posed, and objective. It presents a clear, formalizable task in computational astrophysics that is self-contained and free of contradictions. The problem requires the derivation of physical models from first principles and their implementation in a computational pipeline, which is a substantive and valid scientific exercise. We may therefore proceed with a complete solution.\n\nThe core of the task is to find the largest gravitational softening length, $\\epsilon$, from a discrete set of candidates, that maintains the statistical properties of a cosmological simulation—specifically the matter power spectrum, $P(k)$, and the halo mass function, $n(M)$—within specified tolerances of a high-resolution benchmark. This is achieved by first deriving the theoretical impact of softening on these statistics and then implementing a numerical pipeline to perform the selection.\n\n### 1. Derivation of the Gravitational Suppression Factor in Fourier Space\n\nThe gravitational potential of a point mass $m$ in standard Newtonian gravity is $\\phi_N(r) = -Gm/r$. This potential satisfies the Poisson equation, $\\nabla^2 \\phi = 4\\pi G \\rho$, which in Fourier space becomes $-k^2 \\phi(\\mathbf{k}) = 4\\pi G \\rho(\\mathbf{k})$, yielding the familiar kernel $\\phi(\\mathbf{k}) \\propto \\rho(\\mathbf{k})/k^2$.\n\nThe problem specifies a Plummer-type softened potential to regularize the singularity at $r=0$:\n$$\n\\phi_{\\mathrm{soft}}(r) = -\\frac{Gm}{\\sqrt{r^2 + \\epsilon^2}}\n$$\nwhere $\\epsilon$ is the softening length. To understand its effect on structure formation, which is typically analyzed in Fourier space, we must find the Fourier transform of this softened potential. The Fourier transform of the Newtonian potential of a point mass is $\\tilde{\\phi}_N(\\mathbf{k}) = -4\\pi Gm / k^2$. The Fourier transform of the softened potential is:\n$$\n\\tilde{\\phi}_{\\mathrm{soft}}(\\mathbf{k}) = \\mathcal{F}\\left[ -\\frac{Gm}{\\sqrt{r^2 + \\epsilon^2}} \\right]\n$$\nThis is a standard result, often derived in the context of plasma physics or gravitation. The transform of $(r^2+a^2)^{-1/2}$ is related to the modified Bessel functions of the second kind. The result is:\n$$\n\\tilde{\\phi}_{\\mathrm{soft}}(\\mathbf{k}) = -\\frac{4\\pi Gm}{k^2} \\left[ (k\\epsilon) K_1(k\\epsilon) \\right]\n$$\nwhere $K_1$ is the modified Bessel function of the second kind of order one.\n\nBy comparing the softened and Newtonian potentials in Fourier space, we can identify the multiplicative suppression factor, which we denote $S(k, \\epsilon)$:\n$$\n\\tilde{\\phi}_{\\mathrm{soft}}(\\mathbf{k}) = \\tilde{\\phi}_N(\\mathbf{k}) \\cdot S(k, \\epsilon)\n$$\nTherefore, the suppression factor that modifies the strength of the gravitational coupling at wavenumber $k$ due to a softening of length $\\epsilon$ is:\n$$\nS(k, \\epsilon) = (k\\epsilon) K_1(k\\epsilon)\n$$\nThis function has the correct physical behavior:\n- For long wavelengths ($k\\epsilon \\to 0$), $S(k, \\epsilon) \\to 1$, meaning softening has no effect.\n- For short wavelengths ($k\\epsilon \\to \\infty$), $S(k, \\epsilon) \\to 0$, meaning gravity is strongly suppressed.\n\n### 2. Modeling the Effect on Power Spectrum and Halo Mass Function\n\nThe problem requires constructing models for the predicted (softened) power spectrum, $P_{\\mathrm{pred}}(k;\\epsilon)$, and halo mass function, $n_{\\mathrm{pred}}(M;\\epsilon)$, based on the suppression factor $S(k, \\epsilon)$.\n\n#### 2.1. Matter Power Spectrum ($P(k)$)\n\nThe matter power spectrum is defined as the variance of the density field in Fourier space, $P(k) \\propto \\langle |\\delta(\\mathbf{k})|^2 \\rangle$. The growth of density perturbations $\\delta$ is driven by gravitational instability. In linear perturbation theory and in the framework of the Zel'dovich approximation, the peculiar velocity field is sourced by the gravitational potential, and the particle displacement field $\\mathbf{\\Psi}(\\mathbf{k})$ is proportional to the gradient of the potential, $\\mathbf{\\Psi}(\\mathbf{k}) \\propto i\\mathbf{k} \\phi(\\mathbf{k})$.\n\nWith softening, the potential is suppressed, $\\phi_{\\mathrm{soft}}(\\mathbf{k}) = S(k, \\epsilon) \\phi_N(\\mathbf{k})$. Consequently, the displacement field is also suppressed by the same factor: $\\mathbf{\\Psi}_{\\mathrm{soft}}(\\mathbf{k}) = S(k, \\epsilon) \\mathbf{\\Psi}_N(\\mathbf{k})$.\n\nThe density field is related to the displacement field by the continuity equation, which in linear theory gives $\\delta(\\mathbf{k}) = -i\\mathbf{k} \\cdot \\mathbf{\\Psi}(\\mathbf{k})$. Applying this to the softened case:\n$$\n\\delta_{\\mathrm{soft}}(\\mathbf{k}) = -i\\mathbf{k} \\cdot \\mathbf{\\Psi}_{\\mathrm{soft}}(\\mathbf{k}) = -i\\mathbf{k} \\cdot [S(k, \\epsilon) \\mathbf{\\Psi}_N(\\mathbf{k})] = S(k, \\epsilon) \\delta_N(\\mathbf{k})\n$$\nThe power spectrum, being quadratic in the density field, is therefore suppressed by the square of the suppression factor:\n$$\nP_{\\mathrm{pred}}(k;\\epsilon) = \\langle |\\delta_{\\mathrm{soft}}(\\mathbf{k})|^2 \\rangle = \\langle |S(k, \\epsilon) \\delta_N(\\mathbf{k})|^2 \\rangle = [S(k, \\epsilon)]^2 \\langle |\\delta_N(\\mathbf{k})|^2 \\rangle = [S(k, \\epsilon)]^2 P_{\\mathrm{bench}}(k)\n$$\nThis provides a firm physical justification for choosing the exponent $\\nu=2$.\n\n#### 2.2. Halo Mass Function ($n(M)$)\n\nThe halo mass function describes the number density of collapsed, gravitationally bound objects (halos) of a given mass $M$. Theories like Press-Schechter and its extensions relate $n(M)$ to the variance of the linear density field, $\\sigma^2(M)$, smoothed on a scale $R(M)$ corresponding to the halo mass.\n\nSoftening suppresses the power spectrum, which in turn reduces the variance $\\sigma^2(M)$. As established, $\\delta_{\\mathrm{soft}}(\\mathbf{k}) \\approx S(k, \\epsilon) \\delta_N(\\mathbf{k})$. This suggests that the density fluctuations that seed halos are themselves suppressed. A simple, first-principles argument is that the abundance of halos might scale in proportion to the amplitude of these seed fluctuations. If the number of regions exceeding a collapse threshold is proportional to the typical fluctuation amplitude at that scale, then the halo mass function would be suppressed by a factor of $S(k, \\epsilon)$.\n\nThis implies that:\n$$\nn_{\\mathrm{pred}}(M;\\epsilon) = n_{\\mathrm{bench}}(M) \\cdot [S(k(M), \\epsilon)]^1\n$$\nwhere $k(M)$ is the characteristic wavenumber associated with mass $M$. This provides a physical basis for choosing the exponent $\\gamma=1$. While more sophisticated models exist (e.g., involving the exponential sensitivity of the high-mass tail of $n(M)$ to changes in $\\sigma$), this linear scaling represents a robust and direct consequence of the suppression of the linear density field, consistent with the \"first principles\" approach requested.\n\n### 3. Algorithmic Pipeline and Implementation\n\nThe calibration pipeline is implemented as follows:\n1.  **Initialization**: Define all constants, benchmark data, and test case parameters as specified in the problem. The mean matter density $\\bar{\\rho}$ is calculated as $\\bar{\\rho} = 2.775\\times 10^{11}\\,\\Omega_{\\mathrm{m}}\\,h^2\\,M_\\odot\\,\\mathrm{Mpc}^{-3}$ with $\\Omega_{\\mathrm{m}} = 0.315$. Units are handled consistently, with $\\epsilon$ and $k$ having inverse units of length such that their product $k\\epsilon$ is dimensionless.\n2.  **Iterate Test Cases**: The main program loops through each of the three defined test cases.\n3.  **Candidate Evaluation**: For each test case, the pipeline iterates through every candidate softening length $\\epsilon$ on its specified grid.\n    a. **Physical Constraint**: First, it checks if $\\epsilon$ respects the physical lower bound $\\epsilon \\ge f \\bar{\\ell}$, where $f=0.3$. Candidates that are too small are discarded.\n    b. **Power Spectrum Deviation $\\Delta_P(\\epsilon)$**: For each valid $\\epsilon$, the deviation from the benchmark power spectrum is calculated. For each benchmark wavenumber $k_i$, we compute $P_{\\mathrm{pred}}(k_i;\\epsilon) = P_{\\mathrm{bench}}(k_i)\\,[S(k_i, \\epsilon)]^2$. The root-mean-square of the fractional differences is then computed according to the provided formula for $\\Delta_P(\\epsilon)$.\n    c. **Halo Mass Function Deviation $\\Delta_H(\\epsilon)$**: Similarly, the deviation from the benchmark halo mass function is calculated. For each benchmark mass $M_j$, we compute its characteristic radius $R(M_j) = (3M_j / 4\\pi\\bar{\\rho})^{1/3}$ and wavenumber $k(M_j) = \\pi/R(M_j)$. We then compute $n_{\\mathrm{pred}}(M_j;\\epsilon) = n_{\\mathrm{bench}}(M_j)\\,[S(k(M_j), \\epsilon)]^1$. The root-mean-square of the fractional differences gives $\\Delta_H(\\epsilon)$.\n    d. **Tolerance Check**: The computed deviations are compared against the tolerances: $\\Delta_P(\\epsilon) \\le \\tau_P$ and $\\Delta_H(\\epsilon) \\le \\tau_H$.\n4.  **Selection Logic**:\n    - All values of $\\epsilon$ from the grid that satisfy both the physical constraint and the two tolerance constraints are collected.\n    - If this set of valid softening lengths is not empty, the largest value from the set is chosen as the optimal $\\epsilon$.\n    - If the set is empty (i.e., no value of $\\epsilon$ on the grid satisfies all conditions), the result for that test case is defined as $-1.0$.\n5.  **Final Output**: The selected $\\epsilon$ for each test case, which is in units of $h^{-1}\\,\\mathrm{Mpc}$, is converted to $h^{-1}\\,\\mathrm{kpc}$ by multiplying by $1000$. The final results are collected and printed in the specified format `[result1, result2, result3]`, with each value rounded to three decimal places.\n\nThis procedure provides a complete and deterministic solution to the problem as stated.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import k1\n\ndef solve():\n    \"\"\"\n    Implements a calibration pipeline to select an optimal gravitational softening length\n    based on matching matter power spectra and halo mass functions to benchmarks.\n    \"\"\"\n\n    # --- Fixed Physical Constants and Benchmark Data ---\n\n    # Cosmological parameters\n    OMEGA_M = 0.315\n    # Mean matter density in h^2 M_sun / Mpc^3\n    RHO_BAR = 2.775e11 * OMEGA_M\n\n    # Benchmark wavenumbers k_i in h/Mpc\n    K_BENCH = np.array([0.1, 0.2, 0.5, 1.0, 1.5, 2.0, 3.0])\n    # Benchmark matter power spectrum P_bench(k_i)\n    P_BENCH = np.array([1000.0, 900.0, 750.0, 500.0, 350.0, 250.0, 150.0])\n\n    # Benchmark halo masses M_j in h^-1 M_sun\n    M_BENCH = np.array([1e12, 3e12, 1e13, 3e13, 1e14, 3e14, 1e15])\n    # Benchmark halo mass function n_bench(M_j) in (Mpc/h)^-3 / ln(M)\n    N_BENCH = np.array([1e-3, 6e-4, 3e-4, 1e-4, 3e-5, 5e-6, 1e-6])\n    \n    # Exponents for suppression models, as derived from first principles\n    NU_P = 2.0  # For power spectrum P(k) \\propto [S(k,e)]^nu\n    GAMMA_H = 1.0 # For halo mass function n(M) \\propto [S(k(M),e)]^gamma\n\n    # Factor for physical lower bound on softening\n    F_LOWER_BOUND = 0.3\n\n    # --- Helper Functions ---\n\n    def suppression_factor(k, epsilon):\n        \"\"\"\n        Calculates the Fourier-space suppression factor S(k, epsilon) for a\n        Plummer potential.\n        S(k, e) = (k*e) * K_1(k*e), where K_1 is modified Bessel function.\n        \"\"\"\n        x = k * epsilon\n        # Handle the limit x -> 0 where x*K1(x) -> 1, avoiding potential numerical issues.\n        # SciPy's k1 handles x=0 correctly (inf), so we check x.\n        # A small x limit where the approximation is good.\n        if np.all(x < 1e-6):\n            return np.ones_like(x)\n        # For non-zero x, calculate directly.\n        return x * k1(x)\n\n    def mass_to_wavenumber(M):\n        \"\"\"\n        Converts halo mass M to characteristic wavenumber k(M) via top-hat radius.\n        R(M) = (3*M / (4*pi*rho_bar))^(1/3)\n        k(M) = pi / R(M)\n        \"\"\"\n        # R is in h^-1 Mpc\n        R = (3.0 * M / (4.0 * np.pi * RHO_BAR))**(1.0/3.0)\n        # k is in h Mpc^-1\n        k = np.pi / R\n        return k\n\n    # --- Test Case Definitions ---\n    test_cases = [\n        {\n            \"l_bar\": 0.25,  # h^-1 Mpc\n            \"eps_grid_params\": (0.05, 0.30, 0.005), # start, stop, step in h^-1 Mpc\n            \"tau_P\": 0.08,\n            \"tau_H\": 0.12,\n        },\n        {\n            \"l_bar\": 0.20,\n            \"eps_grid_params\": (0.02, 0.18, 0.004),\n            \"tau_P\": 0.03,\n            \"tau_H\": 0.05,\n        },\n        {\n            \"l_bar\": 0.35,\n            \"eps_grid_params\": (0.10, 0.60, 0.01),\n            \"tau_P\": 0.30,\n            \"tau_H\": 0.30,\n        },\n    ]\n\n    final_results = []\n\n    # --- Main Loop over Test Cases ---\n    for case in test_cases:\n        l_bar = case[\"l_bar\"]\n        start, stop, step = case[\"eps_grid_params\"]\n        tau_P = case[\"tau_P\"]\n        tau_H = case[\"tau_H\"]\n\n        # Generate grid of candidate epsilon values in h^-1 Mpc\n        # Use np.arange and add a small amount to stop to ensure it's inclusive\n        eps_grid = np.arange(start, stop + step / 2, step)\n\n        # Physical lower bound for epsilon in h^-1 Mpc\n        eps_min_phys = F_LOWER_BOUND * l_bar\n\n        valid_epsilons = []\n\n        # characteristic wavenumbers for halo masses\n        k_from_M_bench = mass_to_wavenumber(M_BENCH)\n\n        for eps in eps_grid:\n            # 1. Check physical constraint\n            if eps < eps_min_phys:\n                continue\n\n            # 2. Calculate P(k) deviation\n            S_k = suppression_factor(K_BENCH, eps)\n            P_pred = P_BENCH * (S_k**NU_P)\n            delta_P = np.sqrt(np.mean(((P_pred - P_BENCH) / P_BENCH)**2))\n\n            # 3. Calculate n(M) deviation\n            S_M = suppression_factor(k_from_M_bench, eps)\n            n_pred = N_BENCH * (S_M**GAMMA_H)\n            delta_H = np.sqrt(np.mean(((n_pred - N_BENCH) / N_BENCH)**2))\n\n            # 4. Check tolerances\n            if delta_P <= tau_P and delta_H <= tau_H:\n                valid_epsilons.append(eps)\n\n        if not valid_epsilons:\n            # No epsilon satisfied the constraints\n            result = -1.0\n        else:\n            # Select the largest valid epsilon\n            # The result is in h^-1 Mpc, convert to h^-1 kpc\n            result = max(valid_epsilons) * 1000.0\n\n        final_results.append(result)\n\n    # Format the final output as specified\n    formatted_results = [f\"{res:.3f}\" if res != -1.0 else \"-1.0\" for res in final_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}