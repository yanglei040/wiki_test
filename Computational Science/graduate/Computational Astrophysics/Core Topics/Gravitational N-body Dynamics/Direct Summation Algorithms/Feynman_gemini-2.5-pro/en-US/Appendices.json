{
    "hands_on_practices": [
        {
            "introduction": "Before analyzing the accuracy or performance of a simulation, one must first verify its fundamental correctness. This practice guides you through implementing one of the most crucial sanity checks for an $N$-body code: testing the conservation of center-of-mass motion . You will see firsthand how correctly implementing Newton's third law results in the expected inertial trajectory and, conversely, how a deliberate, subtle bug violating this law causes an unphysical drift that your diagnostic will readily detect.",
            "id": "3508414",
            "problem": "You are tasked with designing and implementing a direct-summation gravitational $N$-body integrator that quantitatively tests conservation of the system’s center-of-mass motion as a sanity check for force summation correctness. Begin from Newton’s laws of motion and the definition of the center of mass, and use only internal gravitational interactions. Using this fundamental base, derive the fact that the center of mass of a closed system with only internal forces follows inertial motion, and use that theoretical result to define a measurable deviation for a numerical simulation. Your program must directly implement a pairwise force computation (no treecodes or multipole expansions), a time integrator, and a diagnostic that compares the simulated center-of-mass trajectory against the expected inertial trajectory.\n\nThe physical model is Newtonian gravity with Plummer softening, with total gravitational acceleration on particle $i$ due to particle $j$ constructed from the softened Newtonian pairwise law and added over all $j\\neq i$. Use the gravitational constant $G$ in the International System of Units (SI) and express all distances in meters, masses in kilograms, and times in seconds.\n\nYour algorithm must implement two force-accumulation modes:\n- A correct symmetric pairwise accumulation that enforces equal-and-opposite pair contributions for each interacting pair, consistent with Newton’s third law.\n- A perturbed mode that deliberately violates action–reaction symmetry by a small dimensionless parameter $\\eta$ to mimic a buggy force summation. In this mode, for every unordered pair $\\{i,j\\}$, multiply the pair’s contribution to particle $i$’s acceleration by $(1+\\eta)$ and to particle $j$’s acceleration by $(1-\\eta)$.\n\nTime integration must use a symplectic leapfrog scheme. Initialize from given positions and velocities at time $t=0$, and advance in uniform time steps $\\Delta t$ for $n_{\\mathrm{steps}}$ steps. At each step, compute the system’s center-of-mass position $\\mathbf{R}_{\\mathrm{cm}}(t)$ and compare it to the inertial reference trajectory predicted from the initial center-of-mass position $\\mathbf{R}_{\\mathrm{cm}}(0)$ and initial center-of-mass velocity $\\mathbf{V}_{\\mathrm{cm}}(0)$. Define the deviation at time $t$ as the Euclidean norm of the vector difference between the simulated and inertial-reference center-of-mass positions. Your program must report, for each test case, the maximum deviation over the full simulation time.\n\nAll outputs must be reported in SI units. The maximum deviation must be expressed in meters. Use radians implicitly for any vector operations; no angles are directly required. Your program must format each reported value as a decimal float in scientific notation with $6$ significant digits.\n\nTest Suite. Implement the following four test cases; for each case, compute the maximum deviation of the system’s center of mass from its expected inertial trajectory. For all cases, use the gravitational constant $G=6.67430\\times 10^{-11}\\ \\mathrm{m^{3}\\ kg^{-1}\\ s^{-2}}$ and the Plummer softening length $\\epsilon$ provided per case.\n\n- Case $1$ (happy path, correct symmetry):\n  - $N=3$\n  - Masses $\\mathbf{m}=[5\\times 10^{24},\\ 6\\times 10^{24},\\ 7\\times 10^{24}]\\ \\mathrm{kg}$\n  - Initial positions $\\mathbf{r}(0)$ in meters:\n    - $\\mathbf{r}_1=[0,\\ 0,\\ 0]$\n    - $\\mathbf{r}_2=[2\\times 10^{9},\\ 0,\\ 0]$\n    - $\\mathbf{r}_3=[-1\\times 10^{9},\\ 1.5\\times 10^{9},\\ 0]$\n  - Initial velocities $\\mathbf{v}(0)$ in meters per second:\n    - $\\mathbf{v}_1=[0,\\ 300,\\ 0]$\n    - $\\mathbf{v}_2=[0,\\ -100,\\ 0]$\n    - $\\mathbf{v}_3=[50,\\ 0,\\ 0]$\n  - Time step $\\Delta t=2000\\ \\mathrm{s}$, number of steps $n_{\\mathrm{steps}}=1000$\n  - Softening $\\epsilon=10^{6}\\ \\mathrm{m}$\n  - Symmetry perturbation parameter $\\eta=0$\n\n- Case $2$ (action–reaction violation, detect drift):\n  - Identical to Case $1$ except use $\\eta=1\\times 10^{-5}$\n\n- Case $3$ (boundary condition $N=1$):\n  - $N=1$\n  - Masses $\\mathbf{m}=[1\\times 10^{26}]\\ \\mathrm{kg}$\n  - Initial positions $\\mathbf{r}(0)$ in meters:\n    - $\\mathbf{r}_1=[1\\times 10^{8},\\ -2\\times 10^{8},\\ 0]$\n  - Initial velocities $\\mathbf{v}(0)$ in meters per second:\n    - $\\mathbf{v}_1=[1200,\\ -500,\\ 0]$\n  - Time step $\\Delta t=1000\\ \\mathrm{s}$, number of steps $n_{\\mathrm{steps}}=2000$\n  - Softening $\\epsilon=10^{6}\\ \\mathrm{m}$\n  - Symmetry perturbation parameter $\\eta=0$\n\n- Case $4$ (zero total momentum, stationary center of mass expected):\n  - $N=4$\n  - Masses $\\mathbf{m}=[2\\times 10^{25},\\ 3\\times 10^{25},\\ 4\\times 10^{25},\\ 5\\times 10^{25}]\\ \\mathrm{kg}$\n  - Initial positions $\\mathbf{r}(0)$ in meters:\n    - $\\mathbf{r}_1=[1\\times 10^{9},\\ 0,\\ 0]$\n    - $\\mathbf{r}_2=[-1\\times 10^{9},\\ 1\\times 10^{9},\\ 0]$\n    - $\\mathbf{r}_3=[0,\\ -1\\times 10^{9},\\ 0]$\n    - $\\mathbf{r}_4=[2\\times 10^{9},\\ 2\\times 10^{9},\\ 0]$\n  - Initial velocities $\\mathbf{v}(0)$ in meters per second:\n    - $\\mathbf{v}_1=[200,\\ 0,\\ 0]$\n    - $\\mathbf{v}_2=[-100,\\ 100,\\ 0]$\n    - $\\mathbf{v}_3=[0,\\ -50,\\ 0]$\n    - $\\mathbf{v}_4=[-20,\\ -20,\\ 0]$\n  - Time step $\\Delta t=1500\\ \\mathrm{s}$, number of steps $n_{\\mathrm{steps}}=1200$\n  - Softening $\\epsilon=5\\times 10^{5}\\ \\mathrm{m}$\n  - Symmetry perturbation parameter $\\eta=0$\n\nRequired final output format. Your program should produce a single line of output containing the four maximum deviations, in meters, each formatted in scientific notation with $6$ significant digits, as a comma-separated list enclosed in square brackets. For example, the output must have the form \"[x,y,z,w]\" where each of $x$, $y$, $z$, and $w$ is a float written in scientific notation with $6$ significant digits and no units. No other text should be printed.",
            "solution": "The problem is well-posed, scientifically grounded, and contains all necessary information for a unique solution. It requests the design and implementation of an $N$-body integrator to test the conservation of center-of-mass motion, a direct consequence of Newton's third law, providing a fundamental sanity check for the force summation algorithm. We will proceed with a full solution.\n\n### Theoretical Foundation: Center-of-Mass Motion in a Closed System\n\nThe foundation of this problem lies in Newtonian mechanics. We begin by defining the center of mass (CM) of a system of $N$ particles, where particle $i$ has mass $m_i$ and position vector $\\mathbf{r}_i$.\n\nThe total mass of the system is $M_{\\mathrm{tot}} = \\sum_{i=1}^{N} m_i$.\nThe position of the center of mass, $\\mathbf{R}_{\\mathrm{cm}}$, is the mass-weighted average of the particle positions:\n$$\n\\mathbf{R}_{\\mathrm{cm}}(t) = \\frac{1}{M_{\\mathrm{tot}}} \\sum_{i=1}^{N} m_i \\mathbf{r}_i(t)\n$$\n\nDifferentiating with respect to time $t$ gives the velocity of the center of mass, $\\mathbf{V}_{\\mathrm{cm}}$:\n$$\n\\mathbf{V}_{\\mathrm{cm}}(t) = \\frac{d\\mathbf{R}_{\\mathrm{cm}}}{dt} = \\frac{1}{M_{\\mathrm{tot}}} \\sum_{i=1}^{N} m_i \\frac{d\\mathbf{r}_i}{dt} = \\frac{1}{M_{\\mathrm{tot}}} \\sum_{i=1}^{N} m_i \\mathbf{v}_i(t)\n$$\nThe quantity $\\sum m_i \\mathbf{v}_i$ is the total momentum of the system, $\\mathbf{P}_{\\mathrm{tot}}$, so $\\mathbf{P}_{\\mathrm{tot}} = M_{\\mathrm{tot}} \\mathbf{V}_{\\mathrm{cm}}$.\n\nDifferentiating a second time yields the acceleration of the center of mass, $\\mathbf{A}_{\\mathrm{cm}}$:\n$$\n\\mathbf{A}_{\\mathrm{cm}}(t) = \\frac{d\\mathbf{V}_{\\mathrm{cm}}}{dt} = \\frac{1}{M_{\\mathrm{tot}}} \\sum_{i=1}^{N} m_i \\frac{d\\mathbf{v}_i}{dt} = \\frac{1}{M_{\\mathrm{tot}}} \\sum_{i=1}^{N} m_i \\mathbf{a}_i(t)\n$$\n\nAccording to Newton's second law, the term $m_i \\mathbf{a}_i$ is equal to the total force acting on particle $i$, $\\mathbf{F}_i^{\\mathrm{tot}}$. For a closed system with only internal forces, this force is the vector sum of forces from all other particles $j$ in the system:\n$$\nm_i \\mathbf{a}_i = \\mathbf{F}_i^{\\mathrm{tot}} = \\sum_{j=1, j\\neq i}^{N} \\mathbf{F}_{ij}\n$$\nwhere $\\mathbf{F}_{ij}$ is the force exerted on particle $i$ by particle $j$. Substituting this into the equation for $\\mathbf{A}_{\\mathrm{cm}}$ gives:\n$$\nM_{\\mathrm{tot}} \\mathbf{A}_{\\mathrm{cm}} = \\sum_{i=1}^{N} \\mathbf{F}_i^{\\mathrm{tot}} = \\sum_{i=1}^{N} \\sum_{j=1, j\\neq i}^{N} \\mathbf{F}_{ij}\n$$\n\nThe crucial step is to apply Newton's third law (the law of action and reaction), which states that forces between any two particles are equal and opposite: $\\mathbf{F}_{ij} = -\\mathbf{F}_{ji}$. The double summation on the right can be viewed as a sum over all interacting pairs $\\{i,j\\}$. For each pair, the sum contains both $\\mathbf{F}_{ij}$ and $\\mathbf{F}_{ji}$.\n$$\n\\sum_{i=1}^{N} \\sum_{j=1, j\\neq i}^{N} \\mathbf{F}_{ij} = \\sum_{i < j} (\\mathbf{F}_{ij} + \\mathbf{F}_{ji})\n$$\nBy Newton's third law, each term $(\\mathbf{F}_{ij} + \\mathbf{F}_{ji})$ is identically zero. Therefore, the total internal force on the system is zero:\n$$\n\\sum_{i=1}^{N} \\mathbf{F}_i^{\\mathrm{tot}} = \\mathbf{0}\n$$\nThis implies that $M_{\\mathrm{tot}} \\mathbf{A}_{\\mathrm{cm}} = \\mathbf{0}$, and thus $\\mathbf{A}_{\\mathrm{cm}} = \\mathbf{0}$. The acceleration of the center of mass is zero. This is the law of conservation of momentum.\n\nIf $\\mathbf{A}_{\\mathrm{cm}} = \\mathbf{0}$, then the velocity $\\mathbf{V}_{\\mathrm{cm}}$ is constant and equal to its initial value, $\\mathbf{V}_{\\mathrm{cm}}(0)$. Integrating once more, we find that the center of mass must follow an inertial trajectory (a straight line at constant velocity):\n$$\n\\mathbf{R}_{\\mathrm{cm}}(t) = \\mathbf{R}_{\\mathrm{cm}}(0) + \\mathbf{V}_{\\mathrm{cm}}(0) t\n$$\nThis equation defines the reference trajectory against which the numerical simulation is tested.\n\n### Algorithmic Design and Numerical Implementation\n\nThe task now is to translate this physical principle into a numerical algorithm.\n\n#### 1. Force Calculation with Plummer Softening\n\nThe gravitational force on particle $i$ due to particle $j$ is given by Newton's law of gravitation, modified with Plummer softening to avoid numerical singularities when particles are very close. The force vector is:\n$$\n\\mathbf{F}_{ij} = G m_i m_j \\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left( \\|\\mathbf{r}_j - \\mathbf{r}_i\\|^2 + \\epsilon^2 \\right)^{3/2}}\n$$\nwhere $G$ is the gravitational constant and $\\epsilon$ is the softening length. The acceleration of particle $i$ is $\\mathbf{a}_i = \\frac{1}{m_i} \\sum_{j \\neq i} \\mathbf{F}_{ij}$.\n\n#### 2. Action-Reaction Symmetry Violation\n\nThe core of the diagnostic test involves two modes for force accumulation:\n- **Symmetric Mode ($\\eta = 0$):** In a direct summation loop over unique pairs $(i, j)$ with $i < j$, we calculate $\\mathbf{F}_{ij}$ and add it to the total force on particle $i$, and add $\\mathbf{F}_{ji} = -\\mathbf{F}_{ij}$ to the total force on particle $j$. This correctly implements Newton's third law. Total system momentum is conserved, up to numerical error.\n- **Perturbed Mode ($\\eta \\neq 0$):** The problem specifies a deliberate violation of symmetry. For each pair $\\{i,j\\}$ (we use the convention $i<j$ to make the choice deterministic), the contribution to particle $i$'s acceleration is scaled by $(1+\\eta)$ and to particle $j$'s acceleration by $(1-\\eta)$. Let $\\mathbf{a}_{ij}$ be the acceleration on $i$ from $j$.\n  - The contribution to $i$'s total acceleration becomes $(1+\\eta)\\mathbf{a}_{ij}$.\n  - The contribution to $j$'s total acceleration becomes $(1-\\eta)\\mathbf{a}_{ji}$.\nThe sum of forces on the pair is no longer zero: $m_i(1+\\eta)\\mathbf{a}_{ij} + m_j(1-\\eta)\\mathbf{a}_{ji} = (1+\\eta)\\mathbf{F}_{ij} + (1-\\eta)\\mathbf{F}_{ji} = ((1+\\eta) - (1-\\eta))\\mathbf{F}_{ij} = 2\\eta\\mathbf{F}_{ij} \\neq \\mathbf{0}$. This creates a net internal force that causes the system's center of mass to accelerate, leading to a measurable deviation from its inertial path.\n\n#### 3. Time Integration: Symplectic Leapfrog (KDK)\n\nWe use a second-order symplectic leapfrog integrator, specifically the \"Kick-Drift-Kick\" (KDK) formulation. It is well-suited for gravitational dynamics due to its good long-term energy and momentum conservation properties (for the symmetric case). The algorithm proceeds as follows, starting with initial positions $\\mathbf{r}(0)$ and velocities $\\mathbf{v}(0)$ at time $t=0$:\n\n1.  **Initial Kick (half-step):** Calculate initial accelerations $\\mathbf{a}(0)$ from $\\mathbf{r}(0)$. Advance velocities by a half time step $\\Delta t/2$:\n    $$\n    \\mathbf{v}(\\Delta t/2) = \\mathbf{v}(0) + \\mathbf{a}(0) \\frac{\\Delta t}{2}\n    $$\n2.  **Main Loop:** For $n = 0, 1, \\dots, n_{\\mathrm{steps}}-1$:\n    a. **Drift (full-step):** Update positions using the half-step velocities:\n       $$\n       \\mathbf{r}((n+1)\\Delta t) = \\mathbf{r}(n\\Delta t) + \\mathbf{v}((n+1/2)\\Delta t) \\Delta t\n       $$\n    b. **Kick (full-step):** Compute new accelerations $\\mathbf{a}((n+1)\\Delta t)$ at the new positions. Update velocities to the next half-step:\n       $$\n       \\mathbf{v}((n+3/2)\\Delta t) = \\mathbf{v}((n+1/2)\\Delta t) + \\mathbf{a}((n+1)\\Delta t) \\Delta t\n       $$\n\n#### 4. Diagnostic Measurement\n\nAt each full time step $t_k = k \\Delta t$ (for $k = 1, \\dots, n_{\\mathrm{steps}}$), after the Drift step, we have the simulated positions $\\mathbf{r}(t_k)$.\n1.  Compute the simulated center-of-mass position:\n    $$\n    \\mathbf{R}_{\\mathrm{cm, sim}}(t_k) = \\frac{1}{M_{\\mathrm{tot}}} \\sum_{i=1}^{N} m_i \\mathbf{r}_i(t_k)\n    $$\n2.  Compute the theoretical inertial reference position:\n    $$\n    \\mathbf{R}_{\\mathrm{cm, ref}}(t_k) = \\mathbf{R}_{\\mathrm{cm}}(0) + \\mathbf{V}_{\\mathrm{cm}}(0) t_k\n    $$\n3.  Calculate the deviation $D(t_k)$ as the Euclidean norm of the difference:\n    $$\n    D(t_k) = \\|\\mathbf{R}_{\\mathrm{cm, sim}}(t_k) - \\mathbf{R}_{\\mathrm{cm, ref}}(t_k)\\|\n    $$\nThe final reported value for each test case is the maximum deviation observed over the entire simulation: $\\max_{k} D(t_k)$.\n\nThis comprehensive approach allows for a direct, quantitative test of the consequences of preserving or violating Newton's third law within a numerical simulation. The case $N=1$ serves as a control, as there are no internal forces, and the deviation should be zero to within machine precision. The case with $\\mathbf{V}_{\\mathrm{cm}}(0)=\\mathbf{0}$ tests for spurious motion of an initially stationary center of mass.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function to execute all test cases and print the final result.\n    \"\"\"\n    G = 6.67430e-11  # SI units: m^3 kg^-1 s^-2\n\n    test_cases = [\n        # Case 1 (happy path, correct symmetry)\n        {\n            \"N\": 3,\n            \"masses\": np.array([5e24, 6e24, 7e24]),\n            \"positions\": np.array([\n                [0.0, 0.0, 0.0],\n                [2e9, 0.0, 0.0],\n                [-1e9, 1.5e9, 0.0]\n            ]),\n            \"velocities\": np.array([\n                [0.0, 300.0, 0.0],\n                [0.0, -100.0, 0.0],\n                [50.0, 0.0, 0.0]\n            ]),\n            \"dt\": 2000.0,\n            \"n_steps\": 1000,\n            \"epsilon\": 1e6,\n            \"eta\": 0.0,\n        },\n        # Case 2 (action–reaction violation, detect drift)\n        {\n            \"N\": 3,\n            \"masses\": np.array([5e24, 6e24, 7e24]),\n            \"positions\": np.array([\n                [0.0, 0.0, 0.0],\n                [2e9, 0.0, 0.0],\n                [-1e9, 1.5e9, 0.0]\n            ]),\n            \"velocities\": np.array([\n                [0.0, 300.0, 0.0],\n                [0.0, -100.0, 0.0],\n                [50.0, 0.0, 0.0]\n            ]),\n            \"dt\": 2000.0,\n            \"n_steps\": 1000,\n            \"epsilon\": 1e6,\n            \"eta\": 1e-5,\n        },\n        # Case 3 (boundary condition N=1)\n        {\n            \"N\": 1,\n            \"masses\": np.array([1e26]),\n            \"positions\": np.array([\n                [1e8, -2e8, 0.0]\n            ]),\n            \"velocities\": np.array([\n                [1200.0, -500.0, 0.0]\n            ]),\n            \"dt\": 1000.0,\n            \"n_steps\": 2000,\n            \"epsilon\": 1e6,\n            \"eta\": 0.0,\n        },\n        # Case 4 (zero total momentum)\n        {\n            \"N\": 4,\n            \"masses\": np.array([2e25, 3e25, 4e25, 5e25]),\n            \"positions\": np.array([\n                [1e9, 0.0, 0.0],\n                [-1e9, 1e9, 0.0],\n                [0.0, -1e9, 0.0],\n                [2e9, 2e9, 0.0]\n            ]),\n            \"velocities\": np.array([\n                [200.0, 0.0, 0.0],\n                [-100.0, 100.0, 0.0],\n                [0.0, -50.0, 0.0],\n                [-20.0, -20.0, 0.0]\n            ]),\n            \"dt\": 1500.0,\n            \"n_steps\": 1200,\n            \"epsilon\": 5e5,\n            \"eta\": 0.0,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        max_deviation = run_simulation(\n            masses=case[\"masses\"],\n            positions=case[\"positions\"],\n            velocities=case[\"velocities\"],\n            G=G,\n            dt=case[\"dt\"],\n            n_steps=case[\"n_steps\"],\n            epsilon=case[\"epsilon\"],\n            eta=case[\"eta\"]\n        )\n        results.append(f\"{max_deviation:.6e}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_accelerations(positions, masses, G, epsilon, eta):\n    \"\"\"\n    Calculates gravitational accelerations using direct summation.\n    \n    This function implements both symmetric force accumulation (eta=0) and a\n    perturbed mode that violates Newton's third law (eta != 0).\n    \"\"\"\n    n_particles = positions.shape[0]\n    accelerations = np.zeros((n_particles, 3))\n    \n    # Iterate over unique pairs of particles (i, j) where i < j\n    for i in range(n_particles):\n        for j in range(i + 1, n_particles):\n            # Vector from particle i to particle j\n            r_ij = positions[j] - positions[i]\n            \n            # Squared distance with softening\n            dist_sq = np.sum(r_ij**2)\n            \n            # Softened inverse cube law factor\n            inv_dist_cubed = (dist_sq + epsilon**2)**(-1.5)\n            \n            # Calculate acceleration contribution for each particle due to the other\n            acc_i_due_to_j = G * masses[j] * inv_dist_cubed * r_ij\n            acc_j_due_to_i = G * masses[i] * inv_dist_cubed * (-r_ij)\n            \n            # Apply symmetric or asymmetric force accumulation\n            # For a pair {i,j}, the contribution to i's acceleration is scaled by (1+eta)\n            # and to j's acceleration by (1-eta).\n            accelerations[i] += (1.0 + eta) * acc_i_due_to_j\n            accelerations[j] += (1.0 - eta) * acc_j_due_to_i\n            \n    return accelerations\n\ndef run_simulation(masses, positions, velocities, G, dt, n_steps, epsilon, eta):\n    \"\"\"\n    Runs a single N-body simulation and returns the max CM deviation.\n    \"\"\"\n    # Defensive copies to avoid modifying the original test case data\n    pos = np.copy(positions)\n    vel = np.copy(velocities)\n    masses_reshaped = masses.reshape(-1, 1)\n    \n    total_mass = np.sum(masses)\n    \n    # Calculate initial center-of-mass position and velocity\n    if total_mass > 0:\n        R_cm_0 = np.sum(masses_reshaped * pos, axis=0) / total_mass\n        V_cm_0 = np.sum(masses_reshaped * vel, axis=0) / total_mass\n    else: # Handle case of zero total mass if needed, though not in tests\n        R_cm_0 = np.zeros(3)\n        V_cm_0 = np.zeros(3)\n\n    max_deviation = 0.0\n\n    # Leapfrog Integrator (KDK - Kick-Drift-Kick)\n    \n    # Initial Kick (half-step)\n    acc = calculate_accelerations(pos, masses, G, epsilon, eta)\n    vel += acc * (dt / 2.0)\n    \n    for step in range(n_steps):\n        # Drift (full step)\n        pos += vel * dt\n        \n        # Kick (full step)\n        acc = calculate_accelerations(pos, masses, G, epsilon, eta)\n        vel += acc * dt\n        \n        # --- Diagnostic Calculation ---\n        current_time = (step + 1) * dt\n        \n        # Calculate simulated center-of-mass position\n        R_cm_sim = np.sum(masses_reshaped * pos, axis=0) / total_mass\n        \n        # Calculate theoretical inertial reference position\n        R_cm_ref = R_cm_0 + V_cm_0 * current_time\n        \n        # Calculate deviation and update maximum\n        deviation = np.linalg.norm(R_cm_sim - R_cm_ref)\n        if deviation > max_deviation:\n            max_deviation = deviation\n            \n    return max_deviation\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "A \"correct\" algorithm is not necessarily an accurate one, as all numerical simulations are subject to errors from both discretization and finite-precision arithmetic. This exercise introduces the forward-backward integration test, a powerful technique for diagnosing and quantifying the numerical errors inherent in a time integration scheme . By comparing a time-reversible symplectic method with a non-reversible Runge-Kutta scheme, you will learn to distinguish between truncation error from the algorithm's approximation and roundoff error from machine limitations.",
            "id": "3508413",
            "problem": "Consider a small $N$-body system evolving under Newtonian gravity. The computational task is to design and execute a forward–backward integration experiment using a direct summation algorithm for gravitational accelerations, and to quantify reversibility errors attributable to truncation and roundoff. The experiment must be performed in dimensionless units with gravitational constant $G=1$. The foundational laws and definitions for this problem are Newton’s second law and Newton’s law of universal gravitation: the acceleration of particle $i$ with mass $m_i$ is given by\n$$\n\\frac{d^2 \\boldsymbol{r}_i}{dt^2} = \\boldsymbol{a}_i(\\boldsymbol{r}) = \\sum_{j \\ne i} G m_j \\frac{\\boldsymbol{r}_j - \\boldsymbol{r}_i}{\\left(\\lVert \\boldsymbol{r}_j - \\boldsymbol{r}_i \\rVert^2 + \\epsilon^2 \\right)^{3/2}},\n$$\nwhere $\\boldsymbol{r}_i \\in \\mathbb{R}^3$ is the position of particle $i$, $\\boldsymbol{a}_i(\\boldsymbol{r})$ is the acceleration due to all other particles, $G$ is the gravitational constant, and $\\epsilon$ is a Plummer softening length to regularize close encounters.\n\nYour program must:\n- Implement a direct summation routine to compute accelerations $\\boldsymbol{a}_i(\\boldsymbol{r})$ for all particles using the formula above with $G=1$.\n- Implement two time integration schemes:\n  - The velocity Verlet (VV) integrator, which is a time-symmetric second-order method. Define the scheme using a half-kick, full drift, and half-kick sequence at each step of size $\\Delta t$.\n  - The classical fourth-order Runge–Kutta (RK4) method. Define the ordinary differential equation system for state $(\\boldsymbol{r},\\boldsymbol{v})$ by $d\\boldsymbol{r}/dt=\\boldsymbol{v}$ and $d\\boldsymbol{v}/dt=\\boldsymbol{a}(\\boldsymbol{r})$, then apply the RK4 update for step size $\\Delta t$.\n\n- Perform the forward–backward experiment: given an initial state $(\\boldsymbol{r}(0),\\boldsymbol{v}(0))$, integrate forward for total time $T$ using $n=\\lfloor T/\\Delta t \\rfloor$ steps with step size $\\Delta t$, then integrate backward for the same number of steps with step size $-\\Delta t$, using the same integrator and the same sequence of operations. Let the final state after backward integration be $(\\boldsymbol{r}_{\\mathrm{fb}},\\boldsymbol{v}_{\\mathrm{fb}})$.\n- Quantify the reversibility error by the Euclidean norm of the difference in the full state vector:\n$$\nE = \\left\\lVert \\mathrm{vec}(\\boldsymbol{r}_{\\mathrm{fb}},\\boldsymbol{v}_{\\mathrm{fb}}) - \\mathrm{vec}(\\boldsymbol{r}(0),\\boldsymbol{v}(0)) \\right\\rVert_2,\n$$\nwhere $\\mathrm{vec}(\\boldsymbol{r},\\boldsymbol{v})$ denotes the vector formed by concatenating all position and velocity components for all particles into a single vector in $\\mathbb{R}^{6N}$.\n\n- Attribute contributions of truncation and roundoff by performing controlled numerical experiments:\n  - To emphasize roundoff, repeat the experiment while quantizing all state variables and intermediate updates to single precision after each update (i.e., using $32$-bit floating point) and compare to double precision (i.e., $64$-bit floating point).\n  - To emphasize truncation, vary the step size $\\Delta t$ while keeping double precision and compare reversibility errors for two different $\\Delta t$ values using the non-time-reversible RK4 method.\n\nAll quantities are dimensionless. No physical units are used. Angles are not explicitly required. The final outputs must be floats.\n\nTest suite:\n- Use the following systems and parameters. In all cases, gravitational constant is $G=1$, and the total integration time is $T$ specified per test. The softening $\\epsilon$ is specified per test.\n\n- Define the initial three-body system for tests with $N=3$:\n  - Masses: $[1.0,1.0,1.0]$.\n  - Positions: $\\boldsymbol{r}(0) = \\left[(-1.0,0.0,0.0),(1.0,0.0,0.0),(0.0,0.0,0.5)\\right]$.\n  - Velocities: $\\boldsymbol{v}(0) = \\left[(0.0,0.5,0.0),(0.0,-0.5,0.0),(0.0,0.0,-0.5)\\right]$.\n\n- Define the initial two-body circular orbit for tests with $N=2$:\n  - Masses: $[1.0,1.0]$.\n  - Positions: $\\boldsymbol{r}(0) = \\left[(-0.5,0.0,0.0),(0.5,0.0,0.0)\\right]$.\n  - Velocities: choose circular velocities in the $y$-direction with magnitude $v=\\sqrt{0.5}$, i.e., $\\boldsymbol{v}(0) = \\left[(0.0,\\sqrt{0.5},0.0),(0.0,-\\sqrt{0.5},0.0)\\right]$.\n\n- Define the trivial $N=1$ system (boundary condition):\n  - Mass: $[1.0]$.\n  - Position: $\\boldsymbol{r}(0) = \\left[(0.0,0.0,0.0)\\right]$.\n  - Velocity: $\\boldsymbol{v}(0) = \\left[(1.0,0.0,0.0)\\right]$.\n\nExperiments to run and report:\n- Test $1$ (roundoff-dominated, reversible method): $N=3$, integrator VV, $\\Delta t=0.01$, $T=1.0$, $\\epsilon=10^{-3}$, double precision ($64$-bit), with quantization to $64$-bit after each update.\n- Test $2$ (enhanced roundoff): same as Test $1$ but single precision ($32$-bit) quantization after each update.\n- Test $3$ (non-reversible truncation present): $N=3$, integrator RK4, $\\Delta t=0.01$, $T=1.0$, $\\epsilon=10^{-3}$, double precision with quantization after each update.\n- Test $4$ (truncation scaling): same as Test $3$ but with $\\Delta t=0.005$.\n- Test $5$ (two-body with reversible method): $N=2$, integrator VV, $\\Delta t=0.05$, $T=1.0$, $\\epsilon=0.0$, double precision with quantization after each update.\n- Test $6$ (boundary case $N=1$, zero acceleration): $N=1$, integrator RK4, $\\Delta t=0.02$, $T=1.0$, $\\epsilon=0.0$, double precision with quantization after each update.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of floats enclosed in square brackets, ordered as $[E_1,E_2,E_3,E_4,E_5,E_6]$ where $E_k$ is the reversibility error for Test $k$. For example, the program must print exactly one line like $[e_1,e_2,e_3,e_4,e_5,e_6]$.",
            "solution": "The user-provided problem is valid and well-posed. It is grounded in the fundamental principles of classical mechanics and numerical analysis as applied to computational astrophysics. The problem asks for the design and implementation of a numerical experiment to study the reversibility properties and error characteristics of two standard integration schemes, Velocity Verlet (VV) and fourth-order Runge-Kutta (RK4), for the gravitational $N$-body problem. All provided parameters, initial conditions, and evaluation metrics are scientifically sound, complete, and unambiguous.\n\nThe solution proceeds by first establishing the mathematical and physical framework, then detailing the implementation of the required numerical algorithms, and finally explaining the design of the forward-backward experiment and the interpretation of its results.\n\n### 1. The Governing Equations of Motion\n\nThe system consists of $N$ point masses interacting via Newtonian gravity. The motion of each particle $i$ with mass $m_i$ and position $\\boldsymbol{r}_i \\in \\mathbb{R}^3$ is governed by Newton's second law, $\\boldsymbol{F}_i = m_i \\boldsymbol{a}_i$, where $\\boldsymbol{a}_i = d^2\\boldsymbol{r}_i/dt^2$ is the acceleration. The force $\\boldsymbol{F}_i$ on particle $i$ is the vector sum of gravitational forces from all other particles $j \\neq i$. Using Newton's law of universal gravitation, with the gravitational constant $G=1$ as specified, the acceleration of particle $i$ is:\n$$\n\\boldsymbol{a}_i(\\boldsymbol{r}) = \\sum_{j \\ne i} m_j \\frac{\\boldsymbol{r}_j - \\boldsymbol{r}_i}{\\lVert \\boldsymbol{r}_j - \\boldsymbol{r}_i \\rVert^3}\n$$\nTo prevent numerical divergence when two particles approach each other (i.e., $\\lVert \\boldsymbol{r}_j - \\boldsymbol{r}_i \\rVert \\to 0$), a Plummer softening length $\\epsilon$ is introduced. The modified, regularized acceleration is:\n$$\n\\boldsymbol{a}_i(\\boldsymbol{r}) = \\sum_{j \\ne i} m_j \\frac{\\boldsymbol{r}_j - \\boldsymbol{r}_i}{\\left(\\lVert \\boldsymbol{r}_j - \\boldsymbol{r}_i \\rVert^2 + \\epsilon^2 \\right)^{3/2}}\n$$\nThis set of $N$ coupled second-order ordinary differential equations (ODEs) can be transformed into a system of $2N$ first-order ODEs by defining a $6N$-dimensional state vector $Y(t) = (\\boldsymbol{r}_1, \\dots, \\boldsymbol{r}_N, \\boldsymbol{v}_1, \\dots, \\boldsymbol{v}_N)$, where $\\boldsymbol{v}_i = d\\boldsymbol{r}_i/dt$ is the velocity. The time evolution of the system is then given by:\n$$\n\\frac{dY}{dt} = f(Y) = \\left( \\boldsymbol{v}_1, \\dots, \\boldsymbol{v}_N, \\boldsymbol{a}_1(\\boldsymbol{r}), \\dots, \\boldsymbol{a}_N(\\boldsymbol{r}) \\right)\n$$\nThis first-order system is suitable for solution by standard numerical integrators.\n\n### 2. Direct Summation Algorithm for Accelerations\n\nA direct summation algorithm computes the acceleration on each particle by iterating through all other particles and summing their contributions. For a system of $N$ particles, this involves calculating $N(N-1)$ pairwise interactions, leading to a computational complexity of $O(N^2)$. For the small $N$ values in this problem, this approach is perfectly adequate. The implementation computes these pairwise forces in a vectorized manner for efficiency.\n\n### 3. Numerical Integration Schemes\n\nThe problem requires implementing two distinct integrators to evolve the system in time.\n\n**Velocity Verlet (VV) Integrator:**\nThe Velocity Verlet algorithm is a second-order, symplectic, and time-reversible integrator. Its time-reversibility makes it an excellent choice for long-term simulations of Hamiltonian systems like the $N$-body problem, as it conserves energy over long periods (with bounded oscillations). A single step from time $t$ to $t+\\Delta t$ is performed as a \"kick-drift-kick\" sequence:\n1.  **Half Kick:** Update velocities by a half step: $\\boldsymbol{v}(t + \\Delta t/2) = \\boldsymbol{v}(t) + \\frac{1}{2}\\Delta t \\cdot \\boldsymbol{a}(\\boldsymbol{r}(t))$.\n2.  **Full Drift:** Update positions using the new half-step velocities: $\\boldsymbol{r}(t + \\Delta t) = \\boldsymbol{r}(t) + \\Delta t \\cdot \\boldsymbol{v}(t + \\Delta t/2)$.\n3.  **Compute New Acceleration:** Calculate $\\boldsymbol{a}(\\boldsymbol{r}(t + \\Delta t))$ at the new positions.\n4.  **Half Kick:** Complete the velocity update: $\\boldsymbol{v}(t + \\Delta t) = \\boldsymbol{v}(t + \\Delta t/2) + \\frac{1}{2}\\Delta t \\cdot \\boldsymbol{a}(\\boldsymbol{r}(t + \\Delta t))$.\nCrucially, these operations are exactly invertible by negating $\\Delta t$. In the absence of roundoff error, integrating forward and then backward by the same amount would recover the initial state perfectly.\n\n**Fourth-Order Runge-Kutta (RK4) Integrator:**\nThe classical RK4 method is a widely used general-purpose integrator known for its high accuracy. It is a fourth-order method, meaning its global error scales as $O((\\Delta t)^4)$. For a system $dY/dt = f(Y)$, the update rule is:\n$$\nY_{n+1} = Y_n + \\frac{\\Delta t}{6}(k_1 + 2k_2 + 2k_3 + k_4)\n$$\nwhere the intermediate slopes are:\n-   $k_1 = f(Y_n)$\n-   $k_2 = f(Y_n + \\frac{\\Delta t}{2} k_1)$\n-   $k_3 = f(Y_n + \\frac{\\Delta t}{2} k_2)$\n-   $k_4 = f(Y_n + \\Delta t k_3)$\nIn our problem, $Y_n = (\\boldsymbol{r}_n, \\boldsymbol{v}_n)$, and $f(Y_n)$ involves computing accelerations. While highly accurate for a given $\\Delta t$, RK4 is neither symplectic nor time-reversible. This means that errors, particularly truncation errors, do not cancel out upon time reversal.\n\n### 4. The Forward-Backward Reversibility Experiment\n\nThis experiment is designed to quantify numerical errors by testing an integrator's ability to reverse a computed trajectory.\n1.  The system is integrated forward from an initial state $(\\boldsymbol{r}(0), \\boldsymbol{v}(0))$ for a time $T$.\n2.  From the final state $(\\boldsymbol{r}(T), \\boldsymbol{v}(T))$, the system is integrated backward for the same duration $T$ (using a step size of $-\\Delta t$).\n3.  The final state of this backward integration, $(\\boldsymbol{r}_{\\mathrm{fb}}, \\boldsymbol{v}_{\\mathrm{fb}})$, is compared to the original initial state.\nThe reversibility error, $E = \\left\\lVert \\mathrm{vec}(\\boldsymbol{r}_{\\mathrm{fb}},\\boldsymbol{v}_{\\mathrm{fb}}) - \\mathrm{vec}(\\boldsymbol{r}(0),\\boldsymbol{v}(0)) \\right\\rVert_2$, measures the total deviation. This error arises from two primary sources:\n-   **Truncation Error:** The intrinsic error from approximating a continuous differential equation with a discrete-step algorithm. For a time-reversible integrator like VV, truncation errors accumulate in a structured way that largely cancels upon reversal. For a non-reversible integrator like RK4, they do not cancel, leading to a significant reversibility error. This error scales with the step size $\\Delta t$.\n-   **Roundoff Error:** The error due to the finite-precision representation of numbers in a computer. These errors accumulate pseudo-randomly. By performing the experiment in both single ($32$-bit) and double ($64$-bit) precision, we can isolate the contribution of roundoff error. The effect of roundoff is simulated by quantizing the state vectors $(\\boldsymbol{r}, \\boldsymbol{v})$ to the target precision after each complete integration step.\n\n### 5. Analysis of Test Cases\nThe provided test cases are designed to systematically probe these error sources:\n-   **Test 1 & 2 (VV, $N=3$):** Comparing double vs. single precision for the time-reversible VV integrator isolates the impact of roundoff error. The error in Test 1 ($64$-bit) should be extremely small, while the error in Test 2 ($32$-bit) will be much larger, demonstrating the cost of reduced precision.\n-   **Test 3 (RK4, $N=3$):** Using the non-reversible RK4 method, the error will be dominated by non-canceling truncation error, which is expected to be substantially larger than the roundoff-dominated error of VV in Test 1, despite RK4 being a higher-order method.\n-   **Test 4 (RK4, $N=3$, smaller $\\Delta t$):** Halving $\\Delta t$ compared to Test 3 will test the scaling of RK4's non-canceling reversibility error. For a non-time-reversible method of order $p$, this error scales as $(\\Delta t)^{p+1}$. For RK4 ($p=4$), the error should scale as $(\\Delta t)^5$. Therefore, the error $E_4$ should be significantly smaller than $E_3$, ideally by a factor close to $(0.01/0.005)^5 = 32$.\n-   **Test 5 (VV, $N=2$):** This test applies the robust VV method to a stable two-body Keplerian orbit. With `double` precision and $\\epsilon=0$, the error should be very small, primarily due to roundoff in an ideal physical system.\n-   **Test 6 (RK4, $N=1$):** A particle with no forces acting on it travels in a straight line. The exact solution is trivial. Any computed error $E_6$ is due solely to the accumulation of floating-point roundoff errors from the position and velocity updates, providing a baseline for machine precision limitations in this computational context.",
            "answer": "```python\nimport numpy as np\n\ndef calculate_accelerations(pos, masses, eps, dtype):\n    \"\"\"\n    Calculates gravitational accelerations using a vectorized direct summation.\n    G is assumed to be 1.\n    \"\"\"\n    n_particles = pos.shape[0]\n    if n_particles <= 1:\n        return np.zeros_like(pos, dtype=dtype)\n\n    # Vectorized calculation of pairwise differences and distances\n    # pos_i shape: (n, 1, 3); pos_j shape: (1, n, 3)\n    # This allows broadcasting to get all pairs of vectors.\n    pos_i = pos[:, np.newaxis, :]\n    pos_j = pos[np.newaxis, :, :]\n    \n    #_r_ij is vector from i to j, has shape (n, n, 3)\n    r_ij = pos_j - pos_i \n    \n    # dist_sq has shape (n, n)\n    dist_sq = np.sum(r_ij**2, axis=-1)\n    \n    # Softened inverse cube distance\n    inv_r3 = (dist_sq + eps**2)**(-1.5)\n    \n    # Set diagonal elements to 0 to avoid self-interaction\n    np.fill_diagonal(inv_r3, 0.0)\n    \n    # masses_j shape: (1, n, 1) to broadcast correctly with r_ij\n    masses_j = masses[np.newaxis, :, np.newaxis]\n    \n    # Sum over j axis; inv_r3 needs an extra dimension for broadcasting\n    # accel shape: (n, 3)\n    accel = np.sum(masses_j * r_ij * inv_r3[..., np.newaxis], axis=1)\n    \n    return accel.astype(dtype)\n\ndef step_vv(pos, vel, masses, dt, eps, dtype):\n    \"\"\"A single step of the Velocity Verlet integrator.\"\"\"\n    a_t = calculate_accelerations(pos, masses, eps, dtype)\n    v_half = vel + 0.5 * dt * a_t\n    pos_new = pos + dt * v_half\n    a_t_plus_dt = calculate_accelerations(pos_new, masses, eps, dtype)\n    vel_new = v_half + 0.5 * dt * a_t_plus_dt\n    return pos_new, vel_new\n\ndef step_rk4(pos, vel, masses, dt, eps, dtype):\n    \"\"\"A single step of the classic 4th-order Runge-Kutta integrator.\"\"\"\n    # k1\n    k1_r = dt * vel\n    k1_v = dt * calculate_accelerations(pos, masses, eps, dtype)\n    \n    # k2\n    k2_r = dt * (vel + 0.5 * k1_v)\n    k2_v = dt * calculate_accelerations(pos + 0.5 * k1_r, masses, eps, dtype)\n    \n    # k3\n    k3_r = dt * (vel + 0.5 * k2_v)\n    k3_v = dt * calculate_accelerations(pos + 0.5 * k2_r, masses, eps, dtype)\n    \n    # k4\n    k4_r = dt * (vel + k3_v)\n    k4_v = dt * calculate_accelerations(pos + k3_r, masses, eps, dtype)\n    \n    # Update state\n    pos_new = pos + (k1_r + 2*k2_r + 2*k3_r + k4_r) / 6.0\n    vel_new = vel + (k1_v + 2*k2_v + 2*k3_v + k4_v) / 6.0\n    \n    return pos_new, vel_new\n\ndef run_experiment(initial_r, initial_v, masses, integrator_name, dt, T, eps, precision_str):\n    \"\"\"\n    Performs a forward-backward integration experiment and returns the reversibility error.\n    \"\"\"\n    dtype = np.float64 if precision_str == 'double' else np.float32\n\n    # Set initial state and precision\n    r0 = initial_r.copy().astype(dtype)\n    v0 = initial_v.copy().astype(dtype)\n    m = masses.copy().astype(dtype)\n    \n    r, v = r0.copy(), v0.copy()\n\n    stepper = step_vv if integrator_name == 'VV' else step_rk4\n    n_steps = int(round(T / abs(dt)))\n\n    # Forward integration\n    for _ in range(n_steps):\n        r_new, v_new = stepper(r, v, m, dt, eps, dtype)\n        r = r_new.astype(dtype)\n        v = v_new.astype(dtype)\n        \n    # Backward integration\n    for _ in range(n_steps):\n        r_new, v_new = stepper(r, v, m, -dt, eps, dtype)\n        r = r_new.astype(dtype)\n        v = v_new.astype(dtype)\n        \n    r_fb, v_fb = r, v\n    \n    # Calculate final error\n    initial_state_vec = np.concatenate((r0.flatten(), v0.flatten()))\n    final_state_vec = np.concatenate((r_fb.flatten(), v_fb.flatten()))\n    \n    error = np.linalg.norm(final_state_vec - initial_state_vec)\n    return float(error)\n\ndef solve():\n    # Initial conditions\n    ic_n3 = {\n        'masses': np.array([1.0, 1.0, 1.0]),\n        'pos': np.array([[-1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 0.5]]),\n        'vel': np.array([[0.0, 0.5, 0.0], [0.0, -0.5, 0.0], [0.0, 0.0, -0.5]])\n    }\n    \n    v_circ = np.sqrt(0.5)\n    ic_n2 = {\n        'masses': np.array([1.0, 1.0]),\n        'pos': np.array([[-0.5, 0.0, 0.0], [0.5, 0.0, 0.0]]),\n        'vel': np.array([[0.0, v_circ, 0.0], [0.0, -v_circ, 0.0]])\n    }\n    \n    ic_n1 = {\n        'masses': np.array([1.0]),\n        'pos': np.array([[0.0, 0.0, 0.0]]),\n        'vel': np.array([[1.0, 0.0, 0.0]])\n    }\n\n    test_cases = [\n        # Test 1: VV, double, N=3\n        {'ic': ic_n3, 'integrator': 'VV', 'dt': 0.01, 'T': 1.0, 'eps': 1e-3, 'precision': 'double'},\n        # Test 2: VV, single, N=3\n        {'ic': ic_n3, 'integrator': 'VV', 'dt': 0.01, 'T': 1.0, 'eps': 1e-3, 'precision': 'single'},\n        # Test 3: RK4, double, dt=0.01, N=3\n        {'ic': ic_n3, 'integrator': 'RK4', 'dt': 0.01, 'T': 1.0, 'eps': 1e-3, 'precision': 'double'},\n        # Test 4: RK4, double, dt=0.005, N=3\n        {'ic': ic_n3, 'integrator': 'RK4', 'dt': 0.005, 'T': 1.0, 'eps': 1e-3, 'precision': 'double'},\n        # Test 5: VV, double, N=2\n        {'ic': ic_n2, 'integrator': 'VV', 'dt': 0.05, 'T': 1.0, 'eps': 0.0, 'precision': 'double'},\n        # Test 6: RK4, double, N=1\n        {'ic': ic_n1, 'integrator': 'RK4', 'dt': 0.02, 'T': 1.0, 'eps': 0.0, 'precision': 'double'},\n    ]\n\n    results = []\n    for case in test_cases:\n        error = run_experiment(\n            initial_r=case['ic']['pos'],\n            initial_v=case['ic']['vel'],\n            masses=case['ic']['masses'],\n            integrator_name=case['integrator'],\n            dt=case['dt'],\n            T=case['T'],\n            eps=case['eps'],\n            precision_str=case['precision']\n        )\n        results.append(error)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "With correctness and accuracy established, the final frontier for a computational algorithm is performance. The $O(N^2)$ complexity of direct summation makes parallelization essential, yet ensuring that all processors remain busy is a non-trivial challenge, especially with heterogeneous workloads. This practice delves into the critical problem of dynamic load balancing , where you will implement and compare a simple static scheduling strategy against a more adaptive work-stealing algorithm to understand the trade-offs between scheduling overhead and computational efficiency.",
            "id": "3508377",
            "problem": "Consider a system of $N$ gravitating particles in a direct-summation $N$-body integrator. Let the position of particle $i$ be $\\mathbf{r}_i$, its mass be $m_i$, and the gravitational constant be $G$. The acceleration of particle $i$ due to all other particles under Newton's law of universal gravitation is\n$$\n\\mathbf{a}_i = G \\sum_{\\substack{j=1 \\\\ j \\neq i}}^{N} m_j \\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left\\lVert \\mathbf{r}_j - \\mathbf{r}_i \\right\\rVert^3}.\n$$\nIn a block time-step scheme, a subset of particles is active at any given global step. Denote the number of active particles by $M$, where $M \\le N$. For each active particle $i$, the direct summation requires evaluating a sum over $N$ sources, so the computational cost per active particle scales linearly with $N$. In heterogeneous astrophysical scenarios, per-particle cost varies due to, for example, adaptive softening, neighbor-dependent corrections, or special-function evaluations. Consequently, the set of $M$ tasks (one per active particle) has a distribution of task durations.\n\nYou are asked to design and evaluate a dynamic load balancing scheme based on work stealing for distributing the $M$ active-particle tasks across $P$ workers. You will implement and compare two scheduling strategies:\n\n- Static contiguous assignment: partition the $M$ tasks into $P$ contiguous blocks, with block sizes differing by at most one, and assign one block to each worker. There is no scheduling overhead in this scheme.\n- Dynamic work stealing with chunking: maintain a global pool of remaining tasks, grouped into fixed-size chunks of size $s$ tasks per chunk. At any moment, the worker with the earliest availability time acquires the next chunk from the pool and incurs a per-acquisition overhead cost $c_{\\mathrm{steal}}$ due to synchronization and communication. The worker's finish time is increased by the sum of task durations in the acquired chunk plus $c_{\\mathrm{steal}}$. This repeats until all tasks are acquired.\n\nThe per-task duration is modeled deterministically to capture both baseline direct-summation cost and heterogeneity. For task index $i \\in \\{1,2,\\dots,M\\}$, define\n$$\nu_i = \\mathrm{frac}\\left(\\frac{\\kappa i}{M}\\right), \\quad \\text{with } \\kappa \\text{ a fixed positive integer coprime to } M,\n$$\n$$\nh_i(z) = \n\\begin{cases}\n(1 - \\tilde{u}_i)^{-z} - 1, & z > 0, \\\\\n0, & z = 0,\n\\end{cases}\n\\quad \\text{where } \\tilde{u}_i = \\min\\{u_i, 1 - 10^{-4}\\},\n$$\nand the task duration\n$$\nt_i = \\alpha N + \\beta + \\gamma \\, h_i(z).\n$$\nHere, $\\alpha$ and $\\beta$ define the baseline linear-in-$N$ cost for one direct summation over $N$ sources; $\\gamma$ controls the amplitude of heterogeneity; $z$ controls tail heaviness; and $\\kappa$ determines the low-discrepancy sequence driving deterministic heterogeneity. All durations are dimensionless computational time units, and all metrics requested below are dimensionless.\n\nYour program must:\n- Implement the static contiguous assignment and compute the static makespan\n$$\nT_{\\mathrm{static}} = \\max_{p \\in \\{1,\\dots,P\\}} \\sum_{i \\in \\mathcal{B}_p} t_i,\n$$\nwhere $\\mathcal{B}_p$ is the contiguous block of tasks assigned to worker $p$.\n- Implement the dynamic work-stealing list scheduling with chunk size $s$ and per-chunk overhead $c_{\\mathrm{steal}}$, and compute the dynamic makespan $T_{\\mathrm{dyn}}$ and the total dynamic overhead $O_{\\mathrm{dyn}} = c_{\\mathrm{steal}} \\times C$, where $C$ is the total number of chunk acquisitions. Also compute the dynamic overhead fraction\n$$\nF_{\\mathrm{over}} = \\frac{O_{\\mathrm{dyn}}}{O_{\\mathrm{dyn}} + \\sum_{i=1}^{M} t_i}.\n$$\n- Report the effectiveness of dynamic load balancing by the speedup\n$$\nS = \\frac{T_{\\mathrm{static}}}{T_{\\mathrm{dyn}}}.\n$$\n\nTest suite. Use the following set of parameter values, which together probe balanced and imbalanced workloads, low and high overhead regimes, and small active subsets. For each case, set $\\kappa = 9973$.\n\n- Case $1$ (balanced baseline, moderate overhead):\n  - $N = 8192$, $M = 1024$, $P = 16$, $s = 8$, $c_{\\mathrm{steal}} = 0.5$, $\\alpha = 3 \\times 10^{-6}$, $\\beta = 1.0$, $\\gamma = 0.05$, $z = 0$.\n- Case $2$ (heavy-tailed heterogeneity, low chunk size):\n  - $N = 65536$, $M = 4096$, $P = 64$, $s = 4$, $c_{\\mathrm{steal}} = 1.0$, $\\alpha = 3 \\times 10^{-6}$, $\\beta = 1.0$, $\\gamma = 10.0$, $z = 3$.\n- Case $3$ (mild heterogeneity, high overhead, fine-grained chunks):\n  - $N = 32768$, $M = 2048$, $P = 32$, $s = 1$, $c_{\\mathrm{steal}} = 5.0$, $\\alpha = 3 \\times 10^{-6}$, $\\beta = 1.0$, $\\gamma = 0.2$, $z = 1$.\n- Case $4$ (small active subset, many workers):\n  - $N = 10000$, $M = 10$, $P = 64$, $s = 1$, $c_{\\mathrm{steal}} = 0.1$, $\\alpha = 3 \\times 10^{-6}$, $\\beta = 1.0$, $\\gamma = 0.5$, $z = 2$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, formatted as\n$$\n\\left[ S_1, F_{\\mathrm{over},1}, S_2, F_{\\mathrm{over},2}, S_3, F_{\\mathrm{over},3}, S_4, F_{\\mathrm{over},4} \\right],\n$$\nwhere $S_k$ and $F_{\\mathrm{over},k}$ are the speedup and overhead fraction for case $k \\in \\{1,2,3,4\\}$. All outputs must be decimal numbers (no percentage signs).",
            "solution": "The problem requires the design and evaluation of two distinct load balancing schemes for parallel computation, contextualized within an $N$-body simulation in computational astrophysics. The two schemes are a static contiguous block assignment and a dynamic work-stealing algorithm with chunking. The problem is scientifically grounded in established principles of parallel computing and performance modeling, is mathematically well-posed, and all parameters and objectives are defined with precision. The problem statement is therefore deemed valid and a full solution is presented below.\n\nOur first step is to compute the duration for each of the $M$ computational tasks. The problem defines a deterministic model for task durations, which captures a baseline cost proportional to $N$ plus a heterogeneous component. The duration $t_i$ for task $i \\in \\{1, 2, \\dots, M\\}$ is given by the formula:\n$$\nt_i = \\alpha N + \\beta + \\gamma h_i(z)\n$$\nHere, $\\alpha$, $\\beta$, $\\gamma$, $z$, and $N$ are provided parameters for each test case. The heterogeneity is introduced by the term $h_i(z)$, which itself depends on a low-discrepancy sequence $u_i$. The procedure for calculating the vector of $M$ task durations is as follows:\n\n1.  A low-discrepancy sequence is generated using the formula $u_i = \\mathrm{frac}(\\frac{\\kappa i}{M}) = \\frac{\\kappa i}{M} - \\lfloor \\frac{\\kappa i}{M} \\rfloor$. This is computed for each task index $i$ from $1$ to $M$. The constant $\\kappa$ is given as $9973$, a prime number that is coprime to all specified values of $M$, ensuring the sequence covers the interval $[0,1)$ with good distribution properties.\n\n2.  To prevent numerical overflow when $u_i$ is close to $1$, a capped value, $\\tilde{u}_i$, is used: $\\tilde{u}_i = \\min\\{u_i, 1 - 10^{-4}\\}$.\n\n3.  The heterogeneity function $h_i(z)$ is then evaluated. If the tail-heaviness parameter $z$ is $0$, then $h_i(0) = 0$. For $z > 0$, the function is $h_i(z) = (1 - \\tilde{u}_i)^{-z} - 1$.\n\n4.  These components are combined to find the total duration $t_i$ for each task. This results in a complete list of task durations $\\{t_1, t_2, \\dots, t_M\\}$, which serves as the input for the scheduling algorithms. Note that while the problem defines task indices from $1$ to $M$, standard programming array indices often start from $0$. This offset must be correctly handled.\n\nWith the task durations established, we proceed to simulate the two scheduling strategies.\n\n**1. Static Contiguous Assignment**\n\nIn this strategy, the ordered list of $M$ tasks is partitioned into $P$ contiguous blocks, and one block is assigned to each of the $P$ workers. The makespan, $T_{\\mathrm{static}}$, is the maximum execution time over all workers. To distribute the tasks as evenly as possible, the block sizes will differ by at most one.\n\nLet $m_0 = \\lfloor M/P \\rfloor$ and $r = M \\pmod P$.\n- The first $r$ workers (indexed $p=0, \\dots, r-1$) are each assigned a block of $m_0+1$ tasks.\n- The remaining $P-r$ workers (indexed $p=r, \\dots, P-1$) are each assigned a block of $m_0$ tasks.\n\nThe total workload for worker $p$, denoted $W_p$, is the sum of the durations of the tasks in its assigned block, $\\mathcal{B}_p$:\n$$\nW_p = \\sum_{i \\in \\mathcal{B}_p} t_i\n$$\nThe problem states that there is no scheduling overhead in this scheme. Therefore, the static makespan is simply the maximum workload among all workers.\n$$\nT_{\\mathrm{static}} = \\max_{p \\in \\{0, 1, \\dots, P-1\\}} W_p\n$$\n\n**2. Dynamic Work Stealing with Chunking**\n\nThis scheme uses a global pool of tasks, grouped into fixed-size chunks of $s$ tasks each. Idle workers fetch the next available chunk from this pool. This is a form of list scheduling. A per-acquisition overhead cost, $c_{\\mathrm{steal}}$, is incurred each time a worker gets a new chunk.\n\nThe simulation of this process requires tracking the finish time of each of the $P$ workers. Let's denote these by an array $T_{\\mathrm{finish}}$, initialized to all zeros. The total number of chunks is $C = \\lceil M/s \\rceil$.\n\nThe algorithm proceeds as follows:\n1.  Initialize worker finish times: $T_{\\mathrm{finish}, p} = 0$ for all $p \\in \\{0, 1, \\dots, P-1\\}$.\n2.  Iterate through all $C$ chunks. In each iteration:\n    a. Find the worker $p^*$ with the earliest availability (i.e., minimum finish time): $p^* = \\arg\\min_{p} T_{\\mathrm{finish}, p}$.\n    b. This worker acquires the next unassigned chunk. Calculate the sum of task durations within this chunk, $W_{\\mathrm{chunk}}$.\n    c. Update the worker's finish time. The new finish time is its previous finish time plus the overhead and the work for the new chunk: $T_{\\mathrm{finish}, p^*} \\leftarrow T_{\\mathrm{finish}, p^*} + c_{\\mathrm{steal}} + W_{\\mathrm{chunk}}$.\n3.  After all $C$ chunks have been assigned, the dynamic makespan, $T_{\\mathrm{dyn}}$, is the maximum finish time across all workers:\n$$\nT_{\\mathrm{dyn}} = \\max_{p \\in \\{0, 1, \\dots, P-1\\}} T_{\\mathrm{finish}, p}\n$$\nThe total dynamic overhead, $O_{\\mathrm{dyn}}$, is the overhead per chunk acquisition multiplied by the total number of acquisitions:\n$$\nO_{\\mathrm{dyn}} = c_{\\mathrm{steal}} \\times C = c_{\\mathrm{steal}} \\times \\lceil M/s \\rceil\n$$\nThe total computational work is the sum of all individual task durations, $W_{\\mathrm{total}} = \\sum_{i=1}^{M} t_i$. The dynamic overhead fraction, $F_{\\mathrm{over}}$, is the ratio of total overhead to the sum of total overhead and total work.\n$$\nF_{\\mathrm{over}} = \\frac{O_{\\mathrm{dyn}}}{O_{\\mathrm{dyn}} + W_{\\mathrm{total}}}\n$$\n\n**3. Final Metrics**\n\nFor each of the four test cases, we calculate the specified metrics based on the results from the two scheduling simulations:\n- The speedup, $S = T_{\\mathrm{static}} / T_{\\mathrm{dyn}}$, measures the relative performance improvement of the dynamic scheme over the static one. A value $S>1$ indicates that dynamic scheduling is more efficient.\n- The overhead fraction, $F_{\\mathrm{over}}$, quantifies the portion of the total computational effort that is expended on the overhead of dynamic scheduling.\n\nThese calculations are performed for each test case, and the resulting pairs $(S_k, F_{\\mathrm{over}, k})$ for $k \\in \\{1, 2, 3, 4\\}$ are formatted into the required output. The special case where $M < P$ (Case $4$) is handled naturally by both algorithms: in the static scheme, $M$ workers get one task each and $P-M$ workers get none; in the dynamic scheme, $M$ workers each acquire one chunk of size $s=1$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\n# from scipy import ...\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, M, P, s, c_steal, alpha, beta, gamma, z)\n        (8192, 1024, 16, 8, 0.5, 3e-6, 1.0, 0.05, 0),\n        (65536, 4096, 64, 4, 1.0, 3e-6, 1.0, 10.0, 3),\n        (32768, 2048, 32, 1, 5.0, 3e-6, 1.0, 0.2, 1),\n        (10000, 10, 64, 1, 0.1, 3e-6, 1.0, 0.5, 2),\n    ]\n\n    kappa = 9973\n    all_results = []\n\n    for case in test_cases:\n        N, M, P, s, c_steal, alpha, beta, gamma, z = case\n\n        # 1. Calculate task durations t_i\n        # Using 1-based indexing for i as in the problem formula\n        i_s = np.arange(1, M + 1)\n        \n        # u_i = frac(kappa * i / M)\n        u_i = (kappa * i_s / M) % 1.0\n        \n        # u_tilde_i = min(u_i, 1 - 1e-4)\n        u_tilde_i = np.minimum(u_i, 1.0 - 1e-4)\n        \n        # h_i(z)\n        if z == 0:\n            h_i = np.zeros(M)\n        else:\n            h_i = (1.0 - u_tilde_i)**(-z) - 1.0\n            \n        # t_i\n        task_durations = alpha * N + beta + gamma * h_i\n\n        # 2. Static Contiguous Assignment\n        base_tasks_per_worker = M // P\n        remainder_tasks = M % P\n        worker_loads_static = np.zeros(P)\n        current_task_idx = 0\n        for p in range(P):\n            num_tasks_for_worker = base_tasks_per_worker + 1 if p < remainder_tasks else base_tasks_per_worker\n            if num_tasks_for_worker > 0:\n                end_idx = current_task_idx + num_tasks_for_worker\n                worker_loads_static[p] = np.sum(task_durations[current_task_idx:end_idx])\n                current_task_idx = end_idx\n        \n        T_static = np.max(worker_loads_static)\n\n        # 3. Dynamic Work Stealing with Chunking\n        num_chunks = math.ceil(M / s)\n        worker_finish_times = np.zeros(P)\n        task_idx_ptr = 0\n        \n        # The core of a list scheduling simulation\n        for _ in range(num_chunks):\n            # Find the worker with the earliest finish time\n            p_min_idx = np.argmin(worker_finish_times)\n            earliest_finish_time = worker_finish_times[p_min_idx]\n            \n            # Define the current chunk of work\n            start_idx = task_idx_ptr\n            end_idx = min(start_idx + s, M)\n            chunk_duration = np.sum(task_durations[start_idx:end_idx])\n            \n            # Update the worker's finish time. It becomes ready at its previous finish\n            # time, then acquires the chunk (incurring overhead) and works on it.\n            worker_finish_times[p_min_idx] = earliest_finish_time + c_steal + chunk_duration\n            \n            # Advance to the start of the next chunk\n            task_idx_ptr += s\n            \n        T_dyn = np.max(worker_finish_times)\n        \n        # 4. Final Metrics\n        O_dyn = c_steal * num_chunks\n        W_total = np.sum(task_durations)\n        \n        # Handle potential division by zero if W_total and O_dyn are both zero\n        if O_dyn + W_total > 0:\n            F_over = O_dyn / (O_dyn + W_total)\n        else:\n            F_over = 0.0\n\n        # Handle potential division by zero if T_dyn is zero\n        S = T_static / T_dyn if T_dyn > 0 else 0.0\n\n        all_results.extend([S, F_over])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{x:.6f}' for x in all_results)}]\")\n\nsolve()\n```"
        }
    ]
}