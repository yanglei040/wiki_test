{
    "hands_on_practices": [
        {
            "introduction": "To truly understand a numerical scheme, one must master its fundamental operations. This first exercise drills down into the core mechanism of the Cloud-in-Cell (CIC) scheme: linear interpolation. By focusing on a particle near the edge of a periodic domain, this problem forces a careful application of the rules and highlights how to correctly handle wrap-around boundary conditions, a common feature in cosmological simulations and a frequent source of subtle implementation errors. ",
            "id": "3516929",
            "problem": "Consider a periodic, one-dimensional domain of length $L$ discretized by $N$ uniformly spaced mesh nodes at positions $x_i = i\\,\\Delta$ for $i \\in \\{0,1,\\dots,N-1\\}$, with grid spacing $\\Delta \\equiv L/N$. In a Particle–Mesh method using the Cloud-In-Cell (CIC) mass assignment, a particle of mass $m_p$ at position $x_p$ contributes to the mesh density by convolving the particle’s Dirac delta with the one-dimensional, compactly supported, piecewise-linear CIC kernel of support $\\Delta$ and unit normalization. The domain is strictly periodic, so distances are measured using the minimal separation on the circle of circumference $L$.\n\nA particle is located at $x_p = L - \\epsilon$ with $0 < \\epsilon < \\Delta$. Using only the definitions above and first principles of periodic distance on a circle, derive the normalized CIC weights $w_i$ assigned to mesh nodes $i=N-1$ and $i=0$, and show explicitly that these are the only nonzero contributions for this particle. Also demonstrate that the total assigned weight is conserved.\n\nProvide your final answer as the row matrix $\\begin{pmatrix} w_{N-1} & w_{0} \\end{pmatrix}$ in closed form as a function of $\\epsilon$ and $\\Delta$. No numerical evaluation is required, and no units are needed. The final answer must be a single analytic expression.",
            "solution": "The Cloud-In-Cell (CIC) mass assignment scheme in one dimension is a linear interpolation method. For a particle at position $x_p$ located in the grid cell between nodes $x_i$ and $x_{i+1}$, its mass is distributed to these two nodes. The weights are linearly proportional to the particle's proximity to the opposing node.\n\nThe grid nodes are at positions $x_i = i\\Delta$ for $i \\in \\{0, 1, \\dots, N-1\\}$. The grid spacing is $\\Delta = L/N$. The domain is periodic, so the node at $x=L$ is identical to the node at $x=0$.\nThe particle is located at $x_p = L - \\epsilon$, where $0 < \\epsilon < \\Delta$.\n\nWe must first identify which grid cell contains the particle. The grid nodes are located at integral multiples of $\\Delta$. The node $i=N-1$ is at $x_{N-1} = (N-1)\\Delta = N\\Delta - \\Delta = L - \\Delta$. The next node in the sequence would be $i=N$, at position $x_N = N\\Delta = L$. Due to periodicity, this position is equivalent to the node $i=0$ at $x_0 = 0$.\n\nThe particle's position is $x_p = L - \\epsilon$. Given that $0 < \\epsilon < \\Delta$, it follows that $L - \\Delta < L - \\epsilon < L$.\nThis means $x_{N-1} < x_p < x_N$, where $x_N$ is the periodic equivalent of $x_0$. Thus, the particle is located in the grid cell adjoining nodes $i=N-1$ and $i=0$. These are the only two nodes that will receive a non-zero weight under the CIC scheme.\n\nLet's denote the cell's \"left\" node as $x_{N-1}$ and its \"right\" node as $x_0 \\equiv L$. The width of this cell is $\\Delta$. The position of the particle within this cell, measured from the left node $x_{N-1}$, is:\n$$d = x_p - x_{N-1} = (L - \\epsilon) - (L - \\Delta) = \\Delta - \\epsilon$$\nThe fractional distance of the particle from the left node is $\\delta_{frac} = d / \\Delta$.\n$$\\delta_{frac} = \\frac{\\Delta - \\epsilon}{\\Delta} = 1 - \\frac{\\epsilon}{\\Delta}$$\nAccording to the CIC algorithm, the weight assigned to the right node ($i=0$) is equal to this fractional distance, and the weight on the left node ($i=N-1$) is $1$ minus the fractional distance.\n\nWeight on node $i=0$:\n$$w_0 = \\delta_{frac} = \\frac{\\Delta - \\epsilon}{\\Delta}$$\n\nWeight on node $i=N-1$:\n$$w_{N-1} = 1 - \\delta_{frac} = 1 - \\left(\\frac{\\Delta - \\epsilon}{\\Delta}\\right) = \\frac{\\Delta - (\\Delta - \\epsilon)}{\\Delta} = \\frac{\\epsilon}{\\Delta}$$\n\nTo show that these are the only non-zero contributions, we consider adjacent nodes. The CIC kernel, $W(x_p - x_i)$, is non-zero only for $|x_p - x_i| < \\Delta$ (using the periodic distance).\nConsider node $i=N-2$: $x_{N-2} = (N-2)\\Delta = L - 2\\Delta$. The periodic distance is:\n$$d(x_p, x_{N-2}) = |(L-\\epsilon) - (L-2\\Delta)| = |2\\Delta - \\epsilon|$$\nSince $0 < \\epsilon < \\Delta$, we have $\\Delta < 2\\Delta - \\epsilon < 2\\Delta$. This distance is greater than $\\Delta$, so $w_{N-2} = 0$.\n\nConsider node $i=1$: $x_1 = \\Delta$. The periodic distance must account for the wrap-around nature of the domain. The direct distance is $|x_p - x_1| = |(L-\\epsilon) - \\Delta| = L - \\Delta - \\epsilon$. The distance across the periodic boundary is $\\epsilon + \\Delta$. The minimal separation is:\n$$d(x_p, x_1) = \\min(L - \\Delta - \\epsilon, \\Delta + \\epsilon) = \\Delta + \\epsilon$$\nSince $\\epsilon > 0$, this distance is greater than $\\Delta$, so $w_1 = 0$.\nAll other nodes are even farther away, so their weights are also zero.\n\nFinally, we demonstrate that the total weight is conserved (i.e., the sum of weights is $1$).\n$$\\sum_i w_i = w_{N-1} + w_0 = \\frac{\\epsilon}{\\Delta} + \\frac{\\Delta-\\epsilon}{\\Delta} = \\frac{\\epsilon + \\Delta - \\epsilon}{\\Delta} = \\frac{\\Delta}{\\Delta} = 1$$\nThe total assigned weight is conserved, thus validating the derived expressions as normalized weights.\n\nThe final result is the set of weights for nodes $i=N-1$ and $i=0$.\n$w_{N-1} = \\frac{\\epsilon}{\\Delta}$\n$w_0 = \\frac{\\Delta - \\epsilon}{\\Delta}$",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\epsilon}{\\Delta} & \\frac{\\Delta - \\epsilon}{\\Delta} \\end{pmatrix}}$$"
        },
        {
            "introduction": "Mass assignment schemes do more than just deposit mass onto a grid; they implicitly convolve the density field with a smoothing kernel. This exercise makes that connection explicit by introducing the concept of the continuous window function $W(x)$ that is equivalent to the discrete CIC assignment rule. By calculating the second moment of this window function, we can quantify the scheme's characteristic smoothing scale, providing a powerful tool for comparing the properties of different methods like Nearest-Grid-Point (NGP), CIC, and Triangular-Shaped-Cloud (TSC). ",
            "id": "3516951",
            "problem": "Consider a one-dimensional, uniform Cartesian mesh with grid spacing $\\Delta$ (assume $\\Delta$ is measured in meters). In particle-mesh density assignment, a particle of unit mass at the origin is mapped to the grid by convolving the point mass with a compact, normalized window function $W(x)$, yielding an effective smoothing of the density field. The window function $W(x)$ is assumed to be even and normalized so that $\\int_{-\\infty}^{\\infty} W(x)\\,dx = 1$. The effective smoothing scale of a mass assignment scheme can be characterized by the second moment\n$$\nm_{2} \\equiv \\int_{-\\infty}^{\\infty} x^{2} W(x)\\,dx,\n$$\nwhich has dimensions of length squared.\n\nMass assignment schemes commonly used in computational astrophysics include Nearest Grid Point (NGP), Cloud-In-Cell (CIC), and Triangular Shaped Cloud (TSC). Starting from the fundamental ideas of interpolation on a grid and conservation of mass:\n- For Nearest Grid Point (NGP), the unit mass is assigned wholly to the single nearest grid point, which corresponds to a uniform top-hat window over a single cell.\n- For Cloud-In-Cell (CIC), the unit mass is split linearly between the two nearest grid points in proportion to the distances, corresponding to a piecewise linear window with compact support over two cells.\n- For Triangular Shaped Cloud (TSC), the unit mass is distributed with a continuous, piecewise quadratic profile over three neighboring cells, corresponding to a compact window of greater support and smoothness.\n\nUsing these physical characterizations, compare the ordering of the effective smoothing scales among NGP, CIC, and TSC by reasoning about how support and continuity affect the magnitude of $m_{2}$. Then, explicitly derive the one-dimensional Cloud-In-Cell (CIC) window $W_{\\mathrm{CIC}}(x)$ from the requirement of linear distance weights and mass conservation, and compute the CIC second moment\n$$\nm_{2,\\mathrm{CIC}} = \\int_{-\\infty}^{\\infty} x^{2} W_{\\mathrm{CIC}}(x)\\,dx\n$$\nin closed form.\n\nExpress your final answer as a single analytic expression in terms of $\\Delta$ only. Do not include units in the final boxed expression. No numerical rounding is required.",
            "solution": "The problem asks for two main results: first, a qualitative comparison of the effective smoothing scales for the Nearest Grid Point (NGP), Cloud-In-Cell (CIC), and Triangular Shaped Cloud (TSC) schemes; and second, an explicit derivation of the one-dimensional CIC window function and the calculation of its second moment.\n\nThe effective smoothing scale is quantified by the second moment of the window function $W(x)$, defined as\n$$\nm_{2} \\equiv \\int_{-\\infty}^{\\infty} x^{2} W(x)\\,dx\n$$\nSince the window function $W(x)$ represents the effective mass distribution of a particle and is non-negative ($W(x) \\ge 0$), the quantity $m_2$ can be interpreted as the variance of this distribution (for a distribution centered at the origin). The term $x^2$ in the integrand gives greater weight to the parts of the function that are farther from the origin. Consequently, a window function that is more spread out, i.e., has a larger effective width or support, will have a larger second moment $m_2$.\n\nLet's analyze the window functions for the three schemes based on their physical descriptions and their support on a grid with spacing $\\Delta$:\n1.  **Nearest Grid Point (NGP):** This scheme assigns a particle's entire mass to the single nearest grid point. This is equivalent to using a top-hat or boxcar window function, $W_{\\mathrm{NGP}}(x)$, which is uniform over one grid cell. To be centered at the origin, its support must be $[-\\Delta/2, \\Delta/2]$, giving a total width of $\\Delta$.\n2.  **Cloud-In-Cell (CIC):** This scheme splits a particle's mass linearly between the two nearest grid points. This corresponds to a triangular window function, $W_{\\mathrm{CIC}}(x)$, which is piecewise linear and has a support extending across two grid cells. Centered at the origin, its support is $[-\\Delta, \\Delta]$, for a total width of $2\\Delta$.\n3.  **Triangular Shaped Cloud (TSC):** This scheme uses a piecewise quadratic profile to distribute mass over three cells. The corresponding window function, $W_{\\mathrm{TSC}}(x)$, is smoother than the CIC window and has a wider support. Centered at the origin, its support is $[-3\\Delta/2, 3\\Delta/2]$, for a total width of $3\\Delta$.\n\nThe support of the window functions increases from NGP to CIC to TSC: $\\text{width}(W_{\\mathrm{NGP}}) < \\text{width}(W_{\\mathrm{CIC}}) < \\text{width}(W_{\\mathrm{TSC}})$. A wider support means that the mass is distributed over a larger range of distances from the center. Since $m_2$ measures the mean-square displacement from the origin, a wider distribution will inherently lead to a larger value for $m_2$. Therefore, we can qualitatively order the smoothing scales as:\n$$\nm_{2,\\mathrm{NGP}} < m_{2,\\mathrm{CIC}} < m_{2,\\mathrm{TSC}}\n$$\n\nNext, we will explicitly derive the CIC window function, $W_{\\mathrm{CIC}}(x)$, and compute its second moment, $m_{2,\\mathrm{CIC}}$.\n\nThe CIC scheme's defining characteristic is its linear interpolation of mass between the two nearest grid points. Let's formalize this to derive the shape of the window function. In particle-mesh methods, the window function $W(x)$ is often proportional to the assignment function $S(x-x_j)$, which gives the fraction of a particle's mass at position $x$ that is assigned to the grid point at $x_j$.\n\nConsider a particle at a position $x_p$ between two grid points, one at $x=0$ and the other at $x=\\Delta$. So, $0 \\le x_p \\le \\Delta$. The mass is split linearly according to the distance from the grid points.\nThe fraction of mass assigned to the grid point at $x=\\Delta$ is proportional to the particle's distance from the grid point at $x=0$, which is $x_p$. So, the fraction is $x_p / \\Delta$.\nThe fraction of mass assigned to the grid point at $x=0$ is proportional to the particle's distance from the grid point at $x=\\Delta$, which is $\\Delta - x_p$. So, the fraction is $(\\Delta - x_p)/\\Delta = 1 - x_p/\\Delta$.\nNote that the two fractions sum to $1$, conserving mass.\n\nThis linear weighting scheme can be described by an assignment function $S(u)$, where $u$ is the distance from a grid point in units of $\\Delta$. More generally, for a particle at $x_p$ and a grid point at $x_j$, the assigned mass fraction is $S(x_p - x_j)$.\nFrom our example, for the grid point at $x_j=0$, the assigned fraction is $1 - x_p/\\Delta$. We require $S(x_p) = 1 - x_p/\\Delta$ for $x_p \\in [0, \\Delta]$.\nFor the grid point at $x_j=\\Delta$, the assigned fraction is $x_p/\\Delta$. The argument is $x_p - \\Delta$. Let $u = x_p - \\Delta$, so $u \\in [-\\Delta, 0]$ and $x_p = u + \\Delta$. The fraction is $(u+\\Delta)/\\Delta = 1 + u/\\Delta$. We require $S(u) = 1 + u/\\Delta$ for $u \\in [-\\Delta, 0]$.\n\nCombining these and using absolute values for symmetry, the assignment function has the form of a triangle:\n$$\nS(x) =\n\\begin{cases}\n1 - \\frac{|x|}{\\Delta} & \\text{for } |x| \\le \\Delta \\\\\n0 & \\text{for } |x| > \\Delta\n\\end{cases}\n$$\nThe problem states that the window function $W(x)$ is normalized such that $\\int_{-\\infty}^{\\infty} W(x)\\,dx = 1$. The assignment function $S(x)$ is not necessarily normalized. Let us compute its integral:\n$$\n\\int_{-\\infty}^{\\infty} S(x)\\,dx = \\int_{-\\Delta}^{\\Delta} \\left(1 - \\frac{|x|}{\\Delta}\\right)dx\n$$\nSince the integrand is an even function, we can write:\n$$\n\\int_{-\\Delta}^{\\Delta} \\left(1 - \\frac{|x|}{\\Delta}\\right)dx = 2 \\int_{0}^{\\Delta} \\left(1 - \\frac{x}{\\Delta}\\right)dx = 2 \\left[x - \\frac{x^2}{2\\Delta}\\right]_{0}^{\\Delta} = 2 \\left(\\Delta - \\frac{\\Delta^2}{2\\Delta}\\right) = 2 \\left(\\Delta - \\frac{\\Delta}{2}\\right) = \\Delta\n$$\nTo get a normalized window function $W_{\\mathrm{CIC}}(x)$, we must divide $S(x)$ by its integral, which is $\\Delta$.\n$$\nW_{\\mathrm{CIC}}(x) = \\frac{1}{\\Delta} S(x) =\n\\begin{cases}\n\\frac{1}{\\Delta}\\left(1 - \\frac{|x|}{\\Delta}\\right) & \\text{for } |x| \\le \\Delta \\\\\n0 & \\text{for } |x| > \\Delta\n\\end{cases}\n$$\nThis function is piecewise linear, has support over two cells ($[-\\Delta, \\Delta]$), is even, and is normalized to $1$, matching all the given descriptions.\n\nNow we compute the second moment, $m_{2,\\mathrm{CIC}}$:\n$$\nm_{2,\\mathrm{CIC}} = \\int_{-\\infty}^{\\infty} x^{2} W_{\\mathrm{CIC}}(x)\\,dx = \\int_{-\\Delta}^{\\Delta} x^{2} \\left[\\frac{1}{\\Delta}\\left(1 - \\frac{|x|}{\\Delta}\\right)\\right] dx\n$$\nThe integrand is an even function of $x$, so we can simplify the integral:\n$$\nm_{2,\\mathrm{CIC}} = 2 \\int_{0}^{\\Delta} x^{2} \\left[\\frac{1}{\\Delta}\\left(1 - \\frac{x}{\\Delta}\\right)\\right] dx = \\frac{2}{\\Delta} \\int_{0}^{\\Delta} \\left(x^2 - \\frac{x^3}{\\Delta}\\right) dx\n$$\nWe perform the integration:\n$$\nm_{2,\\mathrm{CIC}} = \\frac{2}{\\Delta} \\left[ \\frac{x^3}{3} - \\frac{x^4}{4\\Delta} \\right]_{0}^{\\Delta}\n$$\nEvaluating at the limits of integration:\n$$\nm_{2,\\mathrm{CIC}} = \\frac{2}{\\Delta} \\left[ \\left(\\frac{\\Delta^3}{3} - \\frac{\\Delta^4}{4\\Delta}\\right) - (0 - 0) \\right] = \\frac{2}{\\Delta} \\left(\\frac{\\Delta^3}{3} - \\frac{\\Delta^3}{4}\\right)\n$$\nFinding a common denominator for the terms in the parenthesis:\n$$\nm_{2,\\mathrm{CIC}} = \\frac{2}{\\Delta} \\left(\\frac{4\\Delta^3 - 3\\Delta^3}{12}\\right) = \\frac{2}{\\Delta} \\left(\\frac{\\Delta^3}{12}\\right)\n$$\nSimplifying the expression yields the final result:\n$$\nm_{2,\\mathrm{CIC}} = \\frac{2\\Delta^3}{12\\Delta} = \\frac{\\Delta^2}{6}\n$$\nThe result has dimensions of length squared, as required for a second moment.",
            "answer": "$$\\boxed{\\frac{\\Delta^2}{6}}$$"
        },
        {
            "introduction": "Understanding the CIC window function is not merely an academic exercise; it is essential for obtaining accurate scientific results. Because the assignment scheme suppresses power on small scales, any measured power spectrum will be systematically biased. This advanced practice addresses the crucial \"inverse problem\" of deconvolving the window function's effect to recover the true underlying power spectrum. Furthermore, it introduces the concept of regularization to create a stable estimator that manages the fundamental trade-off between bias and variance, a central challenge in physical data analysis. ",
            "id": "3516941",
            "problem": "You are given a three-dimensional uniform Cartesian grid with spacing $\\Delta$ and Cloud-in-Cell (CIC) mass assignment. The goal is to derive the Fourier-space window function $W_{\\mathrm{CIC}}(\\mathbf{k})$, compute its squared magnitude $|W_{\\mathrm{CIC}}(\\mathbf{k})|^2$ relevant to the power spectrum, and implement a numerically stable deconvolution of a measured power spectrum that accounts for the bias versus variance trade-off introduced by regularization near wavevectors where the window function is small.\n\nStart from the following fundamental base:\n- The real-space one-dimensional top-hat box function $T(x)$ of width $\\Delta$ is defined by $T(x) = \\frac{1}{\\Delta}$ for $|x| \\le \\Delta/2$ and $T(x) = 0$ otherwise, so that $\\int_{-\\infty}^{\\infty} T(x) \\, dx = 1$.\n- The Cloud-in-Cell (CIC) assignment kernel in one dimension is the convolution of the top-hat function with itself, $w_{\\mathrm{CIC}}(x) = (T * T)(x)$, which is a triangular function supported on $[-\\Delta, \\Delta]$ and which integrates to $1$.\n- The Fourier transform of a function $f(\\mathbf{x})$ is defined by $F(\\mathbf{k}) = \\int_{\\mathbb{R}^3} f(\\mathbf{x}) \\, e^{-i \\mathbf{k} \\cdot \\mathbf{x}} \\, d^3 \\mathbf{x}$.\n- Convolution in real space corresponds to multiplication in Fourier space: if $h = f * g$, then $\\widehat{h}(\\mathbf{k}) = \\widehat{f}(\\mathbf{k}) \\, \\widehat{g}(\\mathbf{k})$.\n\nTasks:\n1. Derive the one-dimensional Fourier transform $\\widehat{w}_{\\mathrm{CIC}}(k)$ of the one-dimensional Cloud-in-Cell kernel $w_{\\mathrm{CIC}}(x)$ starting from the definition $w_{\\mathrm{CIC}}(x) = (T * T)(x)$ and using the Fourier transform definition above. Using separability on a Cartesian grid, derive the three-dimensional Fourier-space window function $W_{\\mathrm{CIC}}(\\mathbf{k})$ for $\\mathbf{k} = (k_x, k_y, k_z)$.\n2. For a measured power spectrum model $P_{\\mathrm{meas}}(\\mathbf{k}) = |W_{\\mathrm{CIC}}(\\mathbf{k})|^2 \\, P_{\\mathrm{true}}(k) + \\eta(\\mathbf{k})$, with $k = \\|\\mathbf{k}\\|$ and measurement noise $\\eta(\\mathbf{k})$ having zero mean and variance $\\sigma^2(\\mathbf{k})$, design two estimators of the true power spectrum:\n   - The naive deconvolution estimator $P_{\\mathrm{naive}}(\\mathbf{k}) = P_{\\mathrm{meas}}(\\mathbf{k}) / |W_{\\mathrm{CIC}}(\\mathbf{k})|^2$,\n   - A ridge-regularized estimator that minimizes a squared-error objective with a Tikhonov (ridge) penalty, yielding a scalar inverse for each $\\mathbf{k}$ in the form $P_{\\mathrm{ridge}}(\\mathbf{k}) = \\alpha(\\mathbf{k}) \\, P_{\\mathrm{meas}}(\\mathbf{k})$ where the scalar $\\alpha(\\mathbf{k})$ depends on $|W_{\\mathrm{CIC}}(\\mathbf{k})|^2$ and a regularization parameter $\\lambda > 0$.\n3. For each estimator, derive the bias $\\mathrm{bias}(\\mathbf{k}) = \\mathbb{E}[P_{\\mathrm{est}}(\\mathbf{k})] - P_{\\mathrm{true}}(k)$, the variance $\\mathrm{var}(\\mathbf{k}) = \\mathrm{Var}[P_{\\mathrm{est}}(\\mathbf{k})]$, and the mean squared error $\\mathrm{mse}(\\mathbf{k}) = \\mathrm{bias}(\\mathbf{k})^2 + \\mathrm{var}(\\mathbf{k})$. Express these in terms of $|W_{\\mathrm{CIC}}(\\mathbf{k})|^2$, $P_{\\mathrm{true}}(k)$, $\\sigma^2(\\mathbf{k})$, and $\\lambda$.\n4. Implement a program to compute $W_{\\mathrm{CIC}}(\\mathbf{k})$ and evaluate the bias, variance, and mean squared error of both the naive and ridge-regularized estimators for the test suite below.\n\nAssumptions and definitions for numerical evaluation:\n- Use grid spacing $\\Delta = 1$ in dimensionless code units.\n- Use wavenumbers $\\mathbf{k}$ expressed in radians per unit length. This is required for the Fourier transform definition used here.\n- Adopt a dimensionless true isotropic power spectrum $P_{\\mathrm{true}}(k) = A \\exp\\!\\big(- (k/k_c)^2 \\big)$ with $A = 10$ and $k_c = 1$ in code units.\n- Use a white noise model $\\sigma^2(\\mathbf{k}) = \\sigma_0^2$ specified per test case.\n\nTest suite:\n- Case 1 (boundary at zero wavenumber, low noise): $\\mathbf{k} = (0, 0, 0)$, $\\lambda = 10^{-6}$, $\\sigma_0^2 = 10^{-4}$.\n- Case 2 (happy path, moderate wavenumbers): $\\mathbf{k} = (\\pi/4, \\pi/4, \\pi/4)$, $\\lambda = 10^{-6}$, $\\sigma_0^2 = 10^{-3}$.\n- Case 3 (anisotropic high wavenumber with one component at Nyquist): $\\mathbf{k} = (\\pi, 0, 0)$, $\\lambda = 10^{-2}$, $\\sigma_0^2 = 10^{-2}$.\n- Case 4 (extreme high wavenumbers at Nyquist in all directions): $\\mathbf{k} = (\\pi, \\pi, \\pi)$, $\\lambda = 10^{-1}$, $\\sigma_0^2 = 10^{-2}$.\n- Case 5 (mixed high and low components): $\\mathbf{k} = (0.9\\pi, 0.9\\pi, 0.1\\pi)$, $\\lambda = 5 \\times 10^{-3}$, $\\sigma_0^2 = 5 \\times 10^{-3}$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- Each element corresponds to one test case and must be itself a list of six floats in the exact order: $[\\,|W_{\\mathrm{CIC}}(\\mathbf{k})|^2,\\; P_{\\mathrm{true}}(k),\\; \\mathrm{bias}_{\\mathrm{ridge}}(\\mathbf{k}),\\; \\mathrm{var}_{\\mathrm{ridge}}(\\mathbf{k}),\\; \\mathrm{mse}_{\\mathrm{ridge}}(\\mathbf{k}),\\; \\mathrm{mse}_{\\mathrm{naive}}(\\mathbf{k})\\,]$.\n- All quantities are dimensionless in the adopted code units.",
            "solution": "The solution proceeds in four stages as requested:\n1. Derivation of the three-dimensional Cloud-in-Cell (CIC) window function in Fourier space.\n2. Formulation of the naive and ridge-regularized estimators for the true power spectrum.\n3. Derivation of the bias, variance, and mean squared error (MSE) for both estimators.\n4. Numerical implementation and evaluation for the provided test cases.\n\n**1. Derivation of the CIC Window Function $W_{\\mathrm{CIC}}(\\mathbf{k})$**\n\nThe derivation starts from the one-dimensional top-hat function $T(x)$, which is a box function that projects a particle's mass onto a segment of length $\\Delta$.\n$T(x) = \\frac{1}{\\Delta}$ for $|x| \\le \\frac{\\Delta}{2}$ and $T(x) = 0$ otherwise. It is normalized such that $\\int_{-\\infty}^{\\infty} T(x) dx = 1$.\n\nIts Fourier transform, $\\widehat{T}(k)$, is calculated as:\n$$\n\\widehat{T}(k) = \\int_{-\\infty}^{\\infty} T(x) e^{-ikx} dx = \\frac{1}{\\Delta} \\int_{-\\Delta/2}^{\\Delta/2} e^{-ikx} dx\n$$\n$$\n\\widehat{T}(k) = \\frac{1}{\\Delta} \\left[ \\frac{e^{-ikx}}{-ik} \\right]_{-\\Delta/2}^{\\Delta/2} = \\frac{1}{-ik\\Delta} \\left( e^{-ik\\Delta/2} - e^{ik\\Delta/2} \\right)\n$$\nUsing Euler's identity $e^{i\\theta} - e^{-i\\theta} = 2i\\sin(\\theta)$, we get:\n$$\n\\widehat{T}(k) = \\frac{1}{-ik\\Delta} \\left( -2i\\sin\\left(\\frac{k\\Delta}{2}\\right) \\right) = \\frac{2\\sin(k\\Delta/2)}{k\\Delta} = \\frac{\\sin(k\\Delta/2)}{k\\Delta/2}\n$$\nThis is the unnormalized sinc function, which we denote as $\\mathrm{sinc}(x) = \\sin(x)/x$. Thus, $\\widehat{T}(k) = \\mathrm{sinc}(k\\Delta/2)$.\n\nThe one-dimensional CIC assignment kernel, $w_{\\mathrm{CIC}}(x)$, is the convolution of the top-hat function with itself: $w_{\\mathrm{CIC}}(x) = (T * T)(x)$. According to the convolution theorem, its Fourier transform, $\\widehat{w}_{\\mathrm{CIC}}(k)$, is the product of the individual Fourier transforms:\n$$\n\\widehat{w}_{\\mathrm{CIC}}(k) = \\widehat{T}(k) \\cdot \\widehat{T}(k) = \\left( \\mathrm{sinc}\\left(\\frac{k\\Delta}{2}\\right) \\right)^2\n$$\n\nThe three-dimensional CIC kernel is separable on a Cartesian grid, meaning it is the product of three one-dimensional kernels: $W_{\\mathrm{CIC}}^{real}(\\mathbf{x}) = w_{\\mathrm{CIC}}(x)w_{\\mathrm{CIC}}(y)w_{\\mathrm{CIC}}(z)$. Consequently, its three-dimensional Fourier transform, $W_{\\mathrm{CIC}}(\\mathbf{k})$, is the product of the one-dimensional Fourier transforms for each component wavevector $k_x, k_y, k_z$:\n$$\nW_{\\mathrm{CIC}}(\\mathbf{k}) = \\widehat{w}_{\\mathrm{CIC}}(k_x) \\widehat{w}_{\\mathrm{CIC}}(k_y) \\widehat{w}_{\\mathrm{CIC}}(k_z) = \\mathrm{sinc}^2\\left(\\frac{k_x\\Delta}{2}\\right) \\mathrm{sinc}^2\\left(\\frac{k_y\\Delta}{2}\\right) \\mathrm{sinc}^2\\left(\\frac{k_z\\Delta}{2}\\right) = \\prod_{i=x,y,z} \\mathrm{sinc}^2\\left(\\frac{k_i\\Delta}{2}\\right)\n$$\n\n**2. Formulation of Power Spectrum Estimators**\n\nThe gridding process acts as a linear filter on the underlying continuous density field. In Fourier space, the transform of the gridded field is the product of the transform of the continuous field and the window function. The power spectrum, proportional to the squared magnitude of the field's Fourier transform, is therefore modulated by $|W_{\\mathrm{CIC}}(\\mathbf{k})|^2$.\nThe model for the measured power spectrum is given as:\n$$\nP_{\\mathrm{meas}}(\\mathbf{k}) = |W_{\\mathrm{CIC}}(\\mathbf{k})|^2 P_{\\mathrm{true}}(k) + \\eta(\\mathbf{k})\n$$\nwhere $\\eta(\\mathbf{k})$ is a noise term with $\\mathbb{E}[\\eta(\\mathbf{k})] = 0$ and $\\mathrm{Var}[\\eta(\\mathbf{k})] = \\sigma^2(\\mathbf{k})$. Let us define the transfer function $G(\\mathbf{k}) = |W_{\\mathrm{CIC}}(\\mathbf{k})|^2$. Since $W_{\\mathrm{CIC}}(\\mathbf{k})$ is real, this is simply $(W_{\\mathrm{CIC}}(\\mathbf{k}))^2$.\n$$\nG(\\mathbf{k}) = \\left( \\prod_{i=x,y,z} \\mathrm{sinc}^2\\left(\\frac{k_i\\Delta}{2}\\right) \\right)^2 = \\prod_{i=x,y,z} \\mathrm{sinc}^4\\left(\\frac{k_i\\Delta}{2}\\right)\n$$\nThe model becomes $P_{\\mathrm{meas}}(\\mathbf{k}) = G(\\mathbf{k}) P_{\\mathrm{true}}(k) + \\eta(\\mathbf{k})$.\n\n**Naive Deconvolution Estimator:**\nThis estimator inverts the transfer function directly:\n$$\nP_{\\mathrm{naive}}(\\mathbf{k}) = \\frac{P_{\\mathrm{meas}}(\\mathbf{k})}{G(\\mathbf{k})}\n$$\n\n**Ridge-Regularized Estimator:**\nThis estimator is derived by minimizing a Tikhonov-regularized least-squares objective function. For each $\\mathbf{k}$, we seek an estimate $\\hat{P}_{\\mathrm{true}}$ that minimizes:\n$$\nJ(\\hat{P}_{\\mathrm{true}}) = (P_{\\mathrm{meas}}(\\mathbf{k}) - G(\\mathbf{k})\\hat{P}_{\\mathrm{true}})^2 + \\lambda \\hat{P}_{\\mathrm{true}}^2\n$$\nTaking the derivative with respect to $\\hat{P}_{\\mathrm{true}}$ and setting it to zero to find the minimum:\n$$\n\\frac{\\partial J}{\\partial \\hat{P}_{\\mathrm{true}}} = -2G(\\mathbf{k})(P_{\\mathrm{meas}}(\\mathbf{k}) - G(\\mathbf{k})\\hat{P}_{\\mathrm{true}}) + 2\\lambda \\hat{P}_{\\mathrm{true}} = 0\n$$\n$$\n-G(\\mathbf{k})P_{\\mathrm{meas}}(\\mathbf{k}) + G(\\mathbf{k})^2\\hat{P}_{\\mathrm{true}} + \\lambda \\hat{P}_{\\mathrm{true}} = 0\n$$\nSolving for $\\hat{P}_{\\mathrm{true}}$, which is our ridge estimator $P_{\\mathrm{ridge}}(\\mathbf{k})$:\n$$\nP_{\\mathrm{ridge}}(\\mathbf{k}) = \\frac{G(\\mathbf{k})}{G(\\mathbf{k})^2 + \\lambda} P_{\\mathrm{meas}}(\\mathbf{k})\n$$\n\n**3. Bias, Variance, and Mean Squared Error**\n\nWe now analyze the statistical properties of each estimator.\n\n**Naive Estimator ($P_{\\mathrm{naive}}$):**\n$$\nP_{\\mathrm{naive}} = \\frac{G P_{\\mathrm{true}} + \\eta}{G} = P_{\\mathrm{true}} + \\frac{\\eta}{G}\n$$\n- **Expectation and Bias:** The expected value is $\\mathbb{E}[P_{\\mathrm{naive}}] = \\mathbb{E}[P_{\\mathrm{true}} + \\eta/G] = P_{\\mathrm{true}} + \\mathbb{E}[\\eta]/G = P_{\\mathrm{true}}$. The bias is thus zero.\n  $$\n  \\mathrm{bias}_{\\mathrm{naive}}(\\mathbf{k}) = \\mathbb{E}[P_{\\mathrm{naive}}] - P_{\\mathrm{true}} = 0\n  $$\n- **Variance:** The variance is determined solely by the noise term.\n  $$\n  \\mathrm{var}_{\\mathrm{naive}}(\\mathbf{k}) = \\mathrm{Var}\\left[P_{\\mathrm{true}} + \\frac{\\eta}{G}\\right] = \\mathrm{Var}\\left[\\frac{\\eta}{G}\\right] = \\frac{1}{G(\\mathbf{k})^2} \\mathrm{Var}[\\eta] = \\frac{\\sigma^2(\\mathbf{k})}{G(\\mathbf{k})^2}\n  $$\n- **Mean Squared Error:** $\\mathrm{mse} = \\mathrm{bias}^2 + \\mathrm{var}$.\n  $$\n  \\mathrm{mse}_{\\mathrm{naive}}(\\mathbf{k}) = 0^2 + \\frac{\\sigma^2(\\mathbf{k})}{G(\\mathbf{k})^2} = \\frac{\\sigma^2(\\mathbf{k})}{G(\\mathbf{k})^2} = \\frac{\\sigma^2(\\mathbf{k})}{|W_{\\mathrm{CIC}}(\\mathbf{k})|^4}\n  $$\n\n**Ridge Estimator ($P_{\\mathrm{ridge}}$):**\n$$\nP_{\\mathrm{ridge}} = \\frac{G}{G^2 + \\lambda} (G P_{\\mathrm{true}} + \\eta)\n$$\n- **Expectation and Bias:**\n  $$\n  \\mathbb{E}[P_{\\mathrm{ridge}}] = \\mathbb{E}\\left[\\frac{G}{G^2 + \\lambda} (G P_{\\mathrm{true}} + \\eta)\\right] = \\frac{G^2}{G^2 + \\lambda} P_{\\mathrm{true}}\n  $$\n  The estimator is biased. The bias is:\n  $$\n  \\mathrm{bias}_{\\mathrm{ridge}}(\\mathbf{k}) = \\mathbb{E}[P_{\\mathrm{ridge}}] - P_{\\mathrm{true}} = \\left(\\frac{G(\\mathbf{k})^2}{G(\\mathbf{k})^2 + \\lambda} - 1\\right)P_{\\mathrm{true}}(k) = \\frac{-\\lambda}{G(\\mathbf{k})^2 + \\lambda} P_{\\mathrm{true}}(k)\n  $$\n- **Variance:**\n  $$\n  \\mathrm{var}_{\\mathrm{ridge}}(\\mathbf{k}) = \\mathrm{Var}\\left[\\frac{G}{G^2 + \\lambda} (G P_{\\mathrm{true}} + \\eta)\\right] = \\mathrm{Var}\\left[\\frac{G}{G^2 + \\lambda} \\eta\\right] = \\left(\\frac{G}{G^2 + \\lambda}\\right)^2 \\mathrm{Var}[\\eta] = \\frac{G(\\mathbf{k})^2 \\sigma^2(\\mathbf{k})}{(G(\\mathbf{k})^2 + \\lambda)^2}\n  $$\n- **Mean Squared Error:**\n  $$\n  \\mathrm{mse}_{\\mathrm{ridge}}(\\mathbf{k}) = \\mathrm{bias}_{\\mathrm{ridge}}(\\mathbf{k})^2 + \\mathrm{var}_{\\mathrm{ridge}}(\\mathbf{k})\n  $$\n  $$\n  \\mathrm{mse}_{\\mathrm{ridge}}(\\mathbf{k}) = \\left(\\frac{-\\lambda P_{\\mathrm{true}}(k)}{G(\\mathbf{k})^2 + \\lambda}\\right)^2 + \\frac{G(\\mathbf{k})^2 \\sigma^2(\\mathbf{k})}{(G(\\mathbf{k})^2 + \\lambda)^2} = \\frac{\\lambda^2 P_{\\mathrm{true}}(k)^2 + G(\\mathbf{k})^2 \\sigma^2(\\mathbf{k})}{(G(\\mathbf{k})^2 + \\lambda)^2}\n  $$\n\n**4. Numerical Implementation**\n\nThe derived formulas are implemented for the specified test cases. The grid spacing is $\\Delta = 1$. The true power spectrum is $P_{\\mathrm{true}}(k) = 10 \\exp(-k^2)$, with $k = \\|\\mathbf{k}\\|$. The noise variance is a constant $\\sigma^2(\\mathbf{k}) = \\sigma_0^2$.\n\nThe quantities to be computed for each test case are:\n- $G(\\mathbf{k}) = |W_{\\mathrm{CIC}}(\\mathbf{k})|^2 = \\prod_{i=x,y,z} \\mathrm{sinc}^4(k_i/2)$\n- $P_{\\mathrm{true}}(k)$\n- $\\mathrm{bias}_{\\mathrm{ridge}}(\\mathbf{k})$\n- $\\mathrm{var}_{\\mathrm{ridge}}(\\mathbf{k})$\n- $\\mathrm{mse}_{\\mathrm{ridge}}(\\mathbf{k})$\n- $\\mathrm{mse}_{\\mathrm{naive}}(\\mathbf{k})$\n\nThese expressions are evaluated numerically in the provided Python code.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the CIC window function and evaluates bias, variance, and MSE\n    for naive and ridge-regularized power spectrum estimators.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is (k_vector, lambda, sigma_squared).\n    test_cases = [\n        # Case 1: k at origin, low noise\n        (np.array([0.0, 0.0, 0.0]), 1e-6, 1e-4),\n        # Case 2: Moderate wavenumbers, low noise\n        (np.array([np.pi/4, np.pi/4, np.pi/4]), 1e-6, 1e-3),\n        # Case 3: Anisotropic, one component at Nyquist\n        (np.array([np.pi, 0.0, 0.0]), 1e-2, 1e-2),\n        # Case 4: Isotropic at Nyquist\n        (np.array([np.pi, np.pi, np.pi]), 1e-1, 1e-2),\n        # Case 5: Mixed high and low wavenumbers\n        (np.array([0.9*np.pi, 0.9*np.pi, 0.1*np.pi]), 5e-3, 5e-3),\n    ]\n\n    # Parameters for the true power spectrum.\n    A = 10.0\n    k_c = 1.0\n    delta = 1.0  # Grid spacing\n\n    results = []\n\n    def sinc(x):\n        \"\"\"\n        Numerically stable sinc function, sinc(x) = sin(x)/x.\n        \"\"\"\n        return np.where(x == 0.0, 1.0, np.sin(x) / x)\n\n    for case in test_cases:\n        k_vec, lambda_val, sigma_sq_val = case\n\n        # 1. Calculate the true power spectrum P_true(k)\n        k_mag = np.linalg.norm(k_vec)\n        p_true = A * np.exp(-(k_mag / k_c)**2)\n\n        # 2. Calculate the power spectrum transfer function G(k) = |W_CIC(k)|^2\n        # W_CIC(k) = Product_i sinc^2(k_i * delta / 2)\n        # G(k) = |W_CIC(k)|^2 = Product_i sinc^4(k_i * delta / 2)\n        sinc_args = k_vec * delta / 2.0\n        sinc_vals = sinc(sinc_args)\n        G_k = np.prod(sinc_vals**4)\n\n        # 3. Calculate bias, variance, and MSE for both estimators\n        \n        # Guard against division by zero for the naive estimator, though not\n        # expected for these test cases.\n        G_k_sq = G_k**2\n        if G_k_sq == 0.0:\n            mse_naive = np.inf\n        else:\n            mse_naive = sigma_sq_val / G_k_sq\n\n        # Ridge estimator calculations\n        denom_ridge = G_k_sq + lambda_val\n        \n        bias_ridge = (-lambda_val / denom_ridge) * p_true\n        var_ridge = (G_k_sq / (denom_ridge**2)) * sigma_sq_val\n        mse_ridge = bias_ridge**2 + var_ridge\n\n        # Store the results for this case in the specified order\n        # [|W_CIC(k)|^2, P_true(k), bias_ridge, var_ridge, mse_ridge, mse_naive]\n        case_results = [\n            G_k,\n            p_true,\n            bias_ridge,\n            var_ridge,\n            mse_ridge,\n            mse_naive\n        ]\n        results.append(case_results)\n\n    # Format the final output string as specified: [[...],[...],...]\n    # Each inner list is a string representation of the list of floats.\n    list_strs = []\n    for row in results:\n        list_strs.append(f\"[{','.join(f'{x:.8e}' for x in row)}]\")\n    final_output = f\"[{','.join(list_strs)}]\"\n\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}