{
    "hands_on_practices": [
        {
            "introduction": "我们的蒙特卡洛方法实践之旅始于数值积分这一基础任务。第一个练习  将标准蒙特卡洛方法与更精炼的拟蒙特卡洛（QMC）方法进行直接对比。通过计算同一个多维积分，您将亲身体会到，对于平滑的被积函数，QMC 使用的确定性低差异序列如何能够比标准蒙特卡洛方法的伪随机点获得更快的收敛速度。",
            "id": "3522913",
            "problem": "在计算天体物理学的背景下，你的任务是设计并实现一个程序，用于在单位立方体上比较标准蒙特卡洛积分与拟蒙特卡洛积分对一个光滑、可分离的被积函数的表现。考虑函数 $f(\\mathbf{x}) = \\cos(x)\\cos(y)\\cos(z)$ 在立方体 $[0,1]^3$ 上的积分，其中 $(x,y,z)$ 是无量纲的，并且余弦函数的参数以弧度为单位。本问题要求你从蒙特卡洛采样和数值积分的基本原理出发，确保所有的推导、算法选择和比较都基于第一性原理和经过充分检验的结果。\n\n你必须完成以下任务：\n\n1. 使用微积分的基本定义和法则，推导积分 \n$$\nI = \\int_{[0,1]^3} \\cos(x)\\cos(y)\\cos(z)\\,dx\\,dy\\,dz,\n$$\n的精确值，不使用数值求积法。在你的程序中使用该精确值来计算两种方法的绝对误差。\n\n2. 构建 $I$ 的两个估计量：\n   - 一个标准蒙特卡洛估计量 $\\hat{I}_{\\mathrm{MC}}(N)$，基于从 $[0,1]^3$ 上均匀抽取的 $N$ 个独立同分布样本。\n   - 一个拟蒙特卡洛估计量 $\\hat{I}_{\\mathrm{QMC}}(N)$，基于来自 $[0,1]^3$ 上一个低差异序列的 $N$ 个点。\n\n3. 对于标准蒙特卡洛估计量，证明该估计量是无偏的，并基于独立同分布样本的基本概率论结果，解释其方差如何随 $N$ 变化。\n\n4. 对于拟蒙特卡洛估计量，解释为什么低差异序列可以为光滑被积函数带来更快的收敛速度，并提及光滑性（例如，有界混合偏导数）和 Hardy–Krause 意义下的变差属性的作用，以及这些属性如何与星差异（star discrepancy）相结合来限定积分误差。\n\n5. 在一个程序中实现这两种估计量。对于标准蒙特卡洛采样，使用带有指定种子的可复现伪随机数生成器。对于拟蒙特卡洛，使用带有指定种子的可复现置乱低差异序列。不要执行数值求积或外部积分；所有采样必须是显式进行的。\n\n6. 对每个测试用例，计算并报告每个估计量的绝对误差 $|\\hat{I} - I|$。\n\n7. 使用以下样本大小和种子的测试套件来评估估计量。每个测试用例是一个三元组 $(N, s_{\\mathrm{MC}}, s_{\\mathrm{QMC}})$，其中 $N$ 是样本数，$s_{\\mathrm{MC}}$ 是标准蒙特卡洛伪随机数生成器的种子，$s_{\\mathrm{QMC}}$ 是低差异序列置乱的种子：\n   - $(N, s_{\\mathrm{MC}}, s_{\\mathrm{QMC}}) = (1, 7, 101)$\n   - $(N, s_{\\mathrm{MC}}, s_{\\mathrm{QMC}}) = (32, 11, 103)$\n   - $(N, s_{\\mathrm{MC}}, s_{\\mathrm{QMC}}) = (64, 13, 107)$\n   - $(N, s_{\\mathrm{MC}}, s_{\\mathrm{QMC}}) = (1000, 17, 109)$\n   - $(N, s_{\\mathrm{MC}}, s_{\\mathrm{QMC}}) = (4096, 19, 113)$\n\n8. 所有角度必须以弧度为单位进行解释。本问题中没有物理单位。\n\n9. 最终输出格式必须是包含一个列表的单行，其第 $k$ 个元素对应于上面的第 $k$ 个测试用例，并且每个元素是列表 $[N, e_{\\mathrm{MC}}, e_{\\mathrm{QMC}}]$，其中 $e_{\\mathrm{MC}} = |\\hat{I}_{\\mathrm{MC}}(N) - I|$ 且 $e_{\\mathrm{QMC}} = |\\hat{I}_{\\mathrm{QMC}}(N) - I|$。每个误差必须是浮点数。你的程序应该生成一行输出，其中包含用方括号括起来的、以逗号分隔的列表形式的结果（例如：\"[[N1,eMC1,eQMC1],[N2,eMC2,eQMC2],...]\"）。为了可复现性和可读性，在打印前将每个误差四舍五入到 $12$ 位小数。\n\n你的实现必须是一个完整的、可运行的程序，仅使用明确说明的库，且不接受任何用户输入或外部文件。预期的答案类型是按照指定格式化的浮点数和整数列表。目标是从数值和概念上评估标准蒙特卡洛与拟蒙特卡洛在给定相同 $N$ 的情况下，根据被积函数的光滑性和变差属性所表现出的相对误差行为。",
            "solution": "所陈述的问题具有科学依据、提法恰当、客观，并包含足够的信息来推导出唯一、可验证的解。它提出了计算科学中的一个标准而又基本的任务：比较蒙特卡洛和拟蒙特卡洛积分方法对于光滑、可分离函数的表现。所有参数、常数和程序要求都已明确定义。因此，该问题是有效的，并且可以构建一个解决方案。\n\n问题的核心是计算积分 $I = \\int_{[0,1]^3} f(\\mathbf{x})\\,d\\mathbf{x}$，其中被积函数是 $f(\\mathbf{x}) = \\cos(x)\\cos(y)\\cos(z)$，积分域是 $\\mathbb{R}^3$ 中的单位立方体，记作 $[0,1]^3$。\n\n**1. 积分的精确值**\n\n积分为：\n$$\nI = \\int_0^1 \\int_0^1 \\int_0^1 \\cos(x)\\cos(y)\\cos(z)\\,dx\\,dy\\,dz\n$$\n由于被积函数 $f(x,y,z) = \\cos(x)\\cos(y)\\cos(z)$ 是其变量的可分离函数，并且积分域是区间的笛卡尔积（一个立方体），该多维积分可以表示为一维积分的乘积：\n$$\nI = \\left( \\int_0^1 \\cos(u)\\,du \\right) \\left( \\int_0^1 \\cos(v)\\,dv \\right) \\left( \\int_0^1 \\cos(w)\\,dw \\right)\n$$\n这三个积分是相同的。我们使用微积分基本定理来计算这个一维积分，注意到余弦函数的参数以弧度为单位：\n$$\n\\int_0^1 \\cos(u)\\,du = [\\sin(u)]_0^1 = \\sin(1) - \\sin(0) = \\sin(1)\n$$\n因此，积分 $I$ 的精确值为：\n$$\nI = (\\sin(1))^3\n$$\n这个精确值将作为我们衡量数值估计量准确性的基准。\n\n**2. 估计量的构建**\n\n对于积分 $I = \\int_{\\Omega} f(\\mathbf{x})\\,d\\mathbf{x}$，其积分域 $\\Omega$ 的体积为 $V = \\int_{\\Omega} d\\mathbf{x}$，蒙特卡洛积分的一般原理是，将 $I$ 估计为函数在 $N$ 个采样点上取值的平均值，再乘以积分域的体积。估计量为 $\\hat{I}_N = V \\cdot \\frac{1}{N} \\sum_{i=1}^N f(\\mathbf{x}_i)$。对于我们的问题，积分域是单位立方体 $[0,1]^3$，因此其体积 $V$ 为 $1^3 = 1$。因此，估计量简化为函数值的样本均值。\n\n- **标准蒙特卡洛 (MC) 估计量：**\n标准MC估计量 $\\hat{I}_{\\mathrm{MC}}(N)$ 使用一组 $N$ 个点 $\\{\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_N\\}$，这些点是从 $[0,1]^3$ 上的均匀分布中抽取的独立同分布（i.i.d.）样本。估计量为：\n$$\n\\hat{I}_{\\mathrm{MC}}(N) = \\frac{1}{N} \\sum_{i=1}^N f(\\mathbf{x}_i) = \\frac{1}{N} \\sum_{i=1}^N \\cos(x_i)\\cos(y_i)\\cos(z_i)\n$$\n\n- **拟蒙特卡洛 (QMC) 估计量：**\nQMC估计量 $\\hat{I}_{\\mathrm{QMC}}(N)$ 的函数形式与MC估计量相同。然而，采样点 $\\{\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_N\\}$ 不是随机的，而是一个确定性的低差异序列的前 $N$ 个点。这些序列被设计成比伪随机点更均匀地填充空间。\n$$\n\\hat{I}_{\\mathrm{QMC}}(N) = \\frac{1}{N} \\sum_{i=1}^N f(\\mathbf{x}_i) = \\frac{1}{N} \\sum_{i=1}^N \\cos(x_i)\\cos(y_i)\\cos(z_i)\n$$\n在实现中，将使用 Sobol' 序列，这是一种常见且有效的低差异序列。\n\n**3. 标准蒙特卡洛估计量的分析**\n\n- **无偏性：**\n如果一个参数 $\\theta$ 的估计量 $\\hat{\\theta}$ 的期望值等于参数的真值，即 $E[\\hat{\\theta}] = \\theta$，则该估计量是无偏的。对于MC估计量，采样点 $\\mathbf{X}_i$ 是随机变量。根据期望的线性性质：\n$$\nE[\\hat{I}_{\\mathrm{MC}}(N)] = E\\left[\\frac{1}{N} \\sum_{i=1}^N f(\\mathbf{X}_i)\\right] = \\frac{1}{N} \\sum_{i=1}^N E[f(\\mathbf{X}_i)]\n$$\n由于每个 $\\mathbf{X}_i$ 都是从均匀分布 $U([0,1]^3)$ 中抽取的，其概率密度函数为 $p(\\mathbf{x}) = 1$ (当 $\\mathbf{x} \\in [0,1]^3$)，否则为 $0$。$f(\\mathbf{X}_i)$ 的期望值为：\n$$\nE[f(\\mathbf{X}_i)] = \\int_{[0,1]^3} f(\\mathbf{x}) p(\\mathbf{x}) \\,d\\mathbf{x} = \\int_{[0,1]^3} f(\\mathbf{x}) \\cdot 1 \\,d\\mathbf{x} = I\n$$\n将此代回，我们得到：\n$$\nE[\\hat{I}_{\\mathrm{MC}}(N)] = \\frac{1}{N} \\sum_{i=1}^N I = \\frac{1}{N} (N \\cdot I) = I\n$$\n因此，标准MC估计量是积分 $I$ 的一个无偏估计量。\n\n- **方差和收敛性：**\n估计量的方差决定了其收敛速度。由于样本 $\\mathbf{X}_i$ 是独立同分布的，它们的和的方差等于方差的和：\n$$\n\\mathrm{Var}(\\hat{I}_{\\mathrm{MC}}(N)) = \\mathrm{Var}\\left(\\frac{1}{N} \\sum_{i=1}^N f(\\mathbf{X}_i)\\right) = \\frac{1}{N^2} \\sum_{i=1}^N \\mathrm{Var}(f(\\mathbf{X}_i))\n$$\n单个样本函数值的方差 $\\sigma^2 = \\mathrm{Var}(f(\\mathbf{X}_i))$ 对所有 $i$ 都是有限且恒定的：\n$$\n\\sigma^2 = E[(f(\\mathbf{X}) - E[f(\\mathbf{X})])^2] = \\int_{[0,1]^3} (f(\\mathbf{x}) - I)^2 \\,d\\mathbf{x}\n$$\n因此，MC估计量的方差为：\n$$\n\\mathrm{Var}(\\hat{I}_{\\mathrm{MC}}(N)) = \\frac{1}{N^2} (N \\sigma^2) = \\frac{\\sigma^2}{N}\n$$\n估计量的标准误差是方差的平方根，即 $\\sigma/\\sqrt{N}$。这表明标准蒙特卡洛方法的误差以 $O(N^{-1/2})$ 的速率收敛到零，这是中心极限定理的一个结果。这个收敛速率与积分的维度无关，这是MC方法的一个关键优势。\n\n**4. 拟蒙特卡洛估计量的分析**\n\nQMC方法用确定性的低差异点替代伪随机点。QMC中的误差不是一个概率量，而是一个确定性的、有界的误差。控制QMC误差的主要理论结果是 Koksma-Hlawka 不等式：\n$$\n|\\hat{I}_{\\mathrm{QMC}}(N) - I| = \\left| \\frac{1}{N} \\sum_{i=1}^{N} f(\\mathbf{x}_i) - \\int_{[0,1]^d} f(\\mathbf{x}) \\, d\\mathbf{x} \\right| \\le V_{HK}(f) \\cdot D_N^*(\\mathcal{P}_N)\n$$\n该不等式将积分误差与两个关键量联系起来：\n- **$D_N^*(\\mathcal{P}_N)$**：点集 $\\mathcal{P}_N = \\{\\mathbf{x}_1, \\dots, \\mathbf{x}_N\\}$ 的星差异（star discrepancy）。差异是衡量点集在单位立方体中分布均匀程度的量化指标。对于低差异序列（如 Sobol'、Halton 或 Faure 序列），已知 $d$ 维的星差异有界，为 $D_N^* = O\\left(\\frac{(\\log N)^d}{N}\\right)$。\n- **$V_{HK}(f)$**：函数 $f$ 在 Hardy and Krause 意义下的变差。要使被积函数具有有限的 Hardy-Krause 变差，它必须具备一定程度的光滑性。具体来说，如果 $f$ 的所有混合偏导数，直至 $\\frac{\\partial^d f}{\\partial x_1 \\dots \\partial x_d}$，在 $[0,1]^d$ 上都存在且连续，则其变差是有限的。\n\n本问题中的函数 $f(x,y,z) = \\cos(x)\\cos(y)\\cos(z)$ 在 $\\mathbb{R}^3$ 上是无限可微的 ($C^\\infty$)，因此其所有的混合偏导数在紧致域 $[0,1]^3$ 上都是连续且有界的。这保证了其 Hardy-Krause 变差 $V_{HK}(f)$ 是有限的。\n\n综合这些事实，本问题的QMC误差有界为：\n$$\n|\\hat{I}_{\\mathrm{QMC}}(N) - I| = O\\left(\\frac{(\\log N)^d}{N}\\right)\n$$\n对于我们固定的维度 $d=3$，这个理论收敛速率近似为 $O(N^{-1})$，这在渐进意义上优于标准MC的概率性 $O(N^{-1/2})$ 收敛。这种对光滑函数的改进收敛是使用QMC方法的主要动机。在实践中，对于有限的 $N$，使用置乱序列通常能通过打破确定性结构并提供误差估计机制来提高性能，尽管渐进速率保持不变。\n\n**5-9. 实现与执行**\n\n以下程序实现了两种估计量，计算了指定测试用例的绝对误差，并按要求格式化输出。它使用 `numpy` 进行数值运算，使用 `numpy.random.default_rng` 生成MC中的伪随机数，并使用 `scipy.stats.qmc.Sobol` 生成QMC中的置乱 Sobol' 序列。精确值 $I = (\\sin(1))^3$ 被预先计算并用于计算误差。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import qmc\n\ndef solve():\n    \"\"\"\n    Compares Standard Monte Carlo and Quasi-Monte Carlo integration\n    for a smooth, separable integrand over the unit cube.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, s_MC, s_QMC)\n        (1, 7, 101),\n        (32, 11, 103),\n        (64, 13, 107),\n        (1000, 17, 109),\n        (4096, 19, 113),\n    ]\n\n    # 1. Derive the exact value of the integral.\n    # I = integral_0^1 cos(x)dx * integral_0^1 cos(y)dy * integral_0^1 cos(z)dz\n    # integral_0^1 cos(u)du = [sin(u)]_0^1 = sin(1) - sin(0) = sin(1)\n    # So, I = (sin(1))^3\n    exact_integral_value = np.sin(1)**3\n    \n    # The integrand function f(x) = cos(x)cos(y)cos(z)\n    def integrand(points):\n        # points is an array of shape (N, 3)\n        return np.cos(points[:, 0]) * np.cos(points[:, 1]) * np.cos(points[:, 2])\n\n    results = []\n    \n    for case in test_cases:\n        N, s_mc, s_qmc = case\n        \n        # 2. Standard Monte Carlo (MC) estimator\n        # Use a reproducible pseudo-random number generator\n        rng_mc = np.random.default_rng(seed=s_mc)\n        # Generate N i.i.d. uniform samples in [0,1]^3\n        mc_points = rng_mc.uniform(0, 1, size=(N, 3))\n        # Evaluate the integrand at these points\n        mc_f_values = integrand(mc_points)\n        # The estimator is the sample mean (Volume of unit cube is 1)\n        i_hat_mc = np.mean(mc_f_values)\n        \n        # 3. Quasi-Monte Carlo (QMC) estimator\n        # Use a reproducibly scrambled low-discrepancy sequence (Sobol')\n        # The problem specifies scipy 1.11.4, where the parameter is 'seed'.\n        sampler_qmc = qmc.Sobol(d=3, scramble=True, seed=s_qmc)\n        # Generate N points from the Sobol' sequence\n        qmc_points = sampler_qmc.random(n=N)\n        # Evaluate the integrand at these points\n        qmc_f_values = integrand(qmc_points)\n        # The estimator is the sample mean\n        i_hat_qmc = np.mean(qmc_f_values)\n\n        # 4. Compute absolute errors\n        error_mc = abs(i_hat_mc - exact_integral_value)\n        error_qmc = abs(i_hat_qmc - exact_integral_value)\n\n        # 5. Round errors to 12 decimal places and store results\n        rounded_error_mc = round(error_mc, 12)\n        rounded_error_qmc = round(error_qmc, 12)\n        \n        results.append([N, rounded_error_mc, rounded_error_qmc])\n\n    # Final print statement in the exact required format.\n    # The format is a list of lists, represented as a string.\n    # e.g., \"[[N1,eMC1,eQMC1],[N2,eMC2,eQMC2],...]\"\n    result_str = \",\".join(map(str, results))\n    print(f\"[{result_str}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "虽然 QMC 改善了采样的均匀性，但重要性采样则提供了一种更具针对性的策略，它将计算精力集中在被积函数最重要的区域。此练习  将引导您体验设计重要性采样器的完整过程，并揭示该方法稳定性的一个关键方面。您将推导出估计量方差有限的精确条件，从而通过量化的方式清晰地说明，为何审慎选择建议分布对成功至关重要。",
            "id": "3522899",
            "problem": "考虑在计算天体物理学中为指数抑制分布建模时出现的积分 $I=\\int_{0}^{\\infty} e^{-x}\\,dx$。重要性采样是一种用于蒙特卡罗积分的方差缩减技术，它使用具有已知概率密度函数的提议分布来估计积分。设 $X\\sim \\mathrm{Gamma}(k,\\theta)$ 是一个提议分布，其形状参数 $k0$，尺度参数 $\\theta0$，在支撑集 $x\\in [0,\\infty)$ 上具有已知的密度 $q_{k,\\theta}(x)$。重要性采样估计量使用权重函数 $w(x)$，该函数定义为目标被积函数与提议密度之比。该估计量的方差取决于 $w(x)$ 关于 $q_{k,\\theta}(x)$ 的二阶矩，并且可能仅在关于 $(k,\\theta)$ 的特定条件下才为有限值。\n\n另一种直接方法是在截断域 $[0,L]$（其中 $L0$）上进行均匀采样，并结合对可以精确计算的尾部积分 $\\int_{L}^{\\infty} e^{-x}\\,dx$ 进行确定性修正。在这种情况下，通过将已知的尾部贡献加到截断积分的蒙特卡罗估计上，可以构造一个无偏估计量。这个截断修正估计量的方差取决于当 $X\\sim \\mathrm{Uniform}(0,L)$ 时 $e^{-X}$ 的方差。\n\n从重要性采样的基本定义以及Gamma分布和指数积分的已知公式出发，执行以下操作：\n\n1. 对于提议分布 $X\\sim \\mathrm{Gamma}(k,\\theta)$ 及其密度 $q_{k,\\theta}(x)$，显式地推导重要性采样权重 $w(x)$。\n2. 用 $k$ 和 $\\theta$ 推导二阶矩 $\\mathbb{E}_{q_{k,\\theta}}[w(X)^{2}]$ 的精确闭式表达式，并由此获得样本量为 $n$ 时 $I$ 的重要性采样估计量的方差。确定使该方差为有限值的 $(k,\\theta)$ 的精确条件。\n3. 对于在 $[0,L]$ 上的截断均匀方法，其中 $X\\sim \\mathrm{Uniform}(0,L)$ 并且确定性地添加了尾部修正以确保无偏性，用 $L$ 推导样本量为 $n$ 时 $I$ 的蒙特卡罗估计量的精确方差。\n4. 定义理论比率\n$$\nR(k,\\theta,L) \\;=\\; \\frac{\\mathrm{Var}[\\hat{I}_{\\mathrm{IS}}]}{\\mathrm{Var}[\\hat{I}_{\\mathrm{UNI}}]} \\,,\n$$\n其中 $\\mathrm{Var}[\\hat{I}_{\\mathrm{IS}}]$ 是使用 $X\\sim \\mathrm{Gamma}(k,\\theta)$ 的重要性采样估计量的方差，$\\mathrm{Var}[\\hat{I}_{\\mathrm{UNI}}]$ 是在 $[0,L]$ 上带精确尾部修正的截断均匀估计量的方差。证明 $R(k,\\theta,L)$ 与样本量 $n$ 无关，并给出其精确公式。如果重要性采样方差为无穷大，则定义 $R(k,\\theta,L)=+\\infty$。\n\n您的程序必须为以下参数值测试集计算并输出 $R(k,\\theta,L)$：\n- 情况1（理想情况，最优匹配）：$(k,\\theta,L)=(1.0,\\,1.0,\\,5.0)$。\n- 情况2（有限方差，非平凡）：$(k,\\theta,L)=(1.5,\\,0.8,\\,5.0)$。\n- 情况3（近边界有限方差）：$(k,\\theta,L)=(1.9,\\,0.55,\\,8.0)$。\n- 情况4（形状引发的发散）：$(k,\\theta,L)=(2.5,\\,0.8,\\,5.0)$。\n- 情况5（尺度引发的发散）：$(k,\\theta,L)=(1.0,\\,0.4,\\,5.0)$。\n\n所有值都是无量纲的；不涉及物理单位或角度单位。您的输出必须是单行，其中包含一个由方括号括起来的、由逗号分隔的五个数字的列表，顺序与上面列出的情况相同。每个条目必须是 $R(k,\\theta,L)$ 的精确理论值，四舍五入到六位小数。如果值为无穷大，则将 Python 浮点表示 $+\\infty$ 显示为标记 $inf$。例如，输出可能看起来像“[0.000000,0.123456,0.654321,inf,inf]”。\n\n您的程序必须是自包含的，不需要任何输入，并且不得使用任何外部数据。最终输出必须以指定格式精确打印为一行，并且必须依赖于上面推导出的精确公式，而不是经验模拟。",
            "solution": "该问题陈述是关于蒙特卡罗积分技术分析的一个良构练习。它科学地基于已建立的统计学和数学原理，是自包含的，并且没有矛盾或歧义。因此，该问题被视为有效，下面提供了完整的解决方案。\n\n该问题要求推导和计算积分 $I=\\int_{0}^{\\infty} e^{-x}\\,dx = 1$ 的两种不同蒙特卡罗估计量的方差之比。这两种方法是使用Gamma分布提议的重要性采样，以及在截断域上使用精确尾部修正的均匀采样。\n\n**第1部分：重要性采样权重函数**\n\n设目标被积函数为 $f(x) = e^{-x}$。提议分布为 $X\\sim \\mathrm{Gamma}(k,\\theta)$，其中 $x \\in [0,\\infty)$，参数 $k0$ 和 $\\theta0$。该分布的概率密度函数 (PDF) 由下式给出：\n$$\nq_{k,\\theta}(x) = \\frac{x^{k-1} e^{-x/\\theta}}{\\theta^k \\Gamma(k)}\n$$\n其中 $\\Gamma(k)$ 是Gamma函数。重要性采样权重函数 $w(x)$ 定义为被积函数与提议密度之比：\n$$\nw(x) = \\frac{f(x)}{q_{k,\\theta}(x)} = \\frac{e^{-x}}{x^{k-1} e^{-x/\\theta} / (\\theta^k \\Gamma(k))}\n$$\n化简此表达式，我们得到：\n$$\nw(x) = \\theta^k \\Gamma(k) \\, x^{-(k-1)} e^{-x + x/\\theta} = \\theta^k \\Gamma(k) \\, x^{1-k} e^{-x(1 - 1/\\theta)}\n$$\n这是权重函数的显式形式。\n\n**第2部分：重要性采样估计量的方差**\n\n基于从 $q_{k,\\theta}(x)$ 中抽取的样本量为 $n$ 的样本 $\\{X_1, \\dots, X_n\\}$，$I$ 的重要性采样估计量为 $\\hat{I}_{\\mathrm{IS}} = \\frac{1}{n} \\sum_{i=1}^n w(X_i)$。该估计量的方差为：\n$$\n\\mathrm{Var}[\\hat{I}_{\\mathrm{IS}}] = \\frac{1}{n} \\mathrm{Var}_{q_{k,\\theta}}[w(X)] = \\frac{1}{n} \\left( \\mathbb{E}_{q_{k,\\theta}}[w(X)^2] - (\\mathbb{E}_{q_{k,\\theta}}[w(X)])^2 \\right)\n$$\n首先，我们通过计算权重的期望值来验证该估计量是无偏的：\n$$\n\\mathbb{E}_{q_{k,\\theta}}[w(X)] = \\int_0^\\infty w(x) q_{k,\\theta}(x) \\,dx = \\int_0^\\infty \\frac{f(x)}{q_{k,\\theta}(x)} q_{k,\\theta}(x) \\,dx = \\int_0^\\infty f(x) \\,dx = I = 1\n$$\n因此，$(\\mathbb{E}_{q_{k,\\theta}}[w(X)])^2 = 1^2 = 1$。方差由二阶矩 $\\mathbb{E}_{q_{k,\\theta}}[w(X)^2]$ 决定。\n$$\n\\mathbb{E}_{q_{k,\\theta}}[w(X)^2] = \\int_0^\\infty w(x)^2 q_{k,\\theta}(x) \\,dx\n$$\n代入 $w(x)$ 和 $q_{k,\\theta}(x)$ 的表达式：\n$$\n\\mathbb{E}_{q_{k,\\theta}}[w(X)^2] = \\int_0^\\infty \\left( \\theta^k \\Gamma(k) \\, x^{1-k} e^{-x(1 - 1/\\theta)} \\right)^2 \\left( \\frac{x^{k-1} e^{-x/\\theta}}{\\theta^k \\Gamma(k)} \\right) \\,dx\n$$\n$$\n= (\\theta^k \\Gamma(k))^2 \\frac{1}{\\theta^k \\Gamma(k)} \\int_0^\\infty x^{2(1-k)} x^{k-1} e^{-2x(1-1/\\theta)} e^{-x/\\theta} \\,dx\n$$\n$$\n= \\theta^k \\Gamma(k) \\int_0^\\infty x^{2-2k+k-1} e^{-2x + 2x/\\theta - x/\\theta} \\,dx\n$$\n$$\n= \\theta^k \\Gamma(k) \\int_0^\\infty x^{1-k} e^{-x(2 - 1/\\theta)} \\,dx\n$$\n为使该积分收敛，指数项的指数必须为正，即 $2 - 1/\\theta  0$，或 $\\theta  1/2$。该积分是Gamma函数积分的一种形式，$\\int_0^\\infty t^{z-1} e^{-at} dt = a^{-z}\\Gamma(z)$，当 $z0$ 时收敛。此处，$z-1 = 1-k$，所以 $z=2-k$，收敛条件是 $2-k0$，即 $k  2$。\n在这些条件下，该积分的计算结果为：\n$$\n\\int_0^\\infty x^{(2-k)-1} e^{-x(2 - 1/\\theta)} \\,dx = (2-1/\\theta)^{-(2-k)} \\Gamma(2-k)\n$$\n将此结果代回二阶矩的表达式中：\n$$\n\\mathbb{E}_{q_{k,\\theta}}[w(X)^2] = \\theta^k \\Gamma(k) (2-1/\\theta)^{k-2} \\Gamma(2-k) = \\theta^k \\Gamma(k) \\Gamma(2-k) \\left(\\frac{2\\theta-1}{\\theta}\\right)^{k-2}\n$$\n$$\n= \\theta^k \\Gamma(k) \\Gamma(2-k) \\frac{\\theta^{2-k}}{(2\\theta-1)^{2-k}} = \\theta^2 \\Gamma(k) \\Gamma(2-k) (2\\theta-1)^{k-2}\n$$\n当且仅当 $k  2$ 且 $\\theta  1/2$ 时，方差是有限的。如果这两个条件中的任何一个不满足，方差就是无限的。\n该估计量的方差是：\n$$\n\\mathrm{Var}[\\hat{I}_{\\mathrm{IS}}] = \\frac{1}{n} \\left( \\theta^2 \\Gamma(k) \\Gamma(2-k) (2\\theta-1)^{k-2} - 1 \\right)\n$$\n\n**第3部分：截断均匀估计量的方差**\n\n第二种方法估计 $I = \\int_0^L e^{-x}\\,dx + \\int_L^\\infty e^{-x}\\,dx$。尾部积分可以解析地计算：$\\int_L^\\infty e^{-x}\\,dx = e^{-L}$。项 $\\int_0^L e^{-x}\\,dx$ 通过蒙特卡罗方法估计，即通过从 $X_i \\sim \\mathrm{Uniform}(0,L)$ 中采样，其PDF为 $p(x) = 1/L$。\n总估计量为 $\\hat{I}_{\\mathrm{UNI}} = \\frac{1}{n} \\sum_{i=1}^n \\frac{e^{-X_i}}{p(X_i)} + e^{-L} = \\frac{L}{n} \\sum_{i=1}^n e^{-X_i} + e^{-L}$。由于 $e^{-L}$ 项是一个确定性常数，它对方差没有贡献。\n$$\n\\mathrm{Var}[\\hat{I}_{\\mathrm{UNI}}] = \\mathrm{Var}\\left[\\frac{L}{n} \\sum_{i=1}^n e^{-X_i}\\right] = \\frac{L^2}{n^2} \\sum_{i=1}^n \\mathrm{Var}[e^{-X_i}] = \\frac{L^2}{n} \\mathrm{Var}[e^{-X}]\n$$\n其中 $X \\sim \\mathrm{Uniform}(0,L)$。我们计算 $\\mathrm{Var}[e^{-X}] = \\mathbb{E}[(e^{-X})^2] - (\\mathbb{E}[e^{-X}])^2$。\n一阶矩是：\n$$\n\\mathbb{E}[e^{-X}] = \\int_0^L e^{-x} \\frac{1}{L} \\,dx = \\frac{1}{L} [-e^{-x}]_0^L = \\frac{1-e^{-L}}{L}\n$$\n二阶矩是：\n$$\n\\mathbb{E}[e^{-2X}] = \\int_0^L e^{-2x} \\frac{1}{L} \\,dx = \\frac{1}{L} \\left[-\\frac{1}{2}e^{-2x}\\right]_0^L = \\frac{1 - e^{-2L}}{2L}\n$$\n$e^{-X}$ 的方差是：\n$$\n\\mathrm{Var}[e^{-X}] = \\frac{1 - e^{-2L}}{2L} - \\left(\\frac{1-e^{-L}}{L}\\right)^2\n$$\n因此，估计量 $\\hat{I}_{\\mathrm{UNI}}$ 的方差为：\n$$\n\\mathrm{Var}[\\hat{I}_{\\mathrm{UNI}}] = \\frac{L^2}{n} \\left[ \\frac{1 - e^{-2L}}{2L} - \\frac{(1-e^{-L})^2}{L^2} \\right] = \\frac{1}{n} \\left[ \\frac{L(1 - e^{-2L})}{2} - (1-e^{-L})^2 \\right]\n$$\n对于任何 $L0$，该方差是有限且为正的。\n\n**第4部分：方差之比**\n\n比率 $R(k,\\theta,L)$ 定义为两个方差之比。\n$$\nR(k,\\theta,L) = \\frac{\\mathrm{Var}[\\hat{I}_{\\mathrm{IS}}]}{\\mathrm{Var}[\\hat{I}_{\\mathrm{UNI}}]} = \\frac{\\frac{1}{n} \\left( \\theta^2 \\Gamma(k) \\Gamma(2-k) (2\\theta-1)^{k-2} - 1 \\right)}{\\frac{1}{n} \\left( \\frac{L(1 - e^{-2L})}{2} - (1-e^{-L})^2 \\right)}\n$$\n因子 $1/n$ 被消去，表明该比率与样本量 $n$ 无关。\n$$\nR(k,\\theta,L) = \\frac{\\theta^2 \\Gamma(k) \\Gamma(2-k) (2\\theta-1)^{k-2} - 1}{\\frac{L(1 - e^{-2L})}{2} - (1-e^{-L})^2}\n$$\n该公式在 $k  2$ 和 $\\theta  1/2$ 时有效。如果关于 $k$ 和 $\\theta$ 的这些条件不满足，$\\mathrm{Var}[\\hat{I}_{\\mathrm{IS}}]$ 为无穷大，根据定义，$R(k,\\theta,L) = +\\infty$。\n$(k,\\theta)=(1,1)$ 的情况是特殊的，因为提议分布 $q_{1,1}(x)=e^{-x}$ 与被积函数 $f(x)$ 完全匹配。此时，权重的二阶矩为 $\\mathbb{E}[w^2] = 1^2 \\Gamma(1)\\Gamma(1)(2-1)^{-1}-1 = 1$，因此重要性采样估计量的方差为零，对于任何 $L0$，得出 $R(1,1,L)=0$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gamma\n\ndef solve():\n    \"\"\"\n    Computes the theoretical variance ratio R(k, theta, L) for five test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (happy path, optimal match)\n        (1.0, 1.0, 5.0),\n        # Case 2 (finite-variance, nontrivial)\n        (1.5, 0.8, 5.0),\n        # Case 3 (near-boundary finite-variance)\n        (1.9, 0.55, 8.0),\n        # Case 4 (shape-induced divergence)\n        (2.5, 0.8, 5.0),\n        # Case 5 (scale-induced divergence)\n        (1.0, 0.4, 5.0),\n    ]\n\n    results = []\n    for k, theta, L in test_cases:\n        # Step 1: Check for conditions of infinite variance in the importance sampling estimator.\n        # The variance is finite if and only if k  2.0 and theta > 0.5.\n        if k >= 2.0 or theta = 0.5:\n            results.append(np.inf)\n            continue\n\n        # Step 2: Calculate the numerator of the ratio R.\n        # This is the single-sample variance of the importance sampling estimator.\n        # Var_IS = (E[w^2] - 1)\n        # E[w^2] = theta^2 * Gamma(k) * Gamma(2-k) * (2*theta - 1)^(k-2)\n        \n        # A special case for k=1, theta=1 where the proposal matches the integrand.\n        # The variance is exactly 0. This avoids potential floating point issues.\n        if k == 1.0 and theta == 1.0:\n            var_is_num = 0.0\n        else:\n            term1 = theta**2\n            term2 = gamma(k)\n            term3 = gamma(2.0 - k)\n            term4 = (2.0 * theta - 1.0)**(k - 2.0)\n            E_w_sq = term1 * term2 * term3 * term4\n            var_is_num = E_w_sq - 1.0\n\n        # Step 3: Calculate the denominator of the ratio R.\n        # This is the single-sample variance of the truncated uniform estimator.\n        # Var_UNI = L^2 * Var(e^-X) for X ~ U(0,L)\n        # Var_UNI = L/2 * (1 - e^(-2L)) - (1 - e^(-L))^2\n        exp_L = np.exp(-L)\n        exp_2L = np.exp(-2.0 * L)\n        var_uni_den = (L * (1.0 - exp_2L) / 2.0) - (1.0 - exp_L)**2\n\n        # The denominator is a variance, so it should be non-negative.\n        # It is zero only if L->0, which is not the case here.\n        if var_uni_den = 0:\n            # Handle potential numerical instability, although unlikely for these inputs.\n            ratio = np.inf\n        else:\n            ratio = var_is_num / var_uni_den\n        \n        results.append(ratio)\n    \n    # Format the final output string.\n    # Round finite numbers to 6 decimal places.\n    # Python's str() of np.inf produces 'inf'.\n    formatted_results = []\n    for res in results:\n        if np.isinf(res):\n            formatted_results.append(str(res))\n        else:\n            formatted_results.append(f\"{res:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "除了数值积分，蒙特卡洛方法在从复杂分布中生成随机数方面也至关重要。这个练习  探索了接受-拒绝采样法，这是一种用于完成此任务的经典而优雅的基础算法。您的目标是通过计算每次成功接受样本所需的建议分布采样次数的方差来分析该方法的效率，从而将采样器的性能与建议分布和目标分布的匹配程度直接联系起来。",
            "id": "3522962",
            "problem": "在计算天体物理学中，一个模拟的超高能宇宙射线群体由能量域 $[E_{\\min}, E_{\\max}]$ 上的截断幂律概率密度函数（PDF）$p(E)$ 建模，其中 $E_{\\min}  0$ 且 $E_{\\max}  \\infty$。目标 PDF 为 $p(E) = C E^{-\\alpha}$，适用于 $E \\in [E_{\\min}, E_{\\max}]$，其中 $\\alpha  1$，且 $C$ 的选择是为了在 $[E_{\\min}, E_{\\max}]$ 上归一化 $p(E)$。您希望使用接受-拒绝方法，通过在相同域上的提议 PDF $q(E) = D E^{-\\gamma}$（其中 $\\gamma \\neq \\alpha$，且 $D$ 的选择是为了在 $[E_{\\min}, E_{\\max}]$ 上归一化 $q(E)$）从 $p(E)$ 中采样。设 $M$ 是一个包络常数，满足对于所有 $E \\in [E_{\\min}, E_{\\max}]$ 都有 $p(E) \\le M q(E)$，并定义接受规则如下：从 $q$ 中抽取 $E$，从 $\\mathrm{Uniform}(0,1)$ 中抽取 $U$，如果 $U \\le p(E)/(M q(E))$，则接受 $E$。\n\n从接受-拒绝方法和几何分布的基本定义出发，推导期望接受概率 $A$（用 $M$ 表示）以及每个接受样本所需的期望提议抽样次数。然后，将直到下一次接受所需的提议抽样次数建模为一个几何随机变量，并计算其方差。将最终的方差用 $M$ 的封闭形式解析表达式表示。最后，解释当目标分布具有重尾（大的 $\\alpha$ 接近于 $1$）且提议分布 $q$ 匹配不佳导致 $M$ 很大时，效率的权衡问题，并将其与您推导出的方差行为联系起来。\n\n您的最终答案必须是仅含 $M$ 的单一封闭形式方差表达式。不需要进行数值四舍五入，最终答案中也不应包含单位。解释性讨论应包含在您的推导过程中，但不会改变您报告的最终表达式。",
            "solution": "该问题要求推导在接受-拒绝采样方法中，获得一次接受所需的提议抽样次数的方差，并用包络常数 $M$ 表示。分析将首先推导总接受概率，然后利用几何分布的性质。\n\n接受-拒绝方法由以下几个部分定义：\n1.  目标概率密度函数（PDF）$p(E) = C E^{-\\alpha}$，适用于 $E \\in [E_{\\min}, E_{\\max}]$，其中 $C$ 是一个归一化常数。\n2.  提议 PDF $q(E) = D E^{-\\gamma}$，适用于 $E \\in [E_{\\min}, E_{\\max}]$，其中 $D$ 是一个归一化常数。\n3.  一个常数 $M$，使得对于所有 $E \\in [E_{\\min}, E_{\\max}]$ 都有 $p(E) \\le M q(E)$。$M$ 的最有效选择是满足此条件的最小值，即 $M = \\sup_{E} \\frac{p(E)}{q(E)}$。\n4.  采样过程：从 $q(E)$ 中抽取一个候选样本 $E$，并从 $[0, 1]$ 上的均匀分布中抽取一个随机数 $U$。如果 $U \\le \\frac{p(E)}{M q(E)}$，则接受样本 $E$。\n\n首先，让我们确定接受一个提议样本的总概率。这个概率我们记为 $A$，它是接受条件的期望值，该期望值是对从提议分布 $q(E)$ 中抽取的所有可能样本进行平均得到的。接受特定值 $E$ 的概率是 $P(\\text{accept}|E) = \\frac{p(E)}{M q(E)}$。为了求得总概率 $A$，我们将此条件概率用提议 PDF $q(E)$ 加权，并在整个域上积分：\n$$A = \\int_{E_{\\min}}^{E_{\\max}} P(\\text{accept}|E) q(E) dE$$\n代入条件接受概率的表达式，我们得到：\n$$A = \\int_{E_{\\min}}^{E_{\\max}} \\left( \\frac{p(E)}{M q(E)} \\right) q(E) dE$$\n$q(E)$ 项被消去，剩下：\n$$A = \\frac{1}{M} \\int_{E_{\\min}}^{E_{\\max}} p(E) dE$$\n由于 $p(E)$ 是在区间 $[E_{\\min}, E_{\\max}]$ 上被正确归一化的 PDF，根据定义，它在该域上的积分等于 $1$：\n$$\\int_{E_{\\min}}^{E_{\\max}} p(E) dE = 1$$\n因此，总接受概率就是：\n$$A = \\frac{1}{M}$$\n\n从提议分布中抽样直到有一个样本被接受的过程，可以被建模为一系列独立的伯努利试验。每次试验是一次“抽样”，而“成功”对应于样本被接受。在任何一次给定的试验中，成功的概率是 $A = 1/M$。\n\n获得第一次成功所需的试验次数，我们称之为 $K$，服从几何分布。成功概率为 $p$ 的几何随机变量 $K$ 的概率质量函数（PMF）由 $P(K=k) = (1-p)^{k-1}p$ 给出，其中 $k = 1, 2, 3, \\ldots$。\n\n问题要求与此分布相关的两个量：期望抽样次数和方差。\n成功概率为 $p$ 的几何随机变量 $K$ 的期望值是 $E[K] = \\frac{1}{p}$。在我们的例子中，成功概率是 $p=A=1/M$。因此，每个接受样本所需的期望提议抽样次数是：\n$$E[K] = \\frac{1}{A} = \\frac{1}{1/M} = M$$\n这个结果是接受-拒绝方法的基础：所需的平均提议次数等于包络常数 $M$。这突显了选择一个能最小化 $M$ 的提议分布 $q(E)$ 的重要性。\n\n接下来，我们计算抽样次数的方差，$\\text{Var}(K)$。成功概率为 $p$ 的几何随机变量的方差由以下公式给出：\n$$\\text{Var}(K) = \\frac{1-p}{p^2}$$\n代入我们的成功概率 $p = A = 1/M$，我们得到用 $M$ 表示的方差：\n$$\\text{Var}(K) = \\frac{1 - \\frac{1}{M}}{\\left(\\frac{1}{M}\\right)^2}$$\n化简分子中的表达式：\n$$\\text{Var}(K) = \\frac{\\frac{M-1}{M}}{\\frac{1}{M^2}}$$\n现在我们可以化简这个复合分数：\n$$\\text{Var}(K) = \\frac{M-1}{M} \\cdot M^2$$\n$$\\text{Var}(K) = (M-1)M = M^2 - M$$\n这就是获得一个接受样本所需的提议抽样次数的方差的封闭形式解析表达式。\n\n最后，我们解释效率的权衡。算法的效率与期望抽样次数 $M$ 成反比。较小的 $M$ 意味着较高的效率。方差 $\\text{Var}(K)=M^2-M$，在 $M$ 很大时，随 $M$呈二次方增长。当提议分布 $q(E)$ 与目标分布 $p(E)$ 匹配不佳时，会出现大的 $M$ 值。在本问题的背景下，其中 $p(E) \\propto E^{-\\alpha}$ 且 $q(E) \\propto E^{-\\gamma}$，指数 $\\alpha$ 和 $\\gamma$ 之间的巨大不匹配将导致比率 $p(E)/q(E) \\propto E^{\\gamma-\\alpha}$ 在域 $[E_{\\min}, E_{\\max}]$ 上显著变化，从而迫使 $M$ 变得很大以在任何地方都包络住目标 PDF。\n\n当目标分布具有重尾（小的 $\\alpha$，例如 $\\alpha$ 接近 $1$）时，其衰减很慢。如果提议分布 $q(E)$ 匹配不佳（例如 $\\gamma \\gg \\alpha$，导致 $q$ 衰减得快得多），$M$ 将会非常大。大的 $M$ 不仅意味着算法在平均情况下效率低下（需要多次抽样），而且大的方差 $M^2 - M$ 意味着性能也高度不可预测。虽然平均抽样次数是 $M$，但对于大的 $M$，标准差为 $\\sqrt{M^2-M} \\approx M$。这意味着每次接受所需的抽样次数可能会有极端波动，使得模拟的运行时间不稳定且不可靠。因此，大的 $M$ 对采样算法的平均效率和可预测性都有害。",
            "answer": "$$\n\\boxed{M^2 - M}\n$$"
        }
    ]
}