{
    "hands_on_practices": [
        {
            "introduction": "Before tackling complex astrophysical systems, it is invaluable to build intuition with a foundational case. This exercise explores the one-dimensional discrete Laplacian operator, which is the cornerstone of numerical models for diffusion, heat conduction, and wave phenomena. By analytically deriving its eigenvalues and eigenvectors, you will see how the discrete matrix formulation directly gives rise to the familiar sinusoidal modes expected from the continuous counterpart, providing a crucial bridge between the theoretical differential operator and its computational representation .",
            "id": "3526049",
            "problem": "A plane-parallel, optically thick astrophysical slab of thickness $L$ supports thermal diffusion along the Cartesian coordinate $x \\in [0,L]$ with fixed temperatures at the boundaries due to highly efficient radiative coupling to the ambient medium. To analyze numerical stability and mode content in explicit time-integration schemes, consider the spatial operator underlying the one-dimensional second derivative $d^{2}/dx^{2}$ with homogeneous Dirichlet boundary conditions $u(0)=0$ and $u(L)=0$.\n\nDiscretize the interval with $N$ interior grid points at positions $x_{j} = j h$ for $j \\in \\{1,2,\\dots,N\\}$ and $h = L/(N+1)$. Use the standard second-order central finite-difference approximation for the second derivative built from the definition of the derivative as a limit of difference quotients. Define the dimensionless discrete Laplacian matrix $\\tilde{\\mathcal{L}} \\in \\mathbb{R}^{N \\times N}$ by multiplying the usual finite-difference matrix by $h^{2}$, so that the matrix entries are\n$$\n\\tilde{\\mathcal{L}}_{j,j} = -2, \\quad \\tilde{\\mathcal{L}}_{j,j+1} = 1, \\quad \\tilde{\\mathcal{L}}_{j,j-1} = 1,\n$$\nwith all other entries equal to $0$, and with the implicit Dirichlet conditions $u_{0}=0$ and $u_{N+1}=0$.\n\nStarting from these definitions and boundary conditions, derive the eigenpairs $\\big(\\lambda_{k}, v^{(k)}\\big)$ of $\\tilde{\\mathcal{L}}$, and show that the components of each eigenvector $v^{(k)}$ are sinusoidal in the grid index, consistent with the Dirichlet boundaries. Your derivation should begin from the finite-difference recurrence implied by the eigenvalue equation and should justify the admissible discrete wavenumbers that satisfy the boundary conditions.\n\nFinally, provide the analytic expression for the $k$-th eigenvalue $\\lambda_{k}$ of $\\tilde{\\mathcal{L}}$ as a function of the integers $N \\ge 2$ and $k \\in \\{1,2,\\dots,N\\}$. Express your final answer as a single closed-form symbolic expression. No rounding is required, and no physical units are needed for the dimensionless matrix $\\tilde{\\mathcal{L}}$.",
            "solution": "The problem statement has been validated and is deemed a valid, well-posed problem in numerical analysis, specifically concerning the eigenvalue problem for the one-dimensional discrete Laplacian operator with homogeneous Dirichlet boundary conditions. The problem is self-contained, scientifically grounded, and objective. It is a standard exercise in computational mathematics.\n\nThe task is to find the eigenvalues and eigenvectors of the dimensionless discrete Laplacian matrix $\\tilde{\\mathcal{L}} \\in \\mathbb{R}^{N \\times N}$, whose entries are defined as $\\tilde{\\mathcal{L}}_{j,j} = -2$, $\\tilde{\\mathcal{L}}_{j,j+1} = 1$, and $\\tilde{\\mathcal{L}}_{j,j-1} = 1$. The eigenvalue equation is\n$$\n\\tilde{\\mathcal{L}} v = \\lambda v\n$$\nwhere $\\lambda$ is an eigenvalue and $v$ is the corresponding eigenvector with components $v_j$ for $j \\in \\{1, 2, \\dots, N\\}$.\n\nWriting this matrix equation for the $j$-th component, we obtain a linear recurrence relation:\n$$\n\\tilde{\\mathcal{L}}_{j,j-1} v_{j-1} + \\tilde{\\mathcal{L}}_{j,j} v_j + \\tilde{\\mathcal{L}}_{j,j+1} v_{j+1} = \\lambda v_j\n$$\nSubstituting the matrix elements gives:\n$$\nv_{j-1} - 2v_j + v_{j+1} = \\lambda v_j\n$$\nThis relation holds for $j = 1, 2, \\dots, N$. The problem specifies homogeneous Dirichlet boundary conditions, which in this discrete setting become $v_0 = 0$ and $v_{N+1} = 0$.\n\nWe can rearrange the recurrence relation as:\n$$\nv_{j+1} + v_{j-1} = (2 + \\lambda) v_j\n$$\nThis is a second-order homogeneous linear difference equation with constant coefficients. We seek a solution of the form $v_j = z^j$ for some complex number $z$. Substituting this ansatz into the recurrence yields the characteristic equation:\n$$\nz^{j+1} + z^{j-1} = (2 + \\lambda) z^j\n$$\nDividing by $z^{j-1}$ (for $z \\neq 0$, which must be true for a non-trivial solution), we get:\n$$\nz^2 + 1 = (2 + \\lambda) z\n$$\n$$\nz^2 - (2 + \\lambda)z + 1 = 0\n$$\nThe matrix $\\tilde{\\mathcal{L}}$ is real and symmetric, so its eigenvalues $\\lambda$ are real. Furthermore, as a discrete representation of the second derivative with Dirichlet conditions, its eigenvalues are negative. Specifically, it can be shown that $-4  \\lambda  0$. For this range of $\\lambda$, the term $2+\\lambda$ is in the interval $(-2, 2)$, and the discriminant of the quadratic equation, $\\Delta = (2+\\lambda)^2 - 4$, is negative. The roots for $z$ are therefore a pair of complex conjugates.\n\nLet us define an angle $\\theta$ such that $2 + \\lambda = 2 \\cos(\\theta)$. The characteristic equation becomes:\n$$\nz^2 - 2\\cos(\\theta) z + 1 = 0\n$$\nThe roots are given by the quadratic formula:\n$$\nz = \\frac{2\\cos(\\theta) \\pm \\sqrt{4\\cos^2(\\theta) - 4}}{2} = \\frac{2\\cos(\\theta) \\pm 2i\\sin(\\theta)}{2} = \\cos(\\theta) \\pm i\\sin(\\theta) = e^{\\pm i\\theta}\n$$\nThe general solution for $v_j$ is a linear combination of the two independent solutions corresponding to these roots:\n$$\nv_j = A e^{ij\\theta} + B e^{-ij\\theta}\n$$\nUsing Euler's formula, this can be expressed in terms of sinusoidal functions:\n$$\nv_j = C \\sin(j\\theta) + D \\cos(j\\theta)\n$$\nfor some constants $C$ and $D$.\n\nNow we apply the boundary conditions. The first condition is $v_0 = 0$:\n$$\nv_0 = C \\sin(0 \\cdot \\theta) + D \\cos(0 \\cdot \\theta) = C \\cdot 0 + D \\cdot 1 = D = 0\n$$\nThis forces the coefficient $D$ to be zero, so the solution must be of the form $v_j = C \\sin(j\\theta)$. This demonstrates that the eigenvector components are sinusoidal in the grid index $j$, as requested.\n\nThe second boundary condition is $v_{N+1} = 0$:\n$$\nv_{N+1} = C \\sin((N+1)\\theta) = 0\n$$\nFor a non-trivial eigenvector, we must have $C \\neq 0$. Therefore, the argument of the sine function must be an integer multiple of $\\pi$:\n$$\n(N+1)\\theta = k\\pi, \\quad k \\in \\mathbb{Z}\n$$\nThis quantizes the admissible values of $\\theta$:\n$$\n\\theta_k = \\frac{k\\pi}{N+1}\n$$\nThe components of the $k$-th eigenvector are thus given by:\n$$\nv_j^{(k)} = C \\sin\\left(\\frac{jk\\pi}{N+1}\\right)\n$$\nWe must determine the range of the integer mode index $k$ that produces a complete set of linearly independent eigenvectors.\n- If $k=0$, then $\\theta_0=0$ and $v_j^{(0)} = C\\sin(0) = 0$ for all $j$. This is the trivial vector, not an eigenvector.\n- The indices $j$ run from $1$ to $N$. If $k = N+1$, then $v_j^{(N+1)} = C\\sin(j\\pi) = 0$ for all integer $j$. This is also the trivial vector.\n- For $k \\in \\{1, 2, \\dots, N\\}$, we obtain $N$ non-trivial, linearly independent vectors.\n- For other integer values of $k$, the resulting vectors are not new. For example, for $k' = -k$, $v_j^{(-k)} = C \\sin(-jk\\pi/(N+1)) = -v_j^{(k)}$, which is just a scaling of the $k$-th eigenvector. Similarly, $k' = k+2(N+1)$ yields the same eigenvector since $\\sin(x+2\\pi) = \\sin(x)$.\n\nTherefore, a complete and unique set of $N$ eigenvectors is obtained by taking $k \\in \\{1, 2, \\dots, N\\}$.\n\nFinally, we derive the expression for the eigenvalues $\\lambda_k$. We established the relationship $2 + \\lambda = 2 \\cos(\\theta)$. Substituting the quantized values $\\theta_k$ gives:\n$$\n2 + \\lambda_k = 2\\cos\\left(\\frac{k\\pi}{N+1}\\right)\n$$\n$$\n\\lambda_k = 2\\cos\\left(\\frac{k\\pi}{N+1}\\right) - 2\n$$\nUsing the trigonometric identity $\\cos(2\\alpha) = 1 - 2\\sin^2(\\alpha)$, or equivalently $\\cos(x)-1 = -2\\sin^2(x/2)$, we can rewrite the expression for $\\lambda_k$:\n$$\n\\lambda_k = -2 \\left(1 - \\cos\\left(\\frac{k\\pi}{N+1}\\right)\\right) = -2 \\left(2\\sin^2\\left(\\frac{k\\pi}{2(N+1)}\\right)\\right)\n$$\nThis gives the final closed-form expression for the eigenvalues:\n$$\n\\lambda_k = -4\\sin^2\\left(\\frac{k\\pi}{2(N+1)}\\right)\n$$\nThis is the required analytic expression for the $k$-th eigenvalue of $\\tilde{\\mathcal{L}}$ as a function of $N$ and $k$, for $k \\in \\{1, 2, \\dots, N\\}$.",
            "answer": "$$\\boxed{-4\\sin^2\\left(\\frac{k\\pi}{2(N+1)}\\right)}$$"
        },
        {
            "introduction": "Moving from a simple model to a more realistic astrophysical scenario, we now address the problem of stellar oscillations. The governing equations for small, spherically symmetric pulsations can be formulated as a Sturm-Liouville problem, which leads to a generalized eigenvalue problem of the form $Kx = \\lambda Bx$. This hands-on practice guides you through using the powerful Finite Element Method (FEM) to discretize the continuous operator and numerically assemble the stiffness ($K$) and mass ($B$) matrices, a standard workflow in many areas of computational physics .",
            "id": "3526022",
            "problem": "Consider the generalized self-adjoint Sturm–Liouville eigenvalue problem that models spherically symmetric oscillation modes of a star in one spatial dimension, posed on the interval $\\left[0,R\\right]$,\n$$\n-\\frac{d}{dr}\\left(p(r)\\frac{d\\xi}{dr}\\right) + q(r)\\,\\xi(r) \\;=\\; \\lambda\\, w(r)\\,\\xi(r),\n$$\nwhere $r$ is the radial coordinate, $\\xi(r)$ is the displacement eigenfunction, $\\lambda$ is the eigenvalue, $p(r)$ is a positive stiffness profile, $q(r)$ is a nonnegative restoring profile, and $w(r)$ is a positive weight proportional to the density profile. Impose homogeneous Dirichlet boundary conditions $\\xi(0)=0$ and $\\xi(R)=0$. Assume the following astrophysically plausible profiles:\n$$\np(r) = r^2,\\quad q(r) = \\alpha\\, r^2,\\quad w(r) = r^2\\,\\rho(r),\\quad \\rho(r) = \\rho_c\\left(1 - \\left(\\frac{r}{R}\\right)^2\\right),\n$$\nwith $\\alpha  0$ and $\\rho_c  0$. The weak form on $H_0^1(0,R)$ is: find $\\lambda \\in \\mathbb{R}$ and $\\xi \\neq 0$ such that, for all test functions $\\eta$,\n$$\n\\int_0^R p(r)\\,\\frac{d\\xi}{dr}\\,\\frac{d\\eta}{dr}\\,dr \\;+\\; \\int_0^R q(r)\\,\\xi(r)\\,\\eta(r)\\,dr \\;=\\; \\lambda \\int_0^R w(r)\\,\\xi(r)\\,\\eta(r)\\,dr.\n$$\nDiscretize this weak form using the Finite Element (FE) method with continuous piecewise-linear basis functions on a uniform mesh of $N$ elements over $\\left[0,R\\right]$, enforcing the Dirichlet boundary conditions by eliminating the boundary degrees of freedom at $r=0$ and $r=R$. Assemble the symmetric stiffness matrix $K \\in \\mathbb{R}^{n \\times n}$ and symmetric positive definite mass matrix $B \\in \\mathbb{R}^{n \\times n}$, where $n = N-1$ is the number of interior nodes. Use $3$-point Gauss–Legendre quadrature on each element to evaluate all required integrals. Solve the generalized symmetric eigenvalue problem\n$$\nK\\,x = \\lambda\\,B\\,x,\n$$\nand collect the first $m$ eigenmodes into the mode matrix $X \\in \\mathbb{R}^{n \\times m}$ whose columns are the eigenvectors corresponding to the $m$ smallest eigenvalues.\n\nNormalize the computed eigenmodes with respect to $B$ so that each column $x$ of $X$ satisfies $x^\\top B\\,x = 1$. Then numerically verify $B$-orthogonality by computing\n$$\nM \\;=\\; X^\\top B\\,X,\n$$\nand quantifying the deviation from exact orthonormality in two ways:\n- The maximum absolute off-diagonal magnitude, $s = \\max_{i \\neq j} \\left|M_{ij}\\right|$.\n- The maximum absolute diagonal deviation from unity, $t = \\max_{i} \\left|M_{ii} - 1\\right|$.\n\nYour program must implement this procedure and produce results for the following test suite, each specified by $(N, R, \\rho_c, \\alpha, m)$:\n- Case $A$: $(N, R, \\rho_c, \\alpha, m) = (32, 1, 1, 0.05, 6)$.\n- Case $B$: $(N, R, \\rho_c, \\alpha, m) = (64, 1, 1, 0.0001, 6)$.\n- Case $C$: $(N, R, \\rho_c, \\alpha, m) = (16, 1, 1000, 0.2, 4)$.\n\nFor each case, output the pair $[s, t]$ as real numbers. Your program should produce a single line of output containing the results as a comma-separated list of these pairs, enclosed in square brackets. For example, the required final output format is\n$$\n\\left[ [s_A, t_A], [s_B, t_B], [s_C, t_C] \\right],\n$$\nwhere $[s_A, t_A]$ corresponds to Case $A$, $[s_B, t_B]$ to Case $B$, and $[s_C, t_C]$ to Case $C$. No physical units are required in this problem because all quantities have been nondimensionalized.",
            "solution": "The problem of computing the spherically symmetric oscillation modes of a star is presented as a generalized self-adjoint Sturm–Liouville eigenvalue problem on the interval $\\left[0,R\\right]$. The solution requires discretizing this problem using the Finite Element (FE) method and then numerically solving the resulting matrix eigenvalue problem. The steps are as follows.\n\nFirst, we begin with the weak (or variational) formulation of the problem, which is provided. Find an eigenvalue $\\lambda \\in \\mathbb{R}$ and a non-trivial eigenfunction $\\xi \\in H_0^1(0,R)$ such that for all test functions $\\eta \\in H_0^1(0,R)$:\n$$\na(\\xi, \\eta) = \\lambda\\, b(\\xi, \\eta)\n$$\nwhere the bilinear forms $a(\\cdot, \\cdot)$ and $b(\\cdot, \\cdot)$ are defined as:\n$$\na(\\xi, \\eta) = \\int_0^R p(r)\\,\\frac{d\\xi}{dr}\\,\\frac{d\\eta}{dr}\\,dr \\;+\\; \\int_0^R q(r)\\,\\xi(r)\\,\\eta(r)\\,dr\n$$\n$$\nb(\\xi, \\eta) = \\int_0^R w(r)\\,\\xi(r)\\,\\eta(r)\\,dr\n$$\nThe space $H_0^1(0,R)$ is the Sobolev space of functions with square-integrable first derivatives that vanish at the boundaries $r=0$ and $r=R$. The coefficients are given as $p(r) = r^2$, $q(r) = \\alpha r^2$, and $w(r) = r^2\\rho_c(1-(r/R)^2)$. Since $p(r)0$ for $r \\in (0,R]$, $\\alpha0$, and $\\rho_c0$, the bilinear form $a(\\cdot,\\cdot)$ is symmetric and positive definite, defining an inner product on $H_0^1(0,R)$. Similarly, since $w(r)0$ for $r \\in (0,R)$, $b(\\cdot,\\cdot)$ is also symmetric and positive definite, defining an inner product on $L^2(0,R)$.\n\nSecond, we apply the Finite Element Method. The domain $[0,R]$ is discretized into a uniform mesh of $N$ elements of size $h = R/N$. This creates $N+1$ nodes located at $r_i = i h$ for $i=0, 1, \\dots, N$. The solution $\\xi(r)$ is approximated by a function $\\xi_h(r)$ which is a linear combination of continuous, piecewise-linear basis functions (hat functions) $\\phi_j(r)$:\n$$\n\\xi(r) \\approx \\xi_h(r) = \\sum_{j=1}^{N-1} x_j \\phi_j(r)\n$$\nThe sum runs over the $n = N-1$ interior nodes ($j=1, \\dots, N-1$) because the homogeneous Dirichlet boundary conditions $\\xi(0)=0$ and $\\xi(R)=0$ are enforced by excluding the basis functions $\\phi_0(r)$ and $\\phi_N(r)$ associated with the boundary nodes. The coefficients $x_j$ are the unknown values of the approximate solution at the interior nodes, $\\xi_h(r_j)$.\n\nThird, we employ the Galerkin method, where the test functions $\\eta$ are chosen from the same finite-dimensional space as the trial functions $\\xi_h$. We set $\\eta = \\phi_i(r)$ for each interior basis function $i = 1, \\dots, N-1$. Substituting the approximation $\\xi_h$ and test functions $\\phi_i$ into the weak form yields a system of $n$ linear equations:\n$$\n\\sum_{j=1}^{N-1} a(\\phi_j, \\phi_i) x_j = \\lambda \\sum_{j=1}^{N-1} b(\\phi_j, \\phi_i) x_j \\quad \\text{for } i=1, \\dots, N-1\n$$\nThis is a generalized matrix eigenvalue problem $Kx = \\lambda Bx$, where $x = [x_1, \\dots, x_{N-1}]^\\top$ is the vector of unknown coefficients, and $K$ and $B$ are the global stiffness and mass matrices, respectively. Their entries are given by:\n$$\nK_{ij} = a(\\phi_j, \\phi_i) = \\int_0^R \\left( p(r) \\frac{d\\phi_j}{dr} \\frac{d\\phi_i}{dr} + q(r) \\phi_j(r) \\phi_i(r) \\right) dr\n$$\n$$\nB_{ij} = b(\\phi_j, \\phi_i) = \\int_0^R w(r) \\phi_j(r) \\phi_i(r) dr\n$$\nThese matrices are symmetric, and due to the properties of the bilinear forms, $K$ is positive definite and $B$ is positive definite.\n\nFourth, the integrals for the matrix entries are computed numerically using $3$-point Gauss-Legendre quadrature on each element. The basis functions $\\phi_i$ are non-zero only over at most two adjacent elements, making the matrices $K$ and $B$ sparse (specifically, tridiagonal). For each element $[r_e, r_{e+1}]$, we compute the contributions to the global matrices by evaluating $2 \\times 2$ local matrices. An integral over an element is transformed to the reference interval $[-1,1]$ and approximated as:\n$$\n\\int_{r_e}^{r_{e+1}} f(r) dr \\approx \\frac{h}{2} \\sum_{k=1}^{3} w_k^{\\text{Gauss}} f(r(z_k))\n$$\nwhere $z_k$ and $w_k^{\\text{Gauss}}$ are the quadrature points and weights, and $r(z_k)$ is the corresponding point in the physical element.\n\nFifth, after assembling the $n \\times n$ matrices $K$ and $B$, the generalized symmetric eigenvalue problem $Kx=\\lambda Bx$ is solved for the $m$ smallest eigenvalues and corresponding eigenvectors. This is accomplished using a specialized numerical solver, such as `scipy.linalg.eigh`, which is designed for such problems and returns eigenvalues in ascending order and eigenvectors that are orthonormal with respect to the matrix $B$.\n\nFinally, the computed eigenvectors, which form the columns of the mode matrix $X \\in \\mathbb{R}^{n \\times m}$, are already normalized such that $x^\\top B x = 1$. To verify the numerical accuracy of the $B$-orthogonality, we compute the matrix $M = X^\\top B X$. For exact arithmetic and perfect eigenvectors, $M$ would be the identity matrix. The deviation from this ideal is quantified by two metrics: the maximum absolute off-diagonal magnitude, $s = \\max_{i \\neq j} |M_{ij}|$, and the maximum absolute deviation of the diagonal elements from unity, $t = \\max_i |M_{ii} - 1|$. These values provide a measure of the quality of the computed eigenmodes.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef analyze_modes(N, R, rho_c, alpha, m):\n    \"\"\"\n    Solves the Sturm-Liouville problem using FEM and verifies mode orthogonality.\n\n    Args:\n        N (int): Number of elements.\n        R (float): Radius of the star (domain endpoint).\n        rho_c (float): Central density parameter.\n        alpha (float): Parameter for the q(r) profile.\n        m (int): Number of smallest eigenmodes to compute.\n\n    Returns:\n        tuple[float, float]: A pair [s, t] where s is the max absolute off-diagonal\n                             magnitude and t is the max absolute diagonal deviation.\n    \"\"\"\n    # Number of interior nodes\n    n = N - 1\n    # Element size\n    h = R / N\n\n    # 3-point Gauss-Legendre quadrature points and weights on [-1, 1]\n    z_gauss = np.array([-np.sqrt(3/5), 0, np.sqrt(3/5)])\n    w_gauss = np.array([5/9, 8/9, 5/9])\n\n    # Initialize global stiffness (K) and mass (B) matrices\n    K = np.zeros((n, n))\n    B = np.zeros((n, n))\n\n    # Define coefficient functions based on the problem statement\n    def p(r): return r**2\n    def q(r): return alpha * r**2\n    def w(r): return r**2 * rho_c * (1 - (r/R)**2) if R  0 else 0\n\n    # Assemble matrices element by element\n    for e in range(N):\n        r_e = e * h\n        \n        # Local 2x2 matrices for the current element\n        K_loc = np.zeros((2, 2))\n        B_loc = np.zeros((2, 2))\n        \n        # Integrate over the element using Gauss quadrature\n        for k in range(len(z_gauss)):\n            s_k = z_gauss[k]\n            weight_k = w_gauss[k]\n\n            # Map from reference element [-1, 1] to physical element [r_e, r_{e+1}]\n            r_k = r_e + (1 + s_k) * h / 2\n            jac = h / 2\n            \n            p_val = p(r_k)\n            q_val = q(r_k)\n            w_val = w(r_k)\n            \n            # Hat basis functions and their derivatives on the reference element\n            psi = np.array([(1 - s_k) / 2, (1 + s_k) / 2])\n            dpsi_dr = np.array([-1 / h, 1 / h])\n\n            for i in range(2):\n                for j in range(2):\n                    # Integral for stiffness matrix K\n                    integ_K = p_val * dpsi_dr[i] * dpsi_dr[j] + q_val * psi[i] * psi[j]\n                    K_loc[i, j] += weight_k * integ_K * jac\n                    \n                    # Integral for mass matrix B\n                    integ_B = w_val * psi[i] * psi[j]\n                    B_loc[i, j] += weight_k * integ_B * jac\n    \n        # Assemble local matrices into global matrices, considering only interior nodes\n        # Global matrix indices go from 0 to n-1, corresponding to nodes 1 to N-1\n        \n        # Left node of element 'e' is node 'e'. It is interior if e  0.\n        if e  0:\n            g_idx = e - 1\n            K[g_idx, g_idx] += K_loc[0, 0]\n            B[g_idx, g_idx] += B_loc[0, 0]\n\n        # Right node of element 'e' is node 'e+1'. It is interior if e+1  N.\n        if e  N - 1:\n            g_idx = e  # Corresponds to node e+1, so matrix index is (e+1)-1\n            K[g_idx, g_idx] += K_loc[1, 1]\n            B[g_idx, g_idx] += B_loc[1, 1]\n\n        # Off-diagonal terms if both nodes of the element are interior\n        if e  0 and e  N - 1:\n            g_idx_i = e - 1\n            g_idx_j = e\n            K[g_idx_i, g_idx_j] += K_loc[0, 1]\n            K[g_idx_j, g_idx_i] += K_loc[1, 0]\n            B[g_idx_i, g_idx_j] += B_loc[0, 1]\n            B[g_idx_j, g_idx_i] += B_loc[1, 0]\n\n    # Solve the generalized symmetric eigenvalue problem K*x = lambda*B*x\n    # eigh returns eigenvalues in ascending order and B-orthonormalized eigenvectors\n    eigvals, eigvecs = eigh(K, B)\n    \n    # Collect the first m eigenmodes (eigenvectors)\n    X = eigvecs[:, :m]\n    \n    # Numerically verify B-orthogonality by computing M = X^T * B * X\n    M = X.T @ B @ X\n    \n    # Quantify the deviation from orthonormality\n    # s: maximum absolute off-diagonal magnitude\n    M_off_diag = M.copy()\n    np.fill_diagonal(M_off_diag, 0)\n    s = np.max(np.abs(M_off_diag))\n    \n    # t: maximum absolute diagonal deviation from unity\n    t = np.max(np.abs(np.diag(M) - 1))\n    \n    return s, t\n\ndef solve():\n    # Define the test cases from the problem statement\n    test_cases = [\n        # (N, R, rho_c, alpha, m)\n        (32, 1, 1, 0.05, 6),      # Case A\n        (64, 1, 1, 0.0001, 6),    # Case B\n        (16, 1, 1000, 0.2, 4),    # Case C\n    ]\n\n    results = []\n    for case in test_cases:\n        s, t = analyze_modes(*case)\n        results.append([s, t])\n\n    # Format the final output string as specified\n    formatted_results = [f\"[{s},{t}]\" for s, t in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once a large-scale generalized eigenvalue problem is constructed, the next challenge is to solve it efficiently. This practice focuses on inverse iteration, a powerful iterative method for finding specific eigenmodes, such as the fundamental mode or modes near a particular frequency. You will explore how a physically motivated coordinate transformation, known as mass-matrix scaling, can convert the generalized problem into a standard one, often dramatically improving the numerical conditioning and accelerating the convergence of the solver .",
            "id": "3526012",
            "problem": "Consider small-amplitude, spherically symmetric stellar oscillations under the Cowling approximation, where perturbations do not alter the gravitational potential. The linearized radial equation for the Lagrangian displacement amplitude can be cast, after separation of variables and neglect of angular dependence, into a Sturm–Liouville-type generalized eigenvalue problem of the form $A x = \\lambda B x$, where $A$ is a symmetric positive definite (SPD) stiffness matrix, $B$ is a symmetric positive definite (SPD) mass matrix, $x$ is the discrete eigenfunction, and $\\lambda = \\omega^2$ is the squared angular frequency. The matrices $A$ and $B$ arise from a spatial discretization of the operator $L[y] = -\\frac{d}{dr}\\left(c^2(r) \\frac{d y}{dr}\\right) + V(r) y$ with the weight $W(r) = \\rho(r)$, where $c(r)$ is the adiabatic sound speed, $\\rho(r)$ is the mass density, and $V(r)$ is a positive potential term that models stabilizing stratification influenced by gravity. The radial coordinate $r$ ranges from $r = 0$ to $r = R$, and the boundary conditions are regularity at the center ($y'(0) = 0$) and vanishing displacement at the surface ($y(R) = 0$).\n\nYou will construct $A$ and $B$ on a uniform radial grid using the following physically consistent definitions:\n- Let the stellar radius be $R$ in $\\mathrm{m}$, the central density be $\\rho_c$ in $\\mathrm{kg}\\,\\mathrm{m}^{-3}$, the gravitational constant be $G$ in $\\mathrm{m}^3\\,\\mathrm{kg}^{-1}\\,\\mathrm{s}^{-2}$, and the adiabatic index be $\\Gamma_1$ (unitless).\n- Use a polytropic pressure relation $P(r) = K \\rho(r)^{\\Gamma_1}$ with $K$ chosen such that the central sound speed $c(0) = c_0$ in $\\mathrm{m}\\,\\mathrm{s}^{-1}$, that is $K = \\frac{c_0^2}{\\Gamma_1 \\rho_c^{\\Gamma_1 - 1}}$. Hence $c^2(r) = \\Gamma_1 K \\rho(r)^{\\Gamma_1 - 1}$.\n- Model the density profile by $\\rho(r) = \\rho_c \\max\\left(1 - a \\left(\\frac{r}{R}\\right)^2, \\epsilon_\\rho\\right)$ with $a  0$ (unitless) and a small floor $\\epsilon_\\rho$ in $\\mathrm{kg}\\,\\mathrm{m}^{-3}$ to maintain numerical robustness.\n- Define the enclosed mass $M(r)$ by $M(r) = 4 \\pi \\int_0^r \\rho(s) s^2 \\, ds$ and the stabilizing potential $V(r) = \\beta \\frac{G M(r)}{(r + \\epsilon_r)^3}$ with $\\beta  0$ (unitless) and a small regularization length $\\epsilon_r$ in $\\mathrm{m}$.\n\nUse second-order centered finite differences on $N$ uniform intervals of length $h = \\frac{R}{N}$, with unknowns at the interior nodes $r_i = i h$ for $i = 1, 2, \\dots, N - 1$ (dimension $N - 1$). Construct $A$ from the diffusion term using midpoint conductivities $c^2\\left(r_{i \\pm \\frac{1}{2}}\\right)$ and add the diagonal potential $V(r_i)$. Impose the boundary conditions by treating $i = 1$ with a reflective (Neumann) condition at $r = 0$ and $i = N - 1$ with a Dirichlet condition at $r = R$. Construct $B$ as a diagonal matrix with entries $B_{ii} = \\rho(r_i)$.\n\nYou will implement and compare two inverse iteration schemes to approximate the eigenpair associated with the mode nearest a physically motivated shift:\n- Generalized inverse iteration for $A x = \\lambda B x$ with shift $\\mu$: at iteration $k$, solve $(A - \\mu B) u_{k+1} = B x_k$, then set $x_{k+1} = \\frac{u_{k+1}}{\\|u_{k+1}\\|_B}$ where $\\|u\\|_B = \\sqrt{u^\\top B u}$, and update the Rayleigh quotient $\\lambda_{k+1} = \\frac{x_{k+1}^\\top A x_{k+1}}{x_{k+1}^\\top B x_{k+1}}$.\n- Scaled inverse iteration in mass-normalized coordinates using the diagonal scaling $S = B^{-1/2}$ so that $C = S A S$ defines a standard eigenproblem $C z = \\lambda z$: at iteration $k$, solve $(C - \\mu I) z_{k+1} = z_k$, then normalize $z_{k+1} = \\frac{z_{k+1}}{\\|z_{k+1}\\|_2}$, compute $\\lambda_{k+1} = \\frac{z_{k+1}^\\top C z_{k+1}}{z_{k+1}^\\top z_{k+1}}$, and form the physical-space iterate $x_{k+1} = S z_{k+1}$ to assess the residual in the original variables.\n\nBoth schemes must use the same shift $\\mu$ defined by a frequency-scale estimate based on the mean sound speed $\\bar{c}$ and the global length scale $R$: $\\mu = \\kappa \\left(\\frac{\\pi \\bar{c}}{R}\\right)^2$, where $\\kappa$ is a unitless factor strictly between $0$ and $1$. Initialize $x_0$ deterministically by $x_0(i) = \\sin\\left(\\pi \\frac{r_i}{R}\\right)$ and set $z_0 = \\frac{S^{-1} x_0}{\\|S^{-1} x_0\\|_2}$. Use a stopping criterion based on the relative residual $\\frac{\\|A x - \\lambda B x\\|_2}{\\|A\\|_2}$ falling below a tolerance $\\varepsilon$, with a hard cap of $K_{\\max}$ iterations. Note that this residual is evaluated in the original unscaled variables for both methods, and $\\|A\\|_2$ denotes the spectral norm.\n\nThe aim is to demonstrate that physically motivated rescaling and mass normalization cluster the effective scales of the operator and improve the conditioning of the shifted linear solves, thereby accelerating convergence of inverse iteration. You will measure the improvement by the difference in iterations to convergence between the unscaled and the scaled method.\n\nImplement a complete program that:\n- Builds $A$ and $B$ according to the above discretization and physical definitions.\n- Runs both inverse iteration variants with the same shift $\\mu$, tolerance $\\varepsilon$, and iteration cap $K_{\\max}$.\n- Reports, for each test case, the integer difference $\\Delta k = k_{\\text{unscaled}} - k_{\\text{scaled}}$, where $k_{\\text{unscaled}}$ and $k_{\\text{scaled}}$ are the number of iterations taken to satisfy the stopping criterion.\n\nUse the following physical constants and parameters, expressed in International System of Units (SI) where appropriate:\n- $R = 6.96 \\times 10^8$ in $\\mathrm{m}$.\n- $\\rho_c = 1.50 \\times 10^5$ in $\\mathrm{kg}\\,\\mathrm{m}^{-3}$.\n- $G = 6.67430 \\times 10^{-11}$ in $\\mathrm{m}^3\\,\\mathrm{kg}^{-1}\\,\\mathrm{s}^{-2}$.\n- $\\Gamma_1 = \\frac{5}{3}$ (unitless).\n- $c_0 = 5.00 \\times 10^5$ in $\\mathrm{m}\\,\\mathrm{s}^{-1}$.\n- $\\epsilon_\\rho = 1.00$ in $\\mathrm{kg}\\,\\mathrm{m}^{-3}$.\n- $\\epsilon_r = 1.00 \\times 10^3$ in $\\mathrm{m}$.\n- $\\kappa = 0.90$ (unitless).\n- $\\varepsilon = 1.00 \\times 10^{-8}$ (unitless).\n- $K_{\\max} = 100$ (unitless).\n\nProvide a test suite with the following parameter triplets $(N, a, \\beta)$:\n- Case $1$: $(128, 1.00, 0.02)$ is the general \"happy path\".\n- Case $2$: $(64, 1.00, 0.02)$ is a coarse-resolution boundary case.\n- Case $3$: $(256, 1.50, 0.02)$ is a high-contrast edge case stressing conditioning.\n- Case $4$: $(128, 0.20, 0.00)$ is a nearly uniform density case with no stabilizing potential.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the exact order of the cases above, for example, $\"[d_1,d_2,d_3,d_4]\"$, where each $d_i$ is the integer $\\Delta k$ for case $i$.",
            "solution": "The user provides a valid problem statement. It is scientifically grounded in the theory of stellar oscillations, specifically in the context of numerical asteroseismology. It is well-posed, describing a generalized eigenvalue problem for which a solution is sought using a standard iterative method (inverse iteration). The problem statement is objective, complete, and formalizable. All constants, parameters, and algorithmic definitions are provided, allowing for a deterministic and verifiable solution.\n\nThe core of the problem is to construct and solve the generalized eigenvalue problem $A x = \\lambda B x$, which models spherically symmetric stellar oscillations. We will first construct the matrices $A$ and $B$ based on a finite-difference discretization of the governing differential operator on a uniform radial grid. Subsequently, we will implement and compare two variants of the inverse iteration algorithm to find the eigenmode closest to a specified frequency shift, $\\mu$.\n\n### Step 1: Discretization and Matrix Construction\n\nThe problem is defined on a radial grid with $N$ uniform intervals of size $h = R/N$. The unknowns are the displacement amplitudes $y_i$ at the interior nodes $r_i = i h$ for $i = 1, 2, \\dots, N - 1$. The dimension of the system is $d = N - 1$. We will use zero-based indexing for arrays in the implementation, so the vector of unknowns $x$ of size $d$ corresponds to $y_1, \\dots, y_{N-1}$.\n\n**Physical Profiles:**\nFirst, we define the physical quantities as functions of the radial coordinate $r$:\n1.  **Polytropic Constant $K$**: The sound speed at the center $c(0) = c_0$ is used to set the constant $K$ in the polytropic pressure-density relation $P = K \\rho^{\\Gamma_1}$. The squared sound speed is $c^2 = \\frac{\\Gamma_1 P}{\\rho} = \\Gamma_1 K \\rho^{\\Gamma_1-1}$. At the center, $c_0^2 = \\Gamma_1 K \\rho_c^{\\Gamma_1-1}$, which gives $K = \\frac{c_0^2}{\\Gamma_1 \\rho_c^{\\Gamma_1-1}}$.\n2.  **Density $\\rho(r)$**: The density profile is given by $\\rho(r) = \\max(\\rho_c (1 - a(r/R)^2), \\epsilon_\\rho)$.\n3.  **Sound Speed $c^2(r)$**: $c^2(r) = \\Gamma_1 K \\rho(r)^{\\Gamma_1 - 1}$.\n4.  **Enclosed Mass $M(r)$**: This requires integrating the density profile: $M(r) = 4\\pi \\int_0^r \\rho(s) s^2 ds$. Let $r_t$ be the transition radius where $\\rho_c (1 - a(r_t/R)^2) = \\epsilon_\\rho$. This occurs at $r_t = R \\sqrt{(1 - \\epsilon_\\rho/\\rho_c)/a}$ if the argument of the square root is positive; otherwise, the transition does not occur within the star. The integral is evaluated piecewise.\n    For $r \\le r_t$: $M(r) = 4\\pi \\rho_c (r^3/3 - a r^5/(5R^2))$.\n    For $r  r_t$: $M(r) = M(r_t) + 4\\pi \\epsilon_\\rho (r^3 - r_t^3)/3$.\n5.  **Potential $V(r)$**: This term is given by $V(r) = \\beta \\frac{G M(r)}{(r + \\epsilon_r)^3}$.\n\n**Mass Matrix $B$:**\nThe mass matrix $B$ is a diagonal matrix of dimension $d \\times d$ with entries $B_{ii} = \\rho(r_{i+1})$, for $i=0, \\dots, d-1$. This represents a lumped-mass approximation from the term $\\lambda \\rho(r) y$ in the differential equation.\n\n**Stiffness Matrix $A$:**\nThe stiffness matrix $A$ is derived from a second-order centered finite-difference discretization of the operator $L[y] = -\\frac{d}{dr}(c^2(r) \\frac{dy}{dr}) + V(r)y$.\nA general interior node $r_i$ (with $1  i  N-1$) gives the stencil:\n$$ (L[y])_i \\approx \\frac{1}{h^2} \\left[ -c^2(r_{i-1/2}) y_{i-1} + (c^2(r_{i-1/2}) + c^2(r_{i+1/2})) y_i - c^2(r_{i+1/2}) y_{i+1} \\right] + V(r_i) y_i $$\nThis defines the tridiagonal entries of $A$. The matrix must be symmetric, as guaranteed by the self-adjoint nature of the operator $L$.\nThe boundary conditions are $y'(0)=0$ (regularity at the center) and $y(R)=0$ (vanishing displacement at the surface).\n-   **Dirichlet condition at $r=R$**: For the last unknown $y_{N-1}$, the stencil involves $y_N$. Setting $y_N=0$ correctly truncates the matrix. The row for $y_{N-1}$ is: $\\dots -c^2(r_{N-3/2})y_{N-2} + (c^2(r_{N-3/2}) + c^2(r_{N-1/2}))y_{N-1}$.\n-   **Neumann condition at $r=0$**: The problem states to treat node $i=1$ with a reflective condition. To ensure the resulting matrix $A$ is symmetric and positive-definite, we must use a consistent discretization. A common, if not the most accurate, approach that maintains these properties is to approximate the derivative condition $y'(0)=0$ with a first-order forward difference, $\\frac{y_1-y_0}{h}=0$, implying $y_0 = y_1$. Substituting $y_0=y_1$ into the stencil for $y_1$:\n$$ (L[y])_1 \\approx \\frac{1}{h^2} \\left[ -c^2(r_{1/2}) y_0 + (c^2(r_{1/2}) + c^2(r_{3/2})) y_1 - c^2(r_{3/2}) y_2 \\right] + V(r_1) y_1 $$\n$$ \\approx \\frac{1}{h^2} \\left[ (-c^2(r_{1/2}) + c^2(r_{1/2}) + c^2(r_{3/2})) y_1 - c^2(r_{3/2}) y_2 \\right] + V(r_1) y_1 $$\n$$ = \\frac{1}{h^2} \\left[ c^2(r_{3/2}) y_1 - c^2(r_{3/2}) y_2 \\right] + V(r_1) y_1 $$\nThis discretization, while simple, yields a symmetric matrix that is positive-definite, consistent with the problem's premises. The resulting matrix $A$ is constructed as follows (using 0-based index $j=0, \\dots, d-1$):\n-   Off-diagonal entries: $A_{j, j+1} = A_{j+1, j} = -c^2(r_{j+3/2}) / h^2$.\n-   Diagonal entries: $A_{j,j} = (c^2(r_{j+1/2}) + c^2(r_{j+3/2}))/h^2 + V(r_{j+1})$ for $j  0$.\n-   First diagonal entry: $A_{0,0} = c^2(r_{3/2})/h^2 + V(r_1)$.\n-   Last diagonal entry: $A_{d-1,d-1} = (c^2(r_{d-1/2}) + c^2(r_{d+1/2}))/h^2 + V(r_d)$.\n\n### Step 2: Inverse Iteration Algorithms\n\nWe implement two inverse iteration schemes to find the eigenpair $(\\lambda, x)$ where $\\lambda$ is closest to a given shift $\\mu$. The shift is $\\mu = \\kappa (\\pi \\bar{c}/R)^2$, where $\\bar{c}$ is the root-mean-square average of the sound speed over the interior grid nodes. The initial guess for the eigenvector is $x_0(i) = \\sin(\\pi r_i/R)$. Iterations stop when the relative residual $\\frac{\\|A x - \\lambda B x\\|_2}{\\|A\\|_2}$ is less than $\\varepsilon=10^{-8}$, or after $K_{\\max}=100$ iterations.\n\n**Method 1: Generalized Inverse Iteration (unscaled)**\nThe iteration procedure is:\n1.  Initialize $x_0 \\leftarrow x_0 / \\sqrt{x_0^\\top B x_0}$.\n2.  For $k=0, 1, 2, \\dots$:\n    a. Solve $(A - \\mu B) u_{k+1} = B x_k$ for $u_{k+1}$.\n    b. Normalize: $x_{k+1} = u_{k+1} / \\sqrt{u_{k+1}^\\top B u_{k+1}}$.\n    c. Compute Rayleigh quotient: $\\lambda_{k+1} = x_{k+1}^\\top A x_{k+1}$.\n    d. Check for convergence.\n\n**Method 2: Scaled Inverse Iteration**\nThis method transforms the generalized problem into a standard one. Let $S=B^{-1/2}$, which is a diagonal matrix with entries $1/\\sqrt{\\rho(r_i)}$. The transformed problem is $C z = \\lambda z$, where $C = S A S$ and $z = S^{-1} x$.\nThe iteration procedure is:\n1.  Initialize $z_0 = S^{-1} x_0$, and then $z_0 \\leftarrow z_0 / \\|z_0\\|_2$.\n2.  For $k=0, 1, 2, \\dots$:\n    a. Solve $(C - \\mu I) u_{k+1} = z_k$ for $u_{k+1}$.\n    b. Normalize: $z_{k+1} = u_{k+1} / \\|u_{k+1}\\|_2_$.\n    c. Compute Rayleigh quotient: $\\lambda_{k+1} = z_{k+1}^\\top C z_{k+1}$.\n    d. Convert back to physical-space eigenfunction: $x_{k+1} = S z_{k+1}$.\n    e. Check for convergence using the residual in original variables.\n\nThe transformation to the standard eigenproblem is expected to improve the conditioning of the linear system solved at each step, especially for density profiles with high contrast, leading to faster convergence. The final output is the difference in iteration counts, $\\Delta k = k_{\\text{unscaled}} - k_{\\text{scaled}}$.",
            "answer": "```python\nimport numpy as np\nimport scipy.linalg\n\ndef solve():\n    # Physical constants in SI units\n    R = 6.96e8  # m\n    RHO_C = 1.50e5  # kg*m^-3\n    G = 6.67430e-11  # m^3*kg^-1*s^-2\n    GAMMA_1 = 5.0 / 3.0\n    C0 = 5.00e5  # m*s^-1\n    EPSILON_RHO = 1.00  # kg*m^-3\n    EPSILON_R = 1.00e3  # m\n    KAPPA = 0.90\n    TOLERANCE = 1.00e-8\n    K_MAX = 100\n\n    # Polytropic constant K\n    K_CONST = C0**2 / (GAMMA_1 * RHO_C**(GAMMA_1 - 1))\n\n    # Test cases (N, a, beta)\n    test_cases = [\n        (128, 1.00, 0.02),\n        (64, 1.00, 0.02),\n        (256, 1.50, 0.02),\n        (128, 0.20, 0.00),\n    ]\n\n    results = []\n    for N, a, beta in test_cases:\n        # --- 1. Setup Grid and Physical Profiles ---\n        h = R / N\n        # Interior nodes r_1, ..., r_{N-1}\n        # Corresponds to python index 0, ..., N-2\n        r_nodes = h * np.arange(1, N) \n        # Midpoint nodes r_1/2, ..., r_{N-1/2}\n        # Corresponds to python index 0, ..., N-1\n        r_midpoints = h * (np.arange(0, N) + 0.5)\n\n        def rho(r_vec):\n            return np.maximum(RHO_C * (1 - a * (r_vec / R)**2), EPSILON_RHO)\n\n        def c2(r_vec):\n            # Avoid divide by zero if rho is zero, though epsilon_rho should prevent this.\n            return GAMMA_1 * K_CONST * rho(r_vec)**(GAMMA_1 - 1)\n\n        def M(r_vec):\n            # The vectorized calculation of enclosed mass.\n            m_vals = np.zeros_like(r_vec, dtype=float)\n            \n            # Find transition radius r_t\n            if a  (1 - EPSILON_RHO / RHO_C):\n                r_t = R * np.sqrt((1 - EPSILON_RHO/RHO_C) / a)\n            else: # Transition does not occur within [0, R)\n                r_t = R + 1.0 \n\n            # Part 1: r = r_t\n            mask1 = r_vec = r_t\n            r1 = r_vec[mask1]\n            m_vals[mask1] = 4 * np.pi * RHO_C * (r1**3 / 3 - a * r1**5 / (5 * R**2))\n\n            # Part 2: r  r_t\n            mask2 = r_vec  r_t\n            if np.any(mask2):\n                r2 = r_vec[mask2]\n                m_rt = 4 * np.pi * RHO_C * (r_t**3 / 3 - a * r_t**5 / (5 * R**2))\n                m_vals[mask2] = m_rt + 4 * np.pi * EPSILON_RHO * (r2**3 - r_t**3) / 3\n            \n            return m_vals\n\n        def V(r_vec):\n            if beta == 0.0:\n                return np.zeros_like(r_vec)\n            return beta * G * M(r_vec) / (r_vec + EPSILON_R)**3\n\n        # --- 2. Build Matrices A and B ---\n        dim = N - 1\n        A = np.zeros((dim, dim))\n        B = np.zeros((dim, dim))\n\n        rho_nodes = rho(r_nodes)\n        c2_mid = c2(r_midpoints)\n        V_nodes = V(r_nodes)\n\n        # Mass matrix B\n        np.fill_diagonal(B, rho_nodes)\n\n        # Stiffness matrix A\n        h2 = h**2\n        \n        # Fill tridiagonal entries for rows 1 to N-2 (0-based index)\n        # This covers i=1..dim-2, i.e. r_2 to r_{N-2}\n        for i in range(1, dim - 1):\n            A[i, i-1] = -c2_mid[i] / h2\n            A[i, i]   = (c2_mid[i] + c2_mid[i+1]) / h2 + V_nodes[i]\n            A[i, i+1] = -c2_mid[i+1] / h2\n\n        # First row (i=0, for r_1) with Neumann BC y'(0)=0\n        if dim  1:\n            A[0, 0] = c2_mid[1] / h2 + V_nodes[0]\n            A[0, 1] = -c2_mid[1] / h2\n            A[1, 0] = -c2_mid[1] / h2 # Symmetry\n\n        # Last row (i=dim-1, for r_{N-1}) with Dirichlet BC y(R)=0\n        if dim  0:\n            A[dim-1, dim-1] = (c2_mid[dim-1] + c2_mid[dim]) / h2 + V_nodes[dim-1]\n        if dim  1:\n            A[dim-1, dim-2] = -c2_mid[dim-1] / h2\n            \n        # Case for dim=1 (N=2)\n        if dim == 1:\n            A[0,0] = (c2_mid[0] + c2_mid[1])/h2 + V_nodes[0]\n\n\n        # --- 3. Iterative Solvers ---\n        c_nodes_sq = c2(r_nodes)\n        c_mean_sq = np.mean(c_nodes_sq)\n        mu = KAPPA * (np.pi * np.sqrt(c_mean_sq) / R)**2\n        \n        x0 = np.sin(np.pi * r_nodes / R)\n        A_norm = scipy.linalg.norm(A, 2)\n\n        # Method 1: Unscaled\n        k_unscaled = K_MAX\n        try:\n            x = x0 / np.sqrt(x0.T @ B @ x0)\n            shift_matrix = A - mu * B\n            for k in range(1, K_MAX + 1):\n                b_vec = B @ x\n                u = np.linalg.solve(shift_matrix, b_vec)\n                norm_u_B = np.sqrt(u.T @ B @ u)\n                if norm_u_B == 0: break\n                x = u / norm_u_B\n                lambda_ = x.T @ A @ x\n                residual = np.linalg.norm(A @ x - lambda_ * B @ x, 2) / A_norm\n                if residual  TOLERANCE:\n                    k_unscaled = k\n                    break\n        except np.linalg.LinAlgError:\n            k_unscaled = K_MAX\n\n        # Method 2: Scaled\n        k_scaled = K_MAX\n        try:\n            B_diag = np.diag(B)\n            S_diag = 1.0 / np.sqrt(B_diag)\n            S_inv_diag = np.sqrt(B_diag)\n            S = np.diag(S_diag)\n            S_inv = np.diag(S_inv_diag)\n            \n            C = S @ A @ S\n            \n            z0 = S_inv @ x0\n            z = z0 / np.linalg.norm(z0, 2)\n            \n            shift_C_matrix = C - mu * np.identity(dim)\n\n            for k in range(1, K_MAX + 1):\n                z_next = np.linalg.solve(shift_C_matrix, z)\n                norm_z_next = np.linalg.norm(z_next, 2)\n                if norm_z_next == 0: break\n                z = z_next / norm_z_next\n                lambda_ = z.T @ C @ z\n                x = S @ z\n                residual = np.linalg.norm(A @ x - lambda_ * B @ x, 2) / A_norm\n                if residual  TOLERANCE:\n                    k_scaled = k\n                    break\n        except np.linalg.LinAlgError:\n            k_scaled = K_MAX\n            \n        results.append(k_unscaled - k_scaled)\n\n    # --- 4. Final Output ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}