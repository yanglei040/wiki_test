## 引言
在一个不断提供新信息的世界里，一个系统如何才能在不被自身历史数据淹没的情况下进行实时学习和适应？这个基本问题是现代控制和信号处理的核心。传统方法可能在每次获得新观测值时都重新分析所有过去的数据——这是一种低效且通常不切实际的方法——但对于在线参数估计，存在一种更为优雅的解决方案。递推最小二乘（RLS）算法为新数据到来时动态更新模型提供了一个强大的框架。本文将揭开这一基本工具的神秘面纱。首先，在“原理与机制”一章中，我们将剖析该算法的核心递推结构，探究增益向量、协方差矩阵的直观作用，以及使其能够跟踪变化系统的关键——[遗忘因子](@entry_id:175644)。随后，“应用与跨学科联系”一章将展示 RLS 惊人的通用性，从工程领域的[系统辨识](@entry_id:201290)和自适应控制，到其与[估计理论](@entry_id:268624)的其他基石（如卡尔曼滤波器）之间深刻的理论联系。

## 原理与机制

想象一下，你正试图学习一条新的自然法则。你心中有一个简单的模型——也许是像“效应 = 参数 × 原因”这样的关系，或者用数学术语表示为 $y = \theta x$。然而，宇宙并不会直接把规则手册交给你。相反，它会逐一为你提供一连串的例子：一个原因 $x_1$ 产生一个效应 $y_1$，然后一个原因 $x_2$ 产生一个效应 $y_2$，依此类推。你的任务是随着每一条新证据的出现，不断完善你对未知参数 $\theta$ 的猜测。

一种直接但相当粗暴的方法是，在每个新数据点到来时，收集你到目前为止看到的所有数据，然后每一次都执行一次全面的最小二乘分析。这就像每次增加一页新内容时，都要重读整个图书馆的书籍。这种方法可行，但效率极低。自然界和优秀的工程设计都偏爱更优雅的解决方案：一种能够随时更新知识的方法。这正是**递推最小二乘（RLS）**的精神所在。

### 从蛮力到优雅：核心递推

RLS 算法始于一个极其简单的想法。我们不再平等地对待所有过去的观测数据，而是给予最近的事件更大的权重。如果我们怀疑系统的潜在“规则”可能会随时间缓慢变化，例如[化学反应器](@entry_id:204463)中的催化剂会降解，那么这种方法就特别有用[@problem_id:1582112]。我们可以通过寻找在时刻 $t$ 最小化加权平方误差和的参数向量 $\theta_t$ 来将此想法形式化：

$$
J_t(\theta) = \sum_{i=1}^t \lambda^{t-i} (y_i - x_i^\top \theta)^2
$$

这里，$(y_i, x_i)$ 是时刻 $i$ 的数据对，而 $\lambda$ 是**[遗忘因子](@entry_id:175644)**，一个介于 0 和 1 之间的数。如果 $\lambda=1$，所有数据的权重都相等。如果 $\lambda  1$，过去数据的影响会呈指数级衰减。一个来自 $k$ 步之前的观测值的重要性只有我们刚刚收到的观测值的 $\lambda^k$ 倍。

RLS 的精妙之处在于，我们不需要在每一步都解决整个求和问题。通过一些数学技巧（涉及一个称为[矩阵求逆](@entry_id:636005)引理的工具），我们可以推导出一个递推更新公式。最终的算法结构恰好反映了学习过程本身 [@problem_id:3223354] [@problem_id:2850229]：

$$
\hat{\theta}_t = \hat{\theta}_{t-1} + K_t (y_t - x_t^\top \hat{\theta}_{t-1})
$$

让我们来解读这个公式。它表明我们的**新估计值**（$\hat{\theta}_t$）就是我们的**旧估计值**（$\hat{\theta}_{t-1}$）加上一个修正项。括号中的项 $e_t = y_t - x_t^\top \hat{\theta}_{t-1}$ 是**[预测误差](@entry_id:753692)**。它是实际发生的情况（$y_t$）与我们旧模型预测会发生的情况（$x_t^\top \hat{\theta}_{t-1}$）之间的差异。如果我们的预测是完美的，误差为零，我们就不改变估计值。但如果存在误差，我们就会进行调整。

真正的魔力在于 $K_t$ 这一项，即**增益向量**。它是算法的“智能”部分。它不仅告诉我们要改变估计值，还告诉我们应该根据误差做出*多大*的改变以及朝哪个*方向*改变。那么，是什么决定了这个关键的增益呢？

### 运算的大脑：[置信度](@entry_id:267904)与[协方差矩阵](@entry_id:139155)

增益向量 $K_t$ 不是一个固定的常数；它在每一步都会动态计算。它的值取决于两件事：新的输入数据 $x_t$ 和一个被称为**[协方差矩阵](@entry_id:139155)**的神秘对象 $P_t$。让我们抛开形式主义，不要把 $P_t$ 看作一个矩阵，而是看作我们对当前估计值 $\hat{\theta}_t$ 的**不确定性**的表示，或者反过来说，是我们对它的**[置信度](@entry_id:267904)**。一个“大”的 $P_t$ 意味着我们对估计值的置信度低（不确定性高），而一个“小”的 $P_t$ 则意味着我们非常自信。

增益向量的计算公式为：

$$
K_t = \frac{P_{t-1} x_t}{\lambda + x_t^\top P_{t-1} x_t}
$$

看分子部分：增益 $K_t$ 与 $P_{t-1}$ 成正比。这非常直观。如果我们的不确定性高（$P_{t-1}$ 大），增益就会很大，我们将根据新数据进行显著的修正。如果我们的不确定性低（$P_{t-1}$ 小），增益就会很小，我们将固执地更接近旧的估计值，把新的误差看作可能只是一点噪声。

我们初始置信度的影响是显著的，在一个我们从零估计开始的简单场景中可以清楚地看到 [@problem_id:1588640]。如果我们用一个巨大的[协方差矩阵](@entry_id:139155)来初始化算法，比如 $P_0 = 1000 \cdot I$，我们实际上是在告诉它：“我完全不知道真实参数是什么。” 第一个数据点就会导致一个巨大的增益和对我们估计值的大幅更新。相反，如果我们从一个很小的协方差矩阵开始，$P_0 = 0.01 \cdot I$，我们就是在说：“我对我的初始猜测已经相当确定了。” 算法将会非常保守，第一次更新将是微不足道的。这个初始协[方差](@entry_id:200758) $P_0$ 是我们向系统中注入先验信念（或缺乏信念）的工具。

随着每次更新，不仅我们的参数估计值 $\hat{\theta}$ 会改变，我们的不确定性矩阵 $P$ 也会改变。更新规则是：

$$
P_t = \frac{1}{\lambda} (I - K_t x_t^\top) P_{t-1}
$$

$(I - K_t x_t^\top) P_{t-1}$ 这一项表明，整合来自新数据点的信息会降低我们的不确定性，使矩阵 $P$ 变小（至少在由 $x_t$ 提供信息的方向上）。

### 追踪变化的世界：遗忘的艺术

如果世界是静止的，我们可以设置 $\lambda=1$，并观察我们的不确定性 $P_t$ 随着收集越来越多的数据而趋向于零，最终收敛到“真实”参数。但如果世界本身在变化呢？如果我们试图估计的参数正在缓慢漂移呢？[@problem_id:1582112] 如果我们的算法变得过于自信，它将停止听取新数据，从而无法跟踪这些变化。

这就是**[遗忘因子](@entry_id:175644)** $\lambda  1$ 变得至关重要的地方。通过在每一步乘以 $1/\lambda$（一个大于 1 的数），我们人为地增加了我们的不确定性，防止它完全消失。这使得增益 $K_t$ 不会变为零，确保算法保持“警觉”并对新信息做出响应。

$\lambda$ 的选择是一个微妙的平衡行为——一个在敏捷性和稳定性之间的基本权衡。我们可以通过将 $\lambda$ 与**有效记忆长度**联系起来，使其更具体 [@problem_id:1588615]。这个记忆长度的一个常用且有用的近似值是 $N_{eff} \approx \frac{1}{1-\lambda}$。

-   像 $\lambda = 0.9$ 这样的“快速遗忘”值，其记忆长度大约为 $N_{eff} \approx 10$ 个样本。估计器将非常敏捷，能迅速对系统变化做出反应。然而，它也会对随机[测量噪声](@entry_id:275238)非常敏感，导致[参数估计](@entry_id:139349)值[抖动](@entry_id:200248)，并可能引起不稳定的控制行为 [@problem_id:1608448]。

-   像 $\lambda = 0.999$ 这样的“慢速遗忘”值，其记忆长度大约为 $N_{eff} \approx 1000$ 个样本。通过对长历史数据进行平均，估计器会产生非常平滑、抗噪声的参数值。缺点是它对系统参数的真实漂移反应会非常慢，其估计值可能会持续滞后于真实值。

这简而言之就是经典的**[偏差-方差权衡](@entry_id:138822)**。小的 $\lambda$ 产生低偏差（能很好地跟踪变化），但[方差](@entry_id:200758)高（噪声大）。大的 $\lambda$ 产生低[方差](@entry_id:200758)（平滑），但可能有高偏差（滞后于变化）。正确的选择完全取决于应用：你期望系统变化多快，以及你的测量噪声有多大？

### 自满的危险：RLS 的失效模式

就像任何强大的工具一样，RLS 并非没有缺陷。了解其失效模式与了解其工作原理同样重要。这些不仅仅是数学上的奇特现象；它们代表了可能导致复杂控制系统灾难性失败的真实世界现象。

#### 无聊生活的危险：[持续激励](@entry_id:263834)

想象一个自校正调节器正在控制一个熔炉的温度。它工作得非常好，以至于温度变得完全恒定。为了维持这种状态，控制器的输出也变得几乎恒定。系统进入了一个长时间的安静、稳定运行阶段 [@problem_id:1608479]。我们的 RLS 估计器会发生什么？

由系统输入和输出构成的回归向量 $x_t$ 变得几乎恒定。它不再以一种能够“探测”未知参数向量 $\theta$ 所有不同维度的方式变化。这种缺乏丰富、[信息量](@entry_id:272315)大的输入的情况被称为**[持续激励](@entry_id:263834)（PE）**的丧失 [@problem_id:2891027]。为了了解一个 $M$ 维的参数向量，输入信号必须随着时间的推移探索所有 $M$ 个维度。例如，单个[正弦波](@entry_id:274998)永远只能揭示两个维度的信息，这对于辨识一个阶数 $M>2$ 的系统是不够的。

当[持续激励](@entry_id:263834)丧失并且我们使用[遗忘因子](@entry_id:175644) $\lambda  1$ 时，一个称为**[协方差膨胀](@entry_id:635604)**的危险现象就会发生 [@problem_id:1608444]。在不再被输入激励的方向上，算法没有接收到任何新信息。然而，由于 $1/\lambda$ 这一项，它被告知要“忘记”它从未真正拥有过的信息！结果是，不确定性矩阵 $P_t$ 在这些未被激励的方向上开始无界增长。算法对其一无所知的事情变得极度自信。

然后，灾难降临。一个突然的扰动冲击了系统。输入 $x_t$ 现在在某个之前未被激励的方向上有了分量。RLS 算法带着一个被极度放大的 $P_{t-1}$，计算出一个巨大的增益 $K_t$，并对参数施加一个巨大而狂野的修正。这被称为**参数爆发现象**。已经稳定了数小时的估计值突然爆炸，控制器模型变得毫无意义，系统可能被推向不稳定。

为了防止估计器“睡着”并屈服于这种脆弱性，实际应用中通常会采取一些对策。一种方法是向系统中注入一个小的随机“[抖动](@entry_id:200248)”信号，以保证它永远不会变得完全静止。一个更直接的修复方法是通过**协[方差](@entry_id:200758)注入**来修改 RLS 算法本身：在每一步，向协[方差](@entry_id:200758)更新中添加一个小的、恒定的正定矩阵 $Q$。这就像告诉算法：“无论你感觉多确定，都要始终保持最低限度的怀疑。” 它为不确定性设置了一个下限，防止[协方差膨胀](@entry_id:635604)并保持估计器的响应能力 [@problem_id:1608437]。

#### 听到幻听：[有色噪声](@entry_id:265434)问题

标准的 RLS 算法建立在一个关键假设之上：任何未测量的噪声或扰动都是“白”的，意味着它是随机且在时间上不相关的，就像收音机电台之间的静电噪音一样。但如果噪声有模式呢？如果扰动是来自空调机组的缓慢、周期性的气流呢？[@problem_id:1608430]

这种类型的扰动被称为**[有色噪声](@entry_id:265434)**。问题在于，噪声信号可能与回归向量 $x_t$ 相关联，特别是当 $x_t$ 包含系统输出的过去测量值时（几乎总是如此）。算法无法区分真实系统的动态特性和噪声的动态特性。它尽职地试图找到一个能解释它所看到的一切的模型。

其后果是[参数估计](@entry_id:139349)将是**有偏的**。它们会收敛，但会收敛到错误的值。算法将学到一个复合模型，该模型错误地将真实系统动态与[相关噪声](@entry_id:137358)的虚假动[态混合](@entry_id:148060)在一起。这揭示了一个深刻的真理：我们的模型的好坏取决于我们对它们试图描述的世界所做的假设。

