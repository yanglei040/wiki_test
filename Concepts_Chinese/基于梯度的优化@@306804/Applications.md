## 应用与跨学科联系

我们花了一些时间来理解基于梯度的优化机制——这个优雅、近乎欺骗性地简单的思想，即通过在最陡峭的下降方向上迈出小步来找到谷底。我们看到了挑战：布满局部最小值的险峻地形、病态问题的令人眩晕的悬崖，以及可能隐藏路径的噪声迷雾。现在，我们准备好迎接有趣的部分了。我们将踏上横跨现代科学与工程领域的旅程，亲眼见证这同一个思想的实际应用。您将会为其多功能性感到惊讶。指导人工智能心智训练的同一罗盘，可以用来塑造一座桥梁、为一份金融合约定价、发现一个[化学反应](@entry_id:146973)的路径，甚至驾驭一台[量子计算](@entry_id:142712)机。这不是巧合；这是一个关于模型世界统一性的深刻宣言，也是一个关于让事物变得*更好*的简单普适策略的力量的宣言。

### 数字心智：用梯度教导机器

如今，基于梯度的优化最著名的应用或许是在机器学习领域。当我们说我们正在“训练”一个人工智能时，我们通常所做的就是最小化一个成本函数。[成本函数](@entry_id:138681)是衡量机器当前答案“错误”程度的指标。为了让它更聪明，我们只需要让这个成本变小。怎么做？当然是沿着梯度方向。

想象一下，我们想教一台机器区分猫和狗的图片。我们可以构建一个简单的模型，比如逻辑回归分类器，它接收图像的特征——比如说，来自检测事件发生的传感器的空间数据——并输出该图像是猫的概率 [@problem_id:3151580]。我们模型的“参数”，我们称之为 $\beta$，是我们可调整以改变其预测的旋钮。我们定义一个[成本函数](@entry_id:138681)，即*[对数似然](@entry_id:273783)*，当模型出错时（例如，当图片是猫时，却以高概率说“狗”），该函数值很大；而当模型正确时，该函数值很小。这个特定[成本函数](@entry_id:138681)的美妙之处在于它是*[凹函数](@entry_id:274100)*——它看起来像一个单一、光滑的山丘。找到它的顶点（或等效地，其负值的谷底）对于梯度上升来说是一项直接的工作。梯度，或称为*得分向量*，直接指向山顶，我们每走一步都会[调整参数](@entry_id:756220) $\beta$，使模型在工作上做得更好一点。通过引入像样条（splines）这样的灵活特征，我们甚至可以让我们模型的[决策边界](@entry_id:146073)成为一条复杂的[非线性](@entry_id:637147)曲线，让它学习非常复杂的分类规则，而所有这一切都由梯度的简单逻辑引导。

当我们进入深度学习的[世界时](@entry_id:275204)，这幅图景变得更加复杂，也远为强大 [@problem_id:3108395]。一个[深度神经网络](@entry_id:636170)就像一系列这些简单模型相互叠加。神奇的成分是“[激活函数](@entry_id:141784)” $\sigma$，它是在每一层应用的[非线性](@entry_id:637147)扭转。正是这种[非线性](@entry_id:637147)使网络能够学习极其复杂的模式，但它也付出了代价。即使我们最终的[成本函数](@entry_id:138681) $\ell$ 是一个简单的凸碗，将其与多层[非线性激活函数](@entry_id:635291)复合，即 $\ell(\sigma(Wx_i))$，所得到的最终成本景观也是极其非凸的。这是一个广阔的地形，有无数的山谷、峡谷和高原。

当我们在这种情况下使用[梯度下降](@entry_id:145942)时，我们的罗盘只能引导我们到达我们恰好所在的局部山谷的底部。无法保证这是整个地图上最深的山谷——即全局最小值。这是深度学习的根本挑战。现代人工智能所有引人注目的成就，从生成散文到驾驶汽车，都是由那些原则上只保证能找到[驻点](@entry_id:136617)，而非最佳可能解的算法找到的。事实上，这在实践中效果如此之好，本身就是一个激烈的研究课题，暗示了这些高维景观的迷人特性。

这个框架的力量在于，我们作为设计者，可以定义“误差”的含义。考虑训练一个网络来重建图像，即所谓的自编码器（autoencoder） [@problem_id:3099742]。一个朴素的方法是最小化[均方误差](@entry_id:175403)（Mean Squared Error, MSE），即[原始图](@entry_id:262918)像和重建图像中每个像素之间平[方差](@entry_id:200758)的平均值。梯度下降会尽职地最小化这个值，但结果往往是模糊的。为什么？因为平均像素值是减少 MSE 的好方法，但它会破坏精细的细节。如果我们使用一个更有感知意义的损失函数，比如结构相似性指数（Structural Similarity Index, SSIM），它从局部亮度、对比度和结构方面衡量相似性，那会怎么样？因为 SSIM 是由[卷积和](@entry_id:263238)稳定的比率等平滑运算构建的，所以它是可微的。我们可以计算它的梯度！通过沿着基于 SSIM 的损失函数的[梯度下降](@entry_id:145942)，我们引导网络去关心我们眼睛所关心的事情。结果是更清晰的重建图像，保留了纹理和边缘，即使它们的逐像素 MSE 可能稍高一些。我们告诉优化器我们重视什么，它就勤奋地遵循我们的命令。

### 工程的未来：从优化结构到分子

梯度优化的影响远远超出了数字领域。它是现代工程设计的基石。想象一下，你需要设计一个轻质、坚固的机械支架来支撑多个载荷。你从何入手？传统方法依赖于人类的直觉、反复试验。而[优化方法](@entry_id:164468)则要深刻得多。

在一种称为*[拓扑优化](@entry_id:147162)*（topology optimization）的方法中，我们从一个实[心材](@entry_id:176990)料块开始，对块中的每一个点提出问题：这里应该有材料，还是不应该有？[@problem_id:2704329]。我们可以用一个连续的密度变量 $\rho_e$ 来表示我们块中每个小单元的这一选择。然后我们定义一个[目标函数](@entry_id:267263)——也许我们想最小化结构的柔度（compliance），或者确保应力在任何地方都不超过一个临界极限 $\sigma_{\mathrm{allow}}$。问题在于，检查每个可能载荷工况下每个点的应力会给我们带来数百万个约束！这在计算上是无法直接处理的。

诀窍是使用一个光滑的聚合函数，比如 [p-范数](@entry_id:272607)（p-norm），将这数百万个约束组合成*一个单一的、可微的约束*。这个聚合函数作为整个结构中最大应力的光滑上界。现在，我们有了一个定义明确但复杂的[优化问题](@entry_id:266749)。使用[基于梯度的方法](@entry_id:749986)，我们可以计算任何单元密度的微小变化如何影响我们的聚合[应力约束](@entry_id:201787)。这个敏感度信息就是梯度。通过遵循它，优化器系统地从不需要的区域移除材料，并将其添加到关键区域，从而雕刻出一个最优的、通常呈有机形态的形状。计算上的繁重工作——使用伴随法（adjoint method）求解每个载荷工况下结构的响应及其梯度——是巨大的，但指导原则保持不变：一步一步，我们沿着梯度走向更好的设计。

同样的原则也适用于分子这一难以想象的小尺度上 [@problem_id:2952070]。寻找分子的稳定结构或[化学反应](@entry_id:146973)的过渡态是一个在[势能面](@entry_id:147441)（potential energy surface, PES）上的[优化问题](@entry_id:266749)。坐标是原子的位置，[成本函数](@entry_id:138681)是分子的能量。但这个地形是严重“扭曲”的。将两个成键的原子拉开几分之一埃需要巨大的能量——PES 在那个方向上的壁垒极其陡峭。相比之下，分子的一部分绕着一个[单键](@entry_id:188561)旋转（一种扭转运动）几乎不耗费能量——地形在那个方向上非常平坦。

如果你是这个表面上的一个徒步者，一个标准的[梯度下降](@entry_id:145942)步骤将是一场灾难。你会在平坦的扭转方向上迈出一个巨大的、不受控制的步伐，而在刚性的[键伸缩](@entry_id:172690)方向上几乎不动。你通往最小值的路径将是极其低效的。解决方案是物理学与优化的完美结合：*预处理*（preconditioning）。我们通过使用一套反映分子自然运动的[内坐标](@entry_id:169764)（[键长](@entry_id:144592)、键角、扭转角）来改变我们对“距离”的定义。这相当于用一个[海森矩阵](@entry_id:139140)的模型 $\mathbf{P} = \mathbf{B}^\top\mathbf{K}\mathbf{B}$ 来预处理梯度，该模型捕捉了刚度的巨大差异。这种变换有效地“平坦化”了[能量景观](@entry_id:147726)，使得预处理后的梯度成为一个好得多的向导。我们不再只是走下坡路；我们是以一种尊重问题内在物理规律的方式走下坡路，从而大大加快了收敛速度。

### 解码复杂性：金融与经济学

人类系统，如经济体，是出了名的复杂。然而，基于梯度的优化为建立和校准这些复杂性模型提供了一个强大的视角。

金融领域的一个经典问题是寻找期权的*[隐含波动率](@entry_id:142142)*（implied volatility）[@problem_id:2400507]。著名的 [Black-Scholes-Merton](@entry_id:147622) 模型为我们提供了一个期权价格的公式，$C(\sigma)$，它依赖于包括股票波动率 $\sigma$ 在内的几个因素。虽然我们可以在市场上观察到期权的价格 $C^{\mathrm{mkt}}$，但我们无法直接观察到市场对未来波动率的预期。所以，我们反过来解决这个问题。我们*搜索*使模型价格与市场价格相匹配的 $\sigma$ 值。这是一个[求根问题](@entry_id:174994)，但我们可以很容易地将其重新表述为一个[优化问题](@entry_id:266749)：找到最小化平[方差](@entry_id:200758) $(C(\sigma) - C^{\mathrm{mkt}})^2$ 的 $\sigma$。[目标函数](@entry_id:267263)是一个简单的山谷，其唯一的最小值在模型与现实匹配的点。我们可以使用[基于梯度的方法](@entry_id:749986)滑入这个山谷，找到[隐含波动率](@entry_id:142142)，这是[风险管理](@entry_id:141282)和交易的关键参数。这个过程甚至允许一些聪明的技巧，比如重新[参数化](@entry_id:272587) $\sigma = \exp(x)$，以自动强制执[行波](@entry_id:185008)动率必须为正的物理约束。

当我们的模型变得如此复杂，以至于我们无法为其写出一个简单的公式时，挑战就加深了。这在计量经济学中很常见，我们建立复杂的[基于主体的模型](@entry_id:199978)来模拟整个经济。在这种情况下，我们可以求助于*[间接推断](@entry_id:140485)*（indirect inference）[@problem_id:2401772]。我们不能直接将模型与数据进行比较，但我们可以做次好的事情：我们可以*模拟*模型以生成伪数据。然后，我们从真实数据（$\hat{\beta}^{\text{data}}$）和我们的模拟数据（$\hat{\beta}_{S}(\theta)$）中计算一些汇总统计量，其中 $\theta$ 是我们复杂模型的参数。我们的目标是找到使模拟统计量与真实统计量相匹配的参数 $\theta$。目标函数变成了这两组统计量之间的距离，$Q_{S}(\theta) = (\hat{\beta}_{S}(\theta)-\hat{\beta}^{\text{data}})^{\top} W (\hat{\beta}_{S}(\theta)-\hat{\beta}^{\text{data}})$。

在这里，[优化景观](@entry_id:634681)的性质至关重要。如果我们的模拟器是光滑的，并且我们使用了像共同随机数（common random numbers）这样的巧妙的[方差缩减技术](@entry_id:141433)，那么[目标函数](@entry_id:267263) $Q_S(\theta)$ 可以是一个行为良好、可微的[曲面](@entry_id:267450)，非常适合像 BFGS 这样的高效[拟牛顿法](@entry_id:138962)。但如果模型包含离散选择或阈值，景观就会变得不光滑且因模拟噪声而“颠簸”。在这种崎岖的地形中，一个简单的[梯度估计](@entry_id:164549)可能极不可靠。我们可靠的罗盘会不规律地旋转。这时，我们必须更加明智，从[基于梯度的方法](@entry_id:749986)转换到更鲁棒的无导数算法或专门的[随机近似](@entry_id:270652)（stochastic approximation）技术，这些技术是为驾驭这种充满噪声的险峻景观而设计的。

### 量子前沿

我们的最后一站是计算的最前沿：量子世界。[变分量子本征求解器](@entry_id:150318)（Variational Quantum Eigensolver, VQE）是近期[量子计算](@entry_id:142712)机的一种领先算法，旨在解决连最大型超级计算机也无法处理的[量子化学](@entry_id:140193)问题。VQE 是一种优美的[混合算法](@entry_id:171959)，其中[经典计算](@entry_id:136968)机和[量子计算](@entry_id:142712)机协同工作 [@problem_id:2932446]。

[量子计算](@entry_id:142712)机的工作是根据经典计算机发送的一组参数 $\boldsymbol{\theta}$ 来制备一个[量子态](@entry_id:146142) $|\psi(\boldsymbol{\theta})\rangle$。然后它测量该状态的能量 $E(\boldsymbol{\theta})$。这个能量就是我们的目标函数。经典计算机的工作是充当优化器：它接收测量的能量，计算梯度，并告诉[量子计算](@entry_id:142712)机下一组要尝试的更好参数 $\boldsymbol{\theta}_{\text{new}}$。目标是通过迭代找到能产生最低可能能量状态的参数。

这就是基于梯度的优化，但带有一个强大的量子扭曲。由于量子力学的概率性，每次能量测量都会受到*[散粒噪声](@entry_id:140025)*（shot noise）的破坏。我们永远得不到 $E(\boldsymbol{\theta})$ 的真实值，只有一个[统计估计](@entry_id:270031)值。这对我们的优化器造成了严重破坏。像 [L-BFGS](@entry_id:167263)-B 这样试图从梯度历史中学习景观曲率的方法，很容易被噪声欺骗，并可能采取不规律、无用的步骤。像 Adam 这样的算法对噪声更鲁棒，但可能只是在最小值附近的“噪声球”中徘徊，而从未真正稳定下来。

这推动了更复杂优化器的发展。*量子自然梯度*（Quantum Natural Gradient）就是一个典型的例子。就像我们在分子建模中看到的[预处理](@entry_id:141204)一样，它利用了问题底层几何学的知识——在这种情况下，是[量子态空间](@entry_id:197873)的几何学，由[量子 Fisher 信息](@entry_id:137978)度量（Quantum Fisher Information metric）描述。通过用这个度量来预处理梯度，优化器采取的步骤从[量子态](@entry_id:146142)的角度来看更自然、更有效。虽然它需要更多的测量来估计这个度量，但回报通常是[收敛速度](@entry_id:636873)的显著加快，穿透噪声更有效地找到最小值。在这里，在科学的前沿，“走下坡路”这个简单的思想在面对新计算[范式](@entry_id:161181)的根本挑战时，不断适应，变得更加复杂和强大。

从数字大脑中的神经元到分子中的原子，再到量子处理器中的[量子比特](@entry_id:137928)，基于梯度的优化原则是一条金线。它是一种用于改进的通用语言，一种用于在定义我们科学技术世界的广阔而复杂的可能性景观中导航的数学工具。