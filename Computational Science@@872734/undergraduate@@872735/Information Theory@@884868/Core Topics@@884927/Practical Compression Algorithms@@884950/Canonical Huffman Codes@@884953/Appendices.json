{"hands_on_practices": [{"introduction": "This first exercise provides a complete walkthrough of the entire process, from a given set of symbol probabilities to the final canonical Huffman code. By working through this problem, you will practice applying the Huffman algorithm to determine the optimal codelengths and then use those lengths to construct the corresponding canonical codebook. This foundational practice connects the theory of optimal data compression with the structured, practical implementation of canonical codes [@problem_id:1607377].", "problem": "An automated astronomical observatory classifies transient celestial events into four categories based on their observed properties. After a long observation period, the frequencies of these events have been established:\n- Type A: 50%\n- Type B: 25%\n- Type C: 12.5%\n- Type D: 12.5%\n\nTo compress the data stream of these classifications for efficient storage, a canonical Huffman code is to be constructed. The process for ordering symbols to assign codewords requires that for any symbols with the same probability (and therefore the same codelength), the assignment follows alphabetical order (e.g., 'C' is assigned a codeword before 'D').\n\nWhich of the following sets of codewords represents the correct canonical Huffman code for these event types?\n\nA. Type A: 0, Type B: 10, Type C: 110, Type D: 111\n\nB. Type A: 1, Type B: 01, Type C: 001, Type D: 000\n\nC. Type A: 0, Type B: 11, Type C: 100, Type D: 101\n\nD. Type A: 0, Type B: 10, Type C: 111, Type D: 110\n\nE. Type A: 0, Type B: 100, Type C: 101, Type D: 111", "solution": "Let the event probabilities be $p(A)=\\frac{1}{2}$, $p(B)=\\frac{1}{4}$, $p(C)=\\frac{1}{8}$, and $p(D)=\\frac{1}{8}$. The Huffman procedure combines the two least probable symbols at each step:\n\n1. Combine $C$ and $D$: $\\frac{1}{8}+\\frac{1}{8}=\\frac{1}{4}$, yielding a node of probability $\\frac{1}{4}$.\n2. Now the multiset is $\\left\\{\\frac{1}{2},\\frac{1}{4},\\frac{1}{4}\\right\\}$. Combine the two $\\frac{1}{4}$ nodes to get $\\frac{1}{2}$.\n3. Combine the two $\\frac{1}{2}$ nodes to complete the tree.\n\nFrom this, the codeword lengths are determined by depths in the tree: $l(A)=1$, $l(B)=2$, $l(C)=3$, and $l(D)=3$.\n\nTo form the canonical Huffman code, order symbols by increasing length and, for equal lengths, alphabetically: $(A,1)$, $(B,2)$, $(C,3)$, $(D,3)$. Assign canonical codes by starting with code value $0$ at the shortest length and incrementing in binary, left-shifting when moving to longer lengths:\n\n- Assign to $A$ the length-$1$ code $0$.\n- Increment the code value to $1$ and left-shift by $1$ to move to length $2$: $1 \\mapsto 10_{2}$, assign $B \\to 10$.\n- Increment to $11_{2}$ and left-shift by $1$ to move to length $3$: $11_{2} \\mapsto 110_{2}$, assign $C \\to 110$.\n- Increment to $111_{2}$ at the same length, assign $D \\to 111$.\n\nThus the canonical code is $A:0$, $B:10$, $C:110$, $D:111$, which matches option A. Options C, D, and E have either incorrect lengths or violate the alphabetical tie-breaking within the same length; option B assigns the shortest code $1$ instead of $0$, which is not canonical.", "answer": "$$\\boxed{A}$$", "id": "1607377"}, {"introduction": "In many applications, the set of codelengths for a source alphabet is already determined or specified. This exercise isolates and strengthens your ability to execute the core canonicalization algorithm. Starting with a given list of codelengths, you will meticulously follow the procedure of sorting and incremental codeword generation to build the final canonical codebook, a crucial skill for implementing efficient decoders [@problem_id:1607359].", "problem": "An engineer is designing a compression scheme for a resource-constrained embedded system. The system communicates using a small, custom alphabet of six status symbols: `S = {A, B, C, D, E, F}`. To minimize transmission bandwidth, a variable-length prefix code is used. The design specification dictates the exact length for each symbol's binary codeword as follows:\n- `length(A) = 1`\n- `length(B) = 3`\n- `length(C) = 3`\n- `length(D) = 4`\n- `length(E) = 4`\n- `length(F) = 3`\n\nTo ensure that the decoder on the receiving end can be implemented efficiently with minimal memory, the codebook must be constructed according to a specific canonical method. This method guarantees a unique and predictable codebook from the given set of lengths, and it is defined by the following procedure:\n\n1.  The symbols in the alphabet are first arranged into an ordered sequence. The primary sorting key is the symbol's assigned codelength (ascending), and the secondary sorting key for any ties is the symbol's alphabetical order (A before B, B before C, and so on).\n\n2.  The codeword for the first symbol in this ordered sequence is a string of zeros with the length specified for that symbol.\n\n3.  For each subsequent symbol in the sequence, its codeword is generated by taking the binary codeword of the preceding symbol, interpreting it as an integer, adding one to this integer, and then representing the result as a binary string. This new binary string is then padded with trailing zeros (i.e., left-shifted) as needed until its length matches the required codelength for the current symbol.\n\nFollowing this exact procedure, what is the binary codeword for the symbol `D`?\n\nA. `1101`\n\nB. `0111`\n\nC. `1110`\n\nD. `1111`\n\nE. `110`", "solution": "The problem asks us to construct a canonical prefix code based on a specific set of rules and find the codeword for the symbol `D`. We will follow the procedure described in the problem statement step-by-step.\n\n**Step 1: Sort the symbols**\nThe first step is to sort the symbols according to their specified codelengths (ascending) and then alphabetically for symbols with the same length.\n\nThe symbols and their lengths are:\n- A: 1\n- B: 3\n- C: 3\n- D: 4\n- E: 4\n- F: 3\n\nLet's create a list of `(Symbol, Length)` pairs: `(A, 1), (B, 3), (C, 3), (D, 4), (E, 4), (F, 3)`.\n\nNow, we sort this list.\n- The symbol with the shortest length is `A` (length 1). It comes first.\n- Next are the symbols with length 3. Sorting `B`, `C`, and `F` alphabetically gives `B`, `C`, `F`.\n- Finally, the symbols with length 4. Sorting `D` and `E` alphabetically gives `D`, `E`.\n\nCombining these gives the final ordered sequence of symbols: `A, B, C, F, D, E`.\n\n**Step 2: Generate the codewords iteratively**\n\nWe now generate the codeword for each symbol in the sorted sequence.\n\n- **Symbol `A` (Length 1):**\nThis is the first symbol. Its code is a string of zeros of its specified length.\n`code(A) = 0`\n\n- **Symbol `B` (Length 3):**\nThis is the next symbol. The previous code was `code(A) = 0`.\n1.  Integer value of previous code `0` is `0`.\n2.  Add one: `0 + 1 = 1`.\n3.  The previous codeword length was 1, and the current required length is 3. The length has increased.\n4.  Rule 3 states we must pad the new binary number with trailing zeros to match the required length. The binary representation of `1` is `1`. To get from length 1 to length 3, we need to add `3 - 1 = 2` trailing zeros (equivalent to a left shift by 2).\n`code(B) = 100`\n\n- **Symbol `C` (Length 3):**\nThe previous code was `code(B) = 100`.\n1.  Integer value of previous code `100` is `4`.\n2.  Add one: `4 + 1 = 5`.\n3.  The previous codeword length was 3, and the current required length is 3. The length is unchanged.\n4.  The binary representation of `5` is `101`, which has a length of 3. No padding is needed.\n`code(C) = 101`\n\n- **Symbol `F` (Length 3):**\nThe previous code was `code(C) = 101`.\n1.  Integer value of previous code `101` is `5`.\n2.  Add one: `5 + 1 = 6`.\n3.  The previous codeword length was 3, and the current required length is 3. The length is unchanged.\n4.  The binary representation of `6` is `110`, which has a length of 3. No padding is needed.\n`code(F) = 110`\n\n- **Symbol `D` (Length 4):**\nThe previous code was `code(F) = 110`.\n1.  Integer value of previous code `110` is `6`.\n2.  Add one: `6 + 1 = 7`.\n3.  The previous codeword length was 3, and the current required length is 4. The length has increased.\n4.  We must pad the new binary number with trailing zeros. The binary representation of `7` is `111`. To get from length 3 to length 4, we need to add `4 - 3 = 1` trailing zero (equivalent to a left shift by 1).\n`code(D) = 1110`\n\nThis is the answer we are looking for. For completeness, we can calculate the last code.\n\n- **Symbol `E` (Length 4):**\nThe previous code was `code(D) = 1110`.\n1.  Integer value of previous code `1110` is `14`.\n2.  Add one: `14 + 1 = 15`.\n3.  The previous codeword length was 4, and the current required length is 4. The length is unchanged.\n4.  The binary representation of `15` is `1111`, which has a length of 4. No padding is needed.\n`code(E) = 1111`\n\nThe complete canonical codebook is:\n- A: `0`\n- B: `100`\n- C: `101`\n- F: `110`\n- D: `1110`\n- E: `1111`\n\nThe codeword for symbol `D` is `1110`. This corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1607359"}, {"introduction": "Moving from procedure to principle, this problem challenges your conceptual understanding of why canonical Huffman codes are so valuable. The primary advantage of a canonical code is its ability to be represented very compactly, saving significant overhead when transmitting the codebook. This thought experiment asks you to identify the minimal set of information required to perfectly reconstruct a canonical codebook, revealing the elegant efficiency at the heart of their design [@problem_id:1607368].", "problem": "In the field of data compression, a canonical Huffman code is a special type of prefix code that can be described in a very compact way, saving space when transmitting the codebook itself. The construction of a canonical codebook relies on a standard procedure: first, symbols are sorted primarily by their assigned codelengths (from shortest to longest) and secondarily by their value (e.g., alphabetically or by ASCII value). The first symbol in this sorted list is assigned a codeword of all zeros, with the appropriate length. Each subsequent codeword is derived by taking the previous codeword, adding one to its integer value, and then appending zero-bits as needed to lengthen it for the next symbol in the sorted list.\n\nA software developer is designing a system where a server compresses data and sends it to a client. To allow the client to decompress the data, the server must also send the information needed to reconstruct the canonical Huffman codebook. The developer claims that to save bandwidth, the server only needs to transmit two integers to the client: the minimum codelength ($L_{min}$) and the maximum codelength ($L_{max}$) present in the code.\n\nAnother engineer argues this is insufficient for the client to uniquely reconstruct the codebook. What single piece of information, in addition to $L_{min}$ and $L_{max}$, is fundamentally necessary for the reconstruction?\n\nA. The total number of symbols in the source alphabet.\n\nB. The list of how many codewords exist for each codelength from $L_{min}$ to $L_{max}$.\n\nC. The original probability of occurrence for each symbol in the source data.\n\nD. The specific binary string representing the codeword for the most probable symbol.\n\nE. The average codelength of the entire code.", "solution": "Canonical Huffman codes are determined entirely by the multiset of codeword lengths, not by the exact probabilities. Let the alphabet be known and totally ordered (e.g., by ASCII). Let $L_{min}$ and $L_{max}$ be the smallest and largest codeword lengths, and let $n_{\\ell}$ denote the number of codewords of length $\\ell$ for each integer $\\ell$ with $L_{min} \\le \\ell \\le L_{max}$. The multiset of lengths is equivalently represented by the list $\\{n_{\\ell}\\}_{\\ell=L_{min}}^{L_{max}}$.\n\nThe fundamental property used is that canonical assignment depends only on the lengths and the fixed symbol order: when symbols are sorted by nondecreasing length and then by symbol value, their codewords are assigned by taking the previous codeword as a binary integer, adding $1$, and, when moving to a longer length, appending zero-bits as needed.\n\nFormally, let the occupied lengths be $L_{1} < L_{2} < \\cdots < L_{K}$ where $n_{L_{k}} > 0$. Define the first code value (as an integer) at the shortest length by\n$$\nv_{L_{1}} = 0,\n$$\nand assign the $n_{L_{1}}$ codewords of length $L_{1}$ as the integers\n$$\nv_{L_{1}},\\ v_{L_{1}}+1,\\ \\ldots,\\ v_{L_{1}} + n_{L_{1}} - 1\n$$\nwritten in binary with exactly $L_{1}$ bits. Inductively, for each subsequent occupied length $L_{k} > L_{k-1}$, the first code value is\n$$\nv_{L_{k}} = \\left(v_{L_{k-1}} + n_{L_{k-1}}\\right) 2^{L_{k} - L_{k-1}},\n$$\nand the $n_{L_{k}}$ codewords of length $L_{k}$ are\n$$\nv_{L_{k}},\\ v_{L_{k}}+1,\\ \\ldots,\\ v_{L_{k}} + n_{L_{k}} - 1\n$$\nwritten in binary with exactly $L_{k}$ bits. This recurrence precisely encodes the rule “add one to the previous codeword’s integer value and append zeros when increasing length.” Hence, given the counts $\\{n_{\\ell}\\}$ and the known symbol order, the canonical codebook is uniquely determined.\n\nBy contrast, knowing only $L_{min}$ and $L_{max}$ is insufficient: there are many different sequences $\\{n_{\\ell}\\}$ consistent with those bounds. The only necessary and sufficient aggregate constraint on the counts for a complete prefix code is the Kraft equality\n$$\n\\sum_{\\ell=L_{min}}^{L_{max}} n_{\\ell} 2^{-\\ell} = 1,\n$$\nbut this has infinitely many solutions for $\\{n_{\\ell}\\}$ with the same $L_{min}$ and $L_{max}$. For example, choosing $n_{L_{min}} = 1$ forces $n_{L_{max}} = 2^{L_{max}} - 2^{L_{max} - L_{min}}$ to satisfy the Kraft equality when only two lengths are used, yet many other distributions across intermediate lengths also satisfy the equality. Therefore, $L_{min}$ and $L_{max}$ do not uniquely determine the codebook.\n\nAmong the options, the single additional piece of information that is fundamentally necessary is the list of how many codewords exist for each codelength from $L_{min}$ to $L_{max}$, namely $\\{n_{\\ell}\\}_{\\ell=L_{min}}^{L_{max}}$. With that list and the known symbol order, the canonical codebook is uniquely reconstructible. This corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "1607368"}]}