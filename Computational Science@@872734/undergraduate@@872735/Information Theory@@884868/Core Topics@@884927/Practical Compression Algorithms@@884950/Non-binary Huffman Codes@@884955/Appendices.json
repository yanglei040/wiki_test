{"hands_on_practices": [{"introduction": "Before we can begin constructing a non-binary Huffman tree, we must ensure our set of source symbols meets a fundamental structural requirement. This initial exercise [@problem_id:1643132] focuses on the mathematical constraint that governs the creation of any full $D$-ary tree and illustrates the essential role of \"dummy\" symbols in satisfying this condition.", "problem": "A data compression algorithm uses a non-binary Huffman coding scheme to represent messages from a source alphabet. In this particular application, the code alphabet is quaternary, meaning it consists of four distinct symbols ($D=4$). The source generates messages from a set of 8 distinct symbols. The construction of a valid $D$-ary Huffman tree requires that the number of source symbols, including any necessary zero-probability \"dummy\" symbols, allows for the creation of a full $D$-ary tree, where every internal node has exactly $D$ children.\n\nGiven this setup, determine the total number of internal nodes in the resulting quaternary Huffman code tree.", "solution": "Let $D=4$ and let $s=8$ be the number of source symbols. In a full $D$-ary Huffman tree, the number of leaves $L$ (which equals the number of source symbols plus any zero-probability dummy symbols) must satisfy the structural constraint that every internal node has exactly $D$ children.\n\nLet $I$ be the number of internal nodes. In any rooted tree, the number of edges is the total number of nodes minus $1$, so\n$$\nE = (I + L) - 1.\n$$\nIn a full $D$-ary tree, each internal node contributes exactly $D$ edges to its children, so\n$$\nE = D I.\n$$\nEquating these gives\n$$\nD I = I + L - 1 \\quad \\Longrightarrow \\quad L = (D - 1) I + 1.\n$$\nThus $L \\equiv 1 \\pmod{D-1}$. For $D=4$, we need $L \\equiv 1 \\pmod{3}$. The smallest $L \\geq 8$ with this property is found by writing $L = 1 + 3k$ and choosing the smallest integer $k$ such that $1 + 3k \\geq 8$, namely $k=3$, which gives\n$$\nL = 1 + 3 \\cdot 3 = 10.\n$$\nWith $L=10$ and $D=4$, solve for $I$ using $L = (D - 1) I + 1$:\n$$\n10 = 3 I + 1 \\quad \\Longrightarrow \\quad I = \\frac{10 - 1}{3} = 3.\n$$\nTherefore, the total number of internal nodes in the quaternary Huffman code tree is $3$.", "answer": "$$\\boxed{3}$$", "id": "1643132"}, {"introduction": "With the structural prerequisites understood, we can now apply the core Huffman algorithm. This practice [@problem_id:1643155] provides a concrete, step-by-step guide to building a ternary code for a source with a given probability distribution. By working through the iterative merging process, you will gain direct experience in determining the optimal codeword lengths.", "problem": "A discrete memoryless source emits symbols from an alphabet $X = \\{x_1, x_2, x_3, x_4\\}$ with the following probabilities:\n$P(x_1) = 0.50$\n$P(x_2) = 0.20$\n$P(x_3) = 0.15$\n$P(x_4) = 0.15$\n\nA uniquely decodable, variable-length source code is to be constructed for this source using the ternary Huffman algorithm, which groups symbols in sets of three ($D=3$). Determine the set of codeword lengths $\\{l_1, l_2, l_3, l_4\\}$ corresponding to the symbols $\\{x_1, x_2, x_3, x_4\\}$.\n\nWhich of the following represents the set of resulting codeword lengths?\nA. $\\{1, 1, 2, 2\\}$\nB. $\\{1, 2, 2, 2\\}$\nC. $\\{1, 2, 3, 3\\}$\nD. $\\{2, 2, 2, 2\\}$", "solution": "We are to construct a ternary Huffman code for a source with probabilities $P(x_{1})=0.50$, $P(x_{2})=0.20$, $P(x_{3})=0.15$, $P(x_{4})=0.15$. For a $D$-ary Huffman code with $D=3$, the number of leaves $n$ in the full tree must satisfy $n \\equiv 1 \\pmod{D-1}$, i.e., $n \\equiv 1 \\pmod{2}$. The given $n=4$ is even, so we add one dummy symbol with probability $0$ to obtain $n'=5$, which satisfies $5 \\equiv 1 \\pmod{2}$.\n\nInitialize the multiset of weights as $\\{0.50, 0.20, 0.15, 0.15, 0\\}$. The ternary Huffman step repeatedly combines the three smallest weights into a single node whose weight is their sum.\n\nStep 1: Combine the three smallest weights $0$, $0.15$, $0.15$ into a node of weight $0.30$. The current set of nodes becomes $\\{0.50, 0.20, 0.30\\}$.\n\nStep 2: With exactly three nodes left, they become the three children of the root. Hence the nodes of weights $0.50$ (symbol $x_{1}$) and $0.20$ (symbol $x_{2}$) are assigned depth $1$ (length $1$), while the combined node of weight $0.30$ goes to depth $1$ and its constituent leaves $x_{3}$ and $x_{4}$ go to depth $2$ (length $2$).\n\nTherefore the codeword lengths are $l_{1}=1$, $l_{2}=1$, $l_{3}=2$, $l_{4}=2$, which matches option A. As a quick check, the ternary Kraft inequality holds:\n$$\\sum_{i=1}^{4}3^{-l_{i}}=3^{-1}+3^{-1}+3^{-2}+3^{-2}=\\frac{1}{3}+\\frac{1}{3}+\\frac{1}{9}+\\frac{1}{9}=\\frac{8}{9}\\leq 1.$$\nThus the resulting set of codeword lengths is $\\{1,1,2,2\\}$.", "answer": "$$\\boxed{A}$$", "id": "1643155"}, {"introduction": "The Huffman algorithm guarantees an optimal average code length, but the resulting code is not always unique. This final exercise [@problem_id:1643174] explores the subtleties that arise when ties occur during the symbol-merging process. It reveals how different, equally valid choices can produce distinct optimal codes with the same average length but different distributions of codeword lengths, a property we can analyze by examining the variance.", "problem": "A data compression scheme is being designed for a simplified robotic arm's set of six primary commands, $\\mathcal{C} = \\{C_1, C_2, C_3, C_4, C_5, C_6\\}$. Based on extensive operational data, the probabilities of these commands are found to be $P(C_1)=0.30$, $P(C_2)=0.20$, $P(C_3)=0.15$, $P(C_4)=0.15$, $P(C_5)=0.10$, and $P(C_6)=0.10$. A ternary ($D=3$) Huffman code is to be used for encoding these commands.\n\nThe D-ary Huffman algorithm proceeds by iteratively merging the $D$ symbols or previously merged nodes with the lowest probabilities. During this process, a tie is encountered when selecting the three lowest-probability items to merge. Two engineers, following the algorithm correctly, make different valid choices at this tie-point. This leads to the generation of two distinct, yet equally optimal, ternary Huffman codes, which we will call Code A and Code B.\n\nThe set of codeword lengths for the six commands in Code A will be different from the set of lengths for Code B. Let $L_A$ and $L_B$ be the random variables representing the codeword lengths for the original six commands under Code A and Code B, respectively. Calculate the absolute difference between the variances of these two length distributions, $|\\operatorname{Var}(L_A) - \\operatorname{Var}(L_B)|$.\n\nRound your final answer to three significant figures.", "solution": "We construct a ternary Huffman code for the six commands with probabilities $0.30, 0.20, 0.15, 0.15, 0.10, 0.10$. For a $D$-ary Huffman code with $D=3$, a full tree requires the number of leaves $n$ to satisfy $n \\equiv 1 \\pmod{D-1}$. Here $n=6$ and $D-1=2$, so $6 \\not\\equiv 1 \\pmod{2}$. We therefore add one dummy symbol of probability $0$ so that the augmented set has $7$ items, satisfying $7 \\equiv 1 \\pmod{2}$.\n\nStart with the multiset of probabilities $\\{0, 0.10, 0.10, 0.15, 0.15, 0.20, 0.30\\}$. Merge the three smallest items at each step.\n\nStep 1: Merge $0$, $0.10$, $0.10$ to form a node $N_{1}$ with probability $0.20$.\n\nThe remaining items are $\\{0.15, 0.15, 0.20, 0.30, 0.20\\}$, where the two $0.20$ entries are $C_{2}$ and $N_{1}$. Now we must choose the third item to merge with the two $0.15$ values. A tie occurs between $0.20$ from $C_{2}$ and $0.20$ from $N_{1}$, yielding two valid options.\n\nCode A: Merge $0.15, 0.15, 0.20(C_{2})$ to form $N_{2}$ with probability $0.50$. The final three items are $N_{1}(0.20)$, $C_{1}(0.30)$, and $N_{2}(0.50)$, which are merged at the root. Codeword lengths follow from depths:\n- $C_{1}$ is a child of the root, so $l(C_{1})=1$.\n- $N_{1}$ and $N_{2}$ are children of the root. Their leaves are at depth 2. Thus $l(C_{2})=l(C_{3})=l(C_{4})=l(C_{5})=l(C_{6})=2$.\nTherefore, for $L_{A}$, the length distribution is\n$$\nP(L_{A}=1)=0.30,\\quad P(L_{A}=2)=0.70.\n$$\nCompute mean, second moment, and variance:\n$$\n\\mathbb{E}[L_{A}]=1\\cdot 0.30+2\\cdot 0.70=1.70,\n$$\n$$\n\\mathbb{E}[L_{A}^{2}]=1^{2}\\cdot 0.30+2^{2}\\cdot 0.70=3.10,\n$$\n$$\n\\operatorname{Var}(L_{A})=\\mathbb{E}[L_{A}^{2}]-(\\mathbb{E}[L_{A}])^{2}=3.10-(1.70)^{2}=0.21.\n$$\n\nCode B: Merge $0.15, 0.15, 0.20(N_{1})$ to form $N_{2}'$ with probability $0.50$. The final three items are $C_{2}(0.20)$, $C_{1}(0.30)$, and $N_{2}'(0.50)$, which are merged at the root. Codeword lengths:\n- $C_{1}$ and $C_{2}$ are children of the root, so $l(C_{1})=l(C_{2})=1$.\n- $C_{3}$ and $C_{4}$ are children of $N_{2}'$, so $l(C_{3})=l(C_{4})=2$.\n- $C_{5}$ and $C_{6}$ are children of $N_{1}$, which is a child of $N_{2}'$, so $l(C_{5})=l(C_{6})=3$.\nTherefore, for $L_{B}$, the length distribution is\n$$\nP(L_{B}=1)=0.30+0.20=0.50,\\quad P(L_{B}=2)=0.15+0.15=0.30,\\quad P(L_{B}=3)=0.10+0.10=0.20.\n$$\nCompute mean, second moment, and variance:\n$$\n\\mathbb{E}[L_{B}]=1\\cdot 0.50+2\\cdot 0.30+3\\cdot 0.20=1.70,\n$$\n$$\n\\mathbb{E}[L_{B}^{2}]=1^{2}\\cdot 0.50+2^{2}\\cdot 0.30+3^{2}\\cdot 0.20=3.50,\n$$\n$$\n\\operatorname{Var}(L_{B})=\\mathbb{E}[L_{B}^{2}]-(\\mathbb{E}[L_{B}])^{2}=3.50-(1.70)^{2}=0.61.\n$$\n\nThe absolute difference between the variances is\n$$\n|\\operatorname{Var}(L_{A})-\\operatorname{Var}(L_{B})|=|0.21-0.61|=0.40,\n$$\nwhich to three significant figures is $0.400$.", "answer": "$$\\boxed{0.400}$$", "id": "1643174"}]}