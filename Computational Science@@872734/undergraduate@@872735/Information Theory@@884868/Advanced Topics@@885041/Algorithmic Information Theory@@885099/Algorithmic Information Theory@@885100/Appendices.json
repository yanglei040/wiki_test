{"hands_on_practices": [{"introduction": "A core goal of algorithmic information theory is to provide a formal measure for the simplicity or complexity of an object. This first exercise invites you to explore this fundamental idea using one of the simplest possible structured strings: a sequence of $n$ identical characters. By analyzing the Kolmogorov complexity of this string, $K(1^n)$, you will discover the crucial relationship between the complexity of a regular pattern and the complexity of its description [@problem_id:1602461]. This practice illustrates that the informational content of such a string does not grow with its length, but rather with the complexity of the number that defines its length.", "problem": "In algorithmic information theory, the Kolmogorov complexity of a string of characters $x$, denoted $K(x)$, is defined as the length of the shortest computer program that can generate $x$ as its output and then halt. This length is measured in bits. This concept provides a fundamental measure of the amount of information or \"incompressibility\" of a string. We assume the use of a fixed, optimal, universal description language (analogous to a universal Turing machine), which ensures that the complexity values are well-defined up to an additive constant.\n\nConsider a string $s_n$ that consists of the character '1' repeated $n$ times, where $n$ is a positive integer. For instance, $s_4$ is the string '1111'. Let $K(s_n)$ represent the Kolmogorov complexity of the string $s_n$. Let $K(n)$ represent the Kolmogorov complexity of the integer $n$ itself (formally, the length of the shortest program that outputs the standard binary representation of $n$).\n\nWhich of the following equations most accurately describes the relationship between $K(s_n)$ and $K(n)$ for all positive integers $n$? In these options, $c$, $c_1$, and $c_2$ represent positive constants that are independent of $n$.\n\nA. $K(s_n) = n \\cdot c_1 + c_2$\n\nB. $K(s_n) = K(n) + c$\n\nC. $K(s_n) = n + c$\n\nD. $K(s_n) = \\log_2(n) + c$\n\nE. $K(s_n) = c \\cdot K(n)$", "solution": "We work with a fixed optimal universal description language. By definition, $K(x)$ is the length of the shortest program that outputs $x$ and halts.\n\nUpper bound:\nLet $p_{n}$ be a shortest program that outputs the standard binary representation of $n$, so $|p_{n}|=K(n)$. Construct a fixed wrapper program $W$ (independent of $n$) that, when executed, simulates the universal machine on the hardcoded $p_{n}$ to obtain $n$, then prints the character '1' exactly $n$ times and halts. The concatenated description $Wp_{n}$ outputs $s_{n}$, hence\n$$\nK(s_{n}) \\leq |W| + |p_{n}| = K(n) + c_{+},\n$$\nwhere $c_{+}=|W|$ is a positive constant independent of $n$.\n\nLower bound:\nLet $q$ be a shortest program for $s_{n}$, so $|q|=K(s_{n})$. There exists a fixed extractor program $E$ (independent of $n$) that, when executed, runs the hardcoded $q$ to produce $s_{n}$, computes its length $n$, converts it to standard binary, outputs it, and halts. Therefore the concatenated description $Eq$ is a program for $n$, implying\n$$\nK(n) \\leq |E| + |q| = K(s_{n}) + c_{-},\n$$\nwhere $c_{-}=|E|$ is a positive constant independent of $n$. Rearranging gives $K(s_{n}) \\geq K(n) - c_{-}$.\n\nCombining the two bounds,\n$$\nK(n) - c_{-} \\leq K(s_{n}) \\leq K(n) + c_{+},\n$$\nso $K(s_{n}) = K(n) + O(1)$, i.e., they differ by at most an additive constant independent of $n$.\n\nAmong the given options, only the form $K(s_{n})=K(n)+c$ captures this additive-constant relationship for all positive integers $n$. Options asserting linear dependence on $n$ (A, C) are false because $s_{n}$ is highly compressible; $K(s_{n})$ grows like the description length of $n$, not like $n$. Option D, $K(s_{n})=\\log_{2}(n)+c$, is not valid for all $n$ with a single constant because $K(n)$ fluctuates around $\\log_{2}(n)$ up to more than a fixed constant. Option E posits a multiplicative relationship, which is not the correct invariance; the relationship is additive.", "answer": "$$\\boxed{B}$$", "id": "1602461"}, {"introduction": "Building upon the concept of regularity, we now consider a more general form of structure: redundancy. What happens to the complexity of a string if we simply duplicate it? This practice asks you to analyze the relationship between the complexity of a string $x$ and its self-concatenation, $xx$. This is a powerful demonstration of how Kolmogorov complexity formalizes the intuitive notion that storing information twice does not double its intrinsic informational content [@problem_id:1602422]. Solving this problem reveals a key property of algorithmic complexity and deepens your understanding of its application to data compression.", "problem": "In the field of algorithmic information theory, the Kolmogorov complexity (or algorithmic complexity) of a finite binary string $x$, denoted as $K(x)$, is the length of the shortest computer program that can generate $x$ as its output and then halt. This concept provides a measure of the string's inherent randomness or incompressibility. The program is assumed to run on a fixed, universal Turing machine.\n\nImagine a simple data storage protocol where, for redundancy, a data string $x$ is sometimes stored back-to-back with an identical copy of itself, forming the concatenated string $xx$. We are interested in the complexity of this new, longer string.\n\nWhich of the following statements best describes the general relationship between the algorithmic complexity of the original string, $K(x)$, and the complexity of the duplicated string, $K(xx)$, for any binary string $x$? The notation $O(1)$ represents a term that is bounded by a constant, which does not grow with the length or complexity of $x$.\n\nA. $K(xx) = 2K(x) + O(1)$\n\nB. $K(xx) = K(x) + O(1)$\n\nC. $K(xx) = K(x) + \\log_{2}(|x|) + O(1)$, where $|x|$ is the length of the string $x$.\n\nD. The relationship depends on the content of $x$: for algorithmically random strings, $K(xx) \\approx 2K(x)$, while for highly structured strings, $K(xx) \\approx K(x)$.\n\nE. $K(xx) = (K(x))^{2} + O(1)$", "solution": "Let $K(\\cdot)$ denote prefix Kolmogorov complexity (self-delimiting programs) on a fixed universal Turing machine, so additive constants are absorbed into $O(1)$ by the invariance theorem.\n\nUpper bound $K(xx) \\leq K(x) + O(1)$:\nTake a shortest program $p$ that outputs $x$ and halts, so $|p| = K(x)$. Construct a fixed wrapper program $W$ that, given the self-delimiting code $p$ embedded in its code, performs the following computable procedure: simulate $p$ to produce $x$, then simulate $p$ again to produce $x$ a second time. Because $p$ is self-delimiting, $W$ can parse and reuse $p$ without any extra delimiter beyond a constant-size routine. The total length of the combined program is $|W| + |p| = K(x) + O(1)$ and it outputs $xx$, hence\n$$\nK(xx) \\leq K(x) + O(1).\n$$\n\nLower bound $K(xx) \\geq K(x) - O(1)$:\nThere is a fixed computable function $f$ that maps $xx$ to $x$ by splitting the input string into two equal halves and returning the first half. By the basic monotonicity of Kolmogorov complexity under computable transformations, for any string $z$,\n$$\nK(f(z)) \\leq K(z) + O(1).\n$$\nApplying this with $z = xx$ and $f(z) = x$ gives\n$$\nK(x) \\leq K(xx) + O(1),\n$$\nwhich rearranges to\n$$\nK(xx) \\geq K(x) - O(1).\n$$\n\nCombining the upper and lower bounds yields\n$$\nK(xx) = K(x) + O(1).\n$$\n\nThus the correct option is B. (For comparison, if one worked with plain, non-prefix complexity $C(\\cdot)$, one typically has $C(xx) = C(x) + O(\\log|x|)$ due to delimitation overhead; with prefix $K(\\cdot)$, the overhead is $O(1)$.)", "answer": "$$\\boxed{B}$$", "id": "1602422"}, {"introduction": "Our final practice introduces a pivotal concept in algorithmic information theory: conditional complexity. Instead of measuring the absolute complexity of a single string, we now ask how much information is needed to describe one string, given that another is already known. This exercise [@problem_id:1602453] presents a clear and intuitive scenario by asking for the conditional complexity of a bitwise-inverted string, $K(\\text{NOT}(x)|x)$. This will help you understand that if a simple, computable algorithm can transform one object into another, the informational distance between them is very small.", "problem": "In algorithmic information theory, the Kolmogorov complexity of a string $s$, denoted $K(s)$, is the length of the shortest computer program that produces $s$ as output. We consider programs for a fixed, universal Turing machine. This concept quantifies the amount of information contained within the string. A random string has high complexity, as the shortest program to produce it is essentially the program that contains the string itself. A highly patterned string has low complexity.\n\nSimilarly, the conditional Kolmogorov complexity of a string $s$ given a string $t$, denoted $K(s|t)$, is the length of the shortest program that produces $s$ as output, given $t$ as an auxiliary input to the program. This measures the amount of information needed to produce $s$ when $t$ is already known.\n\nLet $x$ be a binary string of length $n$. We define $\\text{NOT}(x)$ as the bitwise complement of $x$, which is the string of length $n$ obtained by flipping every bit of $x$ (i.e., changing every 0 to a 1 and every 1 to a 0).\n\nWhich of the following expressions best characterizes the conditional Kolmogorov complexity $K(\\text{NOT}(x)|x)$ for an arbitrarily long binary string $x$? In the options below, $c$ represents a small positive constant that depends only on the choice of the universal Turing machine, and not on the string $x$ or its length $n$.\n\nA. $n + c$\n\nB. $\\log_{2}(n) + c$\n\nC. $c$\n\nD. $K(x) + c$\n\nE. $n - K(x) + c$", "solution": "Let $U$ be a fixed universal Turing machine, and recall the definition of conditional Kolmogorov complexity:\n$$\nK(s|t) \\equiv \\min\\{\\,|p| : U(p,t)=s\\,\\}.\n$$\nConsider the total computable function $f$ defined by $f(t)=\\text{NOT}(t)$, where $\\text{NOT}(t)$ flips each bit of $t$. Since $f$ is computable and does not depend on the particular input $t$ beyond using it as data, there exists a fixed program $p_{f}$ (a description of the algorithm “scan the input tape and flip each bit, then halt”) such that for all binary strings $x$,\n$$\nU(p_{f},x)=\\text{NOT}(x).\n$$\nThe length $|p_{f}|$ is a constant depending only on the choice of $U$ and the implementation of the flipping procedure, not on $x$ or its length $n$. Therefore,\n$$\nK(\\text{NOT}(x)\\,|\\,x)\\leq |p_{f}| \\equiv c.\n$$\nThis shows that $K(\\text{NOT}(x)|x)$ is bounded above by a constant independent of $n$ and $K(x)$. A trivial lower bound is $K(\\text{NOT}(x)|x)\\geq 0$, and by the invariance theorem, changing $U$ only alters complexities by an additive constant. Hence, the best characterization among the options is that $K(\\text{NOT}(x)|x)$ is a constant (up to an additive constant depending only on $U$), i.e., option C.\n\nThe other options are not appropriate: it does not grow with $n$ (so A and B are too large), it does not depend on $K(x)$ (so D and E are not correct).", "answer": "$$\\boxed{C}$$", "id": "1602453"}]}