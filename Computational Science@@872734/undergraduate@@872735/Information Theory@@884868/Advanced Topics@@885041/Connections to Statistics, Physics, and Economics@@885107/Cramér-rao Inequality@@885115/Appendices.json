{"hands_on_practices": [{"introduction": "We begin our hands-on practice with a foundational scenario involving a discrete random variable. Many real-world estimation problems, from clinical trials to quantum measurements, can be modeled as a series of independent trials with a binary outcome. This exercise [@problem_id:1615021] will guide you through calculating the Cramér-Rao Bound for the probability parameter $\\theta$ in a Bernoulli-like distribution, providing a clear illustration of how to compute Fisher information from a probability mass function.", "problem": "A new type of quantum dot sensor is developed to detect a specific molecular excitation. The sensor's state is observed at discrete time intervals. For each observation, the sensor yields a random output $X$. If the molecule is in an excited state, the sensor outputs the value $X=1$; otherwise, it outputs $X=2$. The probability that the molecule is in the excited state during any given observation is an unknown parameter $\\theta$, where $0 < \\theta < 1$. The outcome of each observation is independent of the others.\n\nConsider a sample of $n$ independent observations, $X_1, X_2, \\ldots, X_n$, from this sensor. The probability mass function for a single observation $X_i$ is given by:\n$P(X_i=1) = \\theta$\n$P(X_i=2) = 1-\\theta$\n\nDetermine the Cramér-Rao Bound (CRB), which provides a lower bound on the variance of any unbiased estimator for the parameter $\\theta$. Express your answer as a symbolic expression in terms of $\\theta$ and $n$.", "solution": "We model each observation as a two-point distribution with parameter $\\theta$: $P(X=1)=\\theta$ and $P(X=2)=1-\\theta$, with $0<\\theta<1$. For a single observation $X$, the log-likelihood is\n$$\n\\ln p(X;\\theta)=\n\\begin{cases}\n\\ln \\theta & \\text{if } X=1,\\\\\n\\ln(1-\\theta) & \\text{if } X=2.\n\\end{cases}\n$$\nThe score function for one observation is\n$$\n\\frac{\\partial}{\\partial \\theta}\\ln p(X;\\theta)=\n\\begin{cases}\n\\frac{1}{\\theta} & \\text{if } X=1,\\\\\n-\\frac{1}{1-\\theta} & \\text{if } X=2.\n\\end{cases}\n$$\nThe Fisher information for one observation is\n$$\nI_{1}(\\theta)=\\mathbb{E}_{\\theta}\\!\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\ln p(X;\\theta)\\right)^{2}\\right]\n=\\theta\\left(\\frac{1}{\\theta}\\right)^{2}+(1-\\theta)\\left(\\frac{1}{1-\\theta}\\right)^{2}\n=\\frac{1}{\\theta}+\\frac{1}{1-\\theta}=\\frac{1}{\\theta(1-\\theta)}.\n$$\nFor $n$ independent observations, Fisher information adds, so\n$$\nI_{n}(\\theta)=n\\,I_{1}(\\theta)=\\frac{n}{\\theta(1-\\theta)}.\n$$\nBy the Cramér-Rao inequality, for any unbiased estimator $\\hat{\\theta}$ of $\\theta$,\n$$\n\\operatorname{Var}(\\hat{\\theta})\\ge \\frac{1}{I_{n}(\\theta)}=\\frac{\\theta(1-\\theta)}{n}.\n$$\nThus, the Cramér-Rao Bound is $\\theta(1-\\theta)/n$.", "answer": "$$\\boxed{\\frac{\\theta(1-\\theta)}{n}}$$", "id": "1615021"}, {"introduction": "Moving from discrete to continuous variables, we now tackle a ubiquitous problem in science and engineering: quantifying random noise. Gaussian noise is a common feature in physical measurements, and estimating its variance, $\\sigma^2$, is essential for understanding signal quality and system performance. This practice [@problem_id:1615036] challenges you to derive the Cramér-Rao Bound for the variance of a zero-mean Gaussian distribution, reinforcing the mechanics of the inequality for continuous probability densities.", "problem": "Consider a physical experiment where a sequence of $n$ measurements, denoted by $x_1, x_2, \\ldots, x_n$, are taken. These measurements are subject to random noise. The noise is modeled as being drawn independently from a Gaussian distribution with a mean of zero and an unknown variance $\\sigma^2$. An engineer wishes to estimate this variance, which represents the noise power in the system. Let $\\hat{\\theta}$ be any unbiased estimator for the parameter $\\theta = \\sigma^2$ based on these $n$ measurements. According to the Cramér-Rao theorem, there is a fundamental lower limit on the variance of any such estimator. Your task is to determine this limit, known as the Cramér-Rao Bound (CRB).\n\nExpress your answer as a function of $n$ and $\\sigma^2$.", "solution": "We model the measurements as independent samples from a Gaussian distribution with known mean zero and unknown variance parameter $\\theta=\\sigma^{2}$. For a single observation $x$, the density is\n$$\nf(x;\\theta)=\\frac{1}{\\sqrt{2\\pi\\theta}}\\exp\\!\\left(-\\frac{x^{2}}{2\\theta}\\right).\n$$\nFor $n$ independent observations $x_{1},\\ldots,x_{n}$, the log-likelihood is\n$$\n\\ln L(\\theta)=\\sum_{i=1}^{n}\\ln f(x_{i};\\theta)=-\\frac{n}{2}\\ln(2\\pi\\theta)-\\frac{1}{2\\theta}\\sum_{i=1}^{n}x_{i}^{2}.\n$$\nDifferentiate with respect to $\\theta$ to obtain the score:\n$$\n\\frac{\\partial}{\\partial\\theta}\\ln L(\\theta)=-\\frac{n}{2}\\frac{1}{\\theta}+\\frac{1}{2}\\frac{1}{\\theta^{2}}\\sum_{i=1}^{n}x_{i}^{2}.\n$$\nDifferentiate again to obtain the observed information:\n$$\n\\frac{\\partial^{2}}{\\partial\\theta^{2}}\\ln L(\\theta)=\\frac{n}{2}\\frac{1}{\\theta^{2}}-\\frac{1}{\\theta^{3}}\\sum_{i=1}^{n}x_{i}^{2}.\n$$\nThe Fisher information is $I(\\theta)=-\\mathbb{E}\\!\\left[\\frac{\\partial^{2}}{\\partial\\theta^{2}}\\ln L(\\theta)\\right]$. Using $\\mathbb{E}\\!\\left[\\sum_{i=1}^{n}x_{i}^{2}\\right]=n\\,\\mathbb{E}[x_{1}^{2}]=n\\theta$, we get\n$$\nI(\\theta)=-\\left(\\frac{n}{2}\\frac{1}{\\theta^{2}}-\\frac{1}{\\theta^{3}}\\,\\mathbb{E}\\!\\left[\\sum_{i=1}^{n}x_{i}^{2}\\right]\\right)\n=-\\left(\\frac{n}{2}\\frac{1}{\\theta^{2}}-\\frac{n\\theta}{\\theta^{3}}\\right)\n=\\frac{n}{2}\\frac{1}{\\theta^{2}}.\n$$\nBy the Cramér-Rao theorem, for any unbiased estimator $\\hat{\\theta}$ of $\\theta$,\n$$\n\\operatorname{Var}(\\hat{\\theta})\\geq \\frac{1}{I(\\theta)}=\\frac{2\\theta^{2}}{n}.\n$$\nSubstituting $\\theta=\\sigma^{2}$ yields the Cramér-Rao Bound\n$$\n\\operatorname{Var}(\\hat{\\theta})\\geq \\frac{2\\sigma^{4}}{n}.\n$$", "answer": "$$\\boxed{\\frac{2\\sigma^{4}}{n}}$$", "id": "1615036"}, {"introduction": "The Cramér-Rao inequality is a powerful theorem, but its application is not without limits; it relies on certain mathematical properties of the underlying probability distribution known as \"regularity conditions.\" This final problem [@problem_id:1614995] explores a classic case where these conditions are not met: estimating the upper bound, $N$, of a discrete uniform distribution. By attempting to calculate the CRLB and analyzing the validity of the result, you will develop a more nuanced and critical understanding of the theoretical assumptions that underpin this fundamental bound.", "problem": "A technology startup is developing a new series of specialized processors. Each processor is assigned a unique serial number from the set $\\{1, 2, \\dots, N\\}$, where $N$ is the total number of processors produced in the first batch, which is unknown. The serial numbers are assigned sequentially starting from 1. A random sample of $n$ processors is drawn (with replacement, for simplicity of analysis) and their serial numbers, $X_1, X_2, \\dots, X_n$, are recorded. We can model each $X_i$ as an independent random variable drawn from a discrete uniform distribution on the integers from 1 to $N$.\n\nYour task is to evaluate the theoretical limits on estimating $N$. Assuming an unbiased estimator for $N$ exists, perform a formal calculation of the Cramér-Rao Lower Bound (CRLB) for the variance of such an estimator. Then, assess the validity of applying the CRLB in this specific scenario.\n\nWhich of the following statements correctly presents the formally calculated CRLB and the conclusion about its applicability?\n\nA. The CRLB is $\\frac{N^2}{n}$. The bound is applicable and provides a tight lower limit on the variance of the best unbiased estimator.\n\nB. The CRLB is $\\frac{(N^2 - 1)}{12n}$. The bound is applicable as it is based on the population variance.\n\nC. The CRLB is $\\frac{N^2}{n^2}$. The bound is applicable and provides a tight lower limit on the variance of the best unbiased estimator.\n\nD. The CRLB is $\\frac{N^2}{n^2}$. However, the applicability of this bound is not guaranteed because one of the regularity conditions for the CRLB is violated.\n\nE. The CRLB cannot be calculated because the likelihood function is not differentiable with respect to the parameter $N$.", "solution": "We model $X_{1},\\dots,X_{n}$ as independent and identically distributed with pmf\n$$\nf(x;N)=\\begin{cases}\n\\frac{1}{N}, & x\\in\\{1,2,\\dots,N\\},\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\nFor a sample $x_{1},\\dots,x_{n}$ with $M=\\max\\{x_{1},\\dots,x_{n}\\}$, the likelihood and log-likelihood (as a function of $N$) are\n$$\nL(N)=N^{-n}\\,\\mathbf{1}\\{N\\geq M\\},\\qquad \\ell(N)=\\ln L(N)=-n\\ln N+\\ln \\mathbf{1}\\{N\\geq M\\}.\n$$\nA formal (but non-regular) score calculation, differentiating only the smooth part and ignoring the indicator, gives for $N>M$\n$$\n\\frac{\\partial}{\\partial N}\\ell(N)=-\\frac{n}{N}.\n$$\nUnder the true $N$, we have $\\mathbf{P}(M\\leq N)=1$, so the above expression holds almost surely, and hence the “formal” Fisher information based on the squared score for the full sample is\n$$\nI(N)=\\mathbf{E}\\!\\left[\\left(\\frac{\\partial}{\\partial N}\\ell(N)\\right)^{2}\\right]=\\mathbf{E}\\!\\left[\\left(-\\frac{n}{N}\\right)^{2}\\right]=\\frac{n^{2}}{N^{2}}.\n$$\nAssuming there exists an unbiased estimator $T(X_{1},\\dots,X_{n})$ of $N$ (so $g(N)=N$ with $g'(N)=1$), the formal Cramér-Rao lower bound (CRLB) derived from this $I(N)$ is\n$$\n\\operatorname{Var}(T)\\;\\ge\\;\\frac{\\left(g'(N)\\right)^{2}}{I(N)}\\;=\\;\\frac{1}{I(N)}\\;=\\;\\frac{N^{2}}{n^{2}}.\n$$\nHowever, the regularity conditions required for the CRLB are violated here:\n- The support of $f(x;N)$ depends on $N$.\n- The log-likelihood includes an indicator $\\mathbf{1}\\{N\\ge M\\}$ and is not differentiable at $N=M$.\n- The score’s expectation is not zero: $\\mathbf{E}\\!\\left[\\frac{\\partial}{\\partial N}\\ell(N)\\right]=-\\frac{n}{N}\\neq 0$.\nBecause these regularity conditions fail, the standard CRLB is not guaranteed to be applicable, and in related uniform-support problems it is known to give invalid or non-tight bounds. Therefore, while the formal calculation yields $\\operatorname{Var}(T)\\ge N^{2}/n^{2}$, its applicability in this model is not guaranteed.", "answer": "$$\\boxed{D}$$", "id": "1614995"}]}