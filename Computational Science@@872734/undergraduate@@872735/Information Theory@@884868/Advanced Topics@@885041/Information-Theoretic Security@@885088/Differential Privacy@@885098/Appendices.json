{"hands_on_practices": [{"introduction": "Our first practice is a cornerstone of applied differential privacy. We will take a common statistical query—calculating an average—and make it private using the Laplace mechanism. This exercise guides you through calculating the query's sensitivity and using the privacy parameter $\\epsilon$ to calibrate the necessary amount of statistical noise. [@problem_id:1618236]", "problem": "A digital wellness research institute is conducting a study on social media usage. They collect data from $N=500$ volunteers. For each volunteer $i$, the database $D$ stores a single number $d_i$, representing their self-reported hours of social media use per day. To handle outliers and ensure consistency, all reported values are clipped to be within the range $[0, H]$, where the maximum allowed daily usage is $H = 8.0$ hours.\n\nThe institute wishes to release the average daily social media usage across all volunteers. This query is formally defined as $f(D) = \\frac{1}{N} \\sum_{i=1}^{N} d_i$. To protect the privacy of the volunteers, the institute will not publish the true average $f(D)$. Instead, they will release a privatized result $\\tilde{f}(D) = f(D) + Y$, where $Y$ is a random noise value. The noise $Y$ is drawn from a distribution with the probability density function $p(y|b) = \\frac{1}{2b} \\exp\\left(-\\frac{|y|}{b}\\right)$, where $b > 0$ is a scale parameter that controls the amount of noise.\n\nThe privacy mechanism must satisfy $\\epsilon$-Differential Privacy (DP). The $\\epsilon$-DP guarantee ensures that for any two databases $D$ and $D'$ that differ in the data of only one volunteer (i.e., they are adjacent), and for any possible set of outcomes $\\mathcal{S}$, the following inequality holds:\n$$\n\\text{Pr}[\\tilde{f}(D) \\in \\mathcal{S}] \\le \\exp(\\epsilon) \\cdot \\text{Pr}[\\tilde{f}(D') \\in \\mathcal{S}]\n$$\nGiven a privacy budget of $\\epsilon = 0.12$, determine the minimum required value of the scale parameter $b$ to ensure the average usage query satisfies $\\epsilon$-Differential Privacy.\n\nExpress your answer for the scale parameter $b$ in hours, rounded to four significant figures.", "solution": "We are releasing the average $f(D) = \\frac{1}{N} \\sum_{i=1}^{N} d_{i}$ under the Laplace mechanism $\\tilde{f}(D) = f(D) + Y$, where $Y$ has density $p(y \\mid b) = \\frac{1}{2b} \\exp\\left(-\\frac{|y|}{b}\\right)$. To ensure $\\epsilon$-Differential Privacy using the Laplace mechanism, the scale must satisfy\n$$\nb = \\frac{\\Delta_{1} f}{\\epsilon},\n$$\nwhere $\\Delta_{1} f$ is the global $\\ell_{1}$-sensitivity of $f$.\n\nCompute the sensitivity of the average. For adjacent databases $D$ and $D'$ differing in one entry, say index $j$,\n$$\n\\left| f(D) - f(D') \\right| = \\left| \\frac{1}{N} \\sum_{i=1}^{N} d_{i} - \\frac{1}{N} \\sum_{i=1}^{N} d_{i}' \\right| = \\frac{1}{N} \\left| \\sum_{i=1}^{N} (d_{i} - d_{i}') \\right| = \\frac{1}{N} \\left| d_{j} - d_{j}' \\right|.\n$$\nSince all values are clipped to $[0, H]$, we have $\\left| d_{j} - d_{j}' \\right| \\leq H$, hence\n$$\n\\Delta_{1} f = \\max_{D \\sim D'} \\left| f(D) - f(D') \\right| \\leq \\frac{H}{N}.\n$$\nThis upper bound is tight by taking one value to be $0$ and the other to be $H$, so $\\Delta_{1} f = \\frac{H}{N}$.\n\nTherefore, the Laplace scale required for $\\epsilon$-DP is\n$$\nb_{\\min} = \\frac{\\Delta_{1} f}{\\epsilon} = \\frac{H}{N \\epsilon}.\n$$\nSubstituting $H = 8.0$, $N = 500$, and $\\epsilon = 0.12$,\n$$\nb_{\\min} = \\frac{8}{500 \\cdot 0.12} = \\frac{8}{60} = \\frac{2}{15} = 0.133333\\ldots\n$$\nRounded to four significant figures, this is $0.1333$ hours.", "answer": "$$\\boxed{0.1333}$$", "id": "1618236"}, {"introduction": "Real-world data analysis often requires more than simple averages. This problem moves to a more complex, non-linear query that counts pairs of individuals who meet a certain criterion. By calculating its $L_1$-sensitivity, you will deepen your understanding of how a query's structure impacts the amount of noise required for privacy. [@problem_id:1618246]", "problem": "A new social networking platform for university students aims to release an aggregate statistic about its user base. The platform maintains a database where each user's record includes their Grade Point Average (GPA). The total population of students that can be included in the database is $N$.\n\nThe proposed query, denoted as $f(D)$, is designed to count the number of distinct, unordered pairs of students in the current database $D$ who are both considered \"high-achievers.\" A student is classified as a high-achiever if their GPA is greater than or equal to a fixed threshold $G$.\n\nTo comply with data privacy regulations, it is necessary to determine the $L_1$-sensitivity of this query. The $L_1$-sensitivity, $\\Delta f$, of a function $f$ is defined as the maximum possible absolute difference in the function's output when applied to any two adjacent databases. Two databases, $D_1$ and $D_2$, are considered adjacent if one can be obtained from the other by adding or removing the record of a single student. The size of the database is variable but cannot exceed the total population size $N$.\n\nFormally, the sensitivity is $\\Delta f = \\max_{D_1, D_2} |f(D_1) - f(D_2)|$, where the maximum is taken over all possible databases $D_1$ and all databases $D_2$ adjacent to $D_1$.\n\nDetermine the $L_1$-sensitivity, $\\Delta f$, of this pair-counting query. Express your answer in terms of the total student population size $N$.", "solution": "Let $D$ be any database and let $h(D)$ denote the number of high-achievers in $D$, i.e., the number of students with GPA at least $G$. The query counts unordered pairs of high-achievers, so\n$$\nf(D) = \\binom{h(D)}{2} = \\frac{h(D)\\big(h(D)-1\\big)}{2}.\n$$\n\nTwo databases are adjacent if they differ by the addition or removal of one record. Consider the effect of such a change on $f$.\n\n1) If the differing record corresponds to a non-high-achiever, then $h(D)$ is unchanged, and therefore $f$ is unchanged:\n$$\n|f(D_{1}) - f(D_{2})| = 0.\n$$\n\n2) If the differing record corresponds to a high-achiever, there are two symmetric cases.\n\na) Addition of a high-achiever: suppose $D_{2}$ is obtained from $D_{1}$ by adding one high-achiever. Let $k = h(D_{1})$, so $h(D_{2}) = k+1$. Then\n$$\nf(D_{2}) - f(D_{1}) = \\binom{k+1}{2} - \\binom{k}{2}\n= \\frac{(k+1)k}{2} - \\frac{k(k-1)}{2}\n= \\frac{k\\big((k+1)-(k-1)\\big)}{2}\n= \\frac{2k}{2}\n= k.\n$$\nThus the absolute change is $k = h(D_{1})$. Since the database size cannot exceed $N$, the smaller database in an addition step can have at most $N-1$ high-achievers, so the change is at most $N-1$.\n\nb) Removal of a high-achiever: suppose $D_{2}$ is obtained from $D_{1}$ by removing one high-achiever. Let $k = h(D_{1})$, so $h(D_{2}) = k-1$. Then\n$$\nf(D_{1}) - f(D_{2}) = \\binom{k}{2} - \\binom{k-1}{2}\n= \\frac{k(k-1)}{2} - \\frac{(k-1)(k-2)}{2}\n= \\frac{(k-1)\\big(k-(k-2)\\big)}{2}\n= \\frac{2(k-1)}{2}\n= k-1.\n$$\nThus the absolute change is $k-1$. The larger database in a removal step can have at most $N$ high-achievers, so the change is at most $N-1$.\n\nTaking the maximum over all adjacent databases and both cases, the $L_{1}$-sensitivity is\n$$\n\\Delta f = N - 1.\n$$", "answer": "$$\\boxed{N-1}$$", "id": "1618246"}, {"introduction": "Privacy does not come for free; there is an inherent trade-off between the strength of the privacy guarantee and the accuracy of the result. This final exercise provides a practical demonstration of this privacy-utility trade-off. You will calculate the probability that a differentially private query, under specific conditions, yields a result with very low utility, highlighting a key challenge in the field. [@problem_id:1618189]", "problem": "A new data analytics startup is testing its privacy-preserving algorithms on a very small, preliminary database. The database contains the ages of its first two clients: one is 18 years old, and the other is 82 years old.\n\nThe startup wishes to compute the sum of the ages in the database. To comply with privacy regulations, they decide to use the Laplace mechanism, a standard technique for achieving $(\\epsilon, 0)$-differential privacy. This mechanism works by first calculating the true sum, and then adding random noise drawn from a Laplace distribution.\n\nThe process is as follows:\n1.  For the purpose of calculating the privacy budget, assume that any individual's age is first clipped to a predefined range of $[0, C]$, where $C = 100$ years. The sensitivity of the sum query is therefore determined by this clipping value.\n2.  The true sum of the (potentially clipped) ages is calculated.\n3.  Noise $Z$ is added to this sum. The noise $Z$ is a random variable drawn from a Laplace distribution with a probability density function given by $p(z) = \\frac{1}{2b} \\exp\\left(-\\frac{|z|}{b}\\right)$, where the scale parameter is $b = \\frac{S_f}{\\epsilon}$. Here, $S_f$ is the sensitivity of the sum query and $\\epsilon$ is the privacy parameter.\n4.  The company chooses a privacy parameter of $\\epsilon = 0.5$.\n\nA query result is deemed to have \"low utility\" if it produces a nonsensical value (i.e., less than 0) or if it deviates from the true sum by more than 100%. In other words, a result $\\tilde{S}$ for a true sum $S$ has low utility if $\\tilde{S} < 0$ or $\\tilde{S} > 2S$.\n\nCalculate the probability that the differentially private sum of ages will have low utility. Express your answer as a decimal rounded to three significant figures.", "solution": "We first determine the sensitivity of the sum query under clipping. With each individual's age clipped to the range $[0, C]$ and $C=100$, changing one individual's value can change the sum by at most $C$, so the sensitivity is $S_{f}=C$.\n\nThe true (clipped) ages are $18$ and $82$, both within $[0,100]$, so the true sum is\n$$\nS=18+82=100.\n$$\nThe Laplace mechanism adds noise $Z$ drawn from $\\mathrm{Laplace}(0,b)$ with density $p(z)=\\frac{1}{2b}\\exp\\left(-\\frac{|z|}{b}\\right)$ and scale\n$$\nb=\\frac{S_{f}}{\\epsilon}=\\frac{C}{\\epsilon}=\\frac{100}{0.5}=200.\n$$\nThe released value is $\\tilde{S}=S+Z$. The result has low utility if $\\tilde{S}<0$ or $\\tilde{S}>2S$. With $S=100$, this condition is\n$$\nS+Z<0 \\;\\;\\text{or}\\;\\; S+Z>200 \\quad\\Longleftrightarrow\\quad Z<-100 \\;\\;\\text{or}\\;\\; Z>100 \\quad\\Longleftrightarrow\\quad |Z|>100.\n$$\nTherefore, the probability of low utility is\n$$\n\\mathbb{P}(|Z|>100)=\\mathbb{P}(Z>100)+\\mathbb{P}(Z<-100).\n$$\nFor $Z\\sim\\mathrm{Laplace}(0,b)$ and any $t\\ge 0$,\n$$\n\\mathbb{P}(Z>t)=\\int_{t}^{\\infty}\\frac{1}{2b}\\exp\\left(-\\frac{z}{b}\\right)\\,dz=\\frac{1}{2}\\exp\\left(-\\frac{t}{b}\\right),\n$$\nand by symmetry,\n$$\n\\mathbb{P}(Z<-t)=\\frac{1}{2}\\exp\\left(-\\frac{t}{b}\\right).\n$$\nHence,\n$$\n\\mathbb{P}(|Z|>t)=\\exp\\left(-\\frac{t}{b}\\right).\n$$\nSetting $t=100$ and $b=200$ gives\n$$\n\\mathbb{P}(\\text{low utility})=\\exp\\left(-\\frac{100}{200}\\right)=\\exp(-0.5)\\approx 0.607 \\text{ (to three significant figures)}.\n$$", "answer": "$$\\boxed{0.607}$$", "id": "1618189"}]}