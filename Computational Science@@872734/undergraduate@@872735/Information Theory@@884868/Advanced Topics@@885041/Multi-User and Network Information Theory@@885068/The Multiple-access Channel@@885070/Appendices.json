{"hands_on_practices": [{"introduction": "The Gaussian Multiple-Access Channel is a cornerstone model in communication theory, representing scenarios like multiple wireless devices communicating with a single cell tower. A critical design question in such systems is how to allocate a shared resource, such as total power, among the users. This exercise [@problem_id:1663805] invites you to explore this very question, revealing a fundamental and perhaps surprising principle about how power allocation affects the total data throughput, or sum-rate capacity, of the system.", "problem": "Two autonomous environmental sensors, Sensor 1 and Sensor 2, are deployed in a remote location to monitor air and soil quality, respectively. They simultaneously transmit their data to a central receiver. This communication system can be modeled as a two-user Gaussian Multiple-Access Channel (MAC).\n\nThe signal received at the central hub is given by the linear sum of the two transmitted signals plus noise:\n$$Y = X_1 + X_2 + Z$$\nHere, $X_1$ and $X_2$ are the signals from Sensor 1 and Sensor 2, which are treated as independent random variables. $Z$ is Additive White Gaussian Noise (AWGN) with a mean of zero and a variance (power) of $N$. The powers of the transmitted signals are $P_1 = E[X_1^2]$ and $P_2 = E[X_2^2]$.\n\nThe sensors share a common power source, imposing a total power constraint $P$. This means any power allocation $(P_1, P_2)$ must satisfy $P_1 + P_2 \\le P$. The goal of the system design is to maximize the sum-rate capacity, $C_{sum} = R_1 + R_2$, which represents the maximum total data rate that can be reliably transmitted from both sensors to the receiver.\n\nWhich of the following power allocation strategies, $(P_1, P_2)$, will achieve the maximum possible sum-rate capacity for this channel?\n\nA. Allocate all available power to Sensor 1 ($P_1 = P, P_2 = 0$).\n\nB. Allocate all available power to Sensor 2 ($P_1 = 0, P_2 = P$).\n\nC. Allocate the power equally between the two sensors ($P_1 = P/2, P_2 = P/2$).\n\nD. Any allocation $(P_1, P_2)$ that uses the total available power, i.e., for which $P_1 + P_2 = P$, will achieve the same maximum sum-rate.\n\nE. The allocation must be asymmetric but non-zero for both, for example, $P_1 = P/3, P_2 = 2P/3$.", "solution": "We model the uplink as a two-user Gaussian multiple-access channel with $Y=X_{1}+X_{2}+Z$, where $Z$ is zero-mean Gaussian with variance $N$ and $X_{1}$, $X_{2}$ are independent with powers $P_{1}$ and $P_{2}$. For any fixed power allocation $(P_{1},P_{2})$, the sum-rate is upper bounded by the mutual information\n$$\nR_{1}+R_{2} \\le I(X_{1},X_{2};Y).\n$$\nUsing the chain rule of entropy and the additive model, we compute\n$$\nI(X_{1},X_{2};Y)=h(Y)-h(Y|X_{1},X_{2})=h(X_{1}+X_{2}+Z)-h(Z),\n$$\nsince $Y|X_{1},X_{2}=Z$. For given second moments $E[X_{1}^{2}]=P_{1}$, $E[X_{2}^{2}]=P_{2}$ and independent $X_{1},X_{2}$, the variance of $Y$ is\n$$\n\\operatorname{Var}(Y)=P_{1}+P_{2}+N.\n$$\nAmong all distributions with a fixed variance, the Gaussian maximizes differential entropy. Thus the maximum of $I(X_{1},X_{2};Y)$ over input distributions with given powers is achieved when $X_{1}$ and $X_{2}$ are Gaussian, yielding\n$$\nI(X_{1},X_{2};Y)=\\frac{1}{2}\\log_2\\!\\left(2\\pi e(P_{1}+P_{2}+N)\\right)-\\frac{1}{2}\\log_2\\!\\left(2\\pi e N\\right)=\\frac{1}{2}\\log_2\\!\\left(1+\\frac{P_{1}+P_{2}}{N}\\right).\n$$\nTherefore, the sum-rate bound and its maximum depend only on the total transmit power $P_{1}+P_{2}$, not on how it is split between the two users. Under the total power constraint $P_{1}+P_{2}\\le P$, the sum-rate is maximized by using the full power, i.e., any allocation satisfying $P_{1}+P_{2}=P$. Hence all such allocations achieve the same maximum sum-rate\n$$\nC_{\\text{sum}}^{\\star}=\\frac{1}{2}\\log_2\\!\\left(1+\\frac{P}{N}\\right),\n$$\nand no particular asymmetric or single-user allocation is required; allocating all power to one sensor or splitting it equally are all special cases of using the full power and thus achieve the same sum-rate maximum.", "answer": "$$\\boxed{D}$$", "id": "1663805"}, {"introduction": "Moving from the continuous, noisy world of Gaussian channels, we now turn to a simple yet insightful discrete, deterministic model: the binary adder channel. This channel models situations where signals combine arithmetically, such as in certain sensor networks. This practice [@problem_id:1663770] challenges you to determine the maximum possible information rate for this channel by finding the optimal input statistics, a key skill in maximizing the efficiency of shared communication resources.", "problem": "Two independent environmental sensors, Sensor 1 and Sensor 2, are deployed to monitor a certain condition. Each sensor produces a binary output: $X_1 \\in \\{0, 1\\}$ for Sensor 1 and $X_2 \\in \\{0, 1\\}$ for Sensor 2. An output of '1' signifies the detection of a specific event, while '0' signifies its absence. The sensors transmit their signals simultaneously over a shared, noiseless communication channel to a central processing hub. The physical nature of the channel is such that it acts as a binary adder; the signal $Y$ received by the hub is the arithmetic sum of the individual sensor signals, i.e., $Y = X_1 + X_2$.\n\nThe events detected by the sensors are statistically independent. The probability that Sensor 1 detects an event is given by $P(X_1=1) = p_1$, and the corresponding probability for Sensor 2 is $P(X_2=1) = p_2$. The pair of probabilities $(p_1, p_2)$ defines the input distribution for this system, which can be configured by calibrating the sensors.\n\nThe goal is to configure the sensor sensitivities (i.e., choose the values of $p_1$ and $p_2$) to maximize the total information throughput from the sensors to the hub. This corresponds to finding the sum-rate capacity of this Multiple-Access Channel (MAC).\n\nWhich of the following options correctly identifies the maximum achievable sum-rate ($R_1 + R_2$) in bits per channel use and the corresponding input probability distribution $(p_1, p_2)$ that achieves this maximum?\n\nA. Maximum sum-rate of $1.0$ bit per channel use, achieved with input probabilities $(p_1, p_2) = (0.5, 0.5)$.\n\nB. Maximum sum-rate of $\\log_2(3)$ bits per channel use, achieved with input probabilities $(p_1, p_2) = (0.5, 0.5)$.\n\nC. Maximum sum-rate of $1.5$ bits per channel use, achieved with input probabilities $(p_1, p_2) = (0.5, 0.5)$.\n\nD. Maximum sum-rate of $1.0$ bit per channel use, achieved with input probabilities $(p_1, p_2) = (1.0, 0.5)$.\n\nE. Maximum sum-rate of $2.0$ bits per channel use, achieved with input probabilities $(p_1, p_2) = (0.5, 0.5)$.", "solution": "We model the binary-adder multiple-access channel with independent Bernoulli inputs $X_{1} \\sim \\mathrm{Bern}(p_{1})$ and $X_{2} \\sim \\mathrm{Bern}(p_{2})$. The channel is deterministic: $Y = X_{1} + X_{2}$ with output alphabet $\\{0,1,2\\}$.\n\nFor a memoryless deterministic MAC, the capacity region satisfies\n$$\nR_{1} \\leq H(X_{1} \\mid X_{2}), \\quad R_{2} \\leq H(X_{2} \\mid X_{1}), \\quad R_{1} + R_{2} \\leq H(Y),\n$$\nwith entropies in bits (base-$2$). Since $X_{1}$ and $X_{2}$ are independent, $H(X_{1} \\mid X_{2}) = H(X_{1})$ and $H(X_{2} \\mid X_{1}) = H(X_{2})$. Therefore, the maximum achievable sum-rate equals\n$$\n\\max_{p_{1},p_{2}} \\min\\big(H(X_{1}) + H(X_{2}),\\, H(Y)\\big).\n$$\nBecause $H(Y) \\leq \\log_{2}(3)$ and $H(X_{1}) + H(X_{2}) \\leq 2$, we can choose $p_{1} = p_{2} = \\frac{1}{2}$ to ensure $H(X_{1}) + H(X_{2}) = 2 \\geq H(Y)$, so the binding constraint for the sum-rate is $H(Y)$. Hence the sum-capacity is\n$$\n\\max_{p_{1},p_{2}} H(Y).\n$$\n\nWe compute the distribution of $Y$ as a function of $(p_{1}, p_{2})$:\n$$\nP(Y=0) = (1-p_{1})(1-p_{2}), \\quad P(Y=1) = p_{1} + p_{2} - 2 p_{1} p_{2}, \\quad P(Y=2) = p_{1} p_{2}.\n$$\nThus\n$$\nH(Y) = -\\sum_{y \\in \\{0,1,2\\}} P(Y=y)\\, \\log_{2} P(Y=y).\n$$\n\nFirst, the absolute upper bound $H(Y) \\leq \\log_{2}(3)$ would require a uniform output distribution $P(Y=0) = P(Y=1) = P(Y=2) = \\frac{1}{3}$. Setting $P(Y=2) = p_{1} p_{2} = \\frac{1}{3}$ and $P(Y=0) = (1-p_{1})(1-p_{2}) = \\frac{1}{3}$ implies with $s := p_{1} + p_{2}$ and $t := p_{1} p_{2}$ that $t = \\frac{1}{3}$ and\n$$\n1 - s + t = \\frac{1}{3} \\quad \\Rightarrow \\quad s - t = \\frac{2}{3} \\quad \\Rightarrow \\quad s = 1.\n$$\nWith $s=1$ and $t=\\frac{1}{3}$, the quadratic $z^{2} - s z + t = 0$ becomes $z^{2} - z + \\frac{1}{3} = 0$, whose discriminant is $1 - \\frac{4}{3} = -\\frac{1}{3} < 0$, so there are no real $(p_{1}, p_{2})$ achieving uniform $Y$. Hence $H(Y) < \\log_{2}(3)$ for all feasible $(p_{1}, p_{2})$.\n\nNext, to maximize $H(Y)$ over feasible $(p_{1}, p_{2})$, observe that for fixed $P(Y=1)$, the sum $P(Y=0) + P(Y=2)$ is fixed, and by concavity of entropy, $H(Y)$ is maximized when $P(Y=0) = P(Y=2)$. This equality requires\n$$\n(1-p_{1})(1-p_{2}) = p_{1} p_{2} \\quad \\Leftrightarrow \\quad 1 - p_{1} - p_{2} = 0 \\quad \\Leftrightarrow \\quad p_{1} + p_{2} = 1.\n$$\nThus it suffices to optimize along $p_{1} + p_{2} = 1$. Define $t := p_{1} p_{2}$. Under $p_{1} + p_{2} = 1$, the distribution becomes\n$$\nP(Y=0) = t, \\quad P(Y=1) = 1 - 2 t, \\quad P(Y=2) = t,\n$$\nwith feasibility $0 \\leq t \\leq \\frac{1}{4}$ (the maximum attained at $p_{1} = p_{2} = \\frac{1}{2}$). The entropy as a function of $t$ is\n$$\nH(t) = -2 t \\log_{2} t - (1 - 2 t) \\log_{2}(1 - 2 t).\n$$\nDifferentiate:\n$$\nH'(t) = 2 \\log_{2}\\!\\left(\\frac{1 - 2 t}{t}\\right).\n$$\nSetting $H'(t) = 0$ gives $1 - 2 t = t$, i.e., $t = \\frac{1}{3}$, which is outside the feasible interval $[0, \\frac{1}{4}]$. Since\n$$\nH''(t) = \\frac{2}{\\ln 2}\\!\\left(-\\frac{2}{1 - 2 t} - \\frac{1}{t}\\right) < 0 \\quad \\text{for } t \\in (0, \\tfrac{1}{2}),\n$$\n$H(t)$ is strictly concave on the feasible interval, so the maximum over $[0, \\frac{1}{4}]$ occurs at the endpoint $t = \\frac{1}{4}$. This corresponds to $p_{1} = p_{2} = \\frac{1}{2}$ and yields\n$$\nH(Y) = -2 \\cdot \\frac{1}{4} \\log_{2}\\!\\left(\\frac{1}{4}\\right) - \\left(1 - 2 \\cdot \\frac{1}{4}\\right) \\log_{2}\\!\\left(1 - 2 \\cdot \\frac{1}{4}\\right)\n= -\\frac{1}{2} \\log_{2}\\!\\left(\\frac{1}{4}\\right) - \\frac{1}{2} \\log_{2}\\!\\left(\\frac{1}{2}\\right)\n= \\frac{3}{2}.\n$$\n\nTherefore, the maximum achievable sum-rate is $\\frac{3}{2}$ bits per channel use, achieved by $(p_{1}, p_{2}) = \\left(\\frac{1}{2}, \\frac{1}{2}\\right)$. Among the provided options, this corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1663770"}, {"introduction": "While knowing the maximum sum-rate is crucial, practical systems often require asymmetric rate allocations to meet diverse user needs. The full picture of a channel's capabilities is described by its capacity region, which outlines all possible rate combinations. Building on the binary adder channel model, this exercise [@problem_id:1642864] delves into this trade-off, asking you to find the maximum rate for one user when the other is transmitting at a fixed, predetermined rate, thereby exploring a specific point on the boundary of the capacity region.", "problem": "Consider a simplified model for a wireless sensor network consisting of two independent, battery-powered sensors, Sensor 1 and Sensor 2. Each sensor monitors a binary event and encodes its finding into a variable, $X_1$ and $X_2$ respectively, where $X_i=0$ represents 'no event' and $X_i=1$ represents 'event detected'. The sensors transmit these variables simultaneously to a central fusion center over a shared channel.\n\nThis communication channel behaves as a Multiple Access Channel (MAC) and is perfectly modeled by a noiseless binary adder. The signal received by the fusion center, $Y$, is the simple arithmetic sum of the two sensor inputs:\n$$Y = X_1 + X_2$$\nTherefore, the received signal $Y$ can take on values in the set $\\{0, 1, 2\\}$, corresponding to the number of sensors that detected an event.\n\nThe communication protocol allows the sensors to choose the probability of detecting an 'event', i.e., $P(X_1=1)$ and $P(X_2=1)$, to encode information. Sensor 2 is configured to transmit information at a constant, reliable rate of $R_2 = 0.8$ bits per channel use.\n\nAssuming that optimal encoding and decoding schemes are used for both sensors, determine the maximum achievable information rate, $R_1$, for Sensor 1 under this condition. All information rates are expressed using logarithms in base 2. Express your answer as an exact decimal value in bits per channel use.", "solution": "We model the multiple access channel as the deterministic adder $Y=X_{1}+X_{2}$ with $X_{1},X_{2}\\in\\{0,1\\}$. For a discrete memoryless MAC with independent inputs and optimal coding, the capacity region for a fixed product input distribution $p(x_{1})p(x_{2})$ is given by\n$$\nR_{1} \\leq I(X_{1};Y|X_{2}),\\quad R_{2} \\leq I(X_{2};Y|X_{1}),\\quad R_{1}+R_{2} \\leq I(X_{1},X_{2};Y).\n$$\nSince the channel is deterministic, $H(Y|X_{1},X_{2})=0$, so\n$$\nI(X_{1};Y|X_{2})=H(Y|X_{2}),\\quad I(X_{2};Y|X_{1})=H(Y|X_{1}),\\quad I(X_{1},X_{2};Y)=H(Y).\n$$\n\nLet $p_{1}=P(X_{1}=1)$ and $p_{2}=P(X_{2}=1)$. Then the distribution of $Y$ is\n$$\nP(Y=0)=(1-p_{1})(1-p_{2}),\\quad P(Y=1)=p_{1}+p_{2}-2p_{1}p_{2},\\quad P(Y=2)=p_{1}p_{2}.\n$$\nDefine the binary entropy function $h(p)= -p \\log_{2} p - (1-p) \\log_{2}(1-p)$. Conditioning on $X_{2}$, we have: if $X_{2}=0$, then $Y=X_{1}$; if $X_{2}=1$, then $Y=1+X_{1}$, which is a binary-valued random variable with the same entropy as $X_{1}$. Therefore\n$$\nH(Y|X_{2})=h(p_{1}),\\quad H(Y|X_{1})=h(p_{2}).\n$$\nThe capacity constraints for a fixed $(p_{1},p_{2})$ are thus\n$$\nR_{1} \\leq h(p_{1}),\\quad R_{2} \\leq h(p_{2}),\\quad R_{1}+R_{2} \\leq H(Y).\n$$\n\nWe are given $R_{2}=0.8$ and seek the maximum $R_{1}$. Feasibility requires $h(p_{2}) \\geq 0.8$. To maximize $R_{1}$ we maximize both $h(p_{1})$ and the sum-rate bound $H(Y)$. The entropy $h(p_{1})$ is maximized by $p_{1}=\\tfrac{1}{2}$, giving $h(p_{1})=1$. The output entropy $H(Y)$ is maximized when $p_{1}=p_{2}=\\tfrac{1}{2}$, which yields\n$$\nP(Y=0)=\\tfrac{1}{4},\\quad P(Y=1)=\\tfrac{1}{2},\\quad P(Y=2)=\\tfrac{1}{4},\n$$\nand hence\n$$\nH(Y)= -\\tfrac{1}{4}\\log_{2}\\tfrac{1}{4} - \\tfrac{1}{2}\\log_{2}\\tfrac{1}{2} - \\tfrac{1}{4}\\log_{2}\\tfrac{1}{4} = \\tfrac{3}{2}.\n$$\nWith $R_{2}=0.8$, the sum-rate constraint gives\n$$\nR_{1} \\leq H(Y) - R_{2} = \\tfrac{3}{2} - 0.8 = 0.7,\n$$\nwhile the individual bound $R_{1} \\leq h(p_{1})=1$ is not active. This pair is achievable because $h(p_{2})=1 \\geq 0.8$ at $p_{2}=\\tfrac{1}{2}$, and the MAC region includes all rate pairs satisfying the inequalities.\n\nMoreover, for any $(p_{1},p_{2})$, $H(Y) \\leq \\tfrac{3}{2}$, so no larger $R_{1}$ can be supported with $R_{2}=0.8$. Therefore, the maximum achievable $R_{1}$ is $0.7$ bits per channel use.", "answer": "$$\\boxed{0.7}$$", "id": "1642864"}]}