{"hands_on_practices": [{"introduction": "The concepts of absolute and relative error are fundamental not only in computational mathematics but also in every experimental science. This first exercise grounds our theoretical discussion in a tangible, real-world scenario: a classic physics experiment to measure the acceleration due to gravity, $g$ [@problem_id:2152043]. By comparing an experimentally derived value with a known reference, you will practice the direct calculation of relative error and appreciate its role in quantifying the accuracy of physical measurements.", "problem": "An undergraduate physics student is performing an experiment to determine the local acceleration due to gravity, $g$. They construct a simple pendulum using a string of measured length $L = 1.250 \\text{ m}$ and a small, dense bob. After allowing the pendulum to oscillate with a small amplitude, the student measures the time for 50 complete oscillations to be $t_{50} = 112.3 \\text{ s}$. The theoretical period $T$ of a simple pendulum is related to its length $L$ and the acceleration due to gravity $g$ by the formula $T = 2\\pi\\sqrt{\\frac{L}{g}}$. The accepted value for the acceleration due to gravity at the location of the laboratory is $g_{ref} = 9.812 \\text{ m/s}^2$.\n\nBased on the student's measurements, calculate the relative error of their experimental value for $g$ compared to the accepted reference value. Express your answer as a decimal, rounded to three significant figures.", "solution": "We are given length $L = 1.250$ and the measured time for $N = 50$ oscillations as $t_{50} = 112.3$. The period is the time per oscillation, so\n$$\nT_{\\text{exp}} = \\frac{t_{50}}{N} = \\frac{112.3}{50} = 2.246.\n$$\nFor a simple pendulum at small amplitude, the theoretical relation between period and $g$ is\n$$\nT = 2\\pi\\sqrt{\\frac{L}{g}}.\n$$\nSolving for $g$ gives\n$$\ng = \\frac{4\\pi^{2}L}{T^{2}}.\n$$\nUsing the experimental period, the experimental estimate is\n$$\ng_{\\text{exp}} = \\frac{4\\pi^{2}L}{T_{\\text{exp}}^{2}}.\n$$\nSubstitute $L = 1.250$ and $T_{\\text{exp}} = 2.246$. First compute $T_{\\text{exp}}^{2}$:\n$$\nT_{\\text{exp}}^{2} = (2.246)^{2} = 5.044516,\n$$\nand note that $4L = 5$, so\n$$\ng_{\\text{exp}} = \\frac{5\\pi^{2}}{5.044516}.\n$$\nNumerically, this yields\n$$\ng_{\\text{exp}} \\approx 9.782508769.\n$$\nWith the accepted reference value $g_{\\text{ref}} = 9.812$, the relative error (as a decimal) is\n$$\n\\text{relative error} = \\frac{|g_{\\text{exp}} - g_{\\text{ref}}|}{g_{\\text{ref}}} = \\frac{|9.782508769 - 9.812|}{9.812} \\approx \\frac{0.029491231}{9.812} \\approx 0.00300563.\n$$\nRounded to three significant figures, the relative error is $0.00301$.", "answer": "$$\\boxed{0.00301}$$", "id": "2152043"}, {"introduction": "After learning how to calculate error, a more subtle question arises: which type of error is more meaningful? The answer depends on the context, particularly the scale of the numbers involved, a common situation in scientific computing [@problem_id:2198986]. This problem presents a thought experiment involving approximations to values that differ by many orders of magnitude, forcing you to reason about whether absolute or relative error provides a more insightful assessment of accuracy.", "problem": "In the analysis of a damped oscillatory system, the characteristic polynomial is found to be $P(x) = x^2 - (10 + 10^{-6})x + 10^{-5} = 0$. The two exact roots of this equation, representing characteristic frequencies of the system, are a large root, $\\beta = 10$, and a very small root, $\\alpha = 10^{-6}$.\n\nTwo different numerical algorithms are used to find approximations of these roots.\n-   Algorithm A is used to approximate the small root $\\alpha$, and it returns the value $\\tilde{\\alpha} = 2 \\times 10^{-6}$.\n-   Algorithm B is used to approximate the large root $\\beta$, and it returns the value $\\tilde{\\beta} = 10.01$.\n\nGiven these results, which of the following statements provides the most meaningful assessment of the accuracy of the two algorithms?\n\nA. Algorithm A is more accurate because its absolute error is significantly smaller than the absolute error of Algorithm B.\n\nB. Algorithm B is more accurate because its relative error is significantly smaller than the relative error of Algorithm A.\n\nC. Both algorithms exhibit poor accuracy, as both approximations result in relative errors greater than 0.0001.\n\nD. The accuracy of the two algorithms cannot be meaningfully compared, as they are approximating roots of vastly different magnitudes.\n\nE. Both algorithms have comparable accuracy because the absolute error of Algorithm A is on the same order of magnitude as the relative error of Algorithm B.", "solution": "We are given the quadratic $P(x) = x^{2} - (10 + 10^{-6})x + 10^{-5} = 0$ with exact roots $\\alpha = 10^{-6}$ and $\\beta = 10$. The numerical approximations are $\\tilde{\\alpha} = 2 \\times 10^{-6}$ and $\\tilde{\\beta} = 10.01$.\n\nTo assess accuracy, we compute both absolute and relative errors for each algorithm. For the small root:\n$$|\\tilde{\\alpha} - \\alpha| = |2 \\times 10^{-6} - 10^{-6}| = 10^{-6},$$\n$$\\text{relative error for } \\alpha = \\frac{|\\tilde{\\alpha} - \\alpha|}{|\\alpha|} = \\frac{10^{-6}}{10^{-6}} = 1.$$\n\nFor the large root:\n$$|\\tilde{\\beta} - \\beta| = |10.01 - 10| = 0.01,$$\n$$\\text{relative error for } \\beta = \\frac{|\\tilde{\\beta} - \\beta|}{|\\beta|} = \\frac{0.01}{10} = 0.001.$$\n\nWhen comparing approximations of quantities with vastly different magnitudes, the relative error is the meaningful metric. Algorithm A has relative error $1$, while Algorithm B has relative error $0.001$. Therefore, Algorithm B is more accurate because its relative error is significantly smaller than that of Algorithm A.\n\nEvaluating the options:\n- A is incorrect because it relies on absolute error, which is not appropriate across different scales, and in fact Algorithm A has much worse relative error.\n- B is correct: Algorithm B is more accurate due to a much smaller relative error.\n- C is not the most meaningful assessment; while both relative errors exceed $0.0001$, declaring both poor without a specified tolerance is arbitrary and ignores the large difference in relative accuracy.\n- D is incorrect; relative error allows meaningful comparison across scales.\n- E is incorrect; $10^{-6}$ and $0.001$ are not of the same order, and mixing absolute and relative errors is not meaningful.\n\nThus the most meaningful assessment is given by B.", "answer": "$$\\boxed{B}$$", "id": "2198986"}, {"introduction": "Our final practice moves from analysis to active intervention, demonstrating how understanding error allows us to design more robust algorithms. We will confront a classic pitfall in numerical computing known as \"catastrophic cancellation,\" which can lead to enormous relative errors even when using a mathematically correct formula [@problem_id:2370392]. This advanced exercise challenges you to not only diagnose the problem in the standard quadratic formula but to use algebraic principles to derive and implement a numerically stable alternative, showcasing the practical power of error analysis.", "problem": "A quadratic equation with real coefficients has the form $a x^2 + b x + c = 0$ with $a \\neq 0$. The exact real roots exist when the discriminant $D = b^2 - 4 a c \\ge 0$. In floating-point (FP) arithmetic, direct evaluation of the quadratic formula can suffer catastrophic cancellation when $b^2 \\gg 4 a c$, because one root is obtained by subtracting two nearly equal numbers. This problem asks you to quantify absolute and relative error for that cancellation-prone root and to mitigate the error by an algebraically equivalent reformulation derived from first principles.\n\nFundamental bases you may use:\n- Vieta’s formulas for quadratic equations: if $r_1$ and $r_2$ are the exact roots, then $r_1 + r_2 = -\\dfrac{b}{a}$ and $r_1 r_2 = \\dfrac{c}{a}$.\n- The quadratic formula expressing the exact roots in real arithmetic when $D \\ge 0$.\n- The definitions of absolute error and relative error. For an approximation $\\tilde{x}$ to a nonzero exact value $x$, the absolute error is $|\\tilde{x} - x|$ and the relative error is $\\dfrac{|\\tilde{x} - x|}{|x|}$. If $x = 0$, define the relative error to be the absolute error.\n\nYour tasks:\n1. For each test case below, compute both floating-point approximations to the two roots by directly applying the quadratic formula in standard double precision (that is, evaluate $\\dfrac{-b \\pm \\sqrt{b^2 - 4 a c}}{2 a}$ in the most straightforward way). Identify the cancellation-prone root as follows: if $b > 0$, then the cancellation-prone root is computed using the $+$ sign; if $b < 0$, it is computed using the $-$ sign. This identification reflects which formula subtracts two nearly equal quantities when $b^2 \\gg 4 a c$.\n2. Starting strictly from Vieta’s formulas and basic algebra, derive a numerically stable reformulation that avoids subtracting nearly equal numbers for the cancellation-prone root, and implement it. Your implementation must not rely on any “given” stabilized formula; it must follow from your derivation. You may, however, compute the other root in any stable manner implied by your derivation and then recover the cancellation-prone root using $r_1 r_2 = \\dfrac{c}{a}$.\n3. For ground truth, compute high-precision approximations to the exact roots using real arithmetic with at least $80$ decimal digits of precision, then cast to double precision for comparison. For each test case, choose the exact root that corresponds to the cancellation-prone one (the one of smaller magnitude when $b^2 \\gg 4 a c$) and compute both its absolute error and its relative error for the naive evaluation (Task $1$) and for your stable reformulation (Task $2$).\n4. Your program must aggregate the results for all test cases into a single flat list of floating-point numbers in the order, per test case: $[\\text{abs\\_err\\_naive}, \\text{rel\\_err\\_naive}, \\text{abs\\_err\\_stable}, \\text{rel\\_err\\_stable}]$, concatenated across test cases in the same order as listed below.\n\nTest suite (each triplet is $(a,b,c)$):\n- Case $1$: $(a,b,c) = (\\,1\\,,\\,10^8\\,,\\,1\\,)$.\n- Case $2$: $(a,b,c) = (\\,1\\,,\\,-10^8\\,,\\,1\\,)$.\n- Case $3$: $(a,b,c) = (\\,1\\,,\\,3\\,,\\,10^{-3}\\,)$.\n- Case $4$: $(a,b,c) = (\\,10^{-3}\\,,\\,10^5\\,,\\,10^{-3}\\,)$.\n\nNumerical and output requirements:\n- Use radians for any angular computations if they arise, although none are expected here.\n- No physical units are involved.\n- All outputs must be raw numbers; do not use a percentage sign. Relative error must be a pure number (for example, output $0.001$ for one-tenth of one percent).\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,\\dots]$). The final list must contain exactly $\\;16\\;$ floating-point numbers corresponding to the $\\;4\\;$ values per test case over $\\;4\\;$ cases, in the same order as the test suite.", "solution": "The problem presented is a classical exercise in numerical analysis, concerning the loss of precision when solving a quadratic equation $a x^2 + b x + c = 0$ using floating-point arithmetic. The analysis of the problem's validity confirms it is scientifically grounded, well-posed, and objective. We shall proceed with a rigorous solution.\n\nThe standard quadratic formula provides the two exact roots, $r_1$ and $r_2$, as:\n$$\nr_{1,2} = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n$$\nThe problem focuses on the condition where $b^2 \\gg 4ac$. In this regime, the discriminant $D = b^2 - 4ac$ is dominated by the $b^2$ term. Consequently, the square root $\\sqrt{b^2 - 4ac}$ can be approximated by a Taylor series expansion:\n$$\n\\sqrt{b^2 - 4ac} = |b| \\sqrt{1 - \\frac{4ac}{b^2}} \\approx |b| \\left(1 - \\frac{2ac}{b^2}\\right) = |b| - \\frac{2ac}{|b|}\n$$\nThis approximation reveals that $\\sqrt{b^2 - 4ac}$ is a quantity very close to $|b|$.\n\nThis proximity is the source of numerical instability. The phenomenon is known as catastrophic cancellation.\n\\begin{itemize}\n    \\item If $b > 0$, the numerator for one of the roots is $-b + \\sqrt{b^2-4ac}$. Since $\\sqrt{b^2-4ac} \\approx b$, this expression involves the subtraction of two nearly equal numbers. This operation results in a significant loss of relative precision in the computed result. The root affected is $r_1 = \\frac{-b + \\sqrt{b^2-4ac}}{2a}$.\n    \\item If $b < 0$, then $-b$ is a positive quantity. The term $\\sqrt{b^2-4ac} \\approx \\sqrt{b^2} = |b| = -b$. The numerator for one root becomes $-b - \\sqrt{b^2-4ac}$, which is again a subtraction of two nearly equal positive numbers (e.g., if $b=-10^8$, $-b=10^8$ and $\\sqrt{D} \\approx 10^8$). This affects the root $r_2 = \\frac{-b - \\sqrt{b^2-4ac}}{2a}$.\n\\end{itemize}\nIn both cases, the root with the smaller magnitude is the one susceptible to this catastrophic cancellation. The other root, which involves an addition of terms of the same sign ($-b$ and $-\\sqrt{D}$ if $b>0$, or $-b$ and $+\\sqrt{D}$ if $b<0$), is computed stably.\n\nTo mitigate this numerical error, we must derive an alternative formulation. The problem requires this derivation to start from first principles, specifically Vieta's formulas. The strategy is to first compute the \"stable\" root accurately and then use it to find the \"unstable\" (cancellation-prone) root.\n\nLet $r_{\\text{stable}}$ be the root that is computed without subtractive cancellation. It can be expressed in a unified manner using the sign function, $\\text{sgn}(b)$:\n$$\nr_{\\text{stable}} = \\frac{-b - \\text{sgn}(b)\\sqrt{b^2-4ac}}{2a}\n$$\nThis formula ensures that the two terms in the numerator, $-b$ and $-\\text{sgn}(b)\\sqrt{D}$, have the same sign, and their sum is computed robustly. For the non-trivial cases where $b^2 \\gg 4ac$, $b$ is non-zero, so $\\text{sgn}(b)$ is either $1$ or $-1$.\n\nHaving obtained an accurate value for $r_{\\text{stable}}$, we employ Vieta's formula for the product of roots, $r_1 r_2 = c/a$. If $r_{\\text{prone}}$ is the other root (the one susceptible to cancellation), then:\n$$\nr_{\\text{prone}} \\cdot r_{\\text{stable}} = \\frac{c}{a}\n$$\nFrom this, we can solve for $r_{\\text{prone}}$:\n$$\nr_{\\text{prone}} = \\frac{c/a}{r_{\\text{stable}}} = \\frac{c}{a \\cdot r_{\\text{stable}}}\n$$\nThis expression for $r_{\\text{prone}}$ involves only division and multiplication, which are numerically stable operations in this context, thus avoiding the catastrophic cancellation inherent in the naive formula.\n\nThe computational procedure to solve the problem is as follows:\n\\begin{enumerate}\n    \\item For each test case $(a, b, c)$, we first establish a ground truth value for the cancellation-prone root. This is achieved by computing the roots using the standard quadratic formula but with high-precision arithmetic (at least $80$ decimal digits, using Python's `decimal` module). The root corresponding to the subtraction of nearly equal terms is identified as the exact value, $x_{\\text{exact}}$, and cast to a standard double-precision float.\n\n    \\item We compute the cancellation-prone root, $\\tilde{x}_{\\text{naive}}$, using the direct quadratic formula in standard double-precision floating-point arithmetic.\n\n    \\item We compute the cancellation-prone root, $\\tilde{x}_{\\text{stable}}$, using the derived stable method. First, the stable root $\\tilde{r}_{\\text{stable}}$ is computed. Then, the prone root is found via $\\tilde{x}_{\\text{stable}} = (c/a) / \\tilde{r}_{\\text{stable}}$.\n\n    \\item For both the naive and stable methods, we calculate the absolute error, $|\\tilde{x} - x_{\\text{exact}}|$, and the relative error, $|\\tilde{x} - x_{\\text{exact}}| / |x_{\\text{exact}}|$. If $x_{\\text{exact}}=0$, the relative error is taken to be the absolute error.\n\\end{enumerate}\nThese four error metrics are then collected for each test case and aggregated into a single list for the final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom decimal import Decimal, getcontext\n\ndef solve():\n    \"\"\"\n    Solves for the roots of a quadratic equation using naive and stable methods,\n    and calculates the absolute and relative errors for the cancellation-prone root.\n    \"\"\"\n    # Set the precision for the decimal module to 85, which is more than the required 80 digits,\n    # to ensure accuracy of the ground truth calculations.\n    getcontext().prec = 85\n\n    # Define the test cases from the problem statement. Each tuple is (a, b, c).\n    test_cases = [\n        (1.0, 1e8, 1.0),\n        (1.0, -1e8, 1.0),\n        (1.0, 3.0, 1e-3),\n        (1e-3, 1e5, 1e-3),\n    ]\n\n    all_results = []\n    for a, b, c in test_cases:\n        # Use standard double-precision floats for coefficients in FP calculations\n        a_fp, b_fp, c_fp = float(a), float(b), float(c)\n\n        # Task 3: Ground truth using high-precision arithmetic\n        a_d, b_d, c_d = Decimal(a), Decimal(b), Decimal(c)\n        discriminant_d = (b_d**2 - 4 * a_d * c_d).sqrt()\n\n        # Identify the exact cancellation-prone root based on the sign of b.\n        # This is the root with the smaller magnitude.\n        if b_fp > 0:\n            # The root from (-b + sqrt(D)) suffers cancellation\n            x_exact_d = (-b_d + discriminant_d) / (2 * a_d)\n        else: # b <= 0\n            # The root from (-b - sqrt(D)) suffers cancellation\n            x_exact_d = (-b_d - discriminant_d) / (2 * a_d)\n        \n        # Cast the high-precision ground truth to a standard float for comparison\n        x_exact = float(x_exact_d)\n\n        # Task 1: Naive evaluation using the standard quadratic formula in double precision\n        discriminant_fp = np.sqrt(b_fp**2 - 4 * a_fp * c_fp)\n        \n        # Identify the cancellation-prone root from the naive calculation\n        if b_fp > 0:\n            x_naive_prone = (-b_fp + discriminant_fp) / (2 * a_fp)\n        else:\n            x_naive_prone = (-b_fp - discriminant_fp) / (2 * a_fp)\n\n        # Task 2: Stable reformulation derived from first principles\n        # First, compute the stable root (the one without subtractive cancellation)\n        # np.copysign is robust and correctly applies the sign of b.\n        # It's equivalent to sgn(b) for b!=0.\n        stable_root = (-b_fp - np.copysign(1.0, b_fp) * discriminant_fp) / (2 * a_fp)\n        \n        # Then, use Vieta's formula (r1 * r2 = c/a) to find the cancellation-prone root.\n        # This avoids the subtraction of nearly equal numbers.\n        if stable_root == 0:\n            # Handle the unlikely case of the stable root being exactly zero\n            # This would imply c=0, in which case the prone root is also 0.\n            x_stable_prone = 0.0\n        else:\n            x_stable_prone = (c_fp / a_fp) / stable_root\n\n        # Task 4: Compute absolute and relative errors for both methods\n        # Naive method errors\n        abs_err_naive = abs(x_naive_prone - x_exact)\n        # Per problem spec, if x_exact is 0, relative error is absolute error\n        if x_exact != 0:\n            rel_err_naive = abs_err_naive / abs(x_exact)\n        else:\n            rel_err_naive = abs_err_naive\n        \n        # Stable method errors\n        abs_err_stable = abs(x_stable_prone - x_exact)\n        if x_exact != 0:\n            rel_err_stable = abs_err_stable / abs(x_exact)\n        else:\n            rel_err_stable = abs_err_stable\n\n        # Aggregate the results for this test case\n        all_results.extend([abs_err_naive, rel_err_naive, abs_err_stable, rel_err_stable])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.17e}' for r in all_results)}]\")\n\nsolve()\n```", "id": "2370392"}]}