{"hands_on_practices": [{"introduction": "A fundamental skill in optimization is determining whether a function is convex. For twice-differentiable functions, the second derivative test provides a direct method for this verification. This practice [@problem_id:2182829] challenges you to apply this test to a function with a variable parameter, allowing you to find the precise condition that guarantees its convexity over a specified interval.", "problem": "In optimization theory, a core concept is the convexity of a function. For a twice-differentiable function of a single variable, $f(x)$, a sufficient condition for it to be convex on a given interval is that its second derivative, $f''(x)$, is non-negative for all points within that interval.\n\nConsider the family of functions defined by:\n$$f(x) = \\exp(ax) + c x^2$$\nwhere $a$ is a non-zero real constant and $c$ is a variable real parameter. We wish to determine the conditions for which this function is convex over the closed symmetric interval $I = [-\\beta, \\beta]$, where $\\beta$ is a positive constant.\n\nIt can be established that for given values of $a$ and $\\beta$, the function $f(x)$ is convex on the interval $I$ if and only if the parameter $c$ satisfies the inequality $c \\ge c_{min}$.\n\nYour task is to find the expression for this minimum value, $c_{min}$, in terms of the parameters $a$ and $\\beta$.", "solution": "For a twice-differentiable real function on an interval, convexity is equivalent to the nonnegativity of the second derivative throughout the interval. For the given function\n$$\nf(x)=\\exp(ax)+c x^{2},\n$$\nthe first derivative is\n$$\nf'(x)=a\\exp(ax)+2cx,\n$$\nand the second derivative is\n$$\nf''(x)=a^{2}\\exp(ax)+2c.\n$$\nConvexity on the closed interval $I=[-\\beta,\\beta]$ is therefore equivalent to\n$$\nf''(x)=a^{2}\\exp(ax)+2c\\ge 0 \\quad \\text{for all } x\\in[-\\beta,\\beta].\n$$\nSince $a^{2}>0$ and $\\exp(ax)>0$, the minimum of $f''(x)$ over $I$ occurs where $\\exp(ax)$ attains its minimum over $I$. Because $\\exp(ax)$ is monotone increasing in $x$ when $a>0$ and monotone decreasing when $a<0$, we have\n$$\n\\min_{x\\in[-\\beta,\\beta]}\\exp(ax)=\\exp(-|a|\\beta).\n$$\nTherefore,\n$$\n\\min_{x\\in[-\\beta,\\beta]} f''(x)=a^{2}\\exp(-|a|\\beta)+2c.\n$$\nThe condition for convexity is that this minimum be nonnegative:\n$$\na^{2}\\exp(-|a|\\beta)+2c\\ge 0 \\quad \\Longleftrightarrow \\quad c\\ge -\\frac{a^{2}}{2}\\exp(-|a|\\beta).\n$$\nThis bound is tight: at $x$ where $\\exp(ax)$ attains its minimum, equality yields $f''(x)=0$, and any smaller $c$ would make $f''$ negative there. Hence,\n$$\nc_{\\min}=-\\frac{a^{2}}{2}\\exp(-|a|\\beta).\n$$", "answer": "$$\\boxed{-\\frac{a^{2}}{2}\\exp(-|a|\\beta)}$$", "id": "2182829"}, {"introduction": "Understanding how convexity behaves under various mathematical operations is crucial for building complex convex models from simpler ones. While the sum of convex functions is always convex, are operations like multiplication or function composition equally reliable at preserving this property? This problem [@problem_id:2182853] asks you to investigate these 'closure' properties, a task that requires careful proof and the construction of counterexamples to separate mathematical fact from fiction.", "problem": "In the study of optimization and signal processing, the properties of convex functions are of fundamental importance. A twice-differentiable function $f(x)$ defined on the set of all real numbers, $\\mathbb{R}$, is said to be convex if its second derivative, $f''(x)$, is non-negative for all $x \\in \\mathbb{R}$. For instance, $f(x)=x^2$ is convex because its second derivative is $f''(x)=2$, which is always non-negative.\n\nConsider the set of all such twice-differentiable convex functions defined on $\\mathbb{R}$. Evaluate the following statements about operations on these functions. Which one of the statements is always true?\n\nA. If $f(x)$ and $g(x)$ are convex functions, then their sum, $h(x) = f(x) + g(x)$, is always a convex function.\n\nB. If $f(x)$ and $g(x)$ are convex functions, then their product, $p(x) = f(x)g(x)$, is always a convex function.\n\nC. If $f(x)$ and $g(x)$ are convex functions, then their composition, $c(x) = f(g(x))$, is always a convex function.\n\nD. If $f(x)$ and $g(x)$ are convex functions, then the function representing their pointwise maximum, $m(x) = \\max(f(x), g(x))$, is not necessarily a convex function.", "solution": "We recall that a twice-differentiable function $f:\\mathbb{R}\\to\\mathbb{R}$ is convex if and only if $f''(x)\\geq 0$ for all $x\\in\\mathbb{R}$.\n\nAnalyze A: Let $f$ and $g$ be convex and twice differentiable on $\\mathbb{R}$, so $f''(x)\\geq 0$ and $g''(x)\\geq 0$ for all $x$. Consider $h(x)=f(x)+g(x)$. Then\n$$\nh''(x)=f''(x)+g''(x)\\geq 0\\quad\\text{for all }x,\n$$\nso $h$ is convex. Thus A is always true.\n\nAnalyze B: Consider $f(x)=x^{2}$ and $g(x)=x^{2}-x$. Both are twice differentiable with\n$$\nf''(x)=2\\geq 0,\\qquad g''(x)=2\\geq 0,\n$$\nso both are convex. Let $p(x)=f(x)g(x)=x^{4}-x^{3}$. Then\n$$\np'(x)=4x^{3}-3x^{2},\\qquad p''(x)=12x^{2}-6x=6\\left(2x^{2}-x\\right).\n$$\nOn the interval $0<x<\\frac{1}{2}$, we have $2x^{2}-x<0$, hence $p''(x)<0$ there. Therefore $p$ is not convex, and B is not always true.\n\nAnalyze C: Take $f(u)=\\exp(-u)$ and $g(x)=x^{2}$. Both are convex and twice differentiable on $\\mathbb{R}$, because\n$$\nf''(u)=\\exp(-u)\\geq 0,\\qquad g''(x)=2\\geq 0.\n$$\nConsider the composition $c(x)=f(g(x))=\\exp(-x^{2})$. Then\n$$\nc'(x)=-2x\\exp(-x^{2}),\\qquad c''(x)=\\exp(-x^{2})\\left(4x^{2}-2\\right).\n$$\nFor $|x|<\\frac{1}{\\sqrt{2}}$, we have $4x^{2}-2<0$, so $c''(x)<0$ on that interval. Hence $c$ is not convex, and C is not always true.\n\nAnalyze D: Let $m(x)=\\max\\{f(x),g(x)\\}$. For any $x,y\\in\\mathbb{R}$ and $t\\in[0,1]$, convexity of $f$ and $g$ gives\n$$\nf(tx+(1-t)y)\\leq t f(x)+(1-t) f(y),\\qquad g(tx+(1-t)y)\\leq t g(x)+(1-t) g(y).\n$$\nTaking pointwise maxima on both inequalities yields\n$$\nm(tx+(1-t)y)=\\max\\{f(tx+(1-t)y),g(tx+(1-t)y)\\}\n\\leq \\max\\{t f(x)+(1-t) f(y),\\, t g(x)+(1-t) g(y)\\}.\n$$\nMoreover,\n$$\n\\max\\{t f(x)+(1-t) f(y),\\, t g(x)+(1-t) g(y)\\}\\leq t \\max\\{f(x),g(x)\\}+(1-t)\\max\\{f(y),g(y)\\},\n$$\nsince each of $t f(x)+(1-t) f(y)$ and $t g(x)+(1-t) g(y)$ is bounded above by the right-hand side. Hence\n$$\nm(tx+(1-t)y)\\leq t m(x)+(1-t) m(y),\n$$\nwhich proves $m$ is convex. Therefore D, which claims $m$ is not necessarily convex, is false.\n\nOnly statement A is always true.", "answer": "$$\\boxed{A}$$", "id": "2182853"}, {"introduction": "Jensen's inequality is a cornerstone result of convexity, formalizing the intuition that for a convex function $f$, the value at an average input is less than or equal to the average of the function's values, i.e., $f(\\mathbb{E}[X]) \\le \\mathbb{E}[f(X)]$. This exercise [@problem_id:2182882] provides a concrete, hands-on calculation of the 'convexity gap', $\\mathbb{E}[f(X)] - f(\\mathbb{E}[X])$, in a probabilistic setting involving vector norms. It offers a tangible look at how Jensen's inequality appears in practical applications like risk assessment and statistical analysis.", "problem": "A robotic agent operates on a 2D Cartesian plane. Its position is a random vector $V$. The agent has two possible states: it can be at position $v_1 = (12, 5)$ with probability $p = \\frac{1}{2}$, or at position $v_2 = (3, 4)$ with probability $1-p = \\frac{1}{2}$. The origin $(0,0)$ is a central charging hub.\n\nA key operational metric is the \"risk-adjusted cost,\" defined as the difference between the expected travel cost and the cost of traveling to the expected position. The travel cost to any position $v$ is directly proportional to its Euclidean distance from the hub, given by the Euclidean norm $C(v) = \\|v\\|_2$.\n\nCalculate the risk-adjusted cost, which is the value of $\\mathbb{E}[C(V)] - C(\\mathbb{E}[V])$, where $\\mathbb{E}[\\cdot]$ denotes the expected value. Choose the correct option from the following.\n\nA. $9 - \\frac{3\\sqrt{34}}{2}$\n\nB. $\\frac{3\\sqrt{34}}{2} - 9$\n\nC. $0$\n\nD. $4.5$", "solution": "The problem asks for the value of $\\mathbb{E}[C(V)] - C(\\mathbb{E}[V])$. This quantity is often called the \"convexity gap\" and is a direct consequence of Jensen's inequality for convex functions. The function $C(v) = \\|v\\|_2$ (the Euclidean norm) is a convex function. For a convex function $C$ and a random variable $V$, Jensen's inequality states that $C(\\mathbb{E}[V]) \\leq \\mathbb{E}[C(V)]$, which means the result should be non-negative.\n\nThe random vector $V$ can take two values:\n$v_1 = (12, 5)$ with probability $P(V=v_1) = \\frac{1}{2}$\n$v_2 = (3, 4)$ with probability $P(V=v_2) = \\frac{1}{2}$\n\nWe need to compute two terms: the expected cost $\\mathbb{E}[C(V)]$ and the cost of the expected position $C(\\mathbb{E}[V])$.\n\nStep 1: Calculate the expected cost $\\mathbb{E}[C(V)]$.\nThe expected cost is the weighted average of the costs for each possible position.\n$$ \\mathbb{E}[C(V)] = P(V=v_1)C(v_1) + P(V=v_2)C(v_2) $$\nThe cost function is the Euclidean norm, $C(v) = \\|v\\|_2 = \\sqrt{v_x^2 + v_y^2}$.\nFirst, we find the cost for each position:\n$$ C(v_1) = \\|v_1\\|_2 = \\sqrt{12^2 + 5^2} = \\sqrt{144 + 25} = \\sqrt{169} = 13 $$\n$$ C(v_2) = \\|v_2\\|_2 = \\sqrt{3^2 + 4^2} = \\sqrt{9 + 16} = \\sqrt{25} = 5 $$\nNow, we can calculate the expected cost:\n$$ \\mathbb{E}[C(V)] = \\frac{1}{2} C(v_1) + \\frac{1}{2} C(v_2) = \\frac{1}{2}(13) + \\frac{1}{2}(5) = \\frac{13+5}{2} = \\frac{18}{2} = 9 $$\n\nStep 2: Calculate the cost of the expected position $C(\\mathbb{E}[V])$.\nFirst, we need to find the expected position vector $\\mathbb{E}[V]$.\n$$ \\mathbb{E}[V] = P(V=v_1) v_1 + P(V=v_2) v_2 $$\n$$ \\mathbb{E}[V] = \\frac{1}{2}(12, 5) + \\frac{1}{2}(3, 4) = (\\frac{12}{2}, \\frac{5}{2}) + (\\frac{3}{2}, \\frac{4}{2}) = (\\frac{12+3}{2}, \\frac{5+4}{2}) = (\\frac{15}{2}, \\frac{9}{2}) $$\nNow, we calculate the cost associated with this expected position:\n$$ C(\\mathbb{E}[V]) = \\|\\mathbb{E}[V]\\|_2 = \\left\\| \\left(\\frac{15}{2}, \\frac{9}{2}\\right) \\right\\|_2 $$\n$$ C(\\mathbbE}[V]) = \\sqrt{\\left(\\frac{15}{2}\\right)^2 + \\left(\\frac{9}{2}\\right)^2} = \\sqrt{\\frac{225}{4} + \\frac{81}{4}} = \\sqrt{\\frac{225 + 81}{4}} = \\sqrt{\\frac{306}{4}} = \\frac{\\sqrt{306}}{2} $$\nWe can simplify the square root term: $\\sqrt{306} = \\sqrt{9 \\times 34} = 3\\sqrt{34}$.\nSo, the cost of the expected position is:\n$$ C(\\mathbb{E}[V]) = \\frac{3\\sqrt{34}}{2} $$\n\nStep 3: Calculate the final difference.\nThe risk-adjusted cost is $\\mathbb{E}[C(V)] - C(\\mathbb{E}[V])$.\n$$ \\mathbb{E}[C(V)] - C(\\mathbb{E}[V]) = 9 - \\frac{3\\sqrt{34}}{2} $$\n\nThis matches option A. We can check that the value is positive, as expected from Jensen's inequality. $\\sqrt{34}$ is between $\\sqrt{25}=5$ and $\\sqrt{36}=6$. Let's approximate it as 5.8. Then $\\frac{3\\sqrt{34}}{2} \\approx \\frac{3 \\times 5.8}{2} = 3 \\times 2.9 = 8.7$. So the difference is approximately $9 - 8.7 = 0.3 > 0$. Option B would be negative. Option C would be true if the function were linear, or for certain other norms like the $L_1$ norm. Option D arises from confusing norms with squares of norms.", "answer": "$$\\boxed{A}$$", "id": "2182882"}]}