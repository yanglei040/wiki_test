{"hands_on_practices": [{"introduction": "To begin our exploration of the Strong Duality Theorem, let's start with a classic and geometrically intuitive problem. We will find the point on a line in a 2D plane that is closest to the origin. By solving both the primal problem (direct minimization) and its corresponding dual problem, we can explicitly verify that their optimal values are identical, providing a concrete demonstration of strong duality in action [@problem_id:2221847]. This exercise builds a foundational understanding of the mechanics of constructing and solving dual problems.", "problem": "Consider an optimization problem defined in $\\mathbb{R}^2$. The objective is to find a point $(x, y)$ that minimizes its squared Euclidean distance from the origin, given by the function $f_0(x, y) = x^2 + y^2$. The minimization is subject to a linear equality constraint, $ax + by = c$, where $a, b,$ and $c$ are non-zero real constants. This formulation is referred to as the primal problem. Let the optimal value of this primal problem be denoted by $p^*$.\n\nThe corresponding Lagrange dual problem involves maximizing the Lagrange dual function, $g(\\nu)$. Let the optimal value of this dual problem be denoted by $d^*$.\n\nYour task is to determine the analytical expressions for both the primal optimal value, $p^*$, and the dual optimal value, $d^*$, in terms of the constants $a, b,$ and $c$.\n\nPresent your final answer as a $1 \\times 2$ row matrix containing the value of $p^*$ as the first element and $d^*$ as the second element.", "solution": "We are minimizing the convex quadratic $f_{0}(x,y)=x^{2}+y^{2}$ subject to the affine equality constraint $ax+by=c$, with $a\\neq 0$ and $b\\neq 0$, so the feasible set is nonempty and KKT conditions are necessary and sufficient.\n\nForm the Lagrangian with dual variable $\\nu\\in\\mathbb{R}$:\n$$\nL(x,y,\\nu)=x^{2}+y^{2}+\\nu(ax+by-c).\n$$\nStationarity with respect to $x$ and $y$ requires\n$$\n\\frac{\\partial L}{\\partial x}=2x+\\nu a=0,\\qquad \\frac{\\partial L}{\\partial y}=2y+\\nu b=0,\n$$\nwhich gives\n$$\nx=-\\frac{\\nu a}{2},\\qquad y=-\\frac{\\nu b}{2}.\n$$\nImposing primal feasibility $ax+by=c$ yields\n$$\na\\left(-\\frac{\\nu a}{2}\\right)+b\\left(-\\frac{\\nu b}{2}\\right)=c\n\\;\\;\\Longrightarrow\\;\\;\n-\\frac{\\nu}{2}(a^{2}+b^{2})=c\n\\;\\;\\Longrightarrow\\;\\;\n\\nu^{\\star}=-\\frac{2c}{a^{2}+b^{2}}.\n$$\nHence the primal optimizer is\n$$\nx^{\\star}=\\frac{ac}{a^{2}+b^{2}},\\qquad y^{\\star}=\\frac{bc}{a^{2}+b^{2}},\n$$\nand the primal optimal value is\n$$\np^{\\star}=(x^{\\star})^{2}+(y^{\\star})^{2}\n=\\frac{a^{2}c^{2}+b^{2}c^{2}}{(a^{2}+b^{2})^{2}}\n=\\frac{c^{2}}{a^{2}+b^{2}}.\n$$\n\nFor the dual, the dual function is $g(\\nu)=\\inf_{x,y}L(x,y,\\nu)$, obtained by substituting the stationary $x=-\\nu a/2$ and $y=-\\nu b/2$:\n$$\nx^{2}+y^{2}=\\frac{\\nu^{2}}{4}(a^{2}+b^{2}),\\qquad\nax+by=-\\frac{\\nu}{2}(a^{2}+b^{2}),\n$$\nso\n$$\ng(\\nu)=\\frac{\\nu^{2}}{4}(a^{2}+b^{2})+\\nu\\left(-\\frac{\\nu}{2}(a^{2}+b^{2})-c\\right)\n=-\\frac{a^{2}+b^{2}}{4}\\nu^{2}-c\\nu.\n$$\nThe dual problem is $\\max_{\\nu\\in\\mathbb{R}}g(\\nu)$; differentiate and set to zero:\n$$\ng'(\\nu)=-\\frac{a^{2}+b^{2}}{2}\\nu-c=0\n\\;\\;\\Longrightarrow\\;\\;\n\\nu^{\\star}=-\\frac{2c}{a^{2}+b^{2}}.\n$$\nEvaluating the dual optimal value,\n$$\nd^{\\star}=g(\\nu^{\\star})\n=-\\frac{a^{2}+b^{2}}{4}\\left(\\frac{4c^{2}}{(a^{2}+b^{2})^{2}}\\right)-c\\left(-\\frac{2c}{a^{2}+b^{2}}\\right)\n=-\\frac{c^{2}}{a^{2}+b^{2}}+\\frac{2c^{2}}{a^{2}+b^{2}}\n=\\frac{c^{2}}{a^{2}+b^{2}}.\n$$\nSince the problem is convex with an affine equality constraint and a feasible point exists, strong duality holds, so $p^{\\star}=d^{\\star}=\\frac{c^{2}}{a^{2}+b^{2}}$.\n\nThus the requested $1\\times 2$ row matrix is $\\begin{pmatrix}p^{\\star}  d^{\\star}\\end{pmatrix}=\\begin{pmatrix}\\frac{c^{2}}{a^{2}+b^{2}}  \\frac{c^{2}}{a^{2}+b^{2}}\\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{c^{2}}{a^{2}+b^{2}}  \\frac{c^{2}}{a^{2}+b^{2}}\\end{pmatrix}}$$", "id": "2221847"}, {"introduction": "This next practice problem moves from a quadratic objective to an exponential one, illustrating the broad applicability of duality principles beyond simple polynomial functions. Here, we are asked to find the minimum 'energy' of a system described by state variables $x$ and $y$ with an exponential cost function, subject to a linear constraint. The Strong Duality Theorem provides a powerful method to confirm the optimality of a proposed solution, acting as a certificate of correctness [@problem_id:2221850]. Solving the dual problem offers an independent and often simpler path to finding the system's true minimum energy.", "problem": "A system is described by two state variables, $x$ and $y$, which are constrained by the relation $x+y=2$. The total 'energy' of the system is given by the function $E(x,y) = \\exp(x) + \\exp(y)$. An engineer claims that the minimum possible energy for this system is achieved when the state variables are equal, i.e., $x=y=1$.\n\nYour task is to determine the true minimum energy $E_{\\text{min}}$ of the system. To do this, you will analyze the problem using the framework of Lagrange duality. The problem is known to be convex and satisfies constraints that guarantee strong duality, meaning the optimal primal value is equal to the optimal dual value.\n\nFind the minimum energy, $E_{\\text{min}}$. Express your answer as a single, exact analytic expression.", "solution": "We consider the convex optimization problem of minimizing $E(x,y)=\\exp(x)+\\exp(y)$ subject to the affine constraint $x+y=2$. The problem is convex and satisfies the regularity conditions guaranteeing strong duality, so the optimal primal value equals the optimal dual value.\n\nForm the Lagrangian with multiplier $\\lambda$ for the equality constraint $x+y-2=0$:\n$$\nL(x,y,\\lambda)=\\exp(x)+\\exp(y)+\\lambda(x+y-2).\n$$\nThe dual function is\n$$\ng(\\lambda)=\\inf_{x,y}L(x,y,\\lambda)=\\inf_{x}\\big(\\exp(x)+\\lambda x\\big)+\\inf_{y}\\big(\\exp(y)+\\lambda y\\big)-2\\lambda.\n$$\nConsider the generic infimum $\\inf_{t}\\big(\\exp(t)+\\lambda t\\big)$. Its derivative with respect to $t$ is $\\exp(t)+\\lambda$. Setting it to zero gives the stationarity condition\n$$\n\\exp(t)+\\lambda=0 \\quad \\Rightarrow \\quad \\exp(t)=-\\lambda.\n$$\nThis requires $\\lambda0$, and then the unique minimizer is $t^{*}=\\ln(-\\lambda)$. Evaluating at this minimizer yields\n$$\n\\inf_{t}\\big(\\exp(t)+\\lambda t\\big)=\\exp(t^{*})+\\lambda t^{*}=-\\lambda+\\lambda\\ln(-\\lambda).\n$$\nTherefore, for $\\lambda0$,\n$$\ng(\\lambda)=2\\big(-\\lambda+\\lambda\\ln(-\\lambda)\\big)-2\\lambda=-4\\lambda+2\\lambda\\ln(-\\lambda).\n$$\nFor $\\lambda=0$, $\\inf_{t}\\exp(t)=0$, hence $g(0)=0$. For $\\lambda0$, $\\inf_{t}\\big(\\exp(t)+\\lambda t\\big)=-\\infty$, so $g(\\lambda)=-\\infty$. Thus the effective domain is $\\lambda\\leq 0$, with the above expression valid for $\\lambda0$ and continuous to $\\lambda=0$.\n\nMaximize $g(\\lambda)$ over $\\lambda\\leq 0$. For $\\lambda0$,\n$$\ng'(\\lambda) = \\frac{d}{d\\lambda}\\big(-4\\lambda+2\\lambda\\ln(-\\lambda)\\big) = -4 + 2\\big(\\ln(-\\lambda)+1\\big) = 2\\ln(-\\lambda)-2,\n$$\nand\n$$\ng''(\\lambda)=\\frac{d}{d\\lambda}\\big(2\\ln(-\\lambda)-2\\big)=\\frac{2}{\\lambda}0 \\quad \\text{for } \\lambda0,\n$$\nso $g$ is strictly concave on its domain, as expected for a dual function. Setting $g'(\\lambda)=0$ gives\n$$\n2\\ln(-\\lambda)-2=0 \\quad \\Rightarrow \\quad \\ln(-\\lambda)=1 \\quad \\Rightarrow \\quad -\\lambda=\\exp(1),\n$$\nhence the unique maximizer is $\\lambda^{*}=-\\exp(1)$. The optimal dual value is\n$$\ng(\\lambda^{*})=-4\\lambda^{*}+2\\lambda^{*}\\ln(-\\lambda^{*})= -4\\big(-\\exp(1)\\big)+2\\big(-\\exp(1)\\big)\\cdot 1=4\\exp(1)-2\\exp(1)=2\\exp(1).\n$$\nBy strong duality, the optimal primal value equals the optimal dual value, so the minimum energy is $E_{\\text{min}}=2\\exp(1)$.\n\nFor completeness, the KKT conditions give the primal optimizer. Stationarity requires\n$$\n\\frac{\\partial L}{\\partial x}=\\exp(x)+\\lambda=0, \\quad \\frac{\\partial L}{\\partial y}=\\exp(y)+\\lambda=0,\n$$\nso $\\exp(x)=\\exp(y)=-\\lambda=\\exp(1)$, which implies $x=y=1$. This satisfies $x+y=2$ and yields $E(1,1)=\\exp(1)+\\exp(1)=2\\exp(1)$, matching the dual optimum.", "answer": "$$\\boxed{2\\exp(1)}$$", "id": "2221850"}, {"introduction": "Our final exercise introduces the crucial concept of inequality constraints, which are common in real-world engineering and robotics problems. Instead of finding the closest point on an infinite line, we now seek the closest point on a finite line segment [@problem_id:2221842]. This requires us to use the full Karush-Kuhn-Tucker (KKT) conditions, where the Lagrange multipliers (dual variables) do more than just help find the optimum. As we will see, their values tell us whether the solution lies in the interior of the segment or at one of its endpoints, revealing the deep connection between dual variables and the nature of the optimal solution.", "problem": "A point robot must travel along a straight line segment path in a two-dimensional Cartesian plane. The path begins at point $A=(1, 5)$ and ends at point $B=(5, 3)$. For a monitoring task, it is necessary to find the location on this path that is closest to a stationary sensor located at the origin $(0,0)$.\n\nThis geometric problem can be cast as a constrained optimization problem. A point on the segment can be parameterized by $P(t) = (1-t)A + tB$, where the parameter $t$ is constrained to the interval $[0, 1]$. The objective is to minimize the squared Euclidean distance from the origin to the point $P(t)$.\n\nLet $d_{min}^2$ be the minimum squared distance. In the standard formulation for such problems, we introduce Lagrange multipliers (dual variables) for the inequality constraints on $t$. Let $\\lambda_1$ be the Lagrange multiplier for the constraint $t \\ge 0$ (which can be written as $-t \\le 0$) and $\\lambda_2$ be the Lagrange multiplier for the constraint $t \\le 1$ (which can be written as $t-1 \\le 0$).\n\nDetermine the numerical values for the minimum squared distance $d_{min}^2$, and the optimal values of the corresponding Lagrange multipliers, $\\lambda_1$ and $\\lambda_2$. Provide your answer as three numbers for the tuple $(d_{min}^2, \\lambda_1, \\lambda_2)$.", "solution": "We parameterize the point on the segment by $P(t)=(1-t)A+tB$ with $A=(1,5)$ and $B=(5,3)$. Thus\n$$\nP(t)=(1,5)+t\\big((5,3)-(1,5)\\big)=(1,5)+t(4,-2)=(1+4t,\\,5-2t),\n$$\nwith the constraint $t\\in[0,1]$.\n\nThe squared Euclidean distance from the origin is the objective function\n$$\nf(t)=\\|P(t)\\|^{2}=(1+4t)^{2}+(5-2t)^{2}.\n$$\nExpanding,\n$$\n(1+4t)^{2}=1+8t+16t^{2},\\qquad (5-2t)^{2}=25-20t+4t^{2},\n$$\nso\n$$\nf(t)=\\big(1+8t+16t^{2}\\big)+\\big(25-20t+4t^{2}\\big)=20t^{2}-12t+26.\n$$\n\nWe cast this as a constrained optimization with inequality constraints $g_{1}(t)=-t\\le 0$ and $g_{2}(t)=t-1\\le 0$. The Lagrangian is\n$$\n\\mathcal{L}(t,\\lambda_{1},\\lambda_{2})=20t^{2}-12t+26+\\lambda_{1}(-t)+\\lambda_{2}(t-1),\n$$\nwith $\\lambda_{1}\\ge 0$ and $\\lambda_{2}\\ge 0$.\n\nThe Karush–Kuhn–Tucker conditions are:\n- Stationarity:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial t}=40t-12-\\lambda_{1}+\\lambda_{2}=0.\n$$\n- Primal feasibility: $0\\le t\\le 1$.\n- Dual feasibility: $\\lambda_{1}\\ge 0$, $\\lambda_{2}\\ge 0$.\n- Complementary slackness:\n$$\n\\lambda_{1}(-t)=0\\quad\\Longleftrightarrow\\quad \\lambda_{1}t=0,\\qquad \\lambda_{2}(t-1)=0.\n$$\n\nFirst find the unconstrained minimizer of $f(t)$ by setting $f'(t)=0$:\n$$\nf'(t)=40t-12=0\\quad\\Longrightarrow\\quad t^{*}=\\frac{12}{40}=\\frac{3}{10}.\n$$\nSince $t^{*}=\\frac{3}{10}\\in(0,1)$, both inequality constraints are inactive (strict): $-t^{*}0$ and $t^{*}-10$. By complementary slackness, this implies\n$$\n\\lambda_{1}^{*}=0,\\qquad \\lambda_{2}^{*}=0.\n$$\nWith these, the stationarity condition reduces to $40t-12=0$, confirming $t^{*}=\\frac{3}{10}$.\n\nEvaluate the minimum squared distance:\n$$\nd_{\\min}^{2}=f\\!\\left(\\frac{3}{10}\\right)=20\\left(\\frac{3}{10}\\right)^{2}-12\\left(\\frac{3}{10}\\right)+26=20\\cdot \\frac{9}{100}-\\frac{36}{10}+26=\\frac{9}{5}-\\frac{18}{5}+26=26-\\frac{9}{5}=\\frac{121}{5}.\n$$\n\nTherefore, the optimal tuple is $\\left(d_{\\min}^{2},\\lambda_{1}^{*},\\lambda_{2}^{*}\\right)=\\left(\\frac{121}{5},0,0\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{121}{5}  0  0\\end{pmatrix}}$$", "id": "2221842"}]}