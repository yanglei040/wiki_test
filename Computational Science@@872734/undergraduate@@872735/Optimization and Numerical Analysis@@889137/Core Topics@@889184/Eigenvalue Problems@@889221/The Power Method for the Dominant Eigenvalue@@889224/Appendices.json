{"hands_on_practices": [{"introduction": "The best way to understand an iterative algorithm is to perform the steps yourself. This first exercise provides a concrete scenario of population dynamics to guide you through the initial iterations of the power method [@problem_id:2218718]. By manually calculating the first two eigenvalue estimates, you will solidify your understanding of the core mechanics of the algorithm.", "problem": "A simplified ecological model describes the population dynamics of two interacting species. The state of the system, representing the populations of the two species at year $k$, is given by a vector $P_k = \\begin{pmatrix} p_{1,k} \\\\ p_{2,k} \\end{pmatrix}$. The population vector in the subsequent year, $P_{k+1}$, is determined by a linear transformation of the current year's vector, according to the equation $P_{k+1} = M P_k$. The matrix $M$ for this system is given by:\n$$\nM = \\begin{pmatrix} 3 & 2 \\\\ 1 & 4 \\end{pmatrix}\n$$\nThe long-term growth rate of the entire system is governed by the dominant eigenvalue of the matrix $M$. To estimate this value, one can use the power method.\n\nThe power method procedure is as follows:\n1. Start with an initial non-zero vector, $x_0$.\n2. For each step $k=1, 2, 3, \\dots$:\n   a. Compute the next vector in the sequence: $y_k = M x_{k-1}$.\n   b. The estimate for the dominant eigenvalue at this step, denoted $\\lambda^{(k)}$, is the component of $y_k$ that has the largest absolute value.\n   c. The normalized vector for the next iteration is calculated as $x_k = \\frac{y_k}{\\lambda^{(k)}}$.\n\nGiven an initial normalized population vector $x_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, perform two full iterations of the power method to find the second estimate of the dominant eigenvalue, $\\lambda^{(2)}$.\n\nExpress your answer for $\\lambda^{(2)}$ as an exact fraction.", "solution": "We apply the given power method to the matrix \n$$\nM=\\begin{pmatrix}3&2\\\\1&4\\end{pmatrix}\n$$\nstarting from the initial vector \n$$\nx_{0}=\\begin{pmatrix}1\\\\0\\end{pmatrix}.\n$$\n\nFirst iteration:\nCompute \n$$\ny_{1}=Mx_{0}=\\begin{pmatrix}3&2\\\\1&4\\end{pmatrix}\\begin{pmatrix}1\\\\0\\end{pmatrix}=\\begin{pmatrix}3\\\\1\\end{pmatrix}.\n$$\nThe largest absolute component of $y_{1}$ is $3$, hence \n$$\n\\lambda^{(1)}=3,\\quad x_{1}=\\frac{y_{1}}{\\lambda^{(1)}}=\\frac{1}{3}\\begin{pmatrix}3\\\\1\\end{pmatrix}=\\begin{pmatrix}1\\\\ \\frac{1}{3}\\end{pmatrix}.\n$$\n\nSecond iteration:\nCompute \n$$\ny_{2}=Mx_{1}=\\begin{pmatrix}3&2\\\\1&4\\end{pmatrix}\\begin{pmatrix}1\\\\ \\frac{1}{3}\\end{pmatrix}=\\begin{pmatrix}3+\\frac{2}{3}\\\\1+\\frac{4}{3}\\end{pmatrix}=\\begin{pmatrix}\\frac{11}{3}\\\\ \\frac{7}{3}\\end{pmatrix}.\n$$\nThe largest absolute component of $y_{2}$ is $\\frac{11}{3}$, so the second estimate of the dominant eigenvalue is\n$$\n\\lambda^{(2)}=\\frac{11}{3}.\n$$\nThis aligns with convergence toward the true dominant eigenvalue.", "answer": "$$\\boxed{\\frac{11}{3}}$$", "id": "2218718"}, {"introduction": "Why does the power method work? This practice provides a clear answer by applying the method to a simple diagonal matrix [@problem_id:2218720]. Because the eigenvectors of a diagonal matrix are aligned with the coordinate axes, the iterative process elegantly isolates the dominant eigenvalue almost immediately. This exercise is designed to build your intuition about the method's convergence properties.", "problem": "Consider the power method for finding the dominant eigenvalue of a matrix. Let $A$ be a $3 \\times 3$ diagonal matrix given by:\n$$A = \\begin{pmatrix} 3 & 0 & 0 \\\\ 0 & 8 & 0 \\\\ 0 & 0 & 5 \\end{pmatrix}$$\nWe apply the power method starting with the initial vector $x_0 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$. The iterative process is defined by the relation $x_{k+1} = \\frac{v_{k+1}}{\\|v_{k+1}\\|_\\infty}$, where $v_{k+1} = A x_k$ and $\\| \\cdot \\|_\\infty$ denotes the maximum norm (i.e., the maximum absolute value of the vector's components).\n\nAfter computing the first normalized iterate, $x_1$, we then compute the next unnormalized vector, $v_2 = A x_1$. What is the value of the largest component of the vector $v_2$?\n\nA. 3\n\nB. 5\n\nC. 8\n\nD. $\\frac{25}{8}$\n\nE. $\\frac{9}{8}$", "solution": "We apply the power method with infinity norm normalization. Given $A=\\operatorname{diag}(3,8,5)$ and $x_{0}=\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix}$, compute the first unnormalized iterate:\n$$v_{1}=A x_{0}=\\begin{pmatrix}3&0&0\\\\0&8&0\\\\0&0&5\\end{pmatrix}\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix}=\\begin{pmatrix}3\\\\8\\\\5\\end{pmatrix}.$$\nThe infinity norm is defined by $\\|y\\|_{\\infty}=\\max_{i}|y_{i}|$, hence\n$$\\|v_{1}\\|_{\\infty}=\\max\\{3,8,5\\}=8.$$\nNormalize to obtain\n$$x_{1}=\\frac{v_{1}}{\\|v_{1}\\|_{\\infty}}=\\begin{pmatrix}\\frac{3}{8}\\\\1\\\\\\frac{5}{8}\\end{pmatrix}.$$\nNext compute the second unnormalized iterate:\n$$v_{2}=A x_{1}=\\begin{pmatrix}3&0&0\\\\0&8&0\\\\0&0&5\\end{pmatrix}\\begin{pmatrix}\\frac{3}{8}\\\\1\\\\\\frac{5}{8}\\end{pmatrix}=\\begin{pmatrix}\\frac{9}{8}\\\\8\\\\\\frac{25}{8}\\end{pmatrix}.$$\nThe largest component of $v_{2}$ is\n$$\\max\\left\\{\\frac{9}{8},\\,8,\\,\\frac{25}{8}\\right\\}=8.$$\nThus the correct option is C.", "answer": "$$\\boxed{C}$$", "id": "2218720"}, {"introduction": "The power method is remarkably robust, but what are its theoretical limits? This exercise explores a crucial edge case: what happens if our initial vector is perfectly orthogonal to the dominant eigenvector [@problem_id:2218731]? By contrasting an ideal, infinite-precision scenario with a realistic one involving tiny numerical errors, you will discover both a theoretical 'failure' of the method and the reason for its practical success and stability.", "problem": "The Power Method is an iterative algorithm used to find the eigenvalue of a matrix with the largest absolute value, known as the dominant eigenvalue. The standard (un-normalized) iteration is defined by $v_{k+1} = A v_k$, starting from an initial vector $v_0$. The corresponding estimate for the dominant eigenvalue at step $k$, denoted as the Rayleigh quotient, is given by $R(A, v_k) = \\frac{v_k^T A v_k}{v_k^T v_k}$. The method is said to converge to an eigenvalue $\\lambda$ if $\\lim_{k \\to \\infty} R(A, v_k) = \\lambda$.\n\nConsider the real symmetric matrix $A$ given by:\n$$\nA = \\begin{pmatrix} 7.5 & 2.5 & 0 \\\\ 2.5 & 7.5 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n$$\nIt is known that the eigenvalues of this matrix are $\\lambda_1 = 10$, $\\lambda_2 = 5$, and $\\lambda_3 = 1$. The corresponding un-normalized eigenvectors are $u_1 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$, $u_2 = \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}$, and $u_3 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}$.\n\nYou are to analyze the behavior of the Power Method under two different scenarios for the initial vector.\n\n1.  **Ideal Scenario**: Suppose the Power Method is applied to matrix $A$ starting with the initial vector $v_0 = \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\end{pmatrix}$. Assuming all calculations are performed with perfect, infinite precision, determine the value to which the Rayleigh quotient will converge. Let this limiting value be $\\lambda_I$.\n\n2.  **Realistic Scenario**: In practice, computers use finite precision arithmetic, which introduces small round-off errors. We can model this by considering an initial vector that is slightly perturbed from the one in the ideal scenario. Let the new initial vector be $v'_0 = v_0 + \\epsilon u_1 = \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\end{pmatrix} + \\epsilon \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$, where $\\epsilon$ is a very small, non-zero constant (e.g., $\\epsilon \\approx 10^{-16}$). Determine the value to which the Rayleigh quotient will converge for this perturbed initial vector, assuming the iteration runs for a sufficiently large number of steps. Let this limiting value be $\\lambda_{II}$.\n\nDetermine the ordered pair $(\\lambda_I, \\lambda_{II})$.", "solution": "Because $A$ is real symmetric, the given eigenvectors $u_{1},u_{2},u_{3}$ corresponding to the distinct eigenvalues $10,5,1$ are mutually orthogonal, and satisfy $A u_{i}=\\lambda_{i} u_{i}$. Let $c_{i}=u_{i}^{T}u_{i}$ for $i\\in\\{1,2,3\\}$.\n\nFor any initial vector $v_{0}$, the un-normalized power iteration produces\n$$\nv_{k}=A^{k}v_{0}=\\sum_{i=1}^{3}\\alpha_{i}\\lambda_{i}^{k}u_{i},\n$$\nwhere $v_{0}=\\sum_{i=1}^{3}\\alpha_{i}u_{i}$. The Rayleigh quotient is\n$$\nR(A,v_{k})=\\frac{v_{k}^{T}A v_{k}}{v_{k}^{T}v_{k}}.\n$$\nUsing orthogonality and symmetry,\n$$\nv_{k}^{T}A v_{k}=\\sum_{i=1}^{3}\\alpha_{i}^{2}\\lambda_{i}^{2k}\\,u_{i}^{T}A u_{i}\n=\\sum_{i=1}^{3}\\alpha_{i}^{2}\\lambda_{i}^{2k}\\lambda_{i}\\,c_{i}\n=\\sum_{i=1}^{3}\\alpha_{i}^{2}\\lambda_{i}^{2k+1}c_{i},\n$$\nand\n$$\nv_{k}^{T}v_{k}=\\sum_{i=1}^{3}\\alpha_{i}^{2}\\lambda_{i}^{2k}c_{i}.\n$$\n\nIdeal scenario: $v_{0}=u_{2}+u_{3}$, so $\\alpha_{2}=1$, $\\alpha_{3}=1$, $\\alpha_{1}=0$. Then\n$$\nv_{k}=5^{k}u_{2}+1^{k}u_{3},\n$$\nand\n$$\nR(A,v_{k})=\\frac{5^{2k+1}c_{2}+1\\cdot c_{3}}{5^{2k}c_{2}+c_{3}}\n=\\frac{5+\\dfrac{c_{3}}{5^{2k}c_{2}}}{1+\\dfrac{c_{3}}{5^{2k}c_{2}}}\\to 5 \\quad\\text{as }k\\to\\infty.\n$$\nThus $\\lambda_{I}=5$.\n\nRealistic scenario: $v_{0}'=v_{0}+\\epsilon u_{1}=u_{2}+u_{3}+\\epsilon u_{1}$ with $0\\neq\\epsilon$ very small. Then\n$$\nv_{k}'=5^{k}u_{2}+1^{k}u_{3}+\\epsilon 10^{k}u_{1},\n$$\nand\n$$\nR(A,v_{k}')=\\frac{\\epsilon^{2}10^{2k+1}c_{1}+5^{2k+1}c_{2}+1\\cdot c_{3}}{\\epsilon^{2}10^{2k}c_{1}+5^{2k}c_{2}+c_{3}}.\n$$\nDividing numerator and denominator by $\\epsilon^{2}10^{2k}c_{1}$ gives\n$$\nR(A,v_{k}')=\\frac{10+\\dfrac{5^{2k+1}c_{2}}{\\epsilon^{2}10^{2k}c_{1}}+\\dfrac{c_{3}}{\\epsilon^{2}10^{2k}c_{1}}}{1+\\dfrac{5^{2k}c_{2}}{\\epsilon^{2}10^{2k}c_{1}}+\\dfrac{c_{3}}{\\epsilon^{2}10^{2k}c_{1}}}\\to 10 \\quad\\text{as }k\\to\\infty,\n$$\nsince $\\left(\\dfrac{5}{10}\\right)^{2k}\\to 0$. Thus $\\lambda_{II}=10$.\n\nTherefore, $(\\lambda_{I},\\lambda_{II})=(5,10)$.", "answer": "$$\\boxed{\\begin{pmatrix} 5 & 10 \\end{pmatrix}}$$", "id": "2218731"}]}