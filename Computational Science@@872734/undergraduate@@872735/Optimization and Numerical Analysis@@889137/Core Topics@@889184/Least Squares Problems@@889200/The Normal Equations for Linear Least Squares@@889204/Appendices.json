{"hands_on_practices": [{"introduction": "The most fundamental application of the normal equations is finding the \"line of best fit\" for a set of data points. This practice provides a direct, hands-on opportunity to translate raw data into a system of linear equations and solve for the optimal parameters of a simple linear model. By working through this exercise [@problem_id:2218054], you will solidify your understanding of how to construct and solve the normal equations, a core skill in data analysis and empirical science.", "problem": "An experimental physicist is studying a phenomenon and has collected four data points $(x_i, y_i)$ which are: $(0, 5)$, $(1, 2)$, $(2, -1)$, and $(3, 10)$. The physicist wishes to model the relationship between $x$ and $y$ using a straight line of the form $y = mx + c$.\n\nTo determine the optimal values for the slope $m$ and the y-intercept $c$, the physicist uses the method of least squares. This method finds the line that minimizes the sum of the squared vertical distances from each data point to the line. This sum, often denoted as $S$, is given by the expression $S = \\sum_{i=1}^{4} (y_i - (mx_i + c))^2$.\n\nYour task is to calculate the exact values of $m$ and $c$ for this line of best fit. Express your answers as rational numbers (i.e., fractions). Present your final answer as a single row matrix containing the values of $m$ and $c$, in that specific order.", "solution": "We seek $m$ and $c$ that minimize the least-squares objective $S=\\sum_{i=1}^{4}\\left(y_{i}-(m x_{i}+c)\\right)^{2}$ for the data points $(0,5)$, $(1,2)$, $(2,-1)$, $(3,10)$. The normal equations are obtained by setting the partial derivatives with respect to $m$ and $c$ to zero:\n$$\n\\frac{\\partial S}{\\partial m}=-2\\sum_{i=1}^{4}x_{i}\\left(y_{i}-(m x_{i}+c)\\right)=0,\\quad \\frac{\\partial S}{\\partial c}=-2\\sum_{i=1}^{4}\\left(y_{i}-(m x_{i}+c)\\right)=0.\n$$\nThese yield the linear system\n$$\nm\\sum_{i=1}^{4}x_{i}^{2}+c\\sum_{i=1}^{4}x_{i}=\\sum_{i=1}^{4}x_{i}y_{i},\\quad m\\sum_{i=1}^{4}x_{i}+4c=\\sum_{i=1}^{4}y_{i}.\n$$\nCompute the required sums from the data:\n$$\n\\sum_{i=1}^{4}x_{i}=0+1+2+3=6,\\quad \\sum_{i=1}^{4}y_{i}=5+2+(-1)+10=16,\n$$\n$$\n\\sum_{i=1}^{4}x_{i}^{2}=0^{2}+1^{2}+2^{2}+3^{2}=14,\\quad \\sum_{i=1}^{4}x_{i}y_{i}=0\\cdot 5+1\\cdot 2+2\\cdot(-1)+3\\cdot 10=30.\n$$\nSubstituting into the normal equations gives\n$$\n14m+6c=30,\\quad 6m+4c=16.\n$$\nEliminate $c$ by multiplying the first equation by $2$ and the second by $3$:\n$$\n28m+12c=60,\\quad 18m+12c=48.\n$$\nSubtract to obtain $10m=12$, hence\n$$\nm=\\frac{6}{5}.\n$$\nSubstitute into $6m+4c=16$ to get\n$$\n6\\cdot \\frac{6}{5}+4c=16\\;\\Rightarrow\\; \\frac{36}{5}+4c=16\\;\\Rightarrow\\; 4c=16-\\frac{36}{5}=\\frac{44}{5}\\;\\Rightarrow\\; c=\\frac{11}{5}.\n$$\nTherefore, the least-squares line is $y=\\frac{6}{5}x+\\frac{11}{5}$, and the requested row matrix is $\\begin{pmatrix}\\frac{6}{5} & \\frac{11}{5}\\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{6}{5} & \\frac{11}{5} \\end{pmatrix}}$$", "id": "2218054"}, {"introduction": "A robust understanding of any method includes knowing its limitations. This exercise shifts our focus from application to a critical theoretical requirement: the linear independence of the model's basis functions. This conceptual problem [@problem_id:2218008] illustrates a common pitfall where the normal equations cannot be solved for a unique solution. Understanding this failure case is crucial for designing valid and effective models in practice.", "problem": "A junior analyst is tasked with modeling the relationship between a controlled variable $x$ and a measured response $y$. The analyst collects $m$ data points $(x_i, y_i)$ for $i=1, \\dots, m$. It is known that $m > 2$ and not all $x_i$ values are zero. The proposed model is a linear combination of two basis functions, $f_1(x)$ and $f_2(x)$, such that the predicted response is $\\hat{y} = c_1 f_1(x) + c_2 f_2(x)$. The analyst chooses the functions $f_1(x) = x$ and $f_2(x) = 2x$.\n\nTo find the optimal coefficients $c_1$ and $c_2$, the analyst uses the method of linear least squares, which aims to find the coefficient vector $\\mathbf{c} = [c_1, c_2]^T$ that minimizes the sum of squared errors between the observed and predicted responses. This is achieved by solving the normal equations, $A^T A \\mathbf{c} = A^T \\mathbf{y}$, where $A$ is the design matrix constructed from the basis functions and the data.\n\nUpon trying to solve this system numerically, the software returns an error indicating that the matrix $A^T A$ is singular and a unique solution for the coefficients cannot be found. Which of the following options provides the correct mathematical explanation for this failure?\n\nA. The number of data points, $m$, is too small to uniquely determine the two coefficients $c_1$ and $c_2$.\n\nB. The model is flawed because the problem is inherently non-linear and cannot be solved with linear least squares.\n\nC. The basis functions $f_1(x) = x$ and $f_2(x) = 2x$ are linearly dependent.\n\nD. The measured response values, $y_i$, are all zero, leading to a trivial solution that the software cannot handle.\n\nE. The transpose operation is invalid because the design matrix $A$ is not square.", "solution": "We form the design matrix by evaluating the basis functions at each data point. For each $i \\in \\{1,\\dots,m\\}$, the $i$-th row of $A$ is\n$$\n\\begin{pmatrix} f_{1}(x_{i}) & f_{2}(x_{i}) \\end{pmatrix}=\\begin{pmatrix} x_{i} & 2x_{i} \\end{pmatrix}.\n$$\nThus, the two columns of $A$ are\n$$\na_{1}=\\begin{pmatrix} x_{1} \\\\ \\vdots \\\\ x_{m} \\end{pmatrix}, \\qquad a_{2}=\\begin{pmatrix} 2x_{1} \\\\ \\vdots \\\\ 2x_{m} \\end{pmatrix}=2a_{1}.\n$$\nTherefore, the columns are linearly dependent, so $\\operatorname{rank}(A)=1<2$. In linear least squares, the normal equations are\n$$\nA^{T}A\\,\\mathbf{c}=A^{T}\\mathbf{y}.\n$$\nA necessary and sufficient condition for a unique least-squares solution is that $A$ has full column rank, equivalently that $A^{T}A$ is invertible. Since the columns of $A$ are linearly dependent, $A^{T}A$ is singular.\n\nThis can be seen explicitly by computing $A^{T}A$. Let $S=\\sum_{i=1}^{m} x_{i}^{2}$. Then\n$$\nA^{T}A=\\begin{pmatrix}\n\\sum_{i=1}^{m} x_{i}^{2} & \\sum_{i=1}^{m} 2x_{i}^{2} \\\\\n\\sum_{i=1}^{m} 2x_{i}^{2} & \\sum_{i=1}^{m} 4x_{i}^{2}\n\\end{pmatrix}\n=\\begin{pmatrix}\nS & 2S \\\\\n2S & 4S\n\\end{pmatrix}\n=S\\begin{pmatrix}\n1 & 2 \\\\\n2 & 4\n\\end{pmatrix}.\n$$\nIts determinant is\n$$\n\\det(A^{T}A)=S^{2}\\left(1\\cdot 4-2\\cdot 2\\right)=S^{2}\\cdot 0=0,\n$$\nso $A^{T}A$ is singular. Because not all $x_{i}$ are zero, $S>0$, but the determinant is still zero due to the column dependence.\n\nTherefore, the correct explanation is that the basis functions $f_{1}(x)=x$ and $f_{2}(x)=2x$ are linearly dependent, causing $A$ to be rank-deficient and $A^{T}A$ to be singular. The other options are incorrect: having $m>2$ does not guarantee uniqueness without independent columns (A is false), the model is linear in the coefficients so linear least squares is appropriate (B is false), $y_{i}=0$ does not cause singularity of $A^{T}A$ (D is false), and the transpose operation is valid for non-square $A$ (E is false).", "answer": "$$\\boxed{C}$$", "id": "2218008"}, {"introduction": "The power of linear least squares extends beyond fitting simple straight lines. By using appropriate basis functions, we can model more complex, non-linear relationships, such as the quadratic behavior explored in this problem. This practice [@problem_id:2218043] demonstrates how to apply the normal equations to polynomial regression, showing the method's versatility in capturing more intricate data patterns while maintaining a linear algebraic framework.", "problem": "An engineer is calibrating a novel cryogenic temperature sensor. The sensor's electrical resistance, $R$, is hypothesized to vary quadratically with the absolute temperature, $T$. The proposed model is $R(T) = c_{0} + c_{1} T + c_{2} T^{2}$, where $c_0$, $c_1$, and $c_2$ are the calibration coefficients to be determined. To find these coefficients, a series of measurements are taken, yielding the following four data points $(T_i, R_i)$:\n\n- $(10.0 \\text{ K}, 125.0 \\text{ } \\Omega)$\n- $(20.0 \\text{ K}, 180.0 \\text{ } \\Omega)$\n- $(30.0 \\text{ K}, 250.0 \\text{ } \\Omega)$\n- $(40.0 \\text{ K}, 350.0 \\text{ } \\Omega)$\n\nYour task is to determine the best-fit values for the coefficients by solving the linear least squares problem that minimizes the sum of the squared differences between the measured resistances and the model's predictions.\n\nFind the value of the linear coefficient, $c_1$. Express your answer in units of $\\Omega/\\text{K}$, rounded to four significant figures.", "solution": "We model the resistance as $R(T)=c_{0}+c_{1}T+c_{2}T^{2}$ and determine $c_{0},c_{1},c_{2}$ in the linear least squares sense. Using the normal equations for least squares with design matrix rows $[1,\\,T_{i},\\,T_{i}^{2}]$ and data $R_{i}$, we form $(X^{\\top}X)\\mathbf{c}=X^{\\top}\\mathbf{y}$. Define the sums $S_{k}=\\sum_{i}T_{i}^{k}$ for $k=0,1,2,3,4$ and $b_{0}=\\sum_{i}R_{i}$, $b_{1}=\\sum_{i}T_{i}R_{i}$, $b_{2}=\\sum_{i}T_{i}^{2}R_{i}$. For the data $(T_{i},R_{i})\\in\\{(10,125),(20,180),(30,250),(40,350)\\}$, these are\n$$\nS_{0}=4,\\quad S_{1}=100,\\quad S_{2}=3000,\\quad S_{3}=100000,\\quad S_{4}=3540000,\n$$\n$$\nb_{0}=905,\\quad b_{1}=26350,\\quad b_{2}=869500.\n$$\nThus the normal equations are\n$$\n\\begin{bmatrix}\n4 & 100 & 3000\\\\\n100 & 3000 & 100000\\\\\n3000 & 100000 & 3540000\n\\end{bmatrix}\n\\begin{bmatrix}\nc_{0}\\\\\nc_{1}\\\\\nc_{2}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n905\\\\\n26350\\\\\n869500\n\\end{bmatrix}.\n$$\nWriting these componentwise,\n$$\n\\begin{aligned}\n&4c_{0}+100c_{1}+3000c_{2}=905\\quad\\text{(1)},\\\\\n&100c_{0}+3000c_{1}+100000c_{2}=26350\\quad\\text{(2)},\\\\\n&3000c_{0}+100000c_{1}+3540000c_{2}=869500\\quad\\text{(3)}.\n\\end{aligned}\n$$\nFrom (1), solve for $c_{0}$:\n$$\nc_{0}=\\frac{905-100c_{1}-3000c_{2}}{4}=226.25-25c_{1}-750c_{2}.\n$$\nSubstitute this into (2) and (3). For (2):\n$$\n100(226.25-25c_{1}-750c_{2})+3000c_{1}+100000c_{2}=26350,\n$$\nwhich simplifies to\n$$\n500c_{1}+25000c_{2}=3725\\;\\Rightarrow\\;20c_{1}+1000c_{2}=149.\\quad\\text{(A)}\n$$\nFor (3):\n$$\n3000(226.25-25c_{1}-750c_{2})+100000c_{1}+3540000c_{2}=869500,\n$$\nwhich simplifies to\n$$\n25000c_{1}+1290000c_{2}=190750\\;\\Rightarrow\\;100c_{1}+5160c_{2}=763.\\quad\\text{(B)}\n$$\nSolve (A) and (B). Multiply (A) by $5$ and subtract from (B):\n$$\n\\bigl(100c_{1}+5160c_{2}\\bigr)-\\bigl(100c_{1}+5000c_{2}\\bigr)=763-745\\;\\Rightarrow\\;160c_{2}=18,\n$$\nso\n$$\nc_{2}=\\frac{18}{160}=\\frac{9}{80}=0.1125.\n$$\nSubstitute into (A):\n$$\n20c_{1}+1000\\cdot\\frac{9}{80}=149\\;\\Rightarrow\\;20c_{1}+112.5=149\\;\\Rightarrow\\;20c_{1}=36.5\\;\\Rightarrow\\;c_{1}=\\frac{73}{40}=1.825.\n$$\nRounded to four significant figures in the required units, the linear coefficient is $1.825$.", "answer": "$$\\boxed{1.825}$$", "id": "2218043"}]}