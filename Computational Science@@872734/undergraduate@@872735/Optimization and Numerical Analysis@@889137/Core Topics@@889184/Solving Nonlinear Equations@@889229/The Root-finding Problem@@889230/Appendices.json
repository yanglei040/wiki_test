{"hands_on_practices": [{"introduction": "The bisection method is celebrated for its simplicity and guaranteed convergence, making it a cornerstone of numerical analysis. This first practice [@problem_id:2219715] moves beyond a simple application and challenges you to think like an engineer. Instead of just narrowing the interval containing the root, you will determine the number of iterations needed to ensure the result is \"good enough\" in a practical senseâ€”by controlling the error in the function's output value.", "problem": "A boutique manufacturer of specialized drone components has modeled its weekly profit, $P(x)$, in US dollars, as a function of the number of components produced and sold, $x$. The profit function is given by:\n$$P(x) = -0.000001x^3 + 0.002x^2 + 15x - 5000$$\nThe company's analysts have determined that a break-even point, where the profit is zero, exists for a production level within the interval $[300, 400]$. To optimize their production targets, managers need to determine this break-even quantity. They plan to use the bisection method on the initial interval $[300, 400]$ to find an approximation, $x_{approx}$, for the true break-even quantity, $x^*$.\n\nWhat is the minimum number of bisection iterations, $n$, required to guarantee that the absolute value of the profit at the approximated break-even point, $|P(x_{approx})|$, is less than $0.01$?", "solution": "We are given the continuous cubic profit function\n$$P(x)=-1 \\times 10^{-6}x^{3}+2 \\times 10^{-3}x^{2}+15x-5000,$$\nwith a root in the interval $\\left[300,400\\right]$. The bisection method halves the interval length at each iteration. Let $[a,b]=[300,400]$, so the initial length is $L_{0}=b-a=100$. After $n$ iterations, the interval length is\n$$L_{n}=\\frac{100}{2^{n}},$$\nand the midpoint $x_{\\text{approx}}$ satisfies the standard bisection error bound in $x$:\n$$|x_{\\text{approx}}-x^{*}|\\leq \\frac{L_{n}}{2}=\\frac{100}{2^{n+1}}.$$\n\nTo ensure a bound on the function value, apply the Mean Value Theorem. There exists $c$ between $x_{\\text{approx}}$ and $x^{*}$ such that\n$$|P(x_{\\text{approx}})-P(x^{*})|=|P'(c)|\\,|x_{\\text{approx}}-x^{*}|.$$\nSince $P(x^*)=0$, for any $M \\geq \\max_{x \\in [300,400]}|P'(x)|$, we have\n$$|P(x_{\\text{approx}})| \\leq M\\,|x_{\\text{approx}}-x^{*}|.$$\nTherefore, it suffices to enforce\n$$|x_{\\text{approx}}-x^{*}|\\leq \\frac{0.01}{M}.$$\n\nCompute a suitable $M$. Differentiate:\n$$P'(x)=-3 \\times 10^{-6}x^{2}+4 \\times 10^{-3}x+15,$$\n$$P''(x)=-6 \\times 10^{-6}x+4 \\times 10^{-3}.$$\nSet $P''(x)=0$ to locate extrema of $P'$:\n$$-6 \\times 10^{-6}x+4 \\times 10^{-3}=0 \\;\\Rightarrow\\; x=\\frac{4 \\times 10^{-3}}{6 \\times 10^{-6}}=\\frac{2}{3} \\times 10^{3}=\\frac{2000}{3},$$\nwhich lies outside $\\left[300,400\\right]$. Since $P''(x)0$ on $\\left[300,400\\right]$, $P'(x)$ is increasing there. Hence\n$$M=\\max_{x \\in [300,400]}|P'(x)|=P'(400)=-3 \\times 10^{-6}\\cdot 160000+4 \\times 10^{-3}\\cdot 400+15=-0.48+1.6+15=16.12.$$\n\nTo guarantee $|P(x_{\\text{approx}})|0.01$, it is sufficient that\n$$\\frac{100}{2^{n+1}} \\leq \\frac{0.01}{16.12} \\;\\;\\Longleftrightarrow\\;\\; 2^{n+1} \\geq \\frac{100 \\cdot 16.12}{0.01}=161200.$$\nSince $2^{17}=131072161200$ and $2^{18}=262144 \\geq 161200$, the smallest integer value for $n+1$ is $18$.\nThis implies the smallest integer value for $n$ is $17$.", "answer": "$$\\boxed{17}$$", "id": "2219715"}, {"introduction": "While Newton's method often converges with impressive speed, its behavior is not always so straightforward and depends critically on the initial guess. This exercise [@problem_id:2219740] invites you to explore one of the more fascinating failure modes of the method: periodic cycles. By finding an initial point that traps the iteration in a 2-cycle, you will gain a deeper appreciation for the rich and complex dynamics underlying this powerful algorithm.", "problem": "Newton's method is an iterative algorithm for finding successively better approximations to the roots (or zeroes) of a real-valued function $f(x)$. The iteration is given by the formula:\n$$x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}$$\nwhere $x_0$ is an initial guess.\n\nWhile this method can converge rapidly to a root, certain initial guesses can lead to other behaviors, such as divergence or periodic cycles. Consider the function $f(x) = x^3 - 2x + 2$. There exists at least one non-zero initial guess, $x_0$, for which Newton's method does not converge to a root but instead enters a periodic cycle of period 2. A cycle of period 2 means that the sequence of iterates becomes $x_0, x_1, x_0, x_1, \\dots$ for two distinct values $x_0$ and $x_1$.\n\nFind one such non-zero real number $x_0$ that initiates a 2-cycle.", "solution": "Let the function be $f(x) = x^3 - 2x + 2$. Its derivative is $f'(x) = 3x^2 - 2$.\nThe Newton's method iteration function, $N(x)$, is given by:\n$$N(x) = x - \\frac{f(x)}{f'(x)} = x - \\frac{x^3 - 2x + 2}{3x^2 - 2}$$\nSimplifying this expression:\n$$N(x) = \\frac{x(3x^2 - 2) - (x^3 - 2x + 2)}{3x^2 - 2} = \\frac{3x^3 - 2x - x^3 + 2x - 2}{3x^2 - 2} = \\frac{2x^3 - 2}{3x^2 - 2}$$\n\nA 2-cycle consists of two distinct points, let's call them $a$ and $b$, such that the iterates alternate between them. This means that starting with $x_0=a$, we get $x_1=b$, and then $x_2=a$, and so on. Mathematically, this is described by the system of equations:\n1. $b = N(a)$\n2. $a = N(b)$\n3. $a \\neq b$\n\nUsing the expression for $N(x)$, we can write this system as:\n1. $b = \\frac{2a^3 - 2}{3a^2 - 2}$\n2. $a = \\frac{2b^3 - 2}{3b^2 - 2}$\n\nThese can be rewritten as:\n1. $b(3a^2 - 2) = 2a^3 - 2$\n2. $a(3b^2 - 2) = 2b^3 - 2$\n\nWhich expands to:\n1. $3a^2b - 2b = 2a^3 - 2$\n2. $3ab^2 - 2a = 2b^3 - 2$\n\nTo solve this system, we can subtract the second equation from the first:\n$(3a^2b - 2b) - (3ab^2 - 2a) = (2a^3 - 2) - (2b^3 - 2)$\n$3ab(a - b) + 2(a - b) = 2(a^3 - b^3)$\n\nSince the points are distinct, $a \\neq b$, so $(a-b) \\neq 0$. We can divide the entire equation by $(a-b)$:\n$3ab + 2 = 2 \\frac{a^3 - b^3}{a - b}$\nUsing the identity $a^3 - b^3 = (a-b)(a^2 + ab + b^2)$, we get:\n$3ab + 2 = 2(a^2 + ab + b^2)$\n$3ab + 2 = 2a^2 + 2ab + 2b^2$\nRearranging the terms, we find a relationship between $a$ and $b$:\n$$2a^2 - ab + 2b^2 - 2 = 0$$\n\nLet $S = a+b$ and $P = ab$. We can rewrite the above equation in terms of $S$ and $P$.\nWe know $a^2+b^2 = (a+b)^2 - 2ab = S^2 - 2P$.\nSo, $2(a^2+b^2) - ab - 2 = 0$ becomes:\n$2(S^2 - 2P) - P - 2 = 0$\n$2S^2 - 4P - P - 2 = 0$\n$2S^2 - 5P - 2 = 0$\nFrom this, we can express $P$ in terms of $S$:\n$$P = \\frac{2S^2 - 2}{5}$$\n\nNow we need a second equation relating $S$ and $P$. Let's add the two original expanded equations:\n$(3a^2b - 2b) + (3ab^2 - 2a) = (2a^3 - 2) + (2b^3 - 2)$\n$3ab(a+b) - 2(a+b) = 2(a^3+b^3) - 4$\nSubstitute $S$ and $P$, and use the identity $a^3+b^3 = (a+b)(a^2-ab+b^2) = S(S^2-2P-P) = S(S^2-3P)$:\n$3PS - 2S = 2S(S^2 - 3P) - 4$\n$3PS - 2S = 2S^3 - 6PS - 4$\n$9PS - 2S = 2S^3 - 4$\n$$2S^3 - 9PS + 2S - 4 = 0$$\n\nNow substitute the expression for $P$ into this second equation:\n$2S^3 - 9\\left(\\frac{2S^2 - 2}{5}\\right)S + 2S - 4 = 0$\nMultiply by 5 to clear the denominator:\n$10S^3 - 9S(2S^2 - 2) + 10S - 20 = 0$\n$10S^3 - 18S^3 + 18S + 10S - 20 = 0$\n$-8S^3 + 28S - 20 = 0$\nDivide by -4:\n$$2S^3 - 7S + 5 = 0$$\n\nThis is a cubic equation for $S = a+b$. We can find its rational roots by testing divisors of the constant term (5) divided by divisors of the leading coefficient (2). Let's test $S=1$:\n$2(1)^3 - 7(1) + 5 = 2 - 7 + 5 = 0$.\nSo, $S=1$ is a root. This means $(S-1)$ is a factor of the polynomial.\nUsing polynomial division, we find:\n$(S-1)(2S^2 + 2S - 5) = 0$.\nThe roots for $S$ are $S=1$ and the roots of $2S^2+2S-5=0$. Let's focus on the simple root $S=1$.\n\nIf $S = a+b = 1$, we can find the corresponding product $P = ab$:\n$P = \\frac{2S^2 - 2}{5} = \\frac{2(1)^2 - 2}{5} = \\frac{0}{5} = 0$.\nSo we have $a+b=1$ and $ab=0$. The two numbers $a$ and $b$ are the roots of the quadratic equation $t^2 - St + P = 0$:\n$t^2 - (1)t + 0 = 0$\n$t(t-1) = 0$\nThe roots are $t=0$ and $t=1$.\nThus, the two points in the 2-cycle are 0 and 1. They are distinct, as required.\n\nThe problem asks for a non-zero initial guess $x_0$ that starts this cycle. We can choose either point of the cycle as the initial guess. If we choose $x_0=0$, the next iterate is $x_1=1$. If we choose $x_0=1$, the next iterate is $x_1=0$.\nSince the problem asks for a non-zero value for $x_0$, we select $x_0=1$.\n\nLet's verify this result.\nIf $x_0=1$:\n$x_1 = N(1) = \\frac{2(1)^3 - 2}{3(1)^2 - 2} = \\frac{2-2}{3-2} = \\frac{0}{1} = 0$.\nNow we compute the next iterate, $x_2$, from $x_1=0$:\n$x_2 = N(0) = \\frac{2(0)^3 - 2}{3(0)^2 - 2} = \\frac{-2}{-2} = 1$.\nSince $x_2=x_0=1$, the sequence is $1, 0, 1, 0, \\dots$, which is a 2-cycle.\nTherefore, a valid non-zero initial guess is 1.", "answer": "$$\\boxed{1}$$", "id": "2219740"}, {"introduction": "Many iterative root-finding techniques can be seen as special cases of a more general framework known as fixed-point iteration. This final practice [@problem_id:2219690] focuses on the central question for any such method: will it converge? You will analyze a general iterative scheme and determine the precise conditions on a parameter $\\alpha$ that guarantee convergence, applying the fundamental convergence theorem for fixed-point iterations.", "problem": "An engineer is using a numerical method to find the solution to the equation $e^{x} = 3$. They choose a fixed-point iteration scheme defined by the recurrence relation:\n$$\nx_{k+1} = x_{k} - \\alpha (e^{x_{k}} - 3)\n$$\nwhere $k$ is the iteration index ($k=0, 1, 2, \\dots$) and $\\alpha$ is a real-valued constant parameter used to control the convergence of the method. For the iteration to converge to the true root of the equation, the parameter $\\alpha$ must lie within a specific range.\n\nAssuming the initial guess $x_0$ is sufficiently close to the root, which of the following represents the open interval of values for $\\alpha$ that guarantees convergence?\n\nA. $(0, 1/3)$\n\nB. $(0, 2/3)$\n\nC. $(-1/3, 1/3)$\n\nD. $(0, 1)$\n\nE. $(-2/3, 2/3)$", "solution": "We seek the fixed point of the iteration $x_{k+1}=g(x_{k})$ with\n$$\ng(x)=x-\\alpha\\left(\\exp(x)-3\\right).\n$$\nThe fixed point $x^{\\ast}$ satisfies $\\exp(x^{\\ast})=3$, hence $x^{\\ast}=\\ln(3)$.\n\nA sufficient condition for local convergence of fixed-point iteration, assuming $x_{0}$ is sufficiently close to $x^{\\ast}$ and $g$ is continuously differentiable near $x^{\\ast}$, is the contraction condition\n$$\n|g'(x^{\\ast})|1.\n$$\nCompute the derivative:\n$$\ng'(x)=1-\\alpha\\exp(x),\n$$\nso at the fixed point,\n$$\ng'(x^{\\ast})=1-\\alpha\\exp(x^{\\ast})=1-3\\alpha.\n$$\nThe convergence condition becomes\n$$\n|1-3\\alpha|1.\n$$\nThis is equivalent to the double inequality\n$$\n-11-3\\alpha1.\n$$\nFrom the left inequality: $-11-3\\alpha\\implies -2-3\\alpha\\implies 23\\alpha\\implies \\alpha\\frac{2}{3}$.\nFrom the right inequality: $1-3\\alpha1\\implies -3\\alpha0\\implies 3\\alpha0\\implies \\alpha0$.\nCombining gives\n$$\n0\\alpha\\frac{2}{3},\n$$\nwhich corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "2219690"}]}