{"hands_on_practices": [{"introduction": "The secant method is celebrated for its efficient, superlinear convergence. To build a strong foundational understanding, we first examine its performance in the simplest non-trivial scenario: finding the root of a linear function. This exercise explores this special case, where the secant line constructed by the method is identical to the function itself, leading to a surprising and insightful result. By analyzing this situation, you will gain a deeper geometric intuition for the algorithm and clarify why the concept of an *asymptotic* convergence rate is not always applicable. [@problem_id:2163466]", "problem": "The secant method is a numerical root-finding algorithm. For a function $f(x)$, given two initial distinct approximations $x_0$ and $x_1$, the next approximation $x_{n+1}$ is calculated using the iterative formula:\n$$x_{n+1} = x_n - f(x_n) \\frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})}$$\nConsider the application of the secant method to find the root of a linear function $f(x) = ax + b$, where $a$ and $b$ are non-zero real constants. The process starts with two distinct initial guesses, $x_0$ and $x_1$, neither of which is the actual root of the function.\n\nWhich of the following statements most accurately describes the performance of the secant method in this specific scenario?\n\nA. The method converges to the exact root in a single iteration, and its order of convergence is the golden ratio, $\\phi \\approx 1.618$.\n\nB. The method converges to the exact root in a single iteration, and the concept of an asymptotic order of convergence is not applicable.\n\nC. The method exhibits quadratic convergence (order of 2), finding the root much faster than its typical superlinear rate.\n\nD. The method fails to converge because the second derivative, $f''(x)$, is zero, which means the error term in the convergence analysis becomes undefined.\n\nE. The method converges linearly (order of 1) and requires a number of iterations that depends on the initial guesses $x_0$ and $x_1$.", "solution": "We apply the secant iteration to the linear function $f(x)=ax+b$ with $a \\neq 0$ and two distinct initial guesses $x_{0} \\neq x_{1}$:\n$$\nx_{n+1}=x_{n}-f(x_{n})\\frac{x_{n}-x_{n-1}}{f(x_{n})-f(x_{n-1})}.\n$$\nFirst, compute the difference in function values for a linear $f$:\n$$\nf(x_{n})-f(x_{n-1})=(ax_{n}+b)-(ax_{n-1}+b)=a(x_{n}-x_{n-1}).\n$$\nSubstitute this into the secant formula for $n=1$ to obtain $x_{2}$:\n$$\nx_{2}=x_{1}-(ax_{1}+b)\\frac{x_{1}-x_{0}}{a(x_{1}-x_{0})}\n=x_{1}-\\frac{ax_{1}+b}{a}\n=x_{1}-x_{1}-\\frac{b}{a}\n=-\\frac{b}{a}.\n$$\nThe exact root $x^{\\ast}$ of $f(x)=ax+b$ satisfies $ax^{\\ast}+b=0$, hence $x^{\\ast}=-\\frac{b}{a}$. Therefore $x_{2}=x^{\\ast}$, i.e., the secant method reaches the exact root in a single iteration after the initial pair. Once $x_{2}$ is exact, subsequent iterates remain at the root since $f(x_{2})=0$ yields\n$$\nx_{3}=x_{2}-0\\cdot\\frac{x_{2}-x_{1}}{0-f(x_{1})}=x_{2}.\n$$\nRegarding the order of convergence, the asymptotic order is defined via the behavior of the nonzero errors $e_{n}=x_{n}-x^{\\ast}$ as $n$ grows. Here, the error becomes exactly zero after one iteration ($e_{2}=0$), so there is no asymptotic error regime to characterize. Consequently, the concept of asymptotic order of convergence is not applicable in this case.\n\nThus, the correct choice is that the method converges to the exact root in a single iteration, and the notion of asymptotic order does not apply.", "answer": "$$\\boxed{B}$$", "id": "2163466"}, {"introduction": "It is a well-known result that the secant method's order of convergence is the golden ratio, $\\phi \\approx 1.618$. This value, however, is derived under standard assumptions, including that the function's second derivative is non-zero at the root. This next practice challenges you to investigate what happens when this assumption is violated. This exploration reveals that the convergence rate is not an immutable property of the algorithm, but rather a dynamic interplay between the method and the function's local behavior, which can sometimes lead to even faster convergence. [@problem_id:2163406]", "problem": "The secant method is a numerical algorithm used to find a root $r$ of a function $f(x)$, where $f(r)=0$. Starting with two initial guesses $x_0$ and $x_1$, the method iteratively generates a sequence of approximations $\\{x_n\\}$ using the recurrence relation:\n$$x_{n+1} = x_n - f(x_n) \\frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})}$$\nThe order of convergence, $p$, of a method is defined by the asymptotic relationship $|\\epsilon_{n+1}| \\approx C |\\epsilon_n|^p$, where $\\epsilon_n = x_n - r$ is the error at the $n$-th iteration and $C$ is a constant. For the secant method, under the standard assumptions that the root $r$ is simple (i.e., $f'(r) \\neq 0$) and the second derivative is non-zero at the root (i.e., $f''(r) \\neq 0$), the order of convergence is famously known to be the golden ratio, $p = \\phi = \\frac{1+\\sqrt{5}}{2} \\approx 1.618$.\n\nConsider a special case where the function $f(x)$ still has a simple root $r$ (so $f'(r) \\neq 0$), but its second derivative vanishes at the root, i.e., $f''(r)=0$. Furthermore, assume that the third derivative is non-zero, $f'''(r) \\neq 0$.\n\nWhat is the new order of convergence for the secant method under these specific conditions?\n\nA. The order of convergence is 1 (linear convergence).\nB. The order of convergence remains the golden ratio, $\\phi \\approx 1.618$.\nC. The order of convergence is 2 (quadratic convergence).\nD. The order of convergence is 3 (cubic convergence).\nE. The method no longer converges to the root.", "solution": "Let $r$ be a simple root, $f'(r)\\neq 0$, with $f''(r)=0$ and $f'''(r)\\neq 0$. Define the errors $e_{n}=x_{n}-r$. Denote $A_{n}=f(x_{n})$ and $A_{n-1}=f(x_{n-1})$. The secant update can be written as\n$$\ne_{n+1}=x_{n+1}-r=e_{n}-A_{n}\\frac{e_{n}-e_{n-1}}{A_{n}-A_{n-1}}=\\frac{A_{n}e_{n-1}-A_{n-1}e_{n}}{A_{n}-A_{n-1}}.\n$$\nExpand $f$ about $r$ up to third order. Let $\\alpha=f'(r)$, $\\beta=f''(r)$, $\\gamma=f'''(r)$. Then\n$$\nA_{n}=\\alpha e_{n}+\\frac{1}{2}\\beta e_{n}^{2}+\\frac{1}{6}\\gamma e_{n}^{3}+O(e_{n}^{4}),\\quad\nA_{n-1}=\\alpha e_{n-1}+\\frac{1}{2}\\beta e_{n-1}^{2}+\\frac{1}{6}\\gamma e_{n-1}^{3}+O(e_{n-1}^{4}).\n$$\nCompute the numerator:\n$$\nA_{n}e_{n-1}-A_{n-1}e_{n}\n=\\frac{1}{2}\\beta e_{n}e_{n-1}(e_{n}-e_{n-1})+\\frac{1}{6}\\gamma e_{n}e_{n-1}(e_{n}^{2}-e_{n-1}^{2})+O(e^{5}).\n$$\nCompute the denominator:\n$$\nA_{n}-A_{n-1}=(e_{n}-e_{n-1})\\Big(\\alpha+\\frac{1}{2}\\beta(e_{n}+e_{n-1})+\\frac{1}{6}\\gamma(e_{n}^{2}+e_{n}e_{n-1}+e_{n-1}^{2})+O(e^{3})\\Big).\n$$\nTherefore,\n$$\ne_{n+1}=e_{n}e_{n-1}\\cdot\\frac{\\frac{1}{2}\\beta+\\frac{1}{6}\\gamma(e_{n}+e_{n-1})+O(e^{2})}{\\alpha+\\frac{1}{2}\\beta(e_{n}+e_{n-1})+\\frac{1}{6}\\gamma(e_{n}^{2}+e_{n}e_{n-1}+e_{n-1}^{2})+O(e^{3})}.\n$$\nUnder the given condition $\\beta=0$ and $\\gamma\\neq 0$, this reduces to\n$$\ne_{n+1}=\\frac{\\gamma}{6\\alpha}\\,e_{n}e_{n-1}(e_{n}+e_{n-1})+O(e^{4}).\n$$\nAs $n$ grows, if the order $p>1$, then $|e_{n}|\\ll |e_{n-1}|$, so the dominant contribution in $e_{n}+e_{n-1}$ is $e_{n-1}$. Hence\n$$\n|e_{n+1}|\\approx C\\,|e_{n}|\\,|e_{n-1}|^{2},\n$$\nfor some constant $C=\\left|\\frac{\\gamma}{6\\alpha}\\right|$. Assume the asymptotic model $|e_{n}|\\approx K\\,|e_{n-1}|^{p}$ and $|e_{n+1}|\\approx \\Lambda\\,|e_{n}|^{p}$. Then\n$$\n|e_{n+1}|\\approx C K\\,|e_{n-1}|^{p+2}\\quad\\text{and}\\quad |e_{n+1}|\\approx \\Lambda K^{p}\\,|e_{n-1}|^{p^{2}}.\n$$\nEquating exponents gives\n$$\np^{2}=p+2,\n$$\nwhose positive root is $p=2$. Therefore, the secant method has quadratic convergence in this case, matching option C.", "answer": "$$\\boxed{C}$$", "id": "2163406"}, {"introduction": "Theoretical analysis provides us with expected convergence rates, but in practical applications, how do we verify these predictions from the numerical output of our code? This final practice demonstrates a powerful technique for empirically measuring the order of convergence from computational data. You will learn how to linearize the error relationship by using a logarithmic scale, allowing you to extract the convergence rate directly from the slope of the resulting line. This is a fundamental skill for validating and analyzing the performance of numerical algorithms in computational science. [@problem_id:2163458]", "problem": "A numerical analyst is investigating the performance of the secant method for finding the root of a complex, non-linear function $f(x) = 0$. Let $x_k$ be the estimate of the root at the $k$-th iteration and $r$ be the true root. The error at this iteration is defined as $e_k = x_k - r$.\n\nFor a root-finding algorithm with an order of convergence $\\alpha$, it is known that for large $k$, the absolute errors are related by\n$$|e_{k+1}| \\approx C |e_k|^\\alpha$$\nwhere $C$ is a constant that depends on the function $f(x)$ but not on the iteration number $k$.\n\nTo empirically determine the order of convergence, the analyst plots $\\ln|e_{k+1}|$ on the vertical axis against $\\ln|e_k|$ on the horizontal axis. For sufficiently converged iterations, the data points form a straight line. From this line, the analyst picks two representative data points, P1 and P2, corresponding to two different pairs of consecutive iterations. The coordinates of these points are:\nP1: $(-9.50, -15.45)$\nP2: $(-15.45, -25.07)$\n\nBased on these two data points, calculate the empirical order of convergence, $\\alpha$. Round your final answer to three significant figures.", "solution": "We are given the asymptotic error relation for an order-$\\alpha$ method:\n$$|e_{k+1}| \\approx C |e_k|^{\\alpha}.$$\nTaking the natural logarithm of both sides gives\n$$\\ln|e_{k+1}| \\approx \\ln C + \\alpha \\ln|e_k|.$$\nThis is a linear relation of the form $y = b + \\alpha x$ with $y = \\ln|e_{k+1}|$ and $x = \\ln|e_k|$, so the slope of the straight line on the plot of $\\ln|e_{k+1}|$ versus $\\ln|e_k|$ equals the order of convergence $\\alpha$.\n\nUsing the two given points P1: $(-9.50,-15.45)$ and P2: $(-15.45,-25.07)$, the slope is\n$$\\alpha = \\frac{y_{2} - y_{1}}{x_{2} - x_{1}} = \\frac{-25.07 - (-15.45)}{-15.45 - (-9.50)} = \\frac{-9.62}{-5.95} = \\frac{9.62}{5.95}.$$\nComputing the quotient,\n$$\\alpha \\approx 1.616806\\ldots,$$\nwhich, rounded to three significant figures, is\n$$\\alpha \\approx 1.62.$$", "answer": "$$\\boxed{1.62}$$", "id": "2163458"}]}