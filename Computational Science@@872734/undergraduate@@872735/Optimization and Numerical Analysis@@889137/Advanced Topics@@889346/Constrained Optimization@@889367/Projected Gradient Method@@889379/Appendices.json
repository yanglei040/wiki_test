{"hands_on_practices": [{"introduction": "To build a solid understanding of the projected gradient method, we begin with the simplest possible scenario: optimizing a function of a single variable within an interval. This exercise demonstrates the core two-step process and introduces the intuitive concept of projection as \"clipping\" a value to stay within a feasible range, revealing how the algorithm behaves when an iterate is at a boundary. [@problem_id:2194842]", "problem": "A simple robotic actuator's control parameter, denoted by $x$, is being optimized to minimize a cost function. The cost function is given by $f(x) = (x - 5)^2$. Due to physical limitations, the control parameter $x$ must lie within the closed interval $[-1, 1]$.\n\nAn engineer decides to use the projected gradient descent method to find the optimal parameter value. The update rule for this method is given by $x_{k+1} = P_{\\mathcal{C}}(x_k - \\alpha \\nabla f(x_k))$, where $\\mathcal{C}$ is the feasible set, $\\alpha$ is the step size, and $P_{\\mathcal{C}}(y)$ is the Euclidean projection of a point $y$ onto the set $\\mathcal{C}$. For a one-dimensional interval $\\mathcal{C} = [a, b]$, the projection is defined as $P_{[a, b]}(y) = \\max(a, \\min(y, b))$.\n\nThe engineer uses a fixed step size of $\\alpha = 0.1$. Two separate optimization runs are initiated.\n- Run A starts from the initial point $x_0^{(A)} = -1$.\n- Run B starts from the initial point $x_0^{(B)} = 1$.\n\nCalculate the value of the parameter after the first iteration, $x_1$, for both runs. Present your answer as a pair of decimal numbers, $(x_1^{(A)}, x_1^{(B)})$.", "solution": "We are given the cost function $f(x) = (x - 5)^{2}$ with feasible set $\\mathcal{C} = [-1, 1]$. The projected gradient descent update is\n$$\nx_{k+1} = P_{[-1,1]}\\left(x_{k} - \\alpha \\nabla f(x_{k})\\right),\n$$\nwith $\\alpha = 0.1$ and $P_{[-1,1]}(y) = \\max(-1, \\min(y, 1))$.\n\nFirst compute the gradient. Since $f(x) = (x - 5)^{2}$, we have\n$$\n\\nabla f(x) = \\frac{d}{dx}(x - 5)^{2} = 2(x - 5).\n$$\nThe unprojected update becomes\n$$\ny_{k} = x_{k} - \\alpha \\nabla f(x_{k}) = x_{k} - 0.1 \\cdot 2(x_{k} - 5) = x_{k} - 0.2 x_{k} + 1 = 0.8 x_{k} + 1.\n$$\n\nRun A starts at $x_{0}^{(A)} = -1$. Thus,\n$$\ny_{0}^{(A)} = 0.8(-1) + 1 = -0.8 + 1 = 0.2,\n$$\nand since $0.2 \\in [-1, 1]$, the projection gives $x_{1}^{(A)} = P_{[-1,1]}(0.2) = 0.2$.\n\nRun B starts at $x_{0}^{(B)} = 1$. Thus,\n$$\ny_{0}^{(B)} = 0.8(1) + 1 = 1.8,\n$$\nand since $1.8 > 1$, the projection gives $x_{1}^{(B)} = P_{[-1,1]}(1.8) = 1$.\n\nTherefore, the pair after the first iteration is $(0.2, 1)$.", "answer": "$$\\boxed{\\begin{pmatrix}0.2 & 1\\end{pmatrix}}$$", "id": "2194842"}, {"introduction": "Moving into two dimensions, we can visualize the projected gradient method in action with a common geometric constraintâ€”a disk. This practice problem uses the analogy of a tethered drone to provide a clear, physical intuition for how an infeasible point is projected back to the closest point on the boundary of a feasible region. [@problem_id:2194905]", "problem": "A small autonomous drone operates in a two-dimensional plane. Its control system is designed to navigate it towards a target located at the coordinates $(5, 5)$. The drone's performance is measured by a cost function, $f(x_1, x_2) = (x_1 - 5)^2 + (x_2 - 5)^2$, which represents the squared Euclidean distance from its current position $(x_1, x_2)$ to the target. The drone is physically tethered to a central pylon at the origin $(0, 0)$ by a flexible cable of length 1, meaning its position must always satisfy the condition $x_1^2 + x_2^2 \\le 1$.\n\nThe drone updates its position once every second according to a two-stage navigation algorithm.\n1.  **Desired Move Calculation:** First, it calculates the direction of the steepest decrease of the cost function at its current position. It then determines a desired next position by moving from its current position in this direction by a distance proportional to the steepness, governed by a step-size parameter $\\alpha = 0.1$.\n2.  **Safety Correction:** If this desired position is outside the reach of its tether, a safety protocol is triggered, which instantly pulls the drone to the closest point on the boundary of its circular operational area (i.e., the circle with radius 1 centered at the origin). If the desired position is within the tether's reach, no correction is needed.\n\nIf the drone starts at the origin, $x^{(0)} = (0, 0)$, determine its exact coordinates $(x_1, x_2)$ after the first full update cycle.", "solution": "The problem asks for the position of the drone after one iteration of a specific update algorithm. Let's translate the described process into a mathematical formulation.\n\nThe drone's position at step $k$ is denoted by $x^{(k)} = (x_1^{(k)}, x_2^{(k)})$. The objective is to minimize the cost function $f(x_1, x_2) = (x_1 - 5)^2 + (x_2 - 5)^2$, subject to the constraint that the drone remains within the unit disk, $C = \\{(x_1, x_2) \\in \\mathbb{R}^2 \\mid x_1^2 + x_2^2 \\le 1\\}$. The initial position is $x^{(0)} = (0, 0)$ and the step-size is $\\alpha = 0.1$.\n\nThe algorithm described is the projected gradient method. The update rule is $x^{(k+1)} = P_C(x^{(k)} - \\alpha \\nabla f(x^{(k)}))$, where $P_C$ is the projection operator onto the feasible set $C$.\n\n**Step 1: Compute the gradient of the cost function.**\nThe direction of steepest descent is the negative of the gradient of the cost function, $-\\nabla f(x_1, x_2)$. First, we find the gradient $\\nabla f(x_1, x_2)$.\n$$\n\\nabla f(x_1, x_2) = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\right)\n$$\nThe partial derivatives are:\n$$\n\\frac{\\partial f}{\\partial x_1} = \\frac{\\partial}{\\partial x_1} \\left( (x_1 - 5)^2 + (x_2 - 5)^2 \\right) = 2(x_1 - 5)\n$$\n$$\n\\frac{\\partial f}{\\partial x_2} = \\frac{\\partial}{\\partial x_2} \\left( (x_1 - 5)^2 + (x_2 - 5)^2 \\right) = 2(x_2 - 5)\n$$\nSo, the gradient is $\\nabla f(x_1, x_2) = (2(x_1 - 5), 2(x_2 - 5))$.\n\n**Step 2: Perform the \"Desired Move Calculation\" (gradient descent step).**\nThis step calculates an intermediate point, let's call it $y^{(1)}$, before the safety correction.\n$$\ny^{(1)} = x^{(0)} - \\alpha \\nabla f(x^{(0)})\n$$\nFirst, evaluate the gradient at the starting position $x^{(0)} = (0, 0)$:\n$$\n\\nabla f(0, 0) = (2(0 - 5), 2(0 - 5)) = (-10, -10)\n$$\nNow, calculate $y^{(1)}$ with $\\alpha = 0.1$:\n$$\ny^{(1)} = (0, 0) - 0.1 \\times (-10, -10) = (0,0) - (-1, -1) = (1, 1)\n$$\nThis point $y^{(1)} = (1, 1)$ is the drone's desired next position before the safety check.\n\n**Step 3: Perform the \"Safety Correction\" (projection step).**\nWe must check if $y^{(1)}$ is within the feasible set $C$, which is defined by $x_1^2 + x_2^2 \\le 1$.\nFor $y^{(1)} = (1, 1)$, we have $1^2 + 1^2 = 2$. Since $2 > 1$, the point $y^{(1)}$ is outside the allowed circular area. The safety protocol is triggered.\n\nThe protocol moves the drone to the closest point on the boundary of the unit circle. This is equivalent to projecting the point $y^{(1)}$ onto the set $C$. For a point $y$ outside the unit disk, its projection onto the disk is found by normalizing the vector, i.e., dividing the vector by its Euclidean norm.\n$$\nx^{(1)} = P_C(y^{(1)}) = \\frac{y^{(1)}}{\\|y^{(1)}\\|_2}\n$$\nFirst, we find the norm of $y^{(1)} = (1, 1)$:\n$$\n\\|y^{(1)}\\|_2 = \\sqrt{1^2 + 1^2} = \\sqrt{2}\n$$\nNow, we compute the new position $x^{(1)}$:\n$$\nx^{(1)} = \\frac{(1, 1)}{\\sqrt{2}} = \\left( \\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}} \\right)\n$$\nTo rationalize the denominator, we multiply the numerator and denominator by $\\sqrt{2}$:\n$$\nx^{(1)} = \\left( \\frac{1 \\cdot \\sqrt{2}}{\\sqrt{2} \\cdot \\sqrt{2}}, \\frac{1 \\cdot \\sqrt{2}}{\\sqrt{2} \\cdot \\sqrt{2}} \\right) = \\left( \\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2} \\right)\n$$\nThus, the exact coordinates of the drone after the first update cycle are $\\left(\\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2}\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} \\end{pmatrix}}$$", "id": "2194905"}, {"introduction": "Many real-world optimization problems, from engineering to machine learning, involve parameters that must be kept within specific bounds, forming a \"box\" constraint. This final practice extends the simple \"clipping\" projection from our first 1D example into two dimensions, showing how the method is applied in a practical controller tuning scenario. [@problem_id:2194880]", "problem": "An engineer is tuning a Proportional-Integral-Derivative (PID) controller for a robotic arm. For this particular application, the tuning process involves adjusting two parameters, let's call them $k_1$ and $k_2$, which are represented by the vector $x = (k_1, k_2)$.\n\nDue to hardware limitations and system stability requirements, these parameters must be kept within a specific range: $-1 \\le k_1 \\le 1$ and $-1 \\le k_2 \\le 1$. This defines the feasible set of parameters as $C = \\{ (k_1, k_2) \\in \\mathbb{R}^2 \\mid -1 \\le k_1 \\le 1, -1 \\le k_2 \\le 1 \\}$.\n\nThe performance of the controller is evaluated by a cost function $J(k_1, k_2)$ that measures factors like tracking error and energy consumption. The engineer has modeled this cost function as $J(x) = 2k_1^2 + k_2^2 - 3k_1 + 4k_2$. The goal is to find the parameter vector $x$ that minimizes this cost within the feasible set $C$.\n\nTo solve this optimization problem, the engineer employs the projected gradient method. The update rule for the parameter vector from an iteration $i$ to $i+1$ is given by:\n$$x_{i+1} = \\Pi_C(x_i - \\alpha \\nabla J(x_i))$$\nwhere $\\Pi_C(y)$ is the Euclidean projection of a point $y$ onto the set $C$, $\\nabla J(x_i)$ is the gradient of the cost function evaluated at $x_i$, and $\\alpha$ is the step size.\n\nStarting with an initial guess of $x_0 = (0, 0)$ and using a step size of $\\alpha = 0.5$, calculate the updated parameter vector $x_1$. Express your answer as a row matrix containing the two components of $x_1$.", "solution": "We are given the cost function $J(k_1,k_2) = 2k_1^2 + k_2^2 - 3k_1 + 4k_2$ and the feasible set $C = \\{(k_1,k_2) \\in \\mathbb{R}^{2} \\mid -1 \\leq k_1 \\leq 1,\\ -1 \\leq k_2 \\leq 1\\}$. The projected gradient update is\n$$\nx_{i+1} = \\Pi_{C}\\bigl(x_{i} - \\alpha \\nabla J(x_{i})\\bigr)\n$$\nFirst compute the gradient of $J$:\n$$\n\\nabla J(k_1,k_2) = \\left(\\frac{\\partial J}{\\partial k_1}, \\frac{\\partial J}{\\partial k_2}\\right) = (4k_1 - 3,\\ 2k_2 + 4).\n$$\nAt the initial point $x_{0} = (0,0)$, the gradient evaluates to\n$$\n\\nabla J(x_{0}) = (4 \\cdot 0 - 3,\\ 2 \\cdot 0 + 4) = (-3,\\ 4).\n$$\nWith step size $\\alpha = 0.5 = \\frac{1}{2}$, the unprojected gradient step is\n$$\nx_{0} - \\alpha \\nabla J(x_{0}) = (0,0) - \\frac{1}{2}(-3,4) = \\left(\\frac{3}{2},\\ -2\\right).\n$$\nThe projection $\\Pi_{C}$ onto the box $C = [-1,1]^{2}$ is obtained by clipping each component to the interval $[-1,1]$. Therefore,\n$$\n\\Pi_{C}\\left(\\frac{3}{2},\\ -2\\right) = (1,\\ -1).\n$$\nHence the updated parameter vector is\n$$\nx_{1} = (1,\\ -1).\n$$\nExpressed as a row matrix, this is\n$$\n\\begin{pmatrix}\n1 & -1\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}1 & -1\\end{pmatrix}}$$", "id": "2194880"}]}