{"hands_on_practices": [{"introduction": "Searching in structured data is a fundamental task in computer science. This practice explores an elegant and efficient algorithm for searching in a 2D matrix where elements are sorted in both rows and columns. Analyzing this algorithm [@problem_id:3207190] is an excellent exercise in reasoning about search space reduction, as each step cleverly eliminates a full row or column, allowing us to precisely determine its worst-case performance by analyzing the longest possible search path.", "problem": "Consider a rectangular two-dimensional matrix $A$ of real numbers of size $n \\times m$ with $n \\geq 1$ and $m \\geq 1$. Each row of $A$ is sorted in nondecreasing order from left to right, and each column of $A$ is sorted in nondecreasing order from top to bottom. A deterministic iterative search algorithm is defined to locate a given real key $x$ as follows: it starts at the top-right position $(i,j) = (1,m)$ and repeats the following step while the indices remain in bounds $1 \\leq i \\leq n$ and $1 \\leq j \\leq m$:\n- Compare $A[i,j]$ with $x$.\n- If $A[i,j] = x$, terminate and report success.\n- If $A[i,j]  x$, update $j \\leftarrow j - 1$.\n- If $A[i,j]  x$, update $i \\leftarrow i + 1$.\nIf the indices go out of bounds (specifically, if $i = n+1$ or $j = 0$), terminate and report that $x$ is not present.\n\nUsing only foundational definitions of iterative algorithms and comparison-based models from data structures and algorithms, derive from first principles the exact worst-case number of comparisons this algorithm performs as a function of $n$ and $m$ on any valid input matrix $A$ and any real key $x$. Your final answer must be a single closed-form analytical expression in terms of $n$ and $m$. No rounding or unit specification is required for this answer.", "solution": "The user wants me to analyze and determine the worst-case time complexity of a specific search algorithm on a 2D sorted matrix.\n\n### Step 1: Extract Givens\n- A rectangular two-dimensional matrix of real numbers, denoted as $A$.\n- The size of the matrix is $n \\times m$, where $n \\geq 1$ and $m \\geq 1$.\n- Each row of $A$ is sorted in nondecreasing order: $A[i,j] \\leq A[i, j+1]$ for all valid $i,j$.\n- Each column of $A$ is sorted in nondecreasing order: $A[i,j] \\leq A[i+1, j]$ for all valid $i,j$.\n- A real key to be located, denoted as $x$.\n- A deterministic iterative search algorithm is defined with the following rules:\n    - The search starts at the top-right position $(i,j) = (1,m)$.\n    - The algorithm iterates while the indices are in bounds: $1 \\leq i \\leq n$ and $1 \\leq j \\leq m$.\n    - Inside the loop, one comparison is made: $A[i,j]$ is compared with $x$.\n    - If $A[i,j] = x$, the algorithm terminates, reporting success.\n    - If $A[i,j]  x$, the column index is updated: $j \\leftarrow j - 1$.\n    - If $A[i,j]  x$, the row index is updated: $i \\leftarrow i + 1$.\n- The algorithm terminates with failure if the indices go out of bounds, which occurs if $i$ becomes $n+1$ or $j$ becomes $0$.\n- The objective is to derive the exact worst-case number of comparisons as a closed-form analytical expression in terms of $n$ and $m$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is subjected to validation before proceeding.\n\n- **Scientific Grounding**: The problem is well-grounded in the field of computer science, specifically in the analysis of algorithms. The data structure (a row-column sorted matrix) and the search algorithm are standard topics. The logic of the algorithm is sound: if $A[i,j]  x$, then for any $k \\geq i$, $A[k,j] \\ge A[i,j]  x$, so the entire remainder of column $j$ can be eliminated. If $A[i,j]  x$, then for any $k \\leq j$, $A[i,k] \\le A[i,j]  x$, so the entire remainder of row $i$ can be eliminated. The algorithm correctly implements this logic.\n- **Well-Posedness**: The problem is well-posed. The algorithm is deterministic, and the termination conditions are clear. The task is to find the maximum number of comparisons over all possible valid inputs (matrix $A$ and key $x$), which is a standard worst-case analysis. A unique, meaningful solution is expected to exist.\n- **Objectivity**: The problem is stated using precise, objective, and formal language. There are no subjective or ambiguous terms.\n- **Flaw Checklist**: The problem does not exhibit any of the listed flaws. It is not scientifically unsound, incomplete, contradictory, unrealistic, or ill-posed. It is a formal, verifiable problem in algorithm analysis.\n\n### Step 3: Verdict and Action\nThe problem is valid. A rigorous derivation of the solution will be provided.\n\n### Derivation\nThe goal is to determine the worst-case number of comparisons performed by the given iterative algorithm. The number of comparisons is equal to the number of iterations of the main loop, as exactly one comparison is performed per iteration. To find the worst-case, we must find the maximum possible number of iterations.\n\nLet the state of the algorithm at the beginning of each iteration be represented by the coordinates $(i,j)$ of the matrix cell being examined. The algorithm starts at $(i,j) = (1,m)$. In each step, the coordinates change from $(i,j)$ to either $(i+1, j)$ (a \"down\" move) or $(i, j-1)$ (a \"left\" move). The algorithm terminates when either the key $x$ is found, or the indices go out of bounds. The worst case occurs when the key is not found (or found at the very last step of the longest possible path), forcing the algorithm to run for the maximum number of steps.\n\nLet's analyze the path of the indices $(i,j)$. Let $k$ be the number of comparisons, which corresponds to $k$ iterations of the loop. Let $(i_t, j_t)$ be the indices at the beginning of iteration $t$, for $t = 1, 2, \\dots, k$.\nThe initial state is $(i_1, j_1) = (1,m)$.\n\nTo analyze the path length, we define a potential function (or an invariant-like quantity) $S$ based on the indices:\n$$S(i,j) = (i - 1) + (m - j)$$\nAt the start of the algorithm (beginning of iteration $t=1$), we are at $(i_1, j_1) = (1,m)$, so the initial value of $S$ is:\n$$S_1 = S(1,m) = (1 - 1) + (m - m) = 0$$\nNow, let's examine how $S$ changes at each step. Suppose at the beginning of iteration $t$, the state is $(i_t, j_t)$. The next state, $(i_{t+1}, j_{t+1})$, is determined by the comparison:\n1.  **Down move**: If $A[i_t, j_t]  x$, then $(i_{t+1}, j_{t+1}) = (i_t+1, j_t)$.\n    The new value of $S$ is $S_{t+1} = S(i_t+1, j_t) = ((i_t+1) - 1) + (m - j_t) = (i_t - 1) + (m - j_t) + 1 = S_t + 1$.\n2.  **Left move**: If $A[i_t, j_t]  x$, then $(i_{t+1}, j_{t+1}) = (i_t, j_t-1)$.\n    The new value of $S$ is $S_{t+1} = S(i_t, j_t-1) = (i_t - 1) + (m - (j_t-1)) = (i_t - 1) + (m - j_t) + 1 = S_t + 1$.\n\nIn every iteration, the value of $S$ increases by exactly $1$. Since $S_1 = 0$, at the beginning of the $k$-th iteration, the value of $S$ will be $S_k = k-1$.\nThe $k$-th comparison takes place at the coordinates $(i_k, j_k)$. Therefore, we have the relation:\n$$k - 1 = S(i_k, j_k) = (i_k - 1) + (m - j_k)$$\n$$k = i_k + m - j_k$$\nThe algorithm performs $k$ comparisons and then terminates. Termination occurs because the next computed indices, $(i_{k+1}, j_{k+1})$, fall outside the matrix bounds. This means either $i_{k+1} = n+1$ or $j_{k+1} = 0$.\nThis can only happen if the $k$-th comparison was performed at a cell $(i_k, j_k)$ on the boundary of the matrix:\n- If the next move is \"down\", causing termination, it must be that $i_k = n$. The move attempts to set $i_{k+1} = n+1$.\n- If the next move is \"left\", causing termination, it must be that $j_k = 1$. The move attempts to set $j_{k+1} = 0$.\n\nSo, the last cell visited, $(i_k, j_k)$, must satisfy either $i_k=n$ or $j_k=1$. We want to find the worst-case, which means we want to maximize $k$. We do this by maximizing the expression $k = i_k + m - j_k$ over all possible reachable terminal cells $(i_k, j_k)$.\n\nCase 1: The last cell visited is on the bottom row, i.e., $i_k=n$.\nThe number of comparisons is $k = n + m - j_k$. To maximize $k$, we must minimize $j_k$. The minimum possible value for the column index is $j_k=1$. This gives a maximum possible value for $k$:\n$$k_{max} = n + m - 1$$\nThis corresponds to the algorithm terminating at cell $(n,1)$.\n\nCase 2: The last cell visited is on the leftmost column, i.e., $j_k=1$.\nThe number of comparisons is $k = i_k + m - 1$. To maximize $k$, we must maximize $i_k$. The maximum possible value for the row index is $i_k=n$. This gives a maximum possible value for $k$:\n$$k_{max} = n + m - 1$$\nThis also corresponds to the algorithm terminating at cell $(n,1)$.\n\nBoth cases yield the same maximum value. The longest path for the search is any path from the top-right corner $(1,m)$ to the bottom-left corner $(n,1)$. Such a path requires a total of $(n-1)$ \"down\" moves and $(m-1)$ \"left\" moves. The total number of cells visited on such a path is $1 + (n-1) + (m-1) = n+m-1$. Since one comparison is made at each cell, the total number of comparisons is $n+m-1$.\n\nIt is possible to construct a matrix $A$ and choose a key $x$ that forces the algorithm to traverse such a path. For example, let $A[i,j] = 1$ for all cells on a path from $(1,m)$ to $(n,1)$, let $A[i,j] = 0$ for all cells \"below and to the left\" of this path, and let $A[i,j] = 2$ for all cells \"above and to the right\" of this path. A search for $x=1.5$ could then trace this path.\n\nTherefore, the exact worst-case number of comparisons is the length of the longest possible path, which is $n+m-1$.", "answer": "$$\\boxed{n+m-1}$$", "id": "3207190"}, {"introduction": "Truly efficient algorithms often come from a deep understanding of the data structures they operate on. This exercise examines a procedure for finding the maximum value within a min-heap, a data structure designed for efficient retrieval of the minimum value. This practice [@problem_id:3207269] teaches us to first analyze the properties of the data structure to constrain the problem, demonstrating that the maximum element must be a leaf node, which in turn drastically simplifies both the algorithm and its analysis.", "problem": "Consider a binary min-heap stored in an array $A[1], A[2], \\dots, A[n]$ for some integer $n \\geq 1$. A binary min-heap is a complete binary tree where every node value is less than or equal to the values of its children, and the standard array representation maps a node at index $i$ to its children at indices $2i$ and $2i+1$ whenever those indices are at most $n$. An iterative procedure is proposed to find the maximum element in the heap:\n- Initialize $m \\leftarrow A[k]$ where $k = \\left\\lfloor \\frac{n}{2} \\right\\rfloor + 1$ (the first leaf position in the array).\n- For each index $i$ from $k+1$ to $n$ in increasing order, perform the comparison “if $A[i]  m$ then update $m \\leftarrow A[i]$; otherwise leave $m$ unchanged.”\nAssume that the cost of the algorithm is measured solely by the number of key comparisons of the form “$A[i]  m$,” and that all other operations have zero cost. Using only the defining properties of binary heaps and their array representation, derive an exact closed-form expression, in terms of $n$, for the worst-case number of key comparisons performed by this algorithm over all valid heaps of size $n$. Your final answer must be a single analytic expression in $n$; do not give an inequality, asymptotic order, or a piecewise definition. No rounding is required.", "solution": "We begin from the core definitions of a binary min-heap and its array representation. A binary min-heap is a complete binary tree in which each node’s key is less than or equal to the keys of its children. The array representation places the root at index $1$ and, for any index $i$, places its children at indices $2i$ and $2i+1$ provided these indices are at most $n$. A node at index $i$ is internal if it has at least one child, which occurs exactly when $2i \\leq n$. Therefore, the set of internal nodes is precisely those indices $i$ with $1 \\leq i \\leq \\left\\lfloor \\frac{n}{2} \\right\\rfloor$. Conversely, the leaves are those indices $i$ with $i \\geq \\left\\lfloor \\frac{n}{2} \\right\\rfloor + 1$ up to $n$. Hence, the number of leaves $L$ in a heap of size $n$ is\n$$\nL = n - \\left\\lfloor \\frac{n}{2} \\right\\rfloor.\n$$\nNext, we argue that the maximum element of a min-heap must reside among the leaves. Consider any non-leaf node at index $i$. By the heap property, its child at index $2i$ (if it exists) satisfies $A[2i] \\geq A[i]$, and similarly $A[2i+1] \\geq A[i]$ if it exists. Following any path from an internal node to a leaf, the sequence of keys is non-decreasing. Therefore, for any internal node, there exists a leaf whose key is greater than or equal to that internal node’s key. Consequently, a maximum key cannot be strictly inside the set of internal nodes; it must be attained at a leaf.\n\nThe given iterative algorithm initializes $m$ to the key at the first leaf index $k = \\left\\lfloor \\frac{n}{2} \\right\\rfloor + 1$, and then scans the remaining leaves from $k+1$ through $n$, performing exactly one comparison per leaf scanned. There is no early termination condition; thus, regardless of the input arrangement of keys, the algorithm will perform exactly one comparison for each of the leaves after the first. Therefore, the exact number of key comparisons performed is\n$$\n\\text{comparisons} = L - 1 = \\left(n - \\left\\lfloor \\frac{n}{2} \\right\\rfloor\\right) - 1.\n$$\nWe can simplify this using the identity $\\left\\lceil \\frac{n}{2} \\right\\rceil = n - \\left\\lfloor \\frac{n}{2} \\right\\rfloor$, valid for all integers $n$. Substituting yields\n$$\n\\text{comparisons} = \\left\\lceil \\frac{n}{2} \\right\\rceil - 1.\n$$\nBecause the algorithm deterministically compares against each remaining leaf exactly once, this count is both the worst-case and the exact count for any valid heap of size $n$. Hence, the required exact closed-form expression in terms of $n$ is\n$$\n\\left\\lceil \\frac{n}{2} \\right\\rceil - 1.\n$$", "answer": "$$\\boxed{\\left\\lceil \\frac{n}{2} \\right\\rceil - 1}$$", "id": "3207269"}, {"introduction": "Analyzing algorithms on dynamic, pointer-based structures like linked lists requires careful attention to how state changes with each iteration. This problem presents an iterative algorithm for removing duplicate values from a sorted singly linked list. The challenge in this analysis [@problem_id:3207266] is that the primary loop pointer does not advance in every iteration, forcing us to identify a more subtle invariant to accurately count the total number of operations and prove the algorithm's linear time efficiency.", "problem": "Consider a singly linked list $L$ of $n$ nodes, where each node stores an integer key and a pointer to the next node. Assume the keys in $L$ are sorted in nondecreasing order, so all duplicate keys appear in consecutive nodes. The following iterative algorithm removes all duplicates, leaving exactly one node for each distinct key:\n\n- Let $x$ denote the head node of $L$.\n- While $x \\neq \\text{null}$ and $x.\\text{next} \\neq \\text{null}$:\n    - If $x.\\text{key} = x.\\text{next}.\\text{key}$, then set $x.\\text{next} := x.\\text{next}.\\text{next}$.\n    - Otherwise, set $x := x.\\text{next}$.\n\nAssume the standard unit-cost Random Access Machine (RAM) model in which each key comparison (such as $x.\\text{key} = x.\\text{next}.\\text{key}$) and each pointer assignment (such as $x := x.\\text{next}$ or $x.\\text{next} := x.\\text{next}.\\text{next}$) takes constant time, denoted $O(1)$. Under this model, derive from first principles a closed-form expression for the exact number of key comparisons the algorithm performs as a function of $n$, for any input instance consistent with the given assumptions. Then deduce from that count the tight asymptotic time complexity (in Big-Theta notation) of the algorithm as a function of $n$. Express your final answer as a single analytic expression in Big-Theta notation.", "solution": "The problem requires an analysis of a given iterative algorithm for removing duplicates from a sorted singly linked list. The analysis must first yield an exact closed-form expression for the number of key comparisons and then deduce the tight asymptotic time complexity in Big-Theta notation.\n\nLet the singly linked list be $L$, consisting of $n$ nodes. We denote the original nodes in sequence as $N_1, N_2, \\ldots, N_n$. Let $k_i$ be the key stored in node $N_i$. Since the list is sorted in nondecreasing order, we have $k_1 \\le k_2 \\le \\ldots \\le k_n$. The algorithm is as follows:\n1. Initialize a pointer $x$ to the head of the list, $N_1$.\n2. Loop while $x \\neq \\text{null}$ and $x.\\text{next} \\neq \\text{null}$.\n3. Inside the loop, compare $x.\\text{key}$ with $x.\\text{next}.\\text{key}$.\n   a. If they are equal, a duplicate is found. The node $x.\\text{next}$ is removed by setting $x.\\text{next} := x.\\text{next}.\\text{next}$. The pointer $x$ remains at its current position to check for further duplicates.\n   b. If they are not equal, there is no duplicate for the current key of $x$. The pointer $x$ is advanced to the next node by setting $x := x.\\text{next}$.\n\nThe primary task is to find the exact number of key comparisons. A key comparison $x.\\text{key} = x.\\text{next}.\\text{key}$ is performed exactly once in each iteration of the `while` loop. Therefore, the total number of key comparisons is equal to the total number of iterations of the loop.\n\nLet us analyze the number of loop iterations. The loop continues as long as $x.\\text{next} \\neq \\text{null}$. We will demonstrate that for any input list of size $n \\ge 1$, the loop executes exactly $n-1$ times.\nIf $n=0$, the list is empty, $x$ is initialized to $\\text{null}$, the loop condition $x \\neq \\text{null}$ is false, and $0$ comparisons are made.\nIf $n=1$, $x$ points to $N_1$, but $x.\\text{next}$ is $\\text{null}$. The loop condition $x.\\text{next} \\neq \\text{null}$ is false, and $0$ comparisons are made. Note that $n-1 = 0$ in this case.\n\nNow, consider $n \\ge 2$. Let's trace the node that $x.\\text{next}$ points to at the beginning of each iteration. Let the iteration number be $i$, starting from $i=1$.\n- **Iteration $i=1$**: Initially, $x$ points to $N_1$. Thus, $x.\\text{next}$ points to $N_2$. The loop condition is true, and the first comparison is made.\n- **Start of Iteration $i=2$**: After the first iteration, we analyze the location of $x.\\text{next}$.\n  - Case 1 ($k_1 = k_2$): The assignment $x.\\text{next} := x.\\text{next}.\\text{next}$ is executed. Since $x$ was $N_1$ and $x.\\text{next}$ was $N_2$, the new $x.\\text{next}$ for $N_1$ becomes $N_3$. The pointer $x$ itself does not change. So, at the start of the second iteration, $x$ is still $N_1$ and $x.\\text{next}$ points to $N_3$.\n  - Case 2 ($k_1 \\neq k_2$): The assignment $x := x.\\text{next}$ is executed. Since $x$ was $N_1$ and $x.\\text{next}$ was $N_2$, $x$ now points to $N_2$. The new $x.\\text{next}$ is the successor of $N_2$ in the original list, which is $N_3$.\nIn both cases, at the start of the second iteration, the node being considered at $x.\\text{next}$ is $N_3$.\n\nWe can generalize this observation. Let's propose an invariant: At the beginning of iteration $i$ (where $1 \\le i \\le n-1$), the pointer $x.\\text{next}$ refers to the original node $N_{i+1}$.\n- **Base Case ($i=1$)**: This is true, as shown above.\n- **Inductive Step**: Assume the invariant holds for iteration $i$, where $1 \\le i  n-1$. So at the start of iteration $i$, $x.\\text{next}$ points to $N_{i+1}$. A comparison is made.\n  - If $x.\\text{key} = x.\\text{next}.\\text{key}$, $x$ remains unchanged, and $x.\\text{next}$ is updated to point to $N_{i+2}$.\n  - If $x.\\text{key} \\neq x.\\text{next}.\\text{key}$, $x$ is updated to point to $N_{i+1}$, so its `next` pointer refers to $N_{i+2}$.\nIn both outcomes, at the start of iteration $i+1$, the node referenced by $x.\\text{next}$ is $N_{(i+1)+1} = N_{i+2}$. The invariant holds.\n\nThis inductive argument shows that the loop iterates for $i=1, 2, \\ldots, n-1$. In the $(n-1)$-th iteration, $x.\\text{next}$ points to $N_n$. After this iteration:\n- If $x.\\text{key} = N_n.\\text{key}$: $x.\\text{next}$ is set to $N_n.\\text{next}$, which is $\\text{null}$.\n- If $x.\\text{key} \\neq N_n.\\text{key}$: $x$ is set to $N_n$, and its `next` pointer is $\\text{null}$.\nIn either scenario, the loop condition $x.\\text{next} \\neq \\text{null}$ will be false before the next potential iteration. Therefore, the loop terminates after exactly $n-1$ iterations.\n\nThe number of key comparisons, $C(n)$, for $n \\ge 1$ is exactly $n-1$. For $n=0$, $C(0)=0$. The closed-form expression covering all non-negative $n$ is $C(n) = \\max(0, n-1)$. Assuming non-trivial list sizes ($n \\ge 1$), the count is $n-1$.\n\nNext, we deduce the tight asymptotic time complexity, $T(n)$. We use the standard unit-cost RAM model, where each elementary operation costs $O(1)$.\nThe algorithm consists of:\n1. An initial pointer assignment ($x := \\text{head}$): This takes constant time, $O(1)$.\n2. The `while` loop:\n   - Loop condition checks: The conditions $x \\neq \\text{null}$ and $x.\\text{next} \\neq \\text{null}$ are checked at the start of each iteration and one final time when the loop terminates. For $n \\ge 1$, this amounts to $n$ checks in total. Each check costs $O(1)$, so the total cost for checks is $n \\times O(1) = O(n)$.\n   - Loop body: The loop executes $n-1$ times for $n \\ge 1$. In each iteration, the algorithm performs:\n     - One key comparison: $O(1)$.\n     - One pointer assignment (either in the `if` or `else` branch): $O(1)$.\n   Thus, the work inside each iteration is constant, $O(1)$. The total time spent in the loop body over all iterations is $(n-1) \\times O(1) = O(n)$.\n\nThe total time complexity is the sum of the costs:\n$T(n) = (\\text{initialization}) + (\\text{loop checks}) + (\\text{loop body execution})$\nFor $n \\ge 1$, $T(n) = O(1) + O(n) + O(n) = O(n)$.\nThis establishes an upper bound on the time complexity.\n\nFor a lower bound, we observe that for any input with $n \\ge 1$, the algorithm must perform $n-1$ iterations. Each iteration involves at least one key comparison and associated pointer operations, which take some minimum constant amount of time, $c  0$. Therefore, the total time must be at least proportional to $n-1$.\n$T(n) \\ge c \\cdot (n-1)$ for some constant $c0$ and for $n \\ge 1$.\nThis implies $T(n) \\in \\Omega(n-1)$, which simplifies to $T(n) \\in \\Omega(n)$.\n\nSince $T(n) \\in O(n)$ and $T(n) \\in \\Omega(n)$, the tight asymptotic time complexity of the algorithm is $\\Theta(n)$.", "answer": "$$\\boxed{\\Theta(n)}$$", "id": "3207266"}]}