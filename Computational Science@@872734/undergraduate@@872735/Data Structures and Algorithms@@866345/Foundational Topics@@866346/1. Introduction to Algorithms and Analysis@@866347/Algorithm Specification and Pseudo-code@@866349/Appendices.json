{"hands_on_practices": [{"introduction": "A direct translation of a mathematical recurrence into code often yields a simple and elegant recursive algorithm. However, this simplicity can hide significant performance issues. This practice [@problem_id:3205750] challenges you to start with the naive recursive specification for the Fibonacci sequence, analyze its exponential time complexity arising from redundant computations, and refactor it into an efficient linear-time iterative solution with constant space. This exercise is fundamental to understanding the concept of dynamic programming and the art of optimizing an algorithm's specification.", "problem": "You are given a recursive specification for the Fibonacci sequence that maps an input integer $n$ to the $n$-th Fibonacci number $F(n)$. The sequence is defined by the core recurrence on nonnegative integers: $F(0) = 0$, $F(1) = 1$, and for all $n \\ge 2$, $F(n) = F(n-1) + F(n-2)$. The naive recursive pseudo-code below follows this definition literally:\n- Input: integer $n \\ge 0$.\n- Procedure $\\mathrm{Fib}(n)$:\n  - If $n \\le 1$ then return $n$.\n  - Else return $\\mathrm{Fib}(n-1) + \\mathrm{Fib}(n-2)$.\n\nTask: Refactor this pseudo-code into a more efficient dynamic programming version and justify the design from first principles of data structures and algorithms. Base your derivation on the fundamental definitions of recurrence relations, the notion of overlapping subproblems, and the cost model where the running time counts elementary operations. Do not use any shortcut identities that jump directly to the answer without constructing the algorithm.\n\nYour deliverables must include:\n- A clear algorithm specification describing how to compute $F(n)$ using dynamic programming with bottom-up iteration and constant auxiliary space, starting from the definition of $F(n)$ and the observation that the naive recursion recomputes overlapping subproblems.\n- Pseudo-code for the refactored algorithm that respects precisely stated loop invariants, ensuring that the computation advances in a valid state from one iteration to the next.\n- A correctness argument that establishes the loop invariant and uses mathematical induction on the iteration counter to conclude that the output equals $F(n)$ for all $n \\ge 0$.\n- A complexity analysis comparing the naive recursive version and your dynamic programming version, expressed using Big-Oh notation (e.g., $O(n)$), and justified from the cost model and the structure of the computation.\n- A Python program that implements the refactored dynamic programming algorithm and applies it to the test suite below.\n\nTest suite:\n- $n \\in \\{0, 1, 2, 5, 10, 50, 90\\}$.\n\nOutput format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test suite, for example $[r_0,r_1,r_2,r_3,r_4,r_5,r_6]$, where each $r_i$ is the integer $F(n)$ for the corresponding test input.", "solution": "The problem requires refactoring a naive recursive algorithm for the Fibonacci sequence into an efficient dynamic programming version, providing a complete justification for the design.\n\n**1. Problem Statement Analysis**\n\nThe problem provides the mathematical definition of the Fibonacci sequence, $F(n)$, for non-negative integers $n$:\n- Base cases: $F(0) = 0$, $F(1) = 1$.\n- Recurrence relation: $F(n) = F(n-1) + F(n-2)$ for $n \\ge 2$.\n\nIt also provides the corresponding naive recursive pseudo-code:\n- Procedure $\\mathrm{Fib}(n)$:\n  - If $n \\le 1$ then return $n$.\n  - Else return $\\mathrm{Fib}(n-1) + \\mathrm{Fib}(n-2)$.\n\nThe task is to transform this into a more efficient algorithm using dynamic programming, specifically a bottom-up iterative approach with constant auxiliary space. This involves identifying the inefficiency in the naive approach and systematically deriving the improved algorithm.\n\n**2. Inefficiency of the Naive Recursive Approach: Overlapping Subproblems**\n\nThe core issue with the naive recursive algorithm is redundant computation. The computation of $F(n)$ involves two recursive calls, $\\mathrm{Fib}(n-1)$ and $\\mathrm{Fib}(n-2)$. The call tree for $F(n)$ expands, and many subproblems are computed multiple times. For example, to compute $F(5)$, the algorithm calls $F(4)$ and $F(3)$. The computation of $F(4)$ in turn requires $F(3)$ and $F(2)$. The subproblem $F(3)$ is thus computed twice. This phenomenon, where the same subproblem is encountered repeatedly in different branches of the recursion tree, is known as **overlapping subproblems**. This is a key characteristic that signals the applicability of dynamic programming.\n\nThe number of recursive calls, $T(n)$, to compute $F(n)$ follows the recurrence $T(n) = T(n-1) + T(n-2) + 1$, with $T(0)=1$ and $T(1)=1$. The solution to this recurrence is exponential in $n$. Specifically, $T(n)$ is in $O(\\phi^n)$, where $\\phi = \\frac{1+\\sqrt{5}}{2}$ is the golden ratio. This exponential time complexity makes the naive algorithm impractical for even moderately large values of $n$.\n\n**3. Dynamic Programming Derivation and Algorithm Specification**\n\nDynamic programming remedies the inefficiency of recomputation by storing the results of subproblems. A bottom-up (or iterative) approach computes the solutions to subproblems in increasing order of size. To compute $F(n)$, we can compute $F(2), F(3), \\dots, F(n)$ in sequence, using previously computed values.\n\nThe recurrence $F(i) = F(i-1) + F(i-2)$ shows that to compute the $i$-th Fibonacci number, we only need the two immediately preceding numbers, $F(i-1)$ and $F(i-2)$. This observation is crucial for space optimization. Instead of storing all previously computed Fibonacci numbers in an array (an $O(n)$ space solution), we only need to maintain the last two values to compute the next one. This leads to an algorithm with constant auxiliary space, $O(1)$.\n\nThe algorithm proceeds as follows:\n- Handle the base cases $n=0$ and $n=1$ directly.\n- For $n \\ge 2$, we initialize two variables to hold $F(0)$ and $F(1)$.\n- We then iterate from $i=2$ to $n$. In each iteration $i$, we compute $F(i)$ using the two stored values representing $F(i-2)$ and $F(i-1)$.\n- After computing $F(i)$, we update the two variables to hold $F(i-1)$ and $F(i)$ in preparation for the next iteration, $i+1$.\n- The loop continues until $F(n)$ is computed.\n\n**4. Pseudo-code with Loop Invariants**\n\nThe following pseudo-code formalizes the constant-space, bottom-up iterative algorithm.\n\n- **Procedure** $\\mathrm{Fib\\_DP}(n)$:\n- **Input**: A non-negative integer $n$.\n- **Output**: The $n$-th Fibonacci number, $F(n)$.\n\n1.  **If** $n = 0$, **return** $0$.\n2.  **If** $n = 1$, **return** $1$.\n3.  \n4.  // Initialize variables for the iterative computation\n5.  $a \\leftarrow 0$  // Represents the $(i-2)$-th Fibonacci number\n6.  $b \\leftarrow 1$  // Represents the $(i-1)$-th Fibonacci number\n7.  \n8.  // Iterate from 2 to n to compute F(2), F(3), ..., F(n)\n9.  **For** $i$ from $2$ to $n$:\n10.     // **Loop Invariant**: At the beginning of the iteration for index $i$,\n11.     // the variable `a` stores $F(i-2)$ and `b` stores $F(i-1)$.\n12. \n13.     $temp \\leftarrow a + b$  // Compute $F(i) = F(i-2) + F(i-1)$\n14.     $a \\leftarrow b$         // Update `a` to be $F(i-1)$ for the next iteration\n15.     $b \\leftarrow temp$      // Update `b` to be $F(i)$ for the next iteration\n16. \n17. // After the loop terminates, `b` holds the value of $F(n)$.\n18. **Return** $b$.\n\n**5. Correctness Argument**\n\nWe prove the correctness of the $\\mathrm{Fib\\_DP}$ algorithm for all non-negative integers $n$.\n\n- **Base Cases**: For $n=0$ and $n=1$, the algorithm correctly returns $0$ and $1$ respectively, which match the definition of $F(0)$ and $F(1)$.\n\n- **Inductive Step ($n \\ge 2$)**: We use the loop invariant to prove correctness for $n \\ge 2$.\n  - **Loop Invariant $P(i)$**: At the start of the loop for index $i$ (where $i$ ranges from $2$ to $n$), `a` = $F(i-2)$ and `b` = $F(i-1)$.\n\n  - **Initialization**: Before the first iteration where $i=2$, the algorithm sets $a \\leftarrow 0$ and $b \\leftarrow 1$. According to the definition of the Fibonacci sequence, $F(2-2) = F(0) = 0$ and $F(2-1) = F(1) = 1$. Thus, the invariant $P(2)$ holds at the start of the first iteration.\n\n  - **Maintenance**: Assume the invariant $P(k)$ holds for some integer $k$ such that $2 \\le k \\le n$. This means at the start of iteration $k$, we have `a` = $F(k-2)$ and `b` = $F(k-1)$.\n    During the body of iteration $k$:\n    1.  $temp \\leftarrow a + b$. By the inductive hypothesis, $temp = F(k-2) + F(k-1)$. By the Fibonacci recurrence relation, $temp = F(k)$.\n    2.  $a \\leftarrow b$. The variable `a` is updated to hold the value $F(k-1)$.\n    3.  $b \\leftarrow temp$. The variable `b` is updated to hold the value $F(k)$.\n\n    At the beginning of the next iteration, the index will be $k+1$. The variables will be `a` = $F(k-1) = F((k+1)-2)$ and `b` = $F(k) = F((k+1)-1)$. This demonstrates that the invariant $P(k+1)$ holds. Thus, the loop invariant is maintained.\n\n  - **Termination**: The loop terminates after the iteration for $i=n$ is completed. At the start of the final iteration ($i=n$), the invariant $P(n)$ holds, meaning `a`=$F(n-2)$ and `b`=$F(n-1)$. Inside this final iteration, `b` is updated to $F(n)$. The loop then finishes. The algorithm proceeds to return the value of `b`, which is now $F(n)$.\n\nThe argument shows that the algorithm correctly computes $F(n)$ for all $n \\ge 2$. Combined with the base cases, the algorithm is correct for all non-negative integers $n$.\n\n**6. Complexity Analysis**\n\n- **Naive Recursive Algorithm ($\\mathrm{Fib}$)**:\n  - **Time Complexity**: As established, the number of operations is proportional to the number of recursive calls, which grows exponentially. The time complexity is $O(\\phi^n)$, where $\\phi \\approx 1.618$.\n  - **Space Complexity**: The space complexity is determined by the maximum depth of the recursion stack. To compute $F(n)$, the recursion goes down to $F(1)$ or $F(0)$, leading to a maximum depth of $n$. Therefore, the space complexity is $O(n)$.\n\n- **Dynamic Programming Algorithm ($\\mathrm{Fib\\_DP}$)**:\n  - **Time Complexity**: For $n \\ge 2$, the algorithm executes a single loop that runs from $i=2$ to $n$. The loop iterates $n-1$ times. Inside the loop, a constant number of elementary operations (one addition, two assignments) are performed. Therefore, the total time complexity is $O(n-1) = O(n)$.\n  - **Space Complexity**: The algorithm uses a fixed number of variables (`n`, `a`, `b`, `temp`, `i`) regardless of the input size $n$. The space required for these variables is constant. Thus, the auxiliary space complexity is $O(1)$.\n\n**Comparison Summary**\n\n| Algorithm | Time Complexity | Auxiliary Space Complexity |\n| :--- | :--- | :--- |\n| Naive Recursive | $O(\\phi^n)$ (Exponential) | $O(n)$ (Linear) |\n| Dynamic Programming | $O(n)$ (Linear) | $O(1)$ (Constant) |\n\nThe dynamic programming approach offers an exponential improvement in time complexity and a reduction from linear to constant auxiliary space, making it vastly superior.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef fib_dp(n: int) - int:\n    \"\"\"\n    Computes the n-th Fibonacci number using dynamic programming with constant space.\n    \n    The algorithm is based on the recurrence F(n) = F(n-1) + F(n-2).\n    It iteratively computes Fibonacci numbers from F(2) up to F(n),\n    keeping track of only the last two computed values.\n\n    Args:\n        n: A non-negative integer.\n\n    Returns:\n        The n-th Fibonacci number, F(n).\n    \"\"\"\n    if not isinstance(n, int) or n  0:\n        raise ValueError(\"Input must be a non-negative integer.\")\n\n    # Base cases as per the definition F(0) = 0, F(1) = 1.\n    if n = 1:\n        return n\n\n    # Initialization for the iterative process.\n    # We start with 'a' as F(0) and 'b' as F(1) to compute F(2).\n    # In general, at the start of the loop to compute F(i), 'a' is F(i-2) and 'b' is F(i-1).\n    a, b = 0, 1\n\n    # The loop runs n-1 times. For n=2, it runs once. For n=3, twice, and so on.\n    # At each step, we update (a, b) from (F(i-2), F(i-1)) to (F(i-1), F(i)).\n    # The Python tuple assignment `a, b = b, a + b` elegantly performs this state update\n    # by first evaluating the right-hand side (b, a + b) using the old values of a and b,\n    # and then assigning them to the left-hand side variables.\n    for _ in range(2, n + 1):\n        a, b = b, a + b\n    \n    # After the loop finishes, 'b' holds the value of F(n).\n    return b\n\ndef solve():\n    \"\"\"\n    Runs the dynamic programming Fibonacci algorithm on the specified test suite\n    and prints the results in the required format.\n    \"\"\"\n    # Test suite as specified in the problem statement.\n    test_cases = [0, 1, 2, 5, 10, 50, 90]\n\n    results = []\n    for n in test_cases:\n        # Calculate the Fibonacci number for each case using the optimized algorithm.\n        result = fib_dp(n)\n        results.append(result)\n\n    # Format the final output as a single-line, comma-separated list in brackets.\n    # Note: Python's integers handle arbitrary size, so F(90) does not overflow.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3205750"}, {"introduction": "An algorithm's specification is only as strong as its ability to handle all possible inputs, including tricky edge cases. In this exercise [@problem_id:3205797], you are presented with a common but flawed pseudo-code for Kadane's algorithm, which fails when all array elements are negative. Your task is to act as a code reviewer, using first principles of dynamic programming to diagnose the logical error and identify the correct modifications. This practice hones the critical skill of debugging algorithms by reasoning about their invariants and ensuring their robustness.", "problem": "Consider the maximum subarray problem under the constraint that the chosen subarray must contain at least one element. Formally, given an array $A$ of length $n$ with elements $A[1], A[2], \\dots, A[n]$, the goal is to find indices $1 \\leq \\ell \\leq r \\leq n$ that maximize the sum $\\sum_{i=\\ell}^{r} A[i]$, where the subarray is required to be nonempty. A commonly taught linear-time algorithm (Kadane's algorithm) maintains a running sum and a global maximum. You are given the following pseudo-code, which is known to be incorrect for arrays in which all numbers are negative, while it often works otherwise:\n\n- Initialize $maxSoFar \\leftarrow 0$ and $current \\leftarrow 0$.\n- For each $x$ in $A$ (from left to right):\n    - Set $current \\leftarrow \\max(0, current + x)$.\n    - Set $maxSoFar \\leftarrow \\max(maxSoFar, current)$.\n- Return $maxSoFar$.\n\nWhen run on $A = \\langle -3, -5, -2 \\rangle$, this pseudo-code returns $0$, even though the correct answer under the nonempty-subarray constraint is $-2$.\n\nStarting from core definitions and reasoning about invariants that a correct linear-time solution must maintain, identify which of the following modifications yield a correct algorithm for all arrays (including the case where all numbers are negative) while preserving $O(n)$ time and $O(1)$ extra space. Each option should be considered as a standalone change; select all that apply.\n\nA. Change only the initialization to $maxSoFar \\leftarrow -\\infty$ while leaving the rest of the pseudo-code unchanged.\n\nB. Initialize $current \\leftarrow A[1]$ and $maxSoFar \\leftarrow A[1]$, then iterate $i$ from $2$ to $n$ with the updates $current \\leftarrow \\max(A[i], current + A[i])$ and $maxSoFar \\leftarrow \\max(maxSoFar, current)$.\n\nC. Before the main loop, check if all elements of $A$ are negative; if so, return $\\max_{1 \\leq i \\leq n} A[i]$. Otherwise, run the original pseudo-code as given.\n\nD. Replace the update $current \\leftarrow \\max(0, current + x)$ with $current \\leftarrow \\max(0, x)$, leaving the rest unchanged.\n\nE. Replace every occurrence of $\\max$ in the pseudo-code with $\\min$, leaving everything else unchanged.\n\nSelect the correct option(s).", "solution": "The user has provided a problem concerning the maximum subarray sum, with a known-incorrect pseudo-code implementation of Kadane's algorithm. The task is to validate the problem statement and, if valid, identify which of the provided modifications correct the algorithm for all possible inputs while maintaining $O(n)$ time and $O(1)$ space complexity.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n- **Problem Domain**: The maximum subarray problem with a nonempty subarray constraint.\n- **Input**: An array $A$ of length $n$ with elements $A[1], A[2], \\dots, A[n]$.\n- **Objective**: Find indices $1 \\leq \\ell \\leq r \\leq n$ that maximize the sum $S = \\sum_{i=\\ell}^{r} A[i]$.\n- **Provided Incorrect Pseudo-code**:\n  - Initialize $maxSoFar \\leftarrow 0$ and $current \\leftarrow 0$.\n  - For each $x$ in $A$:\n    - Set $current \\leftarrow \\max(0, current + x)$.\n    - Set $maxSoFar \\leftarrow \\max(maxSoFar, current)$.\n  - Return $maxSoFar$.\n- **Failure Case**: For input $A = \\langle -3, -5, -2 \\rangle$, the pseudo-code returns $0$, while the correct answer is $-2$.\n- **Task**: Identify all correct modifications from the given options that result in a universally correct algorithm preserving $O(n)$ time and $O(1)$ space.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is a classic and fundamental topic in computer science, specifically in the area of algorithms and dynamic programming. It is scientifically sound and well-established.\n- **Well-Posedness**: The objective is clearly defined (maximize a sum over a constrained set of subarrays). The input is a standard data structure. The question asks for an evaluation of specific modifications to an algorithm, which is a well-posed task.\n- **Objectivity**: The problem is stated using precise mathematical and algorithmic language. There are no subjective or ambiguous terms.\n- **Flaw Analysis**:\n  1.  **Scientific/Factual Unsoundness**: None. The problem correctly identifies a flaw in a common but simplified version of Kadane's algorithm.\n  2.  **Non-Formalizable/Irrelevant**: None. The problem is perfectly formalizable.\n  3.  **Incomplete/Contradictory Setup**: None. The problem provides all necessary information: the goal, the constraints, the faulty algorithm, and a counterexample.\n  4.  **Unrealistic/Infeasible**: Not applicable. This is a problem in theoretical computer science.\n  5.  **Ill-Posed/Poorly Structured**: None. A unique maximum sum exists for any given array. The question is structured clearly.\n  6.  **Pseudo-Profound/Trivial/Tautological**: None. The problem requires a careful understanding of the algorithm's invariants and edge cases.\n  7.  **Outside Scientific Verifiability**: None. The correctness of an algorithm is mathematically verifiable.\n\n**Step 3: Verdict and Action**\n- **Verdict**: The problem is valid.\n- **Action**: Proceed with the solution derivation and option analysis.\n\n**Core Principles and Derivation**\n\nThe maximum subarray problem can be solved using dynamic programming. Let $C(j)$ be the maximum sum of a non-empty subarray ending at index $j$. To compute $C(j)$, we have two choices for the subarray ending at $j$:\n1.  The subarray consists of only the element $A[j]$. The sum is $A[j]$.\n2.  The subarray is formed by extending the maximum subarray ending at index $j-1$ with the element $A[j]$. The sum is $C(j-1) + A[j]$.\n\nSince we want to maximize the sum, we must choose the larger of these two options. This gives the recurrence relation:\n$$C(j) = \\max(A[j], C(j-1) + A[j])$$\nThe base case is $C(1) = A[1]$, as the only non-empty subarray ending at index $1$ is $\\langle A[1] \\rangle$.\n\nThe overall maximum subarray sum, $M$, is the maximum value of $C(j)$ over all possible ending positions $j$:\n$$M = \\max_{1 \\leq j \\leq n} C(j)$$\n\nThis recurrence can be implemented in a single loop, using one variable (let's call it `current`) to track $C(j)$ as $j$ increases, and another variable (let's call it `maxSoFar`) to track $M$.\n\nThe original pseudo-code fails because its update rule $current \\leftarrow \\max(0, current + x)$ is not equivalent to the correct recurrence. Instead of comparing with $A[j]$ (or $x$), it compares with $0$. This implicitly considers an empty subarray (with sum $0$) as an alternative for starting a new subarray, which is why it fails when the true maximum sum is negative. The initialization $maxSoFar \\leftarrow 0$ further solidifies this flaw.\n\n**Option-by-Option Analysis**\n\n**A. Change only the initialization to $maxSoFar \\leftarrow -\\infty$ while leaving the rest of the pseudo-code unchanged.**\n\nThe modified pseudo-code is:\n- Initialize $maxSoFar \\leftarrow -\\infty$ and $current \\leftarrow 0$.\n- For each $x$ in $A$:\n  - Set $current \\leftarrow \\max(0, current + x)$.\n  - Set $maxSoFar \\leftarrow \\max(maxSoFar, current)$.\n- Return $maxSoFar$.\n\nLet's test this with the given failing case $A = \\langle -3, -5, -2 \\rangle$:\n- Initial state: $maxSoFar \\leftarrow -\\infty$, $current \\leftarrow 0$.\n- For $x = -3$: $current \\leftarrow \\max(0, 0 + (-3)) = 0$. $maxSoFar \\leftarrow \\max(-\\infty, 0) = 0$.\n- For $x = -5$: $current \\leftarrow \\max(0, 0 + (-5)) = 0$. $maxSoFar \\leftarrow \\max(0, 0) = 0$.\n- For $x = -2$: $current \\leftarrow \\max(0, 0 + (-2)) = 0$. $maxSoFar \\leftarrow \\max(0, 0) = 0$.\nThe algorithm returns $0$, which is incorrect. The core flaw in the update rule $current \\leftarrow \\max(0, current + x)$ is not addressed. This update prevents the algorithm from ever tracking a negative running sum, which is necessary when all elements are negative.\n\n**Verdict: Incorrect.**\n\n**B. Initialize $current \\leftarrow A[1]$ and $maxSoFar \\leftarrow A[1]$, then iterate $i$ from $2$ to $n$ with the updates $current \\leftarrow \\max(A[i], current + A[i])$ and $maxSoFar \\leftarrow \\max(maxSoFar, current)$.**\n\nThis pseudo-code directly implements the dynamic programming recurrence derived above.\n- The initialization `current $\\leftarrow A[1]$` and `maxSoFar $\\leftarrow A[1]$` correctly sets up the base case for $i=1$. `current` holds $C(1)$, and `maxSoFar` holds the maximum sum seen so far, which is also $C(1)$.\n- The loop iterates from $i=2$ to $n$.\n- The update $current \\leftarrow \\max(A[i], current + A[i])$ is precisely the recurrence $C(i) = \\max(A[i], C(i-1) + A[i])$.\n- The update $maxSoFar \\leftarrow \\max(maxSoFar, current)$ correctly maintains the overall maximum found across all subarray ending positions considered so far ($M = \\max_{1 \\leq j \\leq i} C(j)$).\nLet's test with $A = \\langle -3, -5, -2 \\rangle$:\n- Initial state: $current \\leftarrow -3$, $maxSoFar \\leftarrow -3$. The loop runs for $i=2, 3$.\n- For $i=2$, $A[2]=-5$: $current \\leftarrow \\max(-5, -3 + (-5)) = \\max(-5, -8) = -5$. $maxSoFar \\leftarrow \\max(-3, -5) = -3$.\n- For $i=3$, $A[3]=-2$: $current \\leftarrow \\max(-2, -5 + (-2)) = \\max(-2, -7) = -2$. $maxSoFar \\leftarrow \\max(-3, -2) = -2$.\nThe algorithm returns $-2$, which is correct. This version is the standard, robust formulation of Kadane's algorithm and works for all inputs. The time complexity is $O(n)$ due to the single pass, and the space complexity is $O(1)$.\n\n**Verdict: Correct.**\n\n**C. Before the main loop, check if all elements of $A$ are negative; if so, return $\\max_{1 \\leq i \\leq n} A[i]$. Otherwise, run the original pseudo-code as given.**\n\nThis modification attempts to \"patch\" the original algorithm by handling its specific failure case.\n- **Analysis of the patch**: The original algorithm fails if and only if the maximum subarray sum is a negative number. This occurs if and only if all elements in the array $A$ are negative. In this situation, any subarray sum will be negative. To maximize the sum, one must choose the single element that is the \"least negative,\" i.e., the maximum element of the array. The proposed check `if all elements of A are negative, return max_{1 \\leq i \\leq n} A[i]` correctly handles this case. This check and the subsequent search for the maximum take $O(n)$ time.\n- **Analysis of the \"otherwise\" case**: If the condition is false, it means there is at least one non-negative element in $A$. In this case, the maximum subarray sum must be greater than or equal to $0$ (since we can at least form a subarray with a single non-negative element). The original algorithm, which finds the maximum subarray sum allowing for an empty subarray (sum $0$), will produce the correct non-negative answer in this scenario. It correctly finds positive maximums, and if the maximum is $0$, it will also find $0$. Its only failure is returning $0$ for a negative true maximum. Since this case is now excluded, the original algorithm works correctly.\nThe total time complexity is $O(n)$ for the check plus $O(n)$ for one of the branches, resulting in $O(n)$. The space complexity is $O(1)$. This combined procedure is correct for all inputs.\n\n**Verdict: Correct.**\n\n**D. Replace the update $current \\leftarrow \\max(0, current + x)$ with $current \\leftarrow \\max(0, x)$, leaving the rest unchanged.**\n\nThe modified pseudo-code is:\n- Initialize $maxSoFar \\leftarrow 0$ and $current \\leftarrow 0$.\n- For each $x$ in $A$:\n  - Set $current \\leftarrow \\max(0, x)$.\n  - Set $maxSoFar \\leftarrow \\max(maxSoFar, current)$.\n- Return $maxSoFar$.\n\nThis algorithm no longer computes subarray sums. In each step, $current$ becomes $x$ if $x > 0$ and $0$ otherwise. $maxSoFar$ then tracks the maximum value that `current` has taken. This procedure is equivalent to finding the maximum of $0$ and all elements in the array: $\\max(0, \\max_{x \\in A} x)$.\nLet's test this with a mixed array $A = \\langle -2, 1, -3, 4, -1, 2, 1, -5, 4 \\rangle$. The correct answer is $6$ (from the subarray $\\langle 4, -1, 2, 1 \\rangle$).\nThis algorithm would compute $\\max(0, -2, 1, -3, 4, -1, 2, 1, -5, 4) = 4$. It fails to sum consecutive elements.\n\n**Verdict: Incorrect.**\n\n**E. Replace every occurrence of $\\max$ in the pseudo-code with $\\min$, leaving everything else unchanged.**\n\nThe modified pseudo-code becomes:\n- Initialize $maxSoFar \\leftarrow 0$ and $current \\leftarrow 0$.\n- For each $x$ in $A$:\n  - Set $current \\leftarrow \\min(0, current + x)$.\n  - Set $maxSoFar \\leftarrow \\min(maxSoFar, current)$.\n- Return $maxSoFar$.\n\nThe problem asks to *maximize* the subarray sum. This modification changes the objective to a minimization problem (specifically, finding the minimum subarray sum, allowing for an empty subarray of sum $0$). It does not solve the stated problem. For $A = \\langle -3, -5, -2 \\rangle$, the maximum subarray sum is $-2$. This algorithm would produce:\n- Initial state: $maxSoFar \\leftarrow 0$, $current \\leftarrow 0$.\n- For $x = -3$: $current \\leftarrow \\min(0, 0 + (-3)) = -3$. $maxSoFar \\leftarrow \\min(0, -3) = -3$.\n- For $x = -5$: $current \\leftarrow \\min(0, -3 + (-5)) = -8$. $maxSoFar \\leftarrow \\min(-3, -8) = -8$.\n- For $x = -2$: $current \\leftarrow \\min(0, -8 + (-2)) = -10$. $maxSoFar \\leftarrow \\min(-8, -10) = -10$.\nThe algorithm returns $-10$, which is the minimum subarray sum, not the maximum.\n\n**Verdict: Incorrect.**", "answer": "$$\\boxed{BC}$$", "id": "3205797"}, {"introduction": "The most elegant algorithms are often those that solve a problem in a surprisingly simple and efficient, yet non-obvious, way. The three-reversal algorithm for array rotation is a perfect example of such a solution. This practice [@problem_id:3205801] challenges you not only to specify this algorithm in pseudo-code but also to prove its correctness from first principles. By treating the reversals as permutations and analyzing their composition, you will develop a deeper appreciation for how formal reasoning can validate a clever algorithmic insight.", "problem": "You are given an array rotation task to be specified in precise pseudo-code and validated against a formal specification. Let an array be a function $A:\\{0,1,\\dots,n-1\\}\\to \\mathbb{Z}$ where $n$ is the array length and indexing is $0$-based. A right rotation by $k$ positions is the permutation on indices that maps each position $i$ to $(i+k)\\bmod n$. The goal is to design and implement an in-place algorithm that performs this rotation using exactly $3$ segment reversals.\n\nFundamental base and definitions to use:\n- An array $A$ of length $n$ is a sequence indexed over $\\{0,1,\\dots,n-1\\}$.\n- For integers $l$ and $r$ with $0\\le l\\le rn$, the reversal of the segment $A[l..r]$ is the operation that swaps elements symmetrically until the segment is reversed. The index mapping of a segment reversal $\\mathrm{rev}(l,r)$ is $i\\mapsto l+r-i$ for $i\\in[l,r]$ and $i\\mapsto i$ otherwise.\n- Composition of permutations is associative and yields a permutation on the same index set.\n- Modular arithmetic satisfies $(a\\bmod n)\\in\\{0,1,\\dots,n-1\\}$ and $(x+n)\\bmod n\\equiv x\\bmod n$.\n\nTask:\n1) Specify, in clear pseudo-code, an in-place algorithm RotateRightByK that rotates an array $A$ of length $n$ by an integer $k$ to the right using exactly $3$ reversals, and nowhere uses extra space proportional to $n$.\n2) State the precondition, postcondition, and the correctness specification as the mapping $A[i]\\mapsto A[(i+k)\\bmod n]$ for all $i\\in\\{0,1,\\dots,n-1\\}$.\n3) Justify, from first principles and the definitions above, why your $3$-reversal algorithm implements the specified permutation on indices.\n4) Implement your pseudo-code as a complete, runnable program that applies the algorithm to the test suite below and produces the required output format.\n\nPseudo-code template you must complete and then implement:\n- Procedure $\\mathrm{Reverse}(A,\\ell,r)$:\n  - While $\\ellr$ do: swap $A[\\ell]$ and $A[r]$; set $\\ell\\leftarrow \\ell+1$ and $r\\leftarrow r-1$.\n- Procedure $\\mathrm{RotateRightByK}(A,k)$:\n  - Let $n\\leftarrow \\mathrm{length}(A)$. If $n=0$ then return.\n  - Normalize $k\\leftarrow k\\bmod n$ so that $k\\in\\{0,1,\\dots,n-1\\}$.\n  - Apply exactly $3$ calls to $\\mathrm{Reverse}$ on appropriately chosen index ranges so that the net effect is $A[i]\\mapsto A[(i+k)\\bmod n]$.\n\nConstraints and guarantees:\n- The algorithm must run in $O(n)$ time and use $O(1)$ additional space, where $n$ is the array length.\n- For negative $k$, use the normalization $k\\leftarrow k\\bmod n$ to bring $k$ into the required range before applying reversals.\n\nTest suite to embed in your program:\n- Case $1$: $A=[1,2,3,4,5]$, $k=2$.\n- Case $2$: $A=[10]$, $k=100$.\n- Case $3$: $A=[]$, $k=3$.\n- Case $4$: $A=[0,1,2,3]$, $k=0$.\n- Case $5$: $A=[-1,-2,-3,-4,-5,-6]$, $k=3$.\n- Case $6$: $A=[7,8,9,10,11,12,13]$, $k=-2$.\n\nRequired final output format:\n- Your program must run with no input and print exactly one line that is a single string representation of the list of rotated arrays, in the following format with no spaces: a comma-separated list of bracketed arrays enclosed in a single pair of brackets. For example, the printed line must look like $[[4,5,1,2,3],[10],[],[0,1,2,3],[-4,-5,-6,-1,-2,-3],[9,10,11,12,13,7,8]]$ for the corresponding cases.", "solution": "The problem of rotating an array in-place is a fundamental task in computer science. The requirement is to design an algorithm that achieves this rotation using exactly three segment reversals, operating in linear time $O(n)$ and constant auxiliary space $O(1)$.\n\n### Step 1: Algorithm Specification (Pseudo-code)\n\nFirst, we define the primitive operation of reversing a segment of the array. Let $A$ be an array, and let $\\ell$ and $r$ be the starting and ending indices of the segment to be reversed, where $0 \\le \\ell \\le r  n$.\n\n- Procedure $\\mathrm{Reverse}(A,\\ell,r)$:\n  - While $\\ell  r$ do:\n    - Swap $A[\\ell]$ and $A[r]$.\n    - Set $\\ell \\leftarrow \\ell+1$ and $r \\leftarrow r-1$.\n\nUsing this primitive, we can construct the rotation algorithm. A right rotation by $k$ positions on an array of length $n$ is equivalent to moving the last $k$ elements to the beginning of the array, preserving the order within the two segments. This can be viewed as transforming an array partitioned into two blocks, $A = [B_1|B_2]$, into $[B_2|B_1]$, where $B_1$ has length $n-k$ and $B_2$ has length $k$.\n\nThe algorithm applies three reversals to achieve this transformation.\n\n- Procedure $\\mathrm{RotateRightByK}(A,k)$:\n  - Let $n \\leftarrow \\mathrm{length}(A)$.\n  - If $n=0$ then return.\n  - Normalize $k \\leftarrow k \\bmod n$. This ensures $k \\in \\{0, 1, \\dots, n-1\\}$. The expression $(i+k)\\bmod n$ is well-defined for any integer $k$, but for partitioning the array, we need a non-negative effective rotation count.\n  - If $k=0$ then return. (This is an optimization; the logic below is correct even for $k=0$).\n  - Call $\\mathrm{Reverse}(A, 0, n-k-1)$. This reverses the first block of $n-k$ elements.\n  - Call $\\mathrm{Reverse}(A, n-k, n-1)$. This reverses the second block of $k$ elements.\n  - Call $\\mathrm{Reverse}(A, 0, n-1)$. This reverses the entire array.\n\n### Step 2: Formal Specification\n\n- **Precondition**: $A$ is an array of length $n \\ge 0$, and $k$ is an integer representing the number of positions to rotate right.\n- **Postcondition**: The array $A$ is modified in-place such that its elements are permuted according to a right rotation by $k$. Let $A_{initial}$ denote the state of the array before the operation and $A_{final}$ denote the state after. The postcondition is that for all indices $i \\in \\{0, 1, \\dots, n-1\\}$, the equality $A_{final}[(i+k) \\pmod n] = A_{initial}[i]$ holds.\n- **Correctness Specification**: The net permutation on the array indices effected by the algorithm must be identical to the permutation $\\pi_{rot_k}: i \\mapsto (i+k) \\pmod n$ for all $i \\in \\{0, 1, \\dots, n-1\\}$.\n\n### Step 3: Justification of Correctness\n\nWe must demonstrate that the composition of the three specified reversals implements the desired rotation permutation. Let $n$ be the length of the array $A$. Let the effective rotation amount be $k' = k \\pmod n$, where $0 \\le k'  n$.\n\nThe algorithm consists of three sequential applications of the reversal permutation. Let's define the permutation for a reversal of a segment $[l, r]$ as $\\mathrm{rev}_{(l,r)}$.\nThe permutation map is $\\mathrm{rev}_{(l,r)}(i) = l+r-i$ if $i \\in [l, r]$ and $\\mathrm{rev}_{(l,r)}(i) = i$ otherwise.\n\nThe three permutations applied by the algorithm are:\n1.  $\\pi_1 = \\mathrm{rev}_{(0, n-k'-1)}$\n2.  $\\pi_2 = \\mathrm{rev}_{(n-k', n-1)}$\n3.  $\\pi_3 = \\mathrm{rev}_{(0, n-1)}$\n\nThe total permutation is the composition $\\pi_{total} = \\pi_3 \\circ \\pi_2 \\circ \\pi_1$. We need to show that for any initial index $i \\in \\{0, 1, \\dots, n-1\\}$, its final position is $\\pi_{total}(i) = (i+k') \\pmod n$. We analyze the mapping for an arbitrary index $i$ by considering two cases based on its initial position.\n\n**Case 1: $i \\in [0, n-k'-1]$** (the element is in the first block).\n- **Apply $\\pi_1$**: The index $i$ is within the reversal range $[0, n-k'-1]$.\n  $i_1 = \\pi_1(i) = 0 + (n-k'-1) - i = n-k'-1-i$.\n  The resulting index $i_1$ is also in the range $[0, n-k'-1]$.\n- **Apply $\\pi_2$**: The index $i_1$ is outside the reversal range $[n-k', n-1]$ of $\\pi_2$.\n  $i_2 = \\pi_2(i_1) = i_1 = n-k'-1-i$.\n- **Apply $\\pi_3$**: The index $i_2$ is within the reversal range $[0, n-1]$ of $\\pi_3$.\n  $i_3 = \\pi_3(i_2) = 0 + (n-1) - i_2 = n-1-(n-k'-1-i) = n-1-n+k'+1+i = i+k'$.\n\nFor $i \\in [0, n-k'-1]$, the final position is $i+k'$. Since $i \\le n-k'-1$, we have $i+k' \\le n-1$. Thus, $(i+k') \\pmod n = i+k'$, which matches the target rotation.\n\n**Case 2: $i \\in [n-k', n-1]$** (the element is in the second block).\n- **Apply $\\pi_1$**: The index $i$ is outside the reversal range $[0, n-k'-1]$ of $\\pi_1$.\n  $i_1 = \\pi_1(i) = i$.\n- **Apply $\\pi_2$**: The index $i_1 = i$ is within the reversal range $[n-k', n-1]$ of $\\pi_2$.\n  $i_2 = \\pi_2(i_1) = (n-k') + (n-1) - i_1 = 2n-k'-1-i$.\n  The resulting index $i_2$ is also in the range $[n-k', n-1]$ (as shown by checking the boundaries).\n- **Apply $\\pi_3$**: The index $i_2$ is within the reversal range $[0, n-1]$ of $\\pi_3$.\n  $i_3 = \\pi_3(i_2) = 0 + (n-1) - i_2 = n-1 - (2n-k'-1-i) = n-1-2n+k'+1+i = i+k'-n$.\n\nFor $i \\in [n-k', n-1]$, we have $i+k' \\ge (n-k')+k' = n$. The standard definition of right rotation by $k'$ maps $i$ to $(i+k') \\pmod n$. Since $i+k' \\ge n$ and $i+k'  (n-1)+k'+1 = n+k'2n$, the modulo operation gives $(i+k') \\pmod n = i+k'-n$. This matches our derived final position $i_3$.\n\nIn both cases, the final position of an element initially at index $i$ is $(i+k') \\pmod n$. The algorithm is therefore correct. It uses three reversal passes, each taking $O(n)$ time, for a total time complexity of $O(n)$. It operates in-place, using only a few variables for indices, thus requiring $O(1)$ auxiliary space. This satisfies all problem constraints.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the array rotation problem.\n    \"\"\"\n    # Define the test cases as specified in the problem statement.\n    # Each case is a tuple containing a list (array A) and an integer (rotation k).\n    test_cases = [\n        ([1, 2, 3, 4, 5], 2),\n        ([10], 100),\n        ([], 3),\n        ([0, 1, 2, 3], 0),\n        ([-1, -2, -3, -4, -5, -6], 3),\n        ([7, 8, 9, 10, 11, 12, 13], -2),\n    ]\n\n    rotated_results = []\n    for arr, k in test_cases:\n        # Create a copy to avoid modifying the original list in the test_cases definition.\n        arr_copy = arr.copy()\n        # Apply the rotation algorithm to the copied array.\n        rotate_right_by_k(arr_copy, k)\n        # Store the rotated array.\n        rotated_results.append(arr_copy)\n\n    # Format the results into a single string as required by the problem.\n    # e.g., [[4,5,1,2,3],[10],[],[0,1,2,3],[-4,-5,-6,-1,-2,-3],[9,10,11,12,13,7,8]]\n    # This involves converting each list to its string representation, removing spaces,\n    # joining them with commas, and enclosing the whole string in brackets.\n    output_str = f\"[{','.join(str(r).replace(' ', '') for r in rotated_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(output_str)\n\ndef reverse(arr, l, r):\n    \"\"\"\n    Reverses a segment of the array `arr` in-place from index `l` to `r`.\n    This corresponds to the pseudo-code: Procedure Reverse(A, l, r).\n    \"\"\"\n    while l  r:\n        arr[l], arr[r] = arr[r], arr[l]\n        l += 1\n        r -= 1\n\ndef rotate_right_by_k(arr, k):\n    \"\"\"\n    Rotates the array `arr` to the right by `k` positions in-place using 3 reversals.\n    This corresponds to the pseudo-code: Procedure RotateRightByK(A, k).\n    \"\"\"\n    n = len(arr)\n    # Handle the edge case of an empty array.\n    if n == 0:\n        return\n\n    # Normalize k to be within the range [0, n-1].\n    # For k  0, k % n in Python correctly maps to a positive equivalent.\n    # e.g., -2 % 7 = 5.\n    k = k % n\n\n    # If k is 0, the array does not need to be rotated.\n    if k == 0:\n        return\n\n    # 1. Reverse the first n-k elements.\n    # The segment is A[0 ... n-k-1].\n    reverse(arr, 0, n - k - 1)\n\n    # 2. Reverse the last k elements.\n    # The segment is A[n-k ... n-1].\n    reverse(arr, n - k, n - 1)\n\n    # 3. Reverse the entire array.\n    # The segment is A[0 ... n-1].\n    reverse(arr, 0, n - 1)\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3205801"}]}