{"hands_on_practices": [{"introduction": "Dijkstra's algorithm reliably finds the shortest distance from a source to all other vertices. However, when multiple paths share the same shortest distance, which one is chosen? This exercise [@problem_id:3271591] demonstrates that the choice, often handled by a tie-breaking rule, can produce structurally different Shortest Path Trees (SPTs). You will explore how these different trees, while all valid, can impact downstream applications that depend on path structure, such as finding a lowest common ancestor.", "problem": "You are given an undirected weighted graph with vertex set $V = \\{0,1,2,3,4,5,6\\}$ and edge set consisting of the following edges, each of weight $1$: $(0,1)$, $(0,2)$, $(1,3)$, $(2,3)$, $(1,4)$, $(2,4)$, $(3,5)$, $(4,5)$, $(3,6)$, $(4,6)$. All weights are nonnegative. Consider running Dijkstra's algorithm from source $0$ to compute a Shortest Path Tree (SPT), where an SPT is a spanning arborescence rooted at the source in which the unique path from the root to any vertex realizes a shortest path distance in the given graph. Assume the standard definition of Dijkstra's algorithm: vertices are extracted from a min-priority queue keyed by current tentative distance, and edge relaxations update tentative distances when a strictly smaller value is found.\n\nTo fully specify parent choices when multiple equally short paths exist, consider two variants of Dijkstra's algorithm that differ only in their deterministic tie-breaking rules:\n\n- Variant $\\mathsf{M}$ (min-index): The priority queue breaks ties on equal tentative distances by smaller vertex index; when relaxing an edge $(u,v)$ that yields a tentative distance equal to the current tentative distance of $v$, the algorithm adopts $u$ as the parent of $v$ if and only if $u$ has a smaller index than the current parent of $v$.\n- Variant $\\mathsf{X}$ (max-index): The priority queue breaks ties on equal tentative distances by larger vertex index; when relaxing an edge $(u,v)$ that yields a tentative distance equal to the current tentative distance of $v$, the algorithm adopts $u$ as the parent of $v$ if and only if $u$ has a larger index than the current parent of $v$.\n\nLet the trees output by variants $\\mathsf{M}$ and $\\mathsf{X}$ be $T_{\\mathsf{M}}$ and $T_{\\mathsf{X}}$, respectively, both rooted at $0$. Consider building tree path-query data structures such as Lowest Common Ancestor (LCA), where LCA denotes the Lowest Common Ancestor of two nodes in a rooted tree, and Euler tour plus Range Minimum Query (RMQ).\n\nWhich of the following statements are correct? Select all that apply.\n\nA. Variants $\\mathsf{M}$ and $\\mathsf{X}$ compute identical shortest path distances to all vertices, but $T_{\\mathsf{M}}$ and $T_{\\mathsf{X}}$ can yield different LCA answers for the same pair of vertices when the tree itself is used as the rooted structure for LCA.\n\nB. Variant $\\mathsf{X}$ can produce a spanning tree that is not a valid SPT for this graph because some vertex distances change relative to Variant $\\mathsf{M}$.\n\nC. Regardless of whether $T_{\\mathsf{M}}$ or $T_{\\mathsf{X}}$ is used, any LCA data structure whose preprocessing and query time depend only on the number of vertices (for example, Euler tour plus RMQ preprocessing in $O(n)$ and $O(1)$ query time, or binary lifting in $O(n \\log n)$ and $O(\\log n)$ query time) has the same asymptotic performance; however, constant factors and exact LCA identities may differ.\n\nD. For the given graph and source $0$, the LCA of vertices $5$ and $6$ in $T_{\\mathsf{M}}$ is vertex $3$, whereas the LCA of $5$ and $6$ in $T_{\\mathsf{X}}$ is vertex $4$.\n\nE. Using the min-index tie-breaker $\\mathsf{M}$ always minimizes the height of the resulting SPT compared to any other valid tie-breaking rule.\n\nAnswer choices: A, B, C, D, E.", "solution": "We begin from first principles: a shortest path from a source to a vertex in a graph with nonnegative edge weights is any path whose total weight equals the minimum possible among all such paths. Dijkstra's algorithm maintains a set of vertices with finalized distances equal to their shortest path distances and uses a min-priority queue keyed by tentative distances to extract the next vertex with minimum tentative distance. It relaxes edges $(u,v)$ by setting the tentative distance of $v$ to $\\min\\{ \\text{current tentative}(v), \\text{tentative}(u) + w(u,v) \\}$, where $w(u,v)$ is the edge weight. With nonnegative weights, the first time a vertex is extracted from the priority queue, its tentative distance equals its true shortest path distance. A Shortest Path Tree (SPT) is any rooted spanning tree at the source such that the unique path in the tree from the source to each vertex has length equal to the shortest path distance in the original graph.\n\nBecause there can exist multiple distinct shortest paths of equal total weight to the same vertex, a deterministic tie-breaking policy is required to define parent pointers unambiguously. Variants $\\mathsf{M}$ and $\\mathsf{X}$ differ only in tie-breaking when distances are equal; they never choose a parent that would increase a distance because they only adopt new parents on equal or strictly smaller tentative distances.\n\nWe analyze the given graph. The vertices can be partitioned into layers by their shortest path distance from $0$ because all edge weights are $1$ and edges connect only between adjacent layers as specified:\n\n- Layer at distance $1$: vertices $1$ and $2$, because $(0,1)$ and $(0,2)$ have weight $1$.\n- Layer at distance $2$: vertices $3$ and $4$, each reachable via either $1$ or $2$ with two hops of weight $1$.\n- Layer at distance $3$: vertices $5$ and $6$, each reachable via either $3$ or $4$ with three hops of weight $1$.\n\nFormally, the unique shortest path distance function $d$ satisfies $d(0)=0$, $d(1)=d(2)=1$, $d(3)=d(4)=2$, $d(5)=d(6)=3$. This conclusion follows from the triangle inequalities induced by the edge set and the fact that the graph is undirected with uniform weights $1$ on the listed edges: no shorter path can exist because there are no edges of weight $0$ or direct connections that reduce the hop count below these values.\n\nNow we show that both variants compute these same distances. Dijkstra's algorithm correctness relies on nonnegative weights; the next extracted vertex always has finalized shortest distance. Here, at the first step, $0$ is finalized with $d(0)=0$. Then $1$ and $2$ receive tentative distance $1$. Both variants extract the next vertex among $\\{1,2\\}$, but differ in which equal-distance vertex is chosen first: $\\mathsf{M}$ extracts $1$ before $2$, and $\\mathsf{X}$ extracts $2$ before $1$. Regardless, both $1$ and $2$ are finalized with distance $1$. Next, relaxing from $1$ and $2$ yields tentative distances $2$ for $3$ and $4$. They are then finalized with distance $2$ in some order. Finally, relaxing from $3$ and $4$ yields tentative distances $3$ for $5$ and $6$, which are then finalized with distance $3$. At no point does the tie-breaking rule choose a strictly larger tentative distance; thus both variants compute the same distance labels $d$.\n\nWe now characterize the parent pointers and resulting trees $T_{\\mathsf{M}}$ and $T_{\\mathsf{X}}$. Because every edge has weight $1$ and distances increase by exactly $1$ per layer, any parent of a vertex at distance $k$ must be a neighbor at distance $k-1$. Multiple choices exist at equal distance; the tie-breakers decide among them.\n\n- Variant $\\mathsf{M}$ behavior:\n  - After extracting $0$, relaxations set tentative parents $\\text{parent}(1)=0$ and $\\text{parent}(2)=0$.\n  - Between $1$ and $2$, $\\mathsf{M}$ extracts $1$ first (smaller index). Relaxing $(1,3)$ and $(1,4)$ sets $\\text{parent}(3)=1$ and $\\text{parent}(4)=1$ at tentative distance $2$. When $2$ is later extracted and relaxes $(2,3)$ and $(2,4)$, the candidate distance equals the current tentative distance ($2$). The equality tie-breaker in $\\mathsf{M}$ prefers the smaller-index parent, which is already $1$, so parents remain $\\text{parent}(3)=1$ and $\\text{parent}(4)=1$.\n  - For vertices $5$ and $6$, after extracting $3$ (it has smaller index than $4$ at the same distance), relaxations set $\\text{parent}(5)=3$ and $\\text{parent}(6)=3$ at distance $3$. When $4$ later relaxes $(4,5)$ and $(4,6)$, the equality tie-breaker again prefers the smaller-index parent, so parents remain $3$.\n  - Therefore, $T_{\\mathsf{M}}$ has parent pointers: $\\text{parent}(1)=0$, $\\text{parent}(2)=0$, $\\text{parent}(3)=1$, $\\text{parent}(4)=1$, $\\text{parent}(5)=3$, $\\text{parent}(6)=3$.\n\n- Variant $\\mathsf{X}$ behavior:\n  - After extracting $0$, relaxations set tentative parents $\\text{parent}(1)=0$ and $\\text{parent}(2)=0$.\n  - Between $1$ and $2$, $\\mathsf{X}$ extracts $2$ first (larger index). Relaxing $(2,3)$ and $(2,4)$ sets $\\text{parent}(3)=2$ and $\\text{parent}(4)=2$ at distance $2$. When $1$ is later extracted and relaxes $(1,3)$ and $(1,4)$, the candidate distance equals the current tentative distance ($2$); the equality tie-breaker in $\\mathsf{X}$ prefers the larger-index parent, so parents remain $2$.\n  - For vertices $5$ and $6$, between $3$ and $4$ at the same distance, $\\mathsf{X}$ extracts $4$ first (larger index), setting $\\text{parent}(5)=4$ and $\\text{parent}(6)=4$ at distance $3$. When $3$ later relaxes these edges, the equality tie-breaker prefers the larger-index parent, so parents remain $4$.\n  - Therefore, $T_{\\mathsf{X}}$ has parent pointers: $\\text{parent}(1)=0$, $\\text{parent}(2)=0$, $\\text{parent}(3)=2$, $\\text{parent}(4)=2$, $\\text{parent}(5)=4$, $\\text{parent}(6)=4$.\n\nBoth trees are valid SPTs because, by construction, the path from $0$ to each vertex $v$ in $T_{\\mathsf{M}}$ or $T_{\\mathsf{X}}$ has exactly $d(v)$ edges of weight $1$, hence total weight $d(v)$, which equals the shortest path distance.\n\nWe now examine Lowest Common Ancestor (LCA) implications. The LCA of two vertices $u$ and $v$ in a rooted tree is the unique deepest vertex that is an ancestor of both. In $T_{\\mathsf{M}}$, the root is $0$, and the depths (number of edges from the root) are $\\text{depth}(0)=0$, $\\text{depth}(1)=\\text{depth}(2)=1$, $\\text{depth}(3)=\\text{depth}(4)=2$, $\\text{depth}(5)=\\text{depth}(6)=3$. Moreover, $\\text{parent}(5)=3$ and $\\text{parent}(6)=3$ in $T_{\\mathsf{M}}$, so the unique deepest common ancestor of $5$ and $6$ is $3$. In $T_{\\mathsf{X}}$, $\\text{parent}(5)=4$ and $\\text{parent}(6)=4$, so the LCA of $5$ and $6$ is $4$. Thus, although graph distances are invariant, the LCA answers can differ because they depend on the specific tree structure.\n\nConcerning preprocessing and query complexity for LCA, classical methods such as Euler tour plus Range Minimum Query (RMQ) achieve $O(n)$ preprocessing and $O(1)$ query time, and binary lifting achieves $O(n \\log n)$ preprocessing and $O(\\log n)$ query time, both as functions of the number of vertices $n$. These bounds do not depend on the precise shape of the tree, so asymptotically they are the same for $T_{\\mathsf{M}}$ and $T_{\\mathsf{X}}$. However, constant factors (for example, cache behavior in Euler tour orderings or the exact set of ancestor pointers filled) and the specific LCA vertex identities for a given pair can differ because the trees differ.\n\nWe now analyze each option:\n\n- Option A: Correct. As argued, both variants compute identical shortest path distances because Dijkstra's algorithm with nonnegative weights finalizes true distances, and tie-breaking only selects among equal-distance parents. However, the parent choices induce different SPT shapes, which can and do yield different LCA answers for the same vertex pair, for example $\\text{LCA}(5,6)$.\n- Option B: Incorrect. Variant $\\mathsf{X}$ never accepts a parent that yields a strictly larger tentative distance; it only changes parent on equal distances and thus preserves shortest path distances. Therefore, it still yields a valid SPT.\n- Option C: Correct. The asymptotic preprocessing and query time of standard LCA data structures depend on $n$ (and possibly $\\log n$) but not on the particular shape of the tree. While constant factors and LCA identities may change, the big-$O$ bounds remain the same for $T_{\\mathsf{M}}$ and $T_{\\mathsf{X}}$.\n- Option D: Correct. As shown, $\\text{LCA}_{T_{\\mathsf{M}}}(5,6)=3$ and $\\text{LCA}_{T_{\\mathsf{X}}}(5,6)=4$.\n- Option E: Incorrect. The min-index tie-breaker does not in general minimize tree height; different graphs can produce SPTs of the same height under many tie-breakers, and there exist graphs where different valid SPTs can have different heights that are not necessarily minimized by choosing the smallest-index parent. Moreover, in this specific graph, both $T_{\\mathsf{M}}$ and $T_{\\mathsf{X}}$ have the same height $3$.\n\nTherefore, the correct options are A, C, and D.", "answer": "$$\\boxed{ACD}$$", "id": "3271591"}, {"introduction": "The Bellman-Ford algorithm is essential for graphs with negative edge weights, operating through successive rounds of relaxation. This practice [@problem_id:3271593] lets you trace the algorithm's execution and observe how distance estimates propagate and improve with each iteration. By determining when the distances finalize, you will uncover a deep connection between the algorithm's convergence behavior and a key structural property of the graph: the number of edges in its longest shortest path.", "problem": "Consider the following directed, weighted graph with source vertex $s$ and vertex set $\\{s,a,b,c,d,e,t\\}$. The directed edges and their weights are:\n- $s \\to a$ with weight $2$, $s \\to b$ with weight $7$, $s \\to d$ with weight $15$,\n- $a \\to b$ with weight $-1$, $a \\to c$ with weight $2$, $a \\to d$ with weight $10$,\n- $b \\to c$ with weight $-2$, $b \\to e$ with weight $10$, $b \\to t$ with weight $6$,\n- $c \\to d$ with weight $1$, $c \\to t$ with weight $4$,\n- $d \\to e$ with weight $3$, $d \\to t$ with weight $0$,\n- $e \\to t$ with weight $-1$.\n\nAssume there are no negative-weight cycles reachable from $s$. We run the Bellman–Ford algorithm (in synchronous rounds) from $s$ as follows. Let $d^{(0)}(s)=0$ and $d^{(0)}(v)=+\\infty$ for all $v \\neq s$. For each iteration index $k \\geq 1$, compute a new distance label $d^{(k)}(v)$ for every vertex $v$ by relaxing every edge once, but using only the labels from the previous iteration $d^{(k-1)}(\\cdot)$ when evaluating all relaxations in iteration $k$. That is, within a given iteration, no update to one vertex can influence another update in the same iteration; all updates take effect simultaneously at the end of the iteration.\n\nYour tasks are:\n- Determine the first iteration index $k$ after which all labels $d^{(k)}(v)$ have stabilized to their final single-source shortest-path distances from $s$ and will never change in any subsequent iterations.\n- Justify, from first principles, why this $k$ coincides with the length in edges of the longest among all minimum-weight $s \\to v$ paths, taken over all $v$ that are reachable from $s$.\n\nGive your final answer as the exact integer value of $k$ (no rounding is required).", "solution": "The problem asks for the first iteration index $k$ at which the distance labels computed by the synchronous Bellman-Ford algorithm stabilize to their final values. This occurs when $d^{(k)}(v) = d^{(k-1)}(v)$ for all vertices $v$. The theoretical justification is that this index $k$ corresponds to the maximum number of edges in any shortest path from the source $s$.\n\nWe trace the algorithm's execution step by step. $d^{(k)}(v)$ denotes the distance to vertex $v$ after iteration $k$.\n\n- **Initialization ($k=0$):**\n  $d^{(0)} = [d(s): 0, d(a): \\infty, d(b): \\infty, d(c): \\infty, d(d): \\infty, d(e): \\infty, d(t): \\infty]$\n\n- **Iteration $k=1$:** Relaxing edges from $s$.\n  - $d(a) = d^{(0)}(s) + w(s,a) = 0 + 2 = 2$\n  - $d(b) = d^{(0)}(s) + w(s,b) = 0 + 7 = 7$\n  - $d(d) = d^{(0)}(s) + w(s,d) = 0 + 15 = 15$\n  $d^{(1)} = [0, 2, 7, \\infty, 15, \\infty, \\infty]$\n\n- **Iteration $k=2$:** Relaxing all edges using $d^{(1)}$ values.\n  - $d(b) = \\min(d^{(1)}(b), d^{(1)}(a) + w(a,b)) = \\min(7, 2 - 1) = 1$\n  - $d(c) = \\min(d^{(1)}(c), d^{(1)}(a) + w(a,c), d^{(1)}(b) + w(b,c)) = \\min(\\infty, 2+2, 7-2) = 4$\n  - $d(d) = \\min(d^{(1)}(d), d^{(1)}(a) + w(a,d)) = \\min(15, 2+10) = 12$\n  - $d(e) = \\min(d^{(1)}(e), d^{(1)}(b) + w(b,e)) = \\min(\\infty, 7+10) = 17$\n  - $d(t) = \\min(d^{(1)}(t), d^{(1)}(b) + w(b,t), d^{(1)}(d) + w(d,t)) = \\min(\\infty, 7+6, 15+0) = 13$\n  $d^{(2)} = [0, 2, 1, 4, 12, 17, 13]$\n\n- **Iteration $k=3$:** Using $d^{(2)}$ values.\n  - $d(c) = \\min(d^{(2)}(c), d^{(2)}(b) + w(b,c)) = \\min(4, 1 - 2) = -1$\n  - $d(d) = \\min(d^{(2)}(d), d^{(2)}(c) + w(c,d)) = \\min(12, 4 + 1) = 5$\n  - $d(e) = \\min(d^{(2)}(e), d^{(2)}(b) + w(b,e)) = \\min(17, 1 + 10) = 11$\n  - $d(t) = \\min(d^{(2)}(t), d^{(2)}(b) + w(b,t), d^{(2)}(c) + w(c,t)) = \\min(13, 1+6, 4+4) = 7$\n  $d^{(3)} = [0, 2, 1, -1, 5, 11, 7]$\n\n- **Iteration $k=4$:** Using $d^{(3)}$ values.\n  - $d(d) = \\min(d^{(3)}(d), d^{(3)}(c) + w(c,d)) = \\min(5, -1 + 1) = 0$\n  - $d(e) = \\min(d^{(3)}(e), d^{(3)}(d) + w(d,e)) = \\min(11, 5 + 3) = 8$\n  - $d(t) = \\min(d^{(3)}(t), d^{(3)}(c) + w(c,t), d^{(3)}(d) + w(d,t)) = \\min(7, -1+4, 5+0) = 3$\n  $d^{(4)} = [0, 2, 1, -1, 0, 8, 3]$\n\n- **Iteration $k=5$:** Using $d^{(4)}$ values.\n  - $d(e) = \\min(d^{(4)}(e), d^{(4)}(d) + w(d,e)) = \\min(8, 0 + 3) = 3$\n  - $d(t) = \\min(d^{(4)}(t), d^{(4)}(d) + w(d,t), d^{(4)}(e) + w(e,t)) = \\min(3, 0+0, 8-1) = 0$\n  $d^{(5)} = [0, 2, 1, -1, 0, 3, 0]$\n\n- **Iteration $k=6$:** Using $d^{(5)}$ values.\n  - A full pass of relaxations reveals no further changes. For example, $d(e)$ remains $d^{(5)}(d) + 3 = 0+3=3$, and $d(t)$ remains $\\min(d^{(5)}(t), d^{(5)}(d)+0, d^{(5)}(e)-1) = \\min(0, 0, 3-1)=0$.\n  The distances are now stable. The first iteration that produces the final, stable distance vector is $k=5$.\n\n**Justification from First Principles:**\nThe synchronous Bellman-Ford algorithm has the property that after $k$ iterations, the value $d^{(k)}(v)$ is the weight of the shortest path from $s$ to $v$ using at most $k$ edges. Since there are no negative-weight cycles, any shortest path is simple. The algorithm is guaranteed to find the true shortest path distances, and the process stabilizes when $d^{(k)}(v) = d^{(k-1)}(v)$ for all $v$.\n\nThe exact iteration of convergence, $k$, is determined by the maximum number of edges on any shortest path from $s$. A shortest path with $m$ edges will have its distance propagated from the source one edge at a time, requiring $m$ iterations to be fully discovered. Therefore, all distances will be final only after a number of iterations equal to the maximum number of edges on any shortest path in the graph.\n\nLet's find the shortest paths and their edge counts:\n- $s \\to a$: path $(s,a)$, weight 2, **1 edge**.\n- $s \\to b$: path $(s,a,b)$, weight $2-1=1$, **2 edges**.\n- $s \\to c$: path $(s,a,b,c)$, weight $1-2=-1$, **3 edges**.\n- $s \\to d$: path $(s,a,b,c,d)$, weight $-1+1=0$, **4 edges**.\n- $s \\to e$: path $(s,a,b,c,d,e)$, weight $0+3=3$, **5 edges**.\n- $s \\to t$: path $(s,a,b,c,d,t)$, weight $0+0=0$, **5 edges**.\n\nThe longest shortest path (in terms of edge count) is 5 edges (to vertices $e$ and $t$). Thus, the distance labels will not fully stabilize until iteration $k=5$. The final integer value for $k$ is 5.", "answer": "$$\\boxed{5}$$", "id": "3271593"}, {"introduction": "Real-world routing rarely optimizes for a single metric. Is the \"best\" path the fastest, the cheapest, or the safest? This coding practice [@problem_id:3271663] introduces scalarization, a technique to solve such multi-objective problems by blending criteria like distance and risk into a single edge weight, $w(e) = \\alpha \\cdot \\mathrm{dist}(e) + \\beta \\cdot \\mathrm{risk}(e)$. By implementing and testing this approach, you will gain practical experience in adapting standard shortest path algorithms into powerful decision-making frameworks.", "problem": "You are given a directed graph with each edge annotated by two nonnegative attributes: a distance and a risk. A single-source shortest path problem is defined by scalarizing these two attributes into a single nonnegative edge-weight function using nonnegative coefficients. Starting from the foundational base of graph path costs defined as additive over edges and the definition of optimal paths as those minimizing total additive cost, implement a program that computes single-source shortest paths for a fixed source under multiple scalarizations and reports the distances to all vertices.\n\nDefinitions to use as the fundamental base:\n- A directed graph is a pair $G=(V,E)$ with vertex set $V$ and directed edge set $E\\subseteq V\\times V$.\n- Each directed edge $e\\in E$ has two given nonnegative attributes: $\\mathrm{dist}(e)\\ge 0$ and $\\mathrm{risk}(e)\\ge 0$.\n- For nonnegative coefficients $\\alpha\\ge 0$ and $\\beta\\ge 0$, define the scalarized edge weight function $w_{\\alpha,\\beta}(e)=\\alpha\\cdot \\mathrm{dist}(e)+\\beta\\cdot \\mathrm{risk}(e)$.\n- For a path $P=(e_1,e_2,\\dots,e_k)$, its total cost under $(\\alpha,\\beta)$ is $W_{\\alpha,\\beta}(P)=\\sum_{i=1}^k w_{\\alpha,\\beta}(e_i)$.\n- The single-source shortest path problem asks for $d_{\\alpha,\\beta}(v)$, the minimal total cost $W_{\\alpha,\\beta}(P)$ over all paths from a fixed source vertex $s$ to vertex $v$.\n\nTask:\n- Using only the above base definitions and well-tested facts that additive, nonnegative path costs admit greedy relaxation with a priority rule, design an algorithm to compute $d_{\\alpha,\\beta}(v)$ for all $v\\in V$ for several given $(\\alpha,\\beta)$ pairs, and implement it as a complete program that runs without input.\n- You must not assume any further formulas beyond additivity and nonnegativity; derive the algorithmic steps from those principles.\n\nGraph specification:\n- Vertex set $V=\\{0,1,2,3,4,5,6\\}$ with source $s=0$.\n- Directed edges $E$ with attributes $(\\mathrm{dist},\\mathrm{risk})$ are as follows, written as “from $u$ to $v$ has $(d,r)$”:\n  - From $0$ to $1$ has $(2,8)$.\n  - From $0$ to $2$ has $(5,1)$.\n  - From $0$ to $3$ has $(4,4)$.\n  - From $0$ to $4$ has $(9,1)$.\n  - From $1$ to $3$ has $(2,7)$.\n  - From $1$ to $4$ has $(2,8)$.\n  - From $1$ to $5$ has $(7,2)$.\n  - From $2$ to $3$ has $(1,2)$.\n  - From $2$ to $4$ has $(5,1)$.\n  - From $2$ to $5$ has $(4,1)$.\n  - From $3$ to $4$ has $(2,4)$.\n  - From $3$ to $5$ has $(2,3)$.\n  - From $4$ to $6$ has $(3,9)$.\n  - From $5$ to $6$ has $(3,1)$.\n\nTest suite of scalarization parameters:\n- Case $1$: $(\\alpha,\\beta)=(1,0)$.\n- Case $2$: $(\\alpha,\\beta)=(0,1)$.\n- Case $3$: $(\\alpha,\\beta)=(1,1)$.\n- Case $4$: $(\\alpha,\\beta)=(2,1)$.\n- Case $5$: $(\\alpha,\\beta)=(1,2)$.\n- Case $6$: $(\\alpha,\\beta)=(0,0)$.\n- Case $7$: $(\\alpha,\\beta)=(10,10)$.\n- Case $8$: $(\\alpha,\\beta)=(3,0.1)$.\n\nRequirements:\n- For each case, compute the vector of single-source shortest path distances $[d_{\\alpha,\\beta}(0),d_{\\alpha,\\beta}(1),d_{\\alpha,\\beta}(2),d_{\\alpha,\\beta}(3),d_{\\alpha,\\beta}(4),d_{\\alpha,\\beta}(5),d_{\\alpha,\\beta}(6)]$ in ascending vertex index order, with $d_{\\alpha,\\beta}(0)=0$ by definition.\n- All arithmetic is unitless real numbers; do not round.\n- Final output format: Your program should produce a single line of output containing the results as a comma-separated list of the eight case-vectors enclosed in square brackets. Concretely, print a single line equal to\n  $[[\\text{case1}], [\\text{case2}], [\\text{case3}], [\\text{case4}], [\\text{case5}], [\\text{case6}], [\\text{case7}], [\\text{case8}]]$\n  where each inner list is the seven distances for that case, written as numbers with no units. Do not include any spaces.", "solution": "We start from the base definitions of a directed graph $G=(V,E)$ with nonnegative edge attributes and additive path costs. The total cost of a path $P=(e_1,\\dots,e_k)$ under any fixed nonnegative pair $(\\alpha,\\beta)$ is $W_{\\alpha,\\beta}(P)=\\sum_{i=1}^k w_{\\alpha,\\beta}(e_i)$ where $w_{\\alpha,\\beta}(e)=\\alpha\\cdot \\mathrm{dist}(e)+\\beta\\cdot \\mathrm{risk}(e)$. Because $\\alpha\\ge 0$, $\\beta\\ge 0$, and the edge attributes are nonnegative, it follows that $w_{\\alpha,\\beta}(e)\\ge 0$ for every edge $e$ for all cases specified, including the degenerate case $(\\alpha,\\beta)=(0,0)$ where $w_{\\alpha,\\beta}(e)=0$ for all edges.\n\nFrom the principle of optimality and the additivity of path costs, the minimal path cost $d_{\\alpha,\\beta}(v)$ from source $s$ to any vertex $v$ satisfies that there exists an optimal path whose proper prefix to any intermediate vertex on that path is itself optimal. Under the additional well-tested fact that nonnegative edge weights imply that extending a path cannot decrease its cost (monotonicity), we can employ a greedy relaxation strategy: repeatedly select the not-yet-finalized vertex with the smallest tentative distance, and relax its outgoing edges. This strategy is realized by a priority queue. Each relaxation is an application of the inequality\n$$\nd_{\\alpha,\\beta}(v)\\le d_{\\alpha,\\beta}(u)+w_{\\alpha,\\beta}(u,v)\n$$\nfor each edge $(u,v)\\in E$, with strict improvement when the right-hand side is smaller than the current tentative value. The correctness follows because with nonnegative weights, once a vertex $u$ attains the smallest tentative distance among all unsettled vertices, no alternative route to $u$ via any other unsettled vertex can yield a smaller cost, as that would require passing through a vertex with tentative distance at least as large and then adding a nonnegative edge weight, contradicting minimality.\n\nAlgorithm design derived from these principles:\n- For each case $(\\alpha,\\beta)$, form implicit edge weights via $w_{\\alpha,\\beta}(e)=\\alpha\\cdot \\mathrm{dist}(e)+\\beta\\cdot \\mathrm{risk}(e)$ on-the-fly during relaxation, without modifying the graph.\n- Initialize distances $d_{\\alpha,\\beta}(v)=+\\infty$ for all $v\\in V$ except $d_{\\alpha,\\beta}(s)=0$.\n- Use a min-priority queue keyed by current tentative distance. Pop the smallest, finalize it, and relax all outgoing edges using $d_{\\alpha,\\beta}(v)\\gets \\min\\{d_{\\alpha,\\beta}(v), d_{\\alpha,\\beta}(u)+w_{\\alpha,\\beta}(u,v)\\}$.\n- Continue until the queue is empty.\n\nComplexity: Using a binary heap priority queue, the running time is $O\\big((|V|+|E|)\\log |V|\\big)$ per case, and $O\\big(T\\cdot (|V|+|E|)\\log |V|\\big)$ across $T$ cases.\n\nSensitivity reasoning with respect to $(\\alpha,\\beta)$:\n- Changing $(\\alpha,\\beta)$ linearly changes every edge weight. As $(\\alpha,\\beta)$ varies, the shortest path tree can change where different tradeoffs between distance and risk flip the order of candidate path costs.\n- Positive scaling invariance: if $(\\alpha,\\beta)$ is multiplied by any $\\lambda>0$, then $w_{\\lambda\\alpha,\\lambda\\beta}(e)=\\lambda\\cdot w_{\\alpha,\\beta}(e)$ for all edges $e$, so every path cost is multiplied by $\\lambda$, preserving the set of minimizing paths. Consequently, $d_{\\lambda\\alpha,\\lambda\\beta}(v)=\\lambda\\cdot d_{\\alpha,\\beta}(v)$ for all $v$.\n\nApplication to the given graph:\n- Vertices are $V=\\{0,1,2,3,4,5,6\\}$ with source $s=0$.\n- Edges with $(\\mathrm{dist},\\mathrm{risk})$:\n  $(0\\to 1):(2,8)$, $(0\\to 2):(5,1)$, $(0\\to 3):(4,4)$, $(0\\to 4):(9,1)$,\n  $(1\\to 3):(2,7)$, $(1\\to 4):(2,8)$, $(1\\to 5):(7,2)$,\n  $(2\\to 3):(1,2)$, $(2\\to 4):(5,1)$, $(2\\to 5):(4,1)$,\n  $(3\\to 4):(2,4)$, $(3\\to 5):(2,3)$,\n  $(4\\to 6):(3,9)$, $(5\\to 6):(3,1)$.\n\nFor each case, running the outlined algorithm yields the following complete vectors of distances in vertex index order $[0,1,2,3,4,5,6]$:\n- Case $1$, $(\\alpha,\\beta)=(1,0)$ (pure distance): $[0,2,5,4,4,6,7]$.\n- Case $2$, $(\\alpha,\\beta)=(0,1)$ (pure risk): $[0,8,1,3,1,2,3]$.\n- Case $3$, $(\\alpha,\\beta)=(1,1)$ (equal weighting): $[0,10,6,8,10,11,15]$.\n- Case $4$, $(\\alpha,\\beta)=(2,1)$ (distance emphasized): $[0,12,11,12,19,19,26]$.\n- Case $5$, $(\\alpha,\\beta)=(1,2)$ (risk emphasized): $[0,18,7,12,11,13,18]$.\n- Case $6$, $(\\alpha,\\beta)=(0,0)$ (degenerate zero weights): $[0,0,0,0,0,0,0]$.\n- Case $7$, $(\\alpha,\\beta)=(10,10)$ (positive scaling of Case $3$): by scaling invariance, this equals $10$ times Case $3$, namely $[0,100,60,80,100,110,150]$.\n- Case $8$, $(\\alpha,\\beta)=(3,0.1)$ (distance dominates with slight risk penalty): $[0,6.8,15.1,12.4,13.6,18.7,23.5]$.\n\nInterpretation highlights showing sensitivity:\n- For vertex $6$, the optimal route under $(1,0)$ is $0\\to 1\\to 4\\to 6$ with total distance $7$, whereas under $(0,1)$ it is $0\\to 2\\to 5\\to 6$ with total risk $3$. Under $(2,1)$ the best route becomes $0\\to 3\\to 5\\to 6$ with total cost $26$ in the $2 \\cdot \\mathrm{dist}+\\mathrm{risk}$ metric, while under $(3,0.1)$ the route $0\\to 1\\to 4\\to 6$ is again preferred with cost $23.5$.\n- Case $7$ numerically confirms scaling invariance relative to Case $3$.\n\nThe program produced below implements this computation and prints a single line containing the eight case-vectors, with numbers unrounded and without spaces, in the required outer list order.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Execution environment: Python 3.12, numpy 1.23.5 allowed but not required.\n# This program computes single-source shortest path distances for multiple\n# scalarizations of edge attributes (distance, risk) and prints the results\n# as a single line in the required format.\n\nimport heapq\nimport math\nimport numpy as np  # Allowed; not strictly required but imported per environment spec.\n\ndef dijkstra_scalarized(graph, n_vertices, source, alpha, beta):\n    \"\"\"Compute single-source shortest paths with edge weights w = alpha*dist + beta*risk.\"\"\"\n    dist = [math.inf] * n_vertices\n    dist[source] = 0.0\n    pq = [(0.0, source)]\n    visited = [False] * n_vertices\n    while pq:\n        d_u, u = heapq.heappop(pq)\n        if visited[u]:\n            continue\n        visited[u] = True\n        # If the popped distance is greater than recorded, skip (heap invariant)\n        if d_u > dist[u]:\n            continue\n        for v, d_attr, r_attr in graph.get(u, []):\n            w = alpha * d_attr + beta * r_attr\n            new_d = d_u + w\n            if new_d  dist[v]:\n                dist[v] = new_d\n                heapq.heappush(pq, (new_d, v))\n    return dist\n\ndef format_number(x):\n    \"\"\"Format numbers: integers without decimal point; otherwise compact float.\"\"\"\n    # Treat very small negative zeros as zero\n    if abs(x)  1e-15:\n        x = 0.0\n    # If x is very close to an integer, format as integer\n    r = round(x)\n    if math.isfinite(x) and abs(x - r)  1e-9:\n        return str(int(r))\n    # Otherwise use a compact representation with up to 12 significant digits\n    return format(x, '.12g')\n\ndef solve():\n    # Graph definition: adjacency list with tuples (to, distance, risk)\n    graph = {\n        0: [(1, 2.0, 8.0), (2, 5.0, 1.0), (3, 4.0, 4.0), (4, 9.0, 1.0)],\n        1: [(3, 2.0, 7.0), (4, 2.0, 8.0), (5, 7.0, 2.0)],\n        2: [(3, 1.0, 2.0), (4, 5.0, 1.0), (5, 4.0, 1.0)],\n        3: [(4, 2.0, 4.0), (5, 2.0, 3.0)],\n        4: [(6, 3.0, 9.0)],\n        5: [(6, 3.0, 1.0)],\n        6: []\n    }\n    n_vertices = 7\n    source = 0\n\n    # Test cases: list of (alpha, beta) pairs in the specified order.\n    test_cases = [\n        (1.0, 0.0),     # Case 1\n        (0.0, 1.0),     # Case 2\n        (1.0, 1.0),     # Case 3\n        (2.0, 1.0),     # Case 4\n        (1.0, 2.0),     # Case 5\n        (0.0, 0.0),     # Case 6\n        (10.0, 10.0),   # Case 7\n        (3.0, 0.1)      # Case 8\n    ]\n\n    all_results = []\n    for alpha, beta in test_cases:\n        dist = dijkstra_scalarized(graph, n_vertices, source, alpha, beta)\n        all_results.append(dist)\n\n    # Build the exact required output: one line, outer list of 8 inner lists, no spaces.\n    inner_lists_strings = []\n    for row in all_results:\n        nums = ','.join(format_number(x) for x in row)\n        inner_lists_strings.append(f\"[{nums}]\")\n    output = f\"[{','.join(inner_lists_strings)}]\"\n    print(output)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3271663"}]}