{"hands_on_practices": [{"introduction": "Linear probing is simple to implement, but its performance can be surprisingly sensitive to the order of key insertions. This practice explores the phenomenon of primary clustering, where non-random insertion orders can lead to the formation of large contiguous blocks of occupied slots, drastically degrading performance. By implementing and comparing sorted versus random insertions, you will gain a practical, hands-on understanding of why input data patterns are a critical consideration in hash table design [@problem_id:3257202].", "problem": "You are to implement and analyze an open addressing hash table with linear probing to investigate how batch insertion order affects performance. The investigation must compare two batch insertion orders for the same set of integer keys: ascending sorted order and a pseudorandom order. The comparison must quantify the effect using well-defined metrics and a fixed hash function that creates a monotone mapping from key values to home addresses, leading to potentially non-uniform collisions when keys are not uniformly distributed.\n\nFundamental base and core definitions:\n- Open addressing inserts each key into a single array of capacity $m$ by probing a sequence of candidate indices until finding an empty slot.\n- Linear probing defines the probe sequence for a key $k$ as successive indices $h(k), h(k)+1, h(k)+2, \\dots$ modulo $m$, where $h(k)$ is the hash of $k$.\n- The hash function to implement is the division method $h(k) = \\left\\lfloor \\dfrac{m \\cdot k}{U} \\right\\rfloor$, where $U$ is a positive integer defining the key universe scale, and $k$ is an integer key in the range $[0, U-1]$.\n- The number of probes for inserting a single key is defined as the count of examined slots, including the final successful slot.\n- The maximum contiguous occupied cluster length at the end of a batch is defined as the maximum number of consecutive occupied slots encountered when traversing the table cyclically (wrap-around is considered; the traversal must avoid double-counting by starting immediately after some empty slot).\n\nTwo insertion orders:\n- Sorted order: keys inserted in ascending numerical order.\n- Random order: keys inserted in the order induced by sorting a pseudorandom score for each key generated by a Linear Congruential Generator (LCG). The Linear Congruential Generator (LCG) is defined by $X_{i+1} = (a X_i + c) \\bmod M$ with parameters $a = 1664525$, $c = 1013904223$, and $M = 2^{32}$. A fixed seed $X_0$ is given per test case. To obtain a permutation, generate a score $X_i$ per key and sort keys by these scores.\n\nKey set construction:\n- For each test case, keys are constructed to induce a bimodal density in home addresses: a low-index group and a high-index group.\n- Let $L$ and $t$ be positive integers. The low group consists of $t$ keys for each bucket index $i \\in \\{0, 1, \\dots, L-1\\}$; the high group consists of $t$ keys for each bucket index $j \\in \\{m-L, m-L+1, \\dots, m-1\\}$.\n- For bucket index $b$, choose $t$ distinct keys $k$ from the interval $I_b = \\left[\\left\\lfloor \\dfrac{U \\cdot b}{m} \\right\\rfloor, \\left\\lfloor \\dfrac{U \\cdot (b+1)}{m} \\right\\rfloor - 1\\right]$ so that $h(k) = b$. Use the first $t$ integers in $I_b$ (in ascending order). The total number of keys is $n = 2Lt$, and the load factor is $n/m$. All test cases satisfy $n  m$ to allow successful insertion.\n\nMetrics to compute per test case:\n- The average number of probes for sorted order, denoted $\\overline{P}_{\\mathrm{sorted}}$.\n- The average number of probes for random order, denoted $\\overline{P}_{\\mathrm{random}}$.\n- The final maximum cluster length for sorted order, denoted $C_{\\mathrm{sorted}}$.\n- The final maximum cluster length for random order, denoted $C_{\\mathrm{random}}$.\n- Report the ratios $R_P = \\dfrac{\\overline{P}_{\\mathrm{sorted}}}{\\overline{P}_{\\mathrm{random}}}$ and $R_C = \\dfrac{C_{\\mathrm{sorted}}}{C_{\\mathrm{random}}}$.\n\nTest suite:\nFor each parameter tuple $(m, U, L, t, \\text{seed})$, construct keys and measure the two ratios above.\n1. $(m, U, L, t, \\text{seed}) = (1024, 1024000, 240, 2, 123456789)$ so that $n = 2 \\cdot 240 \\cdot 2 = 960$.\n2. $(m, U, L, t, \\text{seed}) = (512, 512000, 120, 2, 987654321)$ so that $n = 480$.\n3. $(m, U, L, t, \\text{seed}) = (257, 257000, 64, 1, 20231102)$ so that $n = 128$.\n4. $(m, U, L, t, \\text{seed}) = (128, 128000, 24, 2, 31415926)$ so that $n = 96$.\n\nRequired final output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in order for each test case, first $R_P$ then $R_C$, both as floating-point numbers. For the entire test suite above, the output must be:\n$[R_{P,1}, R_{C,1}, R_{P,2}, R_{C,2}, R_{P,3}, R_{C,3}, R_{P,4}, R_{C,4}]$.\n\nConstraints and expectations:\n- Implement the hash table and metrics exactly as defined.\n- No external input is permitted; the program must embed the test suite and print the single output line.\n- Use the specified LCG to generate the pseudorandom order per test case.\n- The program must be complete and runnable and must strictly adhere to the final output format described above.", "solution": "The user provided a detailed problem statement to analyze the performance of an open addressing hash table with linear probing. The analysis focuses on the impact of insertion order by comparing a sorted insertion of keys against a pseudorandom insertion order.\n\n### Step 1: Problem Validation\n\nThe problem is subjected to a rigorous validation process.\n\n**Givens Extracted from the Problem Statement:**\n\n*   **Hash Table Method:** Open addressing with linear probing.\n*   **Table Capacity:** $m$.\n*   **Key Universe:** Integers $k$ in the range $[0, U-1]$.\n*   **Hash Function:** Division method, $h(k) = \\left\\lfloor \\dfrac{m \\cdot k}{U} \\right\\rfloor$.\n*   **Probe Sequence:** For a key $k$, the sequence is $h(k), (h(k)+1) \\pmod m, (h(k)+2) \\pmod m, \\dots$.\n*   **Probe Count Definition:** The number of slots examined for an insertion, including the final empty slot where the key is placed.\n*   **Maximum Cluster Length Definition:** The maximum length of a contiguous block of occupied slots, considering cyclic wrap-around. The measurement starts after an empty slot to handle the wrap-around case unambiguously.\n*   **Key Set Construction:**\n    *   Parameters $L$ and $t$ are positive integers.\n    *   A bimodal distribution of keys is generated.\n    *   Low-index group: For each bucket index $b \\in \\{0, 1, \\dots, L-1\\}$, select the first $t$ integers $k$ from the interval $I_b = \\left[\\left\\lfloor \\dfrac{U \\cdot b}{m} \\right\\rfloor, \\left\\lfloor \\dfrac{U \\cdot (b+1)}{m} \\right\\rfloor - 1\\right]$ such that $h(k)=b$.\n    *   High-index group: For each bucket index $b \\in \\{m-L, m-L+1, \\dots, m-1\\}$, select keys similarly.\n    *   Total number of keys is $n = 2Lt$. It is stated that $n  m$.\n*   **Insertion Orders:**\n    *   **Sorted:** Keys are inserted in ascending numerical order.\n    *   **Random:** Keys are inserted according to an order determined by a Linear Congruential Generator (LCG).\n*   **LCG Specification:** $X_{i+1} = (a X_i + c) \\pmod M$, with $a = 1664525$, $c = 1013904223$, $M = 2^{32}$, and a specific seed $X_0$ for each test case. Keys are sorted based on their generated LCG scores.\n*   **Metrics for Comparison:**\n    *   Average probes for sorted insertion: $\\overline{P}_{\\mathrm{sorted}}$.\n    *   Average probes for random insertion: $\\overline{P}_{\\mathrm{random}}$.\n    *   Maximum final cluster length for sorted insertion: $C_{\\mathrm{sorted}}$.\n    *   Maximum final cluster length for random insertion: $C_{\\mathrm{random}}$.\n*   **Ratios to be Computed:** $R_P = \\dfrac{\\overline{P}_{\\mathrm{sorted}}}{\\overline{P}_{\\mathrm{random}}}$ and $R_C = \\dfrac{C_{\\mathrm{sorted}}}{C_{\\mathrm{random}}}$.\n*   **Test Cases:** Four tuples of $(m, U, L, t, \\text{seed})$ are provided.\n    1.  $(1024, 1024000, 240, 2, 123456789)$\n    2.  $(512, 512000, 120, 2, 987654321)$\n    3.  $(257, 257000, 64, 1, 20231102)$\n    4.  $(128, 128000, 24, 2, 31415926)$\n\n**Validation Verdict:**\n\nThe problem is **valid**. It is scientifically grounded in the principles of data structures and algorithms, specifically hash table analysis. It is well-posed, with all necessary parameters, initial conditions, and definitions provided explicitly. The terminology is precise, and the objectives are objective and quantifiable. The problem describes a deterministic procedure for which a unique solution exists and is computationally feasible. The setup is self-contained and free of contradictions; the condition $n  m$ is satisfied for all test cases, ensuring that all insertions can succeed. The experiment is well-designed to demonstrate the phenomenon of primary clustering in linear probing under specific non-uniform conditions.\n\n### Step 2: Solution Derivation\n\nThe solution involves implementing the specified hash table, key generation, insertion orders, and metric calculations for each test case.\n\n**1. Algorithmic Framework**\n\nFor each test case defined by the parameters $(m, U, L, t, \\text{seed})$:\n1.  Generate the set of $n=2Lt$ integer keys.\n2.  Create two insertion sequences: one sorted, one pseudorandom.\n3.  For each sequence:\n    a.  Initialize an empty hash table of size $m$.\n    b.  Insert all keys, calculating the total number of probes.\n    c.  Compute the average number of probes, $\\overline{P}$.\n    d.  After all insertions, compute the maximum cluster length, $C$.\n4.  Calculate the ratios $R_P$ and $R_C$.\n\n**2. Key Generation**\n\nThe set of keys is the union of two groups:\n*   A low-index group: for each bucket index $b$ from $0$ to $L-1$, we generate $t$ keys. The keys for a given $b$ are the first $t$ integers in the interval $I_b$. The starting key for bucket $b$ is $k_{b,0} = \\lfloor (U \\cdot b) / m \\rfloor$. The $t$ keys are thus $\\{k_{b,0}, k_{b,0}+1, \\dots, k_{b,0}+t-1\\}$.\n*   A high-index group: for each bucket index $b$ from $m-L$ to $m-1$, we generate $t$ keys in the same manner.\nThe total number of keys is $n=2Lt$.\n\n**3. Insertion Order Generation**\n\n*   **Sorted Order:** The entire set of $n$ keys is sorted numerically in ascending order.\n*   **Random Order:** A pseudorandom permutation of the keys is generated.\n    1.  Initialize the LCG state with the given seed: $X_0 = \\text{seed}$.\n    2.  Generate $n$ pseudorandom numbers, $X_1, X_2, \\dots, X_n$, using the recurrence $X_{i+1} = (a X_i + c) \\pmod M$, where $a=1664525$, $c=1013904223$, and $M=2^{32}$.\n    3.  Create pairs of (key, random score).\n    4.  Sort these pairs based on the random score. The resulting order of keys is the pseudorandom insertion sequence.\n\n**4. Hash Table Operations and Metrics**\n\nThe hash table is an array of size $m$, where each cell can be empty or occupied.\n\n*   **Insertion and Probe Counting:** To insert key $k$:\n    1.  Compute the home address $j_0 = h(k) = \\lfloor (m \\cdot k) / U \\rfloor$.\n    2.  Initialize probe count $p=1$.\n    3.  Examine table slot $j = (j_0 + p - 1) \\pmod m$.\n    4.  If the slot is empty, place $k$ there and terminate the insertion for this key. The number of probes is $p$.\n    5.  If the slot is occupied, increment $p$ and repeat from step $3$.\n    The total number of probes is accumulated over all $n$ insertions. The average is $\\overline{P} = (\\sum_{i=1}^{n} p_i) / n$.\n\n*   **Maximum Cluster Length Calculation:**\n    1.  After all $n$ keys are inserted, find the first empty slot in the table array at index $j_{empty}$. If no slot is empty, the cluster length is $m$. The problem guarantees $nm$, so at least one empty slot exists.\n    2.  Initialize `max_length = 0` and `current_length = 0`.\n    3.  Iterate through the table cyclically for $m$ positions, starting from index $(j_{empty} + 1) \\pmod m$.\n    4.  For each slot, if it is occupied, increment `current_length`.\n    5.  If it is empty, update `max_length = max(max_length, current_length)` and reset `current_length = 0$.\n    6.  After the loop completes, perform one final update `max_length = max(max_length, current_length)` to account for any cluster that wraps around the table's end. This final value is $C$.\n\n**5. Analysis of Expected Behavior**\n\nThe hash function $h(k) = \\lfloor (m \\cdot k) / U \\rfloor$ is order-preserving. Keys that are numerically close are mapped to the same or adjacent hash table slots.\n\n*   **Sorted Insertion:** Keys are inserted in increasing order. Keys for bucket $0$ are inserted, then keys for bucket $1$, and so on. When inserting keys for bucket $b$, they will likely collide with the cluster already formed by keys from buckets $0, \\ldots, b-1$. This sequential insertion into adjacent home slots will cause primary clustering to become severe, creating very large clusters and long probe sequences. We expect $\\overline{P}_{\\mathrm{sorted}}$ and $C_{\\mathrm{sorted}}$ to be large.\n\n*   **Random Insertion:** The pseudorandom order ensures that consecutive insertions are unlikely to be for keys that are numerically close. An insertion into the low-index region might be followed by an insertion into the high-index region. This effectively breaks the pattern that causes catastrophic primary clustering, distributing the insertions more evenly over time across the collision-prone regions. We expect $\\overline{P}_{\\mathrm{random}}$ and $C_{\\mathrm{random}}$ to be significantly smaller than their sorted-order counterparts.\n\nConsequently, the ratios $R_P = \\overline{P}_{\\mathrm{sorted}} / \\overline{P}_{\\mathrm{random}}$ and $R_C = C_{\\mathrm{sorted}} / C_{\\mathrm{random}}$ are expected to be significantly greater than $1$, quantifying the performance degradation caused by the sorted insertion order under these specific conditions.\nThe implementation will now proceed based on this formal design.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the hash table analysis problem.\n    It iterates through predefined test cases, runs the insertion experiments,\n    and prints the final results in the required format.\n    \"\"\"\n    test_cases = [\n        (1024, 1024000, 240, 2, 123456789),\n        (512, 512000, 120, 2, 987654321),\n        (257, 257000, 64, 1, 20231102),\n        (128, 128000, 24, 2, 31415926),\n    ]\n\n    # LCG parameters\n    LCG_A = 1664525\n    LCG_C = 1013904223\n    LCG_M_MASK = 0xFFFFFFFF  # (2**32 - 1)\n\n    EMPTY_SLOT = -1 # Sentinel for an empty slot in the hash table\n\n    def generate_keys(m, U, L, t):\n        \"\"\"Generates the bimodal key set based on problem parameters.\"\"\"\n        keys = []\n        # Low-index group\n        for b in range(L):\n            start_key = (U * b) // m\n            keys.extend(range(start_key, start_key + t))\n        # High-index group\n        for b in range(m - L, m):\n            start_key = (U * b) // m\n            keys.extend(range(start_key, start_key + t))\n        return keys\n\n    def get_random_order(keys, n, seed):\n        \"\"\"Permutes keys based on scores from a Linear Congruential Generator.\"\"\"\n        lcg_state = seed\n        scores = []\n        for _ in range(n):\n            lcg_state = (LCG_A * lcg_state + LCG_C)  LCG_M_MASK\n            scores.append(lcg_state)\n        \n        # Pair keys with scores and sort by score\n        keyed_scores = list(zip(keys, scores))\n        keyed_scores.sort(key=lambda x: x[1])\n        \n        return [key for key, score in keyed_scores]\n\n    def run_experiment(m, U, n, key_order):\n        \"\"\"\n        Runs a single experiment for a given key insertion order.\n        Returns the average number of probes and the final max cluster length.\n        \"\"\"\n        table = np.full(m, EMPTY_SLOT, dtype=np.int64)\n        total_probes = 0\n\n        for key in key_order:\n            home_address = (m * key) // U\n            probes = 0\n            while True:\n                probes += 1\n                current_pos = (home_address + probes - 1) % m\n                if table[current_pos] == EMPTY_SLOT:\n                    table[current_pos] = key\n                    total_probes += probes\n                    break\n        \n        avg_probes = total_probes / n\n\n        # Calculate max cluster length\n        max_len = 0\n        current_len = 0\n        \n        # Per problem spec, start traversal after an empty slot to handle wrap-around\n        empty_indices = np.where(table == EMPTY_SLOT)[0]\n        if len(empty_indices) == 0:\n            # This case is not expected as n  m\n            max_len = m\n        else:\n            start_index = (empty_indices[0] + 1) % m\n            for i in range(m):\n                idx = (start_index + i) % m\n                if table[idx] != EMPTY_SLOT:\n                    current_len += 1\n                else:\n                    max_len = max(max_len, current_len)\n                    current_len = 0\n            # Final check for wrap-around cluster\n            max_len = max(max_len, current_len)\n            \n        return avg_probes, max_len\n\n    final_results = []\n    for m, U, L, t, seed in test_cases:\n        n = 2 * L * t\n        \n        keys = generate_keys(m, U, L, t)\n        \n        # Sorted order experiment\n        sorted_keys = sorted(keys)\n        p_sorted, c_sorted = run_experiment(m, U, n, sorted_keys)\n        \n        # Random order experiment\n        random_keys = get_random_order(keys, n, seed)\n        p_random, c_random = run_experiment(m, U, n, random_keys)\n        \n        # Calculate and store ratios\n        R_P = p_sorted / p_random\n        # Handle division by zero for cluster length, though not expected here\n        R_C = (c_sorted / c_random) if c_random != 0 else float('inf')\n        \n        final_results.append(R_P)\n        final_results.append(R_C)\n\n    # Format the final output string\n    output_str = \"[\" + \",\".join(map(str, final_results)) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3257202"}, {"introduction": "After observing that clustering is detrimental, the next step is to quantify its impact with precision. This exercise isolates the effect of a single cluster by having you synthetically construct one and then measure how search times scale with its length, $C$. You will derive the theoretical linear relationship between cost and cluster size and then verify it experimentally, providing a deep insight into the mechanics of linear probing [@problem_id:3257276].", "problem": "Consider a hash table implemented with open addressing and linear probing. The hash table has capacity $m$, a hash function $h(k)$, and probe sequence $p_j(k) = (h(k) + j) \\bmod m$ for $j = 0, 1, \\dots, m-1$. The cost model defines search time as the count of examined slots (probes), which is a unit-free measure in \"probes.\"\n\nStarting from the fundamental definitions:\n- Open addressing places all keys into the table itself; collisions are resolved by finding the next available slot using a probe sequence.\n- Linear probing uses an arithmetic progression probe sequence, which creates contiguous runs of occupied slots (clusters).\n- A search terminates when either the key is found in a probed slot, or an empty slot is encountered. A successful search cost equals the number of probes until the matching key is examined. An unsuccessful search cost equals the number of probes until the first empty slot is examined.\n\nPrimary clustering arises when contiguous runs of occupied slots form and grow; probing into such a cluster forces a sequential scan across the entire cluster. You will construct a synthetic benchmark to isolate this phenomenon.\n\nBenchmark design:\n- Use a modulus-based hash function $h(k) = k \\bmod m$.\n- Fix a start index $s$ and create a single contiguous cluster of length $C$ occupying slots $s, s+1, \\dots, s+C-1$ without wrap-around, with slot $s+C$ empty. Achieve this by inserting keys $k_i = s + i \\cdot m$ for $i = 0, 1, \\dots, C-1$. Under linear probing and the given hash function, each such key initially hashes to $s$ and is placed at the next available slot, filling the contiguous block.\n- For each cluster length $C$, measure:\n  1. The average successful search cost within the cluster, obtained by searching for all $C$ inserted keys and averaging their probe counts.\n  2. The unsuccessful search cost when the initial probe is at the start of the cluster, obtained by searching for a key $k^\\star = s + C \\cdot m$ that hashes to $s$ but is not present.\n  3. The average unsuccessful search cost when the initial probe is uniformly distributed over the cluster offsets, obtained by searching for $C$ distinct keys $u_\\delta = (s + \\delta) + M \\cdot m$ for $\\delta = 0, 1, \\dots, C-1$, where $M$ is a sufficiently large integer ensuring none of these keys is equal to an inserted key. Each such key starts probing at index $s + \\delta$ and is not present.\n\nScientific requirements:\n- Derive the expected dependence of these three costs on the cluster length $C$ from the stated definitions (no shortcut formulas). Your derivation must explain why search time scales linearly with $C$ when probing into a single contiguous cluster.\n- Treat boundary cases carefully. For $C = 0$, define the average successful search cost as $0$ by convention (no successful searches), the unsuccessful search cost from the start as $1$ probe (the start slot is empty), and the average unsuccessful search cost under uniform offsets as $1$ probe.\n\nTest suite:\n- Use a fixed table size $m = 4096$ and start index $s = 123$.\n- Evaluate cluster lengths $C$ in the set $\\{0, 1, 8, 64, 512, 2048, 3968\\}$, which covers an empty cluster, tiny clusters, moderate clusters, and near-maximum clusters without wrap-around since $s + C \\leq m - 1$ for all listed values of $C$.\n\nProgram requirements:\n- Implement linear probing exactly as defined.\n- For each test case cluster length $C$, construct the cluster and compute the three metrics specified above.\n- Express all three metrics in probes (unit-free counts).\n- Aggregate the results for all test cases into a single line of output as a comma-separated list enclosed in square brackets. Each element of this list must itself be a bracketed comma-separated list of the form $[C,\\ \\text{avg\\_succ},\\ \\text{unsucc\\_start},\\ \\text{avg\\_unsucc\\_uniform}]$, where $C$ is an integer and the three costs are floats or integers in probes. For example, the top-level format is $[[\\dots],[\\dots],\\dots]$.", "solution": "The fundamental base is the definition of open addressing with linear probing and the probe-count cost model. Let the table capacity be $m$, the hash function be $h(k) = k \\bmod m$, and the probe sequence be $p_j(k) = (h(k) + j) \\bmod m$. A search examines slots sequentially along the probe sequence; the cost equals the total number of examined slots. A successful search stops when the examined slot contains the target key. An unsuccessful search stops when the examined slot is empty.\n\nConstruct one giant cluster by inserting $C$ keys that all hash to the same start index $s$:\n- Insert keys $k_i = s + i \\cdot m$ for $i \\in \\{0, 1, \\dots, C-1\\}$.\n- Each insertion begins at $h(k_i) = s$ and uses linear probing to find the next empty slot, so the inserted keys occupy $s, s+1, \\dots, s+C-1$ without wrap-around, provided $s + C \\leq m - 1$. Slot $s+C$ remains empty.\n\nWe now derive search costs as functions of cluster length $C$.\n\nSuccessful search within the cluster:\n- Consider the key placed at offset $\\delta \\in \\{0, 1, \\dots, C-1\\}$, which lies in slot $s+\\delta$.\n- Its probe sequence begins at $s$, and the search scans $s, s+1, \\dots, s+\\delta$ until it finds the key. The number of probes equals $\\delta + 1$.\n- Averaging over all keys in the cluster, the average successful search cost is\n$$\n\\frac{1}{C} \\sum_{\\delta=0}^{C-1} (\\delta + 1) = \\frac{1}{C} \\left( \\sum_{\\delta=0}^{C-1} \\delta + \\sum_{\\delta=0}^{C-1} 1 \\right) = \\frac{1}{C} \\left( \\frac{(C-1)C}{2} + C \\right) = \\frac{C+1}{2}.\n$$\n- For the boundary case $C=0$, there are no successful searches to average; by convention we define the average as $0$.\n\nUnsuccessful search starting at the cluster start:\n- Consider a missing key $k^\\star$ with $h(k^\\star) = s$ (for example $k^\\star = s + C \\cdot m$).\n- The probe sequence begins at $s$ and scans the cluster slots $s, s+1, \\dots, s+C-1$, finding each occupied. The first empty slot is at $s+C$.\n- The number of probes equals the number of occupied slots examined plus the empty slot examination, which is $C + 1$.\n- For the boundary case $C=0$, the first probed slot $s$ is empty, so the cost is $1$.\n\nUnsuccessful search with a uniform starting offset over the cluster:\n- Consider missing keys $u_\\delta$ with $h(u_\\delta) = s + \\delta$ for $\\delta \\in \\{0, 1, \\dots, C-1\\}$ and $u_\\delta$ different from any inserted key.\n- The probe sequence begins at $s + \\delta$ and scans $s + \\delta, s + \\delta + 1, \\dots, s+C - 1$, then the first empty slot at $s+C$.\n- The number of probes for offset $\\delta$ is $(C - \\delta) + 1$.\n- Averaging over all offsets,\n$$\n\\frac{1}{C} \\sum_{\\delta=0}^{C-1} \\big( (C - \\delta) + 1 \\big) = \\frac{1}{C} \\left( \\sum_{\\delta=0}^{C-1} (C - \\delta) + \\sum_{\\delta=0}^{C-1} 1 \\right) = \\frac{1}{C} \\left( \\frac{C(C+1)}{2} + C \\right) = \\frac{C+3}{2}.\n$$\n- For the boundary case $C=0$, there are no offsets to average; the cost reduces to the start case, which is $1$.\n\nThese derivations demonstrate linear sensitivity to clustering under linear probing:\n- The average successful search cost grows as $\\frac{C+1}{2}$.\n- The unsuccessful search cost from the cluster start grows as $C+1$.\n- The average unsuccessful search cost with uniform starting offsets over the cluster grows as $\\frac{C+3}{2}$.\nEach expression is an affine function of the cluster length $C$, so creating one giant cluster causes search times to scale linearly with the cluster length.\n\nAlgorithmic realization:\n- Implement insertion and search with linear probing according to the stated definitions.\n- Build the cluster by inserting $C$ colliding keys with initial index $s$ using the modulus-based hash function.\n- Measure probe counts directly by instrumenting the search procedure to count examined slots.\n- For each test case $C \\in \\{0, 1, 8, 64, 512, 2048, 3968\\}$ with $m = 4096$ and $s = 123$, compute:\n  - The average successful search cost across all inserted keys (defined as $0$ for $C=0$).\n  - The unsuccessful search cost from the cluster start using a missing key hashing to $s$.\n  - The average unsuccessful search cost with uniform starting offsets using one missing key per offset.\n- Print the aggregated results as a single line in the specified nested list format. All reported values are in probes.\n\nThis principle-based design directly reflects how linear probing behaves under contiguous occupancy, without relying on shortcut formulas beyond the stated definitions, and produces measurements that match the derived linear scaling.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass LinearProbingTable:\n    def __init__(self, m: int):\n        self.m = m\n        # Use None to denote empty slot\n        self.table = [None] * m\n\n    def h(self, k: int) - int:\n        # Modulus-based hash function\n        return k % self.m\n\n    def insert(self, k: int) - bool:\n        \"\"\"Insert key k using linear probing. Returns True if inserted, False if table is full.\"\"\"\n        idx = self.h(k)\n        for _ in range(self.m):\n            if self.table[idx] is None:\n                self.table[idx] = k\n                return True\n            idx = (idx + 1) % self.m\n        return False  # Table full\n\n    def probe_count_search(self, k: int) - int:\n        \"\"\"Return number of probes used to search for k (successful or unsuccessful).\"\"\"\n        idx = self.h(k)\n        probes = 0\n        for _ in range(self.m):\n            probes += 1\n            slot = self.table[idx]\n            if slot is None:\n                return probes  # unsuccessful: empty slot terminates\n            if slot == k:\n                return probes  # successful: found the key\n            idx = (idx + 1) % self.m\n        # If full cycle without finding empty or the key (should not happen with our construction),\n        # return the maximum probes m.\n        return probes\n\ndef build_cluster_and_measure(m: int, s: int, C: int):\n    \"\"\"\n    Build a single contiguous cluster starting at index s of length C without wrap-around,\n    and measure:\n      - average successful search probes over all inserted keys,\n      - unsuccessful search probes starting from s (key hashing to s but missing),\n      - average unsuccessful search probes when initial probe is uniformly distributed over cluster offsets.\n    \"\"\"\n    # Preconditions: ensure the cluster fits without wrap-around\n    assert s + C = m - 1, \"Cluster must not wrap around.\"\n\n    table = LinearProbingTable(m)\n\n    # Insert C keys that all hash to s to form the cluster in slots s..s+C-1\n    inserted_keys = []\n    for i in range(C):\n        k = s + i * m  # all hash to s\n        ok = table.insert(k)\n        if not ok:\n            raise RuntimeError(\"Insertion failed: table unexpectedly full.\")\n        inserted_keys.append(k)\n\n    # Average successful search over inserted keys\n    if C == 0:\n        avg_succ = 0.0  # by convention\n    else:\n        succ_probes = [table.probe_count_search(k) for k in inserted_keys]\n        avg_succ = float(sum(succ_probes)) / float(len(succ_probes))\n\n    # Unsuccessful search from start (key hashing to s but not present)\n    missing_start_key = s + C * m  # hashes to s, not inserted\n    unsucc_start = float(table.probe_count_search(missing_start_key))\n\n    # Average unsuccessful search with uniform starting offsets over the cluster\n    if C == 0:\n        avg_unsucc_uniform = 1.0  # degenerate case: same as start case\n    else:\n        # For each offset delta in 0..C-1, choose a missing key hashing to s+delta\n        # Ensure keys do not equal any inserted key: pick a large M to avoid collisions with existing keys\n        M = C + 12345  # any large integer suffices\n        unsucc_uniform_probes = []\n        for delta in range(C):\n            u = (s + delta) + M * m\n            unsucc_uniform_probes.append(table.probe_count_search(u))\n        avg_unsucc_uniform = float(sum(unsucc_uniform_probes)) / float(len(unsucc_uniform_probes))\n\n    return [C, avg_succ, unsucc_start, avg_unsucc_uniform]\n\ndef format_list(obj):\n    \"\"\"Format nested lists without spaces, as required.\"\"\"\n    if isinstance(obj, list):\n        return \"[\" + \",\".join(format_list(x) for x in obj) + \"]\"\n    elif isinstance(obj, (int, float)):\n        # Ensure consistent float formatting (no trailing .0 removal for ints)\n        return str(obj)\n    elif isinstance(obj, bool):\n        return \"True\" if obj else \"False\"\n    else:\n        raise TypeError(\"Unsupported type for formatting\")\n\ndef solve():\n    # Define the test cases from the problem statement.\n    m = 4096\n    s = 123\n    test_cases = [\n        # cluster lengths C covering empty, small, moderate, and near-maximum cluster sizes without wrap-around\n        0, 1, 8, 64, 512, 2048, 3968\n    ]\n\n    results = []\n    for C in test_cases:\n        results.append(build_cluster_and_measure(m, s, C))\n\n    # Final print statement in the exact required format: a single line with nested lists, comma-separated, no spaces.\n    print(format_list(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3257276"}, {"introduction": "Managing deletions in an open-addressing table is a non-trivial challenge. This problem explores an elegant alternative to tombstones, backward-shift deletion, through a \"reverse-engineering\" puzzle. You will discover the key invariant this method preserves: the final state of the table is as if the deleted items were never inserted at all, leading to a much deeper appreciation for the logic of data structure operations [@problem_id:3227225].", "problem": "You are given a hash table that uses open addressing with linear probing. The table has length $m$ and stores distinct integer keys. The hash function is $h(k) = k \\bmod m$. The algorithmic rules are as follows:\n- Insertion: To insert a key $k$, probe slots $h(k), h(k)+1, \\dots$ wrapping modulo $m$ until the first empty slot is found, and place $k$ there. No tombstones are used. The set of empty slots is represented by a special sentinel value that is not a valid key.\n- Deletion: The deletion operation is the backward-shift deletion for linear probing (sometimes referred to as \"gap closing\"): upon deleting a key at position $i$, repeatedly move forward through the cluster, shifting each subsequent occupied key one slot backward until an empty slot is encountered, ensuring that the search invariant is preserved.\n\nFundamental base:\n- A hash table with open addressing and linear probing stores a key $k$ at the first available slot encountered on the probe sequence $h(k), h(k)+1, \\dots$ taken modulo $m$.\n- The backward-shift deletion maintains the linear probing search invariant for all remaining keys.\n\nTask:\n- You are given, for each test case, integers $m$ and a sequence $I$ of distinct keys. Starting from an empty table, the table is built by inserting the keys in the order they appear in $I$ using linear probing. Then a sequence of deletions is performed using backward-shift deletion, yielding a specified final configuration $F$ with some slots empty and some containing keys.\n- Given only $m$, the insertion order $I$, and the final configuration $F$, determine the minimum number of deletions that must have occurred to produce $F$ from the table formed by inserting $I$ in order, under the stated algorithms. If $F$ is not achievable from the initial table by any sequence of deletions using backward-shift deletion, output $-1$.\n\nRepresentation:\n- The final configuration $F$ is a list of length $m$ where each entry is either the integer key stored at that slot or the empty sentinel. The empty sentinel is the integer $-1$.\n\nFormal requirements:\n- Let $I = \\langle i_1, i_2, \\dots, i_n \\rangle$ be the sequence of distinct inserted keys. Let $F$ be the final array of length $m$ with entries in $\\{-1\\} \\cup \\mathbb{Z}_{\\ge 0}$, where $-1$ denotes an empty slot and all nonnegative integers denote keys. Let $S$ be the set of all keys appearing in $F$. Your program must:\n  - Verify that every nonempty entry of $F$ is an element of $I$ and that no key appears more than once in $F$.\n  - Construct the candidate table $C$ obtained by inserting, into an empty table of size $m$, exactly the keys of $S$ in the same relative order as they appear in $I$ (i.e., stably filtering $I$ to those keys in $S$) using linear probing.\n  - If $C = F$, return $|I| - |S|$ as the minimal number of deletions. Otherwise, return $-1$.\n\nRationale to be derived in your solution:\n- Under backward-shift deletion for linear probing, deleting a subset of keys and closing gaps results in the same final table as if those deleted keys had never been inserted, while preserving the relative order of the remaining keys along probe paths. Therefore, the minimal number of deletions equals the number of keys present in $I$ but absent from $F$, provided $F$ matches the table that would be built by inserting only the remaining keys in their original relative order.\n\nTest suite:\nFor each test case below, $m$, $I$, and $F$ are given. The empty sentinel is $-1$.\n\n- Test case 1:\n  - $m = 11$\n  - $I = [10, 21, 32, 43]$\n  - $F = [43, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10]$\n  - Expected minimal deletions: integer result.\n\n- Test case 2:\n  - $m = 11$\n  - $I = [10, 21, 32, 43]$\n  - $F = [10, -1, 43, -1, -1, -1, -1, -1, -1, -1, -1]$\n  - This arrangement is intended to be unachievable by any sequence of backward-shift deletions from the insertion of $I$.\n  - Expected output: $-1$.\n\n- Test case 3:\n  - $m = 7$\n  - $I = [14, 21, 28]$\n  - $F = [-1, -1, -1, -1, -1, -1, -1]$\n\n- Test case 4:\n  - $m = 13$\n  - $I = [18, 41, 22, 44, 59]$\n  - After inserting $I$ using linear probing, the table is:\n    - slot 2 - 41, slot 5 - 18, slot 6 - 44, slot 7 - 59, slot 9 - 22, all other slots empty.\n  - $F = [-1, -1, 41, -1, -1, 18, 44, 59, -1, 22, -1, -1, -1]$\n\n- Test case 5:\n  - $m = 5$\n  - $I = [0, 5, 10, 15]$\n  - $F = [5, 15, -1, -1, -1]$\n\n- Test case 6:\n  - $m = 7$\n  - $I = [1, 8, 15]$\n  - $F = [-1, 1, 22, -1, -1, -1, -1]$ where 22 was never inserted.\n\n- Test case 7:\n  - $m = 7$\n  - $I = [3, 10, 17]$\n  - $F = [-1, -1, -1, 3, 3, -1, -1]$ which contains a duplicate key.\n\nYour program should produce a single line of output containing the results for the above cases as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,...]\"). Each result must be an integer, with $-1$ used to indicate impossibility.", "solution": "We begin from the foundational definitions of open addressing with linear probing and the backward-shift deletion operation.\n\nLet $m \\in \\mathbb{Z}_{0}$ be the table length, and let $h(k) = k \\bmod m$ be the hash function for a key $k \\in \\mathbb{Z}$. Linear probing defines the probe sequence for $k$ as the cyclic sequence $h(k), h(k)+1, h(k)+2, \\dots$ taken modulo $m$. Insertion places $k$ into the first empty slot encountered on this sequence. A deletion at position $i$ under backward-shift deletion removes the key at $i$ and then repeatedly shifts subsequent occupied entries one step backward to fill the gap, continuing until an empty slot is encountered. The invariant preserved is that for each key $x$ that remains, a search starting at $h(x)$ and following the linear probe sequence will encounter $x$ without encountering an empty slot earlier.\n\nPrinciple and key property:\n- Consider a sequence $I = \\langle i_1, i_2, \\dots, i_n \\rangle$ of distinct keys inserted into an initially empty table of length $m$ using linear probing. Let $S \\subseteq \\{i_1,\\dots,i_n\\}$ be a subset of keys that remain after performing deletions under backward-shift deletion. The crucial property, derivable from the maintenance of the linear probing invariant and the definition of the backward-shift deletion, is that the final table containing exactly the keys in $S$ equals the table that would be produced by inserting only the keys of $S$ into an empty table using linear probing in the same relative order as they appeared in $I$ (that is, by filtering $I$ to $S$ while preserving order). Intuitively, every deletion creates a gap that is immediately closed by shifting forward keys backward one position while maintaining reachability along probe sequences; iterating this process for any set of deletions is equivalent to having never inserted those deleted keys, because all remaining keys continue to occupy the earliest available positions along the same probe paths, and their relative insertion order is preserved by the local backward shifts.\n\nOutline of derivation:\n- Base fact: For linear probing without tombstones, the position of a key $k$ depends on the occupancy of all slots on its probe path up to its final position. If certain keys occupying earlier slots are absent, $k$ will occupy the earliest available slot on its path.\n- Backward-shift deletion simulates the removal of a key by closing the gap and re-establishing that every remaining key sits at the earliest available slot on its probe path. Because the shifting is local and only moves keys backward into earlier positions on their probe paths, the relative order of keys along the probe sequence imposed by the original insertion order is preserved. This can be shown by induction on the number of deletions: removing one key and closing the gap yields exactly the table obtained by inserting all keys except the removed key in their original relative order; if this holds for $t$ deletions, applying it to the $(t+1)$-th deletion preserves the equivalence.\n\nConsequences for the decision problem:\n- Suppose we are given $m$, the original insertion sequence $I$ of $n$ distinct keys, and a purported final configuration $F$ (a length-$m$ array using an empty sentinel for empty slots). Let $S$ be the set of keys in $F$. If $F$ is achievable via deletions from the table built by inserting $I$, then $F$ must equal the table obtained by inserting only the keys in $S$ in the same relative order as in $I$. If not, there is no sequence of backward-shift deletions that can produce $F$ from the insertion of $I$.\n- Furthermore, if $F$ is achievable, the minimal number of deletions is exactly $|I| - |S|$, because each deleted key must correspond to a distinct key from $I$ that is absent from $F$, and conversely, deleting precisely those $|I| - |S|$ keys yields the unique achievable final arrangement for $S$ as argued above. No fewer deletions can remove more than one key at once, and no superfluous deletions are necessary.\n\nAlgorithm:\n- Input parameters for a test case: $m$, $I$, and $F$.\n- Step $1$: Validate that all nonempty entries of $F$ are distinct and belong to $I$. If any key in $F$ is not in $I$, or a duplicate appears in $F$, or $|F| \\neq m$, return $-1$.\n- Step $2$: Let $S$ be the sequence formed by stably filtering $I$ to those keys that appear in $F$ (preserving their order in $I$). Build a candidate table $C$ by inserting the keys of $S$ into an empty table of length $m$ using linear probing.\n- Step $3$: If $C = F$, output $|I| - |S|$; otherwise, output $-1$.\n\nCorrectness justification:\n- By the property derived from the backward-shift deletion invariant, if there exists any sequence of deletions that yields $F$, then $F$ must equal $C$. Conversely, if $F = C$, deleting exactly the keys in $I \\setminus S$ and using backward-shift deletion produces $F$. Therefore, the decision is both necessary and sufficient, and the minimal number of deletions is exactly the count of removed keys.\n\nComplexity:\n- Constructing $C$ requires at most $O(m + |S|)$ time per test, with each insertion performing at most $m$ probes in the worst case but averaging fewer when load is moderate. Validation and comparison are linear in $m$.\n\nApplying the algorithm to the test suite:\n- Test case $1$: $m = 11$, $I = [10,21,32,43]$, $F$ has keys $\\{10,43\\}$ placed at indices $10$ and $0$ respectively. Filtering $I$ to $S = [10,43]$ and inserting yields exactly $F$. Minimal deletions $= 4 - 2 = 2$.\n- Test case $2$: Same $m$ and $I$, $F$ places $10$ at index $0$ and $43$ at index $2$. Inserting $S = [10,43]$ yields $10$ at index $10$ and $43$ at index $0$, which does not match $F$, so output $-1$.\n- Test case $3$: $m = 7$, $I = [14,21,28]$, $F$ is all empty. $S = []$, so minimal deletions $= 3 - 0 = 3$ and $C = F$.\n- Test case $4$: $m = 13$, $I = [18,41,22,44,59]$, $F$ equals the table obtained immediately after inserting $I$. Thus $S = I$ and minimal deletions $= 0$.\n- Test case $5$: $m = 5$, $I = [0,5,10,15]$, $F = [5,15,-1,-1,-1]$. $S = [5,15]$, and inserting $S$ yields $F$. Minimal deletions $= 4 - 2 = 2$.\n- Test case $6$: $m = 7$, $I = [1,8,15]$, $F$ contains key $22 \\notin I$, hence $-1$.\n- Test case $7$: $m = 7$, $I = [3,10,17]$, $F$ contains duplicate key $3$, hence $-1$.\n\nThe final output should be a single line with the results for the seven test cases in order, as integers in a comma-separated list enclosed in square brackets.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nEMPTY = -1\n\ndef hash_func(k: int, m: int) - int:\n    return k % m\n\ndef build_table_from_keys(m: int, keys):\n    table = [EMPTY] * m\n    for k in keys:\n        idx = hash_func(k, m)\n        # Linear probing to find first empty slot\n        for step in range(m):\n            pos = (idx + step) % m\n            if table[pos] == EMPTY:\n                table[pos] = k\n                break\n        else:\n            # Table full (should not happen in our tests)\n            raise RuntimeError(\"Insertion failed: table full\")\n    return table\n\ndef compute_min_deletions(m: int, insertion_order, final_table):\n    # Validate length\n    if len(final_table) != m:\n        return -1\n    # Extract keys present in final_table and check duplicates\n    seen = set()\n    present_keys = []\n    for val in final_table:\n        if val != EMPTY:\n            if val in seen:\n                return -1\n            seen.add(val)\n            present_keys.append(val)\n    # All keys in F must be from insertion_order\n    ins_set = set(insertion_order)\n    for k in present_keys:\n        if k not in ins_set:\n            return -1\n    # Filter insertion_order stably to keys in present_keys (preserving order of I)\n    present_set = set(present_keys)\n    filtered = [k for k in insertion_order if k in present_set]\n    # Build candidate table\n    candidate = build_table_from_keys(m, filtered)\n    # Compare with final_table\n    if candidate == final_table:\n        return len(insertion_order) - len(filtered)\n    else:\n        return -1\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (m, insertion_order, final_table)\n    test_cases = [\n        # Test case 1\n        (11, [10, 21, 32, 43],\n         [43, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10]),\n        # Test case 2 (impossible)\n        (11, [10, 21, 32, 43],\n         [10, -1, 43, -1, -1, -1, -1, -1, -1, -1, -1]),\n        # Test case 3 (all empty)\n        (7, [14, 21, 28],\n         [-1, -1, -1, -1, -1, -1, -1]),\n        # Test case 4 (no deletions; final equals post-insertion table)\n        (13, [18, 41, 22, 44, 59],\n         [-1, -1, 41, -1, -1, 18, 44, 59, -1, 22, -1, -1, -1]),\n        # Test case 5 (wrap-around cluster, deletions compact)\n        (5, [0, 5, 10, 15],\n         [5, 15, -1, -1, -1]),\n        # Test case 6 (contains key not in I; impossible)\n        (7, [1, 8, 15],\n         [-1, 1, 22, -1, -1, -1, -1]),\n        # Test case 7 (duplicate key in final; impossible)\n        (7, [3, 10, 17],\n         [-1, -1, -1, 3, 3, -1, -1]),\n    ]\n\n    results = []\n    for m, insertion_order, final_table in test_cases:\n        result = compute_min_deletions(m, insertion_order, final_table)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3227225"}]}