{"hands_on_practices": [{"introduction": "While finding a single instance of a value is a classic search problem, real-world datasets often contain duplicates, requiring us to identify the full range of an element's occurrences. This practice challenges you to adapt the jump search algorithm to this more complex scenario. By designing a 'dual' search that expands outwards from an initial find, you will deepen your understanding of how to manipulate search bounds and apply the core principles of jump search to solve a more nuanced problem [@problem_id:3242935].", "problem": "You are given a sorted array in non-decreasing order that may contain duplicate values. Design and implement a complete, runnable program that computes, for each provided test case, the indices of the first and last occurrences of a query value using a dual jump-based search strategy. The dual strategy must rely solely on the monotonicity of sorted arrays and a principled choice of a jump size, without resorting to binary search. Your design must explicitly justify the choice of jump size from a worst-case comparison perspective and then use symmetric leftward and rightward jump expansions to isolate the range of duplicates.\n\nFundamental base and constraints: Let the array be denoted by $A = [A_0, A_1, \\dots, A_{n-1}]$ with $n \\in \\mathbb{N}$ where $n \\geq 0$, and let the query value be denoted by $v \\in \\mathbb{Z}$. The array satisfies $A_i \\leq A_j$ for all indices $i,j \\in \\{0,1,\\dots,n-1\\}$ with $i \\leq j$. The search cost is quantified by the number of element comparisons. You must begin your reasoning from the sortedness property and a comparison-count model; do not rely on or cite pre-derived optimal parameters without justification. You must select a jump size as a function of $n$ based on minimizing worst-case comparisons for jump-style bracket localization and justify this choice in your solution.\n\nRequired algorithmic behavior:\n- Use forward jumps to locate a block that may contain $v$, then linearly scan within that block to find some index $i$ such that $A_i = v$, if it exists.\n- If such an index $i$ is found, expand leftward using fixed-size reverse jumps to bracket the first occurrence, then perform a local linear scan to identify the exact first index $i_{\\text{first}}$.\n- Expand rightward using fixed-size forward jumps to bracket the last occurrence, then perform a local linear scan to identify the exact last index $i_{\\text{last}}$.\n- If $v$ does not occur, return the list $[-1,-1]$.\n\nTest suite: Your program must run on the following set of test cases without any external input, files, or network calls. Each test case is a pair $(A, v)$.\n\n- Case $1$: $A = [\\,1,2,2,2,3,4,5\\,]$, $v = 2$.\n- Case $2$: $A = [\\,5,5,5,6,7\\,]$, $v = 5$.\n- Case $3$: $A = [\\,1,2,3,9,9,9\\,]$, $v = 9$.\n- Case $4$: $A = [\\,1,2,3,4\\,]$, $v = 6$.\n- Case $5$: $A = [\\,8\\,]$, $v = 8$.\n- Case $6$: $A = [\\,8\\,]$, $v = 9$.\n- Case $7$: $A = [\\,7,7,7,7,7,7,7,7\\,]$, $v = 7$.\n- Case $8$: $A = [\\,0,1,1,1,2,2,4,4,4,4,5,9,9,11\\,]$, $v = 4$.\n- Case $9$: $A = [\\,\\,]$ (the empty array), $v = 3$.\n\nAnswer specification:\n- For each test case, the program must output a list of exactly two integers $[i_{\\text{first}}, i_{\\text{last}}]$, where $i_{\\text{first}}$ is the index of the first occurrence of $v$ in $A$, and $i_{\\text{last}}$ is the index of the last occurrence of $v$ in $A$. If $v$ is not present, output $[-1,-1]$.\n- The final output of the program must be a single line containing a comma-separated list of these per-case results, enclosed in square brackets, with no spaces inside the inner result lists. For example, if there are three cases with outputs $[\\,1,3\\,]$, $[\\,0,2\\,]$, and $[\\,4,4\\,]$, the program must print the string \"[[$1$,$3$],[$0$,$2$],[$4$,$4$]]\".\n\nYour program must be fully self-contained, executable as-is, and expressed in a general-purpose language. Numerically, all outputs are pure indices, which are integers, and no physical units apply. There are no angles or percentages involved. The algorithm must not assume any distribution beyond the array being sorted in non-decreasing order.", "solution": "The posed problem is valid as it is scientifically grounded in the principles of algorithm design, is well-posed with a unique and verifiable solution, and is expressed in objective, formal language. It is free from any scientific, logical, or factual unsoundness.\n\nThe problem requires the design of an algorithm to find the first and last occurrences of a query value, denoted as $v$, within a sorted array, $A$, of size $n$. The array is sorted in non-decreasing order, meaning $A_i \\leq A_j$ for all indices $i, j$ such that $0 \\leq i \\leq j < n$. The solution must employ a jump-based search strategy, explicitly avoiding binary search. A core requirement is to justify the choice of jump size, $k$, based on minimizing the worst-case number of comparisons.\n\nThe overall algorithm is structured into three phases:\n1.  An initial jump search to find any index $i$ where $A_i=v$.\n2.  A leftward expanding jump search from this index to locate the first occurrence, $i_{\\text{first}}$.\n3.  A symmetric, rightward expanding jump search to pinpoint the last occurrence, $i_{\\text{last}}$.\n\n**Justification of Jump Size**\n\nA jump search operates by examining elements at fixed intervals of size $k$ to quickly narrow down the region where a target value might exist. The total search cost is dominated by two operations: the jumps themselves and a subsequent linear scan within a narrowed-down block.\n\n1.  **Jumping Phase**: We probe indices $k, 2k, 3k, \\dots, m \\cdot k$ until our search has passed the potential location of $v$. In the worst-case scenario (e.g., $v$ is the last element), the number of jumps, $m$, is approximately $\\frac{n}{k}$. This contributes $\\frac{n}{k}$ comparisons to the total cost.\n\n2.  **Linear Scan Phase**: After the jumping phase, we identify a block of size at most $k$ that must contain $v$ if it exists. A linear search within this block is then performed. In the worst case, this requires an additional $k-1$ comparisons.\n\nThe total worst-case comparison count, $C(k)$, is the sum of the costs from both phases:\n$$C(k) = \\frac{n}{k} + (k-1)$$\nTo find the optimal jump size $k$ that minimizes this cost, we can treat $k$ as a continuous variable and use calculus to find the minimum of the function $C(k)$. The first derivative of $C(k)$ with respect to $k$ is:\n$$\\frac{dC}{dk} = -\\frac{n}{k^2} + 1$$\nSetting this derivative to $0$ to find the critical point yields:\n$$-\\frac{n}{k^2} + 1 = 0 \\implies k^2 = n \\implies k = \\sqrt{n}$$\nThis derivation establishes that the optimal jump size that minimizes the worst-case number of comparisons is $k = \\sqrt{n}$. For an array of discrete elements, we use the integer part $k = \\lfloor \\sqrt{n} \\rfloor$. If $n=0$, this calculation is not applicable; if $n>0$ and $\\lfloor \\sqrt{n} \\rfloor = 0$, a minimum jump size of $1$ must be enforced to ensure progress. The overall time complexity of a search with this optimal jump size is $O(\\sqrt{n})$. This jump size, $k$, will be used consistently throughout all phases of the algorithm.\n\n**Algorithmic Implementation**\n\nThe search for $[i_{\\text{first}}, i_{\\text{last}}]$ proceeds as follows.\n\n**Phase 1: Initial Search for an Occurrence of $v$**\nFirst, handle the edge case: if the array is empty ($n=0$), $v$ cannot be present, so we return $[-1, -1]$. Otherwise, we compute the jump size $k = \\max(1, \\lfloor \\sqrt{n} \\rfloor)$.\n\n1.  **Block Location**: We use forward jumps of size $k$ to find a block that may contain $v$. We initialize two pointers, `prev` and `curr`, to $0$. We advance `curr` by $k$ as long as $A_{\\text{curr}} < v$, setting `prev` to the old value of `curr` before each jump. This process stops when $A_{\\text{curr}} \\geq v$ or `curr` exceeds the array bounds.\n2.  **Linear Scan**: The element $v$, if it exists, must be located within the block of indices $[\\text{prev}, \\min(\\text{curr}, n-1)]$. We perform a linear scan within this block to find an index, let's call it `found_idx`, such that $A_{\\text{found\\_idx}} = v$. If the scan completes without finding $v$, the element is absent from the array, and we return $[-1, -1]$.\n\n**Phase 2: Finding the First Occurrence ($i_{\\text{first}}$)**\nIf Phase $1$ succeeds, we have an index `found_idx` where $A_{\\text{found\\_idx}} = v$. We now search for the first such occurrence.\n\n1.  **Leftward Bracketing**: Starting from `found_idx`, we expand leftward using jumps of size $k$. We define a search range `[start_rng, end_rng]`. Initially, `end_rng` is set to `found_idx`. We repeatedly update `end_rng` to the current position and jump `start_rng` to the left by $k$, as long as `start_rng` is a valid positive index and $A_{\\text{start\\_rng}} = v$. This quickly establishes a bracket `[start_rng, end_rng]` that is guaranteed to contain $i_{\\text{first}}$.\n2.  **Local Linear Scan**: We then perform a fine-grained linear scan forward from `start_rng` to `end_rng`. The first index $j$ in this range for which $A_j = v$ is the required first occurrence, $i_{\\text{first}}$.\n\n**Phase 3: Finding the Last Occurrence ($i_{\\text{last}}$)**\nThis phase mirrors Phase $2$, but expands rightward from `found_idx`.\n\n1.  **Rightward Bracketing**: Starting from `found_idx`, we expand rightward. Initially, `start_rng` is set to `found_idx`. We repeatedly update `start_rng` to the current position and jump `end_rng` rightward by $k$, as long as `end_rng` is within the array bounds and $A_{\\text{end\\_rng}} = v$. This process identifies a bracket `[start_rng, end_rng]` guaranteed to contain $i_{\\text{last}}$.\n2.  **Local Linear Scan**: To pinpoint the exact index, we perform a linear scan backward from `end_rng` to `start_rng`. The first index $j$ encountered (from the right) for which $A_j = v$ is the last occurrence, $i_{\\text{last}}$.\n\nFinally, the algorithm returns the list $[i_{\\text{first}}, i_{\\text{last}}]$, which contains the indices of the first and last occurrences of $v$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\n\ndef dual_jump_search(A, v):\n    \"\"\"\n    Computes the first and last occurrences of a value v in a sorted array A\n    using a dual jump-based search strategy.\n    \n    Args:\n        A (list): A sorted list of numbers in non-decreasing order.\n        v (int or float): The value to search for.\n        \n    Returns:\n        list: A list [i_first, i_last] of the first and last indices of v.\n              Returns [-1, -1] if v is not found.\n    \"\"\"\n    n = len(A)\n    if n == 0:\n        return [-1, -1]\n\n    # k is chosen to minimize worst-case comparisons, derived from d/dk(n/k + k-1) = 0.\n    k = int(n**0.5)\n    if k == 0:\n        k = 1\n\n    # Phase 1: Initial Jump Search to find any occurrence of v.\n    found_idx = -1\n    \n    # 1.a: Find a block where v might be located.\n    prev = 0\n    curr = 0\n    while curr  n and A[curr]  v:\n        prev = curr\n        curr += k\n\n    # 1.b: Linear scan within the identified block.\n    block_end = min(curr, n - 1)\n    for i in range(prev, block_end + 1):\n        if A[i] == v:\n            found_idx = i\n            break\n    \n    if found_idx == -1:\n        return [-1, -1]\n\n    # Phase 2: Find the first occurrence (i_first) by expanding leftward.\n    i_first = -1\n    \n    # 2.a: Bracket the first occurrence with reverse jumps.\n    end_rng_first = found_idx\n    start_rng_first = max(0, found_idx - k)\n    \n    while start_rng_first > 0 and A[start_rng_first] == v:\n        end_rng_first = start_rng_first\n        start_rng_first = max(0, start_rng_first - k)\n\n    # 2.b: Linear scan within the bracket to find the exact first index.\n    for j in range(start_rng_first, end_rng_first + 1):\n        if A[j] == v:\n            i_first = j\n            break\n\n    # Phase 3: Find the last occurrence (i_last) by expanding rightward.\n    i_last = -1\n    \n    # 3.a: Bracket the last occurrence with forward jumps.\n    start_rng_last = found_idx\n    end_rng_last = min(n - 1, found_idx + k)\n\n    while end_rng_last  n - 1 and A[end_rng_last] == v:\n        start_rng_last = end_rng_last\n        end_rng_last = min(n - 1, end_rng_last + k)\n\n    # 3.b: Linear scan (backwards) within the bracket for the exact last index.\n    for j in range(end_rng_last, start_rng_last - 1, -1):\n        if A[j] == v:\n            i_last = j\n            break\n            \n    return [i_first, i_last]\n\ndef solve():\n    \"\"\"\n    Defines and runs the test cases, printing the results in the specified format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        ([1, 2, 2, 2, 3, 4, 5], 2),\n        ([5, 5, 5, 6, 7], 5),\n        ([1, 2, 3, 9, 9, 9], 9),\n        ([1, 2, 3, 4], 6),\n        ([8], 8),\n        ([8], 9),\n        ([7, 7, 7, 7, 7, 7, 7, 7], 7),\n        ([0, 1, 1, 1, 2, 2, 4, 4, 4, 4, 5, 9, 9, 11], 4),\n        ([], 3)\n    ]\n\n    results = []\n    for A, v in test_cases:\n        result = dual_jump_search(A, v)\n        results.append(result)\n\n    # Format the final output string as per the specification.\n    # e.g., [[1,3],[0,2],[-1,-1]]\n    output_str = \"[\" + \",\".join([f\"[{r[0]},{r[1]}]\" for r in results]) + \"]\"\n    \n    # Final print statement in the exact required format.\n    print(output_str)\n\nsolve()\n```", "id": "3242935"}, {"introduction": "Moving from concrete arrays to abstract data models helps solidify our understanding of an algorithm's core logic. This exercise presents a thought experiment involving a conceptually infinite sequence where the goal is to find a transition point by searching backward from a known position [@problem_id:3242857]. Successfully solving this requires applying the fundamental principle of exponential search—using geometrically increasing steps to efficiently bracket a target—in a non-standard direction, highlighting the algorithm's power and flexibility.", "problem": "Consider a conceptually infinite, indexable sequence with indices $0, 1, 2, \\dots$ in which you can only query a monotone Boolean predicate $P(i)$ on an index $i \\in \\mathbb{N}$. Assume that there exists an unknown threshold index $t \\in \\mathbb{N}$ such that $P(i)$ is $\\text{true}$ for all $i \\leq t$ and $P(i)$ is $\\text{false}$ for all $i  t$. You are given an index $S \\in \\mathbb{N}$ with $P(S) = \\text{false}$, but you do not know $t$. The goal is to find the last index $t$ for which $P(t) = \\text{true}$ using as few predicate evaluations as possible.\n\nStarting from the foundational definitions of monotonicity and comparison-based search, choose the option that correctly specifies how to use exponential search in the backward direction from $S$ to bracket $t$ and then conclude with a correct and asymptotically minimal-time search for $t$. Let $D = S - t$ denote the (unknown) distance from the starting false index $S$ to the target $t$.\n\nA. Starting at $S$, probe $P(S-1)$, $P(S-2)$, $P(S-4)$, $P(S-8)$, $\\dots$ (doubling the backward offset) until the first index $j = S - 2^{m}$ with $P(j) = \\text{true}$ is found, where $m \\geq 0$ is minimal. Let the previous offset be $j' = S - 2^{m-1}$ (with the convention that for $m = 0$, $j' = S$). By monotonicity, $P(j) = \\text{true}$ and $P(j') = \\text{false}$, which brackets $t \\in [j, j'-1]$. Perform a standard binary search on $[j, j'-1]$ to find $t$. The total number of predicate evaluations is $\\mathcal{O}(\\log D)$.\n\nB. Starting at $S$, probe $P(S-1)$, $P(S-2)$, $P(S-3)$, $\\dots$ (unit backward steps) until reaching the first index $k$ with $P(k) = \\text{true}$, then perform a binary search on $[k, S-1]$ to find $t$. The total number of predicate evaluations is $\\mathcal{O}(D)$ in the linear phase plus $\\mathcal{O}(\\log D)$ in the binary search phase.\n\nC. Ignore the given $S$ and instead perform forward exponential search from index $0$: probe $P(1)$, $P(2)$, $P(4)$, $P(8)$, $\\dots$ until finding the first false index $u = 2^{q}$ with $P(u) = \\text{false}$ for minimal $q$, which brackets $t \\in [2^{q-1}, 2^{q}-1]$. Then perform binary search on that interval to find $t$. The total number of predicate evaluations is $\\mathcal{O}(\\log t)$.\n\nD. Starting at $S$, probe backward with offsets $1, 2, 4, 8, \\dots$ until encountering the first false index strictly below $S$ (i.e., find $j = S - 2^{m}$ with $P(j) = \\text{false}$ for minimal $m \\geq 1$), then perform binary search on $[j, S]$ to find $t$. The total number of predicate evaluations is $\\mathcal{O}(\\log D)$.", "solution": "The problem asks for an optimal strategy to find the threshold index $t$, defined as the last index where a monotone predicate $P(i)$ is $\\text{true}$, given a starting index $S$ where $P(S)$ is $\\text{false}$. The predicate is $\\text{true}$ for all $i \\leq t$ and $\\text{false}$ for all $i > t$. The search must proceed backward from $S$ and have a complexity related to the distance $D = S - t$.\n\nThe most efficient method is a two-phase algorithm combining backward exponential search with binary search.\n\n1.  **Phase 1: Backward Exponential Search to Bracket the Target.**\n    Starting from index $S$, where $P(S)$ is $\\text{false}$, we must find an index $j  S$ where $P(j)$ is $\\text{true}$ to establish a search range. An exponential search does this efficiently by probing backward with geometrically increasing steps. We test indices $j_m = S - 2^m$ for $m = 0, 1, 2, \\dots$. Let $m^*$ be the smallest integer for which $P(S - 2^{m^*}) = \\text{true}$. This implies that the previous probe at index $S - 2^{m^*-1}$ (for $m^* > 0$) must have yielded $\\text{false}$. This successfully brackets the target index $t$ within the interval $[S - 2^{m^*}, S - 2^{m^*-1} - 1]$. The number of probes in this phase is $m^*+1$, which is $\\mathcal{O}(\\log D)$, since we stop when $2^{m^*} \\ge D$.\n\n2.  **Phase 2: Binary Search to Pinpoint the Target.**\n    Once the bracket containing $t$ is identified, a standard binary search is performed on this interval to find the exact index $t$. The size of the interval is approximately $2^{m^*-1}$, which is on the order of $D$. A binary search on this interval takes $\\mathcal{O}(\\log D)$ predicate evaluations.\n\nThe total number of predicate evaluations is $\\mathcal{O}(\\log D) + \\mathcal{O}(\\log D) = \\mathcal{O}(\\log D)$, which is asymptotically optimal.\n\n-   **Option A** correctly describes this two-phase algorithm: it uses backward exponential probes to establish a bracket $[j, j'-1]$ and then applies binary search, correctly identifying the overall complexity as $\\mathcal{O}(\\log D)$.\n-   **Option B** proposes a linear search, which is inefficient with a complexity of $\\mathcal{O}(D)$.\n-   **Option C** suggests a forward search from index $0$. This ignores the valuable information provided by the starting index $S$ and has a complexity of $\\mathcal{O}(\\log t)$, which can be significantly worse than $\\mathcal{O}(\\log D)$ if $t$ is large but $D$ is small.\n-   **Option D** describes a logically flawed strategy of searching for another `false` index, which fails to bracket the target `true` index.\n\nTherefore, Option A is the only correct and optimal procedure.", "answer": "$$\\boxed{A}$$", "id": "3242857"}, {"introduction": "Search algorithms truly shine when applied to large, structured datasets that go beyond simple flat arrays. This final practice asks you to implement a search on a two-level indexed data structure, which mimics how databases and file systems organize information for rapid retrieval [@problem_id:3242865]. You will compose algorithms by using a jump-style search on the high-level index to quickly locate a data block, followed by an efficient search within that block, demonstrating a powerful pattern for tackling hierarchical data.", "problem": "Consider a two-level index data structure $X$ defined as a finite sequence of inner sequences $X[0], X[1], \\dots, X[B-1]$, where each $X[b]$ is a finite sequence of comparable keys in non-decreasing order, duplicates are permitted within an inner sequence, and empty inner sequences are permitted. The data structure satisfies the global ordering constraint that for all block indices $b$ and $b+1$ such that both $X[b]$ and $X[b+1]$ are non-empty, $\\max(X[b])  \\min(X[b+1])$. This makes the concatenation of the inner sequences globally sorted. You are to design and implement an adaptation of jump search for this two-level index that respects the following principles.\n\n- Only comparisons of keys are permitted; no hashing or auxiliary balanced trees may be used.\n- The outer search must use a monotone representative function per non-empty block (for example, a boundary value) to decide which block may contain the query key.\n- The inner search within a candidate block must use a method that does not assume a priori knowledge of the target’s position and must be asymptotically efficient on sorted arrays.\n- The step sizes and bounds must be derived from first principles, not by guessing, and must be justified by minimizing worst-case comparisons under the constraints of a sorted structure.\n\nFormally, given a query key $x$, your algorithm must:\n- Identify a candidate block index $b^\\*$ by performing a jump-style search over the sequence of non-empty blocks using a monotone representative per block. If no candidate block can contain $x$, report that $x$ is not found.\n- Search within $X[b^\\*]$ to find the leftmost position $j$ such that $X[b^\\*][j] = x$. If such a position exists, return the pair $[b^\\*, j]$; otherwise, report that $x$ is not found.\n\nYour program must implement this algorithm and run it on the following test suite. Each test case consists of a specific two-level index and a query key $x$.\n\nDefine the three data sets:\n- $\\mathcal{D}_A = [[1, 3, 5, 5], [8, 9, 10], [14, 14, 15, 16], [20, 21]]$.\n- $\\mathcal{D}_B = [[-10, -5], [0], [2, 4, 6, 8, 10], [13, 17, 19], [23]]$.\n- $\\mathcal{D}_C = [[], [1, 2, 3], [5], [7, 7, 7, 7], [9, 12]]$.\n\nRun the algorithm on the following ordered list of test cases:\n- $(\\mathcal{D}_A, 14)$.\n- $(\\mathcal{D}_A, 1)$.\n- $(\\mathcal{D}_A, 21)$.\n- $(\\mathcal{D}_A, 7)$.\n- $(\\mathcal{D}_A, 0)$.\n- $(\\mathcal{D}_A, 100)$.\n- $(\\mathcal{D}_B, 17)$.\n- $(\\mathcal{D}_C, 7)$.\n- $(\\mathcal{D}_C, 4)$.\n- $(\\mathcal{D}_B, -10)$.\n\nFor each test case, the output must be either the pair $[b^\\*, j]$ (with both entries being integers) if the key is found, or the integer $-1$ if the key is not found. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1, r_2, r_3]$), in the same order as the test cases above. No physical units, angles, or percentages are involved; all outputs are either integers or lists of integers.", "solution": "The problem requires the design and implementation of a specialized search algorithm for a two-level indexed data structure, denoted as $X$. This structure is composed of a sequence of $B$ inner sequences, $X[0], \\dots, X[B-1]$. Each inner sequence is sorted in non-decreasing order, and a global ordering constraint, $\\max(X[b])  \\min(X[b+1])$ for any adjacent non-empty blocks $X[b]$ and $X[b+1]$, ensures that the concatenation of all elements is globally sorted. The task is to find the leftmost occurrence of a query key $x$ by adapting jump search principles.\n\nThe solution is a two-stage search process. The first stage, an outer search, identifies a single candidate block that could contain the key $x$. The second stage, an inner search, probes this specific block to locate the key.\n\n**Outer Search: Block Identification**\n\nThe outer search operates on the ordered sequence of non-empty blocks. Let there be $N$ such blocks. The problem mandates a jump-style search using a monotone representative for each block. A valid and natural choice for a representative is the first element of each non-empty block, let's say $R_i = \\min(X[b_i])$, where $b_i$ is the original index of the $i$-th non-empty block. The global ordering constraint guarantees that this sequence of representatives is strictly increasing, i.e., $R_i  R_{i+1}$ for all $i \\in [0, N-2]$.\n\nThe core principle is to find the optimal jump step size $k$ to minimize the number of comparisons in the worst case. The search involves two phases: jumping and linear scanning.\n1.  **Jumping Phase:** We jump through the representatives by a step size of $k$. The number of jumps required to find an interval containing the target is at most $\\lceil N/k \\rceil - 1$.\n2.  **Linear Scanning Phase:** Once a jump overshoots the target's potential location (i.e., we find an index $j$ such that $R_j  x$), we must perform a linear scan in the preceding interval of size $k-1$ to pinpoint the correct block.\n\nThe total number of comparisons in the outer search is therefore a function of the step size $k$, given by $C(k) \\approx N/k + k - 1$. To minimize this cost, we treat $k$ as a continuous variable and find the minimum by setting the derivative to zero:\n$$ \\frac{dC}{dk} = -\\frac{N}{k^2} + 1 = 0 $$\nThis yields $k^2 = N$, so the optimal step size is $k = \\sqrt{N}$. For a discrete number of blocks, we use the integer part, $k = \\lfloor \\sqrt{N} \\rfloor$.\n\nThe outer search algorithm is as follows:\n1.  Construct a list of non-empty blocks and their original indices. Let its size be $N$. If $N=0$, the key cannot be found.\n2.  Handle the edge case where the query key $x$ is smaller than the first element of the first non-empty block; in this case, $x$ is not present.\n3.  Using a step size of $k = \\lfloor \\sqrt{N} \\rfloor$, jump through the list of non-empty blocks until an index `curr` is found such that the representative at `curr` is greater than $x$. The previously visited index is `prev`. The candidate block must lie in the index range `[prev, curr - 1]`.\n4.  Perform a reverse linear scan from `curr - 1` down to `prev` to find the last block whose representative is less than or equal to $x$. This block, $X[b^\\*]$, is the unique candidate that can contain $x$.\n\n**Inner Search: Key Localization**\n\nOnce the candidate block $X[b^\\*]$ is identified, we must search within it. The problem specifies that this search must be asymptotically efficient on sorted data and not rely on a priori knowledge of the key's position. Binary search perfectly fits these criteria.\n\nTo satisfy the requirement of finding the *leftmost* position $j$ such that $X[b^\\*][j] = x$, a standard binary search is modified. When an element equal to $x$ is found at an index `mid`, this index is stored as a potential answer, and the search is subsequently narrowed to the left half of the current range (i.e., from the start to `mid - 1`). This ensures that if multiple occurrences of $x$ exist, the search will continue until the first one is found.\n\n**Algorithm Synthesis**\n\nThe complete algorithm integrates these two stages:\n1.  Extract the sequence of non-empty blocks and their original indices. Let the size of this sequence be $N$. If $N=0$, terminate and report \"not found\".\n2.  If the query key $x$ is smaller than the smallest element in the entire data structure, report \"not found\".\n3.  Execute the jump search on the representatives of the $N$ blocks with step size $k = \\lfloor\\sqrt{N}\\rfloor$ to identify the candidate block $X[b^\\*]$. If no such block can contain the key (which occurs if $x$ falls in a gap between blocks), the subsequent inner search will correctly fail.\n4.  Execute the leftmost-finding binary search for $x$ within $X[b^\\*]$.\n5.  If the inner search finds the key at local index $j$, return the pair $[b^\\*, j]$.\n6.  If the inner search does not find the key, report \"not found\". This outcome is definitive as $X[b^\\*]$ was the only possible location for $x$.", "answer": "```python\ndef search_in_two_level_index(data_structure, query_key):\n    \"\"\"\n    Performs a two-level search on the described data structure.\n\n    Args:\n        data_structure (list of lists): The two-level index X.\n        query_key (int or float): The key to search for.\n\n    Returns:\n        list or int: [block_index, inner_index] if found, otherwise -1.\n    \"\"\"\n    # Step 1: Filter to get non-empty blocks and their original indices.\n    non_empty_info = []\n    for i, block in enumerate(data_structure):\n        if block:\n            non_empty_info.append((i, block))\n\n    if not non_empty_info:\n        return -1\n\n    num_non_empty = len(non_empty_info)\n\n    # Step 2: Outer search (Jump Search) to find the candidate block.\n    # Check if the key is smaller than the very first element.\n    if query_key  non_empty_info[0][1][0]:\n        return -1\n\n    # Derive step size from first principles.\n    step_size = int(num_non_empty**0.5)\n    # A step size of 0 is only possible if num_non_empty  1, which is handled above.\n    if step_size == 0:\n        step_size = 1 # Enforce minimum step size of 1\n\n    prev_idx = 0\n    curr_idx = 0\n    # Jumping phase.\n    while curr_idx  num_non_empty and non_empty_info[curr_idx][1][0] = query_key:\n        prev_idx = curr_idx\n        curr_idx += step_size\n\n    # Linear scanning phase within the identified interval.\n    candidate_block_info = None\n    # The range to scan in `non_empty_info` is [prev_idx, min(curr_idx, num_non_empty) - 1].\n    # We scan backwards to find the last block whose first element is = query_key.\n    for i in range(min(curr_idx, num_non_empty) - 1, prev_idx - 1, -1):\n        if non_empty_info[i][1][0] = query_key:\n            candidate_block_info = non_empty_info[i]\n            break\n    \n    if candidate_block_info is None:\n        # This case implies the key is smaller than all elements,\n        # which is already handled by the initial boundary check.\n        return -1\n\n    original_block_idx, block_data = candidate_block_info\n\n    # Step 3: Inner search (Leftmost-finding Binary Search).\n    low = 0\n    high = len(block_data) - 1\n    found_idx = -1\n\n    while low = high:\n        mid = low + (high - low) // 2\n        \n        if block_data[mid] == query_key:\n            found_idx = mid\n            high = mid - 1  # Continue searching left for the first occurrence.\n        elif block_data[mid]  query_key:\n            low = mid + 1\n        else: # block_data[mid]  query_key\n            high = mid - 1\n            \n    if found_idx != -1:\n        return [original_block_idx, found_idx]\n    else:\n        return -1\n\ndef solve():\n    \"\"\"\n    Defines test cases and runs the search algorithm on them, producing\n    the final formatted output.\n    \"\"\"\n    d_a = [[1, 3, 5, 5], [8, 9, 10], [14, 14, 15, 16], [20, 21]]\n    d_b = [[-10, -5], [0], [2, 4, 6, 8, 10], [13, 17, 19], [23]]\n    d_c = [[], [1, 2, 3], [5], [7, 7, 7, 7], [9, 12]]\n\n    test_cases = [\n        (d_a, 14),\n        (d_a, 1),\n        (d_a, 21),\n        (d_a, 7),\n        (d_a, 0),\n        (d_a, 100),\n        (d_b, 17),\n        (d_c, 7),\n        (d_c, 4),\n        (d_b, -10),\n    ]\n\n    results = []\n    for data_structure, query_key in test_cases:\n        result = search_in_two_level_index(data_structure, query_key)\n        if isinstance(result, list):\n            # Format list [b, j] as a string \"[b,j]\" without spaces.\n            results.append(f\"[{result[0]},{result[1]}]\")\n        else:\n            results.append(str(result))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3242865"}]}