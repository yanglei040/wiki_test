{"hands_on_practices": [{"introduction": "This exercise challenges you to adapt the classic 0/1 knapsack framework to accommodate an additional structural constraint: no two adjacent items can be selected. Solving this problem [@problem_id:3230647] requires a careful re-evaluation of the standard recurrence relation. By considering the state of items beyond the immediate predecessor, you will develop a deeper understanding of how to define DP states that capture all necessary information for the principle of optimality to hold.", "problem": "You are given a sequence of $n$ items indexed from $0$ to $n-1$. Each item $i$ has a positive integer weight $w_i$ and a non-negative integer value $v_i$. You are also given a non-negative integer capacity $C$. You must select a subset of items that maximizes the sum of values subject to two constraints: (i) the sum of weights of selected items is at most $C$, and (ii) no two selected items are adjacent in the original index order. The adjacency constraint means that if item $i$ is selected, then item $i-1$ and item $i+1$ (when they exist) must not be selected.\n\nYour task is to write a complete program that, for each parameter set in the test suite, computes the maximum achievable total value under these constraints.\n\nFundamental base for reasoning and design:\n- The principle of optimality of dynamic programming (DP): any optimal solution to a problem contains optimal solutions to its subproblems.\n- The canonical 0/1 knapsack problem structure, extended with an adjacency (transition) constraint that prohibits choosing adjacent indices.\n\nDefinitions to use:\n- Let the items be $i \\in \\{0,1,\\dots,n-1\\}$.\n- Let $w_i \\in \\mathbb{Z}_{>0}$ be weights and $v_i \\in \\mathbb{Z}_{\\ge 0}$ be values.\n- Let $C \\in \\mathbb{Z}_{\\ge 0}$ be the capacity limit.\n\nInput format for your program:\n- There is no external input. Your program must embed the test suite internally as specified below.\n\nRequired output format:\n- Your program should produce a single line of output containing the results for all test cases, as a comma-separated list enclosed in square brackets, with no spaces. For example, if the results are $r_1$, $r_2$, and $r_3$, print $[r_1,r_2,r_3]$.\n\nTest suite:\n- Case $1$ (general \"happy path\"):\n  - $w = [\\,2,1,6,4,3,5,2\\,]$\n  - $v = [\\,6,3,5,6,4,6,2\\,]$\n  - $C = 10$\n- Case $2$ (boundary capacity $0$):\n  - $w = [\\,1,2,3\\,]$\n  - $v = [\\,5,6,7\\,]$\n  - $C = 0$\n- Case $3$ (all weights exceed capacity):\n  - $w = [\\,5,6,7\\,]$\n  - $v = [\\,5,20,4\\,]$\n  - $C = 4$\n- Case $4$ (dense adjacency conflict; capacity allows multiple but adjacency restricts):\n  - $w = [\\,1,1,1,1\\,]$\n  - $v = [\\,10,1,10,1\\,]$\n  - $C = 2$\n- Case $5$ (single item, capacity insufficient):\n  - $w = [\\,5\\,]$\n  - $v = [\\,10\\,]$\n  - $C = 3$\n- Case $6$ (large capacity, selection driven by adjacency rather than capacity):\n  - $w = [\\,1,2,3,4\\,]$\n  - $v = [\\,1,2,3,4\\,]$\n  - $C = 100$\n\nAnswer type:\n- For each case, output the single integer equal to the maximum total value achievable under the constraints.\n\nYour program must adhere to the output format specification above and aggregate all results into the single printed list in one line, for the cases in the order listed.", "solution": "This problem can be solved using dynamic programming, as it exhibits optimal substructure and overlapping subproblems, consistent with the principle of optimality. The problem structure is a synthesis of the 0/1 knapsack problem and a non-adjacency constraint.\n\nLet $dp[i][c]$ be the maximum value that can be obtained by selecting items from the subset $\\{0, 1, \\dots, i\\}$, subject to the adjacency constraint and a total capacity of $c$. Our goal is to compute $dp[n-1][C]$. The DP table will have dimensions $n \\times (C+1)$.\n\nFor each item $i \\in \\{0, 1, \\dots, n-1\\}$, we have two choices:\n1. **Do not select item $i$**: In this case, the maximum value is the same as the maximum value achievable using items $\\{0, 1, \\dots, i-1\\}$ with the same capacity $c$. This is given by $dp[i-1][c]$. This choice is always available.\n\n2. **Select item $i$**: This is possible only if its weight $w_i$ does not exceed the current capacity limit $c$ (i.e., $c \\ge w_i$). If we select item $i$, the adjacency constraint forbids the selection of item $i-1$. Therefore, the remaining items must be chosen from the set $\\{0, 1, \\dots, i-2\\}$. The value from this choice is the value of item $i$ itself, $v_i$, plus the maximum value obtainable from items $\\{0, 1, \\dots, i-2\\}$ with the remaining capacity, $c-w_i$. This value is $v_i + dp[i-2][c-w_i]$.\n\nCombining these two choices, we define the following recurrence for $i \\in \\{0, \\dots, n-1\\}$ and $c \\in \\{0, \\dots, C\\}$:\n$$\ndp[i][c] = \\max(dp[i-1][c], v_i + dp[i-2][c-w_i])\n$$\nThis general recurrence requires careful handling of the base cases. For $i0$, we define $dp[i][c] = 0$ for any $c$.\n\n**Base Cases:**\n- **For $i = 0$**: We are considering only the first item. If we select item $0$, the value is $v_0$ (provided $c \\ge w_0$); otherwise, the value is $0$. So, $dp[0][c] = v_0$ if $c \\ge w_0$, and $dp[0][c] = 0$ otherwise.\n- **For $i = 1$**: We apply the general recurrence. The value is $\\max(dp[0][c], v_1)$ if $c \\ge w_1$, and $dp[0][c]$ otherwise.\n\nThe final answer to the problem is the value in the bottom-right corner of the DP table, $dp[n-1][C]$. The implementation will populate the table row-by-row for $i$ from $0$ to $n-1$, and for each row, column-by-column for $c$ from $0$ to $C$, applying the recurrence relation.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the specified dynamic programming problem for a suite of test cases.\n    \"\"\"\n    # Test suite cases: each is a tuple of (weights, values, capacity)\n    test_cases = [\n        # Case 1: general \"happy path\"\n        ([2, 1, 6, 4, 3, 5, 2], [6, 3, 5, 6, 4, 6, 2], 10),\n        # Case 2: boundary capacity 0\n        ([1, 2, 3], [5, 6, 7], 0),\n        # Case 3: all weights exceed capacity\n        ([5, 6, 7], [5, 20, 4], 4),\n        # Case 4: dense adjacency conflict\n        ([1, 1, 1, 1], [10, 1, 10, 1], 2),\n        # Case 5: single item, capacity insufficient\n        ([5], [10], 3),\n        # Case 6: large capacity, adjacency is primary constraint\n        ([1, 2, 3, 4], [1, 2, 3, 4], 100),\n    ]\n\n    results = []\n    for weights, values, capacity in test_cases:\n        result = _solve_knapsack_adjacent_constraint(weights, values, capacity)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _solve_knapsack_adjacent_constraint(w, v, C):\n    \"\"\"\n    Calculates the maximum value for the knapsack problem with adjacency constraint.\n\n    Args:\n        w: A list of positive integer weights.\n        v: A list of non-negative integer values.\n        C: A non-negative integer capacity.\n\n    Returns:\n        The maximum achievable value as an integer.\n    \"\"\"\n    n = len(w)\n\n    if n == 0 or C == 0:\n        return 0\n\n    # dp[i][c] = max value from items 0..i with capacity c\n    # Use np.int64 to prevent overflow with large values/capacities, though not strictly\n    # necessary for the given test cases, it's good practice.\n    dp = np.zeros((n, C + 1), dtype=np.int64)\n\n    # Base case: i = 0\n    # For the first item, we can take it if its weight is within capacity.\n    for c in range(w[0], C + 1):\n        dp[0, c] = v[0]\n\n    # Fill DP table for items i = 1 to n-1\n    for i in range(1, n):\n        for c in range(C + 1):\n            # Option 1: Don't take item i.\n            # The value is the best we could do with items up to i-1.\n            value_without_i = dp[i - 1, c]\n\n            # Option 2: Take item i.\n            # This is only possible if c = w[i].\n            value_with_i = 0\n            if c = w[i]:\n                # Value of item i itself.\n                value_with_i = v[i]\n                # Plus value from non-adjacent previous items (up to i-2).\n                if i  1:\n                    value_with_i += dp[i - 2, c - w[i]]\n            \n            # dp[i, c] is the maximum of the two options.\n            dp[i, c] = max(value_without_i, value_with_i)\n\n    # The final answer is the max value considering all items up to n-1 and full capacity C.\n    return int(dp[n - 1, C])\n\nsolve()\n```", "id": "3230647"}, {"introduction": "Dynamic programming is not limited to sequences; it is a powerful technique for solving optimization problems on graphs. This practice problem [@problem_id:3230587] asks for the longest path in a Directed Acyclic Graph (DAG) where path scores are multiplicative, demonstrating how to adapt the relaxation step for different objective functions. The key to solving problems on DAGs is processing the nodes in a topological order, which guarantees that all subproblems are solved before they are needed.", "problem": "You are given several instances of the Directed Acyclic Graph (DAG) longest path problem where path quality is defined by a multiplicative aggregation of edge weights. For each instance, nodes are labeled by integers and directed edges carry strictly positive real-number weights. A path score is the product of its edge weights. The goal is to determine, for a specified source node and target node, the maximum possible path score under this multiplicative definition. If no path exists, define the path score to be $0$. The empty path from a node to itself has product $1$ and is allowable when the source equals the target.\n\nBegin from the following fundamental base: the principle of optimality for dynamic programming states that an optimal solution to a problem can be constructed from optimal solutions to its subproblems when the problem exhibits optimal substructure. For directed acyclic graphs, topological ordering provides a way to process vertices so that all edges go from earlier to later in the order. Using these core facts, derive an algorithmic strategy to compute the optimal multiplicative path score from a given source to a given target, ensuring the approach is correct for any DAG with positive edge weights.\n\nYour program must implement this strategy and solve the following test suite. Each test case consists of a node count $n$, an edge list of triples $(u,v,w)$ describing a directed edge from node $u$ to node $v$ with weight $w$, a source node $s$, and a target node $t$. There are no physical units involved. All weights are strictly positive real numbers.\n\nTest Suite:\n- Case $1$ (general case with multiple competing paths):\n  - $n = 6$\n  - edges $= \\{(0,1,2.0),(1,2,3.0),(0,3,1.5),(3,2,2.0),(2,4,0.5),(3,4,4.0),(4,5,1.25),(1,4,1.2)\\}$\n  - $s = 0$, $t = 5$\n- Case $2$ (boundary case: single node, no edges, source equals target):\n  - $n = 1$\n  - edges $= \\{\\}$\n  - $s = 0$, $t = 0$\n- Case $3$ (edge case: target unreachable from source):\n  - $n = 3$\n  - edges $= \\{(0,1,0.9)\\}$\n  - $s = 0$, $t = 2$\n- Case $4$ (weights less than $1$ compete against a shorter path with weights greater than $1$):\n  - $n = 4$\n  - edges $= \\{(0,1,0.5),(1,3,0.5),(0,2,1.1),(2,3,0.95)\\}$\n  - $s = 0$, $t = 3$\n- Case $5$ (mixture of large and small weights to test path selection):\n  - $n = 5$\n  - edges $= \\{(0,1,10.0),(1,2,0.01),(0,3,3.0),(3,2,2.0),(2,4,0.5),(3,4,0.6)\\}$\n  - $s = 0$, $t = 4$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4,result_5]$), where each $result_i$ is the maximum multiplicative path score for Case $i$ as a floating-point number according to the rules above.", "solution": "The problem presented is to find the maximum score of a path from a source node $s$ to a target node $t$ in a Directed Acyclic Graph (DAG). The score of a path is defined as the product of the weights of its constituent edges. All edge weights are given to be strictly positive real numbers. This problem is an archetypal example of dynamic programming on a DAG.\n\nThe solution is founded upon the principle of optimality, which posits that an optimal path from a node $u$ to a node $v$ contains within it optimal paths from $u$ to any intermediate node on the path. For the present problem, this implies that the path of maximum multiplicative score from a source $s$ to any node $v$ must be formed by extending a maximum-score path from $s$ to some predecessor of $v$, say $u$, along the edge $(u,v)$.\n\nLet us define the subproblem. Let $D[v]$ be the maximum multiplicative path score from the source node $s$ to a given node $v$. Our goal is to compute $D[t]$.\n\nThe base case for our dynamic programming formulation concerns the source node $s$ itself. The path from $s$ to $s$ can be considered an empty path. As stipulated, the product of weights for an empty path is $1$. Therefore, the initial maximum score to reach $s$ is $1$. For any other node $v \\neq s$, we do not yet know of any path from $s$, so we initialize its score to $0$. This initialization serves two purposes: it correctly indicates that a node is, as of yet, unreachable from $s$, and it provides a neutral element for the maximization operation over non-negative scores.\nThe initial conditions are thus:\n$$\nD[v] =\n\\begin{cases}\n1  \\text{if } v = s \\\\\n0  \\text{if } v \\neq s\n\\end{cases}\n$$\n\nThe recurrence relation builds upon this. To compute $D[v]$, we must consider all incoming edges to $v$. For each edge $(u, v)$ with weight $w(u,v)$, we can form a path to $v$ by extending the best path to $u$. The score of such a path would be $D[u] \\times w(u,v)$. Since we seek the maximum possible score for $v$, we take the maximum over all its predecessors $u$:\n$$\nD[v] = \\max_{(u,v) \\in E} \\{D[u] \\times w(u,v)\\}\n$$\nwhere $E$ represents the set of all edges in the graph. This \"relaxation\" step updates the score for $v$ if a better path is found through one of its predecessors.\n\nThe crucial element for guaranteeing correctness is the order in which we compute the values $D[v]$. The recurrence for $D[v]$ depends on the values $D[u]$ for all predecessors $u$ of $v$. This implies that we must have finalized the optimal scores for all predecessors of a node before we can finalize the score for the node itself. In a Directed Acyclic Graph, such an ordering is provided by a topological sort. A topological sort of a DAG is a linear ordering of its vertices such that for every directed edge from vertex $u$ to vertex $v$, $u$ comes before $v$ in the ordering.\n\nBy processing the vertices in their topological order, we ensure that when we consider a vertex $u$, the values $D[p]$ for all its predecessors $p$ have already been computed and are optimal. Consequently, when we relax the outgoing edges of $u$, we are propagating the true optimal score from $s$ to $u$.\n\nThe complete algorithm is as follows:\n1. **Graph Representation**: Construct an adjacency list representation of the DAG from the input edge list, where for each node $u$, we store a list of pairs $(v, w)$ for all outgoing edges $(u,v)$ with weight $w$.\n2. **Topological Sort**: Compute a topological ordering of the vertices of the DAG. This can be achieved using Kahn's algorithm (based on in-degrees) or a Depth-First Search (DFS) traversal. Let the resulting ordered list of vertices be $L$.\n3. **Initialization**: Create an array $D$ of size $n$ (the number of nodes), initialized with $D[s] = 1.0$ and $D[v] = 0.0$ for all other vertices $v \\neq s$.\n4. **Path Score Calculation**: Iterate through the vertices $u \\in L$ in their topological order. For each vertex $u$, iterate through its neighbors $v$ (connected by an edge $(u,v)$ with weight $w(u,v)$). Perform the relaxation step:\n$$\nD[v] = \\max(D[v], D[u] \\times w(u,v))\n$$\n5. **Final Result**: After the iteration completes, the value $D[t]$ will be the maximum multiplicative path score from $s$ to $t$. If $t$ is unreachable from $s$, its score $D[t]$ will remain at its initial value of $0$ (for $s \\neq t$).\n\nThis algorithm correctly leverages the acyclic nature of the graph and the principle of optimality to solve the problem in time linear in the number of vertices and edges, specifically $O(n+m)$, where $n$ is the number of vertices and $m$ is the number of edges.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_max_path_score(n, edges, s, t):\n    \"\"\"\n    Calculates the maximum multiplicative path score in a DAG.\n\n    Args:\n        n (int): The number of nodes in the graph, labeled 0 to n-1.\n        edges (list of tuples): A list of (u, v, w) triples representing\n                                directed edges from u to v with weight w.\n        s (int): The source node.\n        t (int): The target node.\n\n    Returns:\n        float: The maximum multiplicative path score from s to t. Returns 0.0\n               if no path exists, and 1.0 if s equals t.\n    \"\"\"\n    if n == 0:\n        return 0.0\n\n    # Build adjacency list\n    adj = {i: [] for i in range(n)}\n    for u, v, w in edges:\n        adj[u].append((v, w))\n\n    # Step 1: Topological Sort using DFS\n    topo_order = []\n    visited = [False] * n\n\n    def dfs(u):\n        visited[u] = True\n        for v, w in adj[u]:\n            if not visited[v]:\n                dfs(v)\n        topo_order.append(u)\n\n    # The topological sort needs to be robust for disconnected components\n    for i in range(n):\n        if not visited[i]:\n            dfs(i)\n    \n    # The result of DFS is a reverse topological sort\n    topo_order.reverse()\n\n    # Step 2: Initialize distances\n    # Scores for paths from source s\n    scores = np.zeros(n, dtype=float)\n    if s  n:\n        scores[s] = 1.0\n\n    # Step 3: Iterate through topologically sorted nodes to calculate scores\n    # The topological sort guarantees that we process nodes in an order\n    # such that all predecessors of a node are processed before the node itself.\n    for u in topo_order:\n        # If a node is unreachable from the source, its score will be 0,\n        # and it cannot contribute to any path scores originating from s.\n        # We only need to relax edges from nodes that have a non-zero score.\n        if scores[u]  0:\n            for v, w in adj[u]:\n                # Relaxation step for multiplicative weights\n                new_score = scores[u] * w\n                if new_score  scores[v]:\n                    scores[v] = new_score\n    \n    if t  n:\n        return scores[t]\n    else:\n        # Target node index is out of bounds\n        return 0.0\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the DAG longest multiplicative path problem.\n    \"\"\"\n    test_cases = [\n        # Case 1 (general case with multiple competing paths)\n        {\n            \"n\": 6,\n            \"edges\": [(0, 1, 2.0), (1, 2, 3.0), (0, 3, 1.5), (3, 2, 2.0),\n                      (2, 4, 0.5), (3, 4, 4.0), (4, 5, 1.25), (1, 4, 1.2)],\n            \"s\": 0, \"t\": 5\n        },\n        # Case 2 (boundary case: single node, no edges, source equals target)\n        {\n            \"n\": 1,\n            \"edges\": [],\n            \"s\": 0, \"t\": 0\n        },\n        # Case 3 (edge case: target unreachable from source)\n        {\n            \"n\": 3,\n            \"edges\": [(0, 1, 0.9)],\n            \"s\": 0, \"t\": 2\n        },\n        # Case 4 (weights  1 compete against a shorter path with weights  1)\n        {\n            \"n\": 4,\n            \"edges\": [(0, 1, 0.5), (1, 3, 0.5), (0, 2, 1.1), (2, 3, 0.95)],\n            \"s\": 0, \"t\": 3\n        },\n        # Case 5 (mixture of large and small weights to test path selection)\n        {\n            \"n\": 5,\n            \"edges\": [(0, 1, 10.0), (1, 2, 0.01), (0, 3, 3.0),\n                      (3, 2, 2.0), (2, 4, 0.5), (3, 4, 0.6)],\n            \"s\": 0, \"t\": 4\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_max_path_score(case[\"n\"], case[\"edges\"], case[\"s\"], case[\"t\"])\n        results.append(result)\n\n    # Format output as a comma-separated list in brackets\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3230587"}, {"introduction": "Many dynamic programming problems focus on finding a single optimal value, but what if there are multiple ways to achieve it? This problem [@problem_id:3230550] modifies the 0/1 knapsack problem to ask for the *number* of distinct optimal solutions. To solve this, you must augment the standard DP state to not only track the maximum value but also to count the number of subsets that achieve it, learning how to combine counts when different choices lead to the same optimal value.", "problem": "You are asked to modify a standard Dynamic Programming (DP) problem so that the goal is not only to find one optimal solution, but to count all distinct optimal solutions. Consider the classical $0/1$ knapsack problem as the base. You are given a finite set of $n$ items, each item $i$ has an integer weight $w_i \\ge 0$ and an integer value $v_i \\ge 0$, and you are given a nonnegative integer capacity $C$. A feasible subset is any subset of indices $S \\subseteq \\{1,2,\\ldots,n\\}$ such that $\\sum_{i \\in S} w_i \\le C$. The standard objective is to maximize the total value $\\sum_{i \\in S} v_i$ over all feasible subsets. In this task, you must compute how many distinct optimal subsets exist, where distinctness is defined by the set of chosen indices: two subsets $S$ and $T$ are considered different if and only if there exists at least one index $j$ such that $j \\in S$ and $j \\notin T$ or $j \\in T$ and $j \\notin S$.\n\nStarting only from fundamental definitions relevant to Dynamic Programming (DP), specifically the principle of optimal substructure and overlapping subproblems, derive a correct and efficient algorithm that, for each input instance, returns the count of distinct subsets that achieve the maximum achievable total value without exceeding the capacity. Your derivation must be principled and should not rely on any unproven shortcut formulas.\n\nYour program must be fully self-contained, take no input, and must process the following fixed test suite of instances. Each instance is a tuple consisting of the list of weights, the list of values, and the capacity, all with integer entries:\n- Instance $1$: weights $\\{3,2,2\\}$, values $\\{4,3,3\\}$, capacity $4$.\n- Instance $2$: weights $\\{1,1,1\\}$, values $\\{1,1,1\\}$, capacity $2$.\n- Instance $3$: weights $\\{5,4,4,2\\}$, values $\\{6,5,5,3\\}$, capacity $8$.\n- Instance $4$: weights $\\{\\}$, values $\\{\\}$, capacity $0$.\n- Instance $5$: weights $\\{3,3,3,3\\}$, values $\\{5,5,5,5\\}$, capacity $6$.\n- Instance $6$: weights $\\{2,1,2,1\\}$, values $\\{2,1,2,1\\}$, capacity $3$.\n- Instance $7$: weights $\\{0,0\\}$, values $\\{0,0\\}$, capacity $0$.\n\nFor each instance, the required output is a single integer: the number of distinct optimal subsets as defined above. There are no physical units involved in this problem.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the instances above. For example, the line must look like $[r_1,r_2,\\ldots,r_7]$ where each $r_k$ is the integer count for instance $k$.", "solution": "We begin from two fundamental principles that justify Dynamic Programming (DP): optimal substructure and overlapping subproblems. The optimal substructure principle states that an optimal solution to a problem can be constructed from optimal solutions of its subproblems. In the context of the $0/1$ knapsack, consider the decision on the last item $i$: either we include item $i$ or we do not. If we do not include item $i$, then the problem reduces to the first $i-1$ items with capacity $C$. If we do include item $i$, then the remaining capacity is $C - w_i$ and the subproblem reduces to the first $i-1$ items with this reduced capacity. The overlapping subproblems principle holds because many subproblems $(i,C')$ are revisited across different decision paths.\n\nWe must extend the standard DP for maximum value to also count how many distinct subsets achieve that maximum. Let us define a DP state that stores two quantities simultaneously:\n- $V[i][c]$: the maximum total value achievable using only the first $i$ items under capacity limit $c$.\n- $K[i][c]$: the number of distinct subsets of the first $i$ items that achieve the value $V[i][c]$ under capacity limit $c$.\n\nWe use the following base conditions derived from the definitions:\n- For $i = 0$ (no items), for every capacity $c \\in \\{0,1,\\ldots,C\\}$, the maximum value is $V[0][c] = 0$ because no item can be taken, and exactly one subset achieves this value: the empty set. Hence $K[0][c] = 1$.\n- For $c = 0$ (zero capacity), for every $i \\in \\{0,1,\\ldots,n\\}$, the maximum value is also $0$ and the number of subsets that achieve this value is the number of ways to choose a subset of zero total weight among the first $i$ items that does not exceed capacity $0$. If there are items with zero weight and zero value, both including and excluding such an item preserve feasibility and value, and thus the count doubles accordingly. This behavior is naturally captured by the recurrence below.\n\nFor the transition, fix $i \\ge 1$ and $c \\ge 0$. Consider two options:\n- Exclude item $i$: this gives value $V[i-1][c]$ with count $K[i-1][c]$.\n- Include item $i$ if $w_i \\le c$: this gives value $V[i-1][c - w_i] + v_i$ with count $K[i-1][c - w_i]$.\n\nDenote these two candidate values by\n$$\n\\text{val\\_excl} = V[i-1][c], \\quad \\text{cnt\\_excl} = K[i-1][c],\n$$\n$$\n\\text{val\\_incl} =\n\\begin{cases}\nV[i-1][c - w_i] + v_i  \\text{if } w_i \\le c, \\\\\n-\\infty  \\text{otherwise},\n\\end{cases}\n\\quad\n\\text{cnt\\_incl} =\n\\begin{cases}\nK[i-1][c - w_i]  \\text{if } w_i \\le c, \\\\\n0  \\text{otherwise}.\n\\end{cases}\n$$\n\nWe then set\n$$\nV[i][c] = \\max(\\text{val\\_excl}, \\text{val\\_incl}).\n$$\nFor the counts,\n$$\nK[i][c] =\n\\begin{cases}\n\\text{cnt\\_incl}  \\text{if } \\text{val\\_incl}  \\text{val\\_excl}, \\\\\n\\text{cnt\\_excl}  \\text{if } \\text{val\\_excl}  \\text{val\\_incl}, \\\\\n\\text{cnt\\_excl} + \\text{cnt\\_incl}  \\text{if } \\text{val\\_excl} = \\text{val\\_incl}.\n\\end{cases}\n$$\n\nThis recurrence is justified as follows:\n- If including strictly improves the value, then all optimal subsets at $(i,c)$ must include item $i$, and their count is exactly the number of optimal subsets for the subproblem $(i-1, c - w_i)$, namely $\\text{cnt\\_incl}$.\n- If excluding strictly dominates, then the optimal subsets at $(i,c)$ are exactly those optimal at $(i-1,c)$, with count $\\text{cnt\\_excl}$.\n- If both choices tie in value, then every optimal subset at $(i,c)$ either includes item $i$ or excludes it, and these two families are disjoint because they differ on whether $i$ is present. Therefore, the total count is the sum $\\text{cnt\\_excl} + \\text{cnt\\_incl}$.\n\nNote that if $w_i = 0$ and $v_i = 0$, then for any $c$ we have $\\text{val\\_incl} = \\text{val\\_excl}$ and $\\text{cnt\\_incl} = \\text{cnt\\_excl}$; thus the recurrence gives $K[i][c] = 2 \\cdot K[i-1][c]$, which correctly counts that including or excluding such an item both yield optimal subsets and are distinct by index. If $w_i = 0$ but $v_i  0$, then inclusion strictly improves the value, and all optimal subsets at $(i,c)$ must include $i$, which is also correctly captured.\n\nCorrectness follows by induction on $i$:\n- Base case $i=0$ holds by definition: $V[0][c] = 0$ and $K[0][c] = 1$.\n- Inductive step: assume for all capacities $c'$ that $V[i-1][c']$ and $K[i-1][c']$ are correct. For capacity $c$, any optimal subset at $(i,c)$ either excludes $i$ and corresponds to an optimal subset counted by $(V[i-1][c], K[i-1][c])$, or includes $i$ and corresponds to an optimal subset counted by $(V[i-1][c-w_i], K[i-1][c-w_i])$ if feasible. The maximum value among these two options defines $V[i][c]$, and disjointness between the inclusion and exclusion families justifies the count rule above. Therefore $V[i][c]$ and $K[i][c]$ are correct.\n\nThe algorithm fills a table of size $(n+1) \\times (C+1)$, with each entry computed in constant time, for time complexity $\\mathcal{O}(n \\cdot C)$ and space complexity $\\mathcal{O}(n \\cdot C)$. This is acceptable for the small fixed instances in the test suite.\n\nApplying the method to the provided instances yields:\n- Instance $1$: maximum value is $6$ by choosing both items of weight $2$; exactly $1$ optimal subset, so the count is $1$.\n- Instance $2$: maximum value is $2$ by choosing any $2$ of the $3$ items; the count is $\\binom{3}{2} = 3$.\n- Instance $3$: maximum value is $10$ by choosing the two items of weight $4$ and value $5$; the count is $1$.\n- Instance $4$: with no items and capacity $0$, the only subset is the empty set, which is optimal with value $0$; the count is $1$.\n- Instance $5$: maximum value is $10$ by choosing any $2$ of the $4$ items; the count is $\\binom{4}{2} = 6$.\n- Instance $6$: maximum value is $3$ by choosing one item of value $2$ and one item of value $1$ within capacity $3$; there are $4$ such pairs, so the count is $4$.\n- Instance $7$: all subsets have value $0$ within capacity $0$ since both items have zero weight and zero value; there are $2^2 = 4$ subsets, so the count is $4$.\n\nTherefore, the program should output the single line\n$$\n[1,3,1,1,6,4,4].\n$$", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef count_optimal_knapsack_subsets(weights, values, capacity):\n    n = len(weights)\n    C = capacity\n    # dp_value[i][c] = best value using first i items with capacity c\n    # dp_count[i][c] = number of subsets achieving dp_value[i][c]\n    dp_value = [[0] * (C + 1) for _ in range(n + 1)]\n    dp_count = [[0] * (C + 1) for _ in range(n + 1)]\n    # Base case: with 0 items, value is 0 and exactly one subset (empty set)\n    for c in range(C + 1):\n        dp_value[0][c] = 0\n        dp_count[0][c] = 1\n\n    for i in range(1, n + 1):\n        w = weights[i - 1]\n        v = values[i - 1]\n        for c in range(0, C + 1):\n            # Exclude current item\n            val_excl = dp_value[i - 1][c]\n            cnt_excl = dp_count[i - 1][c]\n            # Include current item if feasible\n            if w = c:\n                val_incl = dp_value[i - 1][c - w] + v\n                cnt_incl = dp_count[i - 1][c - w]\n            else:\n                val_incl = float('-inf')\n                cnt_incl = 0\n            # Choose best value and set counts accordingly\n            if val_incl  val_excl:\n                dp_value[i][c] = val_incl\n                dp_count[i][c] = cnt_incl\n            elif val_excl  val_incl:\n                dp_value[i][c] = val_excl\n                dp_count[i][c] = cnt_excl\n            else:\n                # Tie: both choices produce optimal value; counts add\n                dp_value[i][c] = val_excl  # same as val_incl\n                dp_count[i][c] = cnt_excl + cnt_incl\n\n    return dp_count[n][C]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is (weights, values, capacity)\n    test_cases = [\n        ([3, 2, 2], [4, 3, 3], 4),         # Instance 1\n        ([1, 1, 1], [1, 1, 1], 2),         # Instance 2\n        ([5, 4, 4, 2], [6, 5, 5, 3], 8),   # Instance 3\n        ([], [], 0),                       # Instance 4\n        ([3, 3, 3, 3], [5, 5, 5, 5], 6),   # Instance 5\n        ([2, 1, 2, 1], [2, 1, 2, 1], 3),   # Instance 6\n        ([0, 0], [0, 0], 0),               # Instance 7\n    ]\n\n    results = []\n    for weights, values, capacity in test_cases:\n        result = count_optimal_knapsack_subsets(weights, values, capacity)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3230550"}]}