{"hands_on_practices": [{"introduction": "The Berendsen thermostat is a popular algorithm for temperature control due to its simplicity and robust convergence. This exercise explores its core mechanism through a simplified analytical model, which describes the temperature relaxation as a first-order process. By solving for the equilibration time under different conditions, you will develop a quantitative understanding of the coupling time constant, $\\tau_T$, and its direct influence on how quickly your simulation reaches the desired target temperature. [@problem_id:2466036]", "problem": "Consider a large box of liquid argon that is weakly coupled to an external heat bath using a Berendsen thermostat. In an idealized continuum description that focuses exclusively on the kinetic temperature, assume the instantaneous system temperature $T(t)$ evolves according to the first-order linear ordinary differential equation\n$$\n\\frac{dT}{dt}=\\frac{T_{\\mathrm{target}}-T(t)}{\\tau_T},\n$$\nwhere $T_{\\mathrm{target}}$ is the target (bath) temperature and $\\tau_T$ is the thermostat coupling time constant. This idealization neglects potential energy contributions and assumes that the number of particles is sufficiently large that $T(t)$ is well defined at all times.\n\nYour task is to quantify the rate of equilibration under the Berendsen thermostat by computing, for each specified case, the minimal physical time $t_{\\mathrm{eq}}$ such that the absolute deviation from the target temperature first becomes less than or equal to a prescribed absolute tolerance $\\Delta$:\n$$\n\\left|T(t)-T_{\\mathrm{target}}\\right|\\le \\Delta,\n$$\nwith the initial condition $T(0)=T_0$. Report $t_{\\mathrm{eq}}$ in picoseconds, rounded to six decimal places.\n\nUse the following test suite, where each case is a quadruple $\\left(T_{\\mathrm{target}},T_0,\\tau_T,\\Delta\\right)$ with temperatures in kelvin and time constants in picoseconds:\n- Case A: $\\left(120\\,\\mathrm{K},300\\,\\mathrm{K},0.5\\,\\mathrm{ps},1\\,\\mathrm{K}\\right)$\n- Case B: $\\left(120\\,\\mathrm{K},300\\,\\mathrm{K},0.05\\,\\mathrm{ps},1\\,\\mathrm{K}\\right)$\n- Case C: $\\left(120\\,\\mathrm{K},300\\,\\mathrm{K},5.0\\,\\mathrm{ps},1\\,\\mathrm{K}\\right)$\n- Case D: $\\left(120\\,\\mathrm{K},120\\,\\mathrm{K},0.5\\,\\mathrm{ps},1\\,\\mathrm{K}\\right)$\n- Case E: $\\left(120\\,\\mathrm{K},80\\,\\mathrm{K},0.5\\,\\mathrm{ps},1\\,\\mathrm{K}\\right)$\n- Case F: $\\left(120\\,\\mathrm{K},300\\,\\mathrm{K},0.5\\,\\mathrm{ps},0.01\\,\\mathrm{K}\\right)$\n\nYour program must produce a single line of output containing the six values of $t_{\\mathrm{eq}}$ for Cases A through F, in order, formatted as a comma-separated list enclosed in square brackets; for example, a valid format is \"[a,b,c,d,e,f]\". All six numbers in the output must be expressed in picoseconds and rounded to six decimal places as specified above. No additional text should be printed.", "solution": "The problem as stated is scientifically and mathematically sound. It constitutes a well-posed initial value problem for a first-order linear ordinary differential equation, which accurately represents the idealized kinetic temperature evolution under a Berendsen thermostat. We shall proceed directly to the analytical solution.\n\nThe governing equation for the system's temperature $T(t)$ is given as:\n$$\n\\frac{dT}{dt} = \\frac{T_{\\mathrm{target}}-T(t)}{\\tau_T}\n$$\nwith the initial condition $T(0) = T_0$. Here, $T_{\\mathrm{target}}$ is the constant target temperature and $\\tau_T$ is the time constant of the thermostat coupling.\n\nTo solve this equation, we define the temperature deviation from the target as $\\delta T(t) = T(t) - T_{\\mathrm{target}}$. The derivative of this quantity is $\\frac{d(\\delta T)}{dt} = \\frac{dT}{dt}$, as $T_{\\mathrm{target}}$ is a constant. Substituting this into the original equation yields a simplified homogeneous linear ODE:\n$$\n\\frac{d(\\delta T)}{dt} = -\\frac{\\delta T(t)}{\\tau_T}\n$$\nThis equation is separable. We can rearrange and integrate it:\n$$\n\\int_{\\delta T(0)}^{\\delta T(t)} \\frac{d(\\delta T')}{\\delta T'} = -\\int_0^t \\frac{dt'}{\\tau_T}\n$$\nwhere $\\delta T(0) = T(0) - T_{\\mathrm{target}} = T_0 - T_{\\mathrm{target}}$. The integration yields:\n$$\n\\ln\\left|\\frac{\\delta T(t)}{\\delta T(0)}\\right| = -\\frac{t}{\\tau_T}\n$$\nSolving for $\\delta T(t)$ by exponentiation gives:\n$$\n\\delta T(t) = \\delta T(0) e^{-t/\\tau_T}\n$$\nSubstituting back the definitions of $\\delta T(t)$ and $\\delta T(0)$, we obtain the complete solution for $T(t)$:\n$$\nT(t) - T_{\\mathrm{target}} = (T_0 - T_{\\mathrm{target}}) e^{-t/\\tau_T}\n$$\n$$\nT(t) = T_{\\mathrm{target}} + (T_0 - T_{\\mathrm{target}}) e^{-t/\\tau_T}\n$$\nThe problem requires finding the minimal time $t_{\\mathrm{eq}}$ at which the absolute deviation from the target temperature becomes less than or equal to a tolerance $\\Delta$:\n$$\n|T(t) - T_{\\mathrm{target}}| \\le \\Delta\n$$\nUsing our solution, this condition becomes:\n$$\n|(T_0 - T_{\\mathrm{target}}) e^{-t/\\tau_T}| \\le \\Delta\n$$\nSince the time constant $\\tau_T$ is positive and we consider $t \\ge 0$, the exponential term $e^{-t/\\tau_T}$ is always positive. Therefore, the inequality simplifies to:\n$$\n|T_0 - T_{\\mathrm{target}}| e^{-t/\\tau_T} \\le \\Delta\n$$\nWe must now find the smallest $t \\ge 0$, denoted $t_{\\mathrm{eq}}$, that satisfies this condition. We consider two distinct scenarios.\n\nScenario 1: The initial condition already satisfies the tolerance.\nIf $|T_0 - T_{\\mathrm{target}}| \\le \\Delta$, the condition is met at $t=0$. Since the function $|T(t) - T_{\\mathrm{target}}|$ is a monotonically decreasing function of time, the condition will hold for all $t > 0$. The minimal time is thus $t_{\\mathrm{eq}} = 0$.\n\nScenario 2: The initial deviation exceeds the tolerance.\nIf $|T_0 - T_{\\mathrm{target}}| > \\Delta$, the system must evolve for some positive time $t_{\\mathrm{eq}}$ to reach the desired state. We find this time by solving for the moment when the equality is first met:\n$$\n|T_0 - T_{\\mathrm{target}}| e^{-t_{\\mathrm{eq}}/\\tau_T} = \\Delta\n$$\nRearranging to solve for $t_{\\mathrm{eq}}$:\n$$\ne^{-t_{\\mathrm{eq}}/\\tau_T} = \\frac{\\Delta}{|T_0 - T_{\\mathrm{target}}|}\n$$\nTaking the natural logarithm of both sides:\n$$\n-\\frac{t_{\\mathrm{eq}}}{\\tau_T} = \\ln\\left(\\frac{\\Delta}{|T_0 - T_{\\mathrm{target}}|}\\right)\n$$\nFinally, solving for $t_{\\mathrm{eq}}$ and using the property $\\ln(x^{-1}) = -\\ln(x)$:\n$$\nt_{\\mathrm{eq}} = -\\tau_T \\ln\\left(\\frac{\\Delta}{|T_0 - T_{\\mathrm{target}}|}\\right) = \\tau_T \\ln\\left(\\frac{|T_0 - T_{\\mathrm{target}}|}{\\Delta}\\right)\n$$\nThis formula is valid for $t_{\\mathrm{eq}}$ when $|T_0 - T_{\\mathrm{target}}| > \\Delta$. The argument of the logarithm is greater than $1$, ensuring $t_{\\mathrm{eq}} > 0$.\n\nWe now apply this framework to the specified test cases. All times are in picoseconds ($\\mathrm{ps}$) and temperatures are in kelvin ($\\mathrm{K}$).\n\nCase A: $(T_{\\mathrm{target}}, T_0, \\tau_T, \\Delta) = (120, 300, 0.5, 1)$\n$|T_0 - T_{\\mathrm{target}}| = |300 - 120| = 180\\,\\mathrm{K}$. Since $180 > 1$, we use the derived formula:\n$t_{\\mathrm{eq}} = 0.5 \\times \\ln\\left(\\frac{180}{1}\\right) = 0.5 \\times \\ln(180) \\approx 2.596478\\,\\mathrm{ps}$.\n\nCase B: $(T_{\\mathrm{target}}, T_0, \\tau_T, \\Delta) = (120, 300, 0.05, 1)$\n$|T_0 - T_{\\mathrm{target}}| = 180\\,\\mathrm{K}$. Since $180 > 1$:\n$t_{\\mathrm{eq}} = 0.05 \\times \\ln\\left(\\frac{180}{1}\\right) = 0.05 \\times \\ln(180) \\approx 0.259648\\,\\mathrm{ps}$.\n\nCase C: $(T_{\\mathrm{target}}, T_0, \\tau_T, \\Delta) = (120, 300, 5.0, 1)$\n$|T_0 - T_{\\mathrm{target}}| = 180\\,\\mathrm{K}$. Since $180 > 1$:\n$t_{\\mathrm{eq}} = 5.0 \\times \\ln\\left(\\frac{180}{1}\\right) = 5.0 \\times \\ln(180) \\approx 25.964784\\,\\mathrm{ps}$.\n\nCase D: $(T_{\\mathrm{target}}, T_0, \\tau_T, \\Delta) = (120, 120, 0.5, 1)$\n$|T_0 - T_{\\mathrm{target}}| = |120 - 120| = 0\\,\\mathrm{K}$. Since $0 \\le 1$, the condition is met at $t=0$.\n$t_{\\mathrm{eq}} = 0.000000\\,\\mathrm{ps}$.\n\nCase E: $(T_{\\mathrm{target}}, T_0, \\tau_T, \\Delta) = (120, 80, 0.5, 1)$\n$|T_0 - T_{\\mathrm{target}}| = |80 - 120| = 40\\,\\mathrm{K}$. Since $40 > 1$:\n$t_{\\mathrm{eq}} = 0.5 \\times \\ln\\left(\\frac{40}{1}\\right) = 0.5 \\times \\ln(40) \\approx 1.844440\\,\\mathrm{ps}$.\n\nCase F: $(T_{\\mathrm{target}}, T_0, \\tau_T, \\Delta) = (120, 300, 0.5, 0.01)$\n$|T_0 - T_{\\mathrm{target}}| = 180\\,\\mathrm{K}$. Since $180 > 0.01$:\n$t_{\\mathrm{eq}} = 0.5 \\times \\ln\\left(\\frac{180}{0.01}\\right) = 0.5 \\times \\ln(18000) \\approx 4.899064\\,\\mathrm{ps}$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the equilibration time under a Berendsen thermostat model\n    for a given set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (T_target, T_0, tau_T, Delta)\n    # T_target: target temperature (K)\n    # T_0: initial temperature (K)\n    # tau_T: thermostat coupling time constant (ps)\n    # Delta: absolute temperature tolerance (K)\n    test_cases = [\n        (120.0, 300.0, 0.5, 1.0),    # Case A\n        (120.0, 300.0, 0.05, 1.0),   # Case B\n        (120.0, 300.0, 5.0, 1.0),    # Case C\n        (120.0, 120.0, 0.5, 1.0),    # Case D\n        (120.0, 80.0, 0.5, 1.0),     # Case E\n        (120.0, 300.0, 0.5, 0.01),   # Case F\n    ]\n\n    results = []\n    for case in test_cases:\n        T_target, T_0, tau_T, Delta = case\n        \n        initial_deviation = abs(T_0 - T_target)\n        \n        # Check if the system is already equilibrated at t=0\n        if initial_deviation <= Delta:\n            t_eq = 0.0\n        else:\n            # The system is not equilibrated, calculate the time t_eq\n            # Formula derived from the ODE solution:\n            # t_eq = tau_T * ln(|T_0 - T_target| / Delta)\n            t_eq = tau_T * np.log(initial_deviation / Delta)\n            \n        results.append(t_eq)\n\n    # Format the results to six decimal places as required.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2466036"}, {"introduction": "Unlike the simple exponential decay of the Berendsen method, the Nosé–Hoover thermostat introduces a dynamic extended variable that couples to the system, generating true canonical ensemble dynamics. This practice delves into the behavior of this thermostat by analyzing its response to small perturbations around the equilibrium temperature. By deriving the characteristic frequency of these temperature oscillations, you will gain insight into the physical meaning of the fictitious mass parameter, $Q$, and how its value dictates the thermostat's dynamic behavior. [@problem_id:2466024]", "problem": "You are modeling the effect of a Nosé–Hoover (NH) thermostat on the kinetic temperature of an idealized system with $g$ free degrees of freedom (DOF). The thermostat is characterized by a friction-like variable $\\zeta(t)$ and a fictitious mass $Q$. The target temperature is $T$. The Boltzmann constant is $k_\\mathrm{B} = 1.380649\\times 10^{-23}\\,\\mathrm{J/K}$. Consider the force-free case so that each velocity component $v_i(t)$ evolves under the NH equations\n$$\\frac{d v_i}{dt} = -\\,\\zeta\\, v_i,$$\nand the thermostat variable evolves as\n$$\\frac{d \\zeta}{dt} = \\frac{1}{Q}\\left(2K - g\\,k_\\mathrm{B}\\,T\\right),$$\nwhere the instantaneous kinetic energy is\n$$K(t) = \\sum_{i=1}^{g} \\frac{1}{2}\\,m_i\\,v_i^2(t).$$\nAssume small-amplitude oscillations of the kinetic temperature about equilibrium so that the motion near the equilibrium kinetic energy $K_0 = \\frac{g}{2}\\,k_\\mathrm{B}\\,T$ is harmonic. Starting from these first principles, determine the small-amplitude angular frequency $\\omega$ (in $\\mathrm{rad/s}$) of these kinetic temperature oscillations as a function of $g$, $T$, and $Q$.\n\nWrite a program that computes $\\omega$ for each of the following test cases. Use the values of $g$, $T$, and $Q$ given below, where $T$ is in $\\mathrm{K}$ and $Q$ is in $\\mathrm{J\\cdot s^2}$. Express each result as a floating-point number in $\\mathrm{s^{-1}}$ (radians per second), rounded to six significant figures.\n\nTest suite (each case is $(g, T, Q)$):\n- Case A (happy path): $(300, 300, 1.2425841\\times 10^{-42})$\n- Case B (small $Q$): $(300, 300, 1.2425841\\times 10^{-44})$\n- Case C (large $Q$): $(300, 300, 1.2425841\\times 10^{-40})$\n- Case D (different $g$ and $T$): $(3, 1000, 1.0\\times 10^{-45})$\n\nFinal output format:\nYour program should produce a single line of output containing the four angular frequencies in the order A, B, C, D, as a comma-separated list enclosed in square brackets with no spaces. For example: \"[valueA,valueB,valueC,valueD]\". Each value must be rounded to six significant figures and must be stated in $\\mathrm{s^{-1}}$.", "solution": "The problem statement must first be subjected to rigorous validation.\n\n**Step 1: Extract Givens**\n\nThe givens are stated as follows:\n-   Number of degrees of freedom: $g$\n-   Target temperature: $T$\n-   Thermostat fictitious mass: $Q$\n-   Boltzmann constant: $k_\\mathrm{B} = 1.380649\\times 10^{-23}\\,\\mathrm{J/K}$\n-   Equations of motion for velocity $v_i(t)$ and thermostat variable $\\zeta(t)$:\n    $$ \\frac{d v_i}{dt} = -\\,\\zeta\\, v_i $$\n    $$ \\frac{d \\zeta}{dt} = \\frac{1}{Q}\\left(2K - g\\,k_\\mathrm{B}\\,T\\right) $$\n-   Instantaneous kinetic energy:\n    $$ K(t) = \\sum_{i=1}^{g} \\frac{1}{2}\\,m_i\\,v_i^2(t) $$\n-   Equilibrium kinetic energy: $K_0 = \\frac{g}{2}\\,k_\\mathrm{B}\\,T$\n-   Assumption: The motion near equilibrium is harmonic, corresponding to small-amplitude oscillations of kinetic temperature.\n-   Objective: Determine the angular frequency $\\omega$ of these oscillations as a function of $g$, $T$, and $Q$.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is evaluated against the validation criteria.\n-   **Scientifically Grounded:** The problem describes the Nosé–Hoover thermostat, a standard and widely used method in molecular dynamics simulations for temperature control. The provided equations of motion are the correct representation of the Nosé–Hoover dynamics in the absence of external potential forces. The analysis of small-amplitude oscillations is a standard technique in physics to study the stability and characteristic frequencies of a dynamical system near an equilibrium point.\n-   **Well-Posed:** The problem is well-posed. It asks for a specific physical quantity, the angular frequency, based on a clear set of physical laws and a standard linearization assumption. All necessary parameters ($g$, $T$, $Q$, $k_\\mathrm{B}$) and equations are provided to derive a unique solution.\n-   **Objective:** The language is precise, quantitative, and devoid of subjective or non-scientific content.\n\nThere are no violations of scientific principles, no missing information for the derivation, and no ambiguities. The setup is a standard textbook example of analyzing thermostat dynamics.\n\n**Step 3: Verdict and Action**\n\nThe problem is deemed **valid**. We proceed to the derivation of the solution.\n\nThe system is described by the state variables $v_i$ (or, more compactly, the total kinetic energy $K$) and the thermostat variable $\\zeta$. The equations of motion are given for $\\frac{d v_i}{dt}$ and $\\frac{d \\zeta}{dt}$. We must find the corresponding equation for $\\frac{dK}{dt}$.\n\nThe rate of change of kinetic energy $K$ is:\n$$ \\frac{dK}{dt} = \\frac{d}{dt} \\left( \\sum_{i=1}^{g} \\frac{1}{2}m_i v_i^2 \\right) = \\sum_{i=1}^{g} m_i v_i \\frac{dv_i}{dt} $$\nSubstituting the equation for $\\frac{dv_i}{dt} = -\\zeta v_i$:\n$$ \\frac{dK}{dt} = \\sum_{i=1}^{g} m_i v_i (-\\zeta v_i) = -\\zeta \\sum_{i=1}^{g} m_i v_i^2 = -2\\zeta \\left( \\sum_{i=1}^{g} \\frac{1}{2} m_i v_i^2 \\right) $$\nThis yields the first key equation for our analysis:\n$$ \\frac{dK}{dt} = -2\\zeta K $$\nThe second equation is given in the problem statement:\n$$ \\frac{d\\zeta}{dt} = \\frac{1}{Q}(2K - g k_\\mathrm{B} T) $$\n\nNext, we identify the equilibrium point of the system. At equilibrium, all time derivatives are zero.\nFrom $\\frac{d\\zeta}{dt} = 0$, we find $2K - g k_\\mathrm{B} T = 0$, which gives the equilibrium kinetic energy $K_{eq} = \\frac{g}{2} k_\\mathrm{B} T$. This is the value $K_0$ specified in the problem.\nFrom $\\frac{dK}{dt} = 0$, we have $-2\\zeta K = 0$. Since we are interested in a system with non-zero temperature, $K_{eq}$ is non-zero, which implies that at equilibrium, $\\zeta_{eq} = 0$.\nThe equilibrium point is $(\\zeta_{eq}, K_{eq}) = (0, K_0)$.\n\nWe now linearize the system of equations around this equilibrium point by considering small perturbations:\nLet $\\zeta(t) = \\zeta_{eq} + \\delta\\zeta(t) = \\delta\\zeta(t)$.\nLet $K(t) = K_{eq} + \\delta K(t) = K_0 + \\delta K(t)$.\n\nWe substitute these into the two differential equations and retain only terms that are first-order in the small perturbations $\\delta\\zeta$ and $\\delta K$.\n\nThe equation for $\\frac{dK}{dt}$ becomes:\n$$ \\frac{d(K_0 + \\delta K)}{dt} = -2(\\delta\\zeta)(K_0 + \\delta K) $$\n$$ \\frac{d(\\delta K)}{dt} = -2K_0 \\delta\\zeta - 2\\delta\\zeta \\delta K $$\nThe term $2\\delta\\zeta \\delta K$ is second-order and is neglected in the linearization. Thus, the first linearized equation is:\n$$ \\frac{d(\\delta K)}{dt} = -2K_0 \\delta\\zeta $$\n\nThe equation for $\\frac{d\\zeta}{dt}$ becomes:\n$$ \\frac{d(\\delta\\zeta)}{dt} = \\frac{1}{Q} \\left( 2(K_0 + \\delta K) - g k_\\mathrm{B} T \\right) $$\nSince $K_0 = \\frac{g}{2}k_\\mathrm{B}T$, it follows that $2K_0 - g k_\\mathrm{B} T = 0$.\n$$ \\frac{d(\\delta\\zeta)}{dt} = \\frac{1}{Q} (2\\delta K) $$\nThis equation is already linear, so it is our second linearized equation:\n$$ \\frac{d(\\delta\\zeta)}{dt} = \\frac{2}{Q} \\delta K $$\n\nWe now have a system of two coupled first-order linear differential equations for the perturbations $\\delta K$ and $\\delta\\zeta$:\n1.  $\\frac{d(\\delta K)}{dt} = -2K_0 \\delta\\zeta$\n2.  $\\frac{d(\\delta\\zeta)}{dt} = \\frac{2}{Q} \\delta K$\n\nTo find the oscillation frequency, we combine these into a single second-order equation. We differentiate the first equation with respect to time:\n$$ \\frac{d^2(\\delta K)}{dt^2} = -2K_0 \\frac{d(\\delta\\zeta)}{dt} $$\nNow, we substitute the second equation into this result:\n$$ \\frac{d^2(\\delta K)}{dt^2} = -2K_0 \\left( \\frac{2}{Q} \\delta K \\right) = -\\frac{4K_0}{Q} \\delta K $$\nRearranging gives the standard form of a simple harmonic oscillator equation:\n$$ \\frac{d^2(\\delta K)}{dt^2} + \\left( \\frac{4K_0}{Q} \\right) \\delta K = 0 $$\nThis equation is of the form $\\frac{d^2x}{dt^2} + \\omega^2 x = 0$, where $\\omega$ is the angular frequency. By comparison, we identify the squared angular frequency:\n$$ \\omega^2 = \\frac{4K_0}{Q} $$\nFinally, we substitute the definition of the equilibrium kinetic energy, $K_0 = \\frac{g}{2}k_\\mathrm{B}T$:\n$$ \\omega^2 = \\frac{4}{Q} \\left( \\frac{g}{2}k_\\mathrm{B}T \\right) = \\frac{2 g k_\\mathrm{B} T}{Q} $$\nThe angular frequency of the small-amplitude oscillations is therefore:\n$$ \\omega = \\sqrt{\\frac{2 g k_\\mathrm{B} T}{Q}} $$\nThis is the required formula. We will now apply it to the test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the small-amplitude oscillation frequency of a Nosé-Hoover thermostat.\n    \"\"\"\n    # Define physical constants.\n    # Boltzmann constant in J/K.\n    k_B = 1.380649e-23\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (g, T, Q)\n    # g: degrees of freedom (dimensionless)\n    # T: target temperature (K)\n    # Q: thermostat mass (J*s^2)\n    test_cases = [\n        # Case A\n        (300, 300, 1.2425841e-42),\n        # Case B\n        (300, 300, 1.2425841e-44),\n        # Case C\n        (300, 300, 1.2425841e-40),\n        # Case D\n        (3, 1000, 1.0e-45),\n    ]\n\n    results = []\n    for g, T, Q in test_cases:\n        # The derived formula for the angular frequency omega is:\n        # omega = sqrt(2 * g * k_B * T / Q)\n        \n        # Calculate the numerator of the term inside the square root.\n        numerator = 2 * g * k_B * T\n        \n        # Calculate the squared angular frequency.\n        omega_squared = numerator / Q\n        \n        # Calculate the angular frequency in rad/s.\n        omega = np.sqrt(omega_squared)\n        \n        results.append(omega)\n\n    # Format the results to six significant figures and join them into the final string.\n    # The \"{:.6g}\" format specifier rounds to 6 significant figures and uses scientific\n    # notation for large/small numbers, which is appropriate here.\n    formatted_results = [f\"{res:.6g}\" for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2466024"}, {"introduction": "The ultimate goal of a thermostat in a production simulation is to generate states that correctly sample the target statistical ensemble, most commonly the canonical (NVT) ensemble. This capstone exercise teaches you how to rigorously validate a thermostat's performance by comparing its output against theoretical predictions from statistical mechanics. By implementing a Chi-squared goodness-of-fit test, you will learn to statistically distinguish between a thermostat that produces the correct kinetic energy distribution (like Nosé-Hoover) and one that artificially suppresses fluctuations (like Berendsen), providing a definitive justification for choosing the appropriate algorithm for your research. [@problem_id:2466053]", "problem": "You are tasked with writing a complete, runnable program that validates whether a Molecular Dynamics (MD) thermostat yields the correct equilibrium kinetic energy fluctuations for a classical system. In the canonical ensemble at absolute temperature $T$ with $f$ quadratic degrees of freedom (DoF), the total kinetic energy $K$ of the system has a Maxwell–Boltzmann distribution that is exactly a Gamma distribution with shape parameter $f/2$ and scale parameter $k_{\\mathrm{B}} T$, which is equivalently expressed as $2K/(k_{\\mathrm{B}} T) \\sim \\chi^2_f$ where $k_{\\mathrm{B}}$ is the Boltzmann constant. Your program must implement a thermostat-validator that evaluates goodness-of-fit of a trajectory’s instantaneous total kinetic energy distribution against this theoretical Gamma distribution using the Chi-squared ($\\chi^2$) test.\n\nYour program must internally generate synthetic trajectories of instantaneous total kinetic energies $K_t$ in Joules for each test case in the suite below, using a fixed pseudo-random number generator seed to ensure reproducibility. Then, for each trajectory, it must perform a Chi-squared goodness-of-fit test against the null hypothesis that $K$ follows the Gamma distribution with shape $f/2$ and scale $k_{\\mathrm{B}}T_{\\text{target}}$. The test should use a significance level $\\alpha = 0.05$. The expected-bin construction must be as follows to ensure unambiguous evaluation:\n- Use exactly $k = \\max(8, \\min(30, \\lfloor n/10 \\rfloor))$ bins, where $n$ is the number of samples in the trajectory.\n- Define bin edges by the quantiles of the null cumulative distribution function so that each bin has equal probability $1/k$ under the null. Explicitly, if $Q(p)$ is the quantile function of $\\mathrm{Gamma}(f/2, k_{\\mathrm{B}}T_{\\text{target}})$, then the internal bin edges are $Q(i/k)$ for $i = 1,2,\\dots,k-1$, with the first edge at $0$ and the last edge at $+\\infty$. This ensures that the expected count in each bin is exactly $n/k$.\n- The Chi-squared statistic is $\\chi^2 = \\sum_{i=1}^{k} (O_i - E_i)^2/E_i$ with $E_i = n/k$ and $O_i$ the observed counts. The degrees of freedom for the $\\chi^2$ distribution are $k - 1$ because all parameters are specified a priori.\n\nA test is declared to “pass” if the null hypothesis is not rejected, that is, if the $p$-value is greater than or equal to $\\alpha$. Otherwise, it “fails.”\n\nBoltzmann’s constant must be taken as $k_{\\mathrm{B}} = 1.380649 \\times 10^{-23}\\ \\mathrm{J/K}$, and all generated kinetic energies must be in Joules. Random sampling must be performed using a fixed seed $s = 123456789$.\n\nSynthetic data generation models:\n- Canonical (Nosé–Hoover-like) data: draw $n$ independent samples from $\\mathrm{Gamma}(f/2, k_{\\mathrm{B}}T_{\\text{gen}})$, where $T_{\\text{gen}}$ is specified for the test case. This models a thermostat that correctly samples the canonical ensemble (Nosé–Hoover-like).\n- Underdispersed (Berendsen-like) data: first draw $n$ independent samples from $\\mathrm{Gamma}(f/2, k_{\\mathrm{B}}T_{\\text{target}})$, compute the mean $\\mu = (f/2) k_{\\mathrm{B}} T_{\\text{target}}$, then transform each sample $K$ to $K' = \\mu + \\sqrt{s}\\,(K - \\mu)$ with $0 < s < 1$, which preserves the mean but reduces the variance by a factor $s$, mimicking the fluctuation suppression characteristic of the Berendsen thermostat. The resulting $K'$ are the trajectory samples.\n\nYour program must run the Chi-squared test as specified for each of the following test cases (unit conventions: temperatures in Kelvin, energies in Joules):\n- Test case A (Nosé–Hoover-like, “happy path”): $f = 60$, $T_{\\text{target}} = 300$, $T_{\\text{gen}} = 300$, $n = 4000$, canonical generation.\n- Test case B (Berendsen-like underfluctuation): $f = 60$, $T_{\\text{target}} = 300$, $n = 4000$, underdispersed with $s = 0.5$.\n- Test case C (temperature mismatch): $f = 60$, $T_{\\text{target}} = 300$, $T_{\\text{gen}} = 360$, $n = 4000$, canonical generation at $T_{\\text{gen}}$.\n- Test case D (low DoF canonical): $f = 4$, $T_{\\text{target}} = 300$, $T_{\\text{gen}} = 300$, $n = 4000$, canonical generation.\n- Test case E (small-sample underfluctuation, edge case): $f = 60$, $T_{\\text{target}} = 300$, $n = 100$, underdispersed with $s = 0.2$.\n\nFor each test case, the program must output a boolean indicating whether the test “passes” (true means fail-to-reject the null, false means reject the null) at significance $\\alpha = 0.05$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., “[true,false,true]”), but using Python boolean literals, for example “[True,False,True,True,False]”, ordered as [A,B,C,D,E].", "solution": "The problem posed is to develop a computational procedure to validate whether a molecular dynamics thermostat correctly reproduces the canonical ensemble's kinetic energy distribution. This is a fundamental task in computational chemistry, as the choice of thermostat critically affects the statistical integrity of a simulation. The validation will be performed using a Chi-squared ($\\chi^2$) goodness-of-fit test on synthetically generated kinetic energy trajectories.\n\nThe theoretical foundation for this problem resides in classical statistical mechanics. For a system in the canonical ensemble (constant number of particles, volume, and temperature) at an absolute temperature $T$, the total kinetic energy, $K$, is not a constant but fluctuates. For a system with $f$ quadratic degrees of freedom, the probability distribution of $K$ is a Gamma distribution. The shape parameter of this distribution is $k = f/2$, and the scale parameter is $\\theta = k_{\\mathrm{B}} T$, where $k_{\\mathrm{B}}$ is the Boltzmann constant. The probability density function is given by:\n\n$$\nP(K; f, T) = \\frac{1}{\\Gamma(f/2) (k_{\\mathrm{B}} T)^{f/2}} K^{f/2 - 1} \\exp\\left(-\\frac{K}{k_{\\mathrm{B}} T}\\right)\n$$\n\nThis distribution, $\\mathrm{Gamma}(f/2, k_{\\mathrm{B}}T)$, is the target for any thermostat aiming to generate a correct canonical ensemble. Thermostats like the Nosé–Hoover are designed to produce this distribution, whereas simpler algorithms like the Berendsen thermostat are known to generate distributions with the correct mean kinetic energy, but with suppressed fluctuations (i.e., a variance smaller than the theoretical value of $(f/2)(k_{\\mathrm{B}}T)^2$).\n\nThe core of the task is to implement the $\\chi^2$ goodness-of-fit test to evaluate the null hypothesis, $H_0$, which states that a given kinetic energy trajectory $\\{K_t\\}$ is sampled from the theoretical $\\mathrm{Gamma}(f/2, k_{\\mathrm{B}}T_{\\text{target}})$ distribution. The test is performed at a significance level of $\\alpha = 0.05$.\n\nThe procedure is as follows:\n\n1.  **Data Generation**: For each test case, we generate a synthetic trajectory of $n$ kinetic energy values. The problem defines two generation models:\n    *   **Canonical (Nosé–Hoover-like)**: Samples are drawn directly from a $\\mathrm{Gamma}(f/2, k_{\\mathrm{B}}T_{\\text{gen}})$ distribution. If $T_{\\text{gen}} = T_{\\text{target}}$, this represents a correctly functioning thermostat.\n    *   **Underdispersed (Berendsen-like)**: Samples $K$ are first drawn from the target distribution $\\mathrm{Gamma}(f/2, k_{\\mathrm{B}}T_{\\text{target}})$. They are then transformed via $K' = \\mu + \\sqrt{s}\\,(K - \\mu)$, where $\\mu = (f/2)k_{\\mathrm{B}}T_{\\text{target}}$ is the theoretical mean energy and $0 < s < 1$. This transformation preserves the mean but reduces the variance by a factor of $s$, mimicking the behavior of a Berendsen thermostat.\n\n2.  **Binning**: The kinetic energy data must be binned to compare observed frequencies with expected frequencies. A critical and unambiguous binning strategy is specified. The number of bins, $k_{bins}$, is determined by the sample size $n$ as $k_{bins} = \\max(8, \\min(30, \\lfloor n/10 \\rfloor))$. The bin edges are chosen to give each bin equal probability under the null hypothesis. This is achieved by using the quantile function (the inverse of the cumulative distribution function, CDF), $Q(p)$, of the null distribution, $\\mathrm{Gamma}(f/2, k_{\\mathrm{B}}T_{\\text{target}})$. The bin edges are set at $Q(i/k_{bins})$ for $i = 0, 1, \\dots, k_{bins}$. The first edge is $Q(0) = 0$ and the last is $Q(1) = +\\infty$.\n\n3.  **Frequency Analysis**: With this binning scheme, the expected count in each bin is identical: $E_i = n/k_{bins}$. The observed counts, $O_i$, are found by counting how many data points fall into each bin.\n\n4.  **$\\chi^2$ Statistic Calculation**: The $\\chi^2$ statistic is computed as the sum of squared, normalized differences between observed and expected counts:\n    $$\n    \\chi^2 = \\sum_{i=1}^{k_{bins}} \\frac{(O_i - E_i)^2}{E_i}\n    $$\n\n5.  **Hypothesis Testing**: The calculated $\\chi^2$ value is compared against the theoretical $\\chi^2$ distribution. Since all parameters of the null distribution ($f$ and $T_{\\text{target}}$) are specified beforehand and not estimated from the data, the number of degrees of freedom for the test is $\\nu = k_{bins} - 1$. The $p$-value is the probability of obtaining a $\\chi^2$ statistic at least as extreme as the one observed, assuming $H_0$ is true.\n\n6.  **Decision**: The null hypothesis is rejected if the $p$-value is less than the significance level $\\alpha = 0.05$. In this problem's terminology, rejection corresponds to a \"fail\" (output `False`). If the $p$-value is greater than or equal to $\\alpha$, we fail to reject the null hypothesis, which corresponds to a \"pass\" (output `True`).\n\nThe implementation will use a fixed random seed, $s_{seed} = 123456789$, to ensure reproducibility. The Boltzmann constant is taken as $k_{\\mathrm{B}} = 1.380649 \\times 10^{-23}\\ \\mathrm{J/K}$. Numerical computations will rely on `numpy` for data handling and random number generation, and `scipy.stats` for statistical functions related to the Gamma and $\\chi^2$ distributions.\n\nLet us analyze the test cases:\n*   **Case A**: Canonical generation with $T_{\\text{gen}} = T_{\\text{target}} = 300\\ \\mathrm{K}$. $H_0$ is true. We expect a \"pass\" (`True`).\n*   **Case B**: Underdispersed generation with $s=0.5$. The variance is incorrect. $H_0$ is false. We expect a \"fail\" (`False`).\n*   **Case C**: Canonical generation with $T_{\\text{gen}} = 360\\ \\mathrm{K}$ and $T_{\\text{target}} = 300\\ \\mathrm{K}$. The mean and variance are incorrect. $H_0$ is false. We expect a \"fail\" (`False`).\n*   **Case D**: Canonical generation with low DoF, $f=4$. $H_0$ is true. We expect a \"pass\" (`True`).\n*   **Case E**: Underdispersed generation with small sample size $n=100$ and strong suppression $s=0.2$. $H_0$ is false. The small sample size reduces test power, but the deviation is large. We still expect a \"fail\" (`False`).\n\nThe final program will execute these five tests and report the boolean outcomes in the specified format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Validates thermostat kinetic energy distributions using the Chi-squared test.\n    \"\"\"\n    # Define constants and test parameters\n    K_B = 1.380649e-23  # Boltzmann constant in J/K\n    ALPHA = 0.05        # Significance level\n    SEED = 123456789    # Fixed seed for reproducibility\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Canonical (Nosé-Hoover-like), correct temperature\n        {'name': 'A', 'f': 60, 'T_target': 300, 'n': 4000, 'type': 'canonical', 'T_gen': 300},\n        # Case B: Underdispersed (Berendsen-like)\n        {'name': 'B', 'f': 60, 'T_target': 300, 'n': 4000, 'type': 'underdispersed', 's': 0.5},\n        # Case C: Canonical, temperature mismatch\n        {'name': 'C', 'f': 60, 'T_target': 300, 'n': 4000, 'type': 'canonical', 'T_gen': 360},\n        # Case D: Canonical, low degrees of freedom\n        {'name': 'D', 'f': 4, 'T_target': 300, 'n': 4000, 'type': 'canonical', 'T_gen': 300},\n        # Case E: Underdispersed, small sample, strong suppression\n        {'name': 'E', 'f': 60, 'T_target': 300, 'n': 100, 'type': 'underdispersed', 's': 0.2},\n    ]\n\n    results = []\n    rng = np.random.default_rng(SEED)\n\n    for case in test_cases:\n        f = case['f']\n        T_target = case['T_target']\n        n = case['n']\n\n        # Generate synthetic kinetic energy data\n        shape_param = f / 2.0\n        \n        if case['type'] == 'canonical':\n            T_gen = case['T_gen']\n            scale_param_gen = K_B * T_gen\n            kinetic_energies = rng.gamma(shape=shape_param, scale=scale_param_gen, size=n)\n        \n        elif case['type'] == 'underdispersed':\n            s_factor = case['s']\n            scale_param_target = K_B * T_target\n            # First, draw from the correct distribution\n            K = rng.gamma(shape=shape_param, scale=scale_param_target, size=n)\n            # Then, transform to reduce variance\n            mean_K = shape_param * scale_param_target\n            kinetic_energies = mean_K + np.sqrt(s_factor) * (K - mean_K)\n        \n        # Perform Chi-squared goodness-of-fit test\n\n        # 1. Determine number of bins\n        k_bins = int(max(8, min(30, n / 10)))\n\n        # 2. Define the null hypothesis distribution\n        scale_param_null = K_B * T_target\n        null_dist = stats.gamma(a=shape_param, scale=scale_param_null)\n\n        # 3. Define bin edges for equal probability under the null hypothesis\n        quantiles = np.linspace(0, 1, k_bins + 1)\n        bin_edges = null_dist.ppf(quantiles)\n\n        # 4. Calculate observed frequencies\n        observed_counts, _ = np.histogram(kinetic_energies, bins=bin_edges)\n\n        # 5. Calculate expected frequencies\n        expected_count = n / k_bins\n\n        # 6. Compute the Chi-squared statistic\n        # The np.sum is over an array that may contain zeros, which is fine.\n        # Python's default division by zero handling raises an error, but here\n        # the denominator `expected_count` is never zero.\n        chi2_statistic = np.sum((observed_counts - expected_count)**2 / expected_count)\n        \n        # 7. Determine degrees of freedom for the test\n        dof = k_bins - 1\n        \n        # 8. Calculate the p-value\n        # p-value is the survival function (1 - CDF) of the chi-squared distribution\n        p_value = stats.chi2.sf(chi2_statistic, df=dof)\n        \n        # 9. Make decision based on significance level\n        # \"pass\" if we fail to reject the null hypothesis (p-value >= alpha)\n        test_passes = p_value >= ALPHA\n        results.append(test_passes)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2466053"}]}