{"hands_on_practices": [{"introduction": "The efficiency of a Replica Exchange Molecular Dynamics simulation is critically dependent on the acceptance probability of swaps between adjacent temperatures. This exercise will guide you through the fundamental calculation of this probability ([@problem_id:2666608]). By using a common and powerful simplification—the Gaussian approximation for energy distributions—you will connect the statistical properties of your system, such as mean energy and variance, directly to the expected success rate of replica exchanges.", "problem": "In Replica Exchange Molecular Dynamics (REMD), two replicas at inverse temperatures $\\beta_1$ and $\\beta_2$ attempt a swap of temperatures with Metropolis acceptance probability given by $\\min\\!\\left(1,\\exp\\!\\left((\\beta_1-\\beta_2)\\,(E_1-E_2)\\right)\\right)$, where $E_1$ and $E_2$ are the instantaneous potential energies sampled independently from the canonical ensembles at temperatures $T_1$ and $T_2$. Consider two adjacent temperatures $T_1=300\\ \\mathrm{K}$ and $T_2=330\\ \\mathrm{K}$. Suppose the measured energy statistics at these temperatures (energies expressed per mole) are approximately Gaussian with means $\\mu_1=-500.0\\ \\mathrm{kJ\\,mol^{-1}}$ and $\\mu_2=-440.0\\ \\mathrm{kJ\\,mol^{-1}}$, and variances $\\sigma_1^2=1496.6033\\ \\mathrm{kJ^2\\,mol^{-2}}$ and $\\sigma_2^2=1810.8900\\ \\mathrm{kJ^2\\,mol^{-2}}$. Assume the two energy samples are independent and that the Gaussian approximation for the canonical energy distribution is valid.\n\nStarting only from the canonical ensemble definition, the Metropolis acceptance criterion for exchanges, and the independence and Gaussian assumptions stated above, derive an analytic expression for the expected swap acceptance probability under these conditions and evaluate it numerically. Use the gas constant $R=0.008314462618\\ \\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$ so that $\\beta_i = 1/(R T_i)$ is consistent with the per-mole energy units. Round your final expected acceptance probability to four significant figures. Express the final answer as a pure number (no units).", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. All necessary data and well-defined assumptions are provided. It represents a standard calculation in the analysis of Replica Exchange Molecular Dynamics simulations. Therefore, the problem is valid, and a solution will be provided.\n\nThe objective is to compute the expected value of the Metropolis acceptance probability, $\\langle P_{\\text{acc}} \\rangle$, for a swap between two replicas at inverse temperatures $\\beta_1$ and $\\beta_2$. The acceptance probability is given by\n$$\nP_{\\text{acc}}(E_1, E_2) = \\min\\!\\left(1, \\exp\\!\\left((\\beta_1-\\beta_2)(E_1-E_2)\\right)\\right)\n$$\nwhere $E_1$ and $E_2$ are the potential energies of the replicas. These are random variables drawn independently from their respective canonical ensembles. The problem states that these energy distributions are approximated as Gaussian: $E_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2)$ and $E_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2^2)$.\n\nLet us define the difference in inverse temperature $\\Delta\\beta = \\beta_1 - \\beta_2$ and the difference in energy $\\Delta E = E_1 - E_2$. The acceptance probability simplifies to $P_{\\text{acc}}(\\Delta E) = \\min(1, \\exp(\\Delta\\beta \\Delta E))$. Since $E_1$ and $E_2$ are independent Gaussian random variables, their difference, $\\Delta E$, is also a Gaussian random variable. Its distribution is $\\Delta E \\sim \\mathcal{N}(\\mu_{\\Delta}, \\sigma_{\\Delta}^2)$, with parameters:\nMean: $\\mu_{\\Delta} = \\mathbb{E}[E_1 - E_2] = \\mathbb{E}[E_1] - \\mathbb{E}[E_2] = \\mu_1 - \\mu_2$.\nVariance: $\\sigma_{\\Delta}^2 = \\text{Var}(E_1 - E_2) = \\text{Var}(E_1) + \\text{Var}(-E_2) = \\text{Var}(E_1) + (-1)^2\\text{Var}(E_2) = \\sigma_1^2 + \\sigma_2^2$.\n\nThe expected acceptance probability is found by integrating over the probability distribution of $\\Delta E$, which we denote by $p_{\\Delta}(x)$:\n$$\n\\langle P_{\\text{acc}} \\rangle = \\mathbb{E}[P_{\\text{acc}}(\\Delta E)] = \\int_{-\\infty}^{\\infty} \\min(1, \\exp(\\Delta\\beta x)) p_{\\Delta}(x) dx\n$$\nwhere $p_{\\Delta}(x) = \\frac{1}{\\sqrt{2\\pi\\sigma_{\\Delta}^2}} \\exp\\left(-\\frac{(x - \\mu_{\\Delta})^2}{2\\sigma_{\\Delta}^2}\\right)$.\n\nGiven $T_1 = 300\\ \\mathrm{K}$ and $T_2 = 330\\ \\mathrm{K}$, we have $T_1  T_2$, which implies $\\beta_1 = 1/(RT_1)  1/(RT_2) = \\beta_2$. Thus, $\\Delta\\beta  0$. This allows us to split the integral based on the sign of the argument of the exponential, $x = \\Delta E$:\n- If $x  0$, then $\\Delta\\beta x  0$, so $\\exp(\\Delta\\beta x)  1$, and $\\min(1, \\exp(\\Delta\\beta x)) = 1$.\n- If $x \\le 0$, then $\\Delta\\beta x \\le 0$, so $\\exp(\\Delta\\beta x) \\le 1$, and $\\min(1, \\exp(\\Delta\\beta x)) = \\exp(\\Delta\\beta x)$.\n\nThe expectation integral is therefore split into two parts:\n$$\n\\langle P_{\\text{acc}} \\rangle = \\int_{0}^{\\infty} 1 \\cdot p_{\\Delta}(x) dx + \\int_{-\\infty}^{0} \\exp(\\Delta\\beta x) p_{\\Delta}(x) dx\n$$\nThe first integral is the probability that $\\Delta E  0$, which can be expressed using the cumulative distribution function (CDF) of the standard normal distribution, $\\Phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^z \\exp(-t^2/2) dt$.\n$$\n\\int_{0}^{\\infty} p_{\\Delta}(x) dx = P(\\Delta E  0) = 1 - P(\\Delta E \\le 0) = 1 - \\Phi\\left(\\frac{0 - \\mu_{\\Delta}}{\\sigma_{\\Delta}}\\right) = 1 - \\Phi\\left(-\\frac{\\mu_{\\Delta}}{\\sigma_{\\Delta}}\\right) = \\Phi\\left(\\frac{\\mu_{\\Delta}}{\\sigma_{\\Delta}}\\right)\n$$\nThe second integral requires us to combine the exponential terms in the integrand:\n$$\n\\int_{-\\infty}^{0} \\exp(\\Delta\\beta x) \\frac{1}{\\sqrt{2\\pi\\sigma_{\\Delta}^2}} \\exp\\left(-\\frac{(x - \\mu_{\\Delta})^2}{2\\sigma_{\\Delta}^2}\\right) dx\n$$\nThe argument of the total exponential is $\\Delta\\beta x - \\frac{(x - \\mu_{\\Delta})^2}{2\\sigma_{\\Delta}^2}$. We complete the square with respect to $x$:\n$$\n-\\frac{1}{2\\sigma_{\\Delta}^2} [x^2 - 2x\\mu_{\\Delta} + \\mu_{\\Delta}^2 - 2\\sigma_{\\Delta}^2\\Delta\\beta x] = -\\frac{1}{2\\sigma_{\\Delta}^2} [x^2 - 2x(\\mu_{\\Delta} + \\sigma_{\\Delta}^2\\Delta\\beta) + \\mu_{\\Delta}^2]\n$$\nLet $\\mu' = \\mu_{\\Delta} + \\sigma_{\\Delta}^2\\Delta\\beta$. The term in the brackets is rewritten as:\n$$\n[x - \\mu']^2 - (\\mu')^2 + \\mu_{\\Delta}^2 = [x - \\mu']^2 - (\\mu_{\\Delta}^2 + 2\\mu_{\\Delta}\\sigma_{\\Delta}^2\\Delta\\beta + (\\sigma_{\\Delta}^2\\Delta\\beta)^2) + \\mu_{\\Delta}^2 = [x - \\mu']^2 - 2\\mu_{\\Delta}\\sigma_{\\Delta}^2\\Delta\\beta - \\sigma_{\\Delta}^4(\\Delta\\beta)^2\n$$\nThe exponent becomes:\n$$\n-\\frac{(x - \\mu')^2}{2\\sigma_{\\Delta}^2} + \\frac{2\\mu_{\\Delta}\\sigma_{\\Delta}^2\\Delta\\beta + \\sigma_{\\Delta}^4(\\Delta\\beta)^2}{2\\sigma_{\\Delta}^2} = -\\frac{(x - \\mu')^2}{2\\sigma_{\\Delta}^2} + \\mu_{\\Delta}\\Delta\\beta + \\frac{\\sigma_{\\Delta}^2(\\Delta\\beta)^2}{2}\n$$\nThe second integral is now:\n$$\n\\int_{-\\infty}^{0} \\exp\\left(\\mu_{\\Delta}\\Delta\\beta + \\frac{\\sigma_{\\Delta}^2(\\Delta\\beta)^2}{2}\\right) \\frac{1}{\\sqrt{2\\pi\\sigma_{\\Delta}^2}} \\exp\\left(-\\frac{(x - \\mu')^2}{2\\sigma_{\\Delta}^2}\\right) dx\n$$\nThe constant exponential factor can be moved outside the integral. The remaining integral is the probability $P(X' \\le 0)$ for a Gaussian variable $X' \\sim \\mathcal{N}(\\mu', \\sigma_{\\Delta}^2)$.\n$$\nP(X' \\le 0) = \\Phi\\left(\\frac{0 - \\mu'}{\\sigma_{\\Delta}}\\right) = \\Phi\\left(-\\frac{\\mu_{\\Delta} + \\sigma_{\\Delta}^2\\Delta\\beta}{\\sigma_{\\Delta}}\\right)\n$$\nCombining all parts, the final analytic expression is:\n$$\n\\langle P_{\\text{acc}} \\rangle = \\Phi\\left(\\frac{\\mu_{\\Delta}}{\\sigma_{\\Delta}}\\right) + \\exp\\left(\\mu_{\\Delta}\\Delta\\beta + \\frac{\\sigma_{\\Delta}^2(\\Delta\\beta)^2}{2}\\right) \\Phi\\left(-\\frac{\\mu_{\\Delta} + \\sigma_{\\Delta}^2\\Delta\\beta}{\\sigma_{\\Delta}}\\right)\n$$\nNow, we substitute the given numerical values.\n$R = 0.008314462618\\ \\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$.\nTemperatures: $T_1 = 300\\ \\mathrm{K}$, $T_2 = 330\\ \\mathrm{K}$.\n$\\Delta\\beta = \\frac{1}{R}\\left(\\frac{1}{T_1} - \\frac{1}{T_2}\\right) = \\frac{1}{0.008314462618}\\left(\\frac{1}{300} - \\frac{1}{330}\\right) = \\frac{1}{0.008314462618}\\left(\\frac{30}{99000}\\right) \\approx 0.036446164\\ (\\mathrm{kJ\\,mol^{-1}})^{-1}$.\n\nEnergy statistics:\n$\\mu_1 = -500.0\\ \\mathrm{kJ\\,mol^{-1}}$, $\\mu_2 = -440.0\\ \\mathrm{kJ\\,mol^{-1}}$.\n$\\sigma_1^2 = 1496.6033\\ \\mathrm{kJ^2\\,mol^{-2}}$, $\\sigma_2^2 = 1810.8900\\ \\mathrm{kJ^2\\,mol^{-2}}$.\n\nParameters for the $\\Delta E$ distribution:\n$\\mu_{\\Delta} = \\mu_1 - \\mu_2 = -500.0 - (-440.0) = -60.0\\ \\mathrm{kJ\\,mol^{-1}}$.\n$\\sigma_{\\Delta}^2 = \\sigma_1^2 + \\sigma_2^2 = 1496.6033 + 1810.8900 = 3307.4933\\ \\mathrm{kJ^2\\,mol^{-2}}$.\n$\\sigma_{\\Delta} = \\sqrt{3307.4933} \\approx 57.5108085\\ \\mathrm{kJ\\,mol^{-1}}$.\n\nWe calculate the arguments for the functions in the analytic expression:\nArgument of the first $\\Phi$: $\\frac{\\mu_{\\Delta}}{\\sigma_{\\Delta}} = \\frac{-60.0}{57.5108085} \\approx -1.043282$.\n$\\Phi(-1.043282) \\approx 0.14841$.\n\nExponent of the exponential term: $\\mu_{\\Delta}\\Delta\\beta + \\frac{\\sigma_{\\Delta}^2(\\Delta\\beta)^2}{2}$\nTerm 1: $\\mu_{\\Delta}\\Delta\\beta = -60.0 \\times 0.036446164 \\approx -2.186770$.\nTerm 2: $\\frac{\\sigma_{\\Delta}^2(\\Delta\\beta)^2}{2} = \\frac{3307.4933 \\times (0.036446164)^2}{2} \\approx \\frac{4.393433}{2} = 2.196717$.\nExponent = $-2.186770 + 2.196717 = 0.009947$.\n$\\exp(0.009947) \\approx 1.009996$.\n\nArgument of the second $\\Phi$: $-\\frac{\\mu_{\\Delta} + \\sigma_{\\Delta}^2\\Delta\\beta}{\\sigma_{\\Delta}}$\n$\\sigma_{\\Delta}^2\\Delta\\beta = 3307.4933 \\times 0.036446164 \\approx 120.5483$.\nArgument $= -\\frac{-60.0 + 120.5483}{57.5108085} = -\\frac{60.5483}{57.5108085} \\approx -1.052816$.\n$\\Phi(-1.052816) \\approx 0.14620$.\n\nFinally, we compute $\\langle P_{\\text{acc}} \\rangle$:\n$\\langle P_{\\text{acc}} \\rangle \\approx 0.14841 + (1.009996) \\times (0.14620) \\approx 0.14841 + 0.147661 \\approx 0.296071$.\n\nRounding to four significant figures, the result is $0.2961$.", "answer": "$$\n\\boxed{0.2961}\n$$", "id": "2666608"}, {"introduction": "Beyond theoretical calculations, a crucial skill for any computational scientist is the ability to diagnose problems in a simulation. This next exercise presents a hypothetical yet plausible scenario: an implementation error where velocities are not correctly handled after a temperature swap ([@problem_id:2461603]). By thinking through the consequences, you will develop a deeper intuition for how different components of the REMD algorithm—the thermostat and the exchange criterion—work together and how their failure manifests in the simulation data.", "problem": "In Replica Exchange Molecular Dynamics (REMD), a set of replicas of the same system are simulated at different temperatures using independent thermostats that, when used alone, would sample the canonical (constant number of particles, volume, and temperature) distribution at their assigned temperature. Consider two replicas with inverse temperatures $\\,\\beta_i\\,$ and $\\,\\beta_j\\,$ that undergo a successful temperature exchange according to the standard REMD exchange rule. Immediately after the swap, a researcher forgets to re-initialize or rescale the particle velocities to be consistent with the new temperatures; that is, each replica continues with the same velocities it had just before the swap, but now under the other temperature’s thermostat. Assume that subsequent time evolution within each replica is performed by a thermostat that has the canonical distribution at its assigned temperature as an invariant measure, and that exchanges are attempted intermittently with the usual REMD proposal that swaps temperatures between replicas.\n\nWhich statement best describes the long-term consequences of this mistake for the stationary ensemble and for sampling efficiency?\n\nA. The stationary configurational distribution remains correct for each temperature because the canonical measure factorizes and the thermostat restores the momentum distribution; however, short-term kinetic mismatches after swaps cause additional relaxation that reduces mixing efficiency across temperatures, even though exchange acceptances are unaffected in the long run.\n\nB. Detailed balance for configurations is violated, so the stationary distribution of potential energies at each temperature becomes permanently biased away from the canonical distribution.\n\nC. The average kinetic energy in each replica remains at its pre-swap value indefinitely, so temperature exchange ceases to provide any benefit and the replicas effectively remain at fixed temperatures.\n\nD. Only the kinetic energy histogram is biased at steady state, while configurational sampling and diffusion in temperature space are unaffected in both the short and long term.", "solution": "The problem statement describes a common scenario in Replica Exchange Molecular Dynamics (REMD) where a procedural error is made. We must validate the problem statement before proceeding to a solution.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   **Method**: Replica Exchange Molecular Dynamics (REMD).\n-   **System**: A set of replicas of the same system simulated at different temperatures.\n-   **Thermostats**: Independent thermostats are used for each replica. When used alone, a thermostat samples the canonical (NVT) distribution for its assigned temperature.\n-   **Exchange Event**: Two replicas with inverse temperatures $\\beta_i$ and $\\beta_j$ undergo a successful temperature exchange based on the standard REMD rule.\n-   **Procedural Error**: After the swap, the particle velocities are not rescaled. Each replica's coordinates and velocities $(q, p)$ continue to evolve, but now under the thermostat of the *other* temperature.\n-   **Assumption 1**: The thermostat used for intra-replica dynamics has the canonical distribution at its assigned temperature as an invariant measure.\n-   **Assumption 2**: Exchanges are attempted intermittently using the standard REMD proposal.\n-   **Question**: What are the long-term consequences of this error for the stationary ensemble and for sampling efficiency?\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding**: The problem is well-grounded in the principles of statistical mechanics and computational chemistry. REMD, thermostats, canonical ensembles, and velocity rescaling are all standard concepts. The described error is a plausible implementation mistake.\n-   **Well-Posed**: The question is specific and asks for the consequences on well-defined quantities (stationary distribution, sampling efficiency). A unique answer can be derived from first principles.\n-   **Objective**: The language is technical and precise.\n-   **Completeness**: The problem provides the necessary information: the nature of the algorithm (REMD), the properties of its components (thermostats), and the specific nature of the error.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. It is scientifically sound, well-posed, and contains sufficient information to derive a logical conclusion. We may proceed with the solution.\n\n### Derivation of the Correct Answer\n\nThe state of the extended ensemble in REMD is described by the set of replica coordinates $\\{q_k\\}$ and the permutation of temperatures $\\{\\beta_k\\}$ across the replicas. The target stationary distribution for the configurations and temperatures is given by:\n$$\n\\mathcal{P}(\\{q_k\\}, \\{\\beta_k\\}) \\propto \\exp\\left(-\\sum_{k=1}^{N} \\beta_k U(q_k)\\right)\n$$\nwhere $N$ is the number of replicas, $U(q_k)$ is the potential energy of the configuration of replica $k$, and $\\beta_k$ is the inverse temperature assigned to that replica. Note that the momenta do not appear in this expression for the configurational ensemble.\n\nThe REMD algorithm consists of two main steps:\n1.  **Intra-replica dynamics**: Each replica evolves for a certain number of steps at its currently assigned temperature.\n2.  **Inter-replica exchange**: A swap of temperatures between two replicas, say $i$ and $j$, is attempted.\n\nLet's analyze the effect of the procedural error on both the stationary distribution and the efficiency.\n\n**1. Stationary Distribution**\n\nThe correctness of the stationary distribution depends on whether the dynamics satisfy detailed balance with respect to the target distribution $\\mathcal{P}$.\n\n-   **The Exchange Step**: The standard REMD exchange rule for swapping the temperatures of replicas $i$ and $j$ (which is equivalent to swapping their configurations) uses the Metropolis-Hastings acceptance probability:\n    $$\n    P_{\\text{accept}} = \\min\\left(1, \\exp\\left[-(\\beta_j - \\beta_i)(U(q_j) - U(q_i))\\right]\\right) = \\min\\left(1, \\exp\\left[(\\beta_i - \\beta_j)(U(q_i) - U(q_j))\\right]\\right)\n    $$\n    This acceptance probability depends **only** on the potential energies $U(q_i)$ and $U(q_j)$ of the configurations being exchanged and their respective inverse temperatures $\\beta_i$ and $\\beta_j$. It does not depend on the kinetic energies or momenta of the particles. Since this rule is preserved in the scenario described, the exchange move itself continues to satisfy detailed balance for the *configurational part of the extended ensemble*.\n\n-   **The Intra-replica Dynamics Step**: Between exchanges, each replica evolves under a thermostat. The problem states that this thermostat \"has the canonical distribution at its assigned temperature as an invariant measure.\" This is a crucial statement. It means that, for a given temperature $T_k$, the dynamics generated by the thermostat will, over a sufficiently long time, produce configurations $q$ and momenta $p$ according to the canonical distribution $\\rho(q, p) \\propto \\exp(-\\beta_k [K(p) + U(q)])$, where $K(p)$ is the kinetic energy. By integrating out the momenta, it follows that these dynamics will also correctly sample the marginal configurational distribution $P(q) \\propto \\exp(-\\beta_k U(q))$.\n\n-   **Conclusion on the Stationary Distribution**: Both components of the algorithm (exchanges and intra-replica dynamics) are constructed to eventually sample the correct configurational distribution. The exchange mechanism ensures that configurations are correctly distributed among the different temperatures, and the intra-replica dynamics ensure that the configuration space at a given temperature is explored correctly. The error concerning velocities does not alter the formal correctness of the target stationary distribution because the exchange criterion is independent of velocity. Therefore, the long-term stationary distribution of configurations, and consequently potential energies, remains correct. Similarly, the thermostat's function guarantees that the long-term, time-averaged kinetic energy distribution at each temperature will also be correct.\n\n**2. Sampling Efficiency**\n\nWhile the stationary distribution is formally correct, the *rate* at which this distribution is sampled is affected.\n\n-   **Kinetic Energy Mismatch**: After a successful swap, a replica's state is $(q_k, p_k)$ but it is now coupled to a new temperature $T'_k$. The momenta $p_k$ were drawn from a distribution corresponding to the old temperature $T_k$. Thus, the kinetic energy $K(p_k)$ does not match the expectation for the new temperature $T'_k$. The system is kinetically out of equilibrium.\n\n-   **Thermostat Relaxation**: The thermostat must now work to restore the kinetic energy to its proper equilibrium value for temperature $T'_k$. This process of thermal relaxation is not instantaneous and takes a finite amount of time, which depends on the coupling strength of the thermostat.\n\n-   **Reduced Efficiency**: During this relaxation period, the system's dynamics are not representative of true canonical sampling at temperature $T'_k$. For instance, if a replica moves from a high temperature to a low one, its \"hot\" velocities will cause it to move in a manner uncharacteristic of the low temperature until the thermostat cools it down. This time spent on kinetic energy equilibration is time not spent on efficient conformational sampling. This additional overhead, incurred after every successful swap, reduces the overall efficiency of the REMD simulation. It slows down the diffusion of replicas through temperature space, which is the very essence of REMD's power to enhance sampling.\n\n-   **Exchange Acceptance Rate**: The long-term average acceptance rate depends on the overlap between the potential energy distributions, $P(U|T_i)$ and $P(U|T_j)$. Since the stationary potential energy distributions are ultimately correct, the long-term average acceptance rate will be unaffected by the velocity-rescaling error.\n\n### Option-by-Option Analysis\n\n**A. The stationary configurational distribution remains correct for each temperature because the canonical measure factorizes and the thermostat restores the momentum distribution; however, short-term kinetic mismatches after swaps cause additional relaxation that reduces mixing efficiency across temperatures, even though exchange acceptances are unaffected in the long run.**\n-   `stationary configurational distribution remains correct`: **Correct**. As derived above, the exchange rule is independent of momenta.\n-   `because the canonical measure factorizes and the thermostat restores the momentum distribution`: This gives the correct physical reasoning. The separation of kinetic and potential energy in the Hamiltonian is key, and the thermostat handles the kinetic part.\n-   `short-term kinetic mismatches ... cause additional relaxation`: **Correct**. This is the immediate consequence of not rescaling velocities.\n-   `reduces mixing efficiency across temperatures`: **Correct**. The relaxation time impedes the random walk in temperature space.\n-   `exchange acceptances are unaffected in the long run`: **Correct**. This depends on the stationary potential energy histograms, which remain correct.\nThis option accurately and completely describes all consequences.\n**Verdict: Correct.**\n\n**B. Detailed balance for configurations is violated, so the stationary distribution of potential energies at each temperature becomes permanently biased away from the canonical distribution.**\n-   `Detailed balance for configurations is violated`: **Incorrect**. The Metropolis rule for exchanges depends only on potential energy, and this rule satisfies detailed balance for the configurational ensemble by construction. The error happens after the acceptance/rejection step and does not alter the rule itself.\n-   `stationary distribution ... becomes permanently biased`: **Incorrect**. This is a false consequence of a false premise.\n**Verdict: Incorrect.**\n\n**C. The average kinetic energy in each replica remains at its pre-swap value indefinitely, so temperature exchange ceases to provide any benefit and the replicas effectively remain at fixed temperatures.**\n-   `average kinetic energy ... remains at its pre-swap value indefinitely`: **Incorrect**. This contradicts the stated function of a thermostat, which is to enforce the target temperature by adjusting kinetic energy.\n-   `temperature exchange ceases to provide any benefit`: **Incorrect**. The benefit (enhanced sampling) is reduced in efficiency, not eliminated. Exchanges still occur.\n**Verdict: Incorrect.**\n\n**D. Only the kinetic energy histogram is biased at steady state, while configurational sampling and diffusion in temperature space are unaffected in both the short and long term.**\n-   `Only the kinetic energy histogram is biased at steady state`: **Incorrect**. At steady state (long-term average), the thermostat ensures the kinetic energy distribution is correct. There are transient deviations, but no permanent bias.\n-   `diffusion in temperature space are unaffected`: **Incorrect**. The diffusion (mixing efficiency) is demonstrably reduced due to the relaxation overhead following each swap.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "2461603"}, {"introduction": "This capstone practice moves you from analysis to design, tasking you with creating an entire algorithm to generate an optimal, non-uniform temperature ladder for a system with complex energetic features ([@problem_id:2461552]). Achieving a constant acceptance rate across all temperatures requires denser replica placement in regions where the system's heat capacity, $C_v(T)$, is high. This is a highly practical skill that directly translates to setting up efficient and effective REMD simulations for real-world research problems.", "problem": "A canonical-ensemble model of a molecular system exhibits two pronounced activation regions at $310\\,\\mathrm{K}$ and $450\\,\\mathrm{K}$. The goal is to design an optimal, non-uniform temperature ladder for Replica Exchange Molecular Dynamics (REMD) that spans a specified temperature interval and ensures that nearest-neighbor replica exchange meets a prescribed expected acceptance criterion.\n\nModeling assumptions and definitions to be used for this problem:\n- Work in reduced units where the Boltzmann constant satisfies $k_{\\mathrm{B}} = 1$. Report all temperatures in $\\mathrm{K}$.\n- The constant-volume heat capacity as a function of temperature is prescribed by\n$$\nC_{v}(T) = c_{0} + A_{1}\\exp\\!\\left(-\\tfrac{1}{2}\\left(\\tfrac{T - 310}{w_{1}}\\right)^{2}\\right) + A_{2}\\exp\\!\\left(-\\tfrac{1}{2}\\left(\\tfrac{T - 450}{w_{2}}\\right)^{2}\\right),\n$$\nwith constants $c_{0} = 100$, $A_{1} = 200$, $w_{1} = 8$, $A_{2} = 150$, $w_{2} = 10$. In these reduced units, $C_{v}(T)$ is dimensionless.\n- For a replica at temperature $T$, the canonical energy fluctuations are modeled as Gaussian with variance\n$$\n\\sigma^{2}(T) = k_{\\mathrm{B}}\\,C_{v}(T)\\,T^{2} = C_{v}(T)\\,T^{2}.\n$$\n- For two neighboring replicas at temperatures $T_{i}$ and $T_{i+1}$, define the inverse temperatures $\\beta_{i} = 1/T_{i}$ and $\\beta_{i+1} = 1/T_{i+1}$. Under a local equal-variance Gaussian approximation evaluated at the midpoint temperature $T_{m} = \\tfrac{T_{i} + T_{i+1}}{2}$, the expected Metropolis swap acceptance between these two replicas is modeled as\n$$\nA(T_{i}, T_{i+1}) = \\operatorname{erfc}\\!\\left(\\frac{|\\beta_{i+1} - \\beta_{i}|\\,\\sigma(T_{m})}{\\sqrt{2}}\\right),\n$$\nwhere $\\operatorname{erfc}(\\cdot)$ is the complementary error function.\n\nDefine an increasing sequence of temperatures $\\{T_{0}, T_{1}, \\dots, T_{N}\\}$ with $T_{0} = T_{\\min}$ and $T_{N} = T_{\\max}$ to be feasible if it satisfies the nearest-neighbor acceptance constraint\n$$\nA(T_{i}, T_{i+1}) \\ge a_{\\mathrm{target}} \\quad \\text{for all } i \\in \\{0,1,\\dots,N-1\\}.\n$$\nAmong all feasible sequences for the same $(T_{\\min}, T_{\\max}, a_{\\mathrm{target}})$, call a sequence optimal if it has the minimal possible length $N+1$.\n\nYour task is to compute an optimal temperature ladder for each case in the following test suite. For each case, output the full sequence $\\{T_{0}, T_{1}, \\dots, T_{N}\\}$ in $\\mathrm{K}$, rounded to one decimal place.\n\nTest suite:\n1. $T_{\\min} = 280\\,\\mathrm{K}$, $T_{\\max} = 500\\,\\mathrm{K}$, $a_{\\mathrm{target}} = 0.3$.\n2. $T_{\\min} = 295\\,\\mathrm{K}$, $T_{\\max} = 330\\,\\mathrm{K}$, $a_{\\mathrm{target}} = 0.3$.\n3. $T_{\\min} = 280\\,\\mathrm{K}$, $T_{\\max} = 500\\,\\mathrm{K}$, $a_{\\mathrm{target}} = 0.4$.\n4. $T_{\\min} = 430\\,\\mathrm{K}$, $T_{\\max} = 470\\,\\mathrm{K}$, $a_{\\mathrm{target}} = 0.3$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a bracketed, comma-separated list of temperatures (in $\\mathrm{K}$) for the corresponding test case. For example: \"[[T0_case1,T1_case1,...],[T0_case2,T1_case2,...],...]\".", "solution": "The problem requires the construction of an optimal temperature ladder, $\\{T_{0}, T_{1}, \\dots, T_{N}\\}$, for Replica Exchange Molecular Dynamics (REMD). The ladder must span a given temperature range $[T_{\\min}, T_{\\max}]$ and satisfy a minimum expected acceptance probability, $a_{\\mathrm{target}}$, for exchanges between adjacent replicas. An optimal ladder is defined as one having the minimum possible number of temperatures, $N+1$.\n\nThe principle of optimality dictates a greedy approach. To minimize the total number of replicas, we must maximize the temperature difference, $T_{i+1} - T_{i}$, at each step $i$ of constructing the ladder, starting from $T_0 = T_{\\min}$. The largest permissible step is one that pushes the expected acceptance probability down to its minimum allowed value, $a_{\\mathrm{target}}$. Therefore, at each step, we must determine the next temperature $T_{i+1}$ by solving the equation:\n$$\nA(T_{i}, T_{i+1}) = a_{\\mathrm{target}}\n$$\nwhere $A(T_i, T_{i+1})$ is the expected acceptance probability between replicas at temperatures $T_i$ and $T_{i+1}$.\n\nThe problem provides a model for this acceptance probability:\n$$\nA(T_{i}, T_{i+1}) = \\operatorname{erfc}\\!\\left(\\frac{|\\beta_{i+1} - \\beta_{i}|\\,\\sigma(T_{m})}{\\sqrt{2}}\\right)\n$$\nHere, $\\beta_{i} = 1/T_{i}$ is the inverse temperature, $T_{m} = (T_{i} + T_{i+1})/2$ is the midpoint temperature, and $\\sigma(T_{m})$ represents the energy fluctuations at $T_m$. Since the temperature sequence is strictly increasing ($T_{i+1}  T_i$), we have $\\beta_{i+1}  \\beta_{i}$, so $|\\beta_{i+1} - \\beta_{i}| = \\beta_{i} - \\beta_{i+1}$.\n\nSubstituting this into our equality and rearranging gives the core equation for our algorithm. Let $k = \\operatorname{erfcinv}(a_{\\mathrm{target}})$, where $\\operatorname{erfcinv}$ is the inverse complementary error function. The equation to be solved for $T_{i+1}$ given $T_i$ is:\n$$\n(\\beta_{i} - \\beta_{i+1})\\,\\sigma(T_{m}) = k\\sqrt{2}\n$$\nSubstituting the definitions for $\\beta$ and $T_m$, we obtain the implicit equation for the next temperature, which we shall denote $T_{\\text{next}}$:\n$$\n\\left(\\frac{1}{T_{i}} - \\frac{1}{T_{\\text{next}}}\\right) \\sigma\\left(\\frac{T_{i} + T_{\\text{next}}}{2}\\right) - k\\sqrt{2} = 0\n$$\nThe energy fluctuation term, $\\sigma(T)$, is given by $\\sigma(T) = T\\sqrt{C_v(T)}$, with the heat capacity $C_v(T)$ defined as:\n$$\nC_{v}(T) = c_{0} + A_{1}\\exp\\!\\left(-\\tfrac{1}{2}\\left(\\tfrac{T - 310}{w_{1}}\\right)^{2}\\right) + A_{2}\\exp\\!\\left(-\\tfrac{1}{2}\\left(\\tfrac{T - 450}{w_{2}}\\right)^{2}\\right)\n$$\nThe parameters are $c_{0} = 100$, $A_{1} = 200$, $w_{1} = 8$, $A_{2} = 150$, and $w_{2} = 10$. The resulting function $\\sigma(T)$ is non-trivial, and as a consequence, the equation for $T_{\\text{next}}$ may not have a unique solution or be monotonic. To satisfy the optimality condition, we must select the largest possible value of $T_{\\text{next}}  T_i$ that solves the equation.\n\nThe algorithmic procedure is as follows:\n1. Initialize the temperature list with the starting temperature: $\\mathcal{T} = \\{T_{\\min}\\}$. Let the current temperature be $T_{\\text{current}} = T_{\\min}$.\n2. While $T_{\\text{current}}  T_{\\max}$:\n    a. Define the function $g(x)$ for the root-finding procedure:\n       $$\n       g(x) = \\left(\\frac{1}{T_{\\text{current}}} - \\frac{1}{x}\\right) \\sigma\\left(\\frac{T_{\\text{current}} + x}{2}\\right) - k\\sqrt{2}\n       $$\n    b. Find the largest root, $T_{\\text{next}}$, of the equation $g(x)=0$ in the interval $(T_{\\text{current}}, T_{\\max}]$.\n    c. If such a root exists and $T_{\\text{next}}  T_{\\max}$, append $T_{\\text{next}}$ to the list $\\mathcal{T}$ and update $T_{\\text{current}} = T_{\\text{next}}$.\n    d. If no root exists in $(T_{\\text{current}}, T_{\\max}]$ (which occurs if $g(T_{\\max}) \\le 0$), or if the found root $T_{\\text{next}} \\ge T_{\\max}$, the process terminates. We append $T_{\\max}$ to $\\mathcal{T}$ to complete the ladder.\n3. The final list $\\mathcal{T}$ represents the optimal temperature ladder.\n\nTo ensure the largest root is found, a simple numerical solver on a fixed interval is insufficient. A robust strategy is required. We implement a backward search for the root's enclosing bracket. Starting from $b=T_{\\max}$, we step backward with a small increment to find an interval $[a, b]$ where $g(a) \\le 0$ and $g(b)  0$. This ensures that the bracket contains the largest root in $(T_{\\text{current}}, T_{\\max}]$. A stable root-finding algorithm, such as the Brent-Dekker method, is then applied on this bracket. This guarantees that at each step we take the largest possible temperature jump, thus producing a ladder with the minimum number of replicas. The final temperatures are rounded to one decimal place as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erfcinv\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Computes optimal temperature ladders for REMD based on a given bi-modal heat capacity model.\n    \"\"\"\n    # Define the constants for the heat capacity model from the problem statement.\n    c0 = 100.0\n    A1 = 200.0\n    w1 = 8.0\n    T1_peak = 310.0\n    A2 = 150.0\n    w2 = 10.0\n    T2_peak = 450.0\n\n    def Cv(T):\n        \"\"\"\n        Calculates the constant-volume heat capacity Cv(T) as per the given model.\n        \"\"\"\n        term1 = A1 * np.exp(-0.5 * ((T - T1_peak) / w1)**2)\n        term2 = A2 * np.exp(-0.5 * ((T - T2_peak) / w2)**2)\n        return c0 + term1 + term2\n\n    def sigma(T):\n        \"\"\"\n        Calculates the energy fluctuation sigma(T), where sigma^2 = Cv(T) * T^2.\n        \"\"\"\n        return T * np.sqrt(Cv(T))\n\n    def find_next_temp(T_i, T_max, C):\n        \"\"\"\n        Finds the next temperature T_next in the ladder that satisfies the acceptance criterion.\n        This function identifies the largest possible root to ensure an optimal (shortest) ladder.\n\n        Args:\n            T_i (float): The current temperature.\n            T_max (float): The maximum temperature of the ladder.\n            C (float): The constant part of the equation, derived from a_target. \n                       C = erfcinv(a_target) * sqrt(2).\n        Returns:\n            float: The next optimal temperature.\n        \"\"\"\n        def g(T_next):\n            \"\"\"The function whose root is sought: g(T_next) = 0.\"\"\"\n            if T_next = T_i:\n                # This region is not of interest. Return a large positive value to guide the solver.\n                return np.inf\n            Tm = (T_i + T_next) / 2.0\n            beta_diff = (1.0 / T_i) - (1.0 / T_next)\n            return beta_diff * sigma(Tm) - C\n\n        # If the step to T_max has an acceptance rate >= a_target, the ladder is complete.\n        if g(T_max) = 0:\n            return T_max\n\n        # To find the largest root, we search backwards from T_max to find a bracket [a, b]\n        # such that g(a) = 0 and g(b) > 0.\n        step = 1.0  # Search step in Kelvin.\n        b = T_max\n        a = b - step\n        while a > T_i:\n            if g(a) = 0:\n                # Bracket [a, b] contains the largest root. We can now solve for it.\n                return brentq(g, a, b)\n            b = a\n            a -= step\n        \n        # If the loop finishes, the root must be in the first interval from T_i.\n        return brentq(g, T_i + 1e-9, b)\n\n    def generate_ladder(T_min, T_max, a_target):\n        \"\"\"\n        Generates the optimal temperature ladder for a given set of parameters.\n        \"\"\"\n        # Pre-calculate the constant C from the target acceptance rate.\n        C = erfcinv(a_target) * np.sqrt(2)\n        \n        temps = [T_min]\n        T_current = T_min\n        \n        # Set a practical limit on the number of replicas to prevent infinite loops.\n        max_replicas = 2000\n        while T_current  T_max and len(temps)  max_replicas:\n            T_next = find_next_temp(T_current, T_max, C)\n            temps.append(T_next)\n            T_current = T_next\n            \n        if len(temps) >= max_replicas:\n            raise RuntimeError(\"Exceeded maximum number of replicas, check parameters.\")\n\n        # Round all temperatures in the final list to one decimal place.\n        return [round(t, 1) for t in temps]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (280.0, 500.0, 0.3),\n        (295.0, 330.0, 0.3),\n        (280.0, 500.0, 0.4),\n        (430.0, 470.0, 0.3),\n    ]\n\n    results = []\n    for T_min, T_max, a_target in test_cases:\n        ladder = generate_ladder(T_min, T_max, a_target)\n        results.append(ladder)\n\n    # Format the final output string as specified in the problem statement.\n    # The format is a list of lists, e.g., [[...],[...]].\n    # str(list) automatically creates the required format for each inner list.\n    formatted_results = ','.join(map(str, results))\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```", "id": "2461552"}]}