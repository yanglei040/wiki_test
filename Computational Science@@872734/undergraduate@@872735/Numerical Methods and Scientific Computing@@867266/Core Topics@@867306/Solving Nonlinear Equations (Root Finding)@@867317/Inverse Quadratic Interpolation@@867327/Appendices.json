{"hands_on_practices": [{"introduction": "To begin, we'll ground our understanding of inverse quadratic interpolation by performing a single, detailed calculation. This exercise guides you through the core mechanics of constructing an inverse quadratic model and using it to find an approximate solution [@problem_id:3243909]. By applying the method to a logistic function, you will see precisely how three points are used to estimate a root and also observe how specific point configurations can lead to interesting special cases.", "problem": "Consider the monotone logistic function $f(x)=\\dfrac{1}{1+\\exp(-k x)}$ with parameter $k0$. You are given the target value $f(x)=c$ with $k=100$ and $c=0.9$. Using three distinct abscissae $x_{0}=-0.05$, $x_{1}=0$, and $x_{2}=0.05$, perform one step of inverse quadratic interpolation (IQI), defined as follows: treat $x$ as a function of $y=f(x)$ and construct the unique quadratic interpolant $p(y)$ in the Lagrange form that satisfies $p\\!\\left(f(x_{i})\\right)=x_{i}$ for $i=0,1,2$. Evaluate $p(c)$ to obtain an IQI estimate of the solution $x$ to $f(x)=c$. Then, derive the exact inverse of the logistic function from first principles, and compute the exact solution $x_{\\text{exact}}$ for the same $k$ and $c$. Finally, compute the absolute numerical error of the IQI estimate with respect to the exact solution, namely $|p(c)-x_{\\text{exact}}|$. Round your final numerical answer to six significant figures.", "solution": "The user-provided problem is rigorously analyzed and validated as a scientifically grounded, well-posed, and objective problem in numerical analysis. All necessary data and conditions are provided, and there are no internal contradictions or ambiguities.\n\nThe problem asks for several calculations related to finding the root of the equation $f(x)=c$ for the logistic function $f(x)=\\dfrac{1}{1+\\exp(-k x)}$ with parameters $k=100$ and $c=0.9$. The steps involve using inverse quadratic interpolation (IQI), finding the exact analytical solution, and computing the error between the two.\n\n**Step 1: Inverse Quadratic Interpolation (IQI) Estimate**\n\nThe core of IQI is to approximate the inverse function $x=f^{-1}(y)$ with a quadratic polynomial. Given three distinct points $(x_0, f(x_0))$, $(x_1, f(x_1))$, and $(x_2, f(x_2))$, we construct a quadratic polynomial $p(y)$ that passes through the points $(y_0, x_0)$, $(y_1, x_1)$, and $(y_2, x_2)$, where $y_i = f(x_i)$.\n\nThe given data are:\n- Function: $f(x) = \\dfrac{1}{1+\\exp(-kx)}$ with $k=100$.\n- Abscissae: $x_0 = -0.05$, $x_1 = 0$, $x_2 = 0.05$.\n- Target value: $y=c=0.9$.\n\nFirst, we compute the corresponding ordinate values $y_i = f(x_i)$:\n$y_0 = f(x_0) = f(-0.05) = \\dfrac{1}{1+\\exp(-100 \\times -0.05)} = \\dfrac{1}{1+\\exp(5)}$.\n$y_1 = f(x_1) = f(0) = \\dfrac{1}{1+\\exp(0)} = \\dfrac{1}{1+1} = \\dfrac{1}{2}$.\n$y_2 = f(x_2) = f(0.05) = \\dfrac{1}{1+\\exp(-100 \\times 0.05)} = \\dfrac{1}{1+\\exp(-5)}$.\n\nThe interpolating quadratic polynomial $p(y)$ in Lagrange form is given by:\n$$p(y) = x_0 \\frac{(y-y_1)(y-y_2)}{(y_0-y_1)(y_0-y_2)} + x_1 \\frac{(y-y_0)(y-y_2)}{(y_1-y_0)(y_1-y_2)} + x_2 \\frac{(y-y_0)(y-y_1)}{(y_2-y_0)(y_2-y_1)}$$\nThe IQI estimate for the solution to $f(x)=c$ is $x_{IQI} = p(c)$. Since $x_1=0$, the middle term vanishes:\n$$x_{IQI} = x_0 \\frac{(c-y_1)(c-y_2)}{(y_0-y_1)(y_0-y_2)} + x_2 \\frac{(c-y_0)(c-y_1)}{(y_2-y_0)(y_2-y_1)}$$\nThe problem setup exhibits a special symmetry. The points are symmetric around $x=0$, i.e., $x_0 = -x_2$. The logistic function $f(x)$ centered at $x=0$ has the property $f(-x) = 1-f(x)$. Thus, $y_0 = f(x_0) = f(-x_2) = 1-f(x_2) = 1-y_2$. We also have $y_1=1/2$.\n\nLet's use these symmetry properties to simplify the expression for $p(y)$. Substitute $x_0=-x_2$, $y_0=1-y_2$, and $y_1=1/2$:\n$$p(y) = -x_2 \\frac{(y-1/2)(y-y_2)}{((1-y_2)-1/2)((1-y_2)-y_2)} + x_2 \\frac{(y-(1-y_2))(y-1/2)}{(y_2-(1-y_2))(y_2-1/2)}$$\n$$p(y) = x_2(y-1/2) \\left[ \\frac{-(y-y_2)}{(1/2-y_2)(1-2y_2)} + \\frac{y-1+y_2}{(2y_2-1)(y_2-1/2)} \\right]$$\nFactoring out common terms in the denominators:\n$$p(y) = x_2(y-1/2) \\left[ \\frac{-(y-y_2)}{-(y_2-1/2)(-(2y_2-1))} + \\frac{y-1+y_2}{-(1-2y_2)(y_2-1/2)} \\right]$$\n$$p(y) = \\frac{x_2(y-1/2)}{(y_2-1/2)(1-2y_2)} \\left[ -(y-y_2) - (y-1+y_2) \\right]$$\n$$p(y) = \\frac{x_2(y-1/2)}{(y_2-1/2)(1-2y_2)} [-y+y_2 -y+1-y_2] = \\frac{x_2(y-1/2)}{(y_2-1/2)(1-2y_2)} [1-2y]$$\nNotice that $1-2y = -2(y-1/2)$. This simplification indicates that the interpolant is actually linear. A more direct proof shows that the coefficient of the $y^2$ term is zero due to this symmetry. The simplified polynomial is:\n$$p(y) = \\frac{x_2(y-1/2)}{y_2-1/2}$$\nThis is the equation of a line passing through $(y_1, x_1) = (1/2, 0)$ and $(y_2, x_2)$. The interpolation degenerates from quadratic to linear for this specific symmetrical choice of points.\n\nWe can now compute the IQI estimate $x_{IQI} = p(c)$ with $c=0.9$:\n$$x_{IQI} = p(0.9) = \\frac{x_2(0.9 - 0.5)}{y_2 - 0.5} = \\frac{0.05 \\times 0.4}{\\frac{1}{1+\\exp(-5)} - 0.5}$$\n$$x_{IQI} = \\frac{0.02}{\\frac{1 - (1+\\exp(-5))/2}{1+\\exp(-5)}} = \\frac{0.02}{\\frac{(1-\\exp(-5))/2}{1+\\exp(-5)}} = \\frac{0.04(1+\\exp(-5))}{1-\\exp(-5)}$$\nNumerically evaluating this expression:\n$\\exp(-5) \\approx 0.006737947$\n$$x_{IQI} \\approx \\frac{0.04(1+0.006737947)}{1-0.006737947} = \\frac{0.04 \\times 1.006737947}{0.993262053} \\approx 0.0405417278$$\n\n**Step 2: Exact Solution**\n\nTo find the exact solution, we must derive the inverse of the logistic function $y=f(x)$.\n$$y = \\frac{1}{1+\\exp(-kx)}$$\nWe solve for $x$:\n$$1+\\exp(-kx) = \\frac{1}{y}$$\n$$\\exp(-kx) = \\frac{1}{y} - 1 = \\frac{1-y}{y}$$\nTaking the natural logarithm of both sides:\n$$-kx = \\ln\\left(\\frac{1-y}{y}\\right)$$\n$$x = -\\frac{1}{k} \\ln\\left(\\frac{1-y}{y}\\right) = \\frac{1}{k} \\ln\\left(\\left(\\frac{1-y}{y}\\right)^{-1}\\right) = \\frac{1}{k} \\ln\\left(\\frac{y}{1-y}\\right)$$\nThis inverse function, $x = f^{-1}(y)$, is the logit function scaled by $1/k$.\n\nThe exact solution $x_{\\text{exact}}$ to $f(x)=c$ is found by evaluating $f^{-1}(c)$ with $k=100$ and $c=0.9$:\n$$x_{\\text{exact}} = \\frac{1}{100} \\ln\\left(\\frac{0.9}{1-0.9}\\right) = \\frac{1}{100} \\ln\\left(\\frac{0.9}{0.1}\\right) = \\frac{\\ln(9)}{100}$$\nNumerically evaluating this expression:\n$\\ln(9) \\approx 2.1972245773$\n$$x_{\\text{exact}} \\approx \\frac{2.1972245773}{100} = 0.0219722458$$\n\n**Step 3: Absolute Numerical Error**\n\nThe final step is to compute the absolute error between the IQI estimate and the exact solution.\n$$\\text{Error} = |x_{IQI} - x_{\\text{exact}}|$$\n$$\\text{Error} \\approx |0.0405417278 - 0.0219722458|$$\n$$\\text{Error} \\approx |0.018569482| = 0.018569482$$\nRounding the final answer to six significant figures, we get $0.0185695$. The first six significant figures are $1, 8, 5, 6, 9, 4$. The seventh digit is $8$, so we round the sixth digit up.", "answer": "$$\\boxed{0.0185695}$$", "id": "3243909"}, {"introduction": "Moving from a single calculation to a complete algorithm, this practice challenges you to implement a robust iterative solver using inverse quadratic interpolation. You will not only code the core IQI update but also incorporate essential fallback strategies to handle cases where the method becomes unstable [@problem_id:3243989]. Comparing your IQI solver's performance against a simpler fixed-point iteration will provide valuable context on its efficiency and convergence behavior.", "problem": "Consider the scalar nonlinear equation $f(x)=0$ with $f(x)=x-\\exp(-x)$. This equation has a unique real solution because $f(x)$ is continuous and strictly increasing on $\\mathbb{R}$, with $\\lim_{x\\to-\\infty}f(x)=-\\infty$ and $\\lim_{x\\to+\\infty}f(x)=+\\infty$. The goal is to construct and compare two derivative-free solvers for this equation: inverse quadratic interpolation and fixed-point iteration.\n\nYou must derive and implement the following two iterative methods from first principles, starting from core definitions of interpolation and fixed-point iteration:\n\n1. Inverse quadratic interpolation (IQI): Given three distinct iterates $x_0$, $x_1$, and $x_2$ with associated function values $f(x_0)$, $f(x_1)$, and $f(x_2)$, build the unique quadratic polynomial in the variable $y$ that interpolates the inverse relation, namely a polynomial $Q(y)$ such that $Q(f(x_i))=x_i$ for $i\\in\\{0,1,2\\}$. Use this interpolant to produce the next iterate by evaluating at $y=0$, i.e., $x_{\\text{new}}=Q(0)$. To avoid numerical instability when the construction is ill-conditioned (for example, when any pair of $f(x_i)$ values are nearly equal so that denominators in the interpolation become tiny), your implementation must detect such cases and fall back to a secant update computed from the two most recent iterates, provided their function values are sufficiently different. If even that is not possible because of near-equal function values, you must retain the current iterate unchanged for that step.\n\n2. Fixed-point iteration: Rewrite the equation in fixed-point form $x=g(x)$ with $g(x)=\\exp(-x)$. Starting from an initial guess $x_0$, iterate $x_{k+1}=g(x_k)$ until convergence. This is a derivative-free method that uses only function evaluation of $g(x)$.\n\nFor both methods, use the same convergence logic. Define an absolute function tolerance $\\varepsilon_f=10^{-12}$ and a step tolerance $\\varepsilon_x=10^{-12}$. An iterate $x_k$ is accepted as converged if either $|f(x_k)|\\le \\varepsilon_f$ or $|x_k-x_{k-1}|\\le \\varepsilon_x$ (for $k\\ge 1$). Impose a maximum of $N_{\\max}=1000$ iterations. Count the number of iterations actually performed until the stopping criterion is first met; if the maximum is reached without meeting the criterion, report the last iterate and the iteration count $N_{\\max}$.\n\nYour program must implement both solvers and apply them to the test suite below. For each test case, run IQI using the specified three initial points $(x_0,x_1,x_2)$ and fixed-point iteration using the specified initial point $x_0$. For each method and each test case, return the final approximate root and the number of iterations taken.\n\nTest suite:\n- Case $1$: IQI with $(x_0,x_1,x_2)=(0.0,1.0,0.5)$ and fixed-point with $x_0=0.0$.\n- Case $2$: IQI with $(x_0,x_1,x_2)=(0.55,0.57,0.60)$ and fixed-point with $x_0=0.55$.\n- Case $3$: IQI with $(x_0,x_1,x_2)=(-2.0,2.0,3.0)$ and fixed-point with $x_0=3.0$.\n- Case $4$: IQI with $(x_0,x_1,x_2)=(0.56,0.565,0.57)$ and fixed-point with $x_0=0.56$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case, append four items in this strict order:\n- The IQI final approximation to the root, rounded to $12$ decimal places.\n- The IQI iteration count as an integer.\n- The fixed-point final approximation to the root, rounded to $12$ decimal places.\n- The fixed-point iteration count as an integer.\n\nThus, the final output is a single list of $16$ entries in the order of Cases $1$ through $4$, each case contributing its four entries, for example, $[x^{\\text{IQI}}_1,n^{\\text{IQI}}_1,x^{\\text{FP}}_1,n^{\\text{FP}}_1,\\dots,x^{\\text{IQI}}_4,n^{\\text{IQI}}_4,x^{\\text{FP}}_4,n^{\\text{FP}}_4]$.\n\nNo physical units or angle units are involved in this problem; all quantities are real scalars. The numerical tolerances $\\varepsilon_f$ and $\\varepsilon_x$ are absolute tolerances on $f(x)$ and step size respectively. The program must be self-contained and must not require any user input or external files.", "solution": "The problem requires the derivation, implementation, and comparison of two derivative-free numerical methods—Inverse Quadratic Interpolation (IQI) and Fixed-Point Iteration—for finding the unique real root of the nonlinear equation $f(x) = x - \\exp(-x) = 0$.\n\n### **Analysis of the Function and Root**\nThe function is $f(x) = x - e^{-x}$. It is a continuous and differentiable function for all $x \\in \\mathbb{R}$. Its derivative is $f'(x) = 1 + e^{-x}$. Since $e^{-x}  0$ for all real $x$, we have $f'(x)  1$, which means $f(x)$ is strictly monotonically increasing. Furthermore, $\\lim_{x\\to-\\infty} f(x) = -\\infty$ and $\\lim_{x\\to\\infty} f(x) = +\\infty$. By the Intermediate Value Theorem, there must be a unique real root $\\alpha$ such that $f(\\alpha)=0$. This root is the solution to $\\alpha = e^{-\\alpha}$, which is given by the Lambert W function, $\\alpha = W(1) \\approx 0.56714329041$.\n\n### **Method 1: Inverse Quadratic Interpolation (IQI)**\n\n#### **Derivation from First Principles**\nInverse quadratic interpolation is a root-finding algorithm that uses three previous iterates to form a quadratic model of the *inverse* function and then uses this model to estimate the root. Let the three distinct points be $(x_0, y_0)$, $(x_1, y_1)$, and $(x_2, y_2)$, where $y_i = f(x_i)$. We seek a quadratic polynomial $Q(y)$ such that $Q(y_i) = x_i$ for $i \\in \\{0, 1, 2\\}$. This is a standard interpolation problem. The unique quadratic interpolant can be expressed using the Lagrange basis polynomials:\n$$\nQ(y) = x_0 \\frac{(y-y_1)(y-y_2)}{(y_0-y_1)(y_0-y_2)} + x_1 \\frac{(y-y_0)(y-y_2)}{(y_1-y_0)(y_1-y_2)} + x_2 \\frac{(y-y_0)(y-y_1)}{(y_2-y_0)(y_2-y_1)}\n$$\nThe root of the original function $f(x)$ corresponds to the value of its inverse $x=f^{-1}(y)$ at $y=0$. We approximate this value by evaluating our interpolant $Q(y)$ at $y=0$. This gives the next iterate, $x_{\\text{new}}$:\n$$\nx_{\\text{new}} = Q(0) = x_0 \\frac{(-y_1)(-y_2)}{(y_0-y_1)(y_0-y_2)} + x_1 \\frac{(-y_0)(-y_2)}{(y_1-y_0)(y_1-y_2)} + x_2 \\frac{(-y_0)(-y_1)}{(y_2-y_0)(y_2-y_1)}\n$$\nSimplifying this expression yields the update formula for IQI:\n$$\nx_{\\text{new}} = x_0 \\frac{y_1 y_2}{(y_0-y_1)(y_0-y_2)} + x_1 \\frac{y_0 y_2}{(y_1-y_0)(y_1-y_2)} + x_2 \\frac{y_0 y_1}{(y_2-y_0)(y_2-y_1)}\n$$\nThis formula requires that the function values $y_0, y_1, y_2$ be distinct, otherwise the denominators become zero.\n\n#### **Algorithmic Design and Fallback Strategy**\nThe iterative process starts with three initial points $(x_a, x_b, x_c)$ and their function values $(y_a, y_b, y_c)$. In each iteration, a new point $x_{\\text{new}}$ is computed, and the oldest point is discarded. The set of points for the next iteration becomes $(x_b, x_c, x_{\\text{new}})$.\n\nA crucial part of a robust IQI implementation is handling cases where the method is ill-conditioned, which occurs when any two of the function values $(y_a, y_b, y_c)$ are nearly equal. The problem specifies a fallback strategy:\n1.  **Attempt IQI:** Calculate $x_{\\text{new}}$ using the formula above. This is only done if the function values $y_a$, $y_b$, and $y_c$ are sufficiently distinct. Numerically, we check if $|y_i - y_j|$ is greater than a small tolerance for all $i \\neq j$.\n2.  **Fallback to Secant Method:** If the IQI update is unstable (i.e., function values are not distinct), the algorithm falls back to the secant method using the two most recent points, $(x_b, y_b)$ and $(x_c, y_c)$. The secant formula for the next iterate is:\n    $$\n    x_{\\text{new}} = x_c - y_c \\frac{x_c - x_b}{y_c - y_b}\n    $$\n    This is only performed if $y_c$ and $y_b$ are sufficiently distinct.\n3.  **Second Fallback (Retain Iterate):** If both IQI and the secant method are unstable (because $y_b \\approx y_c$), the algorithm does not compute a new point and simply carries the most recent iterate forward: $x_{\\text{new}} = x_c$. This prevents division by a near-zero number and maintains stability.\n\n### **Method 2: Fixed-Point Iteration**\n\n#### **Derivation from First Principles**\nFixed-point iteration is a method for finding roots of an equation $f(x)=0$ by rearranging it into the form $x=g(x)$. A solution to this equation is a \"fixed point\" of the function $g$. Given an initial guess $x_0$, the method generates a sequence of iterates using the recurrence relation $x_{k+1} = g(x_k)$.\n\nFor the given equation, $f(x) = x - e^{-x} = 0$, a natural rearrangement is:\n$$\nx = e^{-x}\n$$\nThis gives the iteration function $g(x) = e^{-x}$. The iterative scheme is therefore:\n$$\nx_{k+1} = g(x_k) = \\exp(-x_k)\n$$\nThe convergence of this method is governed by the Contraction Mapping Theorem. The iteration is guaranteed to converge to the unique fixed point in an interval if $|g'(x)|  1$ for all $x$ in that interval. For our problem, $g'(x) = -e^{-x}$. The root $\\alpha \\approx 0.56714$ lies in the interval $[0, 1]$. On this interval, $|g'(x)| = e^{-x} \\le e^0 = 1$. At the root, $|g'(\\alpha)| = e^{-\\alpha} = \\alpha  1$. For any initial guess $x_0-\\ln(1)=\\text{any real number}$ for which convergence criteria apply, the condition for local convergence is satisfied. For $x_0 \\ge 0$, for instance, all subsequent iterates will remain non-negative, and the method will converge to the positive root.\n\n#### **Algorithmic Design**\nThe algorithm starts with an initial value $x_0$. It then iteratively computes $x_1 = g(x_0)$, $x_2=g(x_1)$, and so on, until the stopping criterion is met.\n\n### **Convergence and Termination**\nBoth methods use the same termination criteria. An iterate $x_k$ is considered the converged solution if either of the following conditions is met, for given tolerances $\\varepsilon_f = 10^{-12}$ and $\\varepsilon_x = 10^{-12}$:\n1.  **Function Value Tolerance:** The residual is close to zero: $|f(x_k)| \\leq \\varepsilon_f$.\n2.  **Step Size Tolerance:** The change between successive iterates is small: $|x_k - x_{k-1}| \\leq \\varepsilon_x$ (for $k \\ge 1$).\n\nIf convergence is not achieved after a maximum of $N_{\\max} = 1000$ iterations, the process terminates, and the last computed iterate is returned. The number of iterations is the count of new points generated. An initial guess satisfying the criteria before any new points are computed corresponds to $0$ iterations.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares Inverse Quadratic Interpolation and Fixed-Point Iteration\n    for solving the nonlinear equation f(x) = x - exp(-x) = 0.\n    \"\"\"\n    \n    # Define the primary function f(x) and the fixed-point function g(x)\n    def f(x):\n        return x - np.exp(-x)\n\n    def g(x):\n        return np.exp(-x)\n\n    # Set common parameters for the solvers\n    EPS_F = 1e-12\n    EPS_X = 1e-12\n    N_MAX = 1000\n    DENOM_TOL = 1e-20 # A small tolerance for checking denominators\n\n    def iqi_solver(x0, x1, x2):\n        \"\"\"\n        Solves f(x) = 0 using Inverse Quadratic Interpolation with fallback.\n        \n        Args:\n            x0, x1, x2 (float): Three initial distinct guesses for the root.\n            \n        Returns:\n            tuple: (final root approximation, number of iterations).\n        \"\"\"\n        xa, xb, xc = x0, x1, x2\n\n        # Check initial points for convergence before starting iterations\n        # The prompt implies that n=0 if one of the initial points is the solution.\n        # Check the 'most recent' point x2 first.\n        if abs(f(xc)) = EPS_F or abs(xc - xb) = EPS_X:\n            return xc, 0\n\n        for n in range(1, N_MAX + 1):\n            ya, yb, yc = f(xa), f(xb), f(xc)\n\n            # Check for ill-conditioning: if any f-values are too close\n            if abs(ya - yb)  DENOM_TOL or abs(ya - yc)  DENOM_TOL or abs(yb - yc)  DENOM_TOL:\n                # IQI fails, fallback to secant method on the two most recent points\n                if abs(yc - yb)  DENOM_TOL:\n                    # Secant method also fails, retain the current iterate\n                    x_new = xc\n                else:\n                    x_new = xc - yc * (xc - xb) / (yc - yb)\n            else:\n                # IQI update formula derived from Lagrange interpolation Q(0)\n                term0 = xa * yb * yc / ((ya - yb) * (ya - yc))\n                term1 = xb * ya * yc / ((yb - ya) * (yb - yc))\n                term2 = xc * ya * yb / ((yc - ya) * (yc - yb))\n                x_new = term0 + term1 + term2\n\n            # Update points for the next iteration\n            xa, xb, xc = xb, xc, x_new\n\n            # Check for convergence on the newly computed point\n            if abs(f(xc)) = EPS_F or abs(xc - xb) = EPS_X:\n                return xc, n\n\n        return xc, N_MAX\n\n    def fp_solver(x0):\n        \"\"\"\n        Solves f(x) = 0 using Fixed-Point Iteration.\n        \n        Args:\n            x0 (float): Initial guess for the root.\n            \n        Returns:\n            tuple: (final root approximation, number of iterations).\n        \"\"\"\n        x_prev = x0\n        \n        # Check if the initial guess is already the solution\n        if abs(f(x_prev)) = EPS_F:\n            return x_prev, 0\n\n        for n in range(1, N_MAX + 1):\n            x_curr = g(x_prev)\n            \n            # Check for convergence\n            if abs(f(x_curr)) = EPS_F or abs(x_curr - x_prev) = EPS_X:\n                return x_curr, n\n            \n            x_prev = x_curr\n        \n        return x_curr, N_MAX\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        # Case 1\n        {'iqi_initial': (0.0, 1.0, 0.5), 'fp_initial': 0.0},\n        # Case 2\n        {'iqi_initial': (0.55, 0.57, 0.60), 'fp_initial': 0.55},\n        # Case 3\n        {'iqi_initial': (-2.0, 2.0, 3.0), 'fp_initial': 3.0},\n        # Case 4\n        {'iqi_initial': (0.56, 0.565, 0.57), 'fp_initial': 0.56},\n    ]\n\n    results = []\n    for case in test_cases:\n        # Run IQI solver\n        iqi_root, iqi_iters = iqi_solver(*case['iqi_initial'])\n        results.append(f\"{iqi_root:.12f}\")\n        results.append(str(iqi_iters))\n\n        # Run Fixed-Point solver\n        fp_root, fp_iters = fp_solver(case['fp_initial'])\n        results.append(f\"{fp_root:.12f}\")\n        results.append(str(fp_iters))\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3243989"}, {"introduction": "A mathematically correct formula can sometimes fail in practice due to the limitations of floating-point arithmetic. This final practice explores the critical concept of numerical stability within inverse quadratic interpolation [@problem_id:3244093]. You will investigate a scenario designed to cause catastrophic cancellation in the standard IQI formula and then derive and test an algebraically equivalent but numerically superior version to see the dramatic improvement in accuracy.", "problem": "Consider the task of computing a single inverse quadratic interpolation step to approximate the location of a simple root of a scalar function using three previously computed points. Inverse quadratic interpolation constructs a quadratic polynomial for the inverse mapping $x(f)$ based on three data pairs $(x_0,f_0)$, $(x_1,f_1)$, and $(x_2,f_2)$ where $f_i = f(x_i)$, and then evaluates this polynomial at $f=0$ to estimate the root. The foundational base for this problem is the definition of polynomial interpolation for a function represented in Lagrange or Newton form, and the fact that the Lagrange basis functions sum to unity. You must start from these well-tested facts and definitions and derive any needed working formulas yourself.\n\nYour program must implement two versions of the inverse quadratic interpolation step to compute an estimate $\\hat{x}$ of the root from $(x_0,f_0)$, $(x_1,f_1)$, $(x_2,f_2)$:\n\n- A direct evaluation based on the standard construction of the degree-two interpolant for $x(f)$ at $f=0$, which is known to be susceptible to floating-point cancellation when the function values are very close to each other.\n\n- A rearranged evaluation that you derive from first principles, using the property that the Lagrange basis functions for $x(f)$ sum to one, so as to reduce catastrophic cancellation when combining large, nearly opposite terms.\n\nYou must demonstrate, using a scientifically sound scenario, that the standard formula can fail numerically due to floating-point cancellation, and that the rearranged formula improves numerical stability. All arithmetic is to be performed in double-precision following the Institute of Electrical and Electronics Engineers floating-point standard (IEEE 754).\n\nImplement both versions for the following test suite. In all cases, the unknown exact root is $r=0$ and the error to report is the absolute error $|\\hat{x}-r|$ as a floating-point number:\n\n- Test case $1$ (cancellation-prone cluster near a small offset): Let $f(x)=x^3$. Choose $a=1\\times 10^{-8}$ and $h=1\\times 10^{-16}$. Set $x_0=a$, $x_1=a+h$, $x_2=a-h$, and define $f_i=f(x_i)$. This configuration makes $f_0$, $f_1$, and $f_2$ extremely close, which should trigger floating-point cancellation in the direct evaluation.\n\n- Test case $2$ (well-conditioned linear mapping): Let $f(x)=x$. Set $x_0=-1$, $x_1=0.3$, $x_2=2$, and define $f_i=f(x_i)$. This configuration should be well-behaved and produce an accurate estimate without cancellation issues.\n\n- Test case $3$ (one point near the root): Let $f(x)=x^3$. Set $x_0=-1\\times 10^{-6}$, $x_1=1\\times 10^{-6}$, $x_2=1\\times 10^{-12}$, and define $f_i=f(x_i)$. This configuration places one function value very close to zero.\n\nFor each test case, compute:\n- The absolute error of the direct evaluation, $E_{\\text{direct}}=|\\hat{x}_{\\text{direct}}-r|$.\n- The absolute error of the rearranged evaluation, $E_{\\text{rearr}}=|\\hat{x}_{\\text{rearr}}-r|$.\n\nYour program should produce a single line of output containing the six floating-point results for the three test cases in order as a comma-separated list enclosed in square brackets:\n$[E_{\\text{direct},1},E_{\\text{rearr},1},E_{\\text{direct},2},E_{\\text{rearr},2},E_{\\text{direct},3},E_{\\text{rearr},3}]$.", "solution": "The problem requires the implementation and comparison of two formulas for a single step of inverse quadratic interpolation. The goal is to find an estimate $\\hat{x}$ for a root of a function $f(x)$, given three points $(x_0, f_0), (x_1, f_1), (x_2, f_2)$, where $f_i = f(x_i)$. The root estimate is found by constructing a quadratic polynomial $x(f)$ that passes through the three points $(f_i, x_i)$ and evaluating it at $f=0$.\n\nThe analysis will proceed in two steps:\n1.  Derivation of the two required formulas: a \"direct\" formula and a \"rearranged\" formula.\n2.  Implementation and evaluation of these formulas on the provided test cases.\n\n### Derivation of the Interpolation Formulas\n\nLet the three given data points be $(f_0, x_0)$, $(f_1, x_1)$, and $(f_2, x_2)$. We seek the value $x(0)$ of the unique quadratic polynomial $x(f)$ passing through these points.\n\n#### 1. Direct Evaluation Formula\n\nThe standard construction for an interpolating polynomial is the Lagrange form. The polynomial $x(f)$ is given by:\n$$\nx(f) = x_0 L_0(f) + x_1 L_1(f) + x_2 L_2(f)\n$$\nwhere $L_i(f)$ are the Lagrange basis polynomials:\n$$\nL_0(f) = \\frac{(f - f_1)(f - f_2)}{(f_0 - f_1)(f_0 - f_2)}, \\quad\nL_1(f) = \\frac{(f - f_0)(f - f_2)}{(f_1 - f_0)(f_1 - f_2)}, \\quad\nL_2(f) = \\frac{(f - f_0)(f - f_1)}{(f_2 - f_0)(f_2 - f_1)}\n$$\nThe root estimate, $\\hat{x}$, is obtained by evaluating $x(f)$ at $f=0$:\n$$\n\\hat{x} = x(0) = x_0 L_0(0) + x_1 L_1(0) + x_2 L_2(0)\n$$\nSubstituting $f=0$ into the basis polynomials gives:\n$$\nL_0(0) = \\frac{f_1 f_2}{(f_0 - f_1)(f_0 - f_2)}, \\quad\nL_1(0) = \\frac{f_0 f_2}{(f_1 - f_0)(f_1 - f_2)}, \\quad\nL_2(0) = \\frac{f_0 f_1}{(f_2 - f_0)(f_2 - f_1)}\n$$\nThis leads to the direct evaluation formula:\n$$\n\\hat{x}_{\\text{direct}} = x_0 \\frac{f_1 f_2}{(f_0 - f_1)(f_0 - f_2)} + x_1 \\frac{f_0 f_2}{(f_1 - f_0)(f_1 - f_2)} + x_2 \\frac{f_0 f_1}{(f_2 - f_0)(f_2 - f_1)}\n$$\nThis formula is known to be numerically unstable when the function values $f_0, f_1, f_2$ are close to each other but not close to zero. In this situation, the denominators $(f_i - f_j)$ become small, leading to large values for the individual terms. The final estimate $\\hat{x}$, which should be close to the $x_i$ values, is then computed by summing these large, nearly-canceling terms, a process known as catastrophic cancellation, which can lead to a significant loss of precision.\n\n#### 2. Rearranged Evaluation Formula\n\nThe problem states that a more stable formula can be derived using the property that the sum of the Lagrange basis polynomials is unity:\n$$\n\\sum_{i=0}^{2} L_i(f) = 1\n$$\nThis identity holds for any value of $f$, including $f=0$. We can use this to express the estimate $\\hat{x}$ as a correction to one of the initial points, say $x_2$. We write:\n$$\n\\hat{x} = x_2 + (\\hat{x} - x_2)\n$$\nUsing the sum property, we can write $x_2 = x_2 \\cdot 1 = x_2 \\sum_{i=0}^{2} L_i(0)$. Substituting this and the Lagrange formula for $\\hat{x}$:\n$$\n\\hat{x} - x_2 = \\left( \\sum_{i=0}^{2} x_i L_i(0) \\right) - \\left( x_2 \\sum_{i=0}^{2} L_i(0) \\right)\n$$\n$$\n\\hat{x} - x_2 = \\sum_{i=0}^{2} (x_i - x_2) L_i(0) = (x_0 - x_2)L_0(0) + (x_1 - x_2)L_1(0) + (x_2 - x_2)L_2(0)\n$$\nThe term for $i=2$ vanishes, leaving a formula for the correction term:\n$$\n\\hat{x} - x_2 = (x_0 - x_2)L_0(0) + (x_1 - x_2)L_1(0)\n$$\nThis gives the rearranged evaluation formula:\n$$\n\\hat{x}_{\\text{rearr}} = x_2 + (x_0 - x_2) \\frac{f_1 f_2}{(f_0 - f_1)(f_0 - f_2)} + (x_1 - x_2) \\frac{f_0 f_2}{(f_1 - f_0)(f_1 - f_2)}\n$$\nThis formulation calculates the estimate as a base value $x_2$ plus a correction. While algebraically identical to the direct formula, its numerical properties can be different. The subtraction of nearly equal values of $x_i$ and $f_i$ is still present in the computation of the correction term. However, this form structures the computation differently. In scenarios where the points $x_i$ are clustered, the terms $(x_i - x_2)$ are small, and the formula computes the final result by adding a potentially small correction to an initial guess $x_2$. This can be more robust than summing three potentially large, unrelated terms as in the direct formula.\n\n### Implementation and Numerical Demonstration\n\nThe two formulas, $\\hat{x}_{\\text{direct}}$ and $\\hat{x}_{\\text{rearr}}$, will be implemented and tested against the provided suite of test cases. All calculations are performed in standard double-precision floating-point arithmetic (IEEE 754). For all test cases, the true root is $r=0$, so the absolute error is simply $|\\hat{x}|$.\n\nThe test cases are:\n*   **Test case 1 (Cancellation-prone cluster):** $f(x)=x^3$, with $x_0=a$, $x_1=a+h$, $x_2=a-h$ for $a=1\\times 10^{-8}$ and $h=1\\times 10^{-16}$. The function values $f_i$ are extremely close, providing conditions for catastrophic cancellation.\n*   **Test case 2 (Well-conditioned):** $f(x)=x$, with $x_0=-1$, $x_1=0.3$, $x_2=2$. For a linear function, the interpolation is exact, and both formulas should yield the correct root $\\hat{x}=0$ (up to machine precision).\n*   **Test case 3 (One point near the root):** $f(x)=x^3$, with $x_0=-1\\times 10^{-6}$, $x_1=1\\times 10^{-6}$, $x_2=1\\times 10^{-12}$. Here, one point $(x_2, f_2)$ is extremely close to the root $(0,0)$. The rearranged formula, constructed as a correction to $x_2$, is expected to perform very well.\n\nThe results from these computations will demonstrate the difference in numerical stability between the two formulas.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef direct_evaluation(x0, x1, x2, f0, f1, f2):\n    \"\"\"\n    Computes the root estimate using the direct evaluation of the\n    Lagrange interpolation formula at f=0.\n    \"\"\"\n    # Check for non-distinct function values which would lead to division by zero.\n    if f0 == f1 or f0 == f2 or f1 == f2:\n        # This case is ill-defined for quadratic interpolation.\n        # In a real root-finder, one would fall back to a different method.\n        # For this problem's test cases, it indicates an issue if it occurs.\n        return np.nan\n\n    # Lagrange basis polynomials L_i(f) evaluated at f=0\n    term0 = x0 * f1 * f2 / ((f0 - f1) * (f0 - f2))\n    term1 = x1 * f0 * f2 / ((f1 - f0) * (f1 - f2))\n    term2 = x2 * f0 * f1 / ((f2 - f0) * (f2 - f1))\n    \n    return term0 + term1 + term2\n\ndef rearranged_evaluation(x0, x1, x2, f0, f1, f2):\n    \"\"\"\n    Computes the root estimate using the rearranged formula, derived\n    from the fact that the sum of Lagrange basis polynomials is 1.\n    \"\"\"\n    # Check for non-distinct function values.\n    if f0 == f1 or f0 == f2 or f1 == f2:\n        return np.nan\n\n    # Lagrange basis polynomials L_0(f) and L_1(f) evaluated at f=0\n    L0_at_0 = f1 * f2 / ((f0 - f1) * (f0 - f2))\n    L1_at_0 = f0 * f2 / ((f1 - f0) * (f1 - f2))\n    \n    # Correction term added to the base point x2\n    correction = (x0 - x2) * L0_at_0 + (x1 - x2) * L1_at_0\n    \n    return x2 + correction\n\ndef solve():\n    \"\"\"\n    Executes the inverse quadratic interpolation for the test suite\n    and prints the results.\n    \"\"\"\n    test_cases = [\n        # Test case 1: Cancellation-prone cluster\n        {\n            \"f\": lambda x: x**3,\n            \"x_coords\": (1e-8, 1e-8 + 1e-16, 1e-8 - 1e-16),\n            \"root\": 0.0\n        },\n        # Test case 2: Well-conditioned linear mapping\n        {\n            \"f\": lambda x: x,\n            \"x_coords\": (-1.0, 0.3, 2.0),\n            \"root\": 0.0\n        },\n        # Test case 3: One point near the root\n        {\n            \"f\": lambda x: x**3,\n            \"x_coords\": (-1e-6, 1e-6, 1e-12),\n            \"root\": 0.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        func = case[\"f\"]\n        x0, x1, x2 = case[\"x_coords\"]\n        r = case[\"root\"]\n\n        # All computations use standard Python floats (IEEE 754 double precision)\n        f0 = func(x0)\n        f1 = func(x1)\n        f2 = func(x2)\n\n        # Calculate estimate using the direct formula\n        x_hat_direct = direct_evaluation(x0, x1, x2, f0, f1, f2)\n        error_direct = abs(x_hat_direct - r)\n        results.append(error_direct)\n\n        # Calculate estimate using the rearranged formula\n        x_hat_rearranged = rearranged_evaluation(x0, x1, x2, f0, f1, f2)\n        error_rearranged = abs(x_hat_rearranged - r)\n        results.append(error_rearranged)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3244093"}]}