{"hands_on_practices": [{"introduction": "While Newton's method is powerful, it is not foolproof. This first practice explores a classic failure mode that is immediately apparent from the method's geometric foundation. By analyzing a function with no real roots but a distinct minimum, you will discover how the algorithm can break down when an iterate lands on a point where the tangent line is horizontal, reinforcing the importance of the condition $f'(x) \\neq 0$. [@problem_id:3234373]", "problem": "Consider the scalar nonlinear function $f:\\mathbb{R}\\to\\mathbb{R}$ defined by $f(x)=(x-1)^{2}+1$. This function has a unique local (and global) minimum at $x^{\\ast}=1$ and satisfies $f(x^{\\ast})=1\\neq 0$, so it has no real roots. Newton's method for root-finding updates a current iterate $x_{k}$ by intersecting the tangent line to the graph of $y=f(x)$ at $x=x_{k}$ with the $x$-axis to produce the next iterate $x_{k+1}$. Using only this geometric interpretation and the fact that the tangent line at a local minimum is horizontal, derive the condition on $x_{0}$ that forces the first Newton iterate $x_{1}$ to land exactly at the minimizer $x^{\\ast}=1$, thereby making the next step undefined. Then, solve this condition explicitly for an initial guess $x_{0}$ satisfying $x_{0}>1$.\n\nReport the value of $x_{0}$ and provide it in exact form (no rounding). Additionally, briefly justify why the usual quadratic convergence theory cannot apply from this starting point, based on the geometric picture and the hypotheses required for quadratic convergence. Your final reported value must be the single number $x_{0}$ with $x_{0}>1$.", "solution": "The problem is validated as self-contained, scientifically grounded in the principles of numerical analysis, and well-posed. All the necessary information is provided, the terms are mathematically precise, and the question leads to a unique, derivable solution.\n\nThe problem asks for an initial guess $x_0 > 1$ such that the first iterate of Newton's method, $x_1$, applied to the function $f(x)=(x-1)^{2}+1$, lands exactly on the function's minimizer $x^{\\ast}=1$. Newton's method for finding a root of $f(x)$ generates a sequence of iterates $x_k$ according to the update rule:\n$$x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}$$\nThis rule is derived from the geometric interpretation specified in the problem: $x_{k+1}$ is the $x$-axis intercept of the tangent line to the graph of $y=f(x)$ at the point $(x_k, f(x_k))$.\n\nThe function provided is $f(x)=(x-1)^{2}+1$. Its derivative is $f'(x) = 2(x-1)$.\nThe problem states the condition that the first iterate ($k=0$) must be $x_1 = 1$. Substituting $k=0$ and $x_1=1$ into the Newton's method formula gives:\n$$1 = x_0 - \\frac{f(x_0)}{f'(x_0)}$$\nThis equation defines the condition on the initial guess $x_0$. We can rearrange it to solve for $x_0$:\n$$x_0 - 1 = \\frac{f(x_0)}{f'(x_0)}$$\nNow, we substitute the expressions for $f(x_0)$ and $f'(x_0)$:\n$$x_0 - 1 = \\frac{(x_0-1)^{2}+1}{2(x_0-1)}$$\nFor this expression to be well-defined, we must have $f'(x_0) \\neq 0$, which means $2(x_0-1) \\neq 0$, or $x_0 \\neq 1$. This is consistent with the problem's logic, as starting at the minimizer $x_0=1$ would make the first step undefined due to a horizontal tangent.\n\nTo solve for $x_0$, we can multiply both sides by $2(x_0-1)$:\n$$2(x_0-1)(x_0-1) = (x_0-1)^{2}+1$$\n$$2(x_0-1)^{2} = (x_0-1)^{2}+1$$\nSubtracting $(x_0-1)^{2}$ from both sides yields:\n$$(x_0-1)^{2} = 1$$\nTaking the square root of both sides gives two possibilities:\n$$x_0-1 = 1 \\quad \\text{or} \\quad x_0-1 = -1$$\nSolving for $x_0$ in each case:\n$$x_0 = 2 \\quad \\text{or} \\quad x_0 = 0$$\nThe problem explicitly requests the solution where the initial guess $x_0$ satisfies $x_0 > 1$. Therefore, the required initial guess is $x_0 = 2$.\n\nIf we start at $x_0=2$, the first iterate is $x_1=1$. The next step to find $x_2$ would require calculating $x_2 = x_1 - \\frac{f(x_1)}{f'(x_1)} = 1 - \\frac{f(1)}{f'(1)}$. Since $x^{\\ast}=1$ is the minimizer, the tangent line is horizontal, meaning $f'(1) = 2(1-1) = 0$. Division by zero makes the computation of $x_2$ undefined, as stated in the problem.\n\nFinally, we must briefly justify why the usual quadratic convergence theory for Newton's method does not apply. The theorem for quadratic convergence states that if a sequence of Newton iterates $\\{x_k\\}$ converges to a root $\\alpha$, and if $f'(\\alpha) \\neq 0$ (i.e., $\\alpha$ is a simple root) and $f$ is sufficiently smooth in a neighborhood of $\\alpha$, then the convergence is quadratic.\n\nThe primary reason this theory is inapplicable here is that its fundamental hypothesis is violated. The function is $f(x) = (x-1)^2+1$. Since $(x-1)^2 \\geq 0$ for all real $x$, the minimum value of the function is $f_{\\min} = 1$. Consequently, $f(x)=0$ has no real roots. Newton's method, when applied to this function, cannot converge to a real root because none exists. The theory of quadratic convergence describes the rate of approach to a root, a scenario that is not taking place.\n\nFurthermore, for the specific starting point $x_0=2$, the sequence of iterates is $\\{2, 1\\}$. This sequence terminates because the derivative is zero at $x_1=1$, making the next step undefined. Convergence rate is a property of an infinite sequence approaching a limit. Since the generated sequence is finite, the concept of convergence rate, whether quadratic or otherwise, is not meaningful.", "answer": "$$\\boxed{2}$$", "id": "3234373"}, {"introduction": "Newton's method is more than just a tool for finding pre-defined roots; it is a general framework for solving equations. This exercise showcases its versatility by challenging you to compute a number's reciprocal, $1/a$, using an iteration that cleverly avoids division altogether. This practice encourages you to think about how to creatively reformulate problems into a root-finding format, revealing the surprising power and elegance of numerical algorithms. [@problem_id:3234392]", "problem": "Consider a fixed real scalar $a \\neq 0$ and the task of computing its reciprocal $1/a$ using only multiplication and subtraction. Using the geometric interpretation of Newton’s method as the intersection of the tangent line of a function $f$ at the current iterate with the $x$-axis, formulate the computation of $1/a$ as a root-finding problem for a suitably chosen scalar function $f$ whose evaluation and Newton update can be algebraically reduced to an iteration that uses only multiplication and subtraction.\n\nStarting from the geometric definition of the Newton step (tangent-line $x$-intercept), proceed from first principles to:\n\n- Select a function $f$ with a simple root at $x^{\\star} = 1/a$.\n- Derive the explicit Newton iteration map $N_{a}(x)$ and simplify it algebraically to a form that uses only multiplication and subtraction.\n- Define the error $e_{k} = x_{k} - x^{\\star}$ and derive the exact quadratic error recurrence $e_{k+1} = C\\, e_{k}^{2}$ in a neighborhood of $x^{\\star}$, identifying the constant $C$ in terms of $a$.\n- Assume $a > 0$ and an initial guess $x_{0}$ satisfying $0 < a x_{0} < 2$ to ensure that all iterates remain well-defined and that the Newton step is geometrically meaningful.\n\nGive your final answer as the exact closed-form expression for the constant $C$ (no units). No numerical rounding is required.", "solution": "The problem requires the formulation of an iterative method to compute the reciprocal $1/a$ of a non-zero scalar $a$ using only multiplication and subtraction, based on the geometric interpretation of Newton's method. This involves selecting an appropriate function $f(x)$ whose root is the desired value, deriving the Newton iteration, and analyzing its error propagation to determine the quadratic convergence constant $C$.\n\n**Step 1: Problem Validation**\n\nThe problem is first validated against the required criteria.\n\n*   **Extraction of Givens**:\n    *   A fixed real scalar $a \\neq 0$.\n    *   Task: Compute $1/a$ using only multiplication and subtraction.\n    *   Method: Geometric interpretation of Newton's method.\n    *   The problem is to be formulated as a root-finding problem for a function $f(x)$.\n    *   The root of $f(x)$ must be $x^{\\star} = 1/a$.\n    *   The iteration map $N_a(x)$ must be simplified to a form using only multiplication and subtraction.\n    *   The error is defined as $e_k = x_k - x^{\\star}$.\n    *   The task is to derive the error recurrence $e_{k+1} = C \\, e_k^2$ and find the constant $C$.\n    *   An assumption for convergence is given: $a > 0$ and an initial guess $x_0$ satisfying $0 < a x_0 < 2$.\n\n*   **Validation Verdict**:\n    *   **Scientifically Grounded**: The problem is a standard application of Newton's method for root-finding, a fundamental topic in numerical analysis. The concepts of iteration, convergence, and error analysis are mathematically sound.\n    *   **Well-Posed**: The problem is clearly stated, provides all necessary information and conditions (including a convergence criterion), and leads to a unique, well-defined solution for the constant $C$.\n    *   **Objective**: The problem is stated in precise, objective mathematical language.\n\nThe problem is valid as it is mathematically sound, well-posed, and objective. We may proceed with the solution.\n\n**Step 2: Selection of an Appropriate Function $f(x)$**\n\nThe goal is to find $x^{\\star} = 1/a$. We need a function $f(x)$ such that $f(x^{\\star}) = f(1/a) = 0$. A simple choice that leads to the desired algebraic form for the iteration is:\n$$\nf(x) = a - \\frac{1}{x}\n$$\nClearly, $f(1/a) = a - 1/(1/a) = a - a = 0$. The root is a simple root because the derivative at the root is non-zero.\n\n**Step 3: Geometric Derivation and Simplification of the Newton Iteration**\n\nNewton's method finds the root of a function by iteratively finding the $x$-intercept of the tangent line to the function's graph at the current estimate. The equation of the tangent line to the curve $y = f(x)$ at the point $(x_k, f(x_k))$ is given by:\n$$\ny - f(x_k) = f'(x_k) (x - x_k)\n$$\nThe next iterate, $x_{k+1}$, is the $x$-intercept of this line, which is found by setting $y=0$:\n$$\n0 - f(x_k) = f'(x_k) (x_{k+1} - x_k)\n$$\nSolving for $x_{k+1}$ gives the general formula for Newton's method:\n$$\nx_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}\n$$\nFor our chosen function $f(x) = a - x^{-1}$, the derivative is:\n$$\nf'(x) = \\frac{d}{dx} (a - x^{-1}) = -(-1)x^{-2} = \\frac{1}{x^2}\n$$\nSubstituting $f(x_k)$ and $f'(x_k)$ into the Newton iteration formula:\n$$\nx_{k+1} = x_k - \\frac{a - \\frac{1}{x_k}}{\\frac{1}{x_k^2}}\n$$\nTo simplify this expression and eliminate division, we multiply the numerator and denominator of the fraction by $x_k^2$:\n$$\nx_{k+1} = x_k - x_k^2 \\left(a - \\frac{1}{x_k}\\right)\n$$\nDistributing the $x_k^2$ term:\n$$\nx_{k+1} = x_k - (a x_k^2 - x_k^2 \\cdot \\frac{1}{x_k})\n$$\n$$\nx_{k+1} = x_k - (a x_k^2 - x_k)\n$$\n$$\nx_{k+1} = x_k - a x_k^2 + x_k\n$$\nThis simplifies to the iteration map $N_a(x_k)$:\n$$\nx_{k+1} = 2 x_k - a x_k^2\n$$\nThis expression can also be written as $x_{k+1} = x_k(2 - a x_k)$, which confirms that it uses only multiplication and subtraction, as required.\n\n**Step 4: Derivation of the Error Recurrence Relation**\n\nThe root is $x^{\\star} = 1/a$. The error at iteration $k$ is defined as $e_k = x_k - x^{\\star} = x_k - 1/a$. This implies $x_k = e_k + 1/a$. The error at the next iteration is $e_{k+1} = x_{k+1} - x^{\\star} = x_{k+1} - 1/a$.\n\nWe substitute the iteration map for $x_{k+1}$:\n$$\ne_{k+1} = \\left(2 x_k - a x_k^2\\right) - \\frac{1}{a}\n$$\nNow, we express the right-hand side in terms of the error $e_k$ by substituting $x_k = e_k + 1/a$:\n$$\ne_{k+1} = 2\\left(e_k + \\frac{1}{a}\\right) - a\\left(e_k + \\frac{1}{a}\\right)^2 - \\frac{1}{a}\n$$\nExpand the terms:\n$$\ne_{k+1} = 2e_k + \\frac{2}{a} - a\\left(e_k^2 + \\frac{2e_k}{a} + \\frac{1}{a^2}\\right) - \\frac{1}{a}\n$$\nDistribute the $-a$ term:\n$$\ne_{k+1} = 2e_k + \\frac{2}{a} - a e_k^2 - a\\left(\\frac{2e_k}{a}\\right) - a\\left(\\frac{1}{a^2}\\right) - \\frac{1}{a}\n$$\n$$\ne_{k+1} = 2e_k + \\frac{2}{a} - a e_k^2 - 2e_k - \\frac{1}{a} - \\frac{1}{a}\n$$\nCombine like terms. The terms involving $e_k$ cancel out ($2e_k - 2e_k = 0$). The constant terms also cancel out ($2/a - 1/a - 1/a = 0$).\n$$\ne_{k+1} = (2e_k - 2e_k) + \\left(\\frac{2}{a} - \\frac{1}{a} - \\frac{1}{a}\\right) - a e_k^2\n$$\n$$\ne_{k+1} = -a e_k^2\n$$\nThis is the exact error recurrence relation. Comparing this to the specified form $e_{k+1} = C \\, e_k^2$, we can identify the constant $C$.\n\n**Step 5: Identification of the Constant $C$**\n\nBy direct comparison of the derived error relation $e_{k+1} = -a e_k^2$ with the general form $e_{k+1} = C e_k^2$, the constant $C$ is found to be:\n$$\nC = -a\n$$\nThe convergence condition $0 < a x_0 < 2$ translates to $-1 < a e_0 < 1$, which ensures that $|a e_k| < 1$ for all $k \\geq 0$, leading to quadratic convergence of $x_k$ to $1/a$.", "answer": "$$\\boxed{-a}$$", "id": "3234392"}, {"introduction": "Theoretical concepts like quadratic or linear convergence come to life when they are observed in practice. This final exercise equips you with the tools to become a numerical detective, allowing you to empirically measure the order of convergence from the output of an iterative method. You will first derive a practical formula for the convergence order and then implement it to verify the expected performance of Newton's method in different scenarios, including cases of simple roots, multiple roots, and even higher-order convergence. [@problem_id:3234430]", "problem": "Implement an experiment that connects the geometric construction of Newton’s method with its asymptotic error behavior to empirically estimate the order of convergence. Start from the following foundational base and derive all needed formulas from first principles:\n\n- Newton’s method is the root-finding iteration produced by intersecting the tangent line of a differentiable function $f$ at a current iterate $x_n$ with the horizontal axis, yielding the next iterate $x_{n+1}$.\n- The error at step $n$ is $e_n = x_n - \\alpha$, where $\\alpha$ is an actual root of $f$.\n- The definition of order of convergence states that there exist constants $C \\gt 0$ and $p \\ge 1$ such that $\\displaystyle \\lim_{n \\to \\infty} \\frac{|e_{n+1}|}{|e_n|^p} = C$.\n\nYour tasks are:\n1) From the geometric tangent-line interpretation of Newton’s method and first-order linearization, derive the Newton update $x_{n+1}$ in terms of $x_n$, $f(x_n)$, and $f'(x_n)$, without assuming any pre-given formula.\n2) From the definition of order of convergence, eliminate the unknown asymptotic constant by combining the relation at successive indices. Using three consecutive nonzero errors $e_{n-1}$, $e_n$, and $e_{n+1}$ and natural logarithms, derive a practical estimator that produces a per-iteration estimate of the order $p$ for sufficiently large $n$.\n3) Implement a program that:\n   - Generates Newton iterates $\\{x_n\\}$ for each specified test case, using the exact root $\\alpha$ to compute the errors $e_n = x_n - \\alpha$.\n   - Produces per-iteration estimates of the order $p$ based on your derivation in item $2)$, for all $n$ where three consecutive errors are available and the computation is well-defined.\n   - Returns a single empirical estimate for each test case by taking the median of the last $k$ valid per-iteration estimates (use $k = 5$, or all available if fewer than $5$ exist).\n   - Uses absolute errors to ensure the estimator is sign-agnostic.\n   - Terminates Newton’s iteration when $|e_n| \\lt \\text{tol}$ or when a maximum number of iterations is reached.\n\nTest suite:\n- Case A (simple root, expected quadratic behavior): $f(x) = x^2 - 2$, $f'(x) = 2x$, $\\alpha = \\sqrt{2}$, $x_0 = 1.5$, $\\text{tol} = 10^{-14}$, $\\text{max\\_iter} = 50$.\n- Case B (double root, expected linear behavior): $f(x) = (x-1)^2$, $f'(x) = 2(x-1)$, $\\alpha = 1$, $x_0 = 1.5$, $\\text{tol} = 10^{-14}$, $\\text{max\\_iter} = 50$.\n- Case C (simple root with vanishing second derivative at the root, expected cubic behavior): $f(x) = x + x^3$, $f'(x) = 1 + 3x^2$, $\\alpha = 0$, $x_0 = 0.2$, $\\text{tol} = 10^{-14}$, $\\text{max\\_iter} = 50$.\n\nAngle units are not applicable. There are no physical quantities, so no physical units are required.\n\nFinal output format:\n- Your program should produce a single line of output containing the three empirical order estimates for Cases A, B, and C, in that order, rounded to $6$ decimal places, as a comma-separated list enclosed in square brackets. For example, the printed line should look like $[p_A,p_B,p_C]$, where each $p$ is a decimal rounded to $6$ places.", "solution": "The task is to conduct a computational experiment to empirically estimate the order of convergence for Newton's method. This requires two preliminary derivations based on first principles: one for the Newton iteration formula itself and one for an estimator of the convergence order, $p$. We will then implement a program to apply these formulas to three specific test cases.\n\n### 1. Derivation of the Newton Iteration Formula\n\nThe first task is to derive the update rule for Newton's method from its geometric interpretation. The method approximates a function $f(x)$ near a root by its tangent line at the current iterate, $x_n$. The next iterate, $x_{n+1}$, is defined as the x-intercept of this tangent line.\n\nLet $f(x)$ be a differentiable function. The equation of the tangent line to the curve $y = f(x)$ at the point $(x_n, f(x_n))$ is given by the point-slope form:\n$$\ny - y_1 = m(x - x_1)\n$$\nHere, the point $(x_1, y_1)$ is $(x_n, f(x_n))$, and the slope $m$ is the derivative of the function evaluated at $x_n$, i.e., $m = f'(x_n)$. Substituting these into the line equation gives:\n$$\ny - f(x_n) = f'(x_n) (x - x_n)\n$$\nThe next iterate, $x_{n+1}$, is the x-coordinate of the point where this line intersects the horizontal axis. At the point of intersection, the y-coordinate is $0$. Therefore, we set $y=0$ and $x=x_{n+1}$:\n$$\n0 - f(x_n) = f'(x_n) (x_{n+1} - x_n)\n$$\nTo find $x_{n+1}$, we solve for it, assuming $f'(x_n) \\neq 0$:\n$$\n-f(x_n) = f'(x_n) x_{n+1} - f'(x_n) x_n\n$$\n$$\nf'(x_n) x_{n+1} = f'(x_n) x_n - f(x_n)\n$$\nDividing by $f'(x_n)$ yields the Newton iteration formula:\n$$\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\n$$\nThis formula provides the means to generate a sequence of iterates $\\{x_n\\}$ that, under suitable conditions, converge to a root $\\alpha$ of the function $f(x)$.\n\n### 2. Derivation of the Convergence Order Estimator\n\nThe second task is to derive a practical formula to estimate the order of convergence, $p$. The order of convergence describes how quickly the error of an iterative method decreases. The error at step $n$ is defined as $e_n = x_n - \\alpha$, where $\\alpha$ is the true root.\n\nThe formal definition for an iterative method having convergence order $p$ is that for some constant $C > 0$:\n$$\n\\lim_{n \\to \\infty} \\frac{|e_{n+1}|}{|e_n|^p} = C\n$$\nFor a sequence of iterates sufficiently close to the root (i.e., for large $n$), we can use this relationship as an approximation:\n$$\n\\frac{|e_{n+1}|}{|e_n|^p} \\approx C \\quad (1)\n$$\nThis approximation should also hold for the preceding pair of iterates:\n$$\n\\frac{|e_n|}{|e_{n-1}|^p} \\approx C \\quad (2)\n$$\nSince both expressions approximate the same asymptotic constant $C$, we can equate them to eliminate $C$:\n$$\n\\frac{|e_{n+1}|}{|e_n|^p} \\approx \\frac{|e_n|}{|e_{n-1}|^p}\n$$\nThe problem specifies using three consecutive nonzero errors $e_{n-1}$, $e_n$, and $e_{n+1}$. To solve for $p$, we rearrange the expression:\n$$\n|e_{n+1}| |e_{n-1}|^p \\approx |e_n|^{p+1}\n$$\nTaking the natural logarithm of both sides facilitates the isolation of $p$:\n$$\n\\ln(|e_{n+1}| |e_{n-1}|^p) \\approx \\ln(|e_n|^{p+1})\n$$\nUsing the properties of logarithms, $\\ln(ab) = \\ln(a) + \\ln(b)$ and $\\ln(a^b) = b\\ln(a)$, we get:\n$$\n\\ln|e_{n+1}| + p \\ln|e_{n-1}| \\approx (p+1) \\ln|e_n|\n$$\n$$\n\\ln|e_{n+1}| + p \\ln|e_{n-1}| \\approx p \\ln|e_n| + \\ln|e_n|\n$$\nNow, we group the terms containing $p$:\n$$\np \\ln|e_{n-1}| - p \\ln|e_n| \\approx \\ln|e_n| - \\ln|e_{n+1}|\n$$\n$$\np (\\ln|e_{n-1}| - \\ln|e_n|) \\approx \\ln|e_n| - \\ln|e_{n+1}|\n$$\nUsing the property $\\ln(a) - \\ln(b) = \\ln(a/b)$:\n$$\np \\ln\\left(\\frac{|e_{n-1}|}{|e_n|}\\right) \\approx \\ln\\left(\\frac{|e_n|}{|e_{n+1}|}\\right)\n$$\nFinally, solving for $p$ gives the per-iteration estimator:\n$$\np \\approx \\frac{\\ln\\left(|e_n|/|e_{n+1}|\\right)}{\\ln\\left(|e_{n-1}|/|e_n|\\right)}\n$$\nThis formula, which we will denote $p_n$, provides an estimate for the order of convergence at iteration $n$, given three consecutive errors $e_{n-1}$, $e_n$, and $e_{n+1}$. This estimator is well-defined as long as the errors are nonzero and $|e_{n-1}| \\neq |e_n|$.\n\n### 3. Implementation and Empirical Estimation\n\nThe computational part of the task involves implementing Newton's method and the derived order estimator. For each test case, the program will:\n1.  Initialize with the given starting value $x_0$.\n2.  Iteratively generate $x_1, x_2, \\ldots$ using the Newton update formula.\n3.  In each iteration $n$, compute the absolute error $|e_n| = |x_n - \\alpha|$. The iteration will terminate if $|e_n|$ drops below a tolerance $\\text{tol} = 10^{-14}$ or if a maximum of $\\text{max\\_iter} = 50$ iterations is reached.\n4.  Store the sequence of absolute errors.\n5.  After the iteration terminates, use the stored errors to compute a sequence of per-iteration order estimates $\\{p_n\\}$ using the derived estimator formula. An estimate $p_n$ is computed for each $n$ for which $e_{n-1}, e_n, e_{n+1}$ are available and the computation is well-defined.\n6.  A single empirical estimate of the order for the test case is then calculated by taking the median of the final $k=5$ valid per-iteration estimates. If fewer than $5$ estimates are available, the median of all available estimates is used. This approach provides a robust measure, as the estimator is most accurate for large $n$ when the iterates are close to the root.\n\nThe derived formulas and this computational strategy are sufficient to complete the required analysis for the provided test cases, which are chosen to exhibit quadratic ($p=2$), linear ($p=1$), and cubic ($p=3$) convergence, respectively.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements an experiment to empirically estimate the order of convergence\n    of Newton's method for three test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"f\": lambda x: x**2 - 2.0,\n            \"fp\": lambda x: 2.0 * x,\n            \"alpha\": np.sqrt(2.0),\n            \"x0\": 1.5,\n            \"tol\": 1e-14,\n            \"max_iter\": 50,\n        },\n        {\n            \"name\": \"Case B\",\n            \"f\": lambda x: (x - 1.0)**2,\n            \"fp\": lambda x: 2.0 * (x - 1.0),\n            \"alpha\": 1.0,\n            \"x0\": 1.5,\n            \"tol\": 1e-14,\n            \"max_iter\": 50,\n        },\n        {\n            \"name\": \"Case C\",\n            \"f\": lambda x: x + x**3,\n            \"fp\": lambda x: 1.0 + 3.0 * x**2,\n            \"alpha\": 0.0,\n            \"x0\": 0.2,\n            \"tol\": 1e-14,\n            \"max_iter\": 50,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        x_n = case[\"x0\"]\n        alpha = case[\"alpha\"]\n        tol = case[\"tol\"]\n        max_iter = case[\"max_iter\"]\n        f = case[\"f\"]\n        fp = case[\"fp\"]\n        \n        abs_errors = []\n        for _ in range(max_iter):\n            # Compute and store the absolute error\n            error = x_n - alpha\n            abs_err = np.abs(error)\n            abs_errors.append(abs_err)\n\n            # Check for termination\n            if abs_err < tol:\n                break\n\n            # Calculate the next iterate using Newton's method\n            f_xn = f(x_n)\n            fp_xn = fp(x_n)\n            \n            # Avoid division by zero, though not expected for these cases\n            # with the given initial guesses.\n            if fp_xn == 0:\n                break\n            \n            x_n = x_n - f_xn / fp_xn\n        \n        # We need at least 3 errors to compute one estimate of p\n        if len(abs_errors) < 3:\n            # If not enough errors are generated, we cannot estimate p.\n            # This can happen if x0 is already the root or very close.\n            # For this problem, this branch is not expected to be taken.\n            results.append(np.nan)\n            continue\n\n        p_estimates = []\n        # Iterate to compute per-iteration estimates of p\n        # We need e_{n-1}, e_n, e_{n+1}, which corresponds to\n        # abs_errors[i-1], abs_errors[i], abs_errors[i+1]\n        for i in range(1, len(abs_errors) - 1):\n            e_prev = abs_errors[i-1]\n            e_curr = abs_errors[i]\n            e_next = abs_errors[i+1]\n\n            # Ensure errors are non-zero to avoid issues with log\n            if e_prev == 0 or e_curr == 0 or e_next == 0:\n                continue\n\n            # Denominator of the estimator's main fraction cannot be zero\n            log_arg_denom = e_prev / e_curr\n            if log_arg_denom == 1.0:\n                continue\n\n            # Numerator of the estimator\n            log_arg_num = e_curr / e_next\n            \n            # Compute p using the derived formula\n            p = np.log(log_arg_num) / np.log(log_arg_denom)\n            p_estimates.append(p)\n        \n        # Calculate the final empirical estimate for the case\n        if not p_estimates:\n            # No valid p estimates could be computed.\n            results.append(np.nan)\n            continue\n            \n        k = 5\n        num_estimates = len(p_estimates)\n        \n        # Take the median of the last k estimates, or all if less than k\n        if num_estimates < k:\n            estimates_to_use = p_estimates\n        else:\n            estimates_to_use = p_estimates[-k:]\n        \n        p_final = np.median(estimates_to_use)\n        results.append(p_final)\n    \n    # Format the results to 6 decimal places for final output\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3234430"}]}