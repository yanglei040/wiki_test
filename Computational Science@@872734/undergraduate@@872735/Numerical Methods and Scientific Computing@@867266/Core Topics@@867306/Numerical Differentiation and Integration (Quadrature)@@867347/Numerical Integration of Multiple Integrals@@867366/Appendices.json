{"hands_on_practices": [{"introduction": "Many problems in science and engineering, from quantum mechanics to probability theory, involve integrals over an infinite domain. Directly applying standard quadrature rules is not feasible. This practice introduces Gauss-Hermite quadrature, a powerful technique specifically designed to handle integrals with a Gaussian weight function $e^{-x^2}$. You will see how the method leverages the properties of Hermite polynomials to efficiently and accurately approximate such integrals, transforming a seemingly intractable problem into a straightforward weighted sum. [@problem_id:3258802]", "problem": "Consider the two-dimensional integral of a smooth function against a Gaussian weight. Let $f(x,y)$ be a function for which the integral\n$$I = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} e^{-(x^2+y^2)} f(x,y)\\,dx\\,dy$$\nis finite. A well-tested numerical approach for such integrals uses product quadrature based on Hermite polynomials: one constructs a one-dimensional Gaussian quadrature for the weight $e^{-x^2}$ and applies it independently in each coordinate, forming a tensor-product rule for multiple integrals. This approach leverages the orthogonality of Hermite polynomials with respect to the Gaussian weight and the separability of the weight across dimensions.\n\nIn this problem, you will implement this approach to approximate\n$$I^\\star = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} e^{-(x^2+y^2)} \\cos(x+y)\\,dx\\,dy,$$\nwhere the cosine uses the radian measure for angles. The fundamental basis for your design is:\n- The definition of the Riemann integral and Fubini's theorem for interchanging the order of integration when integrability conditions are met.\n- The orthogonality of the Hermite polynomial family with respect to the Gaussian weight $e^{-x^2}$ on $(-\\infty,\\infty)$, which underlies Gaussian quadrature rules that exactly integrate polynomials up to a certain degree when weighted by $e^{-x^2}$.\n- The construction of multivariate product quadrature by applying one-dimensional rules dimension-wise for separable weights.\n\nYour program must:\n- Use a product Gauss-Hermite quadrature rule to approximate $I^\\star$.\n- Treat $\\cos(\\cdot)$ in radians.\n- Produce results for the following test suite, which varies the number of quadrature nodes per dimension to assess convergence, boundary behavior, and anisotropic sampling:\n    1. $(n_x,n_y) = (1,1)$\n    2. $(n_x,n_y) = (2,3)$\n    3. $(n_x,n_y) = (4,4)$\n    4. $(n_x,n_y) = (8,16)$\n    5. $(n_x,n_y) = (32,32)$\n\nFor each test case, compute a single floating-point approximation of $I^\\star$. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Express each approximation as a float rounded to ten decimal places. For example, an output with three results should look like:\n$[r_1,r_2,r_3],$\nwhere each $r_k$ is the ten-decimal-place rounded approximation for the $k$-th test case.\n\nNo physical units are involved; all angles are in radians. The program must be entirely self-contained, require no user input, and use only the specified libraries.", "solution": "The problem statement has been validated and is determined to be a well-posed and scientifically sound problem in the field of numerical analysis. It requests the numerical approximation of a specific two-dimensional integral using a standard, clearly defined method. All necessary data and parameters are provided.\n\nThe objective is to approximate the two-dimensional integral\n$$I^\\star = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} e^{-(x^2+y^2)} \\cos(x+y)\\,dx\\,dy$$\nThe integrand consists of a Gaussian weight function, $w(x,y) = e^{-(x^2+y^2)}$, and a function $f(x,y) = \\cos(x+y)$. The specified numerical method is a product Gauss-Hermite quadrature rule, which is particularly well-suited for integrals of this form due to the properties of Hermite polynomials and the separability of the weight function.\n\nThe foundational principle is the one-dimensional Gauss-Hermite quadrature rule. This rule approximates an integral over the real line with a Gaussian weight as a discrete weighted sum:\n$$ \\int_{-\\infty}^{\\infty} e^{-t^2} g(t)\\,dt \\approx \\sum_{k=1}^{n} w_k g(t_k) $$\nIn this formula, $n$ represents the number of quadrature nodes. The nodes $\\{t_k\\}_{k=1}^n$ are the roots of the $n$-th degree physicist's Hermite polynomial, $H_n(t)$. The associated weights $\\{w_k\\}_{k=1}^n$ are specifically calculated such that the approximation is exact if $g(t)$ is any polynomial of degree up to $2n-1$. This high degree of accuracy for polynomial integrands makes the method powerful for approximating integrals of smooth functions, which can be locally well-approximated by polynomials.\n\nFor the two-dimensional integral $I^\\star$, the separability of the weight function, $w(x,y) = e^{-x^2}e^{-y^2}$, allows for the construction of a product rule. By applying Fubini's theorem, we can express the double integral as an iterated integral:\n$$ I^\\star = \\int_{-\\infty}^{\\infty} e^{-y^2} \\left( \\int_{-\\infty}^{\\infty} e^{-x^2} \\cos(x+y)\\,dx \\right) dy $$\nThe numerical approximation is performed hierarchically. First, for a fixed value of $y$, the inner integral with respect to $x$ is approximated using an $n_x$-point Gauss-Hermite rule with nodes $\\{x_i\\}_{i=1}^{n_x}$ and weights $\\{w_i^{(x)}\\}_{i=1}^{n_x}$:\n$$ \\int_{-\\infty}^{\\infty} e^{-x^2} \\cos(x+y)\\,dx \\approx \\sum_{i=1}^{n_x} w_i^{(x)} \\cos(x_i+y) $$\nThis approximation is then substituted into the outer integral over $y$:\n$$ I^\\star \\approx \\int_{-\\infty}^{\\infty} e^{-y^2} \\left( \\sum_{i=1}^{n_x} w_i^{(x)} \\cos(x_i+y) \\right) dy $$\nThe finite nature of the sum permits the interchange of the integration and summation operators:\n$$ I^\\star \\approx \\sum_{i=1}^{n_x} w_i^{(x)} \\int_{-\\infty}^{\\infty} e^{-y^2} \\cos(x_i+y)\\,dy $$\nFinally, the remaining integral over $y$ is approximated for each fixed $x_i$ using an $n_y$-point Gauss-Hermite rule with nodes $\\{y_j\\}_{j=1}^{n_y}$ and weights $\\{w_j^{(y)}\\}_{j=1}^{n_y}$:\n$$ \\int_{-\\infty}^{\\infty} e^{-y^2} \\cos(x_i+y)\\,dy \\approx \\sum_{j=1}^{n_y} w_j^{(y)} \\cos(x_i+y_j) $$\nCombining these steps yields the final tensor-product quadrature formula for the approximation of $I^\\star$:\n$$ I^\\star \\approx \\sum_{i=1}^{n_x} \\sum_{j=1}^{n_y} w_i^{(x)} w_j^{(y)} \\cos(x_i+y_j) $$\nThis formula directs us to evaluate the function $f(x,y) = \\cos(x+y)$ on a two-dimensional grid of points $(x_i, y_j)$, and then compute a weighted sum where the weight for each point is the product of the corresponding one-dimensional quadrature weights, $w_i^{(x)} w_j^{(y)}$.\n\nThe implementation will utilize the `numpy.polynomial.hermite.hermgauss` function, which provides the necessary nodes and weights for a given number of points $n$. The double summation is computed for each test case $(n_x, n_y)$ as specified in the problem statement. The convergence of the approximation to the true value of the integral, which can be shown analytically to be $I^\\star = \\pi e^{-1/2} \\approx 1.9045137660$, is expected to be rapid as $n_x$ and $n_y$ increase, due to the smoothness of the function $\\cos(x+y)$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes approximations of a 2D integral using product Gauss-Hermite quadrature\n    for a series of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple represents (n_x, n_y), the number of quadrature nodes in\n    # the x and y dimensions, respectively.\n    test_cases = [\n        (1, 1),\n        (2, 3),\n        (4, 4),\n        (8, 16),\n        (32, 32),\n    ]\n\n    results = []\n    for nx, ny in test_cases:\n        # The integral to approximate is:\n        # I = integral from -inf to inf, integral from -inf to inf of\n        #     e^-(x^2+y^2) * cos(x+y) dx dy\n        # This is approximated by the sum:\n        # Sum_i Sum_j w_i * w_j * cos(x_i + y_j)\n        # where (x_i, w_i) and (y_j, w_j) are Gauss-Hermite nodes and weights.\n\n        # Fetch the 1D Gauss-Hermite quadrature nodes and weights.\n        # The function np.polynomial.hermite.hermgauss is designed for integrals\n        # with the weight function e^(-x^2).\n        x_nodes, x_weights = np.polynomial.hermite.hermgauss(nx)\n        y_nodes, y_weights = np.polynomial.hermite.hermgauss(ny)\n\n        # To implement the double summation efficiently, we use NumPy's broadcasting\n        # and outer products.\n\n        # 1. Create a matrix of product weights.\n        #    The element at (j, i) will be y_weights[j] * x_weights[i].\n        weights_matrix = np.outer(y_weights, x_weights)\n\n        # 2. Create a matrix of node sums for the function argument.\n        #    The element at (j, i) will be y_nodes[j] + x_nodes[i].\n        nodes_sum_matrix = np.add.outer(y_nodes, x_nodes)\n\n        # 3. Evaluate the function cos(x+y) on the grid of nodes.\n        #    The angles are in radians, as is standard for `np.cos`.\n        integrand_values = np.cos(nodes_sum_matrix)\n\n        # 4. Compute the final sum by element-wise multiplication and summation.\n        integral_approximation = np.sum(weights_matrix * integrand_values)\n\n        # Round the result to ten decimal places as specified.\n        rounded_result = round(integral_approximation, 10)\n        results.append(rounded_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3258802"}, {"introduction": "Real-world problems rarely involve simple rectangular domains; we often need to integrate over complex shapes like spheres, cylinders, or ellipsoids. This exercise demonstrates a critical skill in numerical integration: transforming a complex integration domain into a simpler one. By applying a sequence of coordinate transformations and correctly accounting for the change in volume using the Jacobian determinant, you will learn how to adapt standard quadrature methods to work on virtually any well-behaved domain. [@problem_id:3258887]", "problem": "Consider the function $f(x,y,z) = \\sin(x)\\cos(y)e^{z}$ and the family of ellipsoids defined by\n$$\\mathcal{E}(a,b,c;x_0,y_0,z_0) = \\left\\{(x,y,z) \\in \\mathbb{R}^3 \\,\\bigg|\\, \\left(\\frac{x - x_0}{a}\\right)^2 + \\left(\\frac{y - y_0}{b}\\right)^2 + \\left(\\frac{z - z_0}{c}\\right)^2 \\le 1 \\right\\},$$\nwith $a>0$, $b>0$, $c>0$. The average value of $f$ over a volume $V$ is defined fundamentally by\n$$\\langle f \\rangle_V = \\frac{1}{\\operatorname{Vol}(V)} \\iiint_V f(x,y,z)\\, \\mathrm{d}V.$$\nYour task is to design and implement a complete, runnable program that numerically approximates $\\langle f \\rangle_{\\mathcal{E}(a,b,c;x_0,y_0,z_0)}$ for the parameter sets below. You must:\n- Start from the definition of average over a volume and derive a numerically stable algorithm based on a well-posed change of variables that maps $\\mathcal{E}(a,b,c;x_0,y_0,z_0)$ to a canonical domain whose integration measure is accounted for via the appropriate Jacobian determinant.\n- Choose a sound quadrature scheme to approximate the resulting triple integral. You may assume access to orthogonal polynomial nodes and weights (for example, Gauss–Legendre quadrature), but you must derive how they are applied to the transformed integral from first principles. All angles must be measured in radians.\n- Ensure the computation is dimensionally consistent, with all intermediate steps grounded in the definition of multiple integrals and change-of-variables. No shortcuts are permitted; the numerical method must follow from the integral definition and transformations.\n\nTest suite:\n- Case $1$ (happy path): $(a,b,c) = (1,1,1)$, $(x_0,y_0,z_0) = (0,0,0)$, quadrature orders $(N_r, N_\\theta, N_\\phi) = (24,24,24)$.\n- Case $2$ (small axis boundary): $(a,b,c) = (2,1,0.5)$, $(x_0,y_0,z_0) = (0.2,-0.3,0.1)$, quadrature orders $(N_r, N_\\theta, N_\\phi) = (28,28,32)$.\n- Case $3$ (shifted center): $(a,b,c) = (0.75,1.5,1.25)$, $(x_0,y_0,z_0) = (1.0,2.0,-1.0)$, quadrature orders $(N_r, N_\\theta, N_\\phi) = (32,32,36)$.\n- Case $4$ (high aspect ratio edge): $(a,b,c) = (3.0,3.0,0.2)$, $(x_0,y_0,z_0) = (0,0,0)$, quadrature orders $(N_r, N_\\theta, N_\\phi) = (36,48,64)$.\n\nAngle unit: All trigonometric function arguments must be in radians.\n\nFinal output specification:\n- Your program must produce a single line of output containing the four numerical approximations, in the order of the test suite above, rounded to $6$ decimal places, as a comma-separated list enclosed in square brackets; for example, $[r_1,r_2,r_3,r_4],$ where each $r_k$ is a decimal number with exactly $6$ digits after the decimal point.", "solution": "The user-provided problem is assessed as valid. It is a well-posed, scientifically grounded problem in the field of numerical methods, with a complete and consistent set of givens.\n\nThe objective is to compute the average value of a function $f(x,y,z)$ over an ellipsoidal volume $\\mathcal{E}$. The average value is defined as:\n$$\n\\langle f \\rangle_{\\mathcal{E}} = \\frac{1}{\\operatorname{Vol}(\\mathcal{E})} \\iiint_{\\mathcal{E}} f(x,y,z) \\, \\mathrm{d}V\n$$\nThe specific function is $f(x,y,z) = \\sin(x)\\cos(y)e^z$. The domain is the ellipsoid $\\mathcal{E}(a,b,c; x_0, y_0, z_0)$ defined by the inequality:\n$$\n\\left(\\frac{x - x_0}{a}\\right)^2 + \\left(\\frac{y - y_0}{b}\\right)^2 + \\left(\\frac{z - z_0}{c}\\right)^2 \\le 1\n$$\nThe volume of this ellipsoid is a standard result, $\\operatorname{Vol}(\\mathcal{E}) = \\frac{4}{3}\\pi abc$.\n\nThe core of the problem is the numerical evaluation of the triple integral $I = \\iiint_{\\mathcal{E}} f(x,y,z) \\, \\mathrm{d}V$. The ellipsoidal domain is ill-suited for direct integration. A change of variables is necessary to transform the domain into a more convenient shape, such as a unit ball.\n\nFirst, we introduce an affine transformation from a new coordinate system $(u,v,w)$ to the original $(x,y,z)$ coordinates:\n$$\nx = a u + x_0 \\\\\ny = b v + y_0 \\\\\nz = c w + z_0\n$$\nThis transformation maps the unit ball $B = \\{(u,v,w) \\in \\mathbb{R}^3 \\mid u^2+v^2+w^2 \\le 1\\}$ to the ellipsoid $\\mathcal{E}$. To apply the change of variables theorem for multiple integrals, we must compute the determinant of the Jacobian matrix of this transformation. The Jacobian matrix is:\n$$\n\\mathbf{J}_{(u,v,w)\\to(x,y,z)} = \\frac{\\partial(x,y,z)}{\\partial(u,v,w)} = \\begin{pmatrix} \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} & \\frac{\\partial x}{\\partial w} \\\\ \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v} & \\frac{\\partial y}{\\partial w} \\\\ \\frac{\\partial z}{\\partial u} & \\frac{\\partial z}{\\partial v} & \\frac{\\partial z}{\\partial w} \\end{pmatrix} = \\begin{pmatrix} a & 0 & 0 \\\\ 0 & b & 0 \\\\ 0 & 0 & c \\end{pmatrix}\n$$\nThe absolute value of its determinant is $|\\det(\\mathbf{J})| = |abc| = abc$, since the semi-axes $a, b, c$ are strictly positive. The volume element transforms as $\\mathrm{d}V = \\mathrm{d}x\\,\\mathrm{d}y\\,\\mathrm{d}z = abc \\, \\mathrm{d}u\\,\\mathrm{d}v\\,\\mathrm{d}w$.\n\nThe integral $I$ is now expressed over the unit ball $B$:\n$$\nI = \\iiint_{B} f(a u + x_0, b v + y_0, c w + z_0) \\, (abc) \\, \\mathrm{d}u\\,\\mathrm{d}v\\,\\mathrm{d}w\n$$\nThe average value of $f$ can be rewritten using this transformed integral:\n$$\n\\langle f \\rangle_{\\mathcal{E}} = \\frac{abc \\iiint_{B} f(a u + x_0, b v + y_0, c w + z_0) \\, \\mathrm{d}u\\,\\mathrm{d}v\\,\\mathrm{d}w}{\\frac{4}{3}\\pi abc}\n$$\nThe $abc$ term cancels, which simplifies the expression to an average over the unit ball:\n$$\n\\langle f \\rangle_{\\mathcal{E}} = \\frac{1}{\\operatorname{Vol}(B)} \\iiint_{B} f(a u + x_0, b v + y_0, c w + z_0) \\, \\mathrm{d}u\\,\\mathrm{d}v\\,\\mathrm{d}w\n$$\nwhere $\\operatorname{Vol}(B) = \\frac{4}{3}\\pi$.\n\nThe unit ball is best handled using spherical coordinates. We apply a second change of variables from spherical coordinates $(r, \\theta, \\phi)$ to the Cartesian coordinates $(u,v,w)$:\n$$\nu = r \\sin\\theta \\cos\\phi \\\\\nv = r \\sin\\theta \\sin\\phi \\\\\nw = r \\cos\\theta\n$$\nThe integration domain for the unit ball in these coordinates is $r \\in [0, 1]$, $\\theta \\in [0, \\pi]$, and $\\phi \\in [0, 2\\pi]$. The differential volume element is $\\mathrm{d}u\\,\\mathrm{d}v\\,\\mathrm{d}w = r^2 \\sin\\theta \\, \\mathrm{d}r\\,\\mathrm{d}\\theta\\,\\mathrm{d}\\phi$.\n\nLet the transformed integrand function be $g(r, \\theta, \\phi) = f(x(r,\\theta,\\phi), y(r,\\theta,\\phi), z(r,\\theta,\\phi))$, where:\n$$\nx(r,\\theta,\\phi) = a (r \\sin\\theta \\cos\\phi) + x_0 \\\\\ny(r,\\theta,\\phi) = b (r \\sin\\theta \\sin\\phi) + y_0 \\\\\nz(r,\\theta,\\phi) = c (r \\cos\\theta) + z_0\n$$\nThe integral over the unit ball becomes:\n$$\n\\iiint_{B} g \\cdot \\mathrm{d}V_u = \\int_0^{2\\pi} \\int_0^{\\pi} \\int_0^1 g(r, \\theta, \\phi) \\, r^2 \\sin\\theta \\, \\mathrm{d}r\\,\\mathrm{d}\\theta\\,\\mathrm{d}\\phi\n$$\nThe average value is therefore:\n$$\n\\langle f \\rangle_{\\mathcal{E}} = \\frac{3}{4\\pi} \\int_0^{2\\pi} \\int_0^{\\pi} \\int_0^1 \\sin(x(r, \\theta, \\phi))\\cos(y(r, \\theta, \\phi))e^{z(r, \\theta, \\phi)} \\, r^2 \\sin\\theta \\, \\mathrm{d}r\\,\\mathrm{d}\\theta\\,\\mathrm{d}\\phi\n$$\nThis triple integral is now in a form suitable for numerical quadrature. We use Gauss-Legendre quadrature. A one-dimensional integral $\\int_A^B H(\\xi)\\,\\mathrm{d}\\xi$ is approximated by transforming the interval $[A, B]$ to $[-1, 1]$ and applying the quadrature rule:\n$$\n\\int_A^B H(\\xi)\\,\\mathrm{d}\\xi = \\frac{B-A}{2} \\int_{-1}^1 H\\left(\\frac{B-A}{2}\\zeta + \\frac{A+B}{2}\\right)\\,\\mathrm{d}\\zeta \\approx \\frac{B-A}{2} \\sum_{i=1}^N w_i H\\left(\\frac{B-A}{2}\\zeta_i + \\frac{A+B}{2}\\right)\n$$\nwhere $\\zeta_i$ and $w_i$ are the Gauss-Legendre nodes and weights of order $N$.\n\nWe apply this to each of the three integrals in $r, \\theta, \\phi$ with orders $N_r, N_\\theta, N_\\phi$:\n1. For $r \\in [0, 1]$: Factor is $\\frac{1-0}{2}=\\frac{1}{2}$. Nodes are $\\tilde{r}_i = \\frac{1}{2}(\\zeta_{r,i}+1)$.\n2. For $\\theta \\in [0, \\pi]$: Factor is $\\frac{\\pi-0}{2}=\\frac{\\pi}{2}$. Nodes are $\\tilde{\\theta}_j = \\frac{\\pi}{2}(\\zeta_{\\theta,j}+1)$.\n3. For $\\phi \\in [0, 2\\pi]$: Factor is $\\frac{2\\pi-0}{2}=\\pi$. Nodes are $\\tilde{\\phi}_k = \\pi(\\zeta_{\\phi,k}+1)$.\n\nThe total scaling factor from these transformations is $(\\frac{1}{2}) (\\frac{\\pi}{2}) (\\pi) = \\frac{\\pi^2}{4}$.\n\nLet $F(r,\\theta,\\phi) = \\sin(x(r,\\theta,\\phi))\\cos(y(r,\\theta,\\phi))e^{z(r,\\theta,\\phi)} r^2 \\sin\\theta$. The numerical approximation of the integral is:\n$$\n\\int_0^{2\\pi} \\! \\int_0^{\\pi} \\! \\int_0^1 \\! F \\, \\mathrm{d}r \\mathrm{d}\\theta \\mathrm{d}\\phi \\approx \\frac{\\pi^2}{4} \\sum_{i=1}^{N_r} \\sum_{j=1}^{N_\\theta} \\sum_{k=1}^{N_\\phi} w_{r,i} w_{\\theta,j} w_{\\phi,k} F(\\tilde{r}_i, \\tilde{\\theta}_j, \\tilde{\\phi}_k)\n$$\nSubstituting this back into the expression for the average value:\n$$\n\\langle f \\rangle_{\\mathcal{E}} \\approx \\frac{3}{4\\pi} \\left( \\frac{\\pi^2}{4} \\sum_{i,j,k} w_{r,i} w_{\\theta,j} w_{\\phi,k} F(\\tilde{r}_i, \\tilde{\\theta}_j, \\tilde{\\phi}_k) \\right)\n$$\n$$\n\\langle f \\rangle_{\\mathcal{E}} \\approx \\frac{3\\pi}{16} \\sum_{i=1}^{N_r} \\sum_{j=1}^{N_\\theta} \\sum_{k=1}^{N_\\phi} w_{r,i} w_{\\theta,j} w_{\\phi,k} \\sin(x_{ijk})\\cos(y_{ijk})e^{z_{ijk}} \\tilde{r}_i^2 \\sin(\\tilde{\\theta}_j)\n$$\nwhere $x_{ijk}, y_{ijk}, z_{ijk}$ are evaluated at the quadrature nodes $(\\tilde{r}_i, \\tilde{\\theta}_j, \\tilde{\\phi}_k)$. This is the final formula for the numerical algorithm. The implementation will use vectorized operations for efficiency.\n\nNotably, for cases where the ellipsoid is centered at the origin ($(x_0, y_0, z_0) = (0,0,0)$), the integration domain $\\mathcal{E}$ is symmetric with respect to the origin. The function to be integrated, $f(x,y,z)=\\sin(x)\\cos(y)e^z$, is odd with respect to the variable $x$ (i.e., $f(-x,y,z) = -f(x,y,z)$). Since the domain is symmetric with respect to the $y-z$ plane (the plane $x=0$), the exact value of the integral is zero. Test cases $1$ and $4$ fall into this category, and the numerical result is expected to be close to zero, limited only by floating-point precision.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It calculates the average value of a function over an ellipsoidal volume\n    using Gauss-Legendre quadrature based on a rigorous derivation.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: (a,b,c), (x0,y0,z0), (Nr,Ntheta,Nphi)\n        ((1, 1, 1), (0, 0, 0), (24, 24, 24)),\n        # Case 2\n        ((2, 1, 0.5), (0.2, -0.3, 0.1), (28, 28, 32)),\n        # Case 3\n        ((0.75, 1.5, 1.25), (1.0, 2.0, -1.0), (32, 32, 36)),\n        # Case 4\n        ((3.0, 3.0, 0.2), (0, 0, 0), (36, 48, 64)),\n    ]\n\n    results = []\n    for case in test_cases:\n        params, center, orders = case\n        a, b, c = params\n        x0, y0, z0 = center\n        Nr, Ntheta, Nphi = orders\n        \n        # Calculate the numerical approximation for the current case.\n        avg_value = calculate_average_value(a, b, c, x0, y0, z0, Nr, Ntheta, Nphi)\n        results.append(avg_value)\n\n    # Format the results to 6 decimal places and print in the specified format.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef calculate_average_value(a, b, c, x0, y0, z0, Nr, Ntheta, Nphi):\n    \"\"\"\n    Numerically approximates the average value of f(x,y,z) over an ellipsoid.\n\n    Follows the derived formula:\n    <f> ≈ (3π/16) * Σ [w_r*w_θ*w_φ * sin(x)cos(y)exp(z) * r^2*sin(θ)]\n    where the sum is over the grid of Gauss-Legendre quadrature points.\n    \"\"\"\n\n    # Step 1: Get Gauss-Legendre nodes and weights for the interval [-1, 1]\n    zeta_r, w_r = np.polynomial.legendre.leggauss(Nr)\n    zeta_theta, w_theta = np.polynomial.legendre.leggauss(Ntheta)\n    zeta_phi, w_phi = np.polynomial.legendre.leggauss(Nphi)\n\n    # Step 2: Transform nodes to the integration intervals [0,1], [0,π], [0,2π]\n    r_nodes = 0.5 * (zeta_r + 1.0)\n    theta_nodes = 0.5 * np.pi * (zeta_theta + 1.0)\n    phi_nodes = np.pi * (zeta_phi + 1.0)\n    \n    # Step 3: Create a 3D grid of nodes and weights for vectorized computation\n    # 'ij' indexing ensures r varies on axis 0, theta on axis 1, phi on axis 2\n    r, th, ph = np.meshgrid(r_nodes, theta_nodes, phi_nodes, indexing='ij')\n    wr, wth, wph = np.meshgrid(w_r, w_theta, w_phi, indexing='ij')\n\n    # Step 4: Map from spherical coordinates (r, th, ph) to intermediate (u,v,w)\n    u = r * np.sin(th) * np.cos(ph)\n    v = r * np.sin(th) * np.sin(ph)\n    w = r * np.cos(th)\n    \n    # Step 5: Map from intermediate (u,v,w) to final (x,y,z) coordinates\n    x = a * u + x0\n    y = b * v + y0\n    z = c * w + z0\n    \n    # Step 6: Evaluate the function to be integrated at each grid point\n    # This includes the function f(x,y,z) and the Jacobian term from spherical coordinates\n    integrand = np.sin(x) * np.cos(y) * np.exp(z) * r**2 * np.sin(th)\n    \n    # Step 7: Calculate the full weighted sum over the 3D grid\n    # This approximates the integral over the unit ball in (u,v,w) space,\n    # including the scale factors from changing integration variables.\n    # The factors are (1/2) for r, (π/2) for theta, (π) for phi.\n    integral_approximation = (1/2) * (np.pi/2) * np.pi * np.sum(wr * wth * wph * integrand)\n\n    # Step 8: Apply the pre-factor for the average value calculation\n    # The average value is (integral) / Volume = (integral) / (4/3 * π)\n    # The pre-factor here (3π/16) is a combination of the quadrature mapping factors\n    # and the 1/Volume term: (3 / (4*pi)) * (pi**2 / 4) = 3*pi/16.\n    # It is derived in the solution text.\n    # <f> = (3 / (4π)) * I\n    # I ≈ (π^2/4) * sum(...)\n    # <f> ≈ (3 / (4π)) * (π^2/4) * sum(...) = (3π/16) * sum(...)\n    \n    # To be more direct and less prone to combining factors incorrectly:\n    # 1. Calculate the sum of weights times the integrand function F(r,theta,phi)\n    # F = sin(x)*cos(y)*exp(z) * r^2*sin(theta)\n    integrand_without_jacobians = np.sin(x) * np.cos(y) * np.exp(z)\n    \n    # The full integrand in (r,theta,phi) space is F * r^2 * sin(theta)\n    full_integrand = integrand_without_jacobians * r**2 * np.sin(th)\n    \n    # The sum using weights approximates the integral over [-1,1]^3 cube\n    sum_val = np.sum(wr * wth * wph * full_integrand)\n    \n    # The integral over [0,1]x[0,pi]x[0,2pi] includes interval-mapping factors\n    unit_ball_integral = sum_val * (1./2.) * (np.pi/2.) * (np.pi)\n    \n    # The average value is this integral divided by the volume of the unit ball (4/3 pi)\n    average = unit_ball_integral / ((4./3.) * np.pi)\n\n    return average\n\nsolve()\n```", "id": "3258887"}, {"introduction": "As the number of dimensions in an integral increases, traditional grid-based methods become computationally impossible due to the 'curse of dimensionality'. This is where Monte Carlo integration provides a powerful alternative. In this practice, you will use a probabilistic approach to estimate the volume of a 4-dimensional hypersphere, a task that is difficult for grid methods but surprisingly straightforward for Monte Carlo. This exercise offers a first-hand look at how random sampling can overcome the challenges of high-dimensional spaces. [@problem_id:3258918]", "problem": "Consider the volume of a $4$-dimensional ball (hypersphere) of radius $R$. The volume can be expressed as a multiple integral of an indicator function over $\\mathbb{R}^4$, and estimated using Monte Carlo integration. Your task is to design and implement a complete program that numerically estimates this volume with Monte Carlo integration and compares it to the analytical result derived from a well-tested general formula.\n\nStart from the following fundamental bases:\n- The volume of a measurable region $\\Omega \\subset \\mathbb{R}^d$ equals the integral of its indicator function $I_{\\Omega}(\\mathbf{x})$ over $\\mathbb{R}^d$, that is, $\\mathrm{Vol}(\\Omega) = \\int_{\\mathbb{R}^d} I_{\\Omega}(\\mathbf{x}) \\, d\\mathbf{x}$, where $I_{\\Omega}(\\mathbf{x}) = 1$ if $\\mathbf{x} \\in \\Omega$ and $I_{\\Omega}(\\mathbf{x}) = 0$ otherwise.\n- Monte Carlo integration estimates $\\int_{D} f(\\mathbf{x}) \\, d\\mathbf{x}$ by sampling $\\mathbf{X}_1,\\dots,\\mathbf{X}_N$ uniformly from a domain $D$ of finite measure $|D|$, and computing $\\widehat{I}_N = |D|\\cdot \\frac{1}{N}\\sum_{i=1}^{N} f(\\mathbf{X}_i)$.\n- The well-tested general formula for the volume of an $n$-dimensional ball of radius $R$ is $V_n(R) = \\dfrac{\\pi^{n/2} R^n}{\\Gamma\\!\\left(\\frac{n}{2}+1\\right)}$, where $\\Gamma$ is the Gamma function.\n\nTasks to accomplish within your program:\n1. Express the volume of the $4$-dimensional ball of radius $R$ as an integral of an indicator function over a bounding hypercube $D = [-R,R]^4$ and design a Monte Carlo estimator using $N$ independent and identically distributed samples drawn uniformly from $D$ to estimate this integral.\n2. Using the general $n$-ball formula and properties of the Gamma function, derive the analytical closed form for the exact volume in dimension $n=4$ as a function of $R$.\n3. For each test case below, compute:\n   - The Monte Carlo estimate $\\widehat{V}$ of the volume using your estimator.\n   - The exact analytical volume $V_{\\text{exact}}$.\n   - The error metric $E$ defined as follows:\n     - If $V_{\\text{exact}} > 0$, use the relative error $E = \\dfrac{|\\widehat{V} - V_{\\text{exact}}|}{V_{\\text{exact}}}$.\n     - If $V_{\\text{exact}} = 0$, use the absolute error $E = |\\widehat{V} - V_{\\text{exact}}|$.\n   - Round each error $E$ to $6$ decimal places.\n\nImplementation requirements:\n- The program must be a single, self-contained script that uses only the Python standard library and the Numerical Python (NumPy) library.\n- The program must not read any input; it must hard-code the test suite below and produce a single line of output.\n- Randomness must be reproducible by initializing a pseudorandom number generator with the provided seeds.\n\nTest suite:\n- Case $1$: $R = 1.0$, $N = 200000$, $\\text{seed} = 12345$.\n- Case $2$: $R = 0.0$, $N = 10000$, $\\text{seed} = 2023$.\n- Case $3$: $R = 1.0$, $N = 1$, $\\text{seed} = 7$.\n- Case $4$: $R = 1.5$, $N = 150000$, $\\text{seed} = 314159$.\n- Case $5$: $R = 2.0$, $N = 120000$, $\\text{seed} = 424242$.\n\nFinal output format:\n- Your program should produce a single line of output containing the errors for the test cases as a comma-separated list enclosed in square brackets, in the same order as the cases listed above, with each error rounded to $6$ decimal places, for example, $[e_1,e_2,e_3,e_4,e_5]$ where each $e_i$ is a decimal numeral.", "solution": "The problem requires the numerical estimation of the volume of a $4$-dimensional ball (a hypersphere) of radius $R$ using Monte Carlo integration. This estimate will be compared against the exact analytical volume to compute an error metric. The process involves three main steps: deriving the analytical formula for the volume, designing the Monte Carlo estimator, and implementing the computation for a given set of test cases.\n\n### 1. Analytical Volume of a 4-Dimensional Ball\n\nThe problem provides the general formula for the volume of an $n$-dimensional ball of radius $R$:\n$$V_n(R) = \\frac{\\pi^{n/2} R^n}{\\Gamma\\left(\\frac{n}{2}+1\\right)}$$\nwhere $\\Gamma(z)$ is the Gamma function.\n\nFor our specific case, the dimension is $n=4$. Substituting $n=4$ into the formula yields:\n$$V_4(R) = \\frac{\\pi^{4/2} R^4}{\\Gamma\\left(\\frac{4}{2}+1\\right)} = \\frac{\\pi^2 R^4}{\\Gamma(2+1)} = \\frac{\\pi^2 R^4}{\\Gamma(3)}$$\nThe Gamma function has the property that for any positive integer $k$, $\\Gamma(k) = (k-1)!$. Therefore, for $k=3$:\n$$\\Gamma(3) = (3-1)! = 2! = 2 \\cdot 1 = 2$$\nSubstituting this result back into the volume formula gives the exact analytical expression for the volume of a $4$-ball of radius $R$:\n$$V_{\\text{exact}} = V_4(R) = \\frac{\\pi^2 R^4}{2}$$\n\n### 2. Monte Carlo Estimator Design\n\nThe volume of a region $\\Omega \\subset \\mathbb{R}^4$ can be expressed as the integral of its indicator function $I_{\\Omega}(\\mathbf{x})$:\n$$V = \\int_{\\mathbb{R}^4} I_{\\Omega}(\\mathbf{x}) \\, d\\mathbf{x}$$\nwhere $I_{\\Omega}(\\mathbf{x}) = 1$ if $\\mathbf{x} \\in \\Omega$ and $I_{\\Omega}(\\mathbf{x}) = 0$ otherwise. For a $4$-ball of radius $R$ centered at the origin, the region is $\\Omega = \\{ \\mathbf{x} \\in \\mathbb{R}^4 : \\|\\mathbf{x}\\|_2 \\le R \\}$, or $\\Omega = \\{ (x_1, x_2, x_3, x_4) : x_1^2 + x_2^2 + x_3^2 + x_4^2 \\le R^2 \\}$.\n\nTo apply Monte Carlo integration, we choose a simple sampling domain $D$ that encloses $\\Omega$ and has a known volume $|D|$. A natural choice is the hypercube $D = [-R, R]^4$. The volume of this hypercube is:\n$$|D| = (R - (-R))^4 = (2R)^4 = 16R^4$$\nThe integral for the volume of $\\Omega$ can be rewritten over this domain $D$:\n$$V = \\int_{D} I_{\\Omega}(\\mathbf{x}) \\, d\\mathbf{x}$$\nsince $I_{\\Omega}(\\mathbf{x})=0$ for any $\\mathbf{x}$ outside of $\\Omega$ (and thus for any $\\mathbf{x}$ in $D \\setminus \\Omega$).\n\nThe Monte Carlo method estimates this integral by sampling $N$ points $\\mathbf{X}_1, \\dots, \\mathbf{X}_N$ independently and uniformly from $D$. The estimator for the integral is given by:\n$$\\widehat{V} = |D| \\cdot \\frac{1}{N} \\sum_{i=1}^N I_{\\Omega}(\\mathbf{X}_i)$$\nLet $N_{in}$ be the number of sampled points that fall within or on the boundary of the hypersphere $\\Omega$. This count is precisely $N_{in} = \\sum_{i=1}^N I_{\\Omega}(\\mathbf{X}_i)$. The estimator for the volume can then be written as:\n$$\\widehat{V} = |D| \\cdot \\frac{N_{in}}{N} = 16R^4 \\cdot \\frac{N_{in}}{N}$$\nThis is the ratio of the volume of the hypersphere to the volume of the hypercube, approximated by the ratio of \"hits\" to total samples, scaled by the volume of the hypercube.\n\nFor the special case where $R=0$, the hypersphere is a single point with $V_{\\text{exact}}=0$. The bounding box $D = [0,0]^4$ also has volume $|D|=0$, and the estimator correctly yields $\\widehat{V}=0$.\n\n### 3. Computational Procedure and Error Metric\n\nFor each test case defined by parameters $(R, N, \\text{seed})$, the following procedure is executed:\n1.  **Initialize RNG**: The pseudorandom number generator is seeded with the given `seed` to ensure reproducibility.\n2.  **Calculate Exact Volume**: $V_{\\text{exact}}$ is computed using the formula $V_4(R) = \\frac{1}{2}\\pi^2 R^4$.\n3.  **Generate Samples**: $N$ random vectors $\\mathbf{X}_i$, each with $4$ components, are generated. Each component is drawn from a uniform distribution over the interval $[-R, R]$.\n4.  **Count \"Hits\"**: For each sample $\\mathbf{X}_i = (x_{i1}, x_{i2}, x_{i3}, x_{i4})$, we check if it lies within the $4$-ball by testing the condition $x_{i1}^2 + x_{i2}^2 + x_{i3}^2 + x_{i4}^2 \\le R^2$. The number of samples satisfying this condition, $N_{in}$, is counted.\n5.  **Compute Monte Carlo Estimate**: The estimated volume $\\widehat{V}$ is calculated using the formula $\\widehat{V} = 16R^4 \\cdot (N_{in} / N)$. If $R=0$, this calculation is trivial as $\\widehat{V}=0$.\n6.  **Calculate Error**: The error metric $E$ is computed based on the value of $V_{\\text{exact}}$:\n    -   If $V_{\\text{exact}} > 0$: The relative error is calculated as $E = \\dfrac{|\\widehat{V} - V_{\\text{exact}}|}{V_{\\text{exact}}}$.\n    -   If $V_{\\text{exact}} = 0$: The absolute error is calculated as $E = |\\widehat{V} - V_{\\text{exact}}|$. This case occurs when $R=0$, for which both $\\widehat{V}$ and $V_{\\text{exact}}$ are $0$, resulting in an error $E=0$.\n7.  **Store Result**: The calculated error $E$ is rounded to $6$ decimal places.\n\nThis procedure is repeated for all test cases, and the resulting list of rounded errors is formatted as the final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating the volume of a 4D ball using Monte Carlo integration\n    and comparing it to the analytical result for a suite of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (R, N, seed)\n        (1.0, 200000, 12345),\n        (0.0, 10000, 2023),\n        (1.0, 1, 7),\n        (1.5, 150000, 314159),\n        (2.0, 120000, 424242),\n    ]\n\n    results = []\n    for R, N, seed in test_cases:\n        # Task 2: Calculate the exact analytical volume V_exact.\n        # The volume of an n-ball is V_n(R) = (pi^(n/2) * R^n) / Gamma(n/2 + 1).\n        # For n=4, this simplifies to V_4(R) = (pi^2 * R^4) / Gamma(3) = (pi^2 * R^4) / 2.\n        v_exact = (np.pi**2 * R**4) / 2.0\n\n        # Task 1: Design and run the Monte Carlo estimator.\n        \n        # Initialize the pseudorandom number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n\n        v_hat = 0.0\n        # The Monte Carlo simulation is only meaningful for R > 0.\n        # If R = 0, the volume of the ball and bounding box are both 0.\n        if R > 0.0:\n            # Generate N random points in a 4-dimensional space.\n            # The points are sampled from a hypercube D = [-R, R]^4.\n            # rng.uniform generates values in [low, high). Here, [-R, R).\n            # The shape (N, 4) creates N points, each with 4 coordinates.\n            points = rng.uniform(low=-R, high=R, size=(N, 4))\n\n            # Calculate the squared Euclidean distance from the origin for each point.\n            # This is more efficient than calculating the Euclidean distance as it avoids sqrt.\n            # np.sum(points**2, axis=1) calculates x1^2+x2^2+x3^2+x4^2 for each point.\n            squared_distances = np.sum(points**2, axis=1)\n\n            # Count the number of points that fall inside or on the surface of the 4-ball.\n            # The condition is ||x||^2 <= R^2.\n            n_in = np.sum(squared_distances <= R**2)\n\n            # The volume of the sampling hypercube D = [-R, R]^4 is (2R)^4.\n            volume_of_domain = (2.0 * R)**4\n\n            # The Monte Carlo estimate is the volume of the sampling domain\n            # times the ratio of points inside the hypersphere to the total number of points.\n            v_hat = volume_of_domain * (n_in / N)\n        \n        # Task 3: Compute the error metric E.\n        error = 0.0\n        if v_exact > 0:\n            # Relative error\n            error = np.abs(v_hat - v_exact) / v_exact\n        else:\n            # Absolute error (for the R=0 case)\n            error = np.abs(v_hat - v_exact)\n        \n        # Round the error to 6 decimal places.\n        rounded_error = round(error, 6)\n        results.append(str(rounded_error))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3258918"}]}