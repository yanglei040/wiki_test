{"hands_on_practices": [{"introduction": "Piecewise linear interpolation is the most intuitive method for approximating a function: we simply connect a series of known points with straight lines. However, the value of any approximation lies in understanding its accuracy. This exercise provides a foundational practice in both constructing a simple piecewise linear interpolant and quantifying its error, a core task in all of numerical analysis. By finding the maximum deviation between the true function and our linear approximation, you will develop a concrete understanding of interpolation error and the calculus-based tools used to analyze it [@problem_id:2193842].", "problem": "In numerical analysis, piecewise interpolation is a common method to approximate a complex function. Consider the function $f(x) = x^4$ defined on the interval $[-1, 1]$. We wish to approximate this function using a continuous piecewise linear interpolant, which we denote as $L(x)$. This interpolant is constructed using the nodes $x_0 = -1$, $x_1 = 0$, and $x_2 = 1$. The interpolation error on a given subinterval is defined as the maximum absolute difference between the function and its interpolant on that subinterval, i.e., $\\max |f(x) - L(x)|$.\n\nYour task is to determine on which of the two subintervals, $[-1, 0]$ or $[0, 1]$, the interpolation error is largest.\n\nSelect the correct statement from the options below.\n\nA. The subinterval $[-1, 0]$.\n\nB. The subinterval $[0, 1]$.\n\nC. The maximum error is identical on both subintervals.\n\nD. The maximum error occurs at the node $x=0$, so neither subinterval is uniquely larger.\n\nE. There is insufficient information to determine the result.", "solution": "The problem asks us to construct a piecewise linear interpolant $L(x)$ for the function $f(x) = x^4$ on the interval $[-1, 1]$ using nodes at $x = -1, 0, 1$, and then to compare the maximum interpolation error on the subintervals $[-1, 0]$ and $[0, 1]$.\n\nFirst, we evaluate the function $f(x)$ at the given nodes:\n$f(x_0) = f(-1) = (-1)^4 = 1$\n$f(x_1) = f(0) = 0^4 = 0$\n$f(x_2) = f(1) = 1^4 = 1$\n\nNow, we construct the linear interpolant for each subinterval.\n\n**Subinterval 1: $[-1, 0]$**\nThe linear interpolant, let's call it $L_1(x)$, is the line passing through the points $(x_0, f(x_0)) = (-1, 1)$ and $(x_1, f(x_1)) = (0, 0)$.\nThe slope of this line is $m_1 = \\frac{f(x_1) - f(x_0)}{x_1 - x_0} = \\frac{0 - 1}{0 - (-1)} = -1$.\nUsing the point-slope form with the point $(0, 0)$, the equation of the line is:\n$L_1(x) - 0 = -1(x - 0)$, which simplifies to $L_1(x) = -x$.\n\nThe error function on this subinterval is $E_1(x) = f(x) - L_1(x) = x^4 - (-x) = x^4 + x$.\nTo find the maximum absolute error, we need to find the extrema of $E_1(x)$ on $[-1, 0]$. We take the derivative with respect to $x$ and set it to zero:\n$E_1'(x) = \\frac{d}{dx}(x^4 + x) = 4x^3 + 1$.\nSetting $E_1'(x) = 0$ gives $4x^3 = -1$, so $x^3 = -1/4$.\nThe critical point is $x_c = \\sqrt[3]{-1/4} = -\\frac{1}{\\sqrt[3]{4}}$.\nThis value lies in the interval $[-1, 0]$. To verify this, note that $1^3 = 1$ and $2^3 = 8$, so we have $1  \\sqrt[3]{4}  2$. Taking the reciprocal reverses the inequalities: $1 > 1/\\sqrt[3]{4} > 1/2$. Therefore, $x_c = -1/\\sqrt[3]{4}$ is between $-1$ and $-0.5$, and is clearly within the interval $[-1, 0]$.\nThe error at the endpoints of the interval (the nodes) is zero by construction: $E_1(-1) = (-1)^4 + (-1) = 0$ and $E_1(0) = 0^4 + 0 = 0$.\nThe maximum absolute error must therefore occur at the critical point $x_c$.\nThe error at this point is:\n$E_1(x_c) = \\left(-\\frac{1}{\\sqrt[3]{4}}\\right)^4 + \\left(-\\frac{1}{\\sqrt[3]{4}}\\right) = \\frac{1}{4\\sqrt[3]{4}} - \\frac{1}{\\sqrt[3]{4}} = \\frac{1 - 4}{4\\sqrt[3]{4}} = -\\frac{3}{4\\sqrt[3]{4}}$.\nThe maximum absolute error on $[-1, 0]$ is $|E_1(x_c)| = \\frac{3}{4\\sqrt[3]{4}}$.\n\n**Subinterval 2: $[0, 1]$**\nThe linear interpolant, let's call it $L_2(x)$, is the line passing through the points $(x_1, f(x_1)) = (0, 0)$ and $(x_2, f(x_2)) = (1, 1)$.\nThe slope of this line is $m_2 = \\frac{f(x_2) - f(x_1)}{x_2 - x_1} = \\frac{1 - 0}{1 - 0} = 1$.\nUsing the point-slope form with the point $(0, 0)$, the equation of the line is:\n$L_2(x) - 0 = 1(x - 0)$, which simplifies to $L_2(x) = x$.\n\nThe error function on this subinterval is $E_2(x) = f(x) - L_2(x) = x^4 - x$.\nTo find the maximum absolute error, we find the extrema of $E_2(x)$ on $[0, 1]$. We take the derivative:\n$E_2'(x) = \\frac{d}{dx}(x^4 - x) = 4x^3 - 1$.\nSetting $E_2'(x) = 0$ gives $4x^3 = 1$, so $x^3 = 1/4$.\nThe critical point is $x_d = \\sqrt[3]{1/4} = \\frac{1}{\\sqrt[3]{4}}$.\nThis value lies in the interval $[0, 1]$.\nThe error at the endpoints is zero: $E_2(0) = 0^4 - 0 = 0$ and $E_2(1) = 1^4 - 1 = 0$.\nThe maximum absolute error must occur at the critical point $x_d$.\nThe error at this point is:\n$E_2(x_d) = \\left(\\frac{1}{\\sqrt[3]{4}}\\right)^4 - \\left(\\frac{1}{\\sqrt[3]{4}}\\right) = \\frac{1}{4\\sqrt[3]{4}} - \\frac{1}{\\sqrt[3]{4}} = \\frac{1 - 4}{4\\sqrt[3]{4}} = -\\frac{3}{4\\sqrt[3]{4}}$.\nThe maximum absolute error on $[0, 1]$ is $|E_2(x_d)| = \\frac{3}{4\\sqrt[3]{4}}$.\n\n**Comparison**\nThe maximum absolute error on $[-1, 0]$ is $\\frac{3}{4\\sqrt[3]{4}}$.\nThe maximum absolute error on $[0, 1]$ is $\\frac{3}{4\\sqrt[3]{4}}$.\nThe maximum errors on both subintervals are identical.\n\n**Alternative Reasoning using Symmetry**\nThe function $f(x)=x^4$ is an even function, meaning $f(x) = f(-x)$.\nThe nodes are placed symmetrically about $x=0$.\nThe piecewise linear interpolant is $L(x) = -x$ for $x \\in [-1, 0]$ and $L(x) = x$ for $x \\in [0, 1]$. This can be written compactly as $L(x) = |x|$.\nThe function $L(x) = |x|$ is also an even function.\nThe error function $E(x) = f(x) - L(x) = x^4 - |x|$ is the difference of two even functions, which is also an even function.\nFor an even function $E(x)$, the value of $|E(x)|$ is the same as $|E(-x)|$. This means the error distribution is symmetric about $x=0$. Therefore, the maximum error on the interval $[-1, 0]$ must be equal to the maximum error on the interval $[0, 1]$.\n\nBased on both methods of analysis, the maximum error is identical on both subintervals. This corresponds to option C. Option D is incorrect because the error at the node $x=0$ is, by definition of interpolation, zero, which is the minimum error, not the maximum.", "answer": "$$\\boxed{C}$$", "id": "2193842"}, {"introduction": "While piecewise linear functions are simple, they lack the smoothness often required in scientific and engineering applications. Cubic splines offer a significant improvement by ensuring that the first and second derivatives are continuous, resulting in a much smoother curve. This smoothness, however, can come at a cost. This practice problem presents a critical case study where a standard natural cubic spline fails to preserve the simple monotonic (strictly increasing) nature of the data, introducing artificial \"wiggles\" or extrema. Investigating this phenomenon [@problem_id:2193854] is essential for understanding the limitations of common interpolation methods and motivates the need for more sophisticated, shape-preserving techniques.", "problem": "A natural cubic spline is a popular method for interpolating a set of data points $(x_i, y_i)$. A function $S(x)$ is a cubic spline if it is a piecewise cubic polynomial that is continuous and has continuous first and second derivatives at the data points, which are called nodes. A spline is called \"natural\" if its second derivative is zero at the first and last nodes.\n\nConsider a set of three monotonically increasing data points: `P_0 = (0, 0)`, `P_1 = (1, 1/9)`, and `P_2 = (2, 1)`. A natural cubic spline $S(x)$ is constructed to pass through these three points.\n\nAlthough the data points are strictly increasing, the resulting interpolating function $S(x)$ is not monotonic over the entire interval $[0, 2]$. It can be shown that a local extremum exists in the subinterval $[0, 1]$.\n\nDetermine the x-coordinate of this local extremum. Round your final answer to four significant figures.", "solution": "Let the nodes be $x_{0}=0$, $x_{1}=1$, $x_{2}=2$ with values $y_{0}=0$, $y_{1}=\\frac{1}{9}$, $y_{2}=1$. Let $h_{i}=x_{i+1}-x_{i}$, so $h_{0}=h_{1}=1$. For a natural cubic spline, the second derivatives at the nodes $M_{i}=S''(x_{i})$ satisfy $M_{0}=0$, $M_{2}=0$, and the tridiagonal system for the interior node $i=1$:\n$$\nh_{0}M_{0}+2(h_{0}+h_{1})M_{1}+h_{1}M_{2}\n=6\\left(\\frac{y_{2}-y_{1}}{h_{1}}-\\frac{y_{1}-y_{0}}{h_{0}}\\right).\n$$\nSubstituting the data gives\n$$\n4M_{1}=6\\left(\\left(1-\\frac{1}{9}\\right)-\\left(\\frac{1}{9}-0\\right)\\right)\n=6\\left(\\frac{8}{9}-\\frac{1}{9}\\right)=6\\cdot\\frac{7}{9}=\\frac{14}{3},\n$$\nso\n$$\nM_{1}=\\frac{7}{6},\\quad M_{0}=0,\\quad M_{2}=0.\n$$\n\nOn $[x_{0},x_{1}]=[0,1]$, the spline segment is\n$$\nS_{0}(x)=\\frac{M_{0}(x_{1}-x)^{3}}{6h_{0}}+\\frac{M_{1}(x-x_{0})^{3}}{6h_{0}}+\\left(y_{0}-\\frac{M_{0}h_{0}^{2}}{6}\\right)\\frac{x_{1}-x}{h_{0}}+\\left(y_{1}-\\frac{M_{1}h_{0}^{2}}{6}\\right)\\frac{x-x_{0}}{h_{0}}.\n$$\nWith the values above,\n$$\nS_{0}(x)=\\frac{\\frac{7}{6}x^{3}}{6}+\\left(\\frac{1}{9}-\\frac{\\frac{7}{6}}{6}\\right)x=\\frac{7}{36}x^{3}-\\frac{1}{12}x.\n$$\nDifferentiate to find critical points:\n$$\nS_{0}'(x)=\\frac{7}{12}x^{2}-\\frac{1}{12}.\n$$\nSet $S_{0}'(x)=0$ to obtain\n$$\n\\frac{7}{12}x^{2}-\\frac{1}{12}=0\\;\\;\\Longrightarrow\\;\\;7x^{2}-1=0\\;\\;\\Longrightarrow\\;\\;x^{2}=\\frac{1}{7}.\n$$\nIn the interval $[0,1]$, the critical point is\n$$\nx=\\frac{1}{\\sqrt{7}}.\n$$\nNumerically, $\\frac{1}{\\sqrt{7}}\\approx 0.377964\\ldots$, which rounded to four significant figures is $0.3780$.", "answer": "$$\\boxed{0.3780}$$", "id": "2193854"}, {"introduction": "Having seen that standard cubic splines can fail to preserve monotonicity [@problem_id:2193854], we now move from analysis to design. This advanced practice challenges you to build a robust solution from first principles: a Piecewise Cubic Hermite Interpolating Polynomial (PCHIP) that guarantees monotonicity. You will derive the mathematical conditions required for a cubic segment to be monotonic and implement a slope-limiting algorithm to enforce these conditions on the nodal derivatives. This exercise represents a leap into practical scientific computing, where the goal is not just to use a tool, but to build a reliable one that respects the underlying physical or mathematical properties of the data [@problem_id:3261829].", "problem": "You are asked to design and implement, from first principles, a shape-preserving Piecewise Cubic Hermite Interpolating Polynomial (PCHIP) that is guaranteed to be monotonic whenever the input data values are monotonic. The interpolant should be continuously differentiable and must pass through the given data points. The monotonicity guarantee must be achieved by selecting nodal derivatives using a slope-limiting strategy that enforces sufficient local conditions so that, on each subinterval, the cubic segment has a nonnegative (or nonpositive) derivative when the corresponding data are nondecreasing (or nonincreasing). Your design must start from the definitions of cubic Hermite interpolation and the fundamental notion that the derivative of a cubic on an interval can be expressed as a quadratic whose nonnegativity on a closed interval can be enforced by appropriate bounds on its coefficients. You must not assume any shortcut formulas a priori; instead, derive how to constrain the nodal derivatives to satisfy interval-wise monotonicity whenever the data are monotonic.\n\nDefinitions and requirements:\n- Let the data be nodes $x_0  x_1  \\cdots  x_{n-1}$ with values $y_0, y_1, \\ldots, y_{n-1}$. On each subinterval $[x_i, x_{i+1}]$ with width $h_i = x_{i+1} - x_i$, form a cubic Hermite segment using $y_i, y_{i+1}$ and nodal derivatives $m_i, m_{i+1}$. Use the standard cubic Hermite basis functions to define the segment, and ensure $C^1$ continuity by using one derivative $m_i$ at each node $x_i$ across adjacent segments.\n- Your slope-limiting rule must enforce that, whenever the data values $\\{y_i\\}$ are monotone nondecreasing (respectively, monotone nonincreasing), the resulting interpolant $s(x)$ is also monotone nondecreasing (respectively, monotone nonincreasing) across the full domain $[x_0, x_{n-1}]$. Use only properties derived from the derivative of the cubic segment and interval-wise sufficient conditions that guarantee pointwise nonnegativity (or nonpositivity) of the derivative. The rule must handle strictly monotone data and data with flat segments.\n- To quantitatively test monotonicity of your interpolant, for each dataset below, evaluate the interpolant $s(x)$ at $N = 1001$ equally spaced points in $[x_0, x_{n-1}]$. Define the signed monotonicity margin as follows. Let $\\Delta s_j = s(x_{j+1}) - s(x_j)$ for consecutive evaluation points, and define $\\sigma = \\operatorname{sign}(y_{n-1} - y_0)$, with the convention that if $y_{n-1} = y_0$ then $\\sigma = 1$. The margin is\n$$\n\\mu = \\min_j \\sigma \\, \\Delta s_j.\n$$\nBy this definition, if the interpolant is monotone in the required sense, then $\\mu \\ge 0$. If there is any local violation, then $\\mu  0$.\n- Your program must construct the interpolant and compute $\\mu$ for each dataset. Each $\\mu$ must be rounded to $8$ decimal places.\n- Final output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite below, for example, $[\\mu_1,\\mu_2,\\mu_3,\\mu_4]$, where each entry $\\mu_k$ has exactly $8$ digits after the decimal point.\n\nTest suite (each case provides $(x,y)$):\n1. Increasing, nonuniform spacing:\n   - $x = [0.0,\\, 0.7,\\, 1.0,\\, 1.8,\\, 2.5,\\, 3.0]$\n   - $y = [0.0,\\, 0.2,\\, 0.9,\\, 1.1,\\, 2.0,\\, 2.2]$\n2. Decreasing, nonuniform spacing:\n   - $x = [0.0,\\, 0.5,\\, 1.5,\\, 2.2,\\, 3.0]$\n   - $y = [5.0,\\, 4.0,\\, 2.5,\\, 2.0,\\, 1.0]$\n3. Non-monotone values:\n   - $x = [0.0,\\, 0.6,\\, 1.0,\\, 1.4,\\, 2.0]$\n   - $y = [0.0,\\, 1.5,\\, 0.5,\\, 1.6,\\, 1.0]$\n4. Nondecreasing with plateaus:\n   - $x = [0.0,\\, 0.4,\\, 0.8,\\, 1.2,\\, 2.0]$\n   - $y = [1.0,\\, 1.0,\\, 1.3,\\, 1.3,\\, 2.0]$\n\nYour program must be a complete, runnable implementation that:\n- Constructs a continuously differentiable piecewise cubic Hermite interpolant $s(x)$ through the data.\n- Selects nodal derivatives by a limiter that guarantees monotonicity of $s(x)$ whenever $\\{y_i\\}$ are monotone.\n- Computes, for each dataset, the monotonicity margin $\\mu$ using $N = 1001$ equally spaced evaluation points over the domain $[x_0, x_{n-1}]$.\n- Prints a single line in the exact format $[\\mu_1,\\mu_2,\\mu_3,\\mu_4]$ with each $\\mu_k$ rounded to $8$ decimal places.", "solution": "The user requires the design and implementation of a shape-preserving Piecewise Cubic Hermite Interpolating Polynomial (PCHIP) that guarantees monotonicity of the interpolant if the input data is monotonic. The solution must be derived from first principles.\n\n### Step 1: Theoretical Derivation from First Principles\n\n**1. Piecewise Cubic Hermite Interpolation**\nGiven a set of data points $(x_0, y_0), (x_1, y_1), \\ldots, (x_{n-1}, y_{n-1})$ with $x_0  x_1  \\cdots  x_{n-1}$, a piecewise cubic Hermite interpolant $s(x)$ is constructed on each subinterval $[x_i, x_{i+1}]$. On such a subinterval, $s(x)$ is a cubic polynomial defined by the values $y_i, y_{i+1}$ and the derivatives $m_i, m_{i+1}$ at the endpoints $x_i, x_{i+1}$. The interpolant is continuously differentiable ($C^1$) by ensuring the derivative $m_i$ is uniquely defined at each node $x_i$.\n\nLet $h_i = x_{i+1} - x_i$ be the width of the interval. We introduce a local coordinate $t = (x - x_i)/h_i$, which maps the interval $[x_i, x_{i+1}]$ to $[0, 1]$. The cubic polynomial $P_i(t)$ on $[0,1]$ is given by:\n$$P_i(t) = y_i H_{00}(t) + y_{i+1} H_{01}(t) + (h_i m_i) H_{10}(t) + (h_i m_{i+1}) H_{11}(t)$$\nwhere $H_{jk}(t)$ are the cubic Hermite basis functions:\n- $H_{00}(t) = 2t^3 - 3t^2 + 1$ (value at $t=0$)\n- $H_{01}(t) = -2t^3 + 3t^2$ (value at $t=1$)\n- $H_{10}(t) = t^3 - 2t^2 + t$ (scaled derivative at $t=0$)\n- $H_{11}(t) = t^3 - t^2$ (scaled derivative at $t=1$)\n\nThe derivative of the interpolant $s(x)$ with respect to $x$ is related to the derivative of $P_i(t)$ with respect to $t$ by the chain rule: $s'(x) = \\frac{d P_i}{dt} \\frac{dt}{dx} = \\frac{1}{h_i} P_i'(t)$.\n\n**2. Condition for Monotonicity**\nFor the interpolant $s(x)$ to be monotonic on $[x_i, x_{i+1}]$, its derivative $s'(x)$ must be single-signed on that interval. Let's assume the data is non-decreasing, so the secant slope $\\Delta_i = (y_{i+1} - y_i)/h_i \\ge 0$. We require $s'(x) \\ge 0$ for all $x \\in [x_i, x_{i+1}]$. This implies $P_i'(t) \\ge 0$ for all $t \\in [0, 1]$.\n\nThe derivative $P_i'(t)$ is a quadratic in $t$:\n$$P_i'(t) = y_i H'_{00}(t) + y_{i+1} H'_{01}(t) + h_i m_i H'_{10}(t) + h_i m_{i+1} H'_{11}(t)$$\nSubstituting the derivatives of the basis functions:\n- $H'_{00}(t) = 6t^2 - 6t$\n- $H'_{01}(t) = -6t^2 + 6t$\n- $H'_{10}(t) = 3t^2 - 4t + 1$\n- $H'_{11}(t) = 3t^2 - 2t$\n\nWe get:\n$$P_i'(t) = (y_{i+1}-y_i)(6t-6t^2) + h_i m_i(3t^2 - 4t + 1) + h_i m_{i+1}(3t^2 - 2t)$$\nDividing by $h_i$ and substituting $\\Delta_i = (y_{i+1}-y_i)/h_i$:\n$$s'(x) = \\Delta_i(6t-6t^2) + m_i(3t^2 - 4t + 1) + m_{i+1}(3t^2 - 2t)$$\nFor this quadratic in $t$ to be non-negative on $[0,1]$, we need $s'(x_i) = m_i \\ge 0$ and $s'(x_{i+1}) = m_{i+1} \\ge 0$. A further sufficient condition can be derived from the convexity of the cubic. A cubic segment defined by its BÃ©zier control points is monotonic if and only if its control point y-coordinates are monotonic. The control points are:\n$P_0 = (x_i, y_i)$, $P_1 = (x_i + \\frac{h_i}{3}, y_i + \\frac{h_i m_i}{3})$, $P_2 = (x_{i+1} - \\frac{h_i}{3}, y_{i+1} - \\frac{h_i m_{i+1}}{3})$, $P_3 = (x_{i+1}, y_{i+1})$.\nFor non-decreasing data ($y_i \\le y_{i+1}$), we require $y$-coordinates to be non-decreasing:\n$y_i \\le y_i + \\frac{h_i m_i}{3} \\le y_{i+1} - \\frac{h_i m_{i+1}}{3} \\le y_{i+1}$.\nThis yields three conditions:\n1. $m_i \\ge 0$\n2. $m_{i+1} \\ge 0$\n3. $y_i + \\frac{h_i m_i}{3} \\le y_{i+1} - \\frac{h_i m_{i+1}}{3} \\implies m_i + m_{i+1} \\le 3 \\frac{y_{i+1}-y_i}{h_i} = 3\\Delta_i$\n\nIf the data is non-increasing ($\\Delta_i \\le 0$), the conditions become $m_i \\le 0$, $m_{i+1} \\le 0$, and $m_i + m_{i+1} \\ge 3\\Delta_i$. Both cases can be summarized as:\nIf $\\Delta_i=0$, then $m_i=m_{i+1}=0$.\nIf $\\Delta_i \\neq 0$: $\\mathrm{sign}(m_i) = \\mathrm{sign}(m_{i+1}) = \\mathrm{sign}(\\Delta_i)$, and $|\\frac{m_i}{\\Delta_i} + \\frac{m_{i+1}}{\\Delta_i}| \\le 3$.\n\n**3. Slope-Limiter Algorithm Design**\n\nTo construct a PCHIP interpolant, we first estimate initial derivatives at each node and then apply a \"limiter\" to enforce the monotonicity conditions.\n\n**a. Initial Derivative Estimation:**\n- For interior nodes $x_k$ ($k=1, \\ldots, n-2$), if the adjacent secant slopes $\\Delta_{k-1}$ and $\\Delta_k$ have opposite signs, it indicates a local extremum, so we set the initial derivative $m_k = 0$. If they have the same sign, a robust choice is the weighted harmonic mean of the secant slopes (Fritsch  Butland, 1984):\n    $$m_k = \\frac{w_1+w_2}{(w_1/\\Delta_{k-1}) + (w_2/\\Delta_k)} \\quad \\text{where} \\quad w_1 = 2h_k + h_{k-1}, w_2 = h_k + 2h_{k-1}$$\n- For endpoint nodes $x_0$ and $x_{n-1}$, we use a non-centered 3-point formula, equivalent to finding the derivative of a quadratic passing through the first/last three points.\n    $$m_0 = \\frac{(2h_0+h_1)\\Delta_0 - h_0\\Delta_1}{h_0+h_1}$$\n    $$m_{n-1} = \\frac{(2h_{n-2}+h_{n-3})\\Delta_{n-2} - h_{n-2}\\Delta_{n-3}}{h_{n-2}+h_{n-3}}$$\n\n**b. Monotonicity Enforcement (The Limiter):**\nAfter obtaining the initial derivative estimates, we iterate through each interval $[x_k, x_{k+1}]$ and enforce the sufficient conditions derived above. This can be done in a single pass from $k=0$ to $n-2$.\n\nFor each interval $[x_k, x_{k+1}]$:\n1. If $\\Delta_k = 0$, set $m_k=0$ and $m_{k+1}=0$.\n2. Otherwise, check the signs. If $\\mathrm{sign}(m_k) \\neq \\mathrm{sign}(\\Delta_k)$, set $m_k=0$. If $\\mathrm{sign}(m_{k+1}) \\neq \\mathrm{sign}(\\Delta_k)$, set $m_{k+1}=0$.\n3. Check the magnitude condition. Let $s_k = \\mathrm{sign}(\\Delta_k)$. If $s_k(m_k + m_{k+1})  3 |\\Delta_k|$, then the condition is violated. We scale down both derivatives to lie on the boundary of the acceptable region:\n   $$m_k \\leftarrow \\frac{3\\Delta_k}{m_k+m_{k+1}} m_k \\quad \\text{and} \\quad m_{k+1} \\leftarrow \\frac{3\\Delta_k}{m_k+m_{k+1}} m_{k+1}$$\nA single forward pass of this procedure is sufficient because derivatives are only ever reduced in magnitude (or set to zero), which preserves or improves compliance with the conditions on preceding intervals.\n\n**4. Interpolant Evaluation and Monotonicity Margin**\nOnce the final derivatives $\\{m_i\\}$ are determined, the interpolant $s(x)$ can be evaluated at any point `x_eval` by first finding the interval $[x_k, x_{k+1}]$ containing `x_eval`, calculating $t = (\\text{x\\_eval} - x_k)/h_k$, and then using the Hermite basis polynomial formula.\n\nThe monotonicity margin $\\mu = \\min_j \\sigma \\, \\Delta s_j$ is computed, where $\\Delta s_j$ are the differences in the evaluated interpolant at N equally spaced points, and $\\sigma = \\operatorname{sign}(y_{n-1} - y_0)$ (with $\\sigma=1$ if $y_{n-1}=y_0$). A non-negative $\\mu$ confirms that the interpolant is monotonic in the same sense as the overall data trend.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the PCHIP problem for the given test suite.\n    \"\"\"\n    # Test cases from the problem statement\n    test_cases = [\n        (np.array([0.0, 0.7, 1.0, 1.8, 2.5, 3.0]), np.array([0.0, 0.2, 0.9, 1.1, 2.0, 2.2])),\n        (np.array([0.0, 0.5, 1.5, 2.2, 3.0]), np.array([5.0, 4.0, 2.5, 2.0, 1.0])),\n        (np.array([0.0, 0.6, 1.0, 1.4, 2.0]), np.array([0.0, 1.5, 0.5, 1.6, 1.0])),\n        (np.array([0.0, 0.4, 0.8, 1.2, 2.0]), np.array([1.0, 1.0, 1.3, 1.3, 2.0])),\n    ]\n\n    results = []\n    for x, y in test_cases:\n        # Construct the PCHIP interpolator\n        interpolator = PchipInterpolator(x, y)\n        \n        # Evaluate at N=1001 points\n        N = 1001\n        x_eval = np.linspace(x[0], x[-1], N)\n        s_eval = interpolator.evaluate(x_eval)\n        \n        # Calculate monotonicity margin mu\n        delta_s = np.diff(s_eval)\n        \n        sigma_val = y[-1] - y[0]\n        sigma = 1.0 if sigma_val = 0 else -1.0\n        \n        mu = np.min(sigma * delta_s)\n        \n        results.append(f\"{mu:.8f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nclass PchipInterpolator:\n    \"\"\"\n    A shape-preserving Piecewise Cubic Hermite Interpolating Polynomial (PCHIP)\n    that guarantees monotonicity if the input data is monotonic.\n    The implementation is derived from first principles as requested.\n    \"\"\"\n    def __init__(self, x, y):\n        self.x = np.asarray(x, dtype=float)\n        self.y = np.asarray(y, dtype=float)\n        if self.x.ndim != 1 or self.y.ndim != 1 or self.x.shape != self.y.shape:\n            raise ValueError(\"x and y must be 1D arrays of the same shape.\")\n        if self.x.shape[0]  2:\n            raise ValueError(\"Need at least 2 data points for interpolation.\")\n        \n        # Calculate and store the final nodal derivatives after applying the limiter\n        self.m = self._calculate_derivatives(self.x, self.y)\n\n    def _calculate_derivatives(self, x, y):\n        \"\"\"\n        Calculates the nodal derivatives m_k for the PCHIP interpolant,\n        including initial estimation and a monotonicity-preserving limiter.\n        \"\"\"\n        n = len(x)\n        h = np.diff(x)\n        delta = np.diff(y) / h\n        \n        if n == 2:\n            # For two points, the interpolant is a line, derivative is constant\n            return np.array([delta[0], delta[0]])\n        \n        m = np.zeros(n)\n        \n        # Step 1: Initial derivative estimates at interior points (k=1..n-2)\n        for k in range(1, n - 1):\n            if np.sign(delta[k-1]) * np.sign(delta[k])  0:\n                # Weighted harmonic mean for same-sign adjacent secant slopes\n                w1 = 2 * h[k] + h[k-1]\n                w2 = h[k] + 2 * h[k-1]\n                m[k] = (w1 + w2) / (w1 / delta[k-1] + w2 / delta[k])\n            else:\n                # Zero derivative at extrema\n                m[k] = 0.0\n                \n        # Step 2: Initial derivative estimates at endpoints (k=0, n-1)\n        # These are based on fitting a quadratic to the first/last 3 points.\n        m[0] = ((2*h[0] + h[1])*delta[0] - h[0]*delta[1]) / (h[0] + h[1])\n        m[n-1] = ((2*h[n-2] + h[n-3])*delta[n-2] - h[n-2]*delta[n-3]) / (h[n-2] + h[n-3])\n        \n        # Step 3: Apply monotonicity constraints (the limiter) in a single pass.\n        for k in range(n - 1):\n            if delta[k] == 0.0:\n                # If the data is flat, the interpolant must be flat.\n                m[k] = 0.0\n                m[k+1] = 0.0\n            else:\n                # Enforce that derivatives have the same sign as the secant slope.\n                if np.sign(m[k]) != np.sign(delta[k]):\n                    m[k] = 0.0\n                if np.sign(m[k+1]) != np.sign(delta[k]):\n                    m[k+1] = 0.0\n                \n                # Check the magnitude condition derived from Bezier control points.\n                # Expressed generally: s_k * (m_k + m_{k+1}) = 3 * |delta_k|\n                # where s_k = sign(delta_k).\n                \n                # Check for violation\n                violation = False\n                if delta[k]  0 and m[k] + m[k+1]  3.0 * delta[k]:\n                    violation = True\n                elif delta[k]  0 and m[k] + m[k+1]  3.0 * delta[k]:\n                    violation = True\n\n                if violation:\n                    # Scale down m_k and m_{k+1} to meet the boundary\n                    # while preserving their ratio. This can only happen if m_k+m_{k+1} != 0.\n                    # Given the sign checks above, m_k+m_{k+1} will have same sign as delta_k.\n                    scale = (3.0 * delta[k]) / (m[k] + m[k+1])\n                    m[k] *= scale\n                    m[k+1] *= scale\n                        \n        return m\n\n    def evaluate(self, x_eval):\n        \"\"\"\n        Evaluates the PCHIP interpolant at the given points.\n        \"\"\"\n        x_eval = np.asarray(x_eval, dtype=float)\n        \n        # Find which interval each x_eval point belongs to.\n        indices = np.searchsorted(self.x, x_eval, side='right')\n        # Handle points outside the domain by clamping to boundary intervals.\n        indices = np.clip(indices, 1, len(self.x) - 1)\n        # The interval index `k` corresponds to [x_k, x_{k+1}]\n        k = indices - 1\n        \n        # Extract data for the corresponding intervals.\n        x_k = self.x[k]\n        x_k1 = self.x[k+1]\n        y_k = self.y[k]\n        y_k1 = self.y[k+1]\n        m_k = self.m[k]\n        m_k1 = self.m[k+1]\n        \n        h = x_k1 - x_k\n        \n        # Normalize evaluation points to the local coordinate t in [0, 1].\n        t = (x_eval - x_k) / h\n        \n        # Evaluate using the standard Hermite basis functions.\n        t2 = t * t\n        t3 = t2 * t\n        \n        h00 = 2*t3 - 3*t2 + 1\n        h01 = -2*t3 + 3*t2\n        h10 = t3 - 2*t2 + t\n        h11 = t3 - t2\n        \n        s_eval = h00*y_k + h01*y_k1 + h*(h10*m_k + h11*m_k1)\n        \n        return s_eval\n\nsolve()\n```", "id": "3261829"}]}