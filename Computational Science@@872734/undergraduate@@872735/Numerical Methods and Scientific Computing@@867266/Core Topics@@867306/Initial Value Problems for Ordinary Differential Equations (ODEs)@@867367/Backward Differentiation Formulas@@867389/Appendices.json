{"hands_on_practices": [{"introduction": "This first exercise provides a gentle introduction to the first-order Backward Differentiation Formula (BDF1), also known as the Backward Euler method. By applying it to an ordinary differential equation where the derivative depends only on time, the normally implicit calculation becomes straightforward. This practice allows you to focus on the core mechanics of the backward-difference approximation and calculate the resulting error without the added complexity of solving an algebraic equation for the solution at the next step [@problem_id:2155190].", "problem": "Consider the initial value problem defined by the ordinary differential equation $y'(t) = 2t$ with the initial condition $y(0) = 0$.\n\nWe will approximate the solution using a numerical scheme. The first-order Backward Differentiation Formula (BDF1), also known as the backward Euler method, is an implicit method defined by the general recurrence relation:\n$$\ny_{n+1} = y_n + h f(t_{n+1}, y_{n+1})\n$$\nwhere $h$ is the constant step size, $y_n$ is the numerical approximation of $y(t_n)$, and $f(t, y) = y'(t)$.\n\nLet the initial point be $(t_0, y_0) = (0, 0)$. Compute the first step of the method, which yields an approximation $y_1$ for the true value $y(t_1)$ where $t_1 = t_0 + h = h$.\n\nDetermine the absolute error of this first-step approximation, defined as $|y(h) - y_1|$. Your final answer should be an analytical expression in terms of the step size $h$.", "solution": "We are given the initial value problem $y'(t)=2t$ with $y(0)=0$. The exact solution is obtained by integrating:\n$$\ny(t)=\\int 2t\\,dt = t^{2}+C,\n$$\nand using the initial condition $y(0)=0$ gives $C=0$, hence $y(t)=t^{2}$. Therefore,\n$$\ny(h)=h^{2}.\n$$\n\nUsing the BDF1 (backward Euler) method with step size $h$,\n$$\ny_{n+1}=y_{n}+h f(t_{n+1},y_{n+1}).\n$$\nHere $f(t,y)=2t$, which is independent of $y$, so the update becomes\n$$\ny_{n+1}=y_{n}+h\\cdot 2 t_{n+1}.\n$$\nFor the first step, $t_{0}=0$, $y_{0}=0$, and $t_{1}=t_{0}+h=h$, hence\n$$\ny_{1}=y_{0}+h\\cdot 2 t_{1}=0+h\\cdot 2h=2h^{2}.\n$$\n\nThe absolute error of the first-step approximation is\n$$\n|y(h)-y_{1}|=\\left|h^{2}-2h^{2}\\right|=|{-}h^{2}|=h^{2}.\n$$", "answer": "$$\\boxed{h^{2}}$$", "id": "2155190"}, {"introduction": "Building on the basics, this practice explores the application of the BDF1 method to the general linear ODE, $y' = \\alpha y + \\beta$. While BDF methods are implicit, this exercise demonstrates a crucial concept: for linear differential equations, the implicit step yields a simple linear algebraic equation for the next unknown value, $y_{n+1}$. Solving this equation algebraically gives you a direct, explicit update formula, a technique fundamental to applying implicit methods efficiently [@problem_id:2155156].", "problem": "In numerical analysis, the Backward Differentiation Formulas (BDFs) are a family of implicit methods for the numerical integration of ordinary differential equations. Consider a first-order ordinary differential equation of the form $y'(t) = \\alpha y(t) + \\beta$, where $\\alpha$ and $\\beta$ are real constants. We wish to approximate the solution to this equation using a numerical scheme with a constant step size $h$.\n\nLet $y_n$ be the numerical approximation of the true solution $y(t_n)$ at time $t_n = t_0 + nh$. The first-order Backward Differentiation Formula (BDF1), also known as the Backward Euler method, approximates the derivative at time $t_{n+1}$ using the backward difference:\n$$\ny'(t_{n+1}) \\approx \\frac{y_{n+1} - y_n}{h}\n$$\nBy evaluating the differential equation at time $t_{n+1}$ and substituting this approximation, we obtain a recurrence relation for $y_{n+1}$.\n\nDerive a fully explicit formula for the next approximation, $y_{n+1}$, in terms of the current approximation $y_n$, the step size $h$, and the constants $\\alpha$ and $\\beta$.", "solution": "We start from the given differential equation $y'(t)=\\alpha y(t)+\\beta$ and the BDF1 (Backward Euler) approximation of the derivative at $t_{n+1}$:\n$$\ny'(t_{n+1}) \\approx \\frac{y_{n+1}-y_{n}}{h}.\n$$\nEvaluating the differential equation at $t_{n+1}$ and approximating $y(t_{n+1})$ by $y_{n+1}$ gives\n$$\n\\frac{y_{n+1}-y_{n}}{h}=\\alpha y_{n+1}+\\beta.\n$$\nMultiplying both sides by $h$,\n$$\ny_{n+1}-y_{n}=h\\alpha y_{n+1}+h\\beta.\n$$\nCollecting terms in $y_{n+1}$ on the left-hand side,\n$$\n(1-h\\alpha)y_{n+1}=y_{n}+h\\beta.\n$$\nAssuming $1-h\\alpha \\neq 0$, solve for $y_{n+1}$:\n$$\ny_{n+1}=\\frac{y_{n}+h\\beta}{1-h\\alpha}.\n$$\nThis provides the fully explicit update formula in terms of $y_{n}$, $h$, $\\alpha$, and $\\beta$.", "answer": "$$\\boxed{\\frac{y_{n}+h\\beta}{1-h\\alpha}}$$", "id": "2155156"}, {"introduction": "Here, we confront the full challenge and power of implicit methods by applying BDF1 to a nonlinear ODE. For an equation like $y'(t) = \\cos(y(t))$, the implicit formulation leads to a nonlinear algebraic equation for $y_{n+1}$ that cannot be solved directly. This exercise guides you through the standard approach for this situation: using an iterative root-finding algorithm, specifically Newton's method, to approximate the solution at each time step, demonstrating a vital connection between differential equation solvers and numerical root-finding [@problem_id:2155132].", "problem": "Consider the problem of numerically solving the autonomous Ordinary Differential Equation (ODE), a type of differential equation that does not explicitly depend on the independent variable. The specific ODE under consideration is:\n$$y'(t) = \\cos(y(t))$$\nAn implicit numerical scheme is employed to approximate the solution. Let $y_n$ be the numerical approximation of the solution $y(t_n)$ at time $t_n$. With a constant time step $h$, so that $t_{n+1} = t_n + h$, the approximation at the next time step, $y_{n+1}$, is determined by the following implicit equation:\n$$y_{n+1} = y_n + h \\cos(y_{n+1})$$\nTo find the value of $y_{n+1}$ at each step, we must solve this equation. This is accomplished by finding the root of the function $g(x) = x - y_n - h \\cos(x)$, where the root $x$ corresponds to $y_{n+1}$. The root is found using an iterative procedure. Let $y_{n+1}^{(k)}$ be the $k$-th approximation of the root. The subsequent approximation, $y_{n+1}^{(k+1)}$, is determined by finding the root of the line that is tangent to the function $g(x)$ at the point $x = y_{n+1}^{(k)}$.\n\nYour task is to derive the iterative update rule for $y_{n+1}^{(k+1)}$. Express your answer in terms of $y_{n+1}^{(k)}$, $y_n$, and the step size $h$.", "solution": "We are given the implicit equation for $y_{n+1}$ as the root of $g(x)=x-y_{n}-h\\cos(x)$. To compute $y_{n+1}$ iteratively, we apply Newton's method, which updates an iterate $x^{(k)}$ via\n$$\nx^{(k+1)}=x^{(k)}-\\frac{g(x^{(k)})}{g'(x^{(k)})}.\n$$\nFirst, compute the derivative of $g(x)$:\n$$\ng'(x)=\\frac{d}{dx}\\left(x-y_{n}-h\\cos(x)\\right)=1+h\\sin(x).\n$$\nUsing $x^{(k)}=y_{n+1}^{(k)}$, we substitute into Newton's update:\n$$\ny_{n+1}^{(k+1)}=y_{n+1}^{(k)}-\\frac{y_{n+1}^{(k)}-y_{n}-h\\cos\\!\\left(y_{n+1}^{(k)}\\right)}{1+h\\sin\\!\\left(y_{n+1}^{(k)}\\right)}.\n$$\nThis gives the required iterative rule expressed in terms of $y_{n+1}^{(k)}$, $y_{n}$, and $h$.", "answer": "$$\\boxed{y_{n+1}^{(k+1)}=y_{n+1}^{(k)}-\\dfrac{y_{n+1}^{(k)}-y_{n}-h\\cos\\!\\left(y_{n+1}^{(k)}\\right)}{1+h\\sin\\!\\left(y_{n+1}^{(k)}\\right)}}$$", "id": "2155132"}]}