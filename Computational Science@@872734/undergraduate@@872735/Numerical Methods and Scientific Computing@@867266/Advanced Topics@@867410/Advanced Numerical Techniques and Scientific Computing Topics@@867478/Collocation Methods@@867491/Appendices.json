{"hands_on_practices": [{"introduction": "Our exploration of collocation methods begins with the fundamental principle in its most direct form. This practice demonstrates how to transform a differential equation into a simple algebraic problem by using a carefully chosen trial function that already satisfies the boundary conditions. By forcing the residual of our approximation to be zero at a single, strategic 'collocation point', we can solve for the unknown parameter in our trial solution and assess the quality of the result [@problem_id:2159883].", "problem": "An engineer is modeling the steady-state temperature distribution $y(x)$ along a thin, laterally insulated rod of unit length. The rod is subject to an internal heat source proportional to the square of the position $x$, and its temperature is fixed at both ends. The governing differential equation for this system is a second-order linear non-homogeneous Boundary Value Problem (BVP):\n\n$$y''(x) - y(x) = -x^2, \\quad \\text{for } x \\in [0, 1]$$\n\nwith boundary conditions:\n\n$$y(0) = 0, \\quad y(1) = 2$$\n\nTo find an approximate solution, the collocation method is employed. A single-parameter trial function $\\tilde{y}(x)$ is proposed, which is constructed to automatically satisfy the boundary conditions:\n\n$$\\tilde{y}(x) = 2x + c \\cdot x(1-x)$$\n\nwhere $c$ is an unknown constant coefficient to be determined.\n\nYour task is to use a single collocation point at $x_c = 1/2$ to determine the value of the parameter $c$. Then, with this value of $c$, calculate the maximum value of the absolute residual, $\\max_{x \\in [0, 1]} |R(x)|$, where the residual function $R(x)$ is defined as $R(x) = \\tilde{y}''(x) - \\tilde{y}(x) + x^2$.\n\nExpress your final answer as a single real number, rounded to three significant figures.", "solution": "The trial function is $\\tilde{y}(x) = 2x + c\\,x(1-x) = (2+c)x - c x^{2}$, which satisfies the boundary conditions $\\tilde{y}(0)=0$ and $\\tilde{y}(1)=2$. Its derivatives are\n$$\n\\tilde{y}'(x) = (2+c) - 2c x, \\qquad \\tilde{y}''(x) = -2c.\n$$\nThe residual is defined by $R(x) = \\tilde{y}''(x) - \\tilde{y}(x) + x^{2}$, hence\n$$\nR(x) = -2c - \\big[(2+c)x - c x^{2}\\big] + x^{2} = -2c - (2+c)x + (c+1)x^{2}.\n$$\nUsing the collocation condition at $x_{c}=\\frac{1}{2}$, impose $R\\!\\left(\\frac{1}{2}\\right)=0$:\n$$\n-2c - \\frac{2+c}{2} + \\frac{c+1}{4} = 0.\n$$\nWith a common denominator of $4$, this is\n$$\n\\frac{-8c - 2(2+c) + (c+1)}{4} = \\frac{-8c - 4 - 2c + c + 1}{4} = \\frac{-9c - 3}{4} = 0,\n$$\nso $-9c - 3 = 0$ and therefore $c = -\\frac{1}{3}$.\n\nSubstitute $c=-\\frac{1}{3}$ into $R(x)$:\n$$\nR(x) = -2\\!\\left(-\\frac{1}{3}\\right) - \\left(2 - \\frac{1}{3}\\right)x + \\left(1 - \\frac{1}{3}\\right)x^{2} = \\frac{2}{3} - \\frac{5}{3}x + \\frac{2}{3}x^{2} = \\frac{1}{3}\\big(2 - 5x + 2x^{2}\\big).\n$$\nLet $q(x) = 2 - 5x + 2x^{2}$. Then $R(x) = \\frac{1}{3}q(x)$. The function $q$ is a quadratic with $q'(x) = -5 + 4x$, which is negative on $[0,1]$, so $q$ decreases monotonically on $[0,1]$. Moreover, $q\\!\\left(\\frac{1}{2}\\right)=0$ (consistent with the collocation). Thus on $[0,\\frac{1}{2}]$, $q \\ge 0$ and $|q|=q$ decreasing from $q(0)=2$ to $0$, while on $[\\frac{1}{2},1]$, $q \\le 0$ and $|q|=-q$ increasing from $0$ to $|q(1)|=1$. Hence\n$$\n\\max_{x \\in [0,1]} |q(x)| = 2 \\quad \\Rightarrow \\quad \\max_{x \\in [0,1]} |R(x)| = \\frac{1}{3} \\cdot 2 = \\frac{2}{3}.\n$$\nRounded to three significant figures, this is $0.667$.", "answer": "$$\\boxed{0.667}$$", "id": "2159883"}, {"introduction": "Moving beyond a single point, we now explore the power of pseudospectral methods, a sophisticated form of collocation that uses a set of strategically placed nodes. This practice delves into a crucial aspect of these methods: the choice of node distribution and its impact on accurately resolving sharp features in a solution. You will compare two famous families of Chebyshev nodes to see firsthand how clustering points near boundaries can dramatically improve the approximation of a boundary layer [@problem_id:3179398].", "problem": "You will implement a pseudospectral collocation method to study how endpoint clustering affects the resolution of boundary layers when approximating the solution of the ordinary differential equation (ODE) $u'(x)=\\alpha\\,u(x)$ on the interval $[-1,1]$ with the boundary condition $u(1)=1$ (unitless). The exact solution is $u(x)=\\exp\\!\\big(\\alpha\\,(x-1)\\big)$. You must contrast Chebyshev–Gauss nodes $x_k=\\cos\\!\\big(\\frac{(2k-1)\\pi}{2N}\\big)$ for $k=1,2,\\dots,N$ and Chebyshev–Gauss–Lobatto nodes $x_k=\\cos\\!\\big(\\frac{k\\pi}{N}\\big)$ for $k=0,1,\\dots,N$, where all angles are in radians. The goal is to assess how endpoint inclusion and clustering at $x=\\pm 1$ influences resolution of a thin boundary layer near $x=1$ when $\\alpha$ is large and positive.\n\nStart from the following fundamental base:\n- Polynomial interpolation and collocation: approximate $u(x)$ by a polynomial $p(x)$ that interpolates values at distinct nodes $\\{x_k\\}$; enforce the ODE at selected collocation nodes and the boundary condition at $x=1$.\n- The barycentric interpolation formula: for distinct nodes $\\{x_k\\}$ with barycentric weights $\\{w_k\\}$, the interpolant evaluated at $x$ is $$p(x)=\\frac{\\sum_{k=0}^{M-1}\\frac{w_k\\,u_k}{x-x_k}}{\\sum_{k=0}^{M-1}\\frac{w_k}{x-x_k}},$$ where $u_k=p(x_k)$ and $M$ is the number of nodes.\n- The barycentric differentiation matrix $D\\in\\mathbb{R}^{M\\times M}$ defined by $$D_{ij}=\\begin{cases}\\dfrac{w_j}{w_i(x_i-x_j)}, & i\\neq j \\\\ -\\sum_{j\\neq i}D_{ij}, & i=j.\\end{cases}$$ This yields $p'(x_i)=\\sum_{j=0}^{M-1}D_{ij}\\,u_j$.\n\nImplement the following pseudospectral collocation designs:\n- For Chebyshev–Gauss–Lobatto nodes with $N+1$ nodes ($k=0,\\dots,N$), enforce $u(1)=1$ directly at the node $x_0=1$; enforce the ODE $u'(x)=\\alpha\\,u(x)$ at the interior nodes $x_k$ for $k=1,\\dots,N$. This yields a linear system for the nodal values $\\{u_k\\}_{k=0}^N$ with $N+1$ equations.\n- For Chebyshev–Gauss nodes with $N$ nodes ($k=1,\\dots,N$) that do not include the endpoint, construct a square system by enforcing the ODE at $N-1$ nodes and replacing one ODE row with the boundary condition $u(1)=1$ expressed in terms of nodal values via barycentric evaluation. Specifically, for $x^\\ast=1$, define $$\\phi_k=\\frac{w_k}{x^\\ast-x_k},\\qquad \\beta_k=\\frac{\\phi_k}{\\sum_{j=1}^N \\phi_j},$$ and enforce $\\sum_{k=1}^N \\beta_k\\,u_k=1$ as the boundary condition. Enforce the ODE at the remaining $N-1$ nodes via $p'(x_i)-\\alpha\\,p(x_i)=0$. Choose the replaced ODE row to be the node with maximal $x_k$ to align the boundary constraint with the nearest node.\n\nUse known barycentric weights for the Chebyshev families:\n- For Chebyshev–Gauss nodes $x_k=\\cos\\!\\big(\\frac{(2k-1)\\pi}{2N}\\big)$ ($k=1,\\dots,N$), let $w_k=(-1)^{k-1}$.\n- For Chebyshev–Gauss–Lobatto nodes $x_k=\\cos\\!\\big(\\frac{k\\pi}{N}\\big)$ ($k=0,\\dots,N$), let $w_k=(-1)^k\\,c_k$, where $c_0=c_N=\\tfrac{1}{2}$ and $c_k=1$ for $k=1,\\dots,N-1$.\n\nTo quantify resolution of the boundary layer near $x=1$, define a layer-focused evaluation grid of $m$ points with $$\\delta=\\min\\!\\Big(0.5,\\frac{8}{\\alpha}\\Big),\\qquad x_j=1-\\delta+\\frac{j}{m-1}\\,\\delta,\\quad j=0,1,\\dots,m-1,$$ using $m=400$. Evaluate the polynomial approximants $p_{\\text{Gauss}}(x)$ and $p_{\\text{Lobatto}}(x)$ on this grid via the barycentric formula, and compute the maximum absolute errors $$E_{\\text{Gauss}}=\\max_j\\left|p_{\\text{Gauss}}(x_j)-\\exp\\!\\big(\\alpha(x_j-1)\\big)\\right|,\\qquad E_{\\text{Lobatto}}=\\max_j\\left|p_{\\text{Lobatto}}(x_j)-\\exp\\!\\big(\\alpha(x_j-1)\\big)\\right|.$$ Report the base-$10$ logarithm of the error ratio $\\log_{10}\\!\\big(E_{\\text{Gauss}}/E_{\\text{Lobatto}}\\big)$ for each test case.\n\nTest suite:\n- Case $1$: $(N,\\alpha)=(16,20)$.\n- Case $2$: $(N,\\alpha)=(16,100)$.\n- Case $3$: $(N,\\alpha)=(8,50)$.\n- Case $4$: $(N,\\alpha)=(32,100)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each float in scientific notation with six digits after the decimal (e.g., $[1.234567\\mathrm{e}{-2},-3.210000\\mathrm{e}{0}]$). The line must aggregate the four test-case results in the order listed above.", "solution": "The user has provided a valid problem statement. I will proceed with a full solution.\n\nThe problem requires a comparative analysis of two pseudospectral collocation methods for solving the ordinary differential equation (ODE) $u'(x) = \\alpha u(x)$ on the domain $x \\in [-1, 1]$ with a boundary condition $u(1) = 1$. The exact solution is $u(x) = \\exp(\\alpha(x-1))$. For large positive $\\alpha$, this solution features a thin boundary layer near $x=1$, where the function value changes rapidly. The objective is to assess how two different choices of collocation nodes—Chebyshev–Gauss and Chebyshev–Gauss–Lobatto—affect the numerical accuracy in resolving this layer.\n\nThe core of a pseudospectral method is to approximate the unknown function $u(x)$ by a global polynomial $p(x)$ of degree $M-1$, where $M$ is the number of collocation nodes. The polynomial is defined by its values $\\{u_k = p(x_k)\\}$ at a set of distinct nodes $\\{x_k\\}$. The derivatives of the polynomial at these nodes, $p'(x_i)$, can be computed as a linear combination of the nodal values, $p'(x_i) = \\sum_{j} D_{ij} u_j$, where $D$ is the spectral differentiation matrix. By enforcing the ODE and boundary conditions at these nodes, we can construct a linear system for the unknown nodal values $\\{u_k\\}$.\n\nThe problem specifies using the barycentric interpolation formula to represent the polynomial and its derivative. The differentiation matrix $D$ is defined based on the nodes $\\{x_k\\}$ and their corresponding barycentric weights $\\{w_k\\}$ as:\n$$\nD_{ij} = \\begin{cases}\n\\dfrac{w_j}{w_i(x_i - x_j)}, & i \\neq j \\\\\n-\\sum_{j \\neq i} D_{ij}, & i=j\n\\end{cases}\n$$\nOnce the nodal values $\\{u_k\\}$ are found by solving the linear system, the polynomial approximant can be evaluated at any point $x$ using the barycentric formula:\n$$\np(x) = \\frac{\\sum_{k} \\frac{w_k u_k}{x - x_k}}{\\sum_{k} \\frac{w_k}{x - x_k}}\n$$\n\nWe will now detail the implementation for each set of nodes.\n\n### 1. Chebyshev–Gauss–Lobatto Method\n\nThis method uses $M = N+1$ nodes, including the endpoints $x=\\pm 1$.\n- **Nodes**: $x_k = \\cos\\left(\\frac{k\\pi}{N}\\right)$ for $k = 0, 1, \\dots, N$. Note that $x_0 = 1$ and $x_N = -1$.\n- **Barycentric Weights**: $w_k = (-1)^k c_k$, where $c_0 = c_N = \\frac{1}{2}$ and $c_k = 1$ for $k=1, \\dots, N-1$.\n\nA linear system of $N+1$ equations for the $N+1$ unknown nodal values $\\{u_k\\}_{k=0}^N$ is constructed as follows:\n- **Boundary Condition**: The condition $u(1)=1$ is enforced directly at the node $x_0 = 1$. This provides the first equation: $u_0 = 1$.\n- **ODE Collocation**: The ODE, in the form $u'(x) - \\alpha u(x) = 0$, is enforced at the nodes $x_k$ for $k = 1, \\dots, N$. For each such node $x_k$, we get an equation:\n$$\np'(x_k) - \\alpha p(x_k) = 0 \\implies \\sum_{j=0}^{N} D_{kj} u_j - \\alpha u_k = 0\n$$\nThis gives $N$ equations. Combined with the boundary condition, we have a square linear system $A_L u = b_L$, where $u = [u_0, u_1, \\dots, u_N]^T$. The matrix $A_L$ has $[1, 0, \\dots, 0]$ as its first row, and the subsequent rows are derived from the differentiation matrix $(D - \\alpha I)$. The right-hand side is $b_L = [1, 0, \\dots, 0]^T$. Solving this system yields the nodal values for the Lobatto approximant, $p_{\\text{Lobatto}}(x)$.\n\n### 2. Chebyshev–Gauss Method\n\nThis method uses $M=N$ nodes, which are interior to the interval $[-1, 1]$.\n- **Nodes**: $x_k = \\cos\\left(\\frac{(2k-1)\\pi}{2N}\\right)$ for $k = 1, \\dots, N$. For a 0-indexed implementation ($k=0, \\dots, N-1$), the formula becomes $x_k = \\cos\\left(\\frac{(2k+1)\\pi}{2N}\\right)$.\n- **Barycentric Weights**: $w_k = (-1)^{k-1}$ for $k=1, \\dots, N$. For a 0-indexed implementation, $w_k = (-1)^k$.\n\nA linear system of $N$ equations for the $N$ unknown nodal values $\\{u_k\\}_{k=1}^N$ is constructed. Since the boundary point $x=1$ is not a node, the condition $u(1)=1$ must be enforced via interpolation.\n- **Boundary Condition via Interpolation**: We enforce $p(1) = 1$ using the barycentric formula:\n$$\np(1) = \\frac{\\sum_{k=1}^{N} \\frac{w_k u_k}{1 - x_k}}{\\sum_{j=1}^{N} \\frac{w_j}{1 - x_j}} = 1 \\implies \\sum_{k=1}^{N} \\beta_k u_k = 1\n$$\nwhere $\\beta_k = \\frac{\\phi_k}{\\sum_{j=1}^N \\phi_j}$ and $\\phi_k = \\frac{w_k}{1 - x_k}$. This constitutes one linear equation.\n- **ODE Collocation**: To maintain a square system, we enforce the ODE $p'(x_k) - \\alpha p(x_k) = 0$ at $N-1$ of the $N$ nodes. The problem specifies that the ODE equation corresponding to the node with the maximal $x_k$ (i.e., the node closest to $x=1$) should be replaced by the boundary condition equation. This node is $x_1 = \\cos(\\pi/(2N))$ (or $x_0$ in a 0-indexed scheme).\n\nThis setup gives a square linear system $A_G u = b_G$ for the nodal values $u=[u_1, \\dots, u_N]^T$. Solving this system yields the nodal values for the Gauss approximant, $p_{\\text{Gauss}}(x)$.\n\n### 3. Error Analysis\n\nTo quantify and compare the accuracy of the two methods, we evaluate the maximum absolute error for each approximation within the boundary layer region. The evaluation grid is concentrated near $x=1$, defined by:\n- Layer width parameter: $\\delta = \\min(0.5, 8/\\alpha)$.\n- Evaluation points: $x_j = 1 - \\delta + \\frac{j}{m-1}\\delta$ for $j=0, \\dots, m-1$, with $m=400$.\n\nThe maximum errors are computed as:\n$$\nE_{\\text{Gauss}} = \\max_{j} |p_{\\text{Gauss}}(x_j) - u(x_j)|\n$$\n$$\nE_{\\text{Lobatto}} = \\max_{j} |p_{\\text{Lobatto}}(x_j) - u(x_j)|\n$$\nThe final metric for comparison is the base-10 logarithm of the ratio of these errors, $\\log_{10}(E_{\\text{Gauss}}/E_{\\text{Lobatto}})$. A large positive value indicates that the Lobatto method is significantly more accurate for the given problem. This is expected, as the inclusion of the boundary node $x=1$ allows for direct enforcement of the boundary condition and provides higher node density in the boundary layer.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# The problem allows for scipy, but numpy.linalg.solve is sufficient.\n# from scipy.linalg import solve as solve_linear_system\n\ndef bary_eval(x_eval, nodes, u_nodal, weights):\n    \"\"\"\n    Evaluates a polynomial given by nodal values using the barycentric formula.\n    Handles singularities where an evaluation point coincides with a node.\n    \"\"\"\n    p_eval = np.zeros_like(x_eval, dtype=float)\n    for i, x in enumerate(x_eval):\n        # Check if the evaluation point x is very close to one of the nodes.\n        match_indices = np.where(np.isclose(x, nodes))[0]\n        if len(match_indices) > 0:\n            # If so, the interpolated value is simply the nodal value.\n            p_eval[i] = u_nodal[match_indices[0]]\n            continue\n\n        # Otherwise, use the standard barycentric formula.\n        diffs = x - nodes\n        numer_terms = weights * u_nodal / diffs\n        denom_terms = weights / diffs\n        \n        numer = np.sum(numer_terms)\n        denom = np.sum(denom_terms)\n\n        # The ratio gives the interpolated value.\n        # Add a small epsilon to avoid division by zero in pathological cases.\n        if abs(denom) < 1e-100:\n           # This case is unlikely if x is not a node but handled for robustness.\n           closest_node_idx = np.argmin(np.abs(diffs))\n           p_eval[i] = u_nodal[closest_node_idx]\n        else:\n           p_eval[i] = numer / denom\n    return p_eval\n\ndef solve_case(N, alpha):\n    \"\"\"\n    Solves the ODE for a given (N, alpha) pair and returns the log10 error ratio.\n    \"\"\"\n    # ====== Part 1: Chebyshev-Gauss-Lobatto Method ======\n    M_L = N + 1\n    # Nodes and weights (0-indexed: k=0, ..., N)\n    k_L = np.arange(M_L)\n    nodes_L = np.cos(k_L * np.pi / N)\n    weights_L = (-1.0)**k_L\n    weights_L[0] *= 0.5\n    weights_L[N] *= 0.5\n\n    # Differentiation matrix D_L using a direct loop for clarity\n    D_L = np.zeros((M_L, M_L))\n    for i in range(M_L):\n        for j in range(M_L):\n            if i != j:\n                D_L[i, j] = (weights_L[j] / weights_L[i]) / (nodes_L[i] - nodes_L[j])\n    np.fill_diagonal(D_L, -np.sum(D_L, axis=1))\n\n    # Construct linear system A_L u_L = b_L\n    A_L = np.identity(M_L)\n    b_L = np.zeros(M_L)\n    \n    ode_matrix_L = D_L - alpha * np.identity(M_L)\n    \n    # First row: Boundary condition u(1)=1 => u_0 = 1\n    A_L[0, :] = 0.0\n    A_L[0, 0] = 1.0\n    b_L[0] = 1.0\n    \n    # Rows 1 to N: ODE u' - alpha*u = 0 at nodes x_1, ..., x_N\n    A_L[1:, :] = ode_matrix_L[1:, :]\n\n    u_L = np.linalg.solve(A_L, b_L)\n\n    # ====== Part 2: Chebyshev-Gauss Method ======\n    M_G = N\n    # Nodes and weights (0-indexed: k=0, ..., N-1)\n    k_G = np.arange(M_G)\n    nodes_G = np.cos((2 * k_G + 1) * np.pi / (2 * N))\n    weights_G = (-1.0)**k_G\n\n    # Differentiation matrix D_G\n    D_G = np.zeros((M_G, M_G))\n    for i in range(M_G):\n        for j in range(M_G):\n            if i != j:\n                D_G[i, j] = (weights_G[j] / weights_G[i]) / (nodes_G[i] - nodes_G[j])\n    np.fill_diagonal(D_G, -np.sum(D_G, axis=1))\n\n    # Construct linear system A_G u_G = b_G\n    A_G = np.identity(M_G)\n    b_G = np.zeros(M_G)\n    \n    ode_matrix_G = D_G - alpha * np.identity(M_G)\n\n    # First row: BC u(1)=1 implemented via barycentric interpolation.\n    # This replaces the ODE at the node closest to x=1 (k=0).\n    x_star = 1.0\n    phi_G = weights_G / (x_star - nodes_G)\n    beta_G = phi_G / np.sum(phi_G)\n    A_G[0, :] = beta_G\n    b_G[0] = 1.0\n    \n    # Rows 1 to N-1: ODE at remaining nodes\n    A_G[1:, :] = ode_matrix_G[1:, :]\n    \n    u_G = np.linalg.solve(A_G, b_G)\n\n    # ====== Part 3: Error Analysis ======\n    m = 400\n    delta = min(0.5, 8.0 / alpha)\n    x_eval = np.linspace(1.0 - delta, 1.0, m)\n\n    # Evaluate numerical and exact solutions on the fine grid\n    p_L_eval = bary_eval(x_eval, nodes_L, u_L, weights_L)\n    p_G_eval = bary_eval(x_eval, nodes_G, u_G, weights_G)\n    u_exact_eval = np.exp(alpha * (x_eval - 1.0))\n\n    # Compute maximum absolute errors\n    E_Gauss = np.max(np.abs(p_G_eval - u_exact_eval))\n    E_Lobatto = np.max(np.abs(p_L_eval - u_exact_eval))\n\n    # Return log10 of the error ratio, handling E_Lobatto=0\n    if E_Lobatto < 1e-100:\n        return np.inf if E_Gauss > 0 else -np.inf\n    \n    return np.log10(E_Gauss / E_Lobatto)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (16, 20),\n        (16, 100),\n        (8, 50),\n        (32, 100),\n    ]\n\n    results = []\n    for N, alpha in test_cases:\n        result = solve_case(N, alpha)\n        results.append(result)\n\n    # Format results to scientific notation with 6 decimal places.\n    formatted_results = [\"{:.6e}\".format(r) for r in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3179398"}, {"introduction": "While global polynomials, like those used in the previous exercise, are powerful, they are not always the best tool for every problem. This advanced practice introduces an alternative using B-splines, a type of basis function with 'local support' that is only non-zero over a small part of the domain. By comparing a B-spline collocation method against a global polynomial method for a problem with a sharp internal layer, you will gain practical insight into the trade-offs between local and global approaches in scientific computing [@problem_id:3214198].", "problem": "Consider the linear boundary value problem on the closed interval $[0,1]$ given by the singularly perturbed reaction-diffusion operator $-\\varepsilon \\frac{d^2}{dx^2} + I$ applied to an unknown function $u(x)$:\n$$\n-\\varepsilon\\, u''(x) + u(x) = f(x), \\quad x \\in (0,1), \\quad u(0)=g_0, \\quad u(1)=g_1,\n$$\nwhere $\\varepsilon > 0$ is a small parameter and $I$ denotes the identity operator. The right-hand side $f(x)$ and boundary data $g_0,g_1$ are chosen so that a prescribed exact solution with a sharp internal layer is satisfied. Specifically, for a given $\\varepsilon$, define the exact solution\n$$\nu_{\\mathrm{exact}}(x;\\varepsilon) := x + a \\tanh\\!\\Big(\\frac{x-x_0}{\\delta(\\varepsilon)}\\Big),\n$$\nwith parameters $a=0.5$, $x_0=0.5$, and layer width $\\delta(\\varepsilon) = \\sqrt{\\varepsilon}$. Let $z(x;\\varepsilon) := \\frac{x-x_0}{\\delta(\\varepsilon)}$. Its derivatives are\n$$\nu'_{\\mathrm{exact}}(x;\\varepsilon) = 1 + \\frac{a}{\\delta(\\varepsilon)} \\,\\mathrm{sech}^2\\!\\big(z(x;\\varepsilon)\\big), \\quad\nu''_{\\mathrm{exact}}(x;\\varepsilon) = -\\frac{2a}{\\delta(\\varepsilon)^2}\\,\\mathrm{sech}^2\\!\\big(z(x;\\varepsilon)\\big)\\,\\tanh\\!\\big(z(x;\\varepsilon)\\big).\n$$\nDefine the right-hand side and boundary data by\n$$\nf(x) := -\\varepsilon\\, u''_{\\mathrm{exact}}(x;\\varepsilon) + u_{\\mathrm{exact}}(x;\\varepsilon), \\quad g_0 := u_{\\mathrm{exact}}(0;\\varepsilon), \\quad g_1 := u_{\\mathrm{exact}}(1;\\varepsilon).\n$$\nThis construction ensures that the exact solution $u_{\\mathrm{exact}}(x;\\varepsilon)$ satisfies the boundary value problem for each $\\varepsilon$.\n\nYour task is to implement two collocation solvers and compare their accuracy:\n\n- A local-support collocation method using B-spline basis functions of degree $p=3$ (cubic) with an open uniform knot vector on $[0,1]$. Let there be $M$ uniform elements (panels). Use the Greville abscissae as collocation points for the interior equations, and impose the two Dirichlet boundary conditions at $x=0$ and $x=1$. Represent the solution in the B-spline basis and enforce the differential equation at the selected collocation points to obtain a linear system for the basis coefficients.\n\n- A global polynomial collocation method using polynomials of degree $n_{\\mathrm{poly}}-1$ with Chebyshev–Lobatto points on $[0,1]$ as collocation nodes. Construct a differentiation matrix that represents the first derivative operator at the nodes based on the fundamental definition of Lagrange interpolation. Then form the discrete second derivative and enforce the differential equation at the interior nodes; impose the Dirichlet boundary conditions at the endpoints by replacing the first and last equations accordingly, which yields a linear system for the nodal values.\n\nFrom fundamental definitions, your implementation should construct the collocation systems as follows:\n- By the definition of collocation, if $u_h(x)$ denotes the approximate solution, then at each interior collocation node $x_j$ one enforces $-\\varepsilon\\, u_h''(x_j) + u_h(x_j) = f(x_j)$. Boundary equations are enforced by $u_h(0)=g_0$ and $u_h(1)=g_1$.\n- In the B-spline method, represent $u_h(x)$ as a linear combination of B-spline basis functions, and use their first and second derivatives, which follow from the Cox–de Boor recursion and its derivative relations, to assemble the linear system.\n- In the global polynomial method, represent $u_h(x)$ in the Lagrange basis at the Chebyshev–Lobatto nodes; differentiate the interpolant using its barycentric representation to obtain a differentiation matrix, and then square it to approximate the second derivative at the nodes.\n\nNumerically evaluate and compare the accuracy of both methods by computing the $L^2$ error over a fine, uniform grid on $[0,1]$:\n$$\n\\|u_h - u_{\\mathrm{exact}}\\|_{L^2(0,1)} \\approx \\sqrt{\\int_0^1 \\big(u_h(x) - u_{\\mathrm{exact}}(x;\\varepsilon)\\big)^2\\,dx},\n$$\napproximated using a composite trapezoidal rule on a sufficiently fine uniform partition of $[0,1]$. There are no physical units in this problem.\n\nTest Suite. Your program must run the following three parameter sets and report the $L^2$ errors for both methods:\n- Case $1$: $\\varepsilon = 10^{-2}$, $M = 8$, $n_{\\mathrm{poly}} = 10$.\n- Case $2$: $\\varepsilon = 10^{-3}$, $M = 8$, $n_{\\mathrm{poly}} = 10$.\n- Case $3$: $\\varepsilon = 10^{-3}$, $M = 16$, $n_{\\mathrm{poly}} = 20$.\n\nYour program must output a single line containing the concatenated list of six floating-point results in the order\n$$\n[\\mathrm{err}^{\\mathrm{B\\!-\\!spline}}_1,\\ \\mathrm{err}^{\\mathrm{poly}}_1,\\ \\mathrm{err}^{\\mathrm{B\\!-\\!spline}}_2,\\ \\mathrm{err}^{\\mathrm{poly}}_2,\\ \\mathrm{err}^{\\mathrm{B\\!-\\!spline}}_3,\\ \\mathrm{err}^{\\mathrm{poly}}_3],\n$$\nwhere $\\mathrm{err}^{\\mathrm{B\\!-\\!spline}}_k$ and $\\mathrm{err}^{\\mathrm{poly}}_k$ are the $L^2$ errors for the B-spline and global polynomial collocation methods, respectively, for test case $k \\in \\{1,2,3\\}$. The output must be exactly one line formatted as a Python-style list with comma-separated values, for example, $[0.1,0.2,0.3,0.4,0.5,0.6]$.\n\nImplementation constraints:\n- Use the programming language Python $3.12$ and the library NumPy $1.23.5$ only, with no other external libraries.\n- Your code must be completely self-contained, must not read input, and must not access any files or network resources.", "solution": "The user wants to solve a singularly perturbed reaction-diffusion boundary value problem using two collocation methods: B-spline collocation and global polynomial collocation.\n\n### **1. Problem Formulation**\n\nThe boundary value problem is defined on the interval $[0,1]$ as:\n$$\n-\\varepsilon\\, u''(x) + u(x) = f(x), \\quad x \\in (0,1)\n$$\nwith Dirichlet boundary conditions $u(0)=g_0$ and $u(1)=g_1$. The parameter $\\varepsilon > 0$ is small, indicating a singular perturbation problem.\n\nThe problem is constructed using the method of manufactured solutions. The exact solution $u_{\\mathrm{exact}}(x;\\varepsilon)$ is prescribed, which then defines the right-hand side $f(x)$ and the boundary data $g_0, g_1$.\n\nThe exact solution is given by:\n$$\nu_{\\mathrm{exact}}(x;\\varepsilon) = x + a \\tanh\\!\\left(\\frac{x-x_0}{\\delta(\\varepsilon)}\\right)\n$$\nwhere $a=0.5$, $x_0=0.5$, and the layer width is $\\delta(\\varepsilon) = \\sqrt{\\varepsilon}$. This function features an internal layer of width proportional to $\\sqrt{\\varepsilon}$ centered at $x=0.5$.\n\nFrom this, the forcing function $f(x)$ is defined as:\n$$\nf(x) = -\\varepsilon\\, u''_{\\mathrm{exact}}(x;\\varepsilon) + u_{\\mathrm{exact}}(x;\\varepsilon)\n$$\nand the boundary data are:\n$$\ng_0 = u_{\\mathrm{exact}}(0;\\varepsilon), \\quad g_1 = u_{\\mathrm{exact}}(1;\\varepsilon)\n$$\nThe second derivative of the exact solution, required to compute $f(x)$, is:\n$$\nu''_{\\mathrm{exact}}(x;\\varepsilon) = -\\frac{2a}{\\delta(\\varepsilon)^2}\\,\\mathrm{sech}^2\\!\\left(\\frac{x-x_0}{\\delta(\\varepsilon)}\\right)\\,\\tanh\\!\\left(\\frac{x-x_0}{\\delta(\\varepsilon)}\\right)\n$$\n\n### **2. B-spline Collocation Method**\n\nThis method approximates the solution $u(x)$ as a linear combination of cubic B-spline basis functions, $u_h(x) = \\sum_{i=0}^{N-1} c_i B_{i,3}(x)$.\n\n-   **Basis and Knots**: We use cubic B-splines ($p=3$) on a uniform mesh of $M$ elements. This requires an open uniform knot vector on $[0,1]$. For degree $p$ and $M$ elements, the number of basis functions is $N=M+p$. The knot vector $t$ has size $M+2p+1$ and is constructed with multiplicities $p+1$ at both endpoints, e.g., $t = \\{ \\underbrace{0, \\dots, 0}_{p+1}, \\frac{1}{M}, \\dots, \\frac{M-1}{M}, \\underbrace{1, \\dots, 1}_{p+1} \\}$.\n\n-   **Collocation Points**: The differential equation is enforced at the interior Greville abscissae. The Greville abscissae are defined as $\\xi_j = \\frac{1}{p}\\sum_{k=j+1}^{j+p} t_k$ for $j=0, \\dots, N-1$. The points $\\xi_0=0$ and $\\xi_{N-1}=1$ are the boundary points, so the interior collocation points are $\\xi_1, \\dots, \\xi_{N-2}$. There are $N-2 = M+p-2$ such points. For $p=3$, this is $M+1$ points.\n\n-   **Linear System**: We need to solve for the $N=M+p$ coefficients $c_i$.\n    1.  **Boundary Conditions**: The Dirichlet boundary conditions are imposed at $x=0$ and $x=1$. Due to the properties of B-splines with an open knot vector, $B_{0,p}(0)=1$ (and all others are zero) and $B_{N-1,p}(1)=1$ (and all others are zero). This directly determines the first and last coefficients:\n        $$ c_0 = u_h(0) = g_0, \\quad c_{N-1} = u_h(1) = g_1 $$\n    2.  **Interior Equations**: For each interior collocation point $x_j = \\xi_j$ ($j=1, \\dots, N-2$), we enforce the differential equation:\n        $$ -\\varepsilon u_h''(x_j) + u_h(x_j) = f(x_j) $$\n        Substituting $u_h(x) = \\sum_{i=0}^{N-1} c_i B_{i,p}(x)$ gives:\n        $$ \\sum_{i=0}^{N-1} c_i \\left( -\\varepsilon B''_{i,p}(x_j) + B_{i,p}(x_j) \\right) = f(x_j) $$\n        Since $c_0$ and $c_{N-1}$ are known, we can move their contributions to the right-hand side, yielding a linear system of size $(N-2) \\times (N-2)$ for the unknown interior coefficients $c_1, \\dots, c_{N-2}$.\n\n-   **Implementation**: The basis functions $B_{i,p}(x)$ and their derivatives are computed using the Cox-de Boor recursion and its derivative formulas. These recursive functions are implemented with memoization to avoid redundant computations.\n\n### **3. Global Polynomial Collocation Method**\n\nThis method approximates the solution using a single polynomial of degree $n_{\\mathrm{poly}}-1$ over the entire domain.\n\n-   **Basis and Nodes**: The solution is represented by its values $U_j = u_h(x_j)$ at a set of $n_{\\mathrm{poly}}$ collocation points. We use the Chebyshev-Lobatto points, which are the extrema of the Chebyshev polynomial $T_{n_{\\mathrm{poly}}-1}(x)$, mapped from $[-1,1]$ to $[0,1]$:\n    $$ x_j = \\frac{1}{2}\\left(1 - \\cos\\left(\\frac{j\\pi}{n_{\\mathrm{poly}}-1}\\right)\\right), \\quad j=0, \\dots, n_{\\mathrm{poly}}-1 $$\n    These nodes include the endpoints $x_0=0$ and $x_{n_{\\mathrm{poly}}-1}=1$.\n\n-   **Differentiation Matrix**: The core of the method is the differentiation matrix $D$, which approximates the derivative of the function at the nodes from its nodal values. The second derivative is then approximated by $D^2$. The entries of the Chebyshev differentiation matrix for nodes on $[-1,1]$ are known analytically. We construct this matrix and then scale it by a factor of $2$ (due to the chain rule for the mapping from $[-1,1]$ to $[0,1]$) to get the differentiation matrix for our nodes on $[0,1]$.\n\n-   **Linear System**: The differential equation is discretized at the collocation nodes, yielding a matrix system:\n    $$ (-\\varepsilon D^2 + I) U = F $$\n    where $U = [U_0, \\dots, U_{n_{\\mathrm{poly}}-1}]^T$ is the vector of unknown nodal values, $I$ is the identity matrix, and $F = [f(x_0), \\dots, f(x_{n_{\\mathrm{poly}}-1})]^T$ is the vector of the forcing function evaluated at the nodes.\n\n    The Dirichlet boundary conditions $U_0 = g_0$ and $U_{n_{\\mathrm{poly}}-1} = g_1$ are imposed by replacing the first and last rows of this linear system.\n    The modified system is then solved for the nodal values $U$.\n\n### **4. Error Evaluation**\n\nFor both methods, after finding the approximate solution $u_h(x)$, we compute the $L^2$ error against the exact solution:\n$$\n\\|u_h - u_{\\mathrm{exact}}\\|_{L^2(0,1)} = \\sqrt{\\int_0^1 \\left(u_h(x) - u_{\\mathrm{exact}}(x;\\varepsilon)\\right)^2 dx}\n$$\nThe integral is approximated numerically using the composite trapezoidal rule on a fine uniform grid of $2001$ points on $[0,1]$.\n\n-   For the B-spline solution, $u_h(x)$ is evaluated at any point $x$ using its basis expansion.\n-   For the polynomial solution, $u_h(x)$ is evaluated using barycentric Lagrange interpolation, which is a stable and efficient formula for evaluating the polynomial interpolant given its nodal values.\n\n### **5. Summary of Test Cases**\nThe program executes this process for the three specified test cases, comparing the accuracy of the local-support B-spline method with the global polynomial (spectral) method, particularly in the context of resolving the sharp internal layer characteristic of the singular perturbation problem.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the singularly perturbed reaction-diffusion BVP using B-spline and\n    global polynomial collocation methods, and reports the L2 errors.\n    \"\"\"\n    \n    # --- Problem Definition ---\n    # Constants for the exact solution\n    A_PARAM = 0.5\n    X0_PARAM = 0.5\n\n    def u_exact(x, eps):\n        delta = np.sqrt(eps)\n        z = (x - X0_PARAM) / delta\n        # Using np.tanh for vectorization\n        return x + A_PARAM * np.tanh(z)\n\n    def u_exact_d2(x, eps):\n        delta = np.sqrt(eps)\n        z = (x - X0_PARAM) / delta\n        cosh_z = np.cosh(z)\n        sech_z_sq = (1.0 / cosh_z)**2\n        tanh_z = np.tanh(z)\n        return -2.0 * A_PARAM / (delta**2) * sech_z_sq * tanh_z\n\n    def f_rhs(x, eps):\n        return -eps * u_exact_d2(x, eps) + u_exact(x, eps)\n\n    # --- B-Spline Method Implementation ---\n\n    memo_b, memo_b_d1, memo_b_d2 = {}, {}, {}\n\n    def safe_div(num, den):\n        return np.divide(num, den, out=np.zeros_like(num, dtype=float), where=(den != 0))\n\n    def bspline_basis(i, p, x, t):\n        if (i, p, x) in memo_b:\n            return memo_b[(i, p, x)]\n        \n        if p == 0:\n            is_last_interval = (t[i] < t[i+1]) and np.isclose(t[i+1], t[-1])\n            val = 1.0 if (t[i] <= x < t[i+1]) or (is_last_interval and np.isclose(x, t[i+1])) else 0.0\n            memo_b[(i, p, x)] = val\n            return val\n\n        term1_coeff = safe_div(x - t[i], t[i+p] - t[i])\n        term1 = term1_coeff * bspline_basis(i, p - 1, x, t)\n\n        term2_coeff = safe_div(t[i+p+1] - x, t[i+p+1] - t[i+1])\n        term2 = term2_coeff * bspline_basis(i + 1, p - 1, x, t)\n        \n        val = term1 + term2\n        memo_b[(i, p, x)] = val\n        return val\n\n    def bspline_deriv1(i, p, x, t):\n        if (i, p, x) in memo_b_d1:\n            return memo_b_d1[(i, p, x)]\n        \n        term1_val = safe_div(p, t[i+p] - t[i]) * bspline_basis(i, p - 1, x, t)\n        term2_val = safe_div(p, t[i+p+1] - t[i+1]) * bspline_basis(i + 1, p - 1, x, t)\n        val = term1_val - term2_val\n        memo_b_d1[(i, p, x)] = val\n        return val\n\n    def bspline_deriv2(i, p, x, t):\n        if (i, p, x) in memo_b_d2:\n            return memo_b_d2[(i, p, x)]\n        if p < 2:\n            return 0.0\n\n        term1_val = safe_div(p, t[i+p] - t[i]) * bspline_deriv1(i, p - 1, x, t)\n        term2_val = safe_div(p, t[i+p+1] - t[i+1]) * bspline_deriv1(i + 1, p - 1, x, t)\n        val = term1_val - term2_val\n        memo_b_d2[(i, p, x)] = val\n        return val\n\n    def solve_bspline(eps, M):\n        p = 3\n        knots = np.concatenate([\n            np.zeros(p), \n            np.linspace(0, 1, M + 1), \n            np.ones(p)\n        ])\n        num_basis_funcs = M + p\n\n        greville_pts = np.array([np.mean(knots[i+1:i+p+1]) for i in range(num_basis_funcs)])\n        interior_coll_pts = greville_pts[1:-1]\n        \n        num_interior_coeffs = num_basis_funcs - 2\n        A = np.zeros((num_interior_coeffs, num_interior_coeffs))\n        b = np.zeros(num_interior_coeffs)\n\n        g0, g1 = u_exact(0.0, eps), u_exact(1.0, eps)\n        c0, c_last = g0, g1\n\n        for j, x_coll in enumerate(interior_coll_pts):\n            memo_b.clear(); memo_b_d1.clear(); memo_b_d2.clear()\n            b[j] = f_rhs(x_coll, eps)\n            \n            b0_val, b0_d2_val = bspline_basis(0, p, x_coll, knots), bspline_deriv2(0, p, x_coll, knots)\n            b[j] -= c0 * (-eps * b0_d2_val + b0_val)\n            \n            blast_val, blast_d2_val = bspline_basis(num_basis_funcs - 1, p, x_coll, knots), bspline_deriv2(num_basis_funcs - 1, p, x_coll, knots)\n            b[j] -= c_last * (-eps * blast_d2_val + blast_val)\n            \n            for k in range(num_interior_coeffs):\n                i = k + 1\n                b_val, b_d2_val = bspline_basis(i, p, x_coll, knots), bspline_deriv2(i, p, x_coll, knots)\n                A[j, k] = -eps * b_d2_val + b_val\n        \n        c_interior = np.linalg.solve(A, b)\n        coeffs = np.concatenate(([c0], c_interior, [c_last]))\n        return coeffs, knots, p\n\n    # --- Global Polynomial Method Implementation ---\n    def chebyshev_lobatto_nodes(n_poly):\n        N = n_poly - 1\n        return 0.5 * (1.0 - np.cos(np.pi * np.arange(0, N + 1) / N))\n\n    def chebyshev_lobatto_diff_matrix(n_poly):\n        N = n_poly - 1\n        if N == 0: return np.zeros((1, 1))\n        \n        x = np.cos(np.pi * np.arange(0, N + 1) / N) # Nodes on [-1,1] decreasing\n        c = np.full(N + 1, 1.0); c[0] = c[N] = 2.0\n        \n        D = np.zeros((N + 1, N + 1))\n        for i in range(N + 1):\n            for j in range(N + 1):\n                if i == j:\n                    if i == 0: D[i, j] = (2 * N**2 + 1) / 6.0\n                    elif i == N: D[i, j] = -(2 * N**2 + 1) / 6.0\n                    else: D[i, j] = -x[i] / (2 * (1 - x[i]**2))\n                else:\n                    D[i, j] = (c[i] / c[j]) * ((-1)**(i + j)) / (x[i] - x[j])\n\n        # Matrix for increasing nodes on [0,1]\n        return D[::-1, ::-1] * 2.0\n\n    def solve_poly(eps, n_poly):\n        nodes = chebyshev_lobatto_nodes(n_poly)\n        D = chebyshev_lobatto_diff_matrix(n_poly)\n        D2 = D @ D\n        \n        A = -eps * D2 + np.eye(n_poly)\n        b = f_rhs(nodes, eps)\n        \n        g0, g1 = u_exact(0.0, eps), u_exact(1.0, eps)\n        \n        A[0, :] = 0.0; A[0, 0] = 1.0; b[0] = g0\n        A[-1, :] = 0.0; A[-1, -1] = 1.0; b[-1] = g1\n        \n        U = np.linalg.solve(A, b)\n        return U, nodes\n\n    # --- Error Calculation ---\n    def get_uh_bspline(coeffs, knots, p):\n        def u_h(x_eval):\n            x_eval_arr = np.atleast_1d(x_eval)\n            y = np.zeros_like(x_eval_arr, dtype=float)\n            for i, x in enumerate(x_eval_arr):\n                memo_b.clear(); memo_b_d1.clear(); memo_b_d2.clear()\n                y[i] = sum(c * bspline_basis(j, p, x, knots) for j, c in enumerate(coeffs))\n            return y[0] if isinstance(x_eval, (int, float)) else y\n        return u_h\n\n    def get_uh_poly(nodal_vals, nodes):\n        n_poly = len(nodes)\n        weights = np.ones(n_poly); weights[1::2] = -1\n        weights[0] *= 0.5; weights[-1] *= 0.5\n        \n        def u_h(x_eval):\n            x_eval_arr = np.atleast_1d(x_eval)\n            y = np.zeros_like(x_eval_arr, dtype=float)\n            for i, x in enumerate(x_eval_arr):\n                match = np.isclose(x, nodes)\n                if np.any(match):\n                    y[i] = nodal_vals[np.where(match)[0][0]]\n                else:\n                    terms = weights / (x - nodes)\n                    y[i] = np.sum(terms * nodal_vals) / np.sum(terms)\n            return y[0] if isinstance(x_eval, (int, float)) else y\n        return u_h\n    \n    def calculate_l2_error(u_h_func, eps, N_fine=2000):\n        x_fine = np.linspace(0.0, 1.0, N_fine + 1)\n        u_h_vals = u_h_func(x_fine)\n        u_exact_vals = u_exact(x_fine, eps)\n        squared_errors = (u_h_vals - u_exact_vals)**2\n        return np.sqrt(np.trapz(squared_errors, x_fine))\n\n    # --- Main Execution Loop ---\n    test_cases = [\n        (1e-2, 8, 10),\n        (1e-3, 8, 10),\n        (1e-3, 16, 20),\n    ]\n    \n    results = []\n    \n    for eps, M, n_poly in test_cases:\n        # B-spline\n        coeffs_b, knots_b, p_b = solve_bspline(eps, M)\n        uh_bspline_func = get_uh_bspline(coeffs_b, knots_b, p_b)\n        err_b = calculate_l2_error(uh_bspline_func, eps)\n        results.append(err_b)\n        \n        # Polynomial\n        U_poly, nodes_poly = solve_poly(eps, n_poly)\n        uh_poly_func = get_uh_poly(U_poly, nodes_poly)\n        err_p = calculate_l2_error(uh_poly_func, eps)\n        results.append(err_p)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3214198"}]}