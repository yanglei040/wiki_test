{"hands_on_practices": [{"introduction": "A cornerstone of stochastic calculus is Itô's Lemma, which serves as the equivalent of the chain rule for functions of stochastic processes. This powerful tool is essential for understanding how a new quantity, which depends on an underlying random process, evolves over time. This exercise provides direct practice in applying Itô's Lemma to derive the dynamics of potential energy for a particle whose position is described by the Ornstein-Uhlenbeck process, a fundamental model in physics and finance [@problem_id:1710369].", "problem": "A microscopic particle is tethered by a spring and is immersed in a liquid bath at a constant temperature. The particle's one-dimensional position, $X_t$, is subject to a linear restoring force from the spring, a viscous drag from the liquid, and random thermal collisions from the liquid's molecules. The dynamics of its position are modeled by the Ornstein-Uhlenbeck process, a type of Stochastic Differential Equation (SDE), given by:\n$$dX_t = -\\theta X_t dt + \\sigma dW_t$$\nHere, $X_t$ is the displacement from the spring's equilibrium position at time $t$. The parameter $\\theta  0$ represents the strength of the restoring force relative to the viscous drag, and $\\sigma  0$ is a constant representing the magnitude of the thermal noise. $W_t$ is a standard Wiener process that models the random kicks.\n\nThe potential energy stored in the spring is a function of the particle's position, given by $V(x) = \\frac{1}{2} k x^2$, where $k  0$ is the spring constant. Let $Y_t = V(X_t)$ be the stochastic process representing the potential energy at time $t$. The evolution of $Y_t$ can also be described by an SDE of the general form:\n$$dY_t = \\alpha(X_t) dt + \\beta(X_t) dW_t$$\n\nDetermine the drift coefficient $\\alpha(X_t)$ and the diffusion coefficient $\\beta(X_t)$, expressed in terms of the particle's position $X_t$ and the constants $k$, $\\theta$, and $\\sigma$. Present your answer as a 1x2 row matrix containing the two expressions in the order $[\\alpha(X_t) \\quad \\beta(X_t)]$.", "solution": "We are given the Itô diffusion for the particle position:\n$$\ndX_{t} = -\\theta X_{t}\\, dt + \\sigma\\, dW_{t},\n$$\nand the potential energy function\n$$\nV(x) = \\frac{1}{2} k x^{2}, \\quad Y_{t} = V(X_{t}).\n$$\nTo obtain the SDE for $Y_{t}$, apply Itô's formula to $V(X_{t})$:\n$$\ndY_{t} = V'(X_{t})\\, dX_{t} + \\frac{1}{2} V''(X_{t})\\, (dX_{t})^{2}.\n$$\nFor the given $V$, compute derivatives:\n$$\nV'(x) = k x, \\quad V''(x) = k.\n$$\nWrite $dX_{t}$ in the standard form $dX_{t} = a(X_{t})\\, dt + b(X_{t})\\, dW_{t}$ with\n$$\na(X_{t}) = -\\theta X_{t}, \\quad b(X_{t}) = \\sigma.\n$$\nUsing Itô rules $(dW_{t})^{2} = dt$, $dt\\, dW_{t} = 0$, and $(dt)^{2} = 0$, we have\n$$\n(dX_{t})^{2} = b(X_{t})^{2}\\, (dW_{t})^{2} = \\sigma^{2}\\, dt.\n$$\nSubstitute into Itô's formula:\n$$\ndY_{t} = V'(X_{t})\\, a(X_{t})\\, dt + V'(X_{t})\\, b(X_{t})\\, dW_{t} + \\frac{1}{2} V''(X_{t})\\, b(X_{t})^{2}\\, dt.\n$$\nWith $V'(X_{t}) = k X_{t}$ and $V''(X_{t}) = k$, this becomes\n$$\ndY_{t} = k X_{t} \\left(-\\theta X_{t}\\right) dt + k X_{t} \\sigma\\, dW_{t} + \\frac{1}{2} k \\sigma^{2}\\, dt.\n$$\nCollecting the $dt$ and $dW_{t}$ terms, we identify the drift and diffusion coefficients:\n$$\n\\alpha(X_{t}) = -k \\theta X_{t}^{2} + \\frac{1}{2} k \\sigma^{2}, \\qquad \\beta(X_{t}) = k \\sigma X_{t}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}-k \\theta X_{t}^{2} + \\frac{1}{2} k \\sigma^{2}  k \\sigma X_{t}\\end{pmatrix}}$$", "id": "1710369"}, {"introduction": "While analytical tools are powerful, many real-world applications of SDEs rely on numerical simulation. This practice problem transitions from pure analysis to the practical world of computation by examining the most fundamental simulation algorithm: the Euler-Maruyama method. You will explore a critical concept in computational science: a numerical scheme may not automatically inherit all the theoretical properties of the continuous model it approximates. By calculating the probability of failure for a specific case, you will gain a crucial appreciation for the nuances and potential pitfalls of simulating stochastic systems [@problem_id:1710381].", "problem": "The Cox-Ingersoll-Ross (CIR) model is frequently used in financial mathematics to describe the evolution of interest rates over time. A key property of the theoretical model is that the rate process, $X_t$, remains non-negative. The dynamics of $X_t$ are governed by the stochastic differential equation (SDE):\n$$dX_t = \\kappa(\\theta - X_t)dt + \\sigma \\sqrt{X_t} dW_t$$\nwhere $\\kappa  0$ is the rate of mean reversion, $\\theta  0$ is the long-term mean, $\\sigma  0$ is the volatility parameter, and $W_t$ is a standard Wiener process. For the continuous process $X_t$ starting at a positive value to remain strictly positive, a sufficient condition is $2\\kappa\\theta  \\sigma^2$.\n\nTo simulate this process numerically, one can employ the Euler-Maruyama method. A single step of this method with time step $\\Delta t$, starting from a state $X_n$ at time $t_n$, computes the next state $X_{n+1}$ at time $t_{n+1} = t_n + \\Delta t$ as:\n$$X_{n+1} = X_n + \\kappa(\\theta - X_n)\\Delta t + \\sigma \\sqrt{X_n} \\Delta W_n$$\nHere, the increment of the Wiener process, $\\Delta W_n$, is a random variable drawn from a normal distribution with a mean of 0 and a variance of $\\Delta t$.\n\nConsider a specific instance of the CIR model with parameters $\\kappa = 0.5$, $\\theta = 0.04$, and $\\sigma = 0.3$. These parameters satisfy the positivity condition $2\\kappa\\theta  \\sigma^2$. Suppose the current state of the process is $X_n = 0.01$. We wish to simulate the next state, $X_{n+1}$, using the Euler-Maruyama method with a single time step of $\\Delta t = 0.25$.\n\nDespite the theoretical guarantee of positivity for the continuous process, this numerical scheme can produce a negative value. Calculate the probability that the next simulated value, $X_{n+1}$, will be negative. Round your final answer to three significant figures.", "solution": "We apply one Euler-Maruyama step:\n$$\nX_{n+1} = X_{n} + \\kappa(\\theta - X_{n})\\Delta t + \\sigma \\sqrt{X_{n}}\\,\\Delta W_{n},\n$$\nwith $\\Delta W_{n} \\sim \\mathcal{N}(0,\\Delta t)$. Conditional on $X_{n}$, this is an affine transformation of a normal variable, hence $X_{n+1}$ is normally distributed with mean\n$$\nm = X_{n} + \\kappa(\\theta - X_{n})\\Delta t\n$$\nand variance\n$$\nv = \\sigma^{2} X_{n} \\Delta t,\n$$\nso standard deviation $s = \\sqrt{v} = \\sigma \\sqrt{X_{n}\\Delta t}$.\n\nThe probability that the Euler step is negative is\n$$\n\\mathbb{P}(X_{n+1}  0 \\mid X_{n}) = \\mathbb{P}\\!\\left(\\frac{X_{n+1} - m}{s}  \\frac{0 - m}{s}\\right) = \\Phi\\!\\left(-\\frac{m}{s}\\right),\n$$\nwhere $\\Phi$ is the standard normal cumulative distribution function.\n\nSubstituting the given values $\\kappa = 0.5$, $\\theta = 0.04$, $\\sigma = 0.3$, $X_{n} = 0.01$, and $\\Delta t = 0.25$, we compute\n$$\nm = 0.01 + 0.5\\,(0.04 - 0.01)\\,0.25 = 0.01 + 0.5 \\cdot 0.03 \\cdot 0.25 = 0.01375,\n$$\n$$\nv = 0.3^{2} \\cdot 0.01 \\cdot 0.25 = 0.000225, \\quad s = \\sqrt{0.000225} = 0.015.\n$$\nTherefore,\n$$\n\\frac{m}{s} = \\frac{0.01375}{0.015} = \\frac{11}{12}, \\quad \\text{so} \\quad \\mathbb{P}(X_{n+1}  0) = \\Phi\\!\\left(-\\frac{11}{12}\\right).\n$$\nNumerically, $\\Phi(-11/12) \\approx 0.1797$, which rounds to three significant figures as $0.180$.", "answer": "$$\\boxed{0.180}$$", "id": "1710381"}, {"introduction": "Having seen that simple numerical methods can be flawed, we now turn to developing more robust solvers. This advanced practice guides you through the design and analysis of an implicit Euler scheme, a method known for its superior stability, especially for so-called \"stiff\" SDEs. This is not just a coding exercise; you will derive the method from first principles and analytically compute its weak accuracy by comparing the evolution of its moments to the exact solution [@problem_id:3279992]. This capstone problem provides a deep dive into the rigorous process of creating and validating numerical methods for SDEs.", "problem": "You are given the linear Stochastic Differential Equation (SDE) $$dX_t = -\\lambda X_t\\,dt + \\sigma\\,dW_t,$$ where $W_t$ is a standard Brownian motion, $\\lambda  0$, and $\\sigma \\ge 0$. This is the classical Ornstein–Uhlenbeck process. The task is to design, analyze, and implement an Implicit Euler time-stepping method for this SDE on a uniform time grid and to quantify its weak accuracy in terms of the first two moments.\n\nStarting from first principles, use only the following as your base:\n- The definition of a Stochastic Differential Equation (SDE) with drift function $a(x)$ and diffusion coefficient $b(x)$ and the meaning of $dW_t$ as an increment of Brownian motion.\n- The properties of Brownian motion increments: for a uniform time step $\\Delta t$, the increment $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ is Gaussian with mean $0$ and variance $\\Delta t$ and has independent increments across time steps.\n- The definition of the Implicit Euler method for SDEs in which the drift is evaluated at the next time level while the diffusion is left in its standard form with the Brownian increment.\n- The Itô isometry and linearity of expectation for computing moments of Gaussian random variables.\n- The fact that all expectations are with respect to the probability space on which the Brownian motion is defined.\n\nProblem requirements:\n1) Derive, from the above base, the one-step Implicit Euler update that maps $X_n$ at time $t_n$ to $X_{n+1}$ at time $t_{n+1} = t_n + \\Delta t$ when applied to the linear SDE with drift $a(x) = -\\lambda x$ and constant diffusion $\\sigma$.\n2) Using only the properties of Gaussian increments, the Itô isometry, and algebra, derive closed-form expressions (no Monte Carlo simulation) for:\n   - The exact mean $\\mathbb{E}[X_T]$ and variance $\\mathrm{Var}(X_T)$ at time $T$ for the SDE.\n   - The mean and variance of the Implicit Euler approximation after $N$ steps with $T = N \\Delta t$.\n3) Implement a complete, runnable program that:\n   - Computes the absolute errors in mean and variance between the Implicit Euler method and the exact solution at time $T$ without Monte Carlo sampling.\n   - Uses the following test suite of parameter sets $(\\lambda, \\sigma, X_0, T, N)$, with $T = N \\Delta t$ and uniform $\\Delta t = T/N$:\n     - Test $1$: $\\lambda = 200$, $\\sigma = 1$, $X_0 = 1$, $T = 1$, $N = 10$.\n     - Test $2$: $\\lambda = 25$, $\\sigma = 1.5$, $X_0 = -1$, $T = 1$, $N = 2000$.\n     - Test $3$: $\\lambda = 50$, $\\sigma = 0$, $X_0 = 3$, $T = 0.2$, $N = 5$.\n     - Test $4$: $\\lambda = 100$, $\\sigma = 0.5$, $X_0 = 2$, $T = 0.01$, $N = 1$.\n   - For each test, returns two floating-point numbers: the absolute error in the mean and the absolute error in the variance at time $T$. There must be no random sampling in your program.\n4) Final output format:\n   - Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $[\\text{err\\_mean\\_1}, \\text{err\\_var\\_1}, \\text{err\\_mean\\_2}, \\text{err\\_var\\_2}, \\text{err\\_mean\\_3}, \\text{err\\_var\\_3}, \\text{err\\_mean\\_4}, \\text{err\\_var\\_4}]$.\n   - Each number must be rounded to exactly $10$ decimal places in decimal notation (not scientific notation).\n   - No additional text should be printed.\n\nAll quantities in this problem are dimensionless. Angles are not used. Percentages are not used. The final output must be a list of floats as specified above, forming a deterministic testable output for the code you implement.", "solution": "The problem statement has been critically validated and is deemed to be scientifically grounded, well-posed, objective, and self-contained. All provided information is consistent and sufficient for deriving a unique and meaningful solution. We may therefore proceed with the derivation and implementation.\n\nThe problem centers on the Ornstein-Uhlenbeck process, a linear stochastic differential equation (SDE) given by:\n$$dX_t = -\\lambda X_t\\,dt + \\sigma\\,dW_t$$\nwhere $\\lambda  0$, $\\sigma \\ge 0$, and $W_t$ is a standard one-dimensional Brownian motion. The initial value is a deterministic constant, $X_0$.\n\n**1. Derivation of the Implicit Euler Scheme**\n\nThe general form of an SDE is $dX_t = a(X_t, t)\\,dt + b(X_t, t)\\,dW_t$. The Implicit Euler method discretizes this SDE over a uniform time grid $t_n = n\\Delta t$ for $n=0, 1, ..., N$. The problem specifies that the drift term is evaluated at the future time step $t_{n+1}$ and the diffusion term is evaluated at the current time step $t_n$. The one-step update rule from $X_n \\approx X_{t_n}$ to $X_{n+1} \\approx X_{t_{n+1}}$ is:\n$$X_{n+1} = X_n + a(X_{n+1}, t_{n+1})\\,\\Delta t + b(X_n, t_n)\\,\\Delta W_n$$\nwhere $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ is the Brownian increment.\n\nFor the given Ornstein-Uhlenbeck process, the drift and diffusion functions are $a(x, t) = -\\lambda x$ and $b(x, t) = \\sigma$, respectively. Substituting these into the general scheme gives:\n$$X_{n+1} = X_n + (-\\lambda X_{n+1})\\,\\Delta t + \\sigma\\,\\Delta W_n$$\nThis equation is implicit in $X_{n+1}$. We must solve for $X_{n+1}$:\n$$X_{n+1} + \\lambda X_{n+1}\\,\\Delta t = X_n + \\sigma\\,\\Delta W_n$$\n$$X_{n+1}(1 + \\lambda\\,\\Delta t) = X_n + \\sigma\\,\\Delta W_n$$\nIsolating $X_{n+1}$ yields the explicit one-step update formula for the Implicit Euler method applied to this SDE:\n$$X_{n+1} = \\frac{1}{1 + \\lambda\\,\\Delta t} X_n + \\frac{\\sigma}{1 + \\lambda\\,\\Delta t} \\Delta W_n$$\nThis is a recursive formula defining the sequence of numerical approximations $\\{X_n\\}_{n=0}^N$.\n\n**2. Derivation of Moments**\n\nWe will now derive the closed-form expressions for the mean and variance of both the exact solution and the numerical approximation.\n\n**A. Exact Moments of the SDE Solution**\n\nThe analytical solution to the Ornstein-Uhlenbeck SDE with a deterministic initial condition $X_0$ is given by:\n$$X_t = X_0 e^{-\\lambda t} + \\sigma \\int_0^t e^{-\\lambda(t-s)}\\,dW_s$$\nThe second term is an Itô integral.\n\n**Exact Mean:** The expectation $\\mathbb{E}[\\cdot]$ is a linear operator. The expectation of an Itô integral with a deterministic integrand is zero.\n$$\\mathbb{E}[X_T] = \\mathbb{E}\\left[X_0 e^{-\\lambda T} + \\sigma \\int_0^T e^{-\\lambda(T-s)}\\,dW_s\\right]$$\n$$\\mathbb{E}[X_T] = X_0 e^{-\\lambda T} + \\sigma \\mathbb{E}\\left[\\int_0^T e^{-\\lambda(T-s)}\\,dW_s\\right]$$\n$$\\mathbb{E}[X_T] = X_0 e^{-\\lambda T}$$\n\n**Exact Variance:** The variance is defined as $\\mathrm{Var}(Y) = \\mathbb{E}[(Y - \\mathbb{E}[Y])^2]$.\n$$X_T - \\mathbb{E}[X_T] = \\sigma \\int_0^T e^{-\\lambda(T-s)}\\,dW_s$$\n$$\\mathrm{Var}(X_T) = \\mathbb{E}\\left[\\left(\\sigma \\int_0^T e^{-\\lambda(T-s)}\\,dW_s\\right)^2\\right] = \\sigma^2 \\mathbb{E}\\left[\\left(\\int_0^T e^{-\\lambda(T-s)}\\,dW_s\\right)^2\\right]$$\nUsing the Itô isometry, which states that $\\mathbb{E}[(\\int_0^T f(s) dW_s)^2] = \\mathbb{E}[\\int_0^T f(s)^2 ds]$, for a deterministic integrand $f(s) = e^{-\\lambda(T-s)}$:\n$$\\mathrm{Var}(X_T) = \\sigma^2 \\int_0^T \\left(e^{-\\lambda(T-s)}\\right)^2 ds = \\sigma^2 \\int_0^T e^{-2\\lambda(T-s)} ds$$\nLet $u = -2\\lambda(T-s)$, then $du = 2\\lambda ds$. The limits of integration for $u$ are from $-2\\lambda T$ (at $s=0$) to $0$ (at $s=T$).\n$$\\mathrm{Var}(X_T) = \\sigma^2 \\int_{-2\\lambda T}^0 e^u \\frac{du}{2\\lambda} = \\frac{\\sigma^2}{2\\lambda} [e^u]_{-2\\lambda T}^0 = \\frac{\\sigma^2}{2\\lambda} (e^0 - e^{-2\\lambda T})$$\n$$\\mathrm{Var}(X_T) = \\frac{\\sigma^2}{2\\lambda} (1 - e^{-2\\lambda T})$$\nThis formula is valid for $\\lambda  0$, as specified in the problem.\n\n**B. Moments of the Implicit Euler Approximation**\n\nLet $m_n = \\mathbb{E}[X_n]$ and $v_n = \\mathrm{Var}(X_n)$ be the mean and variance of the numerical solution at step $n$. The initial conditions are $m_0 = X_0$ and $v_0 = 0$.\nThe recurrence relation is $X_{n+1} = c X_n + d \\Delta W_n$, where $c = \\frac{1}{1+\\lambda\\Delta t}$ and $d = \\frac{\\sigma}{1+\\lambda\\Delta t}$.\n\n**Numerical Mean:** We take the expectation of the recurrence relation.\n$$m_{n+1} = \\mathbb{E}[X_{n+1}] = \\mathbb{E}[c X_n + d \\Delta W_n] = c \\mathbb{E}[X_n] + d \\mathbb{E}[\\Delta W_n]$$\nSince the Brownian increments have zero mean, $\\mathbb{E}[\\Delta W_n]=0$, we get a simple geometric progression:\n$$m_{n+1} = c m_n$$\nSolving this recurrence from $m_0=X_0$ gives $m_N = c^N m_0$. Thus, at time $T=N\\Delta t$:\n$$\\mathbb{E}[X_N] = X_0 \\left(\\frac{1}{1 + \\lambda\\Delta t}\\right)^N$$\n\n**Numerical Variance:** We derive a recurrence for the variance $v_n$.\n$$X_{n+1} - m_{n+1} = (c X_n + d \\Delta W_n) - c m_n = c(X_n - m_n) + d \\Delta W_n$$\n$$v_{n+1} = \\mathrm{Var}(X_{n+1}) = \\mathbb{E}[(X_{n+1} - m_{n+1})^2] = \\mathbb{E}[(c(X_n - m_n) + d \\Delta W_n)^2]$$\n$$v_{n+1} = \\mathbb{E}[c^2(X_n - m_n)^2 + d^2 (\\Delta W_n)^2 + 2cd(X_n - m_n)\\Delta W_n]$$\nBy linearity of expectation: $v_{n+1} = c^2 \\mathbb{E}[(X_n - m_n)^2] + d^2 \\mathbb{E}[(\\Delta W_n)^2] + 2cd \\mathbb{E}[(X_n - m_n)\\Delta W_n]$.\nWe use the facts:\n- $\\mathbb{E}[(X_n-m_n)^2] = v_n$.\n- $\\mathbb{E}[(\\Delta W_n)^2] = \\mathrm{Var}(\\Delta W_n) + (\\mathbb{E}[\\Delta W_n])^2 = \\Delta t + 0^2 = \\Delta t$.\n- $X_n$ is determined by $\\Delta W_0, ..., \\Delta W_{n-1}$ and is therefore independent of the future increment $\\Delta W_n$. Thus, $\\mathbb{E}[(X_n - m_n)\\Delta W_n] = \\mathbb{E}[X_n - m_n]\\mathbb{E}[\\Delta W_n] = 0 \\cdot 0 = 0$.\n\nThis simplifies the variance recurrence to:\n$$v_{n+1} = c^2 v_n + d^2 \\Delta t$$\nThis is a linear first-order recurrence relation with $v_0 = 0$. We can solve it by unrolling:\n$v_1 = d^2 \\Delta t$\n$v_2 = c^2 v_1 + d^2 \\Delta t = (c^2+1) d^2 \\Delta t$\n$v_N = d^2 \\Delta t \\sum_{k=0}^{N-1} (c^2)^k$\nThis is a finite geometric series sum. Since $\\lambda  0$ and $\\Delta t  0$, we have $c^2  1$.\n$$v_N = d^2 \\Delta t \\frac{1 - (c^2)^N}{1-c^2}$$\nNow, we substitute back $c$ and $d$:\n$d^2 = \\frac{\\sigma^2}{(1+\\lambda\\Delta t)^2}$\n$1-c^2 = 1 - \\frac{1}{(1+\\lambda\\Delta t)^2} = \\frac{(1+\\lambda\\Delta t)^2 - 1}{(1+\\lambda\\Delta t)^2} = \\frac{1+2\\lambda\\Delta t+\\lambda^2(\\Delta t)^2-1}{(1+\\lambda\\Delta t)^2} = \\frac{2\\lambda\\Delta t+\\lambda^2 (\\Delta t)^2}{(1+\\lambda\\Delta t)^2}$\nTherefore, $\\frac{d^2}{1-c^2} = \\frac{\\sigma^2 / (1+\\lambda\\Delta t)^2}{(2\\lambda\\Delta t+\\lambda^2 (\\Delta t)^2) / (1+\\lambda\\Delta t)^2} = \\frac{\\sigma^2}{2\\lambda\\Delta t+\\lambda^2 (\\Delta t)^2} = \\frac{\\sigma^2}{\\Delta t (2\\lambda + \\lambda^2 \\Delta t)}$.\nSubstituting this into the expression for $v_N$:\n$$v_N = \\left(\\frac{\\sigma^2}{\\Delta t (2\\lambda + \\lambda^2 \\Delta t)}\\right) \\Delta t (1 - c^{2N}) = \\frac{\\sigma^2}{2\\lambda + \\lambda^2 \\Delta t} (1 - c^{2N})$$\nFinally, the variance of the numerical solution at time $T=N\\Delta t$ is:\n$$\\mathrm{Var}(X_N) = \\frac{\\sigma^2}{2\\lambda + \\lambda^2 \\Delta t} \\left(1 - \\left(\\frac{1}{1+\\lambda \\Delta t}\\right)^{2N}\\right)$$\n\n**3. Summary of Formulas for Implementation**\n\nThe program will compute the absolute errors between the exact and numerical moments. The required formulas are:\n- **Exact Mean:** $\\mathbb{E}[X_T] = X_0 e^{-\\lambda T}$\n- **Exact Variance:** $\\mathrm{Var}(X_T) = \\frac{\\sigma^2}{2\\lambda} (1 - e^{-2\\lambda T})$\n- **Numerical Mean:** $\\mathbb{E}[X_N] = X_0 \\left(\\frac{1}{1 + \\lambda (T/N)}\\right)^N$\n- **Numerical Variance:** $\\mathrm{Var}(X_N) = \\frac{\\sigma^2}{2\\lambda + \\lambda^2 (T/N)} \\left(1 - \\left(\\frac{1}{1+\\lambda (T/N)}\\right)^{2N}\\right)$\n\nThe absolute errors are $|\\mathbb{E}[X_N] - \\mathbb{E}[X_T]|$ and $|\\mathrm{Var}(X_N) - \\mathrm{Var}(X_T)|$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes absolute errors in mean and variance between the Implicit Euler\n    method and the exact solution for the Ornstein-Uhlenbeck process.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (lambda, sigma, X0, T, N)\n        (200.0, 1.0, 1.0, 1.0, 10),\n        (25.0, 1.5, -1.0, 1.0, 2000),\n        (50.0, 0.0, 3.0, 0.2, 5),\n        (100.0, 0.5, 2.0, 0.01, 1),\n    ]\n\n    results = []\n    for case in test_cases:\n        lam, sig, X0, T, N = case\n        \n        # Calculate time step\n        dt = T / N\n\n        # --- Exact Moments ---\n        # Exact Mean: E[X_T] = X_0 * exp(-lambda*T)\n        exact_mean = X0 * np.exp(-lam * T)\n\n        # Exact Variance: Var(X_T) = (sigma^2 / (2*lambda)) * (1 - exp(-2*lambda*T))\n        # This formula is for lambda  0, which is given in the problem.\n        if lam  0:\n            exact_var = (sig**2 / (2 * lam)) * (1 - np.exp(-2 * lam * T))\n        else:\n            # Although the problem states lambda  0, this case is included for completeness.\n            # For lambda=0, Var(X_T) = sigma^2 * T\n            exact_var = sig**2 * T\n            \n        # --- Numerical Moments (Implicit Euler) ---\n        # Numerical Mean: E[X_N] = X_0 * (1 / (1 + lambda*dt))^N\n        num_mean = X0 * (1 / (1 + lam * dt))**N\n        \n        # Numerical Variance: Var(X_N) = (sigma^2 / (2*lambda + lambda^2*dt)) * (1 - (1/(1+lambda*dt))^(2N))\n        # This formula holds for lambda  0.\n        if lam  0:\n            # Pre-calculate common terms for clarity and efficiency\n            base = 1 / (1 + lam * dt)\n            denominator = 2 * lam + lam**2 * dt\n            \n            # Check for division by zero, although not expected given lambda  0\n            if denominator != 0:\n                num_var = (sig**2 / denominator) * (1 - base**(2 * N))\n            else: # Should not be reached\n                num_var = 0.0\n        else:\n            # For lambda=0, Var(X_N) = sigma^2 * T\n            num_var = sig**2 * T\n            \n        # --- Absolute Errors ---\n        err_mean = abs(num_mean - exact_mean)\n        err_var = abs(num_var - exact_var)\n        \n        results.extend([err_mean, err_var])\n\n    # Format the final output as a comma-separated list of strings,\n    # each rounded to 10 decimal places.\n    formatted_results = [f\"{res:.10f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3279992"}]}