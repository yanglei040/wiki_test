{"hands_on_practices": [{"introduction": "The best way to truly understand an algorithm is to perform its steps manually. This first practice guides you through the fundamental mechanics of the Lanczos iteration. By applying the algorithm to a simple rank-one matrix $A = vv^T$, you will directly compute the first few Lanczos vectors and the entries of the corresponding tridiagonal matrix $T_2$. This exercise demystifies the process, showing how the elegant structure of the tridiagonal matrix emerges from a sequence of matrix-vector products and orthogonalization steps [@problem_id:2184040].", "problem": "The Lanczos algorithm is a numerical method for finding eigenvalues and eigenvectors of a large symmetric matrix. It proceeds by constructing an orthonormal basis for a Krylov subspace and, in doing so, produces a symmetric tridiagonal matrix whose eigenvalues approximate those of the original matrix.\n\nConsider a symmetric matrix $A \\in \\mathbb{R}^{n \\times n}$ defined as a rank-one matrix $A = vv^T$, where $v \\in \\mathbb{R}^n$ is a column vector with unit norm, i.e., $v^T v = 1$.\n\nThe Lanczos algorithm is initiated with a starting vector $q_1$, which is also a unit vector ($q_1^T q_1 = 1$). It is specified that the starting vector $q_1$ is not orthogonal to $v$. Let the cosine of the angle between these two vectors be denoted by $c = v^T q_1$. You are given that $0  c  1$.\n\nThe algorithm iteratively generates a sequence of orthonormal vectors $q_1, q_2, \\dots$ and the entries of a symmetric tridiagonal matrix $T_k$. The procedure for two steps is as follows:\n1.  Compute $w_1 = A q_1$.\n2.  Compute $\\alpha_1 = q_1^T w_1$.\n3.  Compute $w'_2 = w_1 - \\alpha_1 q_1$.\n4.  Compute $\\beta_2 = \\|w'_2\\|$. If $\\beta_2=0$, the algorithm terminates. Otherwise, compute $q_2 = w'_2 / \\beta_2$.\n5.  Compute $w_2 = A q_2$.\n6.  Compute $\\alpha_2 = q_2^T w_2$.\n\nYour task is to determine the $2 \\times 2$ symmetric tridiagonal matrix $T_2$ generated after two full iterations of the algorithm.\n$$\nT_2 = \\begin{pmatrix}\n\\alpha_1  \\beta_2 \\\\\n\\beta_2  \\alpha_2\n\\end{pmatrix}\n$$\nExpress your final answer as a matrix whose entries are functions of $c$.", "solution": "We have $A = v v^{T}$ with $v^{T} v = 1$ and a unit starting vector $q_{1}$ such that $c = v^{T} q_{1} \\in (0,1)$. Apply the Lanczos steps as given.\n\nCompute\n$$\nw_{1} = A q_{1} = v(v^{T} q_{1}) = c v.\n$$\nThen\n$$\n\\alpha_{1} = q_{1}^{T} w_{1} = q_{1}^{T} (c v) = c (q_{1}^{T} v) = c^{2}.\n$$\nForm\n$$\nw'_{2} = w_{1} - \\alpha_{1} q_{1} = c v - c^{2} q_{1}.\n$$\nDecompose $v$ into components parallel and orthogonal to $q_{1}$:\n$$\nv = c q_{1} + r, \\quad r = v - c q_{1}, \\quad q_{1}^{T} r = 0, \\quad \\|r\\| = \\sqrt{1 - c^{2}}.\n$$\nLet $u = r / \\|r\\|$ so that $u$ is unit and orthogonal to $q_{1}$. Define $s = \\sqrt{1 - c^{2}}$, so $v = c q_{1} + s u$. Then\n$$\nw'_{2} = c(c q_{1} + s u) - c^{2} q_{1} = c s u,\n$$\nhence\n$$\n\\beta_{2} = \\|w'_{2}\\| = c s = c \\sqrt{1 - c^{2}},\n$$\nand\n$$\nq_{2} = \\frac{w'_{2}}{\\beta_{2}} = u.\n$$\nNext, we compute $\\alpha_2$:\n$$\n\\alpha_{2} = q_2^T A q_2 = u^T (vv^T) u = (u^T v)(v^T u) = (u^T v)^2.\n$$\nSince $v=cq_1+su$, we have $u^T v = u^T(cq_1+su) = c(u^Tq_1) + s(u^Tu) = c(0) + s(1) = s$.\nTherefore, $\\alpha_2 = s^2 = 1 - c^{2}$.\nThe tridiagonal matrix after two iterations is\n$$\nT_{2} = \\begin{pmatrix}\n\\alpha_{1}  \\beta_{2} \\\\\n\\beta_{2}  \\alpha_{2}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nc^{2}  c \\sqrt{1 - c^{2}} \\\\\nc \\sqrt{1 - c^{2}}  1 - c^{2}\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}c^{2}  c\\sqrt{1-c^{2}} \\\\ c\\sqrt{1-c^{2}}  1-c^{2}\\end{pmatrix}}$$", "id": "2184040"}, {"introduction": "A fascinating and important feature of the Lanczos algorithm is its behavior when the starting vector lies within an invariant subspace of the matrix. In such cases, the algorithm may terminate before completing $n$ steps, a phenomenon known as a \"happy breakdown.\" This exercise provides a concrete example of this scenario, where the Krylov subspace is exhausted early [@problem_id:3246897]. By working through this problem, you will see that this premature termination is not a failure, but a sign that the algorithm has found the exact eigenvalues corresponding to that invariant subspace.", "problem": "Consider a real symmetric matrix $A \\in \\mathbb{R}^{4 \\times 4}$ and a nonzero starting vector $b \\in \\mathbb{R}^{4}$ given by\n$$\nA = \\begin{pmatrix}\n4  0  0  0 \\\\\n0  6  0  0 \\\\\n0  0  2  0 \\\\\n0  0  0  11\n\\end{pmatrix},\n\\qquad\nb = \\begin{pmatrix}\n2 \\\\ 1 \\\\ 0 \\\\ 0\n\\end{pmatrix}.\n$$\nThe subspace $\\mathcal{S} = \\mathrm{span}\\{e_{1},e_{2}\\}$ is an invariant subspace of $A$, and $b \\in \\mathcal{S}$. Using the fundamental definitions of the Krylov subspace $\\mathcal{K}_{k}(A,b)$ and the Lanczos method for eigenvalue approximation on symmetric matrices, apply the Lanczos iteration starting from $b$ to construct the first few orthonormal Lanczos vectors and the associated symmetric tridiagonal projection $T$ until premature termination occurs due to invariance. Then determine the largest Ritz value, defined as the largest eigenvalue of the tridiagonal matrix $T$ produced at termination.\n\nProvide your final answer as a single real-valued number. No rounding is required; give the exact value. Do not include units.", "solution": "The Lanczos method for symmetric matrices constructs an orthonormal basis $\\{q_{1}, q_{2}, \\dots\\}$ for the Krylov subspaces $\\mathcal{K}_{k}(A,b) = \\mathrm{span}\\{b, Ab, \\dots, A^{k-1}b\\}$ via the three-term recurrence. At each step, it forms a symmetric tridiagonal matrix $T$ whose entries are the recurrence coefficients $\\alpha_{j}$ and $\\beta_{j}$, and the eigenvalues of $T$ are the Ritz values that approximate eigenvalues of $A$.\n\nWe start with the invariant subspace observation. Since $A$ is diagonal, $A = \\mathrm{diag}(4,6,2,11)$, the subspace $\\mathcal{S} = \\mathrm{span}\\{e_{1},e_{2}\\}$ is invariant because $A e_{1} \\in \\mathcal{S}$ and $A e_{2} \\in \\mathcal{S}$. Because $b = \\begin{pmatrix}2 \\\\ 1 \\\\ 0 \\\\ 0\\end{pmatrix}$ lies in $\\mathcal{S}$, every vector in $\\mathcal{K}_{k}(A,b)$ remains in $\\mathcal{S}$. Therefore, the maximal dimension of the Krylov sequence is at most $2$, and the Lanczos process will terminate prematurely with $\\beta_{2} = 0$.\n\nWe now carry out the iteration explicitly. Normalize $b$ to obtain\n$$\n\\|b\\| = \\sqrt{2^{2} + 1^{2} + 0^{2} + 0^{2}} = \\sqrt{5}, \\qquad q_{1} = \\frac{b}{\\|b\\|} = \\frac{1}{\\sqrt{5}} \\begin{pmatrix} 2 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n**Step 1 of Lanczos:**\n- Compute $A q_1$:\n$$\nA q_{1} = \\frac{1}{\\sqrt{5}} \\begin{pmatrix} 4 \\cdot 2 \\\\ 6 \\cdot 1 \\\\ 2 \\cdot 0 \\\\ 11 \\cdot 0 \\end{pmatrix}\n= \\frac{1}{\\sqrt{5}} \\begin{pmatrix} 8 \\\\ 6 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n- Compute the first diagonal coefficient $\\alpha_1 = q_1^\\top A q_1$:\n$$\n\\alpha_{1} = q_{1}^\\top A q_{1}\n= \\frac{1}{5} \\begin{pmatrix} 2  1  0  0 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 6 \\\\ 0 \\\\ 0 \\end{pmatrix}\n= \\frac{16+6}{5} = \\frac{22}{5}.\n$$\n- Form the residual $r_{1} = A q_{1} - \\alpha_{1} q_{1}$:\n$$\nr_{1} = \\frac{1}{\\sqrt{5}} \\begin{pmatrix} 8 \\\\ 6 \\\\ 0 \\\\ 0 \\end{pmatrix}\n- \\frac{22}{5} \\frac{1}{\\sqrt{5}} \\begin{pmatrix} 2 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n= \\frac{1}{5\\sqrt{5}} \\begin{pmatrix} 40-44 \\\\ 30-22 \\\\ 0 \\\\ 0 \\end{pmatrix}\n= \\frac{1}{5\\sqrt{5}} \\begin{pmatrix} -4 \\\\ 8 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n- The subdiagonal coefficient $\\beta_1 = \\|r_1\\|$:\n$$\n\\beta_1 = \\left\\| \\frac{1}{5 \\sqrt{5}} \\begin{pmatrix} -4 \\\\ 8 \\\\ 0 \\\\ 0 \\end{pmatrix} \\right\\|\n= \\frac{1}{5 \\sqrt{5}} \\sqrt{(-4)^{2} + 8^{2}}\n= \\frac{\\sqrt{80}}{5 \\sqrt{5}} = \\frac{4\\sqrt{5}}{5\\sqrt{5}} = \\frac{4}{5}.\n$$\n- Normalize to get $q_2 = r_1 / \\beta_1$:\n$$\nq_2 = \\frac{ \\frac{1}{5\\sqrt{5}} \\begin{pmatrix} -4 \\\\ 8 \\\\ 0 \\\\ 0 \\end{pmatrix} }{ \\frac{4}{5} }\n= \\frac{1}{\\sqrt{5}} \\begin{pmatrix} -1 \\\\ 2 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n\n**Step 2 of Lanczos:**\n- Compute $A q_2$:\n$$\nA q_{2} = \\frac{1}{\\sqrt{5}} \\begin{pmatrix} 4 \\cdot (-1) \\\\ 6 \\cdot 2 \\\\ 2 \\cdot 0 \\\\ 11 \\cdot 0 \\end{pmatrix}\n= \\frac{1}{\\sqrt{5}} \\begin{pmatrix} -4 \\\\ 12 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n- Compute the second diagonal coefficient $\\alpha_2 = q_2^\\top A q_2$:\n$$\n\\alpha_2 = q_2^\\top A q_2 = \\frac{1}{5} \\begin{pmatrix} -1  2  0  0 \\end{pmatrix} \\begin{pmatrix} -4 \\\\ 12 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\frac{4+24}{5} = \\frac{28}{5}.\n$$\n- Form the residual $r_2 = A q_2 - \\alpha_2 q_2 - \\beta_1 q_1$:\n$$\nr_2 = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} -4 \\\\ 12 \\\\ 0 \\\\ 0 \\end{pmatrix} - \\frac{28}{5}\\frac{1}{\\sqrt{5}}\\begin{pmatrix} -1 \\\\ 2 \\\\ 0 \\\\ 0 \\end{pmatrix} - \\frac{4}{5}\\frac{1}{\\sqrt{5}}\\begin{pmatrix} 2 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\frac{1}{5\\sqrt{5}}\\begin{pmatrix} -20 - (-28) - 8 \\\\ 60 - 56 - 4 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n- The next subdiagonal coefficient is $\\beta_2 = \\|r_2\\| = 0$. This is the premature termination caused by the starting vector $b$ lying in the invariant subspace $\\mathcal{S}$.\n\nThe tridiagonal matrix $T$ at termination is\n$$\nT = \\begin{pmatrix}\n\\alpha_{1}  \\beta_{1} \\\\\n\\beta_{1}  \\alpha_{2}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\frac{22}{5}  \\frac{4}{5} \\\\\n\\frac{4}{5}  \\frac{28}{5}\n\\end{pmatrix}.\n$$\nThe Ritz values are the eigenvalues of $T$, found by solving $\\det(T - \\lambda I) = 0$:\n$$\n\\left(\\frac{22}{5} - \\lambda\\right)\\left(\\frac{28}{5} - \\lambda\\right) - \\left(\\frac{4}{5}\\right)^{2} = 0.\n$$\nExpanding gives\n$$\n\\lambda^{2} - \\left( \\frac{22}{5} + \\frac{28}{5} \\right) \\lambda + \\frac{22 \\cdot 28}{25} - \\frac{16}{25}\n= \\lambda^{2} - 10 \\lambda + \\frac{616-16}{25} = \\lambda^{2} - 10 \\lambda + 24 = 0,\n$$\nwhich factors as $(\\lambda-6)(\\lambda-4)=0$. The roots are\n$$\n\\lambda \\in \\{4, 6\\}.\n$$\nTherefore, the largest Ritz value produced at termination is $6$.", "answer": "$$\\boxed{6}$$", "id": "3246897"}, {"introduction": "The success of the Lanczos method is critically dependent on the choice of the starting vector. This hands-on coding exercise explores this relationship through the concept of the spectral measure, which dictates which eigenvalues are \"visible\" to the algorithm. You will implement the Lanczos iteration and observe firsthand how a starting vector orthogonal to an eigenvector prevents the detection of the corresponding eigenvalue [@problem_id:3246991]. This practice highlights the importance of choosing a starting vector that is not deficient in any eigenvector direction to ensure a comprehensive approximation of the matrix's spectrum.", "problem": "Consider a real symmetric matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ with eigen-decomposition $\\mathbf{A} = \\mathbf{U}\\mathbf{\\Lambda}\\mathbf{U}^\\top$, where $\\mathbf{U}$ is orthogonal with columns $\\mathbf{u}_j$ forming an orthonormal basis of eigenvectors and $\\mathbf{\\Lambda} = \\mathrm{diag}(\\lambda_1,\\dots,\\lambda_n)$ contains the real eigenvalues. For any unit vector $\\mathbf{v} \\in \\mathbb{R}^n$, the spectral measure induced by $\\mathbf{v}$ places mass $w_j = |\\mathbf{u}_j^\\top \\mathbf{v}|^2$ at eigenvalue $\\lambda_j$. The Krylov subspace of order $k$ generated by $(\\mathbf{A},\\mathbf{v})$ is $\\mathcal{K}_k(\\mathbf{A},\\mathbf{v}) = \\mathrm{span}\\{\\mathbf{v},\\mathbf{A}\\mathbf{v},\\dots,\\mathbf{A}^{k-1}\\mathbf{v}\\}$. The Lanczos method constructs an orthonormal basis $\\{\\mathbf{q}_1,\\dots,\\mathbf{q}_m\\}$ for $\\mathcal{K}_m(\\mathbf{A},\\mathbf{v})$ via a three-term recurrence so that $\\mathbf{A}$ is represented in this basis by a symmetric tridiagonal matrix $\\mathbf{T}_m$ with diagonal entries $\\alpha_j$ and off-diagonal entries $\\beta_j$; the eigenvalues of $\\mathbf{T}_m$ are the Rayleigh-Ritz (RR) approximations of the eigenvalues of $\\mathbf{A}$ restricted to $\\mathcal{K}_m(\\mathbf{A},\\mathbf{v})$. If $w_j = 0$ for some $j$, then $\\mathbf{u}_j$ is orthogonal to $\\mathcal{K}_k(\\mathbf{A},\\mathbf{v})$ for all $k$, and $\\lambda_j$ cannot appear among the RR values from Lanczos started at $\\mathbf{v}$. Conversely, if $\\mathbf{v}$ equals an eigenvector $\\mathbf{u}_j$, then Lanczos terminates immediately with $\\mathbf{T}_1 = [\\lambda_j]$, yielding exact capture of $\\lambda_j$ in one step.\n\nYour task is to implement the Lanczos method to demonstrate these phenomena concretely on a small, fully specified example. Work with the matrix\n$$\n\\mathbf{A} = \\mathrm{diag}(1,2,3,4) \\in \\mathbb{R}^{4\\times 4},\n$$\nwhose orthonormal eigenvectors are the standard basis $\\{\\mathbf{e}_1,\\mathbf{e}_2,\\mathbf{e}_3,\\mathbf{e}_4\\}$ and whose eigenvalues are $\\lambda_1=1$, $\\lambda_2=2$, $\\lambda_3=3$, $\\lambda_4=4$. Implement the classical Lanczos three-term recurrence with a unit starting vector $\\mathbf{v}_1$, building the tridiagonal matrix $\\mathbf{T}_m$ until breakdown at the first index $m$ where $\\beta_m \\le \\varepsilon$, with $\\varepsilon = 10^{-12}$, and then compute the RR values as the eigenvalues of $\\mathbf{T}_m$. Use the membership tolerance $\\delta = 10^{-10}$ to test whether a specific eigenvalue appears among the RR values.\n\nFrom first principles, you must justify and test the following cases:\n- Case $1$ (boundary condition: zero spectral mass). Let $\\mathbf{v}_1^{(\\mathrm{no3})} = \\frac{1}{\\sqrt{3}}(1,1,0,1)^\\top$, so the spectral mass on $\\lambda_3$ is $w_3 = |\\mathbf{e}_3^\\top \\mathbf{v}_1^{(\\mathrm{no3})}|^2 = 0$. Run Lanczos until breakdown and check whether the RR values of $\\mathbf{T}_m$ contain $\\lambda_3$ within tolerance $\\delta$. The expected phenomenon is that $\\lambda_3$ does not appear because $\\mathcal{K}_k(\\mathbf{A},\\mathbf{v}_1^{(\\mathrm{no3})})$ is contained in $\\mathrm{span}\\{\\mathbf{e}_1,\\mathbf{e}_2,\\mathbf{e}_4\\}$.\n- Case $2$ (edge case: immediate capture). Let $\\mathbf{v}_1^{(\\mathrm{exact3})} = \\mathbf{e}_3$. Run Lanczos and report the number of steps $m$ until breakdown. The expected phenomenon is $m=1$ and the single RR value equals $\\lambda_3$ exactly.\n- Case $3$ (happy path: nonzero spectral mass). Let $\\mathbf{v}_1^{(\\mathrm{all})} = \\frac{1}{2}(1,1,1,1)^\\top$, so $w_3 = \\left|\\mathbf{e}_3^\\top \\mathbf{v}_1^{(\\mathrm{all})}\\right|^2 = \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{4}$. Run Lanczos until breakdown and check whether the RR values of $\\mathbf{T}_m$ contain $\\lambda_3$ within tolerance $\\delta$. The expected phenomenon is that $\\lambda_3$ appears among the RR values once the Krylov subspace spans the full invariant subspace.\n\nYour implementation must adhere to the following specifications:\n- Construct $\\mathbf{T}_m$ by recording the scalars $\\alpha_j = \\mathbf{q}_j^\\top \\mathbf{A}\\mathbf{q}_j$ and $\\beta_j = \\lVert \\mathbf{w}_j \\rVert_2$, where $\\mathbf{w}_j = \\mathbf{A}\\mathbf{q}_j - \\alpha_j \\mathbf{q}_j - \\beta_{j-1}\\mathbf{q}_{j-1}$ with $\\beta_0 = 0$ and $\\mathbf{q}_0 = \\mathbf{0}$, and $\\mathbf{q}_{j+1} = \\mathbf{w}_j / \\beta_j$ whenever $\\beta_j  \\varepsilon$. Stop when $\\beta_j \\le \\varepsilon$.\n- Compute the RR values as the eigenvalues of $\\mathbf{T}_m$.\n- Use the specified tolerances $\\varepsilon = 10^{-12}$ and $\\delta = 10^{-10}$.\n\nTest Suite and Final Output Specification:\n- Apply the method to the three cases above. For Case $1$, your program must return a boolean indicating whether $\\lambda_3$ appears among the RR values (expected to be false). For Case $2$, your program must return an integer equal to the number of Lanczos steps $m$ until breakdown (expected to be $1$). For Case $3$, your program must return a boolean indicating whether $\\lambda_3$ appears among the RR values (expected to be true).\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order $[\\text{Case 1 result}, \\text{Case 2 result}, \\text{Case 3 result}]$, for example, $[b_1,i_2,b_3]$, where $b_1$ and $b_3$ are booleans and $i_2$ is an integer.\n\nAll quantities in this problem are dimensionless, and there are no physical or angle units involved.", "solution": "The problem requires the implementation of the Lanczos three-term recurrence to find Rayleigh-Ritz approximations of the eigenvalues of a given real symmetric matrix, $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$. We will use this implementation to concretely demonstrate three fundamental properties of the Lanczos method related to the spectral measure of the starting vector. The matrix is specified as $\\mathbf{A} = \\mathrm{diag}(1,2,3,4)$, whose eigenvalues are $\\lambda_j = j$ for $j=1,2,3,4$, and whose corresponding orthonormal eigenvectors are the standard basis vectors $\\{\\mathbf{e}_1, \\mathbf{e}_2, \\mathbf{e}_3, \\mathbf{e}_4\\}$.\n\n### The Lanczos Algorithm\n\nThe Lanczos algorithm is an iterative method that generates an orthonormal basis $\\{\\mathbf{q}_1, \\dots, \\mathbf{q}_m\\}$ for the order-$m$ Krylov subspace $\\mathcal{K}_m(\\mathbf{A}, \\mathbf{v}_1) = \\mathrm{span}\\{\\mathbf{v}_1, \\mathbf{A}\\mathbf{v}_1, \\dots, \\mathbf{A}^{m-1}\\mathbf{v}_1\\}$, where $\\mathbf{v}_1$ is a given unit starting vector. In this basis, the action of $\\mathbf{A}$ on the subspace $\\mathcal{K}_m$ is represented by a symmetric tridiagonal matrix $\\mathbf{T}_m$.\n\nThe algorithm proceeds via the following three-term recurrence, starting with $\\mathbf{q}_1 = \\mathbf{v}_1$, $\\beta_0=0$, and $\\mathbf{q}_0 = \\mathbf{0}$. The iteration for $j=1, 2, \\dots$ is as follows:\n1.  Compute the matrix-vector product: $\\mathbf{z}_j = \\mathbf{A} \\mathbf{q}_j$.\n2.  Compute the diagonal element of $\\mathbf{T}_m$: $\\alpha_j = \\mathbf{q}_j^\\top \\mathbf{z}_j$.\n3.  Compute the unnormalized next Lanczos vector: $\\mathbf{w}_j = \\mathbf{z}_j - \\alpha_j \\mathbf{q}_j - \\beta_{j-1} \\mathbf{q}_{j-1}$.\n4.  Compute the off-diagonal element of $\\mathbf{T}_m$: $\\beta_j = \\lVert \\mathbf{w}_j \\rVert_2$.\n5.  If $\\beta_j$ is smaller than a given tolerance $\\varepsilon$, the algorithm is said to have a (happy) breakdown. This indicates that the Krylov subspace is invariant under $\\mathbf{A}$. We set $m=j$ and terminate. The dimension of the generated subspace is $m$.\n6.  If $\\beta_j  \\varepsilon$, normalize to find the next Lanczos vector: $\\mathbf{q}_{j+1} = \\mathbf{w}_j / \\beta_j$.\n\nAfter $m$ steps, this process yields the symmetric tridiagonal matrix:\n$$\n\\mathbf{T}_m = \\begin{pmatrix}\n\\alpha_1  \\beta_1    \\\\\n\\beta_1  \\alpha_2  \\beta_2   \\\\\n \\beta_2  \\ddots  \\ddots  \\\\\n  \\ddots  \\alpha_{m-1}  \\beta_{m-1} \\\\\n   \\beta_{m-1}  \\alpha_m\n\\end{pmatrix} \\in \\mathbb{R}^{m \\times m}\n$$\nThe eigenvalues of $\\mathbf{T}_m$, known as Rayleigh-Ritz (RR) values, are approximations to the eigenvalues of $\\mathbf{A}$.\n\n### Analysis of Test Cases\n\nWe will now apply this algorithm to the matrix $\\mathbf{A} = \\mathrm{diag}(1,2,3,4)$ with a breakdown tolerance of $\\varepsilon = 10^{-12}$ and an eigenvalue membership tolerance of $\\delta = 10^{-10}$.\n\n**Case 1: Zero Spectral Mass**\n\nThe starting vector is $\\mathbf{v}_1^{(\\mathrm{no3})} = \\frac{1}{\\sqrt{3}}(1,1,0,1)^\\top$. The spectral measure induced by this vector places mass $w_j = |\\mathbf{e}_j^\\top \\mathbf{v}_1^{(\\mathrm{no3})}|^2$ at eigenvalue $\\lambda_j$. For $\\lambda_3=3$, the mass is $w_3 = |\\mathbf{e}_3^\\top \\mathbf{v}_1^{(\\mathrm{no3})}|^2 = |0|^2 = 0$.\n\nFrom first principles, since the starting vector $\\mathbf{v}_1^{(\\mathrm{no3})}$ is a linear combination of only $\\{\\mathbf{e}_1, \\mathbf{e}_2, \\mathbf{e}_4\\}$, it lies in the subspace $S = \\mathrm{span}\\{\\mathbf{e}_1, \\mathbf{e}_2, \\mathbf{e}_4\\}$. Because $\\mathbf{A}$ is diagonal, this subspace is an invariant subspace of $\\mathbf{A}$, meaning that for any vector $\\mathbf{x} \\in S$, $\\mathbf{A}\\mathbf{x}$ is also in $S$. Consequently, all vectors in the Krylov sequence, $\\mathbf{A}^k \\mathbf{v}_1^{(\\mathrm{no3})}$, remain within $S$. The Lanczos procedure, which performs linear combinations of these vectors, will generate an orthonormal basis $\\{\\mathbf{q}_j\\}$ that also lies entirely within $S$. The resulting tridiagonal matrix $\\mathbf{T}_m$ is the representation of $\\mathbf{A}$ restricted to the Krylov subspace $\\mathcal{K}_m(\\mathbf{A}, \\mathbf{v}_1^{(\\mathrm{no3})}) \\subseteq S$. The eigenvalues of $\\mathbf{A}$ restricted to $S$ are $\\{\\lambda_1, \\lambda_2, \\lambda_4\\} = \\{1, 2, 4\\}$. Therefore, the RR values, which are the eigenvalues of $\\mathbf{T}_m$, can only approximate or exactly equal members of $\\{1, 2, 4\\}$. The eigenvalue $\\lambda_3=3$ cannot appear among the RR values. The algorithm should break down at $m=3$, when the Krylov subspace spans $S$. The implementation will run the Lanczos algorithm and check if any of the computed RR values are within a tolerance $\\delta$ of $\\lambda_3=3$. The expected result is `False`.\n\n**Case 2: Exact Eigenvector Start**\n\nThe starting vector is $\\mathbf{v}_1^{(\\mathrm{exact3})} = \\mathbf{e}_3$, which is the eigenvector corresponding to $\\lambda_3=3$.\n\nThe Krylov subspace of order $k1$ is not well-defined, as the vectors become linearly dependent immediately. $\\mathcal{K}_1(\\mathbf{A}, \\mathbf{e}_3) = \\mathrm{span}\\{\\mathbf{e}_3\\}$. The vector $\\mathbf{A}\\mathbf{e}_3 = \\lambda_3 \\mathbf{e}_3 = 3\\mathbf{e}_3$ is not linearly independent of $\\mathbf{e}_3$. Let's trace the first step of the Lanczos algorithm:\n- Initialize: $\\mathbf{q}_1 = \\mathbf{e}_3 = (0,0,1,0)^\\top$.\n- Step $j=1$:\n  - $\\mathbf{z}_1 = \\mathbf{A}\\mathbf{q}_1 = \\mathbf{A}\\mathbf{e}_3 = 3\\mathbf{e}_3 = (0,0,3,0)^\\top$.\n  - $\\alpha_1 = \\mathbf{q}_1^\\top \\mathbf{z}_1 = \\mathbf{e}_3^\\top (3\\mathbf{e}_3) = 3$.\n  - $\\mathbf{w}_1 = \\mathbf{z}_1 - \\alpha_1\\mathbf{q}_1 = 3\\mathbf{e}_3 - 3\\mathbf{e}_3 = \\mathbf{0}$.\n  - $\\beta_1 = \\lVert \\mathbf{w}_1 \\rVert_2 = 0$.\nSince $\\beta_1=0 \\le \\varepsilon$, the algorithm breaks down at $m=1$. The resulting matrix is $\\mathbf{T}_1 = [\\alpha_1] = [3]$. The only RR value is $3$, which is the exact eigenvalue. The process terminates in one step. The task is to report the number of steps, which is $m=1$.\n\n**Case 3: Non-zero Spectral Mass**\n\nThe starting vector is $\\mathbf{v}_1^{(\\mathrm{all})} = \\frac{1}{2}(1,1,1,1)^\\top$. This vector has a non-zero component along every eigenvector $\\mathbf{e}_j$. The spectral mass on $\\lambda_3=3$ is $w_3 = |\\mathbf{e}_3^\\top \\mathbf{v}_1^{(\\mathrm{all})}|^2 = |1/2|^2 = 1/4 \\neq 0$.\n\nBecause the starting vector is not deficient in any eigenvector direction, the Krylov subspace $\\mathcal{K}_k(\\mathbf{A}, \\mathbf{v}_1^{(\\mathrm{all})})$ will grow in dimension with each step until it spans the entire space $\\mathbb{R}^4$. This is because the matrix $\\mathbf{A}$ has distinct eigenvalues. The Lanczos algorithm will therefore run for $m=4$ steps, generating a basis for $\\mathbb{R}^4$. The resulting matrix $\\mathbf{T}_4$ will be a $4 \\times 4$ tridiagonal matrix. The Lanczos relation is $\\mathbf{A} \\mathbf{Q}_4 = \\mathbf{Q}_4 \\mathbf{T}_4$, where $\\mathbf{Q}_4$ is the orthogonal matrix with columns $\\{\\mathbf{q}_1, \\mathbf{q}_2, \\mathbf{q}_3, \\mathbf{q}_4\\}$. This implies that $\\mathbf{T}_4 = \\mathbf{Q}_4^\\top \\mathbf{A} \\mathbf{Q}_4$, so $\\mathbf{T}_4$ is orthogonally similar to $\\mathbf{A}$. Thus, $\\mathbf{T}_4$ must have the same eigenvalues as $\\mathbf{A}$, which are $\\{1, 2, 3, 4\\}$. The algorithm should terminate at $m=4$ because $\\mathcal{K}_4$ is an invariant subspace (it's the whole $\\mathbb{R}^4$), leading to $\\beta_4=0$. The set of RR values will contain $\\lambda_3=3$. The implementation will confirm this by checking if any RR value is within $\\delta$ of $3$. The expected result is `True`.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef lanczos(A, v_start, epsilon):\n    \"\"\"\n    Implements the Lanczos three-term recurrence.\n\n    Args:\n        A (np.ndarray): The real symmetric matrix.\n        v_start (np.ndarray): The starting unit vector.\n        epsilon (float): The breakdown tolerance for beta.\n\n    Returns:\n        tuple: A tuple containing:\n            - m (int): The number of steps until breakdown.\n            - T_m (np.ndarray): The m x m symmetric tridiagonal matrix.\n    \"\"\"\n    n = A.shape[0]\n    \n    # Ensure v_start is a unit vector\n    q = v_start / np.linalg.norm(v_start)\n    q_prev = np.zeros(n)\n    \n    alphas = []\n    betas_off_diag = []\n    \n    m = 0\n    \n    for j in range(n):  # Loop corresponds to j=1, 2, ..., n\n        z = A @ q\n        alpha = q.T @ z\n        alphas.append(alpha)\n        \n        # w = z - alpha*q - beta_{j-1}*q_{j-1}\n        w = z - alpha * q\n        if j > 0:\n            w -= betas_off_diag[-1] * q_prev\n        \n        beta = np.linalg.norm(w)\n        \n        m = j + 1\n        if beta = epsilon:\n            break\n        \n        betas_off_diag.append(beta)\n        q_prev = q\n        q = w / beta\n    \n    # Construct the tridiagonal matrix T_m of size m x m\n    T_m = np.diag(alphas)\n    if m > 1:\n        T_m += np.diag(betas_off_diag, k=1)\n        T_m += np.diag(betas_off_diag, k=-1)\n        \n    return m, T_m\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the three specified cases.\n    \"\"\"\n    # Define matrix, target eigenvalue, and tolerances\n    A = np.diag([1.0, 2.0, 3.0, 4.0])\n    lambda3 = 3.0\n    epsilon = 1e-12\n    delta = 1e-10\n\n    # Define starting vectors for the three cases\n    v_no3 = np.array([1.0, 1.0, 0.0, 1.0]) / np.sqrt(3.0)\n    v_exact3 = np.array([0.0, 0.0, 1.0, 0.0])\n    v_all = np.array([1.0, 1.0, 1.0, 1.0]) / 2.0\n    \n    test_cases = [\n        {\"name\": \"Case 1\", \"vector\": v_no3},\n        {\"name\": \"Case 2\", \"vector\": v_exact3},\n        {\"name\": \"Case 3\", \"vector\": v_all},\n    ]\n\n    results = []\n\n    # Process Case 1: Zero spectral mass on lambda_3\n    m1, T1 = lanczos(A, test_cases[0][\"vector\"], epsilon)\n    rr_values1 = np.linalg.eigvalsh(T1)\n    case1_result = np.any(np.isclose(rr_values1, lambda3, atol=delta))\n    results.append(case1_result)\n\n    # Process Case 2: Exact eigenvector start\n    m2, T2 = lanczos(A, test_cases[1][\"vector\"], epsilon)\n    case2_result = m2\n    results.append(case2_result)\n\n    # Process Case 3: Non-zero spectral mass on lambda_3\n    m3, T3 = lanczos(A, test_cases[2][\"vector\"], epsilon)\n    rr_values3 = np.linalg.eigvalsh(T3)\n    case3_result = np.any(np.isclose(rr_values3, lambda3, atol=delta))\n    results.append(case3_result)\n    \n    # Convert booleans to lowercase strings for printing, if needed,\n    # but standard str() gives 'True'/'False'. The example format\n    # '[b_1,i_2,b_3]' implies placeholders. Using standard str() representation.\n    # The `map(str, ...)` handles conversion of all types.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3246991"}]}