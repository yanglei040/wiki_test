{"hands_on_practices": [{"introduction": "One of the most common sources of poor conditioning in linear systems is a simple lack of balance, where some equations (rows) involve coefficients that are orders of magnitude different from others. This practice demonstrates a fundamental and intuitive preconditioning strategy called diagonal scaling, or equilibration. By simply rescaling the rows of the matrix, we can often achieve a more balanced system that is easier for iterative methods to solve. The goal is to solve the system $A\\mathbf{x} = \\mathbf{b}$ by transforming it into an equivalent system $A'\\mathbf{x} = \\mathbf{b}'$, where $A' = PA$ and $b' = Pb$ [@problem_id:2194457].", "problem": "Consider the linear system of equations $A\\mathbf{x} = \\mathbf{b}$, where the matrix $A$ and vector $\\mathbf{b}$ are given by:\n$$\nA = \\begin{pmatrix} 2  -1  0 \\\\ 1000  2000  -1000 \\\\ 0  -1  2 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}\n$$\nIt is observed that the convergence of many iterative solvers can be improved by transforming the system into an equivalent one, $A'\\mathbf{x} = \\mathbf{b}'$, where the rows of the new matrix $A'$ have a more uniform \"size\". This transformation is achieved using an invertible matrix $P$ such that $A' = PA$ and $\\mathbf{b}' = P\\mathbf{b}$.\n\nYour task is to find a diagonal matrix $P$ of the form\n$$\nP = \\begin{pmatrix} p_1  0  0 \\\\ 0  p_2  0 \\\\ 0  0  p_3 \\end{pmatrix}\n$$\nthat performs row equilibration on $A$. Specifically, determine the values of $p_1, p_2,$ and $p_3$ such that the infinity norm of each row vector in the resulting matrix $A'$ is equal to 1. The infinity norm of a vector $v = (v_1, v_2, \\dots, v_n)$ is defined as $\\|v\\|_{\\infty} = \\max_{i} |v_i|$. For simplicity, you may assume the diagonal entries of $P$ are positive.\n\nExpress your final answer as the 3x3 matrix $P$.", "solution": "We seek a diagonal scaling matrix $P=\\operatorname{diag}(p_{1},p_{2},p_{3})$ such that $A' = PA$ has each row with infinity norm equal to $1$. Let $a_{i}^{T}$ denote the $i$-th row of $A$. Then the $i$-th row of $A'$ is $p_{i}a_{i}^{T}$. Since we assume $p_i > 0$, the infinity norm scales as\n$$\n\\|p_{i}a_{i}^{T}\\|_{\\infty} = p_{i}\\|a_{i}^{T}\\|_{\\infty}.\n$$\nImposing $\\|p_{i}a_{i}^{T}\\|_{\\infty} = 1$ gives\n$$\np_{i} = \\frac{1}{\\|a_{i}^{T}\\|_{\\infty}} \\quad \\text{for } i=1,2,3.\n$$\nCompute the row infinity norms of $A$:\n- Row $1$: $a_{1}^{T}=(2,-1,0)$, so $\\|a_{1}^{T}\\|_{\\infty}=\\max\\{|2|,|{-1}|,|0|\\}=2$, hence $p_{1}=\\frac{1}{2}$.\n- Row $2$: $a_{2}^{T}=(1000,2000,-1000)$, so $\\|a_{2}^{T}\\|_{\\infty}=\\max\\{|1000|,|2000|,|-1000|\\}=2000$, hence $p_{2}=\\frac{1}{2000}$.\n- Row $3$: $a_{3}^{T}=(0,-1,2)$, so $\\|a_{3}^{T}\\|_{\\infty}=\\max\\{|0|,|{-1}|,|2|\\}=2$, hence $p_{3}=\\frac{1}{2}$.\n\nTherefore,\n$$\nP=\\begin{pmatrix}\n\\frac{1}{2}  0  0 \\\\\n0  \\frac{1}{2000}  0 \\\\\n0  0  \\frac{1}{2}\n\\end{pmatrix}.\n$$\nThis choice ensures each row of $A' = PA$ has infinity norm equal to $1$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{2}  0  0 \\\\ 0  \\frac{1}{2000}  0 \\\\ 0  0  \\frac{1}{2}\\end{pmatrix}}$$", "id": "2194457"}, {"introduction": "After addressing poor scaling, a natural question arises: what is the ideal outcome of preconditioning? The theoretical goal is to transform the system so that the new matrix has a condition number of 1. This exercise challenges you to construct a simple diagonal preconditioner that achieves this 'perfect' conditioning for a $2 \\times 2$ system, providing a concrete understanding of what an optimal preconditioner accomplishes. The goal is to achieve $\\kappa=1$ [@problem_id:2194479].", "problem": "In numerical linear algebra, iterative methods are often used to find approximate solutions to large systems of linear equations of the form $A\\mathbf{x} = \\mathbf{b}$. The efficiency of many such methods is highly dependent on the properties of the coefficient matrix $A$, particularly its condition number, $\\kappa(A)$. To improve convergence, a technique called preconditioning is used. The original system is transformed into an equivalent one, $M\\mathbf{x} = \\mathbf{c}$, where $M = P^{-1}A$ and $\\mathbf{c} = P^{-1}\\mathbf{b}$. The matrix $P$ is called a preconditioner, and it is chosen to make the condition number of the preconditioned matrix $M$, $\\kappa(M)$, as close to 1 as possible, while ensuring that $P^{-1}$ is easy to compute.\n\nConsider the matrix $A$ given by:\n$$A = \\begin{pmatrix} 1  2 \\\\ -4  2 \\end{pmatrix}$$\nWe are looking for a diagonal preconditioner $P$ of the form:\n$$P = \\begin{pmatrix} p_1  0 \\\\ 0  p_2 \\end{pmatrix}$$\nwhere $p_1$ and $p_2$ are positive real numbers.\n\nFind the value of the ratio $p_2/p_1$ such that the condition number of the preconditioned matrix $P^{-1}A$ with respect to the matrix 2-norm, $\\kappa_2(P^{-1}A)$, is exactly 1.", "solution": "We want $\\kappa_{2}(P^{-1}A)=1$. For the matrix 2-norm, $\\kappa_{2}(M)=1$ if and only if there exists $\\alpha0$ such that $M^{T}M=\\alpha I$. Let $M=P^{-1}A$ with $P=\\mathrm{diag}(p_{1},p_{2})$ and $p_{1},p_{2}0$. Then\n$$\nM^{T}M=A^{T}P^{-T}P^{-1}A=A^{T}P^{-2}A,\n$$\nsince $P$ is diagonal with positive entries. Write $D=P^{-2}=\\mathrm{diag}(d_{1},d_{2})$ where $d_{1}=p_{1}^{-2}$ and $d_{2}=p_{2}^{-2}$. We seek $d_{1},d_{2}0$ and $\\alpha0$ such that\n$$\nA^{T}DA=\\alpha I.\n$$\nWith $A=\\begin{pmatrix}12\\\\ -42\\end{pmatrix}$, first compute\n$$\nDA=\\begin{pmatrix}d_{1}2d_{1}\\\\ -4d_{2}2d_{2}\\end{pmatrix},\n$$\nand then\n$$\nA^{T}DA=\\begin{pmatrix}1-4\\\\ 22\\end{pmatrix}\\begin{pmatrix}d_{1}2d_{1}\\\\ -4d_{2}2d_{2}\\end{pmatrix}\n=\\begin{pmatrix}d_{1}+16d_{2}2d_{1}-8d_{2}\\\\ 2d_{1}-8d_{2}4d_{1}+4d_{2}\\end{pmatrix}.\n$$\nFor this to equal $\\alpha I$, the off-diagonal entries must vanish and the diagonal entries must be equal. The off-diagonal condition gives\n$$\n2d_{1}-8d_{2}=0 \\quad \\Longrightarrow \\quad d_{1}=4d_{2}.\n$$\nWith this relation, the diagonals match automatically:\n$$\nd_{1}+16d_{2}=4d_{2}+16d_{2}=20d_{2}, \\quad 4d_{1}+4d_{2}=16d_{2}+4d_{2}=20d_{2}.\n$$\nTherefore $D$ must satisfy $d_{1}=4d_{2}$. In terms of $p_{1},p_{2}$, this is\n$$\np_{1}^{-2}=4p_{2}^{-2} \\quad \\Longrightarrow \\quad \\frac{p_{1}^{-2}}{p_{2}^{-2}}=4 \\quad \\Longrightarrow \\quad \\frac{p_{2}^{2}}{p_{1}^{2}}=4 \\quad \\Longrightarrow \\quad \\frac{p_{2}}{p_{1}}=2,\n$$\nusing $p_{1},p_{2}0$. Hence $\\kappa_{2}(P^{-1}A)=1$ precisely when $p_{2}/p_{1}=2$.", "answer": "$$\\boxed{2}$$", "id": "2194479"}, {"introduction": "The most sophisticated preconditioners are often not generic algebraic constructs but are designed with the underlying physical problem in mind. This advanced practice explores this deep connection by examining a convection-diffusion problem, a model for how heat or a substance flows and spreads. You will see firsthand how the effectiveness of a Gauss-Seidel preconditioner is dramatically enhanced when the order of its operations aligns with the physical direction of flow, illustrating a key principle of modern scientific computing [@problem_id:3263468].", "problem": "Consider the one-dimensional steady convection-diffusion boundary value problem on the interval $[0,1]$ with homogeneous Dirichlet boundary conditions: find a function $u(x)$ such that\n$$\n-\\epsilon \\, \\frac{d^2 u}{dx^2} + \\beta \\, \\frac{d u}{dx} = f(x), \\quad x \\in (0,1), \\quad u(0) = 0, \\quad u(1) = 0,\n$$\nwhere $\\epsilon  0$ is the diffusion coefficient and $\\beta$ is the convection velocity. Discretize this problem using a uniform grid with $n$ interior points, grid spacing $h = \\frac{1}{n+1}$, and construct the linear system $A \\mathbf{x} = \\mathbf{b}$ with $\\mathbf{x} \\in \\mathbb{R}^n$. Use the standard second-order central difference for the diffusion term and the first-order upwind difference for the convection term aligned with the sign of $\\beta$:\n- If $\\beta \\ge 0$, approximate $\\frac{d u}{dx}$ by $\\frac{u_i - u_{i-1}}{h}$.\n- If $\\beta  0$, approximate $\\frac{d u}{dx}$ by $\\frac{u_{i+1} - u_i}{h}$.\n\nWith $f(x)$ discretized as a constant forcing, set $\\mathbf{b}$ to the vector of all ones in $\\mathbb{R}^n$. The resulting matrix $A \\in \\mathbb{R}^{n \\times n}$ is tridiagonal with entries determined by $\\epsilon$, $\\beta$, and $h$.\n\nUse left-preconditioned Generalized Minimal Residual method (GMRES) to solve the linear system, where the left preconditioner $M^{-1}$ is chosen to be the Gauss-Seidel preconditioner. Define the Gauss-Seidel preconditioner based on a permutation (ordering) $\\pi$ of unknowns as follows:\n- Let $P_\\pi$ be the permutation matrix associated with ordering $\\pi$, so that $P_\\pi^\\top A P_\\pi$ is the matrix reordered according to $\\pi$.\n- Define $M_\\pi$ to be the lower triangular part (including the diagonal) of $P_\\pi^\\top A P_\\pi$.\n- The preconditioning operation applies $M_\\pi^{-1}$ to a vector in the permuted coordinates and then maps the result back via $P_\\pi$.\n\nImplement left-preconditioned GMRES to solve the system $M_\\pi^{-1} A \\mathbf{x} = M_\\pi^{-1} \\mathbf{b}$ using the Krylov subspace generated by $M_\\pi^{-1} A$ and initial residual $M_\\pi^{-1} \\mathbf{b}$, starting from the zero initial guess. At each iteration $k$, form the approximation $\\mathbf{x}_k$ from the Krylov basis and compute the relative residual\n$$\n\\rho_k = \\frac{\\|\\mathbf{b} - A \\mathbf{x}_k\\|_2}{\\|\\mathbf{b}\\|_2}.\n$$\nTerminate when $\\rho_k \\le 10^{-8}$ or when the iteration count reaches $200$, whichever occurs first. The measure of effectiveness of the preconditioner for a given ordering $\\pi$ is the number of iterations required to reach the tolerance $10^{-8}$; if convergence is not achieved within $200$ iterations, report the iteration count as $200$.\n\nDemonstrate how the effectiveness of the Gauss-Seidel preconditioner depends on the ordering of unknowns relative to the convection direction by running the following test suite. Fix $n = 80$. For each test case, use the specified $(\\epsilon,\\beta,\\pi)$:\n- Test case $1$: $(\\epsilon, \\beta, \\pi) = (0.01, 20, \\text{natural})$, where $\\pi$ is the natural left-to-right ordering.\n- Test case $2$: $(\\epsilon, \\beta, \\pi) = (0.01, 20, \\text{reversed})$, where $\\pi$ is the right-to-left ordering.\n- Test case $3$: $(\\epsilon, \\beta, \\pi) = (0.01, -20, \\text{natural})$.\n- Test case $4$: $(\\epsilon, \\beta, \\pi) = (0.01, -20, \\text{reversed})$.\n- Test case $5$: $(\\epsilon, \\beta, \\pi) = (1.0, 2, \\text{natural})$.\n- Test case $6$: $(\\epsilon, \\beta, \\pi) = (1.0, 2, \\text{reversed})$.\n\nYour program must:\n- Construct $A$ according to the above discretization rules for each $(\\epsilon,\\beta)$.\n- Build the Gauss-Seidel preconditioner based on the specified ordering $\\pi$.\n- Run left-preconditioned GMRES and record the number of iterations to reach $\\rho_k \\le 10^{-8}$ (or $200$ if not reached).\n- Produce a single line of output containing the six iteration counts as a comma-separated list enclosed in square brackets in the order of the test cases $1$ through $6$ (for example, $[i_1,i_2,i_3,i_4,i_5,i_6]$), where each $i_j$ is an integer.", "solution": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the convection-diffusion problem for a suite of test cases\n    using left-preconditioned GMRES with an ordering-dependent\n    Gauss-Seidel preconditioner.\n    \"\"\"\n\n    def _solve_lower_triangular(L, b):\n        \"\"\"\n        Solves the lower triangular system L*x = b via forward substitution.\n        \"\"\"\n        n = len(b)\n        x = np.zeros(n, dtype=float)\n        for i in range(n):\n            s = np.dot(L[i, :i], x[:i])\n            if abs(L[i, i])  1e-16:\n                # Should not happen as the diagonal is positive definite\n                raise ValueError(\"Matrix is singular or near-singular.\")\n            x[i] = (b[i] - s) / L[i, i]\n        return x\n\n    def _run_preconditioned_gmres(A, b, precon_M_pi, precon_pi, tol, max_iter):\n        \"\"\"\n        Implementation of the left-preconditioned GMRES algorithm.\n        \"\"\"\n        n = A.shape[0]\n\n        def apply_preconditioner(z):\n            \"\"\"\n            Applies the Gauss-Seidel preconditioner M_inv.\n            y = M_inv * z\n            \"\"\"\n            # 1. Permute z to the new coordinate system\n            z_perm = z[precon_pi]\n            \n            # 2. Solve the lower triangular system in the permuted system\n            y_perm = _solve_lower_triangular(precon_M_pi, z_perm)\n            \n            # 3. Permute the solution back to the original coordinate system\n            y = np.zeros_like(y_perm)\n            y[precon_pi] = y_perm\n            return y\n\n        # Initial state for GMRES\n        x = np.zeros(n, dtype=float)\n        norm_b = np.linalg.norm(b)\n\n        if norm_b == 0:\n            return 0\n        \n        r0 = b - A @ x\n        initial_rel_res = np.linalg.norm(r0) / norm_b\n        if initial_rel_res = tol:\n            return 0\n\n        # Starting vector for Arnoldi iteration\n        r_tilde = apply_preconditioner(r0)\n        beta_gmres = np.linalg.norm(r_tilde)\n        \n        if beta_gmres  1e-16:\n            return 0\n\n        V = np.zeros((n, max_iter + 1), dtype=float)\n        H = np.zeros((max_iter + 1, max_iter), dtype=float)\n        V[:, 0] = r_tilde / beta_gmres\n\n        for k in range(max_iter):\n            # Arnoldi process (Modified Gram-Schmidt)\n            w = A @ V[:, k]\n            w_tilde = apply_preconditioner(w)\n            \n            for j in range(k + 1):\n                H[j, k] = np.dot(w_tilde, V[:, j])\n                w_tilde -= H[j, k] * V[:, j]\n            \n            H[k + 1, k] = np.linalg.norm(w_tilde)\n            \n            # Check for breakdown\n            if H[k + 1, k]  1e-16:\n                k_eff = k + 1\n                break\n            \n            V[:, k + 1] = w_tilde / H[k + 1, k]\n            \n            # Solve least squares and check for convergence on the true residual\n            k_eff = k + 1\n            H_k_sub = H[:k_eff + 1, :k_eff]\n            g0 = np.zeros(k_eff + 1)\n            g0[0] = beta_gmres\n            \n            y, _, _, _ = np.linalg.lstsq(H_k_sub, g0, rcond=None)\n            \n            x = V[:, :k_eff] @ y\n            rel_res = np.linalg.norm(b - A @ x) / norm_b\n            \n            if rel_res = tol:\n                return k_eff\n        else: # Loop completed without convergence\n          k_eff = max_iter\n\n        # Final check if loop was broken by breakdown or finished\n        H_k_sub = H[:k_eff, :k_eff]\n        g0 = np.zeros(k_eff)\n        g0[0] = beta_gmres\n        y, _, _, _ = np.linalg.lstsq(H_k_sub, g0, rcond=None)\n        x = V[:, :k_eff] @ y\n        rel_res = np.linalg.norm(b - A @ x) / norm_b\n        if rel_res = tol:\n            return k_eff\n\n        return max_iter\n\n    test_cases = [\n        (0.01, 20.0, \"natural\"),\n        (0.01, 20.0, \"reversed\"),\n        (0.01, -20.0, \"natural\"),\n        (0.01, -20.0, \"reversed\"),\n        (1.0, 2.0, \"natural\"),\n        (1.0, 2.0, \"reversed\"),\n    ]\n\n    n = 80\n    tol = 1e-8\n    max_iter = 200\n    h = 1.0 / (n + 1)\n    b = np.ones(n, dtype=float)\n    \n    results = []\n\n    for epsilon, beta, ordering_str in test_cases:\n        A = np.zeros((n, n), dtype=float)\n        \n        # Assemble the matrix A based on upwind discretization\n        if beta = 0:\n            diag_val = 2 * epsilon / h**2 + beta / h\n            sub_diag_val = -epsilon / h**2 - beta / h\n            super_diag_val = -epsilon / h**2\n        else:  # beta  0\n            diag_val = 2 * epsilon / h**2 - beta / h\n            sub_diag_val = -epsilon / h**2\n            super_diag_val = -epsilon / h**2 + beta / h\n        \n        np.fill_diagonal(A, diag_val)\n        np.fill_diagonal(A[1:], sub_diag_val)\n        np.fill_diagonal(A[:, 1:], super_diag_val)\n        \n        # Define the permutation for the Gauss-Seidel preconditioner\n        if ordering_str == \"natural\":\n            pi = np.arange(n)\n        else:  # \"reversed\"\n            pi = np.arange(n - 1, -1, -1)\n            \n        # Construct the preconditioner matrix M_pi\n        A_perm = A[np.ix_(pi, pi)]\n        M_pi = np.tril(A_perm)\n\n        iterations = _run_preconditioned_gmres(A, b, M_pi, pi, tol, max_iter)\n        results.append(iterations)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "answer": "[6,104,104,6,15,15]", "id": "3263468"}]}