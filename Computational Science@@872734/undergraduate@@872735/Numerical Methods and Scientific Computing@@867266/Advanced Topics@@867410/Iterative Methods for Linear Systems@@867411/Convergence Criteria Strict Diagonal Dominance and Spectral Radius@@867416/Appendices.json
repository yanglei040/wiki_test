{"hands_on_practices": [{"introduction": "To begin our hands-on exploration, we start with the most straightforward test for the convergence of iterative methods: Strict Diagonal Dominance (SDD). While SDD provides a quick and useful guarantee of convergence, the fundamental reason lies in the spectral radius of the iteration matrix being less than one. This exercise [@problem_id:3219050] bridges these two crucial concepts, asking you to first verify the SDD property for a given matrix and then directly compute the spectral radius of its Jacobi iteration matrix to confirm that $\\rho(T_J) \\lt 1$.", "problem": "You will work with the concept of Strict Diagonal Dominance (SDD) and its relationship to convergence criteria expressed through the spectral radius for a basic stationary iterative method. Consider the specific real matrix\n$$\nA \\;=\\; \\begin{pmatrix} 4  3 \\\\ 1  3 \\end{pmatrix}.\n$$\nUsing only foundational definitions, carry out the following tasks.\n\nFirst, verify that $A$ is Strictly Diagonally Dominant (SDD) by rows, where a matrix is SDD by rows if for each row index $i$ the inequality $|a_{ii}| \\;\\; \\sum_{j \\neq i} |a_{ij}|$ holds. Next, compute $A^{-1}$ exactly and verify directly from the same definition that $A^{-1}$ fails to be SDD by rows.\n\nFinally, consider the Jacobi method for solving the linear system $A x = b$, derived by splitting $A$ into the sum of its diagonal part and its strictly off-diagonal remainder, and then forming the associated linear stationary iteration. From first principles, derive the corresponding iteration matrix and compute its spectral radius, defined as the maximum of the absolute values of its eigenvalues. Report, as your final answer, the spectral radius of this Jacobi iteration matrix for the given $A$. No rounding is required; provide an exact value.", "solution": "The problem statement is evaluated to be valid as it is mathematically well-posed, self-contained, factually sound, and directly pertains to fundamental concepts in numerical linear algebra. The tasks are unambiguous and lead to a unique, verifiable solution. We will proceed with the analysis as requested.\n\nThe given matrix is\n$$\nA \\;=\\; \\begin{pmatrix} 4  3 \\\\ 1  3 \\end{pmatrix}\n$$\nThe definition of a matrix being Strictly Diagonally Dominant (SDD) by rows requires that for each row index $i$, the absolute value of the diagonal element is strictly greater than the sum of the absolute values of the off-diagonal elements in that row. That is, for all $i$, $|a_{ii}| > \\sum_{j \\neq i} |a_{ij}|$.\n\nFirst, we verify if $A$ is SDD by rows.\nFor row $i=1$: We must check if $|a_{11}| > |a_{12}|$.\n$$\n|4| > |3| \\implies 4 > 3\n$$\nThis inequality is true.\n\nFor row $i=2$: We must check if $|a_{22}| > |a_{21}|$.\n$$\n|3| > |1| \\implies 3 > 1\n$$\nThis inequality is also true. Since the condition holds for all rows, the matrix $A$ is strictly diagonally dominant by rows.\n\nNext, we compute the inverse of $A$. For a $2 \\times 2$ matrix $\\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix}$, the inverse is given by $\\frac{1}{ad-bc} \\begin{pmatrix} d  -b \\\\ -c  a \\end{pmatrix}$.\nThe determinant of $A$ is $\\det(A) = (4)(3) - (3)(1) = 12 - 3 = 9$.\nThe inverse matrix $A^{-1}$ is therefore:\n$$\nA^{-1} \\;=\\; \\frac{1}{9} \\begin{pmatrix} 3  -3 \\\\ -1  4 \\end{pmatrix} \\;=\\; \\begin{pmatrix} \\frac{3}{9}  -\\frac{3}{9} \\\\ -\\frac{1}{9}  \\frac{4}{9} \\end{pmatrix} \\;=\\; \\begin{pmatrix} \\frac{1}{3}  -\\frac{1}{3} \\\\ -\\frac{1}{9}  \\frac{4}{9} \\end{pmatrix}\n$$\nNow, we verify if $A^{-1}$ is SDD by rows. Let $B = A^{-1}$. We use the components $b_{ij}$ of $B$.\nFor row $i=1$: We must check if $|b_{11}| > |b_{12}|$.\n$$\n\\left|\\frac{1}{3}\\right| > \\left|-\\frac{1}{3}\\right| \\implies \\frac{1}{3} > \\frac{1}{3}\n$$\nThis inequality is false, as $\\frac{1}{3}$ is not strictly greater than itself. Therefore, the matrix $A^{-1}$ fails to be strictly diagonally dominant by rows. There is no need to check the second row.\n\nFinally, we consider the Jacobi method for solving $Ax=b$. The method is derived from the splitting of the matrix $A$ into its diagonal part $D$ and its off-diagonal part $R$, such that $A=D+R$. For the given matrix $A$:\n$$\nD = \\begin{pmatrix} 4  0 \\\\ 0  3 \\end{pmatrix} \\quad \\text{and} \\quad R = A - D = \\begin{pmatrix} 0  3 \\\\ 1  0 \\end{pmatrix}\n$$\nThe system $Ax=b$ becomes $(D+R)x=b$. The Jacobi iteration is defined by rearranging this equation to isolate a new iterate $x^{(k+1)}$:\n$$\nDx^{(k+1)} = b - Rx^{(k)}\n$$\nMultiplying by $D^{-1}$ on the left gives the iterative scheme:\n$$\nx^{(k+1)} = -D^{-1}Rx^{(k)} + D^{-1}b\n$$\nThis is of the form $x^{(k+1)} = T_J x^{(k)} + c$, where the Jacobi iteration matrix $T_J$ is given by $T_J = -D^{-1}R$.\nThe inverse of the diagonal matrix $D$ is found by taking the reciprocal of each diagonal element:\n$$\nD^{-1} = \\begin{pmatrix} \\frac{1}{4}  0 \\\\ 0  \\frac{1}{3} \\end{pmatrix}\n$$\nNow we compute $T_J$:\n$$\nT_J = -D^{-1}R = - \\begin{pmatrix} \\frac{1}{4}  0 \\\\ 0  \\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} 0  3 \\\\ 1  0 \\end{pmatrix} = - \\begin{pmatrix} 0  \\frac{3}{4} \\\\ \\frac{1}{3}  0 \\end{pmatrix} = \\begin{pmatrix} 0  -\\frac{3}{4} \\\\ -\\frac{1}{3}  0 \\end{pmatrix}\n$$\nThe spectral radius, $\\rho(T_J)$, is the maximum of the absolute values of the eigenvalues of $T_J$. To find the eigenvalues $\\lambda$, we solve the characteristic equation $\\det(T_J - \\lambda I) = 0$, where $I$ is the identity matrix.\n$$\nT_J - \\lambda I = \\begin{pmatrix} 0  -\\frac{3}{4} \\\\ -\\frac{1}{3}  0 \\end{pmatrix} - \\begin{pmatrix} \\lambda  0 \\\\ 0  \\lambda \\end{pmatrix} = \\begin{pmatrix} -\\lambda  -\\frac{3}{4} \\\\ -\\frac{1}{3}  -\\lambda \\end{pmatrix}\n$$\nThe determinant is:\n$$\n\\det(T_J - \\lambda I) = (-\\lambda)(-\\lambda) - \\left(-\\frac{3}{4}\\right)\\left(-\\frac{1}{3}\\right) = \\lambda^2 - \\frac{3}{12} = \\lambda^2 - \\frac{1}{4}\n$$\nSetting the determinant to zero to find the eigenvalues:\n$$\n\\lambda^2 - \\frac{1}{4} = 0 \\implies \\lambda^2 = \\frac{1}{4}\n$$\nThe eigenvalues are $\\lambda_1 = \\frac{1}{2}$ and $\\lambda_2 = -\\frac{1}{2}$.\nThe absolute values of the eigenvalues are $|\\lambda_1| = |\\frac{1}{2}| = \\frac{1}{2}$ and $|\\lambda_2| = |-\\frac{1}{2}| = \\frac{1}{2}$.\nThe spectral radius is the maximum of these values:\n$$\n\\rho(T_J) = \\max\\left(\\left|\\frac{1}{2}\\right|, \\left|-\\frac{1}{2}\\right|\\right) = \\max\\left(\\frac{1}{2}, \\frac{1}{2}\\right) = \\frac{1}{2}\n$$\nThe fact that $\\rho(T_J)  1$ guarantees that the Jacobi method converges for this system, which is expected since the matrix $A$ is strictly diagonally dominant.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "3219050"}, {"introduction": "After establishing that Strict Diagonal Dominance is a sufficient condition for convergence, a critical question arises: is it also a necessary one? In other words, must a matrix be SDD for an iterative method to converge? This practice problem [@problem_id:3219001] challenges this notion and deepens your understanding of logical implications in mathematics. By working through a counterexample, you will prove that the Jacobi method can converge even for a matrix that is not strictly diagonally dominant, reinforcing that the spectral radius criterion, $\\rho(T_J) \\lt 1$, is the true and final arbiter of convergence.", "problem": "Consider the linear system $A x = b$ solved by the Jacobi method. A matrix $A = [a_{ij}]$ is said to be strictly diagonally dominant if, for every row $i$, one has $|a_{ii}|  \\sum_{j \\neq i} |a_{ij}|$. The spectral radius $\\rho(M)$ of a square matrix $M$ is defined as the maximum of the magnitudes of its eigenvalues. Determine whether strict diagonal dominance is a necessary condition for the convergence of the Jacobi method, and select the option that correctly provides a counterexample and explains why it works.\n\nA. Strict diagonal dominance is not necessary; for $A = \\begin{bmatrix} 4  3 \\\\ 3  3 \\end{bmatrix}$, the Jacobi method converges even though $A$ is not strictly diagonally dominant (row $2$ satisfies $|a_{22}| = \\sum_{j \\neq 2} |a_{2j}|$). The Jacobi iteration matrix has spectral radius $\\rho = \\sqrt{3/4}  1$, so the iteration converges.\n\nB. Strict diagonal dominance is necessary; without it, the Jacobi method always diverges regardless of the right-hand side $b$ or the initial guess.\n\nC. Strict diagonal dominance is not necessary; for $A = \\begin{bmatrix} 1  2 \\\\ 2  1 \\end{bmatrix}$, the Jacobi method converges because the matrix is symmetric positive definite (SPD).\n\nD. Strict diagonal dominance is not necessary; any matrix with at least one row satisfying $|a_{ii}| = \\sum_{j \\neq i} |a_{ij}|$ yields a nilpotent Jacobi iteration matrix, so the method converges in finitely many steps.", "solution": "The question is whether strict diagonal dominance (SDD) is a necessary condition for the convergence of the Jacobi method. A condition is necessary if its absence guarantees failure. To prove that SDD is not necessary, we need to find a single counterexample: a matrix $A$ that is **not** strictly diagonally dominant, for which the Jacobi method still converges. The Jacobi method converges if and only if the spectral radius of its iteration matrix, $T_J$, is less than 1, i.e., $\\rho(T_J)  1$.\n\nLet's analyze each option:\n\n**A. Strict diagonal dominance is not necessary; for $A = \\begin{bmatrix} 4  3 \\\\ 3  3 \\end{bmatrix}$, the Jacobi method converges even though $A$ is not strictly diagonally dominant (row $2$ satisfies $|a_{22}| = \\sum_{j \\neq 2} |a_{2j}|$). The Jacobi iteration matrix has spectral radius $\\rho = \\sqrt{3/4}  1$, so the iteration converges.**\n1.  Check if $A$ is not SDD: For row 1, $|4|  |3|$ holds. For row 2, $|3|  |3|$ is false. So, $A$ is not strictly diagonally dominant. This part is correct.\n2.  Check for convergence: The Jacobi iteration matrix is $T_J = -D^{-1}(L+U)$.\n    $$ D = \\begin{bmatrix} 4  0 \\\\ 0  3 \\end{bmatrix}, \\quad L+U = \\begin{bmatrix} 0  3 \\\\ 3  0 \\end{bmatrix} $$\n    $$ T_J = - \\begin{bmatrix} 1/4  0 \\\\ 0  1/3 \\end{bmatrix} \\begin{bmatrix} 0  3 \\\\ 3  0 \\end{bmatrix} = - \\begin{bmatrix} 0  3/4 \\\\ 1  0 \\end{bmatrix} = \\begin{bmatrix} 0  -3/4 \\\\ -1  0 \\end{bmatrix} $$\n    The characteristic equation is $\\det(T_J - \\lambda I) = \\lambda^2 - (-3/4)(-1) = \\lambda^2 - 3/4 = 0$. The eigenvalues are $\\lambda = \\pm \\sqrt{3}/2$.\n    The spectral radius is $\\rho(T_J) = \\max(|\\sqrt{3}/2|, |-\\sqrt{3}/2|) = \\sqrt{3}/2 \\approx 0.866$.\n    Since $\\rho(T_J)  1$, the Jacobi method converges. This option provides a valid counterexample and correct analysis.\n\n**B. Strict diagonal dominance is necessary; without it, the Jacobi method always diverges regardless of the right-hand side $b$ or the initial guess.**\nThis is a false statement. Option A provides a direct counterexample. SDD is sufficient, not necessary.\n\n**C. Strict diagonal dominance is not necessary; for $A = \\begin{bmatrix} 1  2 \\\\ 2  1 \\end{bmatrix}$, the Jacobi method converges because the matrix is symmetric positive definite (SPD).**\n1.  Check for convergence: $D=I$, so $T_J = -(L+U) = \\begin{bmatrix} 0  -2 \\\\ -2  0 \\end{bmatrix}$. The characteristic equation is $\\lambda^2 - 4 = 0$, so eigenvalues are $\\lambda=\\pm 2$. The spectral radius is $\\rho(T_J)=2$. Since $\\rho(T_J) \\ge 1$, the method diverges. The claim that it converges is false.\n2.  Furthermore, the reasoning is flawed. The eigenvalues of $A$ are $3$ and $-1$, so it is not positive definite.\n\n**D. Strict diagonal dominance is not necessary; any matrix with at least one row satisfying $|a_{ii}| = \\sum_{j \\neq i} |a_{ij}|$ yields a nilpotent Jacobi iteration matrix, so the method converges in finitely many steps.**\nThis is a false generalization. The matrix in option A is a counterexample to this claim. Its Jacobi matrix $T_J$ has eigenvalues $\\pm \\sqrt{3}/2$, which are non-zero, so $T_J$ is not nilpotent.\n\nConclusion: Option A is the only correct choice. It correctly identifies that SDD is not necessary and provides a valid, fully analyzed counterexample.", "answer": "$$\\boxed{A}$$", "id": "3219001"}, {"introduction": "We have seen that convergence is tied to the spectral radius of a specific iteration matrix. This raises another important question: if the Jacobi method converges for a given system $Ax=b$, can we assume that the Gauss-Seidel method will also converge? This advanced exercise [@problem_id:3219042] demonstrates that this is not the case by asking you to construct a matrix where the Jacobi iteration converges but the Gauss-Seidel iteration diverges. This hands-on construction powerfully illustrates that convergence is a property of the entire iterative scheme, not just the matrix $A$, and that the relationship between the convergence of these two fundamental methods can be surprisingly complex.", "problem": "Let $A \\in \\mathbb{R}^{3 \\times 3}$ be split into $A = D + L + U$ where $D$ is the diagonal part, $L$ is the strictly lower triangular part, and $U$ is the strictly upper triangular part. Consider the stationary iterations for solving $A x = b$: the Jacobi iteration and the Gauss–Seidel iteration. Construct a concrete $3 \\times 3$ real matrix $A$ with integer entries such that $A$ is not strictly diagonally dominant by rows, the Jacobi iteration converges (as characterized by the spectral radius of its iteration matrix), while the Gauss–Seidel iteration diverges (as characterized by the spectral radius of its iteration matrix). For your constructed matrix, explicitly derive the Jacobi and Gauss–Seidel iteration matrices from $D$, $L$, and $U$, compute their spectral radii, and report the value of $\\rho(B_{\\mathrm{GS}}) - \\rho(B_{\\mathrm{J}})$. Express your final answer as an exact real number; no rounding is needed.", "solution": "The problem has been validated and is a well-posed problem in numerical linear algebra. It asks for the construction of a specific $3 \\times 3$ real matrix with integer entries that demonstrates that the convergence of the Jacobi iterative method does not imply the convergence of the Gauss-Seidel method. I will construct such a matrix, verify it meets all conditions, and then perform the required calculations.\n\nLet us construct the matrix $A \\in \\mathbb{R}^{3 \\times 3}$ as follows:\n$$\nA = \\begin{pmatrix} 1  2  -2 \\\\ 1  1  1 \\\\ 2  2  1 \\end{pmatrix}\n$$\nThis matrix has integer entries as required.\n\nFirst, we verify that $A$ is not strictly diagonally dominant by rows. The condition for strict diagonal dominance for a row $i$ is $|a_{ii}|  \\sum_{j \\neq i} |a_{ij}|$.\nFor row $1$: $|a_{11}| = |1| = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{12}| + |a_{13}| = |2| + |-2| = 4$. Since $1 \\not 4$, the condition is not met for the first row.\nFor row $2$: $|a_{22}| = |1| = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{21}| + |a_{23}| = |1| + |1| = 2$. Since $1 \\not 2$, the condition is not met for the second row.\nFor row $3$: $|a_{33}| = |1| = 1$. The sum of the absolute values of the off-diagonal elements is $|a_{31}| + |a_{32}| = |2| + |2| = 4$. Since $1 \\not 4$, the condition is not met for the third row.\nSince the condition fails for all three rows, the matrix $A$ is not strictly diagonally dominant by rows.\n\nNext, we analyze the convergence of the Jacobi and Gauss-Seidel iterations. The matrix $A$ is split into its diagonal ($D$), strictly lower triangular ($L$), and strictly upper triangular ($U$) parts:\n$$\nD = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix}, \\quad L = \\begin{pmatrix} 0  0  0 \\\\ 1  0  0 \\\\ 2  2  0 \\end{pmatrix}, \\quad U = \\begin{pmatrix} 0  2  -2 \\\\ 0  0  1 \\\\ 0  0  0 \\end{pmatrix}\n$$\nNote that $D$ is the identity matrix, $I$.\n\nThe Jacobi iteration matrix is given by $B_{\\mathrm{J}} = -D^{-1}(L+U)$. Since $D=I$, this simplifies to $B_{\\mathrm{J}} = -(L+U)$.\n$$\nB_{\\mathrm{J}} = - \\left( \\begin{pmatrix} 0  0  0 \\\\ 1  0  0 \\\\ 2  2  0 \\end{pmatrix} + \\begin{pmatrix} 0  2  -2 \\\\ 0  0  1 \\\\ 0  0  0 \\end{pmatrix} \\right) = - \\begin{pmatrix} 0  2  -2 \\\\ 1  0  1 \\\\ 2  2  0 \\end{pmatrix} = \\begin{pmatrix} 0  -2  2 \\\\ -1  0  -1 \\\\ -2  -2  0 \\end{pmatrix}\n$$\nTo find the spectral radius $\\rho(B_{\\mathrm{J}})$, we compute the eigenvalues $\\lambda$ from the characteristic equation $\\det(B_{\\mathrm{J}} - \\lambda I) = 0$:\n$$\n\\det \\begin{pmatrix} -\\lambda  -2  2 \\\\ -1  -\\lambda  -1 \\\\ -2  -2  -\\lambda \\end{pmatrix} = -\\lambda(\\lambda^2 - 2) - (-2)(\\lambda - 2) + 2(2 - 2\\lambda) = -\\lambda^3 + 2\\lambda + 2\\lambda - 4 + 4 - 4\\lambda = -\\lambda^3\n$$\nThe characteristic equation is $-\\lambda^3 = 0$, which has a triple root $\\lambda = 0$. The eigenvalues are $\\lambda_1 = \\lambda_2 = \\lambda_3 = 0$.\nThe spectral radius of the Jacobi matrix is $\\rho(B_{\\mathrm{J}}) = \\max\\{|0|\\} = 0$.\nSince $\\rho(B_{\\mathrm{J}})  1$, the Jacobi iteration converges.\n\nThe Gauss-Seidel iteration matrix is given by $B_{\\mathrm{GS}} = -(D+L)^{-1}U$.\nFirst, we find the inverse of $(D+L)$:\n$$\nD+L = \\begin{pmatrix} 1  0  0 \\\\ 1  1  0 \\\\ 2  2  1 \\end{pmatrix}\n$$\nUsing forward substitution to solve $(D+L)Y=I$, we find the inverse:\n$$\n(D+L)^{-1} = \\begin{pmatrix} 1  0  0 \\\\ -1  1  0 \\\\ 0  -2  1 \\end{pmatrix}\n$$\nNow, we compute $B_{\\mathrm{GS}}$:\n$$\nB_{\\mathrm{GS}} = -(D+L)^{-1}U = - \\begin{pmatrix} 1  0  0 \\\\ -1  1  0 \\\\ 0  -2  1 \\end{pmatrix} \\begin{pmatrix} 0  2  -2 \\\\ 0  0  1 \\\\ 0  0  0 \\end{pmatrix} = - \\begin{pmatrix} 0  2  -2 \\\\ 0  -2  3 \\\\ 0  0  -2 \\end{pmatrix} = \\begin{pmatrix} 0  -2  2 \\\\ 0  2  -3 \\\\ 0  0  2 \\end{pmatrix}\n$$\nSince $B_{\\mathrm{GS}}$ is an upper triangular matrix, its eigenvalues are its diagonal entries: $\\lambda_1 = 0$, $\\lambda_2 = 2$, and $\\lambda_3 = 2$.\nThe spectral radius of the Gauss-Seidel matrix is $\\rho(B_{\\mathrm{GS}}) = \\max\\{|0|, |2|, |2|\\} = 2$.\nSince $\\rho(B_{\\mathrm{GS}}) = 2 \\ge 1$, the Gauss-Seidel iteration diverges.\n\nThe constructed matrix $A$ fulfills all the given conditions.\nThe final step is to compute the value of $\\rho(B_{\\mathrm{GS}}) - \\rho(B_{\\mathrm{J}})$.\n$$\n\\rho(B_{\\mathrm{GS}}) - \\rho(B_{\\mathrm{J}}) = 2 - 0 = 2\n$$", "answer": "$$\n\\boxed{2}\n$$", "id": "3219042"}]}