{"hands_on_practices": [{"introduction": "We begin by confronting the central challenge in training recurrent networks: the difficulty of learning long-term dependencies. This exercise uses a classic benchmark known as the 'adding problem' to illustrate the vanishing gradient issue. By analytically comparing a simple RNN with its gated counterparts (GRU and LSTM) under a simplified model, you will directly quantify how gating mechanisms create a more stable pathway for gradients to flow through time, enabling the network to link events over long sequences. [@problem_id:3191191]", "problem": "You are asked to formalize and analyze the well-known \"adding problem\" in sequence learning, focusing on the issue of long-term dependencies in deep learning. The adding problem is defined as follows: given a sequence of real numbers in the interval $[0,1]$ of length $L$, exactly two positions are marked, and the target is the sum of the values at the marked positions. A model processes the sequence step by step and outputs a single scalar at the final time step. To isolate the effect of long-time dependencies, consider the worst case in which the first marked position is at $t=1$ and the final output is produced at $t=L$, so the learning signal for the earliest relevant time step must traverse $L-1$ recurrent transitions.\n\nWork with three architectures:\n- Recurrent Neural Network (RNN) with recurrent update using a smooth nonlinearity,\n- Gated Recurrent Unit (GRU),\n- Long Short-Term Memory (LSTM).\n\nAssume the following scientifically standard and widely accepted foundations:\n- The chain rule of differentiation for compositions of functions applies to backpropagation through time, so that gradients at earlier time steps are products of Jacobians across time steps.\n- For stability, the magnitude of backpropagated gradients is governed by the operator norm of the recurrent Jacobian factors along the path that carries memory across time steps.\n- The recurrent Jacobian for a Recurrent Neural Network (RNN) near the origin is dominated by the recurrent weight matrix, and its long-time behavior is controlled by its spectral radius.\n- The gating mechanisms in Gated Recurrent Unit (GRU) and Long Short-Term Memory (LSTM) architectures multiply the previous state by gate values, thereby directly scaling the gradient that flows through the main memory path.\n\nTo make the comparison explicit and computationally tractable, adopt the following consistent simplifications for the analysis:\n- Treat the recurrent Jacobian of the Recurrent Neural Network (RNN) as approximately time-invariant with spectral radius $\\rho$.\n- Treat the forget gate of the Long Short-Term Memory (LSTM) and the update gate of the Gated Recurrent Unit (GRU) as constant scalars across time: the LSTM forget gate is $f$, and the GRU update gate is $z$.\n- Use a normalized output and loss so that constant multiplicative factors outside the recurrent pathway can be absorbed into a single positive scalar $\\alpha$.\n\nParameter values to use in all computations:\n- $\\rho = 0.90$ for the Recurrent Neural Network (RNN),\n- $f = 0.99$ for the Long Short-Term Memory (LSTM),\n- $z = 0.05$ for the Gated Recurrent Unit (GRU),\n- $\\alpha = 1.0$.\n\nDefine the \"training-signal magnitude\" for the earliest marked input as the magnitude of the gradient of the loss with respect to the earliest marked input, propagated along the principal memory path from time $t=L$ back to $t=1$. Using the foundations stated above (chain rule and product of Jacobians), derive expressions for the training-signal magnitude for each architecture as functions of $L$ and the given parameters. Then implement these expressions in a program.\n\nTest suite:\n- Sequence lengths $L \\in \\{50, 75, 100, 500, 1000\\}$.\n- For each $L$, compute the training-signal magnitude for each architecture in the order: Recurrent Neural Network (RNN), Gated Recurrent Unit (GRU), Long Short-Term Memory (LSTM).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets with no spaces, where the list is flattened across the test suite in ascending order of $L$. That is, the output must be:\n$[$RNN$(50)$,GRU$(50)$,LSTM$(50)$,RNN$(75)$,GRU$(75)$,LSTM$(75)$,RNN$(100)$,GRU$(100)$,LSTM$(100)$,RNN$(500)$,GRU$(500)$,LSTM$(500)$,RNN$(1000)$,GRU$(1000)$,LSTM$(1000)]$,\nwhere each entry is a float representing the training-signal magnitude (unitless). The final outputs are floats; no physical units or angles are involved, and no percentages must be printed.", "solution": "The user requests a formal analysis of the \"adding problem\" to compare the ability of three recurrent architectures—Recurrent Neural Network (RNN), Gated Recurrent Unit (GRU), and Long Short-Term Memory (LSTM)—to handle long-term dependencies. The analysis focuses on the magnitude of the gradient signal propagated from the final time step back to the first relevant input.\n\nThe problem is validated as follows:\n- **Step 1: Extract Givens**\n  - Problem: The \"adding problem\" for a sequence of length $L$.\n  - Goal: Compute the \"training-signal magnitude\" for an input at time $t=1$ when the output is at $t=L$.\n  - Architectures: RNN, GRU, LSTM.\n  - Foundations:\n    - Backpropagation through time is based on the chain rule.\n    - Gradient magnitude is governed by the operator norm of recurrent Jacobians.\n    - RNN Jacobian behavior is controlled by the spectral radius of the recurrent weight matrix.\n    - Gating mechanisms in GRU and LSTM scale the gradient flow.\n  - Simplifications for analysis:\n    - RNN recurrent Jacobian is treated as time-invariant with spectral radius $\\rho$.\n    - LSTM forget gate is a constant scalar $f$.\n    - GRU update gate is a constant scalar $z$.\n    - A single positive scalar $\\alpha$ absorbs all constant multiplicative factors outside the recurrent pathway.\n  - Parameter values:\n    - $\\rho = 0.90$\n    - $f = 0.99$\n    - $z = 0.05$\n    - $\\alpha = 1.0$\n  - Test Suite:\n    - Sequence lengths $L \\in \\{50, 75, 100, 500, 1000\\}$.\n    - Computation order: RNN, GRU, LSTM for each $L$.\n\n- **Step 2: Validate Using Extracted Givens**\n  - **Scientifically Grounded:** The problem is firmly rooted in the established principles of deep learning, specifically the analysis of gradient flow in recurrent networks (the vanishing/exploding gradient problem). The simplifications are standard for creating a tractable analytical model of a complex system.\n  - **Well-Posed:** The problem is clearly defined with all necessary parameters and assumptions, leading to a unique, computable solution for each case.\n  - **Objective:** The language is precise and technical, free of subjectivity.\n\n- **Step 3: Verdict and Action**\n  - The problem is deemed **valid**. The simplifications are explicitly stated and serve to isolate the core mechanism of gradient propagation, which is a standard and informative analytical technique. Proceeding with the solution.\n\nThe core principle for analyzing the training-signal magnitude is backpropagation through time (BPTT). The gradient of the loss function $\\mathcal{L}$ with respect to the hidden state $h_t$ at some time step $t$ is computed via the chain rule by propagating the gradient from a later time step $t+1$:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial h_t} = \\frac{\\partial \\mathcal{L}}{\\partial h_{t+1}} \\frac{\\partial h_{t+1}}{\\partial h_t}\n$$\nTo find the gradient with respect to the state at time $t=1$ from the loss computed at time $t=L$, we must apply this rule recursively for $L-1$ steps:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial h_1} = \\frac{\\partial \\mathcal{L}}{\\partial h_L} \\left( \\prod_{t=2}^{L} \\frac{\\partial h_t}{\\partial h_{t-1}} \\right)\n$$\nThe term $\\frac{\\partial h_t}{\\partial h_{t-1}}$ is the recurrent Jacobian matrix at time $t$. The \"training-signal magnitude\" for the input at $t=1$ is dominated by the magnitude of this product of Jacobians, which determines how much the error signal from the output at $t=L$ is amplified or diminished as it travels back to $t=1$. The problem defines a constant $\\alpha$ to absorb all non-recurrent factors, such as $\\frac{\\partial \\mathcal{L}}{\\partial h_L}$ and the final step $\\frac{\\partial h_1}{\\partial x_1}$. Thus, the signal magnitude $S(L)$ is proportional to the norm of the product of Jacobians. Let's analyze this for each architecture.\n\n**Recurrent Neural Network (RNN)**\nThe RNN hidden state update is of the form $h_t = \\phi(W_{hh} h_{t-1} + W_{xh} x_t + b_h)$, where $\\phi$ is a nonlinear activation function like $\\tanh$. The recurrent Jacobian is $\\frac{\\partial h_t}{\\partial h_{t-1}} = \\text{diag}(\\phi'(...))W_{hh}$. The long-term behavior of the product of these matrices is governed by the spectral radius $\\rho$ of the recurrent weight matrix $W_{hh}$. The problem simplifies the analysis by assuming the effective magnitude contribution of each Jacobian step is a constant factor $\\rho$. Propagating the signal across $L-1$ time steps results in this factor being multiplied $L-1$ times.\nThe training-signal magnitude $S_{RNN}$ for a sequence of length $L$ is therefore:\n$$\nS_{RNN}(L) = \\alpha \\rho^{L-1}\n$$\nGiven $\\alpha = 1.0$ and $\\rho = 0.90$, we have:\n$$\nS_{RNN}(L) = (0.90)^{L-1}\n$$\n\n**Long Short-Term Memory (LSTM)**\nThe key to the LSTM's ability to handle long dependencies is its cell state, $c_t$, which is updated via a gating mechanism: $c_t = f_t \\odot c_{t-1} + i_t \\odot \\tilde{c}_t$. Here, $f_t$ is the forget gate and $\\odot$ denotes element-wise multiplication. The gradient pathway through the cell state from $c_t$ to $c_{t-1}$ is primarily scaled by the forget gate, i.e., $\\frac{\\partial c_t}{\\partial c_{t-1}} \\approx \\text{diag}(f_t)$. The problem simplifies this by assuming the forget gate is a constant scalar $f$ for all time steps. The gradient signal flowing back through the main memory path is scaled by $f$ at each of the $L-1$ steps.\nThe training-signal magnitude $S_{LSTM}$ is:\n$$\nS_{LSTM}(L) = \\alpha f^{L-1}\n$$\nGiven $\\alpha = 1.0$ and $f = 0.99$, we have:\n$$\nS_{LSTM}(L) = (0.99)^{L-1}\n$$\n\n**Gated Recurrent Unit (GRU)**\nThe GRU state update is $h_t = (1-z_t) \\odot h_{t-1} + z_t \\odot \\tilde{h}_t$, where $z_t$ is the update gate. The term $(1-z_t)$ acts as a dynamic forget gate, controlling how much of the previous state $h_{t-1}$ is passed to the current state $h_t$. The gradient of $h_t$ with respect to $h_{t-1}$ is therefore directly scaled by this factor. The problem simplifies the analysis by assuming a constant scalar update gate $z$. Consequently, the scaling factor at each of the $L-1$ backpropagation steps is $(1-z)$.\nThe training-signal magnitude $S_{GRU}$ is:\n$$\nS_{GRU}(L) = \\alpha (1-z)^{L-1}\n$$\nGiven $\\alpha = 1.0$ and $z = 0.05$, the scaling factor is $(1-0.05) = 0.95$. We have:\n$$\nS_{GRU}(L) = (0.95)^{L-1}\n$$\n\nThese derived expressions will now be implemented to compute the required values for the specified test suite.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the training-signal magnitude for RNN, GRU, and LSTM architectures\n    for the \"adding problem\" over various sequence lengths.\n    \"\"\"\n    # Define the parameters from the problem statement.\n    rho_rnn = 0.90  # Spectral radius for RNN\n    f_lstm = 0.99   # Forget gate value for LSTM\n    z_gru = 0.05    # Update gate value for GRU\n    alpha = 1.0     # Constant multiplicative factor (can be omitted as it's 1.0)\n    \n    # Define the test cases for sequence length L from the problem statement.\n    test_cases_L = [50, 75, 100, 500, 1000]\n\n    results = []\n    for L in test_cases_L:\n        # The number of recurrent transitions is L-1.\n        exponent = L - 1\n\n        # Calculate the training-signal magnitude for each architecture.\n        # S(L) = alpha * (base)^(L-1)\n        \n        # RNN\n        s_rnn = alpha * (rho_rnn ** exponent)\n        \n        # GRU\n        # The scaling factor is (1 - z)\n        s_gru = alpha * ((1 - z_gru) ** exponent)\n        \n        # LSTM\n        s_lstm = alpha * (f_lstm ** exponent)\n        \n        # Append results in the specified order: RNN, GRU, LSTM\n        results.append(s_rnn)\n        results.append(s_gru)\n        results.append(s_lstm)\n\n    # Format the final output as a comma-separated list of floats in brackets.\n    # e.g., [val1,val2,val3,...]\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3191191"}, {"introduction": "Having seen *why* gating is necessary, we now zoom in on *how* the LSTM's core memory mechanism works. The cell state is often compared to a conveyor belt, capable of carrying information unchanged over many time steps. This practice challenges you to prove the precise conditions for this perfect memory conservation, connecting the abstract update equations to the concrete roles of the input and forget gates. You will then develop a diagnostic tool to detect these 'memory-preserving' states in action. [@problem_id:3142761]", "problem": "Consider a Long Short-Term Memory (LSTM) cell whose cell state update is defined by the fundamental, element-wise recurrence\n$$\n\\mathbf{c}_t=\\mathbf{f}_t\\odot \\mathbf{c}_{t-1}+\\mathbf{i}_t\\odot \\mathbf{g}_t,\n$$\nwhere $t\\in\\{1,2,\\ldots,T\\}$, $\\mathbf{c}_t\\in\\mathbb{R}^d$ is the cell state at time $t$, $\\mathbf{f}_t\\in[0,1]^d$ is the forget gate, $\\mathbf{i}_t\\in[0,1]^d$ is the input gate, $\\mathbf{g}_t\\in[-1,1]^d$ is the candidate cell input, and $\\odot$ denotes the Hadamard product. Assume an initial state $\\mathbf{c}_0\\in\\mathbb{R}^d$ is given. Work entirely from this definition and standard properties of vector norms and inequalities.\n\nTasks:\n1) Show that if $\\mathbf{f}_t=\\mathbf{1}$ and $\\mathbf{i}_t=\\mathbf{0}$ for all $t$, then $\\mathbf{c}_t=\\mathbf{c}_0$ for all $t$. Your reasoning should use only the cell update definition and a valid proof technique.\n2) Propose a principled diagnostic to detect near-conserved memory segments in a trained network when $\\mathbf{c}_t$ is observable. Define a scalar per-step measure $s_t$ that quantifies relative change using the Euclidean norm, explain why it is appropriate based on the defining recurrence and norm inequalities, and define a near-conserved segment as a contiguous run of time indices where $s_t$ stays below a given tolerance $\\varepsilon0$.\n3) Implement the diagnostic as an algorithm that, given $\\{\\mathbf{c}_t\\}_{t=0}^T$, a tolerance $\\varepsilon0$, and a minimum segment length $L\\in\\mathbb{N}$, returns:\n   - the integer length of the longest run of consecutive time steps $t\\in\\{1,\\ldots,T\\}$ such that $s_t\\le \\varepsilon$, and\n   - a boolean indicating whether there exists at least one run of length at least $L$.\nUse the Euclidean norm and define\n$$\ns_t=\\frac{\\lVert \\mathbf{c}_t-\\mathbf{c}_{t-1}\\rVert_2}{\\lVert \\mathbf{c}_{t-1}\\rVert_2+\\delta},\n$$\nwith a fixed numerical stabilizer $\\delta=10^{-12}$.\n4) For each test case below, first generate $\\{\\mathbf{c}_t\\}_{t=0}^T$ by simulating the LSTM recurrence with the specified $\\mathbf{f}_t$, $\\mathbf{i}_t$, $\\mathbf{g}_t$, and $\\mathbf{c}_0$. Then apply your diagnostic to produce the two required outputs.\n\nTest suite:\n- Case A (perfect conservation): $T=20$, $d=3$, $\\mathbf{c}_0=[2,-1,0.5]$, $\\mathbf{f}_t=\\mathbf{1}$, $\\mathbf{i}_t=\\mathbf{0}$, $\\mathbf{g}_t=[0.3,-0.4,0.5]$ for all $t$, $\\varepsilon=10^{-12}$, $L=10$.\n- Case B (slow exponential drift via forget gate): $T=30$, $d=1$, $\\mathbf{c}_0=[1.0]$, $\\mathbf{f}_t=[0.99]$, $\\mathbf{i}_t=[0.0]$, $\\mathbf{g}_t=[0.0]$ for all $t$, $\\varepsilon=0.005$, $L=5$.\n- Case C (small constant input injection): $T=25$, $d=2$, $\\mathbf{c}_0=[1.0,1.0]$, $\\mathbf{f}_t=[1.0,1.0]$, $\\mathbf{i}_t=[0.02,0.02]$, $\\mathbf{g}_t=[0.5,0.5]$ for all $t$, $\\varepsilon=0.02$, $L=10$.\n- Case D (zero state, exact conservation): $T=10$, $d=3$, $\\mathbf{c}_0=[0.0,0.0,0.0]$, $\\mathbf{f}_t=\\mathbf{1}$, $\\mathbf{i}_t=\\mathbf{0}$, $\\mathbf{g}_t=[0.7,-0.3,0.1]$ for all $t$, $\\varepsilon=10^{-12}$, $L=5$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one test case, in the order A, B, C, D, and is itself a two-element list containing:\n- the integer length of the longest near-conserved run of steps, and\n- the boolean indicating whether there exists a run of at least length $L$.\nThe line must have no spaces. For example, a valid output with two cases would look like `[[3,True],[0,False]]`.", "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of recurrent neural networks, specifically the Long Short-Term Memory (LSTM) cell architecture. The tasks are well-posed, objective, and self-contained, providing all necessary definitions, equations, and data for a unique solution. The problem requires a combination of mathematical proof, principled a priori reasoning, and algorithmic implementation, which is a standard format for an advanced computational science problem.\n\n### Task 1: Proof of State Conservation\n\nWe are asked to show that if the forget gate $\\mathbf{f}_t = \\mathbf{1}$ (a vector of all ones) and the input gate $\\mathbf{i}_t = \\mathbf{0}$ (a vector of all zeros) for all time steps $t \\in \\{1, 2, \\ldots, T\\}$, then the cell state remains constant, i.e., $\\mathbf{c}_t = \\mathbf{c}_0$ for all $t$.\n\nWe will use the principle of mathematical induction. Let $P(t)$ be the proposition $\\mathbf{c}_t = \\mathbf{c}_0$.\n\n**Base Case:** We must show that $P(1)$ is true. The cell state update equation is given as:\n$$\n\\mathbf{c}_t=\\mathbf{f}_t\\odot \\mathbf{c}_{t-1}+\\mathbf{i}_t\\odot \\mathbf{g}_t\n$$\nFor $t=1$, this becomes:\n$$\n\\mathbf{c}_1=\\mathbf{f}_1\\odot \\mathbf{c}_0+\\mathbf{i}_1\\odot \\mathbf{g}_1\n$$\nSubstituting the given conditions $\\mathbf{f}_1 = \\mathbf{1}$ and $\\mathbf{i}_1 = \\mathbf{0}$:\n$$\n\\mathbf{c}_1 = \\mathbf{1} \\odot \\mathbf{c}_0 + \\mathbf{0} \\odot \\mathbf{g}_1\n$$\nThe Hadamard product with the vector $\\mathbf{1}$ is the identity operation ($\\mathbf{1} \\odot \\mathbf{v} = \\mathbf{v}$), and the product with the vector $\\mathbf{0}$ results in the zero vector ($\\mathbf{0} \\odot \\mathbf{v} = \\mathbf{0}$). Thus:\n$$\n\\mathbf{c}_1 = \\mathbf{c}_0 + \\mathbf{0} = \\mathbf{c}_0\n$$\nThe base case $P(1)$ holds.\n\n**Inductive Hypothesis:** Assume that for some integer $k \\ge 1$, the proposition $P(k)$ is true, meaning $\\mathbf{c}_k = \\mathbf{c}_0$.\n\n**Inductive Step:** We must show that $P(k+1)$ is true, i.e., $\\mathbf{c}_{k+1} = \\mathbf{c}_0$. The update rule for $t=k+1$ is:\n$$\n\\mathbf{c}_{k+1}=\\mathbf{f}_{k+1}\\odot \\mathbf{c}_k+\\mathbf{i}_{k+1}\\odot \\mathbf{g}_{k+1}\n$$\nSubstituting the given conditions $\\mathbf{f}_{k+1} = \\mathbf{1}$ and $\\mathbf{i}_{k+1} = \\mathbf{0}$:\n$$\n\\mathbf{c}_{k+1}=\\mathbf{1}\\odot \\mathbf{c}_k+\\mathbf{0}\\odot \\mathbf{g}_{k+1}\n$$\nNow, we apply the inductive hypothesis, $\\mathbf{c}_k = \\mathbf{c}_0$:\n$$\n\\mathbf{c}_{k+1} = \\mathbf{1} \\odot \\mathbf{c}_0 + \\mathbf{0}\n$$\n$$\n\\mathbf{c}_{k+1} = \\mathbf{c}_0\n$$\nThus, $P(k+1)$ is true.\n\nBy the principle of mathematical induction, $\\mathbf{c}_t = \\mathbf{c}_0$ for all integers $t \\ge 1$. This completes the proof.\n\n### Task 2: Principled Diagnostic for Near-Conserved Memory\n\nThe goal is to design a scalar measure $s_t$ that quantifies the change in the cell state $\\mathbf{c}_t$ from one time step to the next. A state is \"conserved\" if it does not change, i.e., $\\mathbf{c}_t \\approx \\mathbf{c}_{t-1}$.\n\nLet's analyze the change vector, $\\Delta\\mathbf{c}_t = \\mathbf{c}_t - \\mathbf{c}_{t-1}$. Using the recurrence relation:\n$$\n\\Delta\\mathbf{c}_t = (\\mathbf{f}_t\\odot \\mathbf{c}_{t-1}+\\mathbf{i}_t\\odot \\mathbf{g}_t) - \\mathbf{c}_{t-1}\n$$\nBy adding and subtracting $\\mathbf{1}\\odot\\mathbf{c}_{t-1} = \\mathbf{c}_{t-1}$, we can isolate the effects of the gates:\n$$\n\\Delta\\mathbf{c}_t = (\\mathbf{f}_t\\odot \\mathbf{c}_{t-1} - \\mathbf{c}_{t-1}) + (\\mathbf{i}_t\\odot \\mathbf{g}_t)\n$$\nFactoring out $\\mathbf{c}_{t-1}$ from the first term gives:\n$$\n\\Delta\\mathbf{c}_t = (\\mathbf{f}_t - \\mathbf{1})\\odot \\mathbf{c}_{t-1} + \\mathbf{i}_t\\odot \\mathbf{g}_t\n$$\nThis equation reveals the two sources of change in the cell state:\n1.  **Forgetting:** The term $(\\mathbf{f}_t - \\mathbf{1})\\odot \\mathbf{c}_{t-1}$ represents the portion of the previous state $\\mathbf{c}_{t-1}$ that is \"forgotten.\" Conservation requires this term to be near zero, which occurs when $\\mathbf{f}_t \\approx \\mathbf{1}$.\n2.  **Input:** The term $\\mathbf{i}_t\\odot \\mathbf{g}_t$ represents the new information being written to the cell state. Conservation requires this term to be near zero, which occurs when $\\mathbf{i}_t \\approx \\mathbf{0}$ (since $\\mathbf{g}_t$ is bounded).\n\nTo quantify the magnitude of this change, we use the Euclidean norm, $\\lVert \\Delta\\mathbf{c}_t \\rVert_2 = \\lVert \\mathbf{c}_t - \\mathbf{c}_{t-1} \\rVert_2$. This gives an absolute measure of change. However, a change of a certain magnitude might be significant for a small state vector but negligible for a large one. Therefore, a more robust measure is the *relative* change, which normalizes the absolute change by the magnitude of the state vector itself.\n\nThe proposed diagnostic,\n$$\ns_t=\\frac{\\lVert \\mathbf{c}_t-\\mathbf{c}_{t-1}\\rVert_2}{\\lVert \\mathbf{c}_{t-1}\\rVert_2+\\delta},\n$$\nis precisely this relative change. It measures the magnitude of the change vector as a fraction of the magnitude of the previous state vector.\n\n*   By using the Euclidean norm, it provides a scalar summary of the total change across all dimensions $d$ of the state vector.\n*   By normalizing by $\\lVert \\mathbf{c}_{t-1} \\rVert_2$, it becomes a scale-invariant measure.\n*   The small constant $\\delta  0$ is a standard numerical stabilizer to prevent division by zero in the case where $\\mathbf{c}_{t-1} = \\mathbf{0}$. In this special case, as shown in test case D, if $\\mathbf{f}_t=\\mathbf{1}$ and $\\mathbf{i}_t=\\mathbf{0}$, then $\\mathbf{c}_t = \\mathbf{c}_{t-1} = \\mathbf{0}$, the numerator is zero, and $s_t=0$, correctly indicating perfect conservation.\n\nA very small value of $s_t$ (i.e., $s_t \\le \\varepsilon$ for some small $\\varepsilon  0$) indicates that $\\lVert \\mathbf{c}_t - \\mathbf{c}_{t-1} \\rVert_2$ is small compared to $\\lVert \\mathbf{c}_{t-1} \\rVert_2$. This condition is met when both sources of change, forgetting and input, are minimal—that is, when $\\mathbf{f}_t \\approx \\mathbf{1}$ and $\\mathbf{i}_t \\approx \\mathbf{0}$. Therefore, $s_t$ is a principled and appropriate diagnostic for detecting near-conserved memory segments.\n\n### Task 3: Algorithm for Diagnostic Implementation\n\nThe algorithm takes as input the sequence of cell states $\\{\\mathbf{c}_t\\}_{t=0}^T$, a tolerance $\\varepsilon$, and a minimum length $L$. It proceeds in two main stages.\n\n**Stage 1: Compute Per-Step Relative Change**\n1.  Initialize an empty list, `s_values`.\n2.  Iterate for $t$ from $1$ to $T$.\n    a. Compute the numerator: `norm_diff` = $\\lVert \\mathbf{c}_t - \\mathbf{c}_{t-1} \\rVert_2$.\n    b. Compute the denominator: `norm_prev` = $\\lVert \\mathbf{c}_{t-1} \\rVert_2 + \\delta$.\n    c. Calculate $s_t = \\frac{\\text{norm\\_diff}}{\\text{norm\\_prev}}$ and append it to `s_values`.\n\n**Stage 2: Find Longest Run of Near-Conservation**\n1.  Initialize `max_run_length = 0` and `current_run_length = 0`.\n2.  Iterate through `s_values` (corresponding to $t=1, \\ldots, T$).\n    a. If the current value $s_t \\le \\varepsilon$:\n       i. Increment `current_run_length` by $1$.\n    b. Else (the run is broken):\n       i. Update `max_run_length = \\max(\\text{max\\_run\\_length, current\\_run\\_length})`.\n       ii. Reset `current_run_length = 0`.\n3.  After the loop finishes, perform one final update to account for a run that extends to the end of the sequence: `max_run_length = \\max(\\text{max\\_run\\_length, current\\_run\\_length})`.\n4.  Determine the boolean output: `found_long_run = (\\text{max\\_run\\_length} \\ge L)`.\n5.  Return the tuple (`max_run_length`, `found_long_run`).\n\nThis algorithm correctly implements the required diagnostic by first calculating the per-step measure and then applying a standard linear scan to find the longest contiguous subsequence satisfying the given condition.\n\n### Task 4: Application to Test Cases\n\nThe algorithm described above, combined with a preliminary simulation of the LSTM recurrence for each test case, yields the results. The simulation step simply applies the equation $\\mathbf{c}_t=\\mathbf{f}_t\\odot \\mathbf{c}_{t-1}+\\mathbf{i}_t\\odot \\mathbf{g}_t$ iteratively for $t=1, \\ldots, T$. The implementation is provided in the final answer.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the LSTM memory conservation problem by simulating the cell state\n    updates for given test cases and then applying a diagnostic to find\n    near-conserved segments.\n    \"\"\"\n    \n    delta = 1e-12\n\n    test_cases = [\n        {\n            # Case A: perfect conservation\n            \"T\": 20, \"d\": 3, \"c0\": np.array([2.0, -1.0, 0.5]),\n            \"ft_gen\": lambda t: np.ones(3),\n            \"it_gen\": lambda t: np.zeros(3),\n            \"gt_gen\": lambda t: np.array([0.3, -0.4, 0.5]),\n            \"epsilon\": 1e-12, \"L\": 10\n        },\n        {\n            # Case B: slow exponential drift via forget gate\n            \"T\": 30, \"d\": 1, \"c0\": np.array([1.0]),\n            \"ft_gen\": lambda t: np.array([0.99]),\n            \"it_gen\": lambda t: np.array([0.0]),\n            \"gt_gen\": lambda t: np.array([0.0]),\n            \"epsilon\": 0.005, \"L\": 5\n        },\n        {\n            # Case C: small constant input injection\n            \"T\": 25, \"d\": 2, \"c0\": np.array([1.0, 1.0]),\n            \"ft_gen\": lambda t: np.ones(2),\n            \"it_gen\": lambda t: np.array([0.02, 0.02]),\n            \"gt_gen\": lambda t: np.array([0.5, 0.5]),\n            \"epsilon\": 0.02, \"L\": 10\n        },\n        {\n            # Case D: zero state, exact conservation\n            \"T\": 10, \"d\": 3, \"c0\": np.array([0.0, 0.0, 0.0]),\n            \"ft_gen\": lambda t: np.ones(3),\n            \"it_gen\": lambda t: np.zeros(3),\n            \"gt_gen\": lambda t: np.array([0.7, -0.3, 0.1]),\n            \"epsilon\": 1e-12, \"L\": 5\n        }\n    ]\n\n    def simulate_lstm(T, c0, ft_gen, it_gen, gt_gen):\n        \"\"\"Generates the cell state sequence {c_t}.\"\"\"\n        c_series = [c0]\n        c_prev = c0\n        for t in range(1, T + 1):\n            ft = ft_gen(t)\n            it = it_gen(t)\n            gt = gt_gen(t)\n            # LSTM cell state update recurrence\n            c_t = ft * c_prev + it * gt\n            c_series.append(c_t)\n            c_prev = c_t\n        return c_series\n\n    def run_diagnostic(c_series, epsilon, L):\n        \"\"\"\n        Calculates the longest run of near-conservation and checks if it\n        meets the minimum length L.\n        \"\"\"\n        T = len(c_series) - 1\n        \n        # Stage 1: Compute per-step relative change s_t\n        s_values = []\n        for t in range(1, T + 1):\n            c_t = c_series[t]\n            c_prev = c_series[t-1]\n            \n            norm_diff = np.linalg.norm(c_t - c_prev, ord=2)\n            norm_prev = np.linalg.norm(c_prev, ord=2)\n            \n            s_t = norm_diff / (norm_prev + delta)\n            s_values.append(s_t)\n            \n        # Stage 2: Find the longest run where s_t = epsilon\n        max_run_length = 0\n        current_run_length = 0\n        for s_t in s_values:\n            if s_t = epsilon:\n                current_run_length += 1\n            else:\n                if current_run_length > max_run_length:\n                    max_run_length = current_run_length\n                current_run_length = 0\n        \n        # Final check for a run extending to the end\n        if current_run_length > max_run_length:\n            max_run_length = current_run_length\n            \n        found_long_run = max_run_length >= L\n        \n        return [max_run_length, found_long_run]\n\n    results = []\n    for case in test_cases:\n        # Generate the time series data for the cell states\n        c_series = simulate_lstm(\n            case[\"T\"], case[\"c0\"], case[\"ft_gen\"],\n            case[\"it_gen\"], case[\"gt_gen\"]\n        )\n        # Apply the diagnostic to the generated series\n        result = run_diagnostic(c_series, case[\"epsilon\"], case[\"L\"])\n        results.append(result)\n\n    # Format the final output string exactly as specified, with no spaces.\n    case_strings = [f\"[{r[0]},{str(r[1])}]\" for r in results]\n    final_output_string = f\"[{','.join(case_strings)}]\"\n    print(final_output_string)\n\nsolve()\n```", "id": "3142761"}, {"introduction": "Theoretical properties are one thing, but how much can an LSTM *really* remember in a practical setting? This final exercise provides a framework for empirically measuring an LSTM's memory capacity. By tasking the network with recalling a past input bit from its current hidden state amidst noise, you will run a computational experiment to determine the maximum time delay over which information can be reliably stored and retrieved, giving you a tangible, operational definition of 'memory' in a neural network. [@problem_id:3153546]", "problem": "You must write a complete program that evaluates the memory capacity of a Long Short-Term Memory (LSTM) recurrent neural network by attempting to reconstruct a delayed past input bit from the current hidden state under additive noise. The program must follow the precise mathematical and algorithmic specification described here and produce results for a provided test suite of parameter settings. All symbols, functions, and numbers in this specification are defined in purely mathematical terms, and no physical units are involved.\n\nBegin from the following fundamental base for modeling sequential data: a recurrent neural network processes a sequence of inputs over discrete time steps, and an LSTM is a specific architecture that maintains an internal cell state and hidden state to control information flow via multiplicative gates. For each time step index $t \\in \\{0,1,2,\\dots,T-1\\}$, with scalar input $x_t \\in \\{0,1\\}$, hidden state $h_t \\in \\mathbb{R}^H$, and cell state $c_t \\in \\mathbb{R}^H$, the LSTM update is defined by the standard equations\n$$\nz_t = W_x x_t + W_h h_{t-1} + b \\in \\mathbb{R}^{4H},\n$$\n$$\ni_t = \\sigma\\!\\left(z_t[0:H]\\right), \\quad f_t = \\sigma\\!\\left(z_t[H:2H]\\right), \\quad g_t = \\tanh\\!\\left(z_t[2H:3H]\\right), \\quad o_t = \\sigma\\!\\left(z_t[3H:4H]\\right),\n$$\n$$\nc_t = f_t \\odot c_{t-1} + i_t \\odot g_t, \\quad h_t = o_t \\odot \\tanh(c_t),\n$$\nwith initial states $h_{-1}=\\mathbf{0}$ and $c_{-1}=\\mathbf{0}$, where $\\sigma(\\cdot)$ is the logistic sigmoid function, $\\tanh(\\cdot)$ is the hyperbolic tangent, $\\odot$ denotes elementwise multiplication, $W_x \\in \\mathbb{R}^{4H \\times 1}$, $W_h \\in \\mathbb{R}^{4H \\times H}$, and $b \\in \\mathbb{R}^{4H}$. All parameters are fixed and randomly initialized once per test case as specified below. To encourage retention, the bias components corresponding to the forget gate are shifted by a positive constant.\n\nDefine the binary input sequence $\\{x_t\\}$ as independent and identically distributed (i.i.d.) Bernoulli random variables with success probability $0.5$. For a given integer delay $k \\ge 1$, the goal is to reconstruct the delayed input $x_{t-k}$ from the current hidden state $h_t$ in the presence of additive Gaussian noise. Specifically, let the noisy feature be $\\tilde{h}_t = h_t + \\varepsilon_t$, where $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2 I_H)$ are i.i.d. Gaussian noise vectors with standard deviation $\\sigma$ and $I_H$ is the $H \\times H$ identity matrix. For each delay $k$, form supervised training pairs $(\\tilde{h}_t, x_{t-k})$ for $t \\in \\{k, k+1, \\dots, T_{\\text{train}}-1\\}$, and similarly form test pairs for an independent test sequence of length $T_{\\text{test}}$. Learn a linear decoder with bias that maps $\\tilde{h}_t \\in \\mathbb{R}^H$ to a real-valued score $\\hat{y}_t \\in \\mathbb{R}$, then threshold at $0.5$ to produce a binary prediction for $x_{t-k}$. The linear decoder must be trained by minimizing a regularized squared error objective (ridge regression) over the training pairs, and then evaluated on the test pairs for the same $k$ and $\\sigma$.\n\nDefine the test accuracy for a fixed delay $k$ as the fraction of correct reconstructions on the test set, with prediction rule $\\mathbb{I}[\\hat{y}_t \\ge 0.5]$. For each test case, define the memory capacity summary as the maximum delay $k$ in the inclusive range $k \\in \\{1,2,\\dots,K_{\\max}\\}$ such that the test accuracy is at least a specified threshold $\\alpha$. If no delay satisfies the threshold, report $0$ for that test case.\n\nYour program must implement the following steps precisely and deterministically:\n- For each test case, instantiate a fresh pseudorandom number generator with the provided seed. Use it for all random draws in that case: LSTM parameters, training inputs, test inputs, and noise.\n- Initialize $W_x$ and $W_h$ with zero-mean Gaussian entries with variance scaling appropriate for stable signals, and initialize $b$ with small zero-mean Gaussian entries. Add a positive forget-gate bias shift to $b[H:2H]$.\n- Generate independent training and test binary input sequences of lengths $T_{\\text{train}}$ and $T_{\\text{test}}$, respectively, each with Bernoulli parameter $0.5$.\n- Run the LSTM forward on each sequence to produce $\\{h_t\\}$ for $t=0,1,\\dots$.\n- For each integer $k$ in $\\{1,2,\\dots,K_{\\max}\\}$:\n  - Build the training design matrix by stacking $\\tilde{h}_t$ row-wise for $t=k,\\dots,T_{\\text{train}}-1$, where independent Gaussian noise with standard deviation $\\sigma$ is added to each $h_t$. The corresponding training targets are the bits $x_{t-k}$ for the same indices.\n  - Train a linear decoder with bias by minimizing a regularized squared error objective with a small nonzero regularization coefficient. Use the trained decoder to produce real-valued outputs on the noisy test design matrix formed analogously from the test sequence.\n  - Threshold the outputs at $0.5$ and compute the test accuracy as a fraction in $[0,1]$.\n- Return the maximum $k$ that achieves at least accuracy $\\alpha$, or $0$ if none.\n\nUse the following test suite of parameter sets. Each test case is a tuple $(H,\\sigma,T_{\\text{train}},T_{\\text{test}},K_{\\max},\\alpha,\\text{seed})$:\n- Case $1$: $(8, 0.0, 3000, 3000, 15, 0.85, 7)$.\n- Case $2$: $(8, 0.3, 3000, 3000, 15, 0.80, 7)$.\n- Case $3$: $(16, 0.3, 3000, 3000, 20, 0.80, 11)$.\n- Case $4$: $(4, 0.6, 3000, 3000, 15, 0.75, 5)$.\n\nYour program must produce a single line of output containing the results as a comma-separated list of integers enclosed in square brackets, ordered by the cases above, for example, \"[2,1,3,0]\". No other text must be printed.\n\nConstraints and clarifications:\n- All computations must be performed using real-valued arithmetic.\n- The linear decoder must include an explicit bias term.\n- The threshold for classification must be exactly $0.5$.\n- The regularization coefficient for training the linear decoder must be strictly positive and small.\n- Angles are not involved; no angle units apply.\n- The required final output format is a single line: a Python list literal with four integers corresponding to the four cases, in order.", "solution": "The problem requires the implementation of a computational experiment to evaluate the memory capacity of a Long Short-Term Memory (LSTM) network. The memory capacity is quantified by determining the maximum delay $k$ for which a past input bit $x_{t-k}$ can be reliably reconstructed from the current, noisy hidden state $\\tilde{h}_t$. This will be accomplished by training a linear decoder for each possible delay and measuring its performance. The entire process must be deterministic, governed by a seed for each test case.\n\nThe core of the system is a standard LSTM network. For each time step $t$, the network takes a scalar binary input $x_t \\in \\{0, 1\\}$ and updates its internal cell state $c_{t} \\in \\mathbb{R}^H$ and hidden state $h_t \\in \\mathbb{R}^H$, based on the previous states $c_{t-1}$ and $h_{t-1}$. The state update equations are as follows:\n\nFirst, a combined pre-activation vector $z_t \\in \\mathbb{R}^{4H}$ is computed as a linear transformation of the current input $x_t$ and the previous hidden state $h_{t-1}$:\n$$\nz_t = W_x x_t + W_h h_{t-1} + b\n$$\nwhere $W_x \\in \\mathbb{R}^{4H \\times 1}$, $W_h \\in \\mathbb{R}^{4H \\times H}$, and $b \\in \\mathbb{R}^{4H}$ are the weight matrices and bias vector, respectively. The initial states are zero vectors, $h_{-1} = \\mathbf{0}$ and $c_{-1} = \\mathbf{0}$.\n\nThe vector $z_t$ is then partitioned into four segments of size $H$, each controlling a specific gating mechanism or contributing to the new cell state content:\n$$\ni_t = \\sigma(z_t[0:H]) \\quad \\text{(Input Gate)}\n$$\n$$\nf_t = \\sigma(z_t[H:2H]) \\quad \\text{(Forget Gate)}\n$$\n$$\ng_t = \\tanh(z_t[2H:3H]) \\quad \\text{(Cell Input)}\n$$\n$$\no_t = \\sigma(z_t[3H:4H]) \\quad \\text{(Output Gate)}\n$$\nHere, $\\sigma(v) = (1 + e^{-v})^{-1}$ is the elementwise logistic sigmoid function, and $\\tanh(v)$ is the elementwise hyperbolic tangent function.\n\nThese components are combined to update the cell state and compute the new hidden state:\n$$\nc_t = f_t \\odot c_{t-1} + i_t \\odot g_t\n$$\n$$\nh_t = o_t \\odot \\tanh(c_t)\n$$\nwhere $\\odot$ denotes elementwise multiplication.\n\nThe parameters of the LSTM must be initialized randomly for each test case, with the process seeded for reproducibility. Following standard practices for maintaining stable signal propagation:\n- The input weight matrix $W_x$ is initialized with entries drawn from a Gaussian distribution $\\mathcal{N}(0, 1)$, corresponding to a variance of $1/\\text{fan\\_in}$ where the fan-in is $1$.\n- The recurrent weight matrix $W_h$ is initialized with entries from $\\mathcal{N}(0, 1/H)$, where the fan-in is the hidden size $H$.\n- The bias vector $b$ is initialized with small entries from $\\mathcal{N}(0, 0.01^2)$.\n- A positive bias shift of $1.0$ is added to the forget gate biases, $b[H:2H]$, to encourage the network to retain information by default at the beginning of training.\n\nThe input sequences $\\{x_t\\}$ are generated as independent and identically distributed Bernoulli random variables with $P(x_t=1) = 0.5$. Two independent sequences are generated: one for training ($T_{\\text{train}}$ steps) and one for testing ($T_{\\text{test}}$ steps). The LSTM is run forward over each sequence to produce the corresponding sequences of hidden states, $\\{h_t^{\\text{train}}\\}$ and $\\{h_t^{\\text{test}}\\}$.\n\nFor each integer delay $k \\in \\{1, 2, \\dots, K_{\\max}\\}$, we train a linear decoder to predict $x_{t-k}$ from a noisy version of the hidden state, $\\tilde{h}_t = h_t + \\varepsilon_t$, where $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2 I_H)$. The decoder model is $\\hat{y}_t = w^T \\tilde{h}_t + b_d$, where $w \\in \\mathbb{R}^H$ is a weight vector and $b_d \\in \\mathbb{R}$ is a bias. The parameters $(w, b_d)$ are determined by minimizing a regularized least-squares objective (ridge regression) on the training set. To ensure the bias term $b_d$ is not penalized, which is standard practice, we solve for it separately. Given training pairs $(\\tilde{h}_t, x_{t-k})$ for $t \\in \\{k, \\dots, T_{\\text{train}}-1\\}$:\n1.  Compute the means of the features and targets: $\\bar{h} = \\frac{1}{N} \\sum_{t=k}^{T_{\\text{train}}-1} \\tilde{h}_t$ and $\\bar{x} = \\frac{1}{N} \\sum_{t=k}^{T_{\\text{train}}-1} x_{t-k}$, where $N = T_{\\text{train}} - k$.\n2.  Center the training data: $h'_t = \\tilde{h}_t - \\bar{h}$ and $x'_t = x_{t-k} - \\bar{x}$.\n3.  Let $H'_{\\text{train}}$ be the matrix whose rows are $h'_t$ and $X'_{\\text{train}}$ be the vector of targets $x'_t$. The weight vector $w$ is found by solving the normal equations for ridge regression:\n    $$\n    w = ((H'_{\\text{train}})^T H'_{\\text{train}} + \\lambda I_H)^{-1} (H'_{\\text{train}})^T X'_{\\text{train}}\n    $$\n    where $\\lambda$ is a small positive regularization coefficient (we will use $\\lambda = 10^{-4}$) and $I_H$ is the $H \\times H$ identity matrix.\n4.  The bias is then calculated as $b_d = \\bar{x} - w^T \\bar{h}$.\n\nOnce trained, the decoder is evaluated on the test set. For each test time step $t \\in \\{k, \\dots, T_{\\text{test}}-1\\}$, a prediction score is computed using the test hidden states with freshly added noise: $\\hat{y}_t^{\\text{test}} = w^T \\tilde{h}_t^{\\text{test}} + b_d$. A binary prediction is made using the rule $\\hat{x}_{t-k} = \\mathbb{I}[\\hat{y}_t^{\\text{test}} \\ge 0.5]$. The accuracy is the fraction of correct predictions: $\\frac{1}{T_{\\text{test}}-k}\\sum_{t=k}^{T_{\\text{test}}-1} \\mathbb{I}[\\hat{x}_{t-k} == x_{t-k}^{\\text{test}}]$.\n\nFor each test case defined by its parameter tuple, the final result is the maximum delay $k \\in \\{1, \\dots, K_{\\max}\\}$ for which the test accuracy meets or exceeds the given threshold $\\alpha$. If no such $k$ exists, the result is $0$. This involves iterating through all possible delays, computing the accuracy for each, and then finding the maximum $k$ that satisfies the condition.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Evaluates the memory capacity of an LSTM network based on the problem specification.\n    \"\"\"\n    test_cases = [\n        # (H, sigma, T_train, T_test, K_max, alpha, seed)\n        (8, 0.0, 3000, 3000, 15, 0.85, 7),\n        (8, 0.3, 3000, 3000, 15, 0.80, 7),\n        (16, 0.3, 3000, 3000, 20, 0.80, 11),\n        (4, 0.6, 3000, 3000, 15, 0.75, 5),\n    ]\n\n    results = []\n    \n    # Constants\n    FORGET_BIAS_SHIFT = 1.0\n    BIAS_VAR = 0.01**2\n    RIDGE_LAMBDA = 1e-4\n\n    def sigmoid(x):\n        return 1 / (1 + np.exp(-x))\n\n    def lstm_forward(x_seq, Wx, Wh, b, H):\n        \"\"\"\n        Performs a forward pass of the LSTM.\n        \"\"\"\n        T = len(x_seq)\n        h = np.zeros((T, H))\n        c = np.zeros((T, H))\n        \n        h_prev = np.zeros(H)\n        c_prev = np.zeros(H)\n\n        for t in range(T):\n            x_t = x_seq[t]\n            z = Wx[:, 0] * x_t + Wh @ h_prev + b\n            \n            i_t = sigmoid(z[0:H])\n            f_t = sigmoid(z[H:2*H])\n            g_t = np.tanh(z[2*H:3*H])\n            o_t = sigmoid(z[3*H:4*H])\n            \n            c_t = f_t * c_prev + i_t * g_t\n            h_t = o_t * np.tanh(c_t)\n            \n            h[t] = h_t\n            c[t] = c_t\n            \n            h_prev = h_t\n            c_prev = c_t\n            \n        return h\n\n    for case in test_cases:\n        H, sigma, T_train, T_test, K_max, alpha, seed = case\n        \n        rng = np.random.default_rng(seed)\n\n        # 1. Initialize LSTM parameters\n        # Glorot/Xavier style initialization for weights\n        Wx = rng.normal(0, np.sqrt(1.0), size=(4 * H, 1))\n        Wh = rng.normal(0, np.sqrt(1.0 / H), size=(4 * H, H))\n        \n        # Small random bias + positive shift on forget gate\n        b = rng.normal(0, np.sqrt(BIAS_VAR), size=(4 * H))\n        b[H : 2 * H] += FORGET_BIAS_SHIFT\n\n        # 2. Generate input sequences\n        x_train = rng.integers(0, 2, size=T_train)\n        x_test = rng.integers(0, 2, size=T_test)\n\n        # 3. Run LSTM forward pass\n        h_train_seq = lstm_forward(x_train, Wx, Wh, b, H)\n        h_test_seq = lstm_forward(x_test, Wx, Wh, b, H)\n        \n        k_accuracies = {}\n\n        for k in range(1, K_max + 1):\n            # 4. Build training data for delay k\n            train_len = T_train - k\n            h_train_k = h_train_seq[k : T_train]\n            noise_train = rng.normal(0, sigma, size=(train_len, H))\n            h_tilde_train = h_train_k + noise_train\n            y_train_k = x_train[0 : train_len]\n\n            # 5. Train linear decoder (Ridge Regression with unpenalized bias)\n            # Center the data\n            h_mean = np.mean(h_tilde_train, axis=0)\n            y_mean = np.mean(y_train_k)\n            \n            h_centered = h_tilde_train - h_mean\n            y_centered = y_train_k - y_mean\n            \n            # Solve for weights w\n            A = h_centered.T @ h_centered + RIDGE_LAMBDA * np.eye(H)\n            B = h_centered.T @ y_centered\n            w = np.linalg.solve(A, B)\n            \n            # Solve for bias b_d\n            b_d = y_mean - h_mean @ w\n\n            # 6. Evaluate decoder on test data\n            test_len = T_test - k\n            if test_len = 0:\n                k_accuracies[k] = 0.0\n                continue\n                \n            h_test_k = h_test_seq[k : T_test]\n            noise_test = rng.normal(0, sigma, size=(test_len, H))\n            h_tilde_test = h_test_k + noise_test\n            y_test_k = x_test[0 : test_len]\n            \n            # Predict scores\n            y_pred_scores = h_tilde_test @ w + b_d\n            \n            # Classify and compute accuracy\n            y_pred_binary = (y_pred_scores >= 0.5).astype(int)\n            accuracy = np.mean(y_pred_binary == y_test_k)\n            k_accuracies[k] = accuracy\n\n        # 7. Find max delay k that meets the accuracy threshold\n        max_k = 0\n        for k in range(1, K_max + 1):\n            if k in k_accuracies and k_accuracies[k] >= alpha:\n                max_k = k\n        results.append(max_k)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3153546"}]}