{"hands_on_practices": [{"introduction": "Before we can match units, we must first understand the core component of Propensity Score Matching: the propensity score itself. This exercise provides a foundational, hands-on calculation to bridge the gap between a statistical model (like logistic regression) and the estimated probability of treatment for a single observation. By working through a realistic, albeit hypothetical, scenario from environmental science, you will solidify your understanding of how covariate information is synthesized into a single, powerful balancing score. [@problem_id:2488850]", "problem": "An environmental scientist, distinguishing their empirical evaluation role from advocacy-oriented environmentalism, seeks to estimate the causal impact of protected area designation on deforestation. Because protected area siting is nonrandom, selection bias can arise if areas designated as protected systematically differ from non-designated areas in biophysical or political characteristics. To address this, the scientist adopts the propensity score framework, where the propensity score is the conditional probability of treatment (protected area designation) given observed covariates.\n\nYou have previously estimated a binary response model for protected area designation using a Generalized Linear Model (GLM) with a logit link based on a training sample from the same region. The predictor variables are slope, distance to roads, and an indicator for proximity to a political boundary. The estimated linear predictor uses the following coefficients (estimated from prior data): intercept $\\beta_{0}=-3.8$, slope coefficient $\\beta_{\\text{slope}}=0.07$ per degree (degrees are the angle unit), distance-to-roads coefficient $\\beta_{\\text{dist}}=0.05$ per kilometer, and political-boundary coefficient $\\beta_{\\text{bound}}=0.60$ for a binary indicator equal to $1$ if the parcel lies within $10$ kilometers of a provincial boundary and $0$ otherwise.\n\nFor a specific forest parcel with slope $18$ degrees, distance to the nearest road $25$ kilometers, and within $10$ kilometers of a provincial boundary (indicator equals $1$), compute the parcel’s propensity score for protected area designation. Begin from the definition that a propensity score is a conditional probability of treatment given covariates, and from the definition of the log-odds transformation (logit) in a GLM with a logit link, and derive any probability mapping you need from those definitions before substituting values.\n\nRound your final numerical propensity score to four significant figures and express it as a unitless decimal (do not use a percentage). In addition, briefly outline in words how matching on this score can reduce selection bias when estimating the impact of protected areas on deforestation, making clear the scientific reasoning that distinguishes inferential evaluation from advocacy.\n\nState only the computed propensity score as your final numerical answer.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Model: Generalized Linear Model (GLM) with a logit link for binary response of protected area designation.\n- The propensity score is defined as the conditional probability of treatment (protected area designation) given observed covariates.\n- Linear predictor coefficients:\n  - Intercept $\\beta_{0} = -3.8$\n  - Slope coefficient $\\beta_{\\text{slope}} = 0.07$ per degree\n  - Distance-to-roads coefficient $\\beta_{\\text{dist}} = 0.05$ per kilometer\n  - Political-boundary coefficient $\\beta_{\\text{bound}} = 0.60$\n- Forest parcel characteristics (covariates):\n  - Slope: $18$ degrees\n  - Distance to nearest road: $25$ kilometers\n  - Proximity to political boundary indicator: $1$\n\n**Step 2: Validate Using Extracted Givens**\n- The problem is **scientifically grounded**. The use of GLMs with a logit link and the propensity score framework are standard, well-established methodologies in statistics and econometrics for causal inference in observational studies.\n- The problem is **well-posed**. It provides all necessary parameters and variable values to compute a unique solution. The question is unambiguous.\n- The problem is **objective**. It uses precise, technical language and correctly frames the methodological challenge of selection bias in program evaluation, distinguishing the empirical-scientific role from advocacy.\n- The problem contains no scientific or factual unsoundness, is not non-formalizable, has no incomplete or contradictory setup, is not unrealistic or infeasible, is not ill-posed, is not trivial, and is scientifically verifiable.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A solution will be derived.\n\nThe task is to compute the propensity score for a specific forest parcel and to explain the logic of propensity score matching. The propensity score, which we denote as $p(X)$, is the conditional probability of receiving treatment ($T=1$) given a vector of observed covariates $X$. In this context, treatment is the designation of a parcel as a protected area.\n\n$$p(X) = P(T=1 | X)$$\n\nThe model used is a Generalized Linear Model (GLM) with a logit link function. The logit function maps a probability $p \\in (0, 1)$ to the real line $(-\\infty, \\infty)$ and is defined as the natural logarithm of the odds:\n\n$$\\text{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right)$$\n\nIn the GLM framework, the link function of the conditional mean of the response is equated to a linear predictor, $\\eta$. For a binary response, the conditional mean is the probability $p$. Thus, we have:\n\n$$\\eta = \\ln\\left(\\frac{p}{1-p}\\right)$$\n\nTo compute the probability $p$ from the linear predictor $\\eta$, we must derive the inverse of the logit function, which is the logistic sigmoid function. We begin by exponentiating both sides:\n\n$$\\exp(\\eta) = \\frac{p}{1-p}$$\n\nNow, we solve for $p$:\n$$\\exp(\\eta) \\cdot (1-p) = p$$\n$$\\exp(\\eta) - p \\cdot \\exp(\\eta) = p$$\n$$\\exp(\\eta) = p + p \\cdot \\exp(\\eta)$$\n$$\\exp(\\eta) = p \\cdot (1 + \\exp(\\eta))$$\n\nThis gives the expression for the propensity score as a function of the linear predictor:\n$$p = \\frac{\\exp(\\eta)}{1 + \\exp(\\eta)}$$\n\nThe linear predictor $\\eta$ is a linear combination of the given covariates and their corresponding coefficients:\n$$\\eta = \\beta_{0} + \\beta_{\\text{slope}} \\cdot X_{\\text{slope}} + \\beta_{\\text{dist}} \\cdot X_{\\text{dist}} + \\beta_{\\text{bound}} \\cdot X_{\\text{bound}}$$\n\nThe problem provides the following values:\n- Intercept: $\\beta_{0} = -3.8$\n- Coefficients: $\\beta_{\\text{slope}} = 0.07$, $\\beta_{\\text{dist}} = 0.05$, $\\beta_{\\text{bound}} = 0.60$\n- Covariates for the parcel: $X_{\\text{slope}} = 18$, $X_{\\text{dist}} = 25$, $X_{\\text{bound}} = 1$\n\nWe substitute these values to compute the linear predictor $\\eta$:\n$$\\eta = -3.8 + (0.07 \\times 18) + (0.05 \\times 25) + (0.60 \\times 1)$$\n$$\\eta = -3.8 + 1.26 + 1.25 + 0.60$$\n$$\\eta = -3.8 + 3.11$$\n$$\\eta = -0.69$$\n\nNow, we use this value of $\\eta$ to compute the propensity score $p$:\n$$p = \\frac{\\exp(-0.69)}{1 + \\exp(-0.69)}$$\n\nComputing the numerical value:\n$$p \\approx \\frac{0.501574}{1 + 0.501574} = \\frac{0.501574}{1.501574} \\approx 0.334033$$\n\nThe problem requires rounding to four significant figures. Therefore, the propensity score for this parcel is $0.3340$.\n\nRegarding the utility of this method, selection bias arises because the siting of protected areas is nonrandom. Parcels designated for protection may systematically differ from those not designated (e.g., they may be more remote, on steeper slopes, or have lower agricultural potential). A naive comparison of outcomes like deforestation would conflate the effect of protection with these pre-existing differences. Propensity score matching is a statistical technique to mitigate this bias. It operates under the assumption of conditional ignorability, which posits that, conditional on the observed covariates $X$, treatment assignment is independent of potential outcomes. By matching a treated unit (a protected parcel) with one or more control units (unprotected parcels) that have very similar propensity scores, we create a comparison group that is balanced on the observed covariates. That is, for a given propensity score, a treated and a control unit had the same *ex ante* probability of being protected. This procedure mimics the properties of a randomized experiment, allowing for a more credible estimate of the causal effect of protection. This purely inferential goal—isolating a causal effect by controlling for confounding factors—is the hallmark of environmental science in this context. It is distinct from environmentalism, which is an advocacy position that may promote protection regardless of its empirically demonstrated, isolated impact. The scientist's role is to provide an objective, evidence-based estimate of the treatment effect, for which this method is a critical tool.", "answer": "$$\n\\boxed{0.3340}\n$$", "id": "2488850"}, {"introduction": "A common misconception is that a propensity score model should include any and all variables that predict treatment. This practice serves as a critical cautionary tale, demonstrating through simulation the dangers of conditioning on a specific type of variable known as a 'collider.' This exercise will guide you through implementing a simulation to reveal M-bias, a phenomenon where adjusting for a collider actually *induces* a spurious association and biases the treatment effect estimate, highlighting why causal reasoning is indispensable in model specification. [@problem_id:3162896]", "problem": "You are asked to design and implement a simulation-based demonstration of M-bias in Propensity Score Matching (PSM) within the potential outcomes framework for causal inference in statistical learning. Begin from the following fundamental base: under the potential outcomes framework, the Average Treatment Effect (ATE) is defined as the average difference between the potential outcomes under treatment and control, and the propensity score is the probability of treatment conditional on observed covariates. A collider is a variable that is caused by two (or more) variables; conditioning on a collider can induce a spurious statistical association (M-bias) between otherwise independent causes, which can bias causal effect estimates if those causes affect the outcome and treatment along different paths.\n\nConstruct a data-generating process (DGP) embodying the canonical M-bias structure using the Directed Acyclic Graph (DAG) concept (Directed Acyclic Graph (DAG)). The DAG is as follows: there exist latent variables $U$ and $V$ such that $U$ influences treatment $T$ but not outcome $Y$, $V$ influences outcome $Y$ but not treatment $T$, and the collider $C$ is influenced by both $U$ and $V$. There is also an observed covariate $X$. The structural equations are:\n- Latent causes: $U \\sim \\mathcal{N}(0,1)$, $V \\sim \\mathcal{N}(0,1)$.\n- Observed covariate: $X \\sim \\mathcal{N}(0,1)$.\n- Collider: $C = \\gamma_U U + \\gamma_V V + \\varepsilon_C$, with $\\varepsilon_C \\sim \\mathcal{N}(0,1)$.\n- Treatment assignment: $T \\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha_0 + \\alpha_U U + \\alpha_X X))$, where $\\text{logit}^{-1}(z) = \\dfrac{1}{1 + e^{-z}}$.\n- Outcome: $Y = \\beta_T T + \\beta_V V + \\beta_X X + \\varepsilon_Y$, with $\\varepsilon_Y \\sim \\mathcal{N}(0,1)$.\n\nUnder this DGP, the true Average Treatment Effect (ATE) equals $\\beta_T$.\n\nYour program must, for each test case, do the following:\n1. Simulate $N$ independent observations according to the DGP above.\n2. Estimate two propensity score models for $T$ using logistic regression (maximum likelihood), each with an intercept term:\n   - Incorrect model (with collider): covariates $\\{X, C\\}$.\n   - Correct model (excluding collider): covariates $\\{X\\}$.\n3. For each fitted propensity score, perform nearest-neighbor matching with replacement and a caliper on the absolute propensity score difference. Specifically:\n   - For each treated unit, find the single closest control unit in propensity score distance; include the pair if the distance is less than or equal to the caliper.\n   - For each control unit, find the single closest treated unit in propensity score distance; include the pair if the distance is less than or equal to the caliper.\n   - Compute the matched estimate of the Average Treatment Effect by averaging all available matched pair differences $Y_{\\text{treated}} - Y_{\\text{control}}$ formed from both directions (this symmetrized matching estimator approximates the Average Treatment Effect rather than only the Average Treatment Effect on the Treated).\n   - If no pairs satisfy the caliper, re-run the nearest-neighbor matching without any caliper (i.e., caliper $= +\\infty$).\n4. Compute the bias of each matched estimator relative to the true ATE:\n   - Bias including collider: $b_{\\text{incl}} = \\widehat{\\text{ATE}}_{\\text{incl}} - \\beta_T$.\n   - Bias excluding collider: $b_{\\text{excl}} = \\widehat{\\text{ATE}}_{\\text{excl}} - \\beta_T$.\n   - Excess absolute bias attributable to including the collider: $\\Delta = |b_{\\text{incl}}| - |b_{\\text{excl}}|$.\n5. Aggregate the results across all test cases into a single line of output as a comma-separated list of per-case triples, where each triple is a bracketed list $[b_{\\text{incl}}, b_{\\text{excl}}, \\Delta]$. The complete output must be enclosed in square brackets. For example: $[[b_1^{\\text{incl}}, b_1^{\\text{excl}}, \\Delta_1],[b_2^{\\text{incl}}, b_2^{\\text{excl}}, \\Delta_2]]$.\n\nTest Suite and Parameters:\nImplement the procedure for the following four test cases. Use the specified random seed to ensure reproducibility.\n\n- Case $1$ (baseline, moderate collider):\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 0.8$, $\\gamma_V = 0.8$, caliper $= 0.05$, seed $= 42$.\n\n- Case $2$ (boundary, no collider effect):\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 0.0$, $\\gamma_V = 0.0$, caliper $= 0.05$, seed $= 1$.\n\n- Case $3$ (strong collider influence):\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.2$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 2.5$, $\\gamma_V = 2.5$, caliper $= 0.05$, seed $= 7$.\n\n- Case $4$ (small sample, moderate collider):\n  - $N = 600$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 1.0$, $\\gamma_V = 1.0$, caliper $= 0.07$, seed $= 123$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list of per-case triples, each triple itself being a comma-separated list in square brackets, with the entire output enclosed in square brackets. For example: $[[r_{11},r_{12},r_{13}],[r_{21},r_{22},r_{23}],[r_{31},r_{32},r_{33}],[r_{41},r_{42},r_{43}]]$. Each $r_{ij}$ must be a floating-point number.", "solution": "The problem statement has been validated and is deemed valid. It presents a well-posed, scientifically grounded simulation exercise in the field of causal inference and statistical learning. The objective is to demonstrate M-bias, a specific type of bias that arises from conditioning on a collider variable, within the context of Propensity Score Matching (PSM). All parameters, models, and procedures are explicitly defined, enabling a reproducible computational solution.\n\n### Theoretical Framework\n\nThe problem is rooted in the potential outcomes framework for causal inference. The goal is to estimate the Average Treatment Effect (ATE), defined as $\\mathbb{E}[Y(1) - Y(0)]$, where $Y(1)$ and $Y(0)$ are the potential outcomes under treatment and control, respectively. The data generating process (DGP) is specified by a set of structural equations that correspond to a Directed Acyclic Graph (DAG). The core of this DAG is the \"M-structure\":\n1. An unobserved variable $U$ is a cause of the treatment $T$ ($U \\rightarrow T$).\n2. Another unobserved variable $V$ is a cause of the outcome $Y$ ($V \\rightarrow Y$).\n3. $U$ and $V$ are independent, i.e., there is no path between them.\n4. $U$ and $V$ are both causes of an observed variable $C$, the collider ($U \\rightarrow C \\leftarrow V$).\n\nIn this structure, $T$ and $Y$ are not associated through the path involving $U$ and $V$ because the path $T \\leftarrow U \\rightarrow C \\leftarrow V \\rightarrow Y$ is blocked by the collider $C$. However, if one conditions on the collider $C$ (e.g., by including it in a regression model), this path becomes unblocked, inducing a spurious statistical association between $U$ and $V$. This spurious association between the causes of treatment ($U$) and outcome ($V$) creates a non-causal statistical association between $T$ and $Y$, leading to biased estimates of the causal effect.\n\nThe specified DGP is given by:\n- Latent causes: $U \\sim \\mathcal{N}(0,1)$, $V \\sim \\mathcal{N}(0,1)$.\n- Observed covariate: $X \\sim \\mathcal{N}(0,1)$.\n- Collider: $C = \\gamma_U U + \\gamma_V V + \\varepsilon_C$, with $\\varepsilon_C \\sim \\mathcal{N}(0,1)$.\n- Treatment assignment: $T \\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha_0 + \\alpha_U U + \\alpha_X X))$.\n- Outcome: $Y = \\beta_T T + \\beta_V V + \\beta_X X + \\varepsilon_Y$, with $\\varepsilon_Y \\sim \\mathcal{N}(0,1)$.\n\nThe true ATE is given by the coefficient $\\beta_T$. The variable $X$ is included as an observed predictor of treatment ($X \\rightarrow T$). In the given test cases, $\\beta_X=0$, so $X$ is not a confounder (i.e., there is no open backdoor path $T \\leftarrow X \\rightarrow Y$). Nevertheless, including predictors of treatment in a propensity score model is standard practice. The \"correct\" propensity score model includes predictors that block all backdoor paths between $T$ and $Y$ without opening new ones. Here, that means adjusting for $X$ but crucially not for the collider $C$.\n\n### Simulation and Estimation Procedure\n\nFor each test case, the following steps are executed:\n\n1.  **Data Generation**: A dataset of $N$ observations is simulated based on the structural equations and the specified parameters. A fixed random seed ensures reproducibility. Variables $U, V, X, \\varepsilon_C, \\varepsilon_Y$ are drawn from standard normal distributions. The collider $C$, binary treatment $T$, and continuous outcome $Y$ are then constructed according to their definitions.\n\n2.  **Propensity Score Estimation**: The propensity score, $e(Z) = P(T=1|Z)$, is estimated using two different logistic regression models, where $Z$ is the set of covariates. The model coefficients are estimated by maximizing the log-likelihood function using a numerical optimization algorithm (BFGS).\n    - **Incorrect Model**: Includes the collider $C$ in the set of covariates, $Z = \\{X, C\\}$. The estimated propensity score is $\\hat{e}_{\\text{incl}}(X, C)$. This model is expected to produce biased results due to conditioning on the collider.\n    - **Correct Model**: Excludes the collider, $Z = \\{X\\}$. The estimated propensity score is $\\hat{e}_{\\text{excl}}(X)$. This model avoids M-bias.\n\n3.  **ATE Estimation via Matching**: For each of the two estimated propensity scores, a matched estimate of the ATE is computed using symmetric nearest-neighbor matching with replacement and a caliper.\n    - **Symmetric Matching**: To estimate the ATE (as opposed to the ATT or ATC), matches are sought from both directions. For each treated unit, the closest control unit (in propensity score distance) is found. Symmetrically, for each control unit, the closest treated unit is found.\n    - **Caliper**: A pair is considered a valid match only if the absolute difference in their propensity scores is within a specified caliper value.\n    - **Fallback**: If no pairs satisfy the caliper condition, the procedure is repeated with an infinite caliper (i.e., finding the nearest neighbor regardless of distance).\n    - **Estimator**: The ATE is estimated as the simple arithmetic mean of the outcome differences, $Y_{\\text{treated}} - Y_{\\text{control}}$, across all valid matched pairs found in both matching directions.\n\n4.  **Bias Analysis**: The performance of each estimator is evaluated by its bias, which is the difference between the estimate and the true ATE ($\\beta_T$).\n    - Bias (collider included): $b_{\\text{incl}} = \\widehat{\\text{ATE}}_{\\text{incl}} - \\beta_T$.\n    - Bias (collider excluded): $b_{\\text{excl}} = \\widehat{\\text{ATE}}_{\\text{excl}} - \\beta_T$.\n    - Excess Absolute Bias: $\\Delta = |b_{\\text{incl}}| - |b_{\\text{excl}}|$. A positive $\\Delta$ indicates that including the collider has amplified the estimation bias, demonstrating the detrimental effect of M-bias.\n\nThe simulation is expected to show that $|b_{\\text{incl}}|$ is significantly larger than $|b_{\\text{excl}}|$ when the collider path strengths ($\\gamma_U, \\gamma_V$) are non-zero, and that this difference, $\\Delta$, increases with the strength of the collider. When $\\gamma_U = \\gamma_V = 0$, the M-structure is absent, and both models should yield similar, low-bias estimates, resulting in a $\\Delta$ near zero.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import expit\n\ndef _logistic_regression(X_design, y_obs):\n    \"\"\"\n    Performs logistic regression using maximum likelihood estimation.\n    \"\"\"\n    def neg_log_likelihood(beta, X, y):\n        \"\"\"\n        Calculates the negative log-likelihood for a logistic model.\n        Uses np.logaddexp for numerical stability.\n        L = sum(y*z - log(1+exp(z))) where z = X @ beta\n        \"\"\"\n        linear_pred = X @ beta\n        log_likelihood = np.sum(y * linear_pred - np.logaddexp(0, linear_pred))\n        return -log_likelihood\n\n    initial_beta = np.zeros(X_design.shape[1])\n    result = minimize(\n        neg_log_likelihood,\n        initial_beta,\n        args=(X_design, y_obs),\n        method='BFGS'\n    )\n    return result.x\n\ndef _perform_matching(T, Y, ps, caliper):\n    \"\"\"\n    Performs symmetric nearest-neighbor matching and computes the ATE estimate.\n    \"\"\"\n    def find_matches(source_indices, target_indices, ps, T_full, Y_full, caliper_val):\n        \"\"\"Helper to find matches for a source group from a target group.\"\"\"\n        ps_source = ps[source_indices]\n        ps_target = ps[target_indices]\n        \n        # Sort target for efficient search\n        sort_map = np.argsort(ps_target)\n        ps_target_sorted = ps_target[sort_map]\n        \n        # Find insertion points for all source PSs into the sorted target PSs\n        insert_points = np.searchsorted(ps_target_sorted, ps_source)\n        \n        matched_diffs = []\n        for i, ps_s in enumerate(ps_source):\n            idx = insert_points[i]\n            \n            best_dist = np.inf\n            best_match_target_original_idx = -1\n\n            # Candidate 1: at insertion point\n            if idx  len(ps_target_sorted):\n                dist = np.abs(ps_s - ps_target_sorted[idx])\n                if dist  best_dist:\n                    best_dist = dist\n                    best_match_target_original_idx = target_indices[sort_map[idx]]\n\n            # Candidate 2: at insertion point - 1\n            if idx > 0:\n                dist = np.abs(ps_s - ps_target_sorted[idx-1])\n                if dist  best_dist:\n                    best_dist = dist\n                    best_match_target_original_idx = target_indices[sort_map[idx-1]]\n\n            source_original_idx = source_indices[i]\n            if best_match_target_original_idx != -1 and best_dist = caliper_val:\n                if T_full[source_original_idx] == 1: # Source is treated\n                    y_diff = Y_full[source_original_idx] - Y_full[best_match_target_original_idx]\n                else: # Source is control\n                    y_diff = Y_full[best_match_target_original_idx] - Y_full[source_original_idx]\n                matched_diffs.append(y_diff)\n        return matched_diffs\n\n    treated_indices = np.where(T == 1)[0]\n    control_indices = np.where(T == 0)[0]\n\n    # Guard against empty treatment/control groups\n    if len(treated_indices) == 0 or len(control_indices) == 0:\n        return np.nan\n\n    # Run with the given caliper\n    all_diffs = []\n    # T -> C matching\n    all_diffs.extend(find_matches(treated_indices, control_indices, ps, T, Y, caliper))\n    # C -> T matching\n    all_diffs.extend(find_matches(control_indices, treated_indices, ps, T, Y, caliper))\n    \n    # If no matches found, re-run with infinite caliper\n    if not all_diffs:\n        all_diffs.extend(find_matches(treated_indices, control_indices, ps, T, Y, np.inf))\n        all_diffs.extend(find_matches(control_indices, treated_indices, ps, T, Y, np.inf))\n        \n    return np.mean(all_diffs) if all_diffs else np.nan\n\ndef solve():\n    \"\"\"\n    Main function to run the M-bias simulation across all test cases.\n    \"\"\"\n    test_cases = [\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 0.8, 'gamma_V': 0.8, \n         'caliper': 0.05, 'seed': 42},\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 0.0, 'gamma_V': 0.0, \n         'caliper': 0.05, 'seed': 1},\n        {'N': 4000, 'alpha_0': 0.0, 'alpha_U': 1.2, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 2.5, 'gamma_V': 2.5, \n         'caliper': 0.05, 'seed': 7},\n        {'N': 600, 'alpha_0': 0.0, 'alpha_U': 1.0, 'alpha_X': 0.5, 'beta_T': 2.0, \n         'beta_V': 1.0, 'beta_X': 0.0, 'gamma_U': 1.0, 'gamma_V': 1.0, \n         'caliper': 0.07, 'seed': 123}\n    ]\n\n    results = []\n    for params in test_cases:\n        # Set seed for reproducibility\n        rng = np.random.default_rng(params['seed'])\n        N = params['N']\n\n        # 1. Simulate data according to the DGP\n        U = rng.normal(size=N)\n        V = rng.normal(size=N)\n        X = rng.normal(size=N)\n        eps_C = rng.normal(size=N)\n        C = params['gamma_U'] * U + params['gamma_V'] * V + eps_C\n        \n        linear_pred_T = params['alpha_0'] + params['alpha_U'] * U + params['alpha_X'] * X\n        prob_T = expit(linear_pred_T)\n        T = rng.binomial(1, prob_T)\n        \n        eps_Y = rng.normal(size=N)\n        Y = params['beta_T'] * T + params['beta_V'] * V + params['beta_X'] * X + eps_Y\n\n        # 2. Estimate two propensity score models\n        # Incorrect model (including collider)\n        X_incl = np.c_[np.ones(N), X, C]\n        coeffs_incl = _logistic_regression(X_incl, T)\n        ps_incl = expit(X_incl @ coeffs_incl)\n\n        # Correct model (excluding collider)\n        X_excl = np.c_[np.ones(N), X]\n        coeffs_excl = _logistic_regression(X_excl, T)\n        ps_excl = expit(X_excl @ coeffs_excl)\n        \n        # 3. Perform matching and estimate ATE for both models\n        ate_incl = _perform_matching(T, Y, ps_incl, params['caliper'])\n        ate_excl = _perform_matching(T, Y, ps_excl, params['caliper'])\n        \n        # 4. Compute bias\n        true_ate = params['beta_T']\n        b_incl = ate_incl - true_ate\n        b_excl = ate_excl - true_ate\n        \n        # 5. Compute excess absolute bias\n        delta = np.abs(b_incl) - np.abs(b_excl)\n        \n        results.append([b_incl, b_excl, delta])\n\n    # Final print statement in the exact required format.\n    output_str = \",\".join([f\"[{r[0]},{r[1]},{r[2]}]\" for r in results])\n    print(f\"[{output_str}]\")\n\nsolve()\n```", "id": "3162896"}, {"introduction": "Real-world datasets often contain a mix of continuous and categorical covariates, some of which may be so critical that we cannot tolerate any imbalance. Simple nearest-neighbor matching may not be sufficient in these cases. This advanced practice guides you in implementing a hybrid matching strategy that enforces exact matches on key categorical confounders while performing caliper-based matching on others, reflecting a more robust and nuanced approach to creating comparable groups in practice. [@problem_id:3163024]", "problem": "You are tasked with implementing a matching procedure that enforces exact matches on key categorical confounders while allowing calipered differences on a continuous covariate. The goal is to assess the bias of the Average Treatment Effect (ATE). Begin from the potential outcomes framework and the definition of the propensity score. Average Treatment Effect (ATE) and Propensity Score Matching (PSM) must be reasoned from first principles in your algorithmic design.\n\nConsider the following data-generating process defined in purely mathematical terms. For each unit $i$, let $X_i$ be a continuous covariate, $C_{1,i}\\in\\{0,1\\}$ be a binary categorical confounder, $C_{2,i}\\in\\{0,1,2\\}$ be a ternary categorical confounder, $T_i\\in\\{0,1\\}$ be the treatment indicator, and $Y_i(0),Y_i(1)$ be the potential outcomes. Let $\\varepsilon_i$ be an independent noise term.\n\nDefine the confounders and covariate:\n- $C_{1,i} \\sim \\mathrm{Bernoulli}(0.5)$.\n- $C_{2,i} \\in \\{0,1,2\\}$ with $\\Pr(C_{2,i}=0)=0.4$, $\\Pr(C_{2,i}=1)=0.4$, $\\Pr(C_{2,i}=2)=0.2$.\n- $X_i \\sim \\mathcal{N}(\\mu_i, 1)$, where $\\mu_i = 0.5\\,C_{1,i} + 0.3\\,\\mathbb{1}\\{C_{2,i}=1\\} - 0.3\\,\\mathbb{1}\\{C_{2,i}=2\\}$.\n\nDefine the treatment assignment using the logistic function $\\sigma(u) = 1/(1+\\exp(-u))$:\n$$\n\\Pr(T_i=1 \\mid X_i, C_{1,i}, C_{2,i}) \n= \\sigma\\!\\Big(\\alpha_0 + \\alpha_X X_i + \\alpha_{C_1} C_{1,i} + \\alpha_{C_2,1}\\,\\mathbb{1}\\{C_{2,i}=1\\} + \\alpha_{C_2,2}\\,\\mathbb{1}\\{C_{2,i}=2\\}\\Big),\n$$\nwith fixed coefficients $\\alpha_0=0.2$, $\\alpha_X=0.8$, $\\alpha_{C_1}=0.6$, $\\alpha_{C_2,1}=0.4$, $\\alpha_{C_2,2}=-0.4$.\n\nDefine the potential outcomes and observed outcome:\n- $\\varepsilon_i \\sim \\mathcal{N}(0,1)$ independently.\n- $Y_i(0) = \\gamma_0 + \\gamma_X X_i + \\gamma_{C_1} C_{1,i} + \\gamma_{C_2,1}\\,\\mathbb{1}\\{C_{2,i}=1\\} + \\gamma_{C_2,2}\\,\\mathbb{1}\\{C_{2,i}=2\\} + \\varepsilon_i$, with $\\gamma_0=1.0$, $\\gamma_X=1.0$, $\\gamma_{C_1}=0.5$, $\\gamma_{C_2,1}=0.2$, $\\gamma_{C_2,2}=-0.2$.\n- $Y_i(1) = Y_i(0) + \\tau$, with $\\tau=2.0$.\n- $Y_i = T_i\\,Y_i(1) + (1-T_i)\\,Y_i(0)$.\n\nThe propensity score is $e(X_i,C_{1,i},C_{2,i})=\\Pr(T_i=1\\mid X_i,C_{1,i},C_{2,i})$. In your program, you must estimate the propensity score via logistic regression using maximum likelihood, employing the design matrix with an intercept and covariates $(X_i, C_{1,i}, \\mathbb{1}\\{C_{2,i}=1\\}, \\mathbb{1}\\{C_{2,i}=2\\})$.\n\nImplement the following matching rule:\n- For every treated unit $i$ with $T_i=1$, find at most one control unit $j$ with $T_j=0$ such that $C_{1,j}=C_{1,i}$ and $C_{2,j}=C_{2,i}$ (exact matching on both categorical confounders).\n- Impose calipers on the continuous covariate and the propensity score: $|X_i - X_j| \\le \\delta_x$ and $|e_i - e_j| \\le \\delta_p$, where $e_k$ denotes the estimated propensity score for unit $k$.\n- Among all eligible control candidates for $i$, choose the one that minimizes $|e_i - e_j|$. Match without replacement.\n\nCompute the estimated ATE as the mean of the matched treated-minus-control differences in observed outcomes, denoted $\\widehat{\\mathrm{ATE}}$. Compute the bias as $\\widehat{\\mathrm{ATE}} - \\tau$.\n\nYour program must implement the above logic and evaluate the bias for each of the following test cases, which together form the test suite:\n- Case $1$: $(\\text{seed}=101, N=800, \\delta_p=0.05, \\delta_x=0.5)$.\n- Case $2$: $(\\text{seed}=202, N=800, \\delta_p=0.02, \\delta_x=0.1)$.\n- Case $3$: $(\\text{seed}=303, N=800, \\delta_p=0.20, \\delta_x=2.0)$.\n- Case $4$: $(\\text{seed}=404, N=120, \\delta_p=0.05, \\delta_x=0.5)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each entry must be the bias for the corresponding case expressed as a decimal float rounded to six decimal places (for example, $[0.012345,-0.004321,0.000000,0.123456]$).", "solution": "The problem requires the implementation of a propensity score matching algorithm to estimate the bias of the Average Treatment Effect (ATE) in a simulated observational study. The solution will be derived from first principles of causal inference, specifically the potential outcomes framework.\n\n### Fundamental Principles of Causal Inference\n\nThe foundation of this problem lies in the potential outcomes framework, often called the Neyman-Rubin Causal Model. For each unit $i$, we define two potential outcomes: $Y_i(1)$, the outcome if the unit receives the treatment, and $Y_i(0)$, the outcome if the unit does not receive the treatment. The treatment assignment is indicated by a binary variable $T_i \\in \\{0, 1\\}$. The causal effect of the treatment for unit $i$ is the difference in its potential outcomes, $Y_i(1) - Y_i(0)$.\n\nThe central estimand of interest is the Average Treatment Effect (ATE), defined as the expected value of this unit-level effect over the entire population:\n$$\n\\mathrm{ATE} = \\mathbb{E}[Y_i(1) - Y_i(0)]\n$$\nIn the specific data-generating process provided, we have $Y_i(1) = Y_i(0) + \\tau$, where $\\tau = 2.0$ is a constant. Thus, the ATE is simply $\\tau$.\n\nThe fundamental problem of causal inference arises because for any given unit $i$, we can only observe one of the two potential outcomes. The observed outcome $Y_i$ is given by:\n$$\nY_i = T_i Y_i(1) + (1-T_i) Y_i(0)\n$$\n\n### Confounding and the Role of Propensity Scores\n\nIn a non-randomized study, treatment assignment is often influenced by pre-treatment covariates. If these covariates also influence the potential outcomes, they are known as confounders. A naive comparison of the average outcome between the treated and control groups, $\\mathbb{E}[Y_i | T_i=1] - \\mathbb{E}[Y_i | T_i=0]$, does not estimate the ATE. Instead, it is biased due to systematic differences in the covariates between the two groups. In this problem, the covariates are $\\mathbf{Z}_i = (X_i, C_{1,i}, C_{2,i})$, and they influence both the treatment assignment $\\Pr(T_i=1 \\mid \\mathbf{Z}_i)$ and the potential outcomes $Y_i(0)$ and $Y_i(1)$.\n\nTo overcome this confounding bias, we rely on the assumption of **unconfoundedness** (or conditional ignorability). This assumption states that, conditional on the covariates $\\mathbf{Z}_i$, the treatment assignment is independent of the potential outcomes:\n$$\n(Y_i(0), Y_i(1)) \\perp T_i \\mid \\mathbf{Z}_i\n$$\nThis assumption holds true by design in the given data-generating process. Under unconfoundedness, we can identify the ATE by adjusting for the covariates.\n\nA powerful tool for this adjustment is the **propensity score**, defined by Rosenbaum and Rubin as the conditional probability of receiving treatment given the covariates:\n$$\ne(\\mathbf{Z}_i) = \\Pr(T_i=1 \\mid \\mathbf{Z}_i)\n$$\nThe key property of the propensity score is that if unconfoundedness holds given $\\mathbf{Z}_i$, it also holds given the scalar propensity score $e(\\mathbf{Z}_i)$, assuming $0  e(\\mathbf{Z}_i)  1$ (the positivity or overlap assumption). This dimensional reduction is crucial, as it allows us to control for confounding by matching or stratifying on a single variable, the propensity score, rather than the full, potentially high-dimensional set of covariates $\\mathbf{Z}_i$.\n\n### Algorithmic Design\n\nThe solution involves a sequence of steps: data generation, propensity score estimation, matching, and finally, ATE estimation and bias calculation.\n\n**1. Data Generation**\nA dataset of size $N$ is generated according to the specified stochastic process. For each unit $i=1, \\dots, N$:\n- Draw the categorical confounders $C_{1,i} \\sim \\mathrm{Bernoulli}(0.5)$ and $C_{2,i}$ from its discrete distribution.\n- Draw the continuous covariate $X_i \\sim \\mathcal{N}(\\mu_i, 1)$, where $\\mu_i$ depends on $C_{1,i}$ and $C_{2,i}$.\n- Calculate the true propensity score using the given logistic function and coefficients $(\\alpha_0, \\alpha_X, \\alpha_{C_1}, \\ldots)$.\n- Assign treatment $T_i \\sim \\mathrm{Bernoulli}(\\Pr(T_i=1 \\mid X_i, C_{1,i}, C_{2,i}))$.\n- Generate the potential outcome $Y_i(0)$ based on the linear model involving the covariates and a noise term $\\varepsilon_i \\sim \\mathcal{N}(0,1)$. The potential outcome $Y_i(1)$ is $Y_i(0) + \\tau$.\n- Determine the observed outcome $Y_i$ based on $T_i$.\n\n**2. Propensity Score Estimation**\nWhile the true propensity score function is known in this simulation, standard practice is to estimate it from the observed data. The problem specifies using logistic regression.\n- A design matrix $\\mathbf{M}$ is constructed for the $N$ observations. Each row $\\mathbf{M}_i$ corresponds to unit $i$ and contains an intercept and the covariates used in the model: $(1, X_i, C_{1,i}, \\mathbb{1}\\{C_{2,i}=1\\}, \\mathbb{1}\\{C_{2,i}=2\\})$.\n- The logistic model predicts the probability of treatment as $p_i(\\boldsymbol{\\beta}) = \\sigma(\\mathbf{M}_i \\cdot \\boldsymbol{\\beta})$, where $\\sigma(u)$ is the sigmoid function and $\\boldsymbol{\\beta}$ is the vector of coefficients to be estimated.\n- The coefficients $\\hat{\\boldsymbol{\\beta}}$ are found by maximizing the log-likelihood function via numerical optimization. This is equivalent to minimizing the negative log-likelihood:\n$$\n\\mathcal{L}(\\boldsymbol{\\beta}) = -\\sum_{i=1}^N \\left[ T_i \\log(p_i(\\boldsymbol{\\beta})) + (1-T_i) \\log(1 - p_i(\\boldsymbol{\\beta})) \\right]\n$$\n- The gradient of the negative log-likelihood, required for efficient optimization, is:\n$$\n-\\nabla_{\\boldsymbol{\\beta}} \\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{i=1}^N (T_i - p_i(\\boldsymbol{\\beta})) \\mathbf{M}_i = \\mathbf{M}^T (\\mathbf{T} - \\mathbf{p}(\\boldsymbol{\\beta}))\n$$\n- Once $\\hat{\\boldsymbol{\\beta}}$ is obtained, the estimated propensity score for each unit is calculated as $\\hat{e}_i = \\sigma(\\mathbf{M}_i \\cdot \\hat{\\boldsymbol{\\beta}})$.\n\n**3. Matching Procedure**\nThe core of the task is to implement the specified matching algorithm. The goal is to find a control counterpart for each treated unit. This is a form of greedy nearest-neighbor matching with additional constraints, performed without replacement.\n- The dataset is partitioned into a treated group ($T_i=1$) and a control group ($T_i=0$).\n- For each treated unit $i$:\n    a. A pool of candidate controls is formed from all available (unmatched) control units $j$.\n    b. The pool is filtered based on the matching rules:\n        - **Exact Match:** $C_{1,j} = C_{1,i}$ and $C_{2,j} = C_{2,i}$.\n        - **Caliper on Covariate:** $|X_i - X_j| \\le \\delta_x$.\n        - **Caliper on Propensity Score:** $|\\hat{e}_i - \\hat{e}_j| \\le \\delta_p$.\n    c. If the resulting pool of eligible controls is not empty, the control unit $j^*$ that minimizes the propensity score distance, $|\\hat{e}_i - \\hat{e}_{j^*}|$, is selected as the match.\n    d. The pair $(i, j^*)$ is recorded, and the control unit $j^*$ is marked as unavailable for future matches.\n    e. If no eligible control is found, the treated unit $i$ is discarded.\n\n**4. ATE Estimation and Bias Calculation**\n- After the matching process is complete, a set of $N_{\\text{matched}}$ pairs is obtained.\n- The estimated ATE is calculated as the simple mean of the outcome differences within these pairs:\n$$\n\\widehat{\\mathrm{ATE}} = \\frac{1}{N_{\\text{matched}}} \\sum_{(i,j) \\in \\text{matched pairs}} (Y_i - Y_j)\n$$\n- This estimator is an approximation of the Average Treatment Effect on the Treated (ATT). Under the constant treatment effect assumption of this problem, ATT = ATE.\n- Finally, the bias of the estimator is computed by comparing it to the true ATE, $\\tau=2.0$:\n$$\n\\text{Bias} = \\widehat{\\mathrm{ATE}} - \\tau\n$$\nThis entire process is repeated for each of the four test cases defined by different random seeds, sample sizes, and caliper widths.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        (101, 800, 0.05, 0.5),\n        (202, 800, 0.02, 0.1),\n        (303, 800, 0.20, 2.0),\n        (404, 120, 0.05, 0.5),\n    ]\n\n    tau = 2.0\n    results = []\n\n    for seed, n_samples, delta_p, delta_x in test_cases:\n        bias = calculate_bias(seed, n_samples, delta_p, delta_x, tau)\n        results.append(f\"{bias:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_bias(seed, n_samples, delta_p, delta_x, tau):\n    \"\"\"\n    Calculates the bias of the ATE estimator for a single simulation case.\n    \"\"\"\n    # 1. Generate data\n    data = generate_data(seed, n_samples, tau)\n    X, C1, C2, T, Y = data['X'], data['C1'], data['C2'], data['T'], data['Y']\n    \n    # 2. Estimate propensity scores\n    e_hat = estimate_propensity_scores(X, C1, C2, T)\n    \n    # 3. Perform matching\n    matched_diffs = perform_matching(X, C1, C2, T, Y, e_hat, delta_p, delta_x)\n    \n    # 4. Calculate ATE and bias\n    if not matched_diffs:\n        # If no matches are found, the mean is undefined.\n        # A reasonable choice is to set the estimated ATE to 0, which is standard in some packages,\n        # though this implies a large bias. The problem setup makes this outcome unlikely.\n        ate_hat = 0.0\n    else:\n        ate_hat = np.mean(matched_diffs)\n    \n    bias = ate_hat - tau\n    return bias\n\ndef generate_data(seed, n_samples, tau):\n    \"\"\"\n    Generates data according to the problem's data-generating process.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # Confounders\n    C1 = rng.binomial(1, 0.5, size=n_samples)\n    C2 = rng.choice([0, 1, 2], size=n_samples, p=[0.4, 0.4, 0.2])\n    \n    mu = 0.5 * C1 + 0.3 * (C2 == 1) - 0.3 * (C2 == 2)\n    X = rng.normal(loc=mu, scale=1, size=n_samples)\n    \n    # Treatment assignment\n    alpha_0, alpha_X, alpha_C1 = 0.2, 0.8, 0.6\n    alpha_C2_1, alpha_C2_2 = 0.4, -0.4\n    \n    linear_pred_T = alpha_0 + alpha_X * X + alpha_C1 * C1 + \\\n                    alpha_C2_1 * (C2 == 1) + alpha_C2_2 * (C2 == 2)\n    propensity_true = 1 / (1 + np.exp(-linear_pred_T))\n    T = rng.binomial(1, propensity_true, size=n_samples)\n    \n    # Potential outcomes\n    gamma_0, gamma_X, gamma_C1 = 1.0, 1.0, 0.5\n    gamma_C2_1, gamma_C2_2 = 0.2, -0.2\n    \n    epsilon = rng.normal(0, 1, size=n_samples)\n    Y0 = gamma_0 + gamma_X * X + gamma_C1 * C1 + \\\n         gamma_C2_1 * (C2 == 1) + gamma_C2_2 * (C2 == 2) + epsilon\n    Y1 = Y0 + tau\n    \n    # Observed outcome\n    Y = T * Y1 + (1 - T) * Y0\n    \n    return {'X': X, 'C1': C1, 'C2': C2, 'T': T, 'Y': Y}\n\ndef estimate_propensity_scores(X, C1, C2, T):\n    \"\"\"\n    Estimates propensity scores using logistic regression with MLE.\n    \"\"\"\n    # Design matrix M\n    M = np.c_[np.ones(len(X)), X, C1, (C2 == 1).astype(int), (C2 == 2).astype(int)]\n    \n    def sigmoid(u):\n        return 1 / (1 + np.exp(-u))\n\n    def neg_log_likelihood(beta, M, T):\n        p = sigmoid(M @ beta)\n        # Add small epsilon to prevent log(0)\n        p = np.clip(p, 1e-9, 1 - 1e-9)\n        return -np.sum(T * np.log(p) + (1 - T) * np.log(1 - p))\n\n    def gradient(beta, M, T):\n        p = sigmoid(M @ beta)\n        return M.T @ (p - T)\n\n    initial_beta = np.zeros(M.shape[1])\n    res = minimize(neg_log_likelihood, initial_beta, args=(M, T), jac=gradient, method='BFGS')\n    \n    beta_hat = res.x\n    e_hat = sigmoid(M @ beta_hat)\n    \n    return e_hat\n\ndef perform_matching(X, C1, C2, T, Y, e_hat, delta_p, delta_x):\n    \"\"\"\n    Performs matching based on exact confounder match and calipers.\n    \"\"\"\n    treated_indices = np.where(T == 1)[0]\n    control_indices = np.where(T == 0)[0]\n    \n    control_data = {\n        'C1': C1[control_indices],\n        'C2': C2[control_indices],\n        'X': X[control_indices],\n        'e_hat': e_hat[control_indices]\n    }\n    \n    is_control_available = np.ones(len(control_indices), dtype=bool)\n    matched_diffs = []\n\n    for i in treated_indices:\n        # Candidate controls must be available and match exactly on C1, C2\n        eligible_mask = (is_control_available)  \\\n                        (control_data['C1'] == C1[i])  \\\n                        (control_data['C2'] == C2[i])\n        \n        # Apply calipers\n        eligible_mask = (np.abs(control_data['X'] - X[i]) = delta_x)\n        eligible_mask = (np.abs(control_data['e_hat'] - e_hat[i]) = delta_p)\n        \n        candidate_control_local_indices = np.where(eligible_mask)[0]\n        \n        if len(candidate_control_local_indices) > 0:\n            # Find the best match among eligible candidates (nearest neighbor on propensity score)\n            prop_diffs = np.abs(control_data['e_hat'][candidate_control_local_indices] - e_hat[i])\n            best_match_local_idx = candidate_control_local_indices[np.argmin(prop_diffs)]\n            \n            # Get the global index of the matched control\n            best_match_global_idx = control_indices[best_match_local_idx]\n            \n            # Record the matched difference and update control availability\n            matched_diffs.append(Y[i] - Y[best_match_global_idx])\n            is_control_available[best_match_local_idx] = False\n            \n    return matched_diffs\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3163024"}]}