{"hands_on_practices": [{"introduction": "Moving beyond predicting absolute rating values, modern recommender systems often focus on learning users' relative preferences. This exercise guides you through building a collaborative filtering model from first principles that learns to rank items based on ordinal data. By implementing a latent factor model trained with a pairwise hinge loss, you will gain hands-on experience with the core mechanics of learning-to-rank, a powerful paradigm in information retrieval and recommendation [@problem_id:3110042].", "problem": "You are asked to implement a pairwise-ranking collaborative filtering algorithm that enforces partial order constraints derived from observed user ratings. The context is statistical learning for recommendation systems. You will use a latent factor model and a pairwise hinge loss to learn user and item embeddings from observed ratings, and then evaluate how well the learned model satisfies the observed ranking constraints.\n\nImplement a program that, for each test case, does the following from first principles:\n- Treat entries of a user-item rating matrix as observations of ordinal preferences. A missing entry is encoded as $0$ and carries no information.\n- For each user $u$, construct all ordered pairs of items $(j,k)$ such that $R_{uj} > R_{uk}$, where $R_{uj}$ denotes the observed rating of user $u$ on item $j$. Each such triple $(u,j,k)$ constitutes a strict partial order constraint that the model must aim to satisfy via $\\hat{R}_{uj} > \\hat{R}_{uk}$.\n- Use a $k$-dimensional latent factor model with predicted score $\\hat{R}_{ui} = p_u^\\top q_i$, where $p_u \\in \\mathbb{R}^k$ is the latent vector for user $u$ and $q_i \\in \\mathbb{R}^k$ is the latent vector for item $i$. Initialize all latent vectors with independent samples from a zero-mean normal distribution with small standard deviation.\n- Define the empirical risk as a pairwise hinge loss with a fixed positive margin $\\gamma$ and $\\ell_2$ regularization. That is, for each constraint $(u,j,k)$, the loss contribution is $\\max\\left(0,\\ \\gamma - \\left(p_u^\\top q_j - p_u^\\top q_k\\right)\\right)$, and the total loss adds $\\frac{\\lambda}{2}\\left(\\lVert P\\rVert_F^2 + \\lVert Q\\rVert_F^2\\right)$ for regularization, where $P$ and $Q$ are the stacked matrices of user and item factors, respectively.\n- Optimize the parameters using Stochastic Gradient Descent (SGD), where the subgradient of the hinge term is applied only when the associated margin violation is positive, and the $\\ell_2$ regularization is applied throughout training. Ensure you randomize the order of constraints each epoch using a fixed random seed to make results reproducible. Stochastic Gradient Descent (SGD) must be explicitly implemented; do not rely on external optimization routines.\n- After training, compute the ranking accuracy as the fraction of satisfied constraints over all constructed constraints for the test case. A constraint $(u,j,k)$ is satisfied if and only if $\\hat{R}_{uj} - \\hat{R}_{uk} > 0$. If a user contributes no constraints (for example, due to only one rating or ties), simply contributes zero constraints to the total denominator. If a test case yields zero total constraints, define the accuracy to be $1.0$ by convention to avoid division by zero. Ties in predictions, i.e., $\\hat{R}_{uj} - \\hat{R}_{uk} = 0$, should be treated as not satisfied.\n\nYour program must process the following three test cases. In each, ratings are integers in the set $\\{1,2,3,4,5\\}$ and missing entries are encoded as $0$. Use the same hyperparameters for all test cases: latent dimension $k = 3$, learning rate $\\eta = 0.05$, regularization coefficient $\\lambda = 0.01$, margin $\\gamma = 1.0$, number of epochs $T = 200$, and random seed $s = 42$ for both initialization and the shuffling of constraints per epoch.\n\nTest case $1$:\n- Rating matrix $R^{(1)}$ of shape $3 \\times 4$:\n  - Row $0$: $[5,3,0,1]$\n  - Row $1$: $[0,4,2,0]$\n  - Row $2$: $[2,0,5,4]$\n\nTest case $2$:\n- Rating matrix $R^{(2)}$ of shape $3 \\times 4$:\n  - Row $0$: $[3,3,1,0]$ (ties between items with equal ratings do not form constraints)\n  - Row $1$: $[0,0,5,0]$ (a single rating yields no constraints)\n  - Row $2$: $[4,4,4,4]$ (all equal ratings yield no constraints)\n\nTest case $3$:\n- Rating matrix $R^{(3)}$ of shape $4 \\times 5$:\n  - Row $0$: $[1,0,4,0,2]$\n  - Row $1$: $[0,5,0,3,0]$\n  - Row $2$: $[2,0,0,0,1]$\n  - Row $3$: $[0,4,1,0,0]$\n\nImplementation details to respect:\n- Construct the set of constraints from $R$ using only pairs $(j,k)$ with $R_{uj} > R_{uk}$ for each user $u$; do not create constraints from equal ratings.\n- Use the specified latent factor model and hinge loss with margin $\\gamma$ and $\\ell_2$ regularization with coefficient $\\lambda$.\n- Implement training with $T$ full passes over the set of constraints using SGD. Use the fixed seed $s$ to initialize parameters and to shuffle the constraints at each epoch to ensure reproducibility.\n- Compute the final ranking accuracy as a float in $[0,1]$ per test case.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of three floating-point numbers enclosed in square brackets, in the order of the test cases, each formatted to exactly four digits after the decimal point (for example, $[0.9750,0.5000,1.0000]$).", "solution": "The user-item rating matrix is treated as a source of ordinal preference data. The problem requires the implementation of a pairwise-ranking collaborative filtering algorithm using a latent factor model. The model's parameters are learned by optimizing a specific objective function via Stochastic Gradient Descent (SGD).\n\n### 1. Model and Objective Function\n\nThe core of the model is to learn latent factor representations for each user and item. For a user $u$ and an item $i$, their respective latent vectors are $p_u \\in \\mathbb{R}^k$ and $q_i \\in \\mathbb{R}^k$, where $k$ is the dimensionality of the latent space. The predicted preference score of user $u$ for item $i$ is given by the dot product:\n$$\n\\hat{R}_{ui} = p_u^\\top q_i\n$$\nThe learning process does not directly predict the rating values. Instead, it aims to preserve the relative ordering of preferences observed in the data. For each user $u$, a strict partial order constraint $(u,j,k)$ is generated for every pair of items $(j,k)$ where the observed rating for item $j$ is strictly greater than for item $k$, i.e., $R_{uj} > R_{uk}$. The set of all such constraints is denoted by $\\mathcal{C}$.\n\nThe model is trained by minimizing an empirical risk function defined by a pairwise hinge loss with $\\ell_2$ regularization. For each constraint $(u,j,k) \\in \\mathcal{C}$, the model should predict $\\hat{R}_{uj} > \\hat{R}_{uk}$. The loss function penalizes violations of this ordering, specifically when $\\hat{R}_{uj} - \\hat{R}_{uk}$ is not greater than a specified margin $\\gamma$. The total objective function $L$ to be minimized is:\n$$\nL(P, Q) = \\sum_{(u,j,k) \\in \\mathcal{C}} \\max\\left(0, \\gamma - (\\hat{R}_{uj} - \\hat{R}_{uk})\\right) + \\frac{\\lambda}{2}\\left(\\lVert P \\rVert_F^2 + \\lVert Q \\rVert_F^2\\right)\n$$\nHere, $P$ and $Q$ are the matrices formed by stacking all user vectors $p_u$ and item vectors $q_i$, respectively. The term $\\lVert \\cdot \\rVert_F^2$ represents the squared Frobenius norm, which is $\\sum_u \\lVert p_u \\rVert_2^2 + \\sum_i \\lVert q_i \\rVert_2^2$. The hyperparameter $\\lambda > 0$ controls the strength of the regularization, which prevents overfitting by penalizing large parameter values. The margin is given as $\\gamma=1.0$.\n\n### 2. Algorithmic Implementation\n\n#### 2.1. Constraint Generation\nFirst, the set of preference constraints $\\mathcal{C}$ is extracted from the input rating matrix $R$. For each user $u$, we identify all items they have rated (where the rating is non-zero). Then, for every ordered pair of these rated items, say item $j$ and item $k'$, if $R_{uj} > R_{uk'}$, the triple $(u,j,k')$ is added to $\\mathcal{C}$. Ties ($R_{uj} = R_{uk'}$) and missing ratings do not contribute constraints.\n\n#### 2.2. Parameter Initialization\nThe user factor matrix $P$ of size $N_u \\times k$ and the item factor matrix $Q$ of size $N_i \\times k$ are initialized. $N_u$ is the number of users and $N_i$ is the number of items. Each entry is drawn from a zero-mean normal distribution with a small standard deviation ($0.1$ is a suitable choice). A fixed random seed ($s=42$) is used to ensure reproducibility.\n\n#### 2.3. Stochastic Gradient Descent (SGD) Optimization\nThe model parameters $P$ and $Q$ are optimized by iterating over the training data for a fixed number of epochs ($T=200$). In each epoch, the set of constraints $\\mathcal{C}$ is shuffled randomly (using the same seeded random number generator) to ensure unbiased updates. The algorithm then iterates through each constraint $(u,j,k') \\in \\mathcal{C}$ and performs an SGD update.\n\nFor a single constraint $(u,j,k')$, the gradients of the objective function with respect to the involved parameters $p_u$, $q_j$, and $q_{k'}$ are computed. Let $x_{ujk'} = p_u^\\top q_j - p_u^\\top q_{k'}$. The indicator function $\\mathbb{I}[\\gamma - x_{ujk'} > 0]$ is $1$ if the margin is violated and $0$ otherwise. The gradients are:\n$$\n\\nabla_{p_u} L = \\lambda p_u + \\mathbb{I}[\\gamma - x_{ujk'} > 0] \\cdot (q_{k'} - q_j)\n$$\n$$\n\\nabla_{q_j} L = \\lambda q_j + \\mathbb{I}[\\gamma - x_{ujk'} > 0] \\cdot (-p_u)\n$$\n$$\n\\nabla_{q_{k'}} L = \\lambda q_{k'} + \\mathbb{I}[\\gamma - x_{ujk'} > 0] \\cdot (p_u)\n$$\nThe parameters are then updated by taking a small step in the negative gradient direction, scaled by the learning rate $\\eta=0.05$:\n$$\np_u \\leftarrow p_u - \\eta \\nabla_{p_u} L\n$$\n$$\nq_j \\leftarrow q_j - \\eta \\nabla_{q_j} L\n$$\n$$\nq_{k'} \\leftarrow q_{k'} - \\eta \\nabla_{q_{k'}} L\n$$\nTo ensure a correct update, the values of $p_u$, $q_j$, and $q_{k'}$ from the beginning of the step must be used for all gradient calculations within that step.\n\n### 3. Evaluation\nAfter $T$ epochs of training, the model's performance is evaluated using ranking accuracy. This metric is the fraction of constraints in $\\mathcal{C}$ that are correctly satisfied by the learned model. A constraint $(u,j,k')$ is considered satisfied if the predicted score for item $j$ is strictly greater than for item $k'$, i.e., $\\hat{R}_{uj} - \\hat{R}_{uk'} > 0$. Ties ($\\hat{R}_{uj} - \\hat{R}_{uk'} = 0$) are counted as not satisfied. The accuracy is calculated as:\n$$\n\\text{Accuracy} = \\frac{|\\{(u,j,k') \\in \\mathcal{C} \\mid p_u^\\top q_j - p_u^\\top q_{k'} > 0\\}|}{|\\mathcal{C}|}\n$$\nIf a test case results in zero constraints being generated ($|\\mathcal{C}| = 0$), the accuracy is defined as $1.0$ by convention.", "answer": "```python\nimport numpy as np\n\ndef run_pairwise_ranking(R, k, eta, lamb, gamma, T, seed):\n    \"\"\"\n    Implements and evaluates the pairwise-ranking collaborative filtering algorithm.\n\n    Args:\n        R (np.ndarray): The user-item rating matrix.\n        k (int): The number of latent dimensions.\n        eta (float): The learning rate for SGD.\n        lamb (float): The regularization coefficient.\n        gamma (float): The margin for the hinge loss.\n        T (int): The number of training epochs.\n        seed (int): The random seed for reproducibility.\n\n    Returns:\n        float: The final ranking accuracy.\n    \"\"\"\n    num_users, num_items = R.shape\n\n    # Step 1: Construct partial order constraints from the rating matrix.\n    # A constraint is a tuple (user_id, preferred_item_id, less_preferred_item_id).\n    constraints = []\n    for u in range(num_users):\n        rated_items_indices = np.where(R[u, :] > 0)[0]\n        # Generate pairs of items rated by the same user\n        for i in range(len(rated_items_indices)):\n            for j in range(len(rated_items_indices)):\n                if i == j:\n                    continue\n                item_j = rated_items_indices[i]\n                item_k = rated_items_indices[j]\n                # Add constraint if a strict preference is observed\n                if R[u, item_j] > R[u, item_k]:\n                    constraints.append((u, item_j, item_k))\n\n    # If there are no constraints, accuracy is 1.0 by definition.\n    if not constraints:\n        return 1.0\n\n    # Step 2: Initialize parameters (user and item latent factor matrices).\n    # The same RNG is used for initialization and shuffling for reproducibility.\n    rng = np.random.default_rng(seed)\n    std_dev = 0.1  # A small standard deviation for initialization\n    P = rng.normal(loc=0.0, scale=std_dev, size=(num_users, k))\n    Q = rng.normal(loc=0.0, scale=std_dev, size=(num_items, k))\n\n    # Step 3: Train using Stochastic Gradient Descent (SGD).\n    for epoch in range(T):\n        rng.shuffle(constraints)  # Shuffle constraints for each epoch\n        for u, j, k_item in constraints:\n            # Get current factors. Make copies to ensure simultaneous updates.\n            p_u = P[u, :].copy()\n            q_j = Q[j, :].copy()\n            q_k = Q[k_item, :].copy()\n\n            # Calculate the difference in predicted scores\n            pred_diff = np.dot(p_u, q_j) - np.dot(p_u, q_k)\n\n            # Check for margin violation to determine the hinge loss gradient part\n            if gamma - pred_diff > 0:\n                grad_pu_hinge = q_k - q_j\n                grad_qj_hinge = -p_u\n                grad_qk_hinge = p_u\n            else:\n                grad_pu_hinge = 0.0\n                grad_qj_hinge = 0.0\n                grad_qk_hinge = 0.0\n            \n            # Update parameters by taking a step against the combined gradient\n            # (regularization + hinge loss)\n            P[u, :] -= eta * (lamb * p_u + grad_pu_hinge)\n            Q[j, :] -= eta * (lamb * q_j + grad_qj_hinge)\n            Q[k_item, :] -= eta * (lamb * q_k + grad_qk_hinge)\n\n    # Step 4: Evaluate ranking accuracy on the set of constraints.\n    satisfied_count = 0\n    for u, j, k_item in constraints:\n        # A constraint is satisfied if the predicted preference order matches the observed one.\n        pred_diff = np.dot(P[u, :], Q[j, :]) - np.dot(P[u, :], Q[k_item, :])\n        if pred_diff > 0:\n            satisfied_count += 1\n            \n    accuracy = satisfied_count / len(constraints)\n    return accuracy\n\ndef solve():\n    \"\"\"\n    Main function to run the algorithm on all test cases and print the results.\n    \"\"\"\n    # Define hyperparameters as specified in the problem\n    k = 3\n    eta = 0.05\n    lamb = 0.01  # `lambda` is a keyword, so `lamb` is used\n    gamma = 1.0\n    T = 200\n    seed = 42\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        np.array([\n            [5, 3, 0, 1],\n            [0, 4, 2, 0],\n            [2, 0, 5, 4]\n        ], dtype=np.float64),\n        np.array([\n            [3, 3, 1, 0],\n            [0, 0, 5, 0],\n            [4, 4, 4, 4]\n        ], dtype=np.float64),\n        np.array([\n            [1, 0, 4, 0, 2],\n            [0, 5, 0, 3, 0],\n            [2, 0, 0, 0, 1],\n            [0, 4, 1, 0, 0]\n        ], dtype=np.float64)\n    ]\n\n    results = []\n    for R_case in test_cases:\n        accuracy = run_pairwise_ranking(R_case, k, eta, lamb, gamma, T, seed)\n        # Format the result to exactly four decimal places\n        results.append(f\"{accuracy:.4f}\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3110042"}, {"introduction": "After building a model, the next step is to master its optimization. This practice delves into the mathematical heart of Bayesian Personalized Ranking (BPR), a cornerstone of modern collaborative filtering that frames ranking as a probabilistic pairwise task. You will derive the gradient of the BPR objective function—a crucial step for training the model with gradient descent—and then apply your derivation to a concrete numerical example to solidify the link between the loss function and parameter updates [@problem_id:3110073].", "problem": "A recommender system uses Bayesian Personalized Ranking (BPR), which models pairwise preferences with a logistic link: for a user $i$ and items $j$ and $k$, the probability that user $i$ prefers item $j$ over item $k$ is $p\\big((i,j,k)\\big) = \\sigma\\!\\big(\\Delta_{ijk}\\big)$ where $\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$ and $\\Delta_{ijk} = u_i^{\\top}(v_j - v_k)$. The training objective is the regularized negative log-likelihood\n$$\n\\mathcal{L}(U,V) = - \\sum_{(i,j,k) \\in \\mathcal{S}} \\ln\\!\\big(\\sigma(\\Delta_{ijk})\\big) + \\frac{\\lambda}{2} \\sum_{i} \\|u_i\\|_2^2 + \\frac{\\lambda}{2} \\sum_{\\ell} \\|v_{\\ell}\\|_2^2,\n$$\nwhere $U = \\{u_i\\}$ are user embeddings, $V = \\{v_{\\ell}\\}$ are item embeddings, $\\lambda > 0$ is a regularization coefficient, and $\\mathcal{S}$ is the set of observed user-item positive-negative pairs.\n\nStarting from this definition and the properties of the logistic function, derive the gradient $\\nabla_{u_i} \\mathcal{L}$ for a fixed user $i$ as a function of $\\{(j,k) \\in \\mathcal{S}_i\\}$, the user embedding $u_i$, and item embeddings $v_j$ and $v_k$. Then, for the specific instance with embedding dimension $d = 3$, user $i$ having two observed pairs $\\mathcal{S}_i = \\{(j_1,k_1),(j_2,k_2)\\}$, regularization $\\lambda = 0.1$, and\n$$\nu_i = \\begin{pmatrix} 0.5 \\\\ -1.0 \\\\ 0.75 \\end{pmatrix}, \\quad\nv_{j_1} = \\begin{pmatrix} 0.2 \\\\ 0.0 \\\\ -0.1 \\end{pmatrix}, \\quad\nv_{k_1} = \\begin{pmatrix} -0.3 \\\\ 0.4 \\\\ 0.0 \\end{pmatrix},\n$$\n$$\nv_{j_2} = \\begin{pmatrix} 1.0 \\\\ -0.5 \\\\ 0.25 \\end{pmatrix}, \\quad\nv_{k_2} = \\begin{pmatrix} -0.5 \\\\ 0.2 \\\\ 0.1 \\end{pmatrix},\n$$\nevaluate the Euclidean norm $\\|\\nabla_{u_i} \\mathcal{L}\\|_2$. Round your final numerical answer to four significant figures. Express your final answer as a pure number with no units.", "solution": "The user-facing problem is to first derive the gradient of the Bayesian Personalized Ranking (BPR) loss function with respect to a user embedding, and then to calculate the Euclidean norm of this gradient for a specific numerical instance.\n\nThe BPR objective function is given as:\n$$\n\\mathcal{L}(U,V) = - \\sum_{(i,j,k) \\in \\mathcal{S}} \\ln\\!\\big(\\sigma(\\Delta_{ijk})\\big) + \\frac{\\lambda}{2} \\sum_{i} \\|u_i\\|_2^2 + \\frac{\\lambda}{2} \\sum_{\\ell} \\|v_{\\ell}\\|_2^2\n$$\nwhere $\\Delta_{ijk} = u_i^{\\top}(v_j - v_k)$ and $\\sigma(x) = (1 + \\exp(-x))^{-1}$.\n\nWe are asked to find the gradient $\\nabla_{u_i} \\mathcal{L}$ for a fixed user $i$. When differentiating with respect to a specific user embedding $u_i$, we only need to consider the terms in $\\mathcal{L}$ that depend on $u_i$. These are the preference terms involving user $i$ and the regularization term for $u_i$. Let $\\mathcal{S}_i$ be the set of observed pairs for user $i$, i.e., $\\mathcal{S}_i = \\{(j,k) | (i,j,k) \\in \\mathcal{S}\\}$.\n\nThe part of the loss function that depends on $u_i$, denoted $\\mathcal{L}_i$, is:\n$$\n\\mathcal{L}_i(u_i) = - \\sum_{(j,k) \\in \\mathcal{S}_i} \\ln\\!\\big(\\sigma(u_i^{\\top}(v_j - v_k))\\big) + \\frac{\\lambda}{2} \\|u_i\\|_2^2\n$$\nThe gradient is $\\nabla_{u_i} \\mathcal{L} = \\nabla_{u_i} \\mathcal{L}_i(u_i)$. We can compute the gradient of each term separately.\n\nThe gradient of the regularization term is a standard result:\n$$\n\\nabla_{u_i} \\left(\\frac{\\lambda}{2} \\|u_i\\|_2^2\\right) = \\nabla_{u_i} \\left(\\frac{\\lambda}{2} u_i^{\\top}u_i\\right) = \\lambda u_i\n$$\n\nFor the negative log-likelihood term, we focus on a single triplet $(i,j,k)$. Let's find the gradient of $\\ln(\\sigma(\\Delta_{ijk}))$ using the chain rule.\n$$\n\\nabla_{u_i} \\ln(\\sigma(\\Delta_{ijk})) = \\frac{d}{d\\sigma} \\ln(\\sigma) \\cdot \\frac{d\\sigma}{d\\Delta_{ijk}} \\cdot \\nabla_{u_i} \\Delta_{ijk}\n$$\nThe derivatives are:\n$1$. $\\frac{d}{d\\sigma} \\ln(\\sigma) = \\frac{1}{\\sigma(\\Delta_{ijk})}$.\n$2$. The derivative of the logistic function is $\\sigma'(x) = \\sigma(x)(1 - \\sigma(x))$. Thus, $\\frac{d\\sigma}{d\\Delta_{ijk}} = \\sigma(\\Delta_{ijk})(1 - \\sigma(\\Delta_{ijk}))$.\n$3$. $\\Delta_{ijk}$ is a linear function of $u_i$. For $\\Delta_{ijk} = u_i^{\\top}(v_j - v_k)$, the gradient is $\\nabla_{u_i} \\Delta_{ijk} = v_j - v_k$.\n\nCombining these results:\n$$\n\\nabla_{u_i} \\ln(\\sigma(\\Delta_{ijk})) = \\frac{1}{\\sigma(\\Delta_{ijk})} \\cdot \\sigma(\\Delta_{ijk})(1 - \\sigma(\\Delta_{ijk})) \\cdot (v_j - v_k) = (1 - \\sigma(\\Delta_{ijk}))(v_j - v_k)\n$$\nUsing the property $1 - \\sigma(x) = \\frac{1+\\exp(-x)-1}{1+\\exp(-x)} = \\frac{\\exp(-x)}{1+\\exp(-x)} = \\frac{1}{\\exp(x)+1} = \\sigma(-x)$, we can write:\n$$\n\\nabla_{u_i} \\ln(\\sigma(\\Delta_{ijk})) = \\sigma(-\\Delta_{ijk})(v_j - v_k)\n$$\nNow, we can write the gradient for the full loss $\\mathcal{L}_i$:\n$$\n\\nabla_{u_i} \\mathcal{L}_i(u_i) = \\nabla_{u_i} \\left( - \\sum_{(j,k) \\in \\mathcal{S}_i} \\ln(\\sigma(\\Delta_{ijk})) + \\frac{\\lambda}{2} \\|u_i\\|_2^2 \\right)\n$$\n$$\n\\nabla_{u_i} \\mathcal{L} = - \\sum_{(j,k) \\in \\mathcal{S}_i} \\sigma(-\\Delta_{ijk})(v_j - v_k) + \\lambda u_i\n$$\nThis is the general expression for the gradient with respect to the user embedding $u_i$.\n\nNext, we evaluate this gradient for the specific instance provided.\nThe parameters are:\n$\\lambda = 0.1$.\n$u_i = \\begin{pmatrix} 0.5 \\\\ -1.0 \\\\ 0.75 \\end{pmatrix}$.\nThe set of pairs for user $i$ is $\\mathcal{S}_i = \\{(j_1,k_1),(j_2,k_2)\\}$, so the sum has two terms.\nThe item embeddings are:\n$v_{j_1} = \\begin{pmatrix} 0.2 \\\\ 0.0 \\\\ -0.1 \\end{pmatrix}, v_{k_1} = \\begin{pmatrix} -0.3 \\\\ 0.4 \\\\ 0.0 \\end{pmatrix}$.\n$v_{j_2} = \\begin{pmatrix} 1.0 \\\\ -0.5 \\\\ 0.25 \\end{pmatrix}, v_{k_2} = \\begin{pmatrix} -0.5 \\\\ 0.2 \\\\ 0.1 \\end{pmatrix}$.\n\nThe gradient is:\n$$\n\\nabla_{u_i} \\mathcal{L} = -\\sigma(-\\Delta_{ij_1k_1})(v_{j_1} - v_{k_1}) - \\sigma(-\\Delta_{ij_2k_2})(v_{j_2} - v_{k_2}) + \\lambda u_i\n$$\n\nFor the first pair $(j_1,k_1)$:\n$v_{j_1} - v_{k_1} = \\begin{pmatrix} 0.2 - (-0.3) \\\\ 0.0 - 0.4 \\\\ -0.1 - 0.0 \\end{pmatrix} = \\begin{pmatrix} 0.5 \\\\ -0.4 \\\\ -0.1 \\end{pmatrix}$.\n$\\Delta_{ij_1k_1} = u_i^{\\top}(v_{j_1} - v_{k_1}) = (0.5)(0.5) + (-1.0)(-0.4) + (0.75)(-0.1) = 0.25 + 0.4 - 0.075 = 0.575$.\nThe coefficient is $\\sigma(-\\Delta_{ij_1k_1}) = \\sigma(-0.575) = \\frac{1}{1 + \\exp(0.575)} \\approx 0.360093$.\n\nFor the second pair $(j_2,k_2)$:\n$v_{j_2} - v_{k_2} = \\begin{pmatrix} 1.0 - (-0.5) \\\\ -0.5 - 0.2 \\\\ 0.25 - 0.1 \\end{pmatrix} = \\begin{pmatrix} 1.5 \\\\ -0.7 \\\\ 0.15 \\end{pmatrix}$.\n$\\Delta_{ij_2k_2} = u_i^{\\top}(v_{j_2} - v_{k_2}) = (0.5)(1.5) + (-1.0)(-0.7) + (0.75)(0.15) = 0.75 + 0.7 + 0.1125 = 1.5625$.\nThe coefficient is $\\sigma(-\\Delta_{ij_2k_2}) = \\sigma(-1.5625) = \\frac{1}{1 + \\exp(1.5625)} \\approx 0.173291$.\n\nThe regularization term is:\n$\\lambda u_i = 0.1 \\begin{pmatrix} 0.5 \\\\ -1.0 \\\\ 0.75 \\end{pmatrix} = \\begin{pmatrix} 0.05 \\\\ -0.1 \\\\ 0.075 \\end{pmatrix}$.\n\nNow we assemble the gradient vector, which we denote $g = \\nabla_{u_i} \\mathcal{L}$:\n$$\ng = -0.360093 \\begin{pmatrix} 0.5 \\\\ -0.4 \\\\ -0.1 \\end{pmatrix} - 0.173291 \\begin{pmatrix} 1.5 \\\\ -0.7 \\\\ 0.15 \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.1 \\\\ 0.075 \\end{pmatrix}\n$$\nThe components of the gradient vector $g = (g_1, g_2, g_3)^{\\top}$ are:\n$g_1 = - (0.360093)(0.5) - (0.173291)(1.5) + 0.05 = -0.1800465 - 0.2599365 + 0.05 = -0.389983$.\n$g_2 = - (0.360093)(-0.4) - (0.173291)(-0.7) - 0.1 = 0.1440372 + 0.1213037 - 0.1 = 0.1653409$.\n$g_3 = - (0.360093)(-0.1) - (0.173291)(0.15) + 0.075 = 0.0360093 - 0.02599365 + 0.075 = 0.08501565$.\n\nSo, the gradient vector is approximately:\n$$\n\\nabla_{u_i} \\mathcal{L} \\approx \\begin{pmatrix} -0.389983 \\\\ 0.165341 \\\\ 0.085016 \\end{pmatrix}\n$$\nFinally, we compute its Euclidean norm $\\|\\nabla_{u_i} \\mathcal{L}\\|_2$:\n$$\n\\|\\nabla_{u_i} \\mathcal{L}\\|_2 = \\sqrt{g_1^2 + g_2^2 + g_3^2}\n$$\n$$\n\\|\\nabla_{u_i} \\mathcal{L}\\|_2 \\approx \\sqrt{(-0.389983)^2 + (0.165341)^2 + (0.085016)^2}\n$$\n$$\n\\|\\nabla_{u_i} \\mathcal{L}\\|_2 \\approx \\sqrt{0.152087 + 0.027338 + 0.007228} = \\sqrt{0.186653} \\approx 0.4320335\n$$\nUsing higher precision for intermediate calculations leads to $\\sqrt{0.186652072} \\approx 0.432032489$. Rounding to four significant figures gives $0.4320$.", "answer": "$$\\boxed{0.4320}$$", "id": "3110073"}, {"introduction": "A model's perceived performance can be misleading if its evaluation is flawed. In real-world recommender systems, user interactions like clicks are heavily influenced by the position of items on the screen, an effect known as position bias. This final practice addresses this critical issue by guiding you to implement an exposure-aware evaluation metric, contrasting it with a naïve approach. By using Inverse Propensity Scoring (IPS) to create an unbiased version of Normalized Discounted Cumulative Gain (NDCG), you will learn a standard and essential technique for robust offline model evaluation [@problem_id:3110057].", "problem": "You are tasked with designing a program to evaluate ranked recommendations under position-dependent exposure bias using collaborative filtering evaluation principles. The setting consists of multiple users, each presented with a ranked list of items. Each position has a propensity to be seen, and only exposed items can be clicked. The goal is to derive and implement an exposure-aware estimate of ranking quality that corrects for non-uniform exposure, and to compare it with the naïve estimate that ignores exposure bias.\n\nStart from the following fundamental base definitions:\n\n- Discounted Cumulative Gain (DCG) evaluates a ranked list by summing position-discounted gains. For a user with list length $L$, a monotonic gain function $g(\\cdot)$, and a position discount $d(r)$, the quantity $\\mathrm{DCG}$ is a sum over positions $r \\in \\{1,\\dots,L\\}$. Use the canonical binary relevance gain $g(y_r) = y_r$ and the logarithmic discount $d(r) = 1/\\log_2(1 + r)$, where $\\log_2(\\cdot)$ denotes the logarithm base $2$.\n- Normalized Discounted Cumulative Gain (NDCG) at list length $L$ is $\\mathrm{DCG}$ divided by the ideal DCG, where the ideal DCG (denoted $\\mathrm{IDCG}$) is the DCG achieved by sorting the items in descending order of their true relevance labels $y_r \\in \\{0,1\\}$.\n\nIn offline collaborative filtering evaluation, observed clicks are affected by exposure. Let $e_r \\in \\{0,1\\}$ indicate whether position $r$ was exposed and let $c_r \\in \\{0,1\\}$ be the observed click. Assume clicks follow the deterministic relation $c_r = e_r \\cdot y_r$ (no additional noise). Let $\\hat{\\pi}_r \\in (0,1]$ be the estimated propensity of exposure at position $r$. Under non-uniform exposure, use the general inverse propensity scoring principle: for any sum over exposed instances, weighting by $1/\\hat{\\pi}_r$ yields an unbiased estimator of the corresponding expectation under the target policy when exposures are independent and correctly modeled.\n\nYour tasks:\n\n1. Derive the exposure-aware estimator for the position-discounted gain sum using inverse propensity weights $1/\\hat{\\pi}_r$, and then normalize by the ideal DCG to obtain the inverse propensity scoring Normalized Discounted Cumulative Gain (IPS-NDCG). Also define the naïve NDCG that ignores exposure bias by using the observed clicks directly without propensity weights.\n2. Implement both metrics at the user level and aggregate across users by averaging the per-user NDCG values to produce a single score per test case for each method.\n3. For each test case, compute the difference between the IPS-NDCG and the naïve NDCG (IPS minus naïve). Your program should output these differences as floating-point numbers.\n\nTest suite specification:\n\n- Use the following four test cases. In each case, lists are already in the ranking order, so positions $r = 1,2,\\dots$ follow the given arrays. For each user, you are provided the arrays of true relevance $y$, exposure propensity $\\hat{\\pi}$, and realized exposure $e$. Observed clicks are defined by $c_r = e_r \\cdot y_r$. All numbers must be treated exactly as given.\n\n- Test Case $1$ (single user, list length $5$):\n  - True relevance $y$: $[0,1,1,1,1]$\n  - Propensities $\\hat{\\pi}$: $[0.95,0.8,0.5,0.2,0.05]$\n  - Exposure $e$: $[1,1,1,0,0]$\n\n- Test Case $2$ (two users, each list length $4$):\n  - User A:\n    - True relevance $y^{(A)}$: $[1,0,1,0]$\n    - Propensities $\\hat{\\pi}^{(A)}$: $[0.9,0.7,0.4,0.2]$\n    - Exposure $e^{(A)}$: $[1,1,0,0]$\n  - User B:\n    - True relevance $y^{(B)}$: $[0,1,1,1]$\n    - Propensities $\\hat{\\pi}^{(B)}$: $[0.95,0.6,0.3,0.1]$\n    - Exposure $e^{(B)}$: $[1,1,1,0]$\n\n- Test Case $3$ (single user, list length $4$; edge case with no clicks observed):\n  - True relevance $y$: $[0,0,0,1]$\n  - Propensities $\\hat{\\pi}$: $[0.9,0.7,0.5,0.01]$\n  - Exposure $e$: $[1,1,1,0]$\n\n- Test Case $4$ (single user, list length $5$; strong position bias at deep positions):\n  - True relevance $y$: $[0,0,1,0,1]$\n  - Propensities $\\hat{\\pi}$: $[0.98,0.9,0.4,0.2,0.02]$\n  - Exposure $e$: $[1,1,1,0,1]$\n\nFinal output format specification:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one test case and is the float difference $\\Delta = \\mathrm{IPS}\\text{-}\\mathrm{NDCG} - \\mathrm{naïve}\\text{-}\\mathrm{NDCG}$ averaged across users in that test case when applicable. For example, an output with four test cases must look like $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4]$.", "solution": "The problem requires the derivation and implementation of two ranking evaluation metrics, a naïve Normalized Discounted Cumulative Gain (NDCG) and an exposure-aware version using Inverse Propensity Scoring (IPS-NDCG), to assess the quality of ranked recommendations under position-dependent exposure bias.\n\n### Step 1: Formal Derivations of Ranking Metrics\n\nWe are given the fundamental definitions for Discounted Cumulative Gain (DCG) and its normalized version, NDCG. Let a ranked list for a user have length $L$. The position in the list is denoted by $r \\in \\{1, 2, \\dots, L\\}$.\n\nThe gain function is the binary relevance $g(y_r) = y_r$, where $y_r \\in \\{0, 1\\}$ is the true relevance of the item at position $r$.\nThe position discount function is $d(r) = 1/\\log_2(1+r)$, where $\\log_2$ is the logarithm to the base $2$.\n\nIn the offline evaluation setting, we do not directly observe $y_r$. Instead, we observe clicks $c_r \\in \\{0, 1\\}$, which depend on both relevance $y_r$ and whether the position was exposed, indicated by $e_r \\in \\{0, 1\\}$. The clicks are deterministically modeled as $c_r = e_r \\cdot y_r$. The estimated probability of exposure at position $r$ is given by the propensity score $\\hat{\\pi}_r \\in (0, 1]$.\n\n**Ideal Discounted Cumulative Gain (IDCG)**\n\nBoth naïve and IPS-NDCG are normalized by the same quantity, the Ideal Discounted Cumulative Gain (IDCG). IDCG represents the maximum possible DCG for the set of items presented to the user. It is calculated by arranging the items in descending order of their true relevance $y_r$, and then computing the DCG for this ideal ranking. Let $y^{\\text{ideal}}$ be the vector of true relevance labels $y$ sorted in descending order.\n\n$$\n\\mathrm{IDCG} = \\sum_{r=1}^{L} d(r) \\cdot y^{\\text{ideal}}_r = \\sum_{r=1}^{L} \\frac{y^{\\text{ideal}}_r}{\\log_2(1+r)}\n$$\n\nIf all items have zero relevance (i.e., $\\sum y_r = 0$), then $\\mathrm{IDCG} = 0$. In this case, any NDCG is conventionally defined to be $0$.\n\n**Naïve NDCG**\n\nThe naïve approach ignores exposure bias and treats observed clicks $c_r$ as if they were the true relevance labels.\n\nThe naïve Discounted Cumulative Gain, $\\mathrm{DCG}_{\\text{naïve}}$, is the sum of discounted observed clicks:\n$$\n\\mathrm{DCG}_{\\text{naïve}} = \\sum_{r=1}^{L} d(r) \\cdot c_r = \\sum_{r=1}^{L} \\frac{c_r}{\\log_2(1+r)}\n$$\nThe naïve Normalized Discounted Cumulative Gain, $\\mathrm{NDCG}_{\\text{naïve}}$, is this value normalized by the IDCG:\n$$\n\\mathrm{NDCG}_{\\text{naïve}} = \\frac{\\mathrm{DCG}_{\\text{naïve}}}{\\mathrm{IDCG}}\n$$\n\n**Inverse Propensity Scoring NDCG (IPS-NDCG)**\n\nTo correct for exposure bias, we use the principle of Inverse Propensity Scoring (IPS). The goal is to obtain an unbiased estimate of the true DCG, which would be $\\sum_{r=1}^{L} d(r) y_r$. This sum can be estimated by up-weighting the gains from observed interactions by the inverse of their observation (exposure) propensity.\n\nThe IPS-based estimator for the gain at position $r$ is $\\frac{e_r y_r}{\\hat{\\pi}_r} = \\frac{c_r}{\\hat{\\pi}_r}$. This estimator is unbiased for the true gain $y_r$ if the propensity model is correct (i.e., $\\hat{\\pi}_r$ is the true probability of exposure $P(e_r=1)$).\n\nThe IPS-based Discounted Cumulative Gain, $\\mathrm{DCG}_{\\text{IPS}}$, is the sum of these propensity-weighted discounted gains:\n$$\n\\mathrm{DCG}_{\\text{IPS}} = \\sum_{r=1}^{L} d(r) \\cdot \\frac{c_r}{\\hat{\\pi}_r} = \\sum_{r=1}^{L} \\frac{c_r}{\\hat{\\pi}_r \\log_2(1+r)}\n$$\nThe IPS Normalized Discounted Cumulative Gain, $\\mathrm{NDCG}_{\\text{IPS}}$, is then:\n$$\n\\mathrm{NDCG}_{\\text{IPS}} = \\frac{\\mathrm{DCG}_{\\text{IPS}}}{\\mathrm{IDCG}}\n$$\n\n### Step 2: Aggregation and Final Calculation\n\nFor test cases involving multiple users, the metrics are computed for each user individually and then averaged. Let $N$ be the number of users in a test case. The final reported scores are:\n$$\n\\overline{\\mathrm{NDCG}}_{\\text{naïve}} = \\frac{1}{N} \\sum_{u=1}^{N} \\mathrm{NDCG}_{\\text{naïve}}^{(u)}\n$$\n$$\n\\overline{\\mathrm{NDCG}}_{\\text{IPS}} = \\frac{1}{N} \\sum_{u=1}^{N} \\mathrm{NDCG}_{\\text{IPS}}^{(u)}\n$$\nThe required output for each test case is the difference $\\Delta$:\n$$\n\\Delta = \\overline{\\mathrm{NDCG}}_{\\text{IPS}} - \\overline{\\mathrm{NDCG}}_{\\text{naïve}}\n$$\nThis procedure will be applied to each of the four specified test cases. The implementation will use numerical arrays to represent the vectors $y$, $c$, $e$, and $\\hat{\\pi}$, and perform vectorized calculations for efficiency.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of evaluating ranked recommendations under position-dependent exposure bias.\n    Computes the difference between IPS-NDCG and naïve-NDCG for a suite of test cases.\n    \"\"\"\n\n    def calculate_ndcgs(y: np.ndarray, pi: np.ndarray, e: np.ndarray):\n        \"\"\"\n        Calculates naïve NDCG and IPS-NDCG for a single user's ranked list.\n\n        Args:\n            y (np.ndarray): Array of true relevance labels (0 or 1).\n            pi (np.ndarray): Array of estimated exposure propensities.\n            e (np.ndarray): Array of realized exposures (0 or 1).\n\n        Returns:\n            tuple[float, float]: A tuple containing (naïve_ndcg, ips_ndcg).\n        \"\"\"\n        L = len(y)\n        if L == 0:\n            return 0.0, 0.0\n\n        # Calculate observed clicks\n        c = e * y\n\n        # Calculate position discounts: d(r) = 1 / log2(r + 1)\n        # For positions r=1,...,L, we need log2(2),...,log2(L+1)\n        ranks = np.arange(1, L + 1)\n        discounts = 1.0 / np.log2(ranks + 1)\n\n        # Calculate naive DCG\n        dcg_naive = np.sum(c * discounts)\n\n        # Calculate IPS-based DCG\n        # Add a small epsilon to pi to avoid division by zero, although problem states pi > 0\n        dcg_ips = np.sum((c / pi) * discounts)\n\n        # Calculate Ideal DCG (IDCG)\n        y_ideal = np.sort(y)[::-1]\n        idcg = np.sum(y_ideal * discounts)\n\n        if idcg == 0:\n            # If there are no relevant items, NDCG is 0\n            return 0.0, 0.0\n\n        ndcg_naive = dcg_naive / idcg\n        ndcg_ips = dcg_ips / idcg\n\n        return ndcg_naive, ndcg_ips\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1 (single user)\n        [\n            {\n                \"y\": np.array([0, 1, 1, 1, 1]),\n                \"pi\": np.array([0.95, 0.8, 0.5, 0.2, 0.05]),\n                \"e\": np.array([1, 1, 1, 0, 0]),\n            }\n        ],\n        # Test Case 2 (two users)\n        [\n            { # User A\n                \"y\": np.array([1, 0, 1, 0]),\n                \"pi\": np.array([0.9, 0.7, 0.4, 0.2]),\n                \"e\": np.array([1, 1, 0, 0]),\n            },\n            { # User B\n                \"y\": np.array([0, 1, 1, 1]),\n                \"pi\": np.array([0.95, 0.6, 0.3, 0.1]),\n                \"e\": np.array([1, 1, 1, 0]),\n            }\n        ],\n        # Test Case 3 (single user, no clicks)\n        [\n            {\n                \"y\": np.array([0, 0, 0, 1]),\n                \"pi\": np.array([0.9, 0.7, 0.5, 0.01]),\n                \"e\": np.array([1, 1, 1, 0]),\n            }\n        ],\n        # Test Case 4 (single user, strong bias)\n        [\n            {\n                \"y\": np.array([0, 0, 1, 0, 1]),\n                \"pi\": np.array([0.98, 0.9, 0.4, 0.2, 0.02]),\n                \"e\": np.array([1, 1, 1, 0, 1]),\n            }\n        ],\n    ]\n\n    results = []\n    for case_data in test_cases:\n        num_users = len(case_data)\n        total_naive_ndcg = 0.0\n        total_ips_ndcg = 0.0\n\n        for user_data in case_data:\n            naive_ndcg, ips_ndcg = calculate_ndcgs(\n                user_data[\"y\"], user_data[\"pi\"], user_data[\"e\"]\n            )\n            total_naive_ndcg += naive_ndcg\n            total_ips_ndcg += ips_ndcg\n        \n        avg_naive_ndcg = total_naive_ndcg / num_users\n        avg_ips_ndcg = total_ips_ndcg / num_users\n        \n        difference = avg_ips_ndcg - avg_naive_ndcg\n        results.append(difference)\n\n    # Format the final output string as [res1,res2,res3,res4]\n    print(f\"[{','.join(f'{r:.7f}' for r in results)}]\")\n\nsolve()\n```", "id": "3110057"}]}