{"hands_on_practices": [{"introduction": "The heart of the Metropolis-Hastings algorithm is the probabilistic decision to accept or reject a proposed new state. This hands-on calculation [@problem_id:1932824] grounds your understanding in this core mechanism. By working through a scenario with a symmetric random-walk proposal, you will compute the acceptance probability, which simplifies to a ratio of the target posterior densities, providing a foundational grasp of how the chain preferentially moves towards regions of higher probability.", "problem": "A statistician is using a Markov Chain Monte Carlo (MCMC) method to sample from the posterior distribution of a parameter $\\lambda$. The posterior distribution is known to follow an exponential distribution with a rate parameter $\\beta_0$, given by the probability density function $\\pi(\\lambda) = \\beta_0 \\exp(-\\beta_0 \\lambda)$ for $\\lambda  0$, and $\\pi(\\lambda)=0$ for $\\lambda \\le 0$.\n\nFor the MCMC simulation, a random-walk Metropolis-Hastings algorithm is employed. The proposal for a new state $\\lambda_p$ given the current state $\\lambda_c$ is drawn from a normal distribution with a mean equal to the current state and a standard deviation $\\sigma$. That is, the proposal distribution is $q(\\lambda_p | \\lambda_c)$ corresponding to a normal distribution $\\mathcal{N}(\\lambda_c, \\sigma^2)$.\n\nSuppose the rate parameter of the posterior is $\\beta_0 = 0.5$ and the standard deviation of the proposal distribution is $\\sigma = 1.0$. At a certain step in the chain, the current state is $\\lambda_c = 2.4$. The algorithm then proposes a new state $\\lambda_p = 3.1$. Both the current and proposed states are in the valid domain ($\\lambda  0$).\n\nCalculate the acceptance probability for this proposed move. Round your final answer to three significant figures.", "solution": "In the Metropolis-Hastings algorithm, the acceptance probability for a proposed move from $\\lambda_{c}$ to $\\lambda_{p}$ is\n$$\n\\alpha = \\min\\left(1,\\;\\frac{\\pi(\\lambda_{p})\\,q(\\lambda_{c}\\mid \\lambda_{p})}{\\pi(\\lambda_{c})\\,q(\\lambda_{p}\\mid \\lambda_{c})}\\right).\n$$\nWith a random-walk normal proposal $q(\\lambda_{p}\\mid \\lambda_{c})$ given by $\\mathcal{N}(\\lambda_{c},\\sigma^{2})$, the proposal is symmetric, so\n$$\nq(\\lambda_{c}\\mid \\lambda_{p})=q(\\lambda_{p}\\mid \\lambda_{c}),\n$$\nand therefore the proposal ratio equals $1$. Thus,\n$$\n\\alpha=\\min\\left(1,\\;\\frac{\\pi(\\lambda_{p})}{\\pi(\\lambda_{c})}\\right).\n$$\nThe target density is exponential with rate $\\beta_{0}$:\n$$\n\\pi(\\lambda)=\\beta_{0}\\exp(-\\beta_{0}\\lambda)\\quad\\text{for}\\ \\lambda0,\\quad \\pi(\\lambda)=0\\ \\text{otherwise}.\n$$\nSince both $\\lambda_{c}$ and $\\lambda_{p}$ are positive, we have\n$$\n\\frac{\\pi(\\lambda_{p})}{\\pi(\\lambda_{c})}\n=\\frac{\\beta_{0}\\exp(-\\beta_{0}\\lambda_{p})}{\\beta_{0}\\exp(-\\beta_{0}\\lambda_{c})}\n=\\exp\\!\\big(-\\beta_{0}(\\lambda_{p}-\\lambda_{c})\\big).\n$$\nSubstituting the given values $\\beta_{0}=0.5$, $\\lambda_{c}=2.4$, and $\\lambda_{p}=3.1$,\n$$\n\\alpha=\\min\\left(1,\\;\\exp\\!\\big(-0.5\\cdot(3.1-2.4)\\big)\\right)\n=\\min\\left(1,\\;\\exp(-0.35)\\right)\n=\\exp(-0.35).\n$$\nNumerically, $\\exp(-0.35)\\approx 0.704688\\ldots$, which rounded to three significant figures is $0.705$.", "answer": "$$\\boxed{0.705}$$", "id": "1932824"}, {"introduction": "For an MCMC sampler to be reliable, its Markov chain must be capable of exploring the entire support of the target distribution, a property known as irreducibility. This coding practice [@problem_id:3160213] offers a compelling, tangible demonstration of what happens when this property fails. By implementing a sampler for a target distribution with a disconnected support, you will see firsthand how an improperly chosen local proposal can \"trap\" the chain, leading to an incorrect characterization of the posterior and highlighting the importance of sampler design.", "problem": "Consider the Metropolis-Hastings algorithm (MH), which constructs a Markov chain with a prescribed stationary distribution. Let the real-valued state space be the union of two disjoint closed intervals, with target probability density function $\\,\\pi(x)\\,$ supported on $$S = [0,1] \\cup [2,3],$$ and zero elsewhere. Define $$\\pi(x) = \\begin{cases} \\tfrac{1}{2},  x \\in [0,1] \\text{ or } x \\in [2,3], \\\\ 0,  \\text{otherwise,} \\end{cases}$$ which is a valid probability density because the total length of $S$ is $2$, and the density is $\\tfrac{1}{2}$ on each unit-length interval. Consider two types of proposals:\n\n- A symmetric local proposal $\\,q(x' \\mid x)\\,$ given by the uniform law on $$[x - \\delta,\\, x + \\delta],$$ where $\\,\\delta  0\\,$ is a fixed half-width. This proposal is symmetric in the sense that $\\,q(x' \\mid x) = q(x \\mid x')\\,$ whenever both are nonzero.\n- An independent proposal $\\,q(x' \\mid x) = q(x')\\,$ given by the uniform law on $$[0,3],$$ which does not depend on the current state $\\,x.$\n\nYou must analyze, implement, and empirically demonstrate the failure of ergodicity (specifically, the failure of $\\psi$-irreducibility) when the local proposal half-width $\\,\\delta\\,$ is too small to cross the gap between the intervals, and contrast it with parameterizations or proposal mechanisms that restore irreducibility.\n\nStart from fundamental bases: the definitions of a Markov chain, the concept of support of a probability measure, the detailed balance condition, and the definition of irreducibility. In particular, use the principle that the MH acceptance function must be derived from ensuring detailed balance with respect to the target density $\\,\\pi(x)\\,$ and that proposals landing in regions where $\\,\\pi(x') = 0\\,$ must be rejected.\n\nAlgorithmic requirements for your program:\n\n- Implement a function that simulates the MH chain for $\\,N\\,$ steps from an initial state $\\,x_0,$ using the specified proposal type and parameter(s). If $\\,\\pi(x_0) = 0,$ the implementation must detect the invalid initial state and return the integer $\\,1\\,$ as the test result for that case.\n- For valid starts, track whether the chain ever visits the right interval $$[2,3]$$ within the $\\,N\\,$ steps. The result for that case must be a boolean: $\\,\\text{True}\\,$ if the chain visits $[2,3]$ at least once, and $\\,\\text{False}\\,$ otherwise.\n- Use a fixed random seed for each test case to ensure reproducibility.\n- Use closed intervals for membership tests; specifically, use $\\,\\le\\,$ comparisons so that points exactly at $\\,0,\\,1,\\,2,\\,$ and $\\,3\\,$ are considered inside their respective intervals.\n\nTest suite and coverage:\n\nLet the gap length be $$g = 1,$$ i.e., the distance between the right endpoint of $[0,1]$ and the left endpoint of $[2,3]$ is $\\,g.$ The following five test cases must be implemented exactly as specified, to cover the happy path, boundary condition, and edge cases:\n\n1. Local symmetric proposal with $\\,\\delta = 0.49,$ initial state $\\,x_0 = 0.5,$ steps $\\,N = 20000,$ seed $\\,42.$ Expected behavior: the chain cannot cross the gap because $\\,\\delta  g.$\n2. Local symmetric proposal with $\\,\\delta = 1.5,$ initial state $\\,x_0 = 1.0,$ steps $\\,N = 20000,$ seed $\\,123.$ Expected behavior: the chain can cross the gap because $\\,\\delta > g.$\n3. Local symmetric proposal with $\\,\\delta = 1.0,$ initial state $\\,x_0 = 1.0,$ steps $\\,N = 20000,$ seed $\\,2023.$ Boundary behavior: the chain cannot cross the gap with nonzero probability because proposals from $\\,x \\in [0,1]\\,$ land in $$[x - 1,\\, x + 1] \\subset [0,2],$$ and the event $\\,x' = 2\\,$ has probability $\\,0.$\n4. Independent proposal $\\,q(x')\\,$ uniform on $[0,3],$ initial state $\\,x_0 = 0.5,$ steps $\\,N = 100,$ seed $\\,7.$ Expected behavior: the chain is irreducible because proposals have positive probability to land in $[2,3]$ from any state in $S.$\n5. Invalid initial state: local symmetric proposal with $\\,\\delta = 0.4,$ initial state $\\,x_0 = 1.5,$ steps $\\,N = 100,$ seed $\\,99.$ Required behavior: detect that $\\,\\pi(x_0) = 0\\,$ and return the integer $\\,1.$\n\nFinal output format:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the five test cases listed above. For the first four test cases, print booleans indicating whether the chain visited $[2,3]$ at least once; for the fifth test case, print the integer $\\,1.$ For example, the printed line must have the form $$[b_1, b_2, b_3, b_4, i_5],$$ where each $\\,b_k\\,$ is a boolean and $\\,i_5 = 1.$ No additional text should be printed.", "solution": "The problem is valid as it is scientifically sound, well-posed, and all necessary information is provided. It presents a canonical example of the failure of irreducibility in the Metropolis-Hastings algorithm, which is a fundamental concept in computational science and Markov chain Monte Carlo methods.\n\nThe Metropolis-Hastings (MH) algorithm is a method for generating a sequence of random samples from a probability distribution for which direct sampling is difficult. The sequence of samples constitutes a Markov chain, which is a stochastic process where the probability of transitioning to any particular state depends solely on the current state and not on the sequence of events that preceded it. The core idea of the MH algorithm is to construct a Markov chain whose stationary distribution is the desired target distribution, $\\pi(x)$. A key property required for a Markov chain to converge to its unique stationary distribution from any starting point within the support is ergodicity. Ergodicity implies that the chain is both irreducible and aperiodic. This analysis focuses on irreducibility.\n\nA Markov chain is said to be $\\pi$-irreducible if, for any state $x$ within the support of $\\pi(x)$, denoted $\\text{supp}(\\pi)$, and any set $A \\subseteq \\text{supp}(\\pi)$ with positive probability, $\\int_A \\pi(x) dx  0$, there is a non-zero probability of the chain moving from $x$ to the set $A$ in a finite number of steps. In this problem, the support of the target distribution is the set $S = [0,1] \\cup [2,3]$. For the chain to be irreducible, it must be possible to transition between the two disjoint intervals $[0,1]$ and $[2,3]$.\n\nThe MH algorithm constructs the transition kernel of the Markov chain to satisfy the detailed balance condition with respect to $\\pi(x)$. This condition is a sufficient, but not necessary, condition for $\\pi(x)$ to be the stationary distribution. Detailed balance is given by:\n$$\n\\pi(x) P(x' \\mid x) = \\pi(x') P(x \\mid x')\n$$\nwhere $P(x' \\mid x)$ is the probability density of transitioning from state $x$ to state $x'$. The MH algorithm defines this transition by a two-step process: proposal and acceptance. First, a candidate state $x'$ is proposed from a proposal distribution $q(x' \\mid x)$. Second, this proposal is accepted with a probability $\\alpha(x' \\mid x)$. The transition density is thus $P(x' \\mid x) = q(x' \\mid x) \\alpha(x' \\mid x)$ for $x' \\neq x$. Substituting this into the detailed balance equation gives:\n$$\n\\pi(x) q(x' \\mid x) \\alpha(x' \\mid x) = \\pi(x') q(x \\mid x') \\alpha(x \\mid x')\n$$\nThe MH acceptance probability is chosen to satisfy this relation:\n$$\n\\alpha(x' \\mid x) = \\min \\left( 1, \\frac{\\pi(x') q(x \\mid x')}{\\pi(x) q(x' \\mid x)} \\right)\n$$\nIf a proposed state $x'$ lies outside the support of $\\pi(x)$, then $\\pi(x')=0$, which leads to an acceptance probability of $\\alpha(x' \\mid x) = 0$. In such cases, the proposal is always rejected, and the chain remains at its current state, i.e., $x_{t+1} = x_t$.\n\nThe specified target distribution is $\\pi(x) = \\frac{1}{2}$ for $x \\in S = [0,1] \\cup [2,3]$ and $\\pi(x) = 0$ otherwise. A crucial simplification arises from this definition: for any two states $x, x' \\in S$, the ratio of the target densities is $\\frac{\\pi(x')}{\\pi(x)} = \\frac{1/2}{1/2} = 1$. The acceptance probability formula thus simplifies to:\n$$\n\\alpha(x' \\mid x) = \\min \\left( 1, \\frac{q(x \\mid x')}{q(x' \\mid x)} \\right)\n$$\nfor any proposed move from $x \\in S$ to $x' \\in S$.\n\nWe analyze the two proposal mechanisms:\n\n1.  **Local Symmetric Proposal**: The proposal distribution is $q(x' \\mid x)$ corresponding to a uniform distribution on $[x-\\delta, x+\\delta]$. The density is $q(x' \\mid x) = \\frac{1}{2\\delta}$ if $x' \\in [x-\\delta, x+\\delta]$ and $0$ otherwise. This is symmetric, meaning $q(x' \\mid x) = q(x \\mid x')$, because the condition $|x' - x| \\le \\delta$ is symmetric in $x$ and $x'$. Therefore, the ratio $\\frac{q(x \\mid x')}{q(x' \\mid x)} = 1$. The acceptance probability for any proposed move to a state $x' \\in S$ is $\\alpha(x' \\mid x) = \\min(1, 1) = 1$. So, if a proposal lands within the support $S$, it is always accepted. If it lands outside $S$, it is always rejected.\n    The irreducibility of the chain depends on whether the proposal distribution can bridge the gap $g=1$ between the intervals $[0,1]$ and $[2,3]$. A proposal from a state $x \\in [0,1]$ is generated from $[x-\\delta, x+\\delta]$. The highest possible value for a proposal originating in $[0,1]$ is from $x=1$, which gives a proposal interval of $[1-\\delta, 1+\\delta]$. For the chain to be able to jump from $[0,1]$ to $[2,3]$, this interval must have a non-zero overlap with $[2,3]$. This requires $1+\\delta \\ge 2$, or $\\delta \\ge 1$.\n    -   **Case 1 ($\\delta = 0.49  1$)**: The maximum reach from $x=1$ is $1.49$. It is impossible to propose a state in $[2,3]$. The chain is reducible, trapped in the interval it started in.\n    -   **Case 2 ($\\delta = 1.5  1$)**: From any $x \\in [0.5, 1]$, the proposal interval $[x-1.5, x+1.5]$ has a non-empty intersection with $[2,3]$. For example, from $x_0=1$, proposals can be up to $2.5$. Transitions are possible, and the chain is irreducible.\n    -   **Case 3 ($\\delta = 1.0$)**: The maximum reach from $x=1$ is exactly $2$. The proposal interval is $[0, 2]$. Since the proposal is drawn from a continuous uniform distribution, the probability of generating the exact value $x'=2$ is $0$. Therefore, the chain cannot cross into the interior of $[2,3]$ with non-zero probability. The chain is reducible.\n\n2.  **Independent Proposal**: The proposal distribution is $q(x' \\mid x) = q(x')$ uniform on $[0,3]$, so the density is $q(x') = \\frac{1}{3}$ for $x' \\in [0,3]$. Here, the proposal does not depend on the current state $x$. The ratio of proposal densities is $\\frac{q(x \\mid x')}{q(x' \\mid x)} = \\frac{q(x)}{q(x')} = \\frac{1/3}{1/3} = 1$ for any $x, x' \\in [0,3]$. Similar to the symmetric case, the acceptance probability for any move to $x' \\in S$ is $\\alpha(x' \\mid x) = 1$.\n    The irreducibility is guaranteed. From any state $x \\in S$, a new state $x'$ is proposed uniformly from $[0,3]$. The probability of this proposal falling into the right interval $[2,3]$ is $\\frac{3-2}{3-0} = \\frac{1}{3}  0$. Since such a proposal will be accepted, the chain can move between the two components of the support in a single step. The chain is irreducible.\n\nFinally, the problem requires identifying invalid initial states. If $x_0$ is such that $\\pi(x_0)=0$ (e.g., $x_0 = 1.5$ as in Case 5), the chain is not properly initialized on the support of the target distribution. The implementation must detect this.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Metropolis-Hastings problem by running five specified test cases.\n    \"\"\"\n\n    def pi(x: float) - float:\n        \"\"\"\n        Target probability density function pi(x).\n        Supported on S = [0,1] U [2,3].\n        \"\"\"\n        if (0.0 = x = 1.0) or (2.0 = x = 3.0):\n            return 0.5\n        return 0.0\n\n    def run_mh_simulation(\n        proposal_type: str,\n        delta: float | None,\n        x0: float,\n        N: int,\n        seed: int\n    ) - bool | int:\n        \"\"\"\n        Simulates the Metropolis-Hastings Markov chain for a given test case.\n\n        Args:\n            proposal_type: 'local' for symmetric or 'independent' for independent proposal.\n            delta: Half-width for the local proposal.\n            x0: Initial state.\n            N: Number of steps.\n            seed: Random seed for reproducibility.\n\n        Returns:\n            - Integer 1 if the initial state x0 is invalid (pi(x0) == 0).\n            - Boolean True if the chain visits the interval [2,3].\n            - Boolean False otherwise.\n        \"\"\"\n        # Step 1: Validate initial state\n        if pi(x0) == 0.0:\n            return 1\n\n        # Step 2: Initialize chain and tracking variables\n        rng = np.random.default_rng(seed)\n        current_x = x0\n        visited_right_interval = (2.0 = current_x = 3.0)\n\n        # Step 3: Run the MCMC simulation for N steps\n        for _ in range(N):\n            # Propose a new state x_prime\n            if proposal_type == 'local':\n                if delta is None:\n                    # This case should not happen based on problem description but is a safeguard\n                    raise ValueError(\"Delta must be provided for local proposal.\")\n                x_prime = rng.uniform(current_x - delta, current_x + delta)\n            elif proposal_type == 'independent':\n                x_prime = rng.uniform(0.0, 3.0)\n            else:\n                raise ValueError(f\"Unknown proposal type: {proposal_type}\")\n\n            # As derived in the solution, for this specific problem, the acceptance\n            # probability alpha is 1 for any proposal that lands in the support of pi,\n            # and 0 otherwise. This simplifies the accept/reject step.\n            if pi(x_prime)  0.0:\n                current_x = x_prime\n\n            # Track if the chain has ever visited the right interval [2, 3]\n            if not visited_right_interval and (2.0 = current_x = 3.0):\n                visited_right_interval = True\n        \n        return visited_right_interval\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1. Local proposal, delta  gap, should not cross\n        {'proposal_type': 'local', 'delta': 0.49, 'x0': 0.5, 'N': 20000, 'seed': 42},\n        # 2. Local proposal, delta  gap, should cross\n        {'proposal_type': 'local', 'delta': 1.5, 'x0': 1.0, 'N': 20000, 'seed': 123},\n        # 3. Local proposal, delta = gap, cannot cross (prob=0 event)\n        {'proposal_type': 'local', 'delta': 1.0, 'x0': 1.0, 'N': 20000, 'seed': 2023},\n        # 4. Independent proposal, should be irreducible and cross\n        {'proposal_type': 'independent', 'delta': None, 'x0': 0.5, 'N': 100, 'seed': 7},\n        # 5. Invalid initial state, should return 1\n        {'proposal_type': 'local', 'delta': 0.4, 'x0': 1.5, 'N': 100, 'seed': 99},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_mh_simulation(\n            proposal_type=case['proposal_type'],\n            delta=case['delta'],\n            x0=case['x0'],\n            N=case['N'],\n            seed=case['seed']\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3160213"}, {"introduction": "In practice, it is often more convenient to run the MCMC sampler on a transformed version of a parameter, for instance, by sampling the logarithm of a strictly positive parameter. This advanced practice [@problem_id:3148250] explores the mathematical rigor necessary to perform such transformations correctly. You will derive and implement the acceptance probability in both the original and transformed spaces, verifying that they are identical when the change of variables is handled properly, including the crucial Jacobian term, thereby ensuring the sampler converges to the correct target distribution.", "problem": "Consider the Metropolis-Hastings algorithm within Markov Chain Monte Carlo (MCMC), which constructs a Markov chain with stationary distribution equal to a desired target density. The Metropolis-Hastings acceptance probability is defined from first principles as follows. Given a target density $\\pi(x)$ on a state space and a proposal kernel $q(x' \\mid x)$, the acceptance probability for a proposed move from state $x$ to state $x'$ is\n$$\n\\alpha(x \\to x') = \\min\\left(1,\\; \\frac{\\pi(x')\\, q(x \\mid x')}{\\pi(x)\\, q(x' \\mid x)}\\right).\n$$\nSuppose we perform Metropolis-Hastings sampling on a transformed variable $u = g(x)$, where $g$ is a bijective, differentiable transformation with differentiable inverse $g^{-1}$ and nonzero Jacobian determinant. The target density must be properly transformed under change-of-variables to a density on the $u$-space, denoted $\\pi_u(u)$, using\n$$\n\\pi_u(u) = \\pi_x\\big(g^{-1}(u)\\big)\\,\\left|\\det J_{g^{-1}}(u)\\right|,\n$$\nwhere $J_{g^{-1}}(u)$ is the Jacobian matrix of $g^{-1}$ evaluated at $u$. If the proposal in $u$-space is $q_u(u' \\mid u)$, then the Metropolis-Hastings acceptance probability in $u$-space is\n$$\n\\alpha_u(u \\to u') = \\min\\left(1,\\; \\frac{\\pi_u(u')\\, q_u(u \\mid u')}{\\pi_u(u)\\, q_u(u' \\mid u)}\\right).\n$$\nBy mapping the proposal from $u$-space back to $x$-space via $x' = g^{-1}(u')$ and $x = g^{-1}(u)$, the implied proposal density $q_x(x' \\mid x)$ can be obtained through change-of-variables. In scientifically consistent implementations, the acceptance probability computed in $u$-space using the properly transformed target must agree with the acceptance probability computed in $x$-space using the original target and the induced proposal.\n\nYour task is to derive the acceptance probability expressions on the transformed variable $u$, identify the correct transformed target $\\pi_u(u)$ including the Jacobian factor, and implement a program that numerically verifies agreement between acceptance probabilities computed in $u$-space and $x$-space for a set of test cases. All mathematical quantities must be handled in dimensionless units.\n\nYou must consider the following transformations and targets:\n- Log transform $u = \\log x$ for $x  0$:\n  - Gamma target on $x$: $\\pi_x(x) \\propto x^{k - 1} \\exp\\left(-\\frac{x}{\\theta}\\right)$, with shape $k  0$ and scale $\\theta  0$.\n  - Exponential target on $x$: $\\pi_x(x) \\propto \\exp(-\\lambda x)$, with rate $\\lambda  0$.\n- Identity transform $u = x$ for $x \\in \\mathbb{R}$:\n  - Standard normal target on $x$: $\\pi_x(x) \\propto \\exp\\left(-\\frac{x^2}{2}\\right)$.\n\nFor proposals:\n- In $u$-space, use a Gaussian random walk proposal with standard deviation $\\sigma  0$: $q_u(u' \\mid u) = \\mathcal{N}(u'; u, \\sigma^2)$.\n- For the log transform case, the induced proposal in $x$-space is log-normal: $q_x(x' \\mid x) = \\text{LogNormal}(x'; \\log x, \\sigma)$.\n- For the identity transform case, the induced proposal in $x$-space is Gaussian: $q_x(x' \\mid x) = \\mathcal{N}(x'; x, \\sigma^2)$.\n\nImplement the following acceptance probability computations:\n- In $u$-space:\n  $$\n  \\alpha_u(u \\to u') = \\min\\left(1,\\; \\exp\\left[\\log \\pi_u(u') - \\log \\pi_u(u) + \\log q_u(u \\mid u') - \\log q_u(u' \\mid u)\\right]\\right).\n  $$\n- In $x$-space:\n  $$\n  \\alpha_x(x \\to x') = \\min\\left(1,\\; \\exp\\left[\\log \\pi_x(x') - \\log \\pi_x(x) + \\log q_x(x \\mid x') - \\log q_x(x' \\mid x)\\right]\\right).\n  $$\n\nUse the following test suite of parameter values to verify agreement between $\\alpha_u$ and $\\alpha_x$ in varied scenarios:\n1. Happy path, log transform with gamma target:\n   - $k = 2.3$, $\\theta = 1.1$, $u = 0.25$, $u' = 0.7$, $\\sigma = 0.5$.\n2. Boundary case near $x \\approx 0$, log transform with gamma target:\n   - $k = 2.3$, $\\theta = 1.1$, $u = -0.1$, $u' = -5.0$, $\\sigma = 0.5$.\n3. Baseline identity transform with standard normal target:\n   - $u = 1.0$, $u' = -1.7$, $\\sigma = 1.0$.\n4. Log transform with exponential target:\n   - $\\lambda = 1.7$, $u = 0.3$, $u' = -1.0$, $\\sigma = 0.7$.\n\nYour program must compute, for each test case, the absolute difference\n$$\n\\Delta = \\left|\\alpha_u - \\alpha_x\\right|\n$$\nas a floating-point number. The final output must be a single line containing a comma-separated list enclosed in square brackets with the four $\\Delta$ values in the order listed above (for example, $\\left[\\delta_1,\\delta_2,\\delta_3,\\delta_4\\right]$). No other text should be printed.", "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded, well-posed, objective, and internally consistent. It presents a standard, non-trivial problem in computational statistics concerning the invariance of the Metropolis-Hastings acceptance probability under a change of variables, provided all densities are transformed correctly.\n\nThe core task is to demonstrate that the Metropolis-Hastings acceptance probability remains the same whether computed in a transformed space ($u$-space) with a transformed target density, or in the original space ($x$-space) with the original target density and an induced proposal density. We must show $\\alpha_u = \\alpha_x$ for several test cases.\n\nThe acceptance probability for a move from state $s$ to $s'$ is given by\n$$ \\alpha(s \\to s') = \\min\\left(1, R\\right) \\quad \\text{where} \\quad R = \\frac{\\pi(s') q(s \\mid s')}{\\pi(s) q(s' \\mid s)} $$\nWorking with logarithms is numerically more stable:\n$$ \\alpha(s \\to s') = \\min\\left(1, \\exp\\left[\\log\\pi(s') - \\log\\pi(s) + \\log q(s \\mid s') - \\log q(s' \\mid s)\\right]\\right) $$\n\nLet's first establish the theoretical equivalence. Let the transformation be $u = g(x)$ with inverse $x = g^{-1}(u)$. The change of variables formula for a probability density function $\\pi_x(x)$ is\n$$ \\pi_u(u) = \\pi_x\\big(g^{-1}(u)\\big) \\left|\\det J_{g^{-1}}(u)\\right| $$\nwhere $J_{g^{-1}}(u)$ is the Jacobian of the inverse transformation.\n\nThe proposal density $q_u(u' \\mid u)$ in $u$-space induces a proposal density $q_x(x' \\mid x)$ in $x$-space, which is also related by a change of variables:\n$$ q_x(x' \\mid x) = q_u\\big(g(x') \\mid g(x)\\big) \\left|\\det J_g(x')\\right| $$\nwhere $J_g(x')$ is the Jacobian of the forward transformation $g$. By the inverse function theorem, $\\left|\\det J_g(x')\\right| = 1 / \\left|\\det J_{g^{-1}}(u')\\right|$, where $u'=g(x')$.\nThus,\n$$ q_x(x' \\mid x) = \\frac{q_u(u' \\mid u)}{\\left|\\det J_{g^{-1}}(u')\\right|} \\quad \\text{and similarly} \\quad q_x(x \\mid x') = \\frac{q_u(u \\mid u')}{\\left|\\det J_{g^{-1}}(u)\\right|} $$\n\nNow, let's write out the acceptance ratio $R_x$ in $x$-space and substitute these relationships:\n$$ R_x = \\frac{\\pi_x(x') q_x(x \\mid x')}{\\pi_x(x) q_x(x' \\mid x)} = \\frac{\\pi_x(x')}{\\pi_x(x)} \\frac{q_u(u \\mid u') / \\left|\\det J_{g^{-1}}(u)\\right|}{q_u(u' \\mid u) / \\left|\\det J_{g^{-1}}(u')\\right|} = \\frac{\\pi_x(x')}{\\pi_x(x)} \\frac{q_u(u \\mid u')}{q_u(u' \\mid u)} \\frac{\\left|\\det J_{g^{-1}}(u')\\right|}{\\left|\\det J_{g^{-1}}(u)\\right|} $$\nRearranging terms, we get:\n$$ R_x = \\left( \\frac{\\pi_x(x') \\left|\\det J_{g^{-1}}(u')\\right|}{\\pi_x(x) \\left|\\det J_{g^{-1}}(u)\\right|} \\right) \\left( \\frac{q_u(u \\mid u')}{q_u(u' \\mid u)} \\right) = \\frac{\\pi_u(u')}{\\pi_u(u)} \\frac{q_u(u \\mid u')}{q_u(u' \\mid u)} = R_u $$\nSince the ratios $R_x$ and $R_u$ are identical, their acceptance probabilities $\\alpha_x = \\min(1, R_x)$ and $\\alpha_u = \\min(1, R_u)$ must also be identical. The numerical implementation will verify this fundamental property.\n\nWe now derive the specific quantities for each case. The proposal in $u$-space is always a symmetric Gaussian random walk, $q_u(u' \\mid u) = \\mathcal{N}(u; u, \\sigma^2)$, which means $q_u(u' \\mid u) = q_u(u \\mid u')$. Therefore, the proposal ratio term $\\log q_u(u \\mid u') - \\log q_u(u' \\mid u) = 0$.\n\n**1. Log transform: $u = \\log x$ for $x  0$**\n- Inverse transform: $x = g^{-1}(u) = \\exp(u)$.\n- Jacobian (1D case): $J_{g^{-1}}(u) = \\frac{dx}{du} = \\exp(u)$.\n- Jacobian determinant: $|\\det J_{g^{-1}}(u)| = \\exp(u)$.\n- The induced proposal in $x$-space is from $x' = \\exp(u')$ where $u' \\sim \\mathcal{N}(u, \\sigma^2) = \\mathcal{N}(\\log x, \\sigma^2)$. This means $x'$ is log-normally distributed. The probability density function is $q_x(x' \\mid x) = \\frac{1}{x'\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\log x' - \\log x)^2}{2\\sigma^2}\\right)$. This proposal is not symmetric in $x$ and $x'$.\n- The log-ratio of the proposals in $x$-space is:\n  $$ \\log q_x(x \\mid x') - \\log q_x(x' \\mid x) = \\left(-\\log x - \\dots\\right) - \\left(-\\log x' - \\dots\\right) = \\log x' - \\log x = \\log(x'/x) $$\n\n**1(a). Gamma Target:** $\\pi_x(x) \\propto x^{k - 1} \\exp\\left(-\\frac{x}{\\theta}\\right)$\n- Log-target in $x$-space: $\\log\\pi_x(x) = (k - 1)\\log x - \\frac{x}{\\theta} + C_x$.\n- Transformed target in $u$-space:\n  $ \\pi_u(u) = \\pi_x(\\exp u) |\\exp u| \\propto (\\exp u)^{k-1} \\exp\\left(-\\frac{\\exp u}{\\theta}\\right) \\exp u = \\exp(ku - \\frac{\\exp u}{\\theta}) $\n- Log-target in $u$-space: $\\log \\pi_u(u) = ku - \\frac{\\exp u}{\\theta} + C_u$.\n\n**1(b). Exponential Target:** $\\pi_x(x) \\propto \\exp(-\\lambda x)$\n- Log-target in $x$-space: $\\log\\pi_x(x) = -\\lambda x + C_x$.\n- Transformed target in $u$-space:\n  $ \\pi_u(u) = \\pi_x(\\exp u) |\\exp u| \\propto \\exp(-\\lambda \\exp u) \\exp u $\n- Log-target in $u$-space: $\\log \\pi_u(u) = u - \\lambda \\exp u + C_u$.\n\n**2. Identity transform: $u = x$ for $x \\in \\mathbb{R}$**\n- Inverse transform: $x = g^{-1}(u) = u$.\n- Jacobian: $J_{g^{-1}}(u) = \\frac{dx}{du} = 1$.\n- Jacobian determinant: $|\\det J_{g^{-1}}(u)| = 1$.\n- The log-ratio of proposals in $x$-space is $0$ because the induced proposal $q_x(x'|x) = \\mathcal{N}(x; x, \\sigma^2)$ is symmetric.\n- The transformed target has the same form: $\\pi_u(u) = \\pi_x(u)$.\n\n**2(a). Standard Normal Target:** $\\pi_x(x) \\propto \\exp\\left(-\\frac{x^2}{2}\\right)$\n- Log-target in $x$-space: $\\log \\pi_x(x) = -\\frac{x^2}{2} + C_x$.\n- Log-target in $u$-space: $\\log \\pi_u(u) = -\\frac{u^2}{2} + C_u$.\n\nThe program will compute the difference $\\Delta = |\\alpha_u - \\alpha_x|$ for each test case by implementing these derived log-density functions and the full acceptance probability formula. Due to the proven theoretical equivalence, $\\Delta$ should be zero, subject to floating-point numerical precision.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and verifies the Metropolis-Hastings acceptance probability under a change of variables.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1. Happy path, log transform with gamma target\n        {'type': 'gamma_log', 'params': {'k': 2.3, 'theta': 1.1}, 'u': 0.25, 'u_prime': 0.7, 'sigma': 0.5},\n        # 2. Boundary case near x=0, log transform with gamma target\n        {'type': 'gamma_log', 'params': {'k': 2.3, 'theta': 1.1}, 'u': -0.1, 'u_prime': -5.0, 'sigma': 0.5},\n        # 3. Baseline identity transform with standard normal target\n        {'type': 'normal_identity', 'params': {}, 'u': 1.0, 'u_prime': -1.7, 'sigma': 1.0},\n        # 4. Log transform with exponential target\n        {'type': 'exp_log', 'params': {'lambda': 1.7}, 'u': 0.3, 'u_prime': -1.0, 'sigma': 0.7}\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        u = case['u']\n        u_prime = case['u_prime']\n        params = case['params']\n        \n        # --- U-Space Calculation ($\\alpha_u$) ---\n        \n        log_pi_u_val = 0.0\n        log_pi_u_prime_val = 0.0\n        \n        if case['type'] == 'gamma_log':\n            k, theta = params['k'], params['theta']\n            # log_pi_u(u) = k*u - exp(u)/theta\n            log_pi_u_val = k * u - np.exp(u) / theta\n            log_pi_u_prime_val = k * u_prime - np.exp(u_prime) / theta\n        elif case['type'] == 'exp_log':\n            lam = params['lambda']\n            # log_pi_u(u) = u - lambda*exp(u)\n            log_pi_u_val = u - lam * np.exp(u)\n            log_pi_u_prime_val = u_prime - lam * np.exp(u_prime)\n        elif case['type'] == 'normal_identity':\n            # log_pi_u(u) = -u^2 / 2\n            log_pi_u_val = -u**2 / 2.0\n            log_pi_u_prime_val = -u_prime**2 / 2.0\n            \n        # For a symmetric Gaussian proposal in u-space, the proposal ratio is 1, and its log is 0.\n        log_q_u_ratio = 0.0\n        \n        log_r_u = log_pi_u_prime_val - log_pi_u_val + log_q_u_ratio\n        alpha_u = min(1.0, np.exp(log_r_u))\n\n        # --- X-Space Calculation ($\\alpha_x$) ---\n        \n        log_pi_x_val = 0.0\n        log_pi_x_prime_val = 0.0\n        log_q_x_ratio = 0.0\n        \n        if 'log' in case['type']:\n            # Log transform: u = log(x) = x = exp(u)\n            x = np.exp(u)\n            x_prime = np.exp(u_prime)\n            # For a log-normal proposal, log q(x|x') - log q(x'|x) = log(x'/x)\n            log_q_x_ratio = np.log(x_prime / x)\n            \n            if 'gamma' in case['type']:\n                k, theta = params['k'], params['theta']\n                # log_pi_x(x) = (k - 1)*log(x) - x/theta\n                log_pi_x_val = (k - 1.0) * np.log(x) - x / theta\n                log_pi_x_prime_val = (k - 1.0) * np.log(x_prime) - x_prime / theta\n            elif 'exp' in case['type']:\n                lam = params['lambda']\n                # log_pi_x(x) = -lambda*x\n                log_pi_x_val = -lam * x\n                log_pi_x_prime_val = -lam * x_prime\n        \n        elif 'identity' in case['type']:\n            # Identity transform: u = x\n            x = u\n            x_prime = u_prime\n            # For a symmetric Gaussian proposal, the proposal ratio is 1, and its log is 0.\n            log_q_x_ratio = 0.0\n            \n            if 'normal' in case['type']:\n                # log_pi_x(x) = -x^2 / 2\n                log_pi_x_val = -x**2 / 2.0\n                log_pi_x_prime_val = -x_prime**2 / 2.0\n\n        log_r_x = log_pi_x_prime_val - log_pi_x_val + log_q_x_ratio\n        alpha_x = min(1.0, np.exp(log_r_x))\n        \n        # Calculate the absolute difference\n        delta = abs(alpha_u - alpha_x)\n        results.append(delta)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3148250"}]}