{"hands_on_practices": [{"introduction": "Understanding a model's coefficients is one thing, but seeing their practical impact is another. This first exercise challenges you to quantify the effect of a categorical predictor by simulating a 'what-if' scenario: what would the model predict if an observation belonged to a different category? By calculating this counterfactual effect, you will gain a concrete understanding of how main effects and interaction terms involving dummy variables translate into tangible changes in the model's output [@problem_id:3164642].", "problem": "You are given a linear regression model with qualitative predictors encoded using reference-cell (also called one-hot with intercept) dummy variables. Let the predicted outcome be denoted by $\\hat{y}(\\mathbf{x}, \\mathbf{z})$, where $\\mathbf{x} \\in \\mathbb{R}^p$ is a vector of quantitative features and $\\mathbf{z}$ is a vector of categorical levels, one level per categorical variable. For each categorical variable $c$ with level set $\\mathcal{L}_c$, a designated baseline level $\\text{baseline}_c \\in \\mathcal{L}_c$ is not explicitly encoded; only indicators for levels in $\\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}$ enter the model. Optionally, interactions between categorical levels and quantitative features may be included.\n\nFormally, the model has the form\n$$\n\\hat{y}(\\mathbf{x}, \\mathbf{z}) \\;=\\; \\beta_0 \\;+\\; \\sum_{j=1}^{p} \\beta_j x_j \\;+\\; \\sum_{c \\in \\mathcal{C}} \\sum_{l \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\gamma_{c,l}\\,\\mathbf{1}\\{z_c = l\\}\n\\;+\\; \\sum_{(c,j)\\in \\mathcal{I}} \\sum_{l \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\delta_{c,l,j}\\,\\mathbf{1}\\{z_c = l\\}\\,x_j,\n$$\nwhere $\\beta_0 \\in \\mathbb{R}$ is the intercept, $\\beta_j \\in \\mathbb{R}$ are coefficients for the quantitative features, $\\gamma_{c,l} \\in \\mathbb{R}$ are main-effect dummy coefficients for categorical variable $c$ at level $l$, and $\\delta_{c,l,j} \\in \\mathbb{R}$ are interaction coefficients between level $l$ of categorical variable $c$ and quantitative feature $x_j$. The set $\\mathcal{I}$ lists the categoricalâ€“quantitative interaction pairs present in the model.\n\nFor a given observation $(\\mathbf{x}, \\mathbf{z})$, consider a counterfactual in which a single categorical variable $c^\\star$ changes its level from $a$ to $b$, producing $\\mathbf{z}_{c^\\star \\leftarrow b}$. Define the raw category-switch effect as\n$$\n\\Delta_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z})\n\\;=\\;\n\\hat{y}(\\mathbf{x}, \\mathbf{z}_{c^\\star \\leftarrow b})\n-\n\\hat{y}(\\mathbf{x}, \\mathbf{z}),\n$$\nand the standardized effect size, given a positive scalar $\\sigma > 0$, as\n$$\nE^{\\mathrm{std}}_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z}) = \\frac{\\Delta_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z})}{\\sigma}.\n$$\n\nYour task is to write a program that, for each of the following test cases, computes $E^{\\mathrm{std}}_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z})$ according to the model specification supplied in the test case. All test cases use reference-cell coding with an intercept; the baseline level of each categorical variable is explicitly specified. If a categorical level equals its baseline, its main-effect contribution is $0$; likewise for interactions, absent or baseline levels contribute $0$.\n\nTest suite:\n\n- Test case $1$:\n  - Quantitative features: one feature named $x$ with coefficient $\\beta_x = 1.5$ and intercept $\\beta_0 = 2.0$.\n  - Categorical variables: one variable named color with levels $\\{\\text{red}, \\text{blue}, \\text{green}\\}$, baseline level red. Main-effect coefficients: $\\gamma_{\\text{color},\\text{blue}} = 0.8$, $\\gamma_{\\text{color},\\text{green}} = -0.5$. No interactions.\n  - Observation: $x = 3.0$, color $=$ red. Switch color to blue. Use $\\sigma = 0.4$.\n\n- Test case $2$:\n  - Quantitative features: one feature named $x$ with coefficient $\\beta_x = -1.0$ and intercept $\\beta_0 = 0.0$.\n  - Categorical variables: one variable named color with levels $\\{\\text{red}, \\text{blue}, \\text{green}\\}$, baseline level red. Main-effect coefficients: $\\gamma_{\\text{color},\\text{blue}} = 1.2$, $\\gamma_{\\text{color},\\text{green}} = -0.3$. No interactions.\n  - Observation: $x = -5.0$, color $=$ green. Switch color to green. Use $\\sigma = 1.0$.\n\n- Test case $3$:\n  - Quantitative features: one feature named $p$ with coefficient $\\beta_p = -2.0$ and intercept $\\beta_0 = 0.0$.\n  - Categorical variables:\n    - brand with levels $\\{\\text{A}, \\text{B}\\}$, baseline A; $\\gamma_{\\text{brand},\\text{B}} = 1.2$.\n    - season with levels $\\{\\text{winter}, \\text{spring}, \\text{summer}, \\text{autumn}\\}$, baseline winter; $\\gamma_{\\text{season},\\text{spring}} = 0.5$, $\\gamma_{\\text{season},\\text{summer}} = 1.0$, $\\gamma_{\\text{season},\\text{autumn}} = 0.2$.\n    - No interactions.\n  - Observation: $p = 0.75$, brand $=$ B, season $=$ autumn. Switch season to summer. Use $\\sigma = 0.5$.\n\n- Test case $4$:\n  - Quantitative features: one feature named $n\\_users$ with coefficient $\\beta_{n\\_users} = 0.2$ and intercept $\\beta_0 = 0.0$.\n  - Categorical variables: one variable named tier with levels $\\{\\text{basic}, \\text{pro}, \\text{enterprise}\\}$, baseline basic. Main-effect coefficients: $\\gamma_{\\text{tier},\\text{pro}} = 0.3$, $\\gamma_{\\text{tier},\\text{enterprise}} = 1.0$.\n  - Interactions present: between tier and $n\\_users$, with $\\delta_{\\text{tier},\\text{pro},\\,n\\_users} = 0.1$, $\\delta_{\\text{tier},\\text{enterprise},\\,n\\_users} = 0.05$.\n  - Observation: $n\\_users = 10$, tier $=$ pro. Switch tier to enterprise. Use $\\sigma = 0.2$.\n\n- Test case $5$:\n  - Quantitative features: two features $x_1$ and $x_2$ with coefficients $\\beta_{x_1} = 1.0$, $\\beta_{x_2} = -0.5$, and intercept $\\beta_0 = 5.0$.\n  - Categorical variables:\n    - brand with levels $\\{\\text{A}, \\text{B}\\}$, baseline A; $\\gamma_{\\text{brand},\\text{B}} = -0.7$.\n    - region with levels $\\{\\text{north}, \\text{south}, \\text{east}\\}$, baseline north; $\\gamma_{\\text{region},\\text{south}} = 0.4$, $\\gamma_{\\text{region},\\text{east}} = -0.2$.\n    - No interactions.\n  - Observation: $x_1 = 4.0$, $x_2 = -2.0$, brand $=$ B, region $=$ south. Switch brand to A. Use $\\sigma = 0.7$.\n\nYour program must compute the standardized effect size $E^{\\mathrm{std}}_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z})$ for each test case and produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$). No physical units are involved. Angles are not involved. Percentages are not involved. The output entries must be real numbers (floating-point) in the order of the test cases $1$ through $5$.", "solution": "The problem asks for the computation of a standardized effect size, $E^{\\mathrm{std}}$, associated with a counterfactual change in a single categorical predictor within a linear regression model. The model incorporates quantitative features, qualitative (categorical) features, and their interactions.\n\nFirst, we must formalize the calculation of the raw category-switch effect, $\\Delta_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z})$. The model is given by:\n$$\n\\hat{y}(\\mathbf{x}, \\mathbf{z}) \\;=\\; \\beta_0 \\;+\\; \\sum_{j=1}^{p} \\beta_j x_j \\;+\\; \\sum_{c \\in \\mathcal{C}} \\sum_{l \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\gamma_{c,l}\\,\\mathbf{1}\\{z_c = l\\}\n\\;+\\; \\sum_{(c,j)\\in \\mathcal{I}} \\sum_{l \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\delta_{c,l,j}\\,\\mathbf{1}\\{z_c = l\\}\\,x_j\n$$\nThe effect is defined as the difference in predicted outcomes:\n$$\n\\Delta_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z}) \\;=\\; \\hat{y}(\\mathbf{x}, \\mathbf{z}_{c^\\star \\leftarrow b}) - \\hat{y}(\\mathbf{x}, \\mathbf{z})\n$$\nwhere $\\mathbf{z}_{c^\\star \\leftarrow b}$ is the feature vector identical to $\\mathbf{z}$ except that the categorical variable $c^\\star$ has its level changed from $a$ to $b$.\n\nWhen we compute this difference, all terms in the model expression for $\\hat{y}$ that do not depend on the level of $c^\\star$ will cancel out. This includes the intercept $\\beta_0$, the main effects of all quantitative predictors $\\sum_{j=1}^{p} \\beta_j x_j$, and the main and interaction effects of all other categorical variables $c \\in \\mathcal{C}$ where $c \\neq c^\\star$.\n\nThe only parts that do not cancel are those related to $c^\\star$. Let us define the total contribution of a level $l$ of a categorical variable $c$ to the prediction for a given quantitative feature vector $\\mathbf{x}$. Let's denote this contribution by $f(c, l, \\mathbf{x})$. From the model definition, this contribution is:\n$$\nf(c, l, \\mathbf{x}) = \\left( \\sum_{l' \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\gamma_{c,l'}\\,\\mathbf{1}\\{l = l'\\} \\right) + \\left( \\sum_{(c,j)\\in \\mathcal{I}} \\sum_{l' \\in \\mathcal{L}_c \\setminus \\{\\text{baseline}_c\\}} \\delta_{c,l',j}\\,\\mathbf{1}\\{l = l'\\}\\,x_j \\right)\n$$\nThis expression can be simplified. If level $l$ is the baseline level, $\\text{baseline}_c$, then all indicator functions $\\mathbf{1}\\{l=l'\\}$ are zero, and thus $f(c, \\text{baseline}_c, \\mathbf{x}) = 0$. If $l$ is not a baseline level, then the expression simplifies to:\n$$\nf(c, l, \\mathbf{x}) = \\gamma_{c,l} + \\sum_{j \\text{ s.t. } (c,j) \\in \\mathcal{I}} \\delta_{c,l,j}\\,x_j \\quad \\text{for } l \\neq \\text{baseline}_c\n$$\nWe can unify these cases by adopting the convention that coefficients for baseline levels are zero: $\\gamma_{c,\\text{baseline}_c} = 0$ and $\\delta_{c,\\text{baseline}_c,j} = 0$ for all $c, j$.\n\nThe raw effect $\\Delta_{c^\\star:a \\to b}$ is the difference between the contributions of the new level $b$ and the original level $a$:\n$$\n\\Delta_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z}) = f(c^\\star, b, \\mathbf{x}) - f(c^\\star, a, \\mathbf{x})\n$$\n$$\n\\Delta_{c^\\star:a \\to b} = \\left( \\gamma_{c^\\star,b} + \\sum_{j \\text{ s.t. } (c^\\star,j) \\in \\mathcal{I}} \\delta_{c^\\star,b,j}\\,x_j \\right) - \\left( \\gamma_{c^\\star,a} + \\sum_{j \\text{ s.t. } (c^\\star,j) \\in \\mathcal{I}} \\delta_{c^\\star,a,j}\\,x_j \\right)\n$$\nFinally, the standardized effect size is obtained by dividing by $\\sigma$:\n$$\nE^{\\mathrm{std}}_{c^\\star:a \\to b}(\\mathbf{x}, \\mathbf{z}) = \\frac{\\Delta_{c^\\star:a \\to b}}{\\sigma}\n$$\nWe now apply this framework to each test case.\n\nTest case 1:\n- Switch $c^\\star=\\text{color}$ from $a=\\text{red}$ to $b=\\text{blue}$.\n- The level $\\text{red}$ is the baseline, so $\\gamma_{\\text{color,red}}=0$. The coefficient for $\\text{blue}$ is $\\gamma_{\\text{color,blue}} = 0.8$.\n- There are no interactions, so all $\\delta$ coefficients are $0$.\n- $\\Delta_{\\text{color}:\\text{red} \\to \\text{blue}} = (\\gamma_{\\text{color,blue}}) - (\\gamma_{\\text{color,red}}) = 0.8 - 0 = 0.8$.\n- Given $\\sigma = 0.4$, the standardized effect is $E^{\\mathrm{std}} = 0.8 / 0.4 = 2.0$.\n\nTest case 2:\n- Switch $c^\\star=\\text{color}$ from $a=\\text{green}$ to $b=\\text{green}$.\n- Since the starting level is the same as the ending level, the change in prediction must be zero.\n- $\\Delta_{\\text{color}:\\text{green} \\to \\text{green}} = \\hat{y}(\\dots, \\text{color}=\\text{green}) - \\hat{y}(\\dots, \\text{color}=\\text{green}) = 0$.\n- With $\\sigma = 1.0$, the standardized effect is $E^{\\mathrm{std}} = 0 / 1.0 = 0.0$.\n\nTest case 3:\n- Switch $c^\\star=\\text{season}$ from $a=\\text{autumn}$ to $b=\\text{summer}$.\n- The variable `brand` does not change, so its contribution cancels. There are no interactions.\n- The baseline for `season` is `winter`. Neither `autumn` nor `summer` is the baseline.\n- Coefficients are $\\gamma_{\\text{season,autumn}} = 0.2$ and $\\gamma_{\\text{season,summer}} = 1.0$.\n- $\\Delta_{\\text{season}:\\text{autumn} \\to \\text{summer}} = \\gamma_{\\text{season,summer}} - \\gamma_{\\text{season,autumn}} = 1.0 - 0.2 = 0.8$.\n- With $\\sigma = 0.5$, the standardized effect is $E^{\\mathrm{std}} = 0.8 / 0.5 = 1.6$.\n\nTest case 4:\n- Switch $c^\\star=\\text{tier}$ from $a=\\text{pro}$ to $b=\\text{enterprise}$.\n- This case includes interactions between `tier` and $n\\_users$.\n- The observation is $n\\_users = 10$. The baseline for `tier` is `basic`.\n- The change involves two non-baseline levels, `pro` and `enterprise`.\n- $\\Delta_{\\text{tier}:\\text{pro} \\to \\text{enterprise}} = f(\\text{tier}, \\text{enterprise}, \\{n\\_users: 10\\}) - f(\\text{tier}, \\text{pro}, \\{n\\_users: 10\\})$.\n- $f(\\text{tier}, \\text{enterprise}, \\{n\\_users: 10\\}) = \\gamma_{\\text{tier,enterprise}} + \\delta_{\\text{tier,enterprise},n\\_users} \\times n\\_users = 1.0 + 0.05 \\times 10 = 1.5$.\n- $f(\\text{tier}, \\text{pro}, \\{n\\_users: 10\\}) = \\gamma_{\\text{tier,pro}} + \\delta_{\\text{tier,pro},n\\_users} \\times n\\_users = 0.3 + 0.1 \\times 10 = 1.3$.\n- $\\Delta = 1.5 - 1.3 = 0.2$.\n- With $\\sigma = 0.2$, the standardized effect is $E^{\\mathrm{std}} = 0.2 / 0.2 = 1.0$.\n\nTest case 5:\n- Switch $c^\\star=\\text{brand}$ from $a=\\text{B}$ to $b=\\text{A}$.\n- The level `A` is the baseline for `brand`, so its effective coefficient is $0$. The level `B` has coefficient $\\gamma_{\\text{brand,B}} = -0.7$.\n- There are no interactions. The state of other variables (`region`, $x_1$, $x_2$) is irrelevant as their contributions cancel.\n- $\\Delta_{\\text{brand}:\\text{B} \\to \\text{A}} = \\gamma_{\\text{brand,A}} - \\gamma_{\\text{brand,B}} = 0 - (-0.7) = 0.7$.\n- With $\\sigma = 0.7$, the standardized effect is $E^{\\mathrm{std}} = 0.7 / 0.7 = 1.0$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the standardized effect size for a counterfactual category switch\n    in a linear regression model for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1\n        {\n            \"c_star\": \"color\",\n            \"from_level\": \"red\",\n            \"to_level\": \"blue\",\n            \"x_vals\": {\"x\": 3.0},\n            \"coeffs\": {\n                \"gamma\": {\"color\": {\"blue\": 0.8, \"green\": -0.5}}\n            },\n            \"baselines\": {\"color\": \"red\"},\n            \"sigma\": 0.4\n        },\n        # Test case 2\n        {\n            \"c_star\": \"color\",\n            \"from_level\": \"green\",\n            \"to_level\": \"green\",\n            \"x_vals\": {\"x\": -5.0},\n            \"coeffs\": {\n                \"gamma\": {\"color\": {\"blue\": 1.2, \"green\": -0.3}}\n            },\n            \"baselines\": {\"color\": \"red\"},\n            \"sigma\": 1.0\n        },\n        # Test case 3\n        {\n            \"c_star\": \"season\",\n            \"from_level\": \"autumn\",\n            \"to_level\": \"summer\",\n            \"x_vals\": {\"p\": 0.75},\n            \"coeffs\": {\n                \"gamma\": {\n                    \"brand\": {\"B\": 1.2},\n                    \"season\": {\"spring\": 0.5, \"summer\": 1.0, \"autumn\": 0.2}\n                }\n            },\n            \"baselines\": {\"brand\": \"A\", \"season\": \"winter\"},\n            \"sigma\": 0.5\n        },\n        # Test case 4\n        {\n            \"c_star\": \"tier\",\n            \"from_level\": \"pro\",\n            \"to_level\": \"enterprise\",\n            \"x_vals\": {\"n_users\": 10},\n            \"coeffs\": {\n                \"gamma\": {\"tier\": {\"pro\": 0.3, \"enterprise\": 1.0}},\n                \"delta\": {\n                    \"tier\": {\n                        \"pro\": {\"n_users\": 0.1},\n                        \"enterprise\": {\"n_users\": 0.05}\n                    }\n                }\n            },\n            \"baselines\": {\"tier\": \"basic\"},\n            \"sigma\": 0.2\n        },\n        # Test case 5\n        {\n            \"c_star\": \"brand\",\n            \"from_level\": \"B\",\n            \"to_level\": \"A\",\n            \"x_vals\": {\"x1\": 4.0, \"x2\": -2.0},\n            \"coeffs\": {\n                \"gamma\": {\n                    \"brand\": {\"B\": -0.7},\n                    \"region\": {\"south\": 0.4, \"east\": -0.2}\n                }\n            },\n            \"baselines\": {\"brand\": \"A\", \"region\": \"north\"},\n            \"sigma\": 0.7\n        }\n    ]\n\n    def get_level_contribution(c_var, level, x_vals, coeffs, baselines):\n        \"\"\"\n        Calculates the total contribution of a specific categorical level to the\n        prediction, including main and interaction effects.\n        \"\"\"\n        if level == baselines[c_var]:\n            return 0.0\n\n        # Main effect (gamma coefficient)\n        gamma = coeffs.get(\"gamma\", {}).get(c_var, {}).get(level, 0.0)\n\n        # Sum of interaction effects (delta coefficients)\n        delta_sum = 0.0\n        # Check if interactions are defined for the variable and level\n        delta_coeffs_for_level = coeffs.get(\"delta\", {}).get(c_var, {}).get(level)\n        if delta_coeffs_for_level:\n            for x_var, x_val in x_vals.items():\n                if x_var in delta_coeffs_for_level:\n                    delta_sum += delta_coeffs_for_level[x_var] * x_val\n        \n        return gamma + delta_sum\n\n    results = []\n    for case in test_cases:\n        c_star = case[\"c_star\"]\n        from_level = case[\"from_level\"]\n        to_level = case[\"to_level\"]\n        x_vals = case[\"x_vals\"]\n        coeffs = case[\"coeffs\"]\n        baselines = case[\"baselines\"]\n        sigma = case[\"sigma\"]\n\n        # Calculate contribution from the original level\n        contrib_from = get_level_contribution(\n            c_star, from_level, x_vals, coeffs, baselines\n        )\n        \n        # Calculate contribution from the new (counterfactual) level\n        contrib_to = get_level_contribution(\n            c_star, to_level, x_vals, coeffs, baselines\n        )\n\n        # Raw effect is the difference in contributions\n        raw_effect = contrib_to - contrib_from\n        \n        # Standardized effect\n        std_effect = raw_effect / sigma\n        results.append(std_effect)\n\n    # Format the output as specified\n    formatted_results = [f\"{r:.16g}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3164642"}, {"introduction": "When comparing models, 'simpler is better' is a good rule of thumb, but what defines a model's complexity? This practice delves into the theoretical foundations of model selection, showing that complexity is measured by the number of free parameters, not just the number of predictors. You will derive an information criterion that correctly penalizes a model for each level of a qualitative predictor, a crucial skill for responsibly comparing models with complex categorical data [@problem_id:3164632].", "problem": "A data analyst is comparing candidate regression models in a statistical learning setting where multiple qualitative predictors appear with many levels. When qualitative predictors are coded using dummy variables with a single reference level, each qualitative predictor with $L$ observed levels contributes $L-1$ free coefficients to the linear predictor, whereas a quantitative predictor contributes one free slope coefficient, and the intercept contributes one free coefficient. Starting from the principle that model selection should minimize the expected Kullback-Leibler (KL) divergence between the true data-generating distribution and the candidate model distribution, and using the asymptotic justification that the training log-likelihood overestimates out-of-sample performance by an amount proportional to the number of free parameters, derive an information criterion that penalizes the total number of estimable level coefficients rather than merely the count of predictors. Then, apply your derived criterion to the following fitted model:\n- The maximized log-likelihood is $\\ln L(\\hat{\\theta}) = -920.35$.\n- There are $q = 4$ quantitative predictors.\n- There are three qualitative predictors with levels $L_{1} = 30$, $L_{2} = 7$, and $L_{3} = 4$.\nCompute the value of your level-penalized information criterion for this fitted model. Round your final answer to four significant figures.", "solution": "The task is to derive a model selection criterion based on minimizing the expected Kullback-Leibler (KL) divergence and then apply it to a given regression model. The core principle, as stated, is that the in-sample log-likelihood is an optimistic estimate of out-of-sample performance, with a bias approximately equal to the number of free parameters in the model.\n\n**Derivation of the Information Criterion**\n\nLet the true, unknown data-generating probability distribution be $f(x)$ and a candidate model's distribution be $g_{\\theta}(x)$. The Kullback-Leibler (KL) divergence from $g_{\\theta}$ to $f$ measures the information lost when approximating $f$ with $g_{\\theta}$:\n$$\nD_{\\text{KL}}(f || g_{\\theta}) = E_{f}[\\ln f(X)] - E_{f}[\\ln g_{\\theta}(X)]\n$$\nMinimizing this divergence is equivalent to maximizing the expected log-likelihood of the model, $E_{f}[\\ln g_{\\theta}(X)]$. Since this expectation is unknown, we use the maximized log-likelihood on the training data, $\\ln L(\\hat{\\theta})$, as an estimate.\n\nThe problem states that this estimate is biased. The expected out-of-sample log-likelihood is better approximated by correcting for this bias, which is proportional to the number of free parameters, $k$:\n$$\nE[\\text{expected log-likelihood}] \\approx \\ln L(\\hat{\\theta}) - k\n$$\nTo create an information criterion that is minimized, we follow convention and multiply by $-2$:\n$$\nIC = -2(\\ln L(\\hat{\\theta}) - k) = -2\\ln L(\\hat{\\theta}) + 2k\n$$\nThis is the Akaike Information Criterion (AIC). The key is to correctly calculate $k$.\n\n**Calculation of the Number of Free Parameters ($k$)**\n\nThe total number of free parameters, $k$, is the sum of all estimable coefficients in the model's linear predictor:\n- One intercept term: $1$ parameter.\n- $q = 4$ quantitative predictors: $4$ parameters.\n- Three qualitative predictors, which contribute $L-1$ parameters each:\n    - Predictor 1 ($L_1 = 30$): $30 - 1 = 29$ parameters.\n    - Predictor 2 ($L_2 = 7$): $7 - 1 = 6$ parameters.\n    - Predictor 3 ($L_3 = 4$): $4 - 1 = 3$ parameters.\n\nSumming these gives the total number of free parameters:\n$$\nk = 1 + 4 + (30 - 1) + (7 - 1) + (4 - 1) = 1 + 4 + 29 + 6 + 3 = 43\n$$\n\n**Application to the Fitted Model**\n\nUsing the derived formula with the given model data:\n- Maximized log-likelihood: $\\ln L(\\hat{\\theta}) = -920.35$\n- Number of parameters: $k = 43$\n\nThe value of the information criterion is:\n$$\nIC = -2(-920.35) + 2(43) = 1840.7 + 86 = 1926.7\n$$\nRounding to four significant figures, the result is $1927$.", "answer": "$$\n\\boxed{1927}\n$$", "id": "3164632"}, {"introduction": "Standard regression minimizes prediction error, but what if we have other goals, such as ensuring fairness across different groups? This advanced exercise demonstrates how you can extend the linear model framework by introducing a custom penalty term that encourages equitable predictions. By deriving and implementing a fairness-aware regularized regression, you will learn how to encode specific objectives into the model-fitting process itself, connecting statistical learning to real-world ethical considerations [@problem_id:3164666].", "problem": "Consider ordinary least squares regression with one continuous predictor and one qualitative predictor having three categories. Let there be $n$ observations indexed by $i \\in \\{1,\\dots,n\\}$, with response $y_i \\in \\mathbb{R}$, continuous predictor $x_i \\in \\mathbb{R}$, and category label $g_i \\in \\{A,B,C\\}$. Use baseline coding with $C$ as the baseline category, and define dummy variables $D_{A,i} \\in \\{0,1\\}$ and $D_{B,i} \\in \\{0,1\\}$ such that $D_{A,i} = 1$ if $g_i = A$ and $D_{B,i} = 1$ if $g_i = B$, and $D_{A,i} = D_{B,i} = 0$ if $g_i = C$. Consider the linear model\n$$\ny_i = \\beta_0 + \\beta_x x_i + \\beta_A D_{A,i} + \\beta_B D_{B,i} + \\varepsilon_i,\n$$\nwhere $\\varepsilon_i$ are mean-zero noise terms. Ordinary least squares minimizes the criterion\n$$\nJ_{\\mathrm{OLS}}(\\beta) = \\sum_{i=1}^{n} \\left(y_i - \\beta_0 - \\beta_x x_i - \\beta_A D_{A,i} - \\beta_B D_{B,i}\\right)^2.\n$$\nTo encourage fairness across categorical predictions, introduce a regularization that penalizes disparities between category-specific predictions at the reference input $x = 0$. The predicted value at $x = 0$ for category $k \\in \\{A,B,C\\}$ is $\\mu_k = \\beta_0 + \\beta_x \\cdot 0 + \\beta_k$, where $\\beta_C$ is implicitly $0$ under baseline coding. Define the fairness-aware penalized criterion\n$$\nJ_{\\lambda}(\\beta) = J_{\\mathrm{OLS}}(\\beta) + \\lambda \\sum_{(k,\\ell) \\in \\{A,B,C\\},\\,k<\\ell} \\left(\\mu_k - \\mu_{\\ell}\\right)^2,\n$$\nwith $\\lambda \\ge 0$. The fairness penalty thus penalizes pairwise differences among $\\beta_A$, $\\beta_B$, and $0$. Your task is to:\n- Derive, from first principles, the normal equations implied by minimizing $J_{\\lambda}(\\beta)$, expressing the penalty as a quadratic form in the dummy coefficients and connecting it to constrained optimization where category predictions are equalized.\n- Implement an algorithm that constructs the design matrix, assembles the augmented normal equations with the fairness penalty, and computes $\\hat{\\beta}$ by solving a linear system.\n- Also compute the constrained least squares solution corresponding to perfect fairness across categories at $x=0$, which in baseline coding implies $\\beta_A = 0$ and $\\beta_B = 0$, i.e., a model with only $\\beta_0$ and $\\beta_x$.\n- For each test case, compute and return:\n  1. The penalized estimator components $[\\hat{\\beta}_0,\\hat{\\beta}_x,\\hat{\\beta}_A,\\hat{\\beta}_B]$,\n  2. The fairness gap defined as $\\sum_{(k,\\ell),\\,k<\\ell} (\\hat{\\mu}_k - \\hat{\\mu}_{\\ell})^2$ with $\\hat{\\mu}_A = \\hat{\\beta}_0 + \\hat{\\beta}_A$, $\\hat{\\mu}_B = \\hat{\\beta}_0 + \\hat{\\beta}_B$, and $\\hat{\\mu}_C = \\hat{\\beta}_0$,\n  3. The constrained estimator components $[\\hat{\\beta}_0^{(c)},\\hat{\\beta}_x^{(c)}]$ obtained by ordinary least squares using only the intercept and $x$.\nUse no physical units. All outputs must be real numbers.\n\nUse the following test suite, which spans a general case, a boundary case with $\\lambda = 0$, a large-$\\lambda$ case, and an imbalance case with few samples for one category:\n\n- Test case $1$ (balanced categories, moderate fairness):\n  - $x = [0,1,2,3,4,5,6,7,8]$\n  - $g = [A,B,C,A,B,C,A,B,C]$\n  - $y = [2.0,1.0,2.0,3.5,2.5,3.5,5.0,4.0,5.0]$\n  - $\\lambda = 1.0$\n\n- Test case $2$ (no fairness penalty):\n  - $x = [0,1,2,3,4,5,6,7,8]$\n  - $g = [A,B,C,A,B,C,A,B,C]$\n  - $y = [2.0,1.0,2.0,3.5,2.5,3.5,5.0,4.0,5.0]$\n  - $\\lambda = 0.0$\n\n- Test case $3$ (strong fairness penalty):\n  - $x = [0,1,2,3,4,5,6,7,8]$\n  - $g = [A,B,C,A,B,C,A,B,C]$\n  - $y = [2.0,1.0,2.0,3.5,2.5,3.5,5.0,4.0,5.0]$\n  - $\\lambda = 1000000.0$\n\n- Test case $4$ (imbalanced categories, moderate fairness):\n  - $x = [0,2,4,1,3]$\n  - $g = [A,B,C,A,B]$\n  - $y = [2.0,1.5,3.0,2.5,2.0]$\n  - $\\lambda = 5.0$\n\nYour program should produce a single line of output containing the results as a comma-separated list of lists in the following order: for each test case, a list\n$$\n[\\hat{\\beta}_0,\\hat{\\beta}_x,\\hat{\\beta}_A,\\hat{\\beta}_B,\\text{fairness\\_gap},\\hat{\\beta}_0^{(c)},\\hat{\\beta}_x^{(c)}]\n$$\nand all four lists enclosed in a single outer list. For example, the output format is\n$$\n[[b_{0,1},b_{x,1},b_{A,1},b_{B,1},fg_1,b_{0,1}^{(c)},b_{x,1}^{(c)}],[b_{0,2},\\dots],\\dots,[b_{0,4},\\dots]].\n$$", "solution": "The problem requires finding the coefficient vector $\\beta = [\\beta_0, \\beta_x, \\beta_A, \\beta_B]^T$ that minimizes a penalized objective function $J_{\\lambda}(\\beta)$, which combines the standard ordinary least squares (OLS) loss with a fairness penalty. The derivation proceeds using matrix algebra.\n\nFirst, we express the linear model $y_i = \\beta_0 + \\beta_x x_i + \\beta_A D_{A,i} + \\beta_B D_{B,i} + \\varepsilon_i$ in matrix form as $y = X\\beta + \\varepsilon$. Here, $y$ is the $n \\times 1$ vector of responses, $X$ is the $n \\times 4$ design matrix with rows $[1, x_i, D_{A,i}, D_{B,i}]$, and $\\beta$ is the $4 \\times 1$ coefficient vector.\n\nThe OLS criterion is the sum of squared residuals, $J_{\\mathrm{OLS}}(\\beta) = (y - X\\beta)^T (y - X\\beta)$.\n\nNext, we formulate the fairness penalty. The predicted intercepts for categories A, B, and C (the baseline) are $\\mu_A = \\beta_0 + \\beta_A$, $\\mu_B = \\beta_0 + \\beta_B$, and $\\mu_C = \\beta_0$. The penalty term is the sum of squared pairwise differences:\n$$\n\\text{Penalty} = \\lambda \\left[ (\\mu_A - \\mu_B)^2 + (\\mu_A - \\mu_C)^2 + (\\mu_B - \\mu_C)^2 \\right]\n$$\nSubstituting the expressions for $\\mu_k$ yields:\n$$\n\\text{Penalty} = \\lambda \\left[ (\\beta_A - \\beta_B)^2 + \\beta_A^2 + \\beta_B^2 \\right] = \\lambda (2\\beta_A^2 + 2\\beta_B^2 - 2\\beta_A\\beta_B)\n$$\nThis penalty is a quadratic form in $\\beta$, which can be written as $\\lambda \\beta^T P \\beta$ using the penalty matrix $P$:\n$$\nP = \\begin{pmatrix}\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 2 & -1 \\\\\n0 & 0 & -1 & 2\n\\end{pmatrix}\n$$\nThe full objective function is $J_{\\lambda}(\\beta) = (y - X\\beta)^T (y - X\\beta) + \\lambda \\beta^T P \\beta$.\n\nTo find the minimum, we set the gradient with respect to $\\beta$ to zero:\n$$\n\\nabla_{\\beta} J_{\\lambda}(\\beta) = -2X^T y + 2X^T X \\beta + 2\\lambda P \\beta = 0\n$$\nThis gives the augmented normal equations:\n$$\n(X^T X + \\lambda P) \\hat{\\beta} = X^T y\n$$\nSolving this linear system yields the penalized estimator $\\hat{\\beta}$. As $\\lambda \\to \\infty$, this solution approaches the constrained least squares solution where $\\beta_A=0$ and $\\beta_B=0$.\n\nThe constrained solution corresponds to a simpler model $y_i = \\beta_0^{(c)} + \\beta_x^{(c)} x_i$, with a design matrix $X_c$ having rows $[1, x_i]$. Its coefficients $\\hat{\\beta}_c = [\\hat{\\beta}_0^{(c)}, \\hat{\\beta}_x^{(c)}]^T$ are found by solving the standard normal equations $(X_c^T X_c) \\hat{\\beta}_c = X_c^T y$.\n\nThe implementation involves:\n1.  Constructing the design matrices $X$ and $X_c$.\n2.  Constructing the penalty matrix $P$.\n3.  Solving the linear system $(X^T X + \\lambda P) \\hat{\\beta} = X^T y$ for the penalized coefficients $\\hat{\\beta}$.\n4.  Calculating the fairness gap: $(\\hat{\\beta}_A - \\hat{\\beta}_B)^2 + \\hat{\\beta}_A^2 + \\hat{\\beta}_B^2$.\n5.  Solving $(X_c^T X_c) \\hat{\\beta}_c = X_c^T y$ for the constrained coefficients $\\hat{\\beta}_c$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the regularized least squares problem for multiple test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (balanced categories, moderate fairness)\n        {\n            \"x\": np.array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=float),\n            \"g\": ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n            \"y\": np.array([2.0, 1.0, 2.0, 3.5, 2.5, 3.5, 5.0, 4.0, 5.0], dtype=float),\n            \"lambda_val\": 1.0\n        },\n        # Test case 2 (no fairness penalty)\n        {\n            \"x\": np.array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=float),\n            \"g\": ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n            \"y\": np.array([2.0, 1.0, 2.0, 3.5, 2.5, 3.5, 5.0, 4.0, 5.0], dtype=float),\n            \"lambda_val\": 0.0\n        },\n        # Test case 3 (strong fairness penalty)\n        {\n            \"x\": np.array([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype=float),\n            \"g\": ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n            \"y\": np.array([2.0, 1.0, 2.0, 3.5, 2.5, 3.5, 5.0, 4.0, 5.0], dtype=float),\n            \"lambda_val\": 1000000.0\n        },\n        # Test case 4 (imbalanced categories, moderate fairness)\n        {\n            \"x\": np.array([0, 2, 4, 1, 3], dtype=float),\n            \"g\": ['A', 'B', 'C', 'A', 'B'],\n            \"y\": np.array([2.0, 1.5, 3.0, 2.5, 2.0], dtype=float),\n            \"lambda_val\": 5.0\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        x, g, y, lambda_val = case[\"x\"], case[\"g\"], case[\"y\"], case[\"lambda_val\"]\n        n = len(y)\n\n        # 1. Construct the full design matrix X\n        X = np.zeros((n, 4))\n        X[:, 0] = 1  # Intercept\n        X[:, 1] = x  # Continuous predictor\n        for i in range(n):\n            if g[i] == 'A':\n                X[i, 2] = 1\n            elif g[i] == 'B':\n                X[i, 3] = 1\n\n        # 2. Construct the penalty matrix P\n        P = np.zeros((4, 4))\n        P[2, 2] = 2\n        P[3, 3] = 2\n        P[2, 3] = -1\n        P[3, 2] = -1\n\n        # 3. Solve for the penalized estimator beta_hat\n        XtX = X.T @ X\n        Xty = X.T @ y\n        A = XtX + lambda_val * P\n        beta_hat = np.linalg.solve(A, Xty)\n\n        # 4. Calculate the fairness gap\n        beta_A_hat, beta_B_hat = beta_hat[2], beta_hat[3]\n        fairness_gap = (beta_A_hat - beta_B_hat)**2 + beta_A_hat**2 + beta_B_hat**2\n\n        # 5. Construct the constrained design matrix Xc\n        Xc = np.zeros((n, 2))\n        Xc[:, 0] = 1  # Intercept\n        Xc[:, 1] = x  # Continuous predictor\n\n        # 6. Solve for the constrained estimator beta_c_hat\n        XctXc = Xc.T @ Xc\n        Xcty = Xc.T @ y\n        beta_c_hat = np.linalg.solve(XctXc, Xcty)\n\n        # 7. Assemble the results for the current test case\n        result = [\n            beta_hat[0], \n            beta_hat[1], \n            beta_hat[2], \n            beta_hat[3], \n            fairness_gap, \n            beta_c_hat[0], \n            beta_c_hat[1]\n        ]\n        all_results.append(result)\n\n    # Format the final output string\n    # E.g., [[val1, val2, ...], [val1, val2, ...]]\n    output_str = \"[\" + \",\".join([\"[\" + \",\".join(map(str, res)) + \"]\" for res in all_results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3164666"}]}