{"hands_on_practices": [{"introduction": "The raw form of a predictor is not always the most effective for modeling. By applying a non-linear transformation, we can often simplify the relationship between a predictor and the response, making it more suitable for linear models. This practice [@problem_id:3160298] guides you through applying the Box-Cox transformation, a systematic and powerful technique for finding a data-driven power transformation that can reduce predictor skewness and improve the fit of your model.", "problem": "You are given the task of programmatically investigating how nonlinear monotone transformations of a single positive predictor affect both its skewness and the quality of a linear model fit. You will use the Box–Cox family of transformations applied to the predictor (feature, input), and you will compare outcomes across a grid of transformation parameters.\n\nFundamental base for the task:\n- Define the Box–Cox transformation for positive inputs as follows. For any $x \\in \\mathbb{R}_{+}$ and parameter $\\lambda \\in \\mathbb{R}$, define\n$$\ng_{\\lambda}(x) = \n\\begin{cases}\n\\dfrac{x^{\\lambda}-1}{\\lambda} & \\text{if } \\lambda \\ne 0, \\\\\n\\log(x) & \\text{if } \\lambda = 0.\n\\end{cases}\n$$\n- The sample skewness $\\gamma_{1}(z)$ of a real-valued sample $z_{1},\\dots,z_{n}$ is defined by\n$$\n\\gamma_{1}(z) = \\frac{\\frac{1}{n}\\sum_{i=1}^{n}\\left(z_{i}-\\bar{z}\\right)^{3}}{\\left(\\frac{1}{n}\\sum_{i=1}^{n}\\left(z_{i}-\\bar{z}\\right)^{2}\\right)^{3/2}},\n\\quad \\bar{z}=\\frac{1}{n}\\sum_{i=1}^{n} z_{i}.\n$$\n- For a linear model with intercept,\n$$\ny_{i} = \\beta_{0} + \\beta_{1} z_{i} + \\varepsilon_{i}, \\quad \\varepsilon_{i} \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(0,\\sigma^{2}),\n$$\nthe ordinary least squares (OLS) fit yields residuals $r_{i}$ and residual sum of squares $\\text{RSS}=\\sum_{i=1}^{n} r_{i}^{2}$. Under the Gaussian error model with $\\hat{\\sigma}^{2}=\\text{RSS}/n$, the maximized log-likelihood is\n$$\n\\ell = -\\frac{n}{2}\\left(\\log\\left(2\\pi \\hat{\\sigma}^{2}\\right)+1\\right).\n$$\n\nYour program must do the following for each specified test case:\n1. Data generation. Generate a positive predictor $X_{i}$ and a response $Y_{i}$ by\n$$\nX_{i} \\sim \\text{LogNormal}(\\mu,\\sigma_{X}^{2}), \\quad \nY_{i} = \\beta_{0} + \\beta_{1}\\, g_{\\lambda^{\\star}}(X_{i}) + \\varepsilon_{i}, \\quad \\varepsilon_{i} \\sim \\mathcal{N}(0,\\sigma_{\\varepsilon}^{2}),\n$$\nfor $i=1,\\dots,n$, using the specified random seed for reproducibility. All random draws must be independent and identically distributed.\n\n2. Transformation grid. Consider the candidate set\n$$\n\\Lambda = \\left\\{-2.0,-1.0,-0.5,-0.25,0.0,0.25,0.5,1.0,2.0\\right\\}.\n$$\n\n3. Skewness equalization. For each $\\lambda \\in \\Lambda$, compute $Z_{i}^{(\\lambda)}=g_{\\lambda}(X_{i})$ and compute the absolute skewness $|\\gamma_{1}(Z^{(\\lambda)})|$. Let $\\hat{\\lambda}_{\\text{skew}}$ be any minimizer over $\\Lambda$. In the event of ties, choose the first minimizer encountered when $\\Lambda$ is scanned in ascending order.\n\n4. Model-fit optimization. For each $\\lambda \\in \\Lambda$, fit the OLS model $Y_{i}=\\beta_{0}^{(\\lambda)}+\\beta_{1}^{(\\lambda)} Z_{i}^{(\\lambda)}+\\varepsilon_{i}^{(\\lambda)}$ with intercept, compute the residual sum of squares $\\text{RSS}(\\lambda)$ and the corresponding maximized log-likelihood\n$$\n\\ell(\\lambda) = -\\frac{n}{2}\\left(\\log\\left(2\\pi \\cdot \\frac{\\text{RSS}(\\lambda)}{n}\\right) + 1\\right).\n$$\nLet $\\hat{\\lambda}_{\\text{fit}}$ be any maximizer of $\\ell(\\lambda)$ over $\\Lambda$. In the event of ties, choose the first maximizer encountered when $\\Lambda$ is scanned in ascending order.\n\n5. Improvement over identity. Define the identity transformation by $\\lambda=1.0$. Let $\\Delta_{\\text{skew}} = \\ell(\\hat{\\lambda}_{\\text{skew}}) - \\ell(1.0)$. Define a boolean improvement indicator $I$ that is true if and only if $\\Delta_{\\text{skew}} > 0$.\n\n6. Output per test case. For each test case, output the list $[\\hat{\\lambda}_{\\text{skew}}, \\hat{\\lambda}_{\\text{fit}}, I, \\Delta_{\\text{skew}}]$, where the two $\\lambda$ values and $\\Delta_{\\text{skew}}$ must be rounded to four decimal places. The boolean $I$ must be either true or false.\n\nTest suite:\nUse the following four test cases. For each case, use the specified parameters $(\\text{seed},n,\\mu,\\sigma_{X},\\beta_{0},\\beta_{1},\\lambda^{\\star},\\sigma_{\\varepsilon})$:\n- Case $1$: $(0,\\,400,\\,0.0,\\,1.0,\\,1.0,\\,2.0,\\,0.0,\\,1.0)$.\n- Case $2$: $(1,\\,400,\\,0.0,\\,0.25,\\,-0.5,\\,1.5,\\,1.0,\\,1.0)$.\n- Case $3$: $(2,\\,400,\\,0.0,\\,1.25,\\,0.0,\\,1.0,\\,0.5,\\,1.5)$.\n- Case $4$: $(3,\\,400,\\,0.5,\\,1.0,\\,0.5,\\,1.0,\\,-0.5,\\,1.0)$.\n\nAngle units are not involved. There are no physical units in this problem.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list of the four per-case results, each itself a list in the form $[\\hat{\\lambda}_{\\text{skew}},\\hat{\\lambda}_{\\text{fit}},I,\\Delta_{\\text{skew}}]$, and the outer list enclosed in square brackets. For example, an output with two cases would look like\n$[[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot]]$.\nAll three real-valued entries within each inner list must be rounded to four decimal places in the textual output.", "solution": "The user wants to investigate the effects of Box-Cox transformations on a predictor variable. I will first validate the problem statement.\n\n### Step 1: Extract Givens\n\n- **Box–Cox Transformation**: For a positive input $x \\in \\mathbb{R}_{+}$ and a parameter $\\lambda \\in \\mathbb{R}$, the transformation is defined as:\n$$\ng_{\\lambda}(x) = \n\\begin{cases}\n\\dfrac{x^{\\lambda}-1}{\\lambda} & \\text{if } \\lambda \\ne 0, \\\\\n\\log(x) & \\text{if } \\lambda = 0.\n\\end{cases}\n$$\n\n- **Sample Skewness**: For a sample $z = \\{z_{1}, \\dots, z_{n}\\}$, the sample skewness is:\n$$\n\\gamma_{1}(z) = \\frac{\\frac{1}{n}\\sum_{i=1}^{n}\\left(z_{i}-\\bar{z}\\right)^{3}}{\\left(\\frac{1}{n}\\sum_{i=1}^{n}\\left(z_{i}-\\bar{z}\\right)^{2}\\right)^{3/2}}, \\quad \\text{where } \\bar{z}=\\frac{1}{n}\\sum_{i=1}^{n} z_{i}.\n$$\n\n- **Linear Model and Log-Likelihood**: For a simple linear regression model $y_{i} = \\beta_{0} + \\beta_{1} z_{i} + \\varepsilon_{i}$ with i.i.d. Gaussian errors $\\varepsilon_{i} \\sim \\mathcal{N}(0,\\sigma^{2})$, the maximized log-likelihood under OLS is:\n$$\n\\ell = -\\frac{n}{2}\\left(\\log\\left(2\\pi \\hat{\\sigma}^{2}\\right)+1\\right),\n$$\nwhere $\\hat{\\sigma}^{2}=\\text{RSS}/n$ is the maximum likelihood estimate of the error variance, with $\\text{RSS}$ being the residual sum of squares.\n\n- **Data Generation Model**:\n$$\nX_{i} \\sim \\text{LogNormal}(\\mu,\\sigma_{X}^{2}), \\quad \nY_{i} = \\beta_{0} + \\beta_{1}\\, g_{\\lambda^{\\star}}(X_{i}) + \\varepsilon_{i}, \\quad \\varepsilon_{i} \\sim \\mathcal{N}(0,\\sigma_{\\varepsilon}^{2})\n$$\nfor $i=1,\\dots,n$, with a specified random seed.\n\n- **Candidate Transformation Parameters**:\n$$\n\\Lambda = \\left\\{-2.0,-1.0,-0.5,-0.25,0.0,0.25,0.5,1.0,2.0\\right\\}\n$$\n\n- **Procedure**:\n    1.  **Skewness Equalization**: Find $\\hat{\\lambda}_{\\text{skew}} \\in \\Lambda$ that minimizes the absolute sample skewness $|\\gamma_{1}(g_{\\lambda}(X))|$.\n    2.  **Model-Fit Optimization**: Find $\\hat{\\lambda}_{\\text{fit}} \\in \\Lambda$ that maximizes the log-likelihood $\\ell(\\lambda)$ of the model $Y \\sim g_{\\lambda}(X)$.\n    3.  **Tie-breaking**: For both optimizations, the first value encountered in an ascending scan of $\\Lambda$ is chosen.\n    4.  **Improvement over Identity**: Calculate $\\Delta_{\\text{skew}} = \\ell(\\hat{\\lambda}_{\\text{skew}}) - \\ell(1.0)$ and a boolean indicator $I = (\\Delta_{\\text{skew}} > 0)$.\n\n- **Output**: For each test case, a list $[\\hat{\\lambda}_{\\text{skew}}, \\hat{\\lambda}_{\\text{fit}}, I, \\Delta_{\\text{skew}}]$ with floating-point numbers rounded to four decimal places.\n\n- **Test Cases**:\n    - Case 1: $(\\text{seed},n,\\mu,\\sigma_{X},\\beta_{0},\\beta_{1},\\lambda^{\\star},\\sigma_{\\varepsilon}) = (0, 400, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0)$.\n    - Case 2: $(\\text{seed},n,\\mu,\\sigma_{X},\\beta_{0},\\beta_{1},\\lambda^{\\star},\\sigma_{\\varepsilon}) = (1, 400, 0.0, 0.25, -0.5, 1.5, 1.0, 1.0)$.\n    - Case 3: $(\\text{seed},n,\\mu,\\sigma_{X},\\beta_{0},\\beta_{1},\\lambda^{\\star},\\sigma_{\\varepsilon}) = (2, 400, 0.0, 1.25, 0.0, 1.0, 0.5, 1.5)$.\n    - Case 4: $(\\text{seed},n,\\mu,\\sigma_{X},\\beta_{0},\\beta_{1},\\lambda^{\\star},\\sigma_{\\varepsilon}) = (3, 400, 0.5, 1.0, 0.5, 1.0, -0.5, 1.0)$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is coherent and well-defined.\n- **Scientifically Grounded**: The problem is built upon fundamental and standard concepts in statistical modeling and data analysis, including the Box-Cox transformation, linear regression, skewness, and likelihood-based model evaluation. The data simulation protocol is a common approach for studying statistical methods.\n- **Well-Posed**: The sequence of operations is clearly specified. The use of a fixed random seed ensures reproducibility. The search for optimal $\\lambda$ values is conducted over a finite, discrete set $\\Lambda$, and the explicit tie-breaking rule guarantees a unique solution for each test case.\n- **Objective**: All definitions and tasks are stated with mathematical precision, leaving no room for subjective interpretation.\n- **Flaw Analysis**:\n    1.  **Scientific/Factual Unsoundness**: None. All formulas and concepts are standard in statistics.\n    2.  **Non-Formalizable/Irrelevant**: The problem is entirely formalizable and highly relevant to its stated topic in statistical learning.\n    3.  **Incomplete/Contradictory**: The problem specification is complete, providing all necessary parameters, data generation procedures, formulas, and criteria for evaluation. There are no contradictions.\n    4.  **Unrealistic/Infeasible**: The specified parameters are reasonable for a simulation study. The generation of $X$ from a LogNormal distribution ensures $X>0$, making the Box-Cox transformation well-defined.\n    5.  **Ill-Posed/Poorly Structured**: None. The problem structure is logical and leads to a unique, meaningful solution.\n    6.  **Pseudo-Profound/Trivial**: The problem requires the integration of several non-trivial statistical computations into a simulation framework to explore a conceptually important trade-off in feature engineering. It is a substantive task.\n    7.  **Outside Scientific Verifiability**: The results are computationally deterministic and verifiable given the random seeds.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed to construct the solution.\n\nThe solution will be implemented as a single Python script. For each test case defined in the problem, the script will execute the following sequence of steps:\n1.  Initialize a random number generator with the specified seed for reproducibility.\n2.  Generate the predictor data $X$ from a LogNormal distribution, $\\text{LogNormal}(\\mu, \\sigma_X^2)$, and the noise term $\\varepsilon$ from a Normal distribution, $\\mathcal{N}(0, \\sigma_\\varepsilon^2)$. The parameters $\\mu$, $\\sigma_X$, and $\\sigma_\\varepsilon$ are provided in each test case.\n3.  Construct the response variable $Y$ using the true underlying relationship: $Y_{i} = \\beta_{0} + \\beta_{1}\\, g_{\\lambda^{\\star}}(X_{i}) + \\varepsilon_{i}$.\n4.  Iterate through the candidate set of transformation parameters $\\Lambda$. For each $\\lambda \\in \\Lambda$:\n    a. Apply the Box-Cox transformation to the predictor: $Z^{(\\lambda)} = g_{\\lambda}(X)$.\n    b. Compute the sample skewness of the transformed predictor, $\\gamma_{1}(Z^{(\\lambda)})$, using the provided formula. The absolute value of this skewness is stored.\n    c. Fit a simple linear regression model of $Y$ on $Z^{(\\lambda)}$ using Ordinary Least Squares (OLS) to obtain coefficient estimates.\n    d. From the OLS fit, calculate the Residual Sum of Squares, $\\text{RSS}(\\lambda)$.\n    e. Use $\\text{RSS}(\\lambda)$ to compute the maximized log-likelihood, $\\ell(\\lambda)$, according to the given formula.\n5.  After iterating through all $\\lambda \\in \\Lambda$, determine $\\hat{\\lambda}_{\\text{skew}}$ by finding the $\\lambda$ that minimizes the stored absolute skewness values. The specified tie-breaking rule (first in ascending order) is handled by using `numpy.argmin`.\n6.  Similarly, determine $\\hat{\\lambda}_{\\text{fit}}$ by finding the $\\lambda$ that maximizes the stored log-likelihood values. The tie-breaking rule is handled by using `numpy.argmax`.\n7.  Calculate the improvement metric $\\Delta_{\\text{skew}} = \\ell(\\hat{\\lambda}_{\\text{skew}}) - \\ell(1.0)$. The value $\\ell(1.0)$ corresponds to the log-likelihood for the model using the identity-like transformation.\n8.  Define the boolean indicator $I$ as true if $\\Delta_{\\text{skew}} > 0$, and false otherwise.\n9.  Assemble the final result for the test case, which is the list $[\\hat{\\lambda}_{\\text{skew}}, \\hat{\\lambda}_{\\text{fit}}, I, \\Delta_{\\text{skew}}]$, ensuring numerical values are rounded to four decimal places.\n10. After processing all test cases, the results are formatted into a single string as a list of lists and printed to standard output.\nHelper functions will be defined for the Box-Cox transformation and other repeated calculations to ensure code clarity and correctness. The `scipy.stats.skew` function will be used for computing skewness as it correctly implements the biased estimator specified in the problem statement.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import skew\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the final result.\n    \"\"\"\n    # Define the test cases as per the problem statement.\n    # Format: (seed, n, mu, sigma_X, beta_0, beta_1, lambda_star, sigma_epsilon)\n    test_cases = [\n        (0, 400, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0),\n        (1, 400, 0.0, 0.25, -0.5, 1.5, 1.0, 1.0),\n        (2, 400, 0.0, 1.25, 0.0, 1.0, 0.5, 1.5),\n        (3, 400, 0.5, 1.0, 0.5, 1.0, -0.5, 1.0),\n    ]\n\n    # Candidate set for the transformation parameter lambda.\n    Lambda = np.array([-2.0, -1.0, -0.5, -0.25, 0.0, 0.25, 0.5, 1.0, 2.0])\n\n    all_results = []\n\n    def box_cox_transform(x, lambda_val):\n        \"\"\"\n        Applies the Box-Cox transformation to the input data x.\n        \"\"\"\n        if lambda_val == 0.0:\n            return np.log(x)\n        else:\n            return (np.power(x, lambda_val) - 1.0) / lambda_val\n\n    for case in test_cases:\n        seed, n, mu, sigma_x, beta_0, beta_1, lambda_star, sigma_eps = case\n        \n        # Initialize random number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n        \n        # Step 1: Data generation.\n        # X is from a LogNormal distribution, ensuring it's positive.\n        X = rng.lognormal(mean=mu, sigma=sigma_x, size=n)\n        # Epsilon is from a Normal distribution.\n        eps = rng.normal(loc=0.0, scale=sigma_eps, size=n)\n        \n        # The true transformed predictor and the response variable Y.\n        X_transformed_true = box_cox_transform(X, lambda_star)\n        Y = beta_0 + beta_1 * X_transformed_true + eps\n        \n        abs_skewness_list = []\n        log_likelihood_list = []\n        \n        # Step 2-4: Iterate through the transformation grid.\n        for lambda_val in Lambda:\n            # Transform the predictor X using the current lambda.\n            Z = box_cox_transform(X, lambda_val)\n            \n            # Compute absolute skewness. scipy.stats.skew with bias=True (default)\n            # matches the formula provided in the problem.\n            current_abs_skew = np.abs(skew(Z))\n            abs_skewness_list.append(current_abs_skew)\n            \n            # Fit an OLS model: Y = b0 + b1*Z.\n            # np.polyfit returns coefficients [b1, b0].\n            b1_fit, b0_fit = np.polyfit(Z, Y, 1)\n            \n            # Calculate predicted Y values and residuals.\n            Y_pred = b0_fit + b1_fit * Z\n            \n            # Compute residual sum of squares (RSS).\n            rss = np.sum((Y - Y_pred)**2)\n            \n            # The MLE for variance is RSS/n.\n            sigma2_hat = rss / float(n)\n            \n            # Compute the maximized log-likelihood.\n            # A check for non-positive variance to avoid math errors, though unlikely here.\n            if sigma2_hat > 0:\n                log_lik = -n / 2.0 * (np.log(2.0 * np.pi * sigma2_hat) + 1.0)\n            else:\n                log_lik = -np.inf\n            log_likelihood_list.append(log_lik)\n\n        # Find the lambda that minimizes absolute skewness.\n        # np.argmin respects the tie-breaking rule (first occurrence).\n        idx_skew = np.argmin(abs_skewness_list)\n        hat_lambda_skew = Lambda[idx_skew]\n        \n        # Find the lambda that maximizes log-likelihood.\n        # np.argmax also respects the tie-breaking rule.\n        idx_fit = np.argmax(log_likelihood_list)\n        hat_lambda_fit = Lambda[idx_fit]\n        \n        # Step 5: Improvement over identity.\n        # Find the log-likelihood for the identity transformation (lambda = 1.0).\n        idx_1 = np.where(Lambda == 1.0)[0][0]\n        log_lik_at_1 = log_likelihood_list[idx_1]\n        \n        # Get the log-likelihood at the skewness-minimizing lambda.\n        log_lik_at_skew = log_likelihood_list[idx_skew]\n        \n        Delta_skew = log_lik_at_skew - log_lik_at_1\n        I = Delta_skew > 0.0\n        \n        # Step 6: Assemble the output for the current case.\n        case_result = [\n            hat_lambda_skew, \n            hat_lambda_fit, \n            bool(I),\n            Delta_skew\n        ]\n        all_results.append(case_result)\n\n    # Format the final output string as a list of lists.\n    result_strings = []\n    for res in all_results:\n        # Format: [float, float, bool, float] with specified rounding and boolean case.\n        s = f\"[{res[0]:.4f},{res[1]:.4f},{str(res[2]).lower()},{res[3]:.4f}]\"\n        result_strings.append(s)\n    \n    # Final print statement must be on a single line in the exact specified format.\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "3160298"}, {"introduction": "While correlation is a common starting point for feature selection, it can be dangerously misleading if not interpreted with caution. This exercise [@problem_id:3160360] demonstrates a classic pitfall known as Simpson's paradox, where a correlation present within subgroups of data reverses when the groups are combined. By computationally constructing this scenario, you will gain a crucial understanding of how unobserved confounding variables can distort the perceived relationship between a feature and the target, leading to incorrect feature selection.", "problem": "You will write a complete program that constructs synthetic data to demonstrate when a simple filter method for feature selection, based on the Pearson Product-Moment Correlation Coefficient (PPMCC), fails due to Simpson’s paradox in the presence of a binary confounder. Use the following foundational definitions and facts as the base: a predictor (feature) $x_j$ is a measurable function used as an input to predict a response $y$; the PPMCC between random variables $X$ and $Y$ is $\\rho(X,Y) = \\mathrm{Cov}(X,Y)/\\{\\sqrt{\\mathrm{Var}(X)}\\sqrt{\\mathrm{Var}(Y)}\\}$; the law of total covariance for a confounder $Z$ is $\\mathrm{Cov}(X,Y) = \\mathbb{E}[\\mathrm{Cov}(X,Y\\mid Z)] + \\mathrm{Cov}(\\mathbb{E}[X\\mid Z],\\mathbb{E}[Y\\mid Z])$. A naive filter method that ranks features by $|\\rho(x_j,y)|$ on pooled data can be misled when $\\mathrm{Cov}(\\mathbb{E}[X\\mid Z],\\mathbb{E}[Y\\mid Z])$ reverses the sign of $\\mathbb{E}[\\mathrm{Cov}(X,Y\\mid Z)]$, which is precisely Simpson’s paradox for correlation. Your task is to implement a simulator that, for specified parameters, generates a dataset with two predictors $x_1$ and $x_2$, a binary confounder $z\\in\\{0,1\\}$, and a response $y$, then determines if the naive filter fails because of Simpson’s paradox. Work in purely mathematical terms; no physical units are involved.\n\nSimulation model for a given parameter set:\n- Let $n_0$ and $n_1$ be the sample sizes in groups $z=0$ and $z=1$, respectively. Construct $z$ by taking $n_0$ zeros and $n_1$ ones.\n- For each group $g\\in\\{0,1\\}$, draw $x_1\\mid z=g \\sim \\mathcal{N}(\\mu^{(x_1)}_g, \\sigma_{x_1}^2)$ independently across samples.\n- Construct $x_2$ in two ways depending on a boolean flag:\n  - If $x_2$ is “confounded,” set $x_2\\mid z=g = \\alpha_g + \\varepsilon^{(2)}$ with $\\varepsilon^{(2)}\\sim \\mathcal{N}(0,\\sigma_{x_2}^2)$ independent of everything else.\n  - If $x_2$ is “unconfounded,” draw $x_2 \\sim \\mathcal{N}(0,\\sigma_{x_2}^2)$ independently of $z$ and all other variables.\n- For each group $g\\in\\{0,1\\}$, generate the response by $y\\mid z=g = \\alpha_g + b\\,x_1 + \\varepsilon^{(y)}$ with $\\varepsilon^{(y)}\\sim \\mathcal{N}(0,\\sigma_y^2)$ independent of all predictors given $z$.\n\nFeature selection rule and failure definition:\n- Compute pooled-sample PPMCCs $r_{1,\\mathrm{all}}=\\rho(x_1,y)$ and $r_{2,\\mathrm{all}}=\\rho(x_2,y)$ across all samples.\n- The naive filter selects the index $j^\\star \\in \\{1,2\\}$ that maximizes $|r_{j,\\mathrm{all}}|$, with ties broken in favor of the smaller index.\n- Compute within-group PPMCCs $r_{1,0}=\\rho(x_1,y\\mid z=0)$ and $r_{1,1}=\\rho(x_1,y\\mid z=1)$.\n- Let $\\epsilon$ be a numerical tolerance equal to $10^{-6}$ to avoid ambiguous zero correlations. Declare that Simpson’s paradox holds for $(x_1,y)$ if $\\mathrm{sign}(r_{1,0})=\\mathrm{sign}(r_{1,1})\\neq 0$, $|r_{1,0}|>\\epsilon$, $|r_{1,1}|>\\epsilon$, $|r_{1,\\mathrm{all}}|>\\epsilon$, and $\\mathrm{sign}(r_{1,\\mathrm{all}})=-\\mathrm{sign}(r_{1,0})$. Declare a filter failure due to Simpson’s paradox if and only if Simpson’s paradox holds for $(x_1,y)$ and $j^\\star\\neq 1$.\n\nImplementation requirements:\n- Use a fixed random seed equal to $12345$ for reproducibility.\n- Use the standard PPMCC formula on finite samples: for vectors $u$ and $v$, $r(u,v)=\\sum_i (u_i-\\bar u)(v_i-\\bar v)/\\{\\sqrt{\\sum_i (u_i-\\bar u)^2}\\sqrt{\\sum_i (v_i-\\bar v)^2}\\}$, provided both standard deviations are nonzero.\n\nTest suite of parameter sets to cover a strong paradox case, a no-confounding case, and a boundary case:\n- Case A (strong Simpson failure expected):\n  - $n_0=600$, $n_1=600$,\n  - $\\mu^{(x_1)}_0=-2.0$, $\\mu^{(x_1)}_1=2.0$,\n  - $\\alpha_0=2.0$, $\\alpha_1=-2.0$,\n  - $b=0.5$,\n  - $\\sigma_{x_1}=0.6$, $\\sigma_y=0.6$,\n  - $x_2$ confounded, $\\sigma_{x_2}=0.4$.\n- Case B (no failure; aligned groups; $x_2$ uninformative):\n  - $n_0=600$, $n_1=600$,\n  - $\\mu^{(x_1)}_0=-2.0$, $\\mu^{(x_1)}_1=2.0$,\n  - $\\alpha_0=-2.0$, $\\alpha_1=2.0$,\n  - $b=0.5$,\n  - $\\sigma_{x_1}=0.6$, $\\sigma_y=0.6$,\n  - $x_2$ unconfounded, $\\sigma_{x_2}=1.0$.\n- Case C (boundary; identical groups; no confounding):\n  - $n_0=600$, $n_1=600$,\n  - $\\mu^{(x_1)}_0=0.0$, $\\mu^{(x_1)}_1=0.0$,\n  - $\\alpha_0=0.0$, $\\alpha_1=0.0$,\n  - $b=0.5$,\n  - $\\sigma_{x_1}=1.0$, $\\sigma_y=1.0$,\n  - $x_2$ unconfounded, $\\sigma_{x_2}=1.0$.\n\nYour program should, for each case in the test suite, output a boolean indicating whether the naive filter fails due to Simpson’s paradox according to the above definition. The final output must be a single line containing the three booleans in order for Cases A, B, and C, formatted as a comma-separated list enclosed in square brackets, for example, $[\\mathrm{True},\\mathrm{False},\\mathrm{False}]$.", "solution": "The problem requires the creation of a computational simulation to demonstrate a specific failure mode of a naive feature selection method. The failure occurs when Simpson's paradox, induced by a binary confounding variable, misleads a filter method based on the Pearson Product-Moment Correlation Coefficient (PPMCC). The task is to construct the data, apply the selection logic, and determine if a failure occurs according to a precise definition for three distinct parameter sets.\n\nFirst, we establish the theoretical underpinnings. A predictor $x_j$ is used to predict a response $y$. A simple filter method for feature selection might rank predictors based on the magnitude of their pooled correlation with the response, $|\\rho(x_j, y)|$. This approach, however, can be flawed in the presence of a confounding variable $z$. The relationship between the pooled (marginal) correlation and the conditional correlations (within strata of $z$) is governed by the law of total covariance:\n$$\n\\mathrm{Cov}(X,Y) = \\mathbb{E}[\\mathrm{Cov}(X,Y\\mid Z)] + \\mathrm{Cov}(\\mathbb{E}[X\\mid Z],\\mathbb{E}[Y\\mid Z])\n$$\nHere, $\\mathbb{E}[\\mathrm{Cov}(X,Y\\mid Z)]$ is the average of the covariances within the subpopulations defined by $Z$, while $\\mathrm{Cov}(\\mathbb{E}[X\\mid Z],\\mathbb{E}[Y\\mid Z])$ is the covariance of the subpopulation means. Simpson's paradox for correlation arises when the second term, the \"confounding\" term, is sufficiently large and has the opposite sign of the first, \"within-group\" term, causing $\\mathrm{sign}(\\mathrm{Cov}(X,Y))$ to be opposite to $\\mathrm{sign}(\\mathrm{Cov}(X,Y\\mid Z=g))$ for all groups $g$.\n\nThe simulation model is defined as follows:\n- A binary confounder $z$ with $n_0$ samples in group $g=0$ and $n_1$ samples in group $g=1$.\n- A predictor $x_1$ generated from a Normal distribution conditional on $z$: $x_1 \\mid (z=g) \\sim \\mathcal{N}(\\mu^{(x_1)}_g, \\sigma_{x_1}^2)$.\n- A response variable $y$ generated via a linear model conditional on $z$: $y \\mid (z=g) = \\alpha_g + b\\,x_1 + \\varepsilon^{(y)}$, where $\\varepsilon^{(y)} \\sim \\mathcal{N}(0, \\sigma_y^2)$. In this model, $x_1$ has a direct relationship with $y$ within each group, governed by the coefficient $b$.\n- A second predictor $x_2$, which can be either \"confounded\" or \"unconfounded\".\n  - If confounded: $x_2 \\mid (z=g) = \\alpha_g + \\varepsilon^{(2)}$, with $\\varepsilon^{(2)} \\sim \\mathcal{N}(0, \\sigma_{x_2}^2)$. This predictor has no direct link to $y$ but is associated with it through the common term $\\alpha_g$, which depends on the confounder $z$.\n  - If unconfounded: $x_2 \\sim \\mathcal{N}(0, \\sigma_{x_2}^2)$, making it independent of all other variables.\n\nThe program implements a function to generate a dataset according to these specifications for a given set of parameters. A fixed random seed of $12345$ ensures reproducibility. The program then proceeds with the analysis:\n\n1.  **Correlation Calculation**: The sample PPMCC, $r(u,v) = \\frac{\\sum_i (u_i-\\bar{u})(v_i-\\bar{v})}{\\sqrt{\\sum_i (u_i-\\bar{u})^2 \\sum_i (v_i-\\bar{v})^2}}$, is calculated for several pairs of variables. A custom implementation is used to handle cases where a variable is constant, returning a correlation of $0$. The following correlations are computed:\n    - Pooled correlations: $r_{1,\\mathrm{all}} = r(x_1, y)$ and $r_{2,\\mathrm{all}} = r(x_2, y)$.\n    - Within-group correlations for $x_1$: $r_{1,0} = r(x_1, y \\mid z=0)$ and $r_{1,1} = r(x_1, y \\mid z=1)$.\n\n2.  **Feature Selection**: The naive filter selects the feature $j^\\star \\in \\{1, 2\\}$ that maximizes the absolute pooled correlation $|r_{j,\\mathrm{all}}|$. Ties are broken in favor of index $j=1$.\n\n3.  **Failure Analysis**: A \"filter failure due to Simpson's paradox\" is declared if two conditions are met simultaneously:\n    a. Simpson's paradox holds for the pair $(x_1, y)$. This is defined as:\n       - The within-group correlations have the same non-zero sign: $\\mathrm{sign}(r_{1,0}) = \\mathrm{sign}(r_{1,1}) \\neq 0$.\n       - The pooled correlation has the opposite sign: $\\mathrm{sign}(r_{1,\\mathrm{all}}) = -\\mathrm{sign}(r_{1,0})$.\n       - All relevant correlations are non-trivial in magnitude, i.e., $|r_{1,0}|, |r_{1,1}|, |r_{1,\\mathrm{all}}| > \\epsilon$, where $\\epsilon = 10^{-6}$.\n    b. The filter selects the wrong feature: $j^\\star \\neq 1$. An ideal feature selector should identify $x_1$ as the relevant predictor due to its direct link to $y$ via the coefficient $b$.\n\nThe program evaluates these conditions for three test cases designed to explore different scenarios:\n- **Case A**: Parameters are chosen to create a strong confounding effect that reverses the sign of the correlation for $x_1$, while making the confounded predictor $x_2$ appear strongly correlated with $y$. A failure is expected.\n- **Case B**: The confounding effect is structured to reinforce, not reverse, the underlying correlation. No Simpson's paradox and no failure are expected.\n- **Case C**: A null case where there are no group differences. This serves as a baseline where no paradox should occur.\n\nThe final output is a list of booleans indicating the outcome of the failure test for each of the three cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef ppmcc(u, v):\n    \"\"\"\n    Computes the Pearson Product-Moment Correlation Coefficient between two vectors.\n    This is a direct implementation of the formula provided in the problem statement.\n    \"\"\"\n    if len(u)  2 or len(v)  2:\n        return 0.0\n\n    u_mean = np.mean(u)\n    v_mean = np.mean(v)\n    \n    u_dev = u - u_mean\n    v_dev = v - v_mean\n    \n    numerator = np.sum(u_dev * v_dev)\n    \n    u_ss = np.sum(u_dev**2)\n    v_ss = np.sum(v_dev**2)\n    \n    denominator = np.sqrt(u_ss * v_ss)\n    \n    if denominator == 0:\n        return 0.0\n        \n    return numerator / denominator\n\ndef run_simulation(params, rng):\n    \"\"\"\n    Runs a single simulation for a given set of parameters.\n    \n    Args:\n        params (dict): A dictionary containing the parameters for the simulation.\n        rng (numpy.random.Generator): The random number generator instance.\n        \n    Returns:\n        bool: True if the naive filter fails due to Simpson's paradox, False otherwise.\n    \"\"\"\n    # Unpack parameters\n    n0, n1 = params['n0'], params['n1']\n    mu_x1_0, mu_x1_1 = params['mu_x1_0'], params['mu_x1_1']\n    alpha0, alpha1 = params['alpha0'], params['alpha1']\n    b = params['b']\n    sigma_x1, sigma_y = params['sigma_x1'], params['sigma_y']\n    is_x2_confounded = params['is_x2_confounded']\n    sigma_x2 = params['sigma_x2']\n    \n    # 1. Generate the binary confounder z\n    z = np.concatenate([np.zeros(n0, dtype=int), np.ones(n1, dtype=int)])\n    \n    # 2. Generate predictor x1\n    x1_group0 = rng.normal(loc=mu_x1_0, scale=sigma_x1, size=n0)\n    x1_group1 = rng.normal(loc=mu_x1_1, scale=sigma_x1, size=n1)\n    x1 = np.concatenate([x1_group0, x1_group1])\n    \n    # 3. Generate predictor x2\n    if is_x2_confounded:\n        eps2 = rng.normal(loc=0, scale=sigma_x2, size=n0 + n1)\n        z_based_alpha_x2 = np.concatenate([np.full(n0, alpha0), np.full(n1, alpha1)])\n        x2 = z_based_alpha_x2 + eps2\n    else: # unconfounded\n        x2 = rng.normal(loc=0, scale=sigma_x2, size=n0 + n1)\n\n    # 4. Generate the response variable y\n    eps_y = rng.normal(loc=0, scale=sigma_y, size=n0 + n1)\n    z_based_alpha_y = np.concatenate([np.full(n0, alpha0), np.full(n1, alpha1)])\n    y = z_based_alpha_y + b * x1 + eps_y\n\n    # 5. Calculate all required correlations\n    r_1_all = ppmcc(x1, y)\n    r_2_all = ppmcc(x2, y)\n    \n    mask0 = (z == 0)\n    mask1 = (z == 1)\n    \n    r_1_0 = ppmcc(x1[mask0], y[mask0])\n    r_1_1 = ppmcc(x1[mask1], y[mask1])\n\n    # 6. Apply the failure definition from the problem statement\n    epsilon = 1e-6\n    \n    sign_r10 = np.sign(r_1_0)\n    sign_r11 = np.sign(r_1_1)\n    sign_r1all = np.sign(r_1_all)\n    \n    # Condition for Simpson's paradox holding for (x1, y)\n    simpson_paradox_holds = (\n        sign_r10 == sign_r11 and\n        sign_r10 != 0 and\n        abs(r_1_0) > epsilon and\n        abs(r_1_1) > epsilon and\n        abs(r_1_all) > epsilon and\n        sign_r1all == -sign_r10\n    )\n    \n    # Naive filter selection rule\n    # j_star = argmax |r_j_all|, tie-break to index 1\n    if abs(r_2_all) > abs(r_1_all):\n        j_star = 2\n    else:\n        j_star = 1\n    \n    # Final definition of filter failure due to Simpson's paradox\n    filter_failure = simpson_paradox_holds and (j_star != 1)\n    \n    return filter_failure\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Strong Simpson failure expected\n        {'n0': 600, 'n1': 600, 'mu_x1_0': -2.0, 'mu_x1_1': 2.0,\n         'alpha0': 2.0, 'alpha1': -2.0, 'b': 0.5, 'sigma_x1': 0.6,\n         'sigma_y': 0.6, 'is_x2_confounded': True, 'sigma_x2': 0.4},\n        # Case B: No failure; aligned groups; x2 uninformative\n        {'n0': 600, 'n1': 600, 'mu_x1_0': -2.0, 'mu_x1_1': 2.0,\n         'alpha0': -2.0, 'alpha1': 2.0, 'b': 0.5, 'sigma_x1': 0.6,\n         'sigma_y': 0.6, 'is_x2_confounded': False, 'sigma_x2': 1.0},\n        # Case C: Boundary; identical groups; no confounding\n        {'n0': 600, 'n1': 600, 'mu_x1_0': 0.0, 'mu_x1_1': 0.0,\n         'alpha0': 0.0, 'alpha1': 0.0, 'b': 0.5, 'sigma_x1': 1.0,\n         'sigma_y': 1.0, 'is_x2_confounded': False, 'sigma_x2': 1.0}\n    ]\n\n    # Initialize a single random number generator with the fixed seed for reproducibility.\n    # This generator is passed to each simulation run to ensure sequential consumption\n    # of random numbers, as implied by a single global seed.\n    rng = np.random.default_rng(12345)\n    \n    results = []\n    for params in test_cases:\n        failure = run_simulation(params, rng)\n        results.append(failure)\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3160360"}, {"introduction": "A model's success in the lab does not guarantee its performance in the real world, especially when the deployment environment differs from the training setting—a common issue known as domain shift. This hands-on exercise [@problem_id:3160364] simulates a practical domain shift where a feature's unit of measurement changes, such as a price shifting from dollars to euros. You will evaluate several feature normalization strategies to see firsthand why simply re-standardizing data is often not enough, and how incorporating domain knowledge is critical for building robust, reliable models.", "problem": "You are given a one-dimensional supervised learning setup in which a single real-valued feature denotes a product price, and the prediction target is a linear function of the price when expressed in a specific currency. The training domain uses United States Dollar (USD). A domain shift occurs at test time because the same real-world quantity is recorded in Euro (EUR) at a known exchange rate. Your task is to implement and evaluate three different feature-normalization strategies for producing consistent predictions under this domain shift.\n\nFundamental base and definitions:\n- A predictor is a function $f:\\mathbb{R}\\to\\mathbb{R}$ that maps an input feature $x$ to a predicted output $y$. We consider the squared loss $L(y,\\hat{y})=(y-\\hat{y})^{2}$.\n- In Empirical Risk Minimization with squared loss over linear functions, the Ordinary Least Squares solution for regressing $y$ on a single input $z$ has slope $\\hat{w}=\\dfrac{\\sum (z-\\bar{z})(y-\\bar{y})}{\\sum (z-\\bar{z})^{2}}$ and intercept $\\hat{c}=\\bar{y}-\\hat{w}\\,\\bar{z}$, where bars denote sample means.\n- Z-score standardization of a feature $x$ with sample mean $\\mu$ and sample standard deviation $\\sigma0$ is defined as $z=(x-\\mu)/\\sigma$.\n\nData-generating mechanism:\n- The ground-truth target is linear in the USD price: $y=\\theta_{0}+\\theta_{1}\\,x_{\\mathrm{USD}}$.\n- Training data are collected in USD. At test time, the observed feature is $x_{\\mathrm{EUR}}=r\\cdot x_{\\mathrm{USD}}$, where $r0$ is the exchange rate (EUR per USD). The labels always follow the USD-based law above.\n\nTraining procedure to be used in all cases:\n1. Compute the training mean $\\mu_{\\mathrm{A}}$ and standard deviation $\\sigma_{\\mathrm{A}}$ of the USD feature $x_{\\mathrm{USD}}$ using population definitions (i.e., average over all $n$ samples with denominator $n$).\n2. Standardize the training feature to $z_{\\mathrm{A}}=(x_{\\mathrm{USD}}-\\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}}$.\n3. Fit the linear predictor $\\hat{y}=\\hat{w}\\,z+\\hat{c}$ by Ordinary Least Squares on $(z_{\\mathrm{A}},y)$.\n\nAt test time, for an observed EUR feature vector $x_{\\mathrm{EUR}}$, evaluate three strategies to construct the standardized input $z$ for inference:\n- Strategy T1 (train-statistics on observed): $z_{\\mathrm{T1}}=(x_{\\mathrm{EUR}}-\\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}}$.\n- Strategy T2 (per-domain standardization): compute $\\mu_{\\mathrm{B}}$ and $\\sigma_{\\mathrm{B}}$ from $x_{\\mathrm{EUR}}$ itself using population definitions, then set $z_{\\mathrm{T2}}=(x_{\\mathrm{EUR}}-\\mu_{\\mathrm{B}})/\\sigma_{\\mathrm{B}}$.\n- Strategy T3 (currency-aware then train-statistics): $z_{\\mathrm{T3}}=(x_{\\mathrm{EUR}}/r-\\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}}$.\n\nFor each strategy, produce predictions $\\hat{y}=\\hat{w}\\,z+\\hat{c}$ and evaluate the root mean squared error (RMSE) on the test set, defined as $\\sqrt{\\dfrac{1}{m}\\sum_{i=1}^{m}(\\hat{y}_{i}-y_{i})^{2}}$, where $m$ is the number of test examples and $y_{i}=\\theta_{0}+\\theta_{1}\\,x_{\\mathrm{USD},i}$.\n\nUse the following fixed numerical specification:\n- Ground truth parameters: $\\theta_{0}=4.0$, $\\theta_{1}=1.2$.\n- Training USD feature values: $[\\,12.0,\\,25.0,\\,40.0,\\,55.0,\\,70.0\\,]$.\n- Training labels: $y=\\theta_{0}+\\theta_{1}\\,x_{\\mathrm{USD}}$ computed exactly from the above.\n- Test suite (four cases), where for each case you are given an exchange rate $r$ and a list of USD prices $x_{\\mathrm{USD}}$; the observed test features are $x_{\\mathrm{EUR}}=r\\cdot x_{\\mathrm{USD}}$:\n  1. Case 1 (general domain shift): $r=0.9$, $x_{\\mathrm{USD}}=[\\,15.0,\\,22.5,\\,60.0,\\,80.0\\,]$.\n  2. Case 2 (no domain shift): $r=1.0$, $x_{\\mathrm{USD}}=[\\,10.0,\\,30.0,\\,50.0\\,]$.\n  3. Case 3 (distributional match under scaling): $r=1.15$, $x_{\\mathrm{USD}}=[\\,12.0,\\,25.0,\\,40.0,\\,55.0,\\,70.0\\,]$.\n  4. Case 4 (strong domain shift): $r=0.5$, $x_{\\mathrm{USD}}=[\\,5.0,\\,15.0,\\,75.0,\\,120.0\\,]$.\n\nYour program should:\n- Implement the training procedure exactly as specified.\n- For each test case, compute the RMSE for strategies T1, T2, and T3 in that order.\n- There are no physical units required in the output; report all values as real numbers.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as\n  $[\\,\\mathrm{RMSE}_{\\mathrm{T1}}^{(1)},\\mathrm{RMSE}_{\\mathrm{T2}}^{(1)},\\mathrm{RMSE}_{\\mathrm{T3}}^{(1)},\\mathrm{RMSE}_{\\mathrm{T1}}^{(2)},\\mathrm{RMSE}_{\\mathrm{T2}}^{(2)},\\mathrm{RMSE}_{\\mathrm{T3}}^{(2)},\\mathrm{RMSE}_{\\mathrm{T1}}^{(3)},\\mathrm{RMSE}_{\\mathrm{T2}}^{(3)},\\mathrm{RMSE}_{\\mathrm{T3}}^{(3)},\\mathrm{RMSE}_{\\mathrm{T1}}^{(4)},\\mathrm{RMSE}_{\\mathrm{T2}}^{(4)},\\mathrm{RMSE}_{\\mathrm{T3}}^{(4)}\\,]$ where the superscript $^{(k)}$ indexes the test case number $k\\in\\{1,2,3,4\\}$.", "solution": "The problem is subjected to validation.\n\n### Step 1: Extract Givens\n- **Predictor Function**: $f:\\mathbb{R}\\to\\mathbb{R}$, mapping an input feature $x$ to a predicted output $\\hat{y}$.\n- **Loss Function**: Squared Loss, $L(y,\\hat{y})=(y-\\hat{y})^{2}$.\n- **Ordinary Least Squares (OLS) Solution for a single regressor $z$**:\n  - Slope: $\\hat{w}=\\dfrac{\\sum (z-\\bar{z})(y-\\bar{y})}{\\sum (z-\\bar{z})^{2}}$\n  - Intercept: $\\hat{c}=\\bar{y}-\\hat{w}\\,\\bar{z}$\n- **Z-score Standardization**: $z=(x-\\mu)/\\sigma$, using sample mean $\\mu$ and sample standard deviation $\\sigma0$. The problem specifies using population definitions (denominator $n$ for mean and variance).\n- **Ground-Truth Data Generating Process**: The true target $y$ is a linear function of the price in USD: $y=\\theta_{0}+\\theta_{1}\\,x_{\\mathrm{USD}}$.\n- **Domain Shift Mechanism**: Training data uses $x_{\\mathrm{USD}}$. Test data uses $x_{\\mathrm{EUR}}=r\\cdot x_{\\mathrm{USD}}$, where $r0$ is a known exchange rate. The target $y$ is always determined by $x_{\\mathrm{USD}}$.\n- **Training Procedure**:\n  1. Compute the training mean $\\mu_{\\mathrm{A}}$ and population standard deviation $\\sigma_{\\mathrm{A}}$ of the training feature $x_{\\mathrm{USD}}$ (from $n$ samples).\n  2. Standardize the training feature: $z_{\\mathrm{A}}=(x_{\\mathrm{USD}}-\\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}}$.\n  3. Fit the linear predictor $\\hat{y}=\\hat{w}\\,z+\\hat{c}$ via OLS on the pair $(z_{\\mathrm{A}},y)$.\n- **Test-Time Inference Strategies**: For an observed test feature vector $x_{\\mathrm{EUR}}$, the input $z$ is constructed via:\n  - **T1 (train-statistics on observed)**: $z_{\\mathrm{T1}}=(x_{\\mathrm{EUR}}-\\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}}$.\n  - **T2 (per-domain standardization)**: Compute mean $\\mu_{\\mathrm{B}}$ and pop. std. dev. $\\sigma_{\\mathrm{B}}$ from $x_{\\mathrm{EUR}}$, then $z_{\\mathrm{T2}}=(x_{\\mathrm{EUR}}-\\mu_{\\mathrm{B}})/\\sigma_{\\mathrm{B}}$.\n  - **T3 (currency-aware then train-statistics)**: $z_{\\mathrm{T3}}=(x_{\\mathrm{EUR}}/r-\\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}}$.\n- **Evaluation Metric**: Root Mean Squared Error (RMSE) on the test set, $\\sqrt{\\dfrac{1}{m}\\sum_{i=1}^{m}(\\hat{y}_{i}-y_{i})^{2}}$, where $m$ is the test set size.\n- **Numerical Specifications**:\n  - Ground Truth Parameters: $\\theta_{0}=4.0$, $\\theta_{1}=1.2$.\n  - Training Data $x_{\\mathrm{USD}}$: $[\\,12.0,\\,25.0,\\,40.0,\\,55.0,\\,70.0\\,]$, $n=5$.\n  - Training Labels: $y=\\theta_{0}+\\theta_{1}\\,x_{\\mathrm{USD}}$.\n  - Test Cases:\n    1. $r=0.9$, $x_{\\mathrm{USD}}=[\\,15.0,\\,22.5,\\,60.0,\\,80.0\\,]$.\n    2. $r=1.0$, $x_{\\mathrm{USD}}=[\\,10.0,\\,30.0,\\,50.0\\,]$.\n    3. $r=1.15$, $x_{\\mathrm{USD}}=[\\,12.0,\\,25.0,\\,40.0,\\,55.0,\\,70.0\\,]$.\n    4. $r=0.5$, $x_{\\mathrm{USD}}=[\\,5.0,\\,15.0,\\,75.0,\\,120.0\\,]$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the principles of linear regression and statistical learning. The concepts of domain shift, feature standardization, and empirical risk minimization are standard in the field. The setup is a simplified but conceptually sound model of a real-world scenario where a model trained in one context (e.g., one currency) must be applied in another. The problem is well-posed: all data, parameters, and procedures are explicitly defined, and no contradictions exist. The feature vectors provided for training and testing all contain distinct elements, ensuring that the standard deviation $\\sigma$ is always greater than zero, making the Z-score standardization well-defined. The problem is not trivial; it requires careful implementation of the specified procedures and highlights fundamental concepts about model robustness under covariate shift. The expected outcome is computationally verifiable.\n\n### Step 3: Verdict and Action\nThe problem is valid. A reasoned solution will be provided.\n\n### Solution\n\nThe problem requires us to train a linear regression model and evaluate its performance under a specific type of domain shift using three different feature normalization strategies.\n\n**1. Training Phase**\n\nThe training process involves fitting a linear model $\\hat{y} = \\hat{w}z + \\hat{c}$ where $z$ is the standardized feature.\n\nFirst, we define the training data. The features are given as $x_{\\mathrm{A, USD}} = [\\,12.0,\\, 25.0,\\, 40.0,\\, 55.0,\\, 70.0\\,]$.\nThe ground truth parameters are $\\theta_{0}=4.0$ and $\\theta_{1}=1.2$. The training labels $y_{\\mathrm{A}}$ are generated by the true model, $y_i = \\theta_{0} + \\theta_{1} x_{\\mathrm{A, USD}, i}$:\n$y_{\\mathrm{A}} = [\\,4.0 + 1.2 \\cdot 12.0,\\, \\dots,\\, 4.0 + 1.2 \\cdot 70.0\\,] = [\\,18.4,\\, 34.0,\\, 52.0,\\, 70.0,\\, 88.0\\,]$.\n\nNext, we calculate the training feature statistics using population definitions (denominator $n=5$):\nThe mean is $\\mu_{\\mathrm{A}} = \\frac{1}{5}(12.0 + 25.0 + 40.0 + 55.0 + 70.0) = \\frac{202.0}{5} = 40.4$.\nThe variance is $\\sigma_{\\mathrm{A}}^2 = \\frac{1}{5}\\sum_{i=1}^{5}(x_{\\mathrm{A, USD}, i} - \\mu_{\\mathrm{A}})^2 = \\frac{1}{5}((12.0-40.4)^2 + \\dots + (70.0-40.4)^2) = \\frac{2133.2}{5} = 426.64$.\nThe standard deviation is $\\sigma_{\\mathrm{A}} = \\sqrt{426.64} \\approx 20.6552656$.\n\nThe training features are standardized: $z_{\\mathrm{A}} = (x_{\\mathrm{A, USD}}-\\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}}$.\nThe relationship between the true labels $y_{\\mathrm{A}}$ and the standardized features $z_{\\mathrm{A}}$ is perfectly linear:\n$y_{\\mathrm{A}} = \\theta_{0} + \\theta_{1}x_{\\mathrm{A, USD}} = \\theta_{0} + \\theta_{1}(\\sigma_{\\mathrm{A}} z_{\\mathrm{A}} + \\mu_{\\mathrm{A}}) = (\\theta_{0} + \\theta_{1}\\mu_{\\mathrm{A}}) + (\\theta_{1}\\sigma_{\\mathrm{A}})z_{\\mathrm{A}}$.\nSince OLS provides the best linear unbiased estimator and the data lies perfectly on a line, the fitted parameters will be exact. The model is $\\hat{y} = \\hat{w}z_{\\mathrm{A}} + \\hat{c}$.\nThe estimated slope is $\\hat{w} = \\theta_{1}\\sigma_{\\mathrm{A}} = 1.2 \\cdot \\sqrt{426.64} \\approx 24.7863187$.\nThe estimated intercept is $\\hat{c} = \\theta_{0} + \\theta_{1}\\mu_{\\mathrm{A}} = 4.0 + 1.2 \\cdot 40.4 = 4.0 + 48.48 = 52.48$.\n\nThese parameters $(\\hat{w}, \\hat{c})$ are fixed and used for inference in all test cases.\n\n**2. Test Phase**\n\nFor each test case, we are given an exchange rate $r$ and a set of test prices $x_{\\mathrm{B, USD}}$. The observed features are $x_{\\mathrm{B, EUR}} = r \\cdot x_{\\mathrm{B, USD}}$, and the true labels are $y_{\\mathrm{B}} = \\theta_{0} + \\theta_{1}x_{\\mathrm{B, USD}}$.\n\n**Strategy T1 (train-statistics on observed):**\nInput for prediction: $z_{\\mathrm{T1}} = (x_{\\mathrm{B, EUR}} - \\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}}$.\nPrediction: $\\hat{y}_{\\mathrm{T1}} = \\hat{w} z_{\\mathrm{T1}} + \\hat{c}$.\nThis strategy naively applies training statistics to a feature from a shifted domain. It fails to account for the currency change and the potential change in the feature distribution.\n\n**Strategy T2 (per-domain standardization):**\nFirst, compute statistics from the test features $x_{\\mathrm{B, EUR}}$: mean $\\mu_{\\mathrm{B}}$ and standard deviation $\\sigma_{\\mathrm{B}}$.\nInput for prediction: $z_{\\mathrm{T2}} = (x_{\\mathrm{B, EUR}} - \\mu_{\\mathrm{B}})/\\sigma_{\\mathrm{B}}$.\nPrediction: $\\hat{y}_{\\mathrm{T2}} = \\hat{w} z_{\\mathrm{T2}} + \\hat{c}$.\nThis strategy adapts to the test distribution's first two moments but ignores the known relationship between domains.\n\n**Strategy T3 (currency-aware then train-statistics):**\nFirst, invert the currency conversion: $x_{\\mathrm{B, USD\\_reconstructed}} = x_{\\mathrm{B, EUR}} / r$. By definition, this perfectly recovers the original $x_{\\mathrm{B, USD}}$.\nInput for prediction: $z_{\\mathrm{T3}} = (x_{\\mathrm{B, USD\\_reconstructed}} - \\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}} = (x_{\\mathrm{B, USD}} - \\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}}$.\nPrediction: $\\hat{y}_{\\mathrm{T3}} = \\hat{w} z_{\\mathrm{T3}} + \\hat{c}$.\nLet's analyze the prediction:\n$\\hat{y}_{\\mathrm{T3}} = (\\theta_{1}\\sigma_{\\mathrm{A}})\\left(\\frac{x_{\\mathrm{B, USD}} - \\mu_{\\mathrm{A}}}{\\sigma_{\\mathrm{A}}}\\right) + (\\theta_{0} + \\theta_{1}\\mu_{\\mathrm{A}})$\n$\\hat{y}_{\\mathrm{T3}} = \\theta_{1}(x_{\\mathrm{B, USD}} - \\mu_{\\mathrm{A}}) + \\theta_{0} + \\theta_{1}\\mu_{\\mathrm{A}}$\n$\\hat{y}_{\\mathrm{T3}} = \\theta_{1}x_{\\mathrm{B, USD}} - \\theta_{1}\\mu_{\\mathrm{A}} + \\theta_{0} + \\theta_{1}\\mu_{\\mathrm{A}} = \\theta_{0} + \\theta_{1}x_{\\mathrm{B, USD}} = y_{\\mathrm{B}}$.\nThe prediction for Strategy T3 is exactly the true label. Therefore, the RMSE for T3 will be $0$ in all cases. This demonstrates that if the domain shift is a known, invertible transformation, applying the inverse transformation before feature engineering yields perfect predictions for a noiseless linear model.\n\nNow we compute the RMSE for all strategies and test cases.\n\n**Case 1: $r=0.9$, $x_{\\mathrm{B, USD}}=[\\,15.0,\\,22.5,\\,60.0,\\,80.0\\,]$**\n$x_{\\mathrm{B, EUR}} = [\\,13.5,\\, 20.25,\\, 54.0,\\, 72.0\\,]$\n$y_{\\mathrm{B}} = [\\,22.0,\\, 31.0,\\, 76.0,\\, 100.0\\,]$\n- T1: RMSE $\\approx 11.2345$\n- T2: RMSE $\\approx 9.0733$\n- T3: RMSE $= 0.0$\n\n**Case 2: $r=1.0$, $x_{\\mathrm{B, USD}}=[\\,10.0,\\,30.0,\\,50.0\\,]$**\nHere, $r=1.0$, so $x_{\\mathrm{B, EUR}} = x_{\\mathrm{B, USD}}$. This represents a shift in data distribution without a scaling change.\n$x_{\\mathrm{B, EUR}} = [\\,10.0,\\, 30.0,\\, 50.0\\,]$\n$y_{\\mathrm{B}} = [\\,16.0,\\, 40.0,\\, 64.0\\,]$\n- T1: $z_{\\mathrm{T1}} = (x_{\\mathrm{B, USD}} - \\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}}$. This is the same transformation as in Strategy T3. As shown for T3, this yields perfect predictions. RMSE $= 0.0$.\n- T2: This strategy uses the mean and std dev of the test set itself, which are different from $\\mu_{\\mathrm{A}}$ and $\\sigma_{\\mathrm{A}}$. Thus, it will result in non-zero error. RMSE $\\approx 3.7919$.\n- T3: Since $r=1.0$, $z_{\\mathrm{T3}} = (x_{\\mathrm{B, EUR}}/1.0 - \\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}} = z_{\\mathrm{T1}}$. RMSE $= 0.0$.\n\n**Case 3: $r=1.15$, $x_{\\mathrm{B, USD}}=[\\,12.0,\\,25.0,\\,40.0,\\,55.0,\\,70.0\\,]$**\nThe test set $x_{\\mathrm{B, USD}}$ is identical to the training set $x_{\\mathrm{A, USD}}$.\n$x_{\\mathrm{B, EUR}} = r \\cdot x_{\\mathrm{A, USD}}$\n- T1: Will produce errors as it treats scaled values as original ones. RMSE $\\approx 5.7008$.\n- T2: Let's analyze this case. $\\mu_{\\mathrm{B}} = \\mathrm{mean}(r \\cdot x_{\\mathrm{A, USD}}) = r \\mu_{\\mathrm{A}}$. $\\sigma_{\\mathrm{B}} = \\mathrm{std}(r \\cdot x_{\\mathrm{A, USD}}) = r \\sigma_{\\mathrm{A}}$.\n  $z_{\\mathrm{T2}} = (x_{\\mathrm{B, EUR}} - \\mu_{\\mathrm{B}})/\\sigma_{\\mathrm{B}} = (r x_{\\mathrm{A, USD}} - r \\mu_{\\mathrm{A}})/(r \\sigma_{\\mathrm{A}}) = (x_{\\mathrm{A, USD}} - \\mu_{\\mathrm{A}})/\\sigma_{\\mathrm{A}} = z_{\\mathrm{A}}$.\n  The standardized inputs for the test set are identical to the standardized inputs of the training set. Since the underlying USD prices and thus the labels are also identical, the predictions $\\hat{y}_{\\mathrm{T2}}$ will be identical to the training labels $y_{\\mathrm{A}} = y_{\\mathrm{B}}$. Thus, the error is zero. RMSE $= 0.0$.\n- T3: As always, RMSE $= 0.0$.\n\n**Case 4: $r=0.5$, $x_{\\mathrm{B, USD}}=[\\,5.0,\\,15.0,\\,75.0,\\,120.0\\,]$**\n$x_{\\mathrm{B, EUR}} = [\\,2.5,\\, 7.5,\\, 37.5,\\, 60.0\\,]$\n$y_{\\mathrm{B}} = [\\,10.0,\\, 22.0,\\, 94.0,\\, 148.0\\,]$\n- T1: RMSE $\\approx 25.1017$\n- T2: RMSE $\\approx 18.0664$\n- T3: RMSE $= 0.0$\n\nThe results illustrate a key principle: explicitly accounting for known sources of domain shift (like a currency conversion) is superior to generic adaptation strategies (like re-standardizing per-domain) or ignoring the shift altogether. Strategy T3, which correctly inverts the known transformation, is robust and achieves perfect performance in this idealized, noiseless setting.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates three feature-normalization strategies\n    for a linear regression model under a currency-based domain shift.\n    \"\"\"\n    \n    # Define ground truth parameters and training data\n    theta_0 = 4.0\n    theta_1 = 1.2\n    x_train_usd = np.array([12.0, 25.0, 40.0, 55.0, 70.0])\n\n    # Define the four test cases\n    test_cases = [\n        # Case 1 (general domain shift)\n        {\"r\": 0.9, \"x_usd\": np.array([15.0, 22.5, 60.0, 80.0])},\n        # Case 2 (no domain shift)\n        {\"r\": 1.0, \"x_usd\": np.array([10.0, 30.0, 50.0])},\n        # Case 3 (distributional match under scaling)\n        {\"r\": 1.15, \"x_usd\": np.array([12.0, 25.0, 40.0, 55.0, 70.0])},\n        # Case 4 (strong domain shift)\n        {\"r\": 0.5, \"x_usd\": np.array([5.0, 15.0, 75.0, 120.0])},\n    ]\n\n    # --- Training Phase ---\n    # The problem specifies using population definitions for mean and std dev.\n    # np.mean() and np.std(ddof=0) compute these.\n    mu_A = np.mean(x_train_usd)\n    sigma_A = np.std(x_train_usd) # default ddof=0 is population std dev\n\n    # The training labels are generated by a perfect linear model without noise.\n    # y = theta_0 + theta_1 * x_usd\n    # The feature x_usd is related to the standardized feature z by x_usd = sigma_A * z + mu_A.\n    # Substituting, we get y = theta_0 + theta_1 * (sigma_A * z + mu_A)\n    # y = (theta_0 + theta_1 * mu_A) + (theta_1 * sigma_A) * z\n    # Since the OLS fit on this noiseless data will be perfect, the learned coefficients\n    # for the model y_hat = c_hat + w_hat * z will be exactly:\n    c_hat = theta_0 + theta_1 * mu_A\n    w_hat = theta_1 * sigma_A\n\n    results = []\n\n    # --- Testing Phase ---\n    for case in test_cases:\n        r = case[\"r\"]\n        x_test_usd = case[\"x_usd\"]\n        \n        # Observed features in the test domain (EUR)\n        x_test_eur = r * x_test_usd\n        \n        # Ground-truth labels, always based on USD price\n        y_test_true = theta_0 + theta_1 * x_test_usd\n        \n        # --- Strategy T1 (train-statistics on observed) ---\n        z_t1 = (x_test_eur - mu_A) / sigma_A\n        y_hat_t1 = w_hat * z_t1 + c_hat\n        rmse_t1 = np.sqrt(np.mean((y_hat_t1 - y_test_true)**2))\n        results.append(rmse_t1)\n        \n        # --- Strategy T2 (per-domain standardization) ---\n        mu_B = np.mean(x_test_eur)\n        sigma_B = np.std(x_test_eur) # ddof=0 for population std dev\n        \n        # Handle the case of zero standard deviation, although not expected here\n        if sigma_B > 1e-9:\n            z_t2 = (x_test_eur - mu_B) / sigma_B\n        else:\n            z_t2 = np.zeros_like(x_test_eur)\n            \n        y_hat_t2 = w_hat * z_t2 + c_hat\n        rmse_t2 = np.sqrt(np.mean((y_hat_t2 - y_test_true)**2))\n        results.append(rmse_t2)\n        \n        # --- Strategy T3 (currency-aware then train-statistics) ---\n        # Reconstruct the feature in the original domain (USD)\n        x_test_usd_reconstructed = x_test_eur / r\n        z_t3 = (x_test_usd_reconstructed - mu_A) / sigma_A\n        y_hat_t3 = w_hat * z_t3 + c_hat\n        rmse_t3 = np.sqrt(np.mean((y_hat_t3 - y_test_true)**2))\n        results.append(rmse_t3)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3160364"}]}