{"hands_on_practices": [{"introduction": "Before diving into complex algorithms, it's crucial to have a solid grasp of the foundational building blocks of convex optimization. This first practice focuses on the properties of convex functions and the concept of the subgradient, which generalizes the standard gradient to non-differentiable functions. By first proving a key result about function composition and then computing subgradients for the widely used hinge loss, you will bridge the gap between abstract theory and its concrete application in machine learning models [@problem_id:3125992].", "problem": "Consider the function composition $f(w) = g(Aw)$ where $g:\\mathbb{R}^m \\to \\mathbb{R}$ is convex and $A:\\mathbb{R}^d \\to \\mathbb{R}^m$ is linear. Use the definition of convexity and the properties of linear maps as the fundamental base. You must proceed from first principles: the definition of convexity states that a function $h$ is convex if for all $x,y$ in its domain and all $t \\in [0,1]$, \n$$\nh(tx + (1-t)y) \\leq t\\,h(x) + (1-t)\\,h(y),\n$$ \nand linearity means $A(tx + (1-t)y) = t\\,A x + (1-t)\\,A y$ for all $x,y$ and all $t \\in [0,1]$.\n\nTask $1$: Prove that the composition $f(w) = g(Aw)$ is convex under the assumptions that $g$ is convex and $A$ is linear. Your proof must rely solely on the definition of convexity and linearity, with no shortcut formulas.\n\nTask $2$: Construct a concrete dataset and a convex piecewise linear function $g$ suitable for statistical learning, and analyze the subgradients of $f$. Let the dataset consist of $n = 2$ labeled examples in $\\mathbb{R}^2$:\n- Feature vectors $x_1 = (1,0)$ and $x_2 = (0,1)$.\n- Labels $y_1 = 1$ and $y_2 = -1$.\n\nDefine the linear map $A$ by stacking the rows $y_i x_i^\\top$, that is,\n$$\nA = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix}.\n$$\nDefine the convex piecewise linear function $g:\\mathbb{R}^2 \\to \\mathbb{R}$ by the hinge loss\n$$\ng(z) = \\sum_{i=1}^{2} \\max\\big(0,\\, 1 - z_i\\big),\n$$\nwhere $z = (z_1,z_2) \\in \\mathbb{R}^2$. Observe that $g$ is the sum of pointwise maxima of affine functions and is therefore convex and piecewise linear.\n\nUsing these definitions, let $f(w) = g(Aw)$ for $w \\in \\mathbb{R}^2$. For any $w$, define the vector $z = Aw$ and the subgradient selection rule for $g$ coordinate-wise as follows:\n- If $z_i  1$, set $s_i = -1$.\n- If $z_i  1$, set $s_i = 0$.\n- If $z_i = 1$, select the canonical representative $s_i = -\\tfrac{1}{2}$ from the subdifferential interval $[-1,0]$.\n\nWith this selection rule, compute one subgradient of $f$ at $w$ via\n$$\n\\partial f(w) \\ni A^\\top s,\n$$\nwhere $s = (s_1,s_2)$ is defined as above.\n\nTask $3$: Verify convexity numerically on specified test cases and compute subgradients for edge and interior cases. Use the following test suite:\n- Convexity checks with the inequality for $f$:\n  $$\n  f(t w_1 + (1-t) w_2) \\le t\\, f(w_1) + (1-t)\\, f(w_2),\n  $$\n  evaluated at:\n  - Case $1$: $w_1 = (0,0)$, $w_2 = (2,-2)$, $t = \\tfrac{1}{3}$.\n  - Case $2$: $w_1 = (0,0)$, $w_2 = (2,-2)$, $t = 0$.\n  - Case $3$: $w_1 = (0,0)$, $w_2 = (2,-2)$, $t = 1$.\n- Subgradient computations at the following points:\n  - Point $a$: $w_a = (0,0)$.\n  - Point $b$: $w_b = (2,-2)$.\n  - Point $c$: $w_c = (1,-1)$.\n\nFor each of the points $w_a$, $w_b$, and $w_c$, compute $f(w)$ (as a real number) and the selected subgradient $A^\\top s$ (as a two-dimensional vector) according to the rule above.\n\nFinal output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The order must be:\n$$\n\\big[\\, \\text{convexity\\_case\\_1},\\ \\text{convexity\\_case\\_2},\\ \\text{convexity\\_case\\_3},\\ f(w_a),\\ \\partial f(w_a),\\ f(w_b),\\ \\partial f(w_b),\\ f(w_c),\\ \\partial f(w_c) \\,\\big],\n$$\nwhere the convexity cases are booleans, each $f(w)$ is a real number, and each $\\partial f(w)$ is a list of two real numbers. No physical units, angle units, or percentages are involved; all outputs are unitless real numbers or booleans.", "solution": "The validity of the problem statement is hereby confirmed. The problem is scientifically grounded in the principles of convex analysis and its application to statistical learning. It is well-posed, with all components precisely defined, objective, and self-contained. The tasks are logically structured, starting with a theoretical proof, followed by numerical verification and computation, which is a standard pedagogical approach in mathematics and engineering.\n\n**Task 1: Proof of Convexity of the Composition**\n\nWe are asked to prove that the function $f(w) = g(Aw)$ is convex, given that $g: \\mathbb{R}^m \\to \\mathbb{R}$ is a convex function and $A: \\mathbb{R}^d \\to \\mathbb{R}^m$ is a linear map. The proof must proceed from the first principles of convexity and linearity.\n\nLet $w_1, w_2$ be any two vectors in the domain of $f$, which is $\\mathbb{R}^d$. Let $t$ be any scalar in the interval $[0, 1]$. To prove that $f$ is convex, we must show that the following inequality holds:\n$$\nf(t w_1 + (1-t) w_2) \\le t f(w_1) + (1-t) f(w_2)\n$$\n\nWe begin by evaluating the left-hand side of the inequality using the definition of $f(w)$:\n$$\nf(t w_1 + (1-t) w_2) = g(A(t w_1 + (1-t) w_2))\n$$\nWe are given that $A$ is a linear map. By the definition of linearity, for any vectors $x, y$ and scalar $t \\in [0, 1]$, $A(tx + (1-t)y) = t Ax + (1-t) Ay$.Applying this property to our expression, we get:\n$$\ng(A(t w_1 + (1-t) w_2)) = g(t A w_1 + (1-t) A w_2)\n$$\nTo simplify the notation, let us define two vectors in $\\mathbb{R}^m$: $z_1 = A w_1$ and $z_2 = A w_2$. The expression becomes:\n$$\ng(t z_1 + (1-t) z_2)\n$$\nNow, we use the given property that the function $g$ is convex. By the definition of convexity for $g$, for any $z_1, z_2$ in its domain and any $t \\in [0, 1]$, we have:\n$$\ng(t z_1 + (1-t) z_2) \\le t g(z_1) + (1-t) g(z_2)\n$$\nSubstituting back the definitions $z_1 = A w_1$ and $z_2 = A w_2$:\n$$\nt g(z_1) + (1-t) g(z_2) = t g(A w_1) + (1-t) g(A w_2)\n$$\nFinally, we use the definition of $f$ again, $f(w) = g(Aw)$, to relate this expression back to $f$:\n$$\nt g(A w_1) + (1-t) g(A w_2) = t f(w_1) + (1-t) f(w_2)\n$$\nBy connecting the chain of expressions and inequalities, we have shown:\n$$\nf(t w_1 + (1-t) w_2) = g(t Aw_1 + (1-t) Aw_2) \\le t g(Aw_1) + (1-t) g(Aw_2) = t f(w_1) + (1-t) f(w_2)\n$$\nThus, $f(t w_1 + (1-t) w_2) \\le t f(w_1) + (1-t) f(w_2)$, which completes the proof that the function $f(w) = g(Aw)$ is convex.\n\n**Task 2  3: Numerical Verification and Subgradient Computation**\n\nWe are given the specific forms of the linear map $A$ and the convex function $g$. Let's formulate the function $f(w)$ explicitly.\nThe weight vector is $w = \\begin{pmatrix} w_x \\\\ w_y \\end{pmatrix} \\in \\mathbb{R}^2$.\nThe linear map is $A = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix}$.\nThe transformation $z = Aw$ is:\n$$\nz = \\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix} \\begin{pmatrix} w_x \\\\ w_y \\end{pmatrix} = \\begin{pmatrix} w_x \\\\ -w_y \\end{pmatrix}\n$$\nThe function $g(z)$ is the hinge loss $g(z) = \\max(0, 1-z_1) + \\max(0, 1-z_2)$.\nSubstituting $z_1=w_x$ and $z_2=-w_y$ into $g(z)$, we get the explicit form of $f(w)$:\n$$\nf(w) = \\max(0, 1-w_x) + \\max(0, 1 - (-w_y)) = \\max(0, 1-w_x) + \\max(0, 1+w_y)\n$$\n\n**Convexity Checks**\nWe check the inequality $f(t w_1 + (1-t) w_2) \\le t f(w_1) + (1-t) f(w_2)$ for $w_1 = (0,0)$ and $w_2 = (2,-2)$.\nFirst, evaluate the function at the endpoints:\n$f(w_1) = f(0,0) = \\max(0, 1-0) + \\max(0, 1+0) = 1 + 1 = 2$.\n$f(w_2) = f(2,-2) = \\max(0, 1-2) + \\max(0, 1+(-2)) = \\max(0,-1) + \\max(0,-1) = 0 + 0 = 0$.\n\nCase 1: $t = \\frac{1}{3}$.\nThe interpolated point is $w_{mix} = \\frac{1}{3}w_1 + \\frac{2}{3}w_2 = \\frac{2}{3}(2,-2) = (\\frac{4}{3}, -\\frac{4}{3})$.\nLHS: $f(w_{mix}) = \\max(0, 1-\\frac{4}{3}) + \\max(0, 1-\\frac{4}{3}) = \\max(0, -\\frac{1}{3}) + \\max(0, -\\frac{1}{3}) = 0$.\nRHS: $t f(w_1) + (1-t) f(w_2) = \\frac{1}{3}(2) + \\frac{2}{3}(0) = \\frac{2}{3}$.\nThe inequality is $0 \\le \\frac{2}{3}$, which is true.\n\nCase 2: $t = 0$.\nThe inequality becomes $f(w_2) \\le f(w_2)$, which is $0 \\le 0$, a true statement.\n\nCase 3: $t = 1$.\nThe inequality becomes $f(w_1) \\le f(w_1)$, which is $2 \\le 2$, a true statement.\n\n**Subgradient Computations**\nA subgradient of $f(w)$ is computed using the chain rule $\\partial f(w) \\ni A^\\top s$, where $s \\in \\partial g(z)$ and $z = Aw$.\nGiven $A = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix}$, its transpose is $A^\\top = A$.\nThe subgradient is $\\partial f(w) \\ni A^\\top s = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix} \\begin{pmatrix} s_1 \\\\ s_2 \\end{pmatrix} = \\begin{pmatrix} s_1 \\\\ -s_2 \\end{pmatrix}$.\nThe components of $s=(s_1, s_2)$ are determined by $z=(w_x, -w_y)$ as per the rule:\n- If $z_i  1$, $s_i = -1$.\n- If $z_i  1$, $s_i = 0$.\n- If $z_i = 1$, $s_i = -1/2$.\n\nPoint a: $w_a = (0,0)$.\n$f(w_a) = 2$.\n$z = Aw_a = (0,0)$, so $z_1 = 0  1$ and $z_2 = 0  1$.\nThis gives $s_1 = -1$ and $s_2 = -1$.\n$\\partial f(w_a) \\ni \\begin{pmatrix} s_1 \\\\ -s_2 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -(-1) \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}$.\n\nPoint b: $w_b = (2,-2)$.\n$f(w_b) = 0$.\n$z = Aw_b = (2, -(-2)) = (2,2)$, so $z_1 = 2  1$ and $z_2 = 2  1$.\nThis gives $s_1 = 0$ and $s_2 = 0$.\n$\\partial f(w_b) \\ni \\begin{pmatrix} s_1 \\\\ -s_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n\nPoint c: $w_c = (1,-1)$.\n$f(w_c) = 0$.\n$z = Aw_c = (1, -(-1)) = (1,1)$, so $z_1 = 1$ and $z_2 = 1$. Both are at the kink.\nThe rule specifies $s_1 = -1/2$ and $s_2 = -1/2$.\n$\\partial f(w_c) \\ni \\begin{pmatrix} s_1 \\\\ -s_2 \\end{pmatrix} = \\begin{pmatrix} -1/2 \\\\ -(-1/2) \\end{pmatrix} = \\begin{pmatrix} -0.5 \\\\ 0.5 \\end{pmatrix}$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs the convexity checks and subgradient computations as per the problem statement.\n    \"\"\"\n\n    # Define the base function f(w) based on the problem derivation\n    def f(w):\n        \"\"\"Computes f(w) = max(0, 1-w_x) + max(0, 1+w_y).\"\"\"\n        w = np.asarray(w)\n        return np.maximum(0, 1 - w[0]) + np.maximum(0, 1 + w[1])\n\n    # Define the subgradient computation function\n    def compute_subgradient(w):\n        \"\"\"Computes a subgradient of f at w using the specified rule.\"\"\"\n        w = np.asarray(w)\n        z1 = w[0]\n        z2 = -w[1]\n\n        # Determine s1 based on z1\n        if z1  1:\n            s1 = -1.0\n        elif z1  1:\n            s1 = 0.0\n        else:  # z1 == 1\n            s1 = -0.5\n\n        # Determine s2 based on z2\n        if z2  1:\n            s2 = -1.0\n        elif z2  1:\n            s2 = 0.0\n        else:  # z2 == 1\n            s2 = -0.5\n\n        # Compute subgradient of f(w) using the chain rule: A^T * s\n        # A^T is [[1, 0], [0, -1]]\n        subgrad_f = np.array([s1, -s2])\n        return subgrad_f.tolist()\n\n    # --- Task 3: Numerical Verification and Computation ---\n    \n    results = []\n\n    # Convexity checks\n    w1 = np.array([0.0, 0.0])\n    w2 = np.array([2.0, -2.0])\n    \n    # Case 1: t = 1/3\n    t1 = 1.0 / 3.0\n    w_mix1 = t1 * w1 + (1 - t1) * w2\n    lhs1 = f(w_mix1)\n    rhs1 = t1 * f(w1) + (1 - t1) * f(w2)\n    results.append(lhs1 = rhs1)\n\n    # Case 2: t = 0\n    t2 = 0.0\n    w_mix2 = t2 * w1 + (1 - t2) * w2\n    lhs2 = f(w_mix2)\n    rhs2 = t2 * f(w1) + (1 - t2) * f(w2)\n    results.append(lhs2 = rhs2)\n    \n    # Case 3: t = 1\n    t3 = 1.0\n    w_mix3 = t3 * w1 + (1 - t3) * w2\n    lhs3 = f(w_mix3)\n    rhs3 = t3 * f(w1) + (1 - t3) * f(w2)\n    results.append(lhs3 = rhs3)\n\n    # Subgradient computations\n    # Point a: w_a = (0,0)\n    w_a = (0.0, 0.0)\n    results.append(f(w_a))\n    results.append(compute_subgradient(w_a))\n\n    # Point b: w_b = (2,-2)\n    w_b = (2.0, -2.0)\n    results.append(f(w_b))\n    results.append(compute_subgradient(w_b))\n\n    # Point c: w_c = (1,-1)\n    w_c = (1.0, -1.0)\n    results.append(f(w_c))\n    results.append(compute_subgradient(w_c))\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3125992"}, {"introduction": "Many modern statistical learning problems, such as the LASSO for sparse regression, involve minimizing an objective function composed of a smooth data-fitting term and a non-smooth regularizer like the $\\ell_1$-norm. This practice guides you through the implementation of the proximal gradient method, a powerful and widely used algorithm designed specifically for such composite optimization problems. You will not only code the algorithm but also empirically verify its convergence rates, forging a direct link between theoretical concepts like the Lipschitz constant $L$ and the strong convexity constant $\\mu$ and the algorithm's real-world performance [@problem_id:3126043].", "problem": "Consider the composite optimization problem in statistical learning where the objective is the sum of a smooth convex term and a convex non-smooth regularizer. Let $f(w) = g(w) + h(w)$ for $w \\in \\mathbb{R}^n$, where $g$ is differentiable and convex with a Lipschitz-continuous gradient, and $h$ is convex and possibly non-smooth but proximable. Specifically, you will study the case\n$$\ng(w) = \\tfrac{1}{2}\\lVert A w - b \\rVert_2^2,\\qquad h(w) = \\lambda \\lVert w \\rVert_1,\n$$\nwith the following fundamental definitions and facts as the starting point:\n- The gradient of the smooth term is $\\nabla g(w) = A^\\top (A w - b)$.\n- The gradient of $g$ is $L$-Lipschitz if there exists $L \\ge 0$ such that $\\lVert \\nabla g(u) - \\nabla g(v) \\rVert_2 \\le L \\lVert u - v \\rVert_2$ for all $u,v$. For the quadratic $g$ above, the smallest valid $L$ equals the spectral norm of $A^\\top A$, that is $L = \\lambda_{\\max}(A^\\top A)$.\n- The function $g$ is $\\mu$-strongly convex if $g(v) \\ge g(u) + \\nabla g(u)^\\top (v-u) + \\tfrac{\\mu}{2} \\lVert v-u \\rVert_2^2$ for all $u,v$. For the quadratic $g$ above, the largest valid $\\mu$ equals the smallest eigenvalue of $A^\\top A$, that is $\\mu = \\lambda_{\\min}(A^\\top A)$, which is strictly positive if and only if $A$ has full column rank.\n- The proximal map of $h$ with stepsize $\\alpha  0$ is $\\mathrm{prox}_{\\alpha h}(v) = \\arg\\min_{u \\in \\mathbb{R}^n} \\left\\{ h(u) + \\tfrac{1}{2\\alpha} \\lVert u - v \\rVert_2^2 \\right\\}$.\n\nYou will implement the proximal gradient method with a fixed stepsize $\\alpha = 1/L$, where each iteration is\n$$\nw^{k+1} = \\mathrm{prox}_{\\alpha h}\\big(w^k - \\alpha \\nabla g(w^k)\\big).\n$$\nFor $h(w) = \\lambda \\lVert w \\rVert_1$, the proximal map is the coordinate-wise soft-thresholding, which is a closed-form operation.\n\nYour tasks:\n1. For each test case, compute $L = \\lambda_{\\max}(A^\\top A)$ and $\\mu = \\lambda_{\\min}(A^\\top A)$.\n2. Implement proximal gradient with stepsize $\\alpha = 1/L$ from the given initial point $w^0$.\n3. Obtain a high-accuracy reference solution $w^\\star$ by running the algorithm for a large number of iterations to near-stationarity, and let $f^\\star = f(w^\\star)$.\n4. Analyze convergence as follows:\n   - If $\\mu  0$, estimate an empirical linear factor by computing, over a tail segment of the iterates, the median of the ratios\n     $$\n     r_k = \\frac{\\lVert w^{k+1} - w^\\star \\rVert_2}{\\lVert w^{k} - w^\\star \\rVert_2},\n     $$\n     skipping indices with zero denominators. Denote this median by $q_{\\text{emp}}$. Also compute the theoretically predicted worst-case factor $q_{\\text{th}}$ that follows from the standard analysis of proximal gradient under $L$-Lipschitz continuity and $\\mu$-strong convexity of $g$ with stepsize $\\alpha = 1/L$. Your program should then report whether the empirical factor does not exceed the theoretical prediction up to a small tolerance, encoded as a boolean.\n   - If $\\mu = 0$, set $q_{\\text{th}} = -1.0$ and $q_{\\text{emp}} = -1.0$ as sentinels and verify the sublinear behavior by forming the tail sequence $c_k = k \\cdot (f(w^k) - f^\\star)$ and checking whether it is essentially nonincreasing within a small numerical tolerance on most steps; report this as a boolean.\n\nImplementation details to enforce scientific realism and testability:\n- Use the soft-thresholding formula for the proximal map of the $\\ell_1$-norm.\n- Use the Euclidean norm $\\lVert \\cdot \\rVert_2$ throughout.\n- To approximate $w^\\star$, iterate the method for $N_\\star = 20000$ steps starting from the given $w^0$.\n- For convergence diagnostics, run $K = 800$ iterations from the same initial point $w^0$ and use only the last $T = 200$ steps to compute empirical factors or sublinear checks.\n- For the strongly convex check, accept $q_{\\text{emp}} \\le q_{\\text{th}} + \\varepsilon_{\\text{lin}}$ with $\\varepsilon_{\\text{lin}} = 10^{-2}$ as success.\n- For the sublinear check when $\\mu = 0$, treat the sequence $\\{c_k\\}$ as essentially nonincreasing if at least a fraction $p = 0.95$ of the consecutive tail differences satisfy $c_{k+1} \\le c_k + \\varepsilon_{\\text{sub}}$ with $\\varepsilon_{\\text{sub}} = 10^{-9}$.\n- If $\\mu$ computed from eigenvalues is smaller than a numerical floor $\\delta = 10^{-12}$, treat it as zero for the purpose of deciding the branch $\\mu = 0$ versus $\\mu  0$.\n\nTest suite:\nProvide results for the following three cases, each specified by $(A,b,\\lambda,w^0)$ with explicit numeric entries. All numbers are dimensionless.\n- Case $1$ (well-conditioned and strongly convex):\n  $$\n  A = \\begin{bmatrix}\n  3  0\\\\\n  0  2\\\\\n  0  0\n  \\end{bmatrix},\\quad\n  b = \\begin{bmatrix}\n  1\\\\\n  -2\\\\\n  0\n  \\end{bmatrix},\\quad\n  \\lambda = 0.2,\\quad\n  w^0 = \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix}.\n  $$\n- Case $2$ (rank-deficient, not strongly convex):\n  $$\n  A = \\begin{bmatrix}\n  1  0\\\\\n  1  0\\\\\n  0  0\n  \\end{bmatrix},\\quad\n  b = \\begin{bmatrix}\n  1\\\\\n  0\\\\\n  0\n  \\end{bmatrix},\\quad\n  \\lambda = 0.1,\\quad\n  w^0 = \\begin{bmatrix} 0.5 \\\\ 0.5 \\end{bmatrix}.\n  $$\n- Case $3$ (ill-conditioned and strongly convex):\n  $$\n  A = \\begin{bmatrix}\n  10  0\\\\\n  0  1\\\\\n  0  0\n  \\end{bmatrix},\\quad\n  b = \\begin{bmatrix}\n  3\\\\\n  -1\\\\\n  0\n  \\end{bmatrix},\\quad\n  \\lambda = 0.05,\\quad\n  w^0 = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}.\n  $$\n\nRequired outputs and format:\n- For each case in the order above, compute and output the sequence of five values\n  $$\n  \\big[L,\\ \\mu,\\ q_{\\text{th}},\\ q_{\\text{emp}},\\ \\text{check}\\big],\n  $$\n  where $L$ and $\\mu$ are as defined, $q_{\\text{th}}$ is the theoretically predicted worst-case linear factor when $\\mu  0$ (and $-1.0$ when $\\mu = 0$), $q_{\\text{emp}}$ is the empirical factor as defined above (and $-1.0$ when $\\mu = 0$), and $\\text{check}$ is a boolean as defined above.\n- Your program should produce a single line of output containing all results concatenated across the three cases into one comma-separated list enclosed in square brackets, in the order\n  $$\n  \\big[L_1,\\mu_1,q_{\\text{th},1},q_{\\text{emp},1},\\text{check}_1,\\ L_2,\\mu_2,q_{\\text{th},2},q_{\\text{emp},2},\\text{check}_2,\\ L_3,\\mu_3,q_{\\text{th},3},q_{\\text{emp},3},\\text{check}_3\\big].\n  $$", "solution": "The user wants to analyze the convergence of the proximal gradient method for a LASSO-type problem. The problem is well-defined, scientifically sound, and all necessary parameters and procedures are explicitly stated. I will proceed with a full solution.\n\nThe objective function to minimize is $f(w) = g(w) + h(w)$, where $w \\in \\mathbb{R}^n$. The components are:\n- A smooth, convex loss term: $g(w) = \\frac{1}{2}\\lVert A w - b \\rVert_2^2$\n- A convex, non-smooth regularization term: $h(w) = \\lambda \\lVert w \\rVert_1$\n\nThe proximal gradient method updates the weight vector $w$ iteratively. The $k$-th iteration is given by:\n$$\nw^{k+1} = \\mathrm{prox}_{\\alpha h}\\left(w^k - \\alpha \\nabla g(w^k)\\right)\n$$\nwhere $\\alpha  0$ is the stepsize.\n\nFirst, we need the components for this iteration:\n1.  **The gradient of $g(w)$**: The gradient of the quadratic loss term $g(w)$ is:\n    $$\n    \\nabla g(w) = A^\\top(A w - b)\n    $$\n2.  **The proximal map of $h(w)$**: For $h(w) = \\lambda \\lVert w \\rVert_1$, the proximal operator is the soft-thresholding function, which applies element-wise to a vector $v$:\n    $$\n    [\\mathrm{prox}_{\\alpha h}(v)]_i = \\mathrm{sign}(v_i) \\max(|v_i| - \\alpha \\lambda, 0)\n    $$\n    This operation effectively shrinks the components of $v$ towards zero, setting small components to exactly zero.\n\nThe convergence rate of the proximal gradient method depends on the properties of $g(w)$, specifically its gradient's Lipschitz constant $L$ and its strong convexity constant $\\mu$.\n-   The Lipschitz constant $L$ for $\\nabla g(w)$ is the largest eigenvalue (spectral norm) of the matrix $A^\\top A$. We denote this as $L = \\lambda_{\\max}(A^\\top A)$.\n-   The strong convexity constant $\\mu$ for $g(w)$ is the smallest eigenvalue of $A^\\top A$. We denote this as $\\mu = \\lambda_{\\min}(A^\\top A)$. $g(w)$ is strongly convex if and only if $\\mu  0$, which occurs when $A$ has full column rank.\n\nThe problem specifies a fixed stepsize $\\alpha = 1/L$.\n\nThe solution process for each test case involves the following steps:\n1.  **Compute Constants**: Given the matrix $A$, we form $A^\\top A$ and compute its eigenvalues to find $L = \\lambda_{\\max}(A^\\top A)$ and $\\mu = \\lambda_{\\min}(A^\\top A)$. We apply a numerical floor $\\delta = 10^{-12}$: if the computed $\\mu$ is less than $\\delta$, we treat it as $0$.\n\n2.  **Find Reference Solution**: We run the proximal gradient algorithm for a large number of iterations, $N_\\star = 20000$, starting from the given initial point $w^0$. The final iterate is taken as a high-accuracy approximation of the true solution, $w^\\star$. The optimal function value is then $f^\\star = f(w^\\star)$.\n\n3.  **Generate Iterates for Analysis**: We run the algorithm again from $w^0$ for $K = 800$ iterations, storing the entire sequence of iterates $\\{w^0, w^1, \\dots, w^K\\}$.\n\n4.  **Analyze Convergence**: The analysis depends on whether $\\mu  0$.\n\n    **Case 1: Strongly Convex ($\\mu  0$)**\n    - The theory of proximal gradient descent with stepsize $\\alpha=1/L$ predicts linear convergence of the iterates to the solution $w^\\star$. The distance to the optimum is expected to decrease by a constant factor at each iteration.\n    - The theoretical worst-case convergence factor $q_{\\text{th}}$ is given by:\n      $$\n      q_{\\text{th}} = \\max\\left(\\left|1 - \\frac{\\mu}{L}\\right|, \\left|1 - \\frac{L}{L}\\right|\\right) = 1 - \\frac{\\mu}{L}\n      $$\n      since $\\mu \\le L$.\n    - We estimate the empirical convergence factor $q_{\\text{emp}}$ from the tail of the generated iterates (the last $T=200$ steps). For each step $k$ in this tail, we compute the ratio:\n      $$\n      r_k = \\frac{\\lVert w^{k+1} - w^\\star \\rVert_2}{\\lVert w^{k} - w^\\star \\rVert_2}\n      $$\n    - The empirical factor $q_{\\text{emp}}$ is the median of these ratios $\\{r_k\\}$.\n    - The final check verifies if the empirical rate is consistent with the theory, i.e., $q_{\\text{emp}} \\le q_{\\text{th}} + \\varepsilon_{\\text{lin}}$ for a tolerance $\\varepsilon_{\\text{lin}} = 10^{-2}$.\n\n    **Case 2: Convex, not Strongly Convex ($\\mu = 0$)**\n    - When $g(w)$ is not strongly convex, the convergence rate is sublinear. Theory predicts $f(w^k) - f^\\star = \\mathcal{O}(1/k)$.\n    - This implies that the sequence $c_k = k \\cdot (f(w^k) - f^\\star)$ should be bounded. We check for a more specific property: whether this sequence is essentially non-increasing in the tail.\n    - We set sentinel values $q_{\\text{th}} = -1.0$ and $q_{\\text{emp}} = -1.0$.\n    - For the last $T=200$ steps of the algorithm (from $k=K-T$ to $k=K-1$), we check if the condition $c_{k+1} \\le c_k + \\varepsilon_{\\text{sub}}$ holds, where $\\varepsilon_{\\text{sub}} = 10^{-9}$ is a small tolerance.\n    - The check is successful (evaluates to `True`) if this condition holds for at least a fraction $p=0.95$ of the steps in the tail.\n\nThis procedure is applied to each of the three test cases provided. The final output is a concatenated list of the five computed values ($L, \\mu, q_{\\text{th}}, q_{\\text{emp}}, \\text{check}$) for each case.", "answer": "```python\nimport numpy as np\n\n# Global constants from the problem statement\nN_STAR = 20000\nK = 800\nT = 200\nDELTA = 1e-12\nEPSILON_LIN = 1e-2\nEPSILON_SUB = 1e-9\nP = 0.95\n\ndef g(w, A, b):\n    \"\"\"Computes the value of the smooth term g(w).\"\"\"\n    return 0.5 * np.linalg.norm(A @ w - b)**2\n\ndef h(w, lambda_reg):\n    \"\"\"Computes the value of the non-smooth term h(w).\"\"\"\n    return lambda_reg * np.linalg.norm(w, 1)\n\ndef f_obj(w, A, b, lambda_reg):\n    \"\"\"Computes the value of the objective function f(w).\"\"\"\n    return g(w, A, b) + h(w, lambda_reg)\n\ndef grad_g(w, A, b):\n    \"\"\"Computes the gradient of the smooth term g(w).\"\"\"\n    return A.T @ (A @ w - b)\n\ndef prox_l1(v, step_size, lambda_reg):\n    \"\"\"Computes the proximal operator for the L1 norm (soft-thresholding).\"\"\"\n    return np.sign(v) * np.maximum(0, np.abs(v) - step_size * lambda_reg)\n\ndef run_proximal_gradient(w0, A, b, lambda_reg, alpha, n_iters):\n    \"\"\"Runs the proximal gradient algorithm for a given number of iterations.\"\"\"\n    w = np.copy(w0)\n    w_history = [np.copy(w)]\n    for _ in range(n_iters):\n        gradient = grad_g(w, A, b)\n        w_update = w - alpha * gradient\n        w = prox_l1(w_update, alpha, lambda_reg)\n        w_history.append(np.copy(w))\n    return w_history\n\ndef analyze_convergence(iterates, w_star, L, mu, A, b, lambda_reg):\n    \"\"\"Analyzes the convergence of the iterates based on mu.\"\"\"\n    if mu  0:\n        # Strongly convex case\n        q_th = 1.0 - mu / L\n        \n        # Tail iterates from w^{K-T} to w^K (T+1 iterates)\n        tail_iterates = iterates[K - T : K + 1]\n        ratios = []\n        for i in range(T):\n            w_k = tail_iterates[i]\n            w_k_plus_1 = tail_iterates[i+1]\n            \n            denom = np.linalg.norm(w_k - w_star)\n            if denom  1e-15:  # Avoid division by zero\n                num = np.linalg.norm(w_k_plus_1 - w_star)\n                ratios.append(num / denom)\n        \n        q_emp = np.median(ratios) if ratios else 0.0\n        check = q_emp = q_th + EPSILON_LIN\n        \n    else:\n        # Convex, but not strongly convex case\n        q_th = -1.0\n        q_emp = -1.0\n        \n        f_star = f_obj(w_star, A, b, lambda_reg)\n        \n        success_count = 0\n        num_comparisons = T\n        \n        # Check c_{k+1} = c_k + eps for k from K-T to K-1\n        for k in range(K - T, K):\n            f_k = f_obj(iterates[k], A, b, lambda_reg)\n            f_k_plus_1 = f_obj(iterates[k+1], A, b, lambda_reg)\n\n            c_k = k * (f_k - f_star)\n            c_k_plus_1 = (k + 1) * (f_k_plus_1 - f_star)\n            \n            if c_k_plus_1 = c_k + EPSILON_SUB:\n                success_count += 1\n                \n        check = (success_count / num_comparisons) = P\n\n    return q_th, q_emp, check\n\ndef solve_case(A_list, b_list, lambda_reg, w0_list):\n    \"\"\"Solves a single test case from the problem statement.\"\"\"\n    A = np.array(A_list, dtype=float)\n    b = np.array(b_list, dtype=float)\n    w0 = np.array(w0_list, dtype=float)\n\n    # 1. Compute L and mu\n    AtA = A.T @ A\n    eigenvalues = np.linalg.eigvalsh(AtA)\n    L = np.max(eigenvalues) if eigenvalues.size  0 else 0.0\n    mu_raw = np.min(eigenvalues) if eigenvalues.size  0 else 0.0\n    mu = mu_raw if mu_raw = DELTA else 0.0\n    \n    alpha = 1.0 / L if L  0 else 1.0\n\n    # 2. Compute reference solution w_star\n    w_star_history = run_proximal_gradient(w0, A, b, lambda_reg, alpha, N_STAR)\n    w_star = w_star_history[-1]\n\n    # 3. Generate iterates for analysis\n    iterates = run_proximal_gradient(w0, A, b, lambda_reg, alpha, K)\n    \n    # 4. Analyze convergence\n    q_th, q_emp, check = analyze_convergence(iterates, w_star, L, mu, A, b, lambda_reg)\n    \n    return [L, mu, q_th, q_emp, str(check).lower()]\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    test_cases = [\n        # Case 1 (well-conditioned and strongly convex)\n        (\n            [[3, 0], [0, 2], [0, 0]], \n            [1, -2, 0], \n            0.2, \n            [2, -1]\n        ),\n        # Case 2 (rank-deficient, not strongly convex)\n        (\n            [[1, 0], [1, 0], [0, 0]], \n            [1, 0, 0], \n            0.1, \n            [0.5, 0.5]\n        ),\n        # Case 3 (ill-conditioned and strongly convex)\n        (\n            [[10, 0], [0, 1], [0, 0]], \n            [3, -1, 0], \n            0.05, \n            [2, 1]\n        ),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        A, b, lambda_reg, w0 = case\n        result = solve_case(A, b, lambda_reg, w0)\n        all_results.extend(result)\n        \n    # Format the final output string\n    formatted_results = []\n    for item in all_results:\n        if isinstance(item, float):\n            formatted_results.append(f\"{item:.10f}\".rstrip('0').rstrip('.'))\n        else:\n            formatted_results.append(str(item))\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3126043"}, {"introduction": "While standard gradient descent is a reliable optimization tool, its convergence can be slow. This practice explores Nesterov's accelerated gradient method, a seminal algorithm that significantly improves convergence speed for smooth convex functions, achieving a theoretically optimal rate. You will implement this method to empirically witness its accelerated $O(1/t^2)$ convergence and, just as importantly, diagnose its breakdown when the crucial assumption of a Lipschitz-continuous gradient is violated. This exercise provides a powerful lesson on both the remarkable power of acceleration techniques and the critical importance of their underlying theoretical conditions [@problem_id:3126019].", "problem": "You are tasked with implementing and empirically assessing an accelerated first-order optimization method for convex functions from the standpoint of gradients and convexity in statistical learning. The goal is to verify the theoretically expected convergence rate under smoothness assumptions and to diagnose the breakdown when the key smoothness assumption is violated. Your program must implement a single procedure to run the same accelerated method across all test cases and return a boolean decision per case.\n\nFundamental base and assumptions:\n- A function $f:\\mathbb{R}^d\\to\\mathbb{R}$ is convex if for all $\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^d$ and $\\theta\\in[0,1]$, $f(\\theta \\mathbf{x}+(1-\\theta)\\mathbf{y})\\le \\theta f(\\mathbf{x})+(1-\\theta) f(\\mathbf{y})$.\n- A differentiable function has an $L$-Lipschitz gradient if there exists $L\\ge 0$ such that $\\|\\nabla f(\\mathbf{x})-\\nabla f(\\mathbf{y})\\|_2\\le L\\|\\mathbf{x}-\\mathbf{y}\\|_2$ for all $\\mathbf{x},\\mathbf{y}$. This implies the descent lemma: $f(\\mathbf{y})\\le f(\\mathbf{x})+\\nabla f(\\mathbf{x})^\\top(\\mathbf{y}-\\mathbf{x})+\\frac{L}{2}\\|\\mathbf{y}-\\mathbf{x}\\|_2^2$.\n- Nesterov accelerated gradient (NAG) is an accelerated first-order method that, under the $L$-Lipschitz gradient assumption, attains the optimal worst-case rate $O(1/t^2)$ in terms of objective suboptimality $f(\\mathbf{x}_t)-f^\\star$, where $t$ denotes the iteration index and $f^\\star$ is the minimum value.\n\nYour tasks:\n- Implement a single-version Nesterov accelerated gradient method that uses step size $1/L$ where $L$ is provided to your program on a per-test-case basis. Use a standard constant step size $1/L$ and the classical Nesterov extrapolation schedule that maintains an auxiliary sequence and a momentum parameter; apply the same implementation to all test cases. Your implementation must operate purely by evaluating the gradient and must not use any line search, backtracking, or oracle beyond the provided $L$.\n- For each test case, run the accelerated method for a prescribed number of iterations $T$, starting from the provided initial point $\\mathbf{x}_0$. Record the sequence of objective values $f(\\mathbf{x}_t)$.\n- To empirically assess whether the observed rate is consistent with $O(1/t^2)$, do the following:\n  1. Let $e_t = f(\\mathbf{x}_t) - f^\\star$, where $f^\\star$ is known for each test case and provided below. Form the sequence $s_t = t^2 e_t$ for $t=1,2,\\dots,T$.\n  2. Consider the last window of iterations $t\\in\\{\\lfloor 0.6T\\rfloor,\\dots,T\\}$. Compute the least-squares slope $\\hat{\\alpha}$ of the regression of $\\log e_t$ versus $\\log t$ over this window. Also compute the boundedness ratio $R = \\max_{t \\text{ in window}} s_t \\,/\\, \\min_{t \\text{ in window}} s_t$.\n  3. Return a boolean decision that is true if and only if both conditions hold simultaneously: $\\hat{\\alpha}\\le -1.8$ and $R \\le 10$. If the sequence ever produces a non-finite objective value, return false.\n- Your program must aggregate these decisions for all test cases and print them in a single line as a comma-separated Python list, for example $[\\text{True},\\text{False},\\text{True}]$.\n\nImplement the method and run it on the following test suite:\n\n- Test case $\\mathbf{A}$ (one-dimensional smooth quadratic, happy path):\n  - Dimension $d=1$.\n  - Function $f(x) = \\tfrac{1}{2}\\, a x^2$ with $a=10$, so the gradient is $\\nabla f(x) = a x$. This is convex with $L=a=10$.\n  - Minimizer $x^\\star=0$ and $f^\\star=0$.\n  - Initial point $x_0=5$.\n  - Use $L=10$ and $T=300$ iterations.\n\n- Test case $\\mathbf{B}$ (higher-dimensional smooth quadratic with varying curvature):\n  - Dimension $d=5$.\n  - Function $f(\\mathbf{x}) = \\tfrac{1}{2}\\,\\mathbf{x}^\\top A \\mathbf{x}$ with $A=\\mathrm{diag}(1,3,5,10,20)$ so $\\nabla f(\\mathbf{x})=A\\mathbf{x}$. This is convex with $L=\\lambda_{\\max}(A)=20$.\n  - Minimizer $\\mathbf{x}^\\star=\\mathbf{0}$ and $f^\\star=0$.\n  - Initial point $\\mathbf{x}_0=[5,-4,3,-2,1]^\\top$.\n  - Use $L=20$ and $T=400$ iterations.\n\n- Test case $\\mathbf{C}$ (convex but gradient not globally Lipschitz; diagnosis of failure):\n  - Dimension $d=5$.\n  - Function $f(\\mathbf{x})=\\sum_{i=1}^d |x_i|^{3/2}$. This function is convex and continuously differentiable with gradient components $\\nabla_i f(\\mathbf{x})=\\tfrac{3}{2}\\,\\mathrm{sign}(x_i)\\,|x_i|^{1/2}$, but its gradient is not Lipschitz on $\\mathbb{R}^d$ because its Jacobian norm is unbounded near $\\mathbf{x}=\\mathbf{0}$.\n  - Minimizer $\\mathbf{x}^\\star=\\mathbf{0}$ and $f^\\star=0$.\n  - Initial point $\\mathbf{x}_0=[5,-4,3,-2,1]^\\top$.\n  - Force the accelerated method to use the same constant $L=20$ and run $T=400$ iterations.\n  - The expected outcome is that the observed behavior will not match $O(1/t^2)$ according to the decision rule above.\n\nNumerical requirements:\n- Angles are not involved.\n- No physical units are involved.\n- The final output of your program must be a single line containing the three boolean decisions for test cases $\\mathbf{A}$, $\\mathbf{B}$, and $\\mathbf{C}$, respectively, as a comma-separated list enclosed in square brackets, for example $[\\text{True},\\text{True},\\text{False}]$.\n\nYour program must be fully self-contained and must not read any input.", "solution": "The user-provided problem has been rigorously validated and found to be well-posed, scientifically grounded, and internally consistent. All necessary parameters and definitions are provided for a complete and unique solution. The problem requires the implementation and empirical analysis of Nesterov's Accelerated Gradient (NAG) method on three distinct test cases, designed to highlight the importance of the gradient's Lipschitz continuity for achieving accelerated convergence rates.\n\n### Principle and Algorithm Design\n\nNesterov's Accelerated Gradient is a first-order optimization algorithm that improves upon the convergence rate of standard gradient descent for a class of convex functions. For a convex function $f$ with an $L$-Lipschitz continuous gradient (i.e., a function that is $L$-smooth), standard gradient descent has a convergence rate for the objective suboptimality, $f(\\mathbf{x}_t) - f^\\star$, of $O(1/t)$. NAG introduces a \"momentum\" term that incorporates information from previous steps to accelerate convergence, achieving the optimal rate of $O(1/t^2)$ for this class of functions.\n\nThe core idea is to evaluate the gradient not at the current iterate $\\mathbf{x}_t$, but at an extrapolated point $\\mathbf{y}_t$ that represents an \"aggressive\" step in the direction of recent progress. The update rule combines a standard gradient step with a momentum step. A common and effective implementation of NAG, which we will use, maintains two sequences of iterates, $\\mathbf{x}_t$ and $\\mathbf{y}_t$, and proceeds as follows:\n\nLet the initial point be $\\mathbf{x}_0$. Set the auxiliary sequence initial point $\\mathbf{y}_0 = \\mathbf{x}_0$. For iterations $t=0, 1, 2, \\dots, T-1$:\n\n1.  **Gradient Step:** The primary sequence is updated by taking a gradient step from the auxiliary point $\\mathbf{y}_t$ with a step size $\\eta = 1/L$.\n    $$\n    \\mathbf{x}_{t+1} = \\mathbf{y}_t - \\frac{1}{L} \\nabla f(\\mathbf{y}_t)\n    $$\n\n2.  **Momentum Step:** The auxiliary sequence is updated by projecting forward from the new point $\\mathbf{x}_{t+1}$ along the direction of the most recent step $(\\mathbf{x}_{t+1} - \\mathbf{x}_t)$.\n    $$\n    \\mathbf{y}_{t+1} = \\mathbf{x}_{t+1} + \\beta_t (\\mathbf{x}_{t+1} - \\mathbf{x}_t)\n    $$\n    The momentum parameter $\\beta_t$ must be chosen carefully. A standard schedule that guarantees the $O(1/t^2)$ rate is $\\beta_t = \\frac{t}{t+3}$ for our $0$-indexed iteration counter $t$.\n\nThe sequence of iterates whose convergence we analyze is $\\{\\mathbf{x}_t\\}_{t=1}^T$.\n\n### Empirical Rate Verification\n\nThe theoretical convergence rate $f(\\mathbf{x}_t) - f^\\star = O(1/t^2)$ implies that the error $e_t = f(\\mathbf{x}_t) - f^\\star$ behaves like $C/t^2$ for some constant $C$ and large $t$. We verify this empirically using two conditions as specified:\n\n1.  **Power-Law Decay Rate:** Taking the logarithm, we get $\\log e_t \\approx \\log C - 2 \\log t$. This shows a linear relationship between $\\log e_t$ and $\\log t$ with a slope of $-2$. We compute the least-squares slope $\\hat{\\alpha}$ of this relationship over the latter part of the iterations ($t \\in \\{\\lfloor 0.6T\\rfloor, \\dots, T\\}$). The condition $\\hat{\\alpha} \\le -1.8$ checks if the observed rate is consistent with the theoretical prediction, allowing for minor finite-iteration deviations.\n\n2.  **Asymptotic Boundedness:** The expression $s_t = t^2 e_t$ should approach the constant $C$ as $t \\to \\infty$. We check if this sequence is \"asymptotically bounded\" by computing the ratio $R = \\max(s_t) / \\min(s_t)$ over the same analysis window. A small ratio indicates that $s_t$ is settling to a nearly constant value. The condition $R \\le 10$ provides a generous tolerance for this behavior.\n\nA test case is considered to demonstrate the accelerated rate if and only if both conditions are met.\n\n### Analysis of Test Cases\n\n-   **Test Cases A and B:** These cases involve quadratic functions, $f(x) = \\frac{1}{2}ax^2$ and $f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^\\top A \\mathbf{x}$. The gradients, $\\nabla f(x) = ax$ and $\\nabla f(\\mathbf{x}) = A\\mathbf{x}$, are linear and therefore globally Lipschitz continuous. The provided Lipschitz constants ($L=10$ for A, $L=20$ for B) are correct. As these functions perfectly satisfy the assumptions for NAG, we expect the method to achieve its theoretical $O(1/t^2)$ rate. The empirical analysis should confirm this, leading to a `True` decision for both cases.\n\n-   **Test Case C:** The function is $f(\\mathbf{x}) = \\sum_i |x_i|^{3/2}$. This function is convex, but its gradient, with components $\\nabla_i f(\\mathbf{x}) = \\frac{3}{2}\\mathrm{sign}(x_i)|x_i|^{1/2}$, is not globally Lipschitz continuous. The Hessian's diagonal elements, $\\frac{\\partial^2 f}{\\partial x_i^2} = \\frac{3}{4}|x_i|^{-1/2}$, are unbounded as $x_i \\to 0$. This means the local smoothness of the function worsens dramatically near the origin. The guarantee for the $O(1/t^2)$ rate of NAG does not hold. Using a fixed step size based on a constant $L=20$ is inappropriate; as the iterates approach the origin, the local Lipschitz constant can become much larger than $20$, making the step size $1/20$ too large and leading to slow convergence or instability. Consequently, the observed convergence rate is expected to be substantially slower than $O(1/t^2)$. The empirical test is designed to detect this failure, and we anticipate a `False` decision.\n\nThe implementation will follow this logic precisely, executing the same NAG algorithm for all cases and applying the specified decision rule.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the optimization problem across all test cases and print the results.\n    \"\"\"\n\n    def run_nesterov_accelerated_gradient(func_f, grad_f, x0, L, T):\n        \"\"\"\n        Implements Nesterov's Accelerated Gradient (NAG) method.\n\n        Args:\n            func_f: The objective function.\n            grad_f: The gradient of the objective function.\n            x0: The initial point.\n            L: The Lipschitz constant of the gradient.\n            T: The number of iterations.\n\n        Returns:\n            A list of objective values for iterations 1 to T, or None if a non-finite value is encountered.\n        \"\"\"\n        x_k = np.array(x0, dtype=np.float64)\n        y_k = np.array(x0, dtype=np.float64)\n        x_prev_k = np.array(x0, dtype=np.float64)\n        \n        objectives = []\n\n        for k in range(T): # Corresponds to iterations t=1, ..., T\n            x_prev_k = x_k\n            \n            # Gradient evaluation and update step for x\n            grad_val = grad_f(y_k)\n            if not np.all(np.isfinite(grad_val)):\n                return None\n            \n            x_k = y_k - (1.0 / L) * grad_val\n            \n            # Store objective value\n            obj_val = func_f(x_k)\n            if not np.isfinite(obj_val):\n                return None\n            objectives.append(obj_val)\n            \n            # Momentum update step for y\n            momentum_coeff = k / (k + 3.0)\n            y_k = x_k + momentum_coeff * (x_k - x_prev_k)\n            \n        return objectives\n\n    def analyze_convergence(objectives, f_star, T):\n        \"\"\"\n        Analyzes the convergence rate based on the sequence of objective values.\n\n        Args:\n            objectives: A list of T objective values.\n            f_star: The known minimum value of the function.\n            T: The total number of iterations.\n\n        Returns:\n            A boolean decision based on the specified criteria.\n        \"\"\"\n        if objectives is None:\n            return False\n\n        # Calculate errors e_t = f(x_t) - f_star for t=1,...,T\n        e_t = np.array([obj - f_star for obj in objectives])\n\n        # Define analysis window: iterations floor(0.6*T) to T\n        start_t = int(np.floor(0.6 * T))\n        if start_t  T:\n            return False \n        \n        window_indices = np.arange(start_t - 1, T)\n        if len(window_indices)  2:\n            return False\n\n        t_vals = window_indices + 1\n        e_vals = e_t[window_indices]\n        \n        # Filter out non-positive errors to avoid issues with log\n        positive_mask = e_vals  0\n        if np.sum(positive_mask)  2: # Need at least two points for regression\n            return False\n\n        t_log = np.log(t_vals[positive_mask])\n        e_log = np.log(e_vals[positive_mask])\n\n        # Condition 1: Check the slope of log-log plot\n        try:\n            slope, _ = np.polyfit(t_log, e_log, 1)\n        except np.linalg.LinAlgError:\n            return False # Should not happen with valid data\n        \n        cond1 = slope = -1.8\n\n        # Condition 2: Check the boundedness ratio of s_t = t^2 * e_t\n        s_t = (t_vals**2) * e_vals\n        s_t_valid = s_t[positive_mask]\n        \n        min_s_t = np.min(s_t_valid)\n        if min_s_t = 0:\n            return False\n            \n        max_s_t = np.max(s_t_valid)\n        R = max_s_t / min_s_t\n        cond2 = R = 10.0\n\n        return cond1 and cond2\n\n    # --- Test Cases Definition ---\n    # Case A\n    a_A = 10.0\n    func_A = lambda x: 0.5 * a_A * x**2\n    grad_A = lambda x: a_A * x\n    \n    # Case B\n    A_B = np.diag([1.0, 3.0, 5.0, 10.0, 20.0])\n    func_B = lambda x: 0.5 * x.T @ A_B @ x\n    grad_B = lambda x: A_B @ x\n\n    # Case C\n    # Note: np.sign(0) is 0, which gives the correct gradient at the origin.\n    func_C = lambda x: np.sum(np.power(np.abs(x), 1.5))\n    grad_C = lambda x: 1.5 * np.sign(x) * np.power(np.abs(x), 0.5)\n\n    test_cases = [\n        {\n            \"id\": \"A\",\n            \"func\": func_A, \"grad\": grad_A,\n            \"x0\": np.array([5.0]), \"L\": 10.0, \"T\": 300, \"f_star\": 0.0\n        },\n        {\n            \"id\": \"B\",\n            \"func\": func_B, \"grad\": grad_B,\n            \"x0\": np.array([5.0, -4.0, 3.0, -2.0, 1.0]), \"L\": 20.0, \"T\": 400, \"f_star\": 0.0\n        },\n        {\n            \"id\": \"C\",\n            \"func\": func_C, \"grad\": grad_C,\n            \"x0\": np.array([5.0, -4.0, 3.0, -2.0, 1.0]), \"L\": 20.0, \"T\": 400, \"f_star\": 0.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        objectives = run_nesterov_accelerated_gradient(\n            case[\"func\"], case[\"grad\"], case[\"x0\"], case[\"L\"], case[\"T\"]\n        )\n        decision = analyze_convergence(objectives, case[\"f_star\"], case[\"T\"])\n        results.append(decision)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3126019"}]}