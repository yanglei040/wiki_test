{"hands_on_practices": [{"introduction": "Choosing the right loss function is critical in regression. While the standard squared error ($L_2$) loss is mathematically convenient, its sensitivity to outliers can be a major drawback. This practice explores the Huber loss, a robust alternative that is less affected by extreme values, and investigates the important property of scale invariance by comparing these losses to a relative error metric. [@problem_id:3143114]", "problem": "Consider a univariate regression setting in which the predictor is a constant $b \\in \\mathbb{R}$ chosen to minimize an empirical loss over three targets $y_{1} = 1$, $y_{2} = 2$, and $y_{3} = 100$. You observe a scaled version of the targets $c y_{i}$ for a known scaling factor $c  0$. You will compare the behavior of the minimizer under the squared loss and the Huber loss, and then construct a scale-invariant alternative based on relative error.\n\nUse the following base definitions:\n- The squared loss is $\\ell_{2}(r) = r^{2}$.\n- The Huber loss with parameter $\\delta  0$ is\n$$\n\\ell_{\\mathrm{Huber}, \\delta}(r) = \n\\begin{cases}\n\\frac{1}{2} r^{2},  |r| \\leq \\delta, \\\\\n\\delta |r| - \\frac{1}{2} \\delta^{2},  |r|  \\delta.\n\\end{cases}\n$$\n\nLet $R_{\\ell}(b; c) = \\sum_{i=1}^{3} \\ell(c y_{i} - b)$ denote the empirical risk under loss $\\ell$ for the scaled targets $c y_{i}$.\n\n1. Derive from first principles the minimizer $b_{\\ell_{2}}^{\\ast}(c)$ of $R_{\\ell_{2}}(b; c)$ and explain how it transforms under scaling of the targets by $c$.\n2. For the Huber loss, work under the regime at the minimizer where the residual for $y_{3}$ is in the linear region and the residuals for $y_{1}$ and $y_{2}$ are in the quadratic region. Starting from the definition of the Huber loss and its derivative, derive the expression for the Huber minimizer $b_{\\mathrm{Huber}}^{\\ast}(c, \\delta)$ in this regime. Then, determine the corresponding conditions on $c$ and $\\delta$ that ensure this regime is valid (i.e., $|c y_{1} - b_{\\mathrm{Huber}}^{\\ast}(c, \\delta)| \\leq \\delta$, $|c y_{2} - b_{\\mathrm{Huber}}^{\\ast}(c, \\delta)| \\leq \\delta$, and $c y_{3} - b_{\\mathrm{Huber}}^{\\ast}(c, \\delta)  \\delta$).\n3. Propose the relative squared error loss\n$$\n\\ell_{\\mathrm{rel}}(r; y) = \\left( \\frac{r}{y} \\right)^{2},\n$$\nand derive from first principles the minimizer $b_{\\mathrm{rel}}^{\\ast}(c)$ of the empirical risk $R_{\\mathrm{rel}}(b; c) = \\sum_{i=1}^{3} \\left( \\frac{c y_{i} - b}{c y_{i}} \\right)^{2}$. Explain the scale behavior of $b_{\\mathrm{rel}}^{\\ast}(c)$ under the scaling factor $c$.\n\nFinally, define\n$$\nD(c, \\delta) = b_{\\mathrm{Huber}}^{\\ast}(c, \\delta) - b_{\\mathrm{rel}}^{\\ast}(c).\n$$\nUnder the regime specified in part 2, express $D(c, \\delta)$ as a single simplified closed-form analytic expression in terms of $c$ and $\\delta$. You do not need to round your answer.", "solution": "The problem requires the derivation and comparison of minimizers for three different loss functions in a simple regression setting. We will address each part of the problem sequentially.\n\nPart 1: Minimizer for the Squared Loss\nThe empirical risk for the squared loss, $\\ell_{2}(r) = r^{2}$, is given by $R_{\\ell_{2}}(b; c) = \\sum_{i=1}^{3} (c y_{i} - b)^{2}$. To find the minimizer $b_{\\ell_{2}}^{\\ast}(c)$, we compute the derivative of the empirical risk with respect to the parameter $b$ and set it to zero. Since $R_{\\ell_{2}}(b; c)$ is a convex function of $b$, the first-order condition identifies the unique global minimum.\n$$\n\\frac{d}{db} R_{\\ell_{2}}(b; c) = \\frac{d}{db} \\sum_{i=1}^{3} (c y_{i} - b)^{2} = \\sum_{i=1}^{3} 2(c y_{i} - b)(-1) = -2 \\sum_{i=1}^{3} (c y_{i} - b)\n$$\nSetting the derivative to zero yields:\n$$\n\\sum_{i=1}^{3} (c y_{i} - b) = 0 \\implies c \\sum_{i=1}^{3} y_{i} - 3b = 0\n$$\nSolving for $b$, we find that the minimizer is the sample mean of the scaled data points:\n$$\nb_{\\ell_{2}}^{\\ast}(c) = \\frac{c}{3} \\sum_{i=1}^{3} y_{i}\n$$\nSubstituting the given target values $y_{1} = 1$, $y_{2} = 2$, and $y_{3} = 100$:\n$$\nb_{\\ell_{2}}^{\\ast}(c) = \\frac{c(1 + 2 + 100)}{3} = \\frac{103c}{3}\n$$\nThe behavior of the minimizer under scaling by $c$ is that it is a linear function of $c$. Specifically, $b_{\\ell_{2}}^{\\ast}(c) = c \\cdot b_{\\ell_{2}}^{\\ast}(1)$. This property is known as scale equivariance.\n\nPart 2: Minimizer for the Huber Loss\nThe problem specifies a regime for the Huber loss minimizer where the residuals for $y_{1}$ and $y_{2}$ are in the quadratic region ($|r| \\leq \\delta$) and the residual for $y_{3}$ is in the linear region ($|r|  \\delta$). Given that $y_3=100$ is much larger than $y_1=1$ and $y_2=2$, the residual $c y_{3} - b$ will be positive. The regime conditions are thus: $|c y_{1} - b| \\leq \\delta$, $|c y_{2} - b| \\leq \\delta$, and $c y_{3} - b  \\delta$.\nUnder these conditions, the empirical risk is:\n$$\nR_{\\mathrm{Huber}}(b; c, \\delta) = \\frac{1}{2}(c y_{1} - b)^{2} + \\frac{1}{2}(c y_{2} - b)^{2} + \\left( \\delta(c y_{3} - b) - \\frac{1}{2}\\delta^{2} \\right)\n$$\nWe find the minimizer $b_{\\mathrm{Huber}}^{\\ast}(c, \\delta)$ by setting the derivative with respect to $b$ to zero:\n$$\n\\frac{d}{db} R_{\\mathrm{Huber}}(b; c, \\delta) = -(c y_{1} - b) - (c y_{2} - b) - \\delta = 0\n$$\n$$\n-c(y_{1} + y_{2}) + 2b - \\delta = 0 \\implies 2b = c(y_{1} + y_{2}) + \\delta\n$$\nSubstituting $y_{1} = 1$ and $y_{2} = 2$, the minimizer is:\n$$\nb_{\\mathrm{Huber}}^{\\ast}(c, \\delta) = \\frac{c(1 + 2) + \\delta}{2} = \\frac{3c + \\delta}{2}\n$$\nNext, we derive the conditions on $c$ and $\\delta$ that ensure this regime is valid by substituting $b_{\\mathrm{Huber}}^{\\ast}(c, \\delta)$ into the regime inequalities:\n1.  $|c y_{1} - b_{\\mathrm{Huber}}^{\\ast}| \\leq \\delta \\implies |c - \\frac{3c + \\delta}{2}| \\leq \\delta \\implies |\\frac{-c - \\delta}{2}| \\leq \\delta$. Since $c  0$ and $\\delta  0$, this becomes $\\frac{c+\\delta}{2} \\leq \\delta$, which simplifies to $c \\leq \\delta$.\n2.  $|c y_{2} - b_{\\mathrm{Huber}}^{\\ast}| \\leq \\delta \\implies |2c - \\frac{3c + \\delta}{2}| \\leq \\delta \\implies |\\frac{c - \\delta}{2}| \\leq \\delta$. This is equivalent to $-2\\delta \\leq c - \\delta \\leq 2\\delta$, or $-\\delta \\leq c \\leq 3\\delta$. Given $c0$, the condition is $0  c \\leq 3\\delta$.\n3.  $c y_{3} - b_{\\mathrm{Huber}}^{\\ast}  \\delta \\implies 100c - \\frac{3c + \\delta}{2}  \\delta \\implies 200c - 3c - \\delta  2\\delta \\implies 197c  3\\delta$, which gives $c  \\frac{3\\delta}{197}$.\nCombining all conditions ($c \\leq \\delta$, $c \\leq 3\\delta$, and $c  \\frac{3\\delta}{197}$), the required relationship is $\\frac{3\\delta}{197}  c \\leq \\delta$.\n\nPart 3: Minimizer for the Relative Squared Error Loss\nThe empirical risk for the relative squared error, $\\ell_{\\mathrm{rel}}(r; y) = (r/y)^2$, is given by:\n$$\nR_{\\mathrm{rel}}(b; c) = \\sum_{i=1}^{3} \\left( \\frac{c y_{i} - b}{c y_{i}} \\right)^{2} = \\sum_{i=1}^{3} \\left( 1 - \\frac{b}{c y_{i}} \\right)^{2}\n$$\nWe find the minimizer $b_{\\mathrm{rel}}^{\\ast}(c)$ by setting the derivative with respect to $b$ to zero:\n$$\n\\frac{d}{db} R_{\\mathrm{rel}}(b; c) = \\sum_{i=1}^{3} 2\\left( 1 - \\frac{b}{c y_{i}} \\right) \\left(-\\frac{1}{c y_{i}}\\right) = -\\frac{2}{c} \\sum_{i=1}^{3} \\left( \\frac{1}{y_{i}} - \\frac{b}{c y_{i}^{2}} \\right) = 0\n$$\n$$\n\\sum_{i=1}^{3} \\frac{1}{y_{i}} - \\frac{b}{c} \\sum_{i=1}^{3} \\frac{1}{y_{i}^{2}} = 0\n$$\nSolving for $b$ gives:\n$$\nb_{\\mathrm{rel}}^{\\ast}(c) = c \\frac{\\sum_{i=1}^{3} 1/y_{i}}{\\sum_{i=1}^{3} 1/y_{i}^{2}}\n$$\nWe compute the sums using $y_{1}=1, y_{2}=2, y_{3}=100$:\n$$\n\\sum_{i=1}^{3} \\frac{1}{y_{i}} = \\frac{1}{1} + \\frac{1}{2} + \\frac{1}{100} = \\frac{100+50+1}{100} = \\frac{151}{100}\n$$\n$$\n\\sum_{i=1}^{3} \\frac{1}{y_{i}^{2}} = \\frac{1}{1^{2}} + \\frac{1}{2^{2}} + \\frac{1}{100^{2}} = 1 + \\frac{1}{4} + \\frac{1}{10000} = \\frac{10000+2500+1}{10000} = \\frac{12501}{10000}\n$$\nSubstituting these sums:\n$$\nb_{\\mathrm{rel}}^{\\ast}(c) = c \\frac{151/100}{12501/10000} = c \\frac{151}{100} \\frac{10000}{12501} = \\frac{15100}{12501} c\n$$\nThe scale behavior of $b_{\\mathrm{rel}}^{\\ast}(c)$ is that it is scale-equivariant. The minimizer is a linear function of $c$, so scaling the targets by $c$ also scales the optimal predictor by $c$. The normalized predictor $b_{\\mathrm{rel}}^{\\ast}(c)/c$ is scale-invariant.\n\nFinal Calculation of $D(c, \\delta)$\nWe are asked to find $D(c, \\delta) = b_{\\mathrm{Huber}}^{\\ast}(c, \\delta) - b_{\\mathrm{rel}}^{\\ast}(c)$ in the regime from part 2.\nUsing the expressions derived above:\n$$\nD(c, \\delta) = \\left( \\frac{3c + \\delta}{2} \\right) - \\left( \\frac{15100}{12501} c \\right)\n$$\nWe rearrange the expression to group terms by $c$ and $\\delta$:\n$$\nD(c, \\delta) = \\left( \\frac{3}{2} - \\frac{15100}{12501} \\right) c + \\frac{\\delta}{2}\n$$\nWe find a common denominator for the coefficient of $c$:\n$$\n\\frac{3}{2} - \\frac{15100}{12501} = \\frac{3 \\cdot 12501 - 2 \\cdot 15100}{2 \\cdot 12501} = \\frac{37503 - 30200}{25002} = \\frac{7303}{25002}\n$$\nThe fraction $\\frac{7303}{25002}$ is irreducible. Substituting this back gives the final expression:\n$$\nD(c, \\delta) = \\frac{7303}{25002} c + \\frac{\\delta}{2}\n$$", "answer": "$$\n\\boxed{\\frac{7303}{25002} c + \\frac{\\delta}{2}}\n$$", "id": "3143114"}, {"introduction": "In classification, different loss functions can lead to models with vastly different behaviors, especially in the presence of noisy data. This exercise contrasts the exponential loss, famously used in AdaBoost, with the more robust logistic loss. By simulating gradient descent, you will gain a hands-on understanding of how their differing responses to large errors (misclassifications) influence model training and robustness. [@problem_id:3143216]", "problem": "You are given binary classification with labels $y \\in \\{-1,+1\\}$ and a real-valued score function $s \\in \\mathbb{R}$. The margin is $m = y s$. Consider two losses on the margin: the exponential loss $\\ell_{\\exp}(m)$ and the logistic loss $\\ell_{\\log}(m)$, defined by\n- $\\ell_{\\exp}(m) = \\exp(-m)$,\n- $\\ell_{\\log}(m) = \\log(1+\\exp(-m))$.\n\nAt a fixed feature value, define the conditional class probability $\\eta \\in [0,1]$ as $\\eta = \\mathbb{P}(Y=+1 \\mid X)$. The conditional risk for a score $s$ is\n$$\nR(s;\\eta) = \\eta \\, \\ell(s) + (1-\\eta) \\, \\ell(-s),\n$$\nwhere $\\ell$ denotes either $\\ell_{\\exp}$ or $\\ell_{\\log}$ applied to the margin.\n\nTask overview:\n1) Starting only from the given definitions, derive the derivative $R'(s;\\eta)$ with respect to $s$ for each of $\\ell_{\\exp}$ and $\\ell_{\\log}$. Your derivation must use the chain rule and must not assume any pre-known shortcut identities beyond the definitions above.\n2) Using your derived $R'(s;\\eta)$, design a small simulation that mimics one-dimensional training via gradient descent on $R(s;\\eta)$ for a fixed $\\eta$. For a given initial score $s_0 \\in \\mathbb{R}$, learning rate $\\alpha  0$, and number of steps $T \\in \\mathbb{N}$, perform the following update independently for each loss:\n   - Initialize $s \\leftarrow s_0$.\n   - For $t = 1,2,\\dots,T$: compute the gradient $g_t = R'(s;\\eta)$, record its magnitude $|g_t|$, and update $s \\leftarrow s - \\alpha \\, g_t$.\n   - After $T$ steps, compute the average gradient magnitude $\\overline{G} = \\frac{1}{T} \\sum_{t=1}^T |g_t|$.\n3) Investigate the effect of extreme noise and tail behavior by comparing the average gradient magnitudes for the two losses. For each test case $(\\eta, s_0)$, compute the ratio\n$$\n\\rho = \\frac{\\overline{G}_{\\log}}{\\overline{G}_{\\exp}},\n$$\nwhere $\\overline{G}_{\\log}$ and $\\overline{G}_{\\exp}$ are the average gradient magnitudes obtained from the logistic and exponential losses, respectively.\n\nRequired simulation settings:\n- Use learning rate $\\alpha = 10^{-3}$.\n- Use $T = 5$ steps.\n- Use the following test suite of $(\\eta, s_0)$ pairs, chosen to probe tails and noise extremes:\n  - $(\\eta, s_0) = (0.99, 8)$,\n  - $(\\eta, s_0) = (0.01, -8)$,\n  - $(\\eta, s_0) = (0.50, 8)$,\n  - $(\\eta, s_0) = (0.99, 0)$,\n  - $(\\eta, s_0) = (0.01, 8)$.\n\nProgram requirements:\n- Implement functions that compute $R'(s;\\eta)$ for each loss directly from the definitions and your derived expressions.\n- For each test case, run the simulation independently for the two losses with the same $(\\eta, s_0)$, $\\alpha$, and $T$, and then compute $\\rho$.\n- Round each $\\rho$ to $6$ decimal places.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite given above, for example, $[\\rho_1,\\rho_2,\\rho_3,\\rho_4,\\rho_5]$.\n- All outputs must be floating-point numbers rounded to $6$ decimal places.", "solution": "The problem is valid as it is scientifically grounded in statistical learning theory, well-posed, objective, and provides all necessary information for a unique solution.\n\nThis problem requires the derivation of the conditional risk gradient for two common loss functions in binary classification—exponential loss and logistic loss—and a numerical simulation to compare their behavior under various conditions.\n\n### Part 1: Derivation of the Conditional Risk Gradient $R'(s;\\eta)$\n\nThe conditional risk for a given score $s$ and conditional class probability $\\eta = \\mathbb{P}(Y=+1 \\mid X)$ is defined as:\n$$\nR(s;\\eta) = \\eta \\, \\ell(s) + (1-\\eta) \\, \\ell(-s)\n$$\nwhere $\\ell(s)$ is the loss when the true label is $y=+1$ (margin $m = s$) and $\\ell(-s)$ is the loss when the true label is $y=-1$ (margin $m=-s$). We seek to find the derivative $R'(s;\\eta) = \\frac{d}{ds}R(s;\\eta)$.\n\n#### 1.1 Exponential Loss\n\nThe exponential loss function is defined on the margin $m$ as $\\ell_{\\exp}(m) = \\exp(-m)$.\nThe conditional risk for the exponential loss is:\n$$\nR_{\\exp}(s;\\eta) = \\eta \\, \\ell_{\\exp}(s) + (1-\\eta) \\, \\ell_{\\exp}(-s)\n$$\nSubstituting the definition of $\\ell_{\\exp}$:\n$$\nR_{\\exp}(s;\\eta) = \\eta \\exp(-s) + (1-\\eta) \\exp(-(-s)) = \\eta \\exp(-s) + (1-\\eta) \\exp(s)\n$$\nTo find the gradient, we differentiate $R_{\\exp}(s;\\eta)$ with respect to $s$:\n$$\nR'_{\\exp}(s;\\eta) = \\frac{d}{ds} \\left( \\eta \\exp(-s) + (1-\\eta) \\exp(s) \\right)\n$$\nUsing the linearity of the derivative and the chain rule for $\\exp(-s)$:\n$$\nR'_{\\exp}(s;\\eta) = \\eta \\frac{d}{ds}(\\exp(-s)) + (1-\\eta) \\frac{d}{ds}(\\exp(s))\n$$\n$$\nR'_{\\exp}(s;\\eta) = \\eta (\\exp(-s) \\cdot (-1)) + (1-\\eta) (\\exp(s))\n$$\n$$\nR'_{\\exp}(s;\\eta) = -\\eta \\exp(-s) + (1-\\eta) \\exp(s)\n$$\nThis is the derivative of the conditional risk for the exponential loss.\n\n#### 1.2 Logistic Loss\n\nThe logistic loss function is defined on the margin $m$ as $\\ell_{\\log}(m) = \\log(1+\\exp(-m))$.\nThe conditional risk for the logistic loss is:\n$$\nR_{\\log}(s;\\eta) = \\eta \\, \\ell_{\\log}(s) + (1-\\eta) \\, \\ell_{\\log}(-s)\n$$\nWe compute the derivative of each term separately. First, let's find the derivative of the logistic loss function $\\ell_{\\log}(m)$ with respect to its argument $m$. Using the chain rule, let $u(m) = 1 + \\exp(-m)$, so $\\ell_{\\log}(m) = \\log(u(m))$.\n$$\n\\frac{d\\ell_{\\log}}{dm} = \\frac{d}{dm}\\log(u(m)) = \\frac{1}{u(m)} \\cdot \\frac{du}{dm} = \\frac{1}{1 + \\exp(-m)} \\cdot (-\\exp(-m)) = -\\frac{\\exp(-m)}{1 + \\exp(-m)}\n$$\nNow, we apply this to the two terms in the derivative of the conditional risk $R'_{\\log}(s;\\eta) = \\frac{d}{ds}R_{\\log}(s;\\eta)$:\n$$\nR'_{\\log}(s;\\eta) = \\eta \\frac{d}{ds}(\\ell_{\\log}(s)) + (1-\\eta) \\frac{d}{ds}(\\ell_{\\log}(-s))\n$$\nFor the first term, we set $m=s$ and use the derivative we just found:\n$$\n\\frac{d}{ds}(\\ell_{\\log}(s)) = -\\frac{\\exp(-s)}{1 + \\exp(-s)}\n$$\nFor the second term, we apply the chain rule. Let $v(s) = -s$. Then $\\frac{d}{ds}(\\ell_{\\log}(-s)) = \\frac{d\\ell_{\\log}}{dv} \\cdot \\frac{dv}{ds}$.\n$$\n\\frac{d}{ds}(\\ell_{\\log}(-s)) = \\left( -\\frac{\\exp(-v)}{1 + \\exp(-v)} \\right) \\cdot (-1) = \\frac{\\exp(-(-s))}{1 + \\exp(-(-s))} = \\frac{\\exp(s)}{1 + \\exp(s)}\n$$\nCombining these results:\n$$\nR'_{\\log}(s;\\eta) = \\eta \\left( -\\frac{\\exp(-s)}{1 + \\exp(-s)} \\right) + (1-\\eta) \\left( \\frac{\\exp(s)}{1 + \\exp(s)} \\right)\n$$\nThis expression can be simplified. Let $\\sigma(s) = \\frac{1}{1+\\exp(-s)} = \\frac{\\exp(s)}{1+\\exp(s)}$ be the sigmoid function.\nNotice that $\\frac{d}{ds}(\\ell_{\\log}(s)) = \\sigma(s)-1$ and $\\frac{d}{ds}(\\ell_{\\log}(-s)) = \\sigma(s)$.\nSubstituting these simplified forms back into the expression for $R'_{\\log}(s;\\eta)$:\n$$\nR'_{\\log}(s;\\eta) = \\eta (\\sigma(s)-1) + (1-\\eta)\\sigma(s)\n$$\n$$\nR'_{\\log}(s;\\eta) = \\eta\\sigma(s) - \\eta + \\sigma(s) - \\eta\\sigma(s)\n$$\n$$\nR'_{\\log}(s;\\eta) = \\sigma(s) - \\eta\n$$\nThis is the final, simplified derivative for the conditional risk of the logistic loss.\n\n### Part 2: Simulation Design\n\nThe simulation implements a one-dimensional gradient descent algorithm to minimize the conditional risk $R(s;\\eta)$ for a fixed $\\eta$.\n\n1.  **Initialization**: For each test case $(\\eta, s_0)$, we initialize the score $s \\leftarrow s_0$. The process is performed independently for the exponential and logistic losses.\n2.  **Iteration**: For a total of $T=5$ steps, and for each step $t \\in \\{1, 2, \\dots, T\\}$:\n    a.  Compute the gradient $g_t = R'(s;\\eta)$ using the appropriate derived formula, $R'_{\\exp}(s;\\eta)$ or $R'_{\\log}(s;\\eta)$.\n    b.  Record the absolute magnitude of the gradient, $|g_t|$.\n    c.  Update the score using the gradient descent rule: $s \\leftarrow s - \\alpha g_t$, with a learning rate of $\\alpha = 10^{-3}$.\n3.  **Aggregation**: After $T$ steps, calculate the average gradient magnitude $\\overline{G} = \\frac{1}{T} \\sum_{t=1}^T |g_t|$. This is done for both $\\overline{G}_{\\exp}$ and $\\overline{G}_{\\log}$.\n4.  **Comparison**: For each test case, compute the ratio $\\rho = \\frac{\\overline{G}_{\\log}}{\\overline{G}_{\\exp}}$. This ratio quantifies the relative magnitude of the gradients produced by the two loss functions under the given conditions. A small $\\rho$ indicates that the logistic loss gradient is much smaller than the exponential loss gradient, suggesting greater stability and less sensitivity to data points that are far from the decision boundary or potentially mislabeled.\n\nThe provided test cases are designed to explore this behavior, particularly in \"tail\" regions where the score $s$ is large in magnitude, and for \"noisy\" labels where $\\eta$ is close to $0$ or $1$ but the score $s$ suggests the opposite class.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# language: Python\n# version: 3.12\n# libraries:\n#   - name: numpy\n#     version: 1.23.5\n\ndef grad_exp(s: float, eta: float) - float:\n    \"\"\"\n    Computes the derivative of the conditional risk for exponential loss.\n    R'_exp(s; eta) = (1 - eta) * exp(s) - eta * exp(-s)\n    \"\"\"\n    return (1.0 - eta) * np.exp(s) - eta * np.exp(-s)\n\ndef grad_log(s: float, eta: float) - float:\n    \"\"\"\n    Computes the derivative of the conditional risk for logistic loss.\n    R'_log(s; eta) = sigma(s) - eta, where sigma(s) is the sigmoid function.\n    \"\"\"\n    # Numerically stable implementation of the sigmoid function\n    if s = 0:\n        z = np.exp(-s)\n        sigma_s = 1.0 / (1.0 + z)\n    else:\n        z = np.exp(s)\n        sigma_s = z / (1.0 + z)\n    return sigma_s - eta\n\ndef run_simulation(\n    grad_func,\n    eta: float,\n    s0: float,\n    alpha: float,\n    T: int\n) - float:\n    \"\"\"\n    Runs a 1D gradient descent simulation and returns the average gradient magnitude.\n    \n    Args:\n        grad_func: The function to compute the gradient (e.g., grad_exp or grad_log).\n        eta: The conditional class probability P(Y=+1|X).\n        s0: The initial score.\n        alpha: The learning rate.\n        T: The number of simulation steps.\n        \n    Returns:\n        The average absolute magnitude of the gradients over T steps.\n    \"\"\"\n    s = float(s0)\n    grad_magnitudes = []\n    for _ in range(T):\n        gradient = grad_func(s, eta)\n        grad_magnitudes.append(np.abs(gradient))\n        s = s - alpha * gradient\n        \n    return np.mean(grad_magnitudes)\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print results.\n    \"\"\"\n    # Required simulation settings\n    alpha = 1e-3\n    T = 5\n\n    # Test suite of (eta, s0) pairs\n    test_cases = [\n        (0.99, 8.0),\n        (0.01, -8.0),\n        (0.50, 8.0),\n        (0.99, 0.0),\n        (0.01, 8.0),\n    ]\n\n    results = []\n    for eta, s0 in test_cases:\n        # Run simulation for logistic loss\n        avg_grad_log = run_simulation(grad_log, eta, s0, alpha, T)\n        \n        # Run simulation for exponential loss\n        avg_grad_exp = run_simulation(grad_exp, eta, s0, alpha, T)\n\n        # Compute the ratio rho. A zero check for avg_grad_exp is a safeguard,\n        # though not expected for these specific test cases.\n        if avg_grad_exp == 0.0:\n            # If both are zero, the ratio is indeterminate (let's define as 1).\n            # If only exp is zero, log/exp is infinite.\n            if avg_grad_log == 0.0:\n                rho = 1.0\n            else:\n                rho = np.inf\n        else:\n            rho = avg_grad_log / avg_grad_exp\n        \n        # Round to 6 decimal places as required.\n        results.append(round(rho, 6))\n\n    # Format the output as a comma-separated list in brackets.\n    output_str = \",\".join(map(str, results))\n    print(f\"[{output_str}]\")\n\nsolve()\n\n```", "id": "3143216"}, {"introduction": "Real-world datasets are often imbalanced, with one class being much rarer than another, which can bias standard classifiers. This practice demonstrates a powerful technique to counteract this: modifying the logistic loss with class-specific weights. You will derive how these weights alter the model's optimal decision-making and see firsthand their impact on performance metrics like calibration, precision, and recall. [@problem_id:3143139]", "problem": "Consider binary classification in statistical learning under Empirical Risk Minimization (ERM). Let the input be a vector of instances with conditional class probabilities denoted by $p(x) = \\mathbb{P}(Y=+1 \\mid X=x)$, where $Y \\in \\{-1,+1\\}$. We study a label-dependent margin-based logistic loss where positive examples incur a larger penalty than negative examples through class-dependent weights. The weighted logistic loss assigns weight $w_{+}  0$ to the positive class and $w_{-}  0$ to the negative class. Assume that the scoring function is a real-valued function $f(x) \\in \\mathbb{R}$, and define the per-instance loss as\n$$\n\\ell(y, f(x)) = \\begin{cases}\nw_{+} \\cdot \\log\\left(1 + e^{-f(x)}\\right)  \\text{if } y = +1, \\\\\nw_{-} \\cdot \\log\\left(1 + e^{f(x)}\\right)  \\text{if } y = -1.\n\\end{cases}\n$$\nThe conditional expected risk at a fixed $x$ is the expectation of $\\ell(Y,f(x))$ over $Y$ given $X=x$. Investigate how the choice of $w_{+}$ and $w_{-}$ affects (i) calibration when the naive predicted probability is defined as the sigmoid of the learned score, and (ii) the precision-recall tradeoff when classifying based on the sign of the score.\n\nStarting from core definitions of expected risk and the logistic loss, derive from first principles the form of the Bayes-optimal score $f^{\\star}(x)$ that minimizes the conditional expected risk at a fixed $x$, express the naive predicted probability $q(x)$ obtained by applying the sigmoid function to $f^{\\star}(x)$, and determine the implied threshold on $p(x)$ for predicting the positive class when using the rule $f^{\\star}(x) \\ge 0$. Use these derivations to design an algorithm that computes an empirical measure of calibration error and expected precision-recall under the weighted loss.\n\nImplementation requirements:\n- Work in a purely mathematical setting where the dataset is represented by a fixed, deterministic vector of conditional probabilities without sampling labels. Let the dataset be $N=99$ instances with probabilities\n$$\np_i = 0.01 + \\frac{i-1}{98} \\cdot 0.98 \\quad \\text{for } i=1,2,\\dots,99,\n$$\nwhich are evenly spaced in $(0,1)$.\n- For each pair $(w_{+}, w_{-})$ in the test suite, compute the Bayes-optimal score $f^{\\star}(x)$ at each instance by your derived expression, compute the naive predicted probability $q(x)$ by applying the sigmoid to $f^{\\star}(x)$, and use it to evaluate calibration and classification performance.\n- Calibration assessment: Compute the Expected Calibration Error (ECE) as follows. Partition the range of naive predicted probabilities into $10$ equal-width bins over $[0,1]$. For each bin, compute the average of the naive predicted probabilities $q(x)$ in the bin and the average of the true probabilities $p(x)$ of the instances that fall into the bin, and accumulate the absolute difference weighted by the fraction of instances in that bin. Explicitly,\n$$\n\\mathrm{ECE} = \\sum_{b=1}^{10} \\frac{n_b}{N} \\cdot \\left| \\overline{q}_b - \\overline{p}_b \\right|,\n$$\nwhere $n_b$ is the number of instances in bin $b$, $\\overline{q}_b$ is the mean of $q(x)$ in bin $b$, and $\\overline{p}_b$ is the mean of $p(x)$ in bin $b$. Bins are defined so that all naive predicted probabilities in $[0,0.1)$ belong to bin $1$, $[0.1,0.2)$ to bin $2$, and so on, with the last bin including the right endpoint $1$.\n- Precision and recall: Let the classification rule predict positive when $f^{\\star}(x) \\ge 0$ and negative otherwise. Compute expected true positives $\\mathrm{TP} = \\sum_{i \\in \\mathcal{P}} p_i$ and expected false positives $\\mathrm{FP} = \\sum_{i \\in \\mathcal{P}} (1 - p_i)$, where $\\mathcal{P}$ is the index set of instances classified as positive. Also compute expected false negatives $\\mathrm{FN} = \\sum_{i \\notin \\mathcal{P}} p_i$ and the total expected positives $\\mathrm{P} = \\sum_{i=1}^{N} p_i$. Then compute precision $\\mathrm{Prec} = \\mathrm{TP} / (\\mathrm{TP} + \\mathrm{FP})$ when the denominator is nonzero (otherwise define it as $0$), and recall $\\mathrm{Rec} = \\mathrm{TP} / \\mathrm{P}$ when the denominator is nonzero (otherwise define it as $0$). All quantities are dimensionless and must be represented as real numbers.\n\nTest suite:\n- Case $1$: $(w_{+}, w_{-}) = (1, 1)$.\n- Case $2$: $(w_{+}, w_{-}) = (3, 1)$.\n- Case $3$: $(w_{+}, w_{-}) = (10, 1)$.\n- Case $4$: $(w_{+}, w_{-}) = (1.5, 1)$.\n\nYour program should produce a single line of output containing the results for the test suite as a comma-separated list of lists, with each inner list containing three real numbers in the order $[\\mathrm{ECE}, \\mathrm{Prec}, \\mathrm{Rec}]$ for the corresponding case. The final output line must have no spaces and each real number must be rounded to six decimal places. For example, the format should be\n$$\n[[r_{1,1},r_{1,2},r_{1,3}],[r_{2,1},r_{2,2},r_{2,3}],[r_{3,1},r_{3,2},r_{3,3}],[r_{4,1},r_{4,2},r_{4,3}]].\n$$", "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information for a complete analytical and computational solution. We begin by deriving the theoretical quantities requested, and then outline the algorithm for their computation.\n\nFirst, we derive the Bayes-optimal score $f^{\\star}(x)$ that minimizes the conditional expected risk. The conditional expected risk $R(f(x) \\mid x)$ is the expectation of the loss $\\ell(Y, f(x))$ over the conditional distribution of the label $Y$ given the features $x$. Let $p(x) = \\mathbb{P}(Y=+1 \\mid X=x)$, which implies $\\mathbb{P}(Y=-1 \\mid X=x) = 1 - p(x)$. The conditional expected risk is:\n$$\nR(f(x) \\mid x) = \\mathbb{E}_{Y \\mid X=x}[\\ell(Y, f(x))] = p(x) \\cdot \\ell(+1, f(x)) + (1 - p(x)) \\cdot \\ell(-1, f(x))\n$$\nSubstituting the definition of the weighted logistic loss:\n$$\nR(f(x) \\mid x) = p(x) \\cdot w_{+} \\log\\left(1 + e^{-f(x)}\\right) + (1 - p(x)) \\cdot w_{-} \\log\\left(1 + e^{f(x)}\\right)\n$$\nTo find the score $f(x)$ that minimizes this risk, we compute the partial derivative of $R$ with respect to $f(x)$ and set it to zero. For notational simplicity, we let $f = f(x)$ and $p = p(x)$.\n$$\n\\frac{\\partial R}{\\partial f} = p \\cdot w_{+} \\left(\\frac{-e^{-f}}{1 + e^{-f}}\\right) + (1 - p) \\cdot w_{-} \\left(\\frac{e^{f}}{1 + e^{f}}\\right)\n$$\nSimplifying the terms in the parentheses:\n$$\n\\frac{-e^{-f}}{1 + e^{-f}} = \\frac{-1}{e^{f} + 1} \\quad \\text{and} \\quad \\frac{e^{f}}{1 + e^{f}}\n$$\nSo the derivative becomes:\n$$\n\\frac{\\partial R}{\\partial f} = -p \\cdot w_{+} \\frac{1}{1 + e^{f}} + (1 - p) \\cdot w_{-} \\frac{e^{f}}{1 + e^{f}}\n$$\nSetting the derivative to zero to find the optimal score $f^{\\star}$:\n$$\np \\cdot w_{+} \\frac{1}{1 + e^{f^{\\star}}} = (1 - p) \\cdot w_{-} \\frac{e^{f^{\\star}}}{1 + e^{f^{\\star}}}\n$$\nAssuming $1+e^{f^{\\star}} \\neq 0$, which is always true for real $f^{\\star}$, we can cancel this term:\n$$\np \\cdot w_{+} = (1 - p) \\cdot w_{-} e^{f^{\\star}}\n$$\nSolving for $e^{f^{\\star}}$:\n$$\ne^{f^{\\star}} = \\frac{p \\cdot w_{+}}{(1 - p) \\cdot w_{-}}\n$$\nThe Bayes-optimal score $f^{\\star}(x)$ is therefore:\n$$\nf^{\\star}(x) = \\log\\left(\\frac{p(x)}{1 - p(x)} \\frac{w_{+}}{w_{-}}\\right) = \\log\\left(\\frac{p(x)}{1 - p(x)}\\right) + \\log\\left(\\frac{w_{+}}{w_{-}}\\right)\n$$\nThis reveals that the optimal score is the sum of the log-odds of the true probability and a bias term determined by the ratio of the class weights.\n\nSecond, we find the naive predicted probability $q(x)$ by applying the sigmoid function $\\sigma(z) = (1 + e^{-z})^{-1}$ to $f^{\\star}(x)$.\n$$\nq(x) = \\sigma(f^{\\star}(x)) = \\frac{1}{1 + e^{-f^{\\star}(x)}}\n$$\nFrom the expression for $e^{f^{\\star}}$, we have $e^{-f^{\\star}(x)} = \\frac{(1 - p(x)) \\cdot w_{-}}{p(x) \\cdot w_{+}}$. Substituting this into the sigmoid function:\n$$\nq(x) = \\frac{1}{1 + \\frac{(1 - p(x))w_{-}}{p(x)w_{+}}} = \\frac{p(x)w_{+}}{p(x)w_{+} + (1 - p(x))w_{-}}\n$$\nIf the weights are balanced ($w_{+} = w_{-}$), then $q(x) = \\frac{p(x)w_{+}}{p(x)w_{+} + (1 - p(x))w_{+}} = p(x)$, meaning the naive predictor is perfectly calibrated. For unbalanced weights, $q(x) \\neq p(x)$, leading to a calibration error.\n\nThird, we determine the classification threshold on $p(x)$. The classification rule predicts the positive class if $f^{\\star}(x) \\ge 0$.\n$$\n\\log\\left(\\frac{p(x)}{1 - p(x)} \\frac{w_{+}}{w_{-}}\\right) \\ge 0\n$$\nSince the logarithm is a monotonically increasing function, this is equivalent to its argument being greater than or equal to $1$:\n$$\n\\frac{p(x)}{1 - p(x)} \\frac{w_{+}}{w_{-}} \\ge 1\n$$\n$$\n\\frac{p(x)}{1 - p(x)} \\ge \\frac{w_{-}}{w_{+}}\n$$\nAssuming $p(x) \\in (0,1)$, we can multiply by $1 - p(x)  0$:\n$$\np(x)w_{+} \\ge (1 - p(x))w_{-} \\implies p(x)w_{+} \\ge w_{-} - p(x)w_{-} \\implies p(x)(w_{+} + w_{-}) \\ge w_{-}\n$$\nThus, the threshold on the true conditional probability $p(x)$ for predicting the positive class is:\n$$\np(x) \\ge \\frac{w_{-}}{w_{+} + w_{-}}\n$$\nThis threshold is lower than $0.5$ when $w_{+}  w_{-}$, encouraging positive predictions, and higher than $0.5$ when $w_{+}  w_{-}$, discouraging them.\n\nFinally, we design the algorithm to compute the required metrics for the given dataset and test cases. The dataset consists of $N=99$ instances with probabilities $p_i = 0.01 + \\frac{i-1}{98} \\cdot 0.98$ for $i=1, \\dots, 99$. This simplifies to an arithmetic progression $p_i = 0.01 \\cdot i$ for $i=1, \\dots, 99$. For each test case $(w_{+}, w_{-})$:\n\n1.  **Compute Naive Probabilities**: For each $p_i$, calculate $q_i = \\frac{p_i w_{+}}{p_i w_{+} + (1-p_i)w_{-}}$.\n2.  **Compute Expected Calibration Error (ECE)**:\n    - Partition the $q_i$ values into $10$ bins: $[0, 0.1), [0.1, 0.2), \\dots, [0.9, 1.0]$.\n    - For each bin $b$, find the set of indices $I_b$ of instances whose $q_i$ falls in that bin.\n    - Let $n_b = |I_b|$. If $n_b  0$, compute the average predicted probability $\\overline{q}_b = \\frac{1}{n_b}\\sum_{i \\in I_b} q_i$ and the average true probability $\\overline{p}_b = \\frac{1}{n_b}\\sum_{i \\in I_b} p_i$.\n    - The ECE is $\\sum_{b=1}^{10} \\frac{n_b}{N} \\cdot \\left| \\overline{q}_b - \\overline{p}_b \\right|$.\n3.  **Compute Precision and Recall**:\n    - Determine the set of instances predicted as positive: $\\mathcal{P} = \\{i \\mid p_i \\ge \\frac{w_{-}}{w_{+} + w_{-}}\\}$.\n    - Calculate expected true positives: $\\mathrm{TP} = \\sum_{i \\in \\mathcal{P}} p_i$.\n    - The sum of expected true positives and false positives is $\\mathrm{TP} + \\mathrm{FP} = \\sum_{i \\in \\mathcal{P}} p_i + \\sum_{i \\in \\mathcal{P}} (1 - p_i) = \\sum_{i \\in \\mathcal{P}} 1 = |\\mathcal{P}|$.\n    - Precision is $\\mathrm{Prec} = \\mathrm{TP} / |\\mathcal{P}|$ (if $|\\mathcal{P}|0$, else $0$).\n    - Total expected positives are $\\mathrm{P} = \\sum_{i=1}^{N} p_i$.\n    - Recall is $\\mathrm{Rec} = \\mathrm{TP} / \\mathrm{P}$ (if $\\mathrm{P}0$, else $0$).\n\nThis procedure is implemented for each test case to produce the final results.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by deriving and computing calibration and classification\n    metrics for a weighted logistic loss.\n    \"\"\"\n    \n    # Define the dataset of conditional probabilities\n    N = 99\n    p = np.arange(1, N + 1) / 100.0  # p_i = i/100 for i=1,...,99\n    \n    # Define the test suite\n    test_cases = [\n        (1.0, 1.0),  # Case 1\n        (3.0, 1.0),  # Case 2\n        (10.0, 1.0), # Case 3\n        (1.5, 1.0)   # Case 4\n    ]\n    \n    results = []\n    \n    for w_plus, w_minus in test_cases:\n        # 1. Compute naive predicted probabilities q_i\n        q = (p * w_plus) / (p * w_plus + (1 - p) * w_minus)\n\n        # 2. Compute Expected Calibration Error (ECE)\n        num_bins = 10\n        bins_p = [[] for _ in range(num_bins)]\n        bins_q = [[] for _ in range(num_bins)]\n        \n        for i in range(N):\n            q_val = q[i]\n            # Determine bin index. Bins are [0, 0.1), [0.1, 0.2), ..., [0.9, 1.0]\n            if q_val == 1.0:\n                bin_idx = num_bins - 1\n            else:\n                bin_idx = int(np.floor(q_val * num_bins))\n            \n            bins_p[bin_idx].append(p[i])\n            bins_q[bin_idx].append(q_val)\n            \n        ece = 0.0\n        for b in range(num_bins):\n            n_b = len(bins_p[b])\n            if n_b  0:\n                mean_p_b = np.mean(bins_p[b])\n                mean_q_b = np.mean(bins_q[b])\n                ece += (n_b / N) * np.abs(mean_q_b - mean_p_b)\n\n        # 3. Compute Precision and Recall\n        # Determine classification threshold on p\n        p_threshold = w_minus / (w_plus + w_minus)\n        \n        # Identify instances predicted as positive\n        positive_indices = np.where(p = p_threshold)[0]\n        \n        # Calculate expected TP, FP, P\n        if len(positive_indices)  0:\n            p_pos = p[positive_indices]\n            tp = np.sum(p_pos)\n            num_pos_pred = len(positive_indices)\n        else:\n            tp = 0.0\n            num_pos_pred = 0\n            \n        total_pos = np.sum(p)\n        \n        # Calculate precision\n        if num_pos_pred  0:\n            precision = tp / num_pos_pred\n        else:\n            precision = 0.0\n            \n        # Calculate recall\n        if total_pos  0:\n            recall = tp / total_pos\n        else:\n            recall = 0.0\n\n        results.append([ece, precision, recall])\n        \n    # Format the final output string as specified\n    output_str = f\"[{','.join([f'[{r[0]:.6f},{r[1]:.6f},{r[2]:.6f}]' for r in results])}]\"\n    print(output_str)\n\nsolve()\n\n```", "id": "3143139"}]}