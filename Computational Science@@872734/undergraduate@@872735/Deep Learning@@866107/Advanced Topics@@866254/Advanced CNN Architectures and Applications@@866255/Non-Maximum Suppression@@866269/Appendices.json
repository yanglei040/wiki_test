{"hands_on_practices": [{"introduction": "The standard Non-Maximum Suppression algorithm is a fast and effective greedy heuristic, but it does not always yield the set of detections with the highest possible total score. This exercise challenges you to frame NMS as a formal optimization problem, specifically an Integer Linear Program (ILP), to find the globally optimal solution. By comparing the results of the greedy algorithm to the exact ILP solution, you will gain a deeper understanding of the trade-offs between computational efficiency and theoretical optimality. [@problem_id:3159494]", "problem": "You are given a set of axis-aligned rectangular bounding boxes in a two-dimensional plane. Each box has coordinates and an associated nonnegative confidence score. The goal is to implement Non-Maximum Suppression (NMS) by formulating it as a constraint satisfaction problem and solving it exactly via Integer Linear Programming (ILP) on small instances, and also by a greedy selection procedure, then comparing the results.\n\nDefinitions and foundations:\n- For a box with coordinates represented by the tuple $(x_1,y_1,x_2,y_2)$, assume $x_1 < x_2$ and $y_1 < y_2$. The area is $(x_2 - x_1)\\,(y_2 - y_1)$.\n- The Intersection over Union (IoU) between two boxes $i$ and $j$ is defined as the ratio of the intersection area to the union area of the two boxes. If there is no overlap, the intersection area is $0$ and $\\mathrm{IoU}_{ij} = 0$. The union area equals the sum of the individual areas minus the intersection area. All IoU values are dimensionless.\n- Non-Maximum Suppression (NMS) suppresses overlapping boxes based on a threshold $t \\in [0,1]$. In this problem, use the following rule: two boxes $i$ and $j$ are mutually exclusive if $\\mathrm{IoU}_{ij} \\ge t$.\n\nFormulation as ILP:\n- Introduce binary decision variables $x_i \\in \\{0,1\\}$ for each box $i$, where $x_i = 1$ means the box is selected and $x_i = 0$ means it is not selected.\n- Let $s_i \\ge 0$ denote the confidence score of box $i$.\n- For every pair $(i,j)$ with $\\mathrm{IoU}_{ij} \\ge t$, impose the constraint $x_i + x_j \\le 1$.\n- Objective: maximize $\\sum_i s_i x_i$ subject to the above constraints.\n- Since instances are small, solve the ILP exactly by enumerating all feasible assignments of $\\{x_i\\}$ that satisfy the constraints and selecting the assignment that maximizes the objective. In the case of ties in total score, break ties by choosing the lexicographically smallest sorted list of selected indices.\n\nGreedy NMS procedure:\n- Sort boxes in descending order of score. When scores are equal, break ties by ascending index.\n- Iterate through the sorted list, selecting a box if it has not been suppressed. Upon selecting box $k$, suppress every remaining box $j$ such that $\\mathrm{IoU}_{kj} \\ge t$.\n- The output is the sorted list (ascending) of selected indices.\n\nYour task:\n- Implement both methods: the exact ILP solver (via enumeration) and the greedy NMS.\n- Use the following test suite. Boxes are specified as $(x_1,y_1,x_2,y_2)$ and all scores are unitless. For each case, indices are $0$-based.\n- For each test case, output a list containing:\n  1. The greedy-selected indices as an ascending list of integers.\n  2. The ILP-selected indices as an ascending list of integers (using lexicographic tie-breaking among optimal solutions).\n  3. A boolean indicating whether the two index lists are identical.\n  4. The greedy total score, rounded to three decimal places.\n  5. The ILP total score, rounded to three decimal places.\n\nTest suite:\n- Case A (happy path, moderate overlaps): threshold $t = 0.3$; boxes and scores\n  - Index $0$: $(0.0, 0.0, 2.0, 2.0)$ with $s_0 = 0.90$\n  - Index $1$: $(0.5, 0.5, 2.5, 2.5)$ with $s_1 = 0.85$\n  - Index $2$: $(2.1, 0.0, 4.1, 2.0)$ with $s_2 = 0.70$\n  - Index $3$: $(0.0, 2.1, 2.0, 4.1)$ with $s_3 = 0.60$\n- Case B (suboptimal greedy due to chain conflicts): threshold $t = 0.5$; boxes and scores\n  - Index $0$: $(0.0, 0.0, 2.0, 2.0)$ with $s_0 = 0.60$\n  - Index $1$: $(0.5, 0.0, 2.5, 2.0)$ with $s_1 = 0.95$\n  - Index $2$: $(1.0, 0.0, 3.0, 2.0)$ with $s_2 = 0.60$\n- Case C (boundary condition $t = 0$): threshold $t = 0.0$; boxes and scores\n  - Index $0$: $(0.0, 0.0, 1.0, 1.0)$ with $s_0 = 0.50$\n  - Index $1$: $(2.0, 0.0, 3.0, 1.0)$ with $s_1 = 0.70$\n  - Index $2$: $(4.0, 0.0, 5.0, 1.0)$ with $s_2 = 0.60$\n- Case D (boundary condition $t = 1$ with identical boxes): threshold $t = 1.0$; boxes and scores\n  - Index $0$: $(0.0, 0.0, 1.0, 1.0)$ with $s_0 = 0.60$\n  - Index $1$: $(0.0, 0.0, 1.0, 1.0)$ with $s_1 = 0.59$\n  - Index $2$: $(2.0, 2.0, 3.0, 3.0)$ with $s_2 = 0.40$\n- Case E (tie-breaking in both strategies): threshold $t = 0.5$; boxes and scores\n  - Index $0$: $(0.0, 0.0, 2.0, 2.0)$ with $s_0 = 0.80$\n  - Index $1$: $(0.5, 0.0, 2.5, 2.0)$ with $s_1 = 0.80$\n  - Index $2$: $(3.0, 0.0, 5.0, 2.0)$ with $s_2 = 0.10$\n\nFinal output format:\n- Your program should produce a single line of output containing a list with one element per test case. Each element must be a list of the form\n  $[G, O, B, S_G, S_O]$,\n  where $G$ is the greedy indices list, $O$ is the ILP indices list, $B$ is the boolean equality indicator, $S_G$ is the greedy total score rounded to three decimal places, and $S_O$ is the ILP total score rounded to three decimal places. The entire output must be a single line, for example:\n  $[[\\dots],[\\dots],[\\dots],[\\dots],[\\dots]]$.", "solution": "The posed problem requires the implementation and comparison of two distinct methods for Non-Maximum Suppression (NMS): a standard greedy heuristic and an exact solver based on an Integer Linear Programming (ILP) formulation. The task is to apply both methods to a series of test cases and report the selected bounding boxes, the resulting total scores, and a comparison between the two sets of results.\n\nFirst, we establish the mathematical foundations for the problem. A bounding box $B_i$ is defined by its coordinates $(x_{i,1}, y_{i,1}, x_{i,2}, y_{i,2})$, where we are given that $x_{i,1} < x_{i,2}$ and $y_{i,1} < y_{i,2}$. The area of box $B_i$ is given by:\n$$\n\\text{Area}(B_i) = (x_{i,2} - x_{i,1})(y_{i,2} - y_{i,1})\n$$\nThe core metric for NMS is the Intersection over Union (IoU), which quantifies the extent of overlap between two boxes, $B_i$ and $B_j$. The intersection area is calculated from the overlapping rectangle:\n$$\n\\text{Area}(B_i \\cap B_j) = \\max(0, \\min(x_{i,2}, x_{j,2}) - \\max(x_{i,1}, x_{j,1})) \\cdot \\max(0, \\min(y_{i,2}, y_{j,2}) - \\max(y_{i,1}, y_{j,1}))\n$$\nThe union area is derived from the principle of inclusion-exclusion:\n$$\n\\text{Area}(B_i \\cup B_j) = \\text{Area}(B_i) + \\text{Area}(B_j) - \\text{Area}(B_i \\cap B_j)\n$$\nThus, the IoU is defined as the ratio:\n$$\n\\mathrm{IoU}_{ij} = \\frac{\\text{Area}(B_i \\cap B_j)}{\\text{Area}(B_i \\cup B_j)}\n$$\nIf the union area is zero (which implies both box areas are zero, a case excluded by the problem statement), the IoU is taken to be $0$. The value of $\\mathrm{IoU}_{ij}$ lies in the interval $[0, 1]$.\n\nThe first method to be implemented is the Greedy NMS algorithm. This is a widely used heuristic that operates as follows:\n1.  A list of all candidate boxes is created, each with an associated confidence score $s_i$ and an original index $i$.\n2.  The list is sorted in descending order based on the confidence scores. In case of a tie in scores, the box with the lower original index is placed first.\n3.  The algorithm iterates through the sorted list. The first box is selected. Then, all other boxes $B_j$ that have an IoU with the selected box $B_i$ greater than or equal to a specified threshold $t$ (i.e., $\\mathrm{IoU}_{ij} \\ge t$) are marked as suppressed and removed from consideration.\n4.  The process repeats with the next available (unsuppressed) box in the sorted list until all boxes have been either selected or suppressed.\n5.  The final output is the set of indices of the selected boxes, sorted in ascending order.\n\nThe second method is an exact solution based on an Integer Linear Programming (ILP) formulation. This approach guarantees an optimal selection of boxes that maximizes the total confidence score, subject to the overlap constraints. The formulation is as follows:\n-   For each box $i$, we introduce a binary decision variable $x_i \\in \\{0, 1\\}$, where $x_i = 1$ if the box is selected and $x_i = 0$ otherwise.\n-   The objective is to maximize the sum of scores of the selected boxes:\n    $$\n    \\text{maximize} \\quad Z = \\sum_{i} s_i x_i\n    $$\n-   The NMS rule is enforced through a set of constraints. For every pair of boxes $(i, j)$ where their overlap meets or exceeds the threshold, $\\mathrm{IoU}_{ij} \\ge t$, we impose the constraint that at most one of them can be selected:\n    $$\n    x_i + x_j \\le 1 \\quad \\forall (i, j) \\text{ such that } i < j \\text{ and } \\mathrm{IoU}_{ij} \\ge t\n    $$\nSince the problem instances are small (up to $4$ boxes), this ILP can be solved exactly by enumerating all $2^N$ possible assignments for the variables $\\{x_i\\}$, where $N$ is the number of boxes. For each assignment, we check if it is feasible (i.e., satisfies all constraints). Among all feasible assignments, we seek the one that yields the maximum objective value. If multiple assignments result in the same maximum score, the tie is broken by selecting the assignment whose corresponding list of indices is lexicographically smallest.\n\nThe implementation will consist of helper functions to calculate IoU, and dedicated functions for the greedy and ILP algorithms. The main procedure will iterate through the provided test suite, execute both algorithms, and format the results as specified, including the selected indices, total scores, and a boolean comparison of the selected index sets. Scores will be reported rounded to three decimal places.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the NMS problem for all test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"t\": 0.3,\n            \"boxes\": np.array([\n                [0.0, 0.0, 2.0, 2.0],\n                [0.5, 0.5, 2.5, 2.5],\n                [2.1, 0.0, 4.1, 2.0],\n                [0.0, 2.1, 2.0, 4.1]\n            ]),\n            \"scores\": np.array([0.90, 0.85, 0.70, 0.60])\n        },\n        {\n            \"t\": 0.5,\n            \"boxes\": np.array([\n                [0.0, 0.0, 2.0, 2.0],\n                [0.5, 0.0, 2.5, 2.0],\n                [1.0, 0.0, 3.0, 2.0]\n            ]),\n            \"scores\": np.array([0.60, 0.95, 0.60])\n        },\n        {\n            \"t\": 0.0,\n            \"boxes\": np.array([\n                [0.0, 0.0, 1.0, 1.0],\n                [2.0, 0.0, 3.0, 1.0],\n                [4.0, 0.0, 5.0, 1.0]\n            ]),\n            \"scores\": np.array([0.50, 0.70, 0.60])\n        },\n        {\n            \"t\": 1.0,\n            \"boxes\": np.array([\n                [0.0, 0.0, 1.0, 1.0],\n                [0.0, 0.0, 1.0, 1.0],\n                [2.0, 2.0, 3.0, 3.0]\n            ]),\n            \"scores\": np.array([0.60, 0.59, 0.40])\n        },\n        {\n            \"t\": 0.5,\n            \"boxes\": np.array([\n                [0.0, 0.0, 2.0, 2.0],\n                [0.5, 0.0, 2.5, 2.0],\n                [3.0, 0.0, 5.0, 2.0]\n            ]),\n            \"scores\": np.array([0.80, 0.80, 0.10])\n        }\n    ]\n\n    def calculate_iou(box1, box2):\n        \"\"\"Calculates Intersection over Union for two bounding boxes.\"\"\"\n        x1_1, y1_1, x2_1, y2_1 = box1\n        x1_2, y1_2, x2_2, y2_2 = box2\n\n        inter_x1 = max(x1_1, x1_2)\n        inter_y1 = max(y1_1, y1_2)\n        inter_x2 = min(x2_1, x2_2)\n        inter_y2 = min(y2_1, y2_2)\n\n        inter_w = max(0, inter_x2 - inter_x1)\n        inter_h = max(0, inter_y2 - inter_y1)\n        intersection_area = inter_w * inter_h\n\n        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n        union_area = area1 + area2 - intersection_area\n\n        if union_area == 0:\n            return 0.0\n        return intersection_area / union_area\n\n    def greedy_nms(boxes, scores, threshold):\n        \"\"\"Performs greedy Non-Maximum Suppression.\"\"\"\n        indices = np.arange(len(scores))\n        \n        # Sort by score (desc) and then index (asc for tie-breaking)\n        sorted_indices = sorted(indices, key=lambda i: (-scores[i], i))\n        \n        selected_indices = []\n        suppressed = np.zeros(len(scores), dtype=bool)\n\n        for i in sorted_indices:\n            if not suppressed[i]:\n                selected_indices.append(i)\n                for j in sorted_indices:\n                    if i != j and not suppressed[j]:\n                        iou = calculate_iou(boxes[i], boxes[j])\n                        if iou >= threshold:\n                            suppressed[j] = True\n        \n        return sorted(selected_indices)\n\n    def ilp_nms(boxes, scores, threshold):\n        \"\"\"Performs exact NMS via ILP formulation (solved by enumeration).\"\"\"\n        num_boxes = len(scores)\n        conflicts = []\n        for i in range(num_boxes):\n            for j in range(i + 1, num_boxes):\n                if calculate_iou(boxes[i], boxes[j]) >= threshold:\n                    conflicts.append((i, j))\n\n        max_score = -1.0\n        best_selection = []\n\n        # Enumerate all 2^N subsets of boxes\n        for i in range(1  num_boxes):\n            current_selection_indices = []\n            for j in range(num_boxes):\n                if (i >> j)  1:\n                    current_selection_indices.append(j)\n            \n            # Check feasibility\n            is_feasible = True\n            for c1, c2 in conflicts:\n                if c1 in current_selection_indices and c2 in current_selection_indices:\n                    is_feasible = False\n                    break\n            \n            if is_feasible:\n                current_score = np.sum(scores[current_selection_indices])\n                \n                if current_score > max_score:\n                    max_score = current_score\n                    best_selection = current_selection_indices\n                elif current_score == max_score:\n                    if not best_selection or current_selection_indices  best_selection:\n                        best_selection = current_selection_indices\n\n        return sorted(best_selection)\n\n    results = []\n    for case in test_cases:\n        t, boxes, scores = case[\"t\"], case[\"boxes\"], case[\"scores\"]\n        \n        # Greedy NMS\n        greedy_indices = greedy_nms(boxes, scores, t)\n        greedy_score = np.sum(scores[greedy_indices])\n\n        # ILP NMS\n        ilp_indices = ilp_nms(boxes, scores, t)\n        ilp_score = np.sum(scores[ilp_indices])\n\n        are_identical = (greedy_indices == ilp_indices)\n        \n        G_str = f\"[{','.join(map(str, greedy_indices))}]\"\n        O_str = f\"[{','.join(map(str, ilp_indices))}]\"\n        \n        # Format the result list for this case as a string\n        case_result_str = (\n            f\"[{G_str},\"\n            f\"{O_str},\"\n            f\"{str(are_identical)},\"\n            f\"{greedy_score:.3f},\"\n            f\"{ilp_score:.3f}]\"\n        )\n        results.append(case_result_str)\n\n    # Print the final list of results\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```", "id": "3159494"}, {"introduction": "Non-Maximum Suppression is a versatile technique that extends beyond bounding boxes to any task involving the localization of peaks in a score map, such as keypoint detection. This practice moves NMS into the domain of 2D heatmaps, where you will implement and compare two common variants: a classic iterative \"hard\" NMS and an efficient, parallelizable version based on max-pooling, a familiar operation in Convolutional Neural Networks. This will help you understand how to adapt NMS to different data representations and appreciate the practical implementation choices involved. [@problem_id:3159525]", "problem": "You are given the task of constructing synthetic two-dimensional heatmaps and evaluating two variants of Non-Maximum Suppression (NMS) for peak detection in the context of deep learning. The synthetic heatmaps are formed by superimposing isotropic Gaussian intensity peaks representing the latent activation maps produced by convolutional detectors. The goal is to determine an integer NMS radius $r(\\sigma)$ in pixels, as a function of the Gaussian standard deviation $\\sigma$, that maximizes correct retention of true peaks while suppressing duplicates, and to compare a \"hard\" greedy NMS to max-pooling-based NMS.\n\nStart from the following accepted foundations and definitions:\n\n- A two-dimensional isotropic Gaussian with center $(\\mu_x, \\mu_y) \\in \\mathbb{R}^2$ and variance $\\sigma^2$ has the form\n$$\ng(x,y \\mid \\mu_x,\\mu_y,\\sigma) = \\exp\\!\\left(-\\frac{(x-\\mu_x)^2+(y-\\mu_y)^2}{2\\sigma^2}\\right).\n$$\n- A heatmap $H(x,y)$ defined on a discrete grid of integer pixel coordinates $(x,y)$ is constructed by summing Gaussian peaks corresponding to true object centers and nearby duplicate bumps. The continuous Gaussian is sampled on the integer grid.\n- Non-Maximum Suppression (NMS) seeks to produce a set of peak coordinates while removing nearby redundant peaks. Two standard variants are considered:\n  1. Hard Non-Maximum Suppression (NMS): obtain a set of candidate local maxima, then greedily select the highest remaining peak and suppress any other candidates within a Euclidean radius $r$ around the selected peak.\n  2. Max-Pooling NMS: apply a two-dimensional maximum filter (equivalently, max-pooling in Convolutional Neural Networks (CNN)) with a square window of side length $w=2r+1$, and keep only the pixels whose value equals the pooled maximum. This suppresses all but the strongest maxima within each window.\n\nDefine the evaluation metric against the primary (intended) peak centers $G=\\{(\\mu_{x,j},\\mu_{y,j})\\}_{j=1}^K$ as follows. For any detected set of peak coordinates $D=\\{(x_i,y_i)\\}$ after NMS at radius $r$, let the matching tolerance be\n$$\nt = \\lceil \\sigma \\rceil,\n$$\nin pixels. The retention count $R(D)$ is the number of primary centers in $G$ that have at least one detected peak within Euclidean distance at most $t$. The duplicate count $U(D)$ is the number of extra detections near primaries, computed as\n$$\nU(D) = \\sum_{j=1}^K \\max\\!\\left(0,\\, \\left|\\left\\{(x_i,y_i)\\in D : \\sqrt{(x_i-\\mu_{x,j})^2+(y_i-\\mu_{y,j})^2} \\le t \\right\\}\\right| - 1\\right).\n$$\nThe score to be maximized is\n$$\nS(D) = R(D) - U(D),\n$$\nwhich increases when true peaks are retained and decreases when duplicates near true peaks survive. For each test case and each NMS method, the desired output is the radius $r$ that maximizes $S(D)$ over a given finite candidate set of radii, with ties broken in favor of the smallest $r$.\n\nYour program must perform the following steps:\n\n1. For each test case, construct a discrete heatmap $H(x,y)$ on a square grid of side length $N$ by summing the following components:\n   - Primary peaks: for each $(\\mu_{x,j},\\mu_{y,j}) \\in G$, add $a_{\\text{prim}} \\cdot g(x,y \\mid \\mu_{x,j},\\mu_{y,j},\\sigma)$.\n   - Duplicate bumps: for each primary peak, add an offset duplicate at $(\\mu_{x,j}+\\delta_{x,j}, \\mu_{y,j}+\\delta_{y,j})$ with amplitude $a_{\\text{dup}}$, i.e., add $a_{\\text{dup}} \\cdot g(x,y \\mid \\mu_{x,j}+\\delta_{x,j},\\mu_{y,j}+\\delta_{y,j},\\sigma)$. All duplicate centers must lie within the grid bounds.\n   The total heatmap is\n   $$\n   H(x,y) = \\sum_{j=1}^K \\left[a_{\\text{prim}} \\cdot g(x,y \\mid \\mu_{x,j},\\mu_{y,j},\\sigma) \\;+\\; a_{\\text{dup}} \\cdot g(x,y \\mid \\mu_{x,j}+\\delta_{x,j},\\mu_{y,j}+\\delta_{y,j},\\sigma)\\right].\n   $$\n2. Implement the two NMS methods:\n   - Hard NMS: generate candidate local maxima from $H(x,y)$ using a local $3 \\times 3$ neighborhood comparison, sort candidates by $H$ in descending order, then greedily select peaks while suppressing any candidate within Euclidean distance $\\le r$ of any already selected peak.\n   - Max-Pooling NMS: compute the maximum-filtered heatmap $\\tilde{H}(x,y)$ with a square window of side length $w=2r+1$, and keep $(x,y)$ where $H(x,y)=\\tilde{H}(x,y)$ and $H(x,y)\\ge \\tau$, with a small threshold $\\tau$ chosen to avoid trivial numerical noise (use $\\tau=10^{-3}$).\n3. For each method and each candidate radius $r$ in the test case's candidate set, compute the score $S(D)$ with tolerance $t=\\lceil \\sigma \\rceil$, then select the radius $r$ that maximizes $S(D)$, using the smallest $r$ in case of ties.\n\nTest Suite and parameters:\n\n- Case $1$ (general separation, small width, small duplicates):\n  - Grid size $N=64$.\n  - Gaussian width $\\sigma=2.0$.\n  - Primaries $G=\\{(16,16), (32,40), (48,20)\\}$.\n  - Duplicate offsets $\\Delta=\\{(1,0), (-1,1), (0,-1)\\}$.\n  - Amplitudes $a_{\\text{prim}}=1.0$, $a_{\\text{dup}}=0.7$.\n  - Candidate radii $R=\\{0,1,2,3,4,5,6\\}$.\n\n- Case $2$ (two nearby primaries, larger width):\n  - Grid size $N=64$.\n  - Gaussian width $\\sigma=4.0$.\n  - Primaries $G=\\{(24,24), (29,24), (40,40)\\}$.\n  - Duplicate offsets $\\Delta=\\{(2,0), (-2,1), (1,-1)\\}$.\n  - Amplitudes $a_{\\text{prim}}=1.0$, $a_{\\text{dup}}=0.8$.\n  - Candidate radii $R=\\{0,1,2,\\dots,12\\}$.\n\n- Case $3$ (border proximity and mixed spacing):\n  - Grid size $N=64$.\n  - Gaussian width $\\sigma=3.0$.\n  - Primaries $G=\\{(4,10), (60,54), (30,8)\\}$.\n  - Duplicate offsets $\\Delta=\\{(1,1), (0,-1), (-1,2)\\}$.\n  - Amplitudes $a_{\\text{prim}}=1.0$, $a_{\\text{dup}}=0.75$.\n  - Candidate radii $R=\\{0,1,2,\\dots,9\\}$.\n\nRequired final output format:\n\n- Your program should produce a single line of output containing the results for the three cases as a comma-separated list enclosed in square brackets. Each case result must itself be a list in the form $[r_{\\text{hard}}, S_{\\text{hard}}, r_{\\text{pool}}, S_{\\text{pool}}]$, where $r_{\\text{hard}}$ and $r_{\\text{pool}}$ are the maximizing radii for hard NMS and max-pooling NMS respectively, and $S_{\\text{hard}}$ and $S_{\\text{pool}}$ are the corresponding maximum scores. For example, the printed line must look like\n$$\n\\big[\\,[r_{\\text{hard}}^{(1)}, S_{\\text{hard}}^{(1)}, r_{\\text{pool}}^{(1)}, S_{\\text{pool}}^{(1)}],\\ [r_{\\text{hard}}^{(2)}, S_{\\text{hard}}^{(2)}, r_{\\text{pool}}^{(2)}, S_{\\text{pool}}^{(2)}],\\ [r_{\\text{hard}}^{(3)}, S_{\\text{hard}}^{(3)}, r_{\\text{pool}}^{(3)}, S_{\\text{pool}}^{(3)}]\\,\\big].\n$$\nAll radii must be expressed in pixels as integers, and all scores must be integers.", "solution": "The user's request is a valid scientific computing problem. It is well-posed, scientifically grounded in the domain of computer vision and deep learning, and objectively defined. All constants, formulas, and evaluation criteria are provided, allowing for a unique and verifiable solution.\n\nThe problem requires the implementation and evaluation of two Non-Maximum Suppression (NMS) algorithms on synthetically generated heatmaps. The solution involves several distinct steps: heatmap generation, implementation of the NMS algorithms, and a scoring procedure to find the optimal NMS radius for each algorithm.\n\n### Step 1: Heatmap Construction\n\nFirst, we construct the two-dimensional discrete heatmap $H(x,y)$. The heatmap is defined on an $N \\times N$ integer grid. The intensity at each pixel $(x,y)$ is the sum of several isotropic Gaussian functions. For each of the $K$ primary object centers $G = \\{(\\mu_{x,j}, \\mu_{y,j})\\}$, we add a \"primary\" Gaussian peak with amplitude $a_{\\text{prim}}$ and a \"duplicate\" Gaussian peak with a smaller amplitude $a_{\\text{dup}}$ at a nearby offset location $(\\mu_{x,j}+\\delta_{x,j}, \\mu_{y,j}+\\delta_{y,j})$. All peaks share the same standard deviation $\\sigma$.\n\nThe Gaussian function is given by:\n$$\ng(x,y \\mid \\mu_x,\\mu_y,\\sigma) = \\exp\\!\\left(-\\frac{(x-\\mu_x)^2+(y-\\mu_y)^2}{2\\sigma^2}\\right)\n$$\nThe total heatmap is the superposition of all these peaks:\n$$\nH(x,y) = \\sum_{j=1}^K \\left[a_{\\text{prim}} \\cdot g(x,y \\mid \\mu_{x,j},\\mu_{y,j},\\sigma) \\;+\\; a_{\\text{dup}} \\cdot g(x,y \\mid \\mu_{x,j}+\\delta_{x,j},\\mu_{y,j}+\\delta_{y,j},\\sigma)\\right]\n$$\nThis is implemented by creating a grid of coordinates and evaluating the sum of Gaussian functions at each grid point.\n\n### Step 2: Implementation of NMS Algorithms\n\nWe implement two distinct NMS variants.\n\n**A. Hard Non-Maximum Suppression (Hard NMS)**\n\nThis is a greedy, iterative algorithm.\n1.  **Candidate Selection**: First, we identify a set of candidate peaks. A pixel $(x,y)$ is considered a candidate if its value $H(x,y)$ is a local maximum, i.e., greater than or equal to the values of its $8$ immediate neighbors. This can be efficiently found by comparing the heatmap to a version of itself filtered by a $3 \\times 3$ maximum filter.\n2.  **Sorting**: The candidate peaks are sorted in descending order based on their intensity values in the heatmap $H$.\n3.  **Greedy Suppression**: We iterate through the sorted list of candidates. The highest-valued candidate is selected and added to the final set of detected peaks. Then, all other candidates that lie within a Euclidean distance of $r$ from this selected peak are marked as suppressed and are removed from consideration. This process is repeated with the next highest-valued, unsuppressed candidate until all candidates have been either selected or suppressed.\n\n**B. Max-Pooling Non-Maximum Suppression (Max-Pooling NMS)**\n\nThis algorithm leverages a maximum filter, an operation equivalent to the max-pooling layers common in CNNs.\n1.  **Maximum Filtering**: A maximum filter with a square window of side length $w=2r+1$ is applied to the entire heatmap $H(x,y)$ to produce a new map, $\\tilde{H}(x,y)$. Each pixel $\\tilde{H}(x,y)$ contains the maximum value from the $w \\times w$ neighborhood centered at $(x,y)$ in the original heatmap.\n2.  **Peak Identification**: A pixel $(x,y)$ is identified as a peak if its original value $H(x,y)$ is equal to the filtered value $\\tilde{H}(x,y)$, indicating it is the maximum in its local $w \\times w$ window. Additionally, a threshold $\\tau = 10^{-3}$ is applied, so we only keep peaks where $H(x,y) \\ge \\tau$. This prevents the selection of trivial maxima in low-intensity or flat regions.\n\n### Step 3: Evaluation and Optimization\n\nTo evaluate the performance of each NMS algorithm for a given radius $r$, we compute a score $S(D)$ based on the set of detected peaks $D$ and the ground truth primary centers $G$.\n\nThe matching tolerance is defined as $t = \\lceil \\sigma \\rceil$. A detected peak is considered associated with a primary center if the Euclidean distance between them is at most $t$.\n\nThe score is composed of two parts:\n-   **Retention Count $R(D)$**: The number of primary centers in $G$ that have at least one detected peak within the tolerance distance $t$. This rewards the algorithm for finding the true peaks.\n-   **Duplicate Count $U(D)$**: For each primary center, we count how many detected peaks are associated with it. If this count is greater than $1$, the excess detections contribute to the duplicate count. Formally, $U(D) = \\sum_{j=1}^K \\max(0, (\\text{number of detections near } (\\mu_{x,j},\\mu_{y,j})) - 1)$. This penalizes the algorithm for failing to suppress redundant detections near a true peak.\n\nThe final score is $S(D) = R(D) - U(D)$. Our goal is to find the integer radius $r$ from a given set of candidates that maximizes this score. In case of a tie in the score, the smaller radius $r$ is chosen.\n\nFor each test case and for each of the two NMS methods, we iterate through all candidate radii, compute the set of detected peaks $D$, calculate the score $S(D)$, and identify the radius that yields the maximum score according to the specified criteria. The final output aggregates these optimal radii and their corresponding scores for all test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.ndimage import maximum_filter\nimport math\n\ndef create_heatmap(N, G, Delta, sigma, a_prim, a_dup):\n    \"\"\"Constructs a 2D heatmap by summing Gaussian peaks.\"\"\"\n    x = np.arange(0, N, dtype=np.float64)\n    y = np.arange(0, N, dtype=np.float64)\n    xx, yy = np.meshgrid(x, y, indexing='xy')\n    heatmap = np.zeros((N, N), dtype=np.float64)\n\n    def gaussian(x_grid, y_grid, mu_x, mu_y, sigma_val):\n        return np.exp(-((x_grid - mu_x)**2 + (y_grid - mu_y)**2) / (2 * sigma_val**2))\n\n    for i, (mu_x, mu_y) in enumerate(G):\n        # Primary peak\n        heatmap += a_prim * gaussian(xx, yy, mu_x, mu_y, sigma)\n        \n        # Duplicate peak\n        delta_x, delta_y = Delta[i]\n        dup_mu_x, dup_mu_y = mu_x + delta_x, mu_y + delta_y\n        heatmap += a_dup * gaussian(xx, yy, dup_mu_x, dup_mu_y, sigma)\n        \n    return heatmap\n\ndef hard_nms(heatmap, r):\n    \"\"\"Performs Hard Non-Maximum Suppression.\"\"\"\n    local_max = (heatmap == maximum_filter(heatmap, size=3, mode='constant', cval=-np.inf))\n    \n    # Filter out maxima in zero-regions to avoid trivial candidates\n    local_max = (heatmap > 1e-9)\n\n    cand_coords_yx = np.argwhere(local_max)\n    if cand_coords_yx.shape[0] == 0:\n        return []\n    \n    cand_values = heatmap[local_max]\n    \n    sorted_indices = np.argsort(cand_values)[::-1]\n    sorted_coords_yx = cand_coords_yx[sorted_indices]\n    \n    selected_peaks_yx = []\n    suppressed = np.zeros(len(sorted_coords_yx), dtype=bool)\n    \n    for i in range(len(sorted_coords_yx)):\n        if suppressed[i]:\n            continue\n        \n        current_peak_yx = sorted_coords_yx[i]\n        selected_peaks_yx.append(current_peak_yx)\n        \n        for j in range(i + 1, len(sorted_coords_yx)):\n            if suppressed[j]:\n                continue\n            \n            other_peak_yx = sorted_coords_yx[j]\n            dist = np.linalg.norm(current_peak_yx - other_peak_yx)\n            if dist = r:\n                suppressed[j] = True\n    \n    # Return list of (x,y) tuples\n    return [(p[1], p[0]) for p in selected_peaks_yx]\n\ndef max_pooling_nms(heatmap, r, threshold=1e-3):\n    \"\"\"Performs Non-Maximum Suppression using a max-pooling approach.\"\"\"\n    w = 2 * r + 1\n    if w = 1:\n        pooled_map = heatmap\n    else:\n        pooled_map = maximum_filter(heatmap, size=w, mode='constant', cval=0)\n    \n    peaks = (heatmap == pooled_map)  (heatmap >= threshold)\n    peak_coords_yx = np.argwhere(peaks)\n    \n    # Return list of (x,y) tuples\n    return [(p[1], p[0]) for p in peak_coords_yx]\n\ndef calculate_score(detected_peaks, ground_truth, tolerance):\n    \"\"\"Calculates the R(D) - U(D) score.\"\"\"\n    if not detected_peaks:\n        return 0, 0, 0 \n\n    K = len(ground_truth)\n    gt_array = np.array(ground_truth, dtype=np.float64)\n    det_array = np.array(detected_peaks, dtype=np.float64)\n\n    # dists[i, j] = distance between detected peak i and ground truth j\n    dists = np.linalg.norm(det_array[:, np.newaxis, :] - gt_array[np.newaxis, :, :], axis=2)\n    \n    matches_per_gt = np.sum(dists = tolerance, axis=0)\n    \n    retention_count = np.sum(matches_per_gt > 0)\n    duplicate_count = np.sum(np.maximum(0, matches_per_gt - 1))\n    \n    score = retention_count - duplicate_count\n    \n    return int(retention_count), int(duplicate_count), int(score)\n\ndef solve():\n    test_cases = [\n        {\n            \"N\": 64, \"sigma\": 2.0, \"G\": [(16, 16), (32, 40), (48, 20)],\n            \"Delta\": [(1, 0), (-1, 1), (0, -1)],\n            \"a_prim\": 1.0, \"a_dup\": 0.7,\n            \"R_cand\": list(range(7))\n        },\n        {\n            \"N\": 64, \"sigma\": 4.0, \"G\": [(24, 24), (29, 24), (40, 40)],\n            \"Delta\": [(2, 0), (-2, 1), (1, -1)],\n            \"a_prim\": 1.0, \"a_dup\": 0.8,\n            \"R_cand\": list(range(13))\n        },\n        {\n            \"N\": 64, \"sigma\": 3.0, \"G\": [(4, 10), (60, 54), (30, 8)],\n            \"Delta\": [(1, 1), (0, -1), (-1, 2)],\n            \"a_prim\": 1.0, \"a_dup\": 0.75,\n            \"R_cand\": list(range(10))\n        }\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        N = case[\"N\"]\n        sigma = case[\"sigma\"]\n        G = case[\"G\"]\n        Delta = case[\"Delta\"]\n        a_prim = case[\"a_prim\"]\n        a_dup = case[\"a_dup\"]\n        R_cand = case[\"R_cand\"]\n        \n        heatmap = create_heatmap(N, G, Delta, sigma, a_prim, a_dup)\n        tolerance = math.ceil(sigma)\n        \n        # Hard NMS evaluation\n        best_score_hard = -1000  # -infinity\n        best_r_hard = -1\n        for r in R_cand:\n            detected_peaks = hard_nms(heatmap, r)\n            _, _, score = calculate_score(detected_peaks, G, tolerance)\n            if score > best_score_hard:\n                best_score_hard = score\n                best_r_hard = r\n        \n        # Max-Pooling NMS evaluation\n        best_score_pool = -1000 # -infinity\n        best_r_pool = -1\n        for r in R_cand:\n            detected_peaks = max_pooling_nms(heatmap, r)\n            _, _, score = calculate_score(detected_peaks, G, tolerance)\n            if score > best_score_pool:\n                best_score_pool = score\n                best_r_pool = r\n        \n        final_results.append([best_r_hard, best_score_hard, best_r_pool, best_score_pool])\n\n    result_str = \",\".join([f\"[{','.join(map(str, res))}]\" for res in final_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3159525"}, {"introduction": "A significant drawback of \"hard\" NMS is its tendency to be overly aggressive, suppressing correct detections in crowded scenes where objects have moderate overlap. This practice introduces a more nuanced hybrid NMS scheme that combines the score attenuation of Soft-NMS for medium overlaps with hard suppression for high overlaps. You will not only implement this advanced variant but also learn to tune its thresholds by performing a grid search to maximize a crucial performance metric, the F1-score, connecting NMS parameterization directly to model validation. [@problem_id:3159559]", "problem": "You are given a hybrid Non-Maximum Suppression (NMS) scheme for object detection that combines hard suppression for high overlap and score attenuation for medium overlap. Build a complete program that, for each test case described below, searches a finite grid of threshold pairs to select the optimal thresholds that maximize a validation objective.\n\nDefinitions and foundational base:\n- Intersection over Union (IoU) for two axis-aligned rectangles with lower-left and upper-right corners given by coordinates $[x_1,y_1,x_2,y_2]$ is defined as the ratio of the intersection area to the union area. Concretely, for boxes $A$ and $B$, the intersection width is $\\max(0,\\min(x_2^A,x_2^B)-\\max(x_1^A,x_1^B))$, the intersection height is $\\max(0,\\min(y_2^A,y_2^B)-\\max(y_1^A,y_1^B))$, the intersection area is the product of these, and the union area is the sum of the areas of $A$ and $B$ minus the intersection area. The IoU is the intersection area divided by the union area, with the convention that if the union is zero, the IoU is zero.\n- Non-Maximum Suppression (NMS) is a post-processing step that keeps a subset of predicted bounding boxes by suppressing redundant predictions based on pairwise IoU and confidence scores.\n- Soft Non-Maximum Suppression (Soft-NMS) attenuates, rather than deletes, scores of boxes that overlap with a selected box according to a weighting function.\n- In this hybrid scheme, for a selected \"current\" box, any other box with IoU in the interval $[t_l,t_h)$ has its score multiplied by a weight $w(i)$, and any other box with IoU $\\ge t_h$ is hard-suppressed by setting its score to zero. Below $t_l$ no changes are applied. For this problem, use a linear weighting function $w(i) = 1 - \\mathrm{IoU}$ for the soft attenuation step.\n\nAlgorithmic specification to implement:\n- Input to hybrid NMS: a set of predicted boxes with associated scores. Process them iteratively by repeatedly selecting the box with the largest current score (break ties by the smallest original index), and then updating the scores of the remaining boxes according to the rules:\n  - If $\\mathrm{IoU} \\ge t_h$, set the other box’s score to $0$ (hard suppression).\n  - Else if $\\mathrm{IoU} \\in [t_l,t_h)$, set the other box’s score to its current score multiplied by $(1 - \\mathrm{IoU})$ (soft attenuation).\n  - Else leave the score unchanged.\n- Continue until no box has a positive score. The retained set is the list of all boxes that were selected by the iterative process, each with its final score. Then, apply a final score threshold $s_{\\min}$ and discard any selected box with final score $ s_{\\min}$.\n\nValidation objective and matching:\n- For evaluation, perform one-to-one greedy matching between the post-NMS predicted boxes and the provided ground-truth boxes: sort the predicted boxes by final score in descending order; for each predicted box in that order, match it to the single currently unmatched ground-truth box with the highest IoU if that IoU is at least a matching threshold $\\tau_{\\mathrm{match}}$. Count matches as true positives, unmatched predictions as false positives, and unmatched ground truths as false negatives. Compute the F1-score as\n$$\n\\mathrm{F1} \\;=\\; \\frac{2 \\cdot \\mathrm{TP}}{2 \\cdot \\mathrm{TP} + \\mathrm{FP} + \\mathrm{FN}}.\n$$\n- The optimal thresholds $(t_l,t_h)$ maximize the F1-score over a finite search grid given per test case. Ties must be broken deterministically by choosing the pair with the largest $t_h$, and if still tied, choosing the smallest $t_l$.\n\nHybrid scheme recap in mathematical terms:\n- For each selected box $b^\\star$, for any other box $b$, with current score $s(b)$ and overlap $o = \\mathrm{IoU}(b^\\star, b)$:\n  - If $o \\ge t_h$, set $s(b) \\leftarrow 0$.\n  - Else if $t_l \\le o  t_h$, set $s(b) \\leftarrow s(b)\\cdot (1 - o)$.\n  - Else leave $s(b)$ unchanged.\n- After iterating until no positive scores remain, keep only selected boxes with final score $\\ge s_{\\min}$.\n\nYour program must implement the hybrid NMS and perform a grid search over $(t_l,t_h)$ for each test case.\n\nTest suite:\nFor each test case, you are given predicted boxes and scores, ground-truth boxes, score threshold $s_{\\min}$, IoU matching threshold $\\tau_{\\mathrm{match}}$, and discrete candidate sets for $t_l$ and $t_h$.\n\n- Test case $1$ (two nearby objects, duplicates, and a medium-overlap large box):\n  - Predicted boxes (each as $[x_1,y_1,x_2,y_2]$) and scores:\n    - $[10,10,60,60]$ with score $0.95$,\n    - $[12,12,58,58]$ with score $0.90$,\n    - $[55,10,105,60]$ with score $0.92$,\n    - $[57,12,103,58]$ with score $0.85$,\n    - $[20,10,95,60]$ with score $0.88$.\n  - Ground-truth boxes:\n    - $[10,10,60,60]$,\n    - $[55,10,105,60]$.\n  - Score threshold $s_{\\min} = 0.50$, IoU matching threshold $\\tau_{\\mathrm{match}} = 0.50$.\n  - Search grid: $t_l \\in \\{0.20,0.30,0.40\\}$, $t_h \\in \\{0.50,0.60,0.70,0.80\\}$ with the constraint $t_l  t_h$.\n\n- Test case $2$ (boundary conditions where $\\mathrm{IoU}$ equals thresholds):\n  - Predicted boxes and scores:\n    - $[10,10,30,30]$ with score $0.95$,\n    - $[10,10,22,30]$ with score $0.80$,\n    - $[10,10,22,20]$ with score $0.70$.\n  - Ground-truth boxes:\n    - $[10,10,30,30]$.\n  - Note: $\\mathrm{IoU}$ between $[10,10,30,30]$ and $[10,10,22,30]$ is $0.60$, and between $[10,10,30,30]$ and $[10,10,22,20]$ is $0.30$.\n  - Score threshold $s_{\\min} = 0.50$, IoU matching threshold $\\tau_{\\mathrm{match}} = 0.50$.\n  - Search grid: $t_l \\in \\{0.30,0.40\\}$, $t_h \\in \\{0.60,0.70\\}$ with $t_l  t_h$.\n\n- Test case $3$ (non-overlapping predictions; tests tie-breaking):\n  - Predicted boxes and scores:\n    - $[0,0,20,20]$ with score $0.90$,\n    - $[40,0,60,20]$ with score $0.85$,\n    - $[80,0,100,20]$ with score $0.70$.\n  - Ground-truth boxes:\n    - $[0,0,20,20]$,\n    - $[40,0,60,20]$.\n  - Score threshold $s_{\\min} = 0.50$, IoU matching threshold $\\tau_{\\mathrm{match}} = 0.50$.\n  - Search grid: $t_l \\in \\{0.20,0.40\\}$, $t_h \\in \\{0.60,0.80\\}$ with $t_l  t_h$.\n\nRequirements:\n- Implement the hybrid NMS and validation evaluation exactly as specified, including the linear weight $w(i) = 1 - \\mathrm{IoU}$ on the interval $[t_l,t_h)$ and hard suppression for $\\mathrm{IoU} \\ge t_h$.\n- For each test case, perform a grid search over $(t_l,t_h)$ on the given candidate sets (respecting $t_l  t_h$) to find the pair that maximizes the F1-score; break ties by selecting the largest $t_h$ and, if still tied, the smallest $t_l$.\n- Final output format: Your program should produce a single line of output containing the list of optimal threshold pairs as a single list of lists of two floats, in the same order as the test cases, with each float rounded to three decimal places, and with no extra spaces. For example: $[[0.400,0.800],[0.300,0.700],[0.200,0.800]]$.", "solution": "The user-provided problem statement has been analyzed and is deemed valid. It is scientifically grounded in the domain of deep learning for object detection, well-posed with clear and consistent definitions, and objective in its formulation. The task requires the implementation of a specified hybrid Non-Maximum Suppression (NMS) algorithm, its application within a grid search procedure to find optimal parameters, and the evaluation of results using a standard F1-score metric. All necessary data, functions, and evaluation criteria are provided, enabling the derivation of a unique and verifiable solution.\n\nThe solution proceeds by first implementing the core components as specified: the Intersection over Union (IoU) calculation, the hybrid NMS algorithm, and the F1-score evaluation metric. These components are then integrated into a grid search framework to solve for the optimal threshold pair for each provided test case.\n\n**1. Intersection over Union (IoU)**\n\nThe IoU for two axis-aligned bounding boxes, $A$ and $B$, defined by their coordinates $[x_1, y_1, x_2, y_2]$, is a measure of their relative overlap. It is the ratio of their intersection area to their union area.\n\n- Let box $A$ be $[x_{1A}, y_{1A}, x_{2A}, y_{2A}]$ and box $B$ be $[x_{1B}, y_{1B}, x_{2B}, y_{2B}]$.\n- The coordinates of the intersection rectangle are:\n  - $x_{1, \\text{inter}} = \\max(x_{1A}, x_{1B})$\n  - $y_{1, \\text{inter}} = \\max(y_{1A}, y_{1B})$\n  - $x_{2, \\text{inter}} = \\min(x_{2A}, x_{2B})$\n  - $y_{2, \\text{inter}} = \\min(y_{2A}, y_{2B})$\n- The intersection area, $A_{\\text{inter}}$, is calculated as:\n$$\nA_{\\text{inter}} = \\max(0, x_{2, \\text{inter}} - x_{1, \\text{inter}}) \\cdot \\max(0, y_{2, \\text{inter}} - y_{1, \\text{inter}})\n$$\n- The area of each box is $\\text{Area}(A) = (x_{2A} - x_{1A}) \\cdot (y_{2A} - y_{1A})$ and $\\text{Area}(B) = (x_{2B} - x_{1B}) \\cdot (y_{2B} - y_{1B})$.\n- The union area, $A_{\\text{union}}$, is given by the principle of inclusion-exclusion:\n$$\nA_{\\text{union}} = \\text{Area}(A) + \\text{Area}(B) - A_{\\text{inter}}\n$$\n- The IoU is then:\n$$\n\\mathrm{IoU}(A, B) = \\frac{A_{\\text{inter}}}{A_{\\text{union}}}\n$$\nA special case is handled where $A_{\\text{union}} = 0$, in which case $\\mathrm{IoU}$ is defined as $0$.\n\n**2. Hybrid Non-Maximum Suppression (NMS)**\n\nThe specified NMS algorithm is an iterative procedure designed to prune redundant bounding box predictions. It processes a list of initial predictions, each with a confidence score.\n\nThe algorithm proceeds as follows:\n1.  Initialize a list of retained boxes, $R$, as empty. Let the set of current predictions be $P$. Original scores and indices are preserved for reference.\n2.  While there exists any box in $P$ with a score greater than $0$:\n    a. Select the box $b^\\star$ from $P$ with the highest current score. Ties are broken by choosing the box with the smallest original index.\n    b. Add $b^\\star$ to the list of retained boxes $R$, storing its score at the moment of selection. Remove $b^\\star$ from consideration in subsequent selection steps (e.g., by setting its score to a non-positive value).\n    c. For every other box $b_j$ remaining in $P$:\n        i. Calculate the overlap $o_j = \\mathrm{IoU}(b^\\star, b_j)$.\n        ii. Update the score $s(b_j)$ according to the hybrid suppression rules, governed by thresholds $t_l$ and $t_h$:\n           - If $o_j \\ge t_h$: $s(b_j) \\leftarrow 0$ (Hard Suppression).\n           - Else if $t_l \\le o_j  t_h$: $s(b_j) \\leftarrow s(b_j) \\cdot (1 - o_j)$ (Soft Attenuation).\n           - Else ($o_j  t_l$): The score $s(b_j)$ remains unchanged.\n3.  After the iterative process concludes, apply a final filtering step to the list of retained boxes $R$. Discard any box from $R$ whose final score (the score it had when selected) is less than a given threshold $s_{\\min}$.\n4.  The output is the final filtered list of retained boxes and their scores.\n\n**3. Validation Objective: F1-Score**\n\nThe performance of the NMS algorithm for a given pair of thresholds $(t_l, t_h)$ is evaluated by computing the F1-score against a set of ground-truth boxes. This involves a greedy matching procedure:\n\n1.  The set of predicted boxes from the NMS output is sorted in descending order of their final scores.\n2.  A one-to-one matching is performed. For each predicted box in the sorted list, we find the ground-truth box with which it has the highest IoU.\n3.  If this highest IoU is greater than or equal to a matching threshold, $\\tau_{\\mathrm{match}}$, and the chosen ground-truth box has not already been matched, the pair is considered a match (a True Positive, TP). Both the predicted and ground-truth boxes are marked as matched.\n4.  After iterating through all predicted boxes:\n    - True Positives (TP) are the number of successful matches.\n    - False Positives (FP) are the number of predicted boxes that could not be matched.\n    - False Negatives (FN) are the number of ground-truth boxes that were not matched.\n5.  The F1-score is then computed. If $\\mathrm{TP} + \\mathrm{FP} + \\mathrm{FN} = 0$, the F1-score is $1$. Otherwise, if $2 \\cdot \\mathrm{TP} + \\mathrm{FP} + \\mathrm{FN} = 0$, the F1-score is $0$. In all other cases:\n$$\n\\mathrm{F1} = \\frac{2 \\cdot \\mathrm{TP}}{2 \\cdot \\mathrm{TP} + \\mathrm{FP} + \\mathrm{FN}}\n$$\n\n**4. Grid Search and Optimization**\n\nFor each test case, the goal is to find the optimal pair of thresholds $(t_l, t_h)$ from a given discrete search grid. The optimization objective is to maximize the F1-score. The search iterates through all valid pairs $(t_l, t_h)$ in the grid, where $t_l  t_h$. The pair that yields the highest F1-score is chosen.\n\nA deterministic tie-breaking rule is applied:\n1.  If multiple pairs yield the same maximum F1-score, the one with the largest value of $t_h$ is preferred.\n2.  If a tie still exists (i.e., multiple pairs share the same maximum F1-score and the same largest $t_h$), the one with the smallest value of $t_l$ is chosen as the final optimum.\n\nThe final program implements these components and executes the grid search for each test case to identify and report the optimal $(t_l, t_h)$ pair according to these specifications.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the solving process for all test cases.\n    It defines test cases, runs the grid search for each, and prints the final results.\n    \"\"\"\n    test_cases = [\n        {\n            \"pred_boxes\": np.array([\n                [10, 10, 60, 60],\n                [12, 12, 58, 58],\n                [55, 10, 105, 60],\n                [57, 12, 103, 58],\n                [20, 10, 95, 60],\n            ]),\n            \"pred_scores\": np.array([0.95, 0.90, 0.92, 0.85, 0.88]),\n            \"gt_boxes\": np.array([\n                [10, 10, 60, 60],\n                [55, 10, 105, 60],\n            ]),\n            \"s_min\": 0.50,\n            \"tau_match\": 0.50,\n            \"tl_grid\": [0.20, 0.30, 0.40],\n            \"th_grid\": [0.50, 0.60, 0.70, 0.80],\n        },\n        {\n            \"pred_boxes\": np.array([\n                [10, 10, 30, 30],\n                [10, 10, 22, 30],\n                [10, 10, 22, 20],\n            ]),\n            \"pred_scores\": np.array([0.95, 0.80, 0.70]),\n            \"gt_boxes\": np.array([\n                [10, 10, 30, 30],\n            ]),\n            \"s_min\": 0.50,\n            \"tau_match\": 0.50,\n            \"tl_grid\": [0.30, 0.40],\n            \"th_grid\": [0.60, 0.70],\n        },\n        {\n            \"pred_boxes\": np.array([\n                [0, 0, 20, 20],\n                [40, 0, 60, 20],\n                [80, 0, 100, 20],\n            ]),\n            \"pred_scores\": np.array([0.90, 0.85, 0.70]),\n            \"gt_boxes\": np.array([\n                [0, 0, 20, 20],\n                [40, 0, 60, 20],\n            ]),\n            \"s_min\": 0.50,\n            \"tau_match\": 0.50,\n            \"tl_grid\": [0.20, 0.40],\n            \"th_grid\": [0.60, 0.80],\n        },\n    ]\n\n    all_optimal_pairs = []\n\n    for case in test_cases:\n        best_f1 = -1.0\n        best_tl = -1.0\n        best_th = -1.0\n\n        for t_h in case[\"th_grid\"]:\n            for t_l in case[\"tl_grid\"]:\n                if t_l >= t_h:\n                    continue\n\n                # Run hybrid NMS\n                final_preds = hybrid_nms(\n                    case[\"pred_boxes\"], case[\"pred_scores\"],\n                    t_l, t_h, case[\"s_min\"]\n                )\n\n                # Evaluate F1 score\n                current_f1 = calculate_f1_score(\n                    final_preds, case[\"gt_boxes\"], case[\"tau_match\"]\n                )\n                \n                # Update best thresholds based on F1 and tie-breaking rules\n                if current_f1 > best_f1:\n                    best_f1 = current_f1\n                    best_tl = t_l\n                    best_th = t_h\n                elif current_f1 == best_f1:\n                    if t_h > best_th:\n                        best_tl = t_l\n                        best_th = t_h\n                    elif t_h == best_th:\n                        if t_l  best_tl:\n                            best_tl = t_l\n        \n        all_optimal_pairs.append([best_tl, best_th])\n\n    # Format the final output string exactly as required\n    formatted_pairs = [f\"[{p[0]:.3f},{p[1]:.3f}]\" for p in all_optimal_pairs]\n    print(f\"[{','.join(formatted_pairs)}]\")\n\ndef calculate_iou(boxA, boxB):\n    \"\"\"Calculates Intersection over Union for two boxes.\"\"\"\n    xA = max(boxA[0], boxB[0])\n    yA = max(boxA[1], boxB[1])\n    xB = min(boxA[2], boxB[2])\n    yB = min(boxA[3], boxB[3])\n\n    inter_area = max(0, xB - xA) * max(0, yB - yA)\n    \n    boxA_area = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n    boxB_area = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n    \n    union_area = boxA_area + boxB_area - inter_area\n    \n    iou = inter_area / union_area if union_area > 0 else 0.0\n    return iou\n\ndef hybrid_nms(boxes, scores, t_l, t_h, s_min):\n    \"\"\"\n    Implements the specified hybrid Non-Maximum Suppression algorithm.\n    \"\"\"\n    num_boxes = len(boxes)\n    current_scores = np.copy(scores)\n    \n    selected_boxes_info = []\n\n    while np.max(current_scores) > 0:\n        # Find index of box with highest score. np.argmax handles ties by taking the first occurrence.\n        best_idx = np.argmax(current_scores)\n        best_box = boxes[best_idx]\n        best_score = current_scores[best_idx]\n        \n        selected_boxes_info.append({\"box\": best_box, \"score\": best_score})\n        \n        # Mark the selected box as processed\n        current_scores[best_idx] = -1.0\n        \n        for i in range(num_boxes):\n            if current_scores[i] = 0:\n                continue\n            \n            iou = calculate_iou(best_box, boxes[i])\n            \n            if iou >= t_h:\n                current_scores[i] = 0.0  # Hard suppression\n            elif t_l = iou  t_h:\n                current_scores[i] *= (1.0 - iou) # Soft attenuation\n\n    # Filter selected boxes by minimum score threshold\n    final_preds = [\n        p for p in selected_boxes_info if p[\"score\"] >= s_min\n    ]\n    return final_preds\n\ndef calculate_f1_score(pred_boxes_info, gt_boxes, tau_match):\n    \"\"\"\n    Calculates the F1 score based on greedy matching between predictions and ground truth.\n    \"\"\"\n    num_preds = len(pred_boxes_info)\n    num_gts = len(gt_boxes)\n\n    if num_preds == 0 and num_gts == 0:\n        return 1.0\n\n    # Sort predictions by score in descending order\n    sorted_preds = sorted(pred_boxes_info, key=lambda x: x[\"score\"], reverse=True)\n    \n    gt_matched = [False] * num_gts\n    tp = 0\n    \n    for pred in sorted_preds:\n        best_iou = -1.0\n        best_gt_idx = -1\n        \n        for i in range(num_gts):\n            if not gt_matched[i]:\n                iou = calculate_iou(pred[\"box\"], gt_boxes[i])\n                if iou > best_iou:\n                    best_iou = iou\n                    best_gt_idx = i\n        \n        if best_iou >= tau_match:\n            tp += 1\n            gt_matched[best_gt_idx] = True\n\n    fp = num_preds - tp\n    fn = num_gts - sum(gt_matched)\n    \n    denominator = 2 * tp + fp + fn\n    if denominator == 0:\n        return 1.0 if tp == 0 and fp == 0 and fn == 0 else 0.0\n\n    return (2 * tp) / denominator\n\n# Execute the main function\nsolve()\n```", "id": "3159559"}]}