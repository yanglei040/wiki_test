{"hands_on_practices": [{"introduction": "To build a solid foundation, we begin with an analytically tractable model that allows for the exact decomposition of uncertainty. This exercise [@problem_id:3197127] uses a Bayesian approach with a Normal-Inverse-Gamma (NIG) prior, a classic statistical tool for modeling unknown mean and variance. By working through this problem, you will see precisely how aleatoric uncertainty relates to data noise and how epistemic uncertainty decreases as more data, or 'evidence', becomes available.", "problem": "You are asked to implement Bayesian evidential regression for a univariate target using the Normal–Inverse-Gamma (NIG) prior and posterior, and to explicitly compute uncertainty decompositions. The goal is to quantify and compare epistemic uncertainty and aleatoric uncertainty in sparse versus dense data regimes. The implementation must be self-contained and produce numerical outputs for a fixed test suite.\n\nStart from the following fundamental basis in probability theory and Bayesian statistics:\n- Let the data-generating process be $y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$, where $\\mathcal{N}$ denotes the Normal distribution.\n- Use the conjugate prior $(\\mu, \\sigma^2) \\sim \\text{Normal–Inverse-Gamma (NIG)}(\\mu_0, \\kappa_0, \\alpha_0, \\beta_0)$, where the conditional prior $p(\\mu \\mid \\sigma^2) = \\mathcal{N}(\\mu_0, \\sigma^2 / \\kappa_0)$ and the marginal prior $p(\\sigma^2) = \\text{Inverse-Gamma}(\\alpha_0, \\beta_0)$.\n- For observed data $D = \\{y_1, \\dots, y_n\\}$ with sample mean $\\bar{y}$ and total sum of squared deviations $S = \\sum_{i=1}^n (y_i - \\bar{y})^2$, the posterior is $(\\mu, \\sigma^2) \\mid D \\sim \\text{NIG}(\\mu_n, \\kappa_n, \\alpha_n, \\beta_n)$ with updated parameters\n$$\n\\kappa_n = \\kappa_0 + n, \\quad\n\\mu_n = \\frac{\\kappa_0 \\mu_0 + n \\bar{y}}{\\kappa_0 + n}, \\quad\n\\alpha_n = \\alpha_0 + \\frac{n}{2}, \\quad\n\\beta_n = \\beta_0 + \\frac{1}{2} S + \\frac{1}{2} \\cdot \\frac{\\kappa_0 n}{\\kappa_0 + n} (\\bar{y} - \\mu_0)^2.\n$$\n- The posterior predictive distribution is a Student's t-distribution with location $\\mu_n$, and its variance equals\n$$\nV_{\\text{pred}} = \\frac{\\beta_n}{\\alpha_n - 1} \\left( 1 + \\frac{1}{\\kappa_n} \\right),\n$$\nprovided $\\alpha_n > 1$. The decomposition follows from the law of total variance:\n$$\nV_{\\text{alea}} = \\mathbb{E}[\\sigma^2 \\mid D] = \\frac{\\beta_n}{\\alpha_n - 1}, \\quad\nV_{\\text{epi}} = \\operatorname{Var}[\\mu \\mid D] = \\frac{\\mathbb{E}[\\sigma^2 \\mid D]}{\\kappa_n} = \\frac{\\beta_n}{(\\alpha_n - 1)\\kappa_n},\n$$\nand therefore $V_{\\text{pred}} = V_{\\text{alea}} + V_{\\text{epi}}$.\n- In evidential regression, the \"evidence level\" for the mean is quantified by the precision-like parameter $\\nu$, which corresponds here to $\\nu = \\kappa_n$; larger $\\nu$ indicates more data support in the region and thus lower epistemic uncertainty.\n\nImplement the following tasks in a single Python program:\n1. Generate data for each test case using $\\mathcal{N}(\\mu_{\\text{true}}, \\sigma_{\\text{true}}^2)$, with the sample size $n = N$. Use a fixed random seed $42$ for reproducibility. No external input is allowed.\n2. For each test case, compute the posterior parameters $(\\mu_n, \\kappa_n, \\alpha_n, \\beta_n)$ using the update equations above.\n3. Compute the evidence level $\\nu = \\kappa_n$, the aleatoric variance $V_{\\text{alea}}$, the epistemic variance $V_{\\text{epi}}$, and the predictive variance $V_{\\text{pred}}$.\n4. Round all reported numbers to six decimal places.\n\nUse the following fixed prior hyperparameters for all test cases: $\\mu_0 = 0$, $\\kappa_0 = 1$, $\\alpha_0 = 2$, $\\beta_0 = 1$.\n\nTest suite and coverage:\n- Case A (dense, low noise): $N = 200$, $\\mu_{\\text{true}} = 0$, $\\sigma_{\\text{true}} = 0.2$.\n- Case B (sparse, low noise): $N = 5$, $\\mu_{\\text{true}} = 0$, $\\sigma_{\\text{true}} = 0.2$.\n- Case C (dense, high noise): $N = 200$, $\\mu_{\\text{true}} = 0$, $\\sigma_{\\text{true}} = 1.0$.\n- Case D (extremely sparse, medium noise): $N = 1$, $\\mu_{\\text{true}} = 0$, $\\sigma_{\\text{true}} = 0.5$.\n- Case E (sparse, low noise, prior-mean conflict): $N = 5$, $\\mu_{\\text{true}} = 3.0$, $\\sigma_{\\text{true}} = 0.2$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a bracketed list corresponding to one case. For each case, output the four-tuple $[\\nu, V_{\\text{alea}}, V_{\\text{epi}}, V_{\\text{pred}}]$, all rounded to six decimal places. The final output format must be:\n\"[[v_a,a_a,e_a,p_a],[v_b,a_b,e_b,p_b],[v_c,a_c,e_c,p_c],[v_d,a_d,e_d,p_d],[v_e,a_e,e_e,p_e]]\"\nwith no spaces in the entire line.", "solution": "The problem is assessed to be valid. It is scientifically grounded in Bayesian statistical theory, well-posed with a unique and computable solution, objective, and self-contained. All necessary mathematical formulations, parameters, and test conditions are provided without ambiguity or contradiction. We may therefore proceed with a complete solution.\n\nThe objective is to implement a Bayesian evidential regression model for a univariate output. This model uses a Normal-Inverse-Gamma (NIG) conjugate prior to derive a posterior distribution over the mean $\\mu$ and variance $\\sigma^2$ of a Gaussian data-generating process. From this posterior, we will decompose the predictive uncertainty into its aleatoric and epistemic components and analyze how these components change with data sparsity and noise level.\n\nFirst, we formalize the probabilistic model. We assume the data $D = \\{y_1, \\dots, y_n\\}$ are independent and identically distributed samples from a Normal distribution with an unknown mean $\\mu$ and an unknown variance $\\sigma^2$:\n$$\ny_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\n$$\n\nThe conjugate prior for $(\\mu, \\sigma^2)$ is the Normal-Inverse-Gamma distribution, denoted as $\\text{NIG}(\\mu_0, \\kappa_0, \\alpha_0, \\beta_0)$. This prior is defined by a conditional Normal distribution for the mean, $p(\\mu \\mid \\sigma^2) = \\mathcal{N}(\\mu_0, \\sigma^2 / \\kappa_0)$, and a marginal Inverse-Gamma distribution for the variance, $p(\\sigma^2) = \\text{Inverse-Gamma}(\\alpha_0, \\beta_0)$. The hyperparameters $(\\mu_0, \\kappa_0, \\alpha_0, \\beta_0)$ encode our prior beliefs. For this problem, we use the fixed prior hyperparameters: $\\mu_0 = 0$, $\\kappa_0 = 1$, $\\alpha_0 = 2$, and $\\beta_0 = 1$.\n\nGiven a set of $n$ observations $D$, we update our prior beliefs to form the posterior distribution $p(\\mu, \\sigma^2 \\mid D)$. Due to the conjugacy of the NIG prior, the posterior is also an NIG distribution, $p(\\mu, \\sigma^2 \\mid D) \\sim \\text{NIG}(\\mu_n, \\kappa_n, \\alpha_n, \\beta_n)$. The updated parameters are calculated using the sample statistics: the sample mean $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$ and the sum of squared deviations $S = \\sum_{i=1}^n (y_i - \\bar{y})^2$. The posterior update equations are:\n$$\n\\kappa_n = \\kappa_0 + n \\\\\n\\mu_n = \\frac{\\kappa_0 \\mu_0 + n \\bar{y}}{\\kappa_0 + n} \\\\\n\\alpha_n = \\alpha_0 + \\frac{n}{2} \\\\\n\\beta_n = \\beta_0 + \\frac{1}{2} S + \\frac{1}{2} \\cdot \\frac{\\kappa_0 n}{\\kappa_0 + n} (\\bar{y} - \\mu_0)^2\n$$\nThe parameter $\\kappa_n$ can be interpreted as the \"evidence level\" $\\nu$ in evidential regression frameworks, quantifying the amount of data supporting the posterior estimate of the mean. A larger $\\kappa_n$ signifies greater confidence in the mean's location.\n\nThe core of the analysis lies in the decomposition of the total predictive variance, $V_{\\text{pred}}$. The posterior predictive distribution for a new observation is a Student's t-distribution. Its variance, $V_{\\text{pred}}$, is given by the law of total variance:\n$$\nV_{\\text{pred}} = \\operatorname{Var}(y^* \\mid D) = \\mathbb{E}[\\operatorname{Var}(y^* \\mid \\mu, \\sigma^2)] + \\operatorname{Var}(\\mathbb{E}[y^* \\mid \\mu, \\sigma^2])\n$$\nThe first term represents the inherent, irreducible randomness in the data, which is the aleatoric uncertainty. The second term represents the uncertainty in our model parameters, which can be reduced with more data, and is thus the epistemic uncertainty. For our model, this decomposition yields:\n1.  **Aleatoric Variance ($V_{\\text{alea}}$)**: The posterior expectation of the data variance, $\\sigma^2$. This is the mean of the posterior marginal Inverse-Gamma distribution for $\\sigma^2$.\n    $$\n    V_{\\text{alea}} = \\mathbb{E}[\\sigma^2 \\mid D] = \\frac{\\beta_n}{\\alpha_n - 1} \\quad (\\text{for } \\alpha_n > 1)\n    $$\n2.  **Epistemic Variance ($V_{\\text{epi}}$)**: The posterior variance of the data mean, $\\mu$.\n    $$\n    V_{\\text{epi}} = \\operatorname{Var}[\\mu \\mid D] = \\frac{\\mathbb{E}[\\sigma^2 \\mid D]}{\\kappa_n} = \\frac{\\beta_n}{(\\alpha_n - 1)\\kappa_n}\n    $$\nThe total predictive variance is the sum of these two components: $V_{\\text{pred}} = V_{\\text{alea}} + V_{\\text{epi}}$.\n\nThe implementation will proceed as follows for each test case:\n1.  Initialize a single `numpy` random number generator with a fixed seed of $42$ for reproducibility across all data generation steps.\n2.  Generate a dataset of size $N$ by drawing from $\\mathcal{N}(\\mu_{\\text{true}}, \\sigma_{\\text{true}}^2)$.\n3.  Compute the sample statistics $\\bar{y}$ and $S$. For the case $N = 1$, $S$ is correctly treated as $0$.\n4.  Apply the update equations to compute the posterior hyperparameters $\\mu_n, \\kappa_n, \\alpha_n, \\beta_n$.\n5.  Use the posterior hyperparameters to calculate the evidence level $\\nu = \\kappa_n$ and the variance components $V_{\\text{alea}}$, $V_{\\text{epi}}$, and $V_{\\text{pred}}$.\n6.  Round all four resulting numerical values to six decimal places and format them as required.\n\nThis procedure will be repeated for all five test cases, which are designed to demonstrate key behaviors:\n-   **Case A vs. B**: Shows the effect of data quantity ($N=200$ vs. $N=5$) on epistemic uncertainty. $V_{\\text{epi}}$ will be significantly smaller in Case A.\n-   **Case A vs. C**: Shows the effect of data noise ($\\sigma_{\\text{true}}=0.2$ vs. $\\sigma_{\\text{true}}=1.0$). $V_{\\text{alea}}$ will be significantly larger in Case C, reflecting the higher intrinsic variance.\n-   **Case D**: An extreme sparse case ($N=1$) where the posterior is a slight update from the prior.\n-   **Case E**: A sparse case ($N=5$) with prior-data conflict ($\\mu_{\\text{true}}=3.0$ vs. $\\mu_0=0$). The conflict term in the $\\beta_n$ update is expected to increase the estimated aleatoric and epistemic variances.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements Bayesian evidential regression with a Normal-Inverse-Gamma prior\n    to compute and decompose predictive uncertainty for several test cases.\n    \"\"\"\n    # Fixed prior hyperparameters\n    mu_0 = 0.0\n    kappa_0 = 1.0\n    alpha_0 = 2.0\n    beta_0 = 1.0\n    \n    # Test suite: (N, mu_true, sigma_true)\n    test_cases = [\n        (200, 0.0, 0.2),  # Case A: dense, low noise\n        (5, 0.0, 0.2),    # Case B: sparse, low noise\n        (200, 0.0, 1.0),  # Case C: dense, high noise\n        (1, 0.0, 0.5),    # Case D: extremely sparse, medium noise\n        (5, 3.0, 0.2),    # Case E: sparse, low noise, prior-mean conflict\n    ]\n    \n    # Initialize a single random number generator for reproducibility\n    rng = np.random.default_rng(42)\n    \n    all_results = []\n\n    for n, mu_true, sigma_true in test_cases:\n        # Step 1: Generate data\n        y_data = rng.normal(loc=mu_true, scale=sigma_true, size=n)\n        \n        # Calculate sample statistics\n        if n > 0:\n            y_bar = np.mean(y_data)\n        else:\n            # This case is not in the test suite but is handled for completeness\n            y_bar = 0.0\n            \n        if n > 1:\n            # Sum of squared deviations from the mean\n            s_stat = np.sum((y_data - y_bar)**2)\n        else:\n            # For n=0 or n=1, the sum of squared deviations is 0\n            s_stat = 0.0\n            \n        # Step 2: Compute posterior parameters\n        kappa_n = kappa_0 + n\n        mu_n = (kappa_0 * mu_0 + n * y_bar) / kappa_n\n        alpha_n = alpha_0 + n / 2.0\n        \n        beta_update_term = (kappa_0 * n / kappa_n) * (y_bar - mu_0)**2\n        beta_n = beta_0 + 0.5 * s_stat + 0.5 * beta_update_term\n        \n        # Step 3: Compute evidence level and uncertainty variances\n        # The condition alpha_n > 1 is always met since alpha_0=2 and n>=1\n        nu = kappa_n\n        v_alea = beta_n / (alpha_n - 1.0)\n        v_epi = v_alea / kappa_n\n        v_pred = v_alea + v_epi\n        \n        # Append the results for the current case\n        # nu is treated as a float for consistent formatting\n        all_results.append([float(nu), v_alea, v_epi, v_pred])\n\n    # Step 4: Format the final output string\n    case_strings = []\n    for case_result in all_results:\n        # Format each number to 6 decimal places and join into a string\n        formatted_numbers = [f\"{num:.6f}\" for num in case_result]\n        case_strings.append(f\"[{','.join(formatted_numbers)}]\")\n        \n    final_output = f\"[{','.join(case_strings)}]\"\n    \n    # Print the final result in the exact required format\n    print(final_output)\n\nsolve()\n```", "id": "3197127"}, {"introduction": "While exact Bayesian inference is insightful, it is often computationally infeasible for modern deep neural networks. This practice [@problem_id:3197106] introduces Monte Carlo (MC) Dropout, a popular and scalable technique that approximates Bayesian inference to estimate epistemic uncertainty. By comparing the uncertainty estimate from MC Dropout against the true analytical value in a simple linear regression setting, you will develop a critical understanding of how this powerful approximation works and how its performance is influenced by hyperparameters like the dropout rate.", "problem": "You are asked to design and implement a program that compares epistemic uncertainty estimated by Monte Carlo (MC) Dropout across different dropout rates with the analytically correct Bayesian posterior epistemic uncertainty in a one-dimensional linear regression problem. Your program must follow the scientific base of the law of total variance and conjugate Bayesian linear regression with a Gaussian prior and Gaussian likelihood. Do not use any heuristic formulas beyond what follows from this basis.\n\nAssume a one-dimensional linear model with additive Gaussian noise: for each training pair $(x_n, y_n)$, $y_n = w x_n + \\epsilon_n$, where $\\epsilon_n \\sim \\mathcal{N}(0,\\sigma^2)$ independently, and a prior $w \\sim \\mathcal{N}(0, s_0^2)$. The law of total variance states that for a new input $x_\\star$, the predictive variance decomposes as $\\mathrm{Var}(y_\\star \\mid x_\\star, \\mathcal{D}) = \\mathbb{E}_{w \\mid \\mathcal{D}}[\\mathrm{Var}(y_\\star \\mid x_\\star, w)] + \\mathrm{Var}_{w \\mid \\mathcal{D}}(\\mathbb{E}[y_\\star \\mid x_\\star, w])$. Use this to define the aleatoric and epistemic components separately. You must derive, from this basis, expressions needed to compute the posterior epistemic variance and the MC Dropout-induced variance at test time for a single-weight model with inverted dropout scaling.\n\nUse the following fixed dataset $\\mathcal{D}$ of size $N = 5$:\n- Inputs $x$ and outputs $y$ (each in the same index order): $x = [-2, -1, 0, 1, 2]$ and $y = [-3.12, -1.64, 0.0, 1.65, 3.14]$. Every number here is a real scalar.\n- Known noise variance $\\sigma^2 = 0.01$ and prior variance $s_0^2 = 1.0$.\n\nDefine $x_\\star = 3.0$. Estimate a single weight parameter by maximum likelihood using ordinary least squares on the given data (no intercept term). Then:\n- Compute the analytically correct Bayesian posterior epistemic variance at $x_\\star$ based on the Gaussian prior and Gaussian likelihood model.\n- Model MC Dropout at test time with a single dropout mask applied to the single weight and inverted dropout scaling. That is, use a Bernoulli mask with keep probability $(1-p)$, scaled by $\\frac{1}{1-p}$ when kept, applied to the single learned weight before predicting at $x_\\star$. From definitions of expectation and variance for a scaled Bernoulli random variable, derive and compute the dropout-induced predictive variance (do not add aleatoric noise here; interpret this dropout-induced predictive variance as the MC Dropout estimate of epistemic variance in this single-weight setting).\n\nFor each dropout rate $p$ in the test suite below, compute the signed fractional error of the MC Dropout epistemic variance with respect to the Bayesian posterior epistemic variance at $x_\\star$:\n$$\\text{fractional\\_error}(p) = \\frac{\\widehat{v}_{\\text{drop}}(p) - v_{\\text{epistemic,true}}}{v_{\\text{epistemic,true}}}.$$\n\nUse the following test suite of dropout rates:\n- $p = 0.0$ (no dropout; boundary case),\n- $p = 0.1$ (light dropout; typical case),\n- $p = 0.5$ (moderate dropout),\n- $p = 0.9$ (heavy dropout; near-degenerate mask rate).\n\nYour program must:\n- Compute the ordinary least squares estimate $\\hat{w}$ from the provided $(x,y)$,\n- Compute the Bayesian posterior epistemic variance at $x_\\star$,\n- For each $p$ in the suite, compute the MC Dropout epistemic variance at $x_\\star$ under inverted dropout scaling applied to the single weight and then the signed fractional error defined above,\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order of $p$ given above, with each value rounded to exactly six decimal places.\n\nThere are no physical units or angles in this problem. All outputs must be real-valued scalars. Your output must be exactly one list on one line, for example, $[a_1,a_2,a_3,a_4]$, where each $a_k$ is the rounded signed fractional error for the corresponding $p$.", "solution": "The problem statement has been critically validated and is determined to be scientifically grounded, well-posed, and internally consistent. It presents a comparison between the epistemic uncertainty derived from a formal Bayesian linear regression model and an estimate obtained via Monte Carlo (MC) Dropout applied to a frequentist point-estimated model. This is a standard and insightful exercise in uncertainty quantification. The necessary data, constants, and definitions are provided to permit a unique and verifiable solution.\n\nThe solution proceeds in four stages:\n1.  Estimation of the model weight $\\hat{w}$ via Ordinary Least Squares (OLS).\n2.  Calculation of the true Bayesian posterior epistemic variance, $v_{\\text{epistemic,true}}$, at the test point $x_\\star$.\n3.  Derivation and calculation of the MC Dropout-induced variance, $\\widehat{v}_{\\text{drop}}(p)$, for different dropout rates $p$.\n4.  Computation of the signed fractional error for each specified dropout rate.\n\n**1. Ordinary Least Squares (OLS) Weight Estimate**\n\nThe model is a single-parameter linear equation $y = wx$. The OLS method minimizes the sum of squared residuals, $L(w) = \\sum_{n=1}^{N} (y_n - w x_n)^2$. The weight estimate $\\hat{w}$ that minimizes $L(w)$ is found by setting the derivative with respect to $w$ to zero:\n$$ \\frac{dL}{dw} = \\sum_{n=1}^{N} -2x_n(y_n - w x_n) = 0 $$\n$$ \\sum_{n=1}^{N} x_n y_n = \\hat{w} \\sum_{n=1}^{N} x_n^2 $$\n$$ \\hat{w} = \\frac{\\sum_{n=1}^{N} x_n y_n}{\\sum_{n=1}^{N} x_n^2} $$\nUsing the provided dataset $\\mathcal{D}$, where the inputs are $\\mathbf{x} = [-2, -1, 0, 1, 2]^T$ and outputs are $\\mathbf{y} = [-3.12, -1.64, 0.0, 1.65, 3.14]^T$:\n$$ \\sum_{n=1}^{N} x_n y_n = (-2)(-3.12) + (-1)(-1.64) + (0)(0.0) + (1)(1.65) + (2)(3.14) = 6.24 + 1.64 + 0 + 1.65 + 6.28 = 15.81 $$\n$$ \\sum_{n=1}^{N} x_n^2 = (-2)^2 + (-1)^2 + 0^2 + 1^2 + 2^2 = 4 + 1 + 0 + 1 + 4 = 10 $$\nThe OLS estimate for the weight is:\n$$ \\hat{w} = \\frac{15.81}{10} = 1.581 $$\n\n**2. True Bayesian Posterior Epistemic Variance**\n\nThe problem defines the epistemic uncertainty based on the law of total variance for a new prediction $y_\\star$ at input $x_\\star$:\n$$ \\mathrm{Var}(y_\\star \\mid x_\\star, \\mathcal{D}) = \\underbrace{\\mathbb{E}_{w \\mid \\mathcal{D}}[\\mathrm{Var}(y_\\star \\mid x_\\star, w)]}_{\\text{Aleatoric Variance}} + \\underbrace{\\mathrm{Var}_{w \\mid \\mathcal{D}}(\\mathbb{E}[y_\\star \\mid x_\\star, w])}_{\\text{Epistemic Variance}} $$\nFor the model $y_\\star = w x_\\star + \\epsilon_\\star$ with noise $\\epsilon_\\star \\sim \\mathcal{N}(0, \\sigma^2)$, the components are:\n- $\\mathbb{E}[y_\\star \\mid x_\\star, w] = w x_\\star$\n- $\\mathrm{Var}(y_\\star \\mid x_\\star, w) = \\sigma^2$\nThe epistemic variance is therefore:\n$$ v_{\\text{epistemic,true}} = \\mathrm{Var}_{w \\mid \\mathcal{D}}(w x_\\star) = x_\\star^2 \\mathrm{Var}_{w \\mid \\mathcal{D}}(w) $$\nTo find the posterior variance of the weight, $\\mathrm{Var}_{w \\mid \\mathcal{D}}(w)$, we use Bayesian inference. The model specifies a Gaussian prior $w \\sim \\mathcal{N}(0, s_0^2)$ and a Gaussian likelihood $p(\\mathcal{D} \\mid w) = \\prod_n \\mathcal{N}(y_n \\mid w x_n, \\sigma^2)$. The posterior $p(w \\mid \\mathcal{D})$ is also Gaussian, $w \\mid \\mathcal{D} \\sim \\mathcal{N}(\\mu_N, s_N^2)$. The posterior precision $s_N^{-2}$ is the sum of the prior precision and the data-dependent likelihood precision:\n$$ \\frac{1}{s_N^2} = \\frac{1}{s_0^2} + \\frac{1}{\\sigma^2} \\sum_{n=1}^{N} x_n^2 $$\nUsing the given values $s_0^2 = 1.0$, $\\sigma^2 = 0.01$, and $\\sum_{n=1}^{N} x_n^2 = 10$:\n$$ \\frac{1}{s_N^2} = \\frac{1}{1.0} + \\frac{10}{0.01} = 1 + 1000 = 1001 $$\nThe posterior variance of the weight is $\\mathrm{Var}_{w \\mid \\mathcal{D}}(w) = s_N^2 = \\frac{1}{1001}$.\nAt the test point $x_\\star = 3.0$, the true epistemic variance is:\n$$ v_{\\text{epistemic,true}} = x_\\star^2 s_N^2 = (3.0)^2 \\left(\\frac{1}{1001}\\right) = \\frac{9}{1001} $$\n\n**3. MC Dropout Epistemic Variance Estimate**\n\nThe problem asks to model MC Dropout at test time by applying a stochastic mask to the OLS weight estimate $\\hat{w}$. With a dropout rate of $p$, the keep probability is $1-p$. A Bernoulli mask $z \\sim \\text{Bernoulli}(1-p)$ is applied. With inverted dropout, the stochastic weight $w_{\\text{drop}}$ is:\n$$ w_{\\text{drop}} = \\hat{w} \\frac{z}{1-p} $$\nThe prediction at $x_\\star$ is $y_\\star^{\\text{drop}} = w_{\\text{drop}} x_\\star$. The MC Dropout variance is the variance of this prediction over the distribution of the mask $z$:\n$$ \\widehat{v}_{\\text{drop}}(p) = \\mathrm{Var}_z(y_\\star^{\\text{drop}}) = \\mathrm{Var}_z\\left(\\hat{w} \\frac{z}{1-p} x_\\star\\right) $$\nSince $\\hat{w}$, $x_\\star$, and $p$ are constant with respect to $z$:\n$$ \\widehat{v}_{\\text{drop}}(p) = (\\hat{w} x_\\star)^2 \\mathrm{Var}_z\\left(\\frac{z}{1-p}\\right) = \\frac{(\\hat{w} x_\\star)^2}{(1-p)^2} \\mathrm{Var}_z(z) $$\nThe variance of a Bernoulli random variable $z \\sim \\text{Bernoulli}(\\theta)$ is $\\theta(1-\\theta)$. Here, $\\theta=1-p$, so $\\mathrm{Var}_z(z) = (1-p)(1 - (1-p)) = p(1-p)$.\nSubstituting this into the expression for $\\widehat{v}_{\\text{drop}}(p)$:\n$$ \\widehat{v}_{\\text{drop}}(p) = \\frac{(\\hat{w} x_\\star)^2}{(1-p)^2} [p(1-p)] = (\\hat{w} x_\\star)^2 \\frac{p}{1-p} $$\nUsing $\\hat{w} = 1.581$ and $x_\\star = 3.0$:\n$$ \\widehat{v}_{\\text{drop}}(p) = (1.581 \\times 3.0)^2 \\frac{p}{1-p} = (4.743)^2 \\frac{p}{1-p} = 22.496049 \\frac{p}{1-p} $$\n\n**4. Signed Fractional Error Calculation**\n\nThe signed fractional error is defined as:\n$$ \\text{fractional\\_error}(p) = \\frac{\\widehat{v}_{\\text{drop}}(p) - v_{\\text{epistemic,true}}}{v_{\\text{epistemic,true}}} = \\frac{\\widehat{v}_{\\text{drop}}(p)}{v_{\\text{epistemic,true}}} - 1 $$\nWe substitute the expressions for $\\widehat{v}_{\\text{drop}}(p)$ and $v_{\\text{epistemic,true}}$:\n$$ \\text{fractional\\_error}(p) = \\frac{22.496049 \\frac{p}{1-p}}{9/1001} - 1 = \\left(\\frac{22.496049 \\times 1001}{9}\\right) \\frac{p}{1-p} - 1 \\approx 2502.060561 \\frac{p}{1-p} - 1 $$\nWe compute this for each $p$ in the test suite $\\{0.0, 0.1, 0.5, 0.9\\}$:\n- For $p=0.0$: $\\text{fractional\\_error}(0.0) = 2502.060561 \\times 0 - 1 = -1.0$.\n- For $p=0.1$: $\\text{fractional\\_error}(0.1) = 2502.060561 \\times \\frac{0.1}{0.9} - 1 \\approx 278.006729 - 1 = 277.006729$.\n- For $p=0.5$: $\\text{fractional\\_error}(0.5) = 2502.060561 \\times \\frac{0.5}{0.5} - 1 = 2502.060561 - 1 = 2501.060561$.\n- For $p=0.9$: $\\text{fractional\\_error}(0.9) = 2502.060561 \\times \\frac{0.9}{0.1} - 1 = 22518.545049 - 1 = 22517.545049$.\n\nRounding these values to six decimal places yields the final results.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the signed fractional error of MC Dropout epistemic variance\n    with respect to the true Bayesian posterior epistemic variance for\n    a 1D linear regression problem.\n    \"\"\"\n    # Define the dataset and constants from the problem statement.\n    x_data = np.array([-2.0, -1.0, 0.0, 1.0, 2.0])\n    y_data = np.array([-3.12, -1.64, 0.0, 1.65, 3.14])\n    \n    sigma2 = 0.01  # Known noise variance\n    s02 = 1.0      # Prior variance\n    x_star = 3.0   # Test point\n    \n    # Test suite of dropout rates\n    p_values = [0.0, 0.1, 0.5, 0.9]\n\n    # Step 1: Compute the Ordinary Least Squares (OLS) estimate for the weight.\n    # The model is y = w*x, so the OLS estimate is w_hat = sum(x*y) / sum(x^2).\n    sum_xy = np.sum(x_data * y_data)\n    sum_x2 = np.sum(x_data**2)\n    w_hat = sum_xy / sum_x2\n\n    # Step 2: Compute the analytically correct Bayesian posterior epistemic variance.\n    # Posterior precision s_N^-2 = s_0^-2 + sum(x^2)/sigma^2\n    # Posterior variance s_N^2 = 1 / (1/s02 + sum_x2/sigma2)\n    posterior_variance_w = 1.0 / (1.0/s02 + sum_x2/sigma2)\n    # Epistemic variance at x_star is v_epistemic = x_star^2 * Var(w|D)\n    v_epistemic_true = x_star**2 * posterior_variance_w\n\n    results = []\n    for p in p_values:\n        # Step 3: Compute the MC Dropout epistemic variance estimate.\n        # This is the variance of the prediction over the dropout mask distribution.\n        # With inverted dropout, v_drop = (w_hat * x_star)^2 * p / (1-p).\n        if p == 1.0:\n            # Although not in the test suite, this is the theoretical limit.\n            v_drop = np.inf\n        else:\n            v_drop = (w_hat * x_star)**2 * p / (1.0 - p)\n\n        # Step 4: Compute the signed fractional error.\n        # fractional_error = (v_drop - v_epistemic_true) / v_epistemic_true\n        fractional_error = (v_drop / v_epistemic_true) - 1.0\n        results.append(fractional_error)\n\n    # Format the final results as a string with each value rounded to 6 decimal places.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3197106"}, {"introduction": "With a grasp of how to calculate and approximate epistemic uncertainty, we can now explore its deeper implications for model reliability. This practice [@problem_id:3197111] delves into the connection between high epistemic uncertainty and model vulnerability to adversarial attacks. You will learn how to find input perturbations that maximally increase the model's uncertainty, demonstrating that a model's 'unknowns' can be actively exploited.", "problem": "Consider Bayesian Linear Regression (BLR) with a Gaussian prior and Gaussian likelihood. Let the parameter vector be $w \\in \\mathbb{R}^d$ with prior $p(w) = \\mathcal{N}(0, \\alpha^{-1} I_d)$, where $\\alpha > 0$ is the prior precision and $I_d$ is the $d \\times d$ identity matrix. Given a design matrix $X \\in \\mathbb{R}^{N \\times d}$ and targets $y \\in \\mathbb{R}^N$, the likelihood is $p(y \\mid X, w) = \\mathcal{N}(X w, \\sigma^2 I_N)$, where $\\sigma^2 > 0$ is the known observation noise variance. For a test input $x_* \\in \\mathbb{R}^d$, the BLR posterior induces a Gaussian predictive distribution for $y_*$ with mean and variance determined by the posterior over $w$. The predictive variance decomposes additively into epistemic and aleatoric components.\n\nStarting from the fundamental definitions of Bayes' theorem with Gaussian prior and likelihood, and linear regression, derive how the posterior over $w$ is Gaussian, identify the posterior covariance, and show that the predictive variance at $x_*$ can be written in the form\n$$\n\\mathrm{Var}(y_* \\mid x_*, X, y) \\;=\\; \\underbrace{x_*^\\top S_N x_*}_{\\text{epistemic}} \\;+\\; \\underbrace{\\sigma^2}_{\\text{aleatoric}},\n$$\nwhere $S_N \\in \\mathbb{R}^{d \\times d}$ is the posterior covariance of $w$.\n\nNow, introduce input perturbations $\\delta \\in \\mathbb{R}^d$ subject to an $\\ell_2$-norm constraint $\\|\\delta\\|_2 \\le \\epsilon$ for a given $\\epsilon \\ge 0$. Define two types of perturbations:\n- Adversarial perturbations: choose $\\delta$ to maximize the epistemic component $(x_* + \\delta)^\\top S_N (x_* + \\delta)$ under the constraint $\\|\\delta\\|_2 \\le \\epsilon$.\n- Natural perturbations: model $\\delta \\sim \\mathcal{N}(0, \\eta^2 I_d)$ with $\\eta^2 \\ge 0$, and consider the expected epistemic component $\\mathbb{E}[(x_* + \\delta)^\\top S_N (x_* + \\delta)]$.\n\nYour task is to implement a program that, for each provided test case, computes:\n1. The BLR posterior covariance $S_N$ from $X$, $\\alpha$, and $\\sigma^2$.\n2. The baseline predictive variance at $x_*$, and its epistemic and aleatoric parts.\n3. The maximal adversarial epistemic variance $(x_* + \\delta_{\\text{adv}})^\\top S_N (x_* + \\delta_{\\text{adv}})$ where $\\delta_{\\text{adv}}$ solves the $\\ell_2$-constrained maximization.\n4. The expected natural epistemic variance $\\mathbb{E}[(x_* + \\delta)^\\top S_N (x_* + \\delta)]$ with $\\delta \\sim \\mathcal{N}(0, \\eta^2 I_d)$.\n5. A boolean indicating whether the adversarial perturbation increases the total predictive variance more than the expected increase under natural perturbations.\n6. A boolean indicating whether the aleatoric component remains unchanged under both perturbations (within a numerical tolerance of $10^{-12}$).\n\nUse the following test suite of parameter values, with all numerical values specified:\n\n- Test case $1$ (happy path, moderate prior strength and small perturbations):\n  - $X = \\begin{bmatrix} 1 & -1 \\\\ 1 & 0 \\\\ 1 & 1 \\\\ 1 & 2 \\end{bmatrix}$, $y = \\begin{bmatrix} 0.0 \\\\ 1.0 \\\\ 2.0 \\\\ 3.0 \\end{bmatrix}$, $x_* = \\begin{bmatrix} 1.0 \\\\ 0.5 \\end{bmatrix}$.\n  - $\\alpha = 1.0$, $\\sigma^2 = 0.04$, $\\epsilon = 0.2$, $\\eta^2 = 0.01$.\n\n- Test case $2$ (boundary condition with zero adversarial radius):\n  - $X = \\begin{bmatrix} 1 & -1 \\\\ 1 & 0 \\\\ 1 & 1 \\\\ 1 & 2 \\end{bmatrix}$, $y = \\begin{bmatrix} 0.0 \\\\ 1.0 \\\\ 2.0 \\\\ 3.0 \\end{bmatrix}$, $x_* = \\begin{bmatrix} 1.0 \\\\ -1.0 \\end{bmatrix}$.\n  - $\\alpha = 1.0$, $\\sigma^2 = 0.04$, $\\epsilon = 0.0$, $\\eta^2 = 0.0025$.\n\n- Test case $3$ (edge case with few data and weak prior leading to higher epistemic variance):\n  - $X = \\begin{bmatrix} 1 & -2 \\\\ 1 & 2 \\end{bmatrix}$, $y = \\begin{bmatrix} -1.0 \\\\ 1.2 \\end{bmatrix}$, $x_* = \\begin{bmatrix} 1.0 \\\\ 3.0 \\end{bmatrix}$.\n  - $\\alpha = 0.1$, $\\sigma^2 = 0.25$, $\\epsilon = 0.5$, $\\eta^2 = 0.0$.\n\nFor each test case, let the baseline epistemic variance be $E_{\\text{base}} = x_*^\\top S_N x_*$ and the baseline aleatoric variance be $A_{\\text{base}} = \\sigma^2$. Let $E_{\\text{adv}} = (x_* + \\delta_{\\text{adv}})^\\top S_N (x_* + \\delta_{\\text{adv}})$ and $E_{\\text{nat}} = \\mathbb{E}[(x_* + \\delta)^\\top S_N (x_* + \\delta)]$. For natural perturbations with $\\delta \\sim \\mathcal{N}(0, \\eta^2 I_d)$, use the identity\n$$\n\\mathbb{E}\\big[(x_* + \\delta)^\\top S_N (x_* + \\delta)\\big] \\;=\\; x_*^\\top S_N x_* \\;+\\; \\eta^2 \\operatorname{tr}(S_N).\n$$\n\nDefine the boolean $b_1$ as true if the adversarial increase in total predictive variance is at least as large as the expected natural increase, that is,\n$$\nb_1 \\;=\\; \\big( (E_{\\text{adv}} - E_{\\text{base}}) \\;\\ge\\; (\\eta^2 \\operatorname{tr}(S_N)) \\big).\n$$\nDefine the boolean $b_2$ as true if the aleatoric component remains unchanged under both perturbations to within tolerance $10^{-12}$, that is,\n$$\nb_2 \\;=\\; \\big( |A_{\\text{base}} - \\sigma^2| < 10^{-12} \\big),\n$$\nwhich checks invariance of the aleatoric term under both perturbations.\n\nYour program should produce a single line of output containing the six booleans for the three test cases, ordered as $[b_{1,1}, b_{2,1}, b_{1,2}, b_{2,2}, b_{1,3}, b_{2,3}]$, as a comma-separated list enclosed in square brackets (for example, $[True,False,...]$). No additional text should be printed.", "solution": "The user-provided problem is valid. It is scientifically grounded in Bayesian statistics and linear algebra, well-posed with a clear objective and sufficient data, and objective in its formulation. We will proceed with a full solution.\n\n### 1. Theoretical Derivation\n\n#### 1.1. Posterior Distribution of Weights\n\nWe begin with Bayesian Linear Regression. The model parameters are the weights $w \\in \\mathbb{R}^d$.\nThe prior distribution over the weights is a zero-mean Gaussian:\n$$p(w) = \\mathcal{N}(w \\mid 0, \\alpha^{-1} I_d) \\propto \\exp\\left(-\\frac{\\alpha}{2} w^\\top w\\right)$$\nwhere $\\alpha > 0$ is the prior precision and $I_d$ is the $d \\times d$ identity matrix.\n\nGiven a training dataset with design matrix $X \\in \\mathbb{R}^{N \\times d}$ and target values $y \\in \\mathbb{R}^N$, the likelihood of the data is also Gaussian:\n$$p(y \\mid X, w) = \\mathcal{N}(y \\mid Xw, \\sigma^2 I_N) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} (y - Xw)^\\top(y - Xw)\\right)$$\nwhere $\\sigma^2 > 0$ is the known variance of the observation noise.\n\nTo find the posterior distribution $p(w \\mid X, y)$, we apply Bayes' theorem:\n$$p(w \\mid X, y) \\propto p(y \\mid X, w) p(w)$$\nSubstituting the expressions for the likelihood and prior:\n$$p(w \\mid X, y) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} (y - Xw)^\\top(y - Xw) - \\frac{\\alpha}{2} w^\\top w\\right)$$\nThe posterior is proportional to the exponential of a function of $w$. To identify the distribution, we examine the argument of the exponential, focusing on terms involving $w$:\n$$L(w) = -\\frac{1}{2\\sigma^2} (y^\\top y - 2y^\\top Xw + w^\\top X^\\top Xw) - \\frac{\\alpha}{2} w^\\top w$$\n$$L(w) = -\\frac{1}{2} \\left( \\frac{1}{\\sigma^2} w^\\top X^\\top Xw - \\frac{2}{\\sigma^2} y^\\top Xw + \\alpha w^\\top I_d w \\right) + \\text{const.}$$\n$$L(w) = -\\frac{1}{2} \\left( w^\\top \\left(\\frac{1}{\\sigma^2} X^\\top X + \\alpha I_d\\right) w - 2 \\left(\\frac{1}{\\sigma^2} X^\\top y\\right)^\\top w \\right) + \\text{const.}$$\nThis is a quadratic form in $w$. A Gaussian distribution $\\mathcal{N}(w \\mid m, S)$ has a log-probability density of the form $-\\frac{1}{2}(w-m)^\\top S^{-1}(w-m) + \\text{const} = -\\frac{1}{2}(w^\\top S^{-1}w - 2m^\\top S^{-1}w) + \\text{const}$.\nBy comparing the quadratic and linear terms in $w$, we can identify the inverse covariance (precision matrix) $S_N^{-1}$ and the mean $m_N$ of the posterior distribution.\n\nThe quadratic term gives the posterior precision matrix:\n$$S_N^{-1} = \\frac{1}{\\sigma^2} X^\\top X + \\alpha I_d$$\nTherefore, the posterior covariance matrix is:\n$$S_N = \\left(\\frac{1}{\\sigma^2} X^\\top X + \\alpha I_d\\right)^{-1}$$\nThe linear term gives the mean: $m_N^\\top S_N^{-1} = (\\frac{1}{\\sigma^2} X^\\top y)^\\top$, which leads to $m_N = S_N \\left(\\frac{1}{\\sigma^2} X^\\top y\\right)$.\nThus, the posterior distribution over the weights is a Gaussian:\n$$p(w \\mid X, y) = \\mathcal{N}(w \\mid m_N, S_N)$$\n\n#### 1.2. Predictive Distribution and Variance Decomposition\n\nFor a new test input $x_* \\in \\mathbb{R}^d$, we wish to find the predictive distribution of the corresponding output $y_*$. This is obtained by marginalizing over the posterior of the weights:\n$$p(y_* \\mid x_*, X, y) = \\int p(y_* \\mid x_*, w) p(w \\mid X, y) dw$$\nHere, $p(y_* \\mid x_*, w) = \\mathcal{N}(y_* \\mid x_*^\\top w, \\sigma^2)$ is the likelihood for the test point, and $p(w \\mid X, y) = \\mathcal{N}(w \\mid m_N, S_N)$ is the posterior. This is an integral over the product of two Gaussians, which results in a Gaussian predictive distribution.\n\nWe are interested in the variance of this predictive distribution, $\\mathrm{Var}(y_* \\mid x_*, X, y)$. We use the law of total variance:\n$$\\mathrm{Var}(y_*) = \\mathbb{E}_{w}[\\mathrm{Var}(y_* \\mid w)] + \\mathrm{Var}_{w}[\\mathbb{E}(y_* \\mid w)]$$\n1.  **Aleatoric Uncertainty**: The first term is the expectation of the observation noise variance over the posterior of $w$.\n    $$\\mathbb{E}_{w}[\\mathrm{Var}(y_* \\mid x_*, w)] = \\mathbb{E}_{w}[\\sigma^2] = \\sigma^2$$\n    This is the aleatoric uncertainty. It is irreducible and represents the inherent stochasticity in the data-generating process. It does not depend on the quantity or quality of the data.\n\n2.  **Epistemic Uncertainty**: The second term is the variance of the model's prediction due to uncertainty in the parameters $w$.\n    $$\\mathrm{Var}_{w}[\\mathbb{E}(y_* \\mid x_*, w)] = \\mathrm{Var}_{w}[x_*^\\top w]$$\n    Since $w \\sim \\mathcal{N}(m_N, S_N)$, the linear transformation $x_*^\\top w$ results in a scalar random variable. Its variance is given by:\n    $$\\mathrm{Var}(x_*^\\top w) = x_*^\\top \\mathrm{Cov}(w) x_* = x_*^\\top S_N x_*$$\n    This is the epistemic uncertainty. It represents the model's uncertainty about the parameters $w$ and can be reduced by observing more data, which would shrink the posterior covariance $S_N$.\n\nSumming the two components, the total predictive variance is:\n$$\\mathrm{Var}(y_* \\mid x_*, X, y) = \\underbrace{x_*^\\top S_N x_*}_{\\text{epistemic}} + \\underbrace{\\sigma^2}_{\\text{aleatoric}}$$\nThis matches the form specified in the problem statement.\n\n#### 1.3. Input Perturbations\n\nWe analyze two types of perturbations $\\delta$ to the input $x_*$.\n\n1.  **Adversarial Perturbations**: We seek to find $\\delta_{adv}$ that maximizes the epistemic variance component for the perturbed input $x_* + \\delta$, subject to an $\\ell_2$-norm constraint $\\|\\delta\\|_2 \\le \\epsilon$. The objective is to maximize $f(\\delta) = (x_* + \\delta)^\\top S_N (x_* + \\delta)$. Since $S_N$ is positive definite, $f(\\delta)$ is a convex function. The maximum of a convex function over a compact convex set (the $\\ell_2$-ball) must lie on the boundary of the set, so $\\|\\delta_{adv}\\|_2 = \\epsilon$ (unless $\\epsilon=0$). Finding the exact solution requires solving a trust-region-like problem. A standard and computationally tractable approach in the context of adversarial examples is to approximate the solution by taking a single gradient ascent step from $\\delta=0$. The gradient of the objective with respect to $\\delta$ is $\\nabla_\\delta f(\\delta) = 2 S_N (x_* + \\delta)$. At $\\delta = 0$, the gradient is $2 S_N x_*$. The ascent direction is thus $S_N x_*$. To satisfy the constraint, we scale this direction to have length $\\epsilon$:\n    $$\\delta_{adv} = \\epsilon \\frac{S_N x_*}{\\|S_N x_*\\|_2}$$\n    This interpretation is used for the computation. If $\\|S_N x_*\\|_2=0$ or $\\epsilon=0$, then $\\delta_{adv}=0$. The maximal adversarial epistemic variance is then $E_{\\text{adv}} = (x_* + \\delta_{adv})^\\top S_N (x_* + \\delta_{adv})$.\n\n2.  **Natural Perturbations**: The perturbation $\\delta$ is modeled as a random variable $\\delta \\sim \\mathcal{N}(0, \\eta^2 I_d)$. We are interested in the expected epistemic variance. As given and verified in the problem derivation, this is:\n    $$E_{\\text{nat}} = \\mathbb{E}[(x_* + \\delta)^\\top S_N (x_* + \\delta)] = x_*^\\top S_N x_* + \\eta^2 \\operatorname{tr}(S_N)$$\n    where $\\operatorname{tr}(S_N)$ is the trace of the posterior covariance matrix.\n\n#### 1.4. Boolean Computations\n\nThe problem requires computing two boolean values for each test case.\n-   $b_1 = \\big( (E_{\\text{adv}} - E_{\\text{base}}) \\ge (\\eta^2 \\operatorname{tr}(S_N)) \\big)$: This compares the increase in epistemic variance due to the adversarial perturbation, $E_{\\text{adv}} - E_{\\text{base}}$, against the expected increase from natural perturbations, $E_{\\text{nat}} - E_{\\text{base}} = \\eta^2 \\operatorname{tr}(S_N)$.\n-   $b_2 = \\big( |A_{\\text{base}} - \\sigma^2| < 10^{-12} \\big)$: This checks if the aleatoric component remains unchanged. By definition, the aleatoric variance is $\\sigma^2$ and is independent of the input $x_*$. Thus, $A_{\\text{base}} = \\sigma^2$, and perturbing the input does not change this component. The condition simplifies to $| \\sigma^2 - \\sigma^2 | < 10^{-12}$, which is $0 < 10^{-12}$. This is always true, so $b_2$ will be true for all valid test cases.\n\n### 2. Implementation Strategy\n\nFor each test case, the program will execute the following steps:\n1.  Define the matrices and scalars $X, y, x_*, \\alpha, \\sigma^2, \\epsilon, \\eta^2$.\n2.  Compute the posterior covariance matrix $S_N = \\left(\\frac{1}{\\sigma^2} X^\\top X + \\alpha I_d\\right)^{-1}$.\n3.  Calculate the baseline epistemic variance $E_{\\text{base}} = x_*^\\top S_N x_*$ and aleatoric variance $A_{\\text{base}} = \\sigma^2$.\n4.  Calculate the adversarial perturbation $\\delta_{adv} = \\epsilon \\frac{S_N x_*}{\\|S_N x_*\\|_2}$ (handling the zero-norm case) and the resulting adversarial epistemic variance $E_{\\text{adv}} = (x_* + \\delta_{adv})^\\top S_N (x_* + \\delta_{adv})$.\n5.  Determine the increase in variance from natural perturbations as $\\eta^2 \\operatorname{tr}(S_N)$.\n6.  Evaluate the boolean conditions $b_1$ and $b_2$ and store the results.\n7.  Format the final collection of booleans into the required output string.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian Linear Regression uncertainty quantification problem for given test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {\n            \"X\": np.array([[1, -1], [1, 0], [1, 1], [1, 2]], dtype=float),\n            \"y\": np.array([[0.0], [1.0], [2.0], [3.0]], dtype=float),\n            \"x_star\": np.array([1.0, 0.5], dtype=float),\n            \"alpha\": 1.0,\n            \"sigma2\": 0.04,\n            \"epsilon\": 0.2,\n            \"eta2\": 0.01,\n        },\n        # Test case 2\n        {\n            \"X\": np.array([[1, -1], [1, 0], [1, 1], [1, 2]], dtype=float),\n            \"y\": np.array([[0.0], [1.0], [2.0], [3.0]], dtype=float),\n            \"x_star\": np.array([1.0, -1.0], dtype=float),\n            \"alpha\": 1.0,\n            \"sigma2\": 0.04,\n            \"epsilon\": 0.0,\n            \"eta2\": 0.0025,\n        },\n        # Test case 3\n        {\n            \"X\": np.array([[1, -2], [1, 2]], dtype=float),\n            \"y\": np.array([[-1.0], [1.2]], dtype=float),\n            \"x_star\": np.array([1.0, 3.0], dtype=float),\n            \"alpha\": 0.1,\n            \"sigma2\": 0.25,\n            \"epsilon\": 0.5,\n            \"eta2\": 0.0,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        X = case[\"X\"]\n        x_star = case[\"x_star\"]\n        alpha = case[\"alpha\"]\n        sigma2 = case[\"sigma2\"]\n        epsilon = case[\"epsilon\"]\n        eta2 = case[\"eta2\"]\n\n        d = X.shape[1]\n        I_d = np.identity(d)\n\n        # 1. Compute the BLR posterior covariance SN\n        precision_matrix = (1 / sigma2) * (X.T @ X) + alpha * I_d\n        SN = np.linalg.inv(precision_matrix)\n\n        # 2. Compute baseline predictive variance components\n        E_base = x_star.T @ SN @ x_star\n        A_base = sigma2\n\n        # 3. Compute maximal adversarial epistemic variance\n        grad_term = SN @ x_star\n        norm_grad_term = np.linalg.norm(grad_term)\n        \n        # Handle cases where gradient is zero or epsilon is zero\n        if norm_grad_term  1e-15 or epsilon == 0.0:\n            delta_adv = np.zeros_like(x_star)\n        else:\n            delta_adv = epsilon * grad_term / norm_grad_term\n        \n        x_adv = x_star + delta_adv\n        E_adv = x_adv.T @ SN @ x_adv\n        \n        adv_increase = E_adv - E_base\n\n        # 4. Compute expected increase from natural perturbations\n        tr_SN = np.trace(SN)\n        nat_increase = eta2 * tr_SN\n\n        # 5. Compute boolean b1\n        b1 = adv_increase >= nat_increase\n\n        # 6. Compute boolean b2\n        # The aleatoric variance is sigma2 by definition and is independent of the input x*.\n        # Therefore, it remains unchanged under any perturbation to x*.\n        # The check simplifies to abs(sigma2 - sigma2)  tol, which is always true.\n        b2 = True \n\n        results.extend([b1, b2])\n\n    # Format the output as specified\n    print(f\"[{','.join(map(lambda b: 'True' if b else 'False', results))}]\")\n\nsolve()\n\n```", "id": "3197111"}]}