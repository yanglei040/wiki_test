{"hands_on_practices": [{"introduction": "To truly understand membership inference, we first build an attack from the ground up. This exercise challenges you to apply Bayesian decision theory to a simplified, yet illustrative, model where training data members receive a slight \"confidence boost,\" a common effect of overfitting. By deriving the optimal decision threshold, you will gain a foundational understanding of how even subtle model behaviors can be exploited in a principled, mathematical way. [@problem_id:3149406]", "problem": "Consider binary classification with label $y \\in \\{-1,+1\\}$ and feature vector $x \\in \\mathbb{R}^2$. The data are generated by a Gaussian discriminant model with shared covariance: $x \\mid y \\sim \\mathcal{N}(\\mu_y,\\Sigma)$ and class prior $\\mathbb{P}(y=+1)=\\mathbb{P}(y=-1)=\\tfrac{1}{2}$. The released classifier computes the Bayes posterior $p_{\\theta}(y \\mid x)$ under the true parameters $(\\mu_{+},\\mu_{-},\\Sigma)$, which for shared covariance corresponds to a logistic function with logit $s(x) = w^{\\top}x + b$, where $w = \\Sigma^{-1}(\\mu_{+}-\\mu_{-})$ and $b = -\\tfrac{1}{2}\\left(\\mu_{+}^{\\top}\\Sigma^{-1}\\mu_{+} - \\mu_{-}^{\\top}\\Sigma^{-1}\\mu_{-}\\right)$.\n\nAssume a simple overfitting effect on members of the training set: for a data point with true label $y$, the model’s reported posterior for the true class is $q(y \\mid x) = \\sigma\\!\\left(s(x) + b_M\\right)$, where $\\sigma(z) = \\tfrac{1}{1+\\exp(-z)}$ is the logistic function and $b_M = \\beta$ if the point is a member of the training set and $b_M=0$ if it is a non-member. The attacker knows $(\\mu_{+},\\mu_{-},\\Sigma)$, the bias parameter $\\beta > 0$, and the true label $y$ for the queried point, and observes the scalar $q(y \\mid x)$. The attacker’s goal is to decide membership $M \\in \\{\\text{member},\\text{non-member}\\}$ under equal priors $\\mathbb{P}(M=\\text{member})=\\mathbb{P}(M=\\text{non-member})=\\tfrac{1}{2}$.\n\nStarting from first principles of Bayes decision theory and the Gaussian discriminant model, derive the optimal (Bayes) membership inference decision for a fixed label $y$ in the form of a single threshold on the observed logit $r = \\ln\\!\\left(\\tfrac{q(y \\mid x)}{1-q(y \\mid x)}\\right)$. Then convert this threshold to the posterior probability domain, $t_p^{\\ast} = \\sigma(t^{\\ast})$.\n\nFinally, evaluate your expression for the specific parameters\n- $\\mu_{+} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$, $\\mu_{-} = \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix}$,\n- $\\Sigma = I_2$ (the $2 \\times 2$ identity),\n- $\\beta = 0.8$,\n- and the known true label $y=+1$,\nand report the numerical value of $t_p^{\\ast}$. Round your answer to four significant figures.\n\nFor empirical validation, consider the following six observations, all with true label $y=+1$, and their membership status $M$:\n- $x^{(1)} = \\begin{pmatrix}1.1 \\\\ -0.2\\end{pmatrix}$ with $M=\\text{member}$,\n- $x^{(2)} = \\begin{pmatrix}0.8 \\\\ 0.3\\end{pmatrix}$ with $M=\\text{member}$,\n- $x^{(3)} = \\begin{pmatrix}1.2 \\\\ -0.1\\end{pmatrix}$ with $M=\\text{member}$,\n- $x^{(4)} = \\begin{pmatrix}0.6 \\\\ -0.4\\end{pmatrix}$ with $M=\\text{non-member}$,\n- $x^{(5)} = \\begin{pmatrix}1.1 \\\\ 0.2\\end{pmatrix}$ with $M=\\text{non-member}$,\n- $x^{(6)} = \\begin{pmatrix}0.7 \\\\ 0.0\\end{pmatrix}$ with $M=\\text{non-member}$.\n\nUsing the derived optimal threshold rule and the known parameters, compute the empirical attack decisions and the resulting empirical accuracy as a check of consistency. Your final reported answer must be the single number $t_p^{\\ast}$ only, rounded to four significant figures, and without units.", "solution": "The user wants me to solve a membership inference problem by deriving an optimal Bayesian decision rule.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   Binary classification label: $y \\in \\{-1,+1\\}$\n-   Feature vector: $x \\in \\mathbb{R}^2$\n-   Data generation model: $x \\mid y \\sim \\mathcal{N}(\\mu_y,\\Sigma)$\n-   Class priors: $\\mathbb{P}(y=+1)=\\mathbb{P}(y=-1)=\\tfrac{1}{2}$\n-   Classifier's logit: $s(x) = w^{\\top}x + b$\n-   Logit parameters: $w = \\Sigma^{-1}(\\mu_{+}-\\mu_{-})$ and $b = -\\tfrac{1}{2}\\left(\\mu_{+}^{\\top}\\Sigma^{-1}\\mu_{+} - \\mu_{-}^{\\top}\\Sigma^{-1}\\mu_{-}\\right)$\n-   Reported posterior for true class $y$: $q(y \\mid x) = \\sigma\\!\\left(s(x) + b_M\\right)$, with $\\sigma(z) = \\tfrac{1}{1+\\exp(-z)}$\n-   Membership bias: $b_M = \\beta$ for a member, $b_M=0$ for a non-member, with $\\beta > 0$\n-   Attacker knowledge: $(\\mu_{+},\\mu_{-},\\Sigma)$, $\\beta$, and the true label $y$\n-   Attacker observation: $q(y \\mid x)$ or equivalently the observed logit $r = \\ln\\!\\left(\\tfrac{q(y \\mid x)}{1-q(y \\mid x)}\\right)$\n-   Attacker goal: Decide membership $M \\in \\{\\text{member},\\text{non-member}\\}$\n-   Membership priors: $\\mathbb{P}(M=\\text{member})=\\mathbb{P}(M=\\text{non-member})=\\tfrac{1}{2}$\n-   Specific parameters for evaluation: $\\mu_{+} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$, $\\mu_{-} = \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix}$, $\\Sigma = I_2$, $\\beta = 0.8$, $y=+1$.\n-   Empirical validation data (all with $y=+1$):\n    -   $x^{(1)} = \\begin{pmatrix}1.1 \\\\ -0.2\\end{pmatrix}$, $M=\\text{member}$\n    -   $x^{(2)} = \\begin{pmatrix}0.8 \\\\ 0.3\\end{pmatrix}$, $M=\\text{member}$\n    -   $x^{(3)} = \\begin{pmatrix}1.2 \\\\ -0.1\\end{pmatrix}$, $M=\\text{member}$\n    -   $x^{(4)} = \\begin{pmatrix}0.6 \\\\ -0.4\\end{pmatrix}$, $M=\\text{non-member}$\n    -   $x^{(5)} = \\begin{pmatrix}1.1 \\\\ 0.2\\end{pmatrix}$, $M=\\text{non-member}$\n    -   $x^{(6)} = \\begin{pmatrix}0.7 \\\\ 0.0\\end{pmatrix}$, $M=\\text{non-member}$\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is well-defined within the fields of statistical decision theory and machine learning security.\n-   **Scientifically Grounded:** The setup uses standard models: Gaussian Discriminant Analysis for classification and a simplified bias model for overfitting, which is a common and sound approach in theoretical studies of membership inference.\n-   **Well-Posed:** All necessary information (distributions, parameters, priors, and the attacker's objective) is provided to derive a unique Bayes-optimal decision rule.\n-   **Objective:** The problem is stated using formal mathematical language, free from ambiguity or subjectivity.\n-   **Completeness:** The problem is self-contained and free of contradictions.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\n\nThe attacker's task is to decide between two hypotheses: $H_1: M=\\text{member}$ and $H_0: M=\\text{non-member}$. The attacker observes the logit $r = \\ln\\!\\left(\\tfrac{q(y \\mid x)}{1-q(y \\mid x)}\\right)$ for a data point $(x,y)$ where the true label $y$ is known. From the problem definition, $q(y \\mid x) = \\sigma(s(x) + b_M)$, which implies the observed logit is $r = s(x) + b_M$.\nUnder the two hypotheses:\n-   $H_1: M=\\text{member} \\implies b_M = \\beta \\implies r = s(x) + \\beta$\n-   $H_0: M=\\text{non-member} \\implies b_M = 0 \\implies r = s(x)$\n\nAccording to Bayes decision theory, the optimal decision rule is to choose the hypothesis with the higher posterior probability. Given the equal priors $\\mathbb{P}(H_1) = \\mathbb{P}(H_0) = \\frac{1}{2}$, this is equivalent to choosing the hypothesis with the higher likelihood. The rule is to decide 'member' (_i.e._, choose $H_1$) if:\n$$ p(r \\mid H_1) > p(r \\mid H_0) $$\nTo find the likelihoods $p(r \\mid H_i)$, we must determine the distribution of the random variable $r$. This depends on the distribution of the true logit $s(x)$. The randomness in $s(x)$ arises from the data point $x$ being drawn from its class-conditional distribution $x \\mid y \\sim \\mathcal{N}(\\mu_y, \\Sigma)$.\n\nThe logit $s(x) = w^\\top x + b$ is an affine transformation of a Gaussian random vector $x$, and is therefore a Gaussian random variable. We need to find its mean and variance, conditioned on the known label $y$.\n\nThe mean of $s(x)$ given $y$ is $\\mathbb{E}[s(x) \\mid y] = w^\\top \\mathbb{E}[x \\mid y] + b = w^\\top \\mu_y + b$.\nLet's define the squared Mahalanobis distance between the class means as $\\Delta^2 = (\\mu_{+} - \\mu_{-})^\\top \\Sigma^{-1} (\\mu_{+} - \\mu_{-})$.\nThe mean for $y=+1$ is:\n$$ \\mathbb{E}[s(x) \\mid y=+1] = w^\\top \\mu_{+} + b = (\\mu_{+}-\\mu_{-})^\\top \\Sigma^{-1} \\mu_{+} - \\frac{1}{2}(\\mu_{+}^\\top\\Sigma^{-1}\\mu_{+} - \\mu_{-}^\\top\\Sigma^{-1}\\mu_{-}) $$\n$$ = \\frac{1}{2}(\\mu_{+}^\\top\\Sigma^{-1}\\mu_{+} - 2\\mu_{+}^\\top\\Sigma^{-1}\\mu_{-} + \\mu_{-}^\\top\\Sigma^{-1}\\mu_{-}) = \\frac{1}{2}(\\mu_{+}-\\mu_{-})^\\top\\Sigma^{-1}(\\mu_{+}-\\mu_{-}) = \\frac{1}{2}\\Delta^2 $$\nSimilarly, for $y=-1$:\n$$ \\mathbb{E}[s(x) \\mid y=-1] = w^\\top \\mu_{-} + b = -\\frac{1}{2}\\Delta^2 $$\nWe can write this compactly as $\\eta_y = \\mathbb{E}[s(x) \\mid y] = y \\frac{\\Delta^2}{2}$.\n\nThe variance of $s(x)$ given $y$ is independent of the mean of $x$:\n$$ \\text{Var}[s(x) \\mid y] = \\text{Var}[w^\\top x \\mid y] = w^\\top \\text{Cov}(x \\mid y) w = w^\\top \\Sigma w $$\n$$ = ((\\mu_{+}-\\mu_{-})^\\top \\Sigma^{-1}) \\Sigma (\\Sigma^{-1}(\\mu_{+}-\\mu_{-})) = (\\mu_{+}-\\mu_{-})^\\top \\Sigma^{-1} (\\mu_{+}-\\mu_{-}) = \\Delta^2 $$\nSo, for a known label $y$, the distribution of the true logit is $s(x) \\mid y \\sim \\mathcal{N}(y \\frac{\\Delta^2}{2}, \\Delta^2)$.\n\nNow we can write the distributions for the observed logit $r$ under both hypotheses:\n-   $H_0$: $r = s(x) \\sim \\mathcal{N}\\left(y \\frac{\\Delta^2}{2}, \\Delta^2\\right)$\n-   $H_1$: $r = s(x) + \\beta \\sim \\mathcal{N}\\left(y \\frac{\\Delta^2}{2} + \\beta, \\Delta^2\\right)$\n\nThe likelihoods are Gaussian probability density functions:\n$$ p(r \\mid H_0) = \\frac{1}{\\sqrt{2\\pi\\Delta^2}} \\exp\\left(-\\frac{(r - y\\frac{\\Delta^2}{2})^2}{2\\Delta^2}\\right) $$\n$$ p(r \\mid H_1) = \\frac{1}{\\sqrt{2\\pi\\Delta^2}} \\exp\\left(-\\frac{(r - (y\\frac{\\Delta^2}{2} + \\beta))^2}{2\\Delta^2}\\right) $$\nThe decision rule $p(r \\mid H_1) > p(r \\mid H_0)$ becomes:\n$$ \\exp\\left(-\\frac{(r - y\\frac{\\Delta^2}{2} - \\beta)^2}{2\\Delta^2}\\right) > \\exp\\left(-\\frac{(r - y\\frac{\\Delta^2}{2})^2}{2\\Delta^2}\\right) $$\nTaking the natural logarithm of both sides:\n$$ -\\frac{(r - y\\frac{\\Delta^2}{2} - \\beta)^2}{2\\Delta^2} > -\\frac{(r - y\\frac{\\Delta^2}{2})^2}{2\\Delta^2} $$\nMultiplying by $-2\\Delta^2$ (and flipping the inequality):\n$$ (r - y\\frac{\\Delta^2}{2} - \\beta)^2  (r - y\\frac{\\Delta^2}{2})^2 $$\nThis inequality holds if and only if $r$ is closer to the mean under $H_1$, which is $y\\frac{\\Delta^2}{2} + \\beta$, than to the mean under $H_0$, which is $y\\frac{\\Delta^2}{2}$. The decision threshold is the midpoint between the two means:\n$$ t^* = \\frac{(y\\frac{\\Delta^2}{2}) + (y\\frac{\\Delta^2}{2} + \\beta)}{2} = y\\frac{\\Delta^2}{2} + \\frac{\\beta}{2} $$\nThe attacker decides 'member' if the observed logit $r$ satisfies $r > t^*$.\n\nThe problem asks for the threshold to be converted to the probability domain:\n$$ t_p^* = \\sigma(t^*) = \\sigma\\left(y\\frac{\\Delta^2}{2} + \\frac{\\beta}{2}\\right) $$\n\n### Numerical Evaluation\nWe are given the parameters:\n-   $\\mu_{+} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$, $\\mu_{-} = \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix}$\n-   $\\Sigma = I_2 = \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix}$, so $\\Sigma^{-1} = I_2$\n-   $\\beta = 0.8$\n-   True label $y=+1$\n\nFirst, we calculate $\\Delta^2$:\n$$ \\mu_{+} - \\mu_{-} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix} - \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix} = \\begin{pmatrix}2 \\\\ 0\\end{pmatrix} $$\n$$ \\Delta^2 = (\\mu_{+} - \\mu_{-})^\\top \\Sigma^{-1} (\\mu_{+} - \\mu_{-}) = \\begin{pmatrix}2  0\\end{pmatrix} \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix} \\begin{pmatrix}2 \\\\ 0\\end{pmatrix} = 4 $$\nNext, we compute the logit threshold $t^*$ for $y=+1$:\n$$ t^* = (+1) \\cdot \\frac{4}{2} + \\frac{0.8}{2} = 2 + 0.4 = 2.4 $$\nThe optimal decision rule for the attacker is to infer 'member' if the observed logit $r$ is greater than $2.4$.\n\nFinally, we convert this threshold to the probability domain:\n$$ t_p^* = \\sigma(2.4) = \\frac{1}{1 + \\exp(-2.4)} $$\n$$ t_p^* \\approx \\frac{1}{1 + 0.09071795} \\approx \\frac{1}{1.09071795} \\approx 0.916830005 $$\nRounding to four significant figures, we get $t_p^* \\approx 0.9168$.\n\n### Empirical Validation\nAs a consistency check, we apply the derived rule to the provided data. The true logit is $s(x) = w^\\top x + b$. With the given parameters, $w = \\Sigma^{-1}(\\mu_+ - \\mu_-) = \\begin{pmatrix}2 \\\\ 0\\end{pmatrix}$ and $b = 0$. So, $s(x) = 2x_1$. The observed logit is $r = s(x) + b_M = 2x_1 + b_M$.\nFor the given points (all with $y=+1$), the decision rule is: predict 'member' if $r > 2.4$.\n\n1.  $x^{(1)} = (1.1, -0.2)$, $M=\\text{member} \\implies b_M=0.8$. $r_1=2(1.1)+0.8=3.0$. $3.0 > 2.4 \\implies$ predict 'member'. (Correct)\n2.  $x^{(2)} = (0.8, 0.3)$, $M=\\text{member} \\implies b_M=0.8$. $r_2=2(0.8)+0.8=2.4$. $2.4 \\ngtr 2.4 \\implies$ predict 'non-member'. (Incorrect)\n3.  $x^{(3)} = (1.2, -0.1)$, $M=\\text{member} \\implies b_M=0.8$. $r_3=2(1.2)+0.8=3.2$. $3.2 > 2.4 \\implies$ predict 'member'. (Correct)\n4.  $x^{(4)} = (0.6, -0.4)$, $M=\\text{non-member} \\implies b_M=0$. $r_4=2(0.6)+0=1.2$. $1.2 \\ngtr 2.4 \\implies$ predict 'non-member'. (Correct)\n5.  $x^{(5)} = (1.1, 0.2)$, $M=\\text{non-member} \\implies b_M=0$. $r_5=2(1.1)+0=2.2$. $2.2 \\ngtr 2.4 \\implies$ predict 'non-member'. (Correct)\n6.  $x^{(6)} = (0.7, 0.0)$, $M=\\text{non-member} \\implies b_M=0$. $r_6=2(0.7)+0=1.4$. $1.4 \\ngtr 2.4 \\implies$ predict 'non-member'. (Correct)\n\nThe attack makes $5$ correct predictions out of $6$, for an empirical accuracy of $\\frac{5}{6}$. The single error occurs at the decision boundary, which is expected and does not invalidate the derived optimal threshold.", "answer": "$$\\boxed{0.9168}$$", "id": "3149406"}, {"introduction": "Real-world training pipelines involve more than just fitting data; they use techniques like data augmentation. This practice explores a more sophisticated attack vector where we assume such augmentations leave a subtle, systematic \"signature\" in a model's outputs for training members. Your task is to derive and implement a statistic that isolates this signature, demonstrating how forensic analysis of model predictions can lead to powerful membership inference attacks. [@problem_id:3149401]", "problem": "You are given a simulated classification model with parameters $\\theta$ that outputs a categorical distribution $p_{\\theta}(y \\mid x)$ via a softmax of logits. The model was trained using label-preserving data augmentations, and these augmentations introduce a systematic, augmentation-specific artifact in the logits for training set members. Your task is to derive and implement a principled membership inference rule that detects the footprint of a known augmentation artifact in $p_{\\theta}(y \\mid x)$ and decides whether a single observed prediction originates from a training member or a non-member.\n\nFundamental base:\n- A classification prediction for an input $x$ is generated from logits $z(x) \\in \\mathbb{R}^{C}$ according to the softmax, $p_{\\theta}(y=i \\mid x) = \\exp(z_i) / \\sum_{j=1}^{C} \\exp(z_j)$, for classes $i \\in \\{1, \\dots, C\\}$.\n- The training augmentation introduces a known, zero-sum signature vector $s \\in \\mathbb{R}^{C}$ (i.e., $\\sum_{i=1}^{C} s_i = 0$) into the logits of training members. Specifically, for a training member, the logits are modeled as $z = \\epsilon + \\alpha s$ and for a non-member $z = \\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_C)$ is additive Gaussian noise, $\\alpha \\in \\mathbb{R}$ is the augmentation strength, and $\\sigma > 0$ is the noise standard deviation. The attacker knows the augmentation signature $s$, the augmentation strength $\\alpha$, and the noise level $\\sigma$.\n- The attacker observes only the probability vector $p \\in \\Delta^{C-1}$ produced by the model, not the logits $z$ directly. The attacker is also given a prior membership probability $\\pi = \\Pr(M=1)$, where $M \\in \\{0,1\\}$ indicates whether the input was a training member. The attacker seeks a decision rule to infer $M$ from $p$, under the model above.\n\nPrincipled derivation requirement:\n- Use the fact that $p_{\\theta}(y \\mid x)$ arises from a softmax of logits and that the augmentation artifact $s$ is zero-sum to construct a scalar statistic on $p$ that isolates the additive artifact in the logits. Starting from the zero-sum constraint and the identity $\\log p_i = z_i - \\log \\sum_{j=1}^{C} \\exp(z_j)$, derive a statistic that depends on $z$ only through an inner product with $s$, and hence has a tractable Gaussian distribution under member versus non-member hypotheses.\n- Starting from the Gaussian model assumptions and the definition of likelihoods, apply the Neyman–Pearson lemma to obtain the optimal likelihood ratio test for deciding membership $M$ from the derived statistic and the prior $\\pi$. Provide a closed-form decision rule expressed only in terms of the observed $p$, the known parameters $(\\alpha, \\sigma, s)$, and $\\pi$.\n\nProgram requirements:\n- Implement the derived decision rule in a complete, runnable program. For each test case, you must first simulate the observed probability vector $p$ using the provided parameters and a deterministic $\\epsilon$ vector exactly as specified. Then, apply your membership inference rule to the simulated $p$ and output a boolean decision for each test case, where $True$ denotes \"member\" and $False$ denotes \"non-member\".\n- Your program must aggregate the results for all test cases into a single line of output containing the decisions as a comma-separated list enclosed in square brackets (e.g., \"[True,False,True]\").\n\nTest suite:\nFor each test case below, you are given the following parameters:\n- Number of classes $C$ (integer).\n- Noise standard deviation $\\sigma$ (float).\n- Augmentation strength $\\alpha$ (float).\n- Augmentation signature $s \\in \\mathbb{R}^{C}$ with zero sum.\n- Prior membership probability $\\pi$ (decimal in $[0,1]$).\n- Deterministic noise vector $\\epsilon \\in \\mathbb{R}^{C}$.\n- Ground-truth membership $M \\in \\{0,1\\}$ used only to simulate $p$.\n\nYou must simulate logits $z = \\epsilon + \\alpha s$ if $M=1$, and $z = \\epsilon$ if $M=0$. Then compute $p$ via the softmax of $z$, and apply your derived decision rule to output the membership decision.\n\nProvide your program’s results for the following four test cases:\n\n- Test case 1 (happy path):\n    - $C = 5$\n    - $\\sigma = 0.5$\n    - $\\alpha = 0.8$\n    - $s = [1.0, -1.0, 0.5, -0.3, -0.2]$\n    - $\\pi = 0.5$\n    - $\\epsilon = [0.2, -0.1, 0.05, -0.02, -0.13]$\n    - $M = 1$\n\n- Test case 2 (boundary condition with no artifact):\n    - $C = 4$\n    - $\\sigma = 0.6$\n    - $\\alpha = 0.0$\n    - $s = [0.6, -0.1, -0.2, -0.3]$\n    - $\\pi = 0.4$\n    - $\\epsilon = [0.1, -0.05, 0.02, -0.07]$\n    - $M = 1$\n\n- Test case 3 (high-noise regime):\n    - $C = 3$\n    - $\\sigma = 2.0$\n    - $\\alpha = 0.3$\n    - $s = [1.0, -0.5, -0.5]$\n    - $\\pi = 0.5$\n    - $\\epsilon = [-0.2, 0.1, 0.05]$\n    - $M = 1$\n\n- Test case 4 (prior shift favoring membership):\n    - $C = 6$\n    - $\\sigma = 0.4$\n    - $\\alpha = 0.5$\n    - $s = [0.9, -0.4, -0.3, 0.1, -0.1, -0.2]$\n    - $\\pi = 0.8$\n    - $\\epsilon = [-0.05, 0.02, -0.01, 0.03, -0.02, 0.03]$\n    - $M = 0$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[True,False,True,False]\"). No other text should be printed.", "solution": "We begin from the core definitions in probabilistic deep learning. A classifier produces logits $z(x) \\in \\mathbb{R}^{C}$ and a probability vector $p_{\\theta}(y \\mid x)$ via the softmax:\n$$\np_i = \\frac{\\exp(z_i)}{\\sum_{j=1}^{C} \\exp(z_j)}, \\quad i \\in \\{1,\\dots,C\\}.\n$$\nTaking logarithms,\n$$\n\\log p_i = z_i - \\log\\left(\\sum_{j=1}^{C} \\exp(z_j)\\right).\n$$\n\nAugmentation artifact model:\nWe assume an augmentation signature $s \\in \\mathbb{R}^{C}$ satisfying the zero-sum constraint $\\sum_{i=1}^{C} s_i = 0$. For a training member ($M=1$), the logits are $z = \\epsilon + \\alpha s$; for a non-member ($M=0$), logits are $z = \\epsilon$. The noise vector $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_C)$ models class-independent variation, where $\\sigma > 0$ and $I_C$ is the $C \\times C$ identity matrix. The signature strength is $\\alpha \\in \\mathbb{R}$. The attacker knows $(\\alpha, \\sigma, s)$.\n\nStatistic isolating the augmentation footprint:\nUsing the zero-sum constraint on $s$, consider the statistic\n$$\nT(p) = \\sum_{i=1}^{C} s_i \\log p_i.\n$$\nSubstituting $\\log p_i$,\n$$\nT(p) = \\sum_{i=1}^{C} s_i \\left( z_i - \\log\\left(\\sum_{j=1}^{C} \\exp(z_j)\\right) \\right) = \\underbrace{\\sum_{i=1}^{C} s_i z_i}_{s^\\top z} - \\left(\\sum_{i=1}^{C} s_i\\right) \\log\\left(\\sum_{j=1}^{C} \\exp(z_j)\\right).\n$$\nSince $\\sum_{i=1}^{C} s_i = 0$, the second term vanishes, yielding\n$$\nT(p) = s^\\top z.\n$$\nThus, although the attacker sees only $p$, the statistic $T(p)$ equals the inner product of $s$ with the logits $z$. This is invariant to additive shifts of logits and exactly isolates the augmentation footprint.\n\nDistribution of the statistic under member and non-member:\nUnder $M=0$, $z = \\epsilon$ with $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_C)$, so $T \\mid M=0 = s^\\top \\epsilon \\sim \\mathcal{N}\\left(0, \\sigma^2 \\|s\\|_2^2\\right)$ because $s^\\top \\epsilon$ is a linear form of a multivariate normal, with variance $\\sigma^2 s^\\top s = \\sigma^2 \\|s\\|_2^2$.\n\nUnder $M=1$, $z = \\epsilon + \\alpha s$, so\n$$\nT \\mid M=1 = s^\\top (\\epsilon + \\alpha s) = s^\\top \\epsilon + \\alpha \\, s^\\top s \\sim \\mathcal{N}\\left(\\alpha \\|s\\|_2^2, \\sigma^2 \\|s\\|_2^2\\right).\n$$\nTherefore, $T$ has Gaussian distributions with shared variance under both hypotheses:\n- Mean under $M=0$: $\\mu_0 = 0$.\n- Mean under $M=1$: $\\mu_1 = \\alpha \\|s\\|_2^2$.\n- Variance under both: $v = \\sigma^2 \\|s\\|_2^2$.\n\nOptimal decision via the Neyman–Pearson lemma:\nFor two simple hypotheses with known densities $f_0$ and $f_1$, the Neyman–Pearson lemma states that the most powerful test at any size is a threshold on the likelihood ratio $\\Lambda(T) = f_1(T)/f_0(T)$. Incorporating prior probability $\\pi = \\Pr(M=1)$ and equal misclassification costs, the Bayes-optimal decision rule is:\n$$\n\\text{Decide } M=1 \\text{ if } \\log \\Lambda(T) > \\log\\left(\\frac{1-\\pi}{\\pi}\\right), \\quad \\text{otherwise decide } M=0.\n$$\nWith $T \\mid M=m \\sim \\mathcal{N}(\\mu_m, v)$, the log-likelihood ratio simplifies to a linear function of $T$:\n\\begin{align*}\n\\log \\Lambda(T) = \\log \\frac{\\phi(T; \\mu_1, v)}{\\phi(T; \\mu_0, v)} \\\\\n= -\\frac{(T-\\mu_1)^2}{2v} + \\frac{(T-\\mu_0)^2}{2v} \\\\\n= \\frac{\\mu_1 - \\mu_0}{v} \\left( T - \\frac{\\mu_1 + \\mu_0}{2} \\right),\n\\end{align*}\nwhere $\\phi(\\cdot; \\mu, v)$ denotes the Gaussian density. Substituting $\\mu_0 = 0$, $\\mu_1 = \\alpha \\|s\\|_2^2$, and $v = \\sigma^2 \\|s\\|_2^2$ yields\n$$\n\\log \\Lambda(T) = \\frac{\\alpha}{\\sigma^2} \\left( T - \\frac{\\alpha \\|s\\|_2^2}{2} \\right).\n$$\nEquivalently, without explicit linearization, one can compute $\\log \\Lambda(T)$ directly via the quadratic form $-\\frac{(T-\\mu_1)^2}{2v} + \\frac{(T-\\mu_0)^2}{2v}$, which is numerically stable even when $\\alpha=0$.\n\nDecision rule:\nGiven $p$, compute $\\log p$ via a numerically stable log-softmax, then $T = \\sum_{i} s_i \\log p_i$. Compute $\\mu_0, \\mu_1, v$ as above and form\n$$\n\\log \\Lambda(T) = -\\frac{(T-\\mu_1)^2}{2v} + \\frac{(T-\\mu_0)^2}{2v}.\n$$\nDefine the threshold\n$$\n\\eta = \\log\\left(\\frac{1-\\pi}{\\pi}\\right).\n$$\nDecide $M=1$ if $\\log \\Lambda(T) > \\eta$, else $M=0$. Note:\n- When $\\alpha = 0$, $\\mu_1 = \\mu_0$, so $\\log \\Lambda(T) = 0$ for all $T$. Then the Bayes decision reduces to choosing $M=1$ if $\\eta  0$ (i.e., $\\pi > 1/2$), otherwise $M=0$, reflecting that the observation carries no information about membership in the absence of an augmentation footprint.\n- Larger $\\alpha$ and smaller $\\sigma$ increase separability by increasing the signal-to-noise ratio in $T$.\n\nAlgorithm implementation details:\n- Simulate logits $z$ for each test case from the provided deterministic $\\epsilon$ and $M$ as $z = \\epsilon + \\alpha s$ if $M=1$, else $z = \\epsilon$.\n- Compute $p$ via the softmax of $z$ using a numerically stable approach: subtract $\\max_i z_i$ before exponentiation.\n- Compute $\\log p$ via log-softmax: $\\log p_i = z_i - \\log \\sum_j \\exp(z_j)$ using the same stability trick.\n- Form $T = s^\\top \\log p$.\n- Compute $\\mu_0 = 0$, $\\mu_1 = \\alpha \\|s\\|_2^2$, $v = \\sigma^2 \\|s\\|_2^2$, and $\\log \\Lambda(T)$ with the quadratic expression.\n- Compare to $\\eta = \\log((1-\\pi)/\\pi)$ and output $True$ if $\\log \\Lambda(T) > \\eta$, else $False$.\n\nApplying this to the provided test suite yields four boolean decisions. The program aggregates them into a single line of output as a comma-separated list enclosed in square brackets.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef softmax(z):\n    # Numerically stable softmax\n    z = np.asarray(z, dtype=np.float64)\n    m = np.max(z)\n    exp_z = np.exp(z - m)\n    return exp_z / np.sum(exp_z)\n\ndef log_softmax(z):\n    # Numerically stable log-softmax\n    z = np.asarray(z, dtype=np.float64)\n    m = np.max(z)\n    log_sum_exp = m + np.log(np.sum(np.exp(z - m)))\n    return z - log_sum_exp\n\ndef membership_decision_from_p(p, s, alpha, sigma, pi):\n    # Compute T = sum_i s_i * log p_i using log(p) directly.\n    log_p = np.log(np.asarray(p, dtype=np.float64))\n    s = np.asarray(s, dtype=np.float64)\n    # Statistic T\n    T = float(np.dot(s, log_p))\n    # Parameters for Gaussian models under H0 (non-member) and H1 (member)\n    norm_sq = float(np.dot(s, s))\n    mu0 = 0.0\n    mu1 = alpha * norm_sq\n    v = (sigma ** 2) * norm_sq\n    # Log-likelihood ratio (numerically stable quadratic form)\n    if v = 1e-12: # Guard against division by zero if s=0 or sigma=0\n        llr = 0.0\n    else:\n        llr = -((T - mu1) ** 2) / (2.0 * v) + ((T - mu0) ** 2) / (2.0 * v)\n    # Threshold from prior\n    # Guard against pi=0 or pi=1\n    if pi == 0:\n        eta = np.inf\n    elif pi == 1:\n        eta = -np.inf\n    else:\n        eta = np.log((1.0 - pi) / pi)\n    # Decision: True means \"member\"\n    return llr > eta\n\ndef simulate_p(C, sigma, alpha, s, epsilon, M):\n    # Simulate logits z and probability vector p\n    s = np.asarray(s, dtype=np.float64)\n    epsilon = np.asarray(epsilon, dtype=np.float64)\n    z = epsilon + (alpha * s if M == 1 else 0.0)\n    # Compute softmax probabilities\n    p = softmax(z)\n    return p\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Each case: (C, sigma, alpha, s, pi, epsilon, M)\n        (5, 0.5, 0.8, [1.0, -1.0, 0.5, -0.3, -0.2], 0.5, [0.2, -0.1, 0.05, -0.02, -0.13], 1),\n        (4, 0.6, 0.0, [0.6, -0.1, -0.2, -0.3], 0.4, [0.1, -0.05, 0.02, -0.07], 1),\n        (3, 2.0, 0.3, [1.0, -0.5, -0.5], 0.5, [-0.2, 0.1, 0.05], 1),\n        (6, 0.4, 0.5, [0.9, -0.4, -0.3, 0.1, -0.1, -0.2], 0.8, [-0.05, 0.02, -0.01, 0.03, -0.02, 0.03], 0),\n    ]\n\n    results = []\n    for case in test_cases:\n        C, sigma, alpha, s, pi, epsilon, M = case\n        # Simulate observed probability vector p\n        p = simulate_p(C, sigma, alpha, s, epsilon, M)\n        # Apply membership inference rule to p\n        decision = membership_decision_from_p(p, s, alpha, sigma, pi)\n        results.append(decision)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(lambda x: 'True' if x else 'False', results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3149401"}, {"introduction": "While single signals can reveal membership, combining multiple indicators often yields a more robust attack. In this final practice, you will construct a composite risk score from several well-known vulnerability signals: prediction margin, confidence entropy, and gradient norms. You will then learn to validate the effectiveness of this score using the Receiver Operating Characteristic Area Under the Curve (ROC AUC), a standard metric for evaluating attack performance in the machine learning security community. [@problem_id:3149361]", "problem": "You are given a multi-class classifier with parameters implicitly defining a conditional class probability distribution for each input instance. For an input vector $x$ with raw logits $z(x) \\in \\mathbb{R}^C$, the predictive distribution is given by the softmax function, which maps logits to probabilities via $p_\\theta(k \\mid x) = \\exp(z_k(x)) / \\sum_{j=1}^C \\exp(z_j(x))$. Consider three per-instance signals derived from $p_\\theta(\\cdot \\mid x)$ and from a per-instance gradient norm provided as input: the top-two margin, the confidence entropy, and the normalized gradient norm. Your task is to define a composite privacy risk score $r(x)$ that combines these signals and to validate its effectiveness as a predictor of membership inference vulnerability by computing the Receiver Operating Characteristic Area Under the Curve (ROC AUC) for a threshold-based membership inference attack that uses $r(x)$ as the membership score.\n\nFundamental base for the derivation:\n- The softmax definition $p_\\theta(k \\mid x) = \\exp(z_k(x)) / \\sum_{j=1}^C \\exp(z_j(x))$.\n- Shannon entropy in natural units (nats): $H(p) = -\\sum_{k=1}^C p_k \\log p_k$.\n- Normalized entropy $H_{\\mathrm{norm}}(p) = H(p) / \\log C$, which lies in $[0,1]$.\n- The top-two probability margin $m(x) = p_{(1)}(x) - p_{(2)}(x)$, where $p_{(1)}(x) \\ge p_{(2)}(x)$ are the largest and second-largest entries of $p_\\theta(\\cdot \\mid x)$; thus $m(x) \\in [0,1]$.\n- A per-instance gradient norm $g(x) \\ge 0$ w.r.t. model parameters is given as input. Normalize it within each test case by the min-max transformation $g_{\\mathrm{norm}}(x) = 0$ if $g_{\\max} = g_{\\min}$, else $g_{\\mathrm{norm}}(x) = (g(x) - g_{\\min}) / (g_{\\max} - g_{\\min})$.\n\nDefine the privacy risk score as a nonnegative weighted combination\n$$\nr(x) = \\alpha \\cdot (1 - m(x)) + \\beta \\cdot H_{\\mathrm{norm}}(p_\\theta(\\cdot \\mid x)) + \\gamma \\cdot g_{\\mathrm{norm}}(x),\n$$\nwhere $\\alpha, \\beta, \\gamma \\ge 0$ are fixed weights provided in the test cases. Intuitively, larger $r(x)$ indicates higher membership inference vulnerability because small margin, high entropy, and large gradient norm are each associated with less confident and potentially overfit behavior.\n\nValidation protocol:\n- Given labels $y_{\\mathrm{mem}}(x) \\in \\{0,1\\}$ that indicate non-member ($0$) or member ($1$) status, validate $r(x)$ as a predictor by computing the Receiver Operating Characteristic (ROC) Area Under the Curve (AUC) for using $r(x)$ as a membership score, where higher $r(x)$ implies a higher likelihood of being a member. Use the equivalence between ROC AUC and the Mann–Whitney $U$ statistic: if $n_1$ is the number of members and $n_0$ is the number of non-members, and if $\\mathrm{rank}(r_i)$ are the average ranks (starting at $1$ for the smallest score) of the scores across all instances with appropriate tie averaging, then\n$$\n\\mathrm{AUC} = \\frac{U}{n_0 n_1}, \\quad \\text{where} \\quad U = \\sum_{i:\\, y_{\\mathrm{mem},i} = 1} \\mathrm{rank}(r_i) - \\frac{n_1 (n_1 + 1)}{2}.\n$$\nThis yields $\\mathrm{AUC} \\in [0,1]$, with $\\mathrm{AUC} = 0.5$ indicating chance-level discrimination.\n\nImplementation requirements:\n- For each test case below, compute probabilities via softmax from logits, then compute $m(x)$, $H_{\\mathrm{norm}}(p)$, $g_{\\mathrm{norm}}(x)$, and $r(x)$ using the provided $\\alpha$, $\\beta$, and $\\gamma$.\n- Compute the ROC AUC using the rank-based formula with average ranks for ties, treating higher $r(x)$ as higher membership likelihood.\n- Your program should produce a single line of output containing the AUC results for all test cases as a comma-separated list enclosed in square brackets, with each AUC rounded to six decimal places, for example $[0.945000,0.731234,0.500000]$.\n\nTest suite:\n- Test Case 1 (clear separation, three classes):\n  - Number of classes $C = 3$.\n  - Weights: $\\alpha = 0.5$, $\\beta = 0.3$, $\\gamma = 0.2$.\n  - Six samples with logits, gradient norms, and membership labels:\n    1. Logits $[3.0, 0.2, -1.0]$, gradient norm $0.10$, $y_{\\mathrm{mem}} = 0$.\n    2. Logits $[2.5, -0.5, 0.0]$, gradient norm $0.15$, $y_{\\mathrm{mem}} = 0$.\n    3. Logits $[-1.0, 0.0, 3.0]$, gradient norm $0.05$, $y_{\\mathrm{mem}} = 0$.\n    4. Logits $[0.5, 0.4, 0.3]$, gradient norm $0.90$, $y_{\\mathrm{mem}} = 1$.\n    5. Logits $[0.0, 0.1, 0.2]$, gradient norm $0.70$, $y_{\\mathrm{mem}} = 1$.\n    6. Logits $[0.2, 0.1, 0.2]$, gradient norm $1.20$, $y_{\\mathrm{mem}} = 1$.\n- Test Case 2 (overlap, three classes):\n  - Number of classes $C = 3$.\n  - Weights: $\\alpha = 0.5$, $\\beta = 0.3$, $\\gamma = 0.2$.\n  - Six samples with logits, gradient norms, and membership labels:\n    1. Logits $[1.5, 1.4, 1.3]$, gradient norm $0.60$, $y_{\\mathrm{mem}} = 0$.\n    2. Logits $[2.0, 0.0, 0.0]$, gradient norm $0.40$, $y_{\\mathrm{mem}} = 0$.\n    3. Logits $[0.5, -0.2, 1.0]$, gradient norm $0.55$, $y_{\\mathrm{mem}} = 0$.\n    4. Logits $[0.8, 0.7, 0.1]$, gradient norm $0.50$, $y_{\\mathrm{mem}} = 1$.\n    5. Logits $[1.8, 0.9, 0.7]$, gradient norm $0.45$, $y_{\\mathrm{mem}} = 1$.\n    6. Logits $[0.2, 0.2, 0.2]$, gradient norm $0.65$, $y_{\\mathrm{mem}} = 1$.\n- Test Case 3 (boundary condition with ties):\n  - Number of classes $C = 3$.\n  - Weights: $\\alpha = 0.5$, $\\beta = 0.3$, $\\gamma = 0.2$.\n  - Four samples with identical logits and gradient norms causing tied risk scores:\n    1. Logits $[0.0, 0.0, 0.0]$, gradient norm $0.30$, $y_{\\mathrm{mem}} = 1$.\n    2. Logits $[0.0, 0.0, 0.0]$, gradient norm $0.30$, $y_{\\mathrm{mem}} = 0$.\n    3. Logits $[0.0, 0.0, 0.0]$, gradient norm $0.30$, $y_{\\mathrm{mem}} = 1$.\n    4. Logits $[0.0, 0.0, 0.0]$, gradient norm $0.30$, $y_{\\mathrm{mem}} = 0$.\n\nYour program must implement the definitions stated above and output a single line containing the three ROC AUC values in the exact format $[a_1,a_2,a_3]$, where each $a_i$ is a float rounded to six decimal places.", "solution": "The user-provided problem statement has been critically validated and is deemed to be **valid**. It is scientifically grounded in the domain of machine learning privacy, well-posed, objective, and self-contained. All definitions, constants, and data are provided, enabling a unique and verifiable solution.\n\nThe problem requires the implementation and validation of a privacy risk score, $r(x)$, designed to quantify the vulnerability of a data instance $x$ to membership inference attacks. The solution involves a multi-step process for each test case provided. We will systematically derive the quantities required to compute the Receiver Operating Characteristic Area Under the Curve (ROC AUC), which serves as the validation metric for the risk score.\n\n**Step 1: Computation of Probability Distributions**\n\nFor each data instance, we are given a vector of raw logits, $z(x) \\in \\mathbb{R}^C$, from a $C$-class classifier. The corresponding predictive probability distribution, $p_\\theta(\\cdot \\mid x)$, is obtained via the softmax function:\n$$\np_\\theta(k \\mid x) = \\frac{\\exp(z_k(x))}{\\sum_{j=1}^C \\exp(z_j(x))}.\n$$\nTo ensure numerical stability against potential overflow or underflow with large logit values, we use the identity $p_\\theta(k \\mid x) = \\frac{\\exp(z_k(x) - z_{\\max})}{\\sum_{j=1}^C \\exp(z_j(x) - z_{\\max})}$, where $z_{\\max} = \\max_j z_j(x)$.\n\n**Step 2: Calculation of Per-Instance Signal Components**\n\nThe privacy risk score $r(x)$ is a composite of three signals. For each instance $x$, we compute:\n\n1.  **Top-Two Probability Margin, $m(x)$**: This signal measures the model's confidence in its top prediction. A small margin indicates ambiguity. Let $p_{(1)}(x)$ and $p_{(2)}(x)$ be the largest and second-largest probabilities in the distribution $p_\\theta(\\cdot \\mid x)$. The margin is:\n    $$\n    m(x) = p_{(1)}(x) - p_{(2)}(x).\n    $$\n    The term used in the risk score is $1 - m(x)$, which is larger for less confident predictions.\n\n2.  **Normalized Confidence Entropy, $H_{\\mathrm{norm}}(p)$**: This signal measures the uncertainty of the predictive distribution. Higher entropy implies greater uncertainty. The Shannon entropy is calculated in natural units (nats):\n    $$\n    H(p) = -\\sum_{k=1}^C p_k \\log p_k,\n    $$\n    where $p_k = p_\\theta(k \\mid x)$ and we define $0 \\log 0 = 0$. This entropy is then normalized to the range $[0, 1]$ by dividing by the maximum possible entropy for a $C$-class distribution, which is $\\log C$:\n    $$\n    H_{\\mathrm{norm}}(p) = \\frac{H(p)}{\\log C}.\n    $$\n\n3.  **Normalized Gradient Norm, $g_{\\mathrm{norm}}(x)$**: For each instance, an initial gradient norm $g(x)$ is provided. This value is normalized across all instances within a single test case using min-max scaling. Let $\\{g_i\\}_{i=1}^N$ be the set of gradient norms for a test case with $N$ samples. Let $g_{\\min} = \\min_i g_i$ and $g_{\\max} = \\max_i g_i$. The normalized norm for instance $i$ is:\n    $$\n    g_{\\mathrm{norm}}(x_i) = \\begin{cases}\n    0  \\text{if } g_{\\max} = g_{\\min} \\\\\n    \\frac{g(x_i) - g_{\\min}}{g_{\\max} - g_{\\min}}  \\text{otherwise}\n    \\end{cases}.\n    $$\n    This places the gradient norms on a common scale of $[0, 1]$ for each test case.\n\n**Step 3: Computation of the Composite Privacy Risk Score, $r(x)$**\n\nThe three signals are combined into a single risk score $r(x)$ using a weighted sum, with non-negative weights $\\alpha, \\beta, \\gamma$ provided for each test case:\n$$\nr(x) = \\alpha \\cdot \\big(1 - m(x)\\big) + \\beta \\cdot H_{\\mathrm{norm}}\\!\\big(p_\\theta(\\cdot \\mid x)\\big) + \\gamma \\cdot g_{\\mathrm{norm}}(x).\n$$\nA higher score $r(x)$ is hypothesized to indicate a greater likelihood that $x$ was part of the training set (a \"member\"), corresponding to higher membership inference vulnerability.\n\n**Step 4: Validation using ROC AUC**\n\nThe effectiveness of $r(x)$ as a membership score is evaluated by calculating the ROC AUC. This metric quantifies the ability of the score to distinguish between members ($y_{\\mathrm{mem}}=1$) and non-members ($y_{\\mathrm{mem}}=0$). We use the rank-based formula for AUC, which is equivalent to the Mann-Whitney $U$ statistic normalized by the product of the number of samples in each class.\n\nLet $\\{r_i\\}_{i=1}^N$ be the set of risk scores for all $N$ instances in a test case.\n1.  **Ranking**: We first compute the rank of each score $r_i$ in the combined list of all scores. Ranks start at $1$. In case of ties, all tied scores receive the average of the ranks they would occupy. For example, if two scores are tied for the 2nd and 3rd positions, both receive rank $(2+3)/2 = 2.5$.\n2.  **U Statistic**: Let $n_1$ be the count of members and $n_0$ be the count of non-members. The Mann-Whitney $U$ statistic is calculated by summing the ranks of the scores corresponding to the member instances and subtracting a correction term:\n    $$\n    U = \\sum_{i:\\, y_{\\mathrm{mem},i} = 1} \\mathrm{rank}(r_i) - \\frac{n_1 (n_1 + 1)}{2}.\n    $$\n3.  **AUC Calculation**: The AUC is then given by:\n    $$\n    \\mathrm{AUC} = \\frac{U}{n_0 n_1}.\n    $$\nThis value ranges from $0$ to $1$, where $1.0$ indicates perfect separation (all members have higher scores than all non-members), $0.5$ indicates performance no better than random chance, and $0.0$ indicates perfect inverse separation.\n\nThis complete procedure is applied to each of the three test cases to yield the final list of AUC values.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the ROC AUC for a membership inference attack based on a composite privacy risk score.\n    \"\"\"\n    test_cases = [\n        {\n            \"C\": 3,\n            \"weights\": (0.5, 0.3, 0.2),  # alpha, beta, gamma\n            \"samples\": [\n                {\"logits\": [3.0, 0.2, -1.0], \"grad_norm\": 0.10, \"y_mem\": 0},\n                {\"logits\": [2.5, -0.5, 0.0], \"grad_norm\": 0.15, \"y_mem\": 0},\n                {\"logits\": [-1.0, 0.0, 3.0], \"grad_norm\": 0.05, \"y_mem\": 0},\n                {\"logits\": [0.5, 0.4, 0.3], \"grad_norm\": 0.90, \"y_mem\": 1},\n                {\"logits\": [0.0, 0.1, 0.2], \"grad_norm\": 0.70, \"y_mem\": 1},\n                {\"logits\": [0.2, 0.1, 0.2], \"grad_norm\": 1.20, \"y_mem\": 1},\n            ]\n        },\n        {\n            \"C\": 3,\n            \"weights\": (0.5, 0.3, 0.2),\n            \"samples\": [\n                {\"logits\": [1.5, 1.4, 1.3], \"grad_norm\": 0.60, \"y_mem\": 0},\n                {\"logits\": [2.0, 0.0, 0.0], \"grad_norm\": 0.40, \"y_mem\": 0},\n                {\"logits\": [0.5, -0.2, 1.0], \"grad_norm\": 0.55, \"y_mem\": 0},\n                {\"logits\": [0.8, 0.7, 0.1], \"grad_norm\": 0.50, \"y_mem\": 1},\n                {\"logits\": [1.8, 0.9, 0.7], \"grad_norm\": 0.45, \"y_mem\": 1},\n                {\"logits\": [0.2, 0.2, 0.2], \"grad_norm\": 0.65, \"y_mem\": 1},\n            ]\n        },\n        {\n            \"C\": 3,\n            \"weights\": (0.5, 0.3, 0.2),\n            \"samples\": [\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 1},\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 0},\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 1},\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 0},\n            ]\n        }\n    ]\n\n    def rankdata(data):\n        \"\"\"\n        Assigns ranks to data, dealing with ties by averaging. Ranks are 1-based.\n        Equivalent to scipy.stats.rankdata(method='average').\n        \"\"\"\n        n = len(data)\n        indexed_data = sorted([(data[i], i) for i in range(n)])\n        \n        ranks = [0.0] * n\n        i = 0\n        while i  n:\n            j = i\n            while j  n - 1 and indexed_data[j][0] == indexed_data[j+1][0]:\n                j += 1\n            \n            # Indices of tied items in the sorted list are from i to j.\n            # Ranks are 1-based, so they would occupy ranks from i+1 to j+1.\n            sum_ranks = sum(range(i + 1, j + 2))\n            avg_rank = sum_ranks / (j - i + 1)\n            \n            for k in range(i, j + 1):\n                original_index = indexed_data[k][1]\n                ranks[original_index] = avg_rank\n            \n            i = j + 1\n            \n        return ranks\n\n    all_results = []\n    for case in test_cases:\n        C = case[\"C\"]\n        alpha, beta, gamma = case[\"weights\"]\n        samples = case[\"samples\"]\n        \n        # Lists to store intermediate computed values for each sample\n        margins = []\n        norm_entropies = []\n        raw_grad_norms = []\n        labels = []\n\n        log_C = np.log(C)\n\n        for sample in samples:\n            logits = np.array(sample[\"logits\"])\n            \n            # 1. Compute probabilities using stable softmax\n            z_stable = logits - np.max(logits)\n            p = np.exp(z_stable) / np.sum(np.exp(z_stable))\n            \n            # 2. Compute margin\n            p_sorted = np.sort(p)[::-1]\n            margin = p_sorted[0] - p_sorted[1] if len(p_sorted) > 1 else p_sorted[0]\n            margins.append(margin)\n            \n            # 3. Compute normalized entropy\n            # Take log only of non-zero probabilities to avoid -inf from log(0)\n            non_zero_p = p[p > 0]\n            entropy = -np.sum(non_zero_p * np.log(non_zero_p))\n            norm_entropy = entropy / log_C\n            norm_entropies.append(norm_entropy)\n            \n            raw_grad_norms.append(sample[\"grad_norm\"])\n            labels.append(sample[\"y_mem\"])\n\n        # 4. Normalize gradient norms for the entire test case\n        g = np.array(raw_grad_norms)\n        g_min, g_max = np.min(g), np.max(g)\n        if g_max == g_min:\n            g_norm = np.zeros_like(g, dtype=float)\n        else:\n            g_norm = (g - g_min) / (g_max - g_min)\n\n        # 5. Compute the final risk score for each sample\n        risk_scores = [\n            alpha * (1 - m) + beta * h_norm + gamma * gn\n            for m, h_norm, gn in zip(margins, norm_entropies, g_norm)\n        ]\n        \n        # 6. Compute ROC AUC using the Mann-Whitney U statistic\n        n0 = labels.count(0)\n        n1 = labels.count(1)\n        \n        if n0 == 0 or n1 == 0:\n            # Although test cases prevent this, handle the edge case.\n            # AUC is typically defined as 0.5 if one class is missing.\n            auc = 0.5  \n        else:\n            ranks = rankdata(risk_scores)\n            sum_ranks_members = sum(ranks[i] for i, label in enumerate(labels) if label == 1)\n            \n            U = sum_ranks_members - (n1 * (n1 + 1) / 2.0)\n            auc = U / (float(n0) * float(n1))\n            \n        all_results.append(auc)\n\n    print(f\"[{','.join(f'{r:.6f}' for r in all_results)}]\")\n\nsolve()\n```", "id": "3149361"}]}